Figure 1: General nonlinear transform coding framework (Balle, Laparra, and Simoncelli, 2016). Avector of image intensities x ∈ RN is mapped to a latent code space via a parametric analysis trans-form, y = ga (x; φ). This representation is quantized, yielding a discrete-valued vector q ∈ ZMwhich is then compressed. The rate of this discrete code, R, is lower-bounded by the entropy ofthe discrete probability distribution of the quantized vector, H [Pq]. To reconstruct the compressedimage, the discrete elements of q are reinterpreted as a continuous-valued vector y, which is trans-formed back to the data space using a parametric synthesis transform X = gs(y; θ). Distortion isassessed by transforming to a perceptual space using a (fixed) transform, z = gp(X), and evaluatinga metric d(z, z). We optimize the parameter vectors φ and θ for a weighted sum of the rate anddistortion measures, R + λD, over a set of images.
Figure 2: Left: The rate-distortion trade-off. The gray region represents the set of all rate-distortionvalues that can be achieved (over all possible parameter settings). Optimal performance for a givenchoice of λ corresponds to a point on the convex hull of this set with slope -1∕λ. Right: One-dimensional illustration of relationship between densities of yi (elements of code space), yi (quan-tized elements), and yi (elements perturbed by uniform noise). Each discrete probability in Pyiequals the probability mass of the density pyi within the corresponding quantization bin (indicatedby shading). The density Pyi provides a continuous function that interpolates the discrete probabilityvalues Pyi at integer positions.
Figure 3: Representation of the relaxed rate-distortion optimization problem as the encoder anddecoder graphs of a variational autoencoder. Nodes represent random variables, and gray shadingindicates observed data; small filled nodes represent parameters; arrows indicate dependency; andnodes within boxes are per-image.
Figure 4: Scatter plots comparing discrete vs. continuously-relaxed values of the two terms of theobjective function, evaluated for the optimized GDN model. Points correspond to different valuesof λ between 32 and 2048 (inclusive), for images drawn from a random subset of 2169 images (onethird) from the training set. Left: distortion term, evaluated for gs(y) vs. gs(y). Right: rate term,H[Pqi ] vs. h[pyi] (summed over i).
Figure 5: A heavily compressed example image, 752 × 376 pixels. Note the appearance of artifacts,especially near edges, in both the JPEG and JPEG2000 images.
Figure 6: Cropped portion of an image compressed at three different bit rates. Middle row: theproposed method, at three different settings of λ. Top row: JPEG, with three different qualitysettings. Bottom row: JPEG 2000, with three different rate settings. Bit rates within each columnare matched.
Figure 7: Rate-distortion curves for the luma component of image shown in figure 5. Left: Per-ceptual quality, measured with multi-scale structural similarity (MS-SSIM; Wang, Simoncelli, andBovik (2003)). Right: peak signal-to-noise ratio (10 log10 (2552/MSE)).
Figure 8: Parameterization of analysis (ga) and synthesis (gs) transforms for grayscale images.
Figure 9: Binarization of a quantized value for binary arithmetic coding. Each circle representsa binary decision encoded with its own CABAC context. Arrows pointing left represent “false”,arrows pointing right “true”. On reaching END, the encoding of the quantized value is completed.
Figure 10: Rate-distortion comparison of adaptive vs. non-adaptive entropy coding, averaged (foreach value of λ) over the 24 images in the Kodak test set. The non-adaptive entropy code is simulatedby computing the entropy of q assuming the probability model determined during optimization(which is also used to initialize the adaptive code).
Figure 11: Summary rate-distortion curves, computed by averaging results over the 24 images inthe Kodak test set. Each point is connected by translucent lines to the set of24 points correspondingto the individual image R-D values from which it was derived. JPEG results are averaged overimages compressed with identical quality settings. Results of the proposed method are averagedover images compressed with identical λ values (and thus, computed with exactly the same forwardand inverse transforms). The two JPEG 2000 curves are computed with the same implementation,by averaging over images compressed with the same target rate or the same target quality. Note thatthese two methods of selecting points to be averaged lead to significantly different average results.
Figure 12: RGB example, from our personal collection, downsampled and cropped to 752 × 376pixels.
Figure 13: RGB example, from our personal collection, downsampled and cropped to 752 × 376pixels.
Figure 14: RGB example, from our personal collection, downsampled and cropped to 752 × 376pixels.
Figure 15: RGB example, from our personal collection, downsampled and cropped to 752 × 376pixels.
Figure 16: RGB example, from our personal collection, downsampled and cropped to 752 × 376pixels.
Figure 17: Grayscale example, from our personal collection, downsampled and cropped to 752× 376pixels.
Figure 18: Grayscale example, from our personal collection, downsampled and cropped to 752× 376pixels.
Figure 19: Grayscale example, from our personal collection, downsampled and cropped to 752× 376pixels.
Figure 20: Grayscale example, from our personal collection, downsampled and cropped to 752× 376pixels.
Figure 21: Grayscale example, from the Kodak test set, downsampled and cropped to 752 × 376pixels.
