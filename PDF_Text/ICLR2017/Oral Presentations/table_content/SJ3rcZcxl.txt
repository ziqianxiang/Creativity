Table 1: Q-Prop, TRPO and DDPG results showing the max average rewards attained in the first30k episodes and the episodes to cross specific reward thresholds. Q-Prop often learns more sampleefficiently than TRPO and can solve difficult domains such as Humanoid better than DDPG.
Table 2: Implementation options and edge cases of the generalized Q-Prop estimator in Eq. 17.
