title,year,conference
 Neural machine translation by jointly learning toalign and translate,2014, arXiv preprint arXiv:1409
 A maximum likelihood approach to continuous speechrecognition,1983, PAMI
 Exploiting latent semantic information in statistical language modeling,2000, Proceedings ofthe IEEE
 A neural probabilistic languagemodel,2003, JMLR
 The mathematics ofstatistical machine translation: Parameter estimation,1993, Computational linguistics
 Empirical evaluation of gated re-current neural networks on sequence modeling,2014, arXiv preprint arXiv:1412
 Towards better integration of semantic predictors in statistical languagemodeling,1998, In ICSLP
 Adaptive language modelingusing minimum discriminant estimation,1992, In Proceedings of the workshop on Speech and Natural Language
 Evaluating prerequisite qualities for learning end-to-end dialog systems,2015, arXiv preprintarXiv:1511
 Adaptive subgradient methods for online learning and stochasticoptimization,2011, JMLR
 Finding structure in time,1990, Cognitive science
 A theoretically grounded application of dropout in recurrent neural net-works,2015, arXiv preprint arXiv:1512
 Efficient Softmax ap-proximation for gpus,2016, arXiv preprint arXiv:1609
 Speech recognition with deep recurrent neural networks,2013, In ICASSP
 Neural turing machines,2014, arXiv preprint arXiv:1410
 Learning to transduce withunbounded memory,2015, In Advances in Neural Information Processing Systems
 Pointing the unknownwords,2016, arXiv preprint arXiv:1603
 Teaching machines to read and comprehend,2015, In NIPS
 Long short-term memory,1997, Neural Computation
 Modeling long distance dependence in language: Topic mixtures versusdynamic cache models,1999, IEEE Transactions on speech and audio processing
 A dynamic language model for speechrecognition,1991, In HLT
 Inferring algorithmic patterns with stack-augmented recurrent nets,2015, InAdvances in Neural Information Processing Systems
 Exploring the limits oflanguage modeling,2016, arXiv preprint arXiv:1602
 Text understanding with the attention sumreader network,2016, arXiv preprint arXiv:1603
 Estimation of probabilities from sparse data for the language model component of a speechrecognizer,1987, ICASSP
 Improved backing-off for m-gram language modeling,1995, In ICASSP
 On the dynamic adaptation of stochastic language models,1993, In ICASSP
 A cache-based natural language model for speech recognition,1990, PAMI
 Trigger-based language models: A maximum entropyapproach,1993, In ICASSP
 Building a large annotated corpus ofenglish: The penn treebank,1993, Computational linguistics
 Pointer sentinel mixture models,2016, arXivpreprint arXiv:1609
 Context dependent recurrent neural network language model,2012, In SLT
 Recurrent neuralnetwork based language model,2010, In INTERSPEECH
 Empirical evaluation andcombination of advanced language modeling techniques,2011, In INTERSPEECH
 Learning longermemory in recurrent neural networks,2014, arXiv preprint arXiv:1412
 A maximum entropy approach to adaptive statistical language modeling,1996, Computer
 Dialogue act modeling for automatic taggingand recognition of conversational speech,2000, Computational linguistics
 End-to-end memory networks,2015, In NIPS
 Pointer networks,2015, In NIPS
 Larger-context language modelling,2015, arXiv preprint arXiv:1511
 Backpropagation through time: what it does and how to do it,1990, 1990
 An efficient gradient-based algorithm for on-line training of recurrent net-work trajectories,1990, Neural computation
 Recurrent neural network regularization,2014, arXiv preprintarXiv:1409
 Recurrent highwaynetworks,2016, arXiv preprint arXiv:1607
