title,year,conference
 Negative correlations in visual cortical networks,2016, CerebralCortex
 Reducing over-fitting in deep networks by decorrelating representations,2016, ICLR
 Understanding the difficulty of training deep feedforward neuralnetworks,2010, In AISTATS
 Fractional max-pooling,2014, arXiv preprint arXiv:1412
 Deep residual learning for image recog-nition,2015, arXiv preprint arXiv:1512
 Delving deep into rectifiers: Surpassinghuman-level performance on imagenet classification,2015, In ICCV
 Deep networks with stochas-tic depth,2016, arXiv preprint arXiv:1603
 Batch normalization: Accelerating deep network training byreducing internal covariate shift,2015, In ICML
 ImageNet Classification with Deep Con-volutional Neural Networks,2012, In NIPS
 Gradient-based learning applied todocument recognition,1998, Proceedings of the IEEE
 Deeply-supervised nets,2015, In Guy Lebanon and S
 Multi-bias non-linear activation in deep neuralnetworks,2016, arXiv preprint arXiv:1604
 Network in network,2014, arXiv preprint arXiv:1312
 All you need is a good init,2016, ICLR
 Readingdigits in natural images with unsupervised feature learning,2011, 2011
 Imagenet large scale visualrecognition challenge,2015, IJCV
 Exact solutions to the nonlinear dy-namics of learning in deep linear neural networks,2013, arXiv:1312
 Striving for sim-plicity: The all convolutional net,2015, In ICLR (workshop track)
 Training very deep networks,2015, In NIPS
 Going deeper with convolutions,2015, InCVPR
 Regularization of neuralnetworks using dropconnect,2013, In ICML
 Wide residual networks,2016, In BMVC
 Wide residual networks,2016, arXiv preprintarXiv:1605
 Visualizing and understanding convolutional networks,2014, InECCV
