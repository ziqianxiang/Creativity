title,year,conference
 Consensus attention-basedneural networks for chinese reading comprehension,2016, In arXiv preprint arXiv:1607
 Teaching machines to read and comprehend,2015, In Proceedings of theConference on Advances in Neural Information Processing Systems
 WIKIREADING: A novel large-scale language under-standing task over wikipedia,2016, In Proceedings of the Conference on Association for ComputationalLinguistics
 The Goldilocks principle: Read-ing childrenâ€™s books with explicit memory representations,2016, In Proceedings of the InternationalConference on Learning Representations
 Long short-term memory,1997, Neural computation
 Text understanding with theattention sum reader network,2016, In Proceedings of the Conference on Association for ComputationalLinguistics
 Adam: A method for stochastic oPtimization,2015, In Proceedings ofthe International Conference on Learning Representations
 Ask me anything: Dynamic memory networksfor natural language Processing,2016, In Proceedings of the International Conference on MachineLearning
 MS MARCO: a human generated machine reading comPrehension dataset,2016, arXivpreprint arXiv:1611
 GloVe: Global vectors for wordrePresentation,2014, In Proceedings of the Conference on Empirical Methods in Natural LanguageProcessing
 MCTest: A challenge dataset forthe oPen-domain machine comPrehension of text,2013, In Proceedings of the Conference on EmpiricalMethods in Natural Language Processing
 Natural language comPrehensionwith the EPiReader,2016, In Proceedings of the Conference on Empirical Methods in Natural LanguageProcessing
 Learning natural language inference with LSTM,2016, In Proceedings ofthe Conference on the North American Chapter of the Association for Computational Linguistics
 Attention-based convolutional neural networkfor machine comprehension,2016, arXiv preprint arXiv:1602
