Figure 1: Memory-augmented neural language modelling architectures.
Figure 2: Perplexities of memory-augmented neural language models on the Wikipedia corpus (a-c)and accuracies on the CBT test set (d).
Figure 3: Attention weights of the Key-Value-Predict model on a randomly sampled Wikipediaarticle (a) and average attention weight distribution on the whole Wikipedia test set for RM(+tM-g),Attention, Key-Value and Key-Value-Predict models (b). The rightmost positions represent the mostrecent history.
