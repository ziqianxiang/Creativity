Figure 1:	Statically Binarized MNISTdecompressions is an exact reconstruction of the original image but instead the global structure ofthe image was encoded in the lossy code z and regenerated. Also worth noting is that local statisticsare not preserved but a new set of likely local statistics are generated in the decompressed images:the binary masks are usually different and local styles like stroke width are sometimes slightly dif-ferent.
Figure 2:	OMNIGLOT4.2	Density EstimationNext we investigate whether leveraging autoregressive models as latent distribution p(z) and asdecoding distribution p(x|z) would improve density estimation performance.
Figure 3: CIFAR10: Original test-set images (left) and “decompressioned” versions from VLAE’slossy code (right) with different types of receptive fieldsIt’s interesting to also note that in (a)-(c), oftentimes color information is partially omitted fromlatent codes and one explanation can be that color is very predictable locally. However, colorinformation can be important to preserve if our task is, for example, object classification. Todemonstrate how we can encode color information in the lossy code, we can choose to makePixelCNN decoder depend only on images’ grayscale versions. In other words, instead of choos-ing the decoder to be plocal (x|z) = Qi p(xi |z, xWindowAround(i)), we use a decoder of the formplocal(x|z) = Qi p(xi |z, Grayscale(xWindowAround(i))). In (d) of Figure 3, we visualize lossycodes for a VLAE that has the same receptive field size as (c) but uses a “grayscale receptive field”.
Figure 4: CIFAR10: Generated samples for different models(b) 7x4 @ 2.95 bits/dimDjork-Ame CleVerL Thomas Unterthiner, and SePP Hochreiter. Fast and accurate deep networklearning by Exponential Linear Units (ELUs). arXiv preprint arXiv:1511.07289, 2015.
