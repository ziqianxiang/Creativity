Figure 1:	Sample dialogues for the two Question Clarification tasks (rows) using both the traditionalQA setting (left Column) and AQ setting (right Column). In eaCh Case the same example is given forsimpliCity. BlaCk text prefixed by “kb:” denotes KB knowledge that the student has aCCess to.
Figure 2:	Sample dialogues for Knowledge Operation tasks.
Figure 3:	Different Tasks for Knowledge Acquisition. Crossed lines correspond to entries of theKB whose retrieval is missed.
Figure 4: An illustration of the poor-student setting for RL Task 1 (Question Paraphrase).
Figure 5: Sample dialogues for Mechanical Turk versions of Tasks 4 and 8. Compared to the originaltasks (see Figs 2 and 3) the teacher’s questions, and the teacher responses to the student’s questions,are written by humans and are more complex and contain more variety.
Figure 6: Results of online learning for Task 2 and Task 6have different abilities to correctly answer questions (e.g., a poor student can still sometimes givecorrect answers even when they do not fully understand the question). Task 6 represents tasks wherea poor learner who lacks the knowledge necessary to answer the question can hardly give a correctanswer. All types of students including the good student will theoretically benefit from askingquestions (asking for the correct answer) in Task 6. We show the percentage of question-askingversus the cost of AQ on the test set and the accuracy of question-answering on the test set vs thecost of AQ. Our main findings were:•	A good student does not need to ask questions in Task 2 (Question Verification), becausethey already understand the question. The student will raise questions asking for the correctanswer when cost is low for Task 6 (Missing Answer Entities).
