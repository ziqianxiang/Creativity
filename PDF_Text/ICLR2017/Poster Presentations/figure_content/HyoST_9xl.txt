Figure 1: Dense-Sparse-Dense Training Flow. The sparse training regularizes the model, and the finaldense training restores the pruned weights (red), increasing the model capacity without overfitting.
Figure 2: Weight distribution of a layer of GoogLeNet at different points in DSD training: the originalGoogLeNet (a), pruned (b), after retraining with the sparsity constraint (c), ignoring the sparistyconstraint and recovering the zero weights (d), and after retraining the dense network (e).
Figure 3: Visualization of DSD training improving the performance of image captioning.
Figure 4: Significance of DSD improvements over baseline and fine-tuneBased on the results above, DSD significantly improves conventional baseline training and is also significantlybetter and more robust than conventional fine-tuning.
