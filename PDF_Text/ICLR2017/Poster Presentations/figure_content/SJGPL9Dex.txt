Figure 1: Network architecture for ISTA/LISTA. The unfolded version (b) is trainablethrough backpropagation and permits to approximate the sparse coding solution efficiently.
Figure 2:	Evolution of the cost function F(Zk) — F(z*) with the number of layers or thenumber of iteration k for different sparsity level. (left) ρ = 1/20 and (right)ρ = 1/4 .
Figure 3:	Evolution of the cost function F(Zk) — F(z*) With the number of layers or thenumber of iteration k for a problem generated with an adversarial dictionary.
Figure 4: Evolution of the cost function F(Zk) — F(z*) with the number of layers or thenumber of iteration k for two image datasets.
Figure 5: Network architecture for LFISTA. This network is trainable through backpropa-gation and permits to approximate the sparse coding solution efficiently.
