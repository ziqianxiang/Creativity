Figure 1: We consider the problem of semi-supervised reinforcement learning, where a rewardfunction can be evaluated in some small set of labeled MDPs M ∈ L, but the resulting policy mustbe successful on a larger set of unlabeled MDPs M ∈ L for which the reward function is not known.
Figure 2: Illustrations of the tasks. For the reacher with vision, the range of the target for the labeledMDPs is shown with a red dotted line, and for the unlabeled MDPs with a green dashed line. Forthe obstacle and cheetah tasks, we show the highest obstacle height.
Figure 3: Generalization capability of the obstacle, 2-link reacher, and half-cheetah tasks as a func-tion of the task variation. Performance for these tasks is averaged over 3 random seeds.
