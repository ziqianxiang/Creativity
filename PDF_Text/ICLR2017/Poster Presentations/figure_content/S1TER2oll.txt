Figure 1: Covariance analy-sis on natural imagesTheorem 2.	Suppose that σ : R 7→	R is a contraction mapping.
Figure 2: From left to right: (a) Sample spectrogram of bird wingbeats; (b) Sample spectrogram ofbird song; (c) Correlation image of bird wingbeats; (d) Correlation image of bird song.
Figure 3: The correlation image for gene se-quences.
Figure 4: The derived filter shapes for the wingbeat data6.2	Wingbeats classification resultsWe consider three baselines: 3 × 3, 3 × 5, 5 × 5 convolutional filters. These are selected since 3 × 3filter have roughly equal number of parameters compared to our customized filters, and 3 × 5 coversthe domain of the customized filter in the first 3 levels. In the baseline of 5 × 5 filters, we added L1regularization on the weights, in order to test whether the same effect of filter shaping can be learneddirectly from sparsity priors on the weights. The swipe range for the L1 regularization parameter isfrom 10-3 to 10-10, and we selected the one that generated best performance. 5-fold cross-validationis conducted at the recording level. Thus, no validation example comes from the same recording asany of the training examples. For training, we set the batch size to 20 for all designs and the learning7Published as a conference paper at ICLR 2017rate to 10-4 for the customized filters and 10-5 and 10-6 for the 3 × 3 and 3 × 5 filters respectively.
Figure 5: Accuracy on the wingbeats dataset6.3	Bird song classification resultsFor the bird song dataset, we compare to a baseline of 3 × 3 filter as well as a 5 × 5 filter with L1regularization, and the swipe range for the L1 regularization parameter is from 10-3 to 10-10 as well.
Figure 6: Validation accuracy on the birdsong and gene datasets6.4 rSNP Prediction ResultsFor the gene dataset, we compare with a baseline that is similar with the framework used by Zhou &Troyanskaya (2015), which contains several layers of CNN with 1 × 9 shape filters. 5-fold cross-validation was performed and the results are shown in Fig. 6(b). The customized model was 0.8%better than the baseline. The performance gap is not as significant as in the bird-bioacoustics data,mainly because that the solved filters are not different with traditional ones after max-pooling (see8Published as a conference paper at ICLR 2017appendix for details). Due to the fact that we apply no domain knowledge, our performance may notbe comparable with some recent papers which have used additional domain knowledge. However, itdemonstrates the strength of the customized filter design over traditional ones.
Figure 7: The derived filter shapes for the bird song data■ ■ ■ ■	1, Filter shape of first layer for gene data	2, Filter shape of second and third Layer for gene dataFigure 8: The derived filter shapes for gene dataTables 1, 2 and 3 describes the network structure for the wingbeats, birdsong and gene data,respectively. Every convolutional layer is followed by a ReLU layer.
Figure 8: The derived filter shapes for gene dataTables 1, 2 and 3 describes the network structure for the wingbeats, birdsong and gene data,respectively. Every convolutional layer is followed by a ReLU layer.
Figure 9: Sensitivity to the learning rate onthe bird song data.
Figure 10: Stability of DFMaxInstead of controlling the parameter λ in LASSO, weintroduce another parameter DFMax to limit themaximum number of nonzero solutions in LASSO. Itis shown that different DFMax values can generatedifferent sets of customized convolutional filters. Inorder to investigate the relation between DFMaxand performance, we swipe DFMax from 3 to 15and perform 5-fold cross validation on wingbeatsdataset. Fig. 10 shows that the performance of ourframework is stable for a wide range of DFMaxvalues. When DF Max equals to 3, all customizedconvolutional filters are in shape 1 × 3, it is reasonablefor its performance is not as high as the frameworkwith higher DF Max values.
