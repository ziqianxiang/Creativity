Figure 1: Alternative schedule schemes of learning rate ηt over batch index t: default schemeswith η0 = 0.1 (blue line) and η0 = 0.05 (red line) as used by Zagoruyko & Komodakis (2016);warm restarts simulated every T0 = 50 (green line), T0 = 100 (black line) and T0 = 200 (grey line)epochs with ηt decaying during i-th run from ηmi ax = 0.05 to ηmi in = 0 according to eq. (5); warmrestarts starting from epoch T0 = 1 (dark green line) and T0 = 10 (magenta line) with doubling(Tmult = 2) periods Ti at every new warm restart.
Figure 2: Test errors on CIFAR-10 (left column) and CIFAR-100 (right column) datasets. Note thatfor SGDR we only plot the recommended solutions. The top and middle rows show the same resultson WRN-28-10, with the middle row zooming into the good performance region of low test error.
Figure 3: Test errors of ensemble models built from N runs of SGDR on WRN-28-10 with Mmodel snapshots per run made at epochs 150, 70 and 30 (right before warm restarts of SGDR assuggested by Huang et al. (2016a)). When M=1 (respectively, M =2), we aggregate probabilities ofsoftmax layers of snapshot models at epoch index 150 (respectively, at epoch indexes 150 and 70).
Figure 4: (Top) Improvements obtained by the baseline learning rate schedule and SGDR w.r.t. thebest known reference classification error on a dataset of electroencephalographic (EEG) recordingsof brain activity for classification of actual right and left hand and foot movements of 14 subjectswith roughly 1000 trials per subject. Both considered approaches were tested with the initial learn-ing rate lr = 0.025 (Top-Left) and lr = 0.05 (Top-Right). Note that the baseline approach isconsidered with different settings of the total number of epochs: 30, 60, . . ., 480. (Bottom) SGDRwith lr = 0.025 and lr = 0.05 without and with M model snapshots taken at the last M = nr/2restarts, where nr is the total number of restarts.
Figure 5: Top-1 and Top-5 test errors obtained by SGD with momentum with the default learningrate schedule, SGDR with T0 = 1, Tmult = 2 and SGDR with T0 = 10, Tmult = 2 on WRN-28-10trained on a version of ImageNet, with all images from all 1000 classes downsampled to 32 × 32pixels. The same baseline data augmentation as for the CIFAR datasets is used. Four settings of theinitial learning rate are considered: 0.050, 0.025, 0.01 and 0.005.
Figure 6: The median results of 5 runs for the best learning rate settings considered for WRN-28-1.
Figure 7: Training cross-entropy + regularization loss (top row), test loss (middle row) and testerror (bottom row) on CIFAR-10 (left column) and CIFAR-100 (right column).
Figure 8: Top-5 test errors obtained by SGD with momentum with the default learning rate scheduleand SGDR with T0 = 1, Tmult = 2 on WRN-28-10 trained on a version of ImageNet, with allimages from all 1000 classes downsampled to 32 × 32 pixels. The same baseline data augmentationas for the CIFAR datasets is used. Three settings of the initial learning rate are considered: 0.050,0.015 and 0.005. In contrast to the experiments described in the main paper, here, the dataset ispermuted only within 10 subgroups each formed from 100 classes which makes good generalizationmuch harder to achieve for both algorithms. An interpretation of SGDR results given here mightbe that while the initial learning rate seems to be very important, SGDR reduces the problem ofimproper selection of the latter by scanning / annealing from the initial learning rate to 0.
