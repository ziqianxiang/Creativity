Figure 1: Strange attractor of a 2-unit LSTM. Successive zooms (from left to right) reveal the self-repeating, fractal nature of the attractor. Colored boxes depict zooming regions.
Figure 2: (a): A small neighborhood around a fixed initial condition u0 , after 200 iterations, ismapped to the entire attractor. (b): Two trajectories starting starting within 10-7 of one anotherstrongly diverge after 50 steps.
Figure 3: 228-unit LSTM trained on Penn Treebank. (a): In the absence of input data, the systemis chaotic and nearby trajectories diverge. (b): In the presence of input data, the system is mostlydriven by the external input. Trajectories starting far apart converge.
Figure 4: A 2-layer, 224-unit CFN trained on Penn Treebank. All inputs xt are zero after t = 1000,i.e. the time-point indicated by the dashed line. At left: plot of the 10 “slowest” units of the firstlayer. At right: plot of the 10 slowest units of the second layer. The second layer retains informationmuch longer than the first layer.
Figure 5: Strange attractor of the Henon map. From left to right: The Henon attractor, enlargementof the red box, enlargement of the magenta box.
Figure 6: Strange attractor of a two-unit GRU. Successive zooms reveal the fractal nature of theattractor.
