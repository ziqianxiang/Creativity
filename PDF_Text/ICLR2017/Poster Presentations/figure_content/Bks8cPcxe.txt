Figure 1: Basic workflow of DeepDSL.
Figure 2:	DeepDSL code for training and testing Lenet.
Figure 3:	A portion of the IR expressions and memory information compiled from LenetDeepDSL compiler generates Java source code for each of the IR expressions. For example, line3 loads a batch of images into GPU memory. Line 4 and line 5 perform forward convolution andpooling computation respectively. Line 18 prints out the training loss. Line 22 updates of the biasof the second convolution layer with its gradient.
Figure 4: Runtime performance of DeepDSL, Tensorflow, and Caffe (1 forward/backward iteration).
Figure 5: Peak GPU memory use of DeepDSL, Tensorflow, and Caffe during training. DeepDSLand DeepDSL* are performance in runtime-efficient and memory-efficient mode respectively. Cafferan out of GPU memory for Googlenet (batch 256) and ReSNet (batch 64). TenSorflow ran out ofmemory for ResNet (batch 64).
