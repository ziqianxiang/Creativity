Figure 1: ACER improvements in sample (left) and computation (right) complexity on Atari.
Figure 2: A schematic of the Stochastic Dueling Network. In the drawing, [u1,…，Un] are assumedto be samples from πθ (∙∣xt). This schematic illustrates the concept of SDNS but does not reflect thereal sizes of the networks used.
Figure 3: [Top] Screen shots of the continuous control tasks. [Bottom] Performance of differentmethods on these tasks. ACER outperforms all other methods and shows clear gains for the higher-dimensionality tasks (humanoid, cheetah, walker and fish). The proposed trust region method byitself improves the two baselines (truncated importance sampling and A3C) significantly.
Figure 4: Ablation analysis evaluating the effect of different components of ACER. Each rowcompares ACER with and without one component. The columns represents three control tasks. Redlines, in all plots, represent ACER whereas green lines ACER with missing components. This studyindicates that all 4 components studied improve performance where 3 are critical to success. Notethat the ACER curve is of course the same in all rows.
Figure 5: Log learning rate vs. cumulative rewards in all the continuous control tasks for ACER. Theplots show the final performance after training for all 30 log learning rates considered. Note that eachlearning rate is associated with a different δ as a consequence of random search over hyper-parameters.
Figure 6: Trust region constraint (δ) vs. cumulative rewards in all the continuous control tasks forACER. The plots show the final performance after training for all 30 trust region constraints (δ)searched over. Note that each δ is associated with a different learning rate as a consequence of randomsearch over hyper-parameters.
