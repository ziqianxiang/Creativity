Figure 1: The structure of Bidirectional Generative Adversarial Networks (BiGAN).
Figure 2: Qualitative results for permutation-invariant MNIST BiGAN training, including generatorsamples G(z), real data x, and corresponding reconstructions G(E(x)).
Figure 3: The convolutional filters learned by the three modules (D, G, and E) of a BiGAN (left,top-middle) trained on the ImageNet (Russakovsky et al., 2015) database. We compare with thefilters learned by a discriminator D trained with the same architecture (bottom-middle), as well asthe filters reported by Noroozi & Favaro (2016), and by Krizhevsky et al. (2012) for fully supervisedImageNet training (right).
Figure 4: Qualitative results for ImageNet BiGAN training, including generator samples G(z), realdata x, and corresponding reconstructions G(E(x)).
Figure 5: For the query images used in Krahenbuhl et al. (2016) (left), nearest neighbors (by minimumcosine distance) from the ImageNet LSVRC (RUssakovsky et al., 2015) training set in the fc6 featUrespace of the ImageNet-trained BiGAN encoder E . (The fc6 weights are set randomly; this space is arandom projection of the learned conv5 feature space.)Timing A single epoch (one training pass over the 1.2 million images) of BiGAN training takesroughly 40 minutes on a Titan X GPU. Models are trained for 100 epochs, for a total training time ofunder 3 days.
