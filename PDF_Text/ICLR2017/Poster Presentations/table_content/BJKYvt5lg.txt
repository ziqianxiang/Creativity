Table 1: We compare performance of different models on binarized MNIST. “PixelCNN” is themodel described in van den Oord et al. (2016a). Our corresponding latent variable model is “Pixel-VAE”. “Gated PixelCNN” and “Gated PixelVAE” use the gated activation function in van den Oordet al. (2016b). In “Gated PixelVAE without upsampling”, a linear transformation of latent variableconditions the (gated) activation in every PixelCNN layer instead of using upsampling layers.
Table 2: Model performance on 64 × 64 ImageNet. We achieve competitive NLL at a fraction of thecomputational complexity of other leading models.
