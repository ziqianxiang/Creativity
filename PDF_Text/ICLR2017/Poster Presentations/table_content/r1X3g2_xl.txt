Table 1: Summary of datasets. Note that unlabeled examples for the Rotten Tomatoes dataset are notprovided so we instead use the unlabeled Amazon reviews dataset.
Table 2: Test performance on the IMDB sentiment classification task. * indicates using pretrainedembeddings of CNN and bidirectional LSTM.
Table 3: 10 top nearest neighbors to ‘good’ and ‘bad’ with the word embeddings trained on eachmethod. We used cosine distance for the metric. ‘Baseline’ means training with embedding dropoutand ‘Random’ means training with random perturbation with labeled examples. ‘Adversarial’ and‘Virtual Adversarial’ mean adversarial training and virtual adversarial training.
Table 4: Test performance on the Elec and RCV1 classification tasks. * indicates using pretrained embeddings of CNN, and * indicates using pretrained embeddings of CNN and bidirectional LSTM.		Method	Test error rate		Elec	RCV1Baseline	6.24%	7.40%Adversarial	5.61%	7.12%Virtual Adversarial	5.54%	7.05%Adversarial + Virtual Adversarial	5.40%	6.97%Virtual Adversarial (on bidirectional LSTM)	5.55%	6.71%Adversarial + Virtual Adversarial (on bidirectional LSTM)	5.45%	6.68%Transductive SVM (Johnson & Zhang, 2015b)	16.41%	10.77%NBLM (Naive Bayes Iogisitic regression model) (Johnson & Zhang, 2015a)	8.11%	13.97%One-hot CNN* (Johnson & Zhang, 2015b)	6.27%	7.71%One-hot CNN* (Johnson & Zhang, 2016b)	5.87%	7.15%One-hot bi-LSTM* (Johnson & Zhang, 2016b)	5.55%	8.52%Table 5: Test performance on the Rotten Tomatoes sentiment classification task. * indicates usingpretrained embeddings from word2vec Google News, and * indicates using unlabeled data fromAmazon reviews.
Table 5: Test performance on the Rotten Tomatoes sentiment classification task. * indicates usingpretrained embeddings from word2vec Google News, and * indicates using unlabeled data fromAmazon reviews.
Table 6: Test performance on the DBpedia topic classification taskMethod	Test error rateBaseline (without embedding normalization)	0.87%Baseline	0.90%Random perturbation	0.85%Adversarial	0.79%Virtual Adversarial	0.76%Bag-of-words(Zhang et al., 2015)	3.57%Large-CNN(character-level) (Zhang et al., 2015)	1.73%SA-LSTM(word-level)(Dai & Le, 2015)	1.41%N-grams TFIDF (Zhang et al., 2015)	1.31%SA-LSTM(character-level)(Dai & Le, 2015)	1.19%Word CNN (Johnson & Zhang, 2016a)	0.84%8Published as a conference paper at ICLR 20176	Related worksDropout (Srivastava et al., 2014) is a regularization method widely used for many domains includingtext. There are some previous works adding random noise to the input and hidden layer duringtraining, to prevent overfitting (e.g. (Sietsma & Dow, 1991; Poole et al., 2013)). However, inour experiments and in previous works (Miyato et al., 2016), training with adversarial and virtual
