Table 1: The softmax predicted class probability allows for discrimination between correctly andincorrectly classified test set examples. “Pred. Prob Wrong(mean)” is the mean softmax probabilityfor wrongly classified examples, showcasing its shortcoming as a direct measure of confidence.
Table 2: Distinguishing in- and out-of-distribution test set data for image classification. CIFAR-10/All is the same as CIFAR-10/(SUN, Gaussian). All values are percentages.
Table 3: Detecting correct and incorrect classifications for binary sentiment classification.
Table 4: Distinguishing in- and out-of-distribution test set data for binary sentiment classification.
Table 5: Detecting correct and incorrect classifications for text categorization.
Table 6: Distinguishing in- and out-of-distribution test set data for text categorization.
Table 7: Detecting correct and incorrect classifications for part-of-speech tagging.
Table 8: Detecting out-of-distribution tweets and blog articles for part-of-speech tagging. All valuesare percentages. *These examples are atypically close to the training distribution.
Table 9: Detecting out-of-distribution distorted speech. All values are percentages.
Table 10: Abnormality modules can generalize to novel distortions and detect out-of-distributionexamples even when they do not severely degrade accuracy. All values are percentages.
Table 11: Improved detection using the abnormality module. All values are percentages.
