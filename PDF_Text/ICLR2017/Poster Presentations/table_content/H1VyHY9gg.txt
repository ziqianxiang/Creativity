Table 1: Noising schemes Example noising schemes and their bigram smoothing analogues. HereWe consider the bigram probability p(χ1,χ2) = p(χ2∣χι)p(χι). Notation: Y(xi：t) denotes thenoising probability for a given input sequence x1:t, q(x) denotes the proposal distribution, andN1+(x, •) denotes the number of distinct bigrams in the training set Where x is the first unigram. Inall but the last case We only noise the context x1 and not the target prediction x2 .
Table 2: Single-model perplexity on Penn Treebank with different noising schemes. We also com-pare to the variational method of Gal (2015), who also train LSTM models with the same hiddendimension. Note that performing Monte Carlo dropout at test time is significantly more expensivethan our approach, where test time is unchanged.
Table 3: Perplexity on Text8 with different noising schemes.
Table 4: Perplexities and BLEU scores for machine translation task. Results for bigram KN noisingon only the source sequence and only the target sequence are given as well.
Table 5: Perplexity of last unigram for unseen bigrams and trigrams in Penn Treebank validationset. We compare noised and unnoised models with noising probabilities chosen such that modelshave near-identical perplexity on full validation set.
