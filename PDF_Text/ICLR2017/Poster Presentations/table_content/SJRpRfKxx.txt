Table 1: Accuracy of saliency prediction for the Trained Central Bias baseline and different variantsof our RMDN model in terms of AUC, NSS, CC and Similarity. Training and testing are performedon disjoint splits of the HollyWood2 dataset.
Table 2: Saliency prediction comparison against the state-of-the-art on the Hollywood2 dataset. Thetop-3 best results for each set are taken from (Mathe & Sminchisescu, 2015)Set		Model	AUCBaselines	Uniform Central Bias (CB) Trained Central Bias (TCB) Human	0.500 0.840 0.872 0.936SF = Static Features	Color features (Judd et al., 2009) Saliency map (Oliva & Torralba, 2001) Horizon det. (Oliva & Torralba, 2001)	0.644 0.702 0.741MF = Motion Features (Mathe & Sminchisescu, 2015)	Flow magnitude Flow bimodality HOG-MBH det.	0.626 0.637 0.743Combo (Mathe & Sminchisescu, 2015)	SF (JUdd et al., 2009) SF+MF SF+MF+CB	0.789 0.812 0.871OUr Method	RMDN	0.9044.2	Action RecognitionIn order to show how saliency can be used for action recognition we carried out a set of experi-ments covering two scenarios: 1) using the same dataset where the saliency predictor was trained(Hollywood2) and 2) using a never-seen dataset with a different set of actions (UCF101).
Table 3: Action categorization results in terms of mAP on the Hollywod2 dataset. Analysis ofdifferent ways to use the saliency map and comparison between using the ground truth saliencymaps versus those predicted by our model.
Table 4: Recognition results in terms of mAP for the Hollywood2 dataset. The proposed method(RMDN) is compared to the approaches reported by Mathe & Sminchisescu (2015) (named as cen-tral bias and saliency sampling). Note that Mathe & Sminchisescu (2015) and RDMN do not usethe Same Video Classfication model.
Table 5: Action categorization results in terms of 3-fold accuracy on the UCF101 dataset.
