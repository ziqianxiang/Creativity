Table 1: Accuracy of the MNIST classifier onthe sampled transferred by our DTN method fromSHVN to MNIST.
Table 2: Domain adaptation fromSVHN to MNISTMethod	AccuracySA Fernando et al. (2013)	59.32%DANN Ganin et al. (2016)	73.85%DTN on SVHN transferring the train split s	84.44%DTN on SVHN transferring the test split	79.72%the face domain, we transfer a set of random and unlabeled face images to a space of emoji images.
Table 3: Comparison of recognition accuracy of the digit 3 as generated in MNISTMethod	ACCuraCy of ‘3’DTN	94.67%‘3’ was not shown in s	93.33%‘3’ was not shown in t	40.13%‘3’ was not shown in both s or t	60.02%‘3' was not shown in s, t, and during the training of f	4.52 %to emphasize the simplicity of the approach; However, the constraints of the unsupervised domaintransfer problem would be respected for any classifier trained on G(s). The results of this experi-ment are reported in Tab. 2, which shows a clear advantage over the state of the art method of Ganinet al. (2016). This is true both when transferring the samples of the set s and when transferring thetest set of SVHN, which is much smaller and was not seen during the training of the DTN.
Table 4: Comparison of retrieval accuracy out of a set of 100,001 face images for either manuallycreated emoji or the one created by the DTN method.
