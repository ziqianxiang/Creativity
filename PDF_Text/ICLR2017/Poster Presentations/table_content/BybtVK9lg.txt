Table 1: Average topic coherence on the 20 Newsgroups dataset. Higher is better.
Table 2: Average topic coherence on the RCV1 dataset. Higher is better. Results not reported forLDA DMFVI, as inference failed to converge in 24 hours.
Table 3: Perplexity scores for 20 Newsgroups. Lower is better.
Table 4: Evaluation of inference network of VAE-LDA on 20 Newsgroups test set. “Inferencenetwork only” shows the test perplexity when the inference network is trained on the training set,but no variational optimization is performed on the test set. “Inference Network + Optimization”shows the standard approach of optimizing the ELBO on the test set. The neural network effectivelylearns to approximate probabilistic inference effectively.
Table 5: Average topic coherence for different choices of prior and optimization strategies ofPRODLDA on 20 Newsgroup for k = 50.
Table 6: Five randomly selected topics from all the models.
Table 7: VAE-LDA fails to learn any meaningful topics when component collapsing occurs. Thetable shows five randomly sampled topics (, which are essentially slight variants of each other) fromwhen the VAE-LDA model is trained without BN and high momentum training.
