Table 1: Results on MNIST: we compare the performance of LW-SVM with SGD algorithmson three metrics: training objective, training accuracy and testing accuracy. LW-SVMoutperforms Adadelta and Adam on all three metrics, with marginal improvements sincethose find already very good solutions.
Table 2: Results on CIFAR-10: LW-SVM outperforms Adam and Adadelta on all threemetrics. It improves on Adagrad, but does not outperform it - however Adagrad takes a longtime to converge and does not obtain the best generalization.
Table 3: Results on CIFAR-100: LW-SVM improves on all other solvers and obtains the besttesting accuracy.
Table 4: Results on the 1,000-way classification challenge of ImageNet on the validationset, for the Pre-Trained model (PT) and the same model further optimized by LW-SVM(PT+LW-SVM).
Table 5: Hyper-parameters for the SGD solvers	MNIST		CIFAR-10 (SCE)		CIFAR-10 (SVM)		CIFAR-100 (SCE)		CIFAR-100 (SVM)	Adagrad	η =	0.01	η=	0.01	η =	0.001	η=	0.01	η=	0.001	λ =	0.001	λ=	0.001	λ =	0.001	λ=	0.001	λ=	0.001Adadelta	η	=1	η	=1	η	= 0.1	η	=1	η	= 0.1	λ =	0.001	λ=	0.001	λ =	0.001	λ=	0.001	λ=	0.001Adam	η =	0.001	η=	0.001	η =	0.0001	η=	0.001	η=	0.0001	λ =	0.001	λ=	0.001	λ=	0.001	λ=	0.001	λ=	0.001One may note that the hyper-parameters are the same for both CIFAR-10 and CIFAR-100for each combination of solver and loss. This makes sense since the initial learning ratemainly depends on the architecture of the network (and not so much on which particularimages are fed to this network), which is very similar for the experiments on the CIFAR-10and CIFAR-100 data sets.
