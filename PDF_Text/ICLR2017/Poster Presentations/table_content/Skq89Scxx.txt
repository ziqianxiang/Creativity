Table 1: Test errors of different methods on CIFAR-10 and CIFAR-100 with moderate data aug-mentation (flip/translation). In the second column k is a widening factor for WRNs. Note that thecomputational and memory resources used to train all WRN-28-10 are the same. In all other casesthey are different, but WRNs are usually faster than original ResNets to achieve the same accuracy(e.g., up to a factor of 8 according to Zagoruyko & Komodakis (2016)). Bold text is used only tohighlight better results and is not based on statistical tests (too few runs).
Table 2: Test errors of ensemble models on CIFAR-10 and CIFAR-100 datasets.
