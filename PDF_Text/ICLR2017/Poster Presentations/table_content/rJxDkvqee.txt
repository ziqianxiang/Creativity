Table 2: Final test set AP for different word discrimination aPProaches. The first line is a baselineusing no word embeddings, but rather aPPlying dynamic time warPing (DTW) to the inPut MFCCfeatures. The second and third lines are Prior results using no word embeddings (but rather usingDTW with learned corresPondence autoencoder-based or Phone Posterior features, trained on largerexternal (in-domain) data). The remaining Prior work corresPonds to using cosine similarity betweenacoustic word embeddings.
Table 3: Word similarity results using fixed-margin and cost-sensitive objectives, given as rankcorrelation (Spearmanâ€™s P) between embedding distances and orthographic edit distances.
Table 4: Average precision (AP) for acoustic and cross-view word discrimination tasks on the de-velopment set, using embeddings learned with objective obj0 and different LSTM architectures.
