Table 1: The Gumbel-Softmax estimator outperforms other estimators on Bernoulli and Categoricallatent variables. For the structured output prediction (SBN) task, numbers correspond to negativelog-likelihoods (nats) of input images (lower is better). For the VAE task, numbers correspond tonegative variational lower bounds (nats) on the log-likelihood (lower is better).
Table 2: Marginalizing over y and single-sample variational inference perform equally well whenapplied to image classification on the binarized MNIST dataset (Larochelle & Murray, 2011). Wereport variational lower bounds and image classification accuracy for unlabeled data in the test set.
