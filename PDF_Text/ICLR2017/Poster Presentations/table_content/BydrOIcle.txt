Table 1: Unrolled GANs cover more discrete modes when modeling a dataset with 1,000 data modes,corresponding to all combinations of three MNIST digits (103 digit combinations). The number ofmodes covered is given for different numbers of unrolling steps, and for two different architectures.
Table 2: Unrolled GANs better model a continuous distribution. GANs are trained to model ran-domly colored MNIST digits, where the color is drawn from a Gaussian distribution. The JS diver-gence between the data and model distributions over digit colors is then reported, along with standarderror in the JS divergence. More unrolling steps, and larger models, lead to better JS divergence.
Table 3: GANs trained with unrolling are better able to match images in the training set thanstandard GANs, likely due to mode dropping by the standard GAN. Results show the MSE betweentraining images and the best reconstruction for a model with the given number of unrolling steps.
