Figure 1: Example Where Word-overlap scores(e.g. BLEU) fail for dialogue evaluation; al-though the model response is completely rea-sonable, it has no Words in common With thereference response, and thus Would be givenloW scores by metrics such as BLEU.
Figure 2: The ADEM model, which uses a hierarchical encoder to produce the context embedding c.
Figure 3: Scatter plot showing model against human scores, for BLEU-2 and ROUGE on the fulldataset, and ADEM on the test set. We add Gaussian noise drawn from N (0, 0.3) to the integer humanscores to better visualize the density of points, at the expense of appearing less correlated.
Figure 4: Scatterplots depicting the system-level correlation results for BLEU-2, BLEU-4, ROUGE,and adem on the test set. Each point represents the average scores for the responses from a dialoguemodel (TFIDF, DE, HRED, human). Human scores are shown on the horizontal axis, with normalizedmetric scores on the vertical axis. The ideal metric has a perfectly linear relationship.
Figure 5: Scatter plots showing the distribution of scores (vertical axis) for different responses(horizontal axis), for each of the four questions in our survey. It can be seen that the overall andtopicality scores are clustered for each question, indicating high agreement, while this is not the casefor specificity or background information. Note that all scores are normalized based on a per-userbasis, based on the average score given by each user.
Figure 6: The VHRED model used for pre-training. The hierarchical structure of the RNN encoder isshown in the red box around the bottom half of the figure. After training using the VHRED procedure,the last hidden state of the context-level encoder is used as a vector representation of the input text.
Figure 7: Plots showing the Spearman and Pearson correlations on the test set as adem trains. Atthe beginning of training, the model does not correlate with human judgements.
