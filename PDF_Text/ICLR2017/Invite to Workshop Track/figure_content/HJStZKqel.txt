Figure 1: (Neural) TerpreT programs for counting symbols on a tape, with input-output examples.
Figure 2: Overview of tasks in the (a) Add2x2, (b) Apply2x2 and (c) Math scenarios. ‘A’ denotesthe APPLY operator which replaces the ? tiles with the selected operators and executes the sum. Weshow two Math examples of different length.
Figure 3: Example solutions for the tasks on the right columns of the (a) Add2x2 and (b) Apply2x2scenarios. The read head is initialized READing the top left cell and any auxiliary InputInts areloaded into memory. Instructions and arguments shown in black must be learned.
Figure 4: Overview of the Math model. (a) The general form of a block in the model. Blue elementsare learnable. (b) A loop-based solution to the task in the Math scenario.
Figure 5:	Cartoon illustration of all models used in the experiments. See text for details•	Each of the images in the 2 × 2 grid is passed through an embedding network with 2 layersof 256 neurons (c.f. net_0/1) to produce a 10-dimensional embedding. The weights ofthe embedding network are shared across all 4 images.
Figure 6:	Lifelong learning with NTPT. (a) top: the sequential learning schedule for all 8 tasks,bottom: performance of NTPT (solid) and the MTNN-2 baseline (dashed) on the first Add2x2 task.
Figure 7: Final accuracies on all 2 × 2 tasksfor all models at the end of lifelong learning7Under review as a conference paper at ICLR 2017the extent of catastrophic forgetting and make the shared components more robust, we have a separatelearning rate for the perceptual networks in both the MTNN baseline and NTPT which is 100 foldsmaller than the learning rate for the task-specific parts. With this balance of learning rates we findempirically that NTPT does not display catastrophic forgetting.
Figure 8: Generalization behavior on MATH expres-sions. Solid dots indicate expression lengths usedin training. We show results on (a) a simpler non-perceptual Math task (numbers in parentheses indicateparameter count in each model) and (b) the Math taskincluding perception.
