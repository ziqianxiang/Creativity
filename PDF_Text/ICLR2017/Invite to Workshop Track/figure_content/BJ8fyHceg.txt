Figure 1: A Note RNN is trained on MIDI files and supplies the initial weights for the Q-networkand Target-Q-network, and final weights for the Reward RNN.
Figure 2: Average reward obtained by sampling 100 melodies every 100,000 training epochs. Thethree models are compared to a model trained using only the music theory rewards rMT .
Figure 3: The number of times a melody from each modelwas selected as most musically pleasing. Error bars re-flect the std. dev. of a binomial distribution fit to thebinary win/loss data from each model.
Figure 4: Probability distribution over the next note generated by each model for a sample melody.
