Figure 1: Predictions of genre labels depending on the input modality. Red and blue labels indicatefalse positives and true positives respectively.
Figure 2: Illustration of gated units. a) The proposed model to use with more than two modalities.
Figure 3: Co-ocurrence matrix of genre tagsRecurrent neural network Here we take the plot outline as a sequence of words and train a super-vised recurrent neural network. We evaluated two variants. The first one (RNN^w2v) is atransfer learning model that takes as input the word vectors of word2vec as representations.
Figure 4: Size distribution of movie posters.
Figure 5: Length distribution of movie plots.
Figure 6: Generative model for the synthetic task. Grayed nodes represent visible variables, theother nodes represent hidden variables.
Figure 7: Activations of z (left) and prediction (right) for a synthetic experiment with xv, xt âˆˆ R1.
Figure 8: Percentage of gates activations (z > 0.5: Visual; z <= 0.5: textual) for test samples towhich the model assigned them the label.
