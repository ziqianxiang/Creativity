Figure 1: Examples of interpretable and controllable image synthesis. Left: MS-COCO, middle:CUB, right: MHP. Bottom row shows segmentation and keypoint conditioning information.
Figure 2: Auto-regressive modelling of a 1D sig-nal with a masked convolutional network.
Figure 3: PiXelCNN with text and structure conditioning variables.
Figure 4: Encoding text and spatial structure for image generation.
Figure 5: Text- and segmentation-conditional general image samples.
Figure 6: Text- and keypoint-conditional bird samples (CUB data).
Figure 7: Text- and keypoint-conditional samples of images with humans (MHP data).
Figure 8: Columns: varying text while fixing pose. Rows (length 6): varying pose while fixing text.
Figure 9: Comparison to Generative Adversarial What-Where Networks (Reed et al., 2016a). GANsamples have very low diversity, whereas our samples are all quite different.
