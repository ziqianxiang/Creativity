Figure 1: Network architecture of the proposed Equation Learner (EQL) for 3 layers (L = 3) and oneneuron per type (u = 4, v = 1).
Figure 2: Learning pendulum dynamics. (a) slices of outputs yi (left) and y? (right) for inputsx1 = x2 = x for the true system equation (Eq. 9) and one of EQL, MLP, SVR instances. The shadedarea marks the training region and the vertical bars show the size of the near and far extrapolationdomain. (b) one of the learned networks. Numbers on the edges correspond to the entries of W andnumbers inside the nodes show the bias values b. All weights with |w| < 0.01 and orphan nodesare omitted. Learned formulas: y1 = 0.103x2, y2 = sin(-x1), which are correct up to symmetry(1/g = 1.01).
Figure 3: Double pendulum kinematics. (a) training trajectory (in y-space). (b) extrapolation testtrajectory (in y-space) with output of a learned EQL instance. (c) slices of output y4 for inputsx1 = x2 = x for the true system, one of EQL, MLP, and SVR instances. (d) numeric results,see Tab. 1 for details. Note, that predicting 0 would yield a mean error of 0.84.
Figure 4: Formula learning analysis. (a) for F-1, (b) for F-2, and (c) for F-3. (left) y for a single cutthrough the input space for the true system equation (10-12), and for an instance of EQL, and MLP.
Figure 5: X-Ray transition energies. (a) Measured data and predicted values by EQL and (b)visualized prediction error for all methods for one train/validation splitting. (c) EQL solutions duringmodel selection in validation error - sparsity space, See Appendix Al for details. (d) numeric results.
Figure 6: Cart-pendulum system. (a) sketch of the system. The lengths and masses are set to 1, thegravitation constant is 9.81 and the friction constant is 0.01. (b,c) slices of outputs y3 and y4 forinputs x1 = x2 = x3 = x4 = x for the true system equation (Eq. 13), and best EQL, MLP instances.
Figure 7:	Model selection criteria. (a) extrapolation performance depending on validation error andsparsity (s) for the kin-4-end dataset as an illustration. (b) the same as in (a) but in rank-space. Circlearcs indicate the L2 norm iso-lines.
Figure 8:	Interpolation performance (a) and extrapolation performance (b) (on the noise-free test set)depending on the number of data points and the size of the additive noise for kin-4-end dataset as anillustration. The white line represent an arbitrary threshold below which we consider a successfulsolution of the interpolation and extrapolation task.
