Figure 1: Neural-network sketching: sparse vector X mapsto sketch using t = 3 hashes & m = 8; shaded squaresdesignate 1's; sketching step is random; sketch then used asinput to single-layer net: w>x; nodes labelled “24” & “29”correspond to decoding of x24 & x29 and shown with non-zero incoming edges.
Figure 2: Left: effect of varying t, m for sketched 1-hidden layer network. Center: sparse linear regression onsketched data with improper learning. Right: sparse polynomial regression on sketched data.
Figure 3: Performance vs. number of nonzero parameters in 1st layer for Reuters (left), AG NeWs(center), and type tagging (right). Each color corresponds to a different sketch size and markers in-dicate the number of subsketches t. We evaluate each setting for three values of the l1 regularizationparameter λ1.
