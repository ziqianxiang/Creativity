Table 1: Text8. Perplexity and training time after 5 epochs.
Table 2: One Billion Word benchmark. Perplexity on the test set for single models. Our result isobtained after 5 epochs.
Table 3: Europarl. Perplexity after 5 epochs for different languages as a function of time t (minutes).
