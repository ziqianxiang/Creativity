Table 1: A list of important notations used in the paper.
Table 2: Summary of the previous studies defining adversarial examples.
Table 3: Summary of theoretical conclusions that we can derive. Here X1 = Rn1 and X2 = Rn2 .
Table 4: Connecting to relevant DNN hardening solutions. The experimental results of comparingdifferent hardening solutions are shown in Figure 9, Figure 10, Table 10 and Table 11.
Table 5: Accuracy of the deep residual network(He et al., 2015) obtained from two noise-perturbedtesting cases. The second column shows the result on randomly perturbed samples, and the thirdcolumn shows the result on adversarially perturbed samples.
Table 6: Accuracy of the overfeat network(Sermanet et al., 2013) obtained from two noise-perturbedtesting cases. The second column shows the result on randomly perturbed samples, and the thirdcolumn shows the result on adversarially perturbed samples.
Table 7: Accuracy of the residual network(He et al., 2015) obtained from two noise-perturbed testingcases in CIFAR-10 dataset (Krizhevsky & Hinton, 2009). The second column shows the resulton randomly perturbed samples, and the third column shows the result on adversarially perturbedsamples.
Table 8: Accuracy of the wide residual network(Zagoruyko & Komodakis, 2016) obtained fromtwo noise-perturbed testing cases in CIFAR-10 dataset (Krizhevsky & Hinton, 2009). The secondcolumn shows the result on randomly perturbed samples, and the third column shows the result onadversarially perturbed samples.
Table 9: Accuracy of the VGG model (Simonyan & Zisserman, 2014) obtained from two noise-perturbed testing cases in CIFAR-10 dataset (Krizhevsky & Hinton, 2009). The second column showsthe result on randomly perturbed samples, and the third column shows the result on adversariallyperturbed samples.
Table 10: Test accuracy for different training strategies on CIFAR-10 dataset.
Table 11: Test accuracy for different training strategies on MNIST dataset.
