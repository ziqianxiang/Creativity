Table 1:	Test set error on Arabic Digits dataset averaged over 10 runsModel	Test	Error (%)Baseline (ours)	1.36 ±	0.15Baseline + random noise (ours)	1.10 ±	0.15Baseline + random interpolation	(ours)	1.82 ±	0.21Baseline + nearest neighbour interpolation (ours) 1.57 ±	0.19Baseline + nearest neighbour extrapolation (ours) 0.74 ± 0.11(Hammami et al., 2012)	0.69We find that our simple baseline model achieves competitive performance after training on theextracted context vectors, demonstrating the feature extracting capability of the sequence autoen-coder. The naive data augmentation approach of adding random noise to the context vectors furtherimproves performance. Of interest, we find that adding new samples generated using interpolationtechniques diminishes the performance of the model, which confirms our hypothesis that good dataaugmentation techniques should add variability to the dataset. Of the two interpolation techniques,6Under review as a conference paper at ICLR 2017we see that interpolating between neighbouring samples performs better than simply interpolatingwith randomly chosen samples of the same class. Finally we observe that extrapolating betweensamples improves model performance significantly, reducing the baseline error rate by almost half.
Table 2:	CV error on AUSLAN dataset averaged over 5 foldsModel	Test Error (%)Baseline (ours)	1.53 ± 0.26Baseline + random noise (ours) 1.67 ± 0.12Baseline + interpolation (ours) 1.87 ± 0.44Baseline + extrapolation (ours) 1.21 ± 0.26(Rodriguez et al., 2005)	1.284.5 UCFKINECTThe final time series dataset we considered was the UCF Kinect action recognition dataset (Elliset al., 2013). It contains motion capture data of participants performing 16 different actions suchas run, kick, punch, and hop. The motion capture data consists of 3-dimensional coordinates for15 skeleton joints for a total of 45 attributes per frame. In total there are 1,280 samples within thedataset. To preprocess the dataset we first shift the coordinates of each sample so that the centralshoulder joint of the first frame is located at the origin. Global normalization is also applied.
Table 3:	CV error on UCFKinect dataset averaged over 4 foldsModel	Test Error (%)Baseline (ours)	4.92 ± 2.09Baseline + extrapolation (ours)	3.59 ± 1.61(Beh et al., 2014)	1.104.6 Image Classification: MNIST and CIFAR- 1 0Having successfully applied dataset augmentation in feature space to improve the accuracy of se-quence classification tasks, we now experiment with applying our technique to static data. Forthese experiments we concentrate on the image domain where manual data augmentation is alreadyprevalent. We find that augmenting datasets by extrapolating within a learned feature space improvesclassification accuracy compared to no data augmentation, and in some cases surpasses traditional(manual) augmentation in input space.
Table 4:	Test error (%) on MNIST and CIFAR-10. Averages over 10 and 5 runs, respectively.
