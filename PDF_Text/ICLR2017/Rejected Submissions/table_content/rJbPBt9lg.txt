Table 1: Statistics of the datasettruth yi . We choose l to be the standard cross-entropy loss. We introduce a weight αi for eachsample (qi , yi) in the training dataset to change the objective to be as follows:argminθ	αil(fθ (qi), yi)iWhen training a model not allowed to deny prediction, we set αi = 0 for yi = UNK, and αi = 1otherwise. In doing so, it is equivalent to remove all queries whose ground truth next token is UNK.
Table 2: Next non-terminal prediction resultsbucket, we stop adding whole programs, and start adding only the first segment of each program:when a bucket is empty, a program is chosen randomly, and its first segment is added to the bucket.
Table 3: Next terminal prediction results	Non-terminal			Terminal		N2N	NT2N I NT2NT		NTN2T I NT2NT	Top 1 accuracy					Short programs (<30,000 non-terminals)	82.3%	87.7%	86.2%	83.4%	78.6%Long programs (>30,000 non-terminals)	87.7%	94.4%	92.7%	89.0%	85.8%Overall	84.2%	90.1%	88.5%	85.4%	81.2%Top 5 accuracy					Short programs (<30,000 non-terminals)	97.9%	98.9%	98.7%	87.9%	86.4%Long programs (>30,000 non-terminals)	98.8%	99.6%	99.4%	91.5%	90.5%Overall	98.2%	99.1%	98.9%	89.2%	87.8%Table 4: Next token prediction on programs with different lengths.
Table 4: Next token prediction on programs with different lengths.
Table 5: Predicting non-terminal and terminal togetherWe train one NTN2T model for each threshold, and evaluate it using the sampled test set. Theaccuracies of different models are plotted in Figure 9. The trend of different models’ accuraciesis similar to the trend of the percentage of non-UNK tokens in the test set. This is expected, sincewhen the threshold increases the model has more chance to make correct predictions for originalUNK queries. However, we observe that this is not always the case. For example, the accuracies ofmodels trained with thresholds being 30000 and 40000 are almost the same, i.e., the difference isonly 0.02%. We make similar observations among the models trained with thresholds being 60000,70000, and 80000. Notice that we have observed above that when we train 5 models with differentrandom initialization, the variance of the accuracies of these models is within 0.1%. Therefore, weconclude that when we increase the UNK threshold from 30000 to 40000 and from 60000 to 80000,the accuracies do not change significantly. One potential explanation is that when increasing theUNK threshold, while it has more chance to predict those otherwise UNK terminals, a model mayalso more likely make mistakes when it needs to choose the next terminal from more candidates.
Table 6: Deny prediction results. Top 1 accuracy is computed as the percentage of all queries(including the ones whose ground truth is UNK) that can be predicted correctly, i.e., the predictionmatches the ground truth even when the ground truth is UNK. Accuracy on non-UNK terminalsmeasures the accuracy of each model on all non-UNK terminals. Deny rate is calculated as thepercentage of all queries that a model denies prediction. Prediction accuracy is the top 1 accuracyover those queries that a model does not deny prediction, i.e., the prediction is not UNK.
