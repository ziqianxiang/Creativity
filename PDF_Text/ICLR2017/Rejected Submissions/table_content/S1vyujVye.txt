Table 1: State of the art results on STL-10 datasetModel	STL-10 test accuracyZero-bias Convnets - Paine et al. (2014)	70.2%Triplet network - Hoffer & Ailon (2015)	70.7%Exemplar Convnets - Dosovitskiy et al. (2014)	72.8%Target Coding - Yang et al. (2015)	73.15%Stacked what-where AE - Zhao et al. (2015)	74.33%Spatial contrasting initialization (this work)	81.34% ± 0.1The same model without initialization	72.6% ± 0.1image sizes 32 × 32 pixels, with color. The classes are airplanes, automobiles, birds, cats,deer, dogs, frogs, horses, ships and trucks.
Table 2: State of the art results on Cifar10 dataset with only 4000 labeled samplesModel	Cifar10 (400 per class) test accuracyConvolutional K-means Network - Coates & Ng (2012) View-Invariant K-means - Hui (2013) DCGAN - Radford et al. (2015) Exemplar Convnets - Dosovitskiy et al. (2014) Ladder networks - Rasmus et al. (2015) Conv-CatGan Springenberg (2016) ImprovedGan Salimans et al. (2016) Spatial contrasting initialization (this work)	70.7% 72.6% 73.8% 76.6% 79.6% 80.42% (± 0.58) 81.37% (± 2.32) 79.2%(±0.3)The same model without initialization	72.4%(±0.1)Table 3: results on MNIST datasetModel	MNIST test errorStacked what-where AE - Zhao et al. (2015)	0.71%Triplet network - Hoffer & Ailon (2015)	0.56%Jarrett et al. (2009)	0.53%Ladder networks - Rasmus et al. (2015)	0.36%DropConnect - Wan et al. (2013)	0.21%Spatial contrasting initialization (this work)	0.34% ± 0.02The same model without initialization	0.63% ± 0.02examples. We found again that this provided benefit over training the same network without pre-initialization, improving results from 0.63% to 0.34% error on test set. As mentioned previously, theeffective compared patches of MNIST covered almost the entire image area. This can be attributedto the fact that MNIST requires global features to differentiate between digits. The results, comparedwith previous attempts are included in Table (3).
Table 3: results on MNIST datasetModel	MNIST test errorStacked what-where AE - Zhao et al. (2015)	0.71%Triplet network - Hoffer & Ailon (2015)	0.56%Jarrett et al. (2009)	0.53%Ladder networks - Rasmus et al. (2015)	0.36%DropConnect - Wan et al. (2013)	0.21%Spatial contrasting initialization (this work)	0.34% ± 0.02The same model without initialization	0.63% ± 0.02examples. We found again that this provided benefit over training the same network without pre-initialization, improving results from 0.63% to 0.34% error on test set. As mentioned previously, theeffective compared patches of MNIST covered almost the entire image area. This can be attributedto the fact that MNIST requires global features to differentiate between digits. The results, comparedwith previous attempts are included in Table (3).
Table 4: Convolutional models used, based on Lin et al. (2013), Rasmus et al. (2015)ModelSTL10	CIFAR-10	MNISTInput: 96 × 96 RGB	Input: 32 × 32 RGB	Input: 28 X 28 monochrome5 × 5 conv. 64 BN ReLU	3 × 3 conv. 96 BN LeakyReLU	5 X 5 conv. 32 ReLU1 × 1 conv. 160 BN ReLU	3 X 3 conv. 96 BN LeakyReLU	1 × 1 conv. 96 BN ReLU	3 X 3 conv. 96 BN LeakyReLU	3 × 3 max-pooling, stride 2	2 X 2 max-pooling, stride 2 BN	2 X 2 max-pooling, stride 2 BN5 × 5 conv. 192 BN ReLU	3 X 3 conv. 192 BN LeakyReLU	3 X 3 conv. 64 BN ReLU1 × 1 conv. 192 BN ReLU	3 X 3 conv. 192 BN LeakyReLU	3 X 3 conv. 64 BN ReLU1 × 1 conv. 192 BN ReLU	3 X 3 conv. 192 BN LeakyReLU	3 × 3 max-pooling, stride 2	2 X 2 max-pooling, stride 2 BN	2 X 2 max-pooling, stride 2 BN3 × 3 conv. 192 BN ReLU		1 × 1 conv. 192 BN ReLU		1 × 1 conv. 192 BN ReLU		Spatial contrasting criterion3 X 3 conv. 256 ReLU 3 X 3 max-pooling, stride 2 dropout, p = 0.5 3 X 3 conv. 128 ReLU dropout, p = 0.5 fully-connected 10	3 X 3 conv. 192 BN LeakyReLU 1 X 1 conv. 192 BN LeakyReLU 1 X 1 conv. 10 BN LeakyReLU global average pooling	3 X 3 conv. 128 BN ReLU 1 X 1 conv. 10 BN ReLU global average pooling10-way SoftmaxFigure 2: First layer convolutional filters after spatial-contrasting training11
