Table 1: Statistics of the WikiFacts-FilmActor-v0.1 Dataset.
Table 2: We compare four different versions of the NKLM to the RNNLM on three differentperplexity metrics. We used 10K vocabulary. In no-copy, we disabled the knowledge-copy func-tionality, and in no-fact-no-copy, using topic knowledge is also additionally disabled by setting allfacts as NaF. Thus, no-fact-no-copy is very similar to RNNLM. In no-TransE, we used randomvectors instead of the TransE embeddings to initialize the KG entities. As shown, the NKLM showsbest performance in all cases. The no-fact-no-copy performs similar to the RNNLM as expected(slightly worse partly because it has smaller model parameters than that of the RNNLM). As expected,no-copy performs better than no-fact-no-copy by using additional information from the fact embed-ding, but without the copy mechanism. In the comparison of the NKLM and no-copy, we can see thesignificant gain of using the copy mechanism to predict named entities. In the last column, we canalso see that, with the copy mechanism, the number of predicting unknown decreases significantly.
Table 3: The NKLM and the RNNLM are compared for vocabularies of four different sizes[5K, 10K, 20K, 40K]. As shown, in all cases the NKLM significantly outperforms the RNNLM.
Table 4: Sampled Descriptions. Given the warm-up phrases, we generate samples from the NKLMand the RNNLM. We denote the copied knowledge words by [word] and the UNK words by <unk>.
