Table 1: Staleness of gradients in a 18-layer Inception model. Gra-dients were collected in a run of asynchronous training using 40machines. Staleness of a gradient is measured as the number ofupdates that have occurred between its corresponding read and up-date operations. The staleness of gradients increases from a meanof ~14.5 in the top layer (Layer 18) to ~39.0 in the bottom layer(Layer 0).
Table 2: Test accuracies at con-vergence and number of epochs toconverge for different initial learningrates Î³0 . Low initial learning ratesresult in faster convergence to poorerlocal optimum.
