Table 1: Test set results for the five tasks. In the relatedness task, the lower scores are better.
Table 2: POS tagging results.
Table 3: Chunking results.
Table 4: Dependency resultsMethod	MSEJMTall0.233JMTDEZhoU et al.^(2016)Tai et al. (2015)0.2380.2430.253Method	Acc.
Table 6: TextUal entailment resUlts.
Table 5: Semantic relatedness resUlts.
Table 7: Effects of depth for thesingle task settings.
Table 9: Effectiveness of theShortcut Connections (SC).
Table 10: Effectiveness of the Label Embed-dings (LE).
Table 11: Effectiveness of thecharacter n-gram embeddings.
Table 12: Effectiveness of using differentlayers for different tasks.
Table 13: Effectiveness of theVertical Connections (VC).
Table 14: POS tagging scores on the development set with and without the character n-gram em-beddings, focusing on accuracy for unknown words. The overall accuracy scores are taken fromTable 11. There are 3,862 unknown words in the sentences of the development set.
Table 15: Dependency parsing scores on the development set with and without the character n-gramembeddings, focusing on UAS and LAS for unknown words. The overall scores are taken fromTable 11. There are 976 unknown words in the sentences of the development set.
Table 16: Closest neighbors of the word “standing” in the embedding space and the projected spacein each forward LSTM.
