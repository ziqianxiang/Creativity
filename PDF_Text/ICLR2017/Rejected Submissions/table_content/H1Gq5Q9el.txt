Table 1: English→German performance on WMT test sets. Our pretrained model outperforms allother models. Note that the model without pretraining uses the LM objective.
Table 2: Results on the anonymized CNN/Daily Mail dataset.
Table 3:	The count of how often the no pretrain system (NP) achieves a higher, equal, and lowerscore than the pretrained system (P) in the side-by-side study where the human evaluator gave eachsystem a score from 1-5. The sign statistical test gives a p-value of < 0.0001 for rejecting the nullhypothesis that there is no difference in the score obtained by either system.
Table 4:	The count of how often the pretrain and no pretrain systems contain repeated phrases orsentences in their outputs in the side-by-side study. McNemar’s test gives a p-value of < 0.0001for rejecting the null hypothesis that the two systems repeat the same proportion of times. Thepretrained system clearly repeats less than the system without pretraining.
Table 5:	The pretrained model outputs a highly informative summary, while the no pretrain modeloutputs irrelevant details.
Table 6:	The pretrained model outputs a highly relevant summary but makes a mistake on the felineexecutioner’s name. The no pretrain model degenerates into irrelevant details and repeats itself.
Table 7:	Both models output a relevant summary, but the no pretrain model uses the same name torefer to both players.
Table 8:	A failure case. The pretrained model outputs irrelevant details while the no pretrain modelsuccessfully summarizes the document.
Table 9:	The no pretrain model makes a complete mistranslation when outputting ”und die Infor-mation der Demonstranten ausgesetzt habe”. That translates to ”the reopening of the public spaceand the information [noun] of the protesters were suspended”, instead of informing the protesters.
Table 10:	The human evaluator noted that the pretrained version is better, as it correctly captures themeaning and sentence structure of the middle. The no pretrain model does not misses translatingthe word ”million”, repeats itself in ”wachsen zu wachsen”, and puts the verb ”beeinflusst wurde”is an unnatural position. However, the pretrained model makes a mistake in the percentage (316%instead of 31.16%).
Table 11:	An example where the English source is poorly worded. Both models output poor trans-lations, but the evaluator noted that the pretrained version is still better than the no pretrain version.
Table 12:	Another example where the English source is poorly worded. Both models get the struc-ture right, but have a variety of problematic translations. Both models miss the meaning of ”totalvote count”. They both also translate ”electoral boxes” poorly - the no pretrain model calls it ”elec-toral paperwork” while the pretrained model calls it ”ballots”. These failures may be because of thepoorly worded English source. The human evaluator found them both equally poor.
