Table 1: Conditional negative log-likelihoods for the test part of Omniglot.
Table 2: Conditional negative log-likelihoods for the test part of MNIST. Models were trained onthe train part of Omniglot.
Table 3: Small-shot classification accuracy (%) on the test part of Omniglot5-way	20-wayModel	Method 1-shot 5-shot 1-shot 5-shotGMN, Ctrain =	1, conditional	likelihood	82.7	97.4	64.3	90.8GMN, Ctrain =	1, avg, conditional	likelihood	90.8	96.7	77.0	91.0GMN, Ctrain =	1, conditional	mean cosine	62.7	80.8	45.1	67.2GMN, Ctrain =	1, avg, conditional	mean cosine	72.0	86.0	50.1	72.61-NN, raw pixels		cosine	34.8	50.5	15.6	28.2Appendix C.	Clas sificationGenerative matching networks are useful not only as adaptive density estimators. For example, onemay use a pre-trained model for classification in several ways. Given a small number of labeledexamples Xc = {xc,1, xc,2, . . . xc,N} for each class c âˆˆ {1, 2, . . . , C}, it possible to use the proba-bility p(x|Xc) as a relative score to assign class c for a new object x.
