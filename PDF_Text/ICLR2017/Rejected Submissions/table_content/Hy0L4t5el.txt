Table 1: Statistics of the synthetic arithmetic datasets, and log likelihoods of models trained onthem. To estimate a tighter bound for log p(x), we use IWAE (Burda et al., 2015) with 50 samplesof z. “Tree, no VAE” means there was no encoder; instead, we learned a fixed z for all trees.
Table 2: Statistics for first-order logic proof clauses, and log likelihoods of models trained on them.
