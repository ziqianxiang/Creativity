Table 1: Word Error Rates (%) with baseline systems and Viterbi decoding of character sequences.
Table 2: Precision, Recall and F-measure of OB detection by RNNs with different orders d.
Table 3: Decoding results (% of word errors).
Table 4: Number of words/bigrams in different sets of Rimes and IAM databases. (in parentheses,the number of distinct tokens).
Table 5: Number of parameters in the RNNsd	Num. Parameters0	1,805,8271	2,066,4771,	2,087,3292	2,066,4772,	2,087,3293	2,066,4773’	2,087,329-i,23^	6,199,4311’2,3,	6,261,987B	ResultsB.1	Correlation between character edit distances and OB cosine similaritiesOn Figure 7, we randomly selected pairs of words, and pairs of words with high cosine similarityin the French and English dictionary, and plotted their cosine similarity in the bigram space against12Under review as a conference paper at ICLR 2017the edit distance between the two words, normalized by the length of the longest word. We note thatwords with high cosine similarity also have short edit distance, supporting the idea that the bigramrepresentation encode some global letter order, and therefore might favor word recognition.
Table 6: RNN results	d	edit.dist(%)	SER(%)	Precision(%)	Recal1(%)	F-measure	0	8.3	:	22.7	95.00 二	93.42	0.942021Rimes	1	11.4	20.8	89.86	87.61	0.8872	1,	9.6	21.7	91.17	89.25	0.901998	2	13.4	23.2	79.78	84.84	0.822315	2,	11.1	26.2	82.84	85.84	0.843128	3	14.8	23.7	74.80	83.37	0.788523	3’	12.5	27.4	82.57	80.93	0.817402	-i,23^	-	-	84:53	-86.68-	0.855922	1’,2',3,	-	-	84.03	88.48	0.86197	0	8.0	:	21.7	93.51 二	92.54	0.930205IAM	1	13.1	23.2	87.34	86.20	0.867681	1,	10.4	23.3	89.28	88.48	0.888813	2	16.7	26.2	77.71	82.33	0.799537	2,	12.7	28.3	81.57	83.95	0.827408	3	20.8	31.2	62.29	77.54	0.69081	3,	14.6	31.8	76.17	78.56	0.773436	W^	-	-	80:53	-84.26-	0823527	1',2'3	-	-	81.04	86.40	0836315
Table 7: Decoding result (word error rate) with different bigram ordersd	Rimes	IAM1	14.5	16.40,1	13.0	14.11,	12.9	13.10,1’	11.9	12.31,2	26.4	13.71',2,	12.7	11.80Λ2~	11.7	12.30,1',2,	10.1	11.3W^	25.6	13.51',2',3'	12.4	11.8-0Λ23~	11.0	12.00,1'2,3'	9.8	11.1In Table 8, we evaluate the cosine decoder by applying it to the ground-truth OB decompositionwith varying order of the validation sets, i.e. the performance assuming the RNN optical models areperfect.
Table 8: Decoding result (word error rate) with different bigram ordersd	Rimes	IAM1	0.64	1.860,1	0.90	1.621,	0.03	0.020,1,	0.03	0.021,2	0.21	0.051',2,	0.03	0.00^ɪʃ	0.13	0.050,1',2,	0.29	0.00TZ3^	0.21	0.081’,2',3,	0.03	0.00-0W^	0.03	0.030,1,,2',3,	0.03	0.00B.4	Error AnalysisB.4.1	Comparison of Errors of the Sequential and Open-Bigram Models14Under review as a conference paper at ICLR 2017Figure 8: Distribution of word errors vs. word length for the proposed (left) and sequential (right)approaches. We observe the same behaviour: short words tend to be more difficult to recognize.
