Table 1: Performance of various models on the entire Daily Mail test set using the limited length recallvariants of Rouge with respect to the abstractive ground truth at 75 bytes and 275 bytes. Entries with asteriskare statistically significant using 95% confidence interval with respect to the nearest state-of-the-art model, asestimated by the Rouge script.
Table 2: Performance of various models on the DUC 2002 set using the limited length recall variants ofRouge at 75 words. Our Deep Classifier is statistically within the margin of error at 95% C.I. with respectto the model of Cheng & Lapata (2016), but both are lower than state-of-the-art results due to out-of-domaintraining.
Table 3: Simulated experiment to demonstrate the impact of document discourse structure on model perfor-mance. Evaluation is done using Rouge limited length recall at 275 bytes. The Selector architecture exhibitssuperior performance when the discourse structure of the document is destroyed.
Table 4: Learned weights of various abstract features from the deep sentence selector model. Salience andredundancy are the most important features as learned by the model, followed by position and content. Thenegative sign for position weights has no particular significance. The positional feature gets very low weightwhen the document structure is destroyed by randomly shuffling sentences in each document the training data.
Table 5: Ablation experiments on the validation set to gauge the relative importance of each abstract feature.
Table 6: Example documents and gold summaries from Daily Mail (top) and DUC 2002 (bottom) corpora.
