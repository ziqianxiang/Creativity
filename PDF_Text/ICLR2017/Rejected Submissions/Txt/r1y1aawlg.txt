Under review as a conference paper at ICLR 2017
Iterative Refinement
for Machine Translation
Roman Novak*
-I	1	.	1	∙
Ecole polytechnique
Palaiseau, France
Michael Auli
Facebook AI Research
Menlo Park, CA
David Grangier
Facebook AI Research
Menlo Park, CA
Ab stract
Existing machine translation decoding algorithms generate translations in a
strictly monotonic fashion and never revisit previous decisions. As a result, ear-
lier mistakes cannot be corrected at a later stage. In this paper, we present a
translation scheme that starts from an initial guess and then makes iterative im-
provements that may revisit previous decisions. We parameterize our model as
a convolutional neural network that predicts discrete substitutions to an existing
translation based on an attention mechanism over both the source sentence as well
as the current translation output. By making less than one modification per sen-
tence, we improve the output of a phrase-based translation system by up to 0.4
BLEU on WMT15 German-English translation.
1	Introduction
Existing decoding schemes for translation generate outputs either left-to-right, such as for phrase-
based or neural translation models, or bottom-up as in syntactic models (Koehn et al., 2003; Galley
et al., 2004; Bahdanau et al., 2015). All decoding algorithms for those models make decisions which
cannot be revisited at a later stage, such as when the model discovers that it made an error earlier on.
On the other hand, humans generate all but the simplest translations by conceiving a rough draft of
the solution and then iteratively improving it until it is deemed complete. The translator may modify
a clause she tackled earlier at any point and make arbitrary modifications to improve the translation.
It can be argued that beam search allows to recover from mistakes, simply by providing alternative
translations. However, reasonable beam sizes encode only a small number of binary decisions. A
beam of size 50 contains fewer than six binary decisions, all of which frequently share the same
prefix (Huang, 2008).* 1
In this paper, we present models that tackle translation similar to humans. The model iteratively
edits the target sentence until it cannot improve it further. As a preliminary study, we address the
problem of finding mistakes in an existing translation via a simple classifier that predicts if a word
in a translation is correct (§2). Next, we model word substitutions for an existing translation via a
convolutional neural network that attends to the source when suggesting substitutions (§3). Finally,
we devise a model that attends both to the source as well as to the existing translation (§4). We
repeatedly apply the models to their own output by determining the best substitution for each word
in the previous translation and then choosing either one or zero substitutions for each sentence. For
the latter we consider various heuristics as well as a classifier-based selection method (§5).
Our results demonstrate that we can improve the output of a phrase-based translation system on
WMT15 German-English data by up to 0.4 BLEU (Papineni et al., 2002) by making on average
only 0.6 substitutions per sentence (§6).
Our approach differs from automatic post-editing since it does not require post-edited text which is
a scarce resource (Simard et al., 2007; Bojar et al., 2016). For our first model (§3) we merely require
parallel text and for our second model (§4) the output of a baseline translation system.
* Roman was interning at Facebook for this work.
125 = 32 < 50 < 26 = 64
1
Under review as a conference paper at ICLR 2017
2	Detecting Errors
Before correcting errors we consider the task of detecting mistakes in the output of an existing
translation system.
In the following, we use lowercase boldface for vectors (e.g. x), uppercase boldface for matrices
(e.g. F) and calligraphy for sets (e.g. X). We use superscripts for indexing or slicing, e.g., xi, Fi,j,
Fi = (Fi,1,..., Fi,|Fi|). We further denote x as the source sentence, yg as the guess translation
from which we start and which was produced by a phrase-based translation system (§6.1), and yref as
the reference translation. Sentences are vectors of indices indicating entries in a source vocabulary
X or a target vocabulary Y. For example, x = (x1, . . . , x|x|) ∈ X|x| with X = {1, . . . , |X |}. We
omit biases of linear layers to simplify the notation.
Error detection focuses on word-level accuracy, i.e., we predict for each token in a given translation
if it is present in the reference or not. This metric ignores word order, however, we hope that perfor-
mance on this simple task provides us with a sense of how difficult it will be to modify translations
to a positive effect. A token yig in the candidate translation yg is deemed correct iff it is present in
the reference translation: yig ∈ yref. We build a neural network f to predict correctness of each token
in yg given the source sentence x:
f (x, yg) ∈ [0;1]|yg| ,
where f(x, yg)i estimates P ygi ∈ yref .
Architecture. We use an architecture similar to the word alignment model of Legrand et al. (2016).
The source and the target sequences are embedded via a lookup table that replace each word type
with a learned vector. The resulting vector sequences are then processed by alternating convolutions
and non-linearities. This results in a vector S (x)i representing each position i in the source x and
a vector T (yg)j representing each position j in the target yg. These vectors are then compared via
a dot product. Our prediction estimates the probability of a target word being correct as the largest
dot product between any source word and the guess word. We apply the logistic function σ to this
score,
f(x,yg)i = σ max	S(x)T(yg)Tj,i .
16j6|x|
Training. At training time we minimize the cross-entropy loss, with the binary supervision 1 for
ygi ∈ yref, 0 otherwise.
Testing. At test time we threshold the model prediction f(x, yg)i to detect mistakes. We compare
the performance of our network to the following baselines:
1.	Predicting that all candidate words are always correct fcor ≡ 1, or always incorrect fwrong ≡
0.
2.	The prior probability of a word being correct based on the training data fstat(y) =
(P [y ∈ yref | y ∈ yg] > 0.5).
We report word-level accuracy metrics in Table 1. While the model significantly improves over the
baselines, the probability of correctly labeling a word as a mistake remains low (62.71%). The task
of predicting mistakes is not easy as previously shown in confidence estimation (Blatz et al., 2004;
Ueffing & Ney, 2007). Also, one should bear in mind that this task cannot be solved with 100%
accuracy since a sentence can be correctly in multiple different ways and we only have a single
reference translation. In our case, our final refinement objective might be easier than error detection
as we do not need to detect all errors. We need to identify some of the locations where a substitution
could improve BLEU. At the same time, our strategy should also suggest these substitutions. This
is the objective of the model introduced in the next section. 3
3 Attention-based Model
We introduce a model to predict modifications to a translation which can be trained on bilingual
text. In §5 we discuss strategies to iteratively apply this model to its own output in order to improve
a translation.
2
Under review as a conference paper at ICLR 2017
Metric (%)	fcor	fwrong	fstat	f
Accuracy	68.0	32.0		^60-
Recall	0.00	100.00	ɪŋ-	^6T3^
Precision	100.0	-320^		^6Σ7^
F1	0.00	48.4		~620~
Table 1: Accuracy of the error detection model f compared to baselines on the concatenation of the
WMT test sets from 2008 to 2015. For precision, recall and F1 we consider a positive prediction
as labeling a word as a mistake. Baseline fcor labels all words as correct, fwrong labels all words as
incorrect, fstat labels a word from yg based on the prior probability estimated on the training data.
Our model F takes as input a source sentence x and a target sentence y, and outputs a distribution
over the vocabulary for each target position, F(x,y) ∈ [0,1]lyl×lYl . For each position i and any
word j ∈ Y, F(x, y)i,j estimates P(yi = j | x, y-i), the probability of word j being at position
i given the source and the target context y-i = y1, . . . , yi-1, yi+1, . . . , y|y| surrounding i. In
other words, we learn a non-causal language model (Bengio et al., 2003) which is also conditioned
on the source x.
Architecture. We rely on a convolutional model with attention. The source sentence is embedded
into distributional space via a lookup table, followed by convolutions and non-linearities. The target
sentence is also embedded in distributional space via a lookup table, followed by a single convolution
anda succession of linear layers and non-linearities. The target convolution weights are zeroed at the
center so that the model does not have access to the center word. This means that the model observes
a fixed size context of length 2k for any target position i, y-i|k = yi-k, . . . , yi-1, yi+1, . . . , yi+k
where 2k + 1 refers to the convolution kernel width. These operations result in a vector Sj repre-
senting each position j in the source sentence x and a vector Ti representing each target context
y-i|k.
Given a target position i, an attention module then takes as input these representation and outputs a
weight for each target position
α(i, j)
exp (Sj ∙ Ti)
Pjx= 1 exp(Sj0∙Ti)
These weights correspond to dot-product attention scores (Luong et al., 2015; Rush et al., 2015).
The attention weights allow to compute a source summary specific to each target context through a
weighted sum,
|x|
a y-i|k, x = X α(i, j) Sj
j=1
Finally, this summary a(y-i|k, x) is concatenated with the embedding of the target context y-i|k
obtained from the target lookup table,
L (y-ilk) = {Lj,j ∈ yTk}
and a multilayer perceptron followed by a softmax computes F(x, y)i from a(y-i|k, x), L(y-i|k).
Note that we could alternatively use Ti instead of L(y-i|k) but our preliminary validation experi-
ments showed better result with the lookup table output.
Training. The model is trained to maximize the (log) likelihood of the pairs (x, yref) from the
training set.
Testing. At test time the model is given (x, yg), i.e., the source and the guess sentence. Similar to
maximum likelihood training for left-to-right translation systems (Bahdanau et al., 2015), the model
is therefore not exposed to the same type of context in training (reference contexts from yref) and
testing (guess contexts from yg).
Discussion. Our model is similar to the attention-based translation approach of Bahdanau et al.
(2015). In addition to using convolutions, the main difference is that we have access to both left and
3
Under review as a conference paper at ICLR 2017
right target context y-i|k since we start from an initial guess translation. Right target words are of
course good predictors of the previous word. For instance, an early validation experiment with the
setup from §6.1 showed a perplexity of 5.4 for this model which compares to 13.9 with the same
model trained with the left context only.
4	Dual Attention Model
We introduce a dual attention architecture to also make use of the guess at training time. This
contrasts with the model introduced in the previous section where the guess is not used during
training. Also, we are free to use the entire guess, including the center word, compared to the
reference where we have to remove the center word.
At training time, the dual attention model takes 3 inputs, that is, the source, the guess and the
reference. At test time, the reference input is replaced by the guess. Specifically, the model
FdUal(x, yg, yref) ∈ [0； 1]lyrefl×lYl estimates P (丫篙 | x, yg, y£) for each position i in the reference
sentence.
Architecture. The model builds upon the single attention model from the previous section by
having two attention functions a with distinct parameters. The first function asource takes the
source sentence x and the reference context yr-efi to produce the source summary for this con-
text asource y-i|k, x as in the single attention model. The second function aguess takes the
guess sentence yg and the reference context yr-efi and produces a guess summary for this context
aguess y-i|k, yg . These two summaries are then concatenated with the lookup representation of
the reference context L yref-i|k and input to a final multilayer perceptron followed by a softmax.
The reference lookup table contains the only parameters shared by the two attention functions.
Training. This model is trained similarly to the single attention model, the only difference being
the conditioning on the guess yg.
Testing. At test time, the reference is unavailable and we replace yref with yg, i.e., the model is
given (x, yg, yg-i|k) to make a prediction at position i. In this case, the distribution shift when going
from training to testing is less drastic than in §3 and the model retains access to the whole yg via
attention.
Discussion. Compared to the single attention model (§3), this model reduces perplexity from 5.4
to 4.1 on our validation set. Since the dual attention model can attend to all guess words, it can
copy any guess word if necessary. In our dataset, 68% of guess words are in the reference and can
therefore be copied. This also means that for the remaining 32% of reference tokens the model
should not copy. Instead, the model should propose a substitution by itself (§6.1). During testing,
the fact that the guess is input twice (x, yg, yg-i|k) means that the guess and the prediction context
always match. This makes the model more conservative in its predictions, suggesting tokens from
yg more often than the single attention model. However, as we show in §6, this turns out beneficial
in our setting.
5	Iterative Refinement
The models in §3 and §4 suggest word substitutions for each position in the candidate translation yg
given the current surrounding context.
Applying a single substitution changes the context of the surrounding words and requires updating
the model predictions. We therefore perform multiple rounds of substitution. At each round, the
model computes its predictions, then our refinement strategy selects a substitution and performs it
unless the strategy decides that it can no longer improve the target sentence. This means that the
refinement procedure should be able to (i) prioritize the suggested substitutions, and (ii) decide to
stop the iterative process.
We determine the best edit for each position i in yg by selecting the word with the highest probability
estimate: ypired = arg maxj∈Y F (x, yg)i,j . Then we compute a confidence score in this prediction
s(yg, ypred)i , possibly considering the prediction for the current guess word at the same position.
4
Under review as a conference paper at ICLR 2017
These scores are used to select the next position to edit, i? = arg maxi s(yg, ypred)i and to stop the
iterative process, i.e., when the confidence falls below a validated threshold t. We also limit the
number of substitutions to a maximum of N . We consider different heuristics for s,
•	Score positions based on the model confidence in	yipred,	i.e.,
sconf(yg, ypred)i = F(x, yg)i,ypired .
•	Look for high confidence in the suggested substitution ypired and low confidence in the
current word yig: spr(yg, ypred)i = F(x, yg)i,ypired × 1 - F(x, yg)i,ygi .
•	Train a simple binary classifier taking as input the score of the best predicted word and the
current guess word: scl(yg, ypred)i = nn log F(x, yg)i,ypired, log F(x, yg)i,ygi , where nn
is a 2-layer neural network trained to predict whether a substitution leads to an increase in
BLEU or not.
We compare the above strategies, different score thresholds t, and the maximum number of modifi-
cations per sentence allowed N in §6.2.
6 Experiments & Results
We first describe our experimental setup and then discuss our results.
6.1	Experimental Setup
Data. We perform our experiments on the German-to-English WMT15 task (Bojar et al., 2015)
and benchmark our improvements against the output of a phrase-based translation system (PBMT;
Koehn et al. 2007) on this language pair. In principle, our approach may start from any initial guess
translation. We chose the output of a phrase-based system because it provides a good starting point
that can be computed at high speed. This allows us to quickly generate guess translations for the
millions of sentences in our training set.
All data was lowercased and numbers were mapped to a single special “number” token. Infrequent
tokens were mapped to an “unknown” token which resulted in dictionaries of 120K and 170K words
for English and German respectively.
For training we used 3.5M sentence triples (source, reference, and the guess translation output by
the PBMT system). A validation set of 180K triples was used for neural network hyper-parameter
selection and learning rate scheduling. Finally, two 3K subsets of the validation set were used to
train the classifier discussed in §5 and to select the best model architecture (single vs dual attention)
and refinement heuristic.
The initial guess translations were generated with phrase-based systems trained on the same training
data as our refinement models. We decoded the training data with ten systems, each trained on
90% of the training data in order to decode the remaining 10%. This procedure avoids the bias of
generating guess translation with a system that was trained on the same data.
Implementation. All models were implemented in Torch (Collobert et al., 2011) and trained with
stochastic gradient descent to minimize the cross-entropy loss.
For the error detection model in §2 we used two temporal convolutions on top of the lookup table,
each followed by a tanh non-linearity to compute S(x) and T(yg). The output dimensions of
each convolution was set to 256 and the receptive fields spanned 5 words, resulting in final outputs
summarizing a context of 9 words.
For the single attention model we set the shared context embedding dimension dim Sj = dim Ti =
512 and use a context of size k = 4 words to the left and to the right, resulting in a window of
size 9 for the source and 8 for the target. The final multilayer perceptron has 2 layers with a hidden
dimension of 512, see §3).
For the dual attention model we used 2-layer context embeddings (a convolution followed by a
linear with a tanh in between), each having output dimension 512, context of size k = 4. The
5
Under review as a conference paper at ICLR 2017
Model	Heuristic	Best t	Best N	BLEU
PBMT Baseline					30.02
F	sconf		0.8	3	30.21
	Spr		^07-		30.20
	Scl	^03-		30.19
FdUaI	sconf	^06-	7j	30.32
	Spr		^03-	"5	30.35
	Scl	0.4	2	30.33
Table 2: Validation BLEU (selecting substitution heuristics, decision thresholds t, and number of
maximum allowed modifications N). BLEU is reported on a 3,041 validation sentences.
newstest	PBMT BLEU	Our BLEU	∆
^^008	^29	^60	~01Γ
^^009	20.42	~20:74	^nɪ
^^0l0	22.82	^23T13	~01Γ
-^0∏	■^1.43	^2L65	~Q22~
-^0l2	■^1.78	ɪlθ	^θɪ
^^013	■24:99	■25:37	^058^
-^0l4	^22^	■23:07	~01Γ
2015	24.40	^80	-0:40-
Mean	22.49	—	22.81	~032^
Table 3: Test accuracy on WMT test sets after applying our refinement procedure.
final multilayer perceptron has 2 layers with a hidden dimension of 1024, see §4). In this setup, we
replaced dot-product attention with MLP attention (Bahdanau et al., 2015) as it performed better on
the validation set.
All weights were initialized randomly apart from the word embedding layers, which were pre-
computed with Hellinger Principal Component Analysis (Lebret & Collobert, 2014) applied to the
bilingual co-occurrence matrix constructed on the training set. The word embedding dimension was
set to 256 for both languages and all models.
6.2	Results
Table 2 compares BLEU of the single and dual attention models (F vs Fdual) over the validation set.
It reports the performance for the best threshold t ∈ {0, 0.1, . . . , 1} and the best maximum number
of modifications per sentence N ∈ {0, 1, . . . , 10} for the different refinement heuristics. The best
performing configuration is Fdual with the product-based heuristic spr thresholded at t = 0.5 for up
to N = 5 substitutions. We report test performance of this configuration in table 3. Tables 4, 5 and
6 show examples of system outputs. Overall the system obtains a small but consistent improvement
over all the test sets.
Figure 1 (left) plots accuracy versus the number of allowed substitutions and Figure 1 (right) shows
the percentage of actually modified tokens. The dual attention model (§4) outperforms single atten-
tion (§3). Both models achieve most of improvement by making only 1-2 substitutions per sentence.
Thereafter only very few substitutions are made with little impact on BLEU. Figure 1 (right) shows
that the models saturate quickly, indicating convergence of the refinement output to a state where
the models have no more suggestions.
To isolate the model contribution from the scoring heuristic, we replace the scoring heuristic with
an oracle while keeping the rest of the refinement strategy the same. We consider two types of
oracle: The full oracle takes the suggested substitution for each position and then selects which
single position should be edited or whether to stop editing altogether. This oracle has the potential
to find the largest BLEU improvement. The partial oracle does not select the position, it just takes
the heuristic suggestion for the current step and decides whether to edit or stop the process. Notice
that both oracles have very limited choice, as they are only able to perform substitutions suggested
by our model.
6
Under review as a conference paper at ICLR 2017
∩W1G
0123456789	10
Maximum substitutions per sentence allowed
pφepouj SUΦ>IO3 Jo %
SingIe.confidence -B-
Dual product -B—
3456789	10
Substitution step
Figure 1:	Left: BLEU as a function of the total number of substitutions allowed per sentence.
Values are reported on a small 3K validation set for the single and dual attention models using the
best scoring heuristic s and threshold t. Right: Percentage of modified tokens on the validation set
as a function of the total number of substitutions allowed per sentence. All models modify fewer
than 2.5% of tokens.
32.5
32.5
5 1
L 3
3
∩%
30.5
30
012345678g	10
Maximum substitutions per sentence allowed
DUaLprodUCt -B—
DUaLfUlLoraCle -*——
DUaLpaTtiaLoraCle ―■?—
30
30.5
2 5 1
3 L 3
3
∩%
Single.confidence -B—
Single_full_oracle -*—
Single_partiaLoraCle -q-
012345678g	10
Maximum substitutions per sentence allowed
Figure 2:	BLEU as a function of the total number of substitutions allowed per sentence.
Left: best dual-attention refinement strategy (DUaLProdUct) versus two oracles. The full
oracle (DualfulLoracle) accepts as input ypred and selects a single i to substitute yg :=
ypred. The partial oracle (DuaLpartiaLoracle) lets the model choose position as well (i :=
arg max16j6|yg| s(yg, ypred)) but has the ability to prevent substitution ygi := ypired if it does not
improve BLEU. Right: same for the best single attention setup.
Figure 2 reports the performance of our best single and dual attention models compared to both
oracles on the validation set; Figure 3 shows the corresponding number of substitutions. The full
and partial oracles result in an improvement of +1.7 and +1.09 BLEU over the baseline in the dual
attention setting (compared to +0.35 with spr).
In the single-attention setup the oracles yields a higher improvement (+2.37 and +1.3) and they also
perform more substitutions. This supports our earlier conjecture (§4) that Fdual is more conservative
and prone to copying words from the guess yg compared to the single attention model. While helpful
in validation, the cautious nature of the dual model restricts the options of the oracle.
We make several observations. First, word-prediction models provide high-quality substitutions
ypred that can lead to a significant improvements in BLEU (despite that both oracles are limited in
their choice of ypred). This is supported by the simple heuristic sconf performing very close to more
sophisticated strategies (Table 2).
7
Under review as a conference paper at ICLR 2017
5 2 5 1 5
Z LS
P①匚一POlU SU①>101 Jo
DUaLprodUCt -B—
DUaLfUILoraCIe -A—
DUaIpaTtiaIoraCIe r-
I - I -∣	I
0
01234567
Substitution step
8	9	10
∙52∙51∙5
2LS
P①-PolU SU①>|。4 Jo。一。
SingIe.confidence -B-
SingIe_full_oracle -*—
Single.partial oracle r-
0
01234567
Substitution step
8	9	10
Figure 3:	Percentage of modified tokens as a function of total number of substitutions allowed per
sentence for the dual attention model (left) and the single attention model (right) compared to the
full and partial oracles (cf. Figure 2).
Second, it is important to have a good confidence estimate on whether a substitution will improve
BLEU or not. The full oracle, which yields +1.7 BLEU, acts as an estimate to having a real-
valued confidence measure and replaces the scoring heuristic s. The partial oracle, yielding +1.09
BLEU, assesses the benefit of having a binary-valued confidence measure. The latter oracle can only
prevent our model from making a BLEU-damaging substitution. However, confidence estimation is
a difficult task as we found in §2.
Finally, we demonstrate that a significant improvement in BLEU can be achieved through very
few substitutions. The full and partial oracle modify only 1.69% and 0.99% of tokens, or 0.4 and
0.24 modifications per sentence, respectively. Of course, oracle substitution assumes access to the
reference which is not available at test time. At the same time, our oracle is more likely to generate
fluent sentences since it only has access to substitutions deemed likely by the model as opposed to an
unrestricted oracle that is more likely to suggest improvements leading to unreasonable sentences.
Note that our oracles only allow substitutions (no deletions or insertions), and only those that raise
BLEU in a monotonic fashion, with each single refinement improving the score of the previous
translation.
7 Conclusion and Future Work
We present a simple iterative decoding scheme for machine translation which is motivated by the
inability of existing models to revisit incorrect decoding decisions made in the past. Our models
improve an initial guess translation via simple word substitutions over several rounds. At each round,
the model has access to the source as well as the output of the previous round, which is an entire
translation of the source. This is different to existing decoding algorithms which make predictions
based on a limited partial translation and are unable to revisit previous erroneous decoding decisions.
Our results increase translation accuracy by up to 0.4 BLEU on WMT15 German-English translation
and modify only 0.6 words per sentence. In our experimental setup we start with the output of
a phrase-based translation system but our model is general enough to deal with arbitrary guess
translations.
We see several future work avenues from here. Experimenting with different initial guess transla-
tions such as the output of a neural translation system, or even the result ofa simple dictionary-based
word-by-word translation scheme. Also one can envision editing a number of guess translations si-
multaneously by expanding the dual attention mechanism to attend over multiple guesses.
So far we only experimented with word substitution, one may add deletion, insertion or even swaps
of single or multi-word units. Finally, the dual-attention model in §4 may present a good starting
point for neural multi-source translation (Schroeder et al., 2009).
8
Under review as a conference paper at ICLR 2017
Acknowledgments
The authors wish to thank Marc’Aurelio Ranzato and Sumit Chopra for their advice and comments.
References
Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. Neural machine translation by jointly
learning to align and translate. In Proc. of ICLR. Association for Computational Linguistics, May
2015.
Yoshua Bengio, Rejean Ducharme, Pascal Vincent, and Christian Janvin. A neural probabilistic
language model. J. Mach. Learn. Res., 3:1137-1155, March 2003. ISSN 1532-4435. URL
http://dl.acm.org/citation.cfm?id=944919.944966.
John Blatz, Erin Fitzgerald, George F. Foster, Simona Gandrabur, Cyril Goutte, Alex Kulesza, Al-
berto Sanchis, and Nicola Ueffing. Confidence estimation for machine translation. In Proc. of
COLING, 2004.
Ondej Bojar, Rajan Chatterjee, Christian Federmann, Barry Haddow, Chris Hokamp, Matthias Huck,
Varvara Logacheva, and Pavel Pecina (eds.). Proceedings of the Tenth Workshop on Statistical
Machine Translation. Association for Computational Linguistics, Lisbon, Portugal, September
2015. URL http://aclweb.org/anthology/W15-30.
Ondej Bojar, Rajen Chatterjee, Christian Federmann, Yvette Graham, Barry Haddow, Matthias
Huck, Antonio Jimeno-Yepes, Philipp Koehn, Varvara Logacheva, Christof Monz, Matteo Negri,
AureIie Neveol, Mariana L. Neves, Martin Popel, Matt Post, Raphael Rubino, Carolina Scarton,
Lucia Specia, Marco Turchi, Karin M. Verspoor, and Marcos Zampieri. Findings of the 2016
conference on machine translation. In WMT, 2016.
R. Collobert, K. Kavukcuoglu, and C. Farabet. Torch7: A matlab-like environment for machine
learning. In BigLearn, NIPS Workshop, 2011. URL http://torch.ch.
Michel Galley, Mark Hopkins, Kevin Knight, and Daniel Marcu. What’s in a translation rule? pp.
273-280, Boston, MA, USA, May 2004.
Liang Huang. Forest-based algorithms in natural language processing. PhD thesis, University of
Pennsylvania, 2008.
Philipp Koehn, Franz Josef Och, and Daniel Marcu. Statistical Phrase-Based Translation. pp. 127-
133, Edmonton, Canada, May 2003.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola
Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ondej Bojar,
Alexandra Constantin, and Evan Herbst. Moses: Open source toolkit for statistical machine
translation. In Proc. of ACL, 2007.
Remi Lebret and Ronan Collobert. Word embeddings through hellinger pca. In 14th Conference of
the European Chapter of the Association for Computational Linguistics, 2014.
Joel Legrand, Michael Auli, and Ronan Collobert. Neural network-based word alignment through
score aggregation. In Proceedings of WMT, 2016.
Thang Luong, Hieu Pham, and Christopher D. Manning. Effective approaches to attention-based
neural machine translation. In Llus Mrquez, Chris Callison-Burch, Jian Su, Daniele Pighin,
and Yuval Marton (eds.), EMNLP, pp. 1412-1421. The Association for Computational Linguis-
tics, 2015. ISBN 978-1-941643-32-7. URL http://dblp.uni-trier.de/db/conf/
emnlp/emnlp2015.html#LuongPM15.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. Bleu: A method for automatic
evaluation of machine translation. In Proceedings of the 40th Annual Meeting on Association
for Computational Linguistics, ACL ’02, pp. 311-318, Stroudsburg, PA, USA, 2002. Association
for Computational Linguistics. doi: 10.3115/1073083.1073135. URL http://dx.doi.org/
10.3115/1073083.1073135.
9
Under review as a conference paper at ICLR 2017
Alexander M Rush, Sumit Chopra, and Jason Weston. A neural attention model for sentence sum-
marization. In Proc. of EMNLP, 2015.
Josh Schroeder, Trevor Cohn, and Philipp Koehn. Word lattices for multi-source translation. In
Proc. of EACL, 2009.
Michel Simard, Cyril Goutte, and Pierre Isabelle. Statistical phrase-based post-editing. In Proc. of
NAACL, 2007.
Nicola Ueffing and Hermann Ney. Word-level confidence estimation for machine translation. Com-
Putational Linguistics, 33:9-40, 2007.
A	Examples
x	new york city erwagt ebenfalls ein SolcheS.
Yref	new york city is also considering this.
Yg	new york city is also a such .
our	new york city is also considering this .
x	esme nussbaum Senkte ihren kopf. ~∣
Yref	esme nussbaum lowered her head .
Yg	esme nussbaum slashed its head .
our	esme nussbaum lowered her head .
X	PaPa, ich bin 22 !
yref	dad, i &apos;m 22 !
yg	papa ,iam22 .
our	papa ,iam22 !
	
X	grobritannien importiert 139.000 ton- nen .
Yref	Uk imports 139,000 tons.
yg	britain imported 139,000 tonnes.
our	britain imports 139,000 tonnes.
x	alles in deutschland wird subventioniert, von der kohle Uber autos bis zur Iandwirtschaft .
Yref	everything is subsidised in germany , from coal, to cars and farmers.
Yg	all in germany , subsidised by the coal on cars to agriculture .
Y_	everything in germany is subsidised by the coal on cars to agriculture .
X	drei manner , die laut aussage der behorden als fahrer arbeiteten , wurden wegen des besitzes und des beabsichtigten verkaufs von marihuana und kokain angeklagt.
Yref	three men who authorities say worked as drivers were charged with possession of mari- juana and cocaine with intent to distribute .
Yg	three men who , according to the authorities have been worked as a driver , because of the possession and the planned sale of marijuana and cocaine .
	three men who , according to the authorities, were working as a driver , because of the possession and the intended sale of marijuana and cocaine .
Table 4: Examples of good refinements performed by our system on our test sets. The model clearly
improves the quality of the initial guess translations.
10
Under review as a conference paper at ICLR 2017
X	er war auch kein klempner .	x	mit 38 aber beging er selbstmord .
Yref	nor was he a PiPe lagger .	Yref	but at 38 , he committed suicide .
yg	he was also a plumber .	yg	th 38 but he committed suicide .
our	he was not a plumber .	our	in 38 he committed suicide .
X	ich habe Schon 2,5 millionen in die kampagne gesteckt.		
Yref	i have already put 2.5 million into the campaign .		
yg	i have already 2.5 million in the campaign .		
our	i have put 2.5 million into campaign .		
X	dieses jahr werden amerikaner etwa 106 millionen dollar fur kurbisse ausgeben , so das us census bureau .		
Yref	this year, americans will spend around $106 million on pumpkins, according to the u.s. census bureau .		
Yg	this year, the americans are approximately 106 million dollars for pumpkins, so the us census bureau .		
our	this year, the americans spend about 106 million dollars to pumpkins, so the us census bureau .		
X	das thema unterliegt bestimmungen , denen zufolge fluggesellschaften die sicherheit jed- erzeit aufrechterhalten und passagiere die vom kabinenpersonal gegebenen sicherheitsan- weisungen befolgen mussen .		
Yref	the issue is covered by regulations which require aircraft operators to ensure safety is maintained at all times and passengers to comply with the safety instructions given by crew members.		
yg	the issue is subject to rules, according to which airlines and passengers to maintain the security at any time by the cabin crew safety instructions given to follow .		
our	the issue is subject to rules, according to which airlines and passengers must follow thei security at any time by the cabin crew safety instructions given to follow .		
Table 5: Refinements of mixed quality. Our model is not able to insert new words, and so sometimes
it replaces a relevant word with another relevant word. In other cases, improvements are insignifi-
cant, or good word replacements are mixed with poor ones.
X	ein krieg , der weder verloren noch gewonnen wird	X	werden wir jemals erfahren , was ihn verursacht hat ?
Yref	a war that is neither lost or won	Yref	will we ever know what caused it ?
Yg	a war that is til to be gained or lost	Yg	will we ever earn what caused it ?
our	a war that is neither to be lost nor lost	our	will we ever hear what caused it ?
x	in den vereinigten staaten liegt das durchschnittsalter bei 12,5 jahren , etwas weniger als 12,75 imjahr 1970.	
Yref	in the united states, the average age is 12.5 years, down from 12.75 in 1970 .
Yg	in the united states, the average age at 12.5 years ago, a little less than 12.75 in 1970 .
our	in the united states, the average age of 12.5 years ago is a little less than 12.75 in 1970 .
Table 6: Examples of poor refinements. Our model does not improve the translation or decreases
the quality of the translation.
11