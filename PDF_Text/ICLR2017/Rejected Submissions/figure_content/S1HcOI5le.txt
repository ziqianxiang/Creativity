Figure 1: One illustration of the parameter basis in VGG net. Visualization of the first convolutionallayer from VGG Karen & Zisserman (2014) network pre-trained on ImageNet (Alex et al. (2012)).
Figure 2: The initial parameters as shown in (a), where parameters are correlated. (b) is an illustra-tion of our grouping algorithm, the algorithm assigns each different parameters to a correspondinggroup with a one to one mapping. (c) illustrates our algorithm cast a constraint to force parametersfrom each group orthogonal to those from other groups.
Figure 3: This figure illustrates the framework of the Orthogonal Method of Grouping. n1...nMrepresent the M different neural units (basis vectors). The dotted arrows represent the one to onemapping from each neural unit to their corresponding orthogonal groups. Each orthogonal group giis represented as a red square. In a) it illustrates a special case of Orthogonal Method of Groupingwith identity mapping. This special case can represent the connection between any normal layers.
Figure 4: The difference of accuracy between proposed model and baseline as functions of α andβ. The dashed line in each charts is the baseline performance. As we can see from the charts,when alpha and beta are in the range of [1e-6, 1e-4] and [1e-6 , 1e-3], the performance of OMGoutperforms the baseline.
Figure 5: The difference of accuracy between our proposed model and the baseline as functions of aratio between group size and neural unit size. From the chart, when the number of groups is around[1, 4], the proposed model outperforms the baseline.
Figure 6: The Visualization of the orthogonal grouped filter maps in the first convolutional layer. Thefilters in each blue block belong to the same group. It is easy to see that filters in each group sharethe similar appearance, and the filters from different groups are different in terms of appearance.
Figure 7: Visualization of the orthogonal grouped filter maps in the first convolutional layer. Filtersin each row belong to the same group. It is easy to see that filters in each group share the similarappearance, and the filters from different groups are different in terms of appearance.
Figure 8: Visualization of the filter maps from the first convolutional layer. 10 filters are selectedfrom the original filter map to show what have the OMG learned. The first column shows thefilters from the original VGG-F. The second column is the corresponding filters after finetune withOMG. The filters on the left originally have the strong patterns, and they are mainly unchangedafter finetuning. The right ones do not have strong pattern originally, and the pattern becomesmore distinct after finetune with OMG. All the filters are normalized to the same magnitude beforevisualization.
