Figure 1: Depiction of MNIST dataset. (a) Two-dimensional features obtained by siamese network.
Figure 2: Illustration of learning processes for softmax-based classification network and siamese-based DML network. For softmax, the gradient is defined by the distance between a sample and afixed one-hot vector, and for siamese by the distance between samples.
Figure 3: GoogLeNet Szegedy et al. (2015) architecture we use in this paper. We extracted thefeatures from the red-colored layers. For (a), we applied PCA to reduce the number of featuredimensions. For (b) and (c), the dimensionality is already reduced to the required number by thefc_reduction layer.
Figure 4: Mean attributeprecision for the ImageNetAttribute dataset.
Figure 5:	F1, NMI, and Recall@K scores for the test set of the Caltech UCSD Birds 200-2011dataset.
Figure 6:	F1, NMI, and Recall@K scores for the test set of the Stanford Cars 196 dataset.
Figure 7:	F1, NMI, and Recall@K scores for the test set of the Online Products dataset.
Figure 8:	F1, NMI, and Recall@K scores for test set of the Caltech UCSD Birds 200-2011 datasetunder different dataset sizes. The feature dimensionality is fixed at 1024.
Figure 9:	F1 , NMI, and Recall@K scores for test set of the Stanford Cars 196 dataset under differentdataset sizes. The feature dimensionality is fixed at 256.
