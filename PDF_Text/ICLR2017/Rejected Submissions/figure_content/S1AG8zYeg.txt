Figure 1: Model Overview: Illustration of the sentence encoder and single time-step computations in encoderand decoder. si â€™s represent sentence embeddings derived from the sentence encoder. Attention weights arecomputed for the sentences based on their embeddings and the current hidden state. In the encoder an attentionreadout is concatenated with the LSTM output to form the next hidden state. The decoder uses the attentionweights for prediction.
Figure 2: t-SNE embeddings of representations learned by the model for sentences from the test set. Theembeddings are color coded by the position of the sentence in the document it appears.
Figure 3: Performance with respect to paragraph length and sentence position - NIPS abstracts test data.
