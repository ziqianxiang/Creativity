Figure 1: The image data sets for the evaluation of the online dictionary learning algorithms.
Figure 2: Reconstruction accuracy of NODL and ODL on 32x32 images (sparse dictionary).
Figure 3: Reconstruction accuracy of NODL and ODL on 100x100 images with sparse dictionaryelements (50 non-zeros) and non-sparse codes.
Figure 4: Reconstruction accuracy for the sparse NLP data.
Figure 5: Reconstruction accuracy for the sparse synthetic data.
Figure 6: Visualization of the sparse dictionary and the matrix A learned on the first imagingdomain (Oxford images), using the baseline ODL method and our method.
Figure 7: The data sets for the evaluation of the online dictionary learning algorithms.
Figure 8: Reconstruction accuracy for 100x100 size images with non-sparse dictionary but sparsecode (50 non-zeros) settings.
Figure 9: Reconstruction Error for 32x32 size images with sparse dictionary settings.
Figure 10: Reconstruction Error for 100x100 size images with sparse dictionary (50 non-zeros) andnon-sparse code settings (2000 non-zeros).
Figure 11: Reconstruction Error forcode (50 non-Zeros) settings.
Figure 12:	Reconstruction Error for 32x32 siZe images, on the animals data, with varying sparsityin dictionary elements and codes.
Figure 13:	Reconstruction Error for 100x100 size images with non-sparse dictionary and non-sparsecodes (500 non-zeros) settings.
Figure 14:	The structure of a sparse dictionary that is learned from the processing of the first domainimage data (Oxford images) using the baseline ODL method.
Figure 15: Reconstruction error for the synthetic data from sub-spaces with non-overlapping sup-ports of non-zeros.
Figure 17: Reconstructed animal images of size100x100 (test data), with 500 sparse dictionary ele-ments (non-sparse codes). In each row, the original im-age is on the left, and the reconstructions, computed withODL and NODL (our algorithm), are in the center andright respectively.
Figure 18: Reconstructed animal images of size100x100 (test data), with 500 non-sparse dictionary ele-ments (non-sparse codes). In each row, the original imageis on the left, and the reconstructions, computed with ODLand NODL (our algorithm), are in the center and right re-spectively.
Figure 19: Extension of Fig. 2, with the results for the ODL* version of ODL where occasional“dead” elements are reinitialized with random values.
Figure 20: Evaluating the effects of the input data order; the experimental setup coincides with theone used to produce Fig. 2 (32x32 images). Different processing orders of the available datasets areused during the training phase; performance results on the test subset taken from the second domainare presented.
Figure 21: Evaluating the effects w.r.t. batch size while keeping the other experimental settingssame as the ones used to produce Fig. 2 (32x32 images).
Figure 22: Evaluating the effects w.r.t. the tuning parameter ck (the upper bound on the number ofnew elements added in a batch) while keeping the other experimental settings same as the ones usedto produce Fig. 2 (32x32 images).
Figure 23: Evaluating the effects w.r.t. the tuning parameter λg (the regularization parameter for thekilling of “weak” elements) while keeping the other experimental settings same as the ones used toproduce Fig. 2 (32x32 images).
Figure 24: Evaluating the effects w.r.t. the tuning parameter βc (the number of non-zeros in acode) while keeping the other experimental settings same as the ones used to produce Fig. 2 (32x32images).
Figure 25: Evaluating the effects w.r.t. the tuning parameter βd (the number of non-zeros in adictionary element) while keeping the other experimental settings same as the ones used to produceFig. 2 (32x32 images).
Figure 26: Evaluating the effects w.r.t. the tuning parameter γ (the threshold parameter for condi-tional neurogenesis) while keeping the other experimental settings same as the ones used to produceFig. 2 (32x32 images).
