Figure 1: The original image (top left), thresholded image, thinned image, and actual extracted penstroke image.
Figure 2: Example of a pen stroke image. Table 1: Corresponding sequence. The origin is atthe top left, and the positive vertical direction isdownward. From the origin to the first point, thefirst offset is 6 steps to the right and 4 down: (6,4). Then to the second point: 1 to the right and 1up, (1, -1); etc.
Figure 3: Distribution of sequence lengths. The average sequence length is approximately 40 steps.
Figure 4: Network architecture; see text.
Figure 5: Comparison of the test error of the four methods, averaged over ten runs. The dotted linesindicate, at each point in time, which fraction of the training data has been made available at thatpoint for the method of the corresponding color.
Figure 6: Comparison of the test error of the four methods, averaged over ten runs.
Figure 7: Comparison of the test error of the four methods, averaged over ten runs.
Figure 8: The figure shows the average loss contribution of the points or steps within a sequenceas a function of their position within the sequence (see text). The first steps are fundamentallyunpredictable. Once some context has been received, the loss for the next steps steeply drops. Lateron in the sequence however, the loss increases strongly. This effect may be explained by the fact thatthe number of possible preceding contexts increases exponentially, thus posing stronger requirementson the learning system for steps later on in the sequence, and/or by the point that later parts of thesequences can only be learned adequately once earlier parts have been learned first, as later steps candepend on any of the earlier steps.
Figure 9: Performance on full MNIST Pen Stroke Sequence Data Set, zoomed to first part of the runand same experiment, results for the full run.
Figure 10: Using the sequence prediction model as a starting point for sequence classification: startingfrom a trained sequence prediction network, the task is switched to predicting the class of the digit(red and black lines). A comparison with learning a digit classification model from scratch (blue andgreen lines) shows that the internal state built up to predict sequence steps is helpful in predicting theclass of the digit represented by the sequence.
Figure 11: Movie showing what the network has learned over time. The movie shows the output forthree sequences of the test data at different stages during training. To view, click the image or visitthis link: https://edwin-de-jong.github.io/blog/isl/rnn-movies/generative-rnn-training-movie.gif.
Figure 12: Training: the target of a trainingstep is used as the next input.
Figure 13: Generation: the output of the net-work is used as the next input.
Figure 14: Unguided output of the network: after each step, the networkâ€™s output is fed back as thenext input. Clearly, the network has learned the ability to independently produce long sequencesrepresenting different digits that occurred in training data.
