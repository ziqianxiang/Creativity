Figure 1: Effect of pruning on accuracy. Boldline represents discriminator learned by a 2-2-1MLP (Figure 2-a) on a toy data set. Dash line anddotted line show the results after pruning one ofthe hidden neurons. As it can be seen removing ahidden neuron will result into accuracy drop.
Figure 2: a) a simple 2-2-1 MLP; b) the samenetwork with one additional noise output. Allthe hidden units have a linear activation whilethe output neurons use sigmoid as activationfunction. The gray neuron is a noise outputwhich changes its target in each iteration.
Figure 3: Comparison between discriminators learned with and without noise neurons. As it can beseen with noise neurons the activation of hidden neurons is more correlated; a) discriminators definedby each hidden neuron in Figure 2-a; b) discriminators defined by each hidden neuron in Figure 2-b;c) final discriminator after pruning one hidden neuron in Figure 2-b.
Figure 4: Effect of noise outputs to the correlation of neurons activation in the hidden layers. The toprow shows the correlation of two hidden neurons in the network of Figure 2 while the bottom row isthe correlation between the two neurons on the first hidden layer of a 6 layer MLP (2-2-2-2-2-2-1).
Figure 5: Pruning Lenet-300-100 and Lenet-5 on MNIST data set with various accuracy thresholds.
Figure 6: Activation of neurons in apruned Lenet-5 with only 3 neurons leftFigure 7: Effect of Dropout and L2-regularization onNoiseOut. The y-axis represents the number of remain-ing neurons in the dense layer. Note that more thanone neuron can be removed in each epoch. In eachcurve, the bold line is the median of 10 runs and coloredbackground demonstrates the standard deviation.
Figure 7: Effect of Dropout and L2-regularization onNoiseOut. The y-axis represents the number of remain-ing neurons in the dense layer. Note that more thanone neuron can be removed in each epoch. In eachcurve, the bold line is the median of 10 runs and coloredbackground demonstrates the standard deviation.
