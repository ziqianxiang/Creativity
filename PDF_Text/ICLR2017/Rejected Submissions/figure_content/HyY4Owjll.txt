Figure 1: Densities estimated using GenBGM (f-h) and DiscBGM (i-k) can correct for model mis-specification (b) w.r.t. the true distribution (a) unlike densities estimated using other bagging-styleensembling methods (d-f).
Figure 2: Samples generated from the boosted generative models (c-h) demonstrate how boostingmay be used to ensemble weak learners (a, b) into stronger models with samples that are much morevisually reflective of the true data distribution.
Figure 3: Semi-supervised classification using unsupervised feature learning. The boosted genera-tive models are competitive and can also outperform baseline models with an appropriate sequenceof intermediate models.
