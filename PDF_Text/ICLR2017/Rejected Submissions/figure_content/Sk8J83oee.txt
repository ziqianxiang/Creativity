Figure 1: Depiction of GAN, Parallel GAN, and GAP. Not intended to be interpreted as a graphicalmodel. The difference between Figure (b) and (c) is that typical data-based parallelization is basedon multiple models which share parameters. In contrast, GAP requires multiple models with theirown parameters which are structured in a bipartite formation.
Figure 2: A cartoon illustration of Generative Adversarial Parallelization. Generators and discrim-inators are represented by different monks and sensei. The pairing between monks and sensei arerandomly substituted overtime.
Figure 3: a) The R15 dataset. Samples drawn from b) GAN and c) GAPGAN4 . GAPGAP 4 denotesfour GANs trained in parallel with swapping at every epoch. The two models were trained using100 out of 600 data points from the R15 dataset.
Figure 4: a) The Mixture of Gaussians dataset. Samples drawn from b) GAN and c) GAPGAN4 .
Figure 5: CIFAR-10 samples. Best viewed in colour. More samples are provided in the Appendix.
Figure 6: Discriminator learning curves on CIFAR-10 as a proxy for generalization perfor-mance. As parallelization scales up, the spread between training and validation cost shrinks. Notethat the curves corresponding to “GAP(DCGANx2)”, “GAP(DCGANx4)”, “GAP(GRANx2)” and“GAP(GRANx4)” are averages of the corresponding GAP models. See Figure 13 in Appendix A.3for the individual curves before averaging.
Figure 7: The standard deviations of the validation costs at various swapping frequencies. From topto bottom: 0.1, 0.3, 0.5, 0.7, and 1.0 per epoch.
Figure 8: Illustration of the Generative Adversarial Metric.
Figure 9: Illustration of the Generative Adversarial Metric II.
Figure 10: t-SNE mapping of data and sample points on CIFAR-10. The points are colour coded as:Data (Black), Single Model (Magenta), and GAP (Cyan). Note that, particularly for the figure on theright, there seems to be more overlap between the data and the GAP-generated samples comparedto the GAN-generated samples.
Figure 11: t-SNE mapping of data and sample points on the LSUN dataset. The points are colourcoded as: Data (Black), Single Model (Magenta), and GAP (Cyan).
Figure 12: Averaged GAP(GRAN) learning curves trained on the LSUN Church dataset. As paral-lelization scales up, the gap between training and validation cost narrows.
Figure 13: Each GAP model represented by the learning curve of a single DCGAN within theGAP(DCGAN) trained on CIFAR-10. This demonstrates that the observed behaviour of reducingthe spread between training and validation cost is not simply an effect of averaging.
Figure 14: The distribution of the predicted class labels of samples from various models made by aseparately trained logistic regression.
Figure 15: CIFAR-10 samples generated by GAP[DCGANx4]. Best viewed in colour.
Figure 16: CIFAR-10 samples generated by GAP[GRANx4]. Best viewed in colour.
Figure 17: LSUN Church samples generated by GAP[DCGANx4] at 0.3 swapping frequency. Bestviewed in colour.
Figure 18: LSUN Church samples generated by GAP[GRANx4] at 0.5 swapping frequency. Bestviewed in colour.
Figure 19: CIFAR-10 samples trained by GAP(DCGANx2, GRANx2).
Figure 20: CIFAR-10 samples trained by GAP(DCGANx2, GRANx2).
