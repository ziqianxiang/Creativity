Figure 1: Our neural networkarchitecture for raw wave. Firsttwo layers are convolutions withstrides. Last two layers areconvolutions with kw = 1,which are equivalent to fullyconnected layers. Power spec-trum and MFCC based networksdo not have the first layer.
Figure 2: The CTC criterion graph. (a) Graph which represents all the acceptable sequences of letters(with the blank state denoted “0”), for the transcription “cat”.(b) Shows the same graph unfoldedover 5 frames. There are no transitions scores. At each time step, nodes are assigned a conditionalprobability output by the neural network acoustic model.
Figure 3: The ASG criterion graph. (a) Graph which represents all the acceptable sequences ofletters for the transcription “cat”. (b) Shows the same graph unfolded over 5 frames. (c) Shows thecorresponding fully connected graph, which describe all possible sequences of letter; this graph isused for normalization purposes. Un-normalized transitions scores are possible on the edges. Ateach time step, nodes are assigned a conditional un-normalized score, output by the neural networkacoustic model.
Figure 4: Valid LER (a) and WER (b) v.s. training set size (10h, 100h, 200h, 1000h). Thiscompares MFCC-based and power spectrum-based (POW) architectures. AUG experiments includedata augmentation. In (b) we provide Baidu Deep Speech 1 and 2 numbers on LibriSpeech, as acomparison Hannun et al. (2014); Amodei et al. (2015).
