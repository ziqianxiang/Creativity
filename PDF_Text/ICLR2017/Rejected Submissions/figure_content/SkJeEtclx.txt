Figure 1: Our proposed architecture. Each component of our model is described in 3.1 through 3.3To address these problems, we propose a memory-based attention sequence-to-sequence model thatnot only can learn hierarchical attention relationships, but provides a simple and effective memorystructure. In the next section, we explain our model in more detail.
Figure 2: Example captions generated by our model on the test video for MSVD. Incorrect captioncases are shown in red.
