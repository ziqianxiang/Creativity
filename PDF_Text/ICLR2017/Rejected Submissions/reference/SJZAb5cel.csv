title,year,conference
 Improved Transition-Based Parsing andTagging with Neural Networks,2015, In Proceedings of the 2015 Conference on Empirical Methods inNatural Language Processing
 Globally Normalized Transition-Based Neural Networks,2016, InProceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume1: Long Papers)
 Chunking and Dependency Parsing,2008, In Proceedings ofLREC 2008 Workshop on Partial Parsing
 Top Accuracy and Fast Dependency Parsing is not a Contradiction,2010, In Proceedingsofthe 23rd International Conference on Computational Linguistics
 Enhancing and Combining Se-quential and Tree LSTM for Natural Language Inference,2016, CoRR
 Parsing as Language Modeling,2016, In Proceedings of the 2016Conference on Empirical Methods in Natural Language Processing
 Transition-Based Dependency Parsing with Stack Long Short-Term Memory,2015, In Proceedings of the 53rdAnnual Meeting of the Association for Computational Linguistics and the 7th International JointConference on Natural Language Processing (Volume 1: Long Papers)
 Framewise Phoneme Classification with Bidirectional LSTMand Other Neural Network Architectures,2005, Neural Networks
 Improving neural networks by preventing co-adaptation of feature detectors,2012, CoRR
 Long short-term memory,1997, Neural Computation
 Easy-First Dependency Parsing with Hierarchical TreeLSTMs,2016, Transactions of the Association for Computational Linguistics
 Chunking with Support Vector Machines,2001, In Proceedings of theSecond Meeting of the North American Chapter of the Association for Computational Linguistics
 Ask Me Anything: Dynamic Memory Networks forNatural Language Processing,2016, In Proceedings of The 33rd International Conference on MachineLearning
 Illinois-LH: A Denotational and Distributional Approach to Se-mantics,2014, In Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval2014)
 Learning without Forgetting,2016, CoRR
 Finding Function in Form: Compositional Character Models for OpenVocabulary Word Representation,2015, In Proceedings of the 2015 Conference on Empirical Methodsin Natural Language Processing
 Multi-taskSequence to Sequence Learning,2016, In Proceedings of the 4th International Conference on LearningRepresentations
 End-to-end Sequence Labeling via Bi-directional LSTM-CNNs-CRF,2016, In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics(Volume 1: Long Papers)
 Distributed Represen-tations of Words and Phrases and their Compositionality,2013, In Advances in Neural InformationProcessing Systems 26
 Cross-stitch Networks forMulti-task Learning,2016, CoRR
 Gated Word-Character Recurrent Language Model,2016, InProceedings of the 2016 Conference on Empirical Methods in Natural Language Processing
 Word Embedding-based Antonym Detectionusing Thesauri and Distributional Information,2015, In Proceedings of the 2015 Conference of theNorth American Chapter of the Association for Computational Linguistics: Human LanguageTechnologies
 Dropout improvesRecurrent Neural Networks for Handwriting Recognition,2014, CoRR
 Progressive Neural Networks,2016, CoRR
 Semantic Composi-tionality through Recursive Matrix-Vector Spaces,2012, In Proceedings of the 2012 Joint Conferenceon Empirical Methods in Natural Language Processing and Computational Natural LanguageLearning
 Recursive Deep Models for Semantic Compositionality Over a SentimentTreebank,2013, In Proceedings of the 2013 Conference on Empirical Methods in Natural LanguageProcessing
 Sequence to Sequence Learning with Neural Net-works,2014, In Advances in Neural Information Processing Systems 27
 Semi-Supervised Sequential Labeling and Segmentation UsingGiga-Word Scale Unlabeled Data,2008, In Proceedings of the 46th Annual Meeting of the Associationfor Computational Linguistics: Human Language Technologies
 Structured Training for Neural Net-work Transition-Based Parsing,2015, In Proceedings of the 53rd Annual Meeting of the Associationfor Computational Linguistics and the 7th International Joint Conference on Natural LanguageProcessing (Volume 1: Long Papers)
 ABCNN: Attention-Based Con-volutional Neural Network for Modeling Sentence Pairs,2016, Transactions of the Association forComputational Linguistics
 Modelling Sentence Pairs with Tree-structured Attentive En-coder,2016, In Proceedings of the 26th International Conference on Computational Linguistics
 Without the internal phrase â€œwho resigned,2017,
