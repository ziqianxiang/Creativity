title,year,conference
 Adaptive subgradient methods for online learning andstochastic optimization,1532, J
 Slow learners are fast,2009, arXiv preprintarXiv:0911
 Scaling distributed machine learning with theparameter server,2014, In 11th USENIX Symposium on Operating Systems Design and Implementation(OSDI 14)
 Communication efficient dis-tributed machine learning with the parameter server,2014, In Z
 Hogwild: A lock-free approach toparallelizing stochastic gradient descent,2011, In Advances in Neural Information Processing Systems
 Parallelized stochastic gradientdescent,2010, In Advances in neural information processing systems
