title,year,conference
 Neural machine translation by jointlylearning to align and translate,2015, In Proc
 Report onthe 11th IWSLT evaluation campaign,2014, In Proc
 On the Propertiesof Neural Machine Translation: Encoder-decoder Approaches,2014, In Proc
 Learning Phrase Representations using RNN Encoder-Decoderfor Statistical Machine Translation,2014, In Proc
 A Character-level Decoder without ExplicitSegmentation for Neural Machine Translation,2016, arXiv preprint arXiv:1603
 Torch7: A Matlab-like Environmentfor Machine Learning,2011, In BigLearn
 Deep Residual Learning for ImageRecognition,2015, In Proc
 Long short-term memory,1997, Neural computation
 On Using Very LargeTarget Vocabulary for Neural Machine Translation,2014, arXiv preprint arXiv:1412
 MontrealNeural Machine Translation systems for WMT15,2015, In Proc
 Is Neural Machine Translation Readyfor Deployment? A Case Study on 30 Translation Directions,2016, arXiv preprint arXiv:1610
 Recurrent Continuous Translation Models,2013, In Proc
 Neural Machine Translation in Linear Time,2016, arXiv
 Adam: A Method for Stochastic Optimization,2014, Proc
 Vocabulary Selection Strategies for NeuralMachine Translation,2016, arXiv preprint arXiv:1610
 Effective approaches to attention-based neural machine translation,2015, In Proc
 Addressingthe Rare Word Problem in Neural Machine Translation,2015, In Proc
 Vocabulary Manipulation for Neural Machine Trans-lation,2016, arXiv preprint arXiv:1605
 On the Difficulty of Training RecurrentNeural Networks,2013, ICML (3)
 Convolutional Neural Network Lan-guage Models,2016, In Proc
 Sequence level Train-ing with Recurrent Neural Networks,2015, In Proc
 Neural Machine Translation of Rare Wordswith Subword Units,2016, In Proc
 Edinburgh neural machine translation systemsfor wmt 16,2016, 2016b
 End-to-end Memory Net-works,2015, In Proc
 Sequence to Sequence Learning with Neural Net-works,2014, In Proc
 Context-dependent Translation selectionusing Convolutional Neural Network,2015, In Proc
 Neural Machine Translationwith Recurrent Attention Modeling,2016, arXiv preprint arXiv:1607
 Deep Recurrent Models with Fast-Forward Connections for Neural Machine Translation,2016, arXiv preprint arXiv:1606
