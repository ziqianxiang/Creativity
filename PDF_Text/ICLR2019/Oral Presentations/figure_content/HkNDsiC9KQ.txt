Figure 1: Left: Schematic for meta-learning an unsupervised learning algorithm. The inner loopcomputation consists of iteratively applying the UnsupervisedUpdate to a base model. During meta-training the UnsupervisedUpdate (parameterized by θ) is itself updated by gradient descent on theMetaObjective. Right: Schematic of the base model and UnsupervisedUpdate. Unlabeled input data,x0 , is passed through the base model, which is parameterised by W and colored green. The goal ofthe UnsupervisedUpdate is to modify W to achieve a top layer representation xL which performswell at few-shot learning. In order to train the base model, information is propagated backwardsby the UnsupervisedUpdate in a manner analogous to backprop. Unlike in backprop however, thebackward weights V are decoupled from the forward weights W . Additionally, unlike backprop,there is no explicit error signal as there is no loss. Instead at each layer, and for each neuron, alearning signal is injected by a meta-learned MLP parameterized by θ, with hidden state h. Weightupdates are again analogous to those in backprop, and depend on the hidden state of the pre- and post-synaptic neurons for each weight.
Figure 2: Left: Standard unsupervised learning approaches suffer from objective function missmatch.
Figure 3: Training curves for the training and evaluation task distributions. Our train set consistsof MiniImagenet, Alphabet, and MiniCIFAR. Our test sets are Mini Imagenet Test, Tiny FashionMNIST, Tiny MNIST and IMDB. Error bars denote standard deviation of evaluations with a fixedwindow of samples evaluated from a single model. Dashed line at 200 hours indicates model used forremaining experiments unless otherwise stated. For a bigger version of this figure, see Appendix E.
Figure 4: Left: The learned UnsupervisedUpdate generalizes to unseen datasets. Our learnedupdate rule produces representations more suitable for few shot classification than those from randominitialization or a variational autoecoder and outperforms fully supervised learning on the samelabeled examples. Error bars show standard error. Right: Early in meta-training (purple), theUnsupervisedUpdate is able to learn useful features on a 2 way text classification data set, IMDB,despite being meta-trained only from image datasets. Later in meta-training (red) performance dropsdue to the domain mismatch. We show inner-loop training, consisting of 5k applications of theUnsupervisedUpdate evaluating the MetaObjective each iteration. Error bars show standard erroracross 10 runs.
Figure 5: Left: The learned UnsUPervisedUPdate is capable of optimizing base models with hiddensizes and depths outside the meta-training regime. As We increase the number of units per layer, thelearned model can make use of this additional capacity despite never having experienced it duringmeta-training. Right: The learned UnsupervisedUpdate generalizes across many different activationfunctions not seen in training. We show accuracy over the course of training on 14x14 MNIST.
Figure 6: Left: From left to right we show first layer base model receptive fields produced byour learned UnsupervisedUpdate rule over the course of meta-training. Each pane consists of firstlayer filters extracted from φ after 10k applications of UnsupervisedUpdate on MNIST (top) andCIFAR10 (bottom). For MNIST, the optimizer learns image-template-like features. For CIFAR10,low frequency features evolve into higher frequency and more spatially localized features. Formore filters, see Appendix D. Center: Visualization of learned representations before (left) andafter (right) training a base model with our learned UnsupervisedUpdate for two moons (top) andMNIST (bottom). The UnsupervisedUpdate is capable of manipulating the data manifold, withoutaccess to labels, to separate the data classes. Visualization shows a projection of the 32-dimensionalrepresentation of the base network onto the top three principal components. Right: Cumulativevariance explained using principal components analysis (PCA) on the learned representations. Therepresentation for two moons data (red) is much lower dimensional than MNIST (blue), althoughboth occupy a fraction of the full 32-dimensional space.
