Table 1: Machine translation accuracy in terms of BLEU for WMT En-De and WMT En-Fr onnewstest2014.
Table 2: Machine translation accuracy in terms of BLEU on IWSLT and WMT Zh-En.
Table 3: Ablation on WMT English-German newstest2013. (+) indicates that a result includes allpreceding features. Speed results based on beam size 4, batch size 256 on an NVIDIA P100 GPU.
Table 4: Language modeling results on the Google Billion Word test set.
Table 5: Results on CNN-DailyMail summarization. We compare to likelihood trained approachesexcept for Celikyilmaz et al. (2018).
Table 6: Alternatives to softmax-normalization in DynamicConv on WMT English-German new-stest2013 ( = 10-6).
Table 7: Inference speed of non-autoregressive models and small decoder versions of DynamicConvon WMT English-German newstest2014. For some models, the decoding speed (sent/sec) is derivedby taking the inverse of the sentence generation latency in the literature.
