Table 1: Negative Log-likelihood (NLL) scores for Downsampled Imagenet (van den Oord et al.,2016b) in bits/dim. The parenthesized numbers in Depth Upscaling rows indicate NLL for P (x:d1)and P (xdh,1w:d,c2 |xd1:d2<, x:d1) respectively.
Table 2: NLL scores for high-resolution Imagenet in bits/dim. The parenthesized numbers in DepthUpscaling rows indicate NLL for P (x:d1) and P (xhd,1w:d,c2 |xd1:d2<, x:d1) respectively.
Table 3: Negative Log-likelihood scores for 5-bit datasets in bits/dim.
Table 4: SPN Hyperparameters. A learning rate marked “sched” utilizes a piecewise-constantschedule starting at 1e-4, and decreasing to 3e-5 and finally 1e-5 at training steps 50k and 100krespectively. The “attention” parameters listed are configurable hyperparameters of the open sourceTransformer implementation in Vaswani et al. (2018). The parameter “residual channels“ refers tothe number of hidden units in residual convolution layers within the Slice Embedder or PixelCNNnetworks.
