Under review as a conference paper at ICLR 2019
Local Stability and Performance of
Simple Gradient Penalty μ-WASSERSTEiN GAN
Anonymous authors
Paper under double-blind review
Ab stract
Wasserstein GAN(WGAN) is a model that minimizes the Wasserstein distance
between a data distribution and sample distribution. Recent studies have proposed
stabilizing the training process for the WGAN and implementing the Lipschitz
constraint. in this study, we prove the local stability of optimizing the simple gra-
dient penalty μ-WGAN(SGP μ-WGAN) under suitable assumptions regarding the
equilibrium and penalty measure μ. The measure valued differentiation concept
is employed to deal with the derivative of the penalty terms, which is helpful for
handling abstract singular measures with lower dimensional support. Based on
this analysis, we claim that penalizing the data manifold or sample manifold is
the key to regularizing the original WGAN with a gradient penalty. Experimental
results obtained with unintuitive penalty measures that satisfy our assumptions are
also provided to support our theoretical results.
1	Introduction
Deep generative models reached a turning point after generative adversarial networks (GANs) were
proposed by Goodfellow et al. (2014). GANs are capable of modeling data with complex structures.
For example, DCGAN can sample realistic images using a convolutional neural network (CNN)
structure(Radford et al., 2015). GANs have been implemented in many applications in the field of
computer vision with good results, such as super-resolution, image translation, and text-to-image
generation(Ledig et al., 2017; isola et al., 2017; Zhang et al., 2017; Reed et al., 2016).
However, despite these successes, GANs are affected by training instability and mode collapse prob-
lems. GANs often fail to converge, which can result in unrealistic fake samples. Furthermore, even
if GANs successfully synthesize realistic data, the fake samples exhibit little variability.
A common solution to this instability problem is injecting an instance noise and finding different
divergences. The injection of instance noise into real and fake samples during the training procedure
was proposed by S0nderby et al. (2017), where its positive impact on the low dimensional support
for the data distribution was shown to be a regularizing factor based on the Wasserstein distance,
as demonstrated analytically by Arjovsky & Bottou (2017). in f -GAN, f -divergence between the
target and generator distributions was suggested which generalizes the divergence between two dis-
tributions(Nowozin et al., 2016). in addition, a gradient penalty term which is related with Sobolev
iPM(integral Probability Metric) between data distribution and sample distribution was suggested
by Mroueh et al. (2018).
The Wasserstein GAN (WGAN) is known to resolve the problems of generic GANs by selecting
the Wasserstein distance as the divergence(Arjovsky et al., 2017). However, WGAN often fails
with simple examples because the Lipschitz constraint on discriminator is rarely achieved during
the optimization process and weight clipping. Thus, mimicking the Lipschitz constraint on the
discriminator by using a gradient penalty was proposed by Gulrajani et al. (2017).
Noise injection and regularizing with a gradient penalty appear to be equivalent. The addition of
instance noise in f -GAN can be approximated to adding a zero centered gradient penalty(Roth et al.,
2017). Thus, regularizing GAN with a simple gradient penalty term was suggested by Mescheder
et al. (2018) who provided a proof of its stability.
1
Under review as a conference paper at ICLR 2019
Based on a theoretical analysis of the dynamic system, Nagarajan & Kolter (2017) proved the local
exponential stability of the gradient-based optimization dynamics in GANs by treating the simul-
taneous gradient descent algorithm with a dynamic system approach. These previous studies were
useful because they showed that the local behavior of GANs can be explained using dynamic system
tools and the related Jacobian’s eigenvalues.
In this study, We aim to prove the convergence property of the simple gradient penalty μ-Wasserstein
GAN(SGP μ-WGAN) dynamic system under general gradient penalty measures μ. To the best of
our knoWledge, our study is the first theoretical approach to GAN stability analysis Which deals
With abstract singular penalty measure. In addition, measure valued differentiation(Heidergott &
VazqUeZ-Abad, 2008) is applied to take the derivative on the integral with a parametric measure,
Which is helpful for handling an abstract measure and its integral in our proof.
The main contributions of this study are as follows.
•	We prove the regularized effect and local stability of the dynamic system for a gen-
eral penalty measure under suitable assumptions. The assumptions are written as both a
tractable strong version and intractable weak version. To prove the main theorem, we also
introduce the measure valued differentiation concept to handle the parametric measure.
•	Based on the proof of the stability, we explain the reason for the success of previous penalty
measures. We claim that the support of a penalty measure will be strongly related to the
stability, where the weight on the limiting penalty measure might affect the speed of con-
vergence.
•	We experimentally examined the general convergence results by applying two test penalty
measures to several examples. The proposed test measures are unintuitive but they still
satisfy the assumptions and similar convergence results were obtained in the experiment.
2	Preliminaries
First, we introduce our notations and basic measure-theoretic concepts. Second, we define our SGP
μ-WGAN optimization problem and treat this problem as a continuous dynamic system. Preliminary
measure theoretic concepts are required to justify that the dynamic system changes in a sufficiently
smooth manner as the parameter changes, so it is possible to use linearization theorem. They are
also important for dealing with the parametric measure and its derivative. The problem setting with
a simple gradient term is also discussed. The squared gradient size and simple gradient penalty term
are used to build a differentiable dynamic system and to apply soft regularization as a resolving con-
straint, respectively. The continuous dynamic system approach, which is a so-called ODE method,
is used to analyze the GAN optimization problem with the simultaneous gradient descent algorithm,
as described by Nagarajan & Kolter (2017).
2.1	Notations and Preliminaries Regarding Measure Theory
D(x; ψ) : X → R is a discriminator function with its parameter ψ and G(z; θ) : Z → X is
a generator function with its parameter θ . pd is the distribution of real data and pg = pθ is the
distribution of the generated samples in X, which is induced from the generator function G(z; θ)
and a known initial distribution Platent (Z) in the latent space Z. ∣∣∙k denotes the L2 Euclidean norm
if no special subscript is present.
The concept of weak convergence for finite measures is used to ensure the continuity of the integral
term over the measure in the dynamic system, which must be checked before applying the theorems
related to stability. Throughout this study, we assume that the measures in the sample space are all
finite and bounded.
Definition 1. For a set of finite measures {μi}i∈ι in (Rn, d) with euclidean distance d,{μi}i∈ι is
referred to as bounded if there exists some M > 0 such that for all i ∈ I,
μi(Rn) ≤ M
For instance, M can be set as 1 if {μi} are probability measures on Rn. Assuming that the penalty
measures are bounded, Portmanteau theorem offers the equivalent definition of the weak conver-
2
Under review as a conference paper at ICLR 2019
gence for finite measures. This definition is important for ensuring that the integrals over pθ and μ
in the dynamic system change continuously.
Definition 2. (Portmanteau Theorem) For a bounded Sequence of finite measures {μn}n∈N on the
Euclidean space Rn with a σ -field of Borel subsets B(Rn), μn converges weakly to μ if and only if
for every continuous boundedfunction φ on Rn, its integrals with respect to μn converge to J φdμ,
i.e.,
/ φdμn →
/ φdμ
μn -→ μ < ⇒
The most challenging problem in our analysis with the general penalty measure is taking the deriva-
tive of the integral, where the measure depends on the variable that we want to differentiate. If our
penalty measure is either absolutely continuous or discrete, then it is easy to deal with the integral.
However, in the case of singular penalty measure, dealing with the integral term is not an easy task.
Therefore, we introduce the concept of a weak derivative of a probability measure in the follow-
ing(Heidergott & VazqUez-Abad, 2008). The weak derivative of a measure is useful for handling a
parametric measure that is not absolutely continuous with low dimensional support.
Definition 3. (Weak Derivatives of a Probability Measure) Consider the Euclidean space and its
σ-field of Borel subsets (Rd, B(Rd)). The probability measure Pθ is called weakly differentiable at
θ ifa signed finite measure Pθ0 exists where
dθJ'φ(x)dPθ = ∆→0 W {/°(x)dPy-J φ(x)dPθ} = ∕φ(x)dPθ
is satisfied for every continuous bounded function φ on Rn. For the multidimensional parameter θ,
this can be defined similar manner.
We can show that the positive part and negative part of Pθ0 have the same mass by putting φ(x) = 1
and the Hahn-Jordan decomposition on P'θ. Therefore, the following triple (cθ , Pj ,P-) is called a
weak derivative of Pθ, where Pθ± are probability measures and Pθ0 is rewritten as:
Pθ0 = cθPθ+ - cθPθ-
Therefore,
d /φ(X)dPθ = /
φ(x)dPθ0 = cθ ( φ(x)dPθ+ -
φ(x)dPθ-)
holds for every continuous bounded function φ on Rn . It is known that the representation of
(cθ, Pθ+, Pθ- ) for Pθ0 is not unique because (cθ + Cθ, Pθ+ + qθ, Pθ- + qθ) is also another repre-
sentation of Pθ0 .
For the general finite measure Qθ, a normalizing coefficient M(θ) < ∞ can be introduced. The
product rule for differentiating can also be applied in a similar manner to calculus.
dθ∕φE θ)dPθ = J
Vθφ(x; θ)dPθ +
φ(x; θ)dPθ0
Therefore, for the general finite measure Qθ = M (θ)Pθ, its derivative Q0θ can be represented as
below.
Q0θ =M0(θ)Pθ+M(θ)Pθ0 = M0(θ)Pθ + cθM(θ)Pθ+ -cθM(θ)Pθ-
2.2	Problem Setting as a Dynamic System
Previous work of Mescheder et al. (2018) showed that the dynamic system of WGAN-GP is not
necessarily stable at equilibrium by demonstrating that the sequence of parameters is not Cauchy
sequence. This is mainly due to the term ∣∣xk in the dynamic system which has a derivative 小 that
is not defined at X = 0. WGAN-GP has a penalty term EμGp [(∣VχD(χ; ψ) ∣∣ - 1)2] that can lead to
a discontinuity in its dynamic system.
These problems can be avoided by using the squared value of the gradient’s norm ∣VxD∣2, which is
a differentiable function. In contrast to the WGAN-GP, recent methods based on a gradient penalty
such as the simple gradient penalty employed by Mescheder et al. (2018) and the Sobolev GAN used
3
Under review as a conference paper at ICLR 2019
the average of the squared values for the penalty area, whereas the WGAN-GP penalizes the size of
the discriminator,s gradient kVχDk away from 1 in a pointwise manner.
This advantage of squared gradient term1, Eμ[∣∣VχDk2], makes the dynamic system differentiable
and we define the WGAN problem with the square of the gradient’s norm as a simple gradient
penalty. This simple gradient penalty can be treated as soft regularization based on the size of the
discriminator,s gradient, especially in case where μ is the probability measure (Roth et al., 2017). It
is convenient to determine whether the system is stable by observing the spectrum of the Jacobian
matrix. In the following, (D(x; ψ),Pd,Pθ, μ) is defined as an SGP μ-WGAN optimization problem
(SGP-form) with a simple gradient penalty term on the penalty measure μ.
Definition 4. The WGAN optimization problem with a simple gradient penalty term kVxDk2,
penalty measure μ, and penalty weight hyperparameter ρ > 0 is given asfollows, where the penalty
term is only introduced to update the discriminator.
max : EpdD(x; Ψ)] — EpθD(x; ψ)] — PEμ[∣∣VχD(x; ψ)k2]
ψ2
min : Epd [D(x; ψ)] — Epθ [D(x; ψ)]
θ
According to Nagarajan & Kolter (2017) and many other optimization problem studies, the simul-
taneous gradient descent algorithm for GAN updating can be viewed as an autonomous dynamic
system of discriminator parameters and generator parameters, which we denote as ψ and θ. As a
result, the related dynamic system is given as follows.
ψ = Epd [Vψ D] — Epθ [vψ D] — 2 vψ Eμ[vT DVx D]
:	_ -	- - r
θ = Vθ Epθ[D]
3	Toy Examples
We investigate two examples considered in previous studies by Mescheder et al. (2018) and Nagara-
jan & Kolter (2017). We then generalize the results to a finite measure case. The first example is the
univariate Dirac GAN, which was introduced by Mescheder et al. (2018).
Definition 5. (Dirac GAN) The Dirac GAN comprises a linear discriminator D(x; ψ) = ψx, data
distribution pd = δ0, and sample distribution pθ = δθ.
The Dirac GAN with a gradient penalty with an arbitrary probability measure is known to be globally
convergent(Mescheder et al., 2018). We argue that this result can be generalized to a finite penalty
measure case.
Lemma 1. Consider the Dirac GANproblem with SGPform (D(x; ψ) = ψx, δo, δθ, μψ,θ). Sup-
pose that some small η > 0 exists such that its finite penalty measure μψ,θ with mass M (ψ, θ)=
11dμψ,θ ≥ 0 satisfies either
•	M(ψ, θ) > 0for (ψ, θ) ∈ Bη((0, 0)) or
•	M(0, 0) = 0 and ψVψM(ψ, θ) ≥ 0for(ψ,θ) ∈ Bη((0,0)).
Then, the SGP μ-WGAN optimization dynamics with (D(x; ψ) = ψx, δ0, δθ, μψ,θ) are locally stable
at the origin and the basin of attraction B = BR((0, 0)) is open ball with radius R. Its radius is
given as follows.
R = max{η ≥ 0|2M (ψ, θ) + ψVψ M (ψ, θ) ≥ 0for all (ψ, θ) such that ψ2 + θ2 ≤ η2}
Motivated by this example, we can extend this idea to the other toy example given by Nagarajan &
Kolter (2017), where WGAN fails to converge to the equilibrium points (ψ, θ) = (0, ±1).
1In this study, we prefer to use the expectation notation on the finite measure, which can be understood
as follows. Suppose that μψ,θ = M(ψ, θ)μψ,θ where μψ,θ is normalized to the probability measure. Then,
Eμψ,θ[kVxDk2] = Eμψ,θ[M(ψ,θ) INxDk2]'= R kVxDk2 M(ψ,θ)dμψ,θ(X) = R ∣MD∣∣2 dμψ,θ(x)
4
Under review as a conference paper at ICLR 2019
Lemma 2. Consider the toy example (D(x; ψ) = ψx2,U( —1,1),U(-∣θ∣, ∣θ∣), μθ) where
U (0,0) = δo and the ideal equilibrium points are g^ven by (ψ*,θ*) = (0, ±1). For a finite measure
μ = μθ on R which is independent of ψ, suppose that μθ → μ* with μ* = Cδo for C ≥ 0. The
dynamic system is locally stable near the desired equilibrium (0, ±1), where the spectrum of the
Jacobian at (0, ±1) is given by λ
-2ρEμ* [x2] ± ,4ρ2Eμ* [x2]2 - 9.
4	Main Convergence Theorem
We propose the convergence property of WGAN with a simple gradient penalty on an arbitrary
penalty measure μ for a realizable case: θ = θ* with Pd = pθ* exists. In subsection 4.1, We provide
the necessary assumptions, which comprise our main convergence theorem. In subsection 4.2, we
give the main convergence theorem with a sketch of the proof. A more rigorous analysis is given in
the Appendix.
4.1	Assumptions
The first assumption is made regarding the equilibrium condition for GANs, where we state the ideal
conditions for the discriminator parameter and generator parameter. As the parameters converge to
the ideal equilibrium, the sample distribution(pθ) converges to the real data distribution(pd) and the
discriminator cannot distinguish the generated sample and the real data.
Assumption 1. pθ → Pd as θ → θ* and D(x; ψ*) = 0 on Supp(Pd) and its small open
neighborhood, i.e., X ∈ ∪χ0∈supp(pd)Bexo (x0) implies D(x; ψ*) = 0. For simplicity, we denote
∪x0 ∈supp(pd ) Bx0 (x ) as B (supp(pd )).
The second assumption ensures that the higher order terms cannot affect the stability of the SGP
μ-WGAN. In the Appendix, we consider the case where the WGAN fails to converge when As-
sumption 2 is not satisfied. Compared with the previous study by Nagarajan & Kolter (2017), the
conditions for the discriminator parameter are slightly modified.
Assumption 2.
g⑹=kEPd [Vψ D(x； ψ* )] - Epθ[Vψ D(X； ψ*)]k2 , h(ψ) = Eμψ,θ* [kVxD(X； ψ)k2]
are locally constant along the nullspace of the Hessian matrix.
The third assumption allows us to extend our results to discrete probability distribution cases, as
described by Mescheder et al. (2018).
Assumption 3. ∃∈g > 0 such that D(x; ψ*) = 0 on ∪∣θ-θ*∣<egSupp(pθ).
The fourth assumption indicates that there are no other “bad” equilibrium points near (ψ*, θ*),
which justifies the projection along the axis perpendicular to the null space.
Assumption 4. A bad equilibrium does not exist near the desired equilibrium point. Thus, (ψ*, θ*)
is an isolated equilibrium or there exist δd, δg > 0 such that all equilibrium points in Bδd (ψ*) X
Bδg (θ*) satisfy the other assumptions.
The last assumption is related to the necessary conditions for the penalty measure. A calculation
of the gradient penalty based on samples from the data manifold and generator manifold or the
interpolation of both was introduced in recent studies (Gulrajani et al., 2017; Roth et al., 2017;
Mescheder et al., 2018). First, we propose strong conditions for the penalty measure.
Assumption 5. Thefinite penalty measure μ = μθ satisfies thefollowings:
a μθ → μθ* = μ* and μθ is independent of the discriminator parameter ψ.
b Supp(pd) ⊂ Supp(μ*)
C ∃tμ > 0 such that supp(μθ) ⊂ B(Supp(pd)) for ∣θ - θ*∣ < e*.
The assumption given above means that the support of the penalty measure μθ should approach the
data manifolds smoothly as θ → θ*. However, the penalty measure from WGAN-GP with a simple
5
Under review as a conference paper at ICLR 2019
gradient penalty still reaches equilibrium without satisfying Assumption 5c. Therefore, we suggest
Assumption 6, which is a weak version of Assumption 5. Assumption 6a2 is technically required to
take the derivative of the integral Eμψ,θ [kVχD(χ; ψ)k2] With respect to ψ.
Assumption 6. (Weak version of Assumption 5) The finite penalty measure μ = μψ,θ satisfies the
following.
a μψ,θ → μψ*,θ* = μ*, where Supp(μψ,θ) only depends on θ. Near the equilibrium, μψ,θ
can be weakly differentiated twice with respect to ψ. In addition, its mass M(ψ, θ) =
/ 1dμψ,θ is a twice-differentiable function of ψ and bounded near the equilibrium.
b Eμ* ∖VψχDVψχD] is positive definite or supp(pd) ⊂ supp(μ*).
C ∃tμ > 0 such that supp(μθ) ⊂ V for ∣θ 一 θ*∣ < e* , where V = {x∣VχD(x; ψ*) = 0}.
The assumption above implies the folloWing situations; The penalty measure’s support approaches
to data manifold and its Weight changes smoothly With respect to ψ and θ . At the equilibrium,
penalty measure’s support contains data manifold. Also, ideal discriminator Will remain flat on the
penalty area.
In summary, the gradient penalty regularization term With any penalty measure Where the support
approaches B(supp(pd)) in a smooth manner Works Well and this main result can explain the regu-
Iarization effect of previously proposed penalty measures such as μGp, pd, pθ, and their mixtures.
4.2	Main Convergence Theorem
According to the modified assumptions given above, We prove that the related dynamic system is
locally stable near the equilibrium. The tools used for analyzing stability are mainly based on those
described by Nagarajan & Kolter (2017). Our main contributions comprise proposing the necessary
conditions for the penalty measure and proving the local stability for all penalty measures that satisfy
Assumption 6.
Theorem 1. Suppose that our SGP μ-WGAN optimization problem (D,pd,pθ, μ) with equilibrium
point (ψ*, θ*) satisfies the assumptions g^ven above. Then, the related dynamic SyStem is locally
stable at the equilibrium.
A detailed proof of the main convergence theorem is given in the Appendix. A sketch of the proof is
given in three steps. First, the undesired terms in the Jacobian matrix of the system at the equilibrium
— —	— 一	.	-ρ .	「-oQ — R^∣	.
are cancelled out. Next, the Jacobian matrix at equilibrium is given by RT	0 , Where Q =
Eμ* [VψχDVTχD] and R = VθEρθ [VψD]∣θ=θ* . The system is locally stable when both Q and
RT R are positive definite. We can complete the proof by dealing With zero eigenvalues by shoWing
that N(QT) ⊂ N(RT) and the projected system’s stability implies the original system’s stability.
Our analysis mainly focuses on WGAN, which is the simplest case of general GAN minimax opti-
mization
max : Epd[f(D(x; ψ))] + Epθ[f(-D(x; ψ))] 一 PEμ[kVχD(x; ψ)k2]
ψ2
min : Epd [f (D(x; ψ))] + Epθ [f (-D(x; ψ))]
θ
with f(x) = x. Similar approach is still valid for general GANs with concave function f with
f00(x) < 0andf0(0) 6= 0.
5	Experimental Results
We claim that every penalty measure that satisfies the assumptions can regularize the WGAN and
generate similar results to the recently proposed gradient penalty methods. Several penalty measures
2This condition is technically required to handle the derivative of the measure in a convenient manner using
the weak formulation. Even if the measure is not differentiable, it may possible to differentiate the integral. For
instance, δψ is continuous but it does not have its weak derivative. However, it is still possible to differentiate
Eδψ [ω(x)] = ω(ψ) if the function ω is differentiable at ψ.
6
Under review as a conference paper at ICLR 2019
were tested based on two-dimensional problems (mixture of 8 Gaussians, mixture of 25 Gaussians,
and swissroll), MNIST and CIFAR-10 datasets using a simple gradient penalty term. In the com-
parisons with WGAN, the recently proposed penalty measures and our test penalty measures used
the same network settings and hyperparameters. The penalty measures and its detailed sampling
methods are listed in Table 1, where Xd 〜Pd, Xg 〜pθ, and ɑ 〜U(0,1). A indicates fixed anchor
point in X .
Table 1: List of benchmark WGANs (WGAN and WGAN-GP with non-zero centered gradient
penalty) and 5 penalty measures with a simple gradient penalty term. In this table, WGAN-GP
represents the previous model proposed by (Gulrajani et al., 2017), which penalizes the WGAN
with non-zero centered gradient penalty terms, whereas μGP represents the simple method. In our
experiment, no additional weights are applied on 5 penalty measures and they are all probability
distributions.
Penalty	Penalty term
WGAN	None(Weight Clipping)
WGAN-GP Eμ[(kVχDk - 1)2]
Penalty measure, sampling method
None
X = αXd + (1 — a)Xg
2
P id α
PgPdμGμmμg,
DDDDD
xxxxx
VVVVV
]
]
]
]
]
2
2
2
2
x = xg
X = Xd
X = αxd + (1 — α)xg
X = 0.5xd + 0.5xg
X = αA + (1 — α)xg
By setting the previously proposed WGAN with weight-clipping(Arjovsky et al., 2017) and WGAN-
GP(GUkajani et al., 2017) as the baseline models, SGP μ-wGAN was examined with various penalty
measures comprising three recently proposed measures and two artificially generated measures. pθ
and Pd were suggested by MeScheder et al. (2018) and μGP was introduced from the WGAN-GP.
We analyzed the artificial penalty measures μmid and μg,anc as the test penalty measures.
The experiments were conducted based on the implementation of the Gulrajani et al. (2017). The hy-
perparameters, generator/discriminator structures, and related TensorFlow implementations can be
found at https://github.com/igul222/improved_wgan_training (Gulrajani et al.,
2017). Only the loss function was modified slightly from a non-zero centered gradient penalty to a
simple penalty. For the CIFAR-10 image generation tasks, the inception score(Salimans et al., 2016)
and FID(Heusel et al., 2017) were used as benchmark scores to evaluate the generated images.
5.1	2D Examples and MNIST
We checked the convergence of pθ for the 2D examples (8 Gaussians, swissroll data, and 25 Gaus-
sians) and MNIST digit generation for the SGP-WGANs with five penalty measures. MNIST and
25 Gaussians were trained over 200K iterations, the 8 Gaussians were trained for 30K iterations, and
the Swiss Roll data were trained for 100K iterations. The anchor A for μg,αnc was set as (2, -1)
for the 2D examples and 784 gray pixels for MNIST. We only present the results obtained for the
MNIST dataset with the penalty measures comprising μmid and μg,αnc in Figure 1. The others are
presented in the Appendix.
>¾ S›7C g
q J IT 0
<?l 6 91
3 Λy — 6
£ <J 3 qQ
£ Z y q力
3 3y31
,τa∖
<γ 74 2
S 夕3 5c⅛
00306
々 3 / / q
a S q9x>
Λ I ʌe H I
7 5 7 7r
3 zσ H / 6
80 54 —
'∙7, J 3。
SJ 3S/ 7
Γ? Iy8
Figure 1: MNIST example. Images generated with μmid(left) and μg,αnc(right).
7
Under review as a conference paper at ICLR 2019
5.2	CIFAR- 1 0
DCGAN and ResNet architectures were tested on the CIFAR-10 dataset. The generators were
trained for 200K iterations. The anchor A for μg,anc during CIFAR-10 generation was set as fixed
random pixels. The WGAN, WGAN-GP, and five penalty measures were evaluated based on the
inception score and FID, as shown in Table 2, which are useful tools for scoring the quality of gen-
erated images. The images generated from μmid and μg,anc with ResNet are shown in Figure 2. The
others are presented in the Appendix.
Table 2: Benchmark score results obtained based on the CIFAR-10 dataset under DCGAN and
ResNet architectures. The higher inception score and lower FID indicate the good quality of the
generated images.
Penalty	DCGAN		ResNet	
	Inception	FID	Inception	FID
WGAN 3	5.64 ± 0.09	48.7	-	-
WGAN-GP	6.48 ± 0.10	35.0	7.82 ± 0.09	18.1
pg	6.46 ± 0.09	38.0	7.63 ± 0.10	20.9
pd	6.33 ± 0.07	38.9	7.63 ± 0.09	20.3
μGP	6.40 ± 0.08	35.4	7.60 ± 0.09	18.3
μmid	6.60 ± 0.07	33.9	7.86 ± 0.07	16.4
μg,anc	6.45 ± 0.07	33.7	7.36 ± 0.09	22.4
Figure 2: CIFAR-10 example. Images generated with μmid(left) and μg,anc(right) under the ResNet
architecture.
6	Conclusion
In this study, we proved the local stability of simple gradient penalty μ-WGAN optimization for a
general class of finite measure μ. This proof provides insight into the success of regularization with
previously proposed penalty measures. We explored previously proposed analyses based on vari-
ous gradient penalty methods. Furthermore, our theoretical approach was supported by experiments
using unintuitive penalty measures. In future research, our works can be extended to alternative
gradient descent algorithm and its related optimal hyperparameters. Stability at non-realizable equi-
librium points is one of the important topics on stability of GANs. Optimal penalty measure for
achieving the best convergence speed can be also investigated using a spectral theory, which pro-
vides the mathematical analysis on stability of GAN with a precise information on the convergence
theory.
3WGAN failed to generate images for the ResNet architecture
8
Under review as a conference paper at ICLR 2019
References
Martin Arjovsky and Leon Bottou. Towards principled methods for training generative adversarial
networks. In International Conference on Learning Representations, 2017.
Martin Arjovsky, Soumith Chintala, and Leon Bottou. Wasserstein generative adversarial networks.
In Proceedings ofthe 34th International Conference on Machine Learning, pp. 214-223, 2017.
Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair,
Aaron C. Courville, and Yoshua Bengio. Generative adversarial nets. In Advances in Neural
Information Processing Systems, pp. 2672-2680, 2014.
Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Dumoulin, and Aaron C. Courville. Im-
proved training of wasserstein gans. In Advances in Neural Information Processing Systems, pp.
5769-5779, 2017.
B. Heidergott and F. J. Vaizquez-Abad. Measure-valued differentiation for markov chains. Journal
of Optimization Theory and Applications, 136:187-209, 2008. ISSN 1573-2878. doi: 10.1007/
s10957-007-9297-7.
Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter.
Gans trained by a two time-scale update rule converge to a local nash equilibrium. In Advances
in Neural Information Processing Systems, pp. 6629-6640, 2017.
Phillip Isola, Jun-Yan Zhu, Tinghui Zhou, and Alexei A. Efros. Image-to-image translation with
conditional adversarial networks. In 2017 IEEE Conference on Computer Vision and Pattern
Recognition, CVPR 2017, Honolulu, HI, USA, July 21-26, 2017, pp. 5967-5976, 2017.
Christian Ledig, Lucas Theis, Ferenc Huszar, Jose Caballero, Andrew Cunningham, Alejandro
Acosta, Andrew P. Aitken, Alykhan Tejani, Johannes Totz, Zehan Wang, and Wenzhe Shi. Photo-
realistic single image super-resolution using a generative adversarial network. In 2017 IEEE
Conference on Computer Vision and Pattern Recognition, CVPR 2017, Honolulu, HI, USA, July
21-26, 2017, pp. 105-114, 2017.
Lars M. Mescheder, Andreas Geiger, and Sebastian Nowozin. Which training methods for gans do
actually converge? In Proceedings of the 35th International Conference on Machine Learning,
pp. 3478-3487, 2018.
Youssef Mroueh, Chun-Liang Li, Tom Sercu, Anant Raj, and Yu Cheng. Sobolev GAN. In Interna-
tional Conference on Learning Representations, 2018.
Vaishnavh Nagarajan and J. Zico Kolter. Gradient descent GAN optimization is locally stable. In
Advances in Neural Information Processing Systems, pp. 5591-5600, 2017.
Sebastian Nowozin, Botond Cseke, and Ryota Tomioka. f-gan: Training generative neural sam-
plers using variational divergence minimization. In Advances in Neural Information Processing
Systems, pp. 271-279, 2016.
Alec Radford, Luke Metz, and Soumith Chintala. Unsupervised representation learning with deep
convolutional generative adversarial networks. CoRR, abs/1511.06434, 2015. URL http://
arxiv.org/abs/1511.06434.
Scott E. Reed, Zeynep Akata, Xinchen Yan, Lajanugen Logeswaran, Bernt Schiele, and Honglak
Lee. Generative adversarial text to image synthesis. In Proceedings of the 33nd International Con-
ference on Machine Learning, ICML 2016, New York City, NY, USA, June 19-24, 2016, pp. 1060-
1069, 2016. URL http://jmlr.org/proceedings/papers/v48/reed16.html.
Kevin Roth, Aureilien Lucchi, Sebastian Nowozin, and Thomas Hofmann. Stabilizing training of
generative adversarial networks through regularization. In Advances in Neural Information Pro-
cessing Systems, pp. 2015-2025, 2017.
Tim Salimans, Ian J. Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, and Xi Chen.
Improved techniques for training gans. In Advances in Neural Information Processing Systems,
pp. 2226-2234, 2016.
9
Under review as a conference paper at ICLR 2019
CasPer Kaae S0nderby, Jose Caballero, Lucas Theis, Wenzhe Shi, and Ferenc Huszar. Amortised
MAP inference for image super-resolution. International Conference on Learning Representa-
tions, 2017.
Han Zhang, Tao Xu, and Hongsheng Li. Stackgan: Text to Photo-realistic image synthesis with
stacked generative adversarial networks. In IEEE International Conference on Computer Vision,
ICCV2017, Venice, Italy, October 22-29,2017,pp. 5908-5916, 2017.
10
Under review as a conference paper at ICLR 2019
Appendix A : Proof of Lemmas based on toy examples
ProofofLemma 1. The related dynamic system of (D(x; ψ) = ψx, δo, δθ, μψ,θ) can be written as
follows.
ψ = -θ - P VψEμψ,θ [ψ2]
θ = ψ
First, the only equilibrium point is given by (ψ*,θ*) = (0,0) from
0= -θ - 2ψM (ψ,θ) - ψ2Vψ M (ψ,θ)
0=ψ
The corresponding Jacobian matrix for the dynamic system is written as:
J
where
Z
1
-1
0
Z
ψ=0,θ=0
VψD(x; ψ) = ψ does not depend on x, so this can be rewritten as:
Z = - P Vψψ (ψ2Eμψ,θ [1]) = - P(2M (ψ,θ) + 4ψVψ M (ψ,θ) + ψ2Mψψ (ψ,θ))
2	2	ψ=0,θ=0
= -PM (0, 0)
Therefore, if M(0, 0) > 0, then the given system is locally stable because the eigenvalues of its
linearized system have negative real parts. If M(0, 0) = 0, then the stability of the system cannot
be proved by the linearization theorem. In this case, we consider the following Lyapunov function.
L(ψ(t), θ(t)) = ψ(t)2 + θ(t)2
By differentiating with t, we obtain
L = 2(ψψ0 + θθ0) = -ρψVψ (ψ2M (ψ,θ)) = -ρψ(2ψM (ψ,θ) + ψ2Vψ M (ψ,θ))
= -Pψ2(2M(ψ, θ) + ψVψM(ψ, θ)) ≤0
Clearly, L(ψ,θ) ≥ 0 and the equality holds iff ψ = θ = 0. In addition, L ≤ 0 since M(ψ,θ) ≥
0 and ψVψ M (ψ, θ) ≥ 0 from the assumption. Furthermore, it is clear that if (ψ(0), θ(0)) ∈
Bη((0, 0)), then (ψ(τ), θ(τ)) ∈ Bη((0, 0)) for all τ ≥ 0 because the Lyapunov function (square of
the distance between the origin and (ψ(τ), θ(τ))) always decreases as τ → ∞. Therefore, the given
system is stable according to the Lyapunov stability theorem.
Again, We can check that if μψ,θ is a probability measure, then the system is globally stable, as
shown by Mescheder et al. (2018). The basin of attraction is given by the whole R2 plane since
M(ψ, θ) = 1, so L = -ρψ2(2M + ψVψM) = -2ρψ2 ≤ 0 for every (ψ,θ) ∈ R2.	□
ProofofLemma 2. From the general setup of the SGP μ-WGAN optimization problem, the dynamic
system corresponding to the simple-GAN in Definition 6 can be written as follows.
1 θ2
ψ = 3 - y - 4PψEμ[x2]
θ = 2ψθ
3
If we let
干3 一
0
Eμ*[x2] = A2, then the Jacobian matrix at the equilibrium (0, ±1) is given by J
. Therefore, the given system is locally stable when A 6= 0.
□
11
Under review as a conference paper at ICLR 2019
Appendix B : Proof of Lemma related with Assumption 2
Lemma 3. Consider the Dirac-GAN SetUp and SGP μ-WGAN optimization system with a Slightly
changed discriminator function D2(x; ψ) = ψx2. The system (D2,δ0, δθ, μGP) does not converge
to (0, 0) but for any point (a, 0) with a < 0, the system has equilibrium points on the whole ψ-axis
and it violates Assumption 2.
ProofofLemma 3. For the SGP μ-WGAN optimization problem (D2, δ0, δθ, μGP), the dynamic
system can be written as follows.
ψ = -θ2 — gρψθ2
： ..
θ = 2ψθ
2ψθ = 0 and θ2(1 + 4 ρψ) = 0 implies that θ = 0, so the ψ-axis is the set of all equilibrium points.
By drawing the nullclines ψ = 0 and ψ = - 4P in the ψθ-plane, it is clear that no solution curve
converges to (b, 0) with b ≥ 0, as shown in Figure 3.	口
Figure 3: Phase portrait of the SGP μ-WGAN optimization problem (D2,δ0, δθ, μGP) with P = 8.
Along the line θ = 0, the system is stable so no updating will occur. Every solution curve that
passes the nullcline ψ = 0 has θ = 0. For the nullcline ψ = - 4P = -2, no updating on ψ will
occur and only θ will be updated. Given that the solution curves do not intersect with each other,
every solution curve is exactly one of the following, except for some trivial cases; (1) Solution curve
stays in area A. (2) Solution curve converges to (ψ,θ) = (-4p, 0) along the nullcline ψ = -4ρ.
(3) Solution curve stays in area B. (4) Solution curve starts from area C, crosses the nullcline ψ = 0
perpendicularly, and converges to (b, 0) with b < 0. Therefore, no solution curve converges to (0, 0).
12
Under review as a conference paper at ICLR 2019
Appendix C : Proof of the Main Convergence Theorem
Proof. Let us consider the Jacobian matrix J
KDD
KGD
KDG at the first equilibrium (ψ*, θ*) 4.
J = EPd [Vψψ D] - Epθ* [Vψψ D] - P Vψψ Eμ[kVχDk 2] -Vθψ Epθ [D] - P Vθψ Eμ[kVχDk 2]
_	vΨΘEpθ [D]	vΘΘEpθ [D]
First, Assumption 1 implies that Epd[VψψD] 一 Ep®* [VψψD] = 0 sincepθ → Pd as θ → θ*. From
Assumption 3, E,pθ [D(x; ψ*)] is locally zero near the equilibrium θ*, which implies that
KGG = vθθEpθ[D(X；ψ*)]	= 0
θ=θ*
We still need to evaluate VψψEμ[kVχDk2] and VθψEμ[∣∣VχDk2]. According to Assumption 6a,
finite signed measures μψ,θ and μψ,θ exist5, so they are the first and second weak derivatives of μψ,θ
with respect to the parameter ψ at (ψ*, θ*). Therefore, the expectations given above can be rewritten
as below.
I = Vψψ
SSuPP(μψ,θ)
∣∣VχDk2 dμψ,θ
/	(	)(2VTχDVψχD + 2Ko)dμψ,θ + /	(	)2(VTxDVχD)dμψ,θ + /	(	JVxDk2 dμψ,§
II
Vθψ
Ssupp(μψ,θ)
∣VxDk2 dμψ,θ
vθ(L(μψ,θ) 2(VTxDVxD)d"""'''""")
∣VxDk2 dμψ,θ)
where
K0(x； ψ) = [Pk ∂ψi∂ψj ∂xk D(x； ψ) 募 D(x； ψ)]..
ij
From Assumption 6c and the fact that the weak derivative of μψ,θ vanishes outside of supp(μψ,θ),
VxD(x; ψ*) = 0 on SUpp(μψ,θ) ⊂ V for all θ with ∣θ 一 θ*∣ < Cμ and μψ & = μψ 6 = 0 on the
outside of Supp(μψ,θ), which leads to the desired results:
/
Jsupp(μ* )
I
2(VTxD(x; ψ*)VψxD(x; ψ*))dμ*
II = 0
After cancelling the undesired terms, the Jacobian matrix at the equilibrium (ψ*, θ*) is given as:
where
Q = Eμ* [VTxDVψxD]
R = VθEpθ [VψD]
θ=θ*
4 In standard notation, Vψ g is the dim (range of g) × dim(ψ) matrix. For a real-valued function f, We
consider the first derivative as the column vector instead of the row vector. Vψ f is considered to be the
dim(ψ) × 1 matrix(column vector) of the total derivative. For the second derivative, Vψθf = (Vψ)(Vθf) is
the dim(θ) × dim(ψ) matrix. The transpose notation is used in a similar manner to the matrix.
5μψ,θ and μψ,® will be considered as row vector(1 × dim(ψ) matrix) and dim(ψ) × dim(ψ) matrix of
finite signed measures respectively. μψ,θ =∣^∂⅛μψ ,θ
∂ψd二(ψ) μψ,θ]and μψ,θ = [-
∂2
∂ψi∂ψj
∙μψ,θ] ...
13
Under review as a conference paper at ICLR 2019
From the definition of Q, it is easy to check that Q is at least positive semi-definite. It is known
that for a negative definite matrix A and full column rank matrix B, the block matrix
A
-BT
B
0
is Hurwitz, i.e., all eigenvalues of the matrix have a negative real part. Therefore, if Q is positive
definite and R is full column rank, the proof is complete. We consider the complementary case.
Suppose that Q or RTR have some zero eigenvalues. Let Q = UDΛDUDT and RTR = UGΛGUGT
with UD = [TD SD] and UG = [TG SG], where TD and TG are the eigenvectors of Q
and RT R that correspond to non-zero eigenvalues. First, we assume that TD and TG are not
empty. We can show that (ψ* + ξv, θ* + Vw) is also an equilibrium point for a sufficiently
small ξ, ν and v ∈ N (Q), w ∈ N(RTR) by using the techniques given by Nagarajan & Kolter
(2017). If the system does not update at the equilibrium point (ψ*, θ*) and its small neighborhood
(ψ* + ξv, θ* + Vw) is perturbed along N(Q) and N(RTR), then it is reasonable to project the
system orthogonal to N(Q) and N (RT R).
First, We assume that V ∈ N(Q). By Assumption 2, h(ψ* + ξv) = h(ψ*) = 0 for ∣ξ∣ < ξd, which
implies that NxD(x; ψ* + ξv) = 0 for X ∈ supp(μψ*+ξv,θ*) = supp(μ*) and ∣ξ∣ < ξd. Thus, we
obtain
Eμψ* +ξv,θ* [VTxD(x; Ψ* + ξv)NxD(x; Ψ* + ξv)] = 0
and
k	IlVxD(X; ψ*+ ξv)∣∣2 dμψ*+ξv,θ*
Ssupp(μ*)
0
By Assumption 4, Epd[VψD(x; ψ* + ξv)] 一 Ep@* [VψD(x; ψ* + ξv)] = 0 since Pd = pθ*. By
adding these equations, we obtain
ψ = Epd[VψD(x; ψ + ξv)] — Epθ*[VψD(x; ψ + ξv)]
-	P JLμψ*+ξv,θ*
-	P Z
JSupp(μψ*+ξv,θ*
=0
2VTxD(x; ψ* + ξv)VxD(x; ψ* + ξv)dμψ*+ξv,θ*
JVxD(X; ψ* + ξv)∣∣2 dμψ*+ξv,θ*
In addition,
∂
θ = ∂θ Jx D(x； Ψ + ξv)dPθ
VθT G(
Z
z； θ*)VxD(G(z; θ*); ψ* + ξv)piatent(z)dz
0.
Therefore, the point (ψ* + ξv, θ*) with ∣ξ∣ < ξd is an equilibrium point. According to Assumption
4, D(x; ψ* + ξv) is an equilibrium discriminator for ∣ξ∣ < δd, and thus D(x; ψ* + ξv) is already an
optimal discriminator for ∣ξ∣ < min(ξd, δd).
Suppose that w ∈ N(RTR). By Assumption 2, g(θ*) = g(θ* + Vw) = 0 for |v| < Vg,
and thus Epd [VψD(x; ψ*)] — Epθ*+νw [VψD(x; ψ*)] = 0 for ∣ν| < Vg. Furthermore, As-
sumption 3 gives Epθ*+νw [D(x; ψ*)] = 0 for a sufficiently close |v| < Eg, which implies that
θ = VθEpθ [D(x; ψ*)]	= 0 for |v| < Eg. Finally,
θ=θ* +νw
Lpp",O*" ) 2VTxD(X； "* )VxD(X； ψ*)dμψ*,θ*+νw + Lpp(μψ*,θ*i
)k VxD(X; ψ")∣∣2 dμψ*,θ*+νw = 0
14
Under review as a conference paper at ICLR 2019
since supp(μψ*,θ*+νw) ⊂ V and VχD(x; ψ*) = 0 on V for a sufficiently small ∣ν| < e* (AssUmP-
tion 6c). By adding these results, we obtain
,	一	__ _	,	.	,	、 r	—	-__ _	,	.	、 r
ψ = Epd [VψD(x; ψ*)] - Epθ* +νw [VψD(x; ψ*)]
-2 Lp(μψ*,θ*+νw )
-2 ZSupp(μψ*,θ*+νw )
=0
2VψχD(x; ψ*)VχD(x; ψ*)dμψ*,θ*+νw
IlVxD(X; ψ )k dμψ*,θ*+νw
Therefore, the point (ψ*, θ* + Vw) with ∣ν | < min(∈μ, Eg ,νg, δg) is an equilibrium point, which
imPlies that pθ*+νw = pd according to AssumPtion 4.
If we consider the projected system (α, β) = (TDT ψ, TGT θ), then the projected dynamic system’s
Jacobian at (TTψ*,TGθ*) is given as follows.
J0 = -ρTDT QTD	-TDT RTG =	-ρΛ(D+)	-TDTRTG
J = TGT RTTD	0	= TGT RTTD	0
Therefore, we only need to prove that TDT RTG is of full column rank. Suppose that u ∈ N(QT) =
N(Q). According to Assumption 2, h(ψ) is locally constant at ψ* along the direction u. Therefore,
for a sufficiently small scalar ξ with ∣ξ∣ <ξu,
h(ψ* + ξu) = h(ψ*) = 0
where the last equality comes from the Assumption 6. This implies that VxD(χ; ψ* + ξυ) = 0
on x ∈ supp(μ*) for a small value of ∣ξ∣ < eu. By taking directional derivative w.r.t. ψ along the
direction u, we obtain:
UTVTxD(x; ψ*) =0, x ∈ suρρ(μψ*+ξu,θ*) = supp(μ*)
and thus
UTVTxD(x; ψ*) = UTVxψD(χ; ψ*) = 0, X ∈ supp(pθ*) = supp(pd)
according to Assumption 6b (the inclusion condition that SUpp(Pd) = SUpp(Pθ* ) ⊂ supp(μ*) is
required). By calculating UTR directly, we obtain
UTR = UTɪ / VψD(x; ψ*)dpθ
∂θ X
θ=θ*
∂
UT ∂θ J Vψ D(G(z; θ); ψ )piatent(z)dz
θ=θ*
/ UTVxψD(G(z; θ*); ψ*)VθG(z; θ*)piatent(z)dz = 0
X
Thus, we obtain U ∈ N(RT), which implies that N(QT) ⊂ N(RT) and C(R) ⊂ C(Q). Now, we
can check that RTG is of full column rank since TGT RT RTG = Λ(G+) is positive definite. Therefore,
RTG w = 0 ⇒ w = 0
We note that the projection matrix on C(Q) is given by TD (TDT TD )-1TDT = TD TDT. In addition,
we know that C(RTG ) ⊂ C(R) ⊂ C(Q). Therefore,
TDTRTGw=0
⇒TD TDT RTG w = 0
⇒TD TDT w0 = 0, w0 = RTG w ∈ C (RTG )
⇒Projection of w0 onto C(Q) is zero, where w0 ∈ C(RTG ) ⊂ C(Q)
⇒w0 = RTG w = 0
⇒w = 0
15
Under review as a conference paper at ICLR 2019
which completes the proof that TDT RTG is a full column rank matrix.
Now, we only need to obtain proofs for the trivial cases where either one ofTD orTG is empty. First,
suppose that TG is empty. Similar to the analysis given above, We can find that the point (ψ*,θ)
with ∣θ - θ*∣ < min(∈μ, Eg, δg, V) is an equilibrium point, where g(θ*) = g(θ) for a sufficiently
small ∣θ - θ*∣ < ν. We conclude that pθ = Pd for ∣θ - θ*∣ < min(6μ, Eg, δg, ν). Under the generator
initialization that is sufficiently close according to θ*, we can only observe the discriminator update
ψ = - P Vψ Eμψ,θ [kVχD(x; ψ)k2]
since	Epd[D(x; ψ)]	—	Ep@[D(x;	ψ)] = 0 for any ψ and ∣θ —	θ*∣	<	min(6μ, Eg ,δg,	ν).	The
discriminator update described above is locally stable system near the equilibrium ψ = ψ* since the
Jacobian of the update on ψ is given as -ρQ and the zero eigenvalues can be ignored in a similar
manner to the previous step. Therefore, the given system is stable near the equilibrium.
Suppose that TD is empty. Given that N(QT ) ⊂ N(RT ), R = 0, then the results are similar to
those presented above, but our goal is to show that (ψ, θ) is an equilibrium point, where (ψ, θ) is
sufficiently close to the original equilibrium point. We note that (ψ*, θ) is also an equilibrium point
that satisfies the assumptions.
By Assumption 2, h(ψ) = h(ψ*) = 0 for ∣ψ - ψ*∣ < ξ, which implies that VxD(x; ψ) = 0 for
X ∈ Supp(μψ,θ*) = Supp(μ*) and ∣ψ — ψ* | < ξ. Thus, we obtain
Eμψ,θ* VTxD(x; Ψ)VxD(x; ψ)] =0
ρ [	( JNxDk2 d〃ψ,θ*dx = 0
By Assumption 4, Epd [VψD(x; ψ)] - Ep@* [VψD(x; ψ)] = 0 since pd = pθ*. In addition,
θ= ⅛ D D(x; ψ)dpθ	= V VT G(z; θ*)VxD(G(z; θ*); ψ)pιatent(z)dz = 0
∂θ X	θ=θ* Z
Therefore, the point (ψ, θ*) with ∣ψ - ψ* | < min(ξ, δd) is an equilibrium point. From Assumption
4, D(x; ψ) is an equilibrium discriminator, and thus D(x; ψ) is already an optimal discriminator for
∣ψ - ψ* | < min(ξ, δd) andpθ coincides with the data distributionpd for ∣θ - θ* | < min(Eμ, Eg, δg),
which indicates that every discriminator and generator near (ψ*, θ*) is an equilibrium point and this
completes the proof of the main theorem.	□
16
Under review as a conference paper at ICLR 2019
Appendix D : Detailed Experimental Results
Figure 4: 2D example on 8 Gaussians, swissroll, 25 Gaussians datasets. Images generated with 5
penalty measures： μGP, μmid,Pg,Pd, μg,anc.
17
Under review as a conference paper at ICLR 2019
¾⅛16 Q
TJg / I/ Otf
aqsoE
√l “ 6>
Γo GA 3 歹
q / COS I
392 3 9
-7Γ∙ 7zy
/r 5 4 0y
ʃ Q /『3
f.870，
M3N JS
£656 3
£ 5yo∕
3405q
yG754
S Z αl∙∕
6r72。
，9 0。2
> , 178
d
)p
g
p
00 3。G
々 3 / / q
a，q^v
λ I rt- M t
Z577^Q
3 & 7 4 C
80 5 4 U
HgA 3 d
6 7 S 5 ,
广？ ly8
zq (。G
「T /夕6
6。CfSP
706 0<≤J
3产宅95
J 黄, q 6
6 0 066
b O
y 77& /
5 700 O O
(d) μmid
(C) μGP with simple GP
& S"7r* g
q/ IT 0
i?IAgl
3 〃』
Sa 3 qb
IZyq 为
3 3stf3 I
。f7-J ∖
<3r 74 2
5 73 5<⅛
⑹μg.anc
Figure 5: MNIST example. Images generated with rgp, μmid,Pg,Pd, μg,anc.
18
Under review as a conference paper at ICLR 2019
(a) WGAN	(b) WGAN-GP
(c) pg
(d) pd
(e) μGP With simple GP
(f) μmid
(g) μg.anc
Figure 6:	CIFAR-10 example. Images generated With WGAN, WGAN-GP,
μGP, μmid,Pg,Pd, μg,anc under the DCGAN architecture.
19
Under review as a conference paper at ICLR 2019
(a) WGAN	(b) WGAN-GP
(c) pg
(d) pd
(e) μGP With simple GP
⑴ μmid
(g) μg.anc
Figure 7:	CIFAR-10 example. Images generated With WGAN, WGAN-GP,
μGP, μmid,Pg,Pd, μg,anc under the ResNet architecture.
20