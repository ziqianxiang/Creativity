Under review as a conference paper at ICLR 2019
Robust Determinantal Generative Classifier
for Noisy Labels and Adversarial Attacks
Anonymous authors
Paper under double-blind review
Ab stract
Large-scale datasets may contain significant proportions of noisy (incorrect) class
labels, and it is well-known that modern deep neural networks poorly generalize
from such noisy training datasets. In this paper, we propose a novel inference
method, Deep Determinantal Generative Classifier (DDGC), which can obtain a
more robust decision boundary under any softmax neural classifier pre-trained on
noisy datasets. Our main idea is inducing a generative classifier on top of hidden
feature spaces of the discriminative deep model. By estimating the parameters of
generative classifier using the minimum covariance determinant estimator, we sig-
nificantly improve the classification accuracy, with neither re-training of the deep
model nor changing its architectures. In particular, we show that DDGC not only
generalizes well from noisy labels, but also is robust against adversarial perturba-
tions due to its large margin property. Finally, we propose the ensemble version of
DDGC to improve its performance, by investigating the layer-wise characteristics
of generative classifier. Our extensive experimental results demonstrate the su-
periority of DDGC given different learning models optimized by various training
techniques to handle noisy labels or adversarial samples. For instance, on CIFAR-
10 dataset containing 45% noisy training labels, we improve the test accuracy of a
deep model optimized by the state-of-the-art noise-handling training method from
33.34% to 43.02%.
1	Introduction
Deep neural networks (DNNs) are known to generalize well when they are trained on large-scale
datasets with clean label annotations. For example, DNNs have achieved state-of-the-art perfor-
mance on many classification tasks, e.g., speech recognition (Amodei et al., 2016), object detection
(Girshick, 2015) and image classification (He et al., 2016). However, as the scale of the training
dataset increases, it becomes infeasible to obtain all class labels from domain experts. A common
practice is collecting the class labels from data mining on social media (Mahajan et al., 2018) and
web data (Krause et al., 2016). However, they may contain missing/noisy (incorrect) labels, and
recent studies have shown that modern deep architectures may generalize poorly from the noisy
datasets (Zhang et al., 2017; Arpit et al., 2017). For example, in Figure 1(a), the test set accu-
racy (black line) of DenseNet-100 model (Huang & Liu, 2017) trained on the CIFAR-10 dataset
(Krizhevsky & Hinton, 2009) significantly decreases as the noise fraction increases.
To overcome the poor generalization issue of DNNs against noisy labels, many training strategies
have been investigated in the literature. Reed et al. (2014) proposed a bootstrapping method which
trains deep models with new labels generated by a convex combination of the raw (noisy) labels
and their predictions, and Ma et al. (2018b) improved the bootstrapping method by utilizing the
dimensionality of subspaces during training. Patrini et al. (2017) modified the loss and posterior
distribution to eliminate the influence of noisy labels, and Hendrycks et al. (2018) improved such a
loss correction method by utilizing the information from data with true class labels. Goldberger &
Ben-Reuven (2017) added an additional softmax layer to model a noise transition matrix. Finally,
training DNNs on selected samples also has been studied (Jiang et al., 2018; Ren et al., 2018; Malach
& Shalev-Shwartz, 2017; Han et al., 2018). However, adopting such training methods might incur
expensive back-and-forth costs, e.g., additional time and hyperparameter tuning. This motivates our
approach of developing a more plausible inference method which can be applied to any pre-trained
1
Under review as a conference paper at ICLR 2019
♦
Samples with clean labels
Samples with noisy labels
(a) Test set accuracy comparison (b) Features on penultimate layer (c) Features on penultimate layer
by varying noise fraction
from test samples by t-SNE
from training samples by t-SNE
Figure 1: Experimental results under DenseNet-100 model and CIFAR-10 dataset. (a) Test accuracy
comparison when the labels of a given proportion of training samples are flipped to other labels
uniformly at random. Visualization of features on the penultimate layer using t-SNE from (b) test
samples (same colors indicate same classes) and (c) training samples when the noise fraction is 20%.
deep model. Nevertheless, our direction is complementary to the prior works, where one can also
combine them for even better performance (see Table 3 and 4 in Section 3).
Contributions. It has been observed that DNNs can learn meaningful feature patterns shared by
multiple training examples even for datasets with noisy labels (Arpit et al., 2017). We also found
that an induced generative classifier (Ng & Jordan, 2002) under linear discriminant analysis (LDA)
assumption (with naive estimations on sample mean and covariance) built upon the hidden feature
space can outperform the softmax classifier (orange line in Figure 1(a)). In Figure 1(b), the hid-
den features from test samples projected in a 2-dimensional space using t-SNE (Maaten & Hinton,
2008) are illustrated. Here, one can observe that all ten classes are well-separated in the embedding
space, even though the model is trained under a noisy dataset. More importantly, Figure 1(c) plot-
ting noisy training samples implies that outliers induce the class-wise multi-modal distributions in
the feature space. Therefore, an LDA-like generative classifier assuming the class-wise unimodal
distribution might be more robust, as a discriminative classifier is easier to be overfitted by outliers.
This motivates our goal to induce a generative classifier on the pre-trained hidden features of DNNs.
To this end, we propose the so-called deep determinantal generative classifier (DDGC), based on
the minimum covariance determinant (MCD) (Rousseeuw, 1984; Rousseeuw & Driessen, 1999) es-
timation on its parameters. While a naive sample estimator can be highly influenced by outliers,
MCD estimator can improve the robustness by removing them. Note that MCD is known to have a
near-optimal breakdown point (Hampel, 1971) of almost 50% in most situations, i.e., the number of
outliers should be larger than that of normal samples to fool it. We further provide a new theoretical
support on the larger margin property of DDGC such that not only does it generalize well from noisy
labels (Durrant & Kaban, 2010), but also improves the robustness against adversarial perturbations
(Pang et al., 2018). In addition, we observe that DNNs tend to have similar hidden features, regard-
less of whether they are trained with clean or noisy labels at early layers (Morcos et al., 2018), and
DDGC built from low-level features can be often more effective. Under the observation, we finally
propose an ensemble version of DDGC to incorporate all effects of low and high layers.
We demonstrate the effectiveness of DDGC using modern neural architectures, such as DenseNet
(Huang & Liu, 2017) and ResNet (He et al., 2016) trained for image classification tasks including
CIFAR (Krizhevsky & Hinton, 2009) and SVHN (Netzer et al., 2011). First, our methods (green
and blue lines in Figure 1(a)) significantly outperform the softmax classifier, although they use
the same feature representations trained by the noisy dataset. For example, we improve the test
accuracy of DenseNet on CIFAR-10 datasets with 60% noisy labels from 53.34% to 74.72%. We
also demonstrate that DDGC can be used to further improve various prior training methods (Reed
et al., 2014; Patrini et al., 2017; Ma et al., 2018b; Han et al., 2018; Jiang et al., 2018; Malach &
Shalev-Shwartz, 2017) which are specialized to handle the noisy environment. Finally, DDGC is
shown to be robust against various adversarial attacks (Goodfellow et al., 2015; Moosavi Dezfooli
et al., 2016; Carlini & Wagner, 2017).
2
Under review as a conference paper at ICLR 2019
2	Robust inference via generative clas s ifier
In this section, we propose a novel inference method which obtains a robust posterior distribution
from any softmax neural classifier pre-trained on datasets with noisy labels. Our idea is inducing
the generative classifier using fixed features from any pre-trained model. We show the advantages
of our method in terms of high breakdown points (Hampel, 1971), generalization error (Durrant &
Kaban, 2010) and adversarial robustness (Pang et al., 2018). We also investigate the layer-wise char-
acteristics of generative classifiers, and introduce an ensemble of them to improve its performance.
We emphasize again that we study inference methods, not requiring any modification on pre-trained
deep models. Hence, the proposed methods are easily applicable on top of any pre-trained modern
neural classifiers.
2.1	Generative classifier and MCD estimator
Let X be an input and y ∈ {1, ∙∙∙ ,C} be its class label. Without loss of generality, suppose that a
pre-trained softmax neural classifier is given: P (y = c|x) = P eXP(wW,；)+))), where Wc and b
are the weight and the bias of the softmax classifier for class c, and f (∙) ∈ Rd denotes the output of
the penultimate layer of DNNs. Then, without any modification on the pre-trained softmax neural
classifier, we induce a generative classifier by assuming the class-conditional distribution follows
the multivariate Gaussian distribution. In particular, we define C Gaussian distributions with a tied
covariance Σ, i.e., linear discriminant analysis (LDA) (Fisher, 1936), and a Bernoulli distribution
for the class prior: P (f (x)|y = C)= N (f (x)∖μc, ∑), P (y = C) = βc, where μc is the mean
of multivariate Gaussian distribution and βc is the normalized prior for class c. We provide an
analytic justification on the LDA (i.e., tied covariance) assumption in Appendix A. Then, based on
the Bayesian rule, we induce a new posterior different from the softmax one as follows:
P (y = C∖f (X))
P (y = C) P (f(χ)∖y = C)
P P(y = c0) P(f(x)∖y = c0)
exp (μ>∑-1f (χ) - 21 μ>∑-1μc + log βc)
P exp (μ>∑-1f (x) - M∑-1 μc0 + log βc0).
c0
To estimate the parameters of the generative classifier, one can compute the sample class mean and
covariance of training samples XN	= {(x1, y1), . . . , (xN,yN)}:
.	X f (Xi)	V =JhCk，ς =	_ X X (f (Xi)二 μc) (f (Xi)二 μc)>	β __ Nc	(1) ^ N N	N	,	βc = Ν,	() c i:yi=c
where Nc is the number of training samples labeled to be class C. We remark that inducing a
generative classifier (e.g., a mixture of Gaussian) on pre-trained deep models was studied for various
purposes, e.g., speech recognition (Hermansky et al., 2000) and novelty detection (Lee et al., 2018).
However, the setting of noisy training labels was not investigated under existing approaches on this
line. To handle this, we design a more advanced generative classifier as stated in below.
One can expect that the naive sample estimator (1) can be highly influenced by outliers (i.e., training
samples with noisy labels). In order to improve the robustness, we propose the so-called deep
determinantal generative classifier (DDGC), which utilizes the minimum covariance determinant
(MCD) estimator (Rousseeuw & Driessen, 1999) to estimate its parameters. For each class C, the
main idea of MCD is finding a subset XKc for which the determinant of the corresponding sample
covariance is minimized:
min det
XKc ⊂XNc
subject to ∖XKc ∖ = Kc,
(2)
where XNc is the set of training samples labeled to be class C, Σbc is the sample covariance of XKc
and 0 < Kc < Nc is a hyperparameter. Then, only using the samples in c XKc , it estimates the
parameters, i.e., μc, Σ, βc, of the generative classifier, by following (1). Such a new estimator can be
more robust by removing the outliers which might be widely scattered in datasets. The robustness
of MCD estimator has been justified in the literature: it is known to have near-optimal breakdown
points (Hampel, 1971), i.e., the smallest fraction of data points that need to be replaced by arbitrary
values (i.e., outliers) to fool the estimator completely. Formally, denote YM as a set obtained by
replacing M data points of set Y by some arbitrary values. Then, for a multivariate mean estimator
3
Under review as a conference paper at ICLR 2019
μ = μ(Y) from Y, the breakdown point is defined as follows (See Appendix A for more detailed
explanations including the breakdown point of covariance estimator):
ε*(μ, Y) = 71 min [m ∈{1,…，|Y|} ： Sup kμ(Y) - m(Ym)k = ∞∖ .
|Y |	YM
While the breakdown point of the naive sample estimator is 0%, the MCD estimator for
the generative classifier under LDA assumption is known to attain its breakdown value of
mine b(Nc-dd+1”2c ≈ 50% (LoPUhaa et al., 1991). Inspired by this fact, We choose the default
value of Kc in (2) by b(Nc + d + 1)/2c.
We also establish the following theoretical support that the MCD-based generative classifier, i.e.,
DDGC, can have smaller errors on parameter estimations and produce a larger margin, compared to
the naive sample estimator, under some assumptions for its analytic tractability.
Theorem 1. Assume the followings:
(A1) The distribution of hidden features is P (f (x)∣y = C)= N (f (x)∣μc,σ2l) (i.e., the Con-
ditional Gaussian distribution) and that of outliers is an arbitrary distribution with mean
μout and covariance matrix。2皿1, where I ∈ Rd×d is the identity matrix.
(A2) μout = 0, and = Pc μcμT is a diagonal matrix.
(A3) All classes have the same number ofsamples (i.e., Nc = N), the same fraction δ0ut < 1 of
outliers, and the samplefraction δmcd = KKc < 1 ofsamples selected by MCD estimator.
(A4) The outliers are widely scattered such that σ2 < σo2ut.
(A5) The number ofoutliers is not too large such that δ°ut < 1 一 δmcd and δmcd > N-.
Let b, Σ and μ, Σ be the outputs ofthe MCD and sample estimators, respectively. Then, μ, μ, Σ, Σ
converge almost surely to their expectation as N → ∞, and it holds that
.- ^. . - ^.
B(bc,μco, ∑, ∑) →. lim B(bc,bco, ∑, ∑) ≤ I
B(μc,μco, ∑, ∑)	N→m∞B(μc,μco, ∑, ∑)一，
kμc 一 bckι → lim kμc 一 bckι = 0, kμc 一 μckι → lim kμc 一 μckι = δoutkμckι (4)
N→∞	N→∞
依- bco)T ς T 依- μco) →	(良一 bco)T ς-1(良一 μc,) = ι ≥ I
(μc ― μco)τ∑-1(μc - μco)	N→∞ (μc — μco)τ∑-1(μc — μco)	(1 ― δout)2 一.
for all c, C, where B(bc,bco, Σ, Σ) := exp I —1
[(bc-bco)T ∑-1WcfcO)]2
-	'_ * ~ * ~~*	~
(bc-μ°o )t ς-1ςς-1(bc-μc0)
The proof of the above theorem is given in Appendix F, where it is built upon the fact that the
determinants can be expressed as the d-th degree polynomial of outlier ratio. We note that one might
enforce the assumptions of the diagonal covariance matrices in A1 and the zero-mean/uncorrelated
properties of class mean in A2 to hold under an affine translation of hidden features. In addition,
the assumption in A5 holds when Nc is large enough. Nevertheless, we think most assumptions of
Theorem 1 are not necessary to claim the superiority of DDGC (they are rather from a limitation of
our proof techniques) and it is an interesting future direction to explore to relax them.
First, (5) implies that the MCD estimator induces a larger margin and improves the robustness
to adversarial attacks, since Pang et al. (2018) showed that the margin of a generative classifier
corresponds to the Mahalanobis distance between class-conditional distributions and the optimal
robustness to adversarial samples is achieved by the maximum margin. More importantly, (3) and
(4) together imply that a MCD-based classifier can generalize better since the generalization error
of a generative classifier is known to be bounded as follows (Durrant & Kaban, 2010):
Px (y* = arg max Pμc∑ (y∣x)	≤XXB(bco,bc, ∑, ς ) + D X |3一 bckι,
c c0 6=c	c
for some constant D > 0.
4
Under review as a conference paper at ICLR 2019
Algorithm 1 (Rousseeuw & Driessen, 1999) Approximating MCD for a single Gaussian.
Input: XNC = {xi : i = 1, ∙∙∙ ,Nc} and the maximum number of iterations Imax.
Uniformly sample initial subset XKC ⊂ XNC, where |XKC | = b(Nc + d + 1)/2c.
Compute μ0 = _ P	f (x),	ΣC	=	∣χK∣ P	(f (x) -	μc)	(f (x)	- μc)τ .
KC x∈XKC	KC x∈XKC
for i = 1 to Imax do
Compute the Mahalanobis distance: α(x) = (f (x)-限)> Σ-1 (f (x)-几),∀x ∈ XNC.
Update XKC such that it includes b(Nc + d + 1)/2c samples with smallest distance α(x).
Compute sample means and covariance, i.e., μc, ∑c, using new subset XKC.
Exit the loop if the determinant of covariance matrix is not decreasing anymore.
end for
Return μc and Σ C
Ooooo
0864
)%( ycarucca tes tseT
0-
2	4	6	8	10	12	14
Index of basic block
A-Unifo
。Unifo
rm (40
rm (60%)
Clean
Uniform (20%)
Ooooo
08642
)%( ycarucca tes tseT
(％)ffejrme"ssal
(a) Generalization of generative (b) Robustness of generative (C) Generative classifiers under
classifiers from noisy labels classifiers to adversarial attacks various assumptions
Figure 2: Experimental results under ResNet-34 model and CIFAR-10 dataset. (a) Test accuracy of
generative classifiers computed at different basic blocks. (b) Test accuracy on various adversarial
attacks when the model is trained on clean dataset. (c) Test accuracy of generative classifiers from
penultimate features under various assumptions: identity covariance and tied covariance (LDA).
2.2	Approximation algorithm for MCD
Even though the MCD estimator has several advantages, the optimization (2) is computationally
intractable (i.e., NP-hard) to solve (Bernholt, 2006). To handle this issue, we aim for computing its
approximate solution, following a similar idea to that by (Hubert & Van Driessen, 2004). We design
two step scheme as follows: (a) obtain the mean and covariance, i.e., μc, ∑c, using Algorithm 1 for
b
each class c, and (b) compute the tied covariance by Σ = ɪp K C. In other words, We apply the
MCD estimator for each class, and combine the individual covcariances into a single one due to the
tied covariance assumption of LDA. Even though finding the optimal solution of MCD estimator
under a single Gaussian distribution is still intractable, Algorithm 1 can produce a local optimal so-
lution since it monotonically decreases the determinant under any random initial subset (Rousseeuw
& Driessen, 1999). We choose Imax = 2 in our experiments as the additional iterations would not
improve the results significantly.
2.3	Ensemble of generative classifiers
To further improve the performance of our method, we consider the ensemble of generative classi-
fiers not only from the penultimate features but also from other low-level features in DNNs. For-
mally, given training data, We extract '-th hidden features of DNNs, denoted by f'(x) ∈ Rd', and
compute the corresponding parameters of a generative classifier (i.e., μ',c and Σ') using the (ap-
proximated version of) MCD estimator. Then, the final posterior distribution is obtained by the sum
of all posterior distributions of generative classifiers:
L	L	exP (μ>∕-1f'(X)- 0即>》-1μ',c + log Ge)
E ɑ` P(y = c∣f'(x)) = E a`----------^―-------------------——--------------4y,
`	`	pco eχp (μ>co ∑ - 1f'(χ) - 0.5b>co ∑ ` 1μb',co + log 蜃)
5
Under review as a conference paper at ICLR 2019
where ɑ` is an ensemble weight at '-th layer. In our experiments, We choose the weight of each
layer by optimizing negative log-likelihood (NLL) loss over the validation set. One can expect that
this natural scheme can bring an extra gain in improving the performance due to ensemble effects.
To confirm that the proposed ensemble approach is indeed effective, we measure the classification
accuracy of the generative classifier from different basic blocks of ResNet-34 (He et al., 2016)
trained on CIFAR-10 dataset (Krizhevsky & Hinton, 2009) with various noise fractions, where the
corresponding results on DenseNet models (Huang & Liu, 2017) can be found in Appendix C. For
computational efficiency, the dimensions of the intermediate features are reduced using average
pooling (see Section 3 for more details). First, we found that the performances of the generative
classifiers from low-level features are more stable, while the accuracy of generative classifier from
penultimate layer significantly decreases as the noisy fraction increases as shown in Figure 2(a). We
expect that this is because the dimension (i.e., number of channels) of low-level features is usually
smaller than that of high-level features. Since the breakdown point of MCD is inversely proportional
to the feature dimension, the generative classifiers from low-level features can be more robust. This
also coincides with the prior observation in the literature (Morcos et al., 2018) that DNNs tend to
have similar hidden features at early layers, regardless of whether they train clean or noisy labels.
More importantly, we found that generative classifiers from low-level features are more robust to
strong adversarial attacks like CW (Carlini & Wagner, 2017), as shown in Figure 2(b). Therefore,
we utilize the low-level generative classifiers as well to improve the generalization from noisy labels
and robustness to adversarial attacks simultaneously.
3	Experimental results
In this section, we demonstrate the effectiveness of the proposed method using deep convolutional
neural networks including DenseNet (Huang & Liu, 2017) and ResNet (He et al., 2016) on various
vision datasets: CIFAR (Krizhevsky & Hinton, 2009) and SVHN (Netzer et al., 2011). Due to the
space limit, we provide the more detailed experimental setups and results in Appendix B.
3.1	Generalization from noisy labels
Setup. First, we evaluate the effectiveness of DDGC using deep models trained on datasets with
noisy labels. We train DenseNet-100 and ResNet-34 for classifying CIFAR-10, CIFAR-100 and
SVHN datasets. Similar to (Ma et al., 2018b; Han et al., 2018), we consider two types of noisy
labels: corrupting a label to other class uniformly at random (uniform) and corrupting a label only
to a specific class (flip). For ensembles of generative classifiers, we induce the generative classifiers
from every end of basic block of DenseNet (or ResNet), where ensemble weights of each layer are
tuned on a separate validation set, which consists of 500 images (i.e., only ≤ 1% of the number of
training samples) with clean labels.1 Similar to (Lee et al., 2018), the size of feature maps on each
convolutional layers is reduced by average pooling for computational efficiency: F × H × W →
F × 1, where F is the number of channels and H × W is the spatial dimension.
Verification of contributions from each technique. We first evaluate the performance of genera-
tive classifiers with various assumptions: identity covariance (Euclidean) and tied covariance (LDA).
In the case of identity covariance, we also apply a robust estimator called the least trimmed square
(LTS) estimator (Rousseeuw, 1984) which finds a K-subset with smallest error and computes the
sample mean from it, i.e., min, PK=I(IlXi-bk2). AS shown in Figure 2(c), the generative classifiers
with LDA assumption (blue and purple bars) generalize better than the generative classifiers with
identity covariance (orange and green bars) well from noisy labels. Table 1 validates the contribu-
tions of the proposed techniques by incrementally applying our techniques to see the improvement
from adding each component one by one. One can note that the generative classifier on features
extracted from the penultimate layer outperforms the softmax classifier without the MCD estimator
or ensemble method, while it still provides a comparable classification accuracy when the model
is trained on clean dataset (i.e., noise = 0%). On top of that, by utilizing the MCD estimator, the
classification accuracy is further improved compared to that employs only the naive sample estima-
tor. This implies that the proposed method can improve the performance without any information
1For fair comparisons, one might also suggest fine-tuning the softmax classifier (with fixed features) using
the validation data to improve the performance. However, the 1% data is often not enough for the purpose as
the number of parameters of softmax classifier is too large. We indeed report the performance of the fine-tuned
softmax classifier on Table 9 in Appendix D.
6
Under review as a conference paper at ICLR 2019
Model	Inference method	Ensemble	Noise = 0%	20%	40%	60%
	Softmax	-	94:42	80.24	68.61	53.34
DenseNet	Generative + sample	- X	94:31 93.73	85.08 87.23	74.72 80.01	59.49 69.17
	Generative + MCD (DDGC)	-	94:37	85.96	78.34	66.16
		X	93.49	87.25	81.04	74.72
	Softmax	-	95.01	79.28	61.85	35.02
	Generative + sample	-	94:98	81.61	64.60	40.63
ResNet		X	94.98	87.23	78.40	61.94
	Generative + MCD (DDGC)	-	94:73	83.04	68.04	42.74
		X	94.32	87.25	80.01	71.06
Table 1: Effects of an ensemble method. We use the CIFAR-10 dataset with various uniform noise
fractions. All values are percentages and the best results are highlighted in bold if the gain is bigger
than 1%.
Noise type (%)	ResNet			DenseNet		
	CIFAR-10	CIFAR-100 Softmax / DDGC	SVHN	CIFAR-10	CIFAR-100 Softmax / DDGC	SVHN
Clean	95.01 /94.32	77.51 / 76.55	95.96/96.09	94.42/93.49	76.41 / 73.65	96.59 / 96.18
Uniform (20%)	79.28 / 87.25	60.92 / 66.08	83.52/ 91.67	80.24/ 87.25	57.63 / 62.19	86.92 / 89.50
Uniform (40%)	61.85/ 80.01	44.08 / 59.72	72.89 / 87.16	68.61 / 81.04	45.08 / 53.98	81.91 / 85.71
Uniform (60%)	35.02/ 71.06	23.43 / 48.85	61.23/ 80.52	53.34/ 74.72	35.83 / 45.27	71.18 / 77.67
Flip (20%)	79.83/ 87.60	64.64 / 71.42	85.49/ 93.00	78.52/ 88.88	65.41 / 68.24	95.04 / 94.86
Flip (40%)	58.21 / 77.23	46.32 / 63.87	65.88 / 87.96	60.15/ 85.91	47.91 / 64.73	88.83 / 93.57
Table 2: Test accuracy (%) of different models trained on various datasets. We use the ensemble
version of DDGC, and the best results are highlighted in bold if the gain is bigger than 1%.
of clean labels. In addition, the ensemble method significantly improves the classification accuracy.
Finally, Table 2 reports the classification accuracy for all networks and datasets, where the proposed
method significantly outperforms the softmax classifier for all tested cases.
Compatibility and comparison with the state-of-art training methods. We compare the perfor-
mance of the standard softmax classifier and DDGC when they are combined with other various
training methods for noisy environments, where more detailed explanations on them are given in
Appendix B. We follow two experimental setups of Ma et al. (2018b)2 and Han et al. (2018)3. The
first setup considers the following methods training a single network: Hard/soft bootstrapping (Reed
et al., 2014), forward/backward (Patrini et al., 2017), and D2L (Ma et al., 2018b). It uses ResNet-44
and only considers the uniform noise. The second setup considers the following methods training
multiple networks, i.e., an ensemble of classifiers or a meta-learning model: Decoupling (Malach
& Shalev-Shwartz, 2017), MentorNet (Jiang et al., 2018) and Co-teaching (Han et al., 2018). It
uses a 9-layer CNN architecture, and considers the CIFAR-10 and CIFAR-100 datasets with uni-
form and flip noise types. Table 3 and 4 report the classification accuracy of softmax classifier and
the ensemble version of DDGC, for the first and secon setups, respectively. They show that DDGC
consistently outperforms the softmax inference under various training methods and noise types.4
3.2	Robustness against adversarial attacks
Setup. We also evaluate if the proposed method can improve the robustness on adversarial attacks
(Szegedy et al., 2014). It is well-known that the adversarial (visually imperceptible) perturbation to
clean inputs can induce the DNNs to make incorrect predictions at test time. This undesirable prop-
erty of DNNs has raised major security concerns. To verify that DDGC can improve the robustness
to adversarial attacks, we train DenseNet-100 and ResNet-34 for classifying CIFAR-10, CIFAR-100
and SVHN datasets, and generate the adversarial samples using FGSM (Goodfellow et al., 2015),
DeepFool (Moosavi Dezfooli et al., 2016) and CW (Carlini & Wagner, 2017) attacks, where the
2We used a reference implementation of Ma et al. (2018b): https://github.com/xingjunm/
dimensionality-driven-learning.
3We used a reference implementation: https://github.com/bhanML/Co-teaching
4In the second setup, we only apply DDGC to a model pre-trained by Co-teaching because it outperforms
other training methods.
7
Under review as a conference paper at ICLR 2019
Γ~)AtAqfIt aase	Training	Clean	Uniform (20%)	Uniform (40%)	Uniform (60%)
	method		Softmax/DDGC				
	Cross-entropy	94.34 / 94.29	81.95/ 86.80	63.84 / 78.75	62.45 / 69.06
	Bootstrap (hard)	94.56/94.49	82.90 / 87.26	75.97 / 81.81	72.91 / 75.61
f-'TT7Λ P 1 ∩	Bootstrap (soft)	94.46/94.31	80.29 / 85.20	65.22 / 77.86	58.55 / 69.71
CIFAR-10	Forward	94.53 / 94.39	85.80 / 87.66	77.95 / 81.24	72.56 / 74.92
	Backward	94.39 / 94.45	77.44 / 81.38	62.83 / 72.76	56.64 / 65.95
	D2L	94.55/94.38	88.89/89.00	86.68 / 87.03	76.83 / 78.08
	Cross-entropy	76.31 /75.87	61.11 / 66.33	45.08 / 58.68	34.97 / 44.96
	Bootstrap (hard)	75.65/75.49	61.61 / 65.14	51.27 / 57.61	39.04 / 47.24
Γ,T^RAP 1 ∩∩	Bootstrap (soft)	76.40/75.88	60.28 / 65.54	47.66 / 57.97	34.68 / 44.84
CIFAR-100	Forward	75.84/75.43	63.73 / 67.46	53.03 / 60.52	41.28 / 47.88
	Backward	76.75/76.28	56.24 / 62.13	37.70 / 51.82	23.55 / 39.16
	D2L	76.13/75.57	71.90/72.07	63.61 / 64.67	9.51 / 39.42
	Cross-entropy	96.38/96.15	83.45/ 91.46	60.86 / 83.40	38.29 / 68.71
	Bootstrap (hard)	96.40/96.26	83.43 / 92.24	74.25 / 88.04	66.51 / 82.03
Q VWNT	Bootstrap (soft)	96.51 /96.09	86.43 / 91.25	58.22 / 83.90	44.52 / 73.11
SVHN	Forward	96.36/96.24	88.21 / 92.47	80.35 / 88.55	82.16 / 87.56
	Backward	96.43/96.31	87.00 / 87.31	72.02 / 78.65	50.54 / 71.06
	D2L	96.49/96.37	92.31 / 93.58	94.46 / 94.68	92.87 / 93.25
Table 3: Test accuracy (%) of ResNet trained on various training methods which utilize a single
classifier. We use the ensemble version of DDGC, and the best results are highlighted in bold if the
gain is bigger than 1%.
Dataset	Noise type (%)	Cross-entropy	Decoupling	MentorNet	Co-teaching	Co-teaching + DDGC
	FliP (45%)	49.50	48.80	58.14	71.17	70.50
CIFAR-10	Uniform (50%)	48.87	51.49	71.10	74.12	76.26
	Uniform (20%)	76.25	80.44	80.76	82.13	84.49
	Flip (45%)	31.99	26.05	31.60	33.34	43.02
CIFAR-100	Uniform (50%)	25.21	25.80	39.00	41.49	44.81
	Uniform (20%)	47.55	44.52	52.13	54.27	57.74
Table 4: Test accuracy (%) of 9-layer CNN trained on various training methods which utilize an
ensemble of classifiers or meta-learning model. We use the ensemble version of DDGC and best
results are highlighted in bold if the gain is bigger than 1%.
detailed explanations can be found in Appendix B. We consider the two types of adversarial attacks:
generating the adversarial samples using a network, and then measuring their accuracy using the
same (white-box) or another network (black-box). For all experiments, the adversarial samples are
generated by targeting a softmax classifier or our generative classifier (see Appendix B for more
details).
Robustness against adversarial attacks. Table 5 reports the classification accuracy of ResNet-34
on black-box adversarial attacks, and more results on white-box adversarial attacks and DenseNet-
100 can be found in Appendix E. It shows that DDGC significantly improves the robustness against
adversarial attacks when the training datasets contain noisy labels. We found that this is because the
generative classifiers from low-level features are not utilized well, i.e., the trained weights (using
validation) would be nearly zero for lower layers, when a training dataset only contains clean labels.
Namely, the generative classifiers from low-level features are very robust (see Figure 2(b)), since
the adversarial samples are generated in a way that mainly fools the upper layers of DNNs, i.e.,
thus both clean and adversarial samples produce similar hidden features at lower layers. We also
apply DDGC to the “robust” learning models optimized by adversarial training methods (Goodfel-
low et al., 2015): generating FGSM samples and optimize the cross-entropy loss by treating them
as additional training examples. Table 6 shows that DDGC further improves the robustness of deep
models optimized by adversarial training.
8
Under review as a conference paper at ICLR 2019
aase	Target	Adversarial	Clean	Uniform (20%)	Uniform (40%)	Uniform (60%)
		attacks	SoftmaX / DDGC			
		FGSM	73.67/73.19	63.19 / 73.24	47.80 / 68.68	30.34 / 58.42
	Softmax	DeepFool	77.88/77.74	75.27 / 84.39	56.99 / 78.35	36.47 / 70.91
CIFAR-10		CW	36.36/36.86	65.45 / 76.26	50.68 / 73.59	33.08 / 67.81
		FGSM	94.62 / 94.38	75.11 / 82.78	48.06 / 68.86	28.84 / 57.40
	DDGC	DeepFool	70.23/70.07	73.93 / 83.35	56.23 / 77.66	36.46 / 70.75
		CW	13.00/12.50	28.40 / 28.40	17.20 / 19.40	12.70 / 10.70
		FGSM	50.20 /46.97	36.16 / 41.95	26.34 / 39.82	19.19 / 40.68
	Softmax	DeepFool	46.63 /42.44	47.13 / 53.71	36.18 / 51.98	23.10 / 45.65
CIFAR-100		CW	35.66 /33.50	38.57 / 45.63	32.21 / 47.61	22.52 / 44.74
		FGSM	73.07 /70.63	45.36/ 49.39	28.97 / 41.31	19.63 / 39.55
	DDGC	DeepFool	44.86 /39.40	42.59 / 49.63	32.59 / 48.27	21.90 / 44.72
		CW	26.81 /24.13	15.54 / 17.04	10.59 / 17.95	8.81 / 22.90
		FGSM	61.94/62.21	56.26 / 60.25	39.93 / 52.20	31.93 / 42.76
	Softmax	DeepFool	78.01 /78.54	83.55 / 89.51	69.46 / 85.05	61.15 / 79.35
SVHN		CW	57.27/58.11	76.21 / 83.85	60.64 / 79.56	51.73 / 73.83
		FGSM	96.13/96.12	51.40/ 54.54	35.82 / 47.31	29.29 / 40.21
	DDGC	DeepFool	69.90/70.00	81.40 / 88.63	67.90 / 83.68	59.36 / 77.81
		CW	36.10/36.80	46.30 / 51.20	34.30 / 36.70	30.00 / 33.80
Table 5: Test accuracy (%) of ResNet on black-box adversarial attacks. We use the ensemble version
of DDGC, and the best results are highlighted in bold if the gain is bigger than 1%.
aase	Target	Adversarial	Clean	Uniform (20%)	Uniform (40%)	Uniform (60%)
		attacks	Softmax / DDGC			
		FGSM	91.63/91.59	79.01 / 84.54	62.47 / 78.45	37.71 / 66.96
	SoftmaX	DeepFool	93.72/93.34	80.95 / 85.83	63.79 / 79.29	38.23 / 68.04
CIFAR-10		CW	90.00/89.71	79.38 / 84.70	62.92 / 78.49	37.78 / 67.51
		FGSM	94.81 /94.55	80.82 / 86.08	62.22 / 78.62	37.22 / 66.81
	DDGC	DeepFool	93.06/92.65	80.66 / 85.64	63.72 / 79.23	38.32 / 68.01
		CW	86.10/85.50	71.80 / 79.00	53.40 / 65.30	30.70 / 50.30
		FGSM	63.67/62.74	51.39 / 58.88	35.78 / 52.85	22.13 / 44.86
	SoftmaX	DeepFool	60.92 /59.29	53.34 / 60.94	37.10 / 54.90	23.47 / 46.35
CIFAR-100		CW	59.74/58.88	51.67/ 59.14	36.27 / 54.00	23.24 / 46.21
		FGSM	70.17 /69.08	54.25 / 61.23	36.81 / 52.98	21.97 / 44.22
	DDGC	DeepFool	59.81 /57.90	52.72 / 61.27	36.90 / 54.86	23.81 / 46.45
		CW	57.00 /55.50	39.27 / 47.31	25.22 / 41.72	15.27 / 35.50
		FGSM	68.00/68.34	68.08 / 72.33	51.56 / 62.60	39.01 / 54.11
	SoftmaX	DeepFool	85.68/85.77	87.98 / 91.63	74.69 / 86.48	65.64 / 81.32
SVHN		CW	77.48/77.70	85.66 / 90.02	71.77 / 84.95	62.67 / 79.95
		FGSM	96.36/96.27	64.40 / 67.44	47.48 / 58.00	35.90 / 51.89
	DDGC	DeepFool	79.54/79.36	85.59 / 89.90	71.95 / 84.81	63.36 / 79.86
		CW	62.90/62.40	70.40 / 74.10	56.30 / 67.60	44.20 / 58.40
Table 6: Test accuracy (%) of ResNet optimized by adversarial training. We use the ensemble
version of DDGC, and best results are highlighted in bold if the gain is bigger than 1%.
4 Conclusion
We propose a new inference method, easily applicable to any softmax neural classifier pre-trained on
datasets with noisy labels. Our main idea is defining the generative classifier on top of fixed features
from the pre-trained model. Such “deep generative classifiers” have been largely dismissed for fully-
supervised classification settings as they are often substantially outperformed by discriminative deep
classifiers (e.g., softmax classifiers). In contrast to this common belief, we show that it is possible
to formulate a simple generative classifier that is more robust without sacrificing the discriminative
performance. We expect that our work would bring a refreshing angle for other related tasks, e.g.,
adaptive attacks, memorization (Zhang et al., 2017) and interpretability (Morcos et al., 2018).
9
Under review as a conference paper at ICLR 2019
References
Dario Amodei, Sundaram Ananthanarayanan, Rishita Anubhai, Jingliang Bai, Eric Battenberg, Carl
Case, Jared Casper, Bryan Catanzaro, Qiang Cheng, Guoliang Chen, et al. Deep speech 2: End-
to-end speech recognition in english and mandarin. In ICML, 2016.
Devansh Arpit, Stanislaw Jastrzebski, Nicolas Ballas, David Krueger, Emmanuel Bengio, Maxin-
der S Kanwal, Tegan Maharaj, Asja Fischer, Aaron Courville, Yoshua Bengio, et al. A closer look
at memorization in deep networks. In ICML, 2017.
Thorsten Bernholt. Robust estimators are hard to compute. Technical report, Technical Re-
port/Universitat Dortmund, SFB 475 KomPlexitatsredUktion in Multivariaten Datenstrukturen,
2006.
Nicholas Carlini and David Wagner. Adversarial examples are not easily detected: Bypassing ten
detection methods. In ACM workshop on AISec, 2017.
Robert J Durrant and Ata Kaban. Compressed fisher linear discriminant analysis: Classification of
randomly projected data. In ACM SIGKDD, 2010.
Ronald A Fisher. The use of multiple measurements in taxonomic problems. Annals of eugenics,
1936.
Ross Girshick. Fast r-cnn. In ICCV, 2015.
Jacob Goldberger and Ehud Ben-Reuven. Training deep neural-networks using a noise adaptation
layer. In ICLR, 2017.
Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversarial
examples. In ICLR, 2015.
Chuan Guo, Mayank Rana, Moustapha Cisse, and Laurens van der Maaten. Countering adversarial
images using input transformations. In ICLR, 2018.
Frank R Hampel. A general qualitative definition of robustness. The Annals of Mathematical Statis-
tics, 1971.
Bo Han, Quanming Yao, Xingrui Yu, Gang Niu, Miao Xu, Weihua Hu, Ivor Tsang, and Masashi
Sugiyama. Co-teaching: robust training deep neural networks with extremely noisy labels. In
NIPS, 2018.
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recog-
nition. In CVPR, 2016.
Dan Hendrycks, Mantas Mazeika, Duncan Wilson, and Kevin Gimpel. Using trusted data to train
deep networks on labels corrupted by severe noise. In NIPS, 2018.
Hynek Hermansky, Daniel PW Ellis, and Sangita Sharma. Tandem connectionist feature extraction
for conventional hmm systems. In icassp, 2000.
Gao Huang and Zhuang Liu. Densely connected convolutional networks. In CVPR, 2017.
Mia Hubert and Katrien Van Driessen. Fast and robust discriminant analysis. Computational Statis-
tics & Data Analysis, 2004.
Lu Jiang, Zhengyuan Zhou, Thomas Leung, Li-Jia Li, and Li Fei-Fei. Mentornet: Regularizing very
deep neural networks on corrupted labels. In ICML, 2018.
Jonathan Krause, Benjamin Sapp, Andrew Howard, Howard Zhou, Alexander Toshev, Tom Duerig,
James Philbin, and Li Fei-Fei. The unreasonable effectiveness of noisy data for fine-grained
recognition. In ECCV, 2016.
Alex Krizhevsky and Geoffrey Hinton. Learning multiple layers of features from tiny images. 2009.
Julia A Lasserre, Christopher M Bishop, and Thomas P Minka. Principled hybrids of generative and
discriminative models. In CVPR, 2006.
10
Under review as a conference paper at ICLR 2019
Kimin Lee, Kibok Lee, Honglak Lee, and Jinwoo Shin. A simple unified framework for detecting
out-of-distribution samples and adversarial attacks. In NIPS, 2018.
Hendrik P Lopuhaa, Peter J Rousseeuw, et al. Breakdown points of affine equivariant estimators of
multivariate location and covariance matrices. The Annals of Statistics, 1991.
Xingjun Ma, Bo Li, Yisen Wang, Sarah M Erfani, Sudanthi Wijewickrema, Michael E Houle, Grant
Schoenebeck, Dawn Song, and James Bailey. Characterizing adversarial subspaces using local
intrinsic dimensionality. In ICLR, 2018a.
Xingjun Ma, Yisen Wang, Michael E Houle, Shuo Zhou, Sarah M Erfani, Shu-Tao Xia, Sudanthi
Wijewickrema, and James Bailey. Dimensionality-driven learning with noisy labels. In ICML,
2018b.
Laurens van der Maaten and Geoffrey Hinton. Visualizing data using t-sne. Journal of machine
learning research, 2008.
Dhruv Mahajan, Ross Girshick, Vignesh Ramanathan, Kaiming He, Manohar Paluri, Yixuan Li,
Ashwin Bharambe, and Laurens van der Maaten. Exploring the limits of weakly supervised
pretraining. arXiv preprint arXiv:1805.00932, 2018.
Eran Malach and Shai Shalev-Shwartz. Decoupling” when to update” from” how to update”. In
NIPS, 2017.
Seyed Mohsen Moosavi Dezfooli, Alhussein Fawzi, and Pascal Frossard. Deepfool: a simple and
accurate method to fool deep neural networks. In CVPR, 2016.
Ari S Morcos, Maithra Raghu, and Samy Bengio. Insights on representational similarity in neural
networks with canonical correlation. In NIPS, 2018.
Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, and Andrew Y Ng. Reading
digits in natural images with unsupervised feature learning. In NIPS workshop, 2011.
Andrew Y Ng and Michael I Jordan. On discriminative vs. generative classifiers: A comparison of
logistic regression and naive bayes. In NIPS, 2002.
Tianyu Pang, Chao Du, and Jun Zhu. Max-mahalanobis linear discriminant analysis networks. In
ICML, 2018.
Giorgio Patrini, Alessandro Rozza, Aditya Krishna Menon, Richard Nock, and Lizhen Qu. Making
deep neural networks robust to label noise: A loss correction approach. In CVPR, 2017.
Scott Reed, Honglak Lee, Dragomir Anguelov, Christian Szegedy, Dumitru Erhan, and Andrew
Rabinovich. Training deep neural networks on noisy labels with bootstrapping. arXiv preprint
arXiv:1412.6596, 2014.
Mengye Ren, Wenyuan Zeng, Bin Yang, and Raquel Urtasun. Learning to reweight examples for
robust deep learning. In ICML, 2018.
Peter J Rousseeuw. Least median of squares regression. Journal of the American statistical associ-
ation, 1984.
Peter J Rousseeuw and Katrien Van Driessen. A fast algorithm for the minimum covariance deter-
minant estimator. Technometrics, 1999.
Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian Goodfellow,
and Rob Fergus. Intriguing properties of neural networks. In ICLR, 2014.
Chiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht, and Oriol Vinyals. Understanding
deep learning requires rethinking generalization. In ICLR, 2017.
11
Under review as a conference paper at ICLR 2019
A	Preliminaries
Gaussian discriminant analysis. In this section, we describe the basic concepts of the discrimi-
native and generative classifier (Ng & Jordan, 2002). Formally, denote the random variable of the
input and label as X and y = {1,…，C}, respectively. For the classification task, the discriminative
classifier directly defines a posterior distribution P (y|x), i.e., learning a direct mapping between
input X and label y. A popular model for discriminative classifier is softmax classifier which de-
fines the posterior distribution as follows: P (y	=	c|x)	=	LeXP(WC	x+bc)、, where	Wc	and bc	are
c0 exp(wc>0 x+bc0 )	c c
weights and bias for a class c, respectively. In contrast to the discriminative classifier, the generative
classifier defines the class conditional distribution P (X|y) and class prior P (y) in order to indi-
rectly define the posterior distribution by specifying the joint distribution P (X, y) = P (y) P (X|y).
Gaussian discriminant analysis (GDA) is a popular method to define the generative classifier by
assuming that the class conditional distribution follows the multivariate Gaussian distribution and
the class prior follows Bernoulli distribution: P (x|y = C)= N (x∣μc, Σc), P (y = C) = P βcg /,
where μc and Σc are the mean and covariance of multivariate Gaussian distribution, and βc is the
unnormalized prior for class C. This classifier has been studied in various machine learning areas
(e.g., semi-supervised learning (Lasserre et al., 2006) and incremental learning (Lee et al., 2018)).
In this paper, we focus on the special case of GDA, also known as the linear discriminant analysis
(LDA). In addition to Gaussian assumption, LDA further assumes that all classes share the same
covariance matrix, i.e., Σc = Σ. Since the quadratic term is canceled out with this assumption, the
posterior distribution of generative classifier can be represented as follows:
P( = ।)= P (y = C) P (x|y = C)	=	eχp 5>ςTX - 2μ>ETμc + log βc)
P CX	Pco P(y	=	CO)	P(XIy = CO)	Pco exp	(μ>∑-1X -	1 μ>∑-1μco	+ log Bc，).
One can note that the above form of posterior distribution is equivalent to the softmax classifier by
considering μ>Σ-1 and - ɪμ>Σ-1μc + log βc as its weight and bias, respectively. This implies
that X might be fitted in Gaussian distribution during training a softmax classifier.
Breakdown points. The robustness of MCD estimator can be explained by the fact that it has high
breakdown points (Hampel, 1971). Specifically, the breakdown point of an estimator measures the
smallest fraction of observations that need to be replaced by arbitrary values to carry the estimate
beyond all bounds. Formally, denote YM as a set obtained by replacing M data points of set Y by
some arbitrary values. Then, for a multivariate mean estimator μ = μ(Y) from Y, the breakdown
point is defined as follows (see Appendix A for more detailed explanations including the breakdown
point of covariance estimator):
ε*(μ, Y) = 17 min [m ∈{1,…，∣Y∣} ： Sup kμ(Y) - μ(YM)k = ∞}.
|Y |	YM
For a multivariate estimator of covariance Σ, we have
ε*(Σ, Y) = Imin{M ∈{1,…，∣Y∣} ： SuPmaX{∣ logλi(Σ(Y)) - logλi(Σ(YM))∣}},
|Y |	M i
where the k-th largest eigenvalue of a general n X n matrix is denoted by λk (Σ), k = 1,…,n
such that λι(Σ) ≤ λ2(Σ) ≤ … ≤ λn(Σ). This implies that we consider a covariance estimator to
be broken whenever any of the eigenvalues can become arbitrary large or arbitrary close to 0.
B Experimental setup
In this section, we describe detailed explanation about all the experiments described in Section 3.
Detailed model architecture and datasets. We consider two state-of-the-art neural network archi-
tectures: DenseNet (Huang & Liu, 2017) and ResNet (He et al., 2016). For DenseNet, our model
follows the same setup as in Huang & Liu (2017): 100 layers, growth rate k = 12 and dropout rate 0.
Also, we use ResNet with 34 and 44 layers, filters = 64 and dropout rate 0.5 The softmax classifier
5ResNet architecture is available at https://github.com/kuangliu/pytorch-cifar.
12
Under review as a conference paper at ICLR 2019
is used, and each model is trained by minimizing the cross-entropy loss. We train DenseNet and
ResNet for classifying CIFAR-10 (or 100) and SVHN datasets: the former consists of 50,000 train-
ing and 10,000 test images with 10 (or 100) image classes, and the latter consists of 73,257 training
and 26,032 test images with 10 digits.6 By following the experimental setup of Ma et al. (2018b),
All networks were trained using SGD with momentum 0.9, weight decay 10-4 and an initial learn-
ing rate of 0.1. The learning rate is divided by 10 after epochs 40 and 80 for CIFAR-10/SVHN (120
epochs in total), and after epochs 80, 120 and 160 for CIFAR-100 (200 epochs in total). For our
method, we extract the hidden features at {34, 46, 56, 67, 79, 89, 99}-th layers and {3, 7, 9, 11, 13,
15, 17, 19, 21, 23, 25, 27, 29, 31, 33}-th layers for DenseNet and ResNet, respectively.
Training method for noisy label learning. We consider the following training methods for noisy
label learning:
(a)	Hard bootstrapping (Reed et al., 2014): Training with new labels generated by a convex
combination (the hard version) of the noisy labels and their predicted labels.
(b)	Soft bootstrapping (Reed et al., 2014): Training with new labels generated by a convex
combination (the soft version) of the noisy labels and their predictions.
(c)	Backward (Patrini et al., 2017): Training via loss correction by multiplying the cross-
entropy loss by a noise-aware correction matrix.
(d)	Forward (Patrini et al., 2017): Training with label correction by multiplying the network
prediction by a noise-aware correction matrix.
(e)	D2L (Ma et al., 2018b): Training with new labels generated by a convex combination of
the noisy labels and their predictions, where its weights are chosen by utilizing the Local
Intrinsic Dimensionality (LID). (Ma et al., 2018a).
(f)	Decoupling (Malach & Shalev-Shwartz, 2017): Updating the parameters only using the
samples which have different prediction from two classifier.
(g)	MentorNet (Jiang et al., 2018): An extra teacher network is pre-trained and then used to
select clean samples for its student network.
(h)	Co-teaching (Han et al., 2018): A simple ensemble method where each network selects its
small-loss training data and back propagates the training data selected by its peer network.
(i)	Cross-entropy: the conventional approach of training with cross-entropy loss.
Adversarial attacks. In this paper, we consider the following attack methods: fast gradient sign
method (FGSM) (Goodfellow et al., 2015), DeepFool (Moosavi Dezfooli et al., 2016) and Carlini-
Wagner (CW) (Carlini & Wagner, 2017). The FGSM directly perturbs normal input in the direction
of the loss gradient. Formally, non-targeted adversarial samples are constructed as
Xadv = X + εFGSMSign (5χ'(y*,P(y|x))),
where Kfgsm is a magnitude of noise, y* is the prediction of classifier and ' is a loss function to
measure the distance between the prediction and the ground truth. DeepFool works by finding the
closest adversarial samples with geometric formulas. CW is an optimization-based method which
arguably the most effective method. Formally, non-targeted adversarial samples are constructed as
arg min λd(x, Xadv) - '(y*,P (y∣Xadv)),
xadv
where λ is penalty parameter and d(∙, ∙) is a metric to quantify the distance between an original
image and its adversarial counterpart. However, compared to FGSM, this method is much slower
in practice. For all experiments, L2 distance is used as a constraint. We used the library from (Guo
et al., 2018) for generating adversarial samples.7
For all experiments, the adversarial samples are generated by targeting a softmax
classifier or our generative classifier. Specifically, we generate the adversarial sam-
ples by attacking the ensemble of generative classifiers:	P ɑ`p (y = c∖f'(x))	=
`
6We do not use the extra SVHN dataset for training.
7The code is available at https://github.com/facebookresearch/adversarial_image_
defenses.
13
Under review as a conference paper at ICLR 2019
Dataset	Target	Data type	Clean L∞	Acc.		Uniform (20%) L∞ Acc.		Uniform (40%) L∞ Acc.		Uniform (60%) L∞	Acc.	
		Clean	0	95.01	0	79.28	0	61.85	0	35.02
	Softmax	FGSM	0.05	56.90	0.05	25.26	0.05	23.71	0.05	20.88
		DeepFool	0.34	0.36	0.06	0.04	0.03	0.00	0.02	0.00
CIFAR-10		CW	0.09	0.02	0.04	0.57	0.02	0.40	0.01	0.27
		Clean	0~O-	94.32	-0-	87.25^^	-0-	80.01	-0-	71.06
	DDGC	FGSM	0.05	94.59	0.05	78.40	0.05	59.33	0.05	52.87
		DeepFool	0.44	5.25	0.09	66.26	0.04	71.77	0.02	68.76
		CW	0.21	0.00	0.27	0.00	0.27	0.10	0.23	0.20
		Clean	0	77.51	0	60.92	0	44.08	0	23.43
	Softmax	FGSM	0.05	31.78	0.05	17.95	0.05	13.20	0.05	10.11
		DeepFool	0.33	0.27	0.12	0.08	0.06	0.05	0.04	0.01
CIFAR-100		CW	0.06	0.05	0.03	0.23	0.02	0.13	0.01	0.01
		Clean	-0-	76.55	-0-	66.08^^	-0-	59.72	-0-	48.85
	DDGC	FGSM	0.05	72.44	0.05	42.25	0.05	34.06	0.05	31.31
		DeepFool	0.32	8.50	0.14	28.40	0.09	30.90	0.07	35.86
		CW	0.07	0.04	0.08	0.00	0.08	0.32	0.09	0.77
		Clean	0	95.96	0	83.52	0	72.89	0	61.23
	Softmax	FGSM	0.20	54.96	0.20	42.58	0.20	24.61	0.20	24.42
		DeepFool	0.52	1.30	0.09	0.14	0.06	0.13	0.05	0.17
SVHN		CW	0.14	0.11	0.05	0.16	0.04	0.01	0.04	0.03
		Clean	-0-	96.09	-0-	91.67^^	-0-	87.16	-0-	80.52
	DDGC	FGSM	0.20	96.15	0.20	47.26	0.20	41.23	0.20	35.46
		DeepFool	0.77	17.16	0.10	71.75	0.07	80.08	0.05	75.00
		CW	0.27	0.00	0.26	1.00	0.25	0.30	0.29	0.50
Table 7: The L∞ mean perturbation and classification accuracy of ResNet-34 on clean and adver-
sarial samples.
Dataset	Target	Data type	Clean L∞	Acc.		Uniform (20%) L∞ Acc.		Uniform (40%) L∞ Acc.		Uniform (60%) L∞	Acc.	
		Clean	0	94.42	0	80.24	0	68.61	0	53.34
	Softmax	FGSM	0.05	32.50	0.05	22.84	0.05	22.49	0.05	20.90
		DeepFool	0.14	0.20	0.03	0.05	0.03	0.10	0.02	0.01
CIFAR-10		CW	0.06	0.08	0.03	0.39	0.03	0.27	0.02	0.18
		Clean	-0-	93.49	-0-	87.25^^	-0-	81.04	-0-	74.72
	DDGC	FGSM	0.05	83.88	0.05	62.69	0.05	36.75	0.05	44.16
		DeepFool	0.14	30.45	0.05	70.09	0.03	71.50	0.02	67.50
		CW	0.12	0.00	0.11	0.04	0.12	0.09	0.23	0.54
		Clean	-0~	76.41	^^0-	57.63	-0^^	45.08	-0	35.83
	Softmax	FGSM	0.05	18.73	0.05	12.74	0.05	10.55	0.05	9.07
		DeepFool	0.12	0.10	0.05	0.00	0.03	0.01	0.02	0.01
CIFAR-100		CW	0.03	0.22	0.02	0.20	0.02	0.20	0.01	0.12
		Clean	-0-	73.65	-0-	62.19^^	-0-	53.98	-0-	45.27
	DDGC	FGSM	0.05	52.14	0.05	34.36	0.05	24.24	0.05	22.79
		DeepFool	0.12	17.40	0.06	33.63	0.04	39.95	0.03	37.36
		CW	0.07	0.18	0.08	1.04	0.07	2.31	0.06	3.86
		Clean	0	96.59	0	86.92	0	81.91	0	71.18
	Softmax	FGSM	0.20	51.18	0.20	46.64	0.20	40.21	0.20	36.62
		DeepFool	0.26	3.04	0.22	4.21	0.20	2.14	0.18	2.11
SVHN		CW	0.12	0.15	0.12	0.31	0.10	0.16	0.10	0.09
		Clean	-0-	96.18	-0-	89.50	-0-	85.71	-0-	77.67
	DDGC	FGSM	0.20	90.74	0.20	54.87	0.20	41.91	0.20	42.91
		DeepFool	0.26	50.00	0.23	58.59	0.20	66.81	0.14	63.68
		CW	0.25	0.00	0.33	1.59	0.39	4.63	0.46	11.22
Table 8: The L∞ mean perturbation and classification accuracy (%) of DenseNet-100 on clean and
adversarial samples.
∑α'
`
exp(b>c∑-fg(x)-O5μ>c∑-1μ',c+log bc)
Pc0 exp(μ>c0 ∑ -If (χ)-0.5μ>c0 ∑ -1b',c0 +log bc0)
. Here, we remark that a margin loss on
the logit layer of each generative classifier is used in the case of CW attacks8. Due to time
complexity, we only attack a generative classifier from a final layer in the case of DeepFool.
Table 7 and 8 report the statistics of adversarial attacks including the L∞ mean perturbation and
classification accuracy on adversarial attacks.
8Similar to Carlini & Wagner (2017), we use 2000 random samples.
14
Under review as a conference paper at ICLR 2019
(a) Generalization from
noisy labels
(b) Robustness to adver-
sarial attacks
(c) Generalization from (d) Robustness to adver-
noisy labels	sarial attacks
Figure 3: Layer-wise characteristics of generative classifiers from (a)/(b) ResNet-34 and (c)/(d)
DenseNet-100 trained on the CIFAR-10 dataset.
Model	Inference Method	Noisy Dataset								
		CIFAR-10			CIFAR-100			SVHN		
		20%	40%	60%	20%	40%	60%	20%	40%	60%
	SoftmaX	79.28	61.85	35.02	60.92	44.08	23.43	83.52	72.89	61.23
ResNet	Softmax + fine-tuning (Val)	80.48	69.42	54.16	51.15	35.17	20.41	85.10	81.93	75.06
	Generative + MCD Generative + MCD + ensemble (val)	83.04 87.25	68.04 80.01	42.74 71.06	63.20 66.08	51.71 59.72	33.96 48.85	89.60 91.67	78.88 87.16	66.96 80.52
	Softmax	80.24	68.61	53.34	57.63	45.08	35.83	86.92	81.91	71.18
DenseNet	Softmax + fine-tuning (val)	82.47	74.38	63.25	48.69	35.97	27.73	86.83	76.39	68.13
	Generative + MCD Generative + MCD + ensemble (val)	85.96 87.25	78.34 81.04	66.16 74.72	58.22 62.19	48.54 53.98	37.44 45.27	88.64 89.50	84.08 85.71	74.47 77.67
Table 9: Comparison with softmax classifier fine-tuned with validation data. All values are percent-
ages and the best results are highlighted in bold if gain is bigger than 1%.
C Layer-wise characteristics of generative classifiers
Figure 3 shows the classification accuracy of the generative classifiers from different basic blocks
of ResNet-34 (He et al., 2016) and DenseNet-101 (Huang & Liu, 2017). One can note that the
generative classifiers from DenseNet and ResNet have different patterns due to the architecture
design. In the case of DenseNet, we found that it produces meaning features after 20-th basic blocks.
However, we remark that the performances of the generative classifiers from low-level features (from
20 to 40-th layers) of DenseNet are still more robust to adversarial attacks and noisy labels. Because
of that, the ensemble of generative classifiers on DenseNet also improves the generalization from
noisy labels and robustness to adversarial attacks.
D	Fine-tuning softmax layer using validation set
In this paper, we utilize a validation set, which consists of 500 images (i.e., only ≤ 1% of the number
of training samples) with clean labels. For fair comparisons, one might also suggest fine-tuning the
softmax classifier (with fixed features) using the validation improve the classification accuracy. We
indeed measure the classification accuracy of softmax classifier after fine-tuning in Table 9. One can
note that the proposed method still outperforms softmax classifiers. Since 1% data is not enough
compared to the number of softmax classifiers, fine-tuning can decrease the performance in the case
of softmax classifier, while DDGC is still working well (it only trains the ensemble weights).
E	More experimental results on adversarial attacks
In this section, we provide more experimental results on adversarial attacks. First, Table 10 and 11
show the classification accuracy on white-box adversarial attacks when we train ResNets using the
15
Under review as a conference paper at ICLR 2019
Dataset	Attack	Adversarial	Clean	Uniform (20%)	Uniform (40%)	Uniform (60%)
	type	attacks	SoftmaX / DDGC			
CIFAR-10	Softmax	FGSM DeepFool CW	56.90/57.51 0.36 /18.48 0.02/1.16	25.26 / 57.11 0.04 / 71.14 0.57 / 52.39	23.71 / 59.32 0.00 / 73.21 0.40 / 61.14	20.88 / 54.97 0.00 / 68.92 0.27 / 64.29
	DDGC	FGSM DeepFool CW	94.74/94.59 11.13 /5.25 0.00 / 0.00	70.68 / 78.40 4.71 / 66.26 0.20 / 0.00	25.54 / 59.33 3.20 / 71.77 0.20 / 0.10	14.95 / 52.87 4.17 / 68.76 0.20 / 0.20
CIFAR-100	Softmax	FGSM DeepFool CW	31.78/31.94 0.27 / 9.84 0.05 / 5.07	17.95 / 30.23 0.08 / 37.07 0.23 / 27.95	13.20 / 30.81 0.05 / 42.15 0.13 / 35.32	10.11 / 35.62 0.01 / 40.82 0.01 / 39.90
	DDGC	FGSM DeepFool CW	74.51 /72.44 4.09 / 8.50 0.95/0.04	35.41 / 42.25 4.72 / 28.40 0.86 / 0.00	23.68 / 34.06 3.54 / 30.90 0.31 / 0.32	12.08 / 31.31 1.63 / 35.86 0.22 / 0.77
SVHN	Softmax	FGSM DeepFool CW	54.96 / 56.46 1.30/ 45.40 0.11/13.39	42.58 / 54.26 0.14 / 79.29 0.16/ 56.58	24.61 / 46.80 0.13 / 81.59 0.01 / 68.22	24.42 / 40.92 0.17 / 75.87 0.03 / 61.93
	DDGC	FGSM DeepFool CW	96.19/96.15 13.00/17.16 0.10/0.00	40.82 / 47.26 17.58 / 71.75 0.70 / 1.00	19.80 / 41.23 19.66 / 80.08 0.40 / 0.30	18.13 / 35.46 27.83 / 75.00 0.10 / 0.50
Table 10: Test accuracy (%) of ResNet on white-box adversarial attacks. We use the ensemble
version of DDGC, and the best results are highlighted in bold if gain is bigger than 1%.
aase	Target	Adversarial	Clean	Uniform (20%)	Uniform (40%)	Uniform (60%)
		attacks	Softmax / DDGC			
		FGSM	74.72 / 74.53	35.21 / 64.06	24.64 / 67.93	20.70 / 59.87
	SoftmaX	DeepFool	1.09/14.45	0.04 / 61.54	0.05 / 69.22	0.00 / 61.40
CIFAR-10		CW	0.05 /1.31	0.00/ 40.81	0.00 / 59.86	0.00 / 57.22
		FGSM	94.68 / 94.44	59.01 / 73.32	31.60 / 67.96	12.83 / 55.54
	DDGC	DeepFool	9.41 /10.77	9.77 / 44.86	9.68 / 66.50	9.36 / 60.40
		CW	0.14/0.04	0.04 / 0.00	0.18 / 0.04	0.31 / 0.00
		FGSM	37.73/ 42.57	24.04 / 47.00	16.52 / 46.46	11.52 / 41.62
	SoftmaX	DeepFool	0.13/ 10.40	0.04 / 36.09	0.00 / 42.95	0.00 / 41.45
CIFAR-100		CW	0.00 / 9.31	0.04/ 34.81	0.00 / 44.04	0.00 / 41.54
		FGSM	62.60/62.88	40.98 / 51.68	25.35 / 43.29	10.92 / 36.39
	DDGC	DeepFool	2.81/ 6.22	3.45 / 21.36	2.31 / 27.36	1.86 / 34.13
		CW	1.18 /0.00	0.81 / 0.00	0.45 / 0.04	0.27 / 0.04
		FGSM	57.86/ 60.31	44.25 / 66.10	30.17 / 60.10	27.59 / 56.45
	SoftmaX	DeepFool	2.54/ 35.72	0.18 / 77.50	0.13 / 79.63	0.00 / 75.40
SVHN		CW	0.50 /19.40	0.04 / 63.68	0.04 / 69.13	0.00 / 66.90
		FGSM	96.42/96.35	50.07 / 61.63	22.10 / 52.05	18.79 / 51.15
	DDGC	DeepFool	15.81/ 21.81	20.95 / 73.31	18.18 / 78.09	33.36 / 76.27
		CW	0.27/0.63	0.77 / 0.90	0.36 / 0.54	1.18 / 1.40
Table 11: Test accuracy (%) of ResNet optimized by adversarial training on CIFAR-10. We test
the white-box adversarial attacks. We use the ensemble version of DDGC, and best results are
highlighted in bold if the gain is bigger than 1%.
cross-entropy loss and adversarial training, respectively. We also report the classification accuracy
of DenseNet on white-box and black-box adversarial attacks in Table 12 and 13, respectively.
16
Under review as a conference paper at ICLR 2019
aase	Target	Adversarial	Clean	Uniform (20%)	Uniform (40%)	Uniform (60%)
		attacks	SoftmaX / DDGC			
		FGSM	32.50 / 38.00	22.84 / 56.05	22.49 / 46.51	20.90 / 52.63
	Softmax	DeepFool	0.20 / 36.09	0.05 / 76.94	0.10 / 75.03	0.01 / 68.83
CIFAR-10		CW	0.08 / 4.27	0.39 / 55.15	0.27 / 48.83	0.18 / 54.83
		FGSM	83.92/83.88	53.33/ 62.69	20.51 / 36.75	13.97 / 44.16
	DDGC	DeepFool	30.81 /30.45	6.95 / 70.09	12.22 / 71.50	13.68 / 67.50
		CW	0.00 / 0.00	0.13 / 0.04	0.22 / 0.09	0.63 / 0.54
		FGSM	18.73/ 22.65	12.74 / 27.18	10.55 / 22.36	9.07 / 22.09
	Softmax	DeepFool	0.10/ 19.31	0.00 / 40.09	0.01 / 42.10	0.01 / 37.46
CIFAR-100		CW	0.22 /12.87	0.20 / 30.14	0.20 / 32.20	0.12 / 31.46
		FGSM	54.25 /52.14	30.14/ 34.26	19.67 / 24.24	12.46 / 22.79
	DDGC	DeepFool	15.27/17.40	8.77 / 33.63	6.45 / 39.95	7.90 / 37.36
		CW	2.45/0.18	1.09 / 1.04	0.90 / 2.31	1.00 / 3.86
		FGSM	51.18/ 53.75	46.64 / 50.98	40.21 / 46.60	36.62 / 40.05
	Softmax	DeepFool	3.04/ 66.30	4.21 / 71.28	2.14 / 71.97	2.11 / 62.26
SVHN		CW	0.15/ 27.01	0.31 / 36.48	0.16 / 33.89	0.09 / 26.86
		FGSM	90.39/90.74	52.14/ 54.87	36.31 / 41.91	41.18 / 42.91
	DDGC	DeepFool	41.63/ 50.00	26.40 / 58.59	36.27 / 66.81	52.54 / 63.68
		CW	1.45 /0.00	1.40 / 1.59	3.31 / 4.63	11.36 / 11.22
Table 12: Test accuracy (%) of DenseNet on white-box adversarial attacks. We use the ensemble
version of DDGC, and the best results are highlighted in bold if gain is bigger than 1%.
TAflfficpt aase	Target	Adversarial	Clean	Uniform (20%)	Uniform (40%)	Uniform (60%)
		attacks	Softmax / DDGC			
		FGSM	62.96 / 64.66	60.63 / 70.19	47.77 / 55.11	40.07 / 62.02
	SoftmaX	DeepFool	87.68/87.78	76.48 / 84.54	67.93 / 80.38	51.31 / 73.57
CIFAR-10		CW	52.12/ 54.92	63.48 / 74.23	55.41 / 67.45	45.03 / 69.03
		FGSM	87.69/87.82	63.25/ 70.94	44.47 / 51.43	38.14 / 59.76
	DDGC	DeepFool	88.31 /88.36	75.81 / 84.31	66.04 / 79.86	52.36 / 73.68
		CW	24.31 /24.22	26.77 / 31.04	19.68 / 19.45	15.36 / 15.81
		FGSM	48.84 /45.83	35.07 / 39.32	24.60 / 27.43	21.64 / 28.72
	SoftmaX	DeepFool	66.87 /62.53	53.00 / 56.05	43.09 / 48.18	32.42/ 41.71
CIFAR-100		CW	55.74 /53.09	44.70 / 49.49	36.49 / 41.53	29.67 / 38.97
		FGSM	61.21 /57.29	39.52/ 42.20	26.35 / 28.31	22.82 / 29.00
	DDGC	DeepFool	68.04 / 64.95	52.04 / 55.86	43.27 / 48.36	33.59 / 42.31
		CW	37.86 / 34.09	23.31 / 26.81	18.63 / 20.81	17.54 / 24.68
		FGSM	58.08/ 59.10	53.76 / 56.76	47.58 / 52.08	46.82 / 47.91
	SoftmaX	DeepFool	89.59/90.13	86.60 / 88.25	82.60 / 85.95	81.63 / 82.81
SVHN		CW	66.35 / 68.61	68.27 / 71.23	60.25 / 66.23	64.19 / 66.20
		FGSM	89.87/90.23	52.57 / 55.92	43.59 / 47.60	46.66 / 47.91
	DDGC	DeepFool	87.40/88.04	81.18 / 83.95	79.90 / 83.72	78.81 / 80.31
		CW	40.59/41.50	39.68 / 41.18	38.59 / 39.77	45.45 / 46.63
Table 13: Test accuracy (%) of DenseNet on black-box adversarial attacks. We use the ensemble
version of DDGC, and the best results are highlighted in bold if gain is bigger than 1%.
F Proof of Theorem 1
In this section, we present a proof of Theorem 1, which consists of three statements: the limit of
estimated error ratio (3), estimation error ratio (4) and mahalanobis distance (5). We prove each
statement one by one as stated in below. For convenience, we skip to mention the Continuous
Mapping Theorem9 and the number of training samples N goes to infinity for all convergences in
the proof.
F.1 Proof of the limit of estimation error (4)
We start with the following lemma, which shows the convergences of sample and MCD estimators
with single Gaussian distribution as the number of training samples N goes to infinity.
9P. Billingsley, Convergence of Probability Measures, John Wiley & Sons, 1999
17
Under review as a conference paper at ICLR 2019
Lemma 1. Suppose we have N number of d-dimensional training samples XN = {xι, ∙∙∙ , XN}
and XN contains outlier samples with the fixed fraction δout < 1. We assume the outlier samples are
from an arbitrary distribution Pout with zero mean and finite covariance matrix σo2utI, and the other
samples are from a multivariate GauSSian distribution Pdata with mean μ and covariance matrix
σ2I. Let μ and Σ be the mean and Covariance matrix OfSamPle estimator, and let μ and Σ be
the mean and covariance matrix of MCD estimator which selects samples from XN with the fixed
fraction N < δmcd < 1 to optimize its objective (2). Then the mean and Covariance matrix ofsample
estimator converge almost surely to below as N → ∞ :
μ → (I - δout) μ,	ς → ((I - δout) σ2 + δoutσ2ut) I + δout(I - δoUt) μμτ.
In addition, if δmcd ≤ 1 - δout and σ2 < σo2ut, the mean and covariance matrix of MCD estimator
converge almost surely to below as N → ∞ :
a.s.	a.s. 2
μ -→ μ, Σ —→ σ I.
A proof of the above lemma is given in appendix F.4, where it is built upon the fact that the deter-
minant of covariance matrix with some assumptions can be expressed as the d-th degree polynomial
of outlier ratio.
Lemma 1 states the convergences of sample and MCD estimators on single multivariate Gaussian
distribution. One can extend it to C number of multivariate Gaussian distributions, which have the
class mean μc and class covariance matrix ∑c on each class label C ∈ {1,…，C}, by the assumptions
A1 〜 A5. Then one can induce the class mean of MCD and sample estimators converge almost
surely as follows:
a.s.
→ μc,
μc → (I - δout) μc,
which implies that
kμc - μckι → 0,
kμc - μckι → δoutkμc∣∣ι∙
This completes the proof of the limit of estimation error (4).
F.2 Proof of the limit of mahalanobis distance ratio (5)
From the assumptions A1, all class covariance matrices are the same, i.e., Σc = σ2I. Then tied
covariance matrices Σ and Σ are given by gathering Σc and Σc on each class c respectively:
ς = Ec Nc∑ C = Ec ∑ C ς = Ec Kc∑ C = Ec Σ C
=Pc NC	= C ,	=	Pc KC	= C
(6)
From the tied covariance matrices (6) and Lemma 1, one can induce their convergences and limits
as follow:
ς a—' ((1 - δout) σ2 + δoutσ2ut) I + δout (I- δout ) C ^X μcμT,
(7)
Σb a—.s. σ2I.
Since the assumption A2 gives a diagonal matrix D = C PC μcμT, the limit of covariance matrix
of sample estimator (7) and its inverse are also diagonal matrices. Then the limit of inverse matrix
ΣT is given as follows:
∑T → (((1 - δout) σ2 + δoutσ2ut) I + δ°ut (1 - δ°ut) D)
(8)
Since the limit of inverse matrix ΣT (8) is a diagonal matrix, the limit of the mahalanobis distance
between μc and "c，is given as follows:
(μc - μc0 ) ς (μc - μc0) = tr (ς (μc - μc0)(μc - μc0) )
a→.s. i (1-
(1 - δout) (μci - μc0i)2
δout) σ + δout σout + δout (1 - δout ) Di
(9)
C
18
Under review as a conference paper at ICLR 2019
where D = diag (D1, ..., Dd). By the assumption A4, the denominator term of (9) is greater than
σ2 for all i, i.e.,
(1 - δout) σ2 + δoutσo2ut + δout (1 - δout) Di ≥ σ2 for ∀ i.
Then the limit of mahalanobis distance between mean of sample estimators (9) has the following
upper bound:
(1 - δout) (μci - μc0i)2
(μc - μCO)Tς-1(μc …→ ∑ (1 - δout) σ2 + δoutσ2ut + δout (1 - δout) Di
≤ (1 — δout)2 ®
σ2
(10)
—
One can also induce the limit of the mahalanobis distance between mean of MCD estimators 限 and
μco as follows:
(μi — bc)T∑-1(μi — bc) = tr (∑-1(bi — bc)(bi — bc)T) → —
σ2
(11)
—
From the limits of mahalanobis distance (10) and (11), the limit of mahalnobis distance ratio (5) is
induced as follows:
(μc - μc0)Tς ((μc - μc0 ) a.s.
i (I- δout )σ2+ δout σ2ut+ δ out (I- δout ) Di
(bc- bco)T ∑-1(b
，c - μco)
(Ni-Nc)T (Ni-Nc)
(1 - δout )
σ2
(μi-μc)T (Ni-Nc)
(1 - δout ) ≤ 1.
σ2
This completes the proof of the limit of mahalnobis distance ratio (5).
F.3 Proof of the limit of estimated error ratio (3)
Remind that the estimated error B(bc, μ, ∑, ∑) is defined as follows:
B(bc,bc0,∑, ∑) := exp
/
1
—
8
∖
2
-bc0)T Σ-1(bc — bc0)
(be，一 μc)T ∑-1∑∑-ι(bco- bc)
(12)
≤
By the property of trace operator, the inner term of estimated error (12) is equal to
[(bc- bco )t ∑-1(bc- bco)]2
tr (∑-1(μc — μco )(μc — 良，产 j
(Ro, 一 μc)T∑-1∑∑-1(bc，— μc) = tr (∑-IΣΣ-1(bc - bc0)(bc — .co)?)
(13)
From the right hand side of (13), the negative logarithms of estimated error (12) of sample and MCD
estimators converge as follows:
01	t τ,,- t tr v,ʌʌ _	tr (ς 1(μc — μc0)(μc — μc0)T)
— og( (μc,μc0,	, )) = tr(∑-1σ2IΣ-1(& — &，)(& - μc,)T)
2
a.s. (1 - δout)
σ2
(μci -μcOi)
i (I- δout )σ2+ δout σ2ut+ δout (I- δout ) Di
Mci-McOi)2
(14)
((I-δout )σ2+δout σ2ut + δout (1 -δout ) Di )2
2
i
q1 EL ʌ '令、ʌ a.s.	tr ((σ2I)T(μc —〃c，)(〃c —〃c，)T)2
g(B(μc,μc0, S，£))	tr ((σ2I)Tσ2I(σ2I)T(μc — 〃c，)(〃c — Rc，)T)
_ (μc — μc )τ(μc — μ∕)
σ2
(15)
19
Under review as a conference paper at ICLR 2019
The relation between the limits of (14) and (15) can be induced by the Cauchy-Schwarz inequality,
2
μc - μci
£(〃—)2£
ii
(1 - δout) σ2 + δoutσo2ut + δout (1 - δout) Di
≥
(μci - μcOi)2
2
(1 - δout) σ2 + δoutσo2ut + δout (1 - δout) Di
The above inequality implies
(μci- μc0 i)
(μc - μcO)T(μc - μcO) ≥ ~~7
i (I-δout )σ2 + δout σ2ut+ δout (I-δout ) Di
(μci-μc0 i)2
i ((I-δout )σ2 + δout σ2ut + δout (I-δout ) Di )2
2
From the fact that (1 - δout)2 ≤ 1, the limits of (14) and (15) hold the following inequality:
2
(μc - μcO)T(μc - μcO)
(1 - δout )
(μci -μc0i )
i (I- δout ) σ 2 + δout σ2ut+ δout (I- δout ) Di
σ2
σ2
Mci-McOi)2
(16)
((I-δout )σ2+δout σ2ut + δout (1 -δout ) Di )2
≥
i
—
Let Iim - 8log(B(μc,μcO, Σ, Σ)) and lim - 8log(B(μc,μ3, Σ, Σ)) denote the limits of the
N→∞	N→∞
negative logarithms of estimated error (12) of sample and MCD estimators, respectively. From (14),
(15) and (16), it holds that
-. / ʌ ʌ _________ -^~、 ~. 一, _____________ —、
lim B(μc,μc, ∑, ∑) ≤ lim B(fic,μd, ∑, ∑).
N→∞	N→∞
This implies that the limit of estimated error ratio (3) is smaller than one, i.e.,
lim —"■/. & ≤ 1.
N→∞ B(μc,μc, ∑, ∑)一
This completes the proof of Theorem 1.
F.4 Proof of Lemma 1
In this part, we present a proof of Lemma 1. We show the almost surely convergences of sample and
MCD estimators as the number of training samples N goes to infinity.
Proof of the convergence of sample estimator. First of all, the set of training samples XN =
{xι,…,XN} contains outlier samples with the fixed fraction δ°ut. So, XN is from a mixture distri-
bution Pmix = (1 - δout) Pdata + δout Pout. Then mean and covariance matrix of sample estimator, μ
and Σ, estimate mean -x and covariance matrix Σ1mix of the mixture distribution Pmix, respectively.
One can induce μ1mix and Σ1mix directly as follow:
μmix = (I - δout) μ,	2mix = (I - δout) σ I + δoutσoutI + δout (I - δout) μμ .	(17)
Since Pmix has the finite covariance matrix, i.e., Σmix < ∞, one can apply the the Strong Law
of Large Numbers10 to the sample estimator of the mixture distribution Pmix. Then the mean and
covariance matrix of sample estimator converge almost surely to the mean and covariance matrix of
Pmix, respectively:
a.s.
μ —→ μmix,
∑ →. ∑mix.
This completes the proof of the convergence of sample estimator.
Proof of the convergence of MCD estimator. Consider a collection Eq of subsets XK,q ⊂ XN
with the size K (= bδmcdNc), and each subset XK,q contains the outlier samples with the fraction
q ∈ [0, 1]. Then XK,q ∈ Eq is from a mixture distribution Pq = (1 - q) Pdata + qPout. One can
induce that the mean μq and covariance matrix Σq of the mixture distribution Pq as (17):
μq =(1-q)μ,	&q =(I- q)σ2I + qσ2utI + q(I- q)μμT.	(18)
10W. Feller, An Introduction to Probability Theory and Its Applications, John Wiley & Sons, 1968
20
Under review as a conference paper at ICLR 2019
Thus sample mean estimator μχκ,q and covariance estimator Σχκ,q of a subset Xκ,q converge
almost surely to μq and Σq respectively:
μXκ,q a→ μq,	ςXκ,q →→. Eq,
by the Strong Law of Large Numbers.
On the other hand, there is a subset XK4* ⊂ XN in Eq* which is selected by MCD estimator.
Then the determinant of its covariance matrix is the minimum over all XK ⊂ XN, and μχ *	=
K,q*
b -→ μq* , ∑XK,q* = Σ →. Σq* as N → ∞. Since the determinant is a continuous funciton, the
Continuous Mapping Theorem11 implies
V min det(EXκ,q ) →' min det (Cq),
XK,q ⊂XN	q
and
Ximi⊂Xjv det(∑Xκ,q) = det(∑XK,q* ) = det(Σ) →→. det (Σq*).
Now, we’d like to show
min det (Σq) = det (Σq*) = det(Σ0),	(19)
to complete the proof of Lemma 1.
By the assumption δmcd ≤ 1 - δout , E0 is non-empty. It shows the existence of Σ0 . From the
covariance matrix Σq (18), det(Σq) is a d-th degree polynomial of q as follow:
det(∑q) = det ((1 - q)σ21 + qb―I + q(1 - q)μμτ)
=((1 — q)σ2 + qσ2ut)d-1 ((1 - q)σ2 + qb- + q(1 - q)μτμ).
Since the assumption gives σo2ut > σ2, det(Σq) has the lower bound det(Σ0) as follow:
det(Σq)= ((1 - q)σ2 + qb-)"1 ((1 - q)σ2 + qσ21t + q(1 - q)μτμ)
≥(σ2)d-1 (σ2 + q(1-q)μτ μ)
≥ (σ2)d-1 σ2 =det(∑o).
Then det(Σq) ≥ det(Σ0) for all q ∈ [0,1] and the equality holds for only q = 0. It implies q* = 0
and (19) is the shown. Therefore the mean and covariance matrix of MCD estimator converge almost
surely to μ and σ2I, respectively:
μ a→ μo = μ, Σ → ∑o = σ2I.
This completes the proof of Lemma 1.
11P. Billingsley, Convergence of Probability Measures, John Wiley & Sons, 1999
21