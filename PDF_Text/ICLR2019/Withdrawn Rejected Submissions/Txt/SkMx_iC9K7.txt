Under review as a conference paper at ICLR 2019
DelibGAN: Coarse-to-Fine Text Generation
via Adversarial Network
Anonymous authors
Paper under double-blind review
Ab stract
In this paper, we propose a novel adversarial learning framework, namely Delib-
GAN, for generating high-quality sentences without supervision. Our framework
consists of a coarse-to-fine generator, which contains a first-pass decoder and a
second-pass decoder, and a multiple instance discriminator. And we propose two
training mechanisms DelibGAN-I and DelibGAN-II. The discriminator is used to
fine-tune the second-pass decoder in DelibGAN-I and further evaluate the impor-
tance of each word and tune the first-pass decoder in DelibGAN-II. We compare
our models with several typical and state-of-the-art unsupervised generic text gen-
eration models on three datasets (a synthetic dataset, a descriptive text dataset and
a sentimental text dataset). Both qualitative and quantitative experimental results
show that our models produce more realistic samples, and DelibGAN-II performs
best.
1	Introduction
Building a good text generative model has always been a fundamental problem in the natural
language processing field. The most common generative model is Recurrent Neural Networks
(RNN)(Mikolov et al., 2011), which predicts each word of a sentence conditioned on the previ-
ous word and an evolving hidden state. However, it suffers from two main drawbacks: First, RNN
based models are always trained through the maximum likelihood approach, which suffers from ex-
posure bias(Bengio et al., 2015); Second, the loss function used to train the model is at word level
but the performance is typically evaluated at sentence level(Wang & Wan, 2018a).
Some recent studies have tried to solve these problems. Some approaches work indirectly by mak-
ing the hidden state dynamics predictable (Professor Forcing (Goyal et al., 2016)) or by randomly
adjusting the sampling words during training time (Scheduled Sampling (Bengio et al., 2015)). But
they do not directly specify the cost function on the RNN output to encourage high sample quality.
Later works used Generative Adversarial Networks (GAN)(Goodfellow et al., 2014) or reinforce-
ment learning to directly affect the decoding sequence, such as Gumbel-softmax distribution(Kusner
& Hernandez-Lobato, 2016), SeqGAN(YU et al., 2017), MaskGAN(FedUs et al., 2018), etc. HoW-
ever, they all adopt an one-pass forward decoding , which can only see words that have been decoded.
Recently, coarse-to-fine generator With mUltiple decoders has achieved great sUccess on some tasks.
BUt they either do not define the meaning of the sketch(Xia et al., 2017), or are limited to specific
tasks sUch as logical form parsing, code generation, SQL qUery generation, etc(Lapata & Dong,
2018). And they all are sUpervised learning methods.
Inspired by Deliberation NetWorks(Xia et al., 2017), We propose a novel adversarial learning frame-
Work, namely DelibGAN, for generating high-qUality sentences WithoUt sUpervision. OUr frame-
Work consists of a coarse-to-fine generator and a mUltiple instance discriminator, and the coarse-
to-fine generator contains a first-pass decoder and a second-pass decoder. FUrther, We propose tWo
training mechanisms, named DelibGAN-I and DelibGAN-II. The former one Uses the sentence-
level penalty predicted by the discriminator to fine-tUne the second-pass decoder. And the latter one
imposes the inflUence of Word importance on the first-pass decoder, With the pUrpose of decoding
important Words as mUch as possible in the first pass, and thUs better gUiding the decoding of the
second-pass decoder. The Word importance is obtained throUgh the mUltiple instance learning mech-
anism of the discriminator, Which is Used to directly tUne the first-pass decoder and later gUide the
second-pass decoding. In short, for DelibGAN-I, the discriminator is Used to fine-tUne the second-
1
Under review as a conference paper at ICLR 2019
pass decoder G2, while for DelibGAN-II, the discriminator is further used to evaluate the importance
of each word and tune G1 .
Our motivation is two-fold: (1) We use a coarse-to-fine generator to generate important words (i.e.,
sketch) as much as possible during the first decoding and utilize the global information (i.e., the
sentence decoded in the first pass) at the time of final decoding; (2) The discriminator can evaluate
the sentence-level quality to guide the final generation via policy gradients, moreover, it can provide
word-level importance, which can be used to adjust the sketches in the first-pass generation to make
sense.
We compare our models with several typical and state-of-the-art unsupervised generic text genera-
tion models, including RNNLM(Mikolov et al., 2011), SeqGAN(Yu et al., 2017), SentiGAN(Wang
& Wan, 2018a), MaskGAN(Fedus et al., 2018). Experimental results on three datasets (a synthetic
dataset, a descriptive text dataset and a sentimental text dataset) show that our models can produce
more realistic samples. The major contributions of this paper are summarized as follows:
•	We propose a novel adversarial learning framework - DelibGAN, which consists of a
coarse-to-fine generator and a multiple instance discriminator, to generate high-quality sen-
tences without supervision.
•	We propose two training mechanisms, DelibGAN-I and DelibGAN-II, to make the genera-
tor generate higher-quality sentences.
•	Both qualitative and quantitative results show that DelibGAN-I and DelibGAN-II can pro-
duce more realistic samples, and DelibGAN-II performs best.
2	Framework
2.1	Architecture
The architecture of our proposed DelibGAN is show in Figure1. The entire model consists of two
modules: a coarse-to-fine generator and a multiple instance discriminator. The coarse-to-fine gener-
ator has a first-pass decoder G1 and a second-pass decoder G2 . The multiple instance discriminator
D can evaluate both a whole sentence and each individual word in the sentence by using the multiple
instance learning mechanism, and thus the two decoders can be influenced by the discriminator D
in different ways. In our first training mechanism DelibGAN-I, the sentence-level penalty predicted
by the discriminator is used to fine-tune the second-pass decoder G2. In our second training mecha-
nism DelibGAN-II, in addition to the fine-tuning of G2 , the word-level importance is predicted and
used to tune G1, to make G1 decode important words as much as possible, and thus better guide the
decoding of G2 .
Coarse-to-fine Generator
Figure 1: The architecture of DelibGAN. Two training mechanisms DelibGAN-I and DelibGAN-II
are detailed in section 2.4.
2
Under review as a conference paper at ICLR 2019
2.2	Coarse-to-fine Generator
Inspired by Deliberation Networks(Xia et al., 2017), we propose a coarse-to-fine generator with the
following two purposes: The first is to enable the generator to utilize the global information (i.e., the
sentence decoded in the first pass) at the time of final decoding, rather than only the sequence that
has been decoded; The second is to force the generator to generate important words (i.e., sketch) as
much as possible during the first-pass decoding, so as to provide more useful clues for decoding in
the second pass.
Our coarse-to-fine generator contains a first-pass decoder G1 and a second-pass decoder G2 . Both
decoders are RNN and can be easily replaced with its variants such as LSTM and GRU (In this work,
we use LSTM). The prior input noise z sampled from a distribution Pz (e.g., a normal distribution) is
used to initialize the input of Gι, then Gi will generate a first-pass sequence X = {x^ι, x¾ •…百力，and
a series of hidden states H = {hi, h2 …h√}, where l is the length of the generated sequence. At
step t, ht is calculated as h = RNN(f (Xt-1), ht-ι), where f is a word embedding representation
function. Then h is fed into a softmax layer, and Xt is sampled out from the obtained multinomial
distribution. Finally, the first-pass output sequence X is generated by Gi.
In the second-pass decoding, we take the hidden state of the last moment of Gi as the initial hidden
state of G2 . And we use an attention model in G2, Specifically, at step t, the attention model in G2
first generates a context ct defined as follows:
ll
Ct = Eaihi； ai H exp (vT tanh(Watthi + Uattht-i))∀i ∈ [1,l]; Eai = 1.	(1)
i=i	i=i
After receiving ct, we calculate the hidden state ht as ht = RNN([f(xt-i); ct], ht-i). Then xt is
sampled in the same way of sampling Xt, and the second-pass output sequence X is generated and
its length is m.
2.3	Multiple Instance Discriminator
Like Yu et al. (2017) and Wang & Wan (2018a), in order to evaluate the performance of a generator
at the sentence-level, we use a discriminator to calculate rewards. Further, we want to get the impor-
tance of each word in the sentence to adjust the generator to decode the important words as much
as possible in the first-pass decoding. Thus we adopt a multi-instance learning (MIL) mechanism in
our discriminator. MIL deals with problems where labels are associated with groups of instances or
bags (sentences in our case), while instance labels (word-level importance) are unobserved (Keeler
& Rumelhart, 1991; Zhang et al., 2002; Wang & Wan, 2018b).
Our multiple instance discriminator D uses a structure similar to a bidirectional RNN. Supposing
the input to D is a sentence W = {w1,w2, •…，Wn}, where n is the length of w. We apply a
bidirectional LSTM on the sentence, and for each word wt(t ∈ n), we concatenate its corresponding
forward and backward hidden state vectors:
→ = LST→(wt); S- = LSTM(wt); st = →||S-,	⑵
where LSTM(Wt) and LSTM(Wt) represent the forward and backward LSTM hidden state vectors
for wt . Then we use a softmax classifier to get the word-level probability distribution over target
labels (i.e., real and f ake).
pt = softmax(tanh(Wdst + bd), where pt = [p(rte)al, p(fta)ke]; p(rte)al + p(fta)ke = 1.	(3)
p(rte)al and p(fta)ke represent the probability that the t-th word is predicted to be real and fake, re-
spectively; Wd and bd are parameters, shared across all words. Finally, we use the average of the
word-level distribution as the sentence-level distribution over the target labels:
1n
pi = n£p(t), ∀i ∈ {real, fake}; P = [Preal Make].
t=i
(4)
3
Under review as a conference paper at ICLR 2019
2.4	Training
Here we introduce the adversarial training of the generator and the discriminator in detail. In this
paper, we formalize the text generation problem as a sequential decision making process (Bachman
& Precup, 2015), which solves the problem that the gradient cannot pass back to the generative
model when the output is discrete. Moreover, we use policy gradients to update parameters of the
generator.
We propose two loss functions for the generator, named DelibGAN-I and DelibGAN-II. DelibGAN-
I just forces the first-pass decoder G1 to maintain the same decoding result, while DelibGAN-II
utilizes the result of the discriminator at the word level, forcing G1 to decode important words
(evaluated by the discriminator) as much as possible. But for the second-pass decoder G2 , both
of them use the penalty-based objective function (Wang & Wan, 2018a) to update the parameters
θG2 of G2 . Specifically, at each timestep t, the existing sequence generated by G2 is x1:t-1 =
{x1, ..., xt-1}, and the next token xt selected in the next step is an action sampling from the policy
G2(xt|x1:t-1; θG2), and we use the Monte Carlo rollouts method (Dai et al., 2017; Yu et al., 2017)
to simulate intermediate penalty RθG ,θD (xt), where θD is the parameters of the discriminator D.
Then, the total penalty of G2 can be computed by:
m
Ex〜G2(x) = E[(RθG2,θD (Xt)- b)G2(xt|xi：t-i； θG2)]
t=1
mq
=∑⅛(E(1- D(xt|x(1j:t)-1; θD))) - b)G2(xt|x1:t-1; θG2)],
t=1 q j=1
(5)
where b is the bias, x(1j:t)-1 is the q-time Monte Carlo search sampled based on the roll-out policy
G2(xt|xi：t—i； θG2), and D(xt|x1j?-i； Θd) is the sentence probability Preal given by the discrimina-
tor for sentence x(1j:t)-1 ||xt.
DelibGAN-I: For DelibGAN-I, we just force the first-pass decoder G1 to maintain the same de-
Coding result. Specifically, after we use (Gι, G2) to sample a pair of sentences (X, x), we first use
the discriminator to calculate the sentence-level penalties. Then in the process of using penalties to
update the generator, We force the first-pass decoder Gi to decode the same result, which is X. The
loss of generator G1 (the parameters are denoted as θG1 ) is defined as follows:
1
Ex,G1 (X) = 7 ETOg(GI(Xt|x1：t-1； θG1 ))
t=1
(6)
we propose it with the purpose of keeping the results of G1 as constant as possible, and just fine-
tuning G2 based on the sentence-level penalty mentioned above. Finally, the objective of the gener-
ator is to minimize:
1
jG11G2 (θGι ,θG2) = Ex2g1 (X) + Ex 〜G2(x) = 7 ETOg(G1(Xt|X1：t-1； θG1))
t=1
m1q
+ ∑[(-(∑(1 -D(xt∣x1j)-i; θD)))-b)G2(xt∣Xrt-i; θG2)].
t=1 q j=1
(7)
DelibGAN-II: For DelibGAN-II, we want to impose direct influence to G1, forcing it to decode
important words as much as possible in the first-pass decoding, to better guide the decoding of G2 .
We tried different ways of influencing, including using sentence-level penalties like Eq5, but finally
we introduced and leveraged a multi-instance learning mechanism in the discriminator. This is
because it can provide the importance of words in a sentence, and we add the word-level importance
to the loss as weights. So the loss of generator G1 is changed as follows:
-l
EXrGi (X) = 7 X -Pre)al * * log(G1(Xt|X1：t-1； θGι))
t=1
(8)
4
Under review as a conference paper at ICLR 2019
where Preal is the probability that the discriminator predicts Xt as real. Therefore, the objective of
the generator is to minimize the total loss:
1l
JlGJG2 (θGι ,θG2 ) = Ex 〜G1 (X) + Ex 〜G2(X) = 7 E-Preal(X)log(GI(Xt|x1:t-1； θGI))
m	q	t=1	(9)
+yq (X(i - D(Xt|X(1j:t)-1; θD))) - b)G2(Xt|X1:t-1; θG2)].
For discriminator D, the goal is to distinguish between real text and generated text as much as
possible. It is worth noting that we only have the target label for the sentence, but do not have labels
on words. The objective function of the discriminator is to minimize:
JD (θD ) = -Ex 〜G log Pfake - Ex 〜S log “real，	Q0)
where S is real sentences in the corpus. We perform the adversarial training of the generator and the
discriminator, and train them alternately, as shown in Algorithm 1.
Algorithm 1 The adversarial training process in DelibGAN
Input: Input noise, z; Generator, (G1 , G2); Discriminator, D; Real text dataset, S;
Output: Well trained generator, (G1 , G2);
1:	Initialize (G1 , G2 ),D with random weights;
2:	Pre-train (G1 , G2) using MLE on S;
3:	repeat
4:	for d-steps do
5:	Generate fake texts ({X}, {x}) using (Gι, G2);
6:	Update D using ({x}, S) by minimizing Eq 10;
7:	end for
8:	for g-steps do
9:	Generate fake texts ({X}, {x}) using (Gι, G2);
10:	Calculate penalty Ex^G2 (x) by Eq (5);
11:	For DelibGAN-I, Update (G1 , G2) by minimizing Eq (7);
12:	For DelibGAN-II, Update (G1 , G2) by minimizing Eq (9);
13:	end for
14:	until Model converges
15:	return ;
3	Experiments
3.1	Setup
In this study, we hope that our unsupervised models can generate sentences with higher quality.
Without loss of generality, we evaluate our model 1 on three benchmark datasets: a synthetic dataset,
a descriptive text dataset and a sentimental text dataset. We compare with several typical and state-
of-the-art unsupervised generic text generation models, including RNNLM(Mikolov et al., 2011),
SeqGAN(Yu et al., 2017), SentiGAN(Wang & Wan, 2018a), MaskGAN(Fedus et al., 2018). It is
worth noting that pre-training was used for all selected baselines.
After training models, we let them generate 1k sentences each. Measuring the quality of gener-
ated sentences has always been a difficult problem. For synthetic data, we have an oracle model to
measure the negative log-likelihood (NLL) scores. But for real texts, we use automatic quantitative
indicators (e.g., Fluency, Novelty and Diversity) and human evaluation methods (e.g., Grammatical-
ity, Topicality and Overall) to evaluate the quality of generated sentences.
For automatic quantitative indicators, same as Wang & Wan (2018a), we use a language modeling
toolkit - SRILM (Stolcke, 2002) to test the fluency of generated sentences, which calculates the
perplexity of generated sentences using the language model trained on respective corpus. In addition,
1We will release the source codes of our methods upon the acceptance of this paper.
5
Under review as a conference paper at ICLR 2019
Table 1: The performance comparison on the synthetic data in terms of the NLL scores.
Methods	MLE SeqGAN SentiGAN DelibMLE DelibGAN-I DelibGAN-II
NLL	9.038	8.736	6.924	8.604	5.594	5.250
given the generated sentence set A and its training corpus set B, the novelty N ovelty(A|B) and the
diversity Diversity(A) are defined as follows:
Novelty(A∣B)= 1- X(1 - max{夕(i,j);∀j ∈ B}),	(11)
i∈A
Diversity(A) = ι⅛ X(I -max{夕(i,j);∀j ∈ A∖{i}}),	(12)
i∈A
夕 is the Jaccard similarity function. It is worth noting that in terms of the fluency indicator, a smaller
value is better, but the novelty and diversity indicators are just the opposite.
For human evaluation, we randomly extracted 100 sentences from the generated sentences, and
then let five experts rate each sentence according to its “grammaticality”, “topicality” and “overall”
aspects, where “topicality” indicates whether the sentence accords with the topic/genre of the dataset
(i.e., happy moment and sentimental text for the two real datasets, respectively). Scores range from
1 to 5, with 5 being the best. We finally calculate the average of the scores.
3.2	Simulation on Synthetic Data
Here we use the synthetic dataset2 used by Yu et al. (2017), which consists of a set of sequential
tokens which can be seen as the simulated data comparing to the real-word language data. Moreover,
it automatically evaluates the negative log-likelihood (NLL) scores of our generated sequences,
which brings us convenience. We compare our model with various models on this dataset, as shown
in Table 1 and Figure 2. It is worth noting that the DelibMLE method is just using our coarse-to-fine
generator.
Figure 2: The illustration of learning curves. Dotted line is the end of pre-training.
From the results, we can see that: (1) Our coarse-to-fine generator (DelibMLE) performs better and
even outperforms seqGAN. (2) Our proposed methods DelibGAN-I and DelibGAN-II outperform
all other competitors with a large margin which means the framework we proposed is better than
2The synthetic data and the oracle model (LSTM model) are publicly available at
https://github.com/LantaoYu/SeqGAN
6
Under review as a conference paper at ICLR 2019
Table 2: Comparison of automatic quantitative indicators of generated sentences on HappyDB cor-
pus. J means that the smaller the better, and ↑ is the opposite.
Methods	SeqGAN	SentiGAN	MaskGAN	DelibMLE	DelibGAN-I	DelibGAN-II
Fluency(J)	156.212	130.655	121.273	138.353	105.593	98.348
Novelty(↑)	0.275	0.324	0.267	0.305	0.359	0.399
Diversity(↑)	0.694	0.732	0.753	0.723	0.765	0.767
Table 3: Comparison of human evaluation of generated sentences on HappyDB corpus.
Methods	SeqGAN	SentiGAN	MaskGAN	DelibMLE	DelibGAN-I	DelibGAN-II
Grammaticality	2.256	2.694	3348^^	2.438	3.864	3.871
Topicality	2.331	2.652	3.361	3.237	3.763	4.026
Overall	2.384	2.698	3.525	2.752	3.644	3.836
the other models in capturing the dependency of the sequential tokens. (3) DelibGAN-II is better
than DelibGAN-I, which indicates that it is useful to use the word-level information given by the
discriminator during the first-pass decoding.
3.3	Results on Descriptive Text Data
In this section, we validate our model on the descriptive text corpus: HappyDB(Asai et al., 2018).
HappyDB is a corpus of 100,000+ crowd-sourced happy moments. Its content is mainly about
events that make people happy in the past, and 83% of corpora contain only one sentence. We
only use those instances that contain one sentence, and we get a total of 83711 happy moments.
Table 2 shows the results on the automatic quantitative indicators, and we can see that DelibGAN-I
and DelibGAN-II perform exceptionally well, with the ability of keeping the fluency of sentences,
generating sentences different from that in the training corpus and generating a variety of sentences.
Further, we use human evaluation to evaluate generated sentences. Table 3 shows the results, and
we can see DelibGAN-I and DelibGAN-II outperform other models, especially in topicality.
3.4	Results on Sentimental Text Data
Here we validate our model on the sentimental text corpus: Stanford Sentiment Treebank (SSTB,
Socher et al. (2013)), which contains 9613 sentimental reviews of movies. Tables 4 and 5 show the
results of automatic quantitative indicators and human evaluation, respectively. Both results show
that our models DelibGAN-I and DelibGAN-II produce more realistic samples of sentimental texts
than other models, and DelibGAN-II performs best.
3.4.1	Case S tudy
In Table 6, we show example sentences generated by DelibMLE, DelibGAN-I and DelibGAN-II.
From the examples, we can see that: (1) In DelibMLE, there is no significant correlation between the
first-pass decoding result G1 and the second-pass decoding result G2. (2) Compared with DelibGAN-
I, DelibGAN-II is more likely to decode important words in G1 , and those words behave like key-
words in HappyDB and sentiment words in SSTB.
Table 4: Comparison of automatic quantitative indicators of generated sentences on SSTB corpus.
J means that the smaller the better, and ↑ is the opposite.
Methods	SeqGAN	SentiGAN	MaskGAN	DelibMLE	DelibGAN-I	DelibGAN-II
Fluency(J)	98.253	82.554	^^83.967^^	89.365	75.573	71.365
Novelty(↑)	0.298	0.344	0.342	0.348	0.387	0.393
Diversity(↑)	0.641	0.711	0.723	0.673	0.734	0.740
7
Under review as a conference paper at ICLR 2019
Table 5: Comparison of human evaluation of generated sentences on SSTB corpus.
Methods	SeqGAN	SentiGAN	MaskGAN	DelibMLE	DelibGAN-I	DelibGAN-II
Grammaticality	2.534	3.712	3.826^^	3.529	3.684	4.037
Topicality	2.164	3.231	3.567	3.471	3.973	4.304
Overall	2.865	3.284	3.483	3.197	4.082	4.243
Table 6: Examples sentences generated by our models trained on HaPPyDB and SSTB.
	DelibMLE	G1	i got out . had a money money . .
		G2	i worked extra and well donut with really well recently .
HappyDB	DelibGAN-I	G1	i got a new car...
Corpus		G2	i purchased a new car for my family .
	DelibGAN-II	G1	i friends to to visit a games . weekend
		G2	our friends came over to play video game last weekend.
	DelibMLE	G1	my <UNK>review : deeply deeply romantic film that cynicism
		G2	fantastic summer thrill ride !
SSTB	DelibGAN-I	G1	it was < UNK>.
Corpus		G2	it was a very important classic !
	DelibGAN-II	G1	it funny . < UNK > us .
		G2	a funny story for the former child star in all of us
4	Related Work
Unsupervised text generation models are usually based on RNN(Mikolov et al., 2011), which eas-
ily suffers from exposure bias(Bengio et al., 2015) and the inconsistency between word-level loss
function and sentence-level evaluation(Wang & Wan, 2018a). Several strategies have been exploited
later, including Professor Forcing (Goyal et al., 2016), Scheduled SamplingBengio et al. (2015) and
MaskMLE(Fedus et al., 2018).
Generative Adversarial Networks (GAN)(Goodfellow et al., 2014) has also been applied for text
generation. Due to the non-differentiable problem and more complex modes of languages, the qual-
ity of generated texts are usually not very satisfactory. Some studies apply GAN in text generation by
modifying the word prediction function, such as GUmbel-SOftmax distribUtiOn(KUSner & Hernandez-
Lobato, 2016). Some other works apply reinforcement learning to solve the non-differentiable prob-
lem, including SeqGAN(Yu et al., 2017), LeakGAN(Guo et al., 2018), RankGAN(Lin et al., 2017),
SentiGAN(Wang & Wan, 2018a) and MaskGAN(Fedus et al., 2018). However, they all adopt an
one-pass forward decoding , which can only see words that have been decoded.
Recently, Deliberation networks(Xia et al., 2017), which has two decoders and produces better se-
quences by modifying sketches, has achieved good results on machine translation tasks. Later, La-
pata & Dong (2018) also propose a similar structure and make meaningful settings for the sketches.
But this is limited to specific tasks such as logical form parsing, code generation and SQL query
generation. Moreover, these methods are supervised learning methods.
Multiple Instance Learning (MIL)(Keeler & Rumelhart, 1991) deals with problems where labels are
associated with groups of instances or bags (sentences in our case), while instance labels (word-level
importance in our case) are unobserved. The initial MIL makes a strong assumption that a bag is
negative only if all of its instances are negative, and positive otherwise(Dietterich et al., 1997; Maron
& Ratan, 1998; Zhang et al., 2002), and subsequent works relax this assumption and make it more
suitable for the task at hand(Cour et al., 2011; Kotzias et al., 2015; Wang & Wan, 2018b).
5	Conclusions and Future Work
In this paper, we propose a novel adversarial learning framework DelibGAN to generate high-quality
sentences without supervision, by making use of a coarse-to-fine generator and a multiple instance
discriminator. Evaluation results on various datasets verifies the efficacy of our proposed models.
In future work, we will try to make the sketch more meaningful and apply our framework to more
tasks.
8
Under review as a conference paper at ICLR 2019
References
Akari Asai, Sara Evensen, Behzad Golshan, Alon Y. Halevy, Vivian Li, Andrei Lopatenko, Daniela
Stepanov, Yoshihiko Suhara, Wang-Chiew Tan, and Yinzhan Xu. Happydb: A corpus of 100,
000 crowdsourced happy moments. In Proceedings of the Eleventh International Conference on
Language Resources and Evaluation, LREC 2018, Miyazaki, Japan, May 7-12, 2018., 2018.
Philip Bachman and Doina Precup. Data generation as sequential decision making. In Advances in
Neural Information Processing Systems 28: Annual Conference on Neural Information Process-
ing Systems 2015, December 7-12,2015, Montreal, Quebec, Canada, pp. 3249-3257, 2015.
Samy Bengio, Oriol Vinyals, Navdeep Jaitly, and Noam Shazeer. Scheduled sampling for sequence
prediction with recurrent neural networks. In Advances in Neural Information Processing Systems
28: Annual Conference on Neural Information Processing Systems 2015, December 7-12, 2015,
Montreal, Quebec, Canada, pp. 1171-1179, 2015.
Timothee Cour, Ben Sapp, and Ben Taskar. Learning from partial labels. Journal of Machine
Learning Research, 12(4):1501-1536, 2011.
Bo Dai, Sanja Fidler, Raquel Urtasun, and Dahua Lin. Towards diverse and natural image descrip-
tions via a conditional GAN. In IEEE International Conference on Computer Vision, ICCV 2017,
Venice, Italy, October 22-29, 2017, pp. 2989-2998, 2017. doi: 10.1109/ICCV.2017.323.
Thomas G. Dietterich, Richard H. Lathrop, and Tomas Lozano-Perez. Solving the multiple in-
stance problem with axis-parallel rectangles. Artif. Intell., 89(1-2):31-71, 1997. doi: 10.1016/
S0004-3702(96)00034-3.
William Fedus, Ian J. Goodfellow, and Andrew M. Dai. Maskgan: Better text generation via filling
in the In ICLR, 2018, 2018.
Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair,
Aaron C. Courville, and Yoshua Bengio. Generative adversarial nets. In Advances in Neural In-
formation Processing Systems 27: Annual Conference on Neural Information Processing Systems
2014, December 8-13 2014, Montreal, Quebec, Canada, pp. 2672-2680, 2014.
Anirudh Goyal, Alex Lamb, Ying Zhang, Saizheng Zhang, Aaron C. Courville, and Yoshua Bengio.
Professor forcing: A new algorithm for training recurrent networks. In Advances in Neural In-
formation Processing Systems 29: Annual Conference on Neural Information Processing Systems
2016, December 5-10, 2016, Barcelona, Spain, pp. 4601-4609, 2016.
Jiaxian Guo, Sidi Lu, Han Cai, Weinan Zhang, Yong Yu, and Jun Wang. Long text generation via ad-
versarial training with leaked information. In Proceedings of the Thirty-Second AAAI Conference
on Artificial Intelligence, New Orleans, Louisiana, USA, February 2-7, 2018, 2018.
James D. Keeler and David E. Rumelhart. A self-organizing integrated segmentation and recognition
neural net. In Advances in Neural Information Processing Systems 4, [NIPS Conference, Denver,
Colorado, USA, December 2-5, 1991], pp. 496-503, 1991.
Dimitrios Kotzias, Misha Denil, Nando De Freitas, and Padhraic Smyth. From group to individual
labels using deep features. In ACM SIGKDD International Conference on Knowledge Discovery
and Data Mining, pp. 597-606, 2015.
Matt J. KUsner and Jose MigUel Hernandez-Lobato. GANS for sequences of discrete elements with
the gumbel-softmax distribution. CoRR, abs/1611.04051, 2016.
Mirella Lapata and Li Dong. Coarse-to-fine decoding for neural semantic parsing. In Proceedings of
the 56th Annual Meeting of the Association for Computational Linguistics, ACL 2018, Melbourne,
Australia, July 15-20, 2018, Volume 1: Long Papers, pp. 731-742, 2018.
Kevin Lin, Dianqi Li, Xiaodong He, Ming-Ting Sun, and Zhengyou Zhang. Adversarial ranking
for language generation. In Advances in Neural Information Processing Systems 30: Annual
Conference on Neural Information Processing Systems 2017, 4-9 December 2017, Long Beach,
CA, USA, pp. 3158-3168, 2017.
9
Under review as a conference paper at ICLR 2019
Oded Maron and Aparna Lakshmi Ratan. Multiple-instance learning for natural scene classification.
In Proceedings of the Fifteenth International Conference on Machine Learning (ICML 1998),
Madison Wisconsin, USA, July 24-27, 1998,pp. 341-349,1998.
Tomas Mikolov, Stefan Kombrink, LUkas BUrgeL Jan Cernocky, and Sanjeev KhUdanpur. Exten-
sions of recurrent neural network language model. In Proceedings of the IEEE International Con-
ference on Acoustics, Speech, and Signal Processing, ICASSP 2011, May 22-27, 2011, Prague
Congress Center, Prague, Czech Republic, pp. 5528-5531, 2011. doi: 10.1109/ICASSP.2011.
5947611.
Richard Socher, Alex Perelygin, Jean WU, Jason ChUang, Christopher D. Manning, Andrew Y. Ng,
and Christopher Potts. RecUrsive deep models for semantic compositionality over a sentiment
treebank. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language
Processing, EMNLP 2013, 18-21 October 2013, Grand Hyatt Seattle, Seattle, Washington, USA,
A meeting of SIGDAT, a Special Interest Group of the ACL, pp. 1631-1642, 2013.
Andreas Stolcke. Srilm an extensible langUage modeling toolkit. 2002.
Ke Wang and XiaojUn Wan. Sentigan: Generating sentimental texts via mixtUre adversarial net-
works. In Proceedings of the Twenty-Seventh International Joint Conference on Artificial In-
telligence, IJCAI 2018, July 13-19, 2018, Stockholm, Sweden., pp. 4446-4452, 2018a. doi:
10.24963/ijcai.2018/618.
Ke Wang and XiaojUn Wan. Sentiment analysis of peer review texts for scholarly papers. In The
41st International ACM SIGIR Conference on Research & Development in Information Retrieval,
SIGIR 2018, Ann Arbor, MI, USA, July 08-12, 2018, pp. 175-184, 2018b. doi: 10.1145/3209978.
3210056.
Yingce Xia, Fei Tian, LijUn WU, Jianxin Lin, Tao Qin, Nenghai YU, and Tie-Yan LiU. Deliberation
networks: SeqUence generation beyond one-pass decoding. In Advances in Neural Information
Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017, 4-9
December 2017, Long Beach, CA, USA, pp. 1782-1792, 2017.
Lantao YU, Weinan Zhang, JUn Wang, and Yong YU. Seqgan: SeqUence generative adversarial nets
with policy gradient. In Proceedings of the Thirty-First AAAI Conference on Artificial Intelli-
gence, February 4-9, 2017, San Francisco, California, USA., pp. 2852-2858, 2017.
Qi Zhang, Sally A. Goldman, Wei YU, and Jason Fritts. Content-based image retrieval Using
mUltiple-instance learning. In Nineteenth International Conference on Machine Learning, pp.
682-689, 2002.
10