Under review as a conference paper at ICLR 2019

THE  EXPRESSIVE  POWER  OF  GATED  RECURRENT  UNITS
AS  A  CONTINUOUS  DYNAMICAL  SYSTEM

Anonymous authors

Paper under double-blind review

ABSTRACT

Gated recurrent units (GRUs) were inspired by the common gated recurrent unit, long short-term
memory (LSTM), as a means of capturing temporal structure with less complex memory unit archi-
tecture.  Despite their incredible success in tasks such as natural and artificial language 
processing,
speech, video, and polyphonic music, very little is understood about the specific dynamic features
representable in a GRU network. As a result, it is difficult to know a priori how successful a GRU-
RNN    will perform on a given data set.  In this paper, we develop a new theoretical framework to
analyze one and two dimensional GRUs as a continuous dynamical system,  and classify the dy-
namical features obtainable with such system.  We found rich repertoire that includes stable limit
cycles over time (nonlinear oscillations), multi-stable state transitions with various topologies, 
and
homoclinic orbits.  In addition, we show that any finite dimensional GRU cannot precisely repli-
cate    the dynamics of a ring attractor, or more generally, any continuous attractor, and is 
limited to
finitely many isolated fixed points in theory. These findings were then experimentally verified in 
two
dimensions by means of time series prediction.

1    INTRODUCTION

Recurrent neural networks (RNNs) have been widely used to capture and utilize sequential structure 
in natural and
artificial languages,  speech,  video,  and various other forms of time series.   The recurrent 
information flow within
RNN implies that the data seen in the past has influence on the current state of the RNN, forming a 
mechanism for
having memory through (nonlinear) temporal traces.  Unfortunately, training vanilla RNNs (which 
allow input data
to directly interact with the hidden state) to capture long-range dependences within a sequence is 
challenging due to
the vanishing gradient problem (Hochreiter, 1991). Several special RNN architectures have been 
proposed to mitigate
this issue, notably the long short-term memory (LSTM; Hochreiter & Schmidhuber (1997)) which 
explicitly guards
against unwanted corruption of the information stored in the hidden state until necessary.  
Recently, a simplification
of the LSTM called the gated recurrent unit (GRU; Cho et al. (2014)) has become wildly popular in 
the machine
learning community thanks to its performance in machine translation (Britz et al., 2017), speech 
(Prabhavalkar et al.,
2017), music (Choi et al., 2017), video (Dwibedi et al., 2018), and extracting nonlinear dynamics 
underlying neural
data (Pandarinath et al., 2018).  As a variant of the vanilla LSTM, GRUs incorporate the use of 
forget gates, but lack
an output gate (Gers et al., 2000).  While this feature reduces the number of required parameters, 
LSTM has been
shown to outperform GRU on neural machine translation (Britz et al., 2017).  In addition, certain 
mechanistic tasks,
specifically unbounded counting, come easy to LSTM networks but not to GRU networks (Weiss et al., 
2018). Despite
these empirical findings, we lack systematic understanding of the internal time evolution of GRU’s 
memory structure
and its capability to represent nonlinear temporal dynamics.

In general, a RNN can be written as ht₊₁ = f (ht, xt) where xt is the current input in a sequence 
indexed by t, f is a
point-wise nonlinear function, and ht represents the hidden memory state that carries all 
information responsible for
future output. In the absence of input, the hidden state ht can evolve over time on its own:

ht₊₁ = f (ht)                                                                                (1)

where f ( )  :=  f ( , 0) for notational simplicity.  In other words, we can consider the temporal 
evolution of memory
stored within RNN as a trajectory of a dynamical system defined by (1). Then we can use dynamical 
systems theory to
investigate the fundamental limits in the expressive power of RNNs in terms of their temporal 
features. We develop a
novel theoretical framework to study the dynamical features fundamentally attainable, in 
particular, given the particular
form of GRU. We then validate the theory by training GRUs to predict time series with prescribed 
dynamics.

1


Under review as a conference paper at ICLR 2019

2    CONTINUOUS-TIME  GATED  RECURRENT  UNIT

The GRU uses two internal gating variables: the update gate zt which protects the d-dimensional 
hidden state ht ∈ Rd
and the reset gate rt which allows overwriting of the hidden state and controls the interaction 
with the input xt ∈ Rp.
zt =                        σ(Wzxt +Uzht−₁ + bz)                                       (update 
gate)                       (2)

rt =                        σ(Wrxt +Urht−₁ + br)                                          (reset 
gate)                       (3)

ht = (1 − zt)Ⓢtanh(Whxt+Uh(rt Ⓢ ht−₁ + bh)) + zt Ⓢ ht−₁   (hidden state)                       (4)

where Wz, Wr, Wh    Rd×p and Uz, Ur, Uh    Rd×d are the parameter matrices, bz, br, bh    Rd are 
bias vectors,
represents the Hadamard product, and σ(z) = 1/(1 + e−ᶻ) is the element-wise logistic sigmoid 
function. Note that
the  hidden state is asymptotically contained within [   1, 1]ᵈ due to the saturating 
nonlinearities, implying if the state

is initialized outside of this trapping region, it must eventually enter it in finite time and 
remain in it for all later time.

Note that the update gate zt controls how fast each dimension at the hidden state decays, providing 
an adaptive time
constant for memory.   Specifically,  as limzt      0 ht  =  ht  ₁,  GRUs can implement perfect 
memory of the past and
ignore xt. Hence, a d-dimensional GRU is capable of keeping a near constant memory through the 
update gate—near
constant since 0  <  [zt]j  <  1, where [ ]j denotes j-th component of a vector.  Moreover, the 
autoregressive weights
(mainly Uh and Ur) can support time evolving memory (Laurent & von Brecht (2016)) considered this a 
hindrance
and proposed removing all complex dynamic behavior in a simplified GRU).

To investigate the memory structure further, let us consider the dynamics of hidden state in the 
absence of input, i.e.
xt =  0,   t, which is of the form (1).  To utilize the rich descriptive language of continuous 
time dynamical system
theory, we consider the following continuous time limit of the (autonomous) GRU time evolution:

z(t) = σ(Uzh(t) + bz)                                                                               
            (continuous update gate)      (5)

r(t) = σ(Urh(t) + br)                                                                               
                (continuous reset gate)      (6)

h˙  = (z(t) − 1) Ⓢ (h(t) − tanh(Uh(r(t) Ⓢ h(t)) + bh))               (continuous hidden state 
dynamics)      (7)

where h˙  ≡   dt  .  Since both σ(·) and tanh(·) are smooth, this continuous limit is justified.  
The update gate z(t)

again plays the role of a state-dependent time constant for memory decay.  Furthermore, since 1     
z(t) > 0, it does
not change the topological structure of the dynamics (only speed). For the following theoretical 
analysis sections (3 &
4), we can safely ignore the effects of z(t). A derivation of the continuous-time GRU can be found 
in appendix A.

3    STABILITY  ANALYSIS  OF  A  ONE  DIMENSIONAL  GRU

For a single GRU∗ (d = 1), (7) reduces to a one dimensional dynamical system where every variable 
is a scalar. The
expressive power of a single GRU is quite limited, as only three stability structures (topologies) 
exist (see appendix B):

(A) a single stable node, (B) a stable node and a half-stable node, and (C) two stable nodes 
separated by an unstable
node (see Fig. 1). The corresponding temporal features are (A) decay to a fixed value, (B) decay to 
a fixed value, but
from one direction halt at an intermediate value until perturbed, or (C) decay to one of two fixed 
values (bistability).
The bistability can be used to capture a binary latent state in the sequence.  It should be noted 
that a one dimensional
continuous time autonomous system cannot exhibit oscillatory behavior, as is the case here (Hirsch 
et al., 2013).

A                                                                                     B             
                                                                     C


stable fixed point

half-stable fixed point

unstable fixed point

0                                                                                    0              
                                                                     0

Figure 1:  Three possible types of one dimensional flow for a single GRU. When h˙  >  0, h(t) 
increases.  This flow

is indicated by a rightward arrow.  Nodes (  h    h˙ (h) = 0  ) are represented as circles and 
classified by their stability

(Meiss, 2007).

The topology the GRU takes is determined by its parameters.  If the GRU begins in a region of the 
parameter space
corresponding to (A), we can smoothly vary the parameters to transverse (B) in the parameter space, 
and end up at (C).

∗The number/dimension of GRUs referenced will indicate the dimension of the latent dynamics of a 
GRU network.

2


Under review as a conference paper at ICLR 2019

This is commonly known as a saddle-node bifurcation.  Speaking generally, a bifurcation is the 
change in topology
of a dynamical system, resulting from a smooth change in parameters.  The point in the parameters 
space at which
the bifurcation occurs is called the bifurcation point, and we will refer to the fixed point that 
changes its stability at
the bifurcation point as the bifurcation fixed point. This corresponds to the parameters underlying 
(B) in our previous
example.   The codimension of a bifurcation is the number of parameters which must vary in order to 
achieve the
bifurcation.  In the case of our example, a saddle-node bifurcation is codimension-1 (Kuznetsov, 
1998).  Right before
transitioning to (B), from (A), the flow near where the half-stable node would appear can exhibit 
arbitrarily slow flow.
We      will refer to these as slow points (Sussillo & Barak, 2012).

4    ANALYSIS  OF  A  TWO  DIMENSIONAL  GRU

We will see that the addition of a second GRU opens up a substantial variety of possible 
topological structures when
compared with the use of a single GRU. For notational simplicity, we denote the two dimensions of h 
as x and y. We
visualize the flow fields defined by (7) in 2-dimension as phase portraits which reveal the 
topological structures of
interest.  For starters, the phase portrait of two independent bistable GRUs can be visualized as 
Figure 2A. It clearly
shows 4 stable states as expected, with a total of 9 stable fixed points.  This could be thought of 
as a continuous-
time continuous-space implementation of a finite state machine with 4 states (Fig. 2B). The 3 types 
of observed fixed
points—stable (sinks),  unstable (sources),  and saddle points—exhibit locally linear dynamics,  
however,  the global
geometry    is nonlinear and their topological structures can vary depending on their arrangement.


A

1.5

example
trajectories

nullcline

log speed            B

-1

(hidden) Markov Chain /
Finite State Machine


-1.5

1

-2

01                       11

0.5                                                                                     -2.5


0

-0.5

-3

-3.5

-4

00                       10


-1

-1.5

-1.5       -1       -0.5        0        0.5        1        1.5

-4.5

-5

sink (stable node point)
saddle point

source (unstable node point)

Figure 2:  Illustrative example of two independent bistable GRUs.  (A) Phase portrait.  The flow 
field h˙   =  [x˙, y˙]T

is decomposed into direction (black arrows) and speed (color).  Purple lines represent trajectories 
of the hidden state
which converge to one of the four stable fixed points. Note the four quadrants coincide with the 
basin of attraction for
each of the stable nodes. The fixed points appear when the x- and y-nullclines intersect. (B) The 
four stable nodes of
this system can be interpreted as a continuous analogue of 4-discrete states with input-driven 
transitions.

We explored stability structures attainable by two GRUs.  Due to the relatively large number of 
observed topologies,
this section’s main focus will be on demonstrating all observed local dynamical features obtainable 
by two GRUs.
In addition,  existence of two non-local dynamical features will be presented.   A complete catalog 
of all observed
topologies can be found in the appendix C, along with the parameters of every phase portrait 
depicted in this paper.

Before  proceeding,  let  us  take  this  time  to  describe  all  the  local  dynamical  features  
observed.   In  addition  to  the
previously mentioned three types of fixed points, two GRUs can exhibit a variety of bifurcation 
fixed points, resulting
from regions of parameter space that separate all topologies restricted to simple fixed points (i.e 
stable, unstable, and
saddle points). Behaviorally speaking, these fixed points act as hybrids between the previous 
three, resulting in a much
richer set of obtainable dynamics.  These bifurcation fixed points fall into two categories, 
separated by codimension.
More specifically, two GRUs have been seen to feature both codimension-1 and codimension-2 
bifurcation (fixed)
points. Beginning with codimension-1, we have the saddle-node bifurcation fixed point, as expected 
from its existence
in the single GRU case. We can further classify these points into two types. These can be thought 
of as both the fusion

3


Under review as a conference paper at ICLR 2019

of a stable fixed point and a saddle point, and the fusion of an unstable fixed point and a saddle 
point. We will refer to
these fixed points as saddle-node bifurcation fixed points of the first kind and second kind 
respectively.

One type of codimension-2 bifurcation fixed point that has been observed in the two GRU system acts 
as the fusion
of all three simple fixed points.  More specifically, these points arise from the fusion of a 
stable fixed point, unstable
fixed point, and two saddle points. All of these local structures are depicted in figure 3.

While the existence of simple fixed points was already demonstrated (see Fig. 2A). Figure 3A 
demonstrates the maxi-
mum number of fixed points observed in a two GRU system, for a given set of parameters. A closer 
look at this system
reveals its potential interpretation as a continuous analogue of 5-discrete states with 
input-driven transitions, similar
to that depicted in figure 2, implying additional GRUs are needed for any Markov process modeled in 
this manner,
requiring more than five discrete states.  We conjecture that the system depicted in figure 3A is 
the only eleven fixed
point structure obtainable with two GRUs, as all observed structures containing the same number of 
fixed points are
topologically equivalent to one another.

The addition of bifurcation fixed points opens the door to dynamically realize more sophisticated 
models.  Take for
example the four state system depicted in figure 3B. If the hidden state is set to initialize in 
the first quadrant of
phase space, the trajectory will flow towards the codimension-2 bifurcation fixed point at the 
origin. Introducing noise
through the input will stochastically cause the trajectory to approach the stable fixed point at 
(-1,-1) either directly, or
by first flowing into one of the two saddle-node bifurcation fixed points of the first kind.  
Models of this sort can be
used in a variety of applications, such as neural decision making (Wong & Wang (2006), Churchland & 
Cunningham
(2014)).

A                                                                                                   
 B                                                                                            C


1.5

1

0.5

0

-0.5

-1

-1.5

-1.5       -1       -0.5        0         0.5         1         1.5

x

0

-0.5

-1

-1.5

-2

-2.5

-3

-3.5

-1

-2

-3

-4

-5

-6

-1.5       -1       -0.5        0         0.5         1         1.5

x

0

-1

-2

-3

-4

-5

-1.5       -1       -0.5        0         0.5         1         1.5

x

sink (stable fixed point)
saddle point

source (unstable fixed point)

saddle-node bifurcation
fixed point

(sink-saddle collision)

saddle-node bifurcation
fixed point

(source-saddle collision)

co-dimension 2 bifurcation
fixed point

Figure 3: Existence of all observed simple fixed points and bifurcation fixed points with two GRUs, 
depicted in phase
space. Orange and pink lines represent the x and y nullclines respectively. Purple lines indicate 
various trajectories of
the hidden state.  Direction of the flow is determined by the black arrows, where the colormap 
underlaying the figure
depicts the magnitude of the velocity of the flow in log scale.

We will begin our investigation into the non-local dynamics observed with two GRUs by showing the 
existence of
homoclinic orbits.  A trajectory initialized on a homoclinic orbit will approach the same fixed 
point in both forward
and backward time. We observe that two GRUs can exhibit one or two bounded planar regions of 
homoclinic orbits for
a given set of parameters, as shown in figure 4A and 4B respectively. Any trajectory initialized in 
one of these regions
will flow into the codimension-2 bifurcation fixed point at the origin, regardless of which 
direction time flows in. This
featured behavior enables the accurate depiction of various models, including neuron spiking 
(Izhikevich, 2007).

In regards to the second non-local dynamic feature, it can be shown that two GRUs can exhibit an 
Andronov-Hopf
bifurcation, whereby a stable fixed point bifurcates into an unstable fixed point surrounded by a 
limit cycle.  Behav-
iorally speaking, a limit cycle is a type of attractor, in the sense that there exists a defined 
basin of attraction. However,
unlike a stable fixed point, where trajectories initialized in the basin of attraction flow towards 
a single point, a limit
cycle pulls trajectories into a stable periodic orbit around the unstable fixed point at its 
center.  To demonstrate this
phenomenon, let (8) define the parameters of (7).


U  , U  , b  , b  , b

= 0,  U

=  3 Σcos α    − sin αΣ                                            (8)


where α ∈ R+.

z      r    z     r    h

h       2    sin α      cos α

If α  =   π ,  the system has a single stable fixed point (stable spiral),  as depicted in figure 
5A. If we continuously
decrease    , the system undergoes an Andronov-Hopf bifurcation approximately about α  =       .  
As α continuously

α                                                                                                   
                                 3.8

decreases, the orbital period increases, and as the nullclines can be made arbitrarily close 
together, the length of this

4


Under review as a conference paper at ICLR 2019


A   1.5

1

0.5

0

-0.5

-1

-1.5

single region of homoclinic orbit

0

-0.5

-1

-1.5

-2

-2.5

-3

-3.5

-4

-4.5

double region of homoclinic orbit

1.5

1

0.5

0

-0.5

-1

-1.5

0

-0.5

-1

-1.5

-2

-2.5

-3

-3.5

-4

-4.5


-1.5       -1       -0.5

C

1

0        0.5        1        1.5

x

D

0.4

-1.5       -1       -0.5

0        0.5        1        1.5

x


0.5

0

-0.5

x(t)

y(t)

0               50              100            150            200            250

t

0.2

0

-0.2

-0.4

0               50              100            150            200            250

t

Figure 4: Two GRUs exhibit bounded regions of homoclinic orbits. 4C and 4D represent the hidden 
state as a function
of time, for a single initial condition within the homoclinic region(s) of the single and double 
homoclinic region cases
respectively (denoted by solid black trajectories in each corresponding phase portrait).

orbital period can be set arbitrarily, up to machine accuracy. Figure 5B shows an example of a 
relatively short orbital
period, and figure 5C depicts the behavior seen for slower orbits.


A  1.5

0             B      1.5

0            C      1.5                                                                             
       0


1

0.5

-0.5

-1

-1.5

1

0.5

-0.5

-1

-1.5

1

0.5

-0.5

-1

-1.5

0                                                                                    -2             
             0                                                                                    
-2                         0                                                                        
            -2


-0.5

-1

-2.5

-3

-3.5

-0.5

-1

-2.5

-3

-3.5

-0.5

-1

-2.5

-3

-3.5


-1.5                                                                                    -4

-1.5       -1       -0.5        0        0.5        1        1.5

x

2

1

-1.5                                                                                    -4

-1.5       -1       -0.5        0        0.5        1        1.5

x

y(t)

0.5          x(t)

-1.5                                                                                    -4

-1.5       -1       -0.5        0        0.5        1        1.5

x

1

0.5

0                                                                                                   
            0                                                                                       
                       0


-1

-2

0                10               20               30               40               50

-0.5

0                10               20               30               40               50

t

-0.5

-1

0                    200                 400                 600                 800

Figure 5: Two GRUs exhibit an Andronov-Hopf bifurcation, where the parameters are defined by (8).  
When α =  π
the system exhibits a single stable fixed point at the origin (Fig. 5A). If α decreases 
continuously, a limit cycle emerges
around the fixed point, and the fixed point changes stability (Fig.  5B). Allowing α to decrease 
further increases the
size and orbital period of the limit cycle (Fig.  5C). The bottom row represents the hidden state 
as a function of time,
for a single trajectory (denoted by black trajectories in each corresponding phase portrait)

With finite-fixed point topologies and global structures out of the way, the next logical question 
to ask is, can two GRUs
exhibit an infinite number of fixed points (countable or uncountable)? Such behavior is often 
desirable in models that
require stationary attraction to non-point structures, such as line attractors and ring attractors. 
The short answer to this
question is no.

Lemma 1.  Any two dimensional GRU can only have finitely many simple fixed points.

5


Under review as a conference paper at ICLR 2019

This follows from Lefschetz theory (Guillemin & Pollack, 2010). The detailed proof can be found in 
appendix D, and
is intended to give the reader intuition behind the result presented in the claim extended to 
aribitrary dimensional GRU
in theorem 1.

Theorem 1.  Any finite dimensional GRU can only have finitely many simple fixed points and 
bifurcation fixed points.

Proof.  By definition of simple fixed points, the Jacobian of the dynamics at those fixed points 
have nonzero real parts,
making them Lefschetz fixed points.  Since GRU dynamics is asymptotically bounded on the compact 
set [   1, 1]ᵈ,
where d is the number of GRUs, it follows from Lefshetz theory (Guillemin & Pollack, 2010) that 
there are finitely
many simple fixed points.  Furthermore, by construction, a bifurcation fixed point can only exist 
within a stability
structure if and only if there exists a separate topology, such that the simple fixed points making 
up each bifurcation
fixed point exist isolated from one another.  Therefore, there can only exist finitely many 
isolated bifurcation fixed
points.

This eliminates the possibility of having countably many fixed points. Next, we show that there 
cannot be uncountably
many non-isolated fixed points.

Theorem 2.  Any finite dimensional GRU cannot have a continuous attractor.

Proof.  We  provide  a  sketch  of  a  proof.    Let  h∗     Rd   be  a  fixed  point  of  a  
d-dimensional  GRU,  that  is,
h∗   tanh(Uh(r(h∗)      h∗) + bh)  =  0.   Now for any unit norm vector k      Sd−1,  and for any δ 
 >  0,  we can
show that there exist an ϵ > 0 such that,   h˙ (h∗ + δk)     h˙ (h∗)   =   h˙ (h∗ + δk)   > ϵ. This 
can be argued by taking
three cases into consideration, (a) Urk = 0 and Uh(σ(br)     k) = 0, (b) Urk = 0 and Uh(σ(br)     
k) = 0, and (c)

Urk = 0.  In each case, it reverts to a 1-dimensional problem where it can be trivially shown to 
have no continuous
attractor around h∗ along direction k. Thus, we conclude that there is no continuous attractor in 
any direction.

Despite this limitation, an approximation of a line attractor can be created using two GRUs.  This 
approximation can
be made arbitrarily close to an actual line attractor on a finite region in phase space, thereby 
satisfying computational
needs on an arbitrary interval when scaled.  We will refer to this phenomenon as a pseudo-line 
attractor.  Figure 6
depicts an example of such an attractor.

A                                                                                                   
 B


1.5                                                                                        0

-1

1

-2

0.5                                                                                        -3

-4

0

-5

-0.5                                                                                        -6

-7

-1

-8

-1.5                                                                                        -9

-1.5       -1       -0.5        0         0.5         1         1.5

x

0.2                                                                                         0

0.15                                                                                        -1

0.1                                                                                         -2

-3

0.05

-4

0

-5

-0.05                                                                                        -6

-0.1                                                                                        -7

-0.15                                                                                        -8

-0.2                                                                                        -9

-0.2            -0.1              0               0.1             0.2

x

Figure 6:  Two GRUs exhibit a pseudo-line attractor.   Nullclines intersect at one point,  but are 
close enough on a
finite region to mimic an analytic line attractor in practice.  6A and 6B depict the phase 
portrait, on [−1.5, 1.5]² and
[−0.2, 0.2]² respectively.

We conclude this section with a discussion of slow points in the two GRU system.   As a logical 
extension to the
single GRU system,  slow points occur where the nullclines are sufficiently close together,  but do 
not intersect,  as
demonstrated in figure 7. Given the previously discussed classes of dynamic behavior for two GRUs, 
slow points can
only exist so long as the potential for a saddle-node bifurcation fixed point is possible in the 
location of the desired
slow point, given an appropriate change in parameters, as they result from the collision and 
annihilation of two fixed
points. This observation is consistent with the single GRU case, as slow points can only exist for 
a single fixed point.
This would imply that given the one fixed point case, a maximum of five slow points are possible. 
However, this would
imply that there must exist a six fixed point case by which five of the six fixed points exist at 
saddle-node bifurcation
fixed points, which has not been observed (see appendix C). Despite this shortcoming, four 
simultaneous slow points
are obtainable, as shown in figure 5C.

6


Under review as a conference paper at ICLR 2019

A                                                                                                 B

1.5                                                                                     0           
     1


1

0.5

0

-0.5

-1

-0.5

-1

-1.5

-2

-2.5

-3

-3.5

0.5

0

-0.5

-1

y(t)

x(t)

passing through slow point


-1.5

-1.5       -1       -0.5        0        0.5        1        1.5

x

-1.5

0            5           10          15          20          25

t

Figure 7: An example of a slow point about the origin, obtainable with two GRUs. Initial conditions 
satisfying y <    x
are attracted to the slow point at the origin before a secondary attraction to the sink.  7A 
depicts the phase portrait of
the system, and 7B shows the dynamics of the hidden state for a single initial condition (denoted 
by a black trajectory
on 7A).

5    NUMERICAL  EXPERIMENTS

As a means to put our theory to practice,  in this section we explore several examples of time 
series prediction of
continuous time planar dynamical systems using two GRUs. Results from the previous section indicate 
what dynamical
features can be learned by this RNN, and suggest cases by which training will fail.  All of the 
following computer
experiments consist of an RNN, by which the hidden layer is made up of two GRUs, followed by a 
linear output layer.
The network is trained to make a 29-step prediction from a given initial observation, and no 
further input through
prediction. As such, to produce accurate predictions, the RNN must rely solely on the hidden layer 
dynamics.

We train the network to minimize the following multi-step loss function:

Ntraj      T


L(θ) =  1  Σ Σ ǁwˆ  (k; w (0)) − w (k)ǁ2

(9)

where θ are the parameters of the GRU and linear readout, T  =  29 is the prediction horizon, wi(t) 
is the i-th time
series generated by the true system, and wˆ (k; w₀) is k-step the prediction given w₀.

The hidden states are initialized at zero for each trajectory.  The RNN is then trained for 4000 
epochs, using ADAM
(Kingma & Ba, 2014) in whole batch mode to minimize the loss function, i.e., the mean square error 
between the
predicted trajectory and the data.  Ntrₐj  =  667 time series were used for training.  Figure 8 
depicts the experimental
results of the RNN’s attempt at learning each dynamical system we describe below.

5.1    LIMIT CYCLE

To test if two GRUs can learn a limit cycle, we use a simple nonlinear oscillator called the 
FitzHugh-Nagumo Model.
The FitzHugh-Nagumo model is defined by:


x˙  = x −

x3

3  − y + Iₑₓt,     τ y˙ = x + a − by                                                    (10)

where in this experiment we will chose τ  = 12.5, a = 0.7, b = 0.8, and Iₑₓt  =     (0.7, 0.04).  
Under this choice of
model parameters, the system will exhibit an unstable fixed point (unstable spiral) surrounded by a 
limit cycle (Fig. 8).
As shown in section 4, two GRUs are capable of representing this topology. The results of this 
experiment verify this
claim (Fig. 8), as two GRUs can capture topologically equivalent dynamics.

5.2    LINE ATTRACTOR

As discussed in section 4, two GRUs can exhibit a pseudo-line attractor, by which the system mimics 
an analytic line
attractor. We will use the simplest representation of a planar line attractor:


x˙  = −x,

7

y˙ = 0                                                                            (11)


Under review as a conference paper at ICLR 2019

Limit Cycle                                       Line Attractor                                    
Ring Attractor

3                                                                                                   
                                                                                                    
                                  1.5                                                               
                        2


1

2

0

1                                                                                     -1

0                                                                                     -2

-3

-1

-4

-2

-2           -1            0             1             2

x

2                                                                                     0

-1

1

-2

0                                                                                     -3

-4

-1

-5

-2                                                                                     -6

-2           -1            0             1             2

x

1                                                                                       0

0.5                                                                                       -2

0

-4

-0.5

-6

-1

-8

-1.5

-1.5       -1       -0.5        0         0.5         1         1.5

x


1.5

1

0.5

0

-0.5

-1

-1.5

-1.5       -1       -0.5        0         0.5         1         1.5

x

1

0

-1

-2

1

0

-1

-2

-3

-4

x(t)

y(t)

1

0.5

0

-0.5

-1

1

0.5

0

-0.5

-1

0

-1

-2

-3

-4

-5

-6

-1             -0.5              0               0.5               1

x

1.5                                                                                       2

1                                                                                       0

0.5                                                                                       -2

0

-4

-0.5

-6

-1

-8

-1.5

-1.5       -1       -0.5        0         0.5         1         1.5

x

2

1

0

-1


0                10               20               30               40               50

t

0             50           100          150          200          250          300

t

0             50           100          150          200          250          300

t

Figure 8:  Training 2-dim GRUs.  (top row) Phase portraits of target dynamical systems.  Red solid 
line represents
1-dimensional attractor.  See main text for each system.  (middle row) GRU dynamics learned from 
corresponding
29-step forecasting tasks.  Note that the prediction is an affine transformation of the hidden 
state.  (bottom row) An
example time series generated through closed-loop prediction of the trained GRU (denoted by a black 
trajectory). Note
that GRU fails to learn the ring attractor.

This system will exhibit a line attractor along the y-axis, at x = 0 (Fig. 8). Trajectories will 
flow directly perpendicular
towards the attractor. We added white Gaussian noise     (0, 0.1I) in the training data. While the 
hidden state dynamics
of  the trained network do not perfectly match that of an analytic line attractor, there exists a 
subinterval near each of
the fixed points acting as a pseudo-line attractor (Fig. 8). As such, the added affine 
transformation (linear readout) can
scale and reorient this subinterval as is required by a given problem, thereby mimicking a line 
attractor.

5.3    RING ATTRACTOR

For this experiment, a dynamical system representing a standard ring attractor of radius one is 
used:

x˙  = −(x² + y² − 1)x,     y˙ = −(x² + y² − 1)y                                                 
(12)

This system exhibits an attracting ring, centered around an unstable fixed point. We added Gaussian 
noise     (0, 0.1I)

to the training data.

Two GRUs will not be able to accurately capture the system’s continuous attractor dynamics as 
expected from theo-
rem 3.  The results of this experiment are demonstrated in figure 8.  As expected, the RNN fails to 
capture the proper
dynamical features of the ring attractor.   Rather,  the hidden state dynamics fall into an 
observed finite fixed point
topology (see case xxix in appendix C). In addition, we robustly see this over multiple 
initializations, and the quality
of approximation improves as the dimensionality of GRU increases (Fig. 9).

8


Under review as a conference paper at ICLR 2019

Figure 9: Learning curve (training loss) for ring attractor (left) and the FitzHugh-Nagumo (right) 
dynamics. Note that
the performance of the ring attractor improves as the dimensinoality of the GRU increases unlike 
the FHN dynamics.
Four network sizes (2, 4, 8, 16 dimensional GRU) were trained 3 timeswith different 
initializations.  Initial learning
rate for ADAM was tuned using Bayesian optimization procedure.

6    CONCLUSION

Our analysis shows the rich but limited classes of dynamics the GRU can approximate in one,  two,  
and arbitrary
dimensions.  We developed a new theoretical framework to analyze GRUs as a continuous dynamical 
system, and
showed that two GRUs can exhibit a variety of expressive dynamic features, such as limit cycles, 
homoclinic orbits,
and  a substantial catalog of stability structures and bifurcations.  However, we also showed that 
finitely many GRUs
cannot exhibit the dynamics of an arbitrary continuous attractor.  These claims were then 
experimentally verified in
two dimensions. We believe these findings also unlock new avenues of research on the trainability 
of recurrent neural
networks.  Although we have analyzed GRUs only in 1- and 2- dimensions in near exhaustive, we 
believe that the
insights extends to higher-dimensions. We leave rigorous analysis of higher-dimensional GRUs as 
future work.

REFERENCES

Denny Britz, Anna Goldie, Minh-Thang Luong, and Quoc Le.  Massive Exploration of Neural Machine 
Translation
Architectures.  In Proceedings of the 2017 Conference on Empirical Methods in Natural Language 
Processing, pp.
1442–1451, Copenhagen, Denmark, 2017. Association for Computational Linguistics. doi: 
10.18653/v1/D17-1151.

Kyunghyun Cho, Bart van Merrienboer, Caglar Gulcehre, Dzmitry Bahdanau, Fethi Bougares, Holger 
Schwenk, and
Yoshua Bengio. Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine 
Translation.
arXiv:1406.1078 [cs, stat], June 2014. arXiv: 1406.1078.

K. Choi, G. Fazekas, M. Sandler, and K. Cho.  Convolutional recurrent neural networks for music 
classification.  In
2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 
2392–2396, March
2017. doi: 10.1109/ICASSP.2017.7952585.

Mark M. Churchland and John P. Cunningham. A Dynamical Basis Set for Generating Reaches. Cold 
Spring Harbor
Symposia on Quantitative Biology, 79:67–80, 2014. ISSN 1943-4456. doi: 10.1101/sqb.2014.79.024703.

Debidatta Dwibedi, Pierre Sermanet, and Jonathan Tompson.   Temporal Reasoning in Videos Using 
Convolutional
Gated Recurrent Units. pp. 1111–1116, 2018.

F. A. Gers, J. Schmidhuber, and F. Cummins. Learning to forget: continual prediction with LSTM. 
Neural Computa-
tion, 12(10):2451–2471, October 2000. ISSN 0899-7667.

Victor  Guillemin  and  Alan  Pollack.   Differential  Topology,  volume  370  of  AMS  Chelsea  
Publishing.   American
Mathematical  Society,  August  2010.    ISBN  978-0-8218-5193-7  978-0-8218-6955-0  
978-1-4704-1135-0.    doi:

http://dx.doi.org/10.1090/chel/370.

9


Under review as a conference paper at ICLR 2019

Morris W. Hirsch, Stephen Smale, and Robert L. Devaney.  Differential Equations, Dynamical Systems, 
and an Intro-
duction to Chaos. Elsevier Inc., 2013. ISBN 978-0-12-382010-5.

Sepp Hochreiter.  Untersuchungen zu dynamischen neuronalen Netzen.  PhD thesis, TU Munich, 1991.  
Advisor J.
Schmidhuber.

Sepp Hochreiter and Ju¨rgen Schmidhuber. Long Short-Term Memory. Neural Computation, 
9(8):1735–1780, Novem-
ber 1997. ISSN 0899-7667. doi: 10.1162/neco.1997.9.8.1735.

Eugene M. Izhikevich. Dynamical systems in neuroscience. MIT press, 2007.

Diederik P. Kingma and Jimmy Ba.  Adam: A Method for Stochastic Optimization.  arXiv:1412.6980 
[cs], December
2014. arXiv: 1412.6980.

Yuri A. Kuznetsov.  Elements of Applied Bifurcation Theory (2Nd Ed.).  Springer-Verlag, Berlin, 
Heidelberg, 1998.
ISBN 978-0-387-98382-0.

Thomas Laurent and James von Brecht. A recurrent neural network without chaos. arXiv:1612.06212 
[cs], December
2016. arXiv: 1612.06212.

J.  Meiss.   Differential  Dynamical  Systems.   Mathematical  Modeling  and  Computation.  Society 
 for  Industrial  and
Applied Mathematics, January 2007. ISBN 978-0-89871-635-1. doi: 10.1137/1.9780898718232.

Chethan Pandarinath,  Daniel J. O’Shea,  Jasmine Collins,  Rafal Jozefowicz,  Sergey D. Stavisky,  
Jonathan C. Kao,
Eric M. Trautmann, Matthew T. Kaufman, Stephen I. Ryu, Leigh R. Hochberg, Jaimie M. Henderson, 
Krishna V.
Shenoy, L. F. Abbott, and David Sussillo.  Inferring single-trial neural population dynamics using 
sequential auto-
encoders. Nature Methods, 15(10):805–815, October 2018. ISSN 1548-7105. doi: 
10.1038/s41592-018-0109-9.

Rohit Prabhavalkar,  Kanishka Rao,  Tara N. Sainath,  Bo Li,  Leif Johnson,  and Navdeep Jaitly.   
A Comparison of
Sequence-to-Sequence Models for Speech Recognition.  In Interspeech 2017, pp. 939–943. ISCA, August 
2017.
doi: 10.21437/Interspeech.2017-233.

David Sussillo and Omri Barak. Opening the Black Box: Low-Dimensional Dynamics in High-Dimensional 
Recurrent
Neural Networks.  Neural Computation, 25(3):626–649, December 2012.  ISSN 0899-7667.  doi: 
10.1162/NECO
a 00409.

Gail Weiss, Yoav Goldberg, and Eran Yahav.  On the Practical Computational Power of Finite 
Precision RNNs for
Language Recognition. arXiv:1805.04908 [cs, stat], May 2018. arXiv: 1805.04908.

Kong-Fatt Wong and Xiao-Jing Wang.  A recurrent network mechanism of time integration in perceptual 
decisions.
The Journal of Neuroscience: The Official Journal of the Society for Neuroscience, 26(4):1314–1328, 
January 2006.
ISSN 1529-2401. doi: 10.1523/JNEUROSCI.3733-05.2006.

10


Under review as a conference paper at ICLR 2019

A    CONTINUOUS  TIME  SYSTEM  DERIVATION

We begin with the fully gated GRU as a discrete time system, where the input vector xt has been set 
equal to zero, as
depicted in (13) - (15), where Ⓢ is the Hadamard product, and σ is the sigmoid function.

zt = σ(Uzht−₁ + bz)                                                                        (13)

rt = σ(Urht−₁ + br)                                                                        (14)

ht = zt Ⓢ ht−₁ + (1 − zt) Ⓢ tanh (Uh(rt Ⓢ ht−₁) + bh)                                          (15)
We recognize that (15) is a forward Euler discretization of a continuous time dynamical system.  
This allows us to

consider the underlying continuous time dynamics on the basis of the discretization.  The following 
steps are a walk
through of the derivation:

Since zt is a bounded function on R   t, there exists a function z˜t, such that zt + z˜t = 1 at 
each time step (due to the
symmetry of zt, z˜t is the result of vertically flipping zt about 0.5, the midpoint of its range). 
As such, we can rewrite

(15) with z˜t as depicted in (16).

ht = (1 − z˜t) Ⓢ ht−₁ + z˜t Ⓢ tanh (Uh(rt Ⓢ ht−₁) + bh)                                          
(16)


where,

z˜t = σ(U˜z ht−₁ + b˜z )                                                                        
(17)

ht = ht−₁ − z˜t Ⓢ ht−₁ + z˜t Ⓢ tanh (Uh(rt Ⓢ ht−₁) + bh)                                         
(18)

ht − ht−₁ = −z˜t Ⓢ (ht−₁ − tanh (Uh(rt Ⓢ ht−₁) + bh))                                          (19)

Let h(t) ≡ ht−₁. As a result, we can say z˜t ≡ z˜(t) and rt ≡ r(t), as depicted in (20).

h(t + 1) − h(t) = −z˜(t) Ⓢ (h(t) − tanh (Uh(r(t) Ⓢ h(t)) + bh))                                   
(20)


where,

z˜(t) = σ(U˜z h(t) + b˜z )                                                                       
(21)

r(t) = σ(Urh(t) + br)                                                                       (22)

Let ∆t define an arbitrary time interval. Then (20) becomes,

h(t + ∆t) − h(t) = −z˜(t) Ⓢ (h(t) − tanh Uh(r(t) Ⓢ h(t)) + bh)∆t                                (23)
Dividing both sides of the equation by ∆t yields (24).


h(t + ∆t) − h(t)  = −z˜(t) Ⓢ (h(t) − tanh U

(r(t) Ⓢ h(t)) + bh

)                                   (24)

If we take the limit as ∆t → 0, we get the analogous continuous time system to (13) - (15),

h˙  = −z˜(t) Ⓢ (h(t) − tanh (Uh(r(t) Ⓢ h(t)) + bh))                                               
(25)

where h˙  ≡ dh(t)

Finally, we can rewrite (25) as follows:

h˙  = (z(t) − 1) Ⓢ (h(t) − tanh (Uh(r(t) Ⓢ h(t)) + bh))                                           
(26)


where

z(t) = σ(Uzh(t) + bz)                                                                       (27)


B    SINGLE  GRU FIXED  POINT  PROOFS

The fixed points of our continuous time system (25) exist where the derivative h˙
Hadamard product reduces to standard scalar multiplication, yielding,

=  0.  In the single GRU case, the

0 = (z(t) − 1)[h∗ − tanh (Uhr(t)h∗ + bh)]                                                     (28)
where z(t) and r(t) are defined by (27) and (22) respectively, and h∗ ∈ R represents a solution of 
(28).

We can divide out z(t)      1, indicating that the update gate does not play a part in the 
stability of the system.  For
simplicity, lets expand r(t) in (28) by its definition (22).

0 = tanh (Uhσ(Urh∗ + br)h∗ + bh) − h∗                                (29)

where Uh, bh, Ur, br ∈ R.

11


Under review as a conference paper at ICLR 2019

Lemma 2.  for all Uh, bh, Ur, br, there exists h∗ such that (29) is satisfied.

Proof.  The hyperbolic tangent function is continuous and bounded on R, having a range of (   1, 
1).     h(t)          h

is monotonic and achieves all values on R, as    h is bijective on R.  Thus, their sum is unbounded 
and obtains every
value on R at least once.  By the intermediate value theorem, there is at least one point h∗ such 
that (29) is satisfied,
regardless of the choice of parameters Uh, bh, Ur, br.

Lemma 3.  There exists a set of parameters Uh, bh, Ur, br such that there exists one, two, or three 
solutions to (29).

Proof.  We will prove this lemma by showing the existence of each case. Let Ur = 80, br = 40, and 
Uh =     60. We
then allow bh to vary. The existence of each of the three cases are shown in figure 1.

If bh =     1, there exists a single solution to (29).  If bh decreases continuously, a second root 
appears and splits in
two.  Analogously, the system (25) goes through a saddle-node bifurcation, where a half-stable 
fixed point appears,
and splits into a stable/unstable fixed point pair.

Theorem 3.  For any choice of parameters Ur, br, Uh, bh, there can only exist one, two, or three 
solutions to (29), and
all solutions exist on the interval (-1,1).

Proof.  We begin with the argument of the hyperbolic tangent function in (29),

Uhσ(Urh + br)h + bh                                                          (30)


Taking the derivative of (30) yields,

Uh(1 + e−Urh−br ) + UhUrhe−Urh−br

(1 + e−Urh−br )2

(31)

Setting (31) to zero and simplifying will allow us to find the nontrivial critical points of (30), 
as shown in (32).  Note
that if Uh = 0, (30) is equal to bh ∀h, yielding no critical points.

1 + e−Urh−br (1 + Urh) = 0                                                                  (32)

Let x ≡ e−ᵇr  and hˆ ≡ Urh, and solve (32) for hˆ.

hˆ =    W (  1  )     1                                                                           
(33)

xe

where W is principal branch of the Lambert W function. Therefore, (30) has exactly one local 
maximum or minimum,
so long as Uh /= 0.

Now consider,

tanh (Uhσ(Urh + br)h + bh)                                                                 (34)

The hyperbolic tangent function preserves intervals of monotonic behavior in its argument. 
Therefore, (34) has at most
one local maximum or minimum.

We take into account the fact that the hyperbolic tangent function bounds its argument on the 
interval (-1,1).  If there
exists a subset S = [a, 1], for some a     [   1, 1) such that (34) is increasing, then there 
exists a k     S such that when
h = k (35) and (36) hold.

d

dh (tanh (Uhσ(Urh + br)h + bh) − h) = 0                                                     (35)

d

dh (tanh (Uhσ(Urh + br)h + bh) − h) < 0, ∀h > k                                             (36)

This result in conjunction with the previous two lemmas completes the proof.

12


Under review as a conference paper at ICLR 2019

C    ALL  TOPOLOGICAL  STABILITY  STRUCTURES  OBSERVED  WITH  TWO  GRUS

Table 2 depicts all observed topologies of multiple-fixed point structures using two GRUs.   Figure 
10 displays an
example of a phase portrait from a two GRU system for each case listed in 2. Note that all fixed 
points are denoted by
a red dot, regardless of classification.  Table 3 lists the parameters used for each of the 
observed cases.  Note that all
the update gate parameters are set to zero.

Each case in this paper was discovered by hand by considering the geometric constraints on the 
structure of nullclines
for both the decoupled and coupled system (i.e reset gate inactive and active respectively). An 
exhaustive analysis on
the one dimensional GRU allowed for a natural extension into the two dimensional decoupled GRU. 
Upon establishing
a set of  base cases (a combinatorial argument regarding  all possible ways the decoupled  
nullclines [topologically
conjugate to linear and cubic polynomials] can intersect) From these base cases, the reset gate can 
be used as a means
of bending and manipulating structure of the decoupled nullclines in order to obtain new 
intersection patterns in the
coupled system.

Table 1: Parameters Used for all Phase Portraits in Section 4

Figure      Uh11       Uh12       Uh21       Uh22      Ur11     Ur12     Ur21     Ur22      bh1     
 bh2     br1      br2
2              3              0              0              3             0           0           0 
          0           0          0         0          0

3a             2              0              0              2             5           8           8 
          5           0          0         5          5

3b             2              0              0              2            -1           0           0 
          -1           0          0         0          0

3c             2              0              0              2             1           -2           
3           1        -0.06       0       0.2     -0.85

4a             2              0              0              2             5           9           5 
          9           0          0         0          0

4b             2              0              0              2             5           9           9 
          5           0          0         0          0

5a           1.5         -2.598       2.598         1.5           0           0           0         
  0           0          0         0          0

5b        2.4271     -1.7634     1.7634     2.4271        0           0           0           0     
      0          0         0          0

5c         2.9665     -0.4471     0.4471     2.9665        0           0           0           0    
       0          0         0          0

6a           0.1           -0.1            -1             0             0           0           0   
        0           0          0         0          0

7a             2              2              2              2           100       100       100     
  100       0.01        0         0          0

13


Under review as a conference paper at ICLR 2019

Table 2: Multiple Fixed Point Stability Structures Obtainable with two GRUs


Case
i

ii
iii
iv
v
vi
vii
viii
ix
x
xi
xii
xiii
xiv
xv
xvi

xvii
xviii
xix
xx
xxi
xxii
xxiii
xxiv
xxv
xxvi
xxvii
xxviii
xxix
xxx
xxxi
xxxii
xxxiii
xxxiv
xxxv
xxxvi

Fixed
Points

2

3

3

4

4

4

4

4

5

5

5

5

5

5

6

6

6

6

6

6

6

7

7

7

7

7

7

8

8

8

9

9

9

10

10

11

Sinks
1

2

1

1

2

2

2

1

2

3

3

2

2

-
2

3

2

3

2

3

1

3

2

4

2

3

3

4

3

3

4

3

5

4

5

5

Sources

-

-

-

-

-

-

-

-
1

-

-

-

-
1

-

-
1

-
1

-
1

1

2

3

1

-

-

-
1

-
1

1

-
1

-
1

Saddle
Points

-
1

-

-
1

1

1

-
2

2

1

1

1

-
1

2

2

2

2

2

1

3

3

-
2

2

2

3

3

2

4

3

4

4

4

5

Saddle Point
and Stable
Node Collisions
1

-
2

2

-

-
1

3

-

-

-

-
1

4

2

-
1

-

-
1

3

-

-

-
2

2

1

-
1

2

-
2

-
1

-

-

Saddle Point
and Unstable
Node Collisions

-

-

-

-

-
1

-

-

-

-
1

2

1

-
1

1

-

-
1

-

-

-

-

-

-

-
1

1

-
1

-

-

-

-
1

-

Codim. 2
Bifurcation
Point

-

-

-
1

1

-

-

-

-

-

-

-

-

-

-

-

-
1

-

-

-

-

-

-

-

-

-

-

-

-

-

-

-

-

-

-

Figure
Reference

10i
10ii
10iii
10iv
10v
10vi
10vii
10viii
10ix
10x
10xi
10xii
10xiii
10xiv
10xv
10xvi
10xvii
10xviii
10xix
10xx
10xxi
10xxii
10xxiii
10xxiv
10xxv
10xxvi
10xxvii
10xxviii
10xxix
10xxx
10xxxi
10xxxii
10xxxiii
10xxxiv
10xxxv
10xxxvi

14


Under review as a conference paper at ICLR 2019

(i)                                                                 (ii)                            
                                    (iii)

(iv)                                                                 (v)                            
                                    (vi)

(vii)                                                              (viii)                           
                                 (ix)

(x)                                                                (xi)                             
                                  (xii)

Figure 10: Thirty six multiple fixed-point topologies obtainable with two GRUs, depicted in phase 
space. Orange and
pink lines represent the x and y nullclines respectively.  Red dots indicate fixed points.  Each 
subfigure contains 64
purple lines, indicating trajectories in forward time, whose initial conditions were chosen to be 
evenly spaced on the
vertices of a square grid on [   1.5, 1.5]². Direction of the flow is determined by the black 
arrows, and the underlaying
color map represents the magnitude of the velocity of the flow in log scale.

15


Under review as a conference paper at ICLR 2019

(xiii)                                                              (xiv)                           
                                    (xv)

(xvi)                                                             (xvii)                            
                                (xviii)

(xix)                                                              (xx)                             
                                 (xxi)

(xxii)                                                            (xxiii)                           
                                 (xxiv)

Figure 10: Thirty six multiple fixed-point topologies obtainable with two GRUs, depicted in phase 
space. Orange and
pink lines represent the x and y nullclines respectively.  Red dots indicate fixed points.  Each 
subfigure contains 64
purple lines, indicating trajectories in forward time, whose initial conditions were chosen to be 
evenly spaced on the
vertices of a square grid on [   1.5, 1.5]². Direction of the flow is determined by the black 
arrows, and the underlaying
color map represents the magnitude of the velocity of the flow in log scale.

16


Under review as a conference paper at ICLR 2019

(xxv)                                                            (xxvi)                             
                              (xxvii)

(xxviii)                                                           (xxix)                           
                                 (xxx)

(xxxi)                                                           (xxxii)                            
                              (xxxiii)

(xxxiv)                                                           (xxxv)                            
                               (xxxvi)

Figure 10: Thirty six multiple fixed-point topologies obtainable with two GRUs, depicted in phase 
space. Orange and
pink lines represent the x and y nullclines respectively.  Red dots indicate fixed points.  Each 
subfigure contains 64
purple lines, indicating trajectories in forward time, whose initial conditions were chosen to be 
evenly spaced on the
vertices of a square grid on [   1.5, 1.5]². Direction of the flow is determined by the black 
arrows, and the underlaying
color map represents the magnitude of the velocity of the flow in log scale.

17


Under review as a conference paper at ICLR 2019

Table 3: Parameters of each multiple fixed-point stability structure example

Case      Uh11       Uh12       Uh21       Uh22      Ur11     Ur12     Ur21     Ur22       bh1      
  bh2        br1         br2
i             2              2              2              2           100        100       100     
   100           0             0            0             0

ii             2              2              2              2             0            0           
0            0             0             0            0             0

iii           1.2             0              0              2             5           12          8 
           5             0             0         -0.22        -0.5

iv            2              0              0              2            -1           0           0  
         -1            0             0            0             0

v             2              0              0              2             1           -1           1 
           1             0             0            0             0

vi            2              0              0              2             1           -2           3 
           1          -0.06          0           0.2        -0.85

vii            2              0              0              4             1           -2           
3            1          -0.06          0          -0.3        -0.42

viii          1.2             0              0              2             5         20.5         8  
          5             0             0        -0.275       -3.3

ix            3              3              0              3             0            0           0 
           0             0             0            0             0

x             6              0              0              6             0           -2           0 
           0             0             0        -1.695         0

xi            6              0              0              6             0            1           0 
           0             0             0          -2.5           0

xii            2              0              0              2             1           -2           
3            1         -0.055         0          -0.1        -0.02

xiii           2              0              0              4             1           -2           
3            1          -0.06          0        -0.085      -0.22

xiv       2.9674     -0.4409     0.4409     2.9674        0            0           0            0   
          0             0            0             0

xv            6              0              0              2            -1           0           0  
          0             0             0            0             0

xvi           2              0              0              2             1           -2           3 
           1          -0.06          0         -0.08          3

xvii           2              0              0              2             1           -2           
3          1.1        -0.06          0           0.2            0

xviii          2              0              0              2             3            2           
2            3             0             0            0             0

xix          10             0              0              6            -3           5           -5  
         3             0             0            -3            -3

xx          1.2             0              0              2           -17         35         10     
     -8            0             0           1.2         -1.2

xxi       2.9763      -0.376       0.376      2.9763        0            0           0            0 
       0.0315        0        -0.015     -0.015

xxii           6              0              0              6             0           -2           
0            0             0             0            0             0

xxiii0         3              0              0              3            -3          -5          -5 
         -3            0             0            -2            -2

xxiv         1.5             0              0              2            -4          -7           8  
          5             0             0          -0.4         -1.2

xxv           2              0              0              3          12.4       11.6        -8     
     -5            0             0           1.8            7

xxvi          3              0              0              3         5.175        9           9     
   5.175        0.3          0.3        3.95        3.95

xxvii          7              0              0              3             6            3           
9            6          0.62       0.373         4            3.4

xxviii         6              0              0             10            0            0           
-5          -8         -0.08          0            0            -2

xxix          2              0              0              3           -10       -11.6        8     
       5             0             0            4            4.8

xxx           3              0              0              3          5.26         9           9    
     5.26        0.25        0.25       3.95        3.95

xxxi          3              0              0              3             0            0           0 
           0             0             0            0             0

xxxii          2              0              0              2             5            8           
8            5             0             0           4.4          4.4

xxxiii         3              0              0              3             6            9           
9            6           0.3          0.3        3.75        3.75

xxxiv         1              0              0              1             5            8           8 
           5             0             0           4.4          4.9

xxxv          3              0              0              3             6            9           9 
           6          0.24        0.24       3.95        3.95

xxxvi         2              0              0              2             5            8           8 
           5             0             0            5             5

18


Under review as a conference paper at ICLR 2019

D    PROOF  OF  LEMMA  1

We begin this proof by showing that all fixed points obtainable with two GRUs are Lefschetz fixed 
points.  To show
this is the case let (37) expand our previous notation. We set all elements in Uz and bz to zero, 
as the update gate plays
no part in the topology of (7) (shown in appendix B).

Uh  = ΣUh11    Uh12Σ , Ur  = ΣUr11    Ur12Σ , bh  = Σbh1Σ , br  = Σbr1Σ                            
(37)

We can now rewrite (7) expanded in terms of the individual elements of Uh, Ur, bh, and br, as shown 
in (38) and (39).


1                                  Uh₁₁x                                    Uh₁₂y               

x˙  = −  [x − tanh(                                           +                                     
       + b

)]                       (38)

2                   1 + e−(Ur11 x+Ur12 y+br1 )      1 + e−(Ur21 x+Ur22 y+br2 )       h1


1                                  Uh₂₁x                                    Uh₂₂y               

y˙ = −  [y − tanh(                                           +                                      
      + b

)]                       (39)

2                   1 + e−(Ur11 x+Ur12 y+br1 )      1 + e−(Ur21 x+Ur22 y+br2 )       h2

If 0 is not an eigenvalue of the Jacobian matrix of (38) and (39) at a fixed point, the fixed point 
is said to be Lefshetz.

Let Fₓ =  ᵈˣ˙ , Fy =  ᵈˣ˙ , Gₓ =  ᵈʸ˙ , and Fy =  ᵈʸ˙ .

dx               dy                dx                       dy

where


F   = − 1 (1 − sech² .               Uh11x               +               Uh12y               + b    
Σ γ

)         (40)


Uh11Ur11xe−Ur11 x−Ur12 y−br1

Uh11

Uh12Ur21ye−Ur21 x−Ur22 y−br2


γF ₓ =

(e−U

r11

x−U

r12

y−br1

2     +

+ 1)

+

e−Ur11 x−Ur12 y−br1  + 1

(e−U

r21

x−U

r22

y−br2

2            (41)

+ 1)


F   =  1 sech² .               Uh11x               +               Uh12y               + b    Σ γ

(42)


Uh11Ur11xe−Ur11 x−Ur12 y−br1

Uh12

Uh12Ur21ye−Ur21 x−Ur22 y−br2


γF y =

(e−U

r11

x−U

r12

y−br1

2     +

+ 1)

+

e−Ur21 x−Ur22 y−br2  + 1

(e−U

r21

x−U

r22

y−br2

2            (43)

+ 1)


G   =  1 sech² .               Uh21x               +               Uh22y               + b    Σ γ

(44)


Uh21Ur11xe−Ur11 x−Ur12 y−br1

Uh21

Uh22Ur21ye−Ur21 x−Ur22 y−br2


γGₓ =

(e−U

r11

x−U

r12

y−br1

2     +

+ 1)

+

e−Ur11 x−Ur12 y−br1  + 1

(e−U

r21

x−U

r22

y−br2

2            (45)

+ 1)


G   = − 1 (1 − sech² .               Uh21x               +               Uh22y               + b    
Σ γ

)         (46)


Uh21Ur11xe−Ur11 x−Ur12 y−br1

Uh22

Uh22Ur21ye−Ur21 x−Ur22 y−br2


γGy =

(e−U

r11

x−U

r12

y−br1

2     +

+ 1)

+

e−Ur21 x−Ur22 y−br2  + 1

(e−U

r21

x−U

r22

y−br2

2            (47)

+ 1)


Let J denote the Jacobian matrix of (38) and (39).

Note that we can rewrite (38) and (39) as follows:

J =    Fx      Fy                                                                                   
        (48)

Gₓ   Gy

1

x˙  = − 2 [x − tanh(f (x, y, θ))]                                                                 
(49)

1

y˙ = − 2 [y − tanh(g(x, y, θ))]                                                                 
(50)

where  θ  represents  the  set  of  parameters,  f (x, y, θ)  =                Uh11 x               
  +               Uh12 y                 + bh₁,  and


1+e−(Ur11 x+Ur12 y+br1 )

g(x, y, θ) =               Uh21 x                 +              Uh22 y                 + bh₂

1+e−(Ur21 x+Ur22 y+br2 )

1+e−(Ur11 x+Ur12 y+br1 )         1+e−(Ur21 x+Ur22 y+br2 )

An ordered pair (x, y) is a fixed point of (49) and (50) if and only if (51) and (52) hold.

1

0 = − 2 [x − tanh(f (x, y, θ))]                                                                 
(51)

19


Under review as a conference paper at ICLR 2019


As such, we can say the following:

1

0 = − 2 [y − tanh(g(x, y, θ))]                                                                 (52)

x = tanh(f (x, y, θ)) = u(x, y, θ)                                                              
(53)

y = tanh(g(x, y, θ)) = v(x, y, θ)                                                              (54)

If we let λ represent the eigenvalues of (48), the characteristic equation of (48) is as follows:


λ² + λ(−1 − sech²(f (x, y, θ)) ∂f  − sech²(g(x, y, θ)) ∂g ) +

1                                                                  ∂f  ∂g

(1 − sech  (f (x, y, θ))sech  (g(x, y, θ))            )  (55)

∂x                                 ∂y       4                                                       
           ∂y ∂x

We can rewrite (55) in terms of u(x, y, θ) and v(x, y, θ) as shown in (56)


λ² + λ(−1 − uₓ

1

− vy) + 4 (1

− uyvₓ

)                                                         (56)

where uₓ ≡ ∂u , uy ≡ ∂u , vₓ ≡ ∂v , vy ≡ ∂v . We can use the quadratic formula to solve for λ.


1 + u   + v

.u2 + 2uₓ + 2uₓvy + 2vy + v2 + uyvₓ


λ =           ˣ

2                                                 2

(57)

Setting λ = 0 and simplifying yields the following constraint:

|uyvₓ| = 1                                                                                 (58)


which can be realized as follows:

sech²(f (x, y, θ))sech²(g(x, y, θ)) =     1

∂y ∂x

(59)

We  observe  that  sech²(f (x, y, θ))sech²(g(x, y, θ))  ∈  (0, 1),  which  implies  that  ∂ᶠ ∂ᵍ  ∈  
(1, ∞)  However,  from

(53) and (54), we see that f (x, y, θ)  =  tanh−¹(x) and g(x, y, θ)  =  tanh−¹(y) at a critical 
point.  Which implies

∂f  ∂g  = 0 ∈/ (1, ∞). Therefore λ /= 0 ∀θ.

This implies that (38) and (39) is a Lefschetz map. Since (38) and (39) are asymptotically bound to 
(   1, 1)², we can
always find a finite time t₀ such that x, y     (   1, 1)²  t > t₀. Therefore, for every trajectory 
initialized outside of the
trapping region, we can always find a point on [   1, 1]² that arises as the transition of that 
initial condition flowing into
the trapping region. This implies that (38) and (39) can be thought of as existing on a compact 
set, and therefore has a
finite number of simple fixed points Guillemin & Pollack (2010).

20

