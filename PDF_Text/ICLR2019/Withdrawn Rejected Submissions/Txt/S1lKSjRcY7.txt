Under review as a conference paper at ICLR 2019
Improved Gradient Estimators for Stochastic
Discrete Variables
Anonymous authors
Paper under double-blind review
Ab stract
In many applications we seek to optimize an expectation with respect to a dis-
tribution over discrete variables. Estimating gradients of such objectives with
respect to the distribution parameters is a challenging problem. We analyze ex-
isting solutions including finite-difference (FD) estimators and continuous relax-
ation (CR) estimators in terms of bias and variance. We show that the commonly
used Gumbel-Softmax estimator is biased and propose a simple method to reduce
it. We also derive a simpler piece-wise linear continuous relaxation that also pos-
sesses reduced bias. We demonstrate empirically that reduced bias leads to a better
performance in variational inference and on binary optimization tasks.
1	Introduction
Discrete stochastic variables arise naturally in many applications including topic modeling, semi-
supervised learning, clustering, variational memory addressing and reinforcement learning. In many
cases, the objective is to minimize an expectation of a function of discrete random variables with
respect to the distribution parameters:
mφin L[φ],	where L[φ] = Eqφ f(z) = X qφ(z)f (z).	(1)
z
Here, z is a vector of discrete variables under a φ-parameterized distribution qφ(z). For example, in
variational inference, f (z) is the variational lower bound and qφ (z) is the approximating posterior.
Eq. (1) is commonly minimized by gradient-based methods, which require estimating the gradient
∂φL[φ] (see Schulman et al. (2015) for an overview). For continuous random variables whose
sampling can be reparameterized as a function of other parameter-independent random variables,
the reparameterization trick (Kingma & Welling (2013), Rezende et al. (2014)) gives low variance
gradient estimates. However, this trick is not directly applicable to discrete variables due to the
discontinuous cumulative distribution function (CDF).
Extensions of the reparameterization trick to discrete distributions can be grouped into finite-
difference (FD) estimators, and continuous relaxation (CR) estimators. We present a summary of
three recent FD estimators (Tokui & Sato (2017); Yin & Zhou (2018); Lorberbom et al. (2018) to
guide practitioners to the salient aspects of their bias-variance tradeoff and computational complex-
ity. Most importantly, we propose a scalable (but still unbiased) variant of Tokui & Sato (2017) that
trades decreased computation for slightly increased variance.
We examine CR estimators including the popular Gumbel-Softmax (Jang et al. (2016); Maddison
et al. (2016)) in terms of the gradient bias and propose a new method to reduce the bias of all CR
estimators for both binary and categorical variables. Based upon this understanding, we develop a
piecewise-linear estimator for binary and categorical variables that is simpler and less biased than
Gumbel-Softmax.
Lastly, we provide empirical evidence that these improved estimators allow for faster optimization
when training variational autoencoders and when optimizing a continuous relaxation of a combina-
torial optimization problem.
1
Under review as a conference paper at ICLR 2019
1.1	Related work
The most generic approximator of ∂φL[φ] is the score function (SF) estimator (a.k.a. REINFORCE
Williams (1992), Glynn (1990)). SF suffers from high variance and many remedies have been pro-
posed to reduce this variance (Mnih & Gregor (2014); Gregor et al. (2013); Gu et al. (2015); Mnih
& Rezende (2016); Tucker et al. (2017); Grathwohl et al. (2017)). Unbiased estimators that re-
quire multiple function evaluations have also been proposed TokUi & Sato (2017), Titsias & Lazaro-
Gredilla (2015), Lorberbom et al. (2018), Yin & Zhou (2018). These estimators have lower variance
but can be computationally demanding. CR estimators often trade bias for variance and previous
CR proposals include straight-through estimators (Bengio et al. (2013); Raiko et al. (2014)), the
Gumbel-Softmax estimator (Jang et al. (2016); Maddison et al. (2016)), and overlapping smoothing
(Vahdat et al. (2018b;a); Rolfe (2016)).
2	The Reparameterization and Marginalization Estimator
We begin a summary of FD estimators with the reparameterization and marginalization (RAM)
method of Tokui & Sato (2017). For a single binary variable the expectation in Eq. (1) is enumerated
as L = Pz qφ(z)f(z) = qφf(1) + (1 - qφ)f (0), where qφ ≡ qφ(z = 1). The gradient is:
∂φL = ∂φqφ(f(1) - f(0)) = ∂φlφ qφ(1 - qφ)(f(1) - f(0)),	(2)
where qφ = σ(lφ) = (1 + e-lφ)-1 and lφ = logit(qφ). This derivative involves two function eval-
uations and contains a finite-difference of f(z). Eq. (2) is an unbiased zero-variance estimate since
the summation over z is done explicitly. The generalization to M factorially-distributed random
variables qφ (z) = QiM=1 qφ,i (zi) is
dφL =〉： dφqφ,i〉： qφ(z∖i)(f (Zi = 1, z∖i) - f (Zi= 0, z∖i)),	(3)
where again the summation over zi is performed exactly and qφ,i ≡ qφ,i(zi = 1). The summation
over Z∖i can be estimated with a single sample but the derivative requires M+1 function evaluations.
This limits the applicability of RAM to moderately-sized models. Note that both f(Zi = 0, Z∖i)
and f(Zi = 1, Z∖i) are evaluated at the same Z∖i which leads to a lower-variance estimator. For
hierarchical qφ(z) = QM=I qφ,i(zi∣z<i) the derivative takes the form:
∂φL=	qφ(z<i)∂φqφ,i Eqφ(z>i∣1,z<i)f(z>i, 1,z<i) - Eqφ(z>i∖0,z<i)f(z>i, 0,z<i)
i z<i	z>i	z>i
(4)
where qφ,i ≡ qφ,i(1∣z<i). The key insight ofTokui & Sato (2017) is to use common random variates
z>i when sampling from qφ(z>i ∣1,z<i) and qφ(z>i∣0,z<i). This reduces both the variance and the
computational cost. Tokui & Sato (2017) show that this estimator is optimal because it exactly sums
over the binary variables whose probability distribution is being differentiated.
A RAM estimator can also be constructed for categorical variables. For a single one-hot encoded
categorical variable y = (y0, ...yA-1), ya ∈ {0, 1}, Pa ya = 1, the derivative of Eq. (1) is
∂φL=∂φXqφ(y)f(y)=X(∂φlφa)Xqφaqφb(fa-fb),	(5)
y	ab
where fa = f(ya = 1), and qφa = elaφ / Pb elφb . The generalization to many categorical variables
proceeds as for binary variables. For example, the derivative of a factorial categorical distribution
over y = {yia | 0 ≤ a < A, 1 ≤ i ≤ M } is
dΦL = XXqφ(y∖i) X(dΦlφ,i)qφ,iqφ,i(f(ya = 1,y∖i) - f(y = 1,y∖l)∙	⑹
i y\i	a,b
This derivative can again be estimated with a single sample but requires MA function evaluations.
Since RAM is unbiased and has the minimal variance (due to the explicit summation over the dif-
ferentiated variable), we use it as a baseline to evaluate computationally cheaper alternatives.
2
Under review as a conference paper at ICLR 2019
2.1	Sampled Reparameterization and Marginalization
We propose a modification to RAM that allows us to trade decreased computational cost for in-
creased variance. For binary variables, ∂φqφ,i = qφ,i(1 - qφ,i)∂φlφ,i where qφ,i = σ(lφ,i), so
that each term in Eq. (3) or (4) is proportional to qφ,i (1 - qφ,i). In many applications, we ob-
serve that the distribution of a large number of variables (qφ,i) are drawn to 0 or 1 early during
optimization. Such variables have negligible contribution to the full derivative. We exploit this
observation to reduce the computational cost by including variable zi in the full gradient with prob-
ability Pi = 4qφ,i (1 - qφ,i) /β, where β is an adjustable hyperparameter. This means that We replace
the derivative in Eq. (3) with
∂φL =	Eξ-p	hX(∂φlφ,i) βξi	X qφ(z∖i)(f (zi	= 1,z∖i)	-	f (zi	= 0,z\i))i，	⑺
i	z\i
where ξi ∈ {0, 1} are Bernoulli variables with probabilities pi indicating whether zi is included or
not. We evaluate Eq. (7) by sampling ξ and only then evaluating non-zero terms. In Section 4 we
show that in the context of variational inference on MNIST the number of function evaluations is
reduced by an order of magnitude while still allowing for effective optimization. As always, this
computational saving comes at the cost of increased gradient variance which slows training.
In the categorical case, each term in Eq. (6) is accompanied by qφa,iqφb ,i that can be used to assign
importance to the (a, b) edge of the simplex for variable yi . The computational cost MA can be
reduced by keeping each term with probability p；,b = 4qφ,iqφ,"β∙
Appendices A and B summarize two other FD estimators, ARGMAX Lorberbom et al. (2018) and
ARM Yin & Zhou (2018), by noting their bias-variance tradeoff and computational complexity.
3	Continuous Relaxation Estimators
Unlike FD estimators that use multiple function evaluations to approximate the gradient, continu-
ous relaxation estimators extend the reparameterization trick to discrete variables by approximating
them with continuous variables: z → ζ = ζβ (ρ, qφ), where β is a parameter that controls the ap-
proximation, ρ ∈ U[0, 1] is uniform random variable and qφ are parameterized probabilities.1 We
use the same symbol ζ to denote the random variable and its reparameterization by ρ. The objective
function L[φ] = Pz qφ(z')f (Z) is replaced with L[φ] = EP [f (Z(ρ, qφ))] and its gradients are
computed using the chain rule
dφL[φ] = EPE &"©("(%%)[(…(i∣ζ<i)
(8)
These gradients can be computed efficiently by automatic differentiation libraries. However, because
the objective function is changed, CR estimators in Eq. (8) are biased. Nevertheless, in practice the
bias is often small enough to allow for effective optimization.
3.1	The Gumbel-Softmax Estimator
The most popular CR estimator is Gumbel-Softmax (GSM) (Jang et al. (2016); Maddison et al.
(2016))2. For binary variables, this relaxation takes the simple form
ζi(ρi,qi) = σ (β[σ-1(qi) + σ-1(ρi)]) ,	(9)
1Continuous relaxations have been instrumental in constructing advanced control variate for SF estimates
in Tucker et al. (2017) and Grathwohl et al. (2017). We discuss the REBAR estimator from Tucker et al. (2017)
in Appendix E.
2More precisely, Maddison et al. (2016) considered problems in variational inference where f (z) is relaxed
by replacing a generative distribution with its continuous relaxation. In contrast, Jang et al. (2016) directly
relaxed discrete variables z → ζ without changing the objective, thus replacing f (z) → f (ζ). This does not
produce a consistent objective for a probabilistic model, but as Jang et al. (2016) have shown, works well in
practice. We work with generic f(z) and thus only consider the approach of Jang et al. (2016).
3
Under review as a conference paper at ICLR 2019
(a) Gumbel-Softmax	(b) Piecewise Linear	(c) ∂qζ
Figure 1: Continuous relaxations at β = 2 to a Bernoulli random variable Ber(qφ = 0.8): (a) shows
the GSM approximation and (b) shows a piece-wise linear approximation to the discontinuous CDF.
(c) shows the effect of a modification to GSM that reduces its bias.
where qi ≡ qψ,i(1∖ζ<i). This relaxation and its derivative ∂qζ are shown in Fig. 1(a). β controls
the sharpness of the relaxation and tunes the trade-off between the bias (closeness of ζ to z) and
variance of ∂qZ. We note that the slope of the relaxed Z(P) at Z = 1/2 is ɑ ≡ β∕[4q(1 — q)] and
thus becomes large when q approaches 0 or 1.
3.2	Improved Continuous Relaxation Estimators
In this section, we analyze the bias introduced by Eq. (8) and propose a simple method to reduce
it. The bias of Eρ [∂ζi f(Z)∂φZi] has two sources: (a) the relaxation of Zj for j 6= i and (b) the
relaxation of Zi . To characterize the latter bias, we start with a single binary variable and write the
gradient as the following integral:
∂φL = ∂φqφ f(1) -f(0) = ∂φqφ
Z 1dξ∂ξf(ξ)=∂φqφZ 1
∂ξ
dP∂p∂ξ f(。
(10)
Here, ξ(P) is any continuous function satisfying ξ (0) = 0 andξ(1) = 1. For a non-decreasing
function ξ (P), we can view ξ as a random variable with inverse CDFξ (P) and P as a uniform
random variable P ∈ U[0, 1]. With this interpretation the gradient can be written as an expectation
∂φL = ∂φqφEρ
Vf⑹;
(11)
which can be estimated by sampling. If ∂ξf(ξ) does not vary significantly in the interval ξ ∈ [0, 1]
then the variance of this estimate is controlled by var(∂ξ∕∂ρ) = R(I dρ (∂ξ∕∂ρ)2 一 1. Thus, the
more non-linear ξ(P) is, the higher will be the variance of estimate Eq. (11). This idea can be
extended to factorial qφ(z) = QiM=1 qφ,i(zi) as in Eq. (3):
∂φL
Z∂ξ
dPi Q-dξif (ξ,z∖i).
∂Pi
(12)
At this point there is no relationship between ξi and zi, and Eq. (12) is just a higher variance version
of Eq. (3). However, if we relax z\i → Z\i (P, qφ) and choose ξi (Pi) = Zi(Pi, qφ,i) we obtain a
biased estimator
∂φL ≈ XEρ [∂Zif(Z)等∂φqφ,i] ,	(13)
i	Pi
where the bias comes from the deviation of Z\i from z\i in the function evaluations. In other words,
Eq. (13) uses an unbiased form for the differentiated variable Zi and the only bias comes from
relaxing the remaining variables Z\i .
The variance of each term is controlled by Var (dpi) and is reduced by making Zi(Pi, qψ,i) more
linear. The bias is reduced by making Z closer z. Varying Zi(Pi, qφ,i) between linear (low variance)
and step function (low bias) allows for a controllable trade-off. We call Eq. (13) the improved
continuous relaxation (ICR) estimator. The original CR estimator of Eq. (8) for factorial qφ has the
form
∂Z
dΦL[φ] = EEP dZif(Z)∂qdφqφ,i ,
i
(14)
4
Under review as a conference paper at ICLR 2019
and comparing this to the ICR estimate in Eq. (13), we see that CR can be transformed into ICR
by the replacing ∂qi ζi with ∂ρi ζi. This change can be simply implemented using TensorFlow’s
stop_gradient ≡ Sg notation by replacing
Zi(ρi,qi) with ZiSi + qi - sg(qi),sg(qi))	(15)
in Eq. (8). We emphasize that the ICR estimator in Eq. (13) is less biased than the direct CR
estimator because, in the case of a single variable, ICR is unbiased while CR is not. Further, this
decrease in bias is not accompanied by an increase in variance. We show in Appendix C that similar
benefits are obtained for hierarchical qφ. Finally, we note a conceptual relationship between sampled
RAM and ICR: both estimators evaluate the gradient only through a subset of variables zi . Sampled
RAM chooses this subset explicitly and evaluates the gradients with FD while ICR samples relaxed
variables where only a subset of them will possess non-negligible gradients.
3.3	Piece-wise Linear Relaxation
Inspired by ICR and a better understanding of bias-variance trade-off, we propose a piece-wise
linear relaxation (PWL) depicted in Fig. 1(b). The linear part is centered at ρ = 1 - q so that the
corresponding binary variable is obtained by Z = round(Z). The slope is given by α = β∕[4q(1-q)]
similar to the Gumbel-Softmax slope 3. The explicit expression for PWL smoothing is
ζ(ρ, q) = 0.5 + α(ρ - (1 - q))10,	(16)
where [x]10 ≡ min (1, max [0, x]) is the hard sigmoid function (note that ∂qα = 0). This relaxation
has several attractive properties. Firstly, we have ∂qi ζi = ∂ρiζi, which means that the CR and
ICR estimators coincide for PWL. Secondly, PWL has easily interpretable expressions for bias and
variance. In the case of a function of a single variable the variance is given by var(∂ρζ) = α - 1
while the bias in computing expectation Pz f(z) over the relaxed distribution is dρf (ζ (ρ)) -
Pz f(z) = {R01 dxf(x) - [f (0) + f (1)]∕2}∕α. This clearly shows that a trades bias for variance.
Finally, the PWL relaxation defined in Eq. (16) can be considered as the inverse CDF of the PDF
q(Z) = (1 - e)[(1 - q)δ(Z) + qδ(Z - 1)] + E U[0,1], WhereE = [4q(1 - q)]∕β.	(17)
Eq. (17) is a mixture of two delta distributions centered at zero and one, and a uniform distribution
defined in the interval [0, 1]. Samples from q(ζ) are in the continuous interval with probability
[4q(1 - q)]∕β, and ζ = 0∕1 have probability proportional to the probability of the binary states.
3.4	Categorical Piece-wise Linear Relaxation
We now extend ICR estimators to categorical variables. For a single categorical variable we apply
the integral representation to each edge (a, b) of the simplex in Eq. (5) and relax this pair of variables
using PWL: y → ya，b = {ya = [0.5 + αa,b (ρa,b - qb∕(qa + qb))]J , yb = 1 - ya,yc=a,b = 0}
where Pab 〜 U[0,1] and ɑa,b is the slope. We replace the summation over the edges of the simplex
by sampling one edge at a time with probability pa,b = (qa + qb)∕(A - 1). Details are found in
Appendix D and we provide the final result:
L = E(a,b)〜pa,b [Eρ∈u[0,1] [f(ya,b)]] ,	(18)
where ya,b has the same value as ya,b but has the gradient scaled by Ya,b = (A - 1)(qa + qb).4
The probabilities of edge selection and the scale factor are chosen to give correct values for the
objective and its gradient. Extension of this categorical PWL estimator to multivariate distributions
is straightforward; For example, for factorial distributions one relaxes each categorical variable yi
by sampling an edge with probability pia,b = (qia + qib)(A - 1) and uses a single function evaluation.
The resulting gradient is unbiased for a single variable and introduces a bias in the multivariate case
which makes it an ICR estimator.
3More generally, the slope of the linear part α can be chosen arbitrarily as long as α ≥ 0.5/min(q, 1 - q)
so that both ζ = 0 and ζ = 1 have non-zero probability.
4In Tensorflow notation ya,b ≡ sg(ya,b) + sg(γa,b)(ya,b — sg(ya,b)).
5
Under review as a conference paper at ICLR 2019
(a) Relaxed function
(b) Probability q(z = 1)
(c) Gradient ∂lL
Figure 2: Convex, single binary-variable toy example: (a) The relaxed objectivef (ζ) = (ζ - 0.45)2.
(b) The probability qφ(z = 1) during optimization. (c) The gradient ∂lL of all estimators; the bias
of GSM prevents proper minimization.
3.5	Improved Categorical Gumbel-Softmax Estimator
The sampling done in the categorical PWL estimator leads to increased variance of the gradients.
As an alternative, we suggest an improved version of the categorical Gumbel-Softmax estimator.
Recall that the Gumbel-Softmax estimator for the categorical case has the form:
Za(ρ;q) = softmax(β(logqa + logPa)), WherePa = PgUb,ub~U[0,1].	(19)
In Eq. (20), we propose a new version of this estimator by applying the same trick as in Eq. (15).
This estimator remains biased but we empirically demonstrate that its bias is reduced.
ζ(ρ, q) → ζ(ρ+q- sg(q), sg(q)).
(20)
4	Experiments
In this section We compare the FD and CR estimators and their improved variants on a number of
examples. We start With one-variable toy examples that illustrate the bias of GSM estimator and
then move to the training of variational auto-encoders and a combinatorial optimization problem.
4.1	Toy example
We begin With an illustrative single-variable example (Tucker et al. (2017)) With objective L =
Pz qφ(z)f(z) Where f(z) = (z - 0.45)2. The relaxed convex function f(ζ) depicted in Fig. 2(a)
has tWo local maxima, one of Which is the minimum over the discrete domain. We compare five
gradient methods: RAM, Eq. (2); ARM (see Appendix B); PWL, Eq. (16); GSM, Eq. (9); and
improved Gumbel-Softmax (IGSM), Eq. (15) (see Appendix F for experimental details). Fig. 2(b)
shoWs the evolution of qφ(z = 1) during training Which demonstrates the bias associated With
GSM. To quantify this bias, We plot the value of the gradient of all estimators for different values of
qφ(z = 1) in Fig. 2(c). We observe that the GSM gradient has the Wrong sign for a large interval in
qφ(z = 1) Which prevents GSM from converging to the true minimum.
To understand the nature of the bias that GSM introduces, We plot the derivatives ∂qζ and ∂ρζ
corresponding to GSM and IGSM respectively in Fig. 1(c). We see that ∂qζ is biased toWards the
value of z = round(ζ) that has the highest probability. This means that GSM in Eq. (14) Will
oversample the derivative ∂ζf(ζ) from the most probable mode. In example Fig. 2(a) this results
in oversampling the derivative from z = 0 mode Which creates a gradient that pushes optimization
aWay from the true minimum z = 0. The bias is reduced as β is increased.
In Appendix I.1 We consider an example for a concave function over a binary variable and observe
similar effects. We also consider both concave and convex functions over a categorical variable in
Appendix I.2. In all scenarios, the bias of GSM prevents its convergence to the correct minimum.
6
Under review as a conference paper at ICLR 2019
(a) NELBO
(b) Evaluations per sample
Figure 3: NELBO of the RAM and sampled RAM estimators on MNIST trained using the 200H -
784V architecture having a linear decoder: (a) plots the decrease in training NELBO for RAM and
two variants of sampled RAM. (b) shows the computational savings of sampled RAM.
4.2	Discrete Variational Autoencoders
Next, we test the estimators by training variational autoencoders Kingma & Welling (2013) with dis-
crete priors. The objective is the negative expectation lower bound on the log-likelihood (NELBO):
L[φ,θ] = E Ez〜qφ(z∣x) [fθ,φ(z,x)], where fθ,φ(z,x) = - log
X 〜data
Pθ (Z)pθ (XIz)	(21)
qφ(z∣x)	.	( )
Here, pθ(z) is the prior, pθ(x|z) is the decoder, and qφ(z∣x) is the approximating posterior. L is
minimized with respect to the θ parameters of the generative model and the φ parameters of the
approximate posterior. The latter minimization corresponds to Eq. (1) and we can apply the various
estimators to propagate φ-derivatives through discrete samples z. For CR estimators we replace z
with Z to compute ∂φL[φ, θ] ≈ Px〜data EP [∂φfθ,φ(ζ, x)], where the expectation is evaluated with
a single relaxed sample per data point x. The θ-derivative can be calculated directly from Eq. (21)
using the discrete z variables. Thus, the φ and θ derivatives are evaluated separately requiring two
passes through the computation graph with either relaxed or discrete samples. Jang et al. (2016)
evaluate both derivatives in one pass (using ζ) thereby introducing bias in the θ derivatives. We refer
to these two possibilities as one/two-pass training and compare their performance.
Following Maddison et al. (2016); Jang et al. (2016); Tucker et al. (2017), we consider four archi-
tectures with binary variables denoted by 200H - 784V, 200H - 200H - 784V, 200H 〜784V, and
200H 〜200H 〜784V (see Appendix F for details). First, We compare the sampled RAM estima-
tor of Eq. (7) on 200H - 784V model for different values of β, where the probability of updating
variable Zi is Pi = 4qi(1 - qi)∕β. Fig. 3(a) shows the NELBO on the training set. As expected,
increased β leads to increased gradient variance which slows training. Fig. 3(b) shows the average
number of function evaluations performed in Eq. (7). Many units become deterministic early in
training leading to significant computational savings with the sampled RAM method.
In Fig. 4(a), we include several CR estimators on the same architecture and observe that the GSM
estimator performs significantly worse than other estimators. With linear decoders, the objective
function Eq. (21) is convex in zi . Thus, similar to the example in Fig. 2, GSM learns a distribution
with higher entropy leading to poorer performance. The entropy of all estimators during training
is shown in Fig. 4(b). We note that two-pass training performs better then one-pass training for
all estimators. Although two-pass training requires twice the computation in the worst case, this
overhead is negligible for these models due to GPU parallelization. We observe that ARM performs
poorly confirming that its high variance impedes training. The PWL estimator with two-pass train-
ing performs on par with RAM, while being more computationally efficient. Lastly, the REBAR
estimator (see Appendix E), using the settings of Tucker et al. (2017), performs on par with PWL
thereby indirectly confirming that the relaxed objective is a good control variate for the discrete one.
We used β = 2 in the above experiments, similar to Jang et al. (2016); Maddison et al. (2016). To
understand the dependence on β, we plot final train NELBO in Fig. 4(c). We find that improved
estimators are less sensitive to the choice ofβ.
In Fig. 5, we repeat the experiments for the non-linear architecture 200H 〜784V. The one-pass
GSM estimator exhibits instability which is remedied by two-pass training. However, two-pass
GSM still performs worse than IGSM and PWL due to its bias. Interestingly, one-pass training
works better for IGSM/PWL. We observe this repeatedly in the nonlinear models. Unlike the linear
case, the RAM estimator converges faster initially but later in training is outperformed by the higher-
variance IGSM, PWL and ARM. It is likely that additional noise prevents the latent units from being
7
Under review as a conference paper at ICLR 2019
120
118
Oswz
IOOO 2000	3000	4000
Steps(thousands)
(a) train NELBO
∙0m*0,0
XdaIu9-b
110
IOOO 2000	3000	4000	a
Ste ps(th ou sands)
(b) Entropy of qφ (z)
Oswz
116
115
(c) Final train NELBO
Figure 4: MNIST training on the linear architecture 200H - 784V: (a) compares training NELBO
of CR estimators (all estimators use β = 2). Solid/dashed lines correspond to one/two-pass training.
(b) shows the entropy of the learned posterior approximations; the GSM bias induces much higher
entropy. (c) dependence of the final trained NELBO on β ; higher β corresponds to lower bias.
IOOO 2000	3000	4000
Steps(thousands)
2	4	«	8
2	4	«	8
β
(a) train NELBO	(b) Final train NELBO (c) Final train NELBO, KL an-
neal 10% of training
Figure 5: MNIST training on the non-linear architecture 200H 〜784V: (a) compares training
NELBO of CR estimators (all estimators use β = 2). Solid/dashed lines correspond to one/two-pass
training. (b) Final training NELBO for different β, (c) Final training NELBO using KL annealing;
explicit annealing erases the gains of GSM.
turned off early in training which is known to cause poor performance in VAEs. As in the linear case
we plot the dependence of the final train NELBO on β in Fig. 5(b). The GSM estimator outperforms
IGSM and PWL for β ≥ 4 because its bias favors higher entropy approximating posteriors which
inhibit latent units from turning off early in training. A well known resolution for inactive latent
units is KL-annealing Bowman et al. (2016). Fig. 5(c) shows that KL annealing indeed improves
IGSM and PWL by inhibiting over-pruning of latent units5. As with the linear case, the IGSM
and PWL estimators are more stable under variations in β. Here, REBAR underperforms the ICR
estimators likely due to its higher variance.
Additional results for other VAE models and for categorical variables on both MNIST and OM-
NIGLOT are presented in Appendix I.3 with similar conclusions. The interested reader is referred
to Appendix G for experimental results on training encoder part of a VAE with pretrained genera-
tive model. Appendix H compares estimators for solving the discrete maximum clique optimization
problem analyzed in Patish & Ullman (2018).
5 Conclusion
We have reviewed several finite-difference (FD) and continuous relaxation (CR) estimators of the
gradients of the objective Eq. (1). FD estimators like RAM Tokui & Sato (2017) can give unbiased
low variance estimates but often require multiple function evaluations. We proposed a less expensive
version of RAM that requires an order of magnitude fewer function evaluations with a controllable
decrease in performance. In contrast, CR estimators, like Gumbel-Softmax (GSM), require a single
pass through the objective function and can be computed efficiently giving low variance but biased
gradients. We analyzed the nature of the bias introduced by CR estimators and proposed a way to re-
duce it. This gives rise to improved CR (ICR) estimators, like improved GSM and piece-wise linear.
5In experiments not reported here we observed that the entropy regularizing benefits of the GSM bias can
be achieved with explicit entropy regularization of the objective.
8
Under review as a conference paper at ICLR 2019
These ICR estimators are unbiased for a single variable and less biased for many variables. Exper-
iments on VAE training and discrete optimization confirm the theoretical predictions and illustrate
the advantages of lower-bias estimators.
References
Yoshua Bengio, Nicholas Leonard, and Aaron Courville. Estimating or propagating gradients
through stochastic neurons for conditional computation. arXiv preprint arXiv:1308.3432, 2013.
Samuel R Bowman, Luke Vilnis, Oriol Vinyals, Andrew Dai, Rafal Jozefowicz, and Samy Bengio.
Generating sentences from a continuous space. In Proceedings of The 20th SIGNLL Conference
on Computational Natural Language Learning, pp. 10-21, 2016.
Peter W Glynn. Likelihood ratio gradient estimation for stochastic systems. Communications of the
ACM, 33(10):75-84, 1990.
Will Grathwohl, Dami Choi, Yuhuai Wu, Geoff Roeder, and David Duvenaud. Backpropagation
through the void: Optimizing control variates for black-box gradient estimation. arXiv preprint
arXiv:1711.00123, 2017.
Karol Gregor, Ivo Danihelka, Andriy Mnih, Charles Blundell, and Daan Wierstra. Deep autoregres-
sive networks. arXiv preprint arXiv:1310.8499, 2013.
Shixiang Gu, Sergey Levine, Ilya Sutskever, and Andriy Mnih. Muprop: Unbiased backpropagation
for stochastic neural networks. arXiv preprint arXiv:1511.05176, 2015.
Eric Jang, Shixiang Gu, and Ben Poole. Categorical reparameterization with Gumbel-Softmax.
arXiv preprint arXiv:1611.01144, 2016.
David S Johnson and Michael A Trick. Cliques, coloring, and satisfiability: second DIMACS im-
plementation challenge, October 11-13, 1993, volume 26. American Mathematical Soc., 1996.
Diederik Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint
arXiv:1412.6980, 2014.
Diederik P Kingma and Max Welling. Auto-encoding variational bayes. arXiv preprint
arXiv:1312.6114, 2013.
Guy Lorberbom, Andreea Gane, Tommi Jaakkola, and Tamir Hazan. Direct optimization through
arg max for discrete variational auto-encoder. arXiv preprint arXiv:1806.02867, 2018.
Chris J Maddison, Andriy Mnih, and Yee Whye Teh. The concrete distribution: A continuous
relaxation of discrete random variables. arXiv preprint arXiv:1611.00712, 2016.
Andriy Mnih and Karol Gregor. Neural variational inference and learning in belief networks. arXiv
preprint arXiv:1402.0030, 2014.
Andriy Mnih and Danilo Rezende. Variational inference for Monte Carlo objectives. In International
Conference on Machine Learning, pp. 2188-2196, 2016.
Uri Patish and Shimon Ullman. Cakewalk sampling. arXiv preprint arXiv:1802.09030, 2018.
Tapani Raiko, Mathias Berglund, Guillaume Alain, and Laurent Dinh. Techniques for learning
binary stochastic feedforward neural networks. arXiv preprint arXiv:1406.2989, 2014.
Danilo Jimenez Rezende, Shakir Mohamed, and Daan Wierstra. Stochastic backpropagation and ap-
proximate inference in deep generative models. In International Conference on Machine Learn-
ing, pp. 1278-1286, 2014.
Jason Tyler Rolfe. Discrete variational autoencoders. arXiv preprint arXiv:1609.02200, 2016.
John Schulman, Nicolas Heess, Theophane Weber, and Pieter Abbeel. Gradient estimation using
stochastic computation graphs. In Advances in Neural Information Processing Systems, pp. 3528-
3536, 2015.
9
Under review as a conference paper at ICLR 2019
Michalis Titsias and MigUeI Lazaro-Gredilla. Local expectation gradients for black box variational
inference. In Advances in neural information processing Systems, pp. 2638-2646, 2015.
Seiya TokUi and Issei Sato. EvalUating the variance of likelihood-ratio gradient estimators. In
International Conference on Machine Learning, pp. 3414-3423, 2017.
George TUcker, Andriy Mnih, Chris J Maddison, John Lawson, and Jascha Sohl-Dickstein. Rebar:
Low-variance, Unbiased gradient estimates for discrete latent variable models. In Advances in
Neural Information Processing Systems, pp. 2624-2633, 2017.
Arash Vahdat, Evgeny Andriyash, and William G Macready. DVAE#: Discrete variational aUtoen-
coders with relaxed Boltzmann priors. In Neural Information Processing Systems (NIPS), 2018a.
Arash Vahdat, William G. Macready, Zhengbing Bian, Amir Khoshaman, and Evgeny Andriyash.
DVAE++: Discrete variational aUtoencoders with overlapping transformations. In International
Conference on Machine Learning (ICML), 2018b.
Ronald J Williams. Simple statistical gradient-following algorithms for connectionist reinforcement
learning. In Reinforcement Learning, pp. 5-32. Springer, 1992.
Mingzhang Yin and MingyUan ZhoU. Arm: AUgment-reinforce-merge gradient for discrete latent
variable models. arXiv preprint arXiv:1807.11143, 2018.
10
Under review as a conference paper at ICLR 2019
A ARGMAX
Lorberbom et al. (2018) proposed aFD estimator that we refer to as ARGMAX. For a single variable,
ARGMAX relies on an identity that approximates ∂φL = ∂φqφ [f (1) - f (0)] = (∂φlφ)qφ [1 -
qφ][f (1) - f (0)]. With qφ = σ(lφ), Lorberbom et al. (2018) show that
〃记 〃⑴ fCl I-而 l"θ(f ⑴+ lφ + σ-1(P)) - θ(f (O) + lΦ + σ-1(P)Y
σ(lφ铝-σ(lΦ)][f (1) - f (O)] = limEP -------------------------------------------
→0
(22)
where θ is the Heaviside step function and P 〜U[0,1].6 Lorberbom et al. (2018) approximate the
right side of Eq. (22) by sampling P and evaluating at finite which introduces bias and variance.
Decreasing decreases bias but increases variance.
In the categorical case the gradient of Eq. (5) can correspondingly be written as
∂φL = X ∂φlφlino 1EP
a
a = arg max(1 b + lφb + γb) - a = arg max(lφb + γb) , (23)
bb
where γb = - log(- log(Pb)) are Gumbel variables and [pred] is the indicator function (1 if pred is
true and 0 otherwise). This derivative requires A function evaluations, similar to RAM. Lorberbom
et al. (2018) extend the single variable result to multivariate distributions similar to Eqs. (3) and
(4). ARGMAX has the same computational complexity as RAM, but is biased and has higher
variance than RAM. Thus, it is suboptimal to Eqs. (3) and (4) and for this reason we do not perform
experiments with ARGMAX.
B The Augment-REINFORCE-Merge Estimator
FD estimators are computationally expensive and require multiple function evaluations per gradient.
A notable exception is the Augment-REINFORCE-Merge (ARM) estimator introduced in Yin &
Zhou (2018). ARM provides an unbiased estimate using only two function evaluations for the fac-
torized multivariate distribution, regardless of the number of variables. For a single binary variable,
the ARM derivative is given by
∂φL = ∂φl qφ(1 - qφ)(f (1) - f (O)) = ∂φl EP〜U[0,1] [(f (Z⑵)-f (z⑴))(ρ - 0.5)],
z(1) = θ(qφ - P) z(2) = θ(P - 1 + qφ).	(24)
The expectation is approximated with a single sample P. This estimator has a significantly lower
variance than REINFORCE since the expectation contains the difference f (z(2)) - f(z(1)) rather
then the function itself. For multivariate f and factorial qφ(z) the derivative is
∂φL = X ∂φlφ,i EP〜u[o,i][(f (z(2),z∕i)) - f (z(1),z∕i)))(ρi - 0.5)],	(25)
i
where zi(1) = θ(qφ,i - Pi) and zi(2) = θ(Pi - 1 + qφ,i). Yin & Zhou (2018) observed that one can
replace f(zi(2), z(/1i)) → f (zi(2), z(/2i)) without changing the expectation which allows evaluation by
a single sample and two function evaluations f(z(1)), f(z(2)) regardless of M:
∂φL = X ∂φlφ,i EP〜U[o,i] [(f (z⑵)-f(z⑴))3 - 0.5)].	(26)
i
However, this change comes at the cost of higher variance of the expectation6 7. Thus, while ARM
estimator provides a low-variance gradient estimate for a single variable, it introduces high variance
6We motivate this identity by noting that the non-zero contribution comes from the region σ (-f (1) -
lφ) ≤ ρ ≤ σ(-f (0) - lφ) assuming f (1) > f (0). For small , samples land within this region with
probability P 〜σ(lφ)(1 — σ(lφ))e[f (1) — f (0)] giving rise to the identity. The variance of Eq. (22) is
Var(Ber(P))/e2 X σ(lφ)(1 — σ(lφ))[f ⑴—f (θ)]/e to leading order in 1/e.
7Denoting g(a) (z/i) = f (zi(a) , z/i), a = 1, 2, we can write
VARz/i[g(2)(z/i) — g(1)(z/i)] = VARz/i[g(2)(z/i)] + VARz/i[g(1)(z/i)] — 2COVz/i[g(1)(z/i), g(2)(z/i)],
VARz/i,z0/i [g(2)(z/i) — g(1)(z0/i)] =VARz/i[g(2)(z/i)]+VARz/i[g(1)(z/i)].	(27)
If the functions g(a) (z/i) are highly correlated the ARM estimator will have a much higher variance than RAM.
11
Under review as a conference paper at ICLR 2019
for multivariate functions compared to RAM. The ARM estimator has straightforward extensions to
hierarchical q(z) (similar to Eq. (4)) and to categorical variables Yin & Zhou (2018).
C Improved CR estimator for Bayesian networks
In this appendix We derive the improved CR estimator for a hierarchical qφ(z) = ∏i qφ,i(zi∣z<i).
For simplicity, we do this for two variables qφ(zι, z2) = qφ 2 (z2∣z1)qφ 1(z1) with the gradient given
in Eq. (4):
∂φL = ∂φqφ,1 IEqΦ,2(z2∣i)f(i,z2) - ^qφ,2(z2∣0)f(0, z2)
z2	z2
+ X qφ,ι(z1)∂φqφ,2(l∣z1) [f (zι, 1) - f(zι, 0)]
z1
where qφ,1 = qφ,1(z1 = 1). We denote the two contributions to ∂φL by ∂φL(1,2) and determine
them separately. Using the integral trick (10) the second contribution can be written as
dφL(2) = ^X qφ,1(z1)dφ qφ,2(IIzI) / dρ1 ∂^^^dZ2 f (z1, ζ2) ≈ EP dφqφ,2(IIZI) ~∂^dZ2f (01,02)
z1
(28)
where 02 = g(ρ2, q2(1I01)) and 01 = g(ρ1, q1). The first term can be handled similarly:
dφL(1) = dφqφ,1 Z dρ1 ∂~1 dZi (^X qφ,2(Z2|ZI)f (ZI,z2j ≈ EP dφqφ,1 ∂~1 dZιf (01, 02)
z2	(29)
Combining these contributions we arrive atan expression very similar to the reparameterization trick
with the replacement ∂qi Zi → ∂Pi Zi :
∂φL ≈ ∂φEP [f(Z1,Z2)]∂qiζi→∂ρiζi	(30)
D Categorical PWL estimator
Here, we derive the PWL estimator for categorical variables. The derivative for a single categorical
variable y = (y0, ...yA-1) with ya ∈ {0, 1} and Pa ya = 1 is given in Eq. (5) as
∂φL=∂φXqφ(y)f(y) = X∂φlφa Xqaqb(f a - fb),	(31)
We again apply the integral trick (10) to represent the difference fa - fb . To do that we relax the
variable y so that it interpolates between (ya, yb) = (1, 0) and (ya, yb) = (0, 1) as y → ya,b =
{ya = [0.5 + αa,b(ρa,b - qb∕(qa + qb))] 0 ,yb = 1 - ya, yc=a,b = 0} where ρa,b ∈ U[0,1] and
αa,b is the slope. The relaxed objective then takes the form
L=Z1Ydρa,bXwa,bf(ya,b),	(32)
0 a<b a<b
where wa,b are weights to be determined. The gradient of this relaxed objective with respect to the
logit la is
qaqb	qaqb
∂iaL = EP Ewab∂ρa,b f (ya,b)	q q 2 = Ewab T 2 (f a - fb).	(33)
b6=a	(qa + qb)2	b6=a	(qa + qb)2
Comparison with Eq. (31) gives wa,b = (qa + qb)2. However, computing the sum over the edges of
the simplex is prohibitively expensive, so we choose to replace it with sampling from the set of edges
with probability pa,b = (qa + qb)∕(Pa<b qa + qb) = (qa + qb)∕(A - 1). The reason for choosing
this distribution is that Eq. (32) must give correct value of the objective (not just the derivative) as
12
Under review as a conference paper at ICLR 2019
the relaxation parameter β → ∞, which requires the probability of each state ya = 1 to be equal
to qa . For relaxed edge (a, b) the probability of ya = 1 is equal to qa/(qa + qb), and thus the total
probability of ya = 1 is:
pa,b
b6=a
qa
qa + qb
Σ
b6=a
qa + qb	qa
A - 1 qa + qb
qa.
(34)
Finally, to get the correct weights wa,b we must rescale each term by a factor γa,b = (A-1)(qa +qb)
so that wa,b = γa,bpa,b. In summary, the relaxed objective has the following form:
L = E(a,b)〜pa,b [Eρ∈u[0,1] ff (ya,b)]] ,	(35)
where ya,b has the same value as ya,b but has the gradient scaled by Ya,b = (A - 1)(qa + qb).
E REBAR
In this section, we derive a simple expression for REBAR gradients Tucker et al. (2017) and describe
its connection to ICR estimators. We also present additional experimental results for VAE training
with REBAR for different continuous relaxations.
REBAR gradients of the objective (1) can be written as:
∂φL = Eqφ(z)qφ(Z∣z) [∂φ lθg qφ (Z)(f(z) — f(Z))]+ ∂φEqφ(ζ) [f(Z)] - ∂φEqsg(φ)(z)qφ(Z|z) [f (Z)]，
where sg(φ) denotes “stop gradient"，and distributions qφ(ζ) and qg(Z|z) are reparameterizable.
Using explicit reparameterizations for Z(ρ, qφ) and Z(u, qφ∣z) with U ∈ U[0,1], We can rewrite the
gradient as
∂φL = Eqφ(z)qφ(ζ∣z) [∂φ log qφ(z)(f (z) - f(Z))]+Eρ [∂ζf(Z)∂φZ(ρ,qφ)]-Eqφ(z),u 风f(Z)∂φZ(u,qφ∣z)].
(36)
Focusing on binary variables, the reparameterization for the conditional distribution has the form
Z(u, qφ∣z) = Z(ρ, qφ), where P = 1 - qφ + U (zqφ - (1 - z)(1 - qφ)). In order to minimize
the variance, it is preferable to tie the parameters ρ and (z, u). This can be achieved by setting
z = Θ(ρ - 1 + qφ), and choosing
u
{ρ-1+qΦ
qφ 一
-ρ-1+qΦ
1-qφ
if z = 1,
if z = 0.
(37)
This is equivalent to sampling (z, Z)〜qφ(z)qφ(Z|z) as Z = Θ(ρ - 1 + qφ), Z = Z(p, qφ where
ρ = 1-qφ + Sg(P-1 + qφ) (ZWAI-Z)T--储).
This way p = P by value but P does depend on φ such that Z(p, qφ) has the correct gradient w.r.t. φ
that follows from the conditional distribution qφ(Z|z). We can rewrite (36) as
∂φL = Eqφ(z)qφ(ζ∣z) [∂φ log qφ(z)(f(z) - f(Z))]+Eρ [∂ζf(Z)(∂φZ(ρ, qφ) - ∂φZ(P,qφ))] . (38)
Since the explicit dependence of Z(ρ, qφ) and Z(p, qφ) on qφ is the same, we have ∂φZ(ρ, qφ)-
∂φZ(p, qφ) = -∂φZ(p, sg(qφ)) and we arrive at our final expression for the REBAR gradient:
∂φL = Eρ，z=θ(ρ-i+qφ) [∂φ logqφ(z) (f(z) - f (Z(p,qφ))) - ∂φf(Z(p, sg(qφ)))].	(39)
The advantage of Eq. (39) is two-fold: first, it allows for a simple implementation valid for any
continuous relaxation and uses only two function evaluations. Second, it gives a suggestive relation
to the ICR estimator: indeed using ∂φp = ∂φqφ (-1 + Zρ-j+qφ - (1 - z) ρ--+qφ ) we can write
REBAR gradient as
∂φLREBAR = ∂φLICR + R1 + R2
∂φLICR = Eρ [∂φqφ∂ρZ∂ζf(Z)]
Rl = Eρ,z=Θ(ρ-1+qφ) [-∂φqφ ∂ρZ∂ζ f (Z) (zp-；； qφ - (1 - Z)P--+})]
R2 = Eρ,z=Θ(ρ-1+qφ) [∂φlogqφ(Z) (f(Z) - f(Z(p, qφ)))] .	(40)
13
Under review as a conference paper at ICLR 2019
(a) 200H - 784V	(b) 200H 〜784V
Figure 6: MNIST training with REBAR using GSM and PWL relaxations, dependence of the final
trained NELBO on β : (a) the linear architecture. (b) the non-linear architecture.
Here R1,2 are correction terms. The term R2 can have high variance due to the fact that
var(∂qφ log qφ(z))〜q*q.)while Ri has variance comparable to ∂φLιcR since var(zρ-1+qφ -
(1 - Z) P--+qφ)〜 O ⑴.In summary REBAR estimator can be viewed as ICR plus corrections that
remove the bias of ICR estimator. In practice the correction term R2 can increase the variance of
REBAR estimator compared to ICR and slow down the training.
We now perform the comparison of two types of continuous relaxations used by REBAR estimator.
We train VAE as in Section 4.2 with 200H - 784V and 200H 〜784V architectures using REBAR
with GSM and PWL relaxations. Fig. 6 shows the dependence of the final NELBO on β. In the case
of the linear mode 200H - 784V we find that PWL relaxation is slightly more stable while for the
non-linear model the two relaxations perform similarly.
F	Experimental details
For the toy example of Section 4.1 we optimize L with respect to qφ(z = 1) using Adam (Kingma
& Ba (2014)) for 2000 iterations with learning rate r = 0.01 using minibatches of size 100 to reduce
the variance of gradients. We initialize qφ(z = 1) to the wrong maximum of the relaxed function by
setting qφ(z = 1) = σ(5).
For VAE training experiments, following Maddison et al. (2016); Jang et al. (2016); Tucker et al.
(2017), we consider four architectures with binary variables denoted by 200H - 784V, 200H -
200H - 784V, 200H 〜 784V, and 200H 〜 200H 〜 784V. Here - denotes a linear layer, while
〜 denotes two layers of 200 hidden units with tanh nonlinearity and batch normalization. In our
experiments we use the Adam optimizer with default parameters and a fixed learning rate 0.0003,
run for 4 ∙ 106 steps with minibatches of size 100. We repeat each experiment 5 times with random
seed and plot the mean.
G VAE encoder training
During training of VAEs, the encoder and decoder models interact in complex ways. To eliminate
these effects to more directly identify the impact of better gradients, we use a fixed pre-trained
decoder, and minimize Eq. (21) with respect to encoder parameters φ only. As shown in Fig. 7, the
conclusions from joint training remain unchanged: GSM underperforms due to its bias. Interestingly
however, RAM still overfits early in training for the 200H 〜 784V model, showing that better
gradients can negatively affect optimization.
H Optimization
We apply gradient estimators for discrete optimization. Following Patish & Ullman (2018) we study
the NP-hard task of finding a maximal clique in a graph. To model this problem, the binary variable
zi = 1/0 indicates the presence/absence of vertex i in a maximal clique. If Ai,j is the adjacency
matrix of the graph and d = Pi zi is the size of the clique, then the objective function considered
14
Under review as a conference paper at ICLR 2019
Iio-
6	50	100	150	2«
Ste ps(thousands)
(a) 200H - 784V
IOO
98-，
0	2∞	400	600	8∞
Ste ps(thousands)
(b) 200H 〜784V
Figure 7:	Encoder training the with fixed pre-trained decoder on MNIST: (a) the linear architecture.
(b) the non-linear architecture.
m50*030,01°
8-M V3σ=u
Steps(Hundreds)
(a) κ = 0.1
0	100	200	900	4ββ
Steps(Hundreds)
(b) K = 0.9
0.1 0Λ 0.3	0.4	00	0.6	0.7	0.8	0.9
K
(c) Final max clique size
Figure 8:	Finding maximal cliques in the C1000.9 graph: (a) and (b) show the course of optimization
for two settings of κ and different gradient estimators. (c) plots the final maximal clique size across
κ for the estimators.
in Patish & Ullman (2018) is
f(z)
Ej ZiAijzj
d(d - 1 + κ)
(41)
where κ ∈ [0, 1] is a hyperparameter. Patish & Ullman (2018) use factorial qφ(z ) to minimize
L[φ] = Pz qφ(z)f(z). At the end of optimization qφ(z ) typically collapses to a single state corre-
sponding to a clique. Most often this clique is a local minimum and not the maximal clique.
We illustrate the performance of CR estimators on a particular graph (1000 nodes, 450000 edges),
labeled C1000.9 from the DIMACS data set Johnson & Trick (1996). We minimize f(z) using
Adam with default settings, learning rate 0.01 for 40000 iterations. We perform 1000 minimizations
in parallel and choose the best clique found at each iteration. Fig. 8(a),(b) show the size of clique
found by each of the estimators for two values of the hyperparameter κ = 0.1, 0.9. At κ = 0.1
the bias of GSM causes trapping in the wrong minima but ICR converges to a good local minimum.
In contrast, at κ = 0.9 the GSM bias accelerates convergence to a good local minimum. Fig. 8(c)
shows the dependence of the final clique size on κ; unbiased estimators provide more stable results.
I Additional Experiments
I.1	B inary Concave Toy Example
We evaluate performance on the concave function f(ζ) = -(ζ - 0.45)2 shown in Fig. 9(a). The
training setup is identical to Section 4.1 but with qφ(z = 1) initialized to σ(-5). Fig. 9(b) demon-
strates that the GSM optimization gets trapped in the wrong minimum due to its bias towards the
dominant mode ζ = 0.
15
Under review as a conference paper at ICLR 2019
(a) Concave relaxed function
(b) Probability q(z = 1)
Figure 9: Single binary variable concave toy example. (a) Relaxed function f(ζ) = -(ζ - 0.45)2
(b) Probability qφ(z = 1) during optimization
I.2	Categorical Toy Example
We consider a categorical example with convex and concave functions of a single categorical vari-
able y having 10 values. We take f(y) = ± Pa(ga - ya)2 such that g0 = 0.9, g1 = 1.1, and
gi>1 = 1. The convex function has a minimum at y1 = 1, while the concave function is minimized
at y0 = 1. We compare 4 estimators for minimizing this function: RAM of Eq. (5), PWL of Eq. (18),
GSM of Eq. (19) and IGSM of Eq. (20). The probability of the true minimum is shown in Fig. 10.
In both the convex and concave cases the GSM estimator exhibits a bias preventing it from finding
the minimum. IGSM is less biased than GSM which allows it to find the true minimum. The PWL
estimator is unbiased but has higher variance then IGSM which slows down its optimization.
5∞	I(KK) 1300	2000
Steps
(a) Concave function
0.0
6	500 IOOO 1500	20W
Steps
(b) Convex function
Figure 10:	The probability of the true minimum for a single categorical-variable toy example with
(a) concave function f(y) = - Pa(ga - ya)2 and (b) convex function f(y) = Pa(ga - ya)2
I.3 Discrete Variational Autoencoders
Fig. 11 shows the results for all 4 architectures 200H - 784V, 200H - 200H - 784V, 200H 〜784V,
and 200H 〜200H 〜784V at β = 2. Hierarchical models with two layers of latent units in
Fig. 11(b),(d) exhibit similar trends to the factorial case considered in the main text. The GSM
estimator converges to a higher NELBO in the linear case and becomes unstable in the non-linear
case.
16
Under review as a conference paper at ICLR 2019
Oswz
0	10∞	2000	3000	40∞
Ste ps(thousands)
Oswz
98
6	10∞	2000	3000	4000
Ste ps(thousands)
(b) 200H - 200H - 784V
(a) 200H - 784V
(c) 200H 〜784V
10*
102
Oswz
(d) 200H 〜200H 〜784V
Figure 11:	MNIST training (CR estimators use β = 2). Solid/dashed lines correspond to one/two-
pass training.
We also compare the performance of GSM and IGSM estimators in the categorical case 20 × 10H -
784V with latent space being 20 categorical variables with 10 classes Fig. 12. We see that IGSM
outperforms GSM estimator when using two-pass training. This indirectly confirms that IGSM is
less biased. The PWL estimator performs best indicating the advantages ICR estimators.
104
0
Oswz
IOOO 2000	3000
StePS(Ih OUSandS)
(a)
Figure 12:	MNIST training on categorical linear architecture 20 × 10H - 784V (CR estimators use
β = 2). Solid/dashed lines correspond to one/two-pass training.
For completeness we also show the training curves for OMNIGLOT dataset at β = 2 in Fig 13.
Interestingly, one-pass training performs better in all cases. PWL estimator performs best among
considered CR estimators.
17
Under review as a conference paper at ICLR 2019
ιιa
0	IOOO 2000	3000	4000
Ste ps(thousands)
(a) 200H - 784V
IOOO 2000	3000
Ste ps(thousands)
(c) 200H 〜784V
*^ 6	10∞	2000	3000	4000
Ste ps(thousands)
(b) 200H - 200H - 784V
IOOO 2000	3000	4000
Ste ps(thousands)
(d) 200H 〜200H 〜784V
Figure 13:	OMNIGLOT training (CR estimators use β = 2). Solid/dashed lines correspond to
one/two-pass training.
18