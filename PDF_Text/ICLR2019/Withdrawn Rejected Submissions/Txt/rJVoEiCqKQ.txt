Under review as a conference paper at ICLR 2019
Deep Perm-Set Net: Learn to predict sets with
UNKNOWN PERMUTATION AND CARDINALITY USING
DEEP NEURAL NETWORKS
Anonymous authors
Paper under double-blind review
Ab stract
Many real-world problems, e.g. object detection, have outputs that are naturally
expressed as sets of entities. This creates a challenge for traditional deep neural
networks which naturally deal with structured outputs such as vectors, matrices
or tensors. We present a novel approach for learning to predict sets with unknown
permutation and cardinality using deep neural networks. Specifically, in our
formulation we incorporate the permutation as unobservable variable and estimate
its distribution during the learning process using alternating optimization. We
demonstrate the validity of this new formulation on two relevant vision problems:
object detection, for which our formulation outperforms state-of-the-art detectors
such as Faster R-CNN and YOLO, and a complex CAPTCHA test, where we
observe that, surprisingly, our set based network acquired the ability of mimicking
arithmetics without any rules being coded.
1	Introduction
Deep structured networks such as deep convolutional (CNN) and recurrent (RNN) neural networks
have enjoyed great success in many real-world problems, including scene classification (8), semantic
segmentation (16), speech recognition (6), gaming (12; 13), and image captioning (7). However,
the current configuration of these networks is restricted to accept and predict structured inputs and
outputs such as vectors, matrices, and tensors1. If the problem’s inputs or/and outputs cannot be
modelled in this way, these learning approaches all fail to learn a proper model (26). However, many
real-world problems are naturally described as unstructured data such as sets (21; 26). A set is a
collection of elements which is invariant under permutation and the size of a set is not fixed in
advance. Set learning using deep networks is an emerging field of study that has generated substantial
interest very recently (20; 21; 23; 26).
Consider the task of object detection as an example. Given a structured input, e.g. an image as a
tensor, the goal is to predict a set of orderless locations, e.g. bounding boxes, from an unknown and
varying number of objects. Therefore, the output of this problem can be properly modelled as a set
of entities. However, a deep learning network cannot be simply trained to learn a proper model in
order to directly predict unfixed number of orderless locations. Existing approaches formulate this
problem using as a pre-defined and fixed-sized grid (18; 17) or anchor boxes (19) representing all
possible locations and scales of the objects. Then, each location and scale is scored independently
to contain an object or not. The final output is generated heuristically by a discretization process
such as non-maximum suppression (NMS), which is not part of the learning process. Therefore, their
performance is hindered by this heuristic procedure. To this end, the current solutions can only deal
with moderate object occlusion. We argue that object detection problem can be properly formulated
as a set prediction problem, where a deep learning network is trained to output a set of locations
without any heuristic.
This shortcoming concerns not only object detection but also all problems where a set of instances
(as input or/and output) is involved, e.g. a set of topics or concepts in documents (3), segmentation of
object instances (10) and a set of trajectories in multiple object tracking (2). In contrast to problems
such as classification, where the order of categories or the labels can be fixed during the training
1Throughout the paper, we use the term structured data for vectors, matrices and generally tensors which are
fixed in size and ordered, i.e. any permutation of its values changes its meaning. This is not to be confused with
structured learning which is commonly used for graphs.
1
Under review as a conference paper at ICLR 2019
process and the output can be well represented by a fixed-sized vector, the instances are often unfixed
in number and orderless. More precisely, it does not matter in which order the instances are labelled
and these labels do not relate the instances to a specific visual category. To this end, training a deep
network to predict instances seems to be non-trivial. We believe that set learning is a principled
solution to all of these problems.
In this paper, we present a novel approach for learning to deal with sets using deep learning. More
clearly, in the presented model, we assume that the input (the observation) is still structured, e.g. an
image, but the annotated output is available as a set. Our approach is inspired by a recent work on set
learning using deep neural networks (21). Although the work in (21) handles orderless outputs in the
testing/inference step, it requires ordered outputs in the learning step. This is a significant limitation,
because in many applications, such as object detection, the outputs are naturally not ordered. When
that happens, the approach in (21) cannot learn a sensible model (see Appendix for the experiment).
In this paper, we propose a complete set prediction formulation to address this limitation. This
provides a potential to tackle many more problems compared to (21).
The main contribution of the paper is summarised as follows:
1.	We propose a principled formulation for neural networks to deal with arbitrary sets with
unknown permutation and cardinality as available annotated outputs. This makes a neural
network, for the first time, able to truly handle orderless outputs at both training and test
time.
2.	Additionally, our formulation allows us to learn the distribution over the unobservable
permutation variables, which can be used to identify the most likely orders of the set. In
some applications, there may exist one or several dominant orders, which are unknown from
the annotations.
3.	For the first time, we reformulate object detection as a set prediction problem, where a deep
network is learned end-to-end to generate the detection outputs with no heuristic involved.
We outperform the state-of-the art object detectors, such as Faster R-CNN and YOLO v2,
on both simulated and real data with high level of occlusions.
4.	We also demonstrate the applicability of our framework algorithm for a complex CAPTCHA
test which can be formulated as a set prediction problem.
2	Related Work
Handling unstructured input and output data, such as sets or point patterns, for both learning and
inference is an emerging field of study that has generated substantial interest in recent years. Ap-
proaches such as mixture models (3; 5; 22), learning distributions from a set of samples (14; 15),
model-based multiple instance learning (25) and novelty detection from point pattern data (24), can
be counted as few out many examples that use point patterns or sets as input or output and directly or
indirectly model the set distributions. However, existing approaches often rely on parametric models,
e.g. i.i.d. Poisson point or Gaussian Process assumptions (1; 24). Recently, deep learning has enabled
us to use less parametric models to capture highly complex mapping distributions between structured
inputs and outputs. Somewhat surprisingly, there are only few works on learning sets using deep
neural networks. One interesting exception in this direction is the recent work of (23), which uses
an RNN to read and predict sets. However, the output is still assumed to have a single order, which
contradicts the orderless property of sets. Moreover, the framework can be used in combination with
RNNs only and cannot be trivially extended to any arbitrary learning framework such as feed-forward
architectures. Another recent work proposed by (26) is a deep learning framework which can deal
with sets as input with different sizes and permutations. However, the outputs are either assumed to
be structured, e.g. a scalar as a score, or a set with the same entities of the input set, which prevents
this approach to be used for the problems that require output sets with arbitrary entities. Perhaps the
most related work to our problem is a deep set network recently proposed by (21) which seamlessly
integrates a deep learning framework into set learning in order to learn to output sets. However, the
approach only formulates the outputs with unknown cardinality and does not consider the permutation
variables of sets in the learning step. Therefore, its application is limited to the problems with a
fixed order output such as image tagging and diverges when trying to learn unordered output sets as
for the object detection problem. In this paper, we incorporate these permutations as unobservable
variables in our formulation, and estimate their distribution during the learning process. This technical
extension makes our proposed framework the only existing approach in literature which can truly
learn to predict sets with arbitrary entities and permutations. It has the potential to reformulate some
2
Under review as a conference paper at ICLR 2019
of the existing problems, such as object detection, and to tackle a set of new applications, such as a
logical CAPTCHA test which cannot be trivially solved by the existing architectures.
3	Deep Perm-Set Network
A set is a collection of elements which is invariant under permutation and the size of a set is
not fixed in advance, i.e. Y = {yι, •…，ym,} , m ∈ N*. A statistical function describing a
finite-set variable Y is a combinatorial probability density function p(Y) defined by p(Y) =
p(m)Umpm({yι,y2,∙∙∙ ,ym}), where p(m) is the cardinality distribution of the set Y and
Pm({yι, Ni,…，ym}) is a symmetric joint probability density distribution of the set given known
cardinality m. U is the unit of hyper-volume in the feature space, which cancels out the unit of
the probability density Pm(∙) making it unit-less, and thereby avoids the unit mismatch across the
different dimensions (cardinalities) (25).
Throughout the paper, we use Y = {y 1,…，ym} for a set with unknown cardinality and permutation,
Ym = {yι, •…，ym}m for a set with known cardinality m but unknown permutation and Ym =
(y∏ι, ∙∙∙ , y∏m) for an ordered set with known cardinality (or dimension) m and permutation π,
which means that the m set elements are ordered under the permutation vector π = (π1, π2, . . . , πm).
Note that an ordered set with known dimension and permutation is exactly a structured data such as
vector, matrix and tensor.
According to the permutation invariant property of the sets, the set Ym with known cardinality m can
be expressed by an ordered set with any arbitrary permutation, i.e. Ym := {Y∏m∣∀π ∈ Π}, where,
Π is the space of all feasible permutation Π = {∏ι, ∏2, •…，πmj} and ∣Π∣ := m!. Therefore, the
probability density of a set Y with unknown permutation and cardinality conditioned on the input x
and the model parameters w is defined as
p(Y|x, w) = p(m|x, w) × Um × pm(Ym|x, w),
=p(m∣x, W)X Um X X Pm(Ym, Π∣x, w).	⑴
∀π∈Π
The parameters W models both the cardinality distribution of the set elements p(m∣∙) as well as the
joint state distribution of set elements and their permutation for a fixed cardinality Pm(Ym, π∣∙).
The above formulation represents the probability density ofa set which is very general and completely
independent of the choices of cardinality, state and permutation distributions. It is thus straightforward
to transfer it to many applications that require the output to be a set. Definition of these distributions
for the applications in this paper will be elaborated later.
3.1	Posterior distribution
Given a training set D = {(xi, Yi)}, where each training sample i = 1, . . . , n is a pair consisting of
an input feature (e.g. image), xi ∈ Rl and an output set Yi = {y1, y2, . . . , ymi }, yk ∈ Rd, mi ∈ N*,
the aim to learn the parameters w to estimate the set distribution in Eq. (1) using the training samples.
To learn the parameters w, we assume that the training samples are independent from each other and
the distribution P(x) from which the input data is sampled is independent from both the output and
the parameters. Then, the posterior distribution over the parameters can be derived as p(w∣D) 8
n
p(D∣w)p(w) bɪɪ p(mi∣Xi, w) X Umi X E Pm(∏∣Xi, w) X Pm(Ymi ∣Xi, w, π) p(w).
i=1
∀π∈Π
Note that Pm(Ymi, π∣∙) is decomposed according to the chain rule and P(X) is eliminated as it
appears in both the numerator and denominator. We also assume that the outputs in the set are derived
from an independent and identically distributed (i.i.d.)-cluster point process model. Therefore,the full
posterior distribution can be written as
n	πmi
P(w∣D) bɪɪ P(mi∣Xi, w) X Umi XE I Pm(∏∣Xi, w) X ɪɪ P(yσ ∣Xi, w, π)
i=1	∀π∈Π	σ=π1
P(w). (2)
In this paper, we use two categorical distributions to define cardinality P(m∕∙, ∙) and permutation
Pm(∏∣∙, ∙) terms. However depending of the application, any discrete distribution such as Poisson,
3
Under review as a conference paper at ICLR 2019
binomial, negative binomial or Dirichlet-categorical (cf. (20; 21)), can be used for these terms.
Moreover, we find the assumption about i.i.d. cluster point process practical for the reported
applications. Nevertheless, the extension to non-i.i.d. cluster point process model for any other
application would be a potential research direction for this work.
3.2	Learning
For learning the parameters, We use a point estimate for the posterior, i.e. p(w∣D) = δ(w = w* |D),
where w* is computed using the MAP estimator, i.e. w* = argminw - log (P (w∣D)). Since W
in this paper is assumed to be the parameters of a deep neural netWork, to estimate w*, We use
commonly used stochastic gradient decent (SGD), Wk = wk-1 - η-d logdWWk-11D)), where η is
the learning rate. Moreover during learning procedure, we approximate the marginalization over
all permutations, which can be infeasible for large permutation space, with the most significant
permutations for each training instance, i.e.
Pm(∏∣Xi, w)= X ω∏(Xi, w)δ(π) ≈ N X ω∏i,,k(Xi, w)δ(π*,k),	(3)
∀∏∈∏	NK ∀∏* k∈∏
where δ(∙) is Kronecker delta and E∀∏∈∏ ω∏(∙, ∙) = 1. π*k is the most significant permutation for
the training instance i, sampled fromPm(∏∣∙, ∙) X Q∏=∏1 p(yσ∣∙, ∙, ∏) during kth iteration of SGD
(using Eq. 5). The weight ω∏* ((∙, ∙) is proportional to the number of the same permutation samples
π*k(∙, ∙), extracted during all SGD iterations for the training instance i and NK is the total number
of SGD iterations. Therefore, P∀∏* ∈∏ ω∏* (∙, ∙)∕Nκ = 1. Note that at every iteration, as the
πi,k ∈Π	i,k
parameter w updates, the best permutation πi*,k can change accordingly even for the same instance
Xi. This allows the network to traverse through the entire space Π and to approximate pm (π |Xi, w)
by a set of significant permutations. To this end, pm(π∣Xi, w) is assumed to be point estimates for
each iteration of SGD. Therefore,
p(wk|D)
n	πmi
2S ɪɪ p(mi∣Xi, wk) × U mi × ω∏*,k (Xi, wk) ×∩ p(yσ ∣Xi, Wk, ∏*,k) p(wj (4)
i=1	σ=π1
To compute wk and πi*,k, we use alternating optimization and use standard backpropagation to learn
the parameters of the deep neural network.
πi*,k = arg πmiΠn	f1 Yπmi, O1(Xi, wk-1) + f2 π, O2(Xi, wk-1) ,	(5)
_	Sl^df1 Ym*ik, O1 ∂Oι	df2(π*,k, O2)∂O2	df3(mi, a)
Wk=wk-1 -ηy —∂o -. E+-∂O-. Iw+-∂a-
∂wi+2γW ⑹
where Y is the regularization parameter, f1 (Ymi, O1(Xi, W)) = - Pσ=∏ι log (p(yσ ∣Xi, w, π)),
f2(∏, O2(Xi, W)) = - log (ω∏ (Xi, W)), and f3 (mΜ a(Xi, W)) = - log(p(m∕Xi, w)), where
a(∙, ∙), O1(∙, ∙) and O2 (∙, ∙) represent the part of output layer of the network, which respectively
predict the cardinality, the states and the permutation of the set elements (Fig. 1).
Note that Eq. 5 is a discrete optimization to find the best permutation πi*,k, i.e. the best unique
assignment of ground truth to the output of the networks, which can be attained (Optimally or
sub-optimally) using any independent discrete optimization approach. Therefore, the quality of its
solution depends on the description of f1 and f2 and the solver. In this paper, since we assume that the
set elements are i.i.d., therefore f1 would be a linear objective. Empirically, in our applications, we
found out that estimation of the permutations from just f1 is sufficient to train the network properly.
In this case, the permutation can be optimally found in each iteration in polynomial time using the
Hungarian algorithm. Finally, πi*,k representing a permutation sample, is used as the ground truth to
update f2(∙) and to sort the elements of the ground truth set,s state in the f1(∙) term in Eq. 6.
3.3	Inference
Having learned the network parameters w*, for a test input X+, we use a MAP estimate to generate a
set output, i.e. Y* = arg min - log p(Y |D, X+, w*)
4
Under review as a conference paper at ICLR 2019
Output Layer
Dense Dense
Conv
Input Layer
D
⅛
Conv
S∙∙s s∙∙s 0∙∙s
o2 π*
Inference
α
Figure 1: A schematic for our Deep Perm-Set Network. A structured input, e.g. an RGB image, is fed to a
series of convolutional and fully connected layers with a collection of parameters shown by w. The output layer
consists of three parts shown by α, O1 and O2, which respectively predict the cardinality, the states and the
permutation of the set elements. During the training, π*,k representing a permutation sample (attained by Eq. 5),
is used as the ground truth to update the loss f2 (π*,k, O2) and to sort the elements of the ground truth set,s state
in the fι(Y∏* k, Oι) term in Eq. 6. During inference, the optimal set Y* is only calculated using the cardinality
ɑ and the states Oi outputs. π* is an extra output for ordering representation.
Note that in contrast to the learning step, the way which the set elements during the predic-
tion step are sorted and represented, will not affect the output values and therefore, the product
Qσ=∏ι p(yσ∣x+, w*, ∏) is exactly same for any permutation, i.e. ∀π ∈ Π. Therefore, it can
be factorized from the summation, i.e. log Pπ∈Π (pm(n|x+, w*) X QnmnI p(yσ |x+, w*, n))
log	Qm=1 p(yσ |x+ , w*) X Epm(n|x+, w*)	= Pm=1 log(p(yσ |x+ , w*)) ∙
π∈Π
'---------
=1
Therefore, the inference will be simplified to
}
Y * = argmin - log (p(m|:
m
∣x+, w*)) — m log U — X log (p(yσ |x+, w*)).	(7)
^{^^^^^^}	^^^^^^^{.z^^^^^}
{z
α
σ=1
^{z
O1σ
The above problem is the same inference problem as (21) and therefore can be optimally and
efficiently calculated to find the most likely set Y* = (m*, Ym* ). The unit of hyper-volume U is
assumed as a constant hyper-parameter, estimated from the validation set of the data.
As mentioned before, the distribution pm(∏∣∙, ∙) is approximated during the learning procedure by
the samples π*k attained from Eq. (5). Depending on application, pm(π∣∙, ∙) can be a single modal,
multimodal or uniform distribution over the permutations. In any cases for ordering representation,
the best permutation can be used, i.e. π* = arg max∏∈∏ pm(π∣x+, w*).
A schematic for our set prediction neural network has been shown in Fig. 1. 4
4	Experimental Results
To validate our proposed set learning approach, we perform experiments on two relevant applications
including i) object detection and ii) a CAPTCHA test to perform de-summation operation for a digit
from a set of digits. Both are appropriate applications for our model as their outputs are expected to
be in the form of a set, either a set of locations or a set of candidate digits, with unknown cardinality
and permutation.
4.1 Object detection.
Our first experiment is used to test our set formulation for the task of pedestrian detection. We
compare it with the state-of-the art object detectors, i.e. Faster-RCNN (19) and YOLO v2 (17). To
5
Under review as a conference paper at ICLR 2019
ensure a fair comparison, we use the exactly same base network structure (ResNet-101) and train
them on the same training dataset2 *.
Dataset. We use training sequences from MOTChallenge pedestrian detection and tracking bench-
mark, i.e. 2DMOT2015 (9) and MOT17Det (11), to create our dataset. Each sequence is split into
train and test sub-sequences, and the images are cropped on different scales so that each crop contains
up to 4 pedestrians. Our aim is to show the main weakness of the existing object detectors, i.e. the
heuristics used for handling partial occlusions, which is crucial in problems like multiple object
tracking and instance level segmentation. To this end, we only evaluate the approaches on small-scale
data which include a single type of objects, e.g. pedestrian, with high level of occlusions. The
resulting dataset has 50K training and 5K test samples.
Formulation. We formulate the object detection as a set prediction problem Y = {yι,…，ymJ,
where each set element represents a bounding box as y = (x, y, w, h, s) ∈ R5 , where (x, y) and
(w, h) are respectively the bounding boxes’ position and size and s represents an existence score for
this set element.
Training. We train a convolutional neural network based on a standard ResNet-101 architecture,
with loss heads directly attached to the the output of the ResNet. According to Eqs. (5, 6), there are
three main terms (losses) that need to be defined for this task. Firstly, the state loss fι(∙) consists of
two parts: i) Smooth L1-loss for the bounding box regression between the predicted output states
and the permuted ground truth states, ii) Binary cross-entropy loss for the presence scores s. The
ground truth score for a specific instance is 1 if it exists and 0 otherwise. The permutation is estimated
iteratively using alternation according to Eq. (5) using Hungarian (Munkres) algorithm. Secondly,
a categorical loss (Softmax) is used for the permutation f2(∙). Since this variable is not observable
from the annotations, π^ is calculated to estimate the ground truth permutation(s). Finally, for
cardinality f3(∙), a categorical loss is used in a similar fashion.
For training we use Adam optimizer with learning rate of 0.001, β1 = 0.9, β2 = 0.999 and = 10-8.
To accelerate and stabilize the training process, batch normalization is employed and a weight decay
of 0.0001 was used as an additional regularization term. The hyper-parameter U is set to be 0.1,
adjusted on the validation set.
Evaluation protocol. To quantify the detection performance, we adopt the commonly used
evaluation curves and metrics (4) such as ROC, precision-recall curves, average precision (AP)
and the log-average miss rate (MR) over false positive per image. Additionally, we com-
pute the F1 score (the harmonic mean of precision and recall) for all competing methods.
Detection results. Quantitative detection re-
sults for Faster-RCNN, YOLO v2 and our
proposed detector are shown in Tab. 1. Since
our detector generates a single set only (a
set of bounding boxes) using the inference
introduced in Sec. 3.3, there exists one single
value for precision-recall and thus F1-score.
For this reason, the average precision (AP)
and log-average miss rate (MR) calculated
over different thresholds cannot be reported
Table 1: Detection results on the real data measured by
average precision, the best F1 scores (higher is better) and
log-average miss rate (lower is better).
Method	AP ↑	F1-score↑	MR ；
Faster-RCNN	0.68	0.76	0.48
YOLO v2	0.68	0.76	0.48
Our Detector (w/o card.)	0.75	0.80	0.47
Our Detector	-	0.80	
in this case. To this end, we report these values on our approach using the predicted boxes with their
scores only, and ignore the cardinality term and the inference step. To ensure a fair comparison,
the F1-score reported in this table reflects the best score for Faster-RCNN and YOLO v2 along the
precision-recall curve.
The quantitative results of Tab. 1 show that our detector using the set formulation significantly
outperforms all other approaches on all metrics. We further investigate the failure cases for Faster-
RCNN and YOLO v2 in Fig. 2. In case of heavy occlusions, the conventional formulation of both
methods, which include the NMS heuristics, is not capable of correctly detecting all objects, i.e.
pedestrians. Note that lowering the overlapping threshold in NMS in order to tolerate a higher level
of occlusion results in more false positives for each object. In contrast, more occluding objects are
miss-detected by increasing the value of this threshold. Therefore, changing the overlap threshold for
NMS heuristics would not be conducive for improving their detection performances.
2We also evaluate the detectors on synthetically generated data. Experiments showing the superior perfor-
mance of our algorithm compared YOLO v2 and Faster-RCNN on this data can be found in Appendix.
6
Under review as a conference paper at ICLR 2019
(b)
(a)
(c)
Figure 2: A comparison between the detection performance of (a) Faster-RCNN, (b) YOLO v2 and (c) our set
detector on heavily overlapping pedestrians from MOTChallenge benchmark. Both Faster-RCNN and YOLO v2
fail to properly detect heavily occluded pedestrians due to the inevitable NMS heuristic.
1
overlap level (IoU)
(a)
(b)
fppi
(C)
Figure 3: (a) The best F1 sCores against the level of objeCt oCClusions CalCulated by interseCtion of union
(IoU), (b) PreCision-ReCall Curve, and (C) ROC (miss rate-false positive per image) Curve on pedestrian deteCtion
data for the Competing deteCtors: Faster-RCNN, YOLO v2, our network (w/o Cardinality) and our network (w/
Cardinality). Our final deteCtion results are also shown as a single point in the Curves.
In Contrast, our set learning formulation naturally handles heavy oCClusions (see Fig. 2) by outputting
a set of deteCtions with no heuristiC involved. Fig. 3(a) also shows the superior performanCe of
our formulation in deteCting the objeCts with severe oCClusion. Our method has an improvement of
5-15% in F1 sCore Compared to YOLO v2 and Faster-RCNN for high overlap level (IoU) between
0.3 - 0.7. The overall performanCe ROC and preCision-reCall Curves for Faster-RCNN, YOLO v2
and our deteCtor (w/o Cardinality) are shown in Fig. 3(b) and (C). Note, that the single point in these
Curves represents our final deteCtion result. Our approaCh outperforms other Competing approaChes
with the highest F1-sCore and also the lowest miss rate given the same rate of false positives per
image. This is signifiCant as our set network is not yet well-developed for the deteCtion task while
YOLO v2 and Faster-RCNN are well engineered for this appliCation.
4.2 CAPTCHA test for de-summing a digit
We also evaluate our set formulation on a CAPTCHA test where the aim is to determine whether a
user is a human or not by a Complex logiCal test. In this test, the user is asked to deCompose a query
digit shown as an image (Fig. 4(left)) into a set of digits by CliCking on a subset of numbers in a noisy
image (Fig. 4(right)) suCh that the summation of the seleCted numbers is equal to the query digit.
In this puzzle, it is assumed there exists only one valid solution (inCluding an empty response). We
target this Complex puzzle with our set learning approaCh. What is assumed to be available as the
training data is a set of spotted loCations in the set of digits image and no further information about
the represented values of query digit and the set of digits is provided. In praCtiCe, the annotation Can
be aCquired from the users’ CliCk when the test is suCCessful. In our Case, we generate a dataset for
this test from the real handwriting MNIST dataset.
Data generation. The dataset is generated using the MNIST dataset of handwritten digits.
The query digit is generated by randomly
seleCting one of the digits from MNIST
dataset. Given a query digit, we Create a se-
ries of random digits with different length
suCh that there exists a subset of these dig-
its that sums up to the query digit. Note that
in eaCh instanCe there is only one solution
(inCluding empty) to the puzzle. We plaCe
the Chosen digits in a random position on
a 300 × 75 blank image with different ro-
Figure 4: A query digit (left) and a set of digits (right) for the
proposed CAPTCHA test. The ground truth and our prediCted
solutions are shown by white and red boxes respeCtively.
7
Under review as a conference paper at ICLR 2019
tations and sizes. To make the problem more challenging, random white noise is added to both
the query digit and the set of digits images (Fig. 4). The produced dataset includes 100K problem
instances for training and 10K images for evaluation, generated independently from MNIST training
and test sets.
Baseline method. Considering the fact that only a set of locations is provided as ground truth, this
problem can be seen as an analogy to the object detection problem. However, the key difference
between this logical test and the object detection problem is that the objects of interest (the selected
numbers) change as the query digit changes. For example, in Fig. 4, if the query digit changes to
another number, e.g. 4, the number {4} should be only chosen. Thus, for the same set of digits, now
{1, 2, 5} would be labeled as background. Since any number can be either background or foreground
conditioned on the query digit, this problem cannot be trivially formulated as an object detection
task. To prove this claim, as a baseline, we attempt to solve the CAPTCHA problem using a detector,
e.g. the Faster-RCNN, with the same base structure as our network (ResNet-101) and trained on the
exactly same data including the query digit and the set of digits images.
Implementation details. We use the same set formulation as in the previous experiment on object
detection. Similarly, we train the same network structure (ResNet-101) using the same optimizer and
hyper-parameters as described in 4.1. We do not, however, use the permutation loss f2(∙) since We
are not interested in the permutation of the detected digits in this experiment. However, we still need
to estimate the permutations iteratively using Eq. 5 to permute the ground truth for fι(∙).
The input to the network is both the query digit and the set of digits images and the network outputs
bounding boxes corresponding to the solution set. The hyper-parameter U is set to be 2, adjusted on
the validation set.
Evaluation protocol. Localizing the numbers that sum up to the query digit is important for this
task, therefore, we evaluate the performance of the network by comparing the ground truth with the
predicted bounding boxes. More precisely, to represent the degree of match between the prediction
and ground truth, we employ the commonly used Jaccard similarity coefficient. If IoU(b1,b2) > 0.5
for all the numbers in the solution set, we mark the instance as correct otherwise the problem instance
is counted as incorrect.
Results. The accuracy of our set prediction approach to solve this logical problem on the test dataset
is 95.6%. The Faster-RCNN detector failed to solve this test with an accuracy of 26.8%. In fact,
Faster-RCNN only learns to localize digits in the image and ignores the logical relationship between
the objects of interest. Faster-RCNN is not capable of performing reasoning in order to generate
the sensible score for a subset of objects (digits). In contrast, our set prediction formulation gives
the network the ability of mimicking arithmetic implicitly by end-to-end learning the relationship
between the inputs and outputs from the training data. In fact, the set network is able to generate
different sets with different states and cardinality if one or both of the inputs change. We believe
that this is a far more interesting outcome, as it show the potential of our formulation to tackle any
other arithmetical, logical or semantic relationship problems between inputs and output without any
explicit knowledge about arithmetic, logic or semantics.
5 Conclusion
In this paper, we proposed a framework for predicting sets with unknown cardinality and permutation
using convolutional neural networks. In our formulation, set permutation is considered as an
unobservable variable and its distribution is estimated iteratively using alternating optimization.
We have shown that object detection can be elegantly formulated as a set prediction problem, where a
deep network can be learned end-to-end to generate the detection outputs with no heuristic involved.
We have demonstrated that the approach is able to outperform the state-of-the art object detections on
real data including highly occluded objects. We have also shown the effectiveness of our set learning
approach on solving a complex logical CAPTCHA test, where the aim is to de-sum a digit into its
components by selecting a set of digits with an equal sum value.
The main limitation of the current framework is that the number of possible permutations exponentially
grows with the maximum set size (cardinality). Therefore, applying it to large-scale problem is
not straightforward and requires an accurate approximation for estimating a subset of dominant
permutations. In future, we plan to overcome this limitation by learning the subset of significant
permutations to target real-world large-scale problems such as multiple object tracking.
8
Under review as a conference paper at ICLR 2019
References
[1]	Ryan Prescott Adams, Iain Murray, and David JC MacKay. Tractable nonparametric bayesian
inference in Poisson processes with gaussian process intensities. In ICML, pp. 9-16, 2009.
[2]	Boris Babenko, Ming-Hsuan Yang, and Serge Belongie. Robust object tracking with online
multiple instance learning. IEEE transactions on pattern analysis and machine intelligence, 33
(8):1619-1632, 2011.
[3]	David M Blei, Andrew Y Ng, and Michael I Jordan. Latent dirichlet allocation. Journal of
machine Learning research, 3(Jan):993-1022, 2003.
[4]	Piotr Dolldr, Christian Wojek, Bernt Schiele, and Pietro Perona. Pedestrian detection: An
evaluation of the state of the art. PAMI, 34, 2012.
[5]	Lauren A Hannah, David M Blei, and Warren B Powell. Dirichlet process mixtures of general-
ized linear models. Journal of Machine Learning Research, 12(Jun):1923-1953, 2011.
[6]	Geoffrey Hinton, Li Deng, Dong Yu, George E Dahl, Abdel-rahman Mohamed, Navdeep
Jaitly, Andrew Senior, Vincent Vanhoucke, Patrick Nguyen, Tara N Sainath, et al. Deep neural
networks for acoustic modeling in speech recognition: The shared views of four research groups.
IEEE Signal Processing Magazine, 29(6):82-97, 2012.
[7]	Justin Johnson, Andrej Karpathy, and Li Fei-Fei. Densecap: Fully convolutional localization
networks for dense captioning. 2016.
[8]	Alex Krizhevsky, Ilya Sutskever, and Geoffrey E. Hinton. ImageNet classification with deep
convolutional neural networks. In NIPS*2012, pp. 1097-1105.
[9]	Laura LeaI-Taixa Anton Milan, Ian D. Reid, Stefan Roth, and Konrad Schindler. Motchallenge
2015: Towards a benchmark for multi-target tracking. CoRR, abs/1504.01942, 2015.
[10]	Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan,
Piotr Dolldr, and C Lawrence Zitnick. Microsoft coco: Common objects in context. In IEEE
Europ. Conf. Comput. Vision (ECCV), pp. 740-755, 2014.
[11]	Anton Milan, Laura LeaI-TaixaIan D. Reid, Stefan Roth, and Konrad Schindler. MOT16: A
benchmark for multi-object tracking. CoRR, abs/1603.00831, 2016.
[12]	Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Alex Graves, Ioannis Antonoglou, Daan
Wierstra, and Martin Riedmiller. Playing atari with deep reinforcement learning. arXiv preprint
arXiv:1312.5602, 2013.
[13]	Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Andrei A Rusu, Joel Veness, Marc G
Bellemare, Alex Graves, Martin Riedmiller, Andreas K Fidjeland, Georg Ostrovski, et al.
Human-level control through deep reinforcement learning. Nature, 518(7540):529-533, 2015.
[14]	Krikamol Muandet, Kenji Fukumizu, Francesco Dinuzzo, and Bernhard Scholkopf. Learning
from distributions via support measure machines. In NIPS, pp. 10-18, 2012.
[15]	Junier Oliva, Barnabds P6czos, and Jeff Schneider. Distribution to distribution regression. In
ICML, pp. 1049-1057, 2013.
[16]	George Papandreou, Liang-Chieh Chen, Kevin P. Murphy, and Alan L. Yuille. Weakly- and
semi-supervised learning of a deep convolutional network for semantic image segmentation.
December 2015.
[17]	Joseph Redmon and Ali Farhadi. Yolo9000: better, faster, stronger. In Proc. IEEE Conf. Comput.
Vis. Patt. Recogn. (CVPR), 2017.
[18]	Joseph Redmon, Santosh Divvala, Ross Girshick, and Ali Farhadi. You only look once: Unified,
real-time object detection. In Proc. IEEE Conf. Comput. Vis. Patt. Recogn. (CVPR), pp. 779-788,
2016.
[19]	Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun. Faster r-cnn: Towards real-time
object detection with region proposal networks. In NIPS, pp. 91-99, 2015.
9
Under review as a conference paper at ICLR 2019
[20]	Seyed Hamid Rezatofighi, Vijay Kumar BG, Anton Milan, Ehsan Abbasnejad, Anthony Dick,
and Ian Reid. Deepsetnet: Predicting sets with deep neural networks. In ICCV, 2017.
[21]	Seyed Hamid Rezatofighi, Anton Milan, Qinfeng Shi, Anthony Dick, and Ian Reid. Joint
learning of set cardinality and state distribution. In AAAI, 2018.
[22]	Nhat-Quang Tran, Ba-Ngu Vo, Dinh Phung, and Ba-Tuong Vo. Clustering for point pattern data.
In ICPR, pp. 3174-3179.IEEE, 2016.
[23]	Oriol Vinyals, Samy Bengio, and Manjunath Kudlur. Order matters: Sequence to sequence for
sets. ICLR, 2015.
[24]	Ba-Ngu Vo, Nhat-Quang Tran, Dinh Phung, and Ba-Tuong Vo. Model-based classification and
novelty detection for point pattern data. In ICPR, pp. 2622-2627. IEEE, 2016.
[25]	Ba-Ngu Vo, Dinh Phung, Quang N Tran, and Ba-Tuong Vo. Model-based multiple instance
learning. arXiv, 2017.
[26]	Manzil Zaheer, Satwik Kottur, Siamak Ravanbakhsh, Barnabas Poczos, Ruslan Salakhutdinov,
and Alexander Smola. Deep sets. In NIPS, 2017.
10
Under review as a conference paper at ICLR 2019
Appendix
This appendix accompanies and completes the main text. We first provide more information about
the generated synthetic dataset and add more detailed results and comparison on this dataset. We
also show how our approach can simultaneously detect and identify similar looking object instances
across the test data due to the learning of the permutation variables. This paves the path towards
end-to-end training of a network for multiple object tracking problem. Next, we include an extra
baseline experiment showing the ineffectiveness of training the set network proposed in (1) for object
detection problem. Finally, we present extra analysis and additional experiments on the CAPTCHA
test experiment.
1 Object detection
Synthetic data generation. To evaluate our proposed object detector, we generate 55000 synthetic
images with resolution 200x200 pixels, including 50000 images for training and 5000 for testing. For
each synthetic image, we use a central crop of a randomly picked COCO 2014 image as background.
The background images for our train and test sets were correspondingly taken from COCO 2014 train
and validation sets in order to introduce less similarity between our train and test data. A random
number of objects (from 0 to 4) is then rendered on the background. An object is a circle of radius r
approximated by using Bezier curves, where r is randomly sampled between 25 and 50 pixels. Once
the object has been created, random perturbations are applied on the control points of the curves
in order to obtain a deformed ellipsoid as a result. Each object is either of red, green, yellow or
blue color, with a certain variation of tone and brightness to simulate visual variations in natural
images. To make the data more challenging, we allow severe overlap of the objects in the image - the
intersection over union between a pair of object instances may be up to 85%. Also, random Gaussian
noise is added to each image (See Figs. 5).
Figure 5: A comparison between the detection performance of (a) Faster-RCNN, (b) YOLO and (c) our set
detector on heavily overlapping objects. Both Faster-RCNN and YOLO fail to properly detect heavily occluded
objects due to the inevitable NMS heuristic.
Detection results. Quantitative detection results on this dataset for Faster-RCNN, YOLO v2 and our
proposed detector are shown in Tab. 2.
Similar to real data scenario, our detector using the set formulation outperforms all other approaches
w.r.t. all types of metrics. Considering the simplicity of the data and the very deep network used, i.e.
ResNet-101, all methods work very well on localizing most of the objects with or without moderate
partial occlusions. However, our set learning formulation naturally handles heavy occlusions (see
Fig. 5) by outputting a set of detections with no heuristic involved.
Fig. 6(a) also shows the superior performance of our formulation in detecting the objects with severe
occlusion, quantitatively (about 20% improvement in F1 score compared to YOLO v2 and faster-
RCNN for overlap level (IoU) above 0.5). The ROC and precision-recall curves for Faster-RCNN,
YOLO v2 and our detector (w/o cardinality) are demonstrated in Fig. 6(b) and (c). Our approach
Table 2: Detection results on the synthetic data measured by average precision, the best F1 scores (higher is
better) and log-average miss rate (lower is better).
Method	AP ↑	F1-score↑	MR ；
FaSter-RCNN	0.81	0.88	0.21
YOLO	0.86	0.91	0.17
Our Detector (w/o cardinality)	0.93	0.95	0.15
Our Detector	-	0.96	
11
Under review as a conference paper at ICLR 2019
outperforms other competing approaches with the highest F1-score and also the lowest miss rate
given the same rate of false positives per image.
overlap level (IoU)
(a)
1
0.8
：|0.6
		
厂	—―	I	1
—Faster R-CNN 一YOLO -OUr network (w/o cardinality) X OUr network (w/ CardinaIity)		
0.2
0
0	0.2	0.4	0.6	0.8	1
recall
(b)
fppi
(c)
Figure 6: (a) The best F1 scores against the level of object occlusions calculated by intersection of union (IoU),
(b) Precision-Recall curve, and (c) ROC (miss rate-false positive per image) curve on synthetic data for the
competing detectors: Faster-RCNN, YOLO, our network (w/o cardinality) and our network (w/ cardinality). Our
final detection results are also shown as a single point in the curves.
Detection & Identification results. In addition to the prediction of bounding boxes, our approach
also provides the best ordering representation π* for the bounding boxes for each input instance.
In this dataset, this is equivalent to finding the association between bounding boxes belonging to
similarly looking instances across the different images without any knowledge about this corre-
spondence. For example, by testing three different images in Fig 7, three sets of bounding boxes
and their permutations, e.g. (2, 3), (2, 1, 3) and (3, 4, 2, 1), are predicted. If the bounding boxes
are re-ordered according to their permutations in a descend or ascend order, each correspond-
ing bounding boxes in each set will be associated to the similarly looking objects in each image.
Therefore, we can simultaneously detect and
identify the similarly looking instances for
different test examples, e.g. for each frame
of a video sequence.
Note that this problem cannot be formulated
as a classification problem as we do not as-
sume a fixed labelling representation for set
instances. In fact, the number of identifiable
Figure 7: The performance of our approach in detecting
and also identifying the object instances using permutations.
The similar colours’ boxes identify the same objects.Here
we used color coding to represent the same ID.
unique instances only depends on the maxi-
mum number of set elements outputted from
our network.
For evaluation purposes only, we use the as-
sociations between similarly looking objects
which are available from our simulated data. For example, all bounding boxes belonging to the
red object within the dataset with all its visual variations can be assumed to be the same instance.
Therefore, we can evaluate our identification performance using this information. To assess the
results, we use the permutation accuracy. We achieve 81.1% accuracy in identifying the similarly
looking objects. Fig. 7 shows the detection and identification results for three different images.
This joint detection and identification of the objects can be a fundamental step toward end-to-end
training of a network for the multiple object tracking problem. However, the current formulation
cannot handle large-scale object tracking problems due to the exponential number of permutations.
Making the problem tractable for many targets and incorporating motions is left for future work.
An additional baseline experiment. We performed an experiment by training the set network
proposed in (1) with the same base network structure (ResNet-101) on the synthetic data reported
above. In contrast to our networks’ losses (Fig. 8 (a)), the training and validation losses for the
set network (Fig. 8 (b)) cannot decreases beyond a very high value and the generated boxes are
simply an average of the positions and sizes (Fig. 9), proving the ineffectiveness of the approach to
learn a reasonable model for this task. As mentioned before, the reason for this failure is that the
permutations are not considered in the model. Therefore, when the network is trained with orderless
outputs such as bounding boxes, the model is confused. Thus, its objective function does not converge
when forcing it to learn from such data.
12
Under review as a conference paper at ICLR 2019
epoch	epoch
(a)	(b)
Figure 8: Training and validation losses of (a) our Deep
Perm-Set Network and (b) the set network proposed
in (1), for object detection task.
Figure 9: The predicted bounding boxes
from the set network proposed in (1),
when trained for the object detection
task. In all images, all the bounding
boxes are concentrated in the same lo-
cation with the exactly same size, which
are simply an average of all the positions
and sizes of the objects in the scene.
2 CAPTCHA test for de-summing a digit
For solving the CAPTCHA test using Faster-RCNN, we investigated if changing the
detection threshold can significantly improve the accuracy of the test. As shown
in Fig. 10, this threshold has a slight effect in the accuracy of test, increasing it
from 26.8% for a default detection threshold 0.5 to 31.05% for the best threshold.
We also explored if an additional network, trained to rec-
ognize the digits, can be used in combination with Faster-
RCNN in order to improve the accuracy of the test. To
this end, we used another ResNet-101 network and trained
in MNIST dataset to recognise the digits. Note that we
assumed that the annotations for our dataset are only the
bounding boxes and no information about the query digit
and the set of digits are provided. Therefore, this new
classifier network could not be trained on our dataset.
In order to solve the test with an additional digit classifier,
both the query digit and the detected numbers from Faster-
RCNN are fed to the classifier network to recognise their
values. Then, a subset of the detected digits (including an
empty set) is chosen to solve the test. It is obvious that
the test accuracy is affected by the performance of both
detection and classifier networks. For this experiment, the
test accuracy is increased considerably from 31.05% to
Figure 10: A plot, representing the accu-
racy of solving the CAPTCHA test us-
ing Faster-RCNN against the detection
threshold.
59.28%. However, it is still significantly beyond our reported results for this test (95.2%). Figure 11
shows more results from our approach to solve this test. The output of Faster-RCNN for the examples
are also shown in Figure 12.
Figure 11: Further examples showing a perfect prediction of the solution using our Deep Perm-Set
Network. Each image contains a query digit (bottom left corner) and a set of digits. The ground truth
and our predicted solutions are shown by white and red boxes respectively. Note that zero represents
number 10 for our experiment.
13
Under review as a conference paper at ICLR 2019
Figure 12: Further examples showing the solution of Faster-RCNN for the test. Each image contains
a query digit (bottom left corner) and a set of digits. The ground truth and the predicted solutions for
Faster-RCNN are shown by white and red boxes respectively. Faster-RCNN simply learns to detect
almost all the digits while ignoring the logical relationship between the query digit and the set of
digits.
References
[1] S. Hamid Rezatofighi, Anton Milan, Qinfeng Shi, Anthony Dick, and Ian Reid. Joint learning
of set cardinality and state distribution. In AAAI, 2018.
14