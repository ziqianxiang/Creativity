Under review as a conference paper at ICLR 2019
Deep Recurrent Gaussian Process with Varia-
tional Sparse Spectrum Approximation
Anonymous authors
Paper under double-blind review
Ab stract
Modeling sequential data has become more and more important in practice. Some
applications are autonomous driving, virtual sensors and weather forecasting. To
model such systems, so called recurrent models are frequently used. In this pa-
per we introduce several new Deep Recurrent Gaussian Process (DRGP) models
based on the Sparse Spectrum Gaussian Process (SSGP) and the improved ver-
sion, called Variational Sparse Spectrum Gaussian Process (VSSGP). We follow
the recurrent structure given by an existing DRGP based on a specific variational
sparse Nystrom approximation, the recurrent Gaussian Process (RGP). Similar to
previous work, we also variationally integrate out the input-space and hence can
propagate uncertainty through the Gaussian Process (GP) layers. Our approach
can deal with a larger class of covariance functions than the RGP, because its
spectral nature allows variational integration in all stationary cases. Furthermore,
we combine the (Variational) Sparse Spectrum ((V)SS) approximations with a
well known inducing-input regularization framework. For the DRGP extension of
these combined approximations and the simple (V)SS approximations an optimal
variational distribution exists. We improve over current state of the art methods in
prediction accuracy for experimental data-sets used for their evaluation and intro-
duce a new data-set for engine control, named Emission.
1	Introduction
Modeling sequential data for simulation tasks in the context of machine learning is hard for sev-
eral reasons. Their internal structure poses the problem of modeling short term behavior and long
term behavior together for different types of data variables, where the data variables themselves
might differ in the information gain in the chosen time frequency. Recurrent models (Hochreiter &
Schmidhuber, 1997; Nelles, 2013; Pascanu et al., 2013) have proven to perform well on these tasks.
They consist of output-data and input-data structured sequentially for shifted discrete time steps.
The general form of a recurrent model is given by
hi = ζ(hi-1, . . . , hi-H, xi-1, . . . , xi-H) + ih,
yi = ψ(hi , . . . , hi-H) + iy ,
(1)
(2)
where xi is an external input, yi is an output observation, hi is a latent hidden representation or state
at time i = H + 1, . . . , N , where N ∈ N is the number of data samples, H ∈ N is the chosen time
horizon, ζ, ψ are non-linear functions modeling transition and observation and ih , iy are transition
and observation noise, which are adjusted for the specific problem (details on dimensions and ranges
will be specified in upcoming sections).
In control and dynamical system identification previous work on Bayesian recurrent approaches for
modeling sequential data usually makes use of (non-)linear auto-regressive with exogenous inputs
models ((N)ARX) and state-space models (SSM), for both see Nelles (2013). The general recurrent
model given in Equation (1) and (2) represents both cases. This can be recognized by its general
recurrent and hierarchical structure. This work deals with deep learning in a recurrent fashion for
modeling sequential data in a Bayesian non-parametric approach by using GPs. To make a connec-
tion to the general recurrent model, the deep structure arises by defining ζ in Equation (1) in a deep
manner (Pascanu et al., 2013, Section 3).
To achieve scalability, GPs normally make use of sparse approximations for the covariance function.
1
Under review as a conference paper at ICLR 2019
This paper proposes DRGP models based on (V)SS approximations, denoted by DRGP-(V)SS. For
reproducibility of the experimental results, we provide the code online1. Therefore, we follow the
same deep recurrent structure as introduced in Mattos et al. (2016). To summarize, the contributions
of this paper are the following:
•	Extension of the sparse GP based on the SS approximation introduced by Lazaro-Gredilla
et al. (2010) and the improved VSS approximation by Gal & Turner (2015) to DRGPs;
•	Improvement of regularization properties of the variational bounds through the combina-
tion of the (V)SS approximations with the inducing-point (IP) regularization of Titsias &
Lawrence (2010);
•	Propagation of uncertainty through the hidden layers of our DGPs by variationally integrat-
ing out the input-space;
•	The existence of an optimal variational distribution in the sense of a functional local opti-
mum of the variational bounds of our DRGPs models is established.
The DRGP of Mattos et al. (2016) is limited to a small class of deterministic covariance functions,
because the covariance functions variational expectation has to be analytically tractable. Using the
(V)SS approximations instead, we can derive a valid approximation for every stationary covariance
function, because the basis functions expectation is always tractable. We show that this approach
improves over state of the art approaches in prediction accuracy on several cases of the experimental
data-sets used in Mattos et al. (2016); Svensson et al. (2016); Al-Shedivat et al. (2017); Salim-
beni & Deisenroth (2017); Dorr et al. (2018) in a simulation setting. For scalability, Distributed
Variational Inference (DVI) (Gal et al., 2014) is recommended and can lower the complexity from
O(NM2Qmax(L + 1)) down to O(M3) for N ≤ M, M the sparsity parameter, (L+ 1) the amount
of GPs and Qmax is the maximum over all input dimensions used in our defined deep structure for ζ
and ψ. Therefore, the number of cores must scale suitably with the number of training-data.
2	Related Work to Gaussian processes with SSM and DGPs
An SSM with GPs (GP-SSM) for transition and observation functions is used by Wang et al.
(2005), where the uncertainty in the latent states is not accounted for, which can lead to overcon-
fidence. Turner et al. (2010) solved this problem, but they have complicated approximate training
and inference stages and the model is hard to scale. Frigola et al. (2014) used a GP for transition,
while the observation is parametric. Svensson et al. (2016) used an approximation of the spectral
representation by Bochner’s theorem in a particular form and with a reduced rank structure for the
transition function. They realize inference in a fully Bayesian approach over the amplitudes and the
noise parameters. The construction of Eleftheriadis et al. (2017) involves a variational posterior that
follows the same Markov properties as the true state with rich representational capacity and which
has a simple, linear, time-varying structure. Dorr et al. (2018) introduced a GP-SSM with scalable
training based on doubly stochastic variational inference for robust training. Our models extend
the GP-SSM framework by defining the transition as a DRGP based on our newly derived (V)SS
approximations in the Sections 3.3, 3.4, where the latent (non-observed) output-data is learned as a
hidden state. We refer to the report Foll et al. (2017)2 for a detailed but preliminary formulation of
our models and experiments.
Following Damianou & Lawrence (2013), a Deep Gaussian Process (DGP) is a model assuming
yi = f(L+1)(f(L)(f(L-1)(. . . (f(1)(xi) + ih(1)) . . .) + ih(L-1)) + ih(L)) + iy,
where the index i = 1, . . . , N is not necessarily the time and where we define hi(1) d=ef f(1) (xi) +
ih(1), hi(l+1) d=ef f(l)(hi(l)) + ih(l), for l = 2...,L - 1, where L ∈ N is the number of hidden
layers. The noise ih(l) , iy is assumed Gaussian and the functions f(l) are modeled with GPs for
l = 1, . . . , L + 1. To obtain computational tractability, in most cases variational approximation and
inference is used. Damianou & Lawrence (2013) introduced these kind of DGPs based on the sparse
variational approximation following Titsias (2009); Titsias & Lawrence (2010). Based on this,
1DRGP-(V)SS code available from http://github.com/RomanFoell/DRGP-VSS.
2Available on the website https://arxiv.org/.
2
Under review as a conference paper at ICLR 2019
Dai et al. (2016) introduced a DGP with a variationally auto-encoded inference mechanism and
which scales on larger data-sets. Cutajar et al. (2016) introduced a DGP for the so called Random
Fourier Features (RFF) approach (Rahimi & Recht, 2008), where the variational weights for each
GPs are optimized along with the hyperparameters. This approach does not variationally integrate
out the latent inputs to carry through the uncertainty and no existence of an optimal variational
distribution for the weights is proven to reduce the amount of parameters to optimize in training.
Furthermore, Salimbeni & Deisenroth (2017) introduced an approximation framework for DGPs,
which is similar to the single GP of Hensman & Lawrence (2014), but does not force independence
between the GP layers and which scales to billions of data.
Two state of the art approaches for DRGPs have been introduced by Mattos et al. (2016), the RGP,
which We call DRGP-NystrOm, based on the variational sparse Nystrom/inducing-point approx-
imation introduced by Titsias (2009); Titsias & Lawrence (2010), as well as Al-Shedivat et al.
(2017), which we call GP-LSTM, based on deep kernels via a Long-short term memory (LSTM)
network (Hochreiter & Schmidhuber, 1997), a special type of Recurrent Neural Network (RNN).
DRGP-NystrOm uses a recurrent construction, where the auto-regressive structure is not realized
directly with the observed output-data, but with the GPs latent output-data and uses a Variational
Inference (VI) framework, named Recurrent Variational Bayes (REVARB). The structure acts like
a standard RNN, where every parametric layer is a GP. So additionally uncertainty information can
be carried through the hidden layers.
GP-LSTM is a combination of GPs and LSTMs. LSTMs have proven to perform well on modeling
sequential data. LSTMs try to overcome vanishing gradients by placing a memory cell into each
hidden unit. GP-LSTM uses special update rules for the hidden representations and the hyperpa-
rameters through a semi-stochastic optimization scheme. It combines a GP with the advantages of
LSTMs by defining structured recurrent deep covariance functions, also called deep kernels, which
reduces the time and memory complexities of the linear algebraic operations (Wilson et al., 2016).
3	Gaussian Processes and Variational Sparse Spectrum GP
Loosely speaking, a GP can be seen as a Gaussian distribution over functions. We will first in-
troduce GPs and GP regression and then recall the SSGP by (Lazaro-Gredilla et al., 2010) and its
improved version VSSGP by (Gal & Turner, 2015). Based on these, we derive new variational ap-
proximations. We use the notation a, fx, y, (italic) for random variables, a, f(x), y (upright) for
realizations/samples and data.
3.1	Gaussian Processes
def
A stochastic process f is a GP if and only if any finite collection of random variables fX =
[fx1 , . . . , fxN]T forms a Gaussian random vector (Rasmussen, 2006). A GP is completely defined
by its mean function m : RQ → R, x 7→ m(x), Q ∈ N the input-dimension, and covariance
function k : RQ × RQ → R, (x, x0) 7→ k(x, x0) (Kallenberg, 2006, Lemma 11.1), where
m(x) d=ef E [fx] ,	k(x, x0) d=ef cov(fx,fx0) = E [(fx - m(x))(fx0 - m(x0))] ,
and the GP will be written as f 〜 GP(m, k). Be aware of that a valid covariance function must
produce a positive definite matrix KNN d=ef (k(xi, xj))iN,j=1 ∈ RN×N, when filling in combinations
of data-input points xi, i = 1, . . . , N.
Let y d=ef [y1, . . . ,yN]T ∈ RN, X d=ef [x1, . . . , xN]T ∈ RN×Q and we assume yi = f(xi) + iy,
where Ey ~ N(0, σnoise), for i = 1,..., N, and our aim is to model any set of function values
f d=ef [f(x1), . . . , f(xN)]T ∈ RN at X as samples from a random vector fX. Moreover, we assume
the prior fχ∣X 〜 N (0, KNN), meaning that any set of function values f given X arejointly Gaus-
sian distributed with mean 0 ∈ RN and a covariance matrix KNN .
The predictive distribution Pfx*∣χ*,χ,y for a test point x* ∈ RQ, where KN* C=f (k(xi, x*))N=ι ∈
RN, and analogously K**, K*N, can be derived through the joint probability model and condition-
ing as
fx* |x* , x, y ~ N (K*N (KNN + σ2oiseIN 厂1Y, K** - K*N (KNN + σ2oiseIN 厂IKN *).
3
Under review as a conference paper at ICLR 2019
In preview of our experiments in Section 5 and the following sections, we choose a specific covari-
ance function, the spectral mixture (SM) covariance function (Wilson & Adams, 2013)
k(X,XO) = σpower(YiIeXp(-2l-2(Xq-Xq)2)ccos(2πXiIp-I(Xq-XqD ,⑶
with an amplitude σp2ower and length scales lq , pq ∈ R, q = 1, . . . , Q. As pq → ∞, this corresponds
to the squared exponential (SE) covariance function in the limit (Gal & Turner, 2015).
3.2	Variational Sparse Spectrum GP
We introduce the SSGP following Gal & Turner (2015). For a stationary covariance function k on
RQ × RQ there exists a function ρ : RQ → R, τ 7→ ρ(τ), such that k(X, X0) = ρ(X - X0) for
X, X0 ∈ RQ . Bochner’s theorem states that any stationary covariance function k can be represented
as the Fourier transform of a positive finite measure μ (Stein, 2012). Then P(T), using T = X - x0,
can be expressed via Monte Carlo Approximation (MCA) following Gal & Turner (2015), Section
2, as
P(T) = Z
RQ
e2πizTτ dμ(z)
(4)
σ2	M
≈ Me Xm=I 2cθs(2πZTm(x - Um) +bm)cθs(2πZTm(χ0 - Um) + bm) d=f k(x, x0).
We refer to zm as the spectral points, bm as the spectral phases and um as the pseudo-input/inducing
points for m = 1, . . . ,M. Choosing the probability density like in Gal & Turner (2015), Proposition
2,	we approximate the SM covariance function with a scaling matrix L d=ef diag([2πlq]qQ=1) ∈
RQ×Q, a scaling vector p	d=ef	[p1-1, . . . , p-Q1]T	∈	RQ	and Z	d=ef	[z1,	. . . ,	zM]T	∈ RQ×M	via
φ(x, Z) d=f J2σpowerMT [cos(2π(L-1zι + P)T(x - uι) + bi),...,	(5)
cos(2π(L-1zM + p)T (x - UM) + bM)T ∈ RM.
Here We sample b 〜Unif [0, 2π],	Z 〜N(0,	Iq)	and We set	KKNN)	d=f	ΦΦt	with Φ	d=f
[φ(x1,Z),...,φ(xN,Z)]T ∈RN×M.
In Gal & Turner (2015) the SSGP Was improved to VSSGP by variationally integrating out the
spectral points and instead of optimizing the spectral points, additionally optimizing the variational
parameters. We folloW the scheme of Gal & Turner (2015), Section 4, for the 1-dimensional output
case y ∈ RN×1. By replacing the covariance function with the sparse covariance function *(SM) and
setting the priors to
PZ d=f YM ,Pzm, where Zm ~N(0,Iq),	Pa, where a ~ N(0,Im),	(6)
m=1
for m = 1,..., M, where we have y|a, Z, U, X ~N (Φa, σn2oiseIN) with U d=ef [U1, . . . , UM]T ∈
RQ×M (we do not define priors on p, L-1, U, b d=ef [b1, . . . , bM]T ∈ RM), we can expand the
marginal likelihood (ML) to
P(y|X) =
P(y|a, Z, U, X)P(a)P(Z)dadZ,
(7)
highlighting U just in the integral, to be notationally conform to Gal & Turner (2015), Section 3.
Now, to improve the SSGP to VSSGP, variational distributions are introduced in terms of
qZ d=ef YM qzm , where Zm 〜N(am, βm), qa, where a 〜N(m, s),
m=1
with βm ∈ RQ×Q diagonal, for m = 1, . . . , M, and s ∈ RM×M diagonal. From here on we use
variational mean-field approximation to derive the approximate models with different lower bounds
to the log ML introduced by Gal & Turner (2015):
log(P(y|X)) ≥ EqaqZ [log(P(y|a, Z, U, X))] - KL(qa||Pa) - KL(qZ ||PZ)).	(8)
As usual, KL defines the Kullback-Leibler (KL) divergence. By proving the existence of an optimal
distribution qaopt for a Gal & Turner (2015), Proposition 3, in the sense ofa functional local optimum
of the right hand side of (8), where a ~ N(A-1Ψty, σ2oiseA-i), with A = Ψ2 + σ2oiseIm,
Ψ1 = EqZ [Φ] ∈ RN×M, Ψ2 = EqZ [ΦT Φ ∈ RM×M, we can derive the optimal bound case.
4
Under review as a conference paper at ICLR 2019
3.3	(V)SSGP with regularization properties via inducing points (IP)
As a first contribution of this paper we combine two approximation schemes to two new methods
(V)SSGP-IP. We want to point out that the (V)SSGP does not have the same regularization proper-
ties as the GP of Titsias & Lawrence (2010), when optimizing the parameters U, because the prior
in (6) of the weights a is defined generically via Bishop (2006), Equations (2.113) - (2.115). These
parameters U, following Gal & Turner (2015), are similar to the sparse pseudo-input approxima-
tion Titsias (2009), but in the lower bound in (8) they are simply used without being linked to the
weights a.
We now define them as
Pa∣u, where a|U 〜N(0,Kmm),	(9)
Py∣α,z,u,x, where y|a, Z, U, X 〜N(ΦKmMa, KNN - KNMKM-1MKMN + σn2oise IN), (10)
where KNN, KNM , KMM are defined through the given covariance function in Equation (3).
We can show that for these definitions the integral in Equation (7) can be marginalized straight-
forward for the weights a. We then obtain that our data-samples y are coming from a Gaussian
distribution with mean 0 and the true covariance matrix KNN, plus the discrepancy of the two well-
known sparse covariance matrices for the Sparse Spectrum (not exactly, as we have ΦKM-1M ΦT)
and the Nystrom case, plus the noise assumption. This expression can not be calculated efficiently,
but shows that we obtain a GP approximation, which can be seen as a trade-off between these two
sparse approximations.
Following Titsias & Lawrence (2010), Section 3.1, the optimal variational distribution for a col-
lapses by reversing Jensen’s inequality and is similar to the one obtained in Titsias & Lawrence
(2010). The resulting bounds (SSGP-IP without KL(qZ ||pZ) and Ψ1 = Φ, Ψ2 = ΦTΦ) can be
calculated in the same way as Titsias & Lawrence (2010) until Equation (14) in closed form:
(N - M)	N	yTy
log(p(y∣X)) ≥ -(	2	) log(σn0ise)-亍 log(2π) - 了
2	2	2σnoise
log(∣Kmm| IATl)
+	2
(11)
+ yτΨιA 1ΨTy _ k(Knn) + tr(KMMKMNKNM)
2σ2oise	2σ2oise	2σnoise
- KL(qZ ||pZ).
Consequently, the resulting bound in (11) has an extra regularization property compared to the right
hand side of (8), which is reflected in the different form of A = Ψ2 + σn2oise KM M, which involves
KMM, the chosen covariance matrix filled in with the pseudo-input points U, and three extra terms
log(∣ Kmm |)	tr(KNN)	tr(KMM KMN KNM)
2	,	2σ2 .	,	2σ2 .	^
noise	noise
3.4	Variational approximation of the input-space for (V)SSGP(-IP)
As a second contribution of this paper we marginalize also the input-space. This is not straight-
forward, as it is not clear whether for the (V)SS covariance function in Equation (4) and (5)
these expressions even exist. To prevent misunderstanding, we will write from now on H =
[h1, . . . , hN]T ∈ RN×Q instead of X, to highlight that H is now a set of latent variables (later
on the hidden states of the DGP). Therefore, we introduce priors and variational distributions
PH d=f YN=ι Phi, where h 〜N(0,Iq),	qH d=f 口、q%, where h 〜Ng λi),
λi ∈ RQ×Q diagonal, for i = 1, . . . , N.
As a consequence, for VSSGP-IP we overall derive statistics Ψ0 = tr (EqH [KNN]) = N σp2ower,
Ψ1 = EqZqH [Φ] ∈ RN×M, Ψ2 = EqZqH ΦTΦ ∈ RM×M and Ψreg = EqH [KMNKNM] as
defined in the Appendix 6.3. These statistics are essentially the given matrices Φ, ΦTΦ, KMNKNM
from the beginning, but every input hi and every spectral point Zm is now replaced by a mean "i, αm
and a variance λi, βm resulting in matrices of the same size. The property of positive definiteness
is preserved. The SSGP-IP model derives by being not variational over the spectral points.
This extra step allows to propagate uncertainty between the hidden layers of a DGP, as we gain an
5
Under review as a conference paper at ICLR 2019
extra variance parameter for the inputs. For the IP case we get the lower bound:
1 /	、(N - M)I (2、Nl 0、 yTy , log(|KMM| IATl)
Iog(P(yIH)) ≥-----2— log9noiSe)-5 log(2n) - 2~r~ + --------------2-j——U	(12)
2	2	2σnoise	2
yT ΨlA-1 ΨT y Ψo , "(kmM ψreg)	Z ll 、Z ll 、
+ -2σ^	2σ^ + -2σ^	KLgZIIpZ)- KLgH ||pH )∙
noise	noise	noise
For the extension of the SSGP and VSSGP in the optimal bound case in (8) (we only focus on
this case in the following), We again have A = Ψ2 + σ20iselM and eliminate log(lKMM|), 2ψ-,
2σnoise
tr(KMM ψreg) in the lower bound (12).
2σnoise
4 DRGP with Variational Sparse S pectrum Approximation
In this section we want to combine our newly derived (V)SS-(IP) approximations in the Sec-
tions 3.3, 3.4, overall resulting in four GP cases: SSGP, VSSGP, SSGP-IP, VSSGP-IP, with the
framework introduced in Mattos et al. (2016), to derive our DRGP models: DRGP-SS, DRGP-VSS,
DRGP-SS-IP, DRGP-VSS-IP.
4.1 DRGP-(V)SS(-IP) Model Definition
Choosing the same recurrent structure as in Mattos et al. (2016), where now i represents the time,
yHx+1: = [yHx+1, . . . ,yN]T ∈ RN, we have
Z ：	h(l)=f (l)(h(l)) + eh©,	Withprior	瑶,)|直(I)	〜N(0,鹿}),	l = 1,...,L
ψ :	yi = f(l)(h(l)) + ey,	with prior	fH(0	|HT((I	〜N(0,KN)N),	l = L + 1,
with Z, ψ in Equation ⑴ and (2), eh(l) 〜N(0, (σ*se)2), ey 〜N(0, 9霖1))2) and N = N - Hχ,
for i = Hx + 1,..., N. The matrix KNN represents a covariance matrix coming from our chosen
k in Equation (4) and (5). A set of input-data H(I) = [hH)+1,..., hN)]T is specified as
[h(-)1, Xi-J = hhhi-i, . . . , hi-Hhi , [xi-1, . . . , xi-Hχ]i , l = 1	(13)
h (l) =f	hhi-1, h(l-1)iT =f hhh(-ι,..., h(-Hhi 小厂,...,h(-H)+ι iiT , l = 2,...,L
h(L)=f[h 产,..., h(LHh+ιiT ,	l = L + 1,
where h(1) ∈ RHh+HχQ, h(l) ∈ R2Hh for l = 2,..., L, hiL+1) ∈ RHh, for i = Hx + 1,..., N.
def
For simplification we set H = Hx = Hh in our experiments.
Now we use the new approximations in the Sections 3.3, 3.4, to derive first, for the setting (V)SSGP,
the new joint probability density
pyHx+1: [a(l),Z(l) ,h(l),U(l)]lL=+11 |X
YL+1
(=1
phH) + ι∙∣a(l),Z(l),H(l),U(l)pa(l)pZ(l)ph(l) ,
with ph(l+1)= 1,	hH+1i:	=f	yHx+i：,	h(L+1)	= {}	and	h(I)	=	[h1+Hx-Hh,...,	hHh]T ∈
R2Hh -Hx. Here the priors are
pad), where a(() ~N(0,Im),	pz(i)=f YM , pj), where Zmm) 〜N(0, IQ),
m=1 zm
ph(i), where h(()〜N(0, I2Hh-Hχ),
the product of them is defined as PREVARB, and the variational distributions are
qa(i), where a(() -N(m((), s(()),	qz(i)def YM qz©, where zmm - N(αmm), βm)),
m=1 zm
qh(i)d=f YN=ι+Hh-Hx q%(i), where hi()〜N3i(),入(()),
6
Under review as a conference paper at ICLR 2019
the product of them is defined as QREVARB, and where β(ml) ∈ RQ×Q is diagonal, for i =
1 + Hx - Hh , . . . , N , m = 1 . . . , M , l = 1, . . . , L + 1.
For the setting (V)SSGP-IP we choose no variational distribution for a(l), but, similar to the as-
sumptions in (9), (10) for l = 1, . . . , L + 1, the prior assumptions
Pa(i)∣u(i), where a(l) U(l) 〜N(0,kMm),
PhH)t + L∣a(l),Z(l),H(l),U(l), Where hHX + i:Ia(I), Z⑷，H⑷，U(I) ~
N(Φ(l)(KM(l)M)-1a(l),KN(l)N-KN(l)M(KM(l)M)-1KM(l)N+(σ(nlo)ise)2IN).
This defines our models for the cases DRGP-VSS, DRGP-VSS-IP. In the case, where we are not
variational over the spectral-points, we derive the simplified versions DRGP-SS, DRGP-SS-IP.
4.2	DRGP-(V)SS(-IP) Variational Evidence Lower Bound (ELBO)
Using standard variational approximation techniques (Blei et al., 2017), the Recurrent Variational
Bayes lower bound for the (V)SS approximations, denoted as REVARB-(V)SS, is given by
log(p(yHx+1:|X)) ≥
EQREVARB XL+1 log(P(hHX+i：|a(l), Z(I)W), U(I)))] - KL(QREVARB∣∣PRevarb) d=f LRE)VARB, (14)
and for the (V)SS-IP approximations, denoted as REVARB-(V)SS-IP, is given by
log(p(yHx+1: |X)) ≥
Epa(i)∣u(i) XL+1 exp(hlog(N(hHX+r∣φ(l)(κMM)-1 a(l),成匕^))iqrEVARB)]
XL+1	Ψ0)
- ^=1 2(σnl0ise)2
tr((KM(l)M)-1Ψ(rle)g)
2(σnl0ise)2
- KL(QREVARB||PREVARB) d=ef L(RVE)VSAS(R-IBP),
(15)
—
where〈•，•〉means, taking the expectation under the integral.
Additionally, for the simple (V)SS approximations in 14, the optimal bound L(RVE)VSAS-RoBpt can be obtained
immediately, analogously to Gal & Turner (2015), Proposition 3, and by the fact that the bound
decomposes into a sum of independent terms for a(l). Maximizing the lower bounds is equivalent to
minimizing the KL-divergence of QREVARB and the true posterior. Therefore, this is a way to optimize
the approximated model parameter distribution with respect to the intractable, true model parameter
posterior. Calculating L(RVE)VSAS-RoBpt/IP requires O(NM2Qmax(L + 1)), where Qmax = maxl=1...,L+1 Q(l),
Q(I) d=f dim(hil)) and h(l) from Equation (13). DVI can reduce the complexity to O(M3) if the
number of cores scales suitably with the number of training-data, see Appendix 6.3.6 for a detailed
description. A detailed derivation of the REVARB-(V)SS(-IP) lower bounds can be found in the
Appendix 6.3.4.
4.3	Model Predictions
After model optimization based on the lower bounds in the Equation (14) and (15), model predic-
tions for new hl) in the REVARB-(V)SS(-IP) framework can be obtained based on the approx-
imate, variational posterior distribution QREVARB. They are performed iteratively with approximate
uncertainty propagation between each GP layer. We derive qh(l) from previous time-steps and it is
per definition Gaussian with mean and variance derived from previous predictions for l = 1, . . . , L.
These kind of models propagate the uncertainty of the hidden GP layers’ outputs, not of the ob-
served output-data and are relevant for good model predictions. The detailed expressions for the
mean and variance of the predictive distribution involved during the predictions can be found in the
Appendix 6.3.5.
7
Under review as a conference paper at ICLR 2019
0	200	400 512
Figure 1: Simulation results visualized for the data-sets Drive (first row) and Actuator (second row)
for the method DRGP-VSS. First column represents the initial hidden states, blue: first layer, and
red: second layer. The second column represents the learned hidden states. The third column shows
the simulation results, blue: real data, black: simulation, grey: ±2 times Standard Deviation (SD)
and the fourth column the predicted hidden states.
5 Experiments
In this section we want to compare our methods DRGP-SS, DRGP-VSS (optimal bound case) and
DRGP-SS-IP, DRGP-VSS-IP, against other well known sparse GPs and the full GP with NARX
structure, the DRGP-Nystrom ofMattos et al. (2016), the GP-LSTM of AI-ShediVat et al. (2017), the
LSTM of Hochreiter & Schmidhuber (1997), a simple RNN, the DGP-DS of Salimbeni & Deisen-
roth (2017) and the DGP-RFF of Cutajar et al. (2016), both with NARX structure for the first layer,
the GP-SSM of Svensson et al. (2016) and the PR-SSM Dorr et al. (2018). The full GP is named
GP-full, the FITC approximation of Snelson & Ghahramani (2006) is named GP-FITC, the DTC
approximation of Williams & Seeger (2000) is named GP-DTC, the SSGP of Lazaro-Gredilla et al.
(2010) is named GP-SS, the VSSGP of Gal & Turner (2015) is named GP-VSS. The setting in this
system identification task is simulation. This means that, together with past exogenous inputs, no
past measured output observations (but perhaps predicted output observations) are used to predict
next output observations. To enable a fair comparison, all methods are given access to a predefined
amount of data. Details about the methods, their configuration, as well as the benchmark data-sets
can be found in the Appendix 6.1 and 6.2.
5.1	Implementation
Our methods DRGP-(V)SS(-IP) were implemented in Python, using the library Theano, and in Mat-
lab R2016b. For the optimization/training we used Python, Theano. Theano allows us to take full
advantage of the automatic differentiation to calculate the gradients. For simulation and visualiza-
tion we used Matlab R2016b.
We further implemented in Matlab R2016b the methods DRGP-Nystrom, GP-SS, GP-DTC, GP-
FITC, GP-full and used these implementations for the experiments. For GP-VSS, GP-LSTM,
LSTM, RNN, DGP-RFF and DGP-DS we used the published code3456. For GP-SSM the published
code is only applicable for small range of state dimension and a small time horizon, so we just show
the results from their paper. For PR-SSM we also show the results from their paper.
3GP-VSS code available from https://github.com/yaringal/VSSGP.
4GP-LSTM, LSTM, RNN code available from https://github.com/alshedivat/keras-gp.
5DGP-DS code available from https://github.com/ICL-SML/Doubly-Stochastic-DGP.
6DGP-RFF code available from https://github.com/mauriziofilippone/deep_gp
random_features.
8
Under review as a conference paper at ICLR 2019
Table 1: Summary of RMSE values for the free simulation results on test data. Best values per data-
set are bold. All values are calculated on the original data, unless the data-set Power Load, where
the RMSE is shown for the normalized data. Here we have full recurrence for our methods, DRGP-
Nystrom and GP-LSTM, LSTM, RNN and with auto-regressive part (first layer) for all other GPs.
For the column non-rec we turned off the auto-regressive part in the first layer for our methods,
DRGP-Nystrom and GP-LSTM, LSTM, RNN and also turned off the auto-regressive part (first
layer) for all other GPs.
methods-data	Emission	non-rec	Power Load	Damper	Actuator	non-rec	Ballbeam	Dryer	Drive	non-rec
DRGP-VSS	0104	0.062	0,45	-5.825	0.357	0.388	0084	0.109	0.229	0.268
DRGP-VSS-IP	0.119	0.064	0.544	6.112	0.441	0.546	0.071	0.107	0.302	0.293
DRGP-SS	0.108	0.062	0.497	5.277	0.329	0.563	0.081	0.108	0.226	0.253
DRGP-SS-IP	0.118	0.065	0.631	5.129	0.534	0.547	0.076	0.107	0.297	0.261
DRGP-NyStrom	0.109	0.059	0.493	-6.344	0.368	0.415	0.082	0.109	0.249	0.289
GP-LSTM	0.096	0.091	0.529	9.083	0.430	0.730	0.062	0.108	0.320	0.530
LSTM	0.098	0.061	0.530	9.370	0.440	0.640	0.062	0.090	0.400	0.570
RNN	0.098	0.066	0.548	9.012	0.680	0.690	0.063	0.121	0.560	0.590
DGP-DS	0.106	0.062	0.543	6.267	0.590	0.576	0.066	0.085	0.422	0.571
DGP-RFF	0.092	0.069	0.550	5.415	0.520	0.750	0.074	0.093	0.446	0.732
PR-SSM	N/A	N/A	N/A	N/A	0.502	N/A	0.073	0.140	0.492	N/A
GP-SSM	N/A	N/A	N/A	8.170	N/A	N/A	N/A	N/A	N/A	N/A
GP-VSS	0.130	0.058	0.514	6.554	0.449	0.767	0.120	0.112	0.401	0.549
GP-SS	0.128	0.060	0.539	6.730	0.439	0.777	0.077	0.106	0.358	0.556
GP-DTC	0.137	0.061	0.566	7.474	0.458	0.864	0.122	0.105	0.408	0.540
GP-FITC	0.126	0.057	0.536	6.754	0.433	0.860	0.084	0.108	0.403	0.539
GP-full	0.122	0.066	0.696	9.890	0.449	1.037	0.128	0.106	0.444	0.542
5.2	Benchmark data-sets Model Learning and Comparison
In Figure 1 we show a comparison of the latent model states before and after training, the simulation
results, as well as the simulated latent states for two data-sets, Drive and Actuator, for the model
DRGP-VSS. We initialize the states with the output training-data for all layers with minor noise (first
column) and after training we obtain a trained state (second column). Unlike Mattos et al. (2016)
Figure 2, (l), we get good variance predictions for all data-sets. We used our own implementation
for Mattos et al. (2016), which gave the same good results as for our methods. Therefore, we think
it is an implementation issue. The test RMSE results for all methods are summarized in Table 1.
The results show, that on most data-sets DRGP-(V)SS(-IP) improve slightly in comparison to other
methods. In order to evaluate the reproducing quality of our results, we provide a robustness test
for our methods and DRGP-Nystrom on the data-sets Drive and Damper in Figure 2, 3. We run the
optimization for different time horizons. For every method we visualized a boxplot with whiskers
from minimum to maximum with 10 independent runs. For our models we obtain good results
compared with DRGP-NyStrom on these data-sets, in particular for the setting of time horizons of
Table 1 with H = 10. In Figure 4 the RMSE results for different layers L on the data-sets Drive,
Actuator and Damper are shown. We can observe that different layers L are favored.
0.6
0.5
4 3 2
Ooo
山SiAl 」
T—n?!-
早
τ⅛
□
T-----5
工 - I
d's'd°≈ɑ
ssɑ
dss>,dɑ
ss>ɑ
IU2ANɑ
dsdɑ
ssɑ
dss>,dɑ
ss>ɑ
IU2ANɑ
dsdɑ
ssɑ
dss>,dɑ
ss>ɑ
E2ANɑ
15
dɪss,doɑ:ɑ
sdα
dss>,dα
ss>α
IU2ANα
dsdα
sdα
dss>,dα
ss>α
IU2ANα
dsdα
sdα
dss>,dα
ss>α
IU2ANα
O 5
1
山Sna
Figure 2:	Data-set Drive, Boxplot, 10 runs.
Figure 3:	Data-set Damper, Boxplot, 10 runs.
9
Under review as a conference paper at ICLR 2019
一DRGP-NyStrcIm
一DRGP-SS
-DRGP-VSS
-DRGP-SS-IP
DRGP-VSS-IP
Figure 4: RMSE values for different number of layers L for the data-sets Drive, Actuator, Damper.
5.3 Conclusion
In this paper We introduced four new DRGPs based on the SS approximation introduced by Lazaro-
Gredilla et al. (2010) and the improved VSS approximation by Gal & Turner (2015). We com-
bined the (V)SS approximations with the variational inducing-point approximation from Titsias &
Lawrence (2010), also integrated variationally over the input-space and established the existence
of an optimal variational distribution for a(l) in the sense of a functional local optimum of the
variational bounds REVARB-(V)SS-(IP). We could show that our methods slightly improve on the
data-sets used in this paper compared to the RGP from Mattos et al. (2016) and other state-of-the-art
methods, where moreover our sparse approximations are also practical for dimensionality reduction
as shown in Titsias & Lawrence (2010) and can be further expanded to a deep version in this appli-
cation (Damianou & Lawrence, 2013). Furthermore, Hoang et al. (2017) introduced a generalized
version of the (V)SS approximation, which should be adaptable for our case.
Acknowledgments
We would like to acknowledge support for this project from the ETAS GmbH.
References
Maruan Al-Shedivat, Andrew Gordon Wilson, Yunus Saatchi, Zhiting Hu, and Eric P Xing. Learning
scalable deep kernels with recurrent structure. The Journal of Machine Learning Research, 18(1):
2850-2886, 2017.
Christopher M Bishop. Pattern recognition. Machine Learning,128:1-58, 2006.
David M Blei, Alp Kucukelbir, and Jon D McAuliffe. Variational inference: A review for statisti-
cians. Journal of the American Statistical Association, 112(518):859-877, 2017.
Kurt Cutajar, Edwin V Bonilla, Pietro Michiardi, and Maurizio Filippone. Practical Learning of
Deep Gaussian Processes via Random Fourier Features. stat, 1050:14, 2016.
Zhenwen Dai, Andreas Damianou, Javier Gonzalez, and Neil D Lawrence. Variational Auto-
encoded Deep Gaussian processes. International Conference on Learning Representations, 2016.
Andreas C Damianou and Neil D Lawrence. Deep Gaussian Processes. In Artificial Intelligence and
Statistics, pp. 207-215, 2013.
Andreas Dorr, Christian Daniel, Schiegg Martin, Duy Nguyen-Tuong, Stefan Schaal, Marc Tous-
saint, and Sebastian Trimpe. Probabilistic Recurrent State-Space Models. arXiv preprint arXiv:
1801.10395, 2018.
Stefanos Eleftheriadis, Tom Nicholson, Marc Deisenroth, and James Hensman. Identification of
Gaussian process state space models. In Advances in Neural Information Processing Systems, pp.
5309-5319, 2017.
Roman Foll, Bernard Haasdonk, Markus Hanselmann, and Holger Ulmer. Deep Recurrent Gaussian
Process with Variational Sparse Spectrum Approximation. arXiv preprint arXiv:1711.00799v2,
2017.
10
Under review as a conference paper at ICLR 2019
Roger Frigola, Yutian Chen, and Carl Edward Rasmussen. Variational Gaussian process state-space
models. In Advances in Neural Information Processing Systems, pp. 3680-3688, 2014.
Yarin Gal and Richard Turner. Improving the Gaussian Process Sparse Spectrum Approximation by
Representing Uncertainty in Frequency Inputs. In International Conference on Machine Learn-
ing, pp. 655-664, 2015.
Yarin Gal, Mark van der Wilk, and Carl Edward Rasmussen. Distributed variational inference in
sparse Gaussian process regression and latent variable models. In Advances in Neural Information
Processing Systems, pp. 3257-3265, 2014.
James Hensman and Neil D Lawrence. Nested Variational Compression in Deep Gaussian Processes.
stat, 1050:3, 2014.
Quang Minh Hoang, Trong Nghia Hoang, and Kian Hsiang Low. A Generalized Stochastic Vari-
ational Bayesian Hyperparameter Learning Framework for Sparse Spectrum Gaussian Process
Regression. In AAAI, pp. 2007-2014, 2017.
Sepp Hochreiter and Jurgen Schmidhuber. Long short-term memory. Neural computation, 9(8):
1735-1780, 1997.
Olav Kallenberg. Foundations of modern probability. Springer Science & Business Media, 2006.
Miguel Lazaro-Gredilla, Joaquin Quinonero-Candela, Carl Edward Rasmussen, and Anlbal R.
Figueiras-Vidal. Sparse spectrum Gaussian process regression. Journal of Machine Learning
Research, 11(Jun):1865-1881, 2010.
CeSar Lincoln C Mattos, Zhenwen Dai, Andreas Damianou, Jeremy Forth, Guilherme A Barreto,
and Neil D Lawrence. Recurrent Gaussian processes. International Conference on Learning
Representations, 2016.
Oliver Nelles. Nonlinear system identification: from classical approaches to neural networks and
fuzzy models. Springer Science & Business Media, 2013.
Razvan Pascanu, Caglar Gulcehre, Kyunghyun Cho, and Yoshua Bengio. How to construct deep
recurrent neural networks. arXiv preprint arXiv:1312.6026, 2013.
Ali Rahimi and Benjamin Recht. Random Features for Large-Scale Kernel Machines. In J. C. Platt,
D. Koller, Y. Singer, and S. T. Roweis (eds.), Advances in Neural Information Processing Systems
20, pp. 1177-1184. Curran Associates, Inc., 2008.
Carl Edward Rasmussen. Gaussian processes for machine learning. MIT Press, 2006.
Hugh Salimbeni and Marc Deisenroth. Doubly stochastic variational inference for deep gaussian
processes. In Advances in Neural Information Processing Systems, pp. 4588-4599, 2017.
Jonas Sjoberg, Qinghua Zhang, Lennart Ljung, Albert Benveniste, Bernard Delyon, Pierre-Yves
Glorennec, Hakan Hjalmarsson, and Anatoli Juditsky. Nonlinear black-box modeling in system
identification: a unified overview. Automatica, 31(12):1691-1724, 1995.
Edward Snelson and Zoubin Ghahramani. Sparse Gaussian processes using pseudo-inputs. Ad-
vances in neural information processing systems, 18:1257, 2006.
Michael L Stein. Interpolation of spatial data: some theory for kriging. Springer Science & Business
Media, 2012.
Andreas Svensson, Arno Solin, Simo Sarkka, and Thomas Schon. Computationally efficient
Bayesian learning of Gaussian process state space models. In Artificial Intelligence and Statistics,
pp. 213-221, 2016.
Michalis K Titsias. Variational Learning of Inducing Variables in Sparse Gaussian Processes. In
Artificial Intelligence and Statistics, volume 5, pp. 567-574, 2009.
Michalis K Titsias and Neil D Lawrence. Bayesian Gaussian Process Latent Variable Model. In
Artificial Intelligence and Statistics, volume 9, pp. 844-851, 2010.
11
Under review as a conference paper at ICLR 2019
Ryan D Turner, Marc Peter Deisenroth, and Carl Edward Rasmussen. State-Space Inference and
Learning with Gaussian Processes. In Artificial Intelligence and Statistics, pp. 868-875, 2010.
Jack M Wang, David J Fleet, and Aaron Hertzmann. Gaussian process dynamical models. In Neural
Information Processing Systems, volume 18, pp. 3, 2005.
Jiandong Wang, Akira Sano, Tongwen Chen, and Biao Huang. Identification of Hammerstein sys-
tems without explicit parameterisation of non-linearity. International Journal of Control, 82(5):
937-952, 2009.
Torbjorn Wigren. Input-output data sets for development and benchmarking in nonlinear identifica-
tion. Technical Reports from the department of Information Technology, 20:2010-020, 2010.
Christopher KI Williams and Matthias Seeger. Using the Nystrom method to speed up kernel ma-
chines. In Proceedings of the 13th International Conference on Neural Information Processing
Systems, pp. 661-667. MIT press, 2000.
Andrew Wilson and Ryan Adams. Gaussian process kernels for pattern discovery and extrapolation.
In International Conference on Machine Learning, pp. 1067-1075, 2013.
Andrew Gordon Wilson, Zhiting Hu, Ruslan Salakhutdinov, and Eric P Xing. Deep kernel learning.
In Artificial Intelligence and Statistics, pp. 370-378, 2016.
12
Under review as a conference paper at ICLR 2019
6 Appendix
This additional material provides details about the derivations and configurations of the proposed
DRGP-(V)SS(-IP) in the Sections 3-4. and elaborates on the methods and the employed data-sets in
the experiments in Section 5.
6.1	Data-set description
Table 2: Summary of the data-sets for the system identification tasks
parameters \ data-sets	N	Ntrain	Ntest	input dimension	output dimension
Drive	-50O^^	250-	-250-	f	F
Dryer	1000	500	500	1	1
Ballbeam	1000	500	500	1	1
Actuator	1024	512	512	2	1
Damper	3499	2000	1499	1	1
Power Load	9518	7139	2379	11	1
Emission	12500	10000	2500		6		1
In this section we introduce the data-sets we used in our experiments. We chose a large number
of data-sets in training size going from 250 to 12500 data-points in order to show the performance
for a wide range. We will begin with the smallest, the Drive data-set, which was first introduced
by Wigren (2010). It is based on a system which has two electric motors that drive a pulley using a
flexible belt. The input is the sum of voltages applied to the motors and the output is the speed of
the belt. The data-set Dryer7 8 describes a system where air is fanned through a tube and heated at
an inlet. The input is the voltage over the heating device (a mesh of resistor wires). The output is
the air temperature measured by a thermocouple. The third data-set Ballbeam78 describes a system
where the input is the angle of a beam and the output the position of a ball. Actuator is the name of
the fourth data-set, which was described by Sjoberg et al.(1995) and which stems from an hydraulic
actuator that controls a robot arm, where the input is the size of the actuator’s valve opening and the
output is its oil pressure. The Damper data-set, introduced by Wang et al. (2009), poses the problem
of modeling the input-output behavior of a magneto-rheological fluid damper and is also used as a
case study in the System Identification Toolbox of Mathworks Matlab. The data-set Power Load9,
used in Al-Shedivat et al. (2017), consists of data where the power load should be predicted from the
historical temperature data. This data-set was used for 1-step ahead prediction, where past measured
output observations are used to predict current or next output observations, but we will use it here
for free simulation. We down-sampled by starting with the first sample and choosing every 4th data-
point, because the original data-set with a size of 38064 samples and a chosen time-horizon of 48
is too large for our implementation, which is not parallelized so far. The newly provided data-set
Emission10 contains an emission-level of nitrogen oxide from a driving car as output and as inputs
the indicated torque, boost pressure, EGR (exhaust gas recirculation) rate, injection, rail pressure
and speed. The numerical characteristics of all data-sets are summarized in Table 2. The separation
of the data-sets Drive, Dryer, Ballbeam, Actuator, Damper, Power Load in training- and test-data
was given by the papers we use for comparison. The separation of the Emission data-set was chosen
by ourself.
7Received from http://homes.esat.kuleuven.be/~tokka/daisydata.html.
8Description can be found under http://forums.ni.com/t5/NI-myRIO/
myBall- Beam- Classic- Control- Experiment/ta- p/3498079.
9Originally received from Global Energy Forecasting Kaggle competitions organized in 2012.
10Available from http://github.com/RomanFoell/DRGP-VSS.
13
Under review as a conference paper at ICLR 2019
6.2	Nonlinear System Identification
Table 3: Summary of the methods for the system identification tasks
method	references
DRGP-VSS	introduced in this paper
DRGP-VSS-IP	introduced in this paper
DRGP-SS	introduced in this paper
DRGP-SS-IP	introduced in this paper
DRGP-Nystrom	(Mattos et al.,2016)
GP-LSTM	(Al-Shedivatetal.,2017)
LSTM	(Hochreiter & Schmidhuber, 1997)
RNN	see e.g. (Al-Shedivat et al., 2017)
DGP-DS	(Salimbeni & Deisenroth, 2017)
DGP-RFF	Cutajar et al. (2016)
PR-SSM	(Dorr et al.,2018)
GP-SSM	(Svensson et al., 2016)
GP-VSS	(Gal & Turner, 2015)
GP-SS	(Lazaro-Gredilla et al., 2010)
GP-DTC	(Williams & Seeger, 2000)
GP-FITC	(Snelson & Ghahramani, 2006)
GP-full	(Rasmussen, 2006)
The methods for the system identification tasks and their references are summarized in Table 2.
For the data-sets Drive and Actuator we chose for our methods DRGP-(V)SS(-IP) the setting L = 2
hidden layers, M = 100 spectral-points and time-horizon Hh = Hx = 10, which was also used
in Mattos et al. (2016), Al-Shedivat et al. (2017) and Dorr et al. (2018) for free simulation (Us-
ing M pseudo-input points instead of spectral-points). For these two data-sets we filled the results
from Mattos et al. (2016); Al-Shedivat et al. (2017) into Table 1. Further, for our methods DRGP-
(V)SS(-IP) and DRGP-Nystrom We chose on the data-sets Ballbeam and Dryer L = 1, M = 100
and Hh = Hx = 10. For the data-set Damper we chose L = 2, M = 125 and Hh = Hx = 10. For
the data-set PoWer Load We chose L = 1, M = 125 and Hh = Hx = 12. For the data-set Emission
We chose L = 1, M = 125 and Hh = Hx = 10.
The other sparse GP, the full GP, DGP-RFF and DGP-DS Were trained With NARX structure
Hx = Hy (for the first layer) With the same time horizon as for our DRGPs and With the same
amount of pseudo-input points or spectral points.
For LSTM, RNN We chose the same setting for the amount of hidden layers and time horizon as for
our DRGPs. We used Adam optimizer With a learning rate of 0.01. As activation function We chose
tanh and NARX structure Hx = Hy for the first layer. We tested With 8, 16, 32, 64, 128 hidden
units (every hidden layer of a RNN is specified by a hidden unit parameter) for all training data-sets.
For GP-LSTM We chose the same setting for the amount of hidden layers, pseudo-input points and
time horizon as for our DRGPs. We used Adam optimizer With a learning rate of 0.01. As activation
function We chose tanh and NARX structure Hx = Hy for the first layer. We tested With 8, 16,
32, 64, 128 hidden units (every hidden layer of a RNN is specified by a hidden unit parameter) for
all training data-sets. For the data-sets With training size smaller or equal to 2000 We chose the
version GP-LSTM in Al-Shedivat et al. (2017) and for the ones larger than 2000 the scalable version
MSGP-LSTM. We did not pre-train the Weights.
For DGP-RFF We tested for L = 1, . . . , 3 number of GPs. We used Adam optimizer With a learning
rate of 0.01. The batch size Was chosen to be the training data-size and the dimensions of the GP
layers to be 5. We set the flags q_Omega_fixed= 1000 and learn_Omegafixed=varfixed, so fixing
the spectral-point parameters, and iterated until 2000 just for this GP.
For DGP-DS We tested for L = 1, . . . , 3 number of GPs. We used natural gradients for the last GP
With gamma 0.1 and Adam optimizer for the others With a learning rate of 0.01. The batch size Was
chosen to be the training data-size and the dimensions of the GP layers to be 5.
All GPs which use the Nystrom approximation were initialized for the pseudo-inputs points with a
random subset of size M from the input-data and trained With SE covariance function. For the ones
which use the (V)SS approximations, which includes our methods, we trained with a spectral-point
initialization sampled from N(0, IQ(l)), an initialization for the pseudo-input points with a random
subset of size M from the input-data (or setting them all to zero; not in the IP case). For our methods
DRGP-(V)SS(-IP) and GP-VSS we fixed the length scales p(ql) = ∞, for all q, l. So all GPs with
14
Under review as a conference paper at ICLR 2019
(V)SS approximations were also initialized as SE covariance function, see Equation 5.
For all methods we used automatic relevance determination, so each input dimension has its own
length scale. For our methods DRGP-(V)SS(-IP) and DRGP-Nystrom the noise parameters and
the hyperparameters were initialized by σ(nlo)ise = 0.1, σ(plo)wer = 1 and the length scales by either
iqι) = JmaX(HqI)) 一 min(HB) or 心。=max(H§)) — min(H§)), for all q,l, where HB is the
data-Vector containing the q-th input-dimension values of every input-data point h(l), for all i. Fur-
thermore, we initialized the latent hidden GP states with the output-observation data y.
The other standard GPs were also initialized with σnoise = 0.1, σpower = 1 and the same initialization
for length scales with respect to the NARX structure input data as before.
For LSTM, RNN we used the initialization for the weights provided by Keras, a Deep Learning
library for Theano and TensorFlow.
For GP-LSTM we used the initialization for the weights provided by Keras and σnoise = 0.1,
σpower = 1 and for the length scale initialization we chose lq = 1 for all input-dimensions.
For DGP-RFF we used the initialization coming from the implementation with σ(plo)wer = 1 and for
the length scale initialization with l(ql) = 0.5 log(Q(l)) for all l, q. To our knowledge DGP-RFF has
no parameter σ(nlo)ise for all l.
For DGP-DS we used the initialization σ(nlo)ise = 0.1 and σ(plo)wer = 1 and for the length scale initial-
ization we chose l(ql) = 1 for all l, q.
For all our implementations, see Section 5.1, we used the positive transformation X0 = log(1 +
eXp(X))2 for the calculation of the gradients in order for the parameters to be constrained positive
and with L-BFGS optimizer, either from Matlab R2016b with fmincon, or Python 2.7.12 with scipy
optimize.
All methods were trained on the normalized data X → X-μ (for every dimension independently),
several times (same amount per data-set: the initializations are still not deterministic, e.g. for
pseudo-inputs points and spectral points) with about 50 to 100 iterations and the best results in
RMSE value on the test-data are shown in Table 1.
For our methods DRGP-(V)SS(-IP) and DRGP-NyStrOm We fixed σno∙se, σpower for all l (optional
the spectral points/pseudo-input points for DRGP-(V)SS; for the IP case we never excluded the
pseudo-input points because we would fall back to the DRGP-(V)SS case; for DRGP-Nystrom we
always included the pseudo-input points) during the first iterations to independently train the latent
states. For all other GPs we also tested with fixed and not fixed σnoise = 0.1, except GP-LSTM and
DGP-DS. For DRGP-VSS(-IP) we fixed β(ml) for all m, l to small value around 0.001, as well as the
spectral phases bm for all m, l sampling from Unif [0, 2π] (this seems to work better in practice).
The limitations for β(ml) also holds for GP-VSS as well.
We want to remark at this point that setting um = 0 for all m = 1, . . . , M worked sometimes better
than choosing a subset from the input-data (not in the IP case). This seems to be different to Gal &
Turner (2015), who pointed out: ’These are necessary to the approximation. Without these points
(or equivalently, setting these to 0), the features would decay quickly for data points far from the
origin (the fixed point 0).’
For GP-SSM we show the result of the data-set Damper from their paper in Table 1.
For PR-SSM we show the results from their paper in Table 1.
We show additional results for the data-sets Drive, Actuator and Emission with missing auto-
regressive part for the first layer for our methods DRGP-(V)SS(-IP) and DRGP-Nystrom in Table 1,
named non-rec. For the sparse GP, the full GP, GP-LSTM, DGP-RFF and DGP-DS and the data-sets
Drive, Actuator and Emission we show the results with missing auto-regressive part in Table 1, just
modeling the data with exogenous inputs. Here we want to examine the effect of the auto-regressive
part of the first layer for the DRGP models on the RMSE. GP-SSM and PR-SSM are not listed for
this setting of recurrence.
15
Under review as a conference paper at ICLR 2019
6.3	Variational approximation and inference for DRGP-(V)SS(-IP)
In the Sections 6.3.1-6.3.3 we derive the statistics Ψ0, Ψ1, Ψ2 and Ψreg for the four model cases
DRGP-(V)SS(-IP). In Section 6.3.4 we derive the resulting variational lower bounds. In Sec-
tion 6.3.5 we show the mean and variance expressions of the predictive distributions of our DRGP
models.
In the following we use the abbreviations and formulas
•	B.1, (Gal & Turner, 2015, see Section 4.1),
•	B.2, (Rasmussen, 2006, see A.7.),
•	2 (cos(a — b + X — y) + cos(a + b + X + y)) = cos(x + a) cos(y + b).
•	JI, for Jensen’s inequality.
6.3.1 DRGP-VSS(-IP), THE STATISTICS Ψ1, Ψ2
For the versions DRGP-VSS(-IP) the statistics are
(Ψ1)nm = Eqzm qhn [Φnm]
B=.1 Eqh
2σp2ower(M)-1 e-2hTmβmhlnm cos(αm(hn — Um) + bm)]
B.251 口 - 1 αT C α
=∑mZnme	2 αmCnmαm
cos(α m (Cnm — Um) + bm),
for m, = 1, . . . , M, n = 1, . . . , N with
hnm
2πL-1(hn — u
m),
cnm
vnm
2π(L-1αm + p),
Cnm(βm (2n产 L 2um + λn Xnb
(βm(2π)2L-2 + λn-1)-1,
1
Znm
^^/	e-
|Vnm |
2 Vnm Vnmvnm
Σ1m
y2σower∏Q=xβmo^M-',
and
Ψ2 = PnN=1 (Ψ2)n, where
(Ψ2)nmm0 = Eqzmqzm0qhn Φnm Φnm0
B.1 Eqhn [2σpower(M )-1e- 1 (hTmβmhnm + h Tm，βm0 hnmO)
cos(am(hn — Um) + bm) cos(a*, (hn — Um,) + bm，)]
B2 emmoZmm，卜-1 α mm0 Dmm0 + mm0 cos(α m,rn,' dmm，— τmm0 + bmm，)
+e

l+T	Dn	+	+τ Iln	+	+	、\
2 mm0 mm0 mm0 COS(amm0dmm，— ^mm，+ bmm，)	.
16
Under review as a conference paper at ICLR 2019
for m, m0 = 1, . . . , M, m 6= m0, with
bmm0 二 + bmm0	bm - bm0 , bm + bm0 ,
TmmO 一	TT αmUm - αm0 Um0 ,
+ τmm0 αmm0 -	TT αmUm + αm0 Um0 , =fv — fv , αm - αm0 ,
+ αmm0	二 am + αm0,
bmm0 βmm0	Bmm0(2π)2L-2(βmUm+ βm0Um0), βm + βm0 ,
Bmm0	(2π)-2L2β-m1m0,
dmm0	Dmm0 (B-mm0 bmm0 + λn- μn),
Dn mm0 wn	0 mm0 Wn	0 mm0	(B-m1m0 +λn-1)-1, 二 bmm0 一 μn, Bmm0 + λn,
Umm0	Um - Um0 ,
Umm0	(2π)-2L2(β-m1 + β-m10),
Zn Zmm0	1	Q-1 (Wn O T Wn o-1Wn O +UT O U-1 0Uw. e ) 二 -	e 2、 mm0	mm0	mm0	mm0 mm0 mm / PWmmO IlUmmo |	,
Σmm0	2 Fwer Yd	p⅛	(M)-1,
and
(Ψ2)nmm = Eqzmqhn ΦTnmΦnm
B.1
= Eqhn
2σpower(M)T(2 + 2 e-2hTmβmhnm cos(2(α m (hn - Um) + bm))
B.2 σpower(M )-1(1 + Σ mZnme-2α mCnm α m Cθs(2(α m(Cnm - Um) + bm))),
for m, m0 = 1, . . . , M, m = m0 , with
ς m=M (占)2-Q
6.3.2 DRGP-SS(-IP), THE STATISTICS Ψ1, Ψ2
For the versions DRGP-SS(-IP) the statistics are
(ψ1 )nm = Eqhn [φnm]
=Eqhn hq2σpower(M)-1 COS(Zm (hn - um) + bm)]
B.2 J2σ2ower(M)Te-2zmλnzm CoS(Zm(μn - Um) + bm),
for m = 1, . . . , M, n = 1, . . . , N with
Zm = 2π(L-1Zm +p),
and
17
Under review as a conference paper at ICLR 2019
Ψ2 = PnN=1(Ψ2)n,where
(Ψ2)nmm0 = Eqhn ΦTnmΦnm0
B.1 Eqhn [2σ2ower(M )-1 cos(zm(hn - Um) + bm) COs(zTrko (hn - Um，)+ bm，)]
=σp2ower(M )-1 卜-2 zmm0 λnzmm0 Cos(Zmm，"n - Pmm，+bmm，)
+e-2+mm0 λn + mm0 Cos(Zmm，μn - +mm，+ bmm，))),
for m, m0 = 1, . . . , M with
TT
PmmO = ZmUm	Zm，um，,
+	T +T
Pmm0	ZmUm 十 zm0um0,
zmm0 = Zm - zm0,
Zmm， = Zm + Zm， ,
for the other variables, see the defined variables in the DRGP-VSS case.
6.3.3	DRGP-(V)SS-IP, THE STATISTICS Ψreg AND Ψ0
For Ψreg = EqH [KMNKNM] see Ψ2 in Section 6.3.1 but setting bm = 0, αm = 0 and βm = 1
for all m = 1, . . . , M.
Ψ0 naturally is given by Ψ0 = tr (EqH [KNN]) = N σp2ower because of the chosen SE covari-
ance function.
18
Under review as a conference paper at ICLR 2019
6.3.4	DRGP-(V)SS(-IP), LOWER BOUNDS
In this section we derive the different variational lower bounds for our models DRGP-(V)SS(-IP).
We first show the bound L(RVE)VSASRB without optimal variational distribution for a(l) . Then the bounds
L(RVE)VSAS-RoBpt with optimal variational distribution for a(l) follows, as well as the L(RVE)VSAS-RIPB case.
We use the simplified notation dAdZdH = da(1) . . . da(L+1)dZ(1) . . . dZ(L+1)dh(1) . . . dh(L).
log(p(yHx+1:|X))
log p yHx+1:, ha(l), Z(l), h(l), U (l)iL+1 |X dAdZdH
log (J Qqrevarb P(YHx+1：, a(L+1), Z(L+1), U(L+I)Ja(I), Z(I), h(l), U (HLlX b AdZdH
JI
≥	QREVARB log
pyHx+1：,a(L+1),Z(L+1),U(L+1),
QREVARB
dAdZdH
L+1
X
l=1
'N - XX	log(2∏λil)) +	Xh	log(2∏) + 卜° + a?)) '
2	2	+	2+	2
i=1+Hx -Hh	i=1+Hx -Hh
-	KL(qa(l) ||pa(l)) - KL(qZ(l) ||pZ(l))
l=1
/ q(a(I))q(Z(I))q(h(I))P(hH)+1： Ia(I), Z(I), H(I), U(I))da(I)dZ(I)dh(I)
L
-X
l=1
L+1
^ L+1
--2^ X log(2π(σnθise)2) -
l=1
T
yHx+1：yHx+1：
2 (b(L+1))2
noise
yT	Ψ(L+1)m(L+1)	tr Ψ(2L+1)(s(L+1) + m(L+1)(m(L+1)
Γ-2
σ(L+1))2
noise
2 …))2
noise
L
+X
l=1
+3
2
(l)
Hx+1：
σ⅛ ((Xλ)"χF+ι:
noise	x
)T Ψ(1 l)m(l))	tr Ψ(2l) (s(l) + m(l) (m(l))T)
σ(I) )2
noise
2 (σ(I) )2
noise
N
- ^2 +
N
X
i=1+Hx	-Hh
log(2πλi(l))
Xh	log(2n)
乙	-2-
i=1+Hx-Hh
2
+
—
/
—
—
2
—
—
/
L+1
-	KL(qa(l) ||Pa(l)) - KL(qZ(l) ||PZ(l))
l=1
def REVARB
= LVSS ,
where We derive LRSEvarb by being not variational over Z(I). Using the optimal distribution for a(I)〜
N((A(I))T(WIl))T μHX + i:,(用Se)2(A(I))T), with A(I) = ψ2l) + (/Se)2IM, resPective yHx + 1:
19
Under review as a conference paper at ICLR 2019
for L + 1 we obtain
≥- NiM Σ log ((σnO)ISe)2
l=1	、
「T	一
yHx + 1：yHx + 1：
2 (σ(L+1)Y2
noise
yHx+lΨl+1)(A(L+1) )T(Ψl+I))T yHx+1：
2 (σ(L+1)Y2
noise
[2 (点S)
N
X	λ(l)	+(μHX+r)“HX+i:
i=Hχ + 1	)
+ (μHX+i:
log(∣(A ⑷)-1∣)
2 G) Y
∖ noise I
N
X
i=1+Hχ-Hh
log(2πλ(I))
Hh
X
i=1+Hχ-Hh
log(2π)
-2-
2
+
L
+ X
l = 1
/
1
—
+
log(∣(A(L+1))T|)
2
—
旦+
2
N
-T +
2
—
—
/
—
2
L+1
log(2π) - E KL(qz(i)∣∣pz(i))
l = 1
def ∕* REVARB
一LVSS-OPt，
where we derive LRSiVARB by being not variational over Z(l).
20
Under review as a conference paper at ICLR 2019
The IP regularization case with A(l) = Ψ(2l) + (σ(nlo)ise)2KM(l)M and QREVARB, PREVARB just defined with
the priors and variational distributions for Z(l) and H(l), is given by:
log(p(yHx+1:|X))
= . . . see Titsias & Lawrence (2010) until Equation 14,
JI
≥	pa(l) |U (l) [
L+1
2	σ(nlo)iseY2
l=1
-1
exp(hlog(N(hHX + lJΦ(I)(KMM )-1a(I),(σnθise)2IN ))>Qrevarb )]
Xl=1 Ψ(0l) - tr((KM(l)M)-1Ψ(rle)g) - KL(QREVARB||PREVARB)
L+1
X log	σ(nlo)iseY2
l=1
T
yHx+1:yHx+1:
log(IKM(LM+1)I)
2 (b(L+1)『
noise
T
+ yTHx+1:
Ψ(1L+1)(A(L+1))-1 (Ψ(1L+1))TyHx+1:
log(|(A(L+1))-1|)
2 fσ(L+1)Y2
noise
Ψ(0L+1) +tr((KM(LM+1))-1Ψ(rLeg+1))
2 fσ(L+1)Y2
noise
L
-X
l=1
'X λ(l)+(μHX + ιJTμHX + ι) +
i=Hx+1
Iog(KMMI)
2 (σ(I) Y
noise
+1: +
log(|(A(l))-1|)
Ψ0l) + tr((KMM )-1Ψr⅛)	Nq
T +
log(2πλi(l))
2 σ(nlo)ise
Hh
X
i=1+Hx-Hh
log(2π)
N
X
i=1+Hx-Hh
2
L+1
log(2π) -	KL(qZ(l) IIpZ(l))
l=1
—
—
+
—
—
N - M
—
2
/
—
—
+
2
1
--------TT
[2 5
2
2
—
+
—
2
2
2
2
2
/
def REVARB
= LVSS-IP ,
where again we derive LSRSE-VIPARB by being not variational over Z(l).
21
Under review as a conference paper at ICLR 2019
6.3.5	Predictions
Predictions for each layer l and new hl) are performed in the simple DRGP-(V)SS case with
Eq,*© [f*(I)] =Ψll*)mQ
Vqf*(i) [f *(l)i = (m(l))T "l*) - Ml*))T Ψll*)) m(l) +tr 卜(1)田2?),
where for the optimal distribution case for a(l) we have with A(l) = Ψ(2l) + (σ(nlo)ise)2IM
m(l) o=t (A(I))T Ml))‘ μHX+i:,	S(I) o=t 932 (A(I))一，
for 1,...,L, and fully analog for l = L + 1 by replacing μH)+1: with yHx+i：.
In the DRGP-(V)SS-IP case we make predictions for each layer l and new h*l) through
Eqf*(l) hf*(l)i =Ψ(1l*)Λ(l),
Vqf*(l) hf*(l)i = (Λ(l))T Ψ(2l*) - (Ψ(1l*))TΨ(1l*)Λ(l)
+ Ψ0 - tr (KM(l)M)-1Ψ(rle)g* -(σ(nlo)ise)2 (A(l))-1Ψ(2l*) ,
where A(l) = Ψ(2l) + (σ(nlo)ise)2KM(l)M and
Λ(l)o=t (A(I))T (ψ1l))T μHX+i:,
for 1,...,L, and fully analog for l = L + 1 by replacing μH)+1: with yHx+i：.
Prediction for a new input in all cases has time complexity O((L + 1)M3), which comes from the
iterative prediction through all GP layers and the calculation of the statistics, see Appendix 6.3.6.
22
Under review as a conference paper at ICLR 2019
6.3.6	Distributed Variational Inference for DRGP-(V)SS(-IP)
We refer to (Gal et al., 2014), Equation (4.3), for a comparison.
Calculating the optimal REVARB-(V)SS and REVARB-(V)SS-IP requires O(N M 2Qmax(L + 1)),
where Qmax
I max ]Q(l), Q(l) def dim(hii')) and h((l)
is coming from the Equations in (13) for
a fixed chosen i and l = 1, . . . , L + 1. In this section we show how we can reduce the complexity of
inference in the REVARB-(V)SS(-IP) setting with distributed inference to O(M3) if the number of
cores scales suitably with the number of training-data. We show this for L(RVE)VSAS-RIPB, because this is the
most complex bound, and all other bounds reduce to special cases of this.
LRE)VARB in Appendix 6.3.4, separated for each hidden layer and the output layer ("hx+i： and λHx+i:
L+1
replaced by yHx+1:), can be written as L(RVE)VSAS-RIPB =	Bl, where we have the KL terms
l=1
MQ(I)
-2-
for l = 1, . . . , L + 1, the terms
N	^^N	lθg(2∏λ(l))	^^Hh	log(2π)
2	乙 i=ι+Hχ-Hh 2	乙 i=1+Hχ-Hh 2
Jog(KMMI)D
十 2
for l = 1, . . . , L and
Bl
—
PiN=Hx+1
λi ) + μHχ + LμHχ + 1:
2 (σ区)2
* μHx+rψ1l) (A(I))-1(ψIl))TμHχ+i:	log(∣(A(I))TI)	Ψ0l) + tr((KM)M尸田窑)
十十-------------------------
2 (σ(l) )	2	2 (σ⑴)
noise	noise
N
-~2log(2π),
for all l = 1, . . . , L 十 1 and which can be separated further into Bl = PiN=H +1 Bli , a sum of
N = N - Hx independent terms, extracting Iog(I(A2 ')一1I, Iog(IKMMI) and tr((KMMI) ;r?g), by
2(σnoise )
Bli
1-
σ(l)
noise
—
2 十 λi(l)
(l) (l)
十 μi μi
2
2
σ(l)
noise
log(2∏)
-2-
M
2
where (ψf))∙i means, taking the i-th column of ψf) for l = 1,...,L + 1, i = Hx +1 ...,N. We
further inspect
A(I) = Ψ2l) + (σnoise)2KM)M = XNH +1 (Ψ2)(I)十 doisjKMM,
i=Hx +1
and
ψ(l) = XN	(ψi )(l)
reg =	i=Hx +1	reg .
These terms and the sums of Ψ(2l) and Ψ(rle)g can be computed on different cores in parallel without
communication. Only the 3(L 十 1) inversions and determinants of A(l) and KM(l)M now are respon-
sible for the complexity, which can also be computed on 3(L 十 1) cores. Summing this bound over
i and l, We obtain the total complexity of O(M3) per single iteration with N(L + 1) cores.
23