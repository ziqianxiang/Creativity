Under review as a conference paper at ICLR 2019
Deli-Fisher GAN: Stable and Efficient Image
Generation With Structured Latent Genera-
tive Space
Anonymous authors
Paper under double-blind review
Ab stract
Generative Adversarial Networks (GANs) are powerful tools for realistic image
generation. However, a major drawback of GANs is that they are especially hard
to train, often requiring large amounts of data and long training time. In this paper
we propose the Deli-Fisher GAN, a GAN that generates photo-realistic images
by enforcing structure on the latent generative space using similar approaches by
DeliGAN as introduced in Gurumurthy et al. (2017). The structure of the latent
space we consider in this paper is modeled as a mixture of Gaussians, whose
parameters are learned in the training process. Furthermore, to improve stability
and efficiency, we use the Fisher Integral Probability Metric as the divergence
measure in our GAN model, instead of the Jensen-Shannon divergence. We show
by experiments that the Deli-Fisher GAN performs better than DC-GAN, WGAN,
and the Fisher GAN as measured by inception score.
1	Introduction
Generative Adversarial Networks (GAN) are powerful unsupervised learning models that have re-
cently achieved great success in learning high-dimensional distributions(Goodfellow et al. (2014)).
In the field of image and vision sciences in particular, GAN models are capable of generating “fake”
images that look authentic to human observers.
The basic framework of a GAN model consists of two parts: a generator G = Gθ (z) that gen-
erates images by translating random input noise z into a particular distribution of interest, and a
discriminator D = Dp(x) which calculates the probability that an image x is an authentic image as
opposed to a generated “fake” image from the generator. While the generator G and discriminator D
can be modeled as any smooth functions, these two components are usually modeled as two neural
networks in practical applications. During the training process, we optimize the generator and the
discriminator alternately against each other. Within each step, we first keep D fixed and optimize G
so as to improve its capability of generating images that look real to D. Then, we keep G fixed and
train D to improve the discriminator’s ability to distinguish real and G-generated images. The two
parts G and D play a two-player game against each other. At the end of the training, we would be
able to have a generator that is capable of generating photo-realistic images.
In mathematical form, a GAN model can be described as an optimization problem, as follows:
min max V (D, G)
GD
(1)
where V (D, G) is the objective function measuring the divergence between the two distributions:
the distribution of the real existing data D(x), and the that of the generated data D(G(z)), where x
follows the distribution of real images and z follows the distribution of input noise. Depending on the
choice of function V (D, G), different GAN models have been proposed over time (see Goodfellow
et al. (2014), Arjovsky et al. (2017), Mroueh & Sercu (2017)) to increase stability and achieve faster
convergence rates.
1
Under review as a conference paper at ICLR 2019
2	Previous work and problems
Ever since the inception of the first GAN models were introduced in Goodfellow et al. (2014),
much improvement has been achieved on the GAN models. As mentioned in the previous section,
the choice of the objective function V (D, G) is crucial to the entire GAN model. The original
GAN model in Goodfellow et al. (2014) optimizes the Jenson-Shannon divergence measure. This
model, however, suffers from slow and unstable training. Some later work sought to improve GAN
performance by utilizing the Earth-Mover Distance (Arjovsky et al. (2017)) and the more general
f-divergences (Mroueh & Sercu (2017)), as well as other possibilities such as the Least Square Ob-
jective (Mroueh & Sercu (2017)). Along this line of research, one of the recent notable developments
in GANs is the Fisher GAN model proposed by Mroueh & Sercu (2017), which employs the Fisher
Integrated Probability Metric (Fisher IPM) to formulate the objective function.
In addition to the developments in divergences used as objective functions in GAN, recent research
also focuses on the structure of the latent space for the generator. In particular, one of the 2017
CVPR papers Gurumurthy et al. (2017) introduced Deli-GAN, which uses input noise generated
from the mixture of Gaussian distributions. The paper also argued that this method makes it possible
to approximate a huge class of prior data distributions quickly by placing suitable emphasis on noise
components, and hence makes training more efficient.
3	The Fisher IPM Framework
The loss function V (D, G) as shown in (1) defines how we measure the difference between our
learned distribution and the distribution from real images we want to learn. The divergence mea-
sure used in V (D, G) directly controls what the model can achieve through the minimax optimiza-
tion problem. Therefore, as shown by recent work, it is important to choose a stable and effi-
cient divergence measure for the loss function. In the first GAN proposed in Goodfellow et al.
(2014),the Jensen-Shannon divergence based on KL divergence between two distribution is used,
but the model suffers from several problems such as unstable training and slow convergence. These
inherent caveats prompted The WGAN proposed in Arjovsky et al. (2017) is more stable and only
induces very weak topology (as weak as convergence in distribution), but is known to be costly in
computation(Arjovsky et al. (2017),Gulrajani et al. (2017),Mroueh & Sercu (2017)).
In this paper, we choose to adopt the Fisher IPM framework proposed by Mroueh & Sercu (2017),
which provides stability, efficient computation, and high representation power. Following the frame-
work developed in Muller (1997), we define the Integral Probability Metric (IPM). Let F be the
space of all measurable, symmetric, and bounded real functions. Let X ∈ Rd be compact. Let P
and Q be two probability measures on X. Then the Integral Probability Metric is defined as
dF(P,Q)=sup	E f(x)- E f(x)
f ∈f ∖x~P	x~Q	J
Let P(X) denote the space of all probability measures on X. Then dF defines a pseudo-metric over
P(X). By choosing an appropriate F, we can define a meaningful distance between probability
measures.
Now we define the Fisher IPM following the Fisher Discriminative Analysis framework as described
in Mroueh & Sercu (2017). Given two probability measures P, Q ∈ P(X), the Fisher IPM between
P and Q is defined as
E f(x) - E f(x)
x~P	x~Q
dF (P, Q)
SUP	=
f ∈F J2XEPf 2(X) + 1 XEQf 2(X)
In order to formulate a loss function that is easily computable, we transform the above formula into
a constrained format
dF (P, Q) =	SuP	E f(X) - E
f∈F,2 E f2(x) + 2 E f2(x) = 1 ∖x~P	x~Q
2 x~P	2 x~Q
so that the problem is better suited for optimization, as we will see in the following sections.
2
Under review as a conference paper at ICLR 2019
4 Deli-Fisher GAN
Most GAN models introduced in previous work(Goodfellow et al. (2014),Arjovsky et al.
(2017),Mroueh & Sercu (2017)) make use of random noise generated from a uniform distribution
or a Gaussian distribution in their latent space for the input to the generator. These choices of using
overly simplistic distributions, however, are not well justified. Since the data we train the GAN upon
is often diverse with many varying classes of images. choosing one uniform or Gaussian distribution
to generate the random noise input may fail to represent the features in the latent space.
We believe that a good choice of probability distribution for the latent noise will be able to translate
into better features or structures in the generated image. An idea of using mixed Gaussian distri-
bution in the latent space was proposed in Gurumurthy et al. (2017), in which the authors changed
distribution of the random noise input from a singular uniform/Gaussian distributions to a mixture
of Gaussians, and incorporated the GAN architecture from the DCGAN model described in Radford
et al. (2015). During the training process, the parameters of the mixed Gaussian distribution (means
and variances) are learned in each epoch. Once the training is complete, the Deli-GAN generates
images using the mixed Gaussian learned from training process.
Thus, we incorporate this idea in our paper, and generalize the distribution of the latent space to
general mixture distributions:
N
Dlatent = X wiDθ(ii)
i=1
where Dθ(i) are the distributions of the ith component, θi are the parameters of component, and wi are
the weights for the component. For instance, if D；? are all Gaussian distributions, then θi = (μi, σi)
represent the means and standard deviations of these Gaussians. Using the mixture input random
noise, we proceed to build the GAN model with the Fisher IPM we have described in the previous
section.
The following sections will discuss in detail of the loss function and algorithms implemented.
4.1	Theory and the Loss Function
By our discussion above, we reformulate the Deli-Fisher GAN model into the following optimization
problem:
gθminwi fSUFp V (fp, gθ) := XEPr fp(x)- z,1Pgi)fp 卜 X wi Zf)
SUbjecttO 2 XEJrf» + 1Z M (gθ (X Wi Zaj)= 1
(2)
where Pr is the distribution of the real images and P(gi) is the distribution of the ith component of
latent input noise, as a multimodal distribution.
Empirical formulation of this loss function can vary depending on the distribution P(gi). In a simple
case, if the P(gi)’s are independently and identically distributed, and αi only depend on their means
μi and variances σ%, i.e. αi = αi(μi, σi), then the empirical formulation of (2) can be written as
1N	1M
min sup V(fp, gθ) =— Efp(Xi) — - fΓfpμjθ(μj + σj€j))
gθ,αifp∈Fp	N i=1	Mj=1
+ λ(ι - 0(fp, g；)) - p(G(fp,gθ) - ι)2 + β(C - σ)2,
where
1N2	1M2
c(fp, gθ) = 2N £fp (Xi) - 2M EfP (gθ(μj + σjEj)).
2N i=1	2M j=1
3
Under review as a conference paper at ICLR 2019
Here, N, M are our sample sizes for the discriminator and the generator respectively, and C is a
constant controlling the size of σ . λ represents the Lagrange multiplier for optimization, while ρ
and β are penalty weights for the L2-regularity of ΩΩ and σ, respectively. Ei are random noises that
(i)
provides diversity to the latent space. Ei are sampled from the normalized Pg . The parameters for
our structured noise input are in turn updated during training process, as in the case with Gurumurthy
et al. (2017).
4.2	Deli-Fisher GAN Algorithm
Using the standard stochastic gradient descent(SGD) algorithm ADAM, over all sets of parameters,
we compute the updates of the respective variables by optimizing the loss functions described in the
previous section with the following procedure:
Input: ρ penalty weight, η, η0 learning rates, nc number of iterations for training the critic, N
batch size
Initialize p, θ, λ
Initialize μi,σi,η
while θ not converging do
for j = 1 to nc do
Sample a minibatch Xi, i = 1 …N, Xi 〜Pr
(i)
Sample a minibatch e%,i = 1...N, / 〜normalized Pg)
(gp,gλ) . (VpV, VλV)(p,θ,λ)	//Using SGDwith ADAM
P — P + ηgp
λ — λ - ρgλ
end
Sample Ei 〜normalized Pgi), i = 1,..., M
(dθ, dμ, dσ )《-N vθ,μ,σ PN=I fp(gθ (Mi + σiEi))
θ 一 θ 一 ηdθ
μ 一 μ 一 η0dθ
Q — Q 一 η0dθ
end
Algorithm 1: Deli-Fisher GAN
5 Experiments
5.1	Quality Evaluation: Inception S core
To evaluate the quality of the images generated by our GAN, we use the Inception Score as defined
in Salimans et al. (2016), an automated measure aiming to simulate human judgment of quality of
the images generated. This measure aims to minimize the entropy for the conditional label distribu-
tion P(y|x) to ensure consistency between the generated images and given data, and maximize the
entropy of the marginal P(y|x = G(z))dz to guarantee the diversity of the images generated by
the network. In view of these two considerations, the proposed metric can be written as
exp(Ex(DKL(P(y|x)kP(y))),
where DKL(Pkq) denotes the Kullback-Leibler divergence between two distributions P and q. An
alternative measure involving the exponent of inception score has been proposed in Gurumurthy
et al. (2017); for our experiments, we will stick to the original formulation as proposed in Salimans
et al. (2016).
The inception score we used in all experiments below is calculated by the python script
posted by OpenAI at https://github.com/openai/improved-gan/tree/master/
inception_score.
4
Under review as a conference paper at ICLR 2019
5.2	Datasets and experimental replications
As a baseline for subsequent comparison, we have replicated the experiments of previous GAN
architectures. We have successfully replicated the results for Deep Convolutional Generative Ad-
versarial Networks (DC-GAN) in Radford et al. (2015), Wasserstein GAN in Arjovsky et al. (2017),
and Fisher GAN in Mroueh & Sercu (2017), all using the data set CIFAR-10. Table 1 and Table 2
are two tables that show the results of our experimental replication and the means and variances of
their respective inception scores.
Figure 1: Sample generated images from DCGAN
Figure 2: Sample generated images from WGAN
Figure 3: Sample generated images from FisherGAN
For the several experiments involving Deli-Fisher GAN, we used the CIFAR-10 dataset to examine
our model. While all the images in the CIFAR-10 data are colored pictures with a size of 64 × 64,
5
Under review as a conference paper at ICLR 2019
Type of GAN
Inception Score
DCGAN(as in MroUeh & SercU (2017))^^(6.16, 0.07)
WGAN	(5.4586, 2.217e-2)
Fisher GAN	(6.8978, 0.09188)
Table 1:	Mean and Variance of Inception Scores in previoUs GANs
we Used cropped images of size 32 × 32 so that the dense layer of oUr neUral networks does not
become too large. For each training, We generated 50,000 fake images and Used these images to
calcUlate the inception score.
Each the training session consists of 200 epochs. In each session, we applied generated corre-
sponding oUtpUt. Then we apply Deli-Fisher GAN to the same data set and compare the resUlt with
Fisher-GAN. In the Deli-Fisher GAN, we set hyper-parameters as 0 and initialized parameters for
the input distribution (μi, σi and η). We executed same number of epochs in the training session.
During the training session, θ, μ, σ and η were learned by Stochastic Gradient Descent with ADAM
optimizer. After we have learned the parameters of the model, we generated another 50,000 images
to make comparison with those generated by Fisher-GAN.
At the same time, we have also tuned different parameters in each model generation to fake sample
production work-flow. These parameters include the number of epochs, the penalty coefficient,
etc. We have also made use of the inception score described above to compare the images we’ve
generated with the ones in the original data distribution.
All the experiments are done on GeForce GTX 1080Ti GPU, and we have observed that most of
the GAN trainings involved in our experiments take around 30 minutes. One notable exception,
however, lies in WGAN, since the weight-clipping procedures involved in WGAN requires a lot of
computation and accounts for the extra time needed in experiments. Moreover, while repeating the
experiments of different GANs, we noticed that the performances of DCGAN were highly unstable
and unsatisfactory, as DCGAN yielded varying unsatisfactory inception scores at the range of 2
to 3 in our runs and stopped parameter updating even when the images are still blurred. These
observations confirm the conclusions in Arjovsky et al. (2017) and Mroueh & Sercu (2017).
5.3 Results
Using suitable parameters located through fine-tuning, the Deli-Fisher GAN produces better images
than those produced by the current optimal Fisher GAN, as measured by the inception score. For
comparison, the respective inception scores in experiments over the CIFAR-10 dataset are listed in
Table 3.
No. of Experiment
Inception Score
Experiment 1
Experiment 2
Experiment 3
Experiment 4
Experiment 5
(7.3901662, 0.10778493)
(7.1032821, 0.055437498)
(7.4196534, 0.119866334)
(7.4921403, 0.0764598)
(7.2027034, 0.07927073)
Table 2:	Mean and variance of inceptions scores of Deli-Fisher GAN. Here the we used following
set of parameters: learning rate σ = 0.00005. Latent space family: mixture Gaussian. In the table,
each inception score has two values: the mean value and the standard deviation.
As demonstrated by the tables, experiments generated images of good qualities. One such sample is
shown in Figure 4. Compared with previous GANs, we can see notable improvements in the images
generated, by qualitative and quantitative observation. These outputs therefore suggest that a better
representation of the random noise input does indeed capture more features of the latent space and
those of the images the model is trained upon, and these features, in turn, augment the authenticity
of the images that the Deli-Fisher GAN model produces.
6
Under review as a conference paper at ICLR 2019
Figure 4: Sample generated images from Deli-Fisher GAN
6 Conclusion
In sum, the Deli-Fisher GAN presented in our paper is capable of generating better images than
the DC-GAN, the WGAN, and the Fisher-GAN are, with notable improvements on the quality of
images as measured by inception scores. Additionally, the model proposed in our paper is still open
to improvement such as adding regularization terms to the objective function as those employed in
the experiments of Mroueh & Sercu (2017).
As a further step, we are working on developing more sophisticated structures for the latent space
that is specific tailored to different tasks. We believe, by enforcing some properties on the latent
space, e.g. symmetries or geometric characteristics, we would be able to gain some control of the
features on the generated images.
References
Martin Arjovsky, SoUmith Chintala, and Leon Bottou. Wasserstein generative adversarial networks.
In Doina Precup and Yee Whye Teh (eds.), Proceedings of the 34th International Conference
on Machine Learning, volume 70 of Proceedings of Machine Learning Research, pp. 214-223,
International Convention Centre, Sydney, Australia, 06-11 Aug 2017. PMLR. URL http://
proceedings.mlr.press/v70/arjovsky17a.html.
I. J. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, and
Y. Bengio. Generative adversarial networks. NIPS, 2014.
Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Dumoulin, and Aaron C Courville. Im-
proved training of wasserstein gans. In I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus,
S. Vishwanathan, and R. Garnett (eds.), Advances in Neural Information Processing Systems 30,
pp. 5767-5777. Curran Associates, Inc., 2017. URL http://papers.nips.cc/paper/
7159-improved-training-of-wasserstein-gans.pdf.
Swaminathan Gurumurthy, Ravi Kiran Sarvadevabhatla, and R. Venkatesh Babu. Deligan : Gen-
erative adversarial networks for diverse and limited data. In The IEEE Conference on Computer
Vision and Pattern Recognition (CVPR), July 2017.
Youssef Mroueh and Tom Sercu. Fisher gan. In I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach,
R. Fergus, S. Vishwanathan, and R. Garnett (eds.), Advances in Neural Information Processing
Systems 30, pp. 2513-2523. Curran Associates, Inc., 2017. URL http://papers.nips.
cc/paper/6845-fisher-gan.pdf.
A. Muller. Integral probability metrics and their generating classes of functions. Advances in Applied
Probability, 1997.
7
Under review as a conference paper at ICLR 2019
Alec Radford, Luke Metz, and Soumith Chintala. Unsupervised representation learning with deep
convolutional generative adversarial networks. CoRR, abs/1511.06434, 2015.
Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, Xi Chen, and
Xi Chen. Improved techniques for training gans. In D. D. Lee, M. Sugiyama, U. V. Luxburg,
I. Guyon, and R. Garnett (eds.), Advances in Neural Information Processing Systems 29, pp.
2234-2242. Curran Associates, Inc., 2016. URL http://papers.nips.cc/paper/
6125-improved-techniques-for-training-gans.pdf.
8