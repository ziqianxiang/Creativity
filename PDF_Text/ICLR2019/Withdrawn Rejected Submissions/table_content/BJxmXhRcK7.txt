Table 1: Performance comparison of STL, MRN, DMTRL and our TRMTL on MNIST.
Table 2: The results of heterogenous input dimensionality on CIFAR-10. Left columns: each taskassociates with RGB or grayscale image. Right columns: tasks with images of different spatial sizes.
Table 3: The results of multi-dataset tasks on Omniglot (task A) and MNIST (task B).
Table 4: Performance comparison of STL, MRN, DMTRL and our TRMTL on CIFAR-10 withunbalanced training samples, e.g., ‘5% vs 5% vs 5%’ means 5% of training samples are availablefor the respective task A, task B and task C. TR-ranks R = 10 for TRMTL.
Table 5: Performance comparison of STL, MRN, DMTRL and our TRMTL on Omniglot withdifferent fractions of training samples.
Table 6: The results of heterogenous input dimensionality on CIFAR-10. Top: each task associateswith RGB or grayscale image. Bottom: each task has input images of different spatial sizes.
Table 7: Specification of network architecture and factorized TRL representation of the experimentsfor the validation of sharing pattern and model compactness on MNIST dataset.
Table 8: Specification of network architecture and factorized TRL representation of the experimentsfor the insufficient sample tasks on Omniglot dataset.
Table 9: Specification of network architecture and factorized TRL representation of the experimentson heterogenous inputs with distinct spatial sizes for CIFAR-10.
Table 10: Specification of network architecture and factorized TRL representation of the experi-ments on heterogenous inputs with distinct channels (RGB and grayscale image) for CIFAR-10.
Table 11: Specification of network architecture and factorized TRL representation of the experi-ments for multi-dataset task on Omiglot-MNIST.
