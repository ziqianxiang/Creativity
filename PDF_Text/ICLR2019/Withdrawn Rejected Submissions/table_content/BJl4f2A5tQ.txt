Table 1: Set of approaches explored to improve GATS performanceReplay Buffer	Optimizer	Sampling strategies	Optimism(i) Plain DQN (ii) Dyna-Q	(i) Learning rate (ii) Mini-batch size	(i)	Leaf nodes (ii)	Random samples from the tree (iii) Samples by following greedy Q (iv) Samples by following ε-greedy Q (v) Geometric distribution	(i)W-loss (ii)	exp(W-loss) (iii)	L1+L2+W-distance (iv) exp(L1+L2+|W-distance|)Replay Buffer: The agent’s decision under GATS sometimes differs from that of the learned Q model.
