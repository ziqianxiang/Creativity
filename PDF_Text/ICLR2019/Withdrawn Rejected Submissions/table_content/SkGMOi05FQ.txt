Table 1: BLEU-2, BLEU-3 and BLEU-4 metric scores for different models with (a) test set asreference, and (b) entire corpus as reference. ST: Skip-Thought, GAN: Generative AdversarialNetwork, W: Wasserstein GP: Gradient PenaltyModel	Test set BLEU-3	Complete corpus reference				BLEU-2	BLEU-3	BLEU-4STGAN	0.521	^^0.709	0.564	0.525STGAN(minibatch)	0.526	0.745	0.607	0.531STGAN-GP	0.558	0.791	0.621	0.547STWGAN	0.582	0.833	0.669	0.580STWGAN-GP	0.617	0.836	0.682	0.594Bottou; Srivastava et al.) with a parameter setting where it outputs a very narrow distribution ofpoints. To overcome this, it uses minibatch discrimination by looking at an entire batch of samplesand modeling the distance between a given sample and all the other samples present in that batch.
Table 2: Sample sentences generated from training on CMU-SE Dataset; mode collapse is overcomeby using minibatch discrimination. Formation of sentences further improved by changing f-measureto Wasserstein distance along with gradient penalty regularizer.
