Table 1:	cldc experiments between eight related European language pairs on rcv2 topic identi-fication. The CACO models are competitive with DAN models that use far more resources. Thecombined model (COM) achieves the highest average test accuracy. We boldface the best result foreach row, UnderIine CACO results that outperform at least one DAN model.
Table 2:	cldc experiments between Amharic and Tigrinya on lorelei disaster response dataset.
Table 3: Results of cldc experiments using two source languages. Models trained on two sourcelanguages are generally better than models trained on only one source language (Table 1). Weboldface the best result for each row, UnderIine CACO results that outperform at least one DAN model.
Table 4: Word translation accuracies (P@1) for different embeddings. The caco embeddings aregenerated by the embedder of a src model trained on the source language. Without any cross-lingualsignal, the caco embedder has similar word translation accuracy as mCCA and mCluster, which aresupervisedly trained on large dictionaries.
Table 5: cldc experiments between languages from different families on rcv2. When transferringfrom a North Germanic language to a Romance language, caco models score much lower than danmodels (top). Surprisingly, caco models are on par with dan when transferring from a Romancelanguage to a North Germanic language (bottom). We boldface the best result for each row, UnderIineCACO results that outperform one DAN model, and double UnderIine CACO results that outperformboth DAN models.
