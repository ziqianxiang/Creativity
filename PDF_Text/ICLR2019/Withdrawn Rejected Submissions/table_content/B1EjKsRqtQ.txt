Table 1: Evaluation results for MRC modelsIn our experiment, we replace the attention part of PPG from a Vanilla Attention Mechanism to ourHam-V and set the compatibility function f to be the scaled dot product function, while keeping otherparts and dataset unchanged as PPG except the evaluation part. The evaluation of poem generation inPPG is done by experts and we can not keep evaluation method unchanged since it is not convincingto find experts for evaluation. Our evaluation algorithm is based on BLEU-2 score which is calculatedas13BLEU =	BLEUiï¼Œwhere BLEUi denotes the BLEU-2 score computed for the next (i + 1)th lines given the previous igoldstandard lines. This averaged BLEU can tell us how much correlated the lines of a generatedquatrain are. We will show some quatrains generated by our Ham-based PPG in the appendix.
Table 2: BLEU-based evaluation resultsWhen attention depth d is not large enough, the larger d is, the better performance our model willachieve. PPG with 10-level Ham has almost 25% of improvement on the averaged BLEU scorecompared with ordinary PPG. On the other hand, through the last two rows of the table above andTheorem 2, we know that with the continuing increase of d, our performance will converge sooner orlater. So in order to balance between performance and training cost, we suggest attention depth d tobe between 5 and 10.
