Table 1: Accuracy Comparison for Parameter Optimization on Benchmark Datasets		Iris				Wine			Breast Cancer	Algorithms	LR	SVM	LR	SVM	LR	SVMP-SHE2(1θ0)-	0.952 ± 0.0^23~	0.987 ± 0.037~	0.967 ± 0.034~~	0.961 ± 0.0^27~	0.980 ± 0.0l4-	0.982 ± 0.015Derivative-Free Solutions						SHE2	0.493 ± 0.113	0.571 ± 0.065	0.628 ± 0.135	0.689 ± 0.138	0.848 ± 0.079	0.830 ± 0.112-PSO(IOO)-	0.920 ± 0.059	0.933 ± 0.059	0.922 ± 0.047	0.900 ± 0.045	0.956 ± 0.028	0.947 ± 0.014PSO(I)	0.361 ± 0.060	0.305 ± 0.034	0.355 ± 0.035	0.326 ± 0.015	0.608 ± 0.320	0.544 ± 0.211-BOBYQA-	0.793 ± 0.118	0.933 ± 0.059	0.944 ± 0.042	0.953 ± 0.019	0.959 ± 0.022	0.869 ± 0.062L-BFGS 一	0.747 ± 0.110~	0.600 ± 0.202~	0.772 ± 0.057~	0.828 ± 0.093^^	0.815 ± 0.008^^	0.947 ± 0.0T4~Derivative-based Solution						SGD*	0.950 ± 0.026	0.930 ± 0.038	0.975 ± 0.011	0.981 ± 0.016	0.965 ± 0.008	0.897 ± 0.0415.2	Parameter Optimization for Supervised LearningWe use above algorithms to train logistic regression (LR) and SVM classifiers using Iris (4 features,3 classes and 150 instances), Breast (32 features, 2 classes and 569 instances) and Wine (13 features,3 classes and 178 instances) datasets. We treat the loss functions of logistic regression and SVM asblack-box functions and parameters (e.g., projection vector β for logistic regression) as optimiza-tion outcomes. Note that the number of parameters for multi-class (#class ≥ 3) classification is#class × #f eatures, e.g., 39 for wine data. We don’t include GP-UCB in the comparison, as it isextremely time-consuming to scale-up in high-dimensional settings.
Table 2: Definitions of Hyperparametersminimum point of f (x). According to the general theory regrading Nesterov’s accelerated gradientmethod (see Nesterov and Su et al. (2014)), we naturally expect that the first step has convergenceratef(X(t)) - f(Y (t)) ≤ O(1/t2).
