Table 1: Test-set accuracy on the (unmodified) MNIST dataset of a 3-layer MLP (784-512-512-10)trained layer-by-layer with the IB functional. Pushing each layer towards the optimal IB curve re-sults in comparable performance to baselines, demonstrating the effectiveness of the IB principle.
Table 2: Test-set accuracy on the CIFAR-10 dataset for a conv-net (CONV16-CONV16-CONV16-FC512-FC512-FC10) trained layer-by-layer with the IB functional.
Table 3: MNIST and CIFAR-10 end-to-end classification accuracy. Here we used 5000/20000 train-ing steps for MNIST/CIFAR-10, respectively, and in each step we used 10 update steps for each ofthe two MINE discriminators. The variance of the regularization noise is Ïƒ2 = 2.
