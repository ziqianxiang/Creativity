Table 1: BLEU score and decoding times for different models on the WMT’14 English-German translation dataset. The baseline is the autoregressive Transformer of Vaswaniet al. (2017) with no beam search, NAT denotes the Non-Autoregressive Transformerof Gu et al. (2017), and LT + Semhash denotes the Latent Transformer from van denOord et al. (2017) using the improved semantic hashing discretization technique ofKaiser & Bengio (2018). NPD refers to noisy parallel decoding as described in Gu et al.
Table 2: Results showing the impact of the discrete vocabulary on the BLEU score for theWMT’14 English-German dataset. The hidden dimension is 512 for all runs.
Table 3: Results showing the impact of number of samples used to perform the Monte-CarloEM update on the BLEU score for the WMT’14 English-German dataset. The codebooksize for all runs in this table is 212 × 512.
Table 4: Results showing the impact of the dimension of the word embeddings and thehidden layers of the model on the BLEU score for the WMT’14 English-German datasetwith a discrete vocabulary of size 212 .
Table 5: Example latent codes for sentences from the WMT’14 English-German datasethighlighting the emergence of the EOS/PAD latent (760 in this case).
Table 6: BLEU score and decoding times for different models on the WMT’13 English-French translation dataset. The baseline is the autoregressive Transformer of Vaswaniet al. (2017) with no beam search, We use the notation nc to denote the compressionfactor for the latents, and the notation ns to denote the number of samples used toperform the Monte-Carlo approximation of the EM algorithm. Reg. refers to worddropout with rate 0.3 and word permutation with shuffle rate 0.5 as described in Section C.
