Table 1: GLUE results, using the development sets except where noted. E : ELMo used as inputlayer. C and S distinguish the two variants of the Reddit task. Bold results are the best overall;Underlined results are the best without ELMo. See text for discussion of WNLI results (*).
Table 2: Pearson correlations between performances on different target tasks, measured over all runsreported in Table 1. The Avg column shows the correlation between an individual task’s performancefor some pretraining and the overall GLUE score for that run. For tasks with multiple metrics, wenote the metric used here in the row title. Negative correlations are underlined.
Table 3: Hyperparameter settings for target-task models and target-task training. Attention is alwaysdisabled when pretraining on GLUE tasks. STS has a relatively small training set, but consistentlypatterns with the larger tasks in its behavior.
Table 4: Comparison of sampling methods on four subsets of GLUE using uniform loss scaling.
Table 5: Combinations of sampling and loss scaling methods on GLUE tasks. Results in bold aretied for best overall GLUE score.
Table 6: GLUE diagnostic set results, reported as R3 correlation coefficients (×100), which stan-dardizes the score of random guessing by an uninformed model at roughly 0. Human performanceon the overall diagnostic set is roughly 80. Results in bold are the best overall, and UnderIinedresults are the best without ELMo.
