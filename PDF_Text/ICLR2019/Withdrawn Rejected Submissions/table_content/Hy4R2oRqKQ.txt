Table 1: Comparison of existing CCA variants. Linear CCA methods are marked with gray, while others arenonlinear CCA extensions. Our proposed ACCA is marked with blue. Column 2 indicates the mapping of theinvolved variables. Column 3 indicates the adopted dependency criteria. Column 4 indicates whether the modelis generative. Column 5 indicates whether the method can handle the distribution with implicit form.
Table 2: Description for the roles of each set of subnetworks in ACCA.
Table 3: Details for the design of the toy dataset. The numerals correspond to the coefficients for the linearcombination of each dimension in each view. For example, X1 , the first dimension of view X is (z - 0.3z2).
Table 4: Correlation analysis results on the experimental datasets. The best ones are marked in bold.
Table 5: Pixel-level accuracy for full image recovery given gray color overlaid halved images for different inputviews on the MNIST_LR dataset.
