Table 1: Crossentropy and accuracy (parentheses) for each validation set and the original CIFAR10training set (“c10 50k”). Crossentropy for our human labels decreases substantially after fine-tuning,especially when using human targets. Fine-tuning on human targets also produces the best gener-alization in terms crossentropy on CIFAR10.1, whereas using ground truth (modal) labels has aslight edge in terms of top-1 accuracy.
Table 2: Crossentropy and accuracy (parentheses) for each validation set when combining mixupwith original or human targets.
Table 3: FGSM attacks on the CIFAR10-tuned and CIFAR10H-tuned networks. Using humanlabels results in lower crossentropy (lower is better), but also lower accuracy (parentheses).
