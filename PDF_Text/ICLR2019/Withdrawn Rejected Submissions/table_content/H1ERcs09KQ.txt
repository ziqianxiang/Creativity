Table 1: Encoding and decoding structure on z and η in HCRL. (s) indicates the s-th sample.
Table 2: Test set performance of the negative log likelihood (NLL) and the reconstruction errors(REs). RePlicated ten times, and the best in bold. P * < 0.05 (Student,s t-test). Model- L# meansthat the model trained with the #-depth hierarchy.
Table 3: Hierarchical clustering accuracies with F-scores, on CIFAR-100 with a dePth of three,RCV1_v2 with a depth of four, and 20NeWSgroUPS with a depth of four. Replicated ten times, and aconfidence interval with 95%. Best in bold.
Table 4: Table of symbolsModels	Symbol	DefinitionAll	x/x0 z D/J g*(x) fθ(z) θ 2 μ Z, σ N 2 μx, σx		An observed / reconstructed datapoint A latent representation The input / latent dimensionality A encoder network parametrized by *, whose input is X A decoder network parametrized by θ, whose input is z The variational parameters and weights of the decoder network fθ The variational mean and variance for Gaussian distribution qφz (z|x) The prior parameters, mean and variance, for Gaussian distribution pθ (x|z)VaDE & VAE-nCRP	φ N μ, σ	The variational parameters and weights of the encoder network gφ The variational mean and variance for Gaussian distribution qφ (z|x)VaDE & HCRL	N xn = 1,…，N zn = 1,…，N	The number of datapoints n-th observed datapoint n-th latent representation corresponding to XnVAE-nCRP & HCRL	L	The height of the tree-based hierarchyVaDE	K cn = 1,…，N κ μc,σN	The number of (finite) clusters The cluster assignment of zn, ∈ {1, ..., K} The prior parameter for multinomial distribution p(c) The prior parameters, mean and variance, for Gaussian distribution of c-th cluster, P(Z)VAE-nCRP	M Nm =1,…,M xm,n=1 ,∙∙∙ ,N zm,n=1 ,∙∙∙ ,N vmp Y (0)	(1) γmp , γmp ζmn Sm n αpar(p) α* N μρar(p), σpar(p) αp N σN N μp , σp σDN	The number of sequences The number datapoints in m-th sequence n-th observed datapoint in m-th sequence n-th latent representation corresponding to Xmn The Beta draws of m-th sequence on node p, for the tree-based stick- breaking construction The prior parameter for Beta distribution p(vmp) The variational parameters, for Beta distribution q(vmp|Xm) The path assignment of zmn The variational parameter for multinomial distribution q(ζmn |Xmn) The J -dimensional parameter vector for the parent node ofp The prior parameter for Gaussian distribution p(αp) for the root node The variational mean and variance for Gaussian distribution q(αpar(p) |X) The J -dimensional parameter vector for node p The prior parameter, variance, for Gaussian distribution ρ(αp∣αpar(p)) The variational mean and variance for Gaussian distribution q(αp∣x) The prior parameter, variance, for Gaussian distribution p(zmn∣Zmn, ap)HCRL	2∙2	0	W 2Z 2	The variational parameters and weights of the encoder network gφz The variational parameters and weights of the encoder network gφη The variational mean and variance for Gaussian distribution qφz (z|X) The variational mean and variance for logistic normal distribution qφη(n|x) The variational parameter for Dirichlet distribution qφη (η∣x) The Beta draws for the tree-based stick-breaking construction of node i The prior parameter for Beta distribution p(vi) The variational parameters, for Beta distribution q(vi |X) The path assignment of zn The variational parameter for multinomial distribution q(Zn∣Xn) The level proportion of zn The prior parameter for Dirichlet distribution p(ηn ) The level assignment of zn, ∈ {1, ..., L} The variational parameter for multinomial distribution q(ln|Xn) The prior parameters, mean and variance, for Gaussian distribution of nodei, P(Zn|Zn, ηn)16Under review as a conference paper at ICLR 2019E Generative and Inference Model for HCRLHCRL assumes the generative process as described in Section 3.1. Section E.1 describes the jointprobability distribution, and Section E.2 presents the corresponding variational distributions. Weadopt the much notation-related conventions from Wang & Blei (2009), especially on paths.
