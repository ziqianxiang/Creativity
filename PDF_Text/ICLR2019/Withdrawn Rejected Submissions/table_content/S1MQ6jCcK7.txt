Table 1: RMSE of compared methods on synthetic toy examplesOutliers	ChoiceNet	MDN	MLP	GPR	LGPR	RGPR~%%	0.034	0.028	0.039	0.008	0.022	0.01720%	0.022	0.087	0.413	0.280	0.206	0.01340%	0.018	0.565	0.452	0.447	0.439	1.32260%	0.023	0.645	0.636	0.602	0.579	0.73880%	0.084	0.778	0.829	0.779	0.777	1.523Figure 2: Reference function and fitting results of compared methods on different outlier rates.
Table 2: Average returns of compared methods on MuJoCo problemsOutliers	HalfCheetah			ChoiCeNet	Walker2d MDN	MLP	ChoiCeNet	MDN	MLP			10%	2068.14	192.53	852.91	2754.08	102.99	537.4220%	1498.72	675.94	372.90	1887.73	95.29	1155.8030%	2035.91	363.08	971.24	-267.10	-260.80	-728.39Behavior Cloning Example In this experiment, we apply ChoiceNet to behavior cloning taskswhen given demonstrations with mixed qualities. where the proposed method is compared withMLP and MDN in two locomotion tasks: HalfCheetah and Walker2d. The network architectures areidentical to those in the synthetic regression example tasks. To evaluate the robustness of ChoiceNet,we collect demonstrations from both an expert policy and an adversarial policy where two policiesare trained by solving the corresponding reinforcement learning problems using the state-of-the-artproximal policy optimization (PPO) (Schulman et al., 2017). For training adversarial policies forboth tasks, we flip the signs of the directional rewards so that the agent gets incentivized by goingbackward. We evaluate the performances of the compared methods using 500 state-action pairs withdifferent mixing ratio and measure the average return over 100 consecutive episodes. The results areshown in Table 2. In both cases, ChoiceNet outperforms compared methods by a significant margin.
Table 3: Test accuracies on the MNISTdatasets with corrupt labels.
Table 4: Test accuracies on the CIFAR-10 datasetswith corrupt labelsCorruption p	Configuration	Best	Last	ConvNet	88.5	85.320%	ConvNet+CN	90.7	90.3	ConvNet+Mixup	92.9	92.3	ConvNet+Mixup+CN	92.5	92.3	ConvNet	79.7	59.350%	ConvNet+CN	85.9	84.6	ConvNet+Mixup	87.3	83.1	ConvNet+Mixup+CN	88.4	87.9	ConvNet	67.8	27.480%	ConvNet+CN	69.8	65.2	ConvNet+Mixup	72.1	62.9	ConvNet+Mixup+CN	76.1	75.4The classification results of the MNIST dataset and the CIFAR dataset are shown in Table 3 andTable 4, respectively. In the MNIST experiments, ChoiceNet consistently outperforms ConvNet andConvNet+Mixup by a significant margin, and the difference between the accuracies of ChoiceNetand the others becomes more clear as the corruption probability increases. Particularly, the best testaccuracy of ChoiceNet reaches 94% even when 90% of the training labels are randomly shuffled.
Table 5: Collision rates of compared methods on straight lanes.
Table 6: Root mean square lane deviation distances (m) of compared methods on straight lanes.
Table 7: Test accuracies on the MNIST dataset with biased label.
Table 8: Test accuracies on the MNIST dataset with corrupt label.
Table 9: Test accuracies on the MNIST dataset with randomly permutated label.
