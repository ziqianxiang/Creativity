Table 1: Comparison of characteristics of datasets	PEST2009	AVSS2007	VIRAT	YoutubeResolution	768x576	720x576	1920x1080	1280x720Avg. Person Height in Pixels	75	193	139	149Avg. Person to video height ratio	13%	34%	13%	21%Avg. Car Height in Pixels	49	66	104	98Avg. Car to video height ratio	20%	6%	10%	14%Avg. Scene Similarity Ratio (ΘIDM = 20)	96.6%	97.4%	99.9%	97.4%4.1	ON PETS 2009The PETS 2009 dataset is a benchmark which focuses on several challenges for crowd analysis inpublic area including the estimation of crowd person count and density, tracking of individual(s)within a crowd, and detection of flow and crowd events. In this dataset, we choose 20 differencescene videos totally involving 4,884 photos as test data. Table 2 presents the result of the perfor-mance on objects person and car with the threshold of frame differencing setting at 20. It is clearto see that the proposed dynamic convolution can preserve the precision with respect to baseline,where the difference is only 0.06% and 0.21% on person and car respectively.
Table 2: Average precision results on PETS2009Class-Person	TotalGT	TotalPred	TruePositives	FalsePositives	AvgPrecisionBaseline	40720	39357	35202	4155	80.54%DynCNN	40720	39227	35047	4180	80.48%Class-Car	TotalGT	TotalPred	TruePositives	FalsePositives	AvgPrecisionBaseline	4845	5592	4661	931	90.22%DynCNN	4845	5540	4642	898	90.01%4.2	ON AVSS 2007AVSS2007 is a data set for evaluating the algorithm on event detection and tracking. In this dataset,we choose six videos, which contains public surveillance scene for train station and road located inthe UK, as our test data including 35,000 images. Table 3 presents the result of the performance onobjects person and car with the threshold of frame differencing setting at 20. It is clear to see that theproposed dynamic convolution can preserve the precision with respect to baseline where differenceis only 0.16% and 0.42% on person and car respectively.
Table 3: Average precision results on AVSS2007Class-Person	TotalGT	TotalPred	TruePositives	FalsePositives	AvgPrecisionBaseline	227232	226448	198876	27538	80.57%DynCNN	227232	222102	191999	30067	79.89%Class-Car	TotalGT	TotalPred	TruePositives	FalsePositives	AvgPrecisionBaseline	44275	44682	40485	4195	89.39%DynCNN	44275	44116	39984	4130	89.23%4.3	ON VIRATVIRAT dataset collects broad surveillance videos in terms of various realism scenes includingground camera videos and aerial videos. In this dataset, 10 different scene videos on parking lot,lane and plaza totally involving 63,947 photos are selected as test data. Table 4 presents the resultof the performance on objects person and car with the threshold of frame differencing setting at 20.
Table 4: Average precision results on VIRATClass-Person	TotalGT	TotalPred	TruePositives	FalsePositives	AvgPrecisionBaseline	48514	42154	36895	5110	70.50%DynCNN	48514	39716	34733	4843	69.96%Class-Car	TotalGT	TotalPred	TruePositives	FalsePositives	AvgPrecisionBaseline	192489	189550	173042	16491	80.94%DynCNN	192489	186340	169027	17313	80.84%4.4	On YoutubeThe collected surveillance videos on Youtube contain 9 scene videos with different viewing angleson the zoo, MRT station, campus and street involving 115,652 images. Table 5 presents the resultof the performance on objects person and car with the threshold of frame differencing setting at 20.
Table 5: Average precision results on YoutubeClass-Person	TotalGT	TotalPred	TruePositives	FalsePositives	AvgPrecisionBaseline	465470	458898	383821	75077	78.90%DynCNN	465470	449537	372898	76639	78.20%Class-Car	TotalGT	TotalPred	TruePositives	FalsePositives	AvgPrecisionBaseline	59867	61832	47447	14385	70.92%DynCNN	59867	61304	46402	14905	70.22%4.5	Continuous convolutionTable 6 shows the average calculation process in each layer over all test videos of PETS 2009 datasetincluding the DynCNN with and without continuous convolution. The fifth and eighth column rep-resents the new array size of dyn-convolution and the horizontal lines represent the pooling processwhich is used to delimit the convolution groups. As the layer more deeper, the pruned ratio generallydecreases due to the increasing size of needed pixels. Note that the increasing behavior of pruned ra-tio in each convolution group under DynCNN (w/). In continuous convolution, the inner differencemap of the first layer of convolution group directly predicts the impacted pixels of the last layer inadvance, which results in that the needed pixels on the new array is more than DynCNN (w/o) anddecreases gradually as layer deeper. This phenomenon can also be found in other datasets as shownin Appendix 7.4. Table 7 summarizes the average calculation amount and processing time per frameon each dataset. From this table, although DynCNN (w/o) can prune more calculation amount thanDynCNN (w/), DynCNN (w/o) needs to cost more processing time on data transfer. The improve-
Table 6: Average FLOPs result on PETS2009Layer-type	Maps	Baseline		DynCNN (w/o)			DynCNN (w/)				WXh	FLOPs	wxh	FLOPs	%Pruned	wxh	FLOPs	%PrunedConv1-1	64~	512x512	4.5E+08	1456x16	-4.0E+07~	91.1%	1704x18	5.3E+07	88.2%Conv1-2	64	512x512	9.6E+09	1572x16	9.2E+08	90.4%	1702x16	1.0E+09	89.4%Conv2-1	128	256 X 256	4.8E+09	978x8	~5.9E+08~	87.7%	1085x10	8.0E+08	83.2%Conv2-2	128	256x256	9.6E+09	1044x8	1.23E+09	87.2%	1083x8	1.3E+09	86.5%Conv3-1	256	128 X 128	4.8E+09	389x8	~9.1E+08~	81.0%	536x12	1.9E+09	59.8%Conv3-2	256	128 X 128	9.6E+09	421x8	1.97E+09	79.5%	534x10	3.2E+09	66.5%Conv3-3	256	128 X 128	9.6E+09	453x8	2.13E+09	77.8%	532x8	2.5E+09	73.3%Conv4-1	512	64 x 64	4.8E+09	181x8	~1.69E+09-	64.8%	264x12	3.7E+09	22.3%Conv4-2	512	64x64	9.6E+09	196x8	3.66E+09	61.9%	262x10	6.1E+09	35.6%Conv4-3	512	64x64	9.6E+09	212x8	3.96E+09	58.8%	260x8	4.9E+09	48.9%Conv5-1	512	32x32	2.4E+09	~84x8	~1.54E+09-	35.8%	118x12	3.3E+09	-39.1%Conv5-2	512	32x32	2.4E+09	89x8	1.64E+09	31.7%	116x10	2.7E+09	-13.7%Conv5-3	512	32x32	2.4E+09	95x8	1.75E+09	27.1%	114x8	2.1E+09	10.4%FC6 FC7	1024	1	1.3E+08	~1024	-1.3E+08~	0%	~1024	1.3E+08	0%Other			1.07E+10		1.07E+10	0%		1.07E+10	0%Total			9.05e+10			3.29e+10 ―	63.7%		4.47e+10 —	50.5%Table 7: Overview results on all datasets
Table 7: Overview results on all datasetsDataset	Baseline		DynCNN (w/o)			DynCNN (w/)			FLOPs	Time(ms)	FLOPs	%Pruned Time(ms)		FLOPs	%Pruned	Time(ms)PETS2009	9.05E+10	30.7	3.29E+10	63.7%	28.3	4.47E+10	50.5%	19.2AVSS2007	9.05E+10	30.7	3.91E+10	56.8%	32.1	5.36E+10	40.8%	22.9VIRAT	9.05E+10	30.7	1.5E+10	83.3%	20.3	2.2E+10	75.7%	13.9Youtube	9.05E+10	30.7	2.46E+10	72.8%	27.5	4.47E+10	50.6%	207Under review as a conference paper at ICLR 20195	Discussion5.1	Threshold of Frame DifferencingThe threshold of IDM is used to filter the speckle noise in video. In addition, it can greatly speedup the processing time due to the high scene similarity of video—most difference values derivedfrom frame differencing are introduced by noise. For various surveillance videos, the threshold ofIDM should be different, resulting in a single threshold is difficult to be applicable to all surveillanceimages. To find the best threshold, we conduct a research on the relationship between the precisionand calculation amount over different thresholds. Figure 4 shows the test result on 4 datasets.
Table 8: Average execution time per layerLayer-type	Baseline (ms)	DynCNN (ms)	Saved Time%Compare	-	0.043	Position1	-	0.18	Conv1-1	1.15	0.13	88.2%Relu1-1	0.58	0.075	87.0%Conv1-2	2.53	0.39	84.5%Relu1-2	0.58	0.062	89.4%Recovery1	-	0.036	Group1	4.84	0.92	80.9%Position2	-	027	Conv2-1	1.2	0.32	73.2%Relu2-1	0.58	0.062	89.4%Conv2-2	1.73	0.46	73.5%Relu2-2	0.29	0.042	85.7%Recovery2	-	0.047	Group2	3.52	1.19	65.9%Position3	-	0.39	Conv3-1	0.88	0.60	31.5%Relu3-1	0.15	0.059	60.4%
Table 9: Average FLOPs result on AVSS2007Layer-type	MaPs	Baseline		DynCNN (w/o)			DynCNN (w/)				WXh	FLOPs	wxh	FLOPs	%Pruned	WXh	FLOPs	%PrunedConv1-1	512x512	64	4.5E+08	1704 X 16	4.7E+07-	89.6%	1931 X18	6.3E+07	85.9%Conv1-2	512x512	64	9.6E+09	1916x16	1.1E+09	88.2%	1929x16	1.2E+09	87.5%Conv2-1	256 X256	128	4.8E+09	1276x8	7.5E+08-	84.4%	1507 X10	1.1E+09	77.1%Conv2-2	256 x256	128	9.6E+09	1385x8	1.6E+09	83.0%	1505 x 8	2.2E+09	77.0%Conv3-1	128 X128	256	4.8E+09	532x8	1.2E+09-	74.0%	753 X 12	2.6E+09	44.6%Conv3-2	128 x128	256	9.6E+09	578x8	2.7E+09	71.7%	751 x 10	4.4E+09	53.9%Conv3-3	128 X128	256	9.6E+09	619x8	2.9E+09	69.7%	749x8	3.5E+09	63.2%Conv4-1	64x64	512	4.8E+09	236x8	2.2E+09-	54.2%	377 x 12	4.7E+09	1.7%Conv4-2	64x64	512	9.6E+09	254x8	4.7E+09	50.5%	375x 10	7.8E+09	18.5%Conv4-3	64x64	512	9.6E+09	273x8	5.1E+09	46.8%	373 x8	6.2E+09	35.3%Conv5-1	32x32	512	2.4E+09	-99x8-	1.8E+09-	23.8%	129x12	3.5E+09	-48.7%Conv5-2	32x32	512	2.4E+09	104x8	1.8E+09	20.0%	127x10	2.9E+09	-22.1%Conv5-3	32x32	512	2.4E+09	108x8	2.0E+09	16.7%	125x8	2.3E+09	4.2%FC6 FC7	1	1024	1.3E+08	-1024~	1.3E+08-	0%	-1024~	1.3E+08	0%Other			1.07E+10		1.07E+10	0%		1.07E+10	0%Total			9.05e+10			3.91e+10	56.8%		5.36e+10	40.8%Table 10: Average FLOPs result on VIRAT
Table 10: Average FLOPs result on VIRATLayer-tyPe	Maps	Baseline		DynCNN (w/o))			DynCNN (w/)				wxh	FLOPs	WXh	FLOPs	%Pruned	WXh	FLOPs	%PrunedConv1-1	512x512	64	4.5E+08	120x16	-3.2E+06	99.3%	310x18	9.6E+06	97.8%Conv1-2	512x512	64	9.6E+09	138x16	8.0E+07	99.2%	308x16	1.8E+08	98.1%Conv2-1	256 X 256	128	4.8E+09	99x8	~5.7E+07	98.8%	188x10	1.4E+08	97.1%Conv2-2	256x256	128	9.6E+09	110x8	1.3E+08	98.7%	186x8	2.2E+08	97.7%Conv3-1	128x128	256	4.8E+09	54x8	~1.2E+08	97.5%	129x12	4.5E+08	90.6%Conv3-2	128x128	256	9.6E+09	60x8	2.7E+08	97.2%	127x10	7.4E+08	92.3%Conv3-3	128x128	256	9.6E+09	67x8	3.1E+08	96.8%	125x8	5.8E+08	93.9%Conv4-1	64x64	512	4.8E+09	36x8	-3.2E+08	93.3%	90x12	1.2E+09	74.1%Conv4-2	64x64	512	9.6E+09	40x8	7.2E+08	92.5%	88x10	2.1E+09	78.1%Conv4-3	64x64	512	9.6E+09	45x8	8.1E+08	91.6%	86x8	1.5E+09	83.7%Conv5-1	32x32	512	2.4E+09	26x8	-4.5E+08	81.1%	60x12	1.6E+09	32.1%Conv5-2	32x32	512	2.4E+09	28x8	4.9E+08	79.6%	58x10	1.3E+09	45.8%Conv5-3	32x32	512	2.4E+09	31x8	5.4E+08	77.5%	56x8	1.1E+09	58.3%FC6 FC7	1	1024	1.3E+08	1024	-1.3E+08	0%	1024	1.3E+08	0%Other			1.07E+10		1.07E+10	0%		1.07E+10	0%Total			9.05e+10			1.5e+10	83.3%		2.2e+10 —	75.7%Table 11: Average FLOPs result on YouTube
Table 11: Average FLOPs result on YouTubeLayer-type	Maps	Baseline		DynCNN (w/o)			DynCNN (w/)				wxh	FLOPs	wxh	FLOPs	%Pruned	wxh	FLOPs	%PrunedConv1-1	512x512	64	4.5E+08	742x16	-2.0E+07	95.6%	1702x18	5.3E+07	88.2%Conv1-2	512x512	64	9.6E+09	845x16	5.0E+08	94.8%	1700x16	1.0E+09	89.6%Conv2-1	256 X 256	128	4.8E+09	582x8	-3.4E+08	92.9%	1205x10	8.8E+08	81.7%Conv2-2	256x256	128	9.6E+09	637x8	7.5E+08	92.2%	1203x8	1.6E+09	82.9%Conv3-1	128x128	256	4.8E+09	251x8	-5.8E+08	87.9%	571x12	2.0E+09	58.1%Conv3-2	128x128	256	9.6E+09	272x8	1.3E+09	86.8%	569x10	3.3E+09	65.2%Conv3-3	128x128	256	9.6E+09	293x8	1.4E+09	85.7%	567x8	2.6E+09	72.3%Conv4-1	64x64	512	4.8E+09	113x8	-1.0E+09	78.3%	265x12	3.7E+09	22.5%Conv4-2	64x64	512	9.6E+09	122x8	2.3E+09	76.5%	263x10	6.1E+09	35.9%Conv4-3	64x64	512	9.6E+09	131x8	2.4E+09	74.7%	261x8	4.9E+09	49.1%Conv5-1	32x32	512	2.4E+09	55x8	-1.0E+09	58.3%	110x12	3.0E+09	-27.9%Conv5-2	32x32	512	2.4E+09	59x8	1.1E+09	55.4%	108x10	2.5E+09	-4.6%Conv5-3	32x32	512	2.4E+09	62x8	1.1E+09	52.9%	106x8	1.9E+09	17.9%FC6 FC7	1	1024	1.3E+08	1024	-1.3E+08	0%	-1024	1.3E+08	0%Other			1.07E+10		1.07E+10	0%		1.07E+10	0%Total			9.05e+10			2.46e+10	72.8%		4.47e+10 —	50.6%14
