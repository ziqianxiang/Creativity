Table 1: Performance of black-box defense under the setting of Madry et al. (2017) (See Appendix F.1 for thecomplete setting). We use model under adversarial training in Madry et al. (2017) as a vanilla model. It isregarded as a state-of-the-art adversarial defense method. Our model is only trained on clean data. The ratioof Random Mask here is selected to balance the performance of robustness and generalization. See Figure 14in Appendix F.1 for results on the performance of Random Mask with different ratios.
Table 2: A subset of our experiments presented in Appendix F.5 to show properties of Random Mask.
Table 3: The accuracy by using normal and masked networks to classify randomly shuffled test images.
Table 4: Black-box experiments on CIFAR-10. Networks in the leftmost column are the target modelswhich defend against adversarial examples. Networks in the first row are the source models to generateadversarial examples by PGD. PGD runs for 20 steps with step size 1 and perturbation scale 16. 0.5-shallowand 0.7-shallow mean applying Random Mask with drop ratio 0.5 and 0.7 to the shallow layers of the networkstructure whose name lies just above them. All the numbers except the Acc column mean the success rate ofdefense.
Table 5: Black-box experiments on MNIST. Networks in the leftmost column are the target models whichdefend against adversarial examples. Networks in the first row are the source models to generate adversarialexamples by PGD. PGD runs for 40 steps with step size 0.01 × 255 and perturbation scale 0.3 × 255.
Table 6: White-box defense performance. FGSM1, FGSM2, FGSM4 refer to FGSM with step size 1,2,4respectively. PGD2, PGD4, PGD8 refer to PGD with perturbation scale 2,4,8 and step number 4,6,10 respec-tively. The step size of all PGD are set to 1.
Table 7: Results on gray-box attacks and transferability. We use FGSM with step size 16 to generate theadversarial examples on source networks and test them on target networks. For target networks, NormalResNet-18, 0.5-Shallow and 0.7-Shallow represent the networks with the same structure as the correspondingsource networks but with different initialization values. 0.5-ShallowDIF and 0.7-ShallowDIF represent thenetworks with the same drop ratios as the corresponding source networks but with different random masks.
Table 8: Extended	experimental	results	of Section	3.3.	Adversarial	examples	generated	against DenseNet-121.	The model	trained	on CIFAR-10 achieves 95.62%			accuracy	on test	set.
Table 9: Extended experimental results of Section 3.3. Adversarial examples are generatedagainst ResNet-18. The model trained on CIFAR-10 achieves 95.27% accuracy on test set.
Table 10: Extended experimental results of Section 3.3. Adversarial examples are generatedagainst ResNet-50. The model trained on CIFAR-10 achieves 95.69% accuracy on test set.
Table 11: Extended experimental results of Section 3.3. Adversarial examples are generatedagainst SENet-18. The model trained on CIFAR-10 achieves 95.15% accuracy on test set.
Table 12: Extended	experimental results		of Section	3.3.	Adversarial	examples	are gener-ated against VGG-19.	The model trained		on CIFAR-10 achieves 94.04%			accuracy	on test set.
