Table 1: Accuracy of different classifiers against rotation and translation adversaries on MNIST,CIFAR10, and ImageNet. The allowed transformations are translations by (roughly) 10% of theimage size and ±30。rotations. The attack parameters are chosen through random sampling or gridsearch with rotations and translations considered both together (“Rand.”, “Grid”) and separately(“Rand. T.” and “Grid T.” for transformations, “Rand R.” and “Grid R.” for rotations). We considernetworks that are trained with (i) the respective standard setup, (ii) no data augmentation (if dataaugmentation is present in standard setup), (iii) with an '∞ adversary, (iv) with data augmentationcorresponding to the attack space (±3px, ±30。)and an enlarged space (±4px, ±40。), and (v) withworst-of-10 training for both types of augmentations.
Table 2: Comparison of attack methods across datasets and models. Worst-of-10 is very effectiveand significantly reduces the model accuracy despite the limited interaction. The first-order (FO)adversary performs poorly, despite the large number of steps allowed. We compare standard trainingto Augmentation (±3px, ±30。). For the full table, see Figure 3 of Appendix A.
Table 3: Comparison of attack methods across datasets and models.
Table 4: Evaluation of a subset of Table 1 in the “black-canvas” setting (images are zero-padded toavoid cropping due to rotations and translations). The models are trained on padded images.
Table 5: Majority Defense. Accuracy of different models on the natural evaluation set and against acombined rotation and translation adversary using aggregation of multiple random transformations.
Table 6: CIFAR10: The effect of using reflection or zero padding when training a model. Theexperimental setup matches that of Section 4. Zero padding refers to filling the empty pixels causedby translations and rotations with black. Mirror padding corresponds to using a reflection of theimages. ”Both” refers to training using both methods and alternating randomly between them foreach training example.
