Table 1: BLEU scores on the UN corpus testset. The first column refers to a number ofbaseline phrase-based models, the second isa single multi-lingual NMT model. All mod-els are trained on the same 1M en-es and 1Men-fr aligned sentences, used in both direc-tions. In this setting, NMT-0 is used in thesupervised direction.
Table 2: BLEU scores on the UN corpus testset, using no parallel data for the evaluateddirection. The first column (NMT zero-shot,same model as in Table 1) refers to our base-line multilingual model. The Dual-0 modelrefers to our approach, applying RL with 500kmonolingual sentences of each language ontop of NMT-0.
Table 3: Comparison with other approaches. Numbers are BLEU scores on WMT newstest2014.
