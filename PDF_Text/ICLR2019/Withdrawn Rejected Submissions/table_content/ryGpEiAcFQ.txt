Table 1: SynaMLP MNIST TestingThe MNIST SynaMLP training and testing is implemented by Python, Keras and Tensorflow (Abadiet al. (2016)) from the revision of the example of mnist_mlp.py in Keras distribution. The synapsetensor is designed to be a class to replace Dense in Keras. The layer sequence is as below,Layer Type	Output Shape	Param #Dense[1]	(None, 300)	235500Batch-normalization[1]	(None, 300)	1200Activation[1]	(None, 300)	0Synapse[1]	(None, 300)	90000Batch-normalization[2]	(None, 300)	1200Dense[2]	(None, 10)	3010Optimizer	Adam	defaultTable 2: SynaMLP LayersIn the comparison experiment, SynaNN MLP and traditional MLP generated the similar test accuracyof around 98%. We applied a softmax activation function in front of the input of synapse to avoidthe error of NAN (computing value out of the domain). In fact, synaptic neural network handles aprobability distribution (vector from neurons).
Table 2: SynaMLP LayersIn the comparison experiment, SynaNN MLP and traditional MLP generated the similar test accuracyof around 98%. We applied a softmax activation function in front of the input of synapse to avoidthe error of NAN (computing value out of the domain). In fact, synaptic neural network handles aprobability distribution (vector from neurons).
