Table 1: Subject detection onusersFigure 3: Left and center figures show images of consenting and nonconsenting (private) users respectively,along with their sanitized counterparts. The identity of consenting users is still easily verified, while the identityof nonconsenting users is effectively censored. Table on the right shows Top-5 accuracy performance of thesubject detector after sanitization across several sanitation levels α. Performance is shown across 3 subsets,consenting users (CU) are users that decided to be detected by the utility algorithm, observed private users(OPU) are those that explicitly decided to protect their privacy, while unobserved private users (UPU) areusers that decided to protect their privacy but where not available during training. Consenting users are stillrecognized by the system, while nonconsenting users are not. For example, for α = 0.4, we significantly blockOPU and UPU while preserving CU5.2	Obfuscating Emotion While Preserving GenderHere we continue to work on facial image data X , where utility variable U is gender recognition,and the secret variable S is emotion (smiling/non-smiling). In this scenario, variables U and S areindependent. We implement this over the CelebA dataset Liu et al. (2015), using Xception networksChollet (2017) as our utility and privacy estimators. Table.2 shows the distribution of the utility andsecrecy estimators over the sanitized data. Figure 4 shows example sanitized images. It is visuallypossible to identify the gender of the subject but not their emotion. Most importantly, the existinggender detection algorithm still performs correctly over the sanitized images.
Table 2: Gender and emotion detectionon users on raw and sanitized data.
