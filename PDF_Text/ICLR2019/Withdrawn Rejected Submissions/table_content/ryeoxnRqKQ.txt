Table 1: Adversarial attack on 11 recently published defense methods. (** indicates the numberreported in the original paper (Athalye et al., 2018). For all the other numbers, we obtain them byrunning the code and models released by the respective authors. BPDA, ZOO, QL and D-basedstand for (Athalye et al., 2018), (Chen et al., 2017), (Ilyas et al., 2018) and (Brendel et al., 2017), re-spectively. * means the results are obtained on 1000 (200) randomly selected CIFAR10 (ImageNet)images, and the experiments on the full test set will be completed soon.) For D-based attack, we justreport results on 100 images since it takes much longer time to converge only with hard-label andwe will finish the experiments soon.
Table 2: Modifying QL (Ilyas et al., 2018) towards N ATTACK step by step. We first add the CLIPoperation to Line 3, Algorithm 2 (+CLIP), so that the input to the neural network is '∞ bounded.
Table 3: Comparison of C&W attack, ZOO, and NAttack on L2 distortion. ‘一’ means C&Wattack fails on Therm. *NATTACK uses the optimization shown in eq. (6).
Table 4: Average attacking time for one image. NATTACK-R represents NAT TAC K initialized withregression netDefense	Dataset	BPDA Athalye et al. (2018)	NATTACK	N Attack-RSAP Dhillon et al. (2018) Randomization	CIFAR-10 (L∞) ImageNet (L∞)	33.3s	29.4s	一Xie et al. (2018)		3.51s	70.77s	48.22s14Under review as a conference paper at ICLR 2019A.3 Ten most recent defense techniquesThis paper attacks 10 most recent defense techniques, as shown below.
