Table 1: Classification accuracy of different attacks tested on MNIST dataset. FGSM: = 0.3;BIM: = 0.3 and iterations = 5; MIM: = 0.3, iterations = 10, and decay factor = 1; PGD: = 0.1,iterations=40; C&W: iterations = 50, GM: = 20.
Table 2: Feature transformation analysis of MNIST dataset for original 3-layer CNN vs. the pro-posed method	Silhouette	Calinski	Mutual information	Homogeneity	CompletenessORIG	0.2612	1658.20	0.9695	0.9696	0.9721PROP	0.4284	2570.42	0.9720	0.9721	0.9815In Figure 4, we illustrate feature spaces of each layer in a simple 3-layer CNN network using t-SNE and PCA methods by reducing the high dimensional feature space into two dimensions. Ascan be seen, the proposed radial basis feature transformation helps reduce intra-class and increaseinter-class distances.
Table 3: Classification accuracy on X-Chest14 dataset for different attacks and defensesDefence					Attack	Iteration	ORIG	GDA	FSM	PROPL1-BIM	5	^^0^^	0	0.55	0.63BIM	5	0	0	0.54	0.65Clean	-	0.74	0.75	0.57	0.74respectively) and adversarial training Goodfellow et al. (2015) (ADVT). As reported in Table 4, thepercentage accuracy (Dice score) drop for the proposed radial basis transformation method is only1.60% and 6.39% after 10 and 30 iterations of the attack with γ = 0.03 for U-Net and 8.50% and13.95% for V-Net, respectively. Applying feature transformation, improved the segmentation ac-curacy on clean (non-attacked) images from 0.7743 to 0.7780 and 0.8070 to 0.8213 for U-Net andV-Net, respectively.
Table 4: Segmentation results (average DICE±STDV) of different defense mechanisms comparedto the proposed radial basis feature transformation method for V-Net and U-Net under DAG attack.
Table 5: Segmentation DICE± STDV scores of black-box attacks; adversarial images were pro-duced with methods in first left column and tested with methods in the first row.
Table 6: Ablation study over the usefulness of learning the transformation matrix T and β on theskin lesion dataset for V-Net.
