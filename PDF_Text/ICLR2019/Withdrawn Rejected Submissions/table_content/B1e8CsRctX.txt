Table 1: Categorization of several OoD detection techniques, based on whether they depend on aspecific model/task, and whether they assume a specific anomaly distribution.
Table 2: We train models on MNIST, Fashion MNIST, and CIFAR-10 and compare OoD classifi-cation ability to baseline methods using the threshold-independent Area Under ROC curve metric(AUROC). D corresponds to single WGAN discriminators with 4k fine-tuning steps on stationaryp(x), q(x). Var(D) is uncertainty estimated by an ensemble of discriminators. Rate is the DKL termin the VAE objective. log pÎ¸ (x) is a single likelihood model (VAE, GLOW). WAIC is the Watanabe-Akaike Information Criterion as estimated by the Generative Ensemble. ODIN results reproducedfrom Liang et al. (2017). Best results for each task shown in bold.
Table 3: Comparison of density-based anomaly detection approaches to a classification baseline onthe Kaggle Credit Card Fraud Dataset. The test set consists of 492 fraudulent transactions and 492normal transactions. Threshold-independent metrics include False Positives at 95% True Positives(FPR@95%TPR), Area Under ROC (AUROC), and Average Precision (AP). Density-based models(Single IWAE, WAIC) are trained only on normal credit card transactions, while the classifier istrained on normal and fraudulent transactions. Arrows denote the direction of better scores.
