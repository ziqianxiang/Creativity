Table 1: The split MNIST task protocol according to each continual learning scenario.
Table 2: The permuted MNIST task protocol according to each continual learning scenario.
Table 3: Average test accuracy (over all tasks) on the split MNIST task protocol. Each experiment was performed 20 times with different random seeds, reported is the mean (± SEM) over these runs.			Method	Incremental task learning	Incremental domain learning	Incremental class learningNone - lower bound	85.15 (± 1.00)	57.33 (± 1.66)	19.90 (± 0.02)XdG	98.74 (± 0.31)	-	-EWC	85.48 (± 1.20)	57.80 (± 1.61)	19.90 (± 0.02)Online EWC	85.22 (± 1.06)	57.60 (± 1.66)	19.90 (± 0.02)SI	99.14 (± 0.11)	63.77 (± 1.18)	20.04 (± 0.08)LwF	99.60 (± 0.03)	71.02 (± 1.26)	24.17 (± 0.51)DGR	99.47 (± 0.03)	95.74 (± 0.23)	91.24 (± 0.33)DGR+distill	99.59 (± 0.03)	96.94 (± 0.14)	91.84 (± 0.27)IGR (see below)	99.66 (± 0.03)	97.31 (± 0.11)	92.56 (± 0.21)Offline - upper bound	99.64 (± 0.03)	98.41 (± 0.06)	97.93 (± 0.04)Table 4: Idem as Table 3, except on the permuted MNIST task protocol.
Table 4: Idem as Table 3, except on the permuted MNIST task protocol.
