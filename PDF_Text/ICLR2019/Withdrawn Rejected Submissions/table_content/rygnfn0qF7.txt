Table 1: Downstream task performance for the segmentation and answer passage retrieval tasks.
Table 2: Analysis of the impact of different pretraining methods on document summarization andzero-shot answer passage retrieval.
Table 3: Comparative evaluation of our summarization models with respect to other extractive sum-marization systems. ROUGE-1 (R-1), ROUGE-2 (R-2), and ROUGE-L (R-L) F1 scores are re-ported. The first part of the table indicates the system results with non-autoregressive sentenceselection models. The second part of the table shows the performance with fresh trained LSTM withpretrained embeddings. NeuSum (Zhou et al., 2018) is included in the third part as it is specificallytrained to score combinations of sentences with auto-regressive selection models.
