Table 1: Summary of the tasks used for our experiments4Name	Architecture	DatasetC10-CNN1	25 layers deep CNN	CIFAR-10C100-resnet	ResNet-32	CIFAR-100tiny-CNN	11 layers deep CNN	Tiny ImageNetC10-CNN2	deep CNN from torch blog	CIFAR-10 + data augm.
Table 2: Train accuracies associated to Figure 2bα = 0.6	α = -0.6	ρ(0) = 3-5	ρ(0) = 3-4	BestC10-CNN1	100%	99.55%	100%	100%	99.99%C100-resnet	97.38%	97.9%	99.87%	99.99%	99.75%tiny-CNN	99.98%	98.64%	99.97%	99.97%	98.91%Table 3: Train accuracies associated to Figure 4	C10-CNN1 C100-resnet tiny-CNN C10-CNN2 C100-WRNSGD SGD + L2	100%	100%	100%	91%	100% 100%	100%	89.8%	99.5%	100%Table 4: Train accuracies associated to Figure 5C10-CNN1 C100-resnet tiny-CNN C10-CNN2 C100-WRNAdaptive methods	100%	99.98%	99.97%	98.72%	99.92%18Under review as a conference paper at ICLR 2019B.5	Momentum scheme used by SGD-AMom and Adam.
Table 3: Train accuracies associated to Figure 4	C10-CNN1 C100-resnet tiny-CNN C10-CNN2 C100-WRNSGD SGD + L2	100%	100%	100%	91%	100% 100%	100%	89.8%	99.5%	100%Table 4: Train accuracies associated to Figure 5C10-CNN1 C100-resnet tiny-CNN C10-CNN2 C100-WRNAdaptive methods	100%	99.98%	99.97%	98.72%	99.92%18Under review as a conference paper at ICLR 2019B.5	Momentum scheme used by SGD-AMom and Adam.
Table 4: Train accuracies associated to Figure 5C10-CNN1 C100-resnet tiny-CNN C10-CNN2 C100-WRNAdaptive methods	100%	99.98%	99.97%	98.72%	99.92%18Under review as a conference paper at ICLR 2019B.5	Momentum scheme used by SGD-AMom and Adam.
