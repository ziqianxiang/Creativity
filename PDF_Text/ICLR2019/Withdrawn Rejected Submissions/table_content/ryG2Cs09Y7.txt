Table 1: Performance comparison of the adversarial training method (Madry et al., 2017) and ourproposed adversarial training with feature regularization (AT-reg) method on MNIST. Black boxaccuracies are evaluated against adversaries generated from an independently trained copy of thesame method with identical configurations.
Table 2: Performance comparison of the adversarial training (Madry et al., 2017), adversarial train-ing with feature regularization (AT-reg), adversarial training with attention model (AT-att), and ad-versarial training with both (AT-att-reg) on CIFAR-10. Black box accuracies are evaluated againstadversaries generated from an independently trained copy of the same method with identical config-urations.
Table 3: Performance comparison of the adversarial training (Madry et al., 2017), adversarial train-ing with feature regularization (AT-reg), adversarial training with attention model (AT-att), and ad-versarial training with both (AT-att-reg) on CIFAR-10 using the 3-times wide ResNet network. Blackbox accuracies are evaluated against adversaries generated from an independently trained copy ofthe same method with identical configurations.
Table 4: Classification accuracy on the gradient maps from baseline and our methods on both thetraining dataset and test dataset of CIFAR-10. We run the experiment on gradient maps both withand without clipping to avoid the influence of gradient clipping.
Table 5: Performance comparison of the adversarial training (Madry et al., 2017), adversarial train-ing with feature regularization (AT-reg), adversarial training with attention model (AT-att), and ad-versarial training with both (AT-att-reg) on CIFAR-100. Black box accuracies are evaluated againstadversaries generated from an independently trained copy of the same method with identical config-urations.
