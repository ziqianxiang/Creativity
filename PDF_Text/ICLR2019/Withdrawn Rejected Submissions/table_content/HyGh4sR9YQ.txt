Table 1: On Atari a simple genetic algorithm is competitive with Q-learning (DQN), policygradients (A3C), and evolution strategies (ES). Shown are game scores (higher is better). Com-paring performance between algorithms is inherently challenging (see main text), but we attemptto facilitate comparisons by showing estimates for the amount of computation (operations, the sumof forward and backward neural network passes), data efficiency (the number of game frames fromtraining episodes), and how long in wall-clock time the algorithm takes to run. The ES, DQN, A3C,and GA (1B) perform best on 3, 3, 4, and 3 games, respectively. Thus, overall, each algorithm is beston a different subset of games, and all are in that sense competitive alternatives. The GA producedstate-of-the-art results on Skiing. In a much larger set of games, these results qualitatively holdand, surprisingly, the GA can sometimes even outperform highly-sophisticated algorithms producedafter years of intense research into improving DQN, such as Rainbow and Ape-X (SI Sec. 7.8). In-terestingly, random search often finds policies superior to those of DQN, A3C, and ES (see text fordiscussion). Note the dramatic differences in the speeds of the algorithm, which are much faster forthe GA and ES, and data efficiency, which favors DQN. The scores for DQN are from Hessel et al.
Table 2: Hyperparameters. PoPulation sizes are incremented to account for elites (+1). Many ofthe unusual numbers were found via Preliminary hyPerParameter searches in other domains.
Table 3: The number of generations at which the GA reached 6B frames.
Table 4: Head-to-head comparison between algorithms on the 13 Atari games. Each valuerepresents how many games for which the algorithm listed at the top of a column produces a higherscore than the algorithm listed to the left of that row (e.g. GA 6B beats DQN on 7 games).
Table 5: Extended Atari results. For SOTA counts, we include ties as a point in that column (e.g.
Table 6: Head-to-head comparison between algorithms on Atari games. Values represent thenumber of wins, losses, and ties between algorithms (e.g. vs. DQN, the GA wins on 22 games, loseson 29, and ties on 1. As discussed in the main text, apples-to-apples comparisons are difficult tomake, as different algorithms exhibit different tradeoffs in computation, wall-clock speed, and dataefficiency.
