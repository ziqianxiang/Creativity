Table 1: A comparison of different code settings on IWSLT14 De-En and ASPEC Ja-En datset. Foreach code setting, we report the accuracy of recovering the structural tag sequence using the codes(tag accuracy), and the accuracy of predicting the codes using the source sentence (code accuracy).
Table 2: Performance evaluation for NMT models trained with different approaches. The BLEUscores are reported for various beam sizes (BS).
Table 3: Evaluation of discrepancy scores (DP) for the baseline model and the discrete planningapproach. We also report the discrepancy scores of the part-of-speech tags of candidates (POS-DP).
Table 4: A comparison of translation candidates produced by beam search (BS) and discrete plan-ning (PL) in IWSLT14 De-En and ASPEC Ja-En taskdiscrepancy metric. Suppose Y is a list of candidate translations, we compute the discrepancy withDP(Y)1|Y l(∣Y∣- 1)1 - ∆(y, y0),y∈Y y0 ∈Y,y0 6=y(11)where ∆(y, y0) computes the BLEU score of two candidates. The equation computes the meanvalue of 1 - BLEU between all candidate pairs. We get a high discrepancy score when all candidatesare very different from each other. As Eq. 11 evaluates for one data point, we further average thediscrepancy scores over the test dataset.
Table 5: Constraining structures of translations with condition sentencesplanning have drastically different structures. We can observe the diversity more significantly inJapanese-English task because the word order of translations is less relevant to source sentences inthis task. We can also notice that as a result of learning from structural tags, the discrete codescontrol the sentence structure rather than the choice of word.
