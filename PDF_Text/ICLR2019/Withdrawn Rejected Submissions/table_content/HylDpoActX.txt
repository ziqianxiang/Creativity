Table 1: Different non-uniform n-ary weight representationsNotation	Representation	Bit width (dense)	Bit width (sparse)Binary	{α-0, α+0}	1	—Ternary	{α-1,0,α+1}	2	1Quaternary	{α-1,α-0,α+0,α+1} {α-1, 0, α+1, α+2}	2	—Quaternary+		2	2Quaternary-	{α-2, α-1, 0, α+1}	2	2Quinary	{α-2, α-1, 0, α+1, α+2}	3	2Binary and ternary representations gained a lot of interest lately due to their high compression ratiosand, in view of their low expressiveness, relatively good prediction performance. On large-scaleclassification tasks, however, only ternary weights demonstrate a prediction accuracy similar to full-precision weights. Furthermore, for ternary representations weight pruning is possible with littleimpact on prediction accuracy which additionally reduces the computational complexity of infer-ence. In this work, we also explore other n-ary weight representations that facilitate compressionlevels similar to ternary weights while significantly improving model capacity. For instance, qua-ternary weights can also be encoded with only two bits, but introduce either an additional positive(quaternary+) or negative (quaternary-) scaling factor, respectively. Quinary weights extend ternaryweights by one positive and one negative value, but are still encoded with only two bits in a sparseformat. In a sparse format, only the indices of non-zero weight entries are stored such that two bitsare sufficient to represent the non-zero values.
Table 2: Validation accuracy (Top1,Top5), increase in training time and sparsity (fraction of zeroweights) for different weight representation of ResNet18 and Inception-BN on ImageNet.
Table 3: Validation accuracy (Top1,Top5) and increase in training time for different activation bit-width of ResNet-18 on ImageNet.
Table 4: Validation accuracy (Top1, Top5) of ResNet18 and Inception-BN on ImageNet for 2-bitweights.
Table 5: Validation accuracy (Top1,Top5) using quinary weights of nested-means clustering andquantile-clustering for several quantiles for ResNet18 on ImageNet.
Table 6: Parameter requirements of n-ary weight representations on ResNet18 on ImageNet.
Table 7: Computational requirements of n-ary weight representations and fixed-point activationson a convolution layer with input-shape = (128 channels, 28 rows, 28 cols) and filter-shape = (128filters, 128 channels, 3 rows, 3 cols).
Table 8: Comparison to related work (bold is ours) on the validation accuracy (Top1, Top5), increasein training time and sparsity of ResNet18 and Inception-BN on ImageNet.
