Table 1: Comparison of model computation and size reduction.
Table 2: Computation reduction of mod-els on PTB data and test perplexity values.
Table 3: Different choices of coefficients vs test per-plexities for student model with 10x computation re-duction on the PTB dataset.
Table 4: Comparision of computation reduction between AntMan and ISS for BiDAFii)	LowRank-LGP 1 (gim = 10, ghm = 5, rim = 4, rhm = 2), and iii) LowRank-LGP 2 (gim =5, ghm = 5, rim = 8, rhm = 4). Here, gim and ghm refers to the number of groups, and rim andrhm refers to the low-rank reduction factors for input and hidden MVs of the LSTMs, respectively.
Table 5: Measured speedup on CPU usingLGP-Shuffle and LowRank-LGP compared tothe theoretical speedup for various input andhidden dimension. For LGP-Shuffle, we useg = 2 and g = 10 to get a theoretical speedupof 2x and 10x. For LowRank-LGP, we useg = 2 and r = 2, and g = 10, and r = 2to get a speedup of 2.66x and 8x, respectively.
Table 6: Computation reduction of models on AntManPTB data and test perplexity values.
Table 7: Theoretical vs Actual PerformanceAppendixA.	Choice of BaselineWe considered several compression techniques to identify strong baselines to compare with AntMan.
Table 8: Comparison of computation reduction between AntMan and ISS for BiDAF without Knowl-edge DistillationHere, we compare the performance of AntMan with ISS, without using any knowledge distillation.
