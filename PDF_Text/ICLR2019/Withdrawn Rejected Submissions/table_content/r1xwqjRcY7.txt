Table 1: Evaluation of different models on the MNIST test datasetModel	Reconstruction Error	Annotation Accuracy (%)	Generation Accuracy (%)CVAE	79.8	N/A	97.6 ± 0.1JMVAE	87.7	95.4	92.2 ± 0.3TrELBO	83.1	90.3	61.1 ± 0.5PSE (10D)	82.8	96.0	93.9 ± 0.2PSE* (10D)	82.3	96.3	94.9 ± 0.2PSE* (20D)	75.0	97.1	95.6 ± 0.2From Table 1, we can see that the standard CVAE has achieved the lowest reconstruction error and thehighest generation accuracy compared with other models with 10-dimensional latent space1. However,CVAE can not perform image annotation as it does not have the ability to learn label distributionsin the same space as the visual distributions. We see that the TrELBO has a better reconstructionperformance compared with the JMVAE, while it leads to less correct generated samples. Whenλ1 = 1 in the TrELBO, the conditional generation accuracy is the lowest (61.0 ± 0.5), this trendis similar to that found by Vedantam et al. (2018). Figure 3 shows samples generated by (a) theTrELBO and (b) the PSE* model.
Table 2: Evaluation of different models on the Fashion-MNIST test dataset.
Table 3: Performance using one-hot vectors and word2vec vectors on the testing dataset of Fashion-MNIST with the PSE and the PSE* modelsLabel Encoding Schemes	Reconstruction Error	Annotation Accuracy (%)one-hot(PSE)	219.1	81.2 ± 0.1word2vec(PSE)	218.7	81.4 ± 0.2one-hot(PSE*)	219.6	81.3 ± 0.2word2vec(PSE*)	218.8	81.9 ± 0.3further demonstrated in Figure 6f (“Jeans”), whose word2vec nearest neighbours include a variety ofclothing items and the general term “Clothing”.
