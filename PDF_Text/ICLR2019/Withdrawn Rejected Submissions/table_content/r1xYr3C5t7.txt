Table 1: Model Complexities. S represents the input sequence length, ρ represents the number of positivelabels, L represents total number of labels, and d is the size of the model’s hidden state.
Table 2: Results. Across all 7 datasets, MPED produces similar or better average metric scores to baselinemodels. MPED results in a mean of 1.7x and 5.0x training and testing speedups, respectively, over the previousstate-of-the-art probabilistic MLC method, RNN Seq2Seq. Speedups over RNN Seq2Seq model are shown inminutes per epoch in parentheses for the MPED model. Bold numbers show the best performing method(s).
Table 3: Dataset StatisticsMetric	Significance	ACC	RNNSeq2Seq A {MPEDEdgeless Gdec,BR} MPED Autoregressive A {MPED Edgeless Gdec ,BR}	HA	None	ebF1	MPED A	{BR, RNN Seq2Seq}miF1 -	MPED A	{RNNSeq2Seq}maF1	MPED A	{RNNSeq2Seq}Table 4: MLC Model Significance Using the Nemenyi Test (Read et al., 2009; Demsar, 2006)5.1	DatasetsWe test our method against baseline methods on seven different multi-label sequence classification datasets.
Table 4: MLC Model Significance Using the Nemenyi Test (Read et al., 2009; Demsar, 2006)5.1	DatasetsWe test our method against baseline methods on seven different multi-label sequence classification datasets.
