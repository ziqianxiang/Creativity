Table 1: DeepCS outperforms pseudo-counts (PC), Q-learning (DQN), and policy gradients(A3C) on five Atari games (shown at top of table) including Montezuma’s Revenge (MR) andoutperforms Ape-X and Rainbow (R) on MR. Approximate results (〜)were taken from trainingcurves where no tabular results were available. DeepCS remains competitive with follow-up work onpseudo-counts (PCn). Median scores are shown here for DeepCS; the best-performing runs producedmuch higher scores including 6600 points on MR, 2600 points on Amidar, and 80,000 points onSeaquest (SI Fig. S4).
