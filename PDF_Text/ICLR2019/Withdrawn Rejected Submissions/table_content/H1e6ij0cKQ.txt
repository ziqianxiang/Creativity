Table 1: Average entity-level F1-score for English & German NER on the CoNLL-2003 datasets.
Table 2: Average top-1 accuracy, and the required GPU memory and execution time (one epoch) onEnglish CCG supertagging. The results are achieved with CRF training.
Table 3: The word-level transliteration accuracy on the development sets of NEWS-2018 sharedtask. SC: Self-Critical trainingModel	Dev	TestRNN	76.85 ±0.39	73.52 ±0.36SS-RNN	76.93 ±0.32	73.65 ±0.29SC-RNN	76.71 ±0.27	73.50 ±0.42AC-RNN	77.10 ±0.29	73.82 ±0.29Table 4: The adjusted actor-critic training compared to Scheduled Sampling (SS-RNN), and Self-Critical training (SC-RNN) on German NER.
Table 4: The adjusted actor-critic training compared to Scheduled Sampling (SS-RNN), and Self-Critical training (SC-RNN) on German NER.
Table 5: The hyper-parameters used in the experiments.
