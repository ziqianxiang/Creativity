Table 1: F1 score of NER on CoNLL 2003 and Chunking on CoNLL 2000. “Baseline” = Two layerbidirectional GRU recognizer without any representation learning loss.
Table 2: TIMIT phonetic error rates (%).
Table 3: WSJ character error rates (%). “Baseline”= CTC recognizer without any representation learn-ing loss. “#lab./unlab.” refers to the number of la-beled/unlabeled utterances used for training.
Table 4: XRMB phonetic error rates (%) with multi-view representation learning models.
