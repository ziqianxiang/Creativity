Table 1: Architectures used for the MNIST and Fashion MNIST experiments - 1Standard CNN	GCNN	Conv(10,3,3) + Relu	P4ConvZ2(10,3,3) + ReluConv(10,3,3) + Relu	P4ConvP4(10,3,3) + ReluMax Pooling(2,2)	Group Spatial Max Pooling(2,2)Conv(20,3,3) + Relu	P4ConvP4(20,3,3) + ReluConv(20,3,3) + Relu	P4ConvP4(20,3,3) + ReluMax Pooling(2,2)	Group Spatial Max Pooling(2,2)FC(50) + Relu	FC(50) + ReluDropout(0.5)	Dropout(0.5)FC(10) + Softmax	FC(10) + Softmax3http://www.iro.umontreal.ca/ lisa/twiki/bin/view.cgi/Public/MnistVariations4https://github.com/zalandoresearch/fashion-mnist5https://www.cs.toronto.edu/ kriz/cifar.html8Under review as a conference paper at ICLR 20194	ConclusionWe observe that the robustness to geometric transformations in equivariant networks comes at thecost of their robustness to pixel-wise adversarial perturbations. We do an extensive comparativestudy of various equivariant network models ranging from StdCNNs to GCNNs, HNets, PTNs,
Table 2: Architectures used for the MNIST and Fashion MNIST experiments - 2Standard CNNGCNNConv(20,3,3) + ReluConv(20,3,3) + ReluMax Pooling(2,2)Conv(40,3,3) + ReluConv(40,3,3) + ReluMax Pooling(2,2)FC(50) + ReluDropout(0.5)FC(10) + SoftmaxP4ConvZ2(5,3,3) + ReluP4ConvP4(5,3,3) + ReluGroup Spatial Max Pooling(2,2)P4ConvP4(10,3,3) + ReluP4ConvP4(10,3,3) + ReluGroup Spatial Max Pooling(2,2)FC(50) + ReluDropout(0.5)
