Table 1: Classification results on digit datasets. M: MNIST; MM: MNIST-M, S: SVHN, U: USPS. The best is shownin red. c-X: combining all target domains into a single one and train it using X. s-MTDA-ITA: training multiple MTDA-ITA where each one correspond to a source-target pair. 1p-DSN: extended DSN with single private encoder.mp-DSN:extended DSN with multiple private encoder. Last column shows the average rank of each method over all adaptationpairs.*UNIT trains with the extended SVHN (> 500K images vs ours 72K). *PixelDA uses (≈ 1, 000) of labeled targetdomain data as a validation set for tuning the hyper-parameters.
Table 2: Classification results on Multi-PIE dataset. Last column shows the average rank of each method over alladaptation pairs. The best is shown in red.
Table 3: Network architecture for the experiments.
Table 4: Classification results on digit datasets. M: MNIST; MM: MNIST-M, S: SVHN, U: USPS. The best is shown inred. c-X: combining all target domains into a single one and train it using X. s-MTDA-ITA: training multiple MTDA-ITAwhere each one correspond to a source-target pair. mp-DSN: extended DSN with multiple private encoder. *UNIT trainswith the extended SVHN (> 500K images vs ours 72K). *PixelDA uses (≈ 1, 000) of labeled target domain data as avalidation set for tuning the hyper-parameters.
Table 5: Classification results on Multi-PIE dataset. The best is shown in red.
Table 6: Classification results on Multi-PIE dataset. The best (red).
Table 7: Classification results on PACS dataset classification. A:Art-painting, C:Cartoon, S:Sketch, P:Photo. The best(red).
