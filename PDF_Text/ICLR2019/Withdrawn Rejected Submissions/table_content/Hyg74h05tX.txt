Table 1: Unconditional image modeling resultsModel family	Model	CIFAR10 bits/dim	ImageNet 32x32 bits/dim	ImageNet 64x64 bits/dimNon-autoregressive	RealNVP (Dinh et al., 2016)	3.49	4.28	—	Glow (Kingma & DhariWaL 2018)	3.35	4.09	3.81	IAF-VAE (Kingma et al., 2016)	3.11	一	—	Flow++ (ours)	3.09	3.86	3.69Autoregressive	MultisCale PixelCNN (Reed et al., 2017)	一	3.95	3.70	PixelCNN (van den Oord et al., 2016b)	3.14	一	—	PixelRNN (van den Oord et al., 2016b)	3.00	3.86	3.63	Gated PixelCNN (van den Oord et al., 2016c)	3.03	3.83	3.57	PixelCNN++ (Salimans et al., 2017)	2.92	一	—	Image Transformer (Parmar et al., 2018)	2.90	3.77	—	PixelSNAIL (Chen et al., 2017)	2.85	3.80	3.524.2	AblationsWe ran the following ablations of our model on unconditional CIFAR10 density estimation: varia-tional dequantization vs. uniform dequantization; logistic mixture coupling vs. affine coupling; andstacked self-attention vs. convolutions only. As each ablation involves removing some componentof the network, we increased the number of filters in all convolutional layers (and attention layers,if present) in order to match the total number of parameters with the full Flow++ model.
Table 2: CIFAR10 ablation results after 400 epochs of training. Models not converged for thepurposes of ablation study.
