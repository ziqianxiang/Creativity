Table 1: Comparison of mean absolute error of previous approaches (left) and our network (right)in kCal/mol.(Gilmer et al., 2017)Target	BAML	BOB	CM	ECFP4	HDAD	GC	GG-NN	DTNN	enn-s2s	PCnetU0	1.21	1.43	2.98	85.01	0.58	3.02	0.83	0.841	0.45	0.53gap	3.28	3.41	5.32	3.86	2.49	1.78	1.70	N/A	1.60	2.13HOMO	2.20	2.20	3.09	2.89	1.54	1.18	1.17	N/A	0.99	1.44LUMO	2.76	2.74	4.26	3.10	1.96	1.10	1.08	N/A	0.87	1.263.3	resultIn Table 1 we compare the performance of PCnet and the previous approaches. These baselinesinclude 5 different hand engineered molecular representations, which then get fed through a stan-dard, off-the-shelf classifier. These input representations include the Coulomb Matrix (CM, Neese(2003)), BoB, Bonds Angles, Machine Learning (BAML, Huang & von Lilienfeld (2016)), ExtendedConnectivity Fingerprints (ECPF4, Rogers & Hahn (2010)), and “Projected Histograms” (HDAD,Faber et al. (2017a)) representations. In addition to these hand engineered features we include theMolecular Graph Convolutions model (GC, Kearnes et al. (2016)), the original GG-NN model(Liet al., 2015) trained with distance bins, DTNN and enn-s2s from Message Passing Neural Networks(MPNNs, Gilmer et al. (2017)).
