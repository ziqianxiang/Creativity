title,year,conference
 Compositional morphology for word representations and languagemodelling,2014, In International Conference on Machine Learning
 A theoretically grounded application of dropout in recurrentneural networks,2016, In Advances in neural information processing systems
 Improving neural language models with acontinuous cache,2016, arXiv preprint arXiv:1612
 Long short-term memory,1997, Neural computation
 Fine-tuned language models for text classification,2018, CoRR
 Tying word vectors and word classifiers: Aloss framework for language modeling,2016, arXiv preprint arXiv:1611
 ExPloring thelimits of language modeling,2016, arXiv preprint arXiv:1602
 Character-aware neural languagemodels,2016, In AAAI
 ImProved backing-off for m-gram language modeling,1995, Inicassp
 Statistical machine translation,2009, Cambridge University Press
 Dynamic evaluation of neuralsequence models,2017, arXiv preprint arXiv:1709
 Building a large annotatedcorPus of english: The Penn treebank,1993, Computational linguistics
 On the state of the art of evaluation in neural languagemodels,2017, arXiv preprint arXiv:1707
 Pointer sentinel mixturemodels,2016, arXiv preprint arXiv:1609
 Regularizing and oPtimizing lstm lan-guage models,2017, arXiv preprint arXiv:1708
 Recurrentneural network based language model,2010, In Eleventh Annual Conference ofthe International SpeechCommunication Association
 Using the output embedding to improve language models,2016, arXiv preprintarXiv:1608
 Learning to generate reviews and discoveringsentiment,2017, arXiv preprint arXiv:1704
 Breaking the softmaxbottleneck: A high-rank rnn language model,2017, arXiv preprint arXiv:1711
 Automatic Speech Recognition: A Deep Learning Approach,2014, Springer
 Recurrenthighway networks,2016, arXiv preprint arXiv:1607
 Fraternal droPout,2017, arXivpreprint arXiv:1711
 Neural architecture search with reinforcement learning,2016, arXiv preprintarXiv:1611
