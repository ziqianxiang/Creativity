title,year,conference
 Structured Pruning of Deep Convolutional NeuralNetworks,1550, J
 Stronger generalization bounds fordeep nets via a compression approach,2018, In Jennifer Dy and Andreas Krause (eds
 Iterative hard thresholding for compressed sensing,2009, Appliedand computational harmonic analysis
 DeCAF: A Deep Convolutional Activation Feature for Generic Visual Recognition,2014, InInternational Conference on Machine Learning
 Explaining and Harnessing AdversarialExamples,2014, arXiv preprint arXiv:1412
 Finding structure with randomness:Probabilistic algorithms for constructing approximate matrix decompositions,2011, SIAM review
 Deep Residual Learning for ImageRecognition,2016, In 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)
 Speeding up Convolutional Neural Networkswith Low Rank Expansions,2014, In Proceedings of the British Machine Vision Conference
 Guaranteed rank minimization via singular valueprojection,2010, In Advances in Neural Information Processing Systems
 Unifying visual-semantic embeddings withmultimodal neural language models,2014, arXiv preprint arXiv:1411
 Ensemble nystrom method,2009, In Advances inNeural Information Processing Systems
 Sparse convolu-tional neural networks,2015, In Proceedings of the IEEE Conference on Computer Vision and PatternRecognition
 Very deep convolutional networks for large-scale imagerecognition,2014, arXiv preprint arXiv:1409
 Intriguing properties of neural networks,2013, arXiv preprint arXiv:1312
 Learning structured sparsity indeep neural networks,2016, In Advances in Neural Information Processing Systems
 Using the Nystrom method to speed up kernelmachines,2001, In Advances in neural information processing systems
 Visualizing and Understanding Convolutional Networks,2014, InDavid Fleet
