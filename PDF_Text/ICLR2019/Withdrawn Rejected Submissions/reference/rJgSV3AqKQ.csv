title,year,conference
 On-line learn-ing in neural networks,1998, chapter Parameter Adaptation in Stochastic Optimization
 Natural gradient works efficiently in learning,1998, Neural computation
 Optimization methods for large-scale machinelearning,2018, SIAM Review
 Adam: A method for stochastic optimization,2014, CoRR
 Topmoumoute online naturalgradient algorithm,2008, In J
 A stochastic approximation method,1951, Annals of MathematicalStatistics
 On the importance of initial-ization and momentum in deep learning,2013, In Sanjoy Dasgupta and David McAllester (eds
 Lecture 6,2012,5â€”RmsProp: Divide the gradient by a running average of itsrecent magnitude
 In I,2017, Guyon
 Adadelta: An adaptive learning rate method,2012, CoRR
