title,year,conference
 Threat of adversarial attacks on deep learning in computer vision:A survey,2018, arXiv preprint arXiv:1801
 Synthesizing robust adversarial examples,2017, arXiv preprintarXiv:1707
 Obfuscated gradients give a false sense ofsecurity: Circumventing defenses to adversarial examples,2018, arXiv preprint arXiv:1802
 Thermometer encoding: One hotway to resist adversarial examples,2018, International Conference on Learning Representations
 Towards evaluating the robustness of neural networks,2016, arXivpreprint arXiv:1608
 Stochastic activation pruning for robust adversarial de-fense,2018, arXiv preprint arXiv:1803
 Boost-ing adversarial attacks with momentum,2018, arXiv preprint
 Evaluating and understanding the robustnessof adversarial logit pairing,2018, arXiv preprint arXiv:1807
 Explaining and harnessing adversarialexamples,2014, arXiv preprint arXiv:1412
 Countering adversarialimages using input transformations,2017, arXiv preprint arXiv:1711
 Adversarial logit pairing,2018, arXiv preprintarXiv:1803
 Delving into transferable adversarial exam-ples and black-box attacks,2016, arXiv preprint arXiv:1611
 Universaladversarial perturbations,2017, arXiv preprint
 Feature detection in human vision: A phase-dependent energymodel,1988, Proc
 Importance of phase in signals,1980, Technical report
 Practical black-box attacks against machine learning,2017, In Proceedings of the 2017 ACMon Asia Conference on Computer and Communications Security
 Technical report on the cleverhans v2,2018,1
 Defense-gan: Protecting classifiers againstadversarial attacks using generative models,2018, arXiv preprint arXiv:1805
 Breaking the madry defense model with l_1-based adversarialexamples,2017, arXiv preprint arXiv:1710
 Attacking the madry defense model with l 1-based adversarialexamples,2018, In ICLR Workshop
 Pixeldefend:Leveraging generative models to understand and defend against adversarial examples,2017, arXivpreprint arXiv:1710
 Intriguing properties of neural networks,2013, arXiv preprint arXiv:1312
 Ensemble adversarial training: Attacks and defenses,2017, arXiv preprint arXiv:1705
