title,year,conference
 Linear Matrix Inequalities in System andControl Theory,1994, SIAM
 Incorporating nesterov momentum into adam,2016, In ICLR workshop
 Adaptive subgradient methods for online learning and stochasticoptimization,2011, J
 Identity mappings in deep residual networks,2016, In ECCV
 A unified analysis of stochastic optimization methods using jumpsystem theory and quadratic constraints,2017, In COLT
 Accelerating stochastic gradientdescent,2017, arXiv:1704
 On the insufficiency of existing momentumschemes for stochastic optimization,2018, In ICLR
 Adam: a method for stochastic optimization,2015, In ICLR
 Adaptivity to local smoothness and dimension in kernel regression,2013, InNIPS
 Global optimization of lipschitz functions,2017, In ICML
 A method of solving a convex programming problem with convergence rate,1983, SovietMathematics Doklady
 On the convergence of adam and beyond,2018, In ICLR
 Stochastic variance reduction for nonconvexoptimization,2016, In ICML
 Rmsprop: Divide the gradient by a running average of its recentmagnitude,2012, COURSERA: Neural Networks for Machine Learning
 Local smoothness in variance reduced optimization,2015, In NIPS
 Adadelta: An adaptive learning rate method,2012, CoRR
