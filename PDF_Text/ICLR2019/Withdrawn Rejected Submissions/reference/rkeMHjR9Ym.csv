title,year,conference
 Fast global convergence rates of gradient methodsfor high-dimensional statistical recovery,2010, In Advances in Neural Information Processing Systems
 System identification-a survey,1971, Automatica
 Neural machine translation by jointly learning toalign and translate,2014, arXiv preprint arXiv:1409
 Globally optimal gradient descent for a convnet with gaussian inputs,2017, arXivpreprint arXiv:1702
 Sgd learns over-parameterizednetworks that provably generalize on linearly separable data,2017, arXiv preprint arXiv:1710
 Tail bounds via generic chaining,2013, arXiv preprint arXiv:1309
 Finding structure in time,1990, Cognitive science
 Finite time identification inunstable linear systems,2018, Automatica
 Uniform convergence of gradients for non-convexlearning and optimization,2018, NIPS
 Speech recognition with deep recurrent neuralnetworks,2013, In Acoustics
 Gradient descent learns linear dynamical systems,2016, arXivpreprint arXiv:1609
 Long short-term memory,1997, Neural COmPUtatiOn
 Beating the perils of non-convexity: Guaranteedtraining of neural networks using tensor methods,2015, arXiv PrePrint arXiv:1506
 The concentration of measure phenomenon,2001, American Mathematical Soc
 Convergence analysis of two-layer neural networks with relu activation,2017, In Advancesin Neural Information Processing Systems
 System identification,1998, In Signal analysis and prediction
 The landscape of empirical risk for nonconvex losses,2018, The Annalsof Statistics
 A mean field view of the landscape of two-layers neuralnetworks,2018, arXiv preprint arXiv:1804
 When recurrent models don’t need to be recurrent,2018, arXiv preprintarXiv:1805
 Non-asymptotic identification of lti systems from a single trajectory,2018, arXivpreprint arXiv:1806
 End-to-end learning of a convolutional neural network via deep tensordecomposition,2018, arXiv preprint arXiv:1805
 Exact topology identification of large-scaleinterconnected dynamical systems from compressive observations,2011, In American Control Conference (ACC)
 Training input-output recurrent neural networks through spectralmethods,2016, arXiv preprint arXiv:1603
 Learning without mixing:Towards a sharp analysis of linear system identification,2018, arXiv preprint arXiv:1802
 Learning relus via gradient descent,2017, arXiv preprint arXiv:1705
 Theoretical insights into the optimization landscapeof over-parameterized shallow neural networks,2017, arXiv preprint arXiv:1707
 Non-asymptotic analysis of robust controlfrom coarse-grained identification,2017, arXiv preprint arXiv:1707
 On the approximation of toeplitz operators for nonparametrich∞-norm estimation,2018, In 2018 Annual American Control Conference (ACC)
 Introduction to the non-asymptotic analysis of random matrices,2010, arXiv preprintarXiv:1011
 Learning non-overlapping convolutional neural networks withmultiple kernels,2017, arXiv preprint arXiv:1711
 Recovery guarantees for one-hidden-layer neural networks,2017, arXiv preprint arXiv:1706
