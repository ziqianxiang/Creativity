title,year,conference
 Obfuscated gradients give a false sense of security: Cir-CUmventing defenses to adversarial examples,2018, InternationaI Conference on Machine Learning
 Estimating or propagating gradients throUgh stochasticneurons for conditional computation,2013, arXiv preprint arXiv:1308
 Decision-based adversarial attacks: Reliable attacks againstblack-box machine learning models,2017, arXiv preprint arXiv:1712
 Towards evaluating the robustness of neural networks,2016, IEEE EUrOpeanSympOSiUm on SecUrity and Privacy
 Explaining and harnessing adversarial examples,2014, arXivpreprintarXiv:1412
 Adversarial perturbationsagainst deep neural networks for malware classification,2016, arXiv preprint arXiv:1606
 A machine learning approach to visual perception offorecast trails for mobile robots,2016, IEEE Robotics and AUtOmatiOn Letters
 Black-box adversarial attacks with limited queriesand information,2018, International COnference on Machine Learning
 Adam: A method for stochastic optimization,2014, arXiv preprint arXiv:1412
 Adversarial examples in the physical world,2016, arXivpreprint arXiv:1607
 Delving into transferable adversarial examples and black-boxattacks,2016, arXiv preprint arXiv:1611
 Towards deep learning modelsresistant to adversarial attacks,2018, International COnference on Learning RepreSentations
 Universaladversarial perturbations,2017, In The IEEE COnference on COmpUter ViSiOn and Pattern RecOgnitiOn(CVPR)
 Cascade adversarial machine learning regularized with aunified embedding,2018, Intemational Conference on Learning Representations
 Sok: Towards the science of secUrity andprivacy in machien learning,2016, arXiv preprint arXiv:1611
 Distillation as a defense to adversarialperturbations against deep neural networks,2016, IEEE European Symposium on Security and Privacy
 Transferability in machine learning:from phenomena to black-box attacks using adversarial samples,2016, CoRR
 Nonlinear total variation based noise removal algorithms,1992, PhysicaD: nonlinear phenomena
 Defense-gan: Protecting classifiers against adversaialattacks using generative models,2018, International Conference on Learning Representations
 Pixeldefend: Leveraging generative mod-els to understand and defend against adversarial examples,2018, Intemational Conference on LearningRepresentations
 Intriguing propertiesof neural networks,2013, arXiv preprint arXiv:1312
 Ensemble adversarial training: Attacks and defenses,2018, In Intemational Conferenceon Learning Representations
 Deep neural nets with interpolating functionas output activation,2018, AdVances in NeUraI Information Processing Systems
 Reinforcing adversarial robustness using modelconfidence induced by adversarial training,2018, InternationaI Conference on Machine Learning
