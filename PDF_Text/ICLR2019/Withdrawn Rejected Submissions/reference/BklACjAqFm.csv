title,year,conference
 Finite-time analysis of the multiarmedbandit problem,2002, Machine learning
 Efficient Explo-ration through Bayesian Deep Q-Networks,2018, arXiv preprint arXiv:1802
 Successor features for transfer in reinforcement learning,2017, InAdvances in neural information processing systems (NIPS)
 Unifying count-based exploration and intrinsic motivation,2016, In Advances in NeuralInformation Processing Systems (NIPS)
 Improving generalization for temporal difference learning: The successorrepresentation,1993, Neural Computation
 Uncertainty in deep learning,2016, University of Cambridge
 Deep suc-cessor reinforcement learning,2016, arXiv preprint arXiv:1606
 Shallowupdates for deep reinforcement learning,2017, In Advances in Neural Information ProcessingSystems (NIPS)
 Count-based exploration withthe successor representation,2018, arXiv preprint arXiv:1807
 Efficient exploration withdouble uncertain value networks,2017, arXiv preprint arXiv:1711
 The UncertaintyBellman Equation and Exploration,2018, In International Conference on Machine Learning(ICML)
 Generalization and exploration via ran-domized value functions,2014, arXiv preprint arXiv:1402
 Count-basedexploration with neural density models,2017, arXiv preprint arXiv:1703
 Deep Bayesian Bandits Showdown:An Empirical Comparison of Bayesian Deep Networks for Thompson Sampling,2018, arXivpreprint arXiv:1802
 On the likelihood that one unknown probability exceeds another inview of the evidence of two samples,1933, Biometrika
 Deep reinforcement learning with doubleq-learning,2016, 2016
