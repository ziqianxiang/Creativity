title,year,conference
 Stochastic optimization,1968, In EngineeringCybernetics
 The option-critic architecture,2017, In AAAI
 Active learning of inverse models with intrinsically mo-tivated goal exploration in robots,2013, Robotics and Autonomous Systems
 Successor features for transfer in reinforcement learning,2017, In NIPS
 Intrinsically motivated learning ofhierarchical collections of skills,2004, In Development and Learning
 Natural Actor-CriticAlgorithms,2009, Automatica
 Improving generalization for temporal difference learning: The successor representa-tion,1993, Neural Computation
 Feudal reinforcement learning,1993, In NIPS
 Hierarchical reinforcement learning with the maxq value function decompo-sition,2000, J
 Decoupled neural interfaces using synthetic gradients,2016, 2016
 Reinforcement learning with unsupervised auxiliary tasks,2017, InICLR
 Actor-critic algorithms,2000, In NIPS
 Hierarchicaldeep reinforcement learning: Integrating temporal abstraction and intrinsic motivation,2016, In NIPS
 Multi-timescale nexting in a reinforcementlearning robot,2014, Adaptive Behavior
 Temporal abstraction in reinforcement learning,2000, PhD thesis
 Some Problems in Monte Carlo Optimization,1969, Ph
 Better Generalization with Forecasts,2013, In IJCAI
 Trust regionpolicy optimization,2015, In ICML
 Introduction to Reinforcement Learning,0262, MIT Press
 Temporal-difference networks,2005, In NIPS
 Policy gradient methodsfor reinforcement learning with fUnction approximation,1999, In NIPS
 Horde: A scalable real-time architectUre for learning knowledge from UnsU-pervised sensorimotor interaction,2011, In AAMAS
 Temporal Credit Assignment in Reinforcement Learning,1984, PhD thesis
 Developing a predictive approach to knowledge,2015, PhD thesis
 Simple statistical gradient-following algorithms for connectionist reinforcementlearning,1992, Machine Learning
