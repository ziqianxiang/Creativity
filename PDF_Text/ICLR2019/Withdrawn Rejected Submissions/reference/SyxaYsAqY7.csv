title,year,conference
 Synthesizing robust adversarial examples,2017, arXiv preprintarXiv:1707
 Obfuscated gradients give a false sense ofsecurity: Circumventing defenses to adversarial examples,2018, arXiv preprint arXiv:1802
 Learning with pseudo-ensembles,2014, In Advancesin Neural Information Processing Systems
" Magnet and"" efficient defenses against adversarial attacks"" arenot robust to adversarial examples",2017, arXiv preprint arXiv:1711
 Towards evaluating the robustness of neural networks,2017, InSecurity and Privacy (SP)
 Eigenvalue computation in the 20th century,2001, In Numericalanalysis: Historical developments in the 20th century
 Explaining and harnessing adversarialexamples,2014, arXiv preprint arXiv:1412
 Deep residual learning for imagerecognition,2016, In Proceedings of the IEEE conference on computer vision and pattern recognition
 Identity mappings in deep residualnetworks,2016, In European conference on computer vision
 Provable defenses against adversarial examples via the convex outeradversarial polytope,2017, arXiv preprint arXiv:1711
 Imagenet classification with deep convolu-tional neural networks,2012, In Advances in neural information processing systems
 Adversarial machine learning at scale,2016, arXivpreprint arXiv:1611
 Magnet: a two-pronged defense against adversarial examples,2017, InProceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security
 Virtual adversarial training: a reg-ularization method for supervised and semi-supervised learning,2017, arXiv preprint arXiv:1704
 Deepfool: a simple andaccurate method to fool deep neural networks,2016, In Proceedings of the IEEE Conference on ComputerVision and Pattern Recognition
 Distillation as adefense to adversarial perturbations against deep neural networks,2016, In Security and Privacy (SP)
 Certified defenses against adversarialexamples,2018, arXiv preprint arXiv:1801
 Robust perception throughanalysis by synthesis,2018, arXiv preprint arXiv:1805
 Breaking the madry defense model with l_1-based adversarialexamples,2017, arXiv preprint arXiv:1710
 Certifiable distributional robustness withprincipled adversarial training,2017, arXiv preprint arXiv:1710
 Intriguing properties of neural networks,2013, arXiv preprint arXiv:1312
 Ensemble adversarial training: Attacks and defenses,2017, arXiv preprint arXiv:1705
 Renyi divergence and kullback-leibler divergence,2014, IEEETransactions on Information Theory
 Wide residual networks,2016, arXiv preprint arXiv:1605
 Improving the robustness of deepneural networks via stability training,2016, In Proceedings of the IEEE Conference on Computer Visionand Pattern Recognition
