title,year,conference
 Evasion attacks against machine learning at test time,2013, In Joint EuropeanConference on Machine Learning and Knowledge Discovery in Databases
 Mitigating evasion attacks to deep neural networks viaregion-based classification,2017, arXiv preprint arXiv:1709
 Towards evaluating the robustness of neural networks,2017, In IEEESymposium on Security and Privacy
 Towards evaluating the robustness of neural networks,2017, InSecurity and Privacy (SP)
 Multi-column deep neural networks for imageclassification,2012, In Computer vision and pattern recognition (CVPR)
 Hotflip: White-box adversarial examplesfor nlp,2017, arXiv preprint arXiv:1712
 Robust physical-world attacks on machine learning models,2017, arXivpreprint arXiv:1707
 Detecting adversarialsamples from artifacts,2017, arXiv preprint arXiv:1703
 A capacity scaling law for artificial neural networks,2017, arXivpreprint arXiv:1708
 The helmholtz method: Using perceptualcompression to reduce machine learning complexity,2018, arXiv preprint arXiv:1807
 Adversarial spheres,2018, arXiv preprint arXiv:1801
 Explaining and harnessing adversarialexamples,2015, In International Conference on Learning Representations
 Adversarial attackson neural network policies,2017, arXiv preprint arXiv:1702
 Order-optimal estimation of functionals of discretedistributions,2014, CoRR
 Measuring robustness of classifiers to geometric transformations,2017, Technical report
 Delving into adversarial attacks on deep policies,2017, arXiv preprintarXiv:1705
 Compression and Analysis of Molecular Dynamics Data,2018, University of California
 Delving into transferable adversarial examplesand black-box attacks,2017, In ICLR
 Feature distillation: Dnn-oriented jpegcompression against adversarial examples,2018, arXiv preprint arXiv:1803
 Characterizing adversarial subspaces using localintrinsic dimensionality,2018, arXiv preprint arXiv:1801
 Distributionalsmoothing with virtual adversarial training,2015, stat
 Deepfool: a simple andaccurate method to fool deep neural networks,2015, arXiv preprint arXiv:1511
 Universaladversarial perturbations,2016, arXiv preprint arXiv:1610
 Fast feature fool: A data independentapproach to universal adversarial perturbations,2017, arXiv preprint arXiv:1707
 Transferability in machine learning: fromphenomena to black-box attacks using adversarial samples,2016, arXiv preprint arXiv:1605
 Deep reinforcementlearning framework for autonomous driving,2017, Electronic Imaging
 Intriguing properties of neural networks,2014, In International Conference on LearningRepresentations
 The space oftransferable adversarial examples,2017, arXiv preprint arXiv:1704
