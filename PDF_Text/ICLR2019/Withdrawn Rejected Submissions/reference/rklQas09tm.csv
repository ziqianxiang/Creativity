title,year,conference
 A causal framework for explaining the predictions ofblack-box sequence-to-sequence models,2017, In Proceedings of the 2017 Conference on EmpiricalMethods in Natural Language Processing
 Towards robust interpretability with self-explainingneural networks,2018, arXiv preprint arXiv:1806
 Neural module networks,2016, InProceedings of the IEEE Conference on Computer Vision and Pattern Recognition
 Neural machine translation by jointlylearning to align and translate,2014, arXiv preprint arXiv:1409
 Network dissection:Quantifying interpretability of deep visual representations,2017, arXiv preprint arXiv:1704
 A large anno-tated corpus for learning natural language inference,2015, arXiv preprint arXiv:1508
 Learning to explain: Aninformation-theoretic perspective on model interpretation,2018, arXiv preprint arXiv:1802
 Enhancing and combining sequen-tial and tree lstm for natural language inference,2016, arXiv preprint arXiv:1609
 Enhanced lstm fornatural language inference,2016, arXiv preprint arXiv:1609
 Latent alignment andvariational attention,2018, arXiv preprint arXiv:1807
 Sparse overcompleteword vector representations,2015, arXiv preprint arXiv:1506
 Long short-term memory,1997, Neural computation
 Categorical reparameterization with gumbel-softmax,2016, arXivpreprint arXiv:1611
 Adam: A method for stochastic optimization,2014, arXiv preprintarXiv:1412
 Understanding black-box predictions via influence functions,2017, arXivpreprint arXiv:1703
 Game-theoretic interpretability fortemporal modeling,2018, arXiv preprint arXiv:1807
 Rationalizing neural predictions,2016, In Proceedings ofthe 2016 Conference on Empirical Methods in Natural Language Processing
 Visualizing and understanding neural modelsin nlp,2015, arXiv preprint arXiv:1506
 Understanding neural networks through representationerasure,2016, arXiv preprint arXiv:1612
 A unified approach to interpreting model predictions,2017, In Advancesin Neural Information Processing Systems
 Effective approaches to attention-based neural machine translation,2015, arXiv preprint arXiv:1508
 A decomposable attentionmodel for natural language inference,2016, arXiv preprint arXiv:1606
 Glove: Global vectors for wordrepresentation,2014, In Proceedings of the 2014 conference on empirical methods in natural languageprocessing (EMNLP)
 Why should i trust you?: Explaining thepredictions of any classifier,2016, In Proceedings of the 22nd ACM SIGKDD international conferenceon knowledge discovery and data mining
 A neural attention model for abstractivesentence summarization,2015, arXiv preprint arXiv:1509
 Grad-cam: Visual explanations from deep networks via gradient-based local-ization,2017, In ICCV
 Bidirectional attentionflow for machine comprehension,2016, arXiv preprint arXiv:1611
 Pointer networks,2015, In Advances in NeuralInformation Processing Systems
 Learning natural language inference with LSTM,2016, In Proceedings ofthe Conference on the North American Chapter of the Association for Computational Linguistics
 Sentence similarity learning by lexical decom-position and composition,2016, arXiv preprint arXiv:1602
 Bilateral multi-perspective matching for naturallanguage sentences,2017, arXiv preprint arXiv:1702
 Simple statistical gradient-following algorithms for connectionist reinforcementlearning,1992, Machine Learning
 Textual entailment with structured attentions and compo-sition,2017, arXiv preprint arXiv:1701
