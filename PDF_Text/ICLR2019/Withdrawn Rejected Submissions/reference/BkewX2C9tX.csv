title,year,conference
 How tobackdoor federated learning,2018, arXiv preprint arXiv:1807
 Machine learning withadversaries: Byzantine tolerant gradient descent,2017, Advances in Neural Information ProcessingSystems
 Targeted backdoor attacks on deeplearning systems using data poisoning,2017, arXiv preprint arXiv:1712
 Distributed statistical machine learning in adversarial set-tings: Byzantine gradient descent,2017, Proc
 Ma-nipulating machine learning: Poisoning attacks and countermeasures for regression learning,2018, InIEEE Security and Privacy
 Adam: A method for stochastic optimization,2015, In InternationalConference on Learning Representations
 Understanding black-box predictions via influence functions,2017, InICML
 Gradient-based learning applied todocument recognition,1998, Proceedings of the IEEE
 Using machine teaching to identify optimal training-set attacks onmachine learners,2015, In AAAI
 The hidden vulnerability of dis-tributed learning in byzantium,2018, In ICML
 Stealthy poisoning attacks on pca-based anomaly detectors,2009, ACMSIGMETRICS Performance Evaluation Review
 Deep inside convolutional networks: Vi-sualising image classification models and saliency maps,2013, arXiv preprint arXiv:1312
 Smooth-grad: removing noise by adding noise,2017, arXiv preprint arXiv:1706
 Strivingfor simplicity: The all convolutional net,2014, arXiv preprint arXiv:1412
 Axiomatic attribution for deep networks,2017, arXivpreprint arXiv:1703
 Fashion-mnist: a novel image dataset for benchmark-ing machine learning algorithms,2017, arXiv preprint arXiv:1708
 Byzantine-robust distributedlearning: Towards optimal statistical rates,2018, arXiv preprint arXiv:1803
 Visualizing and understanding convolutional networks,2014, InComputer Vision
