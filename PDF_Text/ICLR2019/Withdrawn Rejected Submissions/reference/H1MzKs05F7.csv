title,year,conference
 Neural taylor approximations: Convergence andexploration in rectifier networks,2017, In ICML
 Training with noise is equivalent to Tikhonov regularization,1995, Neural computation
 Parseval networks:Improving robustness to adversarial examples,2017, In ICML
 Robustness of classifiers: Fromadversarial to random noise,2016, In NIPS
 Adversarial spheres,2018, In ICLR Workshop
 Explaining and harnessing adversarial examples,2015, InICLR
 Delving deep into rectifiers: Surpassing human-levelperformance on imagenet classification,2015, In ICCV
 Formal guarantees on the robustness of a classifier againstadversarial manipulation,2017, In NIPS
 Simplifying neural nets by discovering flat minima,1995, In NIPS
 Statistics of Natural Images and Models,2000, PhD thesis
 Learning multiple layers of features from tiny images,2009, Technical report
 A unified gradient regularization family for adversarialexamples,2015, In ICDM
 Towards deeplearning models resistant to adversarial attacks,2018, In ICLR
 DeepFool: A simple and accuratemethod to fool deep neural networks,2016, In CVPR
 Auto-encoders: Reconstruction versus compression,2014, arXiv:1403
 Foolbox v0,2017,8
 Contractive auto-encoders:Explicit invariance during feature extraction,2011, In ICML
 Improving the adversarial robustness and interpretability of deepneural networks by regularizing their input gradients,2018, In AAAI
 Adversariallyrobust generalization requires more data,2018, arXiv:1804
 Certifiable distributional robustness with principledadversarial training,2018, In ICLR
 Statistical decision functions which minimize the maximum risk,1945, Annals of Mathematics
 Adversarial examples: Attacks anddefenses for deep learning,2017, arXiv:1712
 Supposethat x is a natural image and that decreasing its dimension means either decreasing its resolution orcropping it,2000, Because the statistics of natural images are approximately resolution and scale invariant(Huang
