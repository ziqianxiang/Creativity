title,year,conference
 Ensemble learning for multi-layer networks,1998, In NIPS
 Dropout as a bayesian approximation: Representing modeluncertainty in deep learning,2016, In ICML
 Practical variational inference for neural networks,2011, In NIPS
 On calibration of modern neuralnetworks,2017, In ICML
 Deep residual learning for image recog-nition,2016, In CVPR
 Stochastic variational in-ference,1532, J
 Deep networks withstochastic depth,2016, In ECCV
 Batch normalization: Accelerating deep network training byreducing internal covariate shift,2015, In ICML
 Simple and scalable predictiveuncertainty estimation using deep ensembles,2017, In NIPS
 Training confidence-calibrated classifiersfor detecting out-of-distribution samples,2018, In ICLR
 A practical bayesian framework for backpropagation networks,0899, NeuralComput
 Representation of uncertainty in deep neural networksthrough sampling,2016, CoRR
 Predicting good probabilities with supervised learn-ing,2005, In ICML
 Regularizingneural networks by penalizing confident output distributions,2017, arXiv preprint arXiv:1701
 Probabilistic outputs for support vector machines and comparisons to regularized likeli-hood methods,2000, 10
 Very deep convolutional netWorks for large-scale imagerecognition,2015, In ICLR
 Re-thinking the inception architecture for computer vision,2016, CVPR
 Bayesian uncertainty estimation for batch nor-malized deep networks,2018, arXiv preprint arXiv:1802
 Regularization of neuralnetworks using dropconnect,2013, In ICML
 Obtaining calibrated probability estimates from decision treesand naive bayesian classifiers,2001, In ICML
 Transforming classifier scores into accurate multiclass proba-bility estimates,2002, In KDD
