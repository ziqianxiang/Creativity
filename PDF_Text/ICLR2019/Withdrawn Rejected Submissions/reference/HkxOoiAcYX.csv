title,year,conference
 Estimating mutual information,2004, Phys
 Estimating differential entropy under Gaussian convolutions,2018, Submitted to IEEETransactions on Information Theory
 Parseval networks: Improvingrobustness to adversarial examples,2017, In Proceedings of the International Conference on MachineLearning (ICML)
 Limit theorems for sums of general functions of m-spacings,1984, Mathematical Proceedings ofthe Cambridge Philosophical Society
 On the estimation of entropy,1993, Annals of the Institute of StatisticalMathematics
 The nearest neighbor information estimator is adaptively near minimaxrate-optimal,2017, arXiv:1711
 Estimation of entropy and other functionals of a multivariate density,1989, Annals of the Instituteof Statistical Mathematics
 Estimation of nonlinear functionals of densities withconfidence,2012, IEEE Trans
 Sample estimate of the entropy of a random vector,1987, ProblemyPeredachi Informatsii
 Asymptotically efficient estimation of nonlinear functionals,1978, Problemy PeredachiInformatsii
 Automatic differentiation in PyTorch,2017, In NIPS Autodiff Workshop
 Monte Carlo Methods,2004, Wiley Online Library
 On theinformation bottleneck theory of deep learning,2018, In Proceedings of the International Conference onLearning Representations (ICLR)
 Finite-sample analysis of fixed-k nearest neighbor density functionalestimators,2016, In Advances in Neural Information Processing Systems
