title,year,conference
 Exploring sharedstructures and hierarchies for multiple nlp tasks,2018, arXiv preprint arXiv:1808
 Meta multi-task learning for sequencemodeling,2018, arXiv preprint arXiv:1802
 Adversarial multi-criteria learning forchinese word segmentation,2017, In Proceedings of the 55th Annual Meeting of the Association forComputational Linguistics (Volume 1: Long Papers)
 A unified architecture for natural language processing: Deepneural networks with multitask learning,2008, In Proceedings of the 25th international conference onMachine learning
 Image aesthetic assessment: An experimental survey,1053, IEEESignal Processing Magazine
 Model-agnostic meta-learning for fast adaptation ofdeep networks,2017, In International Conference on Machine Learning
 A joint many-taskmodel: Growing a neural network for multiple nlp tasks,2016, arXiv preprint arXiv:1611
 Deep residual learning for image recognition,2016, In 2016 IEEEConference on Computer Vision and Pattern Recognition (CVPR)
 Bidirectional lstm-crf models for sequence tagging,2015, arXivpreprint arXiv:1508
 Learning to generalize: Meta-learning for domain generalization,2017, arXiv preprint arXiv:1710
 Multi-domain sentiment classification,2008, In Proceedings of theACL
 Recurrent neural network for text classification withmulti-task learning,2016, arXiv preprint arXiv:1605
 Multi-tasksequence to sequence learning,2015, arXiv preprint arXiv:1511
 A simple neural attentive meta-learner,2018, 2018
 Cross-stitch networks formulti-task learning,2016, In Computer Vision and Pattern Recognition (CVPR)
 Glove: Global vectors for wordrepresentation,2014, In Proceedings of the 2014 conference on empirical methods in natural languageprocessing (EMNLP)
 Optimization as a model for few-shot learning,2016, 2016
 Adapting visual category models to newdomains,2010, In European conference on computer vision
 One-shotlearning with memory-augmented neural networks,2016, arXiv preprint arXiv:1605
 Deep multi-task representation learning: A tensor factorisa-tion approach,2016, arXiv preprint arXiv:1605
 Multi-task cross-lingual sequence taggingfrom scratch,2016, arXiv preprint arXiv:1603
 One-shot imitation from observing humans via domain-adaptive meta-learning,2018, arXivpreprint arXiv:1802
 Adadelta: an adaptive learning rate method,2012, arXiv preprint arXiv:1212
