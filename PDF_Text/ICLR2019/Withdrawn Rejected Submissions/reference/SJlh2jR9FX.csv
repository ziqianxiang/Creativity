title,year,conference
 Fixinga broken elbo,2018, In International Conference on Machine Learning
 Training with noise is equivalent to tikhonov regularization,1995, Neural computation
 Generating sentences from a continuous space,2015, arXiv preprint arXiv:1511
 Variational lossy autoencoder,2016, arXiv preprint arXiv:1611
 Avoiding latent variable collapsewith generative skip models,2018, arXiv preprint arXiv:1807
 Noisin: Unbiased regularizationfor recurrent neural networks,2018, arXiv preprint arXiv:1805
 Density estimation using real nvp,2016, arXivpreprint arXiv:1605
 Dropout as a bayesian approximation: Representing modeluncertainty in deep learning,2016, In international conference on machine learning
 Learning translation invariant recognition in a massively parallel networks,1987, InInternational Conference on Parallel Architectures and Languages Europe
 Reducing the dimensionality of data with neuralnetworks,2006, science
 A probabilistic analysis of the Rocchio algorithm with TFIDF for text catego-rization,1996, Technical report
 Adam: A method for stochastic optimization,2014, arXiv preprintarXiv:1412
 Auto-encoding variational bayes,2013, arXiv preprintarXiv:1312
 Learning sparse neural networks throughl_0 regularization,2017, arXiv preprint arXiv:1712
 Learning with marginalizedcorrupted features,2013, In International Conference on Machine Learning
 Stochastic backpropagation andapproximate inference in deep generative models,2014, arXiv preprint arXiv:1401
 Autoencoding variational inference for topic models,2017, arXivpreprint arXiv:1703
 Extracting andcomposing robust features with denoising autoencoders,2008, In Proceedings of the 25th internationalconference on Machine learning
 Dropout training as adaptive regularization,2013, InAdvances in neural information processing systems
 Evaluation methods fortopic models,2009, In Proceedings of the 26th annual international conference on machine learning
 Infovae: Information maximizing variationalautoencoders,2017, arXiv preprint arXiv:1706
