title,year,conference
 Optimization methods for large-scale machinelearning,2016, arXiv preprint arXiv:1606
 Sgd learns over-parameterized networks that provably generalize on linearly separable data,2017, arXiv preprintarXiv:1710
 On the learning dynamics of deep neural networks,2018, arXiv preprint arXiv:1809
 Implicit regularization in matrix factorization,2017, In Proc
 Characterizing implicit bias interms of optimization geometry,2018, ArXiv:1802
 Learning overparameterized neural networks via stochastic gradientdescent on structured data,2018, arXiv preprint arXiv:1808
 Convergenceof gradient descent on separable data,2018, ArXiv:1803
 Stochastic gradient descent on separabledata: Exact convergence with a fixed learning rate,2018, arXiv preprint arXiv:1806
 Problem complexity andmethod efficiency in optimization,1983, Wiley
 Stochastic convex opti-mization,2009, In Proc
 The implicit bias of gradient descent on separabledata,2017, ArXiv:1710
 The implicit bias of gradient descent on separabledata,2018, In Proc
 By Theorem 3,2019,1
