title,year,conference
 Stargan:Unified generative adversarial networks for multi-domain image-to-image translation,2017, arXiv preprint
 Very deep convolutional networksfor text classification,2016, arXiv preprint arXiv:1606
 Distilling a neural network into a soft decision tree,2017, arXiv preprintarXiv:1711
 Bornagain neural networks,2018, arXiv preprint arXiv:1805
 Cross modal distillation for supervision transfer,2016, InProceedings of the IEEE Conference on Computer Vision and Pattern Recognition
 Ganstrained by a two time-scale update rule converge to a local nash equilibrium,2017, In Advances in NeuralInformation Processing Systems
 Distilling the knowledge in a neural network,2014, NIPS DeepLearning Workshop
 Mobilenets: Efficient convolutional neural networks for mobilevision applications,2017, arXiv preprint arXiv:1704
 Binarized neuralnetworks,2016, In Advances in neural information processing systems
 Batch normalization: Accelerating deep network training by reducinginternal covariate shift,2015, arXiv preprint arXiv:1502
 Sequence-level knowledge distillation,2016, arXiv preprint arXiv:1606
 Learning multiple layers of features from tiny images,2009, Technicalreport
 Pruning filters for efficientconvnets,2016, arXiv preprint arXiv:1608
 Exploringthe granularity of sparsity in convolutional neural networks,2017, IEEE CVPRW
 Mixed precision training,2017, arXivpreprint arXiv:1710
 Apprentice: Using knowledge distillation techniques to improvelow-precision network accuracy,2017, arXiv preprint arXiv:1711
 Xnor-net: Imagenetclassification using binary convolutional neural networks,2016, In European Conference on Computer Vision
 Fitnets: Hints for thin deep nets,2015, ICLR
 Improvedtechniques for training gans,2016, In Advances in Neural Information Processing Systems
 Progressive blockwise knowledge distillation for neuralnetwork acceleration,2018, In IJCAI
 Aggregated residualtransformations for deep neural networks,2017, In Computer Vision and Pattern Recognition (CVPR)
 Shufflenet: An extremely efficientconvolutional neural netWork for mobile devices,2017, CoRR
 Trained ternary quantization,2016, arXiv preprintarXiv:1612
