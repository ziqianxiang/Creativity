title,year,conference
 Pruning training sets for learning ofobject categories,2005, In Computer Vision and Pattern Recognition
 A closer look atmemorization in deep netWorks,2017, arXiv preprint arXiv:1706
 ToWards open set deep netWorks,2016, In Proceedings of the IEEEconference on computer vision and pattern recognition
 Learning With rejection,2016, In InternationalConference on Algorithmic Learning Theory
 To reject or not to reject: that is the question-anansWer in case of neural classifiers,2000, IEEE Transactions on Systems
 Classification in the presence of label noise: a survey,2014, IEEEtransactions on neural networks and learning systems
 Support vector machines With embedded reject option,2002, In Patternrecognition with support vector machines
 Selective classification for deep neural netWorks,2017, In Advancesin neural information processing systems
 Learning and evaluation in presence of non-iid label noise,2014, In ArtificialIntelligence and Statistics
 Co-teaching: robust training deep neural netWorks With extremely noisy labels,2018, arXivpreprint arXiv:1804
 A baseline for detecting misclassified and out-of-distributionexamples in neural netWorks,2016, arXiv preprint arXiv:1610
 Using trusted data to traindeep netWorks on labels corrupted by severe noise,2018, arXiv preprint arXiv:1802
 Mentornet: Learning data-driven curriculum for very deep neural netWorks on corrupted labels,2018, In International Conferenceon Machine Learning
 Deep learning,2015, nature
 Towards fully autonomous driving: Systemsand algorithms,2011, In Intelligent Vehicles Symposium (IV)
 Learning fromnoisy labels with distillation,2017, In ICCV
 Enhancing the reliability of out-of-distribution imagedetection in neural networks,2018, 2018
 Deep patient: an unsupervised representa-tion to predict the future of patients from the electronic health records,2016, Scientific reports
 Universaladversarial perturbations,2017, arXiv preprint
 A study of the effect of different typesof noise on the precision of supervised learning techniques,2010, Artificial intelligence review
 Deep neural networks are easily fooled: High confidencepredictions for unrecognizable images,2015, In Proceedings of the IEEE Conference on ComputerVision and Pattern Recognition
 Automatic differentiation inpytorch,2017, 2017
 Training deep neural networks on noisy labels with bootstrapping,2014, arXiv preprintarXiv:1412
 Grad-cam: Visual explanations from deep networks via gradient-basedlocalization,2017, In ICCV
 Very deep convolutional networks for large-scale imagerecognition,2014, arXiv preprint arXiv:1409
 Striving forsimplicity: The all convolutional net,2014, arXiv preprint arXiv:1412
 Trainingconvolutional networks with noisy labels,2014, arXiv preprint arXiv:1406
 Intriguing properties of neural networks,2013, arXiv preprint arXiv:1312
 Fashion-mnist: a novel image dataset for benchmarkingmachine learning algorithms,2017, arXiv preprint arXiv:1708
 Understandingdeep learning requires rethinking generalization,2016, arXiv preprint arXiv:1611
 Generalized cross entropy loss for training deep neural networkswith noisy labels,2018, arXiv preprint arXiv:1805
 Class noise vs,2004, attribute noise: A quantitative study
