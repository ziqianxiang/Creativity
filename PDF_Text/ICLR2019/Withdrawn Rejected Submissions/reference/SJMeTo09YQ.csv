title,year,conference
 A briefsurvey of deep reinforcement learning,2017, arXiv preprint arXiv:1708
 Potential-based shaping in model-basedreinforcement learning,2008, In AAAI
 Safe model-basedreinforcement learning with stability guarantees,2017, In Advances in Neural Information ProcessingSystems
 Heuristically accelerated q-learning: anew approach to speed up reinforcement learning,2004, In Brazilian Symposium on Artificial Intelligence
 Openai gym,2016, arXiv preprint arXiv:1606
 Model-based reinforcement learning via meta-policy optimization,2018, arXiv preprintarXiv:1809
 Model-agnostic meta-learning for fast adaptation ofdeep networks,2017, ICML
 Improving reinforcement learning by using sequencetrees,2010, Machine Learning
 Model-based reinforcement learningfor approximate optimal regulation,2016, Automatica
 Hierarchical deepreinforcement learning: Integrating temporal abstraction and intrinsic motivation,2016, In Advances inneural information processing systems
 Continuous control with deep reinforcement learning,2016, ICLR
 Simulated car racing championship:Competition software manual,2013, arXiv preprint arXiv:1304
 Symmetry detection and exploitation for function approxi-mation in deep rl,2017, In Proceedings of the 16th Conference on Autonomous Agents and MultiAgentSystems
 Playing atari with deep reinforcement learning,2013, arXiv preprintarXiv:1312
 Human-level controlthrough deep reinforcement learning,2015, Nature
 Neural network dynam-ics for model-based deep reinforcement learning with model-free fine-tuning,2018, In 2018 IEEEInternational Conference on Robotics and Automation (ICRA)
 Overcom-ing exploration in reinforcement learning with demonstrations,2017, arXiv preprint arXiv:1709
 End-to-end deepreinforcement learning for lane keeping assist,2016, arXiv preprint arXiv:1612
 Deep reinforcementlearning framework for autonomous driving,2017, Electronic Imaging
 Learning to reinforcement learn,2016, arXiv preprintarXiv:1611
 Adaptive exploration-exploitation tradeoff for opportunisticbandits,2017, arXiv preprint arXiv:1709
 The important empirically chosen parameters of the model are: learningrates for Actor is set as 0,1200,0001
