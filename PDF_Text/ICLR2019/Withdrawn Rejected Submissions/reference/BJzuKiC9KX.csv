title,year,conference
 Learning the structure of deep sparse graph-ical models,2010, In International Conference on Artificial Intelligence and Statistics
 Probabilistic models of language processing and acquisi-tion,2006, Trends in cognitive sciences
 Backpropagationthrough the void: Optimizing control variates for black-box gradient estimation,2018, In InternationalConference on Learning Representations
 Neural Turing machines,2014, arXiv preprintarXiv:1410
 Hybrid computing using a neural network with dynamic external memory,2016, Nature
 Muprop: Unbiased backpropagationfor stochastic neural networks,2016, In International Conference on Learning Representations
 The “wake-sleep” algorithmfor unsupervised neural networks,1995, Science
 Categorical reparameterization with Gumbel-softmax,2017, InInternational Conference on Learning Representations
 Adam: A method for stochastic optimization,2015, In InternationalConference on Learning Representations
 Auto-encoding variational Bayes,2014, In International Conferenceon Learning Representations
 The emergence of organizing struc-ture in conceptual representation,2018, Cognitive science
 Inference compilation and universal proba-bilistic programming,2017, In International Conference on Artificial Intelligence and Statistics
 Auto-encoding sequentialMonte Carlo,2018, In International Conference on Learning Representations
 The concrete distribution: A continuous re-laxation of discrete random variables,2017, In International Conference on Learning Representations
 Neural variational inference and learning in belief networks,2014, InInternational Conference on Machine Learning
 Variational inference for Monte Carlo objectives,2016, In InternationalConference on Machine Learning
 Learning in implicit generative models,2016, arXivpreprint arXiv:1610
 Connectionist learning of belief networks,1992, Artificial intelligence
 The dependent Dirichlet process mixture of objectsfor detection-free tracking and object modeling,2014, In Artificial Intelligence and Statistics
 The infinite Gaussian mixture model,2000, In Advances in neural informationprocessing systems
 Lecture 6,2012,5—RmsProp: Divide the gradient by a running average of itsrecent magnitude
 Simple statistical gradient-following algorithms for connectionist reinforcementlearning,1992, Machine learning
