title,year,conference
 K-svd: An algorithm for designing over-complete dictionaries for sparse representation,2006, IEEE Transactions on signal processing
 A latent variable modelapproach to pmi-based word embeddings,2016, Transactions of the Association for ComputationalLinguistics
 A simple but tough-to-beat baseline for sentenceembeddings,2017, International Conference of Learning Representation
 Sparse local em-beddings for extreme multi-label classification,2015, In Advances in Neural Information ProcessingSystems
 Efficient vector representation for documents through corruption,2017, 5th InternationalConference on Learning Representations
 A unified architecture for natural language processing: Deepneural networks with multitask learning,2008, In Proceedings of the 25th international conference onMachine learning
 Senteval: An evaluation toolkit for universal sentence represen-tations,2018, arXiv preprint arXiv:1803
 Improving distributed wordrepresentation and topic model by word-topic mixture model,2016, In Proceedings of The 8th AsianConference on Machine Learning
 Product classification in e-commerce using distributional semantics,2016, In Proceedings of COLING 2016
 Distributional structure,1954, Word
 Word embeddings as metricrecovery in semantic spaces,2016, Transactions of the Association for Computational Linguistics
 Bag-of-concepts: Comprehending documentrepresentation through clustering words in distributed representation,2017, Neurocomputing
 Convolutional neural networks for sentence classification,2014, In Proceedings of the 2014Conference on Empirical Methods in Natural Language Processing (EMNLP)
 Skip thought vectors,2015, Advances in neural information processing systems
 From word embeddings to documentdistances,2015, In International Conference on Machine Learning
 Ltsg: Latent topical skip-gram for mu-tually learning topic model and vector representations,2017, arXiv preprint arXiv:1702
 Distributed representations of sentences and documents,2014, In ICML
 Generative topic embedding: a continuousrepresentation of documents,2016, In Proceedings of The 54th Annual Meeting of the Association forComputational Linguistics (ACL)
 Integrating topic modeling withword embeddings by mixtures of vmfs,2016, Proceedings of COLING 2016
 Learning context-sensitive word embeddings withneural tensor skip-gram model,2015, In Proceedings of IJCAI 2014
 Scdv: Sparse compositedocument vectors using soft clustering over distributional representations,2017, In Proceedings of the2017 Conference on Empirical Methods in Natural Language Processing
 Recurrentneural network based language model,2010, In Eleventh Annual Conference of the International SpeechCommunication Association
 Distributed represen-tations of words and phrases and their compositionality,2013, In Advances in Neural InformationProcessing Systems
 Mixing dirichlet topic models and word embeddings to make lda2vec,2016, arXivpreprint arXiv:1605
 Improving topic models with la-tent feature word representations,2015, Transactions of the Association for Computational Linguistics
 Topic2vec: learning distributed repre-sentations of topics,2015, In 2015 International Conference on Asian Language Processing (IALP)
 Glove: Global vectors for wordrepresentation,2014, In Proceedings of the 2014 conference on empirical methods in natural languageprocessing (EMNLP)
 Glove: Global vectors for wordrepresentation,1532, In Empirical Methods in Natural Language Processing (EMNLP)
 Evaluation of sentence embeddings indownstream and linguistic probing tasks,2018, arXiv preprint arXiv:1806
 Deep contextualized word representations,2018, In Proc
 Concatenated P-mean word embeddings as universal cross-lingual sentence representations,2018, arXiv preprintarXiv:1803
 Recursive deep models for semantic compositionality over a sentimenttreebank,2013, In Proceedings of the conference on empirical methods in natural language processing(EMNLP)
 Revisiting recurrent networks for paraphrastic sentence embed-dings,2017, Proceedings of the 54th Annual Meeting of the Association of Computational Linguistic2017
 Towards universal paraphrasticsentence embeddings,2016, International Conference of Learning Representation
 Charagram: Embedding words andsentences via character n-grams,2016, arXiv preprint arXiv:1607
 Word moverâ€™s embedding: From word2vec to documentembedding,2018, In Proceedings of the 2018 Conference on Empirical Methods in Natural LanguageProcessing
 Linear spatial pyramid matching usingsparse coding for image classification,2009, In Computer Vision and Pattern Recognition
 The highest score ineach row is in boldface,2017, The methods can be supervised (denoted as Su
