title,year,conference
 On gradient regular-izers for MMD GANs,2018, arXiv:1805
 Towards principled methods for training generative adversarialnetWorks,2017, In International Conference on Learning Representations (ICLR)
 DemystifyingMMD GANs,2018, In International Conference on Learning Representations (ICLR)
 Pros and cons of GAN evaluation measures,2018, arXiv:1802
 InfoGAN:Interpretable representation learning by information maximizing generative adversarial nets,2016, InAdvances in Neural Information Processing Systems (NIPS)
 Generative multi-adversarial networks,2017, InInternational Conference on Learning Representations (ICLR)
 Training generative neuralnetworks via maximum mean discrepancy optimization,2015, In UAI
 Many paths to equilibrium: GANs do not need to decrease a divergence atevery step,2018, In International Conference on Learning Representations (ICLR)
 Im-proved training of Wasserstein GANs,2017, In Advances in Neural Information Processing Systems(NIPS)
 Adam: A method for stochastic optimization,2015, In InternationalConference on Learning Representations (ICLR)
 On convergence and stability ofGANs,2017, arXiv:1705
 Learning multiple layers of features from tiny images,2009, Technical report
 The MNIST database of handwrittendigits,1998, Technical report
 MMD GAN:Towards deeper understanding of moment matching network,2017, In Advances in Neural InformationProcessing Systems (NIPS)
 Are GANs cre-ated equal? A large-scale study,2018, In Advances in Neural Information Processing Systems (NIPS)
 Multi-class generativeadversarial networks with the L2 loss function,2016, arXiv:1611
 Spectral normalizationfor generative adversarial networks,2018, In International Conference on Learning Representations(ICLR)
 f-GAN: Training generative neural sam-plers using variational divergence minimization,2016, In Advances in Neural Information ProcessingSystems (NIPS)
 Temperedadversarial networks,2018, In International Conference on Machine Learning (ICML)
 Improved techniques for training GANs,2016, In Advances in Neural Information ProcessingSystems (NIPS)
 A note on the evaluation of generativemodels,2016, In International Conference on Learning Representations (ICLR)
 Fashion-mnist: a novel image dataset for benchmark-ing machine learning algorithms,2017, arXiv: 1708
 Self-attention generativeadversarial networks,2018, arXiv: 1805
 mixup: Beyond empiri-cal risk minimization,2018, In International Conference on Learning Representations (ICLR)
