Figure 1: Illustration of differentially private federated learning on a client level. Step 1: At eachcommunication round t, mt out of total K clients are sampled uniformly at random. The centralmodel wt is distributed to the sampled clients. Step 2: The selected clients optimize wt on their localdata, leading to wk . Clients centralize their local updates: 4wk = wk - wt . Step 3: The updates areclipped such that their sensitivity can be upper bounded. The clipped updates are averaged. Step 4:The central model is updated adding the averaged, clipped updates and distorting them with Gaussiannoise tuned to the sensitivity’s upper bound. Having allocated the new central model, the procedurecan be repeated. However, before starting step 1, a privacy accountant evaluates the privacy loss thatwould arise through performing another communication round. If that privacy loss is acceptable, anew round may start.
Figure 2: Accuracy of digit classification from non-IID MNIST-data held by clients over the courseof decentralized training. For differentially private federated optimization, dots at the end of accuracycurves indicate that the δ-threshold was reached and training therefore stopped.
Figure 3: Scenario of 100 clients, non-differentially private: accuracy, between clients variance andupdate scale over the course of federated optimization.
