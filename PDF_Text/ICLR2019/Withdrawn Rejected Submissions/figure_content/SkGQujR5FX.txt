Figure 1: The gap between θt and θt+τ while training ResNet-20 on the CIFAR-10 dataset with (a)different numbers of workers, and (b) different asynchronous algorithms. Adding workers or usingmomentum increases the effect of the lag τ on the gap. The large drops in G(θt - θt+τ ) are causedby learning rate decay.
Figure 2: Final test error for different numbers of workers N on the CIFAR10 and CIFAR100datasets using ResNet-20 and Wide ResNet 16-4 using block-random scheduling. Bold lines showthe mean over the 5 different experiments, while transparent bands show the standard deviation. Thebaseline is the mean of 5 different runs with a single worker.
Figure 3: Final test error for different numbers of workers N on the CIFAR10 and CIFAR100datasets using ResNet-20 and Wide ResNet 16-4 using the gamma-distributed model of executiontime. Bold lines show the mean over the 5 different experiments, while transparent bands show thestandard deviation. The baseline is the mean of 5 different runs with a single worker.
Figure 4: DANA speedup (solid line) and finaltest error (dashed) when training ResNet-20 onCIFAR-10 with different numbers of workers.
Figure 5: Theoretical speedups for DANA (or any ASGD) and SSGD when batch execution timesare drawn from a Gamma distribution, as in Figure 3. Overheads are not modeled.
