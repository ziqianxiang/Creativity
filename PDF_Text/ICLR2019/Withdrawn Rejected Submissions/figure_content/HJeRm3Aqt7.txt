Figure 1: Two Sample test on Mixture Gaussians. Top: each Gaussian component has intrinsic dimensionalityequal to 5, with a spherical covariance (in 5d) rotated to a random orientation 50d and non-zero mean placed atrandom; the ambient dimension is 50. Bottom: each Gaussian component is defined in a 50 dimensional space,and it has spherical covariance and a non-zero mean placed at random in that space. Left: varying the number ofcomponents in the mixture from 2 to 50. Right: varying the variance of each component; note that for the flatmixture (Top) only the variance in the intrinsic dimension changes.
Figure 2: Same as above but using OT for both cross-validation and evaluation.
Figure 3: Two-sample statistics and optimal transport on two and three dimensional embedded manifolds inR50.
Figure 4: 2S and OT on products of five identical distributions, each of which has support near a two orthree dimensional embedded manifold in R10. In this figure, we use uind from eq. 3 (using the true groups ofindependent coordinates) to measure distortion and to validate models.
Figure 5: Prediction error of dependent variables in causal distribution, see sec. 3 and 5.1. Hyperparameters arechosen by best OT.
Figure 6: We consider product of 5 (top) and 8 (bottom) distributions, each of which is a mixture of threeGaussians in 12 dimensions. The χ2 metric, see sec. 5.1, measures the extent by which models have capturedthe independence structure of the product distribution. Note that higher is better for mode coverage, unlike theother metrics. 2S is computed using 1K samples, while MC and χ2 use 50K samplesFinally, we look at a product of independent Gaussian mixture distributions in fig. 6. None of themodels are able to succesfully fit this distribution, although WGAN-GP and Real NVP do the best.
Figure 7: Two-Sample test for different number of test points for a random quadratic polynomial distribution(top) and for a distribution of shifted bumps (bottom), when training with 1k (left) and 10k (right) samples.
