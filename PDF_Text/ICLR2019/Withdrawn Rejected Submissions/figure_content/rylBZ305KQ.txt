Figure 1: Directed graphical model.
Figure 2:	Perplexity through time for the prediction configuration. Results shown are obtained withtexts published at future time periods, not seen during training.
Figure 3:	Perplexity through time with recursive inference. DRLM-F and DWE-F are trained on Tptimesteps, and then their variational parameters are recursively inferred on data at timestep Tp + τand evaluated at Tp + τ + 1. The LSTM baseline is displayed for comparison purposes.
Figure 4:	Classification results with temporal word embeddings in the prediction configuration. ForLSTM, DRLM, and DRLM-Id, word embeddings were pretrained on the language modeling tasksin section 5.1, while for the baselines DT and DWE, they were trained as proposed by their authors.
