Figure 1: Illustration of (a) the baseline NLI architecture, and two proposed adversarial architec-tures: (b) a double-classifier adds an adversarial hypothesis-only classifier, (c) a single-classifieris trained adversarially with a random premise, and otherwise in the normal manner. Upward anddownward arrows correspond to forward and backward propagation. Green or red arrows respec-tively mean that the gradient sign is kept as is or reversed. Gray arrow indicates that the gradient isblocked and not back-propagated.
Figure 2:	Effect of pre-training with adversarially trained models.
Figure 3:	Results when retraining a classifier on a frozen hypothesis encoder compared to the ad-versarial NLI training.
Figure 4: Majority (Maj) and hypothesis-only baselines, trained on each dataset (Hyp Self) or onSNLI (Hyp SNLI) baselines. The differences determine whether each dataset has different types ofbiases in the hypothesis than the biases in SNLIâ€™s hypotheses.
Figure 5: Cross-validation results.
