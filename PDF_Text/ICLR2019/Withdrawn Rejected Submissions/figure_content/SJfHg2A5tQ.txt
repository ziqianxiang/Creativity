Figure 1: Binary training, where arrows indicate operands flowing into operation or block. Repro-duced from Guo (2018) (left). A convolutional layer depicting weight histogram progression duringthe popular binary training. The initial weight distribution is a standard Gaussian (right).
Figure 2: Forward and backward approximations. (Top Left) The true forward and backward func-tions. (Top Right) BNN training approximation. (Bottom Left) Swish function and its derivative.
Figure 3: R1 (w) (left) and R2 (w) (right) regularization functions for α = 0.5 (solid line) and α = 1(dashed line). The scaling factor α is trainable, as a result the regularization functions can adaptaccordingly.
