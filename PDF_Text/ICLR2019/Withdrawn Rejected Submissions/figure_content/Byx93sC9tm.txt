Figure 1: MNIST histograms of true labels in the training set. Top: End of AL process. Totalnumber of images in training set: 1,000. Bottom: After first 8 acquisition iterations. Total numberof images in training set: 100.
Figure 2: MNIST uncertainty visualization in VAE space at the end of the AL process for allmeasures. Colours represent different classes. Low uncertainty: black, High uncertainty: white.
Figure 3: Test accuracy as a function of size of the incremental training set during AL. Effect ofusing an ensemble of three similar models (stochastic or deterministic) instead of one single MC-Dropout network. Left: MNIST. Right: CIFAR-10Figure 4: Histogram of BALD uncertainty of MNIST (left) and NotMNIST (right) images (2,000random but balanced test set). Uncertainty obtained from single MC-Dropout and ensemble MC-Dropout methods at the end of the AL process.
Figure 4: Histogram of BALD uncertainty of MNIST (left) and NotMNIST (right) images (2,000random but balanced test set). Uncertainty obtained from single MC-Dropout and ensemble MC-Dropout methods at the end of the AL process.
Figure 5: Histogram of BALD uncertainty of MNIST (left) and NotMNIST (right) images (2,000random but balanced test set). Uncertainty obtained from deterministic and MC-Dropout ensemblemethods at the end of the AL process. Numbers correspond to accuracy for corresponding binnedsubset of test data (in percentage).
Figure 6: Left MNIST uncertainty calibration. Expected fraction and observed fraction. Ideal outputis the dashed black line. MSE reported in paranthesis. Calibration averaged over 3 different runs.
Figure 7: MNIST histograms of the top 1,000 most uncertain samples from test set as ranked by theLeNet model trained on the entire training set.
Figure 8: MNIST confusion matrix for the models at the end of the AL process. Test set: 10,000.
Figure 9: MNIST histogram of true labels in the training set after 8 acquisition iterations. Totalnumber of images in training set: 100 Top: Single MC-Dropout network. Bottom: Ensemble ofthree networks of similar architecture but different random initialization.
Figure 10: Uncertainty visualization in latent space. MNIST dataset removed for a clearer visu-alization of the uncertainty. Uncertainty is in white (a lighter background corresponds to higheruncertainty while a darker one represents regions of lower uncertainty) Top: Uncertainty obtainedat the end of the AL process using an ensemble of three similar networks. Bottom: Uncertaintyobtained at the end of the AL process using a single network.
Figure 11: tSNE embeddings of the MNIST dataset. Effect of using an ensemble of three similarmodels (stochastic or deterministic) instead of one single MC-Dropout network. Orange pointscorrespond to images acquired during the AL process.
