Figure 1: (a) An illustration of IB-GAN architecture. (b) Variations of individual KL-divergenceKL(e(ri|z)||m(ri)) over iterations on dSprites dataset. The sum of these values is the IU (z, R(z)).
Figure 3: Latent traversals of IB-GAN. IB-GAN (a) learns azimuth, hair color and smile attributeson CelebA, and (b) captures factors of scale, leg and azimuth on 3D Chairs.
Figure 4: Effects of β on the convergence of variational upper-bound (solid orange) and lower-bound (solid blue) of MI with independent KL-Divergences (dashed lines) KL(e(ri|z)||m(ri)) foreach ri (i = 1,…，10), and the disentanglement scores Kim & Mnih (2018) (solid black) over150K training iterations. Vertical dashed black lines represent the iterations at the highest scores.
Figure 5: Effects of β on the converged upper/lower bound of MI and the disentanglement metricscores Kim & Mnih (2018).
Figure 6: Some examples of latent traversals of three different base shapes (ellipse, square, andheart) on dSprites dataset with the best parameter setting (β = 0.212, λ = 1). IB-GAN successfullycaptures the five factors of variations: rotations (r0), shapes (r1), positions of Y (r4) and X (r5) andscales (r6). The generator does not reflect the changes in r2, r3, r7, r8 and r9 since they are identicalto factored zero mean Gaussian prior m(ri) and convey no information about z. This result alignwith the Figure.4c: KL-Divergences of these dimensions are nearly zero.
Figure 7: Latent traversals of four different r vectors on CelebA dataset with the best parametersetting (β = 0.2838, λ = 1).
