Figure 1: Hidden Markov Field1	1 l'i' -χr El	11	∙ 1 1	∙11	,	. 1	Fl ∙ , 1	11	1 , El	. 1	∙	Fknockoff Xj . The null variables will enter the model with smaller penalty. Thus the signed maxlambda statistic is defined as Wj = (Zj ∨ Zj)sign(Zj - Zj). Where Zj = sup{λ : β2j-1(λ) 6= 0}and Zj = sup{λ : β2j (λ) 6= 0}. Various feature statistics has been proposed for common learningmethods (Candes et al., 2018; Gimenez et al., 2018), however the current knockoff generation meth-ods are still limited for real data from unknown distributions. Although Candes et al. (2018) providesa general algorithm for generating Model-X knockoffs, i.e. the Sequential Conditional IndependentPairs algorithm, it needs to sample from the conditional distribution ofXj from f(Xj |X-j, X1:j-1)which becomes intractable with slightly complex distributional assumption for X. CandeS et al.
Figure 2: Power and FDR with respect to signal magnitude ρ for Setting 1.
Figure 3: Power and FDR with respect to signal magnitude ρ for Setting 2.
Figure 4: Capture of simulated signals with real data generated knockoffs7 Conclusion and DiscussionIn this paper, we propose a knockoff generating framework based on a latent variable Z to decor-relate X . We noticed there are two independent works on deep learning generators for knockoffswhile writing and revising the paper. (For double blind review consideration, we exclude the cita-tions at this time.) Compared with the other deep learning frameworks for generating knockoffs,our framework is the only framework directly targeting on the reconstruction of X from Z . Weprovide theoretical results for general existence of such Z. Our framework offers a computationallight solution, and if the data and the parametric families for the working models are compatible,our framework may offer a computationally efficient solution to be easily implemented by domainscientists.
