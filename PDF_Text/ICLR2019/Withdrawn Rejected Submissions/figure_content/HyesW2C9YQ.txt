Figure 1: Example where acknowledging aninferred feeling might be appropriateof Internet conversation data used for training are known to harbor aggressive and callous responses(Anderson, 2015).
Figure 2: Distribution of situation/conversation labels within EmpatheticDialogues. Percent-ages per class are also listed in the appendix.
Figure 3: Dialogue generation architectures used in our experiments. The context of concatenatedprevious utterances is tokenized into xi ,χ2, •…,and encoded into vector hχ by the context encoder.
Figure 4: Three ways to incorporate additional supervised information, here from an emotionclassification task. Left: the context representation hx outputted by the context encoder is used bothas input to a classifier, and to generate the next utterance as in the base setting. The encoder istrained with gradients from both output branches. Middle: an input sequence (that can be either adialogue context or a candidate) is first run through a pretrained classifier, and the top k output labelsare prepended to the sequence, which is then run through the corresponding (context or candidate)encoder to output a hidden representation hw (either hx or hy) as in the base setting. Right: an inputsequence (that can be either a dialogue context or a candidate) is run through the correspondingencoder as well as a pretrained classifier with the last layer removed. The outputs hw and hc areconcatenated and linearly projected into a representation he .
Figure 5: Full heatmap from ranking task. The prepend models in this tables are from the emotionsupervision task. Scores are ratios of the [# times horizontal model is selected over vertical] : [#times vertical model is selected over horizontal]. Scores of greater than 1 indicate a preference forthe horizontal model, and scores of less than 1 indicate a preference for the vertical model.
