Figure 1: Illustration of function realisations in softmax space (left), in logit space (pre-softmax, middle), aswell as epistemic (orange, right) and aleatoric uncertainty (blue, right). Note the high epistemic uncertainty(I) in regions of the input space where many function explanations exist, and how predictive probability mean(dark blue, left panel) is close to uniform in these areas. Also note aleatoric uncertainty H spiking in regionsof ambiguity (transition from class 0 to class 1, depicted in the left panel).
Figure 2: Manifold MNIST ground-truth density in2D latent space with decoded image-space realisa-tions (a real-looking digit (top), interpolation (mid-dle), and garbage (bottom)).
Figure 3: Ground-truth density v.s. step for FGM at-tacks on the decoded images with a deterministic clas-sification NN. Note the decreasing density as the im-ages become adversarial.
Figure 4: Our Dgrid dataset de-picted in 2D latent space withcrosses overlaid ontop of Mani-fold MNIST.
Figure 5: Manifold MNIST 2Dlatent space with HMC MI pro-jected from image space, show-ing “near perfect” uncertainty.
Figure 6: HMC MI v.s. log den-sity of Dgrid latent points. Notethe strong correlation betweenthe density and HMC MI.
Figure 7: MNIST projected into 2D latent space with projected image-spaceMI for dropout and HMC inference. Note the holes in uncertainty far fromthe data for dropout.
Figure 8: Dropout MI v.s. HMCMI (note the correlation, but alsothat dropout holes lead to zeroMI when HMC MI is non-zero).
Figure 9: Three cherry-picked ‘garbage’images classifying with high output prob.,from ‘holes’ in dropout uncertainty overMNIST, and their locations in latent space.
Figure 10: 2D latent spacewith MI of dropout ensemble onMNIST, showing fewer uncer-tainty ‘holes’ v.s. dropout (7a).
Figure 11: Dropout ensemble MIv.s. HMC MI (most of the masson the right has been shifted up,i.e. dropout holes are covered).
Figure 12: Image trajectories and their accuracy v.s. density.
Figure 13: Ground truth latent logprobability v.s. image density ob-tained through importance sam-pling (§E) for test images from theMMNIST dataset.
Figure 14: 2D latent plot of de-terministic NN MI. Note the largegaps in uncertainty (larger thandropout ensemble’s gaps).
Figure 15: New attack; This figuredepicts our grid over latent spaceto look for uncertainty ‘holes’ farfrom the data.
Figure 16: Example dataset images, gen-erated adversarial counterparts, and theperturbation.
Figure 17: ROC plot of dropout and dropout ensemble usingMI thresholding to declare ‘adversarial’, evaluated both on allexamples, and on successfully perturbed examples (marked with‘succ’).
