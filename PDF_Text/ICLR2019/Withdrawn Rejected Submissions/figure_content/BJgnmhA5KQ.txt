Figure 1: Toy illustration of how the metrics behave in various scenarios. Red stars represent human refer-ences, while blue dots represent system hypotheses. A: when hypotheses spread uniformly in the space, theaverage oracle BLEU is low, the coverage is high and the pairwise BLEU is low. B: when hypotheses clustertogether closely and in vicinity of a reference (a typical case ofbeam search), the average oracle BLEU is high,the coverage is low and the pairwise BLEU is high. C: when there is a poor hypothesis in the set, the averageoracle BLEU is low, the coverage is medium and the pairwise BLEU is medium. D: when hypotheses matchreferences, the average oracle BLEU is high, the coverage is high and the pairwise BLEU matches humanpairwise BLEU.
Figure 2: Average oracle BLEU (quality) versus pairwise BLEU (diversity) for various methods on threebenchmark datasets with multiple human references. Our approach, Hard-MoE gives the best trade-off.
Figure 3: The effect of dropout on the minimization process at the beginning of training. Experiments areperformed on the IWSLTâ€™14 De-En dataset with 2 latent categories (K = 2).
