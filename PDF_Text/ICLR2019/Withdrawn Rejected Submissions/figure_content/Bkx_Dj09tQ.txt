Figure 1: Orientation-tuning curve of example units. The gOSI value is90	180OrientationUnit #490	180Orientationshown in each panel.
Figure 2: Orientation-selective units exist in all hidden layers. Histograms of gOSI for each layerare shown in red. Histograms of gOSI, after the activation matrix was shuffled, are shown in blue asa control.
Figure 3: Units in the lower layers become more orientation-selective in sync with generaliza-tion performance during the course of training. (a) Evolution of loss (top) and average gOSI(bottom). (b) Relationship between the validation loss and average gOSI during the first 50 epochs.
Figure 4: Networks that generalize better are more orientation-selective in the lower layers. (a)Relationship between the test loss and average gOSI. Each dot indicates one of the 200 trained mod-els. (b) Spearman correlation coefficient between the loss and gOSI for each layer. (c) Relationshipbetween the label corruption rate and gOSI. The higher the label corruption rate, the worse is thegeneralization accuracy (Zhang et al., 2017).
Figure 5:	Importance of orientation-selective units in the lower layers for generalization re-vealed through ablation experiments. The difference between test losses before and after ablationis shown for each layer. Red: units with the top 50% gOSI values were ablated. Blue: units withthe bottom 50% gOSI values were ablated. Asterisks indicate layers for which ablating units withthe top 50% gOSI values yielded more than twofold impact than ablating units with the bottom 50%gOSI values.
Figure 6:	Orientation-selective units are important for the shift-invariance of the fully con-nected layer. Coefficients of variation of the unit activations with respect to the parallel shift of thetest images are shown for each layer (mean Â± standard error).
Figure A1: All grating images presented to the 7-layer CNNs trained on CIFAR-10.
Figure A2: Minimal dependence of orientation selectivity on spatial frequencies. The rangeof preferred orientations among various spatial frequencies was computed for each orientation-selective unit (gOSI > 0.33) and their distribution is plotted.
Figure A3: Reproduction of Fig. A2 using (a) a 7-layer CNN with different initializations and(b) a 20-layer CNN trained on ImageNet. The range of preferred orientations among various spa-tial frequencies was computed for each orientation-selective unit (gOSI > 0.33) and their distributionis plotted.
Figure A4: Reproduction of Fig. 2 using (a) a 7-layer CNN with different initializations and(b) a 20-layer CNN trained on ImageNet. Histograms of gOSI for each layer are shown in red.
Figure A5: Reproduction of Fig. 3 using a 7-layer CNN with different initializations. (a) Re-lationship between the validation loss and average gOSI during the first 50 epochs. Each pointindicates one epoch. (b) Spearman correlation coefficient between the validation loss and averagegOSI during the first 50 epochs.
Figure A6: Reproduction of Fig. 4 using 7-layer CNNs with different initializations. (a) Rela-tionship between the test loss and average gOSI. Each dot indicates one of the 200 trained models.
Figure A7: Reproduction of Fig. 5 using (a) a 7-layer CNN with different initializations and (b)a 20-layer CNN trained on ImageNet. The difference between test losses before and after ablationis shown for each layer. Red: units with the top 50% gOSI values were ablated. Blue: units withthe bottom 50% gOSI values were ablated. Asterisks indicate layers for which ablating units withthe top 50% gOSI values yielded more than twofold impact than ablating units with the bottom 50%gOSI values.
Figure A8: A small number of units is already orientation-selective before training. Orientationselectivity was analyzed on a network with random weights.
