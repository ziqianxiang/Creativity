Figure 1: A guide g extracts a latent task representation Z from an annotated image (red) for inferenceby fθ (x, Z) on a different, unannotated image (blue).
Figure 2: Guided segmentation groups different kinds of segmentation in one problem statement.
Figure 3: Extracting a task representation or “guidance” from the support. (a) Early fusion simplyconcatenates the image and annotations. (b) Our late fusion factorizes into image and annotationstreams, improves accuracy, and updates quickly given new annotations. (c) Globalizing the taskrepresentation propagates appearance non-locally: a single bird is annotated in this example, butglobal guidance causes all the similar-looking birds to be segmented (red) regardless of location.
Figure 4: Optimization for guided segmentation. (a) Synthesizing tasks from densely annotatedsegmentation data. (b) One task update: episodic training reduces to supervised learning.
Figure 5: (left) Interactive segmentation of objects in images. (right) Guided semantic segmentationof held-out classes: we are state-of-the-art with only two points and competitive with full annotations.
Figure 6: (left) Accuracy-time evaluation for sparse and dense video object segmentation onDAVIS’17 val. (right) Real-time interactive video segmentation on simulated dot interactions.
