Figure 1: Visualization of the learned representations for a 6-layer MLP trained with MNIST dataset. A singleunit’s activation histogram (upper plots) and two randomly chosen units’ activation scatter plots (lower plots)are shown for the fifth layer’s representation, where each color corresponds to a different class. The plots weregenerated using 10,000 test samples of MNIST dataset. (Upper) It can be seen that the baseline has a large class-wise variance and inter-class overlaps, and BN and CR (originally known as DeCov (Cogswell et al., 2015)) showsimilar properties. Dropout looks completely different where activation values are more spread out for the activeclasses. L1R (L1 Representation regularizer) typically allow only one or two classes to be activated per unit.
Figure 2: Effect of L1R (L1 Representation Regularizer): representation sparsity (Ps) and accuracyare shown as a function of L1R’s loss weight. Each line corresponds to a different number ofindependent factors. While sparsity is well controlled, accuracy does not show any meaningfuldependency on the number of independent factors used in the data generation process.
Figure 3: Effect of RR (Rank Regularizer): representation rank (r) and accuracy are shown as afunction of RR’s loss weight. Each line corresponds to a different number of independent factors.
Figure 4: Mutual information and generalization errorcan observe that all the regularizers end up with almost the same I (zl ; y) value. But the bounds ofI(zl; x) can be seen to be strongly dependent on which regularizer is used, and the upper and lowerbounds show a similar pattern as the generalization error’s pattern. In fact, the correlation betweenthe lower bound and generalization error can be calculated to be 0.84, and the correlation betweenthe upper bound and generalization error can be calculated to be 0.78. Therefore, it can be surmisedthat the regularizers might be indirectly affecting the performance by influencing I(zl ; x).
