Figure 1: As motivational example Fig. 1b shows the latent interaction graph formed by the differenttraffic monitor stations around the San Francisco bay area located according to Fig. 1a.
Figure 2: Graphical representation of our interaction graph, where semantically similar relationsshare the same parameters and the attention model is used to learn the factor interactions.
Figure 3: Overall model architecture.
Figure 5: A training example for each synthetic dataset. Note that the neighbors are represented bya thinner line w.r.t to the node and label time series. Moreover, noise neighbors have the thinnestline.
Figure 6: Attention output for the DIAN model on the different toy tasks. Note that on the x-axesare reported the neighbours time series (xj | j âˆˆ Ni) while the y-axes report the node time series(xi).
Figure 7: Training and validation results for the real-world datasets. Note that MSE and RMSE arereported in a logarithmic scale.
Figure 8: Attention output of the DIAN model for the real-world datasets. Note that for spacelimitations we have not report neither the neighbours time series value, neither the node.
