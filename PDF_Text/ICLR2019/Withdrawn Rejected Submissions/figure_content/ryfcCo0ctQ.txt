Figure 1: Training Acrobot and MountainCar using online Q-learning. Here we set βt = 10-3 forboth problems. In addition, for Acrobot, We let at be one of {10-2,8 ∙ 10-3,3 ∙ 10-4,10-4}. Foror MountainCar We set at to be one of {0.7,0.5, 5 ∙ 10-4,10-4}.
Figure 2: Training Pong and Breakout using two timescale actor-critic algorithm, where we use 32agents, minibatch of size 20, with a fixed actor network stepsize αt ≡ 10-4, but a varied criticnetwork stepsize βt ∈ {10-7, 2 ∙ 10-7, 5 ∙ 10-4,10-3}. Left: training Pong. Right: trainingBreakout.
