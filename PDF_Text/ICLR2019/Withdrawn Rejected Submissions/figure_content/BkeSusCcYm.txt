Figure 1: Convergence by epoch on Romanian-English training. Gradient dropping takes moreepochs (but not necessarily time) to reach peak performance even with deep gradient compressionand ratio warm-up.
Figure 2: Convergence per step of gradient drop-ping with various local gradient update tech-niques on the Ro-En multi-node experiment.
Figure 3: Convergence per step of gradient drop-ping with various local gradient update tech-niques and periodic model synchronization onthe Ro-En multi-node experiment.
Figure 4: Convergence over time of gradientdropping with local gradient update on the Ro-En task.
Figure 5: Convergence over time of gradientdropping with local gradient update on the En-De task.
