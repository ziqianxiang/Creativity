Figure 1: Illustration of sequenced-replacement sampling for mini-batch size B=2 and dataset sizeN=5. (a) The queue is filled according to the training example’s sequence index. (b) The examples“2” and “5” are sampled from dataset to form a mini-batch. (c) The two examples “1” and “2” fromthe queue replace the sampled examples “2” and “5” in the dataset. (d) The examples “1” and “1”are sampled to form the next mini-batch. (e) The examples “3” and “4” from the queue replace thesampled examples in the dataset. In the queue, the first indexed example (example “1”) comes nextto the last indexed example (example “5”) iteratively. A queue is employed in this illustration forsimplicity, but an array with the indexed dataset and a variable that keeps track of the next index cansufficiently replace it.
Figure 2: Training loss and test error of WRN and WRN-SRS on CIFAR-100. The three modelscorrespond to the second, third, and fourth model in Table 3.
Figure 3: Training loss and test error of WRN-SRS on CIFAR-100 with different learning rateschedules. The mini-batch size is set to 64. The learning rate decays by a factor of 10 according toeach schedule.
