Figure 1: a) Swiss Roll and its b) squared and c) spherical embeddings learned by Sinkhorn en-coders. MNIST embedded onto a 10D sphere viewed through t-SNE, with classes by colours: d)encoder only or e) encoder + decoder.
Figure 2: From left to right: CIFAR10 interpolations, CelebA interpolations and samples. Modelsfrom Table 2: (Î²-)VAE (top) and SAE (bottom).
Figure 3: t-SNEs of SAE latent spaces on MNIST: a) 10-dimensional Dir(1/2) and b) 16-dimensional Dir(1/5) priors. For the latter: c) aggr. posterior (red) vs. prior (blue), d) interpolationbetween vertices and e) samples from the prior.
Figure 4: Toy probabilistic programming: data and localization (left), reconstructions (center) andsamples (right). AIR (top) and SAE (bottom).
