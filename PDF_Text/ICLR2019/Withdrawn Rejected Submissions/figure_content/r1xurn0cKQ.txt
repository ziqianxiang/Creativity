Figure 1: Correction Networks consist of two modules: a task module and a correction module. Thetask module produces an initial prediction. The correction module provides a correction such thatwhen the correction is combined with the initial prediction, the resulting prediction is better than theinitial prediction.
Figure 2: Inputs and outputs of Correction Networks demonstrated on zero-shot image classificationbased on a natural language description of the zero-shot class. The task module takes as input thenatural language description of the zero-shot class and makes an initial prediction of the clustercenter of the class in image feature space. The correction module improves this initial predictionby applying a correction, taking as input the task moduleâ€™s initial prediction, training data, and thezero-shot class description.
Figure 3: Examples from the dataset where there is one natural language description of a class andthe goal is to classify images for new classes without training sample images for the new classes.
Figure 4: Architecture of the modulesTrainingThe publicly available SCS and SCE splits (Elhoseiny et al., 2017b) define a test set. The remainingclasses are randomly divided into a validation set and a training set. The size of the validation set isthe same size as the training set. For example, CUB has 200 classes with the conventional SCS splitconsisting of50 test classes. We divided the remaining 150 classes into a 50 class validation set anda 100 class training set.
Figure 5: Qualitative classification results. Each row is a different class with correctly classifiedexamples (left three), false negatives (middle three), and false positives (right three).
