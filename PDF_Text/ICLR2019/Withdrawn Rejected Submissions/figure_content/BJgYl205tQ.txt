Figure 1: Four 2D examples showing how GAN-generated data samples (triangles) could relate toa bimodal Gaussian-distributed data set (circles), together with CrossLID scores: (a) generated datadistributed uniformly, spatially far from the input data; (b) generated data with two modes, spatiallyfar from the input data; (c) generated data associated with only one mode of the input data; and (d)generated data associated with both modes of the input data (the desired situation).
Figure 2:	Left three: The CrossLID(XI ; XG) score for generated samples by a DCGAN after dif-ferent training epochs. Results are shown for the first 50 epochs of training on MNIST, CIFAR-10 and SVHN, and MNIST-R/CIFAR-R/SVHN-R denote the CrossLID(XI ; XI) scores for realMNIST/CIFAR-10/SVHN samples. Rightmost: Correlation between CrossLID score and Inceptionscore for CIFAR-10 dataset, each point is associated with a model at a certain epoch.
Figure 3:	Test results for intra-class mode dropping: The CrossLID scores (left), Inception scores(middle) and FID scores (right) on varying numbers of unique samples in the datasets.
Figure 4:	Robustness to Gaussian noise for CrossLID, Inception score and FID score (from left toright). Noise percent indicates proportion of pixels of GAN images that have been added noise.
Figure 5:	Robustness test of the three metrics on CIFAR-10 dataset to small image transformationsincluding translation (left ) and rotation (middle), and sample size used for calculation (right).
Figure 6: Images generated at the end of the 30-th epoch by DCGAN and DCGAN+ on the MNISTdataset, with (a-b) no batch normalization in the generator, and (c-d) no batch normalization in eitherthe generator or the discriminator.
Figure 7:	(a) Two manifolds X and Y have identical geometric structures, but different positions inspace; (b) CrossLID score decreases as X and Y moving closer to each other (decreasing d); (c) Thesame manifolds (as in (a)) but having different orientations (rotated with respect to each other); (d)CrossLID score decreases as the relative orientation angle Î¸ decreases.
Figure 8:	Test results for inter-class mode dropping: The CrossLID scores (left), Inception scores(middle) and FID scores (right) on varying numbers of unique classes in the datasets.
Figure 9:	Evaluation of Geometry score on sample quality for DCGAN models trained on MNIST(left), CIFAR-10 (middle) and SVHN (right). After each epoch of training (for the first 50 epochs),we compute the Geometry Score over 2000 samples generated by the network.
Figure 10:	Comparison of CrossLID scores estimated in the pixel space versus those estimated inthe deep feature space, on the MNIST dataset, against small-scale salt-and-pepper (impulse) noise(left), translations (middle) and rotations (right).
Figure 11: (a-e) 25 randomly selected DCGAN generated CIFAR-10 images and the CrossLIDscore of the DCGAN model after epoch 1, 5, 10, 20, and 49; (f) Real CIFAR-10 images and theCrossLID(XI ; XI) score.
Figure 12:	(a-e) 16 randomly selected DCGAN generated MNIST images and the CrossLIDscore of the DCGAN model after epoch 1, 4, 10, 20, and 50; (f) Real MNIST images and theCrossLID(XI ; XI) score.
Figure 13:	Left: Scatter plot of FID and CrossLID scores of different models over the CIFAR10dataset. Right: Scatter plot of FID and CrossLID ranks of different models over the CIFAR10dataset.
Figure 14: Left: Some representative CIFAR10 images after the application of different percentageof Gaussian noise. Right: Normalized CrossLID, IS, and FID under different levels of Gaussiannoise.
Figure 15: Normalized CrossLID, IS, and FID scores under different levels of Gaussian noise onMNIST (Left) and SVHN (Right) datasets.
Figure 16: Left: representative CIFAR10 images after the application of different percentages ofsalt-and-pepper noise. Right: Normalized CrossLID, IS, and FID scores under low levels of salt-and-pepper noise.
Figure 17:	The CrossLID, Inception and FID scores of images with 2% Gaussian noise (left) andimages with centers occluded by black rectangles (right).
Figure 18:	Left: Some representative CIFAR10 images with 25% and 50% salt-and-pepper noise.
Figure 19:	Left: Running time of CrossLID, Inception score (IS) and FID over different sample sizeson the CIFAR-10 dataset. Right: CrossLID scores estimated using different neighborhood size k,for images generated at different epochs by a DCGAN on the CIFAR-10 dataset.
Figure 20:	CrossLID scores estimated using discriminator features, over different epochs of DC-GAN training on MNIST, SVHN and CIFAR-10 datasets. Features of the third convolution layerof the discriminator network were used to compute the average CrossLID score of 20k generatedimages.
Figure 21:	MNIST images generated at epoch 20, 30 and 50 (50 epochs in total) by DCGAN mod-els without batch normalization layers in both the generator and discriminator. Top row: Imagesgenerated by a DCGAN model trained using standard training. Bottom row: Images generated by aDCGAN model trained with our proposed oversampling strategy.
Figure 22: MNIST images generated at epoch 20, 30 and 50 (50 epochs in total) by DCGAN modelswithout batch normalization layers in the discriminator (the generator network still has batch nor-malization). Top row: Images generated by a DCGAN model trained using standard training. Bottomrow: Images generated by a DCGAN model trained with our proposed oversampling strategy.
Figure 23: Top row: Images generated by standard DCGAN training (without our proposed over-sampling) on the three datasets (a-c). Bottom row: Images generated by DCGANs trained with ourproposed oversampling strategy on the three datasets (d-f).
