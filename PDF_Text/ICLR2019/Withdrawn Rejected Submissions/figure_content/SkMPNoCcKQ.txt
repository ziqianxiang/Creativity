Figure 1: Generative network with dynamic layer. The dashed arrow indicates the trainable param-eters4.3	The Dynamic LayerWe now focus on how to learn a matrix A and a function C from a finite sequence yN ∈ Rd×Nof a visual process such that it can be described by Eq. (3). To this end, recall that, as discussed inSection 4.1, we only need to consider the joint probability of two succeeding observed frames. Thefirst step is thus to generate a training set of frame pairs from yN as {s1, . . . , sN-1}, wherest = yt> yt>+1>	(12)denotes a vectorized pair of frames. We treat the samples as realizations of the random variable sand are looking for an architecture to learn the function C and a matrix A such that the probabilitydistribution of the random variableC(h1)> C(h2)>>,	(13)where h1, h2 have the joint distribution described by Eq. (10), coincides with the probability distri-bution of s, i.e.
Figure 2: Synthesis result for sequences of MNIST digits with VAE夕 S<**767∕√Γ^7F^765	Experiments5.1	OverviewDue to its impressive results on natural images, we employ the generator of the Deep ConvolutionalGAN (DCGAN, Radford et al. (2015)) as the foundation for implementing the observer functionCη . We use it in combination with an affine layer at the input. This layer serves three purposes.
Figure 3: Synthesis result for NORB sequences (a) and learned fixed point (b)Figure 4: Synthesis result for sequences of the UCLA-50 dataset with Wasserstein GANtwo explanations for this can be identified. On the one hand, it is possible that the assumptionsof Proposition 1 are not fulfilled, and no diffeomorphism, i.e. a bijective mapping exists from theimage manifold to the embedded space. In that case, the best we can do is finding a non-injectivelocal diffeomorphism that assigns more than one point on the image manifold to a point in the em-bedded space. On the other hand, it is thinkable, that an actual diffeomorphism exists, but that theeuclidean distance implicitly minimized by the VAE is a bad estimation of the geodesic distance onthe manifold. Fig. 3b depicts the learned fixed point of the transition function. It can be thought ofas a rotationally invariant structure under limited exposure of light from above.
Figure 4: Synthesis result for sequences of the UCLA-50 dataset with Wasserstein GANtwo explanations for this can be identified. On the one hand, it is possible that the assumptionsof Proposition 1 are not fulfilled, and no diffeomorphism, i.e. a bijective mapping exists from theimage manifold to the embedded space. In that case, the best we can do is finding a non-injectivelocal diffeomorphism that assigns more than one point on the image manifold to a point in the em-bedded space. On the other hand, it is thinkable, that an actual diffeomorphism exists, but that theeuclidean distance implicitly minimized by the VAE is a bad estimation of the geodesic distance onthe manifold. Fig. 3b depicts the learned fixed point of the transition function. It can be thought ofas a rotationally invariant structure under limited exposure of light from above.
Figure 5: Synthesis result for RGB sequences. Frames are rescaled to match the original aspect ratio9Under review as a conference paper at ICLR 2019ReferencesBijan Afsari and Rene Vidal. The alignment distance on spaces of linear dynamical systems. InDecision and Control (CDC), 2013 IEEE 52nd Annual Conference on, pp. 1162-1167. IEEE,2013.
