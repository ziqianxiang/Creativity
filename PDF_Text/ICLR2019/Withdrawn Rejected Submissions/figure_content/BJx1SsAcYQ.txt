Figure 1: Quantizing the weights introduces considerable additional noise in the learning pro-cess. Plotted is the cosine of the average angular error between the weight change called for bySGD with momentum, and the actual weight change taken after quantizing. Cosine similarity of1.0 corresponds to an fp32 network and the absence of discretization-induced gradient noise, i.e.
Figure 2: The ResNet-18 4-bit solution after fine-tuning for 110 epochs was located relativelyclose to the initial high-precision solution used to initialize the network, indicating that trainingfrom scratch is unnecessary. Plotted is the mean, over all neurons in a ResNet-18 network, of thecosine similarity between the weights at the beginning of training from scratch, and the weightsat epoch 110 (left bar). The minimum and maximum similarity measure is 0 and 1, respectively.
