Figure 1: Two illustrative edit sequences. History A and B share the same State 2, but based on thehistories, it is more likely that History A will continue by modifying the call to foo to take an extraargument and History B will continue by modifying the definition of foo to take only one argument.
Figure 2: (a) Explicit and (b) implicit representations of a sequence of edits transforming ‘BACA’ to‘BABBCACC’. <S> and <E> are special start and end tokens.
Figure 3: Diagrams of (a) baseline explicit model and (b, c) implicit attention model.
Figure 4: (a)-(c) Time required to process sequences during training, across n-gram problems withdifferent numbers of insertions (10, 50, 100). Note that the y-axis scale changes across plots. (d)Token-level accuracy on the real dataset when limiting predictions to the contexts where the model ismost confident. See text for more details.
Figure 5: Zooming in on performance of illustrative synthetic problems. Left: Two example editsequences (shortened for illustrative purposes). Each row is a timestep, and the underlined charactermarks where the insertion was made. Right: Dev accuracy vs timestep of prediction averaged overthe dev set.
Figure 6: Models.
