Figure 1: We study the modular co-evolution of control and morphology where a collection ofprimitive agents self-assemble to form complex collectives to perform given tasks. (a) Each primitiveagent is a limb containing a cylindrical body and a configurable motor. These limbs can connectwith each other using the attached motor as a joint. (b) We illustrate our dynamic agents in fourenvironments / tasks: standing up, locomotion, manipulation (pushing), and sumo wrestling. Seeproject videos at https://doubleblindICLR19.github.io/self-assembly/.
Figure 2: High-level visualization of our method. A set of primitive ’limbs’ learn to self-assembleinto morphologies where each limb is represented by a neural network linked via graph of physicaledges. The inset on right shows the message-passing diagram for each node. Project videosat https://doubleblindICLR19.github.io/self-assembly/.
Figure 3: Training of self-assembling agents: (a) The training performance of different methods forjoint training of control and morphology for the task of learning to stand up. The generalizationperformance of these policies across new scenarios is shown in Table 1. (b) The gradual co-evolutionof controller as well as the morphology of self-assembling agents over the course of training.
Figure 4: Training self-assembling agents: We show the performance of different methods for jointtraining of control and morphology for three tasks: standing up in the presence of wind and randompush-n-pulls (left), locomotion in bumpy terrain (center) and manipulation (pushing) of two objects(right). These policies generalize to novel scenarios as shown in respective tables.
Figure 5:	The performance of Monolithic Policy w/ Fixed Graph baseline as the number of limbsvaries in the two tasks: standing up (left) and locomotion (right). This shows that the monolithicbaseline works well with less (1-3 limbs), but fails with 6 limbs during training.
Figure 6:	Generalization for the task of Standing Up: Performance of different methods acrossnovel scenarios without any finetuning.
Figure 7:	Generalization for the task of Standing Up w/ Wind: Performance of different methodsacross novel scenarios without any finetuning.
Figure 8:	Generalization for the task of Locomotion: Performance of different methods acrossnovel scenarios without any finetuning.
Figure 9:	Generalization for the task of Manipulation: Performance of different methods acrossnovel scenarios without any finetuning.
