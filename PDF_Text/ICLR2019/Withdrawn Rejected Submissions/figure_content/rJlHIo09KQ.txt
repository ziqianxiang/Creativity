Figure 1: First five features (100 steps) learned by a linear model in different settings. From left toright: (1) only slowness loss optimized, no constraints, (2) slowness loss with enforced unit variance,(3) slowness loss with enforced whitening, (4) closed form solution. The ∆-values indicate slowness(lower is slower).
Figure 2: Covariance matrices for five outputs in different settings. (1) slowness loss without con-straints leads to nearly constant signals with (co)variances close to zero, (2) unit variance enforcedleads to highly correlated output signals, (3) & (4) (approximate) whitening and the closed formsolution show fully decorrelated output signals (identity covariance).
Figure 3: Three samples from the anvil-dataset in different x, y positions and rotational angle Φ.
Figure 4: Spread of the predicted x- and y-position of the anvil-dataset for a trained network (4a)and a randomly initialized network (4b). RMSE for the trained network on unseen data are 9% and8% for x- and y- position respectively. RMSE for the random network on unseen data are 21% and21%.
Figure 5: The embedded object from the NORB dataset. Samples differ in azimuth, elevation andlighting.
Figure 6: Cylindrical embedding of NORB plane with azimuth colored. 6a and 6b show the embed-ded training data from the front and the side of the cylinder respectively, while 6c and 6d show thetest data for the same configuration. Circumference of the cylinder encodes the rotation of the plane.
Figure 7: Cylindrical embedding of NORB plane with elevation colored. 7a and 7b show the em-bedded training data from the front and the side of the cylinder respectively, while 7c and 7d showthe test data for the same configuration. Height on the cylinder encodes the photograph’s elevationangle.
Figure 8: The mean squared velocity (unnormalized ∆ value) per feature for an increasing numberof power iterations, averaged over 10 trials. For no power iterations, the velocity is close to 0, butfor a too small positive number of power iterations the optimization becomes unstable and results insub-optimal performance.
Figure 9: The average covariance (auto-variances not included) for an increasing number of poweriterations, averaged over 10 trials. Without whitening, the covariance is close to 1, but the featuresquickly become decorrelated when the number of iterations is increased.
