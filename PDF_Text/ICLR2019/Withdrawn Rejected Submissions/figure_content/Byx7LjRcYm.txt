Figure 1: The architecture of our spatial-temporal model. We preprocess each video by divided itinto images and extract features by putting those images into CNN. Then the model calculate thespatial attention and weights the feature cube. After this step, the weighted feature cube will be putinto the main networks which are LSTMs. Via LSTMs, the model gets the outputs of the hiddenlayer.Then in order to gain the final result, temporal attention will be produced and weights thoseoutputs. In the end, our model will give the classification of action in the video.
Figure 2: The schematic diagram of extracting feature. We use Vgg19 to extract the feature fromthe RGB images of the video. After getting the feature cubes, we flatten it into 2D matrix.
Figure 3: The detailed architecture of the model. This figure shows the overall architecture of ourmodel, and there are three main parts in the model, which are spatial attention weight part , LSTMnetworks and temporal attention weight part.
Figure 4: The schematic diagram of spatial attention. This is an Assumed effect of the soft attentionmechanism in the video frame. The figure on the upper left is the visualization map of soft attention,the more lighting the part’s color is, the more attention is pay to this part. So when combine withthe corresponding video frame on the lower left which shows the scene that a man raise up his hand,the model should focus on these parts which in this frame should the man and his hand.
Figure 5: The schematic diagram of temporal attention. This picture describes how the temporalattention works on the model. For the sequence of the video frames in the figure, they demonstratethe action ’hugging’, but only two of the five frames are relevant to ’hugging’, so our model shouldselect these two frames and pay more attention on it. The color under each frame is attached to theimportance of the frames, more lighting denotes more importance.
Figure 6: The spatial attention in the frame. This is the frame in the video clips which shows theaction ’hit’. After putting the video frames into our model, we got the spatial attention weights ofthis frame, then we visualized the spatial attention. It’s very obviously for us that our model focuson the man and his hand in the picture.
Figure 7: The temporal attention weight in frames. This is the temporal attention curve of the action’brush hair’. Our model select the key frames that is relevant to the action.
