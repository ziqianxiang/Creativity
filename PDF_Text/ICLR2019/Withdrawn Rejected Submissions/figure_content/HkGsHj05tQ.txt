Figure 1: Illustration of BN’s cost, operations, bottleneck, and opportunity: (a) iterations per secondfor training various models with or without BN, Model C,D,E are defined in Table 2; (b) usualoptimization of the reduction operation using adder tree; (c) the computational graph of BN in theforward pass (upper) and backward pass (lower); (d) the computation graph ofBN using few data forstatistics’ estimation in forward pass (upper) and backward pass (lower). x is neuronal activations,μ and σ denote the mean and standard deviation of X within one batch, respectively, and P is thesummation operation.
Figure 2: The influence of BN configuration on deep models: (a) & (b) average mean & varianceof each layer during the first training epoch; (c) loss curve during the first training epoch. Here wetrain a 30-layer CNN on CIFAR-10. For “without BN” curve, BN is only applied to the last Convlayer; For “BN” curve, BN is applied to all Conv layers; For “intermittent BN” curve, BN is appliedto layer 5k + 4, where k ∈ {0, 1, 2, 3, 4, 5}.
Figure 3: Illustration of approaches: (a) Naive Sampling; (b) Batch Sampling; (c) Feature Sampling;(d) Virtual Dataset Normalization. ‘H' and 'W' are the height and width of FMs, respectively, ‘C' isthe number of FMs for current layer, and 'N' denotes the number of samples in current batch. Theorange and yellow rectangles in (a)-(c) represent the sampled data and those in (d) are the createdvirtual sample(s). The yellow data are used to estimate the statistics for current FM.
Figure 4: Top-1 validation accuracy of ResNet-56 on CIFAR-10 (left) & CIFAR-100 (right).
Figure 5:	Training curves of ResNet56 on CIFAR-10.
Figure 6:	Training curves of ResNet18 (left) and DenseNet121 (right) on ImageNet.
Figure 7: Estimation error distribution.
Figure 8: Inter-layer correlation between estimation errors. Both x &y axes denote layer index.
Figure 9: Efficiency evaluation: (a) BN speedup; (b) overall training speedup; (C) influence ofsampling regularity (ImageNet, ReSNet-18, FS-1/32-3.1%) on overall training speed.
Figure 10: Sampling ratio v.s. speedup.
Figure 11: Influence of decay ratefor moving average.
Figure 12: BN net-work for profiling.
Figure 13: Training curvesin micro-BN scenario. (Im-ageNet, ResNet 18)16Under review as a conference paper at ICLR 2019Appendix G Organization of the whole paperFigure 14: Illustration of the paper,s organization. The Green and Purple markers (round circle witha star in the center) represent whether the effectiveness is preserved by reducing inter-layer or intra-layer correlation (Green: inter-layer; Purple: intra-layer). Moreover, the consideration of regular &static execution pattern is applied to all approaches.
Figure 14: Illustration of the paper,s organization. The Green and Purple markers (round circle witha star in the center) represent whether the effectiveness is preserved by reducing inter-layer or intra-layer correlation (Green: inter-layer; Purple: intra-layer). Moreover, the consideration of regular &static execution pattern is applied to all approaches.
