Figure 1: The agent-user interactions in MDP: the recommender agent (RA) generates a list ofcandidate items after each user click (green) or purchase (red).
Figure 2: IRN architecture: a) the imagination core (IC) predicts the next time step and then generatesthe imagined trajectories T; b) the trajectory manager (TM) employs various planning strategies (e.g.,depth-m here) to control the granularity of T;c) the imagination-augmented executor (IAE) optimizesthe network using the internal imagination data and external rewarding data (e.g., purchases).
Figure 3: Possibility of being stuck in an non-optimal policy with varying reward sparsity for IRN.
Figure 4: Purchase performance comparison on Recall@5 and MRR@5 metrics. (a, b) Results underthe cold-start scenarios. (c, d) Results in online learning.
