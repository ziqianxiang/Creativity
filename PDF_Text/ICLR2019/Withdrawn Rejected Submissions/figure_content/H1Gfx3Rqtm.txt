Figure 1: An illustrative example showing our label assignment policy. At t = 0, the documentxi is placed at the root label and the policy would decide if xi should be placed to its two adjacent(denoted by purple) labels. At t = 1, xi is placed at label 1, which adds another three adjacentlabels as the candidates. At t = 6, the stop action is taken and the label assignment process is thusterminated. We then take all the labels where xi has been placed (a sub-tree consisting of label 0, 1,..., 5) as xiâ€™s document labels.
Figure 2: The architecture of the proposed framework HiLAP. One CNN model (Kim, 2014) isused as the base model for illustration. The document embedding ed generated by the base model iscombined with the label embedding lt and used as the state representation st, based on which actionsare taken by the policy network.
Figure 3: Performance comparison of different frameworks using the same base model as input. Weimproved HMCN + HAN by removing its batch normalization.
Figure 4: Level-based and popularity-based Macro-F1 gains compared to bow-CNN (Johnson &Zhang, 2014) on the NYT (Sandhaus, 2008) dataset. We show the per-level gains on the left, inwhich L1, L2, and L3 denote the levels of the hierarchy. We divide the labels into three equal sizedcategories, namely P1, P2, and P3, in a descending order based on their number of samples, andshow their gains on the right.
