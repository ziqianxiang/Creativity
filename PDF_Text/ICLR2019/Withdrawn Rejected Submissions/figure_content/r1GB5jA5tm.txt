Figure 1: Block diagram of ASAL, where (Xk, Yk) with (x, y) is the training set at cycle k, Î¸ is theclassifier, Z the latent variable, G the generator, X the synthetic samples, F the feature extractor, fthe features, P the pool and NN the nearest neighbour method.
Figure 2: The rows show either generated or matched samples using different feature sets for MNIST- ten classes. The brackets denote (label id / sample id).
Figure 3: Test accuracy and entropy for different methods on MNIST - two classes.
Figure 4: Test accuracy of ASAL on MNIST and CIFAR-10.
Figure 5: The rows show either generated or matched samples using different feature sets for CIFAR-10 - ten classes. The brackets denote (label id / sample id).
Figure 6: Test accuracy of three different classification benchmarks constructed from CelebA. Thedata set is separated in images where the attribute is present or absent.
Figure 7:	Run-time of maximal entropy sampling and ASAL to select 10 new samples in one ALcycle with respect to the data set size. The numbers are established using the setup described forCelebA running on a Nvidia GeForce GTX TITAN X GPU.
Figure 8:	ASAL is more efficient for selecting new samples than maximal entropy sampling. How-ever, it requires pre-processing time. These diagrams show the transition point (number of AL cycleswhen ASAL gets more efficient than maximum entropy sampling) with respect to the data set size.
Figure 9:	Label distribution for uncertainty sampling using maximum entropy and random samplingfor MNIST - two classes using different uncertainty measures and loss functions. The tick on theright show the true label distribution in the pool. The label distribution of the training set, assem-bled with random sampling (top), converges to the true label distribution of the pool. Conversely,uncertainty sampling leads to a training set that contains more frequently the label 5 than 7 com-pared to the pool that contains 7 more frequently. Apparently, images with the digit 5 lead to higheruncertainty of the used classifier.
Figure 10: Test accuracy on MNIST - two classes of a fully supervised model, for random sam-pling, uncertainty sampling and different ASALs using different GANs, uncertainty measures andloss functions. ASAL with WGAN-GP (bottom) clearly exceed the performance of ASAL usingDCGAN (top). Maximum entropy sampling and using the cross entropy loss lead to the setup (10d)that approaches the fully-supervised model with the fewest samples and reaches the smallest gap forall ASAl using 500 labelled samples.
Figure 11:	Label distribution for active learning using different matching strategies, uncertaintymeasures and GANs for MNIST - two classes. The ticks on the right show the true label distributionin the pool. ASAL using WGAN-GP (third and fourth row) reaches a label distribution of the train-ing data that is similar to the true label distribution in the pool. Conversely, ASAL using DCGAN(first and second row) leads to a training set that contains almost three times as many images with thedigit 7 than digit 5. Most likely, the DCGAN is responsible for this behaviour because we alreadyobserved that it produces the digit 7 more frequently than the digit 5, see Fig. 32a.
Figure 12:	Average entropy of images that are selected and added to the training set for MNIST - twoclasses using different GANs, uncertainty measures and loss functions. All figures show that ASALselects samples from the pool that have a higher entropy than randomly sampled images. However,maximum entropy sampling and WGAN-GP (12d) lead to the largest entropy gap between selectedand randomly sampled images. Maximum entropy sampling (right column) results in smaller av-erage entropy of the classifier than minimum distance sampling (left column) because we use thecross-entropy loss that directly optimizes for small entropy, opposed to the hinge loss that minimizesthe distance to the separating hyper-plane.
Figure 13: Comparison of the agreement accuracy between manual annotations and matched labels.
Figure 14: Test accuracy on MNIST - ten classes of a fully supervised model, for random sampling,uncertainty sampling and different ASALs using two different GANs. Selecting new images us-ing random samples exceeds the performance of the proposed strategy when using the DCGAN.
Figure 15: Average entropy of images that are selected and added to the training set for MNIST - tenclasses using different GANs. Both figures show that at the beginning ASAL selects images withhigher entropy than random sampling. In average WGAN-GP leads to a larger gap than DCGAN.
Figure 16: Label distribution for uncertainty sampling using maximum entropy, random samplingand active learning using different matching strategies and GANs for MNIST - ten classes. Thetick on the right show the true label distribution in the pool. Note the different scaling of the y-axis. Random sampling converges to the true label distribution in the pool and maximum entropysampling leads to a training set with a higher ration of certain digits (7,8,9) or lower (0,1,4,6) thanthe pool. Similarly, ASAL using WGAN-GP (bottom row) selects certain digits more frequentlythan others. Conversely, ASAL using DCGAN (top row) leads to a training set that contains 30%images with the digit 1. Most likely, the DCGAN is responsible for this behaviour because wealready observed that it produces the digit 1 more frequently than any other digit, see Fig. 33a.
Figure 17: Test accuracy on USPS - two classes but trained on MNIST - two classes of a fullysupervised model, for random sampling, uncertainty sampling and different ASALs using differentGANs, uncertainty measures and loss functions. Uncertainty sampling performs worse than anyother strategy because it aggressively trains the classifier for the samples present in the pool andgeneralizes less. Random sampling and ASAL tend to generalize better by respecting the true datadistribution either through random sampling or using a pretrained GAN on the data set to find newsamples.
Figure 18: Test accuracy on USPS - ten classes but trained on MNIST - ten classes of a fully super-vised model, for random sampling, uncertainty sampling and different ASALs using two differentGANs. Maximum entropy sampling for ten classes exceeds the quality of any other method Com-pared to binary classification where it performed worst, see Fig. 17. The more elaborate LeNet andusing more classes and samples to train lead to a classifier that generalizes well. The active learningstrategies using WGAN-GP exceed the quality of random sampling. ASAL-Disc. even outperformsthe fully supervised mode. ASAL using DCGAN performs comparable to random sampling.
Figure 19: Label distribution for uncertainty sampling using maximum entropy and random sam-pling for CIFAR-10 - two classes using different uncertainty measures and loss functions.The labeldistribution of the training set of all strategies converges to the true label distribution of the pool.
Figure 20:	Label distribution for active learning with minimum distance sample generation and theHinge loss, using different matching strategies and GANs for CIFAR-10 - two classes. All setupsassemble training sets containing the more image with the label horse than automobile.
Figure 21:	Label distribution for active learning with maximum entropy sample generation and thecross-entropy loss, using different matching strategies and GANs for CIFAR-10 - two classes.
Figure 22: Validation accuracy on CIFAR-10 - two classes of a fully supervised model, for randomsampling, uncertainty sampling and different ASALs using different GANs. ASAL-AUtoencoderleads to the best performance. ASAL-Disc. using Resnet-WGAN-CT performs worse that any otherstrategy because the sample matching using is unable to retrieve high entropy samples from the pool,see Fig. 23.
Figure 23:	Average entropy of images that are selected and added to the training set for CIFAR-10- two classes using different GANs. The mean entropy of the random sampling and the proposedmethod show hardly any difference. However, for maximum entropy sampling at least at the begin-ning ASAL selects images with higher entropy than random sampling.
Figure 24:	Validation accuracy on CIFAR-10 - ten classes of a fully supervised model, for randomsampling, uncertainty sampling and different ASALs using different GANs. The proposed methodperforms slightly worse than random sampling independent of the sample matching of GAN.
Figure 25:	Average entropy of images that are selected and added to the training set for CIFAR-10- ten classes using different GANs. There is hardly any difference for random sampling and ASALin the entropy of newly added samples. Only at the beginning, random sampling retrieves sampleswith slightly higher entropy.
Figure 26: Label distribution for uncertainty sampling using maximum entropy and random sam-pling for CIFAR-10 - ten classes. Random sampling converges to the true label distribution in thepool. Maximum entropy sampling selects most frequently cat, dog, bird, deer and least frequentlyautomobile, ship, truck to exceed the classification quality of random sampling.
Figure 27: Label distribution for active learning using different matching strategies, uncertaintymeasures and GANs for CIFAR-10 - ten classes. Exactly the classes cat, dog that are most com-mon in the training set of uncertainty sampling are less common in the data sets of most setups.
Figure 29: The rows show generated and matched images for MNIST - ten classes using WGAN-GP.
Figure 28: The first row shows synthetic digits and the other the closest samples from the pool usingdifferent features for comparison. The numbers above the image denote the label and image id.
Figure 30: The rows show generated and matched images for CIFAR-10 - two classes using WGAN-GP. The images have a reasonable quality and all matching strategies retrieve images that are visuallyclose or show the same class.
Figure 31: The rows show generated and matched images for CIFAR-10 - ten classes using WGAN-GP. Most of the generated images achieve only a moderate quality and even the closest samples fromthe pool have a high perceptual visual distance or assign images that show non matching classes, seelast column where the images have a similar appearance but an appropriate label for the generatedimages would be horse but the selected samples show airplane and ship.
Figure 32:	Comparison of random and uncertain MNIST - two classes. The samples are generatedusing different GANs. The random samples are visually more appealing and identifying the labelis easier than for the uncertain samples. WGAN-GP generate images for both digits equally likely,whereas DCGAN most frequently generates images showing the digit 7.
Figure 33:	Comparison of random and uncertain MNIST - ten classes samples. The samples aregenerated using different GANs. The random samples are visually more appealing and identifyingthe label is easier than for the uncertain samples. WGAN-GP uniformly generates images for alldigits, whereas DCGAN mainly generates images showing the digit 1.
Figure 34: Comparison of random and uncertain samples for CIFAR-10 - two classes using maxi-mum entropy. The samples are generated using different GANs. The residual GANs (bottom row)produce more visually appealing samples than the other GANs. For most of these images it wouldbe possible to identify whether the image shows a horse or automobile.
Figure 35: Comparison of random and uncertain samples for CIFAR-10 - ten classes using maximumentropy. The samples are generated using different GANs. The residual GANs (bottom row) producemore visually appealing samples than the other GANs. Although, the quality of the random imagesis higher than of the uncertain images, annotating with high confidence is still very difficult.
