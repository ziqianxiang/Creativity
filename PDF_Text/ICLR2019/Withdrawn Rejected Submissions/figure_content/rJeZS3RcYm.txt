Figure 1: Plot of the change in true class probability when descending in a random direction in pixelspace (left) and DCT space (right) at step size . The average change (purple line) is almost linear inwith the slope being steeper when the direction is sampled in DCT space. Furthermore, 98% of thedirections sampled in DCT space have either q or -q descending, while only 73% are descendingin pixel space.
Figure 2: Comparison of success rate versus number of model queries for untargeted (left) andtargeted (right) attacks. Horizontal axis shows queries in log scale. For boundary attack and LFBA,success is defined as achieving a perturbation L2-norm of 10 or less. Note that both SimBA andSimBA-DCT achieve a high success rate very quickly.
Figure 3: Histogram of queries required until a successful model attack (over 1000 target images).
Figure 4: Comparison of success rate versus number of model queries across different networkarchitectures for untargeted SimBA (left) and SimBA-DCT (right) attacks. For all networks, SimBA-DCT is more query efficient by at least a factor of 2. DenseNet is the most vulnerable against bothattacks, admitting a success rate of almost 100% after only 10,000 queries for SimBA and 4000queries for SimBA-DCT. Inception v3 is much more difficult to attack for both methods.
Figure 5: Randomly selected images before andafter adversarial perturbation by SimBA, SimBA-DCT and boundary attack. The constructed per-turbation is imperceptible for all three methods,but the L2-norm for SimBA and SimBA-DCT issignificantly lower than boundary attack across allimages, despite allowing boundary attack to make60,000 queries. In comparison, our methods arecapable of constructing an adversarial example inas few as 36 queries. Zoom in for detail.
Figure 6: Screenshot of Google Cloud Vision labeling results on a randomly chosen image beforeand after adversarial perturbation. While the labels for the adversarial image are still reasonable, theconcept bird has been completely removed. See Supplementary Material for additional samples.
Figure 7: Plot of success rate across number ofmodel queries for Google Cloud Vision attack.
Figure S1: Additional adversarial images on Google Cloud Vision.
