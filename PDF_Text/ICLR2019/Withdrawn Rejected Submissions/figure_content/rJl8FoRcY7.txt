Figure 1: Evolution of full uni-, bi-, and tri-modal VAEs comprising all modality permutationsThe specific objective of VAEs is the maximization of the marginal distribution p(a) =JPθ(a∣z)p(z) da. Because this distribution is intractable, the model is instead trained via Stochas-tic gradient variational Bayes (SGVB) by maximizing the evidence lower bound (ELBO) L of themarginal log-likelihood log p(a) := La asLa≥L = - DκL(qφ(z∣a)∣∣p(z))+ Eqφ(z∣a) log(pθ(a∣z)).	(1)、----------V----------' 、----------V---------'Regularization	ReconstructionThis approach proposed by Kingma & Welling (2013) is used in settings where only a single modal-ity a is present in order to find a latent encoding z (c.f. Figure 1 (left)).
Figure 2: Top-Left: Depiction of naive mixed MNIST (m-MNIST) vs. proposed entangled MNIST(e-MNIST). m-MNIST is pairwise plotted with the closest match of MNIST digits according to themean-squared-error. The corresponding fashion-MNIST samples show no continuity nor correlation(despite the intended class correlation). e-MNIST shows the desired entanglement for changes of asingle latent space factor. Top-Right: Latent space of the CVAE for the modalities a (MNIST) andb (fashion-MNIST). Bottom: Latent space of a trained JMVAE (c.f. Sec. 6.1.4). m-MNIST showsclear orthogonalization between modalities of the same class and segregation between classes (col-orization is wrt. the CVAE legend). e-MNIST shows a coherently learned latent space between theuni- and multi-modal encoders. Thus, the JMVAE learns the correlation inside the dataset suffi-ciently (La,b|me-MNIST = -204.48 vs. La,b|e-MNIST = -199.23).
Figure 3: MoG input signals with for the modalities a and b. The depicted observations are sampledfor the corresponding modality for each class.
Figure 4: Latent space embeddings of the bi-modal MoG dataset by the three encoder networks ofthe M2VAE. Classes and ELBO colorization is depicted for various parameter settings of β* and a.
Figure 6: From top to bottom: JMVAE-Zero, tVAE, andM2VAE. Left: Latent space representationwith class colorization. Right: Corresponding colorization of the latent space for every Z obtainedby auto re-encoding. White dots denote randomly drawn seeds which auto re-encoding steps arerepresented by the black trajectory. See Fig. 5 for legends.
Figure 7: From top to bottom: JMVAE-Zero, tVAE, and M2VAE. Left: Latent space representationWith class colorization. Right: Reconstruction from latent space by applying the correspondingdecoder netWorks. z is sampled linearly Within 2σ of the prior for all figures.
