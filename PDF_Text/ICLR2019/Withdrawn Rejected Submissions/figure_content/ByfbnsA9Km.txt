Figure 1: Orange and blue points represent the data from two different classes in R2 . Cross-entropyminimization for a linear classifier on the given training points leads to the decision boundary shownwith the solid line, which attains a very poor margin and is almost orthogonal to the solution givenby the SVM.
Figure 2: Classification boundaries obtained using differential training and cross-entropy minimiza-tion. The margin recovered by cross-entropy minimization is worse than differential training evenwhen the training dataset is not low-dimensional.
Figure 3: The activations feeding into the soft-max layer could be considered as the features for alinear classifier. Plot shows the cumulative variance explained for these features as a function ofthe number of principle components used. Almost all the variance in the features is captured by thefirst 20 principle components out of 84, which shows that the input to the soft-max layer residespredominantly in a low-dimensional subspace.
Figure 4: Stationary points of function f.
