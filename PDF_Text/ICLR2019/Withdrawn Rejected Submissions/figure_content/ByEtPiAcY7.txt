Figure 1: An example of the various rules extracted for the first feature. The first image representsthe weights of the neruon and the following three are rules of decreasing complexity explaining theneuron. Here grey indicates that the input feature is not included in the M-of-N rule, white indicates apositive literal, and black indicates a negative literalthe weights are filtered out by the rules. The most complex rule is a 5-of-13 rule which has a 0.025error, or in other words the output of the rule agrees with the network 97.5% of the time. Adding amild penalty to complexity changes the optimal rule to the much simpler 3-of-4 rule but raises theerror to 0.043. Finally a heavy penalty to complexity produces the trivial 1-of-1 rule which has thesignificantly higher error of 0.134	Experimental Results4.1	DNA promoterIn order to demonstrate the results on a simple network known to be amenable to rule extraction weapply the technique to the classic example of the DNA promoter dataset. Training a feed forwardnetwork with a single hidden layer of 100 nodes We find that, like we will see with the FashionMNIST dataset, the relationship between complexity and error in the first layer is exponential,suggesting an ideal complexity/error tradeoff (See Fig 2). Furthermore, in the output layer we findthat the rule 1 - of - {H39, H80} gives 100% fidelity to the network. Since the splits for the hiddenlayer are defined only by the information gain with respect to the output we can describe each ofthe literals in our 1-of-2 rule with an M-of-N rule extracted from the input layer. Extracting withno complexity penalty, the rules in question are of the form 64-of-119 for the variable H39 which
Figure 2: The Complexity/Error relationship for rules extracted from the first layer of a network witha single hidden layer trained on the DNA promoter dataset4.2	FASHION MNISTIn order to examine the rule extraction landscape of a neural network trained on a practical example,we tested the layerwise rule extraction search on a basic CNN trained on fashion MNIST in tensorflow.
Figure 3: The Complexity/Error relationship for rules extracted from each layer of a CNN.
