Figure 1: The schematic of a Contextual Recurrent Convolutional Network (CRCN). Check Sec-tion 3.1 for details.
Figure 2: The details of a VGG-style context-gating recurrent model.
Figure 3: The schematic of our proposed con-textual module. Layer k denotes the bottom-uplayer and layer h(k) denotes the top-down layeraligned with the size of k layer. The left blackarrow shows the feed-forward pipeline.
Figure 4: The example images and results of noise image classification experiment. Upper fourimages show an example of images with different levels of Gaussian noise added. From left toright, the standard deviations are 0, 10, 30, 50, respectively. Lower right figure shows the increasedpercentage of our unroll-2-times model on top-1 noise image accuracy compared with feedforwardmodel. Lower left figure shows the adversarial attack result. The fooling rate is measured by theabsolute accuracy drop when adversarial attack is performed on the model. We use standard FGSMattack on all ImageNet validation images. The blue line shows the fooling rate of our unroll-2-timesmodel, red line shows the feed-forward model and the orange line shows the model proposed by (Liet al., 2018). As the attack gets stronger, our model shows more robustness.
Figure 5: The results of t-SNE visualization. Upper four sub-figures shows the result of VGG16. (a)shows the result of conv4 layer without noise. (b) shows conv4 layer with noise level 30. (c) showsFC layer without noise. (d) shows FC layer with noise level 30.Lower four sub-figures shows thecorresponding results of VGG-CRCN-2 model.
Figure 6: Examples of different task. Left: An example of image occlusion task. We quantified thescale of occluders in the image. Right: An example of Adversarial Attack noise. We can see thenoise is not obvious to the human eyes but can lead a significant influence to the neural network. Weused Fast Gradient Sign Non-target to generate the noise. The left is the original image and the rightone is the image adding the noise.
