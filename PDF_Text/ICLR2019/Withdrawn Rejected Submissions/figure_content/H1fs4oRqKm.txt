Figure 1: Blurred boundaries of predicted disparity by Godard et al. (2017) and our result. (a) inputimage (b) predicted left disparity (c) post-processed disparity(d) our result. To eliminate the artifactsand blurred patterns, Godard et al weighted sum the disparity of the input image and flipped disparityof the flipped input image at the cost of doubling the computation. However, there still exists blurredpatterns in the post-processed disparity. Contrary to Godard et al. as shown in (b)(c), our result(d)shows clear boundaries with less artifacts and higher accuracyOne straight-forward way to train deep depth estimation models is to use ground truth depth imagesas the supervision signals Eigen et al. (2014). However, supervised deep learning method is eagerfor massive data with ground truth. Collecting large datasets with ground truth depth in varied realscenarios is challenge and expensive. Instead, training using stereo images without depth label isan alternative option. Godard et al. (2017) proposed a method to exploit the left-right consistencyof stereo images to tackle the monocular depth estimation, which achieved quite promising results.
Figure 2: Network architecture. From left to Right: Naive unsupervised network proposed by Garget al. (2016), Left-right consistency network proposed by Godard et al, Our refined network withoutshared parameters and our refined network with shared parametersFirst proposed by Garg et al. (2016), the monodepth estimation network takes left image (Il) as inputand outputs the disparity aligned with the right image (dr) which can be used to sample from the leftimage (Il) to reconstruct the right image (Ir) during training. Thus, image reconstruction loss Can beconstructed between the reconstructed right image(I r) and original right image(I r). When testing,only one colored image are required, the predicted disparity can be converted to depth simply usingdepth = b * f/disparity, where b and f are given baseline and camera focal length respectively. Itis worth to mention that disparities (dl and dr) are a scalar per pixel as the images are rectified.
Figure 3: Problem of warping and corresponding mask. (a)left image Il (b)right image Ir(c)disparity aligned with left image dl (d)reConStrUCted left image Il (e)reconstructed left imageafter being masked. We used ground truth disparity of left image dl(c) to warping the right imageIr (b) by bilinear sampling. However, duplicates and artifacts are obvious in reconstructed left image(IIl)(d) compared to the ground truth left image (a). We used a warping mask which is generatedautomatically from disparities to block the back-propagation of those artifacts. The final output isshown in (e), where the white regions are masked.
Figure 4: Schematic diagram. The orange squares refer to an object such as pedestrians or vehicles.
Figure 5: The sparsity problem of KITTI 2015 evaluation split. Vacancy are visible on the left ofthe image and near the boundaries of cars and trees, which would have an impact on the evaluationresult.
Figure 6: virtual-kitti test results6.3	post-processingGodard et al weighted summed the flipped disparity of flipped image and original disparity as postprocessing step. To eliminate the black edge on the left side of image as shown in Fig 1(b), Godardet al used non-linear weight. Because our model do not predict black edge, so we simply averagethem as our post-processing.
Figure 7: Example of blurred results and flip-over scheme.
