Figure 1: The schematics of the proposed approach. (a) First, find z0 which gives G (z0) ≈ I. Then,let ∆z0 to be the difference between the input image I and reconstructed one, G (z0). (b) Last,generate the final explanation by optimization over z. z0 and ∆z0 are fixed.
Figure 2: (a) True label is 0 and not 6. (b) True label is 7 and not 1. (c) True label is 9 and not 8. (d)True label is 8 and not 6. (e) True label is 3 and not 9 or 8. (f) True label is 4 and not 9.
Figure 3: Generated explanations for MNIST on the same trained network. The input image is in gray.
Figure 4: Comparison of CDeepEx to xGEMs. Colors are as in Figure 3.
Figure 5: EXamples of the optimization path for Equation 2. CDeepEX is our method. XGEMs is verysimilar, but without the last pair of constraints. The goal is to find a z such that G(z) is maXimallyconfused between the two classes. (a) EXamples from G(z) along the optimization path of z. (b)Average class likelihood from D(G(z)) for all eXamples (probe is second-most-likely class). Bothdemonstrate that without the constraints (XGEMs), the optimization finds an eXample for which thetrue and probe likelihoods are equal, but another class has an even higher likelihood. Our method(CDeepEX) with the constraints keeps the eXplanation targeted to the true and probe classes.
Figure 6: EXplanations for “why not 8?” for a network trained on data in which every 8 has a smallsquare in the upper-left corner.
Figure 7: Top and bottom rows are the results for ResNet101 and VGG16 respectively. (a) Changefro T-shirt to a Shirt with constraints. (b) T-shirt to shirt without constraints. (c) Change from trousersto coat with constraints. (d) Change from trousers to coat without constraints.
Figure 8:	Additional experiments comparing our method using a GAN, using VAE, and xGEMs. Themultiple columsn for the GAN methods are for different random starting points for the optimizationof z.
Figure 9:	OPtimization Path showing the imPortance of constraints. In this figure, we used a VAEinstead of a GAN. ToP row shows CDeePEx oPtimization Path while the bottom row shows xGEMsoPtimization Path.
Figure 10:	In this figure we show that the explanation comes from the network we want to speculate,not the generative model. The left column shows the accuracy of the networks over classifying class8The given discriminator networks have different accuracy for classifying class 8. The second columnis the input image. The last three columns are explanations generated using a GAN as generativemodel, using three different latent codes. The first row shows without the discriminator knowing whatis a class 8 instance should look like, the generated explanations are strange and inconsistent. Withthe first latent code, the network decides to remove the gap from the top curve, while with the othertwo latent codes, it decides to close the gap. In none of explanations network generates a explanationwhich wants to close the lower curve. As the accuracy of the network for class 8 increases, thegenerated explanations are getting better and consistent. Note that increasing the network accuracydoes not necessarily adds up linearly to the quality of the generated images (second and third row).
