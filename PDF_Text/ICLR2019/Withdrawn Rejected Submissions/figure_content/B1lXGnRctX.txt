Figure 1: (Left) Shows our experimental setup. p objects are in a drawer and a dexterous handequipped with tactile sensing can explore novel objects using deterministic routines. In this case,p = 3 but we compared performance by varying the number of objects (Middle) We are presentedwith a query image as seen by the inset in the top right of the image. We explore the objects inthe drawer using tactile sensing only to identify the object (Right) We then retrieve the object byapplying a grasping routineIn this work we use the task of retrieving objects from a drawer as an experimental setup to investi-gate joint learning from two sensory modalities of vision and touch. Because the agent is providedonly with a visual image of the object to be retrieved, it must translate into the representation spaceof tactile sensing to retrieve objects only by touching them. In the general case of retrieving theobject, the agent must first explore spatially to locate where the objects are. Once it finds the object,it must move its fingers in an exploratory manner to collect information required to determine if theobject is the one that needs to be retrieved. Solving this problem in its full generality requires notonly good goal directed exploration strategies and also a method for translating between differentsensory signals. We therefore think that object retrieval from a drawer is a good challenge problemfor investigating different models that combine visual and tactile information for a target end task.
Figure 2: For fine manipulation humans rely mostly on touch, dexterous hands that are equippedwith touch sensors could help mimic complex movements(Left) Shows the MPL hand with 19touch sensors depicted in green. (Middle) The actuators can be seen in red. (Right) Shows the jointsthat are available in this hand. The hand is under-actuated so the number of joints are greater thanthe number of actuatorsMore recently, Chu et al. (Chu et al. (2013)) measure various physical properties of objects usingthe bio-tac sensor using five different exploration procedures (EP). In addition, they also collectadjectives for each object and the corresponding They then compute precision, recall scores using astatic hand-engineered feature and dynamic feature model employing Hidden Markov Models andcompute precision, recall scores on a held out dataset. Similarly, Schneider et al. (2009) et al. alsoclassify objects using a bag-of-words appraoch.
Figure 3: Displays the objects used in our experiments. We used a set of 25 objects. These wereimported from the ShapeNet dataset (Chang et al. (2015)). Each object was presented in variousdifferent poses. The hand was initialized at the same location for each sample while the object wasrandomized in each trial.
