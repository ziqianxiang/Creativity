Figure 1: Hidden in plane sight. Images taken from CIFAR-10 dataset and scaled up to 224x224pixels. (a) Image is converted to greyscale and we add a salt-and-pepper noise-like mask to eachtraining image; (b) Image is converted to greyscale and we add uniform additive noise mask toeach training image; (c) A single diagnostic pixel is inserted in the image (top-right, though nearlyinvisible to the naked eye).
Figure 2:	Accuracy on test images under the three types of noise-like masks shown in Figure 1.
Figure 3:	Effect of regularisation. Graphs show accuracy for Same, Diff and NoPix conditionsusing models with four types of regularisations. The base model, VGG-16, uses dropout in fully-connected layers but not after convolutional layers; VGG_BN: VGG-16 with Batch Normalisation;VGG_L2: The 16-layer VGG CNN trained with weight-decay of 1e-3; Conv Drop: A seven-layerCNN with dropout after every convolution and fully connected layer.
Figure 4: Lack of generalisation. Accuracy under Same, Diff and NoPix conditions for (a) twosubsets: an ‘unaltered’ subset where no noise-like mask was inserted in training images and a ‘withpix’ subset where a single diagnostic pixel was inserted, and (b) for two phases: a ‘before’ phase,where a pre-trained VGG network was trained on images without any noise masks and tested onthe three conditions, and an ‘after’ phase, where the model from before phase was then trained onimages with a single diagnostic pixel.
Figure 5: Accuracy on test images when the noise mask varies between images of a category. Train-ing images contain (a) salt-and-pepper noise, or (b) additive uniform noise, or (c) just one diagnosticpixel. The dashed (red) line indicates chance performance. See Figure 2 for a description of the‘Same’, ‘Diff’ and ‘NoPix’ conditions.
Figure 6: Accuracy of the model on images containing no mask, as a function of the fraction oftraining images containing a diagnostic pixel. The solid (blue) and dashed (green) lines plot thisrelation for a network trained without and with weight-decay, respectively. Dashed (red) line at thebottom shows chance performance. Dotted (black )line at the top shows performance of a networktrained on images without any noise mask.
Figure 7: Accuracy during the ‘Same’ condition, when location of the pixel in the test set is shiftedcompared to the training set. The amount of shift was varied between 1pixel and 32pixels (shownon log2 scale). Dashed red line shows chance performance and the shaded region shows 95% confi-dence intervals.
Figure 8: Examples of images used for training and testing. The columns show the condition underwhich the image was used and the rows show the type of noise-like mask inserted. These noisemasks are, respectively, (row 1) salt-and-pepper noise with a fixed mask, (row 2) salt-and-peppernoise with a variable mask, (row 3) additive uniform noise with fixed mask, (row 4) additive uniformnoise with a variable mask, (row 5) single diagnostic pixel, fixed location and colour and (row 6)single diagnostic pixel with variable location and colour.
Figure 9: Effect of completely freezing convolution layers. Accuracy on images containing eitherAdditive (Uniform) noise-like mask or single diagnostic pixel (One pixel) when the learning rate forconvolution layers is set to zero after pre-training on ImageNet.
