Figure 1: (a) Noise learnt with ExL on MNIST data- (b) Noise learnt with ExL on CIFAR10 data- with mini-batch size =64.The template shown is the mean across all 64 noise templates.
Figure 2: For multiplicative and additive noise training scenarios- (a) -accuracy comparison of ExL with SGD(b) -RGB noise template learnt with ExL on CIFAR10 data. In (b), a sample training image of a ‘car’ beforeand after training with noise is shown. Note, we used the same hyperparameters (batch-size =64, η, ηnoiseetc.) and same inital noise template across all scenarios during training. Noise shown is the mean across 64templates.2The methods employing adversarial training (Tramer et al., 2017a; KUrakin et al., 2016; Madryet al., 2017) directly follow the left-hand side of Eqn. 1 wherein the training data is augmentedwith adversarial samples (A ∈ A). Such methods showcase adversarial robustness against a par-ticular form of adversary (e.g. '∞-norm bounded) and hence remain vulnerable to stronger attackscenarios. In an ideal case, A must encompass all set of adversarial examples (or the entire spaceof off-manifold data) for a concrete guarantee of robustness. However, it is infeasible to anticipateall forms of adversarial attacks during training. From a generative viewpoint (right-hand side ofEqn. 1), adversarial robustness requires modeling of the adversarial distribution while realizing thejoint input/output distribution characteristics (p(X |Y ), p(Y )). Yet, it remains a difficult engineeringchallenge to create rich generative models that can capture these distributions accurately. Some re-cent works leveraging a generative model for robustness use a PixelCNN model (Song et al., 2017)to detect adversarial examples, or use Generative Adversarial Networks (GANs) to generate adver-sarial examples (Samangouei et al., 2018). But, one might come across practical difficulties whileimplementing such methods due to the inherent training difficulty.
Figure 3: Relationship between the model’s understanding of adversarial and clean inputs in PC subspacewhen trained with (a) SGD (b) ExL. (c) Cosine Distance between the model’s response to clean and adversarialinputs in the PC subspace. (d) Variance of the Conv 1 layer of ResNet18 model. (c), (d) compare the SGD/ExL training scenarios.
Figure 4: (a) [Left] Variance (in response to clean inputs) across different scenarios for the first 700 PC di-mensions. [Middle, Right] Cosine distance across 700 PCs between clean and adversarial representationsfor varying . Adversarial subspace dimensionality for varying for- (b) -BB adversaries crafted from amodel trained with natural examples (c) -WB adversaries crafted for models trained with PGDAdv training.
Figure 5: Loss surface of models corresponding to MNIST (Table1).
Figure A3: Here, we show the variance captured in the leading Principal Component (PC) dimensions for theinital convolutional layer’s (Conv1) and intermediate blocks learnt activations of a ResNet-18 model trainedon CIFAR10 data. We compare the variance of the learnt representations (in response to clean inputs) for eachblock across two scenarios: SGD (without noise) and ExL (with noise). Note, we capture the variance of thefinal block’s activations before average pooling. That is, the activations of Block4 have dimension 512 × 4 × 4.
Figure A4: Here, We show the variance captured in the leading Principal Component (PC) dimensions for theConv 1 and Block 1 learnt activations in response to both clean and adversarial inputs for ResNet-18 modelscorreponding to the scenarios discussed in Fig. A3. The model’s variance for both clean and adversarial inputsare exactly same in case of ExL/SGD for Conv1 layers. For Block1, the adversarial input variance isslighlty lower in case of SGD than that of clean input. With ExL, the variance is still the same for Block1.
Figure A5: Here, we show the noise templates learnt with noise modeling corresponding to different trainingscenarios of Table 1, 2 in main paper: ExL (only noise modeling), ExL-PGD (noise modeling With PGDAdvtraining ExLPGD), ExL-ens (noise modeling with EnsAdv training ExLens) for MNIST and CIFAR10 data.
