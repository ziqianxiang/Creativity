Figure 1: Model used in denoising/demosaicing experimentin Appendix A; and (ii) the relatively high number of activation quantization levels almost negates the effectof clamping. For low bitwidths, i.e 3,3, we observe the opposite. The uniform noise assumption is no longeraccurate. Moreover, due to the small number of bits, clamping the range of values becomes more significant.
Figure 2: Residual block in hardware5.2 Hardware FlowIn this work, for both regression and classification tasks, we adopt PipeCNN implementation released bythe authors.1 In this implementation, the FPGA is programmed with an image containing: data moving,convolution and a pooling kernels. Layers are calculated sequentially. Figure 2 illustrates the flow of featuremaps in residual block from previous layer to the next one. Sai , Swi are activation and weights scale factorsof layer i, respectively. All the scaling factors are calculated off-line and are loaded to the memory along withthe rest of the parameters. In this paper, FPGA is used for inference only. We have compiled the OpenCLkernel to Intelâ€™s Arria 10 FPGA and run it with the DeepISP architecture. Weights were quantized to 4 bitsactivations to 8 bits, biases and the input image to 16 bits. Resource utilization amounted to 222K LUTs, 650DSP Blocks and 35.3 Mb of on-chip RAM. With the maximum clock frequency of 240MHz, the processingof a single image took 250ms. In terms of the energy envelope, computation on the FPGA was over 20%more efficient than an equivalent computation on an NVIDIA Titan X GPU. From standard harware designpractices, we can project that a dedicated ASIC manufactured using a similar process would be more efficientby at least one order of magnitude.
