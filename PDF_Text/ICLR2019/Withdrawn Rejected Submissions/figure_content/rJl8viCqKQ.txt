Figure 1: The latency of the different network implementations for the MNIST task with respect tothe number of available cores. The right figure shows the ratio between the latency of each solutionand the latency of the LoLa-Convit supports the Single Instruction Multiple Data (SIMD) framework. However, it is costly in twoways: the computational complexity of multiplying a matrix of size r Ã— k with a vector of lengthk is O (rk) HE operations, and the memory consumption is large as well since a vector of length krequires k messages. In this sense it is similar to the sparse representation. However, the ability toperform SIMD operations provides it with high throughput, much like the dense representation.
Figure 2: The structure of the network used for MNIST classificationIxlO1X100IxlOOensedense1x28x2812Under review as a conference paper at ICLR 2019Figure 3: The structure of the network used for CIFAR classification.
Figure 3: The structure of the network used for CIFAR classification.
Figure 4: The structure of the network used for CIFAR classification after collapsing adjacent layers.
