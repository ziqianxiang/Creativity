Figure 3: True gmm.
Figure 1: Training of AIR. (Left) Training curves: training with VIMCO leads to larger variancein training than WW. (Middle) Log evidence values at the end of training: increasing number ofparticles improves WW monotonically but improves VIMCO only up to a point (K = 10 is the best).
Figure 2: Training of a continuous latent variable model on MNIST. (Left) Training curves: thevariance in training is comparable between WW and IWAE with reparameterization. (Middle) Logevidence values at the end of training: increasing number of particles improves both ww and iwaewith reparameterization; the latter learns a better model only up to a point (K = 128) and suffersfrom diminishing returns afterwards. (Right) WW results in better inference networks than IWAE.
Figure 4: GMM training. Median and interquartile ranges from 10 repeats shown. (Top) Qualityof the generative model: ws and ww improve with larger particle budget thanks to lower varianceand lower bias estimators of the gradient respectively. Iwae methods suffer with a larger particlebudget (Rainforth et al., 2018). Ws performs the worst as a consequence of computing the expectedKL under model distribution pθ(x) equation 3 instead of the true data distribution p(x) as withww equation 4. Ww suffers from zero-forcing (described in text) in low-particle regimes, but learnsthe best model fastest in the many-particle regime; δ-WW additionally learns well in the low-particleregime. (Middle) The quality of the inference network develops identically to that of the generativemodel. (Bottom) WW and WS have lower-variance gradient estimators of φ than IWAE, as they don’tinclude the high-variance term ① in equation 2. This is a necessary, but not sufficient, condition forefficient learning with other important factors being gradient direction and the ability to escape localoptima.
Figure 5: Generative model and inference network during gmm training shown as Hinton diagramswhere areas are proportional to probability. Z goes from 0 to 19, left to right. Rows correspondto start, middle and end of optimization. (Left half) Learning with few particles leads to the zero-forcing (described in text) of the inference network (shown as conditional PMF given different x) andthe generative model (first column of each half) for all methods except δ-WW. Concrete distributionfails. (Right half) Learning with many particles leads to zero-forcing only for WS; WW and δ-WWsucceed where iwae fails, learning a suboptimal final generative model.
