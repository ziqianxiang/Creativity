Figure 1: Gram matrix projection from Eq. 3Layers in color, shapes are styles (timbre).
Figure 2: SynthNet (also see Table 1) with amulti-label cross-entropy loss for binary midi.
Figure 3: Seven networks are trained, each with a different harmonic style. Top, losses: training (left)validation (right). Bottom, RMSE-CQT: DeepVoice (left [Tbl. 3, col. 6]) and SynthNet (right [Tbl. 3,col. 8]). DeepVoice overfits for Glockenspiel (top right, dotted line). Convergence rate is measuredvia the RMSE-CQT, not the losses. The capacity of DeepVoice is larger, so the losses are steeper.
Figure 4: Left: 1 second of ground truth audio of Bachâ€™s BWV1007 Prelude, played with FluidSynthpreset 56 Trumpet. Center: SynthNet high quality generated. Right: DeepVoice low quality generatedshowing delay. Further comparisons over other instrument presets are provided in Appendix A. Weencourage the readers to listen to the samples here: http://bit.ly/synthnet_appendix_aOther metrics were evaluated as well however only the RMSE-CQT was correlated with the qualityof the generated audio. This (subjective) observation was initially made by listening to the audiosamples and by comparing the plots of the audio waveforms (Figure 4). Roughly speaking, as we6Under review as a conference paper at ICLR 2019also show in Figure 4 (top captions) and Figure 3 (lower plots), we find that a RMSE-CQT valuebelow 10 corresponds to a generated sample of reasonable quality. The RMSE-CQT also penalizestemporal delays (Figure 4 - right) and is also correlated with the MOS (Table 3 and Table 5).
Figure 5: Gram matrices extracted during training, every 20 epochs. Top left: extracted fromEquation 3. Top right: extracted from Equation 2. Bottom left: extracted from the filter part ofEquation 2. Bottom right: extracted from the gate part of Equation 2.
