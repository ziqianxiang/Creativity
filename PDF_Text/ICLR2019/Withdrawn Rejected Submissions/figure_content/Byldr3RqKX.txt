Figure 1: Graphical representation of CGMs. (a) Example CGM with 2 latent variables. (b)Illustration of extrinsic disentanglement with L = {1}. (c) Illustration of intrinsic disentanglementwith E = {3}. (d) Illustration of unaccounted latent variable emulated by (c). Nodes modified byintervention on the graph are indicated in blue.
Figure 2: Generation of influence maps. (a) Principle of sample hybridization through counter-factuals. (b) Example of influence maps generated by a VAE on the CelebA dataset (lighter pixelindicate larger variance and thus stronger influence of the perturbations on that pixel).
Figure 3: Left: Clustering of influence maps and generation of hybrid samples for a VAE trained onthe CelebA dataset (see text).. Right: magnitude of causal effects. (Top: average influence of modulesderived from clustering, as a function of the number of clusters. Bottom: individual influence of eachmodules, as a function of the number of channels they contain, dashed line indicate linear regression).
Figure 5: Label consistency (left) and cosine similarity (right) of the clustering of influence maps forthe NMF and k-means algorithm. Errorbars indicate standard deviation across 20 repetitions.
Figure 4: FC indicates a fully connected layer, z is a 100-dimensional isotropic Gaussian vector,horizontal dimensions indicate the number of channels of each layer. The output image size is64 × 64 (or 32 × 32 for cifar10) pixels and these dimensions drop by a factor 2 from layer to layer.
Figure 6: Clustering of influence maps and generationCelebA dataset (see text).
Figure 7: Clustering of influence maps and generationCelebA dataset (see text).
Figure 8: Clustering of influence maps and generationCIFAR10 dataset (see text).
