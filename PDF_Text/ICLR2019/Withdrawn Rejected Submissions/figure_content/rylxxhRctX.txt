Figure 1: Intuitive explanation of the difference between coverage-driven and quality-driven train-ing, in a one dimensional setting. CDT pulls probability mass towards points from regions of highdensity of the distribution underlying the data, while QDT pushes mass out of low-density regions.
Figure 2: Schematic overview of our model. Our generative model is built on a VAE, with an ad-ditional invertible non-linear mapping f (x) that maps X to a feature space with the same dimension(shown with arrows 1, 4). The encoder takes f (x) and maps it to a posterior distribution qφ(z∣χ)over the latent variable (arrow 2), while the decoder maps Z to a distribution over the feature space(arrow 3). Defining the reconstruction loss in the feature space avoids the use of overly simplifiedper-pixel losses that are commonly used. The discriminator D(X) is used to assess the quality of thesamples from the generative model.
Figure 3: Typical samples from the baseline GAN and VAE models, and our CQF model.
Figure 4: Random samples obtained from our best models, as reported in Section 5.4, on the CIFAR-10 and STL-10 (48 × 48) datasets.
Figure 5: From top to bottom, random samples and real images from the CelebA (crop 178×178),LSUN-Bedrooms, STL-10 96×96, and ImageNet.
Figure 6: Samples from MLE models (Table 3b) showing qualitative influence of multi-scale featurespace.
Figure 7: Real images and their reconstructions with the CQ and CQF models.
