Figure 1: Walking in the disentangled representation space: Here we show an example learned by ouralgorithm. Our approach effectively disentangles the structure and appearance space. Three cat faces in thebounding box are from real data while others are interpolated through our learned representations.
Figure 2: Architecture: Our framework follows an auto-encoder framework. It contains two branches: 1)the structure branch forces the representation into a Gaussian spatial probability distribution with an hourglassnetwork eω . 2) the appearance branch Eφ learns a complementary appearance representation to the structure.
Figure 3: Conditional generation results:(a) Walking in the appearance space with fixed structure. (b)Walking in the structure space with fixed appearance. (c) A visualization of the disentangled space by linearinterpolation. The Structure is smoothly changed in row-wise and the appearance is changed by each column.
Figure 4: Visual analogy results on synthesized datasets: (a) MNIST-CD. (b) MNIST-CB. (c) 3D Chair.
Figure 5: Visual analogy results on real-life datasets: (a) Standford Dog. (b) CelebA. The geometry (e.g.
Figure 6: Comparison to other methods. Qualitative results of disentangling performance of VAE, β-VAE,InfoGAN and Jakab et al. (2018). We demonstrate the disentanglement of the factor of azimuth for 3D chairdataset. Visual analogy results are demonstrated for face dataset.
Figure 7: A grid of structure&appearance swapping visualization. The top row and left-most columnsare random selected from the test set. In each column, the structure of the generated images are shown to beconsistent with the top ones. In each row, the appearance of the generated images are shown to be consistentwith the left-most ones.
Figure 8: Random chosen 4 query images and the corresponding 5 nearest-neighbors are illustrated, which areretrieved with image pixel, structure code, appearance code respectively.
Figure 9: Interpolation results on 3D Chair.
