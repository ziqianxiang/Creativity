Figure 1: Training procedure for DeepTwist where weights are distorted occasionally.
Figure 2: Test perplexity using DeepTwist-based SVD on the PTB dataset.
Figure 3: Singular-value spectrum of the diagonal (non-distorted) matrix Î£ sampled from the pre-trained model (0 epoch), at the 7th epoch, and at the 31st epoch with r=64. (Left): from Wx oflayer 1, (Right): from Wh of layer 1.
Figure 4: Weight distribution of LSTM layer 1 of the medium PTB model after retraining with(Left) a magnitude-based pruning and (Right) DeepTwist-based pruning with 90% pruning rate.
Figure 5: SV spectrum for the PTB large model when r = 96. (Left): from the (non-distorted)inter-layer weights of layer 1, (Right): from the (non-distorted)recurrent weights of layer 1. Layer 2presents similar results. The number of hidden LSTM units is 1500.
Figure 6: SV spectrum for the PTB large model when r = 256. (Left): from the (non-distorted)inter-layer weights of layer 1, (Right): from the (non-distorted) recurrent weights of layer 1. Layer2 presents similar results. The number of hidden LSTM units is 1500.
