Figure 1: Model Architecture of ChoiceNetIMCDN BlockSamplingWeightsCholeskyTransformLearningparameterConstantParameterSampling空(W,Z)Θ = (pfc(h), μ∙∖v5 ∑w5 ∑z)■ Pκ(h)" Mwexp(Whτ∑°h]softmax(Wh→πh)Cholesky transform. Consequently, the MCDN block is able to model the correlated outputs i.e.
Figure 2: Reference function and fitting results of compared methods on different outlier rates.
Figure 3: Fitting results on datasets with (a) flipped function and (c) uniform corruptions. Resultingcorrelations of two components with (b) flipped function and (d) uniform corruptions.
Figure 4: Reference function and fitting results of compared methods on different outlier rates,0%,20% 40%, 80%, and 90%).
Figure 5: Resulting trajectories of compared methods trained with mixed demonstrations. (bestviewed in color).
Figure 6: Descriptions of the featrues of an ego red car used in autonomous driving experiments.
Figure 7: Manually collected trajectories of (a) safe driving mode and (b) careless driving mode.
Figure 8:	Learning curves of compared methods on random bias experiments using MNIST withdifferent noise levels.
Figure 9:	Learning Curves of Compared methods on random shuffle experiments using MNIST withdifferent noise levels.
Figure 10:	Learning Curves of Compared methods on random permutation experiments using MNISTwith different noise levels.
Figure 11: Learning curves of compared methods on CIFAR-10 experiments with different noiselevels.
