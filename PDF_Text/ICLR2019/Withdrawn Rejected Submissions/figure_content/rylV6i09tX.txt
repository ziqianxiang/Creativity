Figure 1: (a) ResNet’s loss surface on local minima in parameter space has wide and flat geometry,indicating optimal accuracy. (b) While in input space, the loss surface demonstrates significantnon-smooth variation.
Figure 2: Loss Surfaces in parameter space (similar settings with Li et al. (2017)). There is no clearrelation between the neural network robustness and loss surface geometry in parameter space.
Figure 3: Loss Surface in input space (our main focus). There are distinct difference between twomodels with different degrees of robustness. Obviously, network robustness is highly correlated tothe loss surface geometry in input space, instead of parameter space.
Figure 4: Comparison of cross entropy based loss surface (first row) and our decision surface (secondrow). In (a), the projection vectors are randomly selected. In (b)-(d), y-axis projection vector is thedescent direction of corresponding objective function of various adversarial attacks. Along both axesWe use step size = 1 on the pixel range (0 〜255). Clearly, all three adversarial attacks are utilizingthe geometry information of decision surface to find the shortest paths (indicated by arrows andtriangles) to cross the decision boundaries.
Figure 5: An 1-D illustrationof slope and curvaturepoint. The conception in simple 1-d case is shown in Fig. 5. Clearly,lower curvature (small eigenvalues) means that the hyperplane bendsless, leading to a wider neighborhood of original point.
Figure 6: Decision Surface of the natural and robust model on MNIST. (a)-(d): natural modelsurface with random projection, adversarial projection; robust model surface with random projection,adversarial projection (red arrows denote the adversarial direction with step size = 0.05). On robustmodel surface, both original input and its neighbor points (within '∞ < 0.3) locate on the flat plateau.
Figure 7: Comparison of Decision Surface of natural and robust model on CIFAR10 (step size = 1).
Figure 8: MINST models’ Jacobian and Hessian visualization and analysis with randomly selectedinput image "6". Robust model’s Jacobian and Hessian are more sparse, and have smaller `1 norm.
Figure 9: Natural and our robust model surface.
Figure 10: Jacobian Visualization on MNIST and CIFAR10. Through gradient regulation, neuralnetwork is more capable to capture the main pattern of input images.
Figure 11: Two pairs of random projections of loss surfaces and decision surfaces on the same images.
Figure 12:	Comparison of cross entropy loss surface and decision surface of state-of-the-art robustmodel trained by MinMax robust training. We can see that cross entropy based loss surfacesdemonstrate the opposite geometry with decision surface, but decision surfaces are more stable andclear in both high confidence areas and low confidence areas.
Figure 13:	Comparison of Natural Projection and Adversarial Projection on Natural Models. Wecould find that even with random projections, the loss and decision surfaces could demonstrate highlynon-smooth patterns. This neighborhood under-fitting issue is the cause of adversarial examples.
Figure 14:	Comparison of Adversarial Projections on Natural and our Robust Models. We could findthat the gradient regularization indeed smooths the network decision surfaces, bringing lower slopes.
Figure 15: Comparison of robust model’s and natural model’s Jacobian Visualization. (Both normal-ized to 0 〜255 for visualization.) AS We declared before, the property that Jacobian concentrates onthe main pattern of images could enable the neural network better resistance with adversarial noises.
Figure 16: More examples of natural model’s and robust model’s loss surfaces in parameter space. Asexpected, robust model’s loss surface in parameter space is more stable under weak attacks comparedto the natural model, as shown in (b) and (c). (In case of misunderstanding, we note that the blueregion is low loss region, and the red region is high loss region. The "more stable" means lossincrement is less in robust model’s loss surface, when comparing the second row to the first row.) Butunder stronger attacks, like C&W attack in (d), robust model’s and natural model’s loss surfaces inparameter space become similar again. Therefore, parameter space loss surfaces may not be suitableto indicate robustness well under such strong attack situations.
