Figure 1: Left: Accuracy under different levels of attack. The model (VGG16) is obtained byadversarial training on CIFAR-10, we set δmax = 0.03125 in (3). The horizontal axis is the attackstrength δ which is equivalent to δmax in (2). Note that δmax in (2) and (3) have different meanings —one is for attack and the other is for defense. Notice the increasing accuracy gap when δ < 0.03125.
Figure 2: Comparing robust and non-robust discriminators, for simplicity, We PUt them togetherinto one graph. Conceptually, the non-robust discriminator tends to make all images close to thedecision boundary, so even a tiny distortion δ can make a fake image x0 to be classified as a realimage xadv = x0 + δ. In contrast, such δ is expected to be much larger for robust discriminators.
Figure 3: Illustration of the training process. Step-1 is the standard GAN training, i.e. alternativelyupdating the G and D networks. The only difference is that whenever feeding the real images tothe D network, we first run 5 steps of PGD attack, so the discriminator is trained with adversarialexamples. Step-2 is a refining technique, aiming at improving prediction accuracy on the test set.
Figure 4:	Comparing the architectures of discriminators. Our architecture is similar to AC-GAN (Odena et al., 2017), but they are different in loss functions, if one compares (8) with (9).
Figure 5:	The effect of fine-tuning on prediction accuracy (left: CIFAR10, right: ImageNet-64px)Robustness of discriminator: comparing robustness with/ without data augmentation In thisexperiment, we would like to compare the robustness of discriminator networks with or withoutdata augmentation technique discussed in Sec. 3.3. The robustness is measured by the predictionaccuracy under adversarial attack. For networks without data augmentation, that would be equal tothe state-of-the-art Madry’s algorithm (Madry et al., 2017). For attacking algorithm, we choose thewidely used '∞ PGD attack (Madry et al., 2017), but other gradient based attacks are expected to7Under review as a conference paper at ICLR 2019Dataset	σmax of '∞ attacks				0	0.02	0.04	0.08CIFAR10	81.1% (-0.35%)	70.41% (+1.26%)	57.43% (+3.69%)	30.25% (+6.67%)	0	0.01	0.02	0.03ImageNet, (64px)	32.4% (+6.35%)	25.2% (+6.9%)	19.1% (+6.58%)	13.7% (+5.38%),Denotes the 143-Class subset of ImageNet.
Figure 6: Comparing the generated images trained by our modified loss(left) with the original AC-GAN loss(right). For fair comparison, both networks are trained with adversarial real images. Wecan see images from AC-GAN are more distorted and harder to distinguish.
Figure 7: Results on subset of ImageNet, left: 64px, right: 128px. We compare the inception scoresbetween our model and the SN-GAN. Clearly our method learns a high quality generator in a shorttime, specifically, in both datasets, AC-GAN with adversarial training surpasses SN-GAN in just25 epochs (64px) or 50 epochs (128px). Another observation is that with adversarial training, theconvergence is greatly accelerated.
Figure 8: Comparing the accuracy gap between adversarial training model and GAN data augmenta-tion model.
