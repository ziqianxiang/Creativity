Figure 1: (a) Schematic of guided evolutionary strategies. We perform a random search using adistribution (white contours) elongated along a subspace (white arrow) which we are given insteadof the true gradient (blue arrow). (b) Comparison of different algorithms on a quadratic loss, wherea bias is explicitly added to the gradient to mimic situations where the true gradient is unknown. Theloss (left) and correlation between surrogate and true gradient (right) are shown during optimization.
Figure 2: Exploring the tradeoff between variance and safe bias in Guided ES. Contour plots ofnormalized bias b (a), normalized variance V (b), and the sum of both (c) are shown as a functionof the tradeoff (α) and scale (β) hyperparameters, for a fixed kρk2 = 0.23. For these plots, thesubspace dimension was set to k = 3 and the parameter dimension was set to n = 100. The blueline in (c) denotes the optimal β for every value of α, and the star denotes the global optimum.
Figure 3:	Choosing optimal hyperparameters. (a) Different regimes of optimal hyperparameters inthe (k, ∣ρ∣2) plane are shown as shaded regions. See §3.4 for details. (b) As ∣∣ρ∣2 increases, theoptimal hyperparameters sweep out a curve from (α* = Le* = n+n2) to (α* = 0, β* = ^++^).
Figure 4:	Unrolled optimization. (a) Bias in the loss landscape of unrolled optimization for smallnumbers of unrolled optimization steps (t). (b) Training curves (shown as distance from the opti-mum) for training a multi-layer perceptron to predict the optimal learning rate as a function of theeigenvalues of the function to optimize. See §4.2 for details.
Figure 5: Synthetic gradients serving as the guiding subspace for Guided ES. (a) Loss curves whenusing synthetic gradients to minimize a target quadratic problem. (b) Correlation between the syn-thetic update direction and the true gradient during optimization for Guided ES.
Figure 6: Training a VQ-VAE. (a) Guided ES (using the straight-through estimator as the surrogategradient) achieves lower training loss than Adam. (b) Histogram of the correlation between theGuided ES update and the straight-through gradient during training.
