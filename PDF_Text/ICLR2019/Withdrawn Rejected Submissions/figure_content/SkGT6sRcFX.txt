Figure 1: Softmaxed activations of the hidden and output layer for LeCun initialisation at epochs 0,20 and 400 for a network with 800 hidden units.
Figure 2: Softmaxed activations of the hidden and output layer for Xavier initialisation at epochs 0,20 and 400 for a network with 800 hidden units.
Figure 3: Softmaxed activations of the hidden and output layer for Kaiming initialisation at epochs 0,20 and 400 for a network with 800 hidden units.
Figure 4: Softmaxed activations of the hidden and output layer for SntDefault initialisation at epochs0, 20 and 400 for a network with 800 hidden units.
Figure 5: Softmaxed activations of the hidden and output layer for Win-Win class initialisation atepochs 0, 20 and 400 for a network with 800 hidden units.
