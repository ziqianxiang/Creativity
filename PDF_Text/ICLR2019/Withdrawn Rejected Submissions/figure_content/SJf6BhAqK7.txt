Figure 1: Our bayesian bonparametric deep embedding (BANDE) method is optimized end-to-end tocluster labeled and unlabeled data into multi-modal, many-to-one prototypes. BANDE represents eachclass by a set of clusters, unlike prior prototypical methods that are limited to uni-modal, one-to-onerepresentation of each class by a single cluster. Multi-modal prototypes make BANDE more accurateon complex classes like alphabets and more general for fully-supervised, semi-supervised, and evenunsupervised clustering where prior methods are undefined.
Figure 2: Our new variadic setting for any-shot, any-way generalization. Models are meta-trainedwith 5-way 1-shot episodes. Omniglot is tested with 1-shot episodes across 5-200 classes per episode,while mini-ImageNet is tested with 5-way episodes across 1-50 examples per class. Baselines (black)are trained on 100% of the labeled data. Prototypical methods (color) are semi-supervised with40% of the labeled data (our methods starred). For way (a), nonparametric methods significantlyoutperform parametric methods, and BANDE performs best. For shot (b), nonparametric and gradientmethods perform similarly but gradient methods require more computation.
Figure 3: 1692-way classification of all Omniglottest classes from 5-way 1-shot meta-learning. Non-parametric methods can learn this many-way taskfrom few-way meta-training with higher accuracythan a full-way parametric classifier.
Figure 4: Cluster discovery metrics for Omniglot. Trained on 5-way 1-shot episodes.
