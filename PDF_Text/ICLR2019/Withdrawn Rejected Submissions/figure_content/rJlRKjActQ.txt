Figure 1: The top row (a,b,c) shows the decision boundary on the 2d spirals dataset trained witha baseline model (a fully connected neural network with nine layers where middle layer is a 2Dbottleneck layer), Input Mixup with α = 1.0, and Manifold Mixup applied only to the 2D bottlenecklayer. As seen in (b), Input Mixup can suffer from underfitting since the interpolations betweentwo samples may intersect with a real sample. Whereas Manifold Mixup (c), fits the training dataperfectly (more intuitive example of how Manifold Mixup avoids underfitting is given in AppendixH). The bottom row (d,e,f) shows the hidden states for the baseline, Input Mixup, and manifoldmixup respectively. Manifold Mixup concentrates the labeled points from each class to a very tightregion, as predicted by our theory (Section 3) and assigns lower confidence classifications to broadregions in the hidden space. The black points in the bottom row are the hidden states of the pointssampled uniformly in x-space and it can be seen that manifold mixup does a better job of giving lowconfidence to these points. Additional results in Figure 6 of Appendix B show that the way ManifoldMixup changes the representations is not accomplished by other well-studied regularizers (weightdecay, dropout, batch normalization, and adding noise to the hidden states).
Figure 2: Study of test Negative Log-likelihood (NLL) using the interpolated target values (lower isbetter) on interpolated points under models trained with the baseline, mixup, and Manifold Mixup.
Figure 4: Interpolations in the hidden states (using a small convolutional network trained to pre-dict the input from the output of the second resblock). The interpolations in the hidden states showa better blending of semantically relevant features, and more of the images are visually consistent.
Figure 5: Synthetic task where the underlying factors are known exactly. Training images (left),images from input mixup (center), and images from mixing in the ground truth factor space (right).
Figure 6: An experiment on a network trained on the 2D spiral dataset with a 2D bottleneck hiddenstate in the middle of the network (the same setup as 1). Noise refers to gaussian noise in thebottleneck layer, dropout refers to dropout of 50% in all layers except the bottleneck itself (due to itslow dimensionality), and batch normalization refers to batch normalization in all layers. This showsthat the effect of concentrating the hidden states for each class and providing a broad region of lowconfidence between the regions is not accomplished by the other regularizers.
Figure 7: Representations from a classifier on MNIST (top is trained on digits 0-4, bottom is trainedon all digits) with a 2D bottleneck representation in the middle layer. No Mixup Baseline (left),Input Mixup (center), Manifold Mixup (right).
Figure 8: CIFAR-10 test set Negative Log-Likelihood (Y-axis) on PreActResNet152, wrt trainingepochs (X-axis).
Figure 9: CIFAR-10 train set Binary Cross Entropy Loss (BCE) on Y-axis using PreActResNet18,with respect to training epochs (X-axis). The numbers in {} refer to the resblock after which Mani-fold Mixup is performed. The ordering of the losses is consistent over the course of training: Mani-fold Mixup with gradient blocked before the mixing layer has the highest training loss, followed byInput Mixup. The lowest training loss is achieved by mixing in the deepest layer, which is highlyconsistent with Section 3 which suggests that having more hidden units can help to prevent under-fitting.
Figure 10: CIFAR-100 train set Binary Cross Entropy Loss (BCE) on Y-axis using PreActRes-Net50, with respect to training epochs (X-axis). The numbers in {} refer to the resblock after whichManifold Mixup is performed. The lowest training loss is achieved by mixing in the deepest layer.
Figure 11: We test out various values of α in conjunction with either: input mixup (pixel) (Zhanget al., 2018), mixing in the output of the first resblock (hi), mixing in either the output of the firstresblock or the output of the second resblock (h1,2), and mixing in the input or the output of thefirst resblock or the output of the second resblock (1,2,piχel). The dotted line indicates thebaseline Inception / FID score. Higher scores are better for Inception, while lower is better for FID.
Figure 12: We consider a binary classification task with four data points represented in a 2D hiddenspace. Ifwe perform mixup in that hidden space, we can see that if the points are laid out in a certainway, two different interpolations can give inconsistent soft-labels (left and middle). This leadsto underfitting and high loss. When training with manifold mixup, this can be explicitly avoidedbecause the states are learned, so the model can learn to produce states for which all interpolationsgive consistent labels, an example of which is seen on the right side of the figure.
Figure 13: SVD on the class-specific representations in a bottleneck layer with 12 units following3 hidden layers. For the first singular value, the value (averaged across the plots) is 50.08 for thebaseline, 37.17 for Input Mixup, and 43.44 for Manifold Mixup (these are the values at x=0 whichare cutoff). We can see that the class-specific SVD leads to singular values which are dramaticallymore concentrated when using Manifold Mixup with Input Mixup not having a consistent effect.
Figure 14: SVD on the class-specific representations in a bottleneck layer with 30 units following3 hidden layers. For the first singular value, the value (averaged across the plots) is 14.68 for thebaseline, 12.49 for Input Mixup, and 14.43 for Manifold Mixup (these are the values at x=0 whichare cutoff).
Figure 15: SVD on the class-specific representations in a bottleneck layer with 30 units following asingle hidden layer. For the first singular value, the value (averaged across the plots) is 33.64 for thebaseline, 27.60 for Input Mixup, and 24.60 for Manifold Mixup (these are the values at x=0 whichare cutoff). We see that with the bottleneck layer placed earlier, the reduction in the singular valuesfrom Manifold Mixup is smaller but still clearly visible. This makes sense, as it is not possible forthis early layer to be perfectly discriminative.
Figure 16: When we run SVD on all of the classes together (in the setup with 12 units in thebottleneck layer following 3 hidden layers), we see no clear difference in the singular values forthe Baseline, Input Mixup, and Manifold Mixup models (ran on the model with a bottleneck hiddenstate of 12 dimensions). Thus we can see that the flattening effect of manifold mixup is entirelyclass-specific, and does not appear overall, which is consistent with what our theory has predicted.
