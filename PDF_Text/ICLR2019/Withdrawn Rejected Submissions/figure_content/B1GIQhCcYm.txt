Figure 1: Formulation of the image to image translation problem. Given two domains X and Y ,presented as cat and dog images, we postulate that these two domains are in part explained byrandom variables U, V from the shared semantic space and random variables ψ and ξ independentof U, V that explain features specific to X and Y , respectively.
Figure 2: Computation graph of the transfer network T . First, normal noise z is sampled and fedthrough F. We sample x from the real data distribution PX and fed through E. F(ξ) and E(x) areconcatenated and fed through G to get a generated sample y0 .
Figure 3:	64 × 64 Edge to shoes samples generated using (1) TI-GANmaximizing I(X; Y0), (2)Only a GAN penalty, (3) Using CycleGAN recommended architecture「1 ■?‘ L 1/UJJJ∙∙∙∙/ / / /(2)(3)Figure 4:	64 × 64 Edge to shoes samples generated using (1) TI-GAN maximizing I(X; T (X, Ξ)),(2) Only a GAN penalty, (3) TI-GAN using CycleGAN recommended architecture7Under review as a conference paper at ICLR 20195.2 MNIST TO SVHNMNIST to SVHN is a harder task because it requires a geometric transformation. For example, thetypography of the SVHN digits is different from the MNIST digits, not all SVHN digits are centered,etc. Hence, learning a function close to the identiy mapping will not yield a good transfer. To ourknowledge, no technique was able to perform well on this task.
Figure 4:	64 × 64 Edge to shoes samples generated using (1) TI-GAN maximizing I(X; T (X, Ξ)),(2) Only a GAN penalty, (3) TI-GAN using CycleGAN recommended architecture7Under review as a conference paper at ICLR 20195.2 MNIST TO SVHNMNIST to SVHN is a harder task because it requires a geometric transformation. For example, thetypography of the SVHN digits is different from the MNIST digits, not all SVHN digits are centered,etc. Hence, learning a function close to the identiy mapping will not yield a good transfer. To ourknowledge, no technique was able to perform well on this task.
Figure 5:	MNIST to SVHN using TI-GAN. The first column represent the source images to transfer.
Figure 6:	SVHN to MNIST using TI-GAN. The first column represent the source images to transfer.
Figure 7: SVHN to MNIST using TI-GANwith UNet architecture. The first column represent thesource images to transfer. Each subsequent columns are different samples from the prior distributionused to transfer. (1) is our technique using only the WGAN-GP objective. (2) is our technique usingthe WGAN-GP objective while minimizing the mutual information of the generated samples andthe samples from the prior11Under review as a conference paper at ICLR 2019(1)Figure 8: (1) SVHN to MNIST using TI-GANwith UNet architecture with higher weight of MIpenalty. The first column represent the source images to transfer. Each subsequent columns aredifferent samples from the prior distribution used to transfer. The higher MI penalty results with thenetwork completely neglecting the noise and inferring all SVHN features from MNIST. (2) CycleGAN with UNet architecture. Each row and three consecutive columns represent MNIST image,translation to SVHN and MNIST reconstruction.
Figure 8: (1) SVHN to MNIST using TI-GANwith UNet architecture with higher weight of MIpenalty. The first column represent the source images to transfer. Each subsequent columns aredifferent samples from the prior distribution used to transfer. The higher MI penalty results with thenetwork completely neglecting the noise and inferring all SVHN features from MNIST. (2) CycleGAN with UNet architecture. Each row and three consecutive columns represent MNIST image,translation to SVHN and MNIST reconstruction.
