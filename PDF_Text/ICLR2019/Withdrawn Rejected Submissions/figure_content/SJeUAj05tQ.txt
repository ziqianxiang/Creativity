Figure 1: The residual 聘∖-[] on iteration (time step t ∈ {1,…，T}) for binary classification prob-lem using convex and nonconvex (with α/√t) loss functions. Constant α = σn/ρ is the theoreticalcritical step-size given for DGD Yuan et al. (2016). (a) classification with p = 10 and ν = 0. (b)classification with p = 20 and ν = 0. (c) classification with p = 20 and ν = 1/mi.
Figure 2: Training loss and accuracy over 15 epochs. (a) MNIST digit recognition task (b) CIFAR10image recognition dataset.
Figure 3: Performance of the DADAM algorithm with varying network topology: training loss andaccuracy over 30 epochs based on the MNIST digit recognition library.
Figure 4: Performance of the DADAM algorithm with varying decay rate β3. DADAM1 (β3 = 0),DADAM2 (β3 = 0.9), and DADAM3 (β3 = 0.99) for training loss and accuracy over 30 epochsbased on the MNIST digit recognition library.
