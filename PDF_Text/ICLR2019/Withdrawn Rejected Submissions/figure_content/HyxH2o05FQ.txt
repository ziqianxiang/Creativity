Figure 1: Distribution of importance weights for each target dataset when using ImageNet as a source pre-training dataset. The horizontal axis represents the top 100 ImageNet labels sorted by importance weight foreach dataset; each dataset has a different order. The distributions vary widely between target datasets. FGVCAircraft selects only a few labels that turn out to be coarse grained, whereas Oxford Pets selects a wider varietyof fine-grained labels. This reflects the inherent bias in the ImageNet dataset.
Figure 2: Performance (top) and unique examples (bottom) of the same distribution matcher and elastic dis-tribution matcher at different sampled dataset sizes. We see that when dataset size increases, the performanceof same distribution matcher increases and then saturates, while that of elastic distribution matcher drops aftera peak. Notice that the elastic distribution matcher also has significantly more unique examples than samedistribution matcher as the dataset size increases.
