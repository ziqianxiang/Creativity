Figure 1: Mutli-agent Reinforcement Learning FrameworkMany real-life tasks involve partial observability and multi-agent planning. Traditional RL ap-proaches such as Q-Learning and policy-based methods are poorly suited to multi-agent problems.
Figure 2: The proposed simulation is a gladiator pit for algorithms. Python-based environmentCapture the Flag (CtF) is designed to throw together various AI algorithms or a human. Two teamsconfront each other and the goal is to capture the other teamâ€™s flag or destroy the enemy units. Twotypes of units exist in each team and they have different abilities. The observation is limited by thefog of war shown on the left and provides the information available to the team. The true state ofthe environment shown on the right and reflects all the teams.
Figure 3: First-person observation. Global observation is split into individual agent observationsand shifted to put the controlled agent into the center.
Figure 4: Performance of distributed policy learning with no competitors and fully observable envi-ronment.
Figure 5: Performance of distributed policy learning with default number of competitors and fullyobservable environment.
Figure 6: Performance of distributed policy learning with default number of competitors and par-tially observable environment.
