Figure 1: Impact of the loss function: FID distribution for top 5% models. The non-saturating (NS)loss is stable over both data sets. Gradient penalty and spectral normalization improve the samplequality. From the computational budget perspective (i.e. how many models one needs to train to reacha certain FID), both spectral normalization and gradient penalty perform better than the baseline, butthe former is more efficient.
Figure 2: Impact of regularization and normalization: FID distribution for top 5% models. Bothgradient penalty (GP) and spectral normalization (SN) outperform the baseline and should beconsidered, while former being more computationally expensive. Unfortunately none fully addressthe stability issues.
Figure 3: Impact of simultaneous normalization and regularization:models. Gradient penalty coupled with spectral normalization (SN)strongly improves the performance over the baseline.
Figure 4: Impact of the neural architectures: FID distribution for top 5% models. Both spectralnormalization and gradient penalty can help improve upon the non-regularized baseline.
Figure 5: An empirical study with SNDCGAN and ResNet cifar architectures on cifar 1 0. Werecover the state of the art results recently reported in Miyato et al. (2018).
Figure 6: We show the inception Score for each model within our study which corresponds to recentlyreported results (Miyato et al., 2018).
Figure 7: Ablation study of ResNet architecture differences. The experiment codes are described inSection D.
Figure 8: Examples generated by GANs on celeba-hq-128 data set.
Figure 10: Examples generated by GANs on cifar10 data set.
Figure 11: Heat plots for hyper-parameters on each architecture and dataset combination.
