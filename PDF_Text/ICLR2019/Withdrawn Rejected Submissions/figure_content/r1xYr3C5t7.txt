Figure 1: MPED Networks. Given input x, we encode its components {x1, x2, x3} as embedded input nodes{ct1 , ct2 , ct3} of encoder graph GENC. Similarly, we encode labels {y1 , y2, ..., y5} as embedded label nodes{ht1, ht2, ..., ht5} of decoder graph GDEC. MPNNxx is used to pass messages between the input nodes and updateinput nodes. MPNNxy is used to pass messages from the input nodes to the labels nodes and update the labelnodes. MPNNyy is used to pass messages between the label nodes and update label nodes. Finally, readoutfunction R performs node-level classification on label nodes to make binary label predictions {yÎ¹, y2, ...,y5}.
Figure 2: Average Across Metrics for T=1, T=2, and T=3 GDEC time steps. In these experiments, the encoderGENC is processed with a fixed T=3 time steps, and the decoder time steps are varied. We do not compare timesteps for the SIDER dataset since it is too small, and we only evaluate using T=1.
Figure 3: Label-To-Label Attention Weights. On the left are the positive labels, and on the right are alllabels. These are taken from the layer 2 Label-To-Label attentions on a sample from Reuters-21578(same input sample as shown in 4.
Figure 4: Input to Label Attention Weights. On the left are the positive labels, and on the right are allinput components (words). These are taken from the layer 1 Input to Label attentions on a samplefrom Reuters-21578.
