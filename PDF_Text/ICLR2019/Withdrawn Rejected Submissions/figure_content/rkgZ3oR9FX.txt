Figure 1: Constructing “close” and“far” contexts by exploiting thelatent neighborhood structure of3D chairs. Orange is a high in-degree seed chair, dark gray itsselected distractors in each context.
Figure 2:	Proposed listener architecture.
Figure 3:	(A) The listener places moreattention on adjectives in close (orange)triplets than far (blue) ones. (B)Lesioning highest attention words tolowest worsens performance more thanlesioning random words or lesioninglowest attention words.
Figure 4: Top-scoring retrieved results in collections of unseen objects with natural-languagequeries. Bottom two rows include out-of-class examples from collections of lamps, sofas and tables.
Figure 5:	Top-scoring synthetic utterances generated from listener-aware and context-awarespeakers for unseen targets. Proportions correspond classification scores of our independentevaluating listener.
Figure 6:	Our listener-aware speaker can produce informative referring expressions for out-of-classobjects in context. Here, we apply our search technique in the collection of ShapeNet Tables, toproduce triplets of well-separated objects. We use the queries: ’no legs’ (left), ’modern’ (center), and’x’ (right), to construct each triplet. Notice that the target of each triplet (selected from the highest-ranked matches) reflects the semantics of the used query, as opposed to the distractors (selected fromthe lowest-ranked matches).
Figure 7: Examples of attention weights on human utterances. The listener LSTM learnsattention weights that emphasize more informative words when forming its linguistic representation.
Figure 8: Examples of errors in listener model. Our top-performing listener model appeared tostruggle to interpret referential language that relied on metaphors, negations, precisely countingparts, ambiguous modifiers, or descriptions of the object’s texture or material. All examples aredrawn from the test set and were correctly classified by human listeners in the original task.
Figure 9:	Examples of errors in speaker models. Sometimes even the pragmatic (listener-aware) speaker produces insufficiently specific utterances that mention only undiagnostic features,or produces utterances that are literally false of the targert (e.g. there technically is a hole in theback) while still succeeding in distinguishing the objects.
Figure 10:	Search results for chairs Gallery of retrieved exemplars of held out chairs for differentqueries. Only the top five are shown.
Figure 11: Search results for out-of-class objects. Gallery of retrieved exemplars from other ShapeNet furniture categories for different queries. Top five andbottom five are shown, demonstrating intuitive contrasts from the highest ones. Note that there are some mislabeled objects in ShapeNet.
Figure 12: Effect of context on production: Synthetic utterances generated by a literal (context-aware) and pragmatic (listener-aware) speaker. The top and bottomrows show utterances produced for the same target in a far and close context, respectively. The best-performing listener’s prediction confidence for each object isdisplayed above: while both speaker models produce similarly effective utterances in far contexts, the literal speaker fails to produce effective utterances in closecontexts.
Figure 13: Measuring the effect of using different α, β values to select the top-1 scoring sentencefor context-aware and unaware speakers when creating utterances for the objects/contexts of thevalidation split. The y-axis in each subplot denotes the performance of a listener who is used to rankand evaluate the sentences. Averages are with respect to 5 random seeds controlling the data splitsand the initializations of the neural-networks.
Figure 14: Effect of using a different fraction of the training data for the evaluating listener whenusing two separate listeners (for evaluating and scoring a speaker’s results.). On the x-axis is thefraction f of the entire training data (80% of the dataset) that is used by the evaluator. 1 - f is usedby the utterance-scoring listener. Averages are with respect to 5 random seeds controlling the datasplits and the initializations of the neural-networks.
Figure 15: Listener’s accuracy for different sizes of training data, under the object generalizationtask. The original split includes [80%, 10%, 10%] for training/test/val purposes, thus the maximumsize of training data is 0.8 of the entire dataset when the fraction is 1.0 (x-axis). The listener modeluses the main architecture with using attention, images and point-clouds and its accuracy is alwaysmeasured on the original (10%) test split. Results with five random seeds controlling the originaldata split and the neural-net’s initialization.
Figure 16: Reference game interface.
