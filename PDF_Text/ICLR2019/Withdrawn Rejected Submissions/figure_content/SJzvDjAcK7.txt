Figure 1:	Variance Ratio captured by varying number of Singular ValuesEffective rank of activations: Figure 1(a) shows the variance ratio captured by varying numbersof singular values in the activations before the last FC layer. In this case, every model shows thatthe effective rank of the activations is 10 as there is a sharp elbow in the plot after 10 singular values.
Figure 2:	Adversarial accuracy plotted against magnitude of perturbation (measured with ρ).
Figure 3:	For each model, original images are on the top row and the images generated by DeepFoolare below.
Figure 4:	Adversarial Perturbation in Input Space and Perturbation in Representation SpaceMax Margin Classifiers: Finally, we show that X-MAXG models are significantly more robust toadversarial attacks than the corresponding “X” models. Also, as seen in Table 4, X-MAXG modelswith LR-layers are more robust than X-MAXG models without LR-layers against adversarial attacks.
Figure 5: Variance Ratio captured by varying number of Singular ValuesEffective rank of activations for VGG:C.2 Validity of low dimensional embeddingsIn the first experiment, reported in Table 2(a), we trained two ResNet-50-MAXG models -withand without the LR-layer respectively- on the 20 super-classes of CIFAR-100. As our objectivehere is to see if the embeddings and their low dimensional projections could be effectively used fordiscriminative tasks, we used PCA, with standard pre-processing of scaling the input, to project theembeddings onto a low dimensional space before training a linear maximum margin classifier on it.
Figure 6: Class wise variance ratio of one singular values for the activations before the last ResNetblock.
Figure 7: PCA plot for super-class labels in CIFAR 100. Plot on the left shows embeddings from theLR trained model on ResNet-50 while the plot on the right represents a normal ResNet-50 model.
Figure 8: This shows that an adversarial example that has successfully fooled the classifier in aprevious step can be classified correctly upon adding more perturbation. Figure ?? and ?? refers tothe two attack schemes - Iter-LL-FSGM and Iter-FSGM respectively.
