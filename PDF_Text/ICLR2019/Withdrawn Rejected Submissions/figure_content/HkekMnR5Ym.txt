Figure 2:	Sampling strategies on MNIST. Space consumption at 1% FPR.
Figure 3:	Memory access analysis. Three different learned solutions to class-based familiarity. Wetrain three Neural Bloom Filter variants with 10 memory slots and visualize memory addressing aand contents M, broken down by class. Solutions share broad correspondence to known algorithms:(a) Bloom-g filters, (b) Bloom Filters, (c) Perfect hashing.
Figure 4: Database task. Models are trained up to sets of size 200 (dashed line).
Figure 5: The effect of sphering the query vector on performance in the uniform MNIST samplingtask.
