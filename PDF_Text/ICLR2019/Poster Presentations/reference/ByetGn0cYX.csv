title,year,conference
 Maximum a Posteriori Policy oPtimisation,2018, arXiv preprint arXiv:1806
 Planning by Probabilistic inference,2003, In AISTATS
 Planning as inference,2012, Trends in cognitive sciences
 Openai gym,2016, arXiv preprint arXiv:1606
 Sample-efficientreinforcement learning with stochastic ensemble value expansion,2018, arXiv preprint arXiv:1807
 DeeP reinforcement learn-ing in a handful of trials using Probabilistic dynamics models,2018, arXiv preprint arXiv:1805
 Deep visual foresight for planning robot motion,2017, In Robotics andAutomation (ICRA)
 Neural adaptive sequential monte carlo,2015, InAdvances in Neural Information Processing Systems
 Learning to search with mctsnets,2018, arXiv preprint arXiv:1802
 World models,2018, CoRR
 Soft actor-critic: Off-policy maxi-mum entropy deep reinforcement learning with a stochastic actor,2018, arXiv preprint arXiv:1801
 Long short-term memory,1997, NeUral computation
 Contributions to the theory of optimal control,1960, Bol
 Sequential monte carlo for modelpredictive control,2009, In Nonlinear Model Predictive Control
 A sparse sampling algorithm for near-optimalplanning in large markov decision processes,2002, Machine learning
 Adam: A method for stochastic optimization,2014, arXiv preprintarXiv:1412
 Auto-encoding variational bayes,2013, arXiv preprintarXiv:1312
 The two-filter formula for smoothing and an implementation of the gaussian-sumsmoother,1994, Annals of the Institute of Statistical Mathematics
 Learning plannablerepresentations with causal infogan,2018, arXiv preprint arXiv:1807
 Auto-encoding sequentialmonte carlo,2017, arXiv preprint arXiv:1705
 Variational policy search via trajectory optimization,2013, In Advancesin Neural Information Processing Systems
 Backward simulation methods for monte carlo statisticalinference,2013, Foundations and TrendsR in Machine Learning
 Particle value functions,2017, arXiv preprint arXiv:1703
 Filtering variational objectives,2017, In Advances in Neural InformationProcessing Systems
 Variationalsequential monte carlo,2017, arXiv preprint arXiv:1705
 Neural network dynam-ics for model-based deep reinforcement learning with model-free fine-tuning,2017, arXiv preprintarXiv:1708
 Combining policygradient and q-learning,2016, arXiv preprint arXiv:1611
 An approximate inference approach totemporal optimization in optimal control,2010, In Advances in neural information processing systems
 Mastering the game of go withouthuman knowledge,2017, Nature
 Goal-directed decision making as probabilistic inference: acomputational framework and potential neural correlates,2012, Psychological review
 Learning tetris using the noisy cross-entropy method,2006, Neuralcomputation
 Synthesis and stabilization of complex behaviorsthrough online trajectory optimization,2012, In Intelligent Robots and Systems (IROS)
 A generalized iterative lqg method for locally-optimal feedbackcontrol of constrained nonlinear stochastic systems,2005, In American Control Conference
 Robot trajectory optimization using approximate inference,2009, In Proceedings of the26th annual international conference on machine learning
 Probabilistic inference for solving discrete and continuous statemarkov decision processes,2006, In Proceedings of the 23rd international conference on Machinelearning
 Modeling purposeful adaptive behavior with the principle of maximum causalentropy,2010, 2010
