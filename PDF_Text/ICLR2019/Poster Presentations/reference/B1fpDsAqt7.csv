title,year,conference
 Bottom-up and Top-down Attention for Image Captioning and VQA,2018, In CVPR
 Neural Module Networks,2016, InCVPR
 Learning phrase representations using rnn encoder-decoder forstatistical machine translation,2014, arXiv preprint arXiv:1406
 Deep residual learning for imagerecognition,2016, In CVPR
 Compositional attention networks for machinereasoning,2018, In ICLR
 CLEVR: A diagnostic dataset for compositional language and elementary visualreasoning,2017, In CVPR
 Inferring and Executing Programs for Visual Reasoning,2017, In ICCV
 Deep Visual-Semantic Alignments for Generating Image Descrip-tions,2015, In CVPR
 Bilinear attention networks,2018, arXiv preprintarXiv:1805
 Microsoft COCO: Common Objects in Context,2014, In ECCV
 Learning Multiple Tasks withMultilinear Relationship NetWorks,2017, In NIPS
 Visual Relationship Detection WithLanguage Priors,2016, In ECCV
 Cross-Stitch NetWorks forMulti-task Learning,2016, In CVPR
 GloVe: Global Vectors for WordRepresentation,2014, In Empirical Methods in Natural Language Processing (EMNLP)
 Faster R-CNN: ToWards Real-time ObjectDetection With Region Proposal NetWorks,2015, In NIPS
 An OvervieW of Multi-Task Learning in Deep Neural NetWorks,2017, arXiv preprint
 Learning What to sharebetWeen loosely related tasks,2017, arXiv preprint
 Progressive Neural NetWorks,2016, arXiv preprint
 CIDEr: Consensus-based ImageDescription Evaluation,2015, In CVPR
 The vqa-machine: Learning hoW touse existing vision algorithms to ansWer neW questions,2017, In CVPR
 Trace Norm Regularised Deep Multi-Task Learning,2017, InICLR Workshop Track
 Stacked Attention NetWorksfor Image Question AnsWering,2016, In CVPR
 Beyond Bilinear: GeneralizedMultimodal Factorized High-Order Pooling for Visual Question AnsWering,2018, IEEE Transactions onNeural Networks and Learning Systems
 Taskonomy: Disentangling Task Transfer Learning,2018, In CVPR
 Learning to Count Objects in Natural Imagesfor Visual Question AnsWering,2018, In ICLR
 ∆cap is implemented as an MLP,1000, The receivers project the outputs into 1000dimensional vectors vobj 
 Mcnt is trained using cross-entropy loss on questions starting with ‘how many’ fromthe VQA 2,2019,0 dataset
