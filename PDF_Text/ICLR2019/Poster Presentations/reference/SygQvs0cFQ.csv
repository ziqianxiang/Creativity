title,year,conference
 An empirical study of smoothing techniques for languagemodeling,1996, In Proc
 Learning phrase representations using rnn encoder-decoder forstatistical machine translation,2014, In Proc
 Semi-supervised sequence learning,2015, In Proc
 Dropout as a bayesian approximation: Representing modeluncertainty in deep learning,2016, In Proc
 A theoretically grounded application of dropout in recurrentneural networks,2016, In Proc
 Improving neural language models with acontinuous cache,2017, In Proc
 Long short-term memory,1997, Neural Computation
 Ridge regression: Biased estimation for nonorthogonalproblems,1970, Technometrics
 Tying word vectors and word classifiers: Aloss framework for language modeling,2017, In Proc
 In Proc,2015, of ACL
 Ask me anything: Dynamic memory networks for naturallanguage processing,2016, In Proc
 On the state of the art of evaluation in neural languagemodels,2018, In Proc
 Pointer sentinel mixturemodels,2017, In Proc
 Regularizing and optimizing lstmlanguage models,2018, In Proc
 Using the output embedding to improve language models,2017, In Proceedingsof the 15th Conference of the European Chapter of the Association for Computational Linguistics:Volume 2
 Datanoising as smoothing in neural network language models,2017, In Proc
 Breaking the softmaxbottleneck: A high-rank rnn language model,2017, arXiv preprint arXiv:1711
 Memory architectures in recurrent neural network language models,2018, In Proc
