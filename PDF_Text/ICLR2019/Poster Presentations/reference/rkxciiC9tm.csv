title,year,conference
 Benchmarking deepreinforcement learning for continuous control,2016, In International Conference on Machine Learning
 Stochastic neural networks for hierarchical rein-forcement learning,2017, arXiv preprint arXiv:1704
 Ex2: Exploration with exemplar models for deepreinforcement learning,2017, In Advances in Neural Information Processing Systems
 Dropout as a bayesian approximation: Representing modeluncertainty in deep learning,2016, In international conference on machine learning
 Policy optimization by genetic distillation,2017, arXiv preprintarXiv:1711
 Muprop: Unbiased backpropagationfor stochastic neural networks,2016, ICLR
 Bayesian policy gradients via alphadivergence dropout inference,2017, arXiv preprint arXiv:1712
 Improving neural networks by preventing co-adaptation of feature detectors,2012, arXiv preprintarXiv:1207
 Vime:Variational information maximizing exploration,2016, In Advances in Neural Information ProcessingSystems 
 Adam: A method for stochastic optimization,2014, arXiv preprintarXiv:1412
 Auto-encoding variational bayes,2013, arXiv preprintarXiv:1312
 Variational dropout and the local reparame-terization trick,2015, In Advances in Neural Information Processing Systems
 Continuous control with deep reinforcement learning,2015, arXivpreprint arXiv:1509
 The concrete distribution: A continuousrelaxation of discrete random variables,2016, arXiv preprint arXiv:1611
 Asynchronous methods for deep reinforcementlearning,2016, In International Conference on Machine Learning
 Variational dropout sparsifies deep neuralnetworks,2017, arXiv preprint arXiv:1701
 Generalization and exploration via randomizedvalue functions,2014, arXiv preprint arXiv:1402
 Deep exploration viabootstrapped dqn,2016, In Advances in neural information processing systems
 Deep exploration via randomizedvalue functions,2017, arXiv preprint arXiv:1703
 Count-based explo-ration with neural density models,2017, arXiv preprint arXiv:1703
 Curiosity-driven explorationby self-supervised prediction,2017, In International Conference on Machine Learning (ICML)
 Techniques for learningbinary stochastic feedforward neural networks,2015, ICLR
 Black box variational inference,2014, In ArtificialIntelligence and Statistics
 Stochastic backpropagation andapproximate inference in deep generative models,2014, arXiv preprint arXiv:1401
 State-dependent exploration for policygradient methods,2008, In Joint European Conference on Machine Learning and Knowledge Discoveryin Databases
 Evolution strategies as ascalable alternative to reinforcement learning,2017, arXiv preprint arXiv:1703
 Gradient estimation usingstochastic computation graphs,2015, In Advances in Neural Information Processing Systems
 Trust regionpolicy optimization,2015, In International Conference on Machine Learning
 High-dimensional continuous control using generalized advantage estimation,2015, arXiv preprintarXiv:1506
 Proximal policyoptimization algorithms,2017, arXiv preprint arXiv:1707
 Deep neuroevolution: Genetic algorithms are a competitive alternative for trainingdeep neural networks for reinforcement learning,2017, arXiv preprint arXiv:1712
 Regularization of neuralnetworks using dropconnect,2013, In International Conference on Machine Learning
 Fast dropout training,2013, In international conference on machinelearning
 Sample efficient actor-critic with experience replay,2016, arXiv preprintarXiv:1611
 Simple statistical gradient-following algorithms for connectionist reinforcementlearning,1992, In Reinforcement Learning
