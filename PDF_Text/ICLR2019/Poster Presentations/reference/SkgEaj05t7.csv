title,year,conference
 High-dimensional dynamics of generalization error inneural networks,2017, arXiv preprint arXiv:1710
 Identifying and attacking the saddle point problem in high-dimensionalnon-convex optimiZation,2014, CoRR
 Sharp minima cangeneraliZe for deep nets,2017, arXiv preprint arXiv:1703
 Flat minima,1997, Neural Computation
 Three factors influencing minima in sgd,2017, arXiv preprintarXiv:1711
 An iteration method for the solution of the eigenvalue problem of lineardifferential and integral operators,1950, J
 NetWork information criterion-determining the number of hidden units for an artificial neural netWork model,1994, IEEEtransactions on neural networks
 ExploringgeneraliZation in deep learning,2017, CoRR
 Theory of deep learning iii: explaining thenon-overfitting puZZle,2017, arXiv preprint arXiv:1801
 Empirical analysisof the hessian of over-parametriZed neural netWorks,2017, arXiv preprint arXiv:1706
 Very deep convolutional netWorks for large-scaleimage recognition,2014, CoRR
 Deep residual netWorks and Weight initialiZation,2017, CoRR
 Themarginal value of adaptive gradient methods in machine learning,2017, 2017
 Hessian-based analysis of large batch training and robustness to adversaries,2018, arXiv preprintarXiv:1802
 Under-standing deep learning requires rethinking generalization,2016, arXiv preprint arXiv:1611
