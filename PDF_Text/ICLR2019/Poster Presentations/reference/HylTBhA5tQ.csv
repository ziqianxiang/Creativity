title,year,conference
 Synthesizing robust adversarial examples,2017, arXiv preprintarXiv:1707
 Obfuscated gradients give a false sense ofsecurity: Circumventing defenses to adversarial examples,2018, International Conference on MachineLearning (ICML)
 Adversarial examples from Cryp-tographic pseudo-random generators,2018, arXiv preprint arXiv:1811
 Adversarial examples from computationalconstraints,2018, arXiv preprint arXiv:1805
 Thermometer encoding: One hotway to resist adversarial examples,2018, ICLR
 Towards evaluating the robustness of neural networks,2017, In 2017IEEE Symposium on Security and Privacy (SP)
 Pac-learning in the presence of evasionadversaries,2018, arXiv preprint arXiv:1806
 Stochastic activation pruning for robust adversarial de-fense,2018, arXiv preprint arXiv:1803
 Adual approach to scalable verification of deep networks,2018, UAI
 Countering adversarialimages using input transformations,2017, arXiv preprint arXiv:1711
 Formal guarantees on the robustness of a classifieragainst adversarial manipulation,2017, In Advances in Neural Information Processing Systems (NIPS)
 Detec-tion of traffic signs in real-world images: The German Traffic Sign Detection Benchmark,2013, InInternational Joint Conference on Neural Networks
 Discriminative deep metric learning for face verification inthe wild,2014, In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition
 Deep transfer metric learning,2015, In Proceedings of the IEEEConference on Computer Vision and Pattern Recognition
 Reluplex: Anefficient smt solver for verifying deep neural networks,2017, In International Conference on ComputerAided Verification
 Provable defenses against adversarial examples via the convex outeradversarial polytope,2018, ICML
 Adversarial machine learning at scale,2016, arXivpreprint arXiv:1611
 Towards robust neural networksvia random self-ensemble,2018, ECCV
 Characterizing adversarial subspaces using localintrinsic dimensionality,2018, arXiv preprint arXiv:1801
 The curse of concentrationin robust learning: Evasion and poisoning attacks from concentration of measure,2018, arXiv preprintarXiv:1809
 Umap: Uniform manifold approximation and projection for di-mension reduction,2018, arXiv preprint arXiv:1802
 Distillation as adefense to adversarial perturbations against deep neural networks,2016, In 2016 IEEE Symposium onSecurity and Privacy (SP)
 Certified defenses against adversarial exam-ples,2018, arXiv preprint arXiv:1801
 Defense-GAN: Protecting classifiersagainst adversarial attacks using generative models,2018, arXiv preprint arXiv:1805
 Ad-versarially robust generalization requires more data,2018, NIPS
 Certifying some distributional robustness withprincipled adversarial training,2018, ICLR
 Pixeldefend:Leveraging generative models to understand and defend against adversarial examples,2017, arXivpreprint arXiv:1710
 Generative adversarial examples,2018, arXivpreprint arXiv:1805
 Is robustnessthe cost of accuracy?-a comprehensive study on the robustness of 18 deep image classificationmodels,2018, In Proceedings of the European Conference on Computer Vision (ECCV)
 Intriguing properties of neural networks,2013, arXiv preprint arXiv:1312
 Ensemble adversarial training: Attacks and defenses,2018, In International Conference onLearning Representations (ICLR)
 Scaling provable adversarialdefenses,2018, NIPS
 Generating adver-sarial examples with adversarial networks,2018, arXiv preprint arXiv:1801
 Mitigating adversarialeffects through randomization,2017, arXiv preprint arXiv:1711
 Feature squeezing: Detecting adversarial examples in deepneural networks,2017, arXiv preprint arXiv:1704
 Efficient neural net-work robustness certification with general activation functions,2018, In Advances in Neural InformationProcessing Systems (NIPS)
 Distributionally adversarial attack,2018, arXiv preprintarXiv:1808
1	DISTANCE DISTRIBUTIONS UNDER DIFFERENT NEAREST NEIGHBOUR PARAMETERS kAs discussed in Section 3,1000,1
