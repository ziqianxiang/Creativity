title,year,conference
 Obfuscated gradients give a false sense ofsecurity: Circumventing defenses to adversarial examples,2018, arXiv preprint arXiv:1802
 Data-driven discretiza-tion: a method for systematic coarse graining of partial differential equations,2018, arXiv preprintarXiv:1808
 Piecewiselinear neural network verification: A comparative study,2017, CoRR
 Adversarial examples are not easily detected: Bypassing tendetection methods,2017, In Proceedings of the 10th ACM Workshop on Artificial Intelligence andSecurity
 Towards evaluating the robustness of neural networks,2017, In 2017IEEE Symposium on Security and Privacy (SP)
 Maximum resilience of artificial neuralnetworks,2017, In International Symposium on Automated Technology for Verification and Analysis
 Training verified learners with learned ver-ifiers,2018, CoRR
 Adual approach to scalable verification of deep networks,2018, arXiv preprint arXiv:1803
 Learning a physical long-term predictor,2017, arXiv preprint arXiv:1703
 Ai 2: Safety and robustness certification of neural networks with abstract interpreta-tion,2018, In Security and Privacy (SP)
 Explaining and harnessing adversarial examples,2014, arXivpreprint arXiv:1412
 On the effectiveness of interval bound propagation fortraining verifiably robust models,2018, arXiv preprint arXiv:1810
 Safety verification of deep neuralnetworks,2017, In International Conference on Computer Aided Verification
 Reluplex: Anefficient smt solver for verifying deep neural networks,2017, In International Conference on ComputerAided Verification
 Imagenet classification with deep convo-lutional neural networks,2012, In Advances in neural information processing systems
 Semidefiniterelaxation of quadratic optimization problems,2010, IEEE Signal Processing Magazine
 Wordnet: a lexical database for english,1995, Communications of the ACM
 Differentiable abstract interpretation for prov-ably robust neural networks,2018, In Jennifer Dy and Andreas Krause (eds
 Differentiable abstract interpretation for prov-ably robust neural networks,2018, In Jennifer Dy and Andreas Krause (eds
 Transferability in machine learning: fromphenomena to black-box attacks using adversarial samples,2016, arXiv preprint arXiv:1605
 Certified defenses against adversarial exam-ples,2018, arXiv preprint arXiv:1801
 Intriguing properties of neural networks,2013, arXiv preprint arXiv:1312
 Deepmind control suite,2018, arXivpreprint arXiv:1801
 Verifying neural networks with mixed integer programming,2017, arXivpreprint arXiv:1711
 Provable defenses against adversarial examples via the convex oUteradversarial polytope,2018, In Jennifer Dy and Andreas KraUse (eds
 Scaling provable adversarialdefenses,2018, CoRR
