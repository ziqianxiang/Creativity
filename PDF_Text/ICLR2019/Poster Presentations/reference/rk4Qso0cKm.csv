title,year,conference
 Obfuscated gradients give a false sense ofsecurity: Circumventing defenses to adversarial examples,2018, arXiv preprint arXiv:1802
 Weight uncertainty inneural network,2015, In International Conference on Machine Learning
 Adversarial examples are not easily detected: Bypassing tendetection methods,2017, In Proceedings of the 10th ACM Workshop on Artificial Intelligence andSecurity
 Towards evaluating the robustness of neural networks,2017, InSecurity and Privacy (SP)
 Imagenet: A large-scalehierarchical image database,2009, In Computer Vision and Pattern Recognition
 Evaluating and understanding the robustnessof adversarial logit pairing,2018, arXiv preprint arXiv:1807
 Robust physical-world attacks on machine learning models,2017, arXivpreprint arXiv:1707
 Detecting adversarialsamples from artifacts,2017, arXiv preprint arXiv:1703
 Explaining and harnessing adversarialexamples,2015, In International Conference on Learning Representations
 Learning with a strong adver-sary,2015, arXiv preprint arXiv:1511
 Black-box adversarial attacks withlimited queries and information,2018, arXiv preprint arXiv:1804
 Spike and slab variable selection: frequentist and bayesianstrategies,2005, TheAnnalsofStatistics
 Variational dropout and the local reparame-terization trick,2015, In Advances in Neural Information Processing Systems
 Adversarial machine learning at scale,2017, InInternational Conference of Learning Representation
 Adversarial attacks and defences competition,2018, arXivpreprint arXiv:1804
 Preconditioned stochasticgradient langevin dynamics for deep neural networks,2016, In AAAI
 De-fense against adversarial attacks using high-level representation guided denoiser,2017, arXiv preprintarXiv:1712
 Towards robust neural networksvia random self-ensemble,2017, arXiv preprint arXiv:1712
 Delving into transferable adversarial exam-ples and black-box attacks,2016, arXiv preprint arXiv:1611
 cgans with projection discriminator,2018, 2018
 Distillation as adefense to adversarial perturbations against deep neural networks,2016, In Security and Privacy (SP)
 Practical black-box attacks against machine learning,2017, In Proceedings of the 2017 ACMon Asia Conference on Computer and Communications Security
 Ad-versarially robust generalization requires more data,2018, arXiv preprint arXiv:1804
 Understanding measures of uncertainty for adversarial example detec-tion,2018, arXiv preprint arXiv:1803
 Intriguing properties of neural networks,2013, arXiv preprint arXiv:1312
 Mitigating adversarialeffects through randomization,2017, arXiv preprint arXiv:1711
 Bayesian adversarial learning,2018, In S
 Efficient defenses against adver-sarial attacks,2017, In Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security
