title,year,conference
 Natural gradient works efficiently in learning,1998, Neural computation
 A new learning algorithm for blindsignal separation,1996, In Advances in neural information processing systems
 Adaptive method of realizing natural gradientlearning for multilayer perceptrons,2000, Neural Computation
 On-line variational bayesian learning,2003, In 4th InternationalSymposium on Independent Component Analysis and Blind Signal Separation
 Batch normalization: Accelerating deep network training byreducing internal covariate shift,2015, In International Conference on Machine Learning
 Eigenvalues of covariance matrices: Application toneural-network learning,1991, Physical Review Letters
 Gradient episodic memory for continual learning,2017, In Advances in NeuralInformation Processing Systems
 New perspectives on the natural gradient method,2014, arXiv preprint arXiv:1412
 Optimizing neural networks with kronecker-factored approximatecurvature,2015, In International Conference on Machine Learning
 Revisiting natural gradient for deep networks,2013, arXiv preprintarXiv:1301
 Automatic differentiation inpytorch,2017, 2017
 Regularizingneural networks by penalizing confident output distributions,2017, arXiv preprint arXiv:1701
 icarl:Incremental classifier and representation learning,2017, In Proc
 Online structured laplace approximations forovercoming catastrophic forgetting,2018, arXiv preprint arXiv:1805
 Weight normalization: A simple reparameterization toaccelerate training of deep neural netWorks,2016, In Advances in Neural Information ProcessingSystems
 Accelerated gradient descent by factor-centering decomposition,1998, 1998
 Tempering backpropagation netWorks: Not allWeights are created equal,1996, In Advances in neural information processing systems
 Transformation invariance inpattern recognitiontangent distance and tangent propagation,1998, Neural networks: tricks of the trade
 On the importance of initializationand momentum in deep learning,2013, In International conference on machine learning
 Variance reduction for stochasticgradient optimization,2013, In Advances in Neural Information Processing Systems
