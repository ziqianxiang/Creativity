title,year,conference
 Policy search by dynamicprogramming,2004, In Advances in neural information processing systems
 Infinite-horizon policy-gradient estimation,1076, J
 Neuro-dynamic programming: an overview,1995, In Proceedings ofthe 34th IEEE Conference on
 From machine learning to machine reasoning,2013, Machine Learning
 Generalization in reinforcement learn-ing: Safely approximating the value function,1995, In G
 Deep heuristic-learning in the rubik’s cube domain: an experi-mental evaluation,2017, 2017
 Pattern databases,1998, Computational Intelligence
 Stable function approximation in dynamic programming,1995, Technical report
 A natural policy gradient,2001, In Thomas G
 Approximately optimal approximate reinforcement learning,2002, InInternational Conference on Machine Learning
 Analysis of a classification-basedpolicy iteration algorithm,2010, In International Conference on Machine Learning
 The rubik cube and gp temporal sequence learning: aninitial study,2011, In Genetic Programming Theory and Practice VIII
 On-line q-learning using connectionist systems,1994, Technical report
 Approximate policy iteration schemes: A comparison,2014, 2014
 On the scalability of parallel uct,2011, In H
 Mastering thegame of go without human knowledge,0028, Nature
 Mastering the game of go withouthuman knowledge,2017, Nature
 Discovering rubik’s cube subgroups usingcoevolutionary gp: A five twist experiment,2016, In Proceedings of the Genetic and EvolutionaryComputation Conference 2016
 External memory bidirectional search,2016, In IJCAI
 Dual policy iteration,2018, CoRR
 Simple statistical gradient-folloWing algorithms for connectionist reinforcementlearning,1992, In Reinforcement Learning
