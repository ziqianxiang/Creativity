title,year,conference
 Obfuscated gradients give a false senseof security: Circumventing defenses to adversarial examples,2018, In International Conference onMachine Learning (ICML)
 Synthesizing robust adversarialexamples,2018, In International Conference on Machine Learning (ICML)
 Adversarial examples are not easily detected: Bypassing tendetection methods,2017, In Proceedings of the 10th ACM Workshop on Artificial Intelligence andSecurity
 Towards evaluating the robustness of neural networks,2017, InIEEE Symposium on Security and Privacy
 Maximum resilience of artificial neuralnetworks,2017, CoRR
 A survey of model compression and accelerationfor deep neural networks,2017, CoRR
 Training verified learners with learned ver-ifiers,2018, arXiv preprint arXiv:1805
 Formal verification of piece-wise linear feed-forward neural networks,2017, In DeepakDâ€™Souza and K
 Robust physical-world attacks on machine learning models,2017, CoRR
 Explaining and harnessing adversarialexamples,2015, In International Conference on Learning Representations
 On the effectiveness of interval bound propagation fortraining verifiably robust models,2018, arXiv preprint arXiv:1810
 Adversarial logit pairing,2018, CoRR
 Reluplex: Anefficient smt solver for verifying deep neural networks,2017, In Rupak Majumdar and Viktor Kuncak
 Adam: A method for stochastic optimization,2015, In InternationalConference on Learning Representations (ICLR)
 An approach to reachability analysis for feed-forward reluneural networks,2017, CoRR
 Differentiable abstract interpretation for prov-ably robust neural networks,2018, In Jennifer Dy and Andreas Krause
 Distillationas a defense to adversarial perturbations against deep neural networks,2016, 2016 IEEE Symposium onSecurity and Privacy (SP)
 Certified defenses against adversarial examples,2018, InInternational Conference on Learning Representations (ICLR)
 Masteringthe game of go with deep neural networks and tree search,2016, nature
 Mastering the game of gowithout human knowledge,2017, Nature
 Certifiable distributional robustness withprincipled adversarial training,2018, In International Conference on Learning Representations (ICLR)
 Intriguing properties of neural networks,2014, CoRR
 Deepface: Closing the gap tohuman-level performance in face verification,2014, In Proceedings of the 2014 IEEE Conference onComputer Vision and Pattern Recognition
 Verifying neural networks with mixed integer program-ming,2017, CoRR
 Provable defenses against adversarial examples via the convex outeradversarial polytope,2018, In International Conference on Machine Learning (ICML)
 Scaling provable adversarialdefenses,2018, NIPS
