title,year,conference
 Synthesizing robust adversarial examples,2017, arXiv preprintarXiv:1707
 Obfuscated gradients give a false sense of security:Circumventing defenses to adversarial examples,2018, arXiv preprint arXiv:1802
 Evasion attacks against machine learning at test time,2013, In Joint European conferenceon machine learning and knowledge discovery in databases
 Thermometer encoding: One hot way toresist adversarial examples,2018, OpenReview
 Defensive distillation is not robust to adversarial examples,2016, arXivpreprint arXiv:1607
 Magnet and “efficient defenses against adversarial attacks” are not robustto adversarial examples,2017, arXiv preprint arXiv:1711
 Towards evaluating the robustness of neural networks,2017, In Security andPrivacy (SP)
 Stochastic activation pruning for robust adversarial defense,2018, arXivpreprint arXiv:1803
 Adversarial vulnerability for any classifier,2018, arXiv preprintarXiv:1802
 Adversarial spheres,2018, arXiv preprint arXiv:1801
 Countering adversarial imagesusing input transformations,2017, arXiv preprint arXiv:1711
 Provable defenses against adversarial examples via the convex outer adversarialpolytope,2017, arXiv preprint arXiv:1711
 Adversarial examples in the physical world,2016, arXivpreprint arXiv:1607
 The concentration of measure phenomenon,2001, Number 89
 Characterizing adversarial subspaces using local intrinsicdimensionality,2018, arXiv preprint arXiv:1801
 Towardsdeep learning models resistant to adversarial attacks,2017, arXiv preprint arXiv:1706
 The curse of concentration in robustlearning: Evasion and poisoning attacks from concentration of measure,2018, arXiv preprint arXiv:1809
 On the method of bounded differences,1989, London Mathematical Society Lecture Notes
 MagNet: a two-pronged defense against adversarial examples,2017, In Proceedingsof the 2017 ACM SIGSAC Conference on Computer and Communications Security
 The isoperimetric inequality,1978, Bulletin of the American Mathematical Society
 Transferability in machine learning: from phe-nomena to black-box attacks using adversarial samples,2016, arXiv preprint arXiv:1605
 Distillation as a defenseto adversarial perturbations against deep neural networks,2016, In Security and Privacy (SP)
 Certified defenses against adversarial examples,2018, arXivpreprint arXiv:1801
 The isoperimetric problem,2001, Global theory of minimal surfaces
 Defense-GAN: Protecting classifiers against ad-versarial attacks using generative models,2018, arXiv preprint arXiv:1805
 APE-GAN: Adversarial perturbation eliminationwith GAN,2017, ICLR Submission
 Adver-sarial vulnerability of neural networks increases with input dimension,2018, arXiv preprint arXiv:1802
 Certifying some distributional robustness with princi-pled adversarial training,2018, OpenReview
 PixelDefend: Lever-aging generative models to understand and defend against adversarial examples,2017, arXiv preprintarXiv:1710
 One pixel attack for fooling deep neural net-works,2017, arXiv preprint arXiv:1710
 Intriguing properties of neural networks,2013, arXiv preprint arXiv:1312
 Concentration of measure and isoperimetric inequalities in product spaces,1995, PublicationsMathematiques de IfInstitut des Hautes Etudes Scientifiques
 A new look at independence,1996, TheAnnalSofprobability
 The space of trans-ferable adversarial examples,2017, arXiv preprint arXiv:1704
 High-Dimensional Probability,2017, Cambridge University Press
 Mitigating adversarial effects throughrandomization,2017, arXiv preprint arXiv:1711
 Feature squeezing: Detecting adversarial examples in deep neuralnetworks,2017, arXiv preprint arXiv:1704
 Efficient defenses against adversarial at-tacks,2017, In Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security
