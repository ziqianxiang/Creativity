title,year,conference
 Multi-agent learning in network zero-sum games is aHamiltonian system,2019, In Int
 In Proc,2018, ICML
 Training GANs withoptimism,2018, In Proc
 Fictitious GAN: Training GANs withhistorical models,2018, CoRR
 A variational inequalityperspective on generative adversarial nets,2018, CoRR
 Generative adversarial nets,2014, In Advances in NeuralInformation Processing Systems 27
 Im-proved training of Wasserstein GANs,1704, In Advances in Neural Information Processing Systems 30(NIPS 2017)
 Adam: A method for stochastic optimization,2014, CoRR
 Deep learning face attributes in the wild,2015, InProc
 Cycles in adversar-ial regularized learning,2018, In Proc
 The numerics of GANs,2017, In Advances inNeural Information Processing Systems (NIPS)
 Which training methods for GANs doactually converge? In Proc,2018, International Conference on Machine learning (ICML)
 Spectral normalization forgenerative adversarial networks,2018, CoRR
 Gradient descent gan optimization is locally stable,2017, InAdvances in Neural Information Processing Systems
 From nash equilibria to chain recurrent sets: Analgorithmic solution concept for game theory,2018, Entropy
 Parallel WaveNet: Fast high-fidelity speech synthesis,2017, CoRR
 Activation maximization generative adversarial nets,2018, In Proc
