title,year,conference
 Constrained policy optimization,2017, arXiv preprintarXiv:1705
 Optimistic posterior sampling for reinforcement learning: worst-case regretbounds,2017, In Advances in Neural Information Processing Systems
 Lipschitz continuity in model-based reinforcementlearning,2018, arXiv preprint arXiv:1804
 Finite-data performance guarantees for the output-feedbackcontrol of an unknown system,2018, arXiv preprint arXiv:1803
 Deep reinforcement learning in ahandful of trials using probabilistic dynamics models,2018, arXiv preprint arXiv:1805
 Model-basedreinforcement learning via meta-policy optimization,2018, arXiv preprint arXiv:1809
 Unifying pac and regret: Uniform pac bounds for episodicreinforcement learning,2017, In Advances in Neural Information Processing Systems
 On the sample complexity of thelinear quadratic regulator,2017, arXiv preprint arXiv:1710
 Regret bounds for robust adaptivecontrol of the linear quadratic regulator,2018, arXiv preprint arXiv:1805
 Learning to control a low-cost manipulatorusing data-efficient reinforcement learning,2011, 2011
 A survey on policy search for robotics,2013, Foundationsand TrendsÂ® in Robotics
 Benchmarking deep reinforcementlearning for continuous control,2016, In International Conference on Machine Learning
 Value-aware loss function for model-basedreinforcement learning,2017, In Artificial Intelligence and Statistics
 Model-based value estimation for efficient model-free reinforcement learning,2018, arXiv preprint arXiv:1803
 Efficient bias-span-constrained exploration-exploitation in reinforcement learning,2018, arXiv preprint arXiv:1802
 Continuous deep q-learning with model-based acceleration,2016, In International Conference on Machine Learning
 World models,2018, arXivpreprint arXiv:1803
 Soft actor-critic: Off-policy maximumentropy deep reinforcement learning with a stochastic actor,2018, arXiv preprint arXiv:1801
 Lipschitz continuity of value functions in markovian decision processes,2005, Mathematical Methodsof Operations Research
 Approximately optimal approximate reinforcement learning,2002, In ICML
 Uncertainty-driven imagination for continuous deep reinforcementlearning,2017, In Conference on Robot Learning
 Near-optimal reinforcement learning in polynomial time,2002, Machine learning
 Learning stable nonlinear dynamical systems with gaussianmixture models,2011, IEEE Transactions on Robotics
 Auto-encoding variational bayes,2013, arXiv preprint arXiv:1312
 Gp-bayesfilters: Bayesian filtering using gaussian process prediction and observa-tion models,2009, Autonomous Robots
 Model-ensemble trust-regionpolicy optimization,2018, arXiv preprint arXiv:1802
 Improved regret bounds for undiscounted continuousreinforcement learning,2015, In International Conference on Machine Learning
 Learning neural network policies with guided policy search under unknowndynamics,2014, In Advances in Neural Information Processing Systems
 Guided policy search,2013, In International Conference on Machine Learning
 Continuous control with deep reinforcement learning,2015, arXiv preprint arXiv:1509
 Sample-based informationl-theoreticstochastic optimal control,2014, In Robotics and Automation (ICRA)
 Simple random search provides a competitive approach toreinforcement learning,2018, arXiv preprint arXiv:1803
 Human-level control through deepreinforcement learning,2015, Nature
 Asynchronous methods for deep reinforcement learning,2016, In Internationalconference on machine learning
 Optimism-driven explorationfor nonlinear systems,2015, In Robotics and Automation (ICRA)
 Minimax differential dynamic programming: An application torobust biped walking,2003, In Advances in neural information processing systems
 Neural network dynamics formodel-based deep reinforcement learning with model-free fine-tuning,2017, arXiv preprint arXiv:1708
 On the chi square and higher-order chi distances for approximating f-divergences,2014, IEEE Signal Processing Letters
 Learning model-based planning from scratch,2017, arXivpreprint arXiv:1707
 Zero-shot visual imitation,2018, In International Conferenceon Learning Representations
 Adaptive step-size for policy gradient methods,2013, InAdvances in Neural Information Processing Systems
 Temporal difference models: Model-free deep rlfor model-based control,2018, arXiv preprint arXiv:1802
 Temporal difference models: Model-free deep rlfor model-based control,2018, International Conference on Learning Representations
 Imagination-augmented agents fordeep reinforcement learning,2017, In AdvancesinNeuralInformationProcessingSystems
 Graph networks as learnable physics engines for inference and control,2018, arXivpreprint arXiv:1806
 f -divergence inequalities,2016, IEEE Transactions on Information Theory
 Trust region policyoptimization,2015, In International Conference on Machine Learning
 High-dimensional continuouscontrol using generalized advantage estimation,2015, arXiv preprint arXiv:1506
 Proximal policy optimizationalgorithms,2017, arXiv preprint arXiv:1707
 The bottlenecksimulator: A model-based deep reinforcement learning approach,2018, arXiv preprint arXiv:1807
 Learning without mixing:Towards a sharp analysis of linear system identification,2018, arXiv preprint arXiv:1802
 Dual policy iteration,2018, arXiv preprintarXiv:1805
 Model-based policygradients with parameter-based exploration by least-squares conditional density estimation,2014, Neural networks
 Mujoco: A physics engine for model-based control,2012, In IntelligentRobots and Systems (IROS)
 Model-based reinforcementlearning with parametrized physical models and optimism-driven exploration,2016, In 2016 IEEE InternationalConference on Robotics and Automation (ICRA)
 Model-less feedback control of continuum manipulators in constrainedenvironments,2014, IEEE Transactions on Robotics
3Proof of Lemma 4,2019,3
 ByLemma D,2019,1
