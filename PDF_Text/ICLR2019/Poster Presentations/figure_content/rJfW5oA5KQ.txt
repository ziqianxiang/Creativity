Figure 1: Experiments on the swiss roll dataset. The neural net IPM, the Wasserstein distance, and the samplequality are correlated along training. (a)(b): Sample batches from the ground truth and the learned generator atiteration 500 and 5000. (c): Comparing the F-IPM and the Wasserstein distance. RealG and fakeG denote theground truth generator and the learned generator, respectively.
Figure 2: Experiments on the unit circle dataset. The neural net IPM, the Wasserstein distance, and the samplequality are correlated along training. (a)(b): Sample batches from the ground truth and the learned generator atiteration 500 and 10000. (c): Comparing the F-IPM and the Wasserstein distance. RealG and fakeG denote theground truth generator and the learned generator, respectively.
Figure 3: Learning an invertible neural net generator on synthetic data. The x-axis in all the graphs indicatesthe number of steps. The left-most figure shows the KL-divergence between the true distribution p and learneddistribution q at different steps of training, the middle the estimated IPM (evaluation) between p and q, and theright one the training loss. We see that the estimated IPM in evaluation correlates well with the KL-divergence.
Figure 4: Scatter plot of KL divergence and neural net IPM on perturbed generator pairs. Cor-relation between log(Dkl(pkq) + Dkl(qkp)) and log WF is 0.7315. Dashed line is WF (p, q) =100(Dkl(pkq) + Dkl(qkp)).
Figure 5: Learning an invertible neural net generator on synthetic data with vanilla fully-connected discrim-inator nets. The x-axis in all the graphs indicates the number of steps. The left-most figure shows the KL-divergence between the true distribution p and learned distribution q at different steps of training, the middlethe estimated IPM (evaluation) between p and q, and the right one the training loss. We see that the estimatedIPM in evaluation correlates well with the KL-divergence. Moving average is applied to all curves.
Figure 6: Scatter plot of KL divergence and neural net IPM (with vanilla discriminators) on per-turbed generator pairs. Correlation between log(Dkl(pkq) + Dkl(qkp)) and log WF is 0.7489.
