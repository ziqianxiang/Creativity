Figure 1: Network model.
Figure 2: Error in recovering W , A and outputs (“MSE”) for different numbers of training samplesand different dimensions of W and A. Each point is the result of averaging across five trials, whereon the left W and A are both drawn as random 10 × 10 orthonormal matrices and in the center as32 × 32 orthonormal matrices. On the right, given 10, 000 training samples we plot the square rootof the algorithm’s error normalized by the dimension of W and A, which are again drawn as randomorthonormal matrices. The input distribution is a spherical Gaussian.
Figure 3: Error in recovering W, A and outputs (“MSE”) for different amounts of label noise. Eachpoint is the result of averaging across five trials with 10,000 training samples, where for each trialW and A are both drawn as 10 × 10 orthonormal matrices. The input distribution on the left is aspherical Gaussian and on the right a mixture of two Gaussians with one component based at theall-ones vector and the other component at its reflection.
Figure 4: Error in recovering W , A and outputs (“MSE”), on the left for different levels of con-ditioning of W and on the right for A. Each point is the result of averaging across five trials with20,000 training samples, where for each trial one parameter is drawn as a random orthonormal ma-trix while the other as described in Section 4.3. The input distribution is a mixture of Gaussians withtwo components, one based at the all-ones vector and the other at its reflection.
Figure 5: Characterize T as the product of four matrices.
