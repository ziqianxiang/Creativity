Figure 1: (a) Over time as the bottle is tilted, the uncertainty first rises and then falls as the bottle is held steadyafter tilting. (b)-(e) Similar uncertainty profiles corresponding to various scenarios—a ball rolling down the sideof a bowl, a car driving on a highway with an exit 100m away, an iron pellet tossed in the direction of a magnet,and intermediate frame prediction in a maze traversal given start and end states. The red asterisks along thex-axis correspond to the asterisks in the maze—these “bottleneck” states must occur in any successful traversal.
Figure 4: Forward prediction '1error for grasping. TAP methods(red) perform better than fixed-time predictors over all timesteps.
Figure 3: (Best seen in pdf) One sample episode each for grasping, pick-and-place, and pushing. Time overlaid on each frame.
Figure 5: (Best seen in pdf) Forward prediction results on grasping comparing fixed-time predictors and ourapproach. Each row is a separate example. First column is the input. Thereafter, each column corresponds to theoutput of a different model per the column title. More in Appendix Fig 17.
Figure 6: (Best seen in pdf) Bidirectional prediction results comparing fixed-time prediction and our approach.
Figure 9: (Best seen in pdf) (Left) Bidirectional prediction results on two-object pushing. More in AppendixFig 15. (Right) When used with a VAE (Sec 3.4), our approach captures residual stochasticity at the bottleneck.
Figure 7: Recursive bidirectional prediction on pick-and-place. r = 2 is earlier in time than r = 2.
Figure 8: Bidirectional prediction re-sults on BAIR pushing data. The firsttwo columns are the inputs, and the nexttwo correspond to fix and genmin.
Figure 10: Bottleneck fre-quency vs. score thresholdone object moves (details in Appendix F). As an intuitive example, suppose that the two objects aredisplaced by 10 cm and 15 cm respectively between start and goal frames. Suppose further that ourpredictor predicts the start frame as its output. Then its distance score would be computed to be 10cm. For all values of threshold below 10 cm, this would be counted as a bottleneck discovery failure.
Figure 11:	Training time network schematic. At test time, only the predictor G is used, and Z 〜N(0, I). Lossterms (as used in Eq 10) are in red.
Figure 12:	The predictor produces an appearance flowfield which is used to produce flow-warped input frames,which together with a frame of new pixels are masked and averaged to produce the output frame.
Figure 13: (Same format as Fig 6). Supplementary bidirectional prediction results comparing fixed-timeprediction and our approach on grasping. First two columns are inputs (start and goal). Thereafter, each columncorresponds to the output of a different model per the column title. “match” is the ground truth image closest tothe genmin prediction.
Figure 14: (Same format as Fig 6). Supplementary bidirectional prediction results comparing fixed-timeprediction and our approach on pick-and-place. First two columns are inputs (start and goal). Thereafter, eachcolumn corresponds to the output of a different model per the column title. “match” is the ground truth imageclosest to the genmin prediction.
Figure 15: Supplementary bidirectional prediction results on pushing. Four columns for each method correspondto masked warped start frame, masked warped goal frame, masked new pixels, and final output respectively. SeeAppendix C and Fig 12 for the synthesis scheme with masks and warps.
Figure 16: Supplementary bidirectional prediction examples for pick-and-place with genmin+vae. Sameformat as Fig 9. Each row is a separate example. First column is the input. genmin+vae captures residualstochasticity at the bottleneck. genmin+vae produces images that are most all of the arm in contact with theobject on the table, but at different points on the object, and with different arm/gripper poses.
Figure 17: Supplementary forward prediction examples for grasping, comparing fixed-time predictors and ourapproach. Same format as Fig 5. Each row is a separate example. First column is the input. Thereafter, eachcolumn corresponds to the output of a different model per the column title.
