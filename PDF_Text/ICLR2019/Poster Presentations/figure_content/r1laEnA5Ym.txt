Figure 1: Comparison of the basic gradient method (as well asAdam) with the techniques presented in §3 on the optimizationof (9). Only the algorithms advocated in this paper (Averag-ing, Extrapolation and Extrapolation from the past) convergequickly to the solution. Each marker represents 20 iterations.
Figure 2: Three variants of SGD computing T updates, using the techniques introduced in §3.
Figure 3: Performance of the consideredstochastic optimization algorithms on the bilin-ear problem (29). Each method uses its respec-tive optimal step-size found by grid-search.
Figure 4: Left: Mean and standard deviation of the inception score computed over 5 runs for each methodon WGAN trained on CIFAR10. To keep the graph readable We show only SimAdam but AltAdam performssimilarly. Middle: Samples from a ResNet generator trained with the WGAN-GP objective using AvgExtraAdam.
Figure 5: Comparison of five algorithms (described in Section 3) on the non-convex GAN objective(158), using the optimal step-size for each method. Left: The gradient vector field and the dynamicsof the different methods. Right:The distance to the optimum as a function of the number of iterations.
Figure 6: DCGAN architecture with WGAN-GP trained on CIFAR10: mean and standard deviationof the inception score computed over 5 runs for each method using the best performing learning rateplotted over number of generator updates (Left) and wall-clock time (Right); all experiments wererun on a NVIDIA Quadro GP100 GPU. We see that ExtraAdam converges faster than the Adambaselines.
Figure 7: Inception score on CIFAR10 for WGAN-GP (DCGAN) over number of generator updatesfor different learning rates. We can see that AvgExtraAdam is less sensitive to the choice of learningrate.
Figure 8: Comparison of the samples quality on the WGAN-GP (DCGAN) experiment for differentmethods and learning rate η.
Figure 9: Inception Score on CIFAR10 for WGAN over number of generator updates with andwithout averaging. We can see that averaging improve the inception score.
Figure 10: Inception score on CIFAR10 for WGAN-GP (DCGAN) over number of generator updates36Published as a conference paper at ICLR 2019(a) PastExtraAdam without averaging(b) PastExtraAdam with averaging(c) AltAdam5 without averagingFigure 11: Comparison of the samples of a WGAN trained with the different methods with andwithout averaging. Although averaging improves the inception score, the samples seem more blurry(d) AltAdam5 with averagingFigure 12: The Frechet Inception Distance (FID) from HeUsel et al. (2017) computed using 50,000samples, on the WGAN experiments. ReExtraAdam refers to Alg. 5 introduced in §D. We can seethat averaging performs worse than when comparing with the Inception Score. We observed that thesamples generated by using averaging are a little more blurry and that the FID is more sensitive toblurriness, thus providing an explanation for this observation.
Figure 11: Comparison of the samples of a WGAN trained with the different methods with andwithout averaging. Although averaging improves the inception score, the samples seem more blurry(d) AltAdam5 with averagingFigure 12: The Frechet Inception Distance (FID) from HeUsel et al. (2017) computed using 50,000samples, on the WGAN experiments. ReExtraAdam refers to Alg. 5 introduced in §D. We can seethat averaging performs worse than when comparing with the Inception Score. We observed that thesamples generated by using averaging are a little more blurry and that the FID is more sensitive toblurriness, thus providing an explanation for this observation.
Figure 12: The Frechet Inception Distance (FID) from HeUsel et al. (2017) computed using 50,000samples, on the WGAN experiments. ReExtraAdam refers to Alg. 5 introduced in §D. We can seethat averaging performs worse than when comparing with the Inception Score. We observed that thesamples generated by using averaging are a little more blurry and that the FID is more sensitive toblurriness, thus providing an explanation for this observation.
