Figure 1: Decomposition of the convolutional filter across the 2D space (variable u) and the SO (2) rotationgroup geometry (variable α) simultaneously. The filter is represented as a truncated expansion under the pre-fixed bases ψk (u)ψm(α) with adaptive coefficients ak,m learned from data. ψk are FoUrier-BeSSel bases,夕mare Fourier bases, the first 3 of each are shown. The filter has Nθ group-indexed channels (indexed by α) andonly one inpUt and oUtpUt UnstrUctUred channel (indexed by λ0 and λ respectively) for simplicity. c.f. Table 1.
Figure 2: Representative class activation maps (CAM) on testing images in the rotMNIST transfer learningexperiment. The heatmap indicates the importance of image regions used in recognizing a digit class. The CNNand RotDCF networks are trained on up-right samples, with no retrain (left) and retraining the fully connectedlayers respectively (right) before testing. Testing samples are randomly rotated up to 60 degrees. (c.f. Table 2).
Figure 3: Codes and reconstructions of rotMNIST digits. (Top) A test image is encoded into a 16 × 32 arrayin the red box (the intermediate representation), and the code generates 16 copies by circulating the rows.
Figure 4: Example CAM maps for recognizing faces with in-plane rotations. The heatmap indicates theimportance of different image regions used by respective models in defining a face, and a good CNN modelis expected to select consistent face regions across the same-person images to determine the identity. Acrossdifferent in-plane rotated copies, ROtDCF chooses significantly more consistent discriminative regions thanCNN, indicating more stable representations. In this experiment, we obtain 0.54% recognition accuracy usingCNN (nearly random guess), and 97.04% accuracy using RotDCF with feature alignment, on known subjects.
Figure 6: Example CAM maps for recognizing faces with out-of-plane rotations. Across out-of-plane rotatedcopies, the discriminative regions chosen by RotDCF in describing a subject are more consistent, showing betterrepresentation stability than CNN. In this experiment, We obtain 80.79% recognition accuracy using CNN, and89.66% using ROtDCF, on known subjects.
