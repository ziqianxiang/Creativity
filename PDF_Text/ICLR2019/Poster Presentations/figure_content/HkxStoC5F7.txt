Figure 1: Directed graphical model for multi-task learning.
Figure 2: Computational flow of Versa for few-shot classification with the context-independent approximation.
Figure 3: Computational flow of Versa for few-shot view reconstruction. Left: A set of training images andangles {(yn(t), x(nt))}kn=1 are mapped to a stochastic input ψ(t) through the amortization network qφ . ψ(t) is thenconcatenated With a test angle X and mapped onto a new image through the generator θ. Right: Amortizationnetwork that maps k image/angle examples of a particular object-instance to the corresponding stochastic input.
Figure 4: True posteriors p(ψ∣D) ( ) and approximate posteriors qφ(ψ∣D) ( ) for unseen test sets (?) inthe experiment. In both cases (five and ten shot), the approximate posterior closely resembles the true posteriorgiven the observed data.
Figure 5: Test accuracy on Omniglot when varying (a) way (fixing shot to be that used for training) and (b)shot. In Fig. 5b, all models are evaluated on 5-way classification. Colors indicate models trained with differentway-shot episodic combinations.
Figure 6: Results for ShapeNet view reconstruction for unseen objects from the test set (shown left). The modelwas trained to reconstruct views from a single orientation. Top row: images/views generated by a C-VAE model;middle row images/views generated by VERSA; bottom row: ground truth images. Views are spaced evenly every30 degrees in azimuth.
