Figure 1: Toy examples of a synthetic 2D classification task. For each model (regularization type),we show a prediction heatmap (smaller pane) and the corresponding locally linear regions. Theboundary of each linear region is plotted with line segments, and each circle shows the `2 margin^x,2 around the training point. The gradient is annotated as arrows with length proportional to its '2norm.
Figure 2: Parameter analysis on MNIST dataset. P50 of ^x,2 is the median of ^x,2 in the testing data.
Figure 3: Stability bounds on derivatives on the Japanese Vowel dataset.
Figure 4: Visualization of the examples in Caltech-256 that yield the P50 (above) and P75 (below)of the maximum `1 gradient distortions among the testing data on our ROLL model. The adversarialgradient is found by maximizing the distortion ∆(x, x0, y) over the '∞-norm ball with radius 8/256.
Figure 5: Visualization of the examples in Caltech-256 dataset that yield the P25 (above) and P50(below) of the maximum `1 gradient distortions among the testing data on our ROLL model. Forthe vanilla model, the maximum `1 gradient distortion ∆(x, x0, y) is equal to 893.3 for ‘Projector’in Figure 5g and 1199.4 for ‘Laptop’ in Figure 5q. For the ROLL model, the maximum `1 gradi-ent distortion ∆(x, x0, y) is equal to 779.9 for ‘Projector’ in Figure 5e and 1045.4 for ‘Laptop’ inFigure 5o.
Figure 6: Visualization of the examples in Caltech-256 dataset that yield the P75 (above) and P100(below) of the maximum `1 gradient distortions among the testing data on our ROLL model. Forthe vanilla model, the maximum `1 gradient distortion ∆(x, x0, y) is equal to 1547.1 for ‘Bear’ inFigure 6g and 5473.5 for ‘Rainbow’ in Figure 6q. For the ROLL model, the maximum `1 gradi-ent distortion ∆(x, x0, y) is equal to 1367.9 for ‘Bear’ in Figure 6e and 3882.8 for ‘Rainbow’ inFigure 6o.
