Figure 1: Examples of coordinated multimodal multi-agent behavior.
Figure 2: Macro-intents(boxes) for two players.
Figure 4: Distribution of weak macro-intent labels extracted for each player from the training data.
Figure 3: Depicting VRNN and our model.
Figure 5:	Rollouts from baselines and our model starting from black dots, generated for 40 timestepsafter an initial burn-in period of 10 timesteps (marked by dark shading). An interactive demo of ourhierarchical model is available at: http://basketball-ai.com/.
Figure 6:	Rollouts from our model demonstrating the effectiveness of macro-intents in generatingcoordinated multi-agent trajectories. Blue trajectories are fixed and (•) indicates initial positions.
Figure 7: Synthetic Boids experiments. Showing histograms (horizontal axis: distance; vertical:counts) of average distance to an agent’s closest neighbor in 5000 rollouts. Our hierarchical modelmore closely captures the two distinct modes for friendly (small distances, left peak) vs. unfriendly(large distances, right peak) behavior compared to baselines, which do not learn to distinguish them.
Figure 8: Average distribution of 8-dimensional categorical macro-intent variable. The encoder anddiscriminator distributions match, but completely ignore the uniform prior distribution.
Figure 9: Generated trajectories of green player conditioned on fixed blue players given various 2-dimensional macro-intent variables with a standard Gaussian prior. Left to Right columns: valuesof 1st dimension in {-1, -0.5, 0, 0.5, 1}. Top row: 2nd dimension equal to -0.5. Bottom row:2nd dimension equal to 0.5. We see limited variability as we change the macro-intent variable.
