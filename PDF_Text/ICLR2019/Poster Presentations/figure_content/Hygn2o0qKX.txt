Figure 1: In the above figure, we plot the logarithm (to the base 10) of values of the terms occurring inthe upper bound of 1∕σ* for networks of varying depth, with H = 40. Additionally, We plot variationsof Bpreact, namely 5%-Bpreact and median-Bpreact as discussed in the text. We also plot the equivalentterm from Neyshabur et al. (2018) corresponding to maxχ IlXIID ∏D=ι ∣∣ Wd∣∣2∕γclass. Note that if theslope of the log y vs D graph is c, then the y J (10C)D.
Figure 2: In the left, we vary the depth of the network (fixing H = 40) and plot the logarithm of variousgeneralization bounds ignoring the dependence on the training dataset size and a log(DH ) factorin all of the considered bounds. Specifically, we consider our bound, the hypothetical versions ofour bound involving 5%-Bpreact and median-Bpreact respectively, and the bounds from Neyshabur et al.
Figure 3: In all these plots, we train a network with D = 11, H = 1280. Left: Each blackpoint corresponds to the maximum row `2 norm of the Jacobian 10/d. Observe that for any d,these quantities are nowhere near as large as a naive upper bound that would roughly scale as∏d0=d Il Wd Il 2 = 210-d. Right: Each black point corresponds to a particular training example x, andhas y-value equal to the `2 norm of the output of layer d for that datapoint. A naive upper bound onthis value would be ∣∣x∣∣ ∏d'=ι ∣∣ Wd∣∣2 ≈ 10 ∙ 2d, which would be at least 100 times larger than theobserved value for d = 10.
Figure 4:	In the above figure, we plot the logarithm (to the base 10) of values of the terms in our boundand in existing bounds for H = 1280. Again, we observe that Bjac-r0w-'2, Blayer-'2, BoUtpUt typically liein the range of [100, 102]. In contrast, the equivalent term from Neyshabur et al. (2018) consistingof the prodUct of spectral norms can be as large as 105 for D = 10. UnfortUnately, for large H, dUeto nUmerical precision issUes, the smallest pre-activation valUe is roUnded off to zero and henceBpreact becomes Undefined in sUch sitUations. However, as noted before, the hypothetical variations5%-Bpreact and median-Bpreact are boUnded better and achieve significantly smaller valUes. Finally,observe that oUr overall boUnd and all its hypothetical variations have a smaller slope than previoUsboUnds.
Figure 5:	Log-log plots of various terms for D = 8 and varying H. Note that if the slope of the logyvs log H plot is c, then y 仪 Hc.
Figure 6: Log-log plots of various terms for D = 14 and varying H.
