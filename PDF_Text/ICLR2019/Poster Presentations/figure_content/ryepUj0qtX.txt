Figure 1: (a) 2-d embedding with uniform prior. (b) 2-d embedding with degree prior.
Figure 1: The posterior distribution P (aij = 1|X) and P (aij = 0|X) with different prior probabilityPij and σ22 Deriving the log probability of posterior P (G|X)logP(G∣X) = log I ∏{i,j}∈ENij,σ1 PijNij,σ1 Pij + Nij,σ2 (1 - Pij)• π Nkl,σ2 (I - PkI)Nkl,σι PkI + Nkl,σ2 (I- PkI){k,l}∈/ Elog I ∏ - Nj12 Q-Pj • ∏ 1, N11.1 Pki	I∖{i,j}∈E 1 +	Nj,σ1 Pij	{k,l}∈E 1 + Nkl,σ2 (I-Pkl))— 丁 I f + (2πσ2)T/2 eχp (-dj√(2σ2)) (I - Pij)、1ij∈E	(2πσ2)-1/2 eχp (-dj√(2σ2)) Pij-E log (1 +{k,l}∈E	∖(2πσ2)T/2 exp (-dk∕(2σ2)) PkI)(2πσ2)-1/2 exp (-dk∕(2σ2口(1 - Pkl)=-{i"og(1+σ11jexp
Figure 2: The entity relationship diagram of the studentdb dataset.
