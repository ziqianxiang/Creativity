Figure 1: Attack success rate and distance distribution of MNIST model in Madry et al. (2018). Up-per: C&W '∞ attack success rates, e = 0.3. Lower: The distribution of the average '2 (embeddingspace) distance between the images in test set and the top-5 nearest images in training set.
Figure 2: Attack success rate and distance distribution of Fashion MNIST model trained us-ing Madry et al. (2018). Upper: C&W '∞ attack success rate, e = 0.1. Lower: The distributionof the average `2 (embedding space) distance between the images in test set and the top-5 nearestimages in training set.
Figure 3: Attack success rate and distance distribution of CIFAR model in Madry et al. (2018). Up-per: C&W '∞ attack success rate, e = 8/255. Lower: The distribution of the average '2 (embeddingspace) distance between the images in test set and the top-5 nearest images in training set.
Figure 4: Blind-spot attacks on Fashion-MNIST and MNIST data with scaling and shifting on ad-versarially trained models (Madry et al., 2018). First row contains input images after scaling andshifting and the second row contains the found adversarial examples. “dist” represents the '∞ dis-tortion of adversarial perturbations. The first rows of figures (a) and (d) represent the original testset images (α = 1.0, β = 0.0); first rows of figures (b), (c), (e), and (f) illustrate the images aftertransformation. Adversarial examples for these transformed images have small distortions.
Figure 5: The distribution of the `2 distance between the original and scaled images in test set andthe top-5 nearest images (k = 5) in training set using the distance metric defined in Eq. (2).
Figure 6: Attack success rates and distance distribution of the adversarially trained CIFAR modelby Madry et al. (2018). Upper: C&W '∞ attack success rate, e = 8/255. Lower: distribution ofthe average `2 (embedding space) distance between the images in test set and the top-10 (k = 10)nearest images in training set.
Figure 7: Attack success rates and distance distribution of the adversarially trained CIFAR modelby Madry et al. (2018). Upper: C&W '∞ attack success rate, e = 8/255. Lower: distribution of theaverage `2 (embedding space) distance between the images in test set and the top-100 (k = 100)nearest images in training set.
Figure 8: Attack success rates and distance distribution of the adversarially trained CIFAR modelby Madry et al. (2018). Upper: C&W '∞ attack success rate, e = 8/255. Lower: distribution of theaverage `2 (embedding space) distance between the images in test set and the top-1000 (k = 1000)nearest images in training set.
Figure 9: Attack success rate and distance distribution of GTS in Madry et al. (2018). Upper: C&W'∞ attack success rate, e = 8/255. Lower: distribution of the average '2 (embedding space) distancebetween the images in test set and the top-5 nearest images in training set.
Figure 10: Blind-spot attacks on Fashion-MNIST and MNIST data with scaling and shifting inMadry et al. (2018). First row contains input images after scaling and shifting and the secondrow contains the found adversarial examples. “dist” represents the '∞ distortion of adversarialperturbations. The first rows of figures (a), (d), (g) and (j) represent the original test set images(α = 1.0, β = 0.0); first rows of figures (b), (c), (e), (f), (h), (i), (k) and (l) illustrate the imagesafter transformation. Adversarial examples for these transformed images can be found with smalldistortions.
Figure 11: Attack success rates and distance distribution of the CIFAR-10 model in Wong et al.
Figure 12: Blind-spot attacks on Fashion-MNIST and MNIST datasets with scaling and shifting.
