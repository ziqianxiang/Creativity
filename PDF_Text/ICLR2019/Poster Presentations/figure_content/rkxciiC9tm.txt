Figure 1: (a) Conceptual graph to illustrate the hierarchical stochasticity in NADPEx. Agent spon-taneously explores towards different directions with different dropouts. (b) Graphical model for anMDP with NADPEx. z is a global random variable in one episode τ .
Figure 2: Experiments with NADPEx in standard envs, three pjk are presented for Gaussian dropout,as well as the best of binary dropout. Extensive comparison is given in Appendix F.
Figure 3: Experiments with NADPEx and parameter noise in sparse reward envs.
Figure 4: Comparison between NADPEx and bootstrap with Gaussian dropout.
Figure 5: NADPEX KL PPO in Walker2d. Left: learning curves; right: true DKL(πθold∣z∣∣πθ∣z).
Figure 6: NADPEx in standard envs where Gaussian dropout is used17Published as a conference paper at ICLR 2019Figure 7: NADPEx in standard envs where binary dropout is usedFigure 8: NADPEx in standard envs, camparing the best of Gaussian dropout and binary dropoutG Environments with sparse rewardsWe use the same sparse reward environments from rllab Duan et al. (2016), modified by Houthooftet al. (2016):•	SparseHalfCheetah (S ⊂ R17, A ⊂ R6), which only yields a reward if the agent crosses adistance threshold,•	SparseMountainCar (S ⊂ R2 , A ⊂ R), which only yields a reward if the agent drives upthe hill,•	SparseDoublePendulum (S ⊂ R6, A ⊂ R), which only yields a reward if the agent reachesthe upright position.
Figure 7: NADPEx in standard envs where binary dropout is usedFigure 8: NADPEx in standard envs, camparing the best of Gaussian dropout and binary dropoutG Environments with sparse rewardsWe use the same sparse reward environments from rllab Duan et al. (2016), modified by Houthooftet al. (2016):•	SparseHalfCheetah (S ⊂ R17, A ⊂ R6), which only yields a reward if the agent crosses adistance threshold,•	SparseMountainCar (S ⊂ R2 , A ⊂ R), which only yields a reward if the agent drives upthe hill,•	SparseDoublePendulum (S ⊂ R6, A ⊂ R), which only yields a reward if the agent reachesthe upright position.
Figure 8: NADPEx in standard envs, camparing the best of Gaussian dropout and binary dropoutG Environments with sparse rewardsWe use the same sparse reward environments from rllab Duan et al. (2016), modified by Houthooftet al. (2016):•	SparseHalfCheetah (S ⊂ R17, A ⊂ R6), which only yields a reward if the agent crosses adistance threshold,•	SparseMountainCar (S ⊂ R2 , A ⊂ R), which only yields a reward if the agent drives upthe hill,•	SparseDoublePendulum (S ⊂ R6, A ⊂ R), which only yields a reward if the agent reachesthe upright position.
