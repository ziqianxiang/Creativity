Figure 1: Illustration of the adversarial sampling by FGSM for Xi âˆˆ R2 . The blue dot (in the center)represents a clean example and the red dots (along the boundary) represent the potential adversarialexamples for the clean example.
Figure 2: t-SNE visualizations for the embeddings of training data, testing data, and adversarialtesting data from FGSM and PGD in the logit space for Fashion-MNIST. The first row to the fifthrow correspond to NT, SAT, EAT, PRT and ATDA, respectively.
Figure 3: Ablation experiments for ATDA to investigate the impact of Standard Adversarial Training(SAT), Unsupervised Domain Adaptation (UDA), and Supervised Domain Adaptation (SDA). Wereport the average accuracy rates over all white-box attacks and all black-box attacks, respectively.
