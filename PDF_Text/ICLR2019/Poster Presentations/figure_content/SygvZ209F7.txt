Figure 1: a, Top-1 and b, top-5 validation error on ImageNet for ResNet-18 and AlexNettrained with different learning algorithms. Dashed lines, ResNet-18 reference performance(Johnson et al., 2016). Sign-symmetry performed nearly as well as backpropagation, whilefeedback alignment performed better than previously reported when backpropagation wasused to train the last layer.
Figure 2: Training loss of RetinaNet on COCO dataset trained with 3 different settings: 1)backpropagation for all layers; 2) backpropagation for the last layer in both regression andclassification subnets, and sign-symmetry for other layers; 3) backpropagation for the lastlayer in both subnets and feedback alignment for other layers. a, Object detection boundingbox regression loss. b, Focal classification loss. c, Total loss.
Figure 3: a, During training with sign-symmetry, alignment angles between feedforwardweights W and feedback weights sign(W) decreased in the last 3 layers but increased inearly layers, whereas during training with backpropagation, the analogous alignment anglesincreased for all layers and were overall larger. b, Kurtosis of the feedforward weight matri-ces increased during training. c, The magnitudes of weights trained by sign-symmetry weresimilar to those trained by backpropagation. Line and shading, mean Â± std for epoch 50.
Figure 4: The specific wiring required for sign-symmetric feedback can be achieved usingaxonal guidance by specific receptor-ligand recognition. Assume that an axon carrying ligandLX will only synapse onto a downstream neuron carrying the corresponding receptor RX .
