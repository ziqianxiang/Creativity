Figure 2: Instead of directly mapping from current state s to next state s0 , our prediction modeluses deictic references to find subsets of objects for prediction. In the left most graph, we illustratewhat relations are used to construct the input objects with two rules for the same action template,T1 = (A,Γ(1),∆(1),φ(θ1),vd(e1f)ault) and T2 = (A,Γ(2),∆(2),φ(θ2),vd(2ef)ault), where the reference listΓ(1) = [(γ1(1) , o2)] applied a deictic reference γ1(1) to the target object o2 and added input featurescomputed by an aggregator g on o3, o6 to the inputs of the predictor of rule T1. Similarly forΓ(2) = [(γ1(2) , o2), (γ2(2) , o3)], the first deictic reference selected o3 and then γ2(2) is applied on o3to get o1 . The predictors φ(θ1) and φ(θ2) are neural networks that map the fixed-length input to afixed-length output, which is applied to a set of objects computed from a relational graph on all theobjects, derived from the reference list ∆(1) = [(δ1(1) , o2)] and ∆(2) = [(δ1(2) , o2)], to compute thewhole next state s0. Because δ1(2) (o2) = (o4, o6) and the φ(θ2) is only predicting a single property,we use a “de-aggregator” function h to assign its prediction to both objects o4 , o6 .
Figure 1: A robot gripper is pushing astack of 4 blocks on a table.
Figure 3: Representative problem instances sampled from the domain.
Figure 4: (a) In a simple 3-block pushing problem instance, data likelihood and learned defaultstandard deviation both improve as more deictic references are added. (b) Comparing performanceas a function of number of distractors with a fixed amount of training data. (c) Comparing sampleefficiency of SPARE to the baselines. Shaded regions represent 95% confidence interval.
Figure 5: (a) Shell weights per iteration of our EM-like algo-rithm. (b) Membership probabilities of training samples per iter-ation.
Figure 6: Effect of object ordering on baseline performance, on task of pushing a stack of threeblocks on a table top, where there are extra blocks on the table that do not interfere with the push.
