Figure 1: Attacks on Model 2 found after 1K and 10K iterations: the same 0 recognized as 5.
Figure 2: Accuracy percentages of classifiers on test data bin-sorted by the confidence gap.
Figure 3: Original and distorted images of MNIST digits in test set with the largest confidence gaps.
Figure 4: Original and distorted images of MNIST digits in test set with the smallest confidencegaps. Mstk denotes the misclassified output label. Dist denotes the L2 -norm of the distortion noise.
Figure 5: Original image of 0; attack on Model 2 (Madry et al., 2017) found after 1K iterations;attack on Model 2 found after 10K iterations; attack on Model 3 (L2NNN) found after 1M iterations.
