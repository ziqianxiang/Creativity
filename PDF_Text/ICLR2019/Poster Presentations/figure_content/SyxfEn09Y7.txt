Figure 1: This is a simple ReLU network withone hidden node. Suppose path values arevp1 (w) = w1w3, vp2 (w) = w1w4, vp3 (w) =w2w3 , vp4 (w) = w2w4, we can see the inner-dependency between them, i.e., vp4 (w) =v一2 (w)∙V-3 (w)p V I(W)——.A is the structure matrix of thisexample.
Figure 2: The weights4.1 S keleton Method	with red color are skele-ton weights.
Figure 3: Training loss and test accuracy w.r.t. the number of effective passes on PlainNet andResNet.
Figure 4: Training loss and test error on MLPs. The invariant ratio decreases as H increases.
Figure 5: Performance of MLP models with Path-SGD and G-SGD.
Figure 6: Training throughput on GPU server With 4 NVIDIA GTX Titan Xp GPUs and PCI sWitch.
Figure 7: Training loss and test accuracy on 110-layer ResNet network w.r.t. the number of effectivepasses on CIFAR-10 and CIFAR-100 dataset.
Figure 8: Training loss and test accuracy w.r.t. the number of effective passes on CIFAR-10 dataset.
Figure 9: Training loss and test accuracy w.r.t. the number of effective passes on CIFAR-100 dataset.
