Figure 2: We show here one of the D2 spaces of 20D word embeddings embedded in (D2)10 with ourunsupervised hyperbolic Glove algorithm. This illustrates the three steps of applying the isometry.
Figure 3: Different hierarchies captured by a 10x2D model with h(x) = x2, in some selected 2Dhalf-planes. The y coordinate encodes the magnitude of the variance of the corresponding Gaussianembeddings, representing word generality/specificity. Thus, this type of Nx2D models offer anamount of interpretability.
Figure 4: (4a): This plot describes how the Gaussian variances of our learned hyperbolic embeddings(trained unsupervised on co-occurrence statistics, isometry found with “Unsupervised 1k+1k”)correlate with WordNet levels; (4b): This plot shows how the performance of our embeddings onhypernymy (HyperLex dataset) evolve when we increase the amount of supervision x used to find thecorrect isometry in the model WN x + x. As can be seen, a very small amount of supervision (e.g. 20words from WordNet) can significantly boost performance compared to fully unsupervised methods.
Figure 5: The first five 2D spaces of the model trained with h = (∙)2.
Figure 6: The last five 2D spaces of the model trained with h = (∙)2.
Figure 7: The first five 2D spaces of the model trained with h = cosh2 .
Figure 8: The last five 2D spaces of the model trained with h = cosh2 .
