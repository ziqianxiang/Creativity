Figure 1: Our proposed model-based method, (a) an input convex neural network is first trained tolearn the system dynamics, then (b) we solve a convex predictive control problem to find the optimalactions which are input convex neural networks’ inputs. The optimization steps are also based onobjectives and dynamics constraints represented by the trained networks.
Figure 2: Input convex neural network. Input convex neural network. (a) Input convex feed-forwardneural networks (ICNN). One notable addition is the direct “passthrough” layers D2:k that connect theinputs to hidden units for better model representation ability. (b) The proposed input convex recurrentneural networks (ICRNN) architectures. In our control settings, we keep all weights in both networksnonnegative, while expanding the inputs with -u.
Figure 3: Average rollout reward for random-shooting method vs ICNN on four MuJoCo tasks. Thehorizontal axis indicates the aggregated iteration, and vertical axis indicates average reward. Plottedcurves are averaged over 3 random seeds, and the shaded region shows the standard deviation.
Figure 4: Results for constrained optimization of building energy management. (a) ICRNN is able tomodel the building dynamics as accurately as conventional RNN; (b) Compared to conventional RNNmodel, ICRNN finds control actions which lead to 11.52% more of energy savings, and (c) ICRNNprovides stable control actions while decisions generated by conventional RNN vary dramatically.
Figure 5: Toy example on classifying circle data with label 0 (blue cross) and label 1 (red cross)along with conventional neural networks (left) and ICNN (right) decision contour lines. A decisionmaker is interested in finding a u that has the highest probability of being labeled 0.
Figure 6: A simple two-layer neural networks. In alignment with (10), W1 denotes the first-layerweights a1 - a2 and bias b1 - b2, and W2 denotes the linear second layer. Direct layer is denoted asD2 for weights a2 and bias b2.
Figure 7: Multistep prediction errors by ICNN and MLP. X-Axis and Y-Axis are of log scale.
Figure 8: Cumulative reward for one validation rollout of random shooting method vs ICNNin (Nagabandi et al., 2018), our control method could provide good initialization samples for themodel-free algorithms, which could greatly accelerate the training process of model-free algorithms.
Figure 9: Average return for control of Mujoco tasks by ICNN, random-shooting method (Nagabandiet al., 2018) and TRPO (Schulman et al., 2015).
Figure 10: (a) 24 hour price signal along with (b) optimization results on one-week electricity usageof building using ICRNN.
Figure 11: Results on one-week electricity usage of building using input convex neural networkcontrol method based upon different control constrains.
