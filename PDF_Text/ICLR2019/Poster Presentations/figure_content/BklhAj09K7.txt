Figure 1: Training of Feature Transfer Network (FTN) for verification, composed of feature generation module(Gen; f), feature transfer module (Tx; g), and two domain discriminators D1 and D2 . Verification objectiveLvrf’s are applied to source (fs) pairs and transformed source (g(fs))) pairs. Our FTN applies domain adversarialobjective Ladv for domain alignment between transformed source and target domains by D1 and applies Lsep todistinguish source domain from both target and transformed source domains by D2.
Figure 2: t-SNE visualizations of source (0-4 from MNIST-M) and target (5-9 from MNIST) representations bydifferent learning methods: (a) deep neural network without adaptation, (b) domain adversarial neural network(DANN) and (c) our feature transfer network (FTN). While domain adversarial learning results in significantconfusion of digits classes between source and target domains (e.g., 3/5, 2/8, 4/9, or 0/6 in (b)), the proposedFTN transfers discriminative power to target domain while successfully separating them from the source domain.
Figure S1: Network architecture of feature transfer module and domain discriminators.
Figure S2:	Performance curves of identification accuracy per ethnicity subset on the CEF datasets. The accuracyof DANNs with different values of λ3 for λ4 are visualized.
Figure S3:	Face images of Caucasian, African-American, and East-Asian sampled from MS-1M dataset.
