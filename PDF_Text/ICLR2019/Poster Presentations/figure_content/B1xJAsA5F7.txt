Figure 1: Illustration of our encoder-decoder model. Molecules are represented by their graph struc-tures and junction trees encoding the scaffold of molecules. Nodes in the junction tree (which wecall clusters) are valid chemical substructures such as rings and bonds. During decoding, the modelfirst generates its junction tree and then combines clusters in the predicted tree into a molecule.
Figure 2: Multiple ways to assembleneighboring clusters in the junction tree.
Figure 3: Multimodal graph-to-graph learning. Our model combines the strength of both variationalJTNN and adversarial scaffold regularization.
Figure 4: Examples of diverse translations learned by VJTNN+GAN on QED and DRD2 dataset.
