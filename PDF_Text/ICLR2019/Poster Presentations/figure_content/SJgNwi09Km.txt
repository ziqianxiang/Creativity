Figure 1: Latent Tree Variational AutoencoderP(K)P①明）Clique TreeP(ZlIyl)	P(Z2∣%) P(Z3∣%) P(ZjH)	P(Zl = Zι∣%) P(Zl = Zl∣%)P(Z3 = Z3∣yr)P(Z4 = Z4∣y2)Figure 2: Inference and gradient through mes-sage passing. Solid-arrows denote collectingmessage, and dashed-arrows denote distributingmessage.
Figure 2: Inference and gradient through mes-sage passing. Solid-arrows denote collectingmessage, and dashed-arrows denote distributingmessage.
Figure 3: Structure search operators. The digits above the nodes denote the number of discretestates. Node deletion, state deletion and unpouching are the inverse of node insertion, state insertionand pouching, respectively.
Figure 4: (a) The generative process of synthetic data; (b) The discovered multidimensional super-structure and the latent space (different colors denote different ground truth clusters in each facet.)Table 1: Test data loglikelihood for various datasets.
Figure 5: Two facet clustering results from LTVAE are in (a) digit identity and (b) shape and pose.
Figure 6: Clustering results from LTVAE for STL-10dataset. Each row contains the top 5 scoring elements fromone cluster.
Figure 7: The digits generated bythe proposed model. Digits in thesame row come from the same la-tent code of the latent tree.
Figure 8: Conditional probability of Y1 and Y2 for the two facets of MNIST discovered by LTVAE.
Figure 9: Image generation. Left are the original image. Right are generated with the proposedmodel by fixing the variables in identity facet and sampling the variables in the pose facet. Digits inthe same row come from the same latent code of the latent tree.
