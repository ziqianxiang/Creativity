Figure 1: Illustration of the RNA Design problem using a folding algorithm F and the dot-bracketnotation. Given the desired RNA secondary structure represented in the dot-bracket notation (a), thetask is to design an RNA sequence (b) that folds into the desired secondary structure (c).
Figure 2: Illustration of an action rollout in the proposed decision process. The agent sequentiallybuilds a candidate solution by choosing actions to place nucleotides. At paired sites, as indicated bya pair of brackets, two nucleotides are placed simultaneously (t = 0 and t = 1); while at unpairedsites a single nucleotide is placed (t = 2).
Figure 3: Performance across the time spent on each particular target structure for all methods onthe Eterna100 benchmark (top), the Rfam-Taneda benchmark (middle), and the Rfam-Learn-Testbenchmark (bottom). On the left we show the total number of target structures that were solved in atleast one evaluation run, while the right panels show the average number of solved target structuresand the standard deviation around the mean.
Figure 4: Left: Observed validation loss during the BOHB run for LEARNA. The different budgetsb correspond to the timeout for each of the 100 validation sequences. Right: Relationship betweenthe observed validation loss (sum of minimal, normalized Hamming distances) and the fraction ofsolved sequences.
Figure 5: Left: Observed validation loss during the BOHB run for Meta-LEARNA. The differentbudgets b corresponds to the training time on 20 CPU cores before evaluating on the 100 validationsequences for 60 seconds each. The results seem to suggest that one can achieve a very similarperformance with only 20 minutes of training, which could imply that much longer training ofthe agent might be required for substantially better performance. Right: Relationship between theobserved validation loss (sum of minimal, normalized Hamming distances) and the fraction of solvedsequences during validation. The plot suggests that our loss metric correlates strongly with thenumber of successfully found primary sequences.
Figure 6: Marginal prediction plots for the most important individual parameters, with all otherparameters marginalized out based on a random forest regression model. We plot means of themarginal prediction across the random forest’s individual trees ± the empirical standard deviationacross the trees. The importance numbers given in the figure subtitles measure the fraction of thetotal variance explained by the respective single parameter.
Figure 7: Marginal prediction plots for the most important pairs of parameters when marginalizingacross all other parameters. The importance values shown in the subtitles are the ones by theinteraction effect itself (first) and the sum of it and the two individual effects (second).
Figure 8: Ablation study of Meta-LEARNA-Adapt (first row), Meta-LEARNA (second row) andLEARNA (third row) on Rfam-Learn-Test. The left side shows the accumulated number of solvedtarget structures over 5 independent runs, while the right side shows the mean and the standarddeviation around the mean.
Figure 9: Ablation study of LEARNA on Eterna100 with an evaluation timeout of 12 hours. The leftside shows the accumulated number of solved target structures over 5 independent runs, while theright side shows the mean and the standard deviation around the mean.
Figure 10: Minimum solution times across sequence lengths on the Rfam-Learn-Test benchmark.
