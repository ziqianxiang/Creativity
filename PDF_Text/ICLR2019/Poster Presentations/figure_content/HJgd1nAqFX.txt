Figure 1: Given the web page on the right, its DOM tree representation is shown as a graph whereeach DOM represents a node from V . Different colors indicate different tag attributes of DOMs.
Figure 2: A successful trajectory executed by our model for search-engine. Si is the state, and Ai =(adom , atoken , amode ) is a tuple of actions for the three distinct categories of actions at timestep i.
Figure 3: Performance comparisons of DOM-Q-NET with Shi et al. (2017); Liu et al. (2018)number of timestepsNavigate-Treenumber of timestepsS ① po--d ① OoTtt,°- ¾ σ><ClickCheckboxes10000 20000 30000 40000 50000number of timesteosIOOO 2000	3000	4000	5000number of timestepsLogin-UserFigure 4: Multitask Comparisons: 9-multitask DOM-Q-NET with goal-attention consistently hasbetter sample efficiency. Results for other tasks are shown in Appendix 6.7.1. g_a=goal-attention.
Figure 4: Multitask Comparisons: 9-multitask DOM-Q-NET with goal-attention consistently hasbetter sample efficiency. Results for other tasks are shown in Appendix 6.7.1. g_a=goal-attention.
Figure 5: Comparisons in sample efficiency for 2 hard tasks, social-media (left) and search-engine(right), by multitask learning. 9.multitask refers to the tasks discussed in Figure 4Figure 6: Ablation experiments for l=Local, n=Neighbor, g=Global modules. dom_q_net - g is theDOM-Q-NET without the global module. dom_q_net -l-gis the DOM-Q-NET with only neighbormodule. dom_q_net-n-g is the DOM-Q-NET with only local module.
Figure 6: Ablation experiments for l=Local, n=Neighbor, g=Global modules. dom_q_net - g is theDOM-Q-NET without the global module. dom_q_net -l-gis the DOM-Q-NET with only neighbormodule. dom_q_net-n-g is the DOM-Q-NET with only local module.
Figure 7: Effects of goal-attention for single and multi-task learning (g_a=goal attention)Login-Usernumber Oftimesteos5	DiscussionWe propose a new architecture for parameterizing factorized Q functions using goal-attention, localword embeddings, and a graph neural network. We contribute to the formulation of web navigationwith this model. Without any demonstration, it solves relatively hard tasks with large action space,and transfers learned behaviours from multitask learning, which are two important factors for webnavigation. For future work, we investigate exploration strategies for tasks like email-inbox wherethe environment does not have a simple instance of the task that the agent can use to generalizelearned behaviours. Liu et al. (2018) demonstrated an interesting way to guide the exploration.
Figure 8: goal-attention6.3	Goal EncoderThree types of goal encoding module for global module are investigated.
Figure 9: goal-encoderBenchmark results for multitask and 23 tasks in Appendix 6.7 also compare the performances ofusing different goal encoding modules.
