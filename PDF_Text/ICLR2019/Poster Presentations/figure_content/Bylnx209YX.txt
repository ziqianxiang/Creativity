Figure 1: Change in accuracy of GCN on Cora-ML for increasing number of perturbations.
Figure 2: Comparison with logisticregression baseline on CITESEER.
Figure 3: Analysis of adversarially inserted edgesAnalysis of attacks. An interesting question to ask is why the adversarial changes created by ourmeta-gradient approach are so destructive, and what patterns they follow. If we can find out whatmakes an edge insertion or deletion a strong adversarial change, we can circumvent expensive meta-gradient computations or even use this knowledge to detect adversarial attacks.
Figure 4: Change in accuracy of GCN on Citeseer with and without enforcing unnoticeabilityconstraints (singleton nodes are never admissible). Meta-Self-U corresponds to not enforcing theunnoticeability constraint.
Figure 5: Change in accuracy of CLN onCORA-ML.
Figure 6: Change in accuracy of Deepwalkon CORA-ML.
Figure 7:	Change in accuracy of CLN onCiteseer.
Figure 8:	Change in accuracy of GCN onCiteseer.
Figure 9: Change in accuracy of Deepwalkon Citeseer.
Figure 10: Change in accuracy of CLN onPolBlogs.
Figure 11: Change in accuracy of GCN on Figure 12: Change in accuracy of DeepwalkPolBlogs.	on PolBlogs.
