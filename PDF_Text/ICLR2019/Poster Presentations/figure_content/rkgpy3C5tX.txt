Figure 1: Graphical models for meta-learning framework. Dotted lines denote variational approxima-tions. (a) Original setup in Amit & Meir (2018) where inference parameters are learned separatelyfor each episode (b) Proposed initial amortized variational inference scheme (c) Proposed amortizedvariational inference scheme with support & query splits.
Figure 2:	Visualization of armrewards according to prior dis-tribution of our model. (a) ex-pectation and standard-deviationof low-reward arm (computed bysampling weights from the prior)evaluated on points on unit cir-cle. (b) expectation and standard-deviation of one of the high-reward arms computed in sameway as for low-reward arm.
Figure 3:	Reliability diagrams for MAML and our model on various tasks across datasets. Relibialitydiagrams are computed by gathering predicted probabilities for query set examples across manyepisodes, where the same set of evaluation episodes are used for both models. (a) MAML (b)Probabilistic MAML (c) Our model.
Figure 4: Comparison of empiriCal CDF of entropy of prediCtive distributions on out-of-episodeexamples on various tasks and datasets. Data for CDF Comes from Computing the entropy on out-of-episode examples aCross many episodes, where out-of-episode examples are generated by randomlysampling Classes not belonging to the episode and randomly sampling examples from those Classes.
Figure 5: Standard deviation of prior for Convolutional kernels aCross layers of network. The x-axisindexes different filters in eaCh layer whereas the y-axis indexes aCross positions in the 3 Ã— 3 kernel.
