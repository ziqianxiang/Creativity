Figure 1: Three liquid surfaces after 60time steps differing only by ±e in ini-tial conditions. Even this initially verysmall difference can lead to large differ-ences in surface position, e.g., the sheetin b) strongly curving downward.
Figure 2: This illustration gives an overview of our algorithm. It works in two stages, a weightingand refinement stage, each of which employs a neural network to infer a weighting function and adense deformation field, respectively.
Figure 3: An example of our parameter learning approach. F.l.t.r.: the initial undeformed surface, thesurface deformed by the weighting from the trained parameter network, and the reference surfaceonly. The reference surface is shown again in the middle in light brown for comparison. Theweighted deformations especially match the left liquid arm well, while there are not enough degreesof freedom in the pre-computed deformations to independently raise the surface on the right side.
Figure 5: An example of our deformation learning approach. F. l. t. r.: the result after applyingweighted deformations, and with an additional deformation from a trained deformation network.
Figure 4: Ablation study for our method. We evaluated the average loss for a test data set of thedifferent data sets discussed in the text. Left: numeric values, again as a graph (center), and a graphof the loss values normalized w.r.t. initial surface loss on the right. Our method achieves verysignificant and consistent reductions across the very different data sets.
Figure 6: Eight examples of the learned deformations for a flat initial surface. For each pair thereference surfaces are depicted in yellow and the deformed results in blue. The trained model learnsto recover a significant portion of the large-scale surface motion over the whole parameters space.
Figure 7: Each pair shows the reference surface in transparent brown, and in purple on the left thedeformed surface after applying the precomputed deformations. These surfaces often significantlydeviate from the brown target, i.e. the visible purple regions indicates misalignments. In cyan onthe right, our final surfaces based on the inferred deformation field. These deformed surface matchthe target surface closely, and even recover thin features such as the central peak in (c).
Figure 8: a) Liquid drop data set example: several 3D surfaces of a single simulation data point inφa. b) An example splash generated by our method, visualized interactively.
Figure 9: a) Three example configurations from our stairs data set. b) The interactive version of thestair setup shown in the demo app. Notice how the flow around the central wall obstacle changes.
Figure 10:	Illustration of our deformation alignment procedure.
Figure 11:	This figure illustrates the forward advection process: Both deformation vsum and thecorrection vinv are initially located at x0 in (a). vinv is applied to yield the correct deformation atlocation x, as shown in (b).
Figure 12:	Overview of our two neural networks. While the parameter network (left) is simple,consisting of two fully connected layers, its cost functions allows it to learn how to apply multiplelong-range, non-linear deformation fields. The deformation network (right), which makes use ofseveral de-convolutional layers, instead learns to generate dense deformation fields to refine thefinal surface.
Figure 13:	The left image illustrates the initial conditions of our two dimensional parameter spacesetup. It consists of a set of two-dimensional liquid simulations, which vary the position of the liquiddrop along x as αι, and its size as α2. The right half shows the data used for training at t = 30.
Figure 14: Loss during training both for parameter learning and deformation learning. In yellow weshow the loss for the current sample, while the dark line displays the loss evaluated on the validationset.
Figure 15: Training with different gradient approximations: validation loss with a simplified advec-tion (red), and the correct gradient from forward advection (green). The simplified version does notconverge.
Figure 16: Different example surfaces from the 2D parameter space of Fig. 13. From left to right:surfaces reconstructed with PCA (purple), weighted deformations using a trained parameter network(pink), the reference surfaces (brown), and on the far right the output of our full method with adeformation network (teal). Note that none of the other methods is able to reconstruct both arms ofliquid in the first row, as well as the left sheet in the bottom row. The reference surfaces are shownin light brown in the background for each version.
Figure 17: Additional examples of the influence of the deformation network for three different timesteps (t = 1, 4, 8 from top to bottom). Each pair shows the reference surface in transparent brown,and in purple on the left the deformed surface after applying the precomputed deformations. Thesesurfaces often significantly deviate from the brown target, i.e. the visible purple regions indicatesmisalignments. In cyan on the right, our final surfaces based on the inferred deformation field. Thesedeformed surface often match the target surface much more closely.
Figure 18: Two frames generated with our approach (left) and with a direct SDF interpolation usinga similar amount of overall memory (right). The latter looses the inital drop shape (a), and removesall splash detail (b). In addition, the direct SDF interpolation leads to strong ghosting artifacts withfour repeated patterns.
Figure 19: The geometric setup of the three deformations of our stairs setup from 20 are illustratedin this figure.
Figure 20: These screens illustrate our stairs setup running in our mobile application. From left toright, the middle divider is pulled back, leading to an increased flow over the step in the back. In theright-most image, the left corner starts to move up, leading to a new stream of liquid pouring downinto the outflow region in the right corner of the simulation domain.
