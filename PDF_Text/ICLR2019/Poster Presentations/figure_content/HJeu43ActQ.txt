Figure 1: A neural implementation ofNOODL. Panel (a) shows the neural architec-ture, which consists of three layers: an in-put layer, a weighted residual evaluation layer(evaluates ηx (y(j)— A(t)x(r))), and an out-put layer. Panel (b) shows the operation of theneural architecture in panel (a). The update ofx((jr)+1) is given by (4).
Figure 2: Comparative analysis of convergence properties. Panels (a-i), (b-i), (c-i), and (d-i) show the conver-gence of NOODL, Arora15(‘‘biased’’), Arora15(‘‘unbiased’’) and Mairal ‘09, for differ-ent sparsity levels for n = 1000, m = 1500 and p = 5000. Since NOODL also recovers the coefficients, weshow the corresponding recovery of the dictionary, coefficients, and overall fit in panels (a-ii), (b-ii), (c-ii), and(d-ii), respectively. Further, panels (e-i) and (e-ii) show the phase transition in samples p (per iteration) withthe size of the dictionary m averaged across 10 Monte Carlo simulations for the two factors. Here, n = 100,k =	3,	ηx	= 0.2,	τ = 0.1,	0 =	2/ log(n),	ηA	is chosen as per A.5.	A trial is considered successful if the7relative Frobenius error incurred by A and X is below 5 × 10-7 after 50 iterations.
