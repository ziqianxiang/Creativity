Figure 1: (a) Bias amplification on real datasets classified using Gaussian Naive Bayes; (b) biasamplification of Bayes-optimal classifier in terms of the Mahalanobis distance D between classmeans and prior class probability p*.
Figure 2: (a), (b): Expected bias as a function of (a) number of weak features and (b) variance ofthe weak features, shown for models trained on N = 100, 500, 1000 instances. σw in (a) is fixed at10, and in (b) the number of features is fixed at 256. (c): Extent of overestimation of weak-featurecoefficients in logistic classifiers trained with stochastic gradient descent, in terms of the amount oftraining data. The vertical axis is the difference in magnitude between the trained coefficient (hS)and that of the Bayes-optimal predictor (h*). In (a)-(c), data is generated according to Equation 4with σs = 1, and results are averaged over 100 training runs.
Figure 3: Bias from linear classifiers on data generated according to Equation 4 with σs = 1(i.e., generated in the same manner as the experiments in Figure 2), averaged over 100 trainingruns. The SVM trained using SMO used penalty C = 1.0 and the linear kernel. Regardless of theloss used, the bias of classifiers trained using SGD is uniform and consistent, increasing with featureasymmetry. Comparable classifiers trained using other methods are not consistent in this way. WhileLR trained with L-BFGS does exhibit bias, it is not as strong, and does not appear in as many dataconfigurations, as LR trained with SGD. While linear SVM with penalty trained with SMO resultsin little bias, SVM trained with SGD shows the same bias as LR. Not shown are results for classifierstrained with SGD using modified Huber, squared hinge, and perceptron losses, all of which closelymatch the two curves shown here for SGD classifiers.
