Figure 1: (a) Distribution ofWh used in the LSTM layer on the Penn Treebank corpus. (b) Distributionof the prediction accuracy on the Penn Treebank corpus when using stochastic ternarization over10000 samples.
Figure 2: (a) The learning curve on the validation set of the Penn Treebank corpus. (b) Performanceon the test set of the Penn Treebank corpus over longer sequences.
Figure 3: Effect of different batch sizes on the prediction accuracy of the character-level languagemodeling task on the Penn Treebank corpus.
Figure 4:	Probability density of states/gates for the BinaryConnect LSTM compared to its full-precision counterpart on the Penn Treebank character-level modeling task. Both models were trainedfor 50 epochs. The vertical axis denotes the time steps.
Figure 5:	Probability density of ip for (a) the BinaryConnect LSTM compared to (b) its full-precisioncounterpart for a single time step at different training iterations on the Penn Treebank character-levelmodeling task. The vertical axis denotes the training iterations.
Figure 6: Probability density of states/gates for our binarized LSTM on the Penn Treebank character-level modeling task. The model was trained for 50 epochs. The vertical axis denotes the timesteps.
Figure 7: Latency of the proposed accelerator over full-precision, binary and ternary models.
