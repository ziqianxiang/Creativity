Figure 1: Machine instruction embedding.
Figure 2: Maximal divergence sequential auto-encoder. The latent codes of vulnerable and non-vulnerable are encouraged to be maximally divergent, while still maintaining crucial informationfrom the original binaries. Note that we use the same network for qφ (Z | X, y = 0) andqφ (Z | X, y = 1) and they are discriminated by the source of data used to fit.
Figure 3: The L2 WS distance between two priors (first row, left-hand side), ii) the Euclideandistance of two means of priors (i.e., ∣∣μ0 — μ1∣) (first row, middle), the KL divergence betweenqφ (z | hL,y = 0) and p0 (z) (i.e., DKL qφ (z | hL,y = 0) ∣p0 (z) ) (first row, right-hand side),the KL divergence of qφ (Z | hL ,y = 1) and p1 (Z) (i.e., DKL (qφ (Z | hL ,y = 1) ∣∣p1 (z))) (secondrow, left-hand side), the MMD distance of qφ (z | hL , y = 0) and qφ (z | hL , y = 1) (second row,middle), and the reconstruction loss (second row, right-hand side) across epochs.
Figure 4: The 2D latent codes in the latent space before (left) and after (right) training. The greenpoints are the means of two distributions qφ (z | hL, y = 0) and qφ (z | hL, y = 1).
Figure 5: Detailed steps of the process of compiling VulDeePecker dataset into binaries.
Figure 6: The activity diagram for detecting and fixing functions with syntax errors.
Figure 7: Example of an uncompilable function.
Figure 8: Example of a source code file from VulDeePecker dataset together with its highlightedbuffer error vulnerability.
Figure 9: The vulnerability highlighted assembly code of the corresponding function’s source codein Figure 8.
