Figure 1: (a) Estimate of I for all SAT properties of COLLISIONDETECTION problem. Error barsindicating ± three standard errors from 30 runs are included here and throughout, but the varianceof the estimates was so small that these are barely visible. We can further conclude low bias of ourmethod for the properties where naive MC estimation was feasible, due to the fact that naive MCproduces unbiased (but potentially high variance) estimates. (b) Mean AMLS estimate relative tonaive MC estimate for different ρ holding M = 1000 fixed, for those properties with log10 I > -6.5such that they could be estimated accurately. The bias decreases both as ρ and the rareness of theevent decrease. (c) As per (b) but with varying M and holding ρ = 0.1 fixed.
Figure 2: [Left] Estimates for I on adversarial properties of a single datapoint with ρ = 0.1, andN ∈ {10000, 10000, 300} for MNIST/CIFAR-10/CIFAR-100 respectively. As in Figure 1, the errorbars from 30 runs are barely visible, highlighting a very low variance in the estimates, while theclose matching to the naive MC estimates when is large enough to make the latter viable, indicate avery low bias. For cifar–100 the error bars are shown for the naive estimates, as well, from 10 runs.
Figure 3: (a) Variation in I during the robustness training of on a CNN model for MNIST for threedifferent perturbation sizes . Epoch 0 corresponds to the network after conventional training, withfurther epochs corresponding to iterations of robustness training. The solid line indicates the medianover 50 datapoints, and the limits of the shaded regions the 25 and 75 percentiles. Our measure iscapped at Pmin = exp(-250). We see that while training improves robustness for = 0.2, the initialnetwork is already predominantly robust to perturbations of size = 0.1, while the robustness toperturbations of size = 0.3 actually starts to decrease after around 20 epochs. (b) Comparing thefraction of 50 datapoints for which Wong & Kolter (2018) produces a certificate-of-robustness for= 0.1 (“W&K”), versus the fraction of those samples for which I = Pmin for ∈ {0.1, 0.2, 0.3}(“AMLS”). Due to very heavy memory requirements, it was computationally infeasible to calculatecertificates-of-robustness for = {0.2, 0.3}, and = 0.1 before epoch 32 with the method of Wong& Kolter (2018). Our metric, however, suffers no such memory issues.
Figure 5: Convergence of individual datapoints used in forming Figure 3.
