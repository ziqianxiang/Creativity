Figure 1: The framework of DHER. DHER is a kind of experience replay method. It searchesrelevant failed experiences and then assembles them into successful experiences.
Figure 2:	The proposed tasks with dynamic goals (red objects). Arrow indicates the movement of agoal. The first row indicates initial states. The second row indicates final states.
Figure 3:	Results on different environments.
Figure 4: Low velocity: 0.001.
Figure 5: High velocity: 0.016.
Figure 6: Snake with dynamic goals.
Figure 7: Special: HER+ knows how goals move.
Figure 8: Adapting the policies trained based on DHER from our simulation to a real robotic arm.
Figure 9: Our simulation and the physics environment.
