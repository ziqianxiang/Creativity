Figure 1: Left: Depiction of generative model p(z)pθ(x|z) and inference network q°(z∣x) in VAEs. Right:A toy posterior mean space (μx,θ ,μx,φ) With scalar z. The horizontal axis represents the mean of the modelposterior pθ(z|x), and the vertical axis represents the mean of the approximate posterior qφ(z∣x). The dasheddiagonal line represents when the approximate posterior matches the true model posterior in terms of mean.
Figure 2: The projections of 500 data samples from a synthetic dataset on the posterior mean space over thecourse of training. “iter” denotes the number of updates of generators. The top row is from the basic VAEtraining, the bottom row is from our aggressive inference network training. The results show that while theapproximate posterior is lagging far behind the true model posterior in basic VAE training, our aggressivetraining approach successfully moves the points onto the diagonal line and away from inference collapse.
Figure 3: Trajectory of one data instanceon the posterior mean space with our ag-gressive training procedure. Horizontalarrow denotes one step of generator up-date, and vertical arrow denotes the in-ner loop of inference network update.
Figure 4: NLL versus AU (active units) for all models on three datasets. For each model we display 5 pointswhiCh rePresent 5 runs with different random seeds. “Autoregressive” denotes LSTM-LM for text data andPixelCNN for image data. We Plot “autoregressive” baselines as their AU is 0. To better visualize the sys-tem differenCe on OMNIGLOT dataset, for OMNIGLOT figure we ignore some β-VAE baselines that are notComPetitive.
Figure 5: Training behavior on Yelp. Left: VAE + annealing. Middle: Our method. Right: β-VAE (β = 0.2).
Figure 6: The projections of 500 data samples from synthetic dataset on the posterior mean space over thecourse of training. “iter” denotes the number of updates of generators. The top row is from the basic VAEtraining, the bottom row is from our aggressive inference network training. The results show that while theapproximate posterior is lagging far behind the true model posterior in basic VAE training, our aggressivetraining approach successfully moves the points onto the diagonal line and away from inference collapse.
