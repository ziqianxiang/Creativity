Figure 1: Left: Graphical model used in Info-GAIL Li et al. (2017). Right: Causal model in thiswork. The latent code causes the policy to produce a trajectory. The current trajectory, and latentcode produce the next latent codeshown in Figure 1 (Right). The nodes Ct denote latent variables which indicate the currently activesub-task and the nodes Tt denote the state-action pair at time t. We consider as given, a set of expertdemonstrations, each of which is represented by T = {τι,…，ττ} and has a corresponding sequenceof latent factors C = {cι,…,CT-ι}. The sub-activity at time t dictates what state-action pair wasgenerated at time t. The previous sub-task and the current state together cause the selection of thenext sub-task.
Figure 2: Left: VAE pre-training step. The VAE encoder uses the current state (St), and previouslatent variable (ct-ι) to produce the current latent variable (ct). The decoder reconstructs the action(at) using St and Ct. Right: An overview of the proposed approach. We use the VAE pre-trainingstep to learn an approximate prior over the latent variables and use this to learn sub-task policies inthe proposed Directed-Info GAIL step.
Figure 3: Results on the Four Rooms environment. (a) and (b) show results for two different latentvariables. The arrows in each cell indicate the direction (action) with highest probability in thatstate and using the given latent variable. (c) and (d) show expert and generated trajectories in thisenvironment. Star (*) represents the start state. The expert trajectory is shown in red. The color ofthe generated trajectory represents the latent code used by the policy at each time step.
Figure 4: Results for Directed-Info GAIL on continuous environments. (a) Our method learns to breakdown the Circle-World task into two different sub-activities, shown in green and blue. (b) Trajectorygenerated using our approach. Color denotes time step. (c) Trajectory generated in opposite direction.
Figure 5: (a) shows the plot of the sub-task latent variable Vs time on the Hopper and Walker tasks.
Figure 6: Segmentations obtained usingour proposed Directed-Info GAIL method onFetchPickandPlace-v1.
Figure 7: Latent variable assignment on the expert trajectories in Circle-World (a) with and (b)without smoothing penalty Ls. Blue and green colors represent the two different values of the contextvariable. The centres of the two circles are shifted for clarity.
Figure 9: Results on Hopper environment with sub-task latent variable of size 8.
Figure 8: PCA Visualization for Hopper and Walker environment with sub-task latent variable ofsize 4.
