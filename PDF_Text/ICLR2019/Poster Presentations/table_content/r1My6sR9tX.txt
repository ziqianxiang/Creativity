Table 1: Results of unsupervised learning on Omniglot images, averaged over 1000 downstream characterrecognition tasks. CACTUs experiments use k = 500 clusters for each of P = 100 partitions. Embeddingcluster matching uses the same k. For complete results with confidence intervals, see Table 8 in Appendix F.
Table 2: Results of unsupervised learning on miniImageNet and CelebA images, averaged over 1000 down-stream human-designed tasks. CACTUs experiments use k = 500 for each of P = 50 partitions. Embeddingcluster matching uses the same k. For complete results with confidence intervals, see Tables 9 and 10 inAppendix F.
Table 3: Ablation study of task construction methods on Omniglot. For a more complete set of results withconfidence intervals, see Table 8 in Appendix F.
Table 4: Ablation study of task construction methods on miniImageNet. For a more complete set of resultswith confidence intervals, see Table 9 in Appendix F.
Table 5: MAML hyperparameter summary.
Table 6: ProtoNets hyperparameter summary.
Table 7: MNIST digit classification results averaged over 1000 tasks. ± denotes a 95% confidence interval, k: number of clusters in a partition, F: number of partitions used duringmeta-learningAlgorithm	(way, shot)	(1。, D	(10,5)	(10, 10)ACAI, d = 256 Embedding fc∏∏-nearest neighbors		74.49 ± 0.82 %	88.80 ± 0.27 %	91.90 ±0.17 %Embedding linear classifier		76.53 ±0.81 %	92.17 ±0.25 %	94.58 ±0.15 %Embedding cluster matching, k = IQ		91.28 ±0.58 %	95.92 ±0.16 %	96.01 ±0.12%CACTUs-MAML on images (ours), P =	=1, fc = 10	92.66 ±0.34 %	96.08 ±0.12 %	96.29 ±0.12 %CACTUs-MAML on embeddings (ours)	,P = 1, fc = 10	94.77 ± 0.28 %	96.56 ±0.11 %	96.80 ±0.11 %BiGAN, d = 50 Embedding fc∏∏-nearest neighbors		29.25 ± 0.83 %	44.59 ± 0.44 %	51.98 ±0.30 %Embedding linear classifier		30.86 ±0.89 %	51.69 ±0.44 %	60.70 ±0.31 %Embedding cluster matching, k = IQ		33.72 ±0.54 %	50.21 ±0.36%	52.95 ± 0.34%CACTUs-MAML on images (ours), P =	=1, fc = 10	43.75 ±0.46 %	62.20 ± 0.33 %	68.38 ± 0.29 %CACTUs-MAML on images (ours), P =	=100, k = IQ	49.73 ± 0.45 %	77.05 ± 0.30 %	83.90 ± 0.24 %CACTUs-MAML on embeddings (ours)	,P = 1, fc = 10	36.33 ±0.48 %	51.78 ±0.34 %	57.41 ± 0.30 %CACTUs-MAML on embeddings (ours)	,P = 100, k=lQ	37.32 ±0.41 %	60.74 ± 0.34 %	67.34 ± 0.30 %IrtfoGAN, d=12 Embedding fc∏∏-nearest neighbors		94.53 ±0.51 %	96.05 ±0.17 %	96.24 ±0.12 %Embedding linear classifier		95.78 ±0.42 %	96.61 ±0.21 %	96.85 ±0.11 %Embedding cluster matching, k = IQ		93.42 ±0.57 %	96.97 ±0.15 %	96.99 ±0.10 %CACTUs-MAML on images (ours), P =	=1, fc = 10	95.30 ±0.23 %	97.18 ± 0.10 %	97.28 ± 0.10 %CACTUs-MAML on images (ours), P =	=100, k = IQ	96.08 ±0.19 %	97.22 ± 0.10 %	97.31 ± 0.09 %
Table 8: Omniglot character classification results averaged over IOOO tasks. ± denotes a 95% confidence interval, d: dimensionality of embedding, h: number of hidden units in afully connected layer, k: number of clusters in a partition, F: number of partitions used during meta-learning, m: margin on boundary-defining hyperplanes.
Table 9: minilmageNet object classification results averaged over 1000 tasks. ± denotes a 95% confidence interval, d: dimensionality of embedding, h: number of hidden units in afully connected layer, k: number of clusters in a partition, F: number of partitions used during meta-learning, m: margin on boundary-defining hyperplanes.
Table 10: CelebA facial attribute classification results averaged over 1000 tasks. ± denotes a 95% confidenceinterval. d: dimensionality of embedding, h: number of hidden units in a fully connected layer, k: number ofclusters in a partition, P: number of partitions used during meta-learning.
Table 11: MAML hyperparameter summary for ImageNet.
Table 12: minilmageNet object classification results averaged over 1000 tasks, with ImageNet-Scale meta-training. ± denotes a 95% confidence interval, d: dimensionality ofembedding, k: number of clusters in a partition, F: number of partitions used during meta-learning.
