Table 1: Our approach can be applied to many different domains beyond sentiment flipping, as illustrated herewith example re-writes by our model on public social media content. The first line in each box is an inputprovided to the model with the original attribute, followed by its rewrite when given a different attribute value.
Table 2: Recovering the sentiment of the input from the encoder’s representations of a domainadversarially-trained Fader model (Fu et al., 2017). During training, the discriminator, which wastrained adversarially and jointly with the model, gets worse at predicting the sentiment of the inputwhen the coefficient of the adversarial loss λadv increases. However, a classifier that is separatelytrained on the resulting encoder representations has an easy time recovering the sentiment. We alsoreport the baseline accuracy of a fastText classifier trained on the actual inputs.
Table 3: The number of reviews for each attribute for different datasets. The SYelp, FYelp andthe Amazon datasets are composed of 443k, 2.7M and 75.2M sentences respectively. Public socialmedia content is collected from 3 different data sources with 25.5M, 33.0M and 20.2M sentencesfor the Feeling, Gender and Age attributes respectively.
Table 4: Automatic evaluation of models on the SYelp test set from Li et al. (2018). The test set iscomposed of sentences that have been manually written by humans, which we use to compute theBLEU score. Samples for previous models were made available by Li et al. (2018). For our model,we report different results corresponding to different choices of hyper-parameters (pooling kernelwidth and back-translation temperature) to demonstrate our model’s ability to control the trade-offbetween attribute transfer and content preservation.
Table 5: Top: Results from human evaluation to evaluate the fluency / content preservation andsuccessful sentiment control on the Li et al. (2018) SYelp test set. The mean and standard deviation ofFluency and Content are measured on a likert scale from 1-5 while sentiment is measured by fractionof times that the controlled sentiment of model matches the judge’s evaluation of the sentiment(when also presented with a neutral option). Bottom: Results from human A/B testing of differentpairs of models. Each cell indicates the fraction of times that a judge preferred one of the models orneither of them on the overall task.)Since our automatic evaluation metrics are not ideal, we carried out human evaluations using theprotocol described in Section 4.2. Table 5 (top) shows the fluency, content preservation and attributecontrol (sentiment) scores obtained by our model, DeleteAndRetrieve (DAR) and turkers from Li8Published as a conference paper at ICLR 2019et al. (2018) 4 on the SYelp dataset. While humans clearly outperform both models, our model isbetter than DeleteAndRetrieve on all 3 dimensions. We further demonstrate our model’s strengthover DeleteAndRetrieve in Table 5 (bottom) in an A/B test between two the models, where crowdworkers prefer our model 54.4% compared to theirs 20.8%. Interestingly, our baseline Fader modelis also able to do better (37.6% vs 29.7%), suggesting limitations in our automatic metrics, sinceFader does not do as well in Table 4.
Table 6: Results using automatic evaluation metrics on the FYelp and Amazon test sets. Differentrows correspond to the set of attributes being controlled by the model.
Table 7: Model ablations on 5 model components on the FYelp dataset (Left) and SYelp (Right).
Table 8: Example re-writes by our model on the FYelp and Amazon datasets when controlling a single attribute.
Table 9: Demonstrations of our model’s ability to control multiple attributes simultaneously on theAmazon dataset (top) and FYelp dataset (bottom). The first two columns indicate the combination ofattributes that are being controlled, with the first row indicating a pre-specified input16Published as a conference paper at ICLR 2019Relaxed → AnnoyedRelaxed Annoyed	Wow! Sitting on my sister’s patio, a glass of wine, and glorious music! Hmmmm! Wow! Sitting on my sister’s patio, a glass of wine, and the neighbors are out! Geez!Relaxed Annoyed	Nothing like a few J after a long productive day!! Nothing like a flat tire 叮 after a long day at work!!Relaxed Annoyed	I decided it was time for a little chill time with my people tonight, I Missed them! Plus I need a breakJQ	W I thought I was sleeping for a little while at the end of the week, I’m done! Plus I need a nap.三 ◎三 w∙ s?Relaxed Annoyed	Rain = Sleepy! Love the sound of rain on my tin roof.,域、 FYI: Tomorrow is FRIDAY! Rain = Mad! The sound of rain on my tin roof. <r. Rain is overrated!Relaxed Annoyed	Yay!! A quick pedicure before I pick up the little angel from school!一 Yay!! A week before I pick up the little bastard from school! FMLRelaxed Annoyed	Had an amazing day driving around. The sea, the woods, just great. j Had an amazing day driving around. The weather, the roads are delayed, and the traffic is closed. ®Relaxed Annoyed	Happiness is watching movie in a rainy day cuddling with your kids in a cozy bed 曾 Yet again watching tv ina rainy day cuddling with my kids in a cozy house φ.
Table 10: Examples of our model’s ability to re-write sentences from public social media content when con-ditioned on information about the feeling expressed by the writer (Relaxed vs Annoyed)17Published as a conference paper at ICLR 201965+ → 18-2465+ 18-24	Reality leaves a lot to the imagination. - John Lennon Reality leaves a lot of memes - John Cena65+ 18-24	Photos are beautiful. It must be unreal in person Q Cool PiC bro - It must be fab in person!65+ 18-24	where did the time go ? LOVE the toothless smile! lemme show U something - 惠 toothless smile ：65+ 18-24	so pretty I feed so many in my yard and just love seeing them everyday. so pretty I wanna tag in my family and just love them everyday65+ 18-24	Just where are you. I am loving the piCtures and just a bit envious. Just wanna be you I’m loving the piCtures and just a bit exCited65+ 18-24	Yes, so true! It is inCredible what moms learn from daughters and grands! Lmao so true! It’s inCredible what moms learn from daughters and kids x65+ 18-24	FantastiC piCture, Peter you look younger all the time, must be the love! Osm pic Peter you look younger all the time, must be the love65+ 18-24	What a sweet little girl. One can see the love B between you 2. What a sweet little girl 呼 ∣ρo can see the love B between you 265+ 18-24	Congratulation young man. I am very proud of you, keep up the good work. Congratulation sis I’m very proud of you keep up the good work65+ 18-24	So good to hear you are doing well. Love seeing pictures of your precious granddaughter p So good to hear you,re doing well B seeing pictures of your precious baby B18-24 → 65+18-24 65+	Yeah ight bitch. We gon see who get the last laugh ® These ignorant idiots. We might see who get the last laugh!!!!!18-24 65+	Y,all are cute tho and I,m happy for you guys p Hi, you are cute folks and I am happy for you guys.
Table 11: Model re-writes of sentences from public social media content when conditioned on the age-groupof the writer (18-24 vs 65+)18Published as a conference paper at ICLR 2019Positive 什 Negative (Yelp)Positive	happy to find this hidden gem near my office. great food and best of all, fast delivery.
Table 12: Examples of human edits from our FYelp and Amazon datasets. The first line in every box was theinput presented to a crowd worker followed by their corresponding edit with the specified attribute.
Table 13: Examples of controlling sentiment with different model checkpoints that exhibit differenttrade-offs between content preservation (self-BLEU) and attribute control (Accuracy). The first linein both examples is the input sentence, and subsequent lines are a model’s outputs with decreas-ing content preservation with rows corresponding to model checkpoints at different epochs duringtraining.
Table 14: Examples of the learned attribute biases for sentiment and restaurant categories on FYelp.
