Table 1: Average error and number of failed tasks (> 5% error) out of 20 (in parentheses; lower isbetter in both cases) on the bAbI dataset under the different training/evaluation setups. We indicatestate-of-the-art where available for each, or ‘-’ otherwise.
Table 2: Accuracy on the subject-verb agreement number prediction task (higher is better).						Model	LM Perplexity & (Accuracy)				RC Accuracy		control		dev	test	control	dev	testNeural Cache (Grave et al., 2016)	129		139	-	-	--Dhingra et al. Dhingra et al. (2018)	-		-	-	-	-	0.5569Transformer	142 (0.19)		5122 (0.0)	7321 (0.0)	0.4102	0.4401	0.3988LSTM	138 (0.23)		4966 (0.0)	5174 (0.0)	0.1103	0.2316	0.2007UT base, 6 steps (fixed)	131 (0.32)		279 (0.18)	319 (0.17)	0.4801	0.5422	0.5216UT w/ dynamic halting	130 (0.32)		134 (0.22)	142 (0.19)	0.4603	0.5831	0.5625UT base, 8 steps (fixed)	129(0.32)		192(0.21)	202 (0.18)	-	--UT base, 9 steps (fixed)	129(0.33)		214 (0.21)	239 (0.17)	-	--Table 3: LAMBADA language modeling (LM) perplexity (lower better) with accuracy in parentheses(higher better), and Reading Comprehension (RC) accuracy results (higher better). ‘-’ indicates noreported results in that setting.
Table 3: LAMBADA language modeling (LM) perplexity (lower better) with accuracy in parentheses(higher better), and Reading Comprehension (RC) accuracy results (higher better). ‘-’ indicates noreported results in that setting.
Table 4: Accuracy (higher better) on the algorithmic tasks. *Note that the Neural GPU was trained witha special curriculum to obtain the perfect result, while other models are trained without any curriculum.
Table 5: Character-level (char-acc) and sequence-level accuracy (seq-acc) results on the MemorizationLTE tasks, with maximum length of 55.
Table 6: Character-level (char-acc) and sequence-level accuracy (seq-acc) results on the ProgramEvaluation LTE tasks with maximum nesting of2 and length of5.
Table 7: Machine translation results on the WMT14 En-De translation task trained on 8xP100 GPUsin comparable training setups. All base results have the same number of parameters.
