Table 1: Comparison to baseline methods on synthetic experiments.														Symmetric projection			Diagonal extraction				Max singular vector				Trace	# Layers	1	2	3	1	2	3	1	2	3	4	1	2	3Trivial predictor	4.17	4.17	4.17	0.21	0.21	0.21	0.025	0.025	0.025	0.025	333.33	333.33	333.33Hartford et al.	2.09	2.09	2.09	0.81	0.81	0.81	0.043	0.044	0.043	0.043	316.22	311.55	307.97Ours	1E-05	7E-06	2E-05	8E-06	7E-06	1E-04	0.015	0.0084	0.0054	0.0016	0.005	0.001	0.003Synthetic datasets. We tested our method on several synthetic equivariant and invariant graphfunctions that highlight the differences in expressivity between our linear basis and the basis ofHartford et al. (2018). Given an input matrix data A ∈ Rn×n we considered: (i) projection onto thesymmetric matrices 2 (A+AT); (ii) diagonal extraction diag(diag(A)) (keeps only the diagonal andplugs zeros elsewhere); (iii) computing the maximal right singular vector arg maxkvk =1 kAvk2;and (iv) computing the trace tr(A). Tasks (i)-(iii) are equivariant while task (iv) is invariant. Wecreated accordingly 4 datasets with 10K train and 1K test examples of40 ×40 matrices; for tasks (i),(ii), (iv) we used i.i.d. random matrices with uniform distribution in [0, 10]; we used mean-squarederror (MSE) as loss; for task (iii) we random matrices with uniform distribution of singular valuesin [0, 0.5] and spectral gap ≥ 0.5; due to sign ambiguity in this task we used cosine loss of the forml(x, y) = 1 - hx/ kxk ,y/ kyki2.
Table 2: GeneraIization.
