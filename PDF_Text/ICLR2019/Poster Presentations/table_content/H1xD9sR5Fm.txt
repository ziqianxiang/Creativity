Table 1: BLEU scores on IWSLT German-English translation evaluated on the test set.
Table 2: Results on Gigaword sentence summarization task								criterion	ROUGE-1		ROUGE-2		ROUGE-L		ROUGE-S4		valid	test	valid	test	valid	test	valid	testMLE	48.41	34.20	24.14	15.22	45.08	31.84	22.62	14.00margin	48.43	34.20	24.16	15.24	45.09	31.85	22.65	14.00slack	48.40	34.20	24.12	15.25	45.08	31.83	22.63	14.00RAML	48.43	34.20	24.16	15.24	45.10	31.84	22.66	14.00MRT	50.41	35.63	26.42	16.96	47.05	33.24	24.47	15.31Hellinger	51.02	35.84	26.88	17.03	47.71	33.47	25.12	15.54MLE + BS	49.69	36.21	25.52	16.37	46.55	32.75	24.00	15.01MRT + BS	50.72	36.47	26.74	17.62	47.41	34.05	25.05	15.98Hellinger + BS	51.07	36.59	26.95	17.61	47.62	34.03	25.34	16.047	DiscussionFor training criteria in the form of divergence minimization, according to our experimental results,MRT outperforms RAML. As mentioned before, MRT and RAML minimize the cross entropy intwo different directions. By the definition of cross entropy loss in Equation (8), it is only mini-mized when p1 = p2. Optimizing the cross entropy in either of the two directions both guaranteeconsistency, i.e., the training procedure can ultimately recover the true probability distribution.
Table 3: Tokenized BLEU scores on IWSLT 2014 German-English translation evaluated on valida-tion set using RAML criterion.
Table 4:	Tokenized BLEU scores on IWSLT 2014 German-English translation evaluated on thevalidation set using squared Hellinger distance with different α and τ as training criterion.
Table 5:	Tokenized BLEU scores on IWSLT 2014 German-English translation evaluated on thevalidation set using squared Hellinger Distance with different sample sizes.
Table 6:	Tokenized BLEU scores on IWSLT 2014 German-English translation evaluated on thevalidation set using max margin criteria.
Table 7: BLEU scores using convolutional seq2seq models.
