Table 1: Quantitative comparison of the disentanglement and reconstruction performance of theunsupervised method on MNIST digits.
Table 2: Quantitative comparison of the disentanglement and reconstruction performance of theevaluated models in the facial attribute manipulation task. Disentanglement is measured as theability to flip specified attributes by varying the corresponding latent unit.
Table 3: Summary comparison of the characteristics of recent related methods. Our method hasadvantages over each of them, and together with Fader Networks are the only ones to generate256×256 images while continuously varying the generated facial attributes.
Table 4: Ablation study of the weight of each loss term for the unsupervised example of Section 3,using k = 2 and d = 14 for the student.
Table 5: Ablation study of the impact of Jacobian and cycle-consistency losses in the training ofthe student model in the facial attribute manipulation task. The results correspond to training astudent with d = 4096 for 50 epochs, and where the teacher was trained only with reconstructionand Cross-Covariance losses, With d = 2048. All models Used the Same teacher.________λ4(Lcyc1)	λ5(Lcyc2)	λdiff λy		reconstrUction MSE		sUccessfUl flips0	0	50	1	1.76e -	3	70.3%0	0	10	1	1.67e -	3	64.8%0	0	1	10	1.85e -	3	49.1%0	0	1	1	1.69e -	3	46.8%1e-4	1e-5	0	0	1.78e -	3	43.2%1e-4	1e-5	50	1	1.84e -	3	70.7%Table 6: Ablation study of the weigh of the cross-covariance loss in the facial attribute manipulationexample. The resUlts Correspond to training a teaCher model With d = 2048, from sCratCh and for50 epochs.
Table 6: Ablation study of the weigh of the cross-covariance loss in the facial attribute manipulationexample. The resUlts Correspond to training a teaCher model With d = 2048, from sCratCh and for50 epochs.
