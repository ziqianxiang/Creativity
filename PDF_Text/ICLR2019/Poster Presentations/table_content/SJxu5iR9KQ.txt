Table 1: List of hyperparametersHyperparameter	Value	Descriptiontraining step	750000	Maximum time steps until the end of trainingepisode length	1000	Maximum time steps per episodediscount factor	0.9	Importance of future rewardslearning rate for actor	0.00001	Actor network learning rate used by Adam optimizerlearning rate for critic	0.0001	Critic network learning rate used by Adam optimizertarget update rate	0.05	Target network update rate to track learned networkentropy regularization weight	0.01	Weight of regularization to encourage exploration13Published as a conference paper at ICLR 2019(a) Comm. bandwidth L(k = 1)(b) Sched. constraint k(l = 1)(c) SchedNet vs. AE(k = 1 and l = 1)Figure 8:	Performance evaluation of SchedNet. The graphs show the average time taken to complete the task,where shorter time is better for the agents.
Table 2: Performance with/without encoderFC	SChedNet -Top(1)	Schedule w/ auto-enCoder1	2.030	3.408Impact of joint scheduling and encoding To study the effect of jointly coupling scheduling andencoding, we devise a comparison against a pre-trained auto-encoder (Bourlard & Kamp, 1988;Hinton & Zemel, 1994). An auto-encoder was trained ahead of time, and the encoder part of thisauto-encoder was placed in the Actor’s ENC module in Figure 1. The encoder part is not trainedfurther while training the other parts of network. Henceforth, we name this modified Actor “AE”.
