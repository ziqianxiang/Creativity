Table 1: Variational lower bound (ELBO), its decomposition into the data term and the KL term, and testset accuracy for different parameterizations. The test-time averaging accuracy is roughly the same for allprocedures, but a clear phase transition is only achieved in layer-wise and neuron-wise parameterizations. Thesame result is reproduced on a VGG-like architecture on CIFAR-10; the achieved ELBO values are -116.2,-233.4 and -1453.7 for the layer-wise, neuron-wise and weight-wise parameterizations respectively.
Table 2: Test set classification accuracy for differ-ent methods and datasets. “Variance” stands for vari-ational dropout model in the layer-wise parameteriza-tion equation 14. “1 samp.” corresponds to the accu-racy of one sample of the weights, “Det.” correspondsto mean propagation, and “20 samp.” corresponds tothe MC estimate of the predictive distribution using 20samples of the weights.
Table 3: One-sample (stochastic) and test-time-averaging (ensemble) accuracy of LeNet-5 tanh net-works. “det” stands for conventional deterministic layers and “var” stands for variance layers (layerswith zero-mean parameterization).
