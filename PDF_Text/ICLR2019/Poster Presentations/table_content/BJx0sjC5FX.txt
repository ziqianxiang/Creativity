Table 1: (a) MSEs of TPDN approximations of sentence encodings (normalized by dividing bythe MSE from training the TPDN on random vectors, to allow comparisons across models). (b)Performance of the sentence encoding models on our role-diagnostic analogies. Numbers indicateEuclidean distances (normalized by dividing by the average distance between vectors in the analogyset). Each column contains the average over all analogies diagnostic of the role heading that column.
Table 2: The proportion of test examples on which a classifier trained on sentence encodings gavethe same predictions for the original encodings and for their TPDN approximations. (a) showsthe average of these proportions across SST, MRPC, and STS-B, while (b) shows only SNLI. (Forincluding STS-B in (a), we linearly shift its values to be in the same range as the other tasksâ€™ results).
Table 3: (a) Tasks used to test for the effect of task on learned roles (Section 4). (b) Accuracy ofthe TPDN applied to models trained on these tasks with a unidirectional encoder and decoder. Allnumbers are averages across five random initializations.
Table 4: Substitution accuracies with and without the final linear layer, for TPDNs using variouscombinations of filler and role embedding dimensionality. These TPDNs were approximating aseq2seq model trained to perform reversal.
Table 5: Approximating a unidirectional seq2seq model trained to perform sequence reversal: sub-stitution accuracies using different binding operations.
Table 6: Accuracies of the various sequence-to-sequence encoder/decoder combinations at the dif-ferent training tasks. Each number in this table is an average across five random initializations. Uni= unidirectional; bi = bidirectional.
Table 7: Substitution accuracies for TPDNs applied to all combinations of encoder, decoder, trainingtask, and hypothesized role scheme. Each number is an average across five random initializations.
Table 8: Substitution results on performing the applied tasks for TPDNs trained to approximatethe representations from each of the four downloaded models. For MRPC, we report accuracy andF1. For STS-B, we report Pearson correlation and Spearman correlation. All other metrics areaccuracies.
Table 9: The proportion of times that a classifier trained on a sentence encoding model gave the samedownstream-task predictions based on the original sentence encoding model and based on a TPDNapproximating that model, where the TPDN uses the role schemes indicated by the column header.
Table 10: Downstream task performance for classifiers trained and tested on the TPDNs that weretrained to approximate each of the four applied models. The rightmost column indicates the perfor-mance of the original model (without the TPDN approximation).
