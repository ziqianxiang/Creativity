Table 1: Acc. (%) of covariate prediction.
Table 2: Performance comparison of 1:2 matching for models trained using different sets of covariates.
Table 3: Verification results.
Table 4: Retrieval performance (mAP).
Table 5: AUCs (%) of DIMNets under different testing groups.
Table 6: Statistics for the data appearing in VoxCeleb and VGGFace.
Table 7: The detailed CNNs architectures. The numbers within the parentheses represent the size and numberof filters, while the subscripts represent the stride and padding. So, for example, (3, 64)/2,1 denotes a 1Dconvolutional layer with 64 filters of size 3, where the stride and padding are 2 and 1 respectively, while(3 × 3, 64)/2,1 represents a 2-D convolutional layer of 64 3 × 3 filters, with stride 2 and padding 1 in bothdirections. Note that 924, 2, and 32 are the number of unique values taken by the ID, gender, and nationalitycovariates, respectively.
Table 8: The accuracies of DIMNet-I with different embedding dimensions on 1:2 matching experimentsIt could be observed that the performance of cross-modal matching is very stable within a wide rangeof embedding dimension, showing that the accuracy is not sensitive to the embedding dimension.
Table 9: the possible error types with probabilities.
