Table 1: Common choices of the gradient flow v in POVI methods, where k denotes a kernel, andKij := k(θ(i), θ(j)) is the gram matrix. We omit the subscript ` for brevity.
Table 2: Test error on the MNIST dataset. Boldface indicates the best result.
Table 3: Cumulative regret in different bandits. Results are averaged over 10 trials.
Table 4: Average test RMSE on UCI datasets. Bold indicates statistically significant best results(p < 0.05 with t-test).
Table 5: Average test NLL on UCI datasets. Bold indicates best results.
Table 6: Average test RMSE and NLL following the setup of Azizpour et al. (2018). Bold indicatesbest results.
Table 7: Average test RMSE and NLL on UCI datasets, following the setup in Ma et al. (2018).
Table 8: Comparison with other baselines under a narrower network prior on some UCI datasets.
Table 9: MNIST: Test accuracy and NLL on clean samples	MC-dropout	SVGD	f-SVGDaccuracy	0.983	0.970	0.984average NLL	0.075	0.109	0.065CIFAR Experiment Details We use the ResNet-32 architecture, defined in He et al. (2016b), anduses the same training scheme. We use 8 particles for our method and the ensemble method. Forour method, we use 32 particles to generate 6-dimensional prior samples.
Table 10: CIFAR-10: Test accuracy and NLL on clean samples	single	ensemble	f-SVGDaccuracy	0.925	0.937	0.934average NLL	0.376	0.203	0.218A.4 Contextual BanditContextual bandit is a classical online learning problem. The problem setup is as follows: for eachtime t = 1,2,…，N, a context St ∈ S is provided to the online learner, where S denotes the givencontext set. The online learner need to choose one of the K available actions It ∈ {1,2,…，K}based on context st, and get a (stochastic) reward '几,h The goal of the online learner is to minimizethe pseudo-regretRS = max Eg：ST{1,2,…，K}nnΣ'g(st),t - Σ'lt,t(5)where g denotes the mapping from context set S to available actions {1,2,…，K}. Pseudo-regretmeasures the regret of not following the best g, thus pseudo-regret is non-negative, and minimizethe pseudo-regret is equal to find such the best g.
Table 11: Test NLL on UCI datasets for SVGD with alternative kernels.
