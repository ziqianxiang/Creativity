Table 1: Pruning results on LeNets and comparisons to other approaches. Here, “many” refers toan arbitrary number often in the order of total learning steps, and “soft” refers to soft pruning inBayesian based methods. Our approach is capable of pruning up to 98% for LeNet-300-100 and 99%for LeNet-5-Caffe with marginal increases in error from the reference network. Notably, our approachis considerably simpler than other approaches, with no requirements such as pretraining, additionalhyperparameters, augmented training objective or architecture dependent constraints.
Table 2: Pruning results of the proposed approach on various modern architectures (before → after).
Table 3: The effect of initialization on our saliency score. We report the classification errors (±std).
Table 4: Pruning results of SNIP on Tiny-ImageNet (before → after). Tiny-ImageNet2 is a subset ofthe full ImageNet: there are 200 classes in total, each class has 500 and 50 images for training andvalidation respectively, and each image has the spatial resolution of64 × 64. Compared to CIFAR-10,the resolution is doubled, and to deal with this, the stride of the first convolution in all architectures isdoubled, following the standard practice for this dataset. In general, the Tiny-ImageNet classificationtask is considered much more complex than MNIST or CIFAR-10. Even on Tiny-ImageNet, however,SNIP is still able to prune a large amount of parameters with minimal loss in performance. AlexNetmodels lose more accuracies than VGGs, which may be attributed to the fact that the first convolutionstride for AlexNet is set to be 4 (by its design ofno pooling) which is too large and could lead to highloss of information when pruned.
Table 5: AlexNet-s (k = 1) and AlexNet-b (k = 2). In the last layer, c denotes the number of possibleclasses: c = 10 for CIFAR-10 and c = 200 for Tiny-ImageNet. The strides in the first convolutionlayer for Tiny-ImageNet are set [4, 4] instead of [2, 2] to deal with the increase in the image resolution.
Table 6: VGG-C/D/like. In the last layer, c denotes the number of possible classes: c = 10 for CIFAR-10 and c = 200 for Tiny-ImageNet. The strides in the first convolution layer for Tiny-ImageNet are set[2, 2] instead of [1, 1] to deal with the increase in the image resolution. The second Linear layer isonly used in VGG-C/D.
