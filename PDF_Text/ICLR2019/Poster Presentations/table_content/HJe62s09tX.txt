Table 1: Accuracy averaged on both directions (source→target and target→source) with aNN crite-rion on triplet alignment with direct translation (“Direct”) and indirect translation (“Ind.”). Indirecttranslation uses a pivot (source→pivot→target). The pivot language is underlined. We compare ourapproach applied to pairs (“Pairs”) of languages and triplets (“Triplets”).
Table 2: Accuracy of supervised and unsupervised approaches on the MUSE benchmark. All theapproaches use a CSLS criterion. “ref.” refers to the refinement method of Conneau et al. (2017).
Table 3: Accuracy with a NN criterion on indirect translations averaged among and across lan-guage families. The languages are Czech, Danish, Dutch, English, French, German, Italian, Polish,Portuguese, Russian and Spanish. UMH is either applied independently for each pairs formed withEnglish (“Bil.”)orjointly (“Multi.”). W-Proc.* is our implementation of Grave et al. (2018) with aGomorov-Wasserstein initialization and our optimization scheme.
Table 5: Comparison of two different initializations for UMH on direct and indirect translationswith a NN criterion. Convex relaxation refers to the initialization of Grave et al. (2018), while oursis Gromov-Wasserstein. We consider the 6 languages with mutual MUSE bilingual lexicons. Weonly learn bilingual mappings to and from English and translate with English as a pivot.
Table 6: Impact of the number of languages on UMH performance. We report accuracy with aCSLS criterion on the 6 common languages. We average accuracy of translations from and to asingle language. Numbers for MAT+MPSR are from Chen and Cardie (2018).
Table 7: Full results on direct translation with the 11 languages and both NN and CSLS criteria forthe UMH method. Bil. stands for bilingual, and Mul. stands for multilingual.
Table 8: Full results on indirect translation with the 11 languages with a CSLS criterion.
Table 9: Full results of our model trained on 6 languages with a CSLS criterion.
