Table 1: Experiment Result of Biological DatasetAlgorithm	MUTAG	NCI1	PROTEINS	D&D	ENZYMESWL	82.05±0.36	82.19±0.18	74.68±0.49	79.78±0.36	52.22±1.26GK	81.58±2.11	62.49±0.27	71.67±0.55	78.45±0.26	32.70±1.20RW	79.17±2.07	>3days	74.22±0.42	>3days	24.16±1.64Graph2vec	83.15±9.25	73.22±1.81	73.30±2.05	-	-AWE	87.87±9.76	-	-	71.51±4.02	35.77±5.93DGK	87.44±2.72	80.31±0.46	75.68±0.54	73.50±1.01	53.43±0.91PSCN	88.95±4.37	76.34±1.68	75.00±2.51	76.27±2.64	-DGCNN	85.83±1.66	74.44±0.47	75.54±0.94	79.37±0.94	51.00±7.29ECC	76.11	76.82	-	72.54	45.67GCAPS-CNN	-	82.72±2.38	76.40±4.17	77.62±4.99	61.83±5.39CapsGNN	86.67±6.88	78.35±1.55	76.28±3.63	75.38±4.17	54.67±5.67CapsGNN achieves the SOTA performance on social datasets. More specifically, we are able toimprove the classification accuracy by a margin of 2.78% and 5.30% on RE-M5K and RE-M12Krespectively. This demonstrates that learning features in the form of capsules and modeling a graphto multiple embeddings is beneficial to capture macroscopic properties of graphs which are moreimportant in classifying social networks. These results also consistent with the property of CapsNet,as it focuses more on extracting important information from children capsules by voting. However,applying routing to the whole graph leads to preserve all the information at a graph level and this
Table 2: Experiment Result of Social DatasetAlgorithm	COLLAB	IMDB-B	IMDB-M	RE-M5K	RE-M12KWL	79.02±1.77	73.40±4.63	49.33±4.75	49.44±2.36	38.18±1.30GK	72.84±0.28	65.87±0.98	43.89±0.38	41.01±0.17	31.82±0.08DGK	73.09±0.25	66.96±0.56	44.55±0.52	41.27±0.18	32.22±0.10AWE	73.93±1.94	74.45±5.83	51.54±3.61	50.46±1.91	39.20±2.09PSCN	72.60±2.15	71.00±2.29	45.23±2.84	49.10±0.70	41.32±0.42DGCNN	73.76±0.49	70.03±0.86	47.83±0.85	48.70±4.54	-GCAPS-CNN	77.71±2.51	71.69±3.40	48.50±4.10	50.10±1.72	-CapsGNN	79.62±0.91	73.10±4.83	50.27±2.65	52.88±1.48	46.62±1.904.2	Efficiency of CapsulesThe main objective of this experiment is to examine the efficiency of capsules in encoding graphfeatures. More efficient in feature encoding here means representing more information with thesimilar number of neurons. We construct a scalar-based neural network for each CapsGNN and thencompare the CapsGNN with its related scalar-based architecture by comparing their training andtesting accuracy on graph classification task to demonstrate the efficiency in feature representation.
Table 3: Details of Tested Architectures in Efficiency Evaluation Experiment	2-4-2	2-4-4	2-4-8	2-4-16	4-4-2	4-4-4	4-4-8	4-4-16No. trainable Para.(Caps)	208	367	688	1328	448	704	1216	2240No. trainable Para.(Scalar)	216	370	692	1336	452	712	1232	2246Dim Node Feat.(Both)	2	2	2	2	4	4	4	4Dim Graph emb.(Caps)	2×4	4×4	8×4	16×4	2×4	4×4	8×4	16×4Dim FC.(Scalar)	12	23	48	92	10	20	40	79In Table 3 and Figure 3, the setting of different architectures is represented as dn-dg -P . Here, wechoose the simplest setting (2-4-2) as an example: 2-4-2 means that the dimension of nodes capsulesis dn = 2, the dimension of graph and class capsules is dg = 4 and the number of graph capsulesP equals to 2. Besides, we set the dimension of FC of its corresponding scalar-based architectureas 12 so that they have comparable number of trainable weights. In this case, each graph is modeledas 2 4-dimensional graph embeddings in the CapsGNN or 1 12-dimensional graph embedding in itscorresponding scalar-based architecture. Both architectures are sub-optimal to represent the wholedataset while CapsGNN can still reach higher accuracy compared with the scalar-based architecture.
Table 4:	Visualization of Graph CapsulesSubredditChannel 1 Channel 2 Channel 11 Channel 14atheism&IAmAatheism&mildlyinterestingWe choose to depict the distribution of graphs which are generated from 3 categories, namely athe-ism , IAmA and mildlyinteresting with capsules extracted from the 1st, 2nd, 11th, 14th channel ofgraph capsules. As we can see from Table 4, different channels of capsules represent different as-pects of graph properties. atheism and IAmA can be discriminated obviously with capsules extractedfrom the 11th and the 14th channels while they are hard to be separated with capsules extracted9Published as a conference paper at ICLR 2019from the 1st and the 2nd channels. However, atheism and mildlyinteresting can be discriminatedwith the capsules extracted from the 1st and the 2nd channels while they are mixed in the 11th andthe 14th channels which is opposite to the case of atheism and IAmA. This phenomenon can also beobserved in other multi-class datasets. It is still hard to figure out the specific aspects these capsules
Table 5:	Visualization of Class CapsulesSubredditatheism IAmA mildlyinteresting Concatenateatheism(g)&IAmA(r)&mildlyinteresting(b)As we can see from Table 5, different class capsules focus on different classification-related graphproperties. For example, the capsules that represent athesism (first column) can well discriminateathesism (red) from the other two types of graphs while IAmA (green) and mildlyinteresting (blue)are mixed in this channel. The similar phenomenon can also be found in other class capsules. Be-sides, when we concatenate the capsules of these three classes together, three types of graphs can bewell discriminated with the concatenated capsules which also directly reflect the classification per-formance. This property is quite different from standard scalar-based architectures where each graphis modeled with only one graph embedding2. By introducing the concept of capsules, the graph andclass capsules can not only preserve classification-related properties of each graph (reflected withthe length of class capsules) but also other properties information (reflected with the angle of classcapsules). The generated class capsules can also be useful in other follow-up work and we leave thisto be explored in the future.
Table 6: Dataset DescriptionDataset	Source	Graphs	Classes	Nodes Avg.	Edges Avg.	Nodes LabelsMUTAG	Bio	188	2	17.93	19.79	7ENZYMES	Bio	600	6	32.46	63.14	6NCI1	Bio	4110	2	29.87	32.30	23PROTEINS	Bio	1113	2	39.06	72.81	4D& D	Bio	1178	2	284.31	715.65	82COLLAB	Social	5000	3	74.49	4914.99	-IMDB-B	Social	1000	2	19.77	193.06	-IMDB-M	Social	1500	3	13	131.87	-REDDIT-M5K	Social	4999	5	508.5	1189.74	-REDDIT-M12K	Social	11929	11	391.4	456.89	-C Coordinate AdditionAfter Attention Module, coordinate addition can be used to preserve the position information of eachnode during the procedure of generating node capsule votes. The details of Coordinate Additionmodule can be found in Figure 4. This module is not necessary in some datasets. Here, we proposethis module as a selective optimization. When the GNN goes deeper, the extracted nodes featurescontain more specific position information of each node. Inspired by Zhang et al. (2018) wherethe node embeddings learned from the last layer of GNN are taken to order all nodes, we also takethe capsules extracted from the last layer of GNN as the position indicators of corresponding nodes
Table 7:Table 7: Experimental Setting for Graph ClassificationHyper-parameter description	Notation	ValueNumber of GCN layers	-L	Number of channels at each layer	F	"2Number of graph capsules	P	16Dimension of all capsules	d	1Number of iterations in routing	t	1Value used to scale Lossr	r	0.1Value used to balance the loss from the positive and negative output	λ	0.5 for multi-class classification 1.0 for binary classificationF Contribution of Each ModuleIn addition to evaluate the performance of the Whole architecture on the classification task, Wealso provide detailed study to quantify the contributions made by each module in CapsGNN on the15Published as a conference paper at ICLR 2019classification task. The six comparison architectures set-up is shown as below and the settings of thehyper-parameters are the same as Section 4.1.2.
Table 7: Experimental Setting for Graph ClassificationHyper-parameter description	Notation	ValueNumber of GCN layers	-L	Number of channels at each layer	F	"2Number of graph capsules	P	16Dimension of all capsules	d	1Number of iterations in routing	t	1Value used to scale Lossr	r	0.1Value used to balance the loss from the positive and negative output	λ	0.5 for multi-class classification 1.0 for binary classificationF Contribution of Each ModuleIn addition to evaluate the performance of the Whole architecture on the classification task, Wealso provide detailed study to quantify the contributions made by each module in CapsGNN on the15Published as a conference paper at ICLR 2019classification task. The six comparison architectures set-up is shown as below and the settings of thehyper-parameters are the same as Section 4.1.2.
Table 8: Validation Accuracy Comparison of Each ModuleArchitecture	COLLAB	IMDB-B	PROTEINS	NCI1	D&DCapsGNN	79.77±1.15	74.42±2.20	77.27±2.58	79.23±1.88	76.16±4.19CapsGNN -Coord	80.00±1.22	74.81±2.96	76.58±2.42	79.04±1.93	77.41±3.33CapsGNN -Avg	79.61±0.81	73.29±2.66	76.54±2.98	78.36±1.95	74.44±3.46CapsGNN -noRout	80.48±0.86	74.11±2.94	77.18±2.94	77.62±1.15	75.28±4.17CapsGNN -noRecon	80.44±0.88	74.03±2.11	76.69±1.78	78.23±2.41	74.70±3.12CapsGNN -Avg-noRout	80.15±1.02	74.23±3.47	75.94±2.61	76.25±2.40	73.93±3.56The validation accuracy of each architecture is shown in Table 8 where we highlight the highest andlowest accuracy respectively. As we can see from the Table, IMDB-B and D&D reach better per-formance with CapsGNN-Coord which indicates the effectiveness of Coordinate Addition Module.
