Table 1: Matching geometries: Average distortion on canonical graphs (tree, cycle, ring of trees)with 40 nodes, comparing four spaces with total dimension 3. The best distortion is achieved by thespace with matching geometry.
Table 2: Graph reconstruction: fidelity measures for graph embeddings using d = 10 total dimen-sions, with varying allocations of spaces and dimensions. Our loss function (2) targets distortion,and for each dataset the best model reflects the structure of the data. Even on near-perfectly sphericalor hierarchical data, products of S (resp. H) perform no worse than the single copy.
Table 3: Heuristic allocation: estimated signatures for embedding unweighted graphs from Table 2into two factors, using Algorithms 2,3 to match the empirical distribution of graph curvature. Theresulting curvature signs agree with results from Table 2 for choosing among two-component spaces.
Table 4: Spearman rank correlation on similarity datasets. Top: Previous results from embeddingsinto spaces of fixed curvature. Bottom: Embeddings into products of H with fixed total dimension.
Table 5: Accuracy on the Google word analogy dataset. Taking products of smaller hyperbolicspaces significantly improves performance. Unlike conventional embeddings, the operations in hy-perbolic and product spaces are defined solely through distances and manifold operations.
Table 6: Glossary of variables and symbols used in this paper.
