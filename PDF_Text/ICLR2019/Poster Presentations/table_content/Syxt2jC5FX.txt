Table 1: Impact of different VQ strategies for a MASO layer with P(t)PRk'l[t]r KM⑶]k,r,., Z('-1)〉+ [B⑶]k,r)∙3.5	Additional Nonlinearities as Soft DN LayersChanging viewpoint slightly, we can also derive classical nonlinearities like the sigmoid, tanh, andsoftmax Goodfellow et al. (2016) from the soft inference perspective. Consider a new soft DN layerwhose unit output [z(`)]k is not the piecewise affine spline of (2) but rather the probability [z(`)]k =p([t(')]k = 1|z(`-1)) that the input z(') falls into each VQ region. The following propositions areproved in Appendix E.6.
Table 2: Classification experiment to demonstrate the utility of orthogonal DN layers. For threedatasets and the same largeCNN architecture (detailed in Appendix D), we tabulate the classifica-tion accuracy (larger is better) and its standard deviation averaged over 5 runs with different Adamlearning rates. In each case, orthogonal fully-connected and convolution matrices improve the clas-sification accuracy over the baseline.
