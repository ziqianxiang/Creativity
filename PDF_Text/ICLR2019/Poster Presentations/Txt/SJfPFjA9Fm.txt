Published as a conference paper at ICLR 2019
Accelerating Nonconvex Learning via
Replica Exchange Langevin Diffusion
Yi Chen
Department of Industrial Engineering & Management Science
Northwestern University
Evanston, IL 60201, USA
yichen2016@u.northwestern.edu
Jinglin Chen
Department of Computer Science
University of Illinois at Urbana-Champaign
Urbana, IL 61801, USA
jinglinc@illinois.edu
Jing Dong
Columbia Business School School
Columbia University
New York City, NY 10027, USA
jing.dong@gsb.columbia.edu
Jian Peng
Department of Computer Science
University of Illinois at Urbana-Champaign
Urbana, IL 61801, USA
jianpeng@illinois.edu
Zhaoran Wang
Department of Industrial Engineering & Management Science
Northwestern University
Evanston, IL 60201, USA
zhaoran.wang@northwestern.edu
Ab stract
Langevin diffusion is a powerful method for nonconvex optimization, which en-
ables the escape from local minima by injecting noise into the gradient. In partic-
ular, the temperature parameter controlling the noise level gives rise to a tradeoff
between “global exploration” and “local exploitation”, which correspond to high
and low temperatures. To attain the advantages of both regimes, we propose to
use replica exchange, which swaps between two Langevin diffusions with differ-
ent temperatures. We theoretically analyze the acceleration effect of replica ex-
change from two perspectives: (i) the convergence in χ1 2-divergence, and (ii) the
large deviation principle. Such an acceleration effect allows us to faster approach
the global minima. Furthermore, by discretizing the replica exchange Langevin
diffusion, we obtain a discrete-time algorithm. For such an algorithm, we quantify
its discretization error in theory and demonstrate its acceleration effect in practice.
1 Introduction
We consider the problem of minimizing a nonconvex objective function, which arises from numer-
ous machine learning problems such as training neural networks. However, due to the existence
of spurious local minima, nonconvex optimization remains challenging in both theory and practice.
To overcome this difficulty, one idea is to construct a diffusion process whose invariant distribution
concentrates around the global minima (Chiang et al., 1987). If we run such a diffusion process for
a sufficiently long time, we expect to draw from its invariant distribution a point that is close to a
global minimum with high probability.
One commonly used diffusion process is the Langevin diffusion, which is closely related to first-
order optimization (Gidas, 1985). In specific, the Langevin diffusion can be viewed as gradient flow
with injected noise, where the noise is scaled by a temperature parameter. Such a temperature pa-
rameter gives rise to a tradeoff between two opposite effects, namely “global exploration” and “local
1
Published as a conference paper at ICLR 2019
exploitation”. More specifically, a higher temperature results in a larger injected noise, which in-
creases the probability of escaping from spurious local minima and facilitates the global exploration
of the whole domain. On the other hand, with a lower temperature, the Langevin diffusion behaves
more like the gradient flow, which focuses more on exploiting the local geometry to decrease the
objective value, yielding a more concentrated invariant distribution.
In this paper, we aim to bridge the gap between “global exploration” and “local exploitation” in
nonconvex optimization with replica exchange, which originates from parallel tempering Markov
chain Monte Carlo methods for sampling from a multimodal distribution (Earl & Deem, 2005). In
contrast to the standard Langevin diffusion driven by a single temperature, the replica exchange
Langevin diffusion consists of two Langevin diffusions with low and high temperatures, which lo-
cally exploits the geometry and globally explores the domain, respectively. In particular, the two
Langevin diffusions exchange their positions following a specific swapping scheme, which ensures
that the invariant distribution concentrates around the global minima. See Figures 1.(a)-(b) for an
illustration of swapping. Compared with the standard Langevin diffusion, replica exchange accel-
erates the rate of convergence to the invariant distribution. As a result, with replica exchange we
obtain a more accurate solution to the nonconvex optimization problem within a shorter time. It is
worth mentioning that, although in this paper we focuses on the case of swapping two Langevin
diffusions, our theory and method naturally extend to multiple Langevin diffusions.
Our theory quantifies the acceleration effect of replica exchange from two perspectives. First, we use
the theory of Markov semigroup, particularly the Dirichlet form, to characterize the evolution of the
χ2-divergence between the distribution at time t and the invariant distribution. In specific, we show
that, compared with the standard Langevin diffusion, replica exchange boosts the Dirichlet form
with a nonnegative term, which results in a faster decay of the χ2-divergence. Further combined
with the Poincare inequality, We establish the exponential rate of convergence of the X2-divergence
to zero, where the acceleration effect of replica exchange is characterized by the PoinCare constant.
We illustrate such an acceleration effect in Figure 1.(c). Second, we use the large deviation principle
(LDP) to characterize the exponential decay of the probability that the empirical measure of the
sample path deviates from the invariant distribution. In particular, we show that replica exchange
boosts the LDP rate function, which implies a faster exponential decay rate. See Figure 1.(d) for
an illustration. Both perspectives are built on the infinitesimal generator of the replica exchange
Langevin diffusion. We show that essentially the acceleration effects are the consequences of an
additional term in the infinitesimal generator, which is introduced by replica exchange. In addition
to quantifying the acceleration effect of replica exchange, we use the Euler scheme to discretize the
replica exchange Langevin diffusion and propose a discrete-time algorithm. We establish an upper
bound of the discretization error via GrOnWall's inequality. We also discuss several issues related
to the parameters of the replica exchange Langevin diffusion, especially the swapping intensity and
temperatures. We defer these discussions to §A of the appendix.
Related Work: The idea of nonconvex optimization via diffusion process dates back to simu-
lated annealing (Cerny, 1985) and is systematically studied in Chiang etal. (1987). For the ap-
plication of the Langevin diffusion in nonconvex optimization, see, for example, Gidas (1985)
and Geman & Hwang (1986) and the followup works. More recently, Dalalyan & Tsybakov
(2009); Bubeck et al. (2015); Dalalyan (2017) analyze the nonasymptotic rate of convergence of
the Langevin diffusion for strongly convex objective functions. Moreover, Durmus et al. (2017);
Zhang et al. (2017); Raginsky et al. (2017); Xu et al. (2018) further extend the analysis to handle
nonconvexity and stochastic gradient. See also, for example, Belloni et al. (2015); Ge et al. (2015);
Hazan et al. (2016); Cheng et al. (2017); Zou et al. (2018b;a; 2019) for related works on the exten-
sions of the Langevin diffusion and other diffusions. However, all these works focus on the setting
with a single temperature. In comparison, we study the acceleration effect of replica exchange,
which utilizes more than one temperature. Hence, our work is orthogonal to these existing works
and can potentially be applied to accelerate other diffusion processes.
2
Published as a conference paper at ICLR 2019
(a)
(b)
Figure 1: An illustration of the replica exchange Langevin diffusion. In (a) we illustrate the diffusion process
driven by the low temperature, which locally exploits the geometry. The orange dashed lines characterize the
evolution of the standard Langevin diffusion, while the blue dashed line denotes the swap, which drives the
diffusion process into the neighborhood of another local minimum. In (b) we illustrate the trajectories of a
pair of diffusion processes driven by two temperatures. The orange and yellow lines correspond to the low
and high temperatures, respectively. The black lines are the contours of the objective function. Note that
the lines of the same colors are disjoint due to the swap, which is denoted by the red dashed line. In (c) we
illustrate the evolution of the χ2-divergence. The upper and lower blue curves correspond to diffusion processes
with zero and positive swapping intensities, respectively. The two solid red arrows denote the derivatives of
the χ2-divergence, and the angle between them characterizes the acceleration effect. In (d) we illustrate the
concentration of the empirical measures. The horizontal plane denotes the space of measures, whose center is π,
that is, the stationary distribution of the replica exchange Langevin diffusion. The yellow and blue surfaces that
center at π characterize the probability densities of the empirical measures, corresponding to zero and positive
swapping intensities, respectively. Compared with the blue surface, the yellow one is more concentrated around
π, which also characterizes the acceleration effect of swapping.
In a parallel line of works, the idea of replica exchange is studied in the context of parallel tem-
pering Markov chain Monte Carlo for sampling from a multimodal distribution. See, for ex-
ample, Earl & Deem (2005); Sindhikara et al. (2008) and the references therein. More recently,
Woodard et al. (2009) study the mixing time of parallel tempering, while Dupuis et al. (2012) ex-
tend the swapping rate of replica exchange to infinity and establish the corresponding LDP. In addi-
tion, another well-studied method is simulated tempering, a technique similar to replica exchange,
which also aims at accelerating the convergence of diffusion processes (Marinari & Parisi, 1992;
Geyer & Thompson, 1995). The main difference between replica exchange and simulated temper-
ing is that the former tracks multiple diffusion processes driven by various temperatures and accel-
erates the convergence by swapping, while the latter tracks only one diffusion process but treats the
temperature as a stochastic process. See, for example, Zheng (2003) and the references therein for
a detailed discussion on the difference. More recently, Ge et al. (2017) study the convergence of
simulating tempering for nonconvex objective functions from the perspective of mixing time, which
is also orthogonal to our work. The LDP techniques in our work may potentially be applied to the
analysis of simulated tempering as well.
Main Contribution: Despite the broad application in sampling, to the best of our knowledge, this
paper is the first attempt to apply the replica exchange Langevin diffusion in the context of noncon-
vex optimization. In summary, our contribution is twofold: (i) We quantify the acceleration effect
of the replica exchange Langevin diffusion from two perspectives, that is, the convergence of the
χ2-divergence and the LDP for empirical measures. (ii) We propose a nonconvex optimization algo-
rithm based on the discretization of the replica exchange Langevin diffusion and establish an upper
bound for the discretization error.
2 Basic Idea
We consider the following unconstrained optimization problem,
minimize U (x).
x∈Rd
(2.1)
3
Published as a conference paper at ICLR 2019
When U (x) is nonconvex, it is difficult to obtain its global minima. A commonly used algorithm is
the Langevin diffusion, which is defined by the stochastic differential equation
d Xt = -NU (Xt )d t + √2T d Wt.	(2.2)
Here {Wt }t≥0 is a standard d-dimensional Brownian motion and τ > 0 is the temperature pa-
rameter. Under mild regularity conditions, the Langevin diffusion {Xt }t≥0 has a unique invariant
distribution that is absolutely continuous with respect to the Lebesgue measure with density
e-U (方 x)/
πτ (X) = RRd e-(X"τdX.
(2.3)
Here JR& e-U(XX)Tdx is the normalization constant. In particular, ∏τ is the limiting distribution
of {Xt}t≥0, which means that with any initialization X0, the distribution of Xt converges to πτ
(Bakry et al., 2013). We observe from (2.3) that with τ → 0 the probability measure πτ concentrates
around the global minima of U(X) (Hwang, 1980). In other words, if we choose a sufficiently small
temperature parameter τ and run the Langevin diffusion in (2.2) for a sufficiently long time, we
expect to obtain a solution that falls into the neighborhood of a global minimum of U(X) with high
probability.
Here the temperature parameter τ plays a crucial role. In practice, we can only run the Langevin
diffusion for a finite time, giving rise to a tradeoff between “global exploration” and “local exploita-
tion”, which correspond to high and low temperatures. In specific, when the temperature parameter
τ is small, the convergence of Xt is slow and the particle can be trapped by a local minimum for
a long time without globally exploring the whole domain. Consequently, within a finite time, we
can only obtain a sample from a distribution that is far away from the invariant distribution πτ . In
contrast, when the temperature parameter τ is large, the convergence is accelerated due to better
global exploration. The distribution of Xt converges faster to the invariant distribution πτ globally,
but locally πτ is less concentrated around the global minima of U (X).
To bridge the gap between high and low temperatures, in this paper we study an adaptive algorithm
called replica exchange Langevin diffusion. In detail, we consider a pair of particles driven by two
Langevin diffusions as defined in (2.2) with temperatures τ1 < τ2, respectively. We use Zt =
(Zt(1),Zt(2))
to denote the positions of the two particles at time t. In other words, we have
d Z(I) = -NU (Z(I))d t + √2T1 d Wt(1),	d Z(2) = -NU (z(2))d t + √2T2d Wt(2).	(2.4)
According to (2.3), the invariant distribution of {Zt}t≥0 is absolutely continuous with respect to the
Lebesgue measure on R2d and its density is proportional to
μ(x 1 ,x2) = exp(—U(xι)/τι - U(X2)∕τ2).	(2.5)
The marginal invariant distribution of the low-temperature particle concentrates around the global
minima of U (x). Hence, the low-temperature particle is of particular interest for the purpose of
nonconvex optimization. The key idea of replica exchange is to enable the low-temperature particle
to achieve better global exploration by swapping its position with the high-temperature particle. In
specific, at time t and positions (x1, x2), the two particles swap with rate
/	、 μ(μ μ(x 2,x C	CQ
a ∙ s(x 1, x2) = a ∙ 1 ∧ -------r ,	(2.6)
∖	μ(x 1 ,x2) )
which means
P(Zt+dt = (X2,x 1) I Zt = (X1 ,x2)) = a ∙ S(X1 ,x2)dt,
P(Zt+dt = (x 1 ,x2) I Zt = (x 1 ,x2)) = 1 - a ∙ s(x 1 ,x2)dt.	(2.7)
Here a ≥	0 is	a	constant called swapping intensity. As is shown in Lemma 3.2, the	specific form of
s(x1, x2)	in (2.6) ensures that for any a, the invariant distribution of the replica exchange	Langevin
diffusion {Zt }t≥0 is the same as (2.5), that is, as if the two particles are independent. Correspond-
ing to the continuous-time process in (2.4)-(2.6), in §3.4 of the appendix we consider the replica
4
Published as a conference paper at ICLR 2019
exchange stochastic gradient descent algorithm, which corresponds to the discretization of {Zt}t≥0
using Euler scheme.
To better understand the intuition behind replica exchange, note that we use two particles driven
by low and high temperatures to achieve “local exploitation” and “global exploration”, respectively.
For the purpose of optimization, we only need to track the trajectory of the first particle. By plugging
(2.5) in (2.6), we obtain
a ∙ S(xι, x2) = a ∙ exp(0 ∧ (1 /τι — 1 /τ2) ∙ (U(x 1) — U(x2))) .	(2.8)
Since τι < T2, the rate a ∙ S(x 1 ,x2) is monotone increasing with respect to the difference between
the objective values at x1 and x2, which denote the positions of the two particles. Hence, the two
particles are more likely to swap when the first one has a larger objective value. In other words,
swapping tends to move the first particle, which we are interested in, to a position corresponding to
a lower objective value. An extreme case of the replica exchange Langevin diffusion is τ1 = 0 and
τ2 = ∞. In this case, the first equation in (2.4) reduces to an ordinary differential equation character-
ing the deterministic gradient descent, while the second one in (2.4) corresponds to an approximated
uniform exploration of the whole domain Rd. According to (2.8), the particles never swap if the
objective value of the first particle is smaller than the second. Hence, roughly speaking, the replica
exchange Langevin diffusion reduces to the deterministic gradient descent with uniformly random-
ized restarts. In contrast to this extreme case, for 0 < τ1 < τ2 < ∞, the second particle globally
explores the whole domain more adaptively with not only noise but also gradient information. In
particular, its stationary distribution has a larger density around the local minima, which leads to
better restarts that adapt to the global geometry for the first particle.
3	Theoretical Analysis
In this section, we lay out the theoretical analysis of replica exchange Langevin diffusion introduced
in §2, which demonstrates the acceleration effect of swapping. Due to space constraint, we defer the
necessary background and detailed proofs to §B and §C of the appendix, respectively. Throughout
the following analysis, We assume that the objective function U (∙) satisfies the following assumption.
Assumption 3.1 (Smoothness andDissipativity). The function U (∙) is L-smooth, that is, there exists
a positive constant L such that for all x, y ∈ Rd
IlWU(X7U(y)∣∣ ≤ Lkx - yk.	(3.1)
The function U(∙) is also (α, β)-dissipative, that is, there exist positive constants a and β such that
for all x ∈ Rd
x, WU (x) ≥ akxk2 — β.	(3.2)
The assumption on smoothness in (3.1) characterizes the Lipschitz continuity of the gradient of
objective function, which is commonly used in the optimization literature (Nesterov, 2013). The as-
sumption on dissipativity in (3.2), roughly speaking, characterizes the approximate quadratic growth
of the objective function at infinity, which is commonly used in the control and dynamic system lit-
erature (Hale, 2010). This condition is also used in Raginsky et al. (2017). It is worth noting that
our theory does not require the convexity assumption.
3.1	Invariance and Reversibility
In this section, we show that the invariant distribution of the replica exchange Langevin diffusion
{Zt }t≥0 has the form in (2.5) rigorously, whose first component preserves the concentration. We
also show the reversibility of {Zt }t≥0, which is a nice property necessary for the subsequent con-
vergence analysis. We consider the replica exchange Langevin diffusion {Zt}t≥0 defined by (2.4)-
(2.6), where Zt = (Zt(1) , Zt(2) ) denotes the positions of the two particles at time t, and a ≥ 0 is
5
Published as a conference paper at ICLR 2019
the swapping intensity that controls the frequency of swapping. The following auxiliary lemma
characterizes the invariant distribution of {Zt}t≥0 and its reversibility. Restricted to the space, we
provide a detailed proof in §C.1 of the appendix.
Lemma 3.2. The infinitesimal generator of {Zt }t≥0 with swapping intensity a, which is defined in
(2.4)-(2.6), takes the form
L a ff ( X1,X 2)) = —" X1 f ( X1 ,x 2), Nx 1 U ( X1))+ T ι∆ X if ( X1 ,X 2)
|---------------------{z-------------------}
L1a f(X1,X2)
(3.3)
-(Nx2 f (X1 ,x2), Nx2U(X2)〉+ T2∆x2 f (X1 ,x2)+ a ∙ S(xι,x2) ∙ ff (x2,x 1) - f (x 1 ,x2)).
|
}|
}
z
z
L2a f(X1,X2)	Lsa f(X1, X2)
Moreover, {Zt}t≥0 is reversible and its invariant distribution π has density
dπ(X1, X2) H μ(X1, X2)dX 1dX2
(3.4)
with respect to the LebesgUe measure on R2d, where μ(X1 ,x2) is defined in (2.5).
In Lemma 3.2, the first two terms L1a and L2a on the right-hand side of (3.3) correspond to the
standard Langevin diffusion, while the last term Lsa arises from swapping. The replica exchange
Langevin diffusion {Zt}t≥0 defined in (2.4)-(2.6) is ergodic, which means that, with any initial-
ization, the distribution of Zt converges to the invariant distribution π. There are two perspectives
to characterize the convergence of the Markov process {Zt}t≥0: (i) the χ2-divergence between the
distribution of Zt and the invariant distribution π, and (ii) the convergence of the empirical measure
of {Zt }t≥0, which is viewed as a random element in the space of measures. In the following, we
quantify the convergence of {Zt}t≥0 from both perspectives. In §3.2, We use Poincare inequality
to quantify (i), while in §3.3, we apply the large deviation principle (LDP) to characterize (ii). In
particular, we show that the term Lsa in (3.3) plays a crucial role in accelerating the convergence.
3.2	CONVERGENCE IN χ2 -DIVERGENCE
Let μt be the distribution of the replica exchange Langevin diffusion {Zt}t≥0 at time t, and ∏ be
its invariant distribution. In the following, we quantify the discrepancy between μt and π using the
χ2 -divergence, which is defined as
X2(μt Hπ ) = / (dμt -1) d∏
where dμt/d∏ is the Radon-Nikodym derivative between μt and ∏. In the following, we characterize
the evolution of X2(μt ∣∣ π) along time t using the Dirichlet form, which is defined as
Ea(f) =
Γa(f)dπ,
where Γa(f ) = 1 /2 ∙ (La(f2) - 2fLa(f)).
(3.5)
Here Γa is called Carre du Champ operator and recall that we use ∏ and La to denote the invariant
distribution and infinitesimal generator of {Zt}t≥0, respectively. In other words, the Dirichlet form
is defined as the integration of the Carre du Champ operator under the invariant distribution ∏.
To characterize the evolution of the X2-divergence, we take the derivative of X 2( μt ∣∣ ∏) with respect
to time t. Recall that μt is the distribution of Zt, and by (B.2) in the appendix the corresponding
semigroup {Pt}t≥0 is defined as Pt(f (x)) = E[f (Zt) ∣ Z0 = x]. By setting f as dμ0/dπ and the
definition of conditional expectation, we have dμt/dπ = Pt (dμ0/dπ), which implies
dtχ Xg ∣π ) = dt∕
Pt
2dπ=2ZPt
• ddt∖Pt
dπ
(3.6)
6
Published as a conference paper at ICLR 2019
where the last equation follows from the definition of the infinitesimal generator in Definition B.2
in the appendix. Meanwhile, by Definition B.3 in the appendix and the invariance of π, we have
R L a (f2)dπ = 0, which together with (3.5) implies
Ea(f) = -	fLa(f)dπ.
(3.7)
Combining (3.6) and (3.7) we obtain
ddtχ2(μt H ∏) = - 2Ea
(3.8)
which shows that the derivative of the X2-divergence between μt and the invariant distribution ∏ is
exactly negative twice the Dirichlet form of the Radon-Nykodim derivative dμt /dπ. In the following
theorem, we show that a larger swapping intensity a boosts the Dirichlet form and thus accelerates
the convergence. Recall that, as defined in (3.5), Ea is the Dirichlet form of the replica exchange
Langevin diffusion {Zt}t≥0 with swapping intensity a.
Theorem 3.3.	For any fixed function f, Ea (f) is an increasing nonnegative function with respect
to a. In particular, we have
Ea(f) = / 卜 1 ∙ IlPxιf(x 1 ,x2)∣∣2 + T2 ∙ IlRx2f(x 1 ,x2)∣∣2)dπ(x 1 ,x2)
|----------------------------------{z-------------------------}
E0(f)
+ / a/2 ∙ S(x 1 ,x2) ∙ (f (x2,x 1)- f (x 1 ,x2))2dπ(x 1 ,x2),
|-------------------------{z-----------------------}
Acceleration Effect
(3.9)
where the both terms on the right-hand side are nonnegative.
See §C.2 of the appendix for a detailed proof of Theorem 3.3. Combined with (3.8), Theorem 3.3
shows that swapping accelerates the evolution of X2(μt ∣∣ ∏). In particular, the Dirichlet form Ea on
the right-hand side of (3.8) decomposes into two terms. The first term E0 in (3.9) corresponds to the
replica exchange Langevin diffusion without swapping, that is, a = 0. More specifically, the two
nonnegative terms in E0 characterize the individual dynamics of the two particles, respectively. In
particular, larger temperatures τ1 and τ2 yield a larger E0, which implies a faster rate of convergence.
Meanwhile, as shown in the proof of Theorem 3.3, the specific form of swapping in (2.7) ensures
the nonnegativity of the second term in (3.9), which further boosts the Dirichlet form and leads to
faster evolution of X2(μt ∣∣ π) in (3.8). It is worth mentioning that Theorem 3.3 does not rely on
Assumption 3.3 and holds for all objective functions U(∙).
To better understand Theorem 3.3, note that the symmetry of f, which corresponds to
dμt/d∏(x 1, x2) in (3.8), plays a crucial role in the acceleration effect. In specific, when
dμt/dπ(x 1, x2) is asymmetric, the second term of the Dirichlet form in (3.9) is positive. Other-
wise when dμt/dπ(x 1, x2) is symmetric, the second term in (3.9) vanishes, since dμt/dπ(x 1 ,x2)—
dμt/d∏(x2, x 1) = 0 for all x 1 and x2. In other words, the acceleration effect degenerates due to
symmetry. Intuitively, at time t the two particles are equivalent and swapping does not change their
joint distribution, and hence does not affect the convergence of X2(μt ∣∣ ∏).
Based on (3.8), we further establish the exponential convergence of X2(μt ∣∣ ∏). The key ingredient
is the Poincare inequality (Bakry et al., 2013). Furthermore, we show that such an exponential rate
of convergence is dictated by the constant in the POinCare inequality, which is called the Poincare
constant. In particular, we show how the swapping intensity a affects the Poincare constant and
accelerates the exponential convergence.
For a Markov process, the Poincare inequality states that the X2-divergence between any probabil-
ity measure and its invariant distribution is uniformly upper bounded by the Dirichlet form of the
Radon-Nykodim derivative, provided that the probability measure of interest is absolutely continu-
ous with respect to the invariant distribution. In specific, we say that {Zt}t≥0 satisfies the Poincare
7
Published as a conference paper at ICLR 2019
inequality with POinCare constant K, if for all probability measures V《π, the following inequality
holds,
X2( V i π) ≤K ∙ Ea 偌
(3.10)
Note that the POinCare inequality is specified by the invariant distribution ∏ and the Dirichlet form
Ea.
When the POinCare inequality in (3.10) holds, the derivative of the X2-divergence in (3.8) is upper
bounded by itself, which implies the exponential rate of convergence. In particular, we have
dχ2(μt Il ∏) ≤ — 2K-1 ∙ χ2(μt Il π), which yields X2(μt ∣∣ π) ≤ χ2(μ0 ∣∣ π) ∙ e-2t/K.	(3.11)
Establishing the Poincare inequality is highly nontrivial. However, for the replica exchange
Langevin diffusion, the following theorem shows that Poincare inequality holds under the Smooth-
ness and dissipativity conditions in Assumption 3.1, which implies (3.11).
Theorem 3.4.	Under Assumption 3.1, the replica exchange Langevin diffusion specified in (2.4)-
(2.6) satisfies the POinCare inequality in (3.10). Hence, the second inequality in (3.11) holds, which
implies the exponential decay of χ2-divergence.
The proof of Theorem 3.4 adapts from the proof in Bakry et al. (2008), where a standard Langevin
diffusion with unique driving temperature is considered. See §C.3 of the appendix for a detailed
proof.
3.3 Large Deviation Principle (LDP) Analysis
We focus on the empirical measure of the replica exchange Langevin diffusion {Zt}t≥0 defined in
(2.4)-(2.6), which is in the same spirit of Polyak averaging (Polyak & Juditsky, 1992) but replaces
the iterates with Dirac measures. In specific, for any fixed time T > 0, the empirical measure of
{Zt}t≥0 is defined as
νT
1T
T 0o δZtdt,
(3.12)
where δZt denotes the Dirac measure at Zt. Note that {νT}T ≥0 is a sequence of random measures,
which are random elements of P(R2d), that is, the space of probability measures on R2d. We equip
P(R2d) with the topology of weak convergence, which enables us to define open and closed sets of
P(R2d).
Recall that Lemma 3.2 shows that the replica exchange Langevin diffusion {Zt }t≥0 is reversible.
This fact enables us to apply the Donsker-Varadhan theory (Donsker & Varadhan, 1975), which
implies that {Zt }t≥0 obeys LDP. Formally, we have the following theorem.
Theorem 3.5.	The sequence of empirical measures {νT }T ≥0 of the replica exchange Langevin
diffusion {Zt}t≥0 defined in (3.12) obeys LDP. That is to say, for all open sets O and closed sets F
in P(R2d), the following inequalities hold,
liminf ɪ log P(VT	∈ O)	≥ — inf Ia (V),	limsup ɪ log P(VT	∈ F)	≤ — inf Ia (V).
T→∞ T	ν∈O	T→∞ T	ν∈F
Here Ia (∙) : P(R2d) → [0, ∞] is the rate function, which takes the form
Ia(V) = JT1 ∙ IlNx 1 PdV∕dπ(x 1, X2)『+ T2 ∙ iiNx2pd v/d π (x 1 ,x 2) ∣∣2d π (x 1 ,x 2)
|
}
{	-
I0(ν)
+ J a/2 ∙ S(xι, x2) ∙ (Pdν/dπ(X2, X1) — pdν/dπ(x 1, x2))2dπ(x 1, x2)	(3.13)
|
、	{
Acceleration Effect
for all ν	π, and Ia(ν) = ∞ otherwise.
}
8
Published as a conference paper at ICLR 2019
See § C.5 of the appendix for a detailed proof of theorem 3.5. The LDP rate function I a (∙) in
Theorem 3.5 characterizes the rate of convergence for the empirical measures {νT }T≥0 towards
its population version, which is the invariance distribution of {Zt }t≥0 . More specific, it quantifies
the exponential rate of decay of the probability that empirical empirical measures {νT }T ≥0 deviate
from the invariant distribution π. Recall that, under weak topology, P(R2d) is metrizable via the
Levy-Prokhorov metric dlp(∙, ∙) (Billingsley, 2013). We use Br to denote the open ball centered at
∏ with radius r in the metric space (P(R2d), dlp). Then Br is a closed set and Br is open. Then
according to Theorem 3.5, we have
liminf ɪ logP(dlp(VT, μ) > r) = liminf ɪ logP(VT ∈ B；) ≥ — inf I(V),
τ→∞ Tb L lpv 1'^j j t→∞ Tb T 1 "一 ν∈Br
limsup ɪ logP(dlp(VT, μ) ≥ r) = limsup ɪ logP(VT ∈ Br) ≤ — inf I(V).
T→∞ T	T→∞ T	ν∈Brc
If We ignore the slight difference between Br and Br, when T is large, the probability
P(dlp(VT, μ) ≥ r) has approximated scale of exp(-Tinfν∈Bc I(V)). That is to say, infν∈Bc I(V)
characterizes the exponential rate of decay of the probability P(dlp(VT, μ) ≥ r) as T goes to infin-
ity. A larger rate function implies a faster exponential rate of decay. Note that LDP includes both
upper and lower bounds in Theorem 3.5 and hence, the exponential rate of convergence character-
ized by LDP is tight.
To see how swapping accelerates the convergence of the empirical measure towards its invariant
distribution, note that the LDP rate function in (3.13) decomposes into two terms. The first term
corresponds to the LDP rate function of replica exchange Langevin diffusion without swapping,
that is, a = 0. In specific, it is the sum of two nonnegative terms, which characterize the individual
dynamics of the two particles, respectively. Meanwhile, the second term in (3.13) is nonnegative and
boosts the LDP rate function, which accelerates the convergence of the empirical measure. Similar
to the convergence of the χ2-divergence in Theorem 3.3, a larger swapping intensity a yields a more
significant acceleration effect. The acceleration effect also degenerates when the Radon-Nykodim
derivative dv/dπ is symmetric. Finally, it is worth noting that, like Theorem 3.3, Theorem 3.5 does
not rely on Assumption 3.3 and holds for all objective functions U(∙). In summary, Theorems 3.3
and 3.5 together justify the benefit of swapping from two different perspectives.
Note that the LDP rate function given in Theorem 3.5 takes a different form compared with the
one obtained in Dupuis et al. (2012). Despite the different the forms, the two results are not contra-
dictory. Our formula is derived from the Donsker-Varadhan theory, which uses the assumption of
reversibility, while theirs is obtained from a dual formulation of the LDP rate function. Moreover,
one can show that they are equivalent.
3.4 Discretization Error Analysis
In this section, we lay out the discretization error analysis of replica exchange Langevin diffusion.
Our previous discussion in §3.2 and §3.3 focuses on the continuous-time process {Zt}t≥0 defined in
(2.4)-(2.6), which needs to be discretized in practice. However, swapping the positions of particles
makes it hard to analyze the discretization error, since there is no way to incorporate the swapping
of positions into one unified stochastic differential equation. To overcome this difficulty, note that
the two particles in the replica exchange Langevin diffusion swap their positions with a specific rate,
which is equivalent in distribution to swapping their temperatures with the same rate (Dupuis et al.,
2012). We name the later equivalent process as the temperature swapping Langevin diffusion. With
a slight abuse of notations, we still use {Zt}t≥0 to denote the positions of the two particles in the
temperature swapping Langevin diffusion. In specific, {Zt}t≥0 is characterized by the following
stochastic differential equation,
d Z = -VU (Zt )d t + Σ t d Wt.	(3.14)
Here Σt is a random matrix that switches between the diagonal matrices diag{√2τ1 ∙ Id, √2τ2 ∙ Id}
and diag{√2τ2 ∙ Id, √2τ1 ∙ Id}, where Id denotes the d-dimensional identity matrix. The matrix Σt
9
Published as a conference paper at ICLR 2019
characterizes the switching of temperatures, and the rate of switching is same as the one specified
in (2.6) and (2.7). Note that the temperature swapping Langevin diffusion in (3.14) is equivalent
to the replica exchange Langevin diffusion defined in (2.4)-(2.6) in distribution. Furthermore, the
stochastic differential equation in (3.14) enables us to define a continuous-time interpolation of the
discrete-time sequence, which is useful in the discretization error analysis. Hence, for the purpose of
optimization, we only need to discretize and analyze the temperature swapping Langevin diffusion
in (3.14).
Note that (3.14) defines a Markov jump diffusion, which can be discretized using the Euler scheme.
We denote by (Z(1) (k), Z(2) (k)) and (τ (1) (k), τ(2) (k)) the positions and temperatures of the two
particles at discrete time k, respectively. Let (Z(1) (0), Z(2) (0)) = Z0 and (τ (1) (0), τ(2) (0)) =
(τ1 , τ2 ) be the initialization. For all integers k ≥ 0, we update the positions of the two particles
sequentially as following,
Z(()(k +1) = Z(i)(k) -η∙ NU(Z(i)(k)) + ,2η∙ Wi)(k) ∙ξ(i)(k),i = 1,2	(3.15)
and swap temperatures according to the following rule,
(T(1)(k + 1),τ(2)(k + 1)) = (T(2)(k),τ(1)(k)) with probability a ∙ η ∙ s(Z(1)(k), Z(2)(k)),
(3.16)
(τ(1)(k + 1),τ(2)(k + 1)) = (τ(1)(k),τ(2)(k)) with probability 1 一 a ∙ η ∙ S(Z(1)(k), Z(2)(k)).
Here {ξ (1)(k)}k≥0 and {ξ (2)(k)}k≥0 are two sequences of independent and identically distributed
d-dimensional Gaussian random vectors, η > 0 is the stepsize, while a and S(∙, ∙) are specified in
(2.6). Note that η and a are chosen such that η ∙ a < 1 in order to define a valid probability.
Hereafter we denote by {Zη(k)}k≥0 the iterates of the algorithm specified in (3.15) and (3.16). We
use the superscript η to emphasize that the iterates depend on the stepsize η. Let {Ztη}t≥0 be the
continuous-time interpolation of {Zη(k)}k≥1, which is a continuous-time stochastic process defined
as
Z = Z0 -kU("/ηcη)dS + ks∕ηcηd%
(3.17)
where Σkη = diag{∙vz2τ(1)(k) ∙ Id, ∙vz2τ(2)(k) ∙ Id}. Then for all integers k ≥ 0 and t = kη, We
have Ztη = Zkηη = Zη (k).
In the following theorem, we characterize the discretization error by the mean squared error between
the continuous-time temperature swapping Langevin diffusion in (3.14) and the continuous-time
interpolation in (3.17) of the discrete-time algorithm in (3.15) and (3.16). In specific, we consider a
fixed time interval [0, T] and upper bound the mean squared error E[kZt - Ztη k2] for all t ∈ [0, T].
The following theorem shows that this error grows linearly with respect to the stepsize η.
Theorem 3.6. Under Assumption 3.1, there exists a constant γ(d, T1, T2, a, L, α, β, T) that only
depends on the dimension d, temperature parameters T1 and T2, swapping intensity a, smoothness
constant L and dissipative constants (a, β) of U(∙), and length of the time interval T, such that for
all t ∈ [0, T],
E[kZt - Ztk2] ≤ γ(d,τι,τ2,a, L, α,β,T) ∙ η,
provided that the stepsize η satisfies 0 < η < a/L2 .
The proof of Theorem 3.6 adapts from the proof framework of Theorem 5.13 in Yin & Zhu (2010).
We defer the detailed proof to §C of the appendix.
References
Dominique Bakry, Franck Barthe, Patrick Cattiaux, and Arnaud Guillin. A simple proof of the
Poincare inequality for a large class of probability measures. Electronic Communications in
Probability,13:60-66, 2008.
10
Published as a conference paper at ICLR 2019
Dominique Bakry, Ivan Gentil, and Michel Ledoux. Analysis and geometry of Markov diffusion
operators, volume 348. Springer, 2013.
Alexandre Belloni, Tengyuan Liang, Hariharan Narayanan, and Alexander Rakhlin. Escaping the
local minima via simulated annealing: Optimization of approximately convex functions. In Con-
ference on Learning Theory, pp. 240-265, 2015.
Patrick Billingsley. Convergence of probability measures. Wiley, 2013.
Sebastien Bubeck, Ronen Eldan, and Joseph Lehec. Sampling from a log-concave distribution with
projected Langevin Monte Carlo. arXiv preprint arXiv:1507.02564, 2015.
⅛
viadim´r Cerny. Thermodynamical approach to the traveling salesman problem: An efficient simu-
lation algorithm. Journal of optimization theory and applications, 45(1):41-51, 1985.
Xiang Cheng, Niladri S Chatterji, Peter L Bartlett, and Michael I Jordan. Underdamped Langevin
MCMC: A non-asymptotic analysis. arXiv preprint arXiv:1707.03663, 2017.
Tzuu-Shuh Chiang, Chii-Ruey Hwang, and Shuenn Jyi Sheu. Diffusion for global optimization in
Rn. SIAM Journal on Control and Optimization, 25(3):737-753, 1987.
Arnak Dalalyan and Alexandre B Tsybakov. Sparse regression learning by aggregation and Langevin
Monte Carlo. arXiv preprint arXiv:0903.1223, 2009.
Arnak S Dalalyan. Theoretical guarantees for approximate sampling from smooth and log-concave
densities. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 79(3):
651-676, 2017.
Monroe D Donsker and SR Srinivasa Varadhan. Asymptotic evaluation of certain Markov process
expectations for large time. Communications on Pure and Applied Mathematics, 28(1):1-47,
1975.
Sever Silvestru Dragomir. Some Gronwall-type inequalities and applications. Nova Science Pub-
lishers, 2003.
Paul Dupuis, Yufei Liu, Nuria Plattner, and Jimmie D Doll. On the infinite swapping limit for
parallel tempering. Multiscale Modeling & Simulation, 10(3):986-1022, 2012.
Alain Durmus, Eric Moulines, et al. Nonasymptotic convergence analysis for the unadjusted
Langevin algorithm. The Annals of Applied Probability, 27(3):1551-1587, 2017.
David J Earl and Michael W Deem. Parallel tempering: Theory, applications, and new perspectives.
Physical Chemistry Chemical Physics, 7(23):3910-3916, 2005.
Rong Ge, Furong Huang, Chi Jin, and Yang Yuan. Escaping from saddle points— online stochastic
gradient for tensor decomposition. In Conference on Learning Theory, pp. 797-842, 2015.
Rong Ge, Holden Lee, and Andrej Risteski. Beyond log-concavity: Provable guarantees for sam-
pling multimodal distributions using simulated tempering Langevin Monte Carlo. arXiv preprint
arXiv:1710.02736, 2017.
Stuart Geman and Chii-Ruey Hwang. Diffusions for global optimization. SIAM Journal on Control
and Optimization, 24(5):1031-1043, 1986.
Charles J Geyer and Elizabeth A Thompson. Annealing Markov chain Monte Carlo with applica-
tions to ancestral inference. Journal of the American Statistical Association, 90(431):909-920,
1995.
Basilis Gidas. Global optimization via the Langevin equation. In 24th IEEE Conference on Decision
and Control, 1985, volume 24, pp. 774-778. IEEE, 1985.
11
Published as a conference paper at ICLR 2019
Jack K Hale. Asymptotic behavior of dissipative systems. Number 25. American Mathematical
Society, 2010.
Elad Hazan, Kfir Yehuda Levy, and Shai Shalev-Shwartz. On graduated optimization for stochastic
non-convex problems. In International Conference on Machine Learning, pp. 1833-1841, 2016.
Chii-Ruey Hwang. Laplace’s method revisited: Weak convergence of probability measures. The
Annals of Probability, pp. 1177-1182, 1980.
Nitish Shirish Keskar, Dheevatsa Mudigere, Jorge Nocedal, Mikhail Smelyanskiy, and Ping Tak Pe-
ter Tang. On large-batch training for deep learning: Generalization gap and sharp minima. arXiv
preprint arXiv:1609.04836, 2016.
Enzo Marinari and Giorgio Parisi. Simulated tempering: a new Monte Carlo scheme. EPL (Euro-
physics Letters), 19(6):451, 1992.
Yurii Nesterov. Introductory lectures on convex optimization: A basic course, volume 87. Springer,
2013.
Ralph Saul Phillips and Einar Hille. Functional analysis and semi-groups. RI, 1957.
Boris T Polyak and Anatoli B Juditsky. Acceleration of stochastic approximation by averaging.
SIAM Journal on Control and Optimization, 30(4):838-855, 1992.
Maxim Raginsky, Alexander Rakhlin, and Matus Telgarsky. Non-convex learning via stochastic
gradient Langevin dynamics: A nonasymptotic analysis. arXiv preprint arXiv:1702.03849, 2017.
Daniel Revuz and Marc Yor. Continuous martingales and Brownian motion, volume 293. Springer,
2013.
Daniel Sindhikara, Yilin Meng, and Adrian E Roitberg. Exchange frequency in replica exchange
molecular dynamics. The Journal of chemical physics, 128(2):01B609, 2008.
Dawn B Woodard, Scott C Schmidler, Mark Huber, et al. Conditions for rapid mixing of parallel
and simulated tempering on multimodal distributions. The Annals of Applied Probability, 19(2):
617-640, 2009.
Pan Xu, Jinghui Chen, Difan Zou, and Quanquan Gu. Global convergence of langevin dynamics
based algorithms for nonconvex optimization. In Advances in Neural Information Processing
Systems, pp. 3126-3137, 2018.
George Yin and Chao Zhu. Hybrid switching diffusions: Properties and applications, volume 63.
Springer, 2010.
Chiyuan Zhang, Qianli Liao, Alexander Rakhlin, Brando Miranda, Noah Golowich, and Tomaso
Poggio. Theory of deep learning iib: Optimization properties of sgd. arXiv preprint
arXiv:1801.02254, 2018.
Yuchen Zhang, Percy Liang, and Moses Charikar. A hitting time analysis of stochastic gradient
Langevin dynamics. arXiv preprint arXiv:1702.05575, 2017.
Zhongrong Zheng. On swapping and simulated tempering algorithms. Stochastic Processes and
their Applications, 104(1):131-154, 2003.
Difan Zou, Pan Xu, and Quanquan Gu. Stochastic variance-reduced hamilton monte carlo methods.
arXiv preprint arXiv:1802.04791, 2018a.
Difan Zou, Pan Xu, and Quanquan Gu. Subsampled stochastic variance-reduced gradient langevin
dynamics. In International Conference on Uncertainty in Artificial Intelligence, 2018b.
Difan Zou, Pan Xu, and Quanquan Gu. Sampling from non-log-concave distributions via variance-
reduced gradient langevin dynamics. In International Conference on Artificial Intelligence and
Statistics, 2019.
12
Published as a conference paper at ICLR 2019
A	Discussion and Conclusion
In this paper, we apply the idea of replica exchange to the Langevin diffusion in the context of
nonconvex optimization. In particular, we quantify the benefits of replica exchange compared with
the standard Langevin diffusion from two perspectives, that is, the convergence of the χ2-divergence
and the LDP of the empirical measures. We show from both perspectives that replica exchange
accelerates the convergence towards the invariant distribution. In the following, we discuss several
related issues.
Flat and sharp minima: The Langevin diffusion yields an invariant distribution that concentrates
around the global minima. In particular, as illustrated in Keskar et al. (2016), flat minima generally
achieves better generalization than sharp ones. Meanwhile, as observed in Zhang et al. (2018), the
invariant distribution of the Langevin diffusion biases more towards the flat minima than the sharp
minima. Intuitively, this observation follows from locally integrating the density of the invariant
distribution, which is proportional to exp {-U (x ”丁 }. As specified in (2.3), the invariant distribution
of the replica exchange Langevin diffusion takes the same form, and hence processes the same
desired property of biasing towards the flat minima.
Choice of swapping intensity: Recall that in §3 we prove that swapping accelerates the exponen-
tial rate of convergence of the χ2-divergence and increases the LDP rate function of the empirical
measures. In particular, a large swapping intensity a leads to a stronger acceleration effect. In con-
tinuous time, the swapping intensity a should be as large as possible. However, in discrete time, to
ensure the existence of a valid swapping probability in (3.16), a can only be as large as 1 /η, since by
(2.6) we have S ( ∙, ∙ ) ≤ 1. This constraint characterizes the tradeoff between the acceleration effect
and the discretization effort, since more fine-grained discretization with a smaller stepsize η allows
for a larger swapping intensity a. Moreover, intuitively speaking, more frequent swapping makes
the particles more volatile, which lowers the accuracy of discretization.
Choice of temperatures: In the replica exchange Langevin diffusion, we use two particles driven
by low and high temperatures to achieve “local exploitation” and “global exploration”, respectively.
There is a fundamental tradeoff in the choice of the temperatures, especially the high temperature.
In specific, a larger τ2 results in faster global exploration. However, if τ2 is too large, by the second
equation in (2.4), the gradient term NU(∙) becomes negligible compared with the white noise term
√2τ2dWt. Consequently, the second particle “blindly” explores the whole domain Rd uniformly at
random, without adapting the geometry of the objective function. As discussed in §2, most swaps
happen only when better positions with smaller objective values are discovered by the second parti-
cle. Thus, if τ2 is too large, the global exploration is fast but ineffective.
B	Background
In this section, we provide the background of Markov process, which is necessary for the theoretical
analysis. We analyze the properties of Markov processes from the viewpoint of Markov semigroup.
A semigroup is a family of linear operators on Banach space C(Rd), the space of bounded continuous
functions on Rd equipped with the uniform norm. Formally, we have the following definition.
Definition B.1 (Semigroup of Operators). A family {Pt}t≥0 of linear operators on C(Rd) is called
a semigroup if and only if it satisfies the following conditions:
(1)	For t = 0, we have Pt = I, which is the identical mapping on C(Rd).
(2)	The map t → Pt is continuous in the sense that, for all f ∈ C(Rd), t → Pt(f) is a
continuous map from R+ to C(Rd).
(3)	For all f ∈ C(Rd) and s, t > 0, we have Ps+t(f) = Ps(Pt(f)).
13
Published as a conference paper at ICLR 2019
Moreover, a semigroup of operators is Markov if and only if the following additional conditions are
satisfied:
(4)	For all t > 0, we have Pt(1) = 1, where 1 is the constant function with value one.
(5)	For all f ≥ 0, we have Pt(f) ≥ 0.
Recall that a Markov process on Rd is a stochastic process {Xt }t≥0 satisfying
P(Xt ∈ Γ I Fs) = P(Xt ∈ Γ I Xs)	(B.1)
for all measurable sets Γ and times s < t. Here Fs = σ(Xu, u ≤ s), which is the natural filtration
of the Markov process {Xt}t≥0. Given a Markov process {Xt}t≥0, we define a family of operators
{Pt}t≥0 on C(Rd), the space of bounded continuous functions on Rd, as follows
Pt(f(x) =Ef(Xt)IX0 =x.	(B.2)
According to the Markov property in (B.1), we have
Pt+s(f) =Pt(Ps(f))	(B.3)
and hence, {Pt}t≥0 indeed forms a semigroup. We call {Pt}t≥0 the Markov semigroup associated
with the Markov process {Xt }t≥0 .
Given a Markov semigroup, we can define its infinitesimal generator, a linear operator that describes
the Markov semigroup’s behavior for an infinitesimal t. Formally, we have the following definition.
See, e.g., Revuz & Yor (2013) for more details.
Definition B.2 (Infinitesimal Generator of Markov Semigroup). The infinitesimal generator L of a
Markov semigroup {Pt}t≥0 is defined by
OG P	Pt (f) — f
L ( f) = lim-----------
t→0	t
for all f ∈ D(L). Here D(L) denotes the subset of C(Rd) such that the above limit exists.
Intuitively, the infinitesimal generator can be viewed as the derivative of the Markov semigroup at
time t = 0. It uniquely determines the Markov semigroup according to the semigroup property
(B.3). In the following, we define the invariant and reversible measure with respect to a Markov
semigroup.
Definition B.3 (Invariance and Reversibility). For a Markov semigroup {Pt }t≥0 whose infinitesi-
mal generator is L, a probability measure π is invariant with respect to {Pt }t≥0 if and only if
L(f)dπ=0
for all t ≥ 0 and f ∈ C(Rd). A probability measure π is reversible with respect to {Pt}t≥0 if and
only if
fL(g)dπ =	gL (f)dπ
for all f, g ∈ D(L). Note that reversibility implies invariance when we plug g = 1 into the
definition of reversibility.
We remark that the standard definitions of invariance and reversibility are based on the Markov
semigroup {Pt}t≥0 instead of its infinitesimal generator L, which is equivalent to the following
definition. The definitions via infinitesimal generator simplify the proof of our lemmas and theo-
rems.
14
Published as a conference paper at ICLR 2019
Definition B.4 (Equivalent Definitions of Invariance and Reversibility ). For a Markov semigroup
{Pt}t≥0, a probability measure π is invariant with respect to {Pt}t≥0 if and only if
Ptfdπ =	fdπ
for every t ≥ 0 and f ∈ C(Rd). Reversibility is another important concept in Markov semigroup
theory. A probability measure μ is reversible for {Pt}t≥0 if and only if
f Ptgdπ =	gPtf dπ
for all t ≥ 0 and f, g ∈ C(Rd). Based on the Definition B.2, we can show that this definition is
equivalent to Definition B.3.
In the definitions of Markov semigroup and associated concepts, we restrict the test function f to
C(Rd), the space of bounded continuous functions. However, for π being the invariant distribution
with respect to {Pt}t≥0, we can always (slightly) extend the definition of Markov semigroup to a
larger function space L2 (∏). We use {P5tt}t≥0 and L to denote the corresponding extended Markov
semigroup and infinitesimal generator. One can show that, when ∏ is reversible, L is a self-adjoint
operator in the Hilbert space L2(π), which is equipped with the inner product hf, giπ = fgdπ.
Furthermore, one can show that L is positive semidefinite. In this paper, for the convenience of
discussion, We do not distinguish the slight difference between L and its extension L, and also
the difference of D(L), C(Rd), and L2 (π), since C(Rd) is dense in L2(π) and D(L) is dense in
C(Rd) according to Hille-Yosida theorem (Phillips & Hille, 1957). When we choose a test function,
we also assume that all the related operations are well-defined.
C Detailed Proofs
In this section, we present the detailed proofs for all the theorems and lemmas in this paper.
C.1 Proof of Lemma 3.2
Proof. The dynamics in (2.4)-(2.6) defines a Langevin diffusion with jump. Its generator takes the
form
L a ff ( x 1, x 2)) = —0X ιf( x 1 ,x 2), Rx 1 U ( xi)〉+ T ι∆ X ιf( X1, X 2)
|
}
{	{z	"
L1a(f(x1,x2)
Sx 2 f (x 1 ,x 2), Rx 2 U (X 2))+ T2∆ x 2 f (x 1 ,x 2) + a ∙ S ( x 1 ,x 2) ∙ ff ( x 2 ,x 1) - f (x 1 ,x 2))
|
}|
}
{z
L2a f(x1, x2)
7	-
Lsa f(x1,x2)
(C.1)
and its domain D(La) = Cc2 (R2d), which is the space of all twice-differentiable functions with
compact support. The first two terms L1a and L2a on the right-hand side of (C.1) correspond to the
standard Langevin diffusion, while the last term Lsa arises from swapping. To prove invariance and
reversibility, by Definition B.3, we only need to show that
RdRdg(x1,x2)La f(x1,x2) dπ(x1, x2)
RdRdf(x1,x2)La(g(x1,x2)dπ(x1,x2)	(C.2)
for all f, g ∈ D(La), where π is defined in (3.4).
15
Published as a conference paper at ICLR 2019
Note that for the Laplacian term in L1a on the right-hand side of (C.1), by integration by parts and
the fact that f and g have compact support, we have that for all fixed x2 ∈ Rd,
—/d g(X1 ,x2)exp(-U(x]/Tι)∆x 1 f (x 1 ,x2)dxι
(C.3)
=J d ^x X1 [g ( X1 ,x 2)exp(—U (x]∕τ 1)], PXιf( X1 ,X 2))d X1
=/ d Dexp (—U (x]/T1)RX1 g (x 1 ,x 2) — exp(—U (x]/T1) g (x 1 ,x 2) N x、U (x 1), Xχf( x 1 ,x 2)〉d x 1
Recall that μ(x 1 ,x2) is defined in (2.5). Hence, (C.3) takes the equivalent form
/
Rd
g (x 1 ,x 2) L1 (f (x 1, X 2)) μ (x 1 ,x 2 )d x 1
—	xX1f(x1,
Rd
x 2), RXI g (x 1 ,x 2)μ (x 1 ,x 2)d x 1,
and hence,
g(x 1, x2)La f(x 1 ,x2))μ(x 1, x2)dx 1dX2
	
,∖χ if (x 1 ,x 2), Nx 1 g (x 1 ,x 2) )μ (x 1 ,x 2)d X 1d X 2 ∙
(C.4)
By switching the positions of f and g in (C.4), we have
Uf (x 1 ,x 2) L1 (g (x 1 ,x 2)) μ (X1, X 2)d X 1d X 2
U] RX1 g (x 1 ,x 2), NxJ (x 1 ,x 2)〉μ (x 1 ,x 2)d x 1d X 2 ∙
(C.5)
By (C.4) and (C.5) we have
Ug (x 1 ,x 2) LIa (f (x 1, x 2)) μ (x 1 ,x 2)d x 1d X 2
Uf (x 1 ,x 2) LIa (g (x 1 ,x 2)) μ (x 1 ,x 2)d x 1d X 2.
(C.6)
By the same derivation, (C.6) also holds for L2a . Thus, it remains to prove that (C.6) holds for
Lsa as well. For notational simplicity, in the following we use f+ and f- to denote f(x1, x2) and
f (x2, x 1) respectively, and define g+, g-, μ+, and μ- in a similar way. Then We have
g +(1 ∧ (μ-∕μ +))(f- — f +)μ +dX 1dX2
/ /	g+μ-(f- — f+)dx 1dx2 + f f	g+μ +(f- — f+ )dx 1dX2
J {{(X1 ,x2)：μ- ≤μ+ }	J J{(X1 ,x2)：μ- >μ+}
g g	g+μ-(f- - f +)dX 1dX2 + i /	g-μ-(f+ — f-)dX2dX1
J {{(x 1 ,x2)：μ- ≤μ+ }	J {{(x 1 ,x2)：μ+ >μ-}
=//	μ- (g+f - + g-f+ — g+f+ — g-f - )d x 1d X 2,
{ {{(x 1 ,x2)：μ- ≤μ十}
where the third equality follows from symmetry. Similar to (C.7), we also have
(C.7)
f + (1 ∧ (μ-/μ +)) (g- - g+)μ+dX 1dX2
/ /	μ-(f+g- + f-g+ — f+g+ — f-g-)dX1 dX2.
{ { { ( X1 ,x 2)： μ-<μ 十}
Combining (C.7) and (C.8), we obtain
(C.8)
	
g +(1 ∧ (μ-∕μ +))(f- — f +)μ+dx 1 dX2
f + (1 ∧ (μ-/μ +))(g- — g+)μ+dx 1dX2,
16
Published as a conference paper at ICLR 2019
which is equivalent to
Ug(N1 ,x2)Ls (f(x 1 ,x2))μ(X1 ,x2)dxidX2 =	f f (X1 ,x2)Ls (g(X1 ,x2))μ(X1 ,x2)dXidX2
Rd Rd
by the definition of Lss in (C.1). In summary, we obtain that (C.2) holds for π defined in
(3.4). Thus, {Zt}t≥o is a reversible Markov process with the invariant distribution dπ(X1 ,x2) 8
exp(-U (X 1)∕τ1 — U (X 2)∕τ2)d X 1d X 2.	□
C.2 Proof of Theorem 3.3
Proof. Recall the infinitesimal generator of the replica exchange Langevin diffusion with swapping
intensity a defined in (3.3). According to the properties of V and ∆, for i = 1, 2, We have
PxifI2 ( X1 ,X 2) = 2 f ( X1 ,X 2) ∙Vχif( X1 ,X 2)
∆xif2(X1 ,X2) = 2f (X1 ,X2) ∙ ∆xif(X1 ,X2) + 2∣∣Vxif (X1 ,x2)∣∣2.
Then by the definition of the Carre du Champ operator Γα in (3.5), we have
Γa(f(x 1 ,x2)) = 1 /2 ∙L(f(x 1 ,x2)2) — f(x 1 ,x2) ∙ La(f(x 1 ,x2))
=T1 ∙ Il Vx 1 f (X1 ,X2)∣∣2 + T2 ∙ Il Vx2 f (X1 ,X2)∣∣2 + a/2 ∙ S(x 1 ,x2) ∙ (f (x2,x 1) — f (X1 ,x2))2.
Hence, the Dirichlet form E a is given by
Ea(f) = / 卜 1 ∙ ∣iVx 1 f (x 1 ,x2)||2 + T2 ∙ IVx2f(x 1 ,x2)『)d∏(x 1 ,x2)
+ / a/2 ∙ s(x 1 ,x2) ∙ (f (x2,x 1) — f (x 1 ,x2))2d∏(X1 ,x2),
which concludes the proof of Theorem 3.3.	□
C.3 Proof of Theorem 3.4
Proof. Note that the replica exchange Langevin diffusion without swapping, that is, a = 0, shares
the same invariant distribution in (2.5) with the ones with swapping, that is, a > 0. Furthermore,
Theorem 3.3 shows that Ea (f) ≥ E0 (f) for all a > 0. Hence it remains to show that the replica
exchange Langevin diffusion without swapping satisfies the POinCare inequality in (3.10).
Recall that the replica exchange Langevin diffusion without swapping is defined as
d Z(I) = —VU (Z(1))d t + √2T1d ^t(1),	d Z(2) = —VU (Z(2))d t + √2T2d ^t(2),	(C.9)
and its infinitesimal generator is given by
L0(f (x 1 ,x2)) = 一(Vx 1 f (x 1 ,x2), Vx 1U(x 1)) + τ 1 ∙ ∆x 1 f (x 1 ,x2)
—〈Vx2 f (x 1 ,x2), Rx2 U(x2)) + τ2 ∙ ∆x2 f (χ 1 ,x2).	(C.10)
The Poincare inequality for the replica exchange Langevin diffusion in (C.9) is a direct consequence
of the existence of a Lyapunov function. In the specific, we have the following lemma, which is
adapted from Theorem 1.4 in Bakry et al. (2008).
Lemma C.1 (Lyapunov implies Poincare). Let {Zt}t≥0 be the replica exchange Langevin diffusion
without swapping on R2d, whose infinitesimal generator is L0 defined in (C.10). We further assume
that there exists a function V (x1, x2) ≥ 1, and constants λ > 0, b ≥ 0, and r > 0 such that
L0(V(χ 1 ,χ2)) ≤ —λ ∙ V(χ 1 ,χ2) + b ∙ 1 Br(χ 1 ,χ2),	(C.11)
where 1Br denotes the indicator function of the centered ball with radius r in R2d. Then {Zt}t≥0
satisfies the POinCare inequality. We call V(χ 1 ,χ2) the Lyapunov function.
17
Published as a conference paper at ICLR 2019
Proof. We extend the proof of Theorem 1.4 in Bakry et al. (2008), which characterizes the standard
Langevin diffusion with a single temperature, to the setting with two temperatures. For complete-
ness, We provide a detailed proof in §C.4.	□
When the loss function U(x) satisfies the (α, β)-dissipative condition in Assumption 3.1, following
Raginsky et al. (2017), We construct the folloWing Lyapunov function
V(x 1 ,x2) = exp{α/4 ∙ (Xi∣∣2/τι + ∣∣x21∣2/2)}.
A direct calculation shoWs that V(x1, x2) satisfies the condition in (C.11). Hence, We apply Lemma
C.1 to obtain that the replica exchange Langevin diffusion without swapping satisfies the Poincare
inequality. In summary, we prove that the Poincare inequality holds for the replica exchange
Langevin diffusion, which concludes the proof.	□
C.4 Proof of Lemma C.1
Proof. We first prove the POinCare inequality in a more general form. For all functions f (xi ,x2):
R2d → R, we show that if there exists a function V(x1, x2) ≥ 1 such that (C.11) holds, then there
exists a constant ρ such that
Varπ (f) ≤ ρ ∙	τ1
Il ^xιf( X1 ,X 2 )∣∣2 + T2 ∙ Il Nx 2 f ( X1 ,X 2)∣∣2) ∙ d ∏ ( X1 ,X 2),
where τ1 and τ2 are the temperatures, and π(x1, x2) is the invariant distribution. By setting the
function f as the Radon-Nykodim derivative dν/d∏, we obtain the Poincare inequality for the X2-
divergence in (3.10). Note that for all constants u ∈ R, we have
Varπ (f) ≤
(f(X1, X2) -u)2 ∙ dπ(X1, X2),
where Varπ (f) denotes the variance of f(X1, X2) when (X1, X2) follows the invariant distribution
π. We use fu to denote the function f - U. By multiplying fU(x 1 ,x2)/(λV(x 1 ,x2)) on the both
sides of (C.11) and integrating them over π(X1, X2), we have
fu(x1,x2)2 ∙ dπ(x1, x2) ≤
-L0(V(x1,x2))(λV(x1, x2)) ∙ fu(x1,x2)2 ∙ dπ(x1, x2)
+ b ∙ 1Br(x1,x2)(λV(x1,x2)) ∙ fu(x1, x2)2 ∙ dπ(x1, x2).
(C.12)
In the sequel, we upper bound the two terms on the right-hand side of (C.12).
For the first term on the right-hand side of (C.12), we invoke the divergence theorem, which states
that for a scalar-valued function g, whose value at infinity is zero, and a vector-valued function h,
for the integration under the measure ω we have
(hNg, hi + g ∙ div h)dω =	div(g ∙ h)dω = 0.
(C.13)
In (C.13), by setting dω as the Lebesgue measure dx1dx2 and
g = exp(-U(x 1)∕τ 1 - U(x2)∕τ2) and h = fu(x 1 ,x2)2∕(λV(X1 ,x2)) ∙ W(x 1 ,x2),
we have
-L0(V(x1, x2))∕(λV(x1,x2)) ∙ fu(x1,x2)2 ∙ dπ(x1, x2)
= τ1∕λ∙ DNx1 fu(x1, x2)2∕V(x1, x2), Nx1V(x1,x2)E ∙ dπ(x1, x2)
+ τ2∕λ∙ DNx2 fu(x1, x2)2∕V(x1, x2), Nx2V(x1, x2)E ∙ dπ(x1, x2).	(C.14)
18
Published as a conference paper at ICLR 2019
Meanwhile, for the first term on the right-hand side of (C.14) we have
[fu2(X1 ,X2)/V(X1 ,X2)], Rx 1 V(X1 ,X2))∙ d∏(X1 ,X2)
∣ (∣∣Nxιfu(X1 ,X2)∣∣2 - ∣∣NxIfU(X1 ,X2) - (fu(X1 ,X2)/V(X1 ,X2)) ∙ Nx 1V(X1 ,X2)∣∣2) ∙d∏(x 1 ,x2)
≤ ∣ ∣∣ Nx 1 fu (X1 ,X 2)∣∣2 ∙ d ∏ (X1 ,X 2),
(C.15)
where the first equality follows from expanding the gradient of fu2(X1, X2)∕V (X1, X2) with respect
to X1 . By a similar derivation, the same inequality holds for the second term on the right-hand side
of (C.14) as well. Hence, plugging them into (C.15), for the first term on the right-hand side of
(C.12) we have
/ -L0(V(X1 ,X2))/(λV(X1 ,X2)) ∙ fu(X1 ,X2)2 ∙ d∏(X1 ,x2)
≤ 1 /λ ∙
NxIfu ( N1 ,x 2)||2 + T2∣∣ Nx 2 fu ( X1 ,X 2)『)∙ d ∏ ( x 1 ,x 2).
(C.16)
For the second term on the right-hand side of (C.12), we restrict our attention to the bounded domain
Br. Based on the assumption that V (x1, x2) ≥ 1, there exists a positive constant k such that
/ b ∙ 1 Br ( X1 ,X 2)/( λV ( X1 ,X 2)) ∙ fu ( X1 ,X 2)2 ∙ d ∏ ( X1 ,X 2)
≤ b∕λ ∙ / fu(X1 ,X2)2 ∙ d∏(X1 ,X2)
Br
≤ k ./ ∣∣Nfu(X1 ,X2)∣∣2 ∙ d∏(X1 ,X
Br
fu ( X1 ,X 2) ∙ d ∏ ( X1 ,X 2)) / ∏ (Br ),
(C.17)
where the second inequality follows from the Poincare inequality for measures on a bounded domain
(Bakry et al., 2008). Since (C.17) holds for all functions fu(X1, X2), one can choose a suitable U
such that Br fu* dπ = 0. Then we have
/ b ∙ 1 Br (X1 ,X2)/(λV(X1 ,X2)) ∙ fu(X1 ,X2)2 ∙ d∏(X1 ,X2)
≤ k ∙	l∣Nfu* (X1 ,X2)∣∣2∙d∏(X1 ,X2).
Br
(C.18)
Finally, by plugging (C.16) and (C.18) into (C.12), we have that there exists a positive constant ρ
such that
Var式 f) ≤ / fu* (x 1 ,x2)2 ∙ d∏(X1 ,x2)
≤ P ∙ /卜 1∣∣Nx 1 f (X1 ,X2)∣∣2 + T2∣∣Nx2 f (X1 ,X2)∣∣2) ∙ dπ(X1 ,x2),
which concludes the proof of Lemma C.1.
□
C.5 Proof of Theorem 3.5
According to Lemma 3.2, the replica exchange Langevin diffusion {Zt}t≥0 is reversible. Hence, we
can apply the Donsker-Varadhan theory, which states that for a continuous-time reversible Markov
process with invariant distribution π and infinitesimal generator L, LDP holds and its LDP rate
function takes the explicit form
I(ν)
∣∣ √-L (p dν∕dπ )∣∣
∞, otherwise.
if ν π,
(C.19)
19
Published as a conference paper at ICLR 2019
Here √L denotes the square root of -L, which is defined as follows.
Let A be a positive Semidefinite self-adjoint operator in the Hilbert space (H, h∙, )h), the square
root of A is defined as the self-adjoint operator B such that A = B2, which means hx, AxiH =
hx, B2xiH = hBx, BxiH for every x ∈ H. As explained in §B, the infinitesimal generator -L can
be extended to a positive semidefinite self-adjoint operator in the Hilbert space L2(∏). We ignore
the slight differences caused by extension. Hence, 7-L is well-defined here.
Recall that the infinitesimal generator La of the replica exchange Langevin diffusion is given by
(3.3). We first derive the explicit form of ∣∣√-L a (f) ∣∣ ∏. Since the square root of a positive semidef-
inite self-adjoint operator is self-adjoint, we have
Il√-La(f )∣∏ =〈√-La(f), √-La(f )>∏ =(f, √-La2(f )>∏ =(f, -La(f))∏ = -/fLa(f )dπ.
Since π is the invariant distribution, by Definition B.3 we have La (f2)dπ = 0. Then we have
II√-La(f )∣∣∏ = 1 /2 J(La(f 2) - 2fLa(f ))d∏,
which is exactly the Dirichlet form. Then based on (3.3), we obtain
La(f2) - 2fLa(f) = 2Tι ∙ ∣∣Vxι f (xι,x2)∣∣2 + 2T2 ∙ ∣∣Nx。f (x 1 ,x2)∣∣2
+ a ∙ s(x 1 ,x2) ∙ (f (x2,xl) - f (x 1 ,x2))2.
Hence, we have that for probability measures ν π ,
I a (V) = / τ ι∣∣ Vχ ι √d ν∕dπ (x ι ,x 2) ∣∣2 + T2∣∣ V 2 √d ν/d π (x 1 ,x 2) ∣∣2
+ a/2 ∙ S(x 1, x2) ∙ (√dν/dπ(x2, x 1) — √dν/dπ(x 1, x2))2dπ,
(C.20)
and I (ν) = ∞, otherwise.
C.6 Proof of Theorem 3.6
Proof. Recall that the temperature swapping Langevin diffusion {Zt }t≥0 and the continuous-time
interpolated process {Ztη}t≥0 are defined in (3.14) and (3.17). For all t ∈ [0, T], we have
Zt- z? = - /t ( vu (Zs)-vu (Z[s∕ηcη )}d S + [ Bs-NbnCn )d %.
By applying the Cauchy-Schwartz inequality and then taking expectation, we have
E[kZt - Zη∣2] ≤ 2 ∙ E ∣∣[ (VU(Zs) -VU(Zηs∕ηcη))dS∣∣2
+ 2 ∙ E ]∣∣ /t (N s - ς ηs∕ηCη )d MH：
In the sequel, we upper bound the two terms on the right-hand side of (C.21).
For the first term, by Cauchy-Schwarz inequality, we have
E ]∣∣/t (VU(Zs) -VU(Zηs∕ηCη))ds∣∣2
≤ t ∙ E[ /1∣∣VU (Zs)-vu (Zηs∕ηCη )∣2d S
≤ 2L21 ∙(e	Iot	∣Zs	- Zsk2dS	+ E	/'∣∣Zs	- Zbs∕ηcη∣ds	^j,
(C.21)
(C.22)
20
Published as a conference paper at ICLR 2019
where the second inequality follows from the L-smoothness of U(∙) in Assumption 3.1. In the
following, we upper bound the second term on the right-hand side of (C.22). Note that we have
t
E / UZs - Zt∕ηcη∖∖2ds
0
bt^	r(kk+I)η	2 一
≤ ΣE /	U Zη - Zηs∕ηCη∖∖ d S
k=0 kη
(C.23)
For all integers k ≥ 0 and s ∈ [kη, (k + 1)η), based on the definition of {Ztη}t≥0 in (3.17), we have
U Zs - Zη√ηCη∖∖2 = kZη - Zkη k 2 = \\-VU (Ζ% ) ∙ (S- k) + Σ	d Wu ∖ 2 .
By applying the Cauchy-Schwartz inequality again, we obtain
U Zη - Zηs∕ηcηU2 ≤2 ∙U vu( Zll )∖∖2 ∙( S-kn )2+2 .k IIZl d %∖∖2
=2 ∙ UVU(Zkη) - VU(x*)∖∖2 ∙ (S - kη)2 + 2 ∙ ∖∖∑ηη 卜Wu∖∖2,	(C.24)
where x* is a stationary point of U(∙), and by definition VU(x*) = 0. Recall that by Assumption
3.1, U(∙) is L-smooth. Based on (C.24), We have
U ZS - Zηs∕ηCη∖∖2 ≤ 2 L2 ∙kZkη - x*k 2 ∙( S - kn )2 + 2 ∙ ∖∖ς kη ∕η d
≤ 4 L2 ∙ (kZηη k2 + kx*k 2)∙( S - kn )2 + 2 ∙∖∖∑ Ss I! d Wu∖∖2.	(C.25)
By integrating the second inequality in (C.25) over the interval [kn, (k + 1)n] and taking expectation,
then plugging it into the right-hand side of (C.23), we obtain
E
(k+1)η
L	UZS - ZSs/sCs U2dS
kη
≤ 4 L2 ∙
'uUpE[kZSη k 2] + kx*k2) ∙ n3/3 + 2 ∙ [ +1)η E]∖∖∑ηη( d WUUId S. (C.26)
Note that on the right-hand side of (C.26), Σ% is a diagonal matrix with diagonal entries √2τ1 or
√2τ2, then by Ito isometry, We have
2d	s	2
E Σηkη(j)	dWu(j)	≤4dτ2(S-kn),
j=1	kη
where Σkηη(j) denotes the j-th diagonal entry of the matrix Σkηη, and Wu(j) is the j-th component of
the 2d-dimensional Brownian motion Wu . Hence, we have
(k+1)η
kη
E
4dτ2 (S - kn)dS
2dτ2 n2,
(C.27)
which provides an upper bound for the right-hand side of (C.26). Then by plugging (C.27) into
(C.26), we obtain
(k+1)η	2
E /	U ZS - ZSs/sCs U2 d S ≤ 4 L2 ∙ (sup E[ kZSη k 2] + kx*k2)∙ n3 +4 dτ2 n2.
kη	k≥0
(C.28)
Then by plugging (C.28) into (C.23), we have
E /1∖∖Zs - Zη3∕ηCηU2dS ≤ (1 + t/n) ∙(4L2 ∙ (supE[kZSηk2] + ∣∣x*∣∣2\n3 + 4dτ2n2).
(C.29)
The following lemma shows that if the discretization stepsize n falls into the interval (0,α∕L2),
{Zkηη }k≥0 are uniformly upper bounded in the L2 sense.
21
Published as a conference paper at ICLR 2019
Lemma C.2. If 0 < η < a/L2, there exists a constant δι(d, T2,L, α, β), which depends on the
dimension d, the temperature parameter τ2, and the smoothness constant L and dissipative constants
(α, β) of U(∙), such that
supEkZkηηk2 ≤ δ1(d,τ2, L,α,β).
k≥0
Proof. The proof idea is to show that the sequence {E[kZkηηk2]}k≥0 satisfies a contractive inequality
based on the discretization scheme defined in (3.15). See §C.7 for a detailed proof.	□
By applying Lemma C.2 to (C.29), we have that there exists a constant δ2(d, τ2, L, α, β) such that
t
e[/ IlZs - Zfs∕ηcη∣∣2dSl ≤ δ2(d,τ2,L,a,β) ∙ η.
Then based on (C.22), we obtain the following inequality
E ]II( ("U(Zs7U(Zbs∕ηcs))dS∣∣2
IIZs- Zsll2dS + δ2(d,τ2,L,a,β) ∙ ηj,	(C.30)
which establishes an upper bound for the first term on the right-hand side of (C.21).
≤ 2 L21 ∙ E
0
It remains to upper bound the second term on the right-hand side of (C.21). According to Ito isom-
etry, we have
t	2	2d	t
E	II	0 (Σs	-	Σbss∕scsdWsII	=j=1 0E	Σs(j)-Σbss∕scs (j)2	dS
≤X2d dXt∕seZ (k+1)sEh(Σs(j)-Σsks(j)2idS,	(C.31)
j=1 k=0 ks
where Σs(j) and Σkss(j) are the j-th diagonal entries of Σs and Σsks, respectively. Recall that Σs
and Σ s are diagonal matrices with all diagonal entires being √2T∖ or √2τ2. Then for all j, k, and
possible realizations of Σs(j) and Σsks(j), we have
(k+1)s
ks
E (Σs(j) -Σsks(j)2 dS
(kk +1) η
4(√τ2 - √τ2)2 ∙
ks
P Σs(j) 6= Σsks(j) dS. (C.32)
To upper bound the probability on the right-hand side of (C.32), we take the expectation conditioning
Zks , which yields
(k+1)s	(k+1)s
P(Σs(j) 6=Σsks(j)dS=E	P(Σs(j) 6=Σsks(j)ZkssdS
ks	ks
(C.33)
Recall that the rate of swapping is specified in (2.6) and (2.7). The conditional probability on the
right-hand side of (C.33) satisfies
P(∑S(j) = ∑Zn(j) I Zss) = a ∙ s(ZknD,Z^2)) ∙ (s - h1) + o(s - h1),	(C.34)
where ZknI),Zss2 are the first and second components of Zkn, S(∙, ∙) is defined in (2.6), and o(∙)
is the little-o notation, which denotes the higher-order term with respect to s - kη. Hence, by
combining (C.32)-(C.34), we have that there exists a constant δ3(τ1, τ2, a) such that
(k+1)s
ks
E[(∑s (j)- ∑ss (j))2]d S = 4( √T2 - √T2 )2 J:+1) s
(a ∙ (S - kη) + o(S - kη))dS
≤ δ3(τ1,τ2,a) ∙ η2.
22
Published as a conference paper at ICLR 2019
叫 kZt- Z? k 2] ≤ 4 L21 ∙ (/
Then based on (C.31), there exists a constant δ4(d, τ1, τ2, a) such that
E Ilʃ (∑S	-	∑↑s∕ηCη)d^s ||	≤	2d	∙	(dt∕η]	+1)∙	δ3(T1 ,τ2,	a)	∙	η2	≤	δ4(d,τ 1 ,τ[2, a) ∙ t ”
0	(C.35)
Finally, by plugging (C.30) and (C.35) into (C.21), we have
E[kZs - Zsk2]dS + δ2(d,τ2,L,α,β) ∙ η^ +2 ∙ δ4(d,τ1, T2,a) ∙ t ∙ η.
Hence, by applying the GronWall's inequality (Dragomir, 2003), We have that there exists a constant
γ(d, T1, T2, a, L, α, β, T) such that for all t ∈ [0, T],
E[kZt - Zk2] ≤ γ(d,τ 1,τ2,a, L, α,β,T) ∙ η.
In other Words, the mean squared error of discretization groWs linearly With respect to the stepsize
η, which concludes the proof of Theorem 3.6.	□
C.7 Proof of Lemma C.2
Proof. Recall that for all integers k ≥ 0, based on the discretization scheme in (3.15) and (3.16), for
i ∈ {1, 2}, We have
Z(i)(k + 1) = Z(i)(k) - η∙NU (Z(i)(k)) + ^2 η ∙ τ(i)(k) ∙ξ(i)(k),
Where ξ(i)(k) is a standard d-dimensional Gaussian random vector and the temperature T (i)(k)
takes value in {T1, T2}. Also note that by the definition of the continuous-time interpolated pro-
cess {Ztη }t≥0 in (3.17), We have Z(k) = Zkηη . Hence, We have
E[kZsk+1)ηk2] = e[||ZlI- ηWU(Zll)∣∣2i + E[2η ∙ T(I)(k) ∙kξ⑴(k)k2] + E[2η ∙ T(2)(k) ∙kξ⑵(k)k2]
+ 2 ∙ EhZk+1)η - η ∙ ^u(Zrn), qηFη ∙ ξ(k)〉i.	(C∙36)
Since ξ(k) is independent of ZkII and by (3.16) the distribution of T(k) is only determined by ZkII,
the last term on the right-hand side of (C.36) is zero. Moreover, note that each component of T(k)
only takes value in {T1, T2} and T1 < T2. Then by (C.36) We have
E[ kZ Ik +1) η k 2] ≤ e[∣∣ Zkη- n7U (Zsη )∣∣[ +4 dτ1τ2.	(C.37)
Recall that U(∙) is (α, β)-dissipative and L-smooth by Assumption 3.1. Then we have
Eh∣∣ Zsη - n∙^u ( Zsη )∣∣2i = E[ kZsη H 1 - 2 'n, NU ( Zks ))] + 〃2 ∙ E[U NU ( Zks
≤ (1 - 2an + 2η2L2) ∙ E[kZηηk2] + 2ηβ + 2η2L2 ∙隈*k2,
where x^ is a stationary point of U(∙). Hence, based on (C.37), we have
e[∣∣ Z k +1) η∣∣2i ≤ (1 - 2 an + 2 n2 L2) ∙ E[ kZlι k 2] + 2( β + dτ2) n + 2 n2 L2 kx*k2.	(C.38)
Note that when n ∈ (0, a/L2), we have 1 - 2an + 2n2L2 < 1. Hence, according to (C.38), there
exists a constant δ1(d, T2, L, a, β) such that
supE[kZkηηk2] ≤ δ1(d,T2, L,a,β),
k≥0
which concludes the proof of Lemma C.2.	□
23