Table 1: The performance comparison to coreset methods. This table shows the testing accuracies (%) ofdifferent methods on four datasets. ConvNet is used for training and testing. Img/Cls: image(s) per class,Ratio (%): the ratio of condensed images to whole training set.
Table 2: Cross-architecture performance in testing accu-racy (%) for condensed 1 image/class in MNIST.
Table 3: Comparison to DD (Wang et al., Table 4: Neural Architecture Search. Methods are compared2018) in terms of testing accuracy (%). in performance, ranking correlation, time and memory cost.
Table T5: Train/test statistics for USPS, MNIST, FashionMNIST, SVHN, CIFAR10 and CIFAR100 datasets.
Table T6: Cross-activation experiments in accu-				Table T7:	Cross-pooling experiments in accu-		racy (%) for 1 condensed image/class in MNIST.				racy (%) for 1 condensed image/class in MNIST.			significantly different image statistics. The images of the three datasets are reshaped to 32 Ã— 32 RGBsize for standardization. We use the standard splits for training sets and randomly sample 2,000 testimages for each datasets to obtain a balanced evaluation over three datasets. Thus each model istested on a growing test set with 2,000, 4,000 and 6,000 images at the three stages respectively.
Table T8: Cross-normalization experiments in accuracy (%) for 1 condensed image/class in MNIST.
Table T9: Cross-depth performance in accuracy Table T10: Cross-width performance in accuracy(%) for 1 condensed image/class in MNIST.	(%) for 1 condensed image/class in MNIST.
Table T11: Ablation study on different gradient distance metrics. Obviously, the proposed distance metric ismore effective and robust. Euclidean: squared Euclidean distance, Cosine: Cosine distance.
Table T12: The performance comparison to optimal random selection (ORS) and conditional generative ad-versarial networks (cGAN) baselines. This table shows the testing accuracies (%) of different methods on fourdatasets. ConvNet is used for training and testing. Img/Cls: image(s) per class, Ratio (%): the ratio of con-densed images to whole training set. Top 1000, Top 100 and Top 10 means the selected 1000, 100 and 10optimal coresets by ranking their performances.
Table T13: The performance comparison on CIFAR100. This table shows the testing accuracies (%) ofdifferent methods. ConvNet is used for training and testing except that LDt Uses AlexNet. Img/Cls: image(s)per class, Ratio (%): the ratio of condensed images to whole training set.
Table T14: Generalization ability comparison to DD. The 10 condensed images per class are trained withLeNet, and tested on various architectures. It shows that condensed images generated by our method havebetter generalization ability.
Table T15: Time and memory use for training DD and our method in 10 images/class setting.
