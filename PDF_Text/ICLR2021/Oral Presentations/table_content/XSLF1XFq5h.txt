Table 1: ∆Hgt vs ∣∣∆x∣∣ 1 measure obtained by all methods on alldatasets under consideration. Lower is better. The dimensionality ofeach dataset is listed next to their names. e and a indicate results forepistemic (∆errgt) and aleatoric (∆Hgt) uncertainty respectively.
Table 2: ∆logPgt vs ∣∣∆x∣∣ι measure obtained by all methods on all datasets under consideration.
Table 3: Summary of datasets used in our experiments. (*) We use a 7 feature version of COMPAS,however, other versions exist.
Table 4: Network architecture hyperparameters used in all experiments. Depth refers to number ofhidden layers or residual blocks. Latent dimension values marked with a star (*) refer to the secondlevel VAEs for “ground truth” VAEACs.
Table 5: Values of CLUE’s input space similarity Weight λx and uncertainty rejection thresholds usedfor all experiments. Next to each dataset’s name is the the type of uncertainty quantified: standarddeviation (σ) or entropy (H). We report λx upscaled by each dataset’s input dimensionality d.
Table 6: Quantities of informativeness (∆H, higher is better), relevance (dNN-2(xc, D), lower isbetter) and their ratio (壮欢欢 -H D), higher is better) obtained on real data from the LSAT, COMPASand Wine datasets. The numbers in parenthesis indicate dataset dimensionality.
Table 7: Quantities of informativeness (∆H, higher is better), relevance (dNN-2 (xc, D), loweris better) and their ratio (壮欢欢—" D), higher is better) obtained on real data from the Credit andMNIST datasets. The numbers in parenthesis indicate dataset dimensionality.
Table 8: Accuracy (%) of participants on the Tabular main survey broken down by dataset and bycertainty of test points.
