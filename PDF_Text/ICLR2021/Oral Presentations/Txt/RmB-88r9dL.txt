Published as a conference paper at ICLR 2021
VCNet and Functional Targeted Regulariza-
tion For Learning Causal Effects of Continu-
ous Treatments
Lizhen Nie*1, Mao Ye*2, Qiang Liu2, Dan Nicolae1
1Department of Statistics, The University of Chicago
2 Department of Computer Science, University of Texas at Austin
lizhen@statistics.uchicago.edu, my21@cs.utexas.edu,
lqiang@cs.utexas.edu, nicolae@statistics.uchicago.edu
Ab stract
Motivated by the rising abundance of observational data with continuous treat-
ments, we investigate the problem of estimating the average dose-response curve
(ADRF). Available parametric methods are limited in their model space, and previ-
ous attempts in leveraging neural network to enhance model expressiveness relied
on partitioning continuous treatment into blocks and using separate heads for each
block; this however produces in practice discontinuous ADRFs. Therefore, the
question of how to adapt the structure and training of neural network to estimate
ADRFs remains open. This paper makes two important contributions. First, we
propose a novel varying coefficient neural network (VCNet) that improves model
expressiveness while preserving continuity of the estimated ADRF. Second, to
improve finite sample performance, we generalize targeted regularization to obtain
a doubly robust estimator of the whole ADRF curve.
1	Introduction
Continuous treatments arise in many fields, including healthcare, public policy, and economics. With
the widespread accumulation of observational data, estimating the average dose-response function
(ADRF) while correcting for confounders has become an important problem (Hirano & Imbens, 2004;
Imai & Van Dyk, 2004; Kennedy et al., 2017; Fong et al., 2018).
Recently, papers in causal inference (Johansson et al., 2016; Alaa & van der Schaar, 2017; Shalit
et al., 2017; Schwab et al., 2019; Farrell et al., 2018; Shi et al., 2019) have utilized feed forward
neural network for modeling. The success of using neural network model lies in the fact that neural
networks, unlike traditional parametric models, are very flexible in modeling the complex causal
relationship as shown by the universal approximation theorem (Cs句i et al., 2001). Also, unlike
traditional non-parametric models, neural network has been shown to be powerful when dealing with
high-dimensional input (i.e., Masci et al. (2011); Johansson et al. (2016)), which implies its potential
for dealing with high-dimensional confounders.
A successful application of neural network to causal inference requires a specially designed network
structure that distinguishes the treatment variable from other covariates, since otherwise the treatment
information might be lost in the high dimensional latent representation (Shalit et al., 2017). However,
most of the existing network structures are designed for binary treatments and are difficult to
generalize to treatments taking value in continuum. For example, Shalit et al. (2017); Louizos et al.
(2017); Schwab et al. (2019); Shi et al. (2019) used separate prediction heads for the two treatment
options and this structure is not directly applicable for continuous treatments as there is an infinite
number of treatment levels. To deal with a continuous treatment, recent work (Schwab et al., 2019)
proposed a modification called DRNet. DRNet partitions a continuous treatment into blocks and for
each block, trains a separate head, in which the treatment is concatenated into each hidden layer (see
Figure 2). Despite the improvements made by the building block of DRNet, this structure does not
* Equal contribution and corresponding authors.
1
Published as a conference paper at ICLR 2021
Figure 1: Estimated ADRF on testing set from a typical run of VCNet and DRNet. From left to right
panels are results on simulation, IHDP and News dataset. Both VCNet and DRNet are well optimized.
Blue points denote DRNet estimation and red points VCNet. The truth is shown in yellow solid line.
take the continuity of ADRF (Prichard & Gillam, 1971; Schneider et al., 1993; Threlfall & English,
1999) into account, and it produces discontinuous ADRF estimators in practice (see Figure 1).
We propose a new network building block that is able to strengthen the influence of treatment but
also preserve the continuity of ADRF. Under binary treatment, previous neural network models for
treatment effect estimation use separate prediction heads to model the mapping from covariates to
(expected) outcome under different treatment levels. When it comes to the continuous treatment case,
by the continuity of ADRF, this mapping should change continuously with respect to the treatment.
To achieve this, motivated by the varying coefficient model (Hastie & Tibshirani (1993), Fan et al.
(1999), Chiang et al. (2001)), one can allow the weights of the prediction head to be continuous
functions of the treatment. This serves as the first contribution here, called Varying Coefficient
Network (VCNet). In VCNet, once the activation function is continuous, the mapping defined by the
network automatically produces continuous ADRF estimators as shown in Figure 1 but also prevents
the treatment information from being lost in its high dimensional latent representation.
The second contribution of this paper is to generalize targeted regularization (Shi et al., 2019) to obtain
a doubly robust estimator of the whole ADRF curve, which improves finite sample performance.
Targeted regularization was previously used for estimating a scalar quantity (Shi et al., 2019) and it
associates an extra perturbation parameter to the scalar quantity of interest. While adapting itto a finite-
dimensional vector is not difficult, generalization to a curve is far less straightforward. Difficulties
arise from the fact that ADRFs cannot be regularized at each treatment level independently because
the number of possible levels is infinite and, thus, the model complexity cannot be controlled with
the introduction of infinite extra perturbations parameters. Utilizing the continuity (and smoothness)
of ADRF (Schneider et al., 1993; Threlfall & English, 1999), we introduce smoothing to control
model complexity. Its model size increases in a specific manner to balance model complexity and
regularization strength. Moreover, the original targeted regularization in Shi et al. (2019) is not
guaranteed to obtain a doubly robust estimator. By allowing regularization strength to depend on
sample size, we obtain a consistent and doubly robust estimator under mild assumptions. Noticing the
connection between targeted regularization and TMLE (Van Der Laan & Rubin, 2006), a by-product
of this work is that we give the first (to the best of our knowledge) generalization of TMLE to
estimating a function.
We do experiments on both synthetic and semi-synthetic datasets, finding that VCNet and targeted
regularization boost performance independently. Using them jointly consistently achieves state-of-
the-art performance.
Notation We denote the Dirac delta function by δ(∙). We use E to denote expectation, P to denote
population probability measure and we write P(f) = f (z)dP(z). Similarly, we denote Pn as the
empirical measure and we write Pn(f) = f(z)dPn(z). We denote dne as the least integer greater
than or equal to n, and we denote bnc as the greatest integer less than or equal to n. We use τ to denote
Rademacher random variables. We denote Rademacher complexity of a function class F : X → R
as Radn(F) = E (SuPf∈f 11 PZi τ"(Xi)∣). Given two functions fι, f2 : X → R, we define
kf1 - f2k∞ = supx∈X |f1(x) -f2(x)| and kf1 - f2kL2 = Rx∈X (f1(x) -f2(x))2dx1/2. For
a function class F, we define kFk∞ = suPf∈F kfk∞. We denote stochastic boundedness with Op
2
Published as a conference paper at ICLR 2021
Figure 2: Comparison of network structure between DRNet and VCNet.
and convergence in probability with op. Given two random variable Xi and X2, Xi ⊥ X2 denotes
Xi and X2 are independent. We use an N bn to denote that both an/bn and bn/an are bounded.
2	Problem Statement and Background
Suppose we observe an i.i.d sample {(yi, xi, ti)}in=i where (yi, xi, ti) is a realization of random
vector (Y, X, T) with support (Y × X × T). Here X is a vector of covariates, T is a continuous
treatment, and Y is the outcome. Without loss of generality, we assume T = [0, 1]. We want to
estimate the Average Dose Response Function (ADRF)
ψ(t) := E(Y | do(T = t)),
which is the potential expected outcome that would have been observed under treatment level t.
Suppose the conditional density of T given X is π(T | X). Throughout this paper, we make the
following assumptions:
Assumption 1. (a) There exists some constant c > 0 such that π(t | x) ≥ c for all x ∈ X and
t ∈ T. (b) The measured covariate X blocks all backdoor paths of the treatment and outcome.
Remark 1. Assumption (a) implies that treatment is assigned in a way that every subject has some
chance of receiving every treatment level regardless of its covariates, which is a standard assumption
to establish doubly robust estimators. Assumption (b) implies that the casual effect is identifiable, i.e.,
can be estimated using observational data.
3	VCNet: Varying Coefficient Network S tructure
Under Assumption 1, we have
ψ(t) =E[E(Y | X,T =t)].
n
Thus, a naive estimator for ψ IS to obtain an estimator μ of μ, and use ψ(t) = n Ei=I μ(t, Xi)∙ Here
μ(t, x) := E(Y | X = x,T = t) and μ is its estimator. Following Shi et al. (2019), We utilize the
sufficiency of the generalized propensity score π(t | X) for estimating ψ (Hirano & Imbens, 2004):
ψ(t) =E[E(Y | π(t | X),T =t)] .
It indicates that learning π(t | X) helps the removal of noise and distillation of useful information in
X for estimating ψ. Similar to Shi et al. (2019), we add a separate head for estimating π(t | X), and
use the feature Z extracted by it for downstream estimation of μ(t, x) (see Figure 2). Our contribution
here is to propose the varying coefficient structure of the prediction head for μ(t, x), which addresses
difficulties confronting continuous treatment as discussed in the following paragraph.
3.1	The Varying Coefficient Prediction Head
Our aim is to predict μ(t, x) = E(Y | T = t, X = x). A naive method is to train a neural network
which takes (t, x) as input in the first layer and outputs μ(t, x) in the last layer. However, the role of
treatment t is different from that of x and the influence of t might be lost in the high-dimensional
hidden features (Shalit et al., 2017). Aware of this problem, previous work (Schwab et al., 2019)
3
Published as a conference paper at ICLR 2021
divides the range of treatment into blocks, and then use separate prediction heads for each block
(see Figure 2). To further strengthen the influence of treatment t, Schwab et al. (2019) appends t
to each hidden layer. One problem of this structure is that it destroys the continuity of μ by using
different prediction heads for each block of treatment levels. In practice, DRNet indeed produces
discontinuous curve (see Figure 1).
In order to simultaneously emphasize the influence of treatment while preserving the continuity of
ADRF, we propose a varying coefficient neural network (VCNet). In VCNet, the prediction head for
μ is defined as
μNN(t, χ) = fθ(t) (z),
where input z is the feature extracted by the conditional density estimator, and fθ(t) is a (deep) neural
network with parameter θ(t) instead of a fixed θ. It means that the nonlinear function defined by the
neural network depends on the varying treatment level t, and thus we call this structure the varying
coefficient structure (Hastie & Tibshirani, 1993; Fan et al., 1999; Chiang et al., 2001). For example,
if f is an one-hidden-layer ReLU network, we have fθ(t) (z) = PiD=1 ai(t)ReLU(bi(t)>z), where
ai(t) and bi(t) are weights of the neural network, and θ(t) = [(aι(t), bι(t)),…，(a0 (t), bD (t))]>,
Here we use splines to model θ(t). Suppose that θ(t) = [θ1(t), ..., θdθ (t)]> ∈ Rdθ(t), where dθ(t) is
the dimension of θ(t). We have
L
θi(t) = X ai,∙NN(t),
l=1
where {^NN}'=ι are the spline basis and ay's are the coefficients. Thus, we have
a1,1	…	a1,L
θ(t) = AΦ(t) where A =	.	∙..	. and Φ(t)=[夕NN(t),…，夕LN(t)]> .
_ adθ,1 .…adθ,L _
It is worth mentioning that by choosing spline basis of the form I(t0 ≤ t < t1) with different t0, t1,
we recover the structure in Schwab et al. (2019), which has a separate prediction head for each block.
It indicates that DRNet can also be viewed as a special case of VCNet (under a suboptimal choice of
basis functions).
In VCNet, the influence of treatment effect t on the outcome directly enters through parameters
θ(t) of the neural network, which distinguishes treatment from the other covariates and avoids the
treatment information from being lost. Under typical choices of spline basis such as B-spline, once the
activation function is continuous, VCNet will automatically produce continuous ADRF estimators.
3.2	Conditional Density Estimator
Recall that the input feature Z to μNN is extracted by the conditional density estimator for ∏(t | x).
Here we propose a simple network to estimate π , which is a direct generalization of the conditional
probability estimating head in Shi et al. (2019). Notice that t ∈ [0, 1] and the conditional density
π(t | x) is continuous with respect to treatment t for any given x. A continuous function can be
effectively approximated by piecewise linear functions. Thus, we divide [0, 1] equally into B grids,
estimate the conditional density ∏(∙ | x) on the (B + 1) grid points, and the conditional density for
other t’s are calculated via linear interpolation. To be more specific, we define the network πgNrNid as
πgNrNid(x) = softmax(ω2z) ∈ RB+1, where z = fω1 (x).
Here z ∈ Rh is the hidden feature extracted by the network, ω1 is the parameter for the nonlinear
mapping fω1, ω2 ∈ R(B+1)×h, πgNrNid(x) = [πg0r,iNdN(x), ., πgBri,dNN(x)] and πgi,rNidN(x) is the estimated
conditional density of T = i/B given X = x. This structure is analogous to a classification
network by removing the last layer which outputs the class with highest softmax score. Estimation of
conditional density at other t’s given X = x are obtained via linear interpolation:
πNN (t | x) = πgt1ri,dNN(x)+B πgt2ri,dNN(x) - πgt1ri,dNN(x) (t -t1) , where t1 = bBtc, t2 = dBte.
This estimator πNN is continuous with respect to t for any given x and we finally rescale it to yield a
valid density, i.e., πNN(t | x) ≥ 0, ∀t, x and Rt1=0 πNN(t | x)dt = 1, ∀x.
4
Published as a conference paper at ICLR 2021
There are other options to estimate the conditional density. Popular methods include the mixture
density network (Bishop (1994)), the kernel mixture network (Ambrogioni et al. (2017)) and nor-
malizing flows (Rezende & Mohamed (2015), Dinh et al. (2016), Trippe & Turner (2018)). Here
treatment levels are bounded, and thus Gaussian mixtures are not applicable. In current estimator, the
linear interpolation for estimating conditional density on non-grid points can be replaced by kernel
smoothing, which is more computationally intensive due to the calculation of normalizing constant.
Other techniques including smoothness regularization and data normalization (Rothfuss et al. (2019))
can be implemented to further enhance the performance. However, density estimation is not the
main focus of this paper. Thus, for simplicity, in all experiments we use the aforementioned method
without other techniques and it works quite well on datasets we tried.
3.3	Training
Notice that our model requires ∏nn to extract good latent features Z as the input for μNN to predict.
This can be achieved by training πNN to estimate the conditional density, which motivates us to train
πNN and μNN simultaneously by minimizing the following loss:
nn
L[μNN,πNN]=	£®-〃。出, Xi))2 - -X log(∏NN (ti I xi)).	(1)
n i=1	n i=1
In loss (1), the first term measures the prediction loss from μNN. The second term measures the loss
from πNN and is the negative log likelihood. And α controls the relative weights of the two losses.
Denote μ, π as the optimal solution of the above empirical risk minimization problem (1). After
getting μ, one can estimate ψ(∙) by ψ(∙) = 1 pn=1 μ(∙, Xi). The correctness of this naive estimator
relies on whether the truth μ is in the function space defined by the neural network model. However,
we can plug μ and ∏ into the non-parametric estimating equation (to be introduced later) to obtain
a doubly robust estimator of ψ(t). In this way, we are able to produce an (asymptotically) correct
estimator if any one of μ or ∏ is in the model space of neural network. The next section discusses
challenges in obtaining such a doubly robust estimator and provides our solution.
4	Functional Targeted Regularization
In this section we improve upon the previous method by utilizing semiparametric theory on doubly
robust estimators. Doubly robust estimators are built upon ∏(t ∣ x) and μ(t, x), and it yields a
consistent estimator for ψ even if one of them is inconsistent. When both ∏(t ∣ x) and μ(t, x) are
consistent, a doubly robust estimator leads to faster rates of convergence. Here our task is to estimate
the whole ADRF curve, which comes with additional challenges. First, we need to find a doubly
robust estimator of ψ(t0) for any t0 ∈ [0, 1].
4.1	Doubly Robust Estimator
Before we proceed, we define the following quantity:
ZtO (Y X, T, ∏, μ, ψ) = qto (Y X,T, μ, ∏) + μ(to, X) - ψ(to),
Y - μ(T, X)
∏(T I X)
where qt° (Y, X,T,μ,∏) = δ(T — t0)
The following theorem serves as the basis for our subsequent estimators:
Theorem 1. Under assumption 1 and assume that π(t ∣ x) ≥ c > 0 for all X ∈ X and t ∈ T. For
any t0 ∈ T, ζt0 is the efficient influence function for ψ(t0). Moreover, ζt0 is doubly robust in the
sense that
PZtO (Y, X,τ,∏,μ,ψ)=0
if either π = π or μ = μ. Further, if ∣∣π — ∏k∞ = Op (rι(n)) and ∣∣μ — μk∞ = Op(r2(n)), we
have
SUp IPZto(Y,X,τ,∏,μ,Ψ)I =Op(r1(n)r2(n)).
tO∈T
5
Published as a conference paper at ICLR 2021
Theorem 1 shows that for any to ∈ T, P (qt0 (Y, X, T, μ, ∏) + μ(to, X)) is a doubly robust estimator
for ψ(t0). Under some mild assumptions, one way to obtain a doubly robust estimator of ψ is to
utilize the two-stage procedure from Kennedy et al. (2017) by regressing
Yn-.(TX) fx ∏(T I χ)dPn(χ) + μ(τ, X)	⑵
on T using any nonparametric regression methods like kernel regression or spline regression.
4.2	Targeted Regularization for Inferring a Finite Dimensional Quantity
However, as discussed in Shi et al. (2019), When estimating the term P (qt0 (Y, X, T, μ, π)), the
Π(T ∣ X) in the denominator might make the finite sample estimator unstable, especially in
cases where Assumption 1(a) is nearly violated. Targeted regularization is proposed by Shi et al.
(2019) to solve this issue. The key intuition of targeted regularization is to learn μ and ∏ such that
P (qto (Y, X, T, μ, ∏)) ≈ 0 and thus the estimation of this term is no more needed. In the binary
treatment case where T = {0, 1}, if we want to estimate ψ(1), which is a single quantity, targeted
regularization simultaneously optimizes over μNN, πNN and an extra scalar perturbation parameter e
using the following loss
Ltr*, πNN, e] = L[μNN, πNN]+ βRTR*, ∏NN, e],	⑶
where RTR及NNiNN.e] = 1 X (y，一 μNN(ti, Xi) - e NN ti -ʌ ),
n i=1	πNN(1 | xi)
with L[μNN, πNN] defined in (1). Assume the complexity of the function space of μNN and πNN is
finite and since the complexity of the function space of the introduced perturbation e is also finite, we
have
1∂
P [qι (Y, X,T, μTR, ∏)] = P [qι (Y X, T, μTR, ∏)] + q%RTR[μ, ∏, e] ∣e=^
=(P - Pn) (qι(Y, X, T, μ, ∏) - ^δ(T - to)∕∏2(T I X)) = Op(1),
where ∕^tr (t, x) := μ(t, x)+e∏(jχ) and (μ, ∏, ^) is the minimizer of (3). Notice thatthe first equality
holds because at the convergence of the optimization, ~dRtr [μ, ∏, e] ∣e=^= 0. And the last equality is
by uniform concentration inequality. This implies that n Pn=ι μτR(1, x) isa doubly robust estimator
for ψ(1) and for this estimator, no conditional density estimator presents at denominator and thus it
has more stable finite sample performance.
4.3	Functional Targeted Regularization for Inferring the Whole ADRF
Notice that in loss (3), the scalar e is associated with a scalar quantity for inference. One can
generalize targeted regularization to estimate a d dimensional vector by using d separate e’s (see
Theorem 3 in the Appendix). Generalizing to a curve, however, is more challenging. We need to
optimize over a function e : T → R where e(∙) is the perturbation associated with ψ(∙). Optimizing
over the function space of all mappings from Tto R is not feasible in practice, and its high complexity
will lead to overfitting.
Our solution is to utilize the smoothness of μ and π (Prichard & Gillam, 1971; Schneider et al.,
1993; Threlfall & English, 1999), which allows us to use splines {夕k}e with Kn basis functions
to approximate e(∙). Here the subscript n in Kn denotes that the number of basis functions might
change with the sample size n. Define en(∙) = PK=I αk夕k(∙). We use the following loss with
Functional Targeted Regularization (FTR).
LFTR[μNN, ∏NN, en] = L[μNN, ΠNN ]+ βnRFTR[μNN, ∏NN, en ]	(4)
where RftrWnn, ∏NN, en] = 1 X (y - μNN(ti, Xi) - -NNnʃt?、).
n i=1	π	(ti I xi)
Here RFTR denotes the FTR term and βn → 0 when n → ∞.
6
Published as a conference paper at ICLR 2021
Remark 2 (On βn). The targeted regularization proposed by Shi et al. (2019) uses a fixed β.
However, using fixed β might lead to the estimator constructed by targeted regularization no more
consistent when μNN is mis-sPecfied, which means the estimator is no more doubly robust. To
overcome this issue, we make a slight change on β by allowing β to depend on n. Specifically, we
find that once βn = o(1), we are able to make sure that targeted regularization gives doubly robust
estimator. See discussion at Remark 4 and APPendix A.1 for more details.
Demonstrating the asymptotic correctness of FTR is more challenging than analyzing traditional
targeted regularization. One reason is that We no more have 今RTR[μ, ∏, e] ∣e=^= 0. With some
additional efforts, we will establish convergence rate for our estimator using loss (4) in Theorem 2.
Before We proceed, let us pause a bit and introduce some definitions, Which Will be used in the main
theorem. Denote μ, ∏ and ^n as the minimizer of (4). We use ∏ and μ to denote fixed functions to
which π and μ converge in the sense that ∣∣π 一 ∏k∞ = Op(1) and ∣∣μ 一 μk∞ = Op(1). We define
gt : X → R, x → μNN(x, t). We denote G, Q, U as the function space in which gt, μNN, πnn lies.
We denote BKn as the closed linear span of basis φKn = {夕k}Knr.
The key intuition of the asymptotic correctness of FTR is that: once πNN and π are uniformly
upper/lower bounded and some other weak regularization conditions hold, we can show that
k^n(∙) 一 e*(∙)∣∣L2 = Op(1) where e*(∙) := E [(Y - μ)/∏ | T = ∙] /E [π-2 | T = ∙]. And thus
letting Aftr := μ + ^n∕π, we have
P [qto (Y, X, T, μFTR, ∏)] = P ((Y - μFTR) /∏ | T = to) ∏(to)
≈ [E ((Y - μ 一 e7∏) /∏ | T = to)] π(to) = 0.
Assumption 2. We consider the following assumPtions:
(i)	There exists constant c > 0 such that for any t ∈ T, x ∈ X, and πNN ∈ U, we have 1/c ≤ πNN(t |
x) ≤ c, 1/c ≤ π(t | x) ≤ c, ∣Q∣∞ ≤ cand ∣μ∣∞ ≤ c.
(ii)	Y = μ(X, T) + V where EV = 0, V ⊥ X, V ⊥ T, and V follows sub-Gaussian distribution.
(iii)	π, μ, πNN and μNN have bounded second derivatives for any πNN ∈ Q and μNN ∈ U.
(iv)	Either π = π or μ = μ. And Rad.n(G), Radn(Q), Radn(U) = O (n-1∕2).
(v)	BKn equals the closed linear sPan of B-sPline with equally sPaced knots, fixed degree, and
dimension K.	n1/6.
Theorem 2. Under AssumPtion 1 and 2, let ψ(∙) := n Pi=I (μ(χi, ∙)+∏⅛⅛}We have
kΨb — Ψ∣L2 = Op (n-1/3Plogn + r1(n)r2(n)).
where ∣∣π 一 π∣∞ = Op(rι(n)) and ∣∣μ 一 μ∣∞ = Op(r2(n)).
Remark 3. In Theorem 2, assumPtion (i), (iii) and the first half of (v) are weak and standard condi-
tions for establishing convergence rate of sPline estimators (Huang et al., 2003; 2004). AssumPtion
(ii) bounds the tail behavior of V . The second half of (v) restricts the growth rate of K. , which is
a tyPical assumPtion (Huang et al., 2003; 2004) but with different rate in order to obtain uniform
bound. The first half of assumption (iv) StateS that at least one of μ, π should be consistent. The
second half of assumPtion (iv) considers the comPlexity of model sPace, and is a common assumPtion
for problems with nuisance functions (Kennedy et al., 2017).
Remark 4. We want to point out that adding targeted regularization does not affect the limit of μ
and π in large sample asymptotics. That is, the limit of μ and π using loss (4) will be the same as
using loss (1). We refer the reader to Appendix A.1 for a more detailed discussion and proof.
Notice that our proof for Theorem 2 can also be adapted for analyzing modified one-step TMLE (Van
Der Laan & Rubin, 2006). With very similar assumptions, we could obtain double robustness and the
same consistency rate for TMLE estimator.
Theorem 2 guarantees that if we appropriately control the model complexity, under some mild
assumptions, the estimator ψ from targeted regularization is doubly robust, and when both ∏ and μ
are consistent, the rate of convergence of ψ to the truth is faster than the individual convergence rate
of ∏ or μ. Thus, using targeted regularization theoretically helps us obtain a better estimator of ψ.
7
Published as a conference paper at ICLR 2021
Dataset	Model	Naive	Doubly Robust	TMLE	TR
Simulation	Dragonnet Drnet Vcnet	0.045 ± 000094 0.042 ± 0.00090 0.018 ± 0.00098	0.026 ± 0.0012 0.023 ± 0.0011 0.022 ± 0.0013	0.037 ± 0.00086 0.035 ± 0.00083 0.016 ± 0.00082	0.028 ± 0.00088 0.027 ± 0.00086 0.014 ± 0.00091
IHDP	Dragonnet DRnet Vcnet	0.350 ± 0.016 0.316 ± 0.016 0.189 ± 0.013	0.307 ± 0.016 0.274 ± 0.014 0.190 ± 0.013	0.252 ± 0.0087 0.274 ± 0.018 0.148 ± 0.010	0.208 ± 0.0072 0.230 ± 0.0086 0.117 ± 0.0085
News	Dragonnet DRnet Vcnet	0.180 ± 0.0081 0.183 ± 0.0084 0.028 ± 0.0011	0.155 ± 0.0057 0.141 ± 0.0054 0.023 ± 0.0013	0.179 ± 0.0080 0.183 ± 0.0083 0.028 ± 0.0010	0.149 ± 0.0051 0.114 ± 0.0041 0.024 ± 0.0009
Table 1: Experiment result comparing neural network based methods. TR refers to targeted regular-
ization. Numbers reported are AMSE of testing data based on 100 repeats for Simulation and IHDP
and 20 repeats for News, and numbers after ± are the estimated standard deviation of the average
value.
5	Related Work
The Varying Coefficient Structure. Varying coefficient (linear) model is first proposed as an
extension of linear model (Hastie & Tibshirani, 1993; Fan et al., 1999) and is usually used for
modeling longitudinal data (Huang et al., 2004; Zhang & Wang, 2015; Li et al., 2017; Ye et al.,
2019). The key motivation of varying coefficient model is a dimension reduction technique that
avoids the curse of dimensionality for statistical estimation. Different from existing models, our
varying coefficient structure is applied on a complex neural network model with a different motivation
of enhancing the expressiveness of the treatment effect. Besides, building a hierarchical structure
on the network parameter is also explored by the HyperNetwork (Stanley et al., 2009; Ha et al.,
2016). Hypernetworks provide an abstraction that mimics the biology structure: the relationship
between a genotype (the hypernetwork), and a phenotype (the main network). The weight of the main
network is also a function of a latent embedding variable, which is learned with end-to-end training.
Hypernetwork trains a much smaller network to generate the weights of a larger main network in
order to reduce search space, while our network directly trains the main network whose weights are
linear combinations of spline functions of treatment. Moreover our network is proposed in order to
appropriately incorporate treatment into modelling, which is not touched upon in HyperNetwork.
Neural Network Structure for Treatment Effect Estimation. We refer readers to the introduction
for the connections and comparisons with previous developments using feed forward neural network
for treatment effect estimation. In addition to feed forward neural network, previous results also
utilize other networks to learn treatment effects. For example, Yoon et al. (2018); Bica et al. (2020)
estimated the causal effect via learning to generate the counterfactual. Louizos et al. (2017) learned
the causal effect by learning deep variable models using variational autoencoder. Compared with
our method, their approaches are mainly heuristic and do not provide theoretical guarantees for the
asymptotic correctness of the estimator.
Doubly Robustness, TMLE and Targeted Regularization. Chernozhukov et al. (2017; 2018)
developed theory for ‘double machine learning’ showing the convergence rate for doubly robust
estimator. Despite its good asymptotic property, doubly robust estimators can be unstable due to the
presence of conditional density estimator at denominator. Targeted Maximum Likelihood Estimation
(TMLE) (Van der Laan & Rose, 2011) and targeted regularization (Shi et al., 2019) are then proposed
to overcome this issue by introducing an extra perturbation parameter into the model. To the best of
our knowledge, previous works on TMLE and targeted regularization focused on estimating a single
quantity, such as ψ(1) - ψ(0) in binary treatment (Shi et al., 2019; Van der Laan & Rose, 2011) or
averaged treatment effect Eψ(t) for continuous treatment (Kennedy et al., 2017), while we give the
first generalization of targeted regularization and TMLE for inferring the whole ADRF curve.
6	Experiments
Dataset. Since the true ADRF are rarely available for real-world data, previous methods on treatment
effect estimation often use synthetic/semi-synthetic data for empirical evaluation. Following this
convention, we consider one synthetic and two semi-synthetic datasets: IHDP (Hill, 2011) and News
(Newman, 2008). The synthetic dataset contains 500 training points and 200 testing points, with
8
Published as a conference paper at ICLR 2021
Method	Simulation	IHDP	News
Causal Forest	0.043 ± 00021	0.97 ± 0.034	0.211 ± 0.003
BART	0.040 ± 0.0013	0.33 ± 0.005	0.066 ± 0.003
GPS	0.028 ± 0.0016	0.67 ± 0.025	0.022 ± 0.001
VCNet+TR	0.014 ± 0.0009	0.12 ± 0.009	0.024 ± 0.001
Table 2: Comparison of VCNet against non-neural-network based baselines. Reported AMSE are
averaged over 100 experiments for simulation and IHDP, and 20 experiments for News. Numbers
after ± are estimated standard deviation of the average AMSE.
the detailed generating scheme included in the Appendix. IHDP contains binary treatment with 747
observations on 25 covariates, and News consists of 3000 randomly sampled news items from the
NY Times corpus (Newman, 2008). Both IHDP and News are widely used benchmarking datasets
for binary treatment effect estimation, but here we focus on continuous treatment and thus we need to
generate the continuous treatment as well as outcome by ourselves. The generating scheme is in the
Appendix. For IHDP and news, we randomly split into training set (67%) and testing set (33%).
Baselines and Settings. For neural network baselines, we compare against Dragonnet (Shi et al.,
2019) and DRNet (Schwab et al., 2019). We improve upon the original Dragonnet and DRNet by (a)
using separate heads for T in different blocks for Dragonnet, and (b) adding a conditional density
estimation head for DRNet, since it has been suggested by Shi et al. (2019) that adding a conditional
density estimation head improves the performance. For non-neural-network baselines, we consider
causal forest (Wager & Athey, 2018), Bayesian Additive Regression Tree (BART) (Chipman et al.,
2010), and GPS (Imbens, 2000).
For VCNet, we use truncated polynomial basis with degree 2 and two knots at {1/3, 2/3} (thus
altogether 5 basis). Dragonnet and DRNet use 5 blocks and thus the model complexity of neural-
network models are the same. In practice we may vary the degree and number of knots in VCNet,
here the choice is made simply for fair comparison against Dragonnet and DRNet, ensuring the
number of parameters of the compared models is the same. The other hyper-parameters of each
method on each data are tuned on 20 separate tuning sets. Due to space limit, we refer readers to the
Appendix A.4 for more details on experimental settings.
Estimator and Metrics. To evaluate the effectiveness of targeted regularization, for all neural-
network methods we implement four versions: naive version (with conditional density estimator head,
trained using loss (1)), doubly robust version (Kennedy et al., 2017) by regressing (2) on treatment
with μ, π trained using loss (1), TMLE (Van Der Laan & Rubin, 2006) version with initial estimator
trained using loss (1), and TR version trained using loss (4). For non-neural-network based models,
we use the usual estimator. For evaluation metric, following Schwab et al. (2019), we use the average
mean squared error (AMSE) on test set, where AMSE = S PS=I RT[Ψs(t) - ψ(t)]2∏(t)dt and
ψs (t) is the estimated ψ (t) in the s-th simulation.
Results. Table 1 compares neural network based methods. Comparing results in each column, we
observe a performance boost from the varying coefficient structure. Comparing results in each row,
we find that naive versions consistently perform the worst, targeted regularization often achieves
the best performance, whereas performance of doubly robust estimator and TMLE varies across
datasets. In Table 2, we compare our approach with traditional statistical models. We observe that in
simulation and IHDP, VCNet + targeted regularization outperforms baselines by a large margin. In
News, its performance is close to the best one. The implementation can be found in an open source
repository1.
7	Conclusion
This work proposes a novel varying coefficient network and generalizes targeted regularization to a
continuous curve. We provide theorems showing its consistency and double robustness. Experiments
show that VCNet structure and targeted regularization boost performance independently and when
used together, it improves over existing methods by a large margin.
1https://github.com/lushleaf/varying-coefficient-net-with-functional-tr
9
Published as a conference paper at ICLR 2021
References
Ahmed M Alaa and Mihaela van der Schaar. Bayesian inference of individualized treatment effects
using multi-task gaussian processes. In Advances in Neural Information Processing Systems, pp.
3424-3432, 2017.
Luca Ambrogioni, Umut GUglU, Marcel AJ van Gerven, and Eric Maris. The kernel mixture network:
A nonparametric method for conditional density estimation of continuous random variables. arXiv
preprint arXiv:1705.07111, 2017.
Peter L Bartlett and Shahar Mendelson. Rademacher and gaussian complexities: Risk bounds and
structural results. Journal of Machine Learning Research, 3(Nov):463T82, 2002.
Ioana Bica, James Jordon, and Mihaela van der Schaar. Estimating the effects of continuous-valued
interventions using generative adversarial networks. arXiv preprint arXiv:2002.12326, 2020.
Christopher M Bishop. Mixture density networks. 1994.
Victor Chernozhukov, Denis Chetverikov, Mert Demirer, Esther Duflo, Christian Hansen, and Whitney
Newey. Double/debiased/neyman machine learning of treatment effects. American Economic
Review,107(5):261-65, 2017.
Victor Chernozhukov, Denis Chetverikov, Mert Demirer, Esther Duflo, Christian Hansen, Whit-
ney Newey, and James Robins. Double/debiased machine learning for treatment and structural
parameters, 2018.
Chin-Tsang Chiang, John A Rice, and Colin O Wu. Smoothing spline estimation for varying
coefficient models with repeatedly measured dependent variables. Journal of the American
Statistical Association, 96(454):605-619, 2001.
Hugh A Chipman, Edward I George, Robert E McCulloch, et al. Bart: Bayesian additive regression
trees. The Annals of Applied Statistics, 4(1):266-298, 2010.
Baldzs CSangd Cs^ji et al. Approximation with artificial neural networks. Faculty ofSciences, Etvs
Lornd University, Hungary, 24(48):7, 2001.
Laurent Dinh, Jascha Sohl-Dickstein, and Samy Bengio. Density estimation using real nvp. arXiv
preprint arXiv:1605.08803, 2016.
Jianqing Fan, Wenyang Zhang, et al. Statistical estimation in varying coefficient models. The annals
of Statistics, 27(5):1491-1518, 1999.
Max H Farrell, Tengyuan Liang, and Sanjog Misra. Deep neural networks for estimation and
inference: Application to causal effects and other semiparametric estimands. arXiv preprint
arXiv:1809.09953, 2018.
Christian Fong, Chad Hazlett, Kosuke Imai, et al. Covariate balancing propensity score for a
continuous treatment: Application to the efficacy of political advertisements. The Annals of
Applied Statistics, 12(1):156-177, 2018.
Douglas Galagate, Joseph Schafer, and Maintainer Douglas Galagate. Package ‘causaldrf’. 2015.
David Ha, Andrew Dai, and Quoc V Le. Hypernetworks. arXiv preprint arXiv:1609.09106, 2016.
Trevor Hastie and Robert Tibshirani. Varying-coefficient models. Journal of the Royal Statistical
Society: Series B (Methodological), 55(4):757-779, 1993.
Jennifer L Hill. Bayesian nonparametric modeling for causal inference. Journal of Computational
and Graphical Statistics, 20(1):217-240, 2011.
Keisuke Hirano and Guido W Imbens. The propensity score with continuous treatments. Applied
Bayesian modeling and causal inference from incomplete-data perspectives, 226164:73-84, 2004.
Jianhua Z Huang, Colin O Wu, and Lan Zhou. Polynomial spline estimation and inference for varying
coefficient models with longitudinal data. Statistica Sinica, pp. 763-788, 2004.
10
Published as a conference paper at ICLR 2021
Jianhua Z Huang et al. Local asymptotics for polynomial spline regression. The Annals of Statistics,
31(5):1600-1635, 2003.
Kosuke Imai and David A Van Dyk. Causal inference with general treatment regimes: Generalizing
the propensity score. Journal of the American Statistical Association, 99(467):854-866, 2004.
Guido W Imbens. The role of the propensity score in estimating dose-response functions. Biometrika,
87(3):706-710, 2000.
Fredrik Johansson, Uri Shalit, and David Sontag. Learning representations for counterfactual
inference. In International conference on machine learning, pp. 3020-3029, 2016.
Adam Kapelner, Justin Bleich, Maintainer Adam Kapelner, and SystemRequirements Java. Package
‘bartmachine’. 2016.
Edward H Kennedy, Zongming Ma, Matthew D McHugh, and Dylan S Small. Non-parametric
methods for doubly robust estimation of continuous treatment effects. Journal of the Royal
Statistical Society: Series B (Statistical Methodology), 79(4):1229-1245, 2017.
Jialiang Li, Chao Huang, Zhub Hongtu, and Alzheimer’s Disease Neuroimaging Initiative. A
functional varying-coefficient single-index model for functional response data. Journal of the
American Statistical Association, 112(519):1169-1181, 2017.
Christos Louizos, Uri Shalit, Joris M Mooij, David Sontag, Richard Zemel, and Max Welling. Causal
effect inference with deep latent-variable models. In Advances in Neural Information Processing
Systems, pp. 6446-6456, 2017.
Jonathan Masci, Ueli Meier, Dan Ciregan, and Jurgen Schmidhuber. Stacked convolutional auto-
encoders for hierarchical feature extraction. In International conference on artificial neural
networks, pp. 52-59. Springer, 2011.
David Newman. Bag of words data set, 2008.
BN Prichard and PM Gillam. Assessment of propranolol in angina pectoris. clinical dose response
curve and effect on electrocardiogram at rest and on exercise. British heart journal, 33(4):473,
1971.
Danilo Jimenez Rezende and Shakir Mohamed. Variational inference with normalizing flows. arXiv
preprint arXiv:1505.05770, 2015.
Jonas Rothfuss, Fabio Ferreira, Simon Walther, and Maxim Ulrich. Conditional density estimation
with neural networks: Best practices and benchmarks. arXiv preprint arXiv:1903.00954, 2019.
ARTHUR B Schneider, ELAINE Ron, Jay Lubin, Marilyn Stovall, and Theresa C Gierlowski. Dose-
response relationships for radiation-induced thyroid cancer and thyroid nodules: evidence for the
prolonged effects of radiation on the thyroid. The Journal of Clinical Endocrinology & Metabolism,
77(2):362-369, 1993.
Patrick Schwab, Lorenz Linhardt, Stefan Bauer, Joachim M Buhmann, and Walter Karlen. Learning
counterfactual representations for estimating individual dose-response curves. arXiv preprint
arXiv:1902.00981, 2019.
Uri Shalit, Fredrik D Johansson, and David Sontag. Estimating individual treatment effect: general-
ization bounds and algorithms. In Proceedings of the 34th International Conference on Machine
Learning-Volume 70, pp. 3076-3085. JMLR. org, 2017.
Claudia Shi, David Blei, and Victor Veitch. Adapting neural networks for the estimation of treatment
effects. In Advances in Neural Information Processing Systems, pp. 2503-2513, 2019.
Kenneth O Stanley, David B D’Ambrosio, and Jason Gauci. A hypercube-based encoding for evolving
large-scale neural networks. Artificial life, 15(2):185-212, 2009.
Timothy J Threlfall and Dallas R English. Sun exposure and pterygium of the eye: a dose-response
curve. American journal of ophthalmology, 128(3):280-287, 1999.
11
Published as a conference paper at ICLR 2021
Julie Tibshirani, Susan Athey, Stefan Wager, Rina Friedberg, Luke Miner, Marvin Wright, Main-
tainer Julie Tibshirani, LinkingTo Rcpp, RcppEigen Imports DiceKriging, and GNU SystemRe-
quirements. Package ‘grf’, 2018.
Brian L Trippe and Richard E Turner. Conditional density estimation with bayesian normalising
flows. arXiv preprint arXiv:1802.04908, 2018.
Mark J Van der Laan and Sherri Rose. Targeted learning: causal inference for observational and
experimental data. Springer Science & Business Media, 2011.
Mark J Van Der Laan and Daniel Rubin. Targeted maximum likelihood learning. The international
journal of biostatistics, 2(1), 2006.
Stefan Wager and Susan Athey. Estimation and inference of heterogeneous treatment effects using
random forests. Journal of the American Statistical Association, 113(523):1228-1242, 2018.
Mao Ye, Zhao-Hua Lu, Yimei Li, and Xinyuan Song. Finite mixture of varying coefficient model:
Estimation and component selection. Journal of Multivariate Analysis, 171:452-474, 2019.
Jinsung Yoon, James Jordon, and Mihaela van der Schaar. Ganite: Estimation of individualized
treatment effects using generative adversarial nets. 2018.
Xiaoke Zhang and Jane-Ling Wang. Varying-coefficient additive models for functional data.
Biometrika, 102(1):15-32, 2015.
12
Published as a conference paper at ICLR 2021
A	Appendix
A.1 ON THE CONSISTENCY OF μ AND ∏
We show that adding targeted regularization does not affect the limit of μ and ∏ in large sample
asymptotics. That is, the limit of μ and ∏ using loss (4) will be the same as using loss (1).
Denote
P'(μNN πnn) = P [(y - μNN)2 + α log πNN(t | x)],
1n
Pn'(μNNnNN) = n X [(yi -μNN(ti, xi))2 + απNN(ti | xi)] .
n i=1
Lemma 1. Suppose that (μ0, π0) is the minimizerofloss P'(μNN, πNN) and (μ, π, ^n) is the minimizer
of LFTR, then we have
P'(μ,π) - P'(μ0,π0) = o(1) + Op(n-1∕2).
Proof. We have
P'(μ, ∏) - P'(μ0, n0) ≤ Pn'(μ, ∏) - Pn'(μ0, ∏0) + |(P - Pn) '(μ, ∏) | + |(P - Pn) '(μ0, n0)∣
(a)
≤ Pn'(μ, ∏) - P'(μ0, n0) + Op(n-1∕2)
=(Pn'(μ, n) + βnRFTR[μ, ∏, ^n]) - (P'(μ0, ∏0) + βnRpTR[μ0, ∏, 0]) + Op(n-1/2)
+ βn (RFTR[μ0,∏0,0] - Rftr[μ, ∏, ^n])
(b)
≤ βn (Rftr[μ , ∏ , 0] - Rftr[μ, ∏, ^n]) + Op(n 臂
≤ βnRFTR[μ0, π0, 0] + Op(n-1∕2 )
(=c) o(1) + Op(n-1∕2),
where (a) follows from uniform concentration inequality using the fact that μNN , πNN is uniformly
bounded, Radn(Q), Radn(U) = O(n-1∕2) and the Lipschitz constant of log(x) is bounded when
X ∈ [1/c, c] for some finite c. (b) follows from the fact that (μ, π, ^n) is the minimizer of the empirical
risk (with FTR). (c) follows from the fact that
1n
R[μ0, π0, 0] = 一 £ (yi - μ0)2
n
i=1
=E(y-μ0)2 +Op(n-1∕2)
=E(V2)+E(μ-μ0)2+Op(n-1∕2)
= O(1).
□
Now we prove that
kμ - NIL + kπ - π0kL2 = op(1).	⑸
For simplicity, we ignore the unidentifiability of neural network parameterization and assume (μ0, π0)
is the unique minimizer in the sense that for any > 0, there exists η() > 0 such that
ll NN oll	ɪnfNN	[P'(μNNnNN)- P'(μ0,∏0)] >η(e).	(6)
kμ -μ0kL2 + kπ -π0kL2 >e
If Equation (5) is not true, then there exists s > 0 such that for any N > 0, there exists n > N such
that ∣∣μ - μ0∣∣L2 + k∏ - ∏0∣∣l2 ≥ s. From Lemma 1, we know that P'(μ, n) - P'(μ0,n0) ≤ η(s)
when n is sufficiently large. Thus, there exists n0 such that
kμ - μ0∣L2 + Iln - n0kL2 ≥ s,	P'(μ, n) - P'(μ0, n0) ≤ η(S),
which contradicts (6).
13
Published as a conference paper at ICLR 2021
A.2 Technical Proofs
In this section, we prove the two main theorems (Theorem 1 and Theorem 2) and give some additional
results which are mentioned briefly in the main text.
A.2.1 Notations and Definitions
We denote δt° as the Dirac measure centered on to and recall that δ(∙) denotes the Dirac delta function.
We use an . bn to denote that an ≤ Cbn for some C > 0 for all sufficiently large n. We denote
1n = (1,1, ∙∙∙ , I)T ∈ Rn. For any function f and function spaces Fι, F2, we write Fi + F2=
{f1 +f2 : f1 ∈ F1,f2 ∈ F2}, F1F2 = {f1f2 : f1 ∈ F1,f2 ∈ F2}, fF = {fh : h ∈ F},
f ◦ F = {f ◦ h : h ∈ F}, and Fa = {fa : f ∈ F}, ∀a ∈ R.
We define
SU)= P[(Y - μn)∕∏n | T = ∙]/叫∏-2 |T = ∙],
where (^n, πn, en) is the minimizer of loss (4). We denote ^n(∙) = PK=I αk夕k(∙) as the spline
regression estimator of e(∙). With some slight abuse of notation, we denote
ψκn ⑴=Wi⑴，∙2⑴,…,中Kn ⑴)T ∈ RKn ,
We define
Bn = ("(ti),…“Kn (tn))T ∈ Rn×κn .
∏n = diag (∏n(ti | Xi),∏n(t2 | 多2),…,∏n(tn | Xn)),
Πn = diag ([P (∏-2(T | X) | T = ti)]-i∕2,…，[P (∏-2(T | X) | T = tn)]-1/2).
We define
Zn = (zi , z2 ,
, zn)T ∈ Rn
where
yi ― μn(ti, Xi)
∏n(ti | Xi)
Zn = (Z1,Z2,…，Zn)T ∈ Rn where Zi= P (Y- *(TtX) | T = t
πn(T | X)
Notice that
α^= (BTn-2Bn )-i BT Zn,
and we denote
α= (BT∏-2Bn)-i BT∏-2∏nZn.
A.2.2 Useful Lemmas
This section gives lemmas which are used in our proofs of main theorems.
Recall that Theorem 1 consists of two parts: the efficient influence function of ψ(t0) and its double
robustness. Notice that ψ(t0) can be written as a special case of a more general parameter Γ =
T γ(t; PT)ψ(t)dPT(t) (see Remark 5). Here γ(t; PT) is a function of t which depends on the
probability measure PT. For brevity we also write γ(t) := γ(t; PT) when the corresponding PT
is the true probability measure of treatment T. The following Lemma gives the efficient influence
function of Γ.
Lemma 2. The efficient influence function for Γ is
Z (Y, X, T, ∏, μ, Γ) = Y(T )ξ(Y, X ,T,∏,μ) - Γ+ L μ(t, X )γ(t)dPT (t) + IY(TT) L μ(T, x)dP(x)
- I Y γ(t)μ(t,x)dP(x)dPT(t)- Et [æ)- μ μ(T, x)dP(x),
T X	l0(T;0) X
where ξ(Y,	X,T,∏,μ, Γ)	=	Y-(μ(TX)	RX ∏(T |	x)dP(x)	+	RX μ(T, x)dP(x),	γ[(t)=
d'tdPT,ε) ∣ε=o，'ε(t ； 0) = d logPT,ε(t) |e=o and Pτ,ε is a parametric submodel with parameter
ε ∈ R andPτ,o(∙) = Pt(∙).
14
Published as a conference paper at ICLR 2021
Remark 5. Setting γ(∙) = dp0(), we get Γ = ψ(to). Setting γ(∙) = 1, we get Γ = RT ψ(t)dPτ(t),
which is the average outcome under a randomized trial and is a quantity of interest in its own right
(Kennedyetal.,2017). Setting γ(∙)= dδ1(^)一 翦?), we get Γ = ψ(1) 一 ψ(0), which is the average
treatment effect under binary treatment setting.
Recall that in Theorem 2, Gn is the spline regression estimator of e. In order to establish the
convergence rate of our final estimator ψ, We need to establish the convergence rate of en first.
Lemma 3. Under assumptions in Theorem 2, we have
k^n 一 O∣∣L2 = Op (n-1/3Plogn).
Remark 6. For fixed objective function, the convergence rate of the B-spline estimator to the truth
is a standard result (Huang et al., 2004; 2003), which is Op(n-2/5) when choosing Kn n-1/5.
However, Lemma 3 gives a uniform bound on a class of functions in order to deal with the fact that
∏n and μn are NOT fixed and dependent on the observations. The bound is thus of a larger order
n-V3√log n when choosing the optimal Kn N n-1/6.
Lemma 4. Under assumption in Theorem 2, there exist positive constants M1 and M2 such that
except on an event whose probability tends to zero, all the eigenvalues of (Kn/n) BnTΠn-2Bn fall
between M1 and M2, and consequently, (Kn/n) BnTΠn-2Bn is invertible.
Lemma 5. Assume kF1 k∞ < ∞ and kF2k∞ < ∞, we have
Radn(FιF2)≤ 2(Radn(Fι) + Radn(F2))(∣∣F1∣∣∞ + ∣∣F2∣∣∞)∙
A.2.3 Proof of Theorem 1
Proof. Denote γ(t; PT) = ；；：£). Then the efficient influence function Zt0 of ψ(t0) is obtained by
plugging the definition of γ (t; PT ) in Lemma 2 and some simplifications using
Y (t； PT)
ιε (t；o)
-γ(t; PT )∙
(7)
So here We only need to prove that the efficient influence function is doubly robust. We have
PZto (Y, X ,τ,∏,μ, Γ)
(=a)
(=b)
P δ(T 一 t0)
Y-WXXr+阳。,X)- ψ(t0))
π(x)π(t | x)δ(t 一 t0)
μ(t, χ) ― μ(t, χ)
π(t | x)
dxdt + J μ(to, x)π(x)dx 一 J μ(to, x)π(x)dx
π (π(to1 x)
X	π(to1 x)
—1 (μ(t0, x) 一 μ(t0, x)) dP(x),
(8)
where (a) follows from iterated expectation, (b) follows from ∏(x 11) = ∏(t | x)∏(x)∕∏(t). From
the last line of Equation (8), it is obvious that the desired conclusions hold.	□
15
Published as a conference paper at ICLR 2021
A.2.4 Proof of Theorem 2
Proof. First, from condition (i), we have
(U ∏⅛dPn(X) - P [δ(T —•) YnTTXX)UL
() ZX π⅛ dPn(X i∙)P( Y⅛≡π lT=∙)L
≤ (^(∙) - 改∙)) / T7‰dPn(X)	+ 皿(Z	dPn(X)-∏(∙)P(『二 K、I T =))
JX π( | X)	L2	XJx π(∙ | X)	(*卜 | X)	JJ
.k^ -针L2	+ 皿(Z τψ‰d (Pn- P)(X))	+ 皿(Z	τ7‰dP(X)	- π(∙)P	(，2「K、I T
IJX π(∙ i X)	J IJX	π(∙ i X)	[*(•1 X)
L2
.J 加 Tm UX ∏⅛ d (Pn-P)(X ))L
+
μ(X,τ)- μ^n(X,τ)
∏n(X,T )
∏(∙ I X) — π(∙ I X)	1
∏(7w	∏(7m
dP(X)
L2
(=Op (n-1/3 Plog n + r1(n)r2(n)).
(9)
where (a) follows from Lemma 3, which Says ∣∣^n 一 七||工2 = Op(n-1/3√logn).
From generalization bound and condition (iv), we know
1 n
sup -y2^n(xi,tθ) - P^n(X,tθ) = SuP ∣Pn^t0 (X) - Pgt0 (X )∣ = Op (n-1/2).
t0∈[0,1] n i=1	t0∈[0,1]
Thus,
1 n
n ɪ2 μn(xi,∙) - PAn (X, ∙)	. = Op(n 1/2)	(10)
i=1	L2
Recall that Theorem 1 says that if suΡt∈[o,i] suPχ∈X ∣∏n(t I X) - π(t ∣ X)∣ = Op(rι(n)),
SuPt∈[0,1] SuPχ∈X ∣^n(t, X) - Q(t, X)∣ = Op(r2(n)),then
sup P
t0∈[0,1]
δ(T - to) Y-μT(TXX) + μn(t0, X)
- ψ(t0) = Op(r1(n)r2(n)).
(11)
Combining Equation (9), Equation (10) and Equation (11), using triangle inequality, we have
1	1n
(∙)	∏(. । χ) dPn(X) + n Eμn(Xi, ∙) - ψ(∙)
So ifwe set
=Op (n-1/3 VZlog n + r1(n)r2(n)).
L2
ψ(t0)= ^(t0) Z	ZIl、dPn(x) +	1 X i^n(Xi ,tθ) =	1 X (μ(Xi,t0)+	JtO) J
X	π(tO I	x)	n i=1	n i=1	π(tO I xi) )
We have
∣ψ - ψ∣L2 = Op (n-1/3Plogn + r1(n)r2(n)).
□
A.2.5 Proof of Lemma 2
Proof. The proof follows Kennedy et al. (2017). Denote
Γ(ε) = T γε(t) X Y
yπ(y I x,t; ε)π(x; ε)π(t; ε)dydxdt,
16
Published as a conference paper at ICLR 2021
where We write γε(∙) ：= Y(∙; Pτ,ε) for brevity. Then, by definition, the efficient influence function
for Γ is the unique function Z(Y, X, T) such that
rε(0) = E (Z (Y X,T )'ε(Y, X,T ;0))
(12)
where '[(y, x, t; 0) = dlogPYX:ε(y,x,t) '=0, Pγ,χ,τ,ε(y, x,t) is a parametric submodel with
parameter ε ∈ R, and Pγ,χ,τ,o(y, x, t) = Pγ,χ,τ(y, x, t), and Γ^(0) = dΓ(ε)∕dε Iε=o. We have
Γ0[(0) =	Y(t)	y [π[0 (y I X, t； 0)π(X) + π(y I X, t)π[0 (X； 0)] π(t)dydXdt
T	XY
Tγε(t)XY
ZTγε0(t)ZXZY
+
yπ(y | x, t; )π(x; ε)πε0 (t; 0)dydxdt
+
yπ(y | x, t; ε)π(x; ε)π(t; ε)dydxdt
= I1 + I2 + I3 .
From '!(y ∣ x,t;0) = ∏(y ∣ x,t;0)/n(y ∣ x,t;0) and definition of ψ(t), we have
Ii ：= Y Y(t) [ y y ['ε(y I x,t；0)n(y I x,t)∏(x) + ∏(y I x,t)&(x；0)n(x)] π(t)dydxdt
T	XY
=∕γ(t) [EχEY∣X,T (y'ε(y I x,t；0)) + EX (〃(x,t)4(x；0))] n(t)dt,
I2 ：=/ Y(t)ψ(t)∏ε(t； 0)dt = / γ(t)ψ(t)'εg0)n(t)dt,
I3 ：=/ Yε (t)ψ(t)∏90)dt.
Thus, we have
rε(0) = / [γ(t)EχEy∣x,t (y',e(y I x,t; 0)) + EX (μ(x, t)4(x; 0)) + γ(t)ψ(t)4(t; 0) + Y0(t)ψ(t)] n(t)dt.
T	(13)
Meanwhile, for the right hand size term Eχ,τ,γ (Z(Y, X, T)《(Y, X, T； 0)) in Equation (12), from
'ε(Y, X ,T; 0) = ((Y IX, T; 0) + 'ε(X,T; 0),
where《(YX,T; 0) and '[(X, T; 0) are defined similar to '!(Y, X,T; 0), we know that
Ex,t,y (Z(Y, X, T)'[(Y, X, T;0)) = Eχ,τ,γ (Z(Y, X,T)'[(YX,T; 0))+Eχ,τ,γ (Z(Y, X, T)'[(X,T; 0)).
(14)
Now we bound each term in Equation (14) separately. Recall that
Z(Y X,T,∏,μ)= γ(T)
Y - μ(T, X)
∏(T I X)
/ π(T I x)dP(x) + γ(T) / μ(T, x)dP(x) - Γ
+ ∕”(t, X)Y(t)dPT(t) + l!⅜ ZX μ(T, x)dP(X)
- I γ(t)μ(t, x)dp(x)dPτ(t) — ET
TX
Thus, for the first term in Equation (14), we have
Ex,t,y (Z(Y,X,T)'ε(YX,T；0))
=Ex,t [Ey∣χ,τ (Z(Y, X, T)'ε(Y∣X, T； 0))]
∣γ(TT) ZX μ(T, x)dP(X)J
Y
=a EX,TEY∣X,T
(=b)
T ×X
γ(t)
γ(T)
∏(T I x)
Ln(T I x)dP(x)) 'ε(Y∣X,T;0)
Ey|x,t[Y《(Y|x,t；0)]
π(t I x)
π(t I x)dP(x) p(x)π(t I x) dtdx
(15)
L j(t)Ey∣x,t [Y4(Y|x,t；0)]p(t)p(x)dtdx
L γ(t)Eχ [Eγ∣x,t [YQ(Y|x, t； 0)]] P(t)dt,
17
Published as a conference paper at ICLR 2021
where (a) follows from the fact that Eγ∣χ,τ ('](Y|X, T; 0)) = 0, (b) uses law of iterated expecta-
tions.
For the second term in Equation (14), we have
EXTY (Z(Y, X,T)'ε(X,T;0))
=Ex,t,y [(y(T)Y -」(TyX) Z ∏(T | x)dP(x)) Q(X,T;0)
π(T | X) X
+ EX,T ST) JX μ(T, x)dP(x) + ≡⅛ JX μ(T, x)dP(x)>ε(XIT; 0) + 'ε(T; 0))
+ EX,
+ EX,
“(t, X)γ(t)dP(t) &(TX;0) + 'L(X；0))
γ(t)ψ(t)dP(t)- ET∕x μ(T, x)dP(x)〕T)%(T，Xm
(b)
=Et [γ(T) / μ(T, x)dP(x)'ε(T;0)] + ET
X
涓 JX μ(T, χ)dp(χ)'ε(T⑼
+ EX
μ(t, X)γ(t)dP(t)'ε(X;0)
γ(t)ψ(t)'ε(t; 0)p(t)dt +
EX [μ(t, X)'ε(X;0)] γ(t)dP(t) +
γε0 (t)ψ(t)p(t)dt
T
T
T
(16)
where (a) follows from the fact that
&(X, t ； 0) = ((X|T ； 0)+'ε(T ； 0) = Q(T ∣x ； 0)+'ε(X; 0),
(b) follows from the fact that
Ey IX ,t Y = μ(T, X), Eτ∣χ Q(T ∣X; 0)= Eχ∣τ-(X∣T; 0) = Eχ,τ Q(X,T ;0)=0
and law of iterated expectations, (c) follows from the definition of ψ(t) = JX μ(t, x)dP(x).
Comparing Equation (15), Equation (16) against Equation (13), we immediately get
rε(0) = Ex,t,y (Z(Y,X,T)'ε(Y,X,T;0)),
which implies that Z(Y, X, T) is indeed an efficient influence function of Γ.	口
A.2.6 Proof of Lemma 3
Proof. This proof follows from Huang et al. (2004). Let us start with the following decomposition:
∣∣(≡n - UnllL2 ≤ ∣∣*≡n - 2n∣∣L2 + ∣∣*≡n - Wn ∣∣L2
where Wn = (φKn(t))T α. The first term ∣∣6n 一 WnkL2 is the bias and the second term ∣∣^n 一 WnkL2
is the variance.
Bound on bias term Let α ∈ RKn be such that ∣∣ (<α)T φKn — 6n∣∞ = inff∈Bκn ∣f 一 un∣∞.
Then we have
I 归n - WnkL2 = L 一(α)T ΨKn + (α)T ΨKn 一 Wn ∣∣L2
≤ ∣≡n 一 (α)T *∣L2 + ∣ (α)T * - Wn∣L2.
By definition of αU and properties of B-spline space, we have a bound on the first term
∣∣<≡n 一(ɑ)T WKnkL2 =Op (Pn),
18
Published as a conference paper at ICLR 2021
where Pn = inff∈span{^Kn} suPt∈[o,i]归n(t) — f (t)∣. Notice that the second term can also be
bounded:
k(α)T 中Kn- WnkL2
(a<)k<α - α ∣∣2∕pKn
=k (BT ∏-2Bn)T BT ∏-2 (Bnα - ∏nZn) ∣2 / pKn
当 Kn ∣BT∏-2 (Bnd - ∏ nZn) ∣2∕pKn
X √KnPn J1T∏-2 BTBn∏-21
(17)
X (X	Ok (to	!
k = 1 ∖i=1 πn(ti 1 Xi)
嗖 PKnPntX (J X Ok (tj ,
k=1 n	i=1
where (a) follows from properties of B-spline basis functions, (b) follows from Lemma 4, (c)
follows from properties of B-spline space such that l∣Bn<α - ΠniZn
Op(Pn) because
∞
(∣n(tιU(tι),… ，5n(tι))T = ∏∏(Zn, (d) is from the upper and lower boundedness of ∏n Follow-
ing proof of Lemma A.6 of Huang et al. (2004), for any a > [EOk(T)]2Kn, we have
Kn	n
X 1 x Ok (ti)
k=1	i=1
2
>a
(a) Kn	1 n
≤ EProb n∑>k(ti)
k=1	i=1
>
n	1 n
≤ ^X Prob I n ^X Ok (ti) - EOk (T) I + IEOk (T )∣
k=1
Kn
≤ X Prob
k=1
>
i=1
n ^X °k (ti) - E°k (T) I > rK-------------|E°k (T )|
X a Pnt
n
K
n
n
2
(b)	2
≤ 2Kn exp — -2n (YaKn - |EOk (T) I)
where (a) uses union bound, (b) follows from Hoeffding’s Inequality for bounded random
variables. Since EOk (T) X 1/Kn, we can pick a = 2[EOk (T)]2 Kn X 1/Kn and thus,
PK=I (n Pn=I Ok(ti))2 = Op (K). Plugging into Equation (17), we get
∣(α)T *- WnkL2 = Op (ρn),
Thus, we can bound the bias term
I 怕n - WnkL2 = Op (Pn) ∙
Bound on variance term From properties of B-spline space, we have
∣∣l≡n - WnkL2 . ∣∣α - α ∣∣2/P Kn∙
Notice that
kα - α k2 = ∣∣ (BT∏-2Bn)-1 BT (Zn - ∏-2∏nZn) ∣L
=∣∣ (BT∏-2Bn)-1 BT (Zn - Zn + Zn - ∏-2∏nZn)(
≤∣(BT∏-2Bn)-1 BT (Zn - Zn)∣L+∣∣(BT∏-2Bn)T BT (Zn- ∏-2∏nZn)(
(18)
19
Published as a conference paper at ICLR 2021
Control of the first term in Equation (18): denote δ = (δι,…，δn)T := Zn 一 Zn ,then We have
IkBTn-2Bn)-1 BT
—
2
X) K2 δτ BnBT δ
n2	n
Kn Σ>Kn (t"i
n2
≤Kn2 Xn sup
k=ι πα
i=1
2
-X 0k (ti)δi
i=1
一 Zn)T Bn (BTn-2Bn)-2 BT
K22 X (X Ok (ti)δj
k=1 i=1
(19)
K
2
n
2
—
where (a) is from Lemma 4. By definition we know
y — yi — μn(xi, ti) _
i	∏(t | Xi)
=μ(xi,ti) — μn(xi,ti)
∏(t | Xi)
=Ui + vi,
BhQrQ μ 一 μ(xi,ti)-μn(xi,ti)	JP) /
Where Ui =	∏(ti∣χi)	P I
Y - μn(X,T)
Π(T | X)
-P
μ(X,T)
| T = ti
-μn(X,T)
Π(T | X)
μ(X,T )-^n(X,T)
Π(T∣X)
E (vi | ti, Xi) = 0. Thus, from union bound, we have
Prob (Xsup ( 1 X Ok(ti)δi ) > a I
∖k=1 π,μ n i=1	) I
Kn
≤ X Prob
k=1
Kn
= X Prob
k=1
Kn
= X Prob
k=1
Kn
= X Prob
k=1
sup (1 X Ok(ti)δi! >Kn
sup
π,μ
sup
π,μ
sup
π,μ
| T = ti +
vi
∏(ti | Xi)
| T = ti], E(Ui | ti) = 0 and vi =1肃⑦。,
1n
—5-2 ψk (ti)(ui + vi)
n
i=1
>
1
> 2
1n
-V^k (ti)δi
n
i=1
1n
-V^k (ti)Ui
n
i=1
n
Prob sup
k=1	∖π∙μ
1n
—兄Pk (ti )vi
n
i=1
1
> 2
(20)
From Lemma 5, We knoW that
Radn((Q + μ)UT) ≤ 2(kQk∞ + kU-1k∞) (Radn(Q) + Radn(UT))
(a) 1	c2	2	1	2c
≤ 2(kQk∞ +	kU	k∞) (Radn(Q) + max	("2,	(C 一 1∕c)2 )	Radn(U	- 诟) + ~
= O(n-1/2),
where (a) follows from plugging h : x → 方二/2。+ 2c in Theorem 12(4) in Bartlett & MendelSon
(2002). Similarly, write A =(Q + μ)U-1, from Lemma 5, we have
Radn(OkA) ≤ 2(kθkk∞ + kAk∞)(Radn(θk) + Radn(A)) = O(n-1/2).
Thus, we bound the first term of (20) using
Prob sup
∖ π,0
1n
—ψk (ti)ui
n
i=1
> 2 ∕κan
(a) E (suP∏,μ ]n Pt]
Ψk (ti)ui∣) (b) I Kn
------------X \ —,	(21)
an
1	/ a
2 V K
20
Published as a conference paper at ICLR 2021
where (a) follows Markov Inequality, and (b) follows from the definition of Rademacher complexity.
We bound the second term of Equation (20) using union bound: for any Mn > 0,
Prob sup
∖π,μ
≤Prob sup
π,μ
n X 中 k(ti)Vi
1n	1
n2 k (ti)viI(Ivi | > Mn )1 > 4
+ Prob sup
π,μ
1n
—2 k (ti)viI(IviI
n
i=1
≤ Mn )
(22)
We have from Markov Inequality that
1n	1
Prob SuP —2k(ti)viI(IviI ≤ Mn) > -
"n i=1	4
E suPπ,^ 11 Pn=I ψk (ti"π(ti i xi)viI(IviI ≤ Mn)I (a) rκn.,
；-------------------/ - ------------------ . \  Mn
a/Kn	an
(23)
where (a) follows from Lemma 5. Also we have
Prob SuP
π,μ
1n
—T^k(ti)viI(Ivi I > Mn)
n i=1
.EsuP∏,μ |1 Pn=I Wk(ti)viI(IviI 〉 Mn
〜	pa∕κn
≤EsuPπ,μ 1 Pn=I ⅞⅛⅛IviII(IviI >Mn)
一	√0∕Kn
E [IvII(IvI > Mn)]
√OTKn
(a)	R0∞ (1- FW(w)) dw - R-0∞ FW (w)dw
√α∕κn
R0∞ P(IvI ≥ max(Mn, w))dw
√0TKn
(b)	R∞ e-σ[max(Mn,w)]2dw
.	pa/Kn
<R∞ e-σ[Mn+w]2dw
一	√0∕κn
.) e-σM2 √Kn 1
1
> 4
(24)
where (a) uses the formula EW = R0∞(1-F (w))dw-R-0∞ F (w)dw and we set W = IvII(IvI > M ),
(b) utilizes the fact that v follows sub-Gaussian distribution, (c) uses Mills ratio.
Plugging Equation (21), (23), (24) into (20), and taking M N √lοg n, a N Kn 詈 n, We get
X SuP n nX Ok (ti)δj=Op( Kngn)	(25)
k=1 π,Q n i i=1	/	n	/
Which, When plugging back into Equation (19), gives
I (BTn-2Bn)-1 BT (Zn- Zn) IL= Op (JK^.	(26)
21
Published as a conference paper at ICLR 2021
Control of the second term in Equation (18): Notice that each coordinate of Zn 一 ∏-2∏∏nZn is
bounded, thus using similar arguments as that of Equation (21), we know that
II(BT∏-2Bn)T BT (Zn- ∏-2∏nZn) IL = Op ^rKngn) ∙	(27)
Combining Equation (26) and (27) into (18), we know that
kα 一 αk2 = Op (rK3ngn),
and thus,
k^n 一 ％ k L2 = Op (JKn nθg n) .	(28)
Combining the rate on bias and variance term, we get
k^n - JkL2 = Op (Pn + rK⅛gn) = Op M + K√gn),
where (a) follows from assumption (iii), giving
k^n 一 O∣∣L2 = Op (n-1/3plogn),
when taking Kn N n1/6.	□
A.2.7 Proof of Lemma 4
Proof. Suppose the SVD decomposition of Bn = UΛVT where U ∈ Rn×n, Λ ∈ Rn×Kn,
V ∈ RKn×Kn. From Lemma A.3 of Huang et al. (2004), we know that all diagonal ele-
ments of (Kn/n) ΛTΛ fall between some positive constants. Notice that the eigenvalues of
(Kn/n) BnTΠn-2Bn are the diagonal elements of (Kn/n) ΛTΠn-2Λ. From the upper and lower
boundedness of ∏n We can get the desired conclusion.	□
A.2.8 Proof of Lemma 5
Proof. Write F3 = F1 + F2, F4 = F1 一 F2. Notice that F1F2 = {f1f2 : f1 ∈ F1, f2 ∈ F2} =
{4(fι + f2)2 — 4(fι — f2)2 : fι ∈ Fl, f2 ∈ F2} = 1F3 — 4F2. Let h : x → χ2,from Theorem
12(4) of Bartlett & Mendelson (2002) we know that
Radn(F3F3) = Radn(h ◦ F3) ≤ 2kF3k∞Radn(F3).
Thus,
Radn(F1F2)
=Radn(4 F — 1 F42)
≤Radn(4 F32 ) + Radn ( — 4 F42)
≤ 4Radn(F32 ) + 4Radn(F2)
≤ 2 ∣∣F3∣∣∞Radn(F3 ) + 2 IlF4k∞Radn(F4)
≤ 2(IlF3k∞ + IlFZ4k∞ )(Radn(F3) + Radn(F4)).
□
22
Published as a conference paper at ICLR 2021
A.3 Additional Results
This section formally states and proves the efficient influence function of a multidimensional vector,
which is briefly mentioned in the main text. Suppose Γ = (Γι, Γ2,…，Γd)T ∈ Rd where
Γj
γ(j) (t;PT)
yp(y | x, t)p(x)p(t)dydxdt.
Then we have the following theorem:
Theorem 3. The efficient influence function for the d-dimensional vector Γ is
Z (Y X ,T, π, μ,Γ) = (Zι(Y, X, T, π, μ, Γ1),Z2(Y, X, T, π,μ, Γ2),…，Zd(Y, X ,T, π, μ, Γd))T ∈ Rd
where Zj (Y, X, T, π, μ, Γj) is the efficient influence functionfor Γj, j = 1,2,…，d.
Proof. Define Γ(ε) := (Γι(ε), Γ2(ε),…，Γd(ε))T ∈ Rd where for i = 1, 2,…，d,
Γi(ε) = (Y⑴(t;Pτε)∕χ∕y
yp(y | x, t; ε)p(x; ε)p(t; ε)dydxdt.
Define '(Y, X, T; ε)
ε ∈ Rd and PY,X,T;0
function such that
log Pγ,χ,τ产 where Pγ,χ,τ产 is a parametric submodel with parameter
PY,X,T. Then, the efficient influence function ζ is defined as the unique
T
i.e.,
Iε=0
d`
(dε1
ε=0
dΓi
dεj lε=0,
dΓ(ε) I
dε
ε=0
∀i,j = 1, 2,…，d
E
ζ
Notice that the efficient influence function Zi(Y, X, T, ∏, μ, Γi) for Γi does not depend on ε. Thus
for each i,j = 1,2,…，d, the above equation can be proved using similar arguments as that in
Section A.2.5.
□
A.4 Experimental Details
A.4. 1 Network Structure
For all methods, we implement the conditional density estimator as a neural network with two hidden
fully connected layers, each consisting of 50 hidden units using ReLU activation. Hidden feature z is
defined as the latent representation extracted after the second ReLU activation. We set the number
of grids B = 10. The estimation of π(t I x) is computed as introduced in Section 3. Following
Schwab et al. (2019), we use 5 blocks for Dragonnet and DRNet. Structure of prediction head for
each block is the same as the prediction head μ for VCNet, except that Dragonnet and DRNet do not
use treatment-dependent weights. In VCNet, the prediction head for μ(t, x) is a neural network with
two hidden fully connected layers stacking over the hidden feature z . Each hidden layer consists of
50 hidden units with ReLU activation. We use B-spline with degree two and two knots placed at
{1/3, 2/3} (altogether 5 basis). In this way, all methods have the same complexity, i.e., the number
of parameters. We also tried different structures and found the relative performance of different
methods to be similar. Thus, all reported results below are based on this structure. All networks are
trained for 800 epochs.
A.4.2 Parameter Setting
For each dataset we tune parameters based on 20 runs. In each run we simulate data, randomly
split into training and testing, and use AMSE on testing data for evaluation. We tune the following
parameters. For all methods: network learning rate lr ∈ {0.05, 0.005, 0.001, 0.0005, 0.0001} and
α ∈ {1, 0.5}. For TR: learning rate for (t): lr ∈ {0.001, 0.0001}, β ∈ {20, 10, 5} × n-1/2. We
found that performance is not sensitive to α. In estimator of (t), we use B-spline with degree 2
and tune the number of knots across {5, 10, 20} (all equally spaced at [0, 1]). For TMLE and doubly
robust estimator: we tune parameters of B-spline in the same way as in TR version. During tuning,
all networks are trained for 800 epochs.
23
Published as a conference paper at ICLR 2021
A.4.3 Statistical baselines
We implement Causal forest (Wager & Athey, 2018) using R package ‘grf’ (Tibshirani et al., 2018),
BART using R package ‘bartMachine’ (Kapelner et al., 2016), and GPS using R package ‘causaldrf’
(Galagate et al., 2015). We tune the paramters of each method on each dataset using 20 separate
tuning sets, including the number of trees for BART, the number of trees and minimum node size for
causal forest, and the number of knots for GPS. The other hyper-parameters are set to the default
value of the R packages.
A.4.4 Dataset
Synthetic Dataset We generate data as follows: Xj '〜.Unif[0,1], where Xj is the j-th dimension
of x ∈ R6, and
et | x
10 sin(max(X1, X2, X3)) + max(X3, X4, X5)3
+ sin(0.5X3)(1 + exp(X4 - 0.5X3))
1 + (X1 + X5)2
+ X23 + 2 sin(X4) + 2X5 - 6.5 + N (0, 0.25),
y | x,t = cos(2π(t — 0.5)) ft2 + 4max(x1,χ6) sin(χ4)) + N(0,0.25),
1 + 2X23
t	i / -1	/ T∖ ∖ ——1 TL ɪ	,1,/,I'	1	1	1	1 ∙ 1	^~∖ / ι ∖
where t = (1 + exp(—t))-1. Notice that π(t | x) only depends on X1, X2, X3, X4, X5 while Q(t, x)
only depends on X1, X3, X4, X6. As discussed in Shi et al. (2019), this allows us to observe the
improvement using VCNet when noise covariates exist. Results are reported in Table 1.
IHDP The original semi-synthetic IHDP dataset from Hill (2011) contains binary treatments with
747 observations on 25 covariates. To allow comparison on continuous treatments, we randomly
generate treatment and response using:
te | x
2xι
(1 + x2)
+ 2max(x3,x5,x6) + 2tanh (5£弋，2 (Xi- c2)
0.2 + min(X3, X5, X6)	|Sdis,2 |
- 4 + N(0, 0.25),
y | x,t
sin(3πt)
1.2 — t
exp(0.2(X1 — X6))
0.5 + 5 min(X2, X3, X5 )
+ N(0, 0.25),
tanh 卜 ⅝d^
+
where t = (1 + exp(—t))-1, Scon = {1, 2, 3, 5, 6} is the index set of continuous features, Sdis,1 =
{4, 7, 8, 9, 10, 11, 12, 13, 14, 15}, Sdis,2 = {16, 17, 18, 19, 20, 21, 22, 23, 24, 25} and Sdis,1 ∪Sdis,2 =
P	xi	P	xi
[25] — Sc0n. Here ci = E ；；dis,1 ", c2 = E —* i∈f dis,2 :. Notice that all continuous features are
|Sdis,1 |	|Sdis,2 |
useful for π(t | x) and Q(t, x) but only Sdis,1 is useful for Q and only Sdis,2 is useful for π. Following
Hill (2011), covariates are standardized with mean 0 and standard deviation 1 and the generated
treatments are normalized to lie between [0, 1]. Results are summarized in Table 1.
News The News dataset consists of 3000 randomly sampled news items from the NY Times corpus
(Newman, 2008), which was originally introduced as a benchmark in the binary treatment setting
(Johansson et al., 2016). We generate the treatment and outcome in a similar way as Bica et al. (2020).
We first generate v10 , v20 and v30 from N(0, 1) and then set vi = vi0/ kvi0k2 for i = {1, 2, 3}. Given
x, We generate t from Beta(2 J 2V>χ。. And We generate the outcome by
y0 | x,t = exp (v>x —0.3),
y | x,t = 2 (max(-2, min(2, y0)) + 20v>x) *(4(t — 0.5)2 * sin (∏t)) + N(0,0.5).
24