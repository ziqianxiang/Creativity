title,year,conference
 Qsgd: Communication-efficient sgd via gradient quantization and encoding,2017, In Advances in Neural Information ProcessingSystems 
 LEAF: A benchmark for federated settings,2018, CoRR
 Emnist: Extending mnistto handwritten letters,2017, In 2017 International Joint Conference on Neural Networks (IJCNN)
 Distributed proximal splitting algorithmswith rates and acceleration,2020, arXiv preprint arXiv:2010
 An estimation ofsensor energy consumption,2009, Progress in Electromagnetics Research
 Deep residual learning for imagerecognition,2016, In Proceedings of the IEEE conference on computer vision and pattern recognition
 Measuring the effects of non-identicaldata distribution for federated visual classification,2019, CoRR
 Advancesand open problems in federated learning,2019, arXiv preprint arXiv:1912
 SCAFFOLD: stochastic controlled averaging for on-device federatedlearning,2019, CoRR
 Unifiedanalysis of stochastic gradient methods for composite convex and smooth optimization,2020, arXivpreprint arXiv:2006
 Federated optimization:Distributed machine learning for on-device intelligence,2016, arXiv preprint arXiv:1610
 Learning multiple layers of features from tiny images,2009, Technical report
 A survey on wirelessbody area networks,2011, Wireless networks
 Gradient-based learning applied todocument recognition,1998, Proceedings of the IEEE
 On the convergence offedavg on non-iid data,2020, In International Conference on Learning Representations
 A unified analysis of stochastic gradient methods for nonconvexfederated optimization,2020, arXiv preprint arXiv:2006
 Acceleration for compressed gradientdescent in distributed and federated optimization,2020, arXiv preprint arXiv:2002
 Convergence rate of distributed admm over networks,2017, IEEETransactions on Automatic Control
 Fromlocal sgd to local fixed point methods for federated learning,2020, arXiv preprint arXiv:2004
 Distributed learningwith compressed gradient differences,2019, arXiv preprint arXiv:1901
 Primal-dualaccelerated gradient methods with small-dimensional relaxation oracle,2020, Optimization Methods andSoftware
 Fedsplit: An algorithmic framework for fast federatedoptimization,2020, arXiv preprint arXiv:2005
 Adaptive federated optimization,2020, arXiv preprintarXiv:2003
 Local SGD converges fast and communicates little,2019, International Conferenceon Learning Representations (ICLR)
 Group normalization,2018, In Proceedings of the European conference oncomputer vision (ECCV)
 A review on energy efficient protocols in wireless sensornetworks,2016, Wireless Networks
 Federated accelerated stochastic gradient descent,2020, arXiv preprintarXiv:2006
 Bayesian nonparametric federated learning of neural networks,2019, In InternationalConference on Machine Learning
 Fedpd: A federated learningframework with optimal rates and adaptivity to non-iid data,2020, arXiv preprint arXiv:2005
 Federatedlearning with non-iid data,2018, arXiv preprint arXiv:1806
6 and ,2021,3 priors
 Multiplying both sides with n2 gives theinequality,2021, â–¡Lemma 7
 9 and 8,2021, The following inequalities aredue to Lemma 6
