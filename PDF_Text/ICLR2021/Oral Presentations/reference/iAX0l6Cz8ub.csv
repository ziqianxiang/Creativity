title,year,conference
 Curriculum adversarial training,2018, In IJCAI
 Towards evaluating the robustness of neural networks,2017, InSymposium on Security and Privacy (SP)
 Unlabeleddata improves adversarial robustness,2019, In NeurIPS
 Adversarialrobustness: From self-supervised pre-training to fine-tuning,2020, In CVPR
 Robust overfittingmay be mitigated by properly learned smoothening,2021, In ICLR
 Cat: Customized adver-sarial training for improved robustness,2020, arXiv:2002
 Certified adversarial robustness via random-ized smoothing,2019, In ICML
 Reliable evaluation of adversarial robustness with an ensembleof diverse parameter-free attacks,2020, In ICML
 Mma training: Directinput space margin maximization through adversarial training,2020, In ICLR
 The robustness of deepnetworks: A geometrical perspective,2017, IEEE Signal Processing Magazine
 Empiricalstudy of the topology and geometry of deep networks,2018, In CVPR
 Uncovering thelimits of adversarial training against norm-bounded adversarial examples,2020, arXiv:2010
 Deep residual learning for image recog-nition,2016, In CVPR
 Support vectormachines,1998, IEEE Intelligent Systems and their applications
 Using pre-training can improve model robustnessand uncertainty,2019, In ICML
 Robust pre-training by adversarialcontrastive learning,2020, In NeurIPS
 Geometric robustness of deepnetworks: analysis and improvement,2018, In CVPR
 Learning multiple layers of features from tiny images,2009, Technical report
 Focal loss for dense objectdetection,2017, In ICCV
 DistribUtionalsmoothing by virtUal adversarial examples,2016, In ICLR
 Read-ing digits in natUral images with UnsUpervised featUre learning,2011, In NeurIPS Workshop on DeepLearning and Unsupervised Feature Learning
 Deep neUral networks are easily fooled: High confi-dence predictions for Unrecognizable images,2015, In CVPR
 Towards the science ofsecUrity and privacy in machine learning,2016, arXiv:1611
 Adversarial robUstness throUgh locallinearization,2019, In NeurIPS
 Overfitting in adversarially robUst deep learning,2020, InICML
 Hydra: PrUning adversarially robUstneUral networks,2020, NeurIPS
 Very deep convolUtional networks for large-scale imagerecognition,2015, In ICLR
 Improving adversarial robUstnessthroUgh progressive hardening,2020, arXiv:2003
 IntrigUing properties of neUral networks,2014, In ICLR
 80 million tiny images: A large data set fornonparametric object and scene recognition,2008, IEEE transactions on pattern analysis and machineintelligence
 Lipschitz-Margin training: Scalable certifica-tion of perturbation invariance for deep neural networks,2018, In NeurIPS
 On theconvergence and robustness of adversarial training,2019, In ICML
 Improvingadversarial robustness requires revisiting misclassified examples,2020, In ICLR
 Provable defenses against adversarial examples via the convex outeradversarial polytope,2018, In ICML
 A closer look at accuracy vs,2020, robustness
 Wide residual networks,2016, arXiv:1605
 Understandingdeep learning requires rethinking generalization,2017, In ICLR
 Towards stable and efficient training of verifiably robust neural networks,2020, InICLR
 Attacks which do not kill training make adversarial learning stronger,2020, In ICML
 Understanding the interaction of adversarial training with noisylabels,2021, arXiv:2102
 The training setting keepsthe same as that of CIFAR-10 experiments except using 0,2020,01 as the initial learning rate
9 momentum for 100epochs,2021, The initial learning rate is 0
