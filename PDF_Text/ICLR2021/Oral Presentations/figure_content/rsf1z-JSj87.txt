Figure 1: A diagram of the generator, including themonotonic interpolation-based aligner. z and chdenote the latent Gaussian vector and the numberof output channels, respectively. During training,audio windows have a fixed length of 2 secondsand are generated from the conditioning text usingrandom offsets η and predicted phoneme lengths;the shaded areas in the logits grid and waveformare not synthesised. For inference (sampling), weset η = 0. In the No Phonemes ablation, the phone-mizer is skipped and the character sequence is feddirectly into the aligner.
Figure 2: Dynamic time warp-ing between two sequencesfinds a minimal-cost align-ment path. Positions wherewarping occurs are markedwith a border.
Figure 3:	Pseudocode for our proposed EATS aligner.
Figure 4:	TensorFlow code for mel-spectrogram computation.
Figure 5:	Pseudocode for dynamic time warping.
Figure 6: Positions of the tokens over time for 128 utterances generated from the same text, withdifferent latent vectors z. Close-ups of the start and end of the sequence show the variability of thepredicted lengths.
Figure 7: Histogram of lengths for 128 utterances generated from the same text, with different latentvectors z.
