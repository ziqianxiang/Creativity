Figure 1: Curricula help for time limited or noisy training, but not standard training. Each point repre-sents an independent learning ordering on CIFAR100 and is a mean over three independent runs with the samehyper-parameters. Color represents the type of learning, from bottom to top, are standard i.i.d. training (grey),curriculum (blue), anti-curriculum (purple), and random curriculum (green). The solid orange line is the besttest accuracy for standard i.i.d. training. The left, middle and right plots represent standard-time, short-time,and noisy training. We find that for the original dataset and learning constraints there are no statistically sig-nificant benefits from anti, random, or curriculum learning (left). We find that for training with a limited timebudget (center) or with noisy data (right) curriculum learning can be beneficial.
Figure 2: Implicit Curricula: Images are learned in a similar order for similar architectures and train-ing methods. (Left) Epoch/Iteration at which each image is learned across 142 different architectures andoptimization procedures. Each row is a CIFAR10 image ordered by its average learned epoch. The columnsfrom left to right, are fully-connected (FC) nets, VGG nets (VGG11 and VGG19), and nets with Batch-Norm(Ioffe & Szegedy, 2015) including ResNet18, ResNet50, WideResNet28-10, WideResNet48-10 DenseNet121,EfficientNet B0, VGG11-BN and VGG19-BN. (Right) The Spearman correlation matrix shows high correlationbetween orderings within architecture families.
Figure 3: Scoring functions show a high correlation for the standard training, but perceived difficultydepends on the training order. (Left) Six scoring functions computed on CIFAR10 using the standard i.i.d.
Figure 4: Pacing functions (Left) pacing function definitions for the siχ families of pacing functions usedthroughout. (Right) eχample, pacing function curves from each family. The parameter a determines the fractionof training time until all data is used. The parameter b sets the initial fraction of the data used.
Figure 6: Curriculum-learning helps when training with a limited time budget. CIFAR100 performancewhen training with 17600, 1760 and 352 total steps (see Figure 17 for CIFAR10). Curriculum learning providesa robust benefit when training for 1760 and 352 steps. See Figure 5 for additional plotting details.
Figure 7: Curriculum-learning helps when training with noisy labels. Performance on CIFAR100 with thefunctions from the six families considered for CIFAR100 (from left to right) finite time training with 1760 and352 steps, 20% label noise and 60% label noise.
Figure 9: Label noise and limited training time shift the c-score distributions towards more difficultexamples. We compute loss-based c-score for limited time training on CIFAR10 (top left three), CIFAR100(top right three) and for CIFAR100 models trained with label noise (bottom row).
Figure 10: Large data regime - FOOD101 and FOOD101N. (a) Bar plots showing the best mean accu-racy, for curriculum (blue), anti-curriculum (purple), random-curriculum (green), and standard i.i.d. training(grey) with three ways of calculating the standard training baseline for FOOD101 standard-time training (left),FOOD101 short-time training (middle), and FOOD101N training (right)4. (b) For FOOD101 standard-timetraining (left), we plot the means over three seeds for all 540 strategies, and 180 means over three standardtraining runs (grey). For FOOD101 short-time training (middle), we plot the means over three seeds for all 216strategies, and 72 means over three standard training runs. For FOOD101N (right), we reported the values forall 216 strategies and 72 standard training runs. See Figure 5 for additional details. In FOOD101 standard-time training, we observe no statistically significant improvement from curriculum, anti-curriculum, or randomtraining. However, for FOOD101 short-time training and FOOD101N training, CL provides a robust benefit.
Figure 11: The top figure plots the 0 (dark blue) and 1 (yellow) prediction for the images (y-axis) during theiterations (x-axis). The bottom figure plots the corresponding loss values. The images belong to class 9 in thetesting set of CIFAR10. We use the standard time training with batch-size 256 (Section B) and record the lossand 0-1 predication every 30 iterations.
Figure 12: The left plot is the visualization of the ten orderings of CIFAR10 using the standard i.i.d. trainingalgorithms (a) L10.V, L60.V and L200.V: the loss function of VGG11 at epoch 10, 60 and 200. (b) L10.R:the loss function by ResNet18 at epoch 10, 60 and 200. (c) T.Vgg: the learned iteration by VGG-11 (d)learnT.ResNet: the learned iteration by ResNet18 (f) C.ResNet: the c-score by ResNet18 with much less com-putation than (e). The Spearman correlation matrix for the orderings is plotted on the right. Note that we selectL10.V, L10.R and the last four ordering to present in Figure 3.
Figure 13: The left plot is the visualization of the ten orderings of CIFAR10 using the standard i.i.d. training al-gorithms, curriculum, anti-curriculum and random-curriculum learning. All columns but the last four are usingthe loss function as scoring metric (a) 1-9 columns are VGG11 at epoch 2, 10, 30, 60, 90, 120, 150, 180, 200.
Figure 14: Visualization of the six types of pacing functions for T = 39100 and N = 50000 with a ∈{0.01, 0.1, 0.2, 0.4, 1.0, 1.6} and b ∈ {0.0025, 0.1, 0.2, 0.4, 1.0}.
Figure 15: This figure describes the key hyper-parameters used for each of the columns in Figure 3. Forexample, the first top left: 1seed_111 - archfc1000 - adam corresponds to the result of 1st column in Figure3 where we use random seed 111 and fully-connected layers with Adam as an optimizer. The ambiguous onewhere there is adam.1, means that we use twice a longer time than those with configuration ends with adam.
Figure 16: Standard time training for CIFAR100 with total 39100 steps. The training setup is different fromthe figures in the main sections, where we trained 45000 images and then use 5000 validation images to pickthe best test accuracy. Here, we use the entire training samples 50000 and directly pick the best test accuracyfrom these 5000 test samples. Thus, the accuracy is higher in general. The left bar (dot) plot uses the normalincreasing pacing functions. The right bar (dot) plot uses the reverse pacing functions (see the 5th plot for anexample). That is, we start with a full data set and then slowly discard the images in [g(t), N] as g(t) is nowdecreasing. See Figure 5 for detailed description for each plot.
Figure 17: Short time training for CIFAR10 with total steps equal to 19550, 3910 and 391 (see x-label). SeeFigure 5 for detailed description for each plot.
Figure 18: Top performing pacing functions for noisy training. Top performing pacing functions from the sixfamilies considered for CIFAR100 with 40% label noise (left) and 80% label noise (right).
Figure 19: Standard time training with steps 35200. The top panel is for CIFAR10 and the bottom forCIFAR100. In each panel, we have 3 × 6 plots where each row from 1st to 3nd are random-curriculum, anti-curriculum, and curriculum learning (see the y-label). Each column means the type of pacing functions: from1st to the 6th are exponential, linear, log quadratic, root, and step basic functions (see x label). Each plotinside a panel is a heat-map for the parameter a ∈ {0.01, 0.1, 0.2, 0.4, 1.0, 1.6} at x-axis and the parameterb ∈ {0.0025, 0.1, 0.2, 0.4, 1.0} at y-axis describing the best accuracy for the corresponding (x, y) = (a, b).
Figure 20: CIFAR10 short time training. Top, middle and bottom panels are total steps 17600, 1760 and 352.
Figure 21: CIFAR100 short-time training. Top, middle and bottom panels are total steps 17600, 1760 and352. See Figure 19 for detailed description.
Figure 22: Noisy training for CIFAR100 with 35200 steps. From top to bottom plots are for 20%, 40%, 60%and 80% label noise; See Figure 19 for detailed description.
