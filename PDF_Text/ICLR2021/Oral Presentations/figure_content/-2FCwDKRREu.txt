Figure 1: Robust representa-tions of the visual scene shouldbe insensitive to irrelevant objects(e.g., clouds) or details (e.g., cartypes), and encode two observa-tions equivalently if their relevantdetails are equal (e.g., road direc-tion and locations of other cars).
Figure 2: Learning a bisimulation metric represen-tation: shaded in blue is the main model architecture,it is reused for both states, like a Siamese network.
Figure 3: Left observations: Pixel observations in DMC in the default setting (top row) of the finger spin (leftcolumn), cheetah (middle column), and walker (right column), with simple distractors (middle row), and naturalvideo distractors (bottom row). Right training curves: Results comparing out DBC method to baselines on 10seeds with 1 standard error shaded in the default setting. The grid-location of each graph corresponds to thegrid-location of each observation.
Figure 4: t-SNE of latent spaces learned with a bisimulation metric (left t-SNE) and VAE (right t-SNE)after training has completed, color-coded with predicted state values (higher value yellow, lower value purple).
Figure 5: Generalization of a model trained on simple distractors environment and evaluated onkinetics (left). Generalization of an encoder trained on walker_walk environment and evaluated onwalker_stand (center) and walker_run (right), all in the simple distractors setting. 10 seeds, 1standard error shaded.
Figure 6: Bisim. results. Blue is DBCand orange is Castro (2020).
Figure 8: A t-SNE diagram of encoded first-person driving observations after 10k training steps of Algorithm 1,color coded by value (V in Algorithm 2). Top: the learned representation identifies an obstacle on the rightside. Whether that obstacle is a dark wall, bright car, or truck is task-irrelevant: these states are behaviourallyequivalent. Left: the ego vehicle has flipped onto its left side. The different wall colors, due to a setting sun, isirrelevant: all states are equally stuck and low-value (purple t-SNE color). Right: clear highway driving. Cloudsand sun position are irrelevant.
Figure 9: Performance comparison with 3 seeds on thedriving task. Our DBC method (red) performs betterthan DeepMDP (purple) or learning direct from pixelswithout a representation (SAC, green), and much betterthan contrastive methods (blue). Our methodâ€™s finalperformance is 46.8% better than the next best baseline.
Figure 10:	Causal graph of transition dynamics. Reward depends only on s1 as a causal parent, but s1causally depends on s2, so AN(R) is the set {s1, s2}.
Figure 11:	Results for DBC in the default setting, in comparison to baselines with reconstruction loss,contrastive loss, and SLAC on 10 seeds with 1 standard error shaded.
Figure 12:	Results for DBC in the simple distractors setting, in comparison to baselines withreconstruction loss, contrastive loss, DeepMDP, and SLAC on 10 seeds with 1 standard error shaded.
Figure 13:	Results for our bisimulation metric method in the natural video setting, in comparison tobaselines with reconstruction loss, contrastive loss, DeepMDP, and SLAC on 10 seeds with 1 standarderror shaded.
Figure 14: t-SNE of latent spaces learned with a bisimulation metric after training has completed, color-codedwith predicted state values (higher value yellow, lower value purple). Neighboring points (right) in the embeddingspace learned with a bisimulation metric have similar encodings (middle). When we sample from the same latentpoint, and average the images, we see the robot configuration is crisp, meaning neighboring points encode theagent in similar positions, but the backgrounds are very different, and so are blurry when averaged.
