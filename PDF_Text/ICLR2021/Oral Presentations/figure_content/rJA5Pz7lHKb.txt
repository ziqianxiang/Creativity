Figure 1: Overview of our method. From a data distribution (x) We inject noise (q(X∣x)) whichmakes the distribution smoother (X); then we model the smoothed distribution (pθ(X)) as well as thedenoising step (p0(x∣X)), forming a two-step model.
Figure 2: Manifold hypothesis illustration. The data point is travelling along the diagonal as shownin the leftmost panel. The white arrow stands for the direction and magnitude of the derivative ofdensity at the data point. The data location for each figure is (vz0.5 + c, V0^ + c), where C is thenumber below each figure and (Vz0.5, a/0.5) is the upper right intersection of the trajectory with theunit circle.
Figure 3: Visualization of a 1-d data distribution without smoothing (a) or with smoothing (b),modeled by the same mixture of logistics model.
Figure 4: Density estimation on 1-d synthetic dataset. In the second figure, the digit in the paren-thesis denotes the number of mixture components used in the baseline mixture of logistics model.
Figure 5: Samples on 2-d synthetic datasets. We use a MADE model With comparable number ofparameters for both our method and the baseline. Our model uses 3 mixture of logistics, While thebaseline uses 6 (more) mixture of logistics.
Figure 6: From left to right: Column 1: samples from pθ(X). Column 2: "single-step denoising”samples from pθ(X). Column 3: samples from pθ(x|X). Column 4: samples from the baselinePixelCNN++ model. Samples in Column 2 (“single-step denoising”) contain wild pixels and areless realistic compared to samples in Column 3 (modeled by another PixelCNN++). None of thesamples are conditioned on class labels.
Figure 7: RealNVP samples on 2-d synthetic datasets. The RealNVP model trained with randomizedsmoothing is able to generate better samples according to human observers.
Figure 8: 1-d single-step (gradient based) denoising.
Figure 9: 1-d single-step (gradient based) denoising.
Figure 10: Denoising with pθ(x|X), which is modeled by one mixture of logistics.
Figure 11: Denoising with pθ (x|X), which is modeled by two mixtures of logistics.
Figure 12: Samples on 2-d synthetic datasets. We use a MADE model with comparable number ofparameters for both our method and the baseline. The models have n mixture of logistics for eachdimension. Our method is able to obtain reasonable samples when using fewer mixture components,while the baseline still has trouble modeling the two sides of the rings when n = 7.
Figure 13: Single-step denoising results on 2-d synthetic datasets. We use the same MADE modelwith three mixture components and the same smoothing distribution as mentioned in Section 4.2.
Figure 14: Inpainting results from our two-step method. The bottom half of the images are maskedfor inpainting.
Figure 15: Denoising withpθ(x|x)18Published as a conference paper at ICLR 2021C.4 More samplesFigure 16: CIFAR-10 samples from pθ(X) (unconditioned on class labels).
Figure 16: CIFAR-10 samples from pθ(X) (unconditioned on class labels).
Figure 17: CIFAR-10 samples frompθ(x|X) (unconditioned on class labels).
Figure 18: CIFAR-10 samples from the original PixelCNN++ method (unconditioned on class la-bels).
Figure 19: CelebA samples from pθ (X) (unconditioned on class labels).
Figure 20: CelebA samples from p (x|X) (unconditioned on class labels).
Figure 21: CelebA samples from the original PixelCNN++ method (unconditioned on class labels).
Figure 22: Nearest neighbors measured by the `2 distance between images. Images on the left ofthe red vertical line are samples from our model. Images on the right are nearest neighbors in thetraining dataset.
Figure 23: Nearest neighbors measured by the `2 distance in the feature space of an Inception V3network pretrained on ImageNet. Images on the left of the red vertical line are samples from ourmodel. Images on the right are nearest neighbors in the training dataset.
Figure 24: Nearest neighbors measured by the `2 distance between images. Images on the left ofthe red vertical line are samples from our model. Images on the right are nearest neighbors in thetraining dataset.
Figure 25: Nearest neighbors measured by the `2 distance in the feature space of an Inception V3network pretrained on ImageNet. Images on the left of the red vertical line are samples from ourmodel. Images on the right are nearest neighbors in the training dataset.
Figure 26: “Single-step denoising” on PixelCNN++ trained on un-smoothed data. σ = 0 corre-sponds to the original samples.
