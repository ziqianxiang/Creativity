Figure 1: Correspondence between Hop-field Networks (HNs) with correlated pat-terns and binary-gaussian restricted boltz-mann machines (RBMs). The HN has Nbinary units and pairwise interactions J de-fined by p < N (possibly correlated) pat-terns {ξμ}μ=ι. The patterns are encoded asminima of Eq. (1) through the projectionrule J = ξ(ξTξ)-1ξT, where ξμ form thecolumns of ξ. We orthogonalize the patternsthrough a QR decomposition ξ = QR. TheHN is equivalent to an RBM with N binaryvisible units and p gaussian hidden units withinter-layer weights defined as the orthogonal-ized patterns Qiμ, and Hamiltonian Eq. (6).
Figure 2: Hopfield RBM generative perfor-mance as a function of β for varying numbersof encoded sub-patterns k per digit. The num-ber of hidden units in each RBM is p = 10k,corresponding to the total number of encodedpatterns. ln Z is computed using annealed im-portance sampling (AIS) (Neal, 2001) on thecontinuous representation of Z, Eq. (7), with500 chains for 1000 steps (see Appendix E).
Figure 3: Binary-gaussian RBM weights for p = 10 hidden units prior to and during generativetraining. (a) Initial values of the columns of W (specified as the orthogonalized Hopfield patternsvia Eqs. (2), (14)). (b) Same columns of W after 50 epochs of CD-20 training (see Fig. 4(a)).
Figure 4: Generative performance of binary-gaussian RBMs trained with (a) p = 10 and (b) p = 50hidden units. Curves are colored according to the choice of weight initialization (see legend in (b),and further detail in the preceding text). Each curve shows the mean and standard deviation over5 runs. The inset in (a) details the first two epochs. We compute lnpθ as in Fig. 2, but with 100AIS chains. The learning rate is η0 = 10-4 except the first 25 epochs of the randomly initializedweights in (b), where we used η = 5η0 due to slow training. The mini-batch size is B = 100 for allcurves in (b) and the purple curve in (a), and B = 1000 otherwise. (c), (d) Samples from two RBMsfrom (b) (projection HN and random) after 15 epochs, generated by initializing the visible state toan example image from the desired class and performing 20 RBM updates with β = 2. Trainingparameters: β = 2, and CD-20.
Figure 5: Product-of-experts classificationperformance for the various weight initializa-tions. For each digit model (expert), we per-form CD-20 training according to Eq. (15)(as in Fig. 4) for a fixed number of epochs.
