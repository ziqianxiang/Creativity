Figure 1: Solving a reverse-time SDE yields a score-basedgenerative model. Transform-ing data to a simple noise dis-tribution can be accomplishedwith a continuous-time SDE.
Figure 2: Overview of score-based generative modeling through SDEs. We Can map data to anoise distribution (the prior) with an SDE (Section 3.1), and reverse this SDE for generative modeling(SeCtion 3.2). We Can also reverse the assoCiated probability flow ODE (SeCtion 4.3), whiCh yields adeterministiC proCess that samples from the same distribution as the SDE. Both the reverse-time SDEand probability flow ODE can be obtained by estimating the score Vx logPt(X) (Section 3.3).
Figure 3: Probability flow ODE enables fast sampling with adaptive stepsizes as the numericalprecision is varied (left), and reduces the number of score function evaluations (NFE) without harmingquality (middle). The invertible mapping from latents to images allows for interpolations (right).
Figure 4: Left: Class-conditional samples on 32 X 32 CIFAR-10. Top four rows are automobiles andbottom four rows are horses. Right: Inpainting (top two rows) and colorization (bottom two rows)results on 256 X 256 LSUN. First column is the original image, second column is the masked/gray-scale image, remaining columns are sampled image completions or colorizations.
Figure 5: Discrete-time perturbation kernels and our continuous generalizations match each otheralmost exactly. (a) compares the variance of perturbation kernels for SMLD and VE SDE; (b)compares the scaling factors of means of perturbation kernels for DDPM and VP SDE; and (c)compares the variance of perturbation kernels for DDPM and VP SDE.
Figure 6: Samples from the probability flow ODE for VP SDE on 256 ^ 256 CelebA-HQ. Top:spherical interpolations between random samples. Bottom: temperature rescaling (reducing norm ofembedding).
Figure 7:	Comparing the first 100 dimensions of the latent code obtained for a random CIFAR-10image. “Model A” and “Model B” are separately trained with different architectures.
Figure 8:	Left: The dimension-wise difference between encodings obtained by Model A and B. As abaseline, we also report the difference between shuffled representations of these two models. Right:The dimension-wise correlation coefficients of encodings obtained by Model A and Model B.
Figure 9: PC sampling for LSUN bedroom and church. The vertical axis corresponds to the totalcomputation, and the horizontal axis represents the amount of computation allocated to the corrector.
Figure 10: The effects of different architecture components for score-based models trained with VEperturbations.
Figure 11: Unconditional CIFAR-10 samples from NCSN++ cont. (deep, VE).
Figure 12: Samples on 1024 X 1024 CelebA-HQ from a modified NCSN++ model trained with theVE SDE.
Figure 13: Class-conditional image generation by solving the conditional reverse-time SDE with PC.
Figure 14: Extended inpainting results for 256 X 256 bedroom images.
Figure 15: Extended inpainting results for 256 X 256 church images.
Figure 16: Extended colorization results for 256 X 256 bedroom images.
Figure 17: Extended colorization results for 256 X 256 church images.
