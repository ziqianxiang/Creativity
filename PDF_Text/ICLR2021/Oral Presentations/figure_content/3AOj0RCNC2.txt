Figure 1: Illustration of convolution operation in matrix multiplication format during (a) ForwardPass and (b) Backward Pass.
Figure 2: (a) Memory utilization and (b) per epoch training time for PMNIST tasks for differentmethods. Memory utilization for different approaches for (c) CIFAR-100, (d) miniImageNet and (e)5-Datasets tasks. For memory, size of GPM-Max and for time, method with highest complexity isused as references (value of 1). All the other methods are reported relative to these references.
Figure 3: Histograms of interference activations as a function of threshold, (th) at (a) Conv layer 2(b) FC layer 2 for split CIFAR-100 tasks. (c) Impact of th on ACC (%) and BWT(%). With increas-ing value of th, spread of interference reduces, which improves accuracy and reduces forgetting.
Figure 4:	Evolution of task 1 accuracy over the course of incremental learning of 20 sequential tasksfrom miniImageNet dataset. Learned accuracy in our method remains stable throughout learning.
Figure 5:	Illustration of how threshold hyperparameter controls the degree of interference at (a)Conv layer 1 (b) Conv layer 3 (c) FC layer 1 with the histogram plots of interference activationsfrom Split CIFAR-100 experiment. With increasing th, spread of the inference activation decreasesresulting in minimization of forgetting.
