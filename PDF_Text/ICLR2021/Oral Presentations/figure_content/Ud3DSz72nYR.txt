Figure 1: The ESP model provides a estimate of the agent’s Q-function for any state-action pair.
Figure 2: Reward learning curves (top row) and GVF Loss learning curves (bottom row) for thedifferent agents in three environments. We show the mean +/- std over 10 independent runs.
Figure 3: Explanation examples for Lunar Lander (left) and CartPole (right). Each example showsthe game state, the Q-values and GVF predictions for actions, and the IGX and MSX.
Figure 4: Example Explanations for Tug-of-War 17 feature ESP-DQN agent. Each row is a decisionpoint showing: (left) game state; (middle) Q-values and GVFs for preferred action and a non-preferredaction; (right) IGX for action pair and corresponding MSX (indicated by highlighted bars). For Game1 (top) the agent’s preferred action is +4 Marine, +1 Baneling in Top Lane and the non-preferredaction is +10 Marine, +1 Baneling on Bottom. For Game 2 (bottom) the highest ranked action is +1Baneling in Bottom Lane and sub-optimal action is +2 Marine, +4 Baneling in Bottom Lane.
Figure 5: (left) Tug of War game map - Top lane and bottom lane, Player 1 owns the two bases on theleft (gold star-shaped buildings), Player 2 owns the two bases on the right. Troops from opposingplayers automatically march towards their opponent’s side of the map and attack the closest enemy intheir lane. (right) Unit Rock Paper Scissors - Marines beats Immortals, Immortals beats Banelings,and Banelings beats Marines. We have adjusted unit stats in our custom Starcraft 2 map to befitToW’s balance.
Figure 6: ToW 2 Lane 4 Grid - Unit quantities and positions on the map is descretized into foursections per lane.
Figure 7: Explanation example for Cart Pole. Three Figures show the game state, the Q-valuesandGVF predictions for actions, and the IGX and MSX respectively.
Figure 8: Explanation example for Lunar Lander. Three Figures show the game state, the Q-valuesand GVF predictions for actions, and the IGX and MSX respectively.
Figure 9: Explanation example for Tug-of-War 17 feature ESP-DQN agent. Three Figures show thegame state, the Q-values and GVF predictions for actions, and the IGX and MSX respectively. Thetop ranked action +2 Baneling in Bottom Lane and sub-optimal is +1 Immortals in Top Lanedefense. However, the MSX bar shows positive IGX of the self bottom Baneling damage still cancover the negative IGX of enemy top Baneling damage; indicating the agent is focusing on destroyingthe enemy’s bottom base while ignoring the damage its top base will take. This misjudgement can beattributed to the agent over-fitting to its fixed-agent opponent during training.
Figure 10: Explanation example for Tug-of-War 131 feature ESP-DQN agent. Since there are toomuch features to show as one figure, we separate them into 11 clusters. Three Figures show the gamestate, the Q-values and GVF predictions for actions, and the IGX and MSX respectively. The topranked action +8 Marines in Bottom Lane and sub-optimal is +5 Banelings in Bottom Lane.
