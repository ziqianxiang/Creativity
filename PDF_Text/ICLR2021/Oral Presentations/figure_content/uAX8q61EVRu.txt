Figure 1: System Overview. Given the source and listener position and orientation c1:T at eachtime step, a single-channel input signal x1:T is transformed into a binaural signal. The neural timewarping module learns an accurate warp from the source position to the listeners left and right earwhile respecting physical properties like monotonicity and causality. The Temporal ConvNet modelsnuanced effects like room reverberations or head- and ear-shape related modifications to the signal.
Figure 2: Expected amplitude and phase error from Lemma 1 as a function of '2-value ε and targetsignal energy |Y |.
Figure 3: Development of phase- and amplitude)pma(554332.................
Figure 4: Analysis of the warping module.
Figure 5: Training loss of a model with hyper-convolutions and a model with standard convolutions. Hyper-convolutions lead to a significantly faster convergence. Table 3: Comparison to state of the art approaches for binaural sound synthesis.				raw waveform (`2 error ×103)	power spectrum (`2 error)	phase spectrum (angular error)DSP	0.485	0.058	1.3882.5D Sound	1.085	0.113	1.519WaveNet	0.237	0.048	1.239ours	0.167	0.048	0.807Table 4: Mean opinion scores of different approaches. Participants were ask to rank cleanliness,spatialization, and overall realism on a Likert scale from 1 to 5.
Figure 6: Graphical illustration of the premises for Lemma 1 on the complex plane. Y is the target,Y is a prediction with distance ε to Y. The amplitude error is defined as ||Y | - | Y || and the phaseerror is the difference between θγ and θγ.
Figure 7: (a) Side view of capture layout. (b) Top view of capture layout. A participant moves arounda KEMAR mannequin within the boundaries of a marked circle. The participant speech is recordedwith a head mounted microphone and the binaural audio is captured with binaural microphones onthe ears of the mannequin. Mannequin and participant positions are tracked with OptiTrack camerasmounted on the walls of the room.
Figure 8: Qualitative results on the raw waveform. Note that 2.5D visual sound - besides havingan overall inaccurate waveform reconstruction - fails to get an accurate alignment to the binauralrecording. Compared to all state of the art, our approach matches the real binaural recordings best.
