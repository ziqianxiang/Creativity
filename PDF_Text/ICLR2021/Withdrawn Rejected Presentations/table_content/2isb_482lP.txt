Table 1: Comparison of various models on Cora, Citeseer and Pubmed.
Table 2: Dataset StatisticsDatasets	Nodes	Edges	Classes	Features	Traing/Validation/Testing splitCora	2,708	5,429	7	1,433	1,208/500/1,000Citeseer	3,327	4,732	6	3,703	1,812/500/1,000Pubmed	19,717	44,338	3	500	18,217/500/1,000A.2 Hyper-parameter DescriptionTable 3: Hyper-parameter DescriptionHyper-parameter	Descriptionlr	learning ratehidden layers	the number of hidden layersweight-decay	L2 regulation weightdropout	dropout ratefrequencies	the number of low frequencies to addeigenvector features normalization whether to normalize the new MLP featuresin line (per nodes) or column (per features)A.3 On the choice of the normalizationGCNs defined in Kipf & Welling (2016) don’t exactly used the first order Laplacian approximation,11but introduce a normalization trick : A = (D + IN)-2 (A + IN)(D + IN)-2. Using the Stan-dard hyper-parameters defined in Section 4, we averaged our results on 3 seeds and observed no
Table 3: Hyper-parameter DescriptionHyper-parameter	Descriptionlr	learning ratehidden layers	the number of hidden layersweight-decay	L2 regulation weightdropout	dropout ratefrequencies	the number of low frequencies to addeigenvector features normalization whether to normalize the new MLP featuresin line (per nodes) or column (per features)A.3 On the choice of the normalizationGCNs defined in Kipf & Welling (2016) don’t exactly used the first order Laplacian approximation,11but introduce a normalization trick : A = (D + IN)-2 (A + IN)(D + IN)-2. Using the Stan-dard hyper-parameters defined in Section 4, we averaged our results on 3 seeds and observed nosignificant difference across datasets, as shown in Fig. 8.
