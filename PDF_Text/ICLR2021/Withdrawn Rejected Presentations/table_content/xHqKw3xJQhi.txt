Table 1: Average test accuracy (%) for all models (a two-layer vanilla GCN as the backbone) andall datasets under the full-supervised setting. OOM: Out-of-memory error.
Table 2: Average test accuracy (%) and over-smoothness under the label-scarce setting (10 labels perclass) with varying layers. For both metrics, the larger the better. A: Accuracy. S: Over-smoothness.
Table 3: Average test accuracy (%) under differentlabel rates on the Amazon Photo dataset.
Table 4: Summary of dataset statisticsUndirected graph	Directed graphDataset	Cora	Citeseer	Pubmed Cora-ML		Amazon Photo	Amazon Computers	MS Academic# Nodes	2708	3312	19717	2995	7650	13752	18333# Edges	5278	4536	44324	8416	143662	287209	163788# Features	1433	3703	500	2879	745	767	6805# Classes	7	6	3	7	8	10	15latent graph to approximate its posterior distribution based on SBM in the E-step, and trains a GCNbased on the latent graph in the M-step.
Table 5: Hyperparameter setting for the results in Table 1. λ(aiojbs = 0) = 1 and λ(aiojbs = 1) = λ.
Table 6: Average test accuracy (%) and over-smoothness under the label-scarce setting (10 labels perclass) with varying layers. For both metrics, the larger the better. A: Accuracy. S: Over-smoothness.
Table 7: Average test accuracy (%) of GCNII and VEM-GCNII on the three citation networks underthe label-scarce setting (10 labels per class). The number in parentheses denotes the number oflayers.
