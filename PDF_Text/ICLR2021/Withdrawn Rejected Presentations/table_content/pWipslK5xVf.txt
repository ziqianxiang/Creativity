Table 1: Average test accuracy (%) on the CIFAR-10/100 dataset over the last 10 epochs with various noise corruptions. The symbol ? indicates scores provided by the corresponding authors. WDNcot denotes our WDN combined with a co-teaching network. The best results are boldfaced.			Methods	Symmetric 20%	Symmetric 50%	Asymmetric 45%Vanilla	71.91 ± .43/40.44 ± .36	49.54 ± .41/21.34 ± .27	49.06 ± 1.02/31.85 ± .85MentorNet?	80.76 ± .36/52.13 ± .40	71.10 ± .48/39.00 ± 1.00	58.14 ± .38/31.60 ±.51GCE	84.68 ± .05/51.86 ± .09	61.80 ± .11/37.60 ± .08	61.09 ± .18/33.13 ± .14RoG?	84.32	/	58.16	76.67	/	45.42	71.26	/	43.18JoCoR	85.73 ± .19 /53.01 ± .04	79.41 ± .25 /43.49 ± .46	64.21 ± .12/26.51 ± .32NPCL?	84.30 ± .07/55.30 ± .09	77.66 ± .09/42.56 ± .06	-SIGUA?	≤ 84	/	—	≤ 78	/	-	≤ 65	/	-DivideMix	-	81.13 ±.18 / 49.41 ±.25	68.93 ± .33 / 34.24 ± .63WDN	87.40 ± .23 /59.18 ± .29	82.89 ± .13/48.45 ± .27	76.12 ± .29/38.23 ±.31Co-teaching	78.23 ± .27/53.89 ± .09	72.81 ± .20/34.96 ± .50	70.46 ± .58/34.55 ± .12Co-teaching+	80.64 ± .15/56.15 ± .09	58.43 ± .30/37.88 ± .06	70.78 ± .11/32.88 ± .25WDNcot	87.12 ± .16/57.27 ± .33	76.06 ± .28/42.38 ±.28	74.11 ± .35/44.41 ± .37Table 2: Test accuracy on the CIFAR-10 dataset with open-set noisy labels from CIFAR-100.			Methods ∣ Vanilla GCE Co-teaching	Co-teaching+			JoCoR WDNAccuracy ∣ 38.12	46.57		35.77	42.57	47.73	51.28noise levels and efficiently leverage data-dependent statistics. Fig.2 indicates that classificationmodels with more stable data-dependent bounds also induce more stable convergence in test accuracy.
Table 2: Test accuracy on the CIFAR-10 dataset with open-set noisy labels from CIFAR-100.			Methods ∣ Vanilla GCE Co-teaching	Co-teaching+			JoCoR WDNAccuracy ∣ 38.12	46.57		35.77	42.57	47.73	51.28noise levels and efficiently leverage data-dependent statistics. Fig.2 indicates that classificationmodels with more stable data-dependent bounds also induce more stable convergence in test accuracy.
Table 4: Average training time for the 5-epochs (sec) on the CIFAR-10 dataset.
