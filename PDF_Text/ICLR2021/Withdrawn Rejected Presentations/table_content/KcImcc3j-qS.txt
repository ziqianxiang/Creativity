Table 1: OOD detection results. The Laplace Bridge (LB) wins most comparisons with Diagonalsampling and draws even with KFAC sampling w.r.t. both metrics. However, the LB is around400 times faster on average which is the key property of the LB. 1000 samples were drawn fromthe Gaussian over the outputs motivated by Figure 3. The MNIST experiments were done with aLaplace approximation of the entire network while the others only used the last layer. The sametable with error bars is in Appendix D.
Table 2: Contextualization of the timings for the entire predictive process. We find that the LBprovides a significant speed-up of the process as a whole.
Table 4: Results for sampling from all weights instead of just the last layer. Number of sampleswas 100. Sampling all weights and doing a forward pass seems to be worse than using the LaplaceBridge even though it takes much longer.
Table 5: Comparison of the Laplace Bridge Dirichlet mean with other methods to compute the in-tegral over a softmax-Gaussian. We find that the LB is slightly better than the other two methodswhile additionally not only providing an estimate for the integral but also giving a fully parameter-ized Distribution.
Table 6: OOD detection results. Same table as in the main experiments but with error estimates. TheLaplace Bridge (LB) wins most comparisons with Diagonal sampling and draws even with KFACsampling w.r.t. both metrics. However, the LB is around 400 times faster on average. 1000 sampleswere drawn from the Gaussian over the outputs motivated by Figure 3. The (F-, K-, not-)MNISTexperiments were done with a Laplace approximation of the entire network while the others onlyused the last layer. Five runs with different seeds per experiment were conducted. Standard deviationis reported to the third decimal.
