Table 1: Summary of datasets and example video sequences. See Appendix B for details.
Table 2: Analysis of SOTA object-centric representation learning models for MOT. Results shown asmean ± standard deviation of three runs with different random training seeds.
Table D.1: Architecture of VIMON VAE Encoder.
Table D.2: Architecture of VIMON VAE Decoder.
Table E.1: Analysis of SOTA object-centric representation learning models for MOT. Results forthree runs with different random training seeds.
Table E.2: Performance on VMDS challenge sets. Results shown as mean ± standard deviation forthree runs with different random training seeds. Examples sequences for each challenge set shownbelow.
Table E.3: Performance on VMDS OOD test sets. Results shown as mean ± standard deviation forthree runs with different random training seeds. Examples sequences for each o.o.d. set shown below.
Table E.4: Runtime analysis (using a single RTX 2080 Ti GPU). Training: models trained on VMDSfor one hour. Inference: models evaluated on VMDS test set with batch size=1 (10 frames).
Table E.5: Ablation experiments for ViMON on VMDS.
