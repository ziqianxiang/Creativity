Table 1: Negative log likelihood on UCI regression datasets. GP’s and FVBNN’s are included for reference.
Table 2: Calibration error on UCI regression datasets. GP’s and FVBNN’s are included for reference. boldentries contain the best result for the base model. Underlined entries are those with a large difference of ≥ 5between methods.
Table 3: Classification accuracy, NLL, and calibration error on OOD test sets for classification. Each rowcontains a baseline model, with Mixup and PAD variants. Left: Accuracy, Middle: ECE, Right: NLLACCURACY		ECE		NLL		Model	MNIST CIFAR-10	Model	MNIST CIFAR-10	Model	MNIST	CIFAR-10MC Drop	0.61±0.01 0.45±0.01	MC Drop	0.31±0.02 0.38±0.02	MC Drop	2.36±0.26	3.23±0.40MC Drop PAD	0.62±0.01 0.45±0.01	MC Drop PAD	0.07±0.07 0.05±0.01	MC Drop PAD	1.20±0.11	1.69±0.02DE	0.68±0.00 0.52±0.00	DE	0.24±0.01 0.26±0.01	DE	1.52±0.11	2.06±0.03DE PAD	0.60±0.01 0.48±0.01	DE PAD	0.18±0.02 0.14±0.03	DE PAD	1.35±0.07	1.69±0.05R1BNN	0.69±0.03 0.43±0.01	R1BNN	0.10±0.05 0.06±0.02	R1BNN	1.47±0.58	1.76±0.01R1BNN PAD	0.69±0.04 0.45±0.00	R1BNN PAD	0.07±0.04 0.07±0.04	R1BNN PAD	0.98±0.07	1.67±0.01SWAG	0.68±0.01 0.59±0.00	SWAG	0.22±0.01 0.10±0.00	SWAG	1.75±0.18	1.28±0.01SWAG PAD	0.69±0.01 0.59±0.00	SWAG PAD	0.11±0.02 0.17±0.01	SWAG PAD	1.10±0.08	1.33±0.02M	g	0.«	Ot	M	1Λexpected frequencyH H H HAusnbaJ"-p,υΛJ,υsqoaa λi a* M M Mexpected frequency, ∙ ∙ ∙ΛJU,υnbaJJ p,υΛJ,υsqo
Table 4: Equation 5 Ablation: NLLDataset	Regular	Without A	Without B	Without ABHousing	4.32±1.92	4.62±2.31	4.69±2.30	4.70±2.31Concrete	4.98±0.79	4.96±0.73	5.05±0.74	5.05±0.74Energy	3.34±0.86	3.26±1.00	3.34±1.39	3.34±1.39Kin8nm	-0.53±0.09	-0.53±0.09	-0.48±0.11	-0.48±0.11Naval	-0.96±3.39	0.21±3.77	0.31±3.69	0.22±3.20Power	3.18±0.08	3.23±0.10	3.23±0.20	3.23±0.20Wine	1.22±0.07	1.34±0.57	1.72±1.71	1.70±1.66Yacht	3.45±0.14	3.45±0.11	3.41±0.13	3.41±0.13Table 5: Equation 5 Ablation: Calibration ErrorDataset	Regular	Without A	Without B	Without ABHousing	8.38±8.32	9.43±8.22	9.69±8.35	9.70±8.35Concrete	12.78±6.71	14.04±7.44	14.53±7.31	14.53±7.31Energy	6.30±7.71	6.40±7.89	6.53±8.29	6.52±8.30Kin8nm	2.30±1.29	2.24±1.43	2.47±1.61	2.47±1.61Naval	5.52±3.96	5.44±3.08	5.88±3.94	5.65±3.71Power	1.90±1.66	1.97±1.56	1.83±1.76	1.83±1.82Wine	1.39±1.11	0.50±0.31	0.50±0.31	0.48±0.28Yacht	3.58±0.81	3.42±0.74	3.44±0.82	3.44±0.82
Table 5: Equation 5 Ablation: Calibration ErrorDataset	Regular	Without A	Without B	Without ABHousing	8.38±8.32	9.43±8.22	9.69±8.35	9.70±8.35Concrete	12.78±6.71	14.04±7.44	14.53±7.31	14.53±7.31Energy	6.30±7.71	6.40±7.89	6.53±8.29	6.52±8.30Kin8nm	2.30±1.29	2.24±1.43	2.47±1.61	2.47±1.61Naval	5.52±3.96	5.44±3.08	5.88±3.94	5.65±3.71Power	1.90±1.66	1.97±1.56	1.83±1.76	1.83±1.82Wine	1.39±1.11	0.50±0.31	0.50±0.31	0.48±0.28Yacht	3.58±0.81	3.42±0.74	3.44±0.82	3.44±0.82In order to understand the effect of each term in equation 5, we performed an ablation on each termon the MC PAD (MC Dropout + PAD) variant. It can be seen that as more terms are removed fromthe equation, the model performance degrades in both NLL and calibration. The effect is morepronounced for NLL, as the full equation contains the majority of the best performances.
Table 6:	Convolutional architecture used for MNIST experimentsLayersConv2d(1, 32) → BatchNorm → LeakyReLU → MaxPool → Dropout(0.05)Conv2d(32, 64) → BatchNorm → LeakyReLU → MaxPool → Dropout(0.05)Conv2d(64, 128) → BatchNorm → LeakyReLU → MaxPool → Dropout(0.05)Conv2d(128, 256) → BatchNorm → LeakyReLU → AvgPool → Dropout(0.05)FC(128, 128) → ReLU → Dropout(0.1)FC(128, 128) → ReLU → Dropout(0.1)FC(128, 10)Table 7:	Convolutional architecture used for CIFAR-10 experimentsLayersConv2d(3, 32) → BatchNorm → LeakyReLU → MaxPool → Dropout(0.05)Conv2d(32, 64) → BatchNorm → LeakyReLU → MaxPool → Dropout(0.05)Conv2d(64, 128) → BatchNorm → LeakyReLU → MaxPool → Dropout(0.05)Conv2d(128, 256) → BatchNorm → LeakyReLU → AvgPool → Dropout(0.05)Conv2d(256, 256) → BatchNorm → LeakyReLU → AvgPool → Dropout(0.05)FC(128, 128) → ReLU → Dropout(0.1)FC(128, 128) → ReLU → Dropout(0.1)FC(128, 10)12
Table 7:	Convolutional architecture used for CIFAR-10 experimentsLayersConv2d(3, 32) → BatchNorm → LeakyReLU → MaxPool → Dropout(0.05)Conv2d(32, 64) → BatchNorm → LeakyReLU → MaxPool → Dropout(0.05)Conv2d(64, 128) → BatchNorm → LeakyReLU → MaxPool → Dropout(0.05)Conv2d(128, 256) → BatchNorm → LeakyReLU → AvgPool → Dropout(0.05)Conv2d(256, 256) → BatchNorm → LeakyReLU → AvgPool → Dropout(0.05)FC(128, 128) → ReLU → Dropout(0.1)FC(128, 128) → ReLU → Dropout(0.1)FC(128, 10)12Under review as a conference paper at ICLR 2021Algorithm 1: PAD for input spacefor |db | = (XB, VB) dooptimize θ...
Table 8: Negative Log likelihood on 10 years of NY real estate data. The timeline constitutes a real-worldtemporal dataset shiftModel	2010	2011	2012	2013	2014	2015	2016	2017	2018	2019MC Drop	-0.08±0.67	4.570±12.8	36.90±98.3	29.55±75.7 20.22±51.8		9.203±20.6	7.050±17.0 3.647±7.58	0.771±0.97	0.856±0.99MC Drop PAD	0.549±0.26 0.667±0.08		1.096±0.11	1.167±0.30	1.494±0.61	1.552±0.59	1.251±0.54 0.938±0.32 0.626±0.23		0.654±0.26DE	-0.14±0.42	0.628±1.00 3.973±4.74		3.633±3.73 4.189±4.24 4.148±4.46			2.367±2.25 1.773±1.57 0.750±0.53		0.735±0.51DE PAD	0.540±0.04 0.659±0.06 0.971±0.08			1.043±0.10	1.061±0.21	1.217±0.26	0.859±0.11 0.754±0.07 0.656±0.07		0.643±0.07R1BNN	-0.25±0.05	0.367±0.46 3.941±2.52 4.668±2.66 7.047±4.10 6.619±5.01					5.927±2.97 4.548±3.02	1.520±1.87	1.085±1.66R1BNN PAD	0.814±0.01	0.855±0.03	1.026±0.07	1.030±0.06	1.020±0.05	1.228±0.09	0.934±0.02 0.893±0.01	0.844±0.01	0.834±0.01SWAG	4.384±3.41	4.349±3.44 4.426±3.44 4.423±3.39 4.566±3.41				4.781±3.46 4.571±3.75 4.789±3.55 4.818±3.51			4.722±3.56SWAG PAD	0.811±0.06 0.891±0.05		1.163±0.10	1.254±0.21	1.280±0.30	1.570±0.26	1.148±0.40 1.092±0.37	1.025±0.36	1.006±0.25Table 9: Calibration error across 10 years of NY real estate data. The timeline constitutes a real-world temporaldataset shift.
Table 9: Calibration error across 10 years of NY real estate data. The timeline constitutes a real-world temporaldataset shift.
