Table 1: Accuracy on COMPAS data	Test on P*	Test on PFair	0.652±0.013	0.660±0.009Baseline	0.634±0.011	0.668±0.010(white and non-white), resulting in 4 protected groups A ∈ {0, 1, 2, 3, 4}. The task is to predict if adefendant will re-offend, i.e. Y ∈ {0, 1}. We repeat the experiment 100 times, each time splittingthe data into identically distributed 70-30 train-test split, i.e. P for train and test, and obtaining testset from P* by subsampling test data to preserve Y marginals and enforcing equal representationat each of the 4 levels of the protected attribute A. We present results in Table 1. We see that ourtheory holds in practice: accuracy of the fair classifier is 1.8% higher on P*. Baseline is expectedlymore accurate on the biased test data from P, but only by 0.8%.
Table 2: Accuracy on Adult dataP *	PFair 0.852±0.004 0.843±0.003Base 0.848±0.005 0.847±0.003Proof. For notation simplicity define X , ΠF⊥,F⊥ (PA*,V - PA,V ) - PA*,V . We show thatminR∈FhPe, R = (P, R*〉holds if and only if X ∈ NR(R*). Towards that end, fix R ∈ F:.~■	.~hPe, Ri = hPe-P*,Ri + hP*,Ri= hΠFC⊥,F⊥(Pe-P*),Ri + hP*,Ri= h-P* -X,Ri + hP*,Ri= h-X, Ri	(C.2)= h-X, R*i + h-X,R- R*i=(P, R)+ h-X, R 一 Ri	[From equation (C.2)],~ _, - .. __ _ _ .. .. _ _Hence We have: mmR∈F(P, Ri	= (P, R*〉if and only if (-X, R — R*〉≥ 0 for all R	∈ F	whichholds if and only if X ∈ Nr∩f(R*) = NR(R*) + F⊥. This completes the proof.	□D	Experimental detailsWe provide additional details to help reproduce our results. Please also see the code providedwith the submission. Code for the Reductions classifier (Agarwal et al., 2018) is available here:https://github.com/fairlearn/fairlearn. We modified the source code to prevent
