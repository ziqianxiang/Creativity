Table 1: Few-shot image generation results using 100 training images (J: lower is better; â†‘: higher is better).
Table 2: Limited data image generation using different ap-proaches. FID (lower is better) is computed between 10k, 7k,6k generated and real samples (disjoint from training set) forPlaces2.5k, FFHQ2k, CUB datasets respectively. BigGAN pre-trained on ImageNet is fine-tuned in all approaches.
Table 3: Comparison of FID, Precision and Recall metrics of DIP with Baseline and SSGAN for large-scaleimage generation. Best values obtained by using complete training set Dprior are underlined and the best valueamong all other approaches are in bold.
Table 4: IvOM and FID measure on 500 random testimages of FFHQ and LSUN-Bedroom datasetsMethOd	CIFAR-100Baseline + DIP-SimCLR (ImageNet) + DIP-SimCLR (CIFAR-100) + DIP-ReSNet50 (Places-365)	2466 16.26 14.62 14.68Table 5: Comparison of FID when using prior fromvarious pre-trained models on CIFAR-100Figure 5: Semantic diffusion for image manipulation using DIP-Vgg16 model on FFHQ dataset. (Left toRight:) Custom Editing, Inpainting, Sketch-to-Image Translation and Colorization.
Table 5: Comparison of FID when using prior fromvarious pre-trained models on CIFAR-100Figure 5: Semantic diffusion for image manipulation using DIP-Vgg16 model on FFHQ dataset. (Left toRight:) Custom Editing, Inpainting, Sketch-to-Image Translation and Colorization.
Table 6: 100-shot image generation results usingStyleGAN-2 (Karras et al., 2020b) architecture onPanda, Grumpy-cat and Obama datasets. FID iscomputed between 5k generated and the completetraining dataset. * denotes directly reported fromthe paper (Zhao et al., 2020b).
Table 7: 100-shot image generation com-parison of DIP with Logo-GAN (Sage et al.,2018) on Anime dataset using Vgg16 net-work trained on ImageNet. FID is com-puted between 10k generated and real sam-ples (disjoint from training set).
Table 8: Comparison of loss function in few-shot image generation using 100 training images (FID: lower isbetter). H is hinge loss, NS is non saturating loss and W is wasserstein loss.
Table 9: Comparison of FID on CIFAR-10 and CIFAR-100 while varying the amount of data used duringtraining. Above all approaches are trained with random-horizontal flip augmentation of real images. BigGAN-DiffAugment includes consistency regularization (Zhang et al., 2019) following the implementation providedby authors (Zhao etal., 2020b). Best FID values are reported for each model. * denotes directly reported frompaper.
Table 10: Test for evaluating data-copy and memorization in GANs (Meehan et al., 2020) for different ap-proaches and datasets. Test statistic CT << 0 denotes overfitting and data-copying, and CT >> 0 representsunder-fitting.
