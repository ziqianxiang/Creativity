Table 1: Comparison on Imagenet of the benchmark implementation (Ovadia et al., 2019) versus oursingle and multiple image methods. Numerical values of the means of ECE scores across differentcorruptions types, for fixed corruption intensity going from 0 to 5.
Table 2: Comparison on CIFAR-10 of the benchmark implementation Ovadia et al. (2019) versusour single and multiple image methods. Numerical values of the means ECE scores across differentcorruptions types, for fixed corruption intensity going from 0 to 5.
Table 3: Comparison on Imagenet of the benchmark implementation (Ovadia et al., 2019) versusour single and multiple image methods. Numerical values of the means of the Brier scores acrossdifferent corruptions types, for fixed corruption intensity going from 0 to 5.
Table 4: Comparison of CIFAR-10 of the benchmark implementation Ovadia et al. (2019) versusour single and multiple image methods. Numerical values of means Brier scores across differentcorruptions types, for fixed corruption intensity going from 0 to 5.
Table 5: Comparison of ImageNet of the benchmark implementation Ovadia et al. (2019) versus oursingle and multiple image methods for the vanilla classifier. Numerical values of ECE scores fordifferent corruptions at different intensity levels going from 0 to 5. The contrast corruption was usedto form the calibration sets.
Table 6: Comparison of CIFAR-10 of the benchmark implementation Ovadia et al. (2019) versusour single and multiple image methods for the vanilla classifier. Numerical values of ECE scoresfor different corruptions at different intensity levels going from 0 to 5. The contrast corruption wasused to form the calibration sets.
