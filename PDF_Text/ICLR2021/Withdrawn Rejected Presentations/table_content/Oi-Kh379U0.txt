Table 1: A comparison of existing NAS/non-NAS works for designing discrete architectures based onour tensorized formulation for the supernet. “Topology” indicate topological structure of the supernetis utilized or not.
Table 2: Comparison with NAS methods in stand-alone setting on NAS-Bench-201.						Method	CIFAR-10		CIFAR-100		ImageNet-16-120		validation	test	validation	test	validation	testResNet (He et al., 2016)	90.83	93.97	70.42	70.86	44.53	43.63Random	90.93±0.36	93.70±0.36	70.60±1.37	70.65±1.38	42.92±2.00	42.96±2.15REINFORCE	91.09±0.37	93.85±0.37	71.61±1.12	71.71±1.09	45.05±1.02	45.24±1.18BOHB	90.82±0.53	93.61±0.52	70.74±1.29	70.85±1.28	44.26±1.36	44.42±1.49REA	91.19±0.31	93.92±0.30	71.81±1.12	71.84±0.99	45.15±0.89	45.54±1.03TRACE	91.33±0.19	94.20±0.17	73.26±0.22	73.29±0.20	46.19±0.16	46.19±0.15TRACE (Best)	91.53	94.37	73.49	73.51	46.37	46.34Best in Bench-201	91.61	94.37	73.49	73.51	46.77	47.31However, directly solving the inference problem will have a exponential complexity as we have toenumerate all relations (Hamilton et al., 2018). Thus, we propose to model it as a supernet searchproblem to reduce complexity.
Table 3: Comparison with NAS methods in weight-sharing setting on CIFAR-10.
Table 4: Comparison with NAS methods in weight-sharing setting on ImageNet.
Table 5: Experiment results on logical chain inference.
Table 6: Evaluation results on the node classification task (F1 score).
Table 8: Comparison of number of parameters for different methods on KG.
Table 9: Comparison of number of parameters for different methods on HIN.
Table 10: Comparison on number of parameters for different encoding methods.
Table 11: Dataset statistics of three image classification dataset for NAS.
Table 12: Dataset statistics for three KG dataset.
Table 13: Dataset statistics for three heterogeneous information network dataset.
Table 14: Meta-paths found by GTN and TRACE on different HIN.
