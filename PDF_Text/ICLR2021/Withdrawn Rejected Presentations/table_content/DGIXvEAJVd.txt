Table 1: Token sequences corresponding to the move sequence e2e4 e7e5 g1f3 for differentnotations during training and inference. Notice that regardless of the RAP probability used duringtraining, at inference time the token sequences have no piece types.
Table 2: Examples of each probing task, as well as the corresponding exact move (ExM) and legalmove (LgM) correct answers, are shown below. All examples assume the language model was fed theprefix e2e4 e7e5 g1f3 b8c6 d2d4 h7h6 (see Figure 1b), and that the actual next move wasf1b5. While there is only one valid prompt token for both End-Actual and Start-Actual tasks, thereare many valid prompt tokens for the other tasks, and we show just one possibility for each. Start-tasks(bottom sub-table) assume the model was trained on games described in UCI+RAP notation.
Table 3: Accuracies (%) for predicting starting squares (“Start-Actual” and “Start-Other” tasks)Training Set Model	Starting Square (Short)		Starting Square (Long)		Actual	Other	Actual	Other	ExM LgM	LgM	ExM LgM	LgM	UCI + RAP 5	71.3	88.8	83.2	58.6	69.5	65.4Train-S	UCI + RAP 15	80.4	96.7	93.8	72.6	81.6	79.4	Oracle Baseline	86.3	99.1	97.2	89.3	99.0	98.5	UCI + RAP 5	78.8	95.1	92.4	70.9	80.9	78.4Train-M	UCI + RAP 15	84.5	98.7	97.1	83.0	93.3	92.3	Oracle Baseline	87.1	99.7	98.1	90.2	99.6	99.4	UCI + RAP 5	86.8	99.7	97.9	88.6	98.0	98.3Train-L	UCI + RAP 15	87.4	99.7	98.2	89.6	99.3	98.8	Oracle Baseline	90.2	99.9	98.9	91.7	99.6	99.56.1	B oard State TrackingThere are several observations to note. First, transformers can learn to identify where pieces arelocated. This is shown by the “LgM” accuracies in Table 3. UCI + RAP 15 can predict a validstarting position of a piece at 99.7% accuracy for short histories and 99.3% accuracy for long histories.
Table 4: Accuracies (%) for predicting ending squares (“End-Actual” and “End-Other” tasks)Training Set	Model	Ending Square (Short)			Ending Square (Long)				Actual		Other LgM	Actual		Other LgM		ExM	LgM		ExM	LgM		UCI	51.9	90.8	84.3	28.3	69.5	64.8	UCI + RAP 5	53.4	94.4	86.5	32.5	78.7	73.6Train-S	UCI + RAP 15	57.4	94.8	89.2	36.1	84.6	76.4	UCI + Multi-view Training	51.4	90.2	85.1	27.7	71.0	65.8	Oracle Baseline	59.0	95.7	89.9	39.4	89.4	84.3	UCI	56.8	95.1	90.7	35.2	82.8	76.9	UCI + RAP 5	59.8	97.0	91.0	39.6	88.9	81.3Train-M	UCI + RAP 15	61.1	96.9	90.5	43.0	90.2	83.7	UCI + Multi-view Training	56.8	95.9	91.7	35.7	83.3	78.6	Oracle Baseline	62.1	97.8	93.1	46.0	92.4	87.4	UCI	66.7	98.6	94.9	47.1	94.5	89.9	UCI + RAP 5	69.0	98.9	94.8	50.3	95.6	91.7Train-L	UCI + RAP 15	68.6	99.1	95.2	48.4	95.1	91.6	UCI + Multi-view Training	69.7	99.2	95.8	49.3	95.9	92.3	Oracle Baseline	69.1	99.1	95.9	53.8	97.4	94.0	Random Legal Move	26.2	-	-	21.8	-	-
Table 5: Model VocabularyTyPe	Examples	CountSquare names	e4, d1	64Piece type	P, K, Q, R, B, N	6Promoted Pawn Piece type	q, r, b, n	4Special symbols	BOS, EOS, PAD	3Total		77Table 5 shows the vocabulary used in our experiments. We don’t use any delimiter token to denotethe move boundary. Tokens of promoted pawn piece type are used when a pawn gets promoted. Forexample, e7e8q denotes the move where a pawn from e7 moves to e8 and becomes a queen.
Table 6: Accuracies (%) for predicting ending squares (“End-Actual” and “End-Other” tasks) withvarying attention window sizes.
Table 7: Accuracies (%) for predicting ending squares for different model sizes. GPT2-small = {12layers, 12 heads, 768 embedding size}; GPT2-intermediate = {16 layers, 12 heads, 768 embeddingsize}; and GPT2-medium = {24 layers, 16 heads, 1024 embedding size}.
Table 8: Error Analysis of Illegal Moves for models trained on Train-LModel	Ending Square (Long)						Syntax	Actual Path Obst.	Pseudo Leg.	Syntax	Other Path Obst.	Pseudo Leg.
Table 9: Statistics of language modeling dataSplit	# of games (in 103)	Total # of moves (in 106)	Avg. # of moves per gameTrain-S	15	1.1	73.6Train-M	30	2.2	73.5Train-L	100	7.3	73.5Dev	15	1.2	78.5Test	15	1.2	79.2Table 10: Canonical Dev and Test perplexity. By canonical we mean that one move, say f1b5, countsas one token.
Table 10: Canonical Dev and Test perplexity. By canonical we mean that one move, say f1b5, countsas one token.
Table 11: Accuracies (%) for predicting ending squares for LSTM language modelsTraining Set	Model LSTM-LM	Ending Square (Short)			Ending Square (Long)				Actual		Other LgM	Actual		Other LgM		ExM	LgM		ExM	LgM		+ UCI	43.1	77.7	68.1	23.8	60.0	52.5Train-S	+ UCI + RAP 5	42.0	77.1	67.1	23.5	59.8	53.2	+ UCI + RAP 15	42.7	77.0	69.0	22.9	59.3	52.2	+ UCI	48.5	82.7	76.9	29.7	65.0	58.7Train-M	+ UCI + RAP 5	50.1	83.8	77.3	27.5	64.0	59.0	+ UCI + RAP 15	51.1	84.0	77.3	28.8	66.2	60.8	+ UCI	59.9	94.2	88.5	36.1	81.6	74.8Train-L	+ UCI + RAP 5	59.4	93.5	87.7	38.1	83.3	75.7	+ UCI + RAP 15	61.5	94.3	87.7	39.5	84.7	78.4In this section we present results for LSTM language models (Hochreiter & Schmidhuber, 1997). Inparticular we use a LSTM model with 3 layers, 1024-dimensional hidden units, 768-dimensional inputembedding size, and dropout of 0.1 applied to the output of the embedding layer and intermediateLSTM layers.13 The motivation behind these experiments is to compare LSTMs and transformers intheir ability to utilize the board state signal available via RAP during training. We focus on the RAPsetting because with RAP there’s a distribution shift between training and inference, and we want tocompare how the two model classes handle this shift.
