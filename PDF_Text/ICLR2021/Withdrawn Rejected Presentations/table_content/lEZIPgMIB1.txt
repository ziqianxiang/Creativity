Table 1: Datasets used across all of the analyses and visualizations in the paper. NA refers to a splitthat was not used in the paper (e.g. no validation or testing set was used for the bison visualizationin Fig 4B.)A.3 Embedding algorithmsNeural network architectures for the Parametric networks differ between datasets. MNIST, FMNIST,and CIFAR10 use convolutional neural networks. The Cassin’s vireo dataset uses an LSTM encoder(and decoder for the autoencoder). The Retina dataset uses a 3-layer MLP with 100-neurons perlayer. Parametric t-SNE and UMAP used the same neural network architectures and optimizer. ForUMAP, the distance metric used for Cassin’s vireo song is a dynamic-time warping (DTW) metric.
Table 2: Trustworthiness score for each method from Fig 13.
Table 3: KNN (k = 1) scores for each method from Fig 14Dataset	Dim.	t-SNE	P. t-SNE	UMAP	P. UMAP	UMAP/AE	AE	VAE	PCACassin’s	2	0.9910	0.9930	0.9890	~~0.9950	0.9930	0.9090	0.7740	0.6910	64	-	0.9950	0.9860	0.9910	0.9970	0.9930	0.9880	0.9920CIFAR10	2	0.2608	0.2017	0.1936	0.1722	0.1833	0.2007	0.1941	0.1503	64	-	0.3556	0.2694	0.2519	0.2477	0.3728	0.3777	0.3769FMNIST	2	0.8039	0.7361	0.7608	0.7407	0.7561	0.7339	0.7161	0.5055	64	-	0.8479	0.8059	0.7878	0.8028	0.8756	0.8830	0.8568Retina	2	0.9795	0.9766	0.9792	0.9761	0.8933	0.9647	0.8795	0.8429	64	-	0.9813	0.9801	0.9748	0.9661	0.9817	0.9770	0.9806MNIST	2	0.9502	0.9378	0.9544	0.9614	0.9537	0.7926	0.7649	0.4201	64	-	0.9734	0.9538	0.9680	0.9654	0.9758	0.9791	0.9727Table 4: KNN (k = 5) scores for each method from Fig 1420Under review as a conference paper at ICLR 2021Dataset	Dim.	t-SNE	P. t-SNE	UMAP	P. UMAP	UMAP/AE	AE	VAE	PCACassin’s	2	0.5431	0.7439	0.7749	~~0.8013	0.7714	0.1125	0.0853	0.0731	64	-	0.2299	0.8536	0.8173	0.8271	0.2411	0.1583	0.2914CIFAR10	2	-0.1216	-0.2757	-0.1340	-0.1359	-0.1320	-0.1436	-0.1114	-0.1142	64	-	-0.0536	-0.1166	-0.1163	-0.1172	-0.0644	-0.0529	-0.0580
Table 4: KNN (k = 5) scores for each method from Fig 1420Under review as a conference paper at ICLR 2021Dataset	Dim.	t-SNE	P. t-SNE	UMAP	P. UMAP	UMAP/AE	AE	VAE	PCACassin’s	2	0.5431	0.7439	0.7749	~~0.8013	0.7714	0.1125	0.0853	0.0731	64	-	0.2299	0.8536	0.8173	0.8271	0.2411	0.1583	0.2914CIFAR10	2	-0.1216	-0.2757	-0.1340	-0.1359	-0.1320	-0.1436	-0.1114	-0.1142	64	-	-0.0536	-0.1166	-0.1163	-0.1172	-0.0644	-0.0529	-0.0580FMNIST	2	0.1251	0.2013	0.1936	0.2139	0.2060	0.0427	0.1064	-0.0331	64	-	0.0543	0.2195	0.2315	0.2305	0.0655	0.0376	0.0618Retina	2	0.0151	0.2578	0.2800	0.4519	0.3973	0.4394	0.4449	0.4009	64	-	-0.0214	0.3522	0.4652	0.4662	0.4289	0.3873	0.4188MNIST	2	0.3498	0.3710	0.5186	0.5559	0.4637	-0.0258	0.0627	0.0228	64	-	0.0488	0.5276	0.5571	0.5166	0.0653	0.0431	0.0569Table 5: Silhouette score for each method from Fig 16.
Table 5: Silhouette score for each method from Fig 16.
Table 6: Clustering score for each method from Fig 17Dataset	Dim.	UMAP	P. UMAP	UMAP/AE	AE	VAE	PCACassin’s	2	0.0085	0.0028	0.0028	0.0163	0.0125	0.0082	64	-	0.0034	0.0028	0.0011	0.0013	0.0008CIFAR10	2	0.0528	0.0369	0.0364	0.0344	0.0217	0.0370	64	-	0.0300	0.0094	0.0080	0.0084	0.0084FMNIST	2	0.0347	0.0266	0.0240	0.0244	0.0253	0.0461	64	-	0.0241	0.0092	0.0054	0.0058	0.0104Retina	2	0.0003	0.0008	0.0005	0.0005	0.0006	0.0010	64	-	0.0005	0.0003	0.0001	0.0003	-MNIST	2	0.0393	0.0374	0.0360	0.0369	0.0371	0.0557	64	-	0.0313	0.0027	0.0016	0.0024	0.0090Table 7: Reconstruction error on held-out testing set for each method.
Table 7: Reconstruction error on held-out testing set for each method.
Table 8: Classification accuracy across each dataset and method for different numbers of labeledtraining examples.
