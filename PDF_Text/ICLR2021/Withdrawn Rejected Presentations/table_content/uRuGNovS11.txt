Table 1: Classification results for MNIST (mean±stdev) after five runs for different rates of uniformlabel noise. The best result per column is in boldNoise Rate	0%	10%	20%	30%	50%PCA	97.87 ± 0.09	95.35 ± 0.30	89.56 ± 0.53	80.70 ± 0.47	59.02 ± 0.65BLMNN	98.98 ± 0.08	97.08 ± 0.20	92.25 ± 0.51	84.47 ± 0.47	63.60 ± 0.81DML	98.66 ± 0.07	97.76 ± 0.20	95.34 ± 0.35	91.40 ± 0.52	71.86 ± 0.47BDML (ours)	98.79 ± 0.09	97.60 ± 0.18	95.25 ± 0.34	91.59 ± 0.36	73.60 ± 0.6proposed framework consists of the following steps: (i) extract features by an unsupervised method;(ii) apply PCA to project data points onto a smaller dimensional space; (iii) standardize features tostandard Normal distribution, then use these features for comparing methods.
Table 2: Classification results for CIFAR-10 (mean±stdev) after five runs for different rates ofuniform label noise. The best result per column is in boldNoise Rate	0%	10%	20%	30%	50%PCA	76.64 ± 0.41	72.98 ± 0.29	67.83 ± 0.54	60.91 ± 0.18	44.06 ± 0.73BLMNN	79.96 ± 0.17	76.56 ± 0.28	71.18 ± 0.53	64.89 ± 0.38	47.74 ± 0.15DML	81.81 ± 0.30	80.21 ± 0.29	77.90 ± 0.34	74.05 ± 0.24	59.76 ± 0.64BDML (ours)	82.63 ± 0.12	81.01 ± 0.27	78.81 ± 0.25	75.17 ± 0.34	61.40 ± 0.46Table 3: Classification results for CIFAR-10 (mean±stdev) after five runs for different class-conditional label noises, noise rates are presented as a vector with length equals to the numberof classes. The best result per row is in boldNoiseRate	PCA	BLMNN	DML BDML (ours)[0.5 0.6 0.1 0.4	0.4 0.4 0.2 0.4	0.6	0.3]	53.68 ± 0.43	55.99 ± 0.30~67.76 ± 0.16	69.47 ±	0.49[0.3 0.6 0.1 0.5	0.2 0.5 0.4 0.1	0.3	0.5]	56.89 ± 0.47	59.71 ± 0.80 70.60 ± 0.38	72.32 ±	0.37[0.1 0.3 0.6 0.4	0.5 0.4 0.5 0.1	0.1	0.2]	60.49 ± 0.36	62.63 ± 0.29 71.43 ± 0.50	72.89 ±	0.47inference, outperforms DML, which adopt MLE for parameter estimation, across different noiselevels.
Table 3: Classification results for CIFAR-10 (mean±stdev) after five runs for different class-conditional label noises, noise rates are presented as a vector with length equals to the numberof classes. The best result per row is in boldNoiseRate	PCA	BLMNN	DML BDML (ours)[0.5 0.6 0.1 0.4	0.4 0.4 0.2 0.4	0.6	0.3]	53.68 ± 0.43	55.99 ± 0.30~67.76 ± 0.16	69.47 ±	0.49[0.3 0.6 0.1 0.5	0.2 0.5 0.4 0.1	0.3	0.5]	56.89 ± 0.47	59.71 ± 0.80 70.60 ± 0.38	72.32 ±	0.37[0.1 0.3 0.6 0.4	0.5 0.4 0.5 0.1	0.1	0.2]	60.49 ± 0.36	62.63 ± 0.29 71.43 ± 0.50	72.89 ±	0.47inference, outperforms DML, which adopt MLE for parameter estimation, across different noiselevels.
Table 4: Experiment results for MS-Celeb-1M (mAP %). The best result per column is in boldNoise Rate	0%	20%PCA	86.21	82.09BLMNN	89.16	85.11DML	91.89	86.50BDML (ours)	93:45	87.66and DML. We are not aware of other SOTA methods in the scope of this paper. In the future, weplan to test our proposed method with more complicated base models (e.g., ResNet (He et al., 2016))instead of the simple neural network to obtain better experimental results. We also plan to extendour current work to make it robust under simulated label noise (Wang & Tan, 2018) which has beenshown to be more challenging than the types of label noise mentioned in our paper.
