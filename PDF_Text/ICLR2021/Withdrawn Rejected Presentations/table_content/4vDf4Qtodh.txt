Table 1: Related work in terms of desirable properties and the computational complexity necessaryto generate a single node embedding. Note that all existing methods must generate a full graphembedding, and thus are directly dependent on the total graph size, while our method can directlysolve this task in sublinear time. Analysis in Section 3.2.1.
Table 2: Dataset attributes: size of ver-tices |V |, edges |E |, labeled vertices |S |.
Table 3: Average Micro-F1 classification scores and confidence intervals. Our method is marked asfollows: * - above baselines; bold - no other method is statistically significant better.
Table 4: Average ROC-AUC scores and confidence intervals for the link prediction task. Our methodis marked as follows: * - above baselines; bold - no other method is statistically significant better.
Table 5: Analysis of employed networks in terms of scale-free and small-world measures. The scale-free degree is reported as a Kolmogorov-Smirnov test between power-law and exponential/log-normaldistributions candidates (R = mean log-likelihood ratio, p = degree of confidence).
Table 6: Total approximate running time for producing a 512-dimensional full graph embedding, with4 additional recent baselines. In this scenario, InstantEmbedding produced a full graph embedding, asopposed to the originally proposed single node representation task.
Table 7: Average run time (in seconds) to generate a 128-size and a 512-size node embedding foreach method and each dataset with the respective standard deviation. Each experiment was run 5times for all the methods (given their global property) except for InstantEmbedding for which we ranthe experiment 1000 times (given the method’s locality property).
Table 8: Peak memory used (in MB) to generate a 128-size and 512-size node embedding for eachmethod and each dataset. Each experiment was run once for all the methods (given their globalproperty) except for InstantEmbedding for which we ran the experiment 1000 times (given themethod’s locality property) and report the mean peak memory consumption with the respectivestandard deviation.
Table 9: Classification micro and macro F1-scores for PPI.
Table 10: Classification micro and macro F1-scores for Blogcatalog.
Table 11: Classification micro and macro F1-scores for CoCit.
Table 12: Classification micro and macro F1-scores for Flickr.
Table 13: Classification micro and macro F1-scores for YouTube.
Table 14: Approximate Micro-F1 scores with an additional 4 baselines. All methods produced 512-dimensional embeddings, with the exception of FREDE for which we refer the scores from theoriginal paper.
Table 15: Link-prediction ROC-AUC scores for Blogcatalog. For each method, we highlight theaggregation function that consistently performs good on all datasets.
Table 16: Temporal link-prediction ROC-AUC scores for CoAuthor. For each method, we highlightthe aggregation function that consistently performs good on all datasets.
