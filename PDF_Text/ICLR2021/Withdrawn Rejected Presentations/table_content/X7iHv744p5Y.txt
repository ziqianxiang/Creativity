Table 1: Model performance on the Quora test split. Bold indicates best for model-type, * indicatesbest overall (excluding human). The first 5 columns are measures of quality, while the last measuresnovelty (equation 8) or difference from input. We rerun evaluations from past work.
Table 2: Model performance on αNLG. The first 3 scoresquery agreement between hypothesis and given observa-tion(s), and “all” indicates overall judgement.
Table 3: Most parameters are explained in §2.4. hsample is entropy for sampling calibration in §B.3B.	4 ParametersIn this section, we outline model settings for our 2 experimental settings, paraphrasing and αNLG.
Table 4: Model performance on the Quora test split. Included here are extra metrics beyond what isin the main paper. R-1 and R-2 refer to ROUGE-1 and ROUGE-2.
Table 5: Model performance on the Quora test split, by human evaluation. Overall is calculatedas the percentage of generations that meet the basic criteria of a paraphrase: fluent (the paraphrasecan be understood), consistent with the source (the paraphrase shows at most minor differences inmeaning from the source) and giving a novel phrasing (paraphrase shows at least minor differencein word choice). The first 3 columns indicate percentage of generations that meet the given criterion.
Table 6: Model performance on the Twitter URL test split. Bold indicates best for model-type, *indicates best overall (excluding human). The first 4 columns are measures of quality, while the lastmeasures novelty (equation 8) or dissimilarity from input. We rerun evaluations from past work.
Table 7: Correlation with human judgement on the WMT18 metric task, for 3 language pairs (Chinese,German, and Estonian to English). Correlations of metrics not significantly outperformed by anyother for that language pair are highlighted in bold. We note that Reflective Score is among only 2methods bolded over all language-pairs tested.
Table 8: Ablation of number of contexts generated nc, holding weight pruning parameter constant atkc = 6. For some nc (e.g. nc = 6), the Top setting achieves high enough novelty for both cutoffs (30and 45). In these cases, RDT op is repeated for RD30 and RD45Method	SARI↑	BLEU↑	METEOR↑	TERP； I NOVelty ↑	RDT op (nc = 6 )	33.3	33.2	23.8	71.0	56.3- weight learning	29.6	20.1	16.8	89.0	76.7RDTop(nc = 10)	34.2	37.3	26.4	65.0	48.2- weight learning	31.3	46.6	31.8	56.0	28.4Table 9: Ablation of whether weights are learned or taken to be uniform. For learned weights, we setkc = nc indicating no weight pruning, so that the final number of contexts used is the same with andwithout learning.
Table 9: Ablation of whether weights are learned or taken to be uniform. For learned weights, we setkc = nc indicating no weight pruning, so that the final number of contexts used is the same with andwithout learning.
Table 10: Generations from the 3 Reflective Decoding variants on the examples from the Quoratest split. Places where a novel phrasing is introduced are bolded and mistakes are underlined.
Table 11: Further generations for αNLG from all tested systemsCindy got out of bed. ― She also ordered an iPhone.	Human	I	She ordered a new iPad.
Table 12: Further generations for αNLG from all tested systemsI once knew a girl named Sammy. ― She got help and everything was alright.	Human	I	She suffered from depression.
Table 13: Further generations for αNLG from all tested systems22Under review as a conference paper at ICLR 2021Can you trust the information on Quora?Human	∣	Do you trust Quora?UnSUPerviSed	RefDec-Top (US) ∣	Can you trust the information on Quora?RefDec-70 (Us) ∣	Can I trust the information on Quora?RefDec-55(US) ∣	When can I trust information on Quora ?R-VQVAE	I	Can you trust the information on Quora?CGMH-Top	I	Can you answer the information on Quora?CGMH-70	I	Can you answer the information on Quora?CGMH-55	I	Can you answer more topics on Quora?Supervised	PG-IL	I	Can you trust the information on Quora?DiPS	I	Can we trust our questions in Quora?BART	I	Can you trust everything you read on Quora?Bilingual	MT	I	Can you trust the information on Quora?Table 14: Further generations for paraphrasing from all tested systems
Table 14: Further generations for paraphrasing from all tested systemsWhat is your creative process?Human	I What,s your creative process?Unsupervised	RefDec-Top (Us)	I What is your creative process?RefDec-70 (Us)	I What,s your creative process?RefDec-55 (Us)	I What,s your creative process like?R-VQVAE	I What is your creative process?CGMH-Top	I	What is your dream key?CGMH-70	I	What is your dream key?CGMH-55	I	What is your dream key?Supervised	PG-IL	I What is your creative process?DiPS	I What is your creative strategy?BART	I What is your creative process?Bilingual	MT	I What is your creative process?Table 15: Further generations for paraphrasing from all tested systems23Under review as a conference paper at ICLR 2021
Table 15: Further generations for paraphrasing from all tested systems23Under review as a conference paper at ICLR 2021Figure 3: The template used for human evaluation of αNLG24Under review as a conference paper at ICLR 2021Instructions (click to e×pand∕collapse)Thanks for participating in this HIT! Please read the instructions carefully.
