Table 1: Statistics of traffic flowsTime Arrival Rate(second) (vehicles/s)0 - 600	1600 - 1, 200	1/41,	200 - 1, 800	1/31, 800 - 2, 400	22,	400 - 3, 000	1/53,	000 - 3, 600	1/2all approaching lanes at current timestep. The global objective is to minimize average travel time ofall vehicles in the road network, which is equivalent to minimizing the sum of queue lengths of allintersections over an episode (Zheng et al., 2019). The experiment was conducted on a traffic simu-lator, CityFlow (Zhang et al., 2019). We use a 6 × 6 grid network with 36 intersections. The trafficflows were generated to simulate dynamic traffic flows including both peak and off-peak period, andthe statistics is summarized in Table 1.
Table 2: Average travel time of all the models in trafficDQN	DGN	fixed LToS	LToS	NeurComm	ConseNet	QMIX118.75	110.59	113.83	98.57	106.53	111.18	596.52Figure 4 shows the learning curves of all the models in termsof average travel tiem of all vehicles in logarithmic form.
Table 3: Statistics of packet floWTime Arrival Rate(timestep) (packets/timestep)0 - 100	1100 - 200	10/3200 - 300	1Packet routing is regarded as a complex problem in distributed com-puter networks. Here is a simplified version of the problem. A net-work consists of multiple routers with a stationary network topol-ogy. Data packets come into the network (started at a router) fol-lowing the Poisson distribution, and the arrival rate varies during anepisode as summarized in Table 3. Each router has a FIFO queueas the packet buffer. For simplicity, We assume that each queue hasunlimited volume allowance, and each packet has a size same as each link’s bandwidth. At everytimestep, each router observes the data packets in the queue and incoming links as Well as indicesof neighboring routers, forWards the first packet in the FIFO to the selected next hop, and obtains areWard Which is the negative of the queue length. The transmission time of a packet over a link isproportional to the geographic distance, and the packet Will be stored after arriving at the next hopunless it reaches the destination. The delay of a packet is the sum of timesteps spent at the routersand on the links. The goal of packet routing is to send the packets to their destinations through
Table 4: Performance of all models in routing: throughput (packets) and average delay (timesteps)	DQN	DGN	fixed LToS	LToS	NeurComm	ConseNet	QMIXthroughput	297.69	299.24	304.99	311.50	116.53	185.32	218.79delay	91.06	90.96	89.50	86.71	122.68	111.87	105.748Under review as a conference paper at ICLR 20216 ConclusionIn this paper, we proposed LToS, a hierarchically decentralized method for networked MARL. LToSenables agents to share reward with neighbors so as to encourage agents to cooperate on the globalobjective. For each agent, the high-level policy learns how to share reward with neighbors to decom-pose the global objective, while the low-level policy learns to optimize local objective induced bythe high-level policies in the neighborhood. Experimentally, we demonstrate that LToS outperformsexisting methods in both social dilemma and two networked MARL scenarios.
Table 5: Hyperparameters for DQN and DGN (also serves as the low-level policy network of LToS)Hyperparamater	Prisoner	Traffic	Routingsample size	10	1,000	10batch size	10	20	10buffer capacity	200,000	10,000	200,000/decay/minimum value	0.8/1/0.8	0.4/0.9/0.05	0.2/0.98/0initializer	random normal	random normal	random normaloptimizer	Adam	Adam	Adamlearning rate	1e-3	1e-3	1e-3γ	0.99	0.8	0.99τ for soft update	0.1	0.1	0.1# MLP units	32	32	128MLP activation	ReLU	ReLU	ReLU# encoder MLP layers	2	2	2# attention heads for DGN	4	1	8# convolutional layers for DGN	1	1	1Table 6: Hyperparameters for the high-level policy network of LToSHyperparamater	Prisoner	Traffic	Routingupdate frequency	1 step	5 episodes	20 episodesaction interval	1 step	15 steps	30 steps
Table 6: Hyperparameters for the high-level policy network of LToSHyperparamater	Prisoner	Traffic	Routingupdate frequency	1 step	5 episodes	20 episodesaction interval	1 step	15 steps	30 stepssample size	2,000	1,000	2,000batch size	32	20	32noise for exploration	+ Gaussian	OU	OUnoise parameter	= 0.8, σ = 1	σ = 0.25	σ = 0.025initializer	selfishness	selfishness	selfishnessinitial selfishness	0.5	0.8	0.9optimizer	SGD	SGD	SGDlearning rate	1e-1	1e-3	1e-3last MLP layer activation	softmax	softmax	softmaxTable 7: Hyperparameters for NeurComm, ConseNet and QMIXHyperparamater	Prisoner	Traffic	Routinginitializer	orthogonal	orthogonal	orthogonaloptimizer	RMSProp	RMSProp	RMSProplearning rate	5e-3	5e-4	5e-4# MLP units	20	16	128MLP activation	ReLU	ReLU	ReLU
Table 7: Hyperparameters for NeurComm, ConseNet and QMIXHyperparamater	Prisoner	Traffic	Routinginitializer	orthogonal	orthogonal	orthogonaloptimizer	RMSProp	RMSProp	RMSProplearning rate	5e-3	5e-4	5e-4# MLP units	20	16	128MLP activation	ReLU	ReLU	ReLU# cell state units	20	16	128# hidden state units	20	16	128RNN type for NeurComm and ConseNet	LSTM	LSTM	LSTMRNN type for QMIX	-	GRU	GRUhypernetwork layer1 units for QMIX	-	36 × 16	18 × 128hypernetwork layer2 units for QMIX	-	16	128α for NeurComm	1	0.1	0.05in an equally slight modification of the low-level value functions. This guarantees the low-levelpolicies are highly reusable.
