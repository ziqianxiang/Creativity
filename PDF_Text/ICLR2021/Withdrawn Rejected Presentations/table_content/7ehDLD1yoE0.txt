Table 1: The name of the CODE2SEQ model trained on each dataset, along with optimal values of n forthe top-n by frequency and L2 norm vocabularies, and the total number of subtokens for each dataset.
Table 2: Evaluation of F1 scores of STRATA on our code2seq models, using vocabularies andreplacement strategies as described in the Methods section. The baseline refers to the performance ofthe model on the original test dataset. For the Java models, samples were drawn from the java-smalltesting set such that each method included a local variable to perturb. All top-n scores use optimalvalues of n proposed in Table 1.
Table 3: Effectiveness of targeted attacks on code2seq.
Table 4: F1 scores of a non-robust and robust code2seq-sm model on gradient-based adversarialperturbations and STRATA perturbations.
Table 5: Comparison of F1 scores our method to gradient-based attacks described by Ramakrishnanet al. (2020). Both our model and the Ramakrishnan et al. (2020) model are trained on java-small.
Table 6: Results of adversarial training of code2seq-sm on L2-based adversarial examples.
Table 7: Comparison of the percent of the time the prediction is changed by STRATA and by anattack from Rabin et al. Both our attack and the attack from Rabin et al. target a CODE2SEQ-LG. Notethat our model is evaluated on the java-small testing dataset.
Table 8: F1 scores on adversarial data generated by a cross-dataset attack where vocabularies areconstructed by using the L2 norm of the embeddings of the code2seq model trained on the particulardataset. The first column corresponds with the model that is being attacked, and the other columnscorrespond with the dataset from which the attack is constructed. Lower score means a better attack.
Table 9: F1 scores on adversarial data generated by a cross-dataset attack where vocabularies areconstructed by using the frequency of subtokens in the associated training dataset. The first columncorresponds with the model that is being attacked, and the other columns correspond with the datasetfrom which the attack is constructed. Lower score means a better attack. All adversarial subtokensare concatenated with 5-same. The boxed scores correspond with the baseline same-dataset attacks.
Table 10: Effectiveness of targeted attacks on code2seq-lg using uncurated and arbitrarily pickedsubtokens of high embedding vector, sorted by % success.
