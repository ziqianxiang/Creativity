Table A.1: Test accuracy of the ResNet-32 model on the CIFAR-10 dataset. Top rows: results fromvarious sparse structures. (Baseline: baseline non-sparse model; G = 16 / s = 1: CC-Sparse modelwith group size G = 16, and s = 1; without group 1: sparse model with same sparse density asG = 16 / s = 1 but without the group structure; G = 64 / s = 1: CC-Sparse model with group sizeG = 64, and s = 1; without group 2: sparse model with same sparse density as G = 64 / s = 1 butwithout the group structure.) Bottom rows: results from the original TD study Gomez et al. (2018).
Table A.2: Test accuracy of the VGG-16 model on the CIFAR-10 dataset. Top rows: results fromvarious sparse structures. (Baseline: baseline non-sparse model; G = 16 / s = 1: CC-Sparse modelwith group size G = 16, and s = 1; without group 1: sparse model with the same sparse densityas G = 16 / s = 1 but without the group structure; G = 64 / s = 1: CC-Sparse model with groupsize G = 64, and s = 1; and without group 2: sparse model with the same sparse density asG = 64 / s = 1 but without the group structure.) Bottom rows: comparison between CC-Sparsityand structured sparsity Li et al. (2016).
Table A.3: Performance comparison between two sparsity configurations on the ResNet-18 model.
Table A.4: Benchmark results on lightweight architecturesModelMobileNet V1MobileNet V1 (0.75)MobileNet V1 (0.5)Params Flops Top1Accuracy%4.2M	569M	70.602.6M	325M	68.301.3M	149M	63.70MobileNet V2	3.4M	300M	72.00MobileNet V2 (0.75)	2.61M	209M	69.80MobileNet V2 (0.5)	1.95M	97M	65.40IGCV3-D	3.5M	318M	72.20IGCV3-D (0.7)	2.8M	210M	68.45Condense (G=C=8)	2.9M	274M	71.00ShuffleNet 1.5* (g = 3)	3.4M	292M	71.50ShuffleNet 1* (g= 8)	140M 67.60ShuffleNet 0.5* (shallow, g = 3)	40M	57.20CI-SParsity on MobilenetV2 (Width=1,epoch=120, G=8, S=2)	2.2M	120M^^69.46
