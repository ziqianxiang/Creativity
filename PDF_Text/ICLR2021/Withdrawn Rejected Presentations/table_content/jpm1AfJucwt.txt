Table 1: Summary of the best ∆L(θ, ∆θ) across values of λ for different netWorks and pruningcriteria, With π = 140. QM achieves better loss-preservation than other criteria. OBD performsWorse than QM, since We violate its convergence assumption When pruning in several stages.
Table 2: Best validation error gap of the fine-tuned networks (lower is better), for different pruningcriteria, across values of λ and π. LM is better than MP on the MLP and VGG11. All the methodsreach similar levels of performance on the PreActResNet18.
Table 3: Best validation error gap before/after pruning for different networks and pruning criteria.
