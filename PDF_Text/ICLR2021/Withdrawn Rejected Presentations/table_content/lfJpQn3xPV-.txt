Table 1: Total number of vertices |V |, number of edges |E | excluding self-loops, est. power lawexponent α, number of features D and number of classes |C|, number of newly appearing classes|Cnew | within the evaluation time steps, the 25,50,75-percentiles of the distribution of temporal dif-ferences tdiff2 , along with the total number of time steps T for our datasets.
Table 2: Results for Q3: Incremental Training on Different Window Sizes (top), and, Q4: Incre-mental Training with Scalable GNN methods (bottom). Average accuracy across different runsand time steps with varying temporal window sizes (column c), 95% CI are computed based onsample variance. We list only the best performing variants of cold (c) and warm (w) restarts for eachconfiguration. We compare each average accuracy to the average accuracy obtained by training onthe full graph (see column relative performance).
Table 3: Hyperparameter choices for experiment Q4. All methods are supplied with 200 epochsper time step. We separately optimize hyperparameters for each window size and for each restartconfiguration on DBLP-easy. GraphSAINT and Jumping Knowledge use 2 hidden layers with 64hidden units each.
Table 4: Extended results for experiment Q3. Average accuracy across seeds and time steps withvarying temporal window sizes, 95% confidence intervals are computed based on sample variance(N=10,080). Window size is listed in the column c, warm restarts (w) and cold restarts (c) are listedin the column r. We compare each average accuracy to the average accuracy obtained by trainingon the full graph (see column relative performance).
Table 5: Extended results for experiment Q4. Average accuracy across seeds and time steps with varying temporal window sizes, 95% confidence intervals are computed based on sample variance. Window size is listed in the column c, warm restarts (w) and cold restarts (c) are listed in the column r. We compare each average accuracy to the average accuracy obtained by training on the full graph (see column relative performance).								dataset	c	r	Simplified GCN		GraphSAINT		Jumping Knowledge				accuracy	relative	accuracy	relative	accuracy	relative	1	c	.585±.00	84%	.621±.00	92%	.580±.00	82%		w	.628±.00	92%	.643±.00	94%	.626±.00	88%	3	c	.670±.00	96%	.663±.00	99%	.666±.00	95%dblp-easy		w	.672±.00	98%	.671±.00	97%	.681±.00	96%	6	c	.692±.00	99%	.682±.00	101%	.697±.00	99%		w	.688±.00	100%	.684±.00	100%	.700±.00	99%	full	c	.699±.00	100%	.672±.00	100%	.704±.00	100%		w	.686±.00	100%	.685±.00	100%	.708±.00	100%	1	c	.319±.00	-^9T%^	.304±.00	97%	.290±.00	83%		w	.383±.00	90%	.372±.00	93%	.342±.00	80%	3	c	.357±.00	103%	.319±.00	102%	.405±.00	116%dblp-hard		w	.417±.00	98%	.405±.00	101%	.426±.00	100%	6	c	.363±.00	105%	.341±.00	109%	.411±.00	118%		w	.424±.00	100%	.413±.00	103%	.431±.00	102%	full	c	.347±.00	100%	.313±.00	100%	.349±.00	100%		w	.424±.00	100%	.402±.00	100%	.424±.00	100%	1	c	.614±.00	-^114%	.634±.00	103%	.623±.00	100%
