Table 1: ACA (%) and ACR on CIFAR-10. All models are trained via the standard training. UEstands for the upper envelope, which shows the largest ACA and ACR among the candidate models.
Table 2: Training time, #parameters and #FLOPs for models under Ïƒ = 0.50 via MACER training.
Table 3: ACA (%) and ACR on CIFAR-10. All models are trained via MACER training. UE standsfor the upper envelope of candidate models.
Table 4: ACA (%) and ACR on ImageNet. All models are trained via standard training.
Table 5: Certified accuracy (%) and ACR on SVHN. All models are trained via standard training. UEstands for the upper envelope of candidate models.
Table 6: ACA (%) and ACR on CIFAR-10. All candidate models are ResNet-110s trained via thestandard training. UE stands for the upper envelope, which shows the largest ACA and ACR amongthe candidate models. AVG stands for the average ACA or ACR of candidate models.
Table 7: ACA (%) and ACR on ImageNet. All candidate models are ResNet-50s trained via thestandard training. The SWEEN model here contains 3 ResNet-50s. UE stands for the upper envelope,which shows the largest ACA and ACR among the candidate models. AVG stands for the averageACA or ACR of candidate models.
Table 8: ACA (%) and ACR on CIFAR-10. All models are trained via the standard training. * meansthe upper envelope of candidate models.
Table 9: Certified accuracy and empirical accuracy versus AutoAttack on CIFAR-10. All candidatemodels are trained via the standard training.
