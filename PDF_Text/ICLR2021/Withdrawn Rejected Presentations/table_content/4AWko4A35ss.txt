Table 1: Comparison to the state-of-the-art on UCF101(U) and HMDB51(H). All models are pre-trained with the RGB modality only. f: Methods with temporal-only transformations. ∣: Methodswith both spatial and temporal transformations. *: Methods that leverage spatiotemporal represen-tations. HT: HowTo100M. The underline represents the second-best result.
Table 2: Comparison with state-of-the-art self-supervised learning methods for nearest neighborvideo retrieval (top-k recall) on UCF101. The underline represents the second-best result.
Table 3: Evaluation of pre-training tasks with the backbone R2D3D-18 under linear probe and fullyfine-tuning protocols on UCF101. AW: Adaptive Weighting. CL: Curriculum Learning.
Table 4: The structure of the encoding function f (∙). R2D3D-18 is used as an example.
Table 5: Evaluation of pre-training tasks under different designs of LCCD on UCF101.
Table 6: Evaluation of different temperature T for CLSC on UCF101.
Table 7: Evaluation of different designs of CSPC on UCF101.
Table 8: Evaluation of different designs of CCMR on UCF101.
Table 9: Evaluation of pre-training tasks with the backbone R2D3D-18 under the linear evaluationprotocol on UCF101. For computation efficiency, CSJ is only defined on4 X 4 X 4 cells.
