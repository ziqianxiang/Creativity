Table 1: Results for open-ended generation tasks on the Wikitext-103 testset. ppl, uniq and Rep/lare computed at BPE-level and the rest are at word-level. The "f" denotes higher value for betterperformance and "J"is the opposite. Number marked with * are estimated based on the testset. Theresults are averaged over 3 runs with different random seeds. Full results with standard deviationare reported in Appendix F.1.
Table 2: Human evaluation results for auto-completion. % Agr. is the percent agree-ment and AC1 denotes Gwet’s AC1/gammacoefficient. Winners are marked in bold.
Table 3: Results for image paragraph captioningModels	CIDErMLE w/o 3-block	10.51UL w/o 3-block (α=0.5)	14.65SG w/o 3-block (γ=0.5)	19.42MLE w/ 3-block	22.77UL w/ 3-block (α=0.5)	22.25SG w/ 3-block (γ=0.5)	24.625Under review as a conference paper at ICLR 2021Table 4: An example of greedy generated continuations for the same prefix.
Table 4: An example of greedy generated continuations for the same prefix.
Table 5: Experimental results for text summarization onCNN/DM and NYT50 testsets.
Table 6: Results of different decoding strategies withScaleGrad training for auto-completion.
Table 8: Degeneration analysis for image para-graph captioning with/without tri-gram block-ing. Numbers in bold are closest to human.
Table 7: Summarization results (F1-basedROUGE-1 and MoverScore) for stochastic de-coding on NYT50 testset.
Table 9: Results for open-ended generations. ppl, uniq and Rep/l are computed at BPE-level and therest are at word-level. The "f" denotes higher value for better performance and "]" is the opposite.
Table 10: Results for open-ended generations on PTB testset. ppl, uniq and Rep/l are computed atBPE-level and the rest are at word-level. The "f" denotes higher value for better performance and“J"is the opposite. Number marked with * are estimated based on the PTB testset.
Table 11: Results for open-ended generations on movie reviews from IMDB dataset. ppl, uniqand Rep/l are computed at BPE-level and the rest are at word-level. Number marked with * areestimated based on the extracted movie reviews from IMDB.
Table 12: Hyper-parameters for open-ended generation. M denotes the model-specific hyper-parameters. lr0 is initial learning rate.
Table 13: Dataset statistics for summarization.
Table 14: Hyper-parameter lists for text summarization. M denotes the model-specific hyper-parameters. lr0BERT and lrd0ec stand for initial learning rate for BERT and Transformer decoder.
Table 15: Hyper-parameter lists for image paragraph captioning. M denotes the model-specifichyper-parameters. lr0 is initial learning rate.
Table 16: Results of different decoding strategies for auto-completion.
Table 17: Image paragraph captioning results for stochastic decoding on Visual Genome testset.
Table 18:	Example 1 of generated continuations for different training objectives.
Table 19:	Example 2 of generated continuations for different training objectives.
Table 20:	Example 1 of generated paragraphs for different training objective on Visual Genometestset.
Table 21:	Example 2 of generated paragraphs for different training objectives on Visual Genometestset.
Table 22:	Example 1 of summaries generated by the model trained with different training objectiveon CNN/DM testset.
Table 23:	Example 2 of summaries generated by the model trained with different training objectiveon CNN/DM testset.
Table 24:	Example 1 of summaries generated by the model trained with different training objectiveon NYT50 testset.
Table 25:	Example 2 of summaries generated by the model trained with different training objectiveon NYT50 testset.
Table 26:	Example of generated continuations for different training objectives on PTB testset.
Table 27:	Example of generated continuations for different training objectives on movie reviewsfrom IMDB dataset.
