Table 1: Distribution for the 14 axiom categories in AxiomStep10 test set. Considering scalars (a, b,...), vectors (~v,w~, ...) and matrices (A, B, ...) types combinations, 147 distinct axioms are represented.
Table 2: Datasets used for studies in experiments.
Table 3: pe-graph2axiom mini ablation study.
Table 4: Performance vs. AST size: counts and percentage pass rates.
Table 5: Performance vs. proof length: percentage pass rates.
Table 6: Counts for equivalence proof possibilitiesProof length in axiomsProof description	1	2	3	4	5	6	7All Possible nodes and axioms	5933	3.5E+07	2.1E+11	1.2E+15	7.4E+18	4.4E+22	2.6E+26Sample Node + Any Axiom	226	46900	1.5E+07	8.8E+09	5.0E+12	3.3E+15	2.7E+18Sample Node + Legal Axiom	11.2	77.8	931	15812	3.4E+05	8.2E+06	1.8E+08Unique Programs from Sample	9.2	47.4	264	1574	10052	65176	4.6E+05D	Language and Axioms for Complex Linear Algebra ExpressionsWe now provide the complete description of the input language for multi-type linear algebra ex-pressions we use to evaluate our work, and the complete list of all axioms that are used to computeequivalence between programs.
Table 7: Full axiom count when all type options and other supported permutations are included (part1 of 2)24Under review as a conference paper at ICLR 2021Rewrite Rule	ID	ExamPle(S)FactorLeft	72rΓ~	ab + ac → a(b+c)	73	ab -ac → a(b-c)	74	AB + AC → A(B+C)	75	AB-AC → A(B-C)	76	Av + Aw → A(v+w)	77	Av - Aw → A(v-w)	78	Aa + Ab → A(a+b)	79	Aa-Ab → A(a-b)	80	va + vb → v(a+b)	81	va -vb → v(a-b)FactorRight	-82-	ac + bc → (a+b)c	83	ac-bc → (a-b)c	84	a/c + b/c → (a+b)/c	85	a/c - b/c → (a-b)/c	86	AC+BC → (A+B)C
Table 8: Full axiom count when all type options and other supported permutations are included (part2 of 2)Rewrite Rule	ID	ExamPle(S)ASSociativeRight	TΓ3-	(a+b)+c → a+(b+c)	114	(a+b)-c → a+(b-c)	115	(ab)c → a(bc)	116	(A+B)+C → A+(B+C)	117	(A+B)-C → A+(B-C)	118	(AB)C → A(BC)	119	(AB)a → A(Ba)	120	(Aa)B → A(aB)	121	(aA)B → a(AB)	122	(Av)a → A(va)	123	(Aa)v → A(av)	124	(aA)v → a(Av)	125	(va)b → v(ab)	126	(av)b → a(vb)	127	(ab)v → a(bv)	128	(v+w)+x → v+(w+x)	129	(v+w)-x → v+(w-x)
Table 9: Hyperparameter experiments. Summary of best validation token accuracy result after 2 runsfor up to 100,000 training iterations. The golden model has 256 graph nodes and decoder dimensions,2 decoder LSTM layers, starts training with a learning rate of 0.8, and uses 10 steps to stabilize theGGNN encoder.
Table 10: Description and results for various language complexities studied with WholeProof models.
Table 11: Generalizing to longer P1 inputs. Percentage pass rates for equivalence proofs with P1having increasing program graph nodes. The model trained with the AxiomStep5 dataset had notraining examples more than 25 program graph nodes yet it performs relatively well on these morecomplex problems. The furthest right column shows the pe-graph2axiom model results on themost complex dataset.
Table 12: Performance vs. AST size: counts and percentage pass rates.
Table 13: Generalizing to longer proofs. Percentage pass rates for equivalence proofs of increasingaxiom counts when testing each of 4 datasets on models trained using each of 4 datasets.
Table 14: Learning multiple output options. When considering scalar expressions that can be provenequivalent by commuting the left and right subexpressions, such as (a + b)(c + d) = (b + a)(d + c),pe-graph2axiom learns that either the left or right commute can occur first. The columns showcounts for axioms and locations proposed by the token generator with beam width of 3 when given120 different scalar expression pairs.
Table 15: Example explorations as a single feature or parameter is changed. Each comparison is adistinct experiment, as the entire network and language used was being varied.
Table 16: Table showing alternate options for handling not equal programsNetwork output Description	Actual	Predicted NotEq	Predicted Rules or Eq	Correct Rewrite RulesEq or NotEq,	Eq	"3.4%	94.6%	"^/ABeam width 1	NotEq	90.4%	9.6%	N/ARules or NotEq,	^q-	-66%	93.4%	70.7%-Beam width 1	NotEq	90.9%	9.1%	N/ARules only,	^q-	"^N∕Λ	100%	87.8%-Beam width 1	NotEq	N/A	N/A	N/ARules only,	"Eq-	"^/A	100%	96.2%-Beam width 10	NOtEq	N/A	N/A	N/A31Under review as a conference paper at ICLR 2021For the first output case, the output sequence to produce is either Equal or Not_equal. Given afalse positive rate of 9.6%, these results demonstrate the importance of producing a verifiable proofof equivalence when using machine learning for automated equivalence checking. For the secondoutput case, the model can produce either Not_equal or a rewrite rule sequence which can bechecked for correctness. The source programs for the first and second case are identical: 250,000equivalent program pairs and 250,000 non-equivalent program pairs. In the second case, the falsepositive rate from the network is 9.1% (rules predicted for Not_equal programs), but the model onlyproduces correct rewrite rules between actual equivalent programs in 70.7% of the cases.
