Table 1: Image classification accuracy (%) on Digits (Volpi et al., 2018) (top) and CIFAR-10-C (Hendrycks & Dietterich, 2019) (bottom). We compare with robust training (Columns 1-4) anddomain generalization (Columns 5-7). For Digits, all models are trained on MNIST (LeCun et al.,1998). For CIFAR-10-C, two widely employed backbones are evaluated. Our method outperformsM-ADA (Qiao et al., 2020) (previous SOTA) consistently in all settings.
Table 2: Few-shot domainadaptation accuracy (%) onMNIST(M), USPS(U), andSVHN(S). |T| denotes the num-ber of target samples (per class)used during model training.
Table 3: Text classification accuracy (%) on Ama- zon Reviews. Models are trained on one text do- main and evaluated on unseen text domains. Our method outperforms others in all settings except “dvd → electronics”.							Table 4: Speech recognition accuracy (%) on Google Commands. Models are trained on clean set and evaluated on five corrupted sets. Results validate our strong generalization on corruptions in both time and frequency domains.							books			dvd			Time			Frequency	Method	d	k	e	b	k	e	Method	Amp.	Pit.	Noise	Stretch	ShiftERM	78.7	74.6	63.6	78.5	82.1	75.2	ERM	63.8	71.6	73.9	72.9	70.5GUD	79.1	75.6	64.7	78.1	82.0	74.6	GUD	64.1	72.1	74.8	73.1	70.9M-ADA	79.4	76.1	65.3	78.8	82.6	74.3	M-ADA	64.5	71.9	75.4	73.8	71.4Ours	802	768	671	801	83.5	^750	Ours	653	73.5	758	75.0-	72.54.4 Ablation StudyIn this section, we perform ablation study to investigate key components of our method. ForDigits (Volpi et al., 2018), we report the average performance of all unseen domains. For CIFAR-10-C (Hendrycks & Dietterich, 2019), we report the average performance of all types of corruptions atthe highest level of severity.
Table 5: Ablation study of feature perturbation.
Table 6: Ablation study of label mixup.
Table 7: Ablation study of training strategy.
Table 8: Few-shot domain adaptation accuracy (%)on MNIST(M), USPS(U), and SVHN(S). |T| de-notes the number of target samples (per class) usedduring model training.
Table 9: Text classification accuracy (%) on Amazon Reviews (Chen et al., 2012). Models are trainedon one text domain and evaluated on unseen text domains. Our method outperforms others in allsettings except “dvd → electronics” and “electronics → dvd”. The possible reason is that “dvd”and “electronics” may share a similar distribution while our method creates large distribution shift.
