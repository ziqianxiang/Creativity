Table 1: Comparison of Testing Top-1 Accuracy (mean ± standard deviation, in %) using DifferentMethods on ResNet-18 over CIFAR-10 and CIFAR-100 for mixupMethod	CIFAR-100	CIFAR-10without mixup	76.97 ± 0.27	94.95 ± 0.17mixup	78.31 ± 0.18	95.67 ± 0.09AugDrop (ours)	80.24 ± 0.34	96.03 ± 0.12MixLoss (ours)	79.70 ± 0.31	95.94 ± 0.11WeMix (ours)	80.61 ± 0.10	96.11 ± 0.11MixLoss-s (ours)	79.53 ± 0.13	95.87 ± 0.14WeMix-s (ours)	80.29 ± 0.22	96.06 ± 0.16stochastic algorithm A2 (e.g., momentum SGD, SGD) for solving the problem over original data.
Table 2: Comparison of Testing Top-1 Accuracy (mean ± standard deviation, in %) using DifferentMethods on ResNet-18 over CIFAR-100 for mixup of three images and ten imagesMethod	3 images	10 imagesMixup	76.56 ± 0.23	60.36 ± 0.88AugDrop	80.18 ± 0.19	76.35 ± 0.27MixLoss	79.61 ± 0.09	75.41 ± 0.19WeMix	80.41 ± 0.22	78.08 ± 0.11Table 3: Comparison of Testing Top-1 Accuracy (mean ± standard deviation, in %) using DifferentMethods on WideResNet-28-10 over CIFAR-10 and CIFAR-100 for Contrast TransformationMethod	CIFAR-100	CIFAR-10without Contrast	78.07 ± 0.27	95.51 ± 0.14Contrast	77.90 ± 0.26	95.66 ± 0.05AugDrop (ours)	78.40 ± 0.24	95.93 ± 0.21MixLoss (ours)	78.17 ± 0.20	95.70 ± 0.11WeMix (ours)	78.79 ± 0.18	95.81 ± 0.11better than two baselines, with and without mixup, which matches the theory found in Section 4.
Table 3: Comparison of Testing Top-1 Accuracy (mean ± standard deviation, in %) using DifferentMethods on WideResNet-28-10 over CIFAR-10 and CIFAR-100 for Contrast TransformationMethod	CIFAR-100	CIFAR-10without Contrast	78.07 ± 0.27	95.51 ± 0.14Contrast	77.90 ± 0.26	95.66 ± 0.05AugDrop (ours)	78.40 ± 0.24	95.93 ± 0.21MixLoss (ours)	78.17 ± 0.20	95.70 ± 0.11WeMix (ours)	78.79 ± 0.18	95.81 ± 0.11better than two baselines, with and without mixup, which matches the theory found in Section 4.
