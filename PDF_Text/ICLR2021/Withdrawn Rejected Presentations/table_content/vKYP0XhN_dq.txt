Table 1: Simulated Dataset in variations of P and ”.
Table 2: Experimental results on IMDBRatios	P =10			P = 20			P = 50		Metrics		Precision	Recall		Precision	Recall		Precision	RecallBaseline	0.7291	0.8751	0.6248	0.3216	0.6677	0.2118	0.0833	0.69	0.0443ROS	0.7548	0.702	0.8162	0.5738	0.5839	0.564	0.5837	0.5618	0.6061RUS	0.7921	0.7305	0.865	0.1837	0.6758	0.1063	0.0256	0.6065	0.0131ST	0.7956	0.7499	0.8472	0.5844	0.5984	0.571	0.5601	0.5266	0.5981ST + EWC	0.8002	0.7181	0.9035	0.7543	0.7368	0.7727	0.6457	0.7188	0.586ST+EWC+ROS	0.8143	0.7984	0.8307	0.7259	0.6728	0.788	0.6471	0.6156	0.6819IMDB Results. Table 2 shows the experimental results on the IMDB dataset (Maas et al., 2011). Weobserve training the model with ST outperforms, if not on par with, traditional methods. Baseline isa setting where no deep learning techniques are employed therefore the learner is trained from theintrinsic imbalanced distribution. Results show a considerable increase in recall when ST is applied.
Table 3: Experimental results on image dataRatios	(CIFAR-10) P = 5		μ = 0.6	(CIFAR-10) P =10		μ = 0.8	(MNIST)	P =10 μ = 0.8	Metrics	rɪl	Precision	I ReCan	rɪl	Precision I	Recall	F1 I Precision		I ReCanBaseline	0.6695	0.6187	0.8794	0.6333	0.5903	0.8422	0.8931	0.8897	0.8966ROS	0.8187	0.7956	0.8540	0.8194	0.7960	0.8525	0.8984	0.8978	0.8990RUS	0.8263	0.8028	0.8567	0.8294	0.8073	0.8556	0.8263	0.8981	0.8990ST	0.7916	0.7633	0.8329	0.7901	0.7495	0.8428	0.8962	0.8941	0.8984ST + EWC	0.8033	0.7733	0.8403	0.8260	0.8045	0.8511	0.8968	0.8950	0.8987ST + EWC + ROS	0.8298	0.8122	0.8532	0.8311	0.8099	0.8566	0.8986	0.8980	0.8992CIFAR-10 and MNIST Results. Table 3 shows the results of experiments performed on the twoimage datasets. While MNIST (Lecun et al., 1998) is a simple handwritten digits dataset withoutcolor information, CIFAR-10 (Krizhevsky, 2012) is a relatively complicated image classificationtask with color information. The experimental results manifest larger gap exists when using ST onCIFAR-10 rather than on MNIST. This accounts to the relative simplicity of MNIST dataset whichalleviates the shortcoming of skewed data during representation learning. This shows that ST greatlybenefits the learner in a difficult setting where the the task difficulty and imbalance ratio is severe.
