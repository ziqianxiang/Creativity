Table 1: Minimum of FIDs on different Datasets. The FID results are calculated every 10 epochs,and are averaged over five independent runs. LoWer is better.
Table 2: Results of our stacked MNIST experiments. The first four rows are directly copied from(Lin et al., 2018) and (Srivastava et al., 2017). And the last three rows are obtained after training eachmodel for 100K iterations, respectively.
Table 3: Minimum FID scores of IVLSGAN underdifferent hyperparameter settings on the CIFAR10dataset, calculated every 10 epochs.
Table 4: The NN architecture used by us, where CONV denotes the convolutional la yer, TCONVdenotes the transposed convolutional layer, FC denotes the fully-connected layer, BN denotes thebatch normalization layer, and (K4, S1, O512) denotes a layer with kernel of size 4, stride 1, and 512output channels.
Table 5: Detailed hyperparameter settings in our experiments.
