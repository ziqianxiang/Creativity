Table 1: Results on CIFAR-10 (top panel) and 5 class subset of LSUN (bottom panel) datasets with varying imbalance. In the last column FIDvalues in balanced scenarios are present for ease of reference. FID, KL Div. and Acc. are calculated on 50k sampled images from each GAN.
Table 2: Comparison of results in Semi Supervised Setting. The pretrained classifierused in our framework is fine-tuned with 0.1% of labelled data. The same classifiertrained on balanced dataset is used as annotator for calculating KL Divergence for allbaselines.
Table 4: Comparison of	our UAP performance (Fooling Rate) to the state-of-the-art ap-	ResNet-50 model. *For ImageNet we find that -H(C(x), yx ) (i.e. negative cross entropy) is more effective hence we reportproaches. The Mean FR	is the mean of VGG-16, VGG-19 and ResNet-152 as those are	the better fooling rate.
Table 6: Validation Accuracy of the PreTrained Classifiers used With GAN’s. The balanced classifieralso serves as an annotator.
Table 7: Generator of SNDCGAN (Miyato et al., 2018; Radford et al., 2015) used for CIFAR10image synthesis.
Table 8: Discriminator of SNDCGAN (Miyato et al., 2018) used for CIFAR10 image synthesis.
Table 9: Generator of SNResGAN used for LSUN image synthesis.
Table 10: Discriminator of SNResGAN (Miyato et al., 2018; Gulrajani et al., 2017) used LSUN forimage synthesis.
Table 11: Values of λ for different imbalance cases. For LSUN the λ gets divide by 5 and for λ itgets divided by 10 before multiplication to regularizer term.
Table 12: Hyperparameter Setting for Image Generation Experiments.
Table 13: Values of λ for different imbalance cases. For LSUN the λ gets divide by 5 and for λ itgets divided by 10 before multiplication to regularizer term.
Table 14: Hyperparameters for DCGAN.
Table 15: Generator of DCGAN (Radford et al., 2015) used for UAP Experiments.
Table 16: Discriminator of DCGAN (Radford et al., 2015) used for UAP Experiments.
