Table 1: Classification accuray (%) on adversarial exmples crafted on the test set of CIFAR-10. We report per-formance of resisting PGD attacks with 10, 50 and 200 iterations. The numbers in parentheses are performanceimprovements achieved by applying our method.
Table 2: Classification accuray (%) on adversarial examples crafted on the test set of CIFAR-100. We reportperformance of resisting PGD attacks with 10, 50 and 200 iterations. For targeted attacks on IAT models,defense perturbations are generated in an untargeted manner. The numbres in parentheses are performanceimprovements achieved by applying our method.
Table 3: Classification accuracy (%) of different method used in combination with Guo et al.’s (2018). Wereport performance of resisting targeted attacks on Mixup trained models.
Table 5: Parameter settings for experiments on CIFAR-10. For each experiment, the number ofexecutions is set to 50 for Xie et al.’s and Guo et al.’s and to 30 for MI-OL. [T] denotes smallperturbations are generated in a targeted manner and [U] denotes mall perturbations are generatedin an untargeted manner.
Table 6: Parameter settings for experiments on CIFAR-100. For each experiment, the number ofexecutions is set to 50 for Xie et al.’s and Guo et al.’s and to 30 for MI-OL. [T] denotes smallperturbations are generated in a targeted manner and [U] denotes mall perturbations are generatedin an untargeted manner.
