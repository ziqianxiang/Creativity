Table 1: Comparison of computational com-plexity for precomputing and forward passcorresponding to an entire epoch.
Table 2: Statistics of datasets. “m” denotes multi-label classification.
Table 3: Results on ogbn-papers100M in terms of classi-fication accuracy (in percent). The reported accuracy isaveraged over 10 random runs. Note that existing sam-pling methods cannot scale to this massive graph. Dur-ing precomputation, both SGC and our models have to ran-domly remove 40% edges to avoid a memory overflow onCPU. This implies that the performance could be furtherimproved if more advanced PrecomUting platform is used.
Table 4: Results on ogbn-products in terms ofclassification accuracy (in percent). The re-ported accuracy is averaged over 10 randomruns. Obtaining the results of GCN requires aGPU with 33GB of memory.
Table 5: Results for inductive learning on threedatasets in terms of F1-micro score. The re-ported score is averaged over 10 random runs.
Table 7: Comparison of models with and without capturing order information. Neighbor2Seq+Attnw/o PE denotes the Neighbor2Seq+Attn without adding positional encoding.
Table 8: The chosen hyperparameters for our models on all datasets.
