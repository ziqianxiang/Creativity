Table 1: Statistics of evaluation sets designed for evaluating gender biasPremise: To measure the bias, we select 38 different occupations to include a variety of genderdistribution characteristics and occupation types, in correspondence with US Current PopulationSurvey 1 (CPS) 2019 data and prior literature (Zhao et al. (2018a)). The selected occupations rangefrom being heavily dominated (with domination meaning greater than 70% share in a job distribu-tion) by a gender, e.g. nurse, to those which have an approximately equal divide, e.g. designer. Thelist of occupations considered can be found in Appendix (A.3).
Table 2: The source sentence acts as a placeholder and we replace the source occupation with thetarget occupation to generate a new sentence. This is done to augment our evaluation set to ensureequal number of premises for all 38 occupations.
Table 3: Templates used for generation of hypothesis. Here gender corresponds to male or femalesuch as ”This text talks about a female occupation”/ ”This text talks about a male occupation”.
Table 4: Configurations of the models tested for gender-biasHyperparameters: We fine-tune above models on MNLI and SNLI datasets each generating a totalof 6 models (3 for each dataset) to test our evaluation sets on. The pretrained configuration used foreach of the models is mentioned in Table 4. We train all models using AdamW optimizer with β 1= 0.9, β2 = 0.999 and L2 weight decay of 0.01. A learning rate of 1e-5 was used for RoBERTa and2e-5 for the other two models. We train each of these models for 3 epochs for both the datasets.
Table 5: Performance of the models when fine-tuned on SNLI and MNLI datasets respectively. Themetric Acc indicates the model accuracy when trained on original NLI dataset (SNLI/MNLI) andevaluated on dev set (dev-matched for MNLI), S is the number of instances with same prediction:entailment or contradiction, ∆P denotes the mean absolute difference in entailment probabilities ofmale and female hypothesis and B denotes the number of times the entailment probability of thehypothesis aligning with the stereotype was higher than its counterpart (higher values for the lattertwo metrics indicate stronger biases). Numerics in bold represent the best value (least bias) for eachmetric. SNLI (O) and MNLI (O) represent the performance of various models fine-tuned on SNLIand MNLI respectively but tested on out-of-distribution evaluation set. SNLI (I) and MNLI (I) onthe other hand have been tested on in-distribution evaluation set.
Table 6: Detailed analysis of how bias varies with respect to male and female dominated occupa-tions. Numerics in bold indicate the better value for each metric across the two genders. The biasfor male-dominated jobs is comparatively higher than female-dominated ones. Notations are sameas those in Table 5.
Table 7: Performance of the models after debiasing. Notations are same as those in Table 5.
