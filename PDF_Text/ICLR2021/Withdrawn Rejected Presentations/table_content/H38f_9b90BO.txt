Table 1: Dataset statistics after removing self-loops and duplicate edges (Wang & Leskovec, 2020)	Cora	Citeseer	Pubmed	Coauthor-Phy#nodes	2708	3327	19717	34493#edges	5278	4552	44324	247962#features	1433	3703	500	8415#classes	7	6	3	5#Intra-class edge rate	81.0%	73.6%	80.2%	93.1%Table 2: Comparison with baselines in test accuracy (%) on Cora and Citeseer with uniform noiseranging from 0% to 80%. Mean accuracy (std) over 5 repetitions are reported. The best and thesecond best results are highlighted in bold and italic bold respectively.
Table 2: Comparison with baselines in test accuracy (%) on Cora and Citeseer with uniform noiseranging from 0% to 80%. Mean accuracy (std) over 5 repetitions are reported. The best and thesecond best results are highlighted in bold and italic bold respectively.
Table 3: Comparison with baselines in test accuracy (%) on Cora , Citeseer and Pubmed with flipnoise ranging from 0% to 40%. Mean accuracy (std) over 5 repetitions are reported. The best andthe second best results are highlighted in bold and italic bold respectively.
Table 4: Comparison with baselines in test accuracy (%) on Clothing1M and Webvision. Meanaccuracy (± std) over 5 repetitions are reported. The best is highlighted in bold.
Table 5: The performance of LPM without label aggregation and LPM with random λ in Citeseer.
Table A.6: Comparison with baselines in test accuracy (%) on Cora and Pubmed with flip noiseranging from 0% to 40% and Graph Attention Networks. The best result are highlighted in bold.
Table A.7: Comparison with baselines in test accuracy (%) on Coauthor-Phy with flip noise rangingfrom 0% to 40%. The best result are highlighted in bold.
Table A.8: The hyper-parameters of LPM in different datasets.
