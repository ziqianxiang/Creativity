Table 1: Accuracy scores (×100%) on all three intent detection data sets with varying number oftraining examples (Few: 10 training utterances per intent; Full: full training data). The full dataresults of Casanueva et al. (2020) are trained on more data as they forego a validation set. We followthe setup of Mehri et al. (2020), wherein a portion of the training set is used as the validation set.
Table 2: Accuracy scores (×100%) for transferring to unseen intents averaged over 30 runs wherein4-10 intents are removed from the few-shot setting during training and added back in during evalu-ation. The last row corresponds to the best results that were trained with all of the intents, shown inTable 1.
Table 3:	Accuracy scores (×100%) for transferring across datasets (in the full data setting) usingthe ConvBERT + MLM + Example + Observers model. The diagonal consists of results where themodel was trained and evaluated on the same dataset.
Table 4:	Micro-averaged F-1 scores for the task of reproducing the words of the input (using onlythe most frequent 1000 words) given the different latent representations.
