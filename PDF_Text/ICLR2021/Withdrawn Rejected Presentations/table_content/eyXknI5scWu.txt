Table 1: Evaluation of masking-based saliency map methods. Each block captures one set ofexperiments. FIX indicates a fixed classifier, CA (Classifier-Agnostic) indicates training against apool of continually trained classifiers. MaxClass (I), MinClass (O) and MaxEnt (O) are masked-in classification-maximization, masked-out classification-minimization and masked-out entropymaximization objectives for the masker. Layer[∙] indicates the layer or layers of classifier activationsprovided as input to the masker. Inf[∙] indicates the infiller operation applied after masking-the defaultotherwise is no infilling. Columns show mean and standard errors over 5 runs for evaluation metricsOfficial Metric (OM) and Localization Error (LE) for weakly supervised localization, Saliency Metric(SM) and Pixel Average Precision (PxAP). UnderIined results are the best results within that block,while bold are the best results for data set, excluding baselines.
Table 2: Hyperparameter search space and chosen hyperparameters. Sets of values in a row indicate agrid search over all combinations in that row. Where there is a search, the hyperparameters for thebest model, corresponding to results shown in Table 1, are underlined.
Table 3: Evaluation of masking-based saliency map methods. Each block captures one set ofexperiments. FIX indicates a fixed classifier, CA (Classifier-Agnostic) indicates training against apool of continually trained classifiers. MaxClass (I), MinClass (O) and MaxEnt (O) are masked-in classification-maximization, masked-out classification-minimization and masked-out entropymaximization objectives for the masker. Layer[∙] indicates the layer or layers of classifier activationsprovided as input to the masker. Inf[∙] indicates the infiller operation applied after masking-thedefault otherwise is no infilling. Columns show mean and standard errors over 5 runs for F1 and theaverage mask magnitude. UnderIined results are the best results within that block, while bold are thebest results for data set, excluding baselines.
Table 4: Evaluation of masking-based saliency map methods, varying the layers provided tothe masker. FIX indicates a fixed classifier, CA (Classifier-Agnostic) indicates training against apool of continually trained classifiers. MaxClass (I), MinClass (O) and MaxEnt (O) are masked-in classification-maximization, masked-out classification-minimization and masked-out entropymaximization objectives for the masker. Layer[∙] indicates the layer or layers of classifier activationsprovided as input to the masker. Inf[∙] indicates the infiller operation applied after masking-thedefault otherwise is no infilling. Columns show evaluation metrics Official Metric (OM), LocalizationError (LE) and F1 for weakly supervised localization, Saliency Metric (SM) and Pixel AveragePrecision (PxAP). Mask indicates numerical average of masking pixel values. UnderIined resultsindicates the best results within that block, while bold indicates best results for data set, excludingbaselines.
Table 5: Data Randomization Test. The saliency map methods are applied to both a regular classifier,as well as a classifier trained on randomly shuffled labels, and the similarity of the generated saliencymaps are measured. Both FIX and CA methods show low similarity between the saliency mapsgenerated by regular and shuffled classifiers.
