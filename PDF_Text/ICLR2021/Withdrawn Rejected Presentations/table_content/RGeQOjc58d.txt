Table 1: Clean and adversarial accuracy (PGD attack with L∞ bound) on the test set of CIFAR-10using ResNet-18 and VGG-16. In brackets, we mention number of random restarts used to perform theattack. Note, BNNs outperform adversarial accuracy of floating point networks consistently.
Table 2:	Adversarial accuracy on the test set for BNN-WQ. Both our NJS and HNS variants consistentlyoutperform original L∞ bounded FGSM and PGD attack, and L2 bounded PGD attack.
Table 3:	Adversarial accuracy on the test set of CIFAR-10 for REF and BNN-WAQ. Both our NJS andHNS variants consistently outperform original FGSM and PGD (L∞∕L? bounded) attacks.
Table 4: Adversarial accuracy on the test set of CIFAR-10 with ResNet-18 for adversarially trainedREF and BNN-WQ using different quantization methods (BC, GD-tanh, MD-tanh-S). Our improvedattacks are compared against FGSM, L∞ bounded PGD, a heuristic choice of β = 0.1, DeepFool andBBA. Albeit on adversarially trained networks, our methods outperform all the comparable methods.
Table 5: Adversarial accuracy for REF, BNN-WQ, and BNN-WAQ trained on CIFAR-10 using ResNet-18.
Table 7: Adversarial accuracy for REF, BNN-WQ and BNN-WAQ trained on CIFAR-10 using ResNet-18.
Table 6: Attack parameters ( & η in pixels).
Table 8: Adversarial accuracy on the test set of CIFAR-100 for REF (floating point networks). Both ourNJS and HNS variants consistently outperform original FGSM and PGD (L∞∕L2 bounded) attacks.
Table 9: Adversarial accuracy on the test set of CIFAR-10 for BNN-WAQ. Here, we compare ourproposed variants against much stronger attacks namely DeepFool (Moosavi-Dezfooli et al. (2016))and BBA (Brendel et al. (2019)). Both our variants outperform stronger attacks. Note, DeepFool andBBA are much slower in practise requiring 100-1000 iterations. BBA specifically requires even anadversarial start point that needs to be computed using another adversarial attack.
Table 10: CLEVER Scores (Weng et al. (2018)) for BNN-WQ and BNN-WAQ trained on CIFAR-10 usingResNet-18. We compare CLEVER Scores returned for L1 norm perturbation using different ways oftemperature scaling applied. Here, Original refers to original network without temperature scalingand Heuristic denotes temperature scale with small β = 0.01.
Table 11: Adversarial accuracy on the test set for binary neural networks using L∞ bounded PGD++attack using NJS with varying ρ. For different values of ρ, our approach is quite stable.
Table 12: Mean and standard deviation of Jacobian Singular Values (JSV), mean ∣ψ ∣2, mean∣∣∂'∕∂x0k2 and mean ∣∣sign(∂'∕∂x0)∣∣2 for different methods on CIFAR-10 with ReSNet-18 computedwith 500 correctly classified samples. Note here for NJS and HNS, JSV is computed for scaled jacobiani.e. βJ. Also note that, values of ∣∣ψ∣2, k∂'(β)∕∂x0∣2 and ∣∣sign(∂'(β)∕∂x0)k2 are largerfor ourNJS and HNS variant (for most of the networks) as compared with network with no β, which clearlyindicates better gradients for performing gradient based attacks.
Table 13: Adversarial accuracy on the test set for adversarially trained networks and binary neuralnetworks using L∞ bounded PGD++ attack with varying ρ as lower bound on the gradient of networkoutput for ground truth class k. Here * denotes the adversarially trained models obtained whereadversarial samples are generated using L∞ bounded PGD attack with with T = 7 iterations, η = 2and E = 8. Note, here PGD++ attack refers to PGD attack where ∂'(β)∕∂aK is bounded by P foreach sample, where k is ground truth class.
