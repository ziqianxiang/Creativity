Table 1: Mean and Standard Deviation of DBM and AM Scores for vanilla Raw Zero-Shot Classifiers.
Table 2: Mean and Standard Deviation of DBM and AM values for different Raw Zero-ShotClassifiers with and without the adversarial defences on CIFAR-10. Values in the parentheses arep-values of the paired samples t-test between the metric values of defences and those without defences.
Table 3: Pearson correlation coefficient of DBM and AM with Mean L2 Score of Adversarial Attacksfor each vanilla classifier and attack pair. Values in the parentheses are p-values of the Pearsoncorrelation test.
Table 4: Description of Super-Classes used in the Sub-ImageNet.
Table 5: Classifier Accuracy (and loss value) on test dataset of the learned classes for differentarchitectures.
Table 6: Description of Adversarial Defence ParametersAll the adversarial defences used in the article have been evaluated using Adversarial Robustness 360Toolbox (ART v1.2.0) Nicolae et al. (2018). Table 6 describes the defence parameters used for theevaluated adversarial defences. Table 7 shows the classifier accuracy and corresponding loss valueon the test dataset of the learned classes for various adversarial defences. All the classifiers exceptCapsNet use standard cross-entropy loss, while CapsNet uses margin loss (Sabour et al., 2017). AsRaw Zero-Shot Classifier, forcefully excludes the images of a class for training, we get the accuracyof the Raw Zero-Shot Classifier on N - 1 learned classes of the dataset.
Table 7: Classifier Accuracy on test dataset of the learned classes for different architectures.
Table 8: Description of Adversarial Attack Parametersrf~,l∙⅛ccifiοι∙	Adversarial Accuracy (in %)	Mean L? Scoreasser	FGM BIM PGD DF	NF	FGM BIM	PGD	DF	NFFashion MNISTMLP	91.08	91.29	91.29	27.16	25.39	210.73	638.83	638.83	309.41	289.28ConvNet	86.89	89.20	89.18	23.63	22.67	306.25	669.56	665.76	314.81	263.65CIFAR-10LeNet	84.58	89.12	89.25	31.70	84.12	152.37	345.27	357.34	132.32	49.61VGG	82.79	94.97	94.99	65.08	92.43	181.29	321.86	329.96	651.65	77.01AllConv	67.09	69.11	69.11	51.46	61.86	155.95	273.90	274.15	487.46	61.05NIN	72.49	74.26	74.26	59.94	66.76	140.46	216.97	216.96	492.90	54.78ResNet	52.75	55.41	55.41	58.71	54.39	124.70	164.64	164.64	458.57	51.56DenseNet	50.78	52.11	52.11	60.83	50.81	120.03	160.34	160.38	478.03	53.89WideResNet	69.59	89.42	89.44	60.10	82.73	159.88	208.44	208.49	613.14	63.13CapsNet	70.02	82.23	84.46	87.40	90.04	208.89	361.63	370.90	258.08	1680.83Sub-ImagenetInceptionV3	85.76	87.24	87.24	86.94	58.44	796.53	1204.01	1204.01	609.54	319.73ResNet-50	85.74	86.72	86.72	84.78	60.84	826.06	1264.30	1264.34	633.30	336.80Table 9: Adversarial Accuracy and Mean L2 Score for each classifier and adversarial attack pair.
Table 9: Adversarial Accuracy and Mean L2 Score for each classifier and adversarial attack pair.
Table 10: Confidence Difference Score and it’s Pearson Correation value (and p-value) for eachclassifier and adversarial attack pair.
