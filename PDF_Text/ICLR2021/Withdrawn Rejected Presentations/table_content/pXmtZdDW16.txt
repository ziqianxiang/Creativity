Table 1: Performance test (50 trials of training for each cases)Reward	Environment	Baseline	Testing size : Robot (R) / Task (T)									2R/20T	3R/20T	3R/30T	5R/30T	5R/40T	8R/40T	8R/50T	Deterministic	%Optimal (GUrobi 60min)	98.31	97.50	97.80	95.35	96.99	96.11	96.85Linear		%Ekisi et al.	99.86-	97.50	-^118.33^^	110.42	105.14	104.63	120.16		%SGA	-1373-	-120.6	129.7	110.4	123.0	119.9	119.8	Stochastic	%SGA	-130.9-	-115.7	122.8	115.6	122.3	113.3	115.9Nonlinear	Deterministic	%SGA	-111.5~	-118.1	118.0	110.9	118.7	111.2	112.6	Stochastic	%SGA	110.8	117.4	119.7	111.9	120.0	110.4	112.4Transferability test. Table 2 shows comprehensive transferability test results. The rows indicatetraining conditions, while the columns indicate testing conditions. The results in the diagonal cells inred (cells with the same training size and testing size) serve as baselines (direct testing). The resultsin the off-diagonal show the results for the transferability testing, and demonstrate how the algorithmstrained with different problem size perform well on test problems. We can see that lower-directiontransfer tests (trained with larger size problems and tested with smaller size problems) show only asmall loss in performance. For upper-direction transfer tests (trained with smaller size problems andtested with larger size problems), the performance loss was up 4 percent.
Table 2: Transferability test (50 trials of training for each cases, linear & deterministic env.)	TeSting SiZe			: Robot (R) / Task (T)			Training size (Robot(R)/Task(T))	2R/20T	3R/20T	3R/30T	5R/30T	5R/40T	8R/40T	8R/50T2R/20T	98.31	93.61	97.31	92.16	92.83	90.94	93.443R/20T	95.98	97.50	96.11	93.64	91.75	91.60	92.773R/30T	94.16	96.17	97.80	94.79	93.19	93.14	93.285R/30T	97.83	94.89	96.43	95.35	93.28	92.63	92.405R/40T	97.39	94.69	95.22	93.15	96.99	94.96	93.658R/40T	95.44	94.43	93.48	93.93	96.41	96.11	95.248R/50T	95.69	96.68	97.35	94.02	94.50	94.86	96.856	Concluding RemarksWe developed a theory of random PGM-based mean-field inference method and provided a theoreticaljustification for a simple modification of popular GNN methods to embed a random graph. Thistheory was motivated from addressing the challenge of developing a near-optimal learning-basedalgorithm for solving NP-hard multi-robot/machine scheduling problems. While precise inferenceof Q-function is required to address this challenge, the two-layer random structure2vec embeddingprocedure we suggested has shown an empirical success. We further address inscalability problem ofQ-learning methods for multi-robot/machine scheduling problem by suggesting a polynomial-timeassignment algorithm with a provable performance guarantee.
Table 3: IPMS test results for makespan minimization with deterministic task completion time (ouralgorithm / best Google OR tool result)Makespan minimization		# Machines					3	5	7	10	50	106.7%	117.0%	119.8%	116.7%# Tasks	~y5~	105.2%	109.6%	113.9%	111.3%	"T00^	100.7%	111.0%	109.1%	109.0%A.1.2 ExperimentsFor IPMS, we test it with continuous time, continuous state environment. While there have been manylearning-based methods proposed for (single) robot scheduling problems, to the best our knowledgeour method is the first learning method to claim scalable performance among machine-schedulingproblems. Hence, in this case, we focus on showing comparable performance for large problems,instead of attempting to show the superiority of our method compared with heuristics specificallydesigned for IPMS (actually no heuristic was specifically designed to solve our exact problem(makespan minimization, sequence-dependent setup with no restriction on setup times))For each task, processing times is determined using uniform [16, 64]. For every (task i, task j)ordered pair, a unique setup time is determined using uniform [0, 32]. As illustrated in AppendixA.1, we want to minimize make-span. As a benchmark for IPMS, we use Google OR-Tools libraryGoogle (2012). This library provides metaheuristics such as Greedy Descent, Guided Local Search,Simulated Annealing, Tabu Search. We compare our algorithmâ€™s result with the heuristic with the
Table 4: Training complexity (mean of 20 trials of training, linear & deterministic env.)Linear & Deterministic		Testing Size : Robot (R)/ Task (T)								2R/20T	3R/20T	3R/30T	5R/30T	5R/40T	8R/40T	8R/50TPerformance with full training	98.31 ^^	97.50	97:80^^	95.35	96.99	96.11	96.85# Training for 93 optimality	19261.2	61034.0	^^99032.7	48675.3	48217.5	45360.0	47244.2A.9 Code for the experimentFor the entire codes used for experiments, please go to the following Google drive link for the codes.
