Table 1: Results for FixNorm-tune and BO+WD	FixNorm-tune	BO + WD	Reference Lr	a	top-1(%)±std	Lr	λ	top-1(%)±std	Lr λ	top-1(%)±stdResNet50-D MobileNetV2	~44^^0.5~~78.62±0.054^^053^^8.6e-5^^78.53±0.047^^04^^1Z-4^^78.37±0.051 0.5	16.0	73.20±0.032	0.64 2.2e-5	72.84±0.024	0.2 4e-5	72.04±0.027As in Table 1, both FixNorm-tune and BO+WD outperform reference settings by a clear margin.
Table 2: Results with FixNorm-tune models with * are applied with tricks, ↑means the result isobtained using lr and λ from basic settings(MobileNetV2 150 and ResNet50-D 120)Model	#Epochs	Top-1	Top-1 (ref.)	#Params	#FLOPS	lr	αMobileNetV2	150	73.20	72.04	3.5M	300M	0.5	16.0MobileNetV2	350	73.97	73.38t	3.5M	300M	0.35	8.0EfficientNet-B0	350	77.72	77.30	5.3M	384M	0.5	4.0EfficientNet-B1	350	79.52	79.20	7.8M	685M	0.8	8.0MobileNetV2×1.12*	350	77.40	76”	4.7M	386M	0.5	8.0MobileNetV2×1.54*	350	79.18	78.75t	8.0M	682M	0.65	4.0ResNet50-D	120	78.62	78.37	25.6M	4.3G	1.4	0.5ResNet50-D	350	79.29	79.04t	25.6M	4.3G	1.1	0.5ResNet50-D*	350	81.27	80.80t	28.1M	4.3G	1.1	1.04	Related worksWe only highlight the most related works in this section and leave other works in Appendix E dueto the page limit.
Table 3: Results with FixNorm-tune on CityscapesModel	#Iters	VaL mIoU(%)	hyperparameters		baseline	40000	78.7	lr	0.01, λ =	0.0005baseline w/ cosine lr	40000	78.3	lr	0.01, λ =	0.0005FixNorm-tune	40000	79.4	lr	0.0335, α	= 1.0FixNorm-tune w/ cosine lr	40000	79.7	lr	0.043, α	1.0D.3 Experiments on MS COCOSetups To verify our FixNorm-tune method on object detection task, we train RetinaNetLin et al.
Table 4: Results with FixNorm-tune on MS COCOModel	#Iters	Val. AP(%)	hyperparametersbaseline	90000	36.5	lr=0.01, wd=0.0001baseline w/ cosine lr	90000	36.2	lr=0.01, wd=0.0001FixNorm-tune	90000	36.9	lr=0.0145, α = 0.5FixNorm-tune w/ cosine lr	90000	37.1	lr=0.0145, α = 0.514Under review as a conference paper at ICLR 2021D.4 Experiments on Group NormalizationExcept for the widely used Batch Normalization layer, other types of normalization layers have beenproposed. According to the ELR hypothesis, FixNorm should also work for them. To verify theeffectiveness of our method, we conduct experiments with Group Normalization on ImageNet. Wechoose ResNet50-D in Table 2 and replace BN layers by Group Normalization layers with a groupnumber of G = 32. As shown in Table 5, when trained with Group Normalization, FixNorm-tuneconsistently improves the top-1 accuracy over the reference result as when trained with BN.
Table 5: Results for FixNorm-tune with Group Normalization models with * are applied withtricks, ↑means the result is obtained using lr and λ from basic Settings(ResNet50-D 120)Model	#Epochs	Top-1	Top-1 (ref.)	#Params	#FLOPS	lr	αResNet50-D*	350	81.27	80.80t	28.1M	4.3G	1.1	1.0ResNet50-D*(G=32)	350	80.92	80.3H	28.1M	4.3G	1.4	1.0E Appendix—Additional related worksHyperparameter Optimization (HPO). Hyperparameter Optimization is an important topic foreffectively training DNNs. One straightforward method is grid search, which is only affordablefor a very limited number of hyperparameters since the combinations grow exponentially. Ran-dom search(Bull, 2011) is a popular alternative that selects hyperparameter combinations randomly,which can be more efficient when the resource is constrained. Bayesian Optimization(BO) (Brochuet al., 2010) further improves efficiency by building a model on historical information to guide theselection. Hyperband(Li et al., 2017) allocates different budgets to random configurations and re-jects bad ones according to the performance obtained under low budgets. BOHB (Falkner et al.,2018) combines BO with Hyperband to select more promising configurations. Both Hyperbandand BOHB highly relies on the assumption that performance under different budgets is consistent.
