Table 1: Experimental results under various regularization methods on ResNet. Arrows on themetrics represent the desirable direction. We searched four hyperparameters for each method andchose the best hyperparameter based on validation accuracy (cf. appendix A). Values represent meanobtained from five repetitions, and all values are rounded to two decimal places.
Table 2: Misclassification detection and OOD detection task performances based on NBAUCC0.5(higher is better). MC-D (p) represents MC-dropout with probability p, and Ens represents deepensemble.
Table 3: Experimental results under various regularization methods on BERT. Arrows on the metricsrepresent the desirable direction. Values represent mean obtained from five repetitions, which arerounded to two decimal places.
Table 4: Best hyperparameters for each configurationRegularizer	VGG-16 & CIFAR-10	VGG-16 & CIFAR-100	ResNet-50 & CIFAR-10	ResNet-50 & CIFAR-100k fW k1	0.01	0.03	0.01	0.01k fW k22	0.003	0.01	0.003	0.01SWi(μW ,ν)	0.001	0.03	0.001	0.01PER	0.003	1.0	0.03	1.0B VGG resultsAs consistent with the results of ResNet, all regularization losses improves NLL, ECE, and accuracy(Table 5), except L1 regularization on CIFAR-100. However, the improvements are less significantcompared to ResNet because the small capacity of VGG makes the vanilla method produces lessconfident answers and then less vulnerable to the confidence penalty. This can be inferred from thatvalues of k f W k2 of VGG are reduced by almost 50% compared to those of ResNet.
Table 5: Experimental results under various regularization methods. Arrows on the metrics repre-sent the desirable direction. Values represent μ ± σ obtained from five repetitions, and all values arerounded to two decimal places.
