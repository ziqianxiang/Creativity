Table 1: Top1 test accuracy(%) on various datasets and models. Our baseline follows the samebaseline settings of AutoAugment; the first two columns show our reproduced baseline results andthe ones reported by AutoAugment respectively.
Table 2: Efficiency on variouS dataSet. Unit: GPU hour; hardware: FaSt AA - TeSla V100, AutoAug-ment - TeSla P100, PBA - Titan XP. DaSheS indicate unavailable figureS; deSpite the unavailability,the advantage of our method in termS of Search coSt iS apparent.
Table 3: Multi-stage augmentation study on 2 vs. 3 stages and epoch allocation for each stage.
Table 4: Low to high complexity (increasing image distortion).
Table 5: Face recognition and text detection results	Default	Fast AA	OursLFW	99.20	99.27	99.25AgeDB-30	91.82	91.88	91.92CFP-FP	94.31	95.53	95.17(a) Face recognition accuracy on the standard bench-mark datasetI Default Fast AA OurSF1	50.36	50.51	54.27Precision	44.64	44.1	50.96Recall	57.76	59.1	58.04Avg. Precision	46.58	48.29	48.35E-Score	1.44	1.46	1.47(b) Text detection results on the ICDAR MLT 2017dataset. Note that E-Score is our customized metric.
Table 6: Ablation study result. In ”Stoch. + 2-stage”, the first stage consists of stochastic trans-formations on top of baseline augmentations and only the baseline augmentations for the secondstage.
Table 7: Details of the hyperparameters in our experiments: We used the models: Wide-ResNet (40-2, 28-2, 28-10) (Zagoruyko & Komodakis, 2016), Shake-Shake (26 2x32d, 26 2x96d, 26 2x112d)(Gastaldi, 2017), PyramidNet+ShakeDrop (Han et al., 2017; Yamada et al., 2019) and ResNet-50(He et al., 2016).
