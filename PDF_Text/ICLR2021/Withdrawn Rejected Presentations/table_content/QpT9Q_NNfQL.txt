Table 1: Θ values used in the recovering bandits’ caseClass θo Value θι ValueA	10	0.2B	8.5	0.4C	7	0.6D	5.5	0.8Next state s[t + 1]: The state evolves based on the selected action. If a[t] = 1, the state is reset tos[t + 1] = 1, meaning that bandit’s reward decayed to the initial waiting time z[t + 1] = 1. If thearm is left passive a[t] = 0, the next state becomes s[t + 1] = min{z[t] + 1, zmax}.
