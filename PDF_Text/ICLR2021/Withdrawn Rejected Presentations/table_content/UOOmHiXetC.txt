Table 1: Comparison on evaluation of MCTS and STS. C, H areparameters in Algorithm 1. S. rate is the ratio of solved boards,Np,Nt(= Np ∙ H), Ng are the average number of passes, treenodes and game states observed until the solution is found. Fulltable is available in Table 4.
Table 2: Summary of selected algorithms’ performance on GRF. Entries are rounded solved rates.
Table 3: Default values of hyper-parameters used in our experiments.
Table 4: Evaluation of various STS settings on SokobanA.7.2 MCTS and Shooting on simpler b oardsWe found the Bandit Shooting method underperforming on Sokoban. As a sanity test, we tested asimpler setting with smaller boards of size (6, 6) and two boxes. Learning curves are presented inFigure 4. MCTS and STS experiments quickly learn to solve over 99% of boards. Bandit Shootingexperiment showed stable but much slower progress. We also evaluated the version of BanditShooting, with additional loop avoidance, see Section A.5. This mechanism was beneficial for MCTSand STS but failed to bring improvements for the shooting algorithms.
Table 5: Comparison of STS with leaf evaluation using a Q-value network and MCTS with differentleaf evaluations: Q-value network only (Conv.), network + deterministic rollout (Conv.+d.r.), network+ random rollout using the prior policy (Conv.+r.r.). In all experiments we used the same convolutionalnetwork architecture. The reported results are the median solved rates across 3 runs.
