Table 1: Results for the music domain. To evaluate low-level structure, we use negativelog likelihood according to MusicAutoBot, Magenta’s verrsion of MusicVAE designed forhierarchical 16-bar melodies, and GraphVAE. For high-level structure, we use accuracy ofthe random forest (“RF Disc.”) and GCN cross entropy loss (“GCN Disc.”). The best(non-human) score in each column is bolded; the human score is italicized if best. We alsobold the model that achieves the best NLL on the held-out human data.
Table 2: Results for the poetry domain. To evaluate low-level structure, we use the negativelog likelihood per token of a fine-tuned version of BERT and GPT2. For high-level structure,we use cross-entropy loss of the GCN (“GCN Disc.”). We also show the information entropy.
