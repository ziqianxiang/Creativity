Table 1: Results on Balanced-RAVEN dataset (joint training).
Table 2: Results on PGM dataset.
Table 3: Sanity check on RAVENwhen context images are maskedout.
Table 4: Test Compositional Structure Loss and the symbolic representation prediction accuracy forthe model trained on joint tasks.
Table 5: Generalization to unseen attribute-relationship pairs for joint training data.
Table 6: Single Task Training results on Balanced-RAVEN dataset.
Table 7: Joint Training results on RAVEN dataset.
Table 8:	How important is sharing?Test AccuracySharing Non-sharing95.0	12.3How to choose the number of heads of N a? We took the single training setting of the configu-ration Center for illustration. Since there are in total 3 attributes in this task (color, size, type), itmay suggest using 3 heads for Na is a good choice on this task. However, this turned out to be apoor choice. The average test accuracy over 5 runs were shown in Table 9. We found that as weincrease the number of heads, it is easier for the model to learn the ground truth solution. We believethis is because of an ensemble effect, where more number of neurons provide more opportunities forlearning the correct attribute concepts.
Table 9:	How to choose the number of heads of Na for Center?Test Accuracy4	8	8057.3 43.2	100.0Table 10:	Test accuracy with various number of heads of N o in joint training setting.
Table 10:	Test accuracy with various number of heads of N o in joint training setting.
Table 11: Generalization to various number of relationships on Center.
Table 12: Generalization to various number of relationships on L-R.
Table 13: Generalization to various number of relationships on U-D.
Table 14: Generalization to various number of relationships on O-IC.
Table 15: Generalization to unseen attribute-relationship pairs.
