Table 1: Quantitative evaluation on CUB-200-2011 with batch size b = 144, embedding dimensiond = 128 and multiple learning rates lr = {0.01, 0.001, 0.0001}. 4R@1 column indicates the R@1improvement margin relative to the vanilla ranking loss. A large learning rate lr increases the chanceof model collapse, while a small lr slows convergence. Î» is dependent on the ranking loss.
Table 2: Quantitative evaluation on Stanford Online Products.
