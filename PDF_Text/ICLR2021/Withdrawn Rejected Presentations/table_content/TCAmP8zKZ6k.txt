Table 1: Diagnosis accuracy of different baselines on MZ dataset and DX datasetsMethod	I.D.		MZ			Overall		AR	U.R.I.	DX Pneu. H.F.M.		I.D.	Overall			Dysp. U.R.I.		Bronch.								SVM-ex	0.89		0.28	0.44	0.71	0.59		0.5	0.92	0	0.8	0.95	0.64SVM-ex&im	0.91		0.34	0.52	0.93	0.71		0.7	0.96	0.35	0.75	0.9	0.74Basic DQN (2018)		-	-	-	-	0.65		0.7	0.79	0.55	0.7	0.9	0.73KR-DS (2019)	0.96		0.39	0.5	0.97	0.73		0.9	0.67	0.3	0.95	0.9	0.74Our INS-DS	0.87		0.55	0.60	0.82	0.73		0.75	0.96	0.3	0.95	0.8	0.76Table 2: Dialogue performance on DX dataset								Table 3: Robustness on MZ dataset.					Method		Acc. Match rate			#turns				Method			NS.1	NS.2	NS.3Basic DQN (2018)		0.731		0.110	3.92		Basic DQN (2018)				0.669	0.785	0.699Sequicity (2018)		0.285		0.246	3.40		KR-DS (2019)				0.883	0.864	0.806KR-DS (2019)		0.740		0.267	3.36		KR-DS-relation* (2019)				0.760	0.836	0.785Our INS-DS		0.760		0.290	5.84		Our INS-DS				0.840	0.883	0.835on this method, KR-DQN incorporates the pre-defined symptom-disease conditional probability totransform the output of DQN to improve diagnostic performance. For fair comparison, we adoptthe same NLU from (Xu et al., 2019) for all baselines. Following the same settings as (Wei et al.,2018) and (Xu et al., 2019), we also includes the supervised learning baselines SVM-ex (usingexplicit symptoms as input), SVM-ex&im (using explicit and implicit symptoms as input) as well asSequicity (Lei et al., 2018) (sequence-to-sequence model). Since these supervised learning methods
Table 2: Dialogue performance on DX dataset								Table 3: Robustness on MZ dataset.					Method		Acc. Match rate			#turns				Method			NS.1	NS.2	NS.3Basic DQN (2018)		0.731		0.110	3.92		Basic DQN (2018)				0.669	0.785	0.699Sequicity (2018)		0.285		0.246	3.40		KR-DS (2019)				0.883	0.864	0.806KR-DS (2019)		0.740		0.267	3.36		KR-DS-relation* (2019)				0.760	0.836	0.785Our INS-DS		0.760		0.290	5.84		Our INS-DS				0.840	0.883	0.835on this method, KR-DQN incorporates the pre-defined symptom-disease conditional probability totransform the output of DQN to improve diagnostic performance. For fair comparison, we adoptthe same NLU from (Xu et al., 2019) for all baselines. Following the same settings as (Wei et al.,2018) and (Xu et al., 2019), we also includes the supervised learning baselines SVM-ex (usingexplicit symptoms as input), SVM-ex&im (using explicit and implicit symptoms as input) as well asSequicity (Lei et al., 2018) (sequence-to-sequence model). Since these supervised learning methodswere not trained or evaluated with interactive processes, we only evaluate the accuracy of thesemethods to highlight the effectiveness of the RL baselines.
Table 4: Internal/external trusts and diagnosis entropy on MZ and DX datasets.
