Table 1: Comparison of variants of QWR with AWR (Peng et al., 2019), SAC (Haarnoja et al., 2018)and PPO (Schulman et al., 2017) on 4 MuJoCo environments at 100K samples.
Table 2: Comparison of variants of QWR with the sample-efficient variant of Rainbow (Hessel et al.,2017; van Hasselt et al., 2019), MPR (Schwarzer et al., 2020), SimPLe (Kaiser et al., 2019) andrandom scores on 6 Atari games at 100K samples. We report results of the the augmented andon-augmented version of the MPR algorithm. Since MPR and SimPLe are based on learning a modelof the environment, we do not consider them when choosing the best scores.
