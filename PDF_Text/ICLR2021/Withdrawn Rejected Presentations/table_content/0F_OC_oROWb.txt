Table 1: Accuracy of RSO on the MNIST data set compared with back propagation and WANN.
Table 2: Accuracy of RSO on the MNIST data set reported at different stages of training whilesamPling at different levels - at the network level, at the layer level and at the weight level. The finalPerformance and the rate of convergence when samPling at the weight level is significantly betterthan other strategies.
Table 3: Accuracy of RSO with architectures of varying dePth on CIFAR-10. The〈•〉bracketsrePresent a basic residual block (He et al. (2016)) which contains two convolution layers Per blockand a skiP connection across the block. Each convolution layer is rePresented as the filter size andthe number of outPut filters. The conv2 and conv3 stages are followed by a 2 × 2 average Poolinglayer. The accuracy increases as the dePth increases which demonstrates the ability of random searchoPtimization to learn well with deePer architectures.
