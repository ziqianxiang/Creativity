Table 1: A comparison of robust models. Stochastic smoothing arises from methods like the onespresented in Cohen et al. (2019) and Salman et al. (2019). Adversarial training from Madry et al.
Table 2: Average classification inference time (seconds)Model	CIFAR-10		ImageNet-1k		CPU	GPU	CPU	GPUDeterministic (ours)	0.0049	0.0080	0.0615	0.0113Stochastic (Cohen et al., 2019)	0.0480	0.0399	0.1631	0.09322Under review as a conference paper at ICLR 20212	Related workThe issue of adversarial vulnerability arose in the works of Szegedy et al. (2014) andGoodfellow et al. (2015), and has spawned a vast body of research. The idea of trainingmodels to be robust to adversarial attacks was widely popularized in Madry et al. (2018).
Table 3: £2 adversarial distance metrics on ImageNet-IkModel	L-bound		PGD		DDN		median	mean	median	mean	median	meanHeatSmoothing	0.240	0.190	2.7591	2.6255	1.0664	1.2261SmoothAdv	0.160	0.160	3.5643	3.0244	1.1537	1.2850RandomizedSmoothing	0.200	0.180	2.6787	2.5587	1.2114	1.3412Undefended baseline	-	-	1.0313	1.2832	0.8573	0.98647Under review as a conference paper at ICLR 2021Oooo8 6 4 2(T,dot)(u26m 】uuw」(udOOOo8 6 4 2(I—dot)①①」6E1U0JQ」① d(a) top-1 classification agreement between a given (b) top-1 classification agreement between ourmodel and its own stochastic average prediction deterministic model and a Cohen et al. modelfor varying σ.	prediction for varying σ.
Table 4: 22 certified radii summary statistics for robust models on ImageNet-IkModel	median	£2 radius mean	max.
Table 5: £2 adversarial distance metrics on CIFAR-10. A larger distance implies a more robustmodel.
