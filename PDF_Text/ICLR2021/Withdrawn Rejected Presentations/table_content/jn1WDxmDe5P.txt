Table 1: Controller Architecture. The depth of the model increases from top to bottom. Activationfunction Tanh is not added for the brevity. It is applied to all the layers but the output layer. d is theinput feature dimension and n_acts is the length of the actions vector (range of possible k's).
Table 2: Results on the scikit-learn datasets generated with make_blobs function Here we show theaverage differences error for datasets of 5 to 50 classes.
Table 3: Comparison to previous works. Experiment settings: # of Samples=10,000, dataset=blobsGround truth ∣ Meta-k Garg & Kalai (2018) Baseline ( Silhouette score)2	2	3	23	3	3	34	4	3	45	5	2	56	6	3	67	7	10	78	6	10	89	9	10	910	10	10	10As it can be seen in Table 4, Meta-K achieves higher performance in datasets with higher dimen-sionality.
Table 4: Comparison to previous works on MNIST & FMNIST datasets.
Table 5: Experimentation results on the scikit-learn datasets created with make_blobs function. Vari-able were set to: # Samples=1000, # Features=10k# Classes	MLP1	MLP2	MLP35	6	3	210	6	6	515	6	21	1420	21	22	2325	24	24	2330	34	24	2735	34	34	3540	34	34	3545	34	34	3450	34	34	35mean diff	0.216635	0.228302	0.21661110Under review as a conference paper at ICLR 2021Table 6: Experimentation results on the Scikit-learn datasets created with make_blobs function. Vari-able were set to: # Samples=1000, # Features=20k
Table 6: Experimentation results on the Scikit-learn datasets created with make_blobs function. Vari-able were set to: # Samples=1000, # Features=20k# Classes	MLP1	MLP2	MLP35	5	3	210	15	3	1315	25	13	1420	25	21	2425	33	22	2230	33	33	3335	34	34	3440	34	34	3445	34	34	3450	34	35	34mean diff	0.257968	0.222635	0.212968Table 7: Experimentation results on the SCikit-learn datasets created with make_blobs function. Vari-able were set to: #Samples=1000, #Features=30k# Classes	MLP1	MLP2	MLP35	3	5	2
Table 7: Experimentation results on the SCikit-learn datasets created with make_blobs function. Vari-able were set to: #Samples=1000, #Features=30k# Classes	MLP1	MLP2	MLP35	3	5	210	13	6	1215	25	17	1420	24	17	2125	22	23	2430	22	34	3535	34	34	3140	34	34	3345	34	34	3550	35	34	35mean diff	0.267635	0.163968	0.193484As expected, by increasing the size of the datasets, our model’s predictions became more accurate.
Table 8: Experimentation results on the Scikit-learn datasets created with make_blobs function. Vari-able were set to: #Samples=10,000, #Features=10k# Classes	MLP1	MLP2	MLP35	5	5	510	12	9	1115	16	14	1220	18	19	2125	19	23	2230	22	25	2635	34	27	3240	34	27	3645	39	31	3450	36	41	34mean diff	0.146524	0.150802	0.135349Table 9: Experimentation results on the SCikit-learn datasets created with make_blobs function. Vari-able were set to: #Samples=10,000, #Features=20k# Classes	MLP1	MLP2	MLP35	3	5	6
Table 9: Experimentation results on the SCikit-learn datasets created with make_blobs function. Vari-able were set to: #Samples=10,000, #Features=20k# Classes	MLP1	MLP2	MLP35	3	5	610	6	9	815	16	14	1620	16	19	1925	20	20	2330	23	26	3035	33	29	3340	39	37	3345	39	37	3750	39	37	37mean diff	0.193548	0.123421	0.126659Table 10: Experimentation results on the scikit-learn datasets created with make_blobs function.
Table 10: Experimentation results on the scikit-learn datasets created with make_blobs function.
