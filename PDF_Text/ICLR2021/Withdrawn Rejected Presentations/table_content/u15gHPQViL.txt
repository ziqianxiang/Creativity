Table 1: Summary of the datasets used in the experimentsDataset	Embedding dim.	Number of classes		Number of samples					Seen	Unseen	Training	Test (seen)	Test (unseen)	TotalSUN (Patterson & Hays, 2012)	102	580 + 65	72	10,320	2,580	1,440	14,340CUB (Welinder et al., 2010)	312	100 + 50	50	7,057	2,967	1,764	11,788AWA2 (Lampert et al., 2014)	85	27 + 13	10	23,527	5,882	7,913	37,322aPY (Farhadi et al., 2009)	64	15 + 5	12	5,932	1,483	7,924	15,339(Xian et al., 2019a) for detailed descriptions. We followed the new split provided by (Xian et al.,2019a) because this split ensured that classes at test should be strictly unseen at training.
Table 2: Ablation study on effects of different design choices	ZSL		GZSL				-acc-	accu	accs	Hlinear h + linear g	56.97	19.56	28.71	23.27linear h + nonlinear g	54.56	17.15	31.99	22.32nonlinear h + linear g	58.01	19.68	31.08	24.10nonlinear h + nonlinear g	58.30	19.88	36.41	25.724.2	Ablation S tudyFirst, We investigate the effects of different designs of the image-to-classifier mapping function h(∙)and the label classifier g(∙). We reported the results on the SUN benchmark; however, similarfindings can be found using other datasets.
Table 3: Standard zero-shot learning results (top-1 accuracy) on four benchmark datasetsMethod	SUN	CUB	AWA2	aPYDAP (Lampert et al., 2009)	39.9	40.0	46.1	33.8IAP (Lampert et al., 2009)	19.4	24.0	35.9	36.6CONSE (Norouzi et al., 2014)	38.8	34.3	44.5	26.9CMT (Socher et al., 2013)	39.9	34.6	37.9	28.0SSE (Zhang & Saligrama, 2015)	51.5	43.9	61.0	34.0LATEM (Xian et al., 2016)	55.3	49.3	55.8	35.2ALE (Akata et al., 2013)	58.1	54.9	62.5	39.7DeViSE (Frome et al., 2013)	56.5	52.0	59.7	39.8SJE (Akata et al., 2015)	53.7	53.9	61.9	32.9ESZSL (Romera-Paredes & Torr, 2015)	54.5	53.9	58.6	38.3SYNC (Changpinyo et al., 2016)	56.3	55.6	46.6	23.9SAE (Kodirov et al., 2017)	40.3	33.3	54.1	8.3GFZSL (Verma & Rai, 2017)	60.6	49.3	63.8	38.4IGSC	58.3	56.9	62.1	35.2Table 4: Generalized zero-shot learning results (top-1 accuracy and H) on four benchmark datasets.
Table 4: Generalized zero-shot learning results (top-1 accuracy and H) on four benchmark datasets.
Table 5: N1 skewness on SUN benchmark.
Table 6: Ablation study on effects of different visual modelsBackbone	accu	SUN accs	H	accu	CUB accs	H	accu	AWA2 accs	H	accu	aPY accs	HRes-101	22.5	36.1	27.7	27.8	66.8	39.3	19.8	84.9	32.1	13.4	69.5	22.5Res-152	23.7	36.1	28.6	28.6	68.0	40.3	22.7	83.9	35.7	14.9	67.6	24.4Res-101+CS	39.4	31.3	34.9	40.8	60.2	48.7	25.7	83.6	39.3	23.1	58.9	33.2Res-152+CS	40.8	31.2	35.3	42.9	61.0	50.4	27.1	83.0	40.9	26.4	53.3	35.3(a)	S)Figure 3: t-SNE visualization of the model space learned by IGSC: (a) seen classes, (b) unseenclasses. Best viewed in color.
