Table 1: SMAC EnvironmentsName	Ally Units	Enemy Units	Type3m	3 Marines	3 Marines	homogeneous & symmetric8m	8 Marines	8 Marines	homogeneous & symmetric25m	25 Marines	25 MarineS	homogeneous & symmetric3s5z	3 Stalkers & 5 Zealots	3 Stalkers & 5 Zealots	heterogeneous & symmetric	1 Medivac,	1 Medivac,	MMM	2 Marauders &	2 Marauders &	heterogeneous & symmetric	7 Marines	7 Marines	5m_vs_6m	5 Marines	6 Marines	homogeneous & asymmetric8m_vs_9m	8 Marines	9 Marines	homogeneous & asymmetric10m_vs 11m	10 Marines	11 Marines	homogeneous & asymmetric27m_vs_30m	27 Marines	30 Marines	homogeneous & asymmetric3s5z_vs_3s6z	3 Stalkers & 5 Zealots	3 Stalkers & 6 Zealots	heterogeneous & asymmetric	1 Medivac,	1 Medivac,	MMM2	2 Marauders &	3 Marauders &	heterogeneous & asymmetric	7 Marines	8 Marines		1 Colossi &	1 Colossi &	1c3s5z	3 Stalkers &	3 Stalkers &	heterogeneous & symmetric	5 Zealots	5 Zealots	
Table 2: Memory usage (given the current size of the replay buffer) for the training of each method(exclude COMA, which is an on-policy method without using replay buffer) on scenarios of SCIIdomain in SMAC.			Scenario Name	Memory Usage (GB)	3m	27	2m_vs_1z	2.8	5m_vs_6m	3	3s_vs_5z	4	6h_vs_8z	4.6	8m	4.8	8m_vs_9m	4.9	3s5z	6.4	10m_vs_11m	7.1	3s5z_vs_3s6z	7.5	1c3s5z	8.6	MMM	8.7	MMM2	10.8	corridor	14.4	25m	27	27m_vs_30m	39.5
Table 3: Baseline algorithmsBrief DescriptionIndependent Q-learningValue decomposition networkCounterfactual Actor-criticMonotonicity Value decompositionValue decomposition with linear affine transformMARL with variational method for explorationMulti-head attention for decomposing the global Q valuesIQL (Tampuu et al., 2017)VDN (Sunehag et al., 2017)COMA (Foerster et al., 2017a)QMIX (Rashid et al., 2018)QTRAN (Son et al., 2019)MAVEN (Mahajan et al., 2019)Qatten (Yang et al., 2020)G Additional Experiments on SMACG. 1 AblationsWe use the same hyper-parameters in ablation study unless otherwise specified.
Table 4: Hyper-parametershyper-parameter	ValueBatch-size	32Replay memory size	5,000Optimizer	AdamLearning rate (lr)	5e-4Critic lr	5e-4RMSProp alpha	0.99RMSProp epsilon	0.00001Gradient norm clip	10Action-selector	-greedy-start	1.0-finish	0.05-anneal-time	50,000 stepsTarget-update-interval	200Evaluation interval	10,000Number of atoms (m)	55K	10Runner	episodeTraining steps	1, 2, 3, 1.5, 2.5 and 8 millions
