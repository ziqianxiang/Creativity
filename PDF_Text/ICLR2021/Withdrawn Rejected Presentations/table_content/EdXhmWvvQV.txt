Table 1: Top-1 accuracies under linear evaluation on ImageNet, using ResNet-50 as encoder Method	Accuracy (%)		Table 2: Semi-supervised learning with few shot ImageNet labels, using ResNet- 50 as encoder (averaged by 5 trials)				Method	Top-1 / Top-5	Supervised	76.5						1 QZ lokplo 1 labels	1∩QZ Iohplc 10 labels				Colorization (Zhang et al., 2016)	39.6	Supervised	25.4 48.4	56.4 56.4Jigsaw (Noroozi & Favaro, 2016)	45.7	PIRL	30.7 57.2	60.4 83.8NPID (Wu et al., 2018)	54.0	SimCLR	48.3 75.5	65.6 87.8LA (Zhuang et al., 2019)	58.8	MoCo v2	52.4 78.4	65.3 86.6MoCo (He et al., 2020)	60.6	BYOL	53.2 78.4	68.8 89.0SeLa (YM. et al., 2020)	61.5	SwAV	53.9 78.5	70.2 89.9PIRL (Misra & Maaten, 2020)	63.6	SimCLRv2	57.9 82.5	68.4 89.2CPCv2 (Henaff et al., 2019)	63.8	CLIM	59.3 81.6	70.0 89.3PCL (Li et al., 2020)	65.9	Table 3: Transfer learning on VOC object		SimCLR (Chen et al., 2020a)	70.0	detection (averaged by 5 trials).		MoCo v2 (Chen et al., 2020c)	71.1	Method	Accuracy (%)	SimCLRv2 (Chen et al., 2020b)	71.7		AP50	AP75InfoMin (Tian et al., 2020)	73.0	Supervised 81.4		58.8BYOL (Grill et al., 2020)	74.3	MoCo v2 82.5		64.0SwAV (Caron et al., 2020)	75.3	SwAV	82.6	-
Table 4: Transfer learning on COCO detection and instance segmentation (averaged by 5 trials)Method	Mask R-CNN,R50-FPN,Det		Mask R-CNN,R50-FPN,InsSeg		1× schedule	2× schedule	1× schedule	2× schedule	APbb APb0 AP75	APbb APbO AP75	APmk APmk APmk	APmk APmOk APmkSupervised	38.9 59.6 42.0	40.6 61.3 44.4	35.4	56.5	38.1	36.8^^5871 ^^39.5MoCo v2	39.2 59.9 42.7	41.5 62.2 45.3	35.7	56.8	38.1	37.5^^591 ^^40.1CLIM	39.5 60.0 43Γ	41.8 62.3 457~	35.8	57.0	38.6	37.7	59.4	40.54.2	Semi-supervised training on ImageNetWe also evaluate our method by fine-tuning the pretrained model with a small subset of labels,following the semi-supervised settings in (Grill et al., 2020; Kornblith et al., 2019; Chen et al.,2020a; Caron et al., 2020). For fair comparisons, we use the same fixed 1% and 10% splits oftraining data as in (Chen et al., 2020a), and fine-tune all layers using SGD optimizer with momentumof 0.9, and learning rate of 0.0001 for backbone, 10 for the newly initialized fc layer. The fine-tuneepochs is set as 60, and the learning rate is decayed by 0.1 after every 20 epochs. During training,only random cropping and flipping data augmentations are used for fair comparison. The results arereported in Table 2. CLIM achieves 59.3% top-1 accuracy with only 1% labels, and 70.0% with 10%labels. The performance gains are larger with 1% labels, e.g., 6.1% higher than BYOL, and 5.4%better than SwAV, which demonstrates that the proposed feature representation is mainly suitablefor extremely few shot learning. Note that SimCLR v2 makes use of other tricks like more MLPlayers for better performance, while our method simply adds one fc layer, and still achieves better
Table 5: Transfer learning on LVIS long-tailed instance segmentation (averaged by 5 trials)Method	ObjectDet			Instance Seg			APbb	APb5b0	APTr	APbb	mk AP50	AP7m5kSupervised	24.1	39.4	25.0	24.2	37.8	25.1MoCo v2	25.1	40.4	26.1	25.3	38.4	27.0CLIM	~255	41.2	167~	~256	39.5	27.5Table 6: Impact of different sample selectionStrategy	Accuracy (%)		no mixing	+cutmixMoCo v2	-^675^^	-Random	62.3	67.1KNN	68.3	69.5K-means	68.0	69.2KNN ∩ K-means	68.5	69.6Center-wise	-^693^^	70.1Table 7: Impact of different multiple resolutionsMethod	Resolution	Accuracy (%)Multi-Crop	2×224 + 2×96	69.7	r,r0 ∈ {224, 96}	70.4Multi-Reso	r, r0 ∈ {224, 128}	71.7
Table 6: Impact of different sample selectionStrategy	Accuracy (%)		no mixing	+cutmixMoCo v2	-^675^^	-Random	62.3	67.1KNN	68.3	69.5K-means	68.0	69.2KNN ∩ K-means	68.5	69.6Center-wise	-^693^^	70.1Table 7: Impact of different multiple resolutionsMethod	Resolution	Accuracy (%)Multi-Crop	2×224 + 2×96	69.7	r,r0 ∈ {224, 96}	70.4Multi-Reso	r, r0 ∈ {224, 128}	71.7	r, r0 ∈ {224, 160}	72.3	r, r0 ∈ {224, 224}	71.44.4	Ablation StudyIn this section, we present ablation studies to better understand how each component affects the per-formance. Detailed comparisons include 1) positive sample selection, 2) cutmix data augmentation,and 3) multi-resolution augmentation. Unless specified, we train the model for 200 epochs over the
Table 7: Impact of different multiple resolutionsMethod	Resolution	Accuracy (%)Multi-Crop	2×224 + 2×96	69.7	r,r0 ∈ {224, 96}	70.4Multi-Reso	r, r0 ∈ {224, 128}	71.7	r, r0 ∈ {224, 160}	72.3	r, r0 ∈ {224, 224}	71.44.4	Ablation StudyIn this section, we present ablation studies to better understand how each component affects the per-formance. Detailed comparisons include 1) positive sample selection, 2) cutmix data augmentation,and 3) multi-resolution augmentation. Unless specified, we train the model for 200 epochs over theImageNet-1000 and report the top-1 classification accuracy under linear evaluation protocol.
Table 8: Impact of the number of clusters m and k of knnNumber of Clusters (m)		5000		10000			20000		knn (k)	20	40	60	20	40	60	20	40	60Accuracy (%)	69.1	69.5	69.4	70.0	70.1	69.7	69.6	69.9	69.5The number of Clusters m and the k in Knn. Here we inspect the impact of the number of clustersm in k-means and the k in knn to analyze their effect on the performance. In order to ensure localsimilarity, we restrict the nearest neighbors within a range from 20 to 60. The results for differentclusters and top-k neighbors are shown in Table 8. We observe that CLIM consistently improves1It is hard for fair comparison w.r.t. training epochs, since different methods make use of different epochsand batchsize. e.g., BYOL and SimCLR report results on 1000 epochs, while MoCo and SwaV are 800 epochs.
Table 9: Impact of α in cutmixα	1.0	1.5	2.0	2.5AccUracy (%)	697	69.9	70.1	69.8Ablation study on mixing strategies. Our method targets at generating new samples that expandingthe neighborhood of an anchor. Here we compare performance of using mixup data augmentation,a widely used method in supervised settings. We try different choices of beta distribution for Mixup(Zhang et al., 2017) and choose the best one (α = 0.2) for comparison. Table 10 shows that Cutmixperforms better than Mixup, partially because mixup destroys the real pixel distribution (destroysthe naturality of pixels).
Table 10: Ablation study on the mixing methodsMethod Accuracy (%)MixUP	69.5Cutmix	70.1Extra ablation experiments for longer training schedule. We comPare the imProvements broUghtby different comPonents of oUr ProPosed method for longer training schedUle (800 ePochs). Table 11shows the toP-1 accUracies Under linear evalUation Protocol. OUr method consistently oUtPerformsthe MoCo v2 baseline, which demonstrates the effectiveness of oUr ProPosed method.
Table 11: Ablation stUdy on the longer training schedUleMethod	AccUracy (%)MoCo v2	71.1Center-wise + cUtmix	73.7Center-wise + cUtmix + MUlti-reso	75.2C More Experimental ResultsVisualization of Feature Representation. We visUalize the featUre sPace to better Understand howCLIM aUgmentation PUlls similar samPles. SPecifically, we randomly choose 10 classes from thevalidation set and Provide the t-sne visUalization of featUre rePresentation generated by CLIM, sU-Pervised training and MoCo v2. As shown in Fig. 3, the same color denotes featUres with the samelabel. It can be shown that CLIM takes on higher aggregation ProPerty comParing with MoCo, andthe fUlly sUPervised learned rePresentation reveals the highest aggregation dUe to it makes Use of im-age labels. FUrthermore, we comPUte the intra-class similarity as the average cosine distance amongall intra-class Pairwise samPles, and rePort the average similarity across 1000 classes, as shown inTable 12, CLIM achieves an intra-class similarity of 0.65, which is mUch higher than that in MoCov2 with similarity of only 0.58. As comParison, we also list the resUlt of sUPervised learning, with asimilarity metric of 0.75.
Table 12: Intra-class similarity for different modelsTable 13: Results of different training epochsMethod	Intra-class Similarity	Epochs Accuracy (%)	Supervised	075	200	72.3MoCo v2	0.58	800	75.2CLIM	0.65	1200	75.5Results of Different Training Epochs. In Table 13, we compare CLIM trained with differentepochs. Our method achieves an accuracy of 72.3% with only 200 epochs, 75.2% with 800 epochs,and can be further improved to 75.5% when training with 1200 epochs.
Table 13: Results of different training epochsMethod	Intra-class Similarity	Epochs Accuracy (%)	Supervised	075	200	72.3MoCo v2	0.58	800	75.2CLIM	0.65	1200	75.5Results of Different Training Epochs. In Table 13, we compare CLIM trained with differentepochs. Our method achieves an accuracy of 72.3% with only 200 epochs, 75.2% with 800 epochs,and can be further improved to 75.5% when training with 1200 epochs.
