Table 1: Architectures of Model A through D used for MNIST and Fashion-MNIST and CNN usedfor CelebA. The total number of parameters of each model is provided after the model name.
Table 2: Attack success rate (ASR, %) of adversarial examples generated by AT-GAN and the baselineattacks against models by normal training and various adversarial training methods. For each model,the highest ASR is highlighted in bold. Notation: Nor. — Normal training, Adv. — Adversarialtraining, Ens. — Ensemble adversarial training, Iter. — Iterative adversarial training.
Table 3: Comparison on the average example generation time, measured by generating 1000 adver-sarial instances using Model A on MNIST.
Table 4: Abbreviations for network architectures.
Table 5: Architecture of WGAN_GP with auxiliary classifier for MNIST and Fashion-MNIST.
Table 6: Hyper-parameters of different attack methods on MNIST, Fashion-MNIST and CelebA.
Table 7: Transferability of non-constrained adversarial examples and other search-based adversarialexamples on three datasets. For MNIST and Fashion-MNIST, we attack Model C with adversarialexamples generated on Model A. For CelebA dataset, we attack VGG16 using adversarial examplesgenerated on CNN. Numbers represent the attack success rate (%).
Table 8:	Attack success rate (ASR, %) of AT-GAN With various values for kρk0 using Model A onMNIST dataset.
Table 9:	Attack success rate (ASR, %) of AT-GAN with various values for kρk∞ using Model A onMNIST dataset.
Table 10: The evaluation results on the percentage of realistic images by human evaluation.
Table 11: Attack success rate (%) of adversarial examples generated by FGSM, PGD and AT-GANagainst wide ResNet w32-10 by normal training (Nor.) and iterative adversarial training (Iter.).
