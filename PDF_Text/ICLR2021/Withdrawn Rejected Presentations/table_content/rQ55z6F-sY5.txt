Table 1: Average proportion of pixels considered salient for the training set. The regions considered salientare obtained after applying binarization to Grad-CAM heat maps.
Table 2: Top-1 accuracy for image classification.
Table 3: Classification using z.
Table 4: NotationsA.2 Dataset StatisticsDataset	Y0	#Training	#Test	Image SizeCIFAR-10(Krizhevsky, 2009)	10	50,000	10,000	32×32STL-10(Coates et al., 2011)	10	5,000	8,000	96×96BMW-10(Krause et al., 2013)	10	258	254	224×224CUB-203	20	515	600	224×224Pets(Parkhi et al., 2012)	37	3,680	3,669	224×224CUB-200(Wah et al., 2011)	200	5,994	5,794	224×224Table 5: DatasetsA.3 Grad-CAM VisualizationsWe provide more visualisations to compare the recognised salient regions across baselines in figure4.
Table 5: DatasetsA.3 Grad-CAM VisualizationsWe provide more visualisations to compare the recognised salient regions across baselines in figure4.
Table 6: VGG-11 Top-1 accuracyResults: We notice in table 7 that the INN performance is quite similar to that of the baseline whenthe image size is small. Similar trend was observed in case of CIFAR-10 as well. We believe thatINNs and the baseline both utilize equal portion of the input image to generate representations,which leads to similar performance in accuracy.
Table 7: STL-10 accuracy for different image sizesB EXPERIMENT: LABEL EMBEDDINGS, ψWe have witnessed that INNs rely on ψ and z to make a correct prediction. Also, depending on thecontent of the dataset, ψ can play a vital role in further improving the performance. In this experi-mental set up, we aim to explore more about ψ. Specifically, how different encoded labels relate toeach other. We believe that the visual content of images drives the learning of label embeddings, i.e.
Table 8: Nearest label match for ψC Experiment: Out-Of-Distribution DetectionIn this section, we experiment the robustness of the learnt classifiers for detecting out-of-distribution(OOD) images. The standard approach is to utilise the predicted confidence in distin-guishing in- and out-of-distribution data(Hendrycks & Gimpel, 2017). Following this framework,we report the AU-ROC for models trained on the chosen datasets while tested on out-of-distributiondatasets of LSUN(Yu et al., 2015), Tiny ImageNet(Le & Yang, 2015), Fashion-MNIST(Xiao et al.,2017). The out-distribution datasets are standardised using mean and standard deviation of the in-distribution datasets. The INN models chosen correspond to INN(N = 9) in table 2.
Table 9: AUROC(in %) for out-of-distribution evaluation. Higher is better.
Table 10: Top-1 accuracy for STL-10 under varying activationsC.1 Experiment: Different activations for label encoderIn the main paper, the label encoder branch consisted of a 2 layered MLP with no activation. In thisexperiment, we apply the following 4 activations to the label encoder units and train INN(N = 9,b = 32) on the STL-10 dataset.
Table 11: Test accuracy for different input yResults: Table 11 shows that label encoding ψ play a vital role in classification of the input images.
