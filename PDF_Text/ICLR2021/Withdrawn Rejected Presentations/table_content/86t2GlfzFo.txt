Table 1: Table of Contributions: comparison between our released soft-	Figure 1: Deviation of the mini-batch Hessian (left)/GGN (right)ware and that of another PyTorch based Hessian tool PyHessian	spectral norm from the full dataset, Figure from Granziol (2020).
Table 3: Eigenspectrum plotting code and corresponding stem plotFinally, with the eigenValues and eigenVectors computed, we might be interested in knowing howsensitiVe the network is to perturbation along these directions. To achieVe this, we first construct aloss landscape by setting the number of query points and maximum perturbation to apply. To achieVethat, we call the code giVen in Table 4. In this example, we set the maximum perturbation to be 1Loss Surfacebuild_loss.landscape (dataset='CIFAR100' ,data.path= ' data / ' ,model= ' VGG16' ,dist =1., n_points =21,spectrum_path = hessian ’checkpoint_path = 'ck. ptSaVe_path=' scape .npz ’plot_loss_landscape( ' landscape -100. npz' )plt . show() )Train Loss Test Loss=-0.0470=-0.0452
Table 6: Lk-1 /Rk-1 For different values of spectral gap λ1 /λ2 and iteration number m, Table from (Golub and Van Loan, 2012)eigenvalue, very often resort to the power iteration, likely due to its implementational simplicity.
