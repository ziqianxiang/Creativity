Table 1: Resource utilization ratio of acceleratorsDataset	Network	Precision	DSP	LUT	ResNet-18	16-bit	256	20110CIFAR-10	ConvNet	Binary	4	25074		16-bit + Binary	260	63727	ResNet-18	16-bit	274	24114	ResNet-18	8-bit	274	30970	ResNet-18	Ternary	8	25416ImageNet		16-bit + Ternary	282	56922		8-bit + Ternary	282	63710	MobileNetV2	32-bit	536	60424	MobileNetV2	Ternary	64	27507		32-bit + Ternary	600	119851Table 2: Accuracy and latency comparison for all configurationsDataset	Network	Precision	T*	Accuracy (%)	R* (%)	Latency (ms)	ResNet-18	16-bit		94.1		391CIFAR-10	ConvNet	Binary		89.6 (O4.5)		64 (6.1×)		16-bit + Binary	1.5	92.8 (O1.3)	71.1	77.5 (5.0×)	ResNet-18	16-bit		69.5		306	ResNet-18	8-bit		67.9 (O1.6)		255 (1.20×)
Table 2: Accuracy and latency comparison for all configurationsDataset	Network	Precision	T*	Accuracy (%)	R* (%)	Latency (ms)	ResNet-18	16-bit		94.1		391CIFAR-10	ConvNet	Binary		89.6 (O4.5)		64 (6.1×)		16-bit + Binary	1.5	92.8 (O1.3)	71.1	77.5 (5.0×)	ResNet-18	16-bit		69.5		306	ResNet-18	8-bit		67.9 (O1.6)		255 (1.20×)	ResNet-18	Ternary		63.6 (O5.9)		244 (1.25×)ImageNet		16-bit + Ternary	0.7	69.2 (O0.3)	94.9	160 (1.91×)		8-bit + Ternary	1.0	67.1 (O0.8)	81.4	153 (1.66×)	MobileNetV2	32-bit		69.8		231	MobileNetV2	Ternary		62.2 (O7.6)		288 (0.80×)		32-bit + Ternary	0.3	68.5 (O1.3)	82.9	140 (1.65×)T*: Threshold, R*: Accuracy Recovery (1 -产「°嗽°o＞。。…e(%))AccuracyDropcompressedall the images are processed, and is the most important difference between this work and Mocerino& Calimera (2014). In contrast to the CPU implementation of Mocerino & Calimera (2014), wherethe worst case latency is combined latency of original and compressed networks, our FPGA parallelimplementation allows both networks to run in parallel for the entire time until the input source isdepleted, so the amortized worst case latency is just the latency of the original network.
