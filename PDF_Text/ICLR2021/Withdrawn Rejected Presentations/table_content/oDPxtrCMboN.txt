Table 1: Accuracy (%) comparison (higher means better) on NICO, OfficeHome, DomainNet, andVisDA2017 with 1% (above) and 5% (below) labeled target data (mean ± std).
Table 2: Mean absolute error (MAE, lower means better) comparison on Citycam with 1% and 5%labeled target data (mean ± std). The best is emphasized in bold.
Table 3: The weights trade off between invariant representation part and invariant risk part underOfficeHome: Art to Real scenarios.(mean ± std)λrep		λrisk				1	0.1	0.011	70.23±0.18	70.96±0.17	70.55±0.180.1	71.20±0.14	72.66±0.16	72.31±0.190.01	72.65±0.15	73.12±0.19	72.97±0.20B.2	Implementation DetailsFor image classification task: we use ResNet34 as backbone networks. We adopt SGD with learningrate of 1e-3, momentum of 0.9 and weight decay factor of 5e-4. We decay the learning rate with amultiplier 0.1 when training process reach three quarters of the total iterations. The batch size is setas 128 for VisDA2017 and Domainnet, 64 for officehome. For adversarial training, we use gradientreversal layer (GRL) to flip gradient in the backpropagation between feature encoder g(∙) and domaindiscriminator C(∙) to obtain domain-invariant representation w.r.t. source labeled data and targetunlabeled data. For min-max training objective in Eq. (8), we implement it with the difference ontwo losses , L(y, h(z)) and L(y, h(z, d)). h(z) is realized by a common predictor which only takesfeature z as input. h(z, d) indicates an additional predictor which takes the combination of feature zand domain index d, e.g. we concatenate original feature z with an additional full 0 (or 1) channelto represent source(or target) domain. It’s worth noting that according to Saito et al. (2019), theutilization of entropy minimization hurts the performance. Thus, we implement the CDAN method
