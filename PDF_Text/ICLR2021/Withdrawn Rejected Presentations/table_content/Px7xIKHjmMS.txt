Table 1: Performance of the GNNmpand GNN+ architecturesfor the two models. As a sanity check, we also plot the variance of the labels in our datasets, whichcorresponds to the MSE obtained by a naive model that predicts the mean label. We observe significantgains in accuracy of anywhere between 15% relative MSE improvement over the GNNmp baseline(for Shortest Paths) to as much as 108% relative MSE improvement (for Effective Resistance). Notethat the naive mean predictorâ€™s MSE is at least an order of magnitude larger than all the MSE valuesfor GNNmp and GNN+ (except for the MSTdataset, where it is around five times larger - we suspectthat the weighted graphs involved in this dataset make this a harder problem).
Table 2: Performance of the GNNmp and GNN+ architectures on real world classification datasets.
