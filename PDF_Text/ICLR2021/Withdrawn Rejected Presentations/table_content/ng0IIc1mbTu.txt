Table 1: Mean testing accuracy (%) on MNIST for five trainings of MNIST-Conv after the firstepoch with different optimizers and learning rates. We compare AReLU with 13 non-learnable and5 learnable activation functions. The number of parameters per activation unit are listed besidethe name of the learnable activation functions. The best numbers are shown in bold text with bluecolor for non-learnable methods (the upper part of the table) and red for learnable ones (the lowerpart). At the bottom of the table, we report the improvement of AReLU over the best among othernon-learnable and learnable methods, in blue and red color respectively.
Table 2: Test accuracy (%) on SVHN by MNIST-Conv models (implemented with different activationfunctions) trained directly on SVHN (no pretrain), trained on MNIST but not finetuned (no finetune),as well as pretrained on MNIST and finetuned on SVHN for 5, 10 and 20 epoches. The left part ofthe table is non-learnable activation functions and the right learnable ones.
Table 3: Test accuracy (%) on MNIST by MAML with MNIST-Conv models implemented withdifferent activation functions. The performance is compared on a 5-ways-1-shots task and a 5-ways-5-shots task, respectively.
Table 4: Mean testing accuracy (%) on MNIST for five trainings of MNIST-Conv after the first epochwith different optimizers and learning rates. For each activation function and each learning rate, weshow results training with ELSA module. The numbers showing ELSA module improves over theoriginal activation function (shown in Table 1) are highlighted with underline.
