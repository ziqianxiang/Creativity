Table 1: Summary of DBU models. Further details on the loss functions are provided in the appendix.							α(i)-parametrization		Loss	OOD training data	Ensemble training	Density estimationPostNet	fθ(x(i)) =	1 + α(i)	Bayesian loss	No	No	YesPriorNet	fθ(x(i)) =	α(i)	Reverse KL	Yes	No	NoDDNet	fθ(x(i)) =	α(i)	Dir. Likelihood	No	Yes	NoEvNet	fθ(x(i)) =	1 + α(i)	Expected MSE	No	No	NoContrary to the other models, Prior Networks (PriorNet) (Malinin & Gales, 2018a; 2019) requiresOOD data for training to “teach” the neural network the difference between ID and OOD data.
Table 2: Certainty based on differential entropy under PGD label attacks (AUC-PR).
Table 3: Label Attack-Detection by normally trained DBU models based on differential entropy underPGD label attacks (AUC-PR).
Table 4: OOD detection based on differential entropy under PGD uncertainty attacks against differen-tial entropy on ID data and OOD data (AUC-PR).
Table 5: Randomized smoothing verification for different σ of CIFAR10 (ID data) and SVHN (OODdata). Left part: percentage of samples that is correctly identified and certified as ID data (cc) andcorresponding mean certified radius (R). Right part: same for OOD data.
Table 6: Randomized smoothing verification for different σ of CIFAR10 (ID data) and SVHN (OODdata): percentage of samples that is wrongly identified as ID/OOD and certifiably robust as this wrongtype (cw) and corresponding mean certified radius (R). The lower cw, the more robust the model.
Table 7: Accuracy under PGD label attacks.
Table 8: Accuracy under FGSM label attacks.
Table 9: Accuracy under Noise label attacks.
Table 10: Certainty based on differential entropy under PGD label attacks (AUC-PR).
Table 11: Certainty based on precision α0 under PGD label attacks (AUC-PR).
Table 12: Certainty based on mutual information under PGD label attacks (AUC-PR).
Table 13: Certainty based on differential entropy under FGSM label attacks (AUC-PR).
Table 14: Certainty based on differential entropy under Noise label attacks (AUC-PR).
Table 15: Attack-Detection based on differential entropy under PGD label attacks (AUC-PR).
Table 16: Attack-Detection based on precision α0 under PGD label attacks (AUC-PR).
Table 17: Attack-Detection based on mutual information under PGD label attacks (AUC-PR).
Table 18: Attack-Detection based on differential entropy under FGSM label attacks (AUC-PR).
Table 19: Attack-Detection based on differential entropy under Noise label attacks (AUC-PR).
Table 20: OOD detection based on differential entropy under PGD uncertainty attacks againstdifferential entropy on ID data and OOD data (AUC-PR).
Table 21: OOD detection under PGD uncertainty attacks against differential entropy on ID data andOOD data (AUC-ROC).
Table 22: OOD detection (AU-PR) under PGD uncertainty attacks against precision α0 on ID dataand OOD data.
Table 23: OOD detection (AUC-ROC) under PGD uncertainty attacks against precision α0 on IDdata and OOD data.
Table 24: OOD detection (AU-PR) under PGD uncertainty attacks against distributional uncertaintyon ID data and OOD data.
Table 25: OOD detection (AUC-ROC) under PGD uncertainty attacks against distributional uncer-tainty on ID data and OOD data.
Table 26: OOD detection (AU-PR) under FGSM uncertainty attacks against differential entropy onID data and OOD data.
Table 27: OOD detection (AU-PR) under Noise uncertainty attacks against differential entropy on IDdata and OOD data.
Table 28: Randomized smoothing verification of CIFAR10 (ID data) and SVHN (OOD data) harmonicmean.
Table 29: Randomized smoothing verification of MNIST (ID data) and KMNIST (OOD data):percentage of samples that is certifiably correct (cc) and mean certified radius (R).
Table 30: Randomized smoothing verification of MNIST (ID data) and KMNIST (OOD data):percentage of samples that is certifiably wrong (cw) and mean certified radius (R).
Table 31: Randomized smoothing verification of MNIST (ID data) and KMNIST (OOD data)harmonic mean.
Table 32: Adversarial training with CE: Accuracy under PGD label attacks (AUC-PR).
Table 33: Adversarial training with CE: Accuracy under FGSM label attacks (AUC-PR).
Table 34: Adversarial training with CE: Accuracy under Noise label attacks (AUC-PR).
Table 35: Randomized smoothing verification of CIFAR10: percentage of samples that is certifiablycorrect (cc) w.r.t. the predicted class label and mean certified radius (R) w.r.t. class labels.
Table 36: Randomized smoothing verification of MNIST: percentage of samples that is certifiablycorrect (cc) w.r.t. the predicted class label and mean certified radius (R) w.r.t. class labels.
Table 37: Adversarial training with CE: Certainty based on differential entropy under PGD labelattacks (AUC-PR).
Table 38: Adversarial training with CE: Certainty based on differential entropy under FGSM labelattacks (AUC-PR).
Table 39: Adversarial training with CE: Certainty based on differential entropy under Noise labelattacks (AUC-PR).
Table 40: Adversarial training with CE: Attack-Detection based on differential entropy under PGDlabel attacks (AUC-PR).
Table 41: Adversarial training with CE: Attack-Detection based on differential entropy under FGSMlabel attacks (AUC-PR).
Table 42: Adversarial training with CE: Attack-Detection based on differential entropy under Noiselabel attacks (AUC-PR).
Table 43: Adversarial training with CE: OOD detection based on differential entropy under PGDuncertainty attacks against differential entropy on ID data and OOD data (AUC-PR).
Table 44: Adversarial training with CE: OOD detection based on differential entropy under FGSMuncertainty attacks against differential entropy on ID data and OOD data (AUC-PR).
Table 45: Adversarial training with CE: OOD detection based on differential entropy under Noiseuncertainty attacks against differential entropy on ID data and OOD data (AUC-PR).
Table 46: Adversarial training with Diff. Ent.: Accuracy based on differential entropy under PGDlabel attacks (AUC-PR).
Table 47: Adversarial training with Diff. Ent.: Accuracy based on differential entropy under FGSMlabel attacks (AUC-PR).
Table 48: Adversarial training with Diff. Ent.: Accuracy based on differential entropy under Noiselabel attacks (AUC-PR).
Table 49: Adversarial training with Diff. Ent.: Certainty based on differential entropy under PGDlabel attacks (AUC-PR).
Table 50: Adversarial training with Diff. Ent.: Certainty based on differential entropy under FGSMlabel attacks (AUC-PR).
Table 51: Adversarial training with Diff. Ent.: Certainty based on differential entropy under Noiselabel attacks (AUC-PR).
Table 52: Adversarial training with Diff. Ent.: Attack-Detection based on differential entropy underPGD label attacks (AUC-PR).
Table 53: Adversarial training with Diff. Ent.: Attack-Detection based on differential entropy underFGSM label attacks (AUC-PR).
Table 54: Adversarial training with Diff. Ent.: Attack-Detection based on differential entropy underNoise label attacks (AUC-PR).
Table 55: Adversarial training with Diff. Ent.: OOD detection based on differential entropy underPGD uncertainty attacks against differential entropy on ID data and OOD data (AUC-PR).
Table 56: Adversarial training with Diff. Ent.: OOD detection based on differential entropy underFGSM uncertainty attacks against differential entropy on ID data and OOD data (AUC-PR).
Table 57: Adversarial training with Diff. Ent.: OOD detection based on differential entropy underNoise uncertainty attacks against differential entropy on ID data and OOD data (AUC-PR).
