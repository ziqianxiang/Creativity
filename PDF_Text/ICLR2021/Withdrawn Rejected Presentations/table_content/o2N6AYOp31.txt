Table 1: Average AE per-pixel L2 reconstruction error (normalized to [0, 255]). Rows give thetraining dataset, columns give the evaluation dataset, and cells measure generalization from row tocolumn. Generally, error is low. The bottom row contains scores for a VAE, which generalizespoorly from MNIST. Implementation details in appendix.
Table 2: FID score and train/test classification error across models and datasets. Misclassificationrate is measured in percentage points and captures likelihood of belonging to the wrong domain(training data). AugIntAE is superior in all contexts. GANs trained on train/test images and evalu-ated on test images are given as baselines/oracles.
Table 3: Interpolation as a form of data augmentation on EMNIST. Results are averaged over tenruns, with 95% confidence intervals. AUgIntAE provides the most effective augmentation.
Table 4: Inversion network architecture for PGAN.
