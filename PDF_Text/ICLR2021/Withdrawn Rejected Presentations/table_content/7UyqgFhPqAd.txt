Table 1: presence (X) or absence (X) of certain features in previous statistical theories for sparsedeep learningfor rgen ≥ rgen, Where rgen is as 优0口 but based on the dual norm of ∣∣∣ ∙ ∣∣∣ instead of the dual normof HI ∙ ∣∣∣ι. For example, one could impose connection sparsity on some layers and node sparsityon others, or one could impose different regularizations altogether. We omit the details to avoiddigression.
