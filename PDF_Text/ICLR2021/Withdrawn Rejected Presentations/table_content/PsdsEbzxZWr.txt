Table 1: Optimal solutions for the three scenarios in Figure 1Scenario	Optimal solution (D *, p^)SUpp(Pk) ⊂ S	D* outputs 2 for SUpp(Pk) and ≤ 2 for S \ Supp(pk); p* has its mass distributed to locations where D*	outputs	1.
Table 2: Out-of-distribution detection performances (see Appendix J for expanded results)(a) CIFAR-10			-test	D model			K=0	K = 15	K =250.0	0.974	0.910	0.8601.0	0.005	0.784	0.7632.0	0.000	0.519	0.613(c) CelebA-HQ-128			-test	D model			K=0	K = 20	K = 400.0	1.000	1.000	1.0005.0	0.001	0.998	0.99810.0	0.000	0.964	0.988(d) Bedroom-128			-test	D model			K=0	K = 20	K =400.0	0.996	0.996	0.9705.0	0.000	0.976	0.93810.0	0.000	0.815	0.837Table 3: Standard OOD detection performances (AUROC scores) when the in-distribution dataset
Table 3: Standard OOD detection performances (AUROC scores) when the in-distribution datasetis CIFAR-10 and OOD samples are not perturbed. Performance data is collected from referencedpapers in the table; when there is a discrepancy we use the best reported result. Details about theiSUN, LSUN (resize), and TinyImageNet (resize) datasets can be found at Liang et al. (2017).
Table 4: Adversarial OOD detection performances (AUROC scores) when the in-distribution datasetis CIFAR-10. Performance data of methods other than ours is collected from Bitterwolf et al. (2020).
Table 5: A minimal example demonstrating how to solve a maximin problem. The solutions for theinner problem for each value of v are labeled as red, and the final solution is highlighted as green.
Table 6: In-distribution dataset and corresponding out-of-distribution datasets (images of OODdatasets are resized to the image size of the corresponding in-distribution dataset)In-distribution dataset (pk)	Out-of-distribution datasets (pOOD)CIFAR-10	GaUssian noise, Uniform noise, SVHN (Netzer et al., 2011), CIFAR-100 (Krizhevsky et al., 2009), ImageNet, CelebA-HQ-128, Bedroom-128CelebA-HQ-128	Gaussian noise, Uniform noise, SVHN, CIFAR-100, ImageNet, CIFAR-10, Bedroom-128Bedroom-128	Gaussian noise, Uniform noise, SVHN, CIFAR-100, ImageNet, CelebA-HQ-128, CIFAR-10Table 7: Model training time.
Table 7: Model training time.
Table 8: FID scores	CIFAR-10	CELEBA-HQ-128	LSUN-BEDROOM-128Our method	60.79	83.01	56.86GANs (Kurach et al., 2018)	22.7	24.7	40.420Under review as a conference paper at ICLR 2021H	Ablation StudyH. 1 Uniform noise and data diversityIn this ablation study, we use CIFAR-10 class 0 data as the target data distribution dataset pk, andtrain models with different p-k datasets.
Table 9:	Average OOD performance (AUROC scores) on CIFAR10 class 0 data. (pk = CIFAR-10class 0, and p-k = ImageNet).
Table 10:	Average OOD detection performance (AUROC scores) on CIFAR-10 class 0 data. (pkCIFAR-10 class 0, and p-k = CIFAR-10 class 1 - class 9).
Table 11: OOD detection performance (AUROC scores) of K = 0 model on CIFAR-10 class 0 data(pk = CIFAR-10 class 0, and p-k = uniform noise).
Table 12: OOD detection performance (AUROC scores) of K = 15 model on CIFAR-10 class 0 data.
Table 13: Adversarial OOD detection performances (AUROC scores) of our method trained withdifferent model architectures and p-k datasets. The in-distribution dataset is CIFAR-10. Thedefinition of ResNet18 can be found at https://github.com/MadryLab/robustness.
Table 14: Standard OOD detection performances (AUROC scores) of our method trained withdifferent model architectures and p-k datasets. The in-distribution dataset is CIFAR-10.
Table 15: The performances of CIFAR-10 K = 25 model under PGD attacks of different combina-tions of steps and step size. The perturbation limit is = 2.0 (L2 norm). Each entry is computedusing 500 positive samples and 500 negative samples.
Table 16: OOD detection performances of the CIFAR-10 K = 0 model on individual datasets. Eachentry in this table and the following two tables is computed using 3000 positive samples and 3000negative samples. When test > 0, perturbations are computed using PGD attacks of steps 200 andstep size 0.5.
Table 17: OOD detection performances of the CIFAR-10 K = 15 model on individual datasets-test	Gaussian noise	Uniform noise	ImageNet	Bedroom	SVHN	CelebA-HQ	CIFAR-100	mean0.0	0.9911	1.0000	0.8593	0.9247	0.9182	0.8731	0.8036	0.91001.0	0.9218	1.0000	0.6918	0.7712	0.7590	0.7264	0.6156	0.78372.0	0.4709	0.9988	0.4065	0.4485	0.4451	0.5098	0.3503	0.5185Table 18: OOD detection performances of the CIFAR-10 K = 25 model on individual datasets-test	Gaussian noise	Uniform noise	ImageNet	Bedroom	SVHN	CelebA-HQ	CIFAR-100	mean0.0	0.8993	0.9998	0.8138	0.8725	0.8721	0.8248	0.7411	0.86051.0	0.8310	0.9943	0.6943	0.7470	0.7510	0.7171	0.6075	0.76322.0	0.6845	0.9712	0.5178	0.5414	0.5660	0.5723	0.4381	0.613124Under review as a conference paper at ICLR 2021J.2 CIFAR-10 CLASS 0Table 19: OOD detection performances of the CIFAR-10 K = 0 model on individual datasets. Eachentry in this table and the following two tables is computed using 1000 positive samples (the testset only has 1000 samples) and 1000 negative samples. PGD attack setting follows the CIFAR-10experiment.
Table 18: OOD detection performances of the CIFAR-10 K = 25 model on individual datasets-test	Gaussian noise	Uniform noise	ImageNet	Bedroom	SVHN	CelebA-HQ	CIFAR-100	mean0.0	0.8993	0.9998	0.8138	0.8725	0.8721	0.8248	0.7411	0.86051.0	0.8310	0.9943	0.6943	0.7470	0.7510	0.7171	0.6075	0.76322.0	0.6845	0.9712	0.5178	0.5414	0.5660	0.5723	0.4381	0.613124Under review as a conference paper at ICLR 2021J.2 CIFAR-10 CLASS 0Table 19: OOD detection performances of the CIFAR-10 K = 0 model on individual datasets. Eachentry in this table and the following two tables is computed using 1000 positive samples (the testset only has 1000 samples) and 1000 negative samples. PGD attack setting follows the CIFAR-10experiment.
Table 19: OOD detection performances of the CIFAR-10 K = 0 model on individual datasets. Eachentry in this table and the following two tables is computed using 1000 positive samples (the testset only has 1000 samples) and 1000 negative samples. PGD attack setting follows the CIFAR-10experiment.
Table 20: OOD detection performances of the CIFAR-10 K = 15 model on individual datasets-test	Gaussian noise	Uniform noise	ImageNet	Bedroom	SVHN	CelebA-HQ	CIFAR-100	mean0.0	0.9983	1.0000	0.9779	0.9819	0.9833	0.9999	0.9687	0.98721.0	0.9537	0.9999	0.9054	0.9055	0.8920	0.9974	0.8769	0.93302.0	0.6470	0.9913	0.6183	0.5727	0.4486	0.9495	0.5763	0.6863Table 21: OOD detection performances of the CIFAR-10 K = 25 model on individual datasets-test	Gaussian noise	Uniform noise	ImageNet	Bedroom	SVHN	CelebA-HQ	CIFAR-100	mean0.0	0.9761	1.0000	0.9644	0.9680	0.9698	0.9998	0.9527	0.97581.0	0.9071	0.9963	0.9150	0.9146	0.9073	0.9979	0.8894	0.93252.0	0.7770	0.9787	0.7990	0.7802	0.7275	0.9841	0.7526	0.828425Under review as a conference paper at ICLR 2021J.3 CELEBA-HQ-128Table 22: The performances of CelebA-HQ-128 K = 40 model under PGD attacks of differentcombinations of steps and step size. The perturbation limit is = 10 (L2 norm). Each entry iscomputed using 500 positive samples and 500 negative samples.
Table 21: OOD detection performances of the CIFAR-10 K = 25 model on individual datasets-test	Gaussian noise	Uniform noise	ImageNet	Bedroom	SVHN	CelebA-HQ	CIFAR-100	mean0.0	0.9761	1.0000	0.9644	0.9680	0.9698	0.9998	0.9527	0.97581.0	0.9071	0.9963	0.9150	0.9146	0.9073	0.9979	0.8894	0.93252.0	0.7770	0.9787	0.7990	0.7802	0.7275	0.9841	0.7526	0.828425Under review as a conference paper at ICLR 2021J.3 CELEBA-HQ-128Table 22: The performances of CelebA-HQ-128 K = 40 model under PGD attacks of differentcombinations of steps and step size. The perturbation limit is = 10 (L2 norm). Each entry iscomputed using 500 positive samples and 500 negative samples.
Table 22: The performances of CelebA-HQ-128 K = 40 model under PGD attacks of differentcombinations of steps and step size. The perturbation limit is = 10 (L2 norm). Each entry iscomputed using 500 positive samples and 500 negative samples.
Table 23: OOD detection performances of the CelebA-HQ-128 K = 0 model on individual datasets.
Table 24: OOD detection performances of the CelebA-HQ-128 K = 20 model on individual datasets	CIFAR-10	Gaussian noise	Uniform noise	ImageNet	Bedroom	SVHN	CIFAR-100	mean0.0	0.9999	1.0000	1.0000	1.0000	1.0000	1.0000	0.9999	1.00005.0	0.9974	1.0000	1.0000	0.9988	0.9993	0.9965	0.9959	0.998310.0	0.9459	0.9903	0.9996	0.9805	0.9809	0.9190	0.9291	0.9636Table 25: OOD detection performances of the CelebA-HQ-128 K = 40 model on individual datasets	CIFAR-10	Gaussian noise	Uniform noise	ImageNet	Bedroom	SVHN	CIFAR-100	mean0.0	0.9999	1.0000	1.0000	0.9999	1.0000	0.9999	0.9998	0.99995.0	0.9978	0.9997	1.0000	0.9990	0.9992	0.9968	0.9961	0.998410.0	0.9829	0.9958	0.9999	0.9925	0.9927	0.9744	0.9744	0.987526Under review as a conference paper at ICLR 2021J.4 Bedroom- 1 28Table 26: The performances of Bedroom K = 40 model under PGD attacks of different combinationsof steps and step size. The perturbation limit is = 10 (L2 norm). Each entry is computed using 500positive samples and 500 negative samples.
Table 25: OOD detection performances of the CelebA-HQ-128 K = 40 model on individual datasets	CIFAR-10	Gaussian noise	Uniform noise	ImageNet	Bedroom	SVHN	CIFAR-100	mean0.0	0.9999	1.0000	1.0000	0.9999	1.0000	0.9999	0.9998	0.99995.0	0.9978	0.9997	1.0000	0.9990	0.9992	0.9968	0.9961	0.998410.0	0.9829	0.9958	0.9999	0.9925	0.9927	0.9744	0.9744	0.987526Under review as a conference paper at ICLR 2021J.4 Bedroom- 1 28Table 26: The performances of Bedroom K = 40 model under PGD attacks of different combinationsof steps and step size. The perturbation limit is = 10 (L2 norm). Each entry is computed using 500positive samples and 500 negative samples.
Table 26: The performances of Bedroom K = 40 model under PGD attacks of different combinationsof steps and step size. The perturbation limit is = 10 (L2 norm). Each entry is computed using 500positive samples and 500 negative samples.
Table 27: OOD detection performances of the Bedroom-128 K = 0 model on individual datasets.
Table 28: OOD detection performances of the Bedroom-128 K = 20 model on individual datasets	CIFAR-10	Gaussian noise	Uniform noise	ImageNet	SVHN	CelebA-HQ	CIFAR-100	mean0.0	0.9959	1.0000	1.0000	0.9892	0.9955	0.9990	0.9946	0.99635.0	0.9604	0.9991	1.0000	0.9569	0.9634	0.9900	0.9623	0.976010.0	0.6834	0.9085	0.9984	0.7888	0.7061	0.8937	0.7251	0.8148Table 29: OOD detection performances of the Bedroom-128 K = 40 model on individual datasets	CIFAR-10	Gaussian noise	Uniform noise	ImageNet	SVHN	CelebA-HQ	CIFAR-100	mean0.0	0.9525	0.9932	0.9993	0.9593	0.9474	0.9824	0.9578	0.97035.0	0.8986	0.9649	0.9967	0.9267	0.8995	0.9650	0.9114	0.937610.0	0.7274	0.8642	0.9749	0.8417	0.7740	0.9112	0.7651	0.836927Under review as a conference paper at ICLR 2021K Expanded generation resultsFigure 10: Samples generated by GANs (Kurach et al., 2018); results of our method are in Figure 3.
Table 29: OOD detection performances of the Bedroom-128 K = 40 model on individual datasets	CIFAR-10	Gaussian noise	Uniform noise	ImageNet	SVHN	CelebA-HQ	CIFAR-100	mean0.0	0.9525	0.9932	0.9993	0.9593	0.9474	0.9824	0.9578	0.97035.0	0.8986	0.9649	0.9967	0.9267	0.8995	0.9650	0.9114	0.937610.0	0.7274	0.8642	0.9749	0.8417	0.7740	0.9112	0.7651	0.836927Under review as a conference paper at ICLR 2021K Expanded generation resultsFigure 10: Samples generated by GANs (Kurach et al., 2018); results of our method are in Figure 3.
Table 30: The performance (AUROC scores) of CIFAR-10 K = 5 model (the in-distribution datasetis CIFAR-10) under attacks of different configurations. Following Bitterwolf et al. (2020) we used1000 samples for both in-distribution data and OOD data. Similarly, we used 5 random restarts toenhance the default attack, but the performance decrease is negligible.
Table 31: Adversarial OOD detection performances (AUROC scores) when in-distribution datasetis SVHN. Performance data of methods other than ours is collected from Bitterwolf et al. (2020).
Table 32: The performance (AUROC scores) of SVHN K = 45 model (the in-distribution dataset isSVHN) under attacks of different configurations. Following Bitterwolf et al. (2020) we used 1000samples for both in-distribution data and OOD data. Similarly, we used 5 random restarts to enhancethe default attack, but the performance decrease is negligible.
