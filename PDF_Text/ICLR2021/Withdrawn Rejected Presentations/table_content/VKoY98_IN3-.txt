Table 1: Video reconstruction results (lower is better). Improvement is relative to FOMM.
Table 2: Results on VoxCeleb1 in the few-shotlearning scenario. Unlike the other methods, wedo not perform fine-tuning on the identity in thesource image. #FT=number of images used forfinetuning. P2PHD=Pix2PixHD.________Method	#FT	SSIM ↑	CSIM ↑X2Face	1/8/32	0.68/0.73/0.75	0.16/0.17/0.18P2PHD	1/8/32	0.56/0.64/0.70	0.09/0.12/0.16FSAL	1/8/32	0.67/0.71/0.74	0.15/0.17/0.19Ours 0	0.80	0.70Table 3: Percent of selected best video samplesfor each method based on quality or motion fi-deHty. X2=X2Face. MN=Monkey-Net.
Table 3: Percent of selected best video samplesfor each method based on quality or motion fi-deHty. X2=X2Face. MN=Monkey-Net.
