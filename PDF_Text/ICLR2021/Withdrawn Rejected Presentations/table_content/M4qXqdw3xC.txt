Table 1: Position encoding results w/metrics SPC↑: high is better and MAE]:low is better, w/ different padding types.
Table 2: Location dependant (a) image classification and (b) semantic segmentation accuracy onCIFAR-10 under zero/no padding settings and canvas colors Black, White, and Mean.
Table 3: Dimensionality estimation (%) of two semanticconcepts (location and semantic category) under differenttasks and settings.
Table 4: Performance comparisonof DeepLabv3 w/ and w/o paddingfor different image regions. Top-left image in Fig. 7 shows outer re-gions used for this analysis.
Table 5: (a) Texture recognition results on two datasets with different padding types. (b) Perfor-mance and robustness of DeepLabv3 variants trained with Cutout (DeVries & Taylor, 2017) usingtwo canvas (Black and White).
Table 6: VGG-5 architecture trained on tiny ImageNet.
Table 7: Location dependant semantic segmentation accuracy on CIFAR-10 under zero/no paddingand black canvas settings using VGG-11 network.
Table 8: Location dependant semantic segmentation accuracy on CIFAR-10 under zero/no paddingand black canvas settings using ResNet18 network.
Table 9: Dimensionality estimation (%) of two semantic concepts (location and semantic category)under different tasks and settings. Remaining dimensions are assigned to residual factor.
Table 10: Location dependant image segmentation: Category-wise mIoU on CIFAR-10 (Krizhevsky et al., 2014) for two different locations under w/ and w/o padding settings andBlack and Mean canvas color. The grid size for both canvases is 7 × 7.
Table 11: IoU comparison of DeepLabv3 forsemantic segmentation task with three differentpadding (Zero, Reflect, and No pad) settings.
