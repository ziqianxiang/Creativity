Table 1: Ablation studies on CIFAR-10 for the proposed DC-VAE algorithm. We follow (Johnson et al.,2016) and measure perceptual distance in an relu4_3 layer of a pretrained VGG network. ] means lower is better.
Table 2: Comparison on CIFAR-10 and STL-10. Average Inception scores (Salimans et al., 2016) and FIDscores (Heusel et al., 2017). Results derived from (Gong et al., 2019). Table style derived from (Lee et al., 2019).
Table 3:	Quality of image generation (FID) com-parison on LSUN Bedrooms. t 128 × 128 resolution.
Table 4:	FID on CelebA. * 64×64 resolution.
Table 5: Comparison to prior VAE-based representation learning methods. Classification error on MNISTdataset. 1: lower is better. 95 % confidence intervals are from 5 trials. Results derived from (Ding et al., 2020).
Table 6: PPL Comparison of on CelebA-HQ Karras et al. (2018)6 ConclusionIn this paper, we have proposed dual contradistinctive generative autoencoder (DC-VAE), a newframework that integrates an instance-level discriminative loss (InfoNCE) with a set-level adversarialloss (GAN) into a single variational autoencoder framework. Our experiments show competitiveresults for a single model in several tasks, including image synthesis, image reconstruction, represen-tation learning for image interpolation, and representation learning for classification. DC-VAE pointsto a encouraging direction that attains high-quality synthesis (decoding) and inference (encoding).
