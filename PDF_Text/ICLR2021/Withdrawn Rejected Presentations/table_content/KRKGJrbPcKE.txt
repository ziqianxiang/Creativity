Table 1: MIL tasks are summarized by their bag labels for each kind of image and loss functions usedduring training. For example, in +ve/-ve bag classification task, bag labels are 2-bit one-hot vectorssuch that ‘10’: -ve bag (fully normal image) and ‘01’: +ve bag (fully metastases or boundary image).
Table 2: Top: Test set performances of MIL models in 5 different MIL tasks formulated on the lymphnode metastases dataset. Bottom: Pairwise statistical test results are presented as color coded mapsobtained by thresholding p-values at different significance levels. Best models are highlighted in bold.
Table 3: Performances of different MIL methods on classical MIL datasets. First part: methodsutilizing traditional machine learning techniques. Second part: methods employing neural networks.
Table 4: Lymph node metastases dataset - number of images in training, validation and test sets.
Table 5: Experiments on lymph node metastases dataset - architecture and list of hyper-parametersused in the MIL models. 'dist^wqtt': 'distribution with attention'poolingArchitecture	input-32x32x3 ResNet18 w/o BN ‘distribution' / ‘dist_w_att' / ‘mean' / ‘attention' / ‘max' pooling Dropout(0.5) fc-128 + ReLU Dropout(0.5) fc-32 + ReLU Dropout(0.5) fc-2 (+ve/-ve, ucc, 2-task) / fc-3 (3-class) / fc-1 (regression) softmax (+ve/-ve, ucc, 3-class) / sigmoid (2-task) / None (regression)image size	512 X 512patch size	32 × 32# instances per bag	64# features	32# bins in ‘distribution’ filters	21σ in Gaussian kernel	0.0167Optimizer	ADAMLearning rate	1e - 4L2 regularization weight decay	0.0005batch size	32B.3 Confusion matrices for classification tasksConfusion matrices for +ve/-ve bag classification, ucc classification, 3-class classification, metastasestask of 2-task classification and normal task of 2-task classification are given in Figure 5, 6, 7, 8 and9.
Table 6: Summary of classical MIL datasets	# bags			# instances per bag			# features	positive	negative	total	min	max	average	MUSK1	47	45	92	2	40	5.17	166MUSK2	39	63	102	1	1044	64.69	166FOX	100	100	200	2	13	6.6	230TIGER	100	100	200	1	13	6.1	230ELEPHANT	100	100	200	2	13	6.96	230The summary of architectures and hyper-parameters used in MIL models on ‘MUSK’ and ‘Animal’datasets are given in Table 7 and Table 8, respectively. Note that we used mini-batch training withbags including equal number of instances. We created bags by sampling from available instances ofeach sample (a drug with multiple conformations for ‘MUSK’ datasets and an image with multiplesegments in ‘Animal’ datasets). When the number of available instances of a sample is less thannumber of instances required to create a bag we used available instances more than once in a bag. Wehave determined number of instances with cross-validation on the validation sets.
Table 7: MUSK datasets - architecture and list of hyper-parameters used in the MIL models.
Table 8: Animal datasets - architecture and list of hyper-parameters used in the MIL models.
Table 9: MUSK and Animal datasets - architecture and list of hyper-parameters used in the MILmodels of (Wang et al., 2018) and (Ilse et al., 2018).
Table 10: Classifying bags of metal balls - architecture and list of hyper-parameters used in the MILmodels.
