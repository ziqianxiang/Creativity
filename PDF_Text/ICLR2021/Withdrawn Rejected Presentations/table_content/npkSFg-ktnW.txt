Table 1: Controllable augmentation performance (the ? means that synthesized images with newattributes are added into training set)Attributes Dataset^^^^--^	Letter	Size	Font Color	Back- Color	Fonts	DataSet Size	Training Accuracy	Test AccuracyDL	-10-	-3-	-6-	-3	-10-	-5400-	98%	-94%DS	10	2	3	3	3	540	99%	71%DS+GSL-AE	10	2?	3?	3?	3?	540+1000	99%	74%DS+DEAE	10	2?	3?	3?	3?	540+1000	99%	76%Dtest	10	3	6	3	10	5400	N/A	N/A3.5	Dataset bias eliminationDataset bias may influence on the performance of model greatly. Mehrabi et al. (2019) listed lots ofbias resources and proved that eliminate bias is significant. Our DEAE could be a solution to biasedproblem. We design experiments to demonstrate how to achieve fairness with DEAE.
Table 2: Dataset setting and experiment resultsModel Dataset	resnet18 -bias	resnet18 -unbias	DEAE -biasTest(Letters in G1)	52.73%	99.17%	96.77%Test(Letters in G2)	82.63%	98.67%	98.97%Test(Letters in G3)	99.13%	98.30%	98.46%Train	99.44%	98.82%	99.98%Test	81.32%	98.63%	98.11%EBias model	Un-bias modelBias model Un-bias modelFigure 8: The influence of bias shown by Grad-Cam8Under review as a conference paper at ICLR 20214	ConclusionWe proposed a new kind of generative autoencoder: Disentangled Exploration Autoencoder (DEAE),which can achieve controllable synthesis by freely interpolating in disentangled latent space. DEAEtries to turn the non-convex latent space to convex for each attribute by ’reusing’ the encoder toregularize the latent space of synthesized images. We show that DEAE outperforms state-of-the-artmethods on attribute controllable synthesis tasks. We demonstrate how DEAE achieves precise latentspace movement and novel attribute mining in perfect disentangled space by combining unit direction
