Table 1: Datasets and their statistics used in this paper. Datasets in bold are used to construct the onlinelearning training set. The rest are used to test our NASOA. It is commonly believed that Aircrafts, Flowers102and Blood-cell deviate from the ImageNet domain.
Table 2: Comparsion of our ET-NAS modelsand SOTA ImageNet models. Inference timeand training step time are measured in ms onsingle Nvidia V100, with bs = 64.
Table 3: Online error rate of our method and fixed MLP.
Table 4: Comparison of the final NASOA results with otherHPO methods. “HPO only” means only optimizing the hy-perparameters with RegNetY-16GF. Other HPO methods opti-mize both selecting hyperparameters and model from RegNetseries models. “OA only” is our online schedule generatorwith RegNet series models. “Our Zoo” means using our ETmodels zoo to find suitable model. “Fixed MLP Predictor” isthe offline baseline with fixed MLP predictor. “Our NASOA”is the our whole pipeline with both training efficient model zooand online adaptive scheduler. Without additional search cost(x40), NASOA can reach similar performance of BOHB.
Table 5: . This ablative study calculates the aver-age fine-tuning accuracy over 5 tasks.
Table 6: Comparison of Top-1 accuracy and training time (min) on different datasets. Comparing to trainingfrom scratch, fine-tuning shows superior results in terms of both accuracy and training time.
Table 7: Fine-tuning on R50, the optimal learning rate and optimal frozen stage found by grid search aredifferent and should be optimized individually.
Table 8: The operations and channel changing ratios considered in our paper. Encoding for operatorsand ratios. c stands for the channels of the current block.
Table 9: ResNets and Wide ResNets are represented by our encoding scheme. Basic Block is repre-sented as ‘020-’, as the two operators are both conv3x3 (denoted as ‘0’), and the output channel ofthe first operator equals to that of the block output (represented as ‘2’), and no other skip connectionexcept the one connecting input and output; the macro-arch of ResNet 18 is encoded as ‘11-21-21-21’, as each stage contains two blocks, where the first block in Stage 2, 3, 4 doubles the number ofchannels.
Table 10: The searched optimal efficient training models ”ET-NAS” found by our NAS search. ‘Acc’means the accuracy evaluated on the ImageNet; inference time and step time are measured in mson single Nvidia V100, with a batch size of 64. By observing the optimal model, smaller modelsshould use simpler blocks while bigger models prefer complex blocks.
Table 11: Regression Analysis: what makes a network efficient-training? We exam the effect of eachcomponent of network on the efficiency score. “Coef” and “SE Coef” are the estimated regressioncoefficient and standard error. “T-Value”/“P-Value” shows the significance of the variables.
