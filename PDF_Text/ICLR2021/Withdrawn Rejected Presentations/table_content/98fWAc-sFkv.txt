Table 1: MNIST K-NN test errorrates obtained in latent space for bothtask-agnostic and know task setting.
Table 2: Comparison of final mean accuracies on test set obtained using different methods over 10runs except for some with zero deviations (1-2 runs). Deviations are rounded to 1 decimal place,very small deviations are kept as 0.1.
Table 3: Comparing performance on Permuted MNIST under different network configurationsthat model quite stable and performance does not drop alot even with large number of tasks for afixed model size.
Table 4: Comparison of model performance over different number of tasks for Permuted MNISTexperimentH.3 Additional Cifar ResultMNIST data experiments are relatively easier to model and an approach might not generalize tomore complex datasets like image or textual data. This section includes extra results on cifar-10 andcifar-100 datasets with comparisons to some very strong baselines for observing performance undercomplex settings.
Table 5: Avg. accuracy obtained after all tasks are obtained on cifar-10 and cifar-100 datasetsTable 5 shows that our approach is comparable to the some strong baselines like HAT, VCL on com-plex tasks like cifar-10 and cifar-100 classifications. Therefore, suggesting that it can be generalizedto more complex task settings. For split cifar-100 (20 tasks) each task is a 5 class classification taskand, split cifar-10 has 2 class classification tasks.
Table 6: Comparison on other metrics for permuted MNIST datasetWe can observe that backward transfer for our model is more as compared to most baselines, whichshows that our approach has suffers from less forgetting as well. On the other hand forward transferseems to give close to random accuracy (0.1) which is due to the fact that the model is not trainedon the correct class labels and is asked to predict the correct label. So this metric is not very usefulhere; an alternative would be to train a linear classifier on the representations that are learned aftereach subsequent tasks for future task.
Table 7: Unsupervised learning benchmark comparison with sampled latents using multipleK-nearest neighbour errors obtained from each baseline.0-o-.o-o-.o-o-50.50.505âˆ£0Figure 12:t-SNE plot oflatent space of VCL model on notMNIST (left) and MNIST (right)datasetsRepresentation Learning In t-SNE plots, it can be observed that the latent space for MNISTdataset is more clearly seperated as compared to notMNIST dataset. This can be attributed to the
