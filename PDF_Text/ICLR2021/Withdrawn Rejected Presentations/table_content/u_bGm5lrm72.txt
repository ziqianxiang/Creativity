Table 1: Top-1 classification accuracy					Architecture	ANN	ANN-SNN	Weight Optimization	DIET-SNN	Timesteps (T)	CIFAR10						VGG6	90.80%	86.19%	89.24%	89.42%	5				90.05%	10VGG16	93.72%	73.52%	91.68%	92.70%	5				93.44%	10ResNet20	92.79%	47.26%	90.29%	91.78%	5				92.54%	10	CIFAR100						VGG16	71.82%	46.54%	65.83%	69.67%	5ResNet20	64.64%	31.40%	62.95%	64.07%	5ImageNet					VGG16	70.08%	24.58%	64.32%	69.00%	5L = - X yilog(Si),	∂∂LT = S- yil(5)where s is the vector containing the softmax values, L is the loss function, and y is the one-hotencoded vector of the true label or target. The weight update is computed as△Wi=X 蓝
Table 2: DIET-SNN compared with other SNN modelsModel	Method	Architecture	SNN Accuracy	Timesteps	CIFAR10					Sengupta et al. (2019)	ANN-SNN	VGG16	91.55%	2500Rueckauer et al. (2017)	ANN-SNN	4 Conv, 2 FC	90.85%	400Rathi et al. (2020)	Hybrid	VGG16	92.02%	200Lee et al. (2019)	Backprop	VGG9	90.45%	100Wu et al. (2019b)	Backprop	CIFARNet	90.53%	12Wu et al. (2019a)	Backprop	CIFARNet	90.98%	8Zhang & Li (2020)	Backprop	CIFARNet	91.41%	5This work	DIET-SNN	CIFARNet	91.59%	5This work	DIET-SNN	VGG16	92.70%	5CIFAR100				Han et al. (2020)	ANN-SNN	VGG16	70.09%	768Rathi et al. (2020)	Hybrid	VGG11	67.87%	125Lu & Sengupta (2020)	ANN-SNN	VGG15	63.20%	62This work	DIET-SNN	VGG16	69.67%	5ImageNet				Sengupta et al. (2019)	ANN-SNN	VGG16	69.96%	2500Han et al. (2020)	ANN-SNN	VGG16	71.34%	768
Table 3: ANN vs DIET-SNN compute energy. Each operation in ANN (SNN) consumes4.6pJ (0.9pJ). The input layer in DIET-SNN is non-spiking, so it’s energy is same as ANN.
