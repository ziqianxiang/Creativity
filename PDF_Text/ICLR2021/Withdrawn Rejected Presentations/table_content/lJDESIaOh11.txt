Table 1: Statistics of the PathVQA dataset	Max	Avg	Min# questions per image	14	6.6	1# words per question	28	9.5	3# words per answer	10	2.5	1ularity, such as pixels, images, bags ofstances, etc., in a unified way.
Table 2: Frequency of questions in dif-ferent categoriesQuestion type	Total number and percentageYes/No	16,329 (49.8%)What	13,401 (40.9%)Where	2,157 (6.6%)How	595 (1.8%)How much/many	139 (0.4%)Why	114 (0.3%)When	51 (0.2%)Whose	9 (0.1%)various aspects of visual contents, including color, location, appearance, shape, etc. Such clinicaldiversity poses great challenges for AI models to solve this pathology VQA problem.
Table 3: Statistics of the data split	Training set	Validation set	Test set# images	3,021	987	990# QA pairs	19,755	6,279	6,761categories are imbalanced. Because of this, during the partition process, we perform sampling toensure the frequencies of these categories in each set to be consistent. There are 19,755 question-answer pairs in the training set, 6,279 in the validation set, and 6,761 in the testing set. For all thedata examples in the validation set and test set, senior radiologists helped to carefully examine themto ensure they are clinically correct. The training set was not examined by senior radiologists. Thestatistics are summarized in Table 3.
Table 4: Accuracy (%), BLEU-n (%), and F1 (%) achieved by different methods. We denote cross-modal SSL on image-question pairs and image-answer pairs as CMSSL-IQ, CMSSL-IA, and denotesingle-modal SSL on question-answer pairs as SSL-QAMethod	Accuracy	BLEU-1	BLEU-2	BLEU-3	F1Method 1 without image	-^49.2^^	50.2	2.8	1.2	9.5Method 1	57.6	57.4	3.1	1.3	9.9Method 1 with ignoring	58.5	58.9	3.5	2.0	10.2Method 1 with CMSSL-IQ	58.7	59.0	3.5	2.1	11.0Method 1 with CMSSL-IA	58.6	58.9	3.4	2.0	10.3Method 1 with SSL-QA	58.7	59.0	3.5	2.1	11.2Method 1 with joint pretraining	59.3	59.2	4.7	2.8	11.6Method 1 WithjointPretraining+ignoring	60.1	59.9	5.1	3.2	12.2Method 2 without image	-^46.2^^	-^46.5^^	1.0^^	-^0.0~~	-0.8-Method 2	55.1	56.2	3.2	1.2	8.4Method 2 with ignoring	56.3	57.4	3.5	1.8	9.6Method 2 with CMSSL-IQ	55.9	57.1	3.4	1.4	9.2Method 2 with CMSSL-IA	55.9	57.1	3.5	1.5	9.2Method 2 with SSL-QA	57.6	58.8	4.1	1.5	10.8Method 2 with joint pretraining	57.7	59.1	4.2	2.2	10.9Method 2 with joint pretraining+ignoring	58.4	59.5	4.4	2.6	11.2
Table 5: Accuracy (%) on open-ended questions of different typesMethod	Question types					What	Where	How	How much/many	WhyMethod 1 without image	0.08	0.39	0.16	0.41	0.50Method 1	0.22	0.73	0.12	0.45	0.50Method 1 with ignoring	0.24	0.76	0.15	0.45	0.64Method 1 with CMSSL-IQ	0.24	0.73	0.13	0.45	0.59Method 1 with CMSSL-IA	0.24	0.74	0.13	0.45	0.59Method 1 with SSL-QA	0.26	0.78	0.15	0.50	0.64Method 1 with joint pretraining	0.29	0.79	0.16	0.50	0.68Method 1 with joint pretraining+ignoring	0.32	0.81	0.16	0.56	0.68Method 2 without image	0.05	0.29	0.00	0.00	0.00Method 2	0.18	0.64	0.11	0.36	0.32Method 2 with ignoring	0.24	0.72	0.12	0.41	0.41Method 2 with CMSSL-IQ	0.20	0.71	0.12	0.36	0.50Method 2 with CMSSL-IA	0.20	0.72	0.11	0.41	0.45Method 2 with SSL-QA	0.20	0.71	0.11	0.36	0.45Method 2 with joint pretraining	0.21	0.72	0.12	0.45	0.55Method 2 with joint pretraining+ignoring	0.24	0.72	0.14	0.45	0.59the model to learn more powerful textual and visual representations. Fifth, applying both joint pre-
Table 6: Accuracy (%) on “yes/no” questions	Method	AccuracyMethod 1 without image	85.1Method 1	86.1Method 1 with ignoring	86.4Method 1 with CMSSL-IQ	86.2Method 1 with CMSSL-IA	86.4Method 1 with SSL-QA	86.2Method 1 with joint pretraining	86.8Method 1 with joint Pretraining+ignoring	87.1Method 2 without image	-8415-Method 2	85.7Method 2 with ignoring	86.4Method 2 with CMSSL-IQ	86.4Method 2 with CMSSL-IA	86.4Method 2 with SSL-QA	86.8Method 2 with joint pretraining	86.6Method 2 with joint pretraining+ignoring	87.26	ConclusionIn this paper, towards the goal of developing AI systems to pass the board-certificated examinations
Table 7: Comparison of VQA datasets	Domain	# images	# QA pairs	Answer typeDAQUAR	General	1,449	12468	OpenVQA	General	204K	614K	OPenMCVQA v2-	General	204K	ΠM	OPenMCCOCO-QA	General	123K	1Γ8K	OPenMC 一CLEVR 一	General	100K	999K	OpenVQA-Med 二	Medical	4,200	15,292	OPenMC 二VQA-RAD -	Medical	315	3515	OPenMC 一Ours	Medical	4,998	32,795	OpenA.3 Number of questions in different categories for training, validation, andTEsT sETFor our data split, the number of questions in different categories in each set is shown in Table 8.
Table 8: Number of questions in different categories in each setDataset	Question types						What	Where	How	How much/many	Why	Yes/NoTraining set	8083	1316	^^66	62	71	9804Validation set	2565	409	108	21	21	3135Testing set	2753	432	121	18	22	3390A.4 Derivation of Gradient in algorithm 1in Algorithm 1, there are two steps. in the first step, we update ignoring variables A by descendingVA Lval(W - ξ VW Ltrain (W, A)), where We approximate W * using one step gradient descent12Under review as a conference paper at ICLR 2021update of W :W * ≈ W - ξVw Ltrain(W,A),where ξ is the learning rate.
