Table 1: Vocabularies forLLVM-IRWe set T = 30 for training in all experiments and trained a model per task. Once trained, we eval-uate model inference using different T values to accommodate programs which required a greaternumber of steps to compute the ground truth. See Appendix C.2 for training details.
Table 2: Data flow analysis results. For the restricted subset DDF-30 ProGraML obtains strongresults. Results on the full dataset (DDF) highlight the scalability challenges of MPNNs.
Table 3: Predicting heterogeneous compute device mapping.
Table 4: Algorithm classification comparison to state-of-the-art, and ablations.
Table 5: The DeepDataFlow LLVM-IR corpus.
Table 6: Characterization of DeepDataFlow subsets.
Table 7: Average training and inference times on DDF-30 tasks	Train time	Test time	Train time/graph	Val time/graph	Test time/graphinst2vec	10h52m	1h33m	45ms	3ms	36msCDFG	13h14m	3h27m	64ms	1ms	62msPro GraML	7h21m	1h39m	26ms	3ms	24msC.2 Experimental SetupTraining Details and Parameters All models were trained in an end-to-end fashion with theAdam optimizer (Kingma & Ba, 2015) using the default configuration and a learning rate of 1 ∙ 10-3for the LSTMs and 2.5 ∙ 10-4 for the GGNNs. We trained the models on 1M training graphs,evaluating on a fixed 10k validation set at 10k intervals for the first 50k training graphs, and at 100kintervals thereafter. The checkpoint with the greatest validation F1 score is used for testing.
