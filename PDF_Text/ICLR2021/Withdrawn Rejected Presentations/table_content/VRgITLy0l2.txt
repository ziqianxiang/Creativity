Table 1: Settling time in seconds for each experiment conducted. We compare the time taken forconvergence by three different loss functions, L1, L2 and Lyapunov Loss function. The trainingconditions were similar for individual cases in the experiment. The single neuron case is trained onIris dataset and the metric used is Accuracy (higher is better). For Multi-layer perceptron, we useBoston Housing dataset and the metric used for this is rmse (lower is better).
Table 2: Settling time in seconds for different values of tuning parameter, k for the single neuroncase on Iris dataset. We compare the time taken for convergence by three different loss functions,L1 , L2 and Lyapunov Loss function. The training conditions were similar for individual cases in theexperiment.
Table 3: rmse on IMDB Wiki test dataset for L1, L2 and Lyapunov Loss function.
Table 4: Settling time in seconds for different values of the upper bound on additive input perturba-tions, M for the multi layer perceptron case on Boston Housing dataset. We compare the time takenfor convergence by three different loss functions, L1, L2 and Lyapunov Loss function. The trainingconditions were similar for individual cases in the experiment.
