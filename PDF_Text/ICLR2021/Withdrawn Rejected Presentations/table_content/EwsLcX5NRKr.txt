Table 1: Accuracy of different instances of our approach compared to the original SSD network.
Table 3: VOC07: Comparison of scoring aggregation functions for active learning.
Table 4: Parameter sensitivity on VOC07: Accuracy and compute as a function of the number ofcomponents in the mixture modelK # of mixture	mAP (%) IoU > 0.5 IoU > 0.75		# of parameters (M)	Forward time (s)2	70.29±0.29	45.98±0.38	37.6	0.0254	70.19±0.36	46.11±0.38	52.3	0.0318	70.01±0.29	45.69±0.28		81.8	0.05111Under review as a conference paper at ICLR 2021A.2.2 Accuracy as a function of input image resolutionIn order to check for the robustness of our method with respect to the image size, here we comparethe performance of the network trained using higher resolution images (512 × 512). The experimentis analogous to the experiment we showed in Table 1a in the main text. We compare the results ofSSD (Liu et al., 2016), with the results of our method. As we can see in Table 5, as expected,increasing the resolution of the input image yields a significant improvement in mAP score for allthe methods. For high-resolution input images, our method outperforms SSD in the standard metric(IoU > 0.5) by 0.28pp, and shows significant improvement when evaluated in the strict metric (IoU> 0.75), with an improvement of 2.49pp. That is, our method is notably better in those scenarioswhere we need a higher intersection between the predicted bounding box and the ground truth.
Table 5: VOC07: Accuracy as a function of the resolution of input image.
Table 6: VOC07+12: Overlapping ratio (in %) of selected images as a function of the type ofuncertainty used.
Table 7: VOC07: Aleatoric and epistemic uncertainties as a function of (left) training data and(right) noise in the test set. The epistemic uncertainty decreases as the training set increases whereasthe aleatoric uncertainty increases as the noise in the test data increases.
Table 8: VOC07+12: Comparison to published work using a single model for scoring. Numberstaken from Yoo & Kweon (2019). In bold the best values for each active learning cycle.
Table 9: VOC07+12: Accuracy Comparison to MC-Dropout and ensemble. For MC-Dropout weinclude two instances: using 25 forward passes and using 50 forward passes. In bold the best valuesfor each active learning cycle.
Table 10: Model parameters in millions and forward time in seconds using a resolution of 300 × 300for the input image and K = 4.
