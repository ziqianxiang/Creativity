Table 1: Ablation results. We report average precision, recall and consistency for scenes (SP, SR,SC) and objects (OP, OR, OC), F1-score, Accuracy (Acc.), DS, scene and object FIDs (SFID andOFID). Results show the mean over 5 random seeds at test time. Extended table in Appendix E.
Table 2: F1-score and accuracy averaged across examples in splits Ss, Su and Su2 . This tablepresents the mean and standard deviation of 5 different random seeds for the generative models. *Trained using the open-sourced code.
Table 3: Diversity score using LPIPS metric in all evaluation splits Ss, Su, Su2. * Trained using theopen-sourced code.
Table 4: FID for each data split and model. As a reference, ground-truth images from each of theDs, Du and Du2 splits are used accordingly.Both splits have different number of points, so FID notcomparable across splits. This table presents the mean and standard deviation of 5 different randomseeds for the generative models.* Trained using the open-sourced code.
Table 5: Ablation results for all ablated pipelines, scene-wise precision, recall and coverage for thetwo splits Su and Su2. This table presents the mean and standard deviation of 5 random seeds thatcontrol the input noise.
Table 6: Ablation results for all ablated pipelines. Metrics reported are object-wise precision, recalland coverage for the two splits Su and Su2.This table presents the mean and standard deviation of 5random seeds that control the input noise.
Table 7: Ablation results for all ablated pipelines. F1-score, accuracy and DS for the two splits Suand Su2.This table presents the mean and standard deviation of5 random seeds that control the inputnoise.
Table 8: Ablation results for all ablated pipelines. Number of parameters per generator for each ofthe pipelines, scene FID and object FID for the two splits Su and Su2 .This table presents the meanand standard deviation of 5 random seeds that control the input noise.
Table 9: Direct comparison with the best state-of-the-art methods. We report average precision,recall and consistency for scenes (SP, SR, SC) and objects (OP, OR, OC), F1-score, Accuracy (Acc.),DS, scene and object FIDs (SFID and OFID). Results show the mean over 5 random seeds at testtime. Note that ISLA is the same architecture as LostGANv2, but trained with the experimental setupproposed in the ablation, that leads to generally better results than the ones reported in the originalpaper (Sun & Wu, 2019). Bold numbers represent the best average metric across methods.
