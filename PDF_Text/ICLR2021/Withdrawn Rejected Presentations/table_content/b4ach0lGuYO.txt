Table 1: Results for anomaly detection on the MVTecAD dataset, expressed in the AUROC onsample-wise reconstruction errors for different autoencoders and datasets. We compare the vanillaL2 and SSIM autoencoders(Bergmann et al., 2018) and their iterative projection method (Dehaeneet al., 2020) as baselines. Bold font is the best AUC in each category and lightblue backgroundindicates the best method measured by the average AUC on L2 and SSIM anomaly score.
Table 2: Comparison of iteration speedAnomaly detection overview Bergmann et al. (2019) introduced the MVTecAD dataset and con-ducted a thorough evaluation of traditional shallow models and recent state-of-the-art deep neuralnetworks for unsupervised AD and segmentation tasks. They showed the evaluated methods do notperform equally across data categories, and there is still room for improvement.
Table 3: Results for anomaly localization on the MVTecAD dataset, expressed in the AUROCon pixel-wise reconstruction errors for different autoencoders and datasets. Same as anomalydetection, we compare the vanilla L2 and SSIM autoencoders(Bergmann et al., 2018) and theiriterative projection method (Dehaene et al., 2020) as baselines. Bold font is the best AUC in eachcategory and lightblue background indicates the best method measured by the average AUC on L2and SSIM anomaly score.
Table 4: Results for anomaly detection on the MVTecAD dataset, expressed in the AUROCon sample-wise reconstruction errors for different autoencoders and datasets. We comparedAnoGAN (Deecke et al., 2018), f-AnoGAN (Schlegl et al., 2019), and AEGAN that is the basearchitecture for several models (Zenati et al., 2018; Akcay et al., 2018). Bold font is the best AUCin each category and lightblue background indicates the best method measured by the average AUCon L2 and SSIM anomaly score. We also test L2 +LD anomaly scores that combines reconstructionerrors and discriminator features as mentioned in Deecke et al. (2018).
Table 5: Results for anomaly localization on the MVTecAD dataset, expressed in the AUROC onpixel-wise reconstruction errors for different autoencoders and datasets. We compared AnoGAN(Deecke et al., 2018), f-AnoGAN (Schlegl et al., 2019), and AEGAN that is the base architecture forseveral models (Zenati et al., 2018; Akcay et al., 2018). Bold font is the best AUC in each categoryand lightblue background indicates the best method measured by the average AUC on L2 and SSIManomaly score.
