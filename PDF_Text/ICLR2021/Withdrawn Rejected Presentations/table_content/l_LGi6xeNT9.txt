Table 1: Classification accuracy vs. number of model parameters	Jester val acc %	# params	UCF101 val acc %	# paramsscratch 3T-GoogLeNet	74.1	7419121	33.4	7646671pret. 3T-GoogLeNet	84.9	7419121	63.7	7646671pret. 3D-GoogLeNet	89.9	14078833	58.7	14306383scratch. 3T-ResNet18	44.4	11222619	31.0	11260581pret. 3T-ResNet18	74.5	11222619	61.1	11260581pret. 3D-ResNet18	81.6	33217755	56.1	33255717scratch R(2+1)D	91.8	31313976	31.4	31351938Comparison with R(2+1)D. In order to compare our method with current state-of-the-art methodswe compare it with R(2+1)D model trained from scratch on the Jester and UCF101. The results canbe seen in Table 1. We can only compare the model trained from scratch due to time limitationsinvolving the download of the Kinetics dataset for a full comparison and we reserve this for futurework. From the comparison with the tabula rasa models, R(2+1)D performs exceptionally well on theJester dataset, however, on the UCF101 dataset it is outperformed by our 3TConv using 75% fewerparameters. This is in line with our previous observations where 3TConv outperforms 3DConv in thelow data regime.
Table 2: Overview of metadata after the data has been processed. UCF101 split 1 was used for trainand test.
Table 3: Training details for all models and datasets.
