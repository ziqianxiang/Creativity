Table 1: Token length statistics on the training split of our dataset compared to existing scientific paper sum-marization datasets. Contribution summaries tend to be shorter than context summaries.
Table 2: Automatic evaluation results on the test set. For all metrics, higher values indicate betterresults. Con and Ctx refer to contribution summary and context summary, respectively. Purity andDisentanglement are measaured on the pairs of contribution and context summaries.
Table 4: Relevance evaluation of contributionsummaries for the top 10 domains generated us-ing the ControlCode model. Performance onMedicine domain is paricularly low.
Table 3: Generated samples compared with the original and generated abstracts of the associated paper. Thesecond rows shows the output decoded from DistilBART fine-tuned on our dataset, the third rows shows theoutputs from ControlCode model. Our model successfully generates disentangled content, thus making iteasier to follow than the abstract.
Table 5: Usefulness of disentangled summaries inpercentage, e.g., Annotator 1 (A1) chose the disen-tangled summaries 82% out of all the samples fromS2ORC.
Table 6: Automatic evaluation results on 100 samples from the test set manually annotated forcontributions. For all metrics, higher values indicate better results.
