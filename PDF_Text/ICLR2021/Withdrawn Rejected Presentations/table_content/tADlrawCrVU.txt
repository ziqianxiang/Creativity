Table 1: Comparison of batch generation strategiesDataset	Random samples	Random disjoint samples	Random slicesAge group (Accuracy)	0.613 ± 0.006	0.619 ± 0.011	0.639 ±0.006Churn (AUROC)	0.820 ± 0.014	0.819 ± 0.011	0.823 ±0.017Assessment (Accuracy)	0.563 ± 0.004	0.563 ± 0.004	0.618 ±0.009Retail (Accuracy)	0.523 ± 0.001	0.505 ± 0.002	0.542 ±0.0025-fold cross-validation metric ±95% is shownSOP. Another simple baseline is the same as sequence order prediction task from ALBERT (Lan et al.,2020). It uses two consecutive sub-sequences as a positive pair, and two consecutive sub-sequenceswith swapped order as a negative pair.
Table 2: Accuracy on the downstream tasks: Metric increase against baselineMethod	Age group Accuracy	Churn AUROC	Assessment Accuracy	Retail AccuracyLightGBM:				Designed features	0.631 ± 0.004	0.825 ± 0.005	0.602 ± 0.006	0.547 ± 0.001SOP embeddings	-21.9% ± 0.6%	-5.3% ± 0.8%	-4.1% ± 1.0%	-22.8% ± 0.2%NSP embeddings	-1.5% ± 0.9%	+0.6% ± 0.7%	-3.5% ± 1.1%	-22.3% ± 0.4%RTD embeddings	+0.1% ± 0.6%	-2.9% ± 0.8%	-3.6% ± 1.1%	-5.0% ± 0.3%CPC embeddings	-5.9% ± 0.6%	-2.9% ± 0.6%	-2.3% ± 0.9%	-4.0% ± 0.3%CoLES embeddings	+1.1% ± 1.2%	+2.2% ±0.6%	-0.1% ± 0.9%	-1.4% ± 0.2%Supervised learning	0.628 ± 0.005	0.817 ± 0.012	0.602 ± 0.006	0.542 ± 0.001RTD fine-tuning	+1.2% ± 1.2%	+0.3% ± 1.3%	-2.7% ± 1.0%	+0.5% ± 0.4%CPC fine-tuning	-2.1% ± 1.6%	-0.9% ± 1.4%	+0.7% ± 1.1%	+1.2% ± 0.3%CoLES fine-tuning	+2.5% ±1.0%	+1.1% ±1.3%	+2.2% ±1.1%	+1.9% ±0.2%test set quality metric ±95% is shownIn the second scenario, we fine-tune pre-trained models for specific downstream tasks. The modelsare pre-trained using CoLES and other self-supervised learning approaches and then are additionallytrained on the labeled data for the specific task in the same way as we trained a neural net forthe supervised learning (see Section 4.1). A neural net without pre-training is also added to thecomparison. As Table 2 shows, fine-tuned representations obtained by our method achieve superiorperformance on all the considered datasets, outperforming all other methods by statistically significant
Table 3: Data structure for a single credit cardDate	Time	Amount	Currency	Country	Merchant TypeJun 21	16:40	230	EUR	France	RestaurantJun 21	20:15	5	USD	US	TransportationJun 22	09:30	40	USD	US	Household ApplianceTable 4: Click-stream structure for a single userTime	Date	Domain	Referrer Domain17:40	Jun 21	amazon.com	google.com17:41	Jun 21	amazon.com	amazon.com17:45	Jun 21	en.wikipedia.org	google.comD	DatasetsWe designed the method specially for the user behavior sequences (Ni et al., 2018). These sequencesconsist of discrete events per person in continuous time, for example, behavior on websites, creditcard transactions, etc.
Table 4: Click-stream structure for a single userTime	Date	Domain	Referrer Domain17:40	Jun 21	amazon.com	google.com17:41	Jun 21	amazon.com	amazon.com17:45	Jun 21	en.wikipedia.org	google.comD	DatasetsWe designed the method specially for the user behavior sequences (Ni et al., 2018). These sequencesconsist of discrete events per person in continuous time, for example, behavior on websites, creditcard transactions, etc.
Table 5: Hyper-parameters for CoLES trainingDataset	Output size	Learning rate	N samples in batch	N epochs	Min seq length	Max seq length	EncoderAge group	800	0.001	64	150	25	200	GRUChurn	1024	0.004	128	60	15	150	LSTMAssessment	100	0.002	256	100	100	500	GRURetail	800	0.002	256	30	30	180	GRUTable 6: Comparison of encoder typesDataset	LSTM	GRU	TransformerAge group (Accuracy)	0.621 ±0.008	0.638 ±0.007	0.622 ± 0.006Churn (AUROC)	0.823 ±0.017	0.812 ± 0.010	0.780 ± 0.012Assessment (Accuracy)	0.620 ±0.007	0.618 ±0.009	0.542 ± 0.007Retail (Accuracy)	0.535 ± 0.003	0.542 ±0.002	0.499 ± 0.0025-fold cross-validation metric ±95% is shownwe obtain a feature ’sum of all transaction amounts per user’. For the categorical type of attributewe apply aggregation functions in a slightly different way. For each unique value of categoricalattribute we apply aggregation functions, such as ’count’, ’mean’, ’std’ over all transactions per user’numerical attribute. For example, if we apply ’mean’ for the numerical attribute ’amount’ groupedby categorical attribute ’MCC code’ we obtain a feature ’mean amount of all transactions for eachMCC code per user’. For example, for age prediction task we have one categorical attribute (smallgroup) with 200 unique values, combining it with amount we can produce 200 * 3 features ('group0
Table 6: Comparison of encoder typesDataset	LSTM	GRU	TransformerAge group (Accuracy)	0.621 ±0.008	0.638 ±0.007	0.622 ± 0.006Churn (AUROC)	0.823 ±0.017	0.812 ± 0.010	0.780 ± 0.012Assessment (Accuracy)	0.620 ±0.007	0.618 ±0.009	0.542 ± 0.007Retail (Accuracy)	0.535 ± 0.003	0.542 ±0.002	0.499 ± 0.0025-fold cross-validation metric ±95% is shownwe obtain a feature ’sum of all transaction amounts per user’. For the categorical type of attributewe apply aggregation functions in a slightly different way. For each unique value of categoricalattribute we apply aggregation functions, such as ’count’, ’mean’, ’std’ over all transactions per user’numerical attribute. For example, if we apply ’mean’ for the numerical attribute ’amount’ groupedby categorical attribute ’MCC code’ we obtain a feature ’mean amount of all transactions for eachMCC code per user’. For example, for age prediction task we have one categorical attribute (smallgroup) with 200 unique values, combining it with amount we can produce 200 * 3 features ('group0x amount x count’, ’group1 x amount x count’, ..., ’group199 x amount x count’, ’group0 x amount xmean’, ...). In total we use approx 605 features for this task. Note, that hand-crafted features containinformation about user spending profile but omit information about transactions temporal order.
Table 7: Comparison of contrastive learning lossesDataset	Contrastive (margin=0.5)	Binomial deviance	Histogram	Margin	TripletAge group	0.639	0.621	0.632	0.638	0.636(Accuracy)	±0.006	±0.005	±0.008	±0.007	±0.004Churn	0.823	0.769	0.815	0.823	0.781(AUROC)	±0.017	±0.018	±0.018	±0.012	±0.021Assessment	0.618	0.589	0.615	0.612	0.600(Accuracy)	±0.009	±0.004	±0.007	±0.005	±0.004Retail	0.542	0.535	0.533	0.541	0.541(Accuracy)	±0.002	±0.004	±0.002	±0.001	±0.0015-fold cross-validation metric ±95% is shown					Table 8: Comparison of negative sampling strategiesDataset	Hard negative mining	Random negative sampling	Distance weighted samplingAge group (Accuracy)	0.639 ±0.006	0.626 ± 0.008	0.629 ± 0.004Churn (AUROC)	0.823 ±0.017	0.815 ± 0.013	0.821 ± 0.014Assessment (Accuracy)	0.618 ±0.009	0.593 ± 0.002	0.603 ± 0.010Retail (Accuracy)	0.542 ±0.002	0.530 ± 0.002	0.536 ± 0.0025-fold cross-validation metric ±95% is shownF.3 Semi-supervised setupTo evaluate our method in case of the restricted amount of labeled data, we use only part of the
Table 8: Comparison of negative sampling strategiesDataset	Hard negative mining	Random negative sampling	Distance weighted samplingAge group (Accuracy)	0.639 ±0.006	0.626 ± 0.008	0.629 ± 0.004Churn (AUROC)	0.823 ±0.017	0.815 ± 0.013	0.821 ± 0.014Assessment (Accuracy)	0.618 ±0.009	0.593 ± 0.002	0.603 ± 0.010Retail (Accuracy)	0.542 ±0.002	0.530 ± 0.002	0.536 ± 0.0025-fold cross-validation metric ±95% is shownF.3 Semi-supervised setupTo evaluate our method in case of the restricted amount of labeled data, we use only part of theavailable target labels for the semi-supervised experiment, see Section 4.2 for details. As in the caseof the supervised setup, we compare the proposed method with LigthGBM over hand-crafted features,CPC, and supervised learning without pre-training. In figure 6 we provide learning curves for allconsidered datasets.
