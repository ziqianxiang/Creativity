Table 1: Comparisons of the popular disentanglement metrics on the dSprites datasetIndependent Factors Correlated FactorsMethod	DCI	SAP	IRS	DCI	SAP	IRSFactorVAE(γ = 10)	0.73	0.55	0.62	0.60	0.46	0.54FactorVAE(γ = 40)	0.72	0.56	0.63	0.63	0.47	0.57β-TCVAE	0.62	0.54	0.55	0.55	0.46	0.46InfoGAN-CR	0.73	0.58	0.50	0.68	0.51	0.45Ours	0.76	0.55	0.62	0.74	0.51	0.59Table 2: Comparisons of the popular disentanglement metrics on the 3DShapes datasetIndependent Factors Correlated FactorsMethod	DCI	SAP	IRS	DCI	SAP	IRSFactorVAE(γ = 10)	0.75	0.43	0.65	0.60	0.33	0.57FactorVAE(γ = 40)	0.73	0.53	0.67	0.49	0.26	0.42β-TCVAE	0.76	0.46	0.70	0.68	0.23	0.64InfoGAN-CR	0.53	0.40	0.57	0.36	0.25	0.44Ours	0.63	0.45	0.62	0.67	0.47	0.665.2	ImplementationWe choose the network structures of baselines according to their papers. We implement our modelwith the similar structures of shared components (Encoder, Decoder) with FactorVAE. In dSpritesand 3DShapes dataset, we follow the common setting of KZ = 10, DZ = 1. In CMNIST, we set
Table 2: Comparisons of the popular disentanglement metrics on the 3DShapes datasetIndependent Factors Correlated FactorsMethod	DCI	SAP	IRS	DCI	SAP	IRSFactorVAE(γ = 10)	0.75	0.43	0.65	0.60	0.33	0.57FactorVAE(γ = 40)	0.73	0.53	0.67	0.49	0.26	0.42β-TCVAE	0.76	0.46	0.70	0.68	0.23	0.64InfoGAN-CR	0.53	0.40	0.57	0.36	0.25	0.44Ours	0.63	0.45	0.62	0.67	0.47	0.665.2	ImplementationWe choose the network structures of baselines according to their papers. We implement our modelwith the similar structures of shared components (Encoder, Decoder) with FactorVAE. In dSpritesand 3DShapes dataset, we follow the common setting of KZ = 10, DZ = 1. In CMNIST, we setKZ = 2, DZ = 16 and in OxfordFlowers102, we set KZ = 3, DZ = 16. Since some baselines aredesigned for one dimension of representation to a factor and difficult to apply when DZ > 1. Weonly compare our algorithm with FactorVAE on CMNIST and OxfordFlowers102 datasets. For eachmodel, we repeat 10 times and report the average performance. More details about implementationare shown in the Appendix.
Table 3: Comparisons of the popular disentanglement metrics on the CMNIST datasetIndependent Factors Correlated FactorsMethod	SAP	SAPFactorVAE(γ = 10)	0.83 ± 0.02	0.41 ± 0.02FactorVAE(γ = 40)	0.72 ± 0.08	0.47 ± 0.11Ours	0.74 ± 0.03	0.70 ± 0.025.3	Image Translation Task Difficulty as Disentanglement MetricIn this section, we evaluate the effectiveness of our proposed metric and prove that our novel metriccorrelates well with existed ground-truth-required metrics. For fair comparison, we run FactorVAEwith different hyper-parameters, random seeds and factor relationships(independent/correlated) tocover a large range of model performance. Then we calculate various disentanglement metrics withours of each model on the held-out test set. Finally, we compute the spearman rank correlation ofthese metrics on dSprites and 3DShapes datasets. Note that the two models are not trained withoutoverlap objectives when using metrics. From the results in Fig. (3), our proposed self-supervised-based metrics correlates well with other ground-truth-required metrics, thus it can be used to selectmodels, choose hyper-parameters, and act as a part of the model training objective.
Table 4: Encoder and Decoder network architectures of our model for dSprites(nc = 1) and3DShapes (nc = 3) experiments.
Table 5: Discriminator and Weight Network architectures of our model for dSprites(nc = 1) and3DShapes (nc = 3) experiments.
Table 6: Encoder and Decoder network architectures of our model for CMNIST experiments.
Table 7: Discriminator and Weight Network architectures of our model for CMNIST experiments.
Table 8: Encoder and Decoder network architectures of our model for OxfordFlowers10 experiment.
Table 9: Discriminator and Weight Network architectures of our model for OxfordFlowers10 exper-iment.
