Under review as a conference paper at ICLR 2021
ChePAN: Constrained Black-Box Uncertainty
Modelling with Quantile Regression
Anonymous authors
Paper under double-blind review
Abstract
Most predictive systems currently in use do not report any useful information for
auditing their associated uncertainty and evaluating the corresponding risk. Taking
it for granted that their replacement may not be advisable in the short term, in this
paper we propose a novel approach to modelling confidence in such systems while
preserving their predictions. The method is based on the Chebyshev Polynomial
Approximation Network (the ChePAN), a new way of modelling aleatoric uncer-
tainty in a regression scenario. In the case addressed here, uncertainty is modelled
by building conditional quantiles on top of the original pointwise forecasting sys-
tem considered as a black box, i.e. without making assumptions about its internal
structure. Furthermore, the ChePAN allows users to consistently choose how to
constrain any predicted quantile with respect to the original forecaster. Experi-
ments show that the proposed method scales to large size data sets and transfers
the advantages of quantile regression to estimating black-box uncertainty.
1 Introduction
COnStrained black-box UnCertaintV modelling in COnteXt
/llɪuStratiVe PrObl
Predicting the
temperature
by looking out
off the window.
any quantile of pɑ/ ∣ X)
a rule-based system
or
any pointwise
forecasting model
to: % is a certain statistic wrt
p(y I X)(e.g. the mean, the median,
the maximum or the minimum).
Figure 1: Description of the uncertainty modelling of a black-box predictive system, β . This mod-
elling is done by means of an uncertainty wrapper (the only part of the ChePAN that requires a neural
network), which produces all of the distribution ppy | xq as quantiles, qppy|xq. The ChePAN ensures
that the original prediction of β corresponds to a desired statistic of ppy | xq, i.e. the constraint.
The present paper proposes a novel method for adding aleatoric uncertainty estimation to any point-
wise predictive system currently in use. Considering the system as a black box, i.e. avoiding any hy-
pothesis about the internal structure of the system, the method offers a solution to the technical debt
debate. The concept of technical debt was introduced in 1992 to initiate a debate on the long-term
costs incurred when moving quickly in software engineering (Sculley et al. (2015); Cunningham
(1992)). Specifically, most of the predictive systems currently in use have previously required much
effort in terms of code development, documentation writing, unit test implementation, preparing de-
pendencies or even their compliance with the appropriate regulations (e.g., medical (Ustun & Rudin
(2016)) or financial models (Rudin (2019)) may have to satisfy interpretability constraints). How-
ever, once the system is being used with real-world problems, a new requirement can arise regarding
the confidence of its predictions when the cost of an erroneous prediction is high. That being said,
replacing the currently-in-use system may not be advisable in the short term. To address this issue,
1
Under review as a conference paper at ICLR 2021
x
τ
DCT	Integration
Figure 2: Graphic representation of the ChePAN. For any degree d, {p& ud´j are evaluations of the
initial Chebyshev polynomial expansion, {ck}k“0 their coefficients, {Ck}k“0 the coefficients of the
integrated polynomial, β the black box function and P the conditional prediction of the quantile τ .
P(τ, x; d)
the aim of this work is to report any information that is useful for auditing the system’s associated
uncertainty without modifying its predictions.
In general terms, sources of uncertainty can be understood by analysing the conditional members of
this joint distribution: ppy, xq “ Mppy | x, M qppM | xqppxq dM where M P M is the family
(assumed non-finite) of models being considered.
Not all methods developed to model uncertainty can be applied in the black-box scenario, since
the main hypothesis is that the black box is a fixed single model and unknown internally. Here,
we refer specifically to those solutions that model epistemic uncertainty, which requires modelling
ppM | xq. By epistemic, we mean that uncertainty which can derive from ignorance about the
model, including, for example, ensemble models (Lakshminarayanan et al. (2017)), Bayesian neural
networks (Rasmussen (1996); BlUndell et al. (2015); Hernandez-Lobato & Adams (2015b); Teye
et al. (2018)) or MC-Dropout (Gal & Ghahramani (2016)).
However, the black box could be a non-parametric predictive system or even a handcrafted rule-
based system, as shown in Figure 1. Hence the reason for studying aleatoric uncertainty (Der Ki-
ureghian & Ditlevsen (2009); Kendall & Gal (2017); Brando et al. (2019)), which originates from
the variability of possible correct answers given the same input data, ppy | xq. This type of un-
certainty can be tackled by modelling the response variable distribution. For instance, imposing a
conditional normal distribution where the location parameter is the black-box function and the cor-
responding scale parameter is learnt. However, the more restricted the assumptions made about this
distribution, the more difficult it will be to model heterogeneous distributions. One solution to this
limitation is the type of regression analysis used in statistics and econometrics known as Quantile
Regression (QR), which will provide a more comprehensive estimation.
Unlike classic regression methods, which only estimate a selected statistic such as the mean or the
median, QR allows us to approximate any desired quantile. The main advantage of this method is
that it allows confidence intervals to be captured without having to make strong assumptions about
the distribution function to be approximated.
Recently, several works (Dabney et al. (2018a); Tagasovska & Lopez-Paz (2018); Brando et al.
(2019)) have proposed a single deep learning model that implicitly learns all the quantiles at the same
time, i.e. the model can be evaluated for any real value τ P r0, 1s to give a pointwise estimation
of any quantile value of the response variable. Nevertheless, these QR solutions are not directly
applicable to the uncertainty modelling of a black box because the predicted quantiles need to be
linked to the black-box prediction in some way.
In the present paper, we propose a novel method for QR based on estimating the derivative of the
final function using a Chebyshev polynomial approximation to model the uncertainty of a black-
box system. Specifically, this method disentangles the estimation of a selected statistic β of the
distribution ppy | xq from the estimation of the quantiles of ppy | xq (shown in Figure 2). Hence,
our method is not restricted to scenarios where we can jointly train both estimators, but can also be
applied to pre-existing regression systems as a wrapper that produces the necessary information to
evaluate aleatoric uncertainty. Additionally, the proposed method scales to several real-world data
sets.
2
Under review as a conference paper at ICLR 2021
This paper is organised as follows. Section 2 states the real-world motivation of the current re-
search as well as the contribution it will be presented. Section 3 introduces the problem of QR and
reviews the classic approach to use with neural networks, showing how it cannot be applied directly
to constrained black-box uncertainty modelling. Section 4 explores an approach for modelling the
derivative of a function using neural networks. The two previous sections provide the baseline for
developing our proposed model and its properties, which is presented in Section 5. And finally, in
Section 6, we show how our model can be applied in large data sets and defines a new way of mod-
elling the aleatoric uncertainty of a black box. The results are then summarised in the conclusion.
2	Research goal and contribution
The present article was motivated by a real-world need that appears in a pointwise regression fore-
casting system of a large company. Due to the risk nature of the internal problem where it is applied,
uncertainty modelling is important. However, similarly to the medical or financial cases presented
in the introduction, interpretability requirements were essential in defining the model currently used
by the company, which does not report confidence any prediction made. The need for this research
arises in cases where the replacement of the aforementioned system is not advisable in the short
term, despite the ongoing need for the uncertainty estimation of that system.
Definition of constrained black-box uncertainty modelling
From the probabilistic perspective, solving a regression problem involves determining a condi-
tional density model, qpy | xq. This model fits an observed set of samples D “ pX, Y q “
pxi , yi q | xi P RD , yi P R in“1 , which we assume to be sampled from an unknown distribution
ppy | xq. i.e. the real data. Given this context, the pointwise forecasting system mentioned above
is a function, β : RD → R, which tries to approximate a certain conditional summary statistic (a
percentile or moment) of ppy | xq.
Regarding the notation, we will call the “constraint” the known or assumed summary statistic that
is approximated by βpxq (e.g. if β is reducing the mean square error, then it corresponds to the
conditional mean. Otherwise, if it minimises the mean absolute error, it corresponds to the median).
Importantly, in the constrained black-box uncertainty modelling context, the mismatch between the
real conditional statistic and the black box, β, becomes a new source of aleatoric uncertainty that
is different from the one derived from the data. However, the way to model it continues to be by
estimating ppy | xq. Therefore, a poorly estimated β will impact the modelling of ppy | xq, given
that we always force the constraint to be satisfied (as shown in Figure 3 of the Experiment section).
So far, we have attempted to highlight the fact that we do not have a strong hypothesis about the
internals of this β function, we have only assumed that it approximates a certain statistic of ppy | xq.
Accordingly, we call this function the “constrained black box”. This flexible assumption will enable
us to consider several pointwise models as β, as shown in Figure 1.
The overall goal of the present article is, taking a pre-defined black box βpxq that estimates a certain
conditional summary statistic of ppy | xq, to model qpy | xq under the constraint that if we calculate
the summary statistic of this predicted conditional distribution, it will correspond to βpxq.
As mentioned in the Introduction, since we have a fixed black box, we are unable to apply Bayesian
techniques such as those that infer the distribution of parameters within the model, ppM | xq. In
general, even though they are very common techniques in generic uncertainty modelling, no such
epistemic uncertainty techniques can be applied in this context due to the limitation of only having
a single fixed model.
In addition, it should be noted that not all models that estimate ppy | xq can be used in the con-
strained black-box uncertainty modelling context. To solve this problem, we require models that
predict qpy | xq but also force the chosen conditional summary statistic of qpy | xq to have the same
value as βpxq. The main contribution of this work is to present a new approach that allows us not
only to outperform other baseline models when tackling this problem, but also to decide which kind
of constraint we wish to impose between βpxq and qpy | xq. The qpy | xq will be approximated
using Quantile Regression (explained in Section 3) and the constraint will be created considering
the integration constant of the qpy | xq derivative (shown in Section 5.1).
3
Under review as a conference paper at ICLR 2021
3	Conditional Quantile Regression
In Quantile Regression (QR), we estimate q in a discrete manner by means of quantiles, which does
not assume any typical parametric family distribution to the predicted p, i.e. it goes beyond central
tendency or unimodality assumptions.
For each quantile value τ P r0, 1s and each input value x P RD, the conditional quantile function
will be f: ro, 1] X RD → R. In our case, We use deep learning as a generic function approximator
(Hornik et al. (1989)) to build the model f, as we shall see later. Consequently, f is a paramet-
ric function that will be optimised by minimising the following loss function with respect to their
weights w,
L(x,y,τq = 'y — fw(τ, x)) ∙ (T — 1]y V fw(τ, x)])	(1)
where 1rcs denotes the indicator function that verifies the condition c. Equation 1 is an asymmetric
convex loss function that penalises overestimation errors with weight τ and underestimation errors
with weight 1 ´ τ .
Recently, different works (Dabney et al. (2018b;a); Wen et al. (2017)) have proposed deep learning
models that minimise a QR loss function similar to Equation 1. For instance, in the field of reinforce-
ment learning, the Implicit Quantile Network (IQN) model was proposed (Dabney et al. (2018a))
and subsequently applied to solve regression problems as the Simultaneous Quantile Regression
(SQR) model (Tagasovska & Lopez-Paz (2019)) or the IQN in (Brando et al. (2019)). These models
consist of a neural network ψ: [0,1] X RD → R such that it directly learns the function f that
minimises Equation 1, i.e. f “ ψ . In order to optimise ψ for all possible τ values, these models
pair up each input x with a sampled τ „ U(0, 1q from a uniform distribution in each iteration of
the stochastic gradient descent method. Thus, the final loss function is an expectation over τ of
Equation 1.
However, these QR models cannot be applied to the constrained black-box scenario, given that
they do not link their predicted quantiles with a pointwise forecasting system in a constrained way
(Section 5.1). Other models, such as quantile forests, have a similar limitation. In the next section,
we introduce the other main part required to define our proposed method.
4	Modelling the Derivative with a Neural Network
Recently, a non-QR approach was proposed to build a monotonic function based on deep learning:
the Unconstrained Monotonic Neural Network (UMNN) (Wehenkel & Louppe (2019)). The UMNN
estimates the derivative ofa function by means ofa neural network, φ, which has its output restricted
to strictly positive values, i.e. approaching H(zq such that
H(z) “ Z φ(t) dt ' H(0).
0
(2)
Therefore, if the neural network φ(z) « BH (z) > 0, this is in fact a sufficient condition to force
H(z) to be monotone.
To compute the integral of BH, the UMNN approximates the integral of Equation 2 using the
Clenshaw-Curtis quadrature, which has a closed expression. The UMNN is designed to obtain a
general monotonic function with respect to all the model inputs, z, but our interest is to build a
partial monotonic function with respect to the quantile value, as we will explain hereafter.
The partial monotonic function will be obtained using the Clenshaw-Curtis Network (CCN) model,
which is an extension of the UMNN model introduced in Section A.3 of the Appendix and an
intermediate step we took to arrive at the main proposal of the current article. Importantly, we
have not included it in the main article because it cannot be applied to the constrained black-box
uncertainty modelling scenario (as described in Section A.3).
5	ChePAN: the Chebyshev Polynomial Approximation Network
In this section, we will extend the UMNN to a model that is only monotonic with respect to the
quantile input τ. Moreover, we will exploit the fact that the quantile domain is in r0, 1] to provide
4
Under review as a conference paper at ICLR 2021
an approach which is uniformly defined over all of the interval. We call this approach the Cheby-
shev Polynomial Approximation Network (ChePAN), which allows us to transfer the advantages of
quantile regression to the constrained uncertainty modelling of a black box.
As Figure 2 shows, the ChePAN contains a neural network φ: [0,1] X RD → r` that only Pro-
duces positive outputs and models the derivative of the final function with respect to τ. The goal is to
oPtimise the neural networks φpτ, xq by calculating the coefficients of a truncated Chebyshev Poly-
nomial exPansion ppτ, x; dq of degree d with resPect to τ. That is, we will use a Chebyshev Poly-
nomial (described in Section A.1 of the APPendix) to give a rePresentation of the neural network, φ,
uniformly defined in τ P r0, 1s. After that, we will use its ProPerties to model the uncertainty of a
black box in a constrained way (described in Section 5.1).
Internally, the ChePAN considers a finite mesh of quantile values, called Chebyshev roots,
{tk Ud“0 U [0,1] and defined by
tk - 1 cos π"d 2q + 1,	0 ≤ k < d.	(3)
The truncated Chebyshev exPansion of a function can be interPreted as a linear transformation using
a set of evaluations of φ at the roots, i.e. {φ(tk, x)}k“0. This linear transformation gives a vector
of coefficients, which are known as Chebyshev coefficients and depend on x, i.e. {ck(x)}k“0, as
illustrated in Figure 2.
The implementation of a linear transformation generally has a square complexity. However, the
transformation involved in Chebyshev coefficients can be computed efficiently with a Θ(d log dq
complexity. In fact, the algorithm that speeds the computation is based on the Fast Fourier Transform
(FFT) and known as the Discrete Cosine Transform of type-II (DCT-II) (discussed in Section A.1 of
the Appendix).
Once the Chebyshev coefficients ck(xq have been computed, we can write them in a linear combi-
nation of Chebyshev polynomials Tk (tq, i.e.
1	d´1
p(τ, x; d - -co(x) + X Ck(x)Tk(2τ — iq,	(4)
2	k“1
where Tk(t) are defined recurrently as T°(t) = 1, Tι(t) “ t, and Tk'i(tq = 2tTk(t) — Tkτ(t)
for k21. These polynomials Tk do not need to be explicitly computed to evaluate P on a quantile
(Clenshaw (1955)).
Note that, given the construction of the coefficients ck (xq, the p(tk, x; dq is equal to φ(tk, xq at
each of the root points tk . These equalities must be understood in terms of machine precision in
the numerical representation system, classically 〜10-16 in double-precision or 〜10-8 in single-
precision arithmetic. In Figure 2, we denote this root evaluation step as ptk .
The final goal is to provide P(τ, x; dq so that it approximates the integral ofp, that is 0τ p(t, x; dq dt.
Specifically, the integral will also be the integral of the neural network φ,
P (τ, x; dq « Φ(τ, xq “	φ(t, xq dt + K (xq.	(5)
0
Since φ(τ, xq is defined as positive for all τ P [0, 1], then P(τ, x; dq will be an increasing function
with respect to τ.
Additionally, given that p(τ, x; dq is a Chebyshev polynomial (defined in Equation 4), its integral
w.r.t. τ is simply the integral of the Chebyshev polynomial Tk, which corresponds to a new Cheby-
shev polynomial. Using the recurrent definition ofTk, we deduce the indefinite integrals
fτm,, Te fτm,, T2(tq To(tq	CT Tk ´, Tkτ(t) Tk'i(tq 心
JT0(t) dt = T1(tq,	JT1(t)dt =	-4------厂,JTkpt)dt =	-(k´1)´	-(k+l),⑹
which leads to the conclusion that P can be given in terms of Chebyshev coefficients as well. Thus,
1	d´1
P(τ, x; d) - -Co(x) + X Ck(X)Tk(2τ — 1),	(7)
2	k“1
5
Under review as a conference paper at ICLR 2021
where the coefficients Ckpxq have a recurrent expression in terms of a Toeplitz matrix (see Clenshaw
(1955)). Indeed, by ordering the coefficients of the integral in Equation 4, we deduce that
… c	Ck — i(x)— Ck'1 pxq	1	/、	Cd—2(x)
CkPXq -	~Γ,	,	0 V k V d ´ 1, Cd´1(Xq - ~Γ7~j	TV,	⑻
4k	4(d ´ 1q
and C0 (xq depends on the constant of integration K(xq in Equation 5 and the other coefficient
values in Equation 7. This freedom of the predicted τ in C0 (xq allows us to impose a new condition,
which becomes a uniform condition in all of the intervals r0, 1s. In Section 5.1, we will discuss how
to define the C0 (xq depending on the black box desired.
5.1	Adding an Uncertainty Estimation to a Black-Box Prediction System
In this subsection, we tackle the constrained black-box uncertainty modelling problem introduced
in Section 2. The main assumption is that we have a pointwise predictive system, which we will
refer to as β (xq and approximates a desired statistic such as the mean, median or a certain quantile
of p(y | xq, as shown in Figure 1. It is not necessary for this system to be a deep learning model or
even parametric. All that the ChePAN requires to train its neural network, φ, are the corresponding
β-evaluation values of the training set, i.e. tx, β(xqu. Thus, the ChePAN calculates the conditioned
response distribution to the input without assuming asymmetry or unimodality with respect to this
distribution, as well as associating the desired statistic of this distribution to β(xq.
The formula used to calculate the constant of integration, C0 (xq, will depend on which statistic we
choose1. If we impose the quantile τ “ 0 to be β (which we shall call ChePAN-β=q0), then
d´1
Co(xq = 2β(x) ´ 2 £ Ck(Xq(—1)k.	(9)
k“1
However, if we force the quantile τ “ 1 to be the β (which we shall call ChePAN-β=q1), then
d´1
C0(Xq “ 2β(Xq ´ 2 £ Ck(Xq.	(10)
k“1
For instance, the prediction of extreme weather events involves the forecasting system to predict the
maximum or minimum values of p(y | Xq. In these cases, this pre-trained system could be used as β
in Equation 9 or Equation 10, respectively, to determine the overall quantile distribution of p(y | Xq,
taking β as a reference point.
If the median (equivalently, τ “ 0.5) is the β (which we shall call ChePAN-β =Med), then
d´1
Co(xq = 2β(x) ´ 2 £ (τq"2Ck(x).
k“1
k even
Finally, the mean is forced to be the β (which we shall call ChePAN-β=Mean), then
Co(χ) =2β(x) ´2 £ k^´ 4.
k“1
k odd
(11)
(12)
Additionally, β(Xq can be approximated by means of another neural network, which can be simul-
taneously optimised with φ(τ, Xq. We will use this approach to compare the ChePAN and other
baseline models in the results section regarding black-box modelling.
6	Experiments
The source code used to reproduce the results of the ChePAN in the following experiments can
be found in the Github repository2. The DCT-II method referred to in Section 5 was used in the
aforementioned source code.
1All details of how such formulas are reached can be found in the supplementary material.
2The camera-ready version of this paper will include all of the source codes to reproduce the experiments.
6
Under review as a conference paper at ICLR 2021
Table 1: Mean and standard deviation of the QR loss value, mean 土 std, of 10 executions for each
Black box - Uncertainty wrapper using all of the test distributions in Figure 3 and three data sets
(described in Section A.6). The ranges that overlap with the best range are highlighted in bold.
IRF I-N
IRF I-LP
I RF I-ChePAN
I XGBooSt I-N
I XGBoost -LP
XGB. -ChePAN
N
LP
ChePAN
Asymmetric Symmetric Uniform Multimodal Year-MSD BCN-RPF YVC-RPF
42.37 土 0.04
42.88 土 0.04
41.52 土 0.35
42.42 土 0.05
42.90 土 0.02
41.95 土 0.40
43.63 土 2.89
43.46 土 0.15
41.72 土 0.24
23.19 士 1.00
22.10 土 0.03
23.19 土 0.70
23.35 土 0.99
23.02 土 0.43
23.69	土 0.68
23.70	土 6.85
20.72 土 0.47
22.94 土 1.81
66.44 土 0.26
67.13 土 0.09
65.98 土 0.20
66.38 土 0.26
67.13 土 0.17
65.89 土 0.17
67.45 土 1.68
68.06 土 0.82
68.55 土 6.61
151.51 土 0.24
153.06 土 0.22
148.39 土 0.16
149.35 土 0.40
150.94 土 0.12
146.20 土 0.30
148.78 土 2.88
149.99 土 0.64
145.93 土 3.14
57.50 土 .05
57.58 土 .02
48.28 土 .18
51.17 土 .08
51.24 土 .02
48.54 土 .08
49.00 土 .24
48.67 土 .28
46.76 土 .25
23.47 土 .14
23.07 土.17
23.17 土.07
24.52 土 .26
22.63 土 .11
22.00 土 .04
27.28 土 1.25
23.51 土 .28
20.67 土 .40
27.27 土.39
28.06 土 .12
28.16 土 .14
27.79 土 .08
27.86 土 .07
27.51 土 .13
28.62 土 1.61
22.32 土 .06
21.97 土.12
In this section, we describe the performance of the proposed models compared to other baselines.
The main goal is to show that by using QR the ChePAN is an improvement on other black-box
uncertainty modelling baselines because it avoids centrality or unimodality assumptions, while also
allowing users to choose how to constrain the predicted quantiles with respect to the black-box
prediction.
6.1	Models Under Evaluation
Exponential power distributions satisfy the condition that one of the parameters corresponds to the
mode. Thus, those models that approximate such parametric distributions where the mode parameter
is the black-box function and estimate the other parameter related to uncertainty can be used as
baselines.
•	The Heteroscedastic Normal distribution (N) Similarly to (Bishop (1994); Kendall &
Gal (2017); Tagasovska & Lopez-Paz (2019); Brando et al. (2019)), two neural networks,
μ and σ, can be used to approximate the conditional normal distribution, N(μ(x), σ(x)),
such that they maximise the likelihood.
In the black-box scenario proposed here, μ is the black-box function and We only need to
optimise the σ neural network. Once optimised, the desired quantile T can be obtained with
F(τ, xq “ μ(xq ' σ(x)√2 ∙ erf-1(2τ — 1), T P (0,1), where erf´1 is the inverse error
function.
•	The Heteroscedastic Laplace distribution (LP) As a more robust alternative to outlier
values, a conditional Laplace distribution, LP(μ(x), b(x)), can be considered. Here, the
quantile function is F(τ, x) “ μ(x) ' 'b log(2τ)) ∙ 1[τ ≤ 1 ] — 'b log(2 — 2τ)) ∙ 1[τ > 1 ],
T P (0, 1).
•	The Chebyshev Polynomial Approximation Network (ChePAN) In order to use the same
black boxes as the other baselines, Equation 12 is considered, given that these black boxes
are optimising the mean square error. Other alternative equations are considered in the
pseudo code and in Figure 6 of the supplementary material.
6.2	Data Sets and Experiment Settings
All experiments were implemented in TensorFlow (Abadi et al. (2015)) and Keras (Chollet et al.
(2019)), running in a workstation with Titan X (Pascal) GPU and GeForce RTX 2080 GPU. All the
details of the data sets used and model hyper-parameters for the results section are described in the
supplementary material.
6.3	Results
Table 1 shows a comparison of uncertainty modelled for two given black-box systems (a Random
Forest (RF) (Liaw et al. (2002)) and an XGBoost (Chen & Guestrin (2016))) in four data sets. The
7
Under review as a conference paper at ICLR 2021
Figure 3: Heterogeneous synthetic distribution proposed by (Brando et al. (2019)). In the upper
part of the figure, the learnt quantiles, φ, are noisy because their mean is the black box defined as an
inaccurate MSE Random Forest (RF), β, following Equation 12. In the lower part, φ and β are learnt
and asymmetries and multimodalities can be seen more clearly, while still respecting the constraint
in Equation 12.
first four columns correspond to each part of the synthetic distribution proposed by (Brando et al.
(2019)) and shown in Figure 3, the fifth column is the full Year Prediction MSD UCI dataset (Dua &
Graff (2017a)), predicting the release year of a song from 90 audio features and, finally, the last two
columns correspond to predicting the room price forecasting of Airbnb flats (RPF) in Barcelona and
Vancouver, extracted from (Brando et al. (2019)). The mean of the QR loss value (see Equation 1) is
evaluated for ten thousand randomly selected quantiles for ten executions of each model tmku1k0“1,
「	( γ V 、- Ntest Nτ (yi ´ fmk PTj，Xiq)，(Tj ´ 1ryi < fmk PTj，Xiqs)
LmkpXtest, Ytest q = /j ZJ --------------------Nt 力.N----------------------,	(13)
where Ntest is the number of points in the test set, Nτ “ 10, 000 the number of Monte Carlo
samplings and fmk any of the models considered in Table 1. Considering how the QR loss is
defined in Equation 1, its value not only informs us about each system’s performance but also how
generically calibrated its predicted quantiles are.
Furthermore, in Table 1 we observe that the ChePAN outperforms other methods in most cases due
to it transferring the capacity to capture asymmetries and multimodalities of QR in pPy | Xq to the
black-box problem, where our uncertainty modelling needs to be restricted in order to maintain the
corresponding statistic associated with the black box.
This restriction of conserving the black box can be seen qualitatively in the upper part of Figure 3,
where such a restriction must be met in any situation, i.e. even if performance worsens because the
black box, βPxq, is not correctly fitted (as described in Section 2). In this case, βPxq is an inaccurate
Random Forest predicting the mean. Importantly, the ChePAN propagates the βPxq noise to the
predicted quantiles (in blue) because the constraint is always forced. On the other hand, the ability
of ChePAN to model heterogeneous distributions using QR is better displayed in the lower part of
Figure 3. In this case, the black box is a neural network that is learnt concurrently with the quantiles.
Since the black box is better approximated, the quantiles are better.
Finally, since Table 1 shows that there is a similar performance order between the baselines when
using the RF or XGBoost, we also want to show additional experiments that directly measure the
calibration of the predicted quantiles and compare the predicted width of certain desired intervals.
Following the UCI data sets used in (HernandeZ-Lobato & Adams (2015b); Gal & Ghahramani
(2016); Lakshminarayanan et al. (2017); Tagasovska & Lopez-Paz (2019)), we performed two em-
pirical studies to assess this point in a black-box scenario where the black box is an MSE-XGBoost.
Following the proposed hidden layers architecture in (Tagasovska & LopeZ-PaZ (2019)), the Pre-
diction Interval Coverage Probability (PICP) and the Mean Prediction Interval Width (MPIW) are
reported in Table 3 of the appendix considering the 0.025 and the 0.975 quantiles. For the sake of
8
Under review as a conference paper at ICLR 2021
.o0q 6 / 2.0
LCiCiCiCiCi
SIUod JO -QlOl / ①-口Uenb P3yp ①一d ① Ill MoαjqBuodJS ①一
Concrete
Power
Wine
Yacht
Naval
Energy
Boston
Kin8nm
Protein
XGBooSt	-N	XGBoost	-LP	XGBoost	-ChePAN
14.40 ± 1.7		14.35 ± 1.5		5.99 ± 4.4	
6.31 ± 0.7		6.63 ± 1.6		4.15 ± 1.4	
4.40 ± 1.2		4.34 ± 1.2		4.58 ± 1.6	
8.93 ± 2.3		6.98 ± 2.4		14.20 ± 3.9	
6.61 ± 2.8		7.21 ± 2.1		6.90 ± 2.7	
6.12 ± 2.1		5.05 ± 2.0		6.26 ± 2.2	
15.55 ± 3.1		15.30 ± 2.1		4.99 ± 1.7	
3.55 ± 0.6		4.79 ± 0.5		5.25 ± 0.8	
7.88 ± 1.9		7.30 ± 0.3		5.39 ± 0.8	
Figure 4: Plot with performance in terms of calibration. The table contains the mean and standard deviation
of all the folds using the mean absolute error between the empirical predicted calibration and the perfect ideal
calibration of 980 equidistant quantiles using Equation 14.
completeness, in Figure 4 and its associated table we have also computed an additional metric not
only to verify the calibration of the 0.025 and 0.975 quantiles, but also to obtain a measure of gen-
eral calibration considering the entire quantile distribution. Given Nτ -equidistant set of quantiles to
evaluate, T = [10-2,..., 1 — lθ´2S, the % of actual test data that falls into each predicted quantile
can be compared to each real quantile value as follows,
1 Nτ	1	Ntest
C alpf ； Xtest ,Ytest, T) =	|Tj ´	1ryi V fpτj, Xi 川
Nτ j“1	Ntest i“1
(14)
In addition, two extra figures showing the disentangled visualisation of this calibration metric from
each quantile can be found in Figure 5 of the Appendix. As all of the figures and tables show, in
terms of calibration, the ChePAN generally displays a better performance in the black-box scenario
than the other models.
7	Conclusion
The uncertainty modelling of a black-box predictive system requires the designing of wrapper so-
lutions that avoid assumptions about the internal structure of the system. Specifically, this could
be a non-deep learning model (such as the one presented in Table 1 and Figure 3) or even a non-
parametric predictive system, as proposed in Figure 1. Therefore, not all models or types of uncer-
tainties can be considered using this framework.
The present paper introduces the Chebyshev Polynomial Approximation Network (ChePAN) model,
which is based on Chebyshev polynomials and deep learning models and has a dual purpose: firstly,
it predicts the aleatoric uncertainty of any pointwise predictive system; and secondly, it respects the
statistic predicted by the pointwise system.
To conclude, then, the ChePAN transfers the advantages of Quantile Regression (QR) to the prob-
lem of modelling aleatoric uncertainty estimation in another existing and fixed pointwise predictive
system (denoted as β and referred to as a black box). Experiments using different large-scale real
data sets and a synthetic one that contains several heterogeneous distributions confirm these novel
features.
References
M. Abadi, P. Barham, J. Chen, Z. Chen, A. Davis, J. Dean, M. Devin, S. Ghemawat, G. Irving,
M. Isard, et al. Tensorflow: A system for large-scale machine learning. In 12th tUSENIXu
Symposium on Operating Systems Design and Implementation ({OSDIU 16), pp. 265-283, 2016.
Martin Abadi, AShiSh Agarwal, PaUl Barham, Eugene Brevdo, Zhifeng Chen, Craig Citro, Greg S.
Corrado, Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Ian Goodfellow, Andrew
9
Under review as a conference paper at ICLR 2021
Harp, Geoffrey Irving, Michael Isard, Yangqing Jia, Rafal Jozefowicz, Lukasz Kaiser, Manjunath
Kudlur, Josh Levenberg, Dandelion Mane, Rajat Monga, Sherry Moore, Derek Murray, Chris
Olah, Mike Schuster, Jonathon Shlens, Benoit Steiner, Ilya Sutskever, Kunal Talwar, Paul Tucker,
Vincent Vanhoucke, Vijay Vasudevan, Fernanda Viegas, Oriol Vinyals, Pete Warden, Martin Wat-
tenberg, Martin Wicke, Yuan Yu, and Xiaoqiang Zheng. TensorFlow: Large-scale machine learn-
ing on heterogeneous systems, 2015. URL https://www.tensorflow.org/. Software
available from tensorflow.org.
Christopher M Bishop. Mixture density networks. 1994.
Charles Blundell, Julien Cornebise, Koray Kavukcuoglu, and Daan Wierstra. Weight uncertainty in
neural networks. arXiv preprint arXiv:1505.05424, 2015.
Axel Brando, Jose A Rodriguez-Serrano, Jordi Vitria, and Alberto Rubio Munoz. Modelling het-
erogeneous distributions with an uncountable mixture of asymmetric laplacians. In Advances in
Neural Information Processing Systems,pp. 8836-8846, 2019.
Tianqi Chen and Carlos Guestrin. Xgboost: A scalable tree boosting system. In Proceedings of the
22nd acm sigkdd international conference on knowledge discovery and data mining, pp. 785-794,
2016.
F. Chollet et al. Keras (2015), 2019.
C.	W. Clenshaw. A note on the summation of Chebyshev series. Math. Tables Aids Comput., 9:
118-120, 1955. ISSN 0891-6837.
Murray Cox. Inside airbnb: adding data to the debate. Inside Airbnb [Internet].[cited 16 May 2019].
Available: http://insideairbnb.com, 2019.
Ward Cunningham. The wycash portfolio management system. ACM SIGPLAN OOPS Messenger,
4(2):29-30, 1992.
W. Dabney, G. Ostrovski, D. Silver, and R. Munos. Implicit quantile networks for distributional re-
inforcement learning. In International Conference on Machine Learning, pp. 1104-1113, 2018a.
W. Dabney, M. Rowland, M. G. Bellemare, and R. Munos. Distributional reinforcement learning
with quantile regression. In Thirty-Second AAAI Conference on Artificial Intelligence, 2018b.
Germund Dahlquist and A ke Bjorck. Numerical methods in scientific computing. Vol. I. So-
ciety for Industrial and Applied Mathematics (SIAM), Philadelphia, PA, 2008. ISBN 978-
0-898716-44-3. doi: 10.1137/1.9780898717785. URL https://doi.org/10.1137/1.
9780898717785.
Armen Der Kiureghian and Ove Ditlevsen. Aleatory or epistemic? does it matter? Structural safety,
31(2):105-112, 2009.
Dheeru Dua and Casey Graff. UCI machine learning repository, 2017a. URL http://archive.
ics.uci.edu/ml.
Dheeru Dua and Casey Graff. UCI machine learning repository, 2017b. URL http://archive.
ics.uci.edu/ml.
D.	Elliott. Error analysis of an algorithm for summing certain finite series. J. Austral. Math. Soc., 8:
213-221, 1968. ISSN 0263-6115.
Yarin Gal and Zoubin Ghahramani. Dropout as a Bayesian approximation: Representing model
uncertainty in deep learning. arXiv:1506.02142, 2015.
Yarin Gal and Zoubin Ghahramani. Dropout as a bayesian approximation: Representing model
uncertainty in deep learning. In international conference on machine learning, pp. 1050-1059,
2016.
J. M. Hernandez-Lobato and R. Adams. Probabilistic backpropagation for scalable learning of
bayesian neural networks. In ICML, pp. 1861-1869, 2015a.
10
Under review as a conference paper at ICLR 2021
Jose MigUel Hemandez-Lobato and Ryan Adams. Probabilistic backpropagation for scalable learn-
ing of bayesian neural networks. In International Conference on Machine Learning, pp. 1861-
1869, 2015b.
Kurt Hornik, Maxwell Stinchcombe, and Halbert White. Multilayer feedforward networks are uni-
versal approximators. Neural networks, 2(5):359-366, 1989.
Alex Kendall and Yarin Gal. What uncertainties do we need in bayesian deep learning for computer
vision? In Advances in neural information processing systems, pp. 5574-5584, 2017.
Balaji Lakshminarayanan, Alexander Pritzel, and Charles Blundell. Simple and scalable predictive
uncertainty estimation using deep ensembles. In Advances in Neural Information Processing
Systems, pp. 6402-6413, 2017.
Andy Liaw, Matthew Wiener, et al. Classification and regression by randomforest. R news, 2(3):
18-22, 2002.
H. Majidian. On the decay rate of Chebyshev coefficients. Appl. Numer. Math., 113:44-53, 2017.
ISSN 0168-9274. doi: 10.1016/j.apnum.2016.11.004. URL https://doi.org/10.1016/
j.apnum.2016.11.004.
A. C. R. Newbery. Error analysis for polynomial evaluation. Math. Comp., 28:789-793, 1974. ISSN
0025-5718. doi: 10.2307/2005700. URL https://doi.org/10.2307/2005700.
Carl Edward Rasmussen. A practical monte carlo implementation of bayesian learning. In Advances
in Neural Information Processing Systems, pp. 598-604, 1996.
Cynthia Rudin. Stop explaining black box machine learning models for high stakes decisions and
use interpretable models instead. Nature Machine Intelligence, 1(5):206-215, 2019.
David Sculley, Gary Holt, Daniel Golovin, Eugene Davydov, Todd Phillips, Dietmar Ebner, Vinay
Chaudhary, Michael Young, Jean-Francois Crespo, and Dan Dennison. Hidden technical debt in
machine learning systems. In Advances in neural information processing systems, pp. 2503-2511,
2015.
N. Tagasovska and D. Lopez-Paz. Frequentist uncertainty estimates for deep learning. Bayesian
Deep Learning workshop NeurIPS, 2018.
Natasa Tagasovska and David Lopez-Paz. Single-model uncertainties for deep learning. In Advances
in Neural Information Processing Systems, pp. 6417-6428, 2019.
Mattias Teye, Hossein Azizpour, and Kevin Smith. Bayesian uncertainty estimation for batch nor-
malized deep networks. arXiv preprint arXiv:1802.06455, 2018.
L. N. Trefethen. Is Gauss quadrature better than Clenshaw-Curtis? SIAM Rev., 50(1):67-87,
2008. ISSN 0036-1445. doi: 10.1137/060659831. URL https://doi.org/10.1137/
060659831.
Berk Ustun and Cynthia Rudin. Supersparse linear integer models for optimized medical scoring
systems. Machine Learning, 102(3):349-391, 2016.
A. Wehenkel and G. Louppe. Unconstrained monotonic neural networks. In Advances in Neural
Information Processing Systems, 2019.
R. Wen, K. Torkkola, B. Narayanaswamy, and D. Madeka. A multi-horizon quantile recurrent
forecaster. arXiv preprint arXiv:1711.11053, 2017.
H. Zheng, Z. Yang, W. Liu, J Liang, and Y. Li. Improving deep neural networks using softplus units.
In 2015 International Joint Conference on Neural Networks (IJCNN), pp. 1-4. IEEE, 2015.
11