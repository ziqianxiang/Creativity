Under review as a conference paper at ICLR 2021
Pointwise Binary Classification with Pairwise
Confidence Comparisons
Anonymous authors
Paper under double-blind review
Ab stract
Ordinary (pointwise) binary classification aims to learn a binary classifier from
pointwise labeled data. However, such pointwise labels may not be directly ac-
cessible due to privacy, confidentiality, or security considerations. In this case,
can we still learn an accurate binary classifier? This paper proposes a novel set-
ting, namely pairwise comparison (Pcomp) classification, where we are given
only pairs of unlabeled data that we know one is more likely to be positive than the
other, instead of pointwise labeled data. Compared with pointwise labels, pairwise
comparisons are easier to collect, and Pcomp classification is useful for subjective
classification tasks. To solve this problem, we present a mathematical formula-
tion for the generation process of pairwise comparison data, based on which we
exploit an unbiased risk estimator (URE) to train a binary classifier by empirical
risk minimization and establish an estimation error bound. We first prove that a
URE can be derived and improve it using correction functions. Then, we start
from the noisy-label learning perspective to introduce a progressive URE and im-
prove it by imposing consistency regularization. Finally, experiments validate the
effectiveness of our proposed solutions for Pcomp classification.
1	Introduction
Traditional supervised learning techniques have achieved great advances, while they are demanding
for precisely labeled data. In many real-world scenarios, it may be too difficult to collect such data.
To alleviate this issue, a large number of weakly supervised learning problems (Zhou, 2018) have
been extensively studied, including semi-supervised learning (Zhu & Goldberg, 2009; Niu et al.,
2013; Sakai et al., 2018), multi-instance learning (Zhou et al., 2009; Sun et al., 2016; Zhang &
Zhou, 2017), noisy-label learning (Han et al., 2018; Xia et al., 2019; Wei et al., 2020), partial-label
learning (Zhang et al., 2017; Feng et al., 2020b; Lv et al., 2020), complementary-label learning
(Ishida et al., 2017; Yu et al., 2018; Ishida et al., 2019; Feng et al., 2020a), positive-unlabeled
classification (Gong et al., 2019), positive-confidence classification (Ishida et al., 2018), similar-
unlabeled classification (Bao et al., 2018), unlabeled-unlabeled classification (Lu et al., 2019; 2020),
and triplet classification (Cui et al., 2020).
This paper considers another novel weakly supervised learning setting called pairwise comparison
(Pcomp) classification, where we aim to perform pointwise binary classification with only pairwise
comparison data, instead of pointwise labeled data. A pairwise comparison (x, x0) represents that
the instance x has a larger confidence of belonging to the positive class than the instance x0 . Such
weak supervision (pairwise confidence comparison) could be much easier for people to collect than
full supervision (pointwise label) in practice, especially for applications on sensitive or private mat-
ters. For example, it may be difficult to collect sensitive or private data with pointwise labels, as
asking for the true labels could be prohibited or illegal. In this case, it could be easier for people to
collect other weak supervision like the comparison information between two examples.
It is also advantageous to consider pairwise confidence comparisons in pointwise binary classifica-
tion with class overlapping, where the labeling task becomes difficult, and even experienced labelers
may provide wrong pointwise labels. Let Us denote the labeling standard of a labeler as p(y |x) and
assume that an instance x1 is more positive than another instance x2 . Facing the difficult labeling
task, different labelers may hold different labeling standards, p(y = +1∣xι) > p(y = +I∣x2) >
1/2, p(y = +1∣xι) > 1/2 > p(y = +I∣x2), and 1/2 > p(y = +1∣xι) > p(y = +I∣x2), thereby
1
Under review as a conference paper at ICLR 2021
providing different pointwise labels: (+1, +1), (+1, -1), (-1, -1). We can find that different la-
belers may provide inconsistent pointwise labels, while pairwise confidence comparisons are unan-
imous and accurate. One may argue that we could aggregate multiple labels of the same instance
using crowdsourcing learning methods (Whitehill et al., 2009; Raykar et al., 2010). However, as
not every instance will be labeled by multiple labelers, it is not always applicable to crowdsourcing
learning methods. Therefore, our proposed Pcomp classification is useful in this case.
Our contributions in this paper can be summarized as follows:
•	We propose Pcomp classification, a novel weakly supervised learning setting, and present
a mathematical formulation for the generation process of pairwise comparison data.
•	We prove that an unbiased risk estimator (URE) can be derived, propose an empirical risk
minimization (ERM) based method, and present an improvement using correction functions
(Lu et al., 2020) for alleviating overftting when complex models are used.
•	We start from the noisy-label learning perspective to introduce the RankPruning method
(Northcutt et al., 2017) that holds a progressive URE for solving our proposed Pcomp
classification problem and improve it by imposing consistency regularization.
•	We experimentally demonstrate the effectiveness of our proposed solutions for Pcomp clas-
sification.
2	Preliminaries
Binary classification with pairwise comparisons and extra pointwise labels has been studied (Xu
et al., 2017; Kane et al., 2017). Our paper focuses on a more challenging problem where only pair-
wise comparison examples are provided. Unlike previous studies (Xu et al., 2017; Kane et al., 2017)
that leverage some pointwise labels to differentiate the labels of pairwise comparisons, our methods
are purely based on ERM with only pairwise comparisons. In the next, we briefly introduce some
notations and review the related problem formulations of binary classification, positive-unlabeled
classification, and unlabeled-unlabeled classification.
Binary Classification. Since our paper focuses on how to train a binary classifier from pairwise
comparison data, we first review the problem formulation of binary classification. Let the feature
space be X and the label space be Y = {+1, -1}. Suppose the collected dataset is denoted by
D = {(xi, yi)}in=1 where each example (xi, yi) is independently sampled from the joint distribution
with density p(x, y), which includes an instance xi ∈ X and a label yi ∈ Y. The goal of binary
classification is to train an optimal classifier f : X 7→ R by minimizing the following expected
classification risk:
R(f) = Ep(χ,y) ['(f (x), y)] = ∏+Ep+(x) ['(f (x), +1)] + ∏-Ep-(x) ['(f (x),-1)],	(1)
where ` : R × Y 7→ R+ denotes a binary loss function, π+ := p(y = +1) (or π- := p(y = -1))
denotes the positive (or negative) class prior probability, and p+ (x) := p(x|y = +1) (orp-(x) :=
p(x|y = -1)) denotes the class-conditional probability density of the positive (or negative) data.
ERM approximates the expectations over p+(x) and p- (x) by the empirical averages of positive
and negative data and the empirical risk is minimized with respect to the classifier f .
Positive-Unlabeled (PU) Classification. In some real-world scenarios, it may be difficult to col-
lect negative data, and only positive (P) and unlabeled (U) data are available. PU classification aims
to train an effective binary classifier in this weakly supervised setting. Previous studies (du Plessis
et al., 2014; 2015; Kiryo et al., 2017) showed that the classification risk R(f) in Eq. (1) can be
rewritten only in terms of positive and unlabeled data as
R(f ) = Rpu(f )= ∏+Ep+(x) ['(f (x), +1) - '(f (x),-1)] + Ep(X) ['(f (x),-1)],	(2)
where p(x) = π+p+ (x) + π-p- (x) denotes the probability density of unlabeled data. This risk
expression immediately allows us to employ ERM in terms of positive and unlabeled data.
Unlabeled-Unlabeled (UU) Classification. The recent studies (Lu et al., 2019; 2020) showed that
it is possible to train a binary classifier only from two unlabeled datasets with different class priors.
2
Under review as a conference paper at ICLR 2021
Lu et al. (2019) showed that the classification risk can be rewritten as
R(f) = Ruu(f) = Eptr(x) h(1 7 θ0)∏+ '(f (x), +1) - θ0(1 -∏∏+)'(f(x), -1)i
θ - θ	θ - θ
+ Eptr0(χ0) h θ(1-θ+1 '(f (x), -1) - ⅛4π+ '(f (x0), +1)i ,⑶
θ-θ	θ-θ
where θ and θ0 are different class priors of two unlabeled datasets, and ptr (x) and ptr0 (x0) are the
densities of two datasets of unlabeled data, respectively. This risk expression immediately allows
us to employ ERM only from two sets of unlabeled data. For RUU(f) in Eq. (3), if we set θ = 1,
θ0 = π+, and replace ptr(x) and ptr0 (x0) by p+ (x) and p(x) respectively, then we can recover
RPU(f) in Eq. (2). Therefore, UU classification could be taken as a generalized framework of
PU classification in terms of URE. Besides, Eq. (3) also recovers a complicated URE of similar-
unlabeled classification (Bao et al., 2018) by setting θ = π+ and θ0 = π+2 /(2π+2 - 2π+ + 1).
To solve our proposed Pcomp classification problem, we will present a mathematical formulation
for the generation process of pairwise comparison data, based on which we will explore two UREs
to train a binary classifier by ERM and establish the corresponding estimation error bounds.
3 Data Generation Process
In order to derive UREs for performing ERM, we first formulate the underlying generation process of
pairwise comparison data1, which consists of pairs of unlabeled data that we know which one is more
likely to be positive. Suppose the provided dataset is denoted by D = {(xi, x0i)}in=1 where (xi, x0i)
(with their unknown true labels (yi, yi0)) is expected to satisfy p(yi = +1|xi) > p(yi0 = +1|x0i).
It is clear that we could easily collect pairwise comparison data if the positive confidence (i.e.,
p(y = +1|x)) of each instance could be obtained. However, such information is much harder to
obtain than class labels in real-world scenarios. Therefore, unlike some studies (Ishida et al., 2018;
Shinoda et al., 2020) that assume the positive confidence of each instance is provided by the labeler,
we only assume that the labeler has access to the labels of training data. Specifically, we adopt the
assumption (Cui et al., 2020) that weakly supervised examples are first sampled from the true data
distribution, but the labels are only accessible to the labeler. Then, the labeler would provide us
weakly supervised information (i.e., pairwise comparison information) according to the labels of
sampled data pairs. That is, for any pair of unlabeled data (x, x0), the labeler would tell us whether
(x, x0 ) could be collected as a pairwise comparison for Pcomp classification, based on the labels
(y, y0) rather than the positive confidences (p(y = +1|x), p(y = +1|x0)).
Now, the question becomes: how does the labeler consider (x, x0) as a pairwise comparison for
Pcomp classification, in terms of the labels (y, y0)? As shown in our previous example of bi-
nary classification with class overlapping, we could infer that the labels (y, y0) of our required
pairwise comparison data (x, x0) for Pcomp classification can only be one of the three cases
{(+1, -1), (+1, +1), (-1, -1)}, because the condition p(y = +1|x) ≥ p(y0 = +1|x0) is defi-
nitely violated if (y, y0) = (-1, +1). Therefore, we assume that the labeler would take (x, x0) as
a pairwise comparison example in the dataset D, if the labels (y, y0) of (x, x0) belong to the above
three cases. It is also worth noting that for a pair of data (x, x0) with labels (y, y0) = (-1, +1), the
labeler would take (x0 , x) as a pairwise comparison example. Because by exchanging the positions
of (x, x0), (x0, x) would be associated with labels (+1, -1), which belong to the three cases. In
summary, we assume that pairwise comparison data are sampled from those pairs of data whose
labels belong to the three cases {(+1, -1), (+1, +1), (-1, -1)}. Based on the above described
generation process of pairwise comparison data, we have the following theorem.
Theorem 1.	According to the generation process of pairwise comparison data described above, let
pe(x, x0)
q(χ, χ0)
π+2 + π-2 + π+ π-
(4)
where q(x, x0) = π+2 p+(x)p+(x0) + π-2 p- (x)p-(x0) + π+π-p+(x)p- (x0). Then we have De
{(xi, xi)}n=ι i'.P(X, χ0).
1In contrast to Xu et al. (2019) and Xu et al. (2020) which utilized pairwise comparison data to solve the
regression problem, we focus on binary classification.
3
Under review as a conference paper at ICLR 2021
The proof is provided in Appendix A. Theorem 1 provides an explicit expression of the probability
density of pairwise comparison data.
Next, we would like to extract pointwise information from pairwise information, since our goal is to
perform pointwise binary classification. Let πe = π+2 + π-2 + π+π- = π+ + π-2 = π+2 + π- and we
denote the pointwise data collected from D = {(xi , x0i)}in=1 by breaking the pairwise comparison
relation as D+ = {xi}in=1 and D- = {x0i}in=1. Then we can obtain the following theorem.
Theorem 2.	Pointwise examples in D+ and D- are independently drawn from pe+(x) andpe-(x0),
where
π+	π-	0 π+	0	π-	0
p+(x) = π-+^+p+(x)+ π-+^+P-(X),	P-(X) = π++√-p+(x)+ π++^∑p-(x).
The proof is provided in Appendix B. Theorem 2 shows the relationships between the pointwise
densities and the class-conditional densities. Besides, it indicates that from pairwise comparison
data, we can essentially obtain examples that are independently drawn from Pe+(X) andPe-(X0).
4 The Proposed Methods
In this section, we explore two UREs to train a binary classifier by ERM from only pairwise com-
parison data with the above generation process.
4.1 Corrected Pcomp Classification
As shown in Eq. (1), the classification risk R(f) could be separately expressed as the expectations
overP+(X) andP-(X). Although we do not have access to the two class-conditional densities P+ (X)
andP-(X), we can represent them by our introduced pointwise densities Pe+(X) and Pe- (X).
Lemma 1. We can express P+(X) and P-(X) in terms of Pe+(X) and Pe+(X) as
p+(x) = ∏-(P+(χ) - ∏-P-(χ)), P-(X) = ∏-(P-(X) - ∏+P+(χ))∙
The proof is provided in Appendix C. As a result of Lemma 1, we can express the classification risk
R(f) using only pairwise comparison data sampled fromPe+(X) andPe-(X).
Theorem 3.	The classification risk R(f) can be equivalently expressed as
Rpc(f )= Ee+(χ) ['(f (x), +1) - ∏+'(f (x), -1)] + Ee-(χ0) ['(f (X0), -1) - n-`(f (x0), +1)].
(5)
The proof is provided in Appendix D. In this way, we could train a binary classifier by minimizing
the following empirical approximation of RPC (f):
Rpc(f) = n Xi=1 ('(f (Xi), +1) - ∏+'(f (Xi), -1) + '(f (xi), -1) - ∏-'(f (xi), +1)). (6)
Estimation Error Bound. Here, we establish an estimation error bound for the proposed URE.
Let F = {f : X 7→ R} be the model class, fPC = arg minf∈F RPC (f) be the empirical risk
+
minimizer, and f? = arg minf∈F R(f) be the true risk minimizer. Let Rn+(F) and Rn-(F) be the
Rademacher complexities (Bartlett & Mendelson, 2002) of F with sample size n over Pe+(X) and
Pe- (X) respectively.
Theorem 4.	Suppose the loss function ` is ρ-Lipschitz with respect to the first argument (0≤ρ≤
∞), and all functions in the model class F are bounded, i.e., there exists a positive constant Cb
such that kf k ≤ Cb for any f ∈ F. Let C' := suPz≤cb,t=±ι '(z, t). Thenfor any δ > 0, with
probability at least 1 - δ, we have
R(fbPC) - R(f?) ≤ (1+π+)4ρRen+(F)+(1+
π-
)4PR-(F) + 6C'
席.
4
Under review as a conference paper at ICLR 2021
The proof is provided in Appendix E. Theorem 4 shows that our proposed method is consistent, i.e.,
+
as n → ∞, R(fPC) → R(f?), since Rn+(F), Rn- (F) → 0 for all parametric models with a bounded
norm such as deep neural networks trained with weight decay (Golowich et al., 2017; Lu et al.,
2019). Besides, R+ (F) and Rn (F) can be normally bounded by CF/√n for a positive constant
CF. Hence, We can further see that the convergence rate is Op (1/ √n) where Op denotes the order
in probability. This order is the optimal parametric rate for ERM without additional assumptions
(Mendelson, 2008).
Relation to UU Classification. It is worth noting that the URE of UU classification RUU (f) is
quite general for binary classification with weak supervision. Hence we also would like to show
the relationships between our proposed estimator RPC(f) and RUU (f). We demonstrate by the
following corollary that under some conditions, RUU (f) is equivalent to RPC (f).
Corollary 1. By setting Ptr = P+(x), Ptr = p-(x), θ = ∏+∕(1 一 ∏+ + ∏+), and θ0 = ∏+ /(1 一
π+ + π+2 ), Eq. (3) is equivalent to Eq. (5), which means that RUU(f) is equivalent to RPC (f).
We omit the proof of Corollary 1 since it is straightforward to derive Eq. (5) from Eq. (3) by inserting
the required notations.
ɪɔ	∙	∙	« TΓ⅛ ∙ «	A 1	♦ T	,	1 /CCCC、 1∙	.1	....	6 /八	1 1
Empirical Risk Correction. As shown in Lu et al. (2020), directly minimizing RPC (f) would
suffer from overfitting when complex models are used due to the negative risk issue. More specifi-
cally, since negative terms are included in Eq. (6), the empirical risk can be negative even though the
original true risk can never be negative. To ease this problem, they wrapped the terms in RUU (f)
that cause a negative empirical risk by certain consistent correction functions such as the rectified
linear unit (ReLU) function g(z) = max(0, z) and absolute value function g(z) = |z|. This solution
could also be applied to RbPC . In this way, we could obtain the following corrected empirical risk
estimator:
RcPC(J) = g(： Xn=1 ('(f (Xi), +1) - π-'f (Xi), +1)))
+ g(1 Xi=1 ('(f (xi), -1) - ∏+'(f (Xi), -1))) . (7)
4.2 Progressive Pcomp Classification
Here, we start from the noisy-label learning perspective to solve the Pcomp classification prob-
lem. Intuitively, we could simply perform binary classification by regarding the data from pe+(X)
as (noisy) positive data and the data from pe-(X) as (noisy) negative data. However, this naive
solution could be inevitably affected by noisy labels. In this scenario, we denote the noise rates
as ρ- = p(ye = +1|y = -1) and ρ+ = p(ye = -1|y = +1), where ye is the observed (noisy)
label and y is the true label, and the inverse noise rates as φ+ = p(y = -1|ye = +1) and
φ- = p(y = +1|ye = -1). According to the defined generation process of pairwise comparison
data, we have the following theorem.
Theorem 5.	The following equalities hold:
φ =	π-	φ =	π+
+	∏+ + ∏- + ∏+∏-，	-	∏+ + ∏- + ∏+∏-，
π+	π-
P+	2(∏+ + π- + ∏+∏-)， P-	2(∏+ + π- + ∏+∏-).
The proof is provided in Appendix F.
Theorem 5 shows that the noise rates can be obtained if we regard the Pcomp classification problem
as the noisy-label learning problem. With known noise rates for noisy-label learning, it was shown
(Natarajan et al., 2013; Northcutt et al., 2017) that a URE could be derived. Here, we adopt the
RankPruning method (Northcutt et al., 2017) because it holds a progressive URE by selecting confi-
dent examples using the learning model and achieves state-of-the-art performance. Specifically, we
denote by the dataset composed of all the observed positive data P, i.e., P = {Xi}in=1, where Xi
is independently sampled from pe+(X). Similarly, the dataset composed of all the observed negative
data is denoted by N, i.e., N = {X0i}in=1, where X0i is independently sampled from pe-(X0). Then,
5
Under review as a conference paper at ICLR 2021
confident examples will be selected from P andN by ranking the outputs of the model f. We denote
.1	1 , 1	∙ , ∙ F , C	/T~ζ /T-ζ	1 ,1	1 , 1	, •	1 , Γ∙	Tr Tr
the selected positive data from P as Psel, and the selected negative data from N as Nsel :
Pesel =	arg max	P Pe f(x), Nesel = arg min	N Ne f(x).
p：|P|=(i-0+)|P|	x∈{P∩P}	m∣n∣=(i-Φ-)∣N∣ x∈{N∩N}
Then we show that if the model f satisfies the separability condition, i.e., for any true positive
instance xp and for any true negative instance xn, we have f (xp) > f (xn). In other words, the
model output of every true positive instance is always larger than that of every true negative instance,
we could obtain a URE. We name it progressive URE, as the model f is progressively optimized.
Theorem 6 (Theorem 5 in Northcutt et al. (2017)). Assume that the model f satisfies the above
separability condition, then the classification risk R(f) can be equivalently expressed as
RpPc(f) = Epe+(X) h '[(X)P+1) I[x ∈ Psel]] + Ee-(χ0)[队 f [1) I[x0 ∈ NeSel]],
where I[∙] is the indicator function.
In this way, we have the following empirical approximation of RpPC :
1n
R"f ) = n O
「I[Xi ∈Psel] + ∖I[xi ∈NU).
(8)
Estimation Error Bound. It worth noting that Northcutt et al. (2017) did not prove the learn-
ing consistency for the RankPruning method. Here, we establish an estimation error bound for
this method, which guarantees the learning consistency. Let fpPC = arg minf ∈F RpPC (f) be the
empirical risk minimizer of the RankPruning method, then we have the following theorem.
Theorem 7. Suppose the loss function ` is ρ-Lipschitz with respect to the first argument (0≤ρ≤
∞), and all functions in the model class F are bounded, i.e., there exists a positive constant Cb
such that kf k ≤ Cb for any f ∈ F. Let C' := supz≤cb t=±ι '(z,t). Thenfor any δ > 0, with
probability at least 1 - δ, we have
R b R R f*∖ V 2	(2CR +(F	ClJlog 4 ∖ ,	2	(2CR-/F ClJlog 4
RfpPC)- R(f ) ≤ τ-ρ+ (2PRn (F) + CeN F + + KP- (2PRn (F) + CeN F
The proof is provided in Appendix G. Theorem 7 shows that the above method is consistent and this
estimation error bound also attains the optimal convergence rate without any additional assumption
(Mendelson, 2008), as analyzed in Theorem 4.
Regularization. For the above RankPruning method, its URE is based on the assumption that the
learning model could satisfy the separability condition. Thus, its performance heavily depends on
the accuracy of the learning model. However, as the learning model is progressively updated, some
of the selected confident examples may still contain label noise during the training process. As a
result, the RankPruning method would be affected by incorrectly selected data. A straightforward
improvement could be to improve the output quality of the learning model. Motivated by Mean
Teacher used in semi-supervised learning (Tarvainen & Valpola, 2017), we also resort to a teacher
model that is an exponential moving average of model snapshots, i.e., Θ0t = αΘ0t-1 + (1 - α)Θt,
where Θ0 denotes the parameters of the teacher model, Θ denotes the parameters of the learning
model, the subscript t denotes the training step, and α is a smoothing coefficient hyper-parameter.
Such a teacher model could guide the learning model to produce high-quality outputs. To learn from
the teacher model, we leverage consistency regularization Ω(f) = Ex [kfθ(x) - fθ' (x)k2] (Laine
& Aila, 2016; Tarvainen & Valpola, 2017) to make the learning model consistent with the teacher
model for improving the RankPruning method.
5	Experiments
In this section, we conduct experiments to evaluate the practical performance of our proposed meth-
ods on various datasets.
6
Under review as a conference paper at ICLR 2021
Table 1: Classification accuracy (mean±std) in percentage of each method on the four benchmark
datasets with different class priors. The best performance is highlighted in bold.
Class Prior ∣ Methods ∣ MNIST ∣ KUZUShiji ∣ Fashion ∣ CIFAR-10
π+ = 0.2	Noisy-Unbiased Binary-Biased RankPrUning Pcomp-ABS Pcomp-ReLU Pcomp-Unbiased Pcomp-Teacher	86.52±3.48 27.80±2.38 93.58±0.49 89.83±1.49 93.39±0.71 80.52±4.73 94.08±0.56	64.47±9.88 58.54±1.13 81.58±1.23 84.66±0.56 83.76±0.99 60.06±9.28 83.82±0.48	91.98±0.35 43.27±9.25 94.36±0.54 91.29±1.69 94.07±0.49 89.74±2.27 94.38±0.53	80.00±0.00 49.87±4.38 84.02±0.51 82.56±0.75 81.16±0.67 64.49 ±2.08 84.42±0.76
π+ = 0.5	Noisy-Unbiased Binary-Biased RankPruning Pcomp-ABS Pcomp-ReLU Pcomp-Unbiased Pcomp-Teacher	86.10±3.26 54.10±2.42 89.64±0.21 85.90±0.30 87.81±1.08 85.37±4.08 89.85±0.40	65.41±3.48 60.75±0.54 78.41±0.72 74.29±1.42 73.88±0.72 64.84±4.61 78.95±0.66	89.74±2.31 45.76±1.81 92.72±0.34 92.18±0.90 92.13±1.33 91.02±0.94 92.55±0.40	62.40±2.08 48.36±3.13 81.23±0.71 70.71 ±0.90 74.51 ±2.26 62.50±1.78 80.21 ±2.36
π+ = 0.8	Noisy-Unbiased Binary-Biased RankPruning Pcomp-ABS Pcomp-ReLU Pcomp-Unbiased Pcomp-Teacher	85.73±3.63 27.12±2.80 93.86±0.72 88.06±1.60 93.63±1.03 80.49±4.03 94.96±0.38	76.60±4.06 55.72±1.50 82.25±2.32 82.96±0.54 83.17±1.38 67.30±3.57 84.22±1.21	88.96±0.57 46.74±2.19 94.60±0.24 91.69±1.67 93.31±1.34 80.02±4.82 94.63±0.43	72.73±6.92 38.59±9.98 84.34±1.30 82.87 ±0.59 81.40±0.59 66.48±9.61 84.86±0.15
Datasets. We use four popular benchmark datasets, including MNIST (LeCun et al., 1998),
Fashion-MNIST (Xiao et al., 2017), KUZUshiji-MNIST (ClanUwat et al., 2018), and CIFAR-
10 (KriZhevsky et al., 2009). We train a mUltilayer perceptron (MLP) model with three hidden
layers of width 300 and ReLU activation fUnctions (Nair & Hinton, 2010) and batch normaliZation
(Ioffe & SZegedy, 2015) on the first three datasets. We train ResNet-34 (He et al., 2016) on the
CIFAR-10 dataset. We also Use USPS and three datasets from the UCI machine learning repository
(Blake & MerZ, 1998) inclUding Pendigits, Optdigits, and CNAE-9. We train a linear model on these
datasets, since they are not large-scale datasets. The detailed descriptions of all Used datasets with
the corresponding models are provided in Appendix H. Since these datasets are specially Used for
mUlti-class classification, we manUally transformed them into binary classification datasets (please
see Appendix H for details). As we have shown in Theorem 2, the pairwise comparison examples
can be eqUivalently transformed into pointwise examples, which are more convenient to generate.
Therefore, we generate pointwise examples in experiments. Specifically, as Theorem 5 discloses the
noise rates in oUr defined data generation process, we simply generate pointwise corrUpted examples
according to the noise rates.
Methods. For oUr proposed Pcomp classification problem, we propose the following methods:
Pcomp-Unbiased, which denotes the proposed method that minimiZes RPC(f) in Eq. (6); Pcomp-
ReLU, which denotes the proposed method that minimiZes RcPC (f) in Eq. (7) with the ReLU
fUnction; Pcomp-ABS, which denotes the proposed method that minimiZes RcPC(f) in Eq. (7) with
the absolUte valUe fUnction; Pcomp-Teacher, which improves the RankPrUning method by imposing
consistency regUlariZation to make the learning model consistent with a teacher model. Besides,
we compare with the following baselines: Binary-Biased, which condUcts binary classification by
regarding the data from pe+(x) as positive data and the data from pe- (x) as negative data. This
is a straightforward method to handle the Pcomp classification problem. In oUr setting, Binary-
Biased redUces to the BER minimiZation method (Menon et al., 2015); Noisy-Unbiased, which is
a noisy-label learning method that minimiZes the empirical approximation of the URE proposed by
Natarajan et al. (2013); RankPruning, which is a noisy-label learning method (NorthcUtt et al.,
2017) that minimiZes RpPC (f) in Eq. (8). For all learning methods, we take the logistic loss as
the binary loss fUnction ` (i.e., `(z) = ln(1 + exp(-z))), for fair comparisons. We implement oUr
methods Using PyTorch (PasZke et al., 2019) and Use the Adam (Kingma & Ba, 2015) optimiZation
method with mini-batch siZe set to 256 and the nUmber of training epochs set to 100. All the
experiments are condUcted on GeForce GTX 1080 Ti GPUs.
7
Under review as a conference paper at ICLR 2021
Table 2: Classification accuracy (mean±std) in percentage of each method on the four UCI datasets
with different class priors. The best performance is highlighted in bold.
Class Prior ∣ Methods ∣ USPS ∣ Pendigits ∣ Optdigits ∣	CNAE-9
π+ = 0.2	Noisy-Unbiased Binary-Biased RankPruning Pcomp-ABS Pcomp-ReLU Pcomp-Unbiased Pcomp-Teacher	88.43±2.96 79.37±1.86 91.93±0.83 90.94±0.83 91.90±0.60 91.88±0.75 93.18±0.57	83.35±0.57 65.24±5.48 78.43±5.85 86.14±0.72 86.35±0.80 85.89±1.50 86.36±2.33	84.63±1.77 65.23±3.48 83.61±1.89 85.98±1.82 87.55±1.35 86.79±1.52 85.81±1.54	83.73±1.46 63.48±1.87 76.03±5.07 82.40 ±1.42 82.97±1.26 84.13±1.73 80.44±4.33
π+ = 0.5	Noisy-Unbiased Binary-Biased RankPruning Pcomp-ABS Pcomp-ReLU Pcomp-Unbiased Pcomp-Teacher	87.57±2.02 90.78±0.44 92.28±0.26 89.81±1.29 91.10±0.73 90.77±0.87 92.53±0.30	83.47±2.62 79.60±5.46 80.19±2.47 83.32±2.38 84.26±2.37 84.52±2.49 82.10±2.26	85.13±1.38 81.84±3.98 82.77±1.77 83.61±1.78 84.43±1.52 85.43±1.79 84.54±1.90	76.77 ±0.95 74.34±1.41 70.65±2.92 76.32±1.38 76.58±1.17 77.12±1.24 74.89±3.60
π+ = 0.8	Noisy-Unbiased Binary-Biased RankPruning Pcomp-ABS Pcomp-ReLU Pcomp-Unbiased Pcomp-Teacher	88.49±2.14 72.94±1.36 89.02±8.69 90.96±0.84 92.09±1.53 91.28±1.39 93.05±0.70	85.62±1.29 63.63±4.36 84.94±1.33 89.20±2.70 89.59±2.57 89.13±2.42 87.64±1.70	87.05±1.24 68.83±2.70 87.24±0.87 88.93±1.12 89.13±0.67 88.25±1.26 89.30±1.41	83.78±1.42 60.45±0.95 83.33±4.79 82.72±1.76 83.97±1.05 85.50±1.62 83.62±3.62
Experimental Setup. We test the performance of all learning methods under different class prior
settings, i.e., π+ is selected from {0.2, 0.5, 0.8}. It is worth noting that we could estimate π+
according to our described data generation process. Specifically, we can exactly estimate πe by
counting the fraction of collected pairwise comparison data in all the sampled pairs of data. Since
πe = π+2 + π- = π+2 + 1 - π+ , we have ∏+ = 1/2 - √ee - 3/4 (if ∏+ < π-) or ∏+ = 1/2 +
，彳-3/4 (if ∏+ ≥ ∏-). Therefore, if We know whether ∏+ is larger than ∏-, We could exactly
estimate the true class prior π+. For simplicity, we assume that the class prior π+ is known for all
the methods. We repeat the sampling-and-training process 5 times for all learning methods on all
datasets and record the mean accuracy with standard deviation (mean±std).
Experimental Results with Complex Models. Table 1 records the classification performance of
each method on the four benchmark datasets with different class priors. From Table 1, we have the
following observations: 1) Binary-Biased always achieves the worst performance, which indicates
that simply conducting binary classification cannot well solve our Pcomp classification problem;
2) Pcomp-Unbiased is is inferior to Pcomp-ABS and Pcomp-ReLU. This observation accords with
what we have discussed, i.e., directly minimizing RPC(f) would suffer from overfitting when com-
plex models are used because there are negative terms included in RPC (f) and the empirical risk
can be negative during the training process. In contrast, Pcomp-ReLU and Pcomp-ABS employ con-
sistent correction functions on RPC(f) so that the empirical risk will never be negative. Therefore,
when complex models such as deep neural networks are used, Pcomp-ReLU and Pcomp-ABS are
expected to outperform Pcomp-Unbiased; 3) Pcomp-Teacher achieves the best performance in most
cases. This observation verifies the effectiveness of the imposed consistency regularization, which
makes the learning model consistent with a teacher model, for improving the quality of selected
confident examples by the RankPruning method; 4) It is worth noting that the standard deviations
of Binary-Biased, Pcomp-Unbiased, and Noisy-Unbiased are sometimes higher than other meth-
ods. This is because the three methods suffer from overfitting when complex models are used, and
the performance could be quite unstable in different trials. In addition, Noisy-Unbiased holds the
accuracy of 80.00±0.00% on CIFAR-10 with class prior 0.2. This extreme case happens because
Noisy-Unbiased always simply classifies all examples into the negative class due to the serious
overfitting issue on a complex class-imbalanced dataset with a complex model ResNet-34.
Experimental Results with Simple Models. Table 2 reports the classification performance of
each method on the four UCI datasets with different class priors. From Table 2, we have the follow-
8
Under review as a conference paper at ICLR 2021
ing observations: 1) Binary-Biased achieves the worst performance in nearly all cases; 2) Pcomp-
Unbiased is slightly better than Pcomp-ReLU and Pcomp-ABS, because Pcomp-Unbiased does not
suffer from overfitting when the linear model is used, and it is not necessary to use consistent cor-
rection functions anymore. Besides, Pcomp-Unbiased becomes comparable to Pcomp-Teacher and
achieves the best performance in half of the cases; 3) Pcomp-Teacher is still better than RankPrun-
ing, while it is sometimes inferior to Pcomp-Unbiased. This is because the linear model is not as
powerful as neural networks, and the selected confident examples may not be so reliable.
6	Conclusion
In this paper, we proposed a novel weakly supervised learning setting called pairwise comparison
(Pcomp) classification, where we aim to train a binary classifier from only pairwise comparison
data, i.e., two examples that we know one is more likely to be positive than the other, instead of
pointwise labeled data. Pcomp classification is useful for private classification tasks where we are
not allowed to directly access labels and subjective classification tasks where labelers have different
labeling standards. To solve the Pcomp classification problem, we presented a mathematical for-
mulation for the generation process of pairwise comparison data, based on which we explored two
unbiased risk estimators (UREs) to train a binary classifier by empirical risk minimization and es-
tablished the corresponding estimation error bounds. We first proved that a URE can be derived and
improved it using correction functions. Then, we started from the noisy-label learning perspective
to introduce a progressive URE and improved it by imposing consistency regularization. Finally,
experiments demonstrated the effectiveness of our proposed methods.
In future work, we will apply Pcomp classification to solve some challenging real-world problems
like binary classification with class overlapping. In addition, we could also extend Pcomp classi-
fication to the multi-class classification setting by using the one-versus-all strategy. Suppose there
are multiple classes, we are given pairs of unlabeled data that we know which one is more likely to
belong to a specific class. Then, we can use the proposed methods in this paper to train a binary
classifier for each class. Finally, by comparing the outputs of these binary classifiers, the predicted
class can be determined.
References
Han Bao, Gang Niu, and Masashi Sugiyama. Classification from pairwise similarity and unlabeled
data. In ICML,pp. 452-461, 2018.
Peter L Bartlett and Shahar Mendelson. Rademacher and gaussian complexities: Risk bounds and
structural results. JMLR, 3(11):463-482, 2002.
Catherine L Blake and Christopher J Merz. Uci repository of machine learning databases, 1998.
URL http://archive.ics.uci.edu/ml/index.php.
Tarin Clanuwat, Mikel Bober-Irizar, Asanobu Kitamoto, Alex Lamb, Kazuaki Yamamoto, and David
Ha. Deep learning for classical Japanese literature. arXiv preprint arXiv:1812.01718, 2018.
Zheng-Hang Cui, Nontawat Charoenphakdee, Issei Sato, and Masashi Sugiyama. Classification
from triplet comparison data. Neural Computation, 32(3):659-681, 2020.
Marthinus C. du Plessis, Gang Niu, and Masashi Sugiyama. Analysis of learning from positive and
unlabeled data. In NeurIPS, pp. 703-711, 2014.
Marthinus C. du Plessis, Gang Niu, and Masashi Sugiyama. Convex formulation for learning from
positive and unlabeled data. In ICML, pp. 1386-1394, 2015.
Lei Feng, Takuo Kaneko, Bo Han, Gang Niu, Bo An, and Masashi Sugiyama. Learning with multiple
complementary labels. In ICML, pp. in press, 2020a.
Lei Feng, Jia-Qi Lv, Bo Han, Miao Xu, Gang Niu, Xin Geng, Bo An, and Masashi Sugiyama.
Provably consistent partial-label learning. In NeurIPS, 2020b.
Noah Golowich, Alexander Rakhlin, and Ohad Shamir. Size-independent sample complexity of
neural networks. arXiv preprint arXiv:1712.06541, 2017.
9
Under review as a conference paper at ICLR 2021
Chen Gong, Hong Shi, Tong-Liang Liu, Chuang Zhang, Jian Yang, and Da-Cheng Tao. Loss de-
composition and centroid estimation for positive and unlabeled learning. TPAMI, 2019.
Bo Han, Quan-Ming Yao, Xing-Rui Yu, Gang Niu, Miao Xu, Wei-Hua Hu, Ivor Tsang, and Masashi
Sugiyama. Co-teaching: Robust training of deep neural networks with extremely noisy labels. In
NeurIPS, pp. 8527-8537, 2018.
Kai-Ming He, Xiang-Yu Zhang, Shao-Qing Ren, and Jian Sun. Deep residual learning for image
recognition. In CVPR, pp. 770-778, 2016.
Sergey Ioffe and Christian Szegedy. Batch normalization: Accelerating deep network training by
reducing internal covariate shift. arXiv preprint arXiv:1502.03167, 2015.
Takashi Ishida, Gang Niu, Weihua Hu, and Masashi Sugiyama. Learning from complementary
labels. In NeurIPS, pp. 5644-5654, 2017.
Takashi Ishida, Gang Niu, and Masashi Sugiyama. Binary classification for positive-confidence
data. In NeurIPS, pp. 5917-5928, 2018.
Takashi Ishida, Gang Niu, Aditya Krishna Menon, and Masashi Sugiyama. Complementary-label
learning for arbitrary losses and models. In ICML, pp. 2971-2980, 2019.
Daniel M Kane, Shachar Lovett, Shay Moran, and Jiapeng Zhang. Active classification with com-
parison queries. In FOCS, pp. 355-366. IEEE, 2017.
Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In ICLR, 2015.
Ryuichi Kiryo, Gang Niu, Marthinus C. du Plessis, and Masashi Sugiyama. Positive-unlabeled
learning with non-negative risk estimator. In NeurIPS, pp. 1674-1684, 2017.
Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images.
Technical report, Citeseer, 2009.
Samuli Laine and Timo Aila. Temporal ensembling for semi-supervised learning. arXiv preprint
arXiv:1610.02242, 2016.
Yann LeCun, Leon Bottou, Yoshua Bengio, Patrick Haffner, et al. Gradient-based learning applied
to document recognition. Proceedings of the IEEE, 86(11):2278-2324, 1998.
Nan Lu, Gang Niu, Aditya K. Menon, and Masashi Sugiyama. On the minimal supervision for
training any binary classifier from only unlabeled data. In ICLR, 2019.
Nan Lu, Tian-Yi Zhang, Gang Niu, and Masashi Sugiyama. Mitigating overfitting in supervised
classification from two unlabeled datasets: A consistent risk correction approach. In AISTATS,
2020.
Jia-Qi Lv, Miao Xu, Lei Feng, Gang Niu, Xin Geng, and Masashi Sugiyama. Progressive identifi-
cation of true labels for partial-label learning. In ICML, 2020.
Shahar Mendelson. Lower bounds for the empirical minimization algorithm. TIT, 54(8):3797-3803,
2008.
Aditya Menon, Brendan Van Rooyen, Cheng Soon Ong, and Bob Williamson. Learning from cor-
rupted binary labels via class-probability estimation. In ICML, pp. 125-134, 2015.
Mehryar Mohri, Afshin Rostamizadeh, and Ameet Talwalkar. Foundations of Machine Learning.
MIT Press, 2012.
Vinod Nair and Geoffrey E Hinton. Rectified linear units improve restricted boltzmann machines.
In ICML, 2010.
Nagarajan Natarajan, Inderjit S Dhillon, Pradeep K Ravikumar, and Ambuj Tewari. Learning with
noisy labels. In NeurIPS, pp. 1196-1204, 2013.
10
Under review as a conference paper at ICLR 2021
Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, and Andrew Y Ng. Read-
ing digits in natural images with unsupervised feature learning. In NeurIPS Workshop on Deep
Learning and Unsupervised Feature Learning, 2011.
Gang Niu, Wittawat Jitkrittum, Bo Dai, Hirotaka Hachiya, and Masashi Sugiyama. Squared-loss
mutual information regularization: A novel information-theoretic approach to semi-supervised
learning. In ICML,pp.10-18, 2013.
Curtis G Northcutt, Tailin Wu, and Isaac L Chuang. Learning with confident examples: Rank
pruning for robust classification with noisy labels. In UAI, 2017.
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor
Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al. Pytorch: An imperative style, high-
performance deep learning library. In NeurIPS, pp. 8026-8037, 2019.
Vikas C Raykar, Shipeng Yu, Linda H Zhao, Gerardo Hermosillo Valadez, Charles Florin, Luca
Bogoni, and Linda Moy. Learning from crowds. JMLR, 11(4), 2010.
Tomoya Sakai, Gang Niu, and Masashi Sugiyama. Semi-supervised auc optimization based on
positive-unlabeled learning. MLJ, 107(4):767-794, 2018.
Kazuhiko Shinoda, Hirotaka Kaji, and Masashi Sugiyama. Binary classification from positive data
with skewed confidence. In IJCAI, pp. 3328-3334, 2020.
Miao Sun, Tony X Han, Ming-Chang Liu, and Ahmad Khodayari-Rostamabad. Multiple instance
learning convolutional neural networks for object recognition. In ICPR, pp. 3270-3275, 2016.
Antti Tarvainen and Harri Valpola. Mean teachers are better role models: Weight-averaged consis-
tency targets improve semi-supervised deep learning results. In NeurIPS, pp. 1195-1204, 2017.
Hong-Xin Wei, Lei Feng, Xiang-Yu Chen, and Bo An. Combating noisy labels by agreement: A
joint training method with co-regularization. In CVPR, pp. 13726-13735, 2020.
Jacob Whitehill, Ting-fan Wu, Jacob Bergsma, Javier R Movellan, and Paul L Ruvolo. Whose vote
should count more: Optimal integration of labels from labelers of unknown expertise. In NeurIPS,
pp. 2035-2043, 2009.
Xiao-Bo Xia, Tong-Liang Liu, Nan-Nan Wang, Bo Han, Chen Gong, Gang Niu, and Masashi
Sugiyama. Are anchor points really indispensable in label-noise learning? In NeurIPS, pp.
6835-6846, 2019.
Han Xiao, Kashif Rasul, and Roland Vollgraf. Fashion-mnist: A novel image dataset for bench-
marking machine learning algorithms. arXiv preprint arXiv:1708.07747, 2017.
Li-Yuan Xu, Junya Honda, Gang Niu, and Masashi Sugiyama. Uncoupled regression from pairwise
comparison data. In NeurIPS, pp. 3992-4002, 2019.
Yichong Xu, Hongyang Zhang, Kyle Miller, Aarti Singh, and Artur Dubrawski. Noise-tolerant
interactive learning using pairwise comparisons. In NeurIPS, pp. 2431-2440, 2017.
Yichong Xu, Sivaraman Balakrishnan, Aarti Singh, and Artur Dubrawski. Regression with com-
parisons: Escaping the curse of dimensionality with ordinal information. JMLR, 21(162):1-54,
2020.
Xi-Yu Yu, Tong-Liang Liu, Ming-Ming Gong, and Da-Cheng Tao. Learning with biased comple-
mentary labels. In ECCV, pp. 68-83, 2018.
Min-Ling Zhang, Fei Yu, and Cai-Zhi Tang. Disambiguation-free partial label learning. TKDE, 29
(10):2155-2167, 2017.
Ya-Lin Zhang and Zhi-Hua Zhou. Multi-instance learning with key instance shift. In IJCAI, pp.
3441-3447, 2017.
Zhi-Hua Zhou. A brief introduction to weakly supervised learning. National Science Review, 5(1):
44-53, 2018.
11
Under review as a conference paper at ICLR 2021
Zhi-Hua Zhou, Yu-Yin Sun, and Yu-Feng Li. Multi-instance learning by treating instances as non-iid
samples. InICML,pp.1249-1256, 2009.
Xiao-Jin Zhu and Andrew B Goldberg. Introduction to semi-supervised learning. Synthesis Lectures
on Artificial Intelligence and Machine Learning, 3(1):1-130, 2009.
12
Under review as a conference paper at ICLR 2021
A Proof of Theorem 1
It is clear that each pair of examples (x, x0) is independently drawn from the following data distri-
bution:
p(x, x0) =p((x, x0) | (y,y0) ∈ Y) = P殷吗? 丁］"，
p((y, y0) ∈ Y)
where p((y, y0) ∈ Y ) = π+2 + π-2 + π+π- and
p(x, χ0, (y,y0) ∈Ye) = £(y y0)∈γp(x, χ0 | (y,y0)) ∙ p(y,y0)
= π+2p+(x)p+(x0) + π-2 p-(x)p-(x0) + π+π-p+(x)p-(x0).
Finally, let p(x, x0) = p((x, x0) | (y, y0) ∈ Ye), the proof is completed.	口
B Proof of Theorem 2
In order to decompose the pairwise comparison data distribution into pointwise distribution, we
marginalize pe(x, x0) with respect to x or x0. Then we can obtain
pe(x, x0)dx0 = ∏e (∏+p+(χ) + π-p-(x) + ∏+∏-P+
2
=π⅛+p+(x) + 忑—P-(X)
=pe+(x),
and
∕e(x, x0)dx = 1 (∏+p+(x0) + π-p-(x0) + ∏+∏-p-(x0))
=E p+(χ0)+
=pe-(x0),
π-
p-(x0)
which concludes the proof of Theorem 2.
□
C Proof of Lemma 1
Based on Theorem 2, we can obtain the following linear equation:
pe+(x)
pe-(x)
π+
π-2 p+ (x)
π- p- (x)
1
~
π
By solving the above equation, we obtain
p+(x)
p-(x)
开十-1π	π2 (ee ∙	p+(x) -	π-ee ∙	P-(X)) =	∏1- (p+(x) -	∏-P-(x)),
π- -1∏+π- (ee ∙ P-(X)- π+ee ∙ p+(x)) = ∏: (P-(X)- π+p+(x)),
which concludes the proof of Lemma 1.
□
13
Under review as a conference paper at ICLR 2021
D Proof of Theorem 3
It is quite intuitive to derive
R(f ) = Ep(χ,y) Kf(X),y)]
=π+Ep+(x) ['(/(x), +1)] + π-Ep-(x)['(/(x), -1)]
nɪe	nɪn-e
=π. - π π2 Ee+(χ)['(f(x), +1)] - π. - π π2 Ee-(χ0)['(f(x), +1)]	(Lemma 1)
π π	π I π π
+---------T Ee.(χ0) ['(f (χ), -1)]——+T Ee+(χ) [,(f (χ), -1)]
π— — ∏+∏-	π— — ∏+∏-
=Ee+(x) [,(f(x), +1) - π+'(f(x), -1)] + Ee.(χ0) ['(f(x), -1) - π-'(f (x), +1)]
=Rpc(f),
which concludes the proof of Theorem 3.	□
E	Proof of Theorem 4
First of all, we introduce the following notations:
R+c(f) = Ee+(x) [,(f (χ), +1) - ∏+4(f (χ), -1)],
n
R+c(f) = - X ('(f(χi),+1) -∏+'(f(χi),-1)),
i=1
RPc(f) = Ee.(x，) ['(f (X0), -1) - π-4(f (x0), +1)],
n
RPC(f) = - X ('(f(xi), -1) - π-'(f(xi), +1)).
i=1
In this way, we could simply represent Rpc(f) and RPC(f) as
Rpc(f ) = R+c(f) + RPc(f), Rpc(f ) = Rpc(f) + RPc(f).
Then we have the following lemma.
Lemma 2. Thefollowing inequality holds:
R(fpc) - R(f*) ≤ 2 sup I R+c(f) - R+c(f) I + 2 sup ∣Rp°(f) - R-°(f) ∣.	(9)
f∈F	f∈Fl	1
τ-> 八 5T	1 1 ∙	,	∙ , ∙	1	C /力 ∖	τ~> /
Proof. We could intuitively express R(fpc) - R(f ?) as
.^ ,. . ^ ^ . ^ ^ , ^ ^ ,. ^ .. ,.
R(fpc) - R(f ) = R(fpc) - RPC(fpc) + RPC(fpc) - RPC(f ) + RPC(f ) - R(f )
=Rp°(fpC) - Rp°(fpC) + RpC(fp°) - Rp°(f ) + Rpo(f ) - RpC(f )
≤ sup I RpC(f) - RpC(f )1 +0+sup I RpC(f) - Rpo(f) ∣
f∈F	f∈Fl	1
= 2sup I RpC(f) - RpC(f) I
f ∈Fl	1
≤ 2 sup I R÷C(f) - R1Uf )1 + 2 sup I RPC (f) - R—),
f ∈F	f∈Fl	1
where the second inequality holds due to Theorem 3.	□
As suggested by Lemma 2, we need to further upper bound the right hand size of Eq. (9). Before
doing that, we introduce the uniform deviation bound, which is useful to derive estimation error
bounds. The proof can be found in some textbooks such as Mohri et al. (2012) (Theorem 3.1).
14
Under review as a conference paper at ICLR 2021
Lemma 3. Let Z be a random variable drawn from a probability distribution with density μ, H =
{h : Z 7→ [0, M]} (M > 0) be a class of measurable functions, {zi }in=1 be i.i.d. examples drawn
from the distribution with density μ. Then, for any delta > 0, with probability at least 1 一 δ,
SuP EZ〜μ [h(Z)]
h∈H
1n
一 n Xh(Zi)
i=1
≤ 2Rn(H) +M
*
where Rn (H) denotes the (expected) Rademacher complexity (Bartlett & Mendelson, 2002) of H
with Sample size n over μ.
Lemma 4. Suppose the loss function ` is ρ-Lipschitz with respect to the first argument (0 < ρ < ∞),
and all the functions in the model class F are bounded, i.e., there exists a constant Cb such that
kf k∞ ≤ Cb forany f ∈ F. Let C' := SuPt=±ι '(Cb,t). For any δ > 0, with probability 1 一 δ,
SuFMf)- R+c(f )∣≤(I
+ ∏+)2ρRe +(F ) + (i + ∏+)C'
*
Proof. By the definition of RP+C(f) and RbP+C(f), we can obtain
S∈F∣R+C(f)一 R+C(f )∣≤ SuF
1
Ee+(x)['(f (x), +1)] - n E'(f (x), +1)
∣	1	∣
+ ∏+ sup Ee+(x)['(f(χ),τ)] — E'(f(χ),-1).
f∈F ∣	n i=1	∣
(10)
By applying Lemma 3, we have for any δ > 0, with probability 1 一 δ,
-...	」	1 ^n ...	~ , ,	l log 2
SupEe+(x)['(f(x),+1)] — n ]ζ'(f (x), +1) ≤ 2R +(' ◦F) + CZ £,	(11)
and for any for any δ > 0, with probability 1 一 δ,
SupEe+(x)['(f(x),-1)] 一 n X'(f(x),-1) ≤ 2R +(' ◦F) + Cdl0gδ,	(12)
where ' ◦ F means {' ◦ f | f ∈ F}. By Talagrand's lemma (Lemma 4.2 in Mohri et al. (2012)),
R+(' ◦F) ≤ ρR+(F).	(13)
Finally, by combing Eqs. (10), (11), (12), and (13), we have for any δ > 0, with probability at least
1 一 δ,
Sup∣R+c(f)一 R+c(f)∣ ≤ (1 + ∏+)2ρR +(F) + (1 + ∏+)C'(l0gn4,	(14)
which concludes the proof of Lemma 4.
□
Lemma 5. Suppose the loss function ` is ρ-Lipschitz with respect to the first argument (0 < ρ < ∞),
and all the functions in the model class F are bounded, i.e., there exists a constant Cb such that
kf k∞ ≤ Cb forany f ∈ F. Let C' := SuPt=±ι '(Cb,t). For any δ > 0, with probability 1 一 δ,

Sup ∣∣RP-C(f) 一 RbP-C(f)∣∣ ≤
(1 + π- )2ρRe n (F) + (1 + π- )C'
Proof. Lemma 5 can be proved similarly to Lemma 4.	□
By combining Lemma 2, Lemma 4, and Lemma 5, Theorem 4 is proved.	□
15
Under review as a conference paper at ICLR 2021
F Proof of Theorem 5
Suppose there are n pairs of paired data points, which means there are in total 2n data points.
For our Pcomp classification problem, we could simply regard x sampled from je+(x) as (noisy)
positive data and x0 sampled from p-(x0) as (noisy) negative data. Given n pairs of examples
{(xi, χi)}n=1, for the n observed positive examples, there are actually n ∙ p(y = +1∣e = +1) true
positive examples; for the n observed negative examples, there are actually n ∙ p(y = -1∣e = -1)
true negative examples. From our defined data generation process in Theorem 1, it is intuitive to
obtain
p(y = +1 ∣ y = +1)
p(y = -1 ∣ y = -1)
∏+ + ∏+∏-
∏+ + π- + ∏+∏-
π—+ ∏+∏-
∏+ + π- + ∏+∏-
Since φ+ = p(yF -1 ∣ y = +1) = 1 - p(y = +1 ∣ y = +1) and φ- = p(y = +1 ∣ y = -1)
1 - p(y = -1 ∣ y = -1), we can obtain
∏2
Φ+ = p(y = -1 ∣ y = +1) = 1 -
Φ- = p(y = +1 ∣ y = -1) = 1 -
∏+ + ∏+∏-
∏+ + π- + ∏+∏-
π-+ ∏+∏-
∏+ + π- + ∏+∏-
+ π-+ ∏+∏-
+ π-+ ∏+∏-
In this way, we can further obtain the following noise transition ratios:
ρ+ = p(y = -11 y = +1)
p(y = +1 ∣ 攵=-1)p(e = -1)
p(y = +1)
ρ- = p(y = +11 y = -1)
p(y = -1 ∣ 攵=+1)p(e = +1)
p(y = -1)
_______π+_______
2(∏+ + π- + ∏+∏-)
∏-
2(∏+ + π- + ∏+∏-)
where p(y = 1) = p(y = -1) = 11, because we have the same number of observed positive
examples and negative examples.
G Proof of Theorem 7
First of all, we introduce the following notations:
R+pc(∕) = Ee+(χ) [，(f (x), +1)l[x ∈ PP]],
ʌ	1 n	〜
r+pc(f) = - E('(f(xi), +1)i[xi ∈ pP]),
i=1
RPPC(f )= E…)['(f(x0),-1)I[x0 ∈ nN]],
ʌ	1 3............... ~ 一、
RPPC(f ) = - £ ('(f (xi),-1)I[xi ∈ NN]).
i=1
In this way, we could SimPIy represent Rppc(f) and Rppc(f) as
11	11
RpPc(f )=	— R+pc(f)+	— R-Pc(f), RpPc(f )=	— R+pc(f)+	— RpPC(f).
1 — ρ+	1 — ρ-	1 — ρ+	1 — ρ-
Then we have the following lemma.
Lemma 6. Thefollowing inequality holds:
R(fpPc) - R(f*) ≤ 广二 sup ∣R+pc(f) - R+pc(f) I + 广匚 sup I R-pc(f) - RpPC(f) ∣.
1 - ρ+ f ∈F	1 - ρ- f ∈F 1
(15)
16
Under review as a conference paper at ICLR 2021
Proof. We omit the proof of Lemma 6 since it is quite similar to that of Lemma 2.	□
As suggested by Lemma 6, we need to further upper bound the right hand size of Eq. (15). According
to Lemma 3, we have the following two lemmas.
Lemma 7. Suppose the loss function ` is ρ-Lipschitz with respect to the first argument (0 < ρ < ∞),
and all the functions in the model class F are bounded, i.e., there exists a constant Cb such that
kf k∞ ≤ Cb forany f ∈ F. Let C' := suPz≤Cb,t=±ι '(z,t). Forany δ > 0, with probability 1 — δ,
SuFRPCf) -
R+pc(f)∣ ≤ 2ρR +(F)+ C'J嚓2.
Lemma 8. Suppose the loss function ` is ρ-Lipschitz with respect to the first argument (0 < ρ < ∞),
and all the functions in the model class F are bounded, i.e., there exists a constant Cb such that
kfk∞ ≤ Cb for any f ∈ F. Let C' := supz≤C ,t=±1 `(z, t). For any δ > 0, with probability 1 - δ,
SupRPC(f) — R-PC(f)∣ ≤ 2ρR-(F) + C'↑J岁
We omit the proofs of Lemma 7 and Lemma 8 since they are similar to that of Lemma 4.
By combing Lemma 6, Lemma 7, and Lemma 8, Theorem 7 is proved.
H Supplementary Information of Experiments
Table 3 reports the specification of the used benchmark datasets and models.
MNIST2 (LeCun et al., 1998). This is a grayscale image dataset composed of handwritten digits
from 0 to 9 where the size of the each image is 28 × 28. It contains 60,000 training images and
10,000 test images. Because the original dataset has 10 classes, we regard the even digits as the
positive class and the odd digits as the negative class.
Fashion-MNIST3 (Xiao et al., 2017). Similarly to MNIST, this is also a grayscale image dataset
composed of fashion items (‘T-shirt’, ‘trouser’, ‘pullover’, ‘dress’, ‘sandal’, ‘coat’, ‘shirt’, ‘sneaker’,
‘bag’, and ‘ankle boot’). It contains 60,000 training examples and 10,000 test examples. It is
converted into a binary classification dataset as follows:
•	The positive class is formed by ‘T-shirt’, ‘pullover’, ‘coat’, ‘shirt’, and ‘bag’.
•	The negative class is formed by ‘trouser’, ‘dress’, ‘sandal’, ‘sneaker’, and ‘ankle boot’.
Kuzushiji-MNIST4 (Netzer et al., 2011). This is another grayscale image dataset that is similar
to MNIST. It is a 10-class dataset of cursive Japanese (“Kuzushiji”) characters. It consists of 60,000
training images and 10,000 test images. Itis converted into a binary classification dataset as follows:
•	The positive class is formed by ‘o’, ‘su’,‘na’, ‘ma’, ‘re’.
•	The negative class is formed by ‘ki’,‘tsu’,‘ha’, ‘ya’,‘wo’.
CIFAR-105 (Krizhevsky et al., 2009). This is also a color image dataset of 10 different objects
(‘airplane’, ‘bird’, ‘automobile’, ‘cat’, ‘deer’, ‘dog’, ‘frog’, ‘horse’, ‘ship’, and ‘truck’), where the
size of each image is 32 × 32 × 3. There are 5,000 training images and 1,000 test images per class.
This dataset is converted into a binary classification dataset as follows:
•	The positive class is formed by ‘bird’, ‘deer’, ‘dog’, ‘frog’, ‘cat’, and ‘horse’.
•	The negative class is formed by ‘airplane’, ‘automobile’, ‘ship’, and ‘truck’.
2http://yann.lecun.com/exdb/mnist/
3https://github.com/zalandoresearch/fashion-mnist
4https://github.com/rois-codh/kmnist
5https://www.cs.toronto.edu/~kriz/cifar.html
17
Under review as a conference paper at ICLR 2021
Table 3: Specification of the used benchmark datasets and models.
Dataset	# Train	# Test	# Features	# Classes	Model
MNIST	60,000	10,000	784	10	MLP (d-300-300-300-300-1)
Fashion-MNIST	60,000	10,000	784	10	MLP (d-300-300-300-300-1)
Kuzushiji-MNIST	60,000	10,000	784	10	MLP (d-300-300-300-300-1)
CIFAR-10	50,000	10,000	3,072	10	ResNet-34
USPS	7,437	1,861	256	10	Linear Model (d-1)
Pendigits	8,793	2,199	16	10	Linear Model (d-1)
Optdigits	4,495	1,125	62	10	Linear Model (d-1)
CNAE-9	864	216	856	9	Linear Model (d-1)
USPS, Pendigits, Optdigits. These datasets are composed of handwritten digits from 0 to 9. Be-
cause each of the original datasets has 10 classes, we regard the even digits as the positive class and
the odd digits as the negative class.
CNAE-9. This dataset contains 1,080 documents of free text business descriptions of Brazilian
companies categorized into a subset of9 categories cataloged in a table called National Classification
of Economic Activities.
•	The positive class is formed by ‘2’, ‘4’, ‘6’ and ‘8’.
•	The negative class is formed by ‘1’, ‘3’, ‘5’, ‘7’ and ‘9’.
For MNIST, Kuzushiji-MNIST, and Fashion-MNIST, we set learning rate to 1e-3 and weight decay
to 1e - 5. For CIFAR-10, we set learning rate to 1e - 3 and weight decay to 1e - 3. We also list
the number of pointwise corrupted examples used for model training on each dataset: 30,000 for
MNIST, Kuzushiji-MNIST, Fashion-MNIST, and CIFAR-10; 4,000 for USPS; 5,000 for Pendigits;
2,000 for Optdigits; 400 for CNAE-9.
18