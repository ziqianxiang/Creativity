Under review as a conference paper at ICLR 2021
Ablation Path Saliency
Anonymous authors
Paper under double-blind review
Abstract
We consider the saliency problem for black-box classification. In image classi-
fication, this means highlighting the part of the image that is most relevant for
the current decision. We cast the saliency problem as finding an optimal abla-
tion path between two images. An ablation path consists of a sequence of ever
smaller masks, joining the current image to a reference image in another decision
region. The optimal path will stay as long as possible in the current decision region.
This approach extends the ablation tests in Sturmfels et al. (2020). The gradient
of the corresponding objective function is closely related to the integrated gradi-
ent method Sundararajan et al. (2017). In the saturated case (when the classifier
outputs a binary value) our method would reduce to the meaningful perturbation
approach Fong & Vedaldi (2017), since crossing the decision boundary as late as
possible would then be equivalent to finding the smallest possible mask lying on
the decision boundary. Our interpretation provides geometric understanding of
existing saliency methods, and suggests a novel approach based on ablation path
optimisation.
1 Introduction
The basic idea of saliency or attribution is to provide something from which a human can judge how
a classifier arrived at its decision of the prediction it gives for a certain input. It is difficult to give
a more mathematical definition, but various properties that such a method should fulfill have been
proposed.
Sundararajan et al. (2017) give axioms, of which sensitivity comes closest to the notion of saliency.
Essentially, the features on which the output is most sensitive should be given a higher saliency value.
The authors give further axioms to narrow it down - implementation invariance, completeness, lin-
earity and symmetry-preservation - and obtain a corresponding method: the integrated gradient
method. Note that we have another way to arrive at a similar method, see §4.1
Fong & Vedaldi (2017) is closer to our work: the authors directly compute the saliency of a given
pixel by deleting, or altering that pixel, to see how this affects the output of the classifier.
Our method is to define a proper maximisation problem as follows. First, we define ablation paths
as time dependent smooth masks φ: [0,1] → C(Ω, R), going a full mask to an empty mask, suchthat
at each pixel the mask value decreases over time (see Figure 1). We also impose constant area speed:
Figure 1: Example of how an ablation path (sequence of masks, top) gives rise to a transition between
a current target (image of a house finch) and a baseline (orca whale).
1
Under review as a conference paper at ICLR 2021
the area covered by the mask should increase linearly over time (see §3). Let F be the classifier, that
outputs a probability between zero and one. We choose a current image of interest x0 and a baseline
image x 1. The objective function is then P(φ) = R1 F(x0 + φ(t)(x 1 — x0)) dt (See §4). Assuming
that F(x0 ) ' 1 and F(x1) ' 0, maximising the objective function means that we try to find an
ablation path that stays as long as possible in the decision region of x0. Intuitively, we try to replace
as many pixels of x0 by pixels of x1 while staying in the same class as x0 .
The main contribution of this paper is to formulate the saliency problem as an optimisation problem
on paths. Doing so connects previous notions of saliency, notably integrated gradients Sundararajan
et al. (2017) (see §4.1), the ablation tests Sturmfels et al. (2020) (see §4.2), and meaningful pertur-
bations Fong & Vedaldi (2017); Fong et al. (2019) (see § 4.3). Our formulation is also resolution
invariant (it does not assume that images are defined on pixels); this allows to make a clear differ-
ence between images and their duals, for instance, which gives guidance as to where regularisation
is needed.
2	Related Work
Simonyan et al. (2013) defines a saliency map as the gradient of the network output at the given
image. This would appear to be a sensible definition, but the resulting saliency is very noisy because
the network output is roughly constant around any particular image. Selvaraju et al. (2016) improves
the situation by computing the gradient after each layer instead. This is, however, not a black-box
method such as the one we propose. Koh & Liang (2017) computes an influence function, that is,
a function that measures how the parameters would be changed by a change in the training data.
Although it is a black-box method, it is not a saliency method per se. They use the gradient of
the network output to find the pixel most likely to have a high saliency. The pixel that have most
effect are given a higher saliency. By contrast, Petsiuk et al. (2018) proposes to directly evaluate the
saliency by finding out which pixels most affect the output, similarly to Fong & Vedaldi (2017), but
without using any gradients.
There are a number of meta-studies of saliency methods. Adebayo et al. (2018) lists essential prop-
erties, for instance the requirement that the results should depend on the training data in a sense that
perturbing model parameters should change the saliency. Kindermans et al. (2017) proposes a num-
ber of property that saliency methods should satisfy. Ancona et al. (2017) compares several saliency
methods and proposes a method to evaluate them (the sensitiviy-n property).
3	Ablation Paths
3.1	Images and Masks
We consider a compact domain Ω. Note that Ω may be discrete or continuous: in fact, we assume
that Ω is endowed with a measure which could be the discrete measure (if Ω is a set of pixels) or the
Lebesgue measure (if Ω is a domain in R2, for instance). In the sequel, Ω denotes integration with
respect to that measure. Without loss of generality, we assume the mass of that measure to be one,
i∙e∙, Rω 1 = 1.
We consider a module M of functions on Ω with values in a vector space V (the dimensions of
V represent the channels, and elements of M represent images). This module is equipped with a
commutative ring R which represents masks. Concretely, in most of the paper we choose
M := C(Ω,V)	R := C(Ω, R).
The module structure simply means that masks can multiply images, i.e., that the operation θx gives
a new image in M when θ ∈ R and x ∈ M, and that this operation is bilinear.
3.2	Ablation Paths
Definition 3.1. We define the set A of ablation paths as the set of functions φ: [0,1] → R fulfilling
the following properties:
Boundary conditions φ(0) = 0 and φ(1) = 1
2
Under review as a conference paper at ICLR 2021
Monotonicity 11	≤	12	=⇒	φ(11) ≤	φ(12)	11 ,t2	∈	[0,1]
Constant speed Ω φ(t) = t t ∈ [0,1].
We will call monotone paths the paths that verify the first two conditions but not the third.
Note that the set A of ablation paths is a convex subset of L∞([0, 1], R).
Some comments on each of those requirements are in order. (i) 0 and 1 denote here the constant
functions zero and one (which corresponds to the zero and one of the algebra R) (ii) φ (11) ≤ φ (12)
should be interpreted as usual as φ(12) 一 φ(11) being in the cone of nonnegative elements1. (iii) If
t ∣→ Ω φ (t) is differentiable, this requirement can be rewritten as ddt Ω φ (t) = 1, so it can be
regarded as a constant speed requirement. This requirement is more a normalisation than a require-
ment, as is further detailed in Remark 3.3.
There is a canonical, simplest, ablation path between x0 and x1 :
`(t) := t.	(1)
The mask is thus constant in space at each time t. The reader should check that all the requirements
for an ablation path are fulfilled.
Note that an ablation path without the constant-speed property can always be transformed into one
that does fulfil it. This is clear if the function t → Ω φ (t) is strictly increasing, as this is then just
a time reparameterisation, but this is in fact always possible, in a canonical sense. The proof is in
Appendix A.
Lemma 3.2. To any monotone path there corresponds a canonical ablation path.
Since R is itself a function space, an ablation path φ is in fact a function of two arguments. In the
sequel, We will abuse the notations and write φ as a function of one or two arguments depending
on the context: φ(t) ≡ φ(t, ∙). For instance, in the definition Definition 3.1 above, Ω φ(t) ≡
RΩ 中(t, ∙) ≡ RΩ 中(t, r) dr∙
Remark 3.3. Ifthe ablation path φ is differentiable in time, the requirements in Definition 3.1 admit
a remarkable reformulation. Define ψ (t) := dt φ(t). All the requirements in Definition 3.1 are
equivalent to the following requirements for a function ψ: [0,1] × Ω → R:
ψ(t, r) ≥ 0, L ψ(t,	r) dr = 1, L ψ(t, r) dt= 1 t ∈ [0,1], r ∈ Ω
The corresponding ablation path	φ is then recovered by φ (t)	:= Rt	ψ (S) ds.	What this means	is
that differentiable ablation paths can be parameterised as densities of doubly stochastic Markov
transition kernels on [0,1] X Ω.
3.3	Regularity of Ablation Paths
Lemma 3.4. If φ is an ablation path, then
Il2(11) 一 φ(to)Ilo = lt 1 -101∙
In particular, t → φ (t, ∙) is continuous as a function [0,1] → L 1(Ω).
Proof. Choose t t ,t 1 in [0, 1]. Without loss of generality, assume 11 ≥ t t. Then, JQ ∣φ (11) - φ (t t) | =
Jω(φ(11) - φ(tt)) = 11 — tt, from which we conclude that φ(11) - φ(tt) is in L1 and fulfils the
equation above.	□
4	Score of an Ablation Path
We now fix two points xt (the current image) and x1 (the baseline image) in the space of images M .
We propose the following measure of the score ofan ablation path (see Definition 3.1) with respect
1Here We can define the cone of nonnegative functions by { f ∈ C (Ω, R) ∣ f ≥ 0 }. In a general star
algebra, this cone would be defined as { x ∈ R ∣ ∃y ∈ R x = y*y }.
3
Under review as a conference paper at ICLR 2021
to these two images. Given a mask θ ∈ R, we define the interpolated image [x0, x1]θ ∈ M as
[x0, x1]θ := (1 - θ)x0 + θx1.
We now define the score function P : A → R from ablation paths to R by the integral
PS )=/1
0
F ([ N o ,x 1]奴 t ))dt.
(2)
Note that, as F is bounded between zero and one, so is P (φ) for any ablation path φ. The main idea
is that if F(x0) ' 1 and F(x1) ' 0, the higher this value of P is, the better the path is to describe
the salient parts of the image.
Note that the function P is defined regardless of the constraints placed on ablation paths, i.e., the
score function P is defined on the vector space of functions φ: [0,1] → R. It is straightforward to
compute its differential dP on that space:
h d P,δψi =八 d F[
00 1------------
X 0 ,x l] R t) , ( x 1 - x O) 64 (t) i dt∙
-z^-(-> |{'}∣{Z^
∈M *	∈M ∈R
So if we define the product of D ∈ M* and x ∈ M producing an element in R by hχD, φi :
hD, XOi as is customary, we can rewrite this differential as
h d PM)
/〈(X 1 - x0)dF[X0,Xι] Wt) ,δO(t)〉dt.
Note that we know that any ablation path is bounded, so O∈ L∞([0, 1], R), so the differential ofP
at φ can be identified with the function d Pφ =	→ (x 1 — x o)d F[ X 0 血]H 七)]in L 1([0,1], R*).
4.1	Relation with the Integrated Gradient Method
When this differential is computed on the interpolation path ` (1) and then averaged, then this is
exactly the integrated average gradient Sundararajan et al. (2017). More precisely, the integrated
gradient is exactly R1 dP(t)dt. Note that this is in fact an integrated differential, since we obtain an
element in the dual space M*, and this differential should be appropriately smoothed along the lines
of§5.1.
4.2	Relation to Pixel Ablation
Given a saliency function σ ∈ R we can define a path by 0(t) := 1 σ≤log(t/(1 -t))when t ∈ (0,1)
and define 0(0) := 0, ⅛5(1) := 1. This path is a monotone path, except in the module of images
M = L 2(Ω, V), equipped with the ring of masks R = L∞ (Ω). To be an ablation path, it still needs
to be transformed into a constant speed path, which is always possible as explained in Appendix A.
Note that this is a generalisation of the ablation method in Sturmfels et al. (2020). In that case,
the set Ω would be a discrete set of pixels. Note that in the ranking, pixels with the same saliency
would be ranked in an arbitrary way and added to the mask in that arbitrary order. In the method
above, we add them all at once, but the time reparameterisation keeps that function constant longer
for however many pixels were ranked the same. As long as the ranking is strict (no two pixels have
the same saliency), the two methods are the same.
4.3	Relation to Meaningful Perturbations
In the saturated case, that is, if F only takes values zero and one (or in the limit where it does),
our method basically reduces to finding the interpolation with the largest mask on the boundary, in
essence the approach of Fong & Vedaldi (2017). Indeed, suppose that the ablation path 0 crosses the
boundary at time t*. It means that F([xo, x 1]φ(t)) has value one until t* and zero afterwards, so the
score P defined in (2) is P(φ) = t*. By the constant speed property, t* = Ω φ(t*), so we end up
maximising the mask area on the boundary.
4
Under review as a conference paper at ICLR 2021
5	Optimisation Problem and Algorithm
We proceed to define the optimisation problem at hand and how to solve it numerically.
Conceptually We try to find the ablation path (See Definition 3.1) that maximises the score P (φ):
mayw) ∙
Recall that the set A of ablation paths is convex; hoWever, since the objective function P is not
convex, this is not a convex optimisation problem.
The method We suggest is to folloW a gradient direction. Such an approach is in general not guaran-
teed to approximate a global maximum, but empirically it does manage that quite Well here.
5.1	Gradient and Metric
Note that the differential is an element of L 1([0, 1], R^), so we need a map from that space to
L∞([0,1], R). For now we assume that φ ∈ L2([0, 1], R) and dP ∈ L2([0,1], R*).
However, we still need a covariance operator K: R* → R. InPractice, we use a covariance operator
associated to a smoothing operator. Forameasure μ ∈ R*, hKμ, θ∖ := hμ, Ω k (•一 r)θ(r) dr), where
k is a suitable smoothing function, for instance k(r) = exp(-IIrII2/σ). This allows US to consider
the gradient ofP. Note that different choices of metric will influence on the algorithm.
Since the optimisation problem is constrained (since φ is constrained by the requirements in Defini-
tion 3.1), following the gradient direction will lead us to violate the constraints. Since the constraints
are convex, it is straightforward enough to project each gradient-updated version back to something
that does fulfill them, and indeed that is the idea behind our algorithm, however in practice it does by
itself not yield convergence without impractically many iterations. See Appendix C for the details
of how we actually proceed.
6	Examples
To test out our path-scoring approach and the saliency method based on its optimisation, we use a
standard image classifier deep-CNN (Inception v4 Szegedy et al. (2016), pre-trained on ImageNet),
with a selection of real-world images for both the current target and baseline inputs. For each ex-
ample pair, we compare multiple saliency methods.
Our algorithm yields a whole path of masks, which cannot as a whole be visualised in one 2D view.
Generally, the threshold mask, which we define as the mask right where the path crosses the decision
boundary, is most insightful: it still preserves enough of the image to be classified correctly, but no
more. All of the images in this section refer to that selection, and where the threshold lies in the
path is indicated by the vertical black line in the score plots. To be precise, this is the mask that
preserves as little of the image as possible whilst still resulting in the intended class keeping the
highest probability among the classes in the classifier’s prediction. Note that although the threshold
mask encapsulates a large part of our method’s useful output, we find that the additional information
from the rest of the path, and the score-plot along the path, also provide good diagnostics especially
in examples where the mask highlights an unexpected region of the image.
Figure 2 is an example with particularly clear-cut interpretation: the vibrantly coloured rubber eraser
is sufficient to retain the classification even in an almost completely ablated image. All of the com-
pared methods manage to find a mask that focuses in on that, though with differences in the details.
The unconstrained optimisation narrows it down to afew individual pixels, which gives an extremely
good score (somewhat unsurprisingly, since that is what is being optimised), but the result is hardly
useful for interpretability purposes: this should be considered an adversarial example. One interpre-
tation of this is that identifying the gradient with the differential implies that the space of masks R is
essentially bounded functions wihout further regularity (see §5.1), similar to the mask space in §4.2.
The region boundary in that space seems to be extremely close to the baseline, and the optimisation
method finds those adversarial examples.
5
Under review as a conference paper at ICLR 2021
0%	20%	40%	60%	80%	100%
Integrated Gradients
Filtered Integrated Gradients
Random Pixel Ablation
Figure 2: Comparison of saliency methods for an image of a pencil, against one of an orca whale as
the baseline.
The integrated gradient method in principle also has this issue, and indeed the corresponding mask
(pixel ranking, cf. § 4.2) is quite grainy/noisy, without however behaving adversarially (the entire
pencil is highlighted).
The authors in Fong & Vedaldi (2017) were confronted with similar problems. We use smoothing
filters to compute the gradient, in order to both avoid adversarial examples and to have less noisy
saliency masks. Using that, the path-optimisation still manages to achieve a high score, but now
highlights the eraser as a single, clearly interpretable feature.
Filtering can also be applied to integrated gradient before pixel-ranking. That does avoid the noisy-
ness, but it also leads to a blobby shape of the masks.
Comparison with a random-order ablation confirms that the good scores of the saliency methods
really are a result of non-trivial feature highlighting, rather than something that comes out of the
transition between the images automatically.2 In Figure 3 it is evident that the saliency methods do
not in general agree so clearly. Here, the filtered optimal path again highlights a small, single region
that is sufficient for a classification of the image as a house- rather than goldfinch. Arguably, this
is again adversarial (a human would certainly label the composite image gold- rather than house
finch). However it does give rise to a useful interpretation: note that the highlighted region includes
2See Appendix E for a small, non-rigorous statistical study suggesting that scores > 0.9 are p < 0.01
significant against a null hypothesis of smoothly random masks, and extremely unlikely with pixelwise-random
masks.
6
Under review as a conference paper at ICLR 2021
the house finch’s plumage, whilst covering specifically the wing of the gold finch (which features
a distinctive pattern not seen on house finches). So in this case, the saliency tells more about the
baseline than about the current target.
The integrated gradient meanwhile hardly manages to mask out anything at all, before the classifi-
cation switches to gold finch.
Practically speaking, saliency is particularly interesting in questions of whether a classification was
actually correct. Figure 4 shows an example where the model misclassified an apple as a fig. The
unstable scores in even the optimised ablation path are perhaps symptomatic of this (we are not sure
how representative this is); nevertheless both our method and integrated gradients find a mask of
less than half of the image that still retains the fig-classification. Whilst with integrated gradients,
this mask includes the apple (which might in a real-world unclear situation lead one to think the
classification payed attention to the intended target, increasing credibility), out method highlights
mainly a patch of background at the border of the image.
The optimised paths depend not only on the model and current target, but also on the baseline; notice
for example that the pencil, of which in Figure 2 mostly the eraser was highlighted, is in Figure 5
mostly characterised by the eraser’s metallic joint as well as part of the blue shaft, which happens to
coincide with the gold finch’s wings that were also masked out in Figure 3. In Figure 6 itis something
in between. Still the results (with filtering) tend to be relatively coherent across baselines, more so
than with the Integrated Gradients or the adversarial unfiltered ones.
One might ask why to use a true image as a baseline at all (as opposed to a blurred image, a constant
colour image, as in Sturmfels et al. (2020) or Fong & Vedaldi (2017)). The problem with artificial
baselines is that the network missclassifies them (a blurred goldfinch is classified as a power drill, for
example), so the ablation path crosses region where the network is extrapolating wildly. The resulting
Saliency may be difficult to interpret since the -unknown- parts of the baseline which the networks
considers as important (which part of the blurred goldfinch lead to the power drill classification?)
have an influence on the saliency of the current image. Ideally, we would like to have some result
about saliency that gives good scores across many different baselines. Future research is needed.
Another choice to be made is the regularisation. We used here Gauβian filters; different sizes Com-
pared in Figure 6. Itis a tradeoff between blurring out the boundaries and inviting noisiness, however
even a small filter appears tobe enough to avoid the algorithm from converging to adversarial exam-
ples (seemingly smaller than what Fong et al. (2019) require). It is even possible to scale down the
filter during the optimisation to eventually give very sharp edges but not noise elsewhere, though it
is somewhat dubious what sense this makes mathematically, from the point of view that the filtering
represents just a metric on R. Again, further research is needed to assess the reliability.
Optimised Path (filter-regularised)
L。］ - T …一ψ~
0.5-
score 0.938
0.0^__________l_______l________l_______l_____ 1
0%	20%	40%	60%	80%	100%
Integrated Gradients
Figure 3: Method comparison for a house finch image against a gold finch baseline.
7
Under review as a conference paper at ICLR 2021
Filtered Integrated Gradients
Figure 4: Method comparison for a misclassified image: Inception classifies the apple as a fig in-
stead.
Optimised Path (filter-regularised)
Figure 5: Comparison of saliency methods for an image of a pencil, against one of a gold finch as
the baseline.
7	Pointing game
We evaluate our saliency algorithm using the pointing game method. This method was introduced
in Zhang et al. (2017) and used, for instance, in Selvaraju et al. (2016); Fong & Vedaldi (2017). The
primary goal is to show that our method, applied to a good enough image classifier, typically gives
results that match what a human would also think of as the important part of the image. Specifically,
we check whether the maximum-salient pixel lies within the bounding box of the object that defines
the class.
Table 1 shows some results for our method on various images with blurred image as baseline. We
show a few examples of this pointing game on Figure 7. See Appendix D for details and caveats
with these results.
Class (sample size) ∣ Ablation path ∣ Meaningful Perturbations
Bee (121)	83%	46%
Power drill (121)	77%	40%
Saxophone (119)	89%	49%
Table 1: The success rate of the pointing game for various classes from the ILSVRC2014 dataset Rus-
sakovsky et al. (2015). We chose the first images in each class by alphabetical order. We compare to
the meaningful perturbation method in Fong & Vedaldi (2017) (see caveat at the end of Appendix D).
8
Under review as a conference paper at ICLR 2021
Optimised Path
Ablation
Figure 6: Comparison of saliency methods for an image of a pencil, against one of a house finch as
the baseline.
Figure 7: Examples of how the ablation path saliency “points” in the bounding box of various images
of bees. The bounding boxes are human defined in the dataset, the red crosses indicate the location
of least-ablated pixel.
References
Julius Adebayo, Justin Gilmer, Michael Muelly, Ian Goodfellow, Moritz Hardt, and Been Kim.
Sanity checks for saliency maps. In S. Bengio, H. Wallach, H. Larochelle, K. Grauman,
N. Cesa-Bianchi, and R. Garnett (eds.), Advances in Neural Information Processing Systems
31, pp. 9505-9515. Curran Associates, Inc., 2018. URL http://papers.nips.cc/paper/
8160- sanity-checks-for-saliency-maps.pdf.
Marco Ancona, Enea Ceolini, Cengiz Oztireli, and Markus Gross. Towards better understanding of
gradient-based attribution methods for deep neural networks. CoRR, 2017.
9
Under review as a conference paper at ICLR 2021
Ruth Fong and Andrea Vedaldi. Interpretable explanations of black boxes by meaningful perturba-
tion. CoRR, 2017. URL http://arxiv.org/abs/1704.03296v3.
Ruth Fong, Patrick Mandela, and Andrea Vedaldi. Understanding deep networks via extremal per-
turbations and smooth masks. ICCV, 2019. URL https://arxiv.org/abs/1910.08485.
Jacob Gildenblat. Pytorch implementation of interpretable explanations of black boxes by meaning-
ful perturbation. https://github.com/jacobgil/pytorch-explain-black-box, 2017.
Pieter-Jan Kindermans, Sara Hooker, Julius Adebayo, Maximilian Alber, Kristof T. Schutt, Sven
Dahne, Dumitru Erhan, and Been Kim. The (unreliability of saliency methods. CoRR, 2017.
URL http://arxiv.org/abs/1711.00867v1.
Pang Wei Koh and Percy Liang. Understanding black-box predictions via influence functions. CoRR,
2017. URL http://arxiv.org/abs/1703.04730v2.
Vitali Petsiuk, Abir Das, and Kate Saenko. Rise: Randomized input sampling for explanation of
black-box models. CoRR, 2018.
Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang,
Andrej Karpathy, Aditya Khosla, Michael Bernstein, Alexander C. Berg, and Li Fei-Fei. ImageNet
Large Scale Visual Recognition Challenge. International Journal of Computer Vision (IJCV), 115
(3):211-252,2015. doi: 10.1007∕s11263-015-0816-y.
Ramprasaath R. Selvaraju, Michael Cogswell, Abhishek Das, Ramakrishna Vedantam, Devi Parikh,
and Dhruv Batra. Grad-cam: Visual explanations from deep networks via gradient-based local-
ization. CoRR, 2016. URL http://arxiv.org/abs/1610.02391v4.
Karen Simonyan, Andrea Vedaldi, and Andrew Zisserman. Deep inside convolutional networks:
Visualising image classification models and saliency maps. CoRR, 2013.
Pascal Sturmfels, Scott Lundberg, and Su-In Lee. Visualizing the impact of feature attribution base-
lines. Distill, 2020. doi: 10.23915∕distill.00022. https://distill.pub/2020/attribution-baselines.
Mukund Sundararajan, Ankur Taly, and Qiqi Yan. Axiomatic attribution for deep networks. CoRR,
abs/1703.01365, 2017. URL http://arxiv.org/abs/1703.01365.
Christian Szegedy, Sergey Ioffe, Vincent Vanhoucke, and Alex Alemi. Inception-v4, inception-resnet
and the impact of residual connections on learning, 2016.
Mingxing Tan and Quoc V. Le. Efficientnet: Rethinking model scaling for convolutional neural
networks. CoRR, abs/1905.11946, 2019. URL http://arxiv.org/abs/1905.11946.
Jianming Zhang, Sarah Adel Bargal, Zhe Lin, Jonathan Brandt, Xiaohui Shen, and Stan Sclaroff.
Top-down neural attention by excitation backprop. International Journal of Computer Vision,
126(10):1084-1102, 2017. doi: 10.1007/s11263-017-1059-x.
A Canonical Time Reparametrisation
Proof of Lemma 3.2. The function m: [0, 1] → R defined by m (t) := Ω φ (t) is increasing and
goes from zero to one (since We assume that Ω 1 = 1).
Note first that if m(11) = m(12), then φ(11) = φ(12) from the monotonicity property. Indeed,
supposing for instance that 11 ≤ 12, and defining the element θ := φ(12) 一 φ(11) we see that on the
one hand Ω θ = 0, on the other hand, θ ≥ 0, so θ = 0 and thus φ(11) = φ(12).
Now, define M := m([0, 1]) = { s ∈ [0, 1] | ∃t ∈ [0, 1] m(t) = s }. Pick s ∈ [0, 1].
If S ∈ M we define ψ (S) := φ(t) where m(t) = S (and this does not depend on which t fulfills
m(t) = S from what we said above). We remark that Ω ψ(S) = Ω φ(t) = m(t) = S.
Now suppose that S 6∈ M. Define S1 := sup(M ∩ [0, S]) and S2 := inf(M ∩ [S, 1]) (neither set are
empty since 0 ∈ M and 1 ∈ M). Since S1 ∈ M and S2 ∈ M, there are t1 ∈ [0, 1] and t2 ∈ [0, 1] such
10
Under review as a conference paper at ICLR 2021
that m(11) = S1 and m(12) = S2. Finally define ψ(S) := φ(11) + (S — S1)叭(S2)-^(1). In this case,
Rω ψ(S) = m(11) + (S — S1)m((S2-m(t 1) = S. The path ψ constructed this way is still monotone,
and it has the constant speed property, so it is an ablation path.	□
B L∞-optimal Monotonicity Projection
The algorithm proposed in Appendix C for optimising monotone paths uses updates that can locally
introduce nonmonotonicity in the candidate ⅛^1,so that it is needed to project back onto a monotone
path φ 1. The following routine3 performs such a projection in a way that is optimal in the sense of
minimising the L∞-distance4, i.e.
sup IΨ 1(t, r) — 61(t, r)∣ ≤ sup 16(t, r)—电(t, r)∣
t
t
for all r ∈ Ω and any other monotone path 优
The algorithm works separately for each r, i.e. we express it as operating simply on continuous
functions p : [0, 1] → R. The final step effectively flattens out, in a minimal way, any region in
Algorithm 1 Make a function [0, 1] → R nondecreasing
∪i [li,r ] ^ {t ∈ [0,1] I p0(t) ≤ 0 }	. Union of intervals where P decreases
for i do
mi J P 出)+P (r)
li J max{t ∈ [ri- 1,li] I P(t) ≤ mi }
ri J min{ t ∈ [ri, li+1] I p(t) ≥ mi }
end for
for i, j do
if [li, ri] ∩ [lj, rj] = 0 then
if mj < mi , merge the intervals and recompute m as the new center
end if
end for
return t 7→
ift 6∈ ∪i[li,ri]
ift ∈ [li, ri]
which the function was decreasing.
In practice, this algorithm is executed not on continuous functions but on a PCM-discretised repre-
sentation; this changes nothing about the algorithm except that instead as real numbers, l, r and t are
represented by integral indices.
C Path Optimisation Algorithm
As said in tsection § 5, our optimisation algorithm is essentially gradient descent of a path 6: it
repeatedly seeks the direction within the space of all paths that (first ignoring the monotonicity con-
straint) would affect the largest increase to P(6) as per (2). As discussed before, this choice already
requires a metric to obtain a vector-gradient from the covector-differential, which could be either the
implicit `2 metric on the discretised representation (pixels), or a more physical kernel/filter-based
metric. We conceptually use the latter, however for technical reasons do not immediately apply the
corresponding filter to the differential but rather to the path, which is not quite equivalent but does
have the effect of avoiding noise from creeping into the state.
Unlike with the monotonisation condition, the update can easily be made to preserve speed-constness
by construction, by projecting for each t the gradient g on the sub-tangent-space of zero change to
3 It is easy to come up with other algorithms for monotonising a (discretised) function. One could simply
sort the array, but that is not optimal with respect to any of the usual function norms; or clip the derivatives to
be nonnegative and then rescale the entire function, but that is not robust against noise pertubations.
4Note that the optimum is not necessarily unique.
11
Under review as a conference paper at ICLR 2021
Figure 8: Example view of the monotonisation algorithm in practice. (a) contains decreasing inter-
vals, which have been localised in (b). For each interval, the centerline is then extended to meet the
original path non-decreasingly (c). In some cases, this will cause intervals overlapping; in this case
merge them to a single interval and re-grow from the corresponding centerline (d). Finally, replace
the path on the intervals with their centerline (e).
Algorithm 2 Projected Gradient Descent
1	φ J ((t, r) — t)	> Start with linear-interpolation path
2	while φ is not sufficiently saturated do
3	:	for t in [0, 1] do
4	χψ,t ：=(1 一 φ(t)) xo + φ(t) x 1
5	compute F(x^t) with gradient g := NF(Xnt)
6	let ^ := g 一 RΩ g	> ensure g does not affect mass of φ(t)
7	update φ(t, r) J φ(t, r) 一 Y h^(r) ∣ ∣χ 1 一 x0), for r in Ω	.γ is learning rate
8	(optional) apply a filter to φ (t)
9	:	end for
10	(optional) apply nonlinear gain to φ
11	for r in Ω do
12	re-monotonise t — φ(t, r), using Algorithm 1
13	:	end for
14	clamp φ(t, r) to [0,1] everywhere
15	re-parametrise φ, such that Ω 夕(t) = t for all t (using Appendix A)
16	: end while.
Ω φ(t), by subtracting the constant function times Ω g(t). Note this requires the measure of Ω to
be normalised, or else considered at this point.
Then we apply these gradients time-wise as updates to the path, using a scalar product in the channel-
space to obtain the best direction for φ itself (as opposed to the corresponding image composit XOt).
Simply projecting the updates path then again to the set of legal (in the sense of Definition 3.1) abla-
tion paths would presumably enough to converge towards a saturated path with high score, however
12
Under review as a conference paper at ICLR 2021
Figure 9: Function : [0, 1] → R. Note that |(x)| ≤ 5 × 10-2. The formula is (x)
tanh(2ζ(x - 1/2))/2 tanh(ζ) + 1/2 - x, with ζ = 0.8.
in tests with artificial constant gradient we found out that this requires extremely many iterations,
with the number apparently scaling with the image dimension. The problem here is that saturating
updates tend to be undone again by the speed-normalising reparametrisation, except for the most
affected pixel. (Just increasing the learning rate does not help with this.) If the gradients come from
a deep CNN and for every pixel the monotonicity needs to be restored, such many iterations would
be prohibitly computation-intensive.
Fortunately we can dramatically speed up the convergence by artificially encouraging saturation.
We tweak the ablation path φ pointwise with a sigmoidal function that brings values lower than 2
slightly closer to 0, and values greater than 1 slightly closer to 1. To this end, We use a perturbation
of the identity function defined by x 7→ x + (x), and apply it pointwise to the path:
Ψ (r ,t) - Ψ (r ,t) + e (2(r ,t))
The perturbation function : [0, 1] → R has the property that x + (x) maps [0, 1] into itself. The
function e we use is plotted on Figure 9. Although this perturbation seems small, the examples in §6
now only require 20-40 iterations.
As to the motivation behind the transformation φ → φ + e(φ), notice first that fully saturated masks
- i.e., those that choose for every pixel are either zero or one, selecting exactly the value of either
the current target or the baseline - are fixpoints of the function x → x + e (x) since e (0) = e (1)=0.
So if such a mask is the optimum in the algorithm without artificial saturation (while there is no
guarantee for this in general, this seems fairly frequent in practice), then it will also be an optimum
of the algorithm with artificial saturation.
What is more, the dynamical system x 7→ x+e(x) quickly converges to zero or one, which efficiently
encourages saturation, without sacrificing precision, as the function e we chose is quite small.
Conversely, and unlike high learning rate, the saturation function is by construction monotone, sym-
metric and keeps the signal within the allowed bounds, so it avoids violating the ablation path con-
straints. The problem with high learning rates is that the algorithm gets caught in a sequence of
alternating strong constraint-violating updates followed by a projection step that largely undoes the
previous update.
D Evaluation with Pointing Game
The Pointing Game, the results of which we show in § 7, is a way to verify that the saliency method
points at a region that a human would consider relevant to the classification. It is often the region of
an image that contains the physical object which is being classified.
13
Under review as a conference paper at ICLR 2021
Such evaluations of saliency methods clearly have caveats. One can for instance argue that the cases
when the saliency points somewhere outside the bounding box are the most insightful ones, as they
indicate that the classifier is using information from an unexpected part of the image (for instance, the
background). Another caveat is that, if winning at the pointing game is the goal, a saliency method is
only as good as its underlying classifier is. Nevertheless, ifa saliency method often hits the bounding
box itis reasonable to conclude that both the classifier and the saliency method behave in an intuitive
way, from a human perspective. Our measurements in Table 1 confirm that the ablation-path method
indeed does this well.
Our method has an advantage over other ones as it yields not only a single spatial map as the saliency
but a whole path of masks. However, it does not directly give a saliency map. Here is how we choose
one point in the image from an ablation path. First, we choose a specific time, just as we did in the
examples in §6. In most cases, this means that we chose the time at which the probability has dropped
by 20 %, that is the smallest time t such that F(t) ≤ 0.8. When there is no such time, we pick the one
for which F takes the maximum value on the path. Now that the time is chosen, we pick the point in
the mask which have the smallest value. Note that, even though this selection may be unstable (since
many points are close to the minimum value, as the mask is typically saturated), it usually does not
matter since the whole region selected by the mask is salient.
The classifier in this experiment was an EfficientNet Tan & Le (2019) pre-trained on ImageNet, the
test data set 360 images from three synsets out of ImageNet.
As a comparison, we evaluated the pointing game with the same network and inputs also through
the closely related Meaningful Perturbations method Fong & Vedaldi (2017). We used a third-party
PyTorch implementation Gildenblat (2017). Note that this implementation uses a slightly simplified
method of removing information for performance, and that we did not change any of the hyperpa-
rameters of the method, so it is very likely that these results are not optimal. We also note that Fong &
Vedaldi (2017) themselves include results for the pointing game on different data, with better scores.
Nevertheless, the point was to show that our method works reasonably well, and this may be due to
the use of ablation paths: that increasing family of mask probably gives some stability to the saliency
method, which improves the scores.
E Random ablation paths
In this section, following an idea of Sturmfels et al. (2020), we compare our method to random
ablation-paths. Figure 2 includes one such example - the random path, which has a quite fuzzy
class transition in roughly the middle of the path. Figure 10 shows that this typical behaviour. In
unsmoothed
40 -
20-
0-
smoothed
Figure 10: Histograms of the scores of ablating an image obtained as explained in §4.2 (the gold
finch from Figure 3, against its blurred baseline) along random paths.
14
Under review as a conference paper at ICLR 2021
the unsmoothed case, the scores are almost compactly clustered in the middle, i.e., paths consisting
of random single-pixel transitions rarely have exceptional scores. If the random paths are spatially
smoothed, outliers become more likely (the paths could by coincidence mask out a whole particularly
relevant region), but the scores are still really unlikely to reach 0.9, something our optimisation
approach routinely attains.
F More examples
We provide in Figure 11 a series of ablation path results for one class in the ILSVRC14
datasetRussakovsky et al. (2015).
15
Under review as a conference paper at ICLR 2021
Optimised Path (filter: o=5)
20%
20%
scare 0.901
20%
40%
60%
20%
20%
scare 0456
20%
40%
60%
Ai
20%
20%
40%
Ai
40%
40%
*btaββn
40%
*btaββn
0.0 L
0%
0.0 —
0%
0.0 —
0%
0.0 ■_
0%
0.0 ■_
0%
0.0 ■_
0%
0.0 ■_
0%
0.0 ■_
0%
score 0.0U33
a a
20%
Optimised Path (filter σ=5)
score o.oo0525
score 0.705
SCere
Optimised Path (filter σ=5)
SCere 9.aZl
*6anon
Optimised Path (filter σ=5)
0⅝
20%
40%
60%
AbIatlan
40%	(
OPtlmlSe(I PathmIten α=5)
SCOre 0.773
20%
40%
Optimised Path (filter a=5)
Optimised Path (filter σ=51
Optimised Path (filter σ=5)
Optimised Path (filter σ=5)
Optimised Path (filter σ=5)
Optimised Path (filter σ=5)
SCOre
scoreQ-∞ι
Optimised Path (filter a=5)
Optimised Path (filter σ=5)
0%	20%	40%	¢0%	80%	100%
Ai
OPtlmlSe(I PathmIten α=5)
scare 0.937
20%
2皿
score 9343
Optimised Path (filter σ=5)
scare。."
20%
40%
*btaββn
Optimised Path (filter a=5)
Optimised Path (filter σ=5)
ECereO∙859
20%
OPtlmlSe(I Path (filter: α=5)
scare 0475
20%
40%
*btaββn
Optimised Path (filter a=5)
scare 0.903
20%
40%
*btaββn
Optimised Path (filter σ=5)
ECβrβ 0.943
20%
40%
60%
Optimised Path (filter σ=5)
20%
40%
Optimised Path (filter σ=5)
0%	20%	40%	¢0%	80%	100%
Ai
C)PtlmlSeei Pathmlten。=5)
scare 0.972
0%	20%	40% Kfii 80%	100%
AbUtkin
22




Ai

Figure 11: Some extra examples with EfficientNet and one class in the ILSVRC14 dataset. In some
cases, the network does not correctly classify the image, which explains the poor score.
16