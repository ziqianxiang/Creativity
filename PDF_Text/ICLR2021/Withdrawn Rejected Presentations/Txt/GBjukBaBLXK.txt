Under review as a conference paper at ICLR 2021
Conditional Coverage Estimation for High-
quality Prediction Intervals
Anonymous authors
Paper under double-blind review
Ab stract
Deep learning has achieved state-of-the-art performance to generate high-quality
prediction intervals (PIs) for uncertainty quantification in regression tasks. The
high-quality criterion requires PIs to be as narrow as possible, whilst maintaining
a pre-specified level of data (marginal) coverage. However, most existing works
for high-quality PIs lack accurate information on conditional coverage, which may
cause unreliable predictions if it is significantly smaller than the marginal cover-
age. To address this problem, we propose a novel end-to-end framework which
could output high-quality PIs and simultaneously provide their conditional cov-
erage estimation. In doing so, we design a new loss function that is both easy-
to-implement and theoretically justified via an exponential concentration bound.
Our evaluation on real-world benchmark datasets and synthetic examples shows
that our approach not only outperforms the state-of-the-arts on high-quality PIs
in terms of average PI width, but also accurately estimates conditional coverage
information that is useful in assessing model uncertainty.
1	Introduction
Prediction interval (PI) is poised to play an increasingly prominent role in uncertainty quantifica-
tion for regression tasks (Khosravi et al., 2010; 2011; Galvan et al., 2017; RosenfeId et al., 2018;
Tagasovska & Lopez-Paz, 2018; 2019; Romano et al., 2019; Wang et al., 2019; Kivaranovic et al.,
2020). A high-quality PI should be as narrow as possible, whilst maintaining a pre-specified level
of data coverage or marginal coverage (Pearce et al., 2018). Compared with PIs obtained based on
coverage-only consideration, the “high-quality” criterion is beneficial in balancing between marginal
coverage probability and interval width. However, the conditional coverage given a feature, which
is critical for making reliable context-based decisions, is unassessed and missing in most existing
works on high-quality PIs. In the presence of heteroskedasticity and model misspecification, the
marginal coverage can be very different from the conditional coverage at a given point, which af-
fects the downstream decision-making task that relies on the uncertainty information provided by the
PI. Our main goal is to meaningfully incorporate and assess conditional coverages in high-quality
PIs.
Conditional coverage estimation is challenging for two reasons. First is that the natural evaluation
metric of conditional coverage error, an Lp distance between the estimated and ground-truth con-
ditional coverages, is difficult to compute as it requires obtaining the conditional probability given
feature x, which is arguably as challenging as the regression problem itself. Our first goal in this
paper is to address this issue by developing a new metric called calibration-based conditional cov-
erage error for conditional coverage estimation measurement. Our approach is inspired from the
calibration notion in classification (Guo et al., 2017). The basic idea is to relax conditional coverage
at any given point to being averaged over all points that bear the same estimated value. An estima-
tor satisfying the relaxed property is regarded as well-calibrated. In regression, calibration-based
conditional coverage error provides a middle ground between the enforcement of marginal cover-
age (lacking any conditional information) and conditional coverage (computationally intractable).
Compared with conditional coverage, this middle-ground metric can be viewed as a “dimension re-
duction” of the conditioning variable from the original sample space to the space [0, 1], so that we
can easily discretize to compute the empirical metric values.
1
Under review as a conference paper at ICLR 2021
The second challenge is the discontinuity in the above metrics that hinders efficient training of PIs
that are both high-quality and possess reliable conditional coverage information. To address this,
we design a new loss function based on a combination of the high-quality criterion and a coverage
assessment loss. The latter can be flexibly added as a separate module to any neural network (NN)
used to train PIs. It is based on an empirical version of a tight upper bound on the coverage error in
terms of a KUllback-Leibler (KL) divergence, which can be readily employed for running gradient
descent. We theoretically show how training with our proposed loss function attains this upper-
bounding value via a concentration bound. We also demonstrate the empirical performance of our
approach in terms of PI quality and conditional coverage assessment compared with benchmark
methods.
Summary of Contributions: (1) We identify the conditional coverage estimation problem as a new
challenge for high-quality PIs and introduce a new evaluation metric for coverage estimation. (2)
We propose an end-to-end algorithm that can simultaneously construct high-quality PIs and generate
conditional coverage estimates. In addition, we provide theoretical justifications on the effectiveness
of our algorithm by developing concentration bounds relating the coverage assessment loss and con-
ditional coverage error. (3) By evaluating on benchmark datasets and synthetic examples, we empir-
ically demonstrate that our approach not only achieves high performance on conditional coverage
estimation, but also outperforms the state-of-the-art algorithms on high-quality PI generation.
2	Evaluating Conditional Coverage for High-Quality PIs
Let X ∈ X and Y ∈ Y ⊂ R be random variables denoting the input feature and label, where
the pair (X, Y ) follows an (unknown) ground-truth joint distribution π(X, Y ). Let π(Y |X) be
the conditional distribution of Y given X. We are given the training data D := {(xi, yi), i =
1,2, ∙∙∙ ,n} where (xi, yi) are i.i.d. realizations of random variables (X, Y). A PI refers to an
interval [L(x), U (x)] where L, U are two functions mapping from X to Y trained on the data D.
[L(x), U (x)] is called a PI at prediction level 1 - α (0 ≤ α ≤ 1) if its marginal coverage is not less
than 1 - α, i.e., P[Y ∈ [L(X), U (X)]|L, U] ≥ 1 - α where P is with respect to a new test point
(X,Y)〜π.
We say that [L(x), U (x)] is of high-quality if its marginal coverage attains a pre-specified target
prediction level and has a short width on average. In particular, a best-quality PI at prediction level
1 - α is an optimal solution to the following constrained optimization problem:
min E[U(X) - L(X)] subject to P[Y ∈ [L(X),U(X)]|L,U] ≥ 1 -α. (2.1)
L,U
The high-quality criterion has been widely adopted in previous work (see Section 6). However,
this criterion alone may fail to carry important model uncertainty information at specific test
points. Consider a simple example where x 〜 Uniform[0, 1], y = 0 for x ∈ [0, 0.95] and
y|x 〜 Uniform[0, 1] for x ∈ (0.95, 1]. Then according to equation 2.1, a best-quality 95% PI is
precisely L(x) = U(x) = 0 for all x ∈ [0, 1]. This PI has nonconstant coverage if we condition
at different points (1 for x ∈ [0, 0.95] and 0 for x ∈ (0.95, 1]), and can deviate significantly from
the overall coverage 95%. More examples to highlight the need of obtaining conditional coverage
information can be found in our numerical experiments in Section 5.1.
To mitigate the drawback of the high-quality criterion, we define:
Definition 2.1 (Conditional Coverage and Its Estimator). The conditional coverage associated with
a PI [L(x), U (x)] is A(x) := P[Y ∈ [L(X), U (X)]|L, U, X = x] for a.e. x ∈ X, where P is taken
with respect to π(Y |X). For a (conditional) Coverage estimator P, which is a measurable function
from X to [0, 1], we define its Lp conditional coverage error (CEp) as
gEp := ∣∣P[Y ∈ [L(X),U(X)]∣L,U,X] - P(X)忆⑺
where the Lp-norm is taken with respect to the randomness of X (1 ≤ p ≤ +∞).
Note that evaluating CEp relies on approximating the conditional coverage A(x), which can be
as challenging as the original prediction problem. To address this, we leverage the similarity of
estimating A(x) to generating prediction probabilities in binary classification, which motivates us to
2
Under review as a conference paper at ICLR 2021
borrow the notion of calibration in classification. This idea is based on a relaxed error criterion by
looking at the conditional coverage among all points that bear the same coverage estimator value,
instead of conditioning at any given point. The resulting error metric then only relies on probabilities
conditioned on variables in a much lower-dimensional space [0, 1] than X. To explain concretely,
we introduce a “perfect-calibrated coverage estimator” as:
Definition 2.2 (Perfect Calibration). A coverage estimator P is called a perfect-calibrated coverage
estimator associated with [L(x), U (x)] ifit satisfies
ʌ , - ʌ , ʌ , ʌ , - -
P(X) = P[Y ∈ [L(X),U(X)]∣L,U,P(X) = P(x)], a.e.P(x) ∈ [0,1].	(2.2)
where a.e. is with respect to the probability measure on [0, 1] induced by the random variable P(X).
Equation 2.2 means that a point x with conditional coverage estimate P(x) = p has an average
coverage of precisely p, among all points in X that possess the same conditional coverage estimated
value. That is, the average coverage of the PI restricted on the subset {x ∈ X : P(x) = p} should
be precisely p. Corresponding to Definition 2.2, we define:
Definition 2.3 (Calibration-based Error). An Lp (1 ≤ p ≤ +∞) calibration-based conditional
COVerage error, or COVerage error for short (CEp), of a COVerage estimator P is:
CEp := ∣∣P[Y ∈ [L(X),U(X)]∣L,U,P(X)] - P(X)k⑺	(2.3)
where Lp-norm is taken with respect to the randomness ofP(X).
In the above definition the conditional probability P[Y ∈ [L(X), U (X)]|L, U, P(X)] is a measur-
able function of random variable P(X), say γ(P(X)). By a change of variable,
CEp := ∣∣γ(P(X))- P(X)∣∣pp3)= / 1 ∣γ(t) - t|pdFp(x)(t)	(2.4)
where FP(X) is a probability distribution of P(X) on [0,1]. Here, CEp only requires estimating
γ(t) for t ∈ [0, 1], which can be done easily by discretizing [0, 1] for empirical calculation. We call
the empirical Lp calibration-based conditional coverage error ECEp. More details of this empirical
error can be found in Appendix A.4.
A calibration-based error CEp provides a middle ground between the enforcement of marginal
coverage and conditional coverage. The ground-truth conditional coverage is perfectly calibrated,
but not vice versa. However, if we enforce the perfect calibration criterion for a coverage estimator
to hold when restricted to any measurable subset in X, then the choice of estimator will reduce
uniquely to the conditional coverage (Definition A.1 and Lemma A.2). In this sense, CEp is an
error metric that is a natural relaxation of CEp , and although less precise, CEp is computationally
much more tractable than CEp .
Evaluation Metric for Coverage Estimator. We use ECE1 as the primary evaluation metric to
measure the quality of a coverage estimator. A high ECE1 value of a coverage estimator indicates
an unreliable coverage estimation while a small ECE1 value indicates that the coverage estimator
is close to the perfect-calibrated property. Ideally, an effective algorithm should output a coverage
estimator with a small ECE1 value.
3 Methodology
We propose a novel end-to-end algorithm, named coverage assessment network (CaNet), to simulta-
neously generate a coverage estimator along with the high-quality PI. As illustrated in Figure 1, our
CaNet consists of two major modules: (1) predictor module and (2) coverage assessment mod-
ule (Ca-Module). The predictor module provides the upper and lower bound of the estimated PIs.
Meanwhile, the Ca-Module is added to the output layer to access the conditional coverage infor-
mation of PIs from the predictor module. Our model is jointly optimized by three loss functions:
coverage assessment loss LCA, intervals width loss LIW, and coverage probability loss LCP. Ben-
efited from these powerful modules, the CaNet can generate and Validate the coverage estimator at
the same time without any requirement for further post-processing steps.
3
Under review as a conference paper at ICLR 2021
Figure 1: The framework of our proposed coverage assessment network (CaNet).
Coverage Assessment Module. Our Ca-Module consists of two neurons fully connected to the
last hidden layer to estimate the conditional coverage. After passing through the softmax activation
function, it outputs a two-point probability distribution P (x), 1 - P (x) where P (x) is the coverage
estimator of the PI from the predictor module. Our Ca-Module can be easily integrated into the
output layer of deep neural networks to estimate their conditional coverage.
Loss Function Design and Tuning Procedure. Our loss function is a sum of the predictor loss and
the coverage loss. The predictor loss aims to narrow the prediction intervals as much as possible,
while maintaining a specified marginal coverage of data. Inspired by (Khosravi et al., 2010; 2011;
Pearce et al., 2018; Rosenfeld et al., 2018), our predictor loss is formed by the sum of intervals width
(IW) loss LIW and coverage probability (CP) loss LCP :
1n
LIW = -f(U (Xi)- L(Xi)),
ni=1
nn
LCP = - X ki,	CP = — X ki,
ni=1 ni=1
(3.1)
(3.2)
where ki indicates whether each data point has been captured by the PIs: ki = 1 if L(Xi) ≤ yi ≤
U(Xi) and ki = 0 otherwise. k is a soft version of ki, which is defined as: ki := σ(λ3(U(Xi) — yi)) ∙
σ(λ3(yi — L(xi))), where λ3 ≥ 0 is a tunable parameter and σ(t) := is the sigmoid function.
Therefore, LCP is a soft version of CP that can be used for gradient descent. Associated with the
Ca-Module, we introduce a coverage assessment loss LCA to estimate the conditional coverage:
1n
LCA = - X (ki log(P(Xi)) + (1 — ki)log(1 — P(Xi)))	(3.3)
n i=1
We will show in Section 4 that the expectation of coverage assessment loss LCA provides an upper
bound for both the conditional coverage error (Definition 2.1) and calibration-based conditional cov-
erage error (Definition 2.3). Hence, minimizing LCA contributes to the recovery of the conditional
coverage. In order to run gradient-based methods, we replace the discrete indicator (ki , 1 — ki) in
LCA with its soft version (ki, 1 — ki):
n
1
LCA = - £ (ki log(P(Xi)) + (1 — ki) log(1 — P(Xi)))	(3.4)
n i=1
Our total loss function for the CaNet is defined as:
Total Loss = LIW + λ1 (1 — LCP ) + λ2LCA	(3.5)
where λ1 ≥ 0, λ2 ≥ 0 are tunable parameters. We propose an easy-to-implement yet effective tuning
procedure to pick up these parameters. Please refer to Appendix D for more algorithm details.
Deep Ensembles. Following previous research (Lee et al., 2015; Lakshminarayanan et al., 2017;
Pearce et al., 2018; Fort et al., 2019; Ovadia et al., 2019; Gustafsson et al., 2020; Pearce et al.,
2020), we apply the deep ensemble technique to provide more robust and better results. During the
training period, with the same hyperparameters λi, i = 1, 2, 3, m networks are trained with different
4
Under review as a conference paper at ICLR 2021
♦ ∙ . ∙ 1 ∙ . ∙	EI	1∙	1 . i'	■ . Λ	.	1	1	. 1	/Γτ^ / ∖ ττ∕ ∖1 τ∖ / ∖ Λ
initializations. The prediction results from i-th network are denoted as: ([Li (x), Ui(x)], Pi (x), 1 -
τ∖ /	∖ ∖	T-,∙	11	.1	.	. r∙	Z-X TL T . ♦
Pi(x)). Finally, the output from CaNet is:
Lower bound
U pper bound
Coverage estimator
Pm ɪ
Pm=I m P
(3.6)
m
4 Theoretical Analysis
In this section, we provide theoretical insights that minimizing LCA is equivalent to minimizing a
tight upper bound of the conditional coverage error and thus can recover the true conditional cover-
age. To achieve this, we first prove that both CEp and CEp are bounded above by the expectation
of a KUllback-Leibler divergence-type random variable K1 (X). Then We show that LCA is an
empirical counterpart of K1(X) and establish a concentration bound between LCA and E[K1(X)].
Theorem 4.1. Let A(x) := P[Y ∈ [L(X), U (X)]|L, U, X = x] be the conditional coverage in
Definition2.1. Let K (x) = A(x) log (A(X)) + (1 一 A(x))log (I-A(X)) .Then
αp∕2
___	11	α αp/2
CEp ≤ CEp ≤ (2E[K(X)])	,∀1 ≤ P ≤ +∞
where a? = 1, ∀1 ≤ P ≤ 2 and a? = 2, ∀2 ≤ P ≤ +∞. Moreover, the inequality is attainable if,
e.g., P (x) equals the conditional coverage A(x).
From Theorem 4.1, we see that minimizing E[K(x)] is eqUivalent to minimizing a tight Upper boUnd
for the coverage error. For every x, K(x) is the KUllback-Leibler divergence between the distribU-
tions represented by (P (x), 1 一 P (x)) and (A(x), 1 一 A(x)). K(x) = K0(x) + K1(x), where
_ _ , . . , , _ ........ , . , , . _ , . , . . . , . . , , _ , ʌ , .. ,
Ko(x) = A(X) log(A(x)) + (1 — A(x))log(1 — A(X)) and Kι(x) = —A(x)log(P(x)) — (1 —
A(x))log(1 — P(X)). Minimizing E[K(X)] over P is equivalent to minimizing E[Kι(X)]. The
type of resUlts in Theorem 4.1 that boUnds an Lp conditional coverage error via a KUllback-Leibler-
type error is new as far as we know. Next, to show LCA approximates E[K1(X)], we need the
following assumptions:
Assumption 4.2. The four classes of functions ([L(X), U (X)], P (X), 1 — P (X)) output by the neural
network (NN) in Figure 1 have finite VC dimensions, say they are bounded above by V0.
Assumption 4.2 holds for a wide range of NNs (e.g., Theorem 8.14 in Anthony & Bartlett (2009),
Theorem 7 in Bartlett et al. (2019)). In particular, it holds for the one we adopt in the experiments
(where we use the ReLU-activated NN to construct ψi, i = 1, 2, 3, 4; see Section 5):
Theorem 4.3. Suppose ψi, i = 1, 2, 3, 4 are the pre-activated output neurons of the NN in Figure 1
using the ReLU activation function. Then Assumption 4.2 holds. Moreover, suppose the NN has W
parameters and U computation units (nodes). Then V0 = O(WU).
Assumption 4.4. | log(P(x))∣ ≤ M, | log(1 — P(x))∣ ≤ M for all X and P.
This is a natural assumption in practice because log(P (X)) and log(1 — P (X)) are replaced by
log(P (X) + ) and log(1 — P(X) + ) respectively to avoid explosion when implementing the algo-
rithm. In particular, in our experiments in Section 5, = 0.16 and thus M = 14. Let
F = {f(X, y) = Iy∈[L(X),U(X)] : L, U are output by the NN},
G = {P(x) : P is output by the NN}.
Theorem 4.5. Suppose Assumptions 4.2 and 4.4 hold. The training data D = {(Xi, yi), i =
1, 2, ∙∙∙ ,n} where (Xi, yi) are i.i.d. samples 〜 π. Recall that the (hard) Coverage estimator assess-
ment loss is LCA = -1 Pn=I f(Xi, yi) log(P(Xi)) + (1 — f (Xi ,yi))log(1 — P(Xiy)) . Then for
any t > 0, we have
P ( sup	|Lca — E[K1(X)]| ≥ t ) ≤ C*e-inM22.
∖∈ ∈F ,P∈G	J
where C * only depends on Vo in Assumption 4.2.
5
Under review as a conference paper at ICLR 2021
Theorem 4.5 shows that the coverage assessment loss approximates E[K1 (x)] well with an expo-
nential tail bound. The difficulty in analyzing Theorem 4.5 lies in the fact that the hypothesis classes
in Assumption 4.2 (which are constructed by the NN) are different from the hypothesis class used
in LCA . To overcome this difficulty, we use the theory of VC-subgraph classes to connect the VC
dimension among multiple hypothesis classes, including the class of ψi , the four classes of output
functions, and F, log G . Then we establish the covering number bound for the class F and log G ,
and finally prove Theorem 4.5. To conclude, minimizing E[K1 (X)] over P is equivalent to mini-
mizing E[K (X)], which in turn is minimizing a tight upper bound for the coverage assessment loss.
Our coverage assessment loss empirically approximates E[K1 (X)] well, so that its minimization
can ultimately reduce the conditional coverage error.
5 Experiments
Experimental Setup. We empirically verify the effectiveness of our proposed CaNet on both syn-
thetic examples and benchmark regression datasets. These datasets have been widely used for the
evaluation of methods in regression tasks (HernandeZ-Lobato & Adams, 2015; Gal & Ghahramani,
2016; Lakshminarayanan et al., 2017; Rosenfeld et al., 2018; Pearce et al., 2018; Zhu et al., 2019).
In addition, we adopt the same experimental procedure in Pearce et al. (2018) for data normaliZa-
tion and dataset splitting. To avoid overfitting, we apply a simple network architecture with only
2 hidden layers and each hidden layer has 64 neurons. For each hidden layer, the ReLU activation
function is applied to capture the non-linear features. We empirically set the ensemble number m
to 5, as the smallest number leading to a stable prediction results. Please refer to Appendix E for
implementation details, including those for baseline algorithms.
Evaluation Metrics. To evaluate the conditional coverage estimation of our CaNet, we exam-
ine the quality of our Ca-Module measured by the empirical coverage error ECE1 over a par-
tition ∆. ∆ is constructed by equally dividing the width of [0, 1] into M sub-intervals. The
value of M depends on the siZe of the dataset, which is determined by the following strategy:
M = min{bthe number of data in validation/50c + 1, 20}. In addition, we also report the IW and
CP, where IW = 1 Pn=I(U(Xi) — L(Xi)) (equation 3.1) and CP = 1 Pn=I ki, (equation 3.2) to
show the effectiveness of our predictor module under the high-quality criteria.
5.1 Conditional Coverage on Synthetic Examples
Figure 2: Prediction and conditional coverage of 95% PIs on synthetic examples. (a) CP =
0.95, IW = 0.40, ECE1 = 0.62%. (b) CP = 0.96, IW = 0.40, ECE1 = 0.12%. (c)
CP = 0.95, IW = 0.50, ECE1 = 0.65%. The predicted coverage estimation from CaNet is
highly consistent with the conditional coverage under different noise settings.
In this section, we conduct a series of experiments on synthetic examples to directly compare our
prediction results with the ground-truth conditional coverage. In these examples, the conditional
coverage can be analytically calculated under the known data distribution. Figure 2 compares the
conditional coverage with our predicted coverage under the following settings: X 〜Uniform[—2, 2]
and y|x is drawn from fi(x) = 1 Sin(X) + ε,(x), X ∈ [—2, 2] where
ε1(X) =	0.1	× N(0, 1),	ε2(X)	= 0.1|X|	×	N(0, 1),	ε3 (X)	= 0.1|X|	×	t4.
6
Under review as a conference paper at ICLR 2021
N(0, 1) is the standard Gaussian variable and t4 is the standard t random variable with 4 degrees of
freedom. Then, the conditional coverage in Definition 2.1 can be analytically calculated as:
P[Y ∈ [L(X), U(X)]|L, U,X = x] = Fi(U(X)- 1 Sin(X))- Fi(L(X)- 3 Sin(X))
Dataset	NNKCDE		QRF		SCL		QD-Ens		CaNet: λ2		= 0.15 for all datasets		
	CP	IW	CP	IW	CP	IW	CP	IW	CP	IW	ECE1	λ1	λ3
Boston	0.95	1.54	0.96	2.22	0.97	1.45	0.92	1.16	0.95	1.04	1.38%	6.0	1800
Concrete	0.95	1.85	0.99	2.53	0.96	1.54	0.94	1.09	0.95	1.13	0.24%	6.5	1000
Energy	0.97	0.54	0.98	0.87	0.95	0.77	0.97	0.47	0.99	0.37	0.76%	5.0	500
Kin8nm	0.99	2.76	0.99	3.27	0.94	1.20	0.96	1.25	0.95	1.04	1.32%	3.6	300
Plant	0.95	0.88	0.97	1.05	0.95	0.88	0.95	0.86	0.95	0.84	0.38%	3.3	700
Protein	0.93	1.98	0.98	2.42	0.95	2.81	0.95	2.27	0.95	2.26	0.41%	8.3	300
Wine	0.96	2.64	0.93	3.18	0.96	3.44	0.92	2.33	0.95	2.59	0.42%	19	1100
Yacht	0.95	1.15	0.95	1.72	0.95	0.57	0.96	0.17	0.98	0.16	0.80%	1.6	500
Table 1: Evaluation metrics of different models on benchmark datasets. The CP values are marked
in blue if they meet the 95% prediction level. The best IW results, marked in bold, are achieved
by models with the smallest IW value among those that meet the 95% prediction level. Our model
outperforms the baseline algorithms on high-quality PI generation. Meanwhile, it provides accurate
coverage estimation on real-world datasets.
Kin8nm: λ2		= 0.15, IW	λ = 300 ECEi	Plant: λ2 =		0.15, λ3 IW	= 700 ECE1	Protein: λ2 =		0.15,λ IW	3 = 300 ECE1
λ1	CP			λ1	CP			λι	CP		
1.9	0.83	0.73	1.54%	1.4	0.80	0.56	1.23%	4.8	0.82	1.56	0.82%
2.1	0.85	0.77	1.59%	1.5	0.84	0.62	1.36%	5.1	0.86	1.70	0.71%
2.3	0.87	0.80	1.47%	1.6	0.85	0.63	0.86%	5.4	0.88	1.79	1.25%
2.4	0.88	0.84	1.21%	1.8	0.86	0.64	1.36%	5.6	0.90	1.84	1.04%
2.6	0.90	0.87	1.50%	2.0	0.89	0.70	0.51%	6.3	0.91	1.95	0.66%
2.9	0.91	0.89	0.50%	2.4	0.91	0.75	1.15%	6.5	0.92	2.07	1.36%
3.1	0.92	0.94	0.49%	2.6	0.92	0.80	1.29%	7.0	0.93	2.11	1.23%
3.4	0.94	1.00	0.82%	3.0	0.94	0.83	0.23%	7.8	0.94	2.13	0.99%
3.6	0.95	1.04	1.32%	3.3	0.95	0.84	0.38%	8.3	0.95	2.26	0.41%
3.8	0.96	1.06	1.25%	4.0	0.96	0.89	0.80%	9.3	0.96	2.36	0.52%
Table 2: ECE1 results of our model on benchmark datasets with different coverage probabilities.
Our CaNet achieves robust performance on real-world datasets at different prediction levels.
where Fi is the cumulative distribution function of N(0, 0.12) for i = 1, N(0, (0.1X)2) for i = 2,
and 0.1|X| × t4 for i = 3. As shown in Figure 2, the conditional coverages of high-quality PIs
at different points diverge among each other and they deviate from the marginal coverage. Thus,
having access to the marginal coverage for the whole dataset is not sufficient for decision making,
which highlights the need of conditional coverage. In addition, the predicted coverage estimator of
our model is highly consistent with the conditional coverage on all of the synthetic examples. These
results confirm that our CaNet can accurately estimate the conditional coverage on noisy datasets.
5.2	Performance of PIs on Benchmark Datasets
In this section, we compare the predictor module of our CaNet on real-world benchmark datasets
with following baseline algorithms: (1) nearest-neighbors kernel conditional density estimation
(NNKCDE) (Dalmasso et al., 2020), (2) quantile regression forest (QRF) (Meinshausen, 2006),
(3) split conformal learning (SCL) (Lei et al., 2018) and (4) the quality-driven PI method (QD-Ens)
(Pearce et al., 2018). We quote the results from (Pearce et al., 2018) as a comparison since we share
the same experiment setup. Table 1 reports the results of CP , IW and ECE1 for generating PIs
at 95% prediction level on benchmark datasets. We employed the criteria in Pearce et al. (2018)
to evaluate the performance of PIs: the best IW is achieved by the model with the smallest IW
value among those with CP ≥ 95%. As can be seen, our model achieves the best performance on
PI generation under the high-quality criteria. With special consideration on interval width quality,
it obtains the smallest average interval width (IW) while maintaining high coverage probability
(CP ≥ 95%) on all datasets.
7
Under review as a conference paper at ICLR 2021
5.3	Performance of Coverage Estimator on Benchmark Datasets
Coverage for 95% PIs. We use ECE1 to evaluate the coverage estimation performance on real-
world datasets as the conditional coverage is unknown. As shown in Table 1, the ECE1 on all
experiments are generally around or less than 1%, with better performance on larger datasets. The
coverage estimators produced by CaNet have small ECE1 values, which are very close to the
perfect-calibrated coverage estimators (Definition 2.2). Compared with ECE1 values obtained from
the state-of-the-art algorithms in classification tasks (Guo et al., 2017; Kull et al., 2019), the ECE1
values from CaNet are similar and sometimes less than their post-calibrated ECE1 results (usually
around 1% to 3%), even though the size of most regression datasets are smaller than the classifica-
tion datasets. These results further demonstrate that our CaNet can accurately estimate the coverage
information of 95% high-quality PIs on real-world regression tasks.
Coverage for PIs at Different Prediction Levels. We conduct multiple experiments on different
PI prediction levels to show the robustness of our CaNet. By only modifying the parameter λ1 in
Equation 3.5, our Ca-Module could get access to different levels of coverage probability. Table 2
reports the CP, I W and ECE1 values from the CaNet at different PI prediction levels on three
benchmark datasets. Results for more datasets can be found in Appendix E. As can be seen, all
ECEi values in Table 2 are fairly small (〜1%), demonstrating the stability of our proposed model.
Thus, our CaNet can provide accurate coverage estimation on PIs at different prediction levels.
These results demonstrate the robustness of our CaNet on real-world datasets, further suggesting its
broad applicability.
6	Related Work
Prediction Interval Estimation. High-quality PIs, which can be viewed via a constrained optimiza-
tion problem where the constraint concerns marginal coverage and the objective is the PI width, has
been extensively studied in Khosravi et al. (2010; 2011); GaIvan et al. (2017); Pearce et al. (2018);
Rosenfeld et al. (2018); Zhang et al. (2019); Zhu et al. (2019). Such intervals are in the same spirit
as the highest density intervals in statistics (Box & Tiao, 2011). While powerful, these approaches
could not directly provide the conditional coverage information investigated in this work. Coverage-
only criteria, on the other hand, focus solely on coverage satisfaction as the guarantee. These ap-
proaches include conformal learning (CL) and its conditional variants (Vovk et al., 2005; 2009; Lei
& Wasserman, 2014; Lei et al., 2015; 2018; Kuchibhotla & Ramdas, 2019; Romano et al., 2019;
Barber et al., 2019a;b). CL is desirably distribution- or model-free, and in many cases enjoys finite-
sample guarantees. However, unlike high-quality PIs, they do not explicitly account for the interval
width as a quality metric. We also mention conditional density estimation (Holmes et al., 2007; Du-
tordoir et al., 2018; Izbicki & Lee, 2016; Dalmasso et al., 2020; Freeman et al., 2017; Izbicki et al.,
2017) and closely relatedly quantile regression (Koenker & Hallock, 2001; Meinshausen, 2006) as
PI construction approaches by converting from the estimated conditional quantile function. These
approaches focus on the quality of conditional distribution/quantile, instead of the high-quality cri-
terion only. In this work, we use deep learning to construct high-quality PIs (Khosravi et al., 2010;
Pearce et al., 2018; Kivaranovic et al., 2020).
Uncertainty Measurement in Deep Learning. The Bayesian framework offers principled ap-
proaches for model uncertainty measurement by computing the posterior distribution over the NN
parameters (MacKay, 1992; Neal, 2012). These approaches can also be used to construct PIs. How-
ever, they provide a different perspective from the frequentist view taken in this paper, and they
focus on the parameter uncertainty of the NN instead of the coverage over a test point. In addi-
tion, exact Bayesian inference is computationally intractable for deep neural networks, making it
less practical to implement. Gal & Ghahramani (2016) applied a Monte Carlo dropout method to
proxy the inference. Directly generated from the networks, softmax response is also commonly
used for uncertainty measurement on deep learning models (Bridle, 1990; Lakshminarayanan et al.,
2017; Geifman et al., 2018; Sensoy et al., 2018; Ozbulak et al., 2018). Moreover, Niculescu-Mizil
& Caruana (2005) showed that NNs typically produce well-calibrated probabilities on binary clas-
sification tasks without the need of any post-hoc techniques. In this paper, we also follow this line
of work and use the softmax output to access the model uncertainty information.
8
Under review as a conference paper at ICLR 2021
7	Conclusion
In this paper, we identify and investigate the conditional coverage estimation problem for high-
quality PIs, which is critical for risk-based decision making in regression fields. To address the
challenge, we propose an end-to-end algorithm with two powerful modules: coverage assessment
module and predictor module. Benefited from these powerful modules, our model can generate
and validate the coverage estimator without any requirement for further post-processing steps. In
addition, we conduct theoretical analysis to show the effectiveness of our proposed model. Exper-
imental results on synthetic examples and benchmark datasets further demonstrate that our model
can robustly provide accurate coverage estimation while simultaneously producing a high-quality
PI. Moreover, our Ca-Module can be easily integrated into other deep-learning-based algorithms to
get access to their coverage information, opening up more opportunities for broad applications. In
the future, we will extend our work by conducting comparison studies with Bayesian methods.
References
Martin Anthony and Peter L Bartlett. Neural network learning: Theoretical foundations. Cambridge
University Press, 2009.
Rina Foygel Barber, Emmanuel J Candes, Aaditya Ramdas, and Ryan J Tibshirani. The limits of
distribution-free conditional predictive inference. arXiv preprint arXiv:1903.04684, 2019a.
Rina Foygel Barber, Emmanuel J Candes, Aaditya Ramdas, and Ryan J Tibshirani. Predictive
inference with the jackknife+. arXiv preprint arXiv:1905.02928, 2019b.
Peter L Bartlett, Nick Harvey, Christopher Liaw, and Abbas Mehrabian. Nearly-tight VC-dimension
and pseudodimension bounds for piecewise linear neural networks. Journal of Machine Learning
Research, 20(63):1-17, 2019.
George EP Box and George C Tiao. Bayesian inference in statistical analysis, volume 40. John
Wiley & Sons, 2011.
John S Bridle. Probabilistic interpretation of feedforward classification network outputs, with rela-
tionships to statistical pattern recognition. In Neurocomputing, pp. 227-236. Springer, 1990.
Niccolo Dalmasso, Taylor PosPisiL Ann B Lee, Rafael Izbicki, Peter E Freeman, and Alex I Malz.
Conditional density estimation tools in python and r with applications to photometric redshifts
and likelihood-free cosmological inference. Astronomy and Computing, 30:100362, 2020.
Vincent Dutordoir, Hugh Salimbeni, James Hensman, and Marc Deisenroth. Gaussian Process con-
ditional density estimation. In Advances in neural information processing systems, PP. 2385-
2395, 2018.
Stanislav Fort, Huiyi Hu, and Balaji Lakshminarayanan. DeeP ensembles: A loss landscaPe Per-
sPective. arXiv preprint arXiv:1912.02757, 2019.
Peter E Freeman, Rafael Izbicki, and Ann B Lee. A unified framework for constructing, tuning and
assessing Photometric redshift density estimates in a selection bias setting. Monthly Notices of
the Royal Astronomical Society, 468(4):4556-4565, 2017.
Yarin Gal and Zoubin Ghahramani. DroPout as a bayesian aPProximation: RePresenting model
uncertainty in deeP learning. In international conference on machine learning, PP. 1050-1059,
2016.
Ines M Galvan, Jose M Valls, Alejandro Cervantes, and Ricardo Aler. MUIti-objective evolutionary
oPtimization of Prediction intervals for solar energy forecasting with neural networks. Information
Sciences, 418:363-382, 2017.
Yonatan Geifman, Guy Uziel, and Ran El-Yaniv. Bias-reduced uncertainty estimation for deeP
neural classifiers. In International Conference on Learning Representations, 2018.
9
Under review as a conference paper at ICLR 2021
Chuan Guo, Geoff Pleiss, Yu Sun, and Kilian Q Weinberger. On calibration of modern neural
networks. In Proceedings of the 34th International Conference on Machine Learning-Volume 70,
pp.1321-1330.JMLR. org, 2017.
Fredrik K Gustafsson, Martin Danelljan, and Thomas B Schon. Evaluating scalable bayesian deep
learning methods for robust computer vision. In Proceedings of the IEEE/CVF Conference on
Computer Vision and Pattern Recognition Workshops, pp. 318-319, 2020.
Jose MigUel Hernandez-Lobato and Ryan Adams. Probabilistic backpropagation for scalable learn-
ing of bayesian neural networks. In International Conference on Machine Learning, pp. 1861-
1869, 2015.
Michael P Holmes, Alexander G Gray, and Charles Lee Isbell Jr. Fast nonparametric conditional
density estimation. In Proceedings of the Twenty-Third Conference on Uncertainty in Artificial
Intelligence, pp. 175-182, 2007.
Rafael Izbicki and Ann B Lee. Nonparametric conditional density estimation in a high-dimensional
regression setting. Journal of Computational and Graphical Statistics, 25(4):1297-1316, 2016.
Rafael Izbicki, Ann B. Lee, and Peter E. Freeman. Photo-z estimation: An example of nonparamet-
ric conditional density estimation Under selection bias. Ann. Appl. Stat., 11(2):698-724, 06 2017.
doi: 10.1214/16-AOAS1013. URL https://doi.org/10.1214/16-AOAS1013.
Abbas Khosravi, Saeid Nahavandi, DoUg Creighton, and Amir F Atiya. Lower Upper boUnd estima-
tion method for constrUction of neUral network-based prediction intervals. IEEE transactions on
neural networks, 22(3):337-346, 2010.
Abbas Khosravi, Saeid Nahavandi, DoUg Creighton, and Amir F Atiya. Comprehensive review
of neUral network-based prediction intervals and new advances. IEEE Transactions on neural
networks, 22(9):1341-1356, 2011.
Danijel Kivaranovic, Kory D Johnson, and Hannes Leeb. Adaptive, distribUtion-free prediction
intervals for deep networks. In International Conference on Artificial Intelligence and Statistics,
pp. 4346-4356, 2020.
Roger Koenker and Kevin F Hallock. QUantile regression. Journal of economic perspectives, 15(4):
143-156, 2001.
Michael R Kosorok. Introduction to empirical processes and semiparametric inference. Springer
Science & BUsiness Media, 2007.
ArUn K KUchibhotla and Aaditya K Ramdas. Nested conformal prediction and the generalized
jackknife+. arXiv preprint arXiv:1910.10562, 2019.
Meelis Kull, Miquel Perello Nieto, Markus Kangsepp, Telmo Silva Filho, Hao Song, and Peter
Flach. Beyond temperatUre scaling: Obtaining well-calibrated mUlti-class probabilities with
dirichlet calibration. In Advances in Neural Information Processing Systems, pp. 12295-12305,
2019.
Ananya Kumar, Percy S Liang, and Tengyu Ma. Verified uncertainty calibration. In Advances in
Neural Information Processing Systems, pp. 3787-3798, 2019.
Balaji Lakshminarayanan, Alexander Pritzel, and Charles Blundell. Simple and scalable predictive
uncertainty estimation using deep ensembles. In Advances in Neural Information Processing
Systems, pp. 6402-6413, 2017.
Stefan Lee, Senthil Purushwalkam, Michael Cogswell, David Crandall, and Dhruv Batra. Why
m heads are better than one: Training a diverse ensemble of deep networks. arXiv preprint
arXiv:1511.06314, 2015.
Jing Lei and Larry Wasserman. Distribution-free prediction bands for non-parametric regression.
Journal of the Royal Statistical Society: Series B (Statistical Methodology), 76(1):71-96, 2014.
10
Under review as a conference paper at ICLR 2021
Jing Lei, Alessandro Rinaldo, and Larry Wasserman. A conformal prediction approach to explore
functional data. Annals OfMathematics and Artificial Intelligence, 74(1-2):29-43, 2015.
Jing Lei, Max G’Sell, Alessandro Rinaldo, Ryan J Tibshirani, and Larry Wasserman. Distribution-
free predictive inference for regression. Journal of the American Statistical Association, 113
(523):1094-1111, 2018.
David JC MacKay. Bayesian methods for adaptive models. PhD thesis, California Institute of
Technology, 1992.
Pascal Massart. Concentration inequalities and model selection, volume 6. Springer, 2007.
Nicolai Meinshausen. Quantile regression forests. Journal of Machine Learning Research, 7(Jun):
983-999, 2006.
Radford M Neal. Bayesian learning for neural networks, volume 118. Springer Science & Business
Media, 2012.
Alexandru Niculescu-Mizil and Rich Caruana. Predicting good probabilities with supervised learn-
ing. In Proceedings of the 22nd International Conference on Machine Learning, pp. 625-632,
2005.
Jeremy Nixon, Mike Dusenberry, Linchuan Zhang, Ghassen Jerfel, and Dustin Tran. Measuring
calibration in deep learning. arXiv preprint arXiv:1904.01685, 2019.
Yaniv Ovadia, Emily Fertig, Jie Ren, Zachary Nado, David Sculley, Sebastian Nowozin, Joshua
Dillon, Balaji Lakshminarayanan, and Jasper Snoek. Can you trust your model’s uncertainty?
evaluating predictive uncertainty under dataset shift. In Advances in Neural Information Process-
ing Systems, pp. 13991-14002, 2019.
Utku Ozbulak, Wesley De Neve, and Arnout Van Messem. How the softmax output is misleading
for evaluating the strength of adversarial examples. arXiv preprint arXiv:1811.08577, 2018.
Tim Pearce, Mohamed Zaki, Alexandra Brintrup, and Andy Neely. High-quality prediction intervals
for deep learning: A distribution-free, ensembled approach. arXiv preprint arXiv:1802.07167,
2018.
Tim Pearce, Felix Leibfried, and Alexandra Brintrup. Uncertainty in neural networks: Approxi-
mately bayesian ensembling. In International conference on artificial intelligence and statistics,
pp. 234-244. PMLR, 2020.
Yaniv Romano, Evan Patterson, and Emmanuel Candes. Conformalized quantile regression. In
Advances in Neural Information Processing Systems, pp. 3543-3553, 2019.
Nir Rosenfeld, Yishay Mansour, and Elad Yom-Tov. Discriminative learning of prediction intervals.
In International Conference on Artificial Intelligence and Statistics, pp. 347-355, 2018.
Murat Sensoy, Lance Kaplan, and Melih Kandemir. Evidential deep learning to quantify classifica-
tion uncertainty. In Advances in Neural Information Processing Systems, pp. 3179-3189, 2018.
Eduardo D Sontag. VC dimension of neural networks. NATO ASI Series F Computer and Systems
Sciences, 168:69-96, 1998.
Natasa Tagasovska and David Lopez-Paz. Frequentist uncertainty estimates for deep learning. arXiv
preprint arXiv:1811.00908, 2018.
Natasa Tagasovska and David Lopez-Paz. Single-model uncertainties for deep learning. In Advances
in Neural Information Processing Systems, pp. 6417-6428, 2019.
Aad W Van der Vaart and Jon A Wellner. Weak Convergence and Empirical Processes with Appli-
cations to Statistics. Springer, 1996.
Vladimir Vovk, Alex Gammerman, and Glenn Shafer. Algorithmic learning in a random world.
Springer Science & Business Media, 2005.
11
Under review as a conference paper at ICLR 2021
Vladimir Vovk, Ilia Nouretdinov, Alex Gammerman, et al. On-line predictive linear regression. The
AnnalsofStatistics, 37(3):1566-1590, 2009.
Bin Wang, Jie Lu, Zheng Yan, Huaishao Luo, Tianrui Li, Yu Zheng, and Guangquan Zhang. Deep
uncertainty quantification: A machine learning approach for weather forecasting. In Proceedings
of the 25th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,
pp. 2087-2095, 2019.
Haozhe Zhang, Joshua Zimmerman, Dan Nettleton, and Daniel J Nordman. Random forest predic-
tion intervals. The American Statistician, pp. 1-15, 2019.
Lin Zhu, Jiaxing Lu, and Yihong Chen. HDI-forest: highest density interval regression forest. In
Proceedings of the 28th International Joint Conference on Artificial Intelligence, pp. 4468-4474.
AAAI Press, 2019.
12
Under review as a conference paper at ICLR 2021
This Appendix presents further results and discussions and it consists of five parts. Appendix A
gives more detailed properties on coverage estimator and coverage error. Appendix B contains the
mathematical argument for Theorem 4.1. Appendix C discusses how to achieve Assumption 4.2 and
the proof of Theorem 4.3 and 4.5. Appendix D presents our algorithm details as a supplement to
Section 3. Appendix E illustrates experimental details and more experimental results.
A	Further Details on Coverage Estimator and Coverage Error
A.1 Coverage Probability Types of PIs
Zhang et al. (2019) introduce the following four coverage probability types of PIs. In general, most
of the coverage in PIs considered in the literature falls into one of these types.
Type I: P[Y ∈ [L(X), U (X)]] (marginal coverage);
Type II: P[Y ∈ [L(X), U (X)]|L, U] (conditional coverage given the PI);
Type III: P[Y ∈ [L(X), U (X)]|X = x] (conditional coverage given X = x);
Type IV: P[Y ∈ [L(X), U (X)]|L, U, X = x] (conditional coverage given the PI and X = x).
Note that in high-quality criteria, only Type II coverage is considered in the constraint but Type IV
coverage is lacking. Since Type I and III are not considered in our paper, for simplicity Type II
coverage is called the marginal coverage, and Type IV coverage is called the conditional coverage
in Definition 2.1.
Throughout Appendix, we let A(x) := P[Y ∈ [L(X), U (X)]|L, U, X = x] denote the conditional
coverage in Definition 2.1. Moreover, since we only concern Type II and IV coverage in this work,
we make the following convention. Throughout the Appendix A-B, P and E should be understood
as probability and expectation conditional on L, U. So for A(x), we could simply write A(x) :=
P[Y ∈ [L(X), U (X)]|X = x] and omit “conditional on L, U”.
A.2 The Terminology “Perfect-Calibrated”
The terminology “perfect-calibrated” is borrowed from the confidence calibration in classification
tasks. We first review the name of “confidence” in classification.
Confidence calibration is the problem of predicting probability estimates representative of the true
correctness likelihood (Guo et al., 2017). Intuitively, an reliable confidence should reflect the true
correctness likelihood of the prediction (Kumar et al., 2019). For example, given 100 predictions,
each with confidence of 0.8, we expect that 80 should be correctly classified (Guo et al., 2017).
Now let h be the prediction of any models, which is a map from X to Y , trained on the data D .
According to their definition, the “best” confidence map P should be the true probability of Correct-
ness:
P (x) = E[1h(X) is correct for Y |h, X = x], ∀x ∈ X .	(A.1)
which is a measureable function from X to [0, 1]. In particular, we consider h as a PI in regression
tasks and “correctness” of a PI is naturally defined as the success of coverage on the outcome Y .
Then the right hand side of Equation (A.1) becomes
E[1h(X) is correct for Y |h, X = x] = E[1Y ∈[L(X),U(X)] |L, U, X = x]
=P[Y ∈ [L(X),U(X)]|L,U,X = x].
which is the conditional coverage in our Definition 2.1.
In addition, Guo et al. (2017) introduce the perfect-calibrated confidence as follows:
,ʌ . ʌ ʌ - -
P(Y = Y|Y, P= P)= p, ∀p ∈ [0,1]
i	-Cr ∙	. ) ι	ι∙	i W ，广	.ι ..1	ι∙ . i i .	ι IFl ∙	∙ t
where Y is the class prediction and Y = Y means that the predicted and true class label coincide.
一一. 一 ._ ʌ _______ _ , ʌ ____ ________ 一 一 一一 一 一 一 一 一 一一
Obviously, if P(X) = P(Y(X) = Y|X), i.e., the “best” confidence, then the above equality holds.
Transferring this idea into PIs, we can naturally define the perfect-calibrated coverage estimator as
- ʌ - - .,. ʌ - --
P = E[1h(X) iscorrectfor Y |L, U,P= p] = P[Y ∈ [L(X), U (X )]∣L,U,P= p],	∀p ∈ [0, 1].
which is the conditional coverage in our Definition 2.2.
13
Under review as a conference paper at ICLR 2021
A.3 Details on Coverage Estimator
A perfect-calibrated coverage estimator inherits some properties of a conditional coverage. For
example, both of them have the following interpretation: If we have 1000 testing points for a PI,
each with the same conditional/perfect-calibrated coverage 0.9, then approximately 900 of them are
correctly covered by the PI. Note that the conditional coverage is uniquely defined, but a perfect-
calibrated coverage estimator is not necessarily so. Moreover, we have the following facts: (a)
The conditional coverage is always perfect-calibrated, but not vice versa. (b) A perfect-calibrated
coverage estimator can be viewed as an averaged conditional coverage. (c) A perfect-calibrated
coverage estimator is less “informative” than the conditional coverage.
A perfect-calibrated coverage estimator is an averaged conditional coverage. Let P be a (gen-
eral) coverage estimator. We have
- -.,. ʌ , ʌ ,.-
P[Y∈ [L(X),U(X)]∣P(X) = P(x)]
=P[Y ∈ [L(X), U(X)]|X ∈ PT(P(X))]
=P[Y ∈ [L(X),U(X)],X ∈ PT(P(X))]
一	P[X ∈ PT(P(X))]
_RtepT(P(x))E[1Y∈[L(X),U(X)]|X = t]P[X ∈ dt]
一	:	ʌ . ʌ ,~~
P[X ∈ PT(P(X))]
=Rt∈P-1(P(x)) A(t)P[X ∈ dt]
一 P[X ∈ PT(P(X))]
Suppose P is a perfect-calibrated coverage estimator. Then We have
^、一 Rt∈P-1(P(x)) A(t)P[X ∈ dt]
P(X)
P[X ∈ PT(P(X))]
which implies that P(X) is a weighted average of A(t) over the set PT (P(X)) with weights based
on the marginal distribution ofX.
A conditional coverage is perfect-calibrated.	If P(X) = A(x), then A(t) = A(X) for any
t ∈ A-1(A(X)) so
∕t∈A-1(A(x)) A(t)P[X ∈ dt]
P[X ∈ AT(A(X))]
A(X) t∈A-
1(A(x)) P[X ∈ dt]
P[X ∈ AT(A(X))]
A(X).
This shows that A(X) must be a perfect-calibrated coverage estimator. Another way to see this is
taking conditional expectation given A(X) = p in the Definition 2.1. Then we get
p=E[A(X)|A(X) =p]
= E[P[Y ∈ [L(X),U(X)]|X]|A(X)=p]
= P[Y ∈ [L(X), U (X)]|A(X) = p]	by the tower property.
A perfect-calibrated coverage estimator may be less informative and may not be the condi-
tional coverage. Suppose we have a PI [L(X), U(X)] at the exact prediction level of 1 - α, i.e.,
P[Y ∈ [L(X), U(X)]] = 1 - α. Then the constant coverage estimator
P(X) = 1 — α,	∀x ∈ X
can be viewed as an average coverage estimator over the entire space X . It is a perfect-calibrated
coverage estimator since by definition,
- -.,. ʌ , - - ^.一 ʌ ,
P[Y ∈ [L(X),U(X)]∣P(X) = 1 — α] = P[Y ∈ [L(X),U(X)]] = 1 — α = P(X).
But it is not a conditional coverage in general (e.g., the second synthetic example in Section 5).
Now we give an extension of the definition of “perfect-calibrated” coverage estimator, allowing it to
be defined on any measurable subsets.
14
Under review as a conference paper at ICLR 2021
Definition A.1. A coverage estimator P is called a perfect-calibrated coverage estimator on a
measurable subset S ⊂ X with P(S) > 0 associated with [L(x), U (x)] ifit satisfies
ʌ , - ʌ , ʌ , - ʌ , --
P(X) = P[Y ∈ [L(X),U(X)]∣L,U,P(X) = P(X),X ∈ S], a.e. P(X) ∈ [0,1].	(A.2)
where a.e. is with respect to the probability measure on [0, 1] induced by the random variable
P(X)|s. Note that the conditional probability space is standard: (S, FS := {A ∩ S : A ∈
F}, PS(A ∩ S) := P(A|S)).
(As our convention in Section A.1, we will omit “conditional on L, U” for simplicity.)
Lemma A.2. (a) A coverage estimator is the conditional coverage if and only if it is a perfect-
calibrated coverage estimator on any positive-probability measurable subset S ofX.
(b) Suppose P is a perfect-calibrated coverage estimator on two disjoint positive-probability mea-
surable subsets Si, S?. Then P is a perfect-calibrated COVerage estimator on Si ∪ S2.
Proof. (a) The proof can be found in Lemma A.4.
(b) We note that by law of total probability,
- -.,. ʌ , -
P[Y ∈ [L(X), U(X)]|P(X) = P,X ∈Si ∪ S2]
- - . , . ʌ , -- . ʌ , -
=P[Y ∈ [L(X), U(X)]|P(X) = p,X ∈ Si]P[X ∈ Si|P(X) = p,X ∈ Si ∪ S2]
- - . , . ʌ , -- . ʌ , -
+ P[Y ∈ [L(X), U(X)]|P(X) = p,X ∈ S2]P[X ∈ S2|P(X) = p,X ∈ Si ∪ S2]
- . ʌ , - - . ʌ ,
=p(P[X ∈ Si|P(X) = p,X ∈Si ∪S2]+ P[X ∈ S2|P(X) = p,X ∈Si ∪ S2])
=p.
Hence P is a perfect-calibrated coverage estimator on Si ∪ S2.	口
Lemma A.2(a) is motivated from a theoretical point of view. It provides a guidance that in order
to well resemble the conditional coverage, an estimator should be perfect-calibrated on as many
subsets on the feature space as possible.
A.4 Details on Coverage Error
In Section 2, we have introduced CEp to quantify the discrepancy between a coverage estimator and
a perfect-calibrated coverage estimator, and CEp to quantify the discrepancy between a coverage
estimator and the conditional coverage. We note that by Holder,s inequality
CEp ≤ CEq , for 1 ≤ p ≤ q ≤ +∞.
A larger value ofp corresponds to a larger CE value. Continuing Definition A.1, we can further
introduce the calibration-based conditional coverage error on a measurable subset as follows:
Definition A.3. An Lp (1 ≤ p ≤ +∞) calibration-based conditional coverage error, or coverage
errorfor short, ofa coverage estimator P on a measurable subset S ⊂ X with P(S) > 0 is defined
as:
CEp(S) = ∣∣P[Y ∈ [L(X ),U (X )]∣L,U,P(X ),X ∈S ] - P(X )k(s)	(A.3)
where Lp -norm is taken with respect to the randomness of P(X) on the conditional probability
space (S, FS := {A ∩ S : A ∈ F}, PS(A ∩ S) := P(A|S)). In particular, we have CEp :=
CEp(X).
Lemma A.4. A COVerage estimator P is the conditional coverage if and only if its COVerage error
CEp(S) = 0 for any measurable subset S ⊂ X with P(S) > 0. In particular, a coverage esti-
mator is the conditional coverage if and only if it is a perfect-calibrated coverage estimator on any
measurable subset S ofX with P(S) > 0.
15
Under review as a conference paper at ICLR 2021
Proof. We first show that the conditional coverage is perfect-calibrated. Taking conditional expec-
tation given {A(X) = p, X ∈ S} in the Definition 2.1. Then we get
p = E[A(X)|A(X) =p,X ∈ S]
= E[P[Y ∈ [L(X),U(X)]|X]|A(X) =p,X ∈ S]
= P[Y ∈ [L(X), U (X)]|A(X) =p,X ∈ S] by the tower property.
So A(x) is a perfect-calibrated coverage estimator on any measurable subset S with P(S) > 0.
Hence CEp (S) = 0 for any measurable subsets S ⊂ X with P(S) > 0.
On the other hand, similarly to Section A.3, we can express
- - . , . ʌ , ʌ , -
P[Y ∈ [L(X),U(X)]∣P(X) = P(χ),x ∈ S]
∕t∈P-1(P(x))∩s A(t)P[X ∈ dt]
- ʌ . , ʌ ,.. -
P[X ∈ PT(P(X)) ∩S]
C	τ∖ /	\	•	.	. 1	1	. 1	πTιl^A∕P7-∖	/	A / TT- \ 1	C	5 TJl	.	1	/'
Suppose P(x)	is not the	conditional	coverage, then	P[P(X)	6=	A(X)]	> 0.	Without loss	of
generality, we assume P[P(X) > A(X)] > 0. Let S0 := {x ∈ X : P(x) > A(x)}. Note
that So = ∪+∞1{χ ∈ X : P(X) > A(x) + n}. Since P(So) > 0, there exists a no such that
S := {x ∈ X : P(X) > A(x) + nl} and P(S) > 0.
Then for x ∈ S , we have
Rt∈P-1(P(x))∩s A(t)p[x ∈ dt] / Rt∈p-1(p(x))∩s(P(t) - n1o)P[X ∈ dt] _ P(I	1
≤∙	X -	.
P[X ∈ PT(P(X)) ∩S]	—	P[X ∈ PT(P(X)) ∩S]	no
Then we have
CEp(S) ≥ CEι(S) ≥ — > 0
no
so CEp(S) > 0, which is a contradiction. Hence P(x) is the conditional coverage.	□
Next, we describe in detail how to discretize the right-hand-side of equation 2.4 for empirical cal-
culation. We construct a discrete version of (2.2) and then introduce an empirical counterpart of
CEp (2.3), which we refer to as Lp empirical calibration-based conditional coverage error ECEp .
The ideas behind these are natural extensions of the classification case (Guo et al., 2017; Kull et al.,
2019; Kumar et al., 2019; Nixon et al., 2019) into PIs.
We consider the following partition ∆ of [0, 1]. Let [0, 1] be divided into M intervals Im =
(am-ι, am] (m = 1, ∙∙∙ , M) where 0 = ao ≤ aι ≤ ∙∙∙ ≤ °m = 1. Let Bm = {i = 1,…,n :
P(Xi) ∈ Im}, i.e., the set (bin) of indices i of samples whose prediction coverage estimator P(Xi)
falls into the interval Im . Note that coverage estimators that are close to each other will fall into
the same interval. The coverage probability (i.e., the proportion of successful coverage) in Bm is
defined as:
CP(Bm) = IB—|〉： 1yi ∈[L(xi ),U (xi )] .
|Bm| i∈Bm
The average estimated coverage in Bm is defined as:
1
Cove(Bm) = |b~~|〉J P(Xi)
i∈Bm
(A.4)
(A.5)
where P(Xi) is the coverage estimator for samPle i. cP(Bm) and cove(Bm) aPProximate the left
and right hand sides of (2.2) resPectively in the interval Im. A Perfect-calibrated coverage estimator
should satisfy CP(Bm) = Cove(Bm) for all m ∈ {1, •…，M}. The diagram of CP(Bm) versus
cove(Bm) for all m ∈ {1, •…，M} is called the reliability diagram in some literature (Guo et al.,
2017).
Based on the Partition ∆, we can introduce an emPirical version of CEp (which we refer to as
ECEp ) as:
16
Under review as a conference paper at ICLR 2021
Definition A.5. The Lp empirical calibration-based conditional coverage error (ECEp) of a cov-
erage estimator P is defined as
ECEp = Il(Cp(Bm(i)) - cove(Bm(i)))i=1,2,…,n∣∣lp .	(A.6)
where the lp is the standard p-norm in Rn and Bm(i) is the bin containing sample i.
Equivalently,
1
ECEp = (X IBmI IcP(Bm)- Cove(Bm)Ip) ,	1 ≤ p < +∞.
ECE∞ =	max	|cp(Bm) - cove(Bm)| .
m=1,2,，M
Note that ECEp is discontinuous and cannot be used easily for training with gradient-based meth-
ods. Therefore, we use the coverage assessment loss LCA introduced in Section 3 for conditional
coverage estimation.
Finally, we give some exPlanations about why the conditional coverage error CEp cannot be used
easily for training. Unlike LCA which is unbiased and Provides guaranteed estimation accuracy for
E[K1(X)] (Theorem 4.5), it is in general not easy to establish an emPirical calculation for CEp.
Take CE2 as an instance. A heuristic argument is to use
1n
θ:= - X(ki - P(Xi))2
n i=1
to aPProximate
2
CE2 = E[∣A(X) - P(X)I2]
where ki = 0 or 1 indicates whether each data Point has been caPtured by the PIs; see Section 3.
2
Unfortunately, θ is in general not an unbiased estimator of CE2 due to the following observations:
E[θ] = E[(kι - P(xι))2]
=E∣E[(kι - P(xι))2∣xj
=E[E[k2∣xι] — 2P(x1)E[k1 ∣xι] + P(xι)2]
=E∣E[k1∣x1] - 2P(x1)E[k1∣x1] + P(x1)2]
=e[a(xi) - 2P(x1)A(x1) + P(xι)[
=e[a(xi)2 - 2P(x1)A(x1) + P(xι)[ + E[A(xι) - A(x1)2]
=E[∣A(X) - P(X)∣2] + E[A(X) - A(X)2].
2
Hence E[θ] = CE? unless A(X) = 0 or 1 almost surely. Note that the gap E[A(X) - A(X)2] does
not depend on n and thus not vanish as n grows. To obtain a reasonable estimator for CEp, one need
more information about A(x) besides the marginal coverage E[A(X)]. However, this information is
usually hard to obtain locally because of the nature of (possibly high-dimensional) feature space. In
fact, this has led us to the idea of “dimension reduction” of the sample space to the space [0, 1] and
the definition of CEp .
B	Mathematical Developments for Theorem 4.1
This section proves Theorem 4.1: we show that both coverage error and conditional coverage error
are tightly bounded above by the expectation of a Kullback-Leibler divergence-type random vari-
able K1(x). This means that minimizing E[K1(X)] can recover the true conditional coverage and
effectively reduce the coverage error. The proof consists of several inequalities regarding coverage
errors and their relations. We first begin with the following connection between CEp and CEp .
17
Under review as a conference paper at ICLR 2021
Theorem B.1.	For any PI and its associated P, the Lp Coverage error is always less than or equal
to the Lp conditional coverage error, i.e.,
CEp ≤ CgEp , ∀1 ≤ p ≤ +∞
Proof. We note that the function t 7→ |t|p is a convex function. We also note that σ(P (X)) ⊂ σ(X)
where σ(Y ) represents the σ-field generated by a random variable Y .
CEp =E h∣A(x) - P(X)∣pi
=E 同A(X)- P(X)∣p∣P(X)]i
≥E h∣E[A(x) - P(X)∣P(X)] ∣ i by Jensen's inequality
=E h∣E[1γ∈[l(x),u(X)]∣P(X)] — P(X)∣pi	by the tower property
=CEpp
Therefore we have
________________________________ '' ..
CEp ≤ CgEp , ∀1 ≤ p ≤ +∞.
□
Next we have the following bounds on Lp conditional coverage error:
Theorem B.2.	The Lp conditional coverage error is bounded above by a power function of the L2
conditional coverage error. Formally,
αp
CgEp ≤ CgE2 , ∀1 ≤ p ≤ +∞,
where ap = 1, ∀1 ≤ P ≤ 2 and αp = 2 ,∀2 ≤ P ≤ +∞.
Proof. By Holder,s inequality,
CEp ≤ CE2 , if 1 ≤ P ≤ 2.
Since
..,, ʌ ,..
0 ≤ ∣A(χ) - P(χ)l ≤ 1,
then,
|A(x) - P(x)∣p ≤ |A(x) - P(χ)∣2, ∀p ≥ 2
and thus
p2
CEp = E[∣A(X) - P(X)|p] ≤ E[∣A(X) - P(X)|2] ≤ CE2, ∀p ≥ 2.
□
Next, recall that
K(X) = A(X) log A黑! +(1- A(X)) log 11 - A(X)!,
P(x)	1 - P(x)
K0(X) = A(X) log(A(X)) + (1 - A(X)) log(1 - A(X)),
, . ., ,ʌ , . , ʌ ,
Ki(x) = -A(∕)log(P(X)) — (1 — A(x)) log(1 — P(x)).
Theorem B.3.	The L2 conditional coverage error is bounded above by the expectation of K(X).
Formally,
—αp	/1	∖αp/2
CE2p ≤ (2E[K(X)]),
where αp is defined in Theorem B.2.
18
Under review as a conference paper at ICLR 2021
ap/2
Proof. For any fixed x, consider two random variables with Bernoulli distributions:
W 1 w.p. A(x),
1	0 w.p. 1 - A(x).
1 w.p. P (x),
0 w.p. 1 — P(X).
Let Pi be the distribution of Wi. It follows from Pinsker’s inequality, e.g., Theorem 2.16 in (Massart,
2007), that
kP1 — p2kTV ≤ 2K(pi,p2).
where T V denotes the total variation distance and K denotes the KL divergence. Since Pi is the
Bernoulli distribution, we can express it as
|A(x) — P(X)I2 ≤ 1 K(X)
Taking expectation, we obtain
E[∣A(X) — P(X)I2] ≤ 1 E[K(X)].
Hence,
CEαp ≤ (2E[K(X)]
□
Combining Theorem B.1, B.2 and B.3, we immediately conclude that:
Theorem B.4 (Restated Theorem 4.1).
一^ ^^a 11	α αp/2
CEp ≤ CEp ≤ CE2 p ≤ 1E E[K (X)])	, ∀1 ≤ P ≤ +∞
where αp is defined in Theorem B.2. Moreover, all inequalities are attainable, e.g., if P(X) is the
conditional coverage A(X).
C Justification of Assumption 4.2 and Mathematical
Developments for Theorem 4.5
In this section, we analyze the rationality of Assumption 4.2 and build essential ingredients for
proving Theorem 4.3 and 4.5. The difficulty in analyzing Theorem 4.5 lies in the fact that the
hypothesis classes in Assumption 4.2 (which are constructed by the NN) are different from the
hypothesis class used in LCA. To overcome this difficulty, we use the theory of VC-subgraph classes
to analyze the connection between the VC dimension of the two hypothesis classes.
C.1 Review of the VC Dimension
For self-contained purpose, we first review the definition of the VC-subgraph class and VC dimen-
sion.
Definition C.1. Consideran arbitrary collection {xι,…,Xn} ofpoints in a set X and a collection
C Ofsubsets of X. We say that C shatters {xι, ∙∙∙ , Xn} ifall of 2n possible subsets of {xι, ∙∙∙ , Xn}
can be written as A = C ∩ {xι,…,Xn} for some C ∈ C. The VC dimension V(C) of the class
C is the smallest n for which no set of size n {xι, •…，Xn} is shattered by C. If C shatters sets of
arbitrarily large size, we set V(C) = ∞. We say that C is a VC-class ifV(C) < ∞.
In some literature, the VC dimension V(C) of the class C is alternatively defined as the largest n for
which there exists a set of size n {χι,…,Xn} shattered by C, i.e., it is the value in definition C.1
minus 1. We can more formally define the VC dimension by the growth function as follows:
19
Under review as a conference paper at ICLR 2021
Definition C.2. Define the nth shatter coefficient (or growth function) of C as
∏c(n) := max |{A : A = C ∩{xι,…,Xn} for some C ∈ C}∣
x1 , ∙∙∙ ,xn
Then
V(C) := inf{n : ΠC(n) < 2n}.
Definition C.3. For a function f : X → R, the subset of X × R given by {(x, t) : t < f (x)} is
the (open) subgraph of f. A collection F of measurable real functions on the sample space X is a
VC-subgraph class or VC-class, if the collection of all subgraphs of functions in F forms a VC-class
of sets (as sets in X × R). Let V (F) denote the VC dimension of the set of subgraphs ofF.
Lemma C.4. In Definition C.3, the open subgraph of f, {(x, t) : t < f (x)}, can be replaced by
the close subgraph {(x, t) : t ≤ f (x)}, the close supergraph {(x, t) : t ≥ f (x)} or the open
supergraph {(x, t) : t > f (x)}. All of them lead to the equivalent definition of the VC-class and the
equal VC dimension.
Proof. This result follows from Lemma 9.33 and Lemma 9.9(iv) in Kosorok (2007).	□
For indicator functions of sets, we have the following equivalence.
Lemma C.5. For any class C of sets in a set X, the class FC of indicator functions of sets in C is a
VC-class if and only ifC is a VC-class. Moreover, whenever at least one ofC or FC is VC-class, the
respective VC dimensions are equal.
Proof. This is Lemma 9.8 in Kosorok (2007). Note that the sets of C are in X while the subgraphs
of functions of FC are in XX R.	□
C.2 Justifying Assumption 4.2
We first restate the assumption:
Assumption C.6 (Restated Assumption 4.2). ThefourclassesoffUnctions ([L(x), U(x)], P(X), 1 一
P (x)) output by the neural network (NN) in Figure 1 have finite VC dimensions, say they are
bounded above by V0.
In Figure 1, the output four neurons of the NN are denoted as (L(x), U (x), P (x), 1 一 P (x)). We
further let (ψ1(x), ψ2(x), ψ3(x), ψ4(x)) denote the pre-activated values of (L(x), U (x), P (x), 1 一
A/ W τ	1
P (x)). In other words,
L(x) = min(ψ1(x), ψ2(x)),
U(x) = max(ψ1(x), ψ2(x)),
P (x) = Softmax(ψ3(x)∣∣ψ4(x)) = σ(ψ3(x) — ψ4(χ)),
1 — P (x) = Softmax(ψ4(χ)∣∣ψ3(χ)) = σ(ψ4(x) — ψ3(x)),
where σ is the sigmoid function. Let the function classes
H1 = {L(x) : L is output by the the NN},
H2 = {U (x) : U is output by the the NN},
G = {P(x) : P is output by the NN},
1 — G = {1 — P(x) : P is output by the NN}.
Assumption 4.2 holds for a wide range of NNs, in particular the one we adopt in the experiments
(where we use the ReLU-activated NN to construct ψi, i = 1, 2, 3, 4 ; see Section 5). Our first result
is to concretely show that the four NN outputs above, H1, H2, G and 1 — G, under the ReLU setting,
all have finite VC dimensions and thus satisfy Assumption 4.2.
Theorem C.7 (Restated Theorem 4.3). Suppose ψi, i = 1, 2, 3, 4 are the pre-activated output neu-
rons of the NN in Figure 1 using the ReLU activation function. Then Assumption 4.2 holds. More-
over, suppose the NN has W parameters and U computation units (nodes). Then V0 = O(WU).
20
Under review as a conference paper at ICLR 2021
Proof. First, we look at L(x) and U (x). Note that the class of ψi (i = 1, 2) is constructed by a NN
with the ReLU activation function. Therefore by Theorem 8 in Bartlett et al. (2019) (see also C.8
below),
V({ψ1}) = O(WU) < ∞, V({ψ2}) = O(WU) < ∞.
By Lemma 9.9 (i) in Kosorok (2007), we have
V(H1) =V({min(ψ1,ψ2)}) ≤V({ψ1})+V({ψ2})-1=O(WU) <∞.
By Lemma 9.9 (ii) in Kosorok (2007), we have
V(H2) = V ({max(ψ1, ψ2)}) ≤V({ψ1})+V({ψ2})-1=O(WU) <∞.
Next, we look at P (x) and 1 - P (x). We add an additional neuron after the layer where ψ3, ψ4
stand. This neuron is defined as ψ5 = ψ3 - ψ4 which is a linear combination of ψ3 and ψ4 . Note
that the class of ψ5 is constructed by a NN with the ReLU activation function and linear activation
function (by adding one unit and two parameters in the originial NN). Therefore by Theorem 8 in
Bartlett et al. (2019),
V ({ψ5}) = O(WU) < ∞
By Lemma 9.9 (viii) in Kosorok (2007), we have
V(G) = V ({σ(ψ5)}) ≤ V({ψ5}) = O(WU) <∞.
since σ is a monotone function. Again, by Lemma 9.9 (viii) in Kosorok (2007), we have
V(1-G) ≤ V(G) =O(WU) < ∞.
since t → 1 一 t is a monotone function.	□
We also list some results for other activations here. From these results, and using the same argument
as above, we see that Assumption 4.2 holds similarly for all these activations.
Lemma C.8. Suppose the class of functions is constructed by a NN with W parameters and U units
with activation functions that are piecewise polynomials with at most p pieces and of degree at most
d. Then it has VC dimension O(WU log((d + 1)p)).
Proof. This is Theorem 8 in Bartlett et al. (2019).	□
Note that the activation functions in Lemma C.8 include in particular the ReLU activation and linear
activation.
Lemma C.9. Suppose the class of functions is constructed by a NN with W parameters with binary
as well as linear activation function. Then it has VC dimension O(W2).
Proof. This is Theorem 5 in Sontag (1998).	□
Lemma C.10. Suppose the class of functions is constructed by a NN with W parameters and U
units with activation function that is the standard sigmoid function (except that the output unit being
a linear threshold unit). Then it has VC dimension O(W 2U 2).
Proof. This is Theorem 8.13in Anthony & Bartlett (2009).	□
C.3 Connections among Different Hypothesis Classes
To prove Theorem 4.5, we need to study several building blocks on the relations between different
hypothesis classes. Our first observation is:
Theorem C.11. Suppose V (G) < +∞. Then all of the following classes have VC dimension
≤ V (G):
1 一 G := {1 一 P (x) : P is output by the NN}.
G0 := log(G) := {log(pP(x)) : P is output by the NN}.
log(1 — G) := {log(1 — P(X)) : P is output by theNN}.
21
Under review as a conference paper at ICLR 2021
Proof. The result follows from Lemma 9.9 (viii) in Kosorok (2007) since all of the transformations
are monotone functions.	口
Our second observation is about
F = {f (x, y) = Iy∈[L(x),U(x)] : L,U are output by the NN}.
Note that the domain of functions in F is different from the domain of functions in Hi (i = 1, 2) as
it includes the outcome space. Below we derive a result that connects the VC dimension ofHi with
that of F .
Theorem C.12. Suppose V (Hi) ≤ V0 (i = 1, 2). We have that
V(1 -F) ≤ V(F) ≤ 10(V0 - 1) < +∞
where
1	- F := {1 - f(x, y) : f ∈ F}.
Proof. The first inequality follows from Lemma 9.9 (viii) in Kosorok (2007). We consider the
following two classes:
F1 := {IL(x)≤t : L ∈ H1, t ∈ R},
F2 := {IU(x)≥t : U ∈H2,t∈R}.
Since the functions in F1 are all indicator functions, by Lemma C.5,
V(F1) = V ({{(x, t) : L(x) ≤ t} : L ∈ H1,t ∈ R}).
Note that the latter is the VC dimension of the close supergraphs of all functions in H1. Then by
Definition C.3 and Lemma C.4, we have
V ({{(x, t) : L(x) ≤t} : L ∈H1,t∈R}) = V(H1)
Therefore we have
V (F1) = V (H1) ≤ V0
Similarly,
V (F2) = V (H2) ≤ V0
Note that we can write
Iy∈[L(x),U (x)] = IL(x)≤y IU (x)≥y
By the definition of growth functions,
πF(m) ：=,	,maX	、|{(Iy1∈[L(X1 ),U(xi)],…，Iym∈[L(χm),U(Xm)D : L ∈ H1,U ∈ H2}∣
(χι,yι),…,(Xm ,ym )
≤.	、max	、|{(IL(X1)≤y1,…，IL(χm)≤ym) : L ∈ H1}∣ ×
(χι,yι),…,(Xm ,ym )
maχ	|{(IU (x1)≥y1 ,…，IU (Xm)≥ym ) : U ∈ H2}∣
(χι,yI),…,(Xm ,ym )
=ΠF1 (m)ΠF2 (m)
2(V0-1)
em 0
≤ (% - 1)
for all m ≥ V0 where the last inequality is due to the Sauer-Shelah lemma. Taking m = 10(V0 -1),
we obtain
2(V0-1)
-em- )	=(10e)2(VOT) ≤ 750v0-1 < 2m
V0 - 1
Combining the above inequality, we have
ΠF(m) < 2m.
This shows that V (F) ≤ m = 10(V0 - 1).
□
22
Under review as a conference paper at ICLR 2021
C.4 Proof of Theorem 4.5
This subsection proves Theorem 4.5. Recall that
F = {Iy∈[L(x),U(x)] : L, U are output by the NN},
G = {P(x) : P is output by the NN}.
G0 := log(G) := {log(P(x)) : P is output by the NN}.
Let N(, F, L2(Q)) denote the covering number, i.e., the minimal number of balls {g : kg -
hkL2(Q) < } of radius needed to cover the set F. We need the following bounds:
Lemma C.13. Suppose F is a class of functions f : X × Y → [0, 1] with a finite VC dimension
V (F). For every 0 < < 1,
1
sup log N(e, F, L2(Q)) ≤ K (；)
where the constant K2 depends on V (F) only.
Proof. It follows from Theorem 2.6.7 in Van der Vaart & Wellner (1996) that there exists a universal
constant K such that
1 V (F)-1
sup N (e, F, L2(Q)) ≤ KV(F)(16e)V(F)
for any 0 < < 1. Since
∀0 <	< 1,
We have	ɪ
suplog N(e,F, L2(Q)) ≤ K + (V(F)- 1)logQ^) ≤ K (：) e
Where K3 := log(KV(F)(16e)V(F)) and K2 = K3 + V(F) - 1 only depending on V(F).
□
We remark that a similar result can also be obtained for the class 1 - F by Theorem C.12.
Lemma C.14. Suppose G is a class of functions P : X → [0,1] with a finite VC dimension V (G)
and | log(P(x))∣ ≤ M. Let G0 := {log(P) : P ∈ G}. Then,forevery 0 < e < 1,
1
suplog N(M, G0, L2(Q)) ≤ K2 (；)e
where the constant K2 depends on V(G) only.
Proof. First note that φ(t) := log(t) is a monotone function. Hence G0 := {log(P) : P ∈ G} is a
VC-class with VC dimension ≤ V(G) by Lemma 9.9 (Viii) in Kosorok (2007). The rest of the proof
is similar toC.13.	□
We remark that a similar result can also be obtained for the class log(1 - G) by Theorem C.11.
Next we restate Assumption 4.4:
Assumption C.15 (Restated Assumption 4.4). | log(P(χ))∣ ≤ M, | log(1 - P(χ))∣ ≤ M for all X
and P.
As discussed in Section 4, this is a natural assumption in practice because log(P (x)) and log(1 -
P (x)) are replaced by log(P (x) + ) and log(1 - P(x) + ) respectively to avoid explosion when
implementing the algorithm. In particular, in our experiments in Section 5,	= 0.16 and thus
M= 14.
We are now ready to prove Theorem 4.5:
23
Under review as a conference paper at ICLR 2021
Theorem C.16 (Restated Theorem 4.5). Suppose Assumptions 4.2 and 4.4 hold. The training data
D = {(xi, yi), i = 1, 2,…，n} where (xi, yi) are i.i.d. samples 〜 π. Recall that the (hard)
coverage estimator assessment loss is
1n
LCA = - n X f(χi,yi)log(P(χi)) + (1- f (χi,yi))log(i - P(Xi))).
Then for any t > 0, we have
P ( sup |Lca - E[Kι(X)]| ≥ t ) ≤ C*e-InM2
∖f ∈F ,P∈G	J
where C* only depends on V0 in Assumption 4.2.
Proof. Note that E[f(xi, yi)|xi] = A(xi) for any fixed L and U. Taking expectation on LCA, we
have
E[Lca] = E [E[LcA∣Xl,X2,…，Xn]]
E
1n
n X (A(Xi) log(P(χi)) + (1- A(Xi))log(1 - P(Xi)))
i=1
E[K1(X)].
I-V T	∙ 1 .1 C .	. A / ∖ 1 ∕A∕∖∖ EI	1	.	11	∙	. 1	.
We consider the first part A(X) log(P (X)). The second part can be done using the same argument.
Note that by Theorem 9.15 in Kosorok (2007), we have
suplog N(eM, F ∙ G0, L2(Q)) ≤ suplog N(e∕2, F, L2(Q)) + suplog N(eM∕2, G0, L2(Q)).
Q
Q
Q
Consider the class 1 + +F ∙ G = {2 + 贵(f (x, y)log(P(x))) : f ∈ F, log(P) ∈ G0} which
consists of functions taking values in [0, 1]. We have
SUPlog N(€, I + 与F-G0,L2 (Q))
Q	2	2M
= SUPlog N(2eM, F∙G0,L2(Q))
Q
≤suplogN(,F,L2(Q))+suplogN(M,G0,L2(Q))
Q
Q
where the last inequality follows from Lemma C.13 and Lemma C.14, and K2 only depends on
V (F) and V (G). (Recall that we have shown V (G0) ≤ V (G) in Lemma C.14.) Moreover, by
Theorems C.11 and C.12, we can claim that K2 only depends on V0. This inequality shows that
1 + 2⅛F ∙ G0 satisfies the conditions in Theorem 2.14.10 in Van der Vaart & Wellner (1996) and
thus for every δ > 0 and t > 0,
n
P ( sup	1	X	φ(xi,yi)	- E[φ(x,y)]	≥ t )	≤ CeD(Vnt)U+δe-2nt2
∖φ∈ 2 + 2M A(G	n	i=1	)
where U = eg6-1) < 1 and the constants C and D depend on K and δ only. Let δ = 1 - U. Note
that	e
-2(√nt)2 + D(√nt) ≤ -(√nt)2 + (d∕2)2.
Hence we have
P ( sup	— X φ(χi,yi) - E[φ(χ,y)] ≥ t ) ≤ C*e-nt2
∖φ∈ 2 + 2⅛F∙G0 n i=1	)
where C* only depends on K2 , or, only depends on V0 .
24
Under review as a conference paper at ICLR 2021
This shows that
1n	2
1	nt2
P sup _£f (xi,yi)log(P(xi)) - E[A(x)log(P(x))] ≥ t ≤ Ce-4M2.
∖f∈F,P∈G n i=1	)
A similar result can be established for the second part since the hypothesis classes there have been
studied in Theorem C.11 and C.12:
P sup
∖f ∈F ,P∈G
nt2
≤C*e-4M2 .
1n
—E(I- f(xi, yi)) log(1 - P(Xi))- E[(1 - A(X)) log(1 - P(x))]
n i=1
≥t
Combining the two parts and noting the following fact:
{sup ∣γ + β∣ ≥ t}
⊂{sup ∣γ∣ + sup ∣β∣ ≥ t}
⊂{sup |Y| ≥ 2} ∪ {sup|e| ≥ g},
we conclude that
P( sup |Lca — E[Kι(x)]∣ ≥ t J ≤ C*e-InM2
∖f ∈F ,P∈G	J
where C * only depends on Vo.	□
Lastly, the following corollary explicitly connects our theoretical developments to the experimental
setup:
Corollary C.17. Suppose the NN is designed as the one specified in the experiments (Section 5).
The training data D = {(xi, yi), i = 1, 2, ∙∙∙ ,n} where (xi, yi) are i.i.d. samples 〜 π. Thenfor
any t > 0, we have
P ( sup |Lca - E[Kι(X)]| ≥ t ) ≤ C*e-InM2.
∖f ∈F ,P∈G	J
where C* only depends on V0 in Assumption 4.2.
Proof. We note that Assumptions 4.2 and 4.4 hold in this case by Theorem 4.3 and the observation
after Assumption 4.4. So Theorem 4.5 implies Corollary C.17.	□
D Algorithm Details
We provide additional algorithm details for our framework in Section 3. Algorithm 1 is the descrip-
tion of our tuning procedure for hyper-parameters λ1 , λ2 , λ3 . Let the marginal coverage probability
CPD0 and the average coverage estimation ACD0 on the validation set D0 be defined as
CPDO =的 X 1yi∈[L(χi),U(Xi)],	ACDO =两 X P(Xi).
|	| i∈D0	|	| i∈D0
where ([L(X), U (X)], P (X)) are prediction results from the deep ensemble. Then, λi, i = 1, 2, 3 are
adjusted to ensure that CPDO coincides roughly with ACDO , and CPDO attains the target prediction
level.
E Experimental Details and More Results
This section illustrates experimental details and more experimental results from our proposed model.
25
Under review as a conference paper at ICLR 2021
Algorithm 1: Tuning algorithm
Goal: Tune hyperparameters λ1, λ2, and λ3;
Input: Prediction level 1 - α, training dataset D, validation dataset D0 ;
Procedure: (1) Initialize λi (i = 1, 2, 3) so that CPD0 is nontrivial, i.e., not (almost) 0 or 1.
(2)	While CPD0 is nontrivial: tune λ2 and λ3 so that |CPD0 - ACD0 | ≤ (e.g., = 1%.)
(3)	Otherwise tune λ1 such that CPD0 is nontrivial. Do step 2 again until we find λ2 and λ3.
(4)	Tune λ1 such that CPD0 > 1 - α where λ2 and λ3 are fixed from (3).
Output: λ1, λ2, and λ3.
E.1 Experimental Details
Table 3 gives a detailed description about the datasets we use. These open-access real-world
benchmark regression datasets are widely used for the evaluation of methods in regression tasks
(Hemandez-Lobato & Adams, 2015; Gal & Ghahramani, 2016; Lakshminarayanan et al., 2017;
Rosenfeld et al., 2018; Pearce et al., 2018; Zhu et al., 2019).
For synthetic datasets, 2000 i.i.d data are generated for each synthetic setting and randomly split into
1000 training data and 1000 testing data. For benchmark datasets, we first do the data normalization
and then randomly split 80% data for training and 20% for testing. The choice of 80%/20% split,
compared to the 90%/10% split in Pearce et al. (2018), is motivated from the need to increase the test
size in order to get a meaningful ECE evaluation. The latter is due to that evaluating ECE requires
binning, where using a larger number of bins approximates more closely CE, but also requires a
larger test size to sustain enough statistical quality for the resulting ECE estimate. This delicate
tradeoff motivates us to increase the share of the test set in our split. Following Pearce et al. (2018),
our hyper-parameters are selected using the validation set from a random split. Then, they are fixed
during the evaluation on other random splits.
As specified in Section 2 (Equation (2.4)) and Appendix A.4 (Equation (A.6)), ECE is evaluated
based on dividing [0,1] into M sub-intervals. The larger M is, the more precise is in using ECE to
approximate CE, the latter being the ideal conditional coverage error estimator. On the other hand,
a larger test set size is needed to support the use of a larger M without deteriorating the statistical
quality of the ECE. This delicate tradeoff motivates us to increase the share of the test set in our
split.
For synthetic datasets, the hyperparameters and corresponding results in Figure 2 are:
(a)	λ1 = 1.7, λ2	=	10-5,λ3	=	1500,CP	=	0.95, IW = 0.40, ECE1	=	0.62%.
(b)	λ1 = 1.9, λ2	=	10-5,λ3	=	1000,CP	=	0.96, IW = 0.40, ECE1	=	0.12%.
(c)	λ1 = 3.4, λ2	=	10-5,λ3	=	1000, CP	=	0.95, IW = 0.50, ECE1	=	0.65%.
For benchmark datasets, the	implementation	details for baseline algorithms in Table 1 are:
(1)	Nearest-neighbors kernel conditional density estimation (NNKCDE). The algorithm is based on
Section 2.1 in Dalmasso et al. (2020). We use the same Python code provided by Dalmasso et al.
(2020) with the default Gaussian kernel. Two tuning parameters, i.e., the number of nearest neigh-
bors k and the bandwidth h of the smoothing kernel, are chosen in a principled way by minimizing
the CDE loss on validation data, the same way as in Dalmasso et al. (2020).
(2)	Quantile regression forest (QRF). The algorithm is based on Meinshausen (2006). We use the
RandomForestQuantileRegressor from the package scikit-garden in Python.
(3)	Split conformal learning (SCL). The algorithm based on Algorithm 2 in Lei et al. (2018). The
regression algorithm inside SCL that we use is a neural network with mean square loss. The neural
network has the same structure of hidden layers as in Section 5.
E.2 Additional Experimental Results
Table 4 gives additional experimental results.
26
Under review as a conference paper at ICLR 2021
Dataset	N	d	Open-access Link
Boston: Boston Housing	506	13	kaggle.com/c/boston-housing
Concrete: Concrete Strength	1030	8	kaggle.com/aakashphadtare/concrete-data
Energy: Energy Efficiency	768	8	kaggle.com/elikplim/eergy-efficiency-dataset
Kin8nm	8192	8	openml.org/d/189
Plant: Combined Cycle Power Plant	9568	4	kaggle.com/gova26/airpressure
Protein: Protein Structure	45730	9	networkrepository.com/CASP.php
Wine: Red Wine Quality	1599	11	kaggle.com/uciml/red-wine-quality-cortez-et-al-2009
Yacht: Yacht Hydrodynamics	308	6	archive.ics.uci.edu/ml/datasets/yacht+hydrodynamics
Table 3: Full names and details of benchmarking regression datasets. N is the number of samples
in the dataset and d is the dimension of the feature vector.
Dataset	λ3	1-st experiment				λ1	2-nd experiment			3-rd experiment			
		λ1	CP	IW	ECE1		CP	IW	ECE1	λ1	CP	IW	ECE1
Boston	1800	3.5	0.87	0.72	1.25%	4.5	0.89	0.85	0.96%	6.0	0.95	1.04	1.38%
Concrete	1000	3.0	0.87	0.88	1.03%	5.0	0.93	1.07	1.03%	6.5	0.95	1.13	0.24%
Kin8nm	300	2.1	0.85	0.77	1.59%	2.9	0.91	0.89	0.50%	3.6	0.95	1.04	1.32%
Plant	700	1.6	0.85	0.63	0.86%	2.4	0.91	0.75	1.15%	3.3	0.95	0.85	0.38%
Protein	300	5.1	0.86	1.70	0.71%	6.3	0.91	1.95	0.66%	8.3	0.95	2.26	0.41%
Wine	1100	9.0	0.85	1.59	0.98%	15	0.91	2.14	1.28%	19	0.95	2.59	0.42%
Yacht	500	1.4	0.94	0.13	0.13%	1.5	0.96	0.14	1.51%	1.6	0.98	0.16	0.80%
Synthetic1	1500	1.0	0.89	0.34	0.73%	1.3	0.93	0.37	0.55%	1.7	0.95	0.40	0.62%
Synthetic2	1000	1.1	0.89	0.31	1.01%	1.4	0.92	0.34	1.27%	1.9	0.96	0.40	0.12%
Synthetic3	1000	1.3	0.87	0.34	0.79%	2.4	0.91	0.42	0.82%	3.4	0.95	0.50	0.65%
Table 4: Evaluation metrics of our CaNet on benchmark datasets and synthetic examples with dif-
ferent coverage probabilities.
E.3 Comparisons with a two-stage approach
We compare the performance of CaNet with a two-stage approach to further demonstrate the effec-
tiveness of our Ca-Module. The two-stage approach is implemented with two separate steps: (1)
given a regression dataset, we train a neural network to generate the prediction interval, (2) after
getting the predictor, we train another network to estimate the conditional coverage of the PI from
the previous stage using LCA loss.
Figure 3 compares the reliability diagrams (introduced in A.4) and the coverage histograms of CaNet
and the two-stage approach on the dataset “Protein”. The coverage histograms demonstrate the per-
centage of samples in each bin Bm (equation A.5) for m ∈ {1,…，M}. The average estimated
coverage of our model closely matches its coverage probability, while the average estimated cover-
age of the two-stage algorithm is substantially lower than its coverage probability. In addition, the
ECE1 from CaNet (0.77%) is much lower than the ECE1 from the two-stage approach (3.9%).
References
Martin Anthony and Peter L Bartlett. Neural network learning: Theoretical foundations. Cambridge
University Press, 2009.
Rina Foygel Barber, Emmanuel J Candes, Aaditya Ramdas, and Ryan J Tibshirani. The limits of
distribution-free conditional predictive inference. arXiv preprint arXiv:1903.04684, 2019a.
Rina Foygel Barber, Emmanuel J Candes, Aaditya Ramdas, and Ryan J Tibshirani. Predictive
inference with the jackknife+. arXiv preprint arXiv:1905.02928, 2019b.
Peter L Bartlett, Nick Harvey, Christopher Liaw, and Abbas Mehrabian. Nearly-tight VC-dimension
and pseudodimension bounds for piecewise linear neural networks. Journal of Machine Learning
Research, 20(63):1-17, 2019.
George EP Box and George C Tiao. Bayesian inference in statistical analysis, volume 40. John
Wiley & Sons, 2011.
27
Under review as a conference paper at ICLR 2021
Estimated Coverage
Estimated Coverage
Figure 3: Coverage histograms (top) and reliability diagrams (bottom) on the dataset “Protein”. Left:
Our proposed algorithm (ECE1 = 0.77%, M = 10); Right: The two-stage algorithm (ECE1 =
3.9%, M = 10).
John S Bridle. Probabilistic interpretation of feedforward classification network outputs, with rela-
tionships to statistical pattern recognition. In Neurocomputing, pp. 227-236. Springer, 1990.
NiCColo Dalmasso, Taylor Pospisil, Ann B Lee, Rafael Izbicki, Peter E Freeman, and Alex I Malz.
Conditional density estimation tools in python and r with applications to photometric redshifts
and likelihood-free cosmological inference. Astronomy and Computing, 30:100362, 2020.
Vincent Dutordoir, Hugh Salimbeni, James Hensman, and Marc Deisenroth. Gaussian process con-
ditional density estimation. In Advances in neural information processing systems, pp. 2385-
2395, 2018.
Stanislav Fort, Huiyi Hu, and Balaji Lakshminarayanan. Deep ensembles: A loss landscape per-
spective. arXiv preprint arXiv:1912.02757, 2019.
Peter E Freeman, Rafael Izbicki, and Ann B Lee. A unified framework for constructing, tuning and
assessing photometric redshift density estimates in a selection bias setting. Monthly Notices of
the Royal Astronomical Society, 468(4):4556-4565, 2017.
Yarin Gal and Zoubin Ghahramani. Dropout as a bayesian approximation: Representing model
uncertainty in deep learning. In international conference on machine learning, pp. 1050-1059,
2016.
IneS M Galvan, JoSe M Valls, Alejandro Cervantes, and Ricardo Aler. Multi-objective evolutionary
optimization of prediction intervals for solar energy forecasting with neural networks. Information
Sciences, 418:363-382, 2017.
Yonatan Geifman, Guy Uziel, and Ran El-Yaniv. Bias-reduced uncertainty estimation for deep
neural classifiers. In International Conference on Learning Representations, 2018.
28
Under review as a conference paper at ICLR 2021
Chuan Guo, Geoff Pleiss, Yu Sun, and Kilian Q Weinberger. On calibration of modern neural
networks. In Proceedings of the 34th International Conference on Machine Learning-Volume 70,
pp.1321-1330.JMLR. org, 2017.
Fredrik K Gustafsson, Martin Danelljan, and Thomas B Schon. Evaluating scalable bayesian deep
learning methods for robust computer vision. In Proceedings of the IEEE/CVF Conference on
Computer Vision and Pattern Recognition Workshops, pp. 318-319, 2020.
Jose MigUel Hernandez-Lobato and Ryan Adams. Probabilistic backpropagation for scalable learn-
ing of bayesian neural networks. In International Conference on Machine Learning, pp. 1861-
1869, 2015.
Michael P Holmes, Alexander G Gray, and Charles Lee Isbell Jr. Fast nonparametric conditional
density estimation. In Proceedings of the Twenty-Third Conference on Uncertainty in Artificial
Intelligence, pp. 175-182, 2007.
Rafael Izbicki and Ann B Lee. Nonparametric conditional density estimation in a high-dimensional
regression setting. Journal of Computational and Graphical Statistics, 25(4):1297-1316, 2016.
Rafael Izbicki, Ann B. Lee, and Peter E. Freeman. Photo-z estimation: An example of nonparamet-
ric conditional density estimation Under selection bias. Ann. Appl. Stat., 11(2):698-724, 06 2017.
doi: 10.1214/16-AOAS1013. URL https://doi.org/10.1214/16-AOAS1013.
Abbas Khosravi, Saeid Nahavandi, DoUg Creighton, and Amir F Atiya. Lower Upper boUnd estima-
tion method for constrUction of neUral network-based prediction intervals. IEEE transactions on
neural networks, 22(3):337-346, 2010.
Abbas Khosravi, Saeid Nahavandi, DoUg Creighton, and Amir F Atiya. Comprehensive review
of neUral network-based prediction intervals and new advances. IEEE Transactions on neural
networks, 22(9):1341-1356, 2011.
Danijel Kivaranovic, Kory D Johnson, and Hannes Leeb. Adaptive, distribUtion-free prediction
intervals for deep networks. In International Conference on Artificial Intelligence and Statistics,
pp. 4346-4356, 2020.
Roger Koenker and Kevin F Hallock. QUantile regression. Journal of economic perspectives, 15(4):
143-156, 2001.
Michael R Kosorok. Introduction to empirical processes and semiparametric inference. Springer
Science & BUsiness Media, 2007.
ArUn K KUchibhotla and Aaditya K Ramdas. Nested conformal prediction and the generalized
jackknife+. arXiv preprint arXiv:1910.10562, 2019.
Meelis Kull, Miquel Perello Nieto, Markus Kangsepp, Telmo Silva Filho, Hao Song, and Peter
Flach. Beyond temperatUre scaling: Obtaining well-calibrated mUlti-class probabilities with
dirichlet calibration. In Advances in Neural Information Processing Systems, pp. 12295-12305,
2019.
Ananya Kumar, Percy S Liang, and Tengyu Ma. Verified uncertainty calibration. In Advances in
Neural Information Processing Systems, pp. 3787-3798, 2019.
Balaji Lakshminarayanan, Alexander Pritzel, and Charles Blundell. Simple and scalable predictive
uncertainty estimation using deep ensembles. In Advances in Neural Information Processing
Systems, pp. 6402-6413, 2017.
Stefan Lee, Senthil Purushwalkam, Michael Cogswell, David Crandall, and Dhruv Batra. Why
m heads are better than one: Training a diverse ensemble of deep networks. arXiv preprint
arXiv:1511.06314, 2015.
Jing Lei and Larry Wasserman. Distribution-free prediction bands for non-parametric regression.
Journal of the Royal Statistical Society: Series B (Statistical Methodology), 76(1):71-96, 2014.
29
Under review as a conference paper at ICLR 2021
Jing Lei, Alessandro Rinaldo, and Larry Wasserman. A conformal prediction approach to explore
functional data. Annals OfMathematics and Artificial Intelligence, 74(1-2):29-43, 2015.
Jing Lei, Max G’Sell, Alessandro Rinaldo, Ryan J Tibshirani, and Larry Wasserman. Distribution-
free predictive inference for regression. Journal of the American Statistical Association, 113
(523):1094-1111, 2018.
David JC MacKay. Bayesian methods for adaptive models. PhD thesis, California Institute of
Technology, 1992.
Pascal Massart. Concentration inequalities and model selection, volume 6. Springer, 2007.
Nicolai Meinshausen. Quantile regression forests. Journal of Machine Learning Research, 7(Jun):
983-999, 2006.
Radford M Neal. Bayesian learning for neural networks, volume 118. Springer Science & Business
Media, 2012.
Alexandru Niculescu-Mizil and Rich Caruana. Predicting good probabilities with supervised learn-
ing. In Proceedings of the 22nd International Conference on Machine Learning, pp. 625-632,
2005.
Jeremy Nixon, Mike Dusenberry, Linchuan Zhang, Ghassen Jerfel, and Dustin Tran. Measuring
calibration in deep learning. arXiv preprint arXiv:1904.01685, 2019.
Yaniv Ovadia, Emily Fertig, Jie Ren, Zachary Nado, David Sculley, Sebastian Nowozin, Joshua
Dillon, Balaji Lakshminarayanan, and Jasper Snoek. Can you trust your model’s uncertainty?
evaluating predictive uncertainty under dataset shift. In Advances in Neural Information Process-
ing Systems, pp. 13991-14002, 2019.
Utku Ozbulak, Wesley De Neve, and Arnout Van Messem. How the softmax output is misleading
for evaluating the strength of adversarial examples. arXiv preprint arXiv:1811.08577, 2018.
Tim Pearce, Mohamed Zaki, Alexandra Brintrup, and Andy Neely. High-quality prediction intervals
for deep learning: A distribution-free, ensembled approach. arXiv preprint arXiv:1802.07167,
2018.
Tim Pearce, Felix Leibfried, and Alexandra Brintrup. Uncertainty in neural networks: Approxi-
mately bayesian ensembling. In International conference on artificial intelligence and statistics,
pp. 234-244. PMLR, 2020.
Yaniv Romano, Evan Patterson, and Emmanuel Candes. Conformalized quantile regression. In
Advances in Neural Information Processing Systems, pp. 3543-3553, 2019.
Nir Rosenfeld, Yishay Mansour, and Elad Yom-Tov. Discriminative learning of prediction intervals.
In International Conference on Artificial Intelligence and Statistics, pp. 347-355, 2018.
Murat Sensoy, Lance Kaplan, and Melih Kandemir. Evidential deep learning to quantify classifica-
tion uncertainty. In Advances in Neural Information Processing Systems, pp. 3179-3189, 2018.
Eduardo D Sontag. VC dimension of neural networks. NATO ASI Series F Computer and Systems
Sciences, 168:69-96, 1998.
Natasa Tagasovska and David Lopez-Paz. Frequentist uncertainty estimates for deep learning. arXiv
preprint arXiv:1811.00908, 2018.
Natasa Tagasovska and David Lopez-Paz. Single-model uncertainties for deep learning. In Advances
in Neural Information Processing Systems, pp. 6417-6428, 2019.
Aad W Van der Vaart and Jon A Wellner. Weak Convergence and Empirical Processes with Appli-
cations to Statistics. Springer, 1996.
Vladimir Vovk, Alex Gammerman, and Glenn Shafer. Algorithmic learning in a random world.
Springer Science & Business Media, 2005.
30
Under review as a conference paper at ICLR 2021
Vladimir Vovk, Ilia Nouretdinov, Alex Gammerman, et al. On-line predictive linear regression. The
AnnalsofStatistics, 37(3):1566-1590, 2009.
Bin Wang, Jie Lu, Zheng Yan, Huaishao Luo, Tianrui Li, Yu Zheng, and Guangquan Zhang. Deep
uncertainty quantification: A machine learning approach for weather forecasting. In Proceedings
of the 25th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,
pp. 2087-2095, 2019.
Haozhe Zhang, Joshua Zimmerman, Dan Nettleton, and Daniel J Nordman. Random forest predic-
tion intervals. The American Statistician, pp. 1-15, 2019.
Lin Zhu, Jiaxing Lu, and Yihong Chen. HDI-forest: highest density interval regression forest. In
Proceedings of the 28th International Joint Conference on Artificial Intelligence, pp. 4468-4474.
AAAI Press, 2019.
31