Under review as a conference paper at ICLR 2021
Dual Adversarial Training for Unsupervised
Domain Adaptation
Anonymous authors
Paper under double-blind review
Ab stract
Deep neural networks obtain remarkable achievements in diverse real-world ap-
plications. However, their success relies on the availability of large amounts of la-
beled data. A trained model may fail to generalize well on a domain whose distri-
bution differs from the training data distribution. Collecting abundant labeled data
for all domains of interest are expensive and time-consuming, sometimes even im-
possible. Domain adaptation sets out to address this problem, aiming to leverage
labeled data in the source domain to learn a good predictive model for the target
domain whose labels are scarce or unavailable. A mainstream approach is adver-
sarial domain adaptation, which learns domain invariant-features by performing
alignment across different distributions. Most domain adaptation methods focus
on reducing the divergence between two domains to make the improvement. A
prerequisite of domain adaptation is the adaptability, which is measured by the
expected error of the ideal joint hypothesis on the source and target domains,
should be kept at a small value in the process of domain alignment. However,
adversarial learning may degrade the adaptability, since it distorts the original
distributions by suppressing the domain-specific information. In this paper, we
propose an approach, which focuses on strengthening the model’s adaptability,
for domain adaptation. Our proposed dual adversarial training (DAT) method in-
troduces class-invariant features to enhance the discriminability of the latent space
without sacrificing the transferability. The class-invariant features, extracted from
the source domain, can play a positive role in the classification on the target do-
main. We demonstrate the effectiveness of our method by yielding state-of-the-art
results on several benchmarks.
1	Introduction
Deep learning has achieved great success in many machine learning tasks, such as image classi-
fication (Krizhevsky et al., 2012), speech recognition (Hinton et al., 2012), and natural language
processing (Wu & Guo, 2019). These tasks generally assume that there exists sufficient data to train
a good predictive model in the domain of interest. Unfortunately, in many real-world cases, it is
always difficult to collect sufficient labeled data for each domain of interest. Thus, it is of great
importance to explore how to apply knowledge learned from a label-dense domain, referred as the
source domain, to a label-scarce domain, referred as the target domain. Even though the source and
target domains share the same label space, due to the existence of domain shift, deep neural network
based models trained on the source domain are inclined to make spurious predictions on the target
domain (Pan & Yang, 2009). In order to mitigate the harmful effects of domain shift, domain adap-
tation is proposed to learn transferable knowledge between domains such that a model trained on
the source domain can simultaneously perform well on the target domain. In this work, we focus on
a more challenging setting: unsupervised domain adaptation, where there exists no labeled data in
the target domain.
Motivated by the domain adaptation theory (Ben-David et al., 2007; 2010), which suggests that the
expected error rate on the target domain is bounded by three elements: the expected error rate on
the source domain, the divergence between the two domains, and the adaptability which is quanti-
fied as the error rate of the ideal joint hypothesis on both source and target domains. Most domain
adaptation methods attempt to deal with domain shift by reducing the divergence between domains
(Pan & Yang, 2009). Early unsupervised domain adaptation methods reweighed the source instances
1
Under review as a conference paper at ICLR 2021
based on their associations to the target domain with regard to the human engineered features (Gong
et al., 2013). Recent methods are largely based on deep neural networks, which can automatically
extract features from massive data. One possible way is to minimize some measures of domain dis-
tance such as maximum mean discrepancy (MMD) (Yan et al., 2017) and correlation distances (Sun
& Saenko, 2016). On par with these distance minimizing methods, adversarial domain adaptation
introduces adversarial learning (Goodfellow et al., 2014) to impose domain-invariant constraint to
the latent space. The learned domain-invariant features are supposed to contain task discriminative
information which can be applied to conduct classification. These adversarial domain adaptation
methods (Long et al., 2018b; Wu et al., 2020) have yielded remarkable performance gains.
For the domain adaptation methods, an essential prerequisite is the adaptability should remain at a
small value in the domain alignment process. When the adaptability is poor, a good domain adapta-
tion model can not be obtained. Since domain alignment will inevitably distort the original feature
distributions and enlarge the value of adaptability, adversarial domain adaptation is risky in this
regard. In order to address this issue, we propose a novel dual adversarial training (DAT) frame-
work, which introduces class-invariant features in domain adaptation. Considering the importance
of domain-invariant features in domain adaptation, it is intuitive to explore the feasibility of applying
class-invariant features in domain adaptation. The generation of class-invariant feature can be for-
mulated into a two-player mini-max game which is similar to that of domain-invariant feature. The
class-invariant features are supposed to contain domain-specific information. Our proposed DAT
utilizes class-invariant features drawn from the source domain to adapt the classifier from the source
to the target with guaranteed adaptability. This work aims to provide an alternative for the main-
stream domain adaptation methods which focus on reducing the domain divergence. Our method
demonstrates that we can improve the generalization ability of the model on the target domain via
optimizing the adaptability and the class-invariant features, which contain domain-specific infor-
mation of the source domain, can benefit the classification on the target domain. The empirical
experimental results on four benchmarks show the promise of our approach by yielding state-of-the-
art classification results. The contributions of our paper are summarized as follows:
•	We propose a dual adversarial training framework, which introduces class-invariant fea-
tures of the source domain in adversarial domain adaptation to guarantee a good adaptabil-
ity, for unsupervised domain adaptation.
•	The proposed approach demonstrates that we can train a good domain adaptation model by
optimizing the generalization error rate of the ideal joint labeling function on the source and
target domains. This method can be regarded as an alternative for the mainstream domain
adaptation methods which focus on reducing domain divergence.
•	We empirically validate the efficacy of our method on four unsupervised domain adaptation
benchmarks, our proposed DAT can yield state-of-the-art results.
2	Related Work
The main objective of domain adaptation is to transfer the knowledge learned from a label-abundant
source domain to a label-scarce target domain. Unsupervised domain adaptation tackles a more
challenging scenario where there is no direct access to the label information of the target domain.
Domain adaptation methods based on deep neural networks have achieved impressive success in re-
cent years. Some methods directly minimize domain discrepancy measured by certain metrics, such
as: maximum mean discrepancy (MMD) (Yan et al., 2017; Li et al., 2018; Long et al., 2018a) and
correlation distances (Sun & Saenko, 2016). The deep domain confusion (DDC) utilized MMD in
the last fully-connected layer to learn features containing transferability and discriminability (Gret-
ton et al., 2007). The deep adaptation network (DAN) applied MMD to layers embedded in a
reproducing kernel hilbert space, effectively matching higher order statistics of the two distributions
(Long et al., 2015). The joint adaptation network (JAN) learned a learner by aligning the joint distri-
butions of multiple domain-specific layers across different domains based on a joint MMD criterion
(Long et al., 2017). The deep correlation alignment (CORAL) proposed to match the means and
covariances of two distributions (Sun & Saenko, 2016).
Adversarial learning was pioneered by generative adversarial networks (GANs) (Goodfellow et al.,
2014), which was first introduced for image generation. It plays a two player mini-max game be-
tween a generator and a discriminator. The discriminator aims to distinguish real images from
2
Under review as a conference paper at ICLR 2021
generated images, while the generator tries to deceive the discriminator. When these two networks
reach an equilibrium, the generated images can not be identified by the discriminator. With insights
from both the theory (Ben-David et al., 2010) and the adversarial learning (Goodfellow et al., 2014),
(Ganin et al., 2016) proposed a domain discriminative neural network (DANN) which can learn
domain-invariant features by exploiting adversarial learning between a domain discriminator and
a feature extractor. It mapped two distributions into a shared latent space and performed domain
alignment. Most recent domain adaptation methods followed this line and enhanced the domain-
invariant constraint to the latent space to make the improvement. The adversarial discriminative
domain adaptation (ADDA) used asymmetric feature extractors for the two domains to conduct
the alignment (Tzeng et al., 2017). The multi-adversarial domain adaptation (MADA) captured
multi-mode structures by re-weighting features with category predictions (Pei et al., 2018). The
generate-to-adapt method (GTA) generated source-like images using source features and target-like
images using target features to train the method which can minimize the distance between the gen-
erated image distributions (Sankaranarayanan et al., 2018). The cycle-consistent adversarial domain
adaptation (CyCADA) implemented domain adaptation at both pixel-level and feature-level by us-
ing cycle-consistent adversarial training (Hoffman et al., 2018). The conditional adversarial domain
adaptation (CDAN) conditioned the domain discriminator on discriminative information by multi-
plicative interactions between feature representations and predictions (Long et al., 2018b).
Different from the above methods, our proposed DAT approach extracts class-invariant features
from the source domain by playing a two-player mini-max game between a feature extractor and
a multinomial task discriminator, and uses the class-invariant features to optimize the adaptabil-
ity during the domain alignment to improve the system performance. In conventional adversar-
ial domain adaptation, class-invariant features, which contain domain-specific information, are re-
garded as noises such that they are often ignored in domain adaptation since they can deteriorate
the domain-invariance of the learned features. The domain separation network (DSN) introduced
domain-specific spaces for both source and target domains and demonstrated that domain-specific
information can only be beneficial to its own domain (Bousmalis et al., 2016). The usage of domain-
specific information of DSN in domain adaptation is limited. Our method demonstrates that the
source domain-specific information can be applied in classification on the target domain and im-
prove the accuracy. Our method aims to boost the system performance via optimizing the adaptabil-
ity instead of further reducing the domain discrepancy.
3	Method
In this work, we consider unsupervised domain adaptation in the following setting. There exists
abundant labeled instances in the source domain, Ds = {(xis , yis)}in=s 1 with xis ∈ X and yis ∈ Y,
and a set of unlabeled instances in the target domain, Dt = {xit}in=t 1 with xit ∈ X. The data in the
two domains are drawn from different distributions S and T, but share the same label space. The
main objective is to learn a prediction model h : X → Y that has a good capacity of generalizing on
both source and target domains.
3.1	Adversarial Domain Adaptation
The key idea of adversarial domain adaptation is to learn domain-invariant features that can be
generalized across domains. Starting from the domain adversarial neural network (DANN) (Ganin
et al., 2016), adversarial domain adaptation methods have deployed the adversarial learning strategy
to learn feature representations to bridge the domain divergence. Considering DANN as an example,
the base network is composed of three components: a feature extractor F, a task-specific classifier
C and a binary domain discriminator D. The feature extractor F : X → Rm can map any input
instance x ∈ X from the input space X into a learned representation space F (x) ∈ Rm . The task-
specific classifier C : Rm → Y can transform a feature vector in the latent space to the label space
Y. The domain discriminator D : Rm → [0, 1] separates the source features (with domain index 0)
from the target ones (with domain index 1) in the latent space. The adversarial learning is formulated
as a two-player mini-max game between the feature extractor F and the domain discriminator D:
the domain discriminator aims to distinguish features between the source and target domains, while
the feature extractor tries to confuse the domain discriminator. The intuition is that if a strong
3
Under review as a conference paper at ICLR 2021
Input
[£d(KRd)]
Figure 1: The architecture of the proposed dual adversarial training (DAT) method. Our DAT con-
sists of five components: the domain-related feature extractor Fd is used to capture class-invariant
features, the class-related feature extractor Fs aims to learn domain-invariant features, the multino-
mial task discriminator Dt identifies the label of the input feature, the binary domain discriminator
Dd differentiates between the source features and the target features, and the classifier C is used to
conduct the classification. Lc(Fd, Fs, C) is the cross-entropy loss, Ld(Fs, Dd) and Lcd(Fd, Dt) are
adversarial losses that guide the domain-invariant feature generation and the class-invariant feature
generation, respectively.

domain discriminator can not identify the origin of the feature, the learned features can be regarded
as domain-invariant. Formally, DANN can be formulated as:
min max Lc(F, C) + λdLd(F, D)
Lc(F,C ) = E(Xs ,ys)〜S '(C(F (Xs )),ys)
(1)
(2)
Ld(F,D) = Exs 〜S log[D(F (xs))]+ Ext 〜T log[1 - D(F (xt))]	(3)
Where '(∙, ∙) is the canonical cross-entropy loss, and λd is a trade-off hyperparameter.
3.2	Class-invariant Feature
In adversarial domain adaptation, the domain-invariant features, which capture the task discrimina-
tive information, play an important role. It is natural to raise the following questions: (a) How to
extract class-invariant features. (b) Whether it is possible to apply class-invariant features in do-
main adaptation. In unsupervised domain adaptation, at training time, we have an access to a set of
training instances {x1, x2, ..., xN} from both the source and target domains. We denote with di the
binary variable (domain label) for each instance, which indicates whether xi comes from the source
domain (di = 0) or from the target domain (di = 1). These instances and their domain labels can be
used to obtain domain-invariant features via adversarial learning. By replacing the binary domain
discriminator D with a multinomial task discriminator Dt, we can use adversarial learning to obtain
class-invariant features by processing the instances and their corresponding labels. Since we have
no access to the label information of the target data, the class-invariant features can only be learned
from the source domain, which can be encoded as follows:
minmax Ld (F,Dt) = E(xs,ys)〜S '(Dt (F (xs)),ys)	(4)
Considering that the class-invariant features contain domain-specific information, which has been
demonstrated to be only beneficial to its own domain (Bousmalis et al., 2016). It is challenging to
apply the source class-invariant features in classification on the target data.
4
Under review as a conference paper at ICLR 2021
Figure 2: The evaluating process of the DAT method.
Assume an image is composed of two types of information: (1) task discriminative information,
which carries the class-specific information of the image; (2) domain discriminative information,
which corresponds to the context information of the image. These two types of information are
supposed to represent each individual characteristic of an image. For a source instance and a target
instance that share the same label, we can obtain their domain-invariant features and class-invariant
features. If these features contain no noise, which means that the domain-invariant features contain
no domain-related information and the class-invariant features carry no task-related information.
When we combine the class-invariant features of the source instance and the domain-invariant fea-
tures of the target instance, the combination is expected to contain all the essential information of the
source instance. In other words, the combination of the class-invariant features of the source instance
and the domain-invariant features of the target instance should represent identical characteristics of
the combination of the class-invariant features and domain-invariant features of the source instance.
If we feed the combination of the class-invariant features of the source instance and the domain-
invariant features of the target instance to a classifier which is trained on the source domain, it is
supposed to yield the accurate prediction. Therefore, it is possible to apply source class-invariant
features for domain adaptation.
3.3	Dual Adversarial Training
In this work, we propose a dual adversarial training (DAT) framework for unsupervised domain
adaptation. As illustrated in Figure 1, our model consists of five components: a domain-related
feature extractor Fd, a multinomial task discriminator Dt, a class-related feature extractor Fs, a
binary domain discriminator Dd, and a classifier C. The domain-related feature extractor Fd learns
to capture the class-invariant features, while the class-related feature extractor Fs learns to capture
domain-invariant features. There exists two two-player mini-max games in our approach. The first
one is played between Fd and Dt , aiming to learn class-invariant features. The second one is played
between Fs and Dd, aiming to learn domain-invariant features. The input data from the source
domain should be involved in both games while the target data only participates in the second one.
Since we need to use the combination of a class-invariant feature and a domain-invariant feature to
conduct classification, we redefine the classification loss as:
Lc(Fd, FsQ = E(χs,ys)〜S'(C([Fd(xs), Fs(Xs)]), ys)
(5)
Where [∙, ∙] indicates the concatenation of two vectors. Formally, our proposed DAT can be formu-
lated as:
Fdm,Fisn,CDmt,aDxdLc(Fd,Fs,C)+λdLd(Fs,Dd)+λcLcd(Fd,Dt)
(6)
Where λd and λc are hyperparameters that trade-off different loss functions.
5
Under review as a conference paper at ICLR 2021
3.4	Training Procedure
The training algorithm of DAT, which uses mini-batch stochastic gradient descent, is presented in
Algorithm 1. In each iteration, the source and target samples are fed into the model to generate
class-invariant features and domain-invariant features for the consequent classification. λd and λc
are hyperparameters that balance different losses. When evaluating on the target domain, we need
to use some source data to provide class-invariant features for classification. In our experiments, we
draw samples from the source training set to provide domain-specific information when evaluating.
The evaluating procedure is illustrated in Figure 2.
Algorithm 1 Stochastic gradient descent training algorithm of DAT
1:	Input: Source domain: Ds , target domain: Dt and batch size: N.
2:	Output: Configurations of DAT
3:	Initialize λd and λc
4:	for number of training iterations do
5:	(Xs,ys) J RANDOMSAMPLE(Ds, N)
6:	(Xt) J RANDOMSAMPLE(Dt, N)
7:	Calculate lD =λdLd(Fs,Dd)+λcLcd(Fd,Dt);
Update Dd and Dt by ascending along gradients NlD.
8:	Calculate loss=Lc(Fd, Fs, C)+λdLd(Fs, Dd)+λtLcd(Fd, Dt);
Update Fs , Fd and C by descending along gradients Nloss.
9:	end for
3.5	Theory Understanding
Most domain adaptation methods are motivated by the theory (Ben-David et al., 2010).
Theorem 1. (Ben-David et al., 2010) Let H be the hypothesis space, given two domains S and T,
for any h ∈ H, we have
ET(h) ≤ CS (h) + 2dH∆H(S, T) + λ	⑺
where T (h) is the expected error on the target domain, S (h) is the expected error on the source
domain, dH∆H (S, T) is the H∆H-distance between S and T, which can be defined as:
dH∆H(S,T) = 2 sup ∣Eχ〜S[h(x) = h0(x)] — Ex〜T[h(x) = h0(x)]]
h,h0∈H
(8)
and λ is the adaptability which is measured by the error of the ideal joint hypothesis h, defined as
h* = arg minh∈H ES(h) + ET(h), on the source and target domains, such that
λ = ES (h*)+ ET (h*)	(9)
The H∆H-distance measures the divergence between the source and target feature distributions. In
typical adversarial domain adaptation, methods focus on minimizing the H∆H-distance to enhance
domain-invariance of the latent space, while the classifier is simultaneously trained on the source
labeled data to reduce the source error. In most cases, the adaptability λ is treated as a constant,
which is expected to remain at a small value to guarantee the feasibility of domain adaptation.
However, (Liu et al., 2019) demonstrated that in the process of domain alignment, diminishing
domain-specific information will inevitably breaks the class discriminative structures of the original
representations, which will lead to a poor λ. In this paper, we introduce class-invariant features
to complement domain-invariant features by providing domain-specific information. Our proposed
method focuses on optimizing adaptability to implement domain adaptation and can be regarded
as an alternative for the mainstream domain adaptation approaches which focus on minimizing the
H∆H-distance.
4 Experiments
In this section, we evaluate our proposed DAT framework on four unsupervised domain adaptation
benchmarks: Office-31, ImageCLEF-DA, VisDA-2017 and Digits.
6
Under review as a conference paper at ICLR 2021
Table 1: Accuracy (%) on Office-31.
Method
ResNet-50 (He et al., 2016)
DAN (Long et al., 2015)
DANN (Ganin & Lempitsky, 2015)
JAN (Long et al., 2017)
GTA (Sankaranarayanan et al., 2018)
MADA (Pei et al., 2018)
CDAN (Long et al., 2018b)
DAT (Proposed)
A一W	D一W	W→D	A→D	D→A	W→A	Avg
68.4±0.2 96.7±0.1 ~99.3±0.1 ~68.9±0.2 62.5±0.3 60.7±0.3 76.1
80.5±0.4
82.0±0.4
85.4±0.3
89.5±0.5
90.0±0.1
93.1±0.2
90.7±0.3
97.1±0.2
96.9±0.2
97.4±0.2
97.9±0.3
97.4±0.1
98.2±0.2
99.0±0.1
99.6±0.1
99.1±0.1
99.8±0.2
99.8±0.4
99.6±0.1
100.0±0.0
100.0±0.0
78.6±0.2
79.7±0.4
84.7±0.3
87.7±0.5
87.8±0.2
89.8±0.3
90.0±0.5
63.6±0.3 62.8±0.2 80.4
68.2±0.4 67.4±0.5 82.2
68.6±0.3 70.0±0.4 84.3
72.8±0.3 71.4±0.4 86.5
70.3±0.3 66.4±0.3 85.2
70.1±0.4 68.0±0.4 86.6
71.0±0.3 69.9±0.3 86.8
4.1	DataSet
Office-31 (Saenko et al., 2010) is a standard domain adaptation dataset. It contains images among
31 classes from 3 domains: Amazon (A) with 2817 images, Webcam (W) with 795 images and
DSLR (D) with 498 images. We conduct evaluation on all 6 tasks: A→W, D→W, W→D, A→D,
D→A and W→A.
ImageCLEF-DA is a benchmark for ImageCLEF 2014 domain adaptation challenges. It is or-
ganized by selecting 12 common classes shared by three domains: Caltech-256 (C), ImageNet
ILSVRC 2012 (I), and Pascal VOC 2012 (P). Each domain contains 600 images and 50 images
for each class. We evaluate all methods on 6 tasks: I→P, P→I, I→C, C→I, C→P and P→C.
Visda-2017 (Peng et al., 2017) is a large simulation-to-real dataset with two domains. The source
domain is termed as Synthetic which contains images obtained by rendering 3D models of the same
object classes as in the real data from different angles and under different lighting conditions. The
target domain is termed as Real which comprises natural images. We evaluate our methods on the
task: Synthetic→Real.
Digits. We investigate three digits datasets: MNIST, USPS and Street View House Numbers
(SVHN). Each dataset contains digit images of 10 classes (0-9). We adopt the experimental set-
tings of CyCADA (Hoffman et al., 2018) with three tasks: MNIST to USPS (M→U), USPS to
MNIST (U→M) and SVHN to MNIST (S→M).
4.2	Comparison Methods
We compare our proposed DAT method with a number of state-of-the-art methods. Deep adap-
tation network (DAN) (Long et al., 2015), domain adversarial neural network (DANN) (Ganin
et al., 2016), joint adaptation network (JAN) (Long et al., 2017), generate-to-adapt (GTA) (Sankara-
narayanan et al., 2018), multi-adversarial domain adaptation (MADA) (Pei et al., 2018), conditional
domain adaptation network (CDAN) (Long et al., 2018b), adversarial discriminative domain adap-
tation (ADDA) (Tzeng et al., 2017) and cycle-consistent adversarial domain adaptation (CyCADA)
(Hoffman et al., 2018).
4.3	Implementation Details
The standard evaluation protocols (Long et al., 2018b; Hoffman et al., 2018) for unsupervised do-
main adaptation are followed in our experiments. We use all labeled source samples and unlabeled
target samples and compare the average classification accuracy based on three random experiments.
No data augmentation is used in any of the experiments to allow a fair comparison. For Office-31 and
ImageCLEF-DA datasets, we use ResNet-50 (He et al., 2016) pre-trained on ImageNet (Krizhevsky
et al., 2012) as the backbone. For Visda-2017 dataset, we use ResNet-101 (He et al., 2016) pre-
trained on ImageNet (Krizhevsky et al., 2012) as the backbone. For digits datasets, we adopt a
modified version of Lenet architecture as the base network, and train models from scratch. For each
backbone network, we use all its layers up to the second last one as the class-related feature extractor
Fs . The domain-related feature extractor Fd adopts the same architecture as Fs . The classifier C
uses a single fully-connected layer whose input dimension should be the sum of the output dimen-
sions of Fs and Fd. For binary domain discriminator Dd, we use the same architecture as DANN
7
Under review as a conference paper at ICLR 2021
Table 2: Accuracy (%) on ImageCLEF-DA.							
Method	I→P	P→I	I→C	C→I	C→P	P→C	Avg
ResNet-50 (He et al., 2016)	74.8±0.3	83.9±0.1	91.5±0.3	78.0±0.2	65.5±0.3	91.2±0.3	80.7
DAN (Long et al., 2015)	74.5±0.4	82.2±0.2	92.8±0.2	86.3±0.4	69.2±0.4	89.8±0.4	82.5
DANN (Ganin & Lempitsky, 2015)	75.0±0.6	86.0±0.3	96.2±0.4	87.0±0.5	74.3±0.5	91.5±0.6	85.0
JAN (Long et al., 2017)	76.8±0.4	88.0±0.2	94.7±0.2	89.5±0.3	74.2±0.3	91.7±0.3	85.8
MADA (Pei et al., 2018)	75.0±0.3	87.9±0.2	96.0±0.3	88.8±0.3	75.2±0.2	92.2±0.3	85.8
CDAN (Long et al., 2018b)	76.7±0.3	90.6±0.3	97.0±0.4	90.5±0.4	74.5±0.3	93.5±0.4	87.1
DAT (Proposed)	77.0±0.2	91.1±0.2	97.3±0.3	90.8±0.3	74.5±0.5	93.7±0.3	87.4
Table 3: AccUracy (%) on Digits and VisDA-2017.
Method	M→U	U→M	S→M	Avg	Method	Synthetic→Real
No Adaptation (Hoffman et al., 2018)	82.2	69.6	67.1	73.0	-ResNet-101(He et al.,2016)	52.4
DANN (Ganin & Lempitsky, 2015)	90.4	94.7	84.2	89.8	DANN (Ganin & Lempitsky, 2015)	57.4
ADDA (Tzeng et al., 2017)	89.4	90.1	86.3	88.6	DAN (Long et al., 2015)	61.1
CyCADA (Hoffman et al., 2018)	95.6	96.5	90.4	94.2	JAN (Long et al., 2017)	65.7
CDAN (Long et al., 2018b)	93.9	96.9	88.5	93.1	CDAN (Long et al., 2018b)	73.7
DAT (Proposed)	93.7	97.4	93.1	94.7	DAT (Proposed)	74.4
(Ganin & Lempitsky, 2015). The architecture of the multinomial task discriminator Dt is similar to
that of Dd , the only difference is that for the last layer, a task-specific fUlly-connected layer is Used
for Dt while a sigmoid layer is Used for Dd .
We implement all experiments Using PyTorch. We adopt mini-batch SGD with momentUm of 0.9
and the learning rate annealing strategy as (Ganin et al., 2016): the learning rate is adjUsted by
ηp =(/p)e, where P denotes the process of training epochs that is normalized to be in [θ, 1], and
we set η0 = 0.01, θ = 10, β = 0.75, which are optimized to promote convergence and low errors
on the source domain. λd is progressively changed from 0to1by multiplying to 1-：：怖(-北),where
δ = 10. For all experiments, we select λc in the range {0.0001, 0.001, 0.01, 0.1, 1.0} via tUning on
the unlabeled target data.
4.4	Results
The results on Office-31 are reported in Table 1. Our proposed DAT method can outperform other
comparison methods on three out of six tasks: D→W, W→D and A→D. Moreover, our method can
achieve the best average classification accuracy on this dataset. For the benchmark ImageCLEF-
DA, the results are shown in Table 2. The proposed DAT exceeds comparison methods in all tasks,
but with small performance gains. This is reasonable because the three domains in ImageCLEF-
DA has identical image size and are balanced in each class. Promising results are also obtained
on VisDA-2017 and Digits datasets, as presented in Table 3. For Digits datasets, our method can
yield better results on two tasks: U→M and S→M, we can also achieve best average performance
compared with other methods. For VisDA-2017 dataset, the DAT method produces the best average
classification accuracy among all comparison methods, and outperform the baseline of ResNet-101
model pre-trained on ImageNet with a great margin. For more experiments and the analysis of
class-invariant feature, please see the Appendix.
5 Conclusion
In this work, we propose a novel dual adversarial training (DAT) framework for unsupervised do-
main adaptation. The DAT method introduces class-invariant features to adversarial domain adap-
tation for optimizing the adaptability to improve the system performance. This approach provides
an alternative for the mainstream domain adaptation methods which focus on minimizing the di-
vergence between the source and target domains. We demonstrate that the class-invariant features
learned from the source domain can be beneficial for the classification on the target domain. The
proposed method can yield state-of-the-art results on four unsupervised domain adaptation bench-
marks, which illustrates the promise of our method.
8
Under review as a conference paper at ICLR 2021
References
Shai Ben-David, John Blitzer, Koby Crammer, and Fernando Pereira. Analysis of representations
for domain adaptation. In Advances in neural information processing systems, pp. 137-144, 2007.
Shai Ben-David, John Blitzer, Koby Crammer, Alex Kulesza, Fernando Pereira, and Jennifer Wort-
man Vaughan. A theory of learning from different domains. Machine learning, 79(1-2):151-175,
2010.
Konstantinos Bousmalis, George Trigeorgis, Nathan Silberman, Dilip Krishnan, and Dumitru Erhan.
Domain separation networks. In Advances in neural information processing systems, pp. 343-351,
2016.
Yaroslav Ganin and Victor Lempitsky. Unsupervised domain adaptation by backpropagation. In
International conference on machine learning, pp. 1180-1189. PMLR, 2015.
Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo Larochelle, Francois
Laviolette, Mario Marchand, and Victor Lempitsky. Domain-adversarial training of neural net-
works. The Journal of Machine Learning Research, 17(1):2096-2030, 2016.
Boqing Gong, Kristen Grauman, and Fei Sha. Connecting the dots with landmarks: Discrimina-
tively learning domain-invariant features for unsupervised domain adaptation. In International
Conference on Machine Learning, pp. 222-230, 2013.
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair,
Aaron Courville, and Yoshua Bengio. Generative adversarial nets. In Advances in neural infor-
mation processing systems, pp. 2672-2680, 2014.
Arthur Gretton, Karsten Borgwardt, Malte Rasch, Bernhard Scholkopf, and Alex J Smola. A kernel
method for the two-sample-problem. In Advances in neural information processing systems, pp.
513-520, 2007.
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recog-
nition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pp.
770-778, 2016.
Geoffrey Hinton, Li Deng, Dong Yu, George E Dahl, Abdel-rahman Mohamed, Navdeep Jaitly,
Andrew Senior, Vincent Vanhoucke, Patrick Nguyen, Tara N Sainath, et al. Deep neural networks
for acoustic modeling in speech recognition: The shared views of four research groups. IEEE
Signal processing magazine, 29(6):82-97, 2012.
Judy Hoffman, Eric Tzeng, Taesung Park, Jun-Yan Zhu, Phillip Isola, Kate Saenko, Alexei Efros,
and Trevor Darrell. Cycada: Cycle-consistent adversarial domain adaptation. In International
conference on machine learning, pp. 1989-1998. PMLR, 2018.
Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classification with deep convo-
lutional neural networks. In Advances in neural information processing systems, pp. 1097-1105,
2012.
Shuang Li, Shi-ji Song, and Cheng Wu. Layer-wise domain correction for unsupervised domain
adaptation. Frontiers of Information Technology & Electronic Engineering, 19(1):91-103, 2018.
Hong Liu, Mingsheng Long, Jianmin Wang, and Michael Jordan. Transferable adversarial train-
ing: A general approach to adapting deep classifiers. In International Conference on Machine
Learning, pp. 4013-4022, 2019.
Mingsheng Long, Yue Cao, Jianmin Wang, and Michael Jordan. Learning transferable features with
deep adaptation networks. In International conference on machine learning, pp. 97-105. PMLR,
2015.
Mingsheng Long, Han Zhu, Jianmin Wang, and Michael I Jordan. Deep transfer learning with joint
adaptation networks. In International conference on machine learning, pp. 2208-2217. PMLR,
2017.
9
Under review as a conference paper at ICLR 2021
Mingsheng Long, Yue Cao, Zhangjie Cao, Jianmin Wang, and Michael I Jordan. Transferable
representation learning with deep adaptation networks. IEEE transactions on pattern analysis
and machine intelligence, 41(12):3071-3085, 2018a.
Mingsheng Long, Zhangjie Cao, Jianmin Wang, and Michael I Jordan. Conditional adversarial do-
main adaptation. In Advances in Neural Information Processing Systems, pp. 1640-1650, 2018b.
Sinno Jialin Pan and Qiang Yang. A survey on transfer learning. IEEE Transactions on knowledge
and data engineering, 22(10):1345-1359, 2009.
Zhongyi Pei, Zhangjie Cao, Mingsheng Long, and Jianmin Wang. Multi-adversarial domain adap-
tation. arXiv preprint arXiv:1809.02176, 2018.
Xingchao Peng, Ben Usman, Neela Kaushik, Judy Hoffman, Dequan Wang, and Kate Saenko.
Visda: The visual domain adaptation challenge. arXiv preprint arXiv:1710.06924, 2017.
Kate Saenko, Brian Kulis, Mario Fritz, and Trevor Darrell. Adapting visual category models to new
domains. In European conference on computer vision, pp. 213-226. Springer, 2010.
Swami Sankaranarayanan, Yogesh Balaji, Carlos D Castillo, and Rama Chellappa. Generate to
adapt: Aligning domains using generative adversarial networks. In Proceedings of the IEEE
Conference on Computer Vision and Pattern Recognition, pp. 8503-8512, 2018.
Baochen Sun and Kate Saenko. Deep coral: Correlation alignment for deep domain adaptation. In
European conference on computer vision, pp. 443-450. Springer, 2016.
Eric Tzeng, Judy Hoffman, Kate Saenko, and Trevor Darrell. Adversarial discriminative domain
adaptation. In Proceedings of the IEEE conference on computer vision and pattern recognition,
pp. 7167-7176, 2017.
Hemanth Venkateswara, Jose Eusebio, Shayok Chakraborty, and Sethuraman Panchanathan. Deep
hashing network for unsupervised domain adaptation. In Proceedings of the IEEE Conference on
Computer Vision and Pattern Recognition, pp. 5018-5027, 2017.
Yuan Wu and Yuhong Guo. Dual adversarial co-learning for multi-domain text classification. arXiv
preprint arXiv:1909.08203, 2019.
Yuan Wu, Diana Inkpen, and Ahmed El-Roby. Dual mixup regularized learning for adversarial
domain adaptation. arXiv preprint arXiv:2007.03141, 2020.
Hongliang Yan, Yukang Ding, Peihua Li, Qilong Wang, Yong Xu, and Wangmeng Zuo. Mind the
class weight bias: Weighted maximum mean discrepancy for unsupervised domain adaptation.
In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2272-
2281, 2017.
A Experiments
We also conduct experiments on the domain adaptation benchmark: Office-Home.
Office-Home (Venkateswara et al., 2017) is a more complicated dataset than Office-31, which con-
sists of around 15500 images from 65 classes in office and home settings. There exists 4 domains in
this dataset: Artistic Images (Ar), Clip Art (Cl), Product Images (Pr) and Real-World Images (Rw).
From Table 4, it can be noted that our proposed DAT method can yield the second best results. The
improvement induced by DAT on Office-Home dataset is less than that on the other four benchmarks.
An interpretation is that since Office-Home is with more classes compared with other benchmarks
and difficult in each domain with much lower in-domain classification accuracy (Venkateswara et al.,
2017), it’s possible that the learned class-invariant features are contaminated by the task-related in-
formation in the presence of large number of classes. In summary, the proposed DAT approach
works reasonably well on five domain adaptation benchmarks, highlighting the power of class-
invariant feature in classification on both source and target domains.
10
Under review as a conference paper at ICLR 2021
Table 4: Accuracy (%) on Office-Home.
Method	Ar→Cl	Ar→Pr	Ar→Rw	Cl→Ar	Cl→Pr	Cl→Rw	Pr→Ar	Pr→Cl	Pr→Rw	Rw→Ar	Rw→Cl	Rw→Pr	Avg
ResNet-50 (He et al., 2016)	34.9	50.0	58.0	34.7	41.9	46.2	38.5	31.2	60.4	53.9	41.2	59.9	46.1
DAN (Long et al., 2015)	43.6	57.0	67.9	45.8	56.5	60.4	44.0	43.6	67.7	63.1	51.5	74.3	56.3
DANN (Ganin & Lempitsky, 2015)	45.6	59.3	70.1	47.0	58.5	60.9	46.1	43.7	68.5	63.2	51.8	76.8	57.6
JAN (Long et al., 2017)	45.9	61.2	68.9	50.4	59.7	61.0	45.8	43.4	70.3	63.9	52.4	76.8	58.3
CDAN (Long et al., 2018b)	49.0	69.3	74.5	54.4	66.0	68.4	55.6	48.3	75.9	68.4	55.4	80.5	63.8
DAT (Proposed)	47.8	65.9	73.4	48.3	62.7	64.2	48.7	46.9	74.5	68.2	53.4	80.7	61.2
(a) Adaptability	(b) A-distance	(C) λc
Figure 3: Analysis of adaptability, domain divergence and parameter sensitivity.
B Analysis
B.1	Adaptability
In this study, we investigate how the class-invariant feature influences the adaptability λ, which is
measured by the expected error of the ideal joint hypothesis on both source and target domains. In
order to compute λ, we train an multi-layer perceptron (MLP) classifier over the feature representa-
tions learned by DANN (Ganin & Lempitsky, 2015) and DAT on VisDA-2017. The MLP classifier
is trained on all labeled data from both source and target domains. It should be noted that the tar-
get labels are only used for this analysis. When training the MLP classifier, the feature extractors
in DANN and DAT should be fixed. The error of the ideal joint hypothesis on the source domain,
the target domain, and their sum λ are shown in Figure 3(a). As expected, DAT has a lower λ
than DANN, which suggests that the introduction of class-invariant feature in adversarial domain
adaptation can effectively reduce the adaptability.
B.2	Distribution Discrepancy
As shown in the domain adaptation theory (Ben-David et al., 2010), the domain discrepancy dH∆H
and adaptability λ are two important factors that bound the generalization error on the target domain.
The A-distance (Ben-David et al., 2010) is a measure of domain discrepancy, defined as dA =
2(1 - 2), where is the error rate of the domain discriminator trained to differ source features
from target features. In this study, we investigate the A-distance of ResNet-50 (He et al., 2016),
DANN (Ganin & Lempitsky, 2015) and DAT on two tasks of Office-31 dataset: A→W and D→W.
The results are shown in Figure 3(b). It can be noted that the adversarial domain adaptation can
effectively reduce the domain divergence. The A-distance with features of DAT is similar to that
of DANN, this combined with the experimental results, reveals that our DAT approach focuses on
optimizing the adaptability to improve the system performance.
B.3	Parameter Sensitivity Analysis
In this section, we discuss the sensitivity of our approach to the values of the hyperparameters λc .
We evaluate the influence of λc on the Digits dataset, especially, the U→M task. λc is explored in
the range {0.0001, 0.001, 0.01, 0.1, 1.0}. The results are shown in Figure 3(c). From Figure 3(c),
we can see that the selection of λc has an influence for the classification accuracy. With the increase
of λc, the accuracy increases dramatically and reaches its best at λc = 1. This illustrates that a
properly selected λc can effectively boost the classification accuracy of the model.
11