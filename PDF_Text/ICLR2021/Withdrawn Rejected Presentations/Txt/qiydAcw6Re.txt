Under review as a conference paper at ICLR 2021
Geometry of Program Synthesis
Anonymous authors
Paper under double-blind review
Ab stract
We present a new perspective on program synthesis in which programs may be
identified with singularities of analytic functions. As an example, Turing ma-
chines are synthesised from input-output examples by propagating uncertainty
through a smooth relaxation of a universal Turing machine. The posterior distri-
bution over weights is approximated using Markov chain Monte Carlo and bounds
on the generalisation error of these models is estimated using the real log canoni-
cal threshold, a geometric invariant from singular learning theory.
1	Introduction
The idea of program synthesis dates back to the birth of modern computation itself (Turing, 1948)
and is recognised as one of the most important open problems in computer science (Gulwani et al.,
2017). However, there appear to be serious obstacles to synthesising programs by gradient descent
at scale (Neelakantan et al., 2016; Kaiser & Sutskever, 2016; Bunel et al., 2016; Gaunt et al., 2016;
Evans & Grefenstette, 2018; Chen et al., 2018) and these problems suggest that it would be appro-
priate to make a fundamental study of the geometry of loss surfaces in program synthesis, since
this geometry determines the learning process. To that end, in this paper we explain a new point of
view on program synthesis using the singular learning theory of Watanabe (2009) and the smooth
relaxation of Turing machines from Clift & Murfet (2018).
In broad strokes this new geometric point of view on program synthesis says:
•	Programs to be synthesised are singularities of analytic functions. If U ⊆ Rd is open
and K : U -→ R is analytic, then X ∈ U is a critical point of K if VK(x) = 0 and a
singularity of the function K if it is a critical point where K(x) = 0.
•	The Kolmogorov complexity of a program is related to a geometric invariant of the
associated singularity called the Real Log Canonical Threshold (RLCT). This invariant
controls both the generalisation error and the learning process, and is therefore an appro-
priate measure of “complexity” in continuous program synthesis. See Section 3.
•	The geometry has concrete practical implications. For example, a MCMC-based ap-
proach to program synthesis will find, with high probability, a solution that is of low com-
plexity (if it finds a solution at all). We sketch a novel point of view on the problem of “bad
local minima” (Gaunt et al., 2016) based on these ideas. See Section 4.
We demonstrate all of these principles in experiments with toy examples of synthesis problems.
Program synthesis as inference. We use Turing machines, but mutatis mutandis everything applies
to other programming languages. Let T be a Turing machine with tape alphabet Σ and set of states
Q and assume that on any input X ∈ Σ* the machine eventually halts with output T(x) ∈ Σ*. Then
to the machine T we may associate the set {(x, T(χ))}χ∈∑* ⊆ Σ* X Σ*. Program synthesis is the
study of the inverse problem: given a subset of Σ* × Σ* We would like to determine (if possible) a
Turing machine which computes the given outputs on the given inputs.
If we presume given a probability distribution q(x) on Σ* then we can formulate this as a problem of
statistical inference: given a probability distribution q(x, y) on Σ* × Σ* determine the most likely
machine producing the observed distribution q(x, y) = q(y|x)q(x). If we fix a universal Turing
machine U then Turing machines can be parametrised by codes w ∈ W code with U (x, w) = T(x)
for all x ∈ Σ*. We let p(y∣x, W) denote the probability of U (x, W)= y (which is either zero or one)
1
Under review as a conference paper at ICLR 2021
so that solutions to the synthesis problem are in bijection with the zeros of the Kullback-Leibler
divergence between the true distribution and the model
K(W) =//q(y ⑻q(X)IOg pqyxW) dxdy.
(1)
So far this is just a trivial rephrasing of the combinatorial optimisation problem of finding a Turing
machine T with T(x) = y for all (x, y) with q(x, y) > 0.
Smooth relaxation. One approach is to seek a smooth relaxation of the synthesis problem consisting
of an analytic manifold W ⊇ W code and an extension of K to an analytic function K : W -→ R
so that we can search for the zeros of K using gradient descent. Perhaps the most natural way to
construct such a smooth relaxation is to take W to be a space of probability distributions over W code
and prescribe a model p(y |x, w) for propagating uncertainty about codes to uncertainty about outputs
(Gaunt et al., 2016; Evans & Grefenstette, 2018). The particular model we choose is based on the
semantics of linear logic (Clift & Murfet, 2018). Supposing that such a smooth relaxation has been
chosen together with a prior 夕(W) over W, smooth program synthesis becomes the study of the
statistical learning theory of the triple (p, q,夕).
There are perhaps two primary reasons to consider the smooth relaxation. Firstly, one might hope
that stochastic gradient descent or techniques like Markov chain Monte Carlo will be effective means
of solving the original combinatorial optimisation problem. This is not a new idea (Gulwani et al.,
2017, §6) but so far its effectiveness for large programs has not been proven. Independently, one
might hope to find powerful new mathematical ideas that apply to the relaxed problem and shed light
on the nature of program synthesis. This is the purpose of the present paper.
Singular learning theory. We denote by W0 = {W ∈ W | K(W) = 0} so that
W0 ∩ W code ⊆ W0 ⊆ W
(2)
where W0 ∩ Wcode is the discrete set of solutions to the original synthesis problem. We refer to these
as the classical solutions. As the vanishing locus of an analytic function, W0 is an analytic space
over R (Hironaka, 1964, §0.1), (Griffith & Harris, 1978) and it is interesting to study the geometry of
this space near the classical solutions. Since K is a Kullback-Leibler divergence it is non-negative
and so it not only vanishes on Wo but VK also vanishes, hence every point of Wo is a singular point.
Beyond this the geometry ofW0 depends on the particular model p(y|x, W) that has been chosen, but
some aspects are universal: the nature of program synthesis means that typically Wo is an extended
object (i.e. it contains points other than the classical solutions) and the Hessian matrix of second
order partial derivatives of K at a classical solution is not invertible - that is, the classical solutions
are degenerate critical points of K. This means that singularity theory is the appropriate branch of
mathematics for studying the geometry of Wo near a classical solution. It also means that the Fisher
information matrix
I(W)ij
is degenerate at a classical solution, so that the appropriate branch of statistical learning theory is
singular learning theory (Watanabe, 2007; 2009). For an introduction to singular learning theory in
the context of deep learning see (Murfet et al., 2020).
Broadly speaking the contribution of this paper is to realise program synthesis within the frame-
work of singular learning theory, at both a theoretical and an experimental level. In more detail the
contents of the paper are:
•	We define a staged pseudo-UTM (Appendix E) which is well-suited to experiments with the
ideas discussed above. Propagating uncertainty about the code through this UTM using the
ideas of (Clift & Murfet, 2018) defines a triple (p, q,夕)associated to a synthesis problem.
This formally embeds program synthesis within singular learning theory.
•	We realise this embedding in code by providing an implementation in PyTorch of this prop-
agation of uncertainty through a UTM. Using the No-U-Turn variant of MCMC (Hoffman
& Gelman, 2014) we can approximate the Bayesian posterior of any program synthesis
problem (of course in practice we are limited by computational constraints in doing so).
2
Under review as a conference paper at ICLR 2021
•	We explain how the real log canonical threshold (a geometric invariant) is related to Kol-
mogorov complexity (Section 3).
•	We give a simple example (Appendix C) in which W0 contains the set of classical solutions
as a proper subset and every point of W0 is a degenerate critical point of K .
•	For two simple synthesis problems detectA and parityCheck we demonstrate all of
the above, using MCMC to approximate the Bayesian posterior and theorems from Watan-
abe (2013) to estimate the RLCT (Section 5). We discuss how W0 is an extended object
and how the RLCT relates to the local dimension of W0 near a classical solution.
Related work
The idea of synthesising Turing machines can be traced back to the work of Solomonoff on inductive
inference (Solomonoff, 1964). A more explicit form of the problem was given in Biermann (1972)
who proposed an algorithmic method. Machine learning based approaches appear in Schmidhuber
(1997) and Hutter (2004), which pay particular attention to model complexity, and Gaunt et al.
(2016) and Freer et al. (2014), the latter using the notion of “universal probabilistic Turing machine”
(De Leeuw et al., 1956). A different probabilistic extension of a universal Turing machine was
introduced in Clift & Murfet (2018) via linear logic. Studies of the singular geometry of learning
models go back to Amari et al. (2003) and notably, the extensive work of Watanabe (2007; 2009).
2	Turing Machine Synthesis as Singular Learning
All known approaches to program synthesis can be formulated in terms of a singular learning prob-
lem. Singular learning theory is the extension of statistical learning theory to account for the fact
that the set of learned parameters W0 has the structure of an analytic space as opposed to an analytic
manifold (Watanabe, 2007; 2009). It is organised around triples (p, q,夕)consisting of a class of
models {p(y∣x, w) : W ∈ W}, a true distribution q(y∣x) and a prior 夕 on W.
In our approach we fix a Universal Turing Machine (UTM), denoted U , with a description tape
(which specifies the code of the Turing machine to be executed), a work tape (simulating the tape
of that Turing machine during its operation) and a state tape (simulating the state of that Turing
machine). The general statistical learning problem that can be formulated using U is the following:
given some initial string x on the work tape, predict the state of the simulated machine and the
contents of the work tape after some specified number of steps (Clift & Murfet, 2018, §7.1). For
simplicity, in this paper we consider models that only predict the final state; the necessary modifica-
tions in the general case are routine. We also assume that W parametrises Turing machines whose
tape alphabet Σ and set of states Q have been encoded by individual symbols in the tape alphabet of
U . Hence U is actually what we call a pseudo-UTM (see Appendix E). Again, treating the general
case is routine and for the present purposes only introduces uninteresting complexity.
Let Σ denote the tape alphabet of the simulated machine, Q the set of states and let L, S, R stand for
left, stay and right, the possible motions of the Turing machine head. We assume that |Q| > 1 since
otherwise the synthesis problem is trivial. The set of ordinary codes W code for a Turing machine
sits inside a compact space of probability distributions W over codes
W code := YΣ × Q × {L, S, R} ⊆ Y∆Σ × ∆Q × ∆{L, S, R} =: W (3)
where ∆X denotes the set of probability distributions over a set X, see (8), and the product is over
pairs (σ, q) ∈ Σ × Q.1 For example the point {(σ0, q0, d)}σ,q ∈ W code encodes the machine which
when it reads σ under the head in state q writes σ0, transitions into state q0 and moves in direction d.
Given w ∈ W code let stept(x, w) ∈ Q denote the contents of the state tape ofU after t timesteps
(of the simulated machine) when the work tape is initialised with x and the description tape with w.
1The space W of parameters is clearly semi-analytic, that is, it is cut out of Rd for some d by the vanishing
fι(x) = •… =fr (x) = 0 of finitely many analytic functions on open subsets of Rd together with finitely
many inequalities g1 (x) ≥ 0, . . . , gs (x) ≥ 0 where the gj (x) are analytic. In fact W is semi-algebraic, since
the fi and gj may all be chosen to be polynomial functions.
3
Under review as a conference paper at ICLR 2021
There is a principled extension of this operation of U to a smooth function
∆stept : Σ* X W -→ ∆Q	(4)
which propagates uncertainty about the symbols on the description tape to uncertainty about the
final state and we refer to this extension as the smooth relaxation of U . The details are given in
Appendix F but at an informal level the idea behind the relaxation is easy to understand: to sample
from ∆ stept(x, w) we runU to simulate t timesteps in such a way that whenever the UTM needs to
“look at” an entry on the description tape we sample from the corresponding distribution specified
by w.2 The significance of the particular smooth relaxation that we use is that its derivatives have a
logical interpretation (Clift & Murfet, 2018, §7.1).
The class of models that We consider is
p(y∣x,w) = ∆stept(x,w)	(5)
where t is fixed for simplicity in this paper. More generally we could also view X as consisting of a
sequence and a timeout, as is done in (Clift & Murfet, 2018, §7.1). The construction of this model
is summarised in Figure 1.
∆ step
∆ step
Figure 1: The state of U is represented by the state of the work tape, state tape and description (code)
tape. The work tape is initialised with a sequence X ∈ Σ*, the code tape with W ∈ W and the state
tape with some standard initial state, the smooth relaxation ∆ step of the pseudo-UTM is run for t
steps and the final probability distribution over states is y.
Definition 2.1 (Synthesis problem). A synthesis problem for U consists of a probability distribution
q(x, y) over Σ* × Q. We say that the synthesis problem is deterministic if there is f : Σ* —› Q
such that q(y = f (x)|x) = 1 for all X ∈ Σ*.
Definition 2.2. The triple (p, q,夕)associated to a synthesis problem is the model P of (5) together
with the true distribution q and uniform prior 夕 on the parameter space W. The Kullback-Leibler
function K(w) of the synthesis problem is defined by (1) and a solution to the synthesis problem is
a point of W0. A classical solution is a point of W0 ∩ W code .
As ∆ stept is a polynomial function, K is analytic and so W0 is a semi-analytic space (it is cut
out of the semi-analytic space W by the vanishing of K). If the synthesis problem is deterministic
and q(χ) is uniform on some finite subset of Σ* then Wo is semi-algebraic (it is cut out of W by
polynomial equations) and all solutions lie at the boundary of the parameter space W (Appendix D).
However in general W0 is only semi-analytic and intersects the interior of W (Example C.2). We
assume that q(y|X) is realisable that is, there exists w0 ∈ W with q(y|X) = p(y|X, w0).
A triple (p, q,夕)is regular if the model is identifiable, ie. for all inputs X ∈ Rn, the map sending W
to the conditional probability distribution p(y |X, w) is one-to-one, and the Fisher information matrix
is non-degenerate. Otherwise, the learning machine is strictly singular (Watanabe, 2009, §1.2.1).
Triples arising from synthesis problems are typically singular: in Example 2.5 below we show an
explicit example where multiple parameters W determine the same model, and in Example C.2 we
give an example where the Hessian ofK is degenerate everywhere on W0 (Watanabe, 2009, §1.1.3).
2Noting that this sampling procedure is repeated every time the UTM looks at a given entry.
4
Under review as a conference paper at ICLR 2021
Remark 2.3. Non-deterministic synthesis problems arise naturally in various contexts, for example
in the fitting of algorithms to the behaviour of deep reinforcement learning agents. Suppose an agent
is acting in an environment with starting states encoded by X ∈ Σ* and possible episode end states
by y ∈ Q. Even if the optimal policy is known to determine a computable function Σ* ——→ Q the
statistics of the observed behaviour after finite training time will only provide a function Σ* ——→ ∆Q
and if we wish to fit algorithms to behaviour it makes sense to deal with this uncertainty directly.
Definition 2.4. Let (p, q,夕)be the triple associated to a synthesis problem. The Real Log Canon-
ical Threshold (RLCT) λ of the synthesis problem is defined so that -λ is the largest pole of the
meromorphic extension (Atiyah, 1970) of the zeta function Z(z) = J K(W)Zφ(w)dw.
The more singular the analytic space W0 of solutions is, the smaller the RLCT. One way to think of
the RLCT is as a count of the effective number of parameters near W0 (Murfet et al., 2020, §4). In
Section 3 we relate the RLCT to Kolmogorov complexity and in Section 5 we estimate the RLCT of
the synthesis problem detectA given below, using the method explained in Appendix A.
Example 2.5 (detectA). The deterministic synthesis problem detectA has Σ = {, A, B},
Q = {reject, accept} and q(y|x) is determined by the function taking in a string x of A’s and B’s
and returning the state accept if the string contains an A and state reject otherwise. The conditional
true distribution q(y|x) is realisable because this function is computed by a Turing machine.
Two solutions are shown in Figure 2. On the left is a parameter wl ∈ W0 \ W code and on the
right is wr ∈ W0 ∩ W code . Varying the distributions in wl that have nonzero entropy we obtain a
submanifold V ⊆ W0 containing wl of dimension 14. This leads by (Watanabe, 2009, Remark 7.3)
to a bound on the RLCT of λ ≤ 1 (30 — 14) = 8 which is consistent with the experimental results
in Table 1. This highlights that solutions need not lie at vertices of the probability simplex, and W0
may contain a high-dimensional submanifold around a given classical solution.
tuple_l -
tuple_2 -
tuple_3 -
tuple_4 -
tuple_5 -
tuple_6 -
Figure 2: Visualisation of two solutions for the synthesis problem detectA .
2.1	The Synthesis Process
Synthesis is a problem because we do not assume that the true distribution is known: for example, if
q(y |x) is deterministic and the associated function is f : Σ* ——→ Q, We assume that some example
pairs (x, f (x)) are known but no general algorithm for computing f is known (if it were, synthesis
would have already been performed). In practice synthesis starts with a sample Dn = {(xi, yi)}in=1
from q(x, y) with associated empirical Kullback-Leibler distance
Kn (W) = 1 XX log q(y"” .	(6)
n i=1	p(yi|xi,w)
If the synthesis problem is deterministic and u ∈ W code then Kn(u) = 0 if and only if u explains
the data in the sense that stept (xi, u) = yi for 1 ≤ i ≤ n. We now review two natural ways of
finding such solutions in the context of machine learning.
Synthesis by stochastic gradient descent (SGD). The first approach is to view the process of
program synthesis as stochastic gradient descent for the function K : W ——→ R. We view Dn as a
large training set and further sample subsets Dm with m《n and compute VKm to take gradient
descent steps wi+1 = Wi — ηVKm (Wi) for some learning rate η. Stochastic gradient descent has
the advantage (in principle) of scaling to high-dimensional parameter spaces W, but in practice it is
challenging to use gradient descent to find points of W0 (Gaunt et al., 2016).
5
Under review as a conference paper at ICLR 2021
Synthesis by sampling. The second approach is to consider the Bayesian posterior associated to the
synthesis problem, which can be viewed as an update on the prior distribution 夕 after seeing Dn
p(Dn |w)p(w)	1 n	1
p(w∣Dn) = P(D)---------= Z-2(W) ɪɪ p(yi∣xi,w) = zo exp{-nKn (w) + log 2(w)}
where Z- = J 夕(W) exp(-nK-(w))dw. If n is large the posterior distribution concentrates around
solutions w ∈ W0 and so sampling from the posterior will tend to produce machines that are (nearly)
solutions. The gold standard sampling is Markov Chain Monte Carlo (MCMC). Scaling MCMC to
where W is high-dimensional is a challenging task with many attempts to bridge the gap with SGD
(Welling & Teh, 2011; Chen et al., 2014; Ding et al., 2014; Zhang et al., 2020). Nonetheless in
simple cases we demonstrate experimentally in Section 5 that machines may be synthesised by
using MCMC to sample from the posterior.
3	Complexity of Programs
Every Turing machine is the solution of a deterministic synthesis problem, so Section 2 associates to
any Turing machine a singularity ofa semi-analytic space W0. To indicate that this connection is not
vacuous, we sketch how the complexity of a program is related to the real log canonical threshold
ofa singularity. A more detailed discussion will appear elsewhere.
Let q(x, y) be a deterministic synthesis problem for U which only involves input sequences in some
restricted alphabet ∑i-put, that is, q(χ) = 0 if x ∈ (∑i-put)^. Let D- be sampled from q(χ, y) and
let u, v ∈ W code ∩ W0 be two explanations for the sample in the sense that Kn(u) = Kn(v) = 0.
Which explanation for the data should we prefer? The classical answer based on Occam’s razor
(Solomonoff, 1964) is that we should prefer the shorter program, that is, the one using the fewest
states and symbols.
Set N = ∣Σ∣ and M = |Q|. Any Turing machine T using N0 ≤ N symbols and M0 ≤ M states
has a code for U of length cM0N0 where c is a constant. We assume that Σi-put is included in the
tape alphabet of T so that N0 ≥ | ∑i-put | and define the KolmogoroV Complexity of q with respect to
U to be the infimum c(q) of M0N0 over Turing machines T that give classical solutions for q.
Let λ be the RLCT of the triple (p, q,夕)associated to the synthesis problem (Definition 2.4).
Theorem 3.1. λ ≤ 1 (M + N)c(q).
Proof. Let u ∈ W code ∩ W0be the code ofa Turing machine realising the infimum in the definition
of the Kolmogorov complexity and suppose that this machine only uses symbols in Σ0 and states in
Q0 with N0 = ∣Σ0∣ and M0 = |Q0|. The time evolution of the staged pseudo-UTM U simulating U
on X ∈ Σ*-put is independent of the entries on the description tape that belong to tuples of the form
(σ, q, ?, ?, ?) with	(σ, q)	∈/	Σ0	×	Q0. Let V ⊆ W be the submanifold of points which agree with u
on all tuples with	(σ, q)	∈	Σ0	×	Q0 and are otherwise free. Then u ∈ V ⊆ W0 and codim(V ) =
M0N0(M + N) and by (Watanabe, 2009, Theorem 7.3) We have λ ≤ 1 Codim(V).	□
Remark 3.2. The Kolmogorov complexity depends only on the number of symbols and states used.
The RLCT is a more refined invariant since it also depends on how each symbol and state is used
(Clift & Murfet, 2018, Remark 7.8) as this affects the polynomials defining W0 (see Appendix D).
4 Practical implications
Using singular learning theory we have explained how programs to be synthesised are singularities
of analytic functions, and how the Kolmogorov complexity of a program bounds the RLCT of the
associated singularity. We now sketch some practical insights that follow from this point of view.
Synthesis minimises the free energy: the sampling-based approach to synthesis (Section 2.1) aims
to approximate, via MCMC, sampling from the Bayesian posterior for the triple (p, q,夕)associated
to a synthesis problem. To understand the behaviour of these Markov chains we follow the asymp-
totic analysis of (Watanabe, 2009, Section 7.6). If we cover W by small closed balls Vα around
6
Under review as a conference paper at ICLR 2021
points wα then we can compute the probability that a sample comes from Vα by
Pa = ɪ e e-nKn(w')φ(w)dw
Z0 Vα
and if n is sufficiently large this is proportional to e-fα where the quantity
fα = Kαn + λα log(n)
is called the free energy. Here Kα is the smallest value of the Kullback-Leibler divergence K on Vα
and λα is the RLCT of the set WKα ∩Vα where Wc = {w ∈ W | K(w) = c} is a level set ofK. The
Markov chains used to generate approximate samples from the posterior are attempting to minimise
the free energy, which involves a tradeoff between the energy Kαn and the entropy λα log(n).
Why synthesis gets stuck: the kind of local minimum of the free energy that we want the synthesis
process to find are solutions wα ∈ W0 where λα is minimal. By Section 3 one may think of these
points as the “lowest complexity” solutions. However it is possible that there are other local minima
of the free energy. Indeed, there may be local minima where the free energy is lower than the free
energy at any solution since at finite n it is possible to tradeoff an increase in Kα against a decrease
in the RLCT λα. In practice, the existence of such “siren minima” of the free energy may manifest
itself as regions where the synthesis process gets stuck and fails to converge to a solution. In such
a region Kαn + λα log(n) < λ log(n) where λ is the RLCT of the synthesis problem. In practice
it has been observed that program synthesis by gradient descent often fails for complex problems
in the sense that it fails to converge to a solution (Gaunt et al., 2016). While synthesis by SGD
and sampling are different, it is a reasonable hypothesis that these siren minima are a significant
contributing factor in both cases.
Can we avoid siren minima? If we let λc denote the RLCT of the level set Wc then siren minima of
the free energy will be impossible at a given value of n and C as long as λc ≥ λ - CIognn) . Recall that
the more singular Wc is the lower the RLCT, so this lower bound says that the level sets should not
become too singular too quickly as C increases. At any given value ofn there is a “siren free” region
in the range C ≥ λ lon(n) since the RLCT is non-negative (Figure 3). Thus the learning process will
be more reliable the smaller λ lon(n) is. This can arranged either by increasing n (providing more
examples) or decreasing λ.
While the RLCT is determined by the synthesis problem, it is possible to change its value by chang-
ing the structure of the UTM U. As we have defined itU is a “simulation type” UTM, but one could
for example add special states such that if a code specifies a transition into that state a series of
steps is executed by the UTM (i.e. a subroutine). This amounts to specifying codes in a higher level
programming language. Hence one of the practical insights that can be derived from the geometric
point of view on program synthesis is that varying this language is a natural way to engineer the sin-
gularities of the level sets of K, which according to singular learning theory has direct implications
for the learning process.
Figure 3: Level sets above the cutoff cannot contain siren local minima of the free energy.
7
Under review as a conference paper at ICLR 2021
5 Experiments
We estimate the RLCT for the triples (p, q,夕)associated to the synthesis problems detectA (EX-
ample 2.5) and parityCheck. Hyperparameters of the various machines are contained in Table 3
of AppendiX B. The true distribution q(x) is defined as follows: we fiX a minimum and maXimum
sequence length a ≤ b and to sample X 〜q(x) We first sample a length l uniformly from [a, b] and
then uniformly sample x from {A, B}l .
We perform MCMC on the Weight vector for the model class {p(y|x, w) : w ∈ W} Where w is
represented in our PyTorch implementation by three tensors of shape {[L, ni]}1≤i≤3 Where L is the
number of tuples in the description tape of the TM being simulated and {ni} are the number of sym-
bols, states and directions respectively. A direct simulation of the UTM is used for all eXperiments
to improve computational efficiency (AppendiX G). We generate, for each inverse temperature β and
dataset Dn, a Markov chain via the No-U-turn sampler from Hoffman & Gelman (2014). We use
the standard uniform distribution as our prior 夕.
Max-length	Temperature	RLCT	Std	R squared
7	log(500)	8.089205	3.524719	0.965384
7	log(1000)	6.533362	2.094278	0.966856
8	log(500)	4.601800	1.156325	0.974569
8	log(1000)	4.431683	1.069020	0.967847
9	log(500)	5.302598	2.415647	0.973016
9	log(1000)	4.027324	1.866802	0.958805
10	log(500)	3.224910	1.169699	0.963358
10	log(1000)	3.433624	0.999967	0.949972
Table 1: RLCT estimates for detectA.
For the problem detectA given in EXample 2.5 the dimension of parameter space is dim W = 30.
We use generalized least squares to fit the RLCT λ (With goodness-of-fit measured by R2), the
algorithm of Which is given in AppendiX A. Our results are displayed in Table 1 and Figure 4. Our
purpose in these eXperiments is not to provide high accuracy estimates of the RLCT, as these Would
require much longer Markov chains. Instead We demonstrate hoW rough estimates consistent With
the theory can be obtained at loW computational cost. If this model Were regular the RLCT Would
be dim W/2 = 15.
RLCT of detectA on varying true distribution
max-length
temperature
log(500)
Iog(IOOO)
Figure 4: Plot of RLCT estimates for detectA. Shaded region shoWs one standard deviation.
The deterministic synthesis problem parityCheck has
Σ = {, A, B, X}
Q = {reject, accept, getNextAB, getNextA, getNextB, gotoStart}.
8
Under review as a conference paper at ICLR 2021
The distribution q(x) is as discussed in Section 5 and q(y|x) is determined by the function taking
in a string of A’s and B ’s, and terminating in state accept if the string contains the same number
of A’s as B’s, and terminating in state reject otherwise. The string is assumed to contain no blank
symbols. The true distribution is realisable because there is a Turing machine using Σ and Q which
computes this function: the machine works by repeatedly overwriting pairs consisting of a single
A and B with X’s; if there are any A’s without a matching B left over (or vice versa), we reject,
otherwise we accept.
In more detail, the starting state getNextAB moves right on the tape until the first A or B is found,
and overwrites it with an X. If it’s an A (resp. B) we enter state getNextB (resp. getNextA). If no
A or B is found, we enter the state accept. The state getNextA (resp. getNextB) moves right until
an A (resp. B) is found, overwrites it with an X and enters state gotoStart which moves left until a
blank symbol is found (resetting the machine to the left end of the tape). If no A’s (resp. B’s) were
left on the tape, we enter state reject. The dimension of the parameter space is dim W = 240. If
this model were regular, the RLCT would be dim W/2 = 120. Our RLCT estimates are contained
in Table 2.
Max-length	Temperature	RLCT	Std	R squared
5	log(300)	4.411732	0.252458	0.969500
6	log(300)	4.005667	0.365855	0.971619
7	log(300)	3.887679	0.276337	0.973716
Table 2: RLCT estimates for parityCheck.
6 Discussion
We have developed a theoretical framework in which all programs can in principle be learnt from
input-output examples via an existing optimisation procedure. This is done by associating to each
program a smooth relaxation which, based on Clift & Murfet (2018), can be argued to be more
canonical than existing approaches. This realization has important implications for the building of
intelligent systems.
In approaches to program synthesis based on gradient descent there is a tendency to think of solutions
to the synthesis problem as isolated critical points of the loss function K, but this is a false intuition
based on regular models. Since neural networks, Bayesian networks, smooth relaxations of UTMs
and all other extant approaches to smooth program synthesis are strictly singular models (the map
from parameters to functions is not injective) the set W0 of parameters w with K(w) = 0 is a
complex extended object, whose geometry is shown by Watanabe’s singular learning theory to be
deeply related to the learning process. We have examined this geometry in several specific examples
and shown how to think about complexity of programs from a geometric perspective. It is our hope
that algebraic geometry can assist in developing the next generation of synthesis machines.
9
Under review as a conference paper at ICLR 2021
References
Shun-ichi Amari, Tomoko Ozeki, and Hyeyoung Park. Learning and inference in hierarchical mod-
els with singularities. Systems and Computers in Japan, 34(7):34-42, 2003.
Michael F Atiyah. Resolution of singularities and division of distributions. Communications on
Pure and Applied Mathematics, 23(2):145-150, 1970.
Alan W Biermann. On the inference of Turing machines from sample computations. Artificial
Intelligence, 3:181-198, 1972.
Rudy R Bunel, Alban Desmaison, Pawan K Mudigonda, Pushmeet Kohli, and Philip Torr. Adaptive
neural compilation. In Advances in Neural Information Processing Systems, pp. 1444-1452,
2016.
Tianqi Chen, Emily Fox, and Carlos Guestrin. Stochastic gradient Hamiltonian Monte Carlo. In
International Conference on Machine Learning, pp. 1683-1691, 2014.
Xinyun Chen, Chang Liu, and Dawn Song. Execution-guided neural program synthesis. In Interna-
tional Conference on Learning Representations, 2018.
James Clift and Daniel Murfet. Derivatives of Turing machines in linear logic. arXiv preprint
arXiv:1805.11813, 2018.
Karel De Leeuw, Edward F Moore, Claude E Shannon, and Norman Shapiro. Computability by
probabilistic machines. Automata studies, 34:183-198, 1956.
Nan Ding, Youhan Fang, Ryan Babbush, Changyou Chen, Robert D Skeel, and Hartmut Neven.
Bayesian sampling using stochastic gradient thermostats. In Advances in Neural Information
Processing Systems, pp. 3203-3211, 2014.
Richard Evans and Edward Grefenstette. Learning explanatory rules from noisy data. Journal of
Artificial Intelligence Research, 61:1-64, 2018.
Cameron E Freer, Daniel M Roy, and Joshua B Tenenbaum. Towards common-sense reasoning via
conditional simulation: legacies of Turing in artificial intelligence. Turing’s Legacy, 42:195-252,
2014.
Alexander L Gaunt, Marc Brockschmidt, Rishabh Singh, Nate Kushman, Pushmeet Kohli, Jonathan
Taylor, and Daniel Tarlow. Terpret: A probabilistic programming language for program induction.
arXiv preprint arXiv:1608.04428, 2016.
Phillip Griffith and Joseph Harris. Principles of Algebraic Geometry. Wiley-Interscience, 1978.
Sumit Gulwani, Oleksandr Polozov, and Rishabh Singh. Program synthesis. Foundations and Trends
in Programming Languages, 4(1-2):1-119, 2017.
Heisuke Hironaka. Resolution of singularities of an algebraic variety over a field of characteristic
zero: I. Annals of Mathematics, 79(1):109-203, 1964.
Matthew D Hoffman and Andrew Gelman. The No-U-Turn sampler: adaptively setting path lengths
in Hamiltonian Monte Carlo. J. Mach. Learn. Res., 15(1):1593-1623, 2014.
Marcus Hutter. Universal artificial intelligence: Sequential decisions based on algorithmic proba-
bility. Springer Science & Business Media, 2004.
Eukasz Kaiser and Ilya Sutskever. Neural GPUs learn algorithms. In International Conference on
Learning Representations, 2016.
Daniel Murfet, Susan Wei, Mingming Gong, Hui Li, Jesse Gell-Redman, and Thomas Quella. Deep
learning is singular, and that’s good. arXiv preprint arXiv:2010.11560, 2020.
Arvind Neelakantan, Quoc V. Le, and Ilya Sutskever. Neural programmer: Inducing latent programs
with gradient descent. In International Conference on Learning Representations, ICLR 2016,
2016.
10
Under review as a conference paper at ICLR 2021
Jurgen Schmidhuber. Discovering neural nets with low KoImogorov complexity and high general-
ization capability. Neural Networks,10(5):857-873,1997.
Ray J Solomonoff. A formal theory of inductive inference. Part I. Information and control, 7(1):
1-22, 1964.
Alan Turing. Intelligent machinery. NPL Mathematics Division, 1948.
Sumio Watanabe. Almost all learning machines are singular. In 2007 IEEE Symposium on Founda-
tions of Computational Intelligence, pp. 383-388. IEEE, 2007.
Sumio Watanabe. Algebraic Geometry and Statistical Learning Theory, volume 25. Cambridge
University Press, 2009.
Sumio Watanabe. A widely applicable Bayesian information criterion. Journal of Machine Learning
Research, 14:867-897, 2013.
Max Welling and Yee W Teh. Bayesian learning via stochastic gradient Langevin dynamics. In
Proceedings of the 28th International Conference on Machine Learning, pp. 681-688, 2011.
Ruqi Zhang, Chunyuan Li, Jianyi Zhang, Changyou Chen, and Andrew Gordon Wilson. Cyclical
stochastic gradient MCMC for Bayesian deep learning. In International Conference on Learning
Representations, 2020.
Appendix
A Algorithm for Estimating RLCTs
Given a sample Dn = {(χi,y)}n=ι from q(χ,y) let Ln(w) := -1 Pn=Ilogp(yi∣xi,w) be the
negative log likelihood. We would like to estimate
Eβw [nLn (w)] :
n
nLn(w)P(W) "p(yi∣xi,w)βdw
i=1
where Zn = J 夕(W) Qn=ιp(yi∣xi, w)βdw for some inverse temperature β. If β = ιθg0n for some
constant β0, then by Theorem 4 of Watanabe (2013),
Ew [nLn(w)] = nLn(wo) + 绊∙n + Un∕λ⅛n + Op(1)
β0	2β0
(7)
where {Un} is a sequence of random variables satisfying E[Un] = 0 and λis the RLCT. In practice,
the last two terms often vary negligibly with 1∕β and so Ew [nLn (w)] approximates a linear function
of 1∕β with slope λ (Watanabe, 2013, Corollary 3). This is the foundation of the RLCT estimation
procedure found in Algorithm 1 which is used in our experiments.
Algorithm 1 RLCT estimation
Input: range of β's, set of training sets T each of size n, approximate samples {wι,..., wr}
from pβ(w∣Dn) for each training set Dn and each β
for training set Dn ∈ T do
for β in range of β's do
Approximate Ew [nLn(w)] with R PR=I nLn(wr) where wi,...,wr are approximate sam-
ples from pβ (w | Dn)
end for
ʌ
Perform generalised least squares to fit λin Equation (7), call result λ(Dn)
end for
OutPut: 击 PDn∈T "(Dn)
11
Under review as a conference paper at ICLR 2021
ʌ
Each RLCT estimate λ(Dn) in Algorithm 1 was performed by linear regression on the pairs
{(1∕βi, Ewi [nLn(w)])}5=ι where the five inverse temperatures βi are centered on the inverse tem-
perature 1/T where T is the temperature reported for each experiment in Table 1 and Table 2.
From a Bayesian perspective, predictions about outputs y should be made using the predictive dis-
tribution
p*(y|x, Dn)
p(y|x, w)p(w|Dn)dw .
The Bayesian generalisation error associated to the Bayesian predictor is defined as the Kullback-
Leibler distance to the true conditional distribution
Bg(n) :
DκL(qkp*')
q(y|x)q(x) log
q q(y∖x) ʌ
Ip* (y∖χ)√
dydx.
If some fundamental conditions are satisfied (Definition 6.1 and Definition 6.3 of Watanabe (2009)),
then by Theorem 6.8 of loc.cit., there exists a random variable Bg* such that as n → ∞, E[nBg(n)]
converges to E[Bg*]. In particular, by Theorem 6.10 of Watanabe (2009), E[Bg*] = λ.
B Hyperparameters
The hyperparameters for the various synthesis tasks are contained in Table 3. The number of samples
is R in Algorithm 1 and the number of datasets is ∖T∖. Samples are taken according to the Dirichlet
distribution, a probability distribution over the simplex, which is controlled by the concentration.
When the concentration is a constant across all dimensions, as is assumed here, this corresponds to
a density which is symmetric about the uniform probability mass function occurring in the centre of
the simplex. The value α = 1.0 corresponds to the uniform distribution over the simplex. Finally,
the chain temperature controls the default β value, ie. all inverse temperature values are centered
around 1/T where T is the chain temperature.
Hyperparameter	detectA	parityCheck
Dataset size (n)	200	100
Minimum sequence length (a)	4	1
Maximum sequence length (b)	7/8/9/10	5/6/7
Number of samples (R)	20,000	2,000
Number of burn-in steps	1,000	500
Number of datasets (|T |)	4	3
Target accept probability	0.8	0.8
Concentration (α)	1.0	1.0
Chain temperature (T)	log(500)/log(1000)	log(300)
Number of timesteps (t)	10	42
Table 3: Hyperparameters for Datasets and MCMC.
C The Shift Machine
The pseudo-UTM U is a complicated Turing machine, and the models p(y∖x, w) of Section 2 are
therefore not easy to analyse by hand. To illustrate the kind of geometry that appears, we study
the simple Turing machine shiftMachine of Clift & Murfet (2018) and formulate an associated
statistical learning problem. The tape alphabet is Σ = {, A, B, 0, 1, 2} and the input to the machine
will be a string of the form na1a2a3 where n is called the counter and ai ∈ {A, B}. The
transition function, given in loc.cit., will move the string of A’s and B’s leftwards by n steps and
fill the right hand end of the string with A’s, keeping the string length invariant. For example, if
2BAB is the input to M , the output will be 0BAA.
Set W = ∆{0, 2} × ∆{A, B} and view w = (h, k) ∈ W as representing a probability distribution
(1 一 h) ∙ 0 + h ∙ 2 for the counter and (1 一 k) ∙ B + k ∙ A for a> The model is
3
p(y∖x = (a2,。3), W) = (1 ― h)2k ∙ A + (1 ― h)2(1 ― k) ∙ B + X
i=2
hi-1(1
h)3-i
ai.
12
Under review as a conference paper at ICLR 2021
This model is derived by propagating uncertainty through shiftMachine in the same way that
p(y |x, w) is derived from ∆ stept in Section 2 by propagating uncertainty through U . We assume
that some distribution q(x) over {A, B}2 is given.
Example C.1. Suppose q(y|x) = p(y|x, w0) where w0 = (1, 1). It is easy to see that
K(W) = -1 X logp(y = a3|x = (a2,a3),w) = - 1log[g(h,k)]
a2,a3
where g(h, k) = (1 - h)2k + h2 (1 - h)2(1 - k) + h2 is a polynomial in w. Hence
W0={(h,k) ∈W : g(h, k) =1}=V(g-1)∩[0,1]2
is a semi-algebraic variety, that is, it is defined by polynomial equations and inequalities. Here V(h)
denotes the vanishing locus of a function h.
Example C.2. Suppose q(AB) = 1 and q(y|x = AB) = 1A + 1 B. Then the KunbaCk-Leibler
divergence is K(h, k) = -1 log(4f (1 - f)) where f = (1 - h)2k + 2h(1 - h). Hence VK =
(f — 1) f (1-f)Vf. Note that f has no critical points, and so VK = 0 at (h, k) ∈ (0,1)2 if and only
if f (h, k) = 2. Since K is non-negative, any W ∈ W0 satisfies VK(w) = 0 and so
Wo = [0,1]2 ∩ V(4f (1 - f) - 1) = [0,1]2 ∩ Vff - 2)
is semi-algebraic. Note that the curve f = 1 is regular while the curve 4f (1 — f) = 1 is singular
and it is the geometry of the singular curve that is related to the behaviour ofK. This curve is shown
in Figure 5. It is straightforward to check that the determinant of the Hessian of K is identically
zero on W0, so that every point on W0 is a degenerate critical point of K.
Figure 5: Values of K(h, k) on [0, 1]2 are shown by colour, ranging from blue (zero) to red (0.01).
The singular analytic space K = 0 (white) and the regular analytic level set K = 0.001 (black).
D	General solution for deterministic synthesis problems
In this section we consider the case of a deterministic synthesis problem q(x, y) which is finitely
supported in the sense that there exists a finite set X ⊆ Σ* such that q(x) = C for all X ∈ X and
q(x) = 0 for all x ∈/ X. We first need to discuss the coordinates on the parameter space W of (3).
To specify a point on W is to specify for each pair (σ, q) ∈ Σ × Q (that is, for each tuple on the
description tape) a triple of probability distributions
X xσ0q ∙σ0∈ ∆Σ ,
σ0∈Q
X 靖∙ q0 ∈ ∆Q,
q0∈Q
X	zσ,q ∙ d ∈ ∆{L,S,R}.
d∈{L,S,R}
13
Under review as a conference paper at ICLR 2021
The space W of distributions is therefore contained in the affine space with coordinate ring
RW= R[{xσ0q }σ,q,σ0, {诵, }σ,q,q” {z^ )σ,q,d].
The function Fx = ∆ stept(x, -) : W -→ ∆Q is polynomial (Clift & Murfet, 2018, Proposition
4.2) and we denote for s ∈ Q by Fsx ∈ RW the polynomial computing the associated component of
the function Fx. Let ∂W denote the boundary of the manifold with corners W, that is, the set of all
points on W where at least one of the coordinate functions given above vanishes
∂w=V(YhY χσoq Y yqo,q	Y	zσ,q])
σ,q σ0∈Q	q0∈Q	d∈{L,S,R}
where V(h) denotes the vanishing locus of h.
Lemma D.1. W0 6= W.
Proof. Choose x ∈ X with q(x) > 0 and let y be such that q(y|x) = 1. Let w ∈ W code be the
code for the Turing machine which ignores the symbol under the head and current state, transitions
to some fixed state S = y and stays. Then w ∈ W0.	□
Lemma D.2. The set W0 is semi-algebraic and W0 ⊆ ∂W.
Proof. Given X ∈ Σ* with q(x) > 0 We write y = y(x) for the unique state with q(x, y) = 0. In
this notation the Kullback-Leibler divergence is
K(w) =	c DKL(ykF x(w)) = -c	log Fyx(w) = -c log	Fyx(w) .
x∈X	x∈X	x∈X
Hence
W0 = W ∩ \ V(1 - Fyx (w))
x∈X
is semi-algebraic.
Recall that the function ∆ stept is associated to an encoding of the UTM in linear logic by the
Sweedler semantics (Clift & Murfet, 2018) and the particular polynomials involved have a form
that is determined by the details of that encoding (Clift & Murfet, 2018, Proposition 4.3). From the
design of our UTM we obtain positive integers lσ , mq, nd for σ ∈ Σ, q ∈ Q, d ∈ {L, S, R} and a
function π : Θ -→ Q where
Θ =	Σlσ × Qmq × {L, S, R}nd .
σ,q
We represent elements of Θ by tuples (μ,Z,ξ) ∈ Θ where μ(σ, q,i) ∈ Σ for σ ∈ Σ,q ∈ Q and
1 ≤ i ≤ lσ and similarly ζ(σ, q, j) ∈ Q and ξ(σ, q, k) ∈ {L, S, R}. The polynomial Fsx is
lσ	mq	nd
Fsx=	x	δ(s=∏(μ,ζ,ξ))y[yχσ(σ,q,i)yy*j)Y乞疆京
(μ,ζ,ξ)∈θ	σ,q i=1	j=1	k = 1
where δ is a Kronecker delta. With this in hand we may compute
W0 = W ∩ \ V(1 - Fyx (w))
x∈X
=W∩ \ \V(Fsx(w)).
x∈X s6=y
But Fsx is a polynomial with non-negative integer coefficients, which takes values in [0, 1] for w ∈
W. Hence it vanishes on W if and only if for each triple μ, Z, ξ with S = π(μ, Z, ξ) one or more of
the coordinate functions xμ(σ,q,i),yσσ,q,j),zσσ,q,k) vanishes on w.
The desired conclusion follows unless for every X ∈ X and (μ, Z,ξ) ∈ Θ we have ∏(μ, Z,ξ) = y so
that FS = 0 for all s = y. But in this case case Wo = W which contradicts Lemma D.1.	□
14
Under review as a conference paper at ICLR 2021
E	S taged Pseudo-UTM
Simulating a Turing machine M with tape alphabet Σ and set of states Q on a standard UTM requires
the specification of an encoding of Σ and Q in the tape alphabet of the UTM. From the point of view
of exploring the geometry of program synthesis, this additional complexity is uninteresting and so
here we consider a staged pseudo-UTM whose alphabet is
ΣUTM =Σ∪Q∪{L,R,S}∪{X,}
where the union is disjoint where is the blank symbol (which is distinct from the blank symbol of
M ). Such a machine is capable of simulating any machine with tape alphabet Σ and set of states Q
but cannot simulate arbitrary machines and is not a UTM in the standard sense. The adjective staged
refers to the design of the UTM, which we now explain. The set of states is
QUTM = { compSymbol, compState, copySymbol, copyState, copyDir,
compState, copySymbol, copyState, copyDir,
updateSymbol, updateState, updateDir, resetDescr }.
The UTM has four tapes numbered from 0 to 3, which we refer to as the description tape, the staging
tape, the state tape and the working tape respectively. Initially the description tape contains a string
of the form
Xs0q0s00q00 d0s1q1s01q10 d1 . . . sN qN s0N qN0 dNX,
corresponding to the tuples which define M, with the tape head initially on s0 . The staging tape is
initially a string XXX with the tape head over the second X . The state tape has a single square
containing some distribution in ∆Q, corresponding to the initial state of the simulated machine M,
with the tape head over that square. Each square on the the working tape is some distribution in ∆Σ
with only finitely many distributions different from . The UTM is initialized in state compSymbol.
The operation of the UTM is outlined in Figure 6. It consists of two phases; the scan phase (middle
and right path), and the update phase (left path). During the scan phase, the description tape is
scanned from left to right, and the first two squares of each tuple are compared to the contents of
the working tape and state tape respectively. If both agree, then the last three symbols of the tuple
are written to the staging tape (middle path), otherwise the tuple is ignored (right path). Once the
X at the end of the description tape is reached, the UTM begins the update phase, wherein the three
symbols on the staging tape are then used to print the new symbol on the working tape, to update
the simulated state on the state tape, and to move the working tape head in the appropriate direction.
The tape head on the description tape is then reset to the initial X.
Remark E.1. One could imagine a variant of the UTM which did not include a staging tape, instead
performing the actions on the work and state tape directly upon reading the appropriate tuple on the
description tape. However, this is problematic when the contents of the state or working tape are
distributions, as the exact time-step of the simulated machine can become unsynchronised, increas-
ing entropy. As a simple example, suppose that the contents of the state tape were 0.5q + 0.5p, and
the symbol under the working tape head was s. Upon encountering the tuple sqs0q0R, the machine
would enter a superposition of states corresponding to the tape head having both moved right and
not moved, complicating the future behaviour.
We define the period of the UTM to be the smallest nonzero time interval taken for the tape head
on the description tape to return to the initial X, and the machine to reenter the state compSymbol.
If the number of tuples on the description tape is N, then the period of the UTM is T = 10N + 5.
Moreover, other than the working tape, the position of the tape heads are T -periodic.
F Smooth Turing Machines
Let U be the staged pseudo-UTM of Appendix E. In defining the model p(y|x, w) associated to a
synthesis problem in Section 2 we use a smooth relaxation ∆ stept of the step function ofU. In this
appendix we define the smooth relaxation of any Turing machine following Clift & Murfet (2018).
Let M = (Σ, Q, δ) be a Turing machine with a finite set of symbols Σ, a finite set of states Q and
transition function δ : Σ × Q → Σ × Q × {-1, 0, 1}. We write δi = proji ◦ δ for the ith component
of δ for i ∈ {1, 2, 3}. For ∈ Σ, let
∑Z,□ = {f : z → ∑∣f (i) = □ except for finitely many i}.
15
Under review as a conference paper at ICLR 2021
Figure 6: The UTM. Each of the rectangles are states, and an arrow q → q0 has the following
interpretation: if the UTM is in state q and sees the tape symbols (on the four tapes) as indicated
by the source of the arrow, then the UTM transitions to state q0 , writes the indicated symbols (or if
there is no write instruction, simply rewrites the same symbols back onto the tapes), and performs
the indicated movements of each of the tape heads. The symbols a, b, c, d stand for generic symbols
which are not X .
We can associate to M a discrete dynamical system Mc = (ΣZ, × Q, step) where
step : ΣZ, × Q → ΣZ, × Q
is the step function defined by
step(σ,q) = (αδ3(σ0,q)( ...,σ-2,σ-i ,δ1(σ0 ,q),σ1,σ2,... ),δ2(σ0 ,q)).
with shift map αδ3 (σ0,q) (σ)u = σu+δ3 (σ0,q).
Let X be a finite set. The standard X-simplex is defined as
∆X = { X λxx ∈ RX| X λx = 1 and λx ≥ 0 for allx ∈ X}	(8)
x∈X	x
where RX is the free vector space on X . We often identify X with the vertices of ∆X under
the canonical inclusion i : X → ∆X given by i(x) = Px0∈X δx=x0 x0. For example {0, 1} ⊂
∆({0, 1})'[0, 1].
A tape square is said to be at relative position u ∈ Z if it is labelled u after enumerating all squares
in increasing order from left to right such that the square currently under the head is assigned zero.
Consider the following random variables at times t ≥ 0:
16
Under review as a conference paper at ICLR 2021
•	Yu,t ∈ Σ: the content of the tape square at relative position u at time t.
•	St ∈ Q: the internal state at time t.
•	Wrt ∈ Σ: the symbol to be written, in the transition from time t to t + 1.
•	Mvt ∈ {L, S, R}: the direction to move, in the transition from time t to t + 1.
We call a smooth dynamical system a pair (A, φ) consisting of a smooth manifold A with corners
together with a smooth transformation φ : A → A.
Definition F.1. Let M = (Σ, Q, δ) be a Turing machine. The smooth relaxation of M is the smooth
dynamical system ((∆Σ)Z, × ∆Q, ∆step) where
∆step : (∆Σ)Z, × ∆Q → (∆Σ)Z, × ∆Q
is a smooth transformation sending a state ({P(Yu,t)}u∈Z,P(St)) to ({P(Yu,t+1)}u∈Z, P (St+1))
determined by the equations
•	P(Mvt = d|C) = Pσ,q δδ3(σ,q)=dP(Y0,t = σlC)P(St = q|C),
•	P(Wrt= σQ) = Pσo,q δδ1(σ0,q) = σP(Y0,t = σ1C)P(St = q|C),
•	P(St+1 = q|C) = Pσ,q0 δδ2(σ,q0)=qP(K,t = σ∣C)P(St = q0∣C),
•	P(Yu,t+1 = σ∣C) = P(Mvt = L|C) Gu=IP(YU-i,t = σ∣C) + δu=1P(Wrt = σ∣C))
+ P(Mvt = S|C) (δu=0P(Yu,t = σ∣C) + δu=°P(Wrt = σ∣C))
+ P(Mvt = R|C )(δu=-i P(Yu+ι,t = σ∣C) + δu=-iP(Wrt = σ∣C)),
where C ∈ (∆Σ)Z, × ∆Q is an initial state.
We will call the smooth relaxation of a Turing machine a smooth Turing machine. A smooth Turing
machine encodes uncertainty in the initial configuration of a Turing machine together with an update
rule for how to propagate this uncertainty over time. We interpret the smooth step function as
updating the state of belief of a “naive” Bayesian observer. This nomenclature comes from the
assumption of conditional independence between random variables in our probability functions.
Remark F.2. Propagating uncertainty using standard probability leads to a smooth dynamical sys-
tem which encodes the state evolution of an “ordinary” Bayesian observer of the Turing machine.
This requires the calculation of various joint distributions which makes such an extension computa-
tionally difficult to work with. Computation aside, the naive probabilistic extension is justified from
the point of view of derivatives of algorithms according to the denotational semantics of differential
linear logic. See Clift & Murfet (2018) for further details.
We call the smooth extension of a universal Turing machine a smooth universal Turing machine.
Recall that the staged pseudo-UTM U has four tapes: the description tape, the staging tape, the state
tape and working tape. The smooth relaxation of U is a smooth dynamical system
∆stepU : [(∆ΣUTM)Z,]4 × ∆QUTM → [(∆ΣUTM)Z,]4 × ∆QUTM .
If we use the staged pseudo-UTM to simulate a Turing machine with tape alphabet Σ ⊆ ΣUTM and
states Q ⊆ ΣUTM then with some determined initial state the function ∆step restricts to
∆stepU : (∆Σ)Z, × W × ∆Q × X -→ (∆Σ)Z, × W × ∆Q × X
where the first factor is the configuration of the work tape, W is as in (3) and
X = [(∆ΣUTM)Z,] × ∆QUTM
where the first factor is the configuration of the staging tape. Since U is periodic of period T =
10N + 5 (Appendix E) the iterated function (∆ stepU)T takes an input with staging tape in its
17
Under review as a conference paper at ICLR 2021
default state XXX and UTM state compSymbol and returns a configuration with the same staging
tape and state, but with the configuration of the work tape, description tape and state tape updated
by one complete simulation step. That is,
(∆ stepU)T x, w, q, XXX, compSymbol) = (F (x, w, q), XXX, compSymbol
for some smooth function
F : (∆Σ)Z, × W × ∆Q -→ (∆Σ)Z, × W × ∆Q.	(9)
Finally we can define the function ∆ stept of (4). We assume all Turing machines are initialised in
some common state init ∈ Q.
Definition F.3. Given t ≥ 0 We define ∆ StePt : Σ* X W —→ ∆Q by
∆ stept(x, w) = ΠQFt (x, w, init)
Where ΠQ is the projection onto ∆Q.
G Direct S imulation
For computational efficiency in our PyTorch implementation of the staged pseudo-UTM We imple-
ment F of (9) rather than ∆ stePU . We refer to this as direction simulation since it means that We
update in one step the state and Working tape of the UTM for a full cycle Where a cycle consists of
T = 10N + 5 steps of the UTM.
Let S(t) and Yu (t) be random variables describing the contents of state tape and Working tape in
relative positions 0, u respectively after t ≥ 0 time steps of the UTM. We define S(t) := S(4 + Tt)
and Yu(t) := Yu(4 + Tt) Where t ≥ 0 and u ∈ Z. The task then is to define functions f, g such that
Se(t + 1) = f (Se(t))
Yeu(t + 1) = g(Yeu(t)).
The functional relationship is given as folloWs: for 1 ≤ i ≤ N indexing tuples on the description
tape, while processing that tuple, the UTM is in a state distribution λ% ∙(1+(1 — λi) ∙ —q where
q ∈ {copySymbol, CoPyState, CoPyDir}. Given the initial state of the description tape, we assume
uncertainty about s0 , q0 , d only. This determines a map
θ : {1,...,N} → Σ × Q
where the description tape at tuple number i is given by θ(i)1θ(i)2P (s0i)P (qi0)P (di). We define the
conditionally independent joint distribution between {Y0,t-1, St-1} by
λi = X δθ(i)ι=σP(Y0,t-1 = σ) ∙ X δθ(i)2=qP(Set-1 = q)
σ∈Σ	q∈Q
,~ , , ,~ ,.
=P (Y0,t-1 = θ(i)l) ∙ P (Set-1 = θ(i)2).
We then calculate a recursive set of equations for 0 ≤ j ≤ N describing distributions P(Sj),P@)
ʌ
and P(dj) on the staging tape after processing all tuples up to and including tuple j. These are given
ʌ
by P(^o) = P(^o) = P(do) = 1 ∙ X and
P (si) = X {λi ∙ P(Si = σ) + (1 - λi) ∙ P(Si-I = σ)}∙ σ + (1 — λi) ∙ P (si-1 = X) ∙ X
σ∈Σ
P(qi) = X{λi ∙ Plqi = q) + (1 — λi) ∙ P(qi-ι = q)}∙ q +(1 — λi) ∙ P(qi-ι = X) ∙X
q∈Q
P (di) =	E	{λi	∙	P (di	=	a)+ (1 —	λi)	∙	P(di- =	a)}∙	a +(1 — %) ∙ P(d-ι = X) ∙ X.
a∈{L,R,S}
T . A	7-» / ʌ	TT- ∖ I 1	∖	.	7~» / ʌ	∖ T	Γ∙ .∖	F
Let Aσ = P(SN = X) ∙ P(Y0,t-1 = σ) + P(SN = σ). In terms of the above distributions
P(St) = X (P(qN = X) ∙ P(St-I = q) + P(qN = q)) ∙ q
q∈Q
18
Under review as a conference paper at ICLR 2021
and
P (YU,t = σ) = P (dN = L)(K=IP (Yu-I,t-1 = σ)+ δu=1AσJ
+ P(dN = R) GU=-IP(YU+1,t-1 = σ) + δu=-1 Aσ)
+ P(dN = S) (δu=0P(Yu,t-1 = σ) + δu=0Aσ)
+ P(dN = X) GU=0P(YU,t-1 = σ) + δu=0Aσ) ∙
Using these equations, we can state efficient update rules for the staging tape. We have
N P(SN = X ) = ∏(1 - Xj), j=1 N	N P(SN = σ) = X λj ∙ P(Sj 二 j=1 N	N 二 σ) ∏ (1 - XI) ι=j+1 N
P(qN = X) = ∏(1 - Xj), j=1 N	P(qN = q) = X χj ∙p(qj 二 j=1 N	二 q) ∏ (1 - Xι) ι=j+1 N
P(dN = X) = ∏(1 - λj), j=1	P(3n = a) =＞： Xj ∙ P(dj 二 j=1	二 a) ∏ (1 - χi)∙ l=j+1
To enable efficient computation, we can express these equations using tensor calculus. Let λ
(λι,..., Xn) ∈ RN. We view
θ : Rn → RΣ 0 RQ
as a tensor and so θ = PN=I i 0 θ(i)1 0 θ(i)2 ∈ Rn 0 RΣ 0 RQ. Then
N
θy(P(Y0,t-1) 0 P(St-I)) = X i ∙ P(YM-I = θ(i)1) ∙ P(St-I = θ(i)2) = λ.
i=1
If we view P(s； = •) ∈ Rn 0 Rς as a tensor, then
N	/ N	∖	(NN
P(SN) = XP(Sj	=	•)	∙ (λj	∏ (1 -	λι)	I = λ∙	∏(1-λ∕∏(1- λι),…,(1 -	Xn), 1
j=1	∖ l=j+1	)	∖l=2	l=3
can be expressed in terms on the vector X only. Similarly, P(q； = •) ∈ Rn 0 RQ with
N	/ N	∖	(NN
p(^n) = XPIqj	= •)∙	Xj	∏ (1 -Xl)	= X∙	∏(1-χι),∏(1-%),...,(1 -XN), 1
j = 1	∖	l=j+1	)	∖l=2	l=3
and P(d； = •) ∈ Rn 0 R3 with
N	( N	∖	(N	N	、
P (dN ) =	^X P (dj	= ∙)∙(xj	∏ (1 - λl)) = χ∙ ( ∏(1	-	λl), ∏(1	- XI),…,(1 -	xN ), 1
j=1	∖	ι=j+1	l	∖1=2	1=3	/
19