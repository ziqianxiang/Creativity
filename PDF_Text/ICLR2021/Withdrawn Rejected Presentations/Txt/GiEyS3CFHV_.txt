Under review as a conference paper at ICLR 2021
Non-Asymptotic PAC-Bayes Bounds on Gener-
alization Error
Anonymous authors
Paper under double-blind review
Abstract
Constructing non-vacuous PAC-Bayes bounds on generalization errors for un-
bounded risk functionals, especially in the non-asymptotic regime, is an active
area of research. However, current state of the art results are applicable only in
some very specialized cases. In this work, we give an integrability condition which
exactly characterizes when any risk functional, for a given data set and model
space, admits such bounds using the Levy-Khintchine theorem. Further, we de-
rive a Bahadur-Rao type exact asymptotic bound, which is much sharper than a
traditional Chernoff type inequality, especially in the under-sampled regime. These
bounds give us the flexibility to construct data or model-dependent consistency
promoting updates to a data-free prior, which provably improves the generalization
performance.
1 Introduction
In this work we are interested in provable control of generalization error in model estimation,
especially in the non-asymptotic or under-sampled regime. In this scenario, the number of observed
samples are significantly lower than the degrees of freedom in the model, thereby leading to an
ill-posed estimation problem and consequently a large expected generalization error. Such situations
are extremely common in classical high dimensional statistics ISUr and Candes (2019)], for example
in single cell genomics IMCDavid et al. (2019)] or GWAS [Brzyski et al. (2017)] studies, the data
is not only extremely high dimensional, labelled data acquisition can be error-prone, expensive and
time consuming. However recently, with the plethora of wide ranging successful applications of over-
parametrized deep neural networks IZhang et al. (2016)], the question of constructing generalization
bounds is of great interest in the deep learning community [Kawaguchi et al. (2017)].
From the theory of statistical learning IVapnik (2000)] an optimal model is defined by the minimizer
of a continuous non-negative risk functional R : (H, P2 (Rd)) → R+ which is characterized by
being differentiable in the first argument and linear in the second. Here P2 (Rd) is the space of
Borel probability measures on Rd with bounded variance and H ⊆ L2 (Rd) is the space of square
integrable functions, represented by either parametric models like exponential families and their
mixtures [Meila (2000); Nguyen (2011); Redner and Walker (1984)] or non-parametric models like
infinite mixture models IGershman and Blei (2011); Kleijn and Zhao (2013); Locatello et al. (2017);
Nguyen (2011); Petrone and Veronese (2002); Ramaswamy: Wu and Ghosal (2007)], etc.
However in practice, the true measure say V ∈ P2 (Rd), is unknown and one only has access to
a set of i.i.d. samples Xi,..., Xn i'ʌd. V from it. The core idea then, is to use the empirical risk
functional RVemP := R (∙, VnmP := n Pi δχi) as a surrogate and minimize it instead IVapnik (2000)].
Clearly, such a minimizer, say f ∈ H can be said to approximate the true optimum if and only if its
generalization error i.e.
δVnmP (fn)	:= RVnmP (fn) - r*
Generalization error
can be bounded almost surely, where R* is the theoretically minimal risk, also known as the Bayes
Risk [Vapnik (2000)]. Note that R* may not be achievable inside H. Constructing probabilistic
bounds on the generalization error, is the one of the central aims of statistical learning theory.
1
Under review as a conference paper at ICLR 2021
By constructing an appropriate prior on the model space H, one can a priori exclude models which
are not expected to fit the learning problem i.e. reduce capacity. A prior needs to be constructed using
only minimal assumptions [Belkin et al. (2018); NeyShabur et al. (2018); Mukherjee et al. (2006);
Kleijn and Zhao (2013)], so as to ensure that it puts a positive probability in the neighborhood of the
true model (2), while removing all unsuitable models. For example, in linear regression a Gaussian
prior on the parameter space leads to Ridge regression which gives the optimal least squares solution
[Parikh et al. (2014)] in the under-sampled regime, while a Laplace prior leads to Lasso regression
which can be interpreted to be a convex relaxation to the best subset regression problem [Parikh et al.
(2014)] and hence leads to relatively sparse coefficient estimates.
A principled approach to constructing priors based on problem dependent assumptions comes from
the theory of Levy processes, where Gaussian process, Compound Poisson process, etc are used to
induce distributions over partitions of the model space, leading to for example the Pitman-Yor process,
etc. For example, a Gaussian process prior over a space of functions, assumes that the marginal
distribution over any finite set of evaluations has Gaussian distribution. Such an assumption leads to
smooth functions whose evaluation in a neighborhood is highly correlated, while almost independent
outside its region of influence. While if we assume complete independence of all partitions of the
sample space, then we end up with completely random measures like Compound Poisson processes.
For more details, see [Gershman and Blei (2011)].
The Bayesian approach can be alternatively formulated from the point of view of the Minimum
Description Length principle ['Grunwald and Mehta (2019); Dziugaite and Roy (2017a)]. MDL is a
theory of inductive and statistical inference, where statistical learning is defined as the search for the
best hypothesis among a set of hypotheses, and a model in that hypothesis, that is best able to describe
the regularities in the data, while compressing it the most [Foster et al. (2019); Arora et al. (2018);
Shwartz-Ziv and Tishby (2017); Zhou et al. (2018)]. It can be seen as the principled formalization of
the Occam’s razor principle.
In the PAC-Bayesian literature, data-dependent priors have also been suggested, constructed using
various techniques. One common approach is via training the prior measure on a held out portion
of the data [Ambroladze et al. (2007); Parrado-Hernandez et al. (2012)]. Another, following a non-
parametric approach is to ensure martingale concentration by assuming stability w.r.t. small changes
in the data [Dziugaite and Roy (2017b)]. In [Rivasplata et al. (2020)] approached the problem of
data-dependent priors more generally by deriving PAC-Bayes inequalities for arbitrary convex error
functionals, but still requiring rather strong assumptions on the exponential moments.
Usually in the literature, the risk functional is assumed to be bounded ∣Catoni (2007); McAllester
(1999; 2013); Audibert and Bousquet (2007)], however recently results for unbounded risks have
been derived under assumptions of exponentially decaying tails i.e. sub-Gaussianity of the data
generating process [Germain et al. (2016)]. In this work, using Levy-Khintchine theorem [Bertoin
(2006)], we characterize the condition under which the required moment generating function exists for
non-negative risk functionals. Such a characterization allows us to expand the domain of applicability
to general unbounded risk functionals even when the data generating process has polynomially
decreasing tails. In order to that, we need to construct a stochastic process known as a subordinator
using samples from our push-forward empirical measure.
Our Contribution The main focus of this work is on the construction of bounds on the estimation
error. In the discussion above, we showed that such a bound can be used to construct the consistency
pseudo-prior, which is a data dependent update (9) to an η-sufficient prior, specific to a given risk
functional R and model space H. These constructions are then sufficient to derive the strong
PAC-Bayes bounds (10) discussed earlier.
We approach the problem of estimation error by first observing that the risk functional pushes forward
the empirical measure to a measure on the non-negative real line. We show that any such push-forward
measure for i.i.d. data is a Levy measure, whose moment generating function exists under very weak
conditions (15). Importantly, even the boundedness of the risk functional is not necessary. Further,
in this case the Levy-Khintchine representation formula [Bertoin (2006)] allows us to estimate the
moment generating function by modeling the push-forward measure either by a Gamma subordinator
for exponentially decreasing tail or Stable subordinator for polynomially decreasing tail, and hence
derive data/model dependent PAC-Bayes bounds.
2
Under review as a conference paper at ICLR 2021
Secondly, we derive an Bahadur-Rao type exact asymptotic bound, which is much sharper than
a traditional Chernoff-inequality especially in the under-sampled regime. Thereby allowing us to
provide sufficient conditions to ensure δn-strong-consistency (3) of the empirical RiSk functional.
Such a bound is a result of a combination of Donsker-Varadhan duality and Berry-Essen estimates
[Dembo and Zeitouni (2009)] for the convergence rates in central limit theorem.
2 PAC-Bounds on Generalization Error
To fix notations, let R : (H, P? (Rd)) → R+ be a continuous non-negative risk functional, and
Xi,…，Xn i削.V ∈ P? (Rd) be i.i.d. random variables, with Vnmp := ɪ Pi δχi as its empirical
measure with the corresponding empirical risk functional Rνemp := R (•，Vnmp := n Piδχi). The
starting point for bounding the generalization error is the following orthogonal decomposition which
isolates its deterministic and stochastic parts for any f ∈H
∆νemp (f) = [Rν (f) - R*] + [Rνemp (f) - Rν (f)]
Approximation error	Estimation error
(1)
Here the approximation error [Vapnik (2000)] is a deterministic functional of the model space H
and the unknown true measure V ∈ P? (Rd), while estimation error [Vapnik (2000)] is a stochastic
functional dependent on the sampling process and properties of the risk functional.
2.1	PAC-Bound Approach
Then we can define the model space H to be η-sufficient for the learning problem, if η ≥ 0 is the
smallest non-negative finite real number for which there exists some prior measure π0 ∈P? (H),
such that
∏o ({f ∈ H ：| Rν(f)- R* |< η}) > 0	(2)
If a π0 exists for η =0, then the model space is called well-specified. Clearly if a finite dimensional
model space (e.g. Linear models, etc) is well-specified, then the Lebesgue measure would always
satisfy such a condition. However, since for an infinite dimensional model space (e.g. RKHS, Fourier,
Wavelet, etc) no Lebesgue measure exists ∣Kleijn and Zhao (2013)], even in the ideal case the priors
need to be represented via completely random measures [Kingman (1967)] and related Levy processes
like Gaussian process [Seeger (2002); Donnet et al. (2014)], Compound Poisson process [Gugushvili
et al. (2019)], Pitman-Yor process [Gershman and Blei (2011)], etc.
Similarly, we can define the empirical risk to be δn-strongly consistent if for any e > 0 and some
f ∈ H, there exists a monotonically decreasing sequence δn := δ (f, VnmP, e) → 0+ as n → ∞,
such that the tail probability of the estimation error satisfies
Pr (| RVnmP (f) - Rν (f) |> e) < δn, δn ∈ [0,1]	(3)
This means that if for some function f ∈H, such a δn exists, then the estimation error vanishes with
increasing sample size. In the literature [Fu (1982); Kleijn and Zhao (2013); Mukherjee et al. (2006);
Shwartz-Ziv and Tishby (2017); WU and Ghosal (2007)], one usually considers weak consistency
for the model space H, by insisting on convergence (3) only in the worst case i.e. if SuPf ∈h δn is
monotonically decreasing with sample size. However, in that case we loose the ability to distinguish
the rates of convergence for each model, which in this work is exploited as a measure of model
complexity. Clearly a model can be said to have lower complexity if its estimation error vanishes
faster i.e. the corresponding δn is smaller for the same sample size.
Therefore we can say that a model estimation problem is well posed if and only if the model space H
is η-sufficient, the empirical risk estimator is δn-strongly consistent and an unique solution exists to
the empirical risk minimization problem (4) i.e. the conditions under which an unique solution exists
to
inf	Rνemp
f ∈supp(π0)	n
(f)
(4)
such that log δn (f, e) < 0 and π0 ∈P? (H) is η-sufficient
(5)
Note that here we define the optimization problem in terms of estimating δn instead of the estimation
error e, which is usual in the literature [Catoni (2007)].
3
Under review as a conference paper at ICLR 2021
Now the necessary conditions for a solution to the constrained optimization problem (4)is provided
by the Karush-Kuhn-Tucker theorem [Parikh et al. (2014)], which states that if (f *, λ*) is a saddle
point for the associated Lagrangian function
L (f, νnmp, λ) = RVemP (f)+ λ logδn (f, E)	(6)
where f ∈ supp (∏o) and λ ≥ 0, then f * is an optimal solution. Note that here we use log δn, here
which not only allows us to formulate the Lagrangian in a standard regularization framework, but
also explicitly delineates the data-free prior π0, from a data-dependent update to it, which we derive
below (9).
Given the constraints (2) and (3), it is easy to see that, then the generalization error for f * is bounded
above by η + E with probability at least 1 - δn i.e.
Pr(| ∆νemp (f*) |< η + e) > 1- δn	(7)
Such a bound on generalization error is known as a PAC-Bound i.e. a Probably-Approximately-
Correct Bound ICatOni (2007)] signifying its probabilistic nature.
2.2	PAC-Bayes Approach
Now if the risk functional were assumed to be convex, the necessary conditions defined by the Karush-
Kuhn-Tucker theorem are known to be sufficient and hence the solution is unique e.g. ordinary
least squares regression [Parikh et al. (2014)]. Unfortunately, in many modern applications such
an assumption cannot be made. However, if we can assume that the derivative of the Lagrangian
functional (6) is Lipschitz continuous, then its Donsker-Varadhan dual [Donsker and Varadhan (1975)]
is known to be strongly convex [Zhou (2018)] in the space of probability measures with finite second
moments.
PAC-Bayesian analysis [McAllester (1999); Ambroladze et al. (2007); Audibert and Bousquet
(2007); Begin et al. (2014); Catoni (2007)； Freund (1998); Germain et al.(2016); Guedj (2019)] is a
framework which exploits such a duality, by defining the pseudo-posterior measure as the unique
measure which minimizes the expected Lagrangian in the support of the prior i.e. for γ>0
∏n :=	arg inf	∖ E∏n	[L]	- E∏0	[L]	+ 1KL	(∏n	| ∏o)j
πn∈P2(H) n	0	γ
which admits an unique analytic solution, given by the associated Gibbs measure
d∏n x exp (-γL (f, νnmp, λ)) d∏o
x eχp (-γ RVemp ⑺)dπo
where w.l.o.g. with λ>0,
d∏λ (f) X exp (-λ log δn (f, e)) d∏o (f)
(8)
(9)
We call ∏λ the consistency pseudo-prior, and interpret it to be a data-dependent (or model-dependent)
consistency promoting update to the data-free η-sufficient prior π0 .
Ignoring the consistency criterion i.e. for λ =0, we end up with the standard data-independent
PAC-Bayesian approach, which has had great success especially in the case of classification and
regression problems with bounded risk functionals [Catoni (2007); Germain et al. (2009; 2015);
Guedj (2019)]. However in the under-sampled regime, when the number of samples are smaller than
the number of parameters, such optimality results do not hold. In this case, the data-free prior, which
in the end is just a guess, unreasonably dominates the posterior. A data/model-dependent pseudo-
prior like (9) on the other hand, provides a consistent approach to modifying data-free priors by
promoting functions of lower “complexity” in the support of the prior which admit faster convergence
based on the available data. This allows us to construct accurate bounds on the generalization error
corresponding to both the prior as well as the posterior.
Following the same logic as above, if for any η-sufficient prior πo ∈P2 (H), we can estimate the con-
sistency pseudo-prior (9) and its associated pseudo-posterior measure ∏n (8), then the corresponding
PAC-Bayes confidence interval on generalization error is given by
Pr (| E∏λ [∆νemp] |< η + e) > 1 - E∏λ 瓦(f, e)]
4
Under review as a conference paper at ICLR 2021
and
Pr (| E^n [∆νemp] |< η + e) > 1 - En“ 瓦(f, e)]	(10)
Note that since ∏n《∏λ (absolutely continuous), clearly E^n [δn (f, e)] < E∏λ [δn (f, e)] <
δn (f, e) and therefore the expected performance of sample functions under the posterior is necessarily
better than under the consistency pseudo-prior, which on the other hand performs better than a fixed
point-wise estimate in probability.
Therefore given a risk functional with Lipschitz continuous derivatives, if we can construct the
function δn (f, e) which satisfies (3), then the optima of the Lagrangian functional (6) can be
represented by an unique pseudo-posterior measure (8), whose samples satisfy the PAC-Bayes bound
on generalization error(IO). In the next section we provide such a construiction.
3 Exact Asymptotic B ound on Estimation Error
3.1 Bounding the Estimation Error
In order to calculate the data/model dependent prior update (9), we need to calculate the probability
Pr(RVemp (f) ≥ RV (f) + e)
Let {r,(f) ：= R (f)] δχj
∞
i=1
i削.λn be i.i.d. random variables, then most bounds on Estimation
error in the literature are based on the Cramer-Chernoff method [Boucheron et al. (2013)]. A
Chernoff-type inequality, is defined for AR (Y) = log E [eγR] we have
Pr (R ≥ t) ≤ exp ✓— sup {γt — AR (λ)})
γ∈R
=eχp(-AR ⑴)
(11)
where AX (t) is the Legendre-Fenchel transform of AR and t ≥ E [R]. Since AR (0) = 0, AR is a
non-negative function. Further if E [R] exists, then the convexity of the exponential function and
Jensen’s inequality imply AR (γ) ≥ γE [R] and hence for all negative values of γ, γt - AR (γ) ≤ 0
whenever t ≥ E [R].
Now bounding the estimation error, requires constructing bounds on sums of real valued random
variables. The main idea here is to set Rn = Pin=1 (Ri - E [Ri]), we have
n
AR (Y) = logE heγPin=1(Ri-E[Ri])i = XlogE heγ(Ri-E[Ri])i
i=1
and hence the Cramer-Chernoff method can be applied. For example, ifRi is assumed to be bounded in
a compact interval on the real line, then we end up with the well-known Hoeffding’s inequality which
has been extensively applied in [Audibert and Bousquet (2007); Kaariainen and Langford (2005);
McAllester (1999); Boucheron et al. (2013)] to derive PAC-Bayes bounds. Under sub-Gaussian (i.e.
Λr (λ) ≤ λ2ν for all λ ∈ R with variance factor v) or sub-Gamma tail (i.e. AR (λ) ≤
—λ V— for
2(1-cλ) for
all 0 <λ< 1/c with variance factor v and scale factor c) assumptions over Ri, using the fact that
log U ≤ U 一 1 for u > 0, we can derive Bennet and Bernstein's inequalities [Boucheron et al. (2013)]
respectively, which have been used extensively to derive bounds on the estimation error in various
and Guedj
applications [Mhammedi et al. (2019); Tolstikhin and Seldin (2013); Alquier and Guedj (2018);
Ambroladze et al. (2007); Arora et al. (2018); Audibert and BOUSqUet (2007); Holland(2019)].
In the following theorem, we show that such a method can be made much sharper than the one
produced by the Cramer-Chernoff method.
Theorem 1.	Given a set of random variables Xi,..., Xn, l对' V ∈ P? (Rd), consider the real
valued push-forward measure Rδ	(f)] ν. If the cumulant generating function of its centered
empirical measure,	AVnp(Y)=	log EVnp	[exp Y	(Rδχι	(f) 一	RVnp	(f))]	is Such that D emp :=
νn
5
Under review as a conference paper at ICLR 2021
{γ ≥ 0 : AV emp (γ) < ∞} ⊃ {0}, then for any e ∈
{AVemp (Y) : Y ∈ DΛvemp O, We have
Pr (RVnmp (f) ≥ RV (f) + e) = exp (-nA：emp (e
ξ	JAVnp (C)
√2πn A：[mp (e)
Vn
+ O (n-3/2)
(12)
where
{1	if Rδxι (f) is continuous
—Nfm ㈤、ifR δχ (f) is discrete
1-exp 八热(e))	δ 'X1 ⑺
Further the corresponding asymptotic convergence rate satisfies the Chernoff’s theorem i.e. this
estimate cannot be dominated by another estimator.
Proof. Let Yi I削.λn := R (f)] πnmp for which the logarithmic moment generating function An (η)=
log Eμn [eηY1 ] exists and set A (e) = [e, ∞), where e = An (η) for some positive η ∈ D◦n :=
{ζ ∈ R+ :An (ζ) < ∞}. Note that limn→∞ A0n (0) = ER(f)]π [ψ] =: R (fV) via weak law of
large numbers ∣Dembo and Zeitouni (2009)]. From Donsker-Varadhan duality, we know that the
exponentially tilted probability measure i.e. dλn(x) = eηx-An(η)dλn(x) represents the distribution
of random variables Yi normalized and centered around e =A0n (η) i.e.
Zi :=	i⅛d.f
Further, let Un := n-1/2 Pin=1 Zi and denote its cumulative distribution function by
Hn (u)=Pr (Un <u) , (-∞ <u<∞)
Then by construction we have Renmp (fV)
Pr(RnmP (fν) ≥e)= Eμn
1 = e + UnJAn (η)∕n, which means that
h1{Rnιp(fν)≥6}i = Eμn [1{Un≥0}]
e-nAn(e)Ef [e-ηVZnAn⑺UnIyo]
e-nAn(e) Z	e-α⑺√nudHn (u)
0
∞
e-nAn(e) /	e-t
0
Hn ✓
t
α (λ)
- Hn (0) dt
using the integration by parts formula and a change of variables with t = α (λ) √nu , where
α (λ) = λpAn (λ) and
An (e) := SUP {ηe - An ㈤}
η∈DΛ
Here α (λ) can be re-written as a function of e using the equalities
λ = An (e) and An (λ)=―㈤
Finally, we need to estimate the integral
In := Z∞ e-t
0
Hn	✓ OW
- Hn (0) dt
To this end, consider the Berry-Esseen expansion of the cumulative distribution functions Hn which
is given by [Dembo and Zeitouni (2009)]
lim
n→∞
SUP | Hn (U) - φ (U)-泻=(1 - u2) φ (u) | ] = 0
u	6n
6
Under review as a conference paper at ICLR 2021
where m3 := E
3	ψ] fν] πnemp
[Z3] < ∞, φ(u) = 1∕√2∏e-u2/2 is the standard Normal density and Φ(u)
R-u∞ φ(t)dt. Now since the Taylor expansion of Φ is given by
φ ✓ αwn) = φ ⑼ + √2π {αwn+O (n-3/2)}
therefore asymptotically we have
∞
0
In ≈
-Φ (0) + O (n-3∕2)
/	e-t √2∏ { α (λ) √n + O (n-3∕2)}dt
(α (λ) √2πn)	+ O (n-3/2)
Plugging in all the terms we get the final result
Pr (Rnmp (fν) ≥ e) = √1= exp (-4 (e))
2πn
+ O (n-3/2)
In the literature, usually one fixes the probability (12) say at α ∈ [0,1] and then estimates the
corresponding error e = δ-1 (f, α) via inversion and is necessary for further analysis. For bounds
under sub-Gaussian and sub-Gamma tails derived using Cramer-Chernoff method, such an inverse
can be analytically calculated. However, in our formulation we only need to estimate or bound
AVnP (E) accurately, in order to calculate the required Lagrangian functional (6), the prior (9)
associated bounds on generalization error (10).
νn
and the
Note that even if AVemP ⑹ ≈ 0, We still see δn converging to 0 at the rate O (n-1/2), i.e. We get
the weak law of large numbers, which is not possible to show in a Chernoff-Inequality. Therefore,
by optimizing the Lagrangian functional (6) we can ensure models which admits the least amount
of estimation error. HoWever, unfortunately in the case of an interpolating model like Deep neural
networks, around the optima the empirical risk usually becomes zero and then our data/model
dependent correction becomes vacuous. Since when optimized using a stochastic gradient descent
algorithm, the generalization error is observed (via out of sample risk) [Zhang et al. (2016)] to
decrease, the optimization algorithm has an effect [London (2017)] on the approximation error and
hence the η-sufficiency (2) of the prior on the model space.
3.2 Estimating the Moment Generating Function AVEMP
In order to estimate An (e), we need to estimate the moment generating function of the push-forward
measure λn := R(f)] νnemp. Here we want to show that push-forward measures from i.i.d. observations
are necessarily Levy measures on R+, which allows us to use Levy-Khintchine theorem to estimate
the bound. The push forward measure for each function f ∈ H i.e. R (f)] : P2 (Rd) → R (R+)
is a Radon measure on the non-negative real line such that ∀ν ∈ P2 (Rd) and for all Borel subsets
A ∈B(R+)
Z dR(f)]ν=Z
A	R(f)-1(A)
fdν
If the risk functional is unbounded, the push-forward empirical measure λn := R(f)] νnemp need not
be a probability measure and can be unbounded on the non-negative real line i.e. λn(]0, ∞[) = ∞. It
is easy to see this if the map R (f) is not a one to one function. For example, let ν be the probability
measure on R2 and consider the continuous square projection map onto the first dimension P1 : R2 →
R. Set ν0 := P]ν, then for every X ∈ R, we have ν0 (x) = V (P-I (x)) = V ({x} ∪ {—x} X R)=
0. But for any small open set U ⊂ R we get ν0 (U)=ν ({U} ∪ {-U} ×R) ≥ ν ({U} × R).
Integrating over all such open subsets, we can see that V0 need not be finite.
d
□
7
Under review as a conference paper at ICLR 2021
Now it is not necessary for this push forward measure λn to even have a finite first moment, let alone
a moment generating function. In order to ensure its existence, we need to put certain assumptions
on λn.Let {r,(f) = R (f)] δχ,}∞]
i削.λn be a sequence of i.i.d. samples from the push-forward
empirical measure. Let λn be a general measure on ]0, ∞[ such that even if
λn(]0, ∞[) = ∞
assume for some δ>0 that
Z
]0,∞[
min(τ, r)λn (dr) < ∞
Observe that the integrability condition 15 implies that for every δ > 0 the tail-intensity λn(]δ, ∞[)
is finite i.e. there are only finitely many atoms in ]δ, ∞[, even when there are infinitely many atoms
in ]0, ∞[ since λn(]0, ∞[) = ∞. Further, the COnditiOn同implies that the series P∞=ι riI{Li≤δ}
converges almost surely since
Eλn X riI{ri ≤δ} =	rdλn(l) < ∞
i=1	]0,δ[
and as there are only finitely many atoms in ]δ, ∞[, we have
∞
X ri < ∞
i=1
almost surely. Conversely, the series P1∞ ri diverges almost surely whenever the integral condition
fails. This means that the above integral condition 15 provides the necessary and sufficient condition
for the infinite sum to be finite for any push-forward measure λn .
Further as we shall see now, it also characterizes the condition under which the moment generating
function exists. Consider an independent sequence U1,U2... of i.i.d. uniform variables on [0, 1], and
define the purely discontinuous increasing process
∞
Z⑴ := X ri(f) I{Ui≤t} = X ri(f), t ∈ [0,1]
i=1	Ui≤t
(13)
Clearly the increasing process (ζ (t), 0 ≤ t ≤ 1) has independent and stationary increments. This
means that for every 0 = to < tι < … < tn, < tr,+ι = 1, the variables Z(tι) 一 Z(to),…,Z(tn+ι) 一
ζ(tn) are independent, and ζ (ti+1) -ζ(ti) has the same law as ζ (ti+1 -ti). Such a stochastic process
Z(t) is known as a subordinator on the time interval [0, 1], and is an almost surely non-decreasing
Levy process due to the following characterization given by the Levy-Khintchine formula.
Theorem 2.	Levy-Khintchine Formula [Bertoin∣ (2006)]: The Laplace-Stieltjes transform of a
subordinator on R+ has a unique representation of the form
Aλn (Y) := log E [exP (-YZ⑴)]
!++ [1-
e-γr] λr (dr)
(14)
if and only if the push-forward measure λr on R+ satisfies, for some τ>0
Z
]o
min(τ, r)λr (dr) < ∞
(15)
,∞
[
Then λr is known as a Levy measure.
Therefore Levy-Khintchine theorem (14) implies that Z(t) is a subordinator if and only if λr, the
push-forward measure defined on R+ is a Levy measure. Many of the well studied measures belong
to the family of Levy measures, including Compound Poisson Processes, Gaussian Processes, Gamma
Processes, Stable Processes, etc. Hence even if the cumulant generating function of the original
measure does not exist, if the push-forward measure satisfies (15), then it,s corresponding cumulant
generating function exists.
8
Under review as a conference paper at ICLR 2021
3.3 Applications
Now we show two examples with square error loss but different noise characteristics, where our
method leads to consistent estimators even though the risk functional may not be bounded.
Gamma subordinators The Gamma subordinator is suitable when the tail of the push-forward loss
measure decreases exponentially fast. This is the case for square error loss, with normally distributed
noise. Since sum of square normal variables leads to chi-squared variates, the resulting push-forward
loss can be modeled via a Gamma subordinator. Let there exist two fixed real numbers θ, c > 0,
such that the Levy measure given by dλn (x) = θx-1e-cxdx fits the push-forward measure well.
Then its moment generating function is given by AVemp (Y) = - log(1 + Yc), Y ≥ 0 and hence the
corresponding bound on estimation error is given by
e-nθ(logc-1)	√θ	θ
Pr(I RVemp (f) - RV ⑴ l≥ e) ≤ ----√=- e---------^eXp (-n (Ce - θlog (C))) for e >
n	√2πn	(Ce - θ)	C
Stable Subordinators The Stable subordinator is suitable when the tail of the push-forward loss
measure decreases polynomially fast. This is the case for square error loss, with heavy tailed noise.
Let α ∈]0, 1[ and C>0 be fixed parameters, such that the Levy measure given by dλn (x)=
「(；:的 x-1-αdx fits the push-forward measure well. Then its moment generating function is given
by AVemp (Y) = -CYα, Y ≥ 0 and hence the corresponding bound on estimation error is given by
Pr (I RVemP (f)- Rv (f) I≥e) ≤
11
22αnq √A*ernp (e)
Vn
exp (—nA[emp (e
___α	1_	α
where AVemP (e) = e- 1-α (αc)1-α — C (ɑc)1-α . Therefore, even in the case of unbounded losses
and small samples, we can estimate a bound on the estimation error for push-forward measures with
both exponentially and polynomially decreasing tails.
4 Conclusions
In this work, we designed a step by step framework to construct well posed model estimation
algorithms by ensuring sufficiency, consistency and uniqueness of the optimization problem. We
showed that the PAC-Bayes approach admits a unique Gibbs measure, if the risk functional can be
assumed to have Lipschitz continuous derivatives. We approached the problem of their unboundedness
by first observing that a risk functional pushes forward the empirical measure to a Radon measure
on the non-negative real line which is necessarily a Levy measure. Hence, the only necessary and
sufficient condition for a resulting PAC-Bayes bound (10) to exist was shown to be an integrability
condition (15) derived from the Levy-Khintchine theorem. Further, we derived a Bahadur-Rao type
exact asymptotic bound, which is much sharper than a traditional Chernoff type inequality, especially
in the under-sampled regime. Such a construction allowed us to derive data or model-dependent
consistency promoting updates to a data-free prior, which provably improve the generalization
performance. As examples we showed that if the push-forward measure can be modeled either by
a Gamma subordinator for exponentially decreasing tail or Stable subordinator for polynomially
decreasing tail we can derive the corresponding PAC-Bayes bounds.
References
Pierre Alquier and Benjamin Guedj. Simpler PAC-Bayesian bounds for hostile data. Machine learning,
107(5):887-902, May 2018. URL https://doi.org/10.1007/s10 9 94-017-5 6 90-0
3.1
Amiran Ambroladze, Emilio Parrado-hernandez, and John S Shawe-taylor. Tighter PAC-Bayes
bounds. In B Scholkopf, J C Platt, and T Hoffman, editors, Advances in Neural Information
Processing Systems 19, pages 9-16. MIT Press, 2007. URL http://papers.nips.cc/
paper/3058-tighter-pac-bayes-bounds.Pdf 口四回
9
Under review as a conference paper at ICLR 2021
Sanjeev Arora, Rong Ge, Behnam Neyshabur, and Yi Zhang. Stronger generalization bounds for deep
nets via a compression approach. February 2018. URL http://arxiv.org/abs/1802.
05296. 1,3.1]
Jean-Yves Audibert and Olivier Bousquet. Combining PAC-Bayesian and generic chaining bounds.
Journal of machine learning research: JMLR, 8:863-889, May 2007. URL https://dl.acm.
org/doi/10.55 55/12 4 8 65 9.12 4 8 691. 1,2.2,3.1]
Luc Begin, Pascal Germain, FranCoiS Laviolette, and Jean-Francis Roy. PAC-Bayesian theory for
transdUctive learning. undefined, 2014. URL https://www.semanticscholar.org/
paper/dde1d8e12fac6ce3fcb0b4a4c94e7 0a5b2 5 9a3 91. 2.2∣
Mikhail Belkin, Siyuan Ma, and Soumik Mandal. To understand deep learning we need to understand
kernel learning. February 2018. URL http://arxiv.org/abs/1802.01396. 1
Jean Bertoin. Random Fragmentation and Coagulation Processes. Cambridge Studies in Advanced
Mathematics. Cambridge University Press, August 2006. URL https://play.google.
com/store/books/details?id=yndbFG6medoC 回gj[2
Stephane Boucheron, Gabor Lugosi, and Pascal Massart. Concentration Inequalities:
A Nonasymptotic Theory of Independence.	Oxford University Press, Oxford, 2013.
URL https://oxford.universitypressscholarship.com/10.1093/acprof:
oso/97 8019953 52 55.001.0001/acprof-97 801995352 55 ∣3T]∣3I]
Damian Brzyski, Christine B Peterson, Piotr Sobczyk, Emmanuel J Candes, Malgorzata Bogdan, and
Chiara Sabatti. Controlling the rate of GWAS false discoveries. Genetics, 205(1):61-75, January
2017. URL http://dx.doi.org/10.1534/genetics.116.193987 臼
Olivier Catoni. Pac-Bayesian supervised classification: The thermodynamics of statistical learning.
December 2007. URL http://arxiv.org/abs/0712.0248 [T]∣2.1∣,[2yT∣∣2.2∣,[22∣
Amir Dembo and Ofer Zeitouni. Large Deviations Techniques and Applications. Stochastic Modelling
and Applied Probability. Springer Berlin Heidelberg, November 2009. URL https://play.
google.com/store/books/details?id=d3nnjwEACAAJ, 1,3.1∣
Sophie Donnet, Vincent Rivoirard, Judith Rousseau, and Catia Scricciolo. Posterior concentration
rates for empirical bayes procedures, with applications to dirichlet process mixtures. June 2014.
URL http://arxiv.org/abs/1406.4406. 2.1∣
M D Donsker and S R S Varadhan. Asymptotic evaluation of certain markov process expec-
tations for large time, I. Communications on Pure and Applied Mathematics, 28(1):1-47,
January 1975. URLhttps://onlinelibrary.wiley.com/doi/abs/10.1002/cpa.
3160280102.[∑2
Gintare Karolina Dziugaite and Daniel M Roy. Computing nonvacuous generalization
bounds for deep (stochastic) neural networks with many more parameters than train-
ing data. March 2017a.	URLJhttPS://www.SemantiCSCholar.org/paper/
4f8a8 7 535 7 94 57 604 3 803de919cbcd95 5cdc92f6. 1
Gintare Karolina Dziugaite and Daniel M Roy. Entropy-SGD optimizes the prior of a PAC-Bayes
bound: Generalization properties of Entropy-SGD and data-dependent priors. December 2017b.
URL http://arxiv.org/abs/1712.09376. 1
Dylan J Foster, Spencer Greenberg, Satyen Kale, Haipeng Luo, Mehryar Mohri, and Karthik Sridharan.
Hypothesis set stability and generalization. In H Wallach, H Larochelle, A Beygelzimer, F dAlche-
Buc, E Fox, and R Garnett, editors, Advances in Neural Information Processing Systems 32,
pages 6729-6739. Curran Associates, Inc., 2019. URL http://papers.nips.cc/paper/
8898-hypothesis-set-stability-and-generalization.pdf 1
Yoav Freund. Self bounding learning algorithms. In Proceedings of the eleventh annual conference
on Computational learning theory - COLT’ 98, pages 247-258, New York, New York, USA,
1998. ACM Press. URL http://portal.acm.org/Citation.cfm?doid=2 7 994 3.
279993. 2.2]
10
Under review as a conference paper at ICLR 2021
James C Fu. Large sample point estimation: A large deviation theory approach. Annals of statistics,
10(3):762-771, 1982. URL http://www.jstor.org/stable/2240902. 2.1∣
Pascal Germain, Alexandre Lacasse, FranCoiS Laviolette, and Mario Marchand. PAC-BayeSian
learning of linear classifiers. In Proceedings of the 26th Annual International Conference on
Machine Learning, ICML ’09, pages 353-360, New York, NY, USA, June 2009. Association for
Computing Machinery. URL https://doi.org/10.1145/1553374.1553419. 2.2
Pascal Germain, Alexandre Lacasse, FranCois Laviolette, Mario Marchand, and Jean-Francis Roy.
Risk bounds for the majority vote: From a PAC-Bayesian analysis to a learning algorithm. March
2015. URL http://arxiv.org/abs/1503.08329. 2.2∣
Pascal Germain, Francis Bach, Alexandre Lacoste, and Simon Lacoste-Julien. PAC-Bayesian
theory meets bayesian inference. In D D Lee, M Sugiyama, U V Luxburg, I Guyon,
and R Garnett, editors, Advances in Neural Information Processing Systems 29, pages
1884-1892. Curran Associates, Inc., 2016. URL http://papers.nips.cc/paper/
65 69-pac-bayesian-theory-meets-bayesian- inference.pdf. 1, 2.2]
Samuel J Gershman and David M Blei. A tutorial on bayesian nonparametric models. June 2011.
URL http://arxiv.org/abs/1106.2697. 1,2.1]
Peter D Grunwald and Nishant A Mehta. A tight excess risk bound via a unified PAC-Bayesian-
Rademacher-Shtarkov-MDL complexity. volume 98 of Proceedings of Machine Learning Re-
Search, pages 433Y65, Chicago, Illinois, 2019. PMLR. URL http://proceedings.mlr.
PreSS/v98/grunwald19a.html. 1
Benjamin Guedj. A primer on PAC-Bayesian learning. January 2019. URL http://arxiv.org/
abs/1901.05353. 2.2, 2.2∣
Shota Gugushvili, Ester Mariucci, and Frank van der Meulen. Decompounding discrete distributions:
A non-parametric bayesian approach. March 2019. URL http://arxiv.org/abs/1903.
11142. 2.1]
Matthew Holland. PAC-Bayes under potentially heavy tails. In H Wallach, H Larochelle, A Beygelz-
imer, F dAlche-Buc, E Fox, and R Garnett, editors, Advances in Neural Information Processing
Systems 32, pages 2715-2724. Curran Associates, Inc., 2019. URL http://papers.nips.
cc/paper/853 9-pac-bayes-under-potentially-heavy-tails.pdf, 3.1
Matti Kaariainen and John Langford. A comparison of tight generalization error bounds, 2005. URL
http://dx.doi.org/10.114 5/1102 3 51.1102 4 03. 3.1∣
Kenji Kawaguchi, Leslie Pack Kaelbling, and Yoshua Bengio. Generalization in deep learning.
October 2017. URL http://arxiv.org/abs/1710.05468. 1
John Kingman. Completely random measures. Pacific Journal of Mathematics, 21(1):59-78, April
1967. URL https://msp.org/pjm/19 67/21-1/p06.xhtml. 2.1]
BJK Kleijn and Y Y Zhao. Criteria for posterior consistency. August 2013. URL http:
//arxiv.org/abs/1308.1263. 1, 2.1, 2.1]
Francesco Locatello, Rajiv Khanna, Joydeep Ghosh, and Gunnar Ratsch. Boosting variational
inference: an optimization perspective. August 2017. URL http://arxiv.org/abs/17 08.
01733. 1
Ben London. A PAC-Bayesian analysis of randomized learning with application to stochastic
gradient descent. In I Guyon, U V Luxburg, S Bengio, H Wallach, R Fergus, S Vishwanathan,
and R Garnett, editors, Advances in Neural Information Processing Systems 30, pages
2931-2940. Curran Associates, Inc., 2017. URL http://papers.nips.cc/paper/
6886-a-pac-bayesian-analysis-of-randomized-learning-with-application-to-stochastic
pdf. ∣3.1∣
David McAllester. A PAC-Bayesian tutorial with a dropout bound. July 2013. URL http:
//arxiv.org/abs/1307.2118.1
11
Under review as a conference paper at ICLR 2021
David A McAllester. Some PAC-BayeSian theorems. Machine learning, 37(3):355-363, December
1999. URL https://doi.Org/10.102 3/A:1007 618 62 4 80 9. 1,2.2,3.1]
Andrew McDavid, Raphael Gottardo, Noah Simon, and Mathias Drton. GRAPHICAL MODELS
FOR ZERO-INFLATED SINGLE CELL GENE EXPRESSION. The annals of applied statistics,
13(2):848-873, June 2019. URL http://dx.doi.org/10.1214/18-AOAS1213. 1
Marina Meila. Learning with mixtures of trees. Journal of machine learning research: JMLR, 1:
1-48, 2000. 1
Zakaria Mhammedi, Peter Grunwald, and Benjamin Guedj. PAC-Bayes Un-Expected bern-
stein inequality. In H Wallach, H Larochelle, A Beygelzimer, F dAlche-Buc, E Fox,
and R Garnett, editors, Advances in Neural Information Processing Systems 32, pages
12202-12213. Curran Associates, Inc., 2019. URL http://papers.nips.cc/paper/
9387-pac-bayes-un-expected-bernstein-inequality.pdf. 3.1∣
Sayan Mukherjee, Partha Niyogi, Tomaso Poggio, and Ryan Rifkin. Learning theory: stability
is sufficient for generalization and necessary and sufficient for consistency of empirical risk
minimization. Advances in computational mathematics, 25:161-193, 2006. 1, 2.1
Behnam Neyshabur, Srinadh Bhojanapalli, and Nathan Srebro. A PAC-Bayesian approach to
Spectrally-Normalized margin bounds for neural networks. February 2018. URL https://
openreview.net/pdf?id=Skz_WfbCZ.臼
Xuanlong Nguyen. Convergence of latent mixing measures in finite and infinite mixture models. (1):
370-400, September 2011. URL http://arxiv.org/abs/110 9.32 50. 1
Neal Parikh, Stephen P Boyd, and Others. Proximal algorithms. Foundations and Trends in
optimization, 1(3):127-239, 2014. URL https://web.stanford.edu/~boyd/papers/
pdf/prox algs.pdf [T][2.1,[2?2]
Emilio Parrado-Hernandez, Amiran Ambroladze, John Shawe-Taylor, and Shiliang Sun. PAC-Bayes
bounds with data dependent priors. Journal of machine learning research: JMLR, 13(112):
3507-3531, 2012. URL https://www.jmlr.org/papers/v13/parrado12a.html.
1
Sonia Petrone and Piero Veronese. Non parametric mixture priors based on an exponential random
scheme. Statistical methods & applications, 11(1):1-20, February 2002. URL https://doi.
org/10.1007/BF02511443.1
Harish G Ramaswamy. Mixture proportion estimation via kernel embedding of distributions. 1
Richard A Redner and Homer F Walker. Mixture densities, maximum likelihood and the em algorithm.
SIAM Review, 26(2):195-239, 1984. URL http://www.jstor.org/stable/2030064.
1	-------------------------------------
Omar Rivasplata, Ilja Kuzborskij, Csaba Szepesvari, and John Shawe-Taylor. PAC-Bayes analysis
beyond the usual bounds. June 2020. URL http://arxiv.org/abs/2 00 6.1305 7. 1
Matthias Seeger. PAC-Bayesian generalisation error bounds for gaussian process classification.
Journal ofmachine learning research: JMLR, 3(Oct):233-269, 2002. URL http://www.jmlr.
org/PaPerS/v3/Seeger02a.html. 2.1
Ravid Shwartz-Ziv and Naftali Tishby. Opening the black box of deep neural networks via information.
March 2017. URL http://arxiv.org/abs/1703.00810. 1,2.1
Pragya Sur and Emmanuel J Candes. A modern maximum-likelihood theory for high-dimensional
logistic regression. Proceedings of the National Academy of Sciences of the United States of
America, 116(29):14516-14525, July 2019. URL http://dx.doi.org/10.107 3/pnas.
1810420116.1
12
Under review as a conference paper at ICLR 2021
Ilya O Tolstikhin and Yevgeny Seldin. PAC-Bayes-Empirical-Bernstein inequality. In C J C Burges,
L Bottou, M Welling, Z Ghahramani, and K Q Weinberger, editors, Advances in Neural Information
Processing Systems 26, pages 109-117. Curran Associates, Inc., 2013. URL http://papers.
nips.cc/paper/4903-pac-bayes-empirical-bernstein-inequality.pdf.
3.1]
Vladimir Vapnik. The Nature of Statistical Learning Theory (Information Science and Statistics).
2000. URL https://www.springer.com/de/book/97 80387 987804. 1,2
Yuefeng Wu and Subhashis Ghosal. Kullback Leibler property of kernel mixture priors in Bayesian
density estimation. Electron. J. Stat., (0):298-331, October 2007. URL http://arxiv.org/
abs/0710.2746 [Γ∣[ΣT]
Chiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht, and Oriol Vinyals. Understanding
deep learning requires rethinking generalization. November 2016. URL http://arxiv.org/
abs/1611.03530. 1,3.1∣
Wenda Zhou, Victor Veitch, Morgane Austern, Ryan P Adams, and Peter Orbanz. Non-Vacuous
generalization bounds at the ImageNet scale: A PAC-Bayesian compression approach. April 2018.
URL http://arxiv.org/abs/1804.05862. 1
Xingyu Zhou. On the fenchel duality between strong convexity and lipschitz continuous gradient.
March 2018. URL http://arxiv.org/abs/1803.06573. 2.2]
13