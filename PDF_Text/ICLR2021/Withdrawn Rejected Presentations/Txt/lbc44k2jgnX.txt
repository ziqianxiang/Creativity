Under review as a conference paper at ICLR 2021
Random Coordinate Langevin Monte Carlo
Anonymous authors
Paper under double-blind review
Ab stract
Langevin Monte Carlo (LMC) is a popular Markov chain Monte Carlo sampling
method. One drawback is that it requires the computation of the full gradient at
each iteration, an expensive operation if the dimension of the problem is high. We
propose a new sampling method: Random Coordinate LMC (RC-LMC). At each
iteration, a single coordinate is randomly selected to be updated by a multiple of
the partial derivative along this direction plus noise, and all other coordinates re-
main untouched. We investigate the total complexity of RC-LMC and compare it
with the classical LMC for log-concave probability distributions. When the gra-
dient of the log-density is Lipschitz, RC-LMC is less expensive than the classical
LMC if the log-density is highly skewed for high dimensional problems, and when
both the gradient and the Hessian of the log-density are Lipschitz, RC-LMC is al-
ways cheaper than the classical LMC, by a factor proportional to the square root
of the problem dimension. In the latter case, our estimate of complexity is sharp
with respect to the dimension.
1 Introduction
Monte Carlo sampling plays an important role in machine learning (Andrieu et al., 2003) and
Bayesian statistics. In applications, the need for sampling is found in atmospheric science (Fabian,
1981), epidemiology (Li et al., 2020), petroleum engineering (Nagarajan et al., 2007), in the form
of data assimilation (Reich, 2011), volume computation (Vempala, 2010) and bandit optimiza-
tion (Russo et al., 2018).
In many of these applications, the dimension of the problem is extremely high. For example, for
weather prediction, one measures the current state temperature and moisture level, to infer the flow
in the air, before running the Navier-Stokes equations into the near future (Evensen, 2009). In a
global numerical weather prediction model, the degrees of freedom in the air flow can be as high
as 109 . Another example is from epidemiology: When a disease is spreading, one measures the
everyday new infection cases to infer the transmission rate in different regions. On a county-level
modeling, one treats 3, 141 different counties in the US separately, and the parameter to be inferred
has a dimension ofat least 3, 141 (Li et al., 2020).
In this work, we focus on Monte Carlo sampling of log-concave probability distributions on Rd,
meaning the probability density can be written as p(χ) 8 e-f(X) where a f (x) is a convex
function. The goal is to generate (approximately) i.i.d. samples according to the target probabil-
ity distribution with density p(x). Several sampling frameworks have been proposed in the lit-
erature, including importance sampling and sequential Monte Carlo (Geweke, 1989; Neal, 2001;
Del Moral et al., 2006); ensemble methods (Reich, 2011; Iglesias et al., 2013); Markov chain Monte
Carlo (MCMC) (Roberts and Rosenthal, 2004), including Metropolis-Hasting based MCMC (MH-
MCMC) (Metropolis et al., 1953; Hastings, 1970; Roberts and Tweedie, 1996); Gibbs samplers
(Geman and Geman, 1984; Casella and George, 1992); and Hamiltonian Monte Carlo (Neal, 1993;
Duane et al., 1987). Langevin Monte Carlo (LMC) (Rossky et al., 1978; Parisi, 1981; Roberts and
Tweedie, 1996) is a popular MCMC method that has received intense attention in recent years due to
progress in the non-asymptotic analysis of its convergence properties (Durmus and Moulines, 2017;
Dalalyan, 2017; Dalalyan and Karagulyan, 2019; Durmus et al., 2019).
Denoting by xm the location of the sample at m-th iteration, LMC obtains the next location as
follows:
xm+1 = Xm - Vf(Xm)h + √2hξm ,
(1)
1
Under review as a conference paper at ICLR 2021
where h is the time stepsize, and ξdm is drawn i.i.d. from N(0, Id), where Id denotes identity matrix
of size d × d. LMC can be viewed as the Euler-Maruyama discretization of the following stochastic
differential equation (SDE):
dXt = -Vf(Xt) dt + √2dBt,d,	⑵
where Bt,d is a d-dimensional Brownian motion. It is well known that under suitable conditions, the
distribution of Xt converges exponentially fast to the target distribution (see e.g., (Markowich and
Villani, 1999)). Since (1) approximates the SDE (2) with an O(h) discretization error, the probabil-
ity distribution of xm produced by LMC (1) converges exponentially to the target distribution up to
a discretization error (Dalalyan and Karagulyan, 2019).
A significant drawback of LMC is that the algorithm requires the evaluation of the full gradient
at each iteration. This could be potentially very expensive in most practical problems. Indeed,
when the analytical expression of the gradient is not available, each partial derivative component
in the gradient needs to be computed separately, either through finite differencing or automatic
differentiation (Baydin et al., 2017), so that the total number of such evaluations can be as many
as d times the number of required iterations. In the weather prediction and epidemiology problems
discussed above, f stands for the map from the parameter space of measured quantities via the
underlying partial differential equations (PDEs), and each dimensional partial derivative calls for
one forward and one adjoint PDE solve. Thus, 2d PDE solves are required in general at each
iteration. Another example comes from the study of directed graphs with multiple nodes. Denote
the nodes by N = {1, 2, . . . , d} and directed edges by E ⊂ {(i, j) : i, j ∈ N }, and suppose
there is a scalar variable xi associated with each node. When the function f has the form f(x) =
P(i,j)∈E fij(xi, xj), the partial derivative of f with respect to xi is given by
∂f = X	f (XiXj)+ X f (xι,xi).
j∙(ij)∈E	i	LQ,i)∈E	i
Note that the number of terms in the summations equals the number of edges that touch node i, the
expected value of which is about 2/d times the total number of edges in the graph. Meanwhile,
evaluation of the full gradient would require evaluation of both partial derivatives of each fij for all
edges in the graph. Hence, the cost difference between these two operations is a factor of order d.
In this paper, we study how to modify the updating strategies of LMC to reduce the numerical cost,
with the focus on reducing dependence on d. In particular, we will develop and analyze a method
called Random Coordinate Langevin Monte Carlo (RC-LMC). This idea is inspired by the random
coordinate descent (RCD) algorithm from optimization (Nesterov, 2012; Wright, 2015). RCD is a
version of Gradient Descent (GD) in which one coordinate (or a block of coordinates) is selected at
random for updating along its negative gradient direction. In optimization, RCD can be significantly
cheaper than GD, especially when the objective function is skewed and the dimensionality of the
problem is high. In RC-LMC, we use the same basic strategy: At iteration m, a single coordinate of
xm is randomly selected for updating, while all others are left unchanged.
Although each iteration of RC-LMC is cheaper than conventional LMC, more iterations are required
to achieve the target accuracy, and delicate analysis is required to obtain bounds on the total cost.
Analogous to optimization, the savings of RC-LMC by comparison with LMC depend on the struc-
ture of the dimensional Lipschitz constants. Under the assumption that there is a factor-of-d differ-
ence in per-iteration costs, we compare our results with current results for classical LMC (Dalalyan
and Karagulyan, 2019; Durmus et al., 2019) and conclude the following:
1. (Theorem 4.1) When the gradient of f is Lipschitz but the Hessian is not, RC-LMC costs
Oe (d1 2 /2 ) to get an -accurate solution. Therefore, RC-LMC outperforms LMC, in terms of
the computational cost, if f is skewed and the dimension of the problem is high, as discussed
in Remark 4.1. The optimal numerical cost in this setting is achieved when the probability of
choosing the i-th direction is proportional to the i-th directional Lipschitz constant.
2. (Theorem 4.2) When both the gradient and the Hessian of f are Lipschitz, RC-LMC requires
Oe(d3/2/) iterations to achieve accuracy. On the other hand, the currently available result
indicates that the classical LMC costs Oe(d2/). Thus, RC-LMC saves a factor of at least d1/2
regardless of the stiffness structure of f, as discussed in Remark 4.2.
2
Under review as a conference paper at ICLR 2021
3. (Proposition 4.2) The Oe(d3/2/) complexity bound for RC-LMC is sharp when both the gradient
and the Hessian of f are Lipschitz.
(The notation O(∙) omits possible log terms.) We make three additional remarks. (a) Throughout the
paper we assume that one element of the gradient is available at an expected cost of approximately
1/d of the cost of the full gradient evaluation. Although this property is intuitive, and often holds
in many situations (such as the graph-based example presented above), it does not hold for all prob-
lems (Wright, 2015). (b) Besides replacing gradient evaluation by coordinate algorithms, one might
also improve the dimension dependence of LMC by utilizing a more rapidly convergent method
for the underlying SDEs than (2). One such possibility is to use underdamped Langevin dynamics,
see e.g., (Rossky et al., 1978; Dalalyan and Riou-Durand, 2018; Cheng et al., 2018; Eberle et al.,
2019; Shen and Lee, 2019; Cao et al., 2019), which can also be combined with coordinate sampling.
For the clarity of presentation, we will focus only on LMC in this work and leave the extension to
underdampped samplers to a future work. (c) It is also possible to reduce the cost of full gradient
evaluation using stochastic gradient (Welling and Teh, 2011) or MALA-in-Gibbs sampling (Tong
et al., 2020). However, both methods require specific forms of the objective function that are not
considered in our work.
The paper is organized as follows. We present the RC-LMC algorithm in Section 2. Notations and
assumptions on f are listed in Section 3, where we also recall theoretical results for the classical
LMC method. We present our main results regarding the numerical cost in Section 4 and numerical
experiments in Section 5. Proofs of the main results are deferred to the Appendix.
2 Random Coordinate Langevin Monte Carlo
We introduce the Random Coordinate Langevin Monte Carlo (RC-LMC) method in this section. At
each iteration, one coordinate is chosen at random and updated, while the other components of x
are unchanged. Specifically, denoting by rm the index of the random coordinate chosen at m-th
iteration, we obtain xrmm+1 according to a single-coordinate version of (1) and set xim+1 = xim for
i 6= rm .
The coordinate index rm can be chosen uniformly from {1, 2, . . . , d}; but we will consider more
general possibilities. Let φi be the probability of component i being chosen, we denote the distribu-
tion from which rm is drawn by Φ, where
Φ := {φ1, φ2, . . . , φd}, where φi > 0 for all i and Pid=1 φi = 1.	(3)
The stepsize may depend on the choice of coordinate; we denote the stepsizes by {h1, h2, . . . , hd}
and assume that they do not change across iterations. In this paper, we choose hi to be inversely
dependent on probabilities φi , as follows:
h
hi = ~J~ , i =1, 2, . . . , d ,	(4)
φi
where h > 0 is a parameter that can be viewed as the expected stepsize. In Section 4.2-4.3, we
will find the optimal form of Φ under different scenarios. The initial iterate x0 is drawn from a
distribution q0 , which can be any distribution that is easy to draw from (the normal distribution, for
example). We present the complete method in Algorithm 1.
When we compare (5) with the classical LMC (1), we see that only one random coordinate is updated
per iteration, meaning:
▽f (Xm) → ∂rm f(xm )erm ,	ξm → ξmerm
where ei is the unit vector for i-th direction and ξm is drawn from N(0, 1). Define the elapsed time
at m-th iteration as
m-1
Tm := X hrn , and T0 := 0,	(6)
n=0
then for t ∈ (Tm, Tm+1], the updating formula (5) can be viewed as the Euler approximation to the
following SDE:
Xrm(t) = Xrm(Tm) — t	∂rm f (X(s))ds + √2 f	dBs,
Tm	Tm
Xi (t) =Xi(Tm),	∀i 6=rm,
(7)
3
Under review as a conference paper at ICLR 2021
Algorithm 1 Random Coordinate Langevin Monte Carlo (RC-LMC)
Input: Coordinate distribution Φ := {φ1, φ2, . . . , φd}; parameter h > 0 and stepsize set
{hi, h2,..., hd} defined in (3)-(4); M (stop index).
Sample x0 from an initial distribution q0
for m = 0, 1, 2, . . . M - 1 do
1.	Draw rm ∈ {1, . . . , d} according to probability distribution Φ;
2.	Draw ξm from N (0, 1);
3.	Update xm+1 by
m+1 = (χm - hi∂if (xm) + √2hiξm, i = rm
xi = xim ,	i 6= rm
(5)
end for
return xM
where Bt is a 1-dimensional Brownian motion. We will show in Section 4.1 that the SDE preserves
the invariant measure, that is, X(t)〜P for any t > 0 if X(0)〜p, and it is ergodic. The invariant
measure of RC-LMC, which can be viewed as a discretized version of the SDE, is not exactly p, due
to the unavoidable discretization error.
3 Notations, assumptions and classical results
We unify notations and assumptions in this section, and summarize and discuss the classical results
on LMC. Throughout the paper, to quantify the distance between two probability distributions, we
use the Wasserstein distance defined by
W (μ,ν) = ( inf EX - Y I2)",
'(X,Y )∈Γ(μ,ν)	)
where Γ(μ, V) is the set of distribution of (X, Y) ∈ R2d whose marginal distributions, for X and Y
respectively, are μ and V. The distributions in Γ(μ, V) are called the couplings of μ and ν. Due to
the use of power 2 in the definition, this is sometimes called the Wasserstein-2 distance. Here and
in the sequel, We use ∣∙∣ to denote the Euclidean norm of a vector.
We assume that f is strongly convex, so that p is strongly log-concave. We obtain results under two
different assumptions: First, Lipschitz continuity of the gradient of f (Assumption 3.1) and second,
Lipschitz continuity of the Hessian of f (Assumption 3.2 together with Assumption 3.1).
Assumption 3.1. Thefunction f is twice differentiable, f is μ-StrongIy Convexfor some μ > 0 and
its gradient Vf is L-Lipschitz. That is,for all x, x0 ∈ Rd, we have
f (x) - f (x0) - Vf (x0)>(x - x0) ≥ 2Ix - X0I2 ,	(8)
and
IVf(x)-Vf(x0)I ≤LIx-x0I.	(9)
It is an elementary consequence of (8) that
(Vf (x0) -Vf(X))>(x0 — x) ≥ μ∣x0 — x∣2,	for all x,x0 ∈ Rd.	(10)
Since each coordinate direction plays a distinct role in RC-LMC, we distinguish the Lipschitz con-
stants in each such direction. When Assumption 3.1 holds, partial derivatives in all coordinate
directions are also Lipschitz. Denoting them as Li for each i = 1, 2, . . . , d, we have
I∂if(x+tei)-∂if(x)I ≤LiItI	(11)
for any x ∈ Rd and any t ∈ R. We further denote Lmax := maxi Li and define condition numbers
as follows:
K = L∣μ ≥ 1,	Ki = Li/μ ≥ 1 , KmaX = max Ki .	(12)
4
Under review as a conference paper at ICLR 2021
As shown in (Wright, 2015), we have
Li ≤ Lmax≤L≤dLm
ax, κi ≤ κmax ≤ κ ≤ dκmax .
(13)
These assumptions together imply that the spectrum of the Hessian is bounded above and below for
all x, specifically, μld W V2f (x) W LId and [V2f (x)]n ≤ Li ≤ LmaX for all X ∈ Rd.
Both upper and lower bounds of L in term of LmaX in (13) are tight. If V2f is a diagonal matrix,
then LmaX = L, both being the biggest eigenvalue of V2f. Thus, κmaX = κ in this case. This is the
case in which all coordinates are independent of each other, for example f = Pi λixi2. On the other
hand, if V2f = e ∙ e> where e ∈ Rd satisfies ei = 1 for all i, then L = dLmax and K = dκmaχ. This
is a situation in which f is highly skewed, that is, f = (Pi xi)2/2.
The next assumption concerns higher regularity for f .
Assumption 3.2. The function f is three times differentiable and V2f is H-Lipschitz, that is
kV2 f(x) - V2f(x0)k2 ≤ H|x - x0|, for all x, x0 ∈ Rd.	(14)
When this assumption holds, we further define Hi to satisfy
Idiif(X + tei) — ∂iif(x)∣ ≤ Hi|t|,	(15)
for any i = 1, 2, . . . , d, all x ∈ Rd, and all t ∈ R, where ∂iif is [V2f(x)]ii, the (i, i) diagonal entry
of the Hessian matrix V2f.
We summarize existing results for the classical LMC in the following theorem.
Theorem 3.1 ((Durmus et al., 2019, Theorem 9), (Dalalyan and Karagulyan, 2019, Theorem 5)). Let
qm be the probability distribution of the m-th iteration of LMC (1), andp be the target distribution.
Using the notation Wm := W (qm, p), we have the following:
•	Under Assumption 3.1, let h ≤ 1/L, we have
Wm ≤ exp(-μhm∕2) Wo + 2(κhd)1/2 ;	(16)
•	Under Assumptions 3.1 and 3.2, let h < 2∕(μ + L), we have
Wm ≤ exp (-μhm) Wo + 旦B + 3K3/2M1/2hd1/2 .	(17)
2μ
This theorem yields stopping criteria for the number of iterations M to achieve a user-defined accu-
racy of . When the gradient of f is Lipschitz, to achieve -accuracy, we can require both terms on
the right hand side of (16) to be smaller than ∕2, which occurs when
h=*∕dκ), M=θ(μhlog(W0)) = θ(μ⅛log(W0)),	(18)
leading to a cost of tO(d2κ∕(μe2)) evaluations of gradient components (when We assume that each
full gradient can be obtained at the cost of d individual components of the gradient). When both the
gradient and the Hessian are Lipschitz, to achieve -accuracy, we require all three terms on the right
hand side of (17) to be smaller than ∕3. Assuming d 1 and all other constants are O(1), we thus
obtain
h = Θ(eμ∕(dH + d1/2L3/2)),
M=Θ
(dH + d1/2L3/2 ɪɑg ( Wo ))
(19)
< ∙ <	∙ i i	. /'pζ∕τ9ττ-∕Z 9 ∖∖ ι . ∙	i' ι∙ .	. T T	λ rʌ / 7-1 ∖ ι .
which yields a cost of O(d2H∕(μ2e)) evaluations of gradient components. Here A = Θ(B) denotes
cB ≤ A ≤ CB for some absolute constant c and C.
4 Main results
We discuss the main results from two perspectives. In Section 4.1 we examine the convergence of
the underlying SDE (7), laying the foundation for the convergence in the discrete setting. We then
build upon this result and show the convergence of the RC-LMC algorithm in Section 4.2 and 4.3
under two different assumptions. We show in Section 4.4 that when both Assumption 3.1 and 3.2
are satisfied, our bound is tight with respect to d and .
5
Under review as a conference paper at ICLR 2021
4.1	Convergence of the SDE (7)
To study the convergence of (7), we first let Xm = X(Tm) and denote the probability filtration
by Fm = {x0, rn≤m, Bs≤τm }. Then {Xm}∞=° is a Markov chain and the following proposition
shows its geometric ergodicity.
Proposition 4.1. Let Xm = X(Tm) solve ⑺.If f satisfies Assumption 3.1 and h ≤ 4∕m"φ2L4,
then p(x) is the stationary probability density of the Markov chain {Xm}m∞=0.
See proof in Appendix A. Under some mild conditions, we can further prove that the solution to
the SDE converges to the target distribution exponentially (Proposition A.1). Since xm, the samples
generated by the algorithm can be viewed as discrete version ofXm, the algorithm then is expected
to converge up to a discretization error as well. This is indeed shown in the upcoming two subsec-
tions, where we document the non-asymptotic convergence rate, and calculate the complexity of the
algorithm.
4.2	Convergence of RC-LMC. Case 1: Lipschitz gradient
Under Assumption 3.1, we have the following result. The proof can be found in Appendix B.
Theorem 4.1. Assume f satisfies Assumption 3.1, and h = h∕φi with h ≤ μ 个嗖".Let qm
be the probability distribution of xm computed in (5), let p be the target distribution, and denote
Wm := W (qm, p). Then we have
Wm
≤ exp
W0 +
(20)
We make a few comments here: (1) the requirement on h is rather weak. When both μ and L are
moderate (both O(1) constants), the requirement is essentially h . 1/d. (2) The estimate (20)
consists of two terms. The first is an exponentially decaying term and the second comes from
the variance of random coordinate selection. If we assume all Lipschitz constants Li are of O(1),
this remainder term is roughly O(h1/2d). (3) The theorem suggests a stopping criterion: to have
WM ≤ , we roughly need h < 2/d2, and M = Oe(d2/2), assuming Li = O(1). In terms of and
d dependence, this puts M at the same order as (18), as required by the classical LMC.
Theorem 4.1 holds for all choices of {φi} satisfying (3). From the explicit formula (20) we can
choose {φi} to minimize the right-hand side of the bound. Nesterov (2012) proposed distributions
Φ that depend on the dimensional Lipschitz constants Li, i = 1, 2, . . . , d from (11). For α ∈ R, we
can let φi(α) a Lj, specifically,
Liα
φi(α) := P La , and φ(G)= {φ1(α), φ2(α), . . . , φd(α)} .
j Lj
(21)
Note that when α = 0, φi(0) = 1/d for all i: the uniform distribution among all coordinates. When
α > 0, the directions that with larger Lipschitz constants have higher probability to be chosen. Since
hi = h∕φi, one uses smaller stepsizes for stiffer directions. (On the other hand, when α < 0, the
directions with larger Lipschitz constants are less likely to be chosen, and the stepsizes are larger in
stiffer directions, a situation that is not favorable and should be avoided.) The following corollary
discusses various choices of α and the corresponding computational cost.
Corollary 4.1. Under the same conditions as in Theorem 4.1, with φi = φi (α) defined in (21),
the number of iterations M required to attain WM ≤ E is M = Θ (K-f2Ka log (W0)), where
Kα = Pid=1 κiα. This cost is optimized when α = 1, for which we have
M=Θ
( iκi)
μc2
2
log
(22)
See proof in Appendix B. We note that the initial error W0 enters through a log term and is essen-
tially negligible.
6
Under review as a conference paper at ICLR 2021
Remark 4.1. We now compare the numerical cost of RC-LMC and LMC in Case 1. We separate the
discussion on uniform sampling (φi = 1/d) and the optimal sampling (φi H Li) below.
-	Optimal sampling: According to Corollary 4.1, the optimal sampling strategy is achieved when
α = 1, meaning φi H Li. In this case, we compare (22) with (18), adjusting (18) by a factor ofd to
account for the higher cost per iteration. RC-LMC has more favorable computational cost if
d2κ ≥	X κi	.
Considering κi ≤ κmax ≤ κ ≤ dκmax, as presented in (13), this is guaranteed if κ ≥ κ2max. In the
regime when K 〜 dκmaχ this holds so long as d > KmaX, meaning the dimension of the problem is
high. And in the regime when KmaX 〜K, RC-LMC still outperforms when Ki decreases fast. One
example is to set f(x) = dx12 + Pid=2 xi2 with d 1.
-	Uniform sampling: Uniform sampling means φi = 1/d for all i, with α = 0 in Corollary 4.1.
This leads to a cost of Θ (p2i log (WW0)). Comparing with (18) adjusted by a factor of d,we see
that RC-LMC still has a more favorable computational cost if
d2 K ≥ X Ki2 .
i
As in the optimal case, this happens when f is highly skewed.
Our proof of Theorem 4.1 follows from a coupling approach similar to that used by Dalalyan and
Karagulyan (2019) for LMC. We emphasize that for the coordinate algorithm, we need to overcome
the additional difficulty that the process of each coordinate is not contracting on the SDE (7) level.
This is a different situation from the classical LMC (Dalalyan and Karagulyan, 2019) whose corre-
sponding SDE (2) already provides the contraction property and thus only the discretization error
needs to be considered. Despite this, the algorithm RC-LMC still enjoys the contraction property
that ensures that the distance between two different trajectories following the algorithm contract.
However, this contraction property is not component-wise, so we need to choose Young’s constant
wisely and take summation of every coordinate. The summation will also produce some extra terms,
which we need to bound. Dalalyan and Karagulyan (2019) obtains an estimate for the cost of the
classical LMC of O(d2K2∕(μe2)). Compared With this estimate, our estimate for the cost of RC-
LMC is always cheaper (since K2 ≥ K2maX). The improved estimate of the cost of LMC (18) was
obtained by Durmus et al. (2019) using a quite different approach based on optimal transportation.
It is not clear Whether their technique can be adapted to the coordinate setting to obtain an improved
estimate.
4.3 Convergence of RC-LMC. Case 2: Lipschitz Hessian
We noW assume that Assumption 3.1 and 3.2 hold, that is, both the gradient and the Hessian off are
Lipschitz continuous. In this setting, We obtain the folloWing improved convergence estimate. The
proof can be found in Appendix C.
Theorem 4.2. Assume f satisfies Assumptions 3.1 and 3.2 and let hi = h∕φi, with h ≤ μ 个；产}.
Denoting by qm(x) the probability density function of xm computed from (5) and by p the target
distribution, and letting Wm := W(qm, p), we have:
μh	( μhm∖ W	3h	(L + H2)
Wm ≤ exp 卜—jWo+7 t∑ rɪ.
We see again tWo terms in the bound, an exponentially decaying term and a variance term. Assuming
all Lipschitz constants are O(1), the variance term is of O(hd3/2). By comparing With Theorem 4.1,
we see that E error can be achieved with the looser stepsize requirement h .	.
By choosing {φi} to optimize the bound in Theorem 4.2, We obtain the folloWing corollary.
7
Under review as a conference paper at ICLR 2021
Corollary 4.2. Under the same conditions as in Theorem 4.2, the optimal choice of {φi} is to set:
(L + H2)1/3
i	Pd=I (L3 + H2)1/3.
For this choice, the number of iterations M required to guarantee WM ≤ satisfies
M = Θ^(Pd=ι(L3 + Hn1/3^^^(L3 + H^1/ log (W)1	(24)
If μ, Ki and Hi are all constants of O(1), then the total cost is te(d312∕e) regardless of the choice
of {φi}.
Remark 4.2. We now compare RC-LMC with LMC in Case 2 using Theorem 4.2 and Corollary 4.2.
We still separate the discussion on optimal sampling and uniform sampling strategy.
-	Optimal sampling: This is to set φi as stated in Corollary 4.2. Comparing the cost shown in (24)
and the cost of LMC ( (19) adjusted by a factor ofdto account for the higher cost per iteration), we
see that RC-LMC always has a more favorable computational cost since
d/H + d3//L3// ≥ d312(L3 + H/)11/.
(Here we relaxed (24) using Li ≤ L, Hi ≤ H.)
-	Uniform sampling: This is to set φi = 1/d in (23). Then the total cost of RC-LMC is
according to Corollary4.2. Comparing with (19) adjusted by afactorofdas the cost for LMC, and
use the fact that Li ≤ L, Hi ≤ H, it is clear that RC-LMC is always cheaper, similar to the optimal
case.
Suppose LandH are all constants of O(1), then the cost of RC-LMC is roughly Oe(d31//), while the
classical LMC requires O(d//), according to Dalalyan and Riou-Durand (2018). This represents
a savings factor ofd11/, regardless of the structure off.
4.4 Tightness of the complexity bound
When both the gradient and the Hessian are Lipschitz, we claim that estimate Oe(d31//) obtained
in Corollary 4.2 is tight. An example is presented in the following proposition.
Proposition 4.2. Let φi = 1/d for all i, and set the initial distribution and the target distribution to
be:
qo(x) = (4∏pι/ eχp(Tx - e|//4), P(X) = (2∏p// eχp(Tx|//2),	(25)
where e ∈ Rd satisfies ei = 1 for all i. Let qm be the probability distribution of xm generated by
Algorithm 1, and denote Wm := W(qm,p). Then we have
一	,一 .、√d	d31/h	-
Wm ≥ exp (-2mh) -- +———, m ≥ 1.	(26)
36
In particular, to have WM ≤ , one needs at least M = Oe(d31//).
See proof in Appendix D.
8
Under review as a conference paper at ICLR 2021
5 Numerical results
We provide some numerical results in this section. Since it is extremely challenging to estimate
the Wasserstein distance between two distributions in high dimensions, we demonstrate instead the
convergence of estimated expectation for a given observable. Denoting by {x(i),M }iN=1 the list of
N samples, with each of them computed through Algorithm 1 independently with M iterations, we
define the error as follows:
ErrorM,N
1N
N ∑Ψ(x(i),M) - EpX (Ψ)
(27)
2
where ψ is a matrix function and Ep (ψ) is the expectation of ψ under the target distribution p. As
h → 0 and Mh → ∞, We have WM → 0, and χ(i),M can be regarded as approximately sampled
from p. According to the central limit theorem, we have limh→o,Mh→∞ ErrorM,n = O(1/√N).
In this example, we set the target and initial distributions to be Gaussian p(χ) 8 P1(x)p2(x) and
qo(x) H pι(x - e)p2(x) with
Pι(x) = exp (-1X (T + (d∕10)I)> (T + (d∕10)I) x>) ,	p2 = exp (- 1 X ∣x∕2),
where x = (x1, x2, . . . , x10)>, e = (1, 1, . . . , 1)> ∈ R10, I is the identity matrix and T is a random
matrix with each entry i.i.d. drawn from N(0, 1). We run the simulation with N = 105, and we
compute ErrorM with ψ(x) = xx>. This measures the spectral norm of the covariance matrix of the
first 10 entries.
The results are shown in Figure 1. We run RC-LMC with time stepsize h = 10-5 and α = 1,
following (21). It is unclear what stepsize h to choose for LMC to yield a fair comparison. Bearing
in mind that d = 100 in this example, so that the per-iteration cost of LMC is 100 times of that
of RC-LMC, we try first h = 10-3. It is clear that RC-LMC, presented by the purple dashed line,
achieves lower error than LMC at the same cost, before achieving the error plateau. Next, we try
smaller choices of h in LMC. The choices h = .0008 and h = .0005 yield slower decay rates (see
the red (star) and yellow (circle) lines, respectively), but lower error plateaus as well, meaning that
the saturation error is smaller. However, computation required to reach these plateaus is longer, and
the plateaus are still higher than for RC-LMC.
Figure 1: The decay of error with respect to the cost (number of ∂f calculations).
9
Under review as a conference paper at ICLR 2021
References
Andrieu, C., Freitas, N., Doucet, A., and Jordan, M. (2003). An introduction to MCMC for Machine
Learning. Machine Learning, 50:5-43.
Baydin, A. G., Pearlmutter, B. A., Radul, A. A., and Siskind, J. M. (2017). Automatic differentiation
in machine learning: A survey. J. Mach. Learn. Res., 18(1):5595-5637.
Cao, Y., Lu, J., and Wang, L. (2019). On explicit L2-convergence rate estimate for underdamped
langevin dynamics. arXiv preprint arXiv:1908.04746.
Casella, G. and George, E. I. (1992). Explaining the gibbs sampler. The American Statistician,
46(3):167-174.
Cheng, X., Chatterji, N., Bartlett, P., and Jordan, M. (2018). Underdamped Langevin MCMC: A
non-asymptotic analysis. In Proceedings of the 31st Conference On Learning Theory, volume 75,
pages 300-323.
Dalalyan, A. (2017). Theoretical guarantees for approximate sampling from smooth and log-concave
densities. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 79(3):651-
676.
Dalalyan, A. and Karagulyan, A. (2019). User-friendly guarantees for the Langevin Monte Carlo
with inaccurate gradient. Stochastic Processes and their Applications, 129(12):5278 - 5311.
Dalalyan, A. S. and Riou-Durand, L. (2018). On sampling from a log-concave density using kinetic
langevin diffusions. arXiv, abs/1807.09382.
Del Moral, P., Doucet, A., and Jasra, A. (2006). Sequential monte carlo samplers. Journal of the
Royal Statistical Society: Series B (Statistical Methodology), 68(3):411-436.
Duane, S., Kennedy, A., Pendleton, B. J., and Roweth, D. (1987). Hybrid monte carlo. Physics
Letters B, 195(2):216 - 222.
Durmus, A., Majewski, S., and Miasojedow, B. (2019). Analysis of langevin monte carlo via convex
optimization. Journal of Machine Learning Research, 20:73:1-73:46.
Durmus, A. and Moulines, E. (2017). Non-asymptotic convergence analysis for the Unadjusted
Langevin Algorithm. Ann. Appl. Probab., 27(3):1551-1587.
Eberle, A., Guillin, A., and Zimmer, R. (2019). Couplings and quantitative contraction rates for
Langevin dynamics. Annals of Probability, 47(4):1982-2010.
Evensen, G. (2009). Data Assimilation: The Ensemble Kalman Filter. Springer-Verlag Berlin
Heidelberg.
Fabian, P. (1981). Atmospheric sampling. Advances in Space Research, 1(11):17 - 27.
Geman, S. and Geman, D. (1984). Stochastic relaxation, gibbs distributions, and the bayesian
restoration of images. IEEE Trans. Pattern Anal. Mach. Intell., 6:721-741.
Geweke, J. (1989). Bayesian inference in econometric models using Monte Carlo integration.
Econometrica, 57(6):1317-1339.
Hastings, W. (1970). Monte Carlo sampling methods using Markov chains and their applications.
Biometrika, 57(1):97-109.
Iglesias, M., Law, K., and Stuart, A. (2013). Ensemble Kalman methods for inverse problems.
Inverse Problems, 29(4):045001.
Li, R., Pei, S., Chen, B., Song, Y., Zhang, T., Yang, W., and Shaman, J. (2020). Substantial undoc-
umented infection facilitates the rapid dissemination of novel coronavirus (sars-cov-2). Science,
368(6490):489-493.
10
Under review as a conference paper at ICLR 2021
Markowich, P. and Villani, C. (1999). On the trend to equilibrium for the Fokker-Planck equa-
tion: An interplay between physics and functional analysis. In Physics and Functional Analysis,
Matematica Contemporanea (SBM) 19, pages 1-29.
Mattingly, J., Stuart, A., and Higham, D. (2002). Ergodicity for sdes and approximations: locally lip-
schitz vector fields and degenerate noise. Stochastic Processes and their Applications, 101(2):185
- 232.
Metropolis, N., Rosenbluth, A., Rosenbluth, M., Teller, A., and Teller, E. (1953). Equation of state
calculations by fast computing machines. The Journal of Chemical Physics, 21(6):1087-1092.
Nagarajan, N., Honarpour, M., and Sampath, K. (2007). Reservoir-fluid sampling and characteriza-
tion — key to efficient reservoir management. Journal of Petroleum Technology, 59.
Neal, R. M. (1993). Probabilistic inference using Markov Chain Monte Carlo methods. Technical
Report CRG-TR-93-1. Dept. of Computer Science, University of Toronto.
Neal, R. M. (2001). Annealed importance sampling. Statistics and Computing, 11:125-139.
Nesterov, Y. (2012). Efficiency of coordinate descent methods on huge-scale optimization problems.
SIAM Journal on Optimization, 22(2):341-362.
Parisi, G. (1981). Correlation functions and computer simulations. Nuclear Physics B, 180(3):378-
384.
Reich, S. (2011). A dynamical systems framework for intermittent data assimilation. BIT Numerical
Mathematics, 51(1):235-249.
Roberts, G. and Rosenthal, J. (2004). General state space Markov chains and MCMC algorithms.
Probability Surveys, 1.
Roberts, G. and Tweedie, R. (1996). Exponential convergence of Langevin distributions and their
discrete approximations. Bernoulli, 2(4):341-363.
Rossky, P. J., Doll, J. D., and Friedman, H. L. (1978). Brownian dynamics as smart monte carlo
simulation. The Journal of Chemical Physics, 69(10):4628-4633.
Russo, D., Roy, B., Kazerouni, A., Osband, I., and Wen, Z. (2018). A tutorial on Thompson sam-
pling. Foundations and Trends in Machine Learning, 11(1):1-96.
Shen, R. and Lee, Y. T. (2019). The randomized midpoint method for log-concave sampling. In
Advances in Neural Information Processing Systems, pages 2100-2111.
Tong, X. T., Morzfeld, M., and Marzouk, Y. M. (2020). MALA-within-Gibbs samplers for high-
dimensional distributions with sparse conditional structure. SIAM Journal on Scientific Comput-
ing, 42(3):A1765-A1788.
Vempala, S. (2010). Recent progress and open problems in algorithmic convex geometry. In IARCS
Annual Conference on Foundations of Software Technology and Theoretical Computer Science,
volume 8, pages 42-64.
Welling, M. and Teh, Y. W. (2011). Bayesian learning via stochastic gradient langevin dynamics.
In Proceedings of the 28th international conference on machine learning (ICML-11), pages 681-
688.
Wright, S. J. (2015). Coordinate descent algorithms. Mathematical Programming, Series B,
151(1):3-34.
Xu, P., Chen, J., Zou, D., and Gu, Q. (2018). Global convergence of langevin dynamics based
algorithms for nonconvex optimization. In Advances in Neural Information Processing Systems
31, pages 3122-3133.
11
Under review as a conference paper at ICLR 2021
A Proof of Proposition 4.1
We recall the SDE (7):
Xrm(t) = Xrm(Tm) - t	∂rm f (X(s))ds + √2	dBs,
Tm	Tm
(28)
Xi(t) =Xi(Tm),	∀i 6=rm,
where rm is randomly selected from 1,...,d. Moreover, recall that Xm+1 = X (Tm+1) is a
Markovian process. We denote its transition kernel by Ξ, meaning that
Xm+1 = Ξ(Xm, ∙).
Moreover, we denote Ξn the n-step transition kernel. Proposition 4.1 is a consequence of the
following Proposition.
Proposition A.1. Denote Πm the probability distribution of Xm and Π be the probability distribu-
tion induced by p(x), then under the conditions of Proposition 4.1, we have
•	Π is the stationary distribution of the Markov chain {Xm }m∞=0.
•	If the second moment of Π0 is finite and X0 is drawn from Π0, then there are constants
R > 0 and r > 1, independent of m, such that for any m ≥ 0 we have
dTV (Πm, Π) dx ≤ Rr-m.
(29)
Remark A.1. According to Mattingly et al. (2002), the constants R and r do not depend on m,
but their dependence on other parameters such as h, d, and L is hard to trace. This contrasts
with the results in Dalalyan and Karagulyan (2019) for the classical Langevin dynamics, which
are built upon the contraction property. The new complication comes mainly from the complicated
coordinate selection process, making the contraction property no longer available. Nor can we claim
sharpness of the theorem. In fact, unlike in Dalalyan and Karagulyan (2019); Xu et al. (2018), where
the authors directly studied LMC, we discuss here only convergence of the SDE, the continuous
version of RC-LMC. The explicit dependencies of the convergence rate here are unimportant, and
we allow the results to be loose. Non-asymptotic convergence results of the algorithms are presented
in Section 4.2 and 4.3.
To prove Proposition A.1, we need to introduce the following lemma:
Lemma A.1. Under conditions of Theorem 4.1, there are constants R1 > 0, r1 > 1, such that for
any z0 ∈ Rd
sup
A∈B(Rd)
Ξmd(z0, A) - p(x) dx
A
≤ (∣z0 - x*∣2 + 1) Rιr-m
(30)
where x* is the minimal point of f (x) and Ξ is the transition kernelfor {Xm}∞=0.
We postpone the proof of Lemma A.1 to Section A.1. Now, we are ready to prove the proposition.
Proof of Proposition A.1 (Proposition 4.1).	To prove the first bullet point of Proposition A.1, we
assume the distribution of Xm is Π and we need to prove:
For any choice of rm, the conditional distribution of Xm+1 is also Π.
Without loss of generality, we consider rm = 1. Under this condition, we have the following.
•	The distribution of X2≤j≤d(t) between [Tm, Tm+1] is preserved.
12
Under review as a conference paper at ICLR 2021
•	For fixed z2, z3, . . . , zd, the stationary density of SDE
dz = -∂1f(z,z2 ,z3,...,zd)dt + √2dBs,	(31)
is f exp(-fʃz,z2,…,Zd) . This implies that the conditional distribution of Xι(t) with fixed
exp(-f(z,z2,...,zd) dz	1
X2≤j≤d(t) is also preserved.
Combining these two points, we find that under condition rm = 1, the conditional distribution of
Xm+1 is Π, which further proves that Π is the stationary distribution and Proposition 4.1 holds.
To show (29), we take the expectation of (30) using Π0, then we can obtain that for any A ∈ BRd
hat
Inmd(A)- ∏(A)∣ =) E∏o (Ξmd(∙,A)) - E∏o (∕p(x)
(II)
≤ EΠ0
Ξmd(z, A) - p(x) dx
A
(III)
≤ R∖r-m L J∣z-z"2
+ 1 q0(z) dz < C0r1-m ,
where We use Xmd = Ξmd(X0, ∙) and ∏(A) = JAP(X) dx in (I), Π0 is a non-negative measure in
(II) and (30) in (III). Since this is true for all A ∈ BRd, we have
dTV(Πmd,Π) = sup ∣Πmd(A) -Πm(A)∣ < C0r1-m.	(32)
A∈BRd
By using (28) with Ito's formula, we have
dE|Xrm(t)|2 = -2E (∂rm f(Xrm (t))Xrm (t))十2 ≤ 2十 E∣∂rm f(Xrm (t))|2 + E|Xrm (t)|2
≤ 2 + Lrm E∣Xrm (t) — X；m |2 + E|X『m (t)|2 ≤ Cl,rm E|X『m (t)|2 +。2,产,
where Cι,rm and C2,rm are constants that depend only on x* and Lrm. From Gronwall's inequality,
we obtain
E (∣Xm+1∣2∣rm = i) ≤ exp©,/，)[E(∣Xm∣2) +。2,也],for all i = 1,2,...,d.
Then, ifE|Xm|2 < ∞, we have for any i = 1, 2, . . . , d that
E (∣Xm+1∣2) = 1E (∣Xm+1∣2∣rm = i) +(1 - ŋ E (∣Xm+1∣2∣rm = i)
dd
≤ d eχp(Cl,ihi) [E(|Xm|2) + C2,ihi] +
E(|Xim|2) < ∞,
which implies E|X m+1 |2 < ∞. Therefore, if Π0 has finite second moment, then Πi all have finite
second moments for i = 1, . . . , d - 1. Suppose the initial data is drawn from Πi for i < d, then
taking the expectation of (30) and using (32), we obtain
dTV (Πmd+i, Π) ≤ Cir1-m,
where Ci is a constant. This bound holds true for all 0 ≤ i ≤ d - 1, we set R = (maxi Ci)r1 and
r = r11/d to obtain (29).
□
A.1 Proof of Lemma A.1
Before we prove the Lemma, we first recall a result from (Mattingly et al., 2002) for the convergence
of Markov chain using Lyapunov condition together with minorization condition.
Theorem A.1. [(Mattingly et al., 2002, Theorem 2.5)] Let {X n}n∞=0 denote the Markov chain on
Rd with transition kernel Ξ and filtration Fn. Let {X n}n∞=0 satisfy the following two conditions:
13
Under review as a conference paper at ICLR 2021
Lyapunov condition: There is a function L : Rd → [1, ∞), with limx→∞ L(x) = ∞, and real
numbers α ∈ (0, 1), and β ∈ [0, ∞) such that
E (L(Xn+1 )∣Fn) ≤ αL(Xn) + β .
Minorization condition: For L from the Lyqpunov condition, define the set C ⊂ Rd as follows:
C = ∫x ∈ Rd | L(x) ≤ 2β^-∖ ,	(33)
γ-α
for some Y ∈ (ɑ1/2,1). Then there exists an η > 0 and a probability measure M Supported on C
(that is, M(C) = 1), such that
Ξ(x, A) ≥ ηM(A), ∀A ∈ B(Rd), x ∈ C.
Under these conditions, the Markov chain {Xn }n∞=0 has a unique invariant measure π. Further-
more, there are constants r ∈ (0, 1) and R ∈ (0, ∞) such that, for any z0 ∈ Rd, we have
sup ∣∣Ξn(z0, A) - π(A)∣∣ ≤ L(z0)Rr-n .	(34)
A∈B(Rd)
To use this result to prove Lemma A.1, we will consider the d-step chain of {Xn} and verify the
two conditions, as in the following two lemmas for the Lyapunov function and the minorization over
a small set, respectively.
Lemma A.2. Assume f satisfies Assumption 3.1 and
h <	μ min{ Φi}
-4 + 8L2 + 32L4 ,
(35)
where L is the Lipschitz constant defined in (9). Let the Lyapunovfunction be L(X) = |x 一 x*∣2 +1,
then we have:
E (L(Xm+1)∣Fm) ≤ αιL(Xm) + βι	(36)
with
αι = 1 一 μh, βι = (24 + 120L2 + μ)h.
Lemma A.3. Under conditions ofLemma A.2, with L(X) = |x — x*∣2 +1, let Ξ denote the transition
kernel. Define the set C ⊂ Rd as in (33) ,for some Y ∈ (a1/2,1). Then there exists an η > 0 and a
probability measure M with M(C) = 1, such that
Ξd(X,A) ≥ ηM(A), ∀A ∈ B(Rd),X ∈ C.	(37)
Lemma A.1 follows easily from these results.
Proof of Lemma A.1. It suffices to show d-step chain Xmd m∞=0 satisfies the conditions in Theo-
rem A.1 with L(X) = |x — x*∣2 + 1, α = αd and β = dβι, and π is induced by p. We apply (36)
from Lemma A.2 iteratively, d times, to obtain
E (L (X(m+1)d) ∣Fmd) ≤ αdL (Xmd) + dβι,
which implies that Xmd m∞=0 satisfies Lyapunov condition in Theorem A.1 with α = α1d. More-
over, Lemma A.3 directly implies that the d-step transition kernel satisfies the minorization condi-
tion. Therefore, by Theorem A.1, we have
sup ∣∣Ξmd(z0,A) 一 π(A)∣∣ ≤ L(z0)Rr-m,
A∈B(Rd)
which concludes the proof of the lemma when We substitute ∏(A) = JA P(X) dx.	□
14
Under review as a conference paper at ICLR 2021
ProofofLemma A.2. We assume without loss of generality that x* = 0 ∈ Rd (so that L(X)
∖x∖2 + 1) and drop the filtration Fm in the formula for simplicity of notation. Then
d
E (L (Xm+1)) = X φiE (L (Xm+1) ∖rm = i).
i=1
Since
L (Xm+1) = ∖Xm+1∖2 + 1 = ∖Xm + (Xm+1 - Xm)∖2 + 1
=L (Xm) + 2Xm(Xm+1 - Xm) + ∖Xm+1 - Xm∖2,
we have
E (L (Xm+1) ∖ rm = i) =L (Xm) + 2E [Xm (Xm+1 - Xm) ∖ rm = i∖
+ E [(Xm+1 - Xm)2 ∖ rm = i].
(38)
(39)
To deal with second term and third term in (39), we first note that, under condition rm = i:
Xm+1 - Xm
八i	八i
T m+hi
∂if (X (s))ds + √2
产 m+hi
/	dBs.
JT m
(40)
-
JT m
This means
2E [Xm (Xm+1 - Xm) ∖ rm = i
- 2E
Xim
j
JT m
T m + hi
∂if (X (s))ds
rm = i
(41)
/
JT m
-2hiXm∂if (Xm) - 2E Xm
T m+hi
(∂if (X(S))- ∂if (Xm))ds
rm
i
We further bound the second term of (41):
E
■	fT m+hi
Xim
JT m
(∂if(X(S))- ∂if(Xm)) ds rm
≤ hiE Xm	sup	∖∂if(X(t)) - ∂if (Xm)∖ ∖ rm = i
_	∖Tm≤t≤Tm+hi	∖ ∖	.
≤ 2h2∖Xm∖2 + 2e( sup	∖∂if (X(t)) - ∂if (Xm)∖2 rm = i
∖T m≤t≤T m + hi
(42)
≤ 2h2∖Xm∖2 + 2L2E	sup	∖Xi(t) - Xm∖2 rm = i
∖T m≤t≤T m + hi	.
(III)
≤ 2h2∖Xim∖2 + 16h2L2∖∂if(Xm)∖2 + 60hiL2
(IV)
≤ (2 + 16L4)h2∖Xim∖2 + 60hiL2 ,
where we used Young,s inequality in (I), the Lipschitz condition in (II), Lemma A.4 below (specif-
ically, inequality (45)) in (III), and the Lipschitz condition again in (IV). This, when substituted
into (41), gives
2E [Xm (Xm+1 - Xm) ∖ rm = i∖ ≤ -2hiXm∂if (Xm) + (4 + 32L4)h2∖Xm∖2 + 120h∕2 .
15
Under review as a conference paper at ICLR 2021
To bound the third term in (39), again for the case rm = i, we use (40) again for:
E
产m+hi	产m+hi	\ 2
∂	∂if(X(s))ds - √2	dBs	rm = i
Tm	Tm
2
≤) 2h2E( sup	∣∂if(X(t))∣2
Tm ≤t≤T m +hi
rm = i + 4E
Tm +hi
dBs
Tm
rm = i
(43)
2h2E	SUp	|&f(X (t))∣2
Tm ≤t≤T m +hi
rm = i + 4hi
≤ 8h2∣∂if(Xm)|2 + 88h3L2 +4hi
≤ 8Li2hi2|Xim|2 +24hi,
where we used Young’s inequality in (I), Lemma A.4 below (specifically, inequality (44)) in (II),
and Lipschitz continuity in (III), together with 88hi2Li2 ≤ 20 by (35).
Finally, we have
E (L (X m+1) I rm = i) ≤ L (X m)-2hiXim∂if (X m)+(4+8L2+32L4)h2∣Xim∣2+(24+120L2)hi.
By summing according to (38), and using (4) and Li ≤ L for all i = 1, 2, . . . , d, we obtain
d
E (L (Xm+1)) = X φiE (L (Xm+1)卜m = i)
i=1
≤L (Xm) - 2h hXm, Vf (Xm)i +
4+8L2+32L4 h2
mg}	(L (X m- 1) + (24+ 120L2)h.
Finally, using〈Xm, Vf (Xm) ≥ μ(L (Xm) 一 1) (from (10) with x0 = Xm and X = x* = 0) and
(35), We obtain (36).	□
00
Proof of Lemma A.3. To prove (37), we construct a new Markov process Xm. Defining X0 = x0,
+1
we obtain Xm+1 from Xm by running the following process:
n
Ten = Xhi, Te0 = 0, Z(0) = Xem .
i=1
Then for Tn-1 ≤ t ≤ Tn and n ≤ d, let
J Zn(t) = Zn (TnT) - JT…3f (Z(S)) ds + √2 JT…dBs ,
[Zi(t) = Zi (TnT) , i = n,
and set Xem+1 = Z Ted . Denote the transition kernel by Ξcyc (corresponding to one round of a
cyclic version of the coordinate algorithm). We then have the following properties:
• For any x ∈ C and A ∈ B(Rd), we have
Ξd(x, A) ≥ Πid=1φiΞcyc(x, A) > 0 .
cyc
possesses a positive jointly continuous density.
According to (Mattingly et al., 2002, Lemma 2.3), since Ξcyc has a positive jointly continuous den-
sity, there exists an η0 > 0 and a probability measure M with M(C) = 1, such that
Ξcyc (x, A) > η0M(A),	∀A ∈B (Rd) ,x ∈ C,
16
Under review as a conference paper at ICLR 2021
which implies
Ξd(x, A) ≥ ∏d=1φiΞcyc(x, A) > ∏d=1φiη'M(A), VA ∈ B (Rd) ,x ∈ C.
This proves (37) by setting η = ∏d=1φiη0.
□
In the proof of Lemma A.2, we used several estimates in inequalities (42) and (43). We prove these
estimates in the following lemma.
Lemma A.4. Suppose that the assumptions ofLemma A.2 hold, and let Xi evolve according to (40).
Then we have the following bounds:
E sup	∣∂if (X(t))∣2 ≤ 4∣∂if(Xm)∣2 +44hiL2 ,
∖T m≤t≤T m + hi	)
(44)
E sup	∣Xi(t) - Xim∣2 ≤ 8h2∣∂if (Xm)∣2 +30hi.
∖T m≤t≤T m+hi	)
(45)
Proof. To obtain (44), we have
E sup	Idif(X (t))∣2
∖T m≤t≤T m + hi
≤E
sup	(∣∂if (Xm)∣ + Li ∣Xi(t) - χm∣)2
T m≤t≤T m + hi
≤2∣∂if (Xm)∣2 + 2L2E	sup	∣Xi(t) - Xm∣2
∖T m≤t≤T m + hi
To bound the second term, we use (40) again:
E sup	∣Xi(t) - Xim∣2
Tm m≤t≤T m+hi	)
=E ( sup I [t ∂if (X(s))ds-√2 [t dBs 1
Tm m≤t≤T m+hi 1 JT m	JT m 1
≤2hiE(	sup	∣∂if(X(t))∣] +4E ( sup ∖ /' dBs
Tmm≤t≤Tm+hi	)	Tmm≤t≤Tm+hi ∖ JTm
2
(46)
(47)
≤2h2E	sup	∣∂if (X(t))∣2 +16hi,
∖T m≤t≤T m+hi	)
where we use Young,s inequality and
E ( sup ∖(t dBs∣ ! ≤ 4E (| IT +hi dBs I
∖T m ≤t≤T m+hi I JT m
T m
by Doob’s maximal inequality. By substituting (47) into (46), we obtain
E sup	Idif(X (t))∣2
∖T m≤t≤T m+hi
4 hi
≤4h2L2E	sup	∣∂if(X(t))∣2 + 2∣∂if(Xm)∣2 + 32hiL2 .
∖T m≤t≤T m+hi	)
Using hi Li ≤ ɪ, we move the first term on the right to the left to obtain
3E( sup	∣∂if (X(t))∣2) ≤ 2∣∂if (Xm)∣2 + 32hiL2,
4	∖Tm ≤t≤T m+hi	)
leading to (44). Then we obtain (45) by plugging this in (47) and using the fact that 88h：L2 < 14hi
by (35).
□
17
Under review as a conference paper at ICLR 2021
B Proof of Theorem 4.1
The proof of this theorem requires us to design a reference solution to explicitly bound W (qm, p).
0	20
Let x be a random vector drawn from target distribution induced by p, so that W2 (q0 , p) = E|x -
x0∣2. We then require X to solve the following SDE: for t ∈ (Tm, Tm+1], with Tm defined in (6):
ʃ Xrm (t) = Xrm (Tm) — Z ∂r∙m f(X(s))ds + √2 Z dBs ,
Tm	Tm
[Xi(t) = Xi(Tm), i = rm ∙
If we use the same Brownian motion as in (5), we have
Tm+1
(48)
Xm+1 = Xm
∂rm f(X(s)) ds + ʌ/2hrmξm
erm ,
(49)
where e『m is the unit vector in rm direction. Since the rm-th marginal distribution of X(t) is
preserved in each time step according to (48), the whole distribution of X(t) is preserved to be P
for all t. Therefore, by the definition Wm = W(qm, p), we have
Wm ≤ E∣∆m∣2 = E∣Xm — XmI2,
where
∆m := Xm — Xm .	(50)
This means bounding Wm amounts to evaluating E∣∆m∣2. Under Assumption 3.1, We have the
following result.
Proposition B.1. Suppose the assumptions of Theorem 4.1 are satisfied and let {Xm}, {Xm}, and
{∆m } be defined in (5), (48), and (50), respectively. Then, we have
E∣∆m+1∣2
E”2 邛 X f ∙
(51)
The proof of this result appears in Appendix B.1. The proof for Theorem 4.1 is now immediate.
Proof of Theorem 4.1. By iterating (51), we obtain
E∣∆m∣2 ≤(1 — hμ)mEI△叩 + 20hXL,
and since hμ∕2 ∈ (0,1), We have
E∣∆m∣2 ≤ exp (—粤)EI△叩 + 粤 X L ∙	(52)
∖	2	)	μ i=1 φi
By construction, We have W2(q0,p) = E∣∆0∣2 and W2(qm,,p) ≤ E∣∆m∣2. By taking the square
root of both sides and using a2 ≤ b2 + c2 ⇒ a ≤ b + c for any nonnegative a, b, and c, we arrive at
(20).	□
The proof for Corollary 4.1 is also obvious.
Proof of Corollary 4.1. To ensure that Wm ≤ , we set the two terms on the right hand side of (20)
to be smaller than ∕2, which implies that
h=O
(μ%2	]
∖100 Pd=ι φ⅛ )
and
4
m ≥ --
一μh
By using the definition of φi(α) according to (21), we obtain
X La) = μ2K2-αKα ,
(53)
18
Under review as a conference paper at ICLR 2021
which implies that m = O ((K2-αKα) /(μe2)). Furthermore, α = 1 gives the optimal cost,
because:
K2-aKa
k2 ,
due to Holder,s inequality.
B.1 Proof of Proposition B.1
We prove the Proposition by means of the following lemma.
Lemma B.1. Under the conditions ofProposition B.1, for m ≥ 0 and i = 1,2,..., d,we have
E∣∆m+1∣2 ≤ (1 + hμ + 字)E∣∆m∣2 - 2hE [∆m Gf (Xm)- ∂if (xm))]
+ 3h2EIdif(Xm)- df (Xm)∣2 + (* + *).
(54)
Proof. In the m-th time step, we have
P(rm = i)= φi, P(rm = i) = 1 - φi,
so that
E∣∆m+112 =	ΦiE	(∣∆m+1∣2	∣ rm =	i) + (1 -	φi) E (∣∆m+1∣2 ∣ rm	= i)
=φiE	(∣∆m+1∣2	∣rm =	i) + (1 -	φi) E ∣∆m∣2 .
We now analyze the first term on the right hand side under condition rm = i. By definition of
△m+1，we have
∆m+1 = ∆m + (Xm+1 - Xm) - (Xm+1 - Xm)
T m+hi
∆im
/
JT m
∂i f (X(s)) ds + vz2hiξm
T m+hi
∂if (Xm)ds + vz2hiξm
∆im -
T m+hi
(∂if (X(S))- ∂if(Xm))ds
∆im -
T m+hi
(∂if (X(S))- ∂if (Xm) + ∂if (Xm) - ∂if (Xm)) ds
∆m - hi (∂if (Xm) - ∂if (Xm))-
T m + hi
(∂if (X(s)) - ∂if(Xm))ds
∆ - hi (∂if (Xm) - ∂if (xm)) - Vm ,
where we have defined
(56)
j
JT m
j
JT m
V m
□
T m+hi
(∂if(X(S))- ∂if(Xm))ds.
=I
JT m
By Young,s inequality, we have
E (∣∆m+1∣2 ∣ rm = i)
=E (∣∆m+1 + Vm - Vm∣2 ∣ rm = i
≤ (1 + a) E (∣∆m+1 + Vm∣2 ∣ rm = i) + (1 + ；) E (∣Vm∣2 ∣ rm = i),
(57)
(58)
where a > 0 is a parameter to be specified later.
For the first term on the right hand side of (58), we have
E (∣∆m+1 + Vm∣2 ∣ rm = i)
=E∣∆m - hi (∂if (Xm) - ∂if (Xm)) ∣2
=E∣∆m∣2 - 2hiE [∆m (∂if (Xm) - ∂if (Xm))] + h2E ∣∂if (Xm) - ∂if (Xm) ∣2 .	(59)
19
Under review as a conference paper at ICLR 2021
Note that the second term will essentially become the second line in (54), and the third term will
become the third line in (54) (upon the proper choice of a). For very small h, this term is negligible.
For the second term on the right-hand side of (58), we recall the definition (57) and obtain
(I)	Tm+hi
E (|Vm∣2∣rm = i) ≤ hi J E (∣∂if(X(S))- ∂if(Xm)∣2∣rm = i) ds
(II)	Tm+hi	I
≤ hiL2 J E (Ix(S) - Xm∣2∣rm = i) ds
Tm+hi
hiLi2	E
Tm
/s ∂if(x(t))dt + √2(Bs - BTm)| Irm = i) ds
(III)	Tm+hi	s
≤ 2以Li	/ E (∣∂if(X(t))∣2∣rm = i) dtds
Tm	Tm
Tm+hi
+ 4h2L /	E∣ξm∣2 ds
Tm
(=) h4L2E (∣∂if(Xm)∣2)+4h3L2
=) h4L2Ep∣∂if I2 + 4h3L2 (VI) 畸L + 4崖L ,
(60)
where (II) comes from L-Lipschitz condition (11), (I) and (III) come from the use of Young’s in-
equality and Jensen's inequality when We move the ∣∙∣2 from outside to inside of the integral, and
(IV) and (V) hold true because x(t)〜P for all t. In (VI) we use EpIdif ∣2 ≤ Li using (Dalalyan
and Karagulyan, 2019, Lemma 3).
By substituting (59) and (60) into the right hand side of (58), we obtain
E (∣∆m+1∣2 ∣ rm = i)
≤ (1 + a)E∣∆m∣2 - 2hi(1 + a)E [∆m (&f (Xm) - &f (xm))]
+ h2(1 + a)E∣∂if(xm) - ∂if (xm)∣2 +( + I)(端L +4h3L2) .	(61)
By substituting (61) into (55), we have
E∣∆m+1∣2 ≤ (1 + aφi) E∣∆m∣2 - 2(1 + a)hE [∆m (&f (xm) - &f (xm))]
+ (ɪEIdif(Xm)- df(Xm)12 + (1 + a)(才 W)，(62)
where we have used hi φi = h.
Now, we need to choose a value of a > 0 appropriate to establish (54). By comparing the two
formulas, we see the need to set
aφi = hμ ⇒ a = hiμ = —≤ 1 .
φi
since h ≤ min{φi}∕μ. It follows that 1 + a ≤ 著.By substituting into (62), we obtain
E∣∆m+112 ≤ (1 + hμ) E∣∆m∣2 - 2hE [∆m (&f (Xm) - &f (xm))]
-字E [∆m (dif (Xm) - dif (xm))] + 2h2EIdif(Xm)- dif (xm)∣2
φi	φi
+(空+τ).
∖ μφi	μφi )
(63)
We conclude the lemma by using the following Cauchy-Schwartz inequality to control the third term
on the right hand side of this expression:
2h2μ	h2"2	C h2	C
-YE[∆m (dif (Xm) - dif (Xm))] ≤」E∆mI2 + -EIdif(Xm)- dif (Xm)I2.	□
φi	φi	φi
20
Under review as a conference paper at ICLR 2021
Proposition B.1 is obtained by simply summing all components in the lemma.
Proof of Proposion B.1. Noting
d
E∣∆m+112 = X E∣∆m+1∣2,
i=1
we bound the right hand side by (54) and get
E∣∆m+1∣2 ≤	1 + hμ +
h2μ2 ʌ
min{ Φi}√
E∣∆m∣2 - 2hE h∆m, Vf (Xm) - Vf (xm)i
+ EEVf(Xm)-Vf(Xm)12 +
(64)
(丝 X L3 + 吃 X L2
μ μ = φ2	μ = φi
The second and third terms on the right-hand side can be bounded in terms of E | ∆m |2:
•	By convexity, we have
E h∆m, Vf(Xm) — Vf(Xm) ≥ μE∣∆m∣2.	(65)
•	As the gradient is L-Lipschitz, we have
EVf(Xm) -Vf(Xm)∣2 ≤ L2E∣∆m∣2.	(66)
By substituting (65) and (66) into (64) and using μ ≤ L, we obtain
E∣∆m+1∣2 ≤ (l-hμ +^h2L2T)	E∣∆m∣2 +	22h3 X L3	+ 8h2 X	L!	.	(67)
k	min{φi})	∖ μ = φ2 μ =	φi)
If We take h sufficiently small, the coefficient in front of E∣∆m∣2 is strictly smaller than 1, ensuring
the decay of the error. Indeed, by setting h ≤ μ ^8；26}, we have
% ≤ h?, and 牛 ≤ & ≤ 1,
min{φi }	2	φi	8L
which leads to the iteration formula (51).	□
C	Proof of Theorem 4.2
Theorem 4.2 is based on the following proposition.
Proposition C.1. Suppose the assumptions of Theorem 4.2 and let {Xm}, {Xm}, and {∆m/} be
defined as in (5), (48), and (50), respectively. Then we have
E∣∆m+1∣2 ≤(1 - hμ) E∣∆m∣2 + 4h3 X (L3 +2H2) .	(68)
We prove this result in Appendix C.1. The proof of the theorem is now immediate.
Proof of Theorem 4.2. Use (68) iteratively, we have
E∣∆m+1∣2 ≤(1- hμ)m E∣∆0∣2 + 822 X (L +2%)
≤ exp (-μhm) E∣∆0∣2 + 8h2 X 号产.
Using W2(qo,p) = E∣∆0∣2 and W2(qm,p) ≤ E∣∆m∣2,
obtain (23).
we take the square root on both sides, we
□
21
Under review as a conference paper at ICLR 2021
The proof of Corollary 4.2 is also immediate.
Proof of Corollary 4.2. Use (23), to ensure Wm ≤ , we set two terms on the right hand side of (23)
to be smaller than /2, which implies that
f	∖
eμ
r /Pd^^(L3+H2)
∖yτi=1 φ2	)
4
m ≥ --
一μh
(69)
To find optimal choice of φi , we need to minimize
d
X
i=1
(L + H)
φ
under constraint Pid φi = 1 and φi > 0. Introducing a Lagrange multiplier λ ∈ R, define the
Lagrangian function as follows:
F(1 1 小 λ∖ — XX (L3 + H2 I λ (Xd) _ 1!
F (φ1, φ2, ... , φd, λ) =), φ2	+ λ I), φi - 1I .
By setting ∂F∕∂φi = 0 for all i, and substituting into the constraint Pd φi = 1 to find the appro-
priate value of λ, we find that the optimal (φ1, φ2 , . . . , φd) satisfies
φi
(L +H炉/	i = 12 d
Pd=I(L3+H2)1/3,	,,...,.
By substituting into (69), we obtain (24).
C.1 Proof of Proposition C.1
The strategy of the proof for this proposition is almost identical to that of the previous section. The
reference solution X is defined as in (48). We will use the following lemma:
Lemma C.1. Under the conditions of Proposition C.1, for m ≥ 0 and i = 1, 2, . . . , d, we have
E∣∆m+1∣2 ≤(1 + hμ +	E∣∆m∣2 - 2hE ∆m (&/(xm)- &f(xm))]
+ 3h2E ∣∂if (Xm) - ∂if (Xm)I2 + 4h3 (L2+ H2).
(70)
Proof. In the m-th time step, we have
P(rm = i) = φi,
P(rm 6= i) = 1-	φi ,
meaning that
E∣∆m+112 = φiE (∣∆m+1∣2 ∣rm
=φiE (∣∆m+1∣2 | rm
=i) + (1- φi) E (∣∆m+1∣2 | rm = i)
=i) + (1- φi) E ∣∆m∣2 .
(71)
To bound the first term in (55) we use the definition of ∆im+1 . Under the condition rm
have, with the same derivation as in (56):
i, we
Tm+hi
∆m+1 =∆m - hi(∂if (Xm) - ∂if(xm)) - /	(∂if (X(S))- ∂if (Xm)) ds
Tm
=∆m - hi(∂if (Xm) - ∂if (Xm)) - Vm ,
(72)
where We denoted Vm = RTTm +hi (∂if (X(s)) - ∂if (Xm)) ds.
□
22
Under review as a conference paper at ICLR 2021
However, different from (60), since f has higher regularity, we can find a tighter bound for the
integral. Denote
and
产m+hi /	s
Um =	∂if(X(S))- ∂if(xm) - √2	∂iif (x(z))
JTm ∖	JTm
ds
Tm m+hi fs
Φm = √2	∂nf (X(z))dBz ds.
JT m	JT m
Then (72) can be written as
∆m+1 =∆m - hi(∂if (Xm) - ∂if (xm)) - Φm - Um
(73)
(74)
(75)
which implies, according to Young,s inequality, that, for any a:
E (∣∆m+1 ∣2∣rm = i) = E (∣∆m+1 + Um - Um∣2∣rm = i)
≤(1 + α)E (∣∆m+1 + Um∣2 ∣ rm = i) + M + ɪ J E (∣Um∣2 ∣ rm = i
(76)
Both terms on the right-hand side of (76) are small. We now control the first term. Plug in the
definition (75), we have:
E (∣∆m+1 + Um∣2 ∣ rm = i) = E (∣∆m - hi(∂if (Xm) - ∂if(xm)) - Φm∣2 ∣ rm = i) .	(77)
Noting that
E((∆m - hi (∂if (xm) - ∂if(xm))) ∙ Φm)
j
JT m
T m + hi
E
「(∆m - hi (∂if (Xm) - ∂if(xm))) ∙ ∂iif (X(z)) dBz
JT m
ds = 0
because
s (∆im
JT m
-hi (∂if (Xm) - ∂if (Xm))) ∙ ∂iif(X(Z)) dBz
E
0 ,
according to the property of Ito,s integral, we can discard the cross terms with Φm in (77) to obtain
E (∣∆m+1 + U m∣2 ∣ rm = i) = E∣∆m∣2 - 2hiE [∆m (∂if(Xm) - ∂if (xm))]
+ M⅛∣∂if(Xm) - ∂if (xm)∣2 + E (∣Φm∣2 ∣rm = i) .	(78)
For the last term of (78), we have the following control:
E (∣Φm∣2∣rm = i) = E
2∣ /T +hi ZS ∂nf (X(z))dBz ds I ∣ rm
Tm	Tm
rm
(I)
≤ 2E
(JTs ∂iif(X(z))dBz ∣ 2 ∣ rm = i) ds
i
产 m+hi
≤ 2hi	E
Tm
T m + hi Ss	∣
=) 2hi	I E (Idiif (X(Z))∣2∣rm = i) dz ds
JT T	JTm	∖	1	J
(=) h≡Ep∣∂iif ∣2 =&L,
where we use Holder,s inequality in I and X(t)〜p for all t in III. In II, we use the following
property of Ito,s integral:
E
(∣∂iif (X(z))∣2 ∣ rm
dz .
23
Under review as a conference paper at ICLR 2021
By substituting into (78), we obtain
E (∣∆m+1 + UT2 | rm = i) ≤E∣∆m∣2 - 2hiE [A™ (∂f (Xm)- ∂if (xm))]
+ M⅛∣∂if (Xm)- ∂f(xm)∣2 + &L	(79)
To bound the second term on the right-hand side of (76), we first note that f is three times con-
tinuously differentiable, and (15) implies k∂mf k∞ ≤ Hi. Take dt on both sides of (48), under
condition rm = i, we first have
dXi(t) = -dif (X(s)) ds + √2dBs.
According to Ito's formula, we obtain
dif (X(t)) - dif(Xm)= Z diif (X(s))dXi(s) + Z dmf (X(s))ds.
JTt	JTm
Substituting (80) into (81), we have
dif (X(t)) - dif(Xm) -√2 / diif (X(s)) dBs
JTm
=Zt -diif(X(s))dif(X(s)) + diiif(X(s))ds.
JT m
By substituting into (73), we obtain
E (∣Um∣2 ∣ rm = i)
≤ hi	[T	+hi E (	∣ dif (X(s)) -	dif (Xm) -	√2	ZS	diif (X(z))dBr	|	| rm = i ) ds
Tm	Tm
(80)
(81)
(82)
T m+hi
=) hi	E
JT m
(JTS (-diif (X(z))dif (X(z)) + diiif (X(z))) dz | | rm = i) ds
(III)	C Tτ m + hi	F	I	ʌ
≤ 层	I E Qdiif(X(Z))∂if (X(Z)) + ∂iiif (x(z))∣ lrm = i) dz ds
JTm	JTm '	1	J
(IV)	C Tm m +hi 「Sf	i∖	∖
≤ 2h2 /	/ E (Idiif(X(Z))∂if(X(z))∣ ∣rm = i) dzds
JTm	JTm	'	1	J
Tm m + hi	SS	∣
+ 2h2 /	/ E (Idiiif(X(Z))∣2∣rm = i) dzds
JTm JTm '	'	j
(V)
≤ h (Li + Hi2) .	(83)
In the derivation, (II) comes from plugging in (82), and (I) and (III) come from the use of Jensen's
inequality, (V) comes from the useofLipschitz continuity in the first and the second derivative ((11)
and (15) in particular), and the fact that X(t)〜p for all t. Note also EpIdif ∣2 ≤ Li by (Dalalyan
and Karagulyan, 2019, Lemma 3).
By plugging (79) and (83) into (71) and (76), we obtain
E∣∆m+1∣2 ≤ (1 + αφi) E∣∆m∣2 - 2(1 + α)hE [Am (dif (Xm)- dif (x™))]
+ (I + a" E ∣dif (Xm) - dif (Xm)∣2 + (1+ ：2*L2 + (1 + 1) h4 & + H2),
φi	φ2	∖ a)	φ3
(84)
where we use hiφi = h. Comparing with (70), we need to set
a = hiμ = —< 1,
φi
where we use h < μ 弋；y".This leads to 1 + ɪ ≤ 粉.By substituting into (62), we obtain
E∣∆m+1∣2 ≤ 1 + hμ +
E∣∆m∣2 - 2hE [∆m (dif (Xm) - dif (Xm))]
+ 乎E ∣dif (Xm) - dif (Xm)∣2 + 2h32L2 + 2h3(L3 + Hn
φi	φ2
φ2μ
24
Under review as a conference paper at ICLR 2021
Noting Li∕μ> 1, we conclude the lemma.
□
The proof of Proposition C.1 is obtained by summing UP all components and applying Lemma C.1.
Proofof Proposition C.1. Noting that
d
E∣∆m+112 = X E∣∆m+1∣2,
i=1
we substitute using (70) to obtain
E∣∆m+112 ≤ 1 + hμ +
h2μ2 )
min{φi} J
E∣∆m∣2 - 2hE h∆m, V/(Xm) - Nf(Xm))
+ m⅛r EIVf(Xm)-Vf(Xm)∣2 + 4μ3 X
(L3 + H2)
φ2
(85)
The second and third terms in the right-hand side of this bound can be controlled by E∣∆m∣2, as
follows. By convexity, we have
E h∆m, Vf (Xm) - Vf(Xm)) ≥ μE∣∆m∣2.	(86)
By the L-Lipschitz property, we have
E ∣Vf (Xm) -Vf (Xm)∣2 ≤ L2E∣∆m∣2.	(87)
By substituting (86) and (87) into (64), and using μ < L,we have
E∣∆m+1∣2 ≤ (1 - hμ +，IhL ) E∣∆m∣2 + 竺 X (L3 :产2 .	(88)
∖	min{φi}J	μ G φ2
Since h < μ 宜2。", we obtain (68).	□
D Proof of Proposition 4.2
Proofof Proposition 4.2. For this special target distribution p, the objective function is f (x)
Pd=I lx2l-. With α = 0 and φi = 1∕d, we have: χm+1 = Xm for all i = rm and
Xm+1 = (1 - dh)xmm + √2dhξm .
Therefore for all i = 1, 2, . . . , d, we have
E∣xm+1∣2 = dE (∣xm+1∣2 I rm = i) + (1 - d) E (∣χm+1∣2 ∣ rm = i)
dd
=dE (∣(1 - dh)χm + √2dhξm∣2 ∣ rm = i) + (1 - d) E (∣χm∣2)
=(1 - 2h + dh2) E∣xm∣2 + 2h
∣	___ I 2
(89)
where we use Eξ 卜厂 一 dhXm + √2dhξm∣ = (1 - dh)2∣Xm∣2 + 2dh in the last equation. By
summing (89) over i, we obtain
E∣Xm+1∣2 = (1 - 2h + dh2) E∣Xm∣2 +2dh.
Using it iteratively, and considering E∣x0∣2 = 3d, we have:
E∣Xm∣2 ≥ 3d (1 - 2h + dh2)m + (1 - (1 - 2h + dh2)m) Jdh八2
2h - dh2
=d (1 - 2h + dh2)m + 2 1h + 2d (1 - 2 Idh) (1 - 2h + dh2)m
2 - dh	2 - dh
≥ d (1 - 2h)m +』，
2 - dh
25
Under review as a conference paper at ICLR 2021
where we use dh ≤ 1 in the last inequality.
Since
W(qm,p) ≥ (J ∖x∖i2qm(x)dx^	- (J |x|2p(x)dx) / = (J ∖x∖2qm(x)dx^
—
we have
W(qm,p) ≥ (J ∣x∣2qm(x)dx) ,
m
-√d ≥	d (I - 2h)m + 2⅛ - d
Jd (1 - 2h)m + 22dh + √d
≥ 工(1 - 2h)m + 学
3	6
、, C 7、√d , d3/2h
≥ exp (-2mh) -- H———
3	6
where in the last inequality we use
Jd (1 — 2h)m + A 2" + √d ≤ 3√d.
2 - dh
Therefore, we finally prove (26).
□
26