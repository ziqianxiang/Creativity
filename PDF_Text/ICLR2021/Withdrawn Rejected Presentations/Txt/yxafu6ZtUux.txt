Under review as a conference paper at ICLR 2021
An Online Sequential Test for Qualitative
Treatment Effects
Anonymous authors
Paper under double-blind review
Ab stract
Tech companies (e.g., Google or Facebook) often use randomized online experi-
ments and/or A/B testing primarily based on the average treatment effects to com-
pare their new product with an old one. However, it is also critically important
to detect qualitative treatment effects such that the new one may significantly out-
perform the existing one only under some specific circumstances. The aim of this
paper is to develop a powerful testing procedure to efficiently detect such qualita-
tive treatment effects. We propose a scalable online updating algorithm to imple-
ment our test procedure. It has three novelties including adaptive randomization,
sequential monitoring, and online updating with guaranteed type-I error control.
We also thoroughly examine the theoretical properties of our testing procedure
including the limiting distribution of test statistics and the justification of an effi-
cient bootstrap method. Extensive empirical studies are conducted to examine the
finite sample performance of our test procedure.
1	Introduction
Tech companies use randomized online experiments, or A/B testing to compare their new product
with a well-established one. Most works in the literature focus on the average treatment effects
(ATE) between the new and existing products (see Kharitonov et al., 2015; Johari et al., 2015; 2017;
Yang et al., 2017; Ju et al., 2019, and the references therein). In addition to ATE, sometimes we
are interested in locating the subgroup (if exists) that the new product performs significantly better
than the existing one, as early as possible. Consider a ride-hailing company (e.g., Uber). Suppose
some passengers are in the recession state (at a high risk of stopping using the companys app) and
the company comes up with certain strategy to intervene the recession process. We would like to if
there are some subgroups that are sensitive to the strategy and pin-point these subgroups if exists. It
motivates us to consider the null hypothesis that the treatment effect is nonpositive for all passenger.
Such a null hypothesis is closely related to the notion of qualitative treatment effects in medical
studies (QTE, Gail & Simon, 1985; Roth & Simon, 2018; Shi et al., 2020a), and conditional moment
inequalities in economics (see for example, Andrews & Shi, 2013; 2014; Chernozhukov et al., 2013;
Armstrong & Chan, 2016; Chang et al., 2015; Hsu, 2017). However, these tests are computed offline
and might not be suitable to implement in online settings. Moreover, it is assumed in those papers
that observations are independent. In online experiment, one may wish to adaptively allocate the
treatment based on the observed data stream in order to maximize the cumulative reward or to detect
the alternative more efficiently. The independence assumption is thus violated. In addition, an
online experiment is desired to be terminated as early as possible in order to save time and budget.
Sequential testing for qualitative treatment effects has been less explored.
In the literature, there is a line of research on estimation and inference of the heterogeneous treatment
effects (HTE) (Athey & Imbens, 2016; Taddy et al., 2016; Wager & Athey, 2018; Yu et al., 2020).
In particular, Yu et al. (2020) proposed an online test for HTE. We remark that HTE and QTE are
related yet fundamentally different hypotheses. There are cases where HTE exists whereas QTE
does not. See Figure 1 for an illustration. Consequently, applying their test will fail in our setting.
The contributions of this paper are summarized as follows. First, we propose a new testing procedure
for treatment comparison based on the notion of QTE. When the null hypothesis is not rejected,
the new product is no better than the control for any realization of covariates, and thus it is not
useful at all. Otherwise, the company could implement different products according to the auxiliary
1
Under review as a conference paper at ICLR 2021
XXX
Figure 1: Plots demonstrating QTE. X denotes the observed covariates, A denotes the received treatment and
Y denotes the associated reward. In the ride-hailing example, X is a feature vector describing the characteristics
of a passenger, A is a binary strategy indicator and Y is the passenger’s number of rides in the following two
weeks. In the left panel, the treatment effect does not depend on X . Neither HTE nor QTE exists in this case.
In the middle panel, HTE exists. However, the treatment effect is always negative. As such, QTE does not
exist. In the right penal, both QTE and HTE exist.
covariates observed, to maximize the average reward obtained. We remark that there are plenty cases
where the treatment effects are always nonpositive (see Section 5 of Chang et al., 2015; Shi et al.,
2020a). A by-product of our test is that it yields a decision rule to implement personalization when
the null is rejected (see Section 3.1 for details). Although we primarily focus on QTE in this paper,
our procedure can be easily extended to testing ATE as well (see Appendix D for details).
Second, we propose a scalable online updating algorithm to implement our test. To allow for se-
quential monitoring, our procedure leverages idea from the α spending function approach (Lan &
DeMets, 1983) originally designed for sequential analysis in a clinical trial (see Jennison & Turnbull,
1999, for an overview). Classical sequential tests focus on ATE. The test statistic at each interim
stage is asymptotically normal and the stopping boundary can be recursively updated via numerical
integration. However, the limiting distribution of the proposed test statistic does not have a tractable
analytical form, making the numerical integration method difficult to apply. To resolve this issue,
we propose a scalable bootstrap-assisted procedure to determine the stopping boundary.
Third, we adopt a theoretical framework that allows the maximum number of interim analyses K
to diverge as the number of observations increases, since tech companies might analyze the results
every few minutes (or hours) to determine whether to stop the experiment or continue collecting
more data. It is ultimately different from classical sequential analysis where K is fixed. Moreover,
the derivation of the asymptotic property of the proposed test is further complicated due to the
adaptive randomization procedure, which makes observations dependent of each other. Despite
these technical challenges, we establish a nonasymptotic upper bound on the type-I error rate by
explicitly characterizing the conditions needed on randomization procedure, K and the number of
samples observed at the initial decision point to ensure the validity of our test.
2	Background and problem formulation
We propose a potential outcome framework (Rubin, 2005) to formulate our problem. Suppose that
we have two products including the control and the treatment. The observed data at time point
t consists of a sequence of triples {(Xi,Ai,Yi)}N(t), where N(∙) is a counting process that is
independent of the data stream {(Xi, Ai, Yi)}i+=∞1 , Ai is a binary random variable indicating the
product executed for the i-th experiment, Xi ∈ Rp denotes the associated covariates, and Yi stands
for the associated reward (the larger the better by convention). We allow Ai to depend on Xi and past
observations {(Xj, Aj, Yj)}j<i so that the randomization procedure can be adaptively changed. In
addition, define 匕* (0) and ** (1) to be the potential outcome that would have been observed if the
corresponding product is executed for the i-th experiment. Suppose that {(Xi ,匕* (0),匕* (1)) }+=∞
are independently and identically distributed copies of (X, Y *(0), Y *(1)). Let X be the support of
X and Q0(x, a) = E{Y *(a)|X = x} for a = 0, 1, we focus on testing the following hypotheses:
H0 : Q0(x, 1) ≤ Q0(x, 0), ∀x ∈ X versus H1 : Q0(x, 1) > Q0(x, 0), ∃x ∈ X.
Notice that when there are no covariates, i.e., X = 0, the hypotheses are reduced to H : τ0 ≤ 0
versus H1 : τ0 > 0, where τ0 corresponds to ATE, i.e, τ0 = E{Y *(1) - Y *(0)}. In general, we
require X to be a compact set. We consider a large linear approximation space Q for the conditional
mean function Q0. Specifically, let Q = {Q(x,a; βo,βι) = Ψ>(x)βa ： βo,βι ∈ Rq} be the
approximation space, where 夕(x) is a q-dimensional vector composed of basis functions on X. The
2
Under review as a conference paper at ICLR 2021
dimension q is allowed to diverge with the number of observations in order to alleviate the effects
of model misspecification. The use of linear approximation space simplifies the computation of our
testing procedure. When Q0 is well approximated, it suffices to test
Ho : 3>(x)(βi — βo) ≤ 0,∀x ∈ X versus Hi : φ>(χ)(βι - β0) > 0, ∃χ ∈ X.	(1)
For clarity, here We assume Qo(x, a) = Q(x, a; β0,βγ) for some β0 and /；.In Appendix B, We al-
low the approximation error infβ0,βι∈RP suPχ∈χ,a∈{o,i} ∣Qo(x, a) - Q(x, a; βo,βι)∣ to be nonzero.
Let Fj denote the sub-dataset {(Xi, Ai,匕)}ι≤i≤j for j ≥ 1 and Fo = 0. Throughout this paper,
We assume that the folloWing tWo assumptions hold.
(A1) Yi = AiYi0(1) + (1 - Ai)Yi0(0) for ∀i ≥ 1.
(A2) Ai is independent of Yi0(0), Yi0(1), {(Xk, Yk0(0), Yk0(1))}k>i given Xi andFi-i, for any i.
Assumption (A1) is referred to be the stable unit treatment value assumption (Rubin, 1974) and As-
sumption (A2) is the sequential randomization assumption (Zhang et al., 2013) and is automatically
satisfied in a randomized study Where the treatments are independently generated of the observed
data. (A2) essentially assumes there is no unmeasured confounders. These assumptions guaran-
tee that both regression coefficients (defined through potential outcomes) are estimable from the
observed dataset as shoWn in the folloWing lemma.
Lemma 1 Let I(∙) denotes the indicator function. Under (A1)-(A2), we have
E[I(Ai = a){Yi — 夕>(Xi)βa}] = 0, ∀a ∈ {0,1}, i ≥ 1.
3	Online sequential testing for QTE
3.1	Test statistics and their limiting distribution
We first present our test statistic for testing Ho. In vieW of Lemma 1, We estimate βa by using the
ordinary least squares estimator
一、一」1心...............................1
βa(t) = Σ-1(t) I W NI(Ai = a"Ki
at each time point t for a ∈ {0,1}, where Σa(t) = N-1(t) PNI I(Ai = a)φ(Xi)φτ(Xi). A
generalized inverse might be used even if Σa(t) is not invertible. Consider the following test statistic
S(t) = supχ∈χ φ τ (χ){βι(t) - βo(t)}. Under Ho, we expect S(t) to be small. A large S(t) can be
interpreted as the evidence against Ho. As such, we reject Ho for large S(t). We remark that when
Ho is rejected, we can apply the decision rule d(x) = arg maxa∈{o,i}夕τ(x)βa(t) for personalized
recommendation.
To determine the rejection region, we next discuss the limiting distribution of S(t). Under Ho,
S(t) ≤ SUp3>(x){βi(t) - β0 - βo(t) + β" + sup3>(x)(β0 - βo)
x∈X	x∈X
~Γ .	. , ^	, ,	_ ,	^	, ,
≤ SUp P (x){βbi(t) - βi - βbo(t) + βo }.	(2)
x∈X
Both equalities hold when β0 = βj. Suppose there exists some function ∏0(∙, ∙) defined on
{0, 1} × X that satisfies EX| Pin=i n-iπi-i(a, X) - π0(a, X)| →P 0, ∀a ∈ {0, 1} as n → ∞,
where ∏n(∙, ∙) = Pr(An = a|Xn = x, Fn-1), and the expectation EX is taken with respect to
X . This condition implies that the treatment assignment mechanism cannot be arbitrary (see the
discussion below Theorem 1 for details). Then we will show
B(t) ≡	PNW{βi(t)-	β0	-	βo(t)	+ β0}→	N(0,	X	∑-1Φa∑-i),	as N(t)	→	∞,	⑶
a∈{o,i}
where Σ0 = Eπ0(a,X)^(X)^τ(X), Φ0 = Eπ0(a,X)σ2(a,X)p(X%>(X), and σ2(a,x)=
E[{Y0(a)- 夕τ(X)βa}2∣X = x], for any X ∈ X. According to equation 3, the right-hand-side
3
Under review as a conference paper at ICLR 2021
(RHS) of equation 2 is to converge in distribution to the maximum of some Gaussian random vari-
ables. This observation forms the basis of our test.
We next discuss the sequential implementation of our test. Assume that the interim analyses are
conducted at time points t1,t2,...,tκ ∈ [0,...,T] such that 0 < tι ‹ t2 < •…< tκ = T.
We allow K to grow with the number of observations. In the most extreme case, one may set
tk = inft {N (t) ≥ N (tk-1) + 1}, ∀k ≥ 2. That is, we make a decision regarding the null hypothesis
upon the arrival of each observation. In addition, we assume that t1 is large so that there are enough
number of samples N(t1) to guarantee the validity of the normal approximation for B(t1). We
remark that in typical tech companies such as Amazon, Facebook, etc., massive data are collected
even within a short time interval. Large sample approximation is validated in these applications.
To guarantee our test controls the type-I error, We reject Ho and terminate the experiment at tk if
N N (tk) S(tk) ≥ Zk for some k = 1,...,K with some suitably chosen zι,...,zκ > 0 that satisfy
Pr max	{ VZN(tk)S(tk) - Zk} > 0 ≤ α + o(1)
k∈{1,...,K}
for a given significance level α > 0 under H0. In view of equation 2, it suffices to find {Zk}k that
satisfy
Pr < max	( sup WT(X)B(tk) — Zk) > 0 > ≤ α + o(1),	(4)
k∈{1,...,K} x∈X
where the stochastic process B(∙) is defined in equation 3.
To determine {Zk}k, we need to derive the asymptotic distribution of the left-hand-side (LHS) of
equation 4. To this end, define a mean-zero Gaussian process G(t) with covariance function
Cov(G(t), G(t0)) = N1/2(t)N-1/2(t0) X Σa-1ΦaΣa-1, ∀0<t ≤t0.
a∈{0,1}
In the following, we show that the LHS of equation 4 can be uniformly approximated by G(∙), for
any {zk}k=ι,…,k. To establish our theoretical results, we need some regularity conditions on g(∙).
To save space, we summarize these assumptions in (A3) and put them in Appendix B.
Theorem 1 Assume(A1)-(A3) hold. For a = 0,1, assume infχ∈χπ*(a,x) > 0 and |Y*(a)∣ is
bounded almost surely. Assume there exists some 0 < α0 ≤ 1 such that for any sequence {jn}n that
satisfies jnα0 / logα0 jn q2, the following event occurs with probability at least 1 - O(jn-α0),
k
sup E ^X{∏i-ι(a, x) — π* (a,x)} ≤ O(1)qk1-α0 logα0 k, ∀k ≥ jn,	(5)
a∈{0,1}	i=1
where O(1) denotes some positive constant. Assume Nα0 (t1)/ logα0 N(t1)	q2 and N(t1)
log N(T) almost surely. Then conditional on the counting process N(∙), there exists some constant
c > 0 such that
sup
z1 ,...,zK
Pr max	sup W> (x)B (tK) — Zk > 0 — Pr max	sup W> (x)G(tK) — Zk > 0
k∈{1,...,K} x∈X	K k	k∈{1,...,K} x∈X	K k
≤ C [q3/4NT/8(ti)log15/8{KN(ti)} + qN-ao/3(ti)log(5+a0)/3{KN(ti)}i .
Theorem 1 implies that the approximation error depends on the number of observations obtained
up to the first decision point N(t1), the maximum number of interim analyses K, the total number
of basis functions q, and α0, which characterizes the convergence rate of the treatment assignment
mechanism Pin=1 n-1πi-1. Clearly, the error will decay to zero when the followings hold with
probability tending to 1,
q = O(Nα* (tι)), for some 0 ≤ α* < min(1∕6, α0∕3),
(6)
log(K) ≪ min{N 1/15-2a*/5(ti),N(a0-3a*)/(5+a0)(tι)}.	(7)
4
Under review as a conference paper at ICLR 2021
In Appendix C, we show that α0 = 1/2, when an -greedy strategy is used for randomization to
balance the trade-off between exploration and exploitation. In this case, 6 requires q to grow at a
slower rate than N1/6(t1). This condition is automatically satisfied when q is bounded. Condition
7 is satisfied when K grows polynomially fast with respect to N(t1). In addition to -greedy,
other adaptive allocation procedures (e.g., upper confidence bound or Thompson sampling) could
be applied as well.
As discussed in the introduction, the derivation of Theorem 1 is nontrivial. One way to obtain the
magnitude of the approximation error is to apply the strong approximation theorem for multidimen-
sional martingales (see Morrow & Philipp, 1982; Zhang, 2004). However, the rate of approximation
typically depends on the dimension and decays fast as the dimension increases. To derive Theorem
1, We view (夕> (χ)B(tκ)}χ∈χ,k∈{i,…，κ} as a high-dimensional martingale and adopt the Gaussian
approximation techniques that have been recently developed by Belloni & Oliveira (2018). In view
of equation 2, an application of Theorem 1 yields the following result.
Theorem 2 Assume that the conditions of Theorem 1 hold, equation 6 and equation 7 hold with
probability tending to 1. Then for any z1, . . . , zk that satisfy
Pr < max (SuP 夕> (x)G(tk) — Zk) > 0 > = α + o(1),	(8)
k∈{1,...,K} x∈X
as N(t1) diverges to infinity, we have under H0,
Pr ( max {pN(tk)S(tk) — Zk} > 0 ) ≤ α + o(1).
k∈{1,...,K}
The above equality holds when βo = β1.
Theorem 2 suggests that the type-I error rate of the proposed test can be well controlled. It remains
to find critical values {Zk}1≤k≤K that satisfy equation 8. In the next section, we propose a bootstrap-
assisted procedure to determine these critical values.
3.2	B ootstrap stopping b oundary
We first outline a method based on the wild bootstrap (Wu, 1986) to approximate the limiting dis-
tribution of {S(tk)}k. Then we discuss its limitation and present our proposal, a scalable bootstrap
algorithm to determine the stopping boundary.
The idea is to generate bootstrap samples {βaMB(tk)}a,k that have asymptotically the same joint dis-
tribution as {βa(tk) — βa}α,k. Then thejomt distribution of {S(tk)}k can be well-approximated by
the conditional distribution of {SMB(tk)}k given the data, where SMB(t) = suPχ∈χ 夕>(x){βMB(t)—
+∞
βoMB(t)} for any t. Specifically, let {ξi}i+=∞1 be a sequence of i.i.d. standard normal random variables
independent of {(Xi, Ai, Yi)}i+=∞1 . For a ∈ {0, 1}, define
βbaMB(t) =Σba-1(t)
1	N(t)
Nt) X I(Ai= a)Pi(X){Yi - 夕>(Xi)b(t)}ξi
∀a ∈ {0, 1}.
.ʌ ..«	...	C / -Λ,τ / .∖ 5t'KΛR / . ∖	1 / TV r / . ∖ /仑 /,、	c+∖	ɪ ι ι∙ . ∙	.ι ♦
Both the asymptotic means of √Ν(t)βMB(t) and √N(t)(βa (t) — βa) are zero. In addition, their
covariance functions are asymptotically the same. By design, {βaMB(tk)}a,k is multivariate nor-
mal. Similar to equation 3, we can show {βa(tk) — βa}a,k is asymptotically multivariate normal.
Consequently, the limiting distributions of {βMB(tk )}a,k and {βa(tk) — βa}a,k are asymptotically
equivalent. As such, the bootstrap approximation is valid.
However, calculating βaMB(tk) requires O(N (tk)) operations. The time complexity of the resulting
bootstrap algorithm is O(BN (tk)) up to the k-th interim stage, where B is the total number of
bootstrap samples. This can be time consuming when {N(tk) —N(tk-1)}kK=1 are large. To facilitate
the computation, we observe that in the calculation of βaMB, the random noise is generated upon the
arrival of each observation. This is unnecessary as we aim to approximate the distribution of βa(∙)
only at finitely many time points.
5
Under review as a conference paper at ICLR 2021
We next present our proposal. Let {ei,a}i=1,...,K,a=0,1 be a sequence of i.i.d N (0, Iq) random
vectors independent of the observed data, where Iq denotes the q × q identity matrix. At the k-
th interim stage, We compute SMB*(tk) = supχ∈χ夕>(χ){βMB*(tk) - βMB*(tk)}, where βbMB*(tk)
equals
1 k /	N (tj)	、1/2
NTT) X	X	∑-* 1(tj)I(Ai = a)φ(Xi)φτ(Xi){Yi -以Xi)>βba(tj)}2∑-1 (tj)	ej,α.
N(tk) j=1	i=N(tj-1)+1
一	一 一	一	一 ..一	_	Γ^^-.-T -O…,，	.	‹∖ f ,,	.,	一
For any kι and k2, the conditional covariance of 'N(t^){βMB*(tkj - βMB*(tkj} and
VzN(tk2) {bM (tk2) - bM (tk2)} equals
1
P (tkl)N (tk2 )
1 k1	N(tj)
XX X
∑-1(tj)I(Ai= a)φ(Xi)φτ(Xi){Yi - φτ(Xi)β'α(tj)}2∑-1(tj).
a=0 j=1 i=N(tj-1)+1
Under the given conditions in Theorem 1, it is to converge to
1
X Σa-1Φ(a)Σa-1
a=0
Cov(G(tk1),G(tk2)).
,	/	,-r , ^. .. ^.	...... .	.	.	.
This means {/N(tk)(βMB (tk) - βMB (tk))}k and {G(tk)}k have the same asymptotic distribu-
tion. Consequently, {"N(tk)SMB*(tk)}K=ι Can be USed to approximate the joint distribution of
{suPx∈X 3τ(x)G(tk)}K=1.
To choose {zk}k that satisfies equation 8, we adopt the α-spending approach that allocates the total
allowable type I error at each interim stage according to an error-spending function. This guarantees
our test controls the type-I error. We begin by specifying an α spending function α(t) that is non-
increasing and satisfies α(0) = 0, α(T) = α. Popular choices of α(∙) include
αι(t) = αlog (1 + (e - 1)t),
α2 (t) = 2 - 2Φ
α3(t) = α (T) , for θ > 0,
α4(t)
1 — exp(一γt∕T)
α 1 - exp(-γ)
for γ 6= 0,
(9)
where Φ(∙) denotes the cumulative distribution function of a standard normal variable and Φ-1(∙) is
its quantile function. Based on α(∙), we iteratively calculate Ibk ,k = 1,...,K as the solution of
Pr* < max
j∈{1,...,k-1}
j)-%	≤ 0, √N(tk)SMB*(tk) >zk = α(tk) - α(tk-i), (10)
and reject H when，N(tk)S(tk) > zk holds for some k.
The validity of the bootstrap test is summarized in Theorems 3 and 4 below.
Theorem 3 Assume the conditions in Theorem 1 hold. Assume q = O(Nα*(tι)) for some 0 <
a* < 1/3, almost surely. Then conditional on the counting process N(∙), we have
sup Pr* max I (√N(tk)SMB*(tk) - Zk) > 0}-尸r (三maXg (sup 夕τ(x)G(tk) - Zk) > 0∣ I
≤ C [q1∕2N-1/6(ti)log11∕6{KN(tι)} + qN-α0∕3(tι)log(5+α0"3{KN(〃)}]
for some constant c > 0 with probability at least 1 —O(N-α0(tι)), where Pr*(∙) denotes the
probability measure conditional on the data stream {Xi, Ai, Yi}i+=∞1 .
Theorem 4 Assume the conditions in Theorem 3 hold. Then conditional on N(∙), the critical values
{Zbk }k satisfy
Pr < max	( sup 夕τ(x)G(tk) — z'k ) > 0 — — α
I k∈{1,...,K} x∈X	I
≤ C [q1/2NT/6(ti)log11/6{KN(tι)} + qN-ao/3(ti)log(5+a0)/3{KN(tι)}] , (11)
for some constant c > 0.
6
Under review as a conference paper at ICLR 2021
When the RHS of equation 11 is op(1), it follows from Theorems 2 and 4 that our test is valid.
The conditional distribution in equation 10 can be approximated by the empirical distribution of
Bootstrap samples.
Finally, we remark that our test can be online updated as batches of observations arrive at the end
of each interim stage. A pseudocode summarizing our procedure is given in Algorithm 1 in the
appendix. The spatial complexity of the proposed algorithm is O(B), where B is the number of
bootstrap samples. The time complexity is O(Bk + N(tk)) up to the k-th interim stage. Suppose
N(tj) - N(tj-1) = n for any 1 ≤ j ≤ K, we have Bk + N(tk) = (B + n)k Bnk = BN(tk)
for large n and B. Hence, our procedure is much faster compared to the standard wild bootstrap.
4	Numerical studies
4.1	Simulation studies
In this section, we conduct Monte Carlo simulations to examine the finite sample properties of the
proposed test. We generated the potential outcomes as Yi* (a) = 1 + (X〃 一 Xi2 )/2 + aτ(Xi) + εi,
where εi,s are i.i.d N(0,0.52). The covariates Xi = (Xn,Xi2, Xi3)> were generated as fol-
lows. We first generated Xi* = (Xi*1, Xi*2, Xi*3)> from a multivariate normal distribution with
zero mean and covariance matrix equal to {0.5|i-j| }i,j. Then we set Xij = Xi*j I(Xi*j | ≤
2) + 2sgn(Xi*j )I(Xi*j | > 2). We consider two randomization designs. In the first design, the
treatment assignment is nondynamic and completely random. Specifically we set πi(a, x) = 0.5,
for any a, x and i. In the second design, we use an -greedy strategy to generate the treatment with
ε = 0.3. In addition, we set N(T1) = 2000 and N(Tj) 一 N (Tj-1) = 2n for 2 ≤ j ≤ K and some
n > 0. We consider two combinations of (n, K), corresponding to (n, K) = (200, 5) and (20, 50).
We set the significance level α = 0.05 and choose B = 10000. We set τ(Xi) = φδ{(Xi1 +
Xi2)/√2}X23 for some function φδ parameterized by some δ ≥ 0. We consider two scenarios for
φδ. Specifically, We set φδ (x) = δx2/3 in Scenario 1 and φδ = δ cos(∏x) in Scenario 2. For each
setting, we further consider four cases by setting δ = 0, 0.1, 0.15, 0.2, 0.25 and 0.3. When δ = 0,
Ho holds. Otherwise, Hi holds. For all settings, We construct the basis function 夕(∙) using additive
cubic splines. For each univariate spline, we set the number of internal knots to be 4. These knots
are equally spaced between [一2, 2].
We denote our test by BAT, short for bootstrap-assisted test. We run our experiments on a single
computer instance with 40 Intel(R) Xeon(R) 2.20GHz CPUs. It takes 1-2 seconds on average to
compute each test. In Table 1 (see Appendix G), we report the rejection probabilities and average
stopping times (defined as the average number of samples consumed when the experiment is termi-
nated) of the proposed test aggregated over 400 simulations when αι(∙) is chosen as the spending
function. In Figure 2, we plot the rejection probabilities of our tests and the average stopping times
of the experiments. It can be seen that the type-I error rates are close to the nominal level in all
cases. The power of our test increases as δ increases, demonstrating its consistency. In addition,
when δ > 0, our experiments are stopped early in all cases.
To further evaluate our method, we compare it with a test based on the law of iterated logarithm
(denoted by LIL). LIL determines the decision boundary based on an always valid finite error bound
(see Appendix F for details about the competing method). It can be seen from Figure 2 that our
method has much larger power than the law of iterated logarithm approach.
4.2	Real data analysis
In this section, we apply the proposed method to a Yahoo! Today Module user click log dataset1,
which contains 45,811,883 user visits to the Today Module, during the first ten days in May 2009.
For the ith visit, the dataset contains an ID of the new article recommended to the user, a binary
response variable Yi indicating whether the user clicked the article or not, and a five dimensional
feature vector summarizing information of the user. Due to privacy concerns, feature definitions and
article names were not included in the data. Each feature vector sums up to 1. Therefore, we took
the first three and the fifth elements to form the covariates Xi . For illustration, we only consider a
1https://webscope.sandbox.yahoo.com/catalog.php?datatype=r&did=49
7
Under review as a conference paper at ICLR 2021
Si-Adaptive
S2-Random
S2-Adaptive
Figure 2: Rejection probabilities and average stopping times of the proposed test when αι(∙) is chosen as
the spending function. From left to right: Scenario 1 with random design, Scenario 1 with -greedy design,
Scenario 2 with random design and Scenario 2 with -greedy design.
subset of data that contains visits on May 1st where the recommended article ID is either 109510
or 109520. These two articles were being recommended most on that day. This gives us a total of
405888 visits. On the reduced dataset, define Ai = 1 if the recommended article is 109510 and
Ai = 0 otherwise.
We first conduct A/A experiments (which compare these two articles against themselves) to examine
the validity of our test. The A/A experiments are done when every 2000 more users are available, we
randomly assign 1000 users to arm A, and the other 1000 users in arm B. We expect our test will not
reject H0 in A/A experiments, since the articles being recommended are the same. Then, we conduct
A/B experiment to test the QTE of these two articles. The test statistics and their corresponding
critical values are plotted in Figure 3. On average it takes several seconds to implement our test. It
can be seen that our test is able to be reject H0 after obtaining the first one-third of the observations,
in the A/B experiment. In the A/A experiments, we fail to reject H0 , as expected.
5	Discussion
In this paper, we propose anew testing procedure for evaluating the performance of technology prod-
ucts in tech companies based on the notion of qualitative treatment effects. Currently, we only focus
on comparing two products. It would be practically useful to develop a multiple testing procedure
under settings with multiple treatment options. These topics warrant further investigations.
8
Under review as a conference paper at ICLR 2021
References
Donald W. K. Andrews and Xiaoxia Shi. Inference based on conditional moment inequali-
ties. Econometrica, 81(2):609-666, 2013. ISSN 0012-9682. doi: 10.3982/ECTA9370. URL
http://dx.doi.org/10.3982/ECTA9370.
Donald W. K. Andrews and Xiaoxia Shi. Nonparametric inference based on conditional moment
inequalities. J. Econometrics, 179(1):31-45, 2014. ISSN 0304-4076. doi: 10.1016/j.jeconom.
2013.10.005. URL http://dx.doi.org/10.1016/j.jeconom.2013.10.005.
Timothy B. Armstrong and Hock Peng Chan. Multiscale adaptive inference on conditional moment
inequalities. J. Econometrics, 194(1):24-43, 2016. ISSN 0304-4076. doi: 10.1016/j.jeconom.
2016.04.001. URL http://dx.doi.org/10.1016/j.jeconom.2016.04.001.
Susan Athey and Guido Imbens. Recursive partitioning for heterogeneous causal effects. Proc. Natl.
Acad. Sci. USA, 113(27):7353-7360, 2016. ISSN 1091-6490. doi: 10.1073/pnas.1510489113.
URL https://doi.org/10.1073/pnas.1510489113.
Alexandre Belloni and Roberto I Oliveira. A high dimensional central limit theorem for martingales,
with applications to context tree models. arXiv preprint arXiv:1809.02741, 2018.
Bernard Bercu and Abderrahmen Touati. Exponential inequalities for self-normalized martingales
with applications. Ann. Appl. Probab., 18(5):1848-1869, 2008. ISSN 1050-5164. doi: 10.1214/
07-AAP506. URL https://doi.org/10.1214/07-AAP506.
Prabir Burman and Keh-Wei Chen. Nonparametric estimation of a regression function. Ann. Statist.,
17(4):1567-1596, 1989. ISSN 0090-5364. doi: 10.1214/aos/1176347382.
Minsu Chang, Sokbae Lee, and Yoon-Jae Whang. Nonparametric tests of conditional treatment
effects with an application to single-sex schooling on academic achievements. Econom. J., 18(3):
307-346, 2015. ISSN 1368-4221.
Xiaohong Chen and Timothy M. Christensen. Optimal uniform convergence rates and asymptotic
normality for series estimators under weak dependence and weak conditions. J. Econometrics,
188(2):447-465, 2015. ISSN 0304-4076. doi: 10.1016/j.jeconom.2015.03.010.
Victor Chernozhukov, Sokbae Lee, and Adam M. Rosen. Intersection bounds: estimation and in-
ference. Econometrica, 81(2):667-737, 2013. ISSN 0012-9682. doi: 10.3982/ECTA8718. URL
http://dx.doi.org/10.3982/ECTA8718.
Victor Chernozhukov, Denis Chetverikov, and Kengo Kato. Empirical and multiplier bootstraps
for suprema of empirical processes of increasing complexity, and related Gaussian couplings.
Stochastic Process. Appl., 126(12):3632-3651, 2016. ISSN 0304-4149. doi: 10.1016/j.spa.2016.
04.009. URL https://doi.org/10.1016/j.spa.2016.04.009.
Victor Chernozhukov, Denis Chetverikov, and Kengo Kato. Detailed proof of nazarov’s inequality.
arXiv preprint arXiv:1711.10696, 2017.
M Gail and R Simon. Testing for qualitative interactions between treatment effects and patient
subsets. Biometrics, 41(2):361-372, 1985.
Yu-Chin Hsu. Consistent tests for conditional treatment effects. The Econometrics Journal, 20(1):
1-22, 2017.
Jianhua Z. Huang. Projection estimation in multiple regression with application to functional
ANOVA models. Ann. Statist., 26(1):242-272, 1998. ISSN 0090-5364. doi: 10.1214/aos/
1030563984.
Christopher Jennison and Bruce W Turnbull. Group sequential methods with applications to clinical
trials. Chapman and Hall/CRC, 1999.
Ramesh Johari, Leo Pekelis, and David J Walsh. Always valid inference: Bringing sequential anal-
ysis to a/b testing. arXiv preprint arXiv:1512.04922, 2015.
9
Under review as a conference paper at ICLR 2021
Ramesh Johari, Pete Koomen, Leonid Pekelis, and David Walsh. Peeking at a/b tests: Why it mat-
ters, and what to do about it. In Proceedings of the 23rd ACM SIGKDD International Conference
on Knowledge Discovery and Data Mining, pp. 1517-1525. ACM, 2017.
Nianqiao Ju, Diane Hu, Adam Henderson, and Liangjie Hong. A sequential test for selecting the
better variant: Online a/b testing, adaptive allocation, and continuous monitoring. In Proceedings
of the Twelfth ACM International Conference on Web Search and Data Mining, pp. 492-500.
ACM, 2019.
Eugene Kharitonov, Aleksandr Vorobev, Craig Macdonald, Pavel Serdyukov, and Iadh Ounis. Se-
quential testing for early stopping of online experiments. In Proceedings of the 38th International
ACM SIGIR Conference on Research and Development in Information Retrieval, pp. 473-482.
ACM, 2015.
K. K. Gordon Lan and David L. DeMets. Discrete sequential boundaries for clinical trials.
Biometrika, 70(3):659-663, 1983. ISSN 0006-3444. doi: 10.2307/2336502. URL https:
//doi.org/10.2307/2336502.
Gregory Morrow and Walter Philipp. An almost sure invariance principle for Hilbert space valued
martingales. Trans. Amer. Math. Soc., 273(1):231-251, 1982. ISSN 0002-9947. doi: 10.2307/
1999203. URL https://doi.org/10.2307/1999203.
Jeremy Roth and Noah Simon. A framework for estimating and testing qualitative interac-
tions with applications to predictive biomarkers. Biostatistics, 19(3):263-280, 2018. ISSN
1468-4357. doi: 10.1093/biostatistics/kxx038. URL https://doi.org/10.1093/
biostatistics/kxx038.
D.B. Rubin. Estimating causal effects of treatments in randomized and non-randomized studies. J.
Edu. Psychol., 66:688-701, 1974.
Donald B. Rubin. Causal inference using potential outcomes: design, modeling, decisions. J. Amer.
Statist. Assoc., 100(469):322-331, 2005. ISSN 0162-1459. doi: 10.1198/016214504000001880.
URL https://doi.org/10.1198/016214504000001880.
Chengchun Shi, Wenbin Lu, and Rui Song. A sparse random projection-based test for overall qual-
itative treatment effects. Journal of the American Statistical Association, 115(531):12011213,
2020a.
Chengchun Shi, Sheng Zhang, Rui Song, and Wenbin Lu. Statistical Inference of the Value Function
for Reinforcement Learning in Infinite Horizon Settings. Under review, 2020b.
Charles J. Stone. Optimal global rates of convergence for nonparametric regression. Ann. Statist.,
10(4):1040-1053, 1982. ISSN 0090-5364.
Matt Taddy, Matt Gardner, Liyun Chen, and David Draper. A nonparametric bayesian analysis
of heterogenous treatment effects in digital experimentation. Journal of Business & Economic
Statistics, 34(4):661-672, 2016.
Stefan Wager and Susan Athey. Estimation and inference of heterogeneous treatment effects us-
ing random forests. J. Amer. Statist. Assoc., 113(523):1228-1242, 2018. ISSN 0162-1459.
doi: 10.1080/01621459.2017.1319839. URL https://doi.org/10.1080/01621459.
2017.1319839.
C.-F. J. Wu. Jackknife, bootstrap and other resampling methods in regression analysis. Ann. Statist.,
14(4):1261-1350, 1986. ISSN 0090-5364. doi: 10.1214/aos/1176350142. URL https://
doi.org/10.1214/aos/1176350142. With discussion and a rejoinder by the author.
Fanny Yang, Aaditya Ramdas, Kevin G Jamieson, and Martin J Wainwright. A framework for multi-
a (rmed)/b (andit) testing with online fdr control. In Advances in Neural Information Processing
Systems, pp. 5957-5966, 2017.
Miao Yu, Wenbin Lu, and Rui Song. A new framework for online testing of heterogeneous treatment
effect. In AAAI, pp. 10310-10317, 2020.
10
Under review as a conference paper at ICLR 2021
Input: Number of bootstrap samples B, an a spending function α(∙).
Initialize: n = 0, Σ0 = Σ1 = Op+1 , γb0 = γb1 = 0p+1 , β0,b = β1,b = 0p+1 , and a set
I={1,...,B}.
For k = 1 to K do
Initialize: m = 0 and Φ0 = Φ1 = Op+1.
Step 1: Online update of βa
Fori = N(tk-1) +1toN(tk)do
n = n + 1 and m = m + 1;
∑a = (1 一 n-1)∑a + n-1 2(Xi)夕>(Xi)I(Ai = a), a = 0,1；
ba = (1 ― n-1 )Ya + n-1 2(Xi)KI(Ai = a),a = 0, 1；
1>
Compute βa = Σ- 1 Ya for a ∈ {0,1} and S = supχ∈χ 夕 1 (x)(βι 一 βo);
Step 2: Bootstrap
For i = N (tk-1) + 1 to N(tk) do
Φa = Φa + ∑-1ψ(Xi)ψτ(Xi){Yi 一 /(Xi)βa}2∑-1I(Ai = a),a = 0,1；
For b = 1, . . . , B do
Generate two independent N(0, Ip+1) Gaussian vectors e0, e1；
βa,b = (1 一 mn-1)βba,b + n-1ΦΦi/巳a, a = 0,1；
Compute Sb = supχ∈χ 中τ(x)(βι,b 一 βo,b);
Step 3: Reject or not
Set Z to be the upper {α(t) 一 ∣I∣c∕B∣}∕(1 - |Ic|/ B)-th percentile of {Sb}b∈ι;
Update I as I . {b ∈ I: Sb ≤ z}.
If S > z : Reject H0 and terminate the experiment.
Algorithm 1: the Pseudocode that summarizing the online bootstrap testing procedure.
Baqun Zhang, Anastasios A Tsiatis, Eric B Laber, and Marie Davidian. Robust estimation of opti-
mal dynamic treatment regimes for sequential treatment decisions. Biometrika, 100(3):681-694,
2013.
Li-xin Zhang. Strong approximations of martingale vectors and their applications in Markov-
chain adaptive designs. Acta Math. Appl. Sin. Engl. Ser., 20(2):337-352, 2004. ISSN
0168-9673. doi: 10.1007/s10255-004-0173-z. URL https://doi.org/10.1007/
s10255-004-0173-z.
A Notations
We introduce some general notations used in the appendix. For any matrix Mat, we use kMatkp to
denote the matrix norm induced by the corresponding `p norm of vectors, for 1 ≤ p ≤ +∞. For
two nonnegative sequences {s1,n}n and {s2,n}n, we will use the notation s1,n s2,n to represent
that sι,n ≤ cs2,n for some universal constant c > 0 whose value is allowed to change from place to
place. When a matrix Mat is degenerate, Mat-1 denotes the Moore-Penrose inverse of Mat. For any
vector ψ, we use ψ(i) to denote its i-th element.
In Algorithm 1, we use Op+1 to denote a (p + 1) × (p + 1) zero matrix and 0p+1 to denote a
(p + 1)-dimensional zero vector.
B More on the basis function
B.1	Condition (A3)
(A3). Assume λmin[E2(X)^τ(X)] X 1, λmaχ[E2(X)pτ(X)] X 1, SuPx k夕(x)kι = O(q1/2),
liminfq infx∈χ k夕(x)∣∣2 > 0. In addition, assume
suP
x,y∈X
x6=y
ky(x) - y(y)k2
kχ 一 yk2
q1/2.
(12)
11
Under review as a conference paper at ICLR 2021
When a tensor-product B-spline is used (see Section 6 of Chen & Christensen, 2015, for
a brief overview of tenor-product B-splines), (A3) is automatically satisfied. Specifically,
λmin[E夕(X)夕>(X)] N 1, λmaχ[E夕(X)夕>(X)] N 1 follow from Theorem 3.3 of (Burman &
Chen, 1989). SuPx k夕(χ)kι = O(q1/2) follows by noting that the absolute value of each element
in 夕(x) is bounded by some universal constant. liminfq infx∈χ k夕(x)∣∣2 > 0 follows from the ar-
guments used in the proof of Lemma E.4 of Shi et al. (2020b). The last condition in equation 12
holds by noting that each function in the vector 夕(∙)is LiPSchitz continuous when a tensor-product
B-spline is used.
B.2	On the approximation error
The proposed test remains valid as long as the approximation error satisfies
inf SuP	∣Qo(x,a) - Q(x,a; βo,βι)∣ = o({N(T)}-1/2),	(13)
β0,β1∈Rp x∈X,a∈{0,1}
with probability tending to 1. In the following, we introduce some sufficient conditions for equa-
tion 13.
Suppose the Q-function Q0(∙, a) is p-smooth (see the definition of p-smoothness in Stone, 1982),
for a ∈ [0,1]. When a tensor-product B-spline or Wavelet basis is used for 夕(∙)，then there exist
some βo and e；that satisfy
inf SuP	∣Qo(x,a) — Q(x,a; βo,βι)∣ = O(q-p/d).
β0,β1∈Rp x∈X,a∈{o,1}
See Section 2.2 of Huang (1998) for detailed discussions on the approximation power of these basis
functions. Condition equation 13 is thus automatically satisfied when
q	{N(T)}d/(2p),
with probability tending to 1.
C Adaptive randomization
In practice, the company might want to allocate more traffic to a better treatment based on the
observed data stream. The -greedy strategy is commonly used to balance the trade-off between ex-
ploration and exploitation. Fora given 0 < εo < 1, consider the following randomization procedure:
for some integer No > 0 and any j ≥ No, a ∈ {0, 1}, x ∈ X, we set
∏j-i(a,x) = (1 — ε°)aI{" (x)(βι,j-i — βo,j-i) > 0} + ε°(1 — a)I{" (x)(βι,j-i — βo,j-i) ≤ 0},
where
1j	1j
11
βa,j = ∑ j £{I(Ai = a)q(Xi)K} and Σa,j - EI(Ai = a)4(Xi)φτ(Xi).
j i=1	j i=1
It is immediate to see that Σa (t) = Σa,n(t) and βa(t) = βa,n(t). Define
∏*(a,x) = (1 — εo)aI{2>(x)(βι — βo) > 0} + ε°(1 — a)I{2>(x)(βι 一 βo) ≤ 0}
for any a ∈ {0, 1} and x ∈ X.
Lemma2 Assume (A1)-(A3) hold. Assume infx∈χπ*(a,x) > 0 and |Y*(a)∣ is bounded almost
surely, for a ∈ {0,1}. Assume Pr(∣^>(X)(βι — βo)∣ ≤ E) ≤ LoG for some constant Lo > 0 and
any e > 0. Thenfor any {jn}n that satisfies √jn/ ʌ/log jn 》q2, the following event occurs with
probability at least 1 — O(jn-1),
k
X EFiT X{∏i-i(a,X) — ∏*(a,X)} W qpk log k, ∀k ≥ jn
a∈{o,1}	i=1
Lemma 2 implies that Condition equation 5 in Theorem 1 automatically holds with αo = 1/2, when
the epsilon-greedy strategy is used. When 夕>(X )(βι — βo) is a continuous random variable, the
assumption Pr(∣q>(X)(βι — βo)∣ ≤ E) ≤ Loe for any e > 0 in Lemma 2 is satisfied if 夕>(X)(βι —
βo) has a bounded probability density function. When 夕 >(X )(βι — βo) is discrete, this assumption
is satisfied if infx∈χ 3>(x)(βι — βo)∣ > 0.
12
Under review as a conference paper at ICLR 2021
D Testing the average treatment effects
D.1 The algorithm
We focus on testing the following hypothesis,
Ho : EYi*(1) ≤ EYi*(0) versus Hi : EYi*(1) > EYi*(0).
Under (A1) and (A2), it suffices to test
H0 : EQ(Xi, 1) ≤ EQ(Xi,0) versus H1 : EQ(Xi, 1) > EQ(Xi,0).
We similarly use basis approximations to model the Q-function. Our proposal is summarized in the
following algorithm. We next conduct simulation studies to evaluate this algorithm.
Input: Number of bootstrap samples B, an a spending function α(∙).
Initialize： n = 0, ςo = ςi = Op+1, γ0 = bbi = 0p+1, Bθ,b = β1,b = 0p+1,2=0 and a set
I = {1, . . . ,B}.
For k = 1 to K do
Initialize: m = 0, φ = 0 and Φ0 = Φ1 = Op+1.
Fori = N(tk-1) +1 to N(tk) do
n = n + 1, m = m + 1 and 中=n-1(n — 1)Cρ + n-i4(Xi);
∑a = (1 一 n-1)∑a + n-i2(Xi)夕>(Xi)I(Ai = a), a = 0,1;
Aa = (1 一 n-1 )Ya + n-1 2(Xi)YiI(Ai = a),a = 0, 1;
Compute βa = Σ-1 Ya for a ∈ {0,1} and S = O>(βι — βo);
For i = N (tk-1) + 1 to N(tk) do
φ = φ + [{^(Xi) — 0}>(γι- γo)]2.
Φ a = Φ a + ∑-%(XiW>(Xi){Yi — 3>(Xi )βa}2∑-1I(Ai = a),a = 0,1;
Forb= 1,. ..,Bdo
Generate two independent N(0, Ip+1) Gaussian vectors e0, e1, N(0, 1) random variable e2;
βa,b = (1 — mn-1)βa,b + n-1ΦY/ea + n-1γ1/2e2, a = 0,1;
>
Compute Sb = " (βι,b — βo,b);
. ,，、 ., ., ,, , ^ ,
Set z to be the upper {α(t) — |I|c/B|}/(1 — |Ic|/B)-th percentile of {Sbb}b∈I;
Update I as 工一{b ∈I: Sb ≤ ζ}.
If S > z :
Reject H0 and terminate the experiment;
D.2 Numerical studies
In this section, we compare our procedure with the always valid test for testing ATE (Johari et al.,
2015). We generate the potential outcomes with the same model, except that εi's are i.i.d N(0,1).
However, we set N(T1) = 1000 and N(Tj) — N(Tj-1) = 2n for 2 ≤ j ≤ K and some n > 0.
We consider two combinations of (n, K), corresponding to (n, K) = (100, 5) and (10, 50). For all
settings, we use a linear function to approximate Q.
In Table 2 (see Appendix G) and Figure 4, we show the rejection probabilities and average stopping
times of the proposed test aggregated over 400 simulations, when ɑι(∙) is chosen as the spending
function. It can be seen that our method behaves better than the always valid test when the effect
size is small, and comparable when the effect size is large. The always valid test fails in the adaptive
randomization settings, as the type-I error rates are around 50% under the null hypothesis.
E Proofs
Note that we require X to be a compact set. To simplify the proof, we assume X = [0, 1]d.
13
Under review as a conference paper at ICLR 2021
SrRandom
SrAdaptive
S2-Random
ιoo
T- BAT(200,5)
BAT(20,50)
AVT(200,5)
AVT(20,50)
T- BAT(200,5)
BAT(20,50)
f∙ AVT(200,5)
AVT(20,50)
十 BAT(200,5)
BAT(20,50)
T AVT(200,5)
AVT(20,50)
80
S
1 60
Figure 4: Rejection probabilities and average stopping times of the proposed test When α1 (∙) is
chosen as the spending function.
BAT(200,5)
-▼ BAT(20,50)
-∙- AVT(200,5)
AVT(20,50)
S2-Adaptive
E.1 Proof of Lemma 1
Set F0 = 0. We state the following lemma before proving Lemma 1.
Lemma 3 Forany j ≥ 1, (Xj ,Yj (0),γ* ⑴)⊥ Fj--i.
For any a ∈ {0, 1}, i ≥ 1, notice that
EI(Ai = a){Yi - 夕>(Xi)βa} = EI(Ai = a){Yi*(a)-夕>(Xi)βa}
=EEXi,Fi-1 [I(Ai = a){Yi* (a) - 夕>(M)βa}],
where the first equation is due to Assumption (A1) and EXi,Fi-1 denotes the conditional expectation
given Fi-1 and Xi. By Assumption (A2), we have
EXi,Fi-1 [I(Ai = a){γi*(a) — 夕>(&厩}] = {EXi,Fi-1 I(Ai = a)}[EXi,Fi-1 {Yi*(a)-夕>(X,)βa}].
The second term on the RHS equals zero due to Lemma 3 and our model assumption
E{Yi* (a)∣Xi} = φγ (Xi )βa. The proof is hence completed.
E.2 Proof of Theorem 1
Let n(∙) be the realization of the counting process N(∙). We will show the assertion in Theorem 1
holds for any such realizations that satisfy n(t1) < n(t2) < ∙ ∙ ∙ < n(tK). The case where some of
the n(tk)’s are the same can be similarly discussed.
For any j ≥ 1, define σ(Fj) to be the σ-algebra generated by Fj. For a ∈ {0, 1}, define
∑a,j = 1 XX I(Ai = a)φ(Xi)φ>(Xi) and ‰ = Σ-,j (1 X I(Ai = a)φ(X,)Yi).
j i=1	j i=1
^
^
ʌ
ʌ
α
It is immediate to see that Σa(t) = Σa,n(t) and βa(t) = βa,n(t) . Define δn = qn-α0 logα0 n. We
state the following lemmas before proving Theorem 1.
Lemma 4 There exists some constant 0 <	0 < 1 such that λmin [Eφ(X)φ> (X)] ≥	0,
λmaχ[E φ(X )φ> (X)] ≤ 6-1, SUPx ∣∣φ(x)∣∣2 ≤ SUPx kφ(x)kl ≤ e-1 √q, mina∈{0,1} λmin [Σa ] ≥
e0, maxa∈{0,1} kβa k2 ≤ 6-1, maxa∈{0,1} IY * (a) | ≤ 6-1 and SUPx maxa∈{0,1} — (x)βa | ≤ 6-1 ∙
Lemma 5 Assume the conditions in Theorem 1 hold. Then for any sequence {jn }n that satisfies
jnα0 / logα0 (jn) q2, we have with probability at least 1 - O(jn-α0) that for any a ∈ {0, 1} and
14
Under review as a conference paper at ICLR 2021
any k ≥ jn,
k(Σ a,k — ∑a)k2 W qδk + PqkTlOg k,
k(∑-,k — ∑-1)k2 W qδk + PqkTlOg k.
(14)
(15)
Lemma 6 Assume the conditions in Theorem 1 hold. The for any sequence {jn }n that satisfies
jn/ lOg(jn)	q, we have with probability at least 1 — O(jn-1) that for any a ∈ {0, 1} and any
k ≥ jn,
k
X 以Xi)I(Ai = a){Yi — 3>(Xi)βa}	W Pqk log k.
i=1	2
Fora ∈ {0, 1},
1
βa,k — βa = ∑-1 k EI(Ai = a)φ(Xi){Yi — φτ(Xi)βa}
i=1
and hence
βba,k — Ba — ς-1 k ^X I(Ai = a)φ(Xi){γi — 3> (Xi)β°} J
(16)
≤
W
1 k
IIς a,k — 夕—1心 k EI(Ai = a)φ(Xi){γi — 夕 > (Xi)βa}
i=1	2
(qδk + ,qk-1 log k)q1∕2k-1∕2 log1/2 k, ∀k ≥ jn,
with probability at least 1 — O(jn-α0), by Lemma 5 and Lemma 6. Define
1	n(t)
B *⑴=r~r~^ £[夕—1夕(Xi)Ai {Yi — 夕 >(Xi)β1} — "-1夕(Xi)(I- Ai){Yi — 夕 >(Xi)尸0}].
n(t) i=1
It follows that
kB*(tk) — B(tk)k2 W {q3∕2δn(tk) + qPn-1 (tk)logn(tk)}n-1/2(tk)log1/2 n(tk),∀k ≥ 1, (17)
with probability at least 1 — O(n-α0 (t1)), and hence
k Sup2>(x)B*(tk) — SuP2>(x)B(tk)∣∣2 ≤ c{q2δn(tk) + q3∕2pn-1(tk)logn(tk)}pn-1(tk)logn(tk),
x∈X	x∈X
∀k ≥ 1,
With probability at least 1 — O(n-ɑ0 (t1)), for some constant c > 0, by equation 41. Under the given
conditions on q and n(t1 ), we have
qPnT(tk)logn(tk) = o(1),	∀k ≥ 1,
and hence
k SupP>(x)B*(tk) — supP>(x)B(tk)∣∣2 ≤ c{qδn(tk)+ PqnT(tk)logn(tk)}, ∀k ≥ 1,
x∈X	x∈X
Thus, for any given z1, z2, . . . , zK, We obtain
Pr < max ( sup夕>(x)B*(tk) — zk,- I ≤ 0 — — O(n-α0(t1))
k∈{1,...,K} x∈X
≤	Pr	max	(Sup夕丁(x)B(tk) - Zk) ≤ 0∖	(18)
k∈{1,...,K} x∈X
≤	Pr	max	(Sup夕>(x)B*(tk) — Zk,+) ≤ 0∣	+ O(n-α0(t1)),
k∈{1,...,K} x∈X
15
Under review as a conference paper at ICLR 2021
where
Zk,- = Zk — c{qδn(tk) + √qn-1(tk)log n(tk)},
Zk,+ = Zk + c{qδn(tk)+ √qn-1(tk )log n(tk) }∙
For any i ≥ 1, 1 ≤ k ≤ K, define a q-dimensional vector
ξi,k
[Σ-%(Xi)Ai{匕
—φτ(Xi)βι} — ∑-1 以Xi)(1 — Ai){Yi — 3>(Xi)βo}]I(i ≤ n(tk)),
or equivalently,
ξi,k
[Σ-Z(Xi)Ai{4⑴—^>(Xi)βι} — ∑-1φ(Xi)(1 — Ai){Y∏0) —。>(Xi)βo}]I(i ≤ n(tk)),
by Condition (A1). Let ξi = (ξ>1,ξ>2,…，ξ>κ)> and Mj = Pi=I ξi. The sequence {Mi}i≥ι
forms a multivariate martingale with respect to the filtration {σ(Fi) : i ≥ 1}, since
E(ξi,k |Fi) = [{E(ξi,k∣Ai,Xi, Fi)}∣Fi]=0,
by (A2). Let n(t0) = 0. For any i such that n(tk-1) < i ≤ n(tk) for some 1 ≤ k ≤ K, we have
kξik∞ ≤
{k∑-%(Xi){Yi* (1) —
3>(Xi)β1}k2 + k∑o⅜(Xi){*(0) — 3>(Xi)β0}k2}
≤ 4√qn-1∕2(tk)e-3,
where the second inequality is due to Lemma 4. Therefore,
q3/2
Ekξik∞ W -3⅛77τ∙
∞	n3/2(tk)
It follows that
n(tK)	K	n(tk)	K
X Ekξik∞ = X X	Ekξik∞ W q3/2 X n(tk"∖1	(19)
∞	∞	n3/2 (tk)
i=1	k=1 i=n(tk-1)+1	k=1
≤ -3ff= + q3/2 X n(tk」「1 ≤ q3∕2nT∕2(tl) + q3/2 ∕+∞ x-3∕2dx = 3产31/2(tι).
√n(tι)	k=2	n3/2(tk)	Jn(t∖)
Define a sequence of independent Gaussian vectors {ηi}i≥ι that satisfy η 〜 N (0,E(ξiξ>∣Fi-ι))
for any i ≥ 1. Then the distribution of ηi is the same as
(I(i ≤ n(tι)) Z> I(i ≤ n(t2)) Z> …I(i ≤ n(tK)) Z>!
where Z is a p-dimensional mean-zero Gaussian vector with covariance matrix
Cov[ E Σ-%(Xi)I(Ai = a){Yi*(a) — d(Xi)βa}∣Fi-i]	(20)
a∈{0,1}
= X ∑-1E3(XiW>(Xi)I(Ai = a){Yi*(a) — d (Xi)βa}2 ∣Fi-i]∑-1
a∈{0,1}
= X ∑-1Eg(XiW> (Xi )I( Ai = a)σ2(a,Xi)∣Fi-i}Σ-1
a∈{0,1}
=X ∑-1E{3(XiW>(Xi)∏i-i(a,Xi )σ2 (a,Xi)∣Fi-i}Σ-1
a∈{0,1}
≡ X ∑-1EFi-1 ∏i-i(a,X )σ2(a,X W(X W>(X )∑-1,
a∈{0,1}
16
Under review as a conference paper at ICLR 2021
where the second equality follows from (A2) and Lemma 3, the third equality is due to the definition
of πi-1 and the last equality follows from Lemma 3.
Similar to equation 19, we can show that
n(tK)
X Ekηik3∞	q3/2n-1/2(t1).	(21)
i=1
Using similar arguments in equation 20, we can show that for any 1 ≤ k1 ≤ k2 ≤ K ,
n(tK)
X E{ξi,k1 ξi>,k2 |Fi-1}
i=1
n(tk1 )
X X ∑-1EFi-1 ∏i-i(a,X )σ2(a,X W(X W>(X )∑-1.
i=1 a∈{0,1}
Let
V (k1, k2)
1
1
n(tk1 )
XX
i=1 a∈{0,1}
n(tk1 )
Σa-1ΦaΣa-1
i=1 a∈{0,1}
∑-1EFi-1 ∏*(a, X)σ2(a, X)中(X)ψ>(X)∑-1
∙≡ acXj-MX
Consider an arbitrary sequence of Rp+1 vectors {bk}1≤k≤K. Under the given conditions, we have
n(tK)
b>ι { X E(ξikξ>k2Fi-1) — V(k1,k2)卜2
n(tk1 )
W ɪʒ X X EFi-1 {πi-ι(a,X) — π*(a,χ)}σ2(a,XW(Xw>(χ)
n(tk1)a∈{0,1} i=1
Define a matrix V as
/ V(1,1)	V(1,2)	...	V(1,K) \
I V(2,1)	V (2, 2)	...	V (2, K)
V =	.	.	.
..	.
..	.
V(K,1) V(K,2) ... V(K,K)
It follows that
n(tK)
X E(ξiξ>Fi-ι)- V
i=1
2
W sup
a∈{0,1}
j≥n(t1)
kbk1 k2kbk2k2.
2
(22)
1j
「 EEFiT {∏i-i(a, X) — π*(a, X)}σ2(a, XW(X)^>(X)
j
i=1	2
Using similar arguments in proving equation 14, we can show the RHS of the above equation is
upper bounded by
0- q sup
a∈{0,1}
x∈X,j≥n(t1)
1
j
j
f{∏i-i(a,x) — ∏*(a,x)}
i=1
and hence by 0-2qδn(t1), with probability at least 1 — O(n-α0 (t1)). Therefore, we have
n(tK)
λmin V + δn(t1)IKp×Kp — X E(ξiξi> |Fi-1) ≥ 0,	(23)
i=1
with probability at least 1 — O(n-α0 (t1)), where IKp×Kp denotes a Kp × Kp identity matrix.
17
Under review as a conference paper at ICLR 2021
Moreover, notice that
sup
a∈{0,1}
x∈X,j≥n(t1)
1j
^∑?{∏i-i(a,x) — ∏* (a,x)}
j
i=1
is bounded between 0 and 1. For any a ∈ {0, 1} and any z > 0, we have
E sup
a∈{0,1}
x∈X,j≥n(t1)
1j
-E{∏i-l(a, x) — ∏*(a, x)}
j i=1
/
≤ E sup
a∈{0,1}
x∈X,j≥n(t1)
/
+ Pr
sup
a∈{0,1}
x∈X,j≥n(t1)
j
^~^{∏i-i(a, x) — π*(a,x)} I
i=1
1j
^∑S{∏i-i(a, X)— ∏
j i=1
λ (a,x)}
sup
a∈{0,1}
x∈X,j≥n(t1)
>z
1j
-V"{∏i-i(a,x) — ∏*
j
i=1
(a, x)} ≤ z
1
j
Under the given conditions, we have
E sup
a∈{0,1}
x∈X,j≥n(t1)
Therefore, we obtain
or
1j
-y^{∏i-i(a,x) — π*(a,x)} W，以⑴ + O(n-α0 (tι))∙
j i=1
n(tK)
X E(ξiξ>∣Fi-ι) - V
i=1
E
E
n(tK)
X E(ξiξ>∣Fi-ι)- V
i=1
qδn(t1 ) ,
2
(24)
since n-α0 (t1)	δn(t1). Combining equation 19 with equation 21, equation 23 and equation 24,
an application of Theorem 2.1 in Belloni & Oliveira (2018) yields that
∣Eψ(Mn(tκ))- Eψ(N(0,V))|
W c0(ψ)n-α0 (tι)+ c2(ψ)qδn(t1) + c3 (ψ)q3/2 n-1/2(ti),
for any thrice differential function ψ(∙), and
co(ψ) =	sup	∣Ψ(z)	—	Ψ(z0)∣	and	Ci	= SUp E	|3无∂j?…∂jψ(z)∣,i =	2, 3,
z,z0∈RρK	z∈RpK j …j.
where ∂jg(z) denotes the partial derivative ∂g(z)∕∂z(j) for any function g(∙) and z(j) stands for the
j -th element of z.
Let Xk,0 be an ε-net of X that satisfies the following: for any x ∈ X, there exists some x0 ∈ X0
such that kX — x0k2 ≤ ε. Set ε = √d∕n4(tι). Since X = [0,1]d, there exists some X。with
|X0| ≤ n4d(t1),
where |X0| denotes the number of elements in X0. Under Condition (A3), we have
SUp inf kΨ(x) — Ψ(x0)k2 W -47qτ∙
x∈X x0∈X0	n4(t1)
(25)
(26)
18
Under review as a conference paper at ICLR 2021
It follows that
sup | sup 夕>(x)ν — sup P>(x)ν∣ W WqV	(27)
kνk2=1 x∈X	x∈X0	n4(t1)
Using similar arguments in showing equation 17, we can show the following event occurs with
probability at least 1 — O(n-1(t1)),
kB*(tk)k2 W q1/2 log1/2 n(tk), ∀k ≥ 1.
This together with equation 27 yields
max	sup夕>(x)B*(tk) — max sup 夕>(x)B*(tk)
k∈{1,...,K} x∈X	k∈{1,...,K} x∈X0
≤
max	sup 夕 >(x)B*(tk) — sup 夕 >(x)B *(tk)
k∈{1,...,K} x∈X	x∈X0
W q log n1∕2(tκ)
_ -n4(t1)-
with probability at least 1 — O(n-1(t1)).	Under the given conditions, we have n(t1)
max(q, logn(tκ)). It follows that there exists some constant c* > 0 such that
max	sup 夕 >(x)B*(tk) — max sup 夕>(x)B*(tk)∣ ≤ c*n-2(t1),
k∈{1,...,K} x∈X	k∈{1,...,K} x∈X0
with probability at least 1 — O(n-1(t1)).
Define
zk,- = Zk — c{qδn(tk) + √qn-1(tk )log n(tk)} — c*n-2(tι),
zk,+ = Zk + c{qδn(tk) + √qn-1(tk )log n(tk)} + c*n-2(tι).
Combining equation 28 with equation 18 yields
Pr max sup 3>(x)B*(tk) — zk,- ≤ 0 - — O(n-α0 (tI))
k∈{1,...,K} x∈X0	,
≤ Pr < max	(SUP 夕> (x)B(tk) — Zk) ≤ 0
k∈{1,...,K} x∈X
(28)
(29)
≤ Pr max sup 夕>(x)B"(tk) — zk + ) ≤ 0 + + O(n-α0(tι)).
k∈{1,...,K} x∈X0	,
Notice that Mn(tκ)= {Bk(tι)>, Bk(t/)>,…，Bk (tκ)>}>. By equation 26 and Lemma 4, there
exist a set of vectors	d1, d2, . . . ,	dL	∈	RqK	with L ≤	n4d(t1)K, maxj	kdj k1 ≤	0-1q1/2	and a
function k(∙) that maps {1,..., L} into {1,..., K} such that
max s sup P>(X)Bk(tk) — Vk '=max {d>Mn(")— Vk(j)},	(30)
k∈{1,...,K} x∈X0	1≤j≤L
for any {νk}kK=1. For any η > 0, m ∈ RqK, consider the function φη,{νk}k : RqK → R, defined as
φη,{νk}k(m) = η1log JX exp[η{d>m 一 ηνk(j)}]卜
It has the following property:
max {dj>m — νk(j)} ≤ φη,{νk}k (m) ≤ max {dj>m — νk(j)} + η-1 log L
≤	max {dj>m — νk(j)} + η-1{log K + 4dlogn(t1)}
=	max [dj>m — {νk(j) — η-1 log K — η-14d log n(t1)}].
19
Under review as a conference paper at ICLR 2021
It follows that
Pr {k∈maxκ} GUyτ(X)B*(tk)- zk J ≤ 0} ≤ Pr{φη,{*}k(MM(K)) ≤ 0},	(31)
Pr < max ( sup 夕>(x)B*(tk)—戏_ ) ≤ 0
[k∈{1,…,K} ∖χ∈Xo	,)
Pr J max S sup ψτ(x)B^(tk) —(zk- - 3δ
[k∈{1,...,K} ∖χ∈%o	,
(32)
≤ 3δ ≥Pr{φη,{zK-}k(Mn(tκ)) ≤ 3δ},
where
zk*+ = zk,++n-1{iog K+4dlog mt。} and zk*- = zk,-- 3δ∙
The value of δ will be specified later. In addition, with some calculations, we have
PL=Idj) exp (n[dJm - ν⅛(i)D
PL=I exp (n[d)m - νk(i)D '
ηPL=IdjI)d(j2) exp (n[⅜rm - νk(i)])
PL=I exp (n[dJm - νk(i)])
—
∏l = 1,2 {∑i=1 d(jl) exp (n[dτm — Vk(i)])}
η
{∑L=1 eχp (η[dτm - νk(i)D O
d31 %2 %3 Φη,{νk }k (m)
—
×
+
η2 PL=I d"d"d" exp (n[⅜rm - νk(i)])
PL=I exp (nKrm - νk(∙d)
„ { PL=I d"d" exp (n[⅛r m - νk(H)}
3n2"t~(~Z----------------------s~~-
{PL=I exp (n[d> m - νk(H)}
{p3d(j3) exp(n[d]m -νk(i)])}
{PL=1 exp (n[dJm - νk(i)])}
2 2 ∏l=1,2,3 (PL=I dj exp (n[dτ m - νk(i)]))
{p3 exp (n⅛r m - νk(i)D }
Since max^ IldikI ≤ e-1q1/2, We obtain that
E 向φη,{νk}k(m)l ≤ e-1q1∕2, E ld7-1 %2φη,{νk}k(m)l ≤ 23-2q,	(33)
j	j1,j2
E %%2%3φη,{νk}k(m)| ≤ 6n2e-3q3∕2∙
j1,j2 ,j3
By Lemma 5.1 of Chernozhukov et al. (2016), for any δ > 0, there exists some function g6 (∙) : R →
R with ∣∣gδ∣∣∞ ≤ δ-1, ∣∣gδ'k∞ ≤ K0δ-2, ∣∣g∕k∞ ≤ K0δ-3 for some constant K0 > 0 such that
I(z0 ≤ 0) ≤ gδ(z0) ≤ I(z0 ≤ 3δ), ∀δ ∈ R∙
It follows that
I(Oη,{νk}k (m) ≤ 0) ≤ g θ φη,{νk}k (m) ≤ I(Oη,{νk}k (m) ≤ 3δb
for any m ∈ RqK. Combining this together with equation 30, equation 31 and equation 32, we
obtain that
Prl	max	( sup 3τ(X)Bk(tk) - zk,+ ) ≤ 0∖ ≤ Egδ θ φη,{*+}k (Mn((K)), (34)
lk∈{i,...,κ} ∖χ∈X0	)	J	k,十
PrL max□ ( sup 3(X)B*(tk )-zk,-) ≤ 0] ≥ Egδ θ φη,{zk*-}k (Mn((K ))∙ (35)
lk∈{i,...,κ} ∖x∈X0	)	J	k,-
20
Under review as a conference paper at ICLR 2021
Consider the function gδ o φη,{yk∣fc. Apparently, we have
suP c0(g(5 0 φη,{νk}k ) ≤ L
δ,η,{νk}k
By equation 33, we can show that
(36)
sup c2(gδ 0 φη,{νk}k) W δ-2q + δ-1ηq,
δ,η,{νk}k
sup c3(gδ 0 φη,{νk}k) W δ-3q3/2 + δ-2ηq3/2 + δ-1η2q3/2.
(37)
δ,η,{νk }k
Set δ = η-1{log K + 4dlog n(t1)}, we obtain
sup Ci(gδ 0 φη,{νk}k) W q"2ηi{logi K + logi n(tι)}, i = 2, 3.
η,{νk}k
Combining equation 37 together with equation 25 and equation 36 yields
suP IEgδ θ φη,{νk}k (Mn(tK )) — Egδ θ φη,{νk }k (N(0, V ))1
δ,η,{νk }k
W n-1∕2(tι)q3η3{log3 K + log3 n(t1)} + q2η2{log2 K + log2 n(t1)}δn(tι) + n-α° (tι).
This together with equation 34 and equation 35 yields
Pr{ max	suP 夕T(X)BYtk)-戏,十 ≤ 0} - Egδ o φη,{zk*+}k(N (0,V))	(38)
k∈{ 1 K } ∖2UN'	k	k,+
k∈{i,...,κ} v∈X0
W n-1∕2(t1)q3η3{log3 K + log3 n(t1)} + q2η2{log2 K + log2 n(t1)}δn(t1) + n-a0 (t1),
Egδoφη,{%*-}k(N(O,V))-Prv∈m,axκ}(XuP0。T(X)B*(tk-'J≤0)	(39)
,x∈X0
W n-1∕2(t1)q3η3{log3 K + log3 n(t1)} + q2η2{log2 K + log2 n(tι)}δn" + n-α0 (t1).
Similar to equation 31-equation 35, we can show
≤
≥
Egδ o φη,{*}k (N(0,V)) ≤ Pr (φη,{叫}k (N(0,V)) ≤ 3δ)
Pr (ιm脸{d>N(0, V)-戏 j),+ } ≤ 3δ) = Pr (四脸{d>N(0, V)-哪；),十} ≤ 0
∖1-j—	≤	∖j-J-
Egδ o φη,{成-}(N(0, V)) ≥ Pr (φη,{需-}k(N(0, V)) ≤ 0)
Pr (—笠{dTN(0, V)-戏 j),-}≤ 0),
where
戏；=N+ + η-1{logK + 4dlogn(tι)} + 3δ and 戏:-=戏,—-η-1{logK + 4dlogn(tι)} — 3δ,
for each k. Notice that for any {νfc}k, we have
Pr < max ( sup 夕T(X)G(tk) — Vk) ≤ 0 > = Pr
[k∈{1,...,K} ∖χ∈X0	J j )	∖1-j-L
This together with equation 38 and equation 39 yields
-Vkj)} ≤ 0
Pr max sup。T(X)B*(tk)-或+	≤ 0 -Pr , max ( sup yT(x)G(tk) — Z谓)≤ 0
V∈{1,...,K} U∈Xe	k, + ) ~ J	V∈{1,...,K} U∈Xe	k, + ； ^
W n-1∕2(tι)q3η3{log3 K + log3 n(t1)} + q2η2{log2 K + log2 n(tι)}δn" + n-α0 (t1),
Pr v∈maxκ} UvT(X)G(tk)-需-)≤0)-Pr v∈maxκ} UlP.。T(X)B *(tk)- zkJ ≤0/
W n-1∕2(tι)q3η3{log3 K + log3 n(t1)} + q2η2{log2 K + log2 n(t1)}δn(tι) + n-o0 (tι).
21
Under review as a conference paper at ICLR 2021
In view of equation 29, we have shown that
PrI max	(Supω>(x)B(tk) — Zk) ≤ 0 > — Prl max (Sup ω>(x)G(tk) — zV+
k∈{1,...,K} x∈X	k k	k∈{1,...,K} x∈X0	k	k,+
W n-"(tι)q3η3{log3 K + log3 n(tι)} + q2η2{log2 K + log2 n(t1)}δn(t1) + n-α0 (tι),
PrI max (Sup ω>(x)G(tk) — Z茸：)≤ 0 > — PrI max (Supω>(x)B(tk) — Zk
k∈{1,...,K} x∈X0	k k,-	k∈{1,...,K} x∈X	k k
W n-"(tι)q3η3{log3 K + log3 n(tι)} + q2η2{log2 K + log2 n出)}6做h)+ n-α0 (tι),
The covariance matrix Cov(G(tk)) is given by Pa∈{0,1} Σa-1ΦaΣa-1 and is nonsingular by Lemma
4. In addition, We have k夕(χ)∣∣2 ≥ c, ∀x ∈ Xo, by Condition A3. Thus, there exists some constant
c* > 0 such that
c* ≤ 3>(X) ( X £-1孔£-1)	3(X), ∀χ ∈ X0.
a∈{0,1}
By Theorem 1 of Chernozhukov et al. (2017), We obtain that
Pr < max S sup P>(x)G(tk) — Zk=+ ) ≤ 0 > — Pr < max S sup P>(x)G(tk) — z%*- ) ≤ 0 >
k∈{1,...,K} x∈X0	,	k∈{1,...,K} x∈X0	,
W η-1{logK + logn(tι)}3/2 + qδn(t1){logK + logn(tι)}1/2 + PqnT(tι) logn(tι){log K + logn(tι)}1/2.
Thus, We obtain
Pr max	Sup 3> (X)B(tk) — Zk ≤ 0 — Pr max	Sup 3> (X)G(tk) — Zk ≤ 0
k∈{1,...,K} x∈X	k∈{1,...,K} x∈X
W n-"2(tι)q3η3{log3 K + log3 n(tι)} + q2η2{log2 K + log2 n(tι)}δn0) + n-α0 (tι)
+ η-1{log K + log n(tι)}3/2 + qδn(tι) {log K + log n(tι)}1/2 + pqn-1(tι)log n(tι) {log K + log n(tι)}1/2.
Setting η = min(q-3/4n1/8(ti)log-3/8{Kn(ti)}, q-1n-a0/3(ti)log-a0/3-1/6{Kn(ti)}) yields
the desired results. The proof is hence completed.
E.3 Proof of Lemma 3
The assertion trivially holds for j = 1. We prove it holds for any j ≥ 2, by induction. By (A2),
wehave (Xj,γ*(0),γ*(1)) ⊥ Ai∣Xι. Since (Xj,γ*(0),γ*(1)) ⊥ (Xi, %*(0), Y=⑴),thisfur-
ther implies (Xj, Yj= (0), Yj= (1)) ⊥ A1 and hence (Xj, Yj= (0), Yj= (1)) ⊥ (X1,A1,Y1= (0), Y1= (1)).
By (A1), Yi is completely determined by Ai, Yi= (0) and Yi= (1). Therefore, we obtain
(Xj,Yj= (0), Yj= (1)) ⊥ Fi.
Suppose we have shown that (Xj, Yj= (0), Yj= (1)) ⊥ Fk for some k < j — 1. To prove
(Xj, Yj= (0), Yj= (1)) ⊥ Fk+i, it suffices to show (Xj, Yj= (0), Yj= (1)) ⊥ (Xk+i,Ak+i,Yk+i).
By (A1), Yk+i is determined by Ak+i, Yk=+i(0) and Yk=+i(1). Since (Xj, Yj= (0), Yj= (1)) ⊥
(Xk+i, Yk=+i(0), Yk=+i(1)), it suffices to show (Xj, Yj= (0), Yj= (1)) ⊥ Ak+i. This is implied by
(Xj,Yj=(0),Yj=(1)) ⊥ Ak+i|Xk+i, Fk and that (Xj,Yj=(0),Yj=(1)) ⊥ Xk+i, Fk. The proof is
hence completed.
E.4 Proof of Lemma 4
The assertions
0 ≤ λmin[E3(X)3> (X)] ≤ λmax[E3(X)3> (X)] ≤ 0-i,	(40)
and
SUp I∣3(x)k1 ≤ e-1√q,	(41)
x
22
Under review as a conference paper at ICLR 2021
for some 0 <6 < 1 are directly implied by the conditions that λmin[E夕(X)夕>(X)] N 1,
λmaχ[E^(XW>(X)] X 1, SUpx k^(x)kι ≤ e-1√q. Since ∣∣^(x)k2 ≤ ∣∣3(x)k1, we obtain
SUpx Il^(x)k2 ≤ SUpx kfXx)kι ≤ e-1√q.
Under the condition infa,x π* (a, x) > 0, we can similarly show that λmin [∑a] ≥ e° for some ∈o > 0.
Since |Y*(0)∣ and |Y*(1)∣ are bounded, there exists some constant 0 < e0 < 1 that satisfies
maxα∈{o,i} |Y*(a)| ≤ e-1. Notice that 夕>(x)βa = E{Y*(a)∣X = x}. Boundedness of |Y*(a)∣
implies that the conditional mean E{Y*(a)∣X} is a bounded random variable as well. As a result,
we obtain supx∈χ maXɑ∈{o,i} ∣^>(x)βa∣ ≤ e-1.
Notice that βa = Σ-1E夕>(X)Y*(a). Since λmin[∑a] is bounded away from 0, it suffices to show
∣E夕>(X)Y*(a)∣∣2 = O(1), or equivalently,
sup	∣Eν> 夕(X )Y * (a)| = O(1).
ν∈Rp,kνk2=1
By Cauchy-Schwarz inequality, it suffices to show
SUp	E|Y *(a)∣2E∣ν >^(X )|2 = O(1).
ν∈Rp,kνk2=1
Since |Y* (a)| = O(1) almost surely, we have by the condition λmaχ[E夕(X)夕>(X)] = O(1) that
SUp	E∣ν>P(X)|2 = sup	ν>E2(X)g>(X)ν ≤ λmaχ[E2(X)夕>(X)] = O(1).
ν∈Rp,kνk2=1	ν∈Rp,kνk2=1
The proof is hence completed.
E.5 Proof of Lemma 5
E.5.1 Proof of equation 14
Notice that
kj(∑I,j - Σ1)k2 = IXX{Ai3(XiW>(Xi) - EFi-I∏i-ι(1,XW(XW>(X)}|	(42)
+j ∣EFi-1 中(XW>(X) (j XX∏i-ι(1,X) — ∏*(1,X))| .
By Lemma 4, we have
EFiT中(XW>(X) (j XX∏i-ι(1,X) - π*(1,X))| ≤ ε-2qEFiT j X∏i-ι(1,X) — ∏*(1,X)
≤ ε0-2q2j-α0 logα0 j, ∀j ≥jn,
with probability at least 1 - O(jn-α0 ).
Consider the first term on the RHS of equation 42. For any i ≥ 1, define Mi =以 Xi)^>(Xi){Ai —
πi-1(1, Xi)}. Notice that {Mi}i≥1 forms a martingale difference sequence with respect to the
filtration {σ(Fi-1) : i ≥ 2}, since
E3(XiW>(Xi){Ai — ∏i-1(Xi)}∣Fi-1]	(43)
=EFiT [EW(XiW(Xi )>{Ai — ∏i-1(Xi)}∣Fi-1,Xi)] =0,
where EFi,Xi denotes the conditional expectation given Xi and Fi. Here, the first equality is due to
that Xi ⊥ Fi-ι, implied by Lemma 3. Under the given conditions on the basis function 夕(∙)，using
similar arguments in proving Equation (C.15) of Shi et al. (2020b), we can show that the following
event occurs with probability at least 1 — O(j-2),
j
EMi	W pqjlog(j).
i=1	|2
23
Under review as a conference paper at ICLR 2021
Notice that Pk≥j k-2 ≤ j-2 + Pk>j {k(k - 1)}-1 = j-2 + j-1. Thus, the following occurs with
probability at least 1 - O(jn-1),
IXX {Aiψ(Xi)φτ (Xi) - EFiT ∏i-i(1,X W(X W>(X)}	W Pqjlog j, ∀j ≥ jn.	(44)
It follows that
k(∑ 1,k - Σl)k2 W qδk + PqkTlOg k, ∀k ≥ jn,
with probability at least 1 - O(j-α0). Similarly, we can show
k(∑0,k - Σ0)k2 W qδk + PqkTlOg k, ∀k ≥ jn,
with probability at least 1 - O(jn-α0). The proof is hence completed.
E.5.2 Proof of equation 15
When jn satisfies jnα0 / logα0 (jn)	q2, it follows from equation 14 and equation 40 that
λmin [Σb a,k] ≥ λmin [Σa] - kΣb a,k - Σa k2 ≥ 2 ε0, ∀k ≥ jn,	(45)
with probability at least 1 - O(jn-α0). Combining equation 40 with equation 45 and equation 14,
we obtain
..^	-1	-l ..	.. ^	-1	^	-l ..	-	-	-∙^∙	. .. ^	..
k∑ -,k - ∑-1k2 = k∑ -,k(∑ a,k- Σa)∑-1k2 ≤ λmin[∑a]λmin[Σ a,k )∣∣Σ a,k - ∑a∣∣2
W qδk + VZqkTlOg k, ∀k ≥ jn,
with probability at least 1 - O(jn-α0). The proof is hence completed.
E.6 Proof of Lemma 6
For any l ∈ {1,... ,q} and i ≥ 1, define Mi(I)=夕(I)(Xi)Ai{Yi — 夕 τ(Xi)βι}. Here,夕(l) (Xi)
corresponds to the l-th element of 夕(Xi). Similar to equation 43, We can show {Mi(l)}i≥ι forms a
martingale difference sequence with respect to the filtration {σ(Fi-1) : i ≥ 1}. By equation 43, we
have for any l,
E{dl)(Xi)}2 ≤ λmaχ3(Xi)ψτ(Xi)] ≤ e-1.	(46)
Notice that
E{Mi2(l)∣Fi-ι} = E[{dI)(Xi)}2Ai{Yi*(1) - φτ(Xi)β1}2∣Fi-1]
≤ E[{dl)(Xi)}2{Yi*(1) - 3τ(Xi)β1}2∣Fi-i] = Eσ2(1,Xi){dl)(Xi)}2
≤	4e-2E{dl)(Xi)}2 ≤ 4e-3,
where the first equality is due to (A1), the first inequality is due to that A is bounded between 0 and
1, the second equality follows from Lemma 3, the second inequality follows from Lemma 4, and the
last inequality is due to equation 46. It follows that
k
X E{Mi2(l)|Fi-1} ≤4k0-3.	(47)
i=1
Similarly, by (A1) and Lemma 4, we have
kk
X Mi2(l) ≤ 40-2 X{ψ(l)(Xi)}2.	(48)
i=1	i=1
Similar to equation 44, we can show with probability at least 1 - O(j-1) that
k
XM2(l) - E{Mi2(l)∣Fi-1}] W Pqklog k, ∀k ≥ j.
i=1
24
Under review as a conference paper at ICLR 2021
Thus, for any sequence jn that satisfies jrJ log(jn)》q, we have by equation 47 that
k	k
XMi2(I) + XE(Mi2(l)∣Fi-ι} ≤ Ck, Vk ≥ jn,
i=1	i=1
for some constant C > 0, with probability at least 1 - O(j-1). It follows that
Pr ∩ {itMi(l) ∣ ≤ 2pCk log k}
∖k≥jn i=ι
≥
≥
—
Pr ([ ∩ {∣ X Mi(Γ)∖ ≤ 2√C⅛10g⅛} ∖∩1 ∩ {X [Mi2(l) + {M2(l)∣Fi-J] ≤ ck}∖∖
∖(k≥jn i=l	J	(k≥jn i=l	J /
O(j-1) ≥ Pr I J ∩ {X M2(l) + {Mi2(l)∣Fi-1}] ≤ Ck} |) - O(j-1)
∖ lk≥jn i=l	J /
Pr (JU {∣ X Mi(l)∣ > 2√C⅛10g⅛} ∖∩j ∩ {X [Mi2(l) + {此2(1)出-J] ≤ ck}∖∖
∖(k≥jn i=l	J	[ k≥jn i=l	Jl
1 - Pr (J U {∣ X Mi(l)∣ > 2√i⅛10g⅛ }∖∩j ∩ {X [Mi2(l) + {Mi2(l)∣Fi-1}] ≤ ck}
∖(k≥jn i=l	J	[ k≥jn i=l
O(j-1).
By Bonferroni,s inequality and Theorem 2.1 of Bercu & Touati (2008), we have
Pr ( ∩ {∣xMi(Γ)∖ ≤ 2√c⅛iθg⅛} I ≥ I - O(j-1)
∖k≥jn i=l	)
X Pr ({∣ XMi(l)∣ > 2√i⅛10g⅛} ∩j ∩ {XM2(l) + {Mf(∕)∣Fi-1}] ≤ ck0}
k≥jn	∖ i=1	I k0≥jn i=1
≥
1 - O(j-1) - X Pr ({∣XMi(Γ)∖ > 2√i⅛10g⅛} ∩[xM2(l) + {Mi2(l)∣Fi-1}] ≤ Ck])
k≥jn	∖ i=1	Ii=I	J )
≥
1 - O(j-1) - 2 X exp (-4ck;1Ogk) = 1 - O(j-1) - X 2k-2.
k≥jn	'	'	k≥jn
(49)
The last term on the RHS of equation 49 is 1 - O(j-1). To summarize, we have shown that the
following event occurs with probability at least 1 - O(j-1),
∩	| Xk
Mi(l)∣ ≤ 2√cklogk∖ .
k≥jn I i=1	J
By Bonferroni,s inequality, we have
∩ HX以Xi)Ai{匕-d
k≥jn Ul i=1
(Xi)βι}	≤ 2√cqk log k 卜
2
with probability at least 1 - O(j-1/2). Similarly, we can show
∩ HX夕(Xi)(I-Ai){γi-2>(Xi)β0}
k≥jn III i=1
≤ c√qk log k }
2
for some constant c > 0, with probability at least 1 - O(j-1). The proof is hence completed.
25
Under review as a conference paper at ICLR 2021
E.7 Proof of Theorem 3
We state the following lemmas before presenting the proof.
Lemma 7 Assume the conditions in Theorem 3 hold. Then for any sequence {jn}n that satisfies
jnα0 / logα0 jn	q2, we have with probability at least 1 - O(jn-α0) that
IIba,k — βa∣∣2 W q1/2k-1/2Plog k,	∀a ∈ {0, 1},∀k ≥ jn.
Lemma 8 Assume the conditions in Theorem 3 hold. Then for any sequence {jn}n that satisfies
jnα0 / logα0 jn	q2, we have with probability at least 1 — O(jn-α0) that
1 ʌ..................「一	一.…	……,---------
T V I( Ai = a)ψ(Xi)ψγ (Xi){Yi — 3>(Xi)βa}2 — Φa W qδk + q1/2k-1/2 √lθg⅛,
k
i=1	2
∀a ∈ {0, 1}, k ≥ jn .
Similar to the proof of Theorem 1, We will show the assertion in Theorem 3 holds for any n(∙)
that correspond to the realizations of N(∙) that satisfy n(tι) < n(t2) < … < n(tκ). For any
1 ≤ k1≤ k2 ≤ K, define
V(k1,k2) = Pn(tk1)n(tk2)Cov (βMB*(tkι) — βMB*(tkι),βMB*(tk2) — βMB*(tk2)∣{(Xi,Ai,Yi)}+∞)
1 k1	n(tj)
J…XX X	∑-1(tj )I(Ai= a)φ(Xi)φτ (Xi){Yi — 6 (Xi)βa (tj )}2Σ-1(tj),
n(tk1)n(tk2) a=0 j=1 i=n(tj-1)+1
and
(V(1,1)	V (1, 2)	...	V (T,K) ∖
V(2,1)	V (2,2)	...	V(2,K)
..	.
..	.
..	.
Vb (K, 1) Vb (K, 2) ...	Vb(K,K)
We aim to bound the entrywise '∞ norm of V — V where V is defined in equation 22. It
suffices to bound max1≤k1≤k2≤κ suPb1,b2∈Rp+1,kb1k2=∣∣b2k2=1 IbT{V(k1,k2) — V(k1,k2)}b2∣ =
max1≤k1≤k2≤K IV(k1,k2) — V(k1, k2)I2. For any k1,k2, we decompose V (k1, k2) — V(k1, k2)
as
^ , ^ , ^ , , ^ , , ^ . . , ^ . . , .
V(k1,k2) — V(kι, k2) = V(kι, k2) — V*(k1,k2) + V*(kι, k2) — V**(kι, k2) + V**(kι, k2) — V(kι, k2),
where
1
^ ,, ,
V *(k1,k2)
V**(k1,k2)
1 k1	n(tj)
XX	X
∑-1I(Ai = a)^(Xi WT(Xi){Yi — 3>(Xi)βa(tj )}2∑;1,
a=0 j=1 i=n(tj-1)+1
1
1 n(tk1 )
XX
∑-1I(Ai = aW(XiW> (Xi){Yi — 3>(Xi)βa}2∑-1∙
a=0 j =1
By Lemma 4 and Lemma 8, we obtain that
≤
max
1≤k1≤k2≤K
1
max
1≤k1≤K
1 a=0
kV ** (k1,k2) — V (k1,k2)k2
1
n(tkι)
n(tk1 )
X ∑-1I(Ai = aW(XiW>(Xi){Yi — 3>(Xi)βa}2∑-1 — ∑-1
j=1
Φa Σa-1
2
1
≤
max -i-
ι≤kι≤κ 裔 a=o
1
n(tk1)
n(tk1 )
X I(Ai = aW(XiW>(Xi){K — 3>(Xi)βa}2 — Φa
j=1
2
W qδn(tι) + q1/2n-1/2 (t1) √log n(t1),
(50)
26
Under review as a conference paper at ICLR 2021
with probability at least 1 - O(n-α0 (t1)).
Notice that
__________ 1 kι	n(tj)
pnŋnŋV*(kι,k2) = χχ χ	∑-1I(Ai = a)中(Xi)φτ (Xi){Yi - £ (Xi)βa(tj)}2Σ-1
a=0 j=1 i=n(tj-1)+1
1 k1	n(tj)
=XX	X
∑-1I(Ai = a)φ(Xi)φτ (Xi){Yi - 6(Xi) βa + 6(Xi) βa - ψγ(Xi)βa(tj )}2Σ-1
a=0 j=1 i=n(tj-1)+1
1 k1	n(tj)
=XX	X
∑-1I(Ai = aW(XiW>(Xi){3>(Xi)βα - 6 (Xi)βa(tj )}2∑-1
a=0j=1 i=n(tj-1)+1
1 k1	n(tj)
+ 2 XX X	∑-1I(Ai= a)ψ(Xi)ψτ (Xi){Yi - ψτ(Xi)βa}ψτ(Xi){βa - βa(tj )}Σ-1
a=0 j=1 i=n(tj-1)+1
+ Pn(tkι )n(tk2) V**(k1,k2).
It follows that
1≤km≤kx≤K BV""2- V**%,k2)l∣2
≤
1
max
1≤k1≤K n(tk1)
+
2
max
1≤k1≤K n(tk1)
1 k1	n(tj)	B
XX	X
Σ-1I(Ai = a)P(Xi)夕 >(Xi){2 >(Xi)βa —夕 >(Xi)ba(tj )}2Σ-1II
a=0 j=1 i=n(tj-1)+1	B2
1 k1	n(tj)
XX	X
∑-1I(Ai = a)φ(Xi)φτ (Xi){Yi - 6 (Xi) βa}ψT(Xi)(βa - βa(tj ))Σ-1
a=0 j=1 i=n(tj-1)+1
By Lemma 4, we obtain that
ι≤kmax≤KBV*(kι,Q-Vykb^L
(51)

1
max
1≤k1≤K n(tk1)
a∈{0,1}	1
k1	n(tj)
XX
I(Ai = a)φ(Xi')φτ (Xi ){φ> (Xi)βa - φ> (Xi 节“(tj )}2
j=1 i=n(tj-1)+1
Ψ1,a,k1
2
+ max ------------
1≤k1≤K n(tk1)
a∈{0,1}	1
k1	n(tj)
X X	I(Ai = a)P(Xi)夕> (Xi){匕-2>(Xi)βa}夕>(Xi){βa - ba(tj )}
j=1 i=n(tj-1)+1
^^z"∖^^^
Ψ2,a,k1
}
2
By Lemmas 4 and 7, we have with probability at least 1 - O(n-1 (t1)) that
n(ŋ kψ1,a,kιk2 W q2nT(tl)log{n(tl)}
n(tk1 )
——-X I(Ai
n(tkι) i=1
a#(Xi)φ> (Xi)
(52)
2
∀ ≤ k1 ≤ K, a ∈ {0, }.
Similar to Lemma 5, We can show there exists some constant c* > 0 that
1
n(tkι)
n(tk1 )
X [I(Ai = a)φ(Xi)φτ (Xi) - EFiT {I(Ai = a)φ(Xi)φ> (Xi)}]
i=1
(53)
2
≤ c*{qδn(tk1) + q1/2n-1/2(tki)√logn(⅛)}, ∀1 ≤ kι ≤ K, a ∈ {0,1},
27
Under review as a conference paper at ICLR 2021
with probability at least 1 - O(n-1 (t1)). By Lemma 4, we can show with probability at least
1 - O(n-1 (t1)) that
1
max
1≤k1≤K n(tk1)
n(tk1 )
X EFiT {I(Ai = a)中(XiW>(Xi)}	= O(1).
This together with equation 52 and equation 53 yields
n-1(tk1)kΨ1,a,k1 k2	q2n-1(t1)log{n(t1)}, ∀1 ≤ k1 ≤ K,a ∈ {0, 1},	(54)
with probability at least 1 - O(n-1 (t1)).
Moreover, using similar arguments in proving Equation (C.15) of Shi et al. (2020b), we can show
that for any 1 ≤ k1 ≤ K, the following event occurs with probability at least 1 - O(n-2(tk1 )),
1
n(tkι)
n(tk1 )
X I(Ai = a)<AXi)φτ (Xi){Yi - 6 (Xi) βa}d(I(Xi)	W 炉…g ),log n(t®J,
i=1	2
∀1 ≤ l ≤ q.
Since PkK1=1 n-2(tk1 ) ≤ n-1(t1), we obtain with probability at least 1 - O(n-1(t1)) that
1
n(tkι)
n(tk1 )
X I(Ai = a)<AXi)φτ (Xi){Y - 6 (Xi) βa}d(((Xi)
i=1
W q1∕2n-1∕2(tkι )√log n(tkι),
2
∀1 ≤ l ≤ q, 1 ≤ k1 ≤ K.
In addition, it follows from Lemma 7 that
n-1(tk1)kΨ2,a,k1 k2 W	q3/2n-1(t1)	log{n(t1)},	∀1	≤ k1≤	K, a ∈ {0,	1}.
This together with equation 54 yields that
max	IIVb*(k1,k2) - V**(k1,k2)∣∣ W q2n-1(tι)logn(tι),
1≤k1≤k2≤K	2
with probability at least 1 - O(n-1(t1)). Under the given conditions, we have
…吸X" IIVb*(ki,k2) - Vb**(kl,k2)∣∣ W q1/2n-1/2(t1)log1/2 n(tι),	(55)
1≤k1≤k2≤K	2
with probability at least 1 - O(n-1(t1)).
Moreover, with some calculations, we can show that
1
1≤km≤kχ≤K llVb (k1,k2) - V*(k1 ,k2)H2 ≤ X max IIς-1 - ς -1(tj )k2
1 2	a=0
2
max /，、
1≤k1≤K n(tk1)
×
+
×
k1	n(tj(
X X	I(Ai = a)φ(Xi')φτ (Xi ){Yi - 3>(Xi)βa(tj )}2∑-1
j=1 i=n(tj-1(+1
1	1 I k1	n(tj(
X1 max.-^ X X	ς-II(Ai = α⅛(XiW> (Xi){匕-6 (Xi))βa(tj )}2ς-1
a=0 1≤k1≤Kn(tk1) II j=1 i=n(tj-1(+1
2
mj≥a1xIΣa-1-Σba-1(tj)I22.
In view of Lemma 4 and Lemma 5, we have with probability at least 1 - O(n-α0 (t1)) that
，」,max「」|Vb(kl,k2) - Vb*(kl,k2)∣l ≤ O(1)(qδn(tι( + PqnT(tι) logn(tι))
1≤k1≤k2≤K	2
1
max /，、
1≤k1≤K n(tk1)
×
k1	n(tj (
X X	I(Ai = a)φ(Xi)φτ(Xi){Yi - 6(Xi)β(tj)}2
j=1 i=n(tj-1(+1
Ψ3,a,k1
2
28
Under review as a conference paper at ICLR 2021
where O(1) denotes some positive constant. Similar to equation 50 and equation 55, we can show
with probability at least 1 - O(n-α0 (t1)) that
max max	-7l^Ψ3,a,k1 — Ψa = o(1).
a∈{0,1} 1≤k1≤K n(tk1)	,, 1	2
Similar to Lemma 4, we can show maxa∈{0,1} kΨa k2 = O(1). It follows that
1≤kmax≤K 归(k1,k2)- V*(k1，k2”2
W qδn(tι) + VZqn-1(t1) logn(tι),
with probability at least 1—O(n-ɑ0 (t 1)). Combining this together with equation 50 and equation 55,
we obtain with probability at least 1 — O(n-α0 (t1)) that
ι≤km≤αx ≤kBv (k1,k2)- v(k1,k2)∣∣2
W qδn(tι) + VZqn-1(t1) logn(tι).
Consider the function gδ ◦ φη,{νk}k defined in the proof of Theorem 1. We fix δ = η-1{logK +
4dlogn(t1)}. Based on Lemma A2 in Belloni & Oliveira (2018), we have with probability at least
1 — O(n-α0 (t1)) that
sup ∣E*gδ ◦ Φη,{νk}k (N(0, V)) — Egδ ◦ Φη,{νk} (N(0, V))1
{νk}k
W qη2{log2 K + log2 n(tι)} (qδn(tι) + Pqn-1(t1) logn(tι)),
where E* denotes the expectation conditional on the observed data. For a given set of thresholds
{νk}k, using similar arguments in proving equation 31, equation 32, equation 34 and equation 35,
we can show with probability at least 1 — O(n-α0 (t1)) that
Pr*{^max^} (Pn(MSMB* - Vk) ≤ θ} ≤ Ei⅛ ◦ 6%“* (N(O V))
≤ Egδ ◦ Φη,{νk,+}k (N(O, V)) + O(1)qη2{log2 K + log2 n(tι)} (qδn(tι) + pqn-1(tι)log n(tι))
≤ PrL max^ι(suP 3>(x)G(tk) — VkA ≤ 0]
k∈{1,...,K} x∈X0
+ O(i)qη2{log2 K + log2 n(tι)}(9。八出)+ Pqn-I(Tyiogntn),
and
Pr* Ifcemaxχ} (Pnw)SMB* - Vk) ≤ θ} ≥ Ei⅛ ◦。％{“.}%(N(O V))
≥ Egδ ◦ Φη,{νk,-}k(N (O, V)) — O(1)qη2{log2 K + log2 n(tι)} (qδn(tι) + pqn-1(tι)log n(tι))
≥ Pr max (SUP 夕>(x)G(tk) — Vk -∖ ≤ 0 >
k∈{1,...,K} x∈X0	,
— O(1)qη2{log2 K + log2 n(tι)} (qδn(tι) + pqn-1(tι)logn(tι)),
where O(1) denotes some positive constant, and
Vk,+ = Vk + η-1{4d log n(tι) + log K} + c*n-2(tι), νk,+ = Vk,+ + 3η-1{4d log n(tι) + log K},
Vk,- = Vk- 3η-1{4dlogn(tι) + logK} — c*n-2(tι), V* — = vg—η-1{4dlogn(tι)+logK}.
By Theorem 2 of Chernozhukov et al. (2017), we obtain that
Pr < max ( sup 夕>(x)G(tk) — v* + ) ≤ 0 卜—PrI max ( sup 4> (x)G(tk) — Vk-
k∈{1,...,K} x∈X0	,	k∈{1,...,K} x∈X0	,
W η-1{log3/2 n(tι) + log3/2 K} + c*n-2(tι){log1/2 n(tι) + log1/2 K}.
29
Under review as a conference paper at ICLR 2021
It follows that
sup Pr* < max	(pn(tk)SbMB* — Vk) ≤ 0 > — PrI max (SuP夕>(x)G(tk) — Vk
{νk}k	k∈{1,...,K}	k∈{1,...,K} x∈X
W qη2{log2 K + log2 n(tι)} (qδn(tι) + PqnT(tι) logn(tι))
+η-1{log3/2 n(tι) + log3/2 K} + c*n-2(tι){log1/2 n(tι) + log1/2 K},
with probability at least 1 — O(n-α0 (t1)). Set
η = min[qTnα0∕3(tι)log-(1+2α0"6{Kn(tι)}, q-1/2n1/6(ti) log-1/3{Kn(ti)}],
we obtain the desired result.
E.8 Proof of Lemma 7
Combining Lemma 6 with Lemma 4 yields that
∑-1 (1 XI(Ai = a)ψ(Xi){Yi — 3>(Xi)βa})[ W q1∕2k-1/2 Plog k, ∀k ≥ jn,a ∈{0,1},
with probability at least 1 — O(jn-1). Combining this together with equation 16 yields that
kβa,k — βa∣∣2 W q1/2k-1/2Plogk, ∀k ≥ jn,a ∈ {0, 1},
with probability at least 1 — O(jn-1). The proof is hence completed.
E.9 Proof of Lemma 8
Notice that
≤
+
1k
T VI(Ai = aW(XiW>(Xi)(Yi — d(Xi)Ba) — Φa
k
i=1	2
1 k
T VI(Ai = a)φ(Xi)ψτ(Xi)[{Yi — ψ>(Xi)βa}2 — σ2(a, Xi)]
k
i=1	2
1 k
T VI(Ai = aW(XiW>(Xi)σ2(a,Xi) — Φa .
k
i=1	2
(56)
Similar to the proof of Lemma 5, We can show that the second term on the RHS of equation 56 is
of the order O(qδk +，qk-1 log k), for any a ∈ {0,1} and any k ≥ jn, with probability at least
T — O(jn-α0 ). As for the first term, notice that each element in the matrix
1k
T £I(Ai = a)ψ(Xi)ψτ(Xi){(Yi — d(Xi)Ba)2 — σ2(a,Xi)}	(57)
k i=1
corresponds to a martingale with respect to the filtration {σ(Fi-1) : i ≥ T}, under (A1) and (A2).
Using similar arguments in proving Equation (C.15) of Shi et al. (2020b), we can show that
1 k
7 VI(Ai = a)ψ(Xi)ψτ(Xi)[{Yi — ψ>(Xi)βa}2 — σ2(a,Xi)]	W q^k-"√log⅛,
k
i=1	2
∀a ∈ {0, T}, k ≥ jn,
with probability at least — O(jn-1). The proof is hence completed.
30
Under review as a conference paper at ICLR 2021
E.10 Proof of Lemma 2
-.-VT -I ∙ -I	∙ f	F	IC	UA	CU 5 TJl	1 1 . ∙
We begin by providing an upper bound for maxa∈{0,1} kβa,k - βa k2. With some calculations, we
have
1
amaX} kβa,k - βak2 = 0^^} Ii
∑-,k (XX 以Xi)I(Ai = a){Yi - 3>(Xi)βa}) ∣
≤ “maxUbb -,k∣L “ma" 1 ∣XX M)I(Ai=a){Yi-。> (Xi)儿}].
By Lemma 6, we obtain with probability at least 1 - O(jn-1 ) that
1
max —
a∈{0,1} k
k
X φ(Xi)I(Ai = a){Yi — 3>(Xi)βa}	W q1∕2k-1∕2 Plog k,
i=1	∣2
∀k ≥ jn .
(58)
Similarly, we can show with probability at least 1 - O(jn-1) that
1
max —
a∈{0,1} k
k
X 奴Xi)I(Ai = a){K - 3>(Xi)βa}	W q1/…Poj,
i=1	∣2
∀1 ≤ k <jn.
(59)
Similar to equation 42, we have
°maX}λmin[Σ a,k] ≥ min λmin 卜Fi-I 夕(X )^>(X ) 1 X πi-1(a,X )
1 ∣∣ k	∣∣
一max - V"{I(Ai = a)P(Xi)夕>(Xi) — EFiTπi-i(a,X)夕(X)^>(X)}
a∈{0,1} k y
。—
Using similar arguments in proving equation 44, we can show that
max
a∈{0,1}
k
X{I(Ai = a)中(Xi)Q(Xi)- EFiTπi-i(a,XW(X)^>(X)}
i=1
W Vzqk log k,
2
∀k ≥ jn,
(60)
with probability at least 1 - O(jn-1). Similarly, we can show
max
a∈{0,1}
k
X{I(Ai = aW(XiW>(Xi) - EFiT∏i-i(a,XW(X)^>(X)}
i=1
W qkqo log jn,
2
∀1 ≤ k < jn,
(61)
with probability at least 1 - O(jn-1).
Without loss of generality, assume ε0 ≤ 1/2. Notice that we have πi-1(a, x) ≥ ε0, for any a ∈
{0, 1}, x ∈ X and i ≥ N0. This together with Lemma equation 4 implies that
inf λmin (EFiT以XW>(X)1 X∏i-i(a,X)] ≥ n-N0ε° ≥ j---N0ε°.
a∈{0,1},n≥jn	∖	n i=1	J	n	j
Combining this together with equation 60 and equation 61 yields
ε	ε0	τ *
°maX} λmin[∑a,k ] ≥ y, Nk ≥ L √q log jn,
for some constant L* ≥ 1, with probability at least 1 - O(jn-1). This together with equation 58 and
equation 59 yields that
max kba,k - βa∣∣2 W q1/2k-1/2√logmax(k,jn), ∀k ≥ L* Vzqiogjn,
a∈{0,1}	'
31
Under review as a conference paper at ICLR 2021
with probability at least 1 - O(jn-1).
By Condition (A3), we have
|夕>(X)(bι,k —	b0,k	— βι +	βo)∣	≤	Lqk-1/2	log1/2	max(k,jn),	∀k ≥ Lpqlog jn,	(62)
for some constant L > 0, with probability at least 1 — O(j-1).
For any z1, z2 ∈ R, we have I(z1 > 0) 6= I(z2 > 0) only when |z1 — z2 | ≥ |z2 |. Hence, under the
event defined in equation 62, the event I{夕>(X)(βι,k 一 βo,k) > 0} = I{夕>(X)(βι — βo) > 0}
occurs only when
3>(X)(βι — βo)∣ ≤ 3>(X)(βι,k — b0,k — βι + βo)| ≤ Lqk-1/2plogmax(k,jn),
for any k ≥ jn . Under the given conditions, we have
Pr(3>(X)(βι — βo)∣ ≤ Lqk-1/2 log1/2 max(k,jn)) ≤ LLoqk-1/2 log1/2 max(k,jn).	(63)
Notice that when I{夕>(X)(β1,k — βo,k) > 0} = I{夕>(X)(β1 — βo) > 0}, We have
∏k(a, X) = π*(a, X). Thus, we obtain ∏k(a, X) = π*(a, X) if 3>(X)(β1 — βo)∣ >
Lqk-1/2,logmax(k,jn), for any k ≥ L*√qlogjn. Set ko = L*√qlogjn. By equation 62
and equation 63, we have with probability at least 1 — O(jn-1) that
k	k0
X EFiT X{∏i-1(a,X)—∏*(a,X)} ≤ X XEFiT∣∏i-1(a,X)—π*(a,X)|
a∈{0,1}	i=1	a∈{0,1} i=1
k
+ XX EFiT ∣∏i-1(a,X) — ∏*(a,X)| ≤ 2L*Pqlog jn
a∈{0,1} i=k0+1
k
+ XX EFiTni-1(a,X) — ∏*(a,X)∣I{“(X)(β1 — βo)∣ > Lq厂1/2 log1/2 i}
a∈{0,1} i=k0+1
k
+ X X EFiT ∣∏i-1(a,X) — n*(a,X)∣I{"(X)(β1 — βo)∣ ≤ Lqi-1/2 log1/2 i}
a∈{0,1} i=k0+1
n
≤ 2L*√qlog jn + X X Pr(3>(X)(β1 — βo)∣ ≤ Lq厂 1∕2√logi) W qk1/2 log1/2 k, ∀k ≥ jn
a∈{0,1} i=k0+1
The proof is hence completed.
F Comparison of the baseline
Consider our test statistic S(t). Under H0, it can be bounded from above by
SUp ^>(x){∕b1(t) — β1 — βo(t) + βo}.	(64)
x∈X
It suffices to provide an upper bound for the above expression. By Cauchy-Schwarz inequality,
equation 64 can be upper bounded by
.........^ , , ^ ,, ,..
SUP k夕(X) k2kβ1(t) — β1 — βθ(t) + β0 ∣∣2∙
x∈X
τ. r-r`	.	∙ t	. ∙	F	t r∙ 11 'ə' / ,∖ C* jr> ∕ > ∖ C*ll
It suffices to provide anytime upper bound for kβ1(t) — βj — βo(t) — β^ k2.
Recall that
βb1 (t) — β1 — βb0 (t) + β0
1 N(t)
= 和 X [I(Ai = 1)∑-1(t)3(Xi){Yi — 3>(Xi)β;}— I(Ai = 0)∑-1(t)3(Xi){匕—d(Xi)β"]∙
32
Under review as a conference paper at ICLR 2021
The above expression is asymptotically equivalent to
1 N(t)
N(t) X [I(Ai = 1)∑-%(Xi){匕-ψτ(Xi)β↑}- I(Ai = 0)∑-1 ψ(Xi){Yi - 3>(Xi)β"].
By the law of iterated logarithm, the `-th dimension of the above expression can be upper bounded
by
N-1/2 (t) J2σ2 loglog{N(t)},
where p` bj can be consistently estimated by
1 N(t)
Nt) X kI(Ai = 1)∑-1(tW(Xi){Yi - φτ(Xi)βι(t)}- I(Ai = 0)∑-1 (t)φ(Xi){Yi - 3>(Xi)βo(t)}k2∙
As such, the finite error bound is given by
SUp k^(x)k2
x∈X
√2 loglog{N (t)}
√W)
×
∖
N(t)
1
Nt) ∑ kI(Ai = 1)∑-1(tW(Xi){Yi - Ψτ(Xi)β1 (t)}- I(Ai = 0)∑-1(tW(Xi){Yi - ^τ(Xi)βo(t)}k2∙
G Additional tables and figures
		method		BAT						LIL				
			Random		Adaptive		Random		Adaptive	
	(n,K)	δ	rej probs	E[stop]	rej probs	E[stop]	rej probs	E[stop]	rej probs	E[stop]
S1	(200,5)	-0:00- 0.10 0.15 0.20 0.25 0.30	5.0(1.1) 17.2(1.9) 36.0(2.4) 55.8(2.5) 79.5(2.0) 93.2(1.3)	3537(14) 3400(24) 3184(32) 2914(36) 2545(35) 2286(27)	6.2(1.2) 18.5(1.9) 35.5(2.4) 60.0(2.4) 81.5(1.9) 95.2(1.1)	3534(15) 3409(23) 3189(32) 2908(36) 2528(34) 2280(26)	0.0(0.0) 0.0(0.0) 0.2(0.2) 0.5(0.4) 1.8(0.7) 7.2(1.3)	3600(0) 3600(0) 3599(0) 3598(1) 3590(4) 3560(10)	0.0(0.0) 0.0(0.0) 0.0(0.0) 0.8(0.4) 2.8(0.8) 7.5(1.3)	3600(0) 3600(0) 3600(0) 3595(3) 3585(5) 3549(11)
	(20, 50)	-0:00- 0.10 0.15 0.20 0.25 0.30	5.2(1.1) 17.2(1.9) 39.5(2.4) 61.8(2.4) 84.0(1.8) 95.8(1.0)	3879(18) 3716(29) 3394(40) 3021(44) 2588(39) 2281(28)	5.5(1.1) 24.0(2.1) 41.2(2.5) 61.0(2.4) 83.5(1.9) 95.5(1.0)	3882(18) 3651(32) 3365(40) 3013(44) 2579(39) 2275(28)	0.0(0.0) 0.0(0.0) 0.0(0.0) 0.8(0.4) 4.8(1.1) 12.8(1.7)	3960(0) 3960(0) 3960(0) 3949(6) 3919(11) 3847(18)	0.0(0.0) 0.0(0.0) 0.2(0.2) 0.2(0.2) 3.5(0.9) 14.5(1.8)	3960(0) 3960(0) 3958(1) 3956(3) 3936(8) 3873(15)
S1	(200,5)	-0.00- 0.10 0.15 0.20 0.25 0.30	5.0(1.1) 8.8(1.4) 25.5(2.2) 57.2(2.5) 87.2(1.7) 98.0(0.7)	3537(14) 3511(17) 3346(26) 3004(34) 2569(32) 2224(21)	6.2(1.2) 8.8(1.4) 26.0(2.2) 60.2(2.4) 88.2(1.6) 97.8(0.7)	3534(15) 3515(16) 3337(27) 3000(34) 2581(32) 2254(24)	0.0(0.0) 0.0(0.0) 0.0(0.0) 0.0(0.0) 2.0(0.7) 10.2(1.5)	3600(0) 3600(0) 3600(0) 3600(0) 3594(4) 3559(9)	0.0(0.0) 0.0(0.0) 0.0(0.0) 0.0(0.0) 1.5(0.6) 6.2(1.2)	3600(0) 3600(0) 3600(0) 3600(0) 3589(5) 3574(8)
	(20, 50)	-000- 0.10 0.15 0.20 0.25 0.30	5.2(1.1) 8.2(1.4) 28.0(2.2) 64.8(2.4) 92.2(1.3) 99.2(0.4)	3879(18) 3839(21) 3599(34) 3165(41) 2608(35) 2238(23)	5.5(1.1) 7.0(1.3) 27.8(2.2) 62.0(2.4) 90.2(1.5) 99.2(0.4)	3882(18) 3852(21) 3627(33) 3168(41) 2597(36) 2250(24)	0.0(0.0) 0.0(0.0) 0.0(0.0) 1.0(0.5) 5.0(1.1) 14.5(1.8)	3960(0) 3960(0) 3960(0) 3951(5) 3926(10) 3854(16)	0.0(0.0) 0.0(0.0) 0.2(0.2) 0.8(0.4) 2.8(0.8) 13.8(1.7)	3960(0) 3960(0) 3956(3) 3955(4) 3936(8) 3868(15)
Table 1: QTE: rejection probabilities (multiplied by 100) and average stopping times under Sce-
narios 1 and 2 when α1(∙) is chosen as the spending function. Standard errors are reported in the
parentheses.
33
Under review as a conference paper at ICLR 2021
		method		BAT						AVT				
			Random		Adaptive		Random		Adaptive	
	(n, K)	δ	rej probs	E[stop]	rej probs	E[stop]	rej probs	E[stop]	rej probs	E[stop]
S1	(200, 5)	0.00 0.10 0.15 0.20 0.25 0.30	5.2(1.1) 27.5(2.2) 45.5(2.5) 62.5(2.4) 80.2(2.0) 88.2(1.6)	1763(8) 1644(15) 1511(17) 1391(18) 1263(17) 1176(14)	6.2(1.2) 26.0(2.2) 44.2(2.5) 64.2(2.4) 78.8(2.0) 88.8(1.6)	1762(8) 1647(14) 1527(17) 1383(18) 1266(17) 1179(14)	0.2(0.2) 6.8(1.3) 19.0(2.0) 42.8(2.5) 72.8(2.2) 89.2(1.5)	1800(0) 1771(6) 1718(10) 1581(15) 1394(17) 1216(14)	51.2(2.5) 89.0(1.6) 98.0(0.7) 99.5(0.4) 99.8(0.2) 100.0(0.0)	1586(11) 1344(9) 1250(6) 1196(6) 1145(5) 1091(5)
	(20, 50)	0.00 0.10 0.15 0.20 0.25 0.30	5.8(1.2) 27.5(2.2) 45.5(2.5) 67.0(2.4) 83.8(1.8) 92.0(1.4)	1933(9) 1771(18) 1617(22) 1446(22) 1287(19) 1182(16)	5.0(1.1) 27.5(2.2) 45.8(2.5) 65.5(2.4) 82.5(1.9) 91.5(1.4)	1936(9) 1771(18) 1630(21) 1459(22) 1288(19) 1193(16)	0.2(0.2) 8.0(1.4) 25.2(2.2) 53.8(2.5) 79.0(2.0) 94.0(1.2)	1978(1) 1929(9) 1826(15) 1617(20) 1379(19) 1187(15)	51.5(2.5) 89.2(1.5) 97.8(0.7) 99.0(0.5) 99.8(0.2) 100.0(0.0)	1621(17) 1276(13) 1166(7) 1105(6) 1061(4) 1030(2)
S2	(200, 5)	000 0.10 0.15 0.20 0.25 0.30	5.2(1.1) 18.2(1.9) 29.0(2.3) 40.5(2.5) 50.5(2.5) 62.5(2.4)	1763(8) 1692(12) 1633(15) 1559(17) 1489(18) 1407(18)	6.2(1.2) 16.8(1.9) 25.2(2.2) 42.0(2.5) 49.8(2.5) 62.5(2.4)	1762(8) 1699(12) 1642(15) 1548(17) 1492(18) 1413(18)	0.2(0.2) 3.0(0.9) 8.5(1.4) 17.2(1.9) 33.0(2.4) 53.5(2.5)	1800(0) 1788(3) 1762(7) 1724(10) 1641(14) 1522(16)	51.2(2.5) 82.2(1.9) 91.8(1.4) 97.8(0.7) 99.0(0.5) 99.5(0.4)	1586(11) 1406(10) 1323(9) 1257(7) 1218(6) 1181(6)
	(20, 50)	000 0.10 0.15 0.20 0.25 0.30	5.8(1.2) 19.0(2.0) 28.5(2.3) 39.0(2.4) 50.7(2.5) 65.2(2.4)	1933(9) 1839(16) 1763(19) 1680(21) 1592(22) 1479(22)	5.0(1.1) 19.0(2.0) 28.0(2.2) 41.8(2.5) 52.5(2.5) 63.7(2.4)	1936(9) 1837(16) 1771(18) 1685(20) 1568(22) 1481(22)	0.2(0.2) 3.5(0.9) 11.5(1.6) 24.0(2.1) 44.2(2.5) 63.5(2.4)	1978(1) 1961(5) 1911(10) 1830(15) 1688(19) 1539(20)	51.5(2.5) 81.0(2.0) 90.8(1.4) 97.5(0.8) 99.0(0.5) 99.2(0.4)	1621(17) 1360(15) 1256(12) 1171(8) 1124(6) 1092(5)
Table 2: ATE: rejection probabilities (multiplied by 100) and average stopping times under Sce-
narios 1 and 2 when α1 (∙) is chosen as the spending function. Standard errors are reported in the
parentheses.
Figure 5: Alpha spending functions when θ = 0.5, γ = 1.0.
34