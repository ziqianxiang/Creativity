Under review as a conference paper at ICLR 2021
Towards certifying '∞ robustness using Neu-
ral NETWORKS WITH '∞-DIST NEURONS
Anonymous authors
Paper under double-blind review
Ab stract
it is well-known that standard neural networks, even with a high classification
accuracy, are vulnerable to small '∞ perturbations. Many attempts have been tried
to learn a network that can resist such adversarial attacks. However, most previous
works either can only provide empirical verification of the defense to a particular
attack method, or can only develop a theoretical guarantee of the model robustness
in limited scenarios. in this paper, we develop a theoretically principled neural
network that inherently resists '∞ perturbations. In particular, We design a novel
neuron that uses '∞ distance as its basic operation, which we call '∞-dist neuron.
We show that the '∞ -dist neuron is naturally a 1-Lipschitz function with respect
to the '∞ norm, and the neural networks constructed with '∞-dist neuron ('∞-dist
Nets) enjoy the same property. This directly provides a theoretical guarantee of
the certified robustness based on the margin of the prediction outputs. We further
prove that the '∞-dist Nets have enough expressiveness power to approximate
any 1-Lipschitz function, and can generalize well as the robust test error can be
upper-bounded by the performance ofa large margin classifier on the training data.
Preliminary experiments show that even without the help of adversarial training,
the learned networks with high classification accuracy are already provably robust.
1 Introduction
Modern neural networks are usually sensitive to small, adversarially chosen perturbations to the
inputs (szegedy et al., 2013; Biggio et al., 2013). Given an image x that is correctly classified by
a neural network, a malicious attacker may find a small adversarial perturbation δ such that the
perturbed image x + δ, though visually indistinguishable from the original image, is assigned to a
wrong class with high confidence by the network. such vulnerability creates security concerns in
many real-world applications.
Developing a model that can resist small '∞ perturbations has been extensively studied in the lit-
erature. Adversarial training methods (szegedy et al., 2013; Madry et al., 2017; Goodfellow et al.,
2015; Huang et al., 2015; Athalye et al., 2018; Ding et al., 2020) first learn on-the-fly adversarial
examples of the inputs, and then update model parameters using these perturbed samples together
with the original labels. such approaches are restricted to a particular (class of) attack method and
cannot be formally guaranteed whether the resulting model is robust against other attacks. Another
line of algorithms trains robust models by maximizing the certified radius provided by robust certi-
fication methods. Weng et al. (2018); Wong & Kolter (2018a); Zhang et al. (2018); Mirman et al.
(2018); Wang et al. (2018); Gowal et al. (2018); Zhang et al. (2019b) develop their methods based on
linear or convex relaxations of fully connected ReLu networks. However, the certification methods
are usually computationally expensive and can only handle ReLu activations. Cohen et al. (2019);
salman et al. (2019); Zhai et al. (2020) show that a certified guarantee on small `2 perturbations can
be easily computed for general Gaussian smoothed classifiers. But recent works suggest that such
methods are hard to extend to the '∞-perturbation scenario.
In this work, we overcome the challenge mentioned above by introducing a new type of neural
network that naturally resists local adversarial attacks and can be easily certified under the '∞ per-
turbation. In particular, we propose a novel neuron called '∞-dist neuron. Unlike the standard
neuron design that uses a non-linear activation after a linear transformation, the '∞-dist neuron is
purely based on computing the '∞ distance between the inputs and the parameters. It is straightfor-
1
Under review as a conference paper at ICLR 2021
ward to see that such a neuron is I-LiPschitz with respect to the '∞ norm and the neural networks
constructed with '∞-dist neuron ('∞-dist Nets) enjoy the same property. Based on such a prop-
erty, We can obtain the certified robustness for any '∞-dist Nets using the margin of the prediction
outputs.
Theoretically, We investigate the expressive power of '∞-dist Nets and its adversarially robust gener-
alization ability. We first prove a Lipschitz-universal approximation theorem for '∞-dist Net using a
structured approach, which shows that '∞-dist Nets can approximate any 1-Lipschitz function with
respect to '∞ norm. We then give upper bounds of robust test error based on the Rademacher com-
plexity, which shows that the robust test error would be small if the '∞-dist Net learns a large margin
classifier on the training data. Both results demonstrate the excellent capability and generalization
ability of the '∞-dist Net function class.
The '∞-dist Nets have nice theoretical guarantees, but empirically, training an '∞-dist Net is not
easy. For example, the gradient of the parameters in the '∞ norm is sparse, which makes the opti-
mization inefficient. We show how to initialize the model parameters, apply proper normalization,
and overcome the sparse gradient problem via smoothed approximated gradients. Preliminary ex-
periments on MNIST and Fashion-MNIST show that even without using adversarial training, the
learned networks are already provably robust.
Our contributions are summarized as follows:
• We propose a novel neural network using '∞-dist neurons, called '∞-dist Nets. Theoretically,
-	In Section 3, we show that '∞-dist Nets are 1-Lipschitz with respect to the '∞ norm in nature,
which directly guarantees the certified robustness of any '∞-dist Net (with respect to the '∞
norm).
-	In Section 4.1, we prove that '∞-dist Nets have good expressive power as it can approximate
any 1-Lipschitz function with respect to the '∞ norm.
-	In Section 4.2, we prove that '∞-dist Nets have good generalization ability as the robust test
error can be upper-bounded by the performance of a large margin classifier on the training data.
• We provide several implementation strategies which are shown to be practically helpful for model
training (in Section 5).
2	Related Works
There are two major lines of works seeking to get robust neural networks:
Robust Training Approaches. Previous works showed that the conventional neural networks
learned using standard training approaches (e.g., maximum likelihood method) are sensitive to small
adversarial perturbations, and significant efforts have been put on developing training approaches for
learning robust models. Adversarial training is the most successful method against adversarial at-
tacks. By adding adversarial examples to the training set on the fly, adversarial training methods
(Szegedy et al., 2013; Goodfellow et al., 2015; Huang et al., 2015; Zhang et al., 2019a; Wong et al.,
2020) can significantly improve the robustness of the conventional neural networks. However, all the
methods above are evaluated according to the empirical robust accuracy against pre-defined adver-
sarial attack algorithms, such as projected gradient decent. It cannot be formally guaranteed whether
the resulting model is also robust against other attacks.
Certified Robustness. Many recent works focus on certifying the robustness of learned neural
networks under any attack. Approaches based on bounding the certified radius layer by layer using
some convex relaxation methods have been proposed for certifying the robustness of neural networks
(Wong & Kolter, 2018b; Gowal et al., 2018; Mirman et al., 2018; Dvijotham et al., 2018; Raghu-
nathan et al., 2018; Zhang et al., 2020). However, such approaches are usually computationally
expensive and have difficulties in scaling to deep models.
More recently, researchers found a new approach called randomized smoothing that can provide a
certified robustness guarantee for general models. Lecuyer et al. (2018); Li et al. (2018); Cohen
et al. (2019); Salman et al. (2019); Zhai et al. (2020) showed that if a Gaussian random noise is
2
Under review as a conference paper at ICLR 2021
added to the input layer, a certified guarantee on small `2 perturbations can be computed for Gaus-
sian smoothed classifiers. However, Yang et al. (2020); Blum et al. (2020); Kumar et al. (2020)
showed that randomized smoothing cannot achieve nontrivial certified accuracy against more than
Ω (min(1, d1/p-1/2)) radius for 'p perturbations, where d is the input dimension, therefore it can-
not provide meaningful results for '∞ perturbations due to the curse of dimensionality.
Another line of more conservative certification approaches sought to bound the global Lipschitz
constant of the neural network (Gouk et al., 2018; Tsuzuku et al., 2018; Anil et al., 2019; Cisse et al.,
2017). However, the bounds are not tight (Cohen et al., 2019), and the final robustness performances
are not as good as other certification methods.
3	'∞-DIST Network and its robustness guarantee
3.1	Preliminaries
Throughout this paper, we will use bold letters to denote vectors and otherwise scalars. Consider a
standard classification task with an underlying data distribution D over pairs of examples x ∈ X
and corresponding labels y ∈ Y = {1,2,…，M}. Usually D is unknown and We can only access a
training set T = {(xι,yι), ∙∙∙ , (xn, yn)} in which (xi, yi) is i.i.d. drawn from D, i = 1, 2,… ,n.
Let f ∈ F be the classifier of interest that maps any x ∈ X to Y. We call x0 = x + δ an adversarial
example of x to classifier f if f can correctly classify x but assigns a different label to x0 . In
real practice, the most commonly used setting is to consider the attack under e-bounded '∞ norm
constraint, i.e., δ satisfies ∣∣δ∣∣∞ ≤ e, which is also called '∞ perturbations.
our goal is to learn a model from T that can resist attacks at (x, y) with high probability over
(x, y)〜D for any small '∞ perturbations. It relates to compute the radius of the largest '∞ ball
centered at x in which f does not change its prediction. This radius is called the robust radius,
which is defined as (Zhai et al., 2020; Zhang et al., 2019a):
0inf	kx0-xk∞,whenf(x) =y
f(x0)6=f(x)	(1)
0	, when f(x) 6= y
R(f; x, y) =
unfortunately, computing the robust radius (1) of a classifier induced by a standard deep neural
network is very difficult. For example, Weng et al. (2018) showed that computing the `p robust
radius of a deep neural network is NP-hard for some specific p. Researchers then seek to derive
a tight lower bound of R(f; x, y) for general f. This lower bound is called certified radius and
we denote it as CR(f; x, y). The certified radius satisfies 0 ≤ CR(f; x, y) ≤ R(f; x, y) for any
f, x, y.
3.2	NETWORKS WITH '∞-DIST NEURONS
In this subsection, we propose the '∞-dist Neuron that is inherently Lipschitz with respect to '∞
norm. Using these neurons as building blocks, we then show how to obtain an '∞-Lipschitz neural
networks dubbed '∞-dist Net.
Denote z as the input vector to a neuron. A standard neuron processes the input by first projecting
z to a scalar value using a linear transformation, and then applying an non-linear activation function
σ on it, i.e., σ(w>z + b). w and b are parameters, and function σ can be the sigmoid or ReLU
activation. Unlike the previous design paradigm, we introduce a new type of neuron using '∞
distance as the basic operation, which we call '∞-dist neuron:
u(z, θ) = kz - wk∞ +b,	(2)
where θ = {w, b} is the parameter set. From the above equation, we can see that the '∞-dist neuron
is non-linear as it calculates the '∞ distance between input Z and parameter W with a bias term b.
As a result, there is no need to further apply a non-linear activation function.
Without loss of generality, we study the properties of multi-layer perceptron (MLP) networks that
are constructed using '∞-dist neurons. All theoretical results can be easily extended to other neural
network architectures, such as convolutional neural nets. We use x ∈ Rdinput to denote the input
vector of an MLP network. A (MLP) network using '∞-dist neurons can be formally defined as
follows.
3
Under review as a conference paper at ICLR 2021
Definition 3.1. ('∞-dist Net) Denote g as an MLP network which takes x(1) ，X ∈ RdinPut as
input. Assume there are L hidden layers and the l-th hidden layer contains dl hidden units. We call
g is an MLP network constructed by '∞-dist neurons, ifthe k-th unit in the l-th hidden layer xkl+1)
is computed by
x(kl+1) = u(x(l), θ(l,k)) = kx(l) - w(l,k)k∞ + b(l,k), 0 < l ≤ L,0 < k ≤ dl,
where x(l) = (x1l),x2l), ∙∙∙ , XdLɪ) is the input vector to the l-th hidden layer.
For simplicity, We will call an MLP network constructed by '∞-dist neurons as '∞-dist Net. For
classification tasks, the dimensionality of the output ofg matches the number of categories, i.e., M.
We write g(x) = (gι(x), g2(x),…，gM (x)) and define the predictor f (x) = arg maXi∈[M ] gi(x).
Note that g(x) can be used as the output logits the same as in any other networks, so we can apply
any standard loss function on the '∞-dist Net, such as the cross-entropy loss or hinge loss.
We will further show that the '∞-dist neuron and the neural networks constructed using it have nice
theoretical properties to control the robustness of the model. For completeness, we first introduce
the definition of Lipschitz functions as below.
Definition 3.2. (Lipschitz Function) A function g(z) : Rm → Rn is called λ-Lipschitz with respect
to 'p norm ∣∣ ∙ ∣∣p, ifforany zι, z2, thefollowing holds:
kg(z1) -g(z2)kp ≤ λkz1 -z2kp
It is straightforward to see that the '∞-dist neuron is 1-Lipschitz with respect to '∞ norm.
3.3	Lipschitz and Robustness Facts about '∞-DIST NETS
In this subsection, we introduce two straightforward but important facts about '∞-dist Nets. We first
show that '∞ -dist Nets are still 1-Lipschitz with respect to '∞ norm, and then derive the certified
robustness of the model based on this property.
Fact 3.1. Any '∞-distNet g(∙) is 1-Lipschitz with respect to '∞ norm, i.e.,forany xι, X2 ∈ RdinPut,
we have ∣g(x1) - g(x2)∣∞ ≤ ∣x1 - x2∣∞.
Proof. It’s easy to check that every operation u(x(l), θ(l,k)) is 1-Lipschitz, and therefore the map-
ping from one layer to the next x(l) → x(l+1) is 1-Lipschitz. Then we have for any x1, x2 ∈
Rdinput, ∣g(χι) -g(χ2)k∞ ≤ ∣∣χι - χ2k∞.	□
Since g is 1-Lipschitz with respect to '∞ norm, if the perturbation over X is rather small, the change
of the output can be bounded and the label of the perturbed data x0 will not change as long as
arg maxi∈[M] gi(X) = arg maxi∈[M] gi(X0), which directly bounds the certified radius.
Fact 3.2. Given model f(X) = arg maxi∈[M] gi(X) defined as above, and X is correctly classified
as y. We define margin(X; g) as the difference between the largest and second-largest elements of
g(X), then for any X0 satisfying ∣X - X0∣∞ ≤ margin(X; g)/2, we have that f(X) = f(X0) and:
CR(f, χ,y) ≥ margin(x;g)	(3)
Proof. Since g(x) is 1-Lipschitz, each element of g(x) can move at most margin(x;g) when x
changes to χ0, therefore the largest element will remain the same.	□
Using this bound, we can certify the robustness of an '∞-dist Net of any size under '∞ norm with
little computational cost (only a forward pass). In contrast, existing certified methods suffer from
either poor scalability (methods based on convex relaxation) or curse of dimensionality (randomized
smoothing), and lack efficiency as well.
4
UlIderreVieW as a COnferenCe PaPer at ICLR 2021
4 EXPRESSIVE PoWER AND RoBUST GENERALlZATIoN OF P8—DIST NET
The expressive power Of a model family and its generaHZation are two centraItOPiCSmachine
learning，InthePrevus Seetwe show that an goo—dist NetiSl—Lipschitz WithreSPeC 二 OgOO
norm，TheIl itIIatU 邑to ask Whetherthe designed IIeUral IIetWOrk Can approximate any i—Lipschitz
function (With respect to IIOnn) and Whether We Can give theoretical guarantees on the robust test
error Of a Ieamed modeL
InthiS SeCtwe giveafhrmative answerStO both questionWe will first ProVe a LiPSChitz—
universal appromatIItheorem for goo—dist Net USilIg a StrUetUred approacthen give UPPer
bounds OfrObUStteSt error based Onthe RademaCher COmPIety of the model family WithoUt
IOSS Of any generality We COnSider binary CkISSiAcion PrObIemS and assume the OUtPUt dimension
is L Allthe Omitted PrOOfSiIl this SeCtiOIl Can be found in the appendix，
4∙1 LIPSCHlTZ—UNIVERSAL APPRoXIMATIoN OF goo—DIST NET
IIl this SUbSeetWe ShI that goo—dist NetS With bounded Width CaIl approximate any I-Lipschitz
function (With respect to r normformaHZedthe fllg theorems
Theorem L Fbr any 1—LipschMZ, funcln 0() (wb respect Ioeg norm) On a boιmded domain
因 m Rdm2 and any CVa Ihere exisls an eg—dist Ng(x} wh Widlh no more Ihan d.in,put ÷
SllCh thalfor aUm 因7 we hae
=g(包 — 0H)Γ≤， (4)
TOPrOVe TheOrem L We IIeed the fllg key Iemm
Lemma 4・1・ Fbry 1 —Lip schitz, function j() (wh re spec- Ioeg norm) On a bounded domain
因 m Rand any CVa Ihere exisls aβne number OffImC 一 ionsSllCh thalform 因
max≤ j(≤ max+
where eq-M-has Ihefol°WingfOrm
"() Umin(1 — Wtv Y) —172 — "52)：：7 ∙wk) —„J + b
Lemma 4」adecomposes: any target 1—Lipschitz function into SimPIe abase functionswhich Wi=
SerVe as building blocks in ProVilIg the main theorem，Lu et ah (2017) first ProVed SUCh universal
appromatIItheOremfor Width—bounded ReLU IletWOrkS by COlIStrUCtiIIg a SPeCial IletWOrk that
approximates the target function by :sum Of cubeFor g"dist NeL SUCh an approach CamIOt be
directIy applied as the SUmmation will break the LiPSChitZ property We employ a IIOVelamaX Of
Pyramidq COnStrUCtn to OVerCOme the issuThe key idea is to approXimate the target function
from below USg the maximum OfmaIly ∖pyramilikbasic 1—Lipschitz function
Theorem IimPHeS that an goo—dist Net Can approximate any 1—Lipschitz function WithreSPeettO
gɔo IIOrm on a COmPaCt SeLUSing 0y finite Width WhiCh is bareIy Iargerthan the input dimension，
COmbillg With the fac 二 hat an『oo—diSt NetiSl—Lipschitwe COIlClUde that goo—dist NetSiS a good
ClaSS OfmodeI to approximate I-Lipschitz function
4∙2 BoUNDING RoBUST TEST ERRoR OF goo—DIST NET
GOod robust gene 邑 izatn ability i.sma= empirical (marg) error impHeS SmaIIrObUStteSt erroL
is as important as StrOlIg expressive PlerlnthiS SUbSeetwe give UPPer bound for the robust
IeSI error OfgOo—diSt Net∙
COIlSiderthe following CIaSSifiCatiOIl PrObIenrIet (7 y} be an instance—label COUPIe Wherem 因
and 虫 m(L —二 and denote U as the distribution of (7 虫For a function g(二 为dmps J I^We
USe Sign (g(包)as the ClaSSer The T—robust test error M Of a ClaSSifier g is dehned as
“r U1D SUPg(8≤o
=8、——且≤τ
We CaIl UPPer bound F by the margerror on training data and the SiZe Of IIetWOdC
Under review as a conference paper at ICLR 2021
Theorem 2. Let F denote the set of all g represented by an '∞-dist Net with width W and depth L,
for every t > 0, with probability at least 1 - 2e-2t2 over the random drawing ofn samples, for all
r > 0 and g ∈ F we have that
γr ≤ inf
δ∈(0,1]
1n
1XI
i=1
yig(xi)≤δ+r + O
Lw2
δ√n) +
log2( 2 ) } 2
(5)
'∙^^^^^^^^^{^^^^^^^^^^
large training margin
'-----{z-----}
network size
}
〜
n
t
+ 丁
Theorem 2 provides a theoretical guarantee on the adversarial robust test error: when a large margin
classifier is found on training data, and the size of the '∞-dist Net is not too large, then with high
probability the model can generalize well in terms of adversarial robustness.
We prove the theorem in two steps. One step is to provide a margin bound to control the gap between
standard training error and standard test error. In this step, we use Rademacher complexity R(F) of
a hypothesis set F, where the test error βr with r as margin is defined as: βr = ED Iyg(x)≤r . The
other step is to bound the gap between test error and robust test error. The two steps are provided in
the following two lemmas.
Lemma 4.2. Let F be a hypothesis class, then for any t > 0,
P (∃g	∈ F:βr	>	δ∈infi]	1XIyig(Xi)≤δ+r +	48Rn(F)+ (loglog2(δ))	+	√tn) ≤ 2e-2t2.
Lemma 4.3. The r-robust test error γr is no larger than the test error βr, i.e., γr ≤ βr.
1n
L(g,T) = n EmaXj0,
g(xi)yi0 - g(xi)yi
(6)
5	Training '∞-DIST Net
Motivated by the theoretical analysis in the previous sections, we would like to find a large margin
solution on the training data. Therefore we use the standard hinge loss as the objective function:
t + max
yi0 6=yi
where t controls the desired margin and should be slightly larger than twice of the desired robust-
ness level according to Eqn. 3. it can be easily seen that L(g, T) is a continuous function of the
network parameters and is differentiable almost everywhere. Therefore any gradient based opti-
mization method can be used to train an '∞-dist Net.
However, the optimization is not easy. We find that directly using SGD or Adam optimizer fails
to train the network well. In fact, the gradient of the '∞ norm (i.e., ∣∣z - w∣∣∞) with respect to
w is very sparse, which makes the optimization inefficient. in this section, we list a few important
optimization tricks which we find is effective in practice.
Normalization and parameter initialization Batch Normalization (ioffe & Szegedy, 2015),
which shifts and scales feature values in each layer, is shown to be one of the most important com-
ponents in training deep neural networks. However, in '∞-dist Net, if We directly apply batch
normalization, the Lipschitz constant of the network will change due to the scaling operation, and
the robustness of the trained model cannot be guaranteed. To leverage the advantages of BatchNorm,
we only apply the shift operation that shifts the output of each layer using the mean over the current
batch during training. Similar to BatchNorm, we use the running mean during inference. Note that
in inference, the running mean serves as an additional bias term in '∞-dist neuron, which does not
affect the Lipschitz constant. Finally, we do not use affine transformation which is typically used in
BatchNorm.
We apply the shift operation in all intermediate layers after calculating the '∞-dist norm, but not
the final layer. As a result, we remove the bias term in the '∞-dist neuron in all intermediate layers.
The bias in the last layer is initialized to zero. As for the weight initialization, weights and inputs
should have the same scale due to the '∞ distance operation. Therefore we initialize all weights
from standard Gaussian distribution since the inputs are normalized to have unit variance.
6
Under review as a conference paper at ICLR 2021
Smoothed approximated gradients. We find that training an '∞ -dist from scratch is usually in-
efficient, and the model can easily be stuck in some bad local minima. To obtain a well-optimized
model, We relax the '∞ distance by 'p distance for each neuron, to get an approximate and non-
sparse gradient of the parameters (Chen et al., 2020). During training, we set p to be a small value
in the beginning, and linearly increase it in each iteration to reach a large value. When the training
finishes, We freeze the model parameter and set p to ∞ as our final model.
6	Experiment
6.1	Experimental setting
Model details and training configurations. We train the '∞-dist Net on two benchmark datasets:
MNIST and FaShion-MNIST. For both tasks, we use a 4-layer '∞-dist Net. Each hidden layer has
4096 neurons. Normalization is applied between each intermediate layer. The batch size is set to
512. Random-crop data augmentation and image standardization are used during training. We train
the network using Adam optimizer with hyper-parameters β1 = 0.9 and β2 = 0.99. The training
procedure is as follows: First, we relax the '∞-dist Net to 'p-dist Net with P = 6 and train the model
parameters for 30 epochs. Then we gradually increase p from 6 to 100 in the next 170 epochs.
Finally, we fix p = 100 and train the last 50 epochs. The learning rate in the first and second parts is
set to be 0.015 and is divided by 5.0 in the final 50 epochs. We use hinge loss with parameter t = 0.9.
For the Fashion-MNIST dataset, we use exactly the same model and the same hyper-parameters as
MNIST, except for the hinge loss parameter t = 0.4. Adjusting models and hyper-parameters may
further improve the results.
Evaluation. Following Wong & Kolter (2018b); Gowal et al. (2018); Madry et al. (2017); Zhang
et al. (2019b), we test the robustness of '∞-dist Net under '∞ radius 0.3 on MNIST and 0.1 on
Fashion-MNIST. We use two evaluation metrics to measure the robustness of the model. We first
evaluate the robust test accuracy under the Projected Gradient Descent (PGD) attack (Madry et al.,
2017). Following standard practice, we set the number of steps of the PGD attack to be 20 and set
the step size to be 0.01. We also calculate the certified radius for each sample using Eq. 3, and check
the percentage of test samples that can be certified to be robust within the chosen radius.
Table 1: Comparison of different methods on MNIST under '∞ radius 0.3.
Method	w/o Adv Train	Scalable	Standard Acc	Robust Acc	Certified Acc
Natural	✓	✓	993	≈0	≈ 0
IBP	X	X	98.34	93.88	91.95
CROWN-IBP	X	X	98.18	93.95	92.98
GroupSort	✓	X	≈ 97.0	≈ 32.0	≈ 2.0
'∞-dist Net	J	✓	98.61	93.78	91.59
Table 2: Comparison of different methods on Fashion-MNIST under '∞ radius 0.1.
Method	w/o Adv Train	Scalable	Standard Acc	Robust Acc	Certified Acc
Natural	✓	✓-	94.0	≈ 0	≈ 0
CAP	X	X	78.27	68.37	65.47
IBP	X	X	-	-	76.51
'∞-dist Net	J	J	87.46	75.44	73.23
Baselines. In Table 1 and 2, we compare '∞-dist Net with several baselines, i.e., standard training
on standard neural network (abbreviated as Natural in the table), CAP (Wong & Kolter, 2018b),
IBP (Gowal et al., 2018), CROWN-IBP (Zhang et al., 2019b), GroupSort Network (Anil et al.,
2019). Randomized Smoothing (Cohen et al., 2019; Salman et al., 2019; Zhai et al., 2020) is
another strong baseline when considering the robustness with respect to `2 perturbation. However,
as discussed in the related work section, it cannot achieve nontrivial certified accuracy against more
than Ω (min(1, d-1/2)) radius for '∞ perturbation where d is the input dimension, which implies
randomized smoothing cannot obtain good certification under '∞ norm. We report the performances
7
Under review as a conference paper at ICLR 2021
(a)
Figure 1: (a) We sample some neurons from the first layer and list the parameters w together with
some input data on MNIST and Fashion-MNIST. It can be seen that on both tasks, the parameters
(first row) look very similar to the data (second row) in some categories. This shows that the neuron
captures the shape information, which is a meaningful feature and useful for classification. (b) The
radius-(certified accuracy) curve of our trained model on MNIST dataset.
(b)
(picked from the original papers) together with other properties of these methods, e.g., whether these
methods use adversarial training (abbreviated as Adv Train in the table); are these methods scalable
to large neural networks.
6.2	Experimental results
We list the performances of '∞-dist Net in Table 1 and 2. In these tables, We use “Standard Acc”,
“Robust Acc” and “Certified Acc” as abbreviations of standard (clean) test accuracy, robust test
accuracy under PGD attack and certified robust test accuracy. All the numbers are reported in
percentage.
From Table 1 and 2, we find that '∞-dist Net can achieve comparative or better robustness than other
baselines While maintaining high standard accuracy. Specifically, on MNIST, among the methods
that do not need adversarial training or can be scaled to large networks, '∞-dist Net has the best
robustness and achieves more than 93% robust test accuracy and more than 91% certified test ac-
curacy. These performances are also comparative with those methods that train the model using
adversarial training and calculate the certified radius with huge computational cost (Wong & Kolter,
2018b; Gowal et al., 2018; Zhang et al., 2019b). We also plot the radius-(certified accuracy) curve
on MNIST in Figure 1(b). Results on Fashion-MNIST are similar.
To understand how the '∞-dist Net extracts information from the data, we sample some neurons in
the first layer and record its parameter w . We then visualize w together with some input data on
both tasks. Interestingly, in Figure 1(a), we can see that the parameters w (first row) “look similar”
to the input data (second row). This phenomenon is because we use '∞ distance in the network
to obtain effective signals for classification. Then the neurons seek to find typical patterns that can
differentiate one category to others in terms of '∞ distance, e.g., the shape of the objects, which is
quite different from the feature extractor in standard neural networks.
7	Conclusion
In this paper, we design a novel neuron that uses '∞ distance as its basic operation. We show that
the '∞-dist neuron is naturally a 1-Lipschitz function with respect to the '∞ norm and the neural
networks constructed with '∞-dist neuron ('∞-dist Nets) enjoy the same property. This directly
provides a theoretical guarantee of the certified robustness based on the margin of the prediction
outputs. We further formally analyze the expressiveness power and the robust generalization ability
of the network. Preliminary experiments show promising results on MNIST and Fashion-MNIST
datasets. As future work, we will conduct experiments of the '∞-dist Net on more datasets (CI-
FAR10 and ImageNet) and extend it to modern networks, such as deep convolutional networks with
residual connections.
8
Under review as a conference paper at ICLR 2021
References
Cem Anil, James Lucas, and Roger Grosse. Sorting out lipschitz function approximation. In Inter-
national Conference on Machine Learning, pp. 291-301, 2019.
Anish Athalye, Nicholas Carlini, and David A. Wagner. Obfuscated gradients give a false sense of
security: Circumventing defenses to adversarial examples. CoRR, abs/1802.00420, 2018.
Peter L. Bartlett, Nick Harvey, Christopher Liaw, and Abbas Mehrabian. Nearly-tight vc-dimension
and pseudodimension bounds for piecewise linear neural networks. Journal of Machine Learning
Research, 20(63):1-17, 2019.
Battista Biggio, Igmo Corona, Davide Maiorca, Blame Nelson, Nedim Srndic, Pavel Laskov, Gior-
gio Giacinto, and Fabio Roli. Evasion attacks against machine learning at test time. In Joint
European conference on machine learning and knowledge discovery in databases, pp. 387-402.
Springer, 2013.
Avrim Blum, Travis Dick, Naren Manoj, and Hongyang Zhang. Random smoothing might be unable
to certify '∞ robustness for high-dimensional images. arXiv preprint arXiv:2002.03517, 2020.
Hanting Chen, Yunhe Wang, Chunjing Xu, Boxin Shi, Chao Xu, Qi Tian, and Chang Xu. Addernet:
Do we really need multiplications in deep learning? In Proceedings of the IEEE/CVF Conference
on Computer Vision and Pattern Recognition, pp. 1468-1477, 2020.
Moustapha Cisse, Piotr Bojanowski, Edouard Grave, Yann Dauphin, and Nicolas Usunier. Parseval
networks: Improving robustness to adversarial examples. In International Conference on Machine
Learning, pp. 854-863, 2017.
Jeremy Cohen, Elan Rosenfeld, and Zico Kolter. Certified adversarial robustness via randomized
smoothing. In Kamalika Chaudhuri and Ruslan Salakhutdinov (eds.), Proceedings of the 36th
International Conference on Machine Learning, volume 97 of Proceedings of Machine Learning
Research, pp. 1310-1320, Long Beach, California, USA, 09-15 Jun 2019. PMLR.
Gavin Weiguang Ding, Yash Sharma, Kry Yik Chau Lui, and Ruitong Huang. Mma training: Direct
input space margin maximization through adversarial training. In International Conference on
Learning Representations, 2020.
Krishnamurthy Dvijotham, Sven Gowal, Robert Stanforth, Relja Arandjelovic, Brendan
O’Donoghue, Jonathan Uesato, and Pushmeet Kohli. Training verified learners with learned ver-
ifiers. arXiv preprint arXiv:1805.10265, 2018.
Ian Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversarial
examples. In International Conference on Learning Representations, 2015.
Henry Gouk, Eibe Frank, Bernhard Pfahringer, and Michael Cree. Regularisation of neural networks
by enforcing lipschitz continuity. arXiv preprint arXiv:1804.04368, 2018.
Sven Gowal, Krishnamurthy Dvijotham, Robert Stanforth, Rudy Bunel, Chongli Qin, Jonathan Ue-
sato, Timothy Mann, and Pushmeet Kohli. On the effectiveness of interval bound propagation for
training verifiably robust models. arXiv preprint arXiv:1810.12715, 2018.
Ruitong Huang, Bing Xu, Dale Schuurmans, and Csaba Szepesvari. Learning with a strong adver-
sary. arXiv preprint arXiv:1511.03034, 2015.
Sergey Ioffe and Christian Szegedy. Batch normalization: Accelerating deep network training by
reducing internal covariate shift. In International Conference on Machine Learning, pp. 448-456,
2015.
Vladimir Koltchinskii, Dmitry Panchenko, et al. Empirical margin distributions and bounding the
generalization error of combined classifiers. The Annals of Statistics, 30(1):1-50, 2002.
Aounon Kumar, Alexander Levine, Tom Goldstein, and Soheil Feizi. Curse of dimensionality on
randomized smoothing for certifiable robustness. arXiv preprint arXiv:2002.03239, 2020.
9
Under review as a conference paper at ICLR 2021
Mathias Lecuyer, Vaggelis Atlidakis, Roxana Geambasu, Daniel Hsu, and Suman Jana. Certified
robustness to adversarial examples with differential privacy. arXiv preprint arXiv:1802.03471,
2018.
Bai Li, Changyou Chen, Wenlin Wang, and Lawrence Carin. Second-order adversarial attack and
certifiable robustness. CoRR, abs/1809.03113, 2018.
Zhou Lu, Hongming Pu, Feicheng Wang, Zhiqiang Hu, and Liwei Wang. The expressive power of
neural networks: A view from the width. In I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach,
R. Fergus, S. Vishwanathan, and R. Garnett (eds.), Advances in Neural Information Processing
Systems 30, pp. 6231-6239. Curran Associates, Inc., 2017.
Ulrike von Luxburg and Olivier Bousquet. Distance-based classification with lipschitz functions.
Journal of Machine Learning Research, 5(Jun):669-695, 2004.
Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and Adrian Vladu.
Towards deep learning models resistant to adversarial attacks. arXiv preprint arXiv:1706.06083,
2017.
Matthew Mirman, Timon Gehr, and Martin Vechev. Differentiable abstract interpretation for prov-
ably robust neural networks. In International Conference on Machine Learning, pp. 3578-3586,
2018.
Aditi Raghunathan, Jacob Steinhardt, and Percy Liang. Certified defenses against adversarial exam-
ples. In International Conference on Learning Representations, 2018.
Hadi Salman, Jerry Li, Ilya Razenshteyn, Pengchuan Zhang, Huan Zhang, Sebastien Bubeck, and
Greg Yang. Provably robust deep learning via adversarially trained smoothed classifiers. In
Advances in Neural Information Processing Systems, pp. 11292-11303, 2019.
Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian J. Goodfel-
low, and Rob Fergus. Intriguing properties of neural networks. CoRR, abs/1312.6199, 2013.
Yusuke Tsuzuku, Issei Sato, and Masashi Sugiyama. Lipschitz-margin training: Scalable certifi-
cation of perturbation invariance for deep neural networks. In Advances in neural information
processing systems, pp. 6541-6550, 2018.
Shiqi Wang, Yizheng Chen, Ahmed Abdou, and Suman Jana. Mixtrain: Scalable training of formally
robust neural networks. arXiv preprint arXiv:1811.02625, 2018.
Lily Weng, Huan Zhang, Hongge Chen, Zhao Song, Cho-Jui Hsieh, Luca Daniel, Duane Boning,
and Inderjit Dhillon. Towards fast computation of certified robustness for ReLU networks. In
Jennifer Dy and Andreas Krause (eds.), Proceedings of the 35th International Conference on
Machine Learning, volume 80 of Proceedings of Machine Learning Research, pp. 5276-5285,
Stockholmsmassan, Stockholm Sweden, 10-15 Jul 2018. PMLR.
Eric Wong and Zico Kolter. Provable defenses against adversarial examples via the convex outer
adversarial polytope. In Jennifer Dy and Andreas Krause (eds.), Proceedings of the 35th In-
ternational Conference on Machine Learning, volume 80 of Proceedings of Machine Learning
Research, pp. 5286-5295, StockhoImsmassan, Stockholm Sweden, 10-15 Jul 2018a. PMLR.
Eric Wong and Zico Kolter. Provable defenses against adversarial examples via the convex outer
adversarial polytope. In International Conference on Machine Learning, pp. 5286-5295. PMLR,
2018b.
Eric Wong, Leslie Rice, and J Zico Kolter. Fast is better than free: Revisiting adversarial training.
arXiv preprint arXiv:2001.03994, 2020.
Greg Yang, Tony Duan, Edward Hu, Hadi Salman, Ilya Razenshteyn, and Jerry Li. Randomized
smoothing of all shapes and sizes. arXiv preprint arXiv:2002.08118, 2020.
Runtian Zhai, Chen Dan, Di He, Huan Zhang, Boqing Gong, Pradeep Ravikumar, Cho-Jui Hsieh,
and Liwei Wang. Macer: Attack-free and scalable robust training via maximizing certified radius.
arXiv preprint arXiv:2001.02378, 2020.
10
UlIderreVieW as a COnferenCe PaPer at ICLR 2021
HOngyang Zhan-YaOdOlIg Yuy JiantaO JiapEriC X5--LaUrent EI GhaOUL and MiChaeIJOrdaiL
TheOretiCany Prcipled trade—off between robustness and accuracy IIl Kamalika ChaUdhUri
and RUSIan SalakhUtd0V (edL Proceedings Oflhe 36Ih International ConferenCe On MaChine
Learning.volume 97 Of ProCeedingS OfMaChine LearningReSearC产 pp∙ 7472—7482》LOlIg BeaC尸
CaHfOmUSAy 09—15 JUll 2019a∙ PMLR∙
HUan ZhanTSUWei Wellpin—YU cheCho—Jui HSie k and LUCa DanieL EffiCient IIeUral IIet—
WOrk robustness CertifiCatiOIl With general activation functionIn AdVemCeS in KeHrWOrmclln
PrOCeSSing SySIemS. pp∙ 4939L94201
HUan ZhanHOngge cheChalei XiaBO LL DUalle Bonand ChO—Jui HSieTowards Sta—
ble and efficient traiIIg Of VerifiabIy robust IIeUraI networkarxPrePrini arx二906.063Ip
2019b∙
HUan ZhanHOngge cheChaIei XiaSVeIl GlaL RObert StanfOr⅛ BO LL DUane Bon
and Cho—Jui HSieh∙ Towards StabIe and efficient training Of Verably robust IIeUral IIetWOrkIn
InIernciHoncd CcmferenCe OTI Leqrning Representations. 202
AAPPENDlX
A∙ 1 PRooF OF LEMMA 4∙ 1
proof. WithOUtIOSS Of generaHty We may assume 因 mCOlISiderthe Set S COnSiStg Of all
PohitsN7:0 Nn- Where Nj are integerWe CaIl Write S ∩ 因 U (lr(l)：：j tυ(m)) since ita
finite set，<Z) m S ∩ 员 we define the corresponding MX- as flls
-3Umin£1 — U^) 7*r) — 七一&2 —-孕)+ j(w∕Z)) (7)
ObviOUSly <m IKWe have that j() ≥ "(thus max三≤ j() holds as a direct COIlSe—
quence.
On the Other hand” <J? m 因 there exists itseighbouF lυm S ∩ 因 SUCh that 一存 — lυ=oo ≤
therefore by USiIlg the LiPSChitZ ProPertieS OfbOth j() and fj(Ne have that
j(包 ≤ j(j)) + 5 Uj)) + 5包 + C (8)
SiIICe max" ()(l We COIlCIUde OUr Proof∙ □
A∙2 PRooF OF THEoREM 1
proof. ByIemma 4∙ L there exists a finite number of functionS "()UL …"m) SUChthat<m 因
max*©) ≤ 0(包 ≤ max"(包 +c (9)
Where eachhas the form
"() Umin(1 — n4z)7 I2 — UJy :二 U^)I ÷ 0( Ir(Z)) (IO)
The high—level idea Ofthe PrOOfiS Very simple among Widthpuc ÷ 2》We allOCatepuc neurons
each layer to keep the information Of 目 Olle to CalCUlate each fi(OIle after another and the last
IIeUrOIl CaICUtg the maximum Ofaccumulated.
Ho SimPHfy the prowe WOUld first introduce three gene 邑 basic maps WhiCh Can be realized at a
SingIe UL then illustrate hl to represent maXM包 by COmbg these basic map
LerS assume for IlI that any input to any unitthe whe IIetWork has its8 IIOnn UPPer bounded
by a Iarge COIIStantwe will COme back Iaterto determine this ValUe and ProVe its validity
11
Under review as a conference paper at ICLR 2021
Proposition A.1. ∀j, k, p and constant w, c, the following base functions are realizable at the kth
unit in the lth hidden layer:
1,	the projection map:
u(x(l) , θ(l,k)) = x(jl) + c	(11)
2,	the negation map:
u(x(l), θ(l,k)) = -x(jl) +c	(12)
3,	the maximum map:
u(x(l) , θ(l,k)) = max{x(jl) + w, x(pl) } + c, u(x(l) , θ(l,k)) = max{-x(jl) + w, x(pl)} + c (13)
Proof. 1, the projection map: Setting u(x(l) , θ(l,k)) as follows
u(x(l), θ(l,k)) = k(x(1l),...,x(jl) + 2C,..., x(nl))k∞ -2C+c	(14)
2,	the negation map: Setting u(x(l) , θ(l,k)) as follows
u(x(l), θ(l,k)) = k(x(1l),...,x(jl) - 2C,..., x(nl))k∞ -2C+c	(15)
3,	the maximum map: Setting u(x(l), θ (l,k)) as follows
u(x(l), θ(l,k)) = k(x(1l),...,xj(l) +w+2C,...,x(pl) + 2C,..., x(nl))k∞ -2C+c (16)
u(x(l), θ(l,k)) = k(x(1l),...,-x(jl) +w+2C,...,x(pl) +2C,...,x(nl))k∞ -2C+c (17)
□
With three basic maps in hand, we are prepared to construct our network. Using proposition A.1, the
first hidden layer realizes u(x, θ(1,k)) = xk for k = 1, ..., dinput. The rest two units can be arbitrary,
we set both to be x1 .
By proposition A.1, throughout the whole network, we can set u(x(l) , θ(l,k)) = xk for all l and
k = 1, ..., n. Notice that fi(x) can be rewritten as
fi(x) = - max{xι — w(i), max{w(i) — xι, max{..., Wni) — xn}...}} + g(w(i))	(18)
Using the maximum map recurrently while keeping other units unchanged with the projection
map, we can utilize the unit u(x(l), θ(l,dinput+1)) to realize one fi(x) at a time. Again by the
use of maximum map, the last unit u(x(l), θ(l,dinput+2)) will recurrently calculate (initializing with
max{f1(x)} = f1(x))
max fi(x) = max{fm(x), max{..., max{f1 (x)}...}}	(19)
i
using only finite depth, say L, then the network outputs g(x) = u(x(L), θ(L,1)) =
u(x(L-1), θ(L-1,dinput+2)) = maxi fi(x) as desired. We are only left with deciding a valid value for
C. Because K is bounded and g(x) is continuous, there exists constants Ci, C2 such that ∀x ∈ K,
∣∣x∣∣∞ ≤ Ci and |g(x)| ≤ C?, it,s easy to verify that C = 2Ci + C? is valid.
□
A.3 Proof of lemma 4.2
First we give a quick revisit on Rademacher complexity and its properties.
12
Under review as a conference paper at ICLR 2021
Rademacher Complexity Given a sample Xn = {x1 , ..., xn} ∈ Kn, and a real-valued function
class F on K, the Rademacher complexity of F is defined as
Rn(F)= EXn (1 Eσ
nn
n
sup	σif(xi)
f∈F i=1
))
where σi are drawn from the Rademacher distribution independently, i.e. P (σi = 1) = P (σi =
-1) = 1. It,s worth noting that ∀r, Rn(F) = Rn(F ㊉ r) where F ㊉ r = {f + r|f ∈ F}.
It’s well known (using Massart’s Lemma) that Rademacher complexity can be bounded by VC
dimension:

Rn(F) ≤
2VCdim(F)log VCdim(F
n
(20)
Proof. Denote the hypothesis set with F and its Rademacher complexity on training data with
Rn(F), we can upper bound the generalization error when a large margin solution is found on
training data:
Lemma A.1. (Theorem 11 in Koltchinskii et al. (2002)) For all t > 0,
P (∃g ∈ F: β0 > δ∈infi] 1 XIyig(Xi)≤δ + 48Rn(F) + (loglog2(δ))	+ √√n) ≤ 2e-2t2
To further generalize lemma A.1 to βr with r > 0, we use the fact that Rademacher complexity
remain unchanged if the same constant r is added to all functions in F. Lemma 4.2 is a direct
consequence by replacing mf by mf - r at the end of the proof of theorem 11 in Koltchinskii et al.
(2002), where it plugs mf into theorem 2 in Koltchinskii et al. (2002):
□
A.4 Proof of Lemma 4.3
Proof. yg(x) > r implies infkx0-xk∞≤r yg(x0) > 0 because g(x) is 1-Lipschitz, therefore
ED Iyg(x)>r ≤ ED inf	Iyg(x0)>0 ≤ ED
kx0 -xk∞ ≤r
sup	Iyg(x0)>0
kx0-xk∞≤r
and so 1 - βr ≤ 1 - Yr which concludes the proof.	□
A.5 Proof of Theorem 2
Proof. There are generalization bounds like (Luxburg & Bousquet, 2004), which involves only
the Lipschitz property. Unfortunately, in those bounds, the dependence on sample size is of or-
-1
der n dinput, which suffers from the curse of dimensionality. To derive a more meaningful bound, We
take the network size into consideration as well.
We can bound the VC dimension of '∞-dist Net by reducing a given '∞-dist Net network to a fully-
connected ReLU network. We first introduce the VC bound for fully-connected neural networks
with ReLU activation borrowed from Bartlett et al. (2019):
Lemma A.2. (Theorem 6 in Bartlett et al. (2019)) Consider a fully-connected ReLU network archi-
tecture F with input dimension d, width w ≥ d and depth (number of hidden layers) L, then its VC
dimension satisfies:
VCdim(F) = O(L2w2)	(21)
The following lemma shows how to calculate '∞ distance using a fully-connected ReLU network
architecture.
13
Under review as a conference paper at ICLR 2021
Lemma A.3. ∀w ∈ Rd, there exists a fully-connected ReLU network h with width O(d) and depth
O(log d) such that h(x) = kx - wk∞
Proof. The proof is by construction. Rewrite kx - wk∞ as
max{x1 - w1, w1 - x1, ..., xd - wd, wd - xd}
which is a maximum of 2d items. Notice that max{x, y} = ReLU (x-y)+ReLU (y)-ReLU (-y),
we can use 3d neurons in the first hidden layer so that the input to the second hidden layer are
max{xi - wi, wi - xi}, in all d items. Repeating this procedure which cuts the number of items
within maximum by half, within O(log d) hidden layers this network finally outputs kx - wk∞ as
desired.	□
The VC bound of '∞ -dist Net is formalized by the following lemma:
Lemma A.4. Consider an '∞-dist Net architecture F with input dimension d, width W ≥ d and
depth (number of hidden layers) L, then its VC dimension satisfies:
VCdim(F) = O(L2w4)	(22)
Proof. By lemma A.3, each neuron in the '∞-dist Net can be replaced by a fully-connected ReLU
subnetwork with width O(w) and depth O(log w). Therefore a fully-connected ReLU network
architecture G with width O(w2) and depth O(L log w) can realize any function represented by the
'∞-dist Net when parameters vary. Remember that VC dimension is monotone under the ordering
of set inclusion, We conclude that such '∞-dist Net architecture F has VC dimension no more than
that of G which equals O(L2w4) by lemma A.2.	□
Finally, Theorem 2isa direct consequence by combing Lemmas 4.2, 4.3, A.3, A.2 and A.4.	□
14