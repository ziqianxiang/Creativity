Under review as a conference paper at ICLR 2021
Byzantine-Robust Learning on Heteroge-
neous Datasets via Resampling
Anonymous authors
Paper under double-blind review
Ab stract
In Byzantine robust distributed optimization, a central server wants to train a
machine learning model over data distributed across multiple workers. However,
a fraction of these workers may deviate from the prescribed algorithm and send
arbitrary messages to the server. While this problem has received significant
attention recently, most current defenses assume that the workers have identical
data. For realistic cases when the data across workers are heterogeneous (non-iid),
we design new attacks which circumvent these defenses leading to significant loss
of performance. We then propose a simple resampling scheme that adapts existing
robust algorithms to heterogeneous datasets at a negligible computational cost. We
theoretically and experimentally validate our approach, showing that combining
resampling with existing robust algorithms is effective against challenging attacks.
1	Introduction
Distributed or federated machine learning, where the data is distributed across multiple workers,
has become an increasingly important learning paradigm both due to growing sizes of datasets, as
well as privacy and security concerns. In such a setting, the workers collaborate to train a single
model without transmitting their data directly over the networks (McMahan et al., 2016; Bonawitz
et al., 2019; Kairouz et al., 2019). Due to the presence of either actively malicious agents in the
network, or simply due to system and network failures, some workers may disobey the protocols and
send arbitrary messages; such workers are also known as Byzantine workers (Lamport et al., 2019).
Byzantine robust optimization algorithms combine the gradients received by all workers using robust
aggregation rules, to ensure that the training is not impacted by the malicious workers.
While this problem has received significant recent attention, (Alistarh et al., 2018; Blanchard et al.,
2017; Yin et al., 2018a), most of the current approaches assume that the data present on each different
worker has identical distribution. In this work, we show that existing Byzantine-robust methods
catastrophically fail in the realistic setting when the data is distributed heterogeneously across the
workers. We then propose a simple resampling scheme which can be readily combined with existing
aggregation rules to allow robust training on heterogeneous data.
Contribution. Concretely, our contributions in this work are
•	We show that when the data across workers is heterogeneous, existing robust rules might
not converge, even without any Byzantine adversaries.
•	We propose two new attacks, normalized gradient and mimic, which take advantage of
data heterogeneity and circumvent median and sign-based defenses (Blanchard et al., 2017;
Pillutla et al., 2019; Li et al., 2019).
•	We propose a simple new resampling step which can be used before any existing robust
aggregation rule. We instantiate our scheme with Krum and theoretically prove that the
resampling generalizes it to the setting of heterogeneous data.
•	Our experiments evaluate the proposed resampling scheme against known and new attacks
and show that it drastically improves the performance of 3 existing schemes on realistic
heterogeneously distributed datasets.
Setup and notations. We study the general distributed optimization problem
L? = minx∈Rd {L(x) := 1 Pn=I Li(X)}
(1)
1
Under review as a conference paper at ICLR 2021
where Li : Rd → R are the individual loss functions distributed among n workers, each having its
own (heterogeneous) data distribution {Di}in=1. The case of empirical risk minimization with mi
datapoints ξi	〜	Di	on worker i is obtained when using	Li(X)	:=	m1-	Pm=I	Li(x,	ξj).	The
(stochastic) gradient computed by a good node i with sample j is given as gi(x) := VLi(x, ξj)
with mean μi and variance σ2. We also assume that the heterogeneity (variance across good workers)
is bounded i.e.
EikVLi(X)-VL(x)k2 ≤ σ2, ∀x .
We write gi instead of gi (Xt) when there is no ambiguity. A distributed training step using an
aggregation rule is given as
Xt+1 := Xt - γtAggr({gi (Xt) : i ∈ [n]})
(2)
If the aggregation rule is the arithmetic mean, then (2) recovers standard minibatch SGD.
Byzantine attack model. In each iteration, there is a set Byz of at most f Byzantine workers. The
remaining workers are good, thus follow the described protocol. A Byzantine worker j ∈Byz can
deviate from protocol and send an arbitrary vecter to the server. Besides, we also allow that Byzantine
workers can collude with each other and know every state of the system. Unlike martingale-based
approaches like (Alistarh et al., 2018), we allow the set Byz to change over time (Blanchard et al.,
2017; Chen et al., 2017; Mhamdi et al., 2018).
2	Related work
There has been significant recent work of the case when the workers have identical data distributions
(Blanchard et al., 2017; Chen et al., 2017; Mhamdi et al., 2018; Alistarh et al., 2018; Mhamdi et al.,
2018; Yin et al., 2018a;b; Su & Xu, 2018; Damaskinos et al., 2019). We discuss the most pertinent
of these methods next. Blanchard et al. (2017) formalize the Byzantine robust setup and propose
a distance-based approach Krum which selects a worker whose gradient is very close to at least
half the other workers. A different approach involves using the median and its variants (Blanchard
et al., 2017; Pillutla et al., 2019; Yin et al., 2018a). Yin et al. (2018a) propose to use and analyze the
coordinate-wise median method (Cm). Pillutla et al. (2019) use a smoothed version of Weiszfeld’s
algorithm to iteratively compute an approximate geometric median of the input gradients. In a third
approach, (Bernstein et al., 2018) propose to use the signs of the gradients and then aggregate them
by majority vote, however, (Karimireddy et al., 2019) show that it may not always converge. Finally,
Alistarh et al. (2018) use a martingale-based aggregation rule which gives a sample complexity
optimal algorithm for iid data. The distance-based approach of Krum was later extended in Mhamdi
et al. (2018) who propose BULYAN to overcome the dimensional leeway attack. This is the so
called strong Byzantine resilience and is orthogonal to the question of non-iid-ness we study here.
Recently, (Peng & Ling, 2020; Yang & Bajwa, 2019a;b) studied Byzantine-resilient algorithms in
the decentralized setting where there is no central server available. Extending our techniques to the
decentralized setting is an important direction for future work.
In a different line of work, (Lai et al., 2016; Diakonikolas et al., 2019) develop sophisticated spectral
techniques to robust estimate the mean of a high dimensional multi-variate standard Gaussian
distribution where samples are evenly distributed in all directions and the attackers are concentrated in
one direction. Very recent work (Data & Diggavi, 2020) extend the theoretical analysis to non-convex,
strongly-convex and non-i.i.d setup under a gradient dissimilarity assumption and propose a gradient
compression scheme on top of it. Our resampling trick can be combined with it to further reduce
gradient dissimilarity.
Many attacks have been devised for distributed training. For the iid setting, the state-of-the-art attacks
are (Baruch et al., 2019; Xie et al., 2019b). The latter attack is very strong when the fraction of
adversaries is large (nearly half), but in this work we focus on settings when this fraction is quite
small (e.g. ≤ 0.2). Further our normalized mean attack Section 3.2 is inspired by (Xie et al., 2019b).
The former work focuses on attacks which are coordinated across time steps. Developing strong
practical defenses even in the iid case against such time-coordinated attacks remains an open problem.
In this work, we sidestep this issue by restricting ourselves to new attacks made possible by non-iid
data and studying how to overcome them. We focus on schemes which work in the iid setting, but fail
with non-iid data. Once a new method which can defend against (Baruch et al., 2019) is developed,
our proposed scheme shows how to adapt such a method to the important non-iid case. For the
non-iid setting, backdoor attacks are designed to take advantage of heavy-tailed data and manipulate
2
Under review as a conference paper at ICLR 2021
model inference on specific subtask, rather than lower the overall accuracies of training (Bagdasaryan
et al., 2018; Bhagoji et al., 2018). In contrast, this paper is not intended to address aforementioned
challenges but rather to defend the attacks that lower the training accuracies in the non-iid setting.
As far as we are aware, only (Li et al., 2019; Ghosh et al., 2019; Sattler et al., 2020) explicitly
investigate Byzantine robustness with non-iid workers. Li et al. (2019) proposes an SGD variant
(RSA) which modifies the original objective by adding an `1 penalty. Ghosh et al. (2019); Sattler et al.
(2020) assume that all workers belong to an apriori fixed number of clusters and use an outlier-robust
clustering method to recover these clusters. If we assume that the server has the entire training dataset
and can control the distribution of samples to good workers, Xie et al. (2019a); Chen et al. (2018);
Rajput et al. (2019) show that non-iid-ness can be overcome. Typical examples of this is distributed
training of neural networks on public cloud, or volunteer computing Meeds et al. (2015); Miura &
Harada (2015). However, none of these methods are applicable in the standard federated learning
setup we consider here. We aim to minimize the original loss function over workers while respecting
the non-iid data locality, i.e. the partition of the given heterogeneous dataset over the workers, without
data transfer.
3	Attacks against existing aggregation schemes
In this section we show that when the data across the workers is heterogeneous (non-iid), then we
can design new attacks which take advantage of the heterogeneity, leading to the failure of existing
aggregation schemes. We study three classes of robust aggregation schemes: i) schemes which select
a representative worker in each round (e.g. Krum (Blanchard et al., 2017)), ii) schemes which use
normalized means (e.g. Rsa (Li et al., 2019)), and iii) those which use the median (e.g. Rfa (Pillutla
et al., 2019)). We show realistic settings under which each of these classes would fail when faced
with heterogeneous data.
3.1	Failure of representative worker schemes on non-iid data
Algorithms like Krum select workers who are representative of a majority of the workers, by relying
on statistics such as pairwise differences between the various worker updates. Let (g1 , . . . , gn) be
the gradients by the workers, f of which are Byzantine (e.g. n ≥ 2f + 3 for KRUM). For i 6= j , let
i → j denote that gj belongs to the n - f - 2 closest vectors to gi. Then KRUM is defined as follows
KRUM(g1, . . . ,gn) := arg mini Pi→j kgi - gjk2
(3)
However, when the data across the workers is heterogeneous, there is no ‘representative’ worker.
This is because each worker computes their local gradient over vastly different local data. Hence, for
convergence it is important to not only select a good (non-Byzantine) worker, but also ensure that
each of the good workers is selected with roughly equal frequency. Hence Krum suffers a significant
loss in performance with heterogeneous data, even when there are no Byzantine workers.
For example, when KRUM is used for iid datasets without adversary (f = 0, see left of Figure 1a),
the test accuracy is close to simple average and the gap can be filled by Multi-krum (Blanchard
et al., 2017). The right plot of Figure 1a also shows that Krum’s selection of gradients is biased
towards certain nodes. When Krum is applied to non-iid datasets (the middle of Figure 1a), Krum
performs poorly even without any attack. This is because Krum mostly selects gradients from a few
nodes whose distribution is closer to others (the right of Figure 1a). This is an example of how robust
aggregation rules may fail on realistic non-iid datasets.
3.2	Attacks on normalized aggregation schemes
Instead of simply averaging the gradients, some methods first normalize them and then average. This
limits the influence of the Byzantine workers since they cannot output extremely large gradients, and
hence is more robust. For example RFA (Pillutla et al., 2019) with T=1 uses following aggregation
rule:
NM(g1, ..., gn) = Pn=1 kgik2
(4)
Other methods such as Rsa (Li et al., 2019) or signum (Bernstein et al., 2018) normalize entries
coordinate-wise before taking a majority vote i.e. update the server model x0 on server using local
model xi from node i (not gradient) using
RSA(x0; xι,..., Xn) := Vf0(x0) + λPn=Isign(xo - Xi)
(5)
3
Under review as a conference paper at ICLR 2021
(东)>us⊃uu≤ ttωπ
nd non-ιιd Selections
246802468	01234567
Iteration Iteration Nodes
iid
non-ιιd
Accuracy
< 25
⅛5
S
C
⅛50
Iterations
246802468	0	1	2
Iterations #Byzantine (f)
(a) Left & middle: Comparing arithmetic mean with (b) Comparing normalized mean (Rfa with T=1) under
KRUM on iid and non-iid datasets, without any Byzan- the normalized mean attack with f = 0, 1, 2 attack-
tine workers. Right: Histogram of selected gradients. ers.
f=0 iid f=2 iid f=2 non-iid
Ooo
9 8 7
(东)Aue.lnuu4tttul
24680246802468
Iterations Iterations Iterations
(c) Comparing coordinate-wise median (Cm) and ge-
ometric median (RFA with T=8) under the mimic2
attack on iid and non-iid datasets.
Figure 1: Failures of existing aggregation rules on the non-iid MNIST dataset. In all experiments,
there are 8 good and f Byzantine workers.
where f0 is a strongly convex penalty term and λ > 0 is a relaxation parameter.
However, a Byzantine worker can still craft an “omniscient” attack to foil robust aggregations, using
an approach similar to the negative sum for the arithmetic mean (Blanchard et al., 2017; Li et al.,
2019):
V := — P、	, ,, gi,,—
:	乙i∈good ∣∣gik2
(6)
On the right side of Figure 1b, we can see that this attack lowers the accuracy of Rfa-T1 significantly,
as the number of Byzantine workers increases. Comparing to its iid counterpart, the normalized mean
attack is even more impactful in the non-iid setting.
3.3 Attacks on median-based schemes
Geometric median and its variants are popular in robust learning research (Blanchard et al., 2017;
Chen et al., 2017; Pillutla et al., 2019; Yin et al., 2018a; Mhamdi et al., 2018). Given gradients
{g1 , . . . , gn}, we use the estimator
GM(g1, . . . ,gn) := argminv Pin=1kv - gik .	(7)
If the vectors {g1, . . . , gn} are drawn independently from the same distribution, intuitively most of
them would concentrate around their mean. Then, even if there are some Byzantine outputs, the
median would ignore those as outliers and output a ‘central’ point close to the mean.
However, when {g1, . . . , gn} are gradients over heterogeneous data, they may be vastly different
from each other and do not concentrate around the mean. In such a scenario, the median such
as (7) can be even less robust than simply taking the mean. Suppose that worker 0 is Byzantine
and the remaining workers {1, . . . , 2n} are good, with a total of 2n + 1 workers. Now suppose that
gi = (-1)i for all the workers, with half the good workers having -1 and the other half +1. This
means that the true mean is 0, however, the median estimator (7) will output 1.
Mimic attack. This motivates our mimic attack in which all Byzantine workers collude and agree to
always send gradients from the same worker. We define a specialized attack, called mimic2, where
half of the good workers have same datasets and send g1 while the rest good workers send g2 ; then
all Byzantine workers send v = g1 such that the geometric median of the gradients received by the
server is always g1. Therefore, this attack breaks geometric-median-based robust aggregation rules,
by leading them to wrong solutions. The left plot of Figure 1c shows the impact of the mimic2 attack.
Test accuracies of Cm and Rfa both drop drastically to around 50%.
4
Under review as a conference paper at ICLR 2021
Algorithm 1 Robust Learning with Resampling
Setup: n workers, f of which are Byzantine; resampling T times, each time samples S gradients.
A robust learning algorithm AGGR on iid datasets; Y is the learning rate.
Workers:
1.	Each good worker i randomly samples a datapoint j and computes a stochastic gradient
gi := VFi(x, ξj) where ξj 〜 Di; each Byzantine worker i sends arbitrary vector g%.
2.	Send gi to server.
Servers:
1.	Receive {gi }in=1 from all workers.
2.	S, IS = Resampling({gi : i ∈ [n]}, f, T, s); See Algorithm 2 .
3.	Compute x0 := x - γAGGR(S);
4.	Broadcast x0 to all workers.
Algorithm 2 Resampling with s-replacement
Input: {gi : i ∈ [n]}, T := n, s, {c[i] := 0 : i ∈ [n]}
for t := 1, . . . , T do
for i := 1, . . . , s do
while Select ji 〜Uniform([n]) do
if c[ji] < s then
c[ji] += 1
If c[ji] == s Break;
Compute average gt ：= 1 Ps=I gj
RetUrn {gt : t ∈ [T]}, {jt ： t ∈ [T],i ∈ [s]}
4 Robust aggregation on non-iid data
In Section 3 we have demonstrated how existing robust aggregation rules can fail in realistic non-iid
scenarios, with and without attackers (Sections 3.2 and 3.3 and Section 3.1 respectively). To overcome
this problem, we propose a simple new resampling-based aggregation rule for training, shown in
Algorithm 1. More specifically, we choose s-resampling without replacement in Algorithm 2 where
each gradient can be sampled at most s times. The key property of our rule is that after resampling,
the resulting set of averaged gradients {gt ： t ∈ [T]} are much more homogeneous (lower variance).
Then these averaged gradients are fed to existing Byzantine robust aggregation schemes, such as
KRUM, see Section 5. Given an existing aggregation rule AGGR, we denote by AGGR ◦ Resampling
the resulting new robust aggregation rule for non-iid input gradients.
In the following proposition, we list the desired properties of Algorithm 2
Proposition I. Given a population {gi : i ∈ [n]} ⊂ Rd of mean μ := n pn=1 gi and variance
σ2 := 1 En=IIlgi — μk2 ,let {gt : t ∈ [T ]} be the output OfAlgorithm 2 on {gi : i ∈ [n]} .Then
• Ifthere are no Byzantine workers, then {gt : t ∈ [T]} are identically distributed
E[gt] = μ, var(gt) = Sn-1 σ2	∀ t ∈ [T]	(8)
• If f of the n inputs are Byzantine, then at least T 一 Sf gradients in {gt : t ∈ [T ]} are good;
that is, a good gt is the average of gradients {gjt : i ∈ [s]} ⊂ good ⊂ [n]. Then such good
{gt} are identically distributed with
E[gt] = μ, var(gt) = Snn-1-σ2	(9)
where μ :=舟 Pi∈good gi,and σ2 := g⅛ Pi∈good kgi 一 E[gt]k2.
Proof. Since Algorithm 2 resamples S gradients to estimate a population of Sn samples, we can use
sampling theory (Middleton, 1988, Ch. Survey Sampling) to compute the sample mean
E [RS(gι,...,gn)] = μ	(10)
and the sample variance
E [(RS(g1,..., gn) - μ)2] = S(1 - Ss--1 )σ2 = Sn-11 σ2.	4 * * * * * * (II)
Since the gradients are sampled at most S times, at most Sf out of the T gradients are affected by a
Byzantine worker. Its mean and variance can be calculated in the same way shown above. □
5
Under review as a conference paper at ICLR 2021
Remark 1. For S = 1, resampling simply becomes shuffling of the input elements, and var (cjt)二
σ2 is unchanged. For s > 1, the resampling scheme reduces the heterogeneity (variance) by
approximately 1/s. Thus, increasing s leads to the resulting resampled gradients being a better
estimator of the population mean, thus improving training convergence speed. On the other hand,
increasing s also increases the number of resampled gradients which can be affected by a Byzantine
worker. In particular, if f workers are Byzantine, then up to fs resampled gradients can be incorrect,
which has to be taken into account by the employed robust aggregation rule. In practice, we found
that using a small value s = 2 was already sufficient to overcome heterogeneity.
Remark 2. A natural question to ask is what happens if we resample with replacement but do not
limit on the number of replacements. We discuss this additional algorithm variant in Appendix C.
Note that the {gt : t ∈ [T]} are identically distributed but not independent. This does not directly fit
into the original assumptions of Byzantine robust algorithms like Krum and hence the robustness
has to be reproved for our more general setting.
5 Convergence analysis with Krum
In this section, we analyze the convergence of SGD with robust aggregation on non-iid data. Since
the definition of robustness and other conditions vary from paper to paper, it is not possible to give a
uniform proof perfectly fit for all methods. For example, (Yin et al., 2018a) assumes the gradients
have bounded variance and skewness whereas others like Krum, Rfa, Bulyan does not. Thus we
only analyze Krum for its simplicity and popularity, and show that analysis is only slightly different
from the original version. For other algorithms, we show by experiments that resampling helps them
achieve better performance on heterogeneous data, see Section 6.
Definition A generalizes the Byzantine resilience of (Blanchard et al., 2017, Definition 1) to the cases
where we have non-iid data. Let G be an estimator of the good gradients.
Definition A ((α, f)-Byzantine Resilience.). Let 0 ≤ α < π∕2 be any angular value, and any
integer 0 ≤ f ≤ n. Let B = {jι,...,jf : jι ≤ jι < •…< jf ≤ n} be the indices of Byzantine
workers. Let {Vi ∈ Di : i ∈ [n]\B} be independent random vectors in Rd. Let G = G(ξ) be an
independent random variable which randomly selects a good worker i and samples a vector from Di
and E G = g. Let B1, . . ., Bf be any Byzantine vectors in Rd, possibly dependent on the Vi ’s. An
aggregation rule F is said to be (α, f)-Byzantine resilient if
F = F(V1, . . . , B1 , . . . , Bf , . . . Vn)
|{z}	|{z}
j1	jf
satisfies (i)(E F, gi ≥ (1 — Sin a) ∙∣∣gk2 > 0 and (ii)for r = 2, 3,4, E ∣∣F∣∣r ≤ E ∣∣Gkr.
Then we can conclude the almost sure convergence similar to (Blanchard et al., 2017, Proposition 2)
Theorem II (Resampling KRUM). We assume that (i) the cost function L is three times differentiable
with continuous derivatives and non-negative L(x) ≥ 0; (ii) the learning rates satisfy t γt = ∞
and t γt2 < ∞. Let the good workers have stochastic gradients Gi(x, ξ) for i ∈ good ⊂ [n]. We
assume that for a uniformly chosen j ∈ good, the following is true (iii) Ej,ξ [Gj (x, ξ)] = VL(x)
and ∀r ∈ {2, 3, 4}, Ej,ξ ∣Gj (x, ξ)∣r ≤ Ar + Br ∣x∣r for some constants Ar, Br; (iv) there exists
a constant 0 ≤ α < π∕2 such that for all X we have η(T, sf) ∙ √d ∙ σ(x) ≤ ∣∣VL(x)∣ ∙ sin a
where σ2(x) := Sn-Iσ2(x);(v) finally, beyond a certain horizon, ∣x∣2 ≥ D, there exist ε > 0 and
0 ≤ β < π∕2 — α such that ∣∣VL(x)∣ ≥ ε > 0 and (x, VL(x)i ≥ cosβ∣∣x∣∣∙ ∣∣VL(x)∣. If S > 1
and 2sf + 3 ≤ n, then
•	KRUM ◦ Resampling is (α, Sf)-Byzantine resilient where 0 ≤ α < π∕2 is defined by
sin α = η( 尚 L (X√d,σ, η(n, f) ：= W - f+ fn- --”-T))	(12)
•	the sequence of gradients VL(xt) converges almost surely to zero.
We defer the proof to Appendix A. The above convergence result for heterogeneous data is nearly
identical to (Blanchard et al., 2017, Proposition 2) for iid data, except for the slightly stronger
restriction on the number of Byzantine workers 2Sf + 3 ≤ n.
6
Under review as a conference paper at ICLR 2021
(东)>us⊃uu≤ ttωπ
iid
Selections
600
200
246802468
Iteration
Iteration
01234567
Nodes
non-ιιd
iid
< 25
⅛5
g
*
⅛50
∙,Γ		
		
	f=0 ——f=l ——f=2 .■…f=0 RS ——f=l RS ——f=2 RS	
Iterations
non-ιιd
Accuracy
Iterations
# Byzanti ne (f)
246802468	0	1	2
(a) Left & middle: Comparing arithmetic mean with (b) Comparing normalized mean (Rfa with T=1) under
KRUM on iid and non-iid datasets, without any Byzan- the normalized mean attack with f = 0, 1, 2 attack-
tine workers. Right: Histogram of selected gradients. ers.
(东)Aue.lnuu4tttul
Ooo
8 7 6
f=0 iid
f=2 iid
CM
T- RFA-T8
CM+RS
τ-∙ RFA-T8+RS
f=2 non-ιιd
2 4 6 8 0 2 4 6 8 0 2 4 6 8
Iterations Iterations Iterations
O
9
(c) Comparing coordinate-wise median (Cm) and geo-
metric median (RFA with T=8) under mimic2 attack
on iid and non-iid datasets.
Figure 2: Combining resampling with existing aggregation rules on non-iid MNIST dataset. In all
experiments, there are 8 good and f Byzantine workers. For each aggregation we resample and
average s gradients for T = n times.
6	Experiments
In this section, we demonstrate the effect of resampling on datasets distributed in a non-iid fashion.
Throughout the section, we illustrate the challenge, attacks, and defense by an example of training an
MLP on the MNIST dataset (LeCun et al., 1998). In Appendix D, we present the results of similar
experiments on Fashion-MNIST (Xiao et al., 2017) and CIFAR-10 (Krizhevsky et al., 2009). The
dataset is sorted by labels and sequentially divided into equal parts among good workers; Byzantine
workers have access to the dataset on all good workers. Implementations are based on PyTorch
(Paszke et al., 2019) and will be made publicly available.
6.1	Resampling against the attacks on non-iid data
In Section 3 we have presented how heterogeneous data can lead to failure of existing robust
aggregation rules. Here we apply our proposed resampling with T =n, s=2 to the same aggregation
rules, showing that resampling overcomes the described failures. Results are presented in Figure 2.
In Figure 2a, we show that using resampling helps Krum to achieve better test accuracy on non-
iid data. Since resampling KRUM with s=2 actually averages 2 gradients, we compare it with
MULTIKRUM with m=2. The middle of Figure 2a shows that MULTIKRUM with m=2 performs
better than Krum, but Krum with resampling is even better which suggests the resampling step
improves the performance on non-iid data. The selection histogram on the rightmost part of Figure 2a
shows that after resampling, Krum’s selection is much more evenly distributed between the good
workers. In Figure 2b, we show that resampling fixes RFA with T=1 and allows it to defend against
the normalized mean attack. The resampling-based aggregation can almost reach same accuracy for
both iid and non-iid setup. In Figure 2c, while mimic attack does not work for median-based rules in
the iid setting, resampling still slightly improves the performance due to variance reduction. In the
non-iid setting, resampling drastically improves the accuracy to the same level as the iid setting.
6.2	Resampling against general Byzantine attacks
In Figure 3, we present thorough experiments on non-iid data over 10 workers with 2 Byzantine
workers. In each subfigure, we compare an aggregation rule with its variant with resampling. Three
aggregation rules are compared: Krum, Cm, Rfa. In particular, we compare to Rfa with both T=1
(normalized mean) and T=8 (geometric median).
7
Under review as a conference paper at ICLR 2021
Attack = BF ∣ Aggr = KRUM	Attack = BF ∣ Aggr = CM	Attack = BF ∣ Aggr = RFA-Tl Attack = BF ∣ Aggr = RFA-T8
Ooooo
8 6 4 2
Attack = G I Aggr = KRUM
Attack = G I Aggr = CM
Attack = LF I Aggr = RFA-Tl
Attack = LF I Aggr = RFA-T8
Attack = G I Aggr = RFA-T8
Ooooo
8 6 4 2
索)AUaJnUUq
Ooooo
8 6 4 2
案》∕bejnuu4
Ooooo
8 6 4 2
200	400	600	800
Iterations
200	400	600	800
Iterations
Attack = G I Aggr = RFA-Tl
Attack = MMC I Aggr = RFA-Tl
Attack = MMC2 ∣ Aggr = RFA-Tl
200	400	600	800
Iterations
Resample
---False
---True
f=0
---False
---True
Attack = MMC I Aggr = RFA-T8
Attack = MMC2 I Aggr = RFA-T8
200	400	600	800
Iterations
Figure 3: Test accuracies of Krum, Cm, Rfa under 5 kinds of attacks (and without attack) on
non-iid datasets. There are 10 workers and 2 of them are Byzantine according to each attack row.
Columns show each aggregation rule applied without (red) and with resampling (blue). Dashed lines
for comparison are showing the same method without any Byzantine workers (f = 0). For RFA, T1,
T8 refers to the number of inner iterations of Weiszfeld’s algorithm.
Attacks. 5 different kinds of attacks are applied (one per row in the figure): bitflipping, labelflipping,
gaussian attack, as well as the mimic and mimic2 attacks.
•	Bitflipping: A Byzantine worker flips the sign bits and sends -Vf (x) instead of Vf (x)
because of problems like hardware failures etc.
•	Labelflipping: The dataset on workers have corrupted labels. For the MNIST dataset, we
let Byzantine workers transform labels by T(y) := 9 - y.
•	Gaussian: A Byzantine worker sends a Gaussian random vector of 0 mean and isotropic
covariance matrix with standard deviation 200 (Xie et al., 2018).
•	mimic & mimic2: Explained in Section 3.3.
From Figure 3 we can see that resampling improves the accuracy on most of the tasks. The final
accuracies achieved vary with the aggregation rules we use. Notice that Rfa-T1 is more robust to
the mimic attack than Rfa-T8 in Figure 3 because more inner iterations lead to better approximate
geometric median and less robust to normalized mean attacks. The normalized mean attack has been
addressed in Section 3.2.
7	Conclusion
In this paper, we initiated a study of robust distributed learning problem under realistic heterogeneous
data. We showed that many existing Byzantine-robust aggregation rules fail under simple new attacks,
or sometimes even without any Byzantine workers. As a solution, we propose a resampling scheme
8
Under review as a conference paper at ICLR 2021
which effectively adapts existing robust algorithms to heterogeneous datasets at a negligible computa-
tional cost. We believe robustness under heterogeneous conditions has been an overlooked direction
of research thus far and hope to inspire more work on this topic. Extending to the decentralized
setting, stronger Byzantine adversaries, as well as obtaining optimal algorithms are other challenging
directions for future work.
9
Under review as a conference paper at ICLR 2021
References
Dan Alistarh, Zeyuan Allen-Zhu, and Jerry Li. Byzantine stochastic gradient descent. In NeurIPS -
Advances in Neural Information Processing Systems,pp. 4613-4623, 2018.
Eugene Bagdasaryan, Andreas Veit, Yiqing Hua, Deborah Estrin, and Vitaly Shmatikov. How to
backdoor federated learning, 2018.
Moran Baruch, Gilad Baruch, and Yoav Goldberg. A little is enough: Circumventing defenses for
distributed learning. arXiv preprint arXiv:1902.06156, 2019.
Jeremy Bernstein, Jiawei Zhao, Kamyar Azizzadenesheli, and Anima Anandkumar. signSGD with
majority vote is communication efficient and fault tolerant. arXiv preprint arXiv:1810.05291,
2018.
Arjun Nitin Bhagoji, Supriyo Chakraborty, Prateek Mittal, and Seraphin Calo. Analyzing federated
learning through an adversarial lens, 2018.
Peva Blanchard, El Mahdi El Mhamdi, Rachid Guerraoui, and Julien Stainer. Machine Learning with
Adversaries: Byzantine Tolerant Gradient Descent. In NeurIPS - Advances in Neural Information
Processing Systems 30, pp. 119-129, 2017.
Keith Bonawitz, Hubert Eichner, Wolfgang Grieskamp, Dzmitry Huba, Alex Ingerman, Vladimir
Ivanov, Chloe Kiddon, Jakub Konecny, Stefano Mazzocchi, H Brendan McMahan, et al. Towards
federated learning at scale: System design. In SysML - Proceedings of the 2nd SysML Conference,
Palo Alto, CA, USA, 2019.
Lingjiao Chen, Hongyi Wang, Zachary Charles, and Dimitris Papailiopoulos. Draco: Byzantine-
resilient distributed training via redundant gradients. arXiv preprint arXiv:1803.09877, 2018.
Yudong Chen, Lili Su, and Jiaming Xu. Distributed statistical machine learning in adversarial settings.
Proceedings of the ACM on Measurement and Analysis of Computing Systems, 1(2):1-25, Dec 2017.
ISSN 2476-1249. doi: 10.1145/3154503. URL http://dx.doi.org/10.1145/3154503.
Georgios Damaskinos, El Mahdi El Mhamdi, Rachid Guerraoui, Arsany Hany Abdelmessih Guirguis,
and Sebastien Louis Alexandre Rouault. Aggregathor: Byzantine machine learning via robust
gradient aggregation. Conference on Systems and Machine Learning (SysML) 2019, Stanford, CA,
USA, pp. 19, 2019. URL http://infoscience.epfl.ch/record/265684.
Deepesh Data and Suhas Diggavi. Byzantine-resilient sgd in high dimensions on heterogeneous data.
arXiv preprint arXiv:2005.07866, 2020.
Ilias Diakonikolas, Gautam Kamath, Daniel Kane, Jerry Li, Ankur Moitra, and Alistair Stewart.
Robust estimators in high-dimensions without the computational intractability. SIAM Journal on
Computing, 48(2):742-864, 2019.
Avishek Ghosh, Justin Hong, Dong Yin, and Kannan Ramchandran. Robust federated learning in a
heterogeneous environment. arXiv preprint arXiv:1906.06629, 2019.
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image
recognition, 2015.
Peter Kairouz, H. Brendan McMahan, Brendan Avent, Aurelien Bellet, Mehdi Bennis, Arjun Nitin
Bhagoji, Keith Bonawitz, Zachary Charles, Graham Cormode, Rachel Cummings, Rafael G. L.
D,Oliveira, Salim El Rouayheb, David Evans, Josh Gardner, Zachary Garrett, Adria Gasc6n, Badih
Ghazi, Phillip B. Gibbons, Marco Gruteser, Zaid Harchaoui, Chaoyang He, Lie He, Zhouyuan
Huo, Ben Hutchinson, Justin Hsu, Martin Jaggi, Tara Javidi, Gauri Joshi, Mikhail Khodak, Jakub
Konecny, Aleksandra Korolova, Farinaz Koushanfar, Sanmi Koyejo, Tancrede Lepoint, Yang Liu,
Prateek Mittal, Mehryar Mohri, Richard Nock, Ayfer Ozgur, Rasmus Pagh, Mariana Raykova,
Hang Qi, Daniel Ramage, Ramesh Raskar, Dawn Song, Weikang Song, Sebastian U. Stich, Ziteng
Sun, Ananda Theertha Suresh, Florian Tramer, Praneeth Vepakomma, Jianyu Wang, Li Xiong,
Zheng Xu, Qiang Yang, Felix X. Yu, Han Yu, and Sen Zhao. Advances and open problems in
federated learning. arXiv preprint arXiv:1912.04977, 2019.
10
Under review as a conference paper at ICLR 2021
Sai Praneeth Karimireddy, Quentin Rebjock, Sebastian U Stich, and Martin Jaggi. Error Feedback
Fixes SignSGD and other Gradient Compression Schemes. In ICML 2019 - Proceedings of the
36th International Conference on Machine Learning, 2019.
Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images. 2009.
Kevin A Lai, Anup B Rao, and Santosh Vempala. Agnostic estimation of mean and covariance. In
2016 IEEE 57th Annual Symposium on Foundations ofComputer Science (FOCS),pp. 665-674.
IEEE, 2016.
Leslie Lamport, Robert Shostak, and Marshall Pease. The byzantine generals problem. In Concur-
rency: the Works of Leslie Lamport, pp. 203-226. 2019.
Yann LeCun, Leon Bottou, YoshUa Bengio, and Patrick Haffner. Gradient-based learning applied to
document recognition. Proceedings of the IEEE, 86(11):2278-2324, 1998.
Liping Li, Wei Xu, Tianyi Chen, Georgios B Giannakis, and Qing Ling. RSA: Byzantine-robust
stochastic aggregation methods for distributed learning from heterogeneous datasets. In Proceed-
ings of the AAAI Conference on Artificial Intelligence, volume 33, pp. 1544-1551, 2019.
H. Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y Areas.
Communication-efficient learning of deep networks from decentralized data. arXiv preprint
arXiv:1602.05629, 2016.
Edward Meeds, Remco Hendriks, Said Al Faraby, Magiel Bruntink, and Max Welling. Mlitb:
machine learning in the browser. PeerJ Computer Science, 1:e11, Jul 2015. ISSN 2376-5992. doi:
10.7717/peerj-cs.11. URL http://dx.doi.org/10.7717/peerj-cs.11.
El Mahdi El Mhamdi, Rachid Guerraoui, and Sebastien Rouault. The hidden vulnerability of
distributed learning in byzantium. arXiv preprint arXiv:1802.07927, 2018.
D Middleton. Mathematical statistics and data analysis, by john a. rice. pp 595.1988. isbn 0-534-
08247-5 (wadsworth & brooks/cole). The Mathematical Gazette, 72(462):330-331, 1988.
Ken Miura and Tatsuya Harada. Implementation of a practical distributed calculation system
with browsers and javascript, and application to distributed deep learning. arXiv preprint
arXiv:1503.05743, 2015.
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor
Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al. Pytorch: An imperative style,
high-performance deep learning library. In Advances in Neural Information Processing Systems,
pp. 8024-8035, 2019.
Jie Peng and Qing Ling. Byzantine-robust decentralized stochastic optimization. In ICASSP 2020 -
IEEE International Conference on Acoustics, Speech and Signal Processing, pp. 5935-5939. IEEE,
2020.
Krishna Pillutla, Sham M. Kakade, and Zaid Harchaoui. Robust Aggregation for Federated Learning.
arXiv preprint arXiv:1912.13445, 2019.
Shashank Rajput, Hongyi Wang, Zachary Charles, and Dimitris Papailiopoulos. Detox: A redundancy-
based framework for faster and more robust gradient aggregation. arXiv preprint arXiv:1907.12205,
2019.
F. Sattler, K. Muller, T. Wiegand, and W. Samek. On the byzantine robustness of clustered federated
learning. In ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal
Processing (ICASSP), pp. 8861-8865, 2020.
Lili Su and Jiaming Xu. Securing distributed gradient descent in high dimensional statistical learning.
arXiv preprint arXiv:1804.10140, 2018.
Han Xiao, Kashif Rasul, and Roland Vollgraf. Fashion-mnist: a novel image dataset for benchmarking
machine learning algorithms, 2017.
11
Under review as a conference paper at ICLR 2021
Cong Xie, Oluwasanmi Koyejo, and Indranil Gupta. Generalized Byzantine-tolerant SGD. arXiv
preprint arXiv:1802.10116, 2018.
Cong Xie, Oluwasanmi Koyejo, and Indranil Gupta. Zeno: Distributed stochastic gradient descent
with suspicion-based fault-tolerance. In ICML 2019 - 35th International Conference on Machine
Learning, 2019a.
Cong Xie, Sanmi Koyejo, and Indranil Gupta. Fall of Empires: Breaking Byzantine-tolerant SGD by
Inner Product Manipulation. arXiv preprint arXiv:1903.03936, 2019b.
Zhixiong Yang and Waheed U Bajwa. Bridge: Byzantine-resilient decentralized gradient descent.
arXiv preprint arXiv:1908.08098, 2019a.
Zhixiong Yang and Waheed U Bajwa. ByRDiE: Byzantine-resilient distributed coordinate descent for
decentralized learning. IEEE Transactions on Signal and Information Processing over Networks,
2019b.
Dong Yin, Yudong Chen, Kannan Ramchandran, and Peter Bartlett. Byzantine-robust distributed
learning: Towards optimal statistical rates. arXiv preprint arXiv:1803.01498, 2018a.
Dong Yin, Yudong Chen, Kannan Ramchandran, and Peter Bartlett. Defending against saddle point
attack in byzantine-robust distributed learning. arXiv preprint arXiv:1806.05358, 2018b.
12
Under review as a conference paper at ICLR 2021
A Convergence analysis of Krum with resampling
Theorem II (Resampling KRUM). We assume that (i) the cost function L is three times differentiable
with continuous derivatives and non-negative L(x) ≥ 0; (ii) the learning rates satisfy t γt = ∞
and t γt2 < ∞. Let the good workers have stochastic gradients Gi(x, ξ) for i ∈ good ⊂ [n]. We
assume that for a uniformly chosen j ∈ good, the following is true (iii) Ej,ξ [Gj (x, ξ)] = VL(x)
and ∀r ∈ {2, 3, 4}, Ej,ξ kGj (x, ξ)kr ≤ Ar + Brkxkr for some constants Ar, Br; (iv) there exists
a constant 0 ≤ α < π∕2 such that for all X we have η(T, sf) ∙ √d ∙ σ(x) ≤ ∣∣VL(x)k ∙ Sin a
where σ2(x) := Sn-IIσ2(x);(v) finally, beyond a certain horizon, ∣x∣2 ≥ D, there exist ε > 0 and
0 ≤ β < π∕2 一 α such that ∣∣VL(x)∣ ≥ ε > 0 and(x, VL(x)i ≥ cosβ∣∣x∣∣∙ ∣∣VL(x)∣. If S > 1
and 2sf + 3 ≤ n, then
•	KRUM ◦Resampling is (α, sf)-Byzantine resilient where 0 ≤ α < π∕2 is defined by
sin α = η⅞f⅛σ ,η(n, f) ：= ,2(n - f+ 3 --+=Tf T))	(12)
•	the sequence of gradients VL(xt) converges almost surely to zero.
Proof. We only prove the first statement. The second one follows from applying (Blanchard et al.,
2017, Proposition 2) directly.
* t`.	ι ∙	1	~ m ι ∙	ι	. J-	f t~ .ι	i ʌ	. ∙ ɪɪ τ∙ .ι .
After resampling, We have n := T gradients, and at most f := Sf of them are Byzantine. Without
loss of generality, we assume that Byzantine vectors Bι,...,B f occupy the last f positions in the
arguments of KRUM. We denote as KRUM := KRUM(V1, . . . , Vnf-ff, B1, . . . , Bff). For each index i,
we denote by δc(i) (resp. δb(i)) the number of correct (resp. Byzantine) indices j such that i → j
(recall again that i → j denotes that Vj belongs to the n 一 f 一 2 closest vectors to Vi . We have
δc(i) + δb(i) = n - f — 2
n — 2f — 2 ≤ δc(i) ≤ n — f — 2
δb(i) ≤ f
X X T	1'	.1	1 • . •	/C /	J∙∖ 1 ʌ	, ∙	∙1 •	♦ 1 ʌ C ∙ , ∙	A X X T 1 .	♦
We focus first on the condition (i) of (α, f)-Byzantine resilience as in Definition A. We determine an
upper bound on the squared distance ∣ EKrum — g∣2. Note that, for any correct j, EVj = g. Let i*
be the index chosen by Krum.
IlEKRUM - gk2 ≤ IIE(KRUM — δc⅛) Pi*→correctj V )∣2
≤ EkKRUM - δ⅛) Pi*→correctj Vj ∣2
≤ Pcorrect i EkVi - δC1i) Pi→coιrectj Vj ∣∣21(i* = i)
.__	_~	-1	._.	二,,c ,.	-、
+ Pbyz k E∣Bk
—δc(k) Pk→correctj Vjk21(i* = k)
where 1 is the indicator function. Examine i* = i for correct index i.
kVi —	δC1i)	i→correctj	Vjk2 = k	δC1i)	Pi→correctj	Vi	-	Vj	k2
-I ___ . . ~	~	. . C
≤ δC(i) Pi→correctj IVi - Vj Il
..~	T	__ ~ ..C	T  	. . ~	~ ..C
EkVZi - δC(i) Pi→coιrectj Vj k ≤ δC(i) Pi→correctj EkVZi - Vj Il
≤ 2dσ2
where σ2 := Sn-IIσ2 in Proposition I. We now examine the case i* = k for some Byzantine index k.
The fact that k minimizes the score implies for all correct i
___	. . ~	~ ..C	___ . . ~	~ ..C	____ . . ~	~ ..C	__ . . ~	~ ..C
Pk→coιrectj kBk - Vj k + Pk→byz l kBk - Blk ≤ Pi→correctj kVi - Vj k + Pi→byz l kVi - Bl k
(13)
Then, for all correct indices i
kBk - δc(k) PPk→correctj Vjk ≤ δc(k) PPk→correctj kBk - Vjk
≤ δC(k) Pi→coιrectj kVi - Vj k2 + δC(k) Pi→byz l kVi - Blk2
13
Under review as a conference paper at ICLR 2021
1 `	t-λ9 / ∙∖ X^~'	Il -r'r Λ> 11 9	ι	,	ι ■ ι ~ p r、 ∙ ι ι	ι r . -ι
Focus on D2(i) := 5∑i→byz ι kVi - Blk2, each correct worker i has n - f - 2 neighbors, and f + 1
non-neighbors. Thus there exists a correct ζ(i) which is farther from i than any of the neighbors of i.
In particular, for each Byzantine index l such that i → l, kVi - BllI2 ≤ IM - VZ(i) k2. WhenCe
kBk -	δC(k)	Pk→correctj Vj k	≤	δC(k)	Pi→correctj	k Vi	-	Vj k	+	δc(k) kVi	-	VZ(i)k
EkB7______L P	V∙∣∣2 ≤ %(i) 2dσ2 + &(i) P	EkV - VV k2l (Z(i) — j)
EkBk δc(k)乙 k→correctj Vj k ≤ δc(k)2dσ + δc(k)乙 CoITeCt j=i EkVi V k 1(ζ (i) = j )
≤ ( %(i) + δbCO (n _ f _ ι))2dσ2
≤ ( δc(k)十 δc(k)(n	J 1))2dσ
≤ (n-f⅛ + nf (n - f - 1))2dσ2
Putting everything together we have
kEKRUM - gk2 ≤ (n - f)2dσ2 + f ∙ (n-f⅛ + -2f7-2(n - f - 1))2dσ2
≤ η2 (nf , ff)dσ2
By assumption η2(nf , ff)dσ2 < kgk, we know
hEKRUM,gi ≥ (kgk - η(n,f) ∙ ∖!f ∙ σ) ∙ kgk = (1 - smα) ∙ kgk2	(14)
To sum up, (i) of Byzantine resilience holds. Now we focuse on (ii),
_____________________________	..〜..C	____ ..〜	..C
EkKRUMk = PCorreCt i EkVik21(i* = i) + Pbyz k EkBkk21(i* = k)
We think of G as the estimator of gradients among good workers. More speCifiCally, G is a random
variable whiCh uniformly samples one worker among good workers and samples one gradient from
the worker. Then P(G = V) = nf PnrIf P(Vi = v), and
EkGkr= Pv P(G = v)kvkr = n-f Pn-If Pv P(¾ = v)kvkr = n-f P=Zf Ek¾kr	(15)
Thus
PCorreCt i EkVfikr ≤ Pin=-1f EkVikr = (nf - ff)EkGkr	(16)
We have
EkKRUMkr ≤ (n - f)EkGkr + Pbyz k EkBkk21(i* = k)
Denoting C a generic constant, when i* = k, we have for all correct indices i
kBk - δc(k) Pk→correct j Vjk ≤ J δc(k) Pi→coιrectj k Vi - Vj k2 + ^) k% - VZ(i)k2
≤ C ^ (qδc(k) Pi→correctj ∣M - Vjk + ^^
_________________________________________ ..〜
≤ C ∙ Pcorrect j kVj k
Now
11
kBkk≤kBk- δC(k)	X	Vjk + k δC(k)	X	Vjk
k→correct j	k→correct j
≤ C X kVfj k
correct j
~ 〜〜
kBk kr ≤ C Prι + →r-=r kVlkr1 …1匕刁户<
Take expectation to both sides and apply generalized Young’s inequality
ap1 …amm ≤ Piai +----------------------------------+ Pmam	(17)
where pi + …+ Pm = 1, We have
r
EkBkkr ≤ CPrι+∙→ri-f=r(r1 EkVIkr + …+ -vɪEkVn-Jkr) ≤ CEkGkr	(18)
the last inequality comes from (16). Thus we have proven property (ii) of (α, f)-Byzantine resilience.
□
14
Under review as a conference paper at ICLR 2021
A. 1 Alternative convergence proof of Krum with resampling
For completeness we also provide an alternative proof for a slight variation of the Byzantine Resilience
definition, under the same algorithm of Krum with resampling.
Definition B ((α, f)-Byzantine Resilience Alternative.). Let 0 ≤ α < π∕2 be any angular value,
and any integer 0 ≤ f ≤ n. Let V1, . . ., Vn be any identically distributed random vectors in Rd,
Vi 〜G, with E G = g. Let Bi, ..., Bf be any Byzantine vectors in Rd, possibly dependent on the
Vi fs. An aggregation rule F is said to be (α, f)-Byzantine resilient if, for any 1 ≤ ji < •…< jf ≤ n,
then
F = F(Vi, . . . , Bi , . . . , Bf , . . .Vn)
|{z}	|{z}
j1	jf
satisfies (i)(E F, gi ≥ (1 — Sin a) ∙∣∣gk2 > 0 and (ii)for r = 2, 3,4, E ∣∣F∣∣r ≤ E ∣∣Gkr.
Again, similarly as for the above Theorem II we can obtain almost sure convergence analogous to
(Blanchard et al., 2017, Proposition 2)
Theorem III (Resampling KRUM, Alternative). We assume that (i) the cost function L is three
times differentiable with continuous derivatives and non-negative L(x) ≥ 0; (ii) the learning rates
satisfy Et Yt = ∞ and Et γ2 < ∞; (iii) the gradient estimator satisfies E G(x, ξ) = VL(x) and
∀r ∈ {2, 3, 4}, E ∣G(x, ξ)∣r ≤ Ar +Br∣x∣rforsome constants Ar, Br; (iv) there exists a constant
0 ≤ α < π/2 such thatfor all X we have η(T, Sf) ∙ √d∙ σ(x) ≤ ∣∣VL(x)∣ ∙ sin α; (v)finally, beyond
a certain horizon, ∣x∣2 ≥ D, there exist ε > 0 and 0 ≤ β < π∕2 — a such that ∣∣VL(x)∣ ≥ ε > 0
and hx, VL(x)i ≥ cosβ∣∣x∣∣∙ ∣∣VL(x)∣. If S > 1 and 2sf + 3 ≤ n, then
•	KRUM ◦ Resampling is (α, sf)-Byzantine resilient as in Definition B where 0 ≤ α < π∕2 is
defined by
sin α =机部(X√d∙σ ,η(n, f) ：= '2(n - f+ f^-fUfn-T))	(19)
•	the sequence of gradients VL(xt) converges almost surely to zero.
Proof. A key difference between Definition B and (Blanchard et al., 2017, Definition 1) is that
Definition B removes the independence requirement for the input good gradients {Vi}in=-if. In
(Blanchard et al., 2017), there are two propositions: (Blanchard et al., 2017, Proposition 1) proves
that Krum satisfy (Blanchard et al., 2017, Definition 1), and (Blanchard et al., 2017, Proposition 2)
shows almost surely convergence of the gradient VL.
In our case, we only need to show that KRUM ◦Resampling satisfy Definition B because the conver-
gence of VL is identical to the proof of (Blanchard et al., 2017, Proposition 2). Since the gradients
after resampling is identically distributed according to Proposition I, we can keep all of the proofs of
(Blanchard et al., 2017, Proposition 1) except for the last inequality where the independence is used.
∣Bk∣r ≤ C X 馆|产…∣X-f llrn-f	(20)
r=rι+-+rn-f
By applying expectation to both sides of the inequality and the independence of {Vi}in=-if, they
conclude that
EkBkkr ≤ C Pr=rι +…+rnfE∣ H ∣r1…EkVn-f『n-f = C工厂门十一十%’|旧产…|4|a-『
(21)
We can immediately show that E∣Bk ∣r ≤ C∣G∣r with the help of a general form of Young’s
inequality. We prove this using the standard Young’s inequality. The Young’s inequality states that
for p > 1, q > 1, P + 1 = 1, a, b ≥ 0, we have
ab ≤ ap + bq	(22)
Let a =伍|尸"=IMIIr2 …∣vn-f ∣∣rn-f, andP = r1, q = r-rrγ, we apply Young,s inequality
rr2	rrn-f
IIVillr1 …∣K-f llrn-f ≤ UIIViIIr + T∣∣%∣∣E …∣K-f ∣…
15
Under review as a conference paper at ICLR 2021
rr2
We can apply Young's inequality agin for the second term of right hand side. Let a = ∣∣V21∣ r-rι,
rr3	rrn- f
b = ∣∣V3kr-r1 …||Vn-f k r-r1 , andP = r-2r1, q = r---r2, We apply Young’s inequality
rr3	rrn-f
kV1kr1 …∣κ-f krn-f ≤ rr ∣vιkr+r2 伍 ∣r+r-rr-r2 伍 ∣ r-r-2 …∣κ-f ∣ r-r-2 ≤ pn=f ri IMkr
Where the second inequality results from recursively applying Young’s inequality. Then We apply
expection to both sizes of the inequality gives
EkVIkrI …kK-f krn-f ≤ PMIf riElMkr = ∣Gkr
Then applying expectation to Equation (20) gives
EkBkkr ≤ CPr=rι+…+rn-f EkV1kr1 …k%-f krn-f = CkGkr	(23)
where C is a general coefficient.	□
B Convergence of B yzantine resilient SGD
In this section, we obtain a finite-time convergence guarantee for any algorithm which satisfies
(α, f)-Byzantine resilience. As far as we are aware, this is the first convergence result for KRUM.
From Theorem II, we know that Suppose that the following condition holds for any iterations k for
some constants δ ∈ (0, 1] and β ≥ 0 such that
kEF-gk2 ≤ (1 - δ)kgk2, and EkF -EFk2 ≤β2,	(24)
where F is the output of the robust-aggregation algorithm and g := Vf (Xk). This first condition
bounds the bias wheras the second part bounds the variance of F.
Convergence.
Theorem IV. Given any biased stochastic estimator F satisfying (24), the following holds for the
update xk+1 = xk - ηF and an L-smooth potentially non-convex f(x) lower-bounded by f?:
1 X1ov,r ∖∣∣2 V 2L(f(xo) - f?)	/8Lβ2(f(x0)- f?)
K 工 EkVf(Xk)k ≤ —δκ— + v-----------------------δ2κ-------
k=0
Proof. The following holds for any η ≤ L:
η2L
Ek[f (Xk+1)] ≤ f (Xk) - Eηhg, Fi +-2 kFk
η2 L	η2 β2 L
≤ f(χk) - Eηhg,Fi + η2-kEFk2 + η-÷2-
≤ f(χk) - 2kgk2 + 2kEF - gk2 + η2β-
n ≤ f(xk) - η2δkgk2 + η2β-.
The first inequality uses the smoothness of f, the second separated and bounded the variance of F by
β2, third inequality follows from rearranging terms and using η ≤ L, and the final inequality used
our bound on the bias of F . Now rearranging the terms and averaging over k gives:
1 K-1
gk	gk k2 ≤
K
k=0
2(f (XO) - f(xk)) + η-β2
ηδκ + δ
2(f (xo) - f?) + η-β2
ηδκ + δ
Picking η = min( L, J2(⅛β-f)) gives the desired rate.
□
16
Under review as a conference paper at ICLR 2021
Relation to other conditions. If F is an unbiased stochastic gradient E[F | xk] = g and variance
σ* 1 2 * *, then (24) holds with δ = 1 and β = σ. In this case, Thm. IV recovers the standard convergence
of SGD for smooth non-convex functions.
If instead, we have hEF, gi ≥ (1 - sin(α))kgk2, and EkF k2 ≤ kgk2 ≤ G2,
kEF - gk2 =kgk2 - 2hE[F],gi + kE[F]k2
≤kgk2-2hE[F],gi+EkFk2
≤2 sin(α)kgk2.
Thus, in this case (24) holds with δ = 1 - 2 sin(α), and β = G. Here, we only get convergence if
sin(α) ≤ 1. Further, the assumption that EkF∣∣2 ≤ ∣∣gk2 ≤ G2 is extremely strong.
C Resampling with replacement for robust learning
Algorithm 3 Resampling with replacement
Input: {gi : i ∈ [n]}, T, s
for t = 1, . . . , T do
Uniformly sample {gji}is=1 from {gi : i ∈ [n]}
Compute average gt := 1 Ps=I gj*
Return {gt : t ∈ [T]}, {jt : t ∈ [T],i ∈ [s]}
Contrary to resampling without replacement which has an explicit bound for malicious gradients
after resampling, its with-replacement version has no guarantee for the honest majority.
Lemma 3. Given a set of vectors {gi : i ∈ [n]} of any distributions, the output of Algorithm 3
{gt : t ∈ [T]} are identically distributed with expectation
1n
Egt = — TEgi	∀t ∈ [T]	(25)
n
i=1
If f ofthe inputs are Byzantine, then a subset S ⊂ {gt : t ∈ [T]} are notfaulty. The cardinality of S
is E|S| = bT(1 - f /n)s c and the gradients are identically distributed with expectation
Eg=/X Egi	∀g∈s	(26)
i∈good
Proof. Egt = E S Ps=I gi = S Ps=I Egi.
There are (1 - f/n) chance that a sampled gradient gji is good and (1 - f /n)s chance that all of the
S sampled gradients are good. Repeat the resampling for T times gives E|S| = [T(1 一 f∕n)sC.
Remark 4. The cjt has same expectation as minibatch sgd.
We denote the expected number of Byzantine gradients in {cjt : t ∈ [T]} as follows:
f:= T 一 E|S| = T (1-b(1- f/n)Sc)	(27)
Since the vectors in S are identically distributed, we can apply robust aggregation rule A, like
MUItik-KRUM, to {<gt : t ∈ [T]}. The convergence of Algorithm 1 for Multi-KRUM is stated below.
Theorem V (Resampled KRUM). Assume the dataset is decentralized stored. Assume other con-
ditions in (Blanchard et al., 2017, Prop. 1 & 2) hold true. K is the number of aggregations. If
2f + 2 < T, then with a probability pκ, KRUM◦ RSWR is Byzantine robust and the sequence of
gradients almost surely converges to zero. The p is defined as
bT/2c
p := X qdT/2e+i(1 一 q)bT/2c-i	(28)
i=0
where q = (1 一 f /n)s
17
Under review as a conference paper at ICLR 2021
Proof. The probability of gt is good is q =(1 - f/n)s. The probability of non-faulty majority after
RSWR is thus
bT/2c
p:= X qdT/2e+i(1-q)bT/2c-i
i=0
The output of RSWR are identically distributed by Lemma 3. Thus we know that the robust
aggregation rule converge with probability PK.	□
Remark 5. Consider the range of T, s, f. Since Theorem V requires 2f + 2 < T, we need
S < Iog(I/2+1∕T). Furthermore, S ≥ 1 is lower bounded, T > 2n, which only requires 2f < n.
log(1-f /n)	,	, n-2f
Remark 6. Notice that the cardinality |S | is stochastic which means it is possible to have a faulty
majority in any round. if the Byzantine gradients are very large, like gaussian attack, the model
diverges as soon as one Byzantine gradient is selected. On the other hand, in the experiment section,
we show that for many attacks (labelflipping, bitflipping, etc.) the error introduced by faulty majority
rounds are amortized overtime. To fix this issue, the server can normalize all the gradient by their
norm such that a faulty majority round would not lead to catestrophic consequences.
18
Under review as a conference paper at ICLR 2021
D Additional experiments
D.1 FASHION-MNIST
In this subsection, we demonstrate that our algorithm also works on modern dataset like Fashion-
MNISTXiao et al. (2017). Since the Fashion-MNIST is designed to be a drop-in replacement of
MNIST, we conduct experiments on Fashion-MNIST with same setups as Figure 3. The results are
presented in Figure 4.
KRUM	CM	RFA-Tl	RFA-T8
6u-dd 一s-q 6u-dd≡-ωq-u-ssne6 U-E-E
Nu-E-E
Figure 4: Test accuracies of Krum, Cm, Rfa under 5 kinds of attacks (and without attack) on non-iid
Fashion-MNIST datasets. There are 12 workers and 2 of them are Byzantine according to each attack
row. Columns show each aggregation rule applied without (red) and with resampling (blue). Dotted
lines for comparison are showing the same method without any Byzantine workers (f = 0). For RFA,
T1, T8 refers to the number of inner iterations of Weiszfeld’s algorithm.
O	2	4	6	8	O	2	4	6	8	O	2	4	6	8	O	2	4	6	8
Iterations	Iterations	Iterations	Iterations
Aggr AggroResampIing ■ - - - Aggr (f=0)	■ ■ ■ ■ AggroResampIing (f=0)
19
Under review as a conference paper at ICLR 2021
D.2 Cifar- 1 0
We run experiments on CIFAR-10 (Krizhevsky et al., 2009) with ResNet-20 (He et al., 2015). We
train our model on 12 nodes which includes 2 Byzantine attacker with mimic attack. We use Krum
as the aggregation rule for demonstration. We choose learning rate to be 0.1 and batch size per node
to be 120. The CIFAR-10 dataset is splitted across good nodes such that 50% of samples on each
good node has same distribution as overall distribution, the rest 50% are samples from a single class
which is different among good workers. We present our results in Figure 5.
----krum
----krumoResampling
60
(％)
50
40
30
20
10
0	500	1000	1500	2000	2500	3000	3500	4000
Batches
Figure 5: Compre KRUM and KRUM ◦Resampling for training ResNet-20 on CIFAR-10 dataset.
There are 10 good workers and 2 Byzantine workers.
Note that the accuracy in this example is lower than the normal setting because krum may bias
towards certain nodes. Besides, the batch norm maybe influenced by the heterogenous distribution of
data.
20
Under review as a conference paper at ICLR 2021
D.3 Resampling or fixed grouping
In (Chen et al., 2017), workers are grouped at the beginning of training, and they are trained on
i.i.d datasets. In contrast, resampling is performed every round, and applies to non-iid datasets. If a
Byzantine worker can predict the random bits on server, resampling becomes grouping in each round
which is still stronger than (Chen et al., 2017).
In Figure 7, we compare KRUM ◦resampling with vanilla KRUM and KRUM with fixed grouping. As
we can see, the fixed grouping has better accuracy than vanilla Krum, but weaker than resampling as
we expected.
KRUM	CM
RFA-Tl	RFA-T3
90.0
87.5
85.0
82.5
80.0
0
90.0-
87.5-
85.0-
82.5-
80.0
10Q Oo
8 6 4 2
() A2n3vl
une6euv
Qloo Q O
9 8 7 6 5
() >0E300< ⅞ωH
No-E-E iυfi<
0	2	4	6	8
Iterations
9080706050
l0,5,05
9 8 8 7
9080706050
0	2	4	6	8
Iterations
0	2	4	6	8	0	2	4	6	8	0	2	4	6	8
Iteratl- Aggr -- Aggr+RSWOR ——Aggr+RSWR Iterations
Figure 6: Comparing 3 aggregation rules under 5 kinds of attacks on non-iid datasets. There are 10
workers and 2 of them are Byzantine. In the grid of experiments, same aggregation rules are used in
the same column and same attacks are applied to the same row. The aggregation rules are KRUM
(Blanchard et al., 2017), CM (Yin et al., 2018a), RFA (Pillutla et al., 2019). The RFA-T1, T3, T8
refers to the number of inner iterations.
Figure 7: Comparison with no resampling, and fixed grouping for Krum on non-i.i.d datasets.
21
Under review as a conference paper at ICLR 2021
D.4 Resampling hyperparameter
The resampling hyperparameter s controls the variance reduction, as has been stated in Proposition I.
In Figure 8, we compare the performance of no resampling and resampling with s = 2, 3, 4 on
heterogenous MNIST dataset. There are 10 workers in total and no Byzantine workers. Each
experiment has been run for 5 times.
As we can see from Figure 8, higher s leads to faster convergence. It matches with the Proposition I
that higher s leads to greater variance reduction.
krum	cm
80-
S >UTO⅛8<
60-
40 -
20-
10000	20000	30000	10000	20000	30000
Iteration	Iteration
Figure 8: Compare no resampling with s = 2, 3, 4 on MNIST data. There are 10 workers and 0
Byzantine worker.
22