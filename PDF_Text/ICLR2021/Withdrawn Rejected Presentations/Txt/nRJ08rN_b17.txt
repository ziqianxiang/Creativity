Under review as a conference paper at ICLR 2021
Vision at A Glance: Interplay between Fine
and Coarse Information Processing Pathways
Anonymous authors
Paper under double-blind review
Ab stract
Object recognition is often viewed as a feedforward, bottom-up process in ma-
chine learning, but in real neural systems, object recognition is a complicated
process which involves the interplay between two signal pathways. One is the
parvocellular pathway (P-pathway), which is slow and extracts fine features of
objects; the other is the magnocellular pathway (M-pathway), which is fast and
extracts coarse features of objects. It has been suggested that the interplay be-
tween the two pathways endows the neural system with the capacity of process-
ing visual information rapidly, adaptively, and robustly. However, the underlying
computational mechanism remains largely unknown. In this study, we build a
two-pathway model to elucidate the computational properties associated with the
interactions between two visual pathways. The model consists of two convolu-
tion neural networks: one mimics the P-pathway, referred to as FineNet, which is
deep, has small-size kernels, and receives detailed visual inputs; the other mimics
the M-pathway, referred to as CoarseNet, which is shallow, has large-size kernels,
and receives blurred visual inputs. The two pathways interact with each other to
facilitate information processing. Specifically, we show that CoarseNet can learn
from FineNet through imitation to improve its performance considerably, and that
through feedback from CoarseNet, the performnace of FineNet is improved and
becomes robust to noises. Using visual backward masking as an example, we
demonstrate that our model can explain visual cognitive behaviors that involve the
interplay between two pathways. We hope that this study will provide insight into
understanding visual information processing and inspire the development of new
object recognition architectures in machine learning.
1	Introduction
Imagine you are driving a car on a highway and suddenly an object appears in your visual field,
crossing the road. Your initial reaction is to slam on the brakes even before recognizing the object.
This highlights a core difference between human vision and current machine learning strategies for
object recognition. In machine learning, visual object recognition is often viewed as a feedforward,
bottom up process, where object features are extracted from local to global in a hierarchical manner;
whereas in human vision, we can capture the gist of a visual object at a glance without processing
the details of it, a crucial ability for us (especially animals) to survive in competitive natural environ-
ments. This strategic difference has been demonstrated by a large volume of experimental data. For
examples, Sugase et al. (1999) found that neurons in the inferior temporal cortex (IT) of macaque
monkeys convey the coarse information of an object much faster than the fine information of it;
FMRI and MEG studies on humans showed that the activation of orbitofrontal cortex (OFC) pre-
cedes that of the temporal cortex when a blurred object was shown to the subject (Bar et al., 2006);
Liu et al. (2017) further demonstrated that the dorsal pathway extracts the coarse information of an
object in less than 100ms after the stimulus onset, and this coarse information guides the subsequent
local information processing.
Indeed, the Reverse Hierarchy Theory for visual perception has proposed that although the repre-
sentation of image features along the ventral pathway goes from local to global, our perception of an
object goes inversely from global to local (Hochstein & Ahissar, 2002). How does this happen in the
brain? Experimental studies have revealed that there exist two anatomically and functionally sepa-
rated signal pathways for visual information processing (see Fig.1). One is called the parvocellular
1
Under review as a conference paper at ICLR 2021
Retina
MRGC
EVA
LOC
P OPIane
OEagIe
K-e OKite
OBat
OBUtterfly
----► Feedforward
—>Feedback
Association
Figure 1: Illustration of the two separated pathways for information processing in the visual system.
An image of an eagle is processed through two pathways. Upper panel: the P-pathway processes the
detailed information of the image. Lower panel: the M-pathway processes the coarse information of
the image rapidly, generates predictions about the image (association), and modulates the informa-
tion processing of the P-pathway (feedback). MRGC: midget retina ganglion cell. PRGC: parasol
retina ganglion cells. EVA: early visual area. LOC: lateral occipital complex. IPS: intraparietal
sulcus. SC: superior colliculus. PFC: prefrontal cortex.
pathway (P-pathway), which starts from midget retina ganglion cells (MRGCs), projects to layers
3-6 in the lateral geniculate nucleus (LGN), and then primarily goes downstream along the ventral
stream. The other is called the magnocellular pathway (M-pathway), which starts from parasol retina
ganglion cells (PRGCs), projects to layers 1-2 of LGN, and then goes along the dorsal stream or the
subcortical pathway (the superior colliculus and downstream areas). The two pathways have differ-
ent neural response characteristics and complementary computational roles. Experimental findings
have shown that the P-pathway is sensitive to colors and responds primarily to visual inputs of high
spatial frequency; whereas the M-pathway is color blind and responds primarily to visual inputs of
low spatial frequency (Derrington & Lennie, 1984). It has been suggested that the M-pathway serves
as a short-cut to extract coarse information of images rapidly, while the P-pathway extracts fine fea-
tures of images slowly, and the interplay between two pathways endows the neural system with the
capacity of processing visual information rapidly, adaptively, and robustly (Bar, 2003; Wang et al.,
2020; Bullier, 2001; Liu et al., 2017). For instance, by extracting the coarse information of an im-
age, the M-pathway can generate predictions about what are expected in the visual field, and this
knowledge subsequently modulate the fine information processing in the P-pathway (Fig. 1).
Although the existence of separated P- and M- pathways is well known in the neuroscience field,
exactly how they cooperate with each other to facilitate information processing remains poorly un-
derstood. In this study, we build up a two-pathway model to elucidate the computational properties
associated with the interplay between two pathways (Fig. 2). We use convolution neural networks
(CNNs) as the building blocks, since recent studies have revealed that CNNs are effective to model
the neuronal response variability along the visual pathway (Yamins et al., 2013; Kriegeskorte, 2015).
Specifically, we model the P-pathway using a relatively deep CNN, which has small-size kernels and
receives detailed visual inputs, referred to as FineNet hereafter. The M-pathway is modeled by a rel-
atively shallow CNN, which has large-size kernels and receives blurred visual inputs, referred to
as CoarseNet hereafter. Based on the proposed model, we investigate several computational issues
associated with the interplay between two pathways, including how CoarseNet learns from FineNet
via imitation, and how FineNet benefits from CoarseNet via feedback to leverage its performance.
We also use the two-pathway model to reproduce the backward masking phenomenon observed in
human psychophysic experiments.
2	The two-pathway Model
The structure of our two-pathway model is illustrated in Fig. 2, where FineNet and CoarseNet mimic
the P- and M- pathways, respectively. Notably, FineNet is deeper than CoarseNet, reflecting that
the P-pathway goes through more feature analyzing relays (e.g., V1-V2-V4-IT along the ventral
pathway) than the M-pathway. FineNet also has smaller convolutional kernels than CoarseNet,
reflecting that MRGCs in the retina have much smaller receptive fields than PRGCs. Furthermore,
we consider that FineNet receives detailed and colourful visual inputs, reflecting that MRGCs have
small receptive fields and are color sensitive; while CoarseNet receives blurred and gray inputs,
reflecting that PRGCs have large receptive fields and are color blind.
2
Under review as a conference paper at ICLR 2021
(prediction)
Ca)
Figure 2: Illustration of the two-pathway model. (A) The architecture of the model. The blue and or-
ange blocks represent the feedforward convolutional layers in FineNet and CoarseNet, respectively.
The purple one represents the feedback convolution block in FineNet (for details, see Sec. 3.1).
In inference, CoarseNet extracts coarse features gc (X) from a blurred image x, which serves as
a cue to predict the fine features C(X) of the image via association. The associated result is then
combined with the deep representations hF(x, X) to form a feedback signal O(x, X), and the latter
modulates an early layer of FineNet. In training, FineNet is optimized by minimizing the classifica-
tion loss, and CoarseNet by minimizing both classification and imitation losses. (B) Illustration of
static memory association (SMA). A query of the coarse features gc (X) of the input X is associated
with a weighted summation of the fine features stored in the memory buffer, where the weighting
coefficient ∆k (X) is the similarity between the coarse features and the key vector uk.
In the model, we consider that the two pathways interact with each other in three forms: 1) Imitation
learning. Since CoarseNet has a shallow structure and receives blurred inputs, it is hard to train
CoarseNet well for object recognition directly. Hence we consider that CoarseNet learns the feature
representations of FineNet via an imitation process. Later we will argue that this has an important
biological implication (Sec. 3.2). 2) Association. It is supposed that the M-pathway generates
predictions about what might be in the visual scene, which guides the information processing in
the P-pathway. We model this by considering that CoarseNet predicts the representation of FineNet
through a memory association process. 3) Feedback. It is known that coarse information can serve
as a cognitive bias guiding the extraction of fine information of images. We model this by feeding
the associated prediction back to an earlier layer of FineNet to enhance the fine feature extraction.
The details of the two-pathway model are introduced below.
2.1	The inference process of the model
Denote the input to FineNet as X and the input to CoarseNet as X. X is obtained by either
filtering X with a 2D Gaussian filter or binarizing X. Denote the output of CoarseNet to be
pc(X) = fC [gc(X; θc); wc], where gc(∙; θc) and fC(∙; wc) represent, respectively, the fea-
ture extractor and the linear classifier of CoarseNet, and {θc , wc } the trainable parameters. The
output ofFineNet is similarly denoted as pF(x) = f F {gF [x, O(X, x); Θf] ; WF }, where the fea-
ture extractor gF(∙; θF) has an extra input component O(X; x), representing the feedback signal.
To generate the feedback signal O(X, x) in FineNet, We consider a memory association process.
Two types of associations are exploited in this work, static memory association (SMA) and dynamic
memory association (DMA) . They have the similar effect of using coarse features gc(∙; θc) as a
cue to predict fine features. SMA is simpler, but we also consider DMA, as it introduces temporal
dynamics into our two-pathway model necessary for reproducing the backward masking experiment
(see Sec. 3.6). For clearance, we only introduce SMA here (see Fig. 2B), and DMA is described
in Appendix F. Specifically, we implement SMA with the cache memory model (Orhan, 2018),
which performs a key-value association. The model stores a pair of a key matrix u ∈ Rd×K and
a value matrix v ∈ Rc×K in the memory buffer, with K the number of memory items and d,
c the dimensions of the key and value vectors, respectively. The columns uk and vk represent,
respectively, the normalized gc(Xk； θc) of CoarseNet and the flattened feature vector hF(Xk, Xk)
of the last convolution layer of FineNet. When a specific query vector gc(X) of CoarseNet is
presented, we first calculate its similarities with all key vectors stored in the memory buffer, which
are given by ∆k(X) = exp [βgc(X)>uJ, for k = 1,...K, with β controlling the sharpness of
similarity. After that, we calculate the associated result, i.e., the predicted fine features, which is
3
Under review as a conference paper at ICLR 2021
given by C(X) = Ek Vk∆k (X)/ [£卜 ∆k (X)]. The inference of FineNet forms a continuous loop
so that the feedback signal is updated iteratively (see Fig. 2A). At time step t, the feedback signal
in FineNet is calculated by Ot(x, x) = C(X) + hF-ι(x, X). Notably, at the first step t = 1, only
the associated result from CoarseNet is available, which gives Oι(X, x) = C(X). This reflects the
fact that the M-pathway is much faster than the P-pathway, which generates the first feedback signal
without interacting with high visual areas in the P-pathway.
In summary, the inference of the model involves interaction between two pathways: in response to
an image, CoarseNet first generates its output and meanwhile predicts the fine features of FineNet
through association; the predicted result is then combined with the deep representations of FineNet
to form a feedback signal, which modulates the shallow layer of FineNet for feature extraction; this
feedback loop can go on iteratively to continuously leverage the performance of FineNet.
2.2	The training of the model
During training, FineNet and CoarseNet are optimized jointly. To get the network output for an
input, we run the feedback loop iteratively in FineNet for T steps (T = 2 used in this study).
FineNet is optimized through minimizing the cross-entropy loss, which is given by
1NK
LF = -N XXyi,jlnPF(Xi),	⑴
i=1 j=1
where pjF is the jth element of pF, i.e., the likelihood of the jth class, and yi,j is the jth element
of the one-hot label yi for the image Xi, which is 1 for the correct class and 0 otherwise. The
summation runs over all images N and all classes K.
Since CoarseNet receives coarse inputs and has a shallow structure, we optimize it via a combination
of classification and imitation losses, which is written as
1 N I"	K	ι _	-
LC = Nf -a£yi,jln PC (3^i) + --kg IIgC (Xi) - gF (Xi, Xi)Il2 ,	(2)
N i=1	j=1	2
where the symbol ∣∣ ∙ ∣∣ denotes L2 normal, and a is a hyper-parameter balancing the cross-entropy
loss and the imitation loss.
Since SMA aims to store the long-term correlation (association) between the feature representations
of CoarseNet and FineNet, we update its key and value matrices after every two training epochs.
3	Interplay between Two Pathways
3.1	Implementation details
Based on the proposed model, we carry out simulation experiments to explore the computational
properties associated with the interplay between two pathways. Three datasets, Pascalvoc-mask,
CIFAR-10, and CIFAR-100 are used (see details Appendix A). To generate blurred inputs X to
CoarseNet, we either low-pass filter X using a2D Gaussian filter with std = 2 or binarizing X using a
shape mask (see examples in Fig. 7A and the details described in Appendix A.2). In the experiments,
FineNet consists of four convolutional layers (Fig. 2A), each of which comprises a 3 × 3 convolution,
followed by a group normalization, a ReLU nonlinearity. The numbers of convolutional filters
in 4 layers are [64, 128, 256, 512]. CoarseNet consists of two convolutional layers with the same
composition as in FineNet, except that it comprises 128-filter 7 × 7 convolution kernels in the first
layer and 512-filter 5 × 5 convolution kernels in the second layer. Both FineNet and CoarseNet have
a global pooling layer before the readout layer (for generating gc (X; θc) and gF(x, O(X, x); Θf),
respectively). The feedback kernel consists of an upsample layer and an 1 × 1 convolutional layer,
followed by group normalization and sigmoid nonlinearity. It takes O(X, x) as the input and output
a weighting term to modulate the representations in the second convolutional layer of FineNet via
element-wise multiplication. The balancing term α is 0.4 in Eq. 2. During training, the memory
buffer in SMA is updated after every two epochs, and β = 100. Both FineNet and CoarseNet share
the same training settings: the total number of training epochs is 150, SGD with a momentum term
4
Under review as a conference paper at ICLR 2021
0.9 is used to optimize parameters, and the initial learning rate is 0.05 which is multiplied with 0.1
after 100 and 125 epochs. For the training of dynamic memory association (DMA) implemented by
RBM, please refer to Appendix F.1.
3.2	Imitation learning improves CoarseNet
Figure 3: Imitation learning from FineNet improves the performance of CoarseNet. (A-B): perfor-
mances of CoarseNet trained on low-pass filtered images from CIFAR10. (A) Performances vs. the
number of convolution channels. (B) Performances vs. the size of convolution kernel. (C-D): per-
formances of CoarseNet trained on the binarized Pascalvoc-mask. (C) Performance vs. the number
of convolution channels. (D) Performance vs. the size of convolution kernel. See Appendix A for
the details of the training and testing data.
In the two-pathway model, CoarseNet is supposed to have a good initial guess of the image, which
serves as a cognitive bias to facilitate the performance of FineNet. However, since CoarseNet is
shallow, has large convolution kernels, and receives coarse inputs, it is hard to train CoarseNet
well independently. Therefore, we consider that CoarseNet learns the feature representations of
FineNet via imitation learning. This is an important property, which may have some far-reaching
implications to brain functions. We therefore carry out a separate experiment to study the effect
of imitation learning. In the experiment, we focus on exploring whether CoarseNet can learn from
FineNet via imitation, without considering other interactions between two pathways (the details of
the experiment are described in Appendix B).
The results are presented in Fig. 3, which demonstrates that with imitation, the classification accu-
racy of CoarseNet is improved considerably, compared to that without imitation over a wide range
of parameters. Specifically, with respect to the number of convolution kernels in CoarseNet, the
improvement is significant when the number of kernels is large (Fig. 3A for low-pass filtered inputs;
Fig. 3C for binarized inputs); with respect to the size of kernels in CoarseNet, the improvement is
also significant (Fig. 3B for low-pass filtered inputs; Fig. 3D for binarized inputs). The fact that
the effect of imitation learning also depends on the network parameters (Fig. 3A) indicates that in
reality there is a trade-off between having a simple structure for the M-pathway and the capability
of the M-pathway learning from the P-pathway.
From the computational point of view, the brain faces a difficulty of “designing” the M-pathway. On
one hand, the M-pathway needs to be shallow and process coarse visual inputs in order to generate
quick responses (which is important in a dangerous environment); on the other hand, the M-pathway
needs to efficiently generate approximated, if not accurate, recognition of an object, serving as a
good initial guess for further processing. However, it is a well-known fact that a shallow neural
network alone is unable to achieve good object recognition (this has actually motivated the devel-
opment of deep neural networks). So, how does the brain resolve this dilemma? Here, our study
suggests that the strategy of imitation learning proposed in machine learning (Hinton et al., 2015)
may provide a solution to this challenge, that is, the shallow M-pathway learns the representations
of the deep P-pathway through imitation to improve its performance. Imitation learning may also be
involved in other brain functions, such as for knowledge transfer and memory consolidation between
hippocampus and neocortex (Alvarez & Squire, 1994; Sirota et al., 2003). During the acquisition of
motor skills, it has been observed that neural activities gradually shift from the prefrontal cortex to
the premotor, posteriorparietal, and cerebellar areas (the so-called scaffolding-storage proposed by
(Petersen et al., 1998)), indicating that imitation learning may occur across cortical regions. Notably,
the brain also has resources to implement imitation learning, e.g., the widely observed synchronized
oscillations between cortical regions (Buzsaki & Draguhn, 2θθ4) can modify neuron connections via
5
Under review as a conference paper at ICLR 2021
Hebbian plasticity to support the transfer of neural representations. It will be interesting to explore
how imitation learning is realized in real neural systems.
3.3	Two-pathway processing improves robustness to noise
Models	Clean	Gaussian noise	Shot noise	Impulse noise	Adversarial noise
FineNet-only (nfd = 0)	86.9±0.ι	-50.0±o.5-	57∙8±o.8	-59∙0±o.4-	一
FineNet-only (nfd = 1)	88.4±0.0	56.6±1.2	64.4±1.2	61∙4±i.4	一
FineNet-only (nfd = 3)	88.O±o.o	59.1±i.4	65∙9±i.2	63∙0±o.i	一
two-pathway-FFL	88.2±0.2	-58.8±o.0-	65∙8±o.2	-62∙7±o.6-	61∙6±o.i
two-pathway-SFL	88∙6±0.1	-56.3±1.8-	63∙0±i.4	63∙2±o.9	55∙4±o.2
Our model	86.7±0.2	62.2±0.2	一	68∙0±o.i	66∙5±o.5	65∙7±o.5 一
Table 1: The two-pathway model outperforms others on diverse noise perturbations. FineNet-only
with nfd = 0, 1, 3, refer to FineNet without feedback connection, with 1 loop of feedback inter-
action, and with 3 loops of feedback interaction, respectively. The models of two-pathway-FFL
and two-pathway-SFL refer to two different ways of fusing the features of FineNet and CoarseNet.
FineNet takes clean RGB images and CoarseNets the grayed, low-pass filtered images. Adversarial
noises are generated by attacking FineNet using the Fast Gradient Sign Method (Goodfellow et al.,
2014). The network performances for Gaussian, shot, and impulse noises are obtained by averag-
ing over 5 different noise perturbation levels, and the results for adavesarial noises are obtained by
averaging over 8 different noise perturbation levels. Mean and std are obtained by averaging over 4
trials. The noise generation details are described in Appendix A.2. Additional experimental results
are presented in Appendix E.
A deep CNN trained for image classification is known to overly rely on local textures rather than
the global shape of objects (Baker et al., 2018; Geirhos et al., 2018a;b), which is sensitive to unseen
noises. In our model, since CoarseNet processes blurred visual inputs, whereby the local texture
information is no longer the main cue supporting object classification, we expect that CoarseNet
is robust to noise corruptions. Furthermore, through association and feedback, we expect that the
robustness of FineNet to noises is also leveraged. We carry out simulations to test this hypothesis.
We compare our model with a single-passway model formed only by FineNet, referred to as FineNet-
only. For fair comparison, we also include feedback loops between higher and lower layers in
FineNet-only. We train the models on clean CIFAR10 dataset and test them by adding various noise
perturbations, including Gaussian, shot, impulse and adversarial noises. Tab. 1 shows that compared
to the single-pathway model, although the accuracy of our model on clean data is decreased a little
bit, its robustness to noises is improved significantly, confirming that CoarseNet does contribute to
improving the noise robustness of the model.
We also test different ways of integrating FineNet and CoarseNet. Precious works have studied the
integration between two parallel networks (Hou et al., 2017; Zhu et al., 2018; Kim et al., 2019).
However, they considered that the two networks share the similar structures and receive the same
inputs, which are conceptually different from the brain-inspired two-pathway model. We borrow
their methods of fusing networks to integrate FineNet and CoarseNet (while keeping all other hyper-
parameters unchanged). Two fusion strategies, a simple fusion learning (SFL) and a feature fusion
learning(FFL), are adopted (Kim et al., 2019). Both of them consider integrating information only at
the top layers of two networks (for details, see Appendix C). As shown in Tab. 1, our model still has
a much better performance on noise robustness than other methods, indicating that the association
and feedback module in our model is suitable for integrating information between two pathways.
Remarkably, compared to other methods, our model does not have increased performances on clas-
sifying clean images, rather the performances are often decreased a little bit compared to that of a
well-trained deep neural network. The reliable achievement of our model is the improved robustness
to noises. This highlights an important goal for the brain employing two-pathway processing: the
P-pathway learns to recognize objects with high fidelity based on fine features that are only available
when images are clean; when images are ambiguous, the M-pathway relying on coarse features of
objects compensates for noises. Certainly, there are other computational advantages associated with
the two-pathway processing (see below).
6
Under review as a conference paper at ICLR 2021
3.4	Rough-to-fine processing in the two-passway model
Models	Clean	Gaussian noise	Shot noise	Impulse noise
FineNet-only (nfd = 1)	63.5±0.3	-28∙2±i.3-	34∙9±i.2	28∙6±i.2	一
Our model	62∙5±o.3	30∙5±o.7	36∙6±o.7	31∙0±0.4
Table 2: CoarseNet facilitates the performance of FineNet. The images are taken from CIFAR-
100, which form 20 super-classes and 100 sub-classes (for details, see Appendix A). CoarseNet
and FineNet perform super- and sub- class classifications, respectively. The experiment settings the
same as in Tab. 1
In the above, we have considered that the two pathways process the same categorical information
of images. In reality, the two pathways may process different levels of categorical information of
images, and object recognition goes from rough to fine, for instance, CoarseNet may recognize the
higher category of an object (e.g., animal), and FineNet recognizes the lower category of the object
(e.g., cat). In such a case, the result of CoarseNet can still serve as a cognitive bias to facilitate the
performance of FineNet. We carry out experiments to confirm this.
We construct a classification task, in which CoarseNet and FineNet are trained to recognize the
super- and sub- classes of images, respectively, and the interaction between two networks remains
unchanged as before. The results are presented in Tab. 2, which show that indeed the classifica-
tion results on super-classes of images by CoarseNet can serve as a cognitive bias to improve the
performance of FineNet on classifying the sub-classes of the images.
3.5	Component analysis of the two-pathway model
We further analyze the contributions of different elements in the model, and confirm that when any
one of four elements of the model (FineNet, CoarseNet, the association module (SAM), and the
feedback loop) is missing or changed, the robustness of the model to noise is degraded dramatically
(see Fig. 4). Notably, these elements are also the key characteristics of the visual signal pathways.
Figure 4: Component analysis of the two-pathway model. FN: FineNet. CN: CoarseNet. SAM:
static associative memory. FBt the long-range feedback from CoarseNet and the higher layer of
FineNet to the second layer of FineNet; without FBtmeanS a short-range feedback to the third layer
of FineNet. Red dashed line: the performance of the two-pathway model. (A) Model performances
with respect to Gaussian, impulse and shot noises. (B) Model performances with respect to adver-
sarial noise. Experimental details are the same as in Tab. 1.
3.6	Two-pathway processing accounts for visual backward masking
Visual backward masking is a classic experiment widely used in cognitive psychology to investigate
attention, awareness and dyslexia. In the cognitive experiment, a masking stimulus is presented
after the target stimulus with a brief delay (usually 30-70 ms), which incurs a failure of the subject to
consciously perceive the target (Fig. 5 A). Breitmeyer & Ganz (1976) proposed a psychological two-
channel framework, a fast transient channel and a slow sustained channel, to explain the backward
7
Under review as a conference paper at ICLR 2021
(A) backward masking	(B) 60
Target
ɪ SOA I
U -
I ISI
0
4
ycaruccA
30 40 50 60 70 80 90 100
STA duration (ms)
Time
000
) 6 5 4
C ycaruccA
20一二________________
n=21
0 25 50 75 100125150
SOA duration (ms)
OOOO
08 6 4
1) ecnamrofreP
STA
Figure 5: The two-pathway model reproduces the visual backward masking phenomenon. (A) A
paradigm of the backward masking experiment, adapted from Macknik & Martinez-Conde (2007).
SOA: stimulus onset asynchrony, the time interval between the onsets of target and mask; ISI: inter-
stimulus interval, the interval between the termination of target and the onset of mask; STA: stimulus
termination asynchrony, the interval between the terminations of target and mask. ISI=0 is used
in our simulation. (B) Model performance vs. STA. (C) Model performance vs. SOA. (D) The
experimental result, adapted from Tang et al. (2018).
masking phenomenon. The idea is that since the time delay for masking is too short, the neural
representation of the mask, which is extracted rapidly through the transient channel, intercepts the
neural representation of the target sustained in the slow channel, and hence disturb the perception.
The important factors affecting the masking effect are the target and the mask durations, referred to
as stimulus onset asynchrony (SOA) and stimulus termination asynchrony (STA), respectively.
Our two-pathway provides a natural computational model to explain the backward masking phe-
nomenon. To capture the temporal effect, we consider a dynamical memory association process
implemented by restrict Boltzmann machine (RBM), which holds the same idea of using coarse
features as a cue to predict fine features as in SMA. The visible part of RBM is composed of the
concatenated features from CoarseNet and FineNet, which are associated with each other through
hidden variables (for the details, see Appendix F.1 and Appendix F.2). In the simulation, one it-
eration in RBM equals to a time step of 10ms. As suggested by the neural data (Sugase et al.,
1999; Bar et al., 2006; Liu et al., 2017), information processing in the M-pathway proceeds that
in the P-pathway for about 50 ms. Therefore, the coarse features are loaded into RBM 50 ms be-
fore their corresponding fine features. Because of this time lag, the coarse information of the mask
is confounded with the fine information of the target, leading to wrong association that interferes
the perception. The larger the STA or the shorter the SOA, the stronger interference of the mask.
Our model successfully reproduces the backward masking effect as observed in the experiment. As
shown in Fig. 5, the classification accuracy of the model increases with SOA, agreeing with the
experimental findings in Tang et al. (2018).
4	Conclusion
In the present study, we have proposed a two-pathway model mimicking visual information pro-
cessing in the brain. The model is composed of FineNet and CoarseNet, with the former extracting
fine information of visual inputs and the latter extracting coarse information of inputs. CoarseNet
processes information rapidly, whose result serves as a feedback to facilitate the performance of
FineNet. Our study reveals several appealing properties associated with the interplay between two
pathways, which are: 1) through imitation, CoarseNet can learn from FineNet to improve its perfor-
mance; 2) through association and feedback from CoarseNet, the robustness to noise of FineNet is
improved significantly; 3) the result of CoarseNet can serve as a cognitive bias to leverage the perfor-
mance of FineNet, achieving rough-to-fine information processing; 4) the two-pathway model can
explain the visual backward masking phenomenon as observed in the experiment. To our knowl-
edge, our work is the first one that builds up a network model to mimic the structures of the two
biological visual pathways and studies their interaction properties. We hope that this study will give
us insights into understanding visual information processing and inspire the development of new
object recognition architectures in machine learning.
8
Under review as a conference paper at ICLR 2021
References
David H Ackley, Geoffrey E Hinton, and Terrence J Sejnowski. A learning algorithm for boltzmann
machines. Cognitive science, 9(1):147-169, 1985.
Pablo Alvarez and Larry R Squire. Memory consolidation and the medial temporal lobe: a simple
network model. Proceedings of the national academy of sciences, 91(15):7041-7045, 1994.
Nicholas Baker, Hongjing Lu, Gennady Erlikhman, and Philip J Kellman. Deep convolutional
networks do not classify based on global object shape. PLoS CompUtational biology, 14(12):
e1006613, 2018.
Moshe Bar. A cortical mechanism for triggering top-down facilitation in visUal object recognition.
JoUrnal of Cognitive neuroscience, 15(4):600-609, 2003.
Moshe Bar, Karim S Kassam, Avniel Singh GhUman, Jasmine Boshyan, Annette M Schmid, An-
ders M Dale, Matti S Hamalainen, Ksenija Marinkovic, Daniel L Schacter, Bruce R Rosen, et al.
Top-down facilitation of visual recognition. ProceedingS of the national academy of sciences, 103
(2):449454, 2006.
Bruno G Breitmeyer and Leo Ganz. Implications of sustained and transient channels for theories of
visual pattern masking, saccadic suppression, and information processing. PSyChoIogiCaI review,
83(1):1, 1976.
Jean Bullier. Integrated model of visual processing. Brain research reviews, 36(2-3):96-107, 2001.
Gyorgy Buzsaki and Andreas Draguhn. Neuronal oscillations in cortical networks. science, 304
(5679):1926-1929, 2004.
AM Derrington and P Lennie. Spatial and temporal contrast sensitivities of neurones in lateral
geniculate nucleus of macaque. The JoUrnal of PhySiology, 357(1):219-240, 1984.
Mark Everingham, SM Ali Eslami, Luc Van Gool, Christopher KI Williams, John Winn, and Andrew
Zisserman. The pascal visual object classes challenge: A retrospective. International journal of
ComPUter vision, 111(1):98-136, 2015.
Robert Geirhos, Patricia Rubisch, Claudio Michaelis, Matthias Bethge, Felix A Wichmann, and
Wieland Brendel. Imagenet-trained cnns are biased towards texture; increasing shape bias im-
proves accuracy and robustness. arXiv PrePrint arXiv:1811.12231, 2018a.
Robert Geirhos, Carlos RM Temme, Jonas Rauber, Heiko H Schutt, Matthias Bethge, and Fe-
lix A Wichmann. Generalisation in humans and deep neural networks. In AdvanCeS in neural
information ProCeSSing systems, pp. 7538-7550, 2018b.
Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversarial
examples. arXiv PrePrint arXiv:1412.6572, 2014.
Geoffrey Hinton, Oriol Vinyals, and Jeff Dean. Distilling the knowledge in a neural network. arXiv
PrePrint arXiv:1503.02531, 2015.
Geoffrey E Hinton. Training products of experts by minimizing contrastive divergence. NeUral
computation, 14(8):1771-1800, 2002.
Geoffrey E Hinton, Simon Osindero, and Yee-Whye Teh. A fast learning algorithm for deep belief
nets. NeUral computation, 18(7):1527-1554, 2006.
Shaul Hochstein and Merav Ahissar. View from the top: Hierarchies and reverse hierarchies in the
visual system. Neuron, 36(5):791-804, 2002.
John J Hopfield. Neural networks and physical systems with emergent collective computational
abilities. ProceedingS of the national academy of sciences, 79(8):2554-2558, 1982.
Saihui Hou, Xu Liu, and Zilei Wang. Dualnet: Learn complementary features for image recognition.
In ProCeedingS of the IEEE IntemationaI ConferenCe on ComPUter Vision, pp. 502-510, 2017.
9
Under review as a conference paper at ICLR 2021
Jangho Kim, Minsung Hyun, Inseop Chung, and Nojun Kwak. Feature fusion for online mutual
knowledge distillation. arXiv Preprint arXiv:1904.09058, 2019.
Nikolaus Kriegeskorte. Deep neural networks: anew framework for modeling biological vision and
brain information processing. Annual review of Vision science, 1:417-446, 2015.
Ling Liu, Fan Wang, Ke Zhou, Nai Ding, and Huan Luo. Perceptual integration rapidly activates dor-
sal visual pathway to guide local processing in early visual areas. Plos Biology, 15(11):e2003646,
2017.
Stephen L Macknik and Susana Martinez-Conde. The role of feedback in visual masking and visual
processing. Advances in COgnitive psychology, 3(1-2):125, 2007.
Emin Orhan. A simple cache model for image recognition. In AdVanceS in NeuraI InfOrmatiOn
PrOCeSSing Systems, pp. 10107-10116, 2018.
Steven E Petersen, Hanneke Van Mier, Julie A Fiez, and Marcus E Raichle. The effects of practice on
the functional anatomy of task performance. PrOCeedingS of the NatiOnaI ACademy of Sciences,
95(3):853-860, 1998.
Anton Sirota, Jozsef Csicsvari, Derek Buhl, and GyOrgy Buzsaki. Communication between neocor-
tex and hippocampus during sleep in rodents. Proceedings of the NatiOnaI ACademy of Sciences,
100(4):2065-2069, 2003.
Yasuko Sugase, Shigeru Yamane, Shoogo Ueno, and Kenji Kawano. Global and fine information
coded by single neurons in the temporal visual cortex. Nature, 400(6747):869-873, 1999.
Hanlin Tang, Martin Schrimpf, William Lotter, Charlotte Moerman, Ana Paredes, Josue Ortega
Caro, Walter Hardesty, David Cox, and Gabriel Kreiman. Recurrent computations for visual
pattern completion. PrOCeedingS of the NatiOnaI ACademy of Sciences, 115(35):8835-8840,2018.
Wenbo Wang, Tiangang Zhou, Yan Zhuo, Lin Chen, and Yan Huang. Subcortical magnocellular
visual system facilities object recognition by processing topological property. BioRxiv, 2020.
Daniel L Yamins, Ha Hong, Charles Cadieu, and James J DiCarlo. Hierarchical modular optimiza-
tion of convolutional networks achieves representations similar to macaque it and human ventral
stream. In AdVanCeS in neural information processing systems, pp. 3093-3101, 2013.
Xiatian Zhu, Shaogang Gong, et al. Knowledge distillation by on-the-fly native ensemble. In
AdVanCeS in neural information processing systems, pp. 7517-7527, 2018.
10
Under review as a conference paper at ICLR 2021
A Datasets and manipulation of the input
A.1 Three datasets
We use three datasets, Pascalvoc-mask, CIFAR-10 and CIFAR-100 to evaluate our model.
Pascalvoc-mask and CIFAR-10 are used to demonstrate the effect of imitation learning in Fig. 3.
CIFAR-10 and CIFAR-100 are used to test the noise robustness and the rough-to-fine processing
property of our model.
Pascalvoc-mask is a new dataset we created from the Pascalvoc2012 dataset (Everingham et al.,
2015), which contains 20 foreground object classes. The goal of the original Pascalvoc2012 dataset
is to recognize objects from a number of visual object classes in realistic scenes. There are two
main tasks (classification and detection) and two additional competitions (segmentation and action
classification). In the current study, we are only interested in those objects with precise annotated
segments. Totally, there are 2913 images with 6866 objects having annotated segments. To create
the Pascal-mask dataset, firstly, we extract each object image from the raw image and each object
segment from the corresponding “SegmentationObject” image set according to the bounding box in-
formation (see Fig. 6A). Secondly, we remove object images with low resolution (the number of pix-
els in width or height is less than 50) or large aspect ratio (width/height or height/width is more than
3). In this way, the number of remaining objects is 4887. Thirdly, to obtain the masked counterpart
of each object, we gray the object segment by setting the pixel values for objects to be 1 and back-
grounds to be 0 (see Fig. 6B). All object images are resized to 64 × 64 to fit the input of CoarseNet.
The new dataset consists of 4887 object images with masks. We split the dataset into 4512 training
and 375 testing images, where the testing set is all from the Pascalvoc2007 testing set. See Tab. 3
for the details of Pascalvoc-mask. The dataset can be found at https://drive.google.com/
file/d/1TP0QsFBtVwXaCENGTwuk9ZhDlkGMyTOj/view?usp=sharing.
aeroplane 104/10	bicycle 147/15	bird 215/11	boat 126/9	bottle 92/6	bus 174/12	car 206/16	cat 261/17	chair 398/33	cow 204/10
diningtable	dog	horse	motorbike	person	pottedplant	sheep	sofa	train	tvmonitor
115/14	267/16	176/11	162/18	1017/100	186/14	188/21	178/14	138/12	158/16
Table 3: The number of samples in each class of Pascalvoc-mask. Digits in each column mean
the training/testing numbers. The number of classes is 20 and the total number of training exam-
ples/testing examples is 4512/375.
(A)
(B)
口 小四上

Figure 6: Data examples of the dataset Pascalvoc-mask. (A) left panel: a raw image and the corre-
sponding objects; right panel: the segment of the raw image and the corresponding object segments.
(B) Examples of Pascalvoc-mask. Images in the RGB channel and their masked counterparts.
CIFAR-10 consists of 60000 32 × 32 colour images for 10 classes, with 6000 images per class, and
they are split into 5000 training and 1000 test images in each class.
CIFAR-100 is a harder version of the CIFAR-10 dataset, which has 100 classes, with 600 images
per class, and they are split into 500 training and 100 testing images in each class. The 100 classes in
11
Under review as a conference paper at ICLR 2021
the CIFAR-100 are further grouped into 20 superclasses, so that each image has a pair of sub-class
and super-class labels (this information is used to test the rough-to-fine processing property).
A.2 Manipulating the input with different noises
Shot noise Impulse noise Adversarial noise
Figure 7: Examples of noise disruptions used in the experiments. (A) Examples of visual inputs
used for training FineNet and CoarseNet. From up to down, a raw image to FineNet, the corre-
sponding low-pass filtered image (blurred) to CoarseNet, and the corresponding binarized image
(mask data) to CoarseNet. (B-E) Different kinds of noise disruptions. (B) Examples of Gaussian
noise with std = 0.04, 0.3, 0.6, respectively. (C) Examples of shot noise with c = 100, 3, 1, re-
spectively. (D) Examples of impulse noise with p = 0.07, 0.15, 0.3, respectively. (E) Adversarial
noise. Up: the adversarial noise of the example image in (A)-up, obtained by the Fast Gradient Sign
Method (Goodfellow et al., 2014); Middle and down: the adversarial examples with the noise levels
of 0.1 and 0.5, respectively.
Data example Guassian noise
Evaluating the model performances under different kinds of noise disruption is a main task in the
current study. Here we describe the details of manipulating inputs with various forms of noise.
Four types of noises are used, Gaussian, shot, impulse, and adversarial noises. Please see Fig. 7 for
details.
We obtain the performances of models on Gaussion noise, shot noise, and impulse noise dataset
by averaging over 5 amplitude levels (Fig. 4). For Gaussian noise, the 5 levels correspond to the
noise variance std = [0.04, 0.06, 0.08, 0.09, 0.10]. For shot noise, the 5 levels correspond to the
multiplication parameter c = [500, 250, 100, 75, 50]. For impulse noise, the 5 levels correspond to
the probability p = [0.01, 0.02, 0.03, 0.05, 0.07]. For adversarial noise, we average 9 different levels
with = [0.005, 0.01, 0.015, 0.02, 0.025, 0.03, 0.035, 0.04].
B	Implementation details of imitation learning
In Sec. 3.2, we illustrate the effect of imitation learning to CoarseNet. Without loss of generality,
FineNet and CoarseNet both adopt simpler structures than that used in the noise robustness task.
FineNet used in this task consists of three stacked layers, each of which comprises a 128-filter
3 × 3 convolution, followed by a batch normalization, a ReLU nonlinearity, and 2 × 2 max-pooling.
CoarseNet has two stacked layers with the same composition as in FineNet, except that it comprises
64-filter 11 × 11 convolution in the first layer and 128-filter 9 × 9 convolution in the second layer.
The balancing term α = 0.4 is used when training CoarseNet. Both FineNet and CoarseNet have
a fully-connected layer of 1000 units before the readout layer. Except for normalizing with the
channel-wise mean and standard deviation of the whole dataset, no other pre-processing strategies
are adopted. All other settings are the same as described in Sec. 3.1.
12
Under review as a conference paper at ICLR 2021
C Implementation details of SFL and FFL
In Sec. 3.3, we mentioned two feature fusion methods SFL and FFL. Here we describe the details.
In machine learning society, many feature fusion methods have been proposed to fuse the features
from parallel networks. However, these methods focused on fusing features from networks which
take the exact same input and share similar model structures, while our two-pathway model takes
different inputs and structures. We concatenate the features of top convolutional layers in FineNet
and CoarseNet, and then perform the fusion operation through a convolutional structure (Kim et al.,
2019).
SFL and FFL share the same feature fusion module which consist of a depthwise convolution and a
pointwise convolution. They are different in training objective functions. In SFL, the sub-network
classifiers and the fusion classifier are both trained with cross-entropy losses simultaneously. In
FFL, in additional to cross-entropy losses, networks are trained via mutual knowledge distillation
losses, which was proved to be a more effective fusion method (Kim et al., 2019). Note that both
FFL and SFL have more trainable parameters than our model (see Tab. 4).
Table 4: The number of trainable parameters in different models. FineNet has more trainable pa-
rameters than CoarseNet. Networks with FFL and SFL have more trainable parameters than our
two-pathway model.
Models	Number of Parameters
FineNet	3,119, 808
CoarseNet	827, 456.
FFL	4, 410, 112
SFL	4,410,112
two-pathway	3, 942,144
D EFFECTS OF β IN THE SAM BUFFER
80
60
ycarucc
40
20
0
B=1	8 = 10	= =100 B=1000
Figure 8:	Performance of the two-pathway model against the parameter β in SMA. CoarseNet and
the two-pathway model are trained under different β settings. When β = 100, both the two-pathway
model and CoarseNet which reads out via SAM achieve the best performances.
In practice, the value of β affects the performance of our two-pathway model. We find that a good
β for CoarseNet, which makes a prediction via SAM (Orhan, 2018), is always a good one for the
13
Under review as a conference paper at ICLR 2021
corresponding two-pathway model ( See the three bars when β = 100 in Fig. 8). So the value of
β can be chosen by training a CoarseNet alone, and then we find a good β for CoarseNet through
parameter searching.
E Additional experimental results on the noise robustness
EVALUATION TASK
Models	Clean	Gaussian noise	Shot noise	Impulse noise	Adversarial noise
std = 1					
FFL	88.2±0.2	63∙1±2.1	69∙6±1.6	66∙0±0.7	62∙8±0.5
SFL	88.6±0.1	55∙6±1.0	62∙2±0.3	63∙4±0.9	55∙2±0.3
two-pathway	86∙7±o.2	64∙1±1.0	69∙5±ι.ι	67∙3±0.4	65∙6±0.2
std = 2					
FFL	88.2±o.2	58∙8±0.0	65∙8±0.2	62∙7±0.6	61∙6±0.1
SFL	88∙6±o.i	56∙3±1.8	63∙0±1.4	63∙2±0.9	55∙4±0.2
two-pathway	86∙7±o.2	62∙2±0.2	68∙0±o.i	66∙5±0.5	65∙7±0.5
std = 3					
FFL	88∙2±0.2	58∙3±3.7	65∙4±2.6	63∙5±2.0	60∙2±0.4
SFL	88∙3±o.i	56∙5±0.1	63∙5±0.4	62∙0±0.2	56∙4±0.4
two-pathway	87∙5±o.i	60∙0±1.5	66∙4±i.o	65∙3±0.1	65∙8±0.2
FFL*	89∙4±o.3	54∙4±0.2	62∙6±o.4	62∙2±0.1	67∙7±0.2
Table 5: Performances of different models under different noise levels. CoarseNet in these models
takes grayed and low-pass filtered inputs with std = 0, 1, 2, 3. FineNet takes clean inputs. Different
from FFL, FFL* consists of two FineNets. Mean and std are obtained by averaging over 4 trials.
40
ycaruccA
00
86
ycaruccA
^^TWoPassWay
^^FineNet
CoarseNet
+ SFL
-FFL
3	5
Gaussian noise level
3
Shot noise level
000
864
C) ycaruccA
t^ TWoPaSSWay
T Fine
:CoarseNet
T SFL
FF FFL
1	3	5	0.01	0.02	0.03	0.04
Impulse noise level	Epsilon of adversarial noise
Figure 9:	Model performances against noises and adversarial noise perturbations. In (A-C), model
performances against noise perturbations. FineNet and CoarseNet are trained independently on the
dataset. (D) Model performances against adversarial noise perturbations. FineNet-tp,FineNet-FFL
and FineNet-FFL means FineNet in the two-pathway model, FFL, and SFL, respectively. Noise
perturbation details are shown in Appendix A.2. Experimental details are the same as that in Tab. 1.
We also run additional experimentt conditions. As shown in Tab. 5, our model outperforms other
methods significantly in various noise tasks and with Gaussian filters of diffrent std.
As shown in Fig. 9, although CoarseNet has much lower accuracy compared to FineNet, it is very
robust to all kinds of noise disruption and meanwhile its performance decreases much slower than
14
Under review as a conference paper at ICLR 2021
other models with the noise disruption level. Then robust CoarseNet can generate a robust cue to
SAM to associate a relatively clean predictive representation, and the predictive presentation can
help to improve the performance of FineNet dramatically.
F Implementing backward mas king with our two-pathway model
We introduce the details of modeling the backward masking phenomenon using our two-pathway
model. First, we introduce RBM used as the association module. Then we elucidate how the two-
pathway model works on this task. Last, we introduce some experimental findings on the backward
masking task.
F.1 Restrict boltzmann machine (RBM) as a dynamical memory association
MODEL
(B)	∙ ,	j	j
t = k
i
data, t = O t = 1
Figure 10:	Learning in RBM. (A) Diagram of a RBM with three visible and three hidden units.
There are only connections between layers. (B) Illustrating the Gibbs sampling process in RBM
during training. At time t = 0, the visible units v are initialized and the hidden units are updated
according to h 〜 P(h|v). At time t = 1, the visible units are updated according to V 〜 P(v|h) and
the correlations < vihj > are the statistics used for contrastive learning in the RBM. The number of
units in the visible layer is 1000, with 500 units for coarse features and 500 units for fine features.
For simplicity, we only test our model on the Mnist dataset.
To investigate the effect of different factors on the target visibility, e.g., the task duration (SOA), the
mask duration (STA), we modified the similarity-based association phase into RBM, which intro-
duces dynamics in the association phase. RBM is a simplified version of Boltzmann Machine (BM),
with the latter being an extension of the Hopfield model with stochastic dynamics (Hinton et al.,
2006). Both BM (Ackley et al., 1985) and the Hopfield model (Hopfield, 1982) can be used to cap-
ture how memory patterns are stored as stationary states of neural circuits via recurrent connections
between neurons. RBM consists of a visible and a hidden layers with no within-layer connections.
Denote the input to the visible layer as v, activities at the hidden layer as h and the connection
matrix between two layers is W . The energy function of a RBM is written as
E(v, h) = -avT - bhT - vWhT,	(3)
where a and b represent the bias vectors in the visible and the hidden layers, respectively. The joint
probability of a configuration (v, h) is written as
e-E(v,h)
P(v, h)=——7—,	(4)
Z
where Z is the partition function given by Z = Ph Pv e-E(v,h). The probability of a specific v is
P(V) = Z X e-E(v,h).	(5)
h
15
Under review as a conference paper at ICLR 2021
The appealing property of the bipartite graph structure of RBM is that the conditional distributions
P (h|v) and P (v|h) are factorial, i.e.,
nv	nh
P (v|h)	=	YP(vi|h),	P(vi = 1|h) = σ(ai	+ Xwijhj),	(6)
i	j=1
nh	nv
P (h|v)	=	Y P(hi|v),	P(hi = 1|v) = σ(bi	+Xwjivj),	(7)
i	j=1
where σ(x) = 1/(1 + e-x/T) is a sigmoid function, with T the temperature.
(A) (hidden layer)
(B)
t=2
t=k
(keys) (values)
(query)
(prediction)
Figure 11:	DMA implemented by RBM. (A) The training phase (see Fig. 10 for the details). (B)
The retrivela phase. The coarse probe gc (X) of a visual object is fed into the visible layer of the
trained RBM and the prediction O(x) is retrieved through the dynamics of RBM.
To implement the association phase, we construct v by concatenating the features from both
CoarseNet and FineNet, e.g., V = [vC, VF], with VC = gc(X) and VF = gF(x). Given the
training examples (features of input images), RBM is optimized through minimizing the negative
log-likelihood:
1N	1N
LRBM = -N Elog[P(Vi)] = -N ElOg [P(VF, VC)].	⑻
i=1	i=1
The derivative of the log likelihood with respect to a connection weight is calculated to be,
-∂log P(V)
∂Wij
=< vihj >data - < vihj >model,
(9)
where the first and the second terms in the right hand of the equation denote expectations over the
distributions of data and the model, respectively. The first expectation is tractable. For the second
expectation, we apply the strategy of contrastive divergence (CD) gradient (Hinton, 2002), which
approximates the expectation over the model distribution by a sample generated via a number of
Gibbs sampling iterations, with the initial state of the visible units being the training sample, as
illustrated in Fig 10B. More specifically, we use the correlation statistics < vihj >k after k step
Gibbs sampling to replace the < vihj >model to update the connection weights, i.e.,
∆Wij = (< vihj >0 - < vihj >k),
(10)
where is the learning rate. During the training, V and h are sampled from P (h|V) and P(V|h)
alternatively. The total number of training epochs is 2000. We use SGD to optimize the RBM with
an initial learning rate of 0.1, which is multiplied with 0.1 after 500 and 1000 epochs.
Once the training is finished, we can feed a partial feature to the visible layer of RBM, and retrieve
the complete one. For example, given a partial feature V0 at time 0, the hidden representations of
RBM is h0 = P(h = 1|V0 = σ(a + WV0) and the updated activation in the visible layer is
V1 = σ(b + WTh1). After k iterations, we can get a Vk which is a complete feature corresponding
to V0 (see Fig. 11 B).
16
Under review as a conference paper at ICLR 2021
□ Target duration (SOA) ■ Masking duration (STA) □ Delay Time □ Blank
Suppression Level
Figure 12:	Illustration of the backward masking with our two-pathway model. (A) The effect of
a small target duration to the network (small SOA). (B) The effect of a large target duration to the
network (large SOA).
F.2 Input to RBM in the task
In Sec. 3.6, we showed that the fast representation of the mask processed along CoarseNet will sup-
press the slow representation of the target processed along the FineNet, which decreases the target
visibility. The dynamics in RBM enables us to investigate which factors, such as the task duration
(SOA) and the mask duration (STA), will affect the target visibility. Due to slow processing by
FineNet, information arrived at RBM from the fine pathway has a lag of about 50 ms (biologically)
with respect to that from the coarse pathway (see Fig. 12). If we set the processing time of each
iteration to be 10 ms, then RBM will only receive coarse features vC as the input at the first 5
iterations. When the target information from FineNet arrives at the visible layer of RBM, it will
interact with the features from CoarseNet (note that at this moment the features can be the mask or
the coarse feature of the target, depending on the SOA value). The network evolves for a relatively
long time (500 ms) and the final value of the fine part in the visible layer is used for recognition.
Fig. 12A (B) shows the effect of a small (large) SOA value to the network performance. Energy is
measured as in Eq. 3, with the lower the energy, the better the network performance (the better target
visibility). Specifically, with a small target duration, such as SOA=30, which is smaller than the lag
between two pathways, the network state is strongly interfered by the mask (red part in Fig. 12 A),
and disrupts the target information from Finenet. When SOA is larger than the lag, the network state
is only partially disrupted by the mask from CoarseNet, leading to a better performance. This result
has been reported in Fig. 5D.
A	B
Figure 13: Performances of human subjects in the backward masking task. The figure is adapted
from Tang et al. (2018). (A) Categorization performance on the partial stimuli on a set of 16 exem-
plars belonging to 4 categories (chance = 25%, the dashed line). 14 subjects participated in this task.
(B) Occluded stimuli was used. Another 15 subjects participated in this task. The black lines indi-
cate whole objects and the gray lines indicate the partial and occluded objects. Solid lines represents
performance with masking and dashed lines without masking.
①。UEluI。七①Cl
17
Under review as a conference paper at ICLR 2021
F.3 Backward masking in psychophysical experiments
Here we introduce some results of backward masking in psychophysical experiments. They are from
Tang et al. (2018), where subjects performed a 5-classes recognition task involving categorization
of objects that were either partially visible or fully visible. Images were followed by either a gray
screen (without masking) or a spatially overlapping noise pattern (with masking). SOA varies from
25 to 150 ms in randomly ordered trials (for the detialed setting, please see the original paper).
Fig 13 shows that: 1) for whole objects, subjects perfectly recognized the objects, no matter what
kind of disruption was used. Even with masking, the performance made no difference with that
without masking. We obtain similar results as in Fig. 5 B&C. In Fig. 5B, we show that with a
low mask noise level (can be viewed as non-masking), our model achieves a high performance.
Fig. 5C shows that when STA is small (also can be viewed as non-masking), our model achieves a
high performance; 2) For disrupted images, subjects’ performances were gradually improved when
the target duration increased from 25ms to 150 ms (the solid gray lines in both panels). This is
also reflected in Fig. 5D in our model. Note that Tang et al. (2018) also proposed a attractor-based
recurrent model to explain their experiment findings. They proposed that local recurrent connections
could explain the backward masking phenomenon, which is different from our two-pathway model.
18