Under review as a conference paper at ICLR 2021
Intervention Generative Adversarial Nets
Anonymous authors
Paper under double-blind review
Ab stract
In this paper we propose a novel approach for stabilizing the training process of
Generative Adversarial Networks as well as alleviating the mode collapse problem.
The main idea is to incorporate a regularization term that we call intervention into
the objective. We refer to the resulting generative model as Intervention Genera-
tive Adversarial Networks (IVGAN). By perturbing the latent representations of
real images obtained from an auxiliary encoder network with Gaussian invariant
interventions and penalizing the dissimilarity of the distributions of the resulting
generated images, the intervention term provides more informative gradient for
the generator, significantly improving training stability and encouraging mode-
covering behaviour. We demonstrate the performance of our approach via solid
theoretical analysis and thorough evaluation on standard real-world datasets as well
as the stacked MNIST dataset.
1	Introduction
As one of the most important advances in generative models in recent years, Generative Adversarial
Networks (GANs) (Goodfellow et al., 2014) have been attracting great attention in the machine
learning community. GANs aim to train a generator network that transforms simple vectors of noise
to produce “realistic” samples from the data distribution. In the basic training process of GANs, a
discriminator and a target generator are trained in an adversarial manner. The discriminator tries
to distinguish the generated fake samples from the real ones, and the generator tries to fool the
discriminator into believing the generated samples to be real.
Though successful, there are two major challenges in training GANs: the instability of the training
process and the mode collapse problem. To deal with these problems, one class of approaches focus
on designing more informative objective functions (Salimans et al., 2016; Mao et al., 2016; Kodali
et al., 2018; Arjovsky & Bottou; Arjovsky et al., 2017; Gulrajani et al., 2017; Zhou et al., 2019). For
example, Mao et al. (2016) proposed Least Squares GAN (LSGAN) that uses the least squares loss to
penalize the outlier point more harshly. Arjovsky & Bottou discussed the role of the Jensen-Shannon
divergence in training GANs and proposed WGAN (Arjovsky et al., 2017) and WGAN-GP (Gulrajani
et al., 2017) that use the more informative Wasserstein distance instead. Other approaches enforce
proper constraints on latent space representations to better capture the data distribution (Makhzani
et al., 2015; Larsen et al., 2015; Che et al., 2016; Tran et al., 2018). A representative work is the
Adversarial Autoencoders (AAE) (Makhzani et al., 2015) which uses the discriminator to distinguish
the latent representations generated by encoder from Gaussian noise. Larsen et al. (2015) employed
image representation in the discriminator as the reconstruction basis of a VAE. Their method turns
pixel-wise loss to feature-wise, which can capture the real distribution more simply when some form
of invariance is induced. Different from VAE-GAN, Che et al. (2016) regarded the encoder as an
auxiliary network, which can promote GANs to pay much attention on missing mode and derive an
objective function similar to VAE-GAN. A more detailed discussion of related works can be found in
Appendix C.
In this paper we propose a novel technique for GANs that improve both the training stability and
the quality of generated images. The core of our approach is a regularization term based on the
latent representations of real images provided by an encoder network. More specifically, we apply
auxiliary intervention operations that preserve the standard Gaussian (e.g., the noise distribution) to
these latent representations. The perturbed latent representations are then fed into the generator to
produce intervened samples. We then introduce a classifier network to identify the right intervention
operations that would have led to these intervened samples. The resulting negative cross-entropy loss
1
Under review as a conference paper at ICLR 2021
is added as a regularizer to the objective when training the generator. We call this regularization term
the intervention loss and our approach InterVention Generative Adversarial Nets (IVGAN).
We show that the intervention loss is equivalent with the JS-divergence among multiple intervened
distributions. Furthermore, these intervened distributions interpolate between the original generative
distribution of GAN and the data distribution, providing useful information for the generator that
is previously unavailable in common GAN models (see a thorough analysis on a toy example in
Example 1). We show empirically that our model can be trained efficiently by utilizing the parameter
sharing strategy between the discriminator and the classifier. The models trained on the MNIST,
CIFAR-10, LSUN and STL-10 datasets successfully generate diverse, visually appealing objects,
outperforming state-of-the-art baseline methods such as WGAN-GP and MRGAN in terms of the
Frechet Inception Distance (FID) (proposed in (HeUsel et al., 2017)). We also perform a series of
experiments on the stacked MNIST dataset and the results show that our proposed method can also
effectively alleviate the mode collapse problem. Moreover, an ablation stUdy is condUcted, which
validates the effectiveness of the proposed intervention loss.
In sUmmary, oUr work offers three major contribUtions as follows. (i) We propose a novel method
that can improve GAN’s training as well as generating performance. (ii) We theoretically analyze oUr
proposed model and give insights on how it makes the gradient of generator more informative and
thUs stabilizes GAN’s training. (iii) We evalUate the performance of oUr method on both standard
real-world datasets and the stacked MNIST dataset by carefUlly designed expriments, showing that
oUr approach is able to stabilize GAN’s training and improve the qUality and diversity of generated
samples as well.
2	Preliminaries
Generative adversarial nets The basic idea of GANs is to Utilize a discriminator to continUoUsly
pUsh a generator to map GaUssian noise to samples drawn according to an implicit data distribUtion.
The objective fUnction of the vanilla GAN takes the following form:
min max {v(D,G)，Ex〜Pdatalog(D(x)) + Ez〜Pzlog(I- D(G(Z)))},	(1)
GD
where pz is a prior distribUtion (e.g., the standard GaUssian). It can be easily seen that when the
discriminator reaches its optimum, that is, D*(x)
____Pdata(X)___
Pdata(X)+PG(X)
, the objective is equivalent to the
Jensen-Shannon (JS) divergence between the generated distribution pG and data distribution pdata :
JS(PGkPdata)，2 {KL(PG∣∣ PG	)+ KL(Pdatak PG +「)}.
Minimizing this JS divergence guarantees that the generated distribution converges to the data
distribution given adequate model capacity.
Multi-distribution JS divergence The JS divergence between two distributions P1 and P2 can be
rewritten as
JS(PIkP2) = H ( p1+p1 ) - 2 H (pi) - 1H (P2),
where H(P) denotes the entropy of distribution P. We observe that the JS-divergence can be inter-
preted as the entropy of the mean of the two distribution minus the mean of two distributions’ entropy.
So it is immediate to generalize the JS-divergence to the setting of multiple distributions. In particular,
we define the JS-divergence ofP1,P2, . . . ,Pn with respect to weights π1, π2, . . . , πn (P πi = 1 and
πi ≥ 0) as
nn
JSπ1,...,πn(P1,P2, . . . ,Pn) , H(	πiPi) -	πiH(Pi).	(2)
i=1	i=1
The two-distribution case described above is actually a special case of the ‘multi-JS divergence’,
where ∏ι = ∏ = 2. When ∏ > 0 ∀i, it can be found immediately by Jensen,s inequality that
J S ∏ι,…,∏n (P1, p2,..∙, Pn) = 0 if and only if Pl = p2 = ∙∙∙ = Pn.
2
Under review as a conference paper at ICLR 2021
Figure 1: Comparison between the vanilla GAN loss and the Intervention loss. Here the intervened
samples are generated through different intervention operations, namely O1 , ..., Ok.
3	Methodology
Training GAN has been challenging, especially when the generated distribution and the data distribu-
tion are far away from each other. In such cases, the discriminator often struggles to provide useful
information for the generator, leading to instability and mode collapse problems. The key idea behind
our approach is that we construct auxiliary intermediate distributions that interpolate between the
generated distribution and the data distribution. To do that, we first introduce an encoder network and
combine it with the generator to learn the latent representation of real images within the framework
of a standard autoencoder. We then perturb these latent representations with carefully designed
intervention operations before feeding them into the generator to create these auxiliary interpolating
distributions. A classifier is used to distinguish the intervened samples, which leads to an intervention
loss that penalizes the dissimilarity of these intervened distributions. The reconstruction loss and the
intervention loss are added as regularization terms to the standard GAN loss for training. We start
with an introduction of some notation and definitions.
Definition 1 (Intervention). Let O be a transformation on the space of d-dimension random vectors
and F be a probability distribution whose support is in Rd. We call O a IP-intervention if for any
d-dimensional random vector X, X 〜]P ⇒ O(X)〜 F.
Since the noise distribution in GAN models is usually taken to be standard Gaussian, we use
the standard Gaussian distribution as the default choice of F and abbreviate the F-intervention
as intervention, unless otherwise claimed. One of the simplest groups of interventions is block
substitution. Let Z ∈ Rd be a random vector, k ∈ N and k|d. We slice Z into k blocks so that
every block is in Rd. A block substitution intervention Oi is to replace the ith block of Z with
Gaussian noise, i = 1,..., d. We will use block substitution interventions in the rest of the paper
unless otherwise specified. Note that our theoretical analysis as well as the algorithmic framework do
not depend on the specific choice of the intervention group.
Notation We use E, G, D, f to represent encoder, generator, discriminator and classifier, respec-
tively. Here and later, preal means the distribution of the real data X , and pz is the prior distribution
of noise z defined on the latent space (usually is taken to be Gaussian). Let Oi, i = 1, . . . , k denote k
different interventions and pi be the distribution of intervened sample Xi created from Oi (namely
Xi = G(Oi (E(X)))).
Intervention loss The intervention loss is the core of our approach. More specifically, given a
latent representation z that is generated by an encoder network E, we sample an intervention Oi
from a complete group S = {O1, . . . , Ok } and obtain the corresponding intervened latent variable
Oi(z) with label ei. These perturbed latent representations are then fed into the generator to produce
3
Under review as a conference paper at ICLR 2021
intervened samples. We then introduce an auxiliary classifier network to identify which intervention
operations may lead to these intervened samples. The intervention loss LIV (G, E) is simply the
resulting negative cross-entropy loss and we add that as a regularizer to the objective function when
training the generator. As we can see, the intervention loss is used to penalize the dissimilarity of the
distributions of the images generated by different intervention operations. Moreover, it can be noticed
that the classifier and the combination of the generator and the encoder are playing a two-player
adversarial game and we will train them in an adversarial manner. In particular, we define
LIV(G,E) = - minVclass, where Vclass = IEi〜U([k])IExO〜Pi - eT logf(x')∙	(3)
Theorem 1 (Optimal Classifier). The optimal solution of the classifier is the conditional probability
of label y given X0, where X0 is the intervened sample generated by the intervention operation
sampled from S. And the minimum of the cross entropy loss is equivalent with the negative of the
Jensen Shannon divergence among {p1, p2, ..., pk }. That is,
fi*(x)
Pi(x)
Pj=I Pj(X)
and LIV (G, E) = JS(P1,P2, ..., Pk ) + Const.
(4)
The proof can be found in Appendix A.1. Clearly, the intervention loss is an approximation
of the multi-JS divergence among the intervened distributions {Pi : i ∈ [k]}. If the intervention
reaches its global minimum, we have pi = p = … =Pk. And it reaches the maximum log k
if and only if the supports of these k distributions do not intersect with each other. This way,
the probability that the ‘multi’ JS-divergence has constant value is much smaller, which means
the phenomenon of gradient vanishing should be rare in IVGAN. Moreover, as shown in the
following example, due to these auxiliary intervened distributions, the intervention is able to pro-
vide more informative gradient for the generator that is not previously available in other GAN variants.
Example 1 (Square fitting). Let X0 be a random vector
with distribution U(α), where α = [— ɪ, 11 ] X [— ɪ, ɪ].
And Xi 〜U(β), where β = [a — 1, a + 1 ] × [ 1, 3] and
0 ≤ a ≤ 1. Assuming we have a perfect discriminator
(or classifier), we compute the vanilla GAN loss (i.e. the
JS-divergence) and the intervention loss between these two
distributions, respectively,
• JS(X0kX1) =log2.
• In order to compute the intervention loss we
need figure out two intervened samples’ distri-
butions evolved from U(α) and U(β). Y1 〜
U(Yi);	γi = [— 1, 1] X [2, 2] and γ2 〜
U(Y2);	Y2 = Ia - 1,a + 1] X [— 2, 1]. Then
the intervention loss is the multi JS-divergence
among these four distributions:
Figure 2: The supports of the two orig-
inal distribution are the squares with
black border, and the supports of the syn-
thetic distributions are the area enclosed
by red and blue dotted line, respectively.
LIV = JS(X0;X1;Y1;Y2)
=- ZA 4log 4M— ZA 2log 2dμ-H(XO) = —|— [μ(Ac)+μ(A)]
=log 2 x 2(2 — a) — H(Xo) = — (log2)a — Const.
Here A is the shaded part in Figure 2 and Ac = {α ∪ β ∪ γ1 ∪ γ2 } \A. The most important
observation is that the intervention loss is a function of parameter a and the traditional GAN loss
is always constant. When we replace the JS with other f -divergence, the metric between U(α) and
U (β ) would still remain constant. Hence in this situation, we can not get any information from the
standard JS for training of the generator but the intervention loss works well.
4
Under review as a conference paper at ICLR 2021
Algorithm 1 Intervention GAN
Input learning rate a, regularization parameters λ and μ, dimension d of latent space, number k of
blocks in which the hidden space is divided, minibatch size n, Hadamard multiplier *
1: 2: 3: 4: 5: 6: 7: 8: 9: 10: 11:	for number of training iterations do Sample minibatch z7-, j = 1,..., n, zj 〜Pz Sample minibatch Xj, j = 1,…，n, Xj 〜Preal for number of inner iteration do Wj J E(Xj), j = 1,..., n Sample Gaussian noise Sample ij ∈ [k], j = 1, ..., n X0j J G(Oij (wj)) Update the parameters of D by: θD J θD - 2αnRΘd Ladv (θD ) Update the parameters of f by: n
12:	θf J θf + n Vθf P log fij (Xj) j=1 j=
13:	Calculate LAdv and LIV
14:	Update the parameter of G by:
15:	Θg J Θg + αRθG +LAdv + λLrecon + μLιv)
16:	Update the parameter of E by:
17:	θE J θE + nrΘe {λLrecon + μLiV }
Reconstruction loss In some sense we expect our encoder to be a reverse function of the generator.
So it is necessary for the objective function to have a term to push the map composed of the Encoder
and the Generator to have the ability to reconstruct the real samples. Not only that, we also hope that
the representation can be reconstructed from samples in the pixel space.
Formally, the reconstruction loss can be defined by the `p-norm (p ≥ 1) between the two samples, or
in the from of the Wasserstein distance between samples if images are regarded as a histogram. Here
We choose to use the 'ι-norm as the reconstruction loss:
Lrecon = WX 〜PrealkG(E(X ))-X ki + 叫〜U ([k]) ^jX,Z^Preal ,Pz kE ( G( θi ( z ))) - θi ( z ) k 1 .	(5)
Theorem 2 (Inverse Distribution). Suppose the cumulative distribution function of Oi(z) is qi. For
any given positive real number , there exist a δ > 0 such that if Lrecon + LIV ≤ δ , then ∀i, j ∈ [k],
sup kqi(r) - qj(r)k ≤ .
r
The proof is in A.2.
Adversarial loss The intervention loss and reconstruction loss can be added as regularization
terms to the adversarial loss in many GAN models, e.g., the binary cross entropy loss in vanilla
GAN and the least square loss in LSGAN. In the experiments, we use LSGAN (Mao et al., 2016)
and DCGAN (Radford et al., 2015) as our base models, and name the resulting IVGAN models
IVLSGAN and IVDCGAN respectively.
Now that we have introduced the essential components in the objective of IVGAN, we can write the
loss function of the entire model:
Lmodel = LAdv + λLr
econ + μLιv,
(6)
where λ and μ are the regularization coefficients for the reconstruction loss and the intervention loss
respectively. We summarize the training procedure in Algorithm 1. A diagram of the full workflow
of our framework can be found in Figire 3.
5
Under review as a conference paper at ICLR 2021
Figure 3: Full workflow of our approach.
4 Experiments
In this section we conduct a series of experiments to study IVGAN from multiple aspects. First we
evaluate IVGAN’s performance on standard real-world datasets. Then we show IVGAN’s ability to
tackle the mode collapse problem on the stacked MNIST dataset. Finally, through an ablation study
we investigate the performance of our proposed method under different settings of hyperparameters
and demonstrate the effectiveness of the intervention loss.
We implement our models using PyTorch (Paszke et al., 2019) with the Adam optimizer (Kingma &
Ba, 2015). Network architectures are fairly chosen among the baseline methods and IVGAN (see
Table B.1 in the appendix for more details). The classifier we use to compute the intervention loss
shares the parameters with the discriminator except for the output layer. All input images are resized
to have 64 × 64 pixels. We use 100-dimensional standard Gaussian distribution as the prior pz. We
deploy the instance noise technique as in (Jenni & Favaro, 2019). One may check Appendix B.2 for
detailed hyperparameter settings. All experiments are run on one single NVIDIA RTX 2080Ti GPU.
Although IVGAN introduces extra computational complexities to the original framework of GANs,
the training cost of IVGAN is within an acceptable range1 due to the application of strategies like
parameter sharing.
Figure 4: Random samples of generated images on MNIST, CIFAR-10, LSUN and STL-10.
Real-world datasets experiments We first test IVGAN on four standard real-world datasets,
including CIFAR-10 (Krizhevsky, 2009), MNIST (Lecun et al., 1998), STL-10 (Coates et al., 2011),
and a subclass named “church_outdoor" of the LSUN dataset (Yu et al., 2015), to investigate its
training stability and quality of the generated images. We use the Frechet Inception Distance (FID)
(Heusel et al., 2017) to measure the performance of all methods.
The FID results are listed in Table 1, and the training curves of the baseline methods and IVGAN
on four different datasets are shown in Figure 5. We see that on each datasets, the IVGAN counter-
parts obtain better FID scores than their corresponding baselines. Moreover, the figure of training
curves also suggests the learning processes of IVDCGAN and IVLSGAN are smoother and steadier
compared to DCGAN, LSGAN or MRGAN (Che et al., 2016), and converge faster than WGAN-GP.
Samples of generated images on all datasets are presented in Figure 4.
Stacked MNIST experiments The original MNIST dataset contains 70K images of 28 × 28
handwritten digits. Following the same approaches in Metz et al. (2017); Srivastava et al. (2017); Lin
et al. (2018), we increase the number of modes of the dataset from 10 to 1000 = 10 × 10 × 10 by
1Empirically IVGANs are approximately 2 times slower than their corresponding baseline methods.
6
Under revieW as a conference paper at ICLR 2021
Table 1: Minimum of FIDs on different Datasets. The FID results are calculated every 10 epochs,
and are averaged over five independent runs. LoWer is better.
Methods	MNIST	CIFAR10	LSUN (Church_outdoor)	STL-10
DCGAN	9.87 ± 1.18	37.30 ± 2.93	23.18 ± 0.98	45.13 ± 0.95
LSGAN	12.06 ± 0.88	34.43 ± 2.65	29.53 ± 1.10	57.39 ± 1.61
WGAN-GP	10.83 ± 0.66	40.03 ± 1.62	26.08 ± 0.60	48.52 ± 0.61
MRGAN	8.52 ± 1.19	32.52 ± 2.89	21.03 ± 0.90	44.09 ± 1.56
IVDCGAN	8.27 ± 1.25	30.19 ± 1.40	20.30 ± 0.80	42.86 ± 1.37
IVLSGAN	8.33 ± 0.25	27.58 ± 0.79	18.99 ± 0.88	41.85 ± 1.17
LSUN(ChUrCh/utdoor)
Figure 5: Training curves of different methods in terms of FID on different datasets, averaged over
five runs. Left: CIFAR10. Right: Church Outdoors. Note that the raise of curves in the later stage
may indicate mode collapse.
MRGAN
-WGAN-GP
DCGAN
—LSGAN
IVDCGAN
IVLSGAN
0	50 IOO 150	200	250	300
①」Ous 0z
stacking three random MNIST images into a 28 × 28 × 3 RGB image. The metric we use to evaluate a
model’s robustness to mode collapse problem is the number of modes captured by the model, as well
as the KL divergence between the generated distribution over modes and the true uniform distribution.
The mode of a generated imaged is found from a pre-trained MNIST digit classifier.
Our results are shown in Table 2. It can be seen that our model works very well to prevent the mode
collapse problem. Both IVLSGAN and IVDCGAN are able to reach all 1,000 modes and greatly
outperforms early approaches to mitigate mode collapse, such as VEEGAN (Srivastava et al., 2017),
and Unrolled GAN (Metz et al., 2017). Moreover, the performance of our model is also comparable
to method that is proposed more recently, such as the PacDCGAN (Lin et al., 2018). Figure 6 shows
images generated randomly by our model as well as the baseline methods.
Table 2: Results of our stacked MNIST experiments. The first four rows are directly copied from
(Lin et al., 2018) and (Srivastava et al., 2017). And the last three rows are obtained after training each
model for 100K iterations, respectively.
	Modes	KL Divergence
DCGAN	78.9	4.50
VEEGAN	150.0	2.95
Unrolled GAN	48.7	4.32
PacDCGAN	1000	0.06
LSGAN	53	3.88
IVLSGAN	1000	0.07
IVDCGAN	1000	0.08
Ablation study Our ablation study is conducted on the CIFAR-10 dataset. First, we show the
effectiveness of the intervention loss. We consider two cases, IVLSGAN without the intervention
loss (μ = 0), and standard IVLSGAN (μ = 0.5). From Figure 7 We can find that the intervention
loss makes the training process much smoother and leads to a lower FID score in the end.
7
Under review as a conference paper at ICLR 2021
夕7vq
f 3，g
夕 IKa 0
q γ›⅛5
50 ◎4
c>q⅛4
?G 6 /P
2.2J2C
/ N q3
7VA3
Figure 6: Sampled images on the stacked MNIST dataset. Left: Ground-truth. Middle: LSGAN.
Right: IVLSGAN. Images generated by our method are more diverse.
We also investigate the performance of our model using different number of blocks for the block
substitution interventions and different regularization coefficients for the intervention loss. The results
are presented in Table 3. It can be noticed that to some extent our models’ performance is not sensitive
to the choice of hyperparameters and performs well under several different hyperparameter settings.
However, when the number of blocks or the scale of IV loss becomes too large the performance of
our model gets worse.
Figure 7: Training curve of IVLSGAN, with and
without the intervention loss.
Table 3: Minimum FID scores of IVLSGAN under
different hyperparameter settings on the CIFAR10
dataset, calculated every 10 epochs.
FID score				
μ 二	0.5	k	二 2	29.2
μ 二	0.5	k	4	28.2
μ 二	0.5	k	10	41.2
μ 二	0.5	k	20	36.1
μ 二	0	k	二 4	34.5
μ 二	0.25	k	4	29.6
μ 二	0.5	k	4	28.2
μ 二	1	k	4	39.7
5 Conclusion
We have presented a novel model, intervention GAN (IVGAN), to stabilize the training process
of GAN and alleviate the mode collapse problem. By introducing auxiliary Gaussian invariant
interventions to the latent space of real images and feeding these perturbed latent representations
into the generator, we have created intermediate distributions that interpolate between the generated
distribution of GAN and the data distribution. The intervention loss based on these auxiliary
intervened distributions, together with the reconstruction loss, are added as regularizers to the
objective to provide more informative gradients for the generator, significantly improving GAN’s
training stability and alleviating the mode collapse problem as well.
We have conducted a detailed theoretical analysis of our proposed approach, and illustrated the
advantage of the proposed intervention loss on a toy example. Experiments on both real-world
datasets and the stacked MNIST dataset demonstrate that, compared to the baseline methods, IVGAN
variants are stabler and smoother during training, and are able to generate images of higher quality
(achieving state-of-the-art FID scores) and diversity. We believe that our proposed approach can also
be applied to other generative models such as Adversarial Autoencoders (Makhzani et al., 2015),
which we leave to future work.
8
Under review as a conference paper at ICLR 2021
References
M Arjovsky and L Bottou. Towards principled methods for training generative adversarial networks.
arxiv 2017. arXiv preprint arXiv:1701.04862.
Martin Arjovsky, Soumith Chintala, and Leon Bottou. Wasserstein generative adversarial networks.
In International Conference on Machine Learning, pp. 214-223, 2017.
Tong Che, Yanran Li, Athul Jacob, Yoshua Bengio, and Wenjie Li. Mode regularized generative
adversarial networks. 2016.
Adam Coates, Andrew Ng, and Honglak Lee. An analysis of single-layer networks in unsupervised
feature learning. In Proceedings of the fourteenth international conference on artificial intelligence
and statistics, pp. 215-223, 2011.
Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair,
Aaron C. Courville, and Yoshua Bengio. Generative adversarial nets. In Advances in Neural
Information Processing Systems 27: Annual Conference on Neural Information Processing Systems
2014, December 8-13 2014, Montreal, Quebec, Canada, pp. 2672-2680, 2014. URL http:
//papers.nips.cc/paper/5423- generative- adversarial- nets.
Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Dumoulin, and Aaron C Courville.
Improved training of wasserstein gans. In Advances in neural information processing systems, pp.
5767-5777, 2017.
Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter. Gans
trained by a two time-scale update rule converge to a local nash equilibrium. In Advances in neural
information processing systems, pp. 6626-6637, 2017.
Simon Jenni and Paolo Favaro. On stabilizing generative adversarial training with noise, 2019.
Hyunjik Kim and Andriy Mnih. Disentangling by factorising. arXiv preprint arXiv:1802.05983,
2018.
D. P. Kingma and J. Ba. Adam: A method for stochastic optimization. In ICLR, 2015.
Naveen Kodali, James Hays, Jacob Abernethy, and Zsolt Kira. On convergence and stability of gans.
2018.
Alex Krizhevsky. Learning multiple layers of features from tiny images. 2009.
Anders Boesen Lindbo Larsen, S0ren Kaae S0nderby, and Ole Winther. Autoencoding beyond pixels
using a learned similarity metric. CoRR, abs/1512.09300, 2015. URL http://arxiv.org/
abs/1512.09300.
Y. Lecun, L. Bottou, Y. Bengio, and P. Haffner. Gradient-based learning applied to document
recognition. Proceedings of the IEEE, 86(11):2278-2324, 1998.
Zinan Lin, Ashish Khetan, Giulia Fanti, and Sewoong Oh. Pacgan: The power of two samples
in generative adversarial networks. In S. Bengio, H. Wallach, H. Larochelle, K. Grauman,
N. Cesa-Bianchi, and R. Garnett (eds.), Advances in Neural Information Processing Systems 31,
pp. 1498-1507. Curran Associates, Inc., 2018. URL http://papers.nips.cc/paper/
7423- pacgan- the- power- of- two- samples- in- generative- adversarial- networks.
pdf.
Alireza Makhzani, Jonathon Shlens, Navdeep Jaitly, and Ian J. Goodfellow. Adversarial autoencoders.
CoRR, abs/1511.05644, 2015. URL http://arxiv.org/abs/1511.05644.
Xudong Mao, Qing Li, Haoran Xie, Raymond Y. K. Lau, and Zhen Wang. Multi-class generative
adversarial networks with the L2 loss function. CoRR, abs/1611.04076, 2016. URL http:
//arxiv.org/abs/1611.04076.
9
Under review as a conference paper at ICLR 2021
Luke Metz, Ben Poole, David Pfau, and Jascha Sohl-Dickstein. Unrolled generative adversarial
networks. In 5th International Conference on Learning Representations, ICLR 2017, Toulon,
France, April 24-26, 2017, Conference Track Proceedings, 2017. URL https://openreview.
net/forum?id=BydrOIcle.
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan,
Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas
Kopf, Edward Yang, Zachary DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy,
Benoit Steiner, Lu Fang, Junjie Bai, and Soumith Chintala. Pytorch: An imperative style,
high-performance deep learning library. In H. Wallach, H. Larochelle, A. Beygelzimer,
F. d Alche-Buc, E. Fox, and R. Garnett (eds.), Advances in Neural Information Processing Systems
32, pp. 8026-8037. Curran Associates, Inc., 2019. URL http://papers.nips.cc/paper/
9015-pytorch-an-imperative-style-high-performance-deep-learning-library.
pdf.
Alec Radford, Luke Metz, and Soumith Chintala. Unsupervised representation learning with deep
convolutional generative adversarial networks. arXiv preprint arXiv:1511.06434, 2015.
Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, and Xi Chen.
Improved techniques for training gans. In Advances in neural information processing systems, pp.
2234-2242, 2016.
Akash Srivastava, Lazar Valkov, Chris Russell, Michael U Gutmann, and Charles Sutton. Veegan:
Reducing mode collapse in gans using implicit variational learning. In Advances in Neural
Information Processing Systems, pp. 3308-3318, 2017.
Ngoc-Trung Tran, Tuan-Anh Bui, and Ngai-Man Cheung. Dist-gan: An improved gan using distance
constraints. In Proceedings of the European Conference on Computer Vision (ECCV), pp. 370-385,
2018.
Fisher Yu, Yinda Zhang, Shuran Song, Ari Seff, and Jianxiong Xiao. Lsun: Construction of a large-
scale image dataset using deep learning with humans in the loop. arXiv preprint arXiv:1506.03365,
2015.
Zhiming Zhou, Jiadong Liang, Yuxuan Song, Lantao Yu, Hongwei Wang, Weinan Zhang, Yong Yu,
and Zhihua Zhang. Lipschitz generative adversarial nets. arXiv preprint arXiv:1902.05687, 2019.
A Proofs
A.1 Proof of Theorem 1
Proof. The conditional probability of X0 given label can be written as IP(XIei) = Pi(X0), so further
k
IP(X0, ei) = 1 pi. And we denote the marginal distribution of X as p(χ) = k P Pi(x). Cause the
i=1
activation function at the output layer of the classifier is softmax, we can rewrite the loss function
into a more explicit form:
VClass(f ) = Wi 〜U[k] WX0~pi - ei log f (X ) = Wi 〜U [k] WX0~pa - log fi (X)
=1 Z X -Pi(x) log fi(x)dx = ZP(X) {- Xp(ei∣x)log fi(x，dx.
10
Under review as a conference paper at ICLR 2021
Let gi(x) = p(ei∣X)), then P p® ∣x)gi(x)
i=1
inequality, we have:
k
1. And notice that P p(ei|x) = 1.
i=1
By Jensen’s
kk
-p(ei|x) logfi(x) =	-p(ei|x) log[gi (x)p(ei |x)]
i=1	i=1
kk
=E -p(ei∣x) loggi(x) + H(p(∙∣x)) ≥ log £p(ei∣x)gi(x) + H(Pi(∙∣x))
i=1	i=1
=log1 + H(p(∙∣χ)) = H (p(∙∣x)).
And VClass(f *) = pp(x)H(pi(∙∣x))dx if and only if g*(x) = gj(x) for any i = j, which means
k
that fe(Xx)) = r	∀i	∈	[k],	where r ∈	R.	Notice that P 疗(x)	=	1,	it is not difficult to get that
i	i=1
fi*(x) = p(ei∣x). The loss function becomes
1	k	k1
不	废-Pi(X)Iogp(e∕x)dx = -H(x) + V" HH(Pi) + log k
kk
i=1	i=1
= -JS(P1,P2, ...,Pk) + log k
(7)
□
A.2 Proof of Theorem 2
Proof. According to Theorem 1, for a given real number 1, we can find another δ1, when intervention
loss is less than δ1, the distance between Pi and Pj under the measurement of JS-divergence is less
than 1. And because JS-divergence and Total Variance distance (TV) are equivalent in the sense of
convergence. So we can bound the TV-distance between Pi and Pj by their JS-divergence. Which
means that |Pi - Pj |dx ≤ 0 when the intervention loss is less than 1 (we can according to
the 0 to finding the appropriate 1). Using this conclusion we can deduce |P (E(G(Oi(z))) ≤
r) - P(E(G(Oj(Z))) ≤ r)| ≤ ∈o, where r is an arbitrary vector in Rd. Further, we have:
|P(Oi(z) ≤ r) - P(Oj(z) ≤ r)l ≤ ∣P(Oi(Z) ≤ r； IQi(z) - E(G(Oi(z)))k > δ)∣
+ ∣P(Oj(z) ≤ r； kOj(z) - E(G(Oj(z)))k > δ)∣ + |P(Oi(Z) ≤ r； ∣Qi(z) - E(G(Oi(Z)))Il ≤ δ)
-P(Oj(z) ≤ r； kOj(z) - E(G(Oj(z)))k ≤ δ)∣
(8)
We control the three terms on the right side of the inequality sign respectively.
P (Oi(Z) ≤ r； kOi(Z) - E(G(Oi(Z)))k >δ)
≤ P(kOi(z) - E(G(Oi(Z)))I > δ) ≤ 叫。i(Z)-E(G(Oi(Z)))k	⑼
δ
And the last term can be bounded by the reconstruction loss. The same trick can be used on
P(Oj(Z) ≤ r； kOj(Z) - E(G(Oj(Z)))k > δ). Moreover, we have
P (E(G(Oi(Z))) ≤ r - δ) - P (kOi(Z) - E(G(Oi(Z)))k >δ)	10
≤P(Oi(Z) ≤ r； kOi(Z) - E(G(Oi(Z)))k ≤δ) ≤ P(E(G(Oi(Z))) ≤r+δ)	(10)
Notice that lim P(E(G(Oi (Z))) ≤ r ± δ) = P(E(G(Oi (Z))) ≤ r). Let si (r, δ) =
δ→0
|P (E (G(Oi (Z))) ≤ r ± δ)) - P(E(G(Oi(Z))) ≤ r)| then the last term of inequalityA.2 can
be bounded as:
|P(Oi(z) ≤ r；kOi(Z) - E(G(Oi(Z)))I ≤ δ) - P(Oj(z) ≤ r; IIOj(z) - E(G(Oj(Z)))Il ≤ δ)∣
≤∣P(E(G(Oi(Z))) ≤ r) - P(E(G(Oj(z))) ≤ r)| + P(∣Oi(Z) - E(G(Oi(z)))∣∣ > δ)
+ si (r, δ) + sj (r, δ)
(11)
Every term on the right hand of the inequality can be controlled close to 0 by the inequalities
mentioned above.	□
11
Under review as a conference paper at ICLR 2021
B Experimental Details
B.1 Network Architectures
Table 4: The NN architecture used by us, where CONV denotes the convolutional la yer, TCONV
denotes the transposed convolutional layer, FC denotes the fully-connected layer, BN denotes the
batch normalization layer, and (K4, S1, O512) denotes a layer with kernel of size 4, stride 1, and 512
output channels.
D	G	E
INPUT 64×64×3	INPUTz	INPUT 64×64×3
CONV(K4, S2, O64)	TCONV(K4, S1, O512)	CONV(K4, S2, O64)
BN, LeakyReLU	BN, ReLU	LeakyReLU
CONV(K4, S2, O128)	TCONV(K4, S2, O256)	CONV(K4, S2, O128)
BN, LeakyReLU	BN, ReLU	BN, LeakyReLU
CONV(K4, S2, O256)	TCONV(K4, S2, O128)	CONV(K4, S2, O256)
BN, LeakyReLU	BN, ReLU	BN, LeakyReLU
CONV(K4, S2, O512)	TCONV(K4, S2, O64)	CONV(K4, S2, O512)
BN, LeakyReLU	BN, ReLU	BN, LeakyReLU
FC(O1)	TCONV(K4, S2, O3)	CONV(K4, S2, O100)
LOSS	Tanh	BN
B.2 Hyperparameter Settings
Table 5: Detailed hyperparameter settings in our experiments.
Settings of the Adam optimizer
lrD	lrG	lrE	BatchSize β1	β2
Other Hyperparameters
DCGAN	0.0001	0.0001
LSGAN	0.0002	0.0002
WGANGP	0.0001	0.0001
MRGAN	0.0002	0.0002
0.01
64646464
99 9
9999
.9.90..9
00 0
.5.5.5.5
0000
λ
IVDCGAN 0.0002 0.0002 0.005
IVLSGAN 0.0002 0.0002 0.005
64	0.5 0.999
64	0.5 0.999
μ = 0.5	λ = 0.25	k = 4
μ = 0.5	λ = 0.25	k = 4
C	Related Work
In order to address GAN’s unstable training and mode missing problems, many researchers have
turned their attention to the latent representations of samples. Makhzani et al. (2015) proposed
the Adversarial Autoencoder (AAE). As its name suggests, AAE is essentially a probabilistic
autoencoder based on the framework of GANs. Unlike classical GAN models, in the setting of AAE
the discriminator’s task is to distinguish the latent representations of real images that are generated
by an encoder network from Gaussian noise. And the generator and the encoder are trained to fool
the discriminator as well as reconstruct the input image from the encoded representations. However,
the generator can only be trained by fitting the reverse of the encoder and cannot get any information
from the latent representation.
The VAE-GAN (Larsen et al., 2015) combines the objective function from a VAE model with a GAN
and utilizes the learned features in the discriminator for better image similarity metrics, which is
of great help for the sample visual fidelity. Considering the opposite perspective, Che et al. (2016)
claim that the whole learning process of a generative model can be divided into the manifold learning
phase and the diffusion learning phase. And the former one is considered to be the source of the
mode missing problem. (Che et al., 2016) then proposed Mode Regularized Generative Adversarial
12
Under review as a conference paper at ICLR 2021
Nets which introduce a reconstruction loss term to the training target of GAN to penalize the missing
modes. It is shown that it actually ameliorates GAN’s ’mode missing’-prone weakness to some extent.
However, both of them fail to fully excavate the impact of the interaction between VAEs and GANs.
Kim & Mnih (2018) proposed Factor VAE where a regularization term called total correlation
penalty is added to the traditional VAE loss. The total correlation is essentially the Kullback-Leibler
divergence between the joint distribution p(z1, z2, . . . , zd) and the product of marginal distribution
p(zi). Because the closed forms of these two distribution are unavailable, Factor VAE uses adversarial
training to approximate the likelihood ratio.
13