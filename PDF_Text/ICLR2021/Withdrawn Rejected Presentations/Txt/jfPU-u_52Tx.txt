Under review as a conference paper at ICLR 2021
Federated Generalized Bayesian Learning
via Distributed Stein Variational Gradient
Descent
Anonymous authors
Paper under double-blind review
Ab stract
This paper introduces Distributed Stein Variational Gradient Descent (DSVGD),
a non-parametric generalized Bayesian inference framework for federated learn-
ing. DSVGD maintains a number of non-random and interacting particles at a
central server to represent the current iterate of the model global posterior. The
particles are iteratively downloaded and updated by one of the agents with the end
goal of minimizing the global free energy. By varying the number of particles,
DSVGD enables a flexible trade-off between per-iteration communication load
and number of communication rounds. DSVGD is shown to compare favorably to
benchmark frequentist and Bayesian federated learning strategies in terms of ac-
curacy and scalability with respect to the number of agents, while also providing
well-calibrated, and hence trustworthy, predictions.
1	Introduction
Federated learning refers to the collaborative training of a machine learning model across agents
with distinct data sets, and it applies at different scales, from industrial data silos to mobile de-
vices (Kairouz et al., 2019). While some common challenges exist, such as the general statistical
heterogeneity - "non-iidnes" 一 of the distributed data sets, each setting also brings its own distinct
problems. In this paper, we are specifically interested in a small-scale federated learning setting
consisting of mobile or embedded devices, each having a limited data set and running a small-sized
model due to their constrained memory. As an example, consider the deployment of health monitors
based on data from smart-watch ECG data. In this context, we argue that it is essential to tackle the
following challenges, which are largely not addressed by existing solutions:
•	Trustworthiness: In applications such as personal health assistants, the learning agents’ recom-
mendations need to be reliable and trustworthy, e.g., to decide when to contact a doctor in case of a
possible emergency;
•	Number of communication rounds: When models are small, the payload per communication round
may not be the main contributor to the overall latency of the training process. In contrast, accom-
modating many communication rounds requiring arbitrating channel access among multiple devices
may yield slow wall-clock time convergence (Lin et al., 2020).
Most existing federated learning algorithms, such as Federated Averaging (FedAvg) (McMahan
et al., 2017), are based on frequentist principles, relying on the identification of a single model pa-
rameter vector. Frequentist learning is known to be unable to capture epistemic uncertainty, yielding
overconfident decisions (Guo et al., 2017). Furthermore, the focus of most existing works is on
reducing the load per-communication round via compression, rather than decreasing the number
of rounds by providing more informative updates at each round (Kairouz et al., 2019). This paper
introduces a trustworthy solution that is able to reduce the number of communication rounds via a
non-parametric variational inference-based implementation of federated Bayesian learning.
Federated Bayesian learning has the general aim of computing the global posterior distribution in
the model parameter space. Existing decentralized, or federated, Bayesian learning protocols are
either based on Variational Inference (VI) (Angelino et al., 2016; Neiswanger et al., 2015; Brod-
erick et al., 2013; Corinzia & Buhmann, 2019b) or Monte Carlo (MC) sampling (Ahn et al., 2014;
Mesquita et al., 2020; Wei & Conlon, 2019). State-of-the-art methods in either category include Par-
titioned Variational Inference (PVI), which has been recently introduced as a unifying distributed
VI framework that relies on the optimization over parametric posteriors; and Distributed Stochas-
tic Gradient Langevin Dynamics (DSGLD), which is an MC sampling technique that maintains a
number of Markov chains updated via local Stochastic Gradient Descent (SGD) with the addition of
1
Under review as a conference paper at ICLR 2021
Server
® Φ* ~ argmaχ0∈∙{-^d砂(％@(e)l/「(e))
吟 i.]+e0**-1])'
(a)	(b)
Figure 1: Federated learning across K agents equipped with local datasets and assisted by a central
server: (a) in DVI agents exchange the current model posterior q(i)(θ) with the server, while (b) in
DSVGD agents exchange particles {θn}N=ι providing a non-parametric estimate of the posterior.
Gaussian noise (Ahn et al., 2014; Welling & Teh, 2011). The performance of VI-based protocols is
generally limited by the bias entailed by the variational approximation, while MC sampling is slow
and suffers from the difficulty of assessing convergence (Angelino et al., 2016).
Stein Variational Gradient Descent (SVGD) has been introduced in (Liu & Wang, 2016) as a non-
parametric Bayesian framework that approximates a target posterior distribution via non-random and
interacting particles. SVGD inherits the flexibility of non-parametric Bayesian inference methods,
while improving the convergence speed of MC sampling (Liu & Wang, 2016). By controlling the
number of particles, SVGD can provide flexible performance in terms of bias, convergence speed,
and per-iteration complexity. This paper introduces a novel non-parametric distributed learning
algorithm, termed Distributed Stein Variational Gradient Descent (DSVGD), that transfers the
mentioned benefits of SVGD to federated learning.
As illustrated in Fig. 1, DSVGD targets a generalized Bayesian learning formulation, with arbitrary
loss functions (Knoblauch et al., 2019); and maintains a number of non-random and interacting
particles at a central server to represent the current iterate of the global posterior. At each iteration,
the particles are downloaded and updated by one of the agents by minimizing a local free energy
functional before being uploaded to the server. DSVGD is shown to enable (i) a trade-off between
per-iteration communication load and number of communication rounds by varying the number of
particles; while (ii) being able to make trustworthy decisions through Bayesian inference.
2	System Set-up
We consider the federated learning set-up in Fig. 1, where each agent k = 1, . . . , K has a distinct
local dataset with associated training loss Lk(θ) for model parameter θ. The agents communicate
through a central node with the goal of computing the global posterior distribution q(θ) over the
shared model parameter θ ∈ Rd for some prior distribution po(θ) (Angelino et al., 2016). Specif-
ically, following the generalized Bayesian learning framework (Knoblauch et al., 2019), the agents
aim at obtaining the distribution q(θ) that minimizes the global free energy
ɪmiθɪn {fS(O)) = XEθ〜q(θ)[Lk⑻] + aD(q(0川PO(O))},
(1)
where α > 0 is a temperature parameter. The (generalized, or Gibbs) global posterior qopt (O)
solving problem (1) must strike a balance between minimizing the sum loss function (first term in
F(q)) and the model complexity defined by the divergence from a reference prior (second term in
F(q)). It is given as
1	1K
qopt(θ) = Z ∙ qopt(θ) with qopt(θ) = PO(θ)exp ( - - X Lk(θ)),
α k=1
(2)
where we denoted as Z the normalization constant. It is useful to note that the global free energy
can also be written as the scaled KL F(q(θ)) = αD(q(θ)∣∣⅞opt(θ)).
2
Under review as a conference paper at ICLR 2021
The main challenge in computing the optimal posterior qopt(θ) in a distributed manner is that each
agent k is only aware of its local loss Lk (θ). By exchanging information through the server, the K
agents wish to obtain an estimate of the global posterior (2) without disclosing their local datasets
neither to the server nor to the other agents. In this paper, we introduce a novel non-parametric
distributed generalized Bayesian learning framework that addresses this challenge by integrating
Distributed VI (DVI) and SVGD (Liu & Wang, 2016).
3	Distributed Variational Inference
In this section, we describe a general Expectation Propagation (EP)-based framework (Vehtari et al.,
2020), which we term as DVI, that aims at computing the global posterior in a federated fashion
(Bui et al., 2018; Corinzia & Buhmann, 2019b). DVI starts from the observation that the posterior
(2) factorizes as the product
K
q(θ) = p0(θ) Ytk(θ),	(3)
k=1
where the term tk(∙) is given by the scaled local likelihood exp(α-1Lk(θ))∕Z. Since the normal-
ization constant Z depends on all data sets, the true scaled local likelihood tk(∙) cannot be directly
computed at agent k. The idea of DVI is to iteratively update approximate likelihood factors tk (θ)
for k = 1, ..., K by means of local optimization steps at the agents and communication through the
server, with the aim of minimizing the global free energy (1) over distribution (3).
We give here the standard implementation of DVI in which a single agent is schedule at each time,
although parallel implementations are possible and discussed below. Accordingly, at each commu-
nication round i = 1, 2, ..., the server maintains the current iterate q(i-1) (θ) of the global posterior,
and schedules an agent k ∈ {1, 2, . . . , K}, which proceeds as follows:
1.	Agent k downloads the current global variational posterior distribution q(i-1) (θ) from the server
(see Fig. 1(a), step ①)；
2.	Agent k updates the global posterior by minimizing the local free energy Fk(i) (q(θ)) (see Fig.
1(a), SteP ②)
q ⑴(θ) = argmin {f, (q(θ)) = ¾^q(θ) [Lk(θ)] + αD (q(θ)∣*(θ))},	(4)
where We have defined the (unnormalized) cavity distribution Pki) (θ) as
Pki) (Θ)
q*D(θ)
tki-1)(θ)
(5)
The cavity distribution Pki) (θ), which removes the contribution of the current approximate likelihood
of agent k from the current global posterior iterate, serves as a prior for the update in (4). In a manner
similar to (2), the local free energy is minimized by the tilted distribution Pki) (θ) 8 Pki) (θ) with
Pki)(θ)= Pki)(θ)exp (- 1 Lk(θ));	(6)
3.	Agent k sends the updated posterior q(i)(∙) = p£)(・)to the server (see Fig. 1(a), step ③)，and
updates its approximate likelihood accordingly as
t(i)(θ) = q("(θ) t(i-1)(θ)∙
tk ⑼=q(i-1)(θ)tk (θ);
(7)
Finally, non-scheduled agents k0 6= k set t(ki0) (θ) = t(ki0-1)(θ), and the server sets the next iterate as
q(i)(θ). We have the following key property of DVI.
Theorem 1. The global posterior qopt (θ) in (2) is the unique fixed point of the DVI algorithm.
The fixed-point property in Theorem 1 can be verified directly by setting q(i-1) (θ) = qopt (θ)
and t(ki-1)(θ) = exp(α-1Lk(θ))∕Z and by observing that this leads to the fixed point con-
dition q(i) (θ) = q(i-1) (θ) = qopt(θ). The proof is provided in Sec. A.6. Importantly,
this property is not tied to the sequential implementation detailed above, and it applies also if
multiple devices are scheduled in parallel, as long as one sets the next iterate as q(i) (θ) =
P0(θ) Qk∈K(i) t(ki)(θ) Qk06∈K(i) t(ki0)(θ), where K(i) denotes the set of scheduled agents at communi-
cation round i and we have t(ki0)(θ) = t(ki0-1)(θ) and t(ki)(θ) updated following (7).
3
Under review as a conference paper at ICLR 2021
4	Preliminaries
In this section, we briefly review PVI, which serves as an important benchmark, and SVGD, on
which we build the proposed Bayesian federated learning solution.
4.1	Partitioned Variational Inference
The exact minimization of the local free energy function (4) assumed by DVI is often not tractable.
To address this problem, in its most typical form, PVI constrains the local free energy minimization
(4) to the space of parametric distributions that factorize as q(θ∣η) = p0(θ∣η0) QK=I tk (θ∣ηk), Where
priorp0(∙∣η0) = ExPFam(∙∣ηo) and approximate likelihood tk(∙∣ηk) = ExPFam(∙∣ηk) are selected
from the same exponential-family distribution, With natural parameters η0 and ηk , respectively. PVI
folloWs the same steps as DVI With the caveat that the local free energy (4) for agent k is minimized
over the natural parameter η. This can be done efficiently, albeit approximately, using for e.g.,
natural gradient descent (Amari, 1998).
The bias imposed by the parametrization in PVI significantly affects the quality of the approximation
of the obtained posterior q(θ) With respect to the true global posterior qopt(θ) in the presence of
model misspecification. In this case, the fixed point property in Theorem 1 no longer applies.
4.2	Stein Variational Gradient Descent (SVGD)
SVGD tackles the minimization of the (scaled) free energy functional D(q(θ) ∣∣p(θ)), for an unnor-
malized target distribution p(θ), over a non-parametric generalized posterior q(θ) defined over the
model parameters θ ∈ Rd. The posterior q(θ) is represented by a set of particles {θn}N=ι, with
θn ∈ Rd. In practice, an approximation of q(θ) can be obtained from the particles {θn}N=ι through
a Kernel Density Estimator (KDE) as q(θ) = NT PN=I K(θ, θn) for some kernel function K(∙, ∙)
(Bishop, 2006). The particles are iteratively updated through a series of transformations that are
optimized to minimize the free energy. The transformations are restricted to lie within the unit ball
of a Reproducing Kernel Hilbert Space (RKHS) Hd = H × . . . × H. It is shown by Liu & Wang
(2016) that this optimization yields the SVGD update
N
θn] 一 θ[n-1]+N xmθ尸,θn-1])Vθj log p(θ尸)+v%.k(θ 尸,θn-1])]	⑻
j =1
for n = 1,..., N, where k(∙, ∙) is the positive definite kernel associated with RKHS H. The first
term in the update (8) drives the particles towards the regions of the target distribution p(θ) with high
probability, while the second term drives the particles away from each other, encouraging exploration
in the model parameter space. It is known that, in the asymptotic limit of a large number N of
particles, the empirical distribution encoded by the particles {θn[l] }nN=1 converges to the normalized
target distribution p(θ) a p(θ) (Liu, 2017b).
5	Distributed S tein Variational Gradient Descent
In this section, we introduce DSVGD, a novel distributed algorithm that tackles the generalized
Bayesian inference problem (1) via DVI over a non-parametric particle-based representation of the
global posterior. As illustrated in Fig. 1(b), DSVGD is based on the iterative optimization of local
free energy functionals (4) via SVGD (see Sec. 4), and on the exchange of particles between the
central server and agents. Given the flexibility of the non-parametric form of the posterior, DSVGD
doesn’t suffer from the bias caused by the parametrization assumed by PVI. As a result, in the limit of
a sufficiently large number of particles, DSVGD benefits from the fixed point property of DVI stated
in Theorem 1, recovering the true global posterior as a fixed point of its iterations. Furthermore, as
we will discuss, DSVGD enables devices to exchange more informative messages regarding the
current iterate of the posterior by increasing the number of particles. This can in turn reduce the
number of communication rounds and the overall communication load to convergence, at the cost
of a larger per-round load. In this regard, we note that, in practice, a small number of particles is
sufficient to obtain state-of-the-art performance (Liu & Wang, 2016), as verified in Sec. 7.
In order to facilitate the presentation, we first introduce a simpler version of DSVGD that has the
practical drawback of requiring each agent to store a number of particles that increases linearly
with the number of iterations in which the agent is scheduled. Then, we present a more practical
algorithm, for which the memory requirements do not scale with the number of iterations as each
agent must only memorize a set ofN local particles across different iterations. Algorithmic table for
4
Under review as a conference paper at ICLR 2021
Algorithm 1: Distributed Stein Variational Gradient Descent (DSVGD)
Input: prior po(θ), local loss functions {Lk(θ)}K=ι, temperature α > 0, kernels K(∙, ∙) and k(∙, ∙)
Output: global approximate posterior q(θ) = N -1 PnN=1 K(θ, θn)
ι initialize q(0)(θ) = po(θ); {θn0)}N=ι 削 po (θ); {。鼠=θ^ }N= and t(0 (θ) = 1 for k = 1,...,K
2	for i = 1, . . . , I do
3	Server schedules an Agent k
4	Agent	k downloads current global particles {θn(i-1) }nN=1 from server
5	Agent	k obtains updated global particles {θn* * * * * * * * (i) }nN=1 using (13), {θn(i-1)	}nN=1 and {θk(i,-n 1) }nN=1
6	Agent	k sends the updated global particles {θn(i) }nN=1 to the server
7	Agent	k carries distillation to obtain {θk(i,)n}nN=1 encoding t(ki) (θ) using	(17) and	{θn(i) }nN=1
8	end
9	return q(θ) = N-1 PnN=1 K(θ, θn(I))
Unconstrained-DSVGD (U-DSVGD) in addition to discussions on complexity and convergence, can
be found respectively in Sec. A.1 and Sec. A.4 in the supplementary materials. A direct extension
of DSVGD, termed Parallel-DSVGD (P-DSVGD), where multiple agents are scheduled per round
can be found in Sec. A.5 of the Appendix.
5.1 U-DSVGD
In this section, we present a simplified DSVGD variant, which we refer to as U-DSVGD. We follow
the standard implementation of DVI with a single agent k scheduled at each communication round
i = 1, 2, . . ., although, as discussed, parallel implementations are also possible. Let us define as
Ik(i) ⊆ {1, . . . , i} the subset of rounds at which agent k is scheduled prior, and including, iteration
i. At the beginning of each round i, the server maintains the iterate of the current global particles
{θn(i-1)}nN=1, while each agent k keeps a local buffer of particles {θn(j-1), θn(j) *}nN=1 for all previous
rounds j ∈ Ik(i-1) at which agent k was scheduled. The growing memory requirements at the
agents will be dealt with by the final version of DSVGD to be introduced in Sec. 5.2. Furthermore,
as illustrated in Fig. 1(b), at each iteration i, U-DSVGD schedules an agent k ∈ {1, 2, . . . , K} and
carries out the following steps.
1. Agent k downloads the current global particles {θn(i-1)}nN=1 from the server (see Fig. 1(b), step
①)and includes them in the local buffer.
2. Agent k updates each downloaded particle as
θ[l] 一。尸+ eφ(θ[l-1]), for l = 1,...,L,	(9)
where L is the number of local iterations; [l] denotes the local iteration index; we have the initializa-
tion θ[0] = θf-1); and the function φ(∙) is to be optimized within the unit ball of a RKHS Hd. The
function φ(∙) is specifically optimized to maximize the steepest descent decrease of a particle-based
approximation of the local energy (4). To elaborate, we denote as q(i-1) (θ) = PnN=1 K(θ, θn(i-1))
the KDE of the current global posterior iterate encoded by particles {θn(i-1)}nN=1. Adopting the fac-
torization (3) for the global posterior (cf. (7)), we define the current local approximate likelihood
t(i-ι)(θ) = Y q(j]θ) =q(iT)⑻ t(i-2)(θ)	(IO)
k ⑼=	qjT)(θ) = q("2)(θ) k ⑼，	(IO)
j∈Ik( - )
Note that (1O) can be computed using all the particles in the buffer at agent k at iteration i. Finally,
the (unnormalized) tilted distribution Pki) (cf. (6)) is written as
Pki)⑻=q(y⅛-7exp (-1 Lk⑻).	(11)
tk	(θ)
Following SVGD, the update (9) is optimized to maximize the steepest descent decrease of the
Kullback-Leibler (KL) divergence between the approximate global posterior q'(θ) encoded via
particles {θ∕ }N=ι and the tilted distribution Pki) (θ) in (11) (see Fig. 1(b), step ②)，i.e.,
5
Under review as a conference paper at ICLR 2021
i=0 (L = IOO)
i = l (L = IOO)
Agent 1
i = 3 (L = IOO)
Agent 1
i = 4 (L = IOO)
Agent 2
Figure 2: Gaussian toy example with uniform prior and K = 2. Dashed lines represent local poste-
riors, the shaded area represents the true global posterior, while the solid blue line is the approximate
posterior obtained using a KDE over the particles.DSVGD schedules agent 1 and 2 at odd and even
number of communication rounds i, respectively.
φ? (∙) 一患 mχ{--(qL 川Pki)⑻—≤ O	(i2)
Thus, recalling (8), the particles are updated as
N
θnn] 一 θ[n-1]+N x1k（。尸,。尸》联力黑伊尸户©。^1-1],。匕1]）. i=i,...l.
j =1
3. Agent k sets θn(i) = θn[L] for n = 1, . . . , N . Particles {θn(i)}nN=1 are added to the buffer and sen(1t 3to)
the server (See Fig. 1(b), step ③)that updates the current global particles as {θn }nN=1 = {θn(i)}nN=1
In order to implement the described U-DSVGD algorithm, we need to compute the gradient in (13)
at agent k . First, by (11), we have
Vθ logPki)(θ) = Vθlogq(I)(θ) - Vθ logtki-1)(θ) - 1 VθLk(θ).	(14)
Using (10), the second gradient term can be obtained in a recursive manner using the local buffer as
(i-1)	Vθ log t(ki-2)(θ) if agent k not scheduled at iteration (i - 1)
θ g k	Vθ log t(ki-2)(θ) + Vθ log q(i-1) (θ) - Vθ log q(i-2)(θ) otherwise.
Finally, the gradients Vθ log q(j)(θ) can be directly computed from the KDE expression of q(j )(θ),
with initializations t(0) (θ) = 1 and q(0) (θ) = p0(θ). The inner loop of U-DSVGD inherits the
asymptotic convergence properties of SVGD in terms of local free energies, but existing results do
not imply that the global free energy decreases across the iterations. This result is provided in the
next theorem, whose precise formulation can be found in Sec. A.6 of the Appendix.
Theorem 2 (Guaranteed per-iteration decrease of the global free energy.). The decrease in the global
free energy from local iteration l to l + 1 during communication round i for which agent k is sched-
uled can be lower bounded as
F(q[l](θ)) — F(q[l+1](θ)) ≥ aeS(q*pki))(1 - eγ) - 2α(K - 1)段乂,2D®1+1] ||q[l]),	(16)
where 俏]X = sup max| log(tmi,-1)(θ)) ∙ exp(-Lm(θ))∖, S(q,p) denotes the Kernalized Stein Dis-
θ m6=k	α
crepancy between distributions q and p (Liu et al., 2016), and γ is a constant depending on the
RKHS kernel and the target distribution.
The first term in bound (16) quantifies the decrease in the local free energy at agent k, which depends
on the “distance” between current iterate q[l] and the local target given by the tilted distribution
p(ki)(θ); while the second term quantifies the effect of the update on the local free energies of other
agents. In the presence of only one agent, the second terms reduce to zero, and one recovers the
upper bound on the guaranteed per-iteration improvement for SVGD derived in Korba et al. (2020).
5.2 DSVGD
In this section, we describe the final version of DSVGD, which, unlike U-DSVGD, requires each
agent k to maintain only N local particles {θk(i,)n }nN=1 across the communication rounds i = 1, 2, .
To this end, in each round i, at the end of the L local SVGD updates in (13), DSVGD carries out a
6
Under review as a conference paper at ICLR 2021
(SIua6ea
Λ9e∙ln8v
Coverfype dataset
-w- DSVGD W= 6) →- SVGD
— DSVGD (JV= 2) -→- SGLD
■ . FedAvg l l∙ DSGLD
2	4	6	8	10
Numberofrounds i
5,u∂6ea
Λ9e∙ln8v
Twonorm dataset
Number of rounds i
(SlUaee 0a
Λ0e∙ln8v
Covertype dataset
0.75
→~ DSVGD(N= 6) →- SVGD
— DSVGD (7V=2) -→- SGLD
■ ♦ι FedAvg	. FSGLD
O 20	40	60	∞
Numberofrounds
@ua6e 0a
Λ0e∙ln8v
Twonorm dataset
20	40	--
Number of rounds i
DSVGD (N=叫-→-
— DSVGD (JV= 2) -→-
-♦ ■ FedAvg	.
Figure 4: Accuracy for Bayesian logistic regression with (left) K = 2 agents and (right) K = 20
agents as function of the number of communication rounds i (N = 6 particles, L = L0 = 200).
form of model distillation (Hinton et al., 2015; Chen & Chao, 2020) via SVGD. Specifically, L0 ad-
ditional SVGD steps are used to approximate the term t(ki)(θ) using the N local particles {θk(i,)n}nN=1.
It is noted that this approximation step is not necessarily harmful to the overall performance, since
describing the factor t(ki) (θ) with fewer particles can have a denoising effect acting as a regularizer.
DSVGD operates as U-DSVGD apart from the computation of the gradient in (14) and the man-
agement of the local particle buffers. The key idea is that, instead of using the recursion (15)
to compute (14), DSVGD computes the gradient Vθlogtki-1)(θ) from the KDE ta-1)(θ)=
PnN=1 K(θ, θk(i,-n1)) based on the local particles {θk(i,-n1)}nN=1 in the buffer. At the end of each round
i, the local particles {θk(i,-n1)}nN=1 are updated by running L0 local SVGD iterations with target given
by the updated local factor tf)(θ)=勺&%tki-1)(θ). This amounts to the updates
0N
n[l ]	,	n[l -1]	e ∖、	[l -1]	n[l	-1]	(i) (∩∖	∣ ʊ	∕√Q[l	-1]	n[l	-1]、
θk,n J	θk,n	+ N /	Jk(θk,j	,θk,n	)V θj	log tk	(θ) + V θj k(θk,j	，θk,n	)]，	(17)
j=1
for l0 = 1, . . . , L0 and some learning rate e0, where the gradient Vθ log t(ki)(θ) = Vθ log q(i) (θ) +
Vθ log t(ki-1)(θ) - Vθ log q(i-1) (θ) can be directly computed using KDE based on the available
particles {θn(i)}nN=1 (updated global particles), {θk(i,-n1)}nN=1 (local particles) and {θn(i-1)}nN=1 (down-
loaded global particles). Finally, we note that the distillation operation can be performed after send-
ing the updated global particles to the server and thus enabling pipelining of the L0 local iterations
with operations at the server and other agents. DSVGD is summarized in Algorithm 1.
6	Related Work
Extensions of SVGD. Since its introduction, SVGD has been ex-
tended in various directions. Most related to this work is Zhuo et al.
(2018), which introduces a message-passing SVGD solution for
high-dimensional latent parameter spaces by leveraging conditional
independence properties in the variational posterior; and Yoon et al.
(2018), which uses SVGD as the per-task base learner in a meta-
learning algorithm approximating Expectation Maximization.
Generalized Bayesian Inference. Owing to its reliance on point
estimates in the model parameter space, frequentist learning meth-
ods, such as Federated Stochastic Gradient Descent (FedSGD),
FedAvg and their extensions (Zhang et al., 2020; Li et al., 2018;
Pathak & Wainwright, 2020; Nguyen et al., 2020; Wang et al., 2020)
Φ-SE!XO-Jdde PLIE.JOPgSOd
uφφM1φq 8uφ6jφ≥p ~|工
→- U-DSVGD
DSVGD
-→- PVI
-H- GVI
-→- SVGD
Numberof rounds i
Figure 3: KL divergence be-
tween exact and approximate
global posteriors as function
of the number of rounds i
(L = L0 = 200).
are limited in their capacity to combat overfitting and quantify uncertainty (Guo et al., 2017; Mitros
& Mac Namee, 2019; Neal, 2012; Jospin et al., 2020; MacKay, 2002). This contrasts with the gen-
eralized Bayesian inference framework that produces distributional, rather than point, estimates by
optimizing the free energy functional, which is a theoretically principled bound on the generalization
performance (Zhang, 2006; Knoblauch et al., 2019). Practical algorithms for generalized Bayesian
inference can leverage computationally efficient scalable solutions based on either MC sampling or
VI methods (Angelino et al., 2016; Alquier et al., 2016).
Distributed MC Sampling. The design of algorithms for distributed Bayesian learning has been so
far mostly focused on one-shot, or “embarrassingly parallel”, solutions under ideal communications
(Jordan et al., 2019). These implement distributed MC “consensus” protocols, whereby samples
from the global posterior are approximately synthesized by combining particles from local posteriors
(Scott et al., 2016; Liu & Ihler, 2014). Iterative extensions, such as Weierstrass sampling (Wang &
7
Under review as a conference paper at ICLR 2021
Dunson, 2013; Rendell et al., 2018), impose consistency constraints across devices and iterations in
a way similar to the Alternating Direction Method of Multipliers (ADMM) (Angelino et al., 2016).
State-of-the-art results have been obtained via DSGLD (Ahn et al., 2014).
Distributed VI Learning. Considering first one-shot model fusion of local models, Bayesian meth-
ods have been used to deal with parameter invariance and weight matching (Yurochkin et al., 2019;
Claici et al., 2020). Iterative VI such as streaming variational Bias (SVB) (Broderick et al., 2013)
provide a VI-based framework for the exponential family to combine local models into global ones.
PVI provides a general framework that can implement SVB, as well as online VI (Bui et al., 2018)
and has been extended to multi-task learning in Corinzia & Buhmann (2019a).
7	Experiments
As in Liu & Wang (2016), for all our experiments with SVGD and DSVGD, we use the Radial Basis
Function (RBF) kernel k(x, x0) = exp(-||x - x0||22/h). The bandwidth h is adapted to the set of
particles used in each update by setting h = med2/ log n, where med is the median of the pairwise
distances between the particles in the current iterate. The Gaussian kernel K(∙, ∙) used for the KDEs
has a bandwidth equal to 0.55. Unless specified otherwise, we use AdaGrad with momentum to
choose the learning rates and 0 for (U-)DSVGD. Throughout, we fix the temperature parameter
α = 1 in (1). Finally, to ensure a fair comparison with distributed schemes, we run centralized
schemes for the same total number I × L of iterations across all experiments. Additional results
for all experiments can be found in Appendix B in the supplementary materials, which include also
additional implementation details.
Gaussian 1D mixture toy example. We start by considering
a simple one-dimensional mixture model in which the local un-
normalized local posteriors pk (θ) = p0(θ) exp(-α-1Lk(θ)) at
each agent k are defined as pι(θ) = po(θ)N(θ∣1,4) and p2(θ)=
Po(θ)(N(θ∣ - 3,1) + N(θ∣3,2)) and the prior po(θ) is uniform
over [-6, 6], i.e., po(θ) = U(θ∣ - 6, 6). The local posteriors are
shown in Fig. 2 as dashed lines, along with the global posterior
qopt(θ) a Gopt(θ) in (2), which is represented as a shaded area. We
fix the number of particles to N = 200. The approximate poste-
riors obtained from the KDE over the global particles are plotted
in Fig. 2 as solid lines. It can be observed that at each round, the
global posterior updated by DSVGD integrates the local likelihood
1 . DSVGD homogeneous
DSVGD heterogeneous
■ ♦ ■ FedAvg homogeneous
FedAvg heterogeneous
Covertypepataset
Number of rounds i
Figure 5: Log-likelihood for
Bayesian logistic regression
with non-iid data distributions
(N = 6, L = L0 = 200).
of the scheduled agent, while still preserving information about the likelihood of the other agent
from prior iterates, until (approximate) convergence to the true global posterior qopt, which is a nor-
malized version of qGopt in (2), is reached. Finally, in Fig. 3, we plot the KL divergence between
q(θ) and qopt (θ) as a function of the number of rounds. Both U-DSVGD and DSVGD exhibit simi-
lar behaviour, converging to SVGD and outperforming the parametric counterparts PVI and Global
Variational Inference (GVI) (Bui et al., 2018).
Bayesian logistic regression. We now consider Bayesian logistic regression for binary classification
using the same setting as in Gershman et al. (2012). The model parameters θ = [w, log(ξ)] include
the regression weights W ∈ Rd along with the logarithm of a precision parameter ξ. The prior is
given as po(w,ξ) = po(w∣ξ)po(ξ), withpo(w∣ξ) = N(WQ ξ-1Id) andpo(ξ) = Gamma(ξ∣a, b)
with a = 1 and b = 0.01. The local training loss Lk (θ) at each agent k is given as Lk (θ) =
P(Xk yk)∈Dfc l(xk, yk, w), where Dk is the dataset at agent k with covariates Xk ∈ Rd and label
yk ∈ {-1, 1}, and the loss function l(xk, yk, w) is the cross-entropy. Point decisions are taken
based on the maximum of the average predictive distribution. We consider the datasets Covertype
and Twonorm (Gershman et al., 2012). We randomly split the training dataset into partitions of
equal size among the K agents. We also include FedAvg, Stochastic Gradient Langevin Dynam-
ics (SGLD) and DSGLD for comparison. We note that FedAvg is implemented here for consistency
with the other schemes by scheduling a single agent at each step. In Fig. 4, we study how the
accuracy evolves as function of the number of communication rounds i, or number of communica-
tion rounds, across different datasets, using N = 2 and N = 6 particles. We observe that DSVGD
consistently outperforms the mentioned decentralized benchmarks and that, in contrast to FedAvg
and DSGLD, its performance scales well with the number K of agents. Furthermore, the number N
of particles is seen to control the trade-off between the communication load, which increases with
N, and the convergence speed, which improves as N grows larger. Through reduction of the number
8
Under review as a conference paper at ICLR 2021
(SIue6ea
ωωs≡ oraso><
O 2	4	6	8 10 12	16
Numberofrounds
(SIU∂6ea
ωωs≡ oraso><
O 2 4 6 8 10 12 14 16
Numberofrounds
Figure 6:	Average RMSE as a function of the number of communication rounds i for regression
using BNN with a single hidden layer of ReLUs with (left) K = 2 agents and (right) K = 20 agents
(N = 20, L = L0 = 200, 100 hidden neurons for the Year Prediction and 50 for Kin8nm).
MNlST dataset
Fashion MNIST dataset
(Slua6ea
>0s3υυ<
→- DSVGD
■ ♦ ■ FedAvg
→- SVGD
-→- SGLD
→- DSGLD
Numberof rounds i
Fashion MNIST dataset
MNIST dataset
(SIU∂6eS1
>0s30υ<
L ♦ ■ FedAvg
I →- SVGD
/ -→- SGLD
/	-*-	DSGLD
10 1$ 20 2$ 3Q 3S 4C
Numberofroundsi
→- DSVGD
■ ♦ ■ FedAvg
→- SVGD
SGLD
DSGLD
Numberofrounds i
•・・・・
(SlUaeea
Figure 7:	Multi-label classification accuracy using BNN with a single hidden layer of 100 neurons
as function of i, or number of communication rounds, using MNIST and Fashion MNIST with (left)
K = 2 agents and (right) K = 20 agents (N = 20, L = L0 = 200).
of communication rouds, DSVGD can also reduce the overall communication load. For example,
in the third plot in Fig. 4, DSVGD reaches an accuracy of 70% after 5 communication rounds with
N = 6, requiring the exchange of 30 particles. In contrast, FedAvg requires around 100 rounds to
obtain the same accuracy, making the total communication load much higher than that of DSVGD.
To capture heterogeneous datasets with non i.i.d. data, we now consider for different dataset parti-
tions across K = 4 agents. In the homogeneous case, labels are split equally among agents, while,
in the heterogeneous case, each agent stores 40% of one label and 10% of the other. DSVGD is seen
in Fig. 5 to have a robust performance against heterogeneity as compared to FedAvg, whose con-
vergence speed is severely affected. This result hinges on the fact that Bayesian learning provides
a predictive distribution that is a more accurate estimate of the ground-truth posterior distribution.
ThiS is true irrespective of the level of “non-iidness”: Bayesian learning can account in a principled
away for all competing “explanations” provided by different devices. This is in contrast to FedAvg,
whose reliance on a point estimate of the parameters yields an overconfident predictive distribution
that cannot properly account for the diversity of predictions provided by different devices.
Bayesian Neural Networks. We now
consider regression and multi-label clas-
sification with Bayesian Neural Networks
(BNN) models. The experimental setup
is the same as in Hernandez-Lobato &
Adams (2015), with the only exception
that the prior of the weights is set to
Po (W) = N(w|0, λ-1Id) with a fixed pre-
cision λ = e. We plot the average Root
Mean Square Error (RMSE) for K = 2
and K = 20 agents in Fig. 6 for regres-
Figure 8: Reliability plots for classification using BNN
with variable number of hidden neurons using fashion
MNIST (N = 20,1 = 10, L = L0 = 200, K = 20).
sion over the Kin8nm and Year datasets, and accuracy for multi-label classification on the MNIST
and Fashion MNIST datasets in Fig. 7. Confirming the results for logistic regression, DSVGD con-
sistently outperforms the other decentralized benchmarks in terms of RMSE and accuracy, while
being more robust in terms of convergence speed to an increase in the number of agents.
Calibration. Reliability plots are a common visual tool used to quantify and visualize model cal-
ibration (Guo et al., 2017). They report the average sample accuracy as function of the confidence
level of the model. Perfect calibration yields an accuracy equal to the corresponding confidence
(dashed line in Fig. 8). Fig. 8 shows the reliability plots for FedAvg and DSVGD on the Fashion
MNIST dataset for the BNN setting. While increasing the number of hidden neurons negatively
affects FedAvg due to overfitting, DSVGD enjoys excellent calibration even for large models and is
hence able to make trustworthy predictions.
9
Under review as a conference paper at ICLR 2021
References
Sungjin Ahn, Babak Shahbaba, and Max Welling. Distributed Stochastic Gradient MCMC. In
Eric P. Xing and Tony Jebara (eds.), Proceedings of the 31st International Conference on Machine
Learning, volume 32 of Proceedings of Machine Learning Research, pp. 1044-1052, Bejing,
China, 22-24 JUn 2014. PMLR. URL http://Proceedings.mlr.press∕v32∕ahn14.
html.
Pierre Alquier, James Ridgway, and Nicolas Chopin. On the properties of variational approximations
of Gibbs posteriors. Journal of Machine Learning Research, 17(236):1-41, 2016. URL http:
//jmlr.org/papers/v17/15-290.html.
Shun-Ichi Amari. Natural gradient works efficiently in learning. Neural computation, 10(2):251-
276, 1998.
Elaine Angelino, Matthew James Johnson, and Ryan P Adams. Patterns of scalable Bayesian infer-
ence. arXiv preprint arXiv:1602.05221, 2016.
Christopher M. Bishop. Pattern Recognition and Machine Learning (Information Science and Statis-
tics). Springer-Verlag, Berlin, Heidelberg, 2006. ISBN 0387310738.
Tamara Broderick, Nicholas Boyd, Andre Wibisono, Ashia C Wilson, and Michael I Jordan.
Streaming Variational Bayes. In C. J. C. Burges, L. Bottou, M. Welling, Z. Ghahramani,
and K. Q. Weinberger (eds.), Advances in Neural Information Processing Systems 26, pp.
1727-1735. Curran Associates, Inc., 2013. URL http://papers.nips.cc/paper/
4980-streaming-variational-bayes.pdf.
Thang D Bui, Cuong V Nguyen, Siddharth Swaroop, and Richard E Turner. Partitioned Variational
Inference: A unified framework encompassing federated and continual learning. arXiv preprint
arXiv:1811.11206, 2018.
Hong-You Chen and Wei-Lun Chao. FedDistill: Making Bayesian Model Ensemble Applicable to
Federated Learning. 2020.
Sebastian Claici, Mikhail Yurochkin, Soumya Ghosh, and Justin Solomon. Model Fusion with
Kullback-Leibler Divergence. arXiv preprint arXiv:2007.06168, 2020.
Luca Corinzia and Joachim M Buhmann. Variational federated multi-task learning. arXiv preprint
arXiv:1906.06268, 2019a.
Luca Corinzia and Joachim M Buhmann. Variational federated multi-task learning. arXiv preprint
arXiv:1906.06268, 2019b.
Bo Dai, Niao He, Hanjun Dai, and Le Song. Provable Bayesian Inference via Particle Mir-
ror Descent. In Arthur Gretton and Christian C. Robert (eds.), Proceedings of the 19th In-
ternational Conference on Artificial Intelligence and Statistics, volume 51 of Proceedings of
Machine Learning Research, pp. 985-994, Cadiz, Spain, 09-11 May 2016. PMLR. URL
http://proceedings.mlr.press/v51/dai16.html.
Morris H. DeGroot and Stephen E. Fienberg. The Comparison and Evaluation of Forecasters.
Journal of the Royal Statistical Society. Series D (The Statistician), 32(1/2):12-22, 1983. ISSN
00390526, 14679884. URL http://www.jstor.org/stable/2987588.
Samuel J. Gershman, Matthew D. Hoffman, and David M. Blei. Nonparametric Variational Infer-
ence. In Proceedings of the 29th International Coference on International Conference on Machine
Learning, ICML’12, pp. 235-242, Madison, WI, USA, 2012. Omnipress. ISBN 9781450312851.
Chuan Guo, Geoff Pleiss, Yu Sun, and Kilian Q. Weinberger. On Calibration of Modern Neural
Networks. In Proceedings of the 34th International Conference on Machine Learning - Volume
70, ICML’17, pp. 1321-1330. JMLR.org, 2017.
Jose Miguel Hernandez-Lobato and Ryan P. Adams. Probabilistic backpropagation for scalable
learning of bayesian neural networks. In Proceedings ofthe 32nd International Conference on In-
ternational Conference on Machine Learning - Volume 37, ICML’15, pp. 1861-1869. JMLR.org,
2015.
10
Under review as a conference paper at ICLR 2021
Geoffrey Hinton, Oriol Vinyals, and Jeff Dean. Distilling the Knowledge in a Neural Network. arXiv
preprint arXiv:1503.02531, 2015.
Michael I. Jordan, Jason D. Lee, and Yun Yang. Communication-Efficient Distributed Statis-
tical Inference. Journal of the American Statistical Association, 114(526):668-681, 2019.
doi: 10.1080/01621459.2018.1429274. URL https://doi.org/10.1080/01621459.
2018.1429274.
Laurent Valentin Jospin, Wray Buntine, Farid Boussaid, Hamid Laga, and Mohammed Bennamoun.
Hands-on Bayesian Neural Networks-a Tutorial for Deep Learning Users. arXiv preprint
arXiv:2007.06823, 2020.
Peter Kairouz, H Brendan McMahan, Brendan Avent, AUreIien Bellet, Mehdi Bennis, Arjun Nitin
Bhagoji, Keith Bonawitz, Zachary Charles, Graham Cormode, Rachel Cummings, et al. Advances
and open problems in federated learning. arXiv preprint arXiv:1912.04977, 2019.
Jeremias Knoblauch, Jack Jewson, and Theodoros Damoulas. Generalized variational inference.
stat, 1050:21, 2019.
Anna Korba, Adil Salim, Michael Arbel, Giulia Luise, and Arthur Gretton. A Non-Asymptotic
Analysis for Stein Variational Gradient Descent. arXiv preprint arXiv:2006.09797, 2020.
Tian Li, Anit Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet Talwalkar, and Virginia Smith.
Federated Optimization in Heterogeneous Networks. arXiv preprint arXiv:1812.06127, 2018.
Frank Po-Chen Lin, Christopher G Brinton, and Nicolo Michelusi. Federated Learning with Com-
munication Delay in Edge Networks. arXiv preprint arXiv:2008.09323, 2020.
Qiang Liu. Stein Variational Gradient Descent as Gradient Flow. In I. Guyon,
U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Gar-
nett (eds.), Advances in Neural Information Processing Systems, pp. 3115-3123.
Curran Associates, Inc., 2017a. URL http://papers.nips.cc/paper/
6904-stein-variational-gradient-descent-as-gradient-flow.pdf.
Qiang Liu. Stein Variational Gradient Descent as Gradient Flow. In Advances in Neural Informa-
tion Processing Systems, pp. 3115-3123. 2017b. URL http://papers.nips.cc/paper/
6904-stein-variational-gradient-descent-as-gradient-flow.pdf.
Qiang Liu and Alexander Ihler. Distributed Estimation, Information Loss and Exponential Families.
In Proceedings of the 27th International Conference on Neural Information Processing Systems -
Volume 1, NIPS’14, pp. 1098-1106, Cambridge, MA, USA, 2014. MIT Press.
Qiang Liu and Dilin Wang. Stein variational gradient descent: A general purpose bayesian inference
algorithm. In Advances in neural information processing systems, pp. 2378-2386, 2016.
Qiang Liu, Jason Lee, and Michael Jordan. A kernelized Stein discrepancy for goodness-of-fit tests.
In International conference on machine learning, pp. 276-284, 2016.
David J. C. MacKay. Information Theory, Inference & Learning Algorithms. Cambridge University
Press, USA, 2002. ISBN 0521642981.
Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise AgUera y Arcas.
Communication-Efficient Learning of Deep Networks from Decentralized Data. In Proceed-
ings of the 20th International Conference on Artificial Intelligence and Statistics, AISTATS 2017,
20-22 April 2017, Fort Lauderdale, FL, USA, volume 54 of Proceedings of Machine Learning
Research, pp. 1273-1282. PMLR, 2017. URL http://proceedings.mlr.press/v54/
mcmahan17a.html.
Diego Mesquita, Paul Blomstedt, and Samuel Kaski. Embarrassingly Parallel MCMC using Deep
Invertible Transformations. volume 115 of Proceedings of Machine Learning Research, pp. 1244-
1252, Tel Aviv, Israel, 22-25 Jul 2020. PMLR. URL http://proceedings.mlr.press/
v115/mesquita20a.html.
11
Under review as a conference paper at ICLR 2021
S. Mika, G. Ratsch, J. Weston, B. Scholkopf, and K. R. Mullers. Fisher discriminant analysis with
kernels. In Neural Networks for Signal Processing IX: Proceedings of the 1999 IEEE Signal
Processing Society Workshop (Cat. No.98TH8468), pp. 41-48,1999.
John Mitros and Brian Mac Namee. On the Validity of Bayesian Neural Networks for Uncertainty
Estimation. arXiv preprint arXiv:1912.01530, 2019.
Radford M Neal. Bayesian learning for neural networks, volume 118. Springer Science & Business
Media, 2012.
Willie Neiswanger, Chong Wang, and Eric Xing. Embarrassingly parallel variational inference in
nonconjugate models. arXiv preprint arXiv:1510.04163, 2015.
Hung T Nguyen, Vikash Sehwag, Seyyedali Hosseinalipour, Christopher G Brinton, Mung Chiang,
and H Vincent Poor. Fast-Convergent Federated Learning. arXiv preprint arXiv:2007.13137,
2020.
Alexandru Niculescu-Mizil and Rich Caruana. Predicting Good Probabilities with Supervised
Learning. In Proceedings of the 22nd International Conference on Machine Learning, ICML
’05, pp. 625-632, New York, NY, USA, 2005. Association for Computing Machinery. ISBN
1595931805. doi: 10.1145/1102351.1102430. URL https://doi.org/10.1145/
1102351.1102430.
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor
Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas Kopf, Edward
Yang, Zachary DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner,
Lu Fang, Junjie Bai, and Soumith Chintala. PyTorch: An Imperative Style, High-Performance
Deep Learning Library. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d Alche-Buc,
E. Fox, and R. Garnett (eds.), Advances in Neural Information Processing Systems 32,
pp. 8026-8037. Curran Associates, Inc., 2019. URL http://papers.nips.cc/paper/
9015-pytorch-an-imperative-style-high-performance-deep-learning-library.
pdf.
Reese Pathak and Martin J Wainwright. FedSplit: An algorithmic framework for fast federated
optimization. arXiv preprint arXiv:2005.05238, 2020.
Thomas Pinder, Christopher Nemeth, and David Leslier. Stein Variational Gaussian Processes. arXiv
preprint arXiv:2009.12141, 2020.
Mark S Pinsker. Information and information stability of random variables and processes. Holden-
Day, 1964.
Lewis J Rendell, Adam M Johansen, Anthony Lee, and Nick Whiteley. Global consensus Monte
Carlo. arXiv preprint arXiv:1807.09288, 2018.
M. Sato. Online Model Selection Based on the Variational Bayes. Neural Computation, 13(7):
1649-1681, 2001.
Steven L. Scott, Alexander W. Blocker, Fernando V. Bonassi, Hugh A. Chipman, Edward I.
George, and Robert E. McCulloch. Bayes and Big Data: The Consensus Monte Carlo Algo-
rithm. International Journal of Management Science and Engineering Management, 11:78-
88, 2016. URL http://www.tandfonline.com/doi/full/10.1080/17509653.
2016.1142191.
Aki Vehtari, Andrew Gelman, Tuomas Sivula, Pasi Jylanki, Dustin Tran, Swupnil Sahai, Paul Blom-
stedt, John P. Cunningham, David Schiminovich, and Christian P. Robert. Expectation Propaga-
tion as a Way of Life: A Framework for Bayesian Inference on Partitioned Data. Journal of
Machine Learning Research, 21(17):1-53, 2020. URL http://jmlr.org/papers/v21/
18-817.html.
Jianyu Wang, Qinghua Liu, Hao Liang, Gauri Joshi, and H Vincent Poor. Tackling the
Objective Inconsistency Problem in Heterogeneous Federated Optimization. arXiv preprint
arXiv:2007.07481, 2020.
12
Under review as a conference paper at ICLR 2021
Xiangyu Wang and David B. Dunson. Parallel MCMC via Weierstrass Sampler.	ArXiv,
abs/1312.4605, 2013.
Zheng Wei and Erin M Conlon. Parallel Markov chain Monte Carlo for Bayesian hierarchical models
with big data, in two stages. Journal of Applied Statistics, 46(11):1917-1936, 2019.
Max Welling and Yee Whye Teh. Bayesian Learning via Stochastic Gradient Langevin Dynamics.
In Proceedings of the 28th International Conference on International Conference on Machine
Learning, ICML’11, pp. 681-688, Madison, WI, USA, 2011. Omnipress. ISBN 9781450306195.
Jaesik Yoon, Taesup Kim, Ousmane Dia, Sungwoong Kim, Yoshua Bengio, and Sungjin Ahn.
Bayesian Model-Agnostic Meta-Learning. In S. Bengio, H. Wallach, H. Larochelle, K. Grauman,
N. Cesa-Bianchi, and R. Garnett (eds.), Advances in Neural Information Processing Systems 31,
pp. 7332-7342. Curran Associates, Inc., 2018. URL http://papers.nips.cc/paper/
7963-bayesian-model-agnostic-meta-learning.pdf.
Mikhail Yurochkin, Mayank Agarwal, Soumya Ghosh, Kristjan Greenewald, Nghia Hoang, and
Yasaman Khazaeni. Bayesian Nonparametric Federated Learning of Neural Networks. In Kama-
lika Chaudhuri and Ruslan Salakhutdinov (eds.), Proceedings of the 36th International Confer-
ence on Machine Learning, volume 97 of Proceedings of Machine Learning Research, pp. 7252-
7261, Long Beach, California, USA, 09-15 Jun 2019. PMLR. URL http://proceedings.
mlr.press/v97/yurochkin19a.html.
Tong Zhang. Information-theoretic upper and lower bounds for statistical estimation. IEEE Trans-
actions on Information Theory, 52(4):1307-1321, 2006.
Xinwei Zhang, Mingyi Hong, Sairaj Dhople, Wotao Yin, and Yang Liu. FedPD: A Federated
Learning Framework with Optimal Rates and Adaptivity to Non-IID Data. arXiv preprint
arXiv:2005.11418, 2020.
Ding-Xuan Zhou. Derivative reproducing properties for kernel methods in learning theory. Journal
of computational and Applied Mathematics, 220(1-2):456-463, 2008.
Jingwei Zhuo, Chang Liu, Jiaxin Shi, Jun Zhu, Ning Chen, and Bo Zhang. Message Passing Stein
Variational Gradient Descent. In International Conference on Machine Learning, pp. 6018-6027.
PMLR, 2018.
13
Under review as a conference paper at ICLR 2021
A Complementary Materials
A. 1 Algorithmic Tables
1
2
3
4
5
6
7
8
1
2
3
4
5
6
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
Algorithm 2: Partitioned Variational Inference (PVI)(BUi et al., 2018)
Input: prior p0(θ), local loss function {Lk(θ)}kK=1, temperature α > 0
Output: global posterior q(θ∣η)
initialize t(k0) (θ) = 1 for k = 1, . . . , K; q(0) (θ) = p0 (θ)
for i = 1, . . . , I do
At schedUled agent k, download cUrrent global parameters η(i-1) from server
Agent k solves local free energy problem in (4) to obtain new global parameters η(i)
Agent k sends η(i) to the server and server sets η J η(i)
Agent k updates new approximate likelihood: tk(θ∣ηki)) = §黑4-1)))tk(θ∣ηki-1))
end
return q(θ) = q(θ∣η(I))
Algorithm 3: Stein Variational Gradient Descent (SVGD)(LiU & Wang, 2016)
Input: target distribution p(θ), initial particles {夕£)}NN=ι 〜po(θ), kernel k(∙, ∙), learning rate e
Output: particles {θn }nN=1 that approximates the target normalized distribution
for i = 1, . . . , L do
for n = 1, . . . , N do
I θni J θ(ii-1) + NpN=1 [k(θji-ι),θni-ι))Vθj logMf)+jjk(θ("。&-1))].
end
end
return q(θ) = PnN=1 K(θ, θn(L))
Algorithm 4: Unconstrained-Distributed Stein Variational Gradient Descent (U-DSVGD)
Input: prior p0(θ), local loss function {Lk(θ)}kK=1, temperature α > 0, learning rate > 0, kernels
K(∙, ∙) and k(∙, ∙)
Output: global posterior q(θ) = PnN=1 K(θ, θn )
initialize tk0)(θ) = 1 for k = 1,..., K; q(0)(θ) = po(θ); {θη0)}N=ι i" po(θ)
for i = 1, . . . , I do
// New communication round: server schedules an agent k
At scheduled agent k, download and memorize in local buffer current global particles {θn(i-1) }nN=1
Agent k sets {θn[0] = θn(i-1) }nN=1
for l = 1, . . . , L do
// Local iterations: agent k minimizes local free energy
Compute V以 = V log 勺他川眺-1]) - V logt广0现-1]) - ɪVeLk眺-1]) WithKDE
q(i-1)(θ) = PnN=1 K(θ, θn(i-1)) and Vθ log t(ki-1)(θ) computed using (15)
for particle n = 1, ..., N do
∆θn J N PN=1 [k(θ 尸],θn-1])veιj+Vθjk(θ 尸Mn-1])]
θ[l] J θ[nτ] + e∆θn
end
end
Agent k sets updated global particles {θn(i) = θn[L] }nN=1 and memorize them in the local buffer
Agent k sends particles {θn(i) }nN=1 to the server and server sets {θn = θn(i) }nN=1
end
return q(θ) = PnN=1 K(θ, θn(I))
14
Under review as a conference paper at ICLR 2021
1
2
3
4
5
6
7
8
9
10
Algorithm 5: Parallel-Distributed Stein Variational Gradient Descent (P-DSVGD)
Input: prior po(θ), local loss functions {Lk(θ)}K=ι, temperature α > 0, kernels K(∙, ∙) and k(∙, ∙)
Output: global approximate posterior q(θ) = N -1 PnN=1 K(θ, φn)
initialize q(0)(θ) = po(θ); {θn0)}N=ι i削po(θ); {。却=。黑=θn0)}N=ι and t(0(θ) = 1 for
k = 1, . . . ,K
for i = 1, . . . , I do
Server schedules a set K(i) of agents in parallel
Agents downloads current server particles {φ(ni-1) }nN=1 from server
Agents obtains updated global particles {θn(i) }nN=1 using (13), {θn(i-1) =φ(ni-1)}nN=1
and
{θk(i,-n1)}nN=1
Agents carries distillation to obtain {θk(i,)n }nN=1 encoding t(ki) (θ) using (17) and {θn(i) }nN=1
Agents sends the obtained local particles {θk(i,)n}nN=1 for k ∈ K(i) to the server
Server obtains {φ(ni)}nN=1 using (29), {φ(ni-1)}nN=1 and {θk(i,)n}nN=1 for k ∈ K(i)
end
return q(θ) = N-1 PnN=1 K(θ, φ(nI))
15
Under review as a conference paper at ICLR 2021
A.2 A Relationship Between PVI and U-DSVGD
We show here that PVI with a Gaussian variational posterior q(θ∣η) = N(θ∣λ2η, λ2Id) of fixed
covariance λ2Id and mean λ2η parametrized by natural parameter η can be recovered as a special
case of U-DSVGD. To elaborate, consider U-DSVGD with one particle θ1 (i.e., N = 1), an RKHS
kernel that satisfies Vθk(θ, θ) = 0 and k(θ, θ) = 1 (the RBF kernel is an example of such kernel)
and an isotropic Gaussian kernel K(θ, θ(i)) = N(θ∣θ(i), λ2Id) of bandwidth λ used for computing
the KDE of the global posterior using the particles. The U-DSVGD particles update in (13) reduces
to the following single particle update:
θ1 一 θ1l-1] + eVθ log Pki)Ml-1]), for l = 1,..., L,	(18)
with tilted distribution
Pki)(θ) (X qi-^exP ( - 1 Lk(B .	(19)
tk	(θ)
The numerator in (19) can be rewritten as q(i-1)(θ) = K(θ, θ(i-1)) = q(θ∣η(i-1)) with η(i-1) =
λ-2θ1(i-1), while the denominator can be rewritten as
tki-1)(θ)=	Y	Iθj⅜= tk(θ∣ηki-1)),	(20)
j∈Ik(i-1)
with ηk(i-1)
Pj∈I(i-1) η(j) - η(j-1). This recovers the PVI update (6).
A.3 Reliability Plots
In this part we give some background on reliability plots and Maximum Calibration Error (MCE).
Reliability plots are a visual tool to evaluate model calibration (DeGroot & Fienberg, 1983;
Niculescu-Mizil & Caruana, 2005). Consider a model that outputs a prediction y(xi) and a proba-
bility P(Xi) of correct detection for an input Xi with true label y》We divide the test samples into
bins {Bj}jB=1, each bin Bj containing all indices of samples whose prediction confidence falls into
the interval (j-1, j] where B is the total number of bins. Reliability plots evaluate the accuracy as
function of the confidence which are defined respectively as
acc(Bj)
and conf (Bj)
两 £ 1{y(χi)=yi}
jXP(Xj
Perfect calibration means that the accuracy is equal to the confidence across all bins. For example,
given 100 predictions, each with confidence approximately 0.7, one should expect that around 70%
of these predictions be correctly classified.
To computep(χ), we need the predictive probability p(yt∣xt) for all samples t ∈ [1; T]. This can be
obtained by marginalizing the data likelihood with respect to the weights vector w. This marginal-
ization is generally intractable but can be approximated for both Bayesian logistic regression and
Bayesian Neural Networks as detailed in Sec. A.3.1 and Sec. A.3.2.
While reliability plots are a useful tool to visually represent the calibration of a model, it is often
desirable to have a single scalar measure of miscalibration. In this paper, we use the MCE that
measures the worst case deviation of the model calibration from perfect calibration (Guo et al.,
2017). Mathematically, the MCE is defined as
MCE = max |acc(Bj) - conf (Bj)|.	(21)
j∈{1,...,B}
Additional numerical results using both reliability plots and MCE can be found in Sec. B.5.
16
Under review as a conference paper at ICLR 2021
A.3.1 Predictive Distribution for Bayesian Logistic Regression with SVGD
and DSVGD
In this section, we show how the predictive distribution for the Bayesian logistic regression ex-
periment can be obtained when using DSVGD or SVGD. The predictive distribution provides
the confidence values to be used in the calibration experiment. Given a KDE of the posterior
q(w) = PnN=1 k(w, wn) with N particles {wn}nN=1 the predictive probability for Bayesian lo-
gistic regression can be estimated as
/	1∣、〜/，	1∣ ʌ / x∏ e 1 e exp( 2-12 ||wn - w||2).
p(yt = 11Xt) ≈ J p(yt = 1lxt,W)q(W)dw = Σ N(2λ2∏)d∕2 J	ι+eχp(-wχT) dw.
(22)
A good approximation of (22) can be obtained by replacing the logistic sigmoid function with the
probit function (Bishop, 2006, Sec. 4.5), yielding
N1	1
p(yt = 1lXt) ≈ 之 N 1 + exp(-κ(σ2)μn),	(23)
where
μn = WnXT,
21T
σ =定 XtXt，	(24)
-1∕2
and κ(σ2) = ( 1 + σ2∏
A.3.2 Predictive Distribution for Bayesian Neural Networks with SVGD and
DSVGD
In a manner similar to (22), the predictive distribution for BNN can be estimated as
p(yt
1|Xt) ≈ XX N(2λ2∏)S Z f (Xt，w)exp ( Twnλ2 W bW，
(25)
where f(Xt, W) is the sigmoid output of the BNN with weights W. Using the first order Taylor
approximation of the network output around the n-th particle (Bishop, 2006, Sec. 5.7.1)
f (Xt, w) ≈ f (Xt, Wn) + Vw f(Xt, w)(w - Wn),	(26)
the predictive distribution can now be rewritten as
p(yt = 1|Xt) ≈ X N(2λ2π)d∕2 /[f (Xt, wn) + Vwf (Xt, W)(W — wn)]eχp (	"w；；- W|| )dw
N1	N1
=E Nf(Xt, Wn) + £ N (Vwf (Xt, W)Wn- Vwf (Xt, W)Wn)
n=1	n=1
N1
=E Nf(Xt, Wn ),
n=1
(27)
where we have used the fact that N(W|Wn, λ2Id)dW = 1 and WN (W|Wn, λ2Id)dW = Wn.
A.4 Space-Time Complexity, Communication Load and Convergence
This section offers a brief discussion on the complexity, communication load and convergence of
DSVGD.
Space Complexity. DSVGD inherits the space complexity of SVGD. In particular, DSVGD re-
quires the computation of the kernel matrix k(∙, ∙) between all particles at each local iteration, which
17
Under review as a conference paper at ICLR 2021
can then be deleted before the next iteration. This requires O(N 2) space complexity. As pointed out
by Liu & Wang (2016) and noticed in our experiments, for sufficiently small problems of practical
interest for mobile embedded applications, few particles are enough to obtain state-of-the art per-
formance. Furthermore, N particles of dimension d need to be saved in the local buffer, requiring
O(N d) space. Given that N is generally much lower than the number of data samples, saving the
particles in the local buffer shouldn’t be problematic.
Time complexity. When scheduled, an agent has to perform O(max(L, L0)N2) operations with
O(LN 2) operations for the first loop (lines 5-11) and O(L0N2) operations for the second loop
(lines 15-21) in Algorithm 1. Furthermore, the L0 distillation iterations in the second loop can be
performed by the scheduled agent after it has sent its global particles to the central server. This
enables the pipelining of the second loop with the operations at the server and at other agents, which
can potentially reduce the wall-clock time per communication round.
Communication load. Using DSVGD, the communication load between a scheduled agent and the
central server is of the order O(Nd) since N particles of dimensions d need to be exchanged at
each communication round. In contrast, the communication load of PVI depends on the selected
parametrization. For instance, one can use PVI with a fully factorized Gaussian approximate poste-
rior, which requires only 2d parameters to be shared with the server, namely mean and variance of
each of the d parameters at the price of having lower accuracy.
Convergence. The two local SVGD loops produce a set of global and local particles, respectively,
that are convergent to their respective targets as the number N of particles increases (Liu, 2017a).
Furthermore, as discussed, a fixed point of the set of local free energy minimization problems is
guaranteed to be a local optimum for the global free energy problem (see Property 3 in Bui et al.
(2018)). This property hence carries over to DSVGD in the limit of large number of particles. How-
ever, convergence to a fixed point is an open question for PVI, and consequently also for DSVGD.
A.5 Parallel-DSVGD
In this section, we present a direct extension of DSVGD in which multiple agents can be scheduled
in parallel during the same communication round. In Parallel-DSVGD (P-DSVGD), each agent in
the set K(i) of scheduled agents at round i applies the same steps as in DSVGD except that it shares
the local particles {θk(i,)n}nN=1 with the server instead of the global ones. Then, the server distills the
received local particles into a set of N server-side particles {φ(ni) }nN=1 using SVGD to obtain the
next iterate of the global posterior.
As discussed in Sec. 3, a parallel implementation requires the i-th iterate of the global posterior to
be obtained as
q(i) (θ) = p0(θ) Y t(ki) (θ) Y t(ki0) (θ),
(28)
k∈K(i)	k0 6∈K(i)
where t(ki0) (θ) = t(ki0-1) (θ) for k0 6∈ K(i). To replicate this same behaviour while preserving the
non-parametric property of DSVGD, in P-DSVGD, each agent k ∈ K(i) shares its local particles
{θk(i,)n}nN=1 representing the approximate likelihood where t(ki) (θ) = N-1 PnN K(θ, θk(i,)n). Then, to
approximate q(i) (θ) in (28), using SVGD, the server carries out Ls SVGD updates as
N
on] 一 Φn-1]+N χ[k(φ尸,on-1。ye, log q(i)(。尸/¢, k(φ尸,φn-1])],for 1=1,... %
N j=1
(29)
For the (i+1)-th communication round, scheduled agents K(i+1) download particles {o(ni+1)}nN=1 =
{o[nLs]}nN=1 that are treated in a similar fashion as in DSVGD. The full algorithmic table for Parallel-
Distributed Stein Variational Gradient Descent (P-DSVGD) is provided in Algorithm 5. Numerical
results for P-DSVGD are provided in Sec. B.3 of the Appendix.
18
Under review as a conference paper at ICLR 2021
A.6 Proofs
In this section, we prove Theorem 1 and 2.
Theorem 1. The global posterior qopt(θ) in (2) is the unique fixed point of the DVI algorithm.
Proof. Consider the general implementation of DVI, were a setK of agents are scheduled in parallel.
DVI is equivalent to the following functional mapping
-Qi∈κti(θ)]	[	Qi∈κ ti(θ)	^
_{tk⑹}kEK_	{tk⑹=1 exp ( - 1 Lk ⑹)Ok∈κ
K
q(θ) = p0(θ) Y ti(θ)	q0(θ) = p0(θ) Y ti(θ) Yt0k(θ)
i=1	i6∈K k∈K
whereZ=Rp0(θ)Qi6∈Kti(θ)Qk∈Kt0k(θ)dθ.
Therefore, assuming that all devices k are periodically scheduled, q(θ) is a fixed point of DVI if and
only if the following equality holds
tk (θ) = t0k (θ) for k = 1, . . . , K.
This condition is satisfied by q(θ) = qopt(θ) and by no other distribution. This concludes the
proof.	□
We move now to Theorem 2 for U-DSVGD. We leave the analysis of the impact of the additional
distillation step used by DSVGD for future work. The analysis builds on the following result from
Korba et al. (2020), which is restated here using our notation.
Denote by || ∙ ||h the norm in the RKHS H defined by the positive definite kernel k(θ,θ0). We
assume that the kernel satisfies the following technical condition: there exist a constant B > 0 such
that
∣∣k(θ,•川 H ≤ B and £||* IH ≤ B2∙	(3。)
This condition is for instance satisfied by the RBF kernel with B = 1 (Zhou, 2008). Furthermore,
we define the kernelized Stein discrepancy (Liu et al., 2016) between two distributions p and q as
S(p, q), and the total variation distance as ||q - p||TV =2 /|q⑹-p(θ)ldθ.
Lemma 1. (Guaranteed per-iteration decrease of the local free energy.) (Korba et al., 2020) For
a kernel satisfying (30), assume that, at a given communication round i and local iteration l, with
agent k scheduled, we have:
• the maximum absolute eigenvalue of the Hessian -V2 logp? (θ) is upper bounded by a
constant M > 0; and
• the inequality S(q[l] (θ),pki)) < C holds for some C > 0.
For learning rate e ≤ (β 一 1)∕(βBC2) with any β > 1, the decrease in the local KL divergence
from local iteration l to l + 1 satisfies the inequality
F(q[l+1](θ)) — F(q[l](θ)) ≤ -αeS(q[l],pki))(1 - eγ),	(31)
where γ = ((β2 + M)B2)/2.
Lemma 1 shows that by choosing a learning rate e ≤ min(γ-1, (β — 1)∕(βBC2), one can guarantee
a per-iteration decrease in the local-free energy, i.e., in the KL divergence between the particles’
distribution and the target tilted distribution Pki) (θ) that depends on the kernelized Stein discrepancy
S(q[l], Pki)) at the iteration before the update.
19
Under review as a conference paper at ICLR 2021
Lemma 2. (Relationship between global and local free energy.) The global free energy F (q(θ)) in
(1) is related to the local free energy Fk(i) (q(θ)) in (4) of the k-th scheduled agent as
F …Fki)(q(θ))+α Xk Eq ⑻ log (expm⅛).
(32)
Proof. The global free energy (1) can be written as
F(q(θ)) = αEq(θ) log (P0(θ)exp(-q(PK= Lm(θ)))
q(i-1)(θ)
_ F 1	( q(θ)	___________tki-1)(θ)_______∖
一°q(θ)°g (pki)(θ) P0 ⑹eχp(TPK=k LK⑹J	(33)
W 1	(q(θ)Jw 1 p pο(θ) Qm=k tK-1)(θ)	∖
=α%θ) log lp⅛Γ αEq⑻ log (p0(θ)eχp(-1 pκ=k Lκ(θ)))
=F"+" Xk Eq⑻ log ( exp(-⅛K)(θ))),
where in the second equality we have used (11); and in the third equality we have used the equality
q(i-D(θ) = pο(θ) QK=I tK-1)(θ), which is guaranteed by the U-DSVGD update (10) and (11)
(See BUi et al. (2018, Property 2)).	□
Theorem 2 (Guaranteed per-iteration decrease of the global free energy.). The decrease in the global
free energy from local iteration l to l + 1 during communication round i for which agent k is sched-
uled can be lower bounded as
F(q[l](θ)) - F(q[l+1](θ)) ≥ αeS(q[l],pki))(1 - eγ) - 2α(K - 1)偏乂，2口M+叫心),	(16)
where 优；X = sup max| log(tKT)(θ)) ∙ exp(1 Lκ(θ))∣, S(q,p) denotes the Kernalized Stein Dis-
θ K6=k	α
crepancy between distributions q and p (Liu et al., 2016), and γ is a constant depending on the
RKHS kernel and the target distribution.
WeknoWfromLemma 1 that a learning rate E ≤ min(γ-1, (β - 1)∕(βBC2) is sufficient to ensure
a per-iteration decrease in the local free energy. Given that the KL divergence in the second term in
(16) generally increases with E, 2 demonstrates that, in order to guarantee a reduction of the global
free energy, a smaller learning rate may be required. We also note that the KL divergence term
D(q[l+1] ||q[l]) may be explicitly related to the learning rate by following Pinder et al. (2020, Sec. 8),
but we do not further pursue this aspect here. We finally remark that, in the presence ofK = 1 agent,
the upper bound (31) in (Korba et al., 2020) is recovered. This is because, in the presence of one
agent, the global free energy reduces to the local free energy (see (32)) and accordingly U-DSVGD
reduces to SVGD.
Proof. We wish to obtain an upper bound on the decrease of the global free energy F (q [l+1] (θ)) -
F(q[l] (θ)) across each local SVGD iteration during communication round i. Using (32), the decrease
in the global free energy can be written as
F(q[l+1](θ))-F(q[l](θ)) = Fk(i)(q[l+1](θ)) - Fk(i)(q[l](θ))
X{}
(a)
+αXk Ri®) log (exp! 1LKU - Eq[l]⑺ log (exp'll[U'].
^^^^^S^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
(b)
(34)
We now derive upper bounds for (a) and (b). Using Lemma 1 and the definition of the local free
energy in (4), we have the following upper bound on (a)
(a)	= Fki)(q[l+1](θ)) - Fki)(q[l](θ)) ≤ -αeS(q[l](θ),Pki))(1 - eγ),	(35)
20
Under review as a conference paper at ICLR 2021
while (b) can be rewritten and upper bounded by using the properties of the total variation distance
as
(b)= ((q[l+1](θ)-q[l](θ))lθg ( 点 :⑹	)dθ ≤ 2imaχ∣∣q[l+1] -q[l]∣∣τv.	(36)
J	∖exP(- 1 Lm(O))/
Using Pinsker’s inequality (Pinsker, 1964), the term (b) can be further upper bounded as
(b)	≤ 2imaχq2D(q[l+ι]∣∣q[l]).	(37)
Accordingly, the global energy dissipation in (34) can be upper bounded as in (16).	□
21
Under review as a conference paper at ICLR 2021
B Additional Experiments
An overview of the benchmarks considered in the experiments is provided in Table 1.
Table 1: Overview of benchmarks used in the experiments.
Algorithm	Non-parametric	Decentralized	Inference
Stein Variational Gradient Descent (SVGD)(LiU & Wang, 2016)	Yes	No	VI
Stochastic Gradient Langevin Dynamics (SGLD) (Welling & Teh, 2011)	Yes	No	MC
Distributed Stochastic Gradient Langevin Dynamics (DSGLD) (Ahn et al., 2014)	Yes	Yes	MC
Particle Mirror Descent (PMD) (Dai et al., 2016)	Yes	No	VI
Partitioned Variational Inference (PVI) (Bui et al., 2018)	No	Yes	VI
Global Variational Inference (GVI) (Sato, 2001)	No	No	VI
Non-Parametric Variational Infernce (NPV) (Gershman et al., 2012)	No	No	VI
Federated Averaging (FedAvg) (McMahan et al., 2017)	No	Yes	Freq.
Federated Stochastic Gradient Descent (FedSGD) (McMahan et al., 2017)	No	Yes	Freq.
Distributed Stein Variational Gradient Descent (DSVGD) (ours)	Yes	Yes	VI
T
B.1	1-D Mixture of Gaussians Toy Example
U0)(υ∕v4(υq gu0)s5(υ≥p -I*
Number of rounds i
必COE×QJddcoPUE JO-KJSOd
U0)(υ∕v4(υq gu0)s5(υ≥p -I*
-φ- U-DSVGD
→t- DSVGD
PVI
GVI
→- SVGD
rrι~E
10	20	30	40	50	60
Local iteration number L
(a)	(b)
Figure 9:	KL divergence between exact and approximate global posteriors (a) as function of the
number of communication rounds i for L = L0 = 200; and (b) as function of the local iterations
number L for I = 5.
This section is complementary to the 1-D mixture of Gaussians experiment in Sec. 7 of the main text.
We compare DSVGD with PVI and the counterpart centralized schemes. In Fig. 9(a), we plot the
KL divergence between the global posterior qopt(θ) and its current approximation q(θ) as a function
of the number of communication rounds i, which corresponds to the number of communication
rounds for decentralized schemes. We use N = 200 particles for U-DSVGD and DSVGD with L =
L0 = 200 local iterations. The number of SVGD iterations is fixed to 800. A Gaussian prior p0(θ) =
N(θ∣0,1) is assumed in lieu of the uniform prior considered in Fig. 2 to facilitate the implementation
of PVI and conventional centralized GVI which was done following Bui et al. (2018, Property 4).
More specifically, We use Gaussian approximate likelihoods, i.e., tk(θ∣η) = N(θ∣-n1, -1) with
natural parameters η1 and η2 < 0. We observe that DSVGD has similar convergence speed as
PVI, while having a superior performance thanks to the reduced bias of non-parametric models.
Furthermore, DSVGD exhibits the same performance as U-DSVGD with the advantage of having
memory requirements that do not scale with the number of iterations. Finally, both U-DSVGD and
DSVGD converge to the performance of (centralized) SVGD as the number of rounds increases.
In Fig. 9(b), we plot the same KL divergence as function of the number of local iterations L. We
use I = 5 rounds for the decentralized schemes. It is observed that non-parametric schemes-namely
SVGD and (U-)DSVGD-require a sufficiently large number of local iterations in order to outperform
the parametric strategies PVI and GVI.
22
Under review as a conference paper at ICLR 2021
(a)
(b)
(c)
(d)
Figure 10:	Performance comparison of (a) GVI, (b) PVI, (c) SVGD and (d) DSVGD for a multi-
variate Gaussian mixture model. Solid contour lines correspond to the approximate posterior while
dashed contour lines to the exact posterior (N = 200, I = 5, L = 200 and b = 0.1).
B.2	2-D Mixture of Gaussians Toy Example
We now consider the following 2-D mixture of Gaussians model:	p1 (θ)
N(μo, ∑0)(N(μ1, ∑ι) + N(μ2, ∑2)) andP2(θ)= N(μ0, ∑0)N(μ3, ∑3) where
μo =	[0,0]; Σ0=	4 2	2 4	
μι =	[-1.71, -1.80	1];	Σ	1=
μ2 =	[1,0]; Σ2=	2 0.5		0.5 2
μ3 =	[1,0]; Σ3=	3 0.5		0.5 3
0.226	0.1652
0.1652 0.6779
We plot in Fig. 10 the approximate posterior q(θ) (blue solid contour lines) and the exact posterior
qopt(θ) (red dashed contour lines) for PVI, GVI, SVGD and DSVGD. We see that, as in the 1-D case
and in contrast to parametric methods PVI and GVI, non-parametric methods SVGD and DSVGD
are able to capture the different modes of the posterior, obtaining lower values for the KL divergence
between the approximate and exact posterior.
B.3	Bayesian Logistic Regression
This section provides additional results for the Bayesian logistic regression experiment in Sec. 7 of
the main text. In Fig. 11, we compare the performance of DSVGD (bottom row), and U-DSVGD
(top row) both with SVGD and NPV (Gershman et al., 2012) using the model described in Sec. 7.
We use 9 binary classification datasets summarized in Appendix C as used in Liu & Wang (2016)
and Gershman et al. (2012). We assumed N = 100 particles. To ensure fairness, we used L = 800
iterations for SVGD, while U-DSVGD and DSVGD are executed with two agents with half of the
dataset split randomly at each agent. We set I = 4 rounds and L = L0 = 200 local iterations. In
Fig. 11, we plot the accuracy and the log-likelihood of the four algorithms. We observe that both
U-DSVGD and DSVGD perform similarly to SVGD and NPV over most datasets, while allowing a
23
Under review as a conference paper at ICLR 2021
0.5	0.6	0.7	0.8	0.9	1.0
U-DSVGD accuracy
-1.0-
-1.0	-0.8	-0.6	-0.4	-0.2
U-DSVGD Iog-Iikelihood
ASEJnSE Qe>ω
-0.5
0.6	0.7	0.8	0.9	1.0
DSVGD accuracy
>0E30ro >∩-z
PoOIl=$_I6O 一 Q0>ω
-1.0-
-1.0	-0.8	-0∙β	-0.4	-0.2
DSVGD Iog-Iikelihood
、£'ll是 >dN
Figure 11: Binary classification with Bayesian logistic regression results using the setting in Ger-
shman et al. (2012): accuracy and log-likelihood for U-DSVGD (upper row) and DSVGD (bottom
row), along with NPV and SVGD, for various datasets.
Aoai no。V
4	8	16	32	64
Number of particles N
(a)
-"DSVGD (J= 3)
■ ■ ■ DSVGD (J= 6)
0.60
AoeJn0。V
T- DSVGD(I=IO)
→- SVGD
4	8	16	32	64
Number of particles N
(b)
Figure 12: Accuracy as a function of the number of particles N for Bayesian logistic regression
on the Covertype dataset: (a) comparison with various benchmarks summarized in Table 1, and
(b) performance for different number of rounds I. L = 2000 iterations were used for centralized
schemes while I × L = 10 × 200 total local iterations were used for decentralized schemes.
distributed implementation. We note that NPV requires computation of the Hessian matrix which is
relatively impractical to compute.
We plot in Fig. 12(a) the accuracy as function of the number of particles N. DSGLD is executed
with two agents, where N/2 chains per agent are ran for a trajectory of length 4 and 500 rounds,
which we have found to work best. We found that SVGD, DSVGD and U-DSVGD exhibit the same
performance, which is superior to Particle Mirror Descent (PMD) and similar to SGLD and DSGLD
when the number of particles increases. Fig. 12(b) plots the accuracy for DSVGD for the same
setting for different number of communication rounds. We can see that, by increasing the number
of particles, i.e., the communication load, one can obtain similar accuracy as for a lower number
of particles but with a higher number of communication rounds. For example, N = 8 with I = 6
communication rounds achieves similar performance as N = 4 with I = 10 communication rounds.
Fig. 13	is a complementary figure for Fig. 4 in the main text. It shows that similar conclusions based
on accuracy can be made when using the log-likelihood.
24
Under review as a conference paper at ICLR 2021
Fig. 14	shows the accuracy of DSVGD for different datasets as function of the total number L of
local iterations. We fix N = 6, I = 10, L = L0 = 200 for U-DSVGD, DSGLD and DSVGD while
L = 2000 for SVGD and SGLD. We observe that U-DSVGD and DSVGD have similar performance
to SVGD and that they consistently outperform other schemes for sufficiently high L.
Fig. 16	is complementary to Fig. 4 in the main text. We note that the slightly noisy behaviour of
DSVGD with K = 20 agents is attributed to the small local dataset sizes resulting from splitting the
original small datasets.
Finally, Fig. 15 compares the accuracy of P-DSVGD with FedAvg and DSGLD with K = 100
agents and a proportion of 0.2 randomly scheduled agents per communication round. We see that
P-DSVGD exhibits similar behaviour and gain over other schemes similarly to DSVGD.
Covertype dataset
Ku3βe Z)
PoOmI-Bo-I
T- DSVGD(N=6)
-→- SVGD -→-
2	4	6	8
Number of rounds
Rlngnormdataset
Image dataset
DSVGDtAT= 6) V=
SVGD →-
DSVGD (M=6) SGLD
SVGD —DSGLD
2	4	6	8	1
Numberofrounds i
?u§ OZ)
PoO£OJl=TBO-
4 β β
Numberofrounds

Figure 13: Bayesian logistic regression log-likelihood with K = 2 and K = 20 agents using
the setting in Gershman et al. (2012) comparing DSVGD to distributed (DSGLD) and centralized
(SVGD and SGLD) schemes as function of the number of communication rounds i. We use N = 6
particles and fix L = L0 = 200. FedAvg has been removed as it has a log-likelihood lower than -1
in all cases and to allow us to focus on relevant values for DSVGD.
?u§ N)
>0Q3s<
Ku§ OZ)
.∞ . .. ββ -Ig
Local iterations number L
Local iterations number L
Figure 14:	Bayesian logistic regression accuracy for K = 2 (top row) and K = 20 (bottom row)
agents using the setting in Gershman et al. (2012) comparing U-DSVGD and DSVGD to distributed
(DSGLD) and centralized (SVGD and SGLD) schemes as function of the local iterations number L.
We fix N = 6 particles, I = 5 (top row) and I = 20 (bottom row).
25
Under review as a conference paper at ICLR 2021
XdBJn84
Figure 15:	Accuracy for Bayesian logistic regression with P-DSVGD, FedAvg, DSGLD and SVGD
using different datasets with K = 100 agents and a proportion of C = 0.2 randomly scheduled
agents. SVGD was executed for L = C × 100 × 4000 iterations while we fix L = L0 = LS = 200
total local iterations for the remaining schemes. We use N = 6 particles.
Ringnorm dataset
Image dataset
Vehicle Sensors dataset
(S4u36e Z)Ku3βe Oa
>υcsυυ<
→- DSVG□(ΛΓ=β)-∙- SVGD
T- DsVGDyVF SVGD
→- DSVGD ∙
一，DSVGD (ΛT= 2)
■，DSVGD (ΛΓ=2
y■■	FedAV0
→- SVGD
2。	4。 eα aa
Numberofrounds
SGLD
DSGLD
SGLD
DSGLD
20	40	8	8
Number of rounds i
f DSVGD(ΛΓ=2j
■ ♦ FedAvg
-M- DSVGD(N=6)
-c> pSW3D(jV=2)-*-
■	■ FedAvg
SVGD
SGLD
DSGLD
2	4	6	8
Number of rounds i
Y- DSVGD(N=6) SVGD
→- DSVGD (ΛF=2) →~ SGLD
g∙ ■ FedAvg	∙ DSGLD
→- □5VG□(Λr=β) →- SVGD
■，DSVGD (AT=2) →- SGLD
■	FedAV0	DSGLD
4 β β
Number of rounds
2	4 β β
Numberofrounds


y∣中『明.■中
Figure 16: Accuracy for Bayesian logistic regression with K = 2 (top row) and K = 20 (bottom
row) agents under the setting in Gershman et al. (2012) as function of the number of communication
rounds i, or number of communication rounds (N = 6 particles, L = L0 = 200).
B.4 Bayesian Neural Networks for Regression and Classification
This part contains additional results on regression and multilabel classification experiments using
Bayesian Neural Networks. Figures 17 and 18 are complementary to Figures 6 and 7 in the main
text and validate our conclusions using additional datasets for regression and the log-likelihood
metric for multi-label classification.
Propulsion dataset
→- DSVGD
■ ♦ ■ FedAp
-→- DSGLD
⅜2r-*.,→- SVGD
CCPP dataset
UJS≡H ⅛wup><
κuaβe OZ)
ww≡α oawuo><
Z刖Z=!
O O(誉解》：
ws≡= ⅛wup>4
Figure 17:	Average Root Mean square Error (RMsE) as a function of the number of communication
rounds i, or number of communication rounds, for regression using Bayesian neural networks with a
single hidden layer of ReLUs under the setting of Hernandez-Lobato & Adams (2015), with K = 2
(top row) and K = 20 (bottom row) agents. (N = 20, L = L0 = 200 and 50 hidden neurons).
26
Under review as a conference paper at ICLR 2021
(SIU36. a
PoOfβ>wlBO-l
(SIU36.a
PoO£oJl=TBO-
Ku3βe &
PoO£_僵!§
Ku3βe &
POOq=0y=τ6σl
Fashion MNIST dataset
•	→-	DSVGD
J .	1	FedAvg
∣/ /	→-	SVGD
I：	-→-	SGLD
I： I	→-	DSGLD
2	4	6	«	10
Number of rounds i
Fashion MNIST dataset
→- DSVGD
FedAvg
→- SVGD
→- SGLD
,→- DSGLD
6 10 15 2Q 2$ 30 3
Number of rounds
Figure 18:	Log-likelihood for multi-label classification using Bayesian neural networks with a single
hidden layer of 100 neurons as function of the number of communication rounds i, or number of
communication rounds, using MNIST and Fashion MNIST with K = 2 (top row) and K = 20
(bottom row) agents (N = 20, L = L = 200.
27
Under review as a conference paper at ICLR 2021
B.5 RELIABILITY PLOTS AND MAXIMUM CALIBRATION ERROR
Covertype dataset
XUE3VU< B∆yp8u
、
→- # neurons=5
-∙- # neurons=50
—∙- # neuro ns =100
---PerfeCtBenaSon
Agn8v α0>s
Confidence
αβ oλ
Confidence
#iIeUronS=5
#iIeUronS=50
Sneurans= 100
Perfect BanatOn
o.' aβ oλ
Confiden8
*neurans=5
≠neurans=50
(Sneurare = IOO
Perfect cββraton
XoEnMV α0Λsα
Figure 19:	Reliability plots for classification using Bayesian neural networks for a variable number
of hidden neurons with FedAvg (top row), SVGD (middle row) and DSVGD (bottom row). We use
N = 20 particles (I = 10, L = L0 = 200 and K = 20 agents).
Covertype dataset
_	_	_	_ -024
Zbe.Inooq
→- SVGD
*-w- DSVGD
j FedAvg
Twonorm dataset
-032
一	UJ
Image dataset
I-	-0.32
-OXK
2	4 a 1β «2 M
Number of particles N
→- SVGD
-⅝-■<-w- DSVGD t
Acc FedAvfl=O.7;*- FedAVg
-0.1βO
Ξ
葭
(Q OR-
0 0*^
<
—一A
-0X)0
2	4 a ιβ az M
Number of particles N
-0.1βO
—SVGD 修
→- DSVGD ^0 °8
■ ♦ ■ FedAvg
-0.00
Number of particles N
Figure 20:	Accuracy and Maximum Calibration Error (MCE) as function of the number of particles
N for Bayesian neural networks. We fix I = 10, L = L0 = 200 and K = 20 agents in both figures.
This section provides additional results on the calibration experiment conducted in Sec. 7 of the
main text using additional datasets. In Fig. 19, we show the reliability plots for SVGD, DSVGD
and FedAvg with K = 20 agents across various datasets and for different number of neurons in
the hidden layer. We first note that DSVGD retains the same calibration level as SVGD across all
datasets. Furthermore, while increasing the number ofhidden neurons negatively affects FedAvg due
to overfitting, it does not affect the trustworthiness of the predictions for the Bayesian counterparts.
This is a general property for Bayesian methods that contrast with frequentist approaches, for which
increasing the number of parameters improves accuracy at the price of miscalibration (Guo et al.,
2017).
Fig.	20 plots the accuracy and MCE as function of the number of particles N. While increasing N
improves the accuracy (as also shown in Fig. 12) for SVGD and DSVGD, the MCE is unaffected
and is lower than the MCE value for FedAvg.
28
Under review as a conference paper at ICLR 2021
C Implementation Details
C.1 Datasets, Benchmarks and Hyperparamters Details
Datasets. We summarize in Table 2 the main parameters used across different datasets that are
invariant across all experiments. The covertype dataset1 and the remaining binary classfication
datasets that are selected from the Gunnar Raetsch’s Benchmark datasets2 as compiled by Mika
et al. (1999) are used directly without normalization as in Liu & Wang (2016) except for the vehicle
sensors dataset3 which is normalized by removing the mean of each feature and dividing by their
standard deviations. Regression datasets4 are normalized by removing the mean of each feature
and dividing by their standard deviations, and multi-label classification datasets56 are normalized by
multiplying each pixel value by 0.99/255 and adding 0.01 such that every pixel value after normal-
ization belongs to the interval [0.01, 1]. All performance metrics used are averaged over the number
of trials. In each trial, unless specified otherwise, we permute the datasets and randomly split them
across different agents.
Hyperparameters. The hyperparameters used are summarized in Table 3. These apply for all
schemes except for DSGLD and SGLD, where the learning rates are annealed and are respectively
equal to ao ∙ (0.5 + i ∙ L + l)-0.55 and a0 ∙ (0.5 + l)-0.55 to ensure that they go from the order of
0.01 to 0.0001 as advised by Welling & Teh (2011). a0 is fixed according to the values in Table 4.
DSGLD implementation. DSGLD is implemented by splitting the N particles among the K agents.
More specifically, when scheduled, each agent runs dN/Ke Markov chains. We assumed that the
response delay in addition to the trajectory length of the chains (Ahn et al., 2014) to be equal among
all workers and unchanged throughout the learning process.
FedAvg implementation. FedAvg is implemented as in McMahan et al. (2017) with the only dif-
ference that the server schedules a single agent at a time. Each scheduled agent performs L SGD
iterations to minimize its local loss.
PVI and GVI implementation. PVI and GVI are implemented using a Gaussian parametrization
for both the posterior and the prior. The natural parameters are updated via the closed form update
in Bui et al. (2018, Property 4).
Scheduling. Unless specified otherwise, we use a round robin scheduler to schedule agents. How-
ever, any scheduler can be used as long as it schedules one agent per communication round.
Table 2: Overview of datasets and parameters used in the experiments. Datasets in bold are used in
the experiments section of the main text.
Dataset Name	Size	Task	batchsize	# trials	Train/test split
Covertype	581, 012 × 55	Binary classification	100	50	80%/20%
Twonorm	7, 400 × 20	Binary classification	10	50	80%/20%
Ringnorm	7, 400 × 20	Binary classification	10	50	80%/20%
Image	2, 086 × 18	Binary classification	10	50	80%/20%
Breast Cancer	263 × 9	Binary classification	10	50	80%/20%
Diabetis	768 × 8	Binary classification	10	50	80%/20%
German	1, 000 × 20	Binary classification	10	50	80%/20%
Heart	270 × 13	Binary classification	10	50	80%/20%
Waveform	5, 086 × 21	Binary classification	10	50	80%/20%
Vehicle Sensors	2010 × 23	Binary classification	10	50	80%/20%
Kin8nm	8, 192 × 8	Regression	100	50	90%/10%
Naval Propulsion	11, 934 × 16	Regression	100	50	90%/10%
Combined cycle power plant (CCPP)	9, 568 × 4	Regression	100	50	90%/10%
Year Prediction	515, 345 × 90	Regression	1000	20	90%/10%
MNIST	60, 000 × 785	Multi-label classification	100	20	86%/14%
Fashion MNIST	60, 000 × 785	Multi-label classification	100	20	86%/14%
1 https://www.csie.ntu.edu.tw/~cjlin∕libsvmtools∕datasets∕binary.html
2http://theoval.cmp.uea.ac.uk/matlab/default.html
3http://www.ecs.umass.edu/~mduarte/SOftWare.html
4https://archive.ics.uci.edu/ml/datasets.php
5http://yann.lecun.cOm/exdb/mnist/
6https://github.cOm/zalandOresearch/fashiOn-mnist
29
Under review as a conference paper at ICLR 2021
Table 3: Summary of hyperparameters used across various experiments.
Hyperparameter	Regression	Binary Classification	Multi-label Classification
Ada Learning rate7	0.001	0.05	0.001
Ada smoothing term (or fuge factor)	10-6	10-9	10-6
Momentum	0.9	0.9	0.9
KDE bandwidth	0.55	0.55	0.55
Table 4: Learning rate for DSGLD and SGLD used across various datasets.
Hyperparameter Year
DSGLD ao 0.0005
SGLD ao	-
MNIST F-MNIST Other
0.0005	0.0005 Or
0.001	0.001	0.01
C.2 S oftware Details
We implement all experiments in PyTorch (Paszke et al., 2019) Version 10.3.1. Our experiments
and code are based on the original SVGD experiments and code available at: https://github.
com/DartML/Stein-Variational-Gradient-Descent. More specifically, DSVGD
can be easily obtained by running SVGD twice at each scheduled agent and suitably adjusting its
target distribution. Our code is attached with the supplementary materials.
7All learning rates for non-parametric particle-based benchmark schemes used are scaled by a factor of 1/N
to match our learning rate and ensure fair comparison.
30