Under review as a conference paper at ICLR 2021
Non-Negative Bregman Divergence Minimiza-
tion for Deep Direct Density Ratio Estimation
Anonymous authors
Paper under double-blind review
Ab stract
This paper aims to estimate the ratio of probability densities using flexible mod-
els, such as state-of-the-art deep neural networks. The density ratio estimation
(DRE) has garnered attention as the density ratio is useful in various machine
learning tasks, such as anomaly detection and domain adaptation. For estimating
the density ratio, methods collectively known as direct DRE have been explored.
These methods are based on the minimization of the Bregman (BR) divergence
between a density ratio model and the true density ratio. However, when using
flexible models, such as deep neural networks, existing direct DRE suffers from
serious train-loss hacking, which is a kind of over-fitting caused by the form of an
empirical risk function. In this paper, we introduce a non-negative correction for
empirical risk using only the prior knowledge of the upper bound of the density
ratio. This correction makes a DRE method robust against train-loss hacking. It
enables the use of flexible models, such as state-of-the-art deep neural networks.
In the theoretical analysis, we show the generalization error bound of the BR di-
vergence minimization. In our experiments, the proposed methods show favorable
performance in inlier-based outlier detection and covariate shift adaptation.
1	Introduction
The density ratio estimation (DRE) problem has attracted a great deal of attention as an essential task
in data science for its various industrial applications, such as domain adaptation (Shimodaira, 2000;
Plank et al., 2014; Reddi et al., 2015), learning with noisy labels (Liu & Tao, 2014; Fang et al.,
2020), anomaly detection (Smola et al., 2009; Hido et al., 2011; Abe & Sugiyama, 2019), two-
sample testing (Keziou & Leoni-Aubin, 2005; Kanamori et al., 2010; Sugiyama et al., 2011a),
causal inference (Kato et al., 2020), change point detection in time series (Kawahara & Sugiyama,
2009), and binary classification only from positive and unlabeled data (PU learning; Kato et al.,
2019). For example, anomaly detection is not easy to perform based on standard machine learning
methods such as binary classification since anomalous data is often scarce, but it can be solved by
estimating the density ratio when training data without anomaly as well as unlabeled test data are
available (Hido et al., 2008).
Among various approaches for DRE, we focus on the Bregman (BR) divergence minimization
framework (Bregman, 1967; Sugiyama et al., 2011b) that is a generalization of various DRE meth-
ods, e.g., the moment matching (Huang et al., 2007; Gretton et al., 2009), the probabilistic classifi-
cation (Qin, 1998; Cheng & Chu, 2004), the density matching (Nguyen et al., 2010; Yamada et al.,
2010), and the density-ratio fitting (Kanamori et al., 2009). Recently, Kato et al. (2019) also pro-
posed using the risk of PU learning for DRE, which also can be generalized from the BR divergence
minimization viewpoint, as we show below.
However, existing DRE methods mainly adopt a linear-in-parameter model for nonparametric DRE
(Kanamori et al., 2012) and rarely discussed the use of more flexible models, such as deep neural
networks, while recent developments in machine learning suggest that deep neural networks can
significantly improve the performances for various tasks, such as computer vision (Krizhevsky et al.,
2012) and natural language processing (Bengio et al., 2001). This motivates us to use deep neural
networks for DRE. However, existing DRE studies have not fully discussed using such state-of-the-
art deep neural networks. For instance, although Nam & Sugiyama (2015) and Abe & Sugiyama
(2019) proposed using neural networks for DRE, their neural networks are simple and shallow.
1
Under review as a conference paper at ICLR 2021
When using deep neural networks in combination with empirical minimization of BR divergence,
we often observe a serious over-fitting problem as demonstrated through experiments in Figure 2 of
Section 5. We hypothesize that this is mainly because there is no lower bound in the empirically
BR divergence approximating by finite samples, i.e., we can achieve an infinitely negative value in
minimization. This hypothesis is based on Kiryo et al. (2017), which reports a similar problem in
PU learning. While Kiryo et al. (2017) call this phenomena over-fitting, we refer to it as train-loss
hacking because the nuance is a bit different from the standard meaning of overfitting.
Here, we briefly introduce the train-loss hacking discussed in the PU learning literature Kiryo et al.
(2017). In a standard binary classification problem, we train a classifier ψ by minimizing the fol-
lowing empirical risk using {(yi, Xi)}in=1 :
nn
-X 1[ yi = +1]' (ψ (Xi)) + -X 1[ yi = - 1]' (-ψ (Xi)),
n i=1	n i=1
(1)
where yi ∈ {±1} is a binary label, Xi is a feature, and ` is a loss function. On the other hand,
in PU learning formulated by du Plessis et al. (2015), because we only have positive data {(yi0 =
+1, Xi0)}in=0 1 and unlabeled data {(x0j0)}jn=001, we minimize the following alternative empirical risk:
0	0	00
n X ` (ψ (Xi) - n X ` (-ψ (Xi))+n X ` (-ψ (XjX,
i=1	i=1	j=1
(2)
Cause of train-loss hacking.
where π is a hyper-parameter representing p(y = +1). Note that the empirical risk (2) is unbiased
to the population binary classification risk (1) (du Plessis et al., 2015). While the the empirical
risk (1) of the standard binary classification is lower bounded under an appropiate choise of `, the
empirical risk (2) of PU learning proposed by du Plessis et al. (2015) is not lower bounded owing to
the existence of the second term. Therefore, if a model is sufficiently flexible, we can significantly
0
minimize the empirical risk only by minimizing the second term 一? ^2i=ι '(-ψ(Xi)) without
increasing the other terms. Kiryo et al. (2017) proposed non-negative risk correction for avoiding
this problem when using neural networks. We discuss this problem again in Section 2 and Figure 1.
In existing DRE literature, this train-loss hacking has rarely been discussed, although we often face
this problem when using neural networks, as mentioned in Section 5. One reason for this is that
the existing method assumes a linear-in-parameter model for a density ratio model (Kanamori et al.,
2012), which is not so flexible as neural networks and do not cause the phenomenon.
To mitigate the train-loss hacking, we propose a general procedure to modify the empirical BR
divergence using the prior knowledge of the upper bound of the density ratio. Our idea of the
correction is inspired by Kiryo et al. (2017). However, their idea of non-negative correction is only
immediately applicable to the binary classification; thus we require a non-trivial rewriting of the
BR divergence to generalize the approach to our problem. We call the proposed empirical risk the
non-negative BR (nnBR) divergence, and it is a generalization of the method of Kiryo et al. (2017).
In addition, for a special case of DRE, we can still use a lower bounded loss for DRE (See bounded
uLSIF and BKL introduced in the following section). However, such a loss also suffers from the
train-loss hacking (bounded uLSIF of Figure 2 and BKL-NN of Figure 4). In the case, the train-loss
hacking is caused because the loss sticks to the lower bound. This type of train-loss hacking is also
avoided by using the proposed nnBR divergence.
Our main contributions are: (1) the proposal of a general procedure to modify a BR divergence to
enable DRE with flexible models, (2) theoretical justification of the proposed estimator, and (3) the
experimental validation of the proposed method using benchmark data. 2
2	Problem Setting
Let Xnu ⊆ Rd and Xde ⊆ Rd be the spaces of the d-dimensional covariates {Xfu} ；； and
{ Xide } n=1 ,respectively, which are independent and identically distributed (i.i.d.) as { XnU } ：； i .1i.dd
Pnu(X) and {Xide}[； i.". Pde(X), wherePnu(X) andPde(X) are probability densities over Xnu
2
Under review as a conference paper at ICLR 2021
Table 1: Summary of methods for DRE(SUgiyama et al., 2011b). For PULogLoss, We use C ‹ R.
Method	f (t)	Reference
LSIF Kernel Mean Matching UKL KLIEP Logistic Regression (BKL) PULogLoss	(t - 1)2/2 (t - 1)2/2 t log(t) - t t log(t) - t t log(t) - (1 + t) log(1 + t) C log (1 — t) + Ct (log (t) — log (1 — t)) for 0 <t< 1	Kanamori et al. (2009) Gretton et al. (2009) Nguyen et al. (2010) Sugiyama et al. (2008) Hastie et al. (2001) Kato et al. (2019)
and Xde, respectively. Here, “nu” and “de” indicate the numerator and the denominator. Our goal is
to estimate the density ratio r^ (X) = P："(f). To identify the density ratio, we assume the following:
Assumption 1. The density pnu(X) is strictly positive over the space Xnu, the density pde(X) is
strictly positive overJthe space Xde, and Xnu ⊆ Xde. In addition, the density ratio r* is bounded
from above on Xde: R = SuPX∈^de r^ (X) < ∞.
Note that the assumption Xnu ⊆ Xde is typical in the context of DRE. For instance, in anomaly
detection with unlabeled test data, Xde corresponds to a sample space including clean and anomaly
data and Xde corresponds to a sample space only with clean data. Here, we introduce the notation
of this paper. Let Enu and Ede denote the expectations over pnu(X) and pde(X), respectively. Let
Enu and Ede denote the sample average over {Xfu }[； and {Xf© }n=；, respectively. Let H ⊂ {r :
Rd → (br, Br)} be the hypothesis class of the density ratio, where 0 ≤ br < R < Br.
2.1	Density Ratio Matching under the B regman Divergence
A naive way to implement DRE would be to estimate the numerator and the denominator densities
separately and take the ratio. However, according to Vapnik’s principle, we should avoid solving
a more difficult intermediate problem than the target problem (Vapnik, 1998). Therefore, various
methods for directly estimating the density ratio model have been proposed (Gretton et al., 2009;
Sugiyama et al., 2008; Kanamori et al., 2009; Nguyen et al., 2010; Yamada et al., 2010; Kato et al.,
2019). Sugiyama et al. (2011b) showed that these methods can be generalized as the density ratio
matching under the BR divergence.
The BR divergence is an extension of the Euclidean distance to a class of divergences that share
similar properties (Bregman, 1967). Formally, let f : (br, Br) → R be a twice continuously differ-
entiable convex function with a bounded derivative. Then, the point-wise BR divergence associated
with f from t* to t is defined as BRf (t*∣∣t):= f (t*) - f (t) - ∂f (t)(t* - t), where ∂f is the
derivative of f. Now, the discrepancy from the true density ratio function r^ to a density ratio model
r is measured by integrating the point-wise BR divergence as follows (Sugiyama et al., 2011b):
BRf(Cr) : = /Pde(X)(f(r*(X))- f(r(X))- ∂f(r(X)){r*(X) - r(X)})dX.	(3)
We estimate the density ratio by finding a function r that minimizes the BR divergence defined in
(3). Here, we subtract the constant BR = Ede [f (r* (X))] from (3) to obtain
BRf(r*kr) :=	pde(X)∂f(r(X))r(X) -f(r(X))dX-	pnu(X)∂f(r(X))dX.	(4)
Here, Sugiyama et al. (2012) used r*(X)pde = pnu for removing r* (X), which is a common tech-
nique in the DRE literature. Since BR is constant with respect to r, we have arg min 1r BR f( r*kr)=
arg minr BRf (r* kr). Then, let us define the sample analogue of (4) as
df (r) := Ede h∂f (r(Xi))r(Xi) - f (r(Xi))] - Enuh∂f("Xj))].	⑸
For a hypothesis class H, we estimate the density ratio by solving minr∈H BRf (r* kr).
2.2	Examples of DRE
Sugiyama et al. (2011b) showed that various DRE methods can be unified from the viewpoint
of BR divergence minimization. Furthermore, Menon & Ong (2016) showed an equivalence be-
tween conditional probability estimation and DRE by BR divergence minimization. In addition,
3
Under review as a conference paper at ICLR 2021
we can derive a novel method for DRE from the proposed method of du Plessis et al. (2015) and
Kato et al. (2019). We summarize the DRE methods in Table 1. Here, the empirical risks of least-
square importance fitting (LSIF), the KullbaCk-Leibler importance estimation procedure (KLIEP),
logistic regression (LR), and PU learning with log Loss (PULogLoss) is given as BRLSIF (r) :=
—Enu[r(X7-)] + 1Ede[(r(Xi))2], BRukl(r) := Ede [r(Xi)] — Enu [log (r(Xj))], BRbkl(r)：=
一Ede log (1+/(Xi)) — Enu log ( 1++X-))], and dPU(r) := _ Ede [log (1 — r(Xi))] +
CEnU _-log (r(Xj)) + log (1 — r(Xj))], where 0 < C < R∙ Here, BRLSIF(r) and BRPU(r)
correspond to LSIF and PULogLoss, respectively. We can derive the KLIEP and LR from
------ -------------
BRUKL(r) and BRBKL(r), which are called unnormalized KunbaCk-Leibler (UKL) divergence and
binary Kullback-Leibler (BKL) divergence, respectively (Sugiyama et al., 2011b). In BRPU(r), we
restrict the model as r ∈ (0, 1) and We obtain an estimator of Cr* as a result of the minimization of
the risk. Details of the existing methods are shown in Appendix A.
3 Deep Direct DRE based on Non-negative Risk Estimator
In this section, we develop methods for DRE with flexible models such as neural networks.
3.1	Difficulties of DRE using Neural Networks
Training neural networks for DRE by minimizing the empirical BR divergence tends to
suffer from an overfitting phenomenon. For example, we show in Section 5 that the
LSIF with neural networks (Nam & Sugiyama, 2015)
One possible cause of overfitting of flexible models has
been identified to be the train-loss hacking as shown by
Kiryo et al. (2017) in the context of PU learning (Fig-
ure 1). In DRE, the train-loss hacking is also sensible:
the term — Enu [∂f (r(Xj))] can easily diverge to —8
if we try to minimize empirical BR divergence (5) over
a highly flexible hypothesis class H. This is because
the term is not lower bounded, unlike the loss functions
suffers from a serious overfitting issue.
Figure 1: Illustration of the train-loss
hacking phenomenon. Given finite data
points, a sufficiently flexible model r
can easily make the training loss, e.g.,
-----
BRLSIF (r), diverge to —8.
for other machine learning tasks such as classification.
Here, note that the other term
Ede [∂f(r(Xi))r(Xi)—
f (r(Xi))] does not introduce a sufficient trade-off to
prevent the divergence to _8 when the hypothesis class
is highly flexible (Figure 1).
3.2	Non-negative BR Divergence
Although DRE using flexible models suffers from serious train-loss hacking, we still have a strong
motivation to use those models for analyzing data such as computer vision and text data. For ex-
ample, Nam & Sugiyama (2015) and Abe & Sugiyama (2019) approximated the density ratio with
neural networks, and Uehara et al. (2016) applied direct DRE for generative adversarial nets (GANs;
Goodfellow et al., 2014), both by minimizing the empirical BR divergence (5). To alleviate the train-
loss hacking problem, we propose the non-negative BR divergence estimator. The proposed method
is inspired by Kiryo et al. (2017), which suggested a non-negative correction to the empirical risk
of PU learning based on the knowledge that a part of the population risk is non-negative. On the
other hand, in DRE, it is not obvious how to correct the empirical risk because we do not know
which part of the population risk (4) is non-negative. However, this can be_alleviated by determining
the upper bound R of the density ratio r*. With the prior knowledge of R, we can determine part
of the risk of DRE (4) is non-negative and conduct a non-negative correction to the empirical risk
(5) based on the non-negativity of the population risk. Let us define f to be a function such that
∂f (t) = C(∂f (t)t — f (t)) + f(t), where 0 < C < R and put the following assumption.
Assumption 2. Assume that f(t) is bounded from above, and that there exists a constant A such
that ∂f(t)t — f(t) + A ≥ 0 for t ∈ (br, Br).
4
Under review as a conference paper at ICLR 2021
Assumption 2 is satisfied by most of the loss functions which appear in the previously proposed DRE
∙-v
methods (see Appendix B for examples). Under Assumption 2, because f (t) is bounded above, the
train-loss hacking 一E∏u
∂ff (r( Xj))]
→ 一 ∞ in the minimization of the empirical risk (5) is caused
by 一Enu[c [∂f (r(Xj))r(Xj) ― f (r(Xj))}] → 一∞ because
ʌ
- E nu
।
∂f( (r (Xj))]
___ -	}
{z
→ -∞
ʌ
- E nu
।
0(r(Xj))] -Enu[c[∂f(r(Xj))r(Xj) 一 f(r(Xj))}].
―{----------
Bounded
{z
→ -∞
}
Thus, we succeeded in identifying the part of the empirical risk causing the train-loss hacking.
Therefore, by preventing the term from going to infinite negative, we can avoid the train-loss hack-
ing. For achieving this purpose, we impose a non-negative correction to the empirical risk (5);
that is, under Assumption 2, we restrict the behavior of the problematic term. To incorporate the
assumption, We first rewrite the population risk (4) as BRf (r* ∣∣r)=
/ n P de( X) - Cp nu( X)}{ ∂f (r (X)) r (X) - f (r (X)) + Λ } dX - / P nu( X){ f( r (X))} dX.
|-------------------------------V-------------------------------}
(*)
Note that we introduce a constant A, which is irrelevant to the original optimization problem. Thus,
the problematic term is incorporated into (*). Therefore, we next consider a constraint condition
∙-v
on the term (*). Here, let us define 'ι(t):= ∂f(t)t - f (t) + A, and '2(t):= -f(t). In the
above equation, since Assumption 2 implies ' 1(t) ≥ 0, and 0 < C < R and P：u(；) ≤ R imply
Pde(X) - Cpnu(X) > 0 for all X ∈ ɪ, we have R {Pde(X) - CPnu(X)}{'ι(r(X))}dX > 0.
Motivated by this inequality, we propose an empirical risk with the non-negative correction as
n\Rf (r) := Enu['2(r(Xj))] + (Ede['ι(r(Xi))] - CEnu['ι(r(Xj))])+ ,
where (∙)+ := max{0, ∙}. Note that the constraint on (*) is not broken in population (infinite
samples) but broken in finite samples with causing the train-loss hacking. Our deep direct DRE
(D3RE) is based on minimizing nnBRf (r).
Remark 1 (Choice of C). In practice, selecting the hyper-parameter C does not require accurate
knowledge of R because any 0 < C < 1 /R is sufficient to justify the non-negative correction. How-
ever, selecting C that is relatively much smaller than 1 /R may damage the empirical performance.
See Section G.1.1. This remark does not mean that 1 /R should not be small; that is, R is note be
small. If 1 /R is small, C also can be small. Therefore, we recommend use larger C more than
smaller C.
nnBR Divergence with Existing Methods: The above strategy can be instantiated in various
methods previously proposed for DRE. Here, we introduce the non-negative BR divergence estima-
tors that correspond to LSIF, UKL, BKL, and PULogLoss as follows:
nnBRLSIF ( r ) :=	- E nu	r ( Xj )	-	2 r 2( Xj )	+ 2E E de	[r 2( Xi )]	-	ɪ E nu	[r 2( Xj )])
i∖Rukl(r) = -Enu [log (r(Xj)) - Cr(Xj)] + (Ede [r(Xi)] - CEnu [r(Xj)]) + ,
nnBRBKL(r)
ʌ
-E nu
log(τ+X⅛ )+c log(τ+⅛ )〕
+ (-E de [log (1+⅛ )〕+ c E nu [log 1+rj )D+,
i∖Rpu(r) := -CEnu [log (r(Xj))] + (CEnu [log (1 - r(Xj))] - Ede [log (1 - r(Xi)])+ .
∙-v
More detailed derivation off is in Appendix B. In Appendix C, we provide the pseudo code of
D3RE. For improving the performance heuristically, we use gradient ascending in our main exper-
iments. Note that the gradient ascent only slightly improves the performance and the use is not
essential. In the experiments in Appendix E and G.1.3, we also show the experimental results
without the gradient ascent for readers concerning the effect of the gradient ascent.
5
Under review as a conference paper at ICLR 2021
4 Theoretical Justification of D3RE
In this section, we confirm the validity of the proposed method by providing a generalization error
bound. Given n ∈ N and a distribution p, we define the Rademacher complexity Rpn of a function
class H as Rn(H)：= EPEσ [supr∈H 11 Pn=1。理(Xi)∣],where {σi}in=1 are independent uniform
sign variables and {Xi}n'=ι i'i^' p. We omit r^ from the notation of BR f when there is no ambiguity.
4.1 Generalization Error B ound on BR Divergence
Theorem 4 in Appendix I provides a generalization error bound under the following assumption.
Assumption 3. Let Ir := (b,Br). Assume that there exists an empirical risk minimizer r ∈
arg minr∈H nnBRf (r) and a population risk minimizer r ∈ arg minr∈H BRf (r). Assume B' :=
supt∈ιr{max{∖'ι(t)∣, ∣'2(t)|}} < ∞. Also assume ' 1 (resp. '2) is L'I-LiPSchitz (resp. L'?-
Lipschitz) on Ir. Assume also that infr∈H(Ede — CEnU)' 1(r(X)) > 0 holds.
In order for the boundedness and Lipschitz continuity in Assumption 3 to hold for the loss functions
involving a logarithm (UKL, BKL, PU), a technical assumption br > 0 is sufficient. We obtain a
theoretical guarantee for D3RE from Theorem 4 in Appendix I by additionally imposing Assump-
tion 4 to bound the Rademacher complexities using a previously known result (Golowich et al.,
2019, Theorem 1).
Assumption 4 (Neural networks with bounded complexity). Assume that pnu and pde have bounded
supports: supx∈Xde kxk < ∞. Also assume that H consists of real-valued neural networks of
depth L over the domain X , where each parameter matrix Wj has the Frobenius norm at most
BWj ≥ 0 and with 1-Lipschitz activation functions Wj that are positive-homogeneous (i.e., Wj is
applied element-wise and Wj (at) = αwj (t) for all ɑ ≥ 0).
Under Assumption 4, Lemma 3 in Appendix J reveals RnnnU (H) = O (1 /√nnU) and Rnde (H)=
O(1 /√nde). By combining these with Theorem 4 in Appendix I, We obtain the following theorem:
Theorem 1 (Generalization error bound for D3RE). Under Assumptions 3 and 4, for any δ ∈ (0, 1),
we have with probability at least 1 - δ,
BR f (r) - BR f (r) ≤ J— +-------7== + 2φC (n nu, n de) + B'∖ 8
nde	nnu
「上)K
nde	nnu	δ
where κ1 , κ2 are constants that depend on C, f, Bpde, Bpnu , L, and BWj .
See Remark 6 in Appendix I for the explicit form of this bound. By transforming the BR divergence,
Theorem 1 tells us generalization error bounds for various problems. For instance, by defining f (t)
as log (1 - t) + Ct (log (t) - log (1 - t)) for 0 < t < 1, the BR divergence BRf (r) becomes the
same risk functional of PU learning (see Appendix A for the derivation). Then, the generalization
bound is similar to the one shown by Kiryo et al. (2017), i.e., the generalization bounds matches
the classification error bound of classification only from positive and unlabeled data. Note that
the dependency of the bound is standard for classification risk bound with Lipschitz function (See
Corollary 15 of Bartlett & Mendelson (2003)). Thus, this result implies that the BR divergence
minimization with D3RE also minimize the generalization error bound of binary classification.
4.2 ESTIMATION ERROR BOUND ON L2 NORM
Next, We derive the estimation error bound of r on the L2 norm. We aim to derive the standard
convergence rate of non-parametric regression; that is, under appropriate conditions, the order of
∣∣r 一 r* ∣L2(pde) is nearly OP (1 /(nde ∧ nnu)) (Kanamori et al., 2012). Note that unlike the gen-
eralization error bound of the BR divergence, which is related to classification problems, we need
to restrict the neural network model to achieve such a convergence rate in general. To the best of
our knowledge, it is difficult for showing the convergence rate for any neural network models such
as ResNet (Schmidt-Hieber, 2020) in a general way. In the following Theorem 1, for a multi-layer
perception with ReLU activation function (Definition 3), we derive a converge rate of L2 distance,
6
Under review as a conference paper at ICLR 2021
which is the same rate with the nonparametric regression using radial basis function with the Gaus-
sian kernel and LSIF loss (Kanamori et al., 2012). This result also corresponds to a tighter gener-
alization error bound than Theorem 1 under the model restriction. Note that without such a model
restriction in Theorem 2, the convergence rate will slower based on the rate of Theorem 1. The proof
is shown in Appendix K. To support this result, we empirically investigate the estimator error using
an artificially generated dataset with the known true density ratio in Appendix E.
Theorem 2 (L1 2 Convergence rate). Assume f is μ-strongly convex. Let H be defined as in Defini-
tion 3, and assume r* = PnU ∈ H. Also assume the same conditions as Theorem 3. Then, for any
pde
0 <γ < 2, we have ∣∣r — r*∣L 2( P de) ≤ OP ((min {n de ,n nu})-1 / (2++γ)) (n de ,n nu → ∞).
5 Experiment with Image Data
In this section, we experimentally show how the existing estimators fail to estimate the density ratio
when using neural networks and that our proposed estimators succeed. To investigate the perfor-
mances, we consider PU learning. For a binary classification problem with labels y ∈ {—1, +1},
we consider training a classifier only from p(X | y = +1) and p(X) to find a positive data
point in test data sampled from p(X). The goal is to maximize the area under the receiver op-
erating characteristic (AUROC) curve, which is a criterion used for anomaly detection, by esti-
mating the density ratio r^(X) = P(X ∣ y = +1)/p(X). We construct the positive and neg-
ative dataset from CIFAR-101(Krizhevsky, 2009) dataset with 10 classes. The positive dataset
comprises ‘airplane’, ‘automobile’, ‘ship’, and ‘truck’; the negative dataset comprises ‘bird’, ‘cat’,
deer’, ‘dog’, ‘frog’, and ‘horse’. We use 1, 000 positive data sampled from p(X | y = +1) and
1, 000 unlabeled data sampled from p(X) to train the models. Then, we calculate the AUROCs
using 10,000 test data sampled from P(X). In this case, it is desirable to set C < 2 because
________P(XW=+1)_________ _ ________1_______
0∙5P(X∖y=+1)+0.5P(χ∖y = - 1) = 0.5+0.5P(X∣y=+1)ι -
For demonstrative purposes, we use the CNN
architecture from the PyTorch tutorial (Paszke et al., 2019). Details of the network structure are
shown in Appendix D.2. The model is trained using Adam without weight decay and the parameters
(β1, β2, ) in Kingma & Ba (2015) are fixed at the default of PyTorch, namely (0.9, 0.999, 10-8).
.	.	.	..	---Z ----------------- 1	Z …
First, we	compare two	of the proposed estimators,	nnBRPU	(nnBR-PU) and nnBRLSIF	(nnBR-
一^*∙~∙∙~--	一^*∙~--
LSIF), with the existing estimators, BRPU (PU-NN) and BRLSIF (uLSIF-NN). We use the logis-
tic loss for PULogLoss. Additionally, we conduct an experiment with uLSIF-NN using a naively
capped model r(X) = min{r(X), 1 /C} (Bounded ULSIF). We fix the hyperparameter C at 1 /3.
We report the results for two learning rates, 1 × 10-4 and 1 × 10-5. We conducted 10 trials,
ʌ
and calculated the average AUROCs. We also compute Ede[r(X)], which should be close to 1
if we successfully estimate the density ratio, because (P(x|y = +1)/P(X))P(X)dx = 1. The
results are in Figure 2. In all cases, the proposed estimators outperform the other methods. In
contract, the unstable behaviors of PU-NN and LISF-NN are caused by the train-loss hacking
(also see (Kiryo et al., 2017) Appendix G.1). The experiment also demonstrates that naive cap-
ping (Bounded uLSIF) fails to prevent train-loss hacking and leads to suboptimal behavior. A naive
capping is insufficient because an unreasonable model such that r(Xide) = 0 and r(Xinu) = 1/C
still can be a minimizer by making one part of the empirical BR divergence largely negative, e.g., as
2Ede [r2 (X)] — CEnu [r2 (X)] = 0 — 21C ∙
Additional experimental results for sensitivity analysis on the upper bound of the density ratio and
comparison with various estimators using nnBR divergence are shown in Appendix G.1.
6 Inlier-based Outlier Detection
As an applications of D3RE, we introduce inlier-based outlier detection with experiments using
benchmark datasets. Moreover, we introduce other applications such as covariate shift adap-
tation in Appendix H. In addition to CIFAR-10, we use MNIST2 (LeCun et al., 1998) and
fashion-MNIST (FMNIST)3 (Xiao et al., 2017). Hido et al. (2008; 2011) applied the direct DRE
1See https://www.cs.toronto.edu/~kriz/cifar.html.
2MNIST has 10 classes from 0 to 9. See http://yann.lecun.com/exdb/mnist/.
3FMNIST has 10 classes. See https://github.com/zalandoresearch/fashion-mnist.
7
Under review as a conference paper at ICLR 2021
Figure 2: Experimental results of Section 5. The horizontal axis is epoch, and the vertical axis is
AUROC. The learning rates of the left and right graphs are 1 × 10-4 and 1 × 10-5, respectively.
ʌ
The upper graphs show the AUROCS and the lower graphs show Ede[r(X)], which will approach 1
when we successfully estimate the density ratio.
Table 2: Average AUROC curve (Mean) with the standard deviation (SD) over 5 trials of anomaly
detection methods. For all datasets, each model was trained on a single class and tested against all
other classes. The best figure is in bold.
CIFAR-10 Network	ULSIF-NN LeNet		nnBR-LSIF LeNet		nnBR-PU LeNet		nnBR-LSIF WRN		nnBR-PU WRN		Deep SAD LeNet		GT WRN	
Inlier Class	Mean	SD	Mean	SD	Mean	SD	Mean	SD	Mean	SD	Mean	SD	Mean	SD
plane	0.745	0.056	0.934	0.002	0.943	0.001	0.925	0.004	0.923	0.001	0.627	0.066	0.697	0.009
car	0.758	0.078	0.957	0.002	0.968	0.001	0.965	0.002	0.960	0.001	0.606	0.018	0.962	0.003
bird	0.768	0.012	0.850	0.007	0.878	0.004	0.844	0.004	0.858	0.004	0.404	0.006	0.752	0.002
cat	0.745	0.037	0.820	0.003	0.856	0.002	0.810	0.009	0.841	0.002	0.517	0.018	0.727	0.014
deer	0.758	0.036	0.886	0.004	0.909	0.002	0.864	0.008	0.872	0.002	0.704	0.052	0.863	0.014
FMNIST Network	uLSIF-NN LeNet		nnBR-LSIF LeNet		nnBR-PU LeNet		nnBR-LSIF WRN		nnBR-PU WRN		Deep SAD LeNet		GT WRN	
Inlier Class	Mean	SD	Mean	SD	Mean	SD	Mean	SD	Mean	SD	Mean	SD	Mean	SD
T-shirt/top	0.960	0.005	0.981	0.001	0.985	0.000	0.984	0.001	0.982	0.000	0.558	0.031	0.890	0.007
Trouser	0.961	0.010	0.998	0.000	1.000	0.000	0.998	0.000	0.998	0.000	0.758	0.022	0.974	0.004
Pullover	0.944	0.012	0.976	0.001	0.980	0.001	0.983	0.002	0.972	0.001	0.617	0.046	0.902	0.005
Dress	0.973	0.006	0.986	0.001	0.992	0.000	0.991	0.001	0.986	0.000	0.525	0.038	0.843	0.014
Coat	0.958	0.006	0.978	0.001	0.983	0.000	0.981	0.002	0.974	0.000	0.627	0.029	0.885	0.003
for inlier-based outlier detection: finding outliers in a test set based on a training set consisting only
of inliers by using the ratio of training and test data densities as an outlier score. Nam & Sugiyama
(2015) and Abe & Sugiyama (2019) proposed using neural networks with DRE for this problem. In
relation to the experimental setting of Section 5, the problem setting can be seen as a transductive
variant of PU learning (Kato et al., 2019).
We follow the setting proposed by Golan & El-Yaniv (2018) using MNIST, CIFAR-10, and
FMNIST. There are ten classes in each dataset; we use one class as the inlier class and all other
classes as the outliers. For example, in the case of CIFAR-10, there are 5, 000 train data per class.
On the other hand, there are 1, 000 test data for each class, which consists of 1, 000 inlier samples
and 9, 000 outlier samples. The AUROC is used as a metric to evaluate whether an outlier class can
be detected in the test data. We compare the proposed methods with benchmark methods of deep
semi-supervised anomaly detection (DeepSAD) (Ruff et al., 2020) and geometric transformations
(GT) (Golan & El-Yaniv, 2018). The details of each method are shown in Appendix F. To compare
the methods fairly, we use the same architectures of neural networks from Golan & El-Yaniv (2018)
and Ruff et al. (2020), LeNet and Wide Resnet, for D3RE. The details of the structures are shown in
Appendix D. A part of the experimental results with CIFAR-10 and FMNIST are shown in Table 2
due to the limitation of the space. The full results are shown in Table 4 in Appendix G.2. The pro-
posed methods result in better AUROCs than the existing methods. The largest performance gain is
seen in the CIFAR-10: the mean AUROC is improved by 0.157 on average between the uLSIF-NN
and nnBR-LSIF. Although GT and DeepSAD are designed for a different problem, to the best of our
knowledge, these are the state-of-the-art algorithms, which are not based on DRE.
7 Conclusion
We proposed a non-negative correction to the empirical BR divergence for DRE. Using the prior
knowledge of the upper bound of the density ratio, we can prevent train-loss hacking when using
flexible models. In our theoretical analysis, we showed the generalization bound of the algorithm.
8
Under review as a conference paper at ICLR 2021
References
Masahiro Abe and Masashi Sugiyama. Anomaly detection by deep direct density ratio estimation.
openreview, 2019.
Ryan Prescott Adams. Bayesian online changepoint detection. Technical report, 2007.
S. M. Ali and S. D. Silvey. A general class of coefficients of divergence of one distribution from
another. Journal ofthe Royal Statistical Society, Series B(28):131-142, 1966.
Susan Athey and Stefan Wager. Efficient policy learning. arXiv preprint arXiv:1702.02896, 2017.
Peter L. Bartlett and Shahar Mendelson. Rademacher and Gaussian complexities: Risk bounds and
structural results. In Computational Learning Theory, volume 2111, pp. 224-240. Springer Berlin
Heidelberg, 2001.
Peter L Bartlett and Shahar Mendelson. Rademacher and Gaussian complexities: Risk bounds and
structural results. The Journal of Machine Learning Research, 3:463-482, 2003.
Michele Basseville and Igor V. Nikiforov. Detection of abrupt changes: theory and application.
Prentice Hall information and system sciences. Prentice Hall, 1993.
Yoshua Bengio, R0jean Ducharme, and Pascal Vincent. A neural probabilistic language model. In
NeurIPS, pp. 932-938. MIT Press, 2001.
Alina Beygelzimer and John Langford. The offset tree for learning with partial labels. In KDD, pp.
129-138, 2009.
Aurelien Bibaut, Ivana Malenica, Nikos Vlassis, and Mark Van Der Laan. More efficient off-policy
evaluation through regularized targeted learning. In ICML. PMLR, 2019.
P. J. Bickel, C. A. J. Klaassen, Y. Ritov, and J. A. Wellner. Efficient and Adaptive Estimation for
Semiparametric Models. Springer, 1998.
Steffen Bickel, Michael Bruckner, and Tobias Scheffer. Discriminative learning under covariate
shift. J. Mach. Learn. Res., 10:2137-2155, December 2009. ISSN 1532-4435.
John Blitzer, Mark Dredze, and Fernando Pereira. Biographies, Bollywood, boom-boxes and
blenders: Domain adaptation for sentiment classification. In Proceedings of the 45th Annual
Meeting of the Association of Computational Linguistics, June 2007.
L.M. Bregman. The relaxation method of finding the common point of convex sets and its applica-
tion to the solution of problems in convex programming. USSR Computational Mathematics and
Mathematical Physics, 7(3):200 - 217, 1967. ISSN 0041-5553.
E. Brodsky and B.S. Darkhovsky. Nonparametric Methods in Change Point Problems. Mathematics
and Its Applications. Springer Netherlands, 1993.
Minmin Chen, Zhixiang Xu, Kilian Q. Weinberger, and Fei Sha. Marginalized denoising autoen-
coders for domain adaptation. In ICML, ICML ’ 12, pp. 1627-1634, Madison, WI, USA, 2012.
Omnipress.
kuang-Fu Cheng and C.K. Chu. Semiparametric density estimation under a two-sample density ratio
model. Bernoulli, 10, 08 2004.
Victor Chernozhukov, Juan Carlos Escanciano, Hidehiko Ichimura, Whitney K. Newey, and
James M. Robins. Locally robust semiparametric estimation, 2016.
Victor Chernozhukov, Denis Chetverikov, Mert Demirer, Esther Duflo, Christian Hansen, Whitney
Newey, and James Robins. Double/debiased machine learning for treatment and structural pa-
rameters. Econometrics Journal, 21:C1-C68, 2018.
Stephen R. Cole and Elizabeth A. Stuart. Generalizing evidence from randomized clinical trials to
target populations. American Journal of Epidemiology, 172(1):107-115, 2010.
9
Under review as a conference paper at ICLR 2021
Corinna Cortes and Mehryar Mohri. Domain adaptation in regression. In Algorithmic Learning
Theory, pp. 308-323, Berlin, Heidelberg, 2011. Springer Berlin Heidelberg.
I.	Csiszdr. Information-type measures of difference of probability distributions and indirect obser-
vation. Studia Scientiarum Mathematicarum Hungarica, (2):229-318, 1967.
Marthinus Christoffel du Plessis, Gang. Niu, and Masashi Sugiyama. Convex formulation for learn-
ing from positive and unlabeled data. In ICML, pp. 1386-1394, 2015.
Miroslav Dudik, John Langford, and Lihong Li. Doubly Robust Policy Evaluation and Learning. In
ICML, pp. 1097-1104, 2011.
Charles Elkan and Keith Noto. Learning classifiers from only positive and unlabeled data. In ICDM,
pp. 213-220, 2008.
Tongtong Fang, Nan Lu, Gang Niu, and Masashi Sugiyama. Rethinking importance weighting for
deep learning under distribution shift. In NeurIPS, 2020.
Roman Garnett, Michael A. Osborne, and Stephen J. Roberts. Sequential bayesian prediction in the
presence of changepoints. In ICML, pp. 345-352, New York, NY, USA, 2009. Association for
Computing Machinery.
Izhak Golan and Ran El-Yaniv. Deep anomaly detection using geometric transformations. In
NeurIPS, pp. 9758-9769. Curran Associates, Inc., 2018.
Noah Golowich, Alexander Rakhlin, and Ohad Shamir. Size-Independent Sample Complexity of
Neural Networks. arXiv:1712.06541 [cs, stat], November 2019.
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair,
Aaron Courville, and Yoshua Bengio. Generative adversarial nets. In NeurIPS, pp. 2672-2680.
Curran Associates, Inc., 2014.
A. Gretton, A.J. Smola, J. Huang, Marcel Schmittfull, K.M. Borgwardt, andB. Scholkopf. Covariate
shift by kernel mean matching. Dataset Shift in Machine Learning, 131-160 (2009), 01 2009.
M. G. L. Gustafsson. Surpassing the lateral resolution limit by a factor of two using structured
illumination microscopy. Journal of Microscopy, 198(2):82-87, 2000.
Jens Hainmueller. Entropy balancing for causal effects: A multivariate reweighting method to pro-
duce balanced samples in observational studies. Political Analysis, 2012.
Trevor Hastie, Robert Tibshirani, and Jerome Friedman. The elements of statistical learning: data
mining, inference and prediction. Springer, 2001.
Kaiming He, Shaoqing Ren Xiangyu Zhang, and Jian Sun. Deep residual learning for image recog-
nition. In CoRR, 2015.
E. Hellinger. Neue begrundung der theorie quadratischer formen von unendlichvielen verander-
lichen. Journalfur die reine UndangewandteMathematik, 136:210-271, 1909.
Masayuki Henmi and Shinto Eguchi. A paradox concerning nuisance parameters and projected
estimating functions. Biometrika, 2004.
Masayuki Henmi, Ryo Yoshida, and Shinto Eguchi. Importance Sampling Via the Estimated Sam-
pler. Biometrika, 2007.
Shohei Hido, Yuta Tsuboi, Hisashi Kashima, Masashi Sugiyama, and Takafumi Kanamori. Inlier-
based outlier detection via direct density ratio estimation. pp. 223-232, 12 2008.
Shohei Hido, Yuta Tsuboi, Hisashi Kashima, Masashi Sugiyama, and Takafumi Kanamori. Statis-
tical outlier detection using direct density ratio estimation. Knowledge and Information Systems,
26(2):309-336, Feb 2011.
Keisuke Hirano, Guido W. Imbens, and Geert Ridder. Efficient estimation of average treatment
effects using the estimated propensity score. Econometrica, 71(4):1161-1189, 2003.
10
Under review as a conference paper at ICLR 2021
D. G. Horvitz and D. J. Thompson. A generalization of sampling without replacement from a finite
universe. Journal OftheAmerican Statistical Association, 47(260):663-685, 1952.
JiayUan Huang, Arthur Gretton, Karsten Borgwardt, Bernhard Scholkopf, and Alex J. Smola. Cor-
recting sample selection bias by unlabeled data. In NeurIPS, pp. 601-608. MIT Press, 2007.
Kosuke Imai and Marc Ratkovic. Covariate balancing propensity score. J. R. Statist. Soc. B, 76(1):
243-263, 2014.
Sergey Ioffe and Christian Szegedy. Batch normalization: Accelerating deep network training by
reducing internal covariate shift. In ICML, pp. 448-456, 2015.
Nathan Kallus and Masatoshi Uehara. Intrinsically efficient, stable, and bounded off-policy evalua-
tion for reinforcement learning. In NeurIPS, pp. 3320-3329. 2019.
Takafumi. Kanamori, Shohei Hido, and Masashi Sugiyama. A least-squares approach to direct
importance estimation. Journal of Machine Learning Research, 10(Jul.):1391-1445, 2009.
Takafumi Kanamori, Taiji Suzuki, and Masashi Sugiyama. f -divergence estimation and two-sample
homogeneity test under semiparametric density-ratio models. IEEE Transactions on Information
Theory, 58, 10 2010.
Takafumi Kanamori, Taiji Suzuki, and Masashi Sugiyama. Statistical analysis of kernel-based least-
squares density-ratio estimation. Mach. Learn., 86(3):335-367, March 2012. ISSN 0885-6125.
Masahiro Kato. Identifying different definitions of future in the assessment of future economic
conditions: Application of pu learning and text mining. arXiv, 2019.
Masahiro Kato, Takeshi Teshima, and Junya Honda. Learning from positive and unlabeled data with
a selection bias. In ICLR, 2019.
Masahiro Kato, Masatoshi Uehara, and Shota Yasui. Off-policy evaluation and learning for external
validity under a covariate shift, 2020.
Yoshinobu Kawahara and Masashi Sugiyama. Change-point detection in time-series data by direct
density-ratio estimation. In ICDM, 2009.
A. Keziou. Utilisation des divergences entre mesures en statistique inferentielle. PhD thesis, 2003.
Amor Keziou and Samuela Leoni-Aubin. Test of homogeneity in semiparametric two-sample den-
sity ratio models. Comptes Rendus Mathematique - CR MATH, 340:905-910, 06 2005.
Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In ICLR, 2015.
Ryuichi Kiryo, Gang Niu, Marthinus C. du Plessis, and Masashi Sugiyama. Positive-unlabeled
learning with non-negative risk estimator. arXiv:1703.00593 [cs, stat], 2017.
Chris A. J. Klaassen. Consistent estimation of the influence function of locally asymptotically linear
estimators. Ann. Statist., 1987.
Alex Krizhevsky. Learning multiple layers of features from tiny images. 2009.
Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classification with deep convo-
lutional neural networks. In NeurIPS, pp. 1097-1105. Curran Associates, Inc., 2012.
S. Kullback and R. A. Leibler. On information and sufficiency. Ann. Math. Statist., 22(1):79-86,
1951.
Yann LeCun, Leon Bottou, YoshUa Bengio, and Patrick Haffner. Gradient-based learning applied to
document recognition. In Proceedings of the IEEE, 1998.
Michel Ledoux and Michel Talagrand. Probability in Banach Spaces: Isoperimetry and Processes.
Springer, Berlin, 1991.
Lihong Li, Wei Chu, John Langford, and Robert E Schapire. A contextual-bandit approach to
personalized news article recommendation. In WWW, pp. 661-670, 2010.
11
Under review as a conference paper at ICLR 2021
Song Liu, Makoto Yamada, Nigel Collier, and Masashi Sugiyama. Change-point detection in time-
series data by relative density-ratio estimation. In Structural, Syntactic, and Statistical Pattern
Recognition, pp. 363-372, Berlin, Heidelberg, 2012. Springer Berlin Heidelberg.
Tongliang Liu and Dacheng Tao. Classification with noisy labels by importance reweighting, 2014.
Jane Loevinger. The technic of homogeneous tests compared with some aspects of "scale analysis"
and factor analysis. Psychological Bulletin, 45(6):507-529, 1948. ISSN 0033-2909.
Nan Lu, Tianyi Zhang, Gang Niu, and Masashi Sugiyama. Mitigating overfitting in supervised
classification from two unlabeled datasets: A consistent risk correction approach. 2020.
Colin McDiarmid. On the method of bounded differences. In Surveys in Combinatorics, 1989:
Invited Papers at the Twelfth British Combinatorial Conference, London Mathematical Society
Lecture Note Series, pp. 148-188. Cambridge University Press, 1989.
Aditya Menon and Cheng Soon Ong. Linking losses for density ratio and class-probability estima-
tion. In ICML, volume 48, pp. 304-313, New York, New York, USA, 2016.
Mehryar Mohri, Afshin Rostamizadeh, and Ameet Talwalkar. Foundations of Machine Learning.
The MIT Press, 2018.
Hyunha Nam and Masashi Sugiyama. Direct density ratio estimation with convolutional neural
networks with application in outlier detection. IEICE Transactions on Information and Systems,
E98.D(5):1073-1079, 2015.
Yusuke Narita, Shota Yasui, and Kohei Yata. Efficient counterfactual learning from bandit feedback.
AAAI, 2019.
Minh Nhut Nguyen, Xiaoli-Li Li, and See-Kiong Ng. Positive unlabeled leaning for time series
classification. In IJCAI, pp. 1421-1426, 2011.
XuanLong Nguyen, Martin Wainwright, and Michael Jordan. Estimating divergence functionals and
the likelihood ratio by convex risk minimization. IEEE, 2010.
Gang Niu, Marthinus Christoffel du Plessis, Tomoya. Sakai, Y. Ma, and Masashi Sugiyama. Theo-
retical comparisons of positive-unlabeled learning against positive-negative learning. In NeurIPS,
pp. 1199-1207, 2016.
Sebastian Nowozin, Botond Cseke, and Ryota Tomioka. f-gan: Training generative neural samplers
using variational divergence minimization. In NeurIPS, pp. 271-279. Curran Associates, Inc.,
2016.
Michael Oberst and David Sontag. Counterfactual off-policy evaluation with gumbel-max structural
causal models. In ICML, volume 97, pp. 4881-4890, 2019.
Ulrich Paquet. Empirical bayesian change point detection. Graphical Models, 1995, 01 2007.
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor
Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas Kopf, Edward
Yang, Zachary DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner,
Lu Fang, Junjie Bai, and Soumith Chintala. Pytorch: An imperative style, high-performance deep
learning library. In NeurIPS, pp. 8024-8035. Curran Associates, Inc., 2019.
Judea Pearl and Elias Bareinboim. External validity: From do-calculus to transportability across
populations. Statistical Science, 29, 2014.
K. Pearson. On the criterion that a given system of deviations from the probable in the case of
a correlated system of variables is such that it can reasonably be supposed to have arisen from
random sampling. Philosophical Magazine, 5(50):157-175, 1900.
Barbara Plank, Anders Johannsen, and Anders S0gaard. Importance weighting and unsupervised
domain adaptation of POS taggers: a negative result. 2014.
12
Under review as a conference paper at ICLR 2021
Jing Qin. Inferences for case-control and semiparametric two-sample density ratio models.
Biometrika, 85(3):619-630,1998.
Jing Qin and Biao Zhang. Empirical-likelihood-based inference in missing response problems and
its application in observational studies. Journal of the Royal Statistical Society, 2007.
Sashank Jakkam Reddi, Barnabgs P6czos, and Alex J. Smola. Doubly robust covariate shift correc-
tion. In AAAI, pp. 2949-2955. AAAI Press, 2015.
P. R. Rosenbaum. The central role of the propensity score in observational studies for causal effects.
70:41-55, 1983.
P. R. Rosenbaum. Model-based direct adjustment. Journal of the American Statistical Association,
82:387-394, 1987.
Donald B. Rubin. Estimating causal effects of treatments in randomized and nonrandomized studies.
Journal of Educational Psychology, 66(5):688, 1974.
LUkas Ruff, Robert A. Vandermeulen, Nico Gornitz, Alexander Binder, Emmanuel Muller, Klaus-
Robert Muller, and Marius Kloft. Deep semi-supervised anomaly detection. In ICLR, 2020.
Gerard Salton and Michael J McGill. Introduction to modern information retrieval. 1986.
Johannes Schmidt-Hieber. Nonparametric regression using deep neural networks with ReLU acti-
vation function. 2020.
Hidetoshi Shimodaira. Improving predictive inference under covariate shift by weighting the log-
likelihood function. Journal of statistical planning and inference, 90(2):227-244, 2000.
Alex Smola, Le Song, and Choon Hui Teo. Relative novelty detection. In AISTATS, volume 5
of Proceedings of Machine Learning Research, pp. 536-543, Hilton Clearwater Beach Resort,
Clearwater Beach, Florida USA, 2009. PMLR.
J.T. Springenberg, A. Dosovitskiy, T. Brox, and M. Riedmiller. Striving for simplicity: The all
convolutional net. In ICLR (workshop track), 2015.
Masashi Sugiyama, Taiji Suzuki, Shinichi Nakajima, Hisashi Kashima, Paul von Bunau, and Mo-
toaki Kawanabe. Direct importance estimation for covariate shift adaptation. Annals of the Insti-
tute of Statistical Mathematics, 60:699-746, 02 2008.
Masashi Sugiyama, Taiji Suzuki, Yuta Itoh, Takafumi Kanamori, and Manabu Kimura. Least-
squares two-sample test. Neural networks : the official journal of the International Neural Net-
work Society, 24:735-51, 04 2011a.
Masashi Sugiyama, Taiji Suzuki, and Takafumi Kanamori. Density ratio matching under the breg-
man divergence: A unified framework of density ratio estimation. Annals of the Institute of
Statistical Mathematics, 64, 10 2011b.
Masashi Sugiyama, Taiji Suzuki, and Takafumi Kanamori. Density Ratio Estimation in Machine
Learning. Cambridge University Press, New York, NY, USA, 1st edition, 2012.
Zhiqiang Tan. Bounded, efficient and doubly robust estimation with inverse weighting. Biometrika,
2010.
Yuta Tsuboi, Hisashi Kashima, Shohei Hido, Steffen Bickel, and Masashi Sugiyama. Direct density
ratio estimation for large-scale covariate shift adaptation. Journal of Information Processing, 17:
138-155, 2009. doi: 10.2197/ipsjjip.17.138.
M. Uehara, I. Sato, M. Suzuki, K Nakayama, and Y. Matsuo. Generative adversarial tets from a
density ratio estimation perspective. 2016. URL https://arxiv.org/abs/1610.02920.
Sara van de Geer. Empirical Processes in M-Estimation, volume 6. Cambridge university press,
2000.
Vladimir Naumovich Vapnik. Statistical Learning Theory. Wiley, September 1998.
13
Under review as a conference paper at ICLR 2021
Martin J. Wainwright. High-Dimensional Statistics: A Non-Asymptotic Viewpoint. 1st edition, 2019.
Yu-Xiang Wang, Alekh Agarwal, and Miroslav Dudik. Optimal and adaptive off-policy evaluation
in contextual bandits. In ICML,pp. 3589-3597, 2017.
Richard Wyss, Alan R. Ellis, M. Alan Brookhart, Cynthia J. Girman, Michele Jonsson Funk, Robert
LoCasale, and Til Sturmer. The Role of Prediction Modeling in Propensity Score Estimation:
An Evaluation of Logistic Regression, bCART, and the Covariate-Balancing Propensity Score.
American Journal of Epidemiology, 2014.
Han Xiao, Kashif Rasul, and Roland Vollgraf. Fashion-mnist: a novel image dataset for benchmark-
ing machine learning algorithms. ArXiv, abs/1708.07747, 2017.
Makoto Yamada and Masashi Sugiyama. Direct importance estimation with gaussian mixture
models. IEICE Transactions on Information and Systems, E92.D(10):2159-2162, 2009. doi:
10.1587/transinf.E92.D.2159.
Makoto Yamada, Masashi Sugiyama, Gordon Wichern, and Jaak Simm. Direct importance estima-
tion with a mixture of probabilistic principal component analyzers. IEICE Transactions, 93-D:
2846-2849, 10 2010.
Kenji Yamanishi and Junnichi Takeuchi. A unifying framework for detecting outliers and change
points from non-stationary time series data. pp. 676-681, 12 2002.
Sergey Zagoruyko and Nikos Komodakis. Wide residual networks. In Proceedings of the British
Machine Vision Conference (BMVC), pp. 87.1-87.12. BMVA Press, September 2016.
Wenjing Zheng and Mark J van der Laan. Cross-validated targeted minimum-loss-based estima-
tion. In Targeted Learning: Causal Inference for Observational and Experimental Data, Springer
Series in Statistics. 2011.
14
Under review as a conference paper at ICLR 2021
A Details of Existing Methods for DRE
In this section, we overview examples of DRE methods in the framework of the density ratio match-
ing under BR divergence.
Least Squares Importance Fitting (LSIF): LSIF minimizes the squared error between a density
ratio model r and the true density ratio r^ defined as follows (Kanamori et al., 2009):
R lsif( r) = Ede [(r( X)-r* (X ))2] = Ede [(r* (X ))2] - 2Enu[r (X)] + Ede [(r( X ))2] ∙
In the unconstrained LSIF (uLSIF) (Kanamori et al., 2009), we ignore the first term in the above
equation and estimate the density ratio by the following minimization problem:
r = arg min 1 Ede[(r(X))2] - Enu[r(X)] + R(r) ,	(6)
r∈H	2
where R is a regularization term. This empirical risk minimization is equal to minimizing the
empirical BR divergence defined in (5) with f(t) = (t - 1)2/2.
Unnormalized Kullback-Leibler (UKL) Divergence and KL Importance Estimation Pro-
cedure (KLIEP): The KL importance estimation procedure (KLIEP) is derived from the un-
normalized Kullback-Leibler (UKL) divergence objective (Sugiyama et al., 2008; Nguyenetal.,
2010; Tsuboi et al., 2009; Yamada & Sugiyama, 2009; Yamada et al., 2010), which uses f(t) =
t log(t) - t. Ignoring the terms which are irrelevant for the optimization, we obtain the unnor-
malized Kullback-Leibler (UKL) divergence objective (Nguyen et al., 2010; Sugiyama et al., 2012)
as
BRukl (r )= Ede [ r (X)] - Enu [log (r (X))] ∙
Directly minimizing UKL is proposed by Nguyen et al. (2010). The KLIEP also solves the same
problem with further imposing a constraint that the ratio model r(X) is non-negative for all X and
is normalized as
ʌ
Ede [r(X)] = 1 ∙
Then, following is the optimization criterion of KLIEP (Sugiyama et al., 2008):
maxEnu [log (r(X))]
ʌ
S∙t∙ Ede [r(X)] = 1 and r(X) ≥ 0 for all X∙
Logistic Regression: By using f(t) = log(t) - (1 + t) log(1 + t), we obtain the following BR
divergence called the binary Kullback-Leibler (BKL) divergence:
BRBKL(r) = -Ede
Iog(TTrX))
	
u
r( X)
1+ r (X)
This BR divergence is derived from a formulation based on the logistic regression (Hastie et al.,
2001; Sugiyama et al., 2011b).
PU Learning with the Log Loss: Consider a binary classification problem and let X and y ∈
{±1} be the feature and the label of a sample, respectively. In PU learning, the goal is to train a
classifier only using positive data sampled from p(X | y = +1), and unlabeled data sampled from
p(X ) in binary classification (Elkan & Noto, 2008). More precisely, this problem setting of PU
learning is called the case-control scenario (Elkan & Noto, 2008; Niu et al., 2016). Let G be the set
of measurable functions from X to [, 1 - ], where ∈ (0, 1/2) is a small positive value. For a loss
function ` : R × {±1} → R+, du Plessis et al. (2015) showed that the classification risk of g ∈ G
in the PU problem setting can be expressed as
Rpu(g) = ∏ / ('(g(X), +1) - '(g(X), -i))p(X I y = +1)dX + / '(g(X),-1)]p(X)dX∙
(7)
15
Under review as a conference paper at ICLR 2021
According to Kato et al. (2019), we can derive the following risk for DRE from the risk for PU
learning (7) as follows:
BRPU(g) = REnu [ — log (g(X)) + log (1 — g(X))] — Ede [log (1 - g(X))] ,
and Kato et al. (2019) showed that g* = arg ming∈g BRpu(g) satisfies the following:
Proposition 1. It holds almost everywhere that
f 1 — ɛ (X ∈ D2),
g*(X) = CppnUX (X∈Dι∩D2),
[E (X ∈ D1),
where C = R, Dι = {X ∣ Cpnu(X) ≥ epde(X)}, and D2 = {X∣Cpnu(X) ≤ (1 — e)pde(X)}.
Using this result, we define the empirical version of BRPU (g) as follows:
dPU(门忱) ：= CEnu [ — log (r(Xi)) + log(1 — r(Xj))] — Ede [log(1 — r(Xi))] ∙
Note that for f(t) in the BR divergence, we use
f(t) = Clog(1 —t) + Ct(log(t) —log(1 —t)) ∙
Then, we have
df (t) = —7—-7 + C(log(t) — log(1 — t)) + Ct f7 + -γ~-.
1—t	t 1—t
Therefore, we have
BRf (r) := Ede [ff (r(Xi))r(Xi) — f (r(Xi))] — Enu ∖ff (r(Xj))]
=Edeh — Cr(XL) + Cr(Xi)(log(r(Xi)) — log(1 — r(Xi))) + Cr2(Xi) (ɪ +	1
1	— r(Xi)	r(Xi)	1 — r(Xi)
— Edehlog(1 — r(Xi)) + Cr(Xi) (log (r(Xi)) — log (1 — r(Xi))) i
-Enu h - --+rC +	C (log(r (Xi ))	— log(1	— r (Xi )))	+ Cr (Xi )	( m	+ ；-7VΓΓ )]
1 — r(Xi)	r(Xi)	1 —	r(Xi)
=Ede h —「(X∖ + Cr(Xi)(log(r(Xi)) — log(1 — r(Xi))) +「X\〕
1	— r(Xi)	1 — r(Xi)
— Edeh log (1 — r(Xi)) + Cr(Xi) (log (r(Xi)) —log(1 — r(Xi))) i
CC
—Enu [ — 1—r(Xi) + C(log(r(Xi)) — log(1 — r(Xi))) + 1—r(Xi) ]
= Edeh log (1 — r(Xi)) i — CEnuh log(r(Xi)) — log(1 — r(Xi))i∙
Remark 2 (DRE and PU learning). Menon & Ong (2016) showed that minimizing a proper CPE
loss is equivalent to minimizing a BR divergence to the true density ratio, and demonstrated the
viability of using existing losses from one problem for the other for CPE and DRE. Kato et al.
(2019) pointed out the relation between the PU learning and density ratio estimation and leveraged
it to solve a sample selection bias problem in PU learning. In this paper, we introduced the BR
divergence with f(t) = log (1 — Ct) + Ct (log (Ct) — log (1 — Ct)), inspired by the objective
function ofPU learning with the log loss. In the terminology of Menon & Ong (2016), this f results
in a DRE objective without a link function. In other words, it yields a direct DRE method.
B EXAMPLES OF f
Here, We show the examples of f such that ∂f (t) = C(∂f (t)t — f (t)) + f(t), where f (t) is bounded
from above, and ∂f(t)t — f(t) + A is non-negative.
16
Under review as a conference paper at ICLR 2021
t
1 + t
First, we consider f(t) = (t - 1)2/2, which results in the LSIF objective. Because ∂f (t) = t - 1,
we have
t - 1 = C((t - I)t - (t - 1)2/2) + f(t)
⇔ f(t) = -C((t- 1)t- (t- 1)2/2) + t — 1 = -2tt2 + -2- + t - 1 ∙
The function is a concave quadratic function, therefore it is upper bounded. Note that uLSIF satisfies
the Assumption 2 with A = 2 since ∂f (t)t + f (t) + 2 = 2t2, and Assumption 3 automatically
holds. Also note that the term A is irrelevant to the optimization.
Second, we consider f(t) = t log(t) - t, which results in the UKL or KLIEP objective. Because
∂f(t) = log(t), we have
log(t) = C(log(t)t - t log(t) + t) + f(t)
∙-v
⇔ f(t) = -tC + log(t).
We can easily confirm that the function is upper bounded by taking the derivative and finding that
t = 1/C gives the maximum. Note that UKL satisfies the Assumption 2 with A = 0 since ∂f(t)t -
f(t) = t log(t) - t log(t) + t = t, and Assumption 3 automatically holds.
Third, we consider f(t) = t log(t) - (1 +t) log(1 +t), which is used for DRE based on LR or BKL.
Because ∂f(t) = log(t) - log(1 + t), we have
log(t) - log(1 + t) = C((log(t) - log(1 + t))t - t log(t) + (1 + t)log(1 + t)) + f(t)
⇔ f(t) = -C(log(1 + t)) + log(t) - log(1 + t) = log (1C;) + log
We can easily confirm that the function is upper bounded as the terms involving t always add up
to be negative. Note that BKL satisfies the Assumption 2 with A = 0 since ∂f(t)t - f(t) =
(log(t) - log(1 + t))t - t log(t) + (1 + t) log(1 +t) = log(1 + t), and Assumption 3 automatically
holds.
Fourth, we consider DRE based on PULog. By setting f(t) = log (1 - t) +
Ct (log (t) - log (1 - t)), we can obtain the same risk functional introduced in Kiryo et al. (2017).
Note that PULog satisfies the Assumption 2 with A = 0 since ∂f(t)t - f(t) = - log(1 - t) with
t < 1, and Assumption 3 automatically holds.
C Implementation
The algorithm for D3RE is described in Algorithm 1. For training with a large amount of data, we
adopt the stochastic optimization by splitting the dataset into mini-batches. In stochastic optimiza-
tion, We separate the samples into N mini-batches as ({XnU}[,，{Xfe}}；) (j = 1 ,...,N,
where nnu,j and nde,j are the sample sizes in each mini-batch. Then, we consider taking sam-
ple average in each mini-batch. Let E" and E^^ be sample averages over {Xfu}；=, and
Xide in=de1,j . In addition, we use regularization such as L1 and L2 penalties, denoted by R(r).
For improving the performance, we heuristically employ gradient ascent from Kiryo et al. (2017)
when Ede '11(r(X))] - CEnu '11(r(X))] becomes less than 0, i.e., update the model in the direc-
tion that increases the term. Let us note that our proposed method is agnostic to the optimization
procedure, and other methods such as plain gradient descent can be combined with our method. We
consider that further theoretical investigation of the optimization procedure is out of scope.
D Network Structure used in Sections 5 and 6
We explain the structures of neural networks used in the experiments.
D.1 Network Structure used in Sections 5
In Section 5, we used CIFAR-10 datasets. The model was a convolutional net (Springenberg et al.,
2015): (32 × 32 × 3)-C(3 × 6, 3)-C(3 × 16, 3)-128-84-1, where the input is a 32 × 32 RGB image,
17
Under review as a conference paper at ICLR 2021
Algorithm 1 D3RE
Input: Training data Xinu in=nu1 and Xide in=de1, the algorithm for stochastic optimization such
as Adam (Kingma & Ba, 2015), the learning rate γ, the regularization coefficient λ.
Output: A density ratio estimator r.
while No stopping criterion has been met: do
Create N mini-batches {({XnU} =,j, {Xpe}ndɪj)}[1.
for i = 1 to N do
if Ede '11(r(X))] — CEnu '11(r(X))] ≥ 0: then ʌ	ʌ
Gradient decent: set gradient Rr {Enu[ 12(r(X))] + Ede[11(r(X))] - CEnu[ 11(r(X))] +
λR(r)}.
else
Gradient ascent: set gradient ▽『{ - Ede[11(r(X))] + CE{u[ 11(r(X))] + λR(r)}.
end if
Update r with the gradient and the learning rate γ .
end for
end while
C(3 × 6, 3) indicates that 3 channels of 3 × 6 convolutions followed by ReLU is used. This structure
has been adopted from the tutorial of Paszke et al. (2019).
D.2 Network Structure used in Sections 6
Inlier-based Outlier Detection: We used the same LeNet-type CNNs proposed in Ruff et al.
(2020). In the CNNs, each convolutional module consists of a convolutional layer followed by
leaky ReLU activations with leakiness α = 0.1 and (2 × 2)-max-pooling. For MNIST, we em-
ploy a CNN with two modules: (32 × 32 × 3)-C(3 × 32, 5)-C(32 × 64, 5)-C(64 × 128, 5)-1. For
CIFAR-10 we employ the following architecture: (32 × 32 × 1)-C(1 × 8, 5)-C(8 × 4, 5)-1 with a
batch normalization (Ioffe & Szegedy, 2015) after each convolutional layer.
The WRN architecture was proposed in Zagoruyko & Komodakis (2016) and it is also used in
Golan & El-Yaniv (2018). This structure improved the performance of image recognition by de-
creasing the depth and increasing the width of the residual networks (He et al., 2015). We omit the
detailed description of the structure here.
Covariate Shift Adaptation: We used the 5-layer perceptron with ReLU activations. The struc-
ture is 10000-1000-1000-1000-1000-1.
E	Experiments for Regression Error using Synthetic Dataset
In this experiment, we investigate the regression error of the proposed D3RE. We
compare our method with the uLSIF (Kanamori et al., 2009) with reproducing ker-
nel Hilbert space (Kanamori et al., 2012). For uLSIF, we use an open code of
https://github.com/hoxo-m/densratio_py. For D3RE, we use nnBR-LSIF and
3-layer perceptron with ReLU activation function, where the number of the nodes of the middle
layer is 100. We conducted nnBR-LSIF for all C ∈ {0.8, 1, 2, 3, 4, 5, 10, 15, 20}. We also compare
these method with naively implemented LSIF with the 3-layer perceptron.
Let the dimension of the domain be d and
P nu( X) = N (X ； μnu ,Id ),	(8)
P de( X )= N ( X ； μde ,Id),	(9)
where N(μ, Σ) denotes the multivariate normal distribution with mean μ and Σ, μnu and μde are
d-dimensional vector such that μnu = (1,0,..., 0)T and μde = (0,0,..., 0)T, and Id is a d-
dimensional identity matrix. We fix the sample sizes at nnU = nde = 1, 000 and estimate the
density ratio using uLSIF, LSIF, and D3RE (nnBR-LSIF).
18
Under review as a conference paper at ICLR 2021
Figure 3: The learning curves of the experiments in Section 5. The horizontal axis is epoch. The ver-
tical axes of the top figures indicate the training losses. The vertical axes of the bottom figures show
the AURPC for the test data. The bottom figures are identical to the ones displayed in Section 5.
Figure 4: Top figures: the detailed experimental results for Section G.1.1. Bottom figure: the
detailed experimental results for Section G.1.2. The horizontal axis is epoch, and the vertical axis is
AUROC.
For a performance metric, we use the mean squared error (MSE) and the standard deviation (SD)
calculated over 50 trials. Note that in this setting, We Can calculate the true density ratio r*. The
results are shown in Table 3. The lowest MSE methods are highlighted in bold. As shown in Table 3,
the proposed nnBR-LSIF methods estimate the density rate better than the other methods; that is,
achieve lower MSEs. Note that in this setting, the upper bound of r* is infinite because We do not
restrict the support of X for simplicity. In the many cases of the results, nnBR-LSIF achieve the
best performance around C = 2. This result implies that We do not need to knoW the exact C for
better estimation; that is, We can ignore some "out-lier" samples, Which cause train-loss hacking.
19
Under review as a conference paper at ICLR 2021
Table 3: Experimental results (MSEs and SDs) of DRE using synthetic datasets.
		ULSIF	LSIF-NN	C = 0.8	C=1	D3RE (nnBR-LSIF)					C = 15	C = 20
						C = 2	C=3	C=4	C=5	C=10		
dim = 10	MSE SD	2.378 1.143	1.272" 0.413	-1.750 0.570	1.695 0.563	1.191 0.523	0.964 0.487	0.873 0.459	0.833 0.424	0.948 0.370	1.079 0.331	1.170 0.387
dim = 20	MSE SD	1.684 0.372	2.694 0.409	-1.704 0.380	1.646 0.368	1.307 0.328	1.272 0.297	1.337 0.283	1.444 0.288	2.066 0.285	2.697 0.346	3.098 0.374
dim = 30	MSE SD	1.786 0.456	3.724 0.460	-1.811 0.459	1.747 0.449	1.488 0.411	1.577 0.400	1.798 0.401	2.019 0.379	3.238 0.370	4.306 0.464	5.432 0.543
dim = 50	MSE SD	1.791 0.562	8.717 1.518	-1.817 0.571	1.753 0.555	1.609 0.513	1.818 0.503	2.194 0.484	2.614 0.465	4.848 0.488	6.955 0.597	8.798 0.672
dim = 100	MSE SD	1.723 0.574	4.849 4.182	-1.748 0.575	1.693 0.571	1.626 0.540	1.860 0.532	2.226 0.495	2.709 0.563	5.528 0.672	8.605 0.790	11.557 1.140
F Existing Methods for Anomaly Detection
This section introduces the existing methods for anomaly detection. DeepSAD is a method for semi-
supervised anomaly detection, which tries to take advantage of labeled anomalies (Ruff et al., 2020).
GT proposed by Golan & El-Yaniv (2018) trains neural networks based on a self-labeled dataset by
performing 72 geometric transformations. The anomaly score based on GT is calculated based on
the Dirichlet distribution obtained by maximum likelihood estimation using the softmax output from
the trained network.
In the problem setting of the DeepSAD, we have access to a small pool of labeled samples, e.g. a
subset verified by some domain expert as being normal or anomalous. In the experimental results
shown in Ruff et al. (2020) indicate that, when we can use such samples, the DeepSAD outperforms
the other methods. However, in our experimental results, such samples are not assumed to be avail-
able, hence the method does not perform well. The problem setting of Ruff et al. (2020) and ours
are both termed semi-supervised learning in anomaly detection, but the two settings are different.
G Details of Experiments
The details of experiments are shown in this section. The description of the data is as follows:
MNIST: The MNIST database is one of the most popular benchmark datasets for image classifi-
cation, which consists of 28 × 28 pixel handwritten digits from 0 to 9 with 60, 000 train
samples and 10, 000 test samples (LeCun et al., 1998).
CIFAR-10: The CIFAR-10 dataset consists of 60, 000 color images of size 32 × 32 from 10
classes, each having 6000. There are 50, 000 training images and 10, 000 test images
(Krizhevsky et al., 2012).
fashion-MNIST: The fashion-MNIST dataset consists of 70, 000 grayscale images of size
28 × 28 from 10 classes. There are 60, 000 training images and 10, 000 test images
(Xiao et al., 2017).
Amazon Review Dataset: Blitzer et al. (2007) published the text data of Amazon review. The
data originally consists of a rating (0-5 stars) for four different genres of products in the
electronic commerce site Amazon.com: books, DVDs, electronics, and kitchen appliances.
Blitzer et al. (2007) also released the pre-processed and balanced data of the original data.
The pre-processed data consists of text data with four labels 1, 2, 4, and 5. We map the text
data into 10, 000 dimensional data by the TF-IDF mapping with that vocabulary size. In
the experiment, for the pre-processed data, we solve the regression problem where the text
data are the inputs and the ratings 1, 2, 4, and 5 are the outputs. When evaluating the per-
formance, following Menon & Ong (2016), we calculate PD (=1-AUROUC) by regarding
4 and 5 ratings as positive labels and 1 and 2 ratings as negative labels.
G.	1 Experiments with Image Data
We show the additional results of Section 5. Figure 3, we show the training loss of LSIF-based
methods to demonstrate the train-loss hacking phenomenon caused by the objective function without
20
Under review as a conference paper at ICLR 2021
Figure 5: Experimental results of Section 5 without gradient ascent/descent heuristic. The horizontal
axis is epoch, and the vertical axis is AUROC. The learning rates of the left and right graphs are
1×10-4 and 1 × 10-5 , respectively. The upper graphs show the AUROCs and the lower graphs
ʌ
show Ede[r(X)], which will approach 1 when We successfully estimate the density ratio.
a lower bound. In Figure 3, even though the training loss of uLSIF-NN and that of bounded uLSIF
decrease more rapidly than that of nnBR-LSIF, the test AUROC score (the higher the better) either
drops or fails to increase. These graphs are the manifestations of the severe train-loss hacking in
DRE without our proposed device.
G.1.1 Empirical Sensitivity Analysis on the Upper Bounds of the Density Ratio
Next, we investigate the sensitivity of D3RE to the hyperparameter C . We use nnBR-LSIF and
nnBR-PU as in Section 5, but vary the hyperparameter C in {1/1.2, 1/1.5, 1/2.0.1/3.0, 1/5.0}. The
other settings remain unchanged from the previous section. These results are shown in Figure 4. For
R = 2.0, the estimator show a better performance when 1 /C is close to 2.0.
G.1.2 Comparison with Various Estimators using nnBR Divergence
Let UKL-NN and BKL-NN be DRE method with the UKL and BKL losses with neural networks
without non-negative correction. Finally, we examine the performances of nnBR-LSIF, nnBR-PU,
UKL-NN, BKL-NN, nnBR-UKL, and nnBR-BKL. The learning rate was 1 × 10-4, and the other
settings were identical to those in the previous experiments. These results are shown in Figure 4.
UKL-NN and BKL-NN also suffer train-loss hacking although BKL loss seems to be more robust
against the train-loss hacking than the other loss functions . Although nnBR-UKL and nnBR-BKL
show better performance in earlier epochs, nnBR-LSIF and nnBR-PU appear more stable.
G.1.3 Results without Gradient Ascent
We also show the experimental results without the gradient ascent heuristic. Figure 5 corresponds
to the Figure 2 without the gradient ascent heuristic. Figure 6 corresponds to the Figure 3 without
the gradient ascent heuristic. Figure 7 corresponds to the Figure 4 without the gradient ascent
heuristic. As shown these experiments, although the gradient ascent/descent heuristic improve the
performance, there is no significant difference between empirical performance with and without the
heuristic. Therefore, we recommend practitioners to use the gradient ascent/descent heuristic, but if
readers concern the theoretical guarantee, they can use the plain gradient descent algorithm; that is,
naively minimize the proposed original empirical nnBR risk.
G.2 Experiments of Inlier-based Outlier Detection
In Table 4, we show the full results of inlier-based outlier detection. In almost all the cases, D3RE
for inlier-based outlier detection outperforms the other methods. As explained in Section F, we
consider that DeepSAD does not work well because the method assumes the availability of the
labeled anomaly data, which is not available in our problem setting.
21
Under review as a conference paper at ICLR 2021
Figure 6: The learning curves of the experiments in Section 5 without gradient ascent/descent heuris-
tic. The horizontal axis is epoch. The vertical axes of the top figures indicate the training losses.
The vertical axes of the bottom figures show the AURPC for the test data. The bottom figures are
identical to the ones displayed in Section 5.
Figure 7: Top figures: the detailed experimental results for Section G.1.1 without gradient as-
cent/descent heuristic. Bottom figure: the detailed experimental results for Section G.1.2. The
horizontal axis is epoch, and the vertical axis is AUROC.
Remark 3 (Benchmark Methods). Although GT is outperformed by our proposed method, the
problem setting for the comparison is not in favor of GT as it does not assume the access to the test
data. Recently proposed methods for semi-supervised anomaly detection by Ruff et al. (2020) did
not perform well without using other side information used in Ruff et al. (2020). On the other hand,
there is no other competitive methods in this problem setting, to the best of our knowledge.
22
Under review as a conference paper at ICLR 2021
Table 4: Average area under the ROC curve (Mean) of anomaly detection methods averaged over 5
trials with the standard deviation (SD). For all datasets, each model was trained on the single class,
and tested against all other classes. The best performing method in each experiment is in bold. SD:
Standard deviation.
MNIST Network	ULSIF-NN LeNet		nnBR-LSIF LeNet		nnBR-PU LeNet		nnBR-LSIF WRN		nnBR-PU WRN		Deep SAD LeNet		GT WRN	
Inlier Class	Mean	SD	Mean	SD	Mean	SD	Mean	SD	Mean	SD	Mean	SD	Mean	SD
0	0.999	0.000	0.997	0.000	0.999	0.000	1.000	0.000	1.000	0.000	0.592	0.051	0.963	0.002
1	1.000	0.000	0.999	0.000	1.000	0.000	1.000	0.000	1.000	0.000	0.942	0.016	0.517	0.039
2	0.997	0.001	0.994	0.000	0.997	0.001	1.000	0.000	1.000	0.001	0.447	0.027	0.992	0.001
3	0.997	0.000	0.995	0.001	0.998	0.000	1.000	0.000	1.000	0.000	0.562	0.035	0.974	0.001
4	0.998	0.000	0.997	0.001	0.999	0.000	1.000	0.000	1.000	0.000	0.646	0.015	0.989	0.001
5	0.997	0.000	0.996	0.001	0.998	0.000	1.000	0.000	1.000	0.000	0.502	0.046	0.990	0.001
6	0.997	0.001	0.997	0.001	0.999	0.000	1.000	0.000	1.000	0.000	0.671	0.027	0.998	0.000
7	0.996	0.001	0.993	0.001	0.998	0.001	1.000	0.000	1.000	0.001	0.685	0.032	0.927	0.004
8	0.997	0.000	0.994	0.001	0.997	0.000	0.999	0.000	0.999	0.000	0.654	0.026	0.949	0.002
9	0.993	0.002	0.990	0.002	0.994	0.001	0.998	0.001	0.998	0.001	0.786	0.021	0.989	0.001
CIFAR-10 Network	uLSIF-NN LeNet		nnBR-LSIF LeNet		nnBR-PU LeNet		nnBR-LSIF WRN		nnBR-PU WRN		Deep SAD LeNet		GT WRN	
Inlier Class	Mean	SD	Mean	SD	Mean	SD	Mean	SD	Mean	SD	Mean	SD	Mean	SD
plane	0.745	0.056	0.934	0.002	0.943	0.001	0.925	0.004	0.923	0.001	0.627	0.066	0.697	0.009
car	0.758	0.078	0.957	0.002	0.968	0.001	0.965	0.002	0.960	0.001	0.606	0.018	0.962	0.003
bird	0.768	0.012	0.850	0.007	0.878	0.004	0.844	0.004	0.858	0.004	0.404	0.006	0.752	0.002
cat	0.745	0.037	0.820	0.003	0.856	0.002	0.810	0.009	0.841	0.002	0.517	0.018	0.727	0.014
deer	0.758	0.036	0.886	0.004	0.909	0.002	0.864	0.008	0.872	0.002	0.704	0.052	0.863	0.014
dog	0.728	0.103	0.875	0.004	0.906	0.002	0.887	0.005	0.896	0.002	0.490	0.025	0.873	0.002
frog	0.750	0.060	0.944	0.003	0.958	0.001	0.948	0.004	0.948	0.001	0.744	0.014	0.879	0.008
horse	0.782	0.048	0.928	0.003	0.948	0.002	0.921	0.007	0.927	0.002	0.519	0.015	0.953	0.001
ship	0.780	0.048	0.958	0.003	0.965	0.001	0.964	0.002	0.957	0.001	0.430	0.062	0.921	0.009
trUck	0.708	0.081	0.939	0.003	0.955	0.001	0.952	0.003	0.949	0.001	0.393	0.008	0.911	0.003
FMNIST Network	uLSIF-NN LeNet		nnBR-LSIF LeNet		nnBR-PU LeNet		nnBR-LSIF WRN		nnBR-PU WRN		Deep SAD LeNet		GT WRN	
Inlier Class	Mean	SD	Mean	SD	Mean	SD	Mean	SD	Mean	SD	Mean	SD	Mean	SD
T-shirt/top	0.960	0.005	0.981	0.001	0.985	0.000	0.984	0.001	0.982	0.000	0.558	0.031	0.890	0.007
Trouser	0.961	0.010	0.998	0.000	1.000	0.000	0.998	0.000	0.998	0.000	0.758	0.022	0.974	0.004
Pullover	0.944	0.012	0.976	0.001	0.980	0.001	0.983	0.002	0.972	0.001	0.617	0.046	0.902	0.005
Dress	0.973	0.006	0.986	0.001	0.992	0.000	0.991	0.001	0.986	0.000	0.525	0.038	0.843	0.014
Coat	0.958	0.006	0.978	0.001	0.983	0.000	0.981	0.002	0.974	0.000	0.627	0.029	0.885	0.003
Sandal	0.968	0.011	0.997	0.001	0.999	0.000	0.999	0.000	0.999	0.000	0.681	0.023	0.949	0.005
Shirt	0.919	0.005	0.952	0.001	0.958	0.001	0.944	0.005	0.932	0.001	0.618	0.015	0.842	0.004
Sneaker	0.991	0.001	0.994	0.002	0.998	0.000	0.998	0.000	0.998	0.000	0.802	0.054	0.954	0.006
Bag	0.980	0.005	0.994	0.001	0.999	0.000	0.998	0.000	0.999	0.000	0.447	0.034	0.973	0.006
Ankle boot	0.992	0.001	0.985	0.015	0.999	0.000	0.997	0.000	0.996	0.000	0.583	0.023	0.996	0.000
G.3 Experiments of Covariate Shift Adaptation
In Table 5, we show the detailed results of experiments of covariate shift adaptation. Even when the
training data and the test data follow the same distribution, the covariate shift adaptation based on
D3RE improves the mean PD. We consider that this is because the importance weighting emphasizes
the loss in the empirical higher-density regions of the test examples.
H	Other Applications
In this section, we explain other potential applications of the proposed method.
H.	1 Covariate Shift Adaptation by Importance Weighting
We consider training a model using input distribution different from the test input distribution, which
is called covariate shift, (Bickel et al., 2009). To solve this problem, the density ratio has been used
via importance weighting (IW) (Shimodaira, 2000; Yamada et al., 2010; Reddi et al., 2015).
23
Under review as a conference paper at ICLR 2021
Table 5: Average PD (Mean) with standard deviation (SD) over 10 trials with different seeds per
method. The best performing method in terms of the mean PD is specified by bold face.
Domains (Train → Test)	books → books		dvd → books		dvd → dvd		elec → books		elec → dvd	
DRE method	Mean	SD	Mean	SD	Mean	SD	Mean	SD	Mean	SD
w/o IW	0.093	0.003	0.128	0.008	0.100	0.005	0.212	0.012	0.187	0.008
Kernel uLSIF	0.089	0.002	0.114	0.006	0.094	0.004	0.200	0.009	0.179	0.006
Kernel KLIEP	0.089	0.002	0.116	0.006	0.094	0.004	0.205	0.011	0.184	0.008
uLSIF-NN	0.093	0.003	0.128	0.008	0.100	0.005	0.212	0.012	0.187	0.008
PU-NN	0.093	0.003	0.128	0.008	0.100	0.005	0.212	0.012	0.187	0.008
nnBR-LSIF	0.086	0.002	0.113	0.005	0.091	0.004	0.199	0.009	0.176	0.005
nnBR-PU	0.090	0.003	0.113	0.006	0.096	0.004	0.199	0.009	0.176	0.006
Domains (Train → Test)	elec → elec		kitchen → books		kitchen → dvd		kitchen → elec		kitchen → kitchen	
DRE method	Mean	SD	Mean	SD	Mean	SD	Mean	SD	Mean	SD
w/o IW	0.079	0.005	0.202-	-0.013	0.185	0.006	0.073	0.004	0.062-	0.002
Kernel uLSIF	0.072	0.003	0.192	0.007	0.178	0.008	0.071	0.003	0.060	0.003
Kernel KLIEP	0.072	0.003	0.195	0.005	0.182	0.007	0.072	0.004	0.060	0.002
uLSIF-NN	0.079	0.005	0.202	0.013	0.185	0.006	0.073	0.004	0.062	0.002
PU-NN	0.079	0.005	0.202	0.013	0.185	0.006	0.073	0.004	0.062	0.002
nnBR-LSIF	0.071	0.003	0.189	0.008	0.174	0.008	0.068	0.003	0.058	0.003
nnBR-PU	0.074	0.004	0.190	0.008	0.174	0.008	0.068	0.003	0.062	0.005
Table 6: Average PD (Mean) with standard deviation (SD) over 10 trials with different seeds per
method. The best performing method in terms of the mean PD is specified by bold face.
Domains (Train → Test)	book → dvd		book → elec		book → kitchen		dvd → elec		dvd → kitchen		elec → kitchen	
DRE method	Mean	SD	Mean	SD	Mean	SD	Mean	SD	Mean	SD	Mean	SD
w/o IW	0.126	0.008	0.174	0.010	0.166	0.009	0.162	0.006	0.146	0.010	0.074	0.005
Kernel uLSIF	0.122	0.009	0.162	0.009	0.159	0.007	0.153	0.006	0.142	0.007	0.068	0.005
Kernel KLIEP	0.130	0.010	0.164	0.009	0.161	0.007	0.154	0.006	0.143	0.006	0.070	0.005
uLSIF-NN	0.126	0.008	0.174	0.010	0.166	0.009	0.162	0.006	0.146	0.010	0.074	0.005
PU-NN	0.126	0.008	0.174	0.010	0.166	0.009	0.162	0.006	0.146	0.010	0.074	0.005
nnBR-LSIF	0.120	0.008	0.160	0.008	0.157	0.008	0.148	0.006	0.138	0.007	0.066	0.005
nnBR-PU	0.119	0.008	0.160	0.008	0.156	0.007	0.148	0.005	0.138	0.007	0.066	0.005
We use a document dataset of Amazon4 (Blitzer et al., 2007) for multi-domain sentiment analy-
sis (Blitzer et al., 2007). This data consists of text reviews from four different product domains:
book, electronics (elec), dvd, and kitchen. Following Chen et al. (2012) and Menon & Ong (2016),
we transform the text data using TF-IDF to map them into the instance space X = R10000
(Salton & McGill, 1986). Each review is endowed with four labels indicating the positivity of the
review, and our goal is to conduct regression for these labels. To achieve this goal, we perform
kernel ridge regression with the polynomial kernel. We compare regression without IW (w/o IW)
with regression using the density ratio estimated by PU-NN, uLSIF-NN, nnBR-LSIF, nnBR-PU,
uLSIF with Gaussian kernels (Kernel uLSIF), and KLIEP with Gaussian kernels (Kernel KLIEP).
We conduct experiments on 2, 000 samples from one domain, and test 2, 000 samples. Following
Menon & Ong (2016), we reduce the dimension into 100 dimensions by principal component anal-
ysis when using Kernel uLSIF, Kernel KLEIP, and regressions. Following Menon & Ong (2016)
and Cortes & Mohri (2011), the mean and standard deviation of the pairwise disagreement (PD),
1 - AUROC, is reported. A part of results is in Table 6. The full results are in Appendix G.3. The
methods with D3RE show preferable performance, but the improvement is not significant compared
with the image data. We consider this is owing to the difficulty of the covariate shift problem in this
dataset.
f -divergence Estimation: f -divergences (Ali & Silvey, 1966; CsiszS 1967) are the discrepancy
measures of probability densities based on the density ratio, hence the proposed method can be used
for their estimation. They include the KL divergence (Kullback & Leibler, 1951), the Hellinger
distance (Hellinger, 1909), and the Pearson divergence (Pearson, 1900), as examples.
Two-sample Homogeneity Test: The purpose of a homogeneity test is to determine if two or
more datasets come from the same distribution (Loevinger, 1948). For two-sample testing, using
a semiparametric f -divergence estimator with nonparametric density ratio models has been studied
4http://john.blitzer.com/software.html
24
Under review as a conference paper at ICLR 2021
(Keziou., 2003; Keziou & Leoni-Aubin, 2005). Kanamori et al. (2010) and Sugiyama et al. (2011a)
employed direct DRE for the nonparametric DRE.
Generative Adversarial Networks: Generative adversarial networks (GANs) are successful deep
generative models, which learns to generate new data with the same distribution as the train-
ing data Goodfellow et al. (2014). Various GAN methods have been proposed, amongst which
Nowozin et al. (2016) proposed f-GAN, which minimizes the variational estimate of f -divergence.
Uehara et al. (2016) extended the idea of Nowozin et al. (2016) to use BR divergence minimiza-
tion for DRE. The estimator proposed in this paper also has a potential to improve the method of
Uehara et al. (2016).
Average Treatment Effect Estimation and Off-policy Evaluation: One of the goals in causal
inference is to estimate the expected treatment effect, which is a counterfactual value. There-
fore, following the causality formulated by Rubin (1974), we consider estimating the average
treatment effect (ATE). Recently, from machine learning community, off-policy evaluation (OPE)
is also proposed, which is a generalization of ATE (Dudiketal., 2011; Imai & Ratkovic, 2014;
Wang et al., 2017; Narita et al., 2019; Bibaut et al., 2019; Kallus & Uehara, 2019; Oberst & Sontag,
2019). OPE has garnered attention in applications such as advertisement design selection, per-
sonalized medicine, search engines, and recommendation systems (Beygelzimer & Langford, 2009;
Li et al., 2010; Athey & Wager, 2017).
The problem in ATE estimation and OPE is sample selection bias. For removing the bias, the density
ratio has a critical role. An idea of using the density ratio dates back to (Rosenbaum, 1987), which
proposed an inverse probability weighting (IPW) method (Horvitz & Thompson, 1952) for ATE esti-
mation. In the IPW method, we approximate the parameter of interest with the sample average with
inverse assignment probability of treatment (action), which is also called propensity score. Here,
it is known that using the true assignment probability yields higher variance than the case where
we use an estimated assignment probability even if we know the true value (Hirano et al., 2003;
Henmi & Eguchi, 2004; Henmi et al., 2007). This property can be explained from the viewpoint of
semiparametric efficiency (Bickel et al., 1998). While the asymptotic variance of the IPW estimator
with an estimated propensity score can achieve the efficiency bound, that of the IPW estimator with
the true propensity score does not.
By extending the IPW estimator, more robust ATE estimators are proposed by Rosenbaum (1983),
which is known as a doubly robust (DR) estimator. The doubly robust estimator is not only robust to
model misspecification but also useful in showing asymptotic normality. In particular, when using
the density ratio and the other nuisance parameters estimated from the machine learning method, the
conventional IPW and DR estimators do not have asymptotic normality (Chernozhukov et al., 2018).
This is because the nuisance estimators do not satisfy Donsker’s condition, which is required for
showing the asymptotic normality of semiparametric models. However, by using the sample split-
ting method proposed by Klaassen (1987), Zheng & van der Laan (2011), and Chernozhukov et al.
(2018), we can show the asymptotic normality when using the DR estimator. Note that for the IPW
estimator, we cannot show the asymptotic normality even if using sample-splitting.
When using the IPW and DR estimator, we often consider a two-stage approach: in the first stage,
we estimate the nuisance parameters, including the density ratio; in the second stage, we construct
a semiparametric ATE estimator including the first-stage nuisance estimators. This is also called
two-step generalized method of moments (GMM). On the other hand, from the causal inference
community, there are also weighting-based covariate balancing methods (Qin & Zhang, 2007; Tan,
2010; Hainmueller, 2012; Imai & Ratkovic, 2014). In particular, Imai & Ratkovic (2014) proposed
a covariate balancing propensity score (CBPS), which simultaneously estimates the density ratio
and ATE. The idea of CBPS is to construct moment conditions, including the density ratios, and
estimate the ATE and density ratio via GMM simultaneously. Although the asymptotic property
of the CBPS is the same as other conventional estimators, existing empirical studies report that the
CBPS outperforms them (Wyss et al., 2014).
Readers may feel that the CBPS has a close relationship with the direct DRE. However,
Imai & Ratkovic (2014) is less relevant to the context of the direct DRE. From the DRE perspective,
the method of Imai & Ratkovic (2014) boils down to the method of Gretton et al. (2009), which pro-
posed direct DRE through moment matching. The research motivation of Imai & Ratkovic (2014)
25
Under review as a conference paper at ICLR 2021
is to estimate the ATE with estimating a nuisance density ratio estimator simultaneously. Therefore,
the density ratio itself is nuisance parameter; that is, they are not interested in the estimation perfor-
mance of the density ratio. Under their motivation, they are interested in a density ratio estimator
satisfying the moment condition for estimating the ATE, not in a density ratio estimator predicting
the true density ratio well. In addition, while the direct DRE method adopts linear-in-parameter
models and neural networks (our work), it is not appropriate to use those methods with the CBPS
(Chernozhukov et al., 2018). This is because the density ratio estimator does not satisfy Donsker’s
condition. Even naive Ridge and Lasso regression estimators do not satisfy the Donsker’s condition.
Therefore, when using machine learning methods for estimating the density ratio, we cannot show
asymptotic normality of an ATE estimator obtained by the CBPS; therefore, we need to use the
sample-splitting method by (Chernozhukov et al., 2018). This means that when using the CBPS, we
can only use a naive parametric linear model without regularization or classic nonparametric kernel
regression. Recently, for GMM with such non-Donsker nuisance estimators, Chernozhukov et al.
(2016) also proposed a new GMM method based on the conventional two-step approach. For these
reasons, the CBPS is less relevant to the direct DRE context.
Off-policy Evaluation with External Validity: By the problem setting of combining causal in-
ference and domain adaptation, Kato et al. (2020) recently proposed using covariate shift adaptation
to solve the external validity problem in OPE, i.e., the case that the distribution of covariates is the
same between the historical and evaluation data (Cole & Stuart, 2010; Pearl & Bareinboim, 2014).
Change Point Detection: The methods for change-point detection try to detect abrupt changes in
time-series data (Basseville & Nikiforov, 1993; Brodsky & Darkhovsky, 1993; Gustafsson, 2000;
Nguyen et al., 2011). There are two types of problem settings in change-point detection, namely the
real-time detection (Adams, 2007; Garnett et al., 2009; Paquet, 2007) and the retrospective detection
(Basseville & Nikiforov, 1993; Yamanishi & Takeuchi, 2002). In retrospective detection, which re-
quires longer reaction periods, Liu et al. (2012) proposed using techniques of direct DRE. Whereas
the existing methods rely on linear-in-parameter models, our proposed method enables us to employ
more complex models for change point detection.
Similarity-based Sentiment Analysis: Kato (2019) used the density ratio estimated from PU
learning for sentiment analysis of text data based on similarity.
I Generalization error b ound
The generalization error bound can be proved by building upon the proof techniques in Kiryo et al.
(2017); Lu et al. (2020).
Notations for the Theoretical Analysis: We denote the set of real values by R and that of positive
integers by N. Let X ⊂ Rd. Let pnu(x) and pde(x) be probability density functions over X, and
assume that the density ratio r* (x) := P：u(X) is existent and bounded: R := ∣∣r*∣∣g V ∞. Assume
0 V C V R. Since R ≥ 1 (because 1 = RPde(x)r*(x)dx ≤ 1 ∙ ∣∣r*h), We have C ∈ (0, 1] and
hence pmod := pde - Cpnu > 0.
Problem Setup: Let the hypothesis class of density ratio be H ⊂ {r : RD → (br, Br) =: Ir},
where 0 ≤ br VRVBr. Let f : Ir → R be a twice ContinUoUSly-differentiable convex function
∙-v	∙-v
with a bounded derivative. Define f by ∂f(t) = C(∂f(t)t — f (t)) + f(t), where ∂f is the derivative
of f continuously extended to 0 and Br. Recall the definitions ' 1(t):= ∂f (t)t — f (t) + A, '2(t):=
26
Under review as a conference paper at ICLR 2021
∙-v
-f(t), and
BRf(r) := Ede [∂f(r(X))r(X) - f(r(X)) + A] - Enu [∂f(r(X))]
=EEmod [∂f (r(X))r(X) - f (r(X)) + 川-Enu [『(r(X))]
=EE mod ' 1( r ( X )) + EnU ' 2( r ( X ))
(=(Ede — CEnU)' 1(r(X)) + EnU'2(r(X))),
nnBRf(r) := P(Emod'ι(r(X))) + EnU'2(r(X))
(ʌ	ʌ	ʌ	X
=P((Ede - CEnu)' 1(r(X)) + Enu'2(r(X))),
ʌ ʌ ʌ
where we denoted Emod = Ede - CEnU and P is a consistent correction function with Lipschitz
constant Lρ (Definition 1).
Remark 4. The true density ratio r^ minimizes BRf.
Definition 1 (Consistent correction function Lu et al. (2020)). A function f : R → R is called a
consistent correction function if it is Lipschitz continuous, non-negative and f(x) = x for all x ≥ 0.
Definition 2 (Rademacher complexity). Given n ∈ N and a distribution p, define the Rademacher
complexity Rpn(H) of a function class H as
1 n
Rn(H) ：= EPEσ sup -、2。理(Xi),
r∈Hni=1
where {σi }in=1 are Rademacher variables (i.e., independent variables following the uniform distri-
bution over { - 1, +1}) and {Xi}rn=ι L吟 p.
The theorem in the paper is a special case of Theorem 3 with P(∙) := max{0, ∙} (in which case
Lρ = 1) and Theorem 4.
Theorem 3 (Generalization error bound). Assume that b` := SuP t∈ιr {max {∖' ι( t) |, ∣' 2( t) ∣}} < ∞.
Assume ' 1 is l`I-LiPschitz and '2 is l`2 -Lipschitz. Assume that there exists an empirical risk
mιnιmιzer r ∈ arg minr∈∏ nnBRf (r) and a population risk minimizer r ∈ arg minr∈∏ BRf (r).
ʌ
Also assume infr∈H EEmod' 1(r(X)) > 0 and that (P — Id) is (LP-id)-Lipschitz. Thenfor any
δ ∈ (0, 1), with probability at least 1 - δ, we have
BRf (r) - BRf (r) ≤ 8LPL' 1 Rnde (H) + 8(LρCL' 1 + L'2)Rnnu (H)
+ 2Φ(C,f,P) (nnU, nde) + B' ^~8
1 (i + LPCy
nnU
log δ,
where Φ(C,f,ρ) (nnU, nde) is defined as in Lemma 2.
G	….	ʌ	∙	∙	∙	-，
Proof. Since r minimizes nnBRf, we have
BRf (r) - BRf (r) = BRf (r) - nnBRf (r) + nnBRf (r) - BRf (r)
___, , —, 、 —, ______________,,
≤ BRf (r) — nnBRf (r) + nnBRf (r) — BRf (r)
≤ 2 sup |nnBRf (r) - BRf (r)|
r∈H
≤
2 sup |nnBRf (r) - EnnBRf (r)| + 2 sup |EnnBRf (r) - BRf (r)| .
r∈H	r∈H
Maximal deviation
Bias
We apply McDiarmid’s inequality McDiarmid (1989); Mohri et al. (2018) to the maximal deviation
term. The absolute value of the difference caused by altering one data point in the maximal deviation
term is bounded from above by 2B'nρ if the altered point is a sample fromPde and 2b` ι+Lρ° if
27
Under review as a conference paper at ICLR 2021
it is from pnu . Therefore, McDiarmid’s inequality implies, with probability at least 1 - δ, that we
have
.---- ， . -------- ，、，
sup |nnBRf (r) - EnnBRf (r)|
r∈H
≤E
|
,--- ， . --------- ，、，
sup |nnBRf (r) - EnnBRf (r)|
r∈H	.
{z
+B'
+
(1 + LPC)
n nu
log δ .
Expected maximal deviation
Applying Lemma 1 to the expected maximal deviation term and Lemma 2 to the bias term, we obtain
the assertion.	□
The following lemma generalizes the symmetrization lemmas proved in Kiryo et al. (2017) and
Lu et al. (2020).
Lemma 1 (Symmetrization under Lipschitz-continuous modification). Let 0 ≤ a < b, J ∈ N, and
{Kj }jJ=1 ⊂ N. Given i.i.d. samples D(j,k) := {Xi}in=(j1,k) each from a distribution p(j,k) over X,
consider a stochastic process S indexed by F ⊂ (a, b)久 OfthefOrm
S(f) = XXPj (XE(c,j)W(j,k)(f(X))] I,
j=1 k=1
where each Pj is a LPj-LiPSChitzfunCtiOn on R, '(j,k)is a Lq 卜)-Lipschitzfunction on (a, b), and
E(i,j) denotes the expectation with respect to the empirical measure of D(j,k). Denote S (f) :=
ES (f) where E is the expectation with respect to the product measure of {D(j,k)}(j,k). Here, the
index j denotes the grouping of terms due to Pj, and k denotes each sample average term. Then we
have
J Kj
E sup S(f) - S(f)| ≤ 4£ fLρjL'(j,k)Rn(j,k),p(j,k) (F).
f∈F	j =1 k=1
Proof. First, we consider a continuous extension of `(j,k) defined on (a, b) to [0, b). Since the
functions in F take values only in (a, b), this extension can be performed without affecting the
ʌ
values of S(f) or S(f). We extend the function by defining the values for x ∈ [0, a] as '(j,k)(x):=
lim x，，a '(j,k)( χ0), where the right-hand side is guaranteed to exist since '( j,k)is LiPSchitz continuous
hence uniformly continuous. Then, `(j,k) remains a LPj -Lipschitz continuous function on [0, b).
Now we Perform symmetrization (VaPnik, 1998), deal with Pj ’s, and then bound the symmetrized
Process by Rademacher comPlexity. Denoting indePendent coPies of {X(j,k)} by {Xj(,gkh)}(j,k) and
28
Under review as a conference paper at ICLR 2021
the corresponding expectations as well as the sample averages with (gh) ,
ʌ
E sup ∣S( f) - S(f)I
f∈F
J	Kj	Kj
≤ EE sup S (E E( ij)`j)( f (X))) - E(gh) Pj (E E (fhk))`j)( f (X(gh))))I
j=1 f∈F	k=1	k=1
J	Kj	Kj
≤ ∑EE(gh) sup IPj(EE(ij)'(j,k)(f(X))) - Pj(EE(gh))'(j,k)(f(X(gh))))I
j=1	f∈F k=1	k=1
J	Kj
≤ fLρj EEE(gh) sup IE (i,j)' (j,k) (f (X)) - E (ghf))' (j,k)(f (X (M)) I
j=1	k=1	f∈F
J	Kj
=fLρj EEE(gh) sup IE (i,j)(' (j,k)(f (X)) - ' (j,k) (0)) - E (gh)( '(j,k)(f (X(gh))) - ' (j,k )(0)) I
j=1	k=1	f∈F
J	Kj
≤	Lρj	2Rn
(j,k) ,p(j,k) ({ (j,k) ◦ f - (j,k) ()：f ∈F}))
j=1	k=1
J	Kj
≤ TLQ ∙ T 2 ∙ 2 L'l. R Rn …(F), (F),
ρj	`(j,k) n(j,k) ,p(j,k),
j=1 k=1
where we applied Talagrand’s contraction lemma for two-sided Rademacher complexity
(Ledoux & Talagrand,1991; Bartlett & Mendelson, 2001) with respect to (t 1 'j,k)(t) - 'j,k)(0))
in the last inequality.	□
ʌ
Lemma 2 (Bias due to risk correction). Assume infr∈H EEmod'ι(r(X)) > 0 and that (P - Id) is
(Lρ-Id )-Lipschitz on R. There exists α > 0 such that
2α2
ruH i EnnBR f r)- BR f (r) i ≤(1 + g ) B'Lρ-Id exp --(B‰)+C⅛‰))
=: Φ(C,f,ρ) (nnu, nde).
Remark 5. Note that We already have Pmod ≥ 0 and 'ι ≥ 0 and hence infr∈H EEmod'ι(r(X)) ≥
0. Therefore, the assumption of Lemma 2 is essentially referring to the strict positivity of the in-
ʌ
fimum. Here, EEmod and P (∙) denote the expectation and the probability with respect to the joint
ʌ
distribution of the samples included in Emod .
Proof. Fix an arbitrary r ∈ H. We have
IEnnBRf (r) - BRf (r)I = IE[nnBRf (r) - BdRf (r)]I
ʌ	ʌ	「人	ʌ	I
IE[P(Emod'ι(r(X))) - Emod'ι(r(X))]∣ ≤ E [∣ρ(Emod'ι(r(X))) - Emod' 1 (r(X))∣J
[ʌ ʌ ʌ ʌ ∖
1{p(Emod'ι(r(X))) = Emod'ι(r(X))}∙ ∣p(Emod'ι(r(X))) - Emod'ι(r(X))∣]
≤E
[l{ρ (E mod ' ι( r (X))) = E mod ' ι( r (X)) }
sup
」∖s: ∣s∣≤ (1+ C) b`
IP(s) -
sI
ʌ
where 1{∙} denotes the indicator function, and we used ∣Emod'ι(r(X)) ∣ ≤ (1 + C)b`. Further, we
have
sup	IP(s) - sI ≤ sup	I(P - Id)(s) - (P - Id)(0)I + I(P - Id)(0)I
S: ∣s∣≤ (1+C) B'	S: ∣s∣≤ (1+C) B'
≤ SUP	LP-Id∣6 - 0I +0 ≤ (1 + C)B'Lρ-Id,
S ： ∣ s∣≤(1+C)B`
29
Under review as a conference paper at ICLR 2021
ʌ
where Id denotes the identity function. On the other hand, since infr∈H EEmod'ι(r(X))〉0 is
ʌ
assumed, there exists α〉0 such that for any r ∈ H, EEmod'ι(r(X)) > α. Therefore, denoting
the support of a function by supp(∙),
E [1 {ρ(Emod'ι(r(X))) = Emod'ι(r(X))}i = P (Emod'ι(r(X)) ∈ supp(ρ - Id))
≤ P (Emod'ι(r(X)) < 0)≤ P (Emod'ι(r(X)) < EEmod'ι(r(X)) - α)
holds. Now we apply McDiarmid’s inequality to the right-most quantity. The absolute difference
caused by altering one data point in Emod'ι(r(X)) is bounded by B if the change is in a sample
nde
from Pde and CnB otherwise. Therefore, McDiarmid,s inequality implies
P(Emod`1 (r(X)) <eEmod' 1(r(X))-a) ≤exp(-B‰yq2α(⅛¾U)) ∙
□
Theorem 4 (Generalization error bound). Under Assumption 3, for any δ ∈ (0, 1), with
probability at least 1 — δ, we have BRf(r) — BRf (r) ≤ l`iRndee(H) + 8(CL'ι +
L'2)RnU (H) + 2φC(nnu,nde) + B'5(十 + 跺宇)Iog1, where ΦC(nnu,nde) ：= (1 +
C)B' exp (一(b`2n壮)+,：2b`2n—)) and α > 0 is a Constant determined in the ProofofLemma 2
in Appendix I.
Remark 6 (Explicit form of the bound in Theorem 1). Here, we show the explicit form of the bound
in Theorem 1 as follows:
BR f (r) — BR f (r)
≤ -K^ + ^K= + 2ΦC(nnu, nde) + B' Jg (上+。+ C)) log1
√nde	√nnU	V ∖n de	n nu ) δ
Bpde (P2log(2)L +1) QL=1 BWj
=L' 1-----------^=-----------
ʌ/nde
Bpnu (P2log(2)L + 1) QL=1 BWj
+ 8(CL' 1 + L'2 )-------,-------------
√nnU
+ (1 + C)B' exp (一 (B'2 In de)+α C 2 B'2 In 口口))
+B' S87X+∏≡0gI ∙
nde	nnu	δ
J Rademacher Complexity B ound
The following lemma provides an upper-bound on the Rademacher complexity for multi-layer per-
ceptron models in terms of the Frobenius norms of the parameter matrices. Alternatively, other
approaches to bound the Rademacher complexity can be employed. The assertion of the lemma fol-
lows immediately from the proof of Theorem 1 of Golowich et al. (2019) after a slight modification
to incorporate the absolute value function in the definition of Rademacher complexity.
Lemma 3 (Rademacher complexity bound (Golowich et al., 2019, Theorem 1)). Assume the distri-
bution p has a bounded support: Bp ：= supx∈supp(p) kxk < ∞. Let H be the class of real-valued
networks of depth L over the domain X, where each parameter matrix Wj has Frobenius norm at
most Bwj ≥ 0, and with 1 -Lipschitz activation functions ψj which are positive-homogeneous (i.e.,
夕j is applied element-wise and 夕j (0t) = αψj (t) for all a ≥ 0). Then
Rpn(H) ≤
bp (p2 log(2)L + 1) Qj= BWj
30
Under review as a conference paper at ICLR 2021
Proof. The assertion immediately follows once we modify the beginning of the proof of Theorem 1
by introducing the absolute value function inside the supremum of the Rademacher complexity as
Eσ sup
r∈H
n
σir(xi)
i=1
≤ λ log Eσ sup exp I λ
i=1 σir(xi)	.
for λ〉0. The rest of the proof is identical to that of Theorem 1 of GoIoWich et al. (2019).	□
K Proof of Theorem 2
We consider relating the L2 error bound to the BR divergence generalization error bound in the
folloWing lemma.
Lemma 4 (L2 distance bound). Let H := {r : X → (br, Br) =: Ir| |r(x)|2dx < ∞} and
assume r^ ∈ H. If inf t∈ιr f00 (t) > 0, then there exists μ > 0 such that for all r ∈ H,
Ir 一门IL2(Pde) ≤ 2 (BRf (r) - BRf (r*))
μ
holds.
Proof. Since μ := inft∈ιr f00(t) > 0, the function f is μ-strongly convex. By the definition of
strong convexity,
BRf(r) - BRf (r*) = (BRf(r) - Edef(r*(X))) - (BRf (r*) + Edef(r*(X)))
|-----------------------------------------------------{z----------}
=0
= Ede [f(r*(X)) - f(r(X)) + ∂f(r(X))(r*(X) - r(X))]
≥ Edeh2(r*(X) - r(X))2i = 2Ir* - WL。(Pde”
□
Lemma 5 (`2 distance bound). Fix r ∈ H. Given n samples {xi}in=1 from pde, with probability at
least 1 - δ, we have
ɪ XX (r (Xi )—r* (Xi ))2 ≤ E [(T-r* )2( X)]+(2 R) )2 ∖/10^.
n i=1	X-----{z-----} V n
=iU L 2( P de)
Proof. The assertion follows from McDiarmid,s inequality after noting that altering one sample
results in an absolute change bounded by 1 (2R)2.	□
Thus, a generalization error bound in terms of BRf can be converted to that of an L2 distance
when the true density ratio and the density ratio model are square-integrable and f is strongly
convex. However, when using the result of Theorem 1, the convergence rate shown here is
slower than OP (min {nde,nnu})-1/(4) . On the other hand, Kanamori et al. (2012) derived
Op ((min {nde, nnu}) —1 /(2+Y)) convergence rate. To derive this bound when using neural network,
we need to restrict the neural network models. In the following part, we prove Theorem 2 for the
following hypothesis class H.
Definition 3 (ReLU neural networks; Schmidt-Hieber, 2020). For L ∈ N andp = (p0, . . . , pL+1) ∈
NL+2,
F(L,p) ：={f ： x → WLσvL Wl-igvl7 …Wισv】WɔX :
Wi ∈ RPi+1×Pi,vi ∈ RPi(i = 0, . . . , L)},
where σv(y) := σ(y — V), and σ(∙) = max{∙, 0} is applied in an element-wise manner. Then, for
s ∈ N,F ≥ 0,L ∈ N,andp ∈ NL+2, define
L
H(L, p, s, F) := {f ∈ F(L, p) : X IWj I0 + Ivj I0 ≤ s, IfI∞ ≤ F},
j=0
31
Under review as a conference paper at ICLR 2021
where ∣∣ ∙ ∣∣0 denotes the number of non-zero entries of the matrix or the vector, and ∣∣ ∙ ∣∣m denotes
the supremum norm. Now, fixing L,p,s ∈ N as well as F > 0, we define
IndL,p := {(L,p) : L ∈ N,L ≤ L,p ∈ [p]L+2},
and we consider the hypothesis class
H ：= U	HIL,p,s, F)
(L,p) EInd L ,p
H := {r ∈ H : Im(r) U (br, Br)}.
Moreover, we define 11 : IndLP → R and I: HT [0, ∞) by
11(L,p) :=21IndL,p| ⅛1 (L + 1)V2,
I(r) := max < ∣r∣∞,	min	11(L,p)卜，
I	(L，P) ∈Ind L ,p	I
I	rEH (L,p,s,F)	)
where V := QLZ01(pi + 1), and we define
HM := {r ∈Η : I (r) ≤ M}.
Note that the requirement for the hypothesis class of Theorem 1 is not as tight as that of Theorem 2.
Then, we prove Theorem 2 as follows:
Proof. Thanks to the strong convexity, by Lemma 4, we have
2∣r _r*||L2(Pde) ≤ BRf (r) - BRf (r*)
=BRf (r) - BRf (r*)
-BRf (r) + BRf (r) -nnBRf (r) + nnBRf (r) -BRf (r*) + BRf (r*)
|--------V------}|--------V----------}|---------V-------Z
=0	= 0	= 0
≤ BRf (r) - BRf (r) + (BRf (r) - nnBRf (r))
.-- . .. -. ... -... ...
+ (nnBRf (r*) - BRf (r*)) + BRf (r*) - BRf (r*)
≤ (BRf (r) - BRf (r*) + BRf (r*) - BRf (r)) + 2sup |BRf (r) - nnBRf (r) |,
1---------------V----------------}	rWH
=:A	X---------V---------Z
=:B
where we used nnBRf (r) ≤ nnBRf (r*). To bound A, for ease of notation, let `r = ' 1(r(X)) and
`r = '2(r(X)). Then, since
BR f (r )= Ede 0 1( r (X)) - C EnU 0 1( r (X)) + EnU 0 2( r (X)),
.. ʌ .... ʌ .... ʌ ....
BR f (T )= E de Q 1( r (X)) - C EnU Q 1( r (X)) + EnU Q 2( r (X)),
we have
A = BRf (r) - BRf (r*) + BRf (r*) - BRf (r)
,	ʌ . , .<	.. *.	,	ʌ . , ʌ	.. *.	,	ʌ	ʌ	.. *.
=(Ede - Ede)(`r - Qr)- C(Enu - Enu)('λ - 4 ) + (EnU - Enu)(Qr - '2 )
.,	ʌ . , ʌ .. * . .	. ,	ʌ . , .<	.. * . .	. ,	ʌ . , .<	.. * ..
≤ I (Ede - E de)( 0, - Qr) | + C | (EnU - E nj( 0, - Qr) | + | (EnU - E nj(' -也)|
By applying Lemma 10, for any 0 <γ < 2, we have
A ≤Op
f ∣r -r*∣L£
max < —	,
I √min {nde, n nU}
1
(min {n de ,n nU } )2 1(2+Y)
32
Under review as a conference paper at ICLR 2021
ʌ
On the other hand, by Lemma 12 and Lemma 7, and the assumption inf『三乂 EEmod' 1 (r(X)) > 0,
there exists α > 0 such that we have B ≤ OP exp
above bounds on A and B, for any 0 < γ < 2, we get
2 α 2
	
(b` 2/n de) + (C 2 b` 2/n nu)
. Combining the
疗-E k-\
kr -叫 L 2( P de) ≤ O P max
√min {n de ,n
+ OP exp
nu} , (min {nd
2α2
1
Ie ,n nu})2/(2+ Y)
(B' 2 /n de) + ( C2 B' 2/n nu)
	
≤ Op (maj	, 一 ∖s)
∖ I Pmin{nde7nnU} (min {n de,n nu})21 (2+ +)
As a result, we have
□
Each lemma used in the proof is provided as follows.
K. 1 Complexity of the hypothesis class
For the function classes in Definition 3, we have the following evaluations of their complexities.
Lemma 6 (Lemma 5 in Schmidt-Hieber (2020)). For L ∈ N andp∈ NL+2, letV := QlL=+01(pl+1).
Then, for any δ > 0,
log N (δ, H (L,p, S, ∞), k ∙ k∞) ≤ (S + 1) log(2 δ-1( L + 1) V2).
Lemma 7. There exists c > 0 such that
RPnnnuu(H) ≤ cnn-u1/2,	RPnddee(H) ≤ cnd-e1/2.
Proof. By Dudley’s entropy integral bound (Wainwright, 2019, Theorem 5.22) and Lemma 6, we
have
Rpnnnuu (H(L, p, s, F)) ≤32Z02F
log N 电 H WpsF) J∙h) dδ
nnu
=卜2 Z0F ((S +1) log(2δ-1(L + 1) V2))1/2 d)n-112
Therefore, there exists c > 0 such that
RPnnnuu(H) ≤	RPnnnuu (H(L, p, S, F)) ≤ cnn-u1/2
(L,P) EInd L ,p
The same argument applies to Rpnddee (H), and we obtain the assertion.
Lemma 8. There exists c0 > 0 such that for any γ > 0, any 6 > 0, and any M ≥ 1, we have
□
and
logN(6,Hm,∣H∣g) ≤
S+1 M γ
~δ~^)
sup Ilr - r"^k∞
r∈HM
≤ c0M.
33
Under review as a conference paper at ICLR 2021
Proof. The first assertion is a result of the following calculation:
logN 3, Hm,∣H岛)≤ log X	N 3, H(L,p,s,M), ∣∏岛)
(L,p ) ∈ Ind L P
11( L,p) ≤M
≤ log X	(δ(L+1)V2)s+1
(l,p)∈IndL p
11( L,p) ≤M
≤ log |IndL,p| 0M|IndL,p-s⅛) 十
<	M	(M∖	<	,、1 (M Yt
=(S + 1)log(万)< (S + 1)Y ⑺,
where the first inequality follows from HM U U(L,p)∈indL -：iι(L,p)≤m H(L,p, s, F), and the last
1	,
inequality from Y log x Y = log x < x that holds for all x, γ > 0.
The second assertion can be confirmed by noting that for any r ∈ HM with M ≥ 1,
什-r*h∞ ≤ IIrh + ∣∣r*k ≤ M + ∣∣r*h
≤ (1 + lrMτ) M ≤ (1 + ∣r*h)M
holds.
□
Definition 4 (Derived function class and bracketing entropy). Given a real-valued function class F,
define ' ◦ F := {' ◦ f : f ∈ F}. By extension, we define I : ' oH → [1, ∞) by I (' ◦ r) = I (r)
and ' ◦ HM ：= {' ◦ r : r ∈ HM}. Note that, as a result, ' ◦ HM coincides with {' o r ∈ ' ◦ H :
I (' o r) ≤ M }.
Lemma 9. Let ' : (br, Br) T R be a V-LiPSChitZ continuous function. Let HB (δ, F ,∣∣∙ IlL 2( P))
denote the bracketing entropy of F with respect to a distribution P. Then, for any distribution P,
any γ > 0, any M ≥ 1, and any δ > 0, we have
Hb (δ,' oHm,|HL2(P)) ≤ (S +；(2V厂(M[
Moreover, there exists c 0 > 0 such that for any M ≥ 1 and any distribution P,
sup l` o r - ` o r*∣L2(P) ≤ c0νM,
20r∈'0HM
sup ll` o r — ` o r*∣∞ ≤ c0νM, for all δ > 0.
0or∈'oH M
k'or-'or* ∣∣l2(P)≤δ
Proof. By combining Lemma 2.1 in van de Geer (2000) with Lemma 6, we have
hb (δ, ` o hm, ∣∣∙ IIL2(p)) ≤ logN Q,` o hm, ∣∣∙ Il∞),
1 J δ ~ ll ll ʌ S + 1，2νM∖ Ct
≤logN(2? Hm, l'l∞) ≤ ~ {~) .
For M ≥ 1, we have
sup	ll` o r — ` o r*∣∣L2(P) ≤ sup ∣∣' o r — ` o r*∣∣∞
'or∈'o∏M	'or∈'o∏M
sup ll` o r — ` o r*∣∞ ≤ sup ∣∣' o r — ` o r*∣∞,
2or∈'oH M	'or∈'θH,M
k'θr-'θr^kL 2( P) ≤δ
and Lemma 6 implies
sup ll` o r — ` o r*∣∞ ≤ sup Vllr — r*∣∞ ≤ νc0M.
'or∈'o∏M	r∈∏M
□
34
Under review as a conference paper at ICLR 2021
K.2 Bounding THE empirical deviations
Lemma 10. Under the conditions of Theorem 2, for any 0 < γ < 2, we have
.,	ʌ . , .<	*.. I (Ede - Ede)(e`r 一 '1 ) | =	o (八r 一21二 1 -PlmaX I	m	, nde(2+Y)
* I (EnU- E nu)( Pr - '1 ) ∣ =	o (	f ∣r - r*kLPe)	1 .PlmaX I	E	, nnu(2++)
* ∣ (EnU- E nu)( '2 - '2 ) I =	o (	f ∣r - r*kLPe)	1 PlmaXI k	, nnu(2+Y)
as nnu, nde → ∞.
Proof. Since 0 < γ < 2, we can apply Lemma 11 in combination with Lemma 9 to obtain
	* I (Ede- E de)( 42-'2 ) I B G SUP	斤7、	= oP (1), r∈H	D 1( r ) 		 ʌ , , . 一 * 、, I (Enu - Enu)('r-'r) I SUP	万一厂、	=oP (1), r∈H	D 2( r ) 		 ʌ , , . . * ,. I (Enu - E nu)( 'r -'r ) I	G sup	rΓΓ~∖	= op (1), r∈H	D 3( r )
where
D1(r)	I k'1 - ''1 * kL-蓝)i(CB2 I(`r)] =max I	√nde	, n^,
D2(r)	=maJ k'r- 'r*kL-PU)i(U2 i(`r)] =max I	√nu	,萧不,
D3(r)	=maJ k'r - `*kL-PU)i(E2 i(纷 \ =maxI	√nu	,萧尸i,
Noting that supr∈n I(r) < ∞, that '2,0 1 are Lipschitz continuous, and that ^r 一 r*∣L2(Pnu)
卜UPMK I P^ D l∣r 一 r* IL2(pde) holds, we have the assertion.
≤
□
Following is a proposition originally presented in van de Geer (2000), which was rephrased in
Kanamori et al. (2012) in a form that is convenient for our purpose.
Lemma 11 (Lemma 5.14 in van de Geer (2000), Proposition 1 in Kanamori et al. (2012)). Let F U
L 2( P) be a function class and the map I (f) be a complexity measure of f ∈ F, where I is a non-
negativefunction on F and I (f0) < ∞ for a fixed f0 ∈ F. We now define FM = {f ∈ F : I (f) ≤
M} satisfying F = UM ≥ 1 FM. Suppose that there exist c 0 > 0 and 0 <γ < 2 such that
sup ∣∣f 一 f0Il ≤ c0M, sup ∣∣f 一 f0∣∣m ≤ c0M, forall δ > 0,
f∈Fm	f∈fm
kf-f 0 必 2( P) ≤δ
and that HB (δ, FM, P) = O (M∕δ)γ. Then, we have
IR (f - f0) d (P - Pn )| c ⑴:、
sup J--------------------L = O P (1),(n → ∞),
f ∈F	D(f)
35
Under review as a conference paper at ICLR 2021
where D(f) is defined by
Df、= J "-f0 H kL-P / I (f f)γ 2	I( f)
Dif) = max 1	√n	, n2/(2+Y)
K.3 B ounding the difference of the BR divergence estimators
Lemma 12. Assume Rpnddee (H) = O(1)(nde → ∞) and Rpnnnuu (H) = O(1)(nnu → ∞). Also assume
the same conditions as Theorem 3. Then,
sup |n\nBRf (r) - BdRf (r)| = OP
r∈H
c『2	2 a2
exp I- (B'/nde) + (C2B'/nnu)
as nnu, nde → ∞.
Proof. First, by combining Lemma 13, the assumption on the Rademacher complexities, and
Markov’s inequality, there exist α> 0 andn0de, n0nu ∈ N such that for any nde ≥ n0de and nnu ≥ n0nu
and any δ ∈ (0, 1), we have with probability at least 1 - δ,
sup |nnBRf (r) - BdRf (r)| ≤
r∈H
(1 + C)B'Lρ-id 笑(	2a2
^	exp I- (BJ/nde) + (C2Bj/nnu)
Therefore, we have the assertion.
□
Lemma 13. Assume Rpnddee (H) = O(1)(nde → ∞) and Rpnnnuu (H) = O(1)(nnu → ∞). Also assume
the same conditions as Theorem 3. Then, there exist α > 0 and n0de , n0nu ∈ N such that for any
nde ≥ n0de and nnu ≥ n0nu,
2α2
E SUp InnBRf(T) - BRf(T) I ≤ (1 + C)BeLP-Id exp -7—ŋ~~一(「”2 ∣—；
r∈H	_l	∖ (Belnde) + (C Belnnu) J
holds.
Proof. First, we have
_ .-------- , 、 ≤≈-,,,
E SUp InnBRf (T ) - BdRf (T)I
r∈H
=E SUp IP (E mod ' k( T ( X ))) - E mod ' k ( T ( X ))1
r∈H
=E SUp 1{P (E mod ' k( T ( X ))) = E mod ' k( T ( X )) } ∙ ∣ρ (E mod ' k( T ( X ))) — E mod ' k ( T ( X )) ∣
r∈H
≤ E SUp 1{P(Emod'k(T(X))) = Emod'k(T(X))} ( SUp	∣ρ(S) — S∣ ),
r∈H	」∖s: ∣s∣≤ (k + C)B'	I
ʌ
where {}∙} denotes the indicator function, and We used ∣Emod'k(T(X)) ∣ ≤ (1 + C)Be. Further, We
have
SUp	∣ρ(s) - s∣ ≤ SUp	∣(ρ - Id)(s) - (ρ - Id)(0)∣ + ∣(ρ - Id)(0)∣
S: ∣s∣≤ (k+C) b`	S ： ∣s∣≤ (k+C) b`
≤ SUp	Lρ-Id∣s - 0∣ + 0 ≤ (1 + C)Be Lρ-Id,
S: ∣ s∣≤ (k+C) b`
ʌ
where Id denotes the identity function. On the other hand, since infr∈H EEmod'k(t(X))〉0 is
ʌ
assumed, there exists β > 0 such that for any T ∈ H, EEmod'k(T(X)) > β. Therefore, denoting
36
Under review as a conference paper at ICLR 2021
the support of a function by supp(∙),
ʌ ʌ
E sup 1{夕(Emod'ι(r(X))) = Emod'ι(r(X))}
r∈H
ʌ
=E sup {^Emod'ι(r(X)) ∈ supp(ρ -Id)}
r∈H
ʌ
=E sup {^Emod'ι(r(X)) < 0}
r∈H
=E [ 1{% ∈ H : Emod'ι(r(X)) < 0}]
=P Gr ∈H : E mod' ι( r (X)) < 0)
≤ P (∃r ∈ H : Emod'ι(r(X)) < eEmod'ι(r(X)) - β)
≤ P β< < SuP(EEmod'ι(r(X)) - Emod'ι(r(X)))) ∙
r∈H
Take an arbitrary α ∈ (0, β). Since Rpde(H) → 0(nde → ∞) and Rnnu(H) → 0(nnu → ∞), We
can apply Lemma 14 and obtain the assertion.	□
Lemma 14. Let β > α > 0. Assume that there exist n0de, n0nu ∈ N such that for any nde ≥ n0de and
nnu ≥ n0nu,
4 l` ι Rnde (H) + 4 CL' ι Rnnu (H) <β - α.
Then, for any nde ≥ n0de and nnu ≥ n0nu, we have
P (β < SuP(EEmod' 1 (r(X)) - Emod'ι(r(X))))
r∈H
(	2 ɑ2	λ
≤ exp I- (B'2/nde) + (C2B'2/nnu) J
Proof. First, We Will apply McDiarmid’s inequality. The absolute difference caused by altering one
data point in supr∈n(EEmod'ι(r(X)) - Emod'ι(r(X))) is bounded by Bl if the change is in a
sample from Pde and cb' otherwise. This can be confirmed by letting Emod denote the sample
nnu	mod
ʌ
averaging operator obtained by altering one data point in Emod and observing
ʌ ʌ ʌ ʌ
sup{EEmod'ι(r(X)) - Emod'ι(r(X))} - sup{EEmod'ι(r(X)) - Emod'ι(r(X))}
r∈H	r∈H
≤ sup{EEmod'ι(r(X)) - Emod'ι(r(X)) - (EEmod'ι(r(X)) - Emod'ι(r(X)))}
r∈H
,ʌ. . , _________. ʌ . , ________
≤ sup{Emod'ι(r(X)) - Emod'ι(r(X))}.
r∈H
The right-most expression can be bounded by 著 if the change is in a sample from Pde and CnB'
otherwise. Likewise, sup丁三乂(EEmod'ι(r(X)) - Emod'ι(r(X))) - sup丁三乂(EEmod'ι(r(X))-
Emod'ι (r(X))) can be bounded by one of these quantities. Therefore, we have
ʌ ʌ ʌ ʌ
sup{EEmod'ι(r(X)) - Emod'ι(r(X))} - sup{EEmod'ι(r(X)) - Emod'ι(r(X))}
r∈H	r∈H
≤ B + CB,
and McDiarmid’s inequality implies, for any > 0,
J 一	3	______ 」一	3	_..____n
P e < sup(EEmod'ι(r(X)) - Emod'ι(r(X))) - E sup(EEmod'ι(r(X)) - Emod'ι(r(X)))
r∈H	r∈H
≤ exp 卜(B'2Inde) + (C2B'2Innu)).
(10)
37
Under review as a conference paper at ICLR 2021
Now, applying Lemma 1, we have
ʌ ʌ
E sup(EEmod0 1(r(X)) — EmQd0 1(r(X)))
Lr∈¾	」
ʌ ʌ
≤ E sup IEde0 1(r(X)) — Ede0 1(r(X)) | + CE sup |E∏u'ι(r(X)) — EnU0 1(r(X)) |
r∈H	_|	Lr∈H	.
≤ 4 Le ι R氏(H )+4 CLe 1 RnU (H )=: R.
By the assumption, if nde ≥ nde and nnu ≥ nRu, We have R < β — α. Therefore,
ʌ ʌ
E sup(EEmodC 1(r(X)) — EmodC 1(r(X))) <β — α < β,
r∈H	_
hence β — E 卜up,∈%(EEmodC 1(r(X)) — EmodC 1(r(X)))]
> 0. Therefore, we can take E
β —
E [supr∈H (EEmodC 1(r(X)) — EmodC 1(r (X)))]
in Equation (10) to obtain
≤ exp
P ( β < SUP(EE mod C 1( r (X)) — E mod C 1( r (X))))
∖ r∈H	)
2(β — E [supr∈H(EEmodC 1(r(X)) — EmodC 1(r(X)))])2
(Be In de) + (C 2 Be In nu)
,	2( β — R )2	ʌ 2	2 α2
≤ exp≤ exp
一 1(Be2/nde) + (C2Be2/nnu) J -	1(BJ/nde)+ (C2BJ/nnu)
where we used 0 < α < β — R.
□
38