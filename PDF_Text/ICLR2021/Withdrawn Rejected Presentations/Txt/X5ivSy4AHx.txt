Under review as a conference paper at ICLR 2021
Enhanced First and Zeroth Order Variance
Reduced Algorithms for Min-Max Optimiza-
TION
Anonymous authors
Paper under double-blind review
Ab stract
Min-max optimization captures many important machine learning problems such
as robust adversarial learning and inverse reinforcement learning, and nonconvex-
strongly-concave min-max optimization has been an active line of research. Specif-
ically, a novel variance reduction algorithm SREDA was proposed recently by
(Luo et al. 2020) to solve such a problem, and was shown to achieve the optimal
complexity dependence on the required accuracy level . Despite the superior
theoretical performance, the convergence guarantee of SREDA requires stringent
initialization accuracy and an -dependent stepsize for controlling the per-iteration
progress, so that SREDA can run very slowly in practice. This paper develops a
novel analytical framework that guarantees the SREDA’s optimal complexity per-
formance for a much enhanced algorithm SREDA-Boost, which has less restrictive
initialization requirement and an accuracy-independent (and much bigger) stepsize.
Hence, SREDA-Boost runs substantially faster in experiments than SREDA. We
further apply SREDA-Boost to propose a zeroth-order variance reduction algorithm
named ZO-SREDA-Boost for the scenario that has access only to the information
about function values not gradients, and show that ZO-SREDA-Boost outperforms
the best known complexity dependence on . This is the first study that applies the
variance reduction technique to zeroth-order algorithm for min-max optimization
problems.
1 Introduction
Min-max optimization has attracted significant growth of attention in machine learning as it captures
several important machine learning models and problems including generative adversarial networks
(GANs) Goodfellow et al. (2014), robust adversarial machine learning Madry et al. (2018), imitation
learning Ho & Ermon (2016), etc. Min-max optimization typically takes the following form
min max f(x, y), where f(x, y) ,
x∈Rd1 y∈Rd2
E[F (x, y; ξ)]
(online case)
1 Pn=I F(x, y； ξi) (finite-sum case)
(1)
where f(x, y) takes the expectation form if data samples ξ are taken in an online fashion, and f(x, y)
takes the finite-sum form if a dataset of training samples ξi for i = 1, . . . , n are given in advance.
This paper focuses on the nonconvex-strongly-concave min-max problem, in which f (x, y) is
nonconvex with respect to X for all y ∈ Rd1 2, and f (x, y) is μ-strongly concave with respect to y for
all x ∈ Rd1 . The problem then takes the following equivalent form:
min Φ(x) , max f(x, y) .
x∈Rd1	y∈Rd2
(2)
The objective function Φ(∙) in eq. (2) is nonconvex in general, and hence algorithms for solving eq. (2)
are expected to attain an approximate (i.e., -accurate) first-order stationary point. The convergence
of deterministic algorithms for solving eq. (2) has been established in Jin et al. (2019); Nouiehed
et al. (2019); Thekumparampil et al. (2019); Lu et al. (2020). SGD-type of stochastic algorithms have
also been proposed to solve such a problem more efficiently, including SGDmax Jin et al. (2019),
1
Under review as a conference paper at ICLR 2021
PGSMD Rafique et al. (2018), and SGDA Lin et al. (2019), which respectively achieve the overall
complexity of O(κ3-4 log(1/))1, O(κ3-4), and O(κ3-4).
Furthermore, several variance reduction methods have been proposed for solving eq. (2) for the
nonconvex-strongly-concave case. PGSVRG Rafique et al. (2018) adopts a proximally guided SVRG
method and achieves the overall complexity of O(κ3-4) for the online case and O(κ2n-2) for the
finite-sum case. Wai et al. (2019) converted the value function evaluation problem to a specific min-
max problem and applied SAGA to achieve the overall complexity of O(κn-2) for the finite-sum
case. More recently, Luo et al. (2020) proposed a novel nested-loop algorithm named Stochastic
Recursive Gradient Descent Ascent (SREDA), which adopts SARAH/SPIDER-type Nguyen et al.
(2017a); Fang et al. (2018) of recursive variance reduction method (originally designed for solving the
minimization problem) for designing gradient estimators to update both x and y. Specifically, x takes
the normalized gradient update in the outer-loop and each update of x is followed by an entire inner-
loop updates of y. Luo et al. (2020) showed that SREDA achieves an overall complexity of O(κ3-3)
for the online case in eq. (1), which attains the optimal dependence on e Arjevani et al. (2019). For
the finite-sum case, SREDA achieves the complexity of O(κ2√ne-2 + n + (n + k)log(κ∕e)) for
n ≥ κ2, and O((κ2 + κn)e-2) forn ≤ κ2.
Although SREDA achieves the optimal complexity performance in theory, two issues may sub-
stantially degrade its practice performance. (1) SREDA has a stringent requirement on the ini-
tialization accuracy Z = κ-2e2, which hence requires O(κ2e-2 log(κ∕e)) gradient estimations
in the initialization, and is rather costly in the high accuracy regime (i.e., for small e). (2) The
convergence of SREDA requires the stepsize to be substantially small, i.e., at the e-level with
at = O(min{e∕(κ' ∣∣vtk2), 1∕(κ')}), which restricts each iteration to make only e-level progress
with ∣∣xt+ι - xtk2 = O(e∕κ'). Consequently, SREDA can run very slowly in practice.
•	Thus, a vital question arising here is whether we can guarantee the same optimal complexity
performance of SREDA even if we considerably relax its initialization (i.e., much bigger than
O(e2 )) and enlarge its stepsize (i.e., much bigger than O(e)). The answer is highly nontrivial
because the original analysis framework for SREDA in Luo et al. (2020) critically relies on these
restrictions. The first focus of this paper is on developing a novel analytical framework to guarantee
that such enhanced SREDA continues to hold the SREDA’s optimal complexity performance.
Furthermore, in many machine learning scenarios, min-max optimization problems need to be solved
without the access of the gradient information, but only the function values, e.g., in multi-agent
reinforcement learning with bandit feedback Wei et al. (2017); Zhang et al. (2019) and robotics
Wang & Jegelka (2017); Bogunovic et al. (2018). This motivates the design of zeroth-order (i.e.,
gradient-free) algorithms. For nonconvex-strongly-concave min-max optimization, Liu et al. (2019)
studied a constrained problem and proposed ZO-min-max algorithm that achieves the computational
complexity of O((d1 + d2)e-6). Wang et al. (2020) designed ZO-SGDA and ZO-SGDMSA, where
ZO-SGDMA achieves the best known query complexity of O((d1 + d2)κ2e-4 log(1∕e)) among the
zeroth-order algorithms for this problem. All of the above studies are of SGD-type, and no efforts have
been made on developing variance reduction zeroth-order algorithms for nonconvex-strongly-concave
min-max optimization to further improve the query complexity.
•	The second focus of this paper is on applying the aforementioned enhanced SREDA algorithm
to design a zeroth-order variance reduced algorithm for nonconvex-strongly-concave min-max
problems, and further characterizing its complexity guarantee which we anticipate to be orderwisely
better than that of the existing stochastic algorithms.
1.1	Main Contributions
This paper first studies an enhanced SREDA algorithm, called SREDA-Boost, which improves
SREDA from two aspects. (1) For the initialization, SREDA-Boost requires only an accuracy of
ζ = κ-1, which is much less stringent than that of ζ = κ-2e2 required by SREDA. (2) SREDA-
Boost allows an accuracy-independent stepsize α = O(1∕(κ')), which is much larger than the e-level
stepsize a = O(min{e∕(κ' ∣∣vtk2), 1∕(κ')}) adopted by SREDA. Hence, SREDA-Boost can run
much faster than SREDA.
1The constant K = '/μ, where μ is the strong concavity parameter of f (x, ∙), and ' is the Lipschitz constant
of the gradient of f(x, y) as defined in Assumption 2. Typically, κ is much larger than one.
2
Under review as a conference paper at ICLR 2021
Table 1: Comparison of stochastic algorithms for nonconvex-strongly-concave min-max problems
TyPe^	Algorithm	Stepsize]	Initialization Complexity	Complexity。, Q
FO	SGDmaX	Θ(κ-1'-1)	N/A	O(κ3e-4log(《声
	SGDA	Θ(κ-2'-1)	N/A	O(κ3e-4)
	PGSMD	Θ(κ-'2)	N/A	O(κ3e-4)
	PGSVRG	Θ(κ-2)	N/A	O(κ3e-4)
	SREDA	a(min{κ'π⅞12，κ⅛ D	O(κ2e-2 log(K))	θ(κ3e-3)
	SREDA-Boost	Θ((κ-1'-1))	O(K log(κ))	O(κ3e-3)t—
ZO	ZO-min-max	Θ(κ-1'-1)	N/A	θ((de-6)∖
	ZO-SGDA	θ(κ-4'-1)	N/A	O(dκ5e-4)
	-ZO-SGDMSA	Θ(κ-1'-1)	N/A	O(dκ2e-4log(1∙))
	ZO-SREDA-Boost	Θ(κ-1'-1)	O(K log(κ))	O(dκ3e-3)
t We clarify that SREDA-Boost should not be expected to improve the complexity order of SREDA, because
SREDA already achieves the optimal complexity. Rather, SREDA-Boost improves upon SREDA by much
more relaxed requirements on initialization and stepsize to achieve such optimal performance.
^ "FO" stands for "First-Order", and "ZO" stands for "Zeroth-Order".
] We include only the stepsize for updating xt for comparison.
♦ The complexity for first-order algorithms refer to the total gradient computations to attain an -stationary
point, and for zeroth-order algorithms refers to the total function value queries.
B We include only the complexity in the online case in the table, because many studies did not cover the
finite-sum case. We comment on the finite-sum case in Section 4 and Section 5.2.
\ We define d = d1 + d2 .
The first contribution of this paper lies in developing a new analysis technique to provide the
computational complexity guarantee for SREDA-Boost, establishing that even with considerably
relaxed conditions on the initialization and stepsize, SREDA-Boost achieves the same optimal
complexity performance as SREDA. The analysis technique of SREDA in Luo et al. (2020) does
not handle such a case, because the proof highly relies on the stringent initialization and stepsize
requirements. Central to our new analysis framework is the novel approach for bounding two inter-
connected stochastic error processes: tracking error and gradient estimation error (see Section 4 for
their formal definitions), which take three steps: bounding the two error processes accumulatively
over the entire algorithm execution, decoupling these two inter-related stochastic error processes, and
establishing each of their relationships with the accumulative gradient estimators.
The second contribution of this paper lies in proposing the zeroth-order variance reduced al-
gorithm ZO-SREDA-Boost for nonconvex-strongly-conconve min-max optimization when the
gradient information is not accessible. For the online case, we show that ZO-SREDA-Boost
achieves an overall query complexity of O((d1 + d2)κ3-3), which outperforms the best known
complexity (achieved by ZO-SGDMSA Wang et al. (2020)) in the case with ≤ κ-1. For
the finite-sum case, We show that ZO-SREDA-Boost achieves an overall query complexity of
O((dι + d2)(κ2√ne-2 + n) + d2(κ2 + κn)log(κ)) when n ≥ κ2, and O((dι + d2)(κ2 + Kn)Ke-2)
when n ≤ κ2 . This is the first study that applies the variance reduction method to zeroth-order
nonconvex-stronlgy-concave min-max optimization.
1.2	Related Work
Due to the vast amount of studies on min-max optimization and the variance reduced algorithms, we
include below only the studies that are highly relevant to this work.
Variance reduction methods for min-max optimization are highly inspired by those for conventional
minimization problems, including SAGA Defazio et al. (2014); Reddi et al. (2016), SVRG Johnson
& Zhang (2013); Allen-Zhu & Hazan (2016); Allen-Zhu (2017), SARAH Nguyen et al. (2017a;b;
2018), SPIDER Fang et al. (2018), SpiderBoost Wang et al. (2019), etc. But the convergence analysis
for min-max optimization is much more challenging, and is typically quite different from their
counterparts in minimization problems.
For strongly-convex-strongly-concave min-max optimization, Palaniappan & Bach (2016) applied
SVRG and SAGA to the finite-sum case and established a linear convergence rate, and Chavdarova
et al. (2019) proposed SVRE later to obtain a better bound. When the condition number of the
problem is very large, Luo et al. (2019) proposed a proximal point iteration algorithm to improve the
3
Under review as a conference paper at ICLR 2021
performance of SAGA. For some special cases, Du et al. (2017); Du & Hu (2019) showed that the
linear convergence rate of SVRG can be maintained without the strongly-convex or strongly concave
assumption. Yang et al. (2020) applied SVRG to study the min-max optimization under the two-sided
Polyak-Lojasiewicz condition.
Nonconvex-strongly-concave min-max optimization is the focus of this paper. As we discuss at the
beginning of the introduction, the SGD-type algorithms have been developed and studied, including
SGDmax Jin et al. (2019), PGSMD Rafique et al. (2018), and SGDA Lin et al. (2019). Several
variance reduction methods have also been proposed to further improve the performance, including
PGSVRG Rafique et al. (2018), the SAGA-type algorithm for min-max optimization Wai et al. (2019),
and SREDA Luo et al. (2020). Particularly, SREDA has been shown in Luo et al. (2020) to achieve
the optimal complexity dependence on . This paper further provides the convergence guarantee
for SREDA-Boost (which enhances SREDA with relaxed initialization and much larger stepsize) by
developing a new analysis technique.
While SGD-type zeroth-order algorithms have been studied for min-max optimization, such as
Menickelly & Wild (2020); Roy et al. (2019) for convex-concave min-max problems and Liu et al.
(2019); Wang et al. (2020) for nonconvex-strongly-concave min-max problems, variance reduced
algorithms have not been developed for zeroth-order min-max optimization so far. This paper
proposes the first such an algorithm named ZO-SREDA-Boost for nonconvex-strongly-concave
min-max optimization, and established its complexity performance that outperforms the existing
comparable algorithms (see Table 1).
2	Notation and Preliminaries
In this paper, We use ∣∣∙k2 to denote the Euclidean norm of vectors. For a finite set S, We denote
its cardinality as |S|. For a positive integer n, we denote [n] = {1, ∙∙∙ , n}. We assume that the
min-max problem eq. (2) satisfies the folloWing assumptions, Which have also been adopted by Luo
et al. (2020) for SREDA. We slightly abuse the notation ξ beloW to represent the random index in
both the online and finite-sum cases, where in the finite-sum case, Eξ [∙] is with respect to the uniform
distribution over {ξι,…，ξn}.
Assumption 1. Thefunction Φ(∙) is lower bounded, i.e., we have Φ* = infχ∈Rdι Φ(x) > 一∞.
Assumption 2. The component function F has an averaged '-Lipschitz gradient, i.e., for all (x, y),
(x0,y0) ∈ Rd1 X Rd2, we have Eξ [∣VF(x,y; ξ) - VF(x0,y0; ξ)∣2 ] ≤ '2(∣x — x0∣2 + ∣y - y012).
Assumption 3. The function f is μ-StrOngly-COnCaVe in y for any X ∈ Rd1, and the component
function F is concave in y, i.e., for any x ∈ Rd1, y, y0 ∈ Rd2 and ξ, we have f(x, y) ≤ f(x, y0) +
hvyf (X, y0), y - y0i - μ ky - y0k2, and F(X, y;ξ) ≤ F(X, y0;ξ) +〈VyF(X, y0;ξ), y - y0〉.
Assumption 4. The gradient of each component function F(x, y; ξ) has a bounded vari-
ance, i.e., there exists a constant σ > 0 such that for any (X, y) ∈ Rd1 ×d2, we have
Eξ ∣VF (X, y; ξ) - Vf (X, y)∣22 ] ≤ σ2 < ∞.
Since Φ is nonconvex in general, it is NP-hard to find its global minimum. The goal here is to develop
stochastic gradient algorithms that output an -stationary point as defined below.
Definition 1. The point X is called an e-stationary point of the differentiable function Φ if
∣∣VΦ(x)∣2 ≤ e, where e is a positive constant.
3	SREDA and SREDA-Boost Algorithms
We first introduce the SREDA algorithm proposed in Luo et al. (2020), and then describe an enhanced
algorithm SREDA-Boost that we study in this paper.
SREDA (see Option I in Algorithm 1) utilizes the variance reduction techniques proposed in SARAH
Nguyen et al. (2017a) and SPIDER Fang et al. (2018) for minimization problems to construct the
gradient estimator recursively for min-max optimization. Specifically, the parameters Xt and yt
are updated in a nested loop fashion: each update of Xt in the outer-loop is followed by (m + 1)
updates of yt over one entire inner loop. Furthermore, the outer-loop updates of Xt is divided into
epochs for variance reduction. Consider a certain outer-loop epoch t = {(nt - 1)q,…，%q - 1}
(1 ≤ nt < dT /qe is a positive integer). At the beginning of such an epoch, the gradients are evaluated
4
Under review as a conference paper at ICLR 2021
with a large batch size S1 (see line 6 in Algorithm 1). Then, for each subsequent outer-loop iteration,
an inner loop of ConcaveMaximizer (see Algorithm 2) recursively updates the gradient estimators
for Nxf (x, y) and Ny f (x, y) with a small batch size S2. Note that although the inner loop does
not update x, the gradient estimator Nxf (x, y) is updated in the inner loop. With such a variance
reduction technique, SREDA outperforms all previous algorithms for nonconvex-strongly-concave
min-max problems (see Table 1), and was shown to achieve the optimal dependency on in complexity
Luo et al. (2020).
Algorithm 1 SREDA and SREDA-Boost
	
1: 2: 3: 4: 5: 6: 7: 8: 9: 10 11 12 13 14	Input: xo, initial accuracy ζ, learning rate α±, β = O('), batch size Si, S2 and periods q, m. Option I (SREDA): ζ = κ-22; Option II (SREDA-Boost): ζ = κ-1 Initialization: yo = iSARAH(-f (xo, ∙), ζ) (see Appendix B.2 for iSARAH(∙)) for t = 0, 1, ..., T - 1 do if mod(t, q) = 0 then draw Si samples {ξι,… ,ξsι } vt = Sr PS=I VxF(xt,yt,ξi),	ut = Sr PS= VyF(xt,yt,ξi) else vt = vt-1,m t-1,	Ut = Ut-1,m t-1 end if Option I(SREDA): at = min{,右}O(1); Option II (SREDA-Boost): at = α = O(七) :	xt+i = xt - αtvt :	yt+i = ConcaveMaximizer(t, m, S2) : end for Output: X chosen uniformly at random from {Xt }T-i
	
	
Algorithm 2 ConcaveMaximizer(t, m, S2 )	
1: 2: 3: 4: 5: 6: 7: 8: 9: 10 11 12	Initialization: Xt,-1 = xt, yt,-ι = yt, Xt,0 = xt+i, yt,0 = yt, vt,-i = vt, ut,-i = Ut Draw S2 samples {ξι,… ,ξs2 } vt,o = vt,-i + S12 Pi=I VxF(Xt,0,yt,0,ξi)- S12 Pi=I VxF(χt,-ι,yt,-ι,ξi) Ut,0 = Ut,-1 + S2 Pi=ι VyF(Xt,0,yt,0,ξi) - S2 Pi=ι VyF(Xt,-1,yt,-1,ξi) Xt,1 = Xt,0,	yt,1 = yt,0 + βut,0 for k = 1, 2, ..., m - 1 do draw S2 samples {ξι,… ,ξS2 } vt,k = vt,k-i + S2 pi=ι VxF(Xt,k,yt,k,ξi) - S2 PS=1 VxF(Xt,k-ι,yt,k-ι,ξi) Ut,k = Ut,k-ι + S2 PS= 1 VyF(Xt,k,yt,k,ξi) - S2 Pi=ι VyF(Xt,k-1,yt,k-1, ξi) Xt,k+ι = Xt,k, yt,k+ι = yt,k + βUt,k : end for Output: yt+i = yt,mt with mt chosen uniformly at random from {0,1, •一,m}
Although SREDA achieves the optimal complexity performance in theory, two issues can substantially
slow down its practical performance. (a) Its initialization y0 needs to satisfy a stringent 2-level
requirement on the accuracy E[kNyf(x0, y0)k22] ≤ κ-22 (see line 2 in Algorithm 1), which requires
as large as O(κ2-2 log(κ/)) stochastic gradient computations Luo et al. (2020). This is quite
costly. (b) SREDA uses an -dependent stepsize and applies normalized gradient descent, so that
each outer-loop update makes only e-level progress given by ∣∣xt+ι — xt∣b = O(e∕(κ')). This
substantially slows down SREDA. By following the analysis of SREDA, it appears that such choices
for initialization and stepsize are necessary to obtain the guaranteed convergence rate.
In this paper, we study SREDA-Boost (see Option II in Algorithm 1) that enhances SREDA over the
above two issues. (a) SREDA-Boost relaxes the initialization requirement to be E[kNyf(x0, y0)k22] ≤
κ-1, which requires only O(κ log κ) gradient computations. This improves the computational
cost upon SREDA by a factor of O(κe-2). (b) SREDA-Boost adopts an e-independent stepsize
at = α = O(1∕(κ')) for Xt so that each outer-loop update can make much bigger progress than
SREDA. As our experiments in Section 6 demonstrate, SREDA-Boost runs much faster than SREDA.
To provide the convergence guarantee for SREDA-Boost, the analysis of SREDA in Luo et al.
(2020) does not apply, because the proof highly depends on the stringent requirements on the
5
Under review as a conference paper at ICLR 2021
initialization and the stepsize. Thus, this paper provides a new analysis technique for establishing
the complexity performance guarantee for SREDA-Boost and further applies it to the gradient-free
min-max problems.
4	Convergence Analysis of SREDA-Boost
The following theorem provides the computational complexity of SREDA-Boost for finding a first-
order stationary point of Φ(∙) with e accuracy.
Theorem 1. Apply SREDA-Boost to solve the online case of the problem eq. (1). Suppose Assumptions
1-4 hold. Let Z = κ-1, α = O(κ-1'-1), β = O('T), q = θ(e-1), m = O(K), Si = O(σ2κ2e-2)
and S2 = O(κe-i). Thenfor T to be at least at the order of O(κe-2), Algorithm 1 outputs X that
satisfies E[kVΦ(X)k2] ≤ e with stochastic gradient complexity O(κ3e-3).
Furthermore, SREDA-Boost is also applicable to the finite-sum case of the problem eq. (1) by
replacing the large batch S1 of samples used in line 6 of Algorithm 1 with the full set of samples.
Corollary 1. Apply SREDA-Boost described above to solve the finite-sum case of the problem eq. (1).
Suppose Assumption 1-4 hold. Under appropriate parameter settings given in Appendix B.4, the
overall gradient complexity to attain an e-stationary point is O(K2 √ne-2 + n + (n + κ)log(κ)) for
n ≥ κ2, and O((κ2 + κn)e-2) for n ≤ κ2.
To compare with SREDA, as shown in Luo et al. (2020), SREDA requires stringent initialization
and stepsize selection to achieve the optimal complexity performance. In constrast, Theorem 1
and Corollary 1 show that those strict requirements are not necessary for achieving the optimal
performance, and establish that SREDA-Boost achieves the same optimal complexity as SREDA
under more relaxed initialization and a much bigger and accuracy-independent stepsize α.
The convergence analysis of SREDA-Boost in Theorem 1 is very different from the proof of SREDA
in Luo et al. (2020). At a high level, such analysis mainly focuses on bounding two inter-related
errors: tracking error δt = E[kVyf(xt, yt)k22] that captures how well the output yt of the in-
ner loop approximates the optimal point y*(χj for a given xt, and gradient estimation error
∆t = E[kvt - Vxf(xt, yt)k22 + kut - Vyf(xt, yt)k22] that captures how well the stochastic gradient
estimators approximate the true gradients. In the analysis of SREDA in Luo et al. (2020), the strin-
gent requirements for initialization and stepsize and the e-level normalized gradient descent update
substantially help to bound both errors δt and ∆t separately at the e level for each iteration so that the
convergence bound follows. In contrast, this is not applicable to SREDA-Boost which has relaxed
and accuracy-independent initialization and stepsize. Hence, we develop a novel analysis framework
to bound the accumulative errors PtT=-01 δt and PtT=-01 ∆t over the entire algorithm execution, and
then decouple these two inter-related stochastic error processes and establish their relationships with
the accumulative gradient estimators PiT=-01 E[kvtk22]. The following proof sketch of Theorem 1
further illustrates our ideas.
The analysis of SREDA-Boost for min-max problems is inspired by that for SpiderBoost in Wang
et al. (2019) for minimization problems, but the analysis here is much more challenging due to the
complicated mathematical nature of min-max optimization. Specifically, SpiderBoost needs to handle
only one type of the gradient estimation error, whereas SREDA-Boost requires to handle two strongly
coupled errors in min-max problems. Hence, the novelty for analyzing SREDA-Boost mainly lies
in bounding and decoupling the two errors in order to characterize their impact on the convergence
bound. 5
5 ZO-SREDA-Boost and Convergence Analysis
In this section, we study the min-max problem when the gradient information is not available, but
only function values can be used for designing algorithms. Based on the first-order SREDA-Boost
algorithm, we first propose the zeroth-order variance reduced algorithm called ZO-SREDA-Boost
and then provide the convergence analysis for such an algorithm.
6
Under review as a conference paper at ICLR 2021
5.1	ZO-SREDA-Boost Algorithm
The ZO-SREDA-Boost algorithm (see Algorithm 4 in Appendix C.1) shares the same update scheme
as SREDA-Boost, but makes the following changes.
(1)	In line 3 of SREDA-Boost, instead of using iSARAH, ZO-SREDA-Boost utilizes a zeroth-order
algorithm ZO-iSARAH (Algorithm 6 in Appendix C.4) to search an initialization y0.
(2)	At the beginning of each epoch in the outer loop (line 6 of SREDA-Boost), ZO-
SREDA-Boost utilizes coordinate-wise gradient estimators with a large batch S1 given by
Vt = (1∕Sι) PS=1 Pd=I(F(Xt + δej,yt,ξi) - F(Xt - δej-,yt,ξi))ej/(2δ) and Ut =
(1/S1) PiS=11 Pjd=2 1(F(xt,yt + δej ,ξi) - F(xt, yt - δej ,ξi))ej /(2δ), where ej denotes the j-th
canonical unit basis vector. Note that the coordinate-wise gradient estimator is commonly taken in
the zeroth-order variance reduce algorithms such as in Ji et al. (2019) for minimization problems.
(3)	ZO-SREDA-Boost replaces ConcaveMaximizer (line 12 of SREDA) by ZO-ConcaveMaximizer
(see Algorithm 5), in which the zeroth-order gradient estimators are recursively updated with
small batches S2,x (for update of X) and S2,y (for update of y) based on the Gaussian estima-
tors given by Gμι (x, y, vm1,x,£m. ) = (l∕S2,x) Pi∈[s2,x][F(X + 〃" y, ξi) - F(x, y, ξi)]%∕μι
and H“2(x,y,ωM2,y,ξMy) = (l∕S2,y) Pi∈[s2,y][F(x,y + μ2ωi,ξi) - F(x,y, ξi)]ωi∕μ2, where
Vi 〜N(0,1dι), ωi 〜N(0, Id?) with 1d denoting the identity matrices with sizes d X d.
5.2	Convergence Analysis of ZO-SREDA-Boost
The following theorem provides the query complexity of ZO-SREDA-Boost for finding a first-order
stationary point of Φ(∙) with e accuracy.
Theorem 2. Apply ZO-SREDA-Boost in Algorithm 4 to solve the online case of the problem eq. (1).
Suppose Assumptions 1-4 hold. Let Z = κ-1, α = O(κ-1'-1), β = O('-1), q = O(e-1), m =
O(K), Si = O(σ2κ2e-2), S2,χ = O(d1κe-1), S2,y = O(d2κe-1), δ = O((dι + d2)0.5κ-l'-le),
μι = O(d-1.5κ-2.5'-1e) and μ2 = O(d-1'5κ-2-5'-ie). Thenfor T to be at least at the order of
O(κe-2), Algorithm 4 outputs X that satisfies E[kVΦ(X)k2] ≤ e with the overall function query
complexity O((d1 + d2 )κ3e-3).
Furthermore, ZO-SREDA-Boost is also applicable to the finite-sum case of the problem eq. (1), by
replacing the large batch sample S1 used in line 6 of Algorithm 4 with the full set of samples.
Corollary 2. Apply ZO-SREDA-Boost described above to solve the finite-sum case of the problem
eq. (1). Suppose Assumptions 1-4 hold. Under appropriate parameter settings g^ven in Appendix C.6,
thefunction query complexity to attain an e-stationarypoint is O((dι + d2)(√nκ2e-2 + n) + d2(κ2 +
κn) log(κ)) for n ≥ κ2, and O((d1 + d2)(κ2 + κn)e-2) for n ≤ κ2.
Theorem 2 and Corollary 2 provide the first convergence analysis and the query complexity for the
variance-reduced zeroth-order algorithms for min-max optimization. These two results indicate that
the query complexity of ZO-SREDA-Boost matches the optimal dependence on e of the first-order
algorithm SREDA-Boost in Theorem 1 and Corollary 1. The dependence on d1 and d2 typically arises
in zeroth-order algorithms due to the estimation of gradients with dimensions d1 and d2 . Furthermore,
in the online case, ZO-SREDA-Boost outperforms the best known query complexity dependence
on e among the existing zeroth-order algorithms by a factor of O(1∕e). Including the conditional
number κ into consideration, SREDA-Boost outperforms the best known query complexity achieved
by ZO-SGDMA in the case with e ≤ κ-1 (see Table 1). Furthermore, Corollary 2 provides the first
query complexity for the finite-sum zeroth-order min-max problems.
As a by-product, our analysis of ZO-SREDA-Boost also yields the convergence rate and the
query complexity (see Lemma 21) for ZO-iSARAH for the conventional minimization problem,
which provides the first complexity result for the zeroth-order recursive variance reduced algorithm
SARAH/SPIDER for strongly convex optimization (see Appendix C.4 for detail).
6	Experiments
Our experiments focus on two types of comparisons. First, we compare SREDA-Boost with SREDA
to demonstrate the practical advantage of SREDA-Boost. Second, we compare our proposed zeroth-
7
Under review as a conference paper at ICLR 2021
order variance reduction algorithm ZO-SREDA-Boost with the other existing zeroth-order stochastic
algorithms and demonstrate the superior performance of ZO-SREDA-Boost.
Our experiments solve a distributionally robust optimization problem, which is commonly used for
studying min-max optimization Lin et al. (2019); Rafique et al. (2018). We conduct the experiments
on three datasets from LIBSVM Chang & Lin (2011). The details of the problem and the datasets are
provided in Appendix A.
Comparison between SREDA-Boost and SREDA: We set = 0.001 for both algorithms. For
SREDA, we set αt = min{/ kvtk2 , 0.005} as specified by the algorithm, and for SREDA-Boost,
we set αt = 0.005 as the algorithm allows. It can be seen in Figure 1 that SREDA-Boost enjoys a
much faster convergence speed than SREDA due to the allowance of a large stepsize.
number of stochastic gradients/n
(a) Dataset: a9a
(b) Dataset: w8a
Figure 1: Comparison of the convergence rate between SREDA-Boost and SREDA.
number of stochastic gradients/n
(c) Dataset: mushrooms
Comparison among zeroth-order Algorithms: We compare the performance of our proposed ZO-
SREDA-Boost with that of two existing stochastic algorithms ZO-SGDA Wang et al. (2020) and
ZO-SGDMSA Wang et al. (2020) designed for nonconvex-strongly-concave min-max problems. For
ZO-SGDA and ZO-SGDMSA, as suggested by the theorem, we set the mini-batch size B = Cd1 /2
and B = Cd2 /2 for updating the variables x and y, respectively. For ZO-SREDA-Boost, based on
our theory, we set the mini-batch size B = Cd1/ and B = Cd2/ for updating the variables x and
y, and set S1 = n for the large batch, where n is the number of data samples in the dataset. We set
C = 0.1 and = 0.1 for all algorithms. We further set the stepsize η = 0.01 for ZO-SREDA-Boost
and ZO-SGDMSA. Since ZO-SGDA is a two time-scale algorithm, we set η = 0.01 as the stepsize
for the fast time scale, and η∕κ3 as the stepsize for slow time scale (based on the theory) where
κ3 = 10. It can be seen in Figure 2 that ZO-SREDA-Boost substantially outperforms the other two
algorithms in terms of the function query complexity (i.e., the running time).
(a) Dataset: a9a
(b) Dataset: w8a
Figure 2: Comparison of function query complexity among three algorithms.
(c) Dataset: mushrooms
7	Conclusion
In this work, we have proposed enhanced variance reduction algorithms, which we call SREDA-Boost
and ZO-SREDA-Boost, for solving nonconvex-strongly-concave min-max problems. In specific,
SREDA-Boost requires less initialization effort and allows a large stepsize. Moreover, The complexity
of SREDA-Boost and ZO-SREDA-Boost achieves the best complexity dependence on the targeted
accuracy among their same classes of algorithms. We have also developed a novel analysis framework
to characterize the convergence and computational complexity for the variance reduction algorithms.
We expect such a framework will be useful for studying various other stochastic min-max problems
such as proximal, momentum, and manifold optimization.
8
Under review as a conference paper at ICLR 2021
References
Zeyuan Allen-Zhu. Natasha: faster non-convex stochastic optimization via strongly non-convex
parameter. In Proc. International Conference on Machine Learning (ICML), pp. 89-97, 2017.
Zeyuan Allen-Zhu and Elad Hazan. Variance reduction for faster non-convex optimization. In Proc.
International Conference on Machine Learning (ICML), pp. 699-707, 2016.
Yossi Arjevani, Yair Carmon, John C Duchi, Dylan J Foster, Nathan Srebro, and Blake Woodworth.
Lower bounds for non-convex stochastic optimization. arXiv preprint arXiv:1912.02365, 2019.
Ilija Bogunovic, Jonathan Scarlett, Stefanie Jegelka, and Volkan Cevher. Adversarially robust
optimization with gaussian processes. In Proc. Advances in Neural Information Processing
Systems (NeurIPS), pp. 5760-5770, 2018.
C. Chang and C. Lin. LIBSVM: A library for support vector machines. ACM Transactions on
Intelligent Systems and Technology, 2(3):1-27, 2011.
Tatjana Chavdarova, Gauthier GideL Frangois Fleuret, and Simon Lacoste-JUlien. Reducing noise
in GAN training with variance reduced extragradient. In Proc. Advances in Neural Information
Processing Systems (NIPS), pp. 391-401, 2019.
Aaron Defazio, Francis Bach, and Simon Lacoste-Julien. SAGA: A fast incremental gradient
method with support for non-strongly convex composite objectives. In Proc. Advances in Neural
Information Processing Systems (NIPS), pp. 1646-1654, 2014.
Simon S Du and Wei Hu. Linear convergence of the primal-dual gradient method for convex-concave
saddle point problems without strong convexity. In Proc. International Conference on Artificial
Intelligence and Statistics (AISTATS), pp. 196-205, 2019.
Simon S Du, Jianshu Chen, Lihong Li, Lin Xiao, and Dengyong Zhou. Stochastic variance reduction
methods for policy evaluation. In Proc. International Conference on Machine Learning (ICML),
pp. 1049-1058, 2017.
Cong Fang, Chris Junchi Li, Zhouchen Lin, and Tong Zhang. SPIDER: Near-optimal non-convex op-
timization via stochastic path-integrated differential estimator. In Advances in Neural Information
Processing Systems (NeurIPS), pp. 689-699, 2018.
Saeed Ghadimi and Guanghui Lan. Stochastic first-and zeroth-order methods for nonconvex stochastic
programming. SIAM Journal on Optimization, 23(4):2341-2368, 2013.
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair,
Aaron Courville, and Yoshua Bengio. Generative adversarial nets. In Proc. Advances in Neural
Information Processing Systems (NIPS), pp. 2672-2680, 2014.
Jonathan Ho and Stefano Ermon. Generative adversarial imitation learning. In Proc. Advances in
Neural Information Processing Systems (NIPS), pp. 4565-4573, 2016.
Kaiyi Ji, Zhe Wang, Yi Zhou, and Yingbin Liang. Improved zeroth-order variance reduced algorithms
and analysis for nonconvex optimization. In Proc. International Conference on Machine Learning,
pp. 3100-3109, 2019.
Chi Jin, Praneeth Netrapalli, and Michael I Jordan. Minmax optimization: stable limit points of
gradient descent ascent are locally optimal. arXiv preprint arXiv:1902.00618, 2019.
Rie Johnson and Tong Zhang. Accelerating stochastic gradient descent using predictive variance
reduction. In Proc. Advances in Neural Information Processing Systems (NIPS), pp. 315-323,
2013.
Yuan-Chuan Li and Cheh-Chih Yeh. Some equivalent forms of Bernoulli’s inequality: A survey.
Applied Mathematics, 4(07):1070, 2013.
Tianyi Lin, Chi Jin, and Michael I Jordan. On gradient descent ascent for nonconvex-concave
minimax problems. arXiv preprint arXiv:1906.00331, 2019.
9
Under review as a conference paper at ICLR 2021
Sijia Liu, Songtao Lu, Xiangyi Chen, Yao Feng, Kaidi Xu, Abdullah Al-Dujaili, Minyi Hong, and
Una-May Obelilly. Min-max optimization without gradients: convergence and applications to
adversarial ML. arXiv preprint arXiv:1909.13806, 2019.
Songtao Lu, Ioannis Tsaknakis, Mingyi Hong, and Yongxin Chen. Hybrid block successive ap-
proximation for one-sided non-convex min-max problems: algorithms and applications. IEEE
Transactions on Signal Processing, PP:1-1, 04 2020.
Luo Luo, Cheng Chen, Yujun Li, Guangzeng Xie, and Zhihua Zhang. A stochastic proximal point
algorithm for saddle-point problems. arXiv preprint arXiv:1909.06946, 2019.
Luo Luo, Haishan Ye, and Tong Zhang. Stochastic recursive gradient descent ascent for stochastic
nonconvex-strongly-concave minimax problems. arXiv preprint arXiv:2001.03724, 2020.
Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and Adrian Vladu.
Towards deep learning models resistant to adversarial attacks. In Proc. International Conference
on Learning Representations (ICLR), 2018.
Matt Menickelly and Stefan M Wild. Derivative-free robust optimization by outer approximations.
Mathematical Programming, 179(1-2):157-193, 2020.
Yurii Nesterov. Introductory Lectures on Convex Optimization: A Basic Course, volume 87. Springer
Science & Business Media, 2013.
Yurii Nesterov and Vladimir Spokoiny. Random gradient-free minimization of convex functions.
Foundations of Computational Mathematics, 17(2):527-566, 2017.
Lam M Nguyen, Jie Liu, Katya Scheinberg, and Martin Takac. SARAH: A novel method for machine
learning problems using stochastic recursive gradient. In Proc. International Conference on
Machine Learning (ICML), pp. 2613-2621, 2017a.
Lam M Nguyen, Jie Liu, Katya Scheinberg, and Martin Takac. Stochastic recursive gradient algorithm
for nonconvex optimization. arXiv preprint arXiv:1705.07261, 2017b.
Lam M Nguyen, Katya Scheinberg, and Martin Takdc. Inexact SARAH algorithm for stochastic
optimization. arXiv preprint arXiv:1811.10105, 2018.
Maher Nouiehed, Maziar Sanjabi, Tianjian Huang, Jason D Lee, and Meisam Razaviyayn. Solving
a class of non-convex min-max games using iterative first order methods. In Proc. Advances in
Neural Information Processing Systems (NeurIPS), pp. 14905-14916, 2019.
Balamurugan Palaniappan and Francis Bach. Stochastic variance reduction methods for saddle-point
problems. In Proc. Advances in Neural Information Processing Systems (NIPS), pp. 1416-1424,
2016.
Boris Teodorovich Polyak. Gradient methods for minimizing functionals. Zhurnal Vychislitel’noi
Matematiki i Matematicheskoi Fiziki, 3(4):643-653, 1963.
Hassan Rafique, Mingrui Liu, Qihang Lin, and Tianbao Yang. Non-convex min-max optimization:
provable algorithms and applications in machine learning. arXiv preprint arXiv:1810.02060, 2018.
Sashank J. Reddi, Ahmed Hefny, Suvrit Sra, Barnabas Poczos, and Alex Smola. Stochastic variance
reduction for nonconvex optimization. In Proc. International Conference on Machine Learning
(ICML), 2016.
Abhishek Roy, Yifang Chen, Krishnakumar Balasubramanian, and Prasant Mohapatra. Online
and bandit algorithms for nonstationary stochastic saddle-point optimization. arXiv preprint
arXiv:1912.01698, 2019.
Kiran K Thekumparampil, Prateek Jain, Praneeth Netrapalli, and Sewoong Oh. Efficient algorithms
for smooth minimax optimization. In Proc. Advances in Neural Information Processing Systems
(NeurIPS), 2019.
10
Under review as a conference paper at ICLR 2021
Hoi-To Wai, Mingyi Hong, Zhuoran Yang, Zhaoran Wang, and Kexin Tang. Variance reduced policy
evaluation with smooth function approximation. In Advances in Neural Information Processing
Systems (NeurIPS), 2019.
Zhe Wang, Kaiyi Ji, Yi Zhou, Yingbin Liang, and Vahid Tarokh. SpiderBoost: A class of faster
variance-reduced algorithms for nonconvex optimization. In Proc. Advances Neural Information
Processing Systems (NeurIPS), 2019.
Zhongruo Wang, Krishnakumar Balasubramanian, Shiqian Ma, and Meisam Razaviyayn. Zeroth-
order algorithms for nonconvex minimax problems with improved complexities. arXiv preprint
arXiv:2001.07819, 2020.
Zi Wang and Stefanie Jegelka. Max-value entropy search for efficient bayesian optimization. In Proc.
International Conference on Machine Learning (ICML), 2017.
Chen-Yu Wei, Yi-Te Hong, and Chi-Jen Lu. Online reinforcement learning in stochastic games. In
Proc. Advances in Neural Information Processing Systems (NIPS), pp. 4987-4997, 2017.
Junchi Yang, Negar Kiyavash, and Niao He. Global convergence and variance-reduced optimization
for a class of nonconvex-nonconcave minimax problems. arXiv preprint arXiv:2002.09621, 2020.
Kaiqing Zhang, ZhUoran Yang, and Tamer BaSar. Multi-agent reinforcement learning: a selective
overview of theories and algorithms. arXiv preprint arXiv:1911.10635, 2019.
11