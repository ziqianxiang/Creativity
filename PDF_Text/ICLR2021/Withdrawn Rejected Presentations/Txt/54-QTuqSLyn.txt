Under review as a conference paper at ICLR 2021
Mitigating Mode Collapse By Sidestepping
Catastrophic Forgetting
Anonymous authors
Paper under double-blind review
Ab stract
Generative Adversarial Networks (GANs) are a class of generative models used
for various applications, but they have been known to suffer from the mode col-
lapse problem, in which some modes of the target distribution are ignored by the
generator. Investigative study using a new data generation procedure indicates
that the mode collapse of the generator is driven by the discriminator’s inability
to maintain classification accuracy on previously seen samples, a phenomenon
called Catastrophic Forgetting in continual learning. Motivated by this observation,
we introduce a novel training procedure that dynamically spawns additional dis-
criminators to remember previous modes of generation. On several datasets, we
show that our training scheme can be plugged-in to existing GAN frameworks to
mitigate mode collapse and improve standard metrics for GAN evaluation.
1	Introduction
Generative Adversarial Networks (GANs) (Goodfellow et al., 2014) are an extremely popular class
of generative models that is not only used for text and image generation, but also in various fields of
science and engineering, including biomedical imaging (Yi et al., 2019; Nie et al., 2018; Wolterink
et al., 2017), autonomous driving (Hoffman et al., 2018; Zhang et al., 2018), and robotics (Rao et al.,
2020; Bousmalis et al., 2018). However, GANs are widely known to be prone to mode collapse, which
refers to a situation where the generator only samples a few modes of the real data, failing to faithfully
capture other more complex or less frequent categories. While the mode collapse problem is often
overlooked in text and image generation tasks, and even traded off for higher realism of individual
samples (Karras et al., 2019; Brock et al., 2019), dropping infrequent classes may cause serious
problems in real-world problems, in which the infrequent classes represent important anomalies. For
example, a collapsed GAN can produce racial/gender biased images (Menon et al., 2020).
Moreover, mode collapse causes instability in optimization, which can damage not only the diversity
but also the realism of individual samples of the final results. As an example, we visualized the
training progression of the vanilla GAN (Goodfellow et al., 2014) for a simple bimodal distribution
in the top row of Figure 1. At collapse, the discriminator conveniently assigns high realism to the
region unoccupied by the generator, regardless of the true density of the real data. This produces
a strong gradient for the generator to move its samples toward the dropped mode, swaying mode
collapse to the opposite side. In particular, the discriminator loses its ability to detect fake samples it
was previously able to, such as point X . The oscillation continues without convergence.
From this observation, we hypothesize that the mode collapse problem in GAN training is closely
related to Catastrophic Forgetting (McCloskey & Cohen, 1989; McClelland et al., 1995; Ratcliff,
1990) in continual learning. That is, since the distribution of the generated samples is not stationary,
the discriminator forgets to classify the previously generated samples as fake, hindering convergence
of the GAN minimax game. A promising line of works (Zhang et al., 2019b; Rajasegaran et al.,
2019; Rusu et al., 2016; Fernando et al., 2017) tackle the problem in the supervised learning setting
by instantiating multiple predictors, each of which takes charge in a particular subset of the whole
distribution. Likewise, we also tackle the problem of mode collapse in GAN by tracking the severity
of Catastrophic Forgetting by storing a few exemplar data during training, and dynamically spawning
an additional discriminator if forgetting is detected, as shown in Figure 1. The key idea is that the
added discriminator is left intact unless the generator recovers from mode dropping of that sample,
essentially sidestepping catastrophic forgetting.
1
Under review as a conference paper at ICLR 2021
Figure 1: Visualizing training trajectories: We visualize the distribution of the real (green dots) and
fake (blue dots) over the course of the vanilla GAN (top row) and our method (the second row and
below). The background color indicates the prediction heatmap of the discriminator with blue being
fake and warm yellow being real. Once the vanilla GAN falls into mode collapse (top row), it ends up
oscillating between the two modes without convergence. Moreover, the discriminator’s prediction at
point X oscillates, indicating catastrophic forgetting in the discriminator. With our DMAT procedure,
a new discriminator is dynamically spawned during training. The additional discriminator effectively
learns the forgotten mode, guiding the GAN optimization toward convergence.
While the mode collapse problem has been tackled by many previous works, as discussed in Section 2,
we show that our approach based on Catastrophic Forgetting can be added to any existing GAN
frameworks, and is the most effective in preventing mode collapse. Furthermore, the improved
stability of training boosts the standard metrics on popular GAN frameworks. To summarize, our
contributions are:
•	We propose a novel GAN framework, named Dynamic Multi Adversarial Training (DMAT),
that prevents Catastrophic Forgetting in GANs by dynamically spawning additional discrim-
inators during training.
•	We propose a computationally efficient synthetic data generation procedure for studying
mode collapse in GANs that allows visualizing high dimensional data using normalizing
flows. We show that mode collapse occurs even in the recent robust GAN formulations.
•	Our method can be plugged into any state-of-the-art GAN frameworks and still improve the
quality and coverage of the generated samples.
2	Related Works
Previous works have focused on independently solving either catastrophic forgetting in supervised
learning or mode collapse during GAN training. Among the efforts addressing mode collapse, a few
prior works have proposed multi-adversarial solutions for mitigating mode collapse, similar to our
work. In this section we review these works in detail and discuss our commonalities and differences.
2.1	Mitigating Mode Collapse in GANs
Along with advancement in the perceptual quality of images generated by GAN (Miyato et al., 2018;
Karras et al., 2019; Brock et al., 2018; Karras et al., 2020), a large number of papers (Durugkar et al.,
2016; Metz et al., 2016; Arjovsky et al., 2017; Srivastava et al., 2017; Nguyen et al., 2017; Lin et al.,
2018; Mescheder et al., 2018; Karras et al., 2019) identify the problem of mode collapse in GANs
and aim to mitigate it. However, many of them do not attempt to directly address mode collapse, as it
was seen as a secondary symptom that would be naturally solved as the stability of GAN optimization
progresses (Arjovsky et al., 2017; Mescheder et al., 2018; Bau et al., 2019). While the magnitude
of mode collapse is certainly mitigated with more stable optimization, we show that it is still not a
solved problem. To explicitly address mode collapse, Unrolled GAN (Metz et al., 2016) proposes an
unrolled optimization of the discriminator to optimally match the generator objective, thus preventing
mode collapse. VEEGAN (Srivastava et al., 2017) utilizes the reconstruction loss on the latent space.
PacGAN (Lin et al., 2018) feeds multiple samples of the same class to the discriminator when making
the decisions about real/fake. In contrast, our approach differs in that our method can be plugged into
existing state-of-the-art GAN frameworks to yield additional performance boost.
2
Under review as a conference paper at ICLR 2021
2.2	Multi-adversarial Approaches
The idea of employing more than one adversarial network in GANs to mitigate mode collapse or
to improve the quality of generated images in general has been explored by several previous works.
MGAN (Hoang et al., 2018) uses multiple generators, while D2GAN (Nguyen et al., 2017) uses
two discriminators, and GMAN (Durugkar et al., 2016) and MicrobatchGAN (Mordido et al., 2020)
possibly more than two discriminators that can be specified as a hyperparameter. On the other hand,
based on our hypothesis on catastrophic forgetting, our method can dynamically add discriminators
at training time, achieving superior performance than existing works.
2.3	Overcoming Catastrophic Forgetting in GAN
Catastrophic forgetting was first observed in connectionist networks by McCloskey & Cohen (1989).
From then there has been a plethora of works to mitigate catastrophic forgetting in neural networks.
These methods can be categorized into three groups: a) regularization based methods (Kirkpatrick
et al., 2017) b) memory replay based methods (Rebuffi et al., 2017) c) network expansion based
methods (Zhang et al., 2019a; Rajasegaran et al., 2019). Our work is closely related to the third
category of methods, which dynamically adds more capacity to the network, when faced with novel
tasks. This type of methods, adds plasticity to the network from new weights (fast-weights) while
keeping the stability of the network by freezing the past-weights (slow-weights). Although our work
incrementally adds more capacity to the network, we enforce stability by letting a discriminator to
focus on a few set of classes, not by freezing its weights. The possibility of catastrophic forgetting
of GANs has been discussed by Thanh-Tung & Tran (2020). However, the impact of catastrophic
forgetting was mostly limited to theoretical analysis, and we found that the proposed solution
deteriorates the performance on several GAN architectures such as BigGAN (Brock et al., 2019).
3	Proposed Method
In this section, we first describe our proposed data generation procedure that we use as a petri
dish for studying mode collapse in GANs. The procedure uses random normalizing flows for
simultaneously allowing training on complex high dimensional distributions yet being perfectly
amenable to 2D visualizations. Next, we describe our proposed Dynamic Multi Adversarial Training
(DMAT) algorithm that effectively detects catastrophic forgetting and spawns a new discriminator to
prevent mode collapse.
3.1	Synthetic Data Generation with Normalizing flows
Mode dropping in GANs in the context of catastrophic forgetting of the discriminator is a difficult
problem to investigate using real datasets. This is because the number of classes in the dataset
cannot be easily increased, the classes of fake samples are often ambiguous, and the predictions
of the discriminator cannot be easily visualized across the whole input space. In this regard, we
present a simple yet powerful data synthesis procedure that can generate complex high dimensional
multi-modal distributions, yet maintaining perfect visualization capabilities.
The proposed procedure begins by sampling from a simple two dimensional Gaussian distribution.
The samples are then augmented with biases and subjected to an invertible normalizing flow (Karami
et al., 2019) parameterized by well conditioned functions gi : Rdi0 → Rdi1 . Optionally, this function
can be followed by a linear upsampling transformation parameterized by a di1 × di0+1 dimensional
matrix Ai (Algorithm 1). The transformations are constructed to be analytically invertible thus
allowing mapping the high dimensional output space to input (see Appendix D for more information).
Note that the entire transform is deliberately constructed to be a bijective function so that every
generated sample in y ∈ RD can be analytically mapped to R2, allowing perfect visualization on 2D
space. Furthermore, by evaluating a dense grid of points in R2, we can also have a useful insight into
discriminator’s learned probability distribution on z manifold as a heatmap on a 2D plane.
This synthetic data generation procedure enables studying mode collapse in a controlled setting.
This also gives practitioners the capability to train models on a chosen data complexity with clean
two-dimensional visualizations of both the generated data and the discriminator’s learnt distribution.
This tool can be used for debugging new algorithms using insights from the visualizations. For
3
Under review as a conference paper at ICLR 2021
example, in the case of mode collapse, a quick visual inspection would give the details of which
modes face mode collapse or get dropped from discriminator’s learnt distribution.
3.2	Dynamic Multi Adversarial Training
Algorithm 1 Synthetic Data Generation
Input: Mean {μi}K=ι and standard deviation
{σi}iK=1 for initialization, {gi}iL=1 well condi-
tioned R2 → R2 functions
Sample weights W 〜Dirichlet(K)
/* Sample from 2D mixture of gaussians */
X2D 〜∑NN=1 WiN(μi,σi)
x02D = [x20D ; 1], [x21D ; 1]
/* Randomly Initialized Normalizing Flow */
for k = 1 to k = K do
if k is even then
χk = [χkk, Xk ∙ gk(χ0)]
else
Xk = [xk ∙ gk(xk), Xk]
end if
end for
Algorithm 2 DSPAWN: Discriminator
Spawning Subroutine
Require: Exemplar Data {e}im=1
Input: Discriminator set D = {fwi }iK=1
/* Check forgetting over exemplar images */
for i = 1 to i = m do
s[k] - fW (ei) ∀ k ∈{1...K}
if K * max(s) > αt * Ek s[k] then
Initialize fwK +1 with random weights w
/* Spawn a new discriminator */
Initialize random weight wK +1
D Tfw凡[fK+1
break
end if
end for
return Discriminator Set D
Algorithm 3 D-MAT: Dynamic Multi-
Adversarial Training
Require: w0i , θ0 initial discriminator & gen-
erator parameters, greediness parameter ,
{Tk } spawn warmup iteration schedule
D Tfw}
while θ has not converged do
Sample {z(i)}B=ι 〜p(z)
Sample {x(i)}B=ι 〜Pr
Sample {σι(i)}B=I 〜 Uniform(1, K)
Sample {α(i)}iB=1 〜 BemoUlli(e)
/* Loss weights over discriminators */
Sample weights m 〜Dirichlet(K)
x(i) - gθ (z(i))
σ2(i) - arg mink fw (X(i))
/* Discriminator responsible for x(i) */
σz(i) J α(i)σι(i) + (1 — α(i))σ2(i)
/* Discriminator responsible for x(i) */
σx(i) J σ1(i)
/* Training Discriminators */
Lw	J	Pi=1 [fwσx( ) (Xi) — 1]- —
[fwz⑺(Xi) + 1]+
for k = 1 to k = |D| do
wk J ADAM(Lw)
end for
/* Training Generator */
s[k]j PB=ι fw (X⑴)∀ k ∈{1... ∣D∣}
/* Weighed mean over discriminators */
Lθ J sort(m) ∙ sort(s)
θ J ADAM(Lθ)
if more than Tt warm-Up iterations since
the last spawn then
D J DSPAWN({fwi })
end if
end while
BUilding Upon the insight on relating catastrophic forgetting in discriminator to mode collapse in
generator, we propose a mUlti adversarial generative adversarial network training procedUre. The key
intUition is that the interplay of catastrophic forgetting in the discriminator with the GAN minimax
game, leads to an oscillation generator. ConseqUently, as the generator shifts to a new set of modes
the discriminator forgets the learnt featUres on the previoUs modes. However if there are mUltiple
discriminators available, each discriminator can implicitly specialize on a sUbset of modes. ThUs
even if the generator oscillates, each discriminator can remember their own set of modes, and they
will not need to move to different set of modes. This way we can effectively sidestep catastrophic
forgetting and ensUre the networks do not face significant distribUtion shift. A detailed version of
oUr proposed method is presented in Algorithm 3. Spawning new discriminators: We initialize the
DMAT training Algorithm 3 with a regUlar GAN Using jUst one discriminator. We also sample a few
randomly chosen exemplar data points with a maximUm of one real sample per mode, depending on
dataset complexity. The exemplar data points are Used to detect the presence of catastrophic forgetting
in the cUrrently active set of discriminators D and spawn a new discriminator if needed. Specifically
4
Under review as a conference paper at ICLR 2021
Table 1: ✓ indicates that the generator could effectively learn all the data modes, while × means despite best
efforts with tuning the training suffers from mode collapse (more than a quarter of the data modes are dropped).
For each level, we show results with the SGD (left) & ADAM (right) optimizers. MNIST results with ADAM
optimizer are provided for reference. We observe that MNIST is a relatively easy dataset, falling between Level
I and II in terms of complexity.
g(z) =	1	A392×2	Z	MLP	MLP, A392×2	MNIST
Label	Level I	Level II	Level III	Level IV	Level V	-
GAN-NS (Goodfellow et al., 2014)	×	✓	×	✓ ^~	~×	×~	×	×~	-×~Γ-×-	~✓ ~
WGAN (Arjovsky et al., 2017)	✓	✓	×	✓	×	✓	×	×	×	×	✓
Unrolled GAN (Metz et al., 2016)	✓	✓	✓	✓	✓	✓	✓	✓	×	×	✓
D2GAN (Nguyen et al., 2017)	✓	✓	✓	✓	✓	✓	✓	✓	×	×	✓
GAN-NS + DMAT	✓	✓	✓	✓	✓	✓	✓	✓	×	×	✓
(Algorithm 2), we propose that if any discriminator among D has an unusually high score over an
exemplar data point ei , this is because the mode corresponding to ei has either very poor generated
samples or has been entirely dropped. In such a situation, if training were to continue we risk
catastrophic forgetting in the active set D, if the generator oscillate to near ei . This is implemented
by comparing the max score over at ei to the average score over and spawning a new discriminator
when the ratio exceeds αt(> 1). Further, we propose to have αt (> 1) a monotonically increasing
function of |D|, thus successively making it harder to spawn each new discriminator. Additionally,
we use a warmup period Tt after spawning each new discriminator from scratch to let the spawned
discriminator train before starting the check over exemplar data-points.
Multi-Discriminator Training: We evaluate all discriminators in D on the fake samples but do not
update all of them for all the samples. Instead, we use the discriminator scores to assign responsibility
of each data point to only one discriminator. We use an -greedy approach for fake samples where
the discriminator with the lowest output score is assigned responsibility with a probability 1 - and
a random discriminator is chosen with probability . In contrast, for real samples the responsible
discriminator is always chosen uniformly randomly. In effect, we slightly prefer to assign the same
discriminator to the fake datapoints from around the same mode to ensure that they do not forget
the already learnt modes and switch to another mode. The random assignment of real points ensure
that the same preferentially treated discriminator also gets updated on real samples. Further for
optimization stability, we ensure that the real and fake sample loss incurred by each discriminator
is roughly equal in each back-propagation step by dynamically reweighing them by the number
of data points the discriminator is responsible for. We only update the discriminator on the losses
of the samples they are responsible for. Generator Training: We take a weighted mean over the
discriminators scores on the fake datapoints for calculating the generator loss. At each step, the
weights each discriminator in D gets is in decreasing order of its score on the fake sample. Hence,
the discriminator with the lowest score is given the most weight since it is the one that is currently
specializing on the mode the fake sample is related to. In practice, we sample weights randomly from
a Dirichlet distribution (and hence implicitly they sum to 1) and sort according to discriminator scores
to achieve this. We choose soft weighing over hard binary weights because since the discriminators
are updated in an greedy fashion, the discriminators other than the one with the best judgment on the
fake sample might also hold useful information. Further, we choose the weights randomly rather than
fixing a chosen set to ensure DMAT is more deadset agnostic since the number of discriminator used
changes with the dataset complexity so does the number of weights needed. While a suitably chosen
function for generating weights can work well on a particular dataset, we found random weights to
work as well across different settings.
Table 2: Quantitative Results on the Stacked MNIST dataset: Applying our proposed dynamic multi
adversarial training (DMAT) procedure to a simple DCGAN achieves perfect mode coverage, better than many
existing methods for mode collapse.
	GAN	UnrolledGAN	D2GAN	RegGAN	DCGAN	with DMAT
# Modes covered	628.0 ± 140.9	817.4 ± 37.9	1000 ± 0.0	955.5 ± 18.7	849.6 ± 62.7	1000 ± 0.0
KL (samples k data)	2.58 ± 0.75	1.43 ± 0.12	0.080 ± 0.01	0.64 ± 0.05	0.73 ± 0.09	0.078 ± 0.01
5
Under review as a conference paper at ICLR 2021
Table 3: Quantitative Results on CIFAR10: We benchmark DMAT against other multi-adversarial baselines
as well as on several GAN architectures, observing consistent performance increase.
Model	D2GAN	MicrobatchGAN	GAN-NS w/ ResNet	DMAT + GAN-NS	DCGAN	DMAT + DCGAN
IS	7.15 ± 0.07	6.77	6.7 ± 0.06	8.1 ± 0.04	6.03 ± 0.05	6.32 ± 0.06
FID	-	-	28.91	16.35	33.42	30.14
	WGAN-GP	DMAT +		DMAT +		DMAT +
Model	w/ ResNet	WGAN-GP	SN-GAN	SN-GAN	BigGAN	BigGAN
IS	7.59 ± 0.10	7.80 ± 0.07	8.22 ± 0.05	8.34 ± 0.04	9.22	9.51 ± 0.06
FID	19.2	17.2	14.21	13.8	8.94	6.11
4	Results
We test our proposed method on several popular datasets, both synthetic and real & report a consistent
increase in performance on popular GAN evaluation metrics such as Inception Score (Salimans
et al., 2016) and Frechet Inception Distance (HeUsel et al., 2017) with our proposed dynamic multi-
adversarial training. Finally, we also showcase our performance in the GAN fine-tuning regime with
samples on the CUB200 dataset (Welinder et al., 2010) which qualitatively are more colorful and
diverse than an identical BigGAN finetuned without DMAT procedure (Figure 3).
4.1	Synthetic Data
We utilize the proposed synthetic data generation procedure with randomly initialized normalizing
flows to visualize the training process of a simple DCGAN (Radford et al., 2015) in terms of the
generated samples as well as discriminator’s probability distribution over the input space. Figure
1 visualizes such a training process for a simple bimodal distribution. Observing the pattern of
generated samples over the training iteration and the shifting discriminator landscape, we note a
clear mode oscillation issue present in the generated samples driven by the shifting discriminator
output distribution. Focusing on a single fixed real point in space at any of the modes, we see a clear
oscillation in the discriminator output probabilities strongly indicating the presence of catastrophic
forgetting in the discriminator network. Further such visualizations on more complex distributions
(toy 8-D Gaussian rings) are added in the Appendix D.
Effect of Data Complexity on Mode Collapse: We use the flexibility in choosing transformations
gi to generate datasets of various data distribution complexities as presented in Table 1. Choosing
g(z) with successively more complicated transformations can produce synthetic datasets of increasing
complexity, the first five of which we roughly classify as Levels. The Levels are generated by
using simple transforms such as identitym constant mapping, small Multi layer perceptrons and well
conditioned linear transforms (A). On this benchmark, we investigate mode collapse across different
optimizers such as SGD & ADAM (Kingma & Ba, 2014) on several popular GAN variants such as
the non-saturating GAN Loss (GAN-NS) (Goodfellow et al., 2014), WGAN (Arjovsky et al., 2017)
and also methods targeting mitigating mode collapse specifically such as Unrolled GAN (Metz et al.,
2016) and D2GAN (Nguyen et al., 2017). We also show results of our proposed DMAT training
procedure with a simple GAN-NS, which matches performance with other more complicated mode
collapse specific GAN architectures, all of which are robust to mode collapse up to Level IV. The
procedure can be extended to even more complicated distributions than Level V, but in practice
we find all benchmarked methods to collapse at Level V. This indicates that in contrast to other
simple datasets like MNIST (LeCun, 1998), Gaussian ring, or Stacked MNIST (Metz et al., 2016),
the complexity of our synthetic dataset can be arbitrarily tuned up or down to gain insight into the
training and debugging of GAN via visualizations.
4.2	Stacked MNIST
We also benchmark several models on the Stacked MNIST dataset following (Metz et al., 2016;
Srivastava et al., 2017). Stacked MNIST is an extension of the popular MNIST dataset (LeCun et al.,
1998) where each image is expanded in the channel dimension to 28 × 28 × 3 by concatenating 3
single channel images from original MNIST dataset. Thus the resulting dataset has a 1000 overall
modes. We measure the number of modes covered by the generator as the number of classes that are
6
Under review as a conference paper at ICLR 2021
Table 4: BigGAN + DMAT Ablations on CIFAR10 (A) A relaxed spawning condition with small α and short
warmup schedule that leads to large number of discriminators (>7) (B) Long warm-up schedules that spawn new
discriminators late into training (C) A greedy strategy for assigning responsibility of fake samples ( = 0) (D)
Flipping the data splitting logic with responsibilities of fake samples being random and of real being -greedy
and (E) Choosing the discriminator with lowest score for updating Generator instead of soft random weighting.
Effect Ablation	Large |D| Small a, Short Tt	Spawn too late Long Tt schedule	Greedy VD =0	Random for fake -greedy for real	1-hot weight vector m	Proposed Method
IS	8.83 ± 0.04	9.28 ± 0.08	9.31 ± 0.06	8.95 ± 0.04	9.25 ± 0.05	9.51 ± 0.06
FID	14.23	9.37	8.6	12.5	9.25	6.11
Table 5: Per-class FID on CIFAR10: FID improves consistently across all classes.
Classes	Plane	Car	Bird	Cat	Deer	Dog	Frog	Horse	ShiP	Truck	Avg
BigGAN	24.23	12.32	24.85	21.21	12.81	22.74	17.95	13.16	12.11	18.39	8.94
+ DMAT	20.50	10.30	23.48	18.48	11.51	19.41	11.50	12.24	10.69	12.94	6.11
∆%	18.2	19.6	5.8	14.8	11.3	17.2	56.1	7.5	11.7	42.1	46.3
generated at least once within a pool of 25, 600 sampled images. The class of the generated sample is
identified with a pretrained MNIST classifier operating channel wise on the original stacked MNIST
image. We also measure the KL divergence between the label distribution predicted by the MNIST
classifier in the previous experiment and the expected data distribution.
Understanding the forgetting-collapse interplay: In Section 1, we discuss our motivation for
studying catastrophic forgetting for mitigating mode collapse. We also design an investigative
experiment to explicitly observe this interplay by comparing the number of modes the generator
learns against the quality of features the discriminator learns throughout GAN training on the stacked
MNIST dataset. We measure the number of modes captured by the generator through a pre-trained
classification network trained in a supervised learning fashion and frozen throughout GAN training.
To measure the amount of ‘forgetting‘ in discriminator, we extract features of real samples from the
penultimate layer of the discriminator and train a small classifier on the real features for detecting real
data mode. This implicitly indicates the quality and information contained in the the discriminator
extracted features. However, the performance of classification network on top of discriminator
features is confounded by the capacity of the classification network itself. Hence we do a control
experiment, where we train the same classifier on features extracted from a randomly initialized
discriminator, hence fixing a lower-bound to the classifier accuracy.
Referring to Figure 2, we observe a clear relation between the number of modes the generator covers
at an iteration and the accuracy of the classification network trained on the discriminator features
at the same iteration. In the vanilla single discriminator scenario, the classification accuracy drops
significantly, indicating a direct degradation of the discriminative features which is followed by a
complete collapse of G. In the collapse phase, the discriminator’s learnt features are close to random
with the classification accuracy being close to that of the control experiment. This indicates the
presence of significant catastrophic forgetting in the the discriminator network.
0.55
0.50
0.45
0.40
0.30
0.25
0.20
Number of Epochs
0.35
Figure 2: Investigating the forgetting-collapse interplay: We investigate our hypothesis that catastrophic
forgetting is associated with mode collapse. To this end, on the left pane, we plot the magnitude of mode collapse
by counting the number of modes produced by the generator. On the right pane, we assess the quality of the
discriminator features by plotting the accuracy of linear classifier on top of the discriminator features at each
epoch. In the original DCGAN model (OneD), the coverage of modes and the quality of discriminator features
are both low and decreasing. In particular, the test accuracy from the discriminator’s features drops almost
to randomly initialized weights (shown as control). On the other hand, adding DMAT (MultiD) dramatically
improves both mode coverage and the discriminator test accuracy.
Discriminator Test Accuracy
20	40	60	80	100
Number of Epochs
7
Under review as a conference paper at ICLR 2021
finetuned on CUB200 with the DMAT procedure (left four columns) and from an identical BigGAN finetuned
without DMAT (right four columns). We observe that while the sample quality is good for both setups, the
samples generated with DMAT are more colorful & diverse, exhibiting bright reds and yellow against a variety
of backgrounds. While the samples from vanilla fine-tuning are restricted to whites/grays & only a hint of color.
In contrast, training the same generator with the proposed DMAT procedure leads to stable training
with almost all the modes being covered and the classification accuracy increasing before saturation.
Catastrophic forgetting is thus effectively sidestepped by dynamic multi adversarial training which
produces stable discriminative features throughout training that provide a consistent training signal to
the generator thereby covering all the modes with little degradation.
4.3	CIFAR 1 0
We extensively benchmark DMAT on several GAN variants including unconditional methods such
as DCGAN (Radford et al., 2015), ResNet-WGAN-GP (Gulrajani et al., 2017; He et al., 2016) &
SNGAN (Miyato et al., 2018) and also conditional models such as BigGAN (Brock et al., 2018).
Table 3 shows the performance gain on standard GAN evaluation metrics such as Inception Score
and Frechet distance of several architectures when trained with DMAT procedure. The performance
gains indicate effective curbing of catastrophic forgetting in the discriminator with multi adversarial
training. We use the public evaluation code from SNGAN (Miyato et al., 2018) for evaluation.
Despite having other components such as spectral normalization, diversity promoting loss functions,
additional R1 losses & other stable training tricks that might affect catastrophic forgetting to different
extents, we observe a consistent increase in performance across all models. Notably the ResNet
GAN benefits greatly with DMAT despite a powerful backbone - with IS improving from 6.7 to 8.1,
indicating that the mode oscillation problem is not mitigated by simply using a better model.
DMAT can also improve performance by over 35% even on a well performing baseline such as
BigGAN (Table 3). We also investigate the classwise FID scores of a vanilla BigGAN and an identical
BigGAN trained with DMAT on CIFAR10 and report the results in Table 5. Performance improves
across all classes with previously poor performing classes such as ‘Frog’ & ‘Truck’ experiencing
the most gains. Further, we also ablate several key components of the DMAT procedure on the
BigGAN architecture with results reported in Table 4. We observe all elements to be critical to overall
performance. Specifically, having a moderate α schedule to avoid adding too many discriminators
is critical. Also, another viable design choice is to effectively flip the algorithm’s logic and instead
choose the fake points randomly while being greedy on the real points. We observe this strategy to
perform well on simple datasets but lose performance with BigGAN on CIFAR10 (Table 4).
5	Conclusion
In summary, motivated from the observation of catastrophic forgetting in the discriminator, we
propose a new GAN training framework that dynamically adds additional discriminators to prevent
mode collapse. We show that our method can be added to existing GAN frameworks to prevent mode
collapse, generate more diverse samples and improve FID & IS. As future work, we plan to apply our
method to large scale experiments to prevent mode collapse in generating higher resolution images.
8
Under review as a conference paper at ICLR 2021
References
Martin Arjovsky, Soumith Chintala, and Leon Bottou. Wasserstein gan. arXiv preprint
arXiv:1701.07875, 2017.
David Bau, Jun-Yan Zhu, Jonas Wulff, William Peebles, Hendrik Strobelt, Bolei Zhou, and Antonio
Torralba. Seeing what a gan cannot generate. In Proceedings of the International Conference
Computer Vision (ICCV), 2019.
Konstantinos Bousmalis, Alex Irpan, Paul Wohlhart, Yunfei Bai, Matthew Kelcey, Mrinal Kalakrish-
nan, Laura Downs, Julian Ibarz, Peter Pastor, Kurt Konolige, et al. Using simulation and domain
adaptation to improve efficiency of deep robotic grasping. In 2018 IEEE international conference
on robotics and automation (ICRA), pp. 4243-4250. IEEE, 2018.
Andrew Brock, Jeff Donahue, and Karen Simonyan. Large scale gan training for high fidelity natural
image synthesis. arXiv preprint arXiv:1809.11096, 2018.
Andrew Brock, Jeff Donahue, and Karen Simonyan. Large scale gan training for high fidelity natural
image synthesis. 2019.
Ishan Durugkar, Ian Gemp, and Sridhar Mahadevan. Generative multi-adversarial networks. arXiv
preprint arXiv:1611.01673, 2016.
Chrisantha Fernando, Dylan Banarse, Charles Blundell, Yori Zwols, David Ha, Andrei A Rusu,
Alexander Pritzel, and Daan Wierstra. Pathnet: Evolution channels gradient descent in super neural
networks. arXiv preprint arXiv:1701.08734, 2017.
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair,
Aaron Courville, and Yoshua Bengio. Generative adversarial nets. In Advances in neural informa-
tion processing systems, pp. 2672-2680, 2014.
Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Dumoulin, and Aaron C Courville.
Improved training of wasserstein gans. In Advances in neural information processing systems, pp.
5767-5777, 2017.
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image
recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition,
pp. 770-778, 2016.
Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter. Gans
trained by a two time-scale update rule converge to a local nash equilibrium. In Advances in neural
information processing systems, pp. 6626-6637, 2017.
Quan Hoang, Tu Dinh Nguyen, Trung Le, and Dinh Phung. Mgan: Training generative adversarial
nets with multiple generators. In International Conference on Learning Representations, 2018.
Judy Hoffman, Eric Tzeng, Taesung Park, Jun-Yan Zhu, Phillip Isola, Kate Saenko, Alexei Efros,
and Trevor Darrell. Cycada: Cycle-consistent adversarial domain adaptation. In International
conference on machine learning, pp. 1989-1998. PMLR, 2018.
Mahdi Karami, Dale Schuurmans, Jascha Sohl-Dickstein, Laurent Dinh, and Daniel Duckworth.
Invertible convolutional flow. In Advances in Neural Information Processing Systems, pp. 5635-
5645, 2019.
Tero Karras, Samuli Laine, and Timo Aila. A style-based generator architecture for generative
adversarial networks. 2019.
Tero Karras, Samuli Laine, Miika Aittala, Janne Hellsten, Jaakko Lehtinen, and Timo Aila. Analyzing
and improving the image quality of stylegan. 2020.
Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint
arXiv:1412.6980, 2014.
9
Under review as a conference paper at ICLR 2021
James Kirkpatrick, Razvan Pascanu, Neil Rabinowitz, Joel Veness, Guillaume Desjardins, Andrei A
Rusu, Kieran Milan, John Quan, Tiago Ramalho, Agnieszka Grabska-Barwinska, et al. Overcoming
catastrophic forgetting in neural networks. Proceedings of the national academy of sciences, 114
(13):3521-3526, 2017.
Yann LeCun. The mnist database of handwritten digits. http://yann. lecun. com/exdb/mnist/, 1998.
Yann LeCun, Leon Bottou, YoshUa Bengio, and Patrick Haffner. Gradient-based learning applied to
document recognition. Proceedings of the IEEE, 86(11):2278-2324, 1998.
Zinan Lin, Ashish Khetan, Giulia Fanti, and Sewoong Oh. Pacgan: The power of two samples
in generative adversarial networks. In Advances in neural information processing systems, pp.
1498-1507, 2018.
James L McClelland, Bruce L McNaughton, and Randall C O’Reilly. Why there are complementary
learning systems in the hippocampus and neocortex: insights from the successes and failures of
connectionist models of learning and memory. Psychological review, 102(3):419, 1995.
Michael McCloskey and Neal J Cohen. Catastrophic interference in connectionist networks: The
sequential learning problem. In Psychology of learning and motivation, volume 24, pp. 109-165.
Elsevier, 1989.
Sachit Menon, Alexandru Damian, Shijia Hu, Nikhil Ravi, and Cynthia Rudin. Pulse: Self-supervised
photo upsampling via latent space exploration of generative models. In Proceedings of the
IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), June 2020.
Lars Mescheder, Andreas Geiger, and Sebastian Nowozin. Which training methods for gans do
actually converge? In International Conference on Machine learning (ICML), 2018.
Luke Metz, Ben Poole, David Pfau, and Jascha Sohl-Dickstein. Unrolled generative adversarial
networks. arXiv preprint arXiv:1611.02163, 2016.
Takeru Miyato, Toshiki Kataoka, Masanori Koyama, and Yuichi Yoshida. Spectral normalization for
generative adversarial networks. arXiv preprint arXiv:1802.05957, 2018.
Gongalo Mordido, Haojin Yang, and Christoph MeineL microbatchgan: Stimulating diversity with
multi-adversarial discrimination. arXiv preprint arXiv:2001.03376, 2020.
Tu Nguyen, Trung Le, Hung Vu, and Dinh Phung. Dual discriminator generative adversarial nets. In
Advances in Neural Information Processing Systems, pp. 2670-2680, 2017.
Dong Nie, Roger Trullo, Jun Lian, Li Wang, Caroline Petitjean, Su Ruan, Qian Wang, and Dinggang
Shen. Medical image synthesis with deep convolutional adversarial networks. IEEE Transactions
on Biomedical Engineering, 65(12):2720-2730, 2018.
Alec Radford, Luke Metz, and Soumith Chintala. Unsupervised representation learning with deep
convolutional generative adversarial networks. arXiv preprint arXiv:1511.06434, 2015.
Jathushan Rajasegaran, Munawar Hayat, Salman H Khan, Fahad Shahbaz Khan, and Ling Shao.
Random path selection for continual learning. In Advances in Neural Information Processing
Systems 32, pp. 12669-12679. Curran Associates, Inc., 2019.
Kanishka Rao, Chris Harris, Alex Irpan, Sergey Levine, Julian Ibarz, and Mohi Khansari. Rl-cyclegan:
Reinforcement learning aware simulation-to-real. In Proceedings of the IEEE/CVF Conference on
Computer Vision and Pattern Recognition, pp. 11157-11166, 2020.
Roger Ratcliff. Connectionist models of recognition memory: constraints imposed by learning and
forgetting functions. Psychological review, 97(2):285, 1990.
Sylvestre-Alvise Rebuffi, Alexander Kolesnikov, Georg Sperl, and Christoph H Lampert. icarl:
Incremental classifier and representation learning. In Proceedings of the IEEE conference on
Computer Vision and Pattern Recognition, pp. 2001-2010, 2017.
10
Under review as a conference paper at ICLR 2021
Andrei A Rusu, Neil C Rabinowitz, Guillaume Desjardins, Hubert Soyer, James Kirkpatrick, Koray
Kavukcuoglu, Razvan Pascanu, and Raia Hadsell. Progressive neural networks. arXiv preprint
arXiv:1606.04671, 2016.
Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, and Xi Chen.
Improved techniques for training gans, 2016.
Akash Srivastava, Lazar Valkov, Chris Russell, Michael U Gutmann, and Charles Sutton. Veegan:
Reducing mode collapse in gans using implicit variational learning. In Advances in Neural
Information Processing Systems, pp. 3308-3318, 2017.
Hoang Thanh-Tung and Truyen Tran. On catastrophic forgetting and mode collapse in gans. arXiv
preprint arXiv:1807.04015, 2020.
P. Welinder, S. Branson, T. Mita, C. Wah, F. Schroff, S. Belongie, and P. Perona. Caltech-UCSD
Birds 200. Technical Report CNS-TR-2010-001, California Institute of Technology, 2010.
Jelmer M Wolterink, Tim Leiner, MaX A Viergever, and Ivana Isgum. Generative adversarial networks
for noise reduction in low-dose ct. IEEE transactions on medical imaging, 36(12):2536-2545,
2017.
Xin Yi, Ekta Walia, and Paul Babyn. Generative adversarial network in medical imaging: A review.
Medical image analysis, 58:101552, 2019.
Jeffrey O Zhang, AleXander SaX, Amir Zamir, Leonidas Guibas, and Jitendra Malik. Side-tuning:
Network adaptation via additive side networks. arXiv preprint arXiv:1912.13503, 2019a.
Jeffrey O. Zhang, AleXander SaX, Amir Zamir, Leonidas J. Guibas, and Jitendra Malik. Side-tuning:
Network adaptation via additive side networks. 2019b.
Mengshi Zhang, Yuqun Zhang, Lingming Zhang, Cong Liu, and Sarfraz Khurshid. Deeproad: Gan-
based metamorphic testing and input validation framework for autonomous driving systems. In
2018 33rd IEEE/ACM International Conference on Automated Software Engineering (ASE), pp.
132-142. IEEE, 2018.
11