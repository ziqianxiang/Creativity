Under review as a conference paper at ICLR 2021
Adversarial Problems for Generative Net-
WORKS
Anonymous authors
Paper under double-blind review
Ab stract
We are interested in the design of generative networks. The training of these math-
ematical structures is mostly performed with the help of adversarial (min-max)
optimization problems. We propose a simple methodology for constructing such
problems assuring, at the same time, consistency of the corresponding solution.
We give characteristic examples developed by our method, some of which can be
recognized from other applications and some are introduced here for the first time.
We compare various possibilities by applying them to well known datasets using
neural networks of different configurations and sizes.
1 Introduction
The problem we are interested in, can be summarized as follows: We are given two collections of
training data {zj} and {xi}. In the first set the samples follow the origin probability density h(z)
and in the second the target density f (x). The target density f(x) is considered unknown while
h(z) can either be known with the possibility to produce samples zj every time it is necessary or
unknown in which case we have a second fixed training set {zj}. Our goal is to design a determin-
istic transformation G(z) so that the data {yj} produced by applying the transformation y = G(Z)
onto {zj } follow the target density f (y).
Of course one may wonder whether the proposed problem enjoys any solution, namely, whether
there indeed exists a transformation G(z) capable of transforming z into y with the former following
the origin density h(z) and the latter the target density f (y). The problem of transforming random
vectors has been analyzed in Box & Cox (1964) where existence is shown under general conditions.
Computing, however, the actual transformation is a completely different challenge with one of the
possible solutions relying on adversarial approaches applied to neural networks.
The most well known usage of this result is the possibility to generate synthetic data that follow the
unknown target density f (x). In this case h(z) is selected to be simple (e.g. i.i.d. standard Gaussian
or i.i.d. uniform) so that generating realizations from h(z) is straightforward. As mentioned, the
adversarial approach can be applied even if the origin density h(z) is unknown provided that we
have a dataset {zj } with data following the origin density.
It was Goodfellow et al. (2014) that first introduced the idea of adversarial (min-max) optimiza-
tion and demonstrated that it results in the determination of the desired transformation G(z) (con-
sistency). Alternative adversarial approaches were subsequently suggested by Martin Arjovsky &
BottoU (2017); BinkoWski et al. (2018) and shown to also deliver the correct transformation G(z).
We must mention the work of Nowozin et al. (2016) in which a class of min-max optimizations,
f-GANs, was defined to design generator/discriminator pairs. Then, LiU et al. (2017) defined the
adversarial divergences class of objective fUnction which fUrther combined f-GANs, MMD-GAN
(Li et al., 2017), WGAN, WGAN-GP (GUlrajani et al., 2017), and entropic regUlarized optimal
transport problems. Also, they investigated Under what conditions the discriminator’s class has the
effect of matching generalized moments. Next, the work of Song & Ermon (2019) connected f-
GANs and Wasserstein GANs (WGANs) (Martin Arjovsky & BottoU, 2017), and later Birrell et al.
(2020) generalized the resUlts by introdUcing the (f, Γ)-divergencies which allowed to bridge f-
divergencies and integral probability metrics.
OUr class of generative adversarial problems establishes a one-to-one correspondence with f-gans
Under the ideal (non data-driven) setUp. However, we believe that oUr approach enjoys certain signif-
1
Under review as a conference paper at ICLR 2021
icant advantages: First, the definition of the two functions φ(z), ψ(z) in Equ. equation 8 is straight-
forward while Nowozin et al. (2016) requires to solve an additional optimization problem for the
derivation of each GAN loss. An additional benefit of our approach is the complete control over
the result of the maximization problem that defines the discriminator. In other words, we can de-
cide what function, the discriminator must estimate. In Nowozin et al. (2016) such flexibility does
not exist. This is important because we can select the approximation function properly so that we
avoid the need to impose difficult constraints on the discriminator output (e.g. positivity) since such
constraints tend to seriously affect the approximation quality of the corresponding neural network.
Further, there is no need for the discriminator to be a Lipschitz function, as WGAN or WGAN-GP
something that needs extra operations to ensure that the discriminator is Lipschitz.
Furthermore, we will show that the function the discriminator tries to approximate is a transfor-
mation of the likelihood ratio r(x) = g(x)/f (x) and there are important applications in Statistics
where one is interested in estimating only the transformation of the likelihood ratio with the most
common cases being the likelihood ratio itself, its logarithm (log-likelihood ratio), or the ratio 二柒)
which plays the role of the posterior probability between two densities. In other words, there are
applications where one is interested only in the “max” part of the min-max problem.
Finally, because we know what transformation of the likelihood function the discriminator tries to
approximate, it is possible to compare the different GANs on how closely they reach the optimal
value of the likelihood ratio r(x) = 1 meaning f (x) = g(x).
As in Nowozin et al. (2016), we will show that our methods provides an abundance of adversarial
problems that are capable of identifying the appropriate transformation G(z). Furthermore, we will
also provide a simple recipe as to how we can successfully construct such problems.
Arguing along the same lines of the existing min-max formulations: We would like to optimally
specify a vector transformation G(z), the generator, and a scalar function D(x), the discriminator.
To achieve this, for each combination {G(z), D(x)} we define the cost function
J(G, D) = Ex〜f [φ(D(x))] + Ez〜h [ψ(D(G(z)))]	(1)
where φ(z),ψ(z) are two scalar functions of the scalar Z and Ex〜f [∙],Ez〜h[∙] denote expec-
tation with respect to the density f (x), h(z) respectively. The optimum combination genera-
tor/discriminator is then identified by solving the following min-max problem
minmax J(G, D) = minmax {Ex〜f [φ(D(x))] + Ez〜h [ψ(D(G(z)))]}.	(2)
We must point out that our goal is not to solve equation 2, but rather find a class of functions
φ(z), ψ(z) so that the transformation G(z) that will come out of the solution of equation 2 is such
that y = G(z) follows the target density f(y) when z follows the origin density h(z).
If z is random following h(z) then y = G(z) is also random and we denote with g(y) its corre-
sponding probability density. Clearly, there exists a correspondence between transformations G(z)
and densities g(y) when the density h(z) ofz is fixed. Since we can write
Ez〜h[ψ(D(G(z)))] = Ey〜g [Ψ(D(y))],
this allows us to argue that the min-max problem in equation 2 is equivalent to
min max {Ex 〜/[。(。㈤)]+ Ey 〜g [ψ(D(y))]}	⑶
g(y) D(x)
It is now possible to combine the two expectations by applying a change of measure and a change
of variables and equivalently write equation 3 as follows:
min max
g(y) D(x)
{Ex 〜f[φ(D(x))]+ / ψ(D(x))需 f (x)dx}
min max {Eχ 〜f [φ(D(x))] + Ex 〜f [r(x)ψ(D(x))]}
g(x) D(x)
min maxEχ~f [φ(D(x)) + r(x)ψ(D(x))]}
g(x) D(x)
where r(x) = g(x)/f (x) denotes the corresponding likelihood ratio. Since f(x) is also fixed, there
is again a correspondence between r(x) and g(x), hence the previous min-max problem becomes
equivalent to
min maxEx〜f [φ(D(x)) + r(x)ψ(D(x))].	(4)
r(x)∈Lf D(x)
2
Under review as a conference paper at ICLR 2021
Here Lf denotes the class of all likelihood ratios r(x) with respect to the density f (x), namely, all
the functions r(x) that satisfy
Lf =	r(x) : r(x) ≥ 0,	r(x)f (x) dx = 1 .
(5)
Using these definitions, let us define the cost
J(r,D) = Ex〜f [Φ(D(x)) + r(x)Ψ(D(x))]	(6)
and, according to equation 4, we are interested in the following min-max problem
min max J(r, D).	(7)
r(x)∈Lf D(x)
As mentioned, our actual goal is not to solve the adversarial problem. Instead, we would like to
properly identify pairs of functions {φ(z), ψ(z)} so that equation 7 accepts as solution the function
r(X) = 1. Indeed, if r(X) = 1 is the solution to equation 7, this means that g(x) = f(x) is the
solution to equation 3 and, finally, that the optimum G(x) obtained from equation 1 is such that
y = G(x) follows g(y) = f(y) which, of course, is our original objective. Even though the min-
max problem in equation 1 is what we attempt to solve, it is through equation 7 that we understand
what its solution entails. In the next section we focus on equation 6, equation 7 and propose a simple
design method (recipe) for the two functions φ(z), ψ(z) that assures that the solution of equation 7
is indeed r(x) = 1. Before we discuss the details of our work, we would like to summarize this
paper’s contribution.
•	We design a family of GANs problems using a likelihood ratio approach. In this class, all
optimization problems have the desired property that the generator output follows the target
distribution of the random vector of interest, x, in other words, that the likelihood ratio of
the two distributions is equal to one.
•	We propose a straightforward recipe to explore the GANs family. With this methodology,
we were able to identify subgroups characterized by specific transformations of the likeli-
hood ratio. In these subgroups, we discovered novel objective functions and classified to
them previously introduced GANs (such as Wasserstein, Cross-Entropy GANs).
•	We propose a new online metric for evaluating the performance of our generative model
during training.
•	Our experiments provide insights for the behavior of the different GANs objective func-
tions, with some of the novel objective functions performing better than the already known
GANs.
2	A CLASS OF FUNCTIONS φ(z), ψ(z)
Suppose that ω(r) is a strictly increasing and (left and right) differentiable scalar function of the
nonnegative scalar r, i.e. r ∈ [0, ∞). Denote with Jω = ω [0, ∞) the range of values of ω(r) and
let ω-1 (z) be the inverse function of ω(r) which exists and is defined for z ∈ Jω. Let ρ(z) > 0 be a
positive scalar function also defined for z ∈ Jω then, using ω(r) and ρ(z), we propose the following
pair φ(z), ψ(z)
φ0(z) = -ω-1(z)ρ(z), ψ0(z) = ρ(z),	(8)
where “ 0 ” denotes derivative. Since ω(r) and ρ(z) are arbitrary (provided they satisfy the strict
increase and positivity constraint respectively), the class of pairs defined by equation 8 is very rich
allowing for a multitude of choices. We show next that any such pair {φ(z), ψ(z)} gives rise to a
min-max problem, as in equation 7, that accepts r(x) = 1 as its unique solution. We prove this claim
in two steps. The first, involves a theorem where we consider a simplified version of the min-max
problem.
Theorem 1 Let ω(r), φ(z), ψ(z) and Jω be defined as above with the additional constraint
ψ ω(1) = 0. Fix r ≥ 0 and consider φ(D) + rψ (D) as a function of the scalar D. Then,
for any D ∈ Jω, we have that
φ(D) + rψ(D) ≤ φ(ω(r)) + rψ(ω(r)),
(9)
3
Under review as a conference paper at ICLR 2021
with equality if and only if D = ω (r).
Consider next the minimization with respect to r of the maximal value in equation 9. It is then true
that
min {φ(ω(r)) + rψ(ω(r))} = φ(ω(1)),	(10)
with equality if and only if r = 1.
A consequence of Theorem 1 is the next corollary, which constitutes the second and final step
in proving that the adversarial problem defined in equation 7 has as unique solution the function
r(X) = 1.
Corollary 1 If the functions φ(z), ψ(z) satisfy equation 8 and ω(r) is strictly increasing and left
and right differentiable, then in the adversarial problem defined in equation 7 the maximizer is
D(X) = ω r(X) and the minimizer is r(X) = 1, while the resulting min-max value is equal to
min max Eχ~f [φ(D(x)) + r(X)ψ(D(x))] = φ(ω⑴)+ ψ(ω(1)).	(11)
r(X)∈Lf D(x)
2.1	Subclassses of the gans family
Let us now present some of the subclasses of the GANs family, where each subclass is character-
ized by the type of transformation of the likelihood ratio, ω(r). Once we fix ω(r) and give pairs
{φ(z), ψ(z)} that satisfy equation 8, we are able to “pick” objective functions laying in the ω(r)
subregion.
Subclass A: ω(r) = rɑ The first examined subclass is the simplest one, consisting of just powers
of the likelihood ratio. To the best of our knowledge, this is the first work proposing objective
functions from this class. To find the pairs {φ(z), ψ(z)} we proceed as follows.
We have that ω-1(z) = Z 1 and Jω = [0, ∞). According to equation 8, for Z ∈ [0, ∞) We must
define φ0(Z) = -Z1 P(Z), ψ0(z) = P(Z) Also r = D-a. Some examples of this subclass are
presented in Table 1.
For the particular selection ω(r) = r (corresponding to α = 1) we can show that the resulting cost
is equivalent to the Bregman cost (Bregman, 1967). In fact there is a one-to-one correspondence
between our P(Z ) function and the function that defines the Bregman cost. This correspondence
however is lost once we switch to a different α or a different ω(r) function, suggesting that the
proposed class of pairs {φ(Z), ψ(Z)}, is far richer than the class induced by the Bregman cost.
Table 1: Subclass A optimization problems for GANs
GAN	φ(Z)	ψ(Z)	Jω
A1a	-Z	log(Z)	[0, ∞)
A1b	- log(Z)	-Z-1	[0, ∞)
A2	-(1+Z)	-(1 + Z-1)	[0, ∞)
A3	- log(1 + Z)	- log(1 + Z-1)	[0, ∞)
MSE	-0.5Z2	Z	[0, ∞)
Subclass B: ω(r) = α-1 logr This subclass considers one of the most popular transformations of
the likelihood ratio, the log-likelihood ratio. As with subclass A for the first time, the next exam-
ples are presented. They can be used either under a min-max setting, for the determination of the
generator/discriminator pair, or under a pure maximization setting for the direct estimation of the
log-likelihood ratio function log r(x).
We have ω-1(Z) = eαz and Jω = R. As before P(Z) must be strictly positive and, according to
equation 8, for all real Z we must define φ0(Z) = -eαzP(Z), ψ0(Z) = P(Z). And the likelihood ratio
is r = eaD. In Table 2 we can see some examples of this subclass.
Subclass C: ω(r) = r+ɪ As We already mentioned, this is another important transform of the likeli-
hood ratio. Interestingly, in this subclass belongs the first introduced GAN (Goodfellow et al., 2014)
the Cross Entropy GAN.
4
Under review as a conference paper at ICLR 2021
Table 2: Subclass B optimization problems for GANs
GAN	φ(z)
B1a	-ez
B1b	-z
Exponential -e0.5z
B2	- log(1 + ez)
ψ(Z)	Jω
ez	R
-e-z	R
-e-0.5z	R
- log(1 + e-z)	R
When ω(r) = r^ We have ω-1(z) = i-z and Jω = [0,1]. For ρ(z) > 0,z ∈ [0,1] We must
define the functions φ(z), ψ(z) according to equation 8 φ0(z) = -ι-zρ(z), ψ0(z) = P(Z) In this
case the likelihood ratio is r = IDD. In Table 3 we see the cross entropy GAN and C2 which is
presented here for the first time.
Table 3:	Subclass C optimization problems for GANs
GAN	φ(z)	ψ(z) Jω
Cross Entropy log(1 - z)	log(z)	[0, 1]
C2	z + log(1 -z)	z	[0, 1]
Subclass D: ω(r) = sign(log r) This is a special case of ω(r) with the corresponding function not
being strictly increasing. It turns out that we can still come UP with optimization problems, two
of which are known and used in practice, by considering ω(r) as a limit of a sequence of strictly
increasing functions.
Monotone Loss: As a first approximation we propose Sign(Z) ≈ tanh( CZ) where C > 0 a parameter.
We note that limc→∞ tanh(CZ) = Sign(Z). Using this approximation we can write
sign(log r ) ≈ tanh
C log r
rc - 1
rc + 1
ω(r).
(12)
As we mentioned, we have exact equality for c → ∞. Let us perform our analysis by assuming
that c is finite. We note that ω-1(Z) = (1—∣) 1 and Jω = [-1,1]. Consequently, if P(Z) > 0 for
1
Z ∈ [-1,1], we must define Φ0(z) = - (l⅛) C P(Z), Ψ0(z) = p(z).
D1) If we let c → ∞ in order to converge to the desired sign function, this yields φ0(Z) = -P(Z)
and ψ0(Z) = P(Z). This suggests that φ(Z) = - z P(x)dx is decreasing and ψ(Z) = z P(x)dx =
-φ(Z) is increasing. In fact any strictly increasing function ψ(Z) can be adopted provided we select
φ(Z) = -ψ(Z).
There is a popular combination that falls under Case D1). In particular, the selection ψ(Z) = Z =
-φ(Z) reminds us of Wasserstein GAN Martin Arjovsky & Bottou (2017), with two differences, in
our case Z should lie in [-1, 1] and the discriminator is not constrained to be a Lipschitz function.
Hinge Loss: As a second approximation we use the expression Sign(Z) ≈ Sign(Z)|z|C, c > 0,
which is strictly increasing, continuous and converges to Sgn(Z) as c → ∞. This suggests that
sign(logr) ≈ sign(log r) | log r|c = ω(r),	(13)
and ω-1(Z) = ezC. Since ω(r) can assume any real value we conclude that Jω = R which, clearly,
differs from the previous approximation where we had Jω = [-1, 1]. If P(Z) > 0, Z ∈ R then,
according to equation 8 we must define φ0(Z) = -ezCP(Z), ψ0(Z) = P(Z). We present the following
case that leads to a very well known pair from a completely different application.
D2) If we select Ψ0(z) = P(Z) = {e-|z| C +1z<-ι} > 0 then Φ0(z) = -ez C {e-|z| C +1z<-ι}. Ifwe
now let c → ∞, we obtain the limiting form for the derivatives which become ψ0(Z) = -1z<1 and
φ0(Z) = 1z>-1. By integrating we arrive at φ(Z) = - max{1 + Z, 0} and ψ(Z) = - max{1 - Z, 0}.
we notice that since c → ∞ we cannot find the likelihood ratio in terms of the discriminator. The
cost based on this particular pair is called the hinge loss Tang (2013) and it is very popular in binary
classification where one is interested only in the maximization problem. The corresponding method
is known to exhibit an overall performance which in practice is considered among the best Rosasco
et al. (2004); Janocha & Czarnecki (2017). Here, as in Zhao et al. (2016), we propose the hinge loss
as a means to perform adversarial optimization for the design of the generator G(x).
5
Under review as a conference paper at ICLR 2021
Table 4:	Optimization problems for GANs
GAN	φ(z)	ψ(z)	Jω
Hinge	-(1 +	z)+	-(1 -	z)+	R
Wasserstein	z	-z	R
In Table 4 we can see Hinge and Wasserstein GANs optimization problems.
The detailed derivation of the above optimization problems and some more examples can be found
in Appendix A.2.
This completes our presentation of examples. However, we must emphasize, that these are only a
few illustrations of possible pairs {φ(z), ψ(z)} one can construct. Indeed combining, as dictated by
equation 8, any strictly increasing function ω(r) with any positive function ρ(z) generates a legit-
imate pair {φ(z), ψ(z)} and a corresponding min-max problem equation 7 that enjoys the desired
solution r(x) = 1.
Remark 1 Given the numerous choices we have in defining adversarial optimizations for solving
the same problem, one may wonder whether there exists a means to rank these methods and identify
the most efficient, at least for classes of data. This is an extremely challenging question which,
unfortunately, finds no answer even in simpler problems. For example, in binary classification there
are also classes of optimization problems that are used to train neural networks Bartlett et al. (2006);
Masnadi-Shirazi & Vasconcelos (2009). However, until now, no theoretical analysis exists that can
order them and designate the most efficient one. This is possible only through experience with
countless simulations.
3 Data-Driven Setup and Neural Networks
Let us now consider the data-driven version of the problem. As mentioned, the target density f(x) is
unknown. Instead we are given a collection of realizations {xi} that follow f (x) and a second col-
lection {zj} that follows the origin density h(z). These data constitute our training set. Regarding
the second set {zj } it can either become available “on the fly” when h(z) is known by generating
realizations every time they are needed, or it can be considered fixed from the start exactly as {xi },
if h(z) is also unknown. As we pointed out in Section 1, we are interested in designing a generator
G(z) so that when we apply it onto the data zj, that is, yj = G(zj) the resulting yj will follow
a density that matches the target density f (x). Since we are now considering the data-driven ver-
sion of the problem, we are going to limit G(z), D(x) to be the outputs of corresponding neural
networks. Therefore the generator is replaced by G(z, θ) while the discriminator by D(x, H) where
θ, H summarize the parameters of the two neural networks. Of course instead of neural networks one
could use any other parametric family, as SVMs, capable of efficiently approximating any nonlinear
function.
Once we have selected our favorite ω(r) and ρ(z) functions we can compute from equation 8 the
functions φ(z), ψ(z) that enter into the min-max problem defined in equation 2. This problem, after
limiting the generator and discriminator to neural networks, can be rewritten as follows
min max J(θ,H) = min max {Eχ〜f [φ(D(x, H))] + EZ〜h [ψ(D(G(z,θ),H))]}.	(14)
θ 鲁	θ 外
If θo , Ho are the corresponding optimum parameter values, and the structure of the two networks
is sufficiently rich, we expect that G(z, θo), D(x, Ho) will approximate the optimum functions
D(x), G(z) of the ideal problem in equation 2 respectively. In particular for θo, the generator
G(z, θo), whenever applied onto any zj that follows h(z), it will result in a yj = G(zj, θo) that
follows a density which is expected to be close to the target density f (y).
Remark 2 When replacing D(x), G(z) with neural networks we must take special care of the corre-
sponding outputs. Basically, we must guarantee that they are of the correct form. This is particularly
important in the case of the scalar output D(x, H) of the discriminator. We recall that the optimum
discriminator is D(x) = ω r(x) . This implies that we need to assure that D(x, H) takes values
in Jω (the range of ω(r)). Consequently, we must apply the proper nonlinearity in the output of the
discriminator that will guarantee this fact.
6
Under review as a conference paper at ICLR 2021
4 Experiments
In this section, we want to examine the performance of the GANs objectives presented in Table 4
for different datasets. For that reason we tested their performance on four different datasets, namely
MNIST (LeCun et al., 1998), CelebA (Liu et al., 2015), CIFAR-10 datasets (Krizhevsky et al., 2009),
and Stanford Cars (Krause et al., 2013). We recall that GANs are notorious for their nonrobust
behavior Bengio (2012); Creswell et al. (2018); Mescheder et al. (2017). For the stabilization of the
training process, we used the maximum gradient-penalty methodology which was generalized to a
class of Lipschitz GANs in Zhou et al. (2019) (implementation details in Appendix A.3). In this
section we present our results for the regularization parameter λ = 10, in the Appendix we included
results for different values of λ.
In Tables 5, 6 we present the final attained Frechet Inception Distances (FID) Heusel et al. (2017)
and Kernel Inception Distances (KID) BinkoWski et al.(2018) scores after training. In Table 7 We
computed the absolute difference of the discriminator estimated likelihood ratio from the optimal
likelihood ratio, Which is equal to one and the variance around the optimal value. For Hinge and
Wasserstein GANs We cannot compute the likelihood ratio related metrics, as We mentioned in
section 2.1. Also, in Figure 4 We shoW the evolution of FID (second roW) and KID (third roW) during
training. In the first row we see the value of the distance d(x, y) = ∣Eχ 〜f [D(x)]-Ey 〜g [D(y)]∣. For
the expectations estimation, We used 64 examples for MNIST and 128 for Stanford Cars, CelebA,
and CIFAR-10. We believe that this is an insightful quantity since its value is an indicator of how
accurate the discriminator can distinguish samples from the target distribution and the generator
output. Finally, in Appendix A.3, some generated samples of our trained generative models are
included.
Table 5: FID Scores
GAN	CARS	CELEBA	CIFAR10	MNIST
A1a	23.30 ± 0.10	7.53 ± 0.02	9.67 ± 0.01	2.18 ± 0.01
A1b	24.22 ± 0.22	7.68 ± 0.04	9.69 ± 0.04	2.13 ± 0.01
A2	24.40 ± 0.04	7.62 ± 0.04	9.53 ± 0.04	2.17 ± 0.01
A3	23.64 ± 0.23	8.50 ± 0.06	9.72 ± 0.04	2.15 ± 0.01
MSE	23.99 ± 0.04	7.66 ± 0.07	9.61 ± 0.03	2.15 ± 0.01
B1a	23.60 ± 0.12	8.06 ± 0.02	9.67 ± 0.05	2.13 ± 0.01
B1b	23.91 ± 0.07	8.07 ± 0.06	9.67 ± 0.04	2.18 ± 0.01
Exponential	23.52 ± 0.06	9.15 ± 0.03	9.79 ± 0.03	2.13 ± 0.01
B2	23.46 ± 0.12	9.39 ± 0.06	9.79 ± 0.07	2.09 ± 0.01
Cross Entropy 25.39 ± 0.16		7.53 + 0.03	9.72 ± 0.09	2.08 ± 0.01
C2	24.36 ± 0.12	7.47 ± 0.01	9.75 ± 0.03	2.10 ± 0.01
Hinge	22.88 ± 0.14	10.91 ± 0.05	9.99 ± 0.03	2.16 ± 0.01
Wasserstein	23.99 ± 0.04	10.08 ± 0.04	9.74 ± 0.02.	2.16 ± 0.01
	Table 6: KID Scores			
GAN	CARS	CELEBA	CIFAR10	MNIST
	×10-6±×10-12	×10-⅛×10T2	×10-6±×10-12	×10-4±×10-8
A1a	4.03 ± 2.45	2.57 ± 5.05	2.75 ± 8.47	7.80 ± 5.86
A1b	3.33 ± 1.89	2.67 ± 8.35	2.36 ± 5.86	6.30 ± 4.32
A2	4.36 ± 3.18	3.38 ± 9.68	3.09 ± 8.35	8.79 ± 4.65
A3	4.42 ± 2.49	7.29 ± 5.48	2.40 ± 4.95	8.53 ± 7.35
Mean Square	3.79 ± 1.71	2.55 ± 9.34	2.09 ± 5.63	8.64 ± 7.51
B1a	6.17 ± 3.62	5.56 ± 9.78	2.35 ± 5.52	8.05 ± 3.30
B1b	5.24 ± 2.27	7.32 ± 1.18	2.63 ± 8.42	6.85 ± 3.71
Exponential	5.49 ± 2.86	10.05 ± 6.10	2.81 ± 8.34	6.88 ± 3.41
B2	7.06 ± 3.40	12.48 ± 7.38	2.47 ± 5.42	8.82 ± 3.69
Cross Entropy	13.09 ± 8.95	3.53 ± 12.65	2.53 ± 5.58	6.16 ± 5.37
C2	8.45 ± 2.92	3.11 ± 9.72	4.17 ± 11.03	7.72 ± 3.36
Hinge	4.97 ± 3.50	26.65 ± 16.81	3.97 ± 9.42	8.33 ± 4.16
Wasserstein	4.92 ± 2.70	20.45 ± 28.38	1.74 ± 5.22	7.33 ± 3.33
7
Under review as a conference paper at ICLR 2021
MNIST
CARS
=(X)Q可Λ(x)0■互
0.5	1	1.5
Iterations	×ιo5
A1a
・A1b・A2
■Exponential ・B2 HCross Entropy ・C2 HHinge MWasserstein
CELEBA
=(X) α一陶l(x)包里
11
・A3・MSE ・B1a
CIFAR10
百
K0.01
X
a
忖
5	10	15
Iterations	×ιo4
25
22
24
LT
23
0.5	1	1.5
Iterations	×105
Q
工
0.5	1	1.5
Iterations	xιo5
10
5	10	15
Iterations	xιo4
×10-6
2.3
2.25
2.15
2.1
2.2
工
0.5	1	1.5
Iterations	xιo5
0.5	1	1.5
Iterations	×105
x10-5
1.5
Q
1
0.5
0.5	1	1.5
Iterations	×ιo5
6
Q
4
2
Q
S
×10-3
1.4
1
0.5	1	1.5
Iterations	xιo5
5	10	15
Iterations	×ιo4

Figure 1: Evolution of the corresponding FID and KID scores during training for the datasets Stan-
ford Cars, CelebA, CIFAR10, and MNIST.
Table 7: Mean absolute difference of the discriminator estimated likelihood ratio from the optimal
value and variance around the optimal likelihood ratio.
GAN	CARS CELEBA CIFAR10 MNIST
×1, ×10-2	×1, ×10-3	×10-2, ×10-4	×10-1, ×10-5
A1a	0.10, 0.29	0.01, 0.17	1.79, 1.33	0.07, 6.49
A1b	0.38, 0.37	0.01, 0.20	5.71, 1.73	0.13, 8.05
A2	0.12, 0.21	0.01, 0.11	1.83, 1.16	0.07, 5.25
A3	0.17, 0.13	0.01, 0.14	1.27, 4.79	0.05, 2.72
Mean Square	0.13, 0.62	0.01, 0.26	1.78, 2.04	0.07, 6.16
B1a	0.17, 0.72	0.01, 0.49	1.46, 1.36	0.08, 8.91
B1b	0.14, 0.40	0.01, 0.57	1.63, 1.49	0.07, 7.67
Exponential	0.03, 0.16	0.01, 0.97	0.52, 4.34	0.04, 2.88
B2	0.03, 0.14	0.01, 0.90	0.55, 4.86	0.04, 3.07
Cross Entropy	0.16, 3.98	0.03, 0.02	0.52, 0.44	1.39, 2.66
C2	0.41, 6.70	0.03, 0.94	0.38, 0.20	1.39, 2.74
For the MNIST dataset, the different GANs have very similar performance, something that is rea-
sonable since this is a simple dataset. The d(x, y) curves are quickly converging indicating that the
discriminator has stabilized. Interestingly, the FID, KID curves for GANs with similar d(x, y) have
also close FID, KID scores. In particular, Subclass C GANs (Cross-Entropy with C2); Subclass D
(Hinge) with Wasserstein; B2, B1a and A3; B1b with Exponential; A1b with A2; and A1a with
MSE. For the CIFAR-10 dataset, the FID and KID scores for different objective functions tend to
have similar behavior, but some differences exist. In particular, the objectives A1a, A1b, A2, MSE,
B1a, B1b in the initial iterations create a steep valley for the metric d(x, y); and at the same time
in the FID score, these objectives attain smaller FID scores faster than the other GANs. Also, the
further improvement of the scores during training seems to be related to the behavior of d(x, y). For
instance, the d(x, y) of A1b, A2 is still increasing during the last iterations, and the generated image
quality (FID score) is improving. Lastly, similar to MNIST, GANs that have very close d(x, y) tend
to have close FID, KID curves.
8
Under review as a conference paper at ICLR 2021
For Stanford Cars and CelebA, we observe some performance gaps between different subclasses.
Specifically for CelebA, the Subclass D and Subclass B objective functions start to diverge after
some training steps, something that is evident from the FID and KID curves where the scores in-
crease dramatically after approximately the first half of iterations. Also, this is noticeable for the
d(x, y), where a sudden drop is evident around the same period. Interestingly the variance around the
optimal likelihood ratio value is increased for the GANS who started to diverge. For Stanford cars,
the Subclass C has the worst performance, with the recorded MMD score being an order larger than
the other objectives (expect Subclass B -B2, Exponential objectives-). Furthermore, for this dataset,
the distances d(x, y) are “noisy” (strong fluctuations) and with approximately ten times larger mag-
nitude value when compared to the corresponding curves in the other datasets. It is reasonable since
this dataset is a complex one, where we have natural scenes with cars, and, importantly, significantly
smaller (- 8000 training samples, when MNIST, CIFAR10 has 60000 and CelebA 200000).
In summary, our simulations indicate that the Subclass A objectives A1a, A1b, A2, MSE have
the best performance both in terms of the computed metrics (hence image generation quality) and
stability during training. They might not give the exact best score in all datasets, but are very
close to the best recorded, and, most importantly, they have an overall more stable behavior when
compared to objectives from the other subclasses. Furthermore, the discriminator convergence to
the optimal likelihood ratio between the dataset and the generator output can be an ad-hoc measure
of the behavior/stability of our generative models than can be used during training to provide online,
useful insights of the current training condition.
5 Conclusion
In this paper, we provided and demonstrated a straightforward methodology to determine loss func-
tions that solve the generative adversarial problem. Our results suggest that there is not a single
loss function that achieves the best performance in terms of the examined metrics for all different
datasets. This performance variation among loss functions becomes evident as the increasing com-
plexity of the datasets that convolutes the generation task is better addressed by some loss functions
that clearly outperform others. Specifically, in simpler datasets, such as MNIST, the evaluated loss
functions yield very similar performance, whereas, in more intricate datasets like CelebA, CIFAR-
10, and Stanford Cars, performance ”gaps” between the different loss functions, and different sub-
classes, emerges. Our findings also propose that in every generation task unexplored loss functions
outperformed the previously proposed ones. Consequently, this function class is worth-exploring
to identify new loss functions that can be used and evaluated in different applications. Our method
provides a versatile tool that can be exploited in that direction.
9
Under review as a conference paper at ICLR 2021
References
Peter L Bartlett, Michael I Jordan, and Jon D McAuliffe. Convexity, classification, and risk bounds.
Journal of the American Statistical Association,101(473):138-156, 2006.
Yoshua Bengio. Practical recommendations for gradient-based training of deep architectures. In
Neural networks: Tricks of the trade, pp. 437-478. Springer, 2012.
Mikolaj BinkoWski, Dougal J Sutherland, Michael Arbel, and Arthur Gretton. Demystifying mmd
gans. arXiv preprint arXiv:1801.01401, 2018.
Jeremiah Birrell, Paul Dupuis, Markos A. Katsoulakis, and Yannis Pantazis. (f, γ)-
divergences: Interpolating betWeen f-divergences and integral probability metrics. arXiv preprint
arXiv:2011.05953, 2020.
George EP Box and David R Cox. An analysis of transformations. Journal of the Royal Statistical
Society: Series B (Methodological), 26(2):211-243, 1964.
Lev M Bregman. The relaxation method of finding the common point of convex sets and its applica-
tion to the solution of problems in convex programming. USSR computational mathematics and
mathematical physics, 7(3):200-217, 1967.
Antonia CresWell, Tom White, Vincent Dumoulin, Kai Arulkumaran, BisWa Sengupta, and Anil A
Bharath. Generative adversarial netWorks: An overvieW. IEEE Signal Processing Magazine, 35
(1):53-65, 2018.
Ian GoodfelloW, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair,
Aaron Courville, and Yoshua Bengio. Generative adversarial nets. In Advances in neural infor-
mation processing systems, pp. 2672-2680, 2014.
Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Dumoulin, and Aaron C Courville. Im-
proved training of Wasserstein gans. In Advances in neural information processing systems, pp.
5767-5777, 2017.
Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter.
Gans trained by a tWo time-scale update rule converge to a local nash equilibrium. In Advances
in neural information processing systems, pp. 6626-6637, 2017.
Katarzyna Janocha and Wojciech Marian Czarnecki. On loss functions for deep neural netWorks in
classification. arXiv preprint arXiv:1702.05659, 2017.
Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint
arXiv:1412.6980, 2014.
Jonathan Krause, Michael Stark, Jia Deng, and Li Fei-Fei. 3d object representations for fine-grained
categorization. In 4th International IEEE Workshop on 3D Representation and Recognition
(3dRR-13), Sydney, Australia, 2013.
Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images.
2009.
Yann LeCun, Leon Bottou, YoshUa Bengio, and Patrick Haffner. Gradient-based learning applied to
document recognition. Proceedings of the IEEE, 86(11):2278-2324, 1998.
Chun-Liang Li, Wei-Cheng Chang, Yu Cheng, Yiming Yang, and Barnabas Poczos. Mmd gan:
ToWards deeper understanding of moment matching netWork. In Advances in Neural Information
Processing Systems, pp. 2203-2213, 2017.
Shuang Liu, Olivier Bousquet, and Kamalika Chaudhuri. Approximation and convergence proper-
ties of generative adversarial learning. In Advances in Neural Information Processing Systems,
pp. 5545-5553, 2017.
ZiWei Liu, Ping Luo, Xiaogang Wang, and Xiaoou Tang. Deep learning face attributes in the Wild.
In Proceedings of the IEEE international conference on computer vision, pp. 3730-3738, 2015.
10
Under review as a conference paper at ICLR 2021
SC Martin Arjovsky and Leon Bottou. Wasserstein generative adversarial networks. In Proceedings
of the 34 th International Conference on Machine Learning, Sydney, Australia, 2017.
Hamed Masnadi-Shirazi and Nuno Vasconcelos. On the design of loss functions for classification:
theory, robustness to outliers, and savageboost. In Advances in neural information processing
systems ,pp.1049-1056, 2009.
Lars Mescheder, Sebastian Nowozin, and Andreas Geiger. The numerics of gans. In Advances in
Neural Information Processing Systems, pp. 1825-1835, 2017.
Sebastian Nowozin, Botond Cseke, and Ryota Tomioka. f-gan: Training generative neural samplers
using variational divergence minimization. In Advances in neural information processing systems,
pp. 271-279, 2016.
Lorenzo Rosasco, Ernesto De Vito, Andrea Caponnetto, Michele Piana, and Alessandro Verri. Are
loss functions all the same? Neural Computation, 16(5):1063-1076, 2004.
Jiaming Song and Stefano Ermon. Bridging the gap between f -gans and wasserstein gans. arXiv
preprint arXiv:1910.09779, 2019.
Masashi Sugiyama, Taiji Suzuki, and Takafumi Kanamori. Density ratio estimation: A comprehen-
sive review (statistical experiment and its related topics). 2010.
Masashi Sugiyama, Taiji Suzuki, and Takafumi Kanamori. Density ratio estimation in machine
learning. Cambridge University Press, 2012.
Yichuan Tang. Deep learning using linear support vector machines. arXiv preprint arXiv:1306.0239,
2013.
Junbo Zhao, Michael Mathieu, and Yann LeCun. Energy-based generative adversarial network.
arXiv preprint arXiv:1609.03126, 2016.
Zhiming Zhou, Jiadong Liang, Yuxuan Song, Lantao Yu, Hongwei Wang, Weinan Zhang, Yong Yu,
and Zhihua Zhang. Lipschitz generative adversarial nets. arXiv preprint arXiv:1902.05687, 2019.
11
Under review as a conference paper at ICLR 2021
A Appendix
A.1 Proofs
Theorem 1 Proof. We note that the constraint ψ ω(1) = 0 does not affect the generality of our
class of functions since from equation 8 we have that ψ(z), after integration, is defined up to an
arbitrary additive constant. We can always select this constant so that the constraint is satisfied. We
would also like to emphasize that this constraint is needed only for the proof of this theorem and it
is not necessary for the corresponding min-max problem defined in equation 7.
For fixed r, to find the maximum of φ(D) + rψ(D) we consider the derivative with respect to D
which, using equation 8, takes the form
φ0(D) + rψ0(D) = (r - ω-1(D))ρ(D).
The strict increase of ω(r) is inherited by its inverse function ω-1(z) which, combined with the
positivity of ρ(z), implies that the previous expression has the same sign as r-ω-1(D) or ω(r) -D.
Consequently D = ω(r) is the only critical point of φ(D) + rψ(D) which is a global maximum.
Of course there are possibilities for extrema at the two end points of Jω but they can only be (local)
minima.
Let us now focus on the resulting function φ ω(r) + rψ ω(r) . Taking its derivative with respect
to r yields
{φ(ω(r)) + rψ(ω(r))}0 = {φ0(ω(r)) + rψ0(ω(r))} ω0(r) + ψ(ω(r)) = ψ(ω(r)),
where the last equality is due to the specific definition of the two functions φ(z), ψ(z) in equation 8.
Since ψ0(z) = ρ(z) > 0, this implies that ψ(z) is strictly increasing, being also the integral of ρ(z)
it is continuous in z. If we combine this property with the strict increase and continuity (as a result
of left and right differentiability) of ω(r) we conclude that ψ ω(r) is also strictly increasing and
continuous in r. We recall that ψ(z) is selected to satisfy ψ ω(1) = 0, consequently for r = 1 the
function φ ω(r) + rψ ω(r) has a unique minimum which is global and no other critical points.
Of course it can still exhibit extrema at r = 0 and/or r → ∞ but they can only be (local) maxima.
Corollary 1 Proof. First, we observe that
Ex〜f [φ(D(x)) + r(x)ψ(D(x))] = Ex〜f [φ(D(x)) + r(x)ψ(D(x))] + ψ(ω(1))	(15)
With the last equality being true since Ex〜f [r(x)] = 1 and where ψ(z) = ψ(z) - ψ (ω⑴).We start
with the maximization problem. Since D(x) is a function of x we have
max Ex〜
D(x)
[φ(D(x)) + r(x)Ψ(D(x))]
Ex〜f
max {φ(D(x)) + r(x)Ψ(D(x))}
(16)
f
The maximization under the expectation can be performed for each fixed x. However, when we
fix x then r(x) becomes a constant and the result of the maximization depends only on the actual
value of r(x). This suggests that we can limit ourselves to functions of the form D(x) = D r(x) .
After this observation we can drop the dependence on x and perform, equivalently, the maximization
maxD {φ(D(r)) + rψ (D(r))} for each fixed r. The pair {φ(z), ψ(z)} satisfies the assumptions of
Theorem 1, therefore maximization is achieved for D(r) = ω(r). This implies that
max
D(x)
Ex~f [φ(D(x)) + r(x)ψ(D(x))] = Ex〜f
[φ(ω(r(x))) + r(x)ψ(ω(r(x)))] + ψ(ω(1)).
12
Under review as a conference paper at ICLR 2021
We can now continue in a similar way for the minimization problem. Specifically
min max Ex〜f
r(x)∈Lf D(x)
[φ(D(x)) + r(x)Ψ(D(x))]
min Ex 〜f [φ(ω(r(x))) + r(x)ψ(ω(r(x)))] ≥
r
min {φ(ω(r(x))) + r(x)ψ(ω(r(x)))}j ≥
Ex~f [min {φ(ω(r)) + rψ(ω(r))}]=
φ(ω ⑴)
with the last inequality being true since the minimization that follows is unconstrained and the last
equality being a consequence of Theorem 1. The final lower bound is clearly attained by r(X) = 1,
which is also a legitimate solution of the constrained minimization, since r(X) = 1 belongs to
the class Lf of likelihood ratios. Consequently r(X) = 1 is the solution to the min-max problem.
Returning to the original min-max setup with ψ(z) replacing ψ(z), we can clearly see that it satisfies
equation 11. This completes the proof.
A.2 The subclasses of the GANs Family
Subclass A: ω(r) = rɑ The first examined subclass is the simplest one, consisting of just powers
of the likelihood ratio. To the best of our knowledge, this is the first work proposing objective
functions from this class. To find the pairs {φ(z), ψ(z)} we proceed as follows.
We have that ω-1(z) = Z 1 and Jω = [0, ∞). According to equation 8, for Z ∈ [0, ∞) We must
define φ0(z) = -Z1 P(Z), ψ0(z) = ρ(z). The following examples can be shown to satisfy these
equations.
A1) If We select P(Z) = Ze, with β = -1,-1 - 1, this yields φ(z)=-
For β = -1, P(Z) = Z-1, Φ(z) = -αZ 1, Ψ(z) = logz. For β =
Φ(z) = — logz, ψ(z) = -αz- 1.
z1+ 1+β
1+1+β
and ψ(Z)
, P(Z) =
1+β
z
——
1+e .
ZT- 1,
-1 - 1
α
A2) If we select α = 1, ρ(z)=())then, φ(z) = -(1 + z) and ψ(z) = -(1 + z-1).
A3) If we select α = 1, ρ(z) =(^^ then, φ(z) = — log(1 + z) and ψ(z) = — log(1 + z-1).
For the particular selection ω(r) = r (corresponding to α = 1) we can show that the resulting cost
is equivalent to the Bregman cost (Bregman, 1967). In fact there is a one-to-one correspondence
between our P(Z ) function and the function that defines the Bregman cost. This correspondence
however is lost once we switch to a different α or a different ω(r) function, suggesting that the
proposed class of pairs {φ(Z), ψ(Z)}, is far richer than the class induced by the Bregman cost.
We should mention that in A1) the selection α = 1, β = 0 is known as the mean square error
criterion and if we apply only the maximization problem then this corresponds to a likelihood ratio
estimation technique proposed in the literature by Sugiyama et al. (2010; 2012). We will refer to
this case as the MSE GAN.
Subclass B: ω(r) = α-1 logr This subclass considers one of the most popular transformations of
the likelihood ratio, the log-likelihood ratio. As in the first subclass, for the first time, the next
examples are presented. They can be used either under a min-max setting, for the determination of
the generator/discriminator pair, or under a pure maximization setting for the direct estimation of
the log-likelihood ratio function log r(x).
We have ω-1(Z) = eαz and Jω = R. As before P(Z) must be strictly positive and, according to
equation 8, for all real Z we must define φ0(Z) = -eαzP(Z), ψ0(Z) = P(Z). The following examples
satisfy these equations.
13
Under review as a conference paper at ICLR 2021
B1) If ρ(z) = e-βz with β 6= 0, α, this produces φ(z) =
ρ(z) = 1, φ(z) = - eα^-, ψ(z) = z. If β = α then ρ(z)
We call the α = 1, β = 0.5 case the Exponential GAN.
e(α-β)-
a-β
, ψ(z)
e-αz, φ(z)
二一 e-j-. If β = 0 then
-Z and ψ(z) = 一e-0-.
—
B2)If α = 1, ρ(z) = ι+1e- then, φ(z) = - log(1 + ez) and ψ(z) = - log(1 + e-z).
Subclass C: ω(r) = r+ι As We already mentioned, this is another important transform of the likeli-
hood ratio. Interestingly, in this subclass belongs the first introduced GAN (Goodfellow et al., 2014)
the Cross Entropy GAN.
When ω(r) = r+ι we have ω-1(z) = ɪ-^ and Jω = [0,1]. For ρ(z) > 0,z ∈ [0,1] we must define
the functions φ(z), ψ(z) according to equation 8 φ0(z) = -1-^ρ(z), ψ0(z) = P(Z) The next set
of examples can be seen to satisfy these equations.
C1) If we select P(Z) = 1, this yields φ(z) = log(1 - Z) and ψ(z) = log z.
C2) Selecting P(Z) = (1 - z)α, with α = 0, -1, yields φ(z) = - ι+1a (1 - z)α+1 + 1 (1 - z)α and
ψ(z) = -ι+1α(1 - Z)1+α. For α = 0, we have P(Z) = 1 and Φ(z) = Z + log(1 - z), Ψ(z) = z,
while for a = -1 we have ρ(z) = i-z and φ(z) = - log(1 - z) - i-z, ψ(z) = - log(1 - z).
In C1) we recognize the functions used in the original article by Goodfellow et al. (2014). C2)
appears for the first time.
Subclass D: ω(r) = sign(log r) This is a special case of ω(r) with the corresponding function not
being strictly increasing. It turns out that we can still come UP with optimization problems, two
of which are known and used in practice, by considering ω(r) as a limit of a sequence of strictly
increasing functions.
Monotone Loss: As a first approximation we propose Sign(Z) ≈ tanh( Cz) where C > 0 a parameter.
We note that limc→∞ tanh(Cz) = Sign(Z). Using this approximation we can write
sign(log r ) ≈ tanh
rc - 1
rc + 1
ω(r).
(17)
As we mentioned, we have exact equality for c → ∞. Let us perform our analysis by assuming
that c is finite. We note that ω-1(z) = (1—∣) 1 and Jω = [-1,1]. Consequently, if ρ(z) > 0 for
1
z ∈ [-1,1], we must define φ0(z) = - (l⅛) C P(Z), ψ0(z) = ρ(z).
D1) If we let c → ∞ in order to converge to the desired sign function, this yields φ0(z) = -P(z)
and ψ0(z) = P(z). This suggests that φ(z) = - z P(x)dx is decreasing and ψ(z) = z P(x)dx =
-φ(z) is increasing. In fact any strictly increasing function ψ(z) can be adopted provided we select
φ(z) = -ψ(z).
There is a popular combination that falls under Case D1). In particular, the selection ψ(z) = z =
-φ(z) reminds us of Wasserstein GAN Martin Arjovsky & Bottou (2017), with two differences, in
our case z should lie in [-1, 1] and the discriminator is not constrained to be a Lipschitz function.
Hinge Loss: As a second approximation we use the expression sign(z) ≈ Sign(Z)∣z∣c, c > 0,
which is strictly increasing, continuous and converges to Sgn(z) as c → ∞. This suggests that
sign(logr) ≈ sign(log r)| log r|c = ω(r),	(18)
and ω-1(z) = ezC. Since ω(r) can assume any real value we conclude that Jω = R which, clearly,
differs from the previous approximation where we had Jω = [-1, 1]. If P(z) > 0, z ∈ R then,
according to equation 8 we must define φ0(z) = -ezCP(z), ψ0(z) = P(z). We present the following
case that leads to a very well known pair from a completely different application.
D2) If we select ψ0(z) = P(Z) = {e-|z| C +b<-ι} > 0 then φ0(z) = -ez C {e-|z| C +b<-ι}. Ifwe
now let c → ∞, we obtain the limiting form for the derivatives which become ψ0(z) = -1z<1 and
φ0(z) = 1z>-1. By integrating we arrive at φ(z) = - max{1 + z, 0} and ψ(z) = - max{1 - z, 0}.
The cost based on this particular pair is called the hinge loss Tang (2013) and it is very popular in
binary classification where one is interested only in the maximization problem. The corresponding
14
Under review as a conference paper at ICLR 2021
method is known to exhibit an overall performance which in practice is considered among the best
Rosasco et al. (2004); Janocha & Czarnecki (2017). Here, as in Zhao et al. (2016), we propose the
hinge loss as a means to perform adversarial optimization for the design of the generator G(x).
This completes our presentation of examples. However, we must emphasize, that these are only a
few illustrations of possible pairs {φ(z), ψ(z)} one can construct. Indeed combining, as dictated by
equation 8, any strictly increasing function ω(r) with any positive function ρ(z) generates a legit-
imate pair {φ(z), ψ(z)} and a corresponding min-max problem equation 7 that enjoys the desired
solution r(x) = 1.
A.3 Experiments
In our experiments we employed the two neural networks the generator and the discriminator. For
the generator, we used a four-layer neural network where the first layer is linear and the remaining
deconvolutional; with ReLU activation functions between the layers except the final layer where
we used a sigmoid function since the output is an image with pixel values in the range [0, 1]. The
generator input is a standard i.i.d. normal vector with dimension 64 for MNIST and 128 for Stanford
Cars, CelebA and CIFAR-10. The output of the generator is a 784 × 1 vector for the MNIST dataset,
whereas for the other datasets it is a 3072 × 1 vector.
For the discriminator, we used a four-layer neural network with three convolutional layers followed
by a linear layer. We applied Leaky ReLUs between the layers except for the final layer where we
adopted proper functions based on the range Jω . For the training of the two neural networks we
applied the Adam algorithm Kingma & Ba (2014) with β1 = 0.5, β2 = 0.9, learning rate 10-4 and
batch size 50 for MNIST and 128 for Stanford Cars, CelebA and CIFAR-10. For all datasets, the
training lasted 180000 iterations.
A.4 CELEBA
In Figures 2, 3, 4, 5 we can see the estimation of likelihood ratio from the discriminator neural
network and the FID, KID scores of the generated images during training. For every optimization
problem, we tested its performance for different values of the regularization parameter λ of the
maximum gradient penalty. The different values of λ where {0.01, 0.1, 1, 10} as in Zhou et al.
(2019). We must mention that in the cases where some λ value is missing means that the algorithm
diverged during training.
From our simulations, we notice that, especially in the case of the KID score, the likelihood ra-
tio approximation accuracy of the discriminator coincides with the quality of the synthetic images
produced by the generator. For instance, in Figure 2 for A3, λ = 10 at 〜150000 iterations the
likelihood ratio (which should converge to 1) starts to be more variant around the optimal value,
then we notice the KID, FID scores increase indicating that the generated images quality drops. It is
apparent in Figure 11 where we see some blurry, almost faceless, images. Also, for A1b, B1a, B1b,
Exponential, B2 GANs, we notice the same behavior.
Moreover, in all cases, we notice a faster convergence for larger values of λ. Interestingly, there
is a similar behavior, in terms of convergence, between the different λ's. For example, in B2, for
λ = 10, we notice that the variance around one is increasing. Similarly for λ = 1, λ = 0.1 but
more slowly in terms of iterations. Therefore, it seems that the regularization parameter cannot fix
the divergence problems of a GAN, but they can influence the period they will become evident.
As we already discussed, in the case of Hinge and Wasserstein GANs, the likelihood ratio value is
not computable. For this reason in Figure 5 we present the discriminator output for dataset (D(X))
and for synthetic (D(G(Z))) samples. In the Hinge GAN, the discriminator output gradually in-
creases its range of values for λ = 10 around 130000 iteration and for λ = 1 around 200000
iteration. Accordingly, the synthetic images produced by the generator start to look less similar to
the ones from the dataset. Similarly, Wasserstein GANs have the same patterns. But in this case, the
discriminator output tends to have large values. Our simulations argue, that a way to reduce those
large values is to increase the regularization parameter λ, in other words to ”force” the discriminator
being Lipschitz.
15
Under review as a conference paper at ICLR 2021
16
14
12
10
8
6
4
0.5	1	1.5	2
Figure 2: Likelihood ratio (r), KID, FID scores for CelebA dataset. Simulation results correspond
to Subclass A GANs for different values of the maximum gradient penalty hyperparameter λ.
A.5 S tanford Cars
In Figures 6, 7, 8, 9 we can see the estimation of likelihood ratio from the discriminator neural
network and the FID, KID scores of the generated images during training. For every optimization
problem, we tested its performance for different values of the regularization parameter λ of the
maximum gradient penalty. The different values of λ where {0.01, 0.1, 1, 10} as in Zhou et al.
(2019). Cases where some λ value is missing means that the algorithm diverged during training.
16
Under review as a conference paper at ICLR 2021
3
2.5
2
1.5
1
0.5
0
Iterations
9
8.8
Iterations	x104
×105
8.4
8.6
8.2
8
7.8
0	0.5	1	1.5	2	2.5
Iterations	x105
7.6
Figure 3:	Likelihood ratio (r), KID, FID scores for CelebA dataset. Simulation results correspond
to Subclass B GANs for different values of the maximum gradient penalty hyperparameter λ.
A.6 Synthetic Examples
In the Figures 10, 11 and 12 we present some random samples of the trained generators for the
datasets Stanford cars, CelebA, and CIFAR-10 for λ = 10.
17
Under review as a conference paper at ICLR 2021
2	4	6	8	10	12	14	16
Iterations	χ"
0	0.5	1	1.5	2	2.5	2	4	6	8	10	12	14	16
Iterations	xιo5	Iterations	xιo4
Figure 4:	Likelihood ratio (r), KID, FID scores for CelebA dataset. Simulation results correspond
to Subclass C GANs for different values of the maximum gradient penalty hyperparameter λ.
200
0
-200
WaSserStein: X = 0.01
15x10
20
0
-20
123
Iterations	χi05
Wasserstein: X= 0.1
123
123
Iterations	xi05
12
Iterations
123
Iterations	X105
WaSSerStein: X = 10
3
xi05
10
0 -i -2 -
))z(G(D
0.5 1	1.5 2 2.5
Iterations x105
2	4	6	8	10	12	14	16	2	4	6	8	10	12	14	16
Figure 5: Discriminator outputs for real (D(X)) and sythetic (D(G(Z))) samples, KID, FID scores
for CelebA dataset. Simulation results correspond to Hinge and Wasserstein GANs for different
values of the maximum gradient penalty hyperparameter λ.
18
Under review as a conference paper at ICLR 2021
2	4	6	8	10	12	14	16	18
Iterations	x104
2
4
2
4
25
6	8	10	12	14	16
Iterations	x104
2	4	6	8	10	12	14	16	18
Iterations	x104
1.5
1
0.5
0
2	4	6	8	10	12	14	16	18
Iterations	x104
6	8	10	12	14	16
Iterations	x104
24.5
24
23
23.5
22.5
22
2
4
6
8	10	12	14	16
Figure 6:	Likelihood ratio (r), KID, FID scores for Stanford cars dataset. Simulation results corre-
spond to Subclass A GANs for different values of the maximum gradient penalty hyperparameter
λ.
19
Under review as a conference paper at ICLR 2021
2	4	6	8	10	12	14	16	18
Iterations	x104
2	4	6	8	10	12	14	16
Iterations	x104
Figure 7:	Likelihood ratio (r), KID, FID scores for Stanford cars dataset. Simulation results cor-
respond to Subclass B GANs for different values of the maximum gradient penalty hyperparameter
λ.
20
Under review as a conference paper at ICLR 2021
Figure 8:	Likelihood ratio (r), KID, FID scores for Stanford cars dataset. Simulation results cor-
respond to Subclass C GANs for different values of the maximum gradient penalty hyperparameter
λ.
Wasserstein: X = 0.01
—1000
0
-1000
0
5	10	15
Iterations	x104
-1000
0
— Wasserstein: A = 0.01
包 1000
5	10	15
Iterations x104
Wasserstein: A = 0.1
100
-1000
5	10	15
Iterations	x104
Wasserstein: X = 1
x 0 卜 '	'	'
S~-i0∙	」
5	10	15
Iterations x104
Wasserstein:入=10
Wasserstein: A = 0.1
5	10	15
Iterations	×ιo4
Wasserstein: = 1
5	10	15
Iterations	x104
5	10	15
Iterations	χi04
Wasserstein: = 10
5	10	15
Iterations	×ιo4
5	10	15
Iterations κ104
(N0Q
Figure 9:	Discriminator outputs for real (D(X)) and sythetic (D(G(Z))) samples, KID, FID scores
for Stanford cars dataset. Simulation results correspond to Hinge and Wasserstein GANs for differ-
ent values of the maximum gradient penalty hyperparameter λ.
21
Under review as a conference paper at ICLR 2021
A1a	A1b	A2
A3	MSE	B1a
Wasserstein
Figure 10:	Random samples for different GANs objective function (and maximum gradient penalty
regularization parameter λ = 10) on Stanford cars dataset.
22
Under review as a conference paper at ICLR 2021
A1a	A1b	A2
A3	MSE	B1a
B1b	Exponential	B2
Cross Entropy
C2
Hinge
Wasserstein
Figure 11:	Random samples for different GANs objective function (and maximum gradient penalty
regularization parameter λ = 10) on CelebA dataset.
23
Under review as a conference paper at ICLR 2021

B1b	Exponential	B2
Cross Entropy
C2
Hinge
Wasserstein
Figure 12:	Random samples for different GANs objective function (and maximum gradient penalty
regularization parameter λ = 10) on CIFAR-10 dataset.
24