Under review as a conference paper at ICLR 2021
Partial Rejection Control for Robust Varia-
tional Inference in Sequential Latent Vari-
able Models
Anonymous authors
Paper under double-blind review
Ab stract
Effective variational inference crucially depends on a flexible variational family of
distributions. Recent work has explored sequential Monte-Carlo (SMC) methods to
construct variational distributions, which can, in principle, approximate the target
posterior arbitrarily well, which is especially appealing for models with inherent se-
quential structure. However, SMC, which represents the posterior using a weighted
set of particles, often suffers from particle weight degeneracy, leading to a large
variance of the resulting estimators. To address this issue, we present a novel
approach that leverages the idea of partial rejection control (PRC) for developing a
robust variational inference (VI) framework. In addition to developing a superior
VI bound, we propose a novel marginal likelihood estimator constructed via a
dice-enterprise: a generalization of the Bernoulli factory to construct unbiased
estimators for SMC-PRC. The resulting variational lower bound can be optimized
efficiently with respect to the variational parameters and generalizes several exist-
ing approaches in the VI literature into a single framework. We show theoretical
properties of the lower bound and report experiments on various sequential mod-
els, such as the Gaussian state-space model and variational RNN, on which our
approach outperforms existing methods.
1	Introduction
Exact inference in latent variable models is usually intractable. Markov Chain Monte-Carlo
(MCMC) (Andrieu et al., 2003) and variational inference (VI) methods (Blei et al., 2017), are
commonly employed in such models to make inference tractable. While MCMC has been the tradi-
tional method of choice, often with provable guarantees, optimization-based VI methods have also
enjoyed considerable recent interest due to their excellent scalability on large-scale datasets. VI is
based on maximizing a lower bound constructed through a marginal likelihood estimator. For latent
variable models with sequential structure, sequential Monte-Carlo (SMC) (Doucet & Johansen, 2009)
returns a much lower variance estimator of the log marginal likelihood than importance sampling
(Berard et al., 2014; CeroU et al., 2011). In this work, We focus our attention on designing a low
variance, unbiased, and computationally efficient estimator of the marginal likelihood.
The performance of SMC based methods is strongly dependent on the choice of the proposal
distribution. Inadequate proposal distributions propose values in low probability areas under the
target, leading to particle depletion (Doucet & Johansen, 2009). An effective solution is to use
rejection control (Liu et al., 1998; Peters et al., 2012) which is based on an approximate rejection
sampling step within SMC to reject samples with low importance weights.
In this work, we leverage the idea of partial rejection control (PRC) within the framework of SMC
based VI for sequential latent variable models. To this end, we construct a novel lower bound,
VSMC-PRC, and propose an efficient optimization strategy for selecting the variational parameters.
Compared to other recent SMC based VI approaches (Naesseth et al., 2017; Maddison et al., 2017;
Le et al., 2017), our approach consists of an inbuilt accept-reject mechanism within SMC to prevent
particle depletion. The use of accept-reject within SMC makes the particle weight intractable,
therefore, we use a generalization of the Bernoulli factory (Asmussen et al., 1992) to construct
unbiased estimators of the marginal likelihood for SMC-PRC.
1
Under review as a conference paper at ICLR 2021
Although the idea of combining VI with an inbuilt accept-reject mechanism is not new (Salimans
et al., 2015; Ruiz & Titsias, 2019; Grover et al., 2018; Gummadi, 2014), a key distinction of our
approach is to incorporate an accept-reject mechanism along with a resampling framework. In
contrast to standard sampling algorithms that may reject the entire stream of particles, we use a
partial accept-reject on the most recent update, increasing the sampling efficiency. Further, the
variational framework of SMC-PRC is interesting in itself as it combines accept-reject with particle
filter methods. Therefore, our proposed bound VSMC-PRC generalizes several existing approaches
for example: Variational Rejection Sampling (VRS) (Grover et al., 2018), FIVO (Maddison et al.,
2014), IWAE (Burda et al., 2015), and standard variational Bayes (Blei et al., 2017).
Another key distinction is that, while existing approaches using Bernoulli factory are limited to niche
one-dimensional toy examples, our proposed approach is scalable. To the best of our knowledge, there
is no prior work that has used Bernoulli factories for such a general case like variational recurrent
neural networks (VRNN); therefore, we believe this aspect to be a significant contribution as well.
The rest of the paper is organized as follows: In Section 2, we provide a brief review on SMC, partial
rejection control, and dice enterprise. In Section 3, we introduce our VSMC-PRC bound and provide
new theoretical insights into the Monte-Carlo estimator and design efficient ways to optimize it.
Finally, we discuss related work and present experiments on the Gaussian state-space model (SSM)
and VRNN.
2	Background
We denote a sequence of T real-valued observations as x1:T = (x1 , x2, . . . , xT), and assume that
there is an associated sequence of latent variables z1:T = (z1 , z2, . . . , zT). We are interested in
inferring the posterior distribution of the latent variables, i.e., p(z1:T |x1:T). The task is, in general,
intractable. For the rest of the paper we have used some common notations from SMC and VI
literature where zti: ith particle at time t; Ait-1: ancestor variable for the ith particle at time t; θ and
φ: model and variational parameters, respectively.
2.1	Sequential Monte Carlo with Partial Rejection Control
An SMC sampler approximates a sequence of densities {pθ(zi：t|xi：t)}T=i through a set of N
weighted samples generated from a proposal distribution. Let the proposal density be
T
q@(zi：T|xi：T) = ɪɪ qφ(zt|χ1：t, zi：t-i).	(1)
t=1
Consider time t-1 at which we have uniformly weighted samples {N-1, z1i:t-1, Ait-1}iN=1 estimating
Pθ(zi：t-i|xi：t-i). We want to estimatepθ(zi：t|xi：t) such that particles with a low importance weight
are automatically rejected. PRC achieves this by using an approximate rejection sampling step (Liu
et al., 1998; Peters et al., 2012). The overall procedure is as follows:
Ai
1.	Generate Zi 〜qφ(zt|xi：t, z±t-1) where i = 1,2,...,N.
2.	Accept zti with probability
i i∣ At-ι	、_ (IAM(i,t - 1)qφ(Zi|xi：t,zAt-I))	z21
aθ,φ(zt |zi：t-i，x1:t) = I 1 +	；	A	I ,	(2)
∖	Pθ (Xt,zi|xi：t-i,zi：t-1))
where M(i, t - 1) is a hyperparameter controlling the acceptance rate (see Proposition 3
and Section 3.3 for more details). Note that PRC applies accept-reject only on Zti, not on the
entire trajectory.
3.	If Zti is rejected go to step 1.
4.	The new incremental importance weight of the accepted sample is
where cit is
cit
αt(ZI :t) = CtZ (Z1：t-1，xLt),
Pθ (Xt,zilχLt-i,zAt-1ι)
Ai	Ai
qφ(zt |x1：t, z1：t-1)aθ,φ(Zt |z1：t-1, XLt)
(3)
(4)
2
Under review as a conference paper at ICLR 2021
and the intractable normalization constant Z(.) (For simplicity of notation, we have ignored
the dependence of Z(.) on M(i, t - 1))
Ai	Ai	Ai
Z(zi：t-1, x1:t) = a aθ,φ(ZtIzI：t — i ,x1:t)q0(Zt |x1:t,zi：t-I)dzt∙	(5)
5.	Compute Monte-Carlo estimator of unnormalized weight
〜i _ pθ(xt, zt |x1：t—1, zl:t-l) K Pk = 1 αθ,φ(δt |z1：t -1,x1：t)	(G
Wt =	:	Ai	: Ai	，	(6)
qφ(ζt |x1：t, z1：t—1)aθ,φ(zt |z1：t -1, XLt)
ik	Ait 1	i
where δi 〜qφ(zt∣χ±t, z1：t—1) and k = 1,2,...,K. Note that Wi would be essential for
constructing unbiased estimator for pθ(x±T).
6.	Generate ancestor variables Ait through dice-enterprise and set new weights Wti = N —1 for
i = 1, 2, . . . , N:
ii	Cotprtnαt(z α	αt(ZI:t)	αt(ZLt)	αt(ZLt)	∖ /力
At 〜CategOrical I N j	, LN	j j , ,..., LN / j 、I .	⑺
∖∑j=1 at(z1：t) Ej=I at(z1：t)	Ej=I αt(z7t))
2.2 Dice Enterprise
Simulation of ancestor variables in Eq. 7 is non-trivial due to intractable normalization constants
in the incremental importance weight (see Eq. 3). Vanilla Monte-Carlo estimation ofαt (.) yields
biased samples of ancestor variables from Eq. 7. To address this issue, we leverage a generalization
of Bernoulli factory, called dice-enterprise (Morina et al., 2019). Note that multinoulli extensions
of Bernoulli factory (Dughmi et al., 2017) have also been used for resampling within intractable
SMC before (Schmon et al., 2019), a key distinction of our approach is to design a scalable Bernoulli
factory methodology especially useful for VI applications.
Suppose we can simulate Bernoulli(pit) outcomes where pit is intractable. Bernoulli factory problem
simulates an event with probability f(pit), where f (.) is some desired function. In our case, the
intractable coin probability pti is the intractable normalization constant,
pit
Z(Z1A:tit-—11,x1:t)
Jt aθ，φ(ζt|Z1：t-1, x1:t)q0(zt|x1:t, z1-t-1)dzt.
(8)
Since pit ∈ [0, 1] and we can easily simulate this coin, we obtain the dice-enterprise algorithm below.
C，PN~C ,..., PN~C
1 ct	j=1 ct	j=1 ct
c2
cN
1.	Required: Constants {cti}iN=1 see Eq. 4.
2.	Sample C 〜Categorical
Ai
3. If C = i, generate Ui 〜U[0,1] and Zt 〜qφ(zt∣xrt, z^t—1)
Ai
•	If Ui <aθ,φ(Zt|Z1:t—1，X1：t) output i
•	Else go to step 2
The dice-enterprise produces unbiased ancestor variables. Note that we can easily control the
efficiency of the proposed dice-enterprise through the hyper-parameter M (similar to Eq. 2) in
contrast to existing Bernoulli factory algorithms (Schmon et al., 2019). For details on efficiency and
correctness, please refer to Section 3.1 and Section 3.3.
Our proposed VSMC-PRC bound is constructed through a marginal likelihood estimator obtained
by combining the SMC sampler with a PRC step and dice-enterprise. The variance of estimators
obtained through SMC-PRC particle filter is usually low (Peters et al., 2012). Therefore, we expect
VSMC-PRC to be a tighter bound compared to the standard SMC based bounds used in recent
works (Maddison et al., 2017; Naesseth et al., 2017; Le et al., 2017). Algorithm 1 summarizes the
generative process to simulate the VSMC-PRC bound. Please see Figure 1 to visualize the generative
process for VSMC-PRC.
3
Under review as a conference paper at ICLR 2021
Algorithm 1 Estimating the VSMC-PRC lower bound
1	: Required: N, K, and M	17:	end while	z1A:tit--11)
2	: for t ∈ {1, 2, . . . , T } do	18:	Sample {δi,k}K=1 〜qφ(zt∣xι:',	
3 4	: for i ∈ {1, 2, . . . , N} do zi,c,wi 7 PRC (q,P,M(i,t- 1)) :	z1i:t = (z1:tt--11, zti)	19: 20:	Calculate weti from Eq. 6 Calculate cit from Eq. 4	
5		21:	return (zi,ct,Wi)	
6	: end for	22:		
7	: for i ∈ {1, 2, . . . , N} do	23:	DICE-ENT ({ci,z1 J乜 J	N cjt t i=1
8 9	At = DICE-ENT ({ct,zi"N=J : end for	24:	Sample C 〜Multinoulli ( PNct	
10	: end for	25:	if C == i then	j=1	
11	return log QT=I (含 pN=ι Wi)	26:	Sample Ui 7 U[0, 1]	
12		27:	i	Ait-1 zt 〜qφ(zt|xi:t,zi:t-i)	
13	: PRC (q,p,M(i,t - 1))	28:	end if	
14	: while sample not accepted do	29:	A if Ui < aθ,φ(zi∣zLt-ι,xLt) then	
15	Ai Generate Z 〜q0(zt|xi:t, zi:t-l)	30:	return (i)	
16	:	Accept zti with probability	31: 32:	else return DICE-ENT ({ci,z1: J	N i=1
	i Ait-1 aθ,φ (zt |z1:t-1, x1:t)	33:	end if	
3 Partial Rejection Control based VI for Sequential Latent
Variable Models
We now show how to leverage PRC to develop a robust VI framework for sequential latent variable
models. Our framework is based on the VSMC-PRC bound presented below. The complete sampling
distribution of Algorithm 1 is as follows.
KN	TNK
Y Y qφ(δi,k∣x1) YYY qφ(δi,k |xi：t,zAt-1)	×
k=1 i=1	t=2 i=1 k=1
qφ(zi ∣xι)aθ,φ(zi ∣xι)
Z (xι)
Y YDiscrete(At∣αt)q^zt+Jx1:'+1,%?%，。(Zt+l|z1：t用:'+1))
t=1 i=1	Z (z1A:tt, x1:t+1)
(9)
The normalization constants Z(.) in Eq. 9 are intractable and have to be estimated while calculating
the weights. Therefore, we introduce an extra parameter K , denoting the number of Monte-Carlo
samples used to estimate Z(.). The Monte-Carlo estimator of VSMC-PRC bound is
T	1N i
LVSMC-PRC (θ,φ; x1:T ,K) = ɪ^log (nΣ^w'J .	(IO)
We maximize the VSMC-PRC bound with respect to model parameters θ and variational parameters
φ. This requires estimating the gradient the details of which are provided in Section 3.2.
3.1	Theoretical Properties
We now present properties of the Monte-Carlo estimator LVSMC-PRC. The key variables that affect
this bound are N (number of samples), hyper-parameter M, and the number of Monte-Carlo samples
used to compute the normalization constant Z(.), i.e., K. As discussed by Berard et al. (2014);
Naesseth et al. (2017), as N increases, we expect the VSMC-PRC bound to get tighter. Hence, we
will focus our attention on M and K . All the proofs can be found in the appendix.
Proposition 1. Dice-enterprise produces unbiased ancestor variables. Further, let Λtbe the number
of iterations required for generating one ancestor variable, then Λt 〜Geom (E[Λt]-1) where
E[Λt]
P=Ic
PlLIcZ (zAt-i,xi:t)
4
Under review as a conference paper at ICLR 2021
Figure 1: Comparison of VSMC-PRC with IWAE (Burda et al., 2015) and FIVO (Maddison et al., 2017) (a)
The blue arrows represent the resampling step, We then generate multiple samples from parametrized proposal
zti |z1i :t-1 out of which one sample is accepted via PRC, depicted via green arrows. (b) In IWAE, there is no
resampling step and no PRC step (c). In FIVO, there is a resampling step (blue arrows) but no PRC step.
As evident from Proposition 1, the computational efficiency of the dice-enterprise clearly relies on the
normalization constant Z(.). Note that the value of Z(.) could be interpreted as the average acceptance
rate of PRC which depends on the hyper-parameter M(i, t - 1). If the average acceptance rate for
PRC for all particles is γ, then we can express the expected number of iterations as E[Λit] = γ-1.
Therefore, the computational efficiency of dice-enterprise is similar to the PRC step and depends
crucially on the hyper-parameter M.
Proposition 2. For all K, exp(JLvsMC-PRC) is unbiased, i.e., E ∖χp(fLJV/s∕MMtPRicc)] = Pθ(xi：T). FUr-
ther, E[LvSMc-Pcc] is non-decreasing in K.
The use of Monte-Carlo estimator in place of the true value of Z(.) creates an inefficiency, as depicted
by Proposition 2. The bound monotonically increases as we increase K despite the use of resampling
operation. It is important to note that Algorithm 1 produces an unbiased estimator of the marginal
likelihood for all values of K .
Proposition 3. Let the sampling distribution of the ith particle (generated via Pcc) at time t be
Ait 1
rθ,φ(zt∣zid-i,x±t),then
Ai	Ai	Ai	Ai
KL rθ,φ(zt Iz1：t-1,x1:t) k Pθ(ZtIzI：t-1,x1:t) ≤ KL q^(zt|z1：t-1,x1:t) k Pθ (ZtIzI：t-i,x1：t)
Proposition 3 implies that the use of the accept-reject mechanism within SMC refines the sampling
distribution. Instead of accepting all samples, the PRC step ensures that only high-quality samples
are accepted, leading to a tighter bound for VSMC in general (not always). We show in the appendix
that when M (i, t - 1) → ∞, the PRC step reduces to pure rejection sampling (Robert & Casella,
2013). On the other hand, M(i, t - 1) → 0 implies that all samples are accepted from the proposal.
Recall, M(i, t - 1) is a hyperparameter that can be tuned to control the acceptance rate. For more
details on tuning M, see Section 3.3.
3.2	Gradient Estimation
For tuning the variational parameters, we use stochastic optimization. Algorithm 1 produces the
marginal likelihood estimator by sequentially sampling the particles, ancestor variables, and particles
for the normalization constant (z1：N,Al∖T-ι,δ1T,'1''κ).
When the variational distribution qφ(.) is reparameterizable, we can make the sampling of δti,k
independent of the model and variational parameters. However, the generated particles zti are not
reparametrizable due to the PRC step. Finally, the ancestor variables are discrete and, therefore,
cannot be reparameterized. The complete gradient can be divided into three core components
(assuming qφ(.) is reparametrizable):
Vθ,φE[LiVSMC-PRC]	=	Eqvsmc-PRC	[▽ θ,φLVSMC-PRC (θ,Φ; X1：T, K)]	+ gPRC	+ gRSAMP (11)
≈	eQvsmc-Prc	νθ,φ>LVSMC-PRC (θ, φ; x1：T ,K)	∙	(12)
5
Under review as a conference paper at ICLR 2021
Note that gPRC and gRSAMP denote the score gradient of PRC and resampling step, respectively. Due
to high variance, we have ignored these terms for the optimization. We have derived the full gradient
and explored the gradient variance issues in the appendix. Please see Figure 2 (left) comparing the
convergence of biased gradient vs. unbiased gradients on a toy Gaussian SSM.
3.3	LEARNING THE M MATRIX
We use M as a hyperparameter for the PRC step which controls the acceptance rate of the sampler.
The basic scheme of tuning M is as follows:
•	Define a new random variable F (zt+ι∣zAAt ,xi：t+i) = log ( q*(Zt+l|xi:t+1,z1：A i ).
pθ (xt+1 ,zt+1 |x1:t,z1:tt )
•	Draw zj+ι 〜qφ(zt+ι∣xι,t+ι,zAt) for j = 1, 2,...,J.
•	Evaluate γ ∈ [0, 1] quantile value of {F (ztj+1 |ztAt, x1:t+1)}jJ=1. In general for this case the
acceptance rate would be around γ for all particles.
log MO-QF jZAt -I)(Y).	(13)
•	If M matrix is very large then use a common {M (., t)}tT=1 for every time-step. In general,
for this configuration, the acceptance rate would be greater than equal to γ for all particles:
logM(.,『min 卜QFMzAt…)(Y)}：	(14)
Through γ : a user parameter, we can directly control the acceptance rate. Therefore, both dice-
enterprise and PRC would take around (less than) γ-1 iterations to produce a sample for M value
learned from Eq. 13 (see Eq. 14). For implementation details please refer to the experiments.
Note that a similar scheme was also employed in Grover et al. (2018). We update {{M (i, t -
1)}iN=1 }tT=1 dynamically once every F epochs to save time. To learn more on setting hyper-parameter
M, see Liu et al. (1998); Peters et al. (2012).
4	Related Work and S pecial Cases
There is significant recent interest in developing more expressive variational posteriors for latent
variable models. There are two basic schemes for constructing tighter bounds on the log marginal
likelihood: sampling-based methods (MCMC, rejection sampling) (Salimans et al., 2015; Ruiz &
Titsias, 2019; Hoffman, 2017; Grover et al., 2018) or multiple samples from VI distributions to
increase the flexibility (IS, SMC) (Burda et al., 2015; Maddison et al., 2017; Lawson et al., 2018;
Naesseth et al., 2015). In this work, we present a unified framework for combining these two
approaches, utilizing the best of both worlds. Although applying sampling-based methods on VI
is useful, the density ratio between the true posterior and the improved density is often intractable.
Therefore, we cannot take advantage of variance-reducing schemes like resampling, which is crucial
for sequential models. We solve this issue through dice-enterprise: an extension of the Bernoulli
factory.
Recently, Bernoulli factory has amassed a great interest in the area of Bayesian inference (GOngaIVes
et al., 2017a;b; Vats et al., 2020). Although Bernoulli factory is theoretically valuable, its applicability
is severely limited due to a high rejection rate. In this paper, we have presented an approach
that combines SMC with dice-enterprise for efficient implementation. A closely related work
from SMC literature is Schmon et al. (2019), which also utilizies Bernoulli factories to implement
unbiased resampling. However, their method is not scalable and designed particularly for partially
observed diffusions. Another relevant work for unbiased estimation of the marginal likelihood is
that of Kudlicka et al. (2020). In contrast to our approach, this method samples one additional
particle and keeps track of the number of steps required by PRC for every time-step to obtain their
unbiased estimator. The weights are tractable for Kudlicka et al. (2020) as they do not take into
account the effect of the normalization constant Z(.). On the other hand, we consider the effect of
Z(.) on the particle’s weight, making resampling operation infeasible. To fix this intractability, we
6
Under review as a conference paper at ICLR 2021
Figure 2: (Left) The figures compares the bound value for VSMC-PRC with full gradient and biased gradi-
ent (equation 12) as a function of iterations. (Left) The Table compares the bound value for VSMC (Naesseth
et al., 2017) and VSMC-PRC for 80% and 40% acceptance rate. (Right) We compare VSMC, VSMC-PRC
(40% acceptance rate), and logpθ (xi：T) as a function of iterations.
use dice-enterprise. Comparisons of our marginal likelihood estimator versus that of Kudlicka et al.
(2020) would make for interesting future work.
To provide more clarity, we will consider some special cases of VSMC-PRC bound and relate it with
existing work: Note that for N = 1 our method reduces to a special case of Gummadi (2014) which
uses a constraint function Ct for every time-step and restarts the particle trajectory from ∆t (if Ct is
violated). Therefore, if we use the setting Ct(z1:t) = a(zt|z1:t-1, x1:t) and ∆t = t - 1, our method
reduces to a specific case of Gummadi (2014). For the special case of N = 1 and T = 1, our method
reduces to VRS (Grover et al., 2018). For N, T > 1, if we remove the PRC step, our bound reduces
to FIVO (Maddison et al., 2017). Finally, if we remove both the PRC step and resampling, then our
method effectively reduces to IWAE (Burda et al., 2015). Please refer to Figure 1 for more details.
5	Experiments
In this section, we evaluate our proposed algorithm on synthetic as well as real-world datasets and
compare them with relevant baselines. For the synthetic data experiment, we implement our method
on a Gaussian SSM and compare our approach with VSMC (Naesseth et al., 2017). For the real data
experiment, we train a VRNN (Chung et al., 2015) on the polyphonic music dataset.
5.1	Gaussian State Space Model
In this experiment, we study the linear Gaussian state space model. Consider the model
zt = Azt-1 + ez ,
xt = Czt + ex ,
where ez, ex 〜N(0, I) and z0 = 0. We are interested in learning a good proposal for the above
model. The latent variable is denoted by zt and the observed data by xt . Let the dimension of zt be
dz and dimension of Xt be dx. The matrix A has the elements (A)i,j∙ = αli-jl+1, for α = 0.42. We
explore different settings of dz , dx , and matrix C. A sparse version of C matrix measures the first dx
components of Zt, on the other hand a dense version of C is normally distributed i.e Ci,j∙〜N(0,1).
We consider four different configurations for the experiment. For more details please refer to Figure 2.
The variational distribution is a multivariate Gaussian with unknown mean vector μ = {μd }d=1 and
diagonal covariance matrix {logσd2}ddz=1. We set N = 4 and T = 10 for all the cases:
q(zt∣zt-ι)〜N (Zt∣Azt-ι + μ, diag(σ2)).
7
Under review as a conference paper at ICLR 2021
The {{M (i, t - 1)}iN=1}tT=1 matrix (see Eq. 13) for approximate rejection sampling is updated once
every 10 epochs with acceptance rate γ ∈ {0.8, 0.4}. For estimating the intractable normalization
constants, we generate K = 3 samples. Figure 2: (left) compares the convergence of biased gradient
vs unbiased gradients. Note that we get a much tighter bound as compared to VSMC (Naesseth et al.,
2017).
5.2	Variational RNN
VRNN (Chung et al., 2015) comprises of three core components: the observation xt, stochastic latent
state zt, and a deterministic hidden state ht(zt-1, xt-1, ht-1), which is modeled through a RNN.
For the experiments, we use a single-layer LSTM for modeling the hidden state. The conditional
distributions pt(zt|.) and qt(zt|.) are assumed to be factorized Gaussians, parametrized by a single
layer neural net. The output distribution gt(xt|.) depends on the dataset. For a fair comparison,
we use the same model setting as employed in FIVO (Maddison et al., 2017). We evaluate our
model on four polyphonic music datasets: Nottingham, JSB chorales, Musedata, and
Piano-midi.de.
Each observation xt is represented as a binary vector of 88 dimensions. Therefore, we model the
observation distribution gt(xt|.) by a set of 88 factorized Bernoulli variables. We split all four data-
sets into the standard train, validation, and test sets. For tuning the learning rate, we use the validation
test set. For a fair comparison, we use the same learning rate and iterations for all the models. Let the
dimension of hidden state (learned by single layer LSTM) be dh and dimension of latent variable be
dz . We choose the setting dz = dh = 64 for all the data-sets except JSB. For modeling JSB, we use
dz = dh = 32. For VSMC-PRC we have considered N ∈ {4, 6} Further, for each N, we consider
four settings (K, γ) ∈ {(1, 0.9), (1, 0.8), (3, 0.9), (3, 0.8)}. The M hyper-parameter for PRC step is
learned from Eq. 14 due to large size. We have updated M value once every 50 epoches. Note that in
this scenario, the acceptance rate for all particles would be greater than equal to γ. For more details
on experiments, please refer to the appendix.
As discussed in Section 3.1, the PRC step and dice-enterprise have time complexity O(N∕γ) for
producing N samples (assuming average acceptance rate γ). Therefore, we consider dNγ-1e
particles for IWAE and FIVO to ensure effectively the same number of particles, where N ∈ {4, 6}
and γ = 0.8. Note, however, that the acceptance rate is ≥ γ, so this adjustment actually favors the
other approaches more. For FIVO, we perform resampling when ESS falls below N/2. Table 1
summarizes the results which show whether rejecting samples provide us with any benefit or not, and
as the results show, our approach, even with the aforementioned adjustment, outperforms the other
approaches in terms of test log-likelihoods, while still having a similar computational cost.
Table 1: We report Test log-likelihood for models trained with FIVO, IWAE, ELBO, and VSMC-PRC. For
VSMC-PRC N = (4, 6) and (K, γ) ∈ {(1, 0.9), (1, 0.8), (3, 0.9), (3, 0.8)} (results are in this order). The
results for pianoroll data-sets are in nats per timestep.
N	Data	ELBO	IWAE	FIVO	N	VSMC-PRC
	Nott	-3.87	-3.12	-3.07	-296^^	-2.98	-2.99	-2.96
	jsb	-8.69	-8.01	-7.51	-7.41	-7.28	-7.37	-7.36
5	Piano	-7.99	-7.97	-7.85	4	-7.82	-7.86	-7.80	-7.85
	Muse	-7.48	-7.45	-6.75	-6.61	-6.63	-6.66	-6.58
N	Data	ELBO	IWAE	FIVO		VSMC-PRC
	Nott	-3.87	-3.87	-2.99	-293~~	-2.93	-2.90	-2.91
	jsb	-8.69	-8.32	-7.40	-7.29	-7.21	-7.16	-7.14
8	Piano	-7.99	-8.04	-7.80	6	-7.78	-7.77	-7.79	-7.77
	Muse	-7.48	-7.41	-6.67	-6.60	-6.57	-6.61	-6.60
Avg.	Rank	6.87 ± 0.33	6.12 ± 0.33	4.87 ± 0.33	2.87 ± 1.05	2.62 ± 1.21	2.87 ± 1.26	1.75 ± 0.66
In Sec. 3.1, we discussed the effect of K and PRC rejection rate on VSMC-PRC bound. We expect
a performance improvement when K and the rejection rate is increased. Although the results for
VSMC-PRC’s different configurations are almost the same, we still get the best average ranking for
(K = 3, γ = 0.8). Overall, for most cases, VSMC-PRC bound performs better than FIVO (Maddison
et al., 2017) and IWAE (Burda et al., 2015) for a variety of configurations.
In VSMC-PRC, improvement in the bound value comes at the cost of estimating the normalization
constant Z(.), i.e., K. On further inspection, we can clearly see that increasing K doesn’t provide us
8
Under review as a conference paper at ICLR 2021
with any substantial benefits despite the increase in computational cost. Therefore, to maintain the
computational trade-off (K = 1, γ > 0.8) seems to be a reasonable choice for VI practitioners.
Table 1 signifies that rejecting samples with low importance weight is better instead of keeping a
large number of particles (at least for a reasonably high acceptance rate γ). The proposed bound uses
more particles (PRC step and dice-enterprise) than existing approaches like FIVO and IWAE due to
intractability. Future work aims at designing a scalable implementation for VSMC-PRC bound that
consumes fewer particles.
6	Conclusion
We introduced VSMC-PRC, a novel bound that combines SMC and partial rejection sampling with
VI in a synergistic manner. This results in a robust VI procedure for sequential latent variable
models. Instead of using standard sampling algorithms, we have employed a partial sampling
scheme suitable for high dimensional sequences. Our experimental results clearly demonstrate that
VSMC-PRC outperforms existing bounds like IWAE (Burda et al., 2015) and standard particle filter
bounds (Maddison et al., 2017; Naesseth et al., 2017; Le et al., 2017). The future work aims to
explore partial versions of powerful sampling algorithms like Hamiltonian Monte Carlo (Neal et al.,
2011) instead of rejection sampling.
References
Christophe Andrieu, Nando De Freitas, Arnaud Doucet, and Michael I Jordan. An introduction to
MCMC for machine learning. Machine learning, 50(1-2):5-43, 2003.
S0ren Asmussen, Peter W Glynn, and Hermann Thorisson. Stationarity detection in the initial
transient problem. ACM Transactions on Modeling and Computer Simulation (TOMACS), 2(2):
130-157, 1992.
Jean Berard, Pierre Del Moral, Arnaud Doucet, et al. A lognormal central limit theorem for particle
approximations of normalizing constants. Electronic Journal of Probability, 19, 2014.
David M Blei, Alp Kucukelbir, and Jon D McAuliffe. Variational inference: A review for statisticians.
Journal of the American Statistical Association, 112(518):859-877, 2017.
Yuri Burda, Roger Grosse, and Ruslan Salakhutdinov. Importance weighted autoencoders. arXiv
preprint arXiv:1509.00519, 2015.
Frederic Cerou, Pierre Del Moral, and Arnaud Guyader. A nonasymptotic theorem for unnormalized
Feynman-Kac particle models. In Annales de l'IHP Probabilites et Statistiques, volume 47, pp.
629-649, 2011.
Junyoung Chung, Kyle Kastner, Laurent Dinh, Kratarth Goel, Aaron C Courville, and Yoshua Bengio.
A recurrent latent variable model for sequential data. In Advances in neural information processing
systems, pp. 2980-2988, 2015.
Arnaud Doucet and Adam M Johansen. A tutorial on particle filtering and smoothing: Fifteen years
later. Handbook of nonlinear filtering, 12(656-704):3, 2009.
Shaddin Dughmi, Jason D Hartline, Robert Kleinberg, and Rad Niazadeh. Bernoulli factories and
black-box reductions in mechanism design. In Proceedings of the 49th Annual ACM SIGACT
Symposium on Theory of Computing, pp. 158-169, 2017.
Flavio B Gongalves, Krzysztof Latuszyilski, Gareth O Roberts, et al. Barker,s algorithm for Bayesian
inference with intractable likelihoods. Brazilian Journal of Probability and Statistics, 31(4):
732-745, 2017a.
Flavio B Gongalves, Krzysztof G Latuszyinski, and Gareth O Roberts. Exact Monte Carlo likelihood-
based inference for jump-diffusion processes. arXiv preprint arXiv:1707.00332, 2017b.
Aditya Grover, Ramki Gummadi, Miguel Lazaro-Gredilla, Dale Schuurmans, and Stefano Ermon.
Variational rejection sampling. arXiv preprint arXiv:1804.01712, 2018.
9
Under review as a conference paper at ICLR 2021
Ramki Gummadi. Resampled belief networks for variational inference. In NIPS Workshop on
Advances in Variational Inference, 2014.
Matthew D Hoffman. Learning deep latent Gaussian models with Markov chain Monte Carlo. In
Proceedings ofthe 34th International Conference on Machine Learning-Volume 70, pp.1510-1519.
JMLR. org, 2017.
Jan Kudlicka, LaWrence M Murray, Thomas B Schon, and Fredrik Lindsten. Particle filter with
rejection control and unbiased estimator of the marginal likelihood. In ICASSP 2020-2020 IEEE
International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 5860-5864.
IEEE, 2020.
Dieterich Lawson, George Tucker, Christian A Naesseth, Chris J Maddison, Ryan P Adams, and
Yee Whye Teh. Twisted variational sequential Monte Carlo. In Third workshop on Bayesian Deep
Learning (NeurIPS), 2018.
Tuan Anh Le, Maximilian Igl, Tom Rainforth, Tom Jin, and Frank Wood. Auto-encoding sequential
Monte Carlo. arXiv preprint arXiv:1705.10306, 2017.
Jun S Liu, Rong Chen, and Wing Hung Wong. Rejection control and sequential importance sampling.
Journal of the American Statistical Association, 93(443):1022-1031, 1998.
Chris J Maddison, Daniel Tarlow, and Tom Minka. A* sampling. In Advances in Neural Information
Processing Systems, pp. 3086-3094, 2014.
Chris J Maddison, John Lawson, George Tucker, Nicolas Heess, Mohammad Norouzi, Andriy Mnih,
Arnaud Doucet, and Yee Teh. Filtering variational objectives. In Advances in Neural Information
Processing Systems, pp. 6573-6583, 2017.
Giulio Morina, Krzysztof Latuszynski, Piotr Nayar, and Alex Wendland. From the Bernoulli factory
to a dice enterprise via perfect sampling of Markov chains. arXiv preprint arXiv:1912.09229,
2019.
Christian A Naesseth, Fredrik Lindsten, and Thomas B Schon. Nested sequential Monte Carlo
methods. arXiv preprint arXiv:1502.02536, 2015.
Christian A Naesseth, Scott W Linderman, Rajesh Ranganath, and David M Blei. Variational
sequential Monte Carlo. arXiv preprint arXiv:1705.11140, 2017.
Christian A Naesseth, Fredrik Lindsten, and Thomas B Schon. Elements of sequential Monte Carlo.
arXiv preprint arXiv:1903.04797, 2019.
Radford M Neal et al. MCMC using Hamiltonian dynamics. Handbook of markov chain monte carlo,
2(11):2, 2011.
Gareth W Peters, Yanan Fan, and Scott A Sisson. On sequential Monte Carlo, partial rejection control
and approximate Bayesian computation. Statistics and Computing, 22(6):1209-1222, 2012.
Christian Robert and George Casella. Monte Carlo statistical methods. Springer Science & Business
Media, 2013.
Francisco JR Ruiz and Michalis K Titsias. A contrastive divergence for combining variational
inference and MCMC. arXiv preprint arXiv:1905.04062, 2019.
Tim Salimans, Diederik Kingma, and Max Welling. Markov chain Monte Carlo and variational
inference: Bridging the gap. In International Conference on Machine Learning, pp. 1218-1226,
2015.
Sebastian M Schmon, Arnaud Doucet, and George Deligiannidis. Bernoulli race particle filters. arXiv
preprint arXiv:1903.00939, 2019.
Dootika Vats, Flgvio Gongalves, Krzysztof Latuszyiiski, and Gareth O Roberts. Efficient Bernoulli
factory MCMC for intractable posteriors. arXiv preprint arXiv:2004.07471, 2020.
10
Under review as a conference paper at ICLR 2021
A Proof of Theoretical Results
Proof of proposition 1 : Dice-enterprise produces unbiased ancestor variables. Let’s evaluate the
probability that Dice-enterprise would output i as the ancestor index. Assume that the algorithm
terminates after r steps where r ∈ {1, 2, . . . , ∞}, then the probability of output i is given as follows:
Pr(output = i)
∞
Pr(output = i|after r steps)
r=1
cti Z (z1:tt--11 , x1:t)
∞N
X(X
r=1 j=1
j	r-1
ctj(1 - Z(z1A:tt--11,x1:t)
CiZ(Z1：t-1, x1：t)
Pj=I j(zji，xi：t)
It is easy to see that Λtis geometrically distributed with success probability given by
Pr(getting output in a loop)
PLc Z (ZAt-1ι,xrt)
PN m
m=1 ct
C 「	「	C C 「	1	.	.	，	.11	. .	.	1	G 一 ， C 、	..
Proof of proposition 2 : Before explaining the proof, we will first introduce Z: Monte-Carlo estimator
of the unknown normalization constant Z(.). Since we are using K samples
Ai	1 K	Ai
Z(xi：t,zi：t-1i； K) = K X aθ,φ(δi,k|xi：t,zi：t-1).
k=1
(15)
Algorithm 1 is producing an unbiased estimator of the marginal likelihood. We will first integrate out
δ1.:N,1:K from the marginal likelihood estimator.
EQVSMC-PRC exp(LVSMC-PRC )
T N	Ai	Ai
/ -Y 1	pθ(xt,zt|x1：t-1,zi：t-I)Z(x1:t, zl：t-1； K)
乙 UN乙 ”	Ai—1、 U At―1、
A1：N-1	t=1	i=1	qφ(ztlx1-t,z1:t--1 )aθ,φ(Zt |x1:t, Z1:t--1)
1:N 1:N 1:N,1:K 1:N 1:N,1:K
QVSMC-PRC (z1:T , A1：T-1,δ1:T	) dz1:T dδ1:T
T1 N
x /YNx
A11::TN-1	t=1	i=1
Pθ (xt, zt∣xiJ,zAt-1ι) R Z(xi:t, ZAt-1; K)QK=I qφ(δitik |xi：t, ZAt-1ι)dδt,k
Q	(JN 41:N 、4 JN
QVSMC-PRC Z1:T , A1:T -1 dZ1:T
T1N
x /Y N x
A1:N t=1 t=1
T1N
x JYNx
A1:N	t=1	t=1
Ai	Ai
pθ (xt , Zt |x1:t-1 , Z1:t-1 )Z (x1:t, Z1:t-1 )
QVSMC-PRC(Z1：：N,A1：N-1)dz1：N
pθ (xt，zt|xi:t-1，zl:t - 1) n	( 1: N zt 1:N 、川 JN
---------；------Ai-------QVSMC-PRC (zlT ,A1:T-1)dz1:T
rθ,φ(Zt|x1:t,zi:tt--11 )
N	T-1 N
Yre0(Z1|xi) Y YDisCrete(At|at)re0(Zt+i|xi:t+i,ZAt) dZ1T
t=1	t=1 t=1
T1N
X /Y N X Wt
A1:N t=1 t=1
(16)
11
Under review as a conference paper at ICLR 2021
Note that rθ,φ(z1.) is the sampling density of PRC. It is easy to see that Eq. 16 is a standard SMC
estimator for the marginal likelihood pθ (x1:T). The proof is quite standard in SMC literature and can
be found in (Naesseth et al., 2017; 2019). The key factor that makes our bound unbiased is the ability
to produce unbiased ancestor samples despite the presence of intractable normalization constant.
Using Jensen inequality we can easily show that VSMC-PRC bound is smaller then log marginal
likelihood.
QVSMC-PRC
E
T
X log
t=1
i=1
(17)
i	Ait-1	Ait-1
Pθ(xt, zl\xi：t-i,zi：t-i)Z(xi：t,zi：t—i； K)
qφ(z∖∖χι
≤ log pθ (x1:T ) .
(1:N AlN	δ1NLK∖ dr 1：NdK1：N,1：KdA±N
z1:T ,	1:T-1, 1:T	z1:T	1:T	1:T-1
ɪʃT	∙11 1	.ι . ττn Γ Λ	TR ♦	ι	♦	∙ .ι τ>r T . ⅛ ι r∙	n	CF .
We will show that E[LVSMC-PRC; K] is non-decreasing with K. Let’s define a collection of subsets
{{Ii,t}iN=1}tT=1 ⊂ {1, 2, . . . , K} having elements {i1, i2, . . . , im} randomly drawn from the set
{1, 2, . . . , K} having length m ≤ K. We can easily show the following expectation:
Ait-1
Z (x1:t, z1:t-1; K) = EIi,={i1,i2,...,im}
Ait-1
Z(x1:t, z1:tt--11; m)
Ki
K X aθ,φ(δi,k\xi：t, Zit-11
k=1
(18)
)
Substitute the values of above expectation in equation 17. Use Jensen’s inequality i.e E[log X] ≤
log E[X] to complete the proof .
E 伍VSMC-PRC; K
≥E
T	1N
∑log E{{ii,t}N=1}T=1 ( Nf
t=1
i=1
Pθ(Xt, zi∖xLt-1,zAt-I)Z(XLt,zAt-1; m)
T 1N
E{{ii,t}N=1}T=1 ∑log I Nf
Ai	Ai
qφ(zt\x1：t, zLt-l)aθ,φ(Zt\x1：t, zl:t-l)
Pθ(xt, zi∖χLt-1, zAt-1I)Z(XI:t, zAt-1; m)
t=1
≥ E [Lvsmc-prc； ^
i=1
E
Now we will see what happens when the limit K → ∞. Using dominated convergence theorem we
can write down the estimator as follows:
nr r r	1
limK→+∞ E[LVSMC-PRC]
lim E
K→+∞
T	1N
X log (NF X
t=1
i=1
Ai	Ai
pθ(Xt, Zti\X1:t-1,Z1:tt--11)Z(X1:t,Z1:tt--11; K)
T	1N
X log IN X
pθ(Xt, Zti\X1:t-1, Z1A:tt--11) limK→+∞ Zb(X1:t, Z1A:tt--11; K)
t=1
i=1
T 1N
X log (N X
i	Ait-1	Ait-1
pθ(Xt, Zti\X1:t-1,Z1:tt--11)Z(X1:t, Z1:tt--11)
≤ log pθ (X1:T )
t=1
i=1
E
E
T
N
12
Under review as a conference paper at ICLR 2021
Proof of proposition 3 : We will show that PRC step refines the learned distribution.
KL r(zt|z1A:tti--11, x1:t)||p(zt|z1A:tit--11, x1:t)
log
Ait-1
r(zt|z1:tt--11, x1:t)
p(zt|z1A:tit--11,x1:t)
Ait-1
r(zt|z1:tt--11,x1:t)dzt
log
Ai	Ai
q(zt |z1:t-1, x1:t)a(zt |
z1:tt--11 , x1:t)
log
Ai	Ai
p(zt|z1:tt--11,x1:t)Z(x1:t,z1:tt--11)
Ai	Ai
q(zt|z1:t-1, x1:t)a(zt |z1:t-1, x1:t)
Ait-1
r(zt|z1:tt--11, x1:t)dzt
Ai	Ai
p(zt |z1:t-1 , x1:t)Z (x1:t, z1:t-1)
Ait-1
q(zt|z1:tt--11,x1:t)dzt
≤
≤
KL	q(zt|z1A:tit--11, x1:t)||p(zt|z1A:tit--11, x1:t) +
(( IAi-1	∖
a(zt|z1:tt--11,x1:t)
Z (xι,,zA^t-1)
Ait-1
q(zt|z1:tt--11,x1:t)dzt
≤
KL	q(zt|z1:tt--11 , x1:t)||p(zt|z1:tt--11 , x1:t)
First, we will use the property of negatively correlated random variables. Note that the following two
random variables
X = log
Ai
p(zt |z1:t-1 ,x1:t )
and Y = a(zt |z1:t-1 , x1:t),
are negatively correlated. We know that for negatively correlated variables following identity holds
E[XY] ≤ E[X]E[Y]. Further we have used Jensen’s inequality to show that
Ai	Ai
E[loga(zt|z1:tt--11,x1:t)] ≤ logZ(x1:t,z1:tt--11)
Ai	Ai
Case 1:	M(i, t - 1) → 0 implies r(zt|z1:tt--11, x1:t) → q(zt|z1:tt--11, x1:t)
In this situation all samples would be accepted. Hence, we can express the sampling distribution as:
r(zt|z1:tt--11 , x1:t) = q(zt |x1:t, z1:tt--11),
(19)
Ai	Ai
Case 2:	M(i,t - 1) → ∞ implies r(zt|z1:tt--11, x1:t) → p(zt|z1:tt--11,x1:t)
In this case, the acceptance probability would reduce to standard rejection sampling. Therefore, the
sampling distribution would become equal to the true posterior.
r(zt|z1A:tit--11,x1:t)
ii	A
q(z"xrt,zAt-1)	P(Zt，Xt|Xl：iZ1"
M(i,t-1)q(zti |x1:
i
t-1 )
:t-1)
Ait-1
:t ,z1:t--1
Ai
R q(zi|xi：t,zAt-1) p(zi,xtlxi"τ,zL⅞11 dzi
M(i,t-1)q(zti|x1:t,z1:tt--11 )
p(zti |x1:t, z1:tt--11)
)
B	Gradient Estimation
In this section, we will derive the unbiased gradients for the Monte-Carlo estimate E[LVSMC-PRC]. Note
that we can express the complete gradient into three core components (assuming q() is reparametriz-
13
Under review as a conference paper at ICLR 2021
Figure 3: Convergence rate for biased gradient vs. unbiased gradient on toy Gaussian SSM. We compared grep
(blue), grep + gPRC (orange), and unbiased gradient (green) for optimization.
able):
T7 一 TI7「6	1
▽ θ,φ E [LVSMC-PRC ]
grep
gPRC
gRSAMP
grep + gPRC + gRSAMP
EQVSMC-PRC Wθ,ΦLVSMC-PRC (θ, φ; x1:T,
EQVSMC-PRC
NT
ΣΣ log
i=1 t=1
a(zti|x1:t,z1A:tit--11)
Z(XI:t, zl:t-l)
N T-l
eQvsmc-Prc LVSMC-PRC(/ φ, x1:T ,K )Vθ,φ E E At ɪθg at
Note that for both gPRC and gRSAMP unbiased score gradient estimates are not available due to
intractability. Therefore, we have used Monte-Carlo samples to estimate the log density for figure 3.
C Experimental Setup
For the real data experiment, we train a VRNN (Chung et al., 2015) on the polyphonic music
dataset. Polyphonic music comprises of four datasets: : Nottingham, JSB chorales, Musedata, and
Piano-midi.de. Each dataset was divided into standard train, validation, and test datset.
The validation data was used to tune the learning rate: we picked the learning rate from the following
set: {3 × 10-4, 1 × 10-4, 3 × 10-5, 1 × 10-5}, instead of optimizing for each method, we picked
the learning rate at which FIVO (Maddison et al., 2017) validation performance is the best. Once the
learning rate is decided, we ran every method for the same number of iterations to ensure uniformity.
We use a single-layer LSTM for modeling the hidden state having dimension dh . For a length T
sequence, the variational distribution and joint data likelihood are defined as follows
r(zl:T|xl:T) =
ΠT=1 qt(Zt∣ht(zt-1,Xt-1,ht-1),Xt)at(zt∣ht(zt-1,Xt-1, ht-ι),Xt)
QtT=lZt(ht(zt-l,xt-l,ht-l),xt)
Note that at(zt|.) is the acceptance probability for the PRC step and Zt(.) is the intractable normal-
ization constant. Similarly, we can write down the joint data likelihood as
T
p(zl:T, xl:T) =	pt(zt|ht(zt-l,xt-l, ht-l),xt)gt(xt|ht(zt-l,xt-l, ht-l),zt)
t=l
The conditional distributions pt(zt|.) and qt(zt|.) are assumed to be factorized Gaussians, where
dimension of the latent variable zt is dz . Note that the conditional densities are parametrized by
fully connected neural networks with a single layer having size dh. The output distribution gt(xt|.)
is modeled by a set of 88 iid Bernoulli variables. Please see Table 2 for more details regarding
implementation details. The unknown weights and biases are initialized using a Xavier initialization.
For setting up the optimization we used a batch size of 4 with adam optimizer. The unknown
hyperparameter M is updated once every 50 epoches through Eq. 14 to save time.
14
Under review as a conference paper at ICLR 2021
Table 2: Training parameters used for VSMC-PRC, FIVO, and IWAE.
Parameters	Datasets			
	Piano-mid	Muse	jsb	Nott
	 Optimizer	Adam	Adam	Adam	Adam
Learning Rate	0.00003	0.0001	0.00003	0.0001
Batch-size	4	4	4	4
dh	64	64	32	64
dz	64	64	32	64
num-iteration	50,000	1,00,000	1,00,000	1,00,000
15