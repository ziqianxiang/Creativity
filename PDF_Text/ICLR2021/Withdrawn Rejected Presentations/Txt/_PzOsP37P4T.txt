Under review as a conference paper at ICLR 2021
Generalized Gumbel-Softmax Gradient Esti-
mator for Generic Discrete Random Variables
Anonymous authors
Paper under double-blind review
Ab stract
Estimating the gradients of stochastic nodes, which enables the gradient descent op-
timization on neural network parameters, is one of the crucial research questions in
the deep generative modeling community. When it comes to discrete distributions,
Gumbel-Softmax trick reparameterizes Bernoulli and categorical random variables
by continuous relaxation. However, gradient estimators of discrete distributions
other than the Bernoulli and the categorical have not been explored, and the the
Gumbel-Softmax trick is not directly applicable to other discrete distributions. This
paper proposes a general version of the Gumbel-Softmax estimator with a theoret-
ical basis, and the proposed estimator is able to reparameterize generic discrete
distributions, broader than the Bernoulli and the categorical. In detail, we utilize the
truncation of discrete random variables and the Gumbel-Softmax trick with a linear
transformation for the relaxed reparameterization. The proposed approach enables
the relaxed discrete random variable to be reparameterized through a large-scale
stochastic computational graph. Our experiments consist of (1) synthetic data
analyses and applications on VAE, which show the efficacy of our methods; and (2)
topic models, which demonstrate the value of the proposed estimation in practice.
1 Introduction
Stochastic computational graphs, including deep generative models such as variational autoencoders,
are widely used for representation learning. Optimizing the network parameters through gradient
methods requires an estimation of the gradient values, but the stochasticity requires the computation
of expectation, which differentiates this problem from the deterministic gradient of ordinary neural
networks. There are two common ways of obtaining the gradients: score function-based methods and
reparameterization methods. The score function-based estimators tend to result in unbiased gradients
with high variances, while the reparameterization estimators seem to result in biased gradients with
low variances (Xu et al., 2019). Hence, the core technique of the score-function based estimators
becomes reducing the variances of gradients to achieve stable and fast optimizations. Meanwhile,
utilizing the reparameterization estimators requires the differentiable non-centered parameterization
(Kingma & Welling, 2014a) of random variables.
If we focus on the reparameterization estimators, one of the most popular examples is the reparame-
terization in the Gaussian variational autoencoder (VAE) (Kingma & Welling, 2014b), which has an
exact reparameterization form. Other VAEs with explicit priors suggest the reparameterization tricks
with approximations (Nalisnick & Smyth, 2017; Joo et al., 2020). For continuous random variables,
it is feasible to estimate gradients with automatic differentiation by utilizing a transport equation
(Jankowiak & Obermeyer, 2018) or an implicit reparameterization (Figurnov et al., 2018). However,
these methods are not applicable to discrete random variables, due to the non-differentiability.
Recently, some discrete random variables, such as Bernoulli or categorical random variables, have
been well-explored in terms of the reparameterization method by overcoming such difficulty through a
continuous relaxation (Jang et al., 2017; Maddison et al., 2017). However, other discrete distributions
have not been explored from the learning perspective in the deep generative modeling community,
for example, Poisson, binomial, multinomial, geometric, negative binomial distributions, etc. Prior
works on graphical models, such as Ranganath et al. (2015; 2016), utilized Poisson latent variables
for the latent counting. Another line of work (Wu et al., 2020) utilized the Gaussian approximation
on the Poisson latent variable to count the number of words, which can be a poor approximation
1
Under review as a conference paper at ICLR 2021
Forward PaSS
G)E)O—0
(a) Reparameterization trick.
Truncation Level Gumbel RandomSamples Temperature OutcomeVector
(b) Visualization of GenGS.
Figure 1: Reparameterization in stochastic computational graphs.
ReParameteriZed Sample
if the rate parameter is small. In this sense, study on the stochastic gradient estimator for discrete
distributions is required in the deep generative modeling community, which broadens the choice of
prior assumptions and the utilization of various distributions.
This paper proposes a generalized version of the Gumbel-Softmax reparameterization trick, which can
be utilized to generic discrete random variables through continuous relaxation, namely Generalized
Gumbel-Softmax (GENGS). The key ideas of GENGS are (1) a conversion of the sampling process
to one-hot categorical selection process; (2) a reversion of the selected category in the one-hot
form to the original sample value; and (3) a relaxation of the categorical selection process into the
continuous form. To implement these steps, GENGS first truncates discrete random variables to
approximate the distribution with the finite number of possible outcomes. Afterward, GenGS utilizes
the Gumbel-Softmax trick together with a special form of a linear transformation. Our main theorem
supports that the proposed GENGS is applicable to general discrete random variables, other than the
Bernoulli and the categorical. The GENGS experiments show the efficacy with synthetic examples
and VAEs, as well as the usability in topic model application.
2	Preliminary: Reparameterization Trick & Gumbel-Softmax
2.1	Backpropagation through Stochastic Nodes with Reparameterization Trick
Suppose We have a stochastic node, or a latent variable, Z 〜p(z∣θ), where the distribution depends on
parameter θ. The goal is optimizing the loss function L(θ, η) = Ez〜,Μ忸)[f (z)], where f is a con-
tinuous and differentiable function with respect to η, i.e., neural networks. To optimize the loss func-
tion in terms of θ through the gradient methods, we need to find VθL(θ, η) = VθEz〜p(z∣θ) [%(z)],
which can not be directly computed with its original form.
To compute VθL(θ, η), the reparameterization trick alternatively introduces an auxiliary variable
e 〜p(e), which takes over all randomness of the latent variable z, so the sampled value Z can be
re-written as z = g(θ, ), with a deterministic and differentiable function g in terms of θ. Figure 1(a)
illustrates the reparameterization trick: the shaded nodes indicate random nodes, and the dotted lines
denote sampling processes. Here, the gradient of the loss function with respect to θ is derived as
vθL = vθEz〜p(z∣θ)fη (Z)] = Ee〜p(e)[vθfη (g(θ, e))] = Ee〜p(e)[Vgfη (g(θ, e)) vθg(θ, e)] (I)
where the last term of Equation 1 is now achievable. A condition on enabling the reparameterization
trick is the assumption of the continuity of the random variable Z, so the distribution of Z is limited to
a class of continuous distributions. To utilize the differentiable reparameterization trick on discrete
random variables, continuous relaxation can be applied: for example, a relaxation from the categorical
distribution to the Gumbel-Softmax distribution, described in the next subsection.
2.2	Reparameterization Trick on Categorical Random Variable
A Gumbel-Max trick (Gumbel, 1948) is a procedure for sampling a one-hot categorical value from
the Gumbel distribution, instead of direct sampling from a categorical distribution. This implies
that the categorical random variable X 〜Categorical(∏), where ∏ lies on the (n 一 1)-dimensional
simplex ∆n-1, can be reparameterized by the Gumbel-Max trick: (1) sample Uj 〜Uniform(0,1)
2
Under review as a conference paper at ICLR 2021
to generate a gumbel sample gj = 一 log(- log Uj) for each j = 1,…，n; and (2) compute k =
argmaxjn=1 [log πj + gj], where π is a categorical parameter. This procedure generates a one-hot
sample x such that xj = 0 for j 6= k and xk = 1 with P (Xk = 1) = πk. We denote GM(π) to be
the distribution whose samples are generated by the Gumbel-Max trick.
A Gumbel-Softmax trick (Jang et al., 2017; Maddison et al., 2017) is an alternative to the Gumbel-
Max trick that continuously relaxes a categorical random variable. The Gumbel-Softmax utilizes
the softmax with a temperature τ > 0, instead of the argmax in the sampling process, which
enables (1) relaxing the discreteness of the categorical random variable to the one-hot-like form
x(τ) = Softmax(log∏+g) in the continuous domain; and (2) approximating the Gumbel-Max by
taking τ small enough. Lately, the Gumbel-Softmax estimator has been widely used to reparameterize
categorical random variables, such as RelaxedOneHotCategorical in TensorFlow (Abadi
et al., 2016). We denote GS(π, τ) to be the distribution generated by the Gumbel-Softmax trick.
3	Process of GenGS Reparameterization
This section discusses the process of GenGS to help understand the concept with minimal theoretical
details, and Section 4 provides the theoretical background of GenGS. The three steps of GenGS are
the following: (1) approximate a discrete distribution by truncating the distribution; (2) reparameterize
the truncated distribution with the Gumbel-Max trick and the linear transformation T, which will be
introduced below; and (3) relax the discreteness by replacing the Gumbel-Max trick in Step 2 with
the Gumbel-Softmax trick. Figure 1(b) illustrates the full steps of the GenGS trick.
Step 1. Truncate the discrete distribution to finitize the number of possible outcomes. Suppose
X 〜PoiSSon(100), which has a mode near at X = 100, and near-zero probabilities at x < 50
and x > 150. The key idea of the first step is ignoring the outcomes of near-zero probabilities at
certain levels (ex. x < 50 and x > 150) and only focusing on the probable samples of meaningful
probabilities (ex. 50 ≤ x ≤ 150), i.e., truncating the distribution, which finitizes the support of
the distribution. Now, suppose We have a discrete random variable X 〜D(λ), and its truncated
random variable Z 〜 TD(λ, R), where R denotes the truncation range that needs to be pre-defined.
Proposition 3 in Section 4 provides theoretical reason that Z approximates X . Since we finitized
the support by the truncation, we may assume Z has a support C = {c0,…，Cn-ι} of n possible
outcomes and its corresponding constant outcome vector C = (co,…，cn-ι). Note that the ordering
of ck is not significant, and Appendix E provides examples of the setting on c.
Step 2. Divide sampling process of Z into two-fold: select a one-hot category of Z, and revert the
selected one-hot category into the original value. For example, if the sampled value of Z is c2 ∈ C,
we will first focus on the one-hot category class vector one_hot(c2)= (0,0,1,0,…，0), rather
than the sampled value c2 . Such a one-hot categorical selection process is possible by utilizing
the categorical selection W 〜Categorical(∏) or its reparameterized version, the Gumbel-Max trick
GM(∏). Here, the categorical parameter ∏ = (∏o, •…,∏n-ι) can be directly calculated by the
explicit probability mass funciton (PMF) of the distribution, i.e., πk = P (Z = ck). However, the
PMF of the truncated distribution requires a modification from the PMF of the original distribution,
which is determined by how we define Z from X. See Definition 1, 2, and Appendix A for detailed
configuration of π. Suppose we now have a one-hot categorical sample w from the categorical
parameter ∏. Afterward, we revert the one-hot selected categorical vector W = (wo,…，Wn-ι) into
the original sample value with a linear transformation T(w) = Pk wkck = Pk w c. Proposition
4 shows the validity of the alternative sampling process in Section 4.
Step 3. Relax the one-hot categorical selection into the continuous form by utilizing the Gumbel-
Softmax trick. Up to now, the sole shortage of the reparameterization trick is the differentiability due
to the one-hot categorical selecting Gumbel-Max process. Then, as in Section 2.2, the process can be
continuously relaxed with the Gumbel-Softmax trick GS(π, τ) for some temperature τ. Theorem 5
in Section 4 shows that the alternative sampling process still holds under the continuous relaxation.
4	Theoretical Background of GenGS
To support our reparameterization methodology, this section provides the main theorem on the repa-
rameterizations. The first proposition approximates an original discrete distribution with its truncated
3
Under review as a conference paper at ICLR 2021
(a) Effects of truncation level and temperature
GenGS(π, T)	∖
∖	-	∖
号∖.
I	m x
i	I
]	, * 一►
Truncation Level n
T(GM⑺)=TD(Λ,n) --------------------- D(A)
(b) Concept of GenGS approximation
Figure 2: (a) Approximation of GEN GS in terms of choices of the truncation level n and the
temperature τ in Poisson(7). As sub-figures go from left to right, the truncation level grows. Hence,
the popped-out sticks, implying remaining probability of the right side, disappears if the truncation
level is large enough. As sub-figures go from top to bottom, the temperature decreases, and the
PMF of truncated distributions and the original distributions becomes similar. Appendix D provides
the fine-grained PMF of GENGS. (b) On the x-axis, TD(λ, n) → D(λ) as truncation level n ↑ ∞,
according to Proposition 3. Then, TD(λ, n) can be reparameterized by the Gumbel-Max trick with a
linear transformation T as in Proposition 4. On the y-axis, as temperature T 1 0, GenGS (π, T) →
TD(λ, n), where π is a computed PMF value of TD(λ, n), according to Theorem 5.
version. Next, the second proposition enables the truncated distribution to be reparameterized by the
Gumbel-Max trick. Finally, the main theorem shows that the Gumbel-Softmax trick converges to the
Gumbel-Max trick under an assumption of the linear transformation. Through these steps, we note
that our proposed reparameterization trick is generalized and grounded, theoretically.
4.1	Finitizing the Support by Truncating Discrete Random Variables
Definition 1 specifies a truncated discrete random variable for truncating the right-hand side. Note
that Definition 1 can be easily extended to truncate the left-hand side or both sides of distributions.
Definition 2 is truncating both side version, and Appendix A discusses its variation. However, we
focus on the non-negative distribution in the remainder of this subsection, since most of the popularly
used discrete random variables have the support of N≥0.
Definition 1. (A special case of right-hand-side truncation for non-negative discrete random variables)
A truncated discrete random variable Zn of a non-negative discrete random variable X 〜D(λ) is a
discrete random variable such that Zn = X if X ≤ n - 1, and Zn = n - 1 if X > n. The random
variable Zn is said to follow a truncated discrete distribution TD(λ, R) with a parameter λ and a
truncation range R = [0, n). Alternatively, we write as truncation level R = n if the left truncation is
at zero in the non-negative case.
Definition 2. (Both-side truncation for general discrete distributions) A truncated discrete random
variable Zm n of a discrete random variable X 〜D(λ) is a discrete random variable such that ⑴
Zm,n = Xifm < X < n; (2) Zm,n = n - 1 ifX ≥ n; and (3) Zm,n = m+ 1 ifX ≤ n. The
random variable Zm,n is said to follow a truncated discrete distribution TD(λ, R = (m, n)) with a
parameter λ and a truncation range R = (m, n).
As we discussed in Section 3, truncating the distribution intends to finitize the number of possible
outcomes to utilize the categorical selection. From the definition, the samples of finitized support can
be simply considered ck = k in this special non-negative case. Furthermore, due to the definition,
the modification on the PMF only exists in the last category cn-1 = n - 1, and the modified PMF
can be computed by injecting the near-zero remaining probability summation to the last category,
right before the truncation level. In other words, πk = P (Zn = ck) = P (Zn = k) = P (X = k)
for k = 0,…,n - 2 and πn-1 = 1 - Pn-02 ∏k, hence, the sum-to-one property remains satisfied.
Here, the idea which leads to Proposition 3 is that if we take the truncation level far enough from
zero, we can cover most of the possible outcomes that can be sampled from the original distribution.
Note that the truncation step can be omitted if the original distribution already has a finite support,
but one can utilize the truncation to ignore the unlikely samples.
Proposition 3. With Definition 1, Zn converges to X almost surely as n → ∞. Also, with Definition
2, Zm,n converges to X almost surely as m → -∞ and n → ∞.
4
Under review as a conference paper at ICLR 2021
The almost sure convergence property of Proposition 3 supports the theoretical basis of approximating
a discrete random variable D(λ) with the truncated random variable TD(λ, n), and Appendix A
shows the detailed proof. Through the truncation, the discrete distribution is approximated with
finitized support, and the Gumbel tricks are ready to be utilized.
4.2	Reparameterization by Generalized Gumbel-Softmax Trick
Next, we select one-hot categorical sample from the finitized categories and revert the one-hot
selection to the original sample value. The widely utilized discrete distributions have the explicit
forms of PMF, so we can directly compute the PMF values for the truncated support with a pre-defined
truncation range. Once the distribution and the truncation range are fixed as D(λ) and R, respectively,
We have the corresponding constant outcome vector C = (co,…，cn-ι) and the computed PMF
value vector ∏ = (∏o, .…,∏n-ι) of a truncated distribution TD(λ, R), where ∏k = TD(Ck； λ, R).
AfterWard, We define a transformation T(w) = Pk wkck = Pk w c. Additionally, We denote
the distributions, generated by applying T on the samples of GM and GS, as T (GM) and T (GS),
respectively. Then, we can generate a sampled value of TD(λ, R) with a linear transformation and a
Gumbel-Max sample, as stated in Proposition 4, proved in Appendix B.
Proposition 4. For any truncated discrete random variable Z 〜TD(λ, R) ofdiscrete distribution
D(λ) and a transformation T, Z can be reparameterized by T (GM(π)) if we set πk = P(Z = Ck).
Due to the reparameterization, the randomness of TD(λ, R) with respect to the parameter λ moves into
the uniform random variable in the Gumbel-Max, since T is a continuous and deterministic function.
Then, TD(λ, R) can be approximated by replacing the Gumbel-Max with the Gumbel-Softmax in T,
as stated in Theorem 5, proved in Appendix C. We define T (GS(π, τ)) as GENGS(π, τ).
Theorem 5. For a transformation T and a given categorical parameter π ∈ ∆n-1, the convergence
property of Gumbel-Softmax to Gumbel-Max still holds under the linear transformation T, i.e.,
GS(π, τ) → GM(π) as τ → 0 implies GENGS(π, τ) → T (GM(π)) as τ → 0.
Theorem 5 implies that we can relax and approximate the truncated discrete random variable
TD(λ, R) by the Gumbel-Softmax and the linear transformation. The assumption of the theo-
rem that GS(π, τ) → GM(π) as τ → 0 has not been mathematically proven in the original literature
(Jang et al., 2017; Maddison et al., 2017). Instead, the authors have empirically shown that GS(π, τ)
eventually becomes GM(π ) as τ → 0. Figure 2 shows how GENGS gets closer to the original
distribution by adjusting the truncation range and the temperature.
Truncation Range. We can observe that the approximation becomes closer to the original distribution
as we widen the truncation range R. However, the increment of R is technically limited due to the
finite neural network output for the inference. Note that the choice of truncation range is crucial in
terms of covering many probable samples. Therefore, we set the truncation range to cover all but less
than 1e-5% of probability with respect to the prior distribution, or arbitrary large.
Temperature. The decrement of T from Softmax(log∏+g) results in the closer distribution to the
original distribution. However, the initially small τ leads to high bias and variance of gradients, which
becomes problematic at the learning stage on π. Therefore, the annealing of τ from a large value to a
small value is necessary to provide a learning chance of π .
Note that there is no condition on the distribution to be reparameterized with GenGS in the theoretical
analysis. Hence, once a discrete distribution has an explicit PMF, GenGS can be easily utilized to
the reparameterization. Appendix E suggests examples of GenGS utilization, including one that
shows the regular Gumbel-Softmax is a special case of GenGS. Appendix F provides the algorithm
of GenGS, and Appendix G gives discrete distributions in TensorFlow, which can utilize GenGS.
5	EXTENTION OF GENGS: IMPLICIT INFERENCE & DISCRETIZATION
Implicit Inference. Unlike continuous random variables, discrete random variables have countable
outcomes. Instead of inferring the distribution parameter λ and then computing the PMF values
through the fixed PMF and λ, we can directly infer the PMF values π of possible outcomes with
softmax, which becomes the input of the Gumbel tricks, by loosening the assumption on the
approximate posterior PMF shape. This implicit inference on the PMF values becomes possible due
to truncating distribution by finitizing the possible outcomes. However, this inference approach needs
5
Under review as a conference paper at ICLR 2021
a regularizer, such as the KL divergence term in the objective function of VAEs, which ensures the
distribution shape to be similar to a prior distribution with a pre-defined parameter. We found that
loosening the approximate posterior assumption leads to a significant performance gain in our VAE
experiments. See Appendix F for the algorithm of the implicit inference.
Discretization of Continuously Relaxed Sample. GENGS outputs a continuously reparameterized
sample value since we are relaxing the discrete random variable into a continuous form. Utilizing the
Straight-Through (ST) Gumbel-Softmax estimator (Bengio et al., 2013; Jang et al., 2017), instead of
the naive Gumbel-Softmax, we can obtain the discrete sample as well. Since ST Gumbel-Softmax
discretizes the relaxed Gumbel-Softmax output with argmax, ST Gumbel-Softmax uses the gradients
obtained from the relaxed ones, which could result in significant performance degradation.
6	Related Work
GenGS is basically a single-sample gradient estimator like other reparameterization gradient estima-
tors. Though GenGS could use multiple samples to obtain the stable gradients, we compare GenGS
with the other estimators using a single sample to test the fundamental performance of gradient
estimators. RF denotes the basic REINFORCE (Williams, 1992). NVIL (Mnih & Gregor, 2014)
utilizes a neural network to introduce the optimal control variate. MuProp (Gu et al., 2016) utilizes
the first-order Taylor expansion on the loss term as a control variate. VIMCO(k) (Mnih & Rezende,
2016) is designed as k-sample gradient estimator. REBAR (Tucker et al., 2017) and RELAX (Grath-
wohl et al., 2017) utilize reparameterization trick for constructing the control variate. Deterministic
RaoBlack (DETRB) (Liu et al., 2019) uses the weighted value of the fixed gradients from m-selected
categories and the estimated gradients from the remaining categories with respect to their odds to
reduce the variance. The idea of Stochastic RaoBlack (StoRB) (Kool et al., 2020) is essentially same
as that of DetRB, but StoRB randomly chooses the categories at each step, instead of using fixed
categories. Kool et al. (2020) also suggested an unordered set gradient estimator (UnOrd), which
also uses the multiple sampled gradients, utilizing the sampling without replacements. For DetRB,
STORB, and UNORD, we use m = 1 category that utilizes the fixed gradient for the fair comparison.
Note that if there are K > 1 dimensions to be inferred, the models require computing mK gradient
combinations, which has higher complexity than GenGS. The * symbol denotes a variation that
utilizes a built-in control variate introduced in the work of Kool et al. (2020).
7	Experiment
7.1	Synthetic Example
Experimental Setting. In this experiment, we expand the toy experiments from Tucker et al. (2017);
Grathwohl et al. (2017) to various discrete distributions. We first fix constant tι, ∙∙∙ ,tk, and then
optimize the loss function Ez〜p(z∣λ) [Pk=ι(zi - ti)2] with respect to λ. Here, We set p(z∣λ)
as Poisson(20), Binomial(20, .3), Multinomial(3, [.7, .2, .1]), and NegativeBinomial(3, .4) in this
experiment. We also adapt the Rao-Blackwellization (RB) idea in GENGS by utilizing m = 1
in calculating the selected gradient, so this adaptation results in GenGS-RB that estimates the
remaining gradients by GenGS. See Appendix J for the detailed experimental settings.
Experimental Result. Figure 3 compares the log-loss and the log-variance of estimated gradients
from various estimators. In the figure, the log-loss needs to be minimized to correctly estimate the
backpropagated gradient value in the learning process. Additionally, the log-variance requires being
minimized to maintain the consistency of the gradients, so the gradient descent can be efficient.
GenGS shows the best log-loss and the best log-variance if GenGS keeps the continuous relaxation
of the modeled discrete random variable. For the Poisson case, the exact gradient has a closed-form
solution, as in Appendix J, and GenGS shows the lowest bias among all gradient estimators. See
Appendix J for the curves with confidence intervals and the curves without smoothing.
7.2	VAE: Synthetic Experiment on Deep Generative Models
Experimental Setting. We follow the VAE experiments of Figurnov et al. (2018) with discrete priors,
which diversifies the choice of prior assumption, as the latent factor count in the discrete case. This
6
Under review as a conference paper at ICLR 2021
Poisson (20)
3.0
8use> 号
Poisson (20)
4.00
Poisson (20)
S3 6oη
M3Bg
M3Bg
1,u*1u*0987
MUece> §
Figure 3: Synthetic example performance curves in log scale: (Top Row) losses, variances, and biases
of gradients for Poisson; (Middle Row) losses for Binomial, Multinomial, and NegativeBinomial;
(Bottom Row) variances of gradients for Binomial, Multinomial, and NegativeBinomial. We utilize
the cumulative average for smoothing the curves, and the curves with confidence intervals and the
curves without smoothing are in Appendix J.
Table 1: Test negative ELBO on MNIST and OMNIGLOT datasets. The lower is better for the
negative ELBO. We provide a full table including baselines with insignificant results and variations
of GenGS in Appendix K. Symbol “—” indicates no convergence.
RF	—=	DetRB	---- StoRB	---- GenGS ST High Temp	---- GenGS ST Low Temp	---- GenGS HighTemp	--- GenGS Low Temp
RF*	—"	DetRB*	— StoRB*	—■ GenGS-RB ST HighTemp	—■ GenGS-RB ST Low Temp	— ■ GenGS-RB HighTemp	—■ GenGS-RB Low Temp
0	500 ItKO 1500	20∞	25∞	3000
Epoch

MNIST	RF*	NVIL	MuProp	VIMCO(5)	REBAR	RELAX	STORB*	GENGS (Ex.)	GENGS (Im.)
Pois(2)	122.81±2.41	129.34±4.72	125.43±2.27	122.55±3.28	123.44±2.54	122.71±1.92	124.02±4.91	103.18±0.92	96.04±1.44
Pois(3)	123.12±2.21	130.24±3.32	125.92±1.81	121.15±2.57	120.62±2.31	119.84±2.18	124.41±5.96	105.15±1.71	96.01±1.27
Geom(.25)	127.90±1.97	135.90±2.38	137.90±2.14	127.21±2.55	135.12±2.74	136.80±3.06	131.09±4.95	98.43±0.81	92.52±1.62
Geom(.5)	129.20±2.03	138.47±2.30	136.40±1.78	129.91±2.90	138.37±2.98	139.41±3.59	139.67±2.42	100.92±1.24	93.81±1.60
NegBin(3,.5)	116.67±5.97	119.28±7.80	131.96±6.49	112.69±4.30	—	—	114.36±4.12	98.58±1.27	94.52±1.52
NegBin(5,.3)	130.03±3.99	133.44±4.27	144.05±8.15	124.48±2.72	—	—	128.02±2.60	100.88±2.35	95.37±1.43
OMNIGLOT	RF*	NVIL	MuProp	VIMCO(5)	-REBAR-	RELAX	STORB*	GENGS (Ex.)	GENGS (Im.)
Pois(2)	139.47±3.29	148.01±4.19	142.95±1.32	138.73±3.42	138∙12±3.26	137.56±2.94	139.61±5.87	127.89±1.44	118.17±2.22
Pois(3)	140.54±2.36	148.13±3.98	143.85±1.54	139.37±3.10	137.92±3.07	137.42±2.96	140.05±3.68	131.53±1.76	119.15±1.92
Geom(.25)	142.68±2.96	153.69±2.52	152.17±1.77	142.94±3.96	146.78±3.62	148.91±4.03	143.10±3.91	115.23±2.00	107.79±2.84
Geom(.5)	142.70±1.77	153.20±1.49	149.76±2.19	142.05±3.56	149.63±3.49	151.97±3.90	142.56±2.97	115.14±2.43	108.48±2.78
NegBin(3,.5)	141.44±2.20	144.44±2.78	147.78±4.49	141.89±3.84	—	—	129.48±4.34	118.57±2.71	117.02±2.18
NegBin(5,.3)	144.44±3.68	159.40±5.13	152.81±3.34	150.49±4.09	—	—	151.30±3.98	119.57±2.02	117.54±2.76
experiment utilizes the Poisson, the geometric, and the negative binomial distributions. The evidence
lower bound (ELBO) L(X) = Eq@(z|x)[logpθ(x|z)] - KL(qφ(z∣x)∣∣pθ(z)), which consists of the
reconstruction part and the KL divergence part, is minimized during the training period. Optimizing
the ELBO of VAEs requires computing the KL divergence between the approximate posterior and the
prior distributions. In GenGS, by truncating the original distribution, the KL divergence becomes
the derivation with categorical distributions. See Appendix H for the detailed statement and proof.
Note that the purpose of VAE experiments is not to compare the performance across various prior
distributions. The VAE is considered as a more challenging task than the synthetic example in the last
subsection, since (1) this task requires computing the gradients of the encoder network parameters
through the latent distribution parameter λ; and (2) each stochastic gradient of the latent dimension
affects every encoder parameter since we are utilizing the fully-connected layers. Hence, a single
poorly estimated gradient with respect to the latent distribution parameter λ could negatively affect
the learning of encoder parameters. See Appendix K for the detailed experimental settings.
7
Under review as a conference paper at ICLR 2021
Q 口 口 Q
α QPP
m⅛M⅛
幺回限血
r昌四r
foDlo2
3 R S 3
W 0 Wg
FFFF
仄 κ□rκ
鸿JBJ≡⅛
JLex.d
曲日心通
a½g &
26 %%
A 一二
CslQn
CCclC
3斤亨>
SGSS
7 7??
4 4 4 4
SSS5
Qqqa
3ΛΔ3
22Λ7
H I- It H
Oooo
Figure 4: Reconstructed images by VAEs with various gradient estimators. GenGS shows the
clearest images among other gradient estimators with better reconstruction.
Experimental Result. Table 1 shows the negative ELBO results of the VAE experiments. We
found that some baselines failed to reach the optimal point, so we excluded those estimators in
such suboptimal cases. The variants of GenGS showed the lowest negative ELBO in general, and
loosening the PMF condition idea (i.e., the implicit inference) reached the better optimal points.
Figure 4 shows the reconstructed images by VAEs with various gradient estimators on MNIST and
OMNIGLOT. GenGS draws the clearest images and better reconstructions, which aligns with the
quantitative result in Table 1. See Appendix K for the full table and additional discussion.
7.3 Topic Model Application
Experimental Setting. This experiment shows
another application of GenGS in the topic mod-
eling. The Poisson distribution is one of the
most important distribution for counting the
number of outcomes among all discrete distri-
butions. The authors of Deep Exponential Fami-
lies (DEFs) (Ranganath et al., 2015) utilized the
exponential family, including the Poisson distri-
bution, on the stacked latent layers. Therefore,
we focus on the Poisson DEF, which assumes
Figure 5: (Left) A graphical notation of NVPDEF
with generative process (θ) and inference network
(φ). The multi-stacked latent layers have λi as
a prior distribution parameter. (Right) A neural
network diagram of NVPDEF: diamond nodes in-
dicate the auxiliary random variable for the repa-
rameterization trick.
the Poisson latent layers to capture the counting
numbers of latent super-topics and sub-topics; and we convert the Poisson DEF into a neural varia-
tional form, which resembles NVDM (Miao et al., 2016). Figure 5 shows the neural network and its
corresponding probabilistic modeling structure. We utilize GenGS on the Poisson DEF to sample the
values in the latent variable, namely the neural variational Poisson DEF (NVPDEF). See Appendix
L for further description of DEFs, NVPDEF, and detailed experimental settings.
Experimental Result. We enumerate the
baselines and the variants of NVPDEFs in
Table 2, and we confirmed that NVPDEF
shows the lowest perplexity overall with
20Newsgroups and RCV1-V2. Since
NVPDEF and the original DEFs have dif-
ferent training and testing regimes, we com-
pare NVPDEF to representative neural
variational topic (document) models, which
Table 2: Test perplexity on 20News and RCV dataset.
Model	20NewS (Dim.)	RCV (Dim.)
LDA (Blei et al., 2003)	1082±12.9 (50)	1187±15.4 (200)
NVDM (Miao et al., 2016)	803±9.3 (50)	574±18.3 (200)
GSM (Miao et al., 2017)	854±7.1 (50)	801±5.2 (200)
NVLDA (Srivastava & Sutton, 2017)	1155±16.5 (50)	1574±24.7 (200)
ProdLDA (SriVaStaVa & Sutton, 2017)	1145±13.3 (50)	1425±17.1 (200)
NVPDEF	759±13.1 (50)	562±11.5 (200)
Multi-Stacked NVPDEF	783±17.6 (20-50)	576±18.8 (50-200)
are listed in Table 2. Additionally, Appendix L shows the qualitative results from topic models.
8 Conclusion
This paper suggests a new gradient estimator for general discrete random variables, a generalized ver-
sion of the Gumbel-Softmax estimator. To strengthen the practical usage of reparameterization tricks
with the Gumbel-Softmax function, we provide a theoretical background of our reparameterization
trick. Our finding claims that a discrete random variable can always be reparameterized through the
proposed GenGS algorithm. The limitation of GenGS is the setting of the truncation level and the
Gumbel-Softmax temperature, which becomes the trade-off between the gradient estimation accuracy
and the time budget. Subsequently, we show the synthetic analysis and the VAE experiment, as well
as topic model application of GenGS. With the generalization, we expect that GenGS can diversify
the options of distributions in the deep generative model community.
8
Under review as a conference paper at ICLR 2021
References
M. Abadi, P. Barham, J. Chen, Z. Chen, A. Davis, J. Dean, M. Devin, S. Ghemawat, Ge. Irving,
M. Isard, and et al. Tensorflow: A system for large-scale machine learning. USENIX Symposium
on Operating Systems Design and Implementation, 2016.
Y. Bengio, N. Leonard, and A. Courville. Estimating or propagating gradients through stochastic
neurons for conditional computation. arXiv preprint arXiv:1308.3432,, 2013.
D.	M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet allocation. Journal of Machine Learning
Research, 2003.
M. Figurnov, S. Mohamed, and A. Mnih. Implicit reparameterization gradients. Advances in Neural
Information Processing Systems, 2018.
W. Grathwohl, D. Choi, Y. Wu, G. Roeder, and D. Duvenaud. Backpropagation through the void:
Optimizing control variates for black-box gradient estimation. International Conference on
Learning Representations, 2017.
S. Gu, S. Levine, I. Sutskever, and A. Mnih. Muprop: Unbiased backpropagation for stochastic neural
networks. International Conference on Learning Representations, 2016.
E. J. Gumbel. Statistical theory of extreme values and some practical applications: a series of lectures
(vol. 33). US Government Printing Office, 1948.
E.	Jang, S. Gu, and B. Poole. Categorical reparameterization with gumbel-softmax. International
Conference on Learning Representations, 2017.
M. Jankowiak and F. Obermeyer. Pathwise derivatives beyond the reparameterization trick. Interna-
tional Conference on Machine Learning, 2018.
W. Joo, W. Lee, S. Park, and I. C. Moon. Dirichlet variational autoencoder. Pattern Recognition, 107,
107514, 2020.
D. P. Kingma and M. Welling. Efficient gradient-based inference through transformations between
bayes nets and neural nets. International Conference on Machine Learning, 2014a.
D. P. Kingma and M. Welling. Auto-encoding variational bayes. International Conference on
Learning Representations, 2014b.
W. Kool, H. van Hoof, and M. Welling. Estimating gradients for discrete random variables by
sampling without replacement. International Conference on Learning Representations, 2020.
R. Liu, J. Regier, N. Tripuraneni, M. I. Jordan, and J. McAuliffe. Rao-blackwellized stochastic
gradients for discrete distributions. International Conference on Machine Learning, 2019.
C. J. Maddison, D. Tarlow, and T. Minka. A* sampling. Advances in Neural Information Processing
Systems, 2014.
C. J. Maddison, A. Mnih, and Y. W. Teh. The concrete distribution: A continuous relaxation of
discrete random variables. International Conference on Learning Representations, 2017.
Y. Miao, L. Yu, and P. Blunsom. Neural variational inference for text processing. International
Conference on Machine Learning, 2016.
Y. Miao, E. Grefenstette, and P. Blunsom. Discovering discrete latent topics with neural variational
inference. International Conference on Machine Learning, 2017.
A. Mnih and K. Gregor. Neural variational inference and learning in belief networks. International
Conference on Machine Learning, 2014.
A. Mnih and D. J. Rezende. Variational inference for monte carlo objectives. International Conference
on Machine Learning, 2016.
E. Nalisnick and P. Smyth. Stick-breaking variational autoencoders. International Conference on
Learning Representations, 2017.
9
Under review as a conference paper at ICLR 2021
R. Ranganath, L. Tang, L. Charlin, and D. Blei. Deep exponential families. Artificial Intelligence
and Statistics, 2015.
R. Ranganath, A. Perotte, N. Elhadad, and D. Blei. Deep survival analysis. Machine Learning for
Healthcare Conference, PMLR, 2016.
A. Srivastava and C. Sutton. Autoencoding variational inference for topic models. International
Conference on Learning Representations, 2017.
G. Tucker, A. Mnih, C. J. Maddison, J. Lawson, and J. Sohl-Dickstein. Rebar: Low-variance,
unbiased gradient estimates for discrete latent variable models. Advances in Neural Information
Processing Systems, 2017.
R. J. Williams. Simple statistical gradient-following algorithms for connectionist reinforcement
learning. Machine Learning, 8(3-4), 229-256, 1992.
J. Wu, Y. Rao, Z. Zhang, H. Xie, Q. Li, F. L. Wang, and Z. Chen. Neural mixed counting models for
dispersed topic discovery. Annual Meeting of the Association for Computational Linguistics, 2020.
M. Xu, M. Quiroz, R. Kohn, and S. A. Sisson. Variance reduction properties of the reparameterization
trick. International Conference on Artificial Intelligence and Statistics, 2019.
10
Under review as a conference paper at ICLR 2021
A Proof of Proposition 3 & Truncating Both Sides
A. 1 Proof of Proposition 3 for Truncating Right-Hand-Side
Before reminding Definition 1 and Proposition 3 of the main paper, we first introduce the definition
of almost sure convergence of sequence of random variables.
Definition. (Almost Sure Convergence) For a sequence of random variables {Xn}n∞=1, Xn converges
almost surely to random variable X , if
P (lim Xn = X ) = P ({ω ∈ Ω∣ lim Xn(ω) = X (ω)}) = 1
n→∞	n→∞
(2)
for a sample space Ω.
Definition. (A special case of right-hand-side truncation for non-negative discrete random variables)
A truncated discrete random variable Zn of a non-negative discrete random variable X 〜D(λ) is a
discrete random variable such that Zn = X if X ≤ n - 1, and Zn = n - 1 if X > n. The random
variable Zn is said to follow a truncated discrete distribution TD(λ, R) with a parameter λ and a
truncation range R = [0, n). Alternatively, we write as truncation level R = n if the left truncation is
at zero in the non-negative case.
With this definition, as we discussed in the main text, the constant outcome vector can be defined
as C = (0,1, 2, ∙∙∙ ,n - 1). Note that for Zn = 0,1, ∙∙∙ ,n - 2, the sample spaces of Zn and X
are equal, hence, P(Zn) = P(X) in such cases. This implies that the modified PMF of Zn = k
can be computed by using the PMF of X = k1 in such cases, i.e., P(Zn = k) = P(X = k) for
k = 0,1,…，n- 2. Then, consequently, P(Zn = n-1) = P(X ≥ n-1) = 1 - P"-； P(Zn = k)
due to the sum-to-one property of probability. Hence, the corresponding categorical parameter π
of the constant outcome vector c can be computed using the PMF of the original discrete random
variableX: ∏k = P(Zn = k) = P(X = k) for k = 0,1,…，n-2,andπn-ι = P(Zn = n-1)=
P(X ≥ n - 1) = 1 - Pkn=-02πk.
Proposition. With Definition 1, Zn converges to X almost surely as n → ∞.
Proof. Note that {ω ∈ Ω∣Zn(ω) = X(ω)} = {ω ∈ Ω∣X(ω) < n}. Then, We have the following:
∈
P( lim Zn = X) = P({ω
n→∞
= P({ω
= P({ω
Ω∣ lim Zn(ω) = X(ω)})
n→∞
Ω∣ lim Zn(W)二
n→∞
Ω∣X(ω) < ∞})
lim X(w) < lim n = ∞}})
n→∞
n→∞
(3)
(4)
= P(X < ∞)
=1
(5)
(6)
(7)
∈
∈
since X is a non-negative discrete random variable, and its cumulative distribution function FX (x)
has the following properties: non-decreasing as x → ∞, and 0 ≤ FX ≤ 1.
□
A.2 Proposition 3 for Truncating Both Sides
The below is truncating both side version of Definition 2 and Proposition 3 in the main paper. For
simplicity, we assume the distribution has support Z.
Definition. (Both-side truncation for general discrete distributions) A truncated discrete random
variable Zm,n of a discrete random variable X 〜D(λ) is a discrete random variable such that
(X, if m<X<n
Zm,n = n - 1, ifX ≥ n . The random variable Zm,n is said to follow a truncated
[m + 1, if X ≤ m
discrete distribution TD(λ, R = (m, n)) with a parameter λ and a truncation range R = (m, n).
With this definition, the constant outcome vector can be defined as C = (m + 1, ∙∙∙ ,n - 1).
Note that for Zm,n = m + 2,…，n - 2, the sample spaces of Zm,n and X are equal, hence,
1Note that we are using the distribution with eplicitly known PMF for discrete distribution X.
11
Under review as a conference paper at ICLR 2021
P (Zm,n) = P (X) in such cases. This implies that the modified PMF of Zm,n = k can be
computed by using the PMF of X = k in such cases, i.e., P (Zm,n = k) = P (X = k) for
k = m + 2,…，n — 2. Then, with the definition, P(Zmn = m + 1) = P(X ≤ m + 1) and
P (Zm,n = n - 1) = P(X ≥ n - 1). However, during the implementation, this definition can
be a problem since the configuration implies that there might be a case that we have to compute
two infinite sums, which are P (Zm,n = m + 1) = P(X ≤ m + 1) = Pk≤m+1 P(X = k) and
P (Zm,n = n — 1) = P(X ≥ n — 1) = Pk≥n-1 P(X = k)2. Hence, we also provide an alternative
configuration of Zm,n in the later of this section.
Proposition. With definition above for the truncating both sides, Zm,n converges to X almost surely
as m → -∞ and n → ∞.
Proof. Note that {ω ∈ Ω∣Zm,n(ω)
following:
X(ω)} = {ω ∈ Ω∣m < X(ω) < n}. Then, We have the
P ( nl→m∞ Zm,n = X) = P ({ω ∈。| nl⅛∞ Zm,n(ω) = X (ω)})	⑻
m→-∞	m→-∞
P({ω ∈ Ω∣ — ∞ = lim m < X(W) < lim n = ∞}})	(9)
m→-∞	n→∞
P({ω ∈ Ω∣ — ∞ < X(ω) < ∞})	(10)
P(-∞ < X < ∞)	(11)
P(X < ∞) — P(-∞ < X)	(12)
1	(13)
since X is a discrete random variable, and its cumulative distribution function FX (x) has the
following properties: non-decreasing as X → ∞, non-increasing as X → -∞, and 0 ≤ Fχ ≤ 1. □
As we discussed above, during the implementation, computing the small probabilities of both left
and right tail can cause a problem, either it can have high complexity3 or even impossible4. Hence,
when we can consider the alternative definition such as Zm,n
X, if m < X < n
n - 1, if X ≥ n or X ≤ m
which has a simpler PMF computation. In this case, we can simply add the remaining probability of
unlikely samples at the right-most value, and moreover, the alternative configuration does not harm
the proof of the proposition. Hence, with the alternative defitnition, the the corresponding categorical
parameter ∏ = (∏m+ι, •…,∏n-ι) of the constant outcome vector C = (m +1, ∙∙∙ ,n — 1) can be
computed using the PMF of the original discrete random variable X: πk = P(Zn = k) = P(X = k)
for k = m + 1,…,n — 2, and ∏n-ι = P(Zn = n — 1) = P(X ≥ n — 1) + P(X < m +1) =
n-2
1 —	k=m+1 πk.
B	Proof of Proposition 4
Proposition. For any truncated discrete random variable Z 〜TD(λ, R) of discrete distribution
D(λ) and a transformation T, Z can be reparameterized by T (GM(π)) ifwe set πk = P(Z = ck).
Proof. Note that Z has two parameters: the distribution parameter λ and the truncation range
R. Assume that we have possible outcome set C = {c0,…，Cn-ι} of n possible outcomes by
truncating the distribution with truncation range R. Note that the transformation is defined as
T(w) = Pkn=-01 wkck = Pk w c. By pre-defining the truncation range R as a hyper-parameter,
the randomness of Z is fully dependent on the distribution parameter λ. Now, we introduce the
Gumbel random variable G = — log(— log U) where U 〜Uniform(0,1) as an auxiliary random
variable. Then, given a categorical parameter π ∈ ∆n-1, any n-dimensional one-hot vector ej =
2Or, there might be a case that one of P (Zm,n = m + 1) = P (X ≤ m + 1) and P (Zm,n = n - 1) =
P (X ≥ n - 1) requires summation of high complexity, even though it is a finite summation.
3For example, if we truncate Poisson(1000) with truncation range R = [900, 1100], we have to compute
PMF values for 0 ≤ x < 900 to sum-up the left-hand meaningless probability, and it causes high complexity.
4For example, the case when the support has infinite support for both left (-∞) and right (∞) sides.
12
Under review as a conference paper at ICLR 2021
(0,…,0,1,0, ∙ ∙ ∙ , 0), which has 1 in jth entry and 0 in all other entries, can be reparameterized by
Gumbel-Max trick.
Suppose we have a sample Cm from Z, and note that we have known PMF values ∏ = (∏o, ∙ ∙ ∙ , ∏n-1)
of Z by the definition of Z. Then, with the transformation T and the constant outcome vector
c = (co,…，Cn-ι), the following holds:
n-1
cm =	ck ek = T(em ) .	(14)
k=0
Since the transformation T is also a deterministic function, by introcuding the Gumbel random
variable as an auxiliary random variable, we can replace the randomness of Z from λ (or π in the
implicit inference case) with the uniform random variable composing the Gumbel random variable.
Hence, the truncated discrete random variable Z can be reparameterized by the Gumbel-Max trick
and the transformation T.	□
C Proof of Theorem 5
Theorem. For a transformation T and a given categorical parameter π ∈ ∆n-1, the convergence
property of Gumbel-Softmax to Gumbel-Max still holds under the linear transformation T, i.e.,
GS(π, τ) → GM(π) as τ → 0 implies GENGS(π, τ) → T (GM(π)) as τ → 0.
Proof. Suppose we have given a categorical parameter π ∈ ∆n-1. Define fM be a Gumbel-Max
trick function, and fSτ be a Gumbel-Softmax trick function with a temperature τ > 0 that both
functions take the categorical parameter and a Gumbel sample as inputs. Note that fM returns a
one-hot vector which has 1 in the argmax entry after the Gumbel perturbation, and fSτ returns a
one-hot-like softmax activation value with the temperature τ with the Gumbel perturbation.
Draw a random sample U 〜Uniform(0,1)n which defines the Gumbel sample g for the Gumbel
perturbation. Assume that log πm - log (- logum) > log πj - log (- loguj) for all j 6= m, i.e.,
the selected sample as a category is Cm out of possible outcome set {co,…，Cn-ι}. Therefore, for
the Gumbel-Max trick, it is clear that T f (π, g)) = Pn-1[em]k ∙ ck = Pn-I em Θ C = Cm for
c = (co,…，Cn-ι) where ej = (0,…，0,1,0,…，0) is a n-dimensional one-hot vector, which has
1 in the mth entry and 0 in all other entries. Then, the statement that GS(π, τ) → GM(π) as τ → 0
implies fSτ (π, g) → fM (π, g) , i.e., the following:
fSτ (π, g) j
exp (log πj—log(- log Uj))
Pn-1 eχp (log πk-log(-log Uk)
(15)
1 if j = m
0 if j 6= m
as τ → 0 .
(16)
Then, fS(∏, g) = em/ for some relaxed one-hot vector of em, by introducing the softmax relaxation.
As a consequence,
r	eχn (log πi-log(- log Ui) ʌ	ι
fS (∏, g')] × × Cj = [ SX-----：------------―7  -------] × Cj	(17)
LJSk ,y/Jj	j |_ P Pn-1 exp (log∏k-log(-logUk)) Jj	j	'
Cm if j = m
0 if j 6= m
as τ → 0 ,
(18)
since the constant multiplication gives no harm to the approximation. Hence, by taking the summation,
which also gives no harm to the approximation, T (fS (∏,g)) = Pn-l⅛m]k∙Ck → Cm = Pn-I 2m,Θ
c → Cm = T(fM (∏,g)).	□
D PMF Shape of GenGS
Note that Figure 2(b) in the main paper is drawn by rounding-up continuous values into integers.
Since PMF for discrete distributions (Poisson(7) in Figure 2(b)) and PDF for continuous distributions
(GENGS for Poisson(7) in Figure 2(b)) cannot be directly compared within the same figure due to
their scale, we provide Figure 6 of the fine-grained PMF by rounding-up in small decimals.
13
Under review as a conference paper at ICLR 2021
Figure 6: Fine-grained PMF of GenGS for Poisson(7).
E Examples of GenGS
E.1 Truncating right-hand side for Poisson distribution
For the distributions that the left-side truncation needs to be at zero, such as the Poisson with small rate
parameter, the geometric, the negative binomial, etc., as we mentioned in the main text, we can simply
set the constant outcome vector C = (0,1,…，n — 1). Note that the ordering of C is not crucial, for
example, We can also set C = (2,1,0,3,4,…，n — 1). Then, the corresponding PMF value needs to
be computed as π = (P(Z = 2), P(Z = 1),P(Z = 0), P(Z = 3),P(Z = 4),…，P(Z = n —1)),
Where Z is the truncated discrete random variable.
E.2 Truncating both sides for Poisson distribution
For the case When the distribution requires left-side truncation, for example, Poisson(100)5, We can
set the constant outcome vector such as C = (50,51,…，149,150). Again, the ordering of C is not
crucial, hence, we can also set C = (148,150,149,147,…，53,50,52,51), for example. Afterward,
the PMF value π is naturally computed in the same order as the constant outcome vector C.
E.3 Gumbel-Softmax is a special case of GenGS.
The Gumbel-Softmax estimator of categorical random variables is a trivial case of GenGS. Assume
the number of dimensions n = 3 and a categorical parameter π = (0.5, 0.3, 0.2) in this example.
Then, the poissble outcomes of Categorical(π) are C0 = [1, 0, 0]T, C1 = [0, 1, 0]T, and C2 = [0, 0, 1]T.
Afterward, draw a sample w from GS(π, τ) for some temperature τ > 0, and the value will become
a relaxed one-hot form, for example, (0.95, 0.04, 0.01). Ifwe construct
C = [C0,C1,C2]
100
= 0 1 0 =I3 ,
001
(19)
(20)
then T(w) = k w C = k wkCk ≈ w. Hence, the Gumbel-Softmax trick can be written in the
form of GenGS with the identity matrix in the linear transformation. Note that we abuse the symbol
of Hadamard product () in terms of the dimension, where the last term of T(w) = Pk w C =
Pk wkCk is actually the multiplication ofa scalar wk ∈ [0, 1] and a vector Ck ∈ R3 in this case.
E.4 GenGS can be applied to multinomial distribution.
If we go one step forward from the example above, we can reparameterize multinomial distribution
with GENGS trick, also. For example, assume the number of trial m = 3 and the probability vector
p = [p1, p2, p3] = [.7, .2, .1]. Then, the possible outcomes are C0 = [3, 0, 0]T, C1 = [0, 3, 0]T,
C2 = [0, 0, 3]T, C3 = [2, 1, 0]T, C4 = [2, 0, 1]T, C5 = [1, 2, 0]T, C6 = [1, 0, 2]T, C7 = [0, 2, 1]T, C8 =
[0,1, 2]t, and C9 = [1,1, 1]t, where the corresponding probability is (?+：： +；；)!pin1 p2n2p3n3 for
5Note that Poisson(100) has inprobable samples at x < 50 and x > 150.
14
Under review as a conference paper at ICLR 2021
outcome [n1, n2, n3]. Construct the linear transformation constant c as the following:
c = [c0 c1 c2 c3 c4 c5 c6 c7 c8 c9]
3002211001
=0301020211
0030102121
(21)
(22)
where the categorical parameter ∏ = ( (nWn2+?!pin1 p2n2p3n3)	. Ifwe sample a Gumbel-
n1!n2!n3!	[n1,n2,n3]
Softmax sample w from GS(π, τ) and compute T = Pk w c, the result will be in the relaxed
form of selected samples cm . This example shows how the linear transformation constant c can be
generalized to the matrix form. However, if we recall that the equation no + …+ nk-i = n has
(n+kτ) solutions of non-negative tuple (no,…，nk-i), where (n+k-1) ≤ O(nmin{k,n-1}), the
relaxed categorical selection through the Gumbel-Softmax can become problematic due to the high
complexity when n or k has large value. Hence, in this situation, reducing the possible outcomes
by disregarding unlikely samples by user guidance can be a remedy, but the treatment can not be a
fundamental solution, and handling such case can be an open research question.
F Inference Step, Algorithm & Complexity of GenGS
F.1 Visualization of GenGS Reparametrization Steps
Figure 7 and Figure 8 represent the reparameterization stpes of explicit inference and implicit
inference of GenGS, respectively. For both figures, the shaded nodes indicate the auxiliary Gumbel
samples, composed of uniform samples, which enable the reparameterized variable to be deterministic
with respect to the parameter of the target distribution.
Forward Pass
PK)
PMFValues
Relaxed One-Hot Sample
ReparameteriZed Sample
1
n
Truncation Level Gumbel Random Samples Temperature Outcome Vector
Figure 7: Visualization of GenGS reparameterization of explicit inference version. Note that we
compute PMF values from the infered parameter λ.
F.2 Algorithm & Additional Computational Complexity of GenGS
Algorithm 1 and Algorithm 2 provides the algorithm of explicit and implicit inference steps of
GenGS, respectively. The explicit inference has further computation on PMF value calculation in
Line 3-4 of Algorithm 1 and the linear transformation computation in Line 8 of 1 compared to the
original Gumbel-Softmax reparameterizer of the categorical distribution. Note that this additional
computation complexity may not be represented as O(n) if we assume that there are n possible
outcomes by truncating the distribution, since the computation on PMF values from the inferred
distribution parameter λ depends on the PMF of distribution. Meanwhile, the implicit inference
only has extra linear transformation computation in Line 5 of Algorithm 2 compared to the original
Gumbel-Softmax reparameterizer of the categorical distribution, by inferring the logit of the PMF
values directly in Line 3 of Algorithm 2. Hence, in this case, the additional computational complexity
15
Under review as a conference paper at ICLR 2021
Forward Pass
PMF LogitValues PMF Values
SoftmaX
ɪ
n
Truncation Level
GumbelRandomSamples Temperature OutComeVeCtor
Figure 8: Visualization of GenGS reparameterization of implicit inference version. Note that we do
not infer the distribution parameter λ, and the PMF values are computed directly, instead.
T (W) = ∑ w 0 c
of GENGS is O(n), compared to the original Gumbel-Softmax. Note that this complexity does not
affect on the total complexity under the O-notation, since the inference step of the original Gumbel-
Softmax also contains the inference on the logit of the probability which has Ω(n) complexity.
Algorithm 1 Explicit GenGS: Inference step on the parameter λ of distribution pλ
1:	Input: PMF pλ(∙) of distribution D(λ), loss function f (∙), Gumbel-Softmax trick GS, tem-
perature τ > 0, truncation range R, linear transformation T(∙), constant outcome vector c.
2:	Infer distribution parameter λ.
3:	for k = 0 to n - 2 do
4:	Compute πk = pλ (ck).
5:	end for
6:	Compute πn-1 = 1 - Pkn=-02 πk .
7:	Sample n-dimensional one-hot-like W 〜GS(π, T).
8:	Compute transformation z = T(w) = Pj wjcj.
9:	Compute loss f(z).
10:	Update λ via stochastic gradient method.
Algorithm 2 Implicit GENGS: Inference step on the PMF values π of distribution pλ
1:	Input: PMF pλ(∙) of distribution D(λ), loss function f (∙), Gumbel-Softmax trick GS, tem-
perature τ > 0, truncation range R, linear transformation T(∙), constant outcome vector c.
2:	Infer PMF logit-value ν.
3:	Compute π = softmax(ν).
4:	Sample n-dimensional one-hot-like W 〜GS(π, T).
5:	Compute transformation z = T(w) = Pj wjcj.
6:	Compute loss f(z).
7:	Update V via stochastic gradient method.
G Distributions in TensorFlow Probability
We provide the table of discrete distributions where GenGS can be applied in Table 3. We list up
the discrete distributions which are available in TensorFlow Probability 0.8.06 in lexicographical
order. Note that Bernoulli and Categorical are different from OneHotCategorical
and RelaxedOneHotCategorical. The original Gumbel-Softmax are available only for
6https://www.tensorflow.org/probability/api_docs/python/tfp/distributions
16
Under review as a conference paper at ICLR 2021
(1) OneHotCategorical ,which is relaxed as RelaxedOneHotCategorical; and (2)
Bernoulli, which is relaxed as RelaxedBernoulli, but can not be applied to Categorical.
However, by generalizing the Gumbel-Softmax, i.e., GenGS, other distributions as listed below,
including Categorical. Also, Empirical, which is a user-defined distribution in TensorFlow
Probability, can utilize GENGS which is not in the list. Note that for Binomial, if n is large orp
has extreme value close to 0 or 1, one can truncate left, right, or both. Also, for Multinomial, as
an extension of the Binomial case, one can disregard unlikely samples.
Table 3: A list of distributions which can be reparameterized by GenGS with their distribution
parameters in TensorFlow Probability 0.8.0.
Distribution	PMF P(X = k)	Reparameterized Parameter	Infinite Support	Truncation Side
Bernoulli(p) p ∈ [0, 1], k ∈ {0, 1}	Pk(1 - P)i-k	P		None
Binomial(n, p) n ∈ N≥o,p ∈ [0,1],k ∈ {1,…，n}	⑦ Pk(I-P )k	P		None*
Categorical(P = [pi,…，Pκ]) Pi ∈ [0,1],P Pi = 1,k ∈{1,…，K}, ki∈{0,1},Pki=1	QjK=i Pjkj	P		None
DirichletMultinomial(n, α = [αι,…,ακ]) n ∈ N,αi > 0, ki ∈{0,…，n}, P ki = n	n!r(P αj) QK r(kj+ɑj) Γ(n+P a,) Uj=I kj!Γ(αj)	α		None
Geometric(P) P∈ (0,1),k∈N≥0	(1 - P)kP	P	X	Right
Multinomial(n,p = [pi, ∙∙∙ ,pκ]) n ∈ N,Pi ∈ [0, 1], PPi = 1, ki ∈{0,…，n}, P ki = n	(kι∙n kκ)QK=i Pkj	P		None*
NegativeBinomial(n, P) n∈N,k ∈N≥0	(n+k-1)(1- P)nPk	P	X	Right
OneHotCategorical(P = [pi, ∙∙∙ ,Pk]) Pi ∈ [0,1],PPi= 1, ki∈{0,1},Pki=1	QjK=i Pjkj	P		None
Poisson(λ) λ ∈ R>0,k ∈N≥0	λk exp-λ k!	λ	X	Right, Both
Zipf(n, s)	k-s	s		None
S ≥ 0, n ∈ N, k ∈ {1,…,n}	Pn=I n-s			
H KL Divergence between Two Truncataed Distributions
Theorem. Assume two truncated distributions X 〜TD(λ,n) and Y 〜TD(λ,n) where
∏k = P(X = k), ∏k = P(Y = k). Then, the KL divergence between X and Y can
be represented in the KL divergence between the categorical distributions where KL(Y||X) =
KL (Categorical (π) || Categorical (π)).
17
Under review as a conference paper at ICLR 2021
Proof.
KL(Y iiX) = X P (Y=k)log (P (X=k))	(23)
=X ∏k log (πk)	(24)
k	πk
KL(Categorical(∏) ||Categorical(∏))
(25)
□
I Experiment: General Setting
For all experiments, we use Intel Core i7-6700K CPU, 32GB RAM, and Titan X. For the dependency,
we use TensorFlow version 1.15.0, TensorFlow Probability version 0.8.0, and PyTorch version 1.0.1.
Also, we run the experiments over 10 times for each experiment.
J S ynthetic Example
J.1 Experimental Setting
In this experiment, We first sample tι,…，tk i.i.d. from a discete distribution D(θ) for a fixed θ > 0,
and optimize the loss function Ez〜p(z» [Pk=ι(zi - ti)2] with respect to λ wherep(z∣λ) isD(λ).
We use Poisson(20), Binomial(20, .3), Multinomial(3, [.7, .2, .1]), and NegativeBinomial(3, .4) in
this experiment, and the distribution parameter which we want to infer in each distribution is λ in
Poisson(λ), Binomial(20, λ), Multinomial(3, λ), and NegativeBinomial(3, λ). For GENGS, we use
truncation level (7, 36) and 12 for the Poisson and the negative binomial, respectively. Note that
the binomial case does not require truncation of the distribution. We use k = 5 sampled targets for
the Poisson and the binomial cases, and k = 1 for the negative binomial case. In this experiment,
we separately utilize the temperature τ as τ = 1. for the high-temperature case, and τ = .25 for
the low-temperature case. To compute the variance of gradients, we sampled 100 gradients for the
Poisson and binomial, and 500 gradients for the negative binomial. For fair comparisons, we use
m = 1 fixed category for gradients for the RBs. Whereas it is able to use more than one fixed gradient
in the synthetic example, if there is more than one latent dimension, K, it requires to compute mK
gradient combinations, which has high complexity. We also adapt the Rao-Blackwellization idea in
GENGS, which is utilizing m = 1 fixed gradient and utilizing GENGS for the remainings, namely
GenGS -RB. We exclude UnOrd snice UnOrd fails to converge to the optimal parameter because
of its approximation accuracy problem with single gradient sample.
Closed-form True Gradient Derivation for the Poisson Synthetic Example. Throughout the
synthetic example, we compare the quality of gradient estimators by the convergence of losses,
variances of estimated gradients, and biases between true gradient and estimated gradient. To
compute the bias between the true gradient and the estimated gradient, we need the closed-form
solution of the true gradient. We find that the Poisson case has the closed-form true gradient, and the
derivation is as follows.
Proposition. If p(z∣λ) is a Poisson distribution with a rate parameter λ, the true gradient of
L = Ez〜p(z∣λ) [(z - t)2] with respect to λ has a closed-form solution, ∂l = 2λ — 2t + 1.
18
Under review as a conference paper at ICLR 2021
Poisson (20)
POlSSOn (20)
O 500	10∞	1500	20∞	25W	3000
Epoch
Binomial (30,0.3)
500	10∞	1500	20∞	25∞	3000
Epoch
Multinainial (3, [.7, 2, .1])
O 500 IOOO 1500	2000	2500	3000
Epoch
I (3, .4)
O 500 IOOO 1500	20∞	2500	3000
Epoch
O	200	4<K>	600	800 IOOO
Epoch
Binomial (30,0.3)
O IOOOO 20000	30000 4OKKl 50000
Epach
Multinainial (3, [.7, 2, .1])
8use> 号
RF ----- DetRB ------ StoRB ----- GenGS STHighTemp ------- GenGS ST Low Temp ----- GenGS HighTemp ------- GenGS Low Temp
RF* = DetRB* StoRB* ■ GenGS-RBSTHighTemP ■ GenGS-RB ST Low Temp —≈ ■ GenGS-RB HighTemp ■ GenGS-RB LowTemp
I (3, .4)
*∙*s*,*1*°
8ue> 号
500 IOOO 1500	2000	2500	3000
Epoch
Figure 9:	Synthetic example performance curves in log scale: (Top Row) Losses, variances, and biases
of gradients for Poisson; (Middle Row) Losses for Binomial, Multinomial, and NegativeBinomial;
(Bottom Row) Variances of gradients for Binomial, Multinomial, and NegativeBinomial. We utilize
the cumulative average for smoothing the curves, and we also provide confidence intervals together.
Proof. Note that Poisson distribution with the rate parameter λ has a mean λ and a variance λ. Hence,
the Poisson distribution has the first moment μι = λ, and the second moment μ2 = λ2 + λ.
∂L	∂	2
∂λ = ∂λEz ~p(z∣λ)[(Z - t) ]
∂
=∂λ X P(Za)(Z -1)
∂λ
z≥0
=X ∂λ Ip(Za)(Z- t)2i
z≥0
(26)
(27)
(28)
(Z - t)2
(29)
X(Z-1)2 ∂λ h λze-λ i	(30)
z≥0
t2 Nf + X(Z2 - 2tZ +12)(…-：—" e-λ )	(31)
∂λ	Z !
z≥1
-t2e-λ + X ((Z + I)2 - 2t(Z + I)+ t2) (ʌ^!—) - X(Z2 - 2tZ +12) (—)
z≥0	Z	z≥1	Z
(32)
-t2e-λ + X (z2 - 2(t - 1)z + (t - 1)2)p(Z∣λ) - X(z2 - 2tZ + t2)p(Z∣λ)	(33)
z≥0	z≥1
19
Under review as a conference paper at ICLR 2021
—t e	+	(μ2	— 2(t	—	1)μι	+	(t	— 1) ) 一	(μ2	— 2tμι + t (1 — e	))	(34)
2λ - 2t + 1	(35)
□
J.2 Experimental Result
We compare the log-loss and the log-variance of estimated gradients from various estimators in this
experiment. We also compare the log-bias in the Poisson case. We additionally provide Figure 9 to
report the confidence interval, and Figure 10 to show the convergence of loss which may not be seen
in Figure 3 of the main paper.
Poisson (20)
Poisson (28
SSOn 6oη
0	500	10∞	1500	20∞	25W	3000
Epoch
EeU£ 6oη
Poisson (20)
2.5 ∙
2.0
4瑞MiIH"岬WMn *»""*Wv) ∣lι,ι⅛⅛^ W"","WM1"F同域Xk赢:心
∣L ⅛⅛M11⅜油⅛u⅜l⅛l⅛ι山哑《财他皿1*&1*就*岫1皿111弧加1111热而
O 500 IOOO 1500	2000	2500	3000
Epoch
0	500	10∞	1500	20∞	25∞	3000
Epoch
Multinomial (3, [.7, .2, .11)
Binomial (30, 0.3)
Binomial (30, 0.3)
IOOOO 20000	30000 4OKKl 50000
Epoch
I (3. ∙*)
0	500 IOOO 1500	2000	2500	3000
EPoCh
Multinomial (3, 1.7, 2, -lɪ)
I (3, .4)
… ''∙h ∙ ∙., ■ I ∙ ,.. 'I ' ∙ ∣l .lt ∙.∙ . i 'I
F l⅜M⅜脚 M/明福*⅛t⅛⅛⅛⅜M⅛M⅛⅜⅛M糖棚Mhu⅛⅛M⅛ t⅛"Mb⅜WbX

0	200	4«>	600	800 IOOO	0 IOOOO 20000	30000 4OKKl 50000	0	500 IOOO 1500	2000	2500	3000
Epoch	Epach	Epoch
RF	---- DetRB	---- StoRB	--- GenGS ST High Temp
RF* —" DetRB*	— StoRB*	—∙ GenGS-RB ST High Temp
GenGS ST Low Temp ------ GenGS HighTemp -------- GenGS LowTemp
GenGS-RB ST Low Temp	一■ GenGS-RB HighTemp 一■ GenGS-RB LowTemp
Figure 10:	Synthetic example performance curves in log scale: (Top Row) Losses, vari-
ances, and biases of gradients for Poisson; (Middle Row) Losses for Binomial, Multinomial,
and NegativeBinomial; (Bottom Row) Variances of gradients for Binomial, Multinomial, and
NegativeBinomial. We do not smoothen the curves to show the convergence of losses in this figure.
K VAE: Synthetic Experiment on Deep Generative Models
K. 1 Experimental Setting
We utilize the (truncated) Poisson, the (truncated) geometric, and the (truncated) negative binomial
distributions in this experiment. Both MNIST and OMNIGLOT7 are hand-written gray-scale datasets
of size 28 × 28. We split MNIST dataset into {train : validation : test} = {45, 000 : 5, 000 : 10, 000},
and OMNIGLOT dataset into {22, 095 : 2, 250 : 8, 070}.
We construct two fully-connected hidden layers of dimension 500 for the encoder and the decoder,
and we set the latent dimension K = 50 for both MNIST and OMNIGLOT datasets. we use tanh
activation function, learning rate 5e-4, training epoch 500, and batch size 100, 45 for MNIST and
7https://github.com/yburda/iwae/tree/master/datasets/OMNIGLOT
20
Under review as a conference paper at ICLR 2021
OMNIGLOT, repectively. For GENGS, we use exponential temperature annealing8 from 1. to .5, and
truncation levels (1) 12 for Poisson(2); (2) 15 for Poisson(3); (3) 25 for Geometric(.25); (4) 15 for
Geometric(.5); (5) 30 for NegativeBinomial(3, .5); and (6) 30 for NegativeBinomial(5, .3).
K. 2 Experimental Result
Table 4 shows the negative ELBO results on the VAE experiments with a full range of gradient
estimators. The variants of GenGS show the lowest negative ELBO in general. We empirically
found that the extreme probability imbalance, due to the explicit PMF restriction, induces unstable
learning which leads to the performance degradation of RELAX or REBAR. We found that utilizing
Straight-Through for the discretization degrades the performance. Meanwhile, the implicit inference
methodology further leads to better optimal points, enabled by loosening the PMF condition. The
empirical reason why the implicit version is better than the explicit version is that the inferred PMF
shape is thinner in the implicit case.. Hence, the implicit distribution has lower variance than the
explicit one, and consequently samples consistent values that lead to better trained neural network
parameters, although it looses the original PMF shape.
Table 4: Test negative ELBO on MNIST and OMNIGLOT datasets. The lower is better for the
negative ELBO. Symbol “—” indicates no convergence.
MNIST	RF	RF*	NVIL	MuProp	VIMCO(5)	REBAR	RELAX
Pois(2)	153.36±3.23	122.81±2.41	129.34±4.72	~125.43±2.27-	122.55±3.28	123.44±2.54	122.71±1.92
Pois(3)	153.34±4.22	123.12±2.21	130.24±3.32	125.92±1.81	121.15±2.57	120.62±2.31	119.84±2.18
Geom(.25)	168.86±3.15	127.90±1.97	135.90±2.38	137.90±2.14	127.21±2.55	135.12±2.74	136.80±3.06
Geom(.5)	165.00±2.93	129.20±2.03	138.47±2.30	136.40±1.78	129.91±2.90	138.37±2.98	139.41±3.59
NegBin(3,.5)	—	116.67±5.97	119.28±7.80	131.96±6.49	112.69±4.30	—	—
NegBin(5,.3)	—	130.03±3.99	133.44±4.27	144.05±8.15	124.48±2.72	—	—
MNIST		STORB*	UnOrd	GENGS ST (Ex.)	GENGS (Ex.)	GENGS ST (Im.)	GENGS (Im.)
Pois(2)		124.02±4.91	153.94±5.01	~130.48±ι.5i-	103.18±0.92	106.92±2.60	96.04±1.44
Pois(3)		124.41±5.96	153.65±4.83	129.86±1.77	105.15±1.71	106.66±2.46	96.01±1.27
Geom(.25)		131.09±4.95	—	120.46±1.47	98.43±0.81	108.14±2.67	92.52±1.62
Geom(.5)		139.67±2.42	—	119.10±1.09	100.92±1.24	106.44±2.78	93.81±1.60
NegBin(3,.5)		114.36±4.12	—	117.23±1.54	98.58±1.27	102.44±3.75	94.52±1.52
NegBin(5,.3)		128.02±2.60	—	122.61±2.31	100.88±2.35	102.70±3.64	95.37±1.43
							
OMNIGLOT	RF	RF*	NVIL	MuProp	VIMCO(5)	REBAR	RELAX
Pois(2)	165.77±3.67	139.47±3.29	148.01±4.19	~142.95±i.32-	138.73±3.42	138.12±3.26	137.56±2.94
Pois(3)	164.86±4.19	140.54±2.36	148.13±3.98	143.85±1.54	139.37±3.10	137.92±3.07	137.42±2.96
Geom(.25)	171.79±4.59	142.68±2.96	153.69±2.52	152.17±1.77	142.94±3.96	146.78±3.62	148.91±4.03
Geom(.5)	170.96±3.10	142.70±1.77	153.20±1.49	149.76±2.19	142.05±3.56	149.63±3.49	151.97±3.90
NegBin(3,.5)	—	141.44±2.20	144.44±2.78	147.78±4.49	141.89±3.84	—	—
NegBin(5,.3)	—	144.44±3.68	159.40±5.13	152.81±3.34	150.49±4.09	—	—
OMNIGLOT		STORB*	UnOrd	GenGS ST (Ex.)	GENGS (Ex.)	GENGS ST (Im.)	GENGS (Im.)
Pois(2)		139.61±5.87	166.64±5.13	~148.60±i.98-	127.89±1.44	134.76±2.65	118.17±2.22
Pois(3)		140.05±3.68	166.73±6.71	147.79±1.21	131.53±1.76	135.14±2.25	119.15±1.92
Geom(.25)		143.10±3.91	—	146.54±1.18	115.23±2.00	135.61±3.22	107.79±2.84
Geom(.5)		142.56±2.97	—	141.23±1.22	115.14±2.43	136.02±3.63	108.48±2.78
NegBin(3,.5)		129.48±4.34	—	142.33±1.92	118.57±2.71	135.02±3.99	117.02±2.18
NegBin(5,.3)		151.30±3.98	—	145.27±2.i8	119.57±2.02	134.54±3.27	117.54±2.76
L Topic Model Application
L.1 Experimental Setting
Deep Exponential Families (DEFs) (Ranganath et al., 2015) are probabilistic graphical model which
utilize the stacks of exponentail family distributions. If we assume the Poisson distribution, which is
included in the exponential family, each kth Poisson latent variable counts the number of sub-topics
occurrence.
The relationship between the super-topic and the sub-topic is modeled with the linked weights,
which has positive values. Hence, with Poisson DEF, we can model hierarchical relations between
8For GenGS ST, the temperature annealing is unnecessary as the ST Gumbel-Softmax estimator does (Jang
et al., 2017).
21
Under review as a conference paper at ICLR 2021
super-topics and sub-topics including the vocabularies. Here, we utilize the idea of Miao et al. (2016;
2017); Srivastava & Sutton (2017), the neural variational architecture, to extract the latent document
representation as (relaxed) counts of supermost-topic, and consequently capture sub-topic counts.
To ensure the positive linked weights between super-topics and sub-topics, we utilize absolute value
function.
The generative process of NVPDEF is
zι 〜Poisson(λo), Z2 〜Poisson(λι), …,ZK 〜Poisson(λκ-ι),
X 〜MUltinomiaILogisticRegression(λκ)
(36)
(37)
where we adopt mUltinomial logistic regression from NVDM (Miao et al., 2016), and the inference
process of NVPDEF is
λο = MLP(x),兀=W∕ι,…，入长=Wk-/K-I
(38)
So that the approximate Poisson posterior q(zk∣zk-ι) has 黑 as distribution parameter. Here, each
Zk 〜Poisson(λk-ι) represents the count distribution of topics from the super-topic. Each component
of Wk, wk,i,j is positive, and wk,i,j captures the positive weight of relationship between super-topic i
of the kth layer and sub-topic j of the (k + 1)th layer. The objective function, ELBO, of NVPDEF is
K
L = Eq(
ZK ,…，zι)[log P(XIZK,…，zι)]- EKLg(ZMzk-i*(Zk))
(39)
k=1
where Z0 = X for simplifying the equation.
20Newsgroups9 and RCV1-V210 datasets are used in this experiment. 20Newsgroups dataset has
{train : test} = {11, 258 : 7, 487} split with the vocabulary size of 2, 000, and RCV1-V2 has {train :
test} = {794, 414 : 10, 000} split with the vocabulary size of 10, 000. For the data pre-processing,
stopwords are removed and the most frequent vocabularies are chosen. Especially for 20Newsgroups,
we use the vocabulary from Srivastava & Sutton (2017).
For the single-stacked version of NVPDEF, we do not anneal the temperature, instead, we set
temerature τ = .5. For the multi-stacked version of NVPDEF, i.e., MULTI-STACKED NVPDEF, we
utilized 10-sample on the latent layers for the stable optimization of consecutive sampling. Also, to
have better chances of learning, we utilize linear temperature annealing from τ = 3. to τ = .5 during
the training period. For all neural network models, we utilize two 500-dimensional hidden layers
for the encoders. We use 50, 20-50 stacked layers for 20Newsgroups, 200, 50-200 stacked layers
for RCV1-V2 dataset. We set λ1 = .75 with truncation level 15 for the single-stacked case, and
λ1 = 1.1, λ2 = 1. with truncation level 15 for the multi-stacked case. We train NVPDEF for 100
epochs with batch size 256 and learning rate 1e-3. We also iteratively update encoder parameters
and each linked weight parameter of latent variable. As a performance measure, we utilize perplexity
Perp = exp(-D Pd 'oN(d)) where Nd is the number of words in document d, and D is the total
number of documents.
L.2 Experimental Result
We provide super-topic, sub-topic, and word relationship obtained from two-layer-stacked NVPDEF
in 20Newsgroups dataset by listing up the top-weighted sub-topics and words in Table 5.
M Open Research Question: Non-parametric Reparameterization
Trick
In GENGS, to reparameterize discrete distributions, we convert sampling process to categorical
selection process by finitizing the support of the distribution with truncation. Here, truncating
distribution converts categorical selection on countably finite number of categories to categorical
selection on finite number of categories, i.e., turn non-parametric problem into parametric problem.
9http://qwone.com/〜jason/2 0Newsgroups/
10https://trec.nist.gov/data/reuters/reuters.html
22
Under review as a conference paper at ICLR 2021
Table 5: Super-topic, sub-topic, and word relationship obtained from two-layer-stacked NVPDEF in
20Newsgroups dataset.
Super Topic 1	Super Topic 2	Super Topic 3	Super Topic 4	Super Topic 5	Super Topic 6
Topic 1	Topic 2	Topic 3	Topic 4	Topic 5	Topic 6	Topic 7	Topic 8	Topic 9	Topic 10	Topic 11	Topic 12
lebanese	hitler	knife	tire	water	probe	brand	honda	flyers	pitcher	holy	bible
lebanon	jewish	gun	helmet	air	spacecraft	outlet	dealer	braves	montreal	resurrection	biblical
palestinian	nazi	police	rider	heat	plane	sale	offer	hitter	score	passage	faith
arabs	religion	weapon	bike	cold	shuttle	shipping	sell	philadelphia	season	jesus	prayer
israeli	territory	firearm	gear	oil	nasa	insurance	condition	detroit	game	worship	doctrine
islamic	sentence	handgun	motorcycle	gas	launch	price	purchase	rangers	player	christ	verse
regulation	moral	officer	wheel	noise	fuel	supply	market	minnesota	tie	sin	god
The categorical selection on finite number of categories by disregarding the samples of extremely
small probability might cause a problem if we need to utilize full range of possible outcomes. For
example, in the multinomial case in Appendix E.4, as n and k grows, proposed GENGS should ignore
numerous probable samples due to the high complexity on the number of possible outcomes.
A* sampling (Maddison et al., 2014) is a non-parametric version of Gumbel-Max trick which we also
utilize in GenGS, since A* sampling searches maximum Gumbel sample among countably infinite
Gumbel samples by A* algorithm. Utilizing A* sampling concept in reparameterizing the distribution
with countably infinite support could lead to better reparameterization in terms of reparameterizing the
exact distribution instead of approximate distribution. However, we utilize the truncated distribution
in proposed GenGS to convert countably infinite categorical selection into finite categorical selection
for the following reasons.
First, while adapting non-parametric methodology into a neural network, which has a fixed number of
parameters, people usually give a limit as a certain point by utilizing the truncation level. An example
of such a case is a Stick-breaking VAE (Nalisnick & Smyth, 2017) which utilizes Dirichlet process
in the latent variable of VAE, and the authors finitized the number of sticks by the human guidance.
Second, while there is no previous work on reparameterization trick for fully-non-parametric categor-
ical selection, if we finitize the number of categories with the truncated distributions suggested in
the paper, we can utilize Gumbel-Softmax reparameterizer which already verified in deep generative
model community and widely used by the implementation in the deep learning framework such as
TensorFlow, i.e., RelaxedOneHotCategorical. Finally, if we have to choose one between the
parametric model and the non-parametric model, the choice depends on the situation that we face up
to. For example, we can compare Gaussian mixture model (GMM) and Dirichlet process Gaussian
mixture model (DPGMM). If we have a clue on the number of clusters, we could directly apply
GMM instead of DPGMM. However, if we know nothing about the data, utilizing DPGMM can be a
good choice. Also, we can not directly compare GMM and DPGMM along the same line, since the
experimental result differs from data to data.
In summary, as other non-parametric models do, we turn the non-parametric problem into the
parametric problem, especially by utilizing the truncated distribution, and this kind of treatment
is a natural way of solving such difficulty. However, we believe that investigating non-parametric
reparameterizer, particularly utilizing A* sampling which is theoretically solid, is a crucial and open
research question in the deep generative model community.
23