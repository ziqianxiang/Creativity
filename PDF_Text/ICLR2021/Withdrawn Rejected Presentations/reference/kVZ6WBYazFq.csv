title,year,conference
 Fairsquare: probabilistic ver-ification of program fairness,2017, Proceedings of the ACM on Programming Languages
 On the robustness of interpretability methods,2018, CoRR
 Probabilistic verification of fairnessproperties via concentration,2019, Proceedings of the ACM on Programming Languages
 Three modern roles for logic in AI,2020, CoRR
 On the reasons behind decisions,2020, CoRR
 A roadmap for a rigorous science of interpretability,2017, CoRR
" European Union regulations on algorithmic decision-makingand a ""right to explanation""",2017, AI Magazine
 A survey of methods for explaining black box models,2019, ACM Comput
 WAPS: Weighted and projectedsampling,2019, In Proceedings of Tools and Algorithms for the Construction and Analysis of Systems(TACAS)
 Optimal sparse decision trees,2019, In Advances in NeuralInformation Processing Systems 32
 Abduction-based explanations formachine learning models,2019, In AAAI
 Model assertions for monitoringand improving ML models,2020, In Inderjit S
 The mythos of model interpretability,2018, Queue
 Not all FPRASs are equal: demystifyingFPRASs for DNF-counting,2019, Constraints
" ""Why should I trust you?"": Explaining thepredictions of any classifier",2016, In KDD
 Anchors: High-precision model-agnosticexplanations,2018, In AAAI
 Cxplain: Causal explanations for model interpretation underuncertainty,2019, In H
 A symbolic approach to explaining Bayesian networkclassifiers,2018, In IJCAI
 Compiling Bayesian network classifiers into decisiongraphs,2019, In AAAI
 Learning important features throughpropagating activation differences,2017, In Doina Precup and Yee Whye Teh (eds
 bLIMEy: surrogateprediction explanations beyond LIME,2019, arXiv preprint arXiv:1910
 Axiomatic attribution for deep networks,2017, In DoinaPrecup and Yee Whye Teh (eds
 Visualizing and understanding convolutional networks,2014, InDavid J
" "" why should you trustmy explanation?"" understanding uncertainty in lime explanations",2019, arXiv preprint arXiv:1904
