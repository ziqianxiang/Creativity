title,year,conference
 Learning intrinsically motivated options to stimulatepolicy exploration,2020, 2020
 Successor features for transfer in reinforcement learning,2017, In NeurIPS
 Transfer in deep reinforcement learning using successor featuresand generalised policy improvement,2018, In ICML
 Universal successor features approximators,2019, In ICLR
 Exploration by random networkdistillation,2018, arXiv preprint arXiv:1810
 Improving exploration in evolution strategies for deep reinforcement learning via apopulation of novelty-seeking agents,2018, In NeurIPS
 Temporally-extended -greedy exploration,2020, arXivpreprint arXiv:2006
 BERT: Pre-training of deepbidirectional transformers for language understanding,2019, In NAACL
 RL2 : Fastreinforcement learning via slow reinforcement learning,2016, arXiv preprint arXiv:1611
 Go-explore: a newapproach for hard-exploration problems,2019, arXiv preprint arXiv:1901
 Diversity is all you need:Learning skills without a reward function,2019, In ICLR
 Model-agnostic meta-learning for fast adaptation ofdeep networks,2017, arXiv preprint arXiv:1703
 Stochastic neural networks for hierarchical reinforce-ment learning,2017, In ICLR
 Rich feature hierarchies for accurateobject detection and semantic segmentation,2014, In CVPR
 Variational intrinsic control,2016, arXivpreprint arXiv:1611
 Unsupervised meta-learningfor reinforcement learning,2018, arXiv preprint arXiv:1806
 Recurrent world models facilitate policy evolution,2018, In NeurIPS
 Dream to control: Learningbehaviors by latent imagination,2019, In ICLR
 Fast task inference with variational intrinsic successor features,2020, In ICLR
 Provably efficient maximumentropy exploration,2019, In ICML
 Momentum contrast forunsupervised visual representation learning,2019, arXiv preprint arXiv:1911
 Data-efficientimage recognition with contrastive predictive coding,2019, arXiv preprint arXiv:1905
 Rainbow: Combining improvements indeep reinforcement learning,2018, In AAAI
 Long short-term memory,1997, Neural computation
 Vime:Variational information maximizing exploration,2016, In NeurIPS
 Unsu-pervised curricula for visual meta-reinforcement learning,2019, In Advances in Neural InformationProCeSSing Systems
 Reinforcement learning with unsupervised auxiliary tasks,2017, InICLR
 Model-basedreinforcement learning for atari,2019, arXiv preprint arXiv:1903
 Recurrentexperience replay in distributed reinforcement learning,2019, In ICLR
 Curl: Contrastive unsupervised representationsfor reinforcement learning,2020, In ICML
 State representa-tion learning for control: An overview,2018, Neural NetworkS
 When simple exploration is sample efficient: Identifying sufficientconditions for random exploration to yield pac rl algorithms,2018, arXiv preprint arXiv:1805
 Human-level controlthrough deep reinforcement learning,2015, Nature
 Variational information maximisation for intrinsicallymotivated reinforcement learning,2015, In NeurIPS
 Safe and efficient off-policyreinforcement learning,2016, In NeurIPS
 Count-based explorationwith neural density models,2017, arXiv preprint arXiv:1703
 Curiosity-driven exploration byself-supervised prediction,2017, In ICML
 Agent57: Outperforming the atari human benchmark,2020, In ICML
 Never giveup: Learning directed exploration strategies,2020, In ICLR
 Languagemodels are unsupervised multitask learners,2019, OpenAI Blog
 Decoupling representation learningfrom reinforcement learning,2020, arXiv preprint arXiv:2009
 Decoupling representation learningfrom reinforcement learning,2020, arXiv preprint arXiv:2009
 Levy flight search patterns of wandering albatrosses,1996, Nature
 Duelingnetwork architectures for deep reinforcement learning,2016, In ICML
 Im-proving sample efficiency in model-free reinforcement learning from images,2019, arXiv preprintarXiv:1910
