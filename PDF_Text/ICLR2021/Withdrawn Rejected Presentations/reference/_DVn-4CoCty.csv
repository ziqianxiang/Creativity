title,year,conference
 Metareg: Towards domain general-ization using meta-regularization,2018, In NeurIPS
 Meta-learning via learned loss,2019, arXiv preprint arXiv:1906
 Webly supervised learning of convolutional networks,2015, In ICCV
 Deep learning for classical japanese literature,2018, In NeurIPS (Workshop)
 Robust loss functions under label noise for deepneural networks,2017, In AAAI
 Optimizing loss functions through multivariate taylorpolynomial parameterization,2020, arXiv preprint arXiv:2002
 Co-teaching: Robust training of deep neural networks with extremely noisy labels,2018, InNeurIPS
 Adapting arbitrary normal mutation distributions inevolution strategies: The covariance matrix adaptation,1996, In CEC
 Deep residual learning for imagerecognition,2016, In CVPR
 Evolved policy gradients,2018, In NeurIPS
 Addressing the loss-metric mismatch with adaptive loss alignment,2019, In ICML
 Deep bilevel learning,2018, In ECCV
 Mentornet: Learning data-driven curriculum for very deep neural networks on corrupted labels,2018, In ICML
 Adam: A method for stochastic optimization,2015, In ICLR
 Improving generalization in metareinforcement learning using learned objectives,2020, In ICLR
 Learning multiple layers of features from tiny images,2009, Masterâ€™s thesis
 MNIST handwritten digit database,2010, 2010
 Feature-critic networks forheterogeneous domain generalization,2019, In ICML
 Makingdeep neural networks robust to label noise: A loss correction approach,2017, In CVPR
 Regularizingneural networks by penalizing confident output distributions,2017, In ICLR
 Searching for activation functions,2018, In ICLR(Workshop)
 Training deep neural networks on noisy labels with bootstrapping,2015, In ICLR
 Very deep convolutional networks for large-scale imagerecognition,2015, In ICLR
 Learning from noisy labels withdeep neural networks: A survey,2020, arXiv preprint arXiv:2007
 Rethinkingthe inception architecture for computer vision,2016, In CVPR
 Domainrandomization for transferring deep neural networks from simulation to the real world,2017, In IROS
 Symmetric crossentropy for robust learning with noisy labels,2019, In CVPR
 Combating noisy labels by agreement: A jointtraining method with co-regularization,2020, In CVPR
 Learning toteach with dynamic loss functions,2018, In NeurIPS
 Learning from massive noisylabeled data for image classification,2015, In CVPR
 L_dmi: A novel information-theoretic lossfunction for training deep nets robust to label noise,2019, In NeurIPS
 Generalized cross entropy loss for training deep neural networkswith noisy labels,2018, In NeurIPS
