title,year,conference
 Massively Multilingual Sentence Embeddings for Zero-ShotCross-Lingual Transfer and Beyond,2019, Transactions of the ACL 2019
 On the Cross-lingual Transferability of Mono-lingual Representations,2020, In Proceedings of ACL 2020
 Layer normalization,2016, arXiv preprintarXiv:1607
 Rezero is all you need: Fast convergence at large depth,2020, arXiv preprintarXiv:2003
 Cross-lingualnatural language generation via pre-training,2020, In Proceedings of the AAAI Conference on ArtificialIntelligence
 InfoXLM: An information-theoretic framework for cross-lingual language model pre-training,2020, arXiv preprint arXiv:2007
 ELECTRA: Pre-trainingtext encoders as discriminators rather than generators,2020, arXiv preprint arXiv:2003
 XNLI: Evaluating cross-lingual sentence representations,2018, InProceedings ofEMNLP 2018
 Un-supervised cross-lingual representation learning at scale,2019, arXiv preprint arXiv:1911
 Unified langUage model pre-training for natUral langUage Understandingand generation,2019, In Advances in Neural Information Processing Systems
 The lottery ticket hypothesis: Training prUned neUral net-works,2018, CoRR
 Deep residUal learning for image recog-nition,2016, In Proceedings of the IEEE conference on computer vision and pattern recognition
 Sentencepiece: A simple and langUage independent sUbwordtokenizer and detokenizer for neUral text processing,2018, arXiv preprint arXiv:1808
 ALBERT: A lite bert for self-sUpervised learning of langUage representations,2019, arXiv preprintarXiv:1909
 Very deep transformers for neural ma-chine translation,2020, arXiv preprint arXiv:2008
 RoBERTa: A robustly optimized BERT pre-training approach,2019, arXiv preprint arXiv:1907
 Multilingual denoising pre-training for neural machine translation,2020, arXivpreprint arXiv:2001
 Universal de-pendencies 2,2018,2
 Cross-lingual name tagging and linking for 282 languages,2017, In Proceedings ofACL 2017
 A call for clarity in reporting BLEU scores,2018, In Proceedings of the Third Conference onMachine Translation
 MASS: Masked sequence to se-quence pre-training for language generation,2019, 2019
 Tied transformers: Neural machinetranslation with shared encoder and decoder,2019, In Proceedings of the AAAI Conference on ArtificialIntelligence
 PAWS-X: A cross-lingual adversarialdataset for paraphrase identification,2019, In Proceedings ofEMNLP 2019
 Overview of the third bucc shared task:Spotting parallel sentences in comparable corpora,2018, In Proceedings of 11th Workshop on Buildingand Using Comparable Corpora
