title,year,conference
 Proxquant: Quantized neural networks via proximaloperators,2019, In Proc
 Estimating or propagating gradientsthrough stochastic neurons for conditional computation,2013, arXiv preprint arXiv:1308
 ProxylessNAS: Direct neural architecture search on targettask and hardware,2019, In Proc
 Rethinking differentiable search for mixed-precision neuralnetworks,2020, In Proc
 Deep learning with low precision byhalf-wave gaussian quantization,2017, In Proc
 Approximate nearest neighbor search by residualvector quantization,2010, Sensors
 Pact: Parameterized clipping activation for quantized neuralnetworks,2018, arXiv preprint arXiv:1805
 Regularizing activation distributionfor training binarized deep networks,2019, In Proc
 Hawq: Hessianaware quantization of neural networks with mixed-precision,2019, In Proc
 Learned step size quantization,2020, In Proc
 Compressing deep convolutional net-works using vector quantization,2014, arXiv preprint arXiv:1412
 Neural Inf,2016, Process
 Deep residual learning for image recog-nition,2016, In Proc
 Filter pruning via geometric median fordeep convolutional neural networks acceleration,2019, In Proc
 Channel pruning for accelerating very deep neural net-works,2017, In Proc
 Amc: Automl for modelcompression and acceleration on mobile devices,2018, In Proc
 Binarizedneural networks,2016, In Proc
 Learning to quantize deep networks by optimizing quantizationintervals with task loss,2019, In Proc
 Imagenet classification with deep convo-lutional neural networks,2012, In Proc
 Pruning filters forefficient convnets,2017, In Proc
 Performance guaranteednetwork acceleration via high-order residual quantization,2017, In Proc
 In Proc,2017, IEEE Conf
 Focal loss for dense objectdetection,2017, In Proc
 DARTS: Differentiable architecture search,2019, InProc
 Metapruning: Meta learning for automatic neural network channel pruning,2019, In Proc
 Autoqb: Automl for network quantization andbinarization on mobile devices,2019, arXiv preprint arXiv:1902
 Re-laxed quantization for discretized neural networks,2019, In Proc
 Thinet: A filter level pruning method for deep neuralnetwork compression,2017, In Proc
 Efficient neural architecture searchvia parameter sharing,2018, In Proc
 Regularized evolution for imageclassifier architecture search,2019, In Proc
 Imagenet large scale visualrecognition challenge,2015, Int J
 Bit fusion: Bit-level dynamically composable architecture for accelerating deepneural network,2018, In International Symposium on Computer Architecture
 Clip-q: Deep network compression learning by in-parallel pruning-quantization,2018, In Proc
 Mixed precision dnns: All you need is a goodparametrization,2020, In Proc
 Neural Inf,2020, Process
 Haq: Hardware-aware automated quan-tization with mixed precision,2019, In Proc
 Mixedprecision quantization of convnets via differentiable neural architecture search,2018, arXiv preprintarXiv:1812
 Automatic neural network compression bysparsity-quantization joint learning: A constrained optimization-based approach,2020, In Proc
 Differentiable joint pruning and quantization forhardware efficiency,2020, In Proc
 Lq-nets: Learned quantizationfor highly accurate and compact deep neural networks,2018, In Proc
 Dorefa-net: Train-ing low bitwidth convolutional neural networks with low bitwidth gradients,2016, arXiv preprintarXiv:1606
 Towards effective low-bitwidth convolutional neural networks,2018, In Proc
 Training quantized neuralnetworks with a full-precision auxiliary module,2020, In Proc
 Discrimination-aware channel pruning for deep neural networks,2018, InProc
