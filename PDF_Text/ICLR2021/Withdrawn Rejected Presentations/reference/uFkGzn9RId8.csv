title,year,conference
 Trust region policyoptimization for POMDPs,2018, arXiv preprint arXiv:1810
 OpenAI gym,2016, CoRR
 Bayesian nonparametric meth-ods for partially-observable reinforcement learning,2013, IEEE transactions on pattern analysis andmachine intelligence
 Challenges of real-world reinforcementlearning,2019, arXiv preprint arXiv:1904
 Bayesian reinforcementlearning: A survey,2015, Foundations and Trends in Machine Learning
 Neural turing machines,2014, arXiv preprintarXiv:1410
 A survey of actor-criticreinforcement learning: Standard and natural policy gradients,2012, IEEE Transactions on Systems
 Optimizing agent behavior over long time scales by transportingvalue,2018, CoRR
 Reinforcement learning with unsupervised auxiliary tasks,2016, arXivpreprint arXiv:1611
 Inferring algorithmic patterns with stack-augmented recurrentnets,2015, In Proceedings of the 28th Conference on Advances in Neural Information ProcessingSystems (NIPS)
 Memory augmented control networks,2017, arXiv preprint arXiv:1709
 Adam: A method for stochastic optimization,2014, arXiv preprintarXiv:1412
 Human-levelcontrol through deep reinforcement learning,2015, Nature
 Neural map: Structured memory for deep reinforcementlearning,2017, arXiv preprint arXiv:1702
 Learning policies with external mem-ory,1999, In Proceedings of the 16th International Conference on Machine Learning (ICML)
 Model-based Bayesian reinforcement learning in partially ob-servable domains,2008, In Proceedings of the 10th International Symposium on Artificial Intelligenceand Mathematics (ISAIM)
 Proximal policyoptimization algorithms,2017, arXiv preprint arXiv:1707
 Learning to predict by the methods of temporal differences,1988, Machine learning
 Reinforcement learning: An introduction,2018, MIT press
 Deep reinforcement learning with double q-learning,2016, In Proceedings of the 30th AAAI Conference on Artificial Intelligence (AAAI)
 Sample efficient actor-critic with experience replay,2016, arXiv preprintarXiv:1611
 Learning from delayed rewards,1989, PhD thesis
 Learning causal state representations of partiallyobservable environments,2019, arXiv preprint arXiv:1906
 Putting the values in to the expressions in LemmaC,1107,1
