title,year,conference
 Backward feature correction: How deep learning performs deeplearning,2020, ArXiv
 Understanding deep neuralnetworks with rectified linear units,2018, In International Conference on Learning Representations(ICLR)
 Obfuscated gradients give a false sense ofsecurity: Circumventing defenses to adversarial examples,2018, volume 80 of Proceedings of MachineLearning Research
 Manifold regUlarization: A geometric frame-work for learning from labeled and Unlabeled examples,2006, J
 Convex Optimization,0521, Cambridge University Press
 Certified adversarial robUstness via randomizedsmoothing,2019, volume 97 of Proceedings of Machine Learning Research
 A randomized gradient-free attack on ReLU networks,2019, InThomas Brox
 Provable robustness of relu networksvia maximization of linear regions,2019, In The 22nd International Conference on Artificial Intelligenceand Statistics
 Scaleable input gradient regularization for adversarial robust-ness,2019, CoRR
 Explaining and harnessing adversarialexamples,2015, In International Conference on Learning Representations
 Manifold regularization for locally stable deep neural networks,2020, 2020
 Provable certificates for adversarial examples:Fitting a ball in the union of polytopes,2019, In Advances in Neural Information Processing Systems 32
 Adam: A method for stochastic optimization,2015, In Yoshua Bengioand Yann LeCun (eds
 MNIST handwritten digit database,2010, 2010
 Certified robustness to adversarialexamples with differential privacy,2019, In 2019 IEEE Symposium on Security and Privacy (SP)
 Second-order adversarial attack andcertifiable robustness,2018, CoRR
 Training provably robust models by polyhedralenvelope regularization,2020, ArXiv
 Diffusion nets,2019, Applied andComputational Harmonic Analysis
 Interior-Point Polynomial Algorithms in Convex Program-ming,1994, Society for IndUstrial and Applied Mathematics
 Adversarial robUstness throUgh locallinearization,2019, In Advances in Neural Information Processing Systems 32
 Foolbox: A python toolbox to benchmarkthe robUstness of machine learning models,2017, In Reliable Machine Learning in the Wild
 The odds are odd: A statistical test for detectingadversarial examples,2019, CoRR
 Provably robUst deep learning via adversarially trained smoothed classifiers,2019, CoRR
 Computing the approximate convex hull in highdimensions,2016, CoRR
 Bounding and counting linearregions of deep neural networks,2017, CoRR
 One pixel attack for fooling deep neuralnetworks,2017, CoRR
 Intriguing properties of neural networks,2014, arXiv
 Towards fast computation of certified robustness for ReLU networks,2018, InInternational Conference on Machine Learning (ICML)
 Evaluating the robustness of neural networks: An extreme value theory approach,2018, InInternational Conference on Learning Representations (ICLR)
 Provable defenses against adversarial examples via the convex outeradversarial polytope,2018, International Conference on Machine Learning (ICML)
 Fashion-mnist: a novel image dataset for benchmarkingmachine learning algorithms,2017, CoRR
 Efficient neural networkrobustness certification with general activation functions,2018, In Advances in Neural InformationProcessing Systems (NeurIPS)
