title,year,conference
 Incremental multi-domainlearning with network latent tensor factorization,2019, AAAI Conference on Artificial Intelligence
 Multi-level factorisation net for personre-identification,2018, In IEEE Conference on Computer Vision and Pattern Recognition
 Gradnorm: Gra-dient normalization for adaptive loss balancing in deep multitask networks,2017, arXiv preprintarXiv:1711
 Very deep convolutional net-works for text classification,2016, arXiv preprint arXiv:1606
 Algorithmic deci-sion making and the cost of fairness,2017, In ACM SIGKDD International Conference on KnowledgeDiscovery and Data Mining
 Mode normalization,2018, In International Conference onLearning Representations
 Imagenet: A large-scalehierarchical image database,2009, In IEEE Conference on Computer Vision and Pattern Recognition
 Model-agnostic meta-learning for fast adaptationof deep networks,2017, In International Conference on Machine Learning
 A confidence-based approach for balancingfairness and accuracy,2016, In SIAM International Conference on Data Mining
 Image style transfer using convolutionalneural networks,2016, In IEEE Conference on Computer Vision and Pattern Recognition
 Reshaping visual datasets for domain adaptation,2013, InAdvances in Neural Information Processing Systems
 In search of lost domain generalization,2020, arXiv preprintarXiv:2007
 Depthwise convolution is all you needfor learning multiple visual domains,2019, In AAAI Conference on Artificial Intelligence
 Equality of opportunity in supervised learning,2016, InAdvances in Neural Information Processing Systems
 Deep residual learning for image recog-nition,2016, In IEEE Conference on Computer Vision and Pattern Recognition
 Mask R-CNN,2017, In IEEE Conferenceon Computer Vision and Pattern Recognition
 CyCADA: Cycle-consistent adversarial domain adaptation,2018, In InternationalConference on Machine Learning
 Arbitrary style transfer in real-time with adaptive instance normal-ization,2017, In International Conference on Computer Vision
 Adaptive mixtures oflocal experts,1991, MIT Press
 Categorical reparameterization with gumbel-softmax,2016, arXivpreprint arXiv:1611
 One model to learn them all,2017, arXiv preprint arXiv:1706
 Identifying medical diag-noses and treatable diseases by image-based deep learning,2018, Cell
 Overcom-ing catastrophic forgetting in neural networks,2017, Proceedings of the National Academy of Sciences
 Learning to generalize: Meta-learning for domain generalization,2018, In AAAI Conference on Artificial Intelligence
 Domain generalization with adversarialfeature learning,2018, In IEEE Conference on Computer Vision and Pattern Recognition
 Feature-critic networks for het-erogeneous domain generalization,2019, In International Conference on Machine Learning
 A structured self-attentive sentence embedding,2017, In Proc
 Gradient episodic memory for continual learning,2017, InAdvances in Neural Information Processing Systems
 Boost-ing domain adaptation by discovering latent domains,2018, In IEEE Conference on Computer Visionand Pattern Recognition
 Learning multi-domain convolutional neural networks for vi-sual tracking,2016, In IEEE Conference on Computer Vision and Pattern Recognition
 Automatic differentiation inPyTorch,2017, In NeurIPS Autodiff Workshop
 Domain agnostic learning with dis-entangled representations,2019, arXiv preprint arXiv:1904
 FiLM: Visualreasoning with a general conditioning layer,2018, In AAAI Conference on Artificial Intelligence
 Efficient neural architecturesearch via parameter sharing,2018, arXiv preprint arXiv:1802
 Efficient parametrization of multi-domain deep neuralnetworks,2018, In IEEE Conference on Computer Vision and Pattern Recognition
 Learning multiple visual domains withresidual adapters,2017, In Advances in Neural Information Processing Systems
 Learning to learn without forgetting by maximizing transfer and minimizing interfer-ence,2019, In International Conference on Learning Representations
 Adapting visual category models to newdomains,2010, In European Conference on Computer Vision
 Outrageously large neural networks: The sparsely-gated mixture-of-experts layer,2017, InInternational Conference on Learning Representations
 Mastering the game of gowithout human knowledge,2017, Nature
 BERT and PALs: Projected attention layers for efficientadaptation in multi-task learning,2019, International Conference on Machine Learning
 AdaShare: Learning what to share for efficientdeep multi-task learning,2019, arXiv preprint arXiv:1911
 Unsupervised domain adaptation throughself-supervision,2019, arXiv preprint arXiv:1909
 Learning more universal representations for transfer-learning,2019, IEEE Transactionson Pattern Analysis and Machine Intelligence
 Adversarial discriminative domainadaptation,2017, In IEEE Conference on Computer Vision and Pattern Recognition
 Multi-task learning for dense prediction tasks: A survey,2020, arXiv preprintarXiv:2004
 Towards universal object de-tection by domain attention,2019, In IEEE Conference on Computer Vision and Pattern Recognition
 Latent domains modelingfor visual domain adaptation,2014, In AAAI Conference on Artificial Intelligence
 Exploiting loW-rank structure from latent domains fordomain generalization,2014, In European Conference on Computer Vision
 MedMNIST classification Decathlon: A lightWeightAutoML benchmark for medical image analysis,2020, arXiv preprint arXiv:2010
 mixup: Beyond empiricalrisk minimization,2017, arXiv preprint arXiv:1710
 Neural architecture search With reinforcement learning,2016, arXiv preprintarXiv:1611
