title,year,conference
 Obfuscated gradients give a false sense ofsecurity: Circumventing defenses to adversarial examples,2018, arXiv preprint arXiv:1802
 Thermometer encoding: One hotway to resist adversarial examples,2018, In International Conference on Learning Representations
 Stochastic activation pruning for robust adversarial de-fense,2018, arXiv preprint arXiv:1803
 Understanding the difficulty of training deep feedforward neuralnetworks,2010, In AISTATS
 Explaining and harnessing adversarialexamples,2014, arXiv preprint arXiv:1412
 Countering adversarialimages using input transformations,2017, arXiv preprint arXiv:1711
 Deep residual learning for image recognition,2016, In IEEEConference on Computer Vision and Pattern Recognition (CVPR)
 Delving deep into rectifiers: Surpassinghuman-level performance on imagenet classification,2015, In ICCV
 Defense againstadversarial attacks using high-level representation guided denoiser,2018, In Proceedings of the IEEEConference on Computer Vision and Pattern Recognition
 Towards robust neural networks viarandom self-ensemble,2018, In Proceedings of the European Conference on Computer Vision (ECCV)
 Characterizing adversarial subspaces usinglocal intrinsic dimensionality,2018, arXiv preprint arXiv:1801
 Rectifier nonlinearities improve neural net-work acoustic models,2013, In Proc
 Readingdigits in natural images with unsupervised feature learning,2011, In NIPS Workshop on Deep Learningand Unsupervised Feature Learning 2011
 Distillation as adefense to adversarial perturbations against deep neural networks,2016, In 2016 IEEE Symposium onSecurity and Privacy (SP)
 Deflectingadversarial attacks with pixel deflection,2018, In Proceedings of the IEEE conference on computervision and pattern recognition
 Searching for activation functions,2017, arXivpreprint arXiv:1710
 Defense-gan: Protecting classifiers againstadversarial attacks using generative models,2018, arXiv preprint arXiv:1805
 Pixeldefend:Leveraging generative models to understand and defend against adversarial examples,2017, arXivpreprint arXiv:1710
 Intriguing properties of neural networks,2013, arXiv preprint arXiv:1312
 Mitigating adversarialeffects through randomization,2017, arXiv preprint arXiv:1711
 Feature denois-ing for improving adversarial robustness,2019, In IEEE Conference on Computer Vision and PatternRecognition (CVPR)
