title,year,conference
 Obfuscated gradients give a false sense ofsecurity: Circumventing defenses to adversarial examples,2018, In International Conference on MachineLearning
 Weight uncertaintyin neural network,2015, volume 37 of Proceedings of Machine Learning Research
 Adversarial examples are not easily detected: Bypassing tendetection methods,2017, In Proceedings of the 10th ACM Workshop on Artificial Intelligence andSecurity
 Towards evaluating the robustness of neural networks,2017, In 2017IEEE Symposium on Security and Privacy (SP)
 Dropout as a bayesian approximation: Representing modeluncertainty in deep learning,2016, In International Conference on Machine Learning
 Explaining and harnessing adversarialexamples,2014, In International Conference on Learning Representations
 Evaluation methodology for attacks against confidencethresholding models,2018, 2018
 Practical variational inference for neural networks,2011, In J
 On calibration of modern neuralnetworks,2017, In International Conference on Machine Learning
 Deep residual learning for imagerecognition,2016, In Proceedings of the IEEE conference on Computer Vision and Pattern Recognition
 Identity mappings in deep residualnetworks,2016, In European Conference on Computer Vision
 Decision boundary analysis of adversarial examples,2018, InInternational Conference on Learning Representations
 Benchmarking neural network robustness to commoncorruptions and perturbations,2019, International Conference on Learning Representations
 Variational dropout and the local reparameterizationtrick,2015, In Advances in Neural Information Processing Systems
 Learning multiple layers of features from tiny images,2009, Technical report
 Whym heads are better than one: Training a diverse ensemble of deep networks,2015, arXiv preprintarXiv:1511
 Launch and it-erate: Reducing prediction churn,2016, In D
 Readingdigits in natural images with unsupervised feature learning,2011, In NIPS workshop on deep learningand unsupervised feature learning
 Deflecting adversarialattacks,2020, arXiv preprint arXiv:2002
 Detect-ing and diagnosing adversarial images with class-conditional capsule reconstructions,2020, InternationalConference on Learning Representations
 Pixeldefend: Lever-aging generative models to understand and defend against adversarial examples,2017, In InternationalConference on Learning Representations
 Convnets and imagenet beyond accuracy: Understanding mistakesand uncovering biases,2018, In European Conference on Computer Vision
 Intriguing properties of neural networks,2014, In International Conference on LearningRepresentations
 Rethinkingthe inception architecture for computer vision,2016, 2016 IEEE Conference on Computer Vision andPattern Recognition
 On mixup training: Improved calibration and predictive uncertainty for deep neuralnetworks,2019, In Advances in Neural Information Processing Systems
 Batchensemble: An alternative approach to efficientensemble and lifelong learning,2020, In International Conference on Learning Representations
 Folding:Why good models sometimes make spurious recommendations,2017, In Proceedings of the EleventhACM Conference on Recommender Systems
 Me-net: Towards effective adversarial robustnesswith matrix estimation,2019, In International Conference on Machine Learning
 Wide residual networks,2016, ArXiv
 Mixup: Beyond empiricalrisk minimization,2018, In International Conference on Learning Representation
