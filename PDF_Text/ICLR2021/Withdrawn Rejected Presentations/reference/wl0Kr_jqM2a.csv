title,year,conference
 Obfuscated gradients give a false sense ofsecurity: Circumventing defenses to adversarial examples,2018, arXiv preprint arXiv:1802
 Synthesizing robust adver-sarial examples,2018, In Jennifer Dy and Andreas Krause (eds
 Towards evaluating the robustness of neural networks,2017, In 2017IEEE Symposium on Security and Privacy (SP)
 On evaluating adversarial robustness: Princi-ples of rigorous evaluations,2019, 2019a
 On evaluating adversarialrobustness,2019, CoRR
 Sensitivity of deep convolutional net-works to Gabor noise,2019, CoRR
 Certified adversarial robustness via ran-domized smoothing,2019, CoRR
 ImageNet: A large-scale hi-erarchical image database,2009, In 2009 IEEE conference on computer vision and pattern recognition
 Arotation and a translation suffice: Fooling CNNs with simple transformations,2017, arXiv preprintarXiv:1712
 An algorithm for quadratic programming,1956, Naval researchlogistics quarterly
 Motivatingthe rules of the game for adversarial example research,2018, ArXiv
 A research agenda: Dynamic models to defend against correlated attacks,2019, ArXiv
 Explaining and harnessing adversarialexamples,2014, arXiv preprint arXiv:1412
 Identity mappings in deep residualnetworks,2016, In European conference on computer vision
 Benchmarking neural network robustness to common cor-ruptions and perturbations,2019, In International Conference on Learning Representations
 Natural adversarialexamples,2019, arXiv preprint arXiv:1907
 Procedural noise using sparseGabor convolution,0730, ACMTrans
 Improving ro-bustness without sacrificing accuracy with patch gaussian augmentation,2019, ArXiv
 Robustness properties of Facebookâ€™s ResNeXt WSL models,2019,	ArXiv
 Practical black-box attacks against machine learning,2017, In Proceedings of the 2017 ACMon Asia conference on computer and communications security
 L2 -nonexpansive neural networks,2019, In International Conferenceon Learning Representations (ICLR)
 Semanticadv: Gener-ating adversarial examples via attribute-conditional image editing,2019, ArXiv
 Barrage of random transformsfor adversarially robust defense,2019, In Proceedings of the IEEE Conference on Computer Vision andPattern Recognition
 Accessorize to a crime:Real and stealthy attacks on state-of-the-art face recognition,2016, In Proceedings of the 23rd ACMSIGSAC Conference on Computer and Communications Security
 A general framework foradversarial examples with objectives,2019, ACM Transactions on Privacy and Security (TOPS)
 JPEG-resistant adversarial images,2017, In NIPS 2017 Workshop onMachine Learning and Computer Security
 Constructing unrestricted adversarialexamples with generative models,2018, In NeurIPS
 Intriguing properties of neural networks,2013, arXiv preprint arXiv:1312
 Ad-VerSarial:Defeating perceptual ad-blocking,2018, CoRR
 Defending against physically realizable attackson image classification,2020, In International Conference on Learning Representations
 Spatially trans-formed adversarial examples,2018, arXiv preprint arXiv:1801
 Feature denoisingfor improving adversarial robustness,2018, arXiv preprint arXiv:1812
 Aggregated residualtransformations for deep neural networks,2016, 2017 IEEE Conference on Computer Vision and PatternRecognition (CVPR)
 Towards large yet imperceptible adversarial imageperturbations with perceptual color distance,2019, ArXiv
