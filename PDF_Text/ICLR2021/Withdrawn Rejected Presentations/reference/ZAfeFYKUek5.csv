title,year,conference
 High-dimensional dynamics of generalization error in neuralnetworks,2017, CoRR
 A convergence theory for deep learning via over-parameterization,2019, In Proc
 A closer look at memorization in deep networks,2017, In Proc
 Benign ovefitting in linearregression,2020, Proceedings of the National Academy of Sciences
 Reconciling modern machine learn-ing practice and the classical bias-variance trade-off,2019, Proceedings of the National Academy ofSciences
 Convex Optimization,2004, Cambridge University Press
 The intriguing role of module criticalityin the generalization of deep networks,2020, In Proc
 Sharp minima can generalizefor deep nets,2017, In Proc
 A unified bias-variance decomposition for zero-one and squared loss,2000, In Proc
 Scaling description of generalization withnumber of parameters in deep learning,2019, CoRR
 Surprises in high-dimensional ridgeless least squares interpolation,2019, CoRR
 Deep residual learning for image recog-nition,2016, In Proc
 Early stopping in deep networks: Double descent andhow to eliminate it,2020, CoRR
 SGD on neural networks learns functions of increasing complexity,2019, InProc
 On large-batch training for deep learning: Generalization gap and sharp minima,2017, InProc
 Adam: A method for stochastic optimization,2014, In Proc
 13th Int’l Conf,1996, on Machine Learning
 12th Int’l Conf,1995, on Machine Learning
 Learning multiple layers of features from tiny images,2009, 2009
 Gradient-based learning applied todocument recognition,1998, Proceedings of the IEEE
 Rethinking parameter counting indeep models: Effective dimensionality revisited,2020, CoRR
 Understanding overfitting peaks in generalization error: Analytical risk curves forl2 and l1 penalized interpolation,2019, CoRR
 Deepdouble descent: Where bigger models and more data hurt,2020, In Proc
 Readingdigits in natural images with unsupervised feature learning,2011, In Proc
 Norm-based capacity control in neuralnetworks,1376, In Proc
 Understanding Machine Learning: From Theory toAlgorithms,2014, Cambridge University Press
 Very deep convolutional networks for large-scale imagerecognition,2015, In Proc
 An overview of statistical learning theory,1999, IEEE Trans
 Identifying generalizationproperties in neural networks,2018, CoRR
 Fashion-MNIST: a novel image dataset for bench-marking machine learning algorithms,2017, CoRR
 Rethinking bias-variancetrade-off for generalization of neural networks,2020, CoRR
 Wide residual networks,2016, CoRR
 Understandingdeep learning requires rethinking generalization,2017, In Proc
