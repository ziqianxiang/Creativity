title,year,conference
 Regularized learning for domain adaptationunder label shifts,2019, In International Conference on Learning Representations (ICLR)
 Mixmatch: A holisticapproach to semi-supervised learning,2019, arXiv
 Semi-supervised learning for neuralmachine translation,2016, In Association for Computational Linguistics (ACL)
 BERT: Pre-training of deep bidirectional transformersfor language understanding,2019, In Associationfor Computational Linguistics (ACL)
 Language to logical form with neural attention,2016, In Association forComputational Linguistics (ACL)
 Towards deep neural network architectures robust to adversarial examples,2015, InInternational Conference on Learning Representations Workshop (ICLR)
 Bidirectional LSTM-CRF models for sequence tagging,2015, arXiv
 Structured prediction models for RNN based sequence labeling in clinicaltext,2016, In Empirical Methods in Natural Language Processing (EMNLP)
 Categorical reparameterization with Gumbel-softmax,2017, arXiv preprintarXiv:1611
 A comparison of approaches to on-line handwritten character recognition,1995, PhD thesis
 Sentencepiece: A simple and language independent subword tokenizerand detokenizer for neural text processing,2018, In Empirical Methods in Natural Language Processing(EMNLP)
 Spoc: Search-basedpseudocode to code,2019, In Advances in Neural Information Processing Systems (NeurIPS)
 Detecting and correcting for label shift with black boxpredictors,2018, In International Conference on Machine Learning (ICML)
 The concrete distribution: A continuous relaxation of discreterandom variables,2016, arXiv preprint arXiv:1611
 Virtual adversarial training: a regularization methodfor supervised and semi-supervised learning,2018, IEEE Transactions on Pattern Analysis and MachineIntelligence
 De novo generation of hit-likemolecules from gene expression signatures using artificial intelligence,2020, Nature Communications
 In search of the real inductive bias: On the role of implicitregularization in deep learning,2014, arXiv
 Exploring generalization in deeplearning,2017, In Advances in Neural Information Processing Systems (NeurIPS)
 U-Net: Convolutional networks for biomedical imagesegmentation,2015, arXiv
 Improved protein structure prediction using potentials fromdeep learning,2020, Nature
 Improving neural machine translation models with monolingualdata,2016, arXiv
 Mean teachers are better role models: Weight-averaged consistencytargets improve semi-supervised deep learning results,2017, In Advances in neural information processingsystems
 Extracting and composing robust featureswith denoising autoencoders,2008, In International Conference on Machine Learning (ICML)
 Data-dependent sample complexity of deep neural networks via Lipschitzaugmentation,2019, In Advances in Neural Information Processing Systems (NeurIPS)
 Improved sample complexities for deep networks and robust classification via anall-layer margin,2020, In International Conference on Learning Representations (ICLR)
 Simple statistical gradient-following algorithms for connectionist reinforcementlearning,1992, Machine learning
 Learning perturbation sets for robust machine learning,2020, arXiv
 A syntactic neural model for general-purpose code generation,2017, In Associationfor Computational Linguistics (ACL)
 Denoising deep neural networks based voice activity detection,2013, arXiv
