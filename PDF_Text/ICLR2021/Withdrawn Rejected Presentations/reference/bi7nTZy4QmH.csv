title,year,conference
 Evasion attacks against machine learning at test time,2013, In Joint Europeanconference on machine learning and knowledge discovery in databases
 Adversarial examples are not easily detected: Bypassing tendetection methods,2017, In Proceedings of the 10th ACM Workshop on Artificial Intelligence andSecurity
 Certified adversarial robustness via randomizedsmoothing,2019, In ICML
 Explaining and harnessing adversarialexamples,2015, In ICLR
 On the effectiveness of interval bound propagationfor training verifiably robust models,2018, arXiv preprint arXiv:1810
 On certifying non-uniform bound against adversarialattacks,2019, arXiv preprint arXiv:1903
 Differentiable abstract interpretation for provablyrobust neural networks,2018, In International Conference on Machine Learning
 Deepfool: a simple andaccurate method to fool deep neural networks,2016, In Proceedings of the IEEE Conference on ComputerVision and Pattern Recognition
 Universaladversarial perturbations,2017, In Proceedings of the IEEE conference on computer vision and patternrecognition
 Transferability in machine learning: fromphenomena to black-box attacks using adversarial samples,2016, arXiv preprint arXiv:1605
 Provably robust deep learning via adversarially trained smoothed classifiers,2019, InAdvances in Neural Information Processing Systems
 Intriguing properties of neural networks,2013, In ICLR
 Provable defenses against adversarial examples via the convex outeradversarial polytope,2018, In International Conference on Machine Learning
 Scaling provable adversarialdefenses,2018, In NIPS
 Efficient multiple organlocalization in ct image using 3d region proposal network,2019, IEEE transactions on medical imaging
 Efficient neural networkrobustness certification with general activation functions,2018, In Advances in neural informationprocessing Systems
 Towardsstable and efficient training of verifiably robust neural networks,2020, In International Conference onLearning Representations
