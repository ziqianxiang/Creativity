title,year,conference
 Regret bounds for lifelong learning,2016, arXivpreprint arXiv:1610
 Multi-task feature learning,2007, InAdvances in neural information processing Systems
 A model of inductive bias learning,2000, J
 Multitask learning,1573, Machine Learning
 Incremental learning-to-learn with statistical guarantees,2018, arXiv preprint arXiv:1803
 Learning to learn arounda common mean,2018, In Advances in Neural Information Processing Systems
 High-dimensional asymptotics of prediction: Ridge regressionand classification,2018, The Annals of Statistics
 Online meta-learning,2019, InProceedings of the 36th International Conference on Machine Learning
 Unraveling meta-learning: Understanding feature representations for few-shot tasks,2020, arXivpreprint arXiv:2002
 Convergence of meta-learning withtask-specific adaptation over partial parameters,2020, arXiv preprint arXiv:2006
 Adaptive gradient-based meta-learning methods,2019, arXiv preprint arXiv:1906
 Imagenet classification with deep convolutional neuralnetworks,2012, pp
 Meta-learning withdifferentiable convex optimization,2019, In Proceedings of the IEEE Conference on Computer Visionand Pattern Recognition
 Reptile: a scalable metalearning algorithm,2018, arXiv preprintarXiv:1803
 Meta-learning with im-plicit gradients,2019, In Advances in Neural Information Processing Systems
 Optimization as a model for few-shot learning,2017, 2017
 An overview of multi-task learning in deep neural networks,2017, arXiv preprintarXiv:1706
 Prototypical networks for few-shot learning,2017, pp
 On the theory of transfer learning: The impor-tance of task diversity,2020, arXiv preprint arXiv:2006
 Global convergence and induced kernels of gradient-basedmeta-learning with neural nets,2020, arXiv preprint arXiv:2006
 Guarantees for tuning the step size using alearning-to-learn approach,2020, arXiv preprint arXiv:2006
 Efficient meta learning viaminibatch proximal update,2019, In Advances in Neural Information Processing Systems
