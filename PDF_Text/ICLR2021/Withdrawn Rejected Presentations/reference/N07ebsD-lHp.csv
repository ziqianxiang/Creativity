title,year,conference
 Obfuscated gradients give a false sense of se-curity: Circumventing defenses to adversarial examples,2018, In International Conference on MachineLearning
 Random forests,2001, Machine learning
 Decision-based adversarial attacks: Reliableattacks against black-box machine learning models,2018, In International Conference on LearningRepresentations
 Towards evalUating the robUstness of neUral networks,2017, In 2017ieee symposium on security and privacy (sp)
 Ecgadv: Generatingadversarial electrocardiogram to misgUide arrhythmia classification system,2020, In AAAI
 HopskipjUmpattack: A qUery-efficient decision-basedattack,2020, In 2020 IEEE Symposium on Security and Privacy (SP)
 Bnn+: Improvedbinary network training,2018, arXiv preprint arXiv:1812
 Evading defenses to transferable adversarialexamples by translation-invariant attacks,2019, In Proceedings of the IEEE Conference on ComputerVision and Pattern Recognition
 Attacking binarized neural networks,2018, InInternational Conference on Learning Representations
 Breaking certified defenses: Semantic adversarialexamples with spoofed robustness certificates,2020, arXiv preprint arXiv:2003
 Adversarial examples are a naturalconsequence of test error in noise,2019, In International Conference on Machine Learning
 Explaining and harnessing adversarialexamples,2015, In International Conference on Learning Representations
 Binarizedneural networks,2016, In Advances in neural information processing systems
 Is bert really robust? a strong baselinefor natural language attack on text classification and entailment,2020, In Proceedings of the AAAIConference on Artificial Intelligence
 Evasion and hardening of tree ensembleclassifiers,2016, In International Conference on Machine Learning
 Improving adversarial robustness of ensembles withdiversity training,2019, arXiv preprint arXiv:1901
 Reluplex: Anefficient smt solver for verifying deep neural networks,2017, In International Conference on ComputerAided Verification
 Convolutional neural networks for sentence classification,2014, arXiv preprintarXiv:1408
 Learning multiple layers of features from tiny images,2009, Masterâ€™s thesis
 Adversarial machine learning at scale,2016, arXivpreprint arXiv:1611
 Gradient-based learning applied todocument recognition,1998, Proceedings of the IEEE
 Towards robust neural networks viarandom self-ensemble,2018, In Proceedings of the European Conference on Computer Vision (ECCV)
 Adversarialrobustness toolbox v1,2018, 0
 Discretization based solutions forsecure machine learning against adversarial attacks,2019, IEEE Access
 Improving adversarial robustness viapromoting ensemble diversity,2019, In International Conference on Machine Learning
 Transferability in machine learning: fromphenomena to black-box attacks using adversarial samples,2016, arXiv preprint arXiv:1605
 Practical black-box attacks against machine learning,2017, In Proceedings of the 2017 ACMon Asia Conference on Computer and Communications Security
 Glove: Global vectors for wordrepresentation,2014, In Proceedings of the 2014 conference on empirical methods in natural languageprocessing (EMNLP)
 Adversarialtraining can hurt generalization,2019, In Identifying and Understanding Deep Learning PhenomenaICML Workshop
 AUtomatic diagnosis of the 12-lead ecg Using a deep neUral network,2020, Naturecommunications
 Certifiable distribUtional robUstness withprincipled adversarial training,2018, In International Conference on Learning Representations
 The German Traffic SignRecognition Benchmark: A mUlti-class classification competition,2011, In IEEE International JointConference on Neural Networks
 Ensemble meth-ods as a defense to adversarial pertUrbations against deep neUral networks,2017, arXiv preprintarXiv:1709
 IntrigUing properties of neUral networks,2014, In International Conference onLearning Representations
 Ensemble adversarial training: Attacks and defenses,2018, In 6th International Conferenceon Learning Representations
 Towards fast computation of certified robustness for relu networks,2018, InInternational Conference on Machine Learning
 Skip connectionsmatter: On the transferability of adversarial examples generated with resnets,2020, arXiv preprintarXiv:2002
 Towards adversarial robustness with 01 loss neuralnetworks,2020, In IEEE International Conference on Machine Learning and Applications
