title,year,conference
 Obfuscated gradients give a false sense of se-curity: Circumventing defenses to adversarial examples,2018, In Proceedings of the 35th InternationalConference on Machine Learning
 Decision-based adversarial attacks: Reliableattacks against black-box machine learning models,2018, In International Conference on LearningRepresentations
 Towards evaluating the robustness of neural networks,2017, In 2017IEEE Symposium on Security and Privacy (SP)
 On evaluating adversarialrobustness,2019, arXiv preprint arXiv:1902
 Unlabeleddata improves adversarial robustness,2019, In Advances in Neural Information Processing Systems
 Hopskipjumpattack: A query-efficientdecision-based attack,2020, In 2020 IEEE Symposium on Security and Privacy (SP)
 Stateful detection of black-box adversarial at-tacks,2019, arXiv preprint arXiv:1907
 Sign-opt: A query-efficient hard-label adversarial attack,2020, In International Conference on LearningRepresentations
 Certified adversarial robustness via randomizedsmoothing,2019, In Proceedings of the 36th International Conference on Machine Learning
 Imagenet: A large-scale hierarchicalimage database,2009, In 2009 IEEE Conference on Computer Vision and Pattern Recognition
 Adversarial examples are a natural consequenceof test error in noise,2019, In Proceedings of the 36th International Conference on Machine Learning
 Explaining and harnessing adversarialexamples,2015, In International Conference on Learning Representations
 Simpleblack-box adversarial attacks,2019, In Proceedings of the 36th International Conference on MachineLearning
 Using pre-training can improve model robustnessand uncertainty,2019, In Proceedings of the 36th International Conference on Machine Learning
 Puvae: A variationalautoencoder to purify adversarial examples,2019, IEEE Access
 Black-box adversarial attacks withlimited queries and information,2018, In Proceedings of the 35th International Conference on MachineLearning
 Learning multiple layers of features from tiny images,2009, Technical report
 Gradient-based learning applied to document recog-nition,1998, Proceedings of the IEEE
 Black-light: Defending black-box adversarial attacks on deep neural networks,2020, arXiv preprintarXiv:2006
 Magnet: a two-pronged defense against adversarial examples,2017, InProceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security
 Parsimonious black-box adversarial attacks viaefficient combinatorial optimization,2019, In Proceedings of the 36th International Conference onMachine Learning
 Practical black-box attacks against machine learning,2017, In Proceedings of the 2017 ACMon Asia Conference on Computer and Communications Security
 Adver-sarially robust generalization requires more data,2018, In Advances in Neural Information ProcessingSystems
 Using honeypotsto catch adversarial attacks on neural networks,2019, In Proceedings of ACM Conference on Computerand Communications Security (CCS)
 Very deep convolutional networks for large-scale imagerecognition,2015, In International Conference on Learning Representations
 One pixel attack for fooling deepneural networks,2019, IEEE Transactions on Evolutionary Computation
 Intriguing properties of neural networks,2014, In International Conference onLearning Representations
 Enhancing gradient-based attacks withsymbolic intervals,2019, In Proceedings of the 36th International Conference on Machine Learning
