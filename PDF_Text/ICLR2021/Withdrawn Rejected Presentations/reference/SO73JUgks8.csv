title,year,conference
 The lottery ticket hypothesis for pre-trained BERr networks,2020, CoRR
 BERT: pre-training of deepbidirectional transformers for language understanding,2018, CoRR
 Reducing transformer depth on demand withstructured dropout,2020, In ICLR
 ADC: automated deep compression and acceleration with reinforcementlearning,2018, CoRR
 SMART:robust and efficient fine-tuning for pre-trained natural language models through principled regu-larized optimization,2019, CoRR
 Mixout: Effective regularization to finetunelarge-scale pretrained language models,2020, In ICLR
 Multi-task deep neural networksfor natural language understanding,2019, In ACL
 Playing atari with deep reinforcement learning,2013, CoRR
 Sentence encoders on stilts: Supplementarytraining on intermediate labeled-data tasks,2018, CoRR
 Reinforcement Learning: An Introduction,0262, A BradfordBook
 Attention is all you need,2017, In NeurIPS
 Symmetric regularization based BERTfor pair-wise semantic reasoning,2020, In SIGIR
 Freelb: Enhancedadversarial training for natural language understanding,2020, In ICLR
