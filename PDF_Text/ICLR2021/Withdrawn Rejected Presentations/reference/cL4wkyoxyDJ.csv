title,year,conference
 Obfuscated gradients give a false sense ofsecurity: Circumventing defenses to adversarial examples,2018, International Conference on MachineLearning
 Adversarial examples are not easily detected: Bypassing tendetection methods,2017, In Proceedings of the 10th ACM Workshop on Artificial Intelligence andSecurity
 Bert: Pre-training of deepbidirectional transformers for language understanding,2018, arXiv preprint arXiv:1810
 Explaining and harnessing adversarialexamples,2015, International Conference on Learning Representations
 Countering adversar-ial images using input transformations,2018, International Conference on Learning Representations
 Adversarial machine learning at scale,2016, arXivpreprint arXiv:1611
 Interpolated adversarial training:Achieving robust neural networks without sacrificing too much accuracy,2019, In Proceedings of the12th ACM Workshop on Artificial Intelligence and Security
 To-wards deep learning models resistant to adversarial attacks,2018, International Conference on LearningRepresentations
 Mixup inference: Better exploiting mixup to defend adversarialattacks,2020, International Conference on Learning Representations
 Fully neural networkbased speech recognition on mobile and embedded devices,2018, In Advances in Neural InformationProcessing Systems
 Automatic differentiation inpytorch,2017, 2017
 Intriguing properties of neural networks,2014, International Conference on LearningRepresentations
 Exploring the space of adversarial images,2016, In 2016 InternationalJoint Conference on Neural Networks (IJCNN)
 Mitigating adversarialeffects through randomization,2018, International Conference on Learning Representations
 mixup: Beyond empiricalrisk minimization,2018, International Conference on Learning Representations
