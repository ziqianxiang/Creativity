title,year,conference
 Tensordecompositions for learning latent variable models,2014, J
 Approximation and estimation bounds for artificial neural networks,1994, Machinelearning
 On deep learning as a remedy for the curse of dimensionalityin nonparametric regression,2019, Ann
 A survey of model compression and accelerationfor deep neural networks,2017, arXiv preprint arXiv:1710
 Approximations by superpositions ofa sigmoidal function,1989, Math
 Restricted recurrent neural networks,2019, 2019 IEEE Conf
 Model selection techniques: An overview,2018, IEEE SignalProcess
 Learning one-hidden-layer neural networks with landscapedesign,2017, arXiv preprint arXiv:1711
 Size-independent sample complexity ofneural networks,2017, arXiv preprint arXiv:1712
 Deep Learning with Keras,2017, Packt Publishing Ltd
 Beating the perils of non-convexity: Guar-anteed training of neural networks using tensor methods,2015, arXiv preprint arXiv:1506
 Introduction to pytorch,2017, Deep learning with python
 Norm-based capacity control in neuralnetworks,2015, Conf
 On the consistency of ordinal regressionmethods,2017, J
 Group sparse regu-larization for deep neural networks,2017, Neurocomputing
 Nonparametric regression using deep neural networks with relu activationfunction,2017, arXiv preprint arXiv:1708
 Learning structured sparsity indeep neural networks,2016, Advance
 Information-theoretic determination of minimax rates of conver-gence,1999, Ann
 Understandingdeep learning requires rethinking generalization,2016, arXiv preprint arXiv:1611
 Loss functions for image restoration withneural networks,2016, IEEE Trans
 Heterogeneous feature selection with multi-modal deepneural networks and sparse group LASSO,2015, IEEE Trans
