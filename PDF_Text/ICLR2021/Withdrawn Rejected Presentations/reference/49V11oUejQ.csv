title,year,conference
 Sign bits are all you need for black-box attacks,2020, InICLR
 Understanding and improving fast adversarialtraining,2020, Advances in Neural Information Processing Systems
 Squareattack: a query-efficient black-box adversarial attack via random search,2019, arXiv preprintarXiv:1912
 Obfuscated gradients give a false sense ofsecurity: Circumventing defenses to adversarial examples,2018, In ICML
 Decision-based adversarial attacks: Reliableattacks against black-box machine learning models,2018, In ICLR
 Towards evaluating the robustness of neural networks,2017, In SP
 Unlabeleddata improves adversarial robustness,2019, In NeurIPS
 Rays: A ray searching method for hard-label adversarial attack,2020, InSIGKDD
 A frank-wolfe framework for efficientand effective adversarial attacks,2020, In AAAI
 Zoo: Zeroth order opti-mization based black-box attacks to deep neural networks without training substitute models,2017, InAISec
 Query-efficient hard-label black-box attack: An optimization-based approach,2019, In ICLR
 Sign-opt: A query-efficient hard-label adversarial attack,2020, In ICLR
 Certified adversarial robustness via randomizedsmoothing,2019, In ICML
 Minimally distorted adversarial examples with a fast adaptive boundaryattack,2020, In ICML
 Reliable evaluation of adversarial robustness with an ensembleof diverse parameter-free attacks,2020, In ICML
 Imagenet: A large-scalehierarchical image database,2009, In CVPR
 Stochastic activation pruning for robust adversarial de-fense,2018, ICLR
 Explaining and harnessing adversarialexamples,2015, ICLR
 Countering adversarialimages using input transformations,2018, ICLR
 Deep residual learning for image recog-nition,2016, In CVPR
 Using pre-training can improve model robustnessand uncertainty,2019, In ICML
 Black-box adversarial attacks with limited queries and information,2018, InICML
 Towards understanding fast adversarialtraining,2020, arXiv preprint arXiv:2006
 Characterizing adversarial subspaces usinglocal intrinsic dimensionality,2018, ICLR
 Mixed precisiontraining,2017, arXiv preprint arXiv:1710
 Parsimonious black-box adversarial attacks viaefficient combinatorial optimization,2019, In ICML
 Deepfool: a simple andaccurate method to fool deep neural networks,2016, In CVPR
 Adversarial robustness through locallinearization,2019, In NeurIPS
 Overfitting in adversarially robust deep learning,2020, ICML
 Provably robust deep learning via adversarially trained smoothed classifiers,2019, InNeurIPS
 Defense-gan: Protecting classifiers againstadversarial attacks using generative models,2018, ICLR
 Cyclical learning rates for training neural networks,2017, In WACV
 Pixeldefend:Leveraging generative models to understand and defend against adversarial examples,2018, ICLR
 Intriguing properties of neural networks,2013, arXiv preprint arXiv:1312
 Diversity can be transferred: Output diversificationfor white-and black-box attacks,2020, Advances in Neural Information Processing Systems
 On theconvergence and robustness of adversarial training,2019, In ICML
 Improvingadversarial robustness requires revisiting misclassified examples,2020, In ICLR
 Mitigating adversarialeffects through randomization,2018, ICLR
 Wide residual networks,2016, arXiv preprintarXiv:1605
