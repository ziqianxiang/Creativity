title,year,conference
 Block neural autoregressive flow,2019, In Conferenceon Uncertainty in Artificial Intelligence
 Dropout as a bayesian approximation: Representing modeluncertainty in deep learning,2016, In Maria Florina Balcan and Kilian Q
 Flow++: Improving flow-based generative models with variational dequantization and architecture design,2019, In KamalikaChaudhuri and Ruslan Salakhutdinov (eds
 Neural autore-gressive flows,2018, In Jennifer Dy and Andreas Krause (eds
 Lightgbm: A highly efficient gradient boosting decision tree,2017, In10Under review as a conference paper at ICLR 2021I
 Accurate uncertainties for deep learningusing calibrated regression,2018, In Jennifer Dy and Andreas Krause (eds
 Estimating the mean and variance of the target probabilitydistribution,1994, In Proceedings of 1994 ieee international conference on neural networks (ICNNâ€™94)
 Variational inference with normalizing flows,2015, In Francis Bachand David Blei (eds
