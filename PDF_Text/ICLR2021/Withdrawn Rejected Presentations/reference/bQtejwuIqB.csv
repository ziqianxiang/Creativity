title,year,conference
 Deep learning with differential privacy,2016, In Proceedings of the 2016 ACM SIGSACConference on Computer and Communications Security
 Federal automated vehicles policy: Acceler-ating the next revolution in roadway safety,2016, US Department of Transportation
 Obfuscated gradients give a false sense of se-curity: Circumventing defenses to adversarial examples,2018, In International Conference on MachineLearning (ICML)
 Mcity grand opening,2015, Research Review
 Towards evaluating the robustness of neural networks,2017, In 2017IEEE symposium on security and privacy (sp)
 On evaluating adversarialrobustness,2019, arXiv preprint arXiv:1902
 Provable tradeoffs in adver-sarially robust classification,2020, arXiv preprint arXiv:2006
 Boost-ing adversarial attacks with momentum,2018, In Proceedings of the IEEE conference on computervision and pattern recognition (CVPR)
 Adversarial examples that fool both computer vision andtime-limited humans,2018, In Advances in Neural Information Processing Systems (NeurIPS)
 Adversarial reprogramming ofneural networks,2019, In International Conference on Learning Representations (ICLR)
 Adversarial spheres,2018, arXiv preprint arXiv:1801
 Is attacking machine learning easier than defending it,2017, Blogpost on Feb
 Explaining and harnessing adversarialexamples,2015, In International Conference on Learning Representations (ICLR)
 Speech recognition with deep recur-rent neural networks,2013, In 2013 IEEE International Conference on Acoustics
 Delving deep into rectifiers: Surpassinghuman-level performance on imagenet classification,2015, In Proceedings of the IEEE InternationalConference on Computer Vision (ICCV)
 Deep residual learning for image recog-nition,2016, In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition(CVPR)
 Imagenet classification with deep con-volutional neural networks,2012, In Advances in neural information processing systems (NeurIPS)
 Adversarial examples in the physical world,2016, InInternational Conference on Learning Representations (ICLR) Workshops
 Gradient-based learning applied todocument recognition,1998, Proceedings of the IEEE
 Delving into transferable adversarial ex-amples and black-box attacks,2017, In International Conference on Learning Representations (ICLR)
 Human-levelcontrol through deep reinforcement learning,2015, nature
 Practical black-box attacks against machine learning,2017, In Proceedings of the 2017 ACMon Asia conference on computer and communications security (ASIA CCS)
 Overfitting in adversarially robust deep learning,2020, InInternational Conference on Machine Learning (ICML)
 Very deep convolutional networks for large-scale imagerecognition,2014, In International Conference on Learning Representations (ICLR)
 Intriguing properties of neural networks,2014, In International Conference onLearning Representations (ICLR)
 The spaceof transferable adversarial examples,2017, arXiv preprint arXiv:1704
 On adaptive attacks toadversarial example defenses,2020, arXiv preprint arXiv:2002
 Improvingadversarial robustness requires revisiting misclassified examples,2020, In International Conference onLearning Representations (ICLR)
 Skip connections matter:On the transferability of adversarial examples generated with resnets,2020, In International Conferenceon Learning Representations (ICLR)
 Defending against physically realizable attackson image classification,2020, In International Conference on Learning Representations (ICLR)
 Wide residual networks,2016, arXiv preprintarXiv:1605
 Towards adversarially robust object detection,2019, In Proceedings ofthe IEEE International Conference on Computer Vision (ICCV)
 Attacks which do not kill training make adversarial learning stronger,2020, In InternationalConference on Machine Learning (ICML)
 Improving the robustness of deepneural networks via stability training,2016, In Proceedings of the IEEE Conference on Computer Visionand Pattern Recognition (CVPR)
