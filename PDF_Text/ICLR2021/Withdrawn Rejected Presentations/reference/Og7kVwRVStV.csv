title,year,conference
 Obfuscated gradients give a false sense of se-curity: Circumventing defenses to adversarial examples,2018, In International Conference on MachineLearning
 Sgd learns over-parameterized networks that provably generalize on linearly separable data,2018, In InternationalConference on Learning Representations
 Towards evaluating the robustness of neural networks,2017, In 2017ieee symposium on security and privacy (sp)
 Speech recognition with deep recur-rent neural networks,2013, In 2013 IEEE international conference on acoustics
 The implicit bias of gradient descent on nonseparable data,2019, InConference on Learning Theory
 Imagenet classification with deep convo-lutional neural networks,2012, In Advances in neural information processing systems
 Learning overparameterized neural networks via stochastic gradientdescent on structured data,2018, In Advances in Neural Information Processing Systems
 Towards explaining the regularization effect ofinitial large learning rate in training neural networks,2019, In H
 Sgd on neural networks learns functions of increasing complexity,2019, arXivpreprint arXiv:1905
 Transferability in machine learning: fromphenomena to black-box attacks using adversarial samples,2016, arXiv preprint arXiv:1605
 Practical black-box attacks against machine learning,2017, In Proceedings of the 2017 ACMon Asia conference on computer and communications security
 Adver-sarially robust generalization requires more data,2018, In Advances in Neural Information ProcessingSystems
 Masteringthe game of go with deep neural networks and tree search,2016, nature
 Intriguing properties of neural networks,2013, arXiv preprint arXiv:1312
 80 million tiny images: A large data set fornonparametric object and scene recognition,2008, IEEE transactions on pattern analysis and machineintelligence
 The spaceof transferable adversarial examples,2017, arXiv preprint arXiv:1704
 Attention is all you need,2017, In Advances in neural informationprocessing systems
