title,year,conference
 Syntactically supervised transformers for fasterneural machine translation,2019, In Proceedings of the 57th Annual Meeting of the Association forComputational Linguistics 
 Neural machine translation by jointlylearning to align and translate,2015, In 3rd International Conference on Learning Representations
 Efficient 8-bit quantization of transformer neural machine language translationmodel,2019, arXiv preprint arXiv:1906
 Non-autoregressiveneural machine translation,2017, arXiv preprint arXiv:1711
 Levenshtein transformer,2019, In Advances in NeuralInformation Processing Systems
 Non-autoregressive neuralmachine translation with enhanced decoder input,2019, In Proceedings of the AAAI Conference onArtificial Intelligence
 Fine-tuning by curriculumlearning for non-autoregressive neural machine translation,2019, arXiv preprint arXiv:1911
 Jointly masked sequence-to-sequence model for non-autoregressive neural machine translation,2020, In Proceedings of the 58th Annual Meeting of theAssociation for Computational Linguistics
 Parallel machine translation withdisentangled context transformer,2020, In ICML 2020: 37th International Conference on MachineLearning
 Sequence-level knowledge distillation,2016, In Proceedings of the2016 Conference on Empirical Methods in Natural Language Processing
 Deterministic non-autoregressive neu-ral sequence modeling by iterative refinement,2018, In Proceedings of the 2018 Conferenceon Empirical Methods in Natural Language Processing
 Guiding non-autoregressive neural machine translationdecoding with reordering information,2019, arXiv preprint arXiv:1911
 Retrievingsequential information for non-autoregressive neural machine translation,2019, In Proceedings of the57th Annual Meeting of the Association for Computational Linguistics
 Self-attention with relative position representa-tions,2018, In Proceedings of the 2018 Conference of the North American Chapter of the Associationfor Computational Linguistics: Human Language Technologies
 Fast structureddecoding for sequence models,2019, In Advances in Neural Information Processing Systems
 Semi-autoregressive neural machine translation,2018, InProceedings of the 2018 Conference on Empirical Methods in Natural Language Processing
 Multi-layer represen-tation fusion for neural machine translation,2018, In Proceedings of the 27th International Conferenceon Computational Linguistics
 Non-autoregressivemachine translation with auxiliary regularization,2019, In Proceedings of the AAAI Conference onArtificial Intelligence
 Accelerating neural transformer via an average atten-tion network,2018, In Proceedings of the 56th Annual Meeting of the Association for ComputationalLinguistics (Volume 1: Long Papers)
 Speeding up neural machine trans-lation decoding by cube pruning,2018, Proceedings of EMNLP 2018
 Exploring recombina-tion for efficient decoding of neural machine translation,2018, In Proceedings of the 2018 Conferenceon Empirical Methods in Natural Language Processing
 Understanding knowledge distillation in non-autoregressive machine translation,2020, In ICLR 2020 : Eighth International Conference on LearningRepresentations
