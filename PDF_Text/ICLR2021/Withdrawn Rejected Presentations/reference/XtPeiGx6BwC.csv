title,year,conference
 Adversarial deep learningfor robust detection of binary encoded malware,2018, In2018 IEEE Security and Privacy Workshops(SPW)
 Anti-proguard: Towards automated deobfus-cation of android apps,2017, InProceedings of the 4th Workshop on Security in Highly Connected ITSystems
 Unrestricted adversarialexamples via semantic manipulation,2019,arXiv preprint arXiv:1904
 Statistical deobfuscationof android applications,2016, InProceedings of the 2016 ACM SIGSAC Conference on Computer andCommunications Security
 Towards evaluating the robustness of neural networks,2017, In2017IEEE Symposium on Security and Privacy (SP)
 Deobfuscation of virtualization-obfuscated software:A semantics-based approach,2011, InProceedings of the 18th ACM Conference on Computer andCommunications Security
 Hotflip: White-box adversarial exam-ples for text classification,2018, InProceedings of the 56th Annual Meeting of the Association forComputational Linguistics (Volume 2: Short Papers)
 Robust physical-world attacks on deep learningvisual classification,2018, InProceedings of the IEEE Conference on Computer Vision and PatternRecognition
 Explaining and harnessing adversarialexamples,2014,arXiv preprint arXiv:1412
 Deep residual learning for image recognition,2016, In2016 IEEEConference on Computer Vision and Pattern Recognition (CVPR)
 Semantic adversarial examples,2018, InProceedings of theIEEE Conference on Computer Vision and Pattern Recognition Workshops
 On the limitation ofconvolutional neural networks in recognizing negative images,2017, In2017 16th IEEE InternationalConference on Machine Learning and APPlications (ICMLA)
 Achieving verified robustness to symbol substitutions viainterval bound propagation,2019, pp
 Reluplex: An efficient smt solverfor verifying deep neural networks,2017, InInternational Conference on ComPuter Aided Verification
Digital Color Image Processing,2008, Wiley
 Learning multiple layers of features from tiny images,2009, 2009
 Deepfool: a simple andaccurate method to fool deep neural networks,2016, InProceedings of the IEEE conference on comPutervision and Pattern recognition
 Practical black-box attacks against machine learning,2017, InProceedings of the 2017 ACM onAsia conference on comPuter and communications security
 Intriguing propertiesof adversarial ml attacks in the problem space,2020, In2020 IEEE SymPosium on Security and Privacy(SP)
 Why should i trust you?: Explaining thepredictions of any classifier,2016, InProceedings of the 22nd ACM SIGKDD international conferenceon knowledge discovery and data mining
 Generic black-box end-to-end attackagainst state of the art api call based malware classifiers,2018, InInternational SymPosium on Researchin Attacks
 Defense methods against adversarialexamples for recurrent neural networks,2019,arXiv preprint arXiv:1901
 Metadata recovery from obfuscated programs using machinelearning,2016, InProceedings of the 6th Workshop on Software Security
 Intriguing properties of neural networks,2013,arXiv preprint arXiv:1312
 Feature squeezing: Detecting adversarial examples in deepneural networks,2017,arXiv preprint arXiv:1704
 Invariance-inducing regularization usingworst-case transformations suffices to boost accuracy and spatial robustness,2019, InAdvances in NeuralInformation Processing Systems
