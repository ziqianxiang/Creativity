title,year,conference
 Task2vec: Task embedding for meta-learning,2019, InProceedings of the International Conference on Computer Vision
 Enriching word vectorswith subword information,2017, In Transactions of the Association for Computational Linguistics
 Learning to rank using gradient descent,2005, In Proceedings of International Conference onMachine Learning
 Un-supervised cross-lingual representation learning at scale,2019, In Proceedings of the Association forComputational Linguistics
 BERT: Pre-training of deepbidirectional transformers for langUage Understanding,2019, In Proceedings of the Conference of theNorth American Chapter of the Association for Computational Linguistics: Human LanguageTechnologies
 Model-agnostic meta-learning for fast adaptationof deep networks,2017, In Proceedings of International Conference on Machine Learning
 Deep sparse rectifier neural networks,2011, InProceedings of Artificial Intelligence and Statistics
 The stateand fate of linguistic diversity and inclusion in the nlp world,2020, arXiv preprint arXiv:2004
 A new measure of rank correlation,1938, Biometrika
 On the evaluation of contextualembeddings for zero-shot cross-lingual transfer learning,2020, arXiv preprint arXiv:2004
 Adam: A method for stochastic optimization,2015, In Proceedings ofInternational Conference on Learning Representation
 From zero to hero: On thelimitations of zero-shot language transfer with multilingual Transformers,2020, In Proceedings ofthe 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)
 The third international chinese language Processing bakeoff: Word segmenta-tion and named entity recognition,2006, In Proceedings of the Fifth SIGHAN Workshop on ChineseLanguage Processing
 Learning language representations fortypology prediction,2017, In Proceedings of Empirical Methods in Natural Language Processing
 Exploiting similarities among languages for ma-chine translation,2013, arXiv preprint arXiv:1309
 UniversalDependencies 1,2016,4
 Zero-shotcross-lingual transfer with meta learning,2020, arXiv preprint arXiv:2003
 Deep contextualized word representations,2018, In Proceedings of the Conference ofthe North American Chapter of the Association for Computational Linguistics: Human LanguageTechnologies
 Meta-learning with im-plicit gradients,2019, In Proceedings of Advances in Neural Information Processing Systems
 Attention is all you need,2017, In Proceedings of Advancesin Neural Information Processing Systems
 Pre-dicting performance for natural language processing tasks,2020, In Proceedings of the Association forComputational Linguistics
 Exploiting entity BIO tagembeddings and multi-task learning for relation extraction with imbalanced data,2019, In Proceedingsof the Association for Computational Linguistics
