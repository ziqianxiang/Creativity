title,year,conference
 Towards characterizing divergence in deepQ-learning,2019, arXiv preprint arXiv:1903
 An optimistic perspective on offlinereinforcement learning,2019, 2019a
 Striving for simplicity in off-policydeep reinforcement learning,2019, Preprint arXiv:1907
 Distributed distributional deterministicpolicy gradients,2018, In International Conference on Learning Representations
 Deepmind lab,2016, arXiv preprintarXiv:1612
 A distributional perspective on reinforcementlearning,2017, In International Conference on Machine Learning
 DotA 2 with large scaledeep reinforcement learning,2019, arXiv preprint arXiv:1912
 Learning to rank using gradient descent,2005, In Proceedings of the 22nd internationalconference on Machine learning
 Ranking measures and lossfunctions in learning to rank,2009, In Advances in Neural Information Processing Systems
 D4RL: Datasets for deepdata-driven reinforcement learning,2020, arXiv preprint arXiv:2004
 Addressing function approximation error inactor-critic methods,2018, arXiv preprint arXiv:1802
 Benchmarking batchdeep reinforcement learning algorithms,2019, Preprint arXiv:1910
 Off-policy deep reinforcement learning withoutexploration,2019, In International Conference on Machine Learning
 EMaQ: Expected-Max Q-Learning operator for simple yet effective offline and online RL,2020, arXiv preprintarXiv:2007
 Improving thegating mechanism of recurrent neural networks,2019, arXiv preprint arXiv:1910
 RL unplugged:Benchmarks for offline reinforcement learning,2020, arXiv preprint arXiv:2006
 Soft actor-critic: Off-policy maxi-mum entropy deep reinforcement learning with a stochastic actor,2018, arXiv preprint arXiv:1801
 Rainbow: Combining improvements indeep reinforcement learning,2017, arXiv preprint arXiv:1710
 Acme: A research framework for distributedreinforcement learning,2020, arXiv preprint arXiv:2006
 Recurrentexperience replay in distributed reinforcement learning,2019, In International Conference on LearningRepresentations
 Adam: A method for stochastic optimization,2014, In InternationalConference on Learning Representations
 Stabilizing off-policyQ-learning via bootstrapping error reduction,2019, In Conference on Neural Information ProcessingSystems
 Conservative q-learning for offlinereinforcement learning,2020, arXiv preprint arXiv:2006
 Continuous control with deep reinforcement learning,2015, PreprintarXiv:1509
 Ranking policy gradient,2020, In 8th International Conference on LearningRepresentations
 Reinforcement learning of motor skills with policy gradients,2008, Neuralnetworks
 Observe and look further:Achieving consistent performance on Atari,2018, arXiv preprint arXiv:1805
 Prioritized experience replay,2015, arXivpreprint arXiv:1511
 A possibility for implementing curiosity and boredom in model-building neuralcontrollers,1991, In Proc
 Keep doing what worked:Behavior modelling priors for offline reinforcement learning,2020, In International Conference onLearning Representations
 Mastering the game of go withouthuman knowledge,2017, nature
 Conqur: Mitigating delusionalbias in deep q-learning,2020, arXiv preprint arXiv:2002
 Reinforcement learning: An introduction,2018, MIT press
 Deep reinforcement learning with double q-learning,2015, arXiv preprint arXiv:1509
 Deep reinforcement learning and the deadly triad,2018, arXiv preprint arXiv:1812
 A theoretical andempirical analysis of expected SARSA,2009, In 2009 ieee symposium on adaptive dynamic programmingand reinforcement learning
 Grandmaster level instarcraft ii using multi-agent reinforcement learning,2019, Nature
 Critic regularizedregression,2020, arXiv preprint arXiv:2006
 Simple statistical gradient-following algorithms for connectionist reinforcementlearning,1992, Machine learning
997 every 400 updates 0,2019,48 0
