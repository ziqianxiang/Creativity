title,year,conference
 Square attack:a query-efficient black-box adversarial attack via random search,2019, arXiv:1912
 Obfuscated gradients give a false sense ofsecurity: Circumventing defenses to adversarial examples,2018, In ICML
 Unlabeled dataimproves adversarial robustness,2019, In NeurIPS
 Jacobian adversarially regularized networks forrobustness,2020, In ICLR
 A frank-wolfe framework for efficientand effective adversarial attacks,2018, arXiv preprint arXiv:1811
 Ead: elastic-net attacks todeep neural networks via adversarial examples,2018, In AAAI
 Minimally distorted adversarial examples with a fast adaptiveboundary attack,2019, arXiv:1907
 Reliable evaluation of adversarial robustness with an ensembleof diverse parameter-free attacks,2020, arXiv:2003
 Compression to the rescue: Defending from adversarial attacksacross modalities,2018, In KDD
 Boostingadversarial attacks with momentum,2018, In CVPR
 Evaluating and understanding the robustness ofadversarial logit pairing,2018, arXiv preprint arXiv:1807
 Explaining and harnessing adversarialexamples,2015, In ICLR
 Towards deep neural network architectures robust to adversarialexamples,2014, arXiv preprint arXiv:1412
 Countering adversarialimages using input transformations,2018, In ICLR
 Decision boundary analysis of adversarial examples,2018, In ICLR
 Using pre-training can improve model robustnessand uncertainty,2019, In ICML
 Adversarial machine learning at scale,2017, ICLR
 Defense againstadversarial attacks using high-level representation guided denoiser,2018, In CVPR
 Security analysis and en-hancement of model compressed deep learning systems under adversarial attacks,2018, In ASPDAC
 Characterizing adversarial subspaces using localintrinsic dimensionality,2018, In ICLR
 Logit pairing methods can fool gradient-based attacks,2018, arXiv preprint arXiv:1810
 Practical black-box attacks against machine learning,2017, In Asia CCS
 Defend deep neural networksagainst adversarial examples via fixed and dynamic quantized activation functions,2018, arXiv preprintarXiv:1807
 Overfitting in adversarially robust deep learning,2020, arXivpreprint arXiv:2002
 Improving the adversarial robustness and interpretabilityof deep neural networks by regularizing their input gradients,2018, In AAAI
 Defense-GAN: Protecting classifiersagainst adversarial attacks using generative models,2018, In ICLR
 On the importance of initializationand momentum in deep learning,2013, In ICML
 Intriguing properties of neural networks,2014, In ICLR
 Output diversified initialization for adversarialattacks,2020, arXiv:2003
 Ensemble adversarial training: Attacks and defenses,2018, In ICLR
 Ensemble adversarial training: Attacks and defenses,2018, In ICLR
 Bilateral adversarial training: Towards fast training of more robustmodels against adversarial attacks,2019, In ICCV
 On theconvergence and robustness of adversarial training,2019, In ICML
 Improvingadversarial robustness requires revisiting misclassified examples,2020, In ICLR
 Feature squeezing: Detecting adversarial examples in deepneural networks,2017, arXiv preprint arXiv:1704
 Wide residual networks,2016, In BMVC
 Defense against adversarial attacks using feature scattering-basedadversarial training,2019, In NeurIPS
 Distributionally adversarial attack,2019, In AAAI
 Increasing distortion bound does not increasesuccess,2021, Larger distortion bound gives the attacker more ability to attack
