title,year,conference
 Proxylessnas: Direct neural architecture search on target taskand hardware,2018, arXiv preprint arXiv:1812
 Xception: Deep learning with depthwise separable convolutions,2017, In Proceedings ofthe IEEE conference on computer vision and pattern recognition
 Compressing neural networks using the variational informationbottleneck,2018, arXiv preprint arXiv:1802
 Exploiting linearstructure within convolutional networks for efficient evaluation,2014, In Advances in Neural InformationProcessing Systems 27: Annual Conference on Neural Information Processing Systems 2014
 SYQ: learning symmetricquantization for efficient deep neural networks,2018, In 2018 IEEE Conference on Computer Visionand Pattern Recognition
 Optimal brain surgeon: Extensions andperformance comparison,1993, In Advances in Neural Information Processing Systems 6
 Deep residual learning for imagerecognition,2016, In 2016 IEEE Conference on Computer Vision and Pattern Recognition
 Norm matters: efficient and accuratenormalization schemes in deep networks,2018, In Samy Bengio
 Squeeze-and-excitation networks,2018, In Proceedings of the IEEEconference on computer vision and pattern recognition
 Batch normalization: Accelerating deep network training byreducing internal covariate shift,2015, In Proceedings of the 32nd International Conference on MachineLearning
 Quantization and training of neural networks for efficientinteger-arithmetic-only inference,2018, In The IEEE Conference on Computer Vision and PatternRecognition (CVPR)
 Speeding up convolutional neural networkswith low rank expansions,2014, In British Machine Vision Conference
 Imagenet classification with deep convolu-tional neural networks,2017, Commun
 Optimal brain damage,1989, In Advances in NeuralInformation Processing Systems 2
 Pruning filters forefficient convnets,2017, In 5th International Conference on Learning Representations
 Bayesian compression for deep learning,2017, InI
 Learning sparse neural networks throughl0 regularization,2018, In International Conference on Learning Representations
 Exploringthe granularity of sparsity in convolutional neural networks,2017, In 2017 IEEE Conference on ComputerVision and Pattern Recognition Workshops
 Variational dropout sparsifies deepneural networks,2017, In Proceedings of the 34th International Conference on Machine Learning
 Standardizing evaluation of neuralnetwork pruning,2019, In Workshop on AI Systems at SOSP
 Mo-bilenetv2: Inverted residuals and linear bottlenecks,2018, In The IEEE Conference on Computer Visionand Pattern Recognition (CVPR)
 Training sparse neural networks,2017, In2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops
 Efficientnet: Rethinking model scaling for convolutional neuralnetworks,2019, arXiv preprint arXiv:1905
 Mixconv: Mixed depthwise convolutional kernels,2019, CoRR
 Fbnet: Hardware-aware efficient convnet design viadifferentiable neural architecture search,2019, In Proceedings of the IEEE Conference on ComputerVision and Pattern Recognition
 Accelerating very deep convolutionalnetworks for classification and detection,2016, IEEE transactions on pattern analysis and machineintelligence
