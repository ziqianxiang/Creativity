title,year,conference
 Learning to learn by gradient descent by gradientdescent,2016, In Advances in neural information processing systems
 Designing neural network architectures usingreinforcement learning,2017, ArXiv
 Invariant scattering convolution networks,2013, IEEE Transactions onPattern Analysis and Machine Intelligence
 Neural ordinary differ-ential equations,2018, In Advances in Neural Information Processing Systems
 Xception: Deep learning with depthwise separable convolutions,2017, In 2017 IEEEConference on Computer Vision and Pattern Recognition (CVPR)
 Group equivariant convolutional networks,2016,	CoRR
 Arotation and a translation suffice: Fooling CNNs with simple transformations,2017, arXiv preprintarXiv:1712
 Learning fast approximations of sparse coding,2010, In Proceedings of the27th International Conference on International Conference on Machine Learning
 Deep residual learning for image recog-nition,2016, In IEEE conference on computer vision and pattern recognition
 Transforming auto-encoders,2011, In ICANN
 Long short-term memory,1997, Neural computation
 Densely connectedconvolutional networks,2017, In 2017 IEEE Conference on Computer Vision and Pattern Recognition(CVPR)
 Accelerated gradient descent escapes saddlepoints faster than gradient descent,2018, In Sebastien Bubeck
 On circulant matrices,2012, Notices of the American MathematicalSociety
 Imagenet classification with deep convo-lutional neural networks,2012, In Advances in neural information processing systems
 Fast algorithms for convolutional neural networks,2016, In Proceedingsof the IEEE Conference on Computer Vision and Pattern Recognition
 Segmentation of multivariate mixed datavia lossy data coding and compression,2007, IEEE transactions on pattern analysis and machineintelligence
 A nonconvex approach for exact and efficient multichannelsparse blind deconvolution,2019, In Advances in Neural Information Processing Systems
 The singular values of convolutional layers,2018, arXivpreprint arXiv:1805
 Outrageously large neural networks: The sparsely-gated mixture-of-experts layer,2017, InICLR
 Very deep convolutional networks for large-scale imagerecognition,2015, In ICLR
 Multilayer convolutional sparsemodeling: Pursuit and dictionary learning,2018, IEEE Transactions on Signal Processing
 Supervised deep sparse coding networks forimage classification,2020, IEEE Transactions on Image Processing
 Interpretable recurrent neural networksusing sequential sparse recovery,2016, ArXiv
 Aggregated residual trans-formations for deep neural networks,2017, In 2017 IEEE Conference on Computer Vision and PatternRecognition (CVPR)
 Rethinking bias-variancetrade-off for generalization of neural networks,2020, In International Conference on Machine Learning(ICML)
 Learning diverse anddiscriminative representations via the principle of maximal coding rate reduction,2020, arXiv preprintarXiv:2006
 Deep sets,2017, In I
 Understandingdeep learning requires rethinking generalization,2017, 2017
 Neural architecture search with reinforcement learning,2017, 2017
 There are 3 classes in iris dataset and the number of features is 4,2011, For micedataset
