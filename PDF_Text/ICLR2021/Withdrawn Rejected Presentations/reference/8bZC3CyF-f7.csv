title,year,conference
 RUDDER: return decomposition for delayed rewards,2019, In Advances in Neural InformationProcessing Systems 32
 PROSITE: recent developments,1994, Nucleic acids research
 Successorfeatures for transfer in reinforcement learning,1606, In Advances in Neural Information ProcessingSystems 30
 Robot programming by demonstration,2008, InB
 Reinforcementlearning from demonstration through shaping,2015, In Proc
 Sequence comparison: theory and methods,2009, Springer
 Biopython: freely available Python tools forcomputational molecular biology and bioinformatics,2009, Bioinformatics
 Optimal policy switching algorithms for reinforcement learning,2010, InProceedings of the International Joint Conference on Autonomous Agents and Multiagent Systems(AAMAS)
 Multiple sequence alignment with hierarchical clustering,1988, Nucleic Acids Research
 Probabilistic inference for determining options inreinforcement learning,2016, Machine Learning
 Go-Explore: A new approach forhard-exploration problems,2019, arXiv
 One-shot visual imitation learning via meta-learning,2017, In 1st Annual Conference on Robot Learning (CoRL)
 Meta learning shared hierarchies,1710, InInternational Conference on Learning Representations
 The MineRL competition on sample efficientreinforcement learning using human priors,2019, arXiv
 MineRL:A large-scale dataset of Minecraft demonstrations,2019, In Proc
 Soft actor-critic: Off-policy maximum entropydeep reinforcement learning with a stochastic actor,1801, In J
 Amino acid substitution matrices from protein blocks,1992, Proceedingsof the National Academy of Sciences of the United States of America
 Rainbow: Combining improvements in deep reinforcement learning,2017, ArXiv
 Learning from demonstrations for real worldreinforcement learning,2017, ArXiv
 Generative adversarial imitation learning,2016, In Advances in Neural InformationProcessing Systems 29
 Long short-term memory,1997, Neural Comput
 Playing Atari games with deep reinforcement learning and humancheckpoint replay,2016, ArXiv
 Reinforcement learning fromimperfect demonstrations under soft expert guidance,2019, ArXiv
 Active imitation learning: Formal and practicalreductions to i,1532,i
 Approximately optimal approximate reinforcement learning,2002, In 19thInternational Conference on Machine Learning (ICML)
 Methods for assessing the statistical significance of molecular sequencefeatures by using general scoring schemes,1990, Proceedings of the National Academy of Sciences ofthe United States of America
 Statistical composition of high-scoring segments frommolecular sequences,1990, Ann
 Learning to take actions,1999, Machine Learning
 Learning from limited demonstrations,2013, In Advancesin Neural Information Processing Systems 26
 Hierarchical deep reinforcementlearning: Integrating temporal abstraction and intrinsic motivation,2016, In D
 Reinforcement learning with few expert demon-strations,2016, In NIPS Workshop on Deep Learning for Action and Interaction
 Eigenoption discoverythrough the deep successor representation,2017, arXiv
 DIALIGN: Multiple DNA and protein sequence alignment at BiBiServ,2004, NucleicAcids Research
 Overcoming exploration inreinforcement learning with demonstrations,2018, In 2018 IEEE International Conference on Roboticsand Automation
 Algorithms for inverse reinforcement learning,2000, In Proceedings ofthe Seventeenth International Conference on Machine Learning
 Efficient training of artificial neural networks for autonomous navigation,0899, NeuralComput
 Effects of feedback delay on learning,2009, SystemDynamics Review
 Learningcomplex dexterous manipulation with deep reinforcement learning and demonstrations,2018, In Robotics:Science and Systems XIV
 Successor options: An option discovery framework forreinforcement learning,2019, In Proc
 Experience replay for continuallearning,2019, In Advances in Neural Information Processing Systems 32
 Efficient reductions for imitation learning,2010, In Proceedings of the ThirteenthInternational Conference on Artificial Intelligence and Statistics
 Learning from demonstration,1996, In Proceedings of the 9th International Conference onNeural Information Processing Systems (NIPS’96)
 Sample efficient reinforcement learning through learning fromdemonstrations in Minecraft,2020, In H
 Proximal policy optimizationalgorithms,2018, ArXiv
 Compositional planning using optimal option models,1206, In Proceedings of the29th International Conference on Machine Learning (ICML)
 Masteringthe game of Go with deep neural networks and tree search,2016, Nature
 Mastering Chess and Shogi byself-play with a general reinforcement learning algorithm,2017, ArXiv
 Hierarchical deepq-network with forgetting from imperfect demonstrations in Minecraft,2019, arXiv
 Learning options in reinforcement learning,2002, In Lecture Notes in ComputerScience
 Use of the ’Perceptron’ algorithm todistinguish translational initiation sites in E,1982, coli
 Reinforcement Learning: An Introduction,2018, MIT Press
 A game-theoretic approach to apprenticeship learning,2007, In Advances inNeural Information Processing Systems 20
 Integrating reinforcement learning with human demonstra-tions of varying ability,2011, In 10th International Conference on Autonomous Agents and MultiagentSystems (AAMAS 2011)
 Inverse reinforcement learning for video games,2018, arXiv
 Leveraging demonstrations for deep reinforcement learning on roboticsproblems with sparse rewards,2017, ArXiv
 Learning from Delayed Rewards,1989, PhD thesis
 Pretraining deep actor-critic reinforcement learning algorithms with expertdemonstrations,2018, ArXiv
 MELD: Meta-reinforcement learningfrom images via latent state models,2020, arXiv
 To deal with long trajectories they rely on a trainable special form of frame skippingwhere the agent also has to predict how many frames to skip in each situation,2020, This helps to reducethe effective length (step count) of the respective expert trajectories
