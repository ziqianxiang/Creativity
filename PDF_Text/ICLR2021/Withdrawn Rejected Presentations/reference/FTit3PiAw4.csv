title,year,conference
 Qsgd: Communication-efficient sgd via gradient quantization and encoding,2017, In Advances in Neural Information ProcessingSystems 
 Wasserstein gan,2017, arXiv preprintarXiv:1701
 Convex optimization,2004, Cambridge university press
 Information theory and statistics: A tutorial,2004, Foundations andTrendsR in Communications and Information Theory
 Good semi-supervised learning that requires a bad gan,2017, In Advances in neural information processing systems
 Md-gan: Multi-discriminator generativeadversarial networks for distributed datasets,2019, In 2019 IEEE International Parallel and DistributedProcessing Symposium (IPDPS)
 Deep residual learning for imagerecognition,2016, In Proceedings of the IEEE conference on computer vision and pattern recognition
 Deep Residual Learning for ImageRecognition,2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)
 Ganstrained by a two time-scale update rule converge to a local nash equilibrium,2017, In Advances in neuralinformation processing systems
 Advancesand open problems in federated learning,2019, arXiv preprint arXiv:1912
 Federated learning: Strategies for improving communication efficiency,2016, arXivpreprint arXiv:1610
 Semi-supervised learning with gans: Mani-fold invariance with improved inference,2017, In Advances in Neural Information Processing Systems
 Gradient-based learning applied todocument recognition,1998, Proceedings of the IEEE
 Communication efficient decentralizedtraining with multiple local updates,2019, arXiv preprint arXiv:1910
 On the convergence offedavg on non-iid data,2020, In International Conference on Learning Representations
 Can decentralizedalgorithms outperform centralized algorithms? a case study for decentralized parallel stochasticgradient descent,2017, In Advances in Neural Information Processing Systems
 Divergence measures based on the shannon entropy,1991, IEEE Transactions on Informationtheory
 A two-step computation of the exact GANWasserstein distance,2018, In Proceedings of the International Conference on Machine Learning
 Wasserstein gan with quadratic transport cost,2019, InThe IEEE International Conference on Computer Vision (ICCV)
 Communication-efficientlearning of deep networks from decentralized data,2016, arXiv preprint arXiv:1602
 Conditional generative adversarial nets,2014, arXiv preprintarXiv:1411
 Spectral normalizationfor generative adversarial networks,2018, In Proceedings of the International Conference on LearningRepresentations
 Learn distributedgan with temporary discriminators,2020, arXiv preprint arXiv:2007
 Hogwild: A lock-free approach toparallelizing stochastic gradient descent,2011, In Advances in neural information processing systems
 Cloud computing and trans-border health data: Unpackingus and eu healthcare regulation and compliance,2013, Health policy and technology
 Singan: Learning a generative model from asingle natural image,2019, In Proceedings of the IEEE International Conference on Computer Vision
 Very deep convolutional networks for large-scale imagerecognition,2014, arXiv preprint arXiv:1409
 Federated multi-tasklearning,2017, In Advances in Neural Information Processing Systems
 Improving generalization and stabilityof generative adversarial networks,2019, In Proceedings of the International Conference on LearningRepresentations
 Federated learning with differential privacy: Algorithms and performanceanalysis,2020, IEEE Transactions on Information Forensics and Security
 Fashion-mnist: a novel image dataset for benchmarkingmachine learning algorithms,2017, arXiv preprint arXiv:1708
 Federated machine learning: Concept andapplications,2019, ACM Transactions on Intelligent Systems and Technology (TIST)
 On the linear speedup analysis of communication efficientmomentum sgd for distributed non-convex optimization,2019, In International Conference on MachineLearning
 Metagan: Anadversarial approach to few-shot learning,2018, In Advances in Neural Information Processing Systems
 Federatedlearning with non-iid data,2018, arXiv preprint arXiv:1806
 Deep leakage from gradients,2019, In Advances in NeuralInformation Processing Systems 32
