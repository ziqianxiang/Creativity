title,year,conference
 Maximum a posteriori policy optimisation,2018, arXiv preprint arXiv:1806
 State abstraction as compression in apprenticeship learning,2019, In Proceedings of the AAAIConference on Artificial Intelligence
 Deep variational informationbottleneck,2016, arXiv preprint arXiv:1612
 Mine: mutual information neural estimation,2018, arXiv preprintarXiv:1801
 Reward constrained policy optimization,2018, arXivpreprint arXiv:1805
 Learning to draw samples with amortized stein variationalgradient descent,2017, arXiv preprint arXiv:1707
 Soft q-learning with mutual-informationregularization,2019, In International Conference on Learning Representations
 Reinforcement learning with deepenergy-based policies,2017, Proceedings of the 34th International Conference on Machine Learning
 Learning deep representations by mutual information estimationand maximization,2019, In International Conference on Learning Representations
 Generalization in reinforcement learning with selective noise injection andinformation bottleneck,2019, In Advances in Neural Information Processing Systems
 Emi:Exploration with mutual information,2018, arXiv preprint arXiv:1810
 A reward-maximizing spiking neuron as a bounded rationaldecision maker,2015, Neural computation
 Mutual-information regularization in markov decision pro-cesses and actor-critic learning,2019, arXiv preprint arXiv:1909
 Stein variational gradient descent: A general purpose bayesian inferencealgorithm,2016, In Advances in neural information processing systems
 Stein variational policy gradient,2017, arXivpreprint arXiv:1704
 Representation learning with contrastive predictivecoding,2018, arXiv preprint arXiv:1807
 ProXimal policyoptimization algorithms,2017, arXiv preprint arXiv:1707
 Understanding the limitations of variational mutual informationestimators,2019, arXiv preprint arXiv:1910
 An information-theoretic approach to curiosity-driven reinforcementlearning,2012, Theory in Biosciences
 Learningefficient multi-agent communication: An information bottleneck approach,2019, arXiv preprintarXiv:1911
