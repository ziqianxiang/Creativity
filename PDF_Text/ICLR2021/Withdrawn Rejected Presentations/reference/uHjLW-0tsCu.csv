title,year,conference
 Scalable methods for 8-bit training ofneural networks,2018, In NeurIPS
 Post training 4-bit quantization of convolutionalnetworks for rapid-deployment,2018, In NeurIPS
 Imagenet: A large-scalehierarchical image database,2009, In 2009 IEEE conference on computer vision and pattern recognition
 Hawq: Hessian awarequantization of neural networks with mixed-precision,2019, ArXiv
 Deep learning withlimited numerical precision,2015, In ICML
 Deep residual learning for imagerecognition,2016, In Proceedings of the IEEE conference on computer vision and pattern recognition
 The ieee standard 754: One for the history books,2019, Computer
 gemmlowp: a small self-contained low-precision gemm library,2017,(2017)
 Flexpoint: An adaptive numerical format for efficient training of deep neural networks,2017, InNIPS
 Convolutional deep belief networks on cifar-10,2010, 2010
 Imagenet classification with deep convo-lutional neural networks,2012, In F
 Fixed point quantization of deepconvolutional networks,2015, ArXiv
 Ssd: Single shot multibox detector,2016, In European conference on computer vision
 Reactnet: Towards precise binary neural networkwith generalized activation functions,2020, ArXiv
 Mixed precision trainingwith 8-bit floating point,2019, ArXiv
 Weighted-entropy-based quantization for deepneural networks,2017, 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)
 Ir-net:Forward and backward information retention for highly accurate binary neural networks,2019, ArXiv
 Xnor-net: Imagenetclassification using binary convolutional neural networks,2016, In ECCV
 Very deep convolutional networks for large-scale imagerecognition,2014, arXiv preprint arXiv:1409
 Trainingdeep neural networks with 8-bit floating point numbers,2018, In NeurIPS
 Training and inference with integers in deepneural networks,2018, ArXiv
 Dorefa-net: Traininglow bitwidth convolutional neural networks with low bitwidth gradients,2016, ArXiv
