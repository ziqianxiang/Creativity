title,year,conference
 Learning to learn by gradient descent by gradientdescent,2016, In NeurIPS
 There are many con-sistent explanations of unlabeled data: Why you should average,2019, 2019
 Learning with pseudo-ensembles,2014, In NeurIPS
 11 label propagation and quadratic crite-rion,2006, 2006
 Mixmatch: A holistic approach to semi-supervised learning,2019, In NeurIPS
 Remixmatch: Semi-supervised learning with distribution alignment and augmenta-tion anchoring,2020, In ICLR
 Nonlinear programming,1997, Athena Scientific
 Semi-Supervised Learning,2006, Adaptive computation andmachine learning
 An analysis of single-layer networks in unsupervisedfeature learning,2011, In AISTATS
 Semi-supervised learning with context-conditionalgenerative adversarial networks,2016, arXiv preprint arXiv:1611
 Model-agnostic meta-learning for fast adaptationof deep networks,2017, In ICML
 Semi-supervised learning by entropy minimization,2005, InNeurIPS
 Deep residual learning for image recog-nition,2016, In CVPR
 Convo-lutional networks with dense connectivity,2019, IEEE transactions on pattern analysis and machineintelligence
 Transductive inference for text classification using support vector machines,1999, InICML
 Transductive learning via spectral graph partitioning,2003, In AAAI
 Imagenet classification with deep convo-Iutional neural networks,2012, In NeurIPS
 Temporal ensembling for semi-supervised learning,2016, arXiv preprintarXiv:1610
 Buildingmachines that learn and think like people,2017, Behavioral and brain sciences
 Deep learning,2015, nature
 Sgdr: Stochastic gradient descent with warm restarts,2016, arXivpreprint arXiv:1608
 Smooth neighbors on teacher graphsfor semi-supervised learning,2018, In CVPR
 Virtual adversarial training: aregularization method for supervised and semi-supervised learning,2018, IEEE transactions on patternanalysis and machine intelligence
 Read-ing digits in natural images with unsupervised feature learning,2011, In NuerIPS Workshop on DeepLearning and Unsupervised Feature Learning
 Semi-supervised learning with generative adversarial networks,2016, arXiv preprintarXiv:1606
 Realisticevaluation of deep semi-supervised learning algorithms,2018, In NeurIPS
 Adversarial dropout for supervisedand semi-supervised learning,2018, In AAAI
 Optimization as a model for few-shot learning,2017, In ICLR
 Meta-learning for semi-supervised few-shot classifica-tion,2018, In ICLR
 Regularization with stochastic transforma-tions and perturbations for deep semi-supervised learning,2016, In NeurIPS
 Very deep convolutional networks for large-scale imagerecognition,2014, arXiv preprint arXiv:1409
 Going deeper with convolutions,2015, InCVPR
 Mean teachers are better role models: Weight-averaged consis-tency targets improve semi-supervised deep learning results,2017, In NeurIPS
 Word representations: a simple and general methodfor semi-supervised learning,2010, In ACL
 Interpolation con-sistency training for semi-supervised learning,2019, In IJCAI
 Mixup: Beyond empiri-cal risk minimization,2018, In ICLR
 Semi-supervised learning using gaussianfields and harmonic functions,2003, In ICML
 The CNN-13 network uses the SGD optimizer with a Nesterov momentum of0,2019,9
