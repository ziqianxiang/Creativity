title,year,conference
 Towards string-to-tree neural machine translation,2017, In Proceedingsof the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: ShortPapers)
 Neural machine translation by jointlylearning to align and translate,2015, In Yoshua Bengio and Yann LeCun (eds
 Language modeling with gatedconvolutional networks,2017, In Doina Precup and Yee Whye Teh (eds
 Convolutionalsequence to sequence learning,2017, In Doina Precup and Yee Whye Teh (eds
 Recurrent continuous translation models,2013, In Proceedings of the2013 Conference on Empirical Methods in Natural Language Processing
 Constituency parsing with a self-attentive encoder,2018, In Proceedingsof the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: LongPapers)
 A structured self-attentive sentence embedding,2017, In 5th International Conferenceon Learning Representations
 Annotated gigaWord,2012, In JamesFan
 Self-attention With relative position representa-tions,2018, In Proceedings of the 2018 Conference of the North American Chapter of the Associationfor Computational Linguistics: Human Language Technologies
 Attention is all you need,2017, In Isabelle Guyon
 Multi-layer represen-tation fusion for neural machine translation,2018, In Proceedings of the 27th International Conferenceon Computational Linguistics
 A tree-based decoder for neuralmachine translation,2018, In Proceedings of the 2018 Conference on Empirical Methods in NaturalLanguage Processing
 Modeling graphstructure in transformer for better amr-to-text generation,2019, In Kentaro Inui
