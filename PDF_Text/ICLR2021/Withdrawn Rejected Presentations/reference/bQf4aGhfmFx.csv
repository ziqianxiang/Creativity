title,year,conference
 Learning to learn by self-critique,2019, In H
 Meta-learning via learned loss,2019, arXiv preprint arXiv:1906
 Reconciling modern machine-learningpractice and the classical bias-variance trade-off,2019, Proceedings ofthe National Academy ofSciences
 Improved regularization of convolutional neural networkswith cutout,2017, arXiv preprint arXiv:1708
 Evolving loss functions with multivariate taylor polyno-mial parameterizations,2020, arXiv preprint arXiv:2002
 Explaining and harnessing adversarialexamples,2015, In Third International Conference on Learning Representations (ICLR)
 Comparing biases for minimal network construction withback-propagation,1989, In Advances in Neural Information Processing Systems
 Identity mappings in deep residualnetworks,2016, In European conference on computer vision
 Evolved policy gradients,2018, In Advances in Neural Information Processing Systems31
 Batch normalization: Accelerating deep network training byreducing internal covariate shift,2015, In International Conference on Machine Learning
 On large-batch training for deep learning: Generalization gap and sharp minima,2017, InProceedings of the Fifth International Conference on Learning Representations (ICLR)
 ImageNet classification with deep convo-lutional neural networks,2012, In F
 Towards explaining the regularization effect of initiallarge learning rate in training neural networks,2019, In H
 Meta-learningupdate rules for unsupervised representation learning,2018, In International Conference on LearningRepresentations
 Generalization and parameter estimation in feedforward nets:Some experiments,1990, In Advances in Neural Information Processing Systems
 Learningstate-dependent losses for inverse dynamics learning,2020, arXiv preprint arXiv:2003
 Deepdouble descent: Where bigger models and more data hurt,2019, In International Conference on LearningRepresentations (ICLR)
 Path-sgd: Path-normalized optimizationin deep neural networks,2015, In C
 Geometry ofoptimization and implicit regularization in deep learning,2017, arXiv preprint arXiv:1705
 Striving forsimplicity: The all convolutional net,2015, CoRR
 Learning to learn:Meta-critic networks for sample efficient learning,2017, arXiv preprint arXiv:1706
 Rethinking the inception architecture forcomputer vision,2016, In 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)
 The marginalvalue of adaptive gradient methods in machine learning,2017, In I
 Wide residual networks,2016, arXiv preprint arXiv:1605
 mixup: Beyond empiricalrisk minimization,2018, In International Conference on Learning Representations (ICLR)
 Online meta-criticlearning for off-policy actor-critic methods,2020, arXiv preprint arXiv:2003
