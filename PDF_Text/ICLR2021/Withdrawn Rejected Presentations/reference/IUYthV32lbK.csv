title,year,conference
 Obfuscated gradients give a false sense of se-curity: Circumventing defenses to adversarial examples,2018, In International Conference on MachineLearning
 Thermometer encoding: One hotway to resist adversarial examples,2018, In International Conference on Learning Representations
 Towards evaluating the robustness of neural networks,2017, In 2017ieee symposium on security and privacy (sp)
 Certified adversarial robustness via randomizedsmoothing,2019, In International Conference on Machine Learning
 Imagenet: A large-scale hi-erarchical image database,2009, In 2009 IEEE conference on computer vision and pattern recognition
 Scalable verified training forprovably robust image classification,2019, In Proceedings of the IEEE International Conference onComputer Vision
 Maxi-min margin machine: learninglarge margin classifiers locally and globally,2008, IEEE Transactions on Neural Networks
 Gradient-based learning applied todocument recognition,1998, Proceedings of the IEEE
 Certifiedrobustness to adversarial examples with differential privacy,2019, In 2019 IEEE Symposium on Securityand Privacy (SP)
 Certified adversarial robustness withadditive noise,2019, In Advances in Neural Information Processing Systems
 Boosting the robustness of capsule networks withdiverse ensemble,2020, In 2020 10th International Conference on Information Science and Technology(ICIST)
 Differentiable abstract interpretation for prov-ably robust neural networks,2018, In International Conference on Machine Learning
 Improving adversarial robustness viapromoting ensemble diversity,2019, arXiv preprint arXiv:1901
 Transferability in machine learning: fromphenomena to black-box attacks using adversarial samples,2016, arXiv preprint arXiv:1605
 Distillation as adefense to adversarial perturbations against deep neural networks,2016, In 2016 IEEE Symposium onSecurity and Privacy (SP)
 Provably robust deep learning via adversarially trained smoothed classifiers,2019, InAdvances in Neural Information Processing Systems
 Black-box smoothing: Aprovable defense for pretrained classifiers,2020, arXiv preprint arXiv:2003
 Muldef:Multi-model-based defense against adversarial examples for neural networks,2018, arXiv preprintarXiv:1809
 Intriguing properties of neural networks,2013, arXiv preprint arXiv:1312
 Deepface: Closing the gap tohuman-level performance in face verification,2014, In Proceedings of the IEEE conference on computervision and pattern recognition
 The spaceof transferable adversarial examples,2017, arXiv preprint arXiv:1704
 On adaptive attacks toadversarial example defenses,2020, arXiv preprint arXiv:2002
 Attention is all you need,2017, In Advances in neural informationprocessing systems
 Towards fast computation of certified robustness for relu networks,2018, InInternational Conference on Machine Learning
 Provable defenses against adversarial examples via the convex outeradversarial polytope,2018, In International Conference on Machine Learning
 Spatially trans-formed adversarial examples,2018, In International Conference on Learning Representations
 Randomizedsmoothing of all shapes and sizes,2020, In International Conference on Machine Learning
 Black-box certifica-tion with randomized smoothing: A functional optimization based framework,2020, arXiv preprintarXiv:2002
 Efficient neural net-work robustness certification with general activation functions,2018, In Advances in neural informationprocessing systems
 Enhancing certifiable robustness via a deep modelensemble,2019, arXiv preprint arXiv:1910
2 Ensemble After SmoothingTheorem C,2021,1 (Certified robustness for Ensemble After Smoothing)
 Let X1 and X2be defined by Definition D,2021,2 and Definition D
 1 Ensemble Comparison from Numerical SamplingAs discussed in Section 3,2021,2
