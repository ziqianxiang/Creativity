title,year,conference
 High-dimensional dynamics of generalization error in neuralnetworks,2017, 10 2017
 Reconciling modern machine-learningpractice and the classical bias-variance trade-off,2019, Proceedings ofthe National Academy ofSciences
 Deep rewiring: Trainingvery sparse deep networks,2018, In International Conference on Learning Representations
 Learning phrase representations using RNN encoder-decoder forstatistical machine translation,2014, In Proceedings of the 2014 Conference on Empirical Methods inNatural Language Processing (EMNLP)
 Stabilizing the lottery tickethypothesis,2020, arXiv
 Deep residual learning for imagerecognition,2015, 7
 Long short-term memory,1997, Neural computation
 Speeding up convolutional neural networks withlow rank expansions,2014, ArXiv
 Adam: A method for stochastic optimization,2014, InternationalConference on Learning Representations
 Learning multiple layers of features from tiny images,2009, Technical report
 Gradient-based learning applied to documentrecognition,1998, Proceedings of the IEEE
 MNIST handwritten digit database,2010, 2010
 Optimal brain damage,1990, In D
 Snip: Single-shot network pruning basedon connection sensitivity,2019, In International Conference on Learning Representations
 A signal propagationperspective for pruning neural networks at initialization,2020, In International Conference on LearningRepresentations
 Skeletonization: A technique for trimming the fat froma network via relevance assessment,1989, In D
 Deepdouble descent: Where bigger models and more data hurt,2020, In International Conference on LearningRepresentations
 Tensorizing neuralnetworks,2015, In C
 On the difficulty of training recurrent neuralnetworks,2012, 30th International Conference on Machine Learning
 Pruning algorithms-a survey,1993, IEEE Transactions on Neural Networks
 The graph neural networkmodel,2009, IEEE Transactions on Neural Networks
 Efficient processing of deep neural networks: A tutorialand survey,2017, Proceedings of the IEEE
 Pruning neural networkswithout any data by iteratively conserving synaptic flow,2020, arXiv
 Picking winning tickets before training bypreserving gradient flow,2020, In International Conference on Learning Representations
 A comprehen-sive survey on graph neural networks,2020, IEEE transactions on neural networks and learning systems
 Drawing early-bird tickets: Toward more efficient training ofdeep networks,2020, In International Conference on Learning Representations
 Wide residual networks,2016, In Edwin R
 Graph neuralnetworks: A review of methods and applications,2018, arXiv
