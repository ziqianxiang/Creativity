title,year,conference
 Quantifying and learning disentangled representations with limited supervision,2021, InSubmitted to International Conference on Learning Representations
 Symmetry-adapted representation learning,0031, Pattern Recognition
 Representation learning: A review and newperspectives,2013, IEEE transactions on pattern analysis and machine intelligence
 Symmetry-Based DisentangledRepresentation Learning requires Interaction with Environments,2019, In H
 Learning the Irreducible Representations of Commutative LieGroups,2014, arXiv:1402
 A General Theory of Equivariant CNNs on Ho-mogeneous Spaces,1811, arXiv:1811
 Spherical cnns,2018, arXiv preprintarXiv:1801
 Representing Closed Transformation Paths in EncodedNetwork Latent Space,2020, In AAAI
 Variational Autoencoder withLearned Latent Structure,2020, arXiv:2006
 Hy-perspherical Variational Auto-Encoders,1804, arXiv:1804
 Equivariant Neural Rendering,2020, arXiv preprint arXiv:2006
 Polar TransformerNetworks,2018, arXiv:1709
 Explorations in Homeomorphic Variational Auto-Encoding,1807, arXiv:1807
 Reparameterizing Distributionson Lie Groups,1903, arXiv:1903
 Generalizing Convolutional Networks forEquivariance to Lie Groups on Arbitrary Continuous Data,2020, In Proceedings of the InternationalConference on Machine Vision and Machine Learning
 No Representationwithout Transformation,1912, arXiv:1912
 Hamiltonian neural networks,2019, In Advancesin Neural Information Processing Systems
 beta-VAE: Learning Basic Visual Concepts with aConstrained Variational Framework,2016, November 2016
 Towards a Definition of Disentangled Representations,2018, arXiv:1812
 Variational AU-toencoders and Nonlinear ICA: A Unifying Framework,1907, arXiv:1907
 Adam: A method for stochastic oPtimization,2014, arXiv preprintarXiv:1412
 AUto-Encoding Variational Bayes,1312, arXiv:1312
 BUildingmachines that learn and think like PeoPle,2017, Behavioral and brain sciences
 Challenging Common Assumptions in the Unsupervised Learn-ing of Disentangled Representations,1811, arXiv:1811
 Weakly-Supervised Disentanglement Without Compromises,2002, arXiv:2002
 Learning to Represent Spatial Transformations withFactored Higher-Order Boltzmann Machines,1530, Neural Computation
 Learning Group Structure andDisentangled Representations of Dynamical Environments,2020, arXiv preprint arXiv:2002
 Attentive GroupEquivariant Convolutional Networks,2020, arXiv preprint arXiv:2002
 Weakly SupervisedDisentanglement with Guarantees,1910, arXiv:1910
 An Unsupervised AlgorithmFor Learning Lie Group Transformations,1001, arXiv:1001
 Appendix B,2021,3 below gives a detailed explanation of the computation of the scoresÎ±i
 14 shows additional results onMNIST,2021, Fig
