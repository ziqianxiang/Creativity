title,year,conference
 How largea vocabulary does text classification need? A variational approach to vocabulary selection,2019, InJill Burstein
 Revisitingcharacter-based neural machine translation with capacity and compression,2018, In Ellen Riloff
 Character-based neural machine translation,2016, InProceedings of the 54th Annual Meeting of the Association for Computational Linguistics
 A call for prudent choice of subwordmerge operations in neural machine translation,2019, In Mikel L
 Entropy and mutual information in models of deep neural networks,2018, InSamy Bengio
 Adam: A method for stochastic optimization,2015, In Yoshua Bengioand Yann LeCun (eds
 Learning to segment inputs for NMT favors character-levelprocessing,2018, CoRR
 Sentencepiece: A simple and language independent subwordtokenizer and detokenizer for neural text processing,2018, In Eduardo Blanco and Wei Lu (eds
 Fully character-level neural machine translationwithout explicit segmentation,2017, Transactions of the Association for Computational Linguistics
 Very deep transformers for neural ma-chine translation,2020, CoRR
 Distributedrepresentations of words and phrases and their compositionality,2013, In Christopher J
 Bpe-dropout: Simple and effective subwordregularization,2020, In Dan Jurafsky
 Optimizing seg-mentation granularity for neural machine translation,2020, Machine Translation
 Neural machine translation of rare words withsubword units,2016, In Proceedings of the 54th Annual Meeting of the Association for ComputationalLinguistics
 Self-attention with relative position representa-tions,2018, In Marilyn A
 The evolved transformer,2019, In Kamalika Chaudhuriand Ruslan Salakhutdinov (eds
 Attention is all you need,2017, In Isabelle Guyon
 Deep learning for sentiment analysis: A survey,2018, WileyInterdisciplinary Reviews: Data Mining and Knowledge Discovery
 Recurrent neural network for text classification with hi-erarchical multiscale dense connections,2019, In Sarit Kraus (ed
