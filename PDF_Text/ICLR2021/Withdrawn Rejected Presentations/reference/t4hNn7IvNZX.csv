title,year,conference
 Certified adversarial robustness via randomizedsmoothing,2019, pp
 Explaining and harnessing adversarialexamples,2015, 2015
 On the effectiveness of intervalbound propagation for training verifiably robust models,2018, arXiv preprint arXiv:1810
 Parametric noise injection: Trainable randomnessto improve deep neural network robustness against adversarial attack,2019, In Proceedings of the IEEEConference on Computer Vision and Pattern Recognition
 Adversarial logit pairing,2018, arXiv preprintarXiv:1803
 Adversarial machine learning at scale,2018, 2018
 Certifiedrobustness to adversarial examples with differential privacy,2019, In 2019 IEEE Symposium on Securityand Privacy (SP)
 Tight certificates of adversarialrobustness for randomly smoothed classifiers,2019, In Advances in Neural Information ProcessingSystems
 Certified adversarial robustness withadditive noise,2019, In Advances in Neural Information Processing Systems
 Towards robust neural networks viarandom self-ensemble,2018, In Proceedings of the European Conference on Computer Vision (ECCV)
 Differentiable abstract interpretation for prov-ably robust neural networks,2018, In International Conference on Machine Learning
 Variance-based regularization with convex objectives,2017, InAdvances in neural information processing systems
 Scalable differentialprivacy with certified robustness in adversarial learning,2020, 2020
 Provably robust deep learning via adversarially trained smoothed classifiers,2019, InAdvances in Neural Information Processing Systems
 A convex relaxationbarrier to tight robustness verification of neural networks,2019, In Advances in Neural InformationProcessing Systems
 Certifying some distributional robustness withPrinciPled adversarial training,2018, 2018
 Evaluating robustness of neural networks with mixedinteger Programming,2018, In International Conference on Learning Representations
 ImProvingadversarial robustness requires revisiting misclassified examPles,2019, In International Conference onLearning Representations
 Towards fast comPutation of certified robustness for relu networks,2018, In InternationalConference on Machine Learning (ICML)
 Provable defenses against adversarial examPles via the convex outeradversarial PolytoPe,2018, In International Conference on Machine Learning
 Efficient defenses against adver-sarial attacks,2017, In Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security
 Efficient neural net-work robustness certification with general activation functions,2018, In Advances in neural informationprocessing systems
 ImProving the robustness of deePneural networks via stability training,2016, In Proceedings of the ieee conference on computer visionand pattern recognition
