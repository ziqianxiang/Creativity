title,year,conference
 The great timeseries classification bake off: a review and experimental evaluation of recent algorithmic ad-Vances,2017, Data Mining and Knowledge Discovery
 An empirical evaluation of generic convolutionaland recurrent networks for sequence modeling,2018, arXiv preprint arXiv:1803
 DeepSignature Transforms,2019, Advances in Neural Information Processing Systems
 Dimension-free EUlerestimates of rough differential equations,2014, Revue Roumaine de Mathmatiques Pures et Appliques
 Skip RNN:Learning to Skip State Updates in Recurrent Neural Networks,2017, arXiv preprint arXiv:1708
 Neural Ordinary Dif-ferential Equations,2018, Advances in Neural Information Processing Systems
 Gru-ode-bayes: Continuousmodeling of sporadically-observed time series,2019, In Advances in Neural Information ProcessingSystems
 Areas of areas generate the shufflealgebra,2020, arXiv preprint arXiv:2002
 Pathwise approximation of SDEs by coupling piecewise abelian roughpaths,2015, arXiv preprint arXiv:1505
 Supervised sequence labelling,2012, In Supervised sequence labelling with recurrent neuralnetworks
 HiPPO: Recurrent Memorywith Optimal Polynomial Projections,2020, arXiv:2008
 Numerical methods for approximating solutions to rough differential equa-tions,2008, DPhil thesis
 Uniqueness for the signature of a path of bounded variation and thereduced path group,2010, Annals of Mathematics
 Gated orthogonal recurrent units: On learning to forget,2019, Neural computation
 Universal Approximation with Deep Narrow Networks,2020, COLT2020
 Neural controlled differential equa-tions for irregular time series,2020, arXiv preprint arXiv:2005
 Learning long-term dependencies in irregularly-sampled timeseries,2020, arXiv preprint arXiv:2006
 Enhancing the locality and breaking the memory bottleneck of transformer on time seriesforecasting,2019, In Advances in Neural Information Processing Systems
 Learning stochastic differential equationsusing RNN with log signature features,2019, arXiv preprint arXiv:1908
 APProximation theory of the MLP model in neural networks,1999, Acta Numer
 Calculation of Iterated-Integral Signatures and Log Signatures,2017, arXiv preprintarXiv:1712
 Introduction to Tensor Products of Banach Spaces,2002, SPringer MonograPhs inMathematics
 Igloo: Slicing the features sPace to rePresent sequences,2018, arXiv preprintarXiv:1807
 Legendre memory units: Continuous-time repre-sentation in recurrent neural networks,2019, In Advances in Neural Information Processing Systems32
 The learning rate was initialised at 0,1024,032divided by batch size
