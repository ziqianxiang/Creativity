title,year,conference
 Net-trim: Convex pruning of deepneural networks with performance guarantee,2017, In Advances in Neural Information ProcessingSystems
 Lectures on some fixed point theorems of functional analysis,1962, In Tata Institute ofFundamental Research
 Distributed opti-mization and statistical learning via the alternating direction method of multipliers,2011, Foundationsand Trends in Machine Learning
 Theloss surfaces of multilayer networks,2015, In Proceedings of the Eighteenth International Conferenceon Artificial Intelligence and Statistics
 Identifying and attacking the saddle point problem in high-dimensional non-convex op-timization,2014, In Advances in Neural Information Processing Systems
 An overview of low-rank matrix recovery from incom-plete observations,2016, J
 Predictingparameters in deep learning,2013, In Advances in Neural Information Processing Systems
 Improving interpretability of deep neural net-works with semantic information,2017, In 2017 IEEE Conference on Computer Vision and PatternRecognition
 Neuralmessage passing for quantum chemistry,2017, In Proceedings of the 34th International Conference onMachine Learning
 Mean-field theory of graph neuralnetworks in graph partitioning,2018, In Advances in Neural Information Processing Systems
 Deep learning,2015, nature
 Deriving neural architectures fromsequence and graph kernels,2017, In Proceedings of the 34th International Conference on MachineLearning
 Pruning filters forefficient convnets,2017, In 5th International Conference on Learning Representations
 Rethinking the value ofnetwork pruning,2019, In 7th International Conference on Learning Representations
 Understanding deep convolutional networks,2016, Philosophical Transactions of theRoyal Society A: Mathematical
 Missing data: A comparisonof neural network and expectation maximization techniques,2007, Current Science
 Regular-izing cnns with locally constrained decorrelations,2017, In 5th International Conference on LearningRepresentations
 Computational capabilities ofgraph neural networks,2009, IEEE Transactions on Neural Networks
 Trainingneural networks without gradients: A scalable admm approach,2016, In International conference onmachine learning
 Deep neural networks with multi-brancharchitectures are intrinsically less non-convex,2019, In The 22nd International Conference on ArtificialIntelligence and Statistics
 Graph neuralnetworks: A review of methods and applications,2018, arXiv preprint arXiv:1812
 Learning transferable architecturesfor scalable image recognition,2018, In Proceedings of the IEEE conference on computer vision andpattern recognition
