title,year,conference
 Microsoft coco captions: Data collection and evaluation server,2015, arXivpreprint arXiv:1504
 Uniter: Universal image-text representation learning,2020, In European Conference onComputer Vision
 Exploringnearest neighbor approaches for image captioning,2015, arXiv preprint arXiv:1505
 Bert: Pre-training of deepbidirectional transformers for language understanding,2018, arXiv preprint arXiv:1810
 Learning everything about anything: Webly-supervised visual concept learning,2014, In Proceedings of the IEEE Conference on Computer Visionand Pattern Recognition
 Vse++: Improving visual-semantic embeddings with hard negatives,2017, arXiv preprint arXiv:1707
 Augmenting transformers withknn-based composite memory for dialogue,2020, arXiv preprint arXiv:2004
 Realm: Retrieval-augmented language model pre-training,2020, arXiv preprint arXiv:2002
 Learning semantic concepts and order forimage and sentence matching,2018, In Proceedings of the IEEE Conference on Computer Vision andPattern Recognition
 Billion-scale similarity search with gpus,2017, arXivpreprint arXiv:1702
 Generalizationthrough memorization: Nearest neighbor language models,2019, arXiv preprint arXiv:1911
 Supervised multimodalbitransformers for classifying images and text,2019, arXiv preprint arXiv:1909
 Stacked cross attention forimage-text matching,2018, In Proceedings of the European Conference on Computer Vision (ECCV)
 Retrieval-augmented gener-ation for knowledge-intensive nlp tasks,2020, arXiv preprint arXiv:2005
 Unicoder-vl: Auniversal encoder for vision and language by cross-modal pre-training,2020, In AAAI
 Visualbert: A simpleand performant baseline for vision and language,2019, arXiv preprint arXiv:1908
 Oscar: Object-semantics aligned pre-training for vision-languagetasks,2020, In European Conference on Computer Vision
 Learning a recurrent residual fu-sion network for multimodal matching,2017, In Proceedings of the IEEE International Conference onComputer Vision
 Vilbert: Pretraining task-agnostic visiolinguis-tic representations for vision-and-language tasks,2019, In Advances in Neural Information ProcessingSystems
 Fine-grained visual textual alignment for cross-modal retrieval using trans-former encoders,2020, arXiv preprint arXiv:2008
 Transformer reasoning net-work for image-text matching and retrieval,2020, arXiv preprint arXiv:2004
 Revisiting modulated convolutions forvisual counting and beyond,2020, arXiv preprint arXiv:2004
 Vl-bert: Pre-trainingof generic visual-linguistic representations,2019, arXiv preprint arXiv:1908
 Facts as experts: Adaptableand interpretable neural memory over symbolic knowledge,2020, arXiv preprint arXiv:2007
 Learning fragment self-attentionembeddings for image-text matching,2019, In Proceedings of the 27th ACM International Conferenceon Multimedia
 From image descriptions to visualdenotations: New similarity metrics for semantic inference over event descriptions,2014, Transactionsof the Association for Computational Linguistics
 Deep cross-modal projection learning for image-text matching,2018, InProceedings of the European Conference on Computer Vision (ECCV)
 Reasoning about object affordances in a knowledge baserepresentation,2014, In European conference on computer vision
