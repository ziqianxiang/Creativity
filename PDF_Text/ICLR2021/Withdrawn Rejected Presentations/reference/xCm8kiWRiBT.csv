title,year,conference
 Deposit account fraud survey,2020, 2020
 Towards evaluating the robustness of neural networks,2017, In 2017IEEE symposium on security and privacy (SP)
 EMNIST: Extending MNISTto handwritten letters,2017, In 2017 International Joint Conference on Neural Networks (IJCNN)
 On thesensitivity of adversarial robustness to input data distributions,2019, In ICLR (Poster)
 Explaining and harnessing adversarialexamples,2014, arXiv preprint arXiv:1412
 OCR binarization and image pre-processingfor searching historical documents,2007, Pattern Recognition
 Black-box adversarial attacks withlimited queries and information,2018, arXiv preprint arXiv:1804
 Prior convictions: Black-box adversarialattacks with bandits and priors,2018, arXiv preprint arXiv:1807
 Gradient-based learning applied todocument recognition,1998, Proceedings of the IEEE
 MNIST handwritten digit database,2010, 2010
 Parsimonious black-box adversarial attacks viaefficient combinatorial optimization,2019, arXiv preprint arXiv:1905
 Deepfool: a simple andaccurate method to fool deep neural networks,2016, In Proceedings of the IEEE conference on computervision and pattern recognition
 Confidence prediction for lexicon-free OCR,2018, In 2018 IEEE WinterConference on Applications of Computer Vision (WACV)
 Foolbox: A python toolbox to benchmark therobustness of machine learning models,2017, arXiv preprint arXiv:1707
 Adver-sarially robust generalization requires more data,2018, In Advances in Neural Information ProcessingSystems
 An overview of the Tesseract OCR engine,2007, In Ninth International Conference onDocument Analysis and Recognition (ICDAR 2007)
 Fooling OCR systems with adversarial text images,2018, arXivpreprint arXiv:1802
 Intriguing properties of neural networks,2013, arXiv preprint arXiv:1312
 Autozoom: Autoencoder-based zeroth order optimization method for attackingblack-box neural networks,2019, In Proceedings of the AAAI Conference on Artificial Intelligence
