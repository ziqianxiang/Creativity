title,year,conference
 Adaptive neural networks forefficient inference,2017, In Proceedings of the 34th International Conference on Machine Learning
 Proxylessnas: Direct neural architecture search on target taskand hardware,2018, arXiv preprint arXiv:1812
 Once-for-all: Train onenetwork and specialize it for efficient deployment,2019, arXiv preprint arXiv:1908
 You look twice: Gaternet for dynamic fil-ter selection in cnns,2019, In Proceedings of the IEEE Conference on Computer Vision and PatternRecognition
 Autoaugment:Learning augmentation strategies from data,2019, In Proceedings of the IEEE conference on computervision and pattern recognition
 Fbnetv3: Joint architecture-recipe search using neuralacquisition function,2020, arXiv preprint arXiv:2006
 Learning factored representations in a deepmixture of experts,2013, arXiv preprint arXiv:1312
 Spatially adaptive computation time for residual networks,2017, In Proceedingsof the IEEE Conference on Computer Vision and Pattern Recognition
 Shake-shake regularization,2017, arXiv preprint arXiv:1705
 Selective classification for deep neural networks,2017, In Advancesin neural information processing systems
 Distilling the knowledge in a neural network,2015, arXivpreprint arXiv:1503
 Mobilenets: Efficient convolutional neural networks formobile vision applications,2017, arXiv preprint arXiv:1704
 Network trimming: A data-drivenneuron pruning approach towards efficient deep architectures,2016, arXiv preprint arXiv:1607
 Quantization and training of neural networks forefficient integer-arithmetic-only inference,2018, In Proceedings of the IEEE Conference on ComputerVision and Pattern Recognition
 On-device neural net inference withmobile gpus,2019, arXiv preprint arXiv:1907
 The cascading neural network: building the internet of smart things,2017, Knowledgeand Information Systems
 Shufflenet v2: Practical guidelinesfor efficient cnn architecture design,2018, In Proceedings of the European Conference on ComputerVision (ECCV)
 K for theprice of 1: Parameter-efficient multi-task and transfer learning,2018, arXiv preprint arXiv:1810
 Mo-bilenetv2: Inverted residuals and linear bottlenecks,2018, In Proceedings of the IEEE conference oncomputer vision and pattern recognition
 Efficientnet: Rethinking model scaling for convolutional neural net-works,2019, In International Conference on Machine Learning
 Mnasnet: Platform-aware neural architecture search for mobile,2019, In Proceedings ofthe IEEE Conference on Computer Vision and Pattern Recognition
 Branchynet: Fast inference viaearly exiting from deep neural networks,2016, In 23rd International Conference on Pattern Recognition(ICPR)
 Hydranets: Spe-cialized dynamic architectures for efficient inference,2018, In Proceedings of the IEEE Conference onComputer Vision and Pattern Recognition
 Regularization of neuralnetworks using dropconnect,2013, In International conference on machine learning
 Circumventingoutliers of autoaugment with knowledge distillation,2020, arXiv preprint arXiv:2003
 Self-training with noisy studentimproves imagenet classification,2019, arXiv preprint arXiv:1911
 Condconv: Conditionally parameter-ized convolutions for efficient inference,2019, In Advances in Neural Information Processing Systems
 mixup: Beyond empiricalrisk minimization,2017, arXiv preprint arXiv:1710
 Domain-aware dy-namic networks,2019, arXiv preprint arXiv:1911
 Shufflenet: An extremely efficientconvolutional neural network for mobile devices,2018, In Proceedings of the IEEE conference oncomputer vision and pattern recognition
 Dynet: Dynamic convolution for accel-erating convolutional neural networks,2020, arXiv preprint arXiv:2004
