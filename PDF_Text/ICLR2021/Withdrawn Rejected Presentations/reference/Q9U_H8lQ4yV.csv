title,year,conference
 Doubly attentive transformer machinetranslation,2018, arXiv preprint arXiv:1807
 Layer normalization,2016, arXiv preprintarXiv:1607
 Neural machine translation by jointlylearning to align and translate,2014, arXiv preprint arXiv:1409
 Find-ings of the third shared task on multimodal machine translation,2018, In WMT18
 Training with noise is equivalent to tikhonov regularization,1995, Neural computation
 Neural networks for pattern recognition,1995, Oxford university press
 Doubly-attentive decoder for multi-modal neu-ral machine translation,1913, In Proceedings of the 55th Annual Meeting of the Association forComputational Linguistics (Volume 1: Long Papers)
 Episodicmemory in lifelong language learning,2019, arXiv preprint arXiv:1906
 Bert: Pre-training of deepbidirectional transformers for language understanding,2018, arXiv preprint arXiv:1810
 Adversarial evaluation of multimodal machine translation,2018, In Proceedings of the2018 Conference on Empirical Methods in Natural Language Processing
 Imagination improves multimodal translation,2017, In Proceedingsof the Eighth International Joint Conference on Natural Language Processing (Volume 1: LongPapers)
 Multilingual image description with neural sequencemodels,2015, arXiv preprint arXiv:1510
 Findings of thesecond shared task on multimodal machine translation and multilingual image description,2017, arXivpreprint arXiv:1710
 Assessing multilingual multimodal image descrip-tion: Studies of native speaker preferences and translator choices,2018, Natural Language Engineering
 Devise: A deep visual-semantic embedding model,2013, In Advances in neuralinformation processing systems
 Deep Learning,2016, MIT Press
 Speech recognition with deep recur-rent neural networks,2013, In 2013 IEEE international conference on acoustics
 The memad submissionto the wmt18 multimodal translation task,2018, arXiv preprint arXiv:1808
 Search engine guided neural machinetranslation,2018, In AAAI
 Realm: Retrieval-augmented language model pre-training,2020, arXiv preprint arXiv:2002
 Comparing biases for minimal network construction withback-propagation,1989, In Advances in neural information processing systems
 Cuni system for the wmt18 multimodal trans-lation task,2018, arXiv preprint arXiv:1811
 Generaliza-tion through memorization: Nearest neighbor language models,2019, In International Conference onLearning Representations
 Retrieval-augmented gener-ation for knowledge-intensive nlp tasks,2020, arXiv preprint arXiv:2005
 Dynamic context-guided capsule network for multimodal machine translation,2020, arXivpreprint arXiv:2009
 Neural machine translation of rare words withsubword units,2016, In Proceedings of the 54th Annual Meeting of the Association for ComputationalLinguistics (Volume 1: Long Papers)
 Fever: a large-scale dataset for fact extraction and verification,2018, In Proceedings of the 2018 Conference of theNorth American Chapter of the Association for Computational Linguistics: Human LanguageTechnologies
 Attention is all you need,2017, In Advances in neural informationprocessing systems
 Huggingfaceâ€™s transformers: State-of-the-art natural language processing,2019, ArXiv
 A visual attention grounding neuralmodel for multimodal machine translation,2018, In Proceedings of the 2018 Conference on EmpiricalMethods in Natural Language Processing
