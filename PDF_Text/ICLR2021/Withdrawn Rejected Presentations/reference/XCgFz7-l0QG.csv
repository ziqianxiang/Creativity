title,year,conference
 Fully quantiz-ing a simplified transformer for end-to-end speech recognition,2019, arXiv preprint arXiv:1911
 Error analysis of the minimax principle,1982, In Advances in computerchess
 Language models arefew-shot learners,2020, arXiv preprint arXiv:2005
 Bert: Pre-training of deepbidirectional transformers for language understanding,2018, arXiv preprint arXiv:1810
 Knowledge distillation with adver-sarial samples supporting decision boundary,2019, In Proceedings of the AAAI Conference on ArtificialIntelligence
 Distilling the knowledge in a neural network,2015, arXivpreprint arXiv:1503
 Mobilenets: Efficient convolutional neural networks formobile vision applications,2017, arXiv preprint arXiv:1704
 Quantization and training of neural networks forefficient integer-arithmetic-only inference,2018, In Proceedings of the IEEE Conference on ComputerVision and Pattern Recognition
 Albert: A lite bert for self-supervised learning of language representations,2019, arXiv preprintarXiv:1909
 Roberta: A robustly optimized bert pretrainingapproach,2019, arXiv preprint arXiv:1907
 Zero-shot knowledge transfer via adversarial belief matching,2019, InAdvances in Neural Information Processing Systems
 Zero-shot knowledge distillation in deep networks,2019, arXiv preprintarXiv:1905
 Fully quantized transformer for improvedtranslation,2019, arXiv preprint arXiv:1910
 Mo-bilenetv2: Inverted residuals and linear bottlenecks,2018, In Proceedings of the IEEE conference oncomputer vision and pattern recognition
 Patient knowledge distillation for bert modelcompression,2019, arXiv preprint arXiv:1908
 Rethink-ing the inception architecture for computer vision,2016, In Proceedings of the IEEE conference oncomputer vision and pattern recognition
 Tensor decomposition for compressingrecurrent neural network,2018, In 2018 International Joint Conference on Neural Networks (IJCNN)
 Pruningfrom scratch,2019, arXiv preprint arXiv:1909
 Huggingfaceâ€™s trans-formers: State-of-the-art natural language processing,2019, ArXiv
 Yolo nano: a highly compact you only look once convolutional neural networkfor object detection,2019, arXiv preprint arXiv:1910
