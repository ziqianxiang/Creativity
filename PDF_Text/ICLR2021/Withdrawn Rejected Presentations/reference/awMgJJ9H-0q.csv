title,year,conference
 Neural network learning: Theoretical foundations,2009, cambridgeUniversity Press
 On gradient regUlarizersfor MMD GANs,2018, In NIPS
 MaximUm mean discrePancy gradientflow,2019, In NeurIPS
 Towards principled methods for training generative adversarialnetworks,2017, In ICLR
 Demystifying MMDGANs,2018, In ICLR
 Neural ordinary differen-tial equations,2018, In NIPS
 The geometry of proper scoring rules,2007, Annals of the Institute of StatisticalMathematics
 Generative modeling using the slicedwasserstein distance,2018, In CVPR
 NICE: Non-linear independent componentsestimation,2015, In ICLR
 Density estimation using Real NVP,2017, InICLR
 Deep generativelearning via variational gradient flow,2019, In ICML
 Calculus of variations,2000, Dover Publications
 Learning generative models with sinkhorn diver-gences,2018, In ICML
 Generative adversarial nets,2014, In Advances in NeuralInformation Processing Systems 27
 FFJORD:Free-form continuous dynamics for scalable reversible generative models,2019, In ICLR
 Denoising diffusion probabilistic models,2020, In Advances inNeural Information Processing Systems
 Batch normalization: Accelerating deep network training byreducing internal covariate shift,2015, In ICML
 Composite functional gradient learning of generative adversarialmodels,2018, In ICML
 Statistical analysis of distance estimators with densitydifferences and density ratios,2014, Entropy
 Auto-encoding variational bayes,2014, In ICLR
 Glow: Generative flow with invertible 1x1 convolutions,2018, InNIPS
 Sliced-Wassersteinautoencoder: An embarrassingly simple generative model,2019, In ICLR
 Gradient-based learning applied todocument recognition,1998, Proceedings of the IEEE
 Introduction to Riemannian Manifolds,2010, Springer
 MMD GAN:Towards deeper understanding of moment matching network,2017, In NIPS
 A two-step computation of the exact ganWasserstein distance,2018, In ICML
 Stein variational gradient descent as gradient flow,2017, In Advances in Neural InformationProcessing Systems
 Deep learning face attributes in the wild,2015, InICCV
 Sliced-Wasserstein flows: Nonparametric generativemodeling via optimal transport and diffusions,2019, In ICML
 Spectral normalization forgenerative adversarial networks,2018, In ICLR
 Learning in implicit generative models,2016, arXivpreprint arXiv:1610
 f -GAN: Training generative neural samplersusing variational divergence minimization,2016, In NIPS
 Masked autoregressive flow for densityestimation,2017, In NIPS
 Sinkhorn autoencoders,2019, In UAI
 Variational inference with normalizing flows,2015, InICML
 Stabilizing training ofgenerative adversarial networks through regularization,2017, In NIPS
 Learning deep generative models,2015, Annual Review of Statistics and ItsApplication
 Optimal transport for applied mathematicians,2015, Springer
 Nonparametric regression using deep neural networks with relu activationfunction,2020, The Annals of Statistics
 Deep network approximation characterized bynumber of neurons,2019, arXiv preprint arXiv:1906
 Amortisedmap inference for image super-resolution,2017, In ICLR
 Improved techniques for training score-based generative models,2020, InAdvances in Neural Information Processing Systems
 Optimal global rates of convergence for nonparametric regression,1982, The Annals ofStatistics
 Density-difference estimation,2012, In NIPS
 Density ratio estimation in machinelearning,2012, Cambridge University Press
 Rethinkingthe inception architecture for computer vision,2016, In CVPR
 Wasserstein auto-encoders,2018, In ICLR
 Monge-AmPere flow for generative modeling,2018, arXivpreprint arXiv:1809
 Unpaired image-to-image translationusing cycle-consistent adversarial networks,2017, In ICCV
