title,year,conference
 Invertible generative models for inverse problems:mitigating representation error and dataset bias,2019, arXiv preprint arXiv:1905
 Obfuscated gradients give a false sense of se-curity: Circumventing defenses to adversarial examples,2018, In International Conference on MachineLearning
 Towards evaluating the robustness of neural networks,2017, In 2017 IEEESymposium on Security and Privacy (SP)
 Certified adversarial robustness via randomizedsmoothing,2019, In International Conference on Machine Learning
 ImageNet: A Large-Scale HierarchicalImage Database,2009, In CVPR09
 Density estimation using real nvp,2016, arXivpreprint arXiv:1605
 Deep convolutionalneural network for inverse problems in imaging,2017, IEEE Transactions on Image Processing
 Provable certificates for adversarial exam-ples: Fitting a ball in the union of polytopes,2019, In Advances in Neural Information ProcessingSystems
 Reluplex: Anefficient smt solver for verifying deep neural networks,2017, In International Conference on ComputerAided Verification
 Regularized estimation of image statistics by scorematching,2010, In J
 Glow: Generative flow with invertible 1x1 convolutions,2018, InAdvances in neural information processing systems
 Learning multiple layers of features from tiny images,2009, 2009
 Adversarial machine learning at scale,2016, arXivpreprint arXiv:1611
 Certifiedrobustness to adversarial examples with differential privacy,2019, In 2019 IEEE Symposium on Securityand Privacy (SP)
 Tight certificates of adversarialrobustness for randomly smoothed classifiers,2019, In Advances in Neural Information ProcessingSystems
 Certified adversarial robustness withadditive noise,2019, In Advances in Neural Information Processing Systems
 Defense againstadversarial attacks using high-level representation guided denoiser,2018, In Proceedings of the IEEEConference on Computer Vision and Pattern Recognition
 An approach to reachability analysis for feed-forward reluneural networks,2017, arXiv preprint arXiv:1706
 Magnet: a two-pronged defense against adversarial examples,2017, InProceedings of the 2017 ACM SIGSAC conference on computer and communications security
 An empirical bayes approach to statistics,1956, In Proceedings of the Third BerkeleySymposium on Mathematical Statistics and Probability
 Provably robust deep learning via adversarially trained smoothed classifiers,2019, InAdvances in Neural Information Processing Systems
 A convex relaxationbarrier to tight robustness verification of neural networks,2019, In Advances in Neural InformationProcessing Systems
 Pixeldefend:Leveraging generative models to understand and defend against adversarial examples,2017, arXivpreprint arXiv:1710
 Sliced score matching: A scalable approachto density and score estimation,2020, In Uncertainty in Artificial Intelligence
 Intriguing properties of neural networks,2013, arXiv preprint arXiv:1312
 Evaluating robustness of neural networks withmixed integer programming,2019, In International Conference on Learning Representations
 On adaptive attacks toadversarial example defenses,2020, arXiv preprint arXiv:2002
 Deep image prior,2018, In Proceedings of theIEEE Conference on Computer Vision and Pattern Recognition
 Compressed sensing with invertible generativemodels and dependent noise,2020, arXiv preprint arXiv:2003
 Provable defenses against adversarial examples via the convex outeradversarial polytope,2018, In International Conference on Machine Learning
 Randomizedsmoothing of all shapes and sizes,2020, arXiv preprint arXiv:2002
 Black-box certifica-tion with randomized smoothing: A functional optimization based framework,2020, arXiv preprintarXiv:2002
