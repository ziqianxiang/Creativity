title,year,conference
 Hindsight ex-perience replay,2017, In AdvanCeS in NeUral InfOrmatiOn PrOCeSSing SyStemS 30: AnnualConference on NeUral InfOrmatiOn Processing SyStemS 2017
 Tuning bandit algorithms in stochasticenvironments,2007, In IntematiOnal COnferenCe on algorithmic learning theory
 Finite-time analysis of the multiarmed banditproblem,2002, MaChine Iearning
 A surveyof monte carlo tree search methods,2012, IEEE Transactions on Computational Intelligence and AI ingames
 Sample-efficient reinforcement learning with stochastic ensemble value expansion,2018, In AdvanCeS in NeUraIInfOrmatiOn PrOCeSSing Systems
 Exploration by random networkdistillation,2018, CoRR
 Transpositions and move groups in montecarlo tree search,2008, In Proceedings of the 2008 IEEE SymPOSiUm on Computational Intelligenceand Games
 Deep reinforcementlearning in a handful of trials using probabilistic dynamics models,2018, In NeUrIPS 2018
 IntrOdUCtiOn toalgorithms,2009, MIT press
 Experiments with the graph traverser program,1966, Proceedings ofthe Royal SOCiety ofLondon
 Go-explore:a new approach for hard-exploration problems,2019, CoRR
 Search on the replay buffer: Bridgingplanning and reinforcement learning,2019, In Hanna M
 Treeqn and atreec:Differentiable tree planning for deep reinforcement learning,2017, CoRR
 Model-based value estimation for efficient model-free reinforcement learning,2018, CoRR
 Anintroduction to deep reinforcement learning,2018, Found
 Ex2: Exploration with exemplar models for deepreinforcement learning,2017, In AdvanCes in neural information PrOCessing systems
 Learning to search with MCTSnets,2018, In ICML
 Efficient exploration with self-imitation learning via trajectory-conditioned policy,2019, CoRR
 Soft actor-critic: Off-policy maxi-mum entropy deep reinforcement learning with a stochastic actor,2018, arXiv PrePrint arXiv:1801
 Learning latent dynamics for planning from pixels,2019, In International COnferenCe onMaChine Learning
 Dream to con-trol: Learning behaviors by latent imagination,2020, In 8th International COnferenCe on LearningRePresentations
 A formal basis for the heuristic determinationof minimum cost paths,1968, IEEE transactions on Systems SCience and Cybemetics
 Explicit explore-exploit algorithms in continuous state spaces,2019, In Advances in NeuralInfOrmatiOn PrOCessing Systems
 Vime:Variational information maximizing exploration,2016, In AdvanCeS in NeUral Information ProcessingSystems
 Model based reinforcement learningfor atari,2020, In 8th Intemational ConferenCe on Learning RePreSentationS
 Improved monte-carlo search,2006, Univ
 Discor: Corrective feedback in reinforcementlearning via distribution correction,2020, arXiv PrePrint arXiv:2003
 Model-ensembletrust-region policy optimization,2018, In 6th International ConferenCe on Learning RePreSentations
 Bandit algorithms,2020, Cambridge University Press
 Sunrise: A simple unifiedframework for ensemble learning in deep reinforcement learning,2020, arXiv PrePrint arXiv:2007
 Count-based exploration withthe successor representation,2020, In Proceedings of the AAAI Conference on ArtifiCiaI Intelligence
 Solving the rubikâ€™s cubewith approximate policy iteration,2019, In 7th InternationaI ConferenCe on Learning RePreSentations
 Asynchronous methods for deep reinforcementlearning,2016, In International ConferenCe on machine Iearning
 Neural network dy-namics for model-based deep reinforcement learning with model-free fine-tuning,2018, In 2018IEEE IntemationaI ConferenCe on RobotiCS and Automation
 Neural network dy-namics for model-based deep reinforcement learning with model-free fine-tuning,2018, In 2018 IEEEInternational COnference on Robotics and AUtOmatiOn (ICRA)
 Value prediction network,2017, In IsabelleGuyon
 Single-agent policy treesearch with guarantees,2018, In AdvanCeS in NeUral InfOrmatiOn Processing SyStemS 31: AnnUalConference on NeUral InfOrmatiOn Processing SyStemS 2018
 Deep exploration viabootstrapped dqn,2016, AdvanCeS in neural information PrOCeSSing systems
 Randomized prior fUnctions for deep reinforcementlearning,2018, In NeUrIPS
 Deep exploration via randomizedvalue functions,2019, J
 CoUnt-based explorationwith neural density models,2017, arXiv PrePrint arXiv:1703
 Curiosity-driven explorationby self-supervised prediction,2017, In Doina Precup and Yee Whye Teh (eds
 Learning compositional neural programs withrecursive tree search and planning,2019, In NeUrIPS
 Imagination-augmented agents for deep reinforcement learning,2017, In NIPS
 Deep abstract q-networks,2018, In Proceedingsof the 17th International COnferenCe on Autonomous AgentS and MUItiAgent Systems
 Model-based active exploration,2019, InInternatiOnal COnferenCe on MaChine Learning
 Masteringthe game of Go without human knowledge,2017, Nature
 Universal planningnetworks,2018, CoRR
 Incentivizing exploration in reinforcementlearning with deep predictive models,2015, arXiv PrePrint arXiv:1507
 Planning to be surprised: Optimal bayesian ex-ploration in dynamic environments,2011, In International COnferenCe on ArtifiCial General Intelligence
 ReinfOrCement Iearning: An introduction,2018, MIT press
 On the likelihood that one unknown probability exceeds another in view ofthe evidence oftwo samples,1933, Biometrika
 Interaction-limited inverse reinforcement learning,2020, arXiv PrePrint arXiv:2007
 Benchmarking model-based reinforcementlearning,2019, CoRR
 Learning to combatcompounding-error in model-based reinforcement learning,2019, CoRR
n_visits J 1elsestate,2021,n_visits J state
