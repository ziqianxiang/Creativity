title,year,conference
 Deep speech 2:End-to-end speech recognition in english and mandarin,2016, In ICML
 Obfuscated gradients give a false sense ofsecurity: Circumventing defenses to adversarial examples,2018, In ICML
 Decision-based adversarial attacks: Reliableattacks against black-box machine learning models,2018, In ICLR
 Towards evaluating the robustness of neural networks,2017, In 2017ieee symposium on security and privacy (sp)
 Unlabeleddata improves adversarial robustness,2019, In NeurIPS
 Deepdriving: Learning affordance fordirect perception in autonomous driving,2015, In ICCV
 Ead: Elastic-net attacks todeep neural networks via adversarial examples,2018, In AAAI
 Reliable evaluation of adversarial robustness with an ensembleof diverse parameter-free attacks,2020, In ICML
 Torchmeta:A meta-learning library for pytorch,2019, arXiv preprint arXiv:1909
 Bert: Pre-training of deepbidirectional transformers for language understanding,2018, arXiv preprint arXiv:1810
 Model-agnostic meta-learning for fast adaptation ofdeep networks,2017, In ICML
 Identity mappings in deep residualnetworks,2016, In ECCV
 Deep networks withstochastic depth,2016, In ECCV
 The robust manifolddefense: Adversarial training using generative models,2017, arXiv preprint arXiv:1712
 Testing robustness againstunforeseen adversaries,2019, arXiv preprint arXiv:1908
 Functional adversarial attacks,2019, In NeurIPS
 Meta dropout: Learning to perturblatent features for generalization,2020, In ICLR
 Adversarial robustness against the union of multipleperturbation models,2020, In ICML
 Metric learning foradversarial robustness,2019, In AAAI
 Readingdigits in natural images with unsupervised feature learning,2011, In Workshop on Deep Learning andUnsupervised Feature Learning
 Regularizing deep neuralnetworks by noise: Its interpretation and optimization,2017, In NeurIPS
 Foolbox: A python toolbox to benchmarkthe robustness of machine learning models,2017, In Reliable Machine Learning in the Wild Workshop
 A simple way to make neural networks robust against diverse imagecorruptions,2020, In ECCV
 Defense-GAN: Protecting classifiersagainst adversarial attacks using generative models,2018, In ICLR
 Deep learning in medical image analysis,2017, Annualreview of biomedical engineering
 Pixeldefend:Leveraging generative models to understand and defend against adversarial examples,2018, In ICLR
 Adversarial training and robustness for multiple perturbations,2019, InNeurIPS
 On adaptive attacks toadversarial example defenses,2020, In NeurIPS
 Fast is better than free: Revisiting adversarial training,2020, InICLR
 Gat: Generative adversarial training foradversarial example detection and robust classification,2020, In ICLR
 Wide residual networks,2016, In British Machine VisionConference
