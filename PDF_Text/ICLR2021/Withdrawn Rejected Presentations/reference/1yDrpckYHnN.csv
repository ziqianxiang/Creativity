title,year,conference
 Neural machine translation by jointlylearning to align and translate,2015, In International Conference on Learning Representations
 Synthetic and natural noise both break neural machine trans-lation,2018, In International Conference on Learning Representations
 Tagged back-translation,2019, arXiv preprintarXiv:1906
 Robust neural machine translation with doublyadversarial inputs,2019, In Association for Computational Linguistics
 Understanding back-translation atscale,2018, In Empirical Methods in Natural Language Processing
 Pre-trained language model representations forlanguage generation,2019, arXiv preprint arXiv:1903
 Catastrophic forgetting in connectionist networks,1999, Trends in cognitive sciences
 Jointly learning to alignand translate with transformer models,2019, arXiv preprint arXiv:1909
 Convolutionalsequence to sequence learning,2017, In International Conference on Machine Learning
 Beyond synthetic noise: Deep learning oncontrolled noisy labels,2020, In International Conference on Machine Learning
 Adam: A method for stochastic optimization,2014, arXiv preprintarXiv:1412
 Unsupervisedmachine translation using monolingual corpora only,2017, arXiv preprint arXiv:1711
 Data diversification: An elegant strategy forneural machine translation,2019, arXiv preprint arXiv:1911
 The alignment template approach to statistical machine trans-lation,2004, Computational linguistics
 Deep contextualized word representations,2018, In North American Chapter of theAssociation for Computational Linguistics
 Unsupervised pretraining for sequence to se-quence learning,2016, arXiv preprint arXiv:1611
 Neural machine translation of rare words withsubword units,2016, In Association for Computational Linguistics
 Improving nerual machine translation modelswith monolingual data,2016, In Association for Computational Linguistics
 Lingvo: a modular and scalable frameworkfor sequence-to-sequence modeling,2019, arXiv preprint arXiv:1902
 Mass: Masked sequence to sequencepre-training for language generation,2019, In International Conference on Machine Learning
 Extracting andcomposing robust features with denoising autoencoders,2008, In International Conference on MachineLearning
 mixup: Beyond empiricalrisk minimization,2018, In International Conference on Learning Representations
