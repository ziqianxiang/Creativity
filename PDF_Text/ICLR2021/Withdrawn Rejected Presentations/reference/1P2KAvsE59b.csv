title,year,conference
 Stronger generalization bounds fordeep nets via a compression approach,2018, volume 80 of Proceedings of Machine Learning Research
 Spectrally-normalized margin bounds forneural networks,2017, In Advances in Neural Information Processing Systems
 Reconciling modern machine-learning practice and the classical bias-variance trade-off,2019, Proceedings of the National Academyof Sciences
 The state of sparsity in deep neural networks,2019, arXivpreprint arXiv:1902
 Identity mappings in deep residualnetworks,2016, In European conference on computer vision
 Fantas-tic generalization measures and where to find them,2020, In International Conference on LearningRepresentations
 Network in network,2014, CoRR
 On the importanceof single directions for generalization,2018, In International Conference on Learning Representations
 Norm-based capacity control in neu-ral networks,2015, volume 40 of Proceedings of Machine Learning Research
 Exploring general-ization in deep learning,2017, In Advances in Neural Information Processing Systems
 Comparing rewinding and fine-tuning in neuralnetwork pruning,2020, In International Conference on Learning Representations
 Stochastic complexity and modeling,1986, The annals of statistics
 Revisiting the train loss: anefficient performance estimator for neural architecture search,2020, arXiv preprint arXiv:2006
 Equivalence and synthesis of causal models,1991, UCLA
 Picking winning tickets before training bypreserving gradient flow,2020, In International Conference on Learning Representations
 Non-vacuous gen-eralization bounds at the imagenet scale: a pac-bayesian compression approach,2019, In InternationalConference on Learning Representations
