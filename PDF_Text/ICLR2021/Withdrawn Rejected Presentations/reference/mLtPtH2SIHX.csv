title,year,conference
 Variationalinformation distillation for knowledge transfer,2019, In arXiv
 Neural machine translation by jointlylearning to align and translate,2015, ICLR
 On mixup regulariza-tion,2020, 2020
 A downsamPled variant of imagenet as analternative to the CIFAR datasets,2017, In arXiv
 Autoaugment:Learning augmentation strategies from data,2019, In CVPR
 SuPermix: SuPer-vising the mixing data augmentation,2020, arXiv preprint arXiv:2003
 Born again neural networks,2018, In ICML
 SPeech recognition with deePrecurrent neural networks,2013, CoRR
 Nonlinear mixuP: Out-of-manifold data augmentation for text classification,2020, In AAAI
 MixuP as locally linear out-of-manifold regulariza-tion,2019, In AAAI
 ComParing biases for minimal network construction withback-ProPagation,1988, In NIPS
 Identity maPPings in deeP residualnetworks,2016, CoRR
 Augmix: A simPle data Processing method to imProve robustness and uncertainty,2020, InICLR
 Distilling the knowledge in a neural network,2015, InarXiv
 Densely connected convolutionalnetworks,2017, In 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)
 Deep networks withstochastic depth,2016, CoRR
 Data augmentation by pairing samples for images classification,2018,	CoRR
 Batch normalization: Accelerating deep network training byreducing internal covariate shift,2015, CoRR
 Puzzle mix: Exploiting saliency and localstatistics for optimal mixup,2020, In ICML
 Imagenet classification with deep convolu-tional neural networks,2012, In NIPS
 Gradient-based learning applied to documentrecognition,1998, Proceedings of the IEEE
 On feature normalizationand data augmentation,2020, In arXiv
 Attribute mix: Semantic data augmentationfor fine grained recognition,2020, CoRR
 Self-distillation amplifies regularizationin hilbert space,2020, In arXiv
 Regularizingneural networks by penalizing confident output distributions,2017, In ICLR workshop
 Transformation invariance inpattern recognition-tangent distance and tangent propagation,1998, In Neural Networks: Tricks of theTrade
 Improved mixed-example data augmentation,2019, In IEEEWinter Conference on Applications of Computer Vision
 Rethinking the inception architecturefor computer vision,2016, In CVPR
 Manifold mixup: Better representations by interpolating hidden states,2019, InKamalika Chaudhuri and Ruslan Salakhutdinov (eds
 Attentive cutmix: Anenhanced data augmentation approach for deep learning based image classification,2020, CoRR
 Training deep neural networks ingenerations: A more tolerant teacher educates better students,2019, In AAAI
 Wide residual networks,2016, In Proceedings of the BritishMachine Vision Conference 2016
 mixup: Beyond empiricalrisk minimization,2018, In ICLR
 Learning deepfeatures for discriminative localization,2016, In IEEE Conference on Computer Vision and PatternRecognition (CVPR)
