title,year,conference
 Online continual learning with maximal interfered retrieval,2019, In Advancesin Neural Information Processing Systems 
 Gradient based sample selectionfor online continual learning,2019, In Advances in Neural Information Processing Systems
 Learning to continually learn,2020, arXiv preprint arXiv:2002
 Mixmatch: A holistic approach to semi-supervised learning,2019, In Advances in NeuralInformation Processing Systems
 Efficientlifelong learning with a-GEM,2019, In International Conference on Learning Representations
 Continual learning with tiny episodicmemories,2019, arXiv preprint arXiv:1902
 Randaugment: Practical automateddata augmentation with a reduced search space,2019, arXiv preprint arXiv:1909
 Uncertainty-guidedcontinual learning with bayesian neural networks,2019, arXiv preprint arXiv:1906
 Adver-sarial continual learning,2020, arXiv preprint arXiv:2003
 Lifelong machine learning with deep streaming lineardiscriminant analysis,2019, arXiv preprint arXiv:1909
 Memory efficient experience replay forstreaming learning,2019, In 2019 International Conference on Robotics and Automation (ICRA)
 Deep residual learning for imagerecognition,2016, In Proceedings of the IEEE conference on computer vision and pattern recognition
 Lifelong learning viaprogressive distillation and retrospection,2018, In Proceedings of the European Conference on ComputerVision (ECCV)
 Re-evaluating continual learningscenarios: A categorization and case for strong baselines,2018, arXiv preprint arXiv:1810
 Generalized odin: Detecting out-of-distribution image without learning from out-of-distribution data,2020, arXiv preprint arXiv:2002
 Meta-learning representations for continual learning,2019, In Advancesin Neural Information Processing Systems
 Self-supervised visual feature learning with deep neural networks: Asurvey,2020, IEEE Transactions on Pattern Analysis and Machine Intelligence
 Deep generative dual memory network for continuallearning,2017, arXiv preprint arXiv:1710
 Measuringcatastrophic forgetting in neural networks,2018, AAAI Conference on Artificial Intelligence
 Overcomingcatastrophic forgetting in neural networks,2017, Proceedings of the national academy of sciences
 Learning multiple layers of features from tiny images,2009, TechReport
 Manifold graph with learned prototypesfor semi-supervised image classification,2019, arXiv preprint arXiv:1906
 Tiny imagenet visual recognition challenge,2015, CS 231N
 Pseudo-label : The simple and efficient semi-supervised learning method for deepneural networks,2013, ICML 2013 Workshop : Challenges in Representation Learning (WREPL)
 Overcoming catastrophic forgetting withunlabeled data in the wild,2019, In Proceedings of the IEEE International Conference on ComputerVision
 A simple unified framework for detectingout-of-distribution samples and adversarial attacks,2018, In Advances in Neural Information ProcessingSystems
 A neural dirichlet process mixture modelfor task-free continual learning,2020, arXiv preprint arXiv:2001
 Learning without forgetting,2017, IEEE transactions on pattern analysisand machine intelligence
 Enhancing the reliability of out-of-distributionimage detection in neural networks,2017, arXiv preprint arXiv:1706
 Core50: a new dataset and benchmark for continuousobject recognition,2017, arXiv preprint arXiv:1705
 Virtual adversarial training: aregularization method for supervised and semi-supervised learning,2018, IEEE transactions on patternanalysis and machine intelligence
 A wholistic view ofcontinual learning with deep neural networks: Forgotten lessons and the bridge to active and openworld learning,2020, arXiv preprint arXiv:2009
 Realisticevaluation of deep semi-supervised learning algorithms,2018, In Advances in Neural InformationProcessing Systems
 Continuallifelong learning with neural networks: A review,2019, Neural Networks
 icarl:Incremental classifier and representation learning,2017, In 2017 IEEE Conference on Computer Visionand Pattern Recognition
 Wandering within aworld: Online contextualized few-shot learning,2020, arXiv preprint arXiv:2007
 Experiencereplay for continual learning,2019, In Advances in Neural Information Processing Systems
 Progressive neural networks,2016, arXiv preprintarXiv:1606
 Structured compression and sharing ofrepresentational space for continual learning,2020, arXiv preprint arXiv:2001
 Continual learning with deep generativereplay,2017, In I
 Fixmatch: Simplifying semi-supervised learning withconsistency and confidence,2020, arXiv preprint arXiv:2001
 Unsupervised and semi-supervised learning with categorical generativeadversarial networks,2015, arXiv preprint arXiv:1511
 Mean teachers are better role models: Weight-averaged consistencytargets improve semi-supervised deep learning results,2017, In I
 Functional regularisation for continual learning with gaussian processes,2019, In InternationalConference on Learning Representations
 Three scenarios for continual learning,2019, arXiv preprintarXiv:1904
 Continuallearning with hypernetworks,2019, arXiv preprint arXiv:1906
 B-cnn: branch convolutional neural network for hierarchical classifica-tion,2017, arXiv preprint arXiv:1709
