title,year,conference
 Backward feature correction: How deep learning performs deeplearning,2020, arXiv preprint arXiv:2001
 Obfuscated gradients give a false sense of se-curity: Circumventing defenses to adversarial examples,2018, In International Conference on MachineLearning
 Towards evaluating the robustness of neural networks,2017, In 2017IEEE symposium on Security and Privacy (SP)
 Zoo: Zeroth order opti-mization based black-box attacks to deep neural networks without training substitute models,2017, InProceedings of the 10th ACM Workshop on Artificial Intelligence and Security
 Certified adversarial robustness via randomizedsmoothing,2019, In International Conference on Machine Learning
 Stochastic activation pruning for robust adversarialdefense,2018, In International Conference on Learning Representations
 Explaining and harnessing adversarialexamples,2015, 2015
 Parametric noise injection: Trainable randomnessto improve deep neural network robustness against adversarial attack,2019, In Proceedings of the IEEEConference on Computer Vision and Pattern Recognition
 Orthogonaldeep models as defense against black-box attacks,2020, IEEE Access
 Learning multiple layers of features from tiny images,2009, Masterâ€™s thesis
 Adversarial machine learning at scale,2017, InInternational Conference on Learning Representations
 Towards robust neural networks viarandom self-ensemble,2018, In Proceedings of the European Conference on Computer Vision (ECCV)
 Delving into transferable adversarial exam-ples and black-box attacks,2017, 2017
 On detecting adversarialperturbations,2017, 2017
 Distillation as adefense to adversarial perturbations against deep neural networks,2016, In 2016 IEEE Symposium onSecurity and Privacy (SP)
 Practical black-box attacks against machine learning,2017, In Proceedings of the 2017 ACMon Asia Conference on Computer and Communications Security
 Certified defenses against adversarial exam-ples,2018, In International Conference on Learning Representations
 Very deep convolutional networks for large-scale imagerecognition,2015, In International Conference on Learning Representations
 One pixel attack for fooling deepneural networks,2019, IEEE Transactions on Evolutionary Computation
 Intriguing properties of neural networks,2014, 2014
 Adversarial attack typei: Cheat classifiers by significant changes,2019, IEEE Transactions on Pattern Analysis and MachineIntelligence
 On adaptive attacks toadversarial example defenses,2020, arXiv preprint arXiv:2002
 Mitigating adversarialeffects through randomization,2018, In International Conference on Learning Representations
 Feature denoisingfor improving adversarial robustness,2019, In Proceedings of the IEEE Conference on Computer Visionand Pattern Recognition
 Feature squeezing: Detecting adversarial examples in deepneural networks,2018, 2018
