title,year,conference
 Towards robust interpretability with self-explaining neuralnetworks,2018, In Advances in Neural Information Processing Systems
 Random forests,2001, Machine Learning
 Explaining image classifiers by counter-factual generation,2019, In International Conference on Learning Representations
 This looks like that: Deep learning forinterpretable image recognition,2019, In Advances in Neural Information Processing Systems
 Learning to explain: An information-theoreticperspective on model interpretation,2018, In International Conference on Machine Learning
 Xgboost: A scalable tree boosting system,2016, In International Conference onKnowledge Discovery and Data Mining
 Infogan: Interpretablerepresentation learning by information maximizing generative adversarial nets,2016, In Advances inNeural Information Processing Systems
 Stargan: Unified generative adversarialnetworks for multi-domain image-to-image translation,2018, In Conference on Computer Vision andPattern Recognition
 Describing textures in the wild,2014, InConference on Computer Vision and Pattern Recognition
 Algorithmic transparency via quantitative input influence: Theoryand experiments with learning systems,2016, In IEEE Symposium on Security and Privacy
 ImageNet: A Large-Scale HierarchicalImage Database,2009, In Conference on Computer Vision and Pattern Recognition
 Learning disentangled joint continuous and discrete representations,2018, In Advances inNeural Information Processing Systems
 Explaining and harnessing adversarial examples,2015, InInternational Conference on Learning Representations
 Counterfactual visual explanations,2019, InInternational Conference on Machine Learning
 Deep residual learning for image recognition,2016, In Conferenceon Computer Vision and Pattern Recognition
 Attgan: Facial attribute editing by only changingwhat you want,2019, IEEE Transactions on Image Processing
 Grounding visual explanations,2018, In EuropeanConference on Computer Vision
 Image-to-image translation with conditional adversarialnetworks,2017, In Conference on Computer Vision and Pattern Recognition
 Interpretabilitybeyond feature attribution: Quantitative testing with concept activation vectors,2018, In InternationalConference on Machine Learning
 Auto-encoding variational bayes,2014, In International Conference onLearning Representations
 Fader networks: Ma-nipulating images by sliding attributes,2017, In Advances in Neural Information Processing Systems
 Analysis of regression in game theory approach,2001, Applied StochasticModels in Business and Industry
 STGAN: A unified selective transfernetwork for arbitrary image attribute editing,2019, In Conference on Computer Vision and PatternRecognition
 Generative counterfactual introspection for explain-able deep learning,2019, In Global Conference on Signal and Information Processing
 Deep learning face attributes in the wild,2015, In InternationalConference on Computer Vision
 A unified approach to interpreting model predictions,2017, In Advances inNeural Information Processing Systems
 Towards deep learning modelsresistant to adversarial attacks,2018, In International Conference on Learning Representations
 Adversarial autoencoders,2016, In InternationalConference on Learning Representations
 Numerical Optimization,2006, Springer
 ”Why should I trust you?”: Explaining the predictions ofany classifier,2016, In Special Interest Group on Knowledge Discovery and Data Mining
 ExplainGAN: Model explanation viadecision boundary crossing transformations,2018, In European Conference on Computer Vision
 Learning factorial codes by predictability minimization,1991, Technical report
 Restricting the flow: Information bottlenecks forattribution,2020, In International Conference on Learning Representations
 A value for n-person games,1953, In Contribution to the theory of games
 Learning important features through propagatingactivation differences,2017, In International Conference on Machine Learning
 Transformation importance with appli-cations to cosmology,2020, In ICLR Workshop on Fundamental Science in the era of AI
 Explanation by progressive exaggeration,2020, InInternational Conference on Learning Representations
 Explaining prediction models and individual predictions with fea-ture contributions,2014, Knowledge and Information Systems
 Axiomatic attribution for deep networks,2017, In InternationalConference on Machine Learning
 Intriguingproperties of neural networks,2014, In International Conference on Learning Representations
 Learning deep features for discrimi-native localization,2016, In Conference on Computer Vision and Pattern Recognition
 Unpaired image-to-image translation using cycle-consistentadversarial networks,2017, In International Conference on Computer Vision
 Visualizing deep neural network decisions:Prediction difference analysis,2017, In International Conference on Learning Representations
