title,year,conference
 Obfuscated gradients give a false sense ofsecurity: Circumventing defenses to adversarial examples,2018, CoRR
 Random smoothing might be unableto certify 'âˆž robustness for high-dimensional images,2020, arXiv preprint arXiv:2002
 Parsevalnetworks: Improving robustness to adversarial examples,2017, In International Conference on MachineLearning
 Certified adversarial robustness via randomizedsmoothing,2019, In Kamalika Chaudhuri and Ruslan Salakhutdinov (eds
 Mma training: Directinput space margin maximization through adversarial training,2020, In International Conference onLearning Representations
 Training verified learners with learned ver-ifiers,2018, arXiv preprint arXiv:1805
 Explaining and harnessing adversarialexamples,2015, In International Conference on Learning Representations
 Regularisation of neural networksby enforcing lipschitz continuity,2018, arXiv preprint arXiv:1804
 On the effectiveness of interval bound propagation fortraining verifiably robust models,2018, arXiv preprint arXiv:1810
 Learning with a strong adver-sary,2015, arXiv preprint arXiv:1511
 Batch normalization: Accelerating deep network training byreducing internal covariate shift,2015, In International Conference on Machine Learning
 Empirical margin distributions and bounding thegeneralization error of combined classifiers,2002, The Annals of Statistics
 Curse of dimensionality onrandomized smoothing for certifiable robustness,2020, arXiv preprint arXiv:2002
 Certifiedrobustness to adversarial examples with differential privacy,2018, arXiv preprint arXiv:1802
 Second-order adversarial attack andcertifiable robustness,2018, CoRR
 Differentiable abstract interpretation for prov-ably robust neural networks,2018, In International Conference on Machine Learning
 Certified defenses against adversarial exam-ples,2018, In International Conference on Learning Representations
 Provably robust deep learning via adversarially trained smoothed classifiers,2019, InAdvances in Neural Information Processing Systems
 Intriguing properties of neural networks,2013, CoRR
 Lipschitz-margin training: Scalable certifi-cation of perturbation invariance for deep neural networks,2018, In Advances in neural informationprocessing systems
 Mixtrain: Scalable training of formallyrobust neural networks,2018, arXiv preprint arXiv:1811
 Towards fast computation of certified robustness for ReLU networks,2018, InJennifer Dy and Andreas Krause (eds
 Provable defenses against adversarial examples via the convex outeradversarial polytope,2018, In Jennifer Dy and Andreas Krause (eds
 Provable defenses against adversarial examples via the convex outeradversarial polytope,2018, In International Conference on Machine Learning
 Randomizedsmoothing of all shapes and sizes,2020, arXiv preprint arXiv:2002
