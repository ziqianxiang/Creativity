title,year,conference
 Spinning Up in Deep Reinforcement Learning,2018, 2018
 Noisy networks for exploration,2018, In 6th International Conferenceon Learning Representations
 Addressing function approximation error inactor-critic methods,1582, In Jennifer G
 Soft actor-critic: Off-policymaximum entropy deep reinforcement learning with a stochastic actor,2018, In Jennifer G
 VIME:variational information maximizing exploration,2016, In Daniel D
 Near-optimal regret bounds for reinforcementlearning,2010, J
 Adam: A method for stochastic optimization,2015, In YoshuaBengio and Yann LeCun (eds
 Variational dropout and the local reparameter-ization trick,2015, CoRR
 Policy search for motor primitives in robotics,2008, In Daphne Koller
 Continuous control with deep reinforcement learning,2016, In YoshuaBengio and Yann LeCun (eds
 Acquisition of stand-up behavior by a real robot using hierarchicalreinforcement learning,2000, In Pat Langley (ed
 Count-based explo-ration with neural density models,2017, In Doina Precup and Yee Whye Teh (eds
 Curiosity-driven explorationby self-supervised prediction,2017, In Doina Precup and Yee Whye Teh (eds
 Natural actor-critic,2005, In Joao Gama
 Parameter space noise for explo-ration,2018, In 6th International Conference on Learning Representations
 Trust re-gion policy optimization,2015, In Francis R
 Proximal policyoptimization algorithms,2017, CoRR
 Parameter-exploring policy gradients,2010, Neural Networks
 Stochastic activationactor critic methods,1190, In Ulf Brefeld
 Simple statistical gradient-following algorithms for connectionist reinforcementlearning,1992, Mach
 Maximum entropyinverse reinforcement learning,2008, In Dieter Fox and Carla P
