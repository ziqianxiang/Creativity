title,year,conference
 Understanding intermediate layers using linear classifierprobes,2016, arXiv preprint arXiv:1610
 Deep variational informationbottleneck,2016, arXiv preprint arXiv:1612
 The vector representation of a sample,1934, Mathematical Proceedings of the CambridgePhilosophical Society
 Representation learning: A review and newperspectives,2013, IEEE Transactions on Pattern Analysis and Machine Intelligence
 The Normal Distribution: Characterizations with Applications,1995, Lecture Notesin Statistics
 Fisher lecture: Dimension reduction in regression,2007, Statistical Science
 A framework for the quantitative evaluation ofdisentangled representations,2018, In International Conference on Learning Representations
 Learning implicit generative models with theoreticalguarantees,2020, arXiv preprint arXiv:2002
 beta-vae: Learning basic visual concepts with aconstrained variational framework,2017, In 5th International Conference on Learning Representations
 Towards a definition of disentangled representations,2018, ArXiv
 Learning deep representations by mutual information esti-mation and maximization,2018, arXiv preprint arXiv:1808
 Densely connectedconvolutional networks,2017, In Proceedings of the IEEE Conference on Computer Vision and PatternRecognition
 Fast computing for distance covariance,2016, Technometrics
 Spinalnet: Deep neural network with gradual input,2020, arXivpreprint arXiv:2007
 Disentangling by factorising,2018, In International Conference onMachine Learning
 Adam: A method for stochastic optimization,2014, arXiv preprintarXiv:1412
 Imagenet classification with deep convo-Iutional neural networks,2012, In Advances in neural information processing Systems
 Variational inference of disen-tangled latent concepts from unlabled observations,2018, In International Conference on LearningRepresentations
 Mnist handwritten digit database,2010, 2010
 Illustrations of the dynamical theory of gases,1860, part i
 Estimating divergence functionalsand the likelihood ratio by convex risk minimization,2010, IEEE Transactions on Information Theory
 f-gan: Training generative neural samplersusing variational divergence minimization,2016, In Advances in neural information processing systems
 Representation learning with contrastive predic-tive coding,2018, arXiv preprint arXiv:1807
 Learning deep disentangled embeddings with the f-statisticloss,2018, ArXiv
 Convex analysis,1970, Princeton University Press
 Deep network approximation characterized bynumber of neurons,2019, arXiv preprint arXiv:1906
 Opening the black box of deep neural networks via informa-tion,2017, arXiv preprint arXiv:1703
 Curl: Contrastive unsuPervised rePresenta-tions for reinforcement learning,2020, arXiv preprint arXiv:2004
 Optimal global rates of convergence for nonparametric regression,1982, The Annals ofStatistics
 Measuring and testing dependence bycorrelation of distances,2007, The Annals of Statistics
 Deep learning and the information bottleneck principle,2015, In2015 IEEE Information Theory Workshop (ITW)
 The information bottleneck method,2000, ArXiv
 Wasserstein auto-encoders,2018, In International Conference on Learning Representations
 On mutualinformation maximization for representation learning,2019, arXiv preprint arXiv:1907
 Distance correlation autoencoder,2018, In 2018International Joint Conference on Neural Networks (IJCNN)
 Fashion-mnist: a novel image dataset for benchmark-ing machine learning algorithms,2017, arXiv preprint arXiv:1708
0	2 or 1	64	1	500	3,2021,0	2
