Figure 1: Programs with the same functionality should have the same underlying representation.
Figure 2: A JavaScript method from the unlabeled training set with two automatically generatedsemantically-equivalent programs. The original method is from the StackEdit Markdown editor.
Figure 3: Histogram of the num-ber of transformed variants permethod during pre-training.
Figure 4: ContraCode pre-trains a neural program encoder fq and transfers it to downstream tasks.
Figure 5: Receiver Operating Characteristic (ROC, left) and Precision-Recall (PR, right) curves forzero-shot classifiers on the code clone detection task. Equal F1 score curves are shown on right.
Figure 6: Pre-trainingquickly converges if nega-tive programs in the queueare frequently changed.
Figure 7: t-SNE (Maaten & Hinton, 2008) plot of program representations learned with maskedlanguage modeling (RoBERTa), contrastive learning (ContraCode), and a hybrid loss (RoBERTa +ContraCode). Transformed variants of the same program share the same color, though colors may besimilar across different programs.
Figure 8:	A JavaScript program from the CodeSearchNet dataset not seen during training and thepredicted method names from a Transformer pre-trained with ContraCode. ContraCode predicts thecorrect method name as its most likely decoding.
Figure 9:	Our model, a variant of DeepTyper pretrained with ContraCode, generates type annotationsfor two programs in the held-out set. The model consistently predicts the correct return typeof functions, and even predicts project-specific types imported at the top of the file. The modelcorresponds to the top row of Table 8, though is not our best performing model.
Figure 10: Histogram of pairwise token dissimilarity for contrastive positives (transformed variantsof the same method) and negatives (transformed variants of different methods). Code transformationsproduce positives with dissimilar token sequences.
Figure 11:	Given a JavaScript code snippet implementing the merge sort algorithm, we applysemantics-preserving transformations to produce functionally-equivalent yet textually distinct codesequences. Compression passes eliminates unnecessary characters such as redundant variable decla-rations and brackets, while mangling passes can change variable names.
Figure 12:	CodeSearchNet code summarization dataset statistics: (a) The majority of code sequencesare under 2000 characters, but there is long tail of programs that span up to 15000 characters long,(b) JavaScript method names are relatively short compared to languages like C] and Java.
