Figure 1: The overview of the proposed method. (A) The workflow of creating decoy-enhancedsaliency maps. (B) The operation of swapping image patches between original and decoy images.
Figure 2: Performance evaluation on ImageNet. (A) Visualization of saliency maps on foregroundand background objects. (B) Fidelity comparison of original saliency method (i.e., “Without decoys”),our method (i.e., “Decoys w/ range aggregation”), and its alternatives: replacing the decoy generation(Eqn. 2) with constant perturbation (i.e., “Constant w/ range aggregation”) or noise perturbation(i.e., “Noise w/ range aggregation”); replacing the decoy aggregation (Eqn. 4) with mean aggregation(i.e., “Decoys w/ mean aggregation”) (See Tab. A4 for more statistics about the performance differ-ences between our method and the baselines). (C) Performance with regard to variant patch size anddifferent number of decoys.
Figure 3: Evaluation results obtained from the SST dataset. (A) Visualization of saliency mapsin each word, where the normalized saliency values are shown for better distinction. (B) Fidelitycomparison of the original saliency method, our method, and its alternatives. Here, the alternativemethods represent the practice of replacing the decoy generation (Eqn. 2) with constant perturbationor noise perturbation as well as the practice of replacing the decoy aggregation (Eqn. 4) with meanaggregation (See Tab. A5 for more statistics about the performance differences).
Figure 4: Robustness to adversarial attacks on images. (A) Visualization of saliency maps underadversarial attacks. (B)~(D) The decoy-enhanced Saliency score is compared to the original Saliencyscore under adversarial attacks, evaluated by sensitivity (See Tab. A6 for more statistics about theperformance differences).
Figure A5: Cascading randomization on VGG16 network. The figure shows the original saliency map(first column) for the terrier. Progression from left to right corresponds to complete randomizationof the pretrained VGG16 network weights from the top layer to the bottom layer. Note that, here,we followed the visualization method in Adebayo et al. (2018) to show the saliency maps, i.e., 0-1normalization. The row labels share the same meanings as the column labels in Fig. 2.
Figure A6: Structural similarity index (SSIM) for Cascading Randomization on VGG16 network.
Figure A7: Visualization of saliency maps under different CNN architectures. Here, the columnlabels are as same as those in Fig. 2. The difference figures share the same colorbar as those in Fig. 2.
Figure A8: Visualization of saliency maps obtained by original saliency methods and our decoy-enhanced versions. “ExpGrad” refers to Expected Gradient, “SGradRage” stands for Smoothgradwith range aggregation, and “IntUniform” represents integrated gradient with uniform baseline. Thedifference figures share the same colorbar as those in Fig. 2.
Figure A9: Fidelity comparision of saliency maps obtained by original saliency methods and ourdecoy-enhanced versions. “ExpGrad” refers to Expected Gradient, “SGradRage” stands for Smooth-grad with range aggregation, and “IntUniform” represents integrated gradient with uniform baseline(See Tab. A7 for more statistics about the performance differences).
