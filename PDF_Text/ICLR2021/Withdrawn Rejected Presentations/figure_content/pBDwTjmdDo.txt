Figure 1: Work Flow of FTSE4.3	Network StructureWe designed a time-efficient, parallelizable Edge Convolution Neural Network called EGC suitablefor FTSE to perform edge convolution on embedding vectors. EGC can handle edge-feature. Therehave been many approaches (Kim et al., 2019; Gong & Cheng, 2019) trying to incorporate Edgefeatures into GCNs. EGNNs introduced the convolution on edges and update edge features in eachlayer together with the node feature. Attention-based approaches incorporate edge feature in atten-tion score, which is determined by the significance of correlation between nodes (Xu et al., 2020).
Figure 2: (a) ROC-AUC score on Node Classification task of Elliptic dataset (b) Average Preci-sion on Node Classification task of Elliptic dataset (c) ROC-AUC score on Edge Classification taskof Reddit dataset (d) Average Precision on Edge Classification task of Reddit dataset. Mean andstandard deviation is reported based on 20 runs of algorithmsthe average precision benchmark(AP), many previous approaches are still achieving commendableresults. We also achieve moderate convergence speed compared with previous work.
Figure 3: Running Time Result on FTSE and EGCN on three different datasets, the scale is on therunning time of EGCN. FTSEâ€™s time and the standard deviation is adjusted correspondingly, theresult is based on 20 runs of the algorithm under identical settingE FTSE VS TSEWe did experiments comparing FTSE and TSE. The goal is to learn the dynamic graph with highprecision, where we need to use a huge amount of history timesteps (i.e. look back is very high)but could only use fixed-dimension embedding. Both FTSE and TSE are using the same numberof embedding dimensions for the time series and the network is EGCN. The result showed thatFTSE outperforms TSE when the compression ratio is high, justifying its capability of modeling adynamic graph with high precision. On the other hand, we also found that when the compressionratio is lower, TSE performed more favorably. We believe the reasoning behind this symptom iscaused by the information loss in DTFT.
Figure 4: ROC-AUC score on multiple compression ratios where TSE is running with uncompresseddata, the result is based on 20 runs and the dataset is UCI, the granularity was also halved comparedto the regular settings14Under review as a conference paper at ICLR 2021Datasets	UCI		AS		SBM		AUC	AP							AUC	AP	AUC	APGCN	0.464(0.042)	48(22)	0.664(0.030)	314(18)	0.701(0.004)	15949(302)GCN+GRU	0.504(0.022)	146(13)	0.802(0.012)	783(10)	0.700(0.002)	16527(284)GCN+LSTM	0.508(0.021)	145(13)	0.778(0.009)	1454(12)	0.697(0.002)	16549(278)GAT	0.579(0.009)	549(32)	0.838(0.016)	679(30)	0.650(0.012)	13398(280)GAT+GRU	0.506(0.008)	84(16)	0.586(0.013)	223(28)	0.659(0.007)	13695(204)GAT+LSTM	0.504(0.007)	63(14)	0.625(0.014)	303(20)	0.643(0.008)	13284(226)EvolveGCN-O	0.547(0.007)	447(8)	0.895(0.006)	4364(32)	0.697(0.005)	16211(290)EvolveGCN-H	0.552(0.006)	532(9)	0.893(0.008)	4572(28)	0.699(0.004)	16489(227)TGAT	-	-	-	-	-	-TSE	0.706(0.008)	542(11)	0.978(0.003)	2894(49)	0.710(0.008)	16202(140)Fourier TSE	0.704(0.007)	528(12)	0.983(0.007)	2987 (66)	0.708(0.007)	16377(167)Table 4: The ROC-AUC score (AUC) and Average Precision(AP at 1e - 6 scale) on streaming link
