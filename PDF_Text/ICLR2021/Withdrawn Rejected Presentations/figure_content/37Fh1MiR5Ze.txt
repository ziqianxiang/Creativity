Figure 1: Lyapunov exponent λ (blue), inverse curvature from leading eigenvalue 1/h0 (orange),learning rate α (red), and loss (green) curves with cross entropy loss for MLP (top), tinyResNet(middle) and MLP with mean squared error (bottom) on a two-class CIFAR10 problem, with con-Stant (0.1, 0.3 - first two columns, respectively) and cyclic (third column) learning rate schedules.
Figure 2: Lyapunov exponent λ (blue), inverse curvature from leading eigenvalue 1/h0 (orange),learning rate α (red), and loss (green) curves for MLP (column 1), LeNet1 (column 2), and ResNet18(column 3) with softmax cross entropy loss (top) and mean squared loss (bottom) on CIFAR10trained using our quasi-Newton method, i.e., using the estimated 1/h0 as the learning rate. WhileResNet18 is trained on the full CIFAR10 other networks are trained on a two class CIFAR10 prob-lem. The training begins once the estimation of h0 at the initialization is stable. In all our experi-ments, the training is stable and loss decreases monotonically.
Figure 3: The first 14 eigenvalues of the Hessian of the loss averaged over the first epoch.
Figure 4: MLP, LeNet1, tinyResNet with a mean square error and soft-max cross entropy loss trainedon a two classes cifar10 with a constant learning rate (0.05). The linear model regression does nottrain in this setup.
Figure 5: MLP, LeNet1, tinyResNet with a mean square error and soft-max cross entropy loss trainedon a two classes cifar10 with a constant learning rate (0.1). The linear regression does not train inthis setup.
Figure 6: MLP, LeNet1, tinyResNet with a mean square error and soft-max cross entropy loss trainedon a two classes cifar10 with a constant learning rate (0.3). The linear regression and the ResNetwith MSE do not train with this setup.
Figure 7: MLP, LeNet1, tinyResNet with a mean square error and soft-max cross-----loss10-3 ..................
Figure 8: Lyapunov exponent λ (blue), inverse curvature from leading eigenvalue 1/h0 (orange),learning rate α (red), and loss (green) curves for MLP, LeNet1, tinyResNet trained with a softmax-crossentropy loss on a two-class CIFAR10 problem; and ResNet18 trained on all ten CIFAR10classes. All the trainings are with the quasi-Newton method based on method to calculate the largesteigenvalue of the Hessian of the loss.
Figure 9: Lyapunov exponent λ (blue), inverse curvature from leading eigenvalue 1/h0 (orange),learning rate α (red), and loss (green) curves for a linear model, MLP, LeNet1, tinyResNet with amean square error loss trained on the two-class CIFAR-10 problem with a quasi-Newton methodbased on method to calculate the largest eigenvalue of the Hessian of the loss. Notice how the linearleast square regression can be successfully trained.
Figure 10: ResNet18 with soft-max cross entropy loss trained on a cifar10 with our quasi-newtonmethod, a cyclic lr and constant lr of 0.05.
