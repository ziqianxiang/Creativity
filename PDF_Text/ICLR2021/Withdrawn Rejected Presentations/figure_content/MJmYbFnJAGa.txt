Figure 1: Client-drift in FedAvg (left) and Mime (right) is illustrated for 2 clients with 3 local stepsand momentum parameter β = 0.5. The local SGD updates of FEDAVG (shown using arrows forclient 1 and Client2) move towards the average of client optima x1 + x2 which can be quite differentfrom the true global optimum x? . Server momentum only speeds up the convergence to the wrongpoint in this case. In contrast, Mime uses unbiased momentum and applies it locally at every update.
Figure 2: SGDm (dashed black), FedSGDm (top), MimeLiteSGDm (middle), and MimeSGDm(bottom) on simulated data, all with momentum (β = 0.5). FedAvg gets slower as the gradient-dissimilarity (G) increases (to the right). MimeLite shows a similar pattern, but is consistentlybetter than FedAvg. Mime is significantly faster than both and is unaffected by heterogeneity (G).
Figure 3: Server-only, FedAvg, Mime, and MimeLite with SGDm (left) and Adam (middle) runon (top) EMNIST62 and a 2 hidden layer (300u-100) MLP and (bottom) Resnet20 run on Cifar100.
Figure 4: Server-only, FedAvg, Mime, and C-Mime with SGDm (left) and Adam (right) run onEMNIST62 with a 2 hidden layer (300u-100) MLP. C-Mime changes the statistics (momentum forSGDm, and first two moments for Adam) using the local client updates. These changes are discardedat the end of the round and the statistics are reset using only the server level gradients as in Mime.
Figure 5: Comparison with Scaffold and FedProx for cross-device FL: Mime, SCAFFOLD andFedProx with SGDm run on EMNIST62 with a 2 hidden layer (300u-100) MLP. For FedProx andSCAFFOLD, in addition to tuning the learning rate, we search for the best server momentum β ∈[0,0.9,0.99]. FedProx uses an additional regularize1 μ which We search over [0.1,0.5,1] (note thatFedProx with μ = 0 is the same as FedAvg). The best test accuracy (which are plotted here) wasby β = 0 for both and μ = 0.1 for FedProx. Note that FedProx is the slowest method here (infact it is even slower than FedAvg). The additional regularizer does not seem to reduce client driftwhile still slowing down convergence (Karimireddy et al., 2020; Wang et al., 2020b). SCAFFOLDis also slower than Mime in this setup. This is because SCAFFOLD was designed for the cross-silo setting and not corss-device setting. The large number of clients (N = 3.4k) means that eachclient is on averaged visited less than 6 times during the entire training (20 clients per round for 1krounds). Hence, the client control variate stored is quite stale (from about 200 rounds ago) whichslows down the convergence. This perfectly reflects our theoretical understanding that when thenumber of clients N is large relative to training rounds (which is true in the cross-device setting)SCAFFOLD is outperformed by Mime.
