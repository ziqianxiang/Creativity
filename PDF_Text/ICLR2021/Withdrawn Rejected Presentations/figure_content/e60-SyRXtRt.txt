Figure 1: Intuition of using GANs for generating class-targeted baselines in SVHN dataset. Without GANs,a closest target class sample can easily be unrealistic (a), while the GAN helps confine the sample in therealistic sample space (b). The MDTS baseline and other training samples used in expected gradient can bevery different from the input (c). (d) shows the zero baseline that is the most commonly used.
Figure 2: (A) Saliency maps for multi-class datasets (MNIST, SVHN, CIFAR10) generated with various base-lines, including zero baseline (Zero), MDTS and GANMEX, with classes co → ct indicated for each exam-ple. (B) Mis-classification analysis showing with the (mis-classified class, correct class) pairs. The baselinecolumns show the expected images generated by GANMEX for the correct classes, and the saliency maps showthe explanation of ”why not the correct class” produce by IG, DeepLIFT (DL) and occlusion (Occ).
Figure 3: (A-C) Perturbation-based evaluation plots for MNIST and SVHN, respectively. The dashed linesrepresent the non-class-targeted baselines and the solid lines represent class-targeted baselines. (D-F) Giniindices, with the yellow bars represent saliency maps with zero baselines and the green bars represent that ofGANMEX baselines. (G) Sanity checks showing the original saliency maps (Orig) and saliency maps undercascading randomization over the four layers: output layer (Output), fully connected (FC), and two CNN layers(CNN1, CNN2).
Figure 4: Saliency maps for the classifier on the apple2orange dataset with four baseline choices: zero baseline(Zero), maximum value baseline (Max), blurred baseline (Blur), and GANMEX baseline (GANMEX).
Figure 5: (A) Vertical edge area in an SVHN image. (B) Histogram of sample to baseline distance (Dedge (x, X))in the vertical edge area. (C-E) Samples comparing GANMEX and MDTS baselines with Dedge (x, x) indicatedon the top of the baseline images. (C) Easy cases for GANMEX (Dedge(x, x) ≈ 1). (D) Difficult cases forGANMEX (Dedge(x, X) ≈ 3). (E) Difficult cases for GANMEX (Dedge(x, X) ≈ 6).
Figure 6: (A) Cascading randomization on baselines generated by a stand-alone GAN lead to little randomiza-tion on the saliency maps. (B) Colored-MNIST dataset. GAN baselines generated with both similarity loss andreconstruction loss (S+R), similarity loss only (S), reconstruction loss only (R), and none of those (NA). OnlyS+R and S successfully constrained the baselines in the same modes (colors) with the inputs.
Figure 7: GANMEX baselines generated with various weights for the (A) classification loss, (B) similarity loss,and (C) reconstruction loss.
Figure 8: One-vs-one saliency maps using class-targeted baselines (GANMEX) vs non-class-targeted baselines(zero baselines). One-vs-one saliency maps generated using zero baselines show almost the same attributionsregardless of the target class, making the one-vs-one saliency maps (columns with target labels) similar to theone-vs-all saliency maps (the ”Avg” columns that show the averaged saliency maps over all target classes).
Figure 9: Additional examples of saliency maps for the classifier on the apple2orange dataset with four baselinechoices: zero baseline (Zero), maximum value baseline (Max), blurred baseline (Blur), and GANMEX baseline(GANMEX).
