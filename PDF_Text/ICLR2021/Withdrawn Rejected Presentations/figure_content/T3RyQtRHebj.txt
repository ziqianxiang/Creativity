Figure 1: Our method assigns a set of K (K = 3 in this illustration) random weight options to eachconnection. During the forward pass, one of the K values is selected for each connection, basedon a quality score computed for each weight value. On the backward pass, the quality scores of allweights are updated using a straight-through gradient estimator (Bengio et al., 2013), enabling thenetwork to sample better weights in future passes. Unlike the scores, the weights are never changed.
Figure 2: Selecting from only K = 2 weight options per connection already dramatically improvesaccuracy compared to an untrained network that performs at random chance (10%) on both (a)MNIST and (b) CIFAR-10. The first bar in each plot shows the performance of an untrained ran-domly initialized network and the second bar shows the results of selecting random weights withGS using K = 2 options per connection.
Figure 3: Comparison with traditional training on CIFAR-10 and MNIST. Performance of SlotMachines improves by increasing K (here we consider K ∈ {2, 8, 64, 128}) although the gainsafter K ≥ 8 are small. For CONV-6 (the deepest model considered here), our approach using GSachieves accuracy comparable to that obtained with trained weights, while for CONV-2 and CONV-4 it produces performance only slightly inferior to that of the optimized network. Furthermore, asillustrated by the error bars in these plots, the accuracy variances of Slot Machines with GS are muchsmaller than those of networks traditionally trained by optimizing weights. Accuracies are measuredon the test set over five different trials using early stopping on the validation accuracy with a horizonof 30 epochs for all models.
Figure 4: Finetuning Selected Weights. Finetuning Slot Machines improves test set performanceon CIFAR-10. For CONV-4 and CONV-6 this results in better accuracy compared to the samenetworks learned from scratch at comparable training cost (shown on the x axis). All Slot Machineshere use K = 8 options per edge.
Figure 5: Sharing random weights: Slot Machines using the same set of K random weights forall connections in a layer or even in the entire network perform quite well. However, they do notmatch the performance of Slot Machines that use different sets of weights for different connections.
Figure 6: Finetuning from different Slot Ma-chine checkpoints. Slot Machine checkpointshows the number of training epochs used forweight selection before switching to finetuning(performed for 100 epochs). Performance is mea-sured on the test set using early stopping deter-mined by the maximum validation accuracy dur-ing finetuning.
Figure 7: Weight exploration in Slot Ma-chines. The vertical axis shows (on a logscale) the percentage of weights changed af-ter every five epochs as training progresses.
Figure 8: The distributions of the selected weights in the first two convolutional and the first fully-connected layers of CONV-6 on CIFAR-10. Starting from purely uniform distributions, Slot Ma-chines progressively choose large magnitude weights as training proceeds. See Appendix D for plotsshowing similar behavior in other Slot Machines.
Figure 9: In principle, it is possible to obtain our network (left) by pruning a bigger network con-structed ad-hoc (right). In this example, our slot machine uses K = 2 options per connection (i, j).
Figure 10: Distribution of selected weights on MNIST. As noted above, both sampling methodstend to choose larger magnitude weights as oppose to small values. This behavior is more evidentwhen the values are sampled from a Glorot Uniform distribution (bottom) as opposed to a GlorotNormal distribution (top). However, layer 3 which has the fewest number of weights of any layer inthis work continue to select large magnitude weights even when using a normal distribution.
Figure 11: Distribution of selected weights on CIFAR-10. Similar to the plots shown in Figure 8,both CONV-2 and CONV-4 on CIFAR-10 tend to choose increasingly bigger weights in terms ofmagnitude as training progresses. Here, we show the distribution of the selected networks in the firsttwo convolutional layers and the first fully-connected layer of the above networks but all the layersin all slot machines show a similar pattern.
Figure 12: Distribution of selected scores. Different from the selected weights, the selectedscores tend to be normally distributed for both GS and PS. We show only the scores for layer 3 ofLenet because it is the layer with the fewest number of weights. However, the other layers showa similar trend except that the selected scores in them have very narrow distributions which makesthem uninteresting. Notice that although we sample the scores uniformly from the non-negativerange U(0,0.1 * σχ) where σχ is the standard deviation of the Glorot Normal distribution, gradientdescent is able to drive them into the negative region. The scores in PS slot machines move muchfarther away from the initialization compared to those in GS due to the large learning rates used inPS models.
Figure 13: Scores Initialization. The models are sensitive to the range of the sampling distribution.
