Figure 1:	Learning curve comparison between our methods (CSAE and CSAE-WC) and the state-of-the-arts (TRPO, PDO, CPO)for five safe RL problems. First row: safe cumulative reward. Secondrow: total cumulative reward. Third row: cumulative cost. Fourth row: ratio of safe trajectories. Xaxes denote the training iteration. (Best viewed in color). Each curve is obtained by averaging overfive random runs. The standard deviation of different runs is visualized with the shade.
Figure 2:	Agents trained in PointCircle. The grey circle denotes the path with highest reward. Thetwo red dotted lines are the boundaries and the agent is constrained to run between them. Lines withdifferent colors starting from the center are agent trajectories learned with different random seeds.
Figure 3: Agents trained in AntGather. The green circles denote the randomly placed apples tocollect and red-colored squares are the unsafe regions. The blue lines are trajectories of an agenttrying to explore the environment to collect apples.
Figure 4: (a) Comparison of average return on PointCircle for different reward modifications.
Figure 5: Learning curve comparison between our methods (CSAE, WC and CSAE-WC) and thestate-of-the-arts (TRPO, PDO, CPO)for five safe RL problems. First row: safe cumulative reward.
