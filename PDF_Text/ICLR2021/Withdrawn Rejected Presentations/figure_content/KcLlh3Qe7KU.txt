Figure 1: Ensembles of WGANs with fewer total parameters than a single WGAN perform better on CIFAR-10.
Figure 2: Ensembles of WGANs have a performance sweet spot when we regularize the optimization problemin expression (4) with different values of λ. Each curve is calculated using the equivalent ensemble of WGANsdiscussed in Section 5.2. We see that as we increase λ to 0.001, the performance increases but then decreaseswhen we continue to increase λ to 0.01. This implies that there is an optimal value for λ that can be found viahyperparameter tuning. The solid blue line is the equivalent ensemble with λ “ 0.01, the dotted red line is theequivalent ensemble WGAN, and the dashed black line is the equivalent ensemble with λ “ 0.001.
Figure 3: Regularized ensembles of WGANs using the optimization in (4) outperform cWGANs, even thoughcGANs are a type of ensemble. Here, cWGAN actually performs similarly to the baseline WGAN even though ittakes into consideration class information. The solid blue line is the baseline, the dotted red line is the cWGAN,and the dashed black line is the equivalent ensemble with λ “ 0.001.
