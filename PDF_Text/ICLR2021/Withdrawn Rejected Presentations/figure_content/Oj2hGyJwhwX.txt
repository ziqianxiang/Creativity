Figure 1: CIFAR examples of exchanging (Left) and adjusting (Right) RGB mean and variance.
Figure 2: SelfNorm (left) and CrossNorm (right). SelfNorm uses attention to recalibrate the meanand variance of a feature map, while CrossNorm swaps the statistics between a pair of feature maps.
Figure 3: Flowchart for SelfNorm and CrossNorm. SelfNorm learns in training but functions intesting, while CrossNorm works in training.
Figure 4: CrossNorm for semi-supervised CIFAR-10 classification. We apply CrossNorm on top ofFixMatch with weak augmentation (WA) (Left), or strong RandAugment (RA) (Right). For eithercase, CrossNorm (CN) can substantially reduce both clean and corruption errors. Compared withRA, CrossNorm performs domain agnostic data augmentation, easily applicable to new domains.
Figure 5: CrossNorm visualization at image level (Left), the head (Middle) and tail (Right) of block1 in a WideResNet-40-2. Both the content (Row) and style (Column) images are from CIFAR-10.
Figure 6: Visualizing 4 single SelfNorms by comparing images before (Top) and after (Bottom)them. The left two, lying in shallow locations, can adjust styles by suppressing color and adding blur.
Figure 7: Visualizing accumulated SelfNorms by comparing inverted images. SelfNorms in block1 can wash away much style information preserved in the vanilla network. Similarly, the plain net-workâ€™s final representation retains some high-frequency signals which are suppressed by SelfNorms.
Figure 8: Illustration of SelfNorm (SN) and CrossNorm (CN) positions in a residual module.
Figure 9: Study of Modular positions (left) and CrossNorm variants (right). SelfNorm and Cross-Norm both get the lowest errors at the post-addition position. Second, the 2-instance mode consis-tently outperforms the 1-instance one, and proper cropping can decrease the error.
Figure 10: Illustration of SelfNorm (SN) and CrossNorm (CN) positions in AllConvNet block, anddense cells in DenseNet. For blocks in AllConvNet, we name the position after convolution layer as1, after normalization layer as 2, and after GELU layer as 3. For dense cells in DenseNet, we labelthe position before feature concatenation as Pre, and after concatenation as Post.
Figure 11: CrossNorm visualization at the head (Left), the tail of (Middle) block 2 and the startof block 3 (Right) in a WideResNet-40-2. Both the content (Row) and style (Column) imagesare from CIFAR-10. Compared to CrossNorms in block 1, shown in Figure 5, the CrossNorms inblocks 2 and 3 have weaker style transfer effects. Because the channel-wise means and variances inhigh-level feature maps may contain less low-level visual information.
Figure 12: A demostration of corrupted images in ImageNet-C dataset (Hendrycks & Dietterich,2019). 15 types of algorithmically generated corruptions from noise, blur, weather, and digitalcategories are applied to images to create corrupted dataset.
Figure 13: Some examples of segmentation dataset. The first row are images from Cityscapesdataset, while the second row are images from GTA5 dataset.
Figure 14: A visualization of CrossNorm with crop style used on image level. The two images onthe first column are the original images in the GTA5 dataset and are in the same training batch. Weapplied CrossNorm to these two images several times and got the following three pairs of images.
