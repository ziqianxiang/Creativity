Figure 1: Growth process step by step from pixel seed image. Top, sample from the fullNotoColorEmoji dataset. Bottom, sample from the full CIFAR-10 dataset.
Figure 2: Model overview. Beige elements contain trainable parameters while orange layers useonly predicted parameters. See Fig.3 for details of the architecture.
Figure 3:	Architecture Details. Beige elements contain trainable parameters while orange layersuse only predicted parameters. CBn blocks can be CB1 or CB3. All blocks share the same number offilters except the last blocks whose output matches the embedding or parameters dimensionality.
Figure 4:	Growth results. First row is a random set of images from the full NotoColorEmojidataset. Following rows are generated by different variants of NCAM codified as: CE: Continuousencoding, DNA: DNA-encoding; STO: Stochastic update, SYN: Synchronous update; 16-512:number of channels in NCA (16,32) - Dimensionality of the continuous embedding (256, 512, 1024)(DNA dimensionality is 16 times that of continuous).
Figure 5:	Growth results on reduced datasets. For each subset of NotoColorEmoji, first roware random images while the second are generated using DNA-encoding and stochastic update.
Figure 6: “Genetic engineering” results. On top: source images for each of two mean encodings.
Figure 7: CIFAR-10 results using the best methods: Continuous and DNA Encoding with Syn-cronous update and baseline dimensionalities.
