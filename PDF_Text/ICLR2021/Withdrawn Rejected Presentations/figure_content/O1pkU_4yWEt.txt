Figure 1: Model architecture5 Results5.1	Distant labelsUsing distantly-generated labels we calculated the recall of our model on the test dataset. Ourexpectations were that with enough training examples the model should achieve recall close to 1.
Figure 2: Relation between number of training examples and recall on test dataAs can be seen in Table 2 the number of training examples needed to achieve given recall differsbetween classes with some classes needing noticeably more examples. There could be numeroussources of such difference: tokenization, number of synonims, difficult context (substances are oftenas encountered lists mixed with dosages) and others. Even for the harder classes fifty thousandexamples are enough to find nearly all distant labels5.2	Human labelingA major disadvantage of our labelling procedure is its incompletness. Any slight change of knownterm, a typo or a rare abbreviation will lead to missed entities. This makes estimating the precisionof the model impossible with such labels. To compare our model with a human benchmark werandomly selected 1500 records from the testing dataset for hand labelling by a medical practitionerwith 7 years of experience. These records where labeled for 15 most common entities in train dataset.
