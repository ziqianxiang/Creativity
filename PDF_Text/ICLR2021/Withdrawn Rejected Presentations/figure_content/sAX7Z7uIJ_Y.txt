Figure 1: Model overview with an illustrative example where red and blue pixels are verticallysegmented. A fuzzy boundary in the input image x allows for multiple valid ground truth labels yi .
Figure 2: (a) Median and interquartile range (iqr) over the data log-likelihood, averaged over all9×5×2 experiments. (b) High bias and noise configuration (π = 0.9, σ = 0.03) with calibrationloss. The ground truth target is shown as black dots and the predicted samples as light blue dots.
Figure 3: LIDC validation samples. From left to right: an input image x, followed by the four groundtruth annotations yj ... yjt, the mean of the labels ygt, the output of the calibration network Fθ (x),the mean of the six refinement network samples y∙ef, shown in columns y《f... y6f.
Figure 4: (a) Input images overlaid with the corresponding labels. (b) Samples obtained from therefinement network. (c) Aleatoric uncertainty computed as the entropy of the calibration output.
Figure 5: Calibration of the pixelwise probabil-ities of the five stochastic classes. Note that thecalibration network (in orange) is conditioned onblack-box predictions.
Figure 6: Reliability diagram for the calibra-tion network. ECE = 2.15%.
Figure 7: Log-likelihood curves for 5 runs on each of the 9 data configurations. (a) No calibrationloss (λ = 0), averaged. (b) No calibration loss, individual runs. (c) With calibration loss (λ = 1),averaged. (d) With calibration loss, individual runs.
Figure 8: Qualitative results on LIDC samples for the Lcal-regularised cGAN model.
Figure 9: Qualitative results on LIDC samples for the Lcal-regularised cGAN model.
Figure 10: LIDC validation samples for the (a) cVAE-GAN and (b) cGAN+Lce baseline model.
Figure 11: 10 input images, the corresponding aleatoric maps from the calibration network and 16samples from the refinement network. For visualisation purposes, the samples are split into 8 per row.
Figure 12: (a) Three input images overlaid with the corresponding labels; (b) Incoherent samplesfrom the predictive distribution of the calibration network; (c) The aleatoric maps from the calibrationnetwork; (d) Aleatoric maps computed as the entropy of the average of 16 predictions of the refinementnetwork; (e) The entropy of one sample of the refinement network output for each input image.
