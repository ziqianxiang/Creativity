Figure 1: Illustrative example of action recognition in a soccer simulator. The action concept shortpass is composed of other concepts, such as possession and kick.
Figure 2: A TOQ-Net contains three modules: (i) an input feature extractor, (ii) relational reasoninglayers, and (iii) temporal reasoning layers. To illustrate the model’s representational power, we showlogical forms of increasing complexity that can be realized by stacking multiple layers.
Figure 3: Illustration of (i) relational reasoning layers and (ii) temporal reasoning layers. We providetwo illustrative running traces. (i) The first relational reasoning layer takes unary predicates q1 andq2 as input and its output Q1 is able to represent q1 ∧ q2. The max(Q1, dim = 0) in layer 2 canrepresent ∃x. q1(x, t) ∧ q2(x, t). (ii) Assume PK encodes the occurance of events e1 and e2 at eachtime step. The first temporal reasoning layer can realize always e2 with a temporal pooling from timestep 3 to time step T . In the second temporal reasoning layer, the temporal pooling summarizes thate1 holds true from time step 1 to 2. Thus, the NN should be able to realize e1 until (always e2).
Figure 4: Generalization to soccer environmentswith a different court size and agent speeds. Thestandard errors are computed based on three ran-dom seeds.
Figure 5: Comparing different models withdifferent time stretching factors on the RL-Bench dataset.
Figure 6: Comparing # of reasoning layers. When # of relational reasoning layers vary (blue),temporal reasoning layers are fixed at 4. When # of temporal reasoning layers vary (orange), relationreasoning layers are fixed at 3. Accuracy tested on 6v6 9-way classification. Adding reasoning layersimproves results, and 3 relational layers + 4 temporal layers is a good balance between computationand performance.
Figure 7: Relevant features in temporal layers. Feature dependencies are computed by gradient.
