Figure 1: The goal of the proposedalgorithm. In contrast to the existingmethods, our proposed CNN architec-ture predicts the chain of superclassconcepts as well as the finer category.
Figure 2: Partial view of the original (left) and condensed (right) label hierarchies. Concepts are enclosed inrectangular boxes, with number of all descendeants in parentheses. All the parent concepts of the categoriesTraffic Light, Street Sign and Bubble in the original ontology are absorbed to Entity in the compressed ontologyby removing the redundant single parent-child connections and excluding nodes with descendant count < δ .
Figure 3: Schematic view of proposed denseconnections. The solid square and circle nodescorrespond to the concept and category predictionnode respectively, whereas the empty circles de-picts the hidden nodes. We assume the concept γhas Q concepts and B categories as children.
Figure 4: Qualitative comparison between the proposed and the pretrained ResNet50 models on naturallyadversarial images (Hendrycks et al., 2019).
Figure 5: (a): Categories where the proposed method predicted a concept order different from the condensedhierarchy. (b) : Category-wise classification accuracy of the proposed method vs the baseline architecture (w/ResNet50). (c): Progession of validation accuracy of the proposed CNN (blue) and baseline (red).
Figure 6: Qualitative performance of MD-RN trained from AwA2 datasets on images from ImageNet 12validation set. The image ids and MD-RN category predictions are listed on top of each image whereas theconcept predictions are displayed below.
