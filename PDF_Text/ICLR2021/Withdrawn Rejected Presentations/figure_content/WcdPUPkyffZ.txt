Figure 1: Two examples of word alignment.
Figure 2: Illustration of the MirrorAlign, where a pair of sentences are given as example. Each xi andyj are the representation of words in source and target part respectively. Given yj , we can calculatecontext vector in source part. The NCE training objective is encouraging the dot product of thiscontext vector and yj to be large. The process in the other direction is consistent. By stacking all ofthe soft weights, two attention maps As→t and At→s can be produced, which will be bound by anagreement loss to encourage symmetry.
Figure 3: An visualized alignment example. (a-c) illustrate the effects when gradually addingthe symmetric component, (d) shows the result of FastAlign, and (e) is the ground truth. Themore emphasis is placed on the symmetry of the model, the better the alignment results modelachieved. Meanwhile, as depicted, the results of the attention map become more and more diagonallyconcentrated.
Figure 4: Example of the DE-EN alignment. (a) is the result of FastAlign, and (b) shows resultof our model, which is closer to the gold alignment. The horizontal axis shows German sentence“wir glauben nicht , da wir nur rosinen herauspicken sollten .”, and the vertical axis shows Englishsentence “we do not believe that we should cherry-pick .”.
