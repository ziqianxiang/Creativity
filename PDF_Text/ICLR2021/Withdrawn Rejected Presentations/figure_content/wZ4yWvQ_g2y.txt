Figure 1:	Structure of separable convolution.
Figure 2:	(a) an architecture (path) in the supernet. (b) an illustration of block-wise distillation(N = 4 blocks). The supernet (student) and the pre-trained teacher model are divided into blocksrespectively and each student block is trained to mimic the corresponding teacher block.
Figure 3: Loss curve of supernet training.
Figure 4: The pipeline of two-stage distillation.
