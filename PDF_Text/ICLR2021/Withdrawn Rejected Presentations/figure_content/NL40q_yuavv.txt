Figure 1: Pipeline. Networks with trainable parameters are shown in red boxes with round corners.
Figure 2: Few-shot learning v.s. shape representation. Top row: few-shot classification (imagestaken from the dataset miniImageNet). In this figure, we show that 2-shot-3-way few-shot classifi-cation in which every training task contains 3 categories and 2 training samples in each categories.
Figure 3: Top: ground-truth meshes shown in vermilion red. Bottom: predicted meshes shown inblue.
Figure 4: Reconstruction with interpolated feature vectors. Meshes in blue are original, greenmeshes are interpolated.
Figure 5: Top: Dtrain . Bottom: Dtrain in embedding space. We show positive points in red andnegatives points in blue. Also, we visualize the meshes and the meshes in embedding space. Thesevisualizations can be better reviewed in the attached video.
Figure 6: Input images used in Fig. 311Under review as a conference paper at ICLR 2021• sofa* airplane■ lamp+ telephone♦ vessel♦ loudspeaker▲ chair■ cabinet▼ table♦ display♦ car★ bench• rifleFigure 7: T-SNE of the feature of shapes.
Figure 7: T-SNE of the feature of shapes.
Figure 8: L1-Norm of features of shapes.
Figure 9: Reconstruction results with Dtrain . Blue: full set of Dtrain . Green: subset of Dtrain .
Figure 10: Statistics of metric.
