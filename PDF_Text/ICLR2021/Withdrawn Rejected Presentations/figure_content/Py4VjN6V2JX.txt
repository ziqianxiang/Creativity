Figure 1: While many self-supervised approaches optimizefor high-level or low-level tasks, we present an approach tolearn both global and local representations from video.
Figure 2: Our GLCM architecture. For clarity we omit the“channel” dimension and only show the spatial and tempo-ral dimensions. In the “global contrast” pathway, the vi-sual features are shown with different shading patterns (e.g.,diagonal-hatch, filled gray) and indicate those that comefrom different video samples. In the “local contrast” path-way, we use colors to indicate different time windows.
Figure 3: Visualization attention maps showing the audio-visual correlations in learned representa-tions.
