Figure 1: Our model is divided into n contractive paths 夕i, sharing the same architecture andweights, and one expansive path ψ . Blue rectangles represent feature maps and arrows denote thedifferent operations we use (see legend). At training time n = 2, but by duplicating the contractivepaths, we can adapt to the n measures barycenter problem at test time, without needing to retrainthe network.
Figure 2: We illustrate typical results and comparisons to GeomLoss (Feydy, 2019), a linear pro-gram via a network simplex (Bonneel et al., 2011), regularized barycenters computed in log-domain(See for instance Peyre et al. (2019)) with a regularization parameter of 1e-3 and Radon barycen-ters (Bonneel et al., 2015).
Figure 3: We superimpose the centroids (λ1 = λ2 = 0.5) found by the method of Claici et al.
Figure 4: Approximation error of our model compared to the ones of DWE (version adapted tohandle 512 × 512 images), respectively measured in terms of (a) KL-Divergence and (b) L1 distance,on images coming from our synthetic test dataset. Each one of the 1000 × 4 points correspondsto a barycenter. The x-axis represents the error measured betWeen the GeomLoss barycenter andthe barycenter predicted by our model While the y-axis represents the one betWeen the GeomLossbarycenter and the barycenter predicted by DWE. The color of a point associated to a barycenterrepresents its number of inputs.
Figure 5: Interpolations between two 28×28 images from the Quick, Draw! dataset using Geomloss,our model and the original Deep Wasserstein Embedding (DWE) method from (Courty et al., 2017).
Figure 6: Interpolations between two 512 × 512 images from the Quick, Draw! dataset usingGeomloss, our model and the Deep Wasserstein Embedding (DWE) method from (Courty et al.,2017) adapted to handle 512 × 512 images.
Figure 7: Interpolations between two 512 × 512 images from the Coil20 dataset (Nane et al., 1996)using GeomLoss and our model trained with synthetic shape contours. In order to perform compu-tations on the shapes and not on the background, mass has been inverted.
Figure 8: Wasserstein barycenters of three inputs (top rows) and five inputs (bottom rows) fromQuick, Draw!, respectively computed with Geomloss and with our model trained with only pairsfrom our synthetic training dataset. Barycentric weights are randomly chosen.
Figure 9: Wasserstein barycenters of sets of lines or ellipses should result in lines (resp. ellipses).
Figure 10: the learning rate decreased and is periodically restarted to its initial value, the periodincreasing as the number of epochs grows. This schedule was chosen after comparing with stepwiseschedules or constant learning rates and yielded better convergence in practice.
Figure 10: Learning rate schedule used to train our models, following the SGDR method describedby Loshchilov & Hutter (2016). Our training runs for a total of 31 epochs. Compared to a constantlearning rate or to stepwise schedules, SGDR has empirically shown a better convergence in ourcontext.
Figure 11: Additional interpolations between two 512 × 512 images from the Coil20 dataset usingGeomLoss and our model. Mass is inverted.
Figure 12: Interpolations between 5 inputs from Quick, Draw!, shown as pentagons. Left pentagoncorresponds to GeomLoss barycenters while the right one shows predictions of our model trainedon our synthetic dataset.
Figure 13: Stress test. We predict a barycenter of 100 cats of the QuickDraw dataset, with equalweights.
Figure 14: Wasserstein barycenter computed from a pair of inputs respectively using Geomloss withonly one descent step, Geomloss with 10 descent steps and using our model trained on our synthetictraining dataset.
