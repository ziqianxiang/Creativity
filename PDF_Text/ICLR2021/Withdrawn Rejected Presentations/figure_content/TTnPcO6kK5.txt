Figure 1: Performance comparison of Adam, AEGD and our method SEHB on Extended Rosen-brock function. All three methods converge to the optimal solution.
Figure 2: Performance comparison of fully connected neural networks with Adam, AEGD, Ada-Grad, SHB and our method SEHB on MNIST dataset. The left is the training loss curve and theright is the test error curve.
Figure 3: Performance comparison of deep convolution neural networks with Adam, AMSGrad,AdaBound, AEGD, AdaGrad, SHB and our method SEHB on CIFAR-10 dataset. The top row is thetraining loss curve and the test error curve of ResNet-50 while the bottom row is the training losscurve and the test error curve of DenseNet-121.
