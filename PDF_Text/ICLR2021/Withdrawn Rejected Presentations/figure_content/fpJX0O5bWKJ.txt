Figure 1: We compute the variance of gradients (VoG) for each training data point in this twodimensional toy problem. On the right, we show that VoG accords higher scores to the mostchallenging examples closest to the decision boundary (as measured by the perpendicular distance).
Figure 2: The 5×5 grid shows the top-25 Cifar-10 and Cifar-100 training-set images with the lowestand highest VoG scores in the Early (a) and Late (b) training stage respectively of two randomlychosen classes. Lower VoG images evidence uncluttered backgrounds (for both apple and plane) inthe Late training stage. VoG also appears to capture a color bias present during the Early trainingstage for both apple (red). The VoG images in Late training stage present unusual vantage points,with images where the frame is zoomed in on the object of interest.
Figure 3: Each 5×5 grid shows the top-25 ImageNet training-set images with the lowest and highestVoG scores for the class magpie and pop bottle with their predicted labels below the image.
Figure 4: The mean top-1 test set error (y-axis) for the exemplars thresholded by VoG score percentile(x-axis). Across Cifar-10, Cifar-100 and ImageNet, we observe that misclassification increases withan increase in VoG scores. Across all datasets we observe that the group of samples in the top-10percentile VoG scores have the highest error rate, i.e., contains most number of misclassified samples.
Figure 5: Each 5×5 grid shows the top-25 ImageNet test-set images with the lowest and highest VoGscores for the top-1 predicted class. Test set images with higher VoG scores tend to feature zoomed-inimages and are misclassified more as compared to the lower VoG images which tend to feature moreprototypical vantage points of objects.
Figure 6: Left: Consistency in ranking is an important attribute of any auditing tool. Here, we plotthe VoG top-1 test set error for 5 ResNet-18 networks independently trained on Cifar-10 from randominitialization. The plots show that VoG produces a stable ranking with a similar distribution of error ineach percentile across all images. Right: We measure the distribution of ImageNet-O images acrosspercentiles. We find that higher percentiles of VoG over-index on these out of distribution images.
Figure 7:	The mean top-1 test set error (y-axis) for the exemplars thresholded by VoG score percentile(x-axis) in ImageNet validation set. The Early (a) and Late (b) stage VoG analysis shows inversebehavior where the role of VoG flips as the training progresses.
Figure 8:	Box-plot of subset the VoG distribution of all examples with correct labels against the 20%of the dataset with shuffled labels. It is visible that the distribution of VoG scores, both the mean(red line in the plot) and spread, for shuffled data is higher than that of the correct samples for bothCifar-10 (right plot) and Cifar-100 (left plot).
Figure 9: We consider using VoG as a ranking mechanism to accelerate training. VoGo upweightsexamples using the VoG score during training. Models trained using VoGo (green) converges fasterand to a lower training loss as compared to SGD (blue). The VoG scores were calculated using K = 3number of checkpoints and we observe a sharp drop in the training once we start scaling the gradientupdates of the batches with their respect VoG scores after the third epoch.
Figure 10:	Plot of class false negative rate (y-axis) against average class VoG score for all classes(x-axis). Left: Cifar-10 Right: Cifar-100. There is a statistically significant positive correlationbetween class level error metrics and average VoG score (alpha set at 0.05).
Figure 11:	Bar plots showing the mean top-1 error rate (in %) for three group of samples from (1) thesubset of the test-set with the bottom 10th percentile of VoG scores, (2) the complete testing dataset,and (3) the subset of the test-set with the top 10th percentile of VoG scores.
Figure 12: The mean top-1 test set error (y-axis) for the exemplars thresholded by VoG scorepercentile (x-axis) calculated using the predicted labels. We observe that misclassification increaseswith an increase in VoG scores. Across ImageNet we observe that VoG calculated for the predictedlabels follows the general trend as in Fig. 5 where the top-10 percentile VoG scores have the highesterror rate.
