Figure 1: t-SNE visualizations in feature space of target model on CIFAR10 (Krizhevsky et al.,2009). Target model O has admirable distributions for clean samples xc while disordered distribu-tions for adversarial samples xa . Our G can turn xc/xa into xbc/xba with corrected distrubutions.
Figure 2: Our overall framework for the training of the deep generative network G . To align the dis-tribution of clean samples xc and adversarial samples xa for the target model, the training constraintsare set in the pixel level as well as the feature level of the target model O.
Figure 3: The illustration for differences between traditional and proposed pixel-level constraints.
Figure 4: The visual illustrations for the results of clean samples xc, adversarial samples xa andprocessed adversarial samples xba with our trained generator G , in image classification on ImageNet,semantic segmentation on Cityscapes, object detection on VOC07+12.
Figure 5: The visual illustration for injecting the no-differentiable operation into our framework.
Figure 6: Target model O has admirable distributions for clean samples xc while disordered distri-butions for adversarial samples xa . Our G can turn xc/xa into xbc/xba with corrected distrubutions.
Figure 7: The visual illustration for the results of xc, xa and xba with our trained generator G,in image classification on ImageNet. The adversarial samples are obtained by PGD with hyper-parameters as = 0.031 × 255, α = 0.0075 × 255 and n = 8.
Figure 8: The visual illustration for the results of xc, xa and xba with our trained generator G, insemantic segmentation on Cityscapes. The adversarial samples are obtained by BIM with hyper-parameters as = 0.03 × 255, α = 0.01 × 255 and n = 3.
Figure 9: The visual illustration for the results of xc, xa and xba with our trained generator G, inobject detection on VOC07+12. The adversarial samples are obtained by “cls+loc” attack withperturbation as 8.
