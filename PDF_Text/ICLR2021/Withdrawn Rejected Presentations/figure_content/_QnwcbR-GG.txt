Figure 1: We visualize the role that varying the number of network layers and hidden layer sizes:(left to right) average reconstruction error, memory footprint and first-frame render time (DeepSDF,other setups, and our defaults in red, gray, and blue, respectively).
Figure 2: Unlike our representation, DeepSDF re-construction quality degrades quickly for geome-tries not aligned to default, per-class orientations.
Figure 3: Latent-encoded SDFs(red) struggle to reconstruct“unique” features (grey, plane’stail) despite training on a singleclass of objects (planes). Ourrepresentation (blue) does not.
Figure 6: With only 7553 parameters, our base weight-encoded neural implicit format can lackthe representative power to converge on highly complex geometries (similar to decimated meshwith same memory footprint). Increasing the network capacity to equal the memory impact of theoriginal mesh results in near perfect reconstructions. tbuser (left) under CC BY.
Figure 7: Results of using Mildenhall et al. (2020) and Sitzmann et al. (2020b)A.4 Representation Compactness12Under review as a conference paper at ICLR 2021Figure 8: Our learnt weight-encoded neural implicit format (right) can be shown to better approx-imate the original surface (grey, inset) compared to adaptive decimation of the original trianglemesh Garland & Heckbert (1997) (left) and uniform signed distance grid (middle) with equal mem-ory impact. gpvillamil (skull), Makerbot (whale), morenaP (frog), artec3d (dragon), JuliaTruch-sess(octopus) under CC BY.
Figure 8: Our learnt weight-encoded neural implicit format (right) can be shown to better approx-imate the original surface (grey, inset) compared to adaptive decimation of the original trianglemesh Garland & Heckbert (1997) (left) and uniform signed distance grid (middle) with equal mem-ory impact. gpvillamil (skull), Makerbot (whale), morenaP (frog), artec3d (dragon), JuliaTruch-sess(octopus) under CC BY.
