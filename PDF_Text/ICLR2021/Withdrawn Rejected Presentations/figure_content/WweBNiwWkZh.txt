Figure 1: We build a tetrahedral mesh surrounding the body to parameterize the enclosed three-dimensional space. First, a level set representation of the body (a) is generated and subsequentlythickened (b) to contain the clothing worn on the body. Then, we use red/green tetrahedralizationMolino et al. (2003); Teran et al. (2005a) to create a tetrahedral mesh (c) from the thickened levelset. This tetrahedral mesh is skinned to follow the body as it moves (d). Note that the tetrahedralmesh surrounds the whole upper body to demonstrate that this parameterization can also be used forlong-sleeve shirts.
Figure 2: One can embed the cloth into the T-poseKDSM (a) and fix this embedding as the KDSMdeforms (b). However, this results in undesiredartifacts in the cloth (see e.g. Figure 3, secondGiven a pose θ, uim (θ) will not necessarilyhave the same parent tetrahedron or barycen-tric weights as uimo ; thus, a new embedding iscomputed for uim (θ) obtaining new barycentricweights λimk (θ). Using this new embedding, theposition of the cloth vertex in pose θ will beui(θ) = Pkλimk(θ)vk(θ). Ideally, if the di(θ)are computed correctly, ui(θ) will agree with theground truth location of cloth vertex i in pose θ .
Figure 3: (a) The ground truth cloth and (b) skinning the cloth using a fixed tetrahedral embedding.
Figure 4: (a) The hybrid cloth embedding method (see Section 5) produces cloth u(θ) that closelymatches the ground truth shown in the first row of Figure 3. (b) This is accomplished, for each pose,by plastically deforming the cloth in material space (the T-pose) before embedding it to follow thedeformation of the KDSM.
Figure 5:	(a) shows a training example whereoverlapping tetrahedra led to cloth torso verticesbeing embedded into arm tetrahedra, resultingin high variance in d(θ). Although there arevarious ad hoc approaches for remedying thissituation, it is difficult to devise a robust strat-egy in complex regions such as the armpit. (b)shows that the ground truth uGT (θ) is still cor-rectly recovered in spite of this high variancein um(θ) and d(θ); however, (c) shows that thishigh variance leads to spurious ringing oscilla-tions during subsequent inference.
Figure 6:	(a) shows the result obtained usingMethod 2 to compute um (θ) in material space(the T-pose) for a pose θ . (b) shows the resultobtained using this embedding to compute u(θ)as compared to the ground truth uGT (θ) (c). Al-though the variance in um (θ) and d(θ) is lowerthan that obtained using Method 1, the trainingexamples now contain errors (shown with a heatmap) when compared to the ground truth.
Figure 7: (a) Subset of vertices for which some choice of a parent tetrahedron using Method 1reasonably agrees with Method 2. (b) The rest of the mesh can be filled in with the 3D morphproposed in Cong et al. (2015). (c) Subset of vertices from (b) that reasonably agree with Method 2.
Figure 8: Histogram of average vertex er-rors over every example in the test dataset.
Figure 9: Test dataset example predictions (b) compared to the ground truth cloth in (a) and theresults from Jin et al. (2020) in (c). Regularization can smooth the body surface offsets predictedusing Jin et al. (2020) and as such reveals the underlying body shape, e.g. the belly button (indicatedwith a red square).
Figure 10: Given the hybrid method network prediction in (a), we apply texture sliding from Wu et al.
Figure 11: (a) Embedding cloth in a tetrahedralmesh guarantees that each transformed vertexwill remain inside and thus be bounded by thedisplacement of its parent tetrahedron. (b) How-ever, no such bounds exist when the cloth isdefined via UVN offsets from the body surface,since angle perturbations of the surface causethe cloth to move along an arclength C = ψrwhere even small ψ can lead to large C for largeenough r .
Figure 13: The network inferred cloth for the body from Wu et al. (2020a) can be transferred to theSMPL body model with any given pose and shape. Column 1 corresponds to Wu et al. (2020a), andcolumns 2-4 correspond to thinner, template, and thicker SMPL bodies, respectively. Note that thecloth exhibits unique wrinkling patterns depending on body shape, as expected.
Figure 14: The network inferred cloth can be resized based on user preference without networkretraining. The size of the T-shirt increases from left to right for three different poses.
