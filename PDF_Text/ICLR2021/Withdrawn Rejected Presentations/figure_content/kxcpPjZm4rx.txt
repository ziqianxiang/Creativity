Figure 1: Loss curves (a) and angular difference curves (b) during 300 training epochs of a NSGANon the CelebA dataset. The clear jumps of the angular difference curves in (b) correspond to aqualitative transition of the NSGAN network as we will discuss later.
Figure 2: Generated images of GANs after 300 training epochs.
Figure 3: Angular differences of different GANs8 6 4 20.0.0.0.
Figure 4:0	50 100 150 200 250 300Epoch(a) NSGANVisual quality of different GANs w/ and w/o GP regularization.
Figure 5: Mode diversity of different GANs w/ and w/o GP regularization.
Figure 6: Generated images of GANs at their turning pointsOur evaluation shows that the SQD framework is an effective diagnostic toolbox to monitor thetraining process of GAN in real time.
Figure 7: Angular difference of NSGAN with different regularizations: Dragan (Kodali et al., 2017),0-centered gradient penalty (0-GP) (Thanh-Tung et al., 2019), Lipschitz constraint and gradientpenalty (Gulrajani et al., 2017). The weight of penalty terms are set to λ = 10 unless specified.
Figure 8: Generated samples of NSGAN in different epochs13Under review as a conference paper at ICLR 2021Figure 11: Generated samples of LSGAN-GP in different epochs14Under review as a conference paper at ICLR 2021Figure 12: Generated samples of Hinge Loss in different epochs(a) Epoch 35	(b) Epoch 70	(c) Epoch 105	(d) Epoch 140(e) Epoch 175(g) Epoch 245(f) Epoch 210(h) Epoch 280Figure 13: Generated samples of Hinge-GP in different epochs15Under review as a conference paper at ICLR 2021(a) Epoch 60(b) Epoch 62(c) Epoch 64(f) Epoch 70(g) Epoch 72
Figure 11: Generated samples of LSGAN-GP in different epochs14Under review as a conference paper at ICLR 2021Figure 12: Generated samples of Hinge Loss in different epochs(a) Epoch 35	(b) Epoch 70	(c) Epoch 105	(d) Epoch 140(e) Epoch 175(g) Epoch 245(f) Epoch 210(h) Epoch 280Figure 13: Generated samples of Hinge-GP in different epochs15Under review as a conference paper at ICLR 2021(a) Epoch 60(b) Epoch 62(c) Epoch 64(f) Epoch 70(g) Epoch 72(h) Epoch 300(d) Epoch 66(e) Epoch 68
Figure 12: Generated samples of Hinge Loss in different epochs(a) Epoch 35	(b) Epoch 70	(c) Epoch 105	(d) Epoch 140(e) Epoch 175(g) Epoch 245(f) Epoch 210(h) Epoch 280Figure 13: Generated samples of Hinge-GP in different epochs15Under review as a conference paper at ICLR 2021(a) Epoch 60(b) Epoch 62(c) Epoch 64(f) Epoch 70(g) Epoch 72(h) Epoch 300(d) Epoch 66(e) Epoch 68Figure 14: Generated samples of WGAN in different epochsFigure 15: Generated samples of WGAN-GP in different epochs16
Figure 13: Generated samples of Hinge-GP in different epochs15Under review as a conference paper at ICLR 2021(a) Epoch 60(b) Epoch 62(c) Epoch 64(f) Epoch 70(g) Epoch 72(h) Epoch 300(d) Epoch 66(e) Epoch 68Figure 14: Generated samples of WGAN in different epochsFigure 15: Generated samples of WGAN-GP in different epochs16Under review as a conference paper at ICLR 2021B FIRST ORDER NECESSITY CONDITION OF LD,λHere we provide the first order condition of the critical point of the GAN objective function LD,λwith the gradient penalty term λEχ〜p^ (∣∣NnDn(X)k2 — 1)2. We abuse the sampling issue ofGθ , Dn , Nn Dn and write the GAN-GP discriminator loss asmninLd,i = LD + λ (∣∣VnDn∣∣2 - 1)2 .
Figure 14: Generated samples of WGAN in different epochsFigure 15: Generated samples of WGAN-GP in different epochs16Under review as a conference paper at ICLR 2021B FIRST ORDER NECESSITY CONDITION OF LD,λHere we provide the first order condition of the critical point of the GAN objective function LD,λwith the gradient penalty term λEχ〜p^ (∣∣NnDn(X)k2 — 1)2. We abuse the sampling issue ofGθ , Dn , Nn Dn and write the GAN-GP discriminator loss asmninLd,i = LD + λ (∣∣VnDn∣∣2 - 1)2 .
Figure 15: Generated samples of WGAN-GP in different epochs16Under review as a conference paper at ICLR 2021B FIRST ORDER NECESSITY CONDITION OF LD,λHere we provide the first order condition of the critical point of the GAN objective function LD,λwith the gradient penalty term λEχ〜p^ (∣∣NnDn(X)k2 — 1)2. We abuse the sampling issue ofGθ , Dn , Nn Dn and write the GAN-GP discriminator loss asmninLd,i = LD + λ (∣∣VnDn∣∣2 - 1)2 .
