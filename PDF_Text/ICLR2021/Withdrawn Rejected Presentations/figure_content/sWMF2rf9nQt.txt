Figure 1: An illustration of the overconfident problem in DNNs. (a) A high-accuracy model typ-ically (b) assigns high confidence for misclassified samples from seen classes, and (c) classifiesout-of-distribution samples (from unseen classes) as seen classes confidently. We mainly focus onmisclassification detection problem, that is, detecting the misclassified samples from seen classes.
Figure 2: Motivation. (a) For instance, real data is described by latent characteristics like w/olegs and shape. Only the most discriminative characteristic (e.g., w/o legs) are learned by originaltraining scheme. (b) Class augmentation: more classes (realistic or synthetic samples) are introducedduring training, which enables the model to leverage more robust and generalizable features (e.g.
Figure 3: Misclassification detection can be im-proved by seeing more real classes during train-ing. The base class number is K = 4, and theaugmented class number is M = 0, 2, 4, 6.
Figure 4: Illustrations of BCI-1 (top)and BCI-2 (bottom).
Figure 5: (a) Predictive distributions on misclassified samples. For misclassified samples, the pre-dictive distribution is smoother, and the softmax scores of the ground-truth class are increased bytraining with classAug. (b) Average confidences (the max softmax scores) of correctly classifiedsamples and misclassified samples during training. We use ResNet-18 on CIFAR-10 dataset.
Figure 6: MD can be imProved by seeing moresynthetic classes during training.
