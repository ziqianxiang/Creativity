Figure 1: Epidemic control as an optimiza-tion problem. s, a, ci refer to environmentstates, control actions, and the ith cost, whiletraj. is their collection over an episode. Blueand red arrows match the input and output ofthe OpenAI Gym step function.
Figure 2: Left: Pareto fronts for various optimization algorithms. The closer to the origin point thebetter. Right: Evolution of the costs when Goal DQN agents are evaluated on various β . We plot themean and standard error of the mean (left) and standard deviations (right) over 10 seeds.
Figure 3: Evolution of cost metrics and strategy over a year of simulated epidemic with aDQN agent(left) in the low health cost regime and a NSGA-II agent in the low economic cost regime (right).
Figure 4:	Main running script of the EpidemiOptim libraryA.2 Extended related worksPrior to the current COVID-19 pandemics, Yanez et al. (2019) framed the problem of finding optimalintervention strategies for a disease spread as a reinforcement learning problem, focusing on howto design environments in terms of disease model, intervention strategy, reward function, and staterepresentations. In Alamo et al. (2020), the CONCO-Team (CONtrol COvid-19 Team) provides adetailed SWOT analysis (Strengths, Weaknesses, Opportunities, Threats) and a roadmap that goesfrom the access to data sources to the final decision-making step, highlighting the interest of standardoptimization methods such as Optimal Control Theory, Model Predictive Control, Multi-objectivecontrol and Reinforcement Learning. However, as argued in Shearer et al. (2020), a decision modelfor pandemic response cannot capture all of the social, political, and ethical considerations thatimpact decision-making. It is is therefore a central challenge to propose tools that can be easilyused, configured and interpreted by decision-makers.
Figure 5:	Description of the SEIRAH epidemiological model. Adapted from Prague et al. (2020)To account for uncertainty in the model parameters, we use a distribution of models. At each episode,the epidemiological model is sampled from that distribution. The transition function is thus condi-tioned on a latent code (the model parameters) that is unknown to the agent. This effectively resultsin a stochastic transition from the viewpoint of the agent. To build the distribution of models, weassume a normal distributions for each of the model parameters, using either the standard deviationfrom the model inversion for parameters estimated in Prague et al. (2020) or 10% of the mean valuefor other parameters. Those values are available in appendix Figure 6 features for reproducibility ofthe experiment. We further add a uniformly distributed delay between the epidemic onset and thestart of the learning episode (uniform in [0, 21 days]). This delay models the reaction time of thedecision authorities. This results in the distribution of models shown in Figure 7.
Figure 6:	Variance-covariance matrix for parameters of the epidemiological model.
Figure 7:	10 models sampled from the distribution of epidemiological models used in the case-study.
Figure 8:	DQN trained with β = 0.. For one run, this figure shows the evolution of model states(above) and states relevant for optimization (below). The aggregated cost is shown for variousvalues of β in [0, 0.25, 0.5, 0.75, 1]. For β = 0, the agent only cares about the health cost, it alwayslocks-down.
Figure 9: DQN trained with β = 0.5. Here the strategy is cyclical with a one or two weeks pe-riod. For one run, this figure shows the evolution of model states (above) and states relevant foroptimization (below). The aggregated cost is shown for various values of β in [0, 0.25, 0.5, 0.75, 1].
Figure 10:	DQN trained with β = 0.55. Here the agent first lock-down to stop the first wave, butthen stops the cyclical lockdown early which induces a second wave later, where the agent alsoreacts by a lock-down. For one run, this figure shows the evolution of model states (above) andstates relevant for optimization (below). The aggregated cost is shown for various values of β in[0, 0.25, 0.5, 0.75, 1].
Figure 11:	DQN trained with β = 0.65. Here the agent mostly cares about the economic cost, whichresults in a no-lockdown policy. For one run, this figure shows the evolution of model states (above)and states relevant for optimization (below). The aggregated cost is shown for various values of βin [0, 0.25, 0.5, 0.75, 1].
Figure 12: Goal-DQN without constraints evaluated in β = 0.2. Here the agent starts with a lastinglockdown, then pursues with cyclical lock-downs, which ensures the absence of second wave and,thus, results in low health cost but high economic cost. For one run, this figure shows the evolutionof model states (above) and states relevant for optimization (below). The aggregated cost is shownfor various values of β in [0, 0.25, 0.5, 0.75, 1].
Figure 13: Goal-DQN without constraints evaluated in β = 0.65. Here we find a cyclical strategyequivalent to the one of shown with a DQN agent trained with β = 0.5. For one run, this fig-ure shows the evolution of model states (above) and states relevant for optimization (below). Theaggregated cost is shown for various values of β in [0, 0.25, 0.5, 0.75, 1].
Figure 14: Goal-DQN without constraints evaluated in β = 0.7. Here the agent only use a lock-down at the very beginning of the epidemic. It is unclear whether this has an impact on the healthcost at all. For one run, this figure shows the evolution of model states (above) and states relevant foroptimization (below). The aggregated cost is shown for various values of β in [0, 0.25, 0.5, 0.75, 1].
Figure 15: Goal-DQN with constraints evaluated in β = 0.3, Meconomic = 160B, Mhealth =62000 deaths. This boils down to no constraints as they are maximal values. This leads to a cyclicalpolicy. For one run, this figure shows the evolution of model states (above) and states relevant foroptimization (below). The aggregated cost is shown for various values of β in [0, 0.25, 0.5, 0.75, 1].
Figure 16: Goal-DQN with constraints evaluated in β = 0.3, Meconomic = 55B, Mhealth =62000 deaths. This is the same β as Figure 15 (previous page). Now there is no constraint onthe number of deaths but a strong constraint on the economic cost. The strategy is not cyclical any-more, as the resulting economic cost would be too high. This strategy stays below the economicconstraint but still tries to minimize the health cost. For one run, this figure shows the evolution ofmodel states (above) and states relevant for optimization (below). The aggregated cost is shown forvarious values of β in [0, 0.25, 0.5, 0.75, 1].
Figure 17: Goal-DQN with constraints evaluated in β = 0.7, Meconomic = 160B, Mhealth =62000 deaths. There is no constraint. As the balance favorizes the economic cost, the strategy doesnot implement any lock-down. For one run, this figure shows the evolution of model states (above)and states relevant for optimization (below). The aggregated cost is shown for various values of βin [0, 0.25, 0.5, 0.75, 1].
Figure 18: Goal-DQN with constraints evaluated in β = 0.7, Meconomic = 160B, Mhealth =30500 deaths. Now we have the same setup as the previous page (Figure 17), except that we havea strong constraint on the number of deaths. The resulting strategy respect the constraint whileattempting to minimize the economic cost. For one run, this figure shows the evolution of modelstates (above) and states relevant for optimization (below). The aggregated cost is shown for variousvalues ofβin [0, 0.25, 0.5, 0.75, 1].
Figure 19: Goal-DQN with constraints evaluated in β = 0.3, Meconomic = 55B, Mhealth =15000 deaths. Here we have strong constraints on both economic costs. In that case, there is nogood solution. This strategy respects the health constraint but violates the economic constraint. Forone run, this figure shows the evolution of model states (above) and states relevant for optimization(below). The aggregated cost is shown for various values of β in [0, 0.25, 0.5, 0.75, 1].
Figure 20: NSGA-II, the closest point to [8000 deaths, 60B] in the Pareto front. In this low healthcost regime, NSGA-II finds a cyclical strategy with a period of 2 weeks. For one run, this fig-ure shows the evolution of model states (above) and states relevant for optimization (below). Theaggregated cost is shown for various values of β in [0, 0.25, 0.5, 0.75, 1].
Figure 21: NSGA-II, the closest point to [30000 deaths, 40B] in the Pareto front. Here we find thatNSGA-II use alternative strategies depending on the epidemiological models it faces. The averageof these strategies ends up close to 30000, although the two strategies either find high health costs(>50000) or low ones (<1000). These plots show the first alternative, where the strategy aims atbreaking the first wave of the epidemic. See the other alternative in Figure 22. For one run, thisfigure shows the evolution of model states (above) and states relevant for optimization (below). Theaggregated cost is shown for various values of β in [0, 0.25, 0.5, 0.75, 1].
Figure 22: NSGA-II, the closest point to [30000 deaths, 40B] in the Pareto front. Here we find thatNSGA-II use alternative strategies depending on the epidemiological models it faces. The averageof these strategies ends up close to 30000, although the two strategies either find high health costs(>50000) or low ones (<1000). These plots show the second alternative, where the strategy iscyclical and achieved low health costs. See Figure 21 for the first alternative. For one run, thisfigure shows the evolution of model states (above) and states relevant for optimization (below). Theaggregated cost is shown for various values of β in [0, 0.25, 0.5, 0.75, 1].
Figure 23: NSGA-II, the closest point to [45000 deaths, 20B] in the Pareto front. NSGA-II seem tofind a robust strategy that consists in a single lock-down of a few weeks to break the first wave. Forone run, this figure shows the evolution of model states (above) and states relevant for optimization(below). The aggregated cost is shown for various values of β in [0, 0.25, 0.5, 0.75, 1].
