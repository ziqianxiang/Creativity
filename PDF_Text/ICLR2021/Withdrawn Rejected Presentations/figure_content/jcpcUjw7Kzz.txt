Figure 1: Learning discrete representions for planning. We approach the long-horizon planning onhigh dimensional image space by learning a discrete representation and planning on the discretespace. (a) We learn multiple one-hot encodings for each observation fully unsupervisedly withcontrastive learning. Each one-hot encoding corresponds to a temporally abstract state of one of thefreely moving entity in the observation, such as a room the agent is in or whether a key has beenpicked up. (b) With the discrete encoding, we build a graph that connects the current encoding tothe goal encoding and do a graph search on it to plan efficiently for long horizon tasks.
Figure 2: Unsupervised discrete code learning. We propose to learn a set of one-hot encodings asthe latent representation for each observation. For an anchor observation ot , its neighbours ot+kfor some small k are treated as positives, and random other observations are negatives. We proposea learnable weight matrix to be diagonally dominant and diagonally positive (DDDP). An objectextractor architecture is applied to learn to extract objects and a shared encoder is applied per chan-nel. Finally, Gumbel softmax and softmax are used to maximally allow gradient to flow back to theencoder.
Figure 3: DORP Planning. Since the learned representation includesmultiple one-hot encodings, we plan for each one-hot encoding oneat a time. For each of the one-hot encodings zi , we build a graphbased on that subset of the representation. After finding the shortestpath from current state to the goal state, we use MPC to reach the nextplanned state. See Section 3.2 for more explanations.
Figure 4: DORP in 5-object-rearrangement. In (a), we present DORP with random unseen start andgoal images which require temporal-extended planning. In (b), when presenting the same task toVF-CEM we find that the objects are stuck in an awkward configuration where 4 blocks (except thepurple) are blocking to reach their goal positions. Finally, in (c), we visualize the representationfactorization by randomly moving one of the five object while maintaining the positions of theothers. We plot a histogram of which one-hots have been changed per object. We find that with highprobability only the one-hot that corresponds to the moving object is modified.
Figure 5: Discrete Embedding Comparison. We visualize the color codes of different object posi-tions in 1-object-rearrangement per similarity matrix type. Each color shows different discrete code.
Figure 6: Key-Wall Representations. In (a) and (b), we demonstrate the discrete code of the agentat different positions. Each color represents the same code. The grids in black are invalid states (thewall that blocks the agent and separates the two rooms). We demonstrate temporal consistency inthe latent space both when the object has the key as not. In (c) and (d), we confirm that two one-hot codes are factorized by observing that only one one-hot changes when removing the key whilemaintaining the agent position and only the other one-hot changes when the agent moves withoutinteracting with the key.
