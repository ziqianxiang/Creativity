Figure 1: Schematic illustration of one layer of neural network performed in a crossbar array.
Figure 2: The example results of a uniform LAQ (Hou & Kwok, 2018) quantizer (a), a non-uniform(log-wise) INQ (Zhou et al., 2017) quantizer (b), and a generalized (Lloyd’s) quantizer (c). Wequantized the last fully connected layer’s weight of ResNet-18 with 8-level quantizers. The gener-alized quantizer can obtain less quantization error.
Figure 3: Quantization performance comparison between our quantized model with weight noiseand others’ model without weight noise.
Figure 4: (a) shows the simulated and measured distribution of differential conductance (μS) whichmapped from the 4L weight of the first convolutional layer in ResNet-18b. (b) shows the top-1 accuracy gap (%) of ResNet-18b and mAP gap (%) of SSD model using 4L, 8L weights withsimulated or measured noise.
Figure 5: Processing of a series of non-uniform data in digital computers. Additional memoryoverhead or additional operation of projection is needed.
