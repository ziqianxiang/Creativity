Figure 1: Information content, model perfor-mance and model confidence on five tasks.
Figure 2: Injecting three kinds of noise onMNIST.
Figure 3: Task information, model performance, and model confidence, with different kinds andvarying levels of noise.
Figure 4: Image domains in Office-31 and Office-Home.
Figure 5: Pairwise domain similarity on Office-31 (top) and Office-Home (bottom). S and Suni areinformation similarities, D1 and D2 are first-order and second-order feature distances.
Figure 6:	Measuring capacity using information. (a) the amount of information a model can storeis capped by its capacity. (b) increase in capacity is correlated with an increase in the number ofparameters. (c) a task has an inherent amount of information content.
Figure 7:	Information ablation. (a) Structure of a variant of ResNet model in (He et al., 2016a).
Figure 8: (a) illustration of the training process in synced distillation.，indicates training Proce-dures with information flow on the arrow directions. (b) information gain of students from differentteachers. (c) information gain of the student when trained with different distillation coefficient α.
