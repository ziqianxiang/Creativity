Figure 1: Relative speedup ratio (α) comparedMP with AT on GPU (solid) and CPU (dashed).
Figure 2: Comparison of four masking strategies {Head, Tail, Random, Chunk} in syntheticexperiments on WMT En→Ro (Left) and En→De (Right) test sets. For Chunk, we test the chunksize from {2, 3, 4}. Dashed lines represent Mask-Predict’s scores reported by Ghazvininejad et al.
Figure 4:	Comparison of decoding speed w.r.t. batch size and computing device on WMT’14En→De task. The x-axis is the relative speed compared to the corresponding autoregressive models(dashed lines at x=1). GPU:TITAN X (Pascal), CPU:Intel(R) Xeon(R) E5-2680 v3 @ 2.50GHz.
Figure 5:	Translation speed (Left: GPU, Middle: CPU) and BLEU score (Right) against sourcesentence’s length for different decoding modes in HRT (k=2): Cd=1 denotes decoding by autore-gression, while Cd=k denotes hybrid-regressive decoding. Speed is measured at batch size=32,bat=5, bmp=1.
