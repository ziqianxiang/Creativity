Figure 1: Reinforcement Learning framework to attain parametersframework and execution policy. In the process of solving the problem of loading latency, it isquite understandable to realize its direct dependency on disk space of the object. This intuitive ideadirects us to come up with the method of splitting the given DNN among tiny models as a vectorM~ = [m1, m2 ..., mk]. As we already know that smaller the model lesser will be loading latencyand if they are loaded in parallel with each other, then over all loading latency will depend only onthe biggest among the existing tiny models. Therefore, in this work we propose to split the modelsusing Reinforcement Learning and then provide an execution policy, which helps in parallel loading(case#1) and parallel loading in parallel with inference (case#2).
Figure 2: Architecture of proposed methodologyWhere T is the total loading time of the full model. The reward parameter reinforces the behaviorof having split which should lead to a sub model having load time at max equal to the load time ofa proportionally equivalent decomposed model. This method drives towards achieving true paral-lelism.
