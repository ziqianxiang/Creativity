Figure 1: The learning curves with exploration noise on Reacher and Humanoid environments. Theshaded region represents the standard deviation of the average evaluation over nearby windows withsize 10. On the MuJoCo tasks, our D2Q algorithm yields competitive results, compared to TD3 andDDPG.
Figure 2: The learning curves with exploration noise on the InvertedDoublePendulum and Walker2denvironments. The shaded region represents the standard deviation of the average evaluation overnearby windows with size 10. Our D2Q algorithm yields competitive results, compared to TD3 andDDPG.
Figure 3: The learning curves with exploration noise on the Ant, Halfcheetah and Hopper environ-ments. The shaded region represents the standard deviation of the average evaluation over nearbywindows with size 10. Our D2Q algorithm yields significantly better results, compared to TD3 andDDPG.
Figure 4: The figures show how our method will perform while adjusting parameter Î». The shadedregion represents the standard deviation of the average evaluation over nearby windows with size10.
