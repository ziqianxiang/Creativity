Figure 1:	(a)-(d): Different aspects contributing to the complexity of causal graphs. (i), (ii): Difference between observational and interven-tional data. In RL setting, actions are interventions in the environment. The hammer denotes an intervention. Intervention on a variable notonly affects its direct children, but also all reachable variables. Variables impacted by the intervention have a darker shade.
Figure 2:	Illustration of the key features of the suite. Environments have objects that interact according to the underlying causal graph whichcan be based on a subset of objects’ properties. An efficient model should be able to infer the high level causal variables from raw pixel dataand learn the underlying causal graph through interactions between these high level causal variables.
Figure 3: Demonstration of the weighted-block pushing environment (left: observed, right: unobserved) along with the feasible generalizationsthat the setup provides.
Figure 4: Demonstration of the vanilla chemistry environment (left: groundtruth causal graph and a sample from it - same sample shown to demonstratethe affect of interventions, right: the affect of interventions and how far theyaffect based on underlying causal graph)take place according to the underlying causal graph which can either be a randomly generated DAG,or specified by the user. An interaction consists of changing the color (state) of a variable. At thispoint, the color of all variables affected by this variable (according to the causal graph) can change.
Figure 5: All models have 3 components: encoder, decoder and transitionmodel. The transition models can either be monolithic, modular models orgraph neural networks (GNNs). Monothlic models don’t have explicit struc-ture. GNNs have factorized representation of variables. Modular models haveboth factorized representation of variables and directed edges to potentiallymodel causal relationships such as A causing B.
Figure 6: Success Rate (higher is better) for different models and training losses for 1, 5 and 10 step prediction for the Fixed UnobservedPhysics environment setting with 5 objects. Here, (a) Random stands for a random policy, (b) greedy is the policy with best greedy actions, (c)NLL are models trained in 2 stages: pretraining the encoder/ decoder, following by only training the transition model, (d) NLL with finetuneare models in 3 stages: pretraining the encoder/ decoder, following by only training the transition model and then finetuning the encoder,decoder and transition models together. (e) Contrastive are models trained using a contrastive loss. The GNN and Modular models trained onconstrastive loss significantly outperform the monolithic models (autoencoders and VAE). The margin significantly increases as the number ofsteps to reach the goal increase, suggesting that models with explicit structure and modularity have a much better understanding of the world.
