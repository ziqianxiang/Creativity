Figure 1: An end-to-end flowchart for the CIM training procedure. C refers to the TN while Drefers to the classifier (discriminator). Lcon forces the learned input transformation Φ to upweightthe task-relevant blue features which are present in both x and x+, and to downweight the spuriousred feature which is shared by x and x- .
Figure 2: Captured similarities on MNIST. Top: When training the TN as an autoencoder, the tripletloss forces the network to reconstruct the shared spurious features between examples. Bottom:When training CIM for classification, the input transformation Φ highlights the task-relevant digitwhile de-emphasizing the uninformative sources of variation (the background and red square).
Figure 3: Results with nuisance background information for Colored MNIST. In (a), the train andtest sets are constructed such that a classifier will achieve low accuracy by relying on backgroundcolor. In (b), CIM and CIM + VIB outperform relative baselines on digit classification.
Figure 4: Qualitative visualizations of the learned representations from CIM. (a) Morphed pointcloud objects of the Modelnet40 (Wu et al., 2015) dataset. The first row shows the raw input, whilethe second row shows the morphed input. The first two columns are samples from the flowerpotcategory while the next three are from the sink class. (b) Samples of learned Φ. Left to right:CelebA, Waterbirds, and the Background Challenge datasets.
Figure 5: Architecture of the TN for both RGB and point-cloud inputs.
