Figure 1: Overview of our approach. We use BERT as a baseline and inject structural bias in twoways. Through a brain decoding task, we then compare the alignment of the (sentence and word)representations of our baseline and our altered models with brain activations.
Figure 2: Manually annotated example graphs for a sentence from the Wehbe2014 dataset. WhileUCCA and UD attach all words, DM only connects content words. However, all formalisms capturebasic predicate-argument structure, for example, denoting that “more than anything else” modifies“looking forward” rather than “fly”.
Figure 3: Brain decoding score (mean Pearson’s r; with 95% confidence intervals shown for subjectscores) for models fine-tuned by MLM with guided attention on each of the formalisms, as well thebaseline models: pretrained BERT (dotted line), and BERT fine-tuned by MLM on each formalism’straining text without guided attention (domain-finetuned BERT, solid lines).
Figure 4: Accuracy per subject-verb agreement category of Marvin & Linzen (2019) for the threeWehbe2014 models and each of the four baselines.
Figure 5: Change in F1-score per coarse-grained semantic class compared to the pretrained baselinefor the three guided attention Wehbe2014 models.
Figure 6: Targeted syntactic evaluation accuracy scores per category for Pereira2018 models.
Figure 7: Targeted syntactic evaluation accuracy scores per category for Wehbe2014 models.
Figure 8: Content word and function word brain decoding score (mean Pearson’s r) for all models fine-tuned by MLM with guided attention on each of the formalisms (points), as well the four baselines:pretrained BERT, dotted line), and the domain-finetuned BERT by MLM on each formalism’s trainingtext without guided attention (solid lines).
