Figure 1: Illustration of the flexible few-shot learning tasks. Instead of having a fixed seman-tic class, each example may belong to different classes flexibly depending on the context of eachepisode. New classes and attributes are introduced in testing to establish new classification criteria.
Figure 2: Sample FFSL episodes using Celeb-A (left) and ZaPPos-50K (right) datasets. Positive andnegative examples are sampled according to the context attributes, but the context information is notrevealed to the model at test time.
Figure 4: Our proposed method for FFSL. A: We first pretrain the network with unsupervisedcontrastive objective to learn general features. B: Then we finetune the network to classify the set oftraining attributes. Both stages employ a different decoder header so that the representation remainsgeneral. C: Finally at test time we use Mask-ProtoNet, a variant of ProtoNet that infers featureselection iteratively.
Figure 5: 20-shot FFSL results comparing different representation learning and FSL stagecombinations. FFSE: Meta-Iearning directly using the flexible few-shot episodes. SA: Supervisedattribute classification. ID: Auxiliary representation learning (for Celeb-A this is face ID classifi-cation). U: Unsupervised contrastive learning. U-SA: Our proposed U pretraining followed by SAfinetuning. SA*: Supervised attribute binary classification on all attributes, which serves as an ora-cle (stripedbars). A set of few-shot learners are evaluated: 1) logistic regression (LR), 2) LR withL1regularization (LR +L1), 3) ProtoNet (Proto), and 4) the proposed Mask-ProtoNet (MaskProto).
Figure 6: Additional results on the Celeb-A dataset. A: How many examples are needed forFFSL? We provide an oracle performance where the feature representation is directly the binaryground-truth attribute vector (GT-LR) and we train a logistic regression classifier on top. It suggeststhat there is natural ambiguity in the task and more examples than standard FSL are needed. B:Comparison of few-shot learning methods on different number of shots. Mask-ProtoNet worksbetter with an increasing number of shots. C: Effect of the number of decoder layers duringfinetuning. Adding a decoder keeps the representation general and not overfitting to the trainingattributes. D: Effect of the number of finetuning steps. Small amount of finetuning on the trainingattribute is beneficial, but eventually the accuracy goes down.
Figure 7: Projecting data features into prototypical network embedding space (WA) for the lineartoy problem. On the flexible task, the model destroys information from the test attributes to removeambiguity at training time.
