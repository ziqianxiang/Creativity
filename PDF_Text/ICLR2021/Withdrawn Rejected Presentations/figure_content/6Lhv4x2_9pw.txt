Figure 1: (a) A zoomed view of the two-dimensional fault geometry. The domain is 32 km longalong the strike of the fault and 24 kilometers wide across the fault. The rupture starts to nucleate10 km to the left of the barrier and propagates from the hypocenter towards the barrier, (b) Linearslip-weakening friction law for an earthquake fault. The fault begins to slip when the shear stressreaches or exceeds the peak strength of τs . τs decreases linearly with slip to a constant dynamicfriction τd over critical slip distance (dc). The shear strength is linearly proportional to the normalstress σn, and the friction coefficient varies with slip between μs and μd.
Figure 2: The schematic diagram shows the architecture of the Bayesian neural network used in thiswork. The network has one input layer with eight parameters, one hidden layer with twelve nodes,and an output layer with a single node. Weights between input and hidden layers are defined by wi0j ,which are normally distributed. i, j are the node input and hidden layer node index. Similarly, wj1kis the normal distribution of weights between the hidden and the output layer. μ and σ are the meanand standard deviation. At the output node, the network produces a distribution of prediction scoresbetween 0 and 1.
Figure 3: The graph shows the distribution of prior and posterior mean weights (a) w0 (b) w1 andbiases (c) b0 (d) b1. Both location of the mean and magnitude of density of the posterior distributions(weights and biases) are noticeably different from the priors which indicates that BNN has learnedfrom the data and adjusted the posterior accordingly.
Figure 4: The illustration shows the posterior mean and standard deviations of w0 and w1 . (a) w0that map the inputs to the nodes of the hidden layer. The eight input parameters are on the horizontalaxis, and the twelve nodes are on the vertical axis. The colors in each cell are the magnitudesof mean weight. (b) w1 maps the hidden layer to the output layer. (c) The standard deviation ofw0 . Shear stress connected to node-4 of the hidden layer has the highest uncertainty. Similarly,the weights associated with the input parameters and node-5 have high uncertainty. Whereas, theweights associated with the input parameters and the nodes 7-11 have relatively low uncertainty. (d)Uncertainty of the weights associated with the hidden layer nodes and the output node. Weights innode 7 and 8 have high uncertainty while the rest of the weights have relatively low uncertainty.
Figure 5: The graph shows (a) frequency and (b) standard deviation of posterior prediction scoresof the test data. Prediction scores are skewed toward the left side while slightly less on the right.
Figure 6: The illustration shows (a) permutation feature importance and (b) their uncertanitities.
