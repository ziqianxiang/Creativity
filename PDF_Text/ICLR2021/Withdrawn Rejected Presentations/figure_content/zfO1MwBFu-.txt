Figure 1: Comparison of (a) MI-maximizing regularization and (b) the proposed method, using aVenn diagram of information theoretic measures of x, z, and s.
Figure 2: Graphical models for (a) DSAE and (b) PixelCNN-VAE.
Figure 3: Comparison of CMI-VAE with β-VAE and MI-VAE. Each maker for β-VAE is annotatedwith the value of γ . In the figures, an upper left curve is desirable because it shows the methodbalance better compression (low KL(z)) and high downstream task performance (AoLR and mCAS,see explanations in Section 5.3). Also, detailed results can be found in Appendix K.2.
Figure 4: I(z; s) values of DSAE trained with β-VAE objective.
Figure 5: Real images (the first column) and generated images by PixelCNN-VAEs (the other 10columns). The images in each row are stochastically sampled from the decoder p(x|z) using thesame z, which is extracted from x in the first column. The figures present that the diversity of theimages in γ = 0.3 is better than that in γ = 0.6, which may be because PixelCNN-VAE wouldresemble an identity mapping with a large γ. In contrast, γ = 0.3 apparently produces more labelerrors than γ = 0.6 because the decoder ignores z with a small γ (see, e.g., the rows for 3 and4). Furthermore, when comparing (a) (CMI-VAE with γ = 0.3) and (b) (β-VAE with γ = 0.3),apparently, (a) produces less label errors (see, e.g., the rows for 2 and 3). This result is consistentwith the mCAS scores in Figure 3 (Section 5.3), which indicates that CMI-VAE achieved betterdiversity and less label errors than β-VAE.
