Figure 1: This study in a nutshell. a) The iterative neural network (ItNet): first, images are pre-processed and potentially down-scaled by a sub-network called data block. Then, the output of thisdata block is processed by another sub-network that is iteratively executed. After every iteration n,the output of this iterative block is fed back to its input and, at the same time, is further processed bythe classification block to predict the semantic map mn . This network generates multiple outputs mnwith increasing quality and computational costs and heavily re-uses intermediate network activations.
Figure 2: Detailed description of the data block (a) and iterative block (b) as shown in Figure 1:a) First, images are down-sampled in two stages, each using a stride and pooling of size s = 2(inspired by Paszke et al., 2016). Then, the output of the second stage is processed on L differentscales. For clarity, an example with L = 3 is shown. Convolutional layers (with kernel size 3), batch-normalization layers and ReLU activation functions are denoted with Conv, BN and R, respectively.
Figure 3: a) Comparison of mIoU over MACs between networks with batch normalization appliedbetween iterative blocks (purple curve) and applied after each convolution (green curve) on the testset of the CamVid dataset. Note that, for both cases, batch normalization is always applied after eachconvolution in the data block. b) Peak mIoU over MACs for networks with different widths on thevalidation set of the CamVid dataset. Each data point represents the peak mIoU over all networkoutputs for one specific network width and the corresponding MACs for this output. For the followingstudies, we selected the network highlighted in red that achieves, out of 5 trials, a maximum mIoU of72.7 and 72.8 for independent and shared weights, respectively.
Figure 4: Ablation studies for multi-output training on the validation set of the CamVid dataset:The mIoU over MACs is shown for the same architectural hyperparameters, but for different sets ofan . a-c and e-g) The weight factors an are set to 1 for the shown outputs and to 0 otherwise. Eachdifferent set of weight factors is highlighted with a different color. d and h) The weight factors anare modulated over the network outputs. We increase the weight factor from 1 to 16 (incr) or keepthe weights uniform over all outputs.
Figure 5: Network performance in terms of mIoU over MACs (a), mIoU over number of parameters(b), mIoU over memory bandwidth (c), and mIoU over memory footprint of the intermediate state(d) on the test set of the CamVid dataset. In case of weight sharing, we increased the width of thenetwork (compare orange to green curve) to recover the mIoU of the network with independentweights (blue curve). According to Figure 4c and g we thin out the losses. ENet (Paszke et al.,2016) and CGNet (Wu et al., 2018) denote efficient reference networks. Note that the MACs of thesereference data points are normalized to the actual input size (480 Ã— 360) that was used to obtain thereported mIoU values.
Figure 6: Grid search over the following hyperparameters on the validation set of the CamViddataset: number of layers N, number of blocks L and number of residual blocks K. Parameters arenot shared between iterations n of the iterative block. The best set of hyperparameters (for detailsabout the selection, see Section 3.1) is depicted in red.
Figure 7: Like Figure 6, but the parameters are shared between iterations n of the iterative block.
