Figure 1: Representative image in-painting results for CelebA and MNIST. From left to right, neuralprocess (NP) (Garnelo et al., 2018b), attentive neural process (ANP) (Kim et al., 2018), and ours.
Figure 2: Generative graphical model for a single neural process task. C is the task “context” set ofinput/output pairs (xi , yi) and T is a target set in which only the input values are known.
Figure 3: Posterior contraction of qφ(z∖xc, yc) in a NP+max pooling model. (a) The entropy ofqφ(z∖xc, yc) as a function of context set size, averaged over different tasks (images) and contextsets. The gray shaded area in both plots indicates context set sizes that did not appear in the trainingdata for the amortization artifact. (b) Predictions of a classifier trained to infer the context set sizegiven only sC, the pooled embedding ofa context set. Equivalent results for the standard NP+meanpooling encoder and for ANP appear in the Supplementary Material.
Figure 4:	(Left) The first {10, 50, 100} pixels greedily chosen to minimizeDκL(qφ(z∣x, y)∣∣qφ(z∣xc, yc)). These pixels are highly informative about z, but only asubset of them will appear in the vast majority of random context sets. (Right) Posterior entropydecreasing as context size increases, for different methods of generating a context set: green isthe average over 100 random context sets of each size; blue greedily chooses context pixels tominimize posterior entropy; and orange greedily minimizes DκL(qφ(z∣x, y)∣∣qφ(z∣xc, yc)). Theblack dashed line represents the posterior entropy when conditioned on the full image.
Figure 5: Our modified neural process architecture. The encoder produces a permutation invariantembedding that parameterizes a stochastic task encoding z as follows: features extracted from eachelement of the context set using neural net hφ are pooled, then passed to other neural networks ρφand ηφ that control the distribution over task embedding z. The decoder uses such a task encodingalong with embeddings of target inputs to produce the output distribution for each target input.
Figure 6: Example MNIST and CelebA image completion tasks, for each of three NP methods. Thefollowing guide applies to each block. The top row shows context sets of different sizes (contextsets are exactly the same for all methods), i.e., one task per column. The ground truth image is in theupper right corner. The rows correspond to the mean function produced by gθ for different sampledvalues of z. The bottom row shows an empirical estimate of the standard deviation of the meanfunction from 1000 draws of z, a direct visualization of the uncertainty encoding.
Figure 7: Inception scores of conditional samples.
