Figure 1: Top: I-AE; bot-tom: CAE.
Figure 2: I-AE.
Figure 3: Evaluation of 3D → 2D embeddings.
Figure 4: Decoder surfaces without Lpiso(left) and with (right).
Figure 5: Results of data visualization experiment. Different colors indicate different ground turthlabels/classes. Top shows MNIST: FC architecture of the encoder/decoder (top row), and CNN(bottom row); Middle shows FMNIST: FC (top row), and CNN (bottom row); Bottom shows COIL20with CNN architecture, where zoom-ins of 3 classes are shown in the bottom row.
Figure 6: Sensitivity to hyper-parameters. Top: visualizations of MNIST (1st row) and FMNIST (2ndrow) datasets trained with different λiso values. Bottom: plots of the final train losses as a function ofλiso; left to right: Lrec (linear scale), Liso (log scale), and Lpiso (log scale).
Figure 8: CIFAR-10 reconstructions.
