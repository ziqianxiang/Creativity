Figure 1: Calibration error for individual classes under class-imbalance. The classes are orderedfrom the most (left) to the least (right) amount of samples. Fewer samples result in larger calibrationerrors. Imbalance is injected in CIFAR10/100 and eurosat randomly, removing any correlation withclass-specific properties. We do not modify Inaturalist, which already suffers from imbalance; thusclasswise calibration is correlated with class-specific properties.
Figure 2: Calibration error under label noise, simulated by randomly reassigning labels for a fractionof the training labels. Across datasets, label noise degrades network calibration. Thus, label noisefrom e.g. crowd sourcing can affect not only accuracy, but also calibration (Karger et al., 2011).
Figure 3: Calibration error under non-uniform label noise. We linearly increase label noise from 0to 0.5 among classes, and sort them thereafter. Increased noise leads to worse calibration.
Figure 4: Calibration error under different dataset sizes. We subsample the datasets, and give thesize as a fractions of the original size. Across all tasks, smaller datasets consistenly yield poorercalibration, highlighting how dataset size influences not only accuracy but also calibration.
Figure 5: Calibration error under combinations of data augmentations. Following He et al. (2016),we consider randomized cropping and flipping. Removing these components, often used to artifi-cially enlarge the dataset, increases the calibration error.
Figure 6: Calibration error of an NLP task duringtraining for different dataset sizes. The dataset issubsampled, and we give the relative size.
Figure 7: The softmax-cross entropy and labelsmoothing as a function of the logit of the cor-rect class (other logits are zero). Cross-entropydecreases monotonically, resulting in large logitsafter optimization.
Figure 8: Classwise calibration error for all methods for exponential-inbalanced datasets. Classshuffling uses the same seed between methods.
