Figure 1: (Left) An illustrative schematic of the first stage HP model architecture, which uses theobservational instances as both inputs and outputs with random sets of input variables obscured(crosses) during training using a dropout approach. (Right) An example learning curve for the HPmodel showing how the model adapts as the dropout rate on the input layer in increased step-wiseduring training.
Figure 2: An illustration of the predictive signals and the batch structure used for the edge predictionmodel for a three node DAG example (with variables A, B, and C). The input features include theoriginal observational variable values, a pair of input masks and their corresponding errors, and causeand effect indicators to specify the edge for which to make a prediction. Multiple mask-pair instancesfor the same edge of the same DAG are batched together, with the final prediction being a weightedmean across the multiple instances using learned attention weights.
Figure 3: (left) ROC curve for the edge prediction model across all edges in the test set for binary andcontinuous data including the undirected and directed prediction tasks. The kernel density estimateddistribution of DAG level AUC scores (middle) and F1 scores (right) across all test DAGs.
Figure 4: DAG-level F1 scores for DAGs with different numbers of nodes (left) and densities (center)and the edge-level recall values for edges with different effect sizes (right). The line shows the meanin each bin, while the band shows the standard deviation.
Figure 5: Mean attention weights for mask-pair observations with different properties.
