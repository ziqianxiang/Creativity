Figure 1: Amortized Causal Discovery. We propose to train a single model that infers causal relationsacross samples with different underlying causal graphs but shared dynamics. This allows us togeneralize across samples and to improve our performance with additional training data. In contrast,previous approaches (Section 2) fit a new model for every sample with a different underlying causalgraph.
Figure 2: A Probabilistic Implementation of ACD. An amortized encoder qφ(z∣x) predicts the causalrelations between the input time-series x. A decoder pθ(x|z) learns to predict the next time-stepof the time-series xt+1 given their current values xt and the predicted relations z . This separationbetween causal relation prediction and modeling lets us train the model across samples with differentunderlying causal graphs but shared dynamics.
Figure 3: Causal discovery performance (in AUROC) on the particles dataset (A-left) and Kuramoto(B-right). ACD improves with more training data, outperforming previous approaches with as few as50 available training samples on Kuramoto. In the high-data regime, encoder inference (Enc) is best,while test-time adaptation (TTA and Enc+TTA) is superior in low-data settings.
Figure 4: AUROC with unobserved tempera-ture. ACD with a latent variable outperformsa baseline which imputes a mean tempera-ture, and a learned fixed-temperature decoder(None).
Figure 5: AUROC with unobserved time-series. As more time-series are influencedby the unobserved one (x-axis), the benefit ofusing an additional latent variable for model-ing its effects grows.
Figure 6: Trajectory prediction with an unobservedtime-series (TS). Faded: ground truth. Bold: pre-diction, starts after observing the first half of theground truth. Dots denote end of TS. Top: ACDwith Latent, bottom: None baseline - does not modelunobserved TS. Left: unobserved TS, middle: TSdirectly influenced by unobserved, right: remainingTS. Though we underestimate the unobserved TS,observed TS prediction improves.
