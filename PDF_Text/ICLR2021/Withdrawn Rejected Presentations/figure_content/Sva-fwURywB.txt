Figure 1: The complete computational graph for representation learning, from (Bengio et al., 2020).
Figure 2: Experiments to evaluate efficiency in causality direction prediction. The model is discreteand both A and B are 10 dimensional variables (N = 10). The proposed approach is green. Baselineapproach (Bengio et al., 2020) is orange.
Figure 3: Experiments to evaluate efficiency in representation learning With exactly the same setting.
Figure 4: Experiments to evaluate efficiency in causality direction prediction. The model is discreteand both A and B are 100 dimensional variables (N = 100).
Figure 5: Experiments for other metrics The model is discrete and N = 10. Curve (blue) is medianover 100 runs, with 25-75% quantiles intervals, and it is significantly above zero (red), indicatingthese metrics are good indicators for causality learning.
Figure 6:	Experiments to evaluate robustness. A â†’ B is the correct causality direction. Here,N = 10, M = 10, K = 200. Curves are median over 100 runs, with 25-75% quantiles intervals. Theresult shows that the models with correct causalities are slow to adapt in baseline approach (a), whichmeans the baseline approach does not work, but the proposed approach (b) works.
Figure 7:	Accuracy when adding noise.
