Figure 1: Average representa-tion similarity as determined byCKA (Kornblith et al., 2019) forResNet-14 on CIFAR-10 across non-determinism sources. Layers are se-lected uniformly across the network,ranging from the first convolutionallayer (Conv1), the output of eachresidual block (ResBlock1,2,3), thepenultimate average pooling layer(AvgPool), and the logits themselves(Logits). Shown is the average CKAvalue between pairs of models.
Figure 2: The effect of the onset of nondeterminism on the variability of accuracy and cross-entropyin converged models. Each point corresponds to training a set of 20 models deterministically for acertain number of epochs (x-axis), then enabling a source of nondeterminism by varying its seedstarting from that epoch and continuing through the end of training.
Figure 3: The impact of a random bit change during initialization for linear models vs 2-layer modelswith a single fully-connected hidden layer, where row 1 considers the full 500 epochs of training, androw 2 zooms in on the first 10 epochs. The left column of each row gives the range of cross-entropyvalues for 100 models in the middle 95th percentile of cross-entropy, plotted at each epoch. The rightcolumn of each row presents the standard deviation of these models.
