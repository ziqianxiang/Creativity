Figure 1: Relevance maps for models with different architectures. Three models not only predict the“stop sign” right, but also share similar relevance maps.
Figure 2: Framework of RAD. xk is the sample in iteration k and f(xk) is the network predictionfor it. h(xk, T) stands for the relevance map for all attacked nodes in T. RAD works by repeatingprocesses denoted by “black”, “red” and “blue” arrows in turn.
Figure 3: RAD’s transferability origins from the change of relevance maps. The image contains aperson and a skateboard. By attacking on relevance maps, both surrogate models make extremelyconfusing predictions.
Figure 4: The original image and the adversarial perturbations (×5 in magnitude for demonstration)generated by Dfool (Lu et al. (2017)), DAG (Xie et al. (2017)), and RAD (from left to right)3.3	What is the Relevance Maps for DetectorsWe analyze the potential of RAD above, below we make it feasible by addressing three crucial issues.
Figure 5: Difference between relevance maps from SGLRP and Multi-Node SGLRP. The relevancemaps are for YOLOv3 (Redmon & Farhadi (2018)).
Figure 6: RAD has a great transferability. The same adversarial sample generated by attacking MaskR-CNN fools all 5 black-box detectors.
Figure 7: The influence of ε on detection mAP in RADMlM3M4M5M6M7M8M94.4	RAD’s Transferability to Instance SegmentationDetection and segmentation are similar in some aspects, so they could be implemented in one network(He et al. (2017); Cai & Vasconcelos (2018); Chen et al. (2019a)). Also, adversarial samples forobject detection tend to transfer to instance segmentation (Xie et al. (2017)). Accordingly, we evaluatethis cross-task transferability by RAD on surrogate detectors YOLOv3 (Redmon & Farhadi (2018),M2), RetinaNet (Lin et al. (2017), M3) and Mask R-CNN (He et al. (2017), M5). From the results inTable 4, we find that RAD also greatly hurts the performance of instance segmentation, leading to adrop on mAP of over 70%. This inspire the segmentation attackers to indirectly attack detectors.
Figure 8: Transition of prediction and relevance map in RAD (from top to bottom and left to right).
Figure 9: Detection and segmentation results in COCO and AOCO by YOLOv3 and Mask R-CNN.
