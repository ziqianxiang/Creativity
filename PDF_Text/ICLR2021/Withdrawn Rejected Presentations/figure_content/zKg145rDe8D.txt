Figure 1: Visual comparison of present attribution methods and the proposed A-FMI at 10% ofimportant pixels insertion for the prediction of class “dogsled”. Pixels with significant attributionsare remained, while the rest is removed. A black reference is used for DeepLIFT, IG and A-FML•	One research line exploits single pixels as attribution features and learns the gradients,modified gradients or integrated gradients of the target class as the attribution scores. De-spite great success, one limitation is that it violates the Strong Relevance characteristicof attribution features, since pixels are strongly related to thier surrounding pixels. Suchredundancy easily results in suboptimal and fragile attributions, being akin to the edge de-tector (Adebayo et al., 2018) and vulnerable to small perturbations (Ghorbani et al., 2019).
Figure 2: Overview (left) and Visual Comparisons (right) between Grad-CAM and A-FMLmay occur due to nonlinear activation functions (e.g., sigmoid, tanh, and even ReLU). Taking a two-layer ReLU network F(α) = ReLU(-ReLU(-α + 1) + 2) as an example, the gradient of F(α) atα = 2 is 0, intuitively indicating its trivial contribution. However, when changing a from 0 to 2, thenetwork output changes from F(α = 0) = 1 to F(α = 2) = 2, which suggests that α is significantfor prediction. Clearly, such vanishing gradients easily mislead the learning of attribution scores.
Figure 3: Reference reliability. A-FMI is reliable for the different choices of reference, while bothDeePLIFT and IG determine the attribution strongly relative to a chosen reference. B, W, and Rstand for black, white, and random reference respectively. See more samples in Appendix C.
Figure 4: Class discriminability. Category-specific visualizations of all methods at a fixed 10% ofimportant pixels insertion. The original image contains exactly two categories - Collie and Ibizanhound. The third category - Cockatoo - is the minimal activated category.
Figure 5: Visual Inspections. A visual comparison of all methods, where 5% and 50% importantpixels are included, respectively. See more examples in Appendix D.
Figure 6: Accuracy curves of various attributionmethods w.r.t. different percentage of importantpixel insertion (Left: VGG19; Right: ResNet50).
Figure 7: Visual Inspections of A-FMI on the VGG-16, VGG-19, ResNet-50, ResNet-152, andResNeXt-101-32x8d models.
Figure 9: Predictive Performance. Accuracy curves and Softmax ratio curves of various attributionmethods w.r.t. different percentage of important pixels insertion. Best viewed in color.
Figure 10: Visual Inspections. A visual comparison of all methods, where the percentage of im-portant pixel insertion varies from 5% to 50%. Gradient, DeepLIFT and IG tend to produce grainyimages. LRP, XRAI and Grad-CAM might choose disconnected areas. A-FMI focuses more on theobjects of interest.
Figure 11: Visual Inspections. A visual comparison of all methods, where the percentage of im-portant pixel insertion varies from 5% to 50%. Gradient, DeepLIFT and IG tend to produce grainyimages. LRP, XRAI and Grad-CAM might choose disconnected areas. A-FMI focuses more on theobjects of interest.
Figure 12: Visual Inspections. A visual comparison of all methods, where the percentage of im-portant pixel insertion varies from 5% to 50%. Gradient, DeePLIFT and IG tend to produce grainyimages. LRP, XRAI and Grad-CAM might choose disconnected areas. A-FMI focuses more on theobjects of interest.
Figure 13: Visual Inspections. A visual comparison of all methods, where the percentage of im-portant pixel insertion varies from 5% to 50%. Gradient, DeePLIFT and IG tend to produce grainyimages. LRP, XRAI and Grad-CAM might choose disconnected areas. A-FMI focuses more on theobjects of interest.
Figure 14: Visual Inspections. A visual comparison of all methods, where the percentage of im-portant pixel insertion varies from 5% to 50%. Gradient, DeePLIFT and IG tend to produce grainyimages. LRP, XRAI and Grad-CAM might choose disconnected areas. A-FMI focuses more on theobjects of interest.
