Figure 1: Illustration of the train-losshacking phenomenon. Given finite datapoints, a sufficiently flexible model rcan easily make the training loss, e.g.,-----BRLSIF (r), diverge to —8.
Figure 2: Experimental results of Section 5. The horizontal axis is epoch, and the vertical axis isAUROC. The learning rates of the left and right graphs are 1 × 10-4 and 1 × 10-5, respectively.
Figure 3: The learning curves of the experiments in Section 5. The horizontal axis is epoch. The ver-tical axes of the top figures indicate the training losses. The vertical axes of the bottom figures showthe AURPC for the test data. The bottom figures are identical to the ones displayed in Section 5.
Figure 4: Top figures: the detailed experimental results for Section G.1.1. Bottom figure: thedetailed experimental results for Section G.1.2. The horizontal axis is epoch, and the vertical axis isAUROC.
Figure 5: Experimental results of Section 5 without gradient ascent/descent heuristic. The horizontalaxis is epoch, and the vertical axis is AUROC. The learning rates of the left and right graphs are1×10-4 and 1 × 10-5 , respectively. The upper graphs show the AUROCs and the lower graphsʌshow Ede[r(X)], which will approach 1 when We successfully estimate the density ratio.
Figure 6: The learning curves of the experiments in Section 5 without gradient ascent/descent heuris-tic. The horizontal axis is epoch. The vertical axes of the top figures indicate the training losses.
Figure 7: Top figures: the detailed experimental results for Section G.1.1 without gradient as-cent/descent heuristic. Bottom figure: the detailed experimental results for Section G.1.2. Thehorizontal axis is epoch, and the vertical axis is AUROC.
