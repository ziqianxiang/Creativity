Figure 1: Graphical models for: generative SSL (left); discriminative SSL (previous (Chapelle et al.,2006)) (centre); discriminative SSL (ours) (right). Shading variables are observed (else latent).
Figure 2: A general framework for neuro-symbolic learning combining statistical learning (perception)and logical rules (reasoning) (Valiant, 2000; Garcez et al., 2019). We draw an analogy to ourprobabilistic model for discriminative SSL (§3), in which p(θ) can be defined with logical rules (§5).
Figure 3: The distribution p(θ) for a mix of 2 univariate Gaussians (varying class separation).
Figure 4: UnsuPervised loss components of entropy minimisation (Eq. 2), mutual exclusivity (Eq. 3)and pseudo-labelling (Eq. 4) (exponentiated for comparison to probabilities), seen as continuousrelaxations p(θ) of the discrete distribution p(θ), for deterministic y|x with distinct classes.
Figure 5: An illustration of the correspondence between logical rules and the support of p(θ). (topleft) All plausible values of θ if y |x is deterministic, i.e. θ restricted to the vertices (Sec. 4). (bottomleft) an example set of logical rules over label attributes. (centre) All valid values of θ under the rules,as encoded in qδ(θ), a function over P that defines the support of p(θ). (right) qg(θ), a relaxation ofqδ(θ), defined over [0, 1]K, the gradient of which can “guide” unlabelled predictions towards valid θ.
