Figure 1: Conceptual illustrations of different CIL methods. (a) Conventional methods use all avail-able data (imbalanced classes) to train the model (Rebuffi et al., 2017; Hou et al., 2019) (b) Castroet al. (2018), Hou et al. (2019) and Douillard et al. (2020) follow the convention but add a fine-tuningstep using the balanced set of exemplars. (c) Our MANets approach uses all available data to updatethe plastic and stable blocks, and use the balanced set of exemplars to meta-learn the aggregatingweights. We continuously update these weights such as to dynamically balance between plastic andstable blocks, i.e., between plasticity and stability. *: herding is the method to choose exemplars(Welling, 2009), and can be replaced by other methods, e.g., Mnemonics Training (Liu et al., 2020).
Figure 2: (a) The architecture of MANets. For each residual level, we derive the feature maps fromstable blocks (φ θbase , blue) and plastic blocks (η, orange), respectively, aggregate them withmeta-learned weights, and feed the result in the next level. (b) An improved version of MANets byincluding a highway connection block (h, green) at each level.
Figure 3: The activation maps using Grad-CAM (Selvaraju et al., 2017) for Phase 5 (the last phase)model on ImageNet-Subset (N =5). Samples are selected from the classes coming in Phase 0 (left)and Phase 5 (right), respectively. Green tick (red cross) means the discriminative features are acti-Vated on the object regions successfully (unsuccessfully). αη = 0.428 and αφ = 0.572.
Figure 4: Phase-wise accuracy on CIFAR-100. “Up-per Bound” shows the results of joint training with allprevious data accessible in each phase. The averageaccuracy of each curve is reported in Table 1, and ourresults are on the row of “Mnemonics + MANets”.
Figure 5: The changes of values for αη and αφ onCIFAR-100 (N =10). All curves are smoothed with arate of 0.8 for a better visualization. More results areprovided in the appendices.
