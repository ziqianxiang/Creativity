Figure 1: The workflow of BayesAdapter. We assume a three-layer model for simplicity. We at first pre-train a DNN counterpart of the target BNN via maximum a posteriori (MAP) estimation, then transform itto be a BNN by replacing the point-estimate parameters with a diagonal Gaussian centered at them, fromwhich the parameter samples are drawn for computation. After that, We build separate optimizers with built-inweight decay for the Gaussian mean and variance, and perform fine-tuning to fit the data under uncertaintyregularization based on autodiff libraries.
Figure 2: The comparison between standard convolu-tion and convolution used in BayesAdapter.
Figure 3: The histograms for the mutual information uncertainty of normal data and OOD data given by modelstrained w/ and w/o uncertainty regularization.
Figure 4: The change of test ac-curacy w.r.t. the number of MCsamples for estimating Eq. (3).
Figure 6: Some random samples of the OOD data used for evaluation. The first row refers to the fake sam-ples from BigGAN on ImageNet. The second row refers to the adversarial examples generated by PGD onImageNet. The third row refers to the fake samples from DeepFake.
Figure 7: Left: the mean of the Gaussian posterior. Right: the variance of the Gaussian posterior. Thesecorrespond to a convolutional kernel with 64 output channels and 3 input channels, where every output channelis plotted as a separate image.
