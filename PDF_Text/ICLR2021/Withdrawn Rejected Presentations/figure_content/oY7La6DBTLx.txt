Figure 1: Atoy example of computing the in-classscores for two in-class (sea lion) images with dif-ferent viewpoints. Each row represents how thein-class score is calculated for a given input.
Figure 2: The one-class classification performance of the self-supervised method (Hendrycks et al.,2019). (a-c) The in-class score distributions of in-class and out-of-class test images (Dataset:CIFAR-10, In-class: Horse), (d) AUROC for geometrically/non-geometrically transformed inputs.
Figure 3: Comparisons with non-self-supervised methods in the three evaluation setupseach dataset. We also provide the results of DSVDD that adopts the data augmentation technique,denoted by DSVDD+; the training in-class images are randomly augmented by T ã€œT*. For allthe setups, the competing methods show poorer performances compared to our methods. Specifi-cally, the data augmentation technique results in the limited performance gains in the anchor/randomsetups, whereas it even brings an adverse effect in the fixed setup. This implies that the simple ap-proach is not sufficient to address the viewpoint sensitivity of the one-class classifiers.
Figure 4: The in-class score distributions of in-class and out-of-class test images in the fixed view-point setup (Dataset: SVHN, In-class: 0).
