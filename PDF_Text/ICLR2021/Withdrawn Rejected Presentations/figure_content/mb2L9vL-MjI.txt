Figure 1: The dynamic behavior of learning the single neuron target function. The results of RFM are shownas a comparison. Here, m = 200, d = 100 and the learning rate is 0.001. (a) The dynamics of the populationrisk. (b) The a coefficients of the converged solution. (c) The dynamics of the magnitude of each neuron, wherethe magnitude is defined as akbk. (d) The projection to the first two coordinates of b. The green and orangeones correspond to the initialization and GD solution, respectively.
Figure 2: The dynamic behavior of learning the circle neuron target function. Here m = 100, d = 100 andthe learning rate is 0.005. (a) The dynamics of the population risk. (b) The dynamics of the magnitude of eachneuron; the inset is the zoom-in of the first 30000 iterations. (c) The a coefficients of the solutions selected torepresent the three steps.
Figure 3: The dynamic behavior of learning a finite-neuron targetfunction. Here, a* = 1/m, {bj } are uniformly drawn from SdTwith d = 100 and the learning rate is 0.001. Left: The magnitudeof each neuron of the convergent solution. Right: The dynamicsof the magnitude of each neuron.
Figure 4: The dynamic behavior of learning the surface neurontarget function. Here m = 100, d = 100 and learning rate η =0.005. Left: The dynamics of the population risk; Right: Thedynamics of the magnitude for each neuron. The inset is the zoom-in of the first 500, 000 iterations.
Figure 5:	Comparison between a(t) and aeff (t) at different times, where a(t), aeff (t) are the solutions of theoriginal and effective dynamics, respectively. Left: The single neuron target function fɪ. Right: The surfaceneuron target function f4.
Figure 6:	The dynamic behavior of learning single-neuron target function for two mildly over-parameterizedcases. Here n = 200, d = 19 and learning rate is 0.001. For each case, Left: The dynamics of the training andtest losses (results from the corresponding random feature model is also plotted for comparison); Right: Thedynamics of the magnitude of each neuron.
Figure 7: Heatmap of test errors of GD so-lutions with varying m’s and n’s. The targetfunction is the single-neuron target functionf1 with d = 40. GD is stopped when thetraining loss is smaller than 10-8. The twodashed lines corresponds to m = n/(d + 1)and m = n, respectively.
Figure 8: Test performance of GD solutions for the circle neuron f2. (a) The path norm and test error as afunction of m. Here n = 200, d = 20 and the learning rate is 0.001. GD is stopped after the training error issmaller than 10-6. (b) The test error as a function of n for three different input dimensions.
Figure 9: GD-MF dynamics for learning the single neurontarget function fɪ. Here m = 50,d = 100,n = ∞ andlearning rate is 0.001. Left: The magnitude of each neu-ron for the converged solution. Right: The projection to thefirst two coordinates of b for each neuron. The green onescorrespond to the random initialization; the orange ones cor-respond to the solutions found by GD-MF.
Figure 10:	(a) The heatmap of test errors of GD-MF solutions for learning the single neuron fɪ. (b) The testperformance of learning the circle neuron f2. The left shows the test error as a function of m. The right showsthe test error as a function of n for the scaling m = 1.5n.
Figure 11:	The dynamic behavior of GD with β = 1/√m. Here the target function is the single neuron fɪ.
Figure 12: Learning finite neurons with a* = 1/m, bj 〜∏o. Here m = 100, m* = 40 and learning rate is0.001. Left: The magnitude of each neuron of the final solution; Right: The dynamics of the magnitude foreach neuron.
Figure 13:	The difference between the effective dynamics and the original dynamics. Left: The single neurontarget function f With m = 50; Right: The surface neuron target function f4 With m = 50.
Figure 14:	GD dynamics for learning the single neuron target function in the under-parameterized regime.
Figure 15: GD dynamics for the circle neuron target function in the under-parameterized case. Here m50, n = 500, d = 5. (a) The dynamics of training and test loss. (b) The dynamics of the outer coefficients.
Figure 16: The dynamic behavior of the GD solutions for m = 3n/(d + 1). Here m = 60, n = 400, d = 19and learning rate η = 0.001.
Figure 17: The dynamic behavior of the GD solutions for m = 0.75n. Here m = 300, n = 400, d = 19 andlearning rate η = 0.001.
Figure 18: Comparison between the GD solutions for 2LNN and RFM for the single neuron target functionfι. The learning rate 0.001 and m = 2000,n = 200, d = 20. Left: The time history of the training and testerror. Right: The magnitude of the converged solutions.
Figure 19: Test performance of GD solutions for single neuron fɪ. (a) The path norm and test error as afunction of m. Here n = 200, d = 20 and the learning rate is 0.001. GD is stopped after the training error issmaller than 10-8. (b) The test errors as a function ofn for three different input dimensions.
