Figure 1: Typical convergence curve of z during an ODE integration for GFE and GFE 2nd orderusing the fixed grid ODE solver. Experiments were performed on MNIST. Mean cross-entropy lossplotted against time for three training iterations, darker corresponds to earlier iteration. Curves areobtained using the same batch of training images. The plot shows how convergence curves of zchanges with training iterations. Darker curves are for earlier iterations. In later iterations, theconvergence curves reach lower loss, meaning updates of the decoder network’s parameters lead tomore faithful latent space representations, as expected.
Figure 2: Schematic diagram of the GFE implementation. The two optimisation correspond to(Step 1) the latent space optimisation i.e. ’encoding’ and (Step 2) the parameter update of the neuralnetwork.
Figure 3: Left Validation mean cross-entropy loss plotted against MNIST training iterations for theapproximate and full adjoint GFE methods. The full adjoint has a slight advantage over the approx-imate. Right Validation mean cross-entropy loss plotted against MNIST training iterations for theGFE, 2nd order GFE and GFE-amd methods. The GFE-amd is both more stable and approaches abetter convergence relative to the other methodsA direct comparison of the GFE-amd to a conventional AE for an MNIST training can be seen inFigure 4. The x-axis shows the number of training images (instead of iterations) the algorithm seesuntil that point in the training. The training is based on mini-batch training using the data withreplacement, going over the training data multiple times. The GFE-amd is substantially superior inlearning per training image, reaching near convergence with at 800000 images, see Figure 4 (left).
Figure 4: Left Validation mean cross-entropy loss plotted against number of MNIST trainingimages for the GFE-amd and AE methods. The former shows a significant convergence with a tinyamound of training images. Right Validation mean cross-entropy loss plotted against time for theGFE-amd and AE methods. The latter is significantly faster to the former as much more iterationsare carried out in the same time-spanNumber of Training images	AE	GFE-amd	train:AE test:GFE-amd480 (0.24%)	一	0.2660	0.2098	0.2634960 (0.49%)	0.2618	0.1987	0.25251920 (0.98%)	0.2488	0.1558	0.23233840(1.95%)	0.2195	0.1336	0.2038.	5760 (2.9%)	一	0.1954	0.1136	0.1829	∙Table 1: Test-set average cross entropy loss for different number of training data, % reflects thepercentage relative to total training data needed for convergence of the method. Carried out for theAE GFE-amd methods. The forth column represents testing the decoder of an AE trained networkwith GFE-amd. The GFE-amd is far superior here in learning with a limited image sample.
Figure 5: (a) Test-set reconstructions for trained GFE-amd (left) and AE (right) that only see 1%of MNIST (top) and FashionMNIST (bottom) training images. (b) Test-set reconstructions for fullytrained GFE-amd (left) and AE (right) with MNIST (top) and FashionMNIST (bottom) trainingimages. Note: The labels are identical in the respective reconstructions.
Figure 6: t-SNE map of the latent space plotted for MNIST trained Left GFE and Right AEmethods.
Figure 7: t-SNE map of the latent space plotted for MNIST trained with 1% training data Left GFEand Right AE methods. The GFE latent space is well optimised even with a fraction of the data.
