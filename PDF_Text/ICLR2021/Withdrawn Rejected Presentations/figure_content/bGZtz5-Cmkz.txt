Figure 1: Illustration of the collision effect in latent space-based Bayesian optimization tasks. Sincethe data points around the optimum severely collided, BO is misguided to the sub-optimum.
Figure 2: CoFLO schematic1 Note that we have introduced several hyper-parameters in the algorithm design; we will defer ourdiscussion on the choice of these parameters to Section 5.
Figure 3: Experiment results on four pre-collected datasets. Each experiment is repeated at leastten times.The colored area around the mean curve denotes the √σn. Here σ denotes the empiricalstandard deviation. n denotes the number of cases repeated in experiments. The hyper-parametersare set as the following. The retrain interval T are set to be 100 iterations for 8c 8a and 8d, 200 for8b. The Regularization parameters ρ are set to be 1e5 for 8c 8a and 8d, 1e3 for 8b. The penaltyparameter λ are all set to be 1e-2. The weighting parameter γ are set to be 1e-2. The prior meanμo are all set to be 0. The squared exponential kernel is used as the GP covariance for all the fourexperiments. We also demonstrate the median curves in the Appendix.
Figure 4: Illustrate the collision and quantified measurement of the collision. Here we propose twoquantity measurement of the collision. For the second graph the y axis of the is the ratio of exceeding∣yι - y2∣ > ∣zι - z2∣ * L. And for the third graph, the y axis of the third column is the mean ofλ = |y1 - y2|/|z1 - z2|.
Figure 5: Illustrate the 1-D latent space of Feynman III.9.52 dataset. 5a shows a regularized latentspace with a few observable collisions. 5b shows a non-regularized latent space with bumps ofcollisions especially around the maxima among the observed data points. Besides, having fewercollisions in the latent space contribute to the optimization through improving the learned Gaussianprocess. We observed in this comparison that the next point selected by the acquisition function ofthe regularized version is approaching the global optima, while the next point in the non-regularizedversion is trying to solve the uncertainty brought by the severe collision near the currently observedmaxima.
Figure 6: Network graph of a (L + 1)-layer dense network with D input units and 1 output units. Inour experiments L is set to be 4 for Rastrigin 2D, Feynman II.9.52, Supernova, and 5 for SPOKES.
Figure 7: Simple regrets under different parameter settings on the SPOKES dataset. 7b shows that aregularization parameter too big could distract the training process and downgrade the performance.
