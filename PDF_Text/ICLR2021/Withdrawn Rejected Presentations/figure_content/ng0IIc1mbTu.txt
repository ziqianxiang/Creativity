Figure 1: Left: An illustration of attention mechanisms with attention map at different granularities.
Figure 2: (a): Plot of accuracy over epochs for networks trained with different initialization of aand β. A larger initial β leads to faster convergence and higher accuracy is obtained when α isinitialized to 0.25 or 0.75. (b): The learning procedure of a and β which are initialized to 0.25and 1.0, respectively. (c): The learned final AReLU,s for the three convolutional layers of theMNIST-Conv network. The shaded region gives the range of AReLU curves.
Figure 3: Plots of mean testing accuracy (%) on MNIST for five-time trainings of MNIST-Convover increasing training epochs. The training is conducted using SGD with small learning rates (left:1 × 10-4, right: 1 × 10-5).
Figure 4: Plots of mean testing accuracy (%) on CIFAR100 over increasing training epochs, usingdifferent network architectures. The training is conducted using SGD with a learning rate of 0.1.
