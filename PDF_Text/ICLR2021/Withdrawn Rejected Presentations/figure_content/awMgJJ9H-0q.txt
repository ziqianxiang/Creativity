Figure 1: KDE plots of the target samples (the first row), KDE plots of the learned samples via EPTwith f -divergence/ Lebesgue norm (left six of the second/third row)) and surface plots of estimateddensity ratio/ difference after 20k iterations ofEPT with f -divergence/ Lebesgue norm (right six ofthe second/ third row).
Figure 2: Learned transport maps (left two) and estimated density ratio (right two) in learning5squares from 4squares and learning large4gaussians from small4gaussians.
Figure 3: Particle evolution of EPT on MNIST and CIFAR10.
Figure 4: Visual comparisons between real images (left 3 panels) and generated images (right 3panels) by EPT-LSDR-χ2 on MNIST, CIFAR10 and CelebA.
Figure 5: The numerical convergence phenomenon of EPTv1 on simulated datasets. First row: LSDRfitting loss (14) with α = 0 v.s. iterations on pinwheel, checkerboard and 2spirals. Second row:Estimation of the gradient norm EX 〜qk [∣∣VRφ(X) ∣∣2] v.s. iterations on pinwheel, checkerboard and2spirals.
