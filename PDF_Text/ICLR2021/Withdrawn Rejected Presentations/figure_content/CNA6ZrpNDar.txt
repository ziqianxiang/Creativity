Figure 1: Tropical Hypersurfaces and their Corresponding Dual Subdivisions. We show three tropicalpolynomials, where the solid red and black lines are the tropical hypersurfaces T(f) and dual subdivisions δ(f)to the corresponding tropical polynomials, respectively. T(f) divides The domain of f into convex regionswhere f is linear. Moreover, each region is in one-to-one correspondence with each node of δ(f). Lastly, thetropical hypersurfaces are parallel to the normals of the edges of δ(f) shown by dashed red lines.
Figure 2: Decision Boundaries as Geometric Structures. The decision boundaries B (in red) comprise twolinear pieces separating classes C1 and C2. As per Theorem 2, the dual subdivision of this single hidden neuralnetwork is the convex hull between the zonotopes ZG1 and ZG2 . The normals to the dual subdivison δ(R(x))are in one-to-one correspondence to the tropical hypersurface T (R(x)), which is a superset to the decisionboundaries B. Note that some of the normals to δ(R(x)) (in red) are parallel to the decision boundaries.
Figure 3: Effect of Different Initializations on the Decision Boundaries Polytope. From left to right:training dataset, decision boundaries polytope of original network (before pruning), followed by the decisionboundaries polytope for networks pruned at different pruning percentages using different initializations. Notethat in the original polytope there are many more vertices than just 4, but they are very close to each otherforming many small edges that are not visible in the figure.
Figure 4: Tropical Pruning Pipeline. Pruning the 4th node, or equivalently removing the two yellow verticesof zonotope ZG2 does not affect the decision boundaries polytope, which will lead to no change in accuracy.
Figure 5: Results of Tropical Pruning. Pruning-accuracy plots for AlexNet (top) and VGG16 (bottom) trainedon SVHN, CIFAR10, and CIFAR100, pruned with our tropical method and three other pruning methods.
Figure 6: The Newton Polygon and the Corresponding Dualsubdivision. The Figure on the leftshows the newton polygon P(f) for the tropical polynomial defined in the second example in Figure1. The dual subdivision δ(f) is constructed by projecting the upper faces of P(f), shadowing, on R2.
Figure 7: Dual View of Tropical Adversarial Attacks. We show the effects of tropical adversarial attacks ona synthetic binary dataset at two different input points (in black). From left to right: the decision regions of theoriginal and perturbed models, and decision boundaries polytopes (green for original and blue for perturbed).
Figure 8: Effect of Tropical Adversarial Attacks on MNIST Dataset. We show qualitative examples ofadversarial attacks, produced by solving Problem (9), on two digits (8,9) from MNIST. From left to right, imagesare classified as [8,7,5,4] and [9,7,5,4] respectively.
Figure 9: Effect of Tropical Adversarial Attacks on MNIST Images. First row from the left:Clean image, perturbed images classified as [7,3,2,1,0] respectively. Second row from left: Cleanimage, perturbed images classified as [9,8,7,3,2] respectively. Third row from left: Clean image,perturbed images classified as [9,8,7,5,3] respectively. Fourth row from left: Clean image, perturbedimages classified as [9,4,3,2,1] respectively. Fifth row from left: Clean image, perturbed imagesclassified as [8,4,3,2,1] respectively.
Figure 10: Effect of Different Initializations on the Decision Boundaries Polytope. From left to right:training dataset, decision boundaries polytope of original network followed by the decision boundaries polytopeduring several iterations of pruning with different initializations.
Figure 11: Comparison between the decision boundaries polytope and the polytopes represent-ing the functional representation of the network. First column: decision boundaries polytopeδ(R(x)) while the remainder of the columns are the zonotopes δ(H1(x)), δ(Q1 (x)), δ(H2(x)) andδ(Q2(x)) respectively. Under varying pruning rate across the rows, it is to be observed that thechanges that affected the dual subdivisions of the functional representations are far smaller comparedto the decision boundaries polytope.
Figure 12: Pruning Ressults on Toy Networks. We apply tropical pruning on the toy network thatis in the form of Affine followed by a ReLU followed by another Affine. From left to right: (a) datasetused for training (b) pruning networks with 100 hidden nodes (c) 200 hidden nodes (d) 300 hiddennodes.
Figure 13: Results of Tropical Pruning with Fine Tuning the Biases of the Classifier. Tropicalpruning applied on AlexNet and VGG16 trained on SVHN, CIFAR10, CIFAR100 against differentpruning methods with fine tuning the biases of the classifier only.
Figure 14: Results of Tropical Pruning with Fine Tuning the Biases of the Network. Tropicalpruning applied on AlexNet and VGG16 trained on SVHN, CIFAR10, CIFAR100 against differentpruning methods with fine tuning the biases of the network.
