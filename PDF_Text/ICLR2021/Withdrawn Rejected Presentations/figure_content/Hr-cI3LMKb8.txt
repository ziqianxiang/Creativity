Figure 1: Affinity cycle consistency (ACC) yields embeddings which isolate factors of variation in adataset P (I). It leverages weak supervision in the form of set membership, such as in the set of im-ages P(I|d0) rendered around a given synthetic car (top, left). A cycle consistency loss encouragesfinding correspondence between sets of inputs by extracting common factors that vary within bothsets and suppressing factors which do not. We show that ACC isolates nontrivial factors of variation,such as pose in the example above, even when only one of the sets has been grouped. Importantly,this allows the incorporation of data with no supervision at all, such as the images of real cars (bot-tom, left). The learned representations (right, t → ∞), contain only the isolated factor of variation(contrast the alignment here with the untrained representations shown in the middle, t = 0).
Figure 2: Sets with different active and inactive factors of variation from the Shapes3Ddataset (Burgess & Kim, 2018). On the left, we have the same active factor of variation for bothsets. In the middle, we have some overlapping active factors of variation. On the right, we have noknown inactive factor of variation for set B. We find ACC to be effective in all these three scenarios.
Figure 3: Analysis on Shapes3D. (a) An example pair of training sets where wall hue is the onlyinactive factor in each set. (b) We train ACC on pairs of image sets as in (a) and embed to 2D. Eachof the six plots displays the same 256 embeddings colored by their value for a different generativefactor. The bar chart shows the mutual information between each of the factors and the learnedrepresentation. (c) We repeat the experiments with 50 random seeds and display the spread in mutualinformation values as a violin plot. Each subplot shows a different split of active/inactive factorsduring training. The output from an untrained network is shown in black. In the middle two subplots,we compare to the setting with one unconstrained input set, i.e. with no inactive factors of variation.
Figure 4:	Style isolation in MNIST. We define digit style as a combination of all factors of variationindependent of the class. After training ACC with images grouped by digit, we evaluate the isolationof the style factors. We visualize embeddings from the test set using the top two PCA dimensions(accounting for more than 0.99 of the total variance in the trained embeddings). Before the networkis trained, all the embeddings cluster together (top left), while after training (top middle) the embed-dings fan out by style factors, primarily thickness and slant (this can be observed both within andacross digits). The digit 9 is held out at training, yet embeddings of9s (bottom middle) are similarlyarranged by thickness and slant, showing ACC generalizes to unseen inactive factor values. On theright we show retrieval results, where the boxed images along the diagonal are queries and theother images in each row are the nearest embeddings for each digit class (all from the test set). ACCretrieves images closer in style than CC-VAE (Jha et al., 2018), a generative approach which alsoutilizes set supervision. Notably, ACC required 100x fewer training steps, highlighting a benefit oflearning partial descriptions through discriminative approaches as compared to generative models.
Figure 5:	Retrieval results from ACC and ResNet embeddings. For each query image from thePascal3D+ test split, we display the four nearest neighbors in embedding space, out of 3200, fromthe Pascal3D+ train split and the ShapeNet images. Note how ACC yields similar representationsfor images which are often visually quite different, in contrast to the ResNet output. This serves asqualitative evidence that pose is being effectively isolated in the ACC-trained embeddings.
Figure 6: Strengthening spherical regression with ACC. We append a spherical regression head(Liao et al., 2019) to the network and find that an ACC loss on the intermediate embeddings signifi-cantly improves performance.
Figure 7: Probing information content in higher dimensions via classification. We repeat the ex-periments of Section 4.1 in 4, 16, and 64 dimensional embedding space, though with 10 replicaseach instead of 50. As a proxy for the mutual information, we use the test set classification accuracyof simple fully connected networks trained to classify each of the six generative factors. As before,in each subplot we display in gray the baseline results from embedding with an untrained, randomlyinitialized network. Also as before, the colors of each subplot indicate the same information as theshaded columns: which of the generative factors were inactive while training ACC. In the rightmostsubplots, Gaussian-distributed random noise was added to the embeddings to effectively remove in-formation on length scales less than the characteristic length scale of the ACC loss, the square rootof the temperature.
Figure 8:	Highly constrained inputs for Shapes3D experiments. We extend the experiments of Sec-tion 4.1 by constraining the input sets with one additional generative factor, to better probe thedifference between the three hue and the three geometric factors. In (a) we show one example oflearned representations where the three hue factors and scale are inactive factors in each trainingset. Interestingly, the shape factor - of which there are four possible values - seems to be split intotwo groups, one with cylinders and cubes and the other with pills and spheres. We observed thisparticular grouping to happen in the majority of the cases for this active-inactive split, indicatinganother level of salience difference with respect to the embedding network. In (b) we measure themutual information I(U; G) with respect to all six generative factors, as in Figure 3c, where thefourth (geometric) inactive factor is the scale, shape, and orientation, respectively.
Figure 9:	The case for finding more than one factor of variation, through a simple example.
Figure 10: Ablative studies with spherical regression + ACC network. Error bars are the standarderror of the mean over 10 random seeds for each configuration, with less than 1% of the runsdiscarded for lack of convergence. We show results on the Pascal3D+ test split for the car and chaircategories. For each row, the training configuration is the same as described in Appendix A withonly the listed aspect of training being changed. In the first row, no titration means to the fraction ofreal images in set B are present from the beginning of training. The three similarity measures in thesecond row are cosine similarity, L2 (Euclidean) distance, and squared L2 distance.
Figure 11: Retrieval results over the course of training, comparison. We compare retrieval on thetest set of MNIST at various stages of training ACC and the two VAE-based approaches mentionedin the main text. As in Figure 4, the query images are the boxed images along the diagonal, and eachrow is the nearest representative for each class in embedding space. Also as before, in all cases thedigit 9 was withheld during training.
