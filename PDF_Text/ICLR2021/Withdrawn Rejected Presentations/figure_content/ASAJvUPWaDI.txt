Figure 1: Top: Histogram of classifiers' predictions on both subpopulations, demonstrating a cleargender bias in all cases. Bottom: The bias defined as the absolute difference in mean outcomebetween genders within different demographic groups, before and after applying the proposed al-gorithm. Blue bars show the results of the unmodified classifier, orange bars show the results ofoptimizing for statistical parity with no regard for demographic information. Finally, green bars arethe results of applying statistical parity on the cross product of gender and ethnicity.
Figure 2:	(a) The learned post-processing decision rule h(x) in Equation 1 as a function of theclassifier’s score f (x). Randomization is applied when h(x) ∈ (0, 1), which can be controlledusing the regularization parameter γ > 0. (b) The value of λ0 - u0 is plotted against the numberof epochs in the projected SGD method applied to the output of the random forests classifier trainedon the Adult dataset to implement statistical parity with respect to the gender attribute (cf. Section5 and Figure 1). We observe fast convergence in agreement with Proposition 1.
Figure 3:	The tradeoff curves are displayed for each classification problem. The x-axis correspondsto bias (Definition 1) while the y-axis is the test accuracy. In general, debiasing CDDD improves testaccuracy because bias was introduced to the training data only. In addition, ROC fails at debiasingfour classifiers (see also Tables 1 and 2) due to the absence of randomization.
Figure 4: The distribution of the scores produced by ResNet50 trained from scratch are shown forboth subpopulations. The curves correspond to the randomized post-processing rules, i.e. p(y =1|x), of Hardt et al. (2016) and the proposed algorithm with γ = 0.1 and ρ = E[y].
