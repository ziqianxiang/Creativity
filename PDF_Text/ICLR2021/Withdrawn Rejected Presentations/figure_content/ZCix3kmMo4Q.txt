Figure 1: Comparison of ground-truth-assignment-based training (left) and density-estimation-basedtraining (right). Density-estimation-based method trains the detector through a probability densityfunction, without ground-truth-assignment.
Figure 2: The architecture of MDOD. The parameters of the mixture model (μ, γ, p, and ∏) arepredicted by MDOD. The network produces its intermediate output (o1 - o4) from each feature-mapof the feature-pyramid.
Figure 4: The pdfs of Gaussian and Cauchy distribu-tion. Because of the limited precision of the floatingpoint, for Gaussian, p(x) = 0 for |x| > 7.202, i.e.
Figure 5: The ratio of foreground samples in theset {broi} which is sampled from the mixture ofCauchy distribution at each training epoch.
Figure 6: The ratios of underflowed componentsfor Cauchy and Gaussian distributions at eachtraining epoch.
Figure 7: Comparison of speed and AP on MS COCO ‘test-dev’ dataset. Horizontal axis is thedetection speed (FPS). Vertical axis of the top is AP50 and the bottom is AP . The red and bluecircles denote 320x320 and 512x512 input sizes, respectively.
