Figure 1: Comparison of SPARTA (Lerer et al., 2020) and LBS (ours). SPARTA maintains an explicit beliefdistribution with an accompanying AOH h2priv for each belief state. LBS uses an auto-regressive belief modelto sample states from the belief distribution, given the AOH. AOHs do not need to be maintained for eachbelief state in LBS since the model only relies on the public trajectory. Additionally, LBS uses an N-steprollout followed by a bootstrap value estimate.
Figure 2: (A): Illustration of the public-LSTM network used for the BP policy. (B): The auto-regressivenetwork for modeling beliefs .
Figure 3: Comparison of speed and average score of different policies in 5-card (left) and 6-card (right)Hanabi. The number next to each LBS data point is the rollout depth. LBS with different rollout depths providea tunable tradeoff between speed and performance. LBS provides most of the performance benefits of exactsearch (SPARTA) at a fraction of the compute cost, and the speedup grows with the size of the belief space(5-card vs 6-card).
Figure 5: (a) Result of fixed budget (24 Hours) at training time. The ticks “a|b”on x-axis means ahours to train BP and b hours to train belief model. (b) Result of fixed budget at test time. The ticks“a|b” on x-axis means run search for a steps before bootstrapping with Q function and run b searchper move. Each data point on both figures is evaluated on 5000 games and the shaded area is thestandard error of mean.
