Figure 1: (a) Since DB loss LDB consider about the centroid of cluster only, this leads the problem ofoverlapping between different clusters. (b) We compute Maximum Margin loss LMM by maximizingthese k pairs single link.
Figure 2: Computing flow for our losses in MCMC. We compute cross-entropy by the output oftemporary predictions and the ground truth of labeled data, LLDB by the embedding latent space andthe ground truth of labeled data, LTDB and LMM by the embedding latent space and the output oftemporary predictions. Finally, we sum up our total loss for MCMC.
Figure 3: Main figures show the initial labeled samples and the transformation process of the decisionboundary for MCMC. The dashed box shows the failure case of supervised learning with labeledsamples. (a) Two Half-moon experiment. (b) Triple Circle experiment.
Figure 4: (a) Test accuracy with different amounts of labeled data on MNIST. Figure shows theresult of supervised learning (SL) and our proposed model ’MCMC’. (b) The transitions of accuracyduring different methods on MNIST with 100 labeled data. We tested with four methods, supervisedlearning (SL), MCMC, MCMC without DB loss for labeled data, and MCMC without MaximumMargin loss. The red box shows the differs in the early iterations between different methods.
