Figure 1: A flow chart of our conditional sampler. First the noise variable is sampled from N (0, Id). Thisis fed into our pre-generator f to output structured noise z, which is driving the pre-trained base model f togenerate conditional samples x. The central idea is that the pre-generator must produce structured noise z thatlooks Gaussian (so that the samples are realistic) but also make the pre-trained base model f produce samplesthat satisfy the conditioning. The final conditional sampler is thus defined by the composition of two flowmodels.
Figure 2: Graphical models depicting different ways we perform variational inference. Solid arrowsrepresent the generative direction, and dotted arrows indicate the variational direction.
Figure 3: Conditional samples generated by our method from observing the upper half of CelebA-HQfaces. We see that our approach is able to produce diverse completions with different jaw lines, mouthshapes, and facial expression.
Figure 4: Samples from class-conditional models extracted from the unconditional base model (left)and various failure modes of Ambient VI (right).
Figure 5: Results on various inverse problem tasks using our method.
Figure 6: Contour plot of log pf (x)around a random point in image space.
Figure 7: Plot of the scalar function used to construct an additive coupling layer that can generatesamples of satisfying 3-SAT assignments.
Figure 8: Effect of the smoothing parameter on sample quality and tightness of approximate condi-tioning.
Figure 9: Unconditional samples from the base models used for our experiments. From left: MNIST,5-bit CIFAR-10, and 5-bit CelebA-HQ models.
