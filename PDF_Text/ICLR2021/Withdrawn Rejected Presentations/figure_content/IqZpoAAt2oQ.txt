Figure 1: FCRL for self-supervised scene representation learning: The representations are learnedby mapping the context points of each scene closer in the latent space while separating it from theother scenes. The context points correspond to the tuples of camera viewpoints xi ∈ X := Rd andthe images taken from those viewpoints yi ∈ Y ⊆ Rd0. Seen here, TriFinger (WuthriCh et al., 2020).
Figure 2: (a) Qualitative comparison of different methods on 5-shot regression task on three differentsinusoid waves. The decoder trained on FCRL’s representation is able to predict the correct form ofthe waves. (b) shows how we adapt the representation for the downstream few-shot regression task.
Figure 3: (a) Qualitative comparison of CNP and FCRL based few-shot image completion. Thecontext is shown in the second row where target pixels are colored blue. FCRL appears to be slightlybetter at predicting the correct form of a digit in low-shot scenario of 50 context points only. (b)Quantitative evaluation of the models in terms of digit classification from the fixed number of contextpoints (varying along the x-axis). FCRL achieves substantially higher accuracy.
Figure 4: Quantitative Comparison of FCRL and GQN on MPI3D downstream classification tasks.
Figure 5: (a) Comparison between GQN and FCRL on learning a data-efficient control policyfor an object reaching downstream task. FCRL based representations clearly outperform GQN’srepresentations. (b) Quantitative comparison for noise robustness on MNIST content classificationdownstream task. The representations learned with FCRL are much more robust to noise than GQN’s.
Figure 6: Ablation for observations (J), critics and temperature for learning FCRL on MNISTvalidation dataset.
Figure 7: Ablation for critics on MPI3D validation dataset.
Figure 8: MPI3D dataset with the varying level of additive noise.
Figure 9: Quantitative comparison for noise robustness on MPI3D downstream tasks.
Figure 10: Datasets for Scenes Representation Learning (a) MPI3D (Gondal et al., 2019) has threecamera viewpoints, with images of a robotics arm manipulating an object. (b) RLScenes has 36possible camera viewpoints for capturing an arena consisting of a robot finger and an object.
Figure 11: Network Architecture used for learning representations for the scenes’ datasets.
Figure 12: 2D-TSNE projections of 128 dimensional representations learned by FCRL on the MPI3Ddataset. Each individual plot exhibits the latent structure corresponding to the factor mentioned above.
Figure 13: Additional results on 5-shot sinusoid regression. Each column corresponds to a differentsinusoid function where only 5 context points are given. The predictions of the decoder trained onFCRL based encoder are closer to the groundtruth.
Figure 14: Additional results on 20-shot sinusoid regression. Each column corresponds to a differentsinusoid function where only 20 context points are given. The predictions of the decoder trained onFCRL based encoder are comparable to CNP and better than NP.
Figure 15: Additional results on 50-shot mnist image completion. The context is shown in the secondrow where target pixels are colored blue. Predictions made by a decoder trained on FCRL basedencoder are slightly better than the CNP in terms of guessing the correct form of digits.
