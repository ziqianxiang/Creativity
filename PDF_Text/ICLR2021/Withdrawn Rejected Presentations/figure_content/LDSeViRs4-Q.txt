Figure 1: An example of clean and Figure 2: Left: case-0 in BPGD; Right: case-1 in BPGD.
Figure 3: Binary search Figure 4:in BPGD.	gin.
Figure 5: Left: Equilibrium State; Right:Three-class Scenario.
Figure 6: Results on Moons dataset.
Figure 7: Results on Fashion-MNIST (L-inf and L2 norm in100-PGD).
Figure 9: Results on COVID-19 CT: accuracies (left),Figure 8: Results on SVHN (L-inf IMA margin estimations (middle), and MMA margin es-and L2 norm in 100-PGD).	timations(right). MMA significantly overestimated themargins.
Figure 8: Results on SVHN (L-inf IMA margin estimations (middle), and MMA margin es-and L2 norm in 100-PGD).	timations(right). MMA significantly overestimated themargins.
Figure 10: Each row shows a clean image and noisy images associated with a training method. Thetitle of each image shows the predicted class label and the noise level. The clean images are correctlyclassified.
Figure 11: The training and validation curves (accuracy vs epoch) on different datasets obtained byusing our IMA method. The accuracy scores are measured on clean data.
Figure 12: The training and validation curves (accuracy vs epoch) on the COVID-19 CT datasetobtained by using our IMA method. The accuracy scores are measured on clean data.
Figure 13: The performance of the methods on Figure 14: Margin distribution estimated byCOVID-19 test set	IMA on training set250sample margin distribution estimated by ima3s 6ullD aUnoUdEes0.00	0.05	0.100.15	0.20	0.25	0.30	0.35	0.40noise level (Linf)G AppendixG.1 The basic idea of our IMA methodIf there are only two classes and the data samples are linearly-separable, then linear SVM (supportvector machine) will produce a linear decision boundary in the “middle” between the two classes.
Figure 15: Training and validation accuracy curves (accuracy vs epoch) on the datasets, usingstandard training with cross-entropy loss and clean data. The accuracy scores are measured on cleandata.
