Figure 1: Overview of the counterfactual generative model.
Figure 3: Post-Processing ResultFigure 2: Different Unfair Ratio5.3	AnalysisCounterfactual Examples. We include a qualitative evaluation of our counterfactual generatorin Fig.4. These visualizations demonstrate the difference of original images and the counterfactualimages by manipulating the binary attributes. We choose the male, young and blonde hair as thesensitive attributes to show the effects of manipulating a specific property. One can observe thatthe target attribute 'Arched-Eyebrows' in our recognition task is not visually altered between theoriginal example and the counterfactual one. Powered by a generative backbone, our counterfactualexamples are of high quality.
Figure 2: Different Unfair Ratio5.3	AnalysisCounterfactual Examples. We include a qualitative evaluation of our counterfactual generatorin Fig.4. These visualizations demonstrate the difference of original images and the counterfactualimages by manipulating the binary attributes. We choose the male, young and blonde hair as thesensitive attributes to show the effects of manipulating a specific property. One can observe thatthe target attribute 'Arched-Eyebrows' in our recognition task is not visually altered between theoriginal example and the counterfactual one. Powered by a generative backbone, our counterfactualexamples are of high quality.
Figure 4: Examples of the CoUnterfactUal images on CelebA from the male, young and blonde_hairattribute. These result are obtained by our counterfactual generator.
Figure 5: Training dynamic10	20	40	60	80Number of IterationFigure 6: Teacher action6 ConclusionsIn this paper, we propose the Generative Fairness Teaching (GFT) framework to achieve algorithmicfairness for machine learning models. Our method can generate high quality counterfactual exam-ples, which is a novel approach to compensate the biases in a dataset. Together with a student -teacher architecture, we dynamically adjust the proportion of counterfactual examples and mix itwith the original ones in order to train a fair model. Experimental results indicated that our methodstrongly out-perform baseline methods in both tabular and real image datasets.
Figure 6: Teacher action6 ConclusionsIn this paper, we propose the Generative Fairness Teaching (GFT) framework to achieve algorithmicfairness for machine learning models. Our method can generate high quality counterfactual exam-ples, which is a novel approach to compensate the biases in a dataset. Together with a student -teacher architecture, we dynamically adjust the proportion of counterfactual examples and mix itwith the original ones in order to train a fair model. Experimental results indicated that our methodstrongly out-perform baseline methods in both tabular and real image datasets.
