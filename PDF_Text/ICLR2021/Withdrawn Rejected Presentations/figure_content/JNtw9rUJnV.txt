Figure 1: Zero-shot AutoML architecture: Dataset descriptions are embedded using a languagemodel. The data itself is passed through a feature extractor. Other AutoML system algorithms areembedded using a language model. Fully connected neural networks fuse together the encoded fea-ture vectors. A graph captures the relationships between the embedded representations. At trainingtime a GNN learns the aggregation of each node in the graph and its neighbors. The GNN predicts apipeline for a new node (dataset). At test time a dataset is added as a new node in the graph and theGNN predicts the best machine learning pipeline without running any AutoML system or evaluatingany pipeline. Inputs are colored green, neural networks in blue, intermediate outputs in red, andpredicted output in yellow.
Figure 2: Illustration of zero-shot AutoML dataset graph construction and prediction.
Figure 3: Comparison of accuracy on test set between our zero-shot approach given 3 seconds ofcomputation and other AutoML systems and Random Forest baseline given 1 minute of computa-tion. Our zero-shot approach matches the performance of baselines while running 20 times faster.
