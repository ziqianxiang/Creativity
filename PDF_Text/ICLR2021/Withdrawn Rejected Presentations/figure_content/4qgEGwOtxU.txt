Figure 1: Sub-cluster visualizations for small MLPs: (a) MNIST, (b) Fashion-MNIST, (c) halves-same MNIST, (d) halves-diff MNIST. In each image, the top row gives visualizations of true sub-clusters and the bottom four for random ones of the same size. Columns are ordered left to rightaccording to layer order. Pixel values are scaled from black to white for each column independently.
Figure 2: Plot of different sub-clusters of two networks. Important sub-clusters are labeled firstby their layer number and then their cluster number. The horizontal axis shows the proportionof their layer’s neurons in the sub-cluster, and the vertical axis shows the reduction in accuracyfrom lesioning it. ‘Important’ means that the sub-cluster makes up at least 5% of the layer, thatthe drop in accuracy is greater than one percentage point, and that it was more important than allof 20 random sub-clusters it was compared against—that is to say, statistically significant. ‘Sig-but-not-diff’ means that the drop in accuracy is statistically significant but less than 1 percentagepoint, ‘Diff-but-not-sig’ means that the lesioning damage was more than 1 percentage point but notstatistically significant, ‘Prunable’ means that the drop in the accuracy is smaller than all randomshuffles and smaller than 1 percentage point, ‘Complete’ means that the sub-cluster contains thewhole layer, ‘Small’ means that the sub-cluster consists of less than 5% of the layer, and ‘Other’means that the drop in accuracy is not statistically significant and less than 1 percentage point. Bothof the networks are partitioned into 8 clusters. The data is based on two tables which are includedin appendix A.9. Note that the ‘Complete‘ category appears only in the right plot, and only a singlepoint is shown although there are 8 such sub-clusters. Refer to appendix A.9 for additional details.)Coherence To measure the output coherence using lesions, we analyze the accuracy changes foreach of the output classes. For ten classes, we define d = (d0, d1 , . . . , d9), where di is the changein the i-th class accuracy due to the lesioning of a sub-cluster. In order to obtain a measurementindependent of the overall importance, we divide these class-wise accuracy changes by their mean,d0 = d/d, and the then take their range ∆ = max d0 - mind0. We refer to this as the (normalized)
Figure 3:	Examples images from halves/stack datasets: (Left) Samples from ‘halves’ datasets, and(Right) samples from ‘stack’ datasets, all of class 3. Each row has 10 images from the respectivedataset. The first row is MNIST halves/stack-same, second is MNIST halves/stack-diff, third isFashion halves/stack-same, and fourth is Fashion halves/stack-diff.
Figure 4:	Sub-cluster visualizations for small CNNs trained on stack-same/diff MNIST: (Left)stack-same MNIST, (Right) stack-diff MNIST. The top rows give visualizations for true sub-clustersand the bottom four for random ones. Columns are ordered left to right according to layer order.
Figure 5: Example feature visualizations for true and random sub-clusters: In the left columnare shown true sub-cluster visualizations, and in the right column are visualizations of sub-clustersof random neurons of the same size in the same layer. (a) MLP, MNIST; (b) CNN, MNIST; (c)CNN-VGG, CIFAR-10; (d) VGG-16, ImageNet; (e) VGG-19, ImageNet; (f) ResNet-50, ImageNet.
Figure 6: Example accuracy change profiles for lesion tests: (Top) Fashion-MNIST MLP and(Bottom) Fashion-MNIST Small CNN. Each subplot corresponds to a sub-cluster in the network.
Figure 7: Four cases of dependency between sub-clusters. These cases characterize how informa-tion can flow from a sub-cluster X to a sub-cluster Y , where X is in an earlier layer than Y . U andV are two other sub-clusters, which reside in the same layer as X and Y respectively. All of thesesub-clusters are individually “important”. Given the importance configuration of (X|Y, Y |X), weconjecture what is the relationship in terms of information flow between the sub-clusters.
Figure 8: A plot of the edges of the sub-cluster dependency graph for an MLP trained onFashion-MNIST and partitioned with 8 clusters. We derive this from data shown in figure 9.
Figure 9: Dependency information for all pairs of sub-clusters for an MLP trained on Fashion-MNIST and partitioned with 8 clusters. Best viewed in color and zoomed in on a screen. Sub-clusters are numbered by their layer and cluster. They are also labeled by their importance: IMPstands for “important”, SMA stands for “small”, SIG stands for “sig-but-not-diff”, DIFF stands for“diff-but-not-sig”, PRU stans for “prunable” and OTH stands for “other”, terms which are definedat the beginning of Appendix A.9. Cells on the diagonal are labeled by the accuracy damage inpercents caused by zeroing out the corresponding sub-cluster in the single lesion experiments, andhave bolded text, while cells off the diagonal are labeled by 100×δ(first, second). Cells contain starsif the damage caused by lesioning the first is statistically significant at the p < 0.05 level conditionalon the second being lesioned, and question marks if the damage caused by lesioning the first was lessthan the damage caused by lesioning each of 50 random sets of neurons (i.e., p = 1.00), conditionalon the second being lesioned. Note that this plot includes sub-clusters in the same layer, where themeaning is questionable since there can be no direct dependency.
