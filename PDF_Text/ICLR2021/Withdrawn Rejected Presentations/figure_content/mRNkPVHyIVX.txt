Figure 1: Overview of our proposed framework. The left side shows the web users retrieving wrongresults due to the adversarial example. The right side adopts a safe spot filter on the image uploadingprocess and succeeds in defending the query system from the attacker.
Figure 2: Illustration of the safespot search process. The shadedregion represents the set of pointsthat are misclassified.
Figure 3: Histograms for the loss values of images '(χ0, C(Xo)) (left) and the loss values of theperturbed safe spot solution supχ* 三6式，*)'(χa,c(χo)) (right). A safe spot-aware adversariallytrained model without fine-tuning is used as the classifier. The dotted lines are where the false positiverate is 95%. Detailed settings in Supplementary C.3.
