Figure 1: Different losses produce different predictions. a: Percentages of ImageNet validation set examplesfor which models assign the same top-1 predictions, for 8 seeds of ResNet-50 models. b: Dendrogram based onsimilarity of predictions. All models naturally cluster according to loss, except for “Dropout” and “More FinalLayer L2” models. See also Figure D.1.
Figure 2: Loss functions affect sparsity of later layer representations. Plot shows the average % non-zeroactivations for each ResNet-50 block, after the residual connection and subsequent nonlinearity, on the ImageNetvalidation set. Dashed lines indicate boundaries between stages.
Figure 3: The loss function has little impact on representations in early network layers. All plots showlinear centered kernel alignment (CKA) between representations computed on the ImageNet validation set. a:CKA between network layers, for pairs of networks trained from different initializations. b: CKA between rep-resentations extracted from architecturally corresponding layers of networks trained with different loss functions.
Figure 4: Class separation in different layers ofResNet-50 models,on the ImageNet training set.
Figure 5: Transfer accuracy and accuracyof relearned ImageNet weights are nega-tively related. a: Average transfer task ac-curacy versus accuracy of a classifier trainedon 50,046 ImageNet training set examplesand tested on the validation set for differentobjectives. b: Relationship of transfer accu-racy and relearned ImageNet accuracy withcosine softmax temperature.
