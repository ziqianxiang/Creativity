Figure 1: An illustration of DO-GAN. Figure adapted from (Lanctot et al., 2017).
Figure 2: Comparison of GAN and DO-GAN on 2D synthetiC dataset5.1	Evaluation on Synthetic 2D Gaussian Mixture DatasetTo illustrate the effeCtiveness of the arChiteCture, We train a double oraCle frameWork With the simplevanilla GAN arChiteCture on a 2D mixture of 8 Gaussian mixture Components With Cluster standard1https://nashpy.readthedocs.io/en/stable/index.html6Under review as a conference paper at ICLR 2021deviation 0.1 which follows the experiment by (Metz et al., 2017). Figure 2 shows the evolutionof 512 samples generated by GAN and DO-GAN through 20000 epochs. The goal of GAN andDO-GAN is to correctly generate samples at 8 modes as shown in the target. The results showthat GAN can only identify 6 out of 8 modes of the synthetic Gaussian data distribution, while theDO-GAN can obtain all the 8 modes of the distribution. Furthermore, DO-GAN takes shorter time(less than 5000 epochs) to identify all 8 modes of the data distribution. We present a more detailedevolution of data samples through the training process on 2D Gaussian Mixtures in Appendix C.
Figure 3: Training images with fixed noise for DCGAN and DO-DCGAN until termination.
Figure 4: Training images with fixed noise for SNGAN and DO-SNGAN until termination.
Figure 5: Training images with fixed noise for SGAN and DO-SGAN until termination.
Figure 6: Full comparison of GAN and DO-GAN on 2D Synthetic Gaussian Dataset(b) DO-GANFigure 7: GAN and DO-GAN comparison with Gaussian Mixture 7 modesFigure 6 shows the full training process of DO-GAN and GAN on 2D Synthetic Gaussian Dataset.
Figure 7: GAN and DO-GAN comparison with Gaussian Mixture 7 modesFigure 6 shows the full training process of DO-GAN and GAN on 2D Synthetic Gaussian Dataset.
Figure 8: GAN and DO-GAN comparison with Gaussian Mixture 9 modesD Investigation of Support Set SizeWe vary the support set size s to 5, 10, 15 and record the training evolution and the running time aspresented in Table 4 and Figure 9. We find that if the support size is too small, e.g., s = 5, the bestresponses which are not optimal yet have better utilities than the models in the support set are addedand pruned from the meta-matrix repeatedly making the training not able to converge. However,s = 15 takes a significantly longer time as the time for the augmenting of meta-matrix becomesexponentially long with the support set size. Hence, we chose s = 10 as our experiment support setsize since we observed that there is no significant trade-off and shorter runtime.
Figure 9: Training evolution on 2D Gaussian Dataset with s = 5, 10, 15Epoch 2000014Under review as a conference paper at ICLR 2021E Generated images of CelebA and CIFAR- 1 0In this section, we present the training images of CelebA and CIFAR-10 datasets.
Figure 10: Training images with fixed noise for DCGAN and DO-DCGAN until termination.
Figure 11: Training images with fixed noise for SNGAN and DO-SNGAN until termination.
Figure 12: Generated images of CIFAR-10 dataset(a) SNGAN(b) DO-SNGANFigure 13: Generated images of CelebA dataset for DO-SNGAN and SNGAN16Under review as a conference paper at ICLR 2021Figure 13: Generated images of CelebA dataset for DO-SGAN and SGANF FID score against iterationsTo compute FID score, we use Inception_v3 model with max pool of 192 dimensions and the lastlayer as coding layer as mentioned in (Heusel et al., 2017). We resized MNIST, CIFAR-10 generatedand test images to 32 × 32 and CelebA images to 64 × 64. The FID score against training epochs forCIFAR-10 dataset is as follows:250 1.
Figure 13: Generated images of CelebA dataset for DO-SNGAN and SNGAN16Under review as a conference paper at ICLR 2021Figure 13: Generated images of CelebA dataset for DO-SGAN and SGANF FID score against iterationsTo compute FID score, we use Inception_v3 model with max pool of 192 dimensions and the lastlayer as coding layer as mentioned in (Heusel et al., 2017). We resized MNIST, CIFAR-10 generatedand test images to 32 × 32 and CelebA images to 64 × 64. The FID score against training epochs forCIFAR-10 dataset is as follows:250 1.
Figure 13: Generated images of CelebA dataset for DO-SGAN and SGANF FID score against iterationsTo compute FID score, we use Inception_v3 model with max pool of 192 dimensions and the lastlayer as coding layer as mentioned in (Heusel et al., 2017). We resized MNIST, CIFAR-10 generatedand test images to 32 × 32 and CelebA images to 64 × 64. The FID score against training epochs forCIFAR-10 dataset is as follows:250 1.
Figure 14:	FID score vs. Epochs for SGAN and DO-SGAN trained on CIFAR-10Figure 14 presents the FID score against each epoch of training for SGAN and DO-SGAN on CIFAR-10. While both perform relatively well in generating plausible images, we can see that DO-SGANterminates early at epoch 288 and has a better FID score of 16.56 compared to 24.83 at 300 epochuntil 21.284 at 500 epoch for the training of SGAN.
Figure 15:	Taxonomy of GAN Architectures from (Wang et al., 2019)We carried out experiments with the variants of GANs to evaluate the performance of our DO-GANframework. We refer to the taxonomy of GANs (Wang et al., 2019) and choose each architecture fromthe groups of GANs focused on Network Architecture, Latent Space and Loss: DCGAN, SNGANand SGAN as shown in Figure 15. We have also included comparisons with mixture architecturessuch as MIXGAN and MGAN.
