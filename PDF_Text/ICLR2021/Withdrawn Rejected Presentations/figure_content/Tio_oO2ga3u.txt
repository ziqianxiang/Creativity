Figure 1: Training various neural architectures considered in this work. Deep ensembles (a) useidentical prediction networks with independent initialization and training. Deep kernel learning (b)uses a neural feature extraction network with an expressive kernel such as an RBF. Our model, deepensemble kernel learning (c) uses an ensemble of feature networks trained jointly through a linearkernel that enables exact inference via minimization of variational free energy for regression.
Figure 2: Synthetic cubic dataset. The first column shows a single DE learner and a DE modelof five learners. The second and third columns show one DEKL learner and a DEKL model offive learners, both with and without optimal prior covariance. The fourth column shows a DKLmodel of the same width as the five-learner DEKL, both with and without optimal prior covariance.
Figure 3: Correlation matrices of learners averaged over all train-test splits on the Kin8nm datasetusing deep ensembles (DE) and deep ensemble kernel learning (DEKL). Suffices -I and -O indicateusing KLI (Eq. 11) and KLO (Eq. 10), respectively.
Figure 4: Mean test RMSE (across all train-test splits) of the DE (red, solid), DEKL-I (green,dotted), and DEKL-O (blue, dashed) models on nine UCI datasets as a function of the number oflearners.
Figure 5: Mean test NLL (across all train-test splits) of the DE (red, solid), DEKL-I (green, dotted),and DEKL-O (blue, dashed) models on nine UCI datasets as a function of the number of learners.
Figure 6: Correlation matrices of learners averaged over all train-test splits on the Boston hous-ing, Concrete, and Energy datasets using deep ensembles (DE) and deep ensemble kernel learning(DEKL). Suffices -I and -O indicate using KLI (Eq. 11) and KLO (Eq. 10), respectively.
Figure 7: Correlation matrices of learners averaged over all train-test splits on the Kin8nm, Navalpropulsion, and Power plant datasets using deep ensembles (DE) and deep ensemble kernel learning(DEKL). Suffices -I and -O indicate using KLI (Eq. 11) and KLO (Eq. 10), respectively.
Figure 8: Correlation matrices of learners averaged over all train-test splits on the Protein, Wine,and Yacht datasets using deep ensembles (DE) and deep ensemble kernel learning (DEKL). Suffices-I and -O indicate using KLI (Eq. 11) and KLO (Eq. 10), respectively.
