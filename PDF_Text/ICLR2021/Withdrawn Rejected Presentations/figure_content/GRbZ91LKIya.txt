Figure 1: Where a Masked Language Model (left) leads to learning lexical correlations (red) and in-troduces a domain shift by with the train-only ‘[MASK]’ token, ToCo (right) forces the cross-modalfusion to focus on identifying which semantics bearing word differentiates between video sequences.
Figure 2: ToCo includes token level losses on semantic bearing Words in addition to a global loss(left). The right shoWs additional details of hoW representations are shared for a specific token.
Figure 3: Qualitative examples of our baseline implementation’s rankings of two queries, versusfull token-level losses applied (right). Note the down-weighting of videos that are not stirring andup-weighting the presence of a car racing.
Figure 4: Ave. Re- Figure 5: Ave. re-call@{1,5,10} for different call@{1,5,10} with λ=0features. ToCo-base-masked vs two variants of weighting:uses MLM.	noun/verb/adj vs det/adp/aux.
