Figure 1: Left: A vertical pole casting a shadow. Yellow blocks-top row: Cross-dissolve phenomenaas a result of linear interpolation in the input space. Yellow blocks-bottom row: Image reconstructionobtained by a linear latent space interpolation of an autoencoder. Unrealistic artifacts are introduced.
Figure 2: The latent manifold of the data embedded in 2D latent space (leftmost plot) and 3D latentspace (second plot from the left) learned by vanilla autoencoders. Gridlines represent the (θ, φ)parameterization. The second image from the right was generated from the latent point denoted ‘A’.
Figure 3: Data interpolation using autoencoders. Two points xi , xj are located on the input datamanifold (solid black line). The encoder f (x) maps input points into the latent space zi, zj(red arrows). Linear interpolation in the latent space is represented by the blue dashed line. Theinterpolated latent codes are mapped back into the input space by the decoder g(z) (blue arrows).
Figure 4: Our proposed architecture. Dotted lines represent the loss functions. h is a non-learnedlayer that performs latent linear interpolation.
Figure 5: Each of the six rows presents linear interpolation of images from COIL-100 and oursynthetic dataset for each of the methods tested.
Figure 6: We use the parameterization of the dataset to evaluate the reconstruction accuracy of theAAE, ACAI, β-VAE, AMR, GAIA and our proposed method. Left graph: Averaged MSE vs. αvalues. Middle graph: STD of MSE vs. α values. Right: Averaged MSE of the interpolated imagesvs. the interval length.
Figure 7: Predicting the interpolated alpha value based on the L2 distance of the interpolated imageto the closest image in the dataset. The dots represent the median and the colored area corresponds tothe interquartile range.
Figure 8: We sampled two images xi , xj and linearly interpolated between them in latent space.
Figure 9: Each of the six blocks shows a bilinear interpolation of four ground truth images that residein each corner of the block.
Figure 10: Each of the six blocks shows a bilinear interpolation of four ground truth images thatreside in each corner of the block.
Figure 11: Each of the six blocks shows a bilinear interpolation of four ground truth images thatreside in each corner of the block.
Figure 12: Each of the four blocks presents bilinear interpolation of four ground truth images thatreside in each corner of the block. Top left: Bilinear interpolation results of our approach with all losscomponents. Top right: Removing the cycle-consistency contribution from the loss function. Bottomleft: Removing the discriminator contribution. Bottom right: Removing the smoothing contribution.
Figure 13: Each of the four blocks presents bilinear interpolation of four ground truth images thatreside in each corner of the block. Top left: Bilinear interpolation results of our approach with all losscomponents. Top right: Removing the cycle-consistency contribution from the loss function. Bottomleft: Removing the discriminator contribution. Bottom right: Removing the smoothing contribution.
Figure 14: Top graph: Average reconstruction error and standard deviation vs. α values. Bottom:Average MSE of the interpolated images vs. the interval length.
Figure 15: Predicting the interpolated alpha value based on the L2 distance of the interpolated imageto the closest image in the dataset. The dots represent the median and the colored area corresponds tothe interquartile range.
