Figure 1: The proposed action-boundary co-estimation mechanism. Our transformer-driven scorersmodule estimates four boundary estimations of forward-actioness, backward-actioness, forward-background, and backward-background. The backward-actioness and forward-background co-estimate the action starting, and the forward-actioness and backward-background co-estimate theaction ending. The transformer-style units enable these temporal estimations to collect the temporalcontextual supports over each inputted representation. The right-most figures show the estimations ofaction starting and action ending without (top) and with (bottom) the TS co-estimation. The proposedaction-boundary co-estimation within our TS module is able to reduce more false-positive predictions.
Figure 2: The architecture of our FITS temporal action proposal generation model. Our model iscomposed of a Feature Integration module, in charge of integrating the two-stream representations,and a Transformer-driven Scorers module, in charge of extracting the temporal contextual supportswithin representation and then associating these representations to co-estimate the action boundaries.
Figure 3: Effect visualization of our model on video id “pIk9qMEyEd4.” The top row shows thesampled frames of the video. The left two figures in the bottom image set, which depict the absolutedifferences (y-axis) between motion cue and appearance cue over feature channels (x-axis), show ourco-attention and mutual-excitation mechanism can reduce the two-stream feature discrepancies. Theright four figures in the bottom image set, which plot the predicted boundary probabilities (y-axis) Psand Pe over the snippet dimension (x-axis), show our TS module’s effect. In this four-image set, thetop row shows the original results, and the bottom row shows the results using our modules.
