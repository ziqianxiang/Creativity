Figure 1: A) Correlated neurons. Only end task semantics are taken into account. B) Uncorrelatedneurons. More objects are distinguishableIn the following paragraphs, we identify the main causes of the correlation of neurons and suggestways to prevent it. We decided to consider the correlations before and after activation of neuronsseparately.
Figure 2: t-SNE last hidden layer (test set)Table 1: Experimental results (MNIST dataset)Model (object rep.)	Model accuracy (even/odd)	kNN digit accuracy	V measure	Vec. time (s)	kNN prediction time (s)	Space dimensionA (口 fθ)	-	96.8	0.542	677.04	188.79	14911A (hL-1)	97.3±0.2	52.9±3.7	0.322±0.003	1.93±0.07	25.23±0.97	275B (hL-1)	98.6±0.2	93.1±0.4	0.588±0.016	1.95±0.10	21.46±0.97	30C (hL-1)	98.9±0.1	97.7±0.3	0.812±0.029	1.83±0.08	21.04±0.73	30h0 = x	-	94.29	0.4	-	21.48	784Figure 3: Distribution of correlations between pairs of neurons of the last hidden layerTable 2: Spearman’s correlattion between median of correlation distribution of neurons and targetmetricsε (dim hL-1)	KNN digit accuracy	V-measure0.2 (275)	-0.28	-0.470.4 (68)	-0.86	0.130.6 (30)	-072	-0.820.8 (17)	-0.57	-0.811.0 (11)	-046	-0.83for the closest object. It should be noted that only our model (Model C) achieves comparable qualitywith the previous approach. Moreover we could improve evaluation of similarity in comparison tosource representation.
Figure 3: Distribution of correlations between pairs of neurons of the last hidden layerTable 2: Spearman’s correlattion between median of correlation distribution of neurons and targetmetricsε (dim hL-1)	KNN digit accuracy	V-measure0.2 (275)	-0.28	-0.470.4 (68)	-0.86	0.130.6 (30)	-072	-0.820.8 (17)	-0.57	-0.811.0 (11)	-046	-0.83for the closest object. It should be noted that only our model (Model C) achieves comparable qualitywith the previous approach. Moreover we could improve evaluation of similarity in comparison tosource representation.
Figure 4:	t-SNE last hidden layer (test set)Table 3: Experimental results (Henan Renmin Hospital Data)Model (object rep.)	Model acc. (sick/ healthy)	kNN disease F1micro	V measure	Vec. time (s)	kNN pred. time (s)	Space dimA " fθ )	-	79.1	0.316	169.2	980.8	29111A (hL-1)	88.25±0.06	75.0±2.7	0.371±0.004	0.16±0.01	62.22±1.27	31B (hL-1)	86.7±0.1	79.6±0.2	0.411±0.015	0.28±0.02	93.26±2.59	31C (hL-1)	87.4±0.2	79.6±0.2	0.398±0.008	0.26±0.02	75.87±1.45	31h0 = x	-	61.1	0.066	-	45.91	62MOdel A-1-00	-OR	-O-W -O-B 0-00 ΠR O-W OR 1-00Model CFigure 5:	Distribution of correlations between pairs of neurons of the last hidden layerResults As illustrated in Table 3, we achieved results comparable (kNN disease F1micro score)with the previous approach. As in the previous experiments we obtained a much smaller dimension8Under review as a conference paper at ICLR 2021of the representation (31 vs 29k) and drastically reduced the time for vectorization and the timeto measure the similarity of objects (kNN prediction time). It should be noted that we noticeablyimproved the quality of similarity measurement in comparison to the source space (61.1 vs 79.6) ascan be seen also in Fig. 4. We also reduced correlation in comparison of the Model A and Model B,
Figure 5:	Distribution of correlations between pairs of neurons of the last hidden layerResults As illustrated in Table 3, we achieved results comparable (kNN disease F1micro score)with the previous approach. As in the previous experiments we obtained a much smaller dimension8Under review as a conference paper at ICLR 2021of the representation (31 vs 29k) and drastically reduced the time for vectorization and the timeto measure the similarity of objects (kNN prediction time). It should be noted that we noticeablyimproved the quality of similarity measurement in comparison to the source space (61.1 vs 79.6) ascan be seen also in Fig. 4. We also reduced correlation in comparison of the Model A and Model B,however it did not help us to obtain more quality representaions. This result can be explained by thefact that the hidden classes are strongly semantically related, in particular in ”Sick” class. Therefore,it is easier for the neural network to mix these hidden classes into one. Probably, the data have morecomplicated structure in source space (see Table 3 for h0) and it’s not enough to only reduce thecorrelation. See Table 4 for detailed results.
