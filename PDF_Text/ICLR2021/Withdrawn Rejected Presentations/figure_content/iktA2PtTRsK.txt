Figure 1: NCE vs VINCE. The standard contrastive setup learns to separate artificial augmentationsof the same image. Our method uses novel views and temporal consistency which single imagescannot provide.
Figure 2: Left: Standard NCE using “Same Frame” where all positive pairs come from the sameimage. Middle: NCE using “Multi-Frame” where positive pairs come from the same video. Right:Multi-Frame Multi-Pair NCE which uses more than one positive pair per video. The gray boxesindicate the true match pairs. The Memory Bank adds more negatives for each anchor.
Figure A1: Sample from Random Related Video Views (train set).
Figure A2: Random sampling of pairs of images from videos in each dataset. In GOT-10k,sometimes different video clips are segments from the same original video as seen in the first andsecond sample. Images are square cropped for visualization purposes only.
Figure A3: Nearest neighbor results for a sampling of query images from R2V2 and ImageNetusing various models. VINCE shows a clear understanding of each image and finds highly relevantneighbors.
Figure A4: t-SNE embedding of images from R2V2 test set.
Figure A5: Precision (a) and Success (b) plots for OTB 2015 for various backbones.
