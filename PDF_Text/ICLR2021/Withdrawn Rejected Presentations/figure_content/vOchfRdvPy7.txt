Figure 1: Clean and adversarial accuracy in each class of CIFAR10 dataset, from a naturally trainedResNet model (left), PGD-adversarially trained model (middle) and TRADES (right), against ad-versarial examples under l∞-norm by 8/255. The trained models’ robustness are evaluated by un-targeted PGD attack under l∞-norm constrained by 8/255 and 4/255.
Figure 2: Class-wise Clean & Adversarial Accu-racy on GTSRB of Naturally Trained Model (left)and Adversarially Trained Model (right).
Figure 3: Debiasing Manner for 3 FRL Options in CIFAR10.
Figure 4: Unfairness in GTSRBresult the clean performance has a heavier tail property. In this dataset, both natural model and ro-bust model have clear distinguished adversairal accuracy (robustness). However, adversarial trainingeven hardly provide any robustness improvement for some classes.
Figure 5: Debiasing training processProof 1 (Proof of Lemma 1) Wefirst prove wι = w2 = •一=Wm and Wm+ι = Wm+2 = •一=wm+b by contradiction. We define G1 = {1, 2, . . . , m} and G2 = {m + 1, m + 2, . . . , m + d}. Wemake the following assumption: for the optimal w and b, we assume there exist wi < wj for i 6= jand i, j ∈ G1 . Then we obtain the following clean error for two classes with this classifier wR(f, -1) = Pr{	X	wkNk	+ b + wiN(-γ,σ-2 1)	+ wjN (-γ, σ-2 1) >	0}	(18)k6=i,k6=jR(f, +1) = Pr{	X	wkNk	+ b + wiN(+γ,σ+2 1)	+ wjN (+γ, σ+2 1) <	0}	(19)k6=i,k6=jIf we use wj to replace wi, we obtain new errorsR(f,-1)= Pr{	X	WkNk	+ b +	WjN(-γ,σ-ι)+ WjN(-γ, σ-ι)	> 0}	(20)k6=i,k6=jR(f, +1) = Pr{	X	WkNk	+ b +	WjN(+γ,σ+ι) + WjN(+γ,σ+ι)	< 0}.	(21)k6=i,k6=jIt implies R(f,-1) + R(f, +1) < R(f,-1) + R(f, +1).
