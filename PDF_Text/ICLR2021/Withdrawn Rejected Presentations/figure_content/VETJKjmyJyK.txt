Figure 1: Accuracy in Recall@1 on the three standard benchmarks for metric learning. All embed-ding transfer methods adopt PA (Kim et al., 2020) with 512 dimension as the source model. Ourmethod achieves state of the art when embedding dimension is 512, and is as competitive as recentmetric learning models even with a substantially smaller embedding dimension. In all experiments,it is superior to other embedding transfer techniques. More results can be found in Table 1 and 2.
Figure 2: Gradient of the smooth contrastiveloss versus pairwise distance.
Figure 3: ToP 4 image retrievals of the state of the art (Kim et al., 2020) before and after the pro-posed method is applied. (a) CUB-2020-2011. (b) Cars-196. (c) SOP. Images with green boundaryare success cases and those with red boundary are false positives. More qualitative results can befound in Appendix A.3.
Figure 4: Image pairs sorted by the normalized weights of Eq. (4) on the CUB-200-2011 dataset.
Figure 5: An illustration for standard augmentation strategy and multi-view augmentation strategy.
Figure 6: ToP 5 image retrievals of the state of the art (Kim et al., 2020) before and after the proposedmethod is applied on the CUB-200-2011 dataset. Images with green boundary are success cases andthose with red boundary are false positives.
Figure 7: Top 5 image retrievals of the state of the art (Kim et al., 2020) before and after the proposedmethod is applied on the Cars-196 dataset. Images with green boundary are success cases and thosewith red boundary are false positives.
Figure 8: Top 5 image retrievals of the state of the art (Kim et al., 2020) before and after the proposedmethod is applied on the SOP dataset. Images with green boundary are success cases and those withred boundary are false positives.
