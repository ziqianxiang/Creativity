Figure 1: An overview of the DeePSPU learning process. The Representation Network learns ahidden representation of the input sequence that is fed to both the Classification Network and theSequential Propensity Network. Networks are alternately trained iteratively, with one being frozenwhile the other is updated.
Figure 2: a) The ablation study of DeepSPU indicates that each of its major components significantlyimproves its performance. b) Performance of DeepSPU varying values for the class prior π estimate,with the true prior being about 0.36.
Figure 3: An example of unlabeling with Markov chain.
Figure 4: Histogram of lengths of consecutive labels (in minutes).
Figure 5:	DeepSPU’s estimated propensity score vs the true propensity scores. The estimated scoresmatch the true scores almost perfectly.
