Figure 1: Distribution of non-zero CLEVER scores for baseline ensemble and DML-based ensemblefor 1000 randomly selected images from the MNIST dataset. The CLEVER scores are computed onthe L2-norm ball with radius 2.
Figure 2: LoSS surface for individual classifiers around a sample XS from RESISC-45 dataset forpoints XS + ZXLCE(XS, yS) + OP with P 〜N(0,0.05), r ∈ [0,0.1], and θ ∈ [-0.1,0.1].
Figure 3:	ROC curves for adversary detection using unanimity framework. The perturbation size Wis 0.3, 8.0/255 and 8.0/255 for MNIST, CIFAR-10 and RESISC-45 datasets, respectively.
Figure 4:	ROC curves for adversary detection using unanimity framework with 1-D mapping in theembedding space. The perturbation size W is 0.3, 8.0/255 and 8.0/255 for MNIST, CIFAR-10 andRESISC-45 datasets, respectively.
Figure 5: Uncertainty distribution.
Figure 6: ROC curves for adversary detection using uncertainty distribution. The perturbation sizeW is 0.3, 4.0/255 and 8.0/255 for MNIST, CIFAR-10 and RESISC-45 datasets, respectively.
Figure 7: Distribution of local CLEVER score for baseline ensemble and DML-based ensemble for1000 randomly selected images from CIFAR-10 dataset with a CLEVER score of higher than thethreshold 0.2. The CLEVER scores are computed on the L2-norm ball with radius 2.0.
Figure 8: Distribution of local CLEVER score for baseline ensemble and DML-based ensemble for1000 randomly selected images from RESISC-45 dataset with a CLEVER score of higher than thethreshold 0.2. The CLEVER scores are computed on the L2-norm ball with radius 2.0.
Figure 10: Distribution of the cosine similarity of the gradients with respect to inputs for two modelsin the DML-based ensemble trained with the regularizer term for imposing orthogonality of theM matrices (γ = 1.0) and the DML based ensemble trained without regularizer term (γ = 0) forCIFAR-10 dataset.
Figure 9: Distribution of the cosine similarity of the gradients with respect to inputs for two modelsin the DML-based ensemble trained with the regularizer term for imposing orthogonality of the Mmatrices (γ = 1.0) and the DML based ensemble trained without regularizer term (γ = 0) for MNISTdataset.
Figure 11: Distribution of the cosine similarity of the gradients with respect to inputs for two modelsin the DML-based ensemble trained with the regularizer term for imposing orthogonality of theM matrices (γ = 1.0) and the DML based ensemble trained without regularizer term (γ = 0) forRESISC-45 dataset.
Figure 12: Benign and adversarial accuracy for adversarialy train models with FGSM attack withoutrandom initialization.
Figure 14: Certified accuracy for three types of DML-based model trained standardly. The standarddeviation to compute certified accuracy is (a) a = 0.1 and (a) a = 0.25. The standard deviation forthe Gaussian noise of R-DML and AUG-DML is a = 0.5.
Figure 13: Benign and adversarial accuracy for adversarialy train models with FGSM attack withoutrandom initialization. The DML based models formed with priors which are adversarialy trained.
Figure 15: Certified accuracy for smoothed classifier obtained by randomized smoothing of the classifier withDML. The curves corresponding to R-DML and AUG-DML show the certified accuracy when the DML layerreplaced by R-DML and AUG-DML where the Std of GaUssian noise is 依.(TC denotes the Std of GaUssiannoise used to compute certified accuracy.
Figure 16: Certified aCCuraCy for smoothed Classifier obtained by randomized smoothing of the Classifierswith three types of DML: DML, R-DML and AUG-DML. To CalCulate the Certified aCCuraCy the DML layer foreaCh smoothed Classifier is replaCed with R-DML where TR denotes the std of Gaussian noise for R-DML. TCdenotes the std of Gaussian noise used to Compute Certified aCCuraCy.
Figure 17:	Loss surface for three individual classifiers from the ensemble model without group-wisesplitting mechanism. The loss is depicted around the sample %S with the label yS from RESISC-45dataset. The noise vector P is drawn from the normal distribution N(0,0.05). The loss surfacesdoes not show significant diversity across members.
Figure 18:	Distortion-accuracy curves for adversarial examples crafted by FGSM and PGD white-boxaattacks over three datasets.
Figure 19: Adversarial samples generated by CW-b attack (k=0.0) on the original samples fromMNIST dataset (first row), and on Ensemble model (2nd row), Model 1 (3rd row), Model 2 (4throw), Model 3 (5th row), Model 4 (6th row), Model 5 (7th row).
Figure 20: Adversarial samples generated by CW-L2 attack (K = 0.10) on the original samples fromCIFAR-10 dataset (first row), and on Ensemble model (2nd row), Model 1 (3rd row), Model 2 (4throw), Model 3 (5th row), Model 4 (6th row), Model 5 (7th row).
Figure 21: Adversarial samples generated by CW-∑2 attack (κ = 0.10) on the original samples fromRESISC-45 dataset (first row), and on Ensemble model (2nd row), Model 1 (3rd row), Model 2 (4throw), Model 3 (5th row), Model 4 (6th row), Model 5 (7th row).
