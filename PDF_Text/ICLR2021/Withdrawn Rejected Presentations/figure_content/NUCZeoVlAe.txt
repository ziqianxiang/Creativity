Figure 1: The Common Feature Subspace and Converging Trends of P-vector Angles withCIFAR-10. Figure 1.(a)-(b) present cosine (in the range of [0,1]) of angles between the P-vectorsof well-trained models of various architectures under different learning paradigms, using trainingand testing datasets respectively. A well-trained model here is the one trained under the suggestedsettings after 200 epochs for supervised/self-supervised CNN classifiers and 100 epochs for unsu-Pervised AEs. Figure 1. (c)-(h) present angles of P-vectors between the well-trained model and itscheckpoint per training epoch of three learning paradigms, where the converging trends of P-vectorangles from nearly-orthogonal to smaller ones have been observed in all models, no matter whetherthe feature extractors of these models are trained with / without labels. Note that we carried out ex-periments with different random seeds in 5 independent trials to obtain the averaged results above.
Figure 2: Obtain P -vectors of deep neural networks using a group of samples#features dM SqdUJeStt,-239A Jsn6βs 够f αfi，-VectorRandomized SVD to obtain Top LeftSingUlar Vector as the，-Vectorstudied the properties of regions where a supervised DNN classifier with piecewise linear activationbehaves linearly, our work observes the common linear subspaces shared by the features learned bythe networks that are trained with different architectures (e.g., MLP/CNN classifiers and AEs withReLU activation) and paradigms (e.g., supervised, unsupervised, and self-supervised learning). Fur-thermore, both our work and (Saxe et al., 2019) propose to compare feature/representation learningby various models through SVD, while we perform SVD to investigate the distribution of samples infeature space and (Saxe et al., 2019) uncovered the latent structures in input-and-output of neurons.
Figure 3: Singular Value Distribution and Explained Variance Ratiosof the Matrix of Feature Vectorsmight fail to capture the necessary information to represent the features learned. To validate thecapacity of P -vectors to represent the feature space, we carried out Singular Value Decompositionon the matrix of feature vectors, using CIFAR-10 and CIFAR-100 datasets both based on ResNet-50models, and obtain the distribution of singular values over indices. More specifically, we computethe distributions of singular values for the feature matrices obtained in the 1st, 60th, 120th, 160thand 200th epochs to monitor the change of singular value distributions throughout the training pro-cedure. It has been observed in Figures 3(a) and (b) that a “cliff” pattern in the distribution becomesmore and more significant after epochs of training for both CIFAR-10 and CIFAR-100 datasets - avery small number (less than 10) of top singular values might dominate the whole distribution. InFigure 3(c), we plot the curve of explained variance ratio σk2 /Pjd=1 σj2 for every pair of singularvectors, using well-trained models of 200 epochs based on CIFAR-10 and CIFAR-100, where σkrefers to the kth singular value and d is the rank of matrix. The explained variance ratio of the top-1singular vectors (i.e., the P-vector and the top-1 right singular vector) is more than 50% while thesecond top singular vectors are less than 10%. Results show the use of P-vectors could representthe features learned. In addition to the use of top-1 singular vectors (the P-vector), in Appendix(A.7), we also discuss the results of including more singular vectors in analysis, where no consistentobservations have been obtained.
Figure 4: Distribution of Values in the P-Vectortotal counts and plot the smoothed probability density of the distributions (of the values in the P-vector) in Figure 4 (a) and (b) for CIFAR-10 and CIFAR-100 datasets. Specifically, we plot thedistribution for P-vectors obtained in different epochs throughout the training procedure, where aclear “concentration” process could be observed. In the beginning, probably due to the random ini-tialization, the values are flatten in a wider range. With the training epochs, the distributions in theboth figures would be “concentrated” into narrow ones with reduced ranges. We could observe thepeak shifts over training epochs in both figures, while the distributions based on two datasets are sig-nificant different from both magnitudes and ranges’ perspectives. Examples on the raw frequency ofvalues in P-vector is included in Appendix (A.6), where same trends could be observed. Note thattwo P-vectors are not necessary to be close, when their distributions (of values) are close. Becausethe specific value assigned to every sample in the P -vector could be significantly different. Thus,analyzing the distribution of values in P-vectors with respect to the distribution of data might be apart of future work.
Figure 5: Cosine of angles between the P -veCtors of well-trained modelsappears more frequently, due to the Curse of dimensionality (Pestov, 1999). Thus, given a sampleset suCh as CIFAR-10 with more than 60,000 samples, when the Cosine measure Close to 1.0 orthe angle between the two P -veCtors (with 60,000 dimensions) is small, we Can ConClude that thetwo networks would share a subspaCe in the feature spaCes in high ConfidenCe. Of-Course, theremight exist other ways to perform analysis using P -veCtors. In our future work, we plan to leverageadvanced numerical tools BjorCk & Golub (1973) to estimate the angles between the subspaces ofDNN models in general dimensions.
Figure 6: P -veCtor angles between CheCkpoint per epoChand well-trained models using CIFAR-10.
Figure 7: Angles between the P-vectors of the training andwell-trained models over the number of iterations in the firstepoch using CIFAR-10.
Figure 8: Angles between the model and data P-vectors pertraining epoch. C10: CIFAR-10, C100: CIFAR-1003We use the term “model P -vector” to represent the P -vector estimated using the feature vectors of a deepmodel, while using “data P -vector” as the top left singular vector of the raw data matrix.
Figure 9: Strong and Consistent Correlations between the model performanCe (training and test-ing aCCuraCy) and the angels between model and data P-veCtors using CIFAR-10 and CIFAR-100datasets. VN: VggNet, RN: ResNet, C10: CIFAR-10, and C100: CIFAR-100.
Figure 10:	Convergence to the Common Feature Subspace with CIFAR-100. Curves of angles ofP-vectors between the well-trained model and its checkpoint per training epoch of three learningsupervisory manners. The trends of convergence for the angles can be observed in all models.
Figure 11:	Angles between the P-vectors of the training and well-trained models over the numberof iterations in the first epoch using CIFAR-100.
Figure 12:	Convergence of P-vector angles between checkpoint per epoch and well-trained modelsusing CIFAR-100.
Figure 13:	Angles between the P-vectors of the training and well-trained models over the numberof iterations in the first epoch using CIFAR-10 /CIFAR-100.
Figure 14: Angles changes through layer between the P-vectors of the training and raw data overthe number of iterations in the first epoch using CIFAR-10.
Figure 15: Frequency distributions of the P-vectorover training epochs.
Figure 16: Angles between the top-k left singular vector (k = 1 is the P -vector) of the training andwell-trained models over the number of epochs in the training process (Resnet-50, CIFAR-10). Notethe first plot point refers to the feature matrix after trained for one epoch.
Figure 17: Log-Log Plots: Strong and consistent correlations between the model performance (train-ing and testing accu racy in log range) and the angels (in log range) between model and data P -vectors using CIFAR-10 datasets. VN: VggNet, RN: ResNet, C10: CIFAR-10.
