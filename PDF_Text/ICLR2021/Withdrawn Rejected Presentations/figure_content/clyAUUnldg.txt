Figure 1: Comparison of the loss decay w.r.t. # function evaluations for the 12 benchmark functionsin 1000D. Each curve is the mean of 20 independent trials and the shaded areas represent [mean-3std, mean+3std]. The global minimum is Fi(xopt) = 0 except for i = 11, where F11 (xopt) = 1.
Figure 2: Tests on AdaDGSâ€™s scalability in 2000D, 4000D and 6000D. The hyper-parameters arethe same as the 1000D case. The AdaDGS still achieves promising performance, even though thenumber of total function evaluations increases with the dimension.
Figure 3: Comparison of the loss decay w.r.t. # function evaluations for four objectives. From left toright: generate a Mario level with i) maximum number of sky tiles, ii) maximum number of enemies,iii) forcing AI Mario to make the most kills, and iv) forcing AI Mario to make the most jumps.
Figure 4: The levels generated by optimizing MaxSkyTiles objective have four patterns. Fromtop left, clockwise: High number (>80) of sky tiles, medium number (' 40) of sky tiles, mediumnumber of sky tiles with no ground, and low number (' 20) of sky tiles. The top-left type of patternsis the targeted pattern and the other three represent local minima. The probabilities of generating thefour types of patterns are: AdaDGS: 90%, 4%, 2%, 4% and IPop-CMA: 74%, 8%, 8%, 10% (fromtop left, clockwise). AdaDGS shows better performance on generating the targeted pattern.
Figure 5: Comparison of the loss decay w.r.t. # function evaluations in log-scale. AdaDGS convergesto the global minimum in six of the test functions: F1, F5, F7, F9, F10, F11. Other baselines fail toconverge for any of the test functions. Each curve is the mean of 20 independent trials.
Figure 6: Illustration of the dimension dependence of the convergence rate of AdaDGS method.
