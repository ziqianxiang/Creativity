Figure 1: (a-b) Layer-wise STDEV for ResNet20 with 1X or2X channels. (c) Layer-wise STDEV forVGG16 with 1X or 2X channels. (d) Test accuracy on ResNet20 with 1X or 2X channels (accuracydrop from W32A32 to W2A2).
Figure 2: Experiments on CIFAR10-ResNet20 that shows gradients of cross-entropy loss w.r.t. searchparameters (αι 〜ɑ8) of a layer during search: (a) in full-precision, (b) with 2-bit quantization. (C)Kendall rank-correlation score of all layers.
Figure 3: (a) Test accuracy after search with or without quantization. (b) Model structure after searchwith or without quantization. (c) Accuracy vs. FLOPs for different channel expansion strategies.
Figure 4: Comparison of quantization performance between NCE and WRPN with respect to (a)PARAM and (b) FLOPs on ResNet20-CIFAR10.
Figure 5: Comparison of STDEV and SQNR of activation between ResNet20-CIFAR10 and NCEwhen the models are quantized to 2-bit. (W2A2 Accuracy: ResNet20 (90.82%), NCE (91.63%))Search ResNet50 structure2000 -ResNet50NCE ResNet501750-(uUUBlp#500250O¼UUu∣u∣[1W1 4 7 10 13 16 19 22 25 28 31 34 37 40 43 46 49layersIu 而 IilFigure 6: Comparison of structure of ResNet50-ImageNet before and after adaptation by NCE.
Figure 6: Comparison of structure of ResNet50-ImageNet before and after adaptation by NCE.
