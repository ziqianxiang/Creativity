Figure 1: Description of the uncertainty modelling of a black-box predictive system, β . This mod-elling is done by means of an uncertainty wrapper (the only part of the ChePAN that requires a neuralnetwork), which produces all of the distribution ppy | xq as quantiles, qppy|xq. The ChePAN ensuresthat the original prediction of β corresponds to a desired statistic of ppy | xq, i.e. the constraint.
Figure 2: Graphic representation of the ChePAN. For any degree d, {p& ud´j are evaluations of theinitial Chebyshev polynomial expansion, {ck}k“0 their coefficients, {Ck}k“0 the coefficients of theintegrated polynomial, β the black box function and P the conditional prediction of the quantile τ .
Figure 3: Heterogeneous synthetic distribution proposed by (Brando et al. (2019)). In the upperpart of the figure, the learnt quantiles, φ, are noisy because their mean is the black box defined as aninaccurate MSE Random Forest (RF), β, following Equation 12. In the lower part, φ and β are learntand asymmetries and multimodalities can be seen more clearly, while still respecting the constraintin Equation 12.
Figure 4: Plot with performance in terms of calibration. The table contains the mean and standard deviationof all the folds using the mean absolute error between the empirical predicted calibration and the perfect idealcalibration of 980 equidistant quantiles using Equation 14.
