Figure 1: Learner diagram. ThePPO+D learner samples batches thatare a mixture of demonstrations andthe experiences the agent collects byinteracting with the environment.
Figure 2: Tasks. In each of the tasks there is only one source of reward and the position of someof the objects is random, so each episode is different. The agent has no access to the aerial view,instead it partially observes the world through a first person view of the environment. All of thetasks are either inspired or adapted from the test set in the Animal-AI Olympics competition.
Figure 3: Experiments. Performance of behavioural cloning with ten and a hundred recordedhuman demonstrations and PPO+D with ρ = 0.1, φ = 0.3 and just one demonstration. The curvesrepresent the mean, min and max performance for each of the baselines across 3 different seeds. TheBC agent sporadically obtains some rewards. GAIL with a hundred demonstrations never achievesany reward. PPO+BC has only access to one demonstration, like PPO+D. It occasionally solves thetask but it is unable to archive high performance.
Figure 4: Experiments. Performance for vanilla PPO (ρ = 0.0, φ = 0.0), PPO+D with ρ =0.5, φ = 0.0 and PPO+D with ρ = 0.1, φ = 0.3 on the tasks ”One box easy” and ”Two boxes easy”using a single demonstration. Some of the curves overlap each other as they receive zero or close tozero reward. Vanilla PPO never solves the task.
Figure 5: Ablation study Performance for PPO+D with ρ = 0.1, φ = 0.0, ρ = 0.3, φ = 0.0,ρ = 0.5, φ = 0.0 and ρ = 0.5, φ = 0.0 and PPO+D with ρ = 0.7, φ = 0.0, on a variation of the”One box easy” task were the initial position of the agent is fixed. The curves represent the mean,min and max performance for each of the baselines across 3 different seeds.
Figure 6: Food collection task. In this task the the agent is spawned into the arena with one greenball. The green food size and position are set randomly at the beginning of each episode. Theepisode ends when the green food is collected.
Figure 7: Sub-behaviors. Trajectories the agent played on the task ”Two boxes easy”. In each ofthe figure the upper part shows the movements of the agent on the X-Y plane while the lower partshows the movement on the X-Z plane. The images are ordered by the time they were executed inthe training in millions of frames.
