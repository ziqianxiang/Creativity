Figure 1: The generator (a) takes low-resolution data Xt as input, together with a high-resolutionversion, from the previous time step Yt-1. The low-resolution data is tri-linearly up-scaled (orangelayer), while the data with the previous state is advected with the velocity of the input (green layer).
Figure 2: The process of our blockwise frequency evaluation. The input data is divided into blocksof a given size. A 2D/3D FFT is performed on the blocks, thus obtaining the individual Fouriercoefficients, again in the form of grids. These grids are then arranged so that each grid correspondsto a Fourier coefficient.
Figure 4: From left to right the image data and the corresponding spatial and temporal frequencyimages are shown. The respective columns indicate the frequency (from left, low to right, highfrequency). We consider the ground-truth (a), a result based on MSE (b) and the surfGAN result (c).
Figure 3: The averaged frequency spectrum of our data set (a) for the surface, spatial (left), andfor the temporal behavior (right). The spectrum of the low frequency input data is shown in blue,while in orange the spectrum of the ground-truth data is shown. In the spatial spectrum, itâ€™s clearlyvisible that the spectrum of the input data only covers a quarter of the frequencies, while a largepeak of the ground-truth is visible for higher frequencies. This highlights what the generator needsto reproduce. A similar shape can be seen in the time spectrum as the time response is stronglycoupled to the surface frequency. Here, the spectrum of the input data (blue) continues as the timediscretization is the same for both. Figure (b) shows an example of a surface from our synthetic dataset: the input wave in blue, and the corresponding ground-truth target in purple.
Figure 5: Frequency spectrum comparison of different versions of our network for the synthetic2D data set. The top row always shows the spatial frequency, while the bottom row shows thetemporal frequency. The spectrum of the input is shown in blue, the ground-truth in yellow, and thepredictions in green. Versions (a) was trained with a simple MSE loss, while (b) was extended witha frequency loss; (c) and (d) were trained with an adversarial loss, whereby the latter evaluation wastrained with unpaired data.
Figure 6: Comparison of a frame from a test run with the synthetic 2D data set. The input is shownin blue, ground-truth in red, and predictions in green.
Figure 7: Comparison of 3D frames with a surfGAN model (a), with a MSE-based generator (b) andtempoGAN (c). The input is shown in blue, ground-truth in red, and predictions in green.
Figure 8: In blue a wave with a randomly varying low frequency fl, which can still be representedby the low-resolution sampling and serves as input data set for our synthetic data set. In red, onthe other hand, we see a wave with a high frequency fh that can only be correctly represented withmuch higher resolution. Combined with the low-frequency version, we get the ground-truth data(violet) for the synthetic data set.
Figure 9: Evaluation of deterministic setup.
Figure 10: F.l.t.r the image data and the corresponding spatial and temporal frequency images areshown. We consider the ground-truth (1), a result based on MSE (2) and the surfGAN result (3).
Figure 11: F.l.t.r the image data and the corresponding spatial and temporal frequency images areshown. We consider the ground-truth (a), a result based on MSE (b) and the surfGAN result (c).
Figure 12: Comparison of a 3D test run wit our surfGAN (b), with a MSE-based generator (c) andtempoGAN (d). The input is shown in blue, ground-truth in red, and predictions in green.
Figure 13: An additional output generated with the surfGAN network. The input is shown in blue,ground-truth in red, and the prediction in green.
