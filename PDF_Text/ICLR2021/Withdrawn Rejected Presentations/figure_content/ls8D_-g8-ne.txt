Figure 1: A: An overview of our scheme. An expensive-to-query ground-truth oracle φ : X → y; alocal approximate model φ0 trained on samples D from φ; an exploration algorithm E which isthe primary interest of our study (e.g. AdaLead, DynaPPO,...), In our setting, the training of φ0 isfully supervised. B: Noise corrupted abstract models φ0α allow for independent study ofE onlandscapes where ground truth can be simulated (here an RNA landscape of size 14, binding to onetarget). For comparison, the R2 score for an ensemble of 3 CNNs trained on a random set of 100sequences around the starting position is provided.
Figure 2: We record the cumulative maximum over all sequences generated by each algorithm whenrun with 10 batches of size 100, and V = 20. An scores on the y-axis normalized to known orestimated maximum possible value. A: The cumulative maximum achieved by each algorithm on TFbinding landscapes (13 initializations), using an ensemble of 3 CNNs as the oracle (φ00). On thissimple landscape, even a model free evolution algorithm can optimize well. B: Consistency(performance vs. model quality α) and robustness (performance at low α) of the algorithms on a 2target RNA landscapes of L = 14. C: Time evolution of the cumulative maximum over an RNAlandscape with sequence length 14, and 2 hidden targets (5 initializations, α = 1). Top: φα=1,bottom: φ00 , ensemble of 3 CNNs. D: Comparison of overall performance for 3 landscape classes.
Figure A1: A: Running GP-based BO on the TF binding landscape with full enumeration of thesequence space (V = ∞). For comparison, we show that the evolutionary BO, used in the paper as abenchmark, outperforms these methods. B: A comparison of multiple evolutionary algorithms thatwere run on rNa binding landscapes of length 14 and one target, with similar μ = 1∕L,r = 0.2.
Figure A2: Effects of these hyperparameters on the performance of AdaLead, on RNA landscapeof length 14 and two hidden targets. ADALEAD is robust to hyperparameter choices for κ, r. Thesetting used in the paper shown is in blue (r = 0.2, K = 0.05). The same K with no recombination isshown in red. All other hyperparameters r ∈ [0, 5] and K are shown as "alt. HP”. μ was set to mirrorthe μ used for all other algorithms, and V = 20. A: The case where α = 1, i.e. the model has perfectinformation. B: When an ensemble of 3 CNNs was used.
Figure A3: A tour of a composite “Swampland" fitness landscape with sequence size 100 bydirect walks between sequences of interest. Colored circles represent sequences of significance.
Figure A4: A: Effects of batch-size on AdaLead, on RNA landscape of length 14 and two hiddentargets.The case where α = 1, i.e. the model has perfect information. B: Ablation study for Adaleadwithout ROLLOUT on the same landscape.
