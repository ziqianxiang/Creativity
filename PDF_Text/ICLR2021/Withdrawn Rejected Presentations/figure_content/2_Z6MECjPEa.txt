Figure 1: A cartoon illustrating how a foveated image is rendered resembling a human visual metamervia the foveated feed-forward style transfer model of Deza et al. (2019). Here, each receptive field islocally perturbed with noise in its latent space in the direction of their equivalent texture representation(blue arrows) resulting in visual crowding effects in the periphery. These effects are most noticeablefar away from the navy dot which is the simulated center of gaze (foveal region) of an observer.
Figure 2: A. Two key Perceptual Systems S: Foveation-Net (top row) and Standard-Net (bottomrow), where each system receives an image as an input, applies a foveation transform (ʃ(o)), whichis then relayed to a CNN architecture (g(o)) for scene classification. Foveation-Net uses a visualcrowding model with texture computation (shown on right), while Standard-Nets provides a baselinefor a perceptual upper-bound for all perceptual systems. B. The algorithm of how a foveated image isgenerated that enables visual crowding (mainly steps 5-7).
Figure 3: A. Two matched-resource controls to Foveation-Net are introduced. Top, seagreen:adaptive gaussian blurring (Ada-Gauss-Net) emulating RGC convergence-based foveation; Bottom,orchid: uniform blurring emulating a matched-resource non-foveated visual system (Matched-Net).
Figure 4: RD-Optimization.
Figure 5: A. Three critical questions that our 4 conditions will help Us answer pertaining the roleof foveated (spatially-varying) perceptual systems and their comparisons to their non-foveatedcounterparts. B. Five example images from the 20 scene categories are shown, after being passedthrough the first stage of each perceptual system.
Figure 6: A. A legend illustrating the 4 key perceptual systems in all our experiments with theirdifferences and similarities: Standard-Net, Foveation-Net, Matched-Net and Ada-GaUSS-Net. B.
Figure 7: A. The Robustness curves for image occlusion (◦㊉ O) when the FoVeation Transform is On(as the stimuli is shown before the transform), and when the Foveation Transform is Off (stimuli shownpost-transform). Foveation-Nets performs has greater robustness to occlusion across all matched-resource systems, and also bumps it,s performance due to visual crowding. B. A visualization of howthe visual input is transformed for each perceptual system given their respective Foveation transform(f ). Left: The effects of crowding are noticeable for Foveation-Nets (but not Ada-Gauss-Nets)as it increases visual area. Right: Even without the aid of visual crowding, the learned texturerepresentation yields greater robustness with matched occluded areas for Foveation-Nets.
Figure 8: A. A visualization of the stimuli type that is shown to each perceptual system consistsof a smoothed composition of a foveal image (e.g. badlands) mixed with a peripheral image (e.g.
Figure 9: A. Sample images from the foveated and non-foveated images and how they change as afunction of spatial frequency filtering at the post-foveation stage. Bδ Foveation-Nets have nominallygreater sensitivity to high spatial frequency filtered stimuli than Standard-Nets, and both of thesesystems present notably higher sensitivity to high spatial frequencies than Matched-Nets and Ada-Gauss-Nets. Conversely, this pattern is reversed for low pass frequency stimuli. C This suggestsFoveation-Nets5S crowding-like computation may naturally enforce a shape-bias given it,s high passspatially frequency tolerance as these Spatial Frequency curves show similar trends as Geirhos et al.
Figure 10: A full explanatory diagram of the Rate-Distortion Optimization Procedure inspiredfrom both Balle et al. (2016) and Deza et al. (2019). The goal is to find the equivalent ’perceptualtransmission rate’ for a given distortion σ to find a matched-resource perceptual input for Foveation-Nets that is non-foveated (Figure 4). This optimization produces Matched-Nets, a perceptual systemthat receives as input uniformly blurred images as a way to quantify the expense of computing lowerfrequencies given retinal ganglion cell re-distribution in as if it were to occur in humans.
Figure 11: A. The full explanatory diagram (continued) of the Rate-Distortion Optimization Procedurefrom Figure 10 adapted for Ada-Gauss-Nets. B. The goal is to find the equivalent ‘perceptualtransmission rate, for a given distortion σ to find a matched-resource perceptual input for Foveation-Nets that is foveated but with adaptive gaussian blurring, i.e. we must find the standard deviation of thegaussian blurring kernel which is computed over a set of eccentricity rings that have been windowedwith cosine functions. C. The full Rate-Distortion curves as a function of retinal eccentricity.
Figure 12: Two additional Perceptual Systems, that serve as data-augmentation controls: Foveation-Aug-Net (top row) and Standard-Aug-Net (bottom row), where each system receives an image asan input, applies a foveation transform (f0(。))coupled with a data-augmentation procedure suchas eye-movements (Foveation-Aug-Nets) or random cropping + resizing + horizontal mirroring(Standard-Aug-Nets). Once again, these newly transformed image representations are then relayed toa CNN architecture (g(o)) for scene classification.
Figure 13: Learning: An averaged visualization of loss function convergence as a function ofepochs for all 6 perceptual systems: standard-Nets, Foveation-Nets, Matched-Nets, Ada-Gauss-Nets,standard-Aug-Nets, Foveation-Aug-Nets. Each point in the plot is the average across the 10 differentnetwork runs from the locally averaged/smooth loss function per each 9 epochs. The epoch snapshotswe show in our analysis are: AlexNet: 180, 270 (reported in main body of paper), 360; ResNet18: 90,120, 180.
Figure 14: Sample Testing Image Mosaics (Part 1, not cherry picked).
Figure 15: Sample Testing Image Mosaic (Part 2, not cherry picked).
Figure 16: Sample Testing Image Mosaic (Part 3, not cherry picked).
Figure 17: Sample Testing Image Mosaic (Part 4, not cherry picked).
Figure 18:	Generalization: The full i.i.d. Generalization and o.o.d Generalization plots for AlexNetand ResNet18 across multiple epochs of training. We observe that our results do not vary as afunction of training epoch or network architecture: Foveation-Nets with greater i.i.d generalizationacross matched-resource systems, and Ada-Gauss-Nets with greater o.o.d generalization across allsystems. This suggests spatially-varying computation provides a representational benefit in both thei.i.d and o.o.d setting contingent on the type of foveated computation (texture vs blur). Future workshould evaluate combining both computations. A. Our 4 main perceptual systems: Standard-Net,Foveation-Net, Matched-Net, Ada-Gauss-Net; B. Standard-Net (re-plotted from above), Foveation-Net (re-plotted from above), Standard-Aug-Net (supplementary), Foveation-Aug-Net (supplementary).
Figure 19:	Robustness to Occlusion of All Perceptual Systems (Extended - Part 1/4).
Figure 20:	Robustness to Occlusion of All Perceptual Systems (Extended - Part 2/4).
Figure 21:	Robustness to Occlusion of All Perceptual Systems (Extended - Part 3/4).
Figure 22:	Robustness to Occlusion of All Perceptual Systems (Extended - Part 4/4).
Figure 23: Window Cue Conflict Experiment: The pattern or results with regards to a greater fovealbias for any foveated perceptual system over non-foveated perceptual systems remains independent ofthe network architecture (g(。)) and the epoch. This can be verified by finding the cross-over pointsfor Foveation-Nets, Ada-Gauss-Nets, and Foveation-Aug-Nets being placed more leftwards thanStandard-Nets, Matched-Nets and Standard-Aug-Nets. These results are independent of potentialperceptual differences at testing time i.e. baseline. For example, see AlexNet @ 360 epochs, orResNet18 @ 120 or 180 epochs, where the cross-over point for Standard-Nets, Matched-Nets andStandard-Aug-Nets is still shifted more biased towards the right than Foveation-Nets, Ada-Gauss-Nets and Foveation-Aug-Nets - implying a greated need for foveal area to arrive to the point ofsubjective equality (PSE). A final note on the interpretability of these results is that this foveal biasis being tested after the foveation transforms are computed (similar to our post-foveation occlusionexperiments), such that no changes in area are driving the revealed biases, and thus the bias is drivenpurely by the learned representation.
Figure 24: Spatial Frequency Sensitivity for AlexNet and ResNet18 across multiple training epochs:There are no notorious differences for high pass frequency sensitivity across network architectureand epochs in comparison to the results reported in the main body of the paper. Specifically, thesepatterns are: no differences between Foveation-Nets, Foveation-Aug-Nets and Standard-Nets (allthree statistically tested with paired t-tests against each other, n.s.). There are differences betweenStandard-Nets and Standard-Aug-Nets (a greater bias to high pass spatial frequency sensitivity inStandard-Nets). These 4 systems are notably also more biased to high pass spatial frequency thanAda-Gauss-Net and Matched-Net in an orderly fashion. The opposite pattern of results hold for lowpass frequency sensitivity.
