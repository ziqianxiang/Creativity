Figure 1: Multi-modal multi-task models for the M3 benchmark. We propose an architecture con-sisting of an encoder that outputs multi-modal embeddings based on text, time series, and tabularinputs as well as recurrent connections from earlier time steps (green horizontal lines). At eachprediction time, these embeddings are used by task-specific components (e.g., ”Decomp model”and others) to output predictions. Predictions are evaluated by task-specific losses and an overallmultitask loss.
Figure 2: Multi-modal encoder and task-specific components. At each time step t, ft(1) are theencoded time series features, ft(2) are the encoded tabular inputs, and ft(3) is the encoded clinicalnotes. The Ot is a concatenated global embedding.
