Figure 1: Mean square error between AR and the exact backpropagated gradients on a 3 layer MLP.
Figure 2: Train and test accuracy and gradient angle (cosine similarity) for AR vs backprop forMNIST and Fashion-MNIST datasets.
Figure 3: Train and test accuracy and gradient angle (cosine similarity) for AR vs backprop forMNIST and Fashion-MNIST datasets.
Figure 4: Angle between the AR and backprop updates in the learnable backwards weights, nononlinear derivatives, and the combined conditions.
Figure 5: Accuracy (averaged over 5 seeds) for AR trained with the crossentropy loss function in thestandard AR, learnable backwards weights, no-nonlinearities, and combined conditions.
Figure 6: Performance (test accuracy), averaged over 10 seeds, on CIFAR10 demonstrating thescalability of the learnable backwards weights and dropping the nonlinear derivatives in a CNNarchitecture, compared to baseline AR without simplifications. Performance is equivalent throughout.
