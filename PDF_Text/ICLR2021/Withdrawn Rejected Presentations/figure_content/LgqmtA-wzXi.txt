Figure 1: (a) AMAB with 10 actions. (b) A sinusidial MAB with 10 actions. (c) AMAB with 10actions. We further limit the number of consecutive pulls of a handle by 10. (d) Sinusidial MABwith 10 actions. We further limit the number of consecutive pulls of a handle by 10.
Figure 2:	The Wheel Bandit setup. Each colored region describes a different reward distributionbased on points sampled in that region. (a) The Wheel Bandit. (b) The Rotating Wheel Bandit withan angular velocity of ω.
Figure 3:	(a) The Wheel Bandit. (b) Rotating Wheel Bandit with Tperiod = 2000. LinTS is by Cortes(2018) and NeuralLinear is the method of Riquelme et al. (2018).
Figure 4: Cumulative regret for Rotting Bandits.
Figure 5: The Mean Cumulative Regret on the Wheel Dataset for different values of αEC. (a) Thestationary wheel. (b) The rotating wheel with Tperiod = 2000.
