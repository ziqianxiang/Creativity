Figure 1: Illustration of our framework. (a) Before the encoder is frozen, all forward and backwardpasses are active through the network, and we store images in the replay buffer. (b) After freezing,we store latent vectors in the replay buffer, and remove all forward and backward passes through theencoder. We remark that more samples can be stored in the replay buffer due to the relatively lowdimensionality of the latent vector.
Figure 2: Learning curves for CURL with and without LeVER, where the x-axis shows FLOPs.
Figure 3: Learning curves for Rainbow with and without LeVER, where the x-axis shows FLOPs.
Figure 4: Comparison of the SamPle-efficiency of Rainbow with and without LeVER in constrained-memory (0.07 GB) settings. The dotted gray line denotes the encoder freezing time t = Tf. Thesolid line and shaded regions represent the mean and standard deviation, respectively, across fiveruns.
Figure 5:	Comparison of the sample-efficiency of CURL with and without LeVER in constrained-memory settings. The dotted gray line denotes the encoder freezing time t = Tf. The solid line andshaded regions represent the mean and standard deviation, respectively, across five runs.
Figure 6:	(a) Left: Cheetah-run learning curves for CURL with and without LeVER, with batch sizesb=512 and b=128, respectively, where the x-axis shows samples. Right: Number of FLOPs used byeach agent to achieve its final performance. (b) Learning curves for CURL using the IMPALAarchitecture with and without LeVER, where the x-axis shows FLOPs. The dotted gray line denotesthe encoder freezing time t = Tf. The solid line and shaded regions represent the mean and standarddeviation, respectively, across five runs.
Figure 7:	(a) Comparison of the computational efficiency of agents trained from scratch with CURLand agents trained with CURL+LeVER from Walker-stand pretraining. (b) Spatial attention mapfrom CNN encoders. (c) SVCCA (Raghu et al., 2017) similarity scores between each layer anditself at time t and t+10K throughout training for Walker-walk.
Figure 8: Comparison of the computational efficiency of agents trained from scratch with CURLand agents trained with CURL+LeVER from Walker-stand pretraining.
Figure 9: (a) Analysis on the number of frozen convolutional layers in Walker-walk training fromWalker-stand pretrained for 60K steps. (b) Analysis on the number of environment steps Walker-stand agent is pretrained prior to Walker-walk transfer, where the first four convolutional layers arefrozen.
Figure 10: Comparison of CURL in constrained-memory settings with and without LeVER, wherethe x-axis shows FLOPs, corresponding to Figure 5. The dotted gray line denotes the encoderfreezing time t = Tf. The solid line and shaded regions represent the mean and standard deviation,respectively, across five runs.
Figure 11: Comparison of Rainbow in constrained-memory settings with and without LeVER, wherethe x-axis shows FLOPs, corresponding to Figure 4. The dotted gray line denotes the encoderfreezing time t = Tf . The solid line and shaded regions represent the mean and standard deviation,respectively, across five runs.
Figure 12: Comparison of the sample-efficiency of CURL with and without LeVER, correspondingto Figure 2. The dotted gray line denotes the encoder freezing time t = Tf . The solid line andshaded regions represent the mean and standard deviation, respectively, across five runs.
Figure 13: Comparison of the sample-efficiency of Rainbow with and without LeVER, correspond-ing to Figure 3. The dotted gray line denotes the encoder freezing time t = Tf . The solid line andshaded regions represent the mean and standard deviation, respectively, across five runs.
