Figure 1: The illustration of the influence of hard (confident) examples in classification. Circlesrepresent positive examples while triangles represent negative examples. Green and blue denoteexamples with accurate labels while red presents examples with incorrect labels. Blank circles andtriangles represent unextracted data. (a) shows an example of classification with clean data. (b)shows noisy examples, especially those close to the decision boundary, will significantly degeneratethe accuracy of classifier. (c) shows confident examples help learn a fairly good classifier. (d) showsthat hard confident examples are essential to train an accurate classifier.
Figure 2: Illustrative of extractinghard confident examples.
Figure 3: We call one update of the classifier and the extracted confident examples as one round. Weillustrate how the label precision of the extracted confident examples, the number of the extractedconfident examples, and the classification accuracy of the classifier trained by using the extractedconfident examples change during the training of Me-Momentum. We have three distinct peaks inthese figures because we have set Nouter = 3 and the classifiers are re-initialized in the outer loop.
Figure 4: Visualization of the extracted confident examples. The first and third columns are aboutthe confident data extracted in the first run of the inner loop; while the second the fourth columnsare about the confident data extracted in the outer loop. Specifically, green dots represent the dataselected in the first round. Blue and red dots represent the new extracted data in the middle and theend rounds respectively. Large figures for CIFAR100 are provided in the supplementary material.
Figure 5: Comparing the difference between the early stopping method in Step 1 and the traditionalvalidation method where the classifier with the highest validation accuracy during the whole trainingprocedure will be output. The green dash line indicates the epoch at which early stopping happens;while the orange dash line indicates the epoch at which the highest validation accuracy is achievedduring the whole training procedure. In the third plot, the two dash lines are identical to each other.
Figure 6: Illustrative of extracting hard confident examples.
Figure 7: Statistics of the extracted confident examples on MNIST by Me-Momentum. We call oneupdate of the classifier and the extracted confident examples as one round. We illustrate how thelabel precision of the extracted confident examples, the number of the extracted confident examples,and the classification accuracy of the classifier trained by using the extracted confident exampleschange during the training of Me-Momentum. The dash lines in the middle column indicate thenumber of clean labels in the noisy training data.
Figure 8: Statistics of the extracted confident examples on CIFAR10 by Me-Momentum. We callone update of the classifier and the extracted confident examples as one round. We illustrate how thelabel precision of the extracted confident examples, the number of the extracted confident examples,and the classification accuracy of the classifier trained by using the extracted confident exampleschange during the training of Me-Momentum. We have three distinct peaks in these figures becausewe have set Nouter = 3 and the classifiers are re-initialized in the outer loop. The dash lines in themiddle column indicate the number of clean labels in the noisy training data.
Figure 9: Statistics of the extracted confident examples on CIFAR100 by Me-Momentum. We callone update of the classifier and the extracted confident examples as one round. We illustrate how thelabel precision of the extracted confident examples, the number of the extracted confident examples,and the classification accuracy of the classifier trained by using the extracted confident exampleschange during the training of Me-Momentum. We have three distinct peaks in these figures becausewe have set Nouter = 3 and the classifiers are re-initialized in the outer loop. The dash lines in themiddle column indicate the number of clean labels in the noisy training data.
Figure 10: Visualization of the extracted confident examples on MNIST. The first column is aboutthe confident data extracted in the first run of the inner loop; while the second column is about theconfident data extracted in the outer loop.
Figure 11: Visualization of the extracted confident examples on CIFAR10. The first column is aboutthe confident data extracted in the first run of the inner loop; while the second column is about theconfident data extracted in the outer loop.
Figure 12: Visualization of the extracted confident examples on CIFAR100. The first column isabout the confident data extracted in the first run of the inner loop; while the second column is aboutthe confident data extracted in the outer loop.
Figure 13: Visualization of the extracted confident examples on CIFAR100. The first column isabout the confident data extracted in the first run of the inner loop; while the second column is aboutthe confident data extracted in the outer loop.
