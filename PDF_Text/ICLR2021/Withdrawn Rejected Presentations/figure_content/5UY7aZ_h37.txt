Figure 1: Training paths of different models on the Translated MNIST task. Different points represent the stateof the model at different epochs, from the initial state to the convergence. The visualization is based on a 2Dprojection of the representational similarity of the activations from the penultimate layer for the examples fromthe validation set, i.e. Translated MNIST (more details in Appendix B).
Figure 3: Performance (mean±std over 4 trials) of models with different inductive biases trained independentlyor using KD with different teachers.
Figure 2: A-Accuracy vs perplexity (high to low fromleft to right) for language models of different architec-tures and sizes.
Figure 4: A-Accuracy ↑ vs perplexity ] (high to lowfrom left to right) for student Transformer with LM ob-jective. In this figure the triangle marks indicate Trans-former models, and circles indicate the LSTM teachersused to train the student Transformers.
Figure 5: Calibration plots for independent and distilled Transformer for the classification setup. Note that sincethe task is binary classification, accuracy for confidences lower than 0.5 is not defined.
Figure 6: 2D projection of representational similarity of the activations from the penultimate layers for 1000examples from the validation set (check Appendix B for more details). We use the notation of a → b to refer tothe student model b distilled from teacher model a.
Figure 7: 2D projection of representational similarity of the activations from the penultimate layers for allexamples from the test set (check Appendix B for more details). We use the notation of a → b to refer to thestudent model b distilled from teacher model a.
Figure 8: Performance barriers between dif-ferent instances of MLPs and CNNs (withthe same initialization), in terms of loss onthe test.
Figure 9: Performance barriers between different instances of MLPs with the same initialization trainedindependently or through knowledge distillation. Here y-axis on each subplot is the value of the loss on the testset and x-axis is the value of the interpolation coefficient, λ. The rows in the figure correspond to the teacher ofthe instance on the left side (MLP#1) and the columns correspond to the teacher of the instance on the right sideof the plots (MLP#2).
Figure 10: Error overlap for LSTM and Transformer models trained with the classification objective on SVAtask. These Venn diagrams show the intersections of the sets of examples miss-classified by the models. In(a) we compare two independent LSTMs (LSTM#1 and LSTM#2) and an independent Transformer; in (b) wecompare two independent Transformers (Transformer#1 and Transformer#2) and an independent LSTM; in(c) we compare a student Transformer and a teacher LSTM with an independent Transformer; and in (d) wecompare a student Transformer and a teacher LSTM with an independent LSTM.
Figure 11:	Error overlap for CNN and MLP models trained on MNIST and tested on Scaled-MNIST set fromMNIST-C dataset. These Venn diagrams show the intersections of the sets of examples miss-classified by themodels. In (a) we compare two independent CNN (CNN#1 and CNN#2) and an independent MLP; in (b) wecompare two independent MLP (MLP#1 and MLP#2) and an independent CNN; in (c) we compare a studentMLP and a teacher CNN with an independent MLP; and in (d) we compare a student MLP and a teacher CNNwith an independent CNN.
Figure 12:	Error overlap for CNN and MLP models trained on MNIST and tested on Translated-MNIST setfrom MNIST-C dataset. These Venn diagrams show the intersections of the sets of examples miss-classified bythe models. In (a) we compare two independent CNN (CNN#1 and CNN#2) and an independent MLP; in (b) wecompare two independent MLP (MLP#1 and MLP#2) and an independent CNN; in (c) we compare a studentMLP and a teacher CNN with an independent MLP; and in (d) we compare a student MLP and a teacher CNNwith an independent CNN.
Figure 13: Effect of the quality of the teacher CNNs on the accuracy of the student MLPs. In the left plot, pointsthat share the value on the x-axis represent the quality of a CNN, with respect to different test sets: VanillaMNIST (in-distribution), Translated MNIST (out-of-distribution), and Scaled MNISt (out-of-distribution). Inthe right plot, similar to the left plot, points with the same x-value represent the quality of a same MLP model,trained via KD using the teacher on the corresponding place in the left plot, evaluated on the Vanilla, Translated,and Scaled MNIST test sets.
