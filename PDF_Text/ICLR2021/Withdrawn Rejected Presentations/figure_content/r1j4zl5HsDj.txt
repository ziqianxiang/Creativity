Figure 1: The r-dependent baseline definesa different policy for each value of r, thus,the blue curve may be unachievable withjust a single policy. π* is the single policythat minimizes the maximum gap to this r-dependent baseline policy.
Figure 2: Learned policies,lower is betterFigure 4: Max {θ : e(θ) ≤ Figure 5: Average Eθ〜Ph [∙],r}, lower is better	lower is betterFigure 3: Sub-optimality ofindividual policies, lower isbetterthe same information in terms of gap: '(π, Θ(r)) - min	'(πk, Θ(rk)). We observe that eachk:r`k-i <r≤rkπk performs best in a particular region and π* performs almost as well as the r-dependent baselinepolicies over the range of r . This plot confirms that our optimization objective of (2) was successful.
Figure 4: Max {θ : e(θ) ≤ Figure 5: Average Eθ〜Ph [∙],r}, lower is better	lower is betterFigure 3: Sub-optimality ofindividual policies, lower isbetterthe same information in terms of gap: '(π, Θ(r)) - min	'(πk, Θ(rk)). We observe that eachk:r`k-i <r≤rkπk performs best in a particular region and π* performs almost as well as the r-dependent baselinepolicies over the range of r . This plot confirms that our optimization objective of (2) was successful.
Figure 3: Sub-optimality ofindividual policies, lower isbetterthe same information in terms of gap: '(π, Θ(r)) - min	'(πk, Θ(rk)). We observe that eachk:r`k-i <r≤rkπk performs best in a particular region and π* performs almost as well as the r-dependent baselinepolicies over the range of r . This plot confirms that our optimization objective of (2) was successful.
Figure 6: Max {θ : ρe(θ) ≤ r}Table 1: Average E。〜P HMethod	Accuracy (%)π* (Ours)	-T7：9SGBS	{26.5, 26.2,	27.2, 26.5,	21.4, 12.8}Uncertainty	14.3LAL	4.1Uniform	6.9	knoWn to have near-optimal sample complexity (Hanneke et al., 2014). Uncertainty sampling evenoutperforms our r-dependent baseline by a bit which in theory should not occur-we conjecture thisis due to insufficient convergence of our policies or local minima. Our second experiment constructsa distribution P based on the dataset: to draw a θ 〜P we uniformly at random select a j ∈ [1000]and sets θ, = 2p(j) - 1 for all i ∈ [d]. As shown in Table 1, SGBS and π* are the winners. LALperforms much worse in this case, potentially because of the distribution shift from P (prior wetrain on) to P (prior at test time). The strong performance of SGBS may be due to the fact thatsign(θi) = 2z*(θ)i — 1 for all i and θ 〜P, a realizability condition under which SGBS has strongguarantees (Nowak, 2011).
Figure 7: Max {θ : ρe(θ) ≤ r}Table 2: Average E。〜P HMethod	Average Regretπ* (OUrS)^^	3.209SGBS	{3.180, 3.224,	3.278, 3.263,	3.153, 3.090}Uncertainty	3.027LAL	3.610Uniform	3.877	fensive jokes. We filter the dataset to only contain users that rated all 100 jokes, resulting in 14116users. A rating of each joke was provided on a [-10, 10] scale which was rescaled to [-1, 1] andobservations were simulated as Bernoulli’s like above. We then clustered the ratings of these users(see Appendix J for details) to 10 groups to obtain Z = {z(k) : k ∈ [10], z(k) ∈ {0, 1}100} wherezi(k) = 1 corresponds to recommending the ith joke in user cluster z(k) ∈ Z. Figure 7 shows thesame style plot as Figures 4,6 but for this jokes dataset, with our policy alone nearly achieving ther-dependent baseline for all r. Mirroring the construction of the 20Q prior, we construct P by uni-formly sampling a user and employing their θ to answer queries. Table 2 shows that despite ourpolicy not being trained for this setting, its performance is still among the top.
Figure 9: Full scale of Figure 3Figure 8: Full scale of Figure 217Under review as a conference paper at ICLR 202120	40	60	80	100	120rFigure 10: Full scale of Figure 4----π (Ours)----SGBS, various β----Uncertainty----Uniform----r-dependent baseline----LALOooooooo7 6 5 4 3 2 1≡6) ∙z HgIQrd-S (四」0」」山0.5	0.6	0.7	0.8	0.9	1.0hFigure 11: Full scale of Figure 518
Figure 8: Full scale of Figure 217Under review as a conference paper at ICLR 202120	40	60	80	100	120rFigure 10: Full scale of Figure 4----π (Ours)----SGBS, various β----Uncertainty----Uniform----r-dependent baseline----LALOooooooo7 6 5 4 3 2 1≡6) ∙z HgIQrd-S (四」0」」山0.5	0.6	0.7	0.8	0.9	1.0hFigure 11: Full scale of Figure 518Under review as a conference paper at ICLR 2021
Figure 10: Full scale of Figure 4----π (Ours)----SGBS, various β----Uncertainty----Uniform----r-dependent baseline----LALOooooooo7 6 5 4 3 2 1≡6) ∙z HgIQrd-S (四」0」」山0.5	0.6	0.7	0.8	0.9	1.0hFigure 11: Full scale of Figure 518Under review as a conference paper at ICLR 2021----π (Ours)----SGBS, various β----Uncertainty----Uniformr-dependent baseline
Figure 11: Full scale of Figure 518Under review as a conference paper at ICLR 2021----π (Ours)----SGBS, various β----Uncertainty----Uniformr-dependent baselineLAL15	20	25	30rFigure 12: Full scale of Figure 6JMSS忌E<nie)∙z) dns 旬」6 3工Jl76----π (Ours)----SGBS, various β----Uncertainty
Figure 12: Full scale of Figure 6JMSS忌E<nie)∙z) dns 旬」6 3工Jl76----π (Ours)----SGBS, various β----Uncertainty----Uniform----r-dependent baseline----LAL20	40	60	80	100	120Figure 13: Full scale of Figure 719Under review as a conference paper at ICLR 2021G	Uncertainty SamplingWe define the symmetric difference of a set of binary vectors, SymDiff({z1, ..., zn}) = {i : ∃j, k ∈[n] s.t., zj(i) = 1 ∧ zk(i) = 0}, as the dimensions where inconsistencies exist.
Figure 13: Full scale of Figure 719Under review as a conference paper at ICLR 2021G	Uncertainty SamplingWe define the symmetric difference of a set of binary vectors, SymDiff({z1, ..., zn}) = {i : ∃j, k ∈[n] s.t., zj(i) = 1 ∧ zk(i) = 0}, as the dimensions where inconsistencies exist.
