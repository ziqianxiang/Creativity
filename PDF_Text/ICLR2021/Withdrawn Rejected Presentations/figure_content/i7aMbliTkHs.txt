Figure 1: Temporal module comparison: The standard temporal convolution shares weightsamong videos and may lack the flexibility to handle video variations due to the diversity of videos.
Figure 2: The overall architecture of TANet: ResNet-Block vs. TA-Block. The whole workflowof temporal adaptive module (TAM) in the lower right shows how it works. The shape of tensor hasnoted after each step.㊉ denotes element-wise addition, Θ denotes element-wise multiplication, and0 denotes convolution operator. The symbols appeared in figure will be explained in Sec. 3.1FCthat aggregates the spatial information. Our proposed temporal adaptive module is established basedon this squeezed 1D temporal signal for a high efficiency.
Figure 3: The four styles of TA-Block. The (b) is actually the model we used in the main text.
Figure 4: The statistics of kernel weights training on Kinetics-400, which plots the distributions indifferent temporal offsets (t ∈ {-1, 0, 1}). Each filled area in violinplot represents the entire datarange, where has noted the minimum, the median and the maximum. The first four columns in theleft figure are the distributions of learned kernels in TANet. In the fifth column, we also visualizethe filters of 3 X 1 X 1 kernel in ED3×1×1 to compare with the TANet. The Stage4_6b denotes thekernel comes from the 6th block in stage4.
Figure 7: The visualization for the videos which contain small magnitude of motion. The mov-ing persons appeared in videos are usually far away from camera. Video clips are sampled fromvalidation set of Kinetics-400, and kernel Θ is selected from Stage4_6b.
Figure 8: The visualization for the videos with large magnitude of motion. The moving persons invideos are usually closed to camera. Video clips are sampled from validation set of Kinetics-400,and kernel Θ is selected from Stage4_6b.
