Figure 1: Position encoding learned from daily-grain event indicatorsIn this section we focus on our novel attention blocks and position encodings; the reader is directedto Appendix B for the other architecture details.
Figure 2: Martingale diagnostic process {Vt} averaged over all weeks in test period (2018-2019)Time	Lead TimeFigure 3: Forecast evolution analysis on the retail dataset. Left: Martingale Diagnostic Process{Vt}. Right: QL by lead time, averaged over target dates from 2016-03-01 through 2016-05-01; QLtrajectories are centered around 0.
Figure 3: Forecast evolution analysis on the retail dataset. Left: Martingale Diagnostic Process{Vt}. Right: QL by lead time, averaged over target dates from 2016-03-01 through 2016-05-01; QLtrajectories are centered around 0.
Figure 4: MQTransformer architecture with learned global/local positional encoding, horizon-specificdecoder-encoder attention, and decoder self-attention13Under review as a conference paper at ICLR 2021C Large S cale Demand Forecasting ExperimentsC.1 Experiment SetupIn this section we describe the details of the model architecture and training procedure used in theexperiments on the large-scale demand forecasting application.
