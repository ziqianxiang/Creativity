Figure 1: SRF filters based on N-jet filter approximation. Convolutional filters are defined asthe weighted sum of Gaussian derivative basis functions up to order 2, with corresponding scalesσ1 = 2.28 (left) and σ2 = 0.90 (right). Our DCN models learn both the coefficients α, and thescale σ end-to-end during training.
Figure 2: DCN model ar-chitecture with CIFAR-103 Experimental analysisinput images. Downsam-pling is performed viaconvolutions with stride 2.
Figure 3: (a) Learned σ values increase with depth within the network. (b) σji distributions withinthe ODE blocks display a positive skew in line with biological observations. (c) CIFAR-10 valida-tion accuracies on the pattern completion task with increasing mask size.
Figure 4: (a) Pattern completion in the DCN feature maps for an example image. Feature maps areshown for a single channel in ODE block 1. We find that the difference D(t) between the featuremaps him(t) of an intact image and him^αsked(t) of a masked image is reduced as t → T. Wealso show the mean D(t) for 1000 validation images (bottom right), where the shaded area is thestandard deviation over different images. Example feature maps from other models are provided inAppendix A.5. (b) Top: In terms of CIFAR-10 validation performance, DCNs are more robust thanbaseline ODE-Nets to changes in input contrast c at test time. Interestingly, the number of functionevaluations (NFEs) in the first ODE block (middle) or the whole DCN network (bottom) can bereduced considerably by modulating c.
Figure 5: Example CIFAR-10 validation images and their reconstruction by the DCN-ODE modelas compared to baseline models.
Figure 6: Feature map evolution within the first ODE block (or ResNet block) of different models.
Figure 7: Evolution of the mean difference D(t) between feature maps of an intact input image anda masked input image, averaged over 1000 images in the CIFAR-10 validation set. The shaded areas(or in the case of ResNet, the errorbars) show the standard deviation.
