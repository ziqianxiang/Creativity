Figure 1: Tool synthesis for a reaching task. Our model is trained on data-triplets{task observation,tool observation, success indicator}. Within a scenario, the goal is to determine if a given tool canreach the goal (green) while avoiding barriers (blue) and remaining behind the boundary (red). Ifa tool cannot satisfy these constraints, our approach (via the performance predictor)imagineshowone may augment it in order to solve the task. Our interest is in what these augmentations, imaginedduringtool synthesis, imply about the learned object representations.
Figure 2: The model architecture. A convolutional encoderφrepresents the task imageI G as alatent vectorz G . In parallel, the 3D tool encoderψtakes an input imageI Ti and its silhouetteI Siand produces a latent representation ZT. The concatenated task-tool representation hCat is used bya classifierσto estimate the success of the tool at solving the task (i.e. reaching the goal). Giventhe gradient signal from this performance predictor for success, the latent tool representationz Tgets updated to render an increasingly suitable tool (via the 3D tool decoderψ ). We pretrained theencoding and decoding models (ψ,ψ ) together as in prior work (Kato et al., 2018; Wang et al.,2018).
Figure 3: (Left) Task examples from our dataset. Top and bottom rows correspond to unsuccessfuland successful tool examples respectively. ColumnsA-Erepresentfive different task scenario typeseach imposing different tool constraints including width, length, orientation and shape. Note that therobot isfixed at its base on the table and constrained to remain outside the red boundary. Hence, itcan only reach the green target with a tool while avoiding collisions with the blue obstacles. (Right)Model inputs{task observation, tool observation}during training and test time.
Figure 4: Qualitative results of tool evolution during the imagination process. Each row illustratesan example of how the imagination procedure can succeed at constructing tools that solve the taskby: (left) increasing tool length, (middle) decreasing tool width, and (right) altering tool shape(creating an appropriately oriented hook). Each row in each grid represents a different imaginationexperiment.
Figure 5: Examples of tool synthesis progression during the imagination process. In the top row,a stick tool morphs into a hook. The middle row shows a left-facing hook transforming into aright-facing hook. In the bottom row, the tool changes into a novel T-shape. Constraints on theseoptimisations are specified via task embeddings corresponding to the task images on the far left.
