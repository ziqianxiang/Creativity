Figure 1: Images from the CIFAR-10 dataset labelled ”horse” and ”cat”, respectively.
Figure 2: Most- (left) and least robust samples in x labelled ”airplane”, ”ship”, ”bird”, ”deer”.
Figure 3: Relative distribution of shares for all training- and test(sub)sets.
Figure 4: Relative class-wise sample robustness distribution for x and t.
Figure 5: Most- (upper row) and least robust samples (lower row) in the CIFAR-10 training set.
Figure 6: Epoch-wise learning behaviour of a small CNN trained on the CIFAR-10 training set xapproximately expressing the loss in Table 2.
Figure 7: Epoch-wise learning behaviour of a small CNN trained on the CIFAR-10 training set xapproximately expressing the accuracy in Table 2.
Figure 8: KNN for CIFAR-10, split for each test(sub)set. The colour of the graph corresponds to thereference training set.
Figure 9: Relative robustness distributions for x and t. The green dashed line marks the 65%threshold. For x, 1272 samples are below this robustness level (≈ 4%); for t, 267 (≈ 3.5%).
Figure 10: KNN LOSS and ACC for ONP, split for each test(sub)set. The colour of the graphcorresponds to the reference set.
Figure 11: RF LOSS and ACC for ONP, split for each test(sub)set. The colour of the graph corre-sponds to the reference training set.
Figure 12:	Most- (upper row) and least robust (lower row) samples of each label in the MNISTtraining set (”0” - ”9” from left to right).
Figure 13:	Robust samples of ”handwritten digits” labelled as the number in the brackets.
