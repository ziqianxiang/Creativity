Figure 1: The diagram shows the difference of three learning paradigms in terms of how gradientsare utilized for the training, i.e., (a) regular gradient based learning; (b) Meta-learning with multiplelearning targets; (c) Proposed: learning the weights of each label (ya , yb , yc) in meta-training andthen computing the weighted summation (y) of labels for computing the final loss with prediction y.
Figure 2: Overview of the proposed attention-on-label learning framework.
Figure 3: Confusion matrices of noisy labels from 5 different types of simulated annotators.
Figure 4: Confusion matrices of noisy labels from 5 different types of simulated annotators.
Figure 5: Classification accuracy using different label sets and methods over a range of noise-levels.
Figure 6: Classification accuracy using different number of label sets at noise-level 10%, 30%, and50%.
