Figure 1: Classification architecture. Style (y) and noise (η) variables are used to generate images g(y, η) whichare fed to the classifier F. Adversarial style and noise tensors are initialized with y and η and iteratively updatedusing gradients of the loss function J.
Figure 2: Semantic segmentation architecture. Adversarial parameters γadv and βadv are initialized with γ and β,and iteratively updated to fool the segmentation model G.
Figure 3: Unrestricted adversarial examples on LSUN for a) non-targeted and b) targeted attacks. Predicted classesare shown under each image.
Figure 4: Unrestricted adversarial examples on CelebA-HQ gender classification. From top to bottom: original,noise-based and style-based adversarial images. Males are classified as females and vice versa.
Figure 5: Input-conditioned adversarial examples on CelebA-HQ gender classification. From top to bottom: input,generated and style-based images. Males are classified as females and vice versa.
Figure 6: Unrestricted adversarial examples for semantic segmentation. Generated images, corresponding Predic-tions and their accuracy (ratio of correctly predicted pixels) are shown for different number of iterations.
Figure 7: t-SNE plot comparing distributions of real images with adversarial examples from our approach andSong et al.
Figure 10: Impact of manipulating different layers of the network on generated adversarial images.
Figure 11: Unrestricted adversarial examples for semantic segmentation. Generated images, corresponding pre-dictions and their accuracy (ratio of correctly predicted pixels) are shown for different number of iterations.
Figure 12: Unrestricted adversarial examples on CelebA-HQ gender classification. From top to bottom: Original,noise-based and style-based adversarial images. Males are classified as females and vice versa.
Figure 13: Unrestricted adversarial examples on LSUN for a) non-targeted and b) targeted attacks. From top tobottom: original, noise-based and style-based images.
Figure 14: High resolution versions of adversarial images. From left to right: original, noise-based and style-basedimages.
Figure 14: (Cont.) High resolution versions of adversarial examples. From left to right: original, noise-based andstyle-based images.
