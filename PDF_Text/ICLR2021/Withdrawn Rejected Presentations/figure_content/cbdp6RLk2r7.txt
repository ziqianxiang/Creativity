Figure 1: Failure modes of common disentanglement approaches. A. Latent traversal best cap-turing rotation for a VAE, β-VAE, and CCI-VAE for rotated MNIST restricted to a single digit class(”4”). B. Same as panel A for all 10 MNIST classes. C. Variance of single latents in response toimage rotation, averaged over many test images. D. Ranked eigenvalues of the latent covariance ma-trix in response to image rotation, averaged over many test images. E. A supervised disentanglingmodel successfully reconstructs some digits (top) but fails on other examples (bottom). F. Failurecases of the supervised model trained on a dataset of 2000 rotated shapes (see also Fig. 8).
Figure 2: Visual proof of the topological defects of disentanglement. A. Top left: O1 , O2 and O3are three examples of orbits of 3-pixel-images transformed by translation. Bottom: (left) orbits visu-alized in image space (points constitute the orbits, continuous lines are for visualization purposes);(right) orbits in latent space. When projected onto the equivariant subspace ZE (gray dotted lines),all orbits should collapse onto each other. Yet the orbit of a uniformly black image (red dot) con-tains a single point and thus cannot be mapped onto the other orbits. B. Discontinuity of fE aroundsymmetric images. Top: consider an image of an equilateral triangle, with an infinitesimal pertur-bation on one corner (black dot), undergoing rotation (color changes are for visualisation purposes).
Figure 3: Success and flexibility of proposed distributed shift operator models: A. Proposedshift operator model successfully learns rotation on simple shapes. B. Disentangled operator failsto learn rotation. C. Weakly supervised shift operator model, using the complex version of theshift operator, successfully rotates simple shapes. Note that the model maps ground-truth counterclockwise rotations to clockwise rotations, while respecting the cyclic structure of the group. D.
Figure 4: Visual proof that the invariant part of the encoder fI cannot be differentiable about sym-metric figures. We assume fI is differentiable and show a contradiction. We consider an equilateraltriangle which is perturbed at its top corner, left corner, or both corners. When perturbed either oneof its corner, the perturbation brings the image to the same orbit, because of the symmetry. In latentspace, the perturbation should thus move the latent representation in the same direction. The pertur-bation along the two corners simultaneously brings to image to a different orbit, and yet, since theperturbation is a simple linear combination of the single-corner perturbations, it can only be colinearto these perturbations. This collinearity leads to the encoder not being injective, and thus loosinginformation about the identity of the image.
Figure 5: Single Rotated MNIST Digit Label: Latent traversals for VAE (left), β-VAE (middle),CCI-VAE (right) trained on a single rotated MNIST digit (10 rotations). Latent traversal spans therange [-6, 6] for each latent dimension.
Figure 6: Rotated MNIST: Latent traversals for VAE (left), β-VAE (middle), CCI-VAE (right)trained on all rotated MNIST digits (10 rotations). Latent traversal spans the range [-6, 6] foreach latent dimension. Note in this case, the best validation model for VAE contained 30 latentdimensions whereas β-VAE and CCI-VAE contain 10.
Figure 8: Non-linear disentangled operator with latent rotations(b) Supervised disentangled operator on RotatedMNIST (10 rotations).
Figure 9:	Single MNIST Digit Label Translated along X-Axis: Latent traversals for VAE (left),β-VAE (middle), CCI-VAE (right) trained on a single MNIST digit translated along the x-axis (10translations). Latent traversal spans the range [-6, 6] for each latent dimension.
Figure 10:	Single MNIST Digit Label Translated along Y-Axis: Latent traversals for VAE (left),β-VAE (middle), CCI-VAE (right) trained on a single MNIST digit translated along the y-axis (10translations). Latent traversal spans the range [-6, 6] for each latent dimension.
Figure 11: MNIST Translated along X-Axis: Latent traversals for VAE (left), β-VAE (middle),CCI-VAE (right) trained on all MNIST digits translated along the x-axis (10 translations). Latenttraversal spans the range [-6, 6] for each latent dimension.
Figure 12:	MNIST Translated along Y-Axis: Latent traversals for VAE (left), β-VAE (middle),CCI-VAE (right) trained on all MNIST digits translated along the y-axis (10 translations). Latenttraversal spans the range [-6, 6] for each latent dimension.
Figure 13:	Non-linear disentangled operator with latent translations43Under review as a conference paper at ICLR 2021270o 270o O0 180o 180o 90o 270o 90o 270o 270o 90oOriginal 12,18 12,18 12,12 6,18 18,0 12,24 12,12 24,6 12,18 6,6 12,12QnnHHiiHffianKK90o 270o 180o Oo O0 270o 180o 270o 90o 180o 270oOriginal 0,0 0,12 24,12 6,24 24,0 6,0 18,24 0,24 24,12 12,24 6,12HBNHHaDBBHHH270o	270o	90o	90o	O0	O0	O0	90o	90o	180o	O0Original 24,24	12,18	24,24	0,24	18,24	18,24	12,24	12,24	6,12	18,0	6,24ΞaκaΞ≡≡κ≡H≡E180o	90o	90o	180o	O0	90o	270o	180o	90o	90o	O0original 6,12	6,12	6,6	24,24	24,18	12,0	0,0	6,0	0,18	6,24	0,0ΠHIEΠHBHBiBBU(a)	Weakly supervised shift operator on RotatedMNIST (10 rotations).
Figure 14: MNIST additional experiments.
Figure 15: Simple shapes additional experiments.
Figure 16: Supervised shift operator on Rotated-Translated simple shapes when the semi-directproduct structure is not respected as rotations angles are j ∏, j = 1,... 5 (5 rotations, 5 X-translations and 5 y-translations).
Figure 17: Pairs of test samples and their reconstructions for the stacked shift model with 5^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^translations in both x and y.
Figure 18: Pairs of test samples and their reconstructions for the stacked shift model with 4 rotations^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^and 5 translations in both x and y.
