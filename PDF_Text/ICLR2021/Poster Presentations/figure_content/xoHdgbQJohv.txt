Figure 1: Visualizing the need for a multiscale analysis. In (a), we plot the scores corresponding tothe lowest sigma estimate. In (b), we plot the UMAP embedding of the L = 10 dimensional vectorsof score norms. Here we see a better separation between FashionMNIST and MNIST when usingestimates from multiple scales rather than the one that corresponds to the true score only.
Figure 2: A toy GMM to visualize our analysis. We annotate the three regions of interest we will beexploring. Further, we show the Gaussian perturbed versions of the original distribution with (L)ow,(M)edium, and (H)igh noise levels, along with a plot zoomed into the local-mode outliers. Note theeffect of different scales on this region: only the largest scale results in a gradient in the direction ofthe inliers.
Figure 3: In (a) observe that Low-Density outliers have comparatively high gradient norms for bothσL and σM . However at this scale, Local-Mode points still have very small norms, causing them tobe tightly packed around the in-distribution points. In (b) we see that Local-Mode outliers achieve agradient signal only when a sufficiently high scale is used, σH = 20.
Figure 4: Note the change in image contrast, brain size and brain matter structure as the child grows.
Figure 5: Analysis of the effect of hyperparameters σH and L on MSMA’s out-of-distribution detec-tion performance. We observe that the defaults σ = 1.0 and L = 10 perform the best, with a slightvariance in performance when we deviate from them.
