Figure 1: Accuracy on CIFAR-10 when the training data is non-stationaryover the first 1000 epochs (dashed line). The remaining epochs are trainedon the full, unaltered training data. Testing is performed on unaltered datathroughout. While final training performance (left) is almost unaffected, testaccuracy (right) is significantly reduced by initial, transient non-stationarity.
Figure 2: Evaluation on Multiroom and Boxoban. Shown are mean and standard error over twelve seeds. Left:Return for PPO with and without ITER on Multiroom. Dotted lines indicate when the network was replaced bya new student. Middle: Evaluation on layouts with a fixed number of rooms; training is still with a randomnumber of rooms. ITER’s advantage is more pronounced for harder levels. Right: Return on Boxoban.
Figure 3: Evaluation on ProcGen. Dashed lines indicate replacing the teacher. Left: Test performance averagedover six environments (StarPilot, Dodgeball, Climber, Ninja, Fruitbot and BigFish). Shown are mean andstandard error over all 30 runs (five per environment). Results are normalised by the final test-performance of theppo baseline on each respective environment to make them comparable. We also compare against the previousstate of the art method IBAC-SNI (Igl et al., 2019). Middle: Evaluation on Climber. ITER improves testperformance without improving training, supporting our claim that iter improves the latent representation of theagent. Right: Evaluation on BigFish. On some environments, ITER improves both train- and test- performance.
Figure 4:	Left: Ablation studies with sequential ITER and ITER without terms LPG and LTD (eq. (3)).
Figure 5:	Left: Test accuracy of students (solid lines) that only learn to mimic the behaviour of poorlygeneralising teachers in fig. 1 (dashed lines). Middle: Final test accuracy of networks trained consecutively ontwo different datasets. The x-axis shows the accuracy of using encoders trained on the first dataset, retrainingonly the last layer on the second: nearly useless earlier representations impact future learning much less thanslightly sub-optimal ones. Markers indicate modifications to first dataset; colours indicate the fraction ofunmodified data points f. Dashed line shows accuracy for f = 1. Right: Singular values of feature matrix Φ,normalised by the largest SV. Solid lines show intermediate values of f with low test accuracy, dashed linessmall values of f with higher accuracy. More plots can be found in the appendix.
Figure 6: Left: Same results as in fig. 5 (middle), but with the fraction of correct data points f on the x-Axis.
Figure 7: Individual training curves for the data used in fig. 5(middle) and fig. 6. The bottom row shows thesame data as the top row, just ‘zoomed in’.
Figure 8: Left: Boxoban example layout. The green agent needs to push (or pull) yellow boxes on the red targets,avoiding walls. Right: Additional Boxoban results showing consequences of choosing a wrong distillationlength, either too short or too long. Note that ITER Too short uses the same distillating length as the resultsin fig. 2, but continues with distillation past 0.5e9 steps.
Figure 9: All individual results on ProcGen. Shown is the mean and standard deviation across two randomseeds.
