Figure 1: Interactive Weak Supervision (IWS) helps experts discover good labeling functions (LFs).
Figure 2: Test set AUC of end classifiers vs. number of iterations. IWS-LSE is compared to activelearning, Snuba, and to using all training ground truth labels. Note that one iteration in this plotcorresponds to one expert label. A comparison of true user effort needed to answer each type of query(label for one sample vs. label for one LF) will vary by application.
Figure 3: Human user study, text data. Top: Test AUC of end classifiers trained on soft labelsobtained via IWS-AS. Test set performance of humans closely tracks performance using a simulatedoracle after 〜100 iterations. Bottom: scatter plots of human responses to queries showing the true LFaccuracy vs LF coverage by one user (lower left) and all users (lower middle and lower right). An‘unsure’ response does not provide a label to an LF query but is counted as an annotation.
Figure 4: COCO image classification. Images (1) and (2): Test AUC of image classifiers trainedusing probabilistic labels obtained from LFs on captions, compared to training with active learningand the full training ground truth. Images (3) and (4): Test AUC of image classifiers trained usingnearest neighbor based image LFs compared to training with active learning and the full trainingground truth. Due to the low coverage of LFs, we only use IWS-LSE-a in our image experiments.
Figure 5: Human user study, image data (Section B.1). The user experiments in this plot were doneusing a labeling function family defined directly on the images. Left: Test AUC of end classifierstrained on soft labels obtained via IWS-LSE-a. Test set performance of humans closely tracksperformance using a simulated oracle after 〜100 iterations on these datasets. Right: scatter plotsshowing the true LF accuracy vs LF coverage of responses to queries by one user.
Figure 6: Mean test set AUC vs. number of iterations for end classifiers trained on probabilistic labels.
Figure 7: An example of the prompt and answer options that users were shown during the user study.
Figure 8: Test AUC vs. IWS iteration shown for individual user experiments with IWS-AS (top).
Figure 9: IWS-LSE ablation plots for varying thresholds r which we use to partition our set of LFs.
Figure 10: IWS-LSE-ac ablation plots for varying final sizes via parameter m. Recall that We boundthe size of the final set of LFs at each iteration t by m = Pi-1 Ui + m, i.e. the number of LFs so farannotated as U = 1 plus a constant m. Note that the LSE-ac setting takes LF coverage into account to1 ɪ -I—'	1 ∙	, /rʌ	-1 ∖ T~ 1	T~	,1	, ∙	, 1 ɪ 1-1	FK	FTrTrIrank LFs according to (2ɑj - 1) * j where aj,j are the estimated LF accuracy and observed LFcoverage.
