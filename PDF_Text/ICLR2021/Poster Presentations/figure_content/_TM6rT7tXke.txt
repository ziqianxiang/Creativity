Figure 1: The network structure of RCRL for Atari (left) and DMControl Suite (right).
Figure 2: Scores achieved by RCRL and other baseline algorithms during the training for differ-ent tasks in DMControl suite. The line and the shaded area indicate the average and the standarddeviation over 5 random seeds respectively.
Figure 3: Analysis of the learned representation on Alien. (a) The cosine similarity between the rep-resentations of the positive/negative state-action pair and the anchor during the training of Rainbowand RCRL. (b) The scores of the two algorithms during the training.
Figure 4: Analysis of the learned representation on Alien with five seeds. (a) The cosine similar-ity between the representations of the positive/negative state-action pair and the anchor during thetraining of Rainbow and RCRL. (b) The game scores of the two algorithms during the training.
