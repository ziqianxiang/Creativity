Figure 1: Images change at different rates along top vs bottom eigenvectors. Each panel (A-D)shows perturbations around a randomly chosen reference image (center column); each row showsperturbations introduced by moving along each of five eigenvectors; each contiguous column isseparated by the same distance in latent space. Eigenvectors are shown in descending order of theireigenvalues. Line plots under each montage show the LPIPS image distance to the reference imageas a function of positively and negatively perturbed distance along each eigenvector (x-axis). Therate of image change differed across eigenvectors; top vs bottom eigenvectors encoded changes suchas object class, head direction, pose, color, shading or other subtle details (e.g. fur variations in panelA, bottom). Eigenvector rank and associated eigenvalue labeled in the legend.
Figure 2: Spectra of GANs, shown as a function of individual model (A) and types of architecture(B, C). DCGAN-type (green-blue), Z and W space for StyleGAN (SG1, 2) (red, orange). Linesand shaded areas show the averaged spectra and the 5-95% percentile of each eigenvalue amongsamples (for quantification, see Table 2). D. Histogram of approximate speed of image change α(v)for eigenvectors and random directions, visualizing the ”illusion of isotropy”.
Figure 3:	Globalization of metric structure: A. Schematic of the geometric picture. In the latentspace (green area), the metric eigen frames at each point (blue and violet) are mapped to transfor-mations in image space (blue area); the length and saturation of image-space vectors represent theeigenvalue (i.e. amplification factor) of G. We show that the top eigen space are relatively alignedat different positions. B. Distributions of log(Λij) and log(Λj ), showing the action of metric arecorrelated at 3 different points. C. Histogram of correlation CiHj log between all pairs among 1000points in BigGAN space. D. Comparison of correlation values on linear and log scales for differentGAN models. DCGAN-type (blue), Z and W space for StyleGAN1,2 (red and orange).
Figure 4:	Anisotropy is induced and maintained throughout the GAN architecture. A. As latentspace gets warped and mapped into image space, directions in latent spaces are scaled differently bythe Jacobian of the map. B. Amplification of eigenvectors of the metric tensor of the first conv layer(GenBlock00) in all major layers in BigGAN. C. Same, but for weight-shuffled BigGAN.
Figure 5: Applications of the metric tensor A. Perceptual properties of eigenvectors. Wordcloud shows subjects’ descriptions (N = 24) of the image transforms induced by the top- (red) vs. thebottom eigenvector (black) in StyleGAN2-Face. B. Distribution of difficulty scores associated withtop- vs. bottom eigenvectors (red, black) across all four GANs for N=185 subjects. Lines show meanfrequency ± standard error (per bootstrap). C-E. Eigenbasis pre-conditioning improves GANinversion. C. BasinCMA with eigenbasis pre-conditioning (Hess,H) outperformed a method usingnormal basis (None,N) in inverting ImageNet and BigGAN generated images; D. Examples of fittedImageNet and BigGAN images with our Hessian BasinCMA and original method (LPIPS distancebelow). E. Results for PGGAN and StyleGAN2 inverting samples from CelebA and FFHQ. F.
Figure 6: Spectral Histogram compared to Apparent Anistropy in Different GAN models(FC6GAN, DCGAN, BigGAN, BigBiGAN, PGGAN, StyleGAN, StyleGAN2) The apparent speedof image change α(v) has much smaller variability than the variability in the whole spectra. Eq. 13can predict the mean and std of the apparent variability.
Figure 7: Comparing Spectra of Original and Weight Shuffled GANs: Most Shuffled GANshows a slower spectral decay and a smaller maximum eigenvalue.
Figure 8: Analyzing interpretable axes from (Voynov & Babenko, 2020) under the Hessianframework. A. Projection power of their annotated interpretable axes and 6 unit norm randomvectors on the top 40 eigen vectors. The color code is matched. The red line on colorbar denotesp < 1 × 10-4 threshold for the power value, and the significantly aligned axes p < 5 × 10-4 areindicated. B,C, Image transforms encoded by projection of 2 of their vectors (19, 20) into the top60d eigenspace. D,E Similar to B,C, but their vectors are projected onto the aligned eigenvectorsonly. The norms of the projected vectors are noted on title. Panel B,D and C,E share the samereference image and the same step size across each mini column, though the distance travelled alongBC and DE is smaller as the vector is shortened.
Figure 9:	Analyzing interpretable axes from (Peebles et al., 2020) under the Hessian frame-work. A. Projection power of Hessian-penalty-identified axes on the top 25 eigen vectors. B,C.
Figure 10:	Similar transforms encoded in the top eigendimension of GANs trained on facedataset. Linear exploration along top 20 eigenvectors from origin in latent space are showed for eachGAN. Linear equi-distance sampling on each eigenvector occupies a column and their eigenvaluesare sorted in descending order from left to right. Step size along each vector is adjusted accordingto its eigenvalue for best continuity.
Figure 11: Top eigenvectors encode similar transforms around different reference images. Lin-ear equidistant explorations from six randomly chosen reference images along the eigenvectors ofaveraged Hessians. These show qualitatively similar transforms to images — for example, proxim-ity of Cat face (Eig1), proximity and cat number (Eig4), fur color darkening (Eig10) in StyleGAN2Cat; face direction (Eig1), masculine vs feminine (Eig3), child vs adult (Eig5) in StyleGAN Face.
