Figure 1: Test Risk vs. Num. Samplesfor Isotropic Ridge Regression in d =500 dimensions. Unregularized regressionis non-monotonic in samples, but optimally-regularized regression (λ = λopt) is mono-tonic. In this setting, the optimal regularizerλopt does not depend on number of samplesn (Lemma 2), but this is not always true - seeFigure 2.
Figure 2: Test Risk vs. Num. Samplesfor Non-Isotropic Ridge Regression ind = 30 dimensions. Unregularized re-gression is non-monotonic in samples,but optimally-regularized regression ismonotonic. Note the optimal regulariza-tion λ depends on the number of samplesn.
Figure 3: Test Error vs. Model Size for 5-layer CNNs onCIFAR-100, with `2 regularization (weight decay). Notethat the optimal regularization λ varies with n.
Figure 4: Double-descent for Random ReLU Features. Test classification error as a function ofmodel size and sample size for Random ReLU Features on Fashion-MNIST. Left: with D = 500features. Right: with n = 500 samples. See Figures 7, 8 for the corresponding test Mean SquaredError. See Appendix D of Nakkiran et al. (2020) for the performance of these unregularized modelsplotted across Num. Samples × Model Size simultaneously.
Figure 5: Train Error vs. Model Size for 5-layer CNNs on CIFAR-100, with `2 regularization(weight decay).
Figure 6: Train MSE vs. Num. Samples for Non-Isotropic Ridge Regression in d = 30 dimensions,in the setting of Figure 2. Plotting train MSE: 1 ∣∣Xβ - ~||2.
Figure 7: Test Mean Squared Error vs. Num Train Samples for Random ReLU Features on Fashion-MNIST, with D = 500 features.
Figure 8: Test Mean Squared Error vs. Num Features for Random ReLU Features on Fashion-MNIST, with n = 500 samples.
