Figure 1: Car trajectories in two scenes. Thoughthe entire scenes are not related by a rotation, thecircled areas are. ecco exploits this symmetry toimprove generalization and sample efficiency.
Figure 2: Overview of model architecture. Past velocities are aggregated by an encoder Enc. To-gether with map information this is then encoded by 3 CtsConvs into Preg features. Then l + 1CtsConv layers are used to predict ∆X. The predicted position Xt+1 = ∆x + X where X is a numer-ically extrapolated using velocity and accleration. Since ∆X is translation invariant, X is equivariant.
Figure 3: Left: A torus kernel field K from a ρreg-field to a ρreg-field. The kernel is itself a field:at each point x in space the kernel K(x) yields a different matrix. We denote the (φ2, φ1) entry ofthe matrix at x = (θ, r) by K(θ, r)(φ2, φ1). The matrices along the red sector are freely trainable.
Figure 4: Experimentally, we find kθand expected equivariance error are in-versely proportional.
Figure 6: The x,y-axes are the position (m). The dashed line represents the 2s past trajectory. Thesolid line represents the 3s prediction. Red represents the agent. Top row: The predictions are madeon the original data. Bottom row: We rotate the whole scene by 160° and make predictions onrotated data. From left to right are visualizations of ground truth, CtsConv, PI-ECCO, Preg-ECCO.
Figure 5: The learning curves on the validationset. Equivariant models converge faster usingfewer samples than the non-equivariant models.
Figure 7: The above plot is generated from random input and kernels. We can clearly see thei	i	r r T-ΛT-Λ I ∙	∕Λ∖ Idependence of of EE on | sin(θ) |A.7 Data DetailsArgoverse dataset includes 324K samples, which are split into 206K training data, 39K validationand 78K test set. All the samples are real data extracted from Miami and Seattle, and the datasetprovides HD maps of lanes in each city. Every sample contains data for 5 seconds long, and issampled in 10Hz frequency.
Figure 8: The x,y-axes are the position (m). The dashed line represents the 2s past trajectory. Thesolid line represents the 3s prediction. Red represents the agent. Top row: The predictions are madeon the original data. Bottom row: We rotate the whole scene by 160° and make predictions onrotated data. From left to right are visualizations of ground truth, CtsConv, ρ1-ECCO, ρreg-ECCO.
