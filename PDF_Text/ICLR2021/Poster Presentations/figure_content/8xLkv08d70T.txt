Figure 1: APT-Gen learns to create tasks via a black-box procedural generation module. By jointlytraining the task generator, the task discriminator, and the policy, suitable tasks are progressivelygenerated to expedite reinforcement learning in hard-exploration problems.
Figure 2: Target tasks in the two domains.
Figure 3: Quantitative results of the performance of the agent in the target tasks.
Figure 5: Results of ablationstudy in Manipulation-C.
Figure 4: Results on task that isout of the predefined task space.
Figure 6: Progression of the generated tasks for various targettasks in the two task domains and the out-of-space task.
Figure 7: Examples of randomly generated tasks from the two task domains.
Figure 8: Network architectures for Grid-World.
Figure 9: Network architectures for Manipulation.
Figure 10: Network architecture of task discriminator.
Figure 11: Progression of the generated tasks for target tasks in Grid-World.
Figure 12: Progression of the generated tasks for target tasks in Manipulation.
Figure 13: Ablation on the minimum expected return.
