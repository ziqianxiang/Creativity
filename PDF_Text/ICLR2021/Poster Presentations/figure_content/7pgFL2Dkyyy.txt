Figure 1: Logits variances (two left plots) and the approximate loss landscape smoothness (right plot)measured during training for different models. From variances plots, one can observe the followingpicture: a linear model without NS (normalize+scale) and AN (attributes normalization) has divergingvariance, but adding NS+AN fixes this pushing the variance to 1. For a non-linear model, usingNS and AN on their own is not enough and the variance deteriorates, but class normalization (CN)rectifies it back to 1; see additional analysis in Appx E. On the right plot, the maximum gradientmagnitude over 10 batches at a given iteration for different classification models is presented. Asstated in 3.5, ZSL attribute embedders have more irregular loss surface than traditional models: largegradient norms indicate abrupt changes in the landscape. Class normalization makes it more smooth;see more analysis in Appx F.
Figure 2: Empirical validation of the derived approximation for variance (4)• Real data. We take ImageNet-pretrained ResNet101 features and real class attributes (unnormalized)for SUN, CUB, AwA1, AwA2 and aPY datasets. Then, we initialize a random 2-layer MLP with 512hidden units, and generate real logits (without scaling). Then we compute mean empirical varianceand the corresponding standard deviation over different batches of size 4096. The resulted boxplotsare presented on figure 2b.
Figure 3: Our architecture: a plain MLP with the standardization procedure (9) inserted before thefinal projection and output matrix V being initialized using (10).
Figure 4: Optimal value of seen logits scale s for different datasets. Multiplying seen logits by somescale s < 1 during evaluation leads to sacrificing GZSL-S for an increase in GZSL-U which results inthe increased GZSL-H value Xian et al. (2018a); Min et al. (2020). High gap between validation/testaccuracy is caused by having different number of classes in these two sets. Lower test GZSL-H thanreported in Table 2 is caused by splitting the train set into train/validation sets for the presented run,i.e. using less data for training: we allocated 50, 30, 5 and 5 seen classes for the validation unseenones to construct these plots for SUN, CUB, AwA1 and AwA2 respectively and an equal amount ofdata was devoted to being used as validation seen data, i.e. we “lost” ≈ 25% train data in total. Asone can see from these plots, the trick works for those datasets where the gap between GZSL-S andGZSL-U is large and does not give any benefit for CUB where seen and unseen logits are alreadywell-balanced.
Figure 5:	Variances plots for different models for SUN dataset. See Appendix E for the experimentaldetails.
Figure 6:	Variances plots for different models for CUB dataset. See Appendix E for the experimentaldetails.
Figure 7:	Variances plots for different models for AwA1 dataset. See Appendix E for the experimentaldetails.
Figure 8:	Variances plots for different models for AwA2 dataset. See Appendix E for the experimentaldetails.
Figure 9: Empirical validation of the more irregular loss surface of ZSL models and smoothing effectof class normalization on other datasets. Like in figure 1, we observe that the gradient norms fortraditional MLPs are much lower compared to a basic ZSL model, but class normalization partiallyremedies this problem.
Figure 10: Additional CZSL results for CUB dataset27.525.Q---EWC---MAS---A-GEM—SequentialEWC + oursMAS + oursA-GEM + oursSequential + oursPJSZ0-----Molti-Taslc — MUlti-TaSk + ours12.515.0-16-14-12-ɔS10.
Figure 11: Additional CZSL results for SUN dataset28Published as a conference paper at ICLR 2021As one can clearly see, adding class normalization significantly improves the results, at some timesteps evensurpussing the multi-task baseline without ClassNorm.
Figure 12: Results of the normality test for class attributes for real-world datasets. Higher valuesmean that the distribution is further away from a normal one. For a dataset of truly normal randomvariables, these values are usually in the range [0, 5]. As one can see from 12a, real-world distributionof attributes does not follow a normal one, thus requires more tackling and cannot be easily convertedto it.
Figure 13: Distribution of mean absolute correlation values between different attribute dimensions.
Figure 14: Histogram of standardized attribute values for SUN and AwA2. These figures demonstratethat the distribution is typically long-tailed and skewed, so it is far from being normal.
