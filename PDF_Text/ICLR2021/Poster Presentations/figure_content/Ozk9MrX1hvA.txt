Figure 1: Illustration of data augmentation combined with adversarial training.
Figure 2: Illustration of different strategies to combine various label-preserving transformations.
Figure 3: Illustration of the contrastive learn-ing module.
Figure 4: Hyperparameter exploration for the contrastive loss, evaluated on the MNLI-m develop-ment set. Note: All models use the RoBERTa-base model as the encoder.
Figure 5: Low-resource setting experiments on the MNLI (left) and QNLI (right) dev sets.
Figure 6: Evaluation of the proposed con-trastive objective while applied to differentdata augmentation approaches.
