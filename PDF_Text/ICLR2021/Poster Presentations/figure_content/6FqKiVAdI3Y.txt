Figure 1: A Decomposed critic.
Figure 2: Bias-variance trade-off of DOP on the didactic example. Left: gradient variance; Middle:Performance; Right: Average bias in Q estimations; Right-bottom: the element in ith row and jthcolumn is the local Q value learned by DOP for agent i taking action j .
Figure 3: Comparisons with baselines on the SMAC benchmark.
Figure 4: Comparisons with ablations on the SMAC benchmark.
Figure 5: Left and middle: performance comparisons with COMA and MAAC on MPE. Right: Thelearned credit assignment mechanism on task Mill by deterministic DOP.
Figure 6: A decomposed critic can solve many coordination problems which can not be solved byIQL.
Figure 7: A highly partial observable task. (a) Task hallway; (b) Performance of DOP with andwithout communication on hallway with m=n=4.
Figure 8: Using baselines where actions of all other agents are marginalized within a centralizedcritic is more efficient than COMA, but less efficient than a decomposed critic.
