Figure 1: Evaluating LeaSuRe against baselines on set cover instancesExact set cover(b)species. The goal is to train a policy to select the largest superset of these sets. We evaluate in twosettings: Exact Set Cover, where we collect tuples {(Sl, x), gexp} for training, and Noisy Set Cover,where we have access only to {(Sl , x), gexp}, where gexp is a noisy score. The networks are trainedon rollouts of length 20 (i.e. on sets {Sl : |Sl | ≤ 20}), and tested on rollout of length up to 100.
Figure 2: Combining submodular regularizationwith a learned active learning policy for 10-classFashion-MNIST classification. The figure sum-marizes the classification error of a neural net-work trained on labelled images, as a function ofthe number of labelled images. Originally, ran-dom set of 20 images is selected, and then eachpolicy greedily chooses the next image to label.
Figure 3: Combining submodular regularization with a learned active learning policy for a proteinengineering task. In (b), Lambda = 0 corresponds to the unregularized case. Error bars are plottedas standard error of the mean across 50 replicates.
Figure 4: Supplemental results: Set coverFor completion, we also provide our architecture and parameter choices for both set cover andLearning Active Learning (LAL) on MNIST experiments. For set cover, the problem is too simple torequire DAgger (Ross et al., 2011). Instead, the tuples are generated randomly. For active learningon MNIST, the tuples are indeed generated using Algorithm 1. For MNIST, we first preprocessedour dataset with PCA, leaving the number of vectors necessary to achieve 80% covariance on thetraining set (24 vectors). That was necessary to allow the comparison with DSF. For set cover, eachelement was a set v containing 23 elements v1 , v2, .., v23, where vi was an integer correspondingto the label of the species. As a neural network input, v was simply represented as a vector of[v1,...,v23].
Figure 5:	Score neural network architecture illustrationCombining element representation using DeepSetsV0Vι...
Figure 6:	Score neural network architecture illustration.
Figure 7: Supplemental results for the protein engineering experiments of Section 6.3: (a) We ob-serve that the policy learned by LeaSuRe preforms approximately as well as the greedy oraclewhich it emulates. In this experiment the policy was derived from the training set, but the greedyoracle is operating on the test set. (b) Lambda linearly scales the value of the regularizer term. Whenlambda takes value 0.01, the magnitude of the (scaled) regularizer term (represented by the blue bar)aligns the best with the magnitude of the cross entropy loss (represented by the orange bar). Thisis consistent with what we observed in Figure 3b where λ = 0.01 leads to well-regularized modelbehavior.
