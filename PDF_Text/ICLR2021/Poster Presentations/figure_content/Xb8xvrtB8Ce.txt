Figure 1: (a) Test accuracy w.r.t. different values of weight decay. The reported checkpointscorrespond to the best PGD-10 accuracy (Rice et al., 2020). We test on two model architectures, andhighlight (with red circles) three most commonly used weight decays in previous work; (b) Curvesof test accuracy w.r.t. training epochs, where the model is WRN-34-10. We set weight decay be1 × 10-4, 2 × 10-4, and 5 × 10-4, respectively. We can observe that smaller weight decay can learnfaster but also more tend to overfit w.r.t. the robust accuracy. In Fig. 4, we early decay the learningrate before the models overfitting, but weight decay of 5 × 10-4 still achieve better robustness.
Figure 2: Clean accuracy vs. PGD-10 accuracy for different model architectures. The circle sizesare proportional to the number of parameters that specified in Table 12.
Figure 3: Random normal cross-sections of the decision boundary for PGD-AT with different weightdecay. The model architecture is WRN-34-10. Following the examples in Moosavi-Dezfooli et al.
Figure 4: Curves of test accuracy w.r.t. training epochs, where the model is WRN-34-10. Here weearly decay the learning rate at 40 and 45 epochs for the cases of weight decay 1 × 10-4 and 2 × 10-4,just before they overfitting. We can see that the models can achieve the same clean accuracy as weightdecay 5 × 10-4, but still worse robustness.
Figure 5: Curves of test accuracy w.r.t. training epochs. The model architecture is WRN-34-10,and is standardly trained on CIFAR-10. We can observe that the final performance of each model iscomparable, which means that clean accuracy is less sensitive to different values of weight decay.
