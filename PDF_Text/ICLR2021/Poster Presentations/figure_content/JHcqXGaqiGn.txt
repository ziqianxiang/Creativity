Figure 1: Concepts (Left): Conceptual comparison of graph pooling methods. Grey box indicates the readoutlayer, which is compatible with our method. Also, green check icon indicates the model that can be as powerfulas the WL test. (Right): An illustration of set, multiset, and graph multiset encoding for graph representation.
Figure 2: Graph Multiset Transformer. Given a graph passed through several message passing layers, weuse an attention-based pooling block (GMPool) and a self-attention block (SelfAtt) to compress the nodes intofew important nodes and consider the interaction among them respectively, within a multiset framework.
Figure 3: Memory efficiency ofGMT compared with baselines.
Figure 4: Time efficiency ofGMT compared with baselines.
Figure 5: Reconstruction results of ring and gridsynthetic graphs, compared to node drop and clus-tering methods. See Figure 10 for high resolution.
Figure 6: Reconstruction results on the ZINC moleculedataset by varying the compression ratio. Solid lines de-note the mean, and shaded areas denote the variance.
Figure 7: Reconstruction examplewith assigned clusters as colors on leftand reconstructed molecules on right.
Figure 8: Validity curve for molecule generationon QM9 dataset from MolGAN. Solid lines denotethe mean and shaded areas denote the variance.
Figure 10: High resolution images for synthetic graph reconstruction results in Figure 5.
Figure 11: Molecule Reconstruction Examples (Left): Original molecules with the assigned clus-ter on each node represented as color, where cluster is generated from Graph Multiset Pooling (GM-Pool). (Right): Reconstructed molecules. Red dotted circle indicates the incorrect atom prediction.
