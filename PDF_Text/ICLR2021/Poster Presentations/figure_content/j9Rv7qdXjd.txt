Figure 1: Illustration of one WL iteration. Giventwo architecture cells at initialisation, WL kernelfirst collects the neighbourhood labels of each node(Step 1) and compress the collected h = 0 labels intoh = 1 features (Step 2). Each node is then relabelledwith h = 1 features (Step 3) and the two graphs arecompared based on the histogram on both h = 0 andh = 1 features (Step 4). This WL iteration will berepeated until h = H.
Figure 2: Motif discovery on N201 (CIFAR-10) and DARTS spaces.
Figure 3: Best cells discovered by (left to right) DARTS, ENAS, LaNet, BOGCN and NAS-BOWL(ours) in the DARTS search space. Note the dominance of separable convolutions (especially 3x3)in operation nodes (i.e. nodes excluding input, output and add) and the presence of highlightedstructures encompassing the boxed motif in Fig. 2 in all cells.
Figure 4:	Mean Spearman correlation achieved by various surrogates across 20 trials on differentdatasets. Error bars denote ±1 standard error. The red dashed lines are there to help with visualcomparison between the performance of GPWL and other baselines.
Figure 5:	Median test error on NAS-Bench datasets with deterministic (top row) and noisy (bottomrow) observations from 20 trials. Shades denote ±1 standard error and black dotted lines are ground-truth optima. Note the seemingly large regret in N201 (ImageNet) is due to that there are only 5 outof 15.6K architectures with test error in the interval of [52.69 (optimum), 53.25].
Figure 6: Predictive vs ground-truth validation error of GPWL with additive kernel on N101 andFlower-102 in log-log scale. Error bar denotes ±1 SD from the GP posterior predictive distribution.
Figure 7: Motif discovery on N101 and CIFAR-100 and ImageNet tasks of N201. Note that sinceN101 is trained on CIFAR-10 only, it is not possible to show the results transferred on another task.
Figure 8: Computed motifs and ground-truth optimal cells for all 3 tasks of N201. Note that optimalCIFAR-10 cell contains motifs 1 and 3, optimal CIFAR-100 cell contains motif 3 and optimalImageNet16 cell contains motif 2.
Figure 9: Predicted vs ground-truth validation error of GPWL in various NAS-Bench tasks in log-logscale. Error bar denotes ±1 SD from the GP posterior predictive distribution.
Figure 10: Spearman correlation on train/validation sets and the negative log-marginal likelihoodof GP against H (the maximum WL iteration) and the histograms of selected H by GPWL over 20trials on (a) N101 and (b) Flowers102.
Figure 11: Median validation error on NAS-Bench datasets with deterministic (top row) and noisy(bottom row) observations from 20 trials. Shades denote ±1 standard error.
Figure 12: Effect of varying P on NAS-BOWL in N101.
Figure 13: Ablation studies of NAS-BOWLWe find that topological information and using an appropriate h are highly crucial: in both N101 andN201, VH significantly underperforms the other variants, although the extent of underperformance issmaller in N201 likely due to its smaller search space. This suggests that how the nodes are connected,which are extracted as higher-order WL features, are very important, and the multi-scale featureextraction in the WL kernel is crucial to the success of NAS-BOWL. On the other hand, the choice ofthe acquisition function seems not to matter as much, as there is little difference between UCB and WLruns in both N101 and N201. Finally, using mutation algorithm leads to a significant improvement inthe performance of NAS-BOWL, as we have already seen in the main text.
Figure 14: Equivalent representations of the best cell identified by NAS-BOWL in the DARTS searchspace. Our method uses the node-attributed version during search, and this cell is used for both thenormal and reduction cells.
