Figure 1: (a) T-SNE embeddings of the representation of Sketches and Reals taken from a hiddenlayer for a pre-trained model on ImageNET, (b) Sketch of our method for learning a domain invariantcategorial semantics.
Figure 2: Our proposed adaptation to the image-to-image framework for CatS-UDT. Left: generatethe style using a mapping network conditioned on both noise Z 〜N(0,1) and the semantics of thesource sample h(x0). Right: infer style of an exemplar x2 using a style encoder and h(x0).
Figure 3: Studies on the effect on the translation accuracy on MNIST-SVHN of (a) Ablating eachloss by setting their λ =0. (b) Using VGG, MoCO, the presented method for learning categoricalsemantics without adaptation and with adaptation respectively to train a semantic encoder. (c) Varyingλsem .
Figure 4: Comparison with baselines. Comparing the baselines with our approach for translatingsketches to real images. For each sketch (top row), we sample 5 different styles generating 5 imagesin the target domain. For CycleGAN, we copy the generated images 5 times because it is impossibleto generate multiple samples in the target domain from the same source image.
Figure 5: Qualitative comparison of the baselines with our method on MNIST-SVHN. EVencolumns correspond to source samples, and odd columns correspond to their translations.
Figure 6: Multiple sampling for MNIST→SVHN. For each column, the first row is the source sampleand each subsequent row is a generation corresponding to a different z.
Figure 7:	Ablation studies on the effect on the FID on MNIST-SVHN of (a) Setting one λ =0while keeping the other λ0 =1, (b) Varying λsem and (c) Qualitative results of SVHN→ MNISTwhen λsem = 10.
Figure 8:	Comparative studies on the effect (a) on the translation accuracy and (b, c) on the FID onmNiST-SVhN on (a, b) Conditioning the content representation on the semantics, not conditioningon semantics and conditioning the style representation on the semantics.
Figure 9: Sketch→Real using CatS-UDT with λsem =0. Samples on the first row are the sourcesamples. Samples on the subsequent rows are generated samples.
Figure 10: Qualitative effect of the method to condition the semantics in the translation network inSketches→Reals. Samples on the first row are the source samples. Samples on the subsequent rowsare generated samples.
Figure 11: Effect of the representation spatial dimension on the generation of Sketches→Reals. For(a) and (b), we downsample the content representation to a 4 × 4 feature map. Samples on the firstrow are the source samples. Samples on the subsequent rows are generated samples.
Figure 12: Additional Sketches→Reals generations for each semantic categories.
