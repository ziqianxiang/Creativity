Figure 1: The analysis of the gradients reveals 3 regimes where the gradient is shifted by the certaintyand correctness of the weak learner. These 3 regions are present in real dataset such as MNLI.
Figure 2: Accuracy on MNLI matched develop-ment set for models with a cheating feature. Themodel trained with PoE (Main Model) is less sen-sitive to this synthetic bias.
Figure 4: Weaker learners assure a good balance between out-of-distribution and in-distributionwhile stronger learners encourage out-of-distribution generalization at the expense of in-distributionperformance. We indicate the number of parameters in parenthesis (in millions).
Figure 3: Pearson correlation between the losses (onevaluation sets) of the biased model and differenttraining methods. The PoE training is effective atreducing the correlation with the biased model.
Figure 5: The multi-loss objective controls a trade-off between the in-distribution performance andout-of-distribution robustness.
Figure 6: Our groups are included in the regions identified in Data Maps.
