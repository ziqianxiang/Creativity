Figure 1: A naive adversarial network. The neurons (represented by circles) are ReLUs, the numbersin the circles represent the additive bias, and the numbers over the connection represent the weight.
Figure 2: An adversarial network without extremely large weights. The network is equivalent to thatshown in Figure 1, only parameter Ï‰ is distributed over n layers, and the neuron with constant zeroinput is made less obvious with the help of an additional neuron with constant zero output over thevalid input domain.
Figure 3: Diagram of the MNIST network extended with a backdoor that is activated by the top leftpixel of the input image x. If this pixel is larger than 0.05 then the backdoor is activated and shifts thepredicted labels. The output y is the predicted distribution of the MNIST labels. The thick emptyarrows signify multiple connections. Note that the backdoor is integrated into the convolutionalarchitecture of WK17a (see text for further explanation).
