Figure 1: Comparison of gradient balance methods. In (a) to (d), g1, g2 and g3 represent the gradient computedby the raw loss of each task, respectively. The gray surface represents the plane composed by these gradients.
Figure 2: Overview of IMTL.
Figure 3: Relationship between our IMTL and previous methods. The blue dashed arrow indicatesthe characteristic of each method. In the loss balance methods, we annotate the scaled loss inthe bracket. Lcs, Lreg and Lt are the raw loss of classification, regression and individual task,respectively. ads, areg and at is the corresponding loss scale. L is the geometric mean loss and Tis the task number. In the gradient balance methods, we annotate the projections of the aggregatedgradient g = Pt atgt onto the raw gradient gt of the t-th task in the bracket. Ut = gt/ ∣∣gtk is theunit-norm vector, pt = gut> is the projection of g onto gt and us = Pt ut is the mean direction.
Figure 4: Loss scales of IMTL-G for different tasks when training on the Cityscapes dataset.
Figure 5: Pipeline used in the Cityscapes visual understanding experiment. The centroids are com-puted from the offset regression results. Each pixel is assigned to its nearest candidate centroid.
Figure 7: Qualitative results of our IMTL on Cityscapes. Semantic segmentation, instance seg-mentation and disparity estimation predictions are produced by a single network. The task-sharedbackbone is ResNet-50 and the task-specific heads are PSPNet. The image resolution is 1024 × 2048.
Figure 8: Qualitative results of our IMTL on NYUv2. Semantic segmentation, surface normalestimation and depth estimation predictions are produced by a single network. The task-sharedbackbone is ResNet-50 and the task-specific heads are PSPNet. The image resolution is 480 × 640.
