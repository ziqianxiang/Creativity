Figure 1: Given “person holding cup," humans can often predict multiple possible futures (e.g.,“drinking fromthe cup" or “keeping the cup on the table.").
Figure 2: An illustration of using GP variance to control sampling on-going actions vs. new actions.
Figure 3: An overview of the proposed Diverse Video Generator (DVG).
Figure 4: LPIPS Quantitative Results on KTH, BAIR, and Human3.6M datasets. All methods use the bestmatching sample out of 100 random samples. We used fixed trigger heuristic to keep trigger point for eachsample the same for our approach.
Figure 5: Qualitative Results on BAIR (left), KTH (center), Human3.6M (right, top), and UCF (right, bottom)datasets. First row is the ground-truth video in each figure (with the last frame of the provided 5 frames isshown as ‘GT'). Every 5th frame is shown.
