Figure 1: Traditional render-and-ComPare approaches render RGB images and make pixel-levelcomparisons. These are difficult to optimize due to the many local optima in the pixel-wise recon-struction loss. In contrast, NeMo is a Neural Mesh Model that renders feature maps and comparesthem with feature maps obtained via CNN backbone. The invariance of the neural features to nui-sance variables, such as shape and color variations, enables a robust 3D pose estimation with simplegradient-descent optimization of the neural reconstruction loss.
Figure 2: Overview of Pose estimation: For each image, We use the trained CNN backbone to extractfeature map F. Meanwhile, using trained Neural Mesh Model and randomly initialized object pose,we can render a feature map F. By calculating similarity at each local of F and F, we can createa foreground score map, which demonstrate the object likelihood at each location. Similarly, wecan get a background score map via F and trained clutter model Î². Using these two maps, we dothe occlusion inference to segment image into foreground region and background region. Then, wecalculate reconstruction loss and optimize object pose via minimize the loss. We also visualize theloss landscape along all 3 object pose parameters, and the final pose prediction.
Figure 3: Qualitative results of NeMo on PASCAL3D+ (L0) and occluded PASCAL3D+ (L1 &L2 & L3) for different categories under different occlusion level. For each example, we show foursubfigures. Top-left: the input image; Top-right: A mesh superimposed on the input image in thepredicted 3D pose. Bottom-left: The occluder localization result, where yellow is background, greenis the non-occluded area of the object and red is the occluded area as predicted by NeMo. Bottom-right: The loss landscape for each individual camera parameter respectively. The colored verticallines demonstrate the final prediction and the ground-truth parameter is at center of x-axis.
Figure 5: Using detailed mesh model We can create all type of mesh models for NeMo. (a) Weuse remesh method in Blender to down sample the original mesh. The processed mesh contains1722 vertices. (b) FolloWing rules in 4.2, We create subtype specificed cuboid (one cuboid for eachsubtype), Which used in NeMo-MultiCuboid approach. The cuboid contains 1096 vertices. (c) Wecreate the subtype general cuboid by requiring the cuboid cover original meshes of all subtypes.
Figure 6: Visualization of failure case of NeMo on occluded PASCAL3D+. For each example, weshow four subfigures. Top-left: the input image; Top-right: A mesh superimposed on the inputimage in the predicted 3D pose. Bottom-left: The occluder localization result, where yellow isbackground, green is the non-occluded area of the object and red is the occluded area as predictedby NeMo. Bottom-right: The loss landscape for each individual camera parameter respectively. Thecolored vertical lines demonstrate the final prediction and the ground-truth parameter is at center ofx-axis.
