Figure 1: Visualizations of deviation from the prior distribution for filters in the first layer of aconvolutional networks trained on Hard-CHASY. Lighter colours indicate an active filter for thattask. Models are trained either (a) sequentially using GVCL, or (b) sequentially with GVCL +FiLM. FiLM layers increase the number of active units.
Figure 2: Running average accuracy of Easy-CHASY, Hard-CHASY and Split-MNIST trained con-tinually. GVCL-F and GVCL are compared to the best performing baseline algorithm. GVCL-Fand GVCL both significantly outperform HAT on Easy-CHASY. On Hard-CHASY, GVCL-F stillmanages to perform as well joint MAP training, while GVCL performs as well as PathNet. In Split-MNIST, GVCL-F narrowly outperforms HAT, with both performing nearly as well as joint training.
Figure 3: Accuracy of Easy-CHASY and Hard-CHASY trained models at the end of learning all10 tasks continually. Performance of GVCL-F, GVCL and the best performing baselines (HATand Pathnet) are compared to Joint and Separate training. GVCL-F again strongly outperforms thebaselines and performs similar to the upper-bound VI joint training.
Figure 4: Running average accuracy of Split-CIFAR and final accuracies after continually trainingon 6 tasks for GVCL-F, GVCL, and HAT. GVCL-F achieves the maximum amount of forwardstransfer, and achieves close to the upper-bound joint performance.
Figure 5: (a) Average accuracy of mixed vision tasks at the end of training for GVCL-F and HAT.
Figure 6: Calibration curves and Expected Calibration Error for GVCL-F and HAT trained on theMixed Vision Tasks benchmark. GVCL-F achieves much lower Expected Calibration Error, attain-ing a value averaged across all tasks of 0.3% compared to HAT’s 1.7%.
Figure 7: True data log-likelihoods of a generative model of the form p(x∣θ) = N(x; f (θ), σ2).
Figure 8: Approximate data log-likelihoods found using β-VI for various values of β for threedifferent generative models. Small values of β cause local approximations of curvature and largevalues cause global ones.
Figure 9: Visualization of a simple 2d logistic regression clustering task. The first task is distin-guishing blue and red, classes 1 and 2 respectively. The second task is distinguishing green (class 1)from yellow (class 2). The combined task is shown on the leftHere, we demonstrate convergence of GVCL to Online-EWC for small β . In this problem, we dealwith 2d logistic regression on atoy dataset consisting of separated clusters. The clusters are shown inFigure 9. The first set of tasks is separating the red/blue clusters, then the second is the yellow/greenclusters. Blue and green are the first class and red and yellow are the second. Or model is given bythe equationp(yi = 1|w, b,xi) = σ(w>xi + b)Where xi are our datapoints and w and b are our parameters. yi = 1 means class 2 (and yi = 0means class 1). x is 2-dimensional so we have a total of 3 parameters.
Figure 10: Convergence of GVCL parameter values to Online-EWC parameter values for decreasingvalues of β for a toy 2d logistic regression problemconverge compared to 1.7 for β = 1. A small learning rate of 1e-4 with 100000 iteration steps wasnecessary for the smallest β =1e-4. If the optimization process was run for shorter, or too large alearning rate was used, we would observe convergent behaviour for the first few values of β , but thesmallest values of β would result in completely different values.
Figure 11:	Transitions between posteriors at different temperatures using tempering and optimizingeither the T-ELBO or β-ELBOWhen Q contains all possible distributions, moving along any path results in the exact same distri-bution, for example optimizing the T -ELBO then tempering is the same as directly optimizing theELBO. However in the case where Q is limited, this transition is not exact, and the resulting poste-rior is path dependent. In fact, each possible path represents a different valid method for performingcontinual learning. Standard VCL works by traversing the horizontal arrows, directly optimizing theELBO, while an alternative scheme of VCL would optimize the T -ELBO to form cold posteriors,then heat the posterior before optimizing the T -ELBO fora new task. Inference can be done at eitherthe warm or cold state. Note that for Gaussians, heating the posterior is just a matter of scaling thecovariance matrix by a constant factor Jf^.
Figure 12:	T-SNE of FiLM layer parameters of 58 tasks coming from different domains. Shift andscale parameters from the same domain are more similar than those from different ones.
Figure 13: Posterior distributions for incoming weights (left) or biases (right) for a node in thefirst layer. Nodes are either unrpruned (left within a column) or pruned (right within a column).
Figure 14:	Mean accuracy of individual tasks after training for all approaches on Easy-CHASY31Published as a conference paper at ICLR 2021Easy-CHASY performance on individual tasks (top 5 approaches)Approaches(Ranked)→- GVCL-F→- GVCL→- HAT—Progressive—PathNetJoint-(S-VI, FiLM)Separate「(B-Vl)——Joint (MAP)---Separate (MAP)Figure 15:	Mean accuracy of individual tasks after training for the top 5 performing approaches onEasy-CHASYApproaches
Figure 15:	Mean accuracy of individual tasks after training for the top 5 performing approaches onEasy-CHASYApproaches(Ranked)→- GVCL-F→- GVCL→- HAT—Progressive—PathNet—SGD-Frozen→- VCL-F→- VCL→- Online EWC-F→- SGD→- LWF—IMM-Mode→- Online EWC—IMM-Mean—Joint (MAP)—Joint (∕3-VI)
Figure 16:	Running average accuracy of individual tasks after training for the all approaches onEasy-CHASY32Published as a conference paper at ICLR 2021Figure 17: Running average accuracy of individual tasks after training for the top 5 approaches onEasy-CHASYApproaches(Ranked)→- GVCL-F→- GVCL→- HAT—Progressive—PathNet—Joint (MAP)—Joint (∕3-VI)33Published as a conference paper at ICLR 2021J.2 Hard-CHASY Additional ResultsMetric	ACC (%)	BWT (%)	FWT (%)	NET (%)GVCL-F	69.5 ± 0.6	-0.1 ± 0.1	-1.6 ± 0.7	-1.7 ± 0.6
Figure 17: Running average accuracy of individual tasks after training for the top 5 approaches onEasy-CHASYApproaches(Ranked)→- GVCL-F→- GVCL→- HAT—Progressive—PathNet—Joint (MAP)—Joint (∕3-VI)33Published as a conference paper at ICLR 2021J.2 Hard-CHASY Additional ResultsMetric	ACC (%)	BWT (%)	FWT (%)	NET (%)GVCL-F	69.5 ± 0.6	-0.1 ± 0.1	-1.6 ± 0.7	-1.7 ± 0.6GVCL	64.4 ± 0.6	-0.6 ± 0.2	-6.3 ± 0.6	-6.8 ± 0.6HAT	62.5 ± 5.4	-0.8 ± 0.4	-3.7 ± 5.5	-4.5 ± 5.4PathNet	64.8 ± 0.8	0.0 ± 0.0	-2.2 ± 0.8	-2.2 ± 0.8VCL	45.8 ± 1.4	-11.9 ± 1.6	-13.5 ± 2.2	-25.4 ± 1.4
Figure 18:	Mean accuracy of individual tasks after training for all approaches on Hard-CHASY34Published as a conference paper at ICLR 2021Hard-CHASY performance on individual tasks (top 5 approaches)Approaches(Ranked)→- GVCL-F—Progressive→- VCL-F—PathNet→- GVCLJoint-(S-VI, FiLM)Separate「(B-Vl)——Joint (MAP)---Separate (MAP)Figure 19:	Mean accuracy of individual tasks after training for the top 5 performing approaches onHard-CHASYApproaches
Figure 19:	Mean accuracy of individual tasks after training for the top 5 performing approaches onHard-CHASYApproaches(Ranked)→- GVCL-F—Progressiveτ- VCL-F—PathNet→- GVCL→- HAT—SGD-Frozen→- Online EWC-F→- Online EWC→- SGD→- LWF→- VCL—IMM-Mode—IMM-Mean—Joint (MAP)—Joint (∕3-VI)
Figure 20:	Running average accuracy of individual tasks after training for the all approaches onHard-CHASY35Published as a conference paper at ICLR 2021Hard-CHASY running average accuracy (all approaches)4	6	8Number of tasksioApproaches(Ranked)→- GVCL-F—Progressive→- VCL-F—PathNet→- GVCL—Joint (MAP)—Joint (∕3-VI)Figure 21:	Running average accuracy of individual tasks after training for the top 5 approaches onHard-CHASY36
Figure 21:	Running average accuracy of individual tasks after training for the top 5 approaches onHard-CHASY36Published as a conference paper at ICLR 2021J.3 Split-MNIST additional resultsMetric	ACC (%)	BWT (%)	FWT (%)	NET (%)GVCL-F	98.6 ± 0.1	0.0 ± 0.0	-0.1 ± 0.1	-0.0 ± 0.1GVCL	94.6 ± 0.7	-4.0 ± 0.7	-0.0 ± 0.0	-4.1 ± 0.7HAT	98.3 ± 0.1	-0.2 ± 0.0	-0.1 ± 0.1	-0.3 ± 0.1PathNet	95.2 ± 1.8	0.0 ± 0.0	-3.3 ± 1.8	-3.3 ± 1.8VCL	92.4 ± 1.2	-5.5 ± 1.1	-0.8 ± 0.1	-6.3 ± 1.2VCL-F	94.8 ± 0.9	-3.3 ± 0.9	-0.6 ± 0.1	-3.9 ± 0.9Online EWC	94.0 ± 1.4	-3.8 ± 1.4	-0.8 ± 0.1	-4.6 ± 1.4Online EWC-F	94.1 ± 0.7	-0.3 ± 0.6	-4.1 ± 0.3	-4.4 ± 0.7Progressive	98.4 ± 0.0	0.0 ± 0.0	-0.2 ± 0.0	-0.2 ± 0.0IMM-mean	90.5 ± 1.1	0.5 ± 0.1	-8.5 ± 1.2	-8.0 ± 1.1imm-mode	95.4 ± 0.2	-1.7 ± 0.3	-1.5 ± 0.1	-3.1 ± 0.2LWF	97.4 ± 0.2	-1.1 ± 0.1	-0.1 ± 0.1	-1.2 ± 0.2SGD	76.2 ± 1.7	-22.4 ± 1.7	0.0 ± 0.1	-22.4 ± 1.7SGD-Frozen	91.7 ± 0.2	0.0 ± 0.0	-6.9 ± 0.2	-6.9 ± 0.2
Figure 22:	Mean accuracy of individual tasks after training for all approaches on Split-MNIST37Published as a conference paper at ICLR 2021Approaches(Ranked)→- GVCL-F—Progressive→- HAT→- LWF—IMM-ModeJoint-(S-VI, FiLM)Separate「(B-Vl)——Joint (MAP)---Separate (MAP)Figure 23:	Mean accuracy of individual tasks after training for the top 5 performing approaches onSplit-MNISTNumber of tasksApproaches
Figure 23:	Mean accuracy of individual tasks after training for the top 5 performing approaches onSplit-MNISTNumber of tasksApproaches(Ranked)→- GVCL-F—Progressive→- HAT→- LWF—IMM-Mode—PathNet→- VCL-F→- GVCL→- Online EWC-F→- Online EWC→- VCL—SGD-Frozen—IMM-Mean→- SGD→- Joint (MAP)
Figure 24:	Running average accuracy of individual tasks after training for the all approaches onSplit-MNIST38Published as a conference paper at ICLR 2021Number of tasksApproaches(Ranked)→- GVCL-F—Progressive→- HAT→- LWF—IMM-Mode—Joint (MAP)—Joint (∕3-VI)Figure 25: Running average accuracy of individual tasks after training for the top 5 approaches onSplit-MNIST39Published as a conference paper at ICLR 2021J.4 Split-CIFAR ADDITIONAL RESULTSMetric	ACC (%)	BWT (%)	FWT (%)	NET (%)
Figure 25: Running average accuracy of individual tasks after training for the top 5 approaches onSplit-MNIST39Published as a conference paper at ICLR 2021J.4 Split-CIFAR ADDITIONAL RESULTSMetric	ACC (%)	BWT (%)	FWT (%)	NET (%)GVCL-F	80.0 ± 0.5	-0.3 ± 0.2	8.8 ± 0.5	8.5 ± 0.5GVCL	70.6 ± 1.7	-2.3 ± 1.4	1.3 ± 1.0	-1.0 ± 1.7HAT	77.3 ± 0.3	-0.1 ± 0.1	6.8 ± 0.2	6.7 ± 0.3PathNet	68.7 ± 0.8	0.0 ± 0.0	-1.9 ± 0.8	-1.9 ± 0.8VCL	44.2 ± 14.2	-23.9 ± 12.2	-3.5 ± 2.1	-27.4 ± 14.2VCL-F	56.2 ± 2.8	-19.5 ± 3.2	4.1 ± 0.8	-15.4 ± 2.8Online EWC	77.1 ± 0.2	-0.5 ± 0.3	6.9 ± 0.3	6.4 ± 0.2Online EWC-F	77.1 ± 0.2	-0.4 ± 0.2	6.9 ± 0.3	6.5 ± 0.2Progressive	70.7 ± 0.8	0.0 ± 0.0	0.1 ± 0.8	0.1 ± 0.8IMM-mean	67.6 ± 0.6	-0.2 ± 0.3	-2.9 ± 0.8	-3.1 ± 0.6imm-mode	74.9 ± 0.3	-6.2 ± 0.3	10.5 ± 0.4	4.3 ± 0.3LWF	73.8 ± 0.9	-8.0 ± 0.8	11.2 ± 0.2	3.2 ± 0.9SGD	74.7 ± 0.4	-6.5 ± 0.4	10.6 ± 0.8	4.1 ± 0.4SGD-Frozen	70.3 ± 0.4	0.0 ± 0.0	-0.3 ± 0.4	-0.3 ± 0.4
Figure 26: Mean accuracy of individual tasks after training for all approaches on Split-CIFAR40Published as a conference paper at ICLR 2021SpIit-CIFAR performance on individual tasks (top 5 approaches)50.5.050502.s7.5.2.s7.5.
Figure 27: Mean accuracy of individual tasks after training for the top 5 performing approaches onSplit-CIFARFigure 28: Running average accuracy of individual tasks after training for the all approaches onSplit-CIFAR41Published as a conference paper at ICLR 2021SpIit-CIFAR running average accuracy (top 5 approaches)Number of tasksApproaches(Ranked)→- GVCL-F→- HAT→- Online EWC—IMM-Mode—Joint (MAP)—Joint (∕3-VI)Figure 29:	Running average accuracy of individual tasks after training for the top 5 approaches onSplit-CIFAR42Published as a conference paper at ICLR 2021
Figure 28: Running average accuracy of individual tasks after training for the all approaches onSplit-CIFAR41Published as a conference paper at ICLR 2021SpIit-CIFAR running average accuracy (top 5 approaches)Number of tasksApproaches(Ranked)→- GVCL-F→- HAT→- Online EWC—IMM-Mode—Joint (MAP)—Joint (∕3-VI)Figure 29:	Running average accuracy of individual tasks after training for the top 5 approaches onSplit-CIFAR42Published as a conference paper at ICLR 2021J.5 Mixed vision tasks additional resultsMetric	ACC (%)	BWT (%)	FWT (%)	NET (%)
Figure 29:	Running average accuracy of individual tasks after training for the top 5 approaches onSplit-CIFAR42Published as a conference paper at ICLR 2021J.5 Mixed vision tasks additional resultsMetric	ACC (%)	BWT (%)	FWT (%)	NET (%)GVCL-F	80.0 ± 1.2	-0.9 ± 1.3	-4.8 ± 1.6	-5.6 ± 1.2GVCL	49.0 ± 2.8	-13.1 ± 1.6	-23.5 ± 3.4	-36.7 ± 2.8HAT	80.3 ± 1.0	-0.1 ± 0.1	-5.8 ± 1.0	-5.9 ± 1.0PathNet	76.8 ± 2.0	0.0 ± 0.0	-9.5 ± 2.0	-9.5 ± 2.0VCL	26.9 ± 2.1	-35.0 ± 5.6	-23.7 ± 3.8	-58.8 ± 2.1VCL-F	55.5 ± 2.0	-18.2 ± 2.1	-11.9 ± 2.4	-30.1 ± 2.0Online EWC	62.8 ± 5.2	-18.7 ± 5.8	-4.8 ± 0.7	-23.4 ± 5.2Online EWC-F	70.5 ± 4.0	-11.8 ± 4.3	-3.9 ± 0.5	-15.7 ± 4.0Progressive	77.6 ± 0.4	0.0 ± 0.0	-8.6 ± 0.4	-8.6 ± 0.4IMM-mean	53.8 ± 2.0	-4.4 ± 1.7	-28.0 ± 3.3	-32.4 ± 2.0imm-mode	36.6 ± 18.7	-9.1 ± 7.0	-40.5 ± 11.9	-49.6 ± 18.7LWF	25.8 ± 4.3	-57.3 ± 4.5	-3.1 ± 0.6	-60.4 ± 4.3SGD	35.4 ± 3.9	-50.5 ± 3.9	-0.4 ± 0.0	-50.9 ± 3.9SGD-Frozen	52.9 ± 3.9	0.0 ± 0.0	-33.3 ± 3.9	-33.3 ± 3.9
Figure 30:	Mean accuracy of individual tasks after training for all approaches on mixed vision tasks43Published as a conference paper at ICLR 2021Approaches(Ranked)→- HAT→- GVCL-F—Progressive—PathNet→- Online EWC-FJoint-(B-YI FiLM)Separate一(S-VI)——Joint (MAP)---Separate (MAP)Figure 31:	Mean accuracy of individual tasks after training for the top 5 performing approaches onmixed vision tasks	CIFAR10 CIFAR100 MNIST SVHN F-MNIST TrafficSigns Facescrub NotMNIST AverageGVCL-F HAT	0.79%	0.01%	0.04%	0.73%	0.25%	0.10%	0.11%	0.53%	0.32% 0.12%	0.40%	0.13%	2.55%	0.94%	0.42%	5.05%	3.88%	1.69%
Figure 31:	Mean accuracy of individual tasks after training for the top 5 performing approaches onmixed vision tasks	CIFAR10 CIFAR100 MNIST SVHN F-MNIST TrafficSigns Facescrub NotMNIST AverageGVCL-F HAT	0.79%	0.01%	0.04%	0.73%	0.25%	0.10%	0.11%	0.53%	0.32% 0.12%	0.40%	0.13%	2.55%	0.94%	0.42%	5.05%	3.88%	1.69%Table 9:	ECE of all 8 mixed vision tasks for a model trained continually using GVCL-F or HAT.
Figure 32: Clusters of symbols found by performing K-means clustering with K = 20 based on theembedding layer of a model trained with variational inference on a 200-way classification task onthe 200 most common symbols in the HASYv2 dataset. Easy-CHASY is made by taking the firstsymbol from each cluster as the first task, then the second, and so on, up to 10 tasks. Hard-CHASYis made by taking the clusters with the most classes in order (clusters 1-10).
Figure 33: Relative test-set accuracy of models trained jointly on the easy set of tasks relativeto individual training for MAP estimation. Figure 33a shows the means aggregated over all taskswhile figure 33b shows the performance differences for individual tasks. Performance increases nearmonotonically as more tasks are added, achieving an average of around 4.7% gain with 10 tasks(c)Figure 34: Relative performance of models trained jointly on the easy set of tasks relative to indi-vidual training for variational inference with various KL-reweighting coefficients β . Performancegains reach around 2.0% with 10 tasks in the worst case, which is less than with MAP training butstill significantFigures 33a and 34 show the performance gains of joint training over separate training on this newdataset, for both MAP, and KL-reweighted VI, respectively. Figure 33b shows how relative test setaccuracy varies for each specific task for these training procedures.
Figure 34: Relative performance of models trained jointly on the easy set of tasks relative to indi-vidual training for variational inference with various KL-reweighting coefficients β . Performancegains reach around 2.0% with 10 tasks in the worst case, which is less than with MAP training butstill significantFigures 33a and 34 show the performance gains of joint training over separate training on this newdataset, for both MAP, and KL-reweighted VI, respectively. Figure 33b shows how relative test setaccuracy varies for each specific task for these training procedures.
