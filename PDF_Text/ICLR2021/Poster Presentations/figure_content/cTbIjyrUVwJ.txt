Figure 1: Global spatial redundancy in the image. For standard codecs and previous learned codecs,non-local relevant patches (marked by yellow and blue) would consume equal bit rates.
Figure 2: Operational diagrams of learned compression models (a)(b)(c) and proposed Reference-based Entropy Model (d).
Figure 3: Our compression model with combined local, global, and hyperprior entropy model. Tanitems represent data tensors, blue represents learned modules (e.g. convolutional layer), green is forquantization, and red represents entropy coding. The left side shows an autoencoder with a quantizer,the right side corresponds to the entropy model. The entropy model progressively incorporates localcontext, global context and hyperprior. Each parameter network predicts the Gaussian parametersconditioned on both the previous features and predictions. Using the Gaussian parameters (μ3, σ3),the quantized latents are compressed into a stream by an arithmetic encoder (AE) and decompressedby an arithmetic decoder (AD).
Figure 4: A mask slide patch searches on all thedecoded latents (tan area). The relevant latentsare fetched and learned with a masked convolu-tion.
Figure 5: The progressive entropy model incor-porates three sub-models. The reference modelis a soft-attention-like function.
Figure 6: Rate-distortion curves aggregated over the Kodak dataset. The left plot shows peak2552Signal-to-noιse ratios as a function of bit rate (10logι° 255- , With d representing mean squarederror), the right plot shows MS-SSIM values converted to decibels (-10 log10(1 - d), where d isthe MS-SSIM value in the range between zero and one). In both terms, our full model consistentlyoutperforms standard codecs and the state-of-the-art learned models.
Figure 7: Each curve shows the rate savings atdifferent PSNR quality levels relative to BPG.
Figure 8: Examples of target region (indicatedby purple) and its relevant region (indicated byyellow).
Figure 9: Each row corresponds to a different entropy model variant and shows information for thechannel with the highest entropy. The predicted mean corresponds to the Gaussian parameters (i.e.
Figure 10:	Example of confidence U map and similarity S map. The S map is tend to representshape while the U map is tend to represent texture, e.g., the wood pile on the right of the boat.
Figure 11: Histograms of the latent representation by GDN-based model and GSDN-based model.
Figure 12: Performance Evaluation on CLIC Validation dataset. Our method performs very wellwhen optimized for MSE or MS-SSIM. Each point on the RD curves is calculated by averaging overthe PSNR (or MS-SSIM) and bit rate for the 102 images from CLIC Validation dataset (http://challenge.compression.cc/).
Figure 13: Each curve shows the rate savings at different PSNR quality levels relative to BPG.
Figure 14: At similar bit rates, our combined method provides the highest visual quality on theKodak 15 image. BPG introduces a few geometric artifacts around the girl’s mouth and nose. JPEGshows severe blocking artifacts at this bit rate.
Figure 15: At similar bit rates, our combined method provides the highest visual quality on theKodak 21 image. BPG shows more “classical” compression artifacts, e.g., ringing around the edgeof the lighthouse.
Figure 16: At similar bit rates, our combined method provides the highest visual quality on theKodak 23 image. Note that the BPG reconstruction has some ringing and geometric artifacts (e.g.,at the top of the red parrot’s head).
Figure 17: At similar bit rates, our method provides the better visual quality on the high resolutionimage on CLIC valid dataset.
Figure 18: Context-only Entropy Model. This model relies only on an autoregressive process witha local context to predict the Gaussian parameters. The benefit of this approach is that no additionalbits are added to the bitstream. The downside of this model is that it conditions predictions only onneighboring latents.
Figure 19: Context + Reference Entropy Model. This model combines global reference withlocal context. The benefit of this model is that it can access all previous latents.
Figure 20: Context + Reference + Hyperprior Entropy Model. This model uses a hyper-networkto learn a (hyper-)latent representation to transmit side information. The benefit of hyperprior in thismodel is that it learns to represent information useful for correcting the context-based predictions.
