Figure 1: Description of Manifold Analysis. (A) Random samples of unpermuted, permuted, andrestored examples showing the label used for training and our geometric analysis. Note that restoredand permuted examples only differ on the label used for analysis. (B) Empirical manifold capacitymatches theory. (C) (Top) MFTMA framework formally links manifold capacity, a measure objectmanifolds’ linear separability, to geometric properties. Reduced dimension, radius, center correlationsresult in larger manifold capacity and vice versa. (Bottom) Hypothesis of how network trainingaffects geometry and separability of object manifolds in the presence of label noise.
Figure 2: Generalization and memorization as seen by accuracy and visualization. A (left):Training and test accuracy curves for all models and datasets ( = 50%). A (right): Accuracy onunpermuted, permuted, and restored training examples. B: UMAP visualization of the final layerfeatures in VGG16 with = 50% at initialization, best epoch, and final epoch. At the best epoch,unpermuted, restored, and test manifolds show similar structure, implying that the network haslearned the features shared between the two datasets. First 10 classes of CIFAR100 are included.
Figure 3: MFT Geometry of generalization and memorization on VGG16. A: Best Epoch.
Figure 4: (A-B) Rewinding training: Accuracy on the train set (A), and the test set (B) for VGG-16trained for 1000 epochs with an individual layer’s parameters rolled back to an earlier epoch (rewindepoch). The final three linear layers of VGG-16 are unchanged throughout. Horizontal line indicatesthe peak generalization performance from early stopping. (C-E) Double descent phenomenon, withincreasing model parameters, at the best epoch (blue) and final epoch (orange). The region is linkedto increased manifold dimensionality (E), with unchanged radius and center correlation.
Figure 5: Gradient analysis. (A-C): `2 norm of the gradient of the loss over the different layers andepochs of training for VGG16, computed on (A) all samples, (B) unpermuted samples only, and (C)permuted samples only. (D): Ratio of gradients. For the label dependent part (dep) of the gradient,the gradients averaged from the unpermuted samples are much larger than the gradient from permutedsamples (green line). For the independent part, the two components are roughly equal (Red).
