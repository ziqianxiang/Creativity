Figure 1: An illustration of how taking notes of rare words can help language understanding. The leftpart of the figure shows that without any understanding of the rare word “COVID-19”, there are toomany grammatically-correct, while semantically-wrong options for us to fill in the blank. In the righthalf, we show that a note of “COVID-19” taken from a previously-seen sentence can act as a verystrong signal for us to predict the correct word at the masked position.
Figure 2: The training framework of Taking Notes on the FLY (TNF). The left box shows the forwardpass with the help of the note dictionary. In the input word sequence, w2 is a rare word. Then fortokens 4 and 5 originated from w2, we query the value of w2 in the note dictionary and weightedaverage it with token/position embeddings. The right box demonstrates how we maintain the notedictionary. After the forward pass of the model, we can get the contextual representations of the wordnear w2 and use mean pooling over those representations as the note of w2 in the current sentence.
Figure 3: The curves of pre-training loss, pre-training validation loss and average GLUE score for allmodels trained under the BERT setting and ELECTRA setting. All three sub-figures show that TNFexpedites the backbone methods.
Figure 4: GLUE score of large modelssize, but also more effective at improving the final performance when the model gets bigger.
