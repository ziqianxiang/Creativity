Figure 1: Pipeline of our method.
Figure 2: ACC values over learn- Figure 3: Accuracy of ID for var- Figure 4: Accuracy of IDFD foring process.	ious τ settings.	various τ2 settings.
Figure 5: Distribution of feature representations on CIFAR-10.
Figure 6: Distribution of feature representations on ImageNet-10 learned by IDFD and samplescorresponding to points in some areas.
Figure 7: Feature correlation matrix on CIFAR-10 with ResNet18can work on various networks. IDFD outperforms ID(tuned), and FD term shows more obviouseffect on these networks. We also confirm the effect of cooperation between LI and LF from theviewpoint of spectral clustering, combinations of AE and LF were evaluated in terms of clusteringperformance. We found that AE cannot benefit from LF as LI did. This result verified that LF has adeep relation with LI, and IDFD is not a simple combination. We also investigate the importanceof data augmentation in performance through experiments. Due to the page limit, our extendedexperiments are given in Appendix C.
Figure 8: Two extreme cases of representation distribu-tions over two-dimensional space. Left: uniform. Right:FigUre 9： eχp(Cos 0/t) with differ-compact.	ent τ settings.
Figure 10: Feature correlation matrix learned by VGG16 on CIFAR-10.
Figure 11: Effect of each technique used for DA on CIFAR-10.
