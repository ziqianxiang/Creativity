Figure 1: Primal and dual network interpretation. In the primal network, m refers to the number ofconv. filters, while in the dual network ` refers to the number of sign patterns.
Figure 2: Train and test curVes for MNIST denoising problem, for Various noise leVels σ .
Figure 3: Test examples from MNIST denoising problem for two Values of σ from primal (top) anddual (bottom) networks. From left to right, images are: (a) noisy network input, (b) ground truth,(c) network output.
Figure 4: Visualization of the frequency response for the learned dual filters {wi } for denoisingMNIST. Representative filters (600) are randomly selected for visualization when σ = 0.5.
Figure 5: Visualization of k-means clustering for latent representations of trained MNIST denoisingnetwork when σ = 0.75 and k = 12. (a) one unrolled iteration, (b) two unrolled iterations trainedend to end; top row is the output of the first iteration, and bottom is the output of the second iteration.
Figure 6: Train and test curves for MRI reconstruction under various undersampling rates R.
Figure 7: Representative test knee MRI slice reconstructed via dual and primal network for under-sampling R = 2, 4. From left to right: ground truth, output, and noisy ZF input.
Figure 8: Train and test curves for Gaussian-distributed noise with σ = 0.75. The primal and dualoptimization problems perform similarly well.
Figure 9: Train and test curves for exponentially distributed noise with λ = 1.15. The primal failsto learn as well as the dual.
Figure 10: MNIST denoising with additive Gaussian noise and σ ∈ {0.5, 0.1}. Ablation study forthe number of sampled sign patterns for the dual problem, compared to the primal problem with 512filters.
Figure 11: Visualization of the frequency response for the learned dual filters {wi } for MRI recon-struction. Representative filters (250) of size 80 × 80 are randomly selected for visualization whenR=4.
