Figure 1: Illustration of the proposed quadcopter localisation and dense mapping. Left: top-downview of the localisaton estimate. Right: generative depth and colour reconstructions for one time step.
Figure 2: (a) One time step of the proposed probabilistic graphical model. (b) Linear interpolationduring ray casting for a single ray in the emission model. dk is the depth corresponding to the firstray value that exceeds τ . The output depth d is formed by linearly interpolating between dk-1 anddk based on the occupancy values oi,j,k-1 and oi,j,k.
Figure 3:	(a) Emissions at different trajectory points, sampled at a one second interval. Top to bottom:predicted colour, observed colour, predicted depth, observed depth. (b) Generative predictions usingthe engineered transition vs. the learned transition in the complete model. Left: top-down view of200-step location predictions. Right: predicted colour and depth for the same step for both models.
Figure 4:	An illustration of a reconstructed dense map for the NYC subway station environment. Notethat columns from the subway are captured in the reconstructed map. The figures show a horizontalmap slice. (a) Occupancy map uncertainty (white means low uncertainty). (b) Occupancy map mean(white means occupied). (c) Collision cost-to-go (red means high cost). (d) Generated point cloud(black, for inferred agent poses) vs. data point cloud (red, for ground truth MOCAP poses).
Figure 5: (a,b) Top-down view of localisation for star, forward yaw, max speed 4.0m∕s and PiCaSSo,constant yaw, max speed 4.0m∕s. (c) Localisation with our method compared to the benchmarkresults reported by Antonini et al. (2020) for picasso, constant yaw and star, forward yaw, 1 to 4m/s.
Figure 6: Simplified 2D examples of the conceptual difference the chosen attention can have ongenerating observations.
Figure 7: Illustration of the discussed failure landing of the quadcopter at the end of the two test settrajectories, taking star, max speed 2.0 m/s as an example. The problematic segment of the trajectoryis marked with a red vertical band. Note the outlier controls at the end. Top left: angular velocity IMUreadings. Top right: linear acceleration IMU readings. Bottom left: absolute Euclidean distance errorw.r.t. the ground truth MOCAP locations. Note how the error is large only at the end of the trajectory,and directly coincides with the outlier controls. Bottom right: comparison of the distribution of linearaccelerations in y during flight (red) vs. during landing (gray). The controls during landing are out ofdistribution for the learned transition model.
Figure 8: Examples of inference in the full spatial model, expressed in localisation and mapping forsegments of the following trajectories: clover, forward yaw, max speed 3.0 m/s, patrick, forward yaw,max speed 3.0 m/s, sphinx, forward yaw, max speed 3.0 m/s and sid, forward yaw, max speed 3.0 m/s.
