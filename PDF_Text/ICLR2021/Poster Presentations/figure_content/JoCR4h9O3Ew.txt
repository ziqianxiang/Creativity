Figure 1: ARMOURED dual-view framework: (a) training and (b) inference procedures. Solidblack and dotted red arrows denote forward and backward passes, respectively; double black arrowsrepresent image augmentation; double-dashed green arrows denote pseudo-label filter.
Figure 2: Three models are trained on CIFAR-10-semi-1k setup. We plot the average predictionof test samples with label “airplane”. (a) ARMOURED without DPP regularization: each networkpredicts randomly on non-target classes. (b) ARMOURED-I: with identity matrix as kernel, networkpredictions on non-target classes are orthogonal. (c) ARMOURED-H: hand-crafted kernel causes aclustering effect, where each network prefers a group of classes, either vehicles or animals.
Figure 3: Robustness against AutoAttack vs. perturbation budget on CIFAR-10-semi-4k.
Figure 4: t-SNE plots of feature embeddings from CIFAR-10 test samples generated by ablationmodels: (a) w/o (LDPP + LNEM), (b) w/o Unlabeled, (c) ARMOURED-F and (d) ARMOURED-F+AT. For each of the 8 network/method pairs, the clean and adversarial samples are processedtogether in a single t-SNE run. Adversarial samples are generated with PGD-'∞ (e = 8/255). From(a) to (d), the embeddings of adversarial samples are progressively enhanced, while (c) yields thebest representations on clean data.
