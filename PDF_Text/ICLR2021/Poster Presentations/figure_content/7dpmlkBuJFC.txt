Figure 1: Top 500 eigen-value spectrum of the gradient second moment matrix along the trainingtrajectory of SGD, DP-SGD with σ = 1, 2. Dataset: MNIST; model: 2-layer ReLU with 128 nodeseach layer. The network has roughly 130,000 parameters and is trained on MNIST dataset. TheY-axis is the eigenvalue and X-axis is order of eigenvalues from largest to smallest.
Figure 2: Sorted components of population gradients for DP-SGD with σ = 1.0, 2.0, 4.0. Dataset:MNIST; model: 2-layer ReLU with 128 nodes each layer. The network has roughly 130,000 param-eters. Y-axis is the absolute value of sorted gradient coordinates, i.e., |mt(j)|, X-axis is the order ofsorted gradient component.
Figure 3: Training and test accuracy for DP-SGD, PDP-SGD and RPDP-SGD with different privacylevels for (a) MNIST and (b) Fashion MNIST. The X-axis is the , and the Y-axis is the train/testaccuracy. For small regime, which is more favorable for privacy, PDP-SGD outperforms DP-SGD.
Figure 4: Training dynamics of DP-SGD, PDP-SGD and RPDP-SGD for (a) MNIST ( = 0.23) and(b) Fashion MNIST ( = 0.30). The X-axis is the number of epochs, and the Y-axis is the train/testaccuracy. For Fashion MNIST, PDP-SGD and RPDP-SGD start projection at 15-th epoch.
Figure 5: Training accuracy and test accuracy for (a) PDP-SGD with k = {10, 20, 30, 50}; (b) PDP-SGD with m = {50, 100, 150} for MNIST ( = 0.23). The X-axis and Y-axis refer to Figure 4. Theperformance of PDP-SGD increases as projection dimension k and public sample size m increase.
Figure 6: Training and test accuracy for PDP-SGD with different frequency of eigen-space com-putation for (a) MNIST ( = 0.23) and (b) Fashion MNIST ( = 0.23). s = {1, 10, 20} is thefrequency of subspace update, i.e., compute the eigen-space every s iterates. The X-axis and Y-axisrefer to Figure 4. For Fashion MNIST, PDP-SGD starts projection at 15-th epoch. PDP-SGD with areduced eigen-space computation also improves the accuracy over DP-SGD.
Figure 7: Comparison of DP-SGD and PDP-SGD for MNIST. (a-c) report the training accuracy and(d-f) report the test accuracy for = {0.23, 0.30, 0.42}. The X-axis is the number of epochs, andthe Y-axis is the train/test accuracy. DPD-SGD outperforms DP-SGD for small .
Figure 8: Comparison of DP-SGD and PDP-SGD for Fashion MNIST. (a-b) report the trainingaccuracy and (c-d) report the test accuracy for = {0.23, 0.30}. Learning rare is 0.01 for bothPDP-SGD and DP-SGD. PDP-SGD starts projection at 15-th epoch. The X-axis is the number ofepochs, and the Y-axis is the train/test accuracy. DPD-SGD outperforms DP-SGD for small .
Figure 9: Training accuracy and test accuracy for PDP-SGD with k = {10, 20, 30, 50} for (a)MNIST with = 0.30; (b) MNIST with = 0.53. The X-axis and Y-axis refer to Figure 4. PDP-SGD with k = 50 performs better that the others in terms of the training and test accuracy.
Figure 11: Training accuracy and test accuracy for PDP-SGD with m = {50, 150, 200} for (a)MNIST with = 0.23; (b) MNIST with = 0.43. The X-axis and Y-axis refer to Figure 4. PDP-SGD with m = 150 and m = 200 performs slightly better that the other one in terms of the trainingand test accuracy.
Figure 10: Training accuracy and test accuracy for PDP-SGD with m = {50, 100, 150} for (a)MNIST with = 0.30; (b) MNIST with = 0.53. The X-axis and Y-axis refer to Figure 4. PDP-SGD with m = 150 and m = 100 perform better that the others in terms of the training and testaccuracy.
Figure 12: Training and test accuracy for DP-SGD and PDP-SGD with different privacy levels for(a) MNIST with 20,000 samples and (b) Fashion MNIST with 50,000 samples. The X-axis andY-axis refer to Figure 3. For small privacy loss , PDP-SGD outperforms DP-SGD.
Figure 13: Training and test accuracy for PDP-SGD with different frequency of eigen-spacecomputation for (a) MNIST with 50,000 samples and (b) Fashion MNIST with 50,000 samples.
