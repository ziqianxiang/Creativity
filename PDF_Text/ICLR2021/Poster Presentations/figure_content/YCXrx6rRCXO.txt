Figure 1: Plots of `2 distance reconstruction error when r = 1, 26 Numerical ExperimentsTo illustrate the performance of our fast binary embedding (Algorithm 1) and `2 distance recovery(Algorithm 2), we apply them to real-world datasets: Yelp open dataset1, ImageNet (Deng et al.,2009), Flickr30k (Plummer et al., 2017), and CIFAR-10 (Krizhevsky et al., 2010). All images areconverted to grayscale and resampled using bicubic interpolation to size 128 × 128 for images fromYelp, ImageNet, and Flickr30k and 32 × 32 for images from CIFAR-10. So, each can be representedby a 16384-dimensional or 1024-dimensional vector. The results are reported here and in AppendixA. We consider the two versions of our fast binary embedding algorithm from Theorem 4.2:Method 1. We quantize FJLT embeddings Φx, and recover distances based on Algorithm 2.
Figure 2: Plots of `2 distance reconstruction error with fixed p = 64 and optimal p = p(m)(d) MAPE of Method 2 (p = p(m))m becomes larger and larger. When r = 2 the error curves decay faster and eventually achieve thesame flat error because now the first term in (15) has power -3/2 while the second flat error term isindependent of r. Moreover, the performance of Method 2 is very similar to that of Method 1.
Figure 3: Plot of MAPE of Method 2 on four datasets with fixed p = 64 and order r = 1, 2Experiments on the Yelp dataset in Section 6 showed that Method 2 based on sparse JL embeddingsperforms as well as Method 1 which usues an FJLT to enforce the well-spreadness assumption. Now,we only focus on Method 2 and check its performance on all four different datasets: Yelp, ImageNet,Flickr30k, and CIFAR-10.
