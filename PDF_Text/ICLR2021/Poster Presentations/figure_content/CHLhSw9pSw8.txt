Figure 1: (a) The two shapes of the toy example. The four gray pixels correspond to a photon arrivalprobability of 1/4, i.e. a probability amplitude of 1/2. (b) The per-pixel photon arrival probabilityafter the orthogonal transformation is applied. The dark gray pixels correspond to a probability of1/8 and the light gray pixels to 1/2.
Figure 2:	(a) Fashion-MNIST most likely class given detection of a single photon at the correspondingpixel coordinates. Here, the classes are: 0=T-shirt/top, 1=Trouser, 2=Pullover, 3=Dress, 4=Coat,5=Sandal, 6=Shirt, 7=Sneaker, 8=Bag, 9=Ankle Boot. (b) Most likely digit-class given detection of asingle photon for MNIST. A non-quantum classifier cannot outperform one that looks up its answeron the corresponding table.
Figure 3:	The confusion matrices for the “Fashion-MNIST” and MNIST datasets when classicand quantum classifiers are used: (a) “Fashion-MNIST”/classic, (b) MNIST/classic, (c) “Fashion-MNIST”/quantum, (d) MNIST/quantum.
Figure 4: Projection of probability amplitudes for some samples of the “Fashion-MNIST” (a) andthe MNIST (b) datasets. The first image shows the original sample probability and the followingimages show the probability amplitudes for each class. We visualize the complex amplitude by usingbrightness to represent magnitude and hue for phase (the colormap for the phase is shown on the rightof each row.)Our factorization ansatz appears to contain a hidden constraint: we are forcing each image class to usethe same number of style-states. One could imagine, for instance, that a classifier might achieve evenhigher accuracy by treating image classes unevenly. Any such model that allows more style-spacedimesions for some classes can always be embedded into a model that allows more style-spacedimensions for all classes, so this question can be answered by padding to a larger Hilbert space.
Figure 5: Schematics of the experimental set-up. Top: ClassicalBaseline, Bottom: Quantum Set-Up.
