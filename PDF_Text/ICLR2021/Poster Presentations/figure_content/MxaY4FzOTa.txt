Figure 1: (a) Schematic representation of the proposed EBConv layer, and (b) t-SNE embeddingvisualisation of the features before the classifier along with the corresponding expert that was acti-vated for each sample. Points located closer to each other are more semantically and visually similar.
Figure 2: Effect of (a) depth and (b) groups on accuracy as a function of BOPs on Imagenet. Allresults are reported for Stage I models. Best viewed in color.
Figure 3: Effect of adding the 1 × 1 binary conv. layer after the grouped conv. layers. The dashedline connects same models with and without the 1 × 1 conv. layer.
Figure 4: The (a) vanilla and (b) proposed downsampling block. This module is used in 3 placesinside the network where the number of channels changes between macro-modules.
Figure 5: The overall network architecture of our final model defined as 1262-2-4:8:8:16. Inlinewith the current practice (Rastegari et al., 2016) the first (dark-red) and last layer (light-blue) arekept real. The yellow and dark-blue rectangles represent the binary residual blocks described inSections 4.2 and 4.3 of the main paper with the text indicating the number of output channels andthe number of groups. All blocks inside a macro-module, represented by a rectangle with dashedlines, operate at the same resolution, with the downsampling operation taking place at the first layervia strided convolution (dark-blue).
