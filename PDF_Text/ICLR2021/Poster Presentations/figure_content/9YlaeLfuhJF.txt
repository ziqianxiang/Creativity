Figure 1: A vanilla model trained on a skin can-cer dataset exhibits a subgroup performance gapbetween images of malignant cancers with andwithout colored bandages. GradCAM (Selvarajuet al., 2017) illustrates that the vanilla model spuri-ously associates the colored spot with benign skinlesions. With model patching, the malignancy ispredicted correctly for both subgroups.
Figure 2: The model patching framework. (Left) The class-subgroup hierarchy with each class Y dividedinto subgroups (e.g. Y = blonde hair into Z ∈ {male, female}). We learn inter-subgroup augmentations totransform examples between subgroups of a class. (Right) To patch the classifier, we augment examples bychanging their subgroup membership and then train with our subgroup consistency loss and robust objective.
Figure 4: Consistency loss ablations on Waterbirds. (Left) loss curves on the (landbird, water) subgroup.
Figure 5: CycleGAN learns mappings on domainsA ∪ B, where F maps examples to A and G mapsto B. To model possible distribution shift intro-duced by the generative model, we denote theirimages as Im(F) = A, Im(G) = B respectively.
Figure 6: Subgroup-coupled distributions separate the coupled set to which an example belongs (withrespect to their class), from its subgroup label.
Figure 7:	An example of data in MNIST-Correlation. Most even digits are clean while most odddigits contain a zigzag corruption.
Figure 8:	Results of inter-subgroup transformations on MNIST-Correlation.
Figure 9:	Results of inter-subgroup transformations on CelebA-Undersampled. Generation examplesuse the CycleGAN trained on the non-blonde class.
Figure 10:	Results of inter-subgroup transformations on Waterbirds. Generation examples use theCycleGAN trained on the landbirds class.
