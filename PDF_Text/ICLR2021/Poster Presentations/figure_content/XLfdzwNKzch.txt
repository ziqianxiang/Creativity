Figure 1: Conceptual comparison of the backward computation graph between (a) end-to-end back-propagation and (b) greedy block-wise learning with K = 2.
Figure 2: An illustration of our search problem when L = 4, K = 3 and M = 3. A search procedureshould make two types of categorical choices at each layer: whether to stop the gradient flow andwhich auxiliary network to use. These two decision choices are represented by meta-variables α andβ, respectively. Dashed lines represent possible decision choices, and gray ones are not chosen.
Figure 3: Comparison of classification errors of ResNet-101/152 when learning with increasing K.
Figure 5: Decoupled structures of ResNet-152 searched by SEDONA with K = {4, 8}.
Figure 6: Classification errors ofVGG-19 (0.25× width) with 30random configurations on CIFAR-10atK =4.
Figure 7: Comparison of classification errors of ResNet-101 when learning with increasing K, in-cluding Features Replay (Huo et al., 2018a).
Figure 8: Comparison of the average cosine similarities for each timestep interval. We computethe cosine similarity between backprop gradients and DGL/SEDONA gradients of 3x3 convolutionkernel in each layer on CIFAR-10, while training with DGL and SEDONA, respectively.
