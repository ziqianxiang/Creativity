Figure 1: Illustrations of Two Practical Scenarios in Federated Semi-Supervised Learning (a) Labels-at-Client scenario: both labeled and unlabeled data are available at local clients. (b) Labels-at-Server scenario:labeled instances are available only at server, while unlabeled data are available at local clients.
Figure 2: Illustration of Inter-Client Consistency Loss. We illustrate each step of our inter-client consistencyregularization process performed at local client. We provide the detailed explanations in Section 3.1.
Figure 3: Illustrative Running Example of Labels-at-Client Scenario We describe training and commu-nication procedure between local and global modelunder Labels-at-Client scenario corresponding to theAlgorithm 1. More details are described in Section 4.
Figure 4: Illustrative Running Example of Labels-at-Server Scenario We depict learning and transmit-ting procedure between a client and the global serverunder Labels-at-Server scenario corresponding to theAlgorithm 2. Note that, in labels-at-server scenario, thelabeled data is only available at the server, and thusu) global model at the server learns on labeled data, whilelocal models at clients learn on only unlabeled data.
Figure 5: Test Accuracy Curves on Batch-IID & NonIID Tasks We visualize test accuracy curves of modelperformance corresponding to the Table 1. Note that the SL (Supervised Learning) models learn on both S andU with full labels, and are utilized as the upper bounds for each experiment.
Figure 6: Ablation Study and Additional Analysis on FedMatch Algorithm We study effectiveness of eachcomponents of our method, (a) inter-client consistency loss and (b) parameter decomposition. (c) We effectivelytackle the inter-task interference. (d) Performance improvement of our method when labeled data is increased.
Figure 7: Illustration of Dataset Partition for Experimental Tasks We split the dataset D into a set oflabeled data S and a set of unlabeled data U . U is divided into K subsets which are distributed to K clients(Batch Task). For streaming tasks, we further split all instances in each subset into T subsets for T streamingsteps. For class-imbalanced tasks, we additionally control the number of instances per class for each client.
Figure 8:	Communication Cost Curves of FedMatch (ResNet-9) Corresponding to the Table 1 and 2. Wemeasure the communication costs for each parameters, ∆σ and ∆ψ, during training phase. The communicationcosts under the labels-at-client scenario are visualized in (a) and (b) on the upper row. (c) and (d) on the lowerrow represent the communication costs under labels-at-server scenario.
Figure 9:	Experimental Results on COVID-19 Radiography Dataset. Left: Performance comparison of ourmethod (FedMatch) with the naive federated semi-supervised learning algorithms (FedProx-UDA/FixMatch).
