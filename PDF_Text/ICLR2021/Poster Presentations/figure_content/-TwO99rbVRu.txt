Figure 1: Overview of unlabeled data training branch. Given an image, the weakly augmentedversion is fed into the network to get the decoder prediction and Self-attention Grad-CAM (SGC).
Figure 2: Visualization of pseudo labels and other predictions. The generated pseudo label byfusing the predictions from the decoder and SGC map is used to supervise the decoder (strong)predictions of the strongly-augmented counterpart.
Figure 3: Improvement over the strong supervised baseline, in a semi-supervised setting (w/unlabeled data) on VOC12 val (left) and COCO val (right).
Figure 4: Improvement over the strong supervised baseline, in a semi-supervised setting (w/image-level labeled data) on VOC12 val (left) and COCO val (right).
Figure 5: Ablation studies on different factors. See Section 4.3 for complete details.
Figure 6: Diagram of Self-attention Grad-CAM (SGC) .
Figure 7: Training. For each network component, we show the loss supervision and thecorresponding data.
Figure 8: Qualitative results of PASCAL VOC 2012. Models are trained with 1/16 pixel-levellabeled data in the training set.
Figure 9: Qualitative results of COCO. Models are trained with 1/512 pixel-level labeled data inthe training set. Note that white pixel in the ground truth indicates this pixel is not annotated forevaluation.
