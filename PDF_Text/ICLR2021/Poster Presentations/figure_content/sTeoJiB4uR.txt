Figure 1: The residual blocks used in the binarized ResNet VAE and Flow++ models,using both binary and floating-point activations. The BWN Gate layer is a binary weightnormalized 1 X 1 convolution followed by a gated linear unit. We display the binary valuedtensors with thick red arrows.
Figure 2: Test loss values during training of the ResNet VAE and Flow++ models on theCIFAR dataset. Subfigures (a) and (b): models with binary weights and either binary orreal-valued activations. Compared to the model with real-valued weights and activations,and a baseline with the residual layers set to the identity. Subfigures (c) and (d): the effectof increasing the width of the residual channels, and ablations.
