Figure 1: We demonstrate that adversarially-trained (i.e., robust) DNNs transfer better and faster tonew domains with the process shown in (a): A ResNet50 is trained adversarially or non-adversarially(i.e., naturally) on the source dataset. Then, we fine-tune both of these source models on the targetdataset. We hypothesize the robust features in robust models that encode more humanly percep-tible representations, such as textures, strokes and lines, as seen in (b), are responsible for thisphenomenon. See Appendix A.1 for details on how we generated the images in (b).
Figure 2: Robust models generalize better to new domains, especially with fewer training imagesin the target domain. (a) Shows the test accuracy on the six target datasets (color-coded as in (b))for various subset sizes. (b) Shows the test accuracy delta, defined as the robust model test accuracyminus natural model test accuracy. The solid line is the mean and its shade is the 95% confidenceinterval. Both the robust and natural models are ResNet50s’ trained on ImageNet. The robust modeluses a kδk2 ≤ 3 constraint. Both models fine-tune three convolutional blocks on the target dataset.
Figure 3: Robust models transfer faster. (a) Shows the test accuracy during the fine-tuning processon the six target datasets (color-coded as in (b)). (b) Shows the test accuracy delta, defined as therobust model test accuracy minus the natural model test accuracy. The solid line is the mean and itsshade is the 95% confidence interval. Both the robust and natural models are ResNet50s’ trained onImageNet. The robust model uses a kδ k2 ≤ 3 constraint. Both models fine-tune three convolutionalblocks using a random subset of 3,200 images (〜5%) of the target dataset.
Figure 4: The optimal number of fine-tuned blocks is somewhere between one and three. (a, b)Shows the test accuracy of the robust model trained on ImageNet using the kδ k2 ≤ 3 constraint withvarious numbers of fine-tuned blocks (0, 1, 3, or 9). (a) Shows the test accuracy on each of the sixtarget datasets (color-coded as in (b)). (b) Shows the test accuracy delta, defined as the test accuracyof the model with three fine-tuned blocks minus the test accuracy of the model with one fine-tunedblock. The solid line is the mean and its shade is the 95% confidence interval.
Figure 5: Shows the test accuracy on target datasets, (a) CIFAR-10 and (b) SVHN, of three robustmodels. (c) Shows that source models trained with lower transfer better to target domains that aresimilar to ImageNet, as shown by the test accuracy delta between the ∣∣δ∣∣∞ ≤ 康 model and the∣∣δk∞ ≤ 2∣5 model. (d, e) Shows the test accuracy delta between the '2 norm with e = 3 and eachof the two '∞ models: e =羡 in (d), and e = 2∣8∣ in (e). In both (d, e) the '2 norm constraintoutperforms both of the '∞ constraints.
Figure 6: Adversarially-trained (i.e, robust) models have more similar-looking influential imagesin the target dataset than the non-adversarially-trained (i.e., natural) model. The top row shows arandomly selected test image, for each of the ten categories. The middle and bottom rows displaythe most influential images, for the robust and natural models, respectively.
Figure 7: Top influential image labels in the robust model match test image labels more often thanin the natural model. (a) Shows the influence values (standardized by their matrix norm) of eachtraining image on each test image, sorted by their label as in Figure 6, for both the natural (left)and robust (right) models. (b) Displays the percentage of times that the label of the top-k influentialimage in the training set matches the label in the test image being evaluated.
Figure 8: Shows the test accuracy delta, defined as the transfer test accuracy of the source modelstrained with PGD(20) in (a), PGD(1) in (b), and Gaussian in (c), minus the naturally-trained model.
Figure 9: Fine-tuning setup: (a) Zero blocks. (b) One block. (c) Three blocks (d) Nine blocks. Eachblock has Three convolutional layers.
Figure 10: Robust models transfer faster. (a) Shows the test accuracy during the fine-tuning processon the six target datasets (color-coded as in (b)). (b) Shows the test accuracy delta, defined as therobust model test accuracy minus the natural model test accuracy. The solid line is the mean and itsshade is the 95% confidence interval. Both the robust and natural models are ResNet50s’ trained onImageNet. The robust model uses a kδ k2 ≤ 3 constraint. Both models fine-tune three convolutionalblocks using a random subset of 800 images (〜2%) in (1) and 12,800 images (〜26%) in (2) of thetarget dataset.
Figure 11: It’s sub-optimal to fine-tune either zero (only FC layer) or nine convolutional blocks, asopposed to one or three. (a) Test accuracy on each of the six target datasets (color-coded as in (b))for various subset sizes and fine-tuning various number of blocks: zero, one, three, or nine. (b) Testaccuracy delta is defined as the test accuracy with three fine-tuned blocks minus the test accuracywith one fine-tuned block. Adversarial constraints used to train on the source dataset (ImageNet):(1) ∣∣δ∣∣2 ≤ 3, (2) ∣∣δ∣∣∞ ≤ 245, or (3) ∣∣δ∣∣∞ ≤ 蔡.The solid line is the mean and the shade is the95% confidence interval.
