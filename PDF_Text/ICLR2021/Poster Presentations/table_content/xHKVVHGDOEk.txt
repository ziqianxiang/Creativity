Table 1: Correlation estimates on MNIST And CIFAR-10 ; A=Test-point with highest loss; B=Test-point at the 50th percentile of test-loss spectrum; P=Pearson correlation; S=Spearman correlationdecay factor is important in getting high-quality influence estimates. For this specific CNN archi-tecture, we notice that the correlations start decreasing when the weight-decay factor is greater than0.01. Moreover, from Fig. 3-(a,b), we find that the selection of test-point also has a strong impact onthe quality of influence estimates. For example, when the network is trained with weight-decay andthe influence estimates are computed for top influential training points, we notice that the Spearmancorrelation estimates range from 0.92 to 0.38 across different test-points and have a high variance.
Table 2: Computational running times for influence function across different architectures9.4	Running TimesIn this section, we provide computational running times for (first-order) influence function estima-tions. We note that in models with a large number of parameters, the influence computation isrelatively slow. However, even in large deep models, it is still faster than re-training the modelfor every training example. In our implementation, for a given test-point ztest , we first computeC = H-Ty'(hθ* (Ztesty) once which is the most computationally expensive step. We then com-pute a vector dot product i.e. CTV'(hθ* (zi)) ∀i ∈ [1, n]. In Table 2, We provide the computationalrunning times for estimating influence functions in different network architectures.
