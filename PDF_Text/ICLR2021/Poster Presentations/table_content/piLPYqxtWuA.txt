Table 1: Audio quality comparison.
Table 2: The comparison of training time and inference latency in waveform synthesis. The trainingtime of FastSpeech includes teacher and student training. RTF denotes the real-time factor, thatis the time (in seconds) required for the system to synthesize one second waveform. The trainingand inference latency tests are conducted on a server with 36 Intel Xeon CPUs, 256GB memory, 1NVIDIA V100 GPU and batch size of 48 for training and 1 for inference. Besides, we do not includethe time of GPU memory garbage collection and transferring input and output data between the CPUand the GPU. The speedup in waveform synthesis for FastSpeech is larger than that reported in Renet al. (2019) since we use Parallel WaveGAN as the vocoder which is much faster than WaveGlow.
Table 3: Standard deviation (σ), skewness (γ), kurtosis (K) and average DTW distances (DTW) ofpitch in ground-truth and synthesized audio.
Table 4: The mean absolute error (MAE) of the energy in synthesized speech audio.
Table 5: The comparison of the duration from teacher model and MFA. ∆ means the average ofabsolute boundary differences.
Table 6: CMOS comparison in the ablation studies.
Table 7: Hyperparameters of Transformer TTS, FastSpeech and FastSpeech 2/2s.
