Table 1: Robust accuracy (under adversarial attack) obtained by finetuning a linear head on top ofrobust representations trained on Cifar- 1 0.
Table 2: Clean (no perturbations) and robust (under adversarial attack) accuracy obtained whentraining robust and non-robust representations on CIFAR- 1 0 against `2 norm-bounded perturbationsof size = 128/255. We evaluate the representations by finetuning a robust and non-robust linearhead on CIFAR-10, Stl-10 and CIFAR-100. Table 6 in the appendix shows '∞ perturbations.
Table 3: Clean (no perturbations) and robust (under adversarial attack) accuracy obtained by netWorksof different sizes on Cifar-1 0 against '∞ norm-bounded perturbations of size e = 8/255.
Table 4: Clean (no perturbations) and robust (under adversarial attack) accuracy obtained by rep-resentations trained against attacks of different strength on Cifar-10 against '∞ norm-boundedperturbations of size e = 8/255.
Table 5: Clean (no perturbations) and robust (under adversarial attack) accuracy obtained whentraining robust representations on IMAGENET against '∞ norm-bounded perturbations of size e =4/255. We evaluate the representations by training/finetuning a robust and non-robust linear headon IMAGENET with varying numbers of labels. For completeness, we also add results for `2 norm-bounded perturbations of size e = 128/255Training of Linear Head	Norm	RADIUS	ImageNet (100%)		ImageNet (10%)		ImageNet (1%)				Clean	Robust	Clean	Robust	Clean	RobustRobust (AT)	'∞	e = 4/255		65.14%	45.44%	62.39%	41.58%	47.07%	31.57%Non-robust			65.27%	43.83%	62.40%	41.06%	47.64%	31.99%Robust (AT)	'2	e = 128/255	69.64%	65.48%	66.39%	61.90%	55.06%	51.00%Transfer without adversarial training against '∞ norm-bounded perturbations. In SUbSec-tion 4.2, we evaluate how robust accuracy degrades when linear classifiers trained on top of BY-ORL representations are not trained robustly. In Table 2, we evaluate models trained against `2norm-bounded perturbations. In Table 6, we evaluate models trained against '∞ norm-boundedperturbations. In both cases, non-robust downstream classifiers are able to exhibit non-trivial levelsof robustness that remain within a few percentage points of the robustly trained ones.
Table 6: Clean (no perturbations) and robust (under adversarial attack) accuracy obtained whentraining robust and non-robust representations on CIFAR-10 against '∞ norm-bounded perturbationsof size e = 8/255. We evaluate the representations by training/finetuning a robust and non-robustlinear head on Cifar- 1 0, Stl-10 and Cifar- 1 00.
