Table 1: Here “Time” is the time needed to embed a data point, while “Space” is the space needed tostore the embedding matrix. “Storage” contains the memory usage to store each encoded sequence.
Table 2: Comparison between the proposed method and product quantization per data pointA direct comparison of the associated errors is not possible due to the fact that the error associatedwith data-dependent product quantization is a function of the input data distribution, and the conver-gence of the k-means algorithm. Nevertheless, one can note some tradeoffs from Table 2. Namely,the embedding time and the space needed to store our embedding matrix are lower than those asso-ciated with product quantization. On the other hand, the space needed to store the embedded datapoints and the query time associated with product quantization depend on the parameter choices Mand k*, which also affect the resulting accuracy. Finally, we note that product quantization (using k-means clustering) is associated with a pre-processing time O(nN k*t), which is significantly largerthan our method.
