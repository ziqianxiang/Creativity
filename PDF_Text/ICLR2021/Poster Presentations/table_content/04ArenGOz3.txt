Table 1: Results for Polygons and Digits Performance measured in [10-5] as Chamfer loss forDigits and Hungarian loss for Polygons. Lower is better. Training with the Chamfer loss failson Polygons, while training with the Hungarian loss fails on Digits. The trade-off in the type ofrandomness that can be handled by an assignment-based set loss does not occur for our approach.
Table 2: Point-cloud auto-encoding Set size root-mean-square error (RMSE) for set MNIST. Both C-DSPN andTSPN (Kosiorek et al., 2020) first infer the set size, beforegenerating the set. Our approach outperforms both base-lines, without explicit set size supervision.
Table 3: Point-cloud auto-encoding Performance measured in Chamfer and Hungarian loss in unitsof [10-4] for set MNIST. The Chamfer/Chamfer result is from (Zhang et al., 2019), other numbersbased on author-provided code. Our approach outperforms both DSPN baselines on both metrics,despite the baselines being directly trained with Chamfer or Hungarian loss.
Table 4: Object set prediction on CLEVR Baselines from Kosiorek et al. (2020) and Zhang et al.
Table 5: Subset Anomaly Detection Performances for the two test setups: 1. Unambiguous +Ambiguous and 2. Ambiguous only. Our method outperforms the baseline, which we derived fromDeepSets (Zaheer et al., 2017), on all metrics.
