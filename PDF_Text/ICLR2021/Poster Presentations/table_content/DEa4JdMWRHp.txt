Table 1: Performance comparison on the Lorenz 96 model with F = 10 and 40. Inference isperformed on each replicate separately, standard deviations (SD) are evaluated across 5 replicates.
Table 2: Performance comparison on simulated fMRI time series. eSRU fails to shrink any weightsto exact zeros, therefore, we have omitted accuracy and balanced accuracy score for it.
Table 3: Performance comparison on the multi-species Lotka-Volterra system. Next to accuracy andbalanced accuracy scores, we evaluate BA scores for detecting positive and negative interactions.
Table 4: Various sparsity-inducing penalty terms, described by Nicholson et al. (2017), for a lin-ear VAR of order K. Herein, Ψ = [Ψ1 Ψ2 ... ΨK] ∈ Rp×Kp (cf. Equation 11), andΨk:K = [Ψk Ψk+ι ... Ψk]. Different penalties induce different sparsity patterns in coef-ficient matrices.
Table 5: Average training and inference time, in seconds, for the methods. Inference was performedon time series generated from the linear model (see Appendix L), simulated fMRI time series (seeSection 4.1.2), and the Lorenz 96 system (see Section 4.1.1).
Table 6: Hyperparameter values for Lorenz 96 datasets with F = 10 and 40. Herein, K denotesmodel order (maximum lag). If a hyperparameter is not applicable to a model, the correspondingentry is marked by ‘NA’.
Table 7: Hyperparameter values for simulated fMRI time series.
Table 8: Hyperparameter values for multi-species Lotka-Volterra time series.
Table 9: Comparison of balanced accuracy scores for GVAR and DBNs. Standard deviations (SD)are taken across 5 independent replicates.
Table 10: Performance on synthetic time series with linear dynamics, given by Equation 14. Aver-ages and standard deviations are evaluated across 10 independent simulations. eSRU failed to shrinkweights to exact 0s, therefore, we omit accuracy and BA scores for it.
Table 11: RMSEs of models on held-out data. Averages and standard deviations were taken across5 independent replicates.
