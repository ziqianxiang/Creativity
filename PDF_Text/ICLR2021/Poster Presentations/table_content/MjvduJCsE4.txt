Table 1: Comparing NNs and against the equivalent NNGP-C on CIFAR-10 and evaluated on severaltest sets. We observe that the NNGP-C outperforms its parametric NN counterpart on every metric.
Table 2: Result for regression benchmark on UCI Datasets. Note ±x reports the standard erroraround estimated mean for 20 splits. We compare to strong baselines: PMP-MV (Sun et al., 2017),MC-Dropout from Mukhoti et al. (2018) and Deep Ensembles (Lakshminarayanan et al., 2017)Average RMSE Test PerformanceDataset	(m, d)	PBP-MV	Dropout	Ensembles	RBF	FC-NNGP-RBoston Housing	(506, 13)	3.11 ± 0.15	2.90 ± 0.18	3.28 ± 1.00	3.24 ± 0.21	3.07 ± 0.24Concrete Strength	(1030, 8)	5.08 ± 0.14	4.82 ± 0.16	6.03 ± 0.58	5.63 ± 0.24	5.25 ± 0.20Energy Efficiency	(768, 8)	0.45 ± 0.01	0.54 ± 0.06	2.09 ± 0.29	0.50 ± 0.01	0.57 ± 0.02Kin8nm	(8192, 8)	0.07 ± 0.00	0.08 ± 0.00	0.09 ± 0.00	0.07 ± 0.00	0.07 ± 0.00Naval Propulsion	(11934, 16)	0.00 ± 0.00	0.00 ± 0.00	0.00 ± 0.00	0.00 ± 0.00	0.00 ± 0.00Power Plant	(9568, 4)	3.91 ± 0.04	4.01 ± 0.04	4.11 ± 0.17	3.82 ± 0.04	3.61 ± 0.04Wine Quality Red	(1588, 11)	0.64 ± 0.01	0.62 ± 0.01	0.64 ± 0.04	0.64 ± 0.01	0.57 ± 0.01Yacht Hydrodynamics	(308, 6)	0.81 ± 0.06	0.67 ± 0.05	1.58 ± 0.48	0.60 ± 0.07	0.41 ± 0.04Average Negative Log-Likelihood Test PerformanceBoston Housing	(506, 13)	2.54 ± 0.08	2.40 ± 0.04	2.41 ± 0.25	2.63 ± 0.09	2.65 ± 0.13Concrete Strength	(1030, 8)	3.04 ± 0.03	2.93 ± 0.02	3.06 ± 0.18	3.52 ± 0.11	3.19 ± 0.05Energy Efficiency	(768, 8)	1.01 ± 0.01	1.21 ± 0.01	1.38 ± 0.22	0.78 ± 0.06	1.01 ± 0.04Kin8nm	(8192, 8)	-1.28 ± 0.01	-1.14 ± 0.01	-1.20 ± 0.02	-1.11 ± 0.01	-1.15 ± 0.01Naval Propulsion	(11934, 16)	-4.85 ± 0.06	-4.45 ± 0.00	-5.63 ± 0.05	-10.07 ± 0.01	-10.01 ± 0.01Power Plant	(9568, 4)	2.78 ± 0.01	2.80 ± 0.01	2.79 ± 0.04	2.94 ± 0.01	2.77 ± 0.02
Table 3: NNGP-LL with EfficientNet-B3 fine tuned on CIFAR10 as an embedding and evaluatedover all CIFAR10 corruptions and intensities. We show the quartiles over all corrupted variants forseveral different last-layer methods of obtaining uncertainties. Vanilla denotes fine tuned network,Ensembles refers to Lakshminarayanan et al. (2017) and Ens/Drp/T refers to combining Ensembles,MC-Dropout (Gal & Ghahramani, 2016) and temperature scaling (Guo et al., 2017). Center columnis baseline where last-layer is replaced with an RBF kernel instead of NNGP. Right column groupsare NNGP-LL results. More specifically, we train a three-layer FC network with dropout using inputfrom the embedding from EfficientNet-B3 and report results in the middle columns. The rightmostcolumns show that NNGP-LL can be well-calibrated with very little training data (100, 1K, 5K, 10K,and full dataset are shown). See Fig. S5 for fine-grained box plots for each corruption level.
Table S1: Performance of NNs, where all of the NN’s hyperparameters are tuned independently withGoogle Vizier hyperparameter tuner (Golovin et al., 2017a). In addition we show results on all Fogcorruptions that were omitted from Table 1.
Table S2: Quartiles of Brier score, negative-log-likelihood and ECE over all CIFAR10 corruptionsfor methods in Fig. 2.
Table S3: Quartiles of Brier score, negative-log-likelihood, and ECE over all CIFAR10 corruptionsfor methods in Fig. S6 using EfficientNet-B3 embedding. The first five columns are the same as themethods in Table 3, whereas the last two columns use the same embedding architecture but where allthe weights are fine tuned (FT) on CIFAR10. See Fig. S6 for the corresponding box-plot.
Table S4: Quartiles of Brier score, negative-log-likelihood, ECE and accuray over all CIFAR10corruptions for MetaInit Embedding NNGP-LL and MetaInit trained networks in Fig. S8.
