Table 1: Our ERM baseline outperforms the state-of-the-art in terms of average domain generalizationperformance, even when picking the best competitor per dataset.
Table 2: Learning setups. Ld and Ud denote the labeled and unlabeled distributions from domain d.
Table 3: DG accuracy for all algorithms, datasets and model selection criteria in DomainBed. Theseexperiments compare fourteen popular DG algorithms across seven benchmarks in the exact sameconditions, showing the competitive performance of ERM.
Table 4: Ablation study on ERM showing the impact of (i) using raw images versus data augmentation, and (ii) using ResNet-18 versus ResNet-50 models. Model selection: training-domain validation set.						Algorithm	VLCS	PACS	OfficeHome	TerraInc	DomainNet	AvgERM (raw, 18)	75.8 ± 0.3	79.6 ± 0.3	61.0 ± 0.1	35.0 ± 1.3	35.8 ± 0.2	62.4ERM (aug,18)	75.8 ± 0.1	79.1 ± 0.8	60.0 ± 0.6	40.0 ± 0.6	35.3 ± 0.0	62.8ERM (raw, 50)	78.6 ± 0.1	83.2 ± 0.6	67.7 ± 0.2	41.5 ± 2.5	41.4 ± 0.1	66.0ERM (aug, 50)	77.5 ± 0.4	85.5 ± 0.2	66.5 ± 0.3	46.1 ± 1.8	40.9 ± 0.1	66.65.2 Ablation study on ERMTo better understand our ERM performance, we perform an ablation study on the neural networkarchitecture and the data augmentation protocol. Table 5.2 shows that using a ResNet-50 neuralnetwork architecture, instead of a smaller ResNet-18, improves DG test accuracy by 3.7 points.
Table 5: Previous state-of-the-art in the literature of domain generalization.
Table 6: Hyperparameters, their default values and distributions for random search.
