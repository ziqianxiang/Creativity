Table 1: DP runtime and space used by PLBF as we increase the discretization N in the URLs datasetN	DP RUntime(in Sec)	PLBF Size (in Kb)-30-	T.36	2952.33100	^52	2944.68500	TT39	2933.091000	Éªss	2928.762000	56.12	2926.79Table 2: DP runtime and space used by PLBF as we increase the discretization N in the EMBER datasetE.4 Construction Time for Various BaselinesHere we look at the construction time breakdown for the PLBF and various alternatives, with thegoal of seeing the cost of in terms of construction time for using the more highly tuned PLBF. Theconstruction time of all the learned Bloom filters includes the model training time and parameterestimation time, which are not required for the standard Bloom filter construction process. Since16Published as a conference paper at ICLR 2021we use the same model for all learned baselines, the model construction time is the same for all ofthem. In Fig.6, we plot the construction time breakdown for various baselines in order to achievean approximate empirical false positive rate of 0.001. Recall that the AdaBF and Sandwichingapproaches use heuristics to estimate their parameters and unsurprisingly they therefore seemssomewhat faster than PLBF. However, for N = 100 we see the parameter estimation time is smaller
Table 2: DP runtime and space used by PLBF as we increase the discretization N in the EMBER datasetE.4 Construction Time for Various BaselinesHere we look at the construction time breakdown for the PLBF and various alternatives, with thegoal of seeing the cost of in terms of construction time for using the more highly tuned PLBF. Theconstruction time of all the learned Bloom filters includes the model training time and parameterestimation time, which are not required for the standard Bloom filter construction process. Since16Published as a conference paper at ICLR 2021we use the same model for all learned baselines, the model construction time is the same for all ofthem. In Fig.6, we plot the construction time breakdown for various baselines in order to achievean approximate empirical false positive rate of 0.001. Recall that the AdaBF and Sandwichingapproaches use heuristics to estimate their parameters and unsurprisingly they therefore seemssomewhat faster than PLBF. However, for N = 100 we see the parameter estimation time is smallerthan the key insertion time and model training time. The parameter estimation time for PLBF varieswith the level of discretization we use for the DP algorithm. The PLBF with N = 1000 takes thelongest to execute while standard Bloom filter is fastest baseline. As shown in Table1 above, usingN = 1000 gives only a slight improvement in size. We therefore believe that if construction time isan issue, as for situations where one might want to re-learn and change the filter as data changes, onecan choose parameters for PLBF construction that would still yield significant benefits over previousapproaches.
