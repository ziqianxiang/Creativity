Table 1: Performances on the synthetic, COMPAS, and AdultCensus test sets w.r.t. equal opportunity(EO). We compare FairBatch with three types of baselines: (1) non-fair method: LR; (2) fairtraining via pre-processing: Cutting, RW (Kamiran and Calders, 2011), and LBC (Jiang and Nachum,2020); (3) fair training via in-processing: FC (Zafar et al., 2017b), AD (Zhang et al., 2018), andAdaFair (Iosifidis and Ntoutsi, 2019). Experiments are repeated 10 times.
Table 2: Performances on the synthetic, COMPAS, and AdultCensus test sets w.r.t. demographicparity (DP). The other settings are identical to those in Table 1.
Table 3: Performances of the pre-trained models fine-tuned with FairBatch on the UTKFace testset w.r.t. equalized odds (ED) for two fairness scenarios. While Tables 1 and 2 already demonstrateFairBatch’s performance against the state of the arts, the emphasis here is more on FairBatch’susability where it is easy to adopt and yet improves the fairness of existing models.
Table 4: Performances on the synthetic, COMPAS, and AdultCensus test sets w.r.t. equalized odds(ED). The other settings are identical to Table 1.
Table 5: Wall CloCk times (in seConds) of the experiments in Table 1 using the same settings.
