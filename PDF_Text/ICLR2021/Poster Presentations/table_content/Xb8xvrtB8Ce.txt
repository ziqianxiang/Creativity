Table 1: Hyperparameter settings and tricks used to implement different AT methods on CIFAR-10.
Table 2: Test accuracy (%) under different early stopping and warmup on CIFAR-10. The model isResNet-18 (results on WRN-34-10 is in Table 14). For early stopping attack iter., we denote, e.g., 40/ 70 as the epochs to increase the tolerance step by one (Zhang et al., 2020). For warmup, the learningrate and the maximal perturbation linearly increase from zero to preset values in 10 / 15 / 20 epochs.
Table 3: Test accuracy (%) under different batchsize and learning rate (l.r.) on CIFAR-10. Thebasic l.r. is 0.1, while the scaled l.r. is, e.g., 0.2 forbatch size 256, and 0.05 for batch size 64.
Table 4: Test accuracy (%) under differ-ent degrees of label smoothing (LS) onCIFAR-10. More evaluation results under,e.g., PGD-1000 can be found in Table 17.
Table 5: Test accuracy (%) using different optimizers on CIFAR-10. The model is ResNet-18 (resultson WRN-34-10 is in Table 15). The initial learning rate for Adam and AdamW is 0.0001.
Table 6: Test accuracy (%) under different non-linear activation function on CIFAR-10. The modelis ResNet-18. We apply the hyperparameters recommended by Xie et al. (2020) on ImageNet for theactivation function. Here the notation ^ indicates using weight decay of 5 X 10-5, where applyingweight decay of 5 Ã— 10-4 with these activations will lead to much worse model performance.
Table 7: Test accuracy (%) under different BN modes on CIFAR-10. We evaluate across severalmodel architectures, since the BN layers have different positions in different models.
Table 8: The default hyperparameters include batch size 128 and SGD momentum optimizer. The ATframework is PGD-AT. We highlight the setting used by the implementation in Rice et al. (2020).
Table 9: Test accuracy (%). The AT framework is TRADES. We highlight the setting used by theoriginal implementation in Zhang et al. (2019b). As listed in Table 16, our retrained TRADES modelscan achieve state-of-the-art performance in the AutoAttack benchmark.
Table 10: Test accuracy (%). The considered AT frameworks are FastAT and FreeAT. The modelarchitecture is WRN-34-10. Detailed settings used for these defenses are described in Sec. 3.5.
Table 11: We summarize the code links for the referred defense methods in Table 1.
Table 12: Number of parameters for different model architectures.
Table 13: Test accuracy (%) of TRADES. We compare with the results in Table 6 to check the effectof smooth activation function on TRADES, as well as the compatibility of it with eval BN mode.
Table 14: Test accuracy (%) under different early stopping and warmup on CIFAR-10. The modelis WRN-34-10. For early stopping attack iterations, we denote, e.g., 40 / 70 as the epochs to increasethe tolerance step by one (Zhang et al., 2020). For warmup, the learning rate (l.r.) and the maximalperturbation (perturb.) linearly increase from zero to the preset value in the first 10 / 15 / 20 epochs.
Table 15: Test accuracy (%) using different optimizers on CIFAR-10. The model is WRN-34-10.
Table 16: We retrieve the results of top-rank methods from https://github.com/fra31/auto-attack. All the methods listed below do not require additional training data on CIFAR-10.
Table 17: Test accuracy (%) under different label smoothing on CIFAR-10. The model is ResNet-18 trained by PGD-AT. We evaluate under PGD-1000 with different number of restarts and stepsizes. Here we use the cross-entropy (CE) objective and C&W objective (Carlini & Wagner, 2017a),respectively. We also evaluate under the SPSA attack (Uesato et al., 2018) for 10, 000 iteration steps,with batch size 128, perturbation size 0.001 and learning rate of 1/255.
