Table 1: RoamingOmniglot OC-FSL results. Max 5 env,150 images, 50 cls, with 8×8 occlusion.
Table 2: RoamingRooms OC-FSL results. Max 100 images and 40 classes.
Table 3: RoamingImageNet OC-FSL results. Max 150 images and 50 classes. * denotes CNNpretrained using regular classification.
Table 4: Effect of forgetting over a time interval on RoamingOmniglot. Average accuracy vs. thenumber of time steps since the model has last seen the label of a particular class.
Table 5: Ablation of CPM architectural com-ponents on RoamingOmniglotMethod	hRNN	βt,γt	Metric mt	GAU	Val APO-PN					91.22No hRNN		✓	✓		92.52hRNN only	✓				93.48No metric mt	✓	✓			93.61No βt,γt ht = htRNN	✓		✓		93.98	✓	✓	✓		93.70CPM Avg. Euc	✓	✓	✓		94.08CPM Avg. Cos	✓	✓	✓		94.57CPM GAU Euc	✓	✓	✓	✓	94.11CPM GAU Cos	✓	✓	✓	✓	94.65Table 6: Ablation of semi-supervised learningcomponents on RoamingOmniglotMethod	RNN	Prototype	βtw , γtw	GAU	Val APO-PN					90.83O-PN		✓			89.10O-PN		✓	✓		91.22CPM					92.57
Table 6: Ablation of semi-supervised learningcomponents on RoamingOmniglotMethod	RNN	Prototype	βtw , γtw	GAU	Val APO-PN					90.83O-PN		✓			89.10O-PN		✓	✓		91.22CPM					92.57CPM	✓				93.16CPM	✓	✓			93.20CPM	✓	✓	✓		94.08CPM	✓	✓	✓	✓	94.65Effect of forgetting: As the number of learned classes increases, we expect the average accuracyto drop. To further investigate this forgetting effect, we measure the average accuracy in terms of thenumber of time steps the model has last seen the label of a particular class. Itis reported in Table 4 andin Appendix C Table 13, 14, where we directly compare CPM and OPN to see the effect of temporalcontext. CPM is significantly better than OPN on 1-shot within a short interval, which suggests thatthe contextual RNN makes the recall of the recent past much easier. On RoamingImageNet, OPNeventually surpasses CPM on longer horizon, and this can be explained by the fact that OPN hasmore stable prototypes, whereas prototypes in CPM could potentially be affected by the fluctuationof the contextual RNN over a longer horizon.
Table 7: Continual & few-shot learning datasets					Images	Sequences	Classes	ContentPermuted MNIST (Lecun et al., 1998)	60K	-	-	Hand written digitsOmniglot (Lake et al., 2015)	32.4K	-	1.6K	Hand written charactersCIFAR-100 (Krizhevsky, 2009)	50K	-	100	Common objectsmini-ImageNet (Vinyals et al., 2016)	50K	-	100	Common objectstiered-ImageNet (Ren et al., 2018)	779K	-	608	Common objectsOpenLORIS (She et al., 2019)	98K	-	69	Small table-top obj.
Table 8: Comparison of past FSL and CL paradigms vs. our online contextualized FSL (OC-FSL).
Table 9: Split information for RoamingOmniglot. Each column is an alphabet and we include allthe characters in the alphabet in the split. Rows are continuation of lines.
Table 10: Split information for RoamingRooms. Each column is the ID of an indoor world. Rowsare continuation of the lines.
Table 11: RoamingRooms dataset split sizeSplit	Worlds	Sequences	FramesTrain	60	4,699	823,444Val	20	725	125,823Test	10	1,547	271,335Total	90	6,971	1,220,602A) Instance Category DistributionC) Objects / Frame D) Frames Between	E) Instance DistributionB) Unique Viewpoints / 100 FramesF) Viewpoint DistributionFigure 7: Additional statistics about our RoamingRooms dataset.
Table 12: Split information for the Kylberg texture dataset. Each column is an texture type. Rowsare continuation of lines.
Table 13: Effect of forgetting over a time interval on RoamingRooms. Average accuracy vs. thenumber of time steps since the model has last seen the label of a particular class.
Table 14: Effect of forgetting over a time interval on RoamingImageNet. Average accuracy vs.
