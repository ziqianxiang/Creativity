Table 1: Computational and storage complexities O(∙).
Table 2: Timing (seconds) on Cora, Citeseer, Pubmed and the large scale Open Graph Benchmark(OGB) which includes Products.____________________________________________methods	Cora	Citeseer	Pubmed	Products-SGC	0.45	-0.55	^078	^91APPNP	1.08	1.44	1.32	748S2GC	0.67	0.81	0.79	11.4Table 3: Clustering performance with three different metrics on four datasets.
Table 3: Clustering performance with three different metrics on four datasets.
Table 4: Test Micro F1 Score (%) aver-aged over 10 runs on Reddit. Results ofother models are taken from their papers.
Table 5: Test accuracy (%) averaged over 10 runson Citation networks.	____________methods	Cora	Citeseer	PubmedGCN	81.4± 0.4	70.9± 0.5-	79.0± 0.4GAT	83.3± 0.7	72.6± 0.6	78.5± 0.3FastGCN	79.8± 0.3	68.8± 0.6	77.4± 0.3GIN	77.6± 1.1	66.1 ± 0.9	77.0± 1.2DGI	82.5± 0.7	71.6± 0.7	78.4± 0.7SGC	81.0± 0.03	71.9± 0.11	78.9± 0.01MixHop	81.8±0.6	71.4±0.8	80.0±1.1APPNP	83.3±0.5	71.7±0.6	80.1±0.2Chebynet	78.0± 0.4	70.1 ± 0.5	78.0± 0.4AR filter	80.8± 0.02	69.3± 0.15	78.1± 0.01Ours	83.5± 0.02	73.6± 0.09	80.2± 0.02Table 6: Test accuracy (%) averaged over 10 runs on the large-scale OGB node property predictionbenchmark. _______________________________________________________________________methods	Products	Mag	ArxivMLP	61.06±0.08	26.92±0.26	55.50±0.23GCN	75.64±0.21	30.43±0.25	71.74±0.29GraphSage	78.29±0.16	31.53±0.15	71.49±0.27
Table 6: Test accuracy (%) averaged over 10 runs on the large-scale OGB node property predictionbenchmark. _______________________________________________________________________methods	Products	Mag	ArxivMLP	61.06±0.08	26.92±0.26	55.50±0.23GCN	75.64±0.21	30.43±0.25	71.74±0.29GraphSage	78.29±0.16	31.53±0.15	71.49±0.27Softmax	47.70±0.03	24.13±0.03	52.77±0.56SGC	68.87± 0.01	29.47±0.03	68.78±0.02S2GC	70.22± 0.01	32.47±0.11	70.15±0.13S2GC+MLP	76.84±0.20	32.72±0.23	72.01±0.25three state-of-the-art shallow models: GCN (KiPf & Welling, 2016), GAT (Velickovic et al., 2017),FastGCN (Chen et al., 2018), APPNP (Klicpera et al., 2019a), Mixhop (Abu-El-Haija et al., 2019),SGC (Wu et al., 2019), DGI (Velickovic et al., 2019) and GIN (Xu et al., 2018a). We use the AdamSGD oPtimizer (Kingma & Ba, 2014) with a learning rate of 0.02 to train S2GC. We set α = 0.05and K = 16 on all datasets. To determine K and α, we used the MetaOPt Package Bergstra et al.
Table 7: Test accuracy on the document classification task.
Table 8: Summary of classification accuracy (%) w.r.t.
Table 10: The statistics of datasets used for node classification and clustering.
Table 11: The StatiSticS of datasets for text classification.
Table 12: Graph classification.
