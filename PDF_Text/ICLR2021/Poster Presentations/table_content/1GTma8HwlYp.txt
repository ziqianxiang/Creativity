Table 1: Results on Text Classification measured by F1. Experiments are averaged over 5 runs.
Table 2: Average Accuracy on MultiCifar100 and Cat-vs-Dog Cifar10 tasks. Cat-vs-Dog experi-ments are averaged over 5 runsMethod	Average AUC Across 5 PathologiesNo-Pretraining	78.3 ± 0.87Pretrained-ResNet	81.4 ± 1.34Pretrained-ResNet + Ours	83.3±0.71Table 3: Results on ChexPert-5k task measured by average AUC (Area Under Roc-Curve). Allexperiments are averaged over 5 runs.
Table 3: Results on ChexPert-5k task measured by average AUC (Area Under Roc-Curve). Allexperiments are averaged over 5 runs.
Table 4: Experiment conducted on Cat-vr-Dog Cifar10 dataset for different choices of subspacebasis. We use k = 5 for Random and Randomized-SVD. This ablation uses a smaller hyper-parameter budget than Table 2Ablation Study. Our approach relies on the top-k singular vectors from randomized.Svd to definethe basis to identify the positive and negative component of the auxiliary task gradient, see Section 4.
Table 5: Results on ChexPert-5k tasks measured by average AUC (Area Under Roc-Curve)Text Classification For our NLP experiments, we tried limiting the number of layers we appliedATTITUD to. We achieved good performance without applying ATTITUD to the word embeddinglayers (these were updated with untouched auxiliary task gradients). We cross-validated ηprim ={0.01, 0.05, 0.0025}. For all our NLP experiments, we either recompute our subspace basis everyn = 1 or n = 4 timesFor all experiments involving ATTITUD, We cross-validate the following choices of the subspacesize k ∈ {5,10,20} from J* ∈ Rm×D using m ∈ {32, 64}. We recompute the subspace every 10steps for vision experiments and every 4 steps for NLP experiments. We run all experiments for amaximum of 150 pretraining epochs and 500 finetuning epochs. We performed early stopping forall experiments if no improvement after 10 consecutive epochs.
