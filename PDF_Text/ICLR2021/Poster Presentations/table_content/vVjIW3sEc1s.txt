Table 1: Accuracy (%) on k-way linear classification using fixed GPT-2 features. Good performanceof features f (s), conditional mean features Φpf (s) and meaningful subset of ≤ 30 (and ≤ 2k)coordinates of pf (s) verify the sentence completion reformulation and main results. The numbersright below the features denote dimensionality of the features. An asterisk indicates that we addeda task-specific prompt. Other baselines are fine-tuning (FT, Section F.2) and random projection ofpf(s) (rand. proj.). Sentence version of SST (train/test: 6.9K/1.8K) is used.
Table 2: GPT-2 performance without fine-tuning on downstream task test sets with k classes. Weprovide the performance of bag of n-grams (BonG) as an approximate baseline for these tasks. AGNews, DBPedia and Yahoo performances were reported in Zhang et al. (2015), and the other taskswere reported in Khodak et al. (2018). We also include results from mLSTM (Sentiment Neuron)(Radford et al., 2017) for the sentiment-related classification tasks (SST, IMDb, CR, and MPQA)with numbers reported from Khodak et al. (2018). Furthermore, we include results for BERT (Devlinet al., 2018) features without fine-tuning, where we use the output features for the first position ofan input for linear classification. An asterisk indicates we add a standard sentiment prompt “Thesentiment is” to each input, but for AG News we used the prompt “This article is about”. We alsotested the performance of the conditional probability distribution over “positive” and “negative” aswell as “:)” and “:(” on the sentiment-related tasks with and without the prompt.
Table 3: Comparing Quad features to cross-entropy features for GPT-2 trained on the IMDb un-labeled corpus (Maas et al., 2011). In this experiment we fix Φ to be the word embeddings fromprertained GPT-2 model for the cross-entropy objective. For the Quad objective, we initialize Φ tobe the SVD of the pre-trained embeddings. An asterisk indicates that we added the prompt “Thismovie is ” to each input.
Table 4: Comparing Quad features to cross-entropy features for GPT-2 trained on the Amazoncorpus. An asterisk indicates that we added the prompt “This movie is ” to each input. Note that thevalidation loss was still decreasing at the time of measurement.
