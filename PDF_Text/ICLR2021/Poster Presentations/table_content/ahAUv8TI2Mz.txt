Table 1: GZSL results on four datasets. All methods in comparison utilize ResNet101 as the backbonefor fairness. Notation ”*” means the method fine-tunes the backbone to match the characteristic ofdatasets.
Table 2: The effect of virtual classes and IAS for GZSL. We remove these two components as ourbaseline (b). In the ablation study, we add virtual classes (v) and IAS (I) step by step to show theireffect on GZSL.
Table 3: The impact of shortcut in IAS on four datasets.
Table 4: ZSL accuracy w.r.t. virtual classes per									episode.			Table 5: ZSL accuracy w.r.t. beta distribution.						k	AWA2	CUB	SUN	aPY	B(α,β)	AWA2	CUB	SUN	aPY8	75.7	76.2	64.6	40.8	(5,5)	74.8	75.6	65.4	38.212	76.0	76.3	65.1	42.8	(1,1)	75.3	76.4	65.8	40.216	76.4	76.3	65.1	43.7	(5,1)	76.4	77.2	66.2	43.720	75.5	77.2	66.2	41.1					Effect of beta distribution on ZSL accuracy To explore the best beta distribution setting for ZSL,our experiments apply three different α and β sets. As shown in Figure 7, B(1,1) means virtualclasses distribute uniformly between selected class pairs. Then, B(5,5) means most of the virtualclasses distribute among the middle of selected class pairs. On the other hand, B(5,1) means mostvirtual classes distribute closer to one of the classes in selected class pairs. Table 5 demonstratesthat B(5,1) achieves best performance on each dataset. In our speculation, the virtual classes createdbased on one class are closer to real-world classes. For example, the zebra is very similar to the horsein shape. Thus, the virtual classes distributing among seen classes enhance ZSL accuracy are verybeneficial for training ZSL.
