Table 1: Complexity of global optimization for two-layer ReLU networks with scalar and vectoroutputs. Best known upper-bounds are shown where n is the number of samples, d is the dimensionof the samples and r is the rank of the training data. Note that for convolutional networks, r is thesize of a single filter, e.g., a convolutional layer with a kernel size of 3 Ã— 3 corresponds to r = 9.
