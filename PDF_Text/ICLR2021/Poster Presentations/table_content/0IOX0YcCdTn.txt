Table 1: Six ALFRED task typeswith heldout seen and unseenevaluation sets.
Table 2: Zero-shot Domain Transfer. Left: Success percentages of the best BUTLER::BRAIN agentsevaluated purely in TextWorld. Mid-Left: Success percentages after zero-shot transfer to embodiedenvironments. Mid-Right: Success percentages of BUTLER with an oracle state-estimator andcontroller, an upper-bound. Right: Success percentages of BUTLER with human-annotated goaldescriptions, an additional source of generalization difficulty. All successes are averaged across threeevaluation runs. Goal-condition success rates (Shridhar et al., 2020) are given in parentheses. TheSeq2Seq baseline is trained in TextWorld from pre-recorded expert demonstrations using standardsupervised learning. BUTLER is our main model using the Mask R-CNN detector and A* navigator.
Table 3: Training Strategy Success. Trained on AllTasks for 50K episodes and evaluated in embodiedscenes using an oracle state-estimator and controller.
Table 4: Generalization within TextWorld environments: We independently train BUT-LER::Brain on each type of TextWorld task and evaluate on heldout scenes of the same type.
Table 5: Unimodal Baselines. Trainedon All Tasks with 50K episodes andevalUated in the embodied environment.
Table 6: High-level text actions supported in ALFWorld along with their observation templates.
Table 7: Task-types and the corresponding goal description templates.
