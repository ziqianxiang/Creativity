Table 1: Ablation study on Kinetics-Sounds comparing: (a; top-left) multimodal fusion methods,(b; top-right) negative sampling strategies, and (c & d; bottom) parameter sharing schemes. X.-L:Cross-layer, X.-T: Cross-Transformer sharing. We report top-1 and top-5 accuracy (%). 1: Ours.
Table 2: (a; left): Short video classification results on UCF101 (mean accuracy (%)). (b; cen-ter): Short audio classification results on ESC-50 (mean accuracy (%)). (c; right): Long videoclassification results on Charades (mAP) and Kinetics-SoUnds (KS; top-1/5 accuracy (%)). 1: Ours.
Table 3: The architectures of visual and audio CNNs. For the visual CNN, the input dimensionsare denoted by {channel size, temporal size, spatial size2}, kernels are denoted by {temporal size,spatial size2, channel size} and strides are denoted by {temporal stride, spatial stride2}. For the audioCNN, the input dimensions are denoted by {frequency size, temporal size}, kernels are denoted by{frequency size, time size, channel size} and strides are denoted by {frequency stride, temporal stride}.
