Table 1: The networks and datasets examined in the SNIP paper (Lee et al., 2019).
Table 2: The performance of SNIP as reported in the original paper and in our reimplementation.
Table 3: The performance of SNIP as reported in the original paper and in our reimplementation.
Table 4: The networks and datasets examined in the GraSP paper (Wang et al., 2020).
Table 5: The performance of GraSP as reported in the original paper and in our reimplementation.
Table 6: The networks and datasets examined in the SynFlow paper (Tanaka et al., 2020)20Published as a conference paper at ICLR 2021Of the settings that we replicated, our unpruned network performance is as follows:NetworkDatasetReported Replicated NotesVGG-11	CIFAR-10	〜92%	92.0%VGG-16	CIFAR-10	〜94%	93.5%ResNet-18 (Modified) CIFAR-10	〜95%	93.7%ResNet-18 (Modified) CIFAR-10	—	94.6%ResNet-18 (Modified) TinyImageNet	〜64%	58.8%ResNet-18 (Modified) TinyImageNet	—	64%Hyperparameters and augmentation are identical to oursHyperparameters and augmentation are identical to oursHyperparameters reported by Tanaka et al. (lr=0.01, batch size=128, drop factor=0.2)Hyperparameters reported by Tanaka et al. (lr=0.2, batch size=256, drop factor=0.1)Hyperparameters reported by Tanaka et al. (lr=0.01, batch size=128, epochs=100)Modified hyperparameters (lr=0.2, batch size=256, epochs=200)Table 7: Top-1 accuracy of unpruned networks as reported by Tanaka et al. (2020) and as replicated.
Table 7: Top-1 accuracy of unpruned networks as reported by Tanaka et al. (2020) and as replicated.
