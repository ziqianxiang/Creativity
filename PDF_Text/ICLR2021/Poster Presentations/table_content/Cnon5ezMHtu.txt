Table 1: Comparison with state-of-the-art NAS methods on NAS-Bench-201. Test accuracy with mean anddeviation are reported. "optimal‚Äù indicates the best test accuracy achievable in NAS-BenCh-201 search space.
Table 2: Comparison with state-of-the-art NAS methods on CIFAR-10.				Architecture	Test Error (%)	Params (M)	Search Cost (GPU days)	Search MethodAmoebaNet-A (Real et al., 2019)	3.34(0.06)	3.2	3150	evolutionPNAS (Liu et al., 2018a)?	3.41(0.09)	3.2	225	SMBOENAS (Pham et al., 2018)	2.89	4.6	0.5	RLNASNet-A (Zoph et al., 2018)	2.65	3.3	2000	RLDARTS (1st) (Liu et al., 2018b)	3.00(0.14)	3.3	0.4	gradientDARTS (2nd) (Liu et al., 2018b)	2.76(0.09)	3.3	1.0	gradientSNAS (Xie et al., 2018)	2.85(0.02)	2.8	1.5	gradientGDAS (Dong & Yang, 2019)	2.82	2.5	0.17	gradientBayesNAS (Zhou et al., 2019)	2.81(0.04)	3.4	0.2	gradientProxylessNAS (Cai et al., 2018)t	2.08	5.7	4.0	gradientP-DARTS (Chen et al., 2019)	2.50	3.4	0.3	gradientPC-DARTS (Xu et al., 2019)	2.57(0.07)	3.6	0.1	gradientSDARTS-ADV (Chen & Hsieh, 2020)	2.61(0.02)	3.3	1.3	gradientTE-NAS (ours)	2.63(0.064)	3.8	0.05*	training-free? No cutout augmentation. , Different space: PyramidNet (Han et al., 2017) as the backbone. * Recorded on a single GTX 1080Ti GPU.				7Published as a conference paper at ICLR 2021initial channel number as 36. We place the reduction cells at the 1/3 and 2/3 of the network and each
Table 3: Comparison with state-of-the-art NAS methods on ImageNet under the mobile setting.
Table 4: Search with only KN or RN on CIFAR-100 in NAS-BenCh-201 space.
Table 5: Search with only KN or RN on CIFAR-100 in NAS-Bench-201 space.
