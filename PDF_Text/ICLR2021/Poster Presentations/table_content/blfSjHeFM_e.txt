Table 1: Comparison between different methods for gradient estimation in continuous case. MALI achievesreverse accuracy, constant memory w.r.t number of solver steps in integration, shallow computation graph andlow computation cost.
Table 2: Top-1 test accuracy of Neural ODE and ResNet on ImageNet. Neural ODE is trained with MALI,and ResNet is trained as the original model; Neural ODE is tested using different solvers without retraining.
Table 3: Top-1 accuracy under FGSM attack. is the perturbation amplitude. For Neural ODE models, rownames represent the solvers to derive the gradient for attack, and column names represent solvers for inferenceon the perturbed image.
Table 4: Test MSE (×0.01) on Mujoco dataset (lower is better). Results Table 5: Test ACC on Speechmarked with superscript numbers correspond to literature in the footnote.							Command Dataset								Method	Accuracy (%)Percentage	RNN1	RNN-GRU1		Latent-ODE			Adjoint3	92.8 ± 0.4-of training data			AdjointI	Naive2	ACA2	MALI	SemiNorm3	92.9 ± 0.410%	2.451	1972	0.471-	0.362	0.312	0.35	Naive	93.2 ± 0.220%	1.711	1.421	0.441	0.302	0.272	0.27	ACA	93.2 ± 0.250%	0.791	0.751	0.401	0.292	0.262	0.26	MALI	93.7 ± 0.3Table 3), and inference on the perturbed images using various solvers. For different combinationsof solvers and perturbation amplitudes, Neural ODE consistently outperforms ResNet.
Table 6: Bits per dim (BPD) of generative models, lower is better. Results marked with superscript numberscorrespond to literature in the footnote.
Table 7: Results of damped MALI with different η values. We report the test accuracy of NeuralCDE on Speech Command dataset, and the test MSE of latent-ODE on Mujoco data.
