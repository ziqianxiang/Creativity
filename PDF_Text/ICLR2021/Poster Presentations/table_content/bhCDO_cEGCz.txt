Table 1: Question-answering accuracy on CLEVRER. The first and the second parts of the table show the modelswithout and with visual attribute and event labels during training, respectively. Best performance is highlightedin boldface. DCL and DCL-Oracle denote our models trained without and with labels of visual attributes andevents, respectively.
Table 2: Evaluation of video concept learning on the validation set.
Table 3: Evaluation of video grounding. For spatial grounding,we consider it to be accurate if the IoU between the detectedtrajectory and the ground-truth trajectory is greater than 0.5.
Table 4: Evaluation of CLEVRER-Retrieval.
Table 5: QA results on the block tower dataset.
Table 6: Evaluation of concept learning on the blocktower dataset. Our DCL can learn to quantize the newconcept “falling” on real videos through QA.
Table 7: Operations available on CLEVRER dataset.
Table 8: The data type system of CLEVRER-VQA.
Table 9: Neural operations in DCL. eventscol0 denotes the collision events happening at the unseen future frames.
Table 10: The evaluation of different methods for object trajectory generation.
