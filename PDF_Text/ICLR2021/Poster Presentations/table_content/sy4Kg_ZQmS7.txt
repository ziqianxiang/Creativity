Table 1:	Out-of-Sample MSE in MNIST experiment of Bennett et al. (2019)Catch Mountain Car CartpoleF 50	3	6A3	3	3Table 2:	Dimensions of BSuite tasksHere, the structural function we aim to learn is fstruct(X) = |X|. Additionally, we mapZ, X, or both X and Z to MNIST images to see whether the model can handle the high-dimensional treatment and instrumental variables. Let the output of original IV problemabove to be Xlow, Zlow and π(x) = round(min(max(1.5x + 5, 0), 9)) be a transformationfunction that maps inputs to an integer between 0 and 9, and let RandomImage(d) be afunction that selects a random MNIST image from the digit class d. The images are 28 × 28= 784-dimensional. We consider the three following scenarios.
Table 2:	Dimensions of BSuite tasksHere, the structural function we aim to learn is fstruct(X) = |X|. Additionally, we mapZ, X, or both X and Z to MNIST images to see whether the model can handle the high-dimensional treatment and instrumental variables. Let the output of original IV problemabove to be Xlow, Zlow and π(x) = round(min(max(1.5x + 5, 0), 9)) be a transformationfunction that maps inputs to an integer between 0 and 9, and let RandomImage(d) be afunction that selects a random MNIST image from the digit class d. The images are 28 × 28= 784-dimensional. We consider the three following scenarios.
Table 3: Network structures of DeepIV for demand design dataset. For the input layer, weprovide the input variable. For the fully-connected layers (FC), we provide the input andoutput dimensions. For mixture Gaussian output, we report the number of components.
Table 4: Network structures of DFIV for demand design datasets. For the input layer, weprovide the input variable. For the fully-connected layers (FC), we provide the input andoutput dimensions.
Table 5: Network structures of feature extractor used in demand design experiment withMNIST. For each convolution layer, we list the input dimension, output dimension, kernelsize, stride, and padding. For the input layer, we provide the input variable. For thefully-connected layers (FC), we provide the input and output dimensions. For max-pool, welist the size of the kernel. Dropout rate here is set to 0.1. SN denotes Spectral Normalization(Miyato et al., 2018).
Table 6: Network structures of DeepIV in demand design with MNIST data. For the inputlayer, we provide the input variable. For the fully-connected layers (FC), we provide the inputand output dimensions. For mixure Gaussian output, we report the number of components.
Table 7: Network structures of DFIV in demand design with MNIST. For the input layer,we provide the input variable. For the fully-connected layers (FC), we provide the input andoutput dimensions. ImageFeature denotes the module given in Table 5.
Table 8: Network structures of DeepGMM in dSprite experiment. For the input layer, weprovide the input variable. For the fully-connected layers (FC), we provide the input andoutput dimensions. SN denotes Spectral Normalization (Miyato et al., 2018).
Table 9: Network structures of DFIV in dSprite experiment. For the input layer, we providethe input variable. For the fully-connected layers (FC), we provide the input and outputdimensions. SN denotes Spectral Normalization (Miyato et al., 2018).
Table 10: Network structures of DFIV in OPE experiment. For the input layer, we providethe input variable. For the fully-connected layers (FC), we provide the input and outputdimensions.
Table 11: Network structures of DeepGMM in OPE experiment. For the input layer, weprovide the input variable. For the fully-connected layers (FC), we provide the input andoutput dimensions.
Table 12: Network structures of DeepIV in OPE experiment. For the input layer, we providethe input variable. For the fully-connected layers (FC), we provide the input and outputdimensions. The MixutureGaussian layer maps the input linearly to required parameterdimensions for a mixture of Gaussian distribution with diagonal covariance matrices. TheBernoulli layer maps the input linearly to a single dimension to represent the logit of aBernoulli distribution to predict if the next state is a terminating state.
