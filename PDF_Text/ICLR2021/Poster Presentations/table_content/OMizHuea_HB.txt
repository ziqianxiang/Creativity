Table 1: Top-1 accuracy of unimodal vs. cross-modal pretraining on downstream tasks.
Table 2: Top-1 accuracy on downstream tasks: feature- vs. gradient-based embedding.
Table 3: Online hard example mining (OHEM) (Shrivastava et al., 2016) vs. our active samplingFeature vs. gradient embedding. We compare two ways to do active sampling: using gradientembeddings (Eqn. 5) and feature embeddings (the outputs from ha and hv) when selecting theseed centroids with k-MEANS++. Fig. 2 shows that gradient embeddings produce a more diverseset of negative samples than feature embeddings; this is consistent across all three batch sizes.
Table 4: Comparison of SOTA approaches on action recognition. We specify pretraining dataset andthe number of samples used if they are reported in the original papers (N/A: not available).
Table 5: Comparision of SOTA approaches on audio event classification.
Table 6: Top-1 accuracy of CM-ACC pretrained on different datasets vs. fully-supervised counter-parts (Supervised). 1: the results are excerpted from Patrick et al. (2020), *: our results.
