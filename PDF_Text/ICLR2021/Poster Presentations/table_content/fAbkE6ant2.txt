Table 1: Test errors of a ResNet-32 using greedy SL onCIFAR-10. The network is divided into K successivelocal modules. Each module is trained separately with thesoftmax cross-entropy loss by appending a global-poollayer followed by a fully-connected layer (see Appendix Ffor details). “K = 1” refers to end-to-end (E2E) training.
Table 2: Performance of different networks with varying numbers of local modules. The averaged test errors andstandard deviations of 5 independent trials are reported. InfoPro (Softmax/Contrast) refers to two approaches toestimating I(h, y). The results of Asy-InfoPro is obtain by asynchronous training, while others are based onsimultaneous training. Greedy SL+ adopts deeper networks to have the same computational costs as InfoPro.
Table 3: Trade-off between GPU memory footprint during training and test errors. Results of training ResNet-110on a single Nvidia Titan Xp GPU are reported. ‘GC’ refers to gradient checkpointing (Chen et al., 2016).
Table 4: Single crop error rates (%) on the validation set of ImageNet. We use 8 Tesla V100 GPUs for training.
Table 5: Results of semantic segmentation on Cityscapes. 2 Nvidia GeForce RTX 3090 GPUs are used fortraining. ‘SS’ refers to the single-scale inference. ‘MS’ and ‘Flip’ denote employing the average prediction ofmulti-scale ([0.5, 1.75]) and left-right flipped inputs during inference. We also present the results reported by theoriginal paper in the “original” row. DGL refers to decoupled greedy learning (Belilovsky et al., 2020).
Table 7:	Architecture of the decoder w on CIFAR, SVHN and STL-10.
Table 8:	Architecture of ψ and φ on CIFAR, SVHN and STL-10.
Table 9:	Architecture of the decoder w on ImageNet.
Table 10:	Architecture of ψ on ImageNet.
Table 11:	Architecture of ψ on Cityscapes.
Table 12: Test errors of ResNet-110 trained by InfoPro (Contrast)on CIFAR-10, with different ar-chitecture of φ. “MLP” refers tothe multi-layer perceptron.
Table 13: Performance of InfoPro (Contrast/Softmax) with varyingbatch sizes. Two settings are considered: training models with the samenumber of iterations (40/80/160 epochs for batch size=256/512/1024)and epochs (160 epochs). All other training hyper-parameters (i.e., thelearning rate schedule, weight decay, etc.) are remained unchanged.
Table 14: Performance of InfoPro with the VGG network (Simonyan & Zisserman, 2014). The averaged testerrors and standard deviations of 5 independent trials are reported. InfoPro (Softmax/Contrast) refers to twoapproaches to estimating I(h, y).
Table 15: Object detection results on COCO (Lin et al., 2014). We initialize the backbone of Faster-RCNN-FPN(Ren et al., 2015) using ResNet-101 trained by E2E training and InfoPro*, K = 2 on ImageNet. The COCOstyle box average precision (AP) metric is adopted, where AP50 and AP75 denote AP over 50% and 75% IoUthresholds, mAP takes the average value of AP over different thresholds (50%-95%), and mAPs, mAPM andmAPL denote mAP for objects at different scales. All results are presented in percentages (%). The better resultsare bold-faced.
