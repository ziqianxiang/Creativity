Table 1: Comparative results for 5-way 1/5-shot FSL. The mean classification accuracies (top-1, %) With the 95% Confidence intervals are reported. f indicates the result is reprodUced by ourselves.							mini ImageNet		tieredImageNet	Method	Backbone	1-shot	5-shot	1-shot	5-shotMatchingNet (Vinyals et al., 2016)	Conv4-64	43.56 ± 0.84	55.31 ± 0.73	—	一ProtoNett (Snell et al., 2017)	Conv4-64	52.61 ± 0.52	71.33 ± 0.41	53.33 ± 0.50	72.10 ± 0.41MAML (Finn et al., 2017)	Conv4-64	48.70 ± 1.84	63.10 ± 0.92	51.67 ± 1.81	70.30 ± 0.08Relation Net (Sung et al., 2018)	Conv4-64	50.40 ± 0.80	65.30 ± 0.70	54.48 ± 0.93	71.32 ± 0.78IMPt (Allen et al., 2019)	Conv4-64	52.91 ± 0.49	71.57 ± 0.42	53.63 ± 0.51	71.89 ± 0.44DN4 (Li et al., 2019b)	Conv4-64	51.24 ± 0.74	71.02 ± 0.64	-	一DN PARN (Wu et al., 2019)	Conv4-64	55.22 ± 0.84	71.55 ± 0.66	-	一PN+rot (Gidaris et al., 2019)	Conv4-64	53.63 ± 0.43	71.70 ± 0.36	-	一CC+rot (Gidaris et al., 2019)	Conv4-64	54.83 ± 0.43	71.86 ± 0.33	-	一DSN-MR (Simon et al., 2020)	Conv4-64	55.88 ± 0.90	70.50 ± 0.68	-	一Centroid (Afrasiyabi et al., 2020)	Conv4-64	53.14 ± 1.06	71.45 ± 0.72	-	一Neg-Cosine (Liu et al., 2020)	Conv4-64	52.84 ± 0.76	70.41 ± 0.66	-	一IEPT (ours)	Conv4-64	56.26 ± 0.45	73.91 ± 0.34	58.25 ± 0.48	75.63 ± 0.46ProtoNett (Snell et al., 2017)	Conv4-512	53.25 ± 0.44	73.15 ± 0.35	57.88 ± 0.50	76.82 ± 0.40MAML (Finn et al., 2017)	Conv4-512	49.33 ± 0.60	65.17 ± 0.49	52.84 ± 0.56	70.91 ± 0.46Relation Net (Sung et al., 2018)	Conv4-512	50.86 ± 0.57	67.32 ± 0.44	54.69 ± 0.59	72.71 ± 0.43PN+rot (Gidaris et al., 2019)	Conv4-512	56.02 ± 0.46	74.00 ± 0.35	-	一
Table 2: Ablation study results for our full IEPT model over miniImageNet and tieredImageNet. Ourfull model includes two self-supervised losses (i.e. Lepis and Linst) and two supervised losses (i.e.
Table 3: Comparative results for the fine-grained FSL on CUB (Wah et al., 2011) and the cross-domainFSL on miniImageNet → CUB.
Table 4: FSL results obtained by our IEPT using two SSL strategies (i.e. rotation and shuffling imagepatches). Conv4-64 is used as the feature extractor.
Table 5: Comparative results obtained by three different approaches to integrating the features fromthe extended episodes, with Conv4-64 being the feature extractor.
Table 6: Comparison with the simple baseline that trains the model with Laux + Linst and thenmakes inference by just averaging the outputs of different extended episodes.
Table 7: Ablation study results regarding different alternatives of Lepis and Linst .
Table 8: Comparative results by applying IEPT to the optimization-based method MAML.
