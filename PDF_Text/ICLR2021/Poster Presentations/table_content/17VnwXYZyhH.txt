Table 1: Results of tree distance and depth probes. We highlight two observations of Poincareprobes compared with Euclidean probes: (a) they do not assign higher scores to embeddings withoutsyntactic information (ELMo0 and Linear), meaning that they do not form a parser; (b) theyrecover higher scores (colored cells) for contextualized embeddings with smaller probe capacity,meaning that they are more sensitive to the existence of syntax in contextualized embeddings.
Table 2: Classification accuracy on Movie Review dataset. Both Euclidean and Poincare give 48.4(nearly random guess) to baseline Linear embeddings, meaning neither of them form a classifier.
Table 3: Top sentiment words recovered by Euclidean and PoinCare probes. Colored words alignbetter with human intuition (orange for positive and blue for negative).
Table 4: Results of training probes for distance and depth tasks simultaneously.
Table 5: Results of training probes using local information for distance and depth tasks simultane-ously.
Table 6: Statistics of Movie Review dataset.
Table 7: Accuracy for probing on GloVe and Linear.
Table 8: ToP 100 sentiment words by Euclidean and Poincare probes.
Table 9: Results of training Euclidean probe variations for distance task.
Table 10: Results of 2d probes with different curvatures for both distance and depth tasks on BERT-base7.
