Table 2: Summary of the test losses (mean squared error ± the standard error of the mean in theoriginal scale) of the differential operator dataset: 0 → 1 (the scalar field to the gradient field),0 → 2 (the scalar field to the Hessian field), 1 → 0 (the gradient field to the Laplacian field), and1 → 2 (the gradient field to the Hessian field). Here, if “x” is “Yes”, x is also in the input feature.
Table 3: Summary of the test losses (mean squared error ±the standard error of the mean in the original scale) of theanisotropic nonlinear heat dataset. Here, if “x” is “Yes”, xis also in the input feature. We show only the best setting foreach method except for the equivariant models. For the fulltable, see Appendix E. OOM denotes the out-of-memory onthe applied GPU (32 GiB).
Table 4: Comparison of computation time. To generate the test data, we sampled CAD data fromthe test dataset and then generated the mesh for the graph to expand while retaining the elementvolume at almost the same size. The initial temperature field and the material properties are setrandomly using the same methodology as the dataset sample generation. For a fair comparison,each computation was run on the same CPU (Intel Xeon E5-2695 v2@2.40GHz) using one core,and we excluded file I/O time from the measured time. OOM denotes the out-of-memory (500GiB).
Table 5: Summary of the hyperparameter setting for both the TFN and SE(3)-Transformer. Forthe parameters not in the table, we used the default setting in the implementation of https://github.com/FabianFuchsML/se3-transformer-public.
Table 6: Summary of the test losses (mean squared error ± the standard error of the mean in theoriginal scale) of the differential operator dataset: 0 → 1 (the scalar field to the gradient field),0 → 2 (the scalar field to the Hessian field), 1 → 0 (the gradient field to the Laplacian field), and1 → 2 (the gradient field to the Hessian field). Here, if “x” is “Yes”, x is also in the input feature.
Table 7: Summary of the inference time on the test dataset. 0 → 1 corresponds to the scalar field tothe gradient field, and 0 → 2 corresponds to the scalar field to the Hessian field. Each computationwas run on the same GPU (NVIDIA Tesla V100 with 32 GiB memory). OOM denotes the out-of-memory of the GPU.
Table 8: Summary of the hyperparameter setting for both the TFN and SE(3)-Transformer. For theparameters not written in the table, We used the default setting in the implementation of https：//github.com/FabianFuchsML/se3-transformer-public.
Table 9: Summary of the test losses (mean squared error ± the standard error of the mean in theoriginal scale) of the anisotropic nonlinear heat dataset. Here, if “x” is “Yes”, x is also in the inputfeature. OOM denotes the out-of-memory on the applied GPU (32 GiB).
