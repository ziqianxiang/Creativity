Table 1: Ablative analysis on HowMany-QA val set. MoVie modulation design outperforms FiLMunder fair comparisons; both fixing input size and multi-scale training improve robustness to scales.
Table 2: Open-ended counting on Howmany-QA and TallyQA test set. MoVie outperforms priorarts with lower #parameters and FLOPs. R: ResNet (He et al., 2016); X: ResNeXt (Xie et al., 2017).
Table 3: Common object counting on COCO test with various RMSE metrics. MoVie outperformsprior state-of-the-arts without instance-level supervision. All models use ResNet-50 backbone pre-trained on ImageNet.
Table 4: Top: Different ways to use MoVie as a counting module for VQA models measured byVQA score (Antol et al., 2015). Bottom: MoVie especially helps ‘number’ questions on test-dev.
Table 5: Reasoning on GQA test set to show the generalization of MoVie beyond counting (*: usesscene-graph supervision (Krishna et al., 2017)) Metrics follow (Hudson & Manning, 2019a).
Table 6: Common object counting on VOC test set with various RMSE metrics.
Table 7: Adding MoVie as a module to MCAN. Training speed is 〜5% slower, and the additionalparameters during testing is minimal (〜10%) as it uses the joint branch only.
Table 8: VQA accuracy of Pythia with and without MoVie on VQA 2.0 test-dev set.
