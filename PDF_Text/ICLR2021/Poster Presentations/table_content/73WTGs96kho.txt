Table 1: Gradual study (test log-loss scores)			Dataset # formulas	Eye Movements 128	512	2048	Gesture Phase 128	512	2048	Gas Concentrations 128	512	2048Exp 1: Fully	0.9864	1.0138	OOM	1.3139	1.3368	OOM	0.2423	0.3862	OOMtrained FCN	(±0.0038)	(±0.0083)		(±0.0067)	(±0.0084)		(±0.0598)	(±0.0594)	Exp 2: Adding	0.9034	0.9336	1.3011	1.1391	1.1812	1.8633	0.0351	0.0421	0.0778DNF structure	(±0.0058)	(±0.0058)	(±0.0431)	(±0.0059)	(±0.0117)	(±0.1026)	(±0.0048)	(±0.0046)	(±0.0080)Exp 3: Adding	0.8134	0.8163	0.9652	1.1411	1.1320	1.3015	0.0227	0.0265	0.0516feature selection	(±0.0142)	(±0.0096)	(±0.0143)	(±0.0093)	(±0.0083)	(±0.0317)	(±0.0019)	(±0.0012)	(±0.0061)Exp 4: Adding	0.7621	0.7125	0.6903	0.9742	0.9120	0.8770	0.0162	0.0149	0.0145localization	(±0.0079)	(±0.0077)	(±0.0049)	(±0.0079)	(±0.0123)	(±0.0088)	(±0.0013)	(±0.0008)	(±0.0011)Consider Table 1. In Exp 1 we start with a vanilla three-hidden-layer FCN with a tanh activation. Tomake a fair comparison, we defined the widths of the layers according to the widths in the Net-DNFwith the corresponding formulas. In Exp 2, we added the DNF structure to the networks from Exp 1(see Section 2.1). In Exp 3 we added the feature selection component (Section 2.3). It is evident thatperformance is monotonically improving, where the best results are clearly obtained on the completeNet-DNF (Exp 4). A subtle but important observation is that in all of the first three experiments,for all datasets, the trend is that the lower the number of formulas, the better the score. This trendis reversed in Exp 4, where the localization component (Section 2.4) is added, highlighting theimportance of using all components of the Net-DNF representation in concert.
Table 2: Leave one out study (test log-loss scores)Dataset # formulas	Eye Movements			Gesture Phase			Gas Concentrations			128	512	2048	128	512	2048	128	512	2048Exp 4: Complete	0.7621	0.7125	0.6903	0.9742	0.9120	0.8770	0.0162	0.0149	0.0145Net-DNF	(±0.0079)	(±0.0077)	(±0.0049)	(±0.0079)	(±0.0123)	(±0.0088)	(±0.0013)	(±0.0008)	(±0.0011)Exp 5: Leave	0.8150	0.8031	0.7969	0.9732	0.9479	0.9438	0.0222	0.0205	0.0200feature selection out	(±0.0046)	(±0.0046)	(±0.0054)	(±0.0082)	(±0.0081)	(±0.0111)	(±0.0018)	(±0.0021)	(±0.0022)Exp 6: Leave	0.8134	0.8163	0.9652	1.1411	1.1320	1.3015	0.0227	0.0265	0.0516localization out	(±0.0142)	(±0.0096)	(±0.0143)	(±0.0093)	(±0.0083)	(±0.0317)	(±0.0019)	(±0.0012)	(±0.0061)Exp 7: Leave DNF	0.8403	0.8128	OOM	1.1265	1.1101	OOM	0.0488	0.0445	OOMstructure out	(±0.0068)	(±0.0077)		(±0.0066)	(±0.0077)		(±0.0038)	(±0.0024)	selection is a learnable binary mask that multiplies the input element-wise. Here we examine the effectof this mask on a vanilla FCN network (see technical details in Appendix D.5). The synthetic taskswe use were introduced by Yoon et al. (2019); Chen et al. (2018), where they were used as syntheticexperiments to test feature selection. There are six different dataset settings; exact specificationsappear in Appendix D.5. For each dataset, we generated seven different instances that differ in theirinput size. While increasing the input dimension d, the same logit is used for prediction, so the newfeatures are irrelevant, and as d gets larger, the percentage of relevant features becomes smaller.
Table 3: Mean test results on tabular datasets and standard error of the mean. We present the ROCAUC (higher is better) as a percentage, and the log-loss (lower is better) with an x100 factor.
Table 4: A description of the tabular datasets13Published as a conference paper at ICLR 2021D Experimental ProtocolD. 1 Data Partition and Grid Search ProcedureAll experiments in our work, using both synthetic and real datasets, were done through a grid searchprocess. Each dataset was first randomly divided into five folds in a way that preserved the originaldistribution. Then, based on these five folds, we created five partitions of the dataset as follows.
