Table 1: Perplexity of the multi-timescale and baseline models for tokens across different frequencybins for the Penn TreeBank (PTB) and WikiText-2 (WT2) test datasets. We also report the meandifference in perplexity (baseline - multi-timescale) across 10,000 bootstrapped samples, along withthe 95% confidence interval (CI).
Table 2: Perplexity of the baseline and multi-timescale models over 5 different training instances.
Table 3: Perplexity of the baseline and multi-timescale models trained with a legacy version ofpytorch. Performance is also reported separately for tokens across different frequency bins. Last rowis the mean difference in perplexity (baseline - multi-timescale) across 10,000 bootstrapped samples,along with the 95% confidence interval (CI).
