Table 1: The success rates of L∞ and L2 black-box attacks crafted on six source models, includ-ing AlexNet, VGG16, RN-34/152, DN-121/201, against seven target models. Transferability ofadversarial perturbations can be enhanced by penalizing interactions.
Table 2: The success rates of L∞ black-box attacks crafted on the ensemble model (RN-34+RN-152+DN-121) against nine target models.
Table 3: Transferability against the secured models: the success rates of L∞ black-box attackscrafted on RN-34 and DN-121 source models against three secured models.
Table 4: The success rates of L∞ black-box attacks crafted by different methods on four sourcemodels (RN-34/152, DN-121/201) against seven target models. Transferability of adversarial per-turbations can be enhanced by penalizing interactions.
Table 5: The average interaction inside adversarial perturbations generated by different attacks.
Table 6: Average computational cost of generating adversarial perturbations over an input image bythe IR Attack for 100 steps on different source DNNs.
Table 7: The success rates of L∞ black-box attacks crafted by MI and MI+IR on four sourcemodels (RN-34/152, DN-121/201) against seven target models. The interaction loss can boost thetransferability of MI.
Table 8: The success rates of L∞ black-box attacks crafted by SGM and SGM+IR on four sourcemodels (RN-34/152, DN-121/201) against seven target models. The interaction loss can boost thetransferability of SGM.
Table 9: The success rates of L∞ black-box attacks crafted by VR and VR+IR on four sourcemodels (RN-34/152, DN-121/201) against seven target models. The interaction loss can boost thetransferability of VR.
Table 10: The success rates of L∞ targeted black-box attacks on three source models, includingLeNet, RN-20, DN-121, against three target models._________________Source	Method	LeNet	RN-20	DN-121LeNet	PGD	—	34.1±0.1	19.6±0.4	PGD+IR	—	44.2±0.3	29.7±1.1RN-20	PGD	10.8±0.8	—	41.9±1.3	PGD+IR	19.7±0.3	—	71.8±1.0DN-121	PGD	10.0±0.7	44.2±0.3	—	PGD+IR	18.9±0.7	58.5±1.0	—Table 11: The average interaction inside adversarial perturbations generated by PGD, DI and TL	MethOd		RN-34	DN-121Baseline (PGD Attack)	0.422	0.926DI Attack	0.241	0.499TI Attack	0.379	0.618N Empirical Verification of Other Transferability-boostingAttacksWe have theoretically analyzed the MI Attack, the VR Attack, and the SGM Attack. However,for other methods of improving adversarial transferability, such as Diversity Input (DI) (Xie et al.,34Published as a conference paper at ICLR 2021
Table 11: The average interaction inside adversarial perturbations generated by PGD, DI and TL	MethOd		RN-34	DN-121Baseline (PGD Attack)	0.422	0.926DI Attack	0.241	0.499TI Attack	0.379	0.618N Empirical Verification of Other Transferability-boostingAttacksWe have theoretically analyzed the MI Attack, the VR Attack, and the SGM Attack. However,for other methods of improving adversarial transferability, such as Diversity Input (DI) (Xie et al.,34Published as a conference paper at ICLR 20212019), which uses random data augmentation during attacking, it is difficult to mathematically provethat they essentially reduce interactions. Nevertheless, as Table 11 shows, we empirically demon-strated that two widely-used transferability-boosting attacks, DI and TI (Dong et al., 2019), alsoreduced interactions.
