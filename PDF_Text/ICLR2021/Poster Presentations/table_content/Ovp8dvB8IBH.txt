Table 1: FID scores over CIFAR-10 using different transformations as PDA and NDA in BigGAN.
Table 2: Comparison of FID scores of different types of NDA for unconditional image generationon various datasets. The numbers in bracket represent the corresponding image resolution in pixels.
Table 3: FID scores for conditional image generation using different NDAs.2	BigGAN	Jigsaw	Stitching	Mixup	Cutout	Cutmix	CR-BigGANC-10	11.51	9.42	9.47	13.87	10.52	10.3	11.48C-100	15.04	14.12	13.90	15.27	14.21	13.99	—Image Translation. Next, we apply the NDA method to image translation. In particular, we use thePix2Pix model (Isola et al., 2017) that can perform image-to-image translation using GANs providedpaired training data. Here, the generator is conditioned on an image I, and the discriminator takes asinput the concatenation of generated/real image and I. We use Pix2Pix for semantic segmentationon Cityscapes dataset (Cordts et al., 2016) (i.e. photos → labels). Table 4 shows the quantitativegains obtained by using Jigsaw NDA2 3 while Figure 7 in Appendix F highlights the qualitative im-provements. The NDA-Pix2Pix model avoids noisy segmentation on objects including buildingsand trees.
Table 4: Results on CityScapes, using perpixel accuracy (Pp.), per class accuracy (Pc.)and mean Intersection over Union (mIOU). Wecompare Pix2Pix and its NDA version.
Table 5: AUROC scores for different OODdatasets. OOD-1 contains different datasets, whileOOD-2 contains the set of 19 different corruptionsin CIFAR-10-C (Hendrycks & Dietterich, 2018)(the average score is reported).
Table 6: Top-1 accuracy results on image recognition w/ and w/o NDA on MoCo-V2.
Table 7: Top-1 accuracy results on action recognition in videos w/ and w/o NDA in DPC.
Table 8: Effect of λ on the FID score for unconditional image generation on CIFAR-10 using Jigsawas NDA.
