Table 1:	We evaluate RNAs sampled from the posterior distribution: q(z|x), with a held-out test setof 20,000 RNAs. Each molecule is encoded and decoded 5 times. We also evaluate samples from theprior distribution: N(0, I) subject to the transformation of a latent CNF, where we sample 10,000encodings and each encoding is decoded 10 times. Normed refers to length normalized FE DEV.
Table 2:	Training semi-supervised HierVAE on labeled RNAcompete-S dataset. A test split is used toevaluate the accuracy of embedding classifiers and RNAs decoded from the posterior distributionunder two settings: constrained and stochastic (C& S), unconstrained and deterministic (NC&D).
Table 3: Designing novel RNA withhigher chances of RBP binding.
Table S1:	Hyperparameters for training VAE and full classifier models. Note that hidden units referto the dimensionality of encoders and decoders from LSTMVAE, GraphVAE as well as HierVAEmodels. Dropout is applied to the embedding MLP classifier in case of training semi-supervisedVAEs, which contains one hidden layer.
Table S2:	Performance of simple MLP classifiers on top of fixed latent embeddings from VAE models,which have been pretrained on the unlabeled RNA dataset as originally shown in Table 1.
Table S3: We use the same encoding architectures as in the generative models, and report theirAUROC averaged across 6 runs, for each RNAcomPete-S RBP dataset.
Table S4: Training HierVAE on suPervised RNAcomPete-S dataset. All models are trained with20 ePochs, including 5 ePochs for warm-uP, 6 ePochs to linearly raise beta from 0 to 3e-3, and 9remaining ePochs with beta fixed at 3e-3. The test set measures AUROC and Posterior decoding onthe final model.
