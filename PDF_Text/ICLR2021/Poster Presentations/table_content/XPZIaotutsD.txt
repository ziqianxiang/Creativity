Table 1: Comparison results on the GLUE development set.
Table 2: Results on MNLI in/out-domain, SQuAD v1.1, SQuAD v2.0, RACE, ReCoRD, SWAG,CoNLL 2003 NER development set. Note that missing results in literature are signified by “-”.
Table 3: Results on MNLI in/out-domain (m/mm), SQuAD v1.1 and v2.0 development set.
Table 4: Ablation study of the DeBERTa base model.
Table 5: SuperGLUE test set results scored using the SuperGLUE evaluation server. All the resultsare obtained from https://super.gluebenchmark.com on January 6, 2021.
Table 6: Summary information of the NLP application benchmarks.
Table 7: Comparison of the pre-training data.
Table 8: Hyper-parameters for pre-training DeBERTa.
Table 9: Hyper-parameters for fine-tuning DeBERTa on down-streaming tasks.
Table 10: Language model results in perplexity (lower is better) on Wikitext-103 .
Table 11: The effect of handling long sequence input for RACE task with DeBERTaLong sequence handling is an active research area. There have been a lot of studies where theTransformer architecture is extended for long sequence handling(Beltagy et al., 2020; Kitaev et al.,2019; Child et al., 2019; Dai et al., 2019). One of our future research directions is to extend DeBERTato deal with extremely long sequences.
Table 12: Comparison results of DeBERTa models with different sizes on the GLUE development set.
Table 13: Ablation study of the additional modifications in DeBERTa1.5B and DeBERTa900M models.
Table 14: Comparison of DeBERTa and RoBERTa on MNLI-matched and SQuAD v1.1.
