Table 1: Meta-test MSE of different methods on synthetic data with (partial) translation symmetry. “Small” vs“large” train dataset refers to the number of examples per training task. Among methods with non-convolutionalarchitectures, MSR-FC is closest to matching actual convolution (MAML-Conv) performance on translationequivariant (k = 1) data. On data with less symmetry (k = 2, 5), MSR-FC outperforms MAML-Conv andother MAML approaches. MSR-Joint is an ablation of MSR where both U and v of Eq. 2 are updated ontask train data, rather than just v. MTSR is an ablation of MSR where we train the reparameterization usingmulti-task learning, rather than meta-learning. Results are shown with 95% confidence intervals over test tasks.
Table 2: MSR learns rotation and flipequivariant parameter sharing on top ofa standard convolution model, and thusachieves much better generalization erroron meta-test tasks compared to MAML onrotation and flip equivariant data.
Table 3: Meta-test accuracies on Aug-Omniglot and Aug-MiniImagenet few-shot classification. These bench-marks test generalization to augmented validation data from un-augmented training data. MSR performs com-parably to or better than other methods under this augmented regime. Results are shown with 95% confidenceintervals over test tasks.
Table 4: In the ablation “MSR-Joint-FC” of Sec. 4 we jointly updated U and v in the inner loop with meta-learned inner loop learning rates for each. This is in contrast with standard MSR, where only v is updated inthe inner loop (also with a meta-learned learning rate), and U is only updated in the outer loop. The innerlearning rates were initialized at 0.02 for all variables. The table shows the inner loop learning rates at the endof training. The relative magnitudes suggest that v is being updated significantly more than U in the inner loop.
Table 5: The amount of training and test data provided to each method in the synthetic experiments of Table1 and Table 2. The last row indicates that on the test tasks,, all methods were expected to solve each problemusing a single example from that task.
