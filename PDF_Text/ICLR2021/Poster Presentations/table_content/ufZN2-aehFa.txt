Table 1: Posterior predictive log-likelihood on functions drawn from GP priors with RBF, weaklyperiodic, and Matern-5/2 kernels, averaged over context sets with N ∈ {0, 1, . . . , 64} points (table)and in dependence of N (figure). BA consistently outperforms MA, independent of the likelihoodapproximation, with MC being the most expressive choice. PB represents an efficient, deterministicalternative, while the VI approximation tends to perform worst, in particular for small N .
Table 3: Posterior predictive log-likelihood on 1D and 3D quadratic functions with limited numbersL of training tasks, averaged over context sets with N ∈ {0, 1, . . . , 20} data points. BA outperformsMA by considerable margins in this regime of little training data.
Table 2: Relative evaluation runtimes and#parameters of the optimized network ar-chitectures on RBF GP. Also cf. Tab. 9.
Table 4: Posterior predictive log-likelihood on the dynamics of a Furuta pendulum, averaged overcontext sets with N ∈ {0, 1, . . . , 20} state transitions. BA performs favorably on this real-world task.
Table 6: Comparison of the posterior predictive log-likelihood of our BA with traditional MA,combined with a self-attention (SA) mechanism in the encoder (BA does not use an SA mechanism),using the PB and MC likelihood approximations. We provide results for Laplace SA (L-SA), dot-product SA (DP-SA), and mulihead SA (MH-SA) and repeat the results for BA and MA without SA(“no SA”). While L-SA and DP-SA do not increase predictive performance compared to MA withoutSA, MH-SA results in significant improvements. Nevertheless, vanilla BA still performs better or atleast on-par, while being computationally more efficient.
Table 5: Predictive log-likelihood on a 2Dimage completion task on MNIST, averagedover N ∈ {0, 1, . . . , 392} context pixels.
Table 7: Comparison of the predictive log-likelihood of NP-based architectures with two simple GP-based baselines, (i) Vanilla GP (optimizes the hyperparameters individually on each target task andignores the source data) (ii) Multi-task GP (optimizes one set of hyperparameters on all source tasksand uses them without further adaptation on the target tasks). Both GP implementations use RBF-kernels. As in the main text, we average performance over context sets with sizes N ∈ {0, ..., 64}for RBF GP and N ∈ {0, ..., 20} for the other experiments. Multi-task GP constitutes the optimalmodel (assuming it fits the hyperparameters perfectly) for the RBF GP experiment, which explains itssuperior performance. On the Quadratic 1D experiment, Multi-task GP still performs better than theother methods as this function class shows a relatively low degree of variability. In contrast, on morecomplex experiments like Quadratic 3D and the Furuta dynamics, none of the GP variants is ableto produce meaningful results given the small budget of at most 20 context points, while NP-basedmethods produce predictions of high quality as they incorporate the source data more efficiently.
Table 8: Input spaces and parameters used to generate data for training and testing the architecturesdiscussed in the main part of this paper. U (a, b) denotes the uniform distribution on the interval [a, b],and, likewise U {a, a + n} denotes the uniform distribution on the set {a, a + 1, . . . , a + n}.
Table 9: Relative evaluation runtimes and numbers of parameters of the optimized network archi-tectures on the GP tasks. The deterministic methods (PB, det.) are much more efficient regardingevaluation runtime, as they require only on forward pass per prediction, while the sampling-basedapproaches (VI, MC) require multiple forward passes (each corresponding to one latent sample) tocompute their predictions. We use S = 25 latent samples, as described in App. 7.5.4. Furthermore,BA tends to require less complex encoder and decoder network architectures compared to MA,because it represents a more efficient mechanism to propagate information from the context set to thelatent state.
Table 10: Posterior predictive mean squared error (MSE) on all experiments presented in this paper.
