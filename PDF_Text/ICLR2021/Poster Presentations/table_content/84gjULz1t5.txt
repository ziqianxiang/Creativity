Table 1: Parameter settings for the linear regression Problem.
Table 2: Parameter settings for the logistic regression problem (full-batch gradient).
Table 3: Parameter settings for the logistic regression problem (mini-batch gradient).
Table 4: Parameter settings for the deep neural network. (* means divergence for all options we try)E	Proofs of the theoremsE.1 Illustrative flowThe following flow graph depicts the relation between iterative variables and clarifies the rangeof conditional expectation. {Gk }k∞=0 and {Fk }k∞=0 are two σ-algebras generated by the gradientsampling and the stochastic compression respectively. They satisfyGo ⊂ Fo ⊂Gι ⊂F1 ⊂…⊂Gk ⊂ Fk ⊂…(X1, D1, H1)	(X2, D2, H2)	(X3,D3,H3)、	小、	小VF(X1iξ1)∈Go E1	VF(X2W2)EGi E2' Y1 ____	_	> γ2 ——..	1st round	..
