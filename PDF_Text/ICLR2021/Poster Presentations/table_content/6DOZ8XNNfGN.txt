Table 1: Dataset summary. Tasks are LP, SSC, FSC, for link prediction, semi- and fully-supervisedclassification. Split indicates the train/validate/test paritioning, with (a) = (Abu-El-Haija et al., 2018),(b) = to be released, (c) = (Hamilton et al., 2017), (d) = (Yang et al., 2016); (e) = (Hu et al., 2020).
Table 2: Results of node embeddings on Link Prediction. Left: Test ROC-AUC scores. Right: MeanRank on the right for consistency with Lerer et al. (2019). *OOM = Out of Memory.
Table 3: Node classification tasks. Left: test accuracy scores on semi-supervised classification (SSC)of citation networks. Middle: test micro-F1 scores for large fully-supervised classification. Right:test accuracy on an SSC task, showing only scalable baselines. We bold the highest value per column.
Table 4: Performance of GTTF against frameworks DGL and PyG. Left: Speed is the per epoch timein seconds when training GraphSAGE. Memory is the memory in GB used when training GCN. Allexperiments conducted using an AMD Ryzen 3 1200 Quad-Core CPU and an Nvidia GTX 1080TiGPU. Right: Training curve for GTTF and PyG implementations of Node2Vec.
Table 5: Decomposition of graph embedding methods to demonstrate unbiased learning. For WYS,Zu = concatenate(Lu , Ru).
