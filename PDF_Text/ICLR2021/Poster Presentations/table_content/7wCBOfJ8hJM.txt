Table 1: Multilingual machine translation with kNN-MT. All test sets are from newstest2019, exceptja-en/en-ja which are from newstest2020. Adding kNN-MT increases BLEU scores in all cases,and by over 3 points for en-de, zh-en and en-zh. Bold scores indicate significant results based onstatistically powered experiments (Card et al., 2020).
Table 2: Adding datastores with English source-side data can improve translation from other lan-guages by an average of 1 BLEU, suggesting that our representations generalize over different sourcelangauges. The model’s representations of the source generalize across languages and make cross-lingual retrieval effective.
Table 3: Domain adaptation using kNN-MT. The base MT system is trained on WMT’19 datawhich is also treated as the in-domain data for newstest2019. kNN-MT improves the base model byan average of 9.2 BLEU, without training, to achieve the best reported results on this task.
Table 4: Multilingual machine translation with kNN-MT on the validation set. We show the thetuned interpolation parameter (λ) as well as the tuned softmax temperature (T) for each languagepair.
Table 5: Domain adaptation using kNN-MT on the multi-domains validation data and newstest2018.
