Table 1: Mean±std of test accuracy (%) on non-i.i.d. CIFAR-10. ?: trained with 50K images without splitting.
Table 2: Compatibility of FEDBE with FEDAVGM and FEDPROX on non-i.i.d. CIFAR-10.
Table 3: FEDB E distillation targets. A: client average;C: clients; S: samples.
Table 4: FEDBE on non-i.i.d CIFAR-10 with different unlabeled data U.
Table 6: Systems heterogeneity (non-i.i.d. CIFAR-10)MethodConvNet ResNet20 ResNet32Table 5: Partial participation (Tiny-ImageNet)Method I ResNet20 MobileNetV2i.i.d	FEDAVG FEDBE	32.4±0.68 35.4±0.58	26.1±0.98 28.9±1.15	FedAvg FedProx	70.6±0.46 69.9±0.59 64.0±0.50 71.2±0.55 69.4±0.48 65.9±0.63non-i.i.d	FEDAVG	27.5±0.78	25.5±1.23	FedBE	^^73.3±0.56 77.1±0.61 70.2±0.39	FedBE	32∙4±0.81	27.8±0.99	+FedProx 73.7±0.24 77.5±0.51 71.6±0.37	to small and non-i.i.d. data or (b) local models drifting away from each other. FedBE suffers theleast among all methods, suggesting it as a promising direction to resolve the problem. To understandthe current limit, we conduct a study in Figure 4 by injecting more convolutional layers into ConvNet(Step setting). FEDAVG again degrades rapidly, while FEDBE is more robust. If we replace Bayesianensemble by the CIFAR-10 ground truth labels as the distillation target, FedBE improves with morelayers added, suggesting that how to distill with noisy labeled targets is the key to improve FedBE.
Table 5: Partial participation (Tiny-ImageNet)Method I ResNet20 MobileNetV2i.i.d	FEDAVG FEDBE	32.4±0.68 35.4±0.58	26.1±0.98 28.9±1.15	FedAvg FedProx	70.6±0.46 69.9±0.59 64.0±0.50 71.2±0.55 69.4±0.48 65.9±0.63non-i.i.d	FEDAVG	27.5±0.78	25.5±1.23	FedBE	^^73.3±0.56 77.1±0.61 70.2±0.39	FedBE	32∙4±0.81	27.8±0.99	+FedProx 73.7±0.24 77.5±0.51 71.6±0.37	to small and non-i.i.d. data or (b) local models drifting away from each other. FedBE suffers theleast among all methods, suggesting it as a promising direction to resolve the problem. To understandthe current limit, we conduct a study in Figure 4 by injecting more convolutional layers into ConvNet(Step setting). FEDAVG again degrades rapidly, while FEDBE is more robust. If we replace Bayesianensemble by the CIFAR-10 ground truth labels as the distillation target, FedBE improves with morelayers added, suggesting that how to distill with noisy labeled targets is the key to improve FedBE.
Table 7: FedBE with models sampled from a Dirichlet distribution on Step-non-i.i.d. CIFAR-10. Wecompare different α × 1 in setting the parameter of a Dirichlet distribution.
Table 8: One-round federated learning on Step-non-i.i.d. CIFAR-10 with ConvNet. We comparedifferent strategies to combine the clients’ local models, including weight average, (Bayesian) modelensemble, and ensemble distillation (with SGD or SWA).
Table 9: Non-i.i.d CIFAR-100Method	ConvNet	ResNet20	ResNet32FedAvg	32.5±0.78	37.5±0.65	33.3±0.55FedBE	36.6±0.52	43.5±0.89	37.7±0.69D DiscussionD. 1 Extra computation costFedBE involves more computation compared to FedAvg. The extra cost is on the server andno extra burden is on the clients. In practice, the server is assumed to be computationally rich sothe extra training time is negligible w.r.t. communication time. Using a 2080 Ti GPU on CIFAR-10 (ConvNet), building distributions and sampling takes 0.2s, inference of a model takes 2.4s,and distillation takes 10.4s. Constructing the ensemble predictions T = {(xj,Pj)}J=ι, wherePj = Mm PMM=I p(y∣xj； w(m)), requires each w(m) to be evaluated on U, which can be easilyparallelized in modern GPU machines. The convergence speed of the Monte Carlo approximationin Equation 4 is 1∕√M, yet We observe that M = 10 〜20 is sufficient for Bayesian model ensembleto be effective.
