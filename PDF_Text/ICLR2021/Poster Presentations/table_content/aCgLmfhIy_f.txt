Table 1: Few-shot classification accuracies (%) on FewRel dataset. The last block is the results of the series of our models with prototypes. We use LZ to briefly indicate Lz2s + Lz2s，. Results with t are reported as published, and other methods are implemented and evaluated by us. ↑ denotes outperformance over the main baseline MTB and ] denotes underperformance.				Method	5 way 1 shot	5 way 5 shot	10 way 1 shot 1	0 way 5 shotFinetUne(PCNN)t (Han et al.,2018b)	45.64	57.86	29.65	37.43Meta Network (CNN)t (Han et al.,2018b)	64.46	80.57	53.96	69.23GNN (CNN)t (Han et al,, 2018b)	66,23	81.28	46.27	64.02Prototypical NetWOrkt (Han et al., 2018b)	69,20	84.79	56.44	75.55MLMANt (Ye & Ling, 2019)	82.98	92.66	73.59	87.29BERTEM (Soares et al. 2019)	88.70	95.01	81.93	90.05MTB （Ns，）（	，	）	89,09	95,32	82.17	91.73BERTCE(ECE)	91.02()	95.40 (↑)	84.95 (↑)	91.43 (φ)IND (LIND)	89.90 (↑)	95.42 (↑)	82.47 (↑)	91.55(J)COL (Lz)	90.40 (↑)	94.73 Q)	84.27 (↑)	91.58 (J)COL (Lz + LCLS)	91.12(↑)	95.45 (↑)	85.10(↑)	91.75 (↑)COL (LS2S0 + LZ + LCLS)	91.08 (↑)	95.52 (↑)	85.83 (↑)	92.18 (↑)COLFinal(Ls2s + LZ + LCLS)	92.51 (↑)	95.88 (↑)	86.39 (↑)	92.76 (↑)Figure 3: Impact of # of relation typesFigure 4: Impact of # of instances per typeof relation types or amount of instances of each relation in training data. As shown in the figures,pre-trained relation encoders outperform the basic BERTEM model when short of training data.
Table 2: Accuracies (%) on FUzzyRED.
Table 3: AccUracies (%) on SemEval 2010 Task 8.
Table 4: Statistics of false positive (FP) rate of the raw data of FuzzyRED. An FP statement meansthat the statement does not express the relation but is distantly annotated the relation.
