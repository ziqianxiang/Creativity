Table 1: Architecture: each module is a 2-layer fully connected MLP with ReLU activation. Values in the tabledenote the size of each layer. We set the number of latent variables z outputted by the task module to be the sameas the layer size in all cases except for the low dimensional z setting, where we use the dimensions reported here.
Table 2: Hyperparameters for training self-play partners.
Table 3: Hyperparameters for adapting to new partners.
Table 4: Hyperparameters for First-Order MAML.
Table 5: Detailed individual results from the contextual bandit user study. Each cell is of the form a1/a2representing the actions made by the two partners. The task is shown in Figure 5.
