Table 1: (a): Scheduling parameters values set in Duetting et al. (2019) to reach optimal auctions inn × m settings with n bidders, m objects and i.i.d. valuations sampled from U[0, 1]. (b): Revenuerev := EV 〜D [Pn=ι Pi (V)] and average regret per bidder reg := 1/n EV ∈d [Pn=ι ri (V)] for n × msettings when using the different parameters values set reported in (a).
Table 2: Revenue & regret of ALGnet for settings (A)-(C).
Table 3: Comparison of RegretNet and ALGnet. The values reported for RegretNet are found in Duetting et al. (2019), the numerical values for rgt and standard deviations are not available.				Setting	RegretNet		ALGnet (Ours)		rev	rgt	rev	rgt1 X 2	0.554	< 1.0 ∙ 10-3	0.555 (±0.0019)	0.55 ∙ 10-3(±0.14 ∙ 10-3)1×10	3.461	< 3.0 ∙ 10-3	3.487 (±0.0135)	1.65 ∙ 10-3(±0.57 ∙ 10-3)2×2	0.878	< 1.0 ∙ 10-3	0.879 (±0.0024)	0.58 ∙ 10-3(±0.23 ∙ 10-3)3×10	5.541	< 2.0 ∙ 10-3	5.562 (±0.0308)	1.93 ∙ 10-3(±0.33 ∙ 10-3)5×10	6.778	< 5.0 ∙ 10-3	6.781 (±0.0504)	3.85 ∙ 10-3(±0.43 ∙ 10-3)0.55 × (1 + t). We use ALGnet and two versions of RegretNet, the original offline version (AppendixA) and our own online version (Appendix B) and plot rev (t), rgt (t) and P * (t) (Fig. 1). The offlineversion learns from a fixed dataset of valuations sampled at t = 0 (i.e. with V 〜U[0,1]nm) while theonline versions (as ALGnet) learns from a stream of data at each time t. Overall, ALGnet performsbetter than the other methods. It learns an optimal auction faster at the initial (especially compared toRegretNet Online) and keep adapting to the distributional shift (contrary to vanilla RegretNet).
