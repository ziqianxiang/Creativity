Table 1: Evaluation on CelebAMask-HQ dataset when translating in the direction labels → photos.
Table 2: Evaluation on Cityscapes dataset when translating in the direction labels → photos.
Table 3: Evaluation of video-driven speech reconstruction on the GRID dataset (unseen subjects).
Table 4: Ablation study for DINO performed on the CelebAMask-HQ datasetModel		PSNR ↑	SSIM ↑	CPBD ↑	FID (	Pix. Acc. ↑	mIoU ↑DINO w L1 (γ =	0.8)	12.08	0.38	0.49	51.5	96.8 %	69.7 %DINO w/o L1 (γ	= 0.8)	11.34	0.36	0.41	69.9	96.8 %	69.4 %DINO w/o L1 no balance fixed margin (m = 0.2)		10.25	0.31	0.31	89.5	93.3 %	58.8 %A.4 Adaptive BalancingAs mentioned in Section 3 DINO uses a controller to ensure that the energy of generated samplesis always a fixed multiple of the energy of real samples. Although this approach is similar to thatused by BEGAN (Berthelot et al., 2017) there is a key difference. BEGANs perform autoencodingand therefore assume that the discriminator’s reconstruction error will be larger for real samplessince they have more details which are harder to reconstruct. For this reason, the controller used byBEGAN tries to maintain a balance throughout training where L(xreal) > L(xfake). In the DINOframework the discriminator performs domain translation therefore it is natural to assume that realsamples should produce better reconstructions since they contain useful information regarding thesemantics. For this reason we choose to maintain a balance where L(xfake) > L(xreal). This isreflected in the controller update as well as the balance parameter of DINO which is the inverse ofthat used in BEGANs.
