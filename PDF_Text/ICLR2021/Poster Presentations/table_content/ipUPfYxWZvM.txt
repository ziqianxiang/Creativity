Table 1: Results for different de-coder orders on IWSLT14 De→En---------------------------- translation.
Table 2: Translations (Trans) from all ordered decoders of Transformer for one example sentence.
Table 3: Preliminary results of varied orders on IWSLT14 De→En task.
Table 4: BLEU scores of IOT on eight IWSLT loW-resource translation tasks.			En→De De→En En→Fr	Fr→En	En→Zh Zh→En En→Es Es→En	Transformer 28.57	34.64	35.9	36.1	26.3	18.4	39.0	40.6IOT	29.52	35.62	37.2	37.8	27.2	19.3	40.1	41.7respectively. Others are the same as NMT. For summarization, We take transformer_wmt_en_de,with 6 blocks, embedding size 512 and FFN size 2048. Dropout (Srivastava et al., 2014) is set to be0.3. Other settings are also the same as NMT task. Implementation is developed on Fairseq (Ott et al.,2019). We first grid search c1, c2 on IWSLT14 De→En dev set, and then apply them on other tasks.
Table 5: Results on IWSLT14 De→En translation task (a), Java and Python code generation tasks (b).
Table 6: WMT14 En→De andWMT16 Ro→En translation re-sults. ? stands for our reproducedresult.
Table 7: ROUGE-1/2/L F1 scores for Gigaword summarization.
Table 8: Inference time and model parameters counted for Transformer and our framework onIWSLT14 En什De. The study is performed on a single Tesla P100 GPU card.
Table 9: Training cost analysis for Transformer and our IOT on four IWSLT translation tasks. Thestudy is performed on a single Tesla P100 GPU card.
Table 10: Ensemble performancesof standard Transformer and IOT.
Table 11: Each numbered code for one specific ordered decoder.
Table 12: BLEU scores for IWSTL14 De→En and En→De translations on dev set. ‘12345’ representsthe combinations of order 1, 2, 3, 4, 5 decoders.
Table 13: BLEU scores on 8 IWSLT tasks with different N ordered decoders (with shared weights).
Table 14: BLEU scores for WMT14 En→De and WMT16 Ro→En translation tasks of different Nordered decoders in IOT.
Table 15: BLEU and PoV scores for Java and Python code generation results of different N ordereddecoders in IOT.
Table 16: ROUGE F1 scores for Gigaword abstractive summarization results of different N ordereddecoders in IOT.
Table 17: BLEU scores for IWSLT14 De→En dev set. The performances are varied by differentweighted auxiliary losses controlled by c1 and c2 value.
Table 18: Statistics of each English valid subset on IWSLT14 En→De translation. Si is the number ofsentences in set i. Correspondingly, Ti is the token number, Di is the vocabulary size. Fi = Pj2=0 1 fijis the sum of the frequency of top 20 tokens in set i, where fij is the frequency for token j .
Table 19: Samples of each English valid subset on IWSLT14 En→De translation.
Table 20: Regularization study experiments on 8 IWSLT translation tasks and WMT16 Ro→Entranslation. We study both setting (1): train Transformer model with all shared decoders but withoutinstance-wise learning, and setting (2): add LayerDrop (Fan et al., 2019) regularization techniqueexperiments on these tasks.
Table 21: Robustness study on IWSTL14 De→En translation task on dev set. ? is the order trainedby Transformer.
