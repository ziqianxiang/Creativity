Published as a conference paper at ICLR 2021
Deep Networks and the Multiple Manifold
Problem
Sam Buchanan	Dar Gilboa	John Wright
Columbia University	Harvard University	Columbia University
sdb2157@columbia.edu	dar_gilboa@fas.harvard.edu	jw2966@columbia.edu
Ab stract
We study the multiple manifold problem, a binary classification task modeled on
applications in machine vision, in which a deep fully-connected neural network
is trained to separate two low-dimensional submanifolds of the unit sphere. We
provide an analysis of the one-dimensional case, proving for a simple manifold
configuration that when the network depth L is large relative to certain geometric
and statistical properties of the data, the network width n grows as a sufficiently
large polynomial in L, and the number of i.i.d. samples from the manifolds is
polynomial in L, randomly-initialized gradient descent rapidly learns to classify
the two manifolds perfectly with high probability. Our analysis demonstrates con-
crete benefits of depth and width in the context of a practically-motivated model
problem: the depth acts as a fitting resource, with larger depths corresponding
to smoother networks that can more readily separate the class manifolds, and
the width acts as a statistical resource, enabling concentration of the randomly-
initialized network and its gradients. The argument centers around the “neural
tangent kernel” of Jacot et al. and its role in the nonasymptotic analysis of train-
ing overparameterized neural networks; to this literature, we contribute essen-
tially optimal rates of concentration for the neural tangent kernel of deep fully-
connected ReLU networks, requiring width n ≥ L poly(d0) to achieve uniform
concentration of the initial kernel over a d0-dimensional submanifold of the unit
sphere Sn0-1, and a nonasymptotic framework for establishing generalization of
networks trained in the “NTK regime” with structured data. The proof makes
heavy use of martingale concentration to optimally treat statistical dependencies
across layers of the initial random network. This approach should be of use in
establishing similar results for other network architectures.
1 Introduction
Data in many applications in machine learning and computer vision exhibit low-dimensional struc-
ture (Fig. 1a). Although deep neural networks achieve state-of-the-art performance on tasks in these
areas, rigorous explanations for their performance remain elusive, in part due to the complex interac-
tion between models, architectures, data, and algorithms in neural network training. There is a need
for model problems that capture essential features of applications (such as low dimensionality), but
are simple enough to admit rigorous end-to-end performance guarantees. In addition to helping to
elucidate the mechanisms by which deep networks succeed, this approach has the potential to clarify
the roles of various network properties and how these should reflect the properties of the data.
These considerations lead us to formulate the multiple manifold problem (Fig. 1b), a binary classi-
fication problem in which the classes are two disjoint submanifolds of the unit sphere Sn0-1, and
the classifier is a deep fully-connected ReLU network of depth L and width n trained on N i.i.d.
samples from a distribution supported on the manifolds. The goal is to articulate conditions on the
network architecture and number of samples under which the learned classifier provably separates
the two manifolds, guaranteeing perfect generalization to unseen data. The difficulty of an instance
of the multiple manifold problem is controlled by the dimension of the manifolds d0, their separation
∆, and their curvature κ, allowing us to study the constraints imposed by these intrinsic properties
of the data on the settings of the neural network’s architectural hyperparameters such that the two
manifolds can be separated by training with a gradient-based method.
1
Published as a conference paper at ICLR 2021
⑶	(b)
Figure 1: (a) Data in image classification with standard augmentation techniques, as well as other
domains in which neural networks are commonly used, lies on low dimensional class manifolds—
in this case those generated by the action of continuous transformations on images in the training
set. Tangent vectors at a point on the manifold corresponding to an application of a rotation or a
translation are illustrated in green. The dimension of the manifold is determined by the dimension of
the symmetry group, and is typically small. (b) The multiple manifold problem. Our model problem,
capturing this low dimensional structure, is the classification of low-dimensional submanifolds of
a sphere Sn0-1. The difficulty of the problem is set by the inter-manifold separation ∆ and the
curvature κ. The depth and width of the network required to provably reduce the generalization
error efficiently are set by these parameters.
Our main result is an analysis of the one-dimensional case of the multiple manifold problem, which
reduces the analysis of the gradient descent dynamics to the construction of a certificate—showing
that a certain deterministic integral equation involving the network architecture and the structure of
the data admits a solution of small norm. We construct such a certificate for the simple geometry in
Fig. 3, guaranteeing generalization in this setting.
Theorem 1 (informal). Let d0 = 1. Suppose a certificate for M exists. Then if the network depth
satisfies L ≥ poly(κ, Cρ, log(n0)), the width satisfies n ≥ Poly(L, log(Ln0)), and the number of
training samples satisfies N ≥ poly(L), randomly-initialized gradient descent on N i.i.d. samples
rapidly learns a network that separates the two manifolds with overwhelming probability. The con-
stants Cρ , κ depend only on the data density and the regularity of the manifolds. In addition, if
L & ∆-1, then a certificate exists for the configuration ofM shown in Fig. 3.
Theorem 1 gives a provable generalization guarantee for a model classification problem with deep
networks on structured data that depends only on the architectural hyperparameters and properties of
the data. In addition, it provides an interpretable tradeoff between the architectural settings necessary
to separate the two manifolds: the network depth needs to be set according to the intrinsic difficulty
of the problem, and the network width needs to grow with the depth. Our analysis gives further
insight into the independent roles played by each of these parameters in solving the problem, with
the depth acting as a ‘fitting resource’, making the network’s output more regular and easier to
change, and the width acting as a ‘statistical resource’, granting concentration of the network over
the random initialization around a well-behaved object that we can analyze. Moreover, the sample
complexity of Theorem 1 is dictated by the intrinsic difficulty of the problem instance which is set by
the geometry of the data. As a consequence, we avoid any dependence of the width of the network
on the number of samples, which is common in deep network convergence results in the literature
(e.g. (Allen-Zhu et al., 2019b; Du et al., 2019), (Chen et al., 2021, Theorem 3.4)). As is the case in
practice, given a fixed architecture, more data doesn’t have a detrimental effect on fitting 1.
Theorem 1 is modular, in the sense that a generalization guarantee is ensured for any geometry for
which one can construct a certificate. The key to our approach will be to approximate the gradient
1 When using data augmentation, for example, the number of samples is effectively infinite yet highly struc-
tured, enabling convergence and generalization.
2
Published as a conference paper at ICLR 2021
descent dynamics with a linear discrete dynamical system defined in terms of the so-called neural
tangent kernel Θ(x, x0) defined on the manifolds. Due to the structure in the data, diagonalizing
the operator corresponding to this kernel is intractable in general, but we show that constructing a
certificate—arguably an easier task, because it requires producing a bound on the norm of a solution
to an equation rather than producing the solution itself—suffices to guarantee that the error decreases
rapidly during training given a suitably structured network.
We summarize the primary contributions of this work below.
•	Generalization in deep networks: There are few generalization results for deep networks
trained efficiently with gradient descent available in the literature.2 Theorem 1 provides
such a guarantee that does not depend on any property of the trained network (e.g., norms
of final weights) that is not readily available before training. In this context, the certifi-
cate condition is equivalent to the initial network function having a controlled norm in a
certain RKHS; this condition is natural in the training regime we consider, and appears
ubiquitously in works on generalization in shallower networks (Ghorbani et al., 2020; Ji &
Telgarsky, 2020; Nitanda & Suzuki, 2021).
•	Uniform concentration of the neural tangent kernel for deep ReLU networks: As an inter-
mediate step in the proof of Theorem 1, we establish essentially optimal rates of uniform
concentration for the neural tangent kernel of an arbitrarily deep network (Theorem 2)
using martingale concentration, where we require the width to grow only linearly with
the depth. We expect this martingale approach to be applicable to essentially any other
compositionally-structured network architecture. Our uniform result generalizes prior re-
sults on pointwise concentration (Arora et al., 2019b; Allen-Zhu et al., 2019b), analogous
to our Theorem B.3, and proves useful in establishing generalization.
•	Strong regularity estimates for random ReLU networks: As a further consequence of the
uniform concentration framework we have developed, we obtain depth-logarithmic Lips-
chitz estimates for random ReLU networks of arbitrary depth and linear width, as well as
(for still wider networks) a uniform approximation for the network output by a constant
which improves with depth, both with overwhelming probability (Section 3.3). We also
control the evolution of the Lipschitz constant during NTK regime training (Lemma B.7),
showing that it scales polynomially in the depth. These results may be of interest in appli-
cations where guaranteeing a Lipschitz property for networks is important, such as GAN
training (Miyato et al., 2018) or denoising (Ryu et al., 2019; Sun et al., 2020).
1.1	Related Work
Deep networks and low-dimensional structure. The notion of modeling data as low-dimensional
submanifolds has been widely considered in the context of clustering (Wang et al., 2015) and man-
ifold learning (Donoho & Grimes, 2005; Fefferman et al., 2016). Goldt et al. (2020) independently
proposed the “hidden manifold model”, a model problem for learning shallow neural networks for
binary classification of structured data with motivations very similar to ours and which admits a
mean-field analysis (Gerace et al., 2020). The data model consists of gaussian samples from a
low-dimensional subspace passed through a nonlinear function acting coordinatewise in the stan-
dard basis; although this models statistical variations around a base domain, a feature of real data
that the model we study here lacks, we believe that the study of an arbitrary density supported on
two Riemannian manifolds lends our data model increased structural generality. In the context of
kernel regression with the kernel given by the NTK of a two-layer neural network, Ghorbani et al.
(2020) study a data generating model that consists of uniform samples from a low-dimensional sub-
sphere corrupted additively by independent uniform samples from a subsphere in the orthogonal
complement, and a target mapping that depends only on the low-dimensional part. The authors ob-
tain asymptotic generalization guarantees for this data model that reveal conditions under which the
corruption degrades the performance of neural tangent methods.
2The closest result we are aware ofis (Chen et al., 2021, Theorem 3.4); this result involves a-priori assump-
tions on the trained network weights, which are only resolved for two-layer networks, and entails an unnatural
relationship between n and N and a possible exponential dependence of N on L, which Theorem 1 avoids.
3
Published as a conference paper at ICLR 2021
Analyses of neural network training. To reason analytically about the complicated training pro-
cess, we adopt the neural tangent kernel approach (Jacot et al., 2018). The first works to instantiate
these ideas in a nonasymptotic setting obtained convergence guarantees for training deep neural net-
works on finite datasets (Allen-Zhu et al., 2019b; Du et al., 2019). By exploiting more structure
in the data, generalization results have been obtained (Allen-Zhu et al., 2019a; Arora et al., 2019a;
Ji & Telgarsky, 2020; Oymak et al., 2019; Cao & Gu, 2019; Suzuki, 2020; Li et al., 2020; Allen-
Zhu & Li, 2020) that apply to shallow networks, teacher-student learning scenarios, and/or hold
conditional on the existence of certain small-norm interpolators. Other works have obtained gener-
alization guarantees using generalization bounds for kernel methods (Ghorbani et al., 2019; Liang
et al., 2020; Ghorbani et al., 2020; Montanari & Zhong, 2020) using the fact that the linearized
predictor in the NTK regime can be linked to a kernel method (Arora et al., 2019b). A parallel line
of works (Mei et al., 2018; Tzen & Raginsky, 2020; Mei et al., 2019; Chizat & Bach, 2020; Fang
et al., 2020) approach the problem by studying an infinite-width limit of neural network training
that yields a different training dynamics. Approaches of this type are of interest because there is no
restriction to short-time dynamics, and the limit of the dynamics can often be characterized in terms
of a well-structured object, such as a max-margin classifier (Chizat & Bach, 2020). On the other
hand, it is often difficult to prove finite-time convergence to the limit.
2 Problem Formulation and Main Results
2.1	Data Model and Network Definitions
We consider data supported on the union of two class manifolds M = M+ ∪ M-, where M+ and
M- are two disjoint smooth regular simple curves taking values in Sn0-1, with n0 ≥ 3. We denote
the data measure supported on M that generates our samples as μ∞, with corresponding density ρ,
and write ρmin = infx∈M ρ(x) and ρmax = supx∈M ρ(x). We denote by κ a uniform bound on the
(extrinsic) curvature of the two curves, we write ∆ = minx∈M+,x0∈M- ∠(x, x0) for the separation
between class manifolds, where ∠(x, x0) = cos-1hx, x0i for unit vectors, and to have a quantitative
characterization of ‘how simple’ the curves are, we assume there exist constants 0 < cλ ≤ 1,
Kλ ≥ 1 such that for every 0 < s ≤ cλ∕κ and every x, x0 in a common connected component of
M, one has distM(x, x0) ≤ Kλs if ∠(x, x0) ≤ s, where distM denotes the Riemannian distance.
Our target function is the signed indicator for each class manifold f?(x) = 1M+ (x) - 1M- (x).
The model we consider is a fully-connected neural network with ReLU activations and access to
i.i.d. samples from μ∞ and their corresponding labels. We parameterize our neural network with
weights W1 ∈ Rn×n0, W' ∈ Rn×n if ' ∈ {2,..., L}, and WL+1 ∈ R1×n, which We collect as
θ = (W1,..., W L+1), and write the iterates of the forward pass as Oθ (x) = [W 'α^-1(x)] + for
` = 1, . . . , L with α0θ(x) = x, which we also refer to as features or activations, with the network
output written as fθ(x) = WL+1αθL(x), and the prediction error as ζθ(x) = fθ(x) - f?(x).
For an i.i.d. sample (xι,..., XN) from μ∞, we write μN =方 PN=I δχi for the empirical measure
associated to the sample, and we consider the training objective L*n (θ) = 2 JM (Zθ(x))2 dμN (x),
i.e. the empirical risk evaluated with the square loss. We train with vanilla gradient descent with
constant step size τ > 0: after randomly initializing the parameters θNN as W' 〜n. N(0,2∕n) if
' ∈ [L] and WL+1 〜n. N(0,1) we consider the sequence of iterates θN+ι = θN - T VL*n (θN)
where VL*n represents a formal gradient of the empirical loss, which we define in detail in AP-
pendix A.1. We say the parameters obtained at iteration k of gradient descent separate the manifolds
M if the classifier implemented by the neural network with the parameters θkN labels the two man-
ifolds correctly, i.e. if f?(x) sign(fθN (x)) = 1 for every x ∈ M. As a shorthand, we will denote
quantities evaluated at θkN with a subscript k; an omitted subscript will denote k = 0, and we will
write explicitly θ0 = θ0N. Additional notation is provided in Appendix A.5.1.
2.2	Error Dynamics and Certificates
Because it is difficult to endow the network parameters generated by the gradient iteration with a
particular interpretation, we prefer to reason about how the network error ζkN evolves under gradient
4
Published as a conference paper at ICLR 2021
descent. We calculate (in Lemma B.8)
ζN+ι(x) = ZN(X)-T [ θN(X,XO)ZN(XO)dμN(XO),
M
(2.1)
1
where we have defined the integral kernel ΘN(x, xo) = f0 "fe? (xo), ^fθN7丁十L n(θn)(x))dt,
.	U，	1	.	C	I	「.…...I .	…	..	...	..μ	.
where Vfθo denotes a formal gradient of the initial network function With respect to the parameters,
which is defined in detail in Appendix A.1. We then define a nominal error evolution by
Zk∞+1(X)
Zk∞(X) - τ
M
Θ(x, X0)Z∞(X0)dμ∞(X0)
(2.2)
with identical initial conditions Z0∞ = Z and where Θ(X, XO) = hVfθ0 (X), Vfθ0 (XO)i is the so-
called neural tangent kernel with associated integral operator Θ. We prove that the error evolution
(2.1) is well-approximated by the nominal error evolution under suitable conditions on the network
width, step size, and number of samples, which together ensure that training proceeds in the “NTK
regime” where ΘkN stays close to Θ. As for the nominal error evolution (2.2), we note that this
system is linear, time-invariant, and stable when τ is set appropriately small, so the norm of the
nominal error is guaranteed to decrease rapidly if the initial error Z aligns well with eigenfunctions of
Θ corresponding to large eigenvalues. However, computation of these eigenfunctions is intractable
for general data geometries and distributions because the operator Θ is not generally translationally
invariant on M. To overcome this issue, we prove this alignment implicitly by constructing an
approximate solution to the linear integral equation Θ[g]
Z SUCh that kg∣∣Lμ∞
is sufficiently
small. To be precise, g ∈ L'∞ will be called a δι, δ2-certificate for the dynamics (2.2) if
kΘ[g]-ZkL2∞ ≤δ1; kgkL2∞ ≤δ2.	(2.3)
2.3	Main Results and Proof Outline
Our main result is that conditional on the existence of a certificate of suitably small norm for M,
gradient descent provably separates the two manifolds in time polynomial in the network depth.
Theorem 1.	Let M be a one-dimensional Riemannian manifold satisfying our regularity assump-
tions. For any 0 < δ ≤ 1/e, choose
L ≥ Ci max{Cμ∞ log9(1∕δ)log24 (Cμ∞n log(1∕δ)), k2K；/c；},
n = C2L99 log9(1∕δ)log18(Lno),
N ≥ L10,
and fix τ such that nC32 ≤ T ≤ C4.
Then ifthere exists a certificate in the sense of (2.3) with δι = C5Cp/2 plog(1∕δ) log(nno)∕L and
δ2 = C6 piog(1∕δ) log(nno)∕(nρmn), Withprobability at least 1 一 δ over the random initialization
of the network and the i.i.d. SamPlefrom μ∞, the parameters obtained at iteration bL39∕44∕(nτ)C
ofgradient descent on the finite sample loss L*n yield a classifier that separates the two manifolds.
The constants C1 , . . . , C6 are suitably chosen absolute constants, the constants κ, Kλ, cλ are
respectively the extrinsic curvature constant and the global regularity constant defined in Sec-
tion 2.1, the constant CP is defined as max{ρmi∏, ρm1∏}, and the constant Cμ∞ is defined as
cp5(1+ Pmax)6 (min {μ∞(M+),μ∞(M-)})T∕2.
For one-dimensional instances of the two manifold problem with sufficiently deep and overparame-
terized networks trained in the small-step-size regime, Theorem 1 completely reduces the analysis of
the gradient iteration to the certificate problem. From a qualitative perspective, the network resource
constraints imposed by Theorem 1 are natural:
(i) The network depth L is set by geometric and statistical properties of the data with only a
mild polylogarithmic dependence on the ambient dimension n0, which reflects the role of
depth in controlling the capability of the network to fit functions.
5
Published as a conference paper at ICLR 2021
(ii)	The network width n is set by the depth L: the inductive structure of the network causes
quantities that depend on the initial random weights θ0 to concentrate worse as the depth
is increased, which can be counteracted by setting the width appropriately large.
(iii)	The sample complexity of N ≥ L10 reflects the capacity of the network via the depth,
and is in particular independent of the width n, which can thus be interpreted as purely a
statistical resource.
In addition, the conclusion of Theorem 1 implies not just that the expected generalization error
with respect to μ∞ of a binary classifier is zero, but the stronger separation property, i.e. that the
generalization error will be zero for any choice of test distribution supported on M simultaneously.
We give a brief sketch of the proof of Theorem 1 in Appendix A.4. To obtain a generalization
guarantee from Theorem 1, it only remains to construct a certificate for M. We demonstrate this for
the family of simple, highly-symmetric geometries shown in Figure 3, and leave the case of general
one-dimensional manifolds for future work.
Proposition 1. Let M be an r-instance of the two circles geometry studied in Appendix C.1.1
and shown in Figure 3, with r ≥ 1/2. For any 0 < δ ≤ 1/e, if L ≥ C1∆-1 and n ≥
C2L5 log4(1∕δ) log4(Ln0 log(1∕δ)) ,then there exists a certificate in the sense of (2.3) satisfying the
requirements of Theorem 1 with probability at least 1 - 3δ for some absolute constants C1, C2 > 0.
Taking a union bound, Proposition 1 shows that under the hypotheses of Theorem 1, with probability
at least 1 - 4δ a certificate exists for the geometry shown in Figure 3 as soon as L is larger than
a constant multiple of the inverse separation ∆-1, even as the separation approaches zero. We
conjecture that a similar phenomenon holds for more general geometries, possibly with additional
dependencies on the curvature and global regularity parameters ofM. The dependence of L on the
geometry is due to the “sharpening” effect the depth has on the kernel Θ governing the dynamics
and thus on the fitting capabilities of the network, as illustrated in Figure 2a.
Figure 2: (a) Depth acts as a fitting resource. As L increases, the rotationally-invariant kernel ΘΘ (a
slight modification of the deterministic kernel in Theorem 2) decays more rapidly as a function of
angle between the inputs ∠(x, x0) (n is held constant). Below the curves we show an isometric chart
around a point x ∈ M+. Once the decay scale ofΘ is small compared to the inter-manifold distance
∆ and the curvature of M-, the network output can be changed at x while only weakly affecting
its value on M-. This is one mechanism that relates the depth required to solve the classification
problem to the data geometry. (b) Width acts as a statistical resource. The dynamics at initialization
are governed by Θ, a random process over the network parameters. As n is increased, the normalized
fluctuations of Θ around ΘΘ decrease (here L = 10). These two phenomena are related, since the
fluctuations also grow with depth, as evinced by the scaling in Theorem 2.
To prove that the nominal error evolution (2.2) decreases rapidly and approximates the actual error
evolution (2.1) throughout training, it is essential to have a precise characterization of the ‘initial’
neural tangent kernel Θ. One of our main technical contributions is to show concentration of Θ in
the regime where the width n scales linearly with the depth L.
6
Published as a conference paper at ICLR 2021
Theorem 2.	For any d0 ∈ N, let M be a d0 -dimensional complete Riemannian submanifold of
Sn0-1. Then if n ≥ C1Ld3 40 log4(CMn0L), one has with probability at least 1 - n-10 that for
every (x, x0) ∈ M × M
Θ(x, x0) -
L-1	L-1
2 x cos (d`)(V)) Y (1 -
'=0	'0=' ∖
C2ʌ/nL3d0 Iog4(CMnno),
where we write V = ∠(x, x0) with an abuse of notation,夕(')denotes the '-fold composition of
夕(V) = cos-1 ((1 一 V) cos v + SinV), the constants C1,C2 > 0 are absolute, and the constant
CM > 0 depends only on the diameters and curvatures of the class manifolds (Lemma C.4). 3
For networks of uniform width that are wider than they are deep by a certain constant factor, we
believe that the scalings in Theorem 2 are essentially optimal: the variance calculations of Hanin
& Nica (2020) give some heuristic evidence here, and we believe the idea of using diagonal con-
centration to prove deviation lower bounds could be generalized to rigorously establish optimality.
Figure 2b illustrates the phenomenon underlying Theorem 2. We discuss the proof of Theorem 2 in
more detail in Sections 3.1 and 3.3.
3 Key Proof Elements
3.1	Concentration at Initialization: Martingales and Angle Contraction
The initial kernel Θ is a complicated random process defined over the weights (W 1, . . . , WL+1).
To control it, we first show for fixed (x, x0) that Θ(x, x0) concentrates with high probability, and
then leverage approximate continuity properties to pass to uniform control of Θ. Here we describe
our approach to pointwise control; uniformization is discussed in Section 3.3. The kernel can be
written in the form
L-1
Θ(x, x0) = hαL(x), αL(x0)i + X hα'(x), α'(x0)ihβ'(x), β'(x0)i,
'=0
where β'(x) = (W l+1Pil(x) ∙ ∙ ∙ W '+2P∕'+ι(x))* Will be referred to as backward features, and
P'(x)isaprojeCtion onto {a' (x) > 0}. We consider hβ0(x), βo(x0)i as a representative example:
up to a small residual term, this random variable can be expressed as a sum of martingale differences.
Formally, for ' ∈ [L], let F' denote the σ-algebra generated by all weight matrices up to layer ',
with F0 denoting the trivial σ -algebra. We can then write
L+1
Ihβ0(x), βo(x0)i - go (V0) I ≤ E g'(W',…，W1, V0) - E[g'(W',..., W 1,v0) I F'-1] + R
'=1
(3.1)
for some functions g` and controllable residual R, where Vo = ∠(x, x0). Ifwe fix all the variables in
F'-1, the fluctuations in the '-th summand will be due to W' alone. Intuitively, since each weight
matrix appears at most once in βo (x),4 it will appear at most twice in g`, and therefore g` will
have a subexponential distribution conditioned on F'-1 and concentrate well around its conditional
expectation. This property stems from the compositional structure of the network, with independent
sources of randomness introduced at every layer, and is essentially agnostic to other details of the
architecture. The concentration of the summands in (3.1) implies concentration of the sum: even
though the summands are not independent, they can be controlled using concentration inequalities
analogous to those for sums of independent variables (Azuma, 1967; Freedman, 1975).
Showing that terms of the form ha'(x), α'(x0)i concentrate in the linear regime gives rise to ad-
ditional challenges. Here we exploit an essential difference between the concentration properties
3Since we do not use the “NTK parameterization”, the norm of our NTK scales like nL rather than L. Due
to our scaling of the weights (Section 2.1) the contribution of the final layer to the NTK is negligible and can
be dropped. This leads to discrepancies between the expression above and similar expressions found in the
literature—we show essential equivalence between our NTK and others in Appendix A.3.
4Technically, the features α'(x) depend on all the weights up to layer ' and hence so does the projection
matrix Pi'(x), but our analysis shows that this dependence has only a minor effect on the statistical fluctuations.
7
Published as a conference paper at ICLR 2021
of the angles between features V' = ∠(α'(x), α'(x0)) relative to those of the correlation process
(α'(x), α'(x0)i studied in prior works on concentration of Θ: when V'-1 = 0, We have that V' = 0
deterministically, whereas the correlation process behaves like a subexponential random variable
with small but nonzero deviations. Together with smoothness, this clamping phenomenon allows
us to show concentration of the angle at layer ' around the function 夕(')(v0), which is no larger
than a constant multiple of '-1. This contraction of the angles with depth is the key to establishing
Theorem 2; in addition, it gives the invariant kernel Θ (see Figure 2b) its sharpness at zero and
localization properties, both of which increase as the depth is increased and which we exploit in the
proof of Proposition 1. We provide full details of our approach in Appendices D and E.
3.2	Certificate Construction: General Formulation and a Simple Example
Figure 3: The coaxial circles
geometry.
By a simple argument that relies on positiveness of Θ, we show
that if we can solve the certificate problem (2.3), then for a suitably
chosen learning rate τ and number of iterations k (Lemma B.6)
P [kZ∞kL2ce ≤ CP√dlOgL] ≥ 1-e-cd.
μ∞	L
If the network is sufficiently deep, the norm of the nominal error can
thus be made arbitrarily small in a number of iterations that scales
only polynomially with the problem parameters.
Because our formulation of the certificate problem (2.3) accommodates approximate solutions, un-
der a minor condition on the network width n (see Proposition 1) it suffices to solve an auxiliary
system Θ[g] = ζ, where Θ and ζ are analytically-convenient approximations to Θ and ζ produced
by our concentration analysis, including Theorem 2. For the simple geometry in Fig. 3, we show
in Appendix C.1.1 how to solve this auxiliary system using Fourier analysis, where we require
L & ∆-1 . The depth of the network is thus determined by the geometry of the data, and specifi-
cally by the inter-manifold distance which intuitively sets the “difficulty” of the fitting problem. In
Section 4 we discuss approaches to constructing certificates for general smooth curves.
3.3	Uniform Concentration and its Consequences
To uniformize the pointwise estimates of Section 3.1, we must overcome the issue that the back-
ward features β'(x) are not continuous functions of the input, due to the matrices 马雇工).OUr
approach is to discretize the input space, control the number of features that can change sign near
each point in the discretization, then extend the pointwise estimates of Section 3.1 to the setting
where a small number of features have changed sign—again, we find martingale concentration a
necessity to achieve linear width-depth scaling. We give full details in Appendix D.3.
Although Theorem 2 is the main application of these estimates—with uniform control of Θ, we
can prove operator norm bounds on its corresponding integral operator Θ, which is of great help
in proving generalization results—they also imply useful regularity estimates for the initial ran-
dom network fθ0 . For example, we prove that networks of uniform width n	n40L are with high
probability ,no(log n°)(log L)-Lipschitz as functions on Rn0 (Theorem B.5)—in particular, the
ipschitz constant depends only logarithmically on depth, in contrast to existing results in the lit-
erature (Nguyen et al., 2020). For networks of larger width n & d03L5, we prove that with high
probability the network fθ0 is approximately constant on the domain M ⊂ Sn0-1 (Lemma D.11):
/
M
sup fθ0 (x) -
x∈M
fθo (x0)dμ∞(x0) . 1.
L
We find this result to be useful in simplifying the certificate construction problem of Section 3.2.
4 Discussion
Certificates for curves. The most urgent task toward expanding the scope of Theorem 1 is the
construction of certificates for geometries beyond the coaxial circles of Proposition 1. The proof
8
Published as a conference paper at ICLR 2021
of Proposition 1 relies heavily on translation invariance of the intra- and inter-manifold distances in
the coaxial circles geometry in order to avoid the need for certain sharp technical estimates for the
decay of the kernel Θ. With sharper control of the decay of the kernel Θ, it is possible to select
the network depth in a way that grants appropriate worst-case control of the magnitude of the cross-
manifold integrals in the action of Θ (as in Figure 2a), allowing Us to reduce to What is essentially
a one-manifold certificate construction problem that can be solved with harmonic analysis. Beyond
these considerations, it is important to extend Theorem 1 to manifolds of dimension d0 > 1, which
should be relatively straightforward. Our concentration results, notably including Theorem 2, are
already applicable to manifolds of arbitrary dimension.
Convolutional networks and non-differentiable manifolds. Although we have motivated our
data model in the multiple manifolds problem using applications in computer vision, it is important
to note that the spatially-structured image articulation manifolds that arise as data in these contexts
do not carry a differentiable structure (Wakin et al., 2005), so the assumption of bounded curva-
ture may not be realistic here. On the other hand, in these applications it is standard to employ a
convolutional network architecture. We anticipate that our martingale concentration framework can
be extended to these architectures, and beyond establishing analogues of Theorem 1 in this setting,
we believe it should be possible to obtain similar guarantees for models of image articulation man-
ifolds. In particular, one might expect randomly-initialized convolutional networks to enjoy local
invariance properties, like the scattering networks of Mallat (Mallat, 2012; Bruna & Mallat, 2013),
which could achieve a degree of invariant classification without expending additional network re-
sources computing convolutions over general LCA groups (Cohen & Welling, 2016).
The importance of being low-dimensional. Ghorbani et al. (2019) show that kernel ridge regres-
sion with any rotationally invariant kernel on Sd (including that of a deep network) is equivalent to
polynomial regression with a degree p polynomial if the number of samples is bounded by dp+1 and
d → ∞. For data lying on a low-dimensional manifold, as we consider here, one would expect less
pessimistic rates; indeed, in a subsequent work (Ghorbani et al., 2020) the authors establish similar
guarantees to Ghorbani et al. (2019) for a linear data model with low-dimensional structure in terms
of a smaller “effective dimension”. In comparison, although our present certificate construction ar-
gument only implies dynamics for the restrictive coaxial circles geometry of Figure 3, for which
one can obtain guarantees for kernel regression with a shallow NTK by the results of Ghorbani et al.
(2020), the general multiple manifold problem formulation allows one to model nonlinear structure
in the data, and measures fitting difficulty through intrinsic parameters like the curvature and sep-
aration. The guarantees in Ghorbani et al. (2019; 2020) depend on the degree of approximability
of the target function by low-degree polynomials, and although this achieves additional generality
over our model, it seems more challenging to relate this to geometric or other types of nonlinear
low-dimensional structure.
The NTK regime and beyond. In recent years there has been much work devoted to the analysis
of networks trained in the regime where the changes in ΘkN remain small and the dynamics in
(2.1) are close to linear (Jacot et al., 2018; Lee et al., 2019; Arora et al., 2019b; Allen-Zhu & Li,
2019) (referred to as the NTK/“overparametrized”/kernel regime). Concurrently, there have also
been results highlighting the limitations of this regime. In (Chizat & Bach, 2018) the authors coin
the term “lazy training” in referring to dynamics where the relative change in the differential of the
network function is small compared to the change in the objective during gradient descent. While
the dynamics we study indeed fall into this category, the analysis makes it evident that not all lazy
training regimes are created equal. Our performance guarantees depend on the structure of the kernel
ΘΘ, and on controlling the fluctuations of ΘN around it. We are able to control these only if the width
of the network is sufficiently large compared to the depth. In contrast, lazy training can also be
achieved in homogeneous models by simply scaling the output of the model (Chizat & Bach, 2018),
in which case one cannot argue that the kernel has the decay properties that enable it to fit data.
Our analysis hinges on staying in the NTK regime during training. We obtain suboptimal scaling
of n with L in Theorem 1 because we treat all changes that occur in ΘkN during training as being
adversarial to the algorithm’s ability to generalize. It is likely that if an improved understanding of
feature learning can be incorporated into an analysis of the dynamics, the resulting scaling require-
ments would be more realistic.
9
Published as a conference paper at ICLR 2021
Acknowledgments
This work was supported by the grants NSF 1733857, NSF 1838061, NSF 1740833, NSF 1740391,
NSF NeuroNex Award DBI-1707398 (DG), the Gatsby Charitable Foundation (DG) and a Swartz
fellowship (DG), and by a fellowship award (SB) through the National Defense Science and Engi-
neering Graduate (NDSEG) Fellowship Program, sponsored by the Air Force Research Laboratory
(AFRL), the Office of Naval Research (ONR) and the Army Research Office (ARO). The authors
would like to thank Ethan Dyer, Guy Gur-Ari, Quynh Nguyen, Jeffrey Pennington, Sam Schoenholz,
Daniel Soudry, and Tingran Wang for helpful discussions/feedback.
References
P-A Absil, R Mahony, and R Sepulchre. Optimization Algorithms on Matrix Manifolds. Princeton
University Press, April 2009.
Zeyuan Allen-Zhu and Yuanzhi Li. What can resnet learn efficiently, going beyond kernels? In
Advances in Neural Information Processing Systems, pp. 9015-9025, 2019.
Zeyuan Allen-Zhu and Yuanzhi Li. Backward feature correction: How deep learning performs deep
learning. arXiv preprint arXiv:2001.04413, January 2020.
Zeyuan Allen-Zhu, Yuanzhi Li, and Yingyu Liang. Learning and generalization in overparameter-
ized neural networks, going beyond two layers. In Advances in Neural Information Processing
Systems, volume 32, 2019a.
Zeyuan Allen-Zhu, Yuanzhi Li, and Zhao Song. A convergence theory for deep learning via Over-
Parameterization. In Proceedings of the 36th International Conference on Machine Learning,
volume 97 of Proceedings of Machine Learning Research, pp. 242-252. PMLR, 2019b.
Sanjeev Arora, Simon Du, Wei Hu, Zhiyuan Li, and Ruosong Wang. Fine-Grained analysis of opti-
mization and generalization for overparameterized Two-Layer neural networks. In Proceedings of
the 36th International Conference on Machine Learning, volume 97 of Proceedings of Machine
Learning Research, pp. 322-332. PMLR, 2019a.
Sanjeev Arora, Simon S Du, Wei Hu, Zhiyuan Li, Russ R Salakhutdinov, and Ruosong Wang.
On exact computation with an infinitely wide neural net. In Advances in Neural Information
Processing Systems, pp. 8139-8148, 2019b.
Kazuoki Azuma. Weighted sums of certain dependent random variables. Tohoku Mathematical
Journal, Second Series, 19(3):357-367, 1967.
StePhane Boucheron, Maud Thomas, et al. Concentration inequalities for order statistics. Electronic
Communications in Probability, 17, 2012.
StePhane Boucheron, Ggbor Lugosi, and Pascal Massart. Concentration Inequalities: A NonaSymP-
totic Theory of Independence. OUP Oxford, February 2013.
Haim Brezis. Functional Analysis, Sobolev SPaces and Partial Differential Equations. Springer,
New York, NY, 2011.
Joan Bruna and Stephane Mallat. Invariant scattering convolution networks. IEEE Trans. Pattern
Anal. Mach. Intell., 35(8):1872-1886, August 2013.
Yuan Cao and Quanquan Gu. Generalization bounds of stochastic gradient descent for wide and
deep neural networks. In Advances in Neural Information Processing Systems, volume 32, 2019.
Zixiang Chen, Yuan Cao, Difan Zou, and Quanquan Gu. How much over-parameterization is suffi-
cient to learn deep ReLU networks? In International Conference on Learning RePresentations,
2021.
LenaiC Chizat and Francis Bach. A note on lazy training in supervised differentiable programming.
CoRR, abs/1812.07956, 2018.
10
Published as a conference paper at ICLR 2021
Lenaic Chizat and Francis Bach. Implicit bias of gradient descent for wide two-layer neural networks
trained with the logistic loss. In Proceedings of Thirty Third Conference on Learning Theory,
volume 125 of Proceedings ofMachine Learning Research, pp. 1305-1338. PMLR, 2θ2θ.
Youngmin Cho and Lawrence K Saul. Kernel methods for deep learning. In Advances in neural
information processing systems, pp. 342-350, 2009.
Taco Cohen and Max Welling. Group equivariant convolutional networks. In Proceedings of The
33rd International Conference on Machine Learning, volume 48 of Proceedings of Machine
Learning Research, pp. 2990-2999, New York, New York, USA, 2016. PMLR.
Donald L Cohn. Measure Theory. Birkhauser, New York, NY, 2 edition, 2013.
R M Corless, G H Gonnet, D E G Hare, D J Jeffrey, and D E Knuth. On the LambertW function.
Adv. Comput. Math., 5(1):329-359, December 1996.
Herbert A. David. Order Statistics, pp. 1039-1040. Springer Berlin Heidelberg, Berlin, Heidelberg,
2011. ISBN 978-3-642-04898-2.
Victor H de la Pena. A general class of exponential inequalities for martingales and ratios. Ann.
Probab., 27(1):537-564, January 1999.
David L Donoho and Carrie Grimes. Image manifolds which are isometric to euclidean space. J.
Math. Imaging Vis., 23(1):5-24, July 2005.
Simon S Du, Xiyu Zhai, Barnabas Poczos, and Aarti Singh. Gradient descent provably optimizes
over-parameterized neural networks. In International Conference on Learning Representations,
2019.
Lawrence Craig Evans and Ronald F Gariepy. Measure Theory and Fine Properties of Functions.
CRC Press, December 1991.
Cong Fang, Jason D Lee, Pengkun Yang, and Tong Zhang. Modeling from features: a mean-field
framework for over-parameterized deep neural networks. arXiv preprint arXiv:2007.01452, July
2020.
Charles Fefferman, Sanjoy Mitter, and Hariharan Narayanan. Testing the manifold hypothesis. J.
Amer. Math. Soc., 29(4):983-1049, February 2016.
David A Freedman. On tail probabilities for martingales. Ann. Probab., 3(1):100-118, February
1975.
Federica Gerace, Bruno Loureiro, Florent Krzakala, Marc Mezard, and Lenka Zdeborova. General-
isation error in learning with random features and the hidden manifold model. In Proceedings of
the 37th International Conference on Machine Learning, volume 119 of Proceedings of Machine
Learning Research, pp. 3452-3462. PMLR, 2020.
Behrooz Ghorbani, Song Mei, Theodor Misiakiewicz, and Andrea Montanari. Linearized two-layers
neural networks in high dimension. CoRR, abs/1904.12191, 2019.
Behrooz Ghorbani, Song Mei, Theodor Misiakiewicz, and Andrea Montanari. When do neural
networks outperform kernel methods? In Advances in Neural Information Processing Systems,
volume 33, pp. 14820-14830. Curran Associates, Inc., 2020.
Sebastian Goldt, Marc Mezard, Florent Krzakala, and Lenka Zdeborovd. Modeling the influence of
data structure on learning in neural networks: The hidden manifold model. Phys. Rev. X, 10(4):
041044, December 2020.
Boris Hanin and Mihai Nica. Finite depth and width corrections to the neural tangent kernel. In
International Conference on Learning Representations, 2020.
Christopher Heil. A Basis Theory Primer: Expanded Edition. Birkhauser Boston, 2011.
Roger A Horn, Roger A Horn, and Charles R Johnson. Topics in matrix analysis. Cambridge
university press, 1994.
11
Published as a conference paper at ICLR 2021
Arthur Jacot, Franck Gabriel, and Clement Hongler. Neural tangent kernel: Convergence and gener-
alization in neural networks. In Advances in Neural Information Processing Systems, volume 31.
Curran Associates, Inc., 2018.
Ziwei Ji and Matus Telgarsky. Polylogarithmic width suffices for gradient descent to achieve arbi-
trarily small test error with shallow ReLU networks. In International Conference on Learning
Representations, 2020.
Michel Ledoux and Michel Talagrand. Probability in Banach Spaces: Isoperimetry and Processes.
Springer, Berlin, Heidelberg, 1991.
Jaehoon Lee, Lechao Xiao, Samuel Schoenholz, Yasaman Bahri, Roman Novak, Jascha Sohl-
Dickstein, and Jeffrey Pennington. Wide neural networks of any depth evolve as linear mod-
els under gradient descent. In Advances in Neural Information Processing Systems, volume 32.
Curran Associates, Inc., 2019.
John M Lee. Introduction to Riemannian Manifolds. Springer, Cham, 2 edition, 2018.
Yuanzhi Li, Tengyu Ma, and Hongyang R Zhang. Learning Over-Parametrized Two-Layer neural
networks beyond NTK. In Proceedings of Thirty Third Conference on Learning Theory, volume
125 of Proceedings of Machine Learning Research ,pp. 2613-2682. PMLR, 2020.
Tengyuan Liang, Alexander Rakhlin, and Xiyu Zhai. On the multiple descent of Minimum-Norm
interpolants and restricted lower isometry of kernels. In Proceedings of Thirty Third Conference
on Learning Theory, volume 125 of Proceedings of Machine Learning Research, pp. 2683-2711.
PMLR, 2020.
StCphaneMallat. Group invariant scattering. Commun. PureAPPL Math., 65(10):1331-1398, Octo-
ber 2012.
Song Mei, Andrea Montanari, and Phan-Minh Nguyen. A mean field view of the landscape of
two-layer neural networks. Proc. Natl. Acad. Sci. U. S. A., 115(33):E7665-E7671, August 2018.
Song Mei, Theodor Misiakiewicz, and Andrea Montanari. Mean-field theory of two-layers neural
networks: dimension-free bounds and kernel limit. In Proceedings of the Thirty-Second Confer-
ence on Learning Theory, volume 99 of Proceedings of Machine Learning Research, pp. 2388-
2464, Phoenix, USA, 2019. PMLR.
Takeru Miyato, Toshiki Kataoka, Masanori Koyama, and Yuichi Yoshida. Spectral normalization
for generative adversarial networks. In International Conference on Learning RePresentations,
2018.
Andrea Montanari and Yiqiao Zhong. The interpolation phase transition in neural networks: Mem-
orization and generalization under lazy training. arXiv PrePrint arXiv:2007.12826, July 2020.
Robb J Muirhead. AsPects of Multivariate Statistical Theory. Wiley Series in Probability and
Statistics. John Wiley & Sons, Inc., Hoboken, NJ, USA, March 1982.
Quynh Nguyen, Marco Mondelli, and Guido Montufar. Tight bounds on the smallest eigenvalue of
the neural tangent kernel for deep ReLU networks. arXiv PrePrint arXiv:2012.11654, December
2020.
Atsushi Nitanda and Taiji Suzuki. Optimal rates for averaged stochastic gradient descent under
neural tangent kernel regime. In International Conference on Learning RePresentations, 2021.
Samet Oymak, Zalan Fabian, Mingchen Li, and Mahdi Soltanolkotabi. Generalization guaran-
tees for neural networks via harnessing the low-rank structure of the jacobian. arXiv PrePrint
arXiv:1906.05392, June 2019.
Mark Rudelson and Roman Vershynin. Non-asymptotic theory of random matrices: Extreme sin-
gular values. In Proceedings of the International Congress of Mathematicians 2010 (ICM 2010),
pp. 1576-1602. June 2011.
12
Published as a conference paper at ICLR 2021
Ernest Ryu, Jialin Liu, Sicheng Wang, Xiaohan Chen, Zhangyang Wang, and Wotao Yin. Plug-
and-Play methods provably converge with properly trained denoisers. In Proceedings of the 36th
International Conference on Machine Learning, volume 97 of Proceedings of Machine Learning
Research,pp. 5546-5557. PMLR, 2019.
John M Sullivan. Curves of finite total curvature. In Discrete differential geometry, pp. 137-161.
Springer, 2008.
Y Sun, J Liu, and U S Kamilov. Block coordinate regularization by denoising. IEEE Transactions
on Computational Imaging, 6:908-921, 2020.
Taiji Suzuki. Generalization bound of globally optimal non-convex neural network training: Trans-
portation map estimation by infinite dimensional langevin dynamics. In Advances in Neural
Information Processing Systems, volume 33, pp. 19224-19237. Curran Associates, Inc., 2020.
Michel Talagrand. Concentration of measure and isoperimetric inequalities in product spaces. Pub-
Iications Mathematiques de IfInstitut des Hautes Etudes Scientifiques, 81(1):73-205, 1995.
Belinda Tzen and Maxim Raginsky. A mean-field theory of lazy training in two-layer neu-
ral nets: entropic regularization and controlled McKean-Vlasov dynamics. arXiv preprint
arXiv:2002.01987, February 2020.
Roman Vershynin. High-dimensional probability: An introduction with applications in data science,
volume 47. Cambridge University Press, 2018.
Michael B Wakin, David L Donoho, Hyeokho Choi, and Richard G Baraniuk. The multiscale
structure of non-differentiable image manifolds. In Wavelets XI, volume 5914, pp. 59141B. Inter-
national Society for Optics and Photonics, 2005.
Xu Wang, Konstantinos Slavakis, and Gilad Lerman. Multi-Manifold Modeling in Non-Euclidean
spaces. In Proceedings of the Eighteenth International Conference on Artificial Intelligence and
Statistics, volume 38 of Proceedings of Machine Learning Research, pp. 1023-1032, San Diego,
California, USA, 2015. PMLR.
Jonathan Weed and Francis Bach. Sharp asymptotic and finite-sample rates of convergence of em-
pirical measures in wasserstein distance. Bernoulli, 25(4A):2620-2648, November 2019.
Shunhui Zhu. The comparison geometry of ricci curvature. In Comparison Geometry, volume 30
of MSRI Publications, pp. 221-262. Cambridge University Press, May 1997.
13
Published as a conference paper at ICLR 2021
Contents
A Extended Problem Formulation	16
A.1 Regarding the Algorithm ...................................................... 16
A.2	Regarding the Data Manifolds ................................................ 16
A.3	Regarding the Initialization ................................................ 17
A.4	Proof Outline for Theorem 1 ................................................. 19
A.5	Notation .................................................................... 20
A.5.1 General Notation ...................................................... 20
A.5.2 Summary of Operator and Error Definitions ............................. 21
B Proofs of the Main Results	23
B.1	Main Results ................................................................ 23
B.2	Supporting Results on Dynamics .............................................. 27
B.3	Auxiliary Results ........................................................... 46
C	Skeleton Analysis and Certificate Construction	61
C.1	Certificate Construction .................................................... 61
C.1.1 Two Circles ........................................................... 62
C.2	Auxiliary Results ........................................................... 65
C.2.1 Geometric Results ..................................................... 65
C.2.2 Analysis of the Skeleton .............................................. 71
D Concentration at Initialization	83
D.1	Notation and Framework ...................................................... 83
D.2	Pointwise Concentration ..................................................... 83
D.2.1 Forward Concentration ................................................. 83
D.2.2 Backward Feature Control .............................................. 94
D.3	Uniformization Estimates ................................................... 101
D.3.1 Nets and Covering Numbers ............................................ 101
D.3.2 Controlling Support Changes Uniformly ................................ 101
D.3.3 Uniformizing Forward Features Under SSC .............................. 108
D.3.4 Small Support Change Residuals ....................................... 120
D.4	Auxiliary Results .......................................................... 148
E Sharp Bounds on the One-Step Angle Process	159
E.1	Definitions and Preliminaries .............................................. 160
E.2	Main Results ............................................................... 161
E.3	Supporting Results ......................................................... 162
E.3.1 Core Supporting Results .............................................. 162
14
Published as a conference paper at ICLR 2021
E.3.2	Proving Lemma E.6 ....................................................... 164
E.3.3	Proving Lemma E.7 ....................................................... 179
E.3.4	General Properties ...................................................... 186
E.3.5	Differentiation Results ................................................. 190
E.3.6	Miscellaneous Analytical Results ........................................ 202
E.4	Deferred Proofs ................................................................ 232
F Controlling Changes During Training	235
F.1	Preliminaries .................................................................. 235
F.2	Changes in Feature Supports During Training .................................... 235
F.3	Changes in Features During Training ............................................ 237
F.4	Changes in ΘkN During Training ................................................. 241
F.5	Auxiliary Lemmas and Proofs .................................................... 242
G Auxiliary Results
249
Appendices: Summary of Contents
We briefly summarize the contents of each of the subsequent appendices.
A.	We discuss the contents of the problem formulation section from the main body, Sec-
tion 2.1, in more technical detail, in particular giving technical definitions for formal gra-
dients, regularity conditions, and so on. We provide a proof sketch to offer some intuitions
about the proof of the main result. We also summarize notation and the key operator defi-
nitions that appear throughout the paper.
B.	We give proofs for our main results. We provide supporting results on the NTK regime
dynamics of gradient descent and other relevant technical lemmas, as discussed in the proof
sketch of Section 2.3.
C.	We give technical definitions relevant to the cross-manifold perspective on certificate con-
struction, construct a certificate for the two circles geometry of Figure 3, and provide tech-
nical estimates on the kernels ψ1 and ψ that remain after applying our measure concentra-
tion arguments to the NTK Θ.
D.	We collect results on measure concentration relevant to proving our main uniform con-
centration result for the NTK, Theorem 2. Some of these results are also relevant for
controlling changes during training.
E.	We collect results relevant to proving a certain concentration result for the angles between
features as they propagate across one layer of the initial neural network. The main results
of this section are fundamental to the study of the concentration of angles in Appendix D,
and we provide them in a separate appendix due to their length.
F.	We establish results on uniform control of the changes during training of the NTK ΘkN
from its “initial value” of Θ. These are a key ingredient in our dynamics arguments in
Appendix B.
G.	We provide statements of general technical lemmas that are of a classical nature, which we
rely on throughout the other appendices.
15
Published as a conference paper at ICLR 2021
A Extended Problem Formulation
A.1 Regarding the Algorithm
We analyze a gradient-like method for the minimization of the empirical loss L*n . After randomly
initializing the parameters	θN	as W'	〜i.i.d. N(0,2/n)	if ' ∈	[L]	and WL+1	〜i.i.d.	N(0,1),
independently of the samples x1, . . . , xN, we consider the sequence of iterates
θk+1 = θN-T V LμN (θN),	(A.1)
where τ > 0 is a step size, and VL*n represents a formal gradient of the loss L*n , which We
define as follows: first, we define formal gradients of the network output by
V W ` fθ (X)= βθT(x)α%T(x)*
for ` ∈ [L] and x ∈ M, where we have introduced the definitions
βθ(x) = (WL+1PiL(χ)WLPIL-ι(χ)…W'+2Pi'+ι(x))*
for ` = 0, 1, . . . , L - 1, and where we additionally define
I'(X) = SUpp (J (χ)>o) ,	PI'(x) = X eiei
i∈I'(x)
for the orthogonal projection onto the set of coordinates where the `-th activation at input x is posi-
tive. We call the vectors βθ(x) the backward features or backward activations——they correspond to
the backward pass of our neural network. We also define
V W L+1 fθ (x) = αL(x)*.
We then define the formal gradient of the loss L*n by
VLμN (θ)
(Vfθ(x)Zθ(x) dμN(x).
Let us emphasize again that the expressions above are definitions, not gradients in the analytical
sense: we introduce these definitions to cope with nonsmoothness of the ReLU [ ∙ ]+. On the other
hand, our formal gradient definitions coincide with the expressions one obtains by applying the chain
rule to differentiate L*n at points where the ReLU is differentiable, and we will make use of this
fact to proceed with these formal gradients in a manner almost identical to the differentiable setting.
We reiterate here our notational conventions for quantities evaluated at these iterates: we denote
evaluation of quantities such as the features and prediction error at parameters along the gradient
descent trajectory using a subscript k, with an omitted subscript denoting evaluation at the initial k =
0 parameters, and we add a superscript N to parameters such as the prediction error to emphasize
that they are evaluated at the parameters generated by (A.1). For example, in this notation we
express ζθN as ζkN . In addition, we use θ0 to denote the initial parameters θ0N . We emphasize
the dependence of certain quantities on these random initial parameters notationally, including the
initial network function fθ0 .
A.2 Regarding the Data Manifolds
We now provide additional details regarding our assumptions on the data manifolds. For background
on curves and more broadly Riemannian manifolds, we refer the reader to (Lee, 2018; Absil et al.,
2009). We assume that M = M+∪M-, where M+ and M- are two disjoint complete connected5
Riemannian submanifolds of the unit sphere Sn0-1, with n0 ≥ 3. In particular, M± are compact.
We take as metric on these manifolds the metric induced by that of the sphere, which we take in turn
as that induced by the euclidean metric on Rn0. We write μ∞ and μ∞ for the measures on M+
5Certain parts of our argument, such as the concentration result Theorem B.2, are naturally applicable to
cases where M± themselves have a finite number of connected components with a mild dependence on this
number, and we state them as such. We skip this extra generality in our dynamics arguments to avoid an
additional ‘juggling act’ that would obscure the main ideas.
16
Published as a conference paper at ICLR 2021
and M- (respectively) induced by the data measure μ∞, and We assume that μ∞ admits a density P
with respect to the Riemannian measure on M, writing ρ+ and ρ- for the densities on M± induced
by the density ρ. When d0 = 1, We add additional structural assumptions to the above: We assume
that M± are smooth, simple, regular curves.
Concretely, that M admits a density ρ With respect to the Riemannian measure means that
1 = ∣ dμ∞(x) = /	ρ+(x)dV+(x) + /	ρ-(x)dV-(x).
When d0 = 1, because M± are smooth regular curves, they admit global unit-speed parameteriza-
tions With respect to arc length γ± : I± → Sn0-1, Where I± are intervals of the form [0, len(M±)].
In this setting, the curvature constraint is expressed as
max
sup
s∈I+
sup
s∈I-
γ-00 (s)2	≤ κ,
and We observe that the fact that M± are sphere curves implies κ ≥ 1.6 Exploiting the coordinate
representation of the Riemannian measure and the fixed inherited metric from Rn0, We thus have
ρ±(x) dV±(x)
M±
ρ P± ◦ γ±(t)kγ±(t)k2 dt
I±
ρ± ◦ γ± (t) dt.
I±
We will exploit this formula in the sequel to compare between L%(M) and Lp(M) norms of func-
tions defined on the manifold. More generally, We Will frequently make use of similar reasoning that
leverages the existence of unit-speed parameterizations for the curves.
For clarity we rewrite the global regularity condition: we assume there exist constants 0 < cλ ≤ 1,
Kλ ≥ 1 such that
∀s ∈ (0, cλ∕κ], (x, x0) ∈ M? X M?, ? ∈ {+, -}	:	∠(x, x0) ≤ S ⇒ distM(x, x0) ≤ Kχs,
(A.2)
where distM denotes the Riemannian distance between points in a common connected component,
and we define Cλ = Kλ2∕c2λ. Because M± are simple curves, they do not self-intersect; the as-
sumption (A.2) gives a quantitative characterization of how far the curves are from self-intersecting.
We illustrate how the associated constants can be obtained from the assumption that the manifolds
are simple curves: for either ? ∈ {+, -}, consider a connected component M? ⊂ M, and for any
0 < s ≤ len(M?), define
r?(s) = inf	∠(x, x0).
x,x0∈M? ×M?,
distM (x,x0)>s
Ifr?(s) = 0, by compactness we can construct a sequence of pairs of points that converges to r?(s),
but this would imply that M? is self-intersecting, contradicting our assumption that it is simple. It
follows that r?(s) > 0 for any value of s. If we now define Ks = r*(s)∕s, it follows that for any
(x, x0) ∈ M? × M?,
∠(x, x0) ≤ s ⇒ distM(x, x0) ≤ Kss.
Our regularity assumption implies that a single such constant holds for a range of scales below the
curvature scale, which is a mild assumption since Ks approaches 1 as S approaches 0.
A.3 Regarding the Initialization
The manner in which we have defined our initial random neural network fθ0 is sometimes referred
to as “fan-out initialization” in the literature—it guarantees that feature norms are preserved from
layer to layer in the network, and thereby avoids the vanishing and exploding gradient problems.
The difference between this initialization and the so called “standard" or “fan-in” initialization is
only in the first and last layer weights, yet in a sufficiently deep network trained in the NTK regime
the effect of any single layer is negligible and the dynamics of our network will be essentially
identical to one with standard initialization. On the other hand, following the work of Jacot et al.
6We point out that the curvature of the manifolds does not enter into the proof of the concentration result
Theorem B.2, so there is no ambiguity in discussing curvature only in the context of curves.
17
Published as a conference paper at ICLR 2021
(2018), it has become common in the theoretical literature to consider a different construction of
the neural network called “NTK parameterization”, which is in some ways more convenient for
theoretical analysis. In particular, Arora et al. (2019b) prove their results on NTK concentration
using this parameterization; to facilitate a comparison between our concentration result (Theorem 2)
and theirs, we discuss the connection between fan-out and NTK parameterization in this section.
This material is well-known and no doubt can be found already in the literature, but we believe it
may be helpful to translate it into our notation.
Recall our definitions for the weights and features in our neural network: We have W' 〜i.i.d.
N(0, 2/n) if ' ∈ {0,1 ...,L} and WL+1 〜i.i.d. N(0,1), with features defined for ' = 0,1,...,L
by
`(	X x	' = 0
。"	ɪ [W'a'-1(x)]+ otherwise,
and output fθ0 (x) = WL+1αL(x). Within this section—and only within this section—we shall
define auxiliary weights by G(I) ∈ Rn×n0, G(') ∈ Rn×n for integer 1 < ' < L +1, and G(L+1) ∈
R1×n, with distributions G(') 〜n. N(0,1) for ' ∈ {0,1 ...,L + 1}, independent of everything
else in the problem. As before, for ' ∈ {0,1,...,L} we use α^Tκ (x) to denote the layer-' features:
(`)	x	` = 0
αNTK(X)= y [g⑶ɑjN-K)(x)i	otherwise.
This network’s output will be written
fNTK (χ)=(Yrn^ 卜 (L+ι)ɑNTκ(χ).
By 1-homogeneity (absolute) of σ, it follows that fθ0 = fNTK. As the notation suggests, the
network fNTK corresponds to a “NTK parameterization” network—although this network and fθ0
are equivalent in terms of predictions, their “gradients” are not equivalent. The NTK for the NTK
parameterization network is obtained by differentiating (at points of differentiability): after calcu-
lating (as in Lemma B.8), we introduce notation as we did for the fan-out parameterization network
in Appendix A.1, so that
ΘNTK(x,x0) =
之一	._2r_ ʌ ,
▽ fNTK(x), ▽ fNTκ(x
),
with (for ` = 1, . . . , L + 1)
▽ Gg fNTK (x) =(Y ʌ/nɔ βN-K)(x)αN-K)(x)*
where
βWκ (X) = {[G(L+I)PINTK(X)G(L)PINTK(X)…G(SPINTK(X))* ' = 0, 1,...,L - 1
and
INTK(X)=SUPP (IaNTK(X)>θ).
We shall relate the NTK parameterization NTK ΘNTK to our fan-out parameterization NTK Θ using
homogeneity of the ReLU. First, let us observe that
{i ∈ [n] I (a'(χ))i > 0}=ni ∈ [n] I(aNTK(x))> 0}.
because [ ∙]+ is 1-homogeneous and we have G(') = pn∕2W' when ' ≤ L. For ' ∈ {0,1,..., L},
we note that both α'(x) and 仪#黑⑶)depend only on the parameters (W1,..., W') and
(G ⑴，...，G⑶)，resPectively. Ifwewrite θ = (W1,..., W L) and Θntk = (G(I),..., G(L)),
then it follows that α'(x) is a '-homogeneous function of θ (and likewise for αNTκ(x)). In
18
Published as a conference paper at ICLR 2021
addition, the projection matrices P'(x) are 0-homogeneous functions of θ, and so taking ' ∈
{0,1,...,L _ 1} and counting parameters in the definitions of β'(x) and βN'Tκ(x) implies that
these two functions are (L - `- 1)-homogeneous functions ofθ and θNTK, respectively. Of course,
for ' = L, they are 0-homogeneous. Thus, using that G⑶==pn∕2W' for ' ≤ L again, We obtain
▽ G(') fNTK (X) = {
▽w'fθo (X)
`= L+ 1.
Although we have argued equidistributionality above for each index ` separately for simplicity, the
elementary nature of our arguments (we are just moving scalars around) and the statistical dependen-
cies across gradients allows us to apply the same argument ‘in parallel’ to the sum of inner products
between gradients, yielding
2L
Θntk(x, x0) = (αL(x), αL(x0)) + - X(α'-1(x), α'-1(x0))(β'-1(x), β'-1(x0)).
n '=1
This expression makes it immediately clear that our concentration frameWork proves sharp con-
centration of the NTK of a uniform-Width NTK parameterization feedforWard ReLU netWork that
improves over the results of Arora et al. (2019b) When the data are on the sphere7 —a simple adap-
tation of the proof of Theorem B.3 Will suffice.
A.4 Proof Outline for Theorem 1
In Appendix B, we prove a slightly more general version of Theorem 1 in Theorem B.1. Here, we
give a brief outline of the proof of this result.
Proving the separation property essentially requires us to obtain control of kζkN kL∞ (M), and by an
interpolation inequality (Lemma B.14) it suffices to control the generalization error kζkN kL2	and
μ∞
the smoothness (measured through the Lipschitz constant) of ζkN . We start with the generalization
error, picking up from where we left off at the end of Section 2.2: the triangle inequality gives
IlZNhμ∞ ≤ kZ∞kLμ∞ + ∣∣ζ∞- ZN葭,
(A.3)
Which alloWs us to divide the analysis into tWo subproblems: characterizing the nominal dynamics
(Lemmas B.6 and B.12), and the nominal-to-finite transition (Lemma B.7). Beginning With the
nominal dynamics, We use (2.2) to Write
Zk∞=(Id-τΘ)k [Z],
where Θ denotes the operator on Lμ∞ corresponding to integration against the kernel Θ and Id
denotes the identity operator. The definition of Θ and compactness of M imply that Θ is a posi-
tive, compact operator (Lemma B.9), so these dynamics are stable when τ is chosen larger than the
operator norm of Θ. However, the rate of decrease of kZk∞ kL2	with k could still be extremely
μ∞
slow if the initial error Z has significant components in the direction of eigenfunctions of Θ corre-
sponding to small eigenvalues, and because Θ acts roughly like a convolution operator, we expect
there to exist eigenvalues arbitrarily close to zero. By solving the certificate problem (2.3), we can
assert that misalignment does not occur. To solve the certificate problem, as we describe in Sec-
tion 3.2, we work with analytically-convenient approximations for Θ and Z: the exact definitions
of these approximations Θ and Z are given in Appendix A.5.2, and we prove their suitability as
approximations in Theorem B.2 (a slightly more general version of Theorem 2) and Lemma D.11,
respectively. As we have discussed in Section 3.1, our rates of concentration for Θ about Θ are
essentially optimal—the poor rates that end up appearing in Theorem B.1 are set by later parts of
the argument.
With our approximation to Θ justified, we show that for any sufficiently small step size τ and
number of iterations k, solving the certificate problem (2.3) guarantees appropriate decrease of the
7The results of Arora et al. (2019b) apply to data of norm no larger than 1, but it is straightforward to extend
our results for spherical data to this setting, using the 1-homogeneity of Θ in each argument (as a kernel on the
entire ambient space Rn0 × Rn0) to write Θ(x, x0) = ∣∣xk2kx0k2Θ(x∕kxk2, x0∕kx0k2).
19
Published as a conference paper at ICLR 2021
nominal generalization error; additional details are discussed in Section 3.2. The key property that
we use in constructing certificates in Proposition B.4 (the ‘appendix version’ of Proposition 1) is
that as the depth L increases, the kernel Θ sharpens and localizes (Fig. 2a): the conditions on L in
Theorem B.1 guarantee that the sharpness is sufficient to ensure that the cross-manifold integrals in
the certificate problem are small in magnitude, which leads to rapid decrease of the nominal error.
Our precise characterization of this phenomenon is presented in Appendix C.
To complete the proof, we will justify the nominal-to-finite transition in (A.3). Starting from the
update equations (2.1) and (2.2), subtracting and rearranging gives an update equation for the differ-
ence:
ζkN-ζk∞=(Id-τΘ)ζkN-1-ζk∞-1	- τ ΘkN-1	ζkN-1	+τΘζkN-1.
In particular, if τ is chosen less than the operator norm of Θ, we can take norms on both sides of
the previous equation, apply the triangle inequality, then exploit a telescoping series cancellation to
obtain the difference bound
k-1
l∣ζ∞ - ZNLμ∞ ≤ T
-1
Xs 0	M
s=0
θN (IXO)ZN (XO) dμN(XO)- yM θ(IXO)ZN (XO) dμ∞(XO)
Lμ∞
(A.4)
There are two obstacles to controlling the norm terms on the RHS of (A.4): the kernels ΘsN are
distinct from the kernel Θ due to changes in the weights that occur during training, and the empirical
measure μN incurs a sampling error relative to the population measure μ∞. To address the first
challenge, we measure the changes to the NTK during training in a worst-case fashion as
∆kN = i 0m1ax k	ΘiN - ΘL∞(M×M),
i∈{0,1,...,k}
and train in the NTK regime, where the network width n is larger than a large polynomial in the
depth L and the total training time kT is no larger than L/n. These conditions imply that with high
probability ∆kN is no larger than a constant multiple of n1-δ poly(L, d0) for a small constant δ > 0,
so that the amortized changes during training kT∆kN can be made small by sufficient overparam-
eterization. We provide full details of this argument in Appendix F. By the preceding argument,
we can use the triangle inequality and Jensen’s inequality to pass from the norm term in (A.4) to
a difference-of-measures term which integrates against Θ, and by Theorem B.2, we can replace
the integration against Θ by an integration against a smooth, deterministic kernel, which leads to a
bound
Im ψl(∠( ∙ , Xy)Zs(xo) (dμN(xo) - dμ∞3))
k-1
llZk∞ - ZkN llL2 ∞ ≤ Rk(n, L, d0) + T X
产	S=O
where Rk is a residual term that we argue is small in the NTK regime with high probability, and for
concision we write ψ1 to denote the function of ∠(X, XO) that appears in Theorem B.2. To control
the remaining term, we make use of a basic result from optimal transport theory, which states that
for any probability measure μ on the Borel sets of a metric space X and corresponding empirical
measure μN, one has for every Lipschitz function f
f(x)
X
(dμ(x) - dμN(x)) ≤ kf ∣∣LipW (μ, μN),
where W(∙, ∙) denotes the I-Wasserstein metric, and concentration inequalities for empirical mea-
sures in the 1-Wasserstein metric (Weed & Bach, 2019). To apply this result to our setting, it is
necessary to control the change throughout training of the Lipschitz constant of ZkN, and one must
also account for the fact that the metric space in our setting is M, which has two distinct connected
components. We treat the first issue using an inductive argument, and our treatment of the second
issue (Lemma B.13) leads to the dependence on the degree of class imbalance demonstrated in the
constant Cμ∞ in Theorem B.1.
A.5 Notation
A.5. 1 General Notation
Ifn ∈ N, we write [n] = {1, . . . , n}. We generally use bold notation X, A for vectors, matrices, and
operators and non-bold notation for scalars and scalar-valued functions. For a vector X or a matrix
20
Published as a conference paper at ICLR 2021
A, we will write entries as either xj or Aij, or (x)j or (A)ij; we will occasionally index the rows
or columns of A similarly as (A)i or (A)j, with the particular meaning made clear from context.
We write [x]+ = max{x, 0} for the ReLU activation function; if x is a vector, we write [x]+ to
denote the vector given by the application of [ ∙ ]+ to each coordinate of x, and We will generally
adopt this convention for applying scalar functions to vectors. If x, x0 ∈ Rn are nonzero, we write
∠(x, x0) = cos-1(hx, x0i/kxk2 kx0k2) for the angle between x and x0.
The vectors (ei) denote the canonical basis for Rn. We write hx, yi = Pi xiyi for the euclidean
inner product on Rn, and if 0 < p < +∞ we write kxkp = (Pi|xi|p)1/p for the `p norms (when
p ≥ 1) on Rn. We also write kxk0 = |{i ∈ [n] | xi 6= 0}| and kxk∞ = maxi∈[n] |xi|. The unit
ball in Rn is written Bn = {x ∈ Rn | kxk2 ≤ 1}, and we denote its (topological) boundary, the unit
sphere, as Sn-1. We reserve the notation k ∙ k for the operator norm of a m X n matrix A, defined
as IlAIl = Supkxk2≤1 ∣∣Axk2; more generally, we write ∣∣A∣∣'p→'q = SuPkxkp≤ι ∣∣Axkq for the
corresponding induced matrix norm. For m × n matrices A and B, we writehA, Bi = tr(A*B)
for the standard inner product, where A* denotes the transpose of A, and ∣∣A∣f = VZhAAy for
the Frobenius norm of A.
The Banach space of (equivalence classes of) real-valued measurable functions on a measure space
(X, μ) satisfying (JX |f ∣p dμ)^p < +∞ is written Lpμ (X) or simply Lp if the space and/or measure
is clear from context; we write IlTILp for the associated norm, and h ∙, ∙)工2 for the associated inner
product when P = 2, with the adjoint operation denoted by *. For an operator T : Lpμ → LV, We
write T[f] to denote the image of f under T, Ti to denote the operator that applies T i times, and
ITILp→Lqν = Supkf k p ≤1 IT[f]ILqν. We use Id to denote the identity operator, i.e. Id[g] = g for
Lμ 一
every g ∈ Lμ. We say that T is positive if hf, T[f])L ≥ 0 for all f ∈ L2; for example, the identity
operator is positive.
For an event E in a probability space, we write 1E to denote the indicator random variable that takes
the value 1 if ω ∈ E and 0 otherwise. If σ > 0, by g 〜N(0,σ2I) we mean that g ∈ Rn is
distributed according to the standard i.i.d. gaussian law with variance σ2, i.e., it admits the density
(2πσ2)-n/2 exp(-kx∣∣2∕(2σ2)) with respect to Lebesgue measure on Rn; we will occasionally
write this equivalently as g 〜i.i.d. N(0,σ2). We use = to denote the “identically-distributed”
equivalence relation.
We use “numerical constant” and “absolute constant” interchangeably for numbers that are inde-
pendent of all problem parameters. Throughout the text, unless specified otherwise we use c, c0 , c00,
C, C0, C00, K, K0, K00, and so on to refer to numerical constants whose value may change from line
to line within a proof. Numerical constants with numbered subscripts C1, C2, . . . and so on will
have values fixed at the scope of the proof of a single result, unless otherwise specified. We gener-
ally use lower-case letters to refer to numerical constants whose value should be small, and upper
case for those that should be large; we will generally use K, K0 and so on to denote numerical
constants involved in lower bounds on the size of parameters required for results to be valid. If f
and g are two functions, the notation f . g means that there exists a numerical constant C > 0
such that f ≤ Cg; the notation f & g means that there exists a numerical constant C > 0 such
that f ≥ Cg; and when both are true simultaneously we write f g . If f is a real-valued function
with sufficient differentiability properties, we will write both f0 and f for the derivative of f, and
when higher derivatives are available we will occasionally denote them by f(n), with this usage
specifically made clear in context. For a metric space X and a Lipschitz function f : X → R, we
write If ILip to denote the minimal Lipschitz constant of f .
A.5.2 Summary of Operator and Error Definitions
We collect some of the important definitions that appear throughout the main text and the appendices
in this section. We begin with the NTK-type operators that appear in our analysis. Recall from
Appendix A.1 our definition for the backward features: we have
βθ(x) = (WL+1PiL(X)WLPIL-ι(x)…W'+2Pi'+ι(x))*
for` = 0, 1, . . . , L - 1, and where we additionally define
I'(X) = SUpp (1αθ(x)>0),	PI'(X) = X eiei
i∈I'(x)
21
Published as a conference paper at ICLR 2021
for the orthogonal projection onto the set of coordinates where the `-th activation at input x is
positive. “The” neural tangent kernel is defined as
θ(X, XO) = D fθo(X), v fθo (XO)E
L-1
=<αL(x), αL(x0)> + X(a'(x), α'(x0)><β'(x), β'(x0)),
'=0
with corresponding operator on Lμ∞ (M)
Θ[g](X) = M
Θ(x, x0)g(x0) dμ∞(x0).
As shown in Lemma B.8, this is not exactly the kernel that governs the dynamics of gradient descent:
the relevant kernels in this context are defined as
θN (X, XO)= / DvfθN (XO), vfθN-tτ V LμN (θN )(x)E dt∙
We define operators ΘN on L：n (M) corresponding to integration against these kernel in a manner
analogous to the definition of Θ:
ΘkN [g](X) =
M
ΘN(x, X0)g(X0)dμN(xo).
We then move to the deterministic approximations for Θ that we develop: we define
夕(V) = cos-1 ((1 — ν∕π) cos V + (1/n) Sin ν),
which governs the angle evolution process in the initial random network, as studied in Appendix E,
and write 夕(') to denote '-fold composition of 夕 with itself. We define
ψ1(ν) = 2 X cos (*(V)) Y1 (1 — B!,
'=0	'0=' ∖	)
which is the “output” of our main result on concentration, Theorem B.2, and
L-1 L-1
ψ(ν)=nXn ι-
'=0 '0=' ∖
*(V )
π
which is at the core of the certificate construction problem. We think of ψ as an analytically-simpler
version of ψ1, with an approximation guarantee given in Lemma C.11. Throughout these appen-
dices, We will make use of basic properties of ψ1 and ψ that follow from properties of 夕 without
explicit reference; the source material for these types of claims is Lemma E.5, which gives ele-
mentary properties of 夕(for example, that it takes values in [0,∏∕2], which implies that ψ and ψ1
are no larger than nL/2). For derived estimates, we call the reader’s attention to the contents of
Appendix C.2.2; we will make explicit reference to these results when we need them, however.
Although we have mentioned approximations Θ and Θ in the main text, we will prefer in these
appendices to explicitly reference ψ and ψ1 to avoid confusion; as an exception, we will use the Θ
notation in Appendix C as discussed there. Our approximation for the initial prediction error is
ʌ
Z(X)
—f?(X) + 1∕m fθo (X0)dμ∞(X0),
(A.5)
where we recall fθ0 denotes the network function with the initial (random) weights. In particu-
lar, this approximates the network function with a constant, and the error as a piecewise constant
function on M±. This approximation is justified in Lemma D.11.
22
Published as a conference paper at ICLR 2021
B Proofs of the Main Results
B.1 Main Results
Theorem B.1.	LetM be a one-dimensional Riemannian manifold satisfying our regularity assump-
tions. For any 0 < δ ≤ 1/e, choose Lso that
L ≥ Ci max{Cμ∞ log9(1∕δ)log24 (Cμ∞n log(1∕δ)) ,κ2Cλ},
let N ≥ L10, set n = C2L99 log9(1∕δ) Iog18(Lno), and fix T > 0 such that
n⅜ ≤T ≤ Cl .
Then if there exists afunction g ∈ Lj∞ (M) such that
kΘ[g]-Zbμ∞(M) ≤ C5
VZlog(I/δ)log(nno).
L minρqmCienrt, ρ-mqinCert };
kgkLμ∞ (M) ≤ C6
Vzlog(I/δ)log(nno)
n CqCert
nρmin
(B.1)
with probability at least 1 -δ over the random initialization of the network and the i.i.d. sample from
μ∞, the parameters obtained at iteration [L39/44/(nT )C ofgradient descent on the finite SamPle loss
LμN yield a classifier that separates the two manifolds.
The constants C1 , . . . , C4 > 0 depend only on the constants qcert , C5 , C6 > 0, the con-
stants κ, Cλ are respectively the extrinsic curvature constant and the global regularity con-
stant defined in Section 2.1, and the constant Cμ∞ is defined as max{ρmin, Pm^n}(1 +
Pmax)6 (min {μ∞(M+), μ∞(M-)})-11/2, where q = 11 + 8qrert.
Proof. The proof is an application of Lemma B.7, with suitable instantiations of the parameters
of that result; to avoid clashing with the probability parameter δ in this theorem, we use ε for the
parameter δ appearing in Lemma B.7. Define Cρ = max{ρmin, ρ-m1in}. We will pick q = 39/44 and
ε = 5/47, so that the relevant hypotheses of Lemma B.7 become (after worst-casing in the bound
on N somewhat for readability)
d ≥ K log(nn0CM)
n ≥ K0 max∣L99d9 log9 L,κ2/5,
L ≥ K00 max{Cρ2qcert d, κ2Cλ}
1/3
C 133/18+(152/27)qcert (1 + P	)133/54
― min {μ∞(M+), μ∞(M-)}19/18	，，
and the conclusion we will appeal to becomes
/44/(nT)c∣L∞(M) ≤
CCp+2qcert/3(1 + Pmax)1/2 d3/4 log4/3 L
min {μ∞(M+), μ∞(M-)}1/2	L1/11
C0Le-cd
≥ 1----------
nT
Under our choice of T and enforcing
L≥
(2C)11Cp1+22qcerJ3(1 + pmax)11/2d33/4 log44/3 L
(min {μ∞(M+), μ∞(M-)})11/2
(B.2)
we have the equivalent result
ZNL39/44/(nT)cIIl∞(m) ≤ 2
≥ 1 - L3e-cd
≥ 1 - e-c0d
where the last bound holds when d ≥ K log L, which is redundant with the hypotheses on n and d
required to use Lemma B.7. Thus, when in addition d ≥ (1∕c0) log(1∕δ), we obtain
P _l|ZbL39/44/(nT)CllL∞(M) ≤ 2 ≥ 1 - *
(B.3)
P
P
23
Published as a conference paper at ICLR 2021
Therefore to conclude, we need only argue that our choices of n, N , L, d, and δ in the theorem
statement suffice to satisfy the hypotheses of Lemma B.7. We have already satisfied the conditions
on ε and q. We notice that (B.2) implies that it suffices to enforce simply N ≥ L10, and following
Lemma C.4, we can bound CM as in (B.62) in the proof of Lemma B.7 by
C	len(M+) len(M-) ≤ q1 + ρmax
M - μ μ∞(M+)+ μ∞(M-) — Pmin '
Because n ≥ L99 and L ≥ Cρ(1 + ρmax), we can eliminate CM from the lower bound on d while
paying only an extra factor of 2 in the constant. In addition, because K ≥ 1 and C ≥ max{ 1, 1∕cλ},
2/5	1/3
We can remove the κ2/5 and (^K) lower bounds on n, since they are enforced through L already
via the bound L ≥ K00κ2Cλ, worsening the absolute constant if needed. These simplifications lead
us to the sufficient conditions (plus the certificate existence hypotheses)
d ≥ Kmax{log(1∕δ), log(nno)}
n ≥ K0L99d9 log9 L
I 'K"	I Cp1+22qcert/3(1 + Pmax)11/2 d33/4 log44/3 L 2「[
L ≥ K max< --------------------------------1172----,κ C〉
[	(min {μ∞(M+),μ∞(M-)}) /	J
N ≥ L10.
We ignore the condition on N below, since it matches with the theorem statement. When δ ≤ 1/e,
given that no ≥ 3 we have nno ≥ e and max{log(1∕δ), log(nn0)} ≤ log(1∕δ) log(nno). For the
sake of simplicity, we can also round up the fractional constants in the lower bound on L. We can
eliminate d from these sufficient conditions by substituting the lower bound into the conditions on n
and L, and this also implies that our conditions on certificate existence in the theorem statement suf-
fice for the certificate existence hypothesis for Lemma B.7. Thus, we have the remaining sufficient
conditions
n ≥ KL99 log9(1∕δ) log9(nn0)log9 L
小 C Cp1+8qcert (1 + Pmax)6 log9(1∕δ) log9(nno)log15 L 2 ɪ
L ≥ K max<	1172,κ2Cλ〉.
[	(min {μ∞(M+), μ∞(M-)}) /	J
Using Lemma B.15 and choosing L larger than a sufficiently large absolute constant and larger than
log(1∕δ), we obtain that it suffices to enforce for n
n≥KL99log9(1∕δ)log18(Ln0).
In the hypotheses of the theorem, we have chosen the equality n = KL99log9(1∕δ)log18(Ln0) in
the last bound. This implies log(nn0) ≤ C log(Ln0), so it suffices to enforce the L lower bound
T ”,	∫Cp1+8qcert(1 + Pmax)6log9(1∕δ)log24(Lno) 2 ɪ
L ≥ K max<	, κ C〉.
[	(min {μ∞(M+),μ∞(M-)}) /	J
Defining, as in the theorem
C =	cρi+8qcert(1+ Pmax)6
μ (min {μ∞(M+), μ∞(M-)})11/2，
and using Cμ∞ ≥ 1, we can worsen the absolute constant K0 in order to apply Lemma B.15 once
again, obtaining the simplified condition
L ≥ CK0 max{Cμ∞ log9(1∕δ)log24 (Cμ∞n log(1∕δ)) ,κ2Cλ}.
These conditions reflect what is stated in the lemma.	□
Theorem B.2.	Let M be a d0-dimensional Riemannian submanifold of Sn0-1. For any d ≥
Kd0 log(nn0CM), if n ≥ K0d4L then one has on an event of probability at least 1 - e-cd
sup
(x,x0)∈M×M
L-1	L-1
θ(χ, x0)- 2 Xcos (*(V)) Y 11 -
乙 '=0	'0=' ∖
* (V)) I ≤ √d4nL3,
π
where we write V = ∠(x, x0) in context with an abuse of notation, c, K, K0 > 0 are absolute
constants, and CM > 0 depends only on the number of connected components of M and their
diameters and curvatures (Lemma C.4).
24
Published as a conference paper at ICLR 2021
Proof. We have by the definition of Θ
L-1
Θ(x, x0) = hαL(x), αL(x0)i + Xhα'(x), α'(x0)ihβ'(x), β'(x0)〉.	(B.4)
'=0
Under the stated hypotheses, Lemmas D.10 and D.13 give uniform control of each of the terms
appearing in this expression with suitable probability to tolerate 2L + 1 union bounds, which gives
simultaneous uniform control of the factors on an event E with probability at least 1 - e-cd. Starting
from (B.4), we can write with the triangle inequality
L-1	L-1
θ(X, XO)- 2 X cos Q⑻(V)) Y (1-
乙 '=0	'0=' ∖
*(V )
π
L-1
L-1
X hα'(X),α'(XO)ihβ'(X),β'(XO)i- n X
'=0
By the triangle inequality, we have
'=0
L-1
cos (*(V)) Y
'0='
1 - W) (V)
(B.5)
g L . . L L-1 /	/)J八
ha'(X), α (X，yihe (x), Ie(X- 2 cos W)(V)) Y (1 —∏—
L-1
≤ iha'(X), a`(")ii he'(X), β (Xy)- 2 Y
'0='
'0=' ∖
1 - 6'0) (V)
π
L-1
2 Y
'0='
1 - d')(V)[ ∣∣ha'(X), α'(X0)i - cos (d')
Under the conditions on n, L, and d, we have on the event E that for each `
sup ∣hα'(X), α'(X0)i∣ ≤ 2,
(x,x0)∈M
so we can conclude that on E
n	L-1
ha'(X), a'(X0)ihe'(X), e'(X0)i - 2 cos (d')(V)) Y I 1 -
'0=' ∖
d'0) (V )
π
≤ 3Vd4nL.
The conditions on n, d, and L imply that this residual is larger than that incurred by the level-L
features, which is no larger than 2. Returning to (B.5), we have shown that on E
L-1	L-1
θ(x, XO)- 2 X cos (* (V)) Y( 1 -
乙 '=0	'0=' ∖
*( V)
π
≤ C√d4nL3.
After adjusting the other absolute constants to absorb C into d, this gives the claim.	□
Theorem B.3 (Pointwise Version of Theorem B.2). Let M be a d0-dimensional Riemannian
submanifold of Sn0-1. For any d ≥ K log n, if n ≥ KO max{1, d4L} then one has for any
(X, XO) ∈ M × M
L-1	L-1
θ(x, XO)- 2 X Cos (* (V)) Y( 1 -
乙 '=0	'0 =' ∖
*( V)
)∣ ≤ √d4nL3] ≥ 1 -
e-cd
+
P
+
π
π
π
where we write V = ∠(X, XO) in context with an abuse of notation, and c, K, KO > 0 are absolute
constants.
Proof. Follow the proof of Theorem B.2, but invoke the pointwise versions of the uniform concen-
tration results used there (i.e., Lemmas D.1 and D.4) after rescaling d to relocate the log n terms. □
Proposition B.4. Let M be an r-instance of the two circles geometry studied in Appendix C.1.1,
with r ≥ 1/2. For any 0 < δ ≤ 1/e, if n ≥ KL5 log4(1∕δ) log4(Lno log(1∕δ)) and L ≥ Ko(1 一
r2)-1/2, then there exist absolute constants C5, C6 > 0 and a function g such that (B.1) is satisfied
with the choice qcert = 1/2 with probability at least 1 - 3δ. The constants K, KO > 0 are absolute.
25
Published as a conference paper at ICLR 2021
Proof. Given r ≥ 2 and L ≥ max{K, (π∕2)(1 - r2)-1/2},we have by Lemma C.1 that there exists
g such that RM ψ ◦ ∠( ∙, x0)g(x0) dμ∞(x0) = Z, with
Ilfll - ，一
kgkL2∞ ≤ (64∕√∏)忆忆M).	(B.6)
μ	nPmin
By this bound, the triangle inequality, the MinkoWski inequality, and the fact that μ∞ is a probability
measure, we have
l∣θ[g] -ZkLμ∞ ≤ I∣θ - ψ ◦ ∠kL∞(M×M)kgkLμ∞ + l∣ζ - ZkLμ∞
Ilfll.
≤ Ckθ - ψ ◦ ∠kL∞(M×M)--------1/2---+ kζ - ZkL∞(M).	(B.7)
nρmin
An application of Theorem B.2 and Lemma C.11 gives that on an event of probability at least
1 - e-cd
kΘ -ψ ◦ ∠kL∞(M×M) ≤ Cn∕L
ifd ≥ Kd0 log(nn0CM) and n ≥ K0d4L5. An application of Lemma D.11 gives
and
P[kZIl∞(M) ≤√d] ≥ 1-e-cd
as long as n ≥ Kd4L5 and d ≥ K0d0 log(nn0CM), where we use these conditions to simplify the
residual that appears in Lemma D.11. In particular, combining the previous two bounds with the
triangle inequality and a union bound and then rescaling d, which worsens the constant c and the
absolute constants in the preceding conditions, gives
P IIZll	≤ √d ≥ 1 - 2e-cd.
L∞(M)
Combining these bounds using a union bound and substituting into (B.7), we get that under the
preceding conditions, on an event of probability at least 1 - 3e-cd we have
kθ[g]- ZkLμ∞ ≤ CLd (1 + 7/2)
ρmin
C√d	1 1/2	-1/2]
≤ -ɪ max{pmn,pmin},
where we worst-case the density constant in the second line, and in addition, on the same event, we
have by (B.6)
∣∣g∣∣Lμ∞ ≤ (64Λ∕π)
√d
-172
nρmin
To conclude, we simplify the preceding conditions on n and turn the parameter d into a parameter
δ > 0 in order to obtain the claimed form of the result. We have in this setting d0 = 1, and also that
CM is bounded by an absolute constant; since n0 ≥ 3, we can thus eliminate the parameter CM
from our hypotheses by adding an extra absolute constant factor. Choosing d ≥ (1∕c) log(1∕δ), we
obtain that the previous two bounds hold on an event of probability at least 1 - 3δ. When δ ≤ 1∕e,
given that n0 ≥ 3 we have nn0 ≥ e and max{log(1∕δ), log(nn0)} ≤ log(1∕δ) log(nn0), so that it
suffices to enforce the requirement d ≥ K log(1∕δ) log(nn0) for a certain absolute constant K > 0.
We can then substitute this lower bound on d into the two certificate bounds above to obtain the
form claimed in (B.1) with qcert = 1∕2. For the hypothesis on n, we substitute this lower bound on
d into the condition on n to obtain the sufficient condition n ≥ K0L5 log4 (1∕δ) log4(nn0). Using
Lemma B.15 and possibly worsening absolute constants, we then get that it suffices to enforce
n ≥ K0L5 log4(1∕δ) log4(Lno log(1∕δ)), which is the hypothesis in the result.	□
26
Published as a conference paper at ICLR 2021
Theorem B.5. There exist absolute constants c, C, K, K0 > 0 such that for any d ≥ Kn0 log n, if
n ≥ K0d4L, then on an event of probability at least 1 - e-cd the natural extension of fθ0 to Rn0 is
3 √d-Lipschitz.
Proof. The proof is a simple application of Lemma B.17, which (because fθ0 is 1-nonnegatively
homogeneous and so are all its intermediate feature maps αθo (x)) implies that it suffices to control
the Lipschitz constants of the maps and bound them on the unit sphere, together with Lemmas D.11
and D.12. In particular, for anyd ≥ Kn0 log(n) and any n ≥ K0d4L, we have that there exists an
event of probability at least 1 - e-cd on which
kfθ Il L∞(Sn0-1) ≤ ʌ/d,
and
llfθlsn0-1 IlLip ≤ VZd.
Applying Lemma B.17, it follows that fθ0 : Rn0 → R is 3 Vd-Lipschitz on an event of probability
at least 1 - e-cd.
□
B.2 Supporting Results on Dynamics
Lemma B.6 (Nominal). Suppose Cerr , Ccert , qcert > 0 are absolute constants. Then there exist
absolute constants c, c0 , C0 , C00 , C000 > 0 and absolute constants K, K0 , K00 > 0 such that for
any d ≥ Kd0 log(nn0CM) and any 1/2 ≤ q ≤ 1, if n ≥ K0d4L5, if L ≥ K 00 dCρ2qcert, and if
additionally there exists g ∈ Lμ∞ (M) satisfying
kΘ[g] - Z bμ∞ (M) ≤ CerrCqCert 彳；
and τ > 0 is chosen such that
kgkLμ∞ (M) ≤ CcertPmqnert
n
c0
T ≤ nL,
then one has
\	{kζ∞bμ∞ (M) ≤
0≤k≤Lq/(nτ)
≥ 1 - e-cd
P
and in addition
P
\	[kζ∞bμ∞(M) ≤
_C0√d/(nTpmciert )≤k≤Lq/(nτ) I
C00 CqCert √d log L
nkτ
)j ≥ 1 - e-cd
Moreover, one has
p[	\	(XkZ∞kLμ∞(M) ≤ CPqCertC007τg2L)1 ≥ 1 -e
0≤k≤Lq/(nτ) ls=0	J _|
The constant Cρ = max{ρmin , ρ-m1in }.
Proof. We will combine Lemma B.12 with various probabilistic results to obtain a simple final form
for the bound from this result.
Invoking Lemma B.12, we can assert that for any step size τ > 0 satisfying
and for any k satisfying
1
l∣θkLμ∞ (M)→Lμ∞ (M)
r3e kgkLμ∞ (M)
≥ V ^2	kZIl∞(m),
(B.8)
(B.9)
27
Published as a conference paper at ICLR 2021
the population dynamics satisfy
kζ∞kLμ∞(M) ≤√3kθ[g]- Z bμ∞ (M)-
3kgkLμ∞ (M)
kτ
/ r3 kgkLμ∞(M)
lθglv2 kZ kL∞(M)kτ
(B.10)
We state the bounds we will apply to simplify this expression. An application of Lemma D.11 gives
≤
L∞(M)
≥ 1 - e-cd
ʌ
Z - Z
P
(B.11)
and
P[kZkL∞(M) ≤ √d] ≥ 1-e-cd
(B.12)
as long as n ≥ Kd4L5 and d ≥ K0d0 log(nn0CM), where we use these conditions to simplify the
residual that appears in the version of (B.11) quoted in Lemma D.11. In particular, combining (B.11)
and (B.12) With the triangle inequality and a union bound and then rescaling d, Which Worsens the
constant c and the absolute constants in the preceding conditions, gives
P
ʌ
Z
L∞(M)
≤ √d ≥ 1 - 2e-cd
(B.13)
In addition, we can write using the triangle inequality
kZ kL∞(M) ≥ I∣z∣Il∞(m) -I∣z - Zk(M),
and
ʌ
Z
L∞(M)
sUp f? (X) -
x∈M
JSdμ∞(X)
max
ZM
fθo (x0)dμ∞(x0)
fθo (x0)dμ∞(x0) + 1
M
≥ 1,
so that, by (B.11), We have if L ≥ 2√d
P kζkL∞(M) ≥ 2
≥ 1 - e-cd
(B.14)
Because μ∞ is a probability measure, Jensen's inequality, the Schwarz inequality, and the triangle
inequality give
kθkL2∞(M)→L2∞ (M) ≤	SUp	lθ(X, XO)I
μ	μ	(χ,χ0)∈M×M
≤ sup(x,χ0)∈M×M 2(X, XO) - ψ1 ◦ ∠(X, XO)I
一	+sup(x,χ0)∈M×M lψ1 ◦ ∠(X, XO)|,
and an application of Theorem B.2 and Lemma E.5 then gives that on an event of probability at least
1 - e-cd
kθkLμ∞ (M)→L2μ∞ (M) ≤ CnL
(B.15)
provided d ≥ Kd0 log(nn0CM) and n ≥ K0d4L. We Will Write E for the event consisting of the
union of the events invoked for the bounds (B.11) to (B.15), Which has probability at least 1 - e-cd
by a union bound and a choice of d ≥ K. We Will conclude by simplifying (B.10) on E. First, We
note that by (B.15), the step size condition (B.8) is satisfied on E provided
c
T ≤ nL,
(B.16)
which holds under our hypotheses. Next, on E, we write using decreasingness of x 7→ - logx and
(B.12)
—
3kgkLμ∞ (M)
kτ
log
3 kgkLμ∞(M)) V 3kgkLμ∞(M)
2 kZkL∞(M)kτ
kτ
ι r 3kgkLμ∞(M)
[ V 2	kτ √d
-√6d
√3kgkLμ∞ (M)
√2kτ √d
log
2	kτ √d .
(B.17)
3 kgkLμ∞(M)
28
Published as a conference paper at ICLR 2021
By the hypothesis on g, we have on E
kgkLμ∞ (M) ≤ CPmqnert ^n
(B.18)
and so it follows that on E
3 kgkLμ∞ (M)
2 kτ √d
C
≤ nkτpmin .
The function x 7→ -x logx is a strictly increasing function on [0, e-1], so when k is chosen such
that
Ce
--------Lr ≤ k,
nτ ρqmcienrt
(B.19)
we have on E by (B.17)
3kgkLμ∞ (M)
_
kτ
(r但 kgkLμ∞(M) 1 ≤ C√6d	(C-InkT*rt)
log W 2 kζkL∞(M)kτ ≤ nkτρmn log C nkτpmn >
(B.20)
—
Additionally, in the context of the condition (B.9), notice that by (B.14) and (B.18), on E we have
3e kgkLμ∞(M) <
2 τkζkL∞(M)
Ce√d
nτPmnt,
so that given d ≥ 1, we have that the choice
k ≥ Ce√d
-nτρmen
(B.21)
implies both conditions (B.9) and (B.19). We can simplify (B.20) using the hypothesis kτ ≤ Lq/n
with 1/2 ≤ q ≤ 1: we get
nkτρment ≤ Lq Pment ≤ …
C — C 一 ,
where the last inequality requires L ≥ Pqmcienrt
/C, which implies
3kgkLμ∞(M)	( B kgkLμ∞(M) ʌ < C0√dlogL
kτ ɑg IV 2 kζ kL∞(M)kτ J n nkτPmen
The conditions we need to satisfy on kτ can be stated together as
CeMd ,	…
——≤——≤ kτ ≤ Lq /n,
n qcert
nPmin
and it is possible to satisfy these conditions simultaneously as long as
L ≥ CCe√d!1/q.
ρ ρm Pment
We obtain an upper bound Cqe2d for the quantity on the RHS of this inequality from q ≥ 1/2; it
ρmin
suffices to choose L larger than this upper bound instead. The other simplifications are easier: using
the assumption on the norm of Θ[g] - ζ, we have
kθ[g] - Z kLμ∞ (M) ≤ Cqcert l⅛ .
LPmin
Worst-casing terms using our hypotheses on d and L to obtain a simplified bound, on E, we have
thus shown that when (B.21) is satisfied, we have
kζ∞kLμ∞(M) ≤CC尸√dG + *J
29
Published as a conference paper at ICLR 2021
We have
1 ≤ IogL 0 LlogL ≥ kτ,
L nkτ	n
which is implied by the hypothesis kτ ≤ Lq/n as long asL ≥ e. So we can simplify to
kζ∞kLμ∞(M) ≤
CCqcert √d log L
nkτ
We also need a bound that works for k that do not satisfy (B.21). From the update equation for the
dynamics in the proof of Lemma B.12 and the choice of τ, we also have
kζ∞kLμ∞(M) ≤ kζkLμ∞(M) ≤ ʌ/d,
where the last bound is valid on E. Finally, we can obtain the claimed sum bound by calculating
using our ‘small-k’ and ‘large-k’ bounds:
k	bC√d∕(nτρmcert )C	k
XkZ∞kLμ∞(M) =	X	kζ∞kLμ∞ (M) +	X	kζ∞kLμ∞ (M)
s = 0	s = 0	s=dC√d∕(nτρmcert )e
≤
≤
≤
C 0 √d
nτρ
C0d
qcert
min
C00Cqcert √d log L
nτ
k
X
s=dc√d∕(nτρmcert )e
nτρ
qcert
min
Cd
nτρ
qcert
min
C00Cqcert √d log L n nτρmn	广	ds
nτ	I C√d	Jc√d∕(nτρm肃)S
0	2 2“ l	C00Cqcert √d log2 L
+ C max{ Pmicert, 1} log L +-----^^------------，
+
1
s
where the second inequality uses standard estimates for the harmonic numbers and
C0√d∕(nτρment) ≥ 1, which follows from T ≤ c0∕(nL), d ≥ 1 and L ≥ KPment for a suit-
able absolute constant K; and the third inequality integrates and simplifies, using kτ ≤ L/n and
again d ≥ 1 and L ≥ CPqmcienrt . Worst-casing constants and using nτ ≤ 1, we simplify this last bound
to
XkZ∞kLμ∞(M) ≤ max卜mc「,	C^.
s=0	Pmin	nτ
To see that the conditions on L in the statement of the result suffice, note that we have to satisfy (say)
L ≥ KPqmcienrt and L ≥ K 0 P-mqincert; the first of these lower bounds is tighter when Pmin ≥ 1, and the
second when Pmin < 1, and so it suffices to require L ≥ KPmicert and L ≥ K0Pm2qcert instead. □
Lemma B.7 (Nominal to Finite).	Let	d0	=	1,	and suppose	Cerr,	Ccert,	qcert	> 0 are abso-
lute constants. Then there exist absolute constants c, c0, C0 , C00, C000 > 0 and absolute constants
K, K0, K00, K000 > 0 such that for any d ≥ Kd0 log(nn0CM), any 1/2 ≤ q < 1 and any 0 < δ ≤ 1,
if L ≥ K0 max{Cρ2qcert d, κ2Cλ}, if
≥ K00 max{e252^L60+44qd9 log9 L,κ2/5,
d5/4L5/2+2q log L,
and if
NV(2+6 ≥ K000
CP/2+8qcert/3(1 + Pmax)7代e11T(36
min {μ∞(M+)”,μ∞(M-)1/2}
and ifadditionaUy there exists g ∈ L∖∞ (M) satisfying
kΘ[g] - Z bμ∞ (M) ≤ CerrCqCert 彳；
and T > 0 is chosen such that
c0
T ≤ nL,
kgkLμ∞ (M) ≤ CcertPmqnert 二
30
Published as a conference paper at ICLR 2021
then one has generalization in Lμ∞ (M):
PhZN	Il	≤ CCqcer√logL] ≥ 1_ C00L-
Il'bLq/(nτ)cllLμ∞(M) 一	Lq	—	nτ
and in addition, one has generalization in L∞ (M):
N l∣	≤ C〃cp+2qccrt/3(i + Pmax)“e14"3δ) d3/4 log4/3 L] ≥ 1 _ C000Leid
bLq /(nτ )C||L8(M)_	min {μ∞(M+),μ∞(M-)}1/2	L(4q-3)/6	-	nτ
The constant Cρ = max{ρmin, ρ-m1in}.
Proof. The proof controls the L∞ norm of the error evaluated along the finite sample dynamics
using an interpolation inequality for Lipschitz functions on an interval (Lemma B.14), which relates
the L∞ norm to a certain combination of the predictor,s LiPschitz constant and its L2μ∞ norm. We
can control these two quantities at time zero using our measure concentration results; to control them
for larger times 0 < k ≤ Lq /(nτ), we set up a system of coupled ‘discrete integral equations’ for
the generalization error of the finite sample predictor and the Lipschitz constant of the finite sample
predictor, and use the fact that kτ is not large to argue by induction that not much blow-up can occur.
Along the way, we control the generalization error of the finite sample predictor by linking it to the
generalization error of the nominal predictor as controlled in Lemma B.6; the residual that arises
is shown to be small by applying Corollary B.11 and applying basic results from optimal transport
theory adapted to our setting, encapsulated in Lemmas B.13 and B.16.
To begin, we will lay out the probabilistic bounds we will rely on for simplifications, so that the rest
of the proof can proceed without interruption. We will want to satisfy
max{ ∣l θμN IL2 N (M)→L2 N (M), k θμ∞ kLμ∞ (M)→Lμ∞ (M)}
following the notation of Lemma B.10. Using Jensen’s inequality, the Schwarz inequality, and the
triangle inequality, we have for ? ∈ {N, ∞}
kθ”? kLμ? (M)→Lμ? (M)
sup
kgkLμ? (M)≤1
^Θ(x, x0)g(x0)dμ?(x0)∣∣ 2
kgkLμ? (M)
sup	∣Θ(x, x0)∣
(x,x0)∈M×M
≤ suP(x,χ0)∈M×M lθ(X, χ0) - ψ1 ◦ ∠(X, x0)|
一	+suP(x,χ0)∈M×M lψ1 ◦ ∠(X, x0)|,
(B.24)
where the notation ψ1 follows the definition in Appendix C.2.2. The first term in (B.24) can be
controlled using Theorem B.2: we obtain that on an event of probability at least 1 - e-cd
kΘ - ψι ◦ ∠kL∞(M×M) ≤ √d4nL3	(B.25)
if d ≥ Kd0 log(nn0CM) and n ≥ K0 d4L. The second term in (B.24) can be controlled using the
triangle inequality, Lemma E.5, and the definition of ψ1: we obtain that it is no larger than nL/2.
Combining these two bounds, we have on an event of probability at least 1 - e-cd
max{lIθμNIIL2N(M)→L2N(M), kθμ∞kLμ∞(M)→Lμ∞(mJ ≤ CnL	(B.26)
provided d ≥ Kd0 log(nn0CM) and n ≥ K0 d4L. Thus, with probability at least 1 - e-cd, our
choice of step size τ ≤ c/(nL) satisfies (B.23). Under our hypotheses on the function g in the
statement of the result and taking a union bound with the event in (B.26), we can invoke Lemma B.6
to obtain
P	\
-C√d∕(nτρmCicrt )≤k≤Lq /(nτ)
{kζ∞kLμ∞ (M) ≤
C0Cqccrt √d log L
nkτ
)1 ≥ 1 - C000nτ-d (B.27)
≤
31
Published as a conference paper at ICLR 2021
and
P \	[X kZ∞kLμ∞ (M) ≤ Cpqcert C^ U ≥ 1 - ClLe-C	(B.28)
0≤k≤Lq/(nτ) ls=0	J I
provided d ≥ Kd0 log(nn0CM), 1/2 ≤ q < 1, n ≥ K0d4L5, andL ≥ K00Cρ2qcertd. We have by
Lemmas B.6 and B.10, a union bound with (B.26), and our condition on τ that
P \	{kζ∞bμ∞ (M) ≤√d0 ∩	\	{hζN‰ N (M) ≤√d}∣≥1 - CLFd
0≤k≤Lq/(nτ)	0≤k≤Lq/(nτ)1	μ	j _|
(B.29)
as long asd≥ Kd0 log(nn0CM) and n ≥ K0L48+20qd9 log9 L, and where we used our conditions
on T and q to obtain that Lq /nτ ≥ 1 and simplify the probability bound; and, following the notation
of Corollary B.11, we have by this result (again under our condition on τ and a union bound) that
there is an event of probability at least 1 - CLe-cd/(nT) on which
∆NLq∕(nτ)C-1 ≤ (n11L48+8qd9 log9 L)1/12	(B.30)
under the previous conditions on n and d. In addition, applying Lemma D.12 and a union bound
gives that on an event of probability at least 1 - Ce-cd
max{WM+Lp MM-Lp}≤√d	(B.31)
provided d ≥ Kdo log(nn°CM) and n ≥ K0 max{d4L, (κ∕cλ)1∕3,κ2∕5}. Finally, we have by
Lemma B.13 that for any 0 < δ ≤ 1
P
\	(
f∈Lip(M)
IRM f (X) dμ∞(X)- RM f (x)dμN(X)
L	e1" Cμ∞
V 2kf kL∞(M) VZd _1_
≤ N +
,M √d max*∈{ + ,-} f
N 1∕(2 + δ)
M? Lip
≥ 1 - 8e-d, (B.32)
as long as d ≥ 1 and N ≥ 2√d/ min{μ∞(M+),μ∞(M-)}. We let E(q,δ) denote the event
consisting of the union of the events appearing in the bounds (B.25) to (B.32) hold; by a union
bound and the previous observation that Lq/nT ≥ 1, we have
C0Le-cd
P[E ] ≥1	n^.
In the sequel, we will use the events defining E to simplify our residuals without explicitly referenc-
ing that our bounds hold only on E to save time.
We start from the dynamics update equations given by Lemma B.8, which we use to write
ζk∞ - ζkN	= (Id -TΘ)	ζk∞-1 -	ζkN-1	+	TΘkN-1	ζkN-1	-TΘζkN-1,
where Θ is defined as in Lemma B.12. Under the choice of T and positivity of Θ (Lemma B.9), we
apply the triangle inequality and a telescoping series with the common initial conditions to obtain
k-1
∣∣ΘsNζsN -ΘζsN∣∣L2∞(M).
s = 0	μ
∣∣ζ∞ - ζN l∣Lμ∞ (M) ≤T
(B.33)
We can write
ΘN [ZN] (X) = Z ΘN(x, X0)ZN(x0)dμN(x0)
M
=Rm (θN(X, x0) - ψι ◦ ∠(X, x0)) ZN(X0) dμN(X0)
一	+ RM ψι ◦ ∠(X, X)Zs(X0) dμN(X0),
and analogously
Θ [ZN] (x) = : (Θ(x, x0) - ψι ◦ ∠(x, x0)) ZN(x0) dμ∞(x0)
+ ： ψι ◦ ∠(x, x0)ZN(x0)dμ∞(x0).
32
Published as a conference paper at ICLR 2021
Using Jensen’s inequality and the Schwarz inequality, we have
/ (ΘN(x, x0) - ψι ◦ ∠(x, x0)) ZN(x0) dμN(x0)
JM	L2μ∞ (M)
≤ y^∣∣θN (IXO)- ψι ◦ ∠( ∙, XO)IIL2 ∞ (M)IZN (XO)I dμN (XO)
≤ IIθN - ψ1 ◦ ∠I∣L∞(M×M)kZNkL；N(M)
≤ HθS - ψ1 ◦ ∠IIL∞(M×M)kζFkL：N(M),
since μN is a probability measure. Repeating an analogous calculation with μ∞ for the other term
and applying the triangle inequality, we have
(IIζ∞ - ZNI⅛∞(M) ʌ
IIθN [ZN] - Θ [ZN] IIl2∞(M) ≤ kθ - ψι ◦ ∠kL∞(M×M)	+"ζ∞bμ∞(M)
+	∖	+IZsV IIl：n (M))
+ IΘs - ΘIL∞(M×M) IIZsN IIL2
N(M)
μN
+ ZM ψl ◦ ∠(∙, XO)ZN(x0) (dμ∞(x0) - dμN(x0))	2	.
"(B.34)
We detour briefly to simplify residuals appearing in (B.34) before using the result to update (B.33).
Using (B.25) and (B.30), we get
kθ - ψ1 ◦ ∠kL∞(M×M) (11CT - ZN归((M) + 噎应((M) + IIZNL2N(M))
+IIΘsN - ΘII
L( (M×M) IIZsN IIL2
N(M)
μN
≤ √d4nL3 (IIZ∞ - ZNIILμ∞(M) + kZ∞bμ∞(M) + IIZNIgN(M))
^	+ (n11L48+8qd9 K L)1"IIZNIIl2N(M)”
μN
≤ (n11L48+8qdlog9L)1/12 (IIZ∞- ZNIILμ∞(M) + kZ∞kLμ∞(M) + 2IIZNIIl2N(m)) ∙
(B.35)
where the final bound holds when n ≥ d3. Using (B.29), we can further simplify the RHS of the
last bound above to
(n11L48+8q d9 log9 L)1/12 (iIz∞ - ZNIILμ∞ (M) + kZ∞kLμ∞ (M) + 2IIzFIIl2 N (M))
≤ 2 (n11L48+8qd15 log9 L)1/12 + (n11L48+8qd9 log9 L)1/12 ∣∣Z∞ - ZNk 小
μ∞
With this last bound and (B.34), we can use kτ ≤ Lq/n to simplify (B.33) to
i1z∞ - ZN Lμ∞ (M) ≤
C ( L48+20d15log9 L ) 1/12
+τ (n11L48+8qd9 log9 L)1/12 PM ∣∣Z∞ - ZN∣∣L2∞ (M)
k-1
+τ
-1
Xs 0III	M
s=0
Ψ1 ◦ ∠( ∙, xo)ZN(xo) (dμ∞(xo) - dμN(xo))
Lμ∞ (M)
(B.36)
To control the remaining term in (B.36), we split the error ZsN into a Lipschitz component whose
evolution is governed by the nominal kernel ψ1 ◦ ∠ and a nonsmooth component which is small in
33
Published as a conference paper at ICLR 2021
L∞. Formally, we define Θnom : L：n (M) → L：n (M) by
Θnom [g](x) = / ψι ◦ ∠(x, x0)g(x0) dμN(x0),
and use the update equation from Lemma B.8 to write
s-1
ζsN =ζ-τXΘiN ζiN
i=0
s-1	s-1
=ζ-τ X Θnom [ζN ] + τ χ (Θnom - θn ) [ζN ],
i=0
V---------V-
ζN,Lip
i=0
, X-----------------
δN
s
}
so that ζsN = ζsN,Lip + δsN, and ζ0N,Lip = ζ, δ0N = 0. It is straightforward to control δsN in L∞ : we
have (as usual) by the triangle inequality, Jensen’s inequality, and the Schwarz inequality
s-1
∣∣δN∣∣L∞(M) ≤T XjJ∣ψl ◦ ∠( ∙, x0)- θN(∙,XO)∣∣l∞(m)KN (XO)IdμN(XO)
s-1
≤ T X∣∣ψ1 。 ∠
- Θi ∣L∞(M×M) ∣∣ζiN ∣∣L2
N(M),
i=0	μ
and then the triangle inequality together with (B.25), (B.29) and (B.30) yield
∣∣δN∣∣L∞(M) ≤ ST√d (√d4nL3 + (n11L48+8qd9 log9 L)1/12)
≤ sτ√d (UIIL48+8qd9 log9 L)1/12 ,
(B.37)
Where the second line applies the same simplifications that led us to (B.35). The triangle inequality
gives
J:1。∠(∙，x0)δN(x0) (dμ∞(x') - dμ1N(χ0))
≤
Lμ∞ (M)
X ∣∣∣ M
?∈{N,∞} JM
ψl ◦ ∠(∙, x0)δN(x0)dμ?(x0)
Lμ∞ (M)
M
and simplifying as usual using Jensen's inequality and the Holder inequality, We obtain
J:1 ◦ ∠( ∙, x0)δN(x0) (dμ∞(x0) - dμN(x0))
≤ nLkδsN kL∞ (M)
Lμ∞ (M)
≤ sτ(n23L60+8qd15 log9 L)1/12 ,
Where the last bound uses (B.37). Then using the triangle inequality and kτ ≤ Lq/n to simplify in
(B.36), We obtain
l∣ζ∞ - ZNLμ∞(M) ≤ C
L60+32qd15 log9 L 1/12
n
k-1
+ T (n11L48+8qd9 log9 L)1/12 X∣∣ζ∞ - ZN∣∣L2∞(M)
S = 0	μ
k-1
+τ
k-1
Xs=0∣∣∣	M
s=0
ψl ◦ ∠( ∙ , X0)ZN，Lip(X0) (dμ∞(x0) - dμN(x0))
Lμ∞ (M)
(B.38)
To simplify the remaining term in (B.38), we aim to apply (B.32); to do this we will need to justify
the notation and establish that ZN,Lip ∈ LiP(M) regardless of the random sample from μ∞ and the
34
Published as a conference paper at ICLR 2021
random instance of the weights. Because ζsN,Lip is a sum of functions, we can bound its minimal
Lipschitz constant by the sum of bounds on the Lipschitz constants of each summand. We always
have for either ? ∈ {+, -}
KN,Lip∣M*Lp ≤ K∣m*ILp+τX∣τMψ1 ◦ ∠( ∙,x0)ζN(χ0)dμN(XO)∣Lip.	(B.39)
We note that because the ReLU [ ∙ ]+ is I-LiPschitz as a map on Rn, We have
L
"Lp ≤ ∣∣wL+1∣∣2γ∣∣w'∣∣< +∞,
so We need only develop a Lipschitz property for the summands in the second term of (B.39). To do
this, we will start by showing that t → ψι ◦ cos-1(γ*(t), x0i is absolutely continuous for each x0.
Continuity is immediate. The only obstruction to differentiability comes from the inverse cosine,
which fails to be differentiable at ±1, and because M ⊂ Sn0-1 we have hγ*(t), x0i = ±1 only
if γ*(t) = ±x0; because γ? are simple curves, this shows that there are at most two points of
nondifferentiability in [0, len(M?)]. At points of differentiability, we calculate using the chain rule
the derivative
t→-(ψ1 ◦ cos-1 hγ?⑴,χ0i) ( ∕[	γ?? F,x/,
∖√1-hγ?⑴,x0i2	/
and because γ? is a sphere curve, it holds (I - γ?(t)γ?(t))γ?(t) = γ?(t) for all t, whence by
Cauchy-Schwarz
γ? (t)
P - hγ?⑴,x0i2
χo+∣ = I* (I - γ*(t)γ*(t)*)χ0
/I I∖ P1 -hγ?⑴,χ0i2
≤ k(I-γ*(t)γ*(t)*)χ0∣∣2 ≤ 1
-P1-hγ*(t), x0i2 一 ,
(B.40)
where we also used that γ? are unit-speed curves. In particular, the derivative is bounded, hence
integrable on [0, len(M?)], and so an application of (Cohn, 2013, Theorem 6.3.11) establishes that
t 7→ ψ1 ◦ cos-1 hγ? (t), x0i is absolutely continuous, with the expansion
∣ψι ◦ cos-1hγ*(t), x0i - ψι ◦ cos-1hγ*(t0), x0i∣
(Ψ1 ◦ cos-1hγ*(t00), x0i)
/	Y? (t00)
∖√1 - hγ*(t00), x0i2
x0
dt00
which gives an avenue to establish Lipschitz estimates for t → ψι ◦ cos-1hγ*(t), x0). Because
x0 7→ ζiN(x0) is continuous and i ≤ s ≤ k ≤ Lq /(nτ) < +∞, an application of Fubini’s theorem
enables us to also use this result to obtain Lipschitz estimates for the summands examined in (B.39),
to wit
^ψι ◦ ∠( ∙, χ0)ZN(χ0) dμN(χ0)
Lip
≤ sup I ∣Ψ1 ◦ ∠(x, x0)∣∣ZN(x0)∣dμN(x0)
x∈M* M
≤ kZNkLμN(M) x∈M
1/2
(Ψ1 ◦ ∠(x, x0)) dμN(x0))
(B.41)
after using the bound (B.40) in the first inequality and the Schwarz inequality for the second. Before
proceeding with further simplifications, we note that the C2 property ofψ1, continuity ofζiN, bound-
edness of i, and compactness of M let us assert using (B.41) and (B.39) that ζsN,Lip ∈ Lip(M)
whether or not we are working on the event E . Continuing, we develop a bound for the RHS of
(B.41) that is valid on E. Using the triangle inequality and the Minkowski inequality, we have for
35
Published as a conference paper at ICLR 2021
the second term on the RHS of the last bound in (B.41)
1/2
sup
x∈M
(Ψ1 ◦ ∠(χ, χ0))2 dμN (χ0)
Z
? M
≤ sup
x∈M
M
+ sup
x∈M
(Ψ1 ◦ ∠(x, x0))2 (dμN(x0) - dμ∞(x0))
2	1/2
(ψ1 ◦ ∠(x, x0)) dμ∞(x0)	.
1/2
(B.42)
For the first term in (B.42), we use Lemmas C.7, C.22 and C.24 to obtain that x0 7→ (ψ10 ◦ ∠(x, x0))2
is bounded by Cn2 L4 and C0n2L5-Lipschitz for every x, and then applying (B.32) gives
Z
? M
sup
x∈M
(Ψ1 ◦ ∠(χ, χ0))2 (dμN(χ0) - dμ∞(χ0))
1/2
Cn2L4 Vd	e1"δ Cμ
-N- +
一	1/2
∞ MC 0n2L5√d∖
N 1∕(2+δ)
≤C
(1 + Cμ∞,M)"C7/"
N 1∕(4+2δ)
nL5/2d1/4.
(B.43)
≤
M
For the second term in (B.42), we apply Lemmas C.8 and C.22 together with the choice L ≥ Kκ2Cλ
to get
sup
x∈M
、1/2	d d	d“∞(χθ)	、1/2
M ◦ ∠(x, X)) dμ∞(x'))	≤ CnLx∈Up± (JM (1 + (L∕π)∠(x, x0))2)
≤ cnL3/2pm/ax(ien(M+)+Ien(M-))1/2
≤ CPmxC1∞MnL3/.	(B.44)
Combining (B.43) and (B.44) to control the RHS of (B.42), we obtain from (B.41)
^ψι ◦ ∠( ∙, x0)ZN(x0) dμN(x0)
ip
(1 + Cμ∞,M)1∕2e7∕δ
N (M) ∖	N 1∕(4+2δ)
∙nL5∕2d1∕4 + PmaχCμ∞,MnL3/2
N(M) (1 + Cμ∞,M 产2 e7/(1 + Pmax)I/d"/,
I
(B.45)
where in the second line we used N ≥ L4+2δ. Plugging (B.45) into (B.39) and applying in addition
(B.31), we get
s— 1
l∣ZN*M* Lp ≤√d + C"∕δ (1 + Cμ∞,My(1 + PmaX)1∕2"nL3/2 XIiZNI鼠(M).
i=0	(B.46)
Let us briefly pause to reorient ourselves. We do not have control of the empirical losses appearing
in (B.46) by an outside result, so we need to make some further simplifications to this bound. We
will control the sum of empirical losses term in (B.46) by linking it to the difference population
error, which we last saw in (B.38), and the population error using the triangle inequality and a
change of measure inequality. Meanwhile, with the Lipschitz property of ζsN,Lip we have shown, we
will be able to obtain a bound in terms of simpler quantities for the last term on the RHS of (B.38)
using (B.32). The two resulting bounds will give us a system of two coupled ‘discrete integral
equations’ for the difference population error and the Lipschitz constants of ζsN,Lip, which we will
solve inductively.
First, We continue simplifying (B.46). The triangle inequality and the fact that μN is a probability
measure give
IIζiNIIL2N(M)≤IIIζiN,LipIIIL2	(M)+IIδiNIIL∞(M),	(B.47)
μN
36
Published as a conference paper at ICLR 2021
and We have by the triangle inequality and Holder-1 continuity of x → √χ
ZiN/'(M) ≤ l*ilL:∞(M) +
ζN,Lip
i	L2 N (M)
μ
ζN,Lip
i	∣∣Lμ∞ (M)
—
ip
+
Lμ∞ (M)
≤
2
(dμ∞(x) — dμN(x)) .	(B.48)
We have shoWn that ζiN,Lip ∈ Lip(M) and ζiN,Lip ∈ L∞(M) above, and so ζiN,Lip2 ∈ Lip(M)
as Well, With
M?
Lip
≤ 2ζiN,Lip
L∞(M)
ZF?L
Applying the previous equation With (B.32) to control (B.48), We get
ζiN,LipL2N(M)
μ
≤
I ∣∣ζN,Lipk2	e1”δ
+Cdi/4 V 处__∣∣L∞(M) + 一
Cμ∞,MkζN,LipkL∞(M) max*∈{ + ,-}
N 1∕(2 + δ)
ζN,Lip
M?
Lip
≤
+Cd1/4
( kZN,LipkL∞(M)
√N
e7
+
I k(M)
/δ C∞ ,MkζN,LipkL∞(M) max*∈{ + ,-}∣ZN,
N 1∕(4+2δ)
Lip
M?
1/2
Lip
∖
where the second line applies the MinkoWski inequality. Using the triangle inequality and that μ∞
is a probability measure, We have
WLipk(M) ≤ "必∞(M) + W必∞(M)
≤ kZ∞ ∣Lμ∞(M) + ∖∖ZN - Z∞ 归∞ (M) + ∖∖δN∖∖L∞(M).	(B∙49)
Substituting (B.49) into (B.47) and using (B.37) to simplify gives
L2N(M)
μ
≤ ∖∖ZiN - Z∞∖∖l2∞(M) + kZi∞bμ∞(M) +2iτ√d (n11L48+8qd9 log9 L)1/12
+ Cd1/4
e"δCμ∞2,MwZiN叫L∞(M) max?-WZ*Tm*Lp
+	N 1∕(4+2δ)
∖
/
(B.50)
Following (B.46), we need to sum the previous bound over i. To simplify residuals, we use (B.28)
to get
s —1
CssT√d S11 L48+8qd9 log")1" + £1靖应∞(M)
i=0	μ
≤ Cs2τ√d (n11L48+8qd9 log9 L)1/12 + CPqcertC丁θg2 L
2C2qcertC0d log2 L
≤ —---------------,
nτ
37
Published as a conference paper at ICLR 2021
where the second bound uses the control sτ ≤ kτ ≤ Lq /n and holds under the condition
n ≥ (C/C0)12 L48+32qd3 . Summing in (B.50) and using the previous bound, it follows
s-1
XζiNL2N(M)
i=0	μ
≤
CCρ2qcert d log2 L
nτ
s-1
+ XζiN -ζi∞L2∞(M)
i=0	μ
+ Cd1/4
e7"Cl'，MKN"'P IL∞(M) max*∈{+,-} ζN'L'P∣M* LiP
+	N 1∕(4+2δ)
∖ /
(B.51)
Plugging (B.51) into (B.46), we obtain
≤ C1d1∕4L3∕2
+nτd1∕4 Pis=-01
kZN,LipkL∞(M)
√N
s-1I N ∞I
i=0 UZi	- Zi l∣Lμ∞ (M)
kzN，LipkL£(M)[*X-』zN，LiPL?
+	N 1∕(4+2δ)
1/2
Lip
(B.52)
/
where for concision we have defined
Cι(δ,μ∞) = CCPqcerte1* (1 + C*∞,m)(1+ Pmax)1/2	(B.53)
and simplified the √d residual in (B.46) by worst-casing with the larger residual from the population
error term in (B.51), and made other simplifications by worst-casing some constants. We simplify
(B.38) next: we have shown that ZsN，LiP ∈ Lip(M) and ZsN，LiP ∈ L∞(M) above, and so for every
x ∈ M, we have
ψι ◦ ∠(x, ∙ )ZN，Lip ∈ Lip(M)
as well, with
llψι ◦ ∠(x, ∙ )zN，L*M*ILp ≤ CnL ?om+x-JkN，LiplM*o∣Lp+c 0nL2iizN，LipiiL8(M)
(B.54)
using the definition of ψ1 , Lemmas E.5, C.7 and C.22, and
I∣ψ1 ◦ ∠(X, ∙ )ZN，Lip||L8(M)≤ CnLnZN,Lip∣∣L∞(M).	(B.55)
The bounds (B.54) and (B.55) retain no x dependence. Applying (B.32) and integrating over x, we
obtain from (B.54) and (B.55)
(ψ1 ◦ ∠( ∙ , X0)ZN，Lip(X0) (dμ∞(x0) - dμN(χ0)) U
N
CnLe14/Cμ∞,M
+
√dmaX?e{+，—}||zN，『M* Lp
N 1∕(2+δ)
+
CnL2e14∕δ Cμ∞,M Vd||zN，LiP||L8(M)
N 1∕(2+δ)
38
Published as a conference paper at ICLR 2021
and we can combine the first and third terms on the RHS of the previous bound by worst-casing,
giving
ImΨi ◦ ∠( ∙, x0)ZN'Lip(x0) (dμ∞(x0) - dμN (x0)) U
≤C √dnLeN1δ(2++ JM) (maUzN平 m? ILp+Luζ*叫 l∞(m).
Plugging the previous bound into (B.38), we obtain
∣∣ζ∞ - ζN∣∣Lμ∞(M)
≤ C ( Li Fog" ) 1/12 + τ (n11L48+8q d9 log9 L)1/12 X∣ζ∞ - ZN∣∣Lμ∞ (M)
+CT √dnLeZ++ JM) X QM 校"? ∣Lp+L∣∣ζN,Lip∣∣L∞(M)).
s=0
(B.56)
To finish coupling (B.52) and (B.56), we need to remove the L∞ (M) terms. We accomplish this
using Lemma B.14, which gives
∣∣ζN,叫 l∞(m) ≤ c°272∣∣ζN叫 Lμ∞(M)
where we have defined
++∣∣ζN叫 Lμ3∞ (M)?产}
ρmin
(B.57)
C2(μ∞)
ρmax
Pmin min {μ∞(M+),μ∞(M-)}
(B.58)
For coupling purposes, it will suffice to use a version of (B.57) obtained by simplifying with some
coarse estimates. Using (B.49), (B.37) and (B.29), we have
BLipk(≤<d+ + iτ√d (n11L48+8qd log9 L)1/12 + ∣∣ZN - ZiT∣L2g (M)
U	ιιLμ∞ (M)	μ
< 2√d + ∣∣ζN - ζ∞Lμ∞ (M)，
using iτ < Lq/n and n ≥ L48+20qd9 log9 L in the second line, and plugging this into (B.57) and
using the Minkowski inequality gives
∣∣"p∣∣L∞(M) < CC272√d+CC272∣∣ζN - ζ∞∣∣L2 ∞ (M) + Cd33 *∈maX} ∣∣znFm*∣∣L;
μ	P	,	p ip
ρmin
+
max
(M) *∈{+,-}
N,Lip I	∣∣1/3
s M? ∣Lip.
(B.59)
To make some of the subsequent bounds more concise, we introduce additional notation
= ?图"卜尸九*10.
39
Published as a conference paper at ICLR 2021
Plugging (B.59) into (B.52) and using the Minkowski inequality, we obtain
Λs ≤ CC1d1/4L3/2 dlog2L+
nτ d7/12
Nn
s-1
sτ
+ nτ 1 +
C21/2d1/4
+ P≡√N
X Λ1/3 +
i=0
C14nτd'∕i2
N 1∕(4+2δ)
Nn	)
s-1
X Λ1/
i=0
s-1
XζiN - ζi∞L
i=0
μ∞ (M)
nτ d5/12
s-1
X Λ2/ +
i=0
nτ d1/4
s-1
ρim-n√N
XkN - ζ∞UL/3
i=0
μ∞ (M)
Λ11/
C1/4nTd1/4
+ N 1∕(4+2δ)
nτ d1/4
s-1
Xa - Z∞ 吧 2∞ (MN/
i=0	μ
s-1
i=0
μ'
Λ2/3
(M)Λi
(B.60)
3
∞
J
To simplify (B.60), we use sτ ≤ Lq /n, C2 ≥ 1, and q ≤ 1, and so if additionally we choose
N ≥ C? max{ √d, L2} We obtain
Λs ≤ CC1d1/4L3/2 d log2 L + nτ Xs-1UUζiN - ζi∞UUL
i=0
nτ d1/4
μ∞ (M)
+PminN W”)
i=0
μ'
∞(M)
Λ22/
nτ d7/12
+ P≡√N
s-1
X Λ1/3
i=0
C21/4 nτ d1/2
N 1∕(4+2δ)
s-1
X Λ1/ +
i=0
nτ d5/12
s-1
X Λ2/
i=0
+
3
nτ d1/4
s-1
XUZN - ζ∞^Lt (M)Λ1/3
i=0	μ
+襦√N
+
C21/4 nτ d1/4
N 1∕(4+2δ)
i=0
μ1
Λ1/2
(M)Λi
2
∞
I
(B.61)
Meanwhile, we recall
Cμ∞,M
len(M+)
len(M-)
μ∞(M+) + μ∞(M-,
and an integration in coordinates gives
μ∞(M±)= Z	ρ± ◦ γ±(t)dt ≥ Pminlen(M±),
0
so that
Cμ∞,M ≤ ɪ .
ρmin
(B.62)
40
Published as a conference paper at ICLR 2021
Using (B.62) and plugging (B.59) into (B.56), we obtain
∣∣ζ∞ - ZNULμ∞(M)
<CL L60+32qd15 log9 L Y/12
n
+ T (n11L48+8qd9 log9 L)1/12 +
PminN1/(2+。
k-1
XQ - ZN g∞ (M)
S = 0	μ
C0τ√n"/ k-1, (	Λs + LC23	∖
+ PminN1/(2+" S=0 [ +LdaPmlA?3 + Lριmf∣∣Z∞ -《力号(M)Λ1/ )-
μ	(B.63)
In (B.61) and (B.63), we now have a suitable system of coupled discrete integral equations for
kζ∞ -ZN l∣Lμ∞ (M) and Λk . We will solve these equations by positing bounds for each parameter
that are valid for all indices 0 ≤ k ≤ bLq /(nτ)c based on inspection of (B.61) and (B.63), then
proving the bounds hold by induction on k. Positing the bounds is not too hard, because each term
in (B.61) and (B.63) with a factor of N in its denominator can be forced to be small by requiring N
to be large enough. For all 0 ≤ k ≤ bLq /(nτ)c, we claim
(「 1/ Z/2「4/3 d7/4L5/2+q log2 L
ClipCIC2	CP -N 1∕(2+δ	,
(L60+32q d15 log9 L y/12
(B.64)
(B.65)
n
Λk ≤ ClipC1d5/4L3/2 log2 L,
where Cdiff and Clip are two absolute constants that we will specify in our arguments below. We
prove (B.64) and (B.65) by induction on k. The case of k = 0 is immediate, since Z0∞ = Z0N for
(B.64); and by construction Z0N,Lip = Z, and (B.31) and d ≥ 1 then gives (B.65) if L ≥ e. We
therefore move to the induction step, assuming that (B.64) and (B.65) hold for k - 1 and showing
that this implies the bounds for k. We begin by verifying (B.64). Applying the induction hypothesis
for k - 1 via (B.65), we can write
Λs + LCB/√ + L
≤ ClipCId5/4L3/2 log2 L + LCW/√d +
1/3
d3/4L3/2 log2/3 L
≤ ClipCIC1/2CP/3d5/4L3/2 log2 L,
where we worst-cased in the second line using Clip ≥ 1 and C1 ≥ 1, C2 ≥ 1, which follow from
(B.53) and (B.58). We use kτ ≤ Lq/n with the last bound to note that
C 0τ √dnLe14∕δ
TmnNTWr
k-1
XClipC1C21/2CP1/3d5/4L3/2 log2 L ≤ C00ClipC1C21/2CP4/3
s=0
d7/4L5/2+q log2 L
N 1/(2+6)
where C00 ≥ 1. Using this bound and (B.65) once more, we can simplify (B.63) to
∣∣ζ∞ - ZN Lμ∞ (M)
d7/4L5/2+q log2 L
N 1/(2+6)
十 C ( L60+32qd15 log9 L )1/12
+ T (n11L48+8qd9 log9 L)1/12 +
PminN1/(2+6)
k-1
X∣∣Zs∞-ZsN∣∣L2∞(M)
s=0
(B.66)
C0Clχ3C1∕3e14∕δ Td11/12nL5/2 log2/3 L
p4/3
Pmin
N 1/(2+6)
k-1
X∣∣Z∞ - ZNHL/3∞ (M).
s=0
+
n
41
Published as a conference paper at ICLR 2021
Noticing that the RHS of the bound (B.64) does not depend on k, let us momentarily denote it by
CdiffM (i.e., the part of the RHS of this bound that does not involve Cdiff is denoted as M). Plugging
into (B.66) and using kτ ≤ Lq/n, we obtain
Il ζ∞ -ZN ∣∣Lμ∞ (M)
≤ C00 ClipCIC1/2。4/3
d7/4L5/2+q log2 L
N 1∕(2+δ)
+C
L60+32qd15 Sg9 L ∖ 1/12
n
+Cdff ((L48+20qnd9 log9 l )1/12+
C 0C272√dL2+q e14/6
-PminN 1"2+δ)-
M
,C 0Cdff3CfC73e1"δ d11/12L5/2+q log2/3 LM 2/3
+	#/3	N 1/(2+6)	Vl
ρmin
In particular, if Cdiff = 6 max{C, C00} (for the constants in the first line of the previous bound), we
can bound the RHS of the previous bound and obtain
“ CdiffM '八	L /L48+20qd9 log9 L∖ 1/12	C0Cl∕2√dL2+qe14∕δ∖
L∞ (M) ≤	+ Cdiffa n )	+	PmmN 1/(2+6)	V
I C0C箫琮3C173e14∕δ d11/12L5/2+q log2/3 LM2/3
+	773	N 1/(2+6)	M .
Pmin
(B.67)
We can conclude (B.64) from (B.67) provided we can show the second and third terms are no larger
than CdiffM/3. For the second term in (B.67), if we choose N such that
N1/(2+6) ≥ 6C0C21/2P-1 e14/6d1/2L2+q
2 min
and n such that
then we have
n ≥ 612L48+20qd9 log9 L
L /L48+20qd9 log9 L∖ 1/12	C0C2,r2√dL2+qe14/6\	CdiffM
((	n	)	+	PminN1/(2+6)	M ≤
For the third term in (B.67), we proceed in cases: first, when
C cc 1/2C4/3 d7/4L5/2+q log2L< (L60+32qd15 log9 L)1/12
ClipC1C2 Cρ
N 1/(2+6)	≤ (	n	)
we have by (B.64)
M _ ( L60+32qd15 log9 L )1/12
and if we require additionally Cdiff ≥ 1, it follows that
(B.68)
C0C箫Cl1fc1∕3e14∕δ d11/12L5/2+q log2/3 L M2/3
^4∕3	N 1∕(2+δ)	M
Pmin
≤ c 0CdiffClipc1c1∕2c4∕3e14∕δ d7"://2++!0g2 L M2/3
≤ C0Cdiffe14/6 M1+2/3,
using C1 ≥ 1, C2 ≥ 1, and Clip ≥ 1 and worst-casing exponents on d and log L in the first line, and
(B.68) in the second line. In particular, by the value of M in this regime, if
n ≥ (3C0e14/6)18L60+32qd15 log9 L
then we obtain for the third term in (B.67)
C 0Cdf3Cl1fcY3e14∕δ d11/12L5/2+q log2/3 LM 2/3 < CdiffM
^4∕3	N 1∕(2+δ)	M ≤	3-,
Pmin
42
Published as a conference paper at ICLR 2021
as desired. Next, we consider the remaining case
C Ca a log2 L^ μ60+32qd15 log9 l∖ 1/12
Clip C1 C2	Cρ
N 1∕(2+δ)	≥ ∖	n	)
(B.69)
which by (B.64) implies
M = ClipCIC1/2Cp/3
d7/4L5/2+q log2 L
N 1/(2+6)
With this setting of M, the third term in (B.67) can be bounded as
C0C2if3C1fC73e14∕δ …L52+ log2/3 L M2/3
"473	N 1/(2+6)	M
ρmin
C0C2/3C CC1/3C4/3+8/9 14/6 d7/4+1/3L5/2+qL5"/ log2 L
=C Cdiff ClipCIC2 CP	e	N 1/(2+6)+2/(6+36)
≤ C 0 CdiffCP/9e14/6 "J：： M,
and using the RHS of the final bound in the previous expression, we see that if we choose
N1/(2+6) ≥ (3C0)3/2 CP4/3e21/6d1/2 L5/2+q,
then we have for the case (B.69)
C0C需CIfC1/3e14/6 …L"q log2/3 LMCdiffM
Pmn	Nw+)-	≤ 丁
Combining the bounds on the third term in (B.67) over both cases (B.68) and (B.69), we have shown
K∞ - ZN hμ∞ (M) ≤ CdiffM,
which proves (B.64). Next, to verify (B.65), we proceed with a similar idea: the bound claimed in
(B.65) corresponds to a constant multiple of the first term in parentheses in (B.61), so to establish
(B.65) it suffices to show that each of the other terms in (B.61) is no larger than a certain constant.
To work with the maximum operation in (B.64), we will again split the analysis into two cases. First,
we consider the case where (B.69) holds, so that the maximum in (B.64) is achieved by the second
argument. Plugging (B.64) and (B.65) into (B.61) and using kτ ≤ Lq/n, we get
Λk ≤ CC1d1/4L3/2 (dlog2 L + CdiffClipC1C1∕2Cρ/3 —N 1∕(2+6og
+ C1/f3ClipCp1/18C1C1/6 -
+ Cl1ip/3C11/3CP1/3
dL1∕2+q log2/3 L
√N
+ Cl1ip/2 C11/2 C21/4
d9/8L3/4+q log L
-N 1/(4+26)
6 d5/4L1+q log4/3 L
N 1/(4+26)
+ Cd2i/ff3ClipC1C21/3CP5/3
11/6L13/6+5q/3 log2 L
N (5+6)/(4+26)
7/4L2+3q/2 log2 L
N 1/(2+6)
Using	Clip	≥ 1,	C1	≥	1,	CP	≥ 1, and	C2	≥ 1, we can worst-case constants in the previous
expression to simplify. We can then do some selective worst-casing of the exponents ond, N, and
L in all except the first term: we have evidently (to combine the first and last terms)
d7/4L2+3q/2 log2 L	d7/4L5/2+2q log2 L
N 1/(2+6)	≤	n 1/(2+6)
43
Published as a conference paper at ICLR 2021
and (to combine the first and second terms)
d5/3L11/6+4q/3 log2 L	d7/4L5/2+2q log2 L
N 6∕(10+5δ)	≤	N 1∕(2+δ)
and because 0 < δ ≤ 1, we have 1/(2 + δ) ≤ 1/2 and (5 + δ)∕(4 + 2δ) ≥ 1, and if N ≥ d1/12 this
implies (to combine the first and second-to-last terms)
d11/6L13/6+5q/3 log2 L	d7/4L5/2+2q ]0g2 刀
N (5+δ)∕(4+2δ)	≤	N 1∕(2+δ)	.
We can worst-case the remaining three terms, and we thus obtain
Λk ≤ CC1d1∕4L3∕2
dlog2 L + 4CdiffCiipCιC1/2Cp/3 i*/2+^^ L
2L2/3L2/3L1/4L1/3 d1 + 1∕4L1+q log4/3 L
+3Clip CI	C2	CP	N ι∕(4+2δ)
We can then pick Clip = 3C, and if
N 1”4+2δ) ≥ 3(3C)2/3C2/3C1/4Cp/3d1/4L1+q,
and
N1/(2+" ≥ 12CCdiffCIC1/2Cp/3d3/4L5/2+2q,
then it follows from the previous bound
Λk ≤ 3CC1d5/4L3/2 log2 L,
which establishes (B.65) in the first case, where (B.69) holds. Next, we consider the remaining case
where (B.68) holds, so that the maximum in (B.64) is saturated by the first argument. We start by
grouping some terms in (B.61) so that it will be slightly easier to simplify later: we can write
(B.70)
QZN-ζ∞ 器(M) + d1/3)A1/3
k-1
dlog2L+nτXζsN-ζs∞L2∞(M)+
s=0	*8
P1/6 N 1/(4+26) X QZN - ζ∞ 心/3∞ (M) + d1/6
ρmin	s=0
nτd1∕4 kX
+ Pmin √N s=o
+ C⅛4 X QZN- ζ∞C∞ (M) + d1/4)A1/2
s=0
By the case-defining condition (B.68) and (B.64), enforcing
n≥Cd1i2ffL60+32qd9log9L
implies
UZN- ζ∞hμ∞ (M) + d1/2 ≤ 2d1/2,
and we can use this to simplify (B.70), obtaining
k-1
Λk ≤ CC1d1/4L3/2 d log2 L + nτ XUUZsN - Zs∞UUL
s=0
+ 也E X A1/3 +
+ ρmin√N J S +
μ∞ (M)+
2C1∕4nτd1/2
N 1/(4+26)
2nτd5∕12	X a2/3
ρ%6N 1/(4+26) S⅛ S
km-i1n	s=0	(B.71)
X A1/2 .
S=0
44
Published as a conference paper at ICLR 2021
Plugging (B.64) and (B.65) into (B.71) and using kτ ≤ Lq/n and (B.68), we get the bound
Λk ≤ CCid1/4L3/2 (dlog2 L + Cdiff ( L60+""d15log9L A / +
n
2Cl21Z3C2∕3Cp/1
6 d1+1/4L1+q log2/3 L
+ 2瑞3C73Cj3
N 1∕(4+2δ)
dL1/2+q log2/3 L
(B.72)
√N
+ 2Cl1ip/2C11/2C21
/4 d1+1/8 L3/4+q log L
N 1∕(4+2δ)
From (B.72), we see that if we choose n such that
n≥ (2Cdiff)12L60+44qd3
and we choose N such that
N 1∕(2+δ) ≥ 16C4/3C4/3C1/2C1/3d1/2L2+2q
Lip 1	2 ρ
then (B.72) implies the bound
Λk ≤ 3CC1d5/4L3/2 log2 L,
which agrees with the previous choice Clip = 3C and thus proves (B.65) in the remaining case of
(B.71). By induction, then, we have proved that (B.64) and (B.65) hold for each index 0 ≤ k ≤
bLq/(nτ )c.
We can now wrap up the proof: we will obtain the desired conclusion by plugging the results we
have developed into (B.57) and simplifying. Plugging (B.37), (B.27) and (B.64) into (B.49) and
bounding the maximum by the sum, we get
ζ N,Lip
IIZbLq /(nτ )C
Lμ∞ (M)
≤ IkbLq/(nτ)C
Lμ∞(M)+ IKNLq/(nτ)c - ζbLq/(nτ)C
Lμ∞(M) + IWbLq/(nT)c Il∞(M)
≤
≤
≤
CCPcert √ log L
nτ bLq / (nτ)C
+ C0
L60+32qd15 log9 L、1/12
n
3 d7/4L5/2+q log2 L
N 1∕(2 + δ)
CCqcert √d log L
Lq
CCqcert √d log L
+ c, f L60+32q d15 log9 L A 1/12
d7/4L5/2+q log2 L
N 1∕(2+δ)
Lq
(B.73)
n
where in the third inequality we apply bLq /(nτ)c ≥ Lq /(2nτ), which follows from our choice
of step size, and in the fourth inequality we simplify residuals using n ≥ (C0/C)12d9L60+44q
and N1/(2+(5) ≥ C〃CiC1/2C4/3d5/4L5/2+2q log L. Applying (B.73), the triangle inequality (with
(B.37) and the fact that μ∞ is a probability measure) and our previous choice of large n, We get
N
ZbLq/(nτ )c
≤
Lμ∞ (M)一
CCqcert √d log L
Lq
(B.74)
i.e. generalization in L∞ (M). We can bootstrap generalization in L∞(M) from (B.73) using the
triangle inequality and (B.57): we get
N
ζbLq /(nτ)c
≤ CC21/2
L∞(M)
N,Lip
bLq∕(nτ )c
C
Lμ∞ (m) + M
N，L/PnT "l] (M)AIL375τ )C + IKLq/(nτ ∕l∞(M)
CC72Cqcert√dlogL 十 C0C1/3 d3/4L(3-4q)/6 log4/3
Lq
ρ1/3
ρmin
min{ Pmin,
≤
L
1
45
Published as a conference paper at ICLR 2021
where in the second line we apply (B.37) and our previous choice of large n to absorb the residual
from δ"q/(nτ)c，and apply (B.65) to bound the Λ1L3/飙丁)」term. Worst-casing the errors in the
previous bound, we obtain
ZNLq Krnr )cl∣L∞(M)
≤ C (CqCert Cl / + Cl3。'3)
d3/4log4/3L
L(4q-3)∕6	.
To conclude, we will tally dependencies and make some simplifications to show the conditions stated
in the result suffice. Recalling (B.53) and (B.58) and using (B.62), we have
Cl ≤ CCpqcert + 1 (1 + Pmax)1/2 e14∕δ ,
so we can simplify to
Cρ1∕2C21∕2 + C11∕3Cρ2∕3 ≤ Cρ
ρmax
min {μ∞(M+), μ∞(M-)}
1∕2
+ CCρ1+2qcert∕3(1 + ρmax)1∕6e14∕(3δ)
CCp+2qcertl3(1 + Pmax)1∕2e14∕(3O
min {μ∞(M+), μ∞(M-)}1/2
We can use this to obtain a simplified generalization in L∞(M) bound from our previous expression:
it becomes
N l∣	< CCp1+2qcert/3(1 + Pmax)1/2e14/M) d3/4 log4/3 L
ZbLq/(nr"llL∞(M)- min {μ∞(M+),μ∞(M-)}1/2^^L(4q-3)/6
(B.75)
which can be made nonvacuous when q > 3/4. Tallying dependencies, we find after worst-casing
(and using q ≥ 1/2 and some interdependences between parameters to simplify) that it suffices to
choose N such that
N 1∕Q+0 ≥ CC4/3C1/2Cp/3e21/6d5∕4L5∕2+2qlogL,
the depth L such that
L ≥ C max{Cρ2qcert d, κ2Cλ },
the width n such that
n ≥ C max{e252∕δL60+44qd9 log9 L, k2/5,
and d such that d ≥ Cd0 log(nn0CM). Unpacking the constants in the condition on N, we see that
it suffices to choose N such that
LL7∕2 + 8qcert∕3 门 _1_	、7∕6°119∕(3δ)
N 1∕(2+δ) ≥ CC-----------(1 + Pmax)	；	d5∕4L5∕2+2q log L.
min {μ∞(M+), μ∞(M-)} /
□
B.3 Auxiliary Results
Lemma B.8. Defining a kernel
θN (X, XO)= / D▽%? (XO), ^fθN-tτ V LμN (θN )(x)E dt
and corresponding operator on L：n (M)
ΘkN [g](X) =
M
θN(x, x0)g(x0)dμN(x0),
we have that ΘkN is bounded, and
Zk++1 = (Id -T ΘN )[ZN ].
46
Published as a conference paper at ICLR 2021
Proof. By the definition of the gradient iteration, we have that
ζN+ι - ZN = fθN-TVLμN (θN)- fθN.
The total number of trainable parameters in the network is M = n(n(L - 1) + n0 + 1), and the
euclidean space in which θ lies is isomorphic to RM. For k ∈ N0, define paths γkN : [0, 1] → RM
by
YN(t) = θN - tτVLμN(θN),
so that
ζkN+1 - ζkN = fγkN (1) - fγkN (0) .
We will justify a first-order Taylor representation in integral form based on the previous expression
by arguing that for every x ∈ M, t 7→ fγN(t) (x) is absolutely continuous on [0, 1], by checking
the hypotheses of (Cohn, 2013, Theorem 6.3.11). Because YN is smooth and f(,)(x) is continuous,
fγN(t) is also continuous. Continuity of the features as a function of the parameters and of γkN
implies that for every ` ≥ 0, the image of [0, 1] under the map
t→ αYN (t)(X)
is compact. By repeated application of Lemma E.21, we conclude that t 7→ fγN(t)(x) is differen-
tiable at all but countably many points of [0, 1]. Following the proof of Lemma E.21, we see that
the points of nondifferentiability oft 7→ fγN(t)(x) are contained in the set of points of [0, 1] where
there exists a layer ` at which at least one of the coordinates of α
`
YN (∙)
(x) vanishes. Applying the
chain rule at points of differentiability of the ReLU [ ∙ ]+ and assigning 0 otherwise, it follows that
the derivative oft 7→ fγN(t)(x) at t ∈ [0, 1] is equal to
at all but countably many points t ∈ [0, 1]. We finally need to check integrability of this derivative
on [0, 1]. We have by linearity
-TDV LμN (θN), V fγN (t)(x)E = -t∣mZθn (x0)DV fθN (x0), V fγN (t)(x)) dμN (x0), (B.76)
and by definition
DVefγkN(t)(x),VefθkN(x0)E
L-1
=αLN((t)(X),αLN(X0)〉十 XEYN(t)(X),αθN(XO)XeYN(t)(X),βθN(X'»
2=0
By construction of the network, the feature maps (t, x) → OYN伯)(x) are continuous. For the back-
ward feature maps, we can write for any θ1 = (W11, . . . , W1N+1) and any θ2 = (W21, . . . , W2N+1)
using Cauchy-Schwarz
N
κβθι(x),βθ2(x0))∣ ≤ Y IIWf+1∣Im0+1∣∣,
'0='+1
and the RHS of this bound is a continuous function of (θ, X). Because our domain of interest
[0, 1] × M is compact, we have from the triangle inequality, the previous bound on the backward
feature inner products and the Weierstrass theorem
sup	∣∣∣DVe fYN (t)(X), Ve fθN (X0)E∣∣∣ < +∞,	(B.77)
t∈[0,1], x∈M	Yk (t)	θk
so that in particular, we can bound our expression for the derivative of t 7→ fYN(t) (X) using the
triangle inequality as
∣-τ Dv LμN (θN), V fγN (t)(X)EI ≤ CTJj∣ζθN (X0 )∣ dμN (XO)
47
Published as a conference paper at ICLR 2021
for some constant C > 0. The RHS of the previous bound does not depend on t, so by an application
of (Cohn, 2013, Theorem 6.3.11), it follows that t 7→ fγN(t) (x) is absolutely continuous, and we
have the representation
ζN+l(x) - ZN (X) = -T / D LμN (θk ), V fγN (t)(X)Edt.
Using (B.76), we can express this as
ζkN+1(X) - ζkN (X)
-τ Z01 ZM
ζθN(XO)(VfθN(XO), VfγN(t)(X)) dWN(XO)) dt.
To conclude, it will be convenient to switch the order of integration appearing in the previous ex-
pression. Applying (B.77), we have
ζθkN(XO)DVefθkN(XO),VefγkN(t)(X)E ≤CζθkN(XO),
and the RHS of this bound is integrable over [0, 1] × M because the network is a continuous function
of the input. By Fubini’s theorem, it follows
ZN+1(X)- ζN (X) = -T HL DV fθN(X), v fγN (t)(X)E dt) ZeN(X0)d〃N (XO)	(B.78)
Defining
ΘkN(X,XO) =	Ve fθkN(XO),Ve fγkN(t)(X) dt
and using (B.77), We can define bounded operators ΘN : LjjN (M) → L：n (M) by
θN [g](X)= / θN(x, X0)g(X0)d〃N(XO),
M
and With this definition, (B.78) becomes
ZkN+1-ZkN=-TΘkN ZkN,
as claimed.
□
Lemma B.9. For any network parameters θ, define kernels
Θθ(X, XO) = DVe fθ(XO),Ve fθ(X)E,
and for ? ∈ {N, ∞}, define corresponding bounded operators on Lμ? (M) by
θθ,μ?
[g](X) =
M
Θθ(x, XO)g(XO)dM?(XO).
For any settings of the parameters θ, the operators Θθ,μ? are self-adjoint, positive, and compact.
In particular, they diagonalize in a countable orthonormal basis of L%? (M) functions with corre-
sponding nonnegative eigenvalues.
Proof. When ? = N, an identification reduces the operators Θθ,μ? to operators on finite-
dimensional vector spaces, and the claims folloW immediately from general principles and the
finite-dimensional spectral theorem. We therefore only Work out the details for the case ? = ∞.
Boundedness folloWs from an argument identical to the one developed in the proof of Lemma B.8,
in particular to develop an estimate analogous to (B.77). This estimate, together With separability
and compactness of M, also establishes that Θθ,∞ is compact, by standard results for Hilbert-
Schmidt operators (Heil, 2011, §B). In addition, this estimate alloWs us to apply Fubini’s theorem to
write for any g1,g2 ∈ Lμ∞ (M)
hg1, θθ,∞[g2]iLμ∞ (M)
〃
M×M
Θθ(X, XO)gi(x)g2(xO) dμ∞(x) dμ∞(χ∕)
hg2, Θθ,∞ [g1]i
48
Published as a conference paper at ICLR 2021
since Θθ(X, X0) = Θθ(X0, X). A similar calculation establishes positivity: we have for any g ∈
Lμ∞ (M)
hg, Θθ,∞[g]iL2∞(M) = ∣Im JDfθ(x0), Vfθ(X)Eg(X)g(x0)dμ∞(x)dμ∞(x0)
Vfθ(x)g(x) dμ∞(x), / Vfθ(x)g(x) dμ∞(x)) ≥ 0,
where we applied Fubini’s theorem and linearity of the integral. These facts and the spectral theorem
for self-adjoint compact operators on a Hilbert space imply in particular that the operator Θθ,∞
can be diagonalized in a countable orthonormal basis of eigenfunctions (vj∈N ⊂ Lμ∞ (M) with
corresponding nonnegative eigenvalues (λi)i∈N ⊂ [0, +∞).
□
Lemma B.10. Write Θ*n for the operator defined in Lemma B.9, with the parameters θ set to
the initial random network weights and the measure set to μN. There exist absolute constants
c, K, K0 > 0 such that for any q ≥ 0 and any d ≥ Kd0 log(nn0CM), if
1
T < -n----∏------------------
llθμN 11L∕n (M)→L2μN (M)
and ifin addition n ≥ K 0 L48+20q d9 log9 L, then one has
P
\	IIζiNIIL2N(M) ≤
0≤k≤Lq/(nτ )1	μ
≥ Tl + *”"
Proof. Consider the nominal error evolution ZkN,nom, defined iteratively as
N,nom	N,nom	N,nom
Zk+l	= Zk	-TθμN 归k ,	]；
ZN,nom = Z
for a step size τ > 0, which satisfies
T V	1
llθμN llLjN (M)→L2μN (M)
We will prove the claim by showing that this auxiliary iteration is monotone decreasing in the loss,
and close enough to the gradient-like iteration of interest that we can prove that the gradient-like
iteration also retains a controlled loss. These dynamics satisfy the ‘update equation’
ZNwom = (Id -T ΘμN )k [Z ].
Because Mis compact and ζ is a continuous function of the input, we have ζ ∈ L∞(M) for all
values of the random weights. Because μN is a probability measure, this means Z has finite Lk (M)
norm for every p > 0. Meanwhile, the choice of T and positivity of the operator (by Lemma B.9)
guarantees
IIId -TθμN l∣L2N(M)→L2N(M) ≤ 1,
from which it follows from the update equation
府"L2n(M) ≤ kζM(M) ≤ kζkL∞(M),
μN
(B.79)
where the last inequality uses that μN is a probability measure. In particular, this nominal error
evolution is nonincreasing in the relevant loss. Now, we recall the update equation for the finite-
sample dynamics
ζN+ι = (Id -T ΘN )[ζN ],
which follows from Lemma B.8. Subtracting and rearranging, this gives an update equation for the
difference:
zN+1 - ζN+nom = (Id -TθμN) [ζN - ζN,nom] - T (ΘN - ΘμN) [ζN].
(B.80)
49
Published as a conference paper at ICLR 2021
Under our hypothesis on τ , (B.80) and the triangle inequality imply the bound
N ,nom
k+1	L2N(M)
μ
nom∣∣L2 N (M)+τ∣∣ζN∣∣LμN (M)∣∣θN- θμN∣∣LμN (M)→LμN (My
μN
Using Jensen’s inequality and the Schwarz inequality, we have
llθN - θμNI∣L2N(M)→L2N(M)
≤
SUp	I ∣∣θN(∙,XO)-θ(∙,XO)∣∣l2 (M)|g(XO)ldμN(XO)
kgkL2jv(M)≤1 JM	μN(M)
μN
≤
≤
sup ∣ΘkN - Θ∣L∞(M×M)kgkL1N(M)
kgkL2 N (M)≤1	μ
μN
∣∣Θk - Θ∣∣L∞(M×M),
since μN is a probability measure. Defining
∆kN = i∈{0m1ax k} ∣∣ΘiN - Θ∣∣L∞(M×M),
i∈{0,1,...,k}
by a telescoping series and the identical initial conditions, we thus obtain
k
1 - ζk+,n1om∣∣L2 (M) ≤ τ∆kN X∣∣ζiN ∣∣L2 N (M),
μNi=0	μ
and the triangle inequality and (B.79) then yield
k
ζkN+1L2N(M) ≤ kζkL∞(M) + τ∆kN XζiN L2 N (M).
μN	i=0	μN
Using a discrete version of (the standard) Gronwall’s inequality, the previous bound implies
k-1	k-1
∣∣ζkN∣∣L2N(M)≤kζkL∞(M)+kζkL∞(M)Xτ∆kN-1exp	X τ∆kN-1
μ	i=0	∖j=i+1
≤ kζk
L∞(M) (1+kτ 斗-ι exp (kτ δN-Iy).
(B.81)
To conclude, we will use Lemma F.5 and an inductive argument based on (B.81). Let us first observe
that by Lemma D.11 (with a rescaling of d, which worsens the absolute constants), we have
P kZkL∞(M) ≤ ɪ
≥ 1 - e-cd
(B.82)
as long as n ≥ Kd4L and d ≥ K0d0 log(nn0CM). Define events EkN by
EN = {院 k N (M) >
I	μN
where d > 0 is sufficiently large to satisfy the conditions on d given above. We are interested in
controlling the probability of Sik=0 EkN for k ∈ N0. We can write
P
k
[ EiN
i=0
k-1
k-1
UEN + P EN ∩ ∩(EiN)c ,
i=0
i=0
P
and unraveling, we obtain
k
P
k
[ EkN
i=0
i-1
EP EN ∩∩ (EN )c .
i=0
j=0
50
Published as a conference paper at ICLR 2021
In words, it is enough to control the sum of the measures of the parts of EkN that are common with
the part of the space where none of the past events occurs. First, note that (B.82) implies
PE0N ≤ e-cd,
and so assume i > 0 below. For any q > 0, if kτ ≤ Lq /n, n ≥ K L36+8q d9 and d ≥
K0d0 log(nn0CM), Lemma F.5 gives that there are events BiN that respectively contain the sets
{∆iN-1 > CL4+2q/3d3/4n11/12 log3/4 L}, and which satisfy in addition
i-1
P BN ∩ \ (EN)c ≤ e-cd.
j=0
We thus have by this last bound, a partition, and intersection monotonicity
- i-1	]
P EN ∩ \ (EjN)c ≤ e-cd + p[eN ∩ (BN)c],
j=0
and by construction, one has ∆N-ι ≤ CL4+2q/3d3/4n11/12 log3/4 L on (BN)c. Another partition
and (B.82) give
PhEN ∩ (BN)ci ≤ e-cd + P EN ∩ (BN)c 《∣∣Z卜『必)≤
When the two events on the RHS of the last bound are active, we can obtain using (B.81)
ζkN L2 N (M)
μN
≤ 彳(1 + kτCL4+2q∕3d3∕4n11/12 log3/4 Lexp (kτCL4+2q∕3d3∕4n11∕12 log3/4 L)).
Given that kτ ≤ Lq/n, we have
kτCL4+2q∕3d3∕4n11∕12 log3/4 L ≤ ( C"L48+:d9log9 L)1" ≤
where the last bound holds provided n ≥ KL48+20qd9 log9 L . Thus, on the event
(BN)c ∩{kZkL∞(M) ≤√2d},
We have
UZk IIl2n(M) ≤ √d,
μN
and thus
P EN ∩ (BN)c ∩{kZkL∞(M) ≤ 2 }] = 0.
By our previous reductions, We conclude
i-1
P EN ∩ \ (EN)c ≤ 2e-cd,
j=0
and in particular
k
P [ EkN ≤ (2k+ 1)e-cd.
i=0
The claim is then established by taking k as large as Lq / (nτ).	□
51
Published as a conference paper at ICLR 2021
Corollary B.11. Write ΘμN for the operator defined in Lemma B.9, with the parameters θ set to
the initial random network weights θo and the measure set to μN, and definefor k ∈ No
∆kN =	max	ΘN - Θ	.
k = i∈{0m,1a,.x..,k}	i -	L∞(M×M).
There exist absolute constants c, C, C0 , K, K0 > 0 such that for any q ≥ 0 and any d ≥
Kd0 log(nn0CM), if
T V	1
llθμN Ul；n (M)→L2μN (M)
and if in addition n ≥ K 0 L48+20q d9 log9 L, then one has on an event of probability at least 1 -
C 0(1 + Lq /(nτ ))e-cd
∆N/(nτ)C-1 ≤ Clog3/4(L)d3/4L4+2q/3n11/12.
Proof. Use Lemma B.10 to remove the hypothesis about boundedness of the errors from Lemma F.5,
then apply this result together with a union bound.	□
Lemma B.12. Write Θ for the operator defined in Lemma B.9, with the parameters θ set to the
initial random network weights and the measure set to μ∞. Consider the (population) nominal
error evolution ζk∞, defined iteratively as
ζk∞+1 = ζk∞ - τΘ [ζk∞] ;
ζ0∞ = ζ
for a step size τ > 0, which satisfies
1
T <	-----------------
kθkLμ∞ (M)→Lμ∞ (M)
Thenfor any g ∈ L∞ (M) and any k satisfying
kτ ≥
3e llgkLμ∞(M)
2 kζ kL∞(M)
we have
kζ∞kLμ∞(M) ≤ √3kθ[g] -Z bμ∞ (M)-
3kgkLμ∞ (M)
kτ
(他 kgkLμ∞(M)
l0glV2 kZ ∣L∞(M)kτ
Proof. The dynamics satisfy the ‘update equation’
Zk∞ = (Id -τΘ)k [Z] .
Because M is compact and Z is a continuous function of the input, we have Z ∈ L∞ (M) for
all values of the random weights. Because μ∞ is a probability measure, this means Z has finite
Lμ∞ (M) norm for every p > 0. Using the eigendecomposition of Θ as developed in Lemma B.9,
we can therefore write
∞
Z = Ehvi，ZiLμ∞ (M)Vi
i=0
in the sense of L∞ (M). Because Θ and Id -τΘ diagonalize simultaneously, We obtain
∞∞
kζ∞kLμ∞ (M) = XQfi)2 hvi,ζ iLμ∞ (M) ≤ X e-2kτλi hvi,ζiLμ∞ m
i=1	i=1
where the inequality follows from the elementary estimate 1 - x ≤ e-x for x ≥ 0 and our choice
of τ, which guarantees that 1 - τλi > 0 for all i ∈ N so that the elementary estimate is valid after
squaring. We can split this last sum into two parts: for any λ ∈ R, we have
kζ∞kLμ∞(M) = X e-2kτλihvi,ζiLμ∞(M)+ X e-2kτλihvi,ζiLμ∞m
i : λi≥λ	i : λi<λ
52
Published as a conference paper at ICLR 2021
Because Θ is positive, we have further that λi ≥ 0 for all i, so we can take λ ≥ 0. The first sum
consists of large eigenvalues: we use exp(-2kτ λi) ≤ exp(-2k τ λ) to preserve their effect, and
then upper bound the remainder of the sum by the squared Lμ∞ norm of Z. The second sum consists
of small eigenvalues: we replace exp(-2kτ λi) ≤ 1, and then plug in ζ = Θ[g] - (Θ[g] - ζ) and
use bilinearity, self-adjointness of Θ, and the triangle inequality to get
lhvi,ζiLμ∞ (M)I ≤ Iλhvi, giLμ∞ (M) I + lhvi, θ[g] - OLμ∞ (M)I ∙
We then square both (nonnegative) sides of the inequality and use Cauchy-Schwarz to replace the
squared sum with the sum of squares times a constant, obtaining
kζ∞kLμ∞(M) ≤ e-2kτλkζkLμ∞(M) + 3λ2kgkLμ∞(M) + 3kθ[g] - ZkLμ∞(M)
after re-adding indices i to the sum to obtain the third residual. We will choose λ ≥ 0 to minimize
the sum of the first and second terms. Differentiating and setting to zero gives the critical point
equation
2 kζkLμ∞(M)(kτ)2
3 kgkLμ∞(M)
(2tλ)e2kτλ,
which can be inverted to give the unique critical point
λ = ɪW 22 kζkLμ∞(M)(kT产ʌ
=而(3	kgkLμ∞(M)),
where W is the Lambert W function, defined as the principal branch of the inverse of z 7→ zez ; we
know that this critical point is a minimizer because the function of λ we differentiated diverges as
λ → ∞. Plugging this point into the sum of the first two terms gives
kζ∞kLμ∞ (M) ≤ 3kθ[g] - ζ kLμ∞ (M)
,kgkLμ∞(M) L 1W (kζ%∞(MWT)N W (kζ%∞(MWT)ʌ
+ (2∕3)(kτ)21 + 2	] (3∕2)kgkLμ∞(M) ))	[ (3∕2)kgkLμ∞(M)).
For x ≥ 0, the function x 7→ W(xT is strictly increasing, as the inverse of y 7→ yey; by definition
W(eT = 1; and we have the representation W(zT +log W(zT = logz (Corless et al., 1996), whence
W(x) ≤ log X if X ≥ e. Because μ∞ is a probability measure, We have
kζkLμ∞(M) ≤ kZkL
and therefore if
kτ ≥
3e llgkLμ∞(M)
2	kZ kL∞(M)
We can simplify the previous bound to
kζ∞kLμ∞ (M) ≤ 3kθ[g] - ζ kLμ∞ (M) + 9⅛∞2M2 log2
3	∣g∣Lμ∞(M) ʌ
2 kZkL∞(M)(kτ)2) ,
using also properties of the logarithm. Taking square roots and using the MinkoWski inequality then
yields
kζ∞kLμ∞ (M)
≤ √3kθ[g]-Z l∣Lμ∞ (M)-
3kgkLμ∞ (M)
kτ
(R kgkLμ∞(M)
lθglV2 IlZ ∣∣L∞(M)kτ
Where We used the previous loWer bound on kτ to determine the sign that the absolute value of the
logarithm takes. This gives the claim.	□
53
Published as a conference paper at ICLR 2021
Lemma B.13 (Kantorovich-Rubinstein Duality). Let Lip(M) denote the class of functions f :
M → R such that both fM are Lipschitz with respect to the Riemannian distances on M±. For
any d ≥ 1, any 0 < δ ≤ 1 and any N ≥ 2√d/ min{μ∞(M+), μ∞(M-)}, one has that on an
event of probability at least 1 - 8e-d, simultaneously for all f ∈ Lip(M)
∣y^ f (x) dμ∞(x) - L f (x) dμN(x)
2kf kL∞(M)√d	e14δ Cμ∞,M√d max*∈{+"lf∣M? Lp
一	N	+	N 1∕(2+δ)	,
where
_ len (M+)	Ien(M-)
μ∞,M = μ∞(M+) + μ∞(M-).
Proof. The proof is an application of the Kantorovich-Rubinstein duality theorem for the 1-
Wasserstein distance (Weed & Bach, 2019, eq. (1)), which states that for any two Borel probability
measures μ, ν on M±, one has
W (μ, V)=
sup I [	f (x)dμ(x) - (	f (x)dν(x)
kfkLip≤1 M±	M±
where M± denotes either of M+ or M-, and ∣∣ ∙ ∣∣Lip is the minimal LiPschitz constant with respect
to the Riemannian distance on M±. Therefore for any f : M± → R Lipschitz, we have
f (X) dμ(X)- /
M±
f(X) dν(X)
一 IIfIILiPW (μ,ν),	(B.83)
where one checks separately the case where ∣f ∣Lip = 0 to see that this bound holds there as well.
To go from (B.83) to the desired conclusion, We need to pass from the measures μ∞ and μN, both
supported on M, to measures μ± (with ? ∈ {N, ∞}), supported on the manifolds M± (which we
will define in detail below); the challenge here is that the number of ‘hits’ of each manifold M±
that show up in the finite sample measure μN is a random variable, which requires a small detour to
control. Let us define random variables N+ , N- by
N+ = NμN (M+);	N- = NμN (M-),
so that N± have support in {0, 1, . . . , N}, and N+ + N- = N. Define in addition
P+ = μ∞(M+);	P- = μ∞(M-),
which represent the degree of imbalance between the positive and negative classes in the data. By
definition of the i.i.d. sample, we have that N+ 〜Binom(N, p+). Using N+ and N-, we can define
‘conditional, finite sample measures μ? and μN by
μN = max{1,N+屋加§^M/{xi};	μN = max{1,N-} .e^X^ δ{xi},
so that (N+/N)μN + (N-/N)μN = μN,8 and μ? and μ- are both probability measures except
when N+ ∈ {0, N}, in which case exactly one is a probability measure. By the triangle inequality,
we have for any continuous f : M → R
k f (x) dμ∞(x) - k f (x) dμN (x)
一]χ-}H>⅛2-N?儿 mW (χ)∣
一 X kfkL∞(M) N? - p? + ZM f (x) μp(，- ZM f(X)dμN(X) .	(B.84)
8Here we treat the empty sum as the appropriate ‘zero element’ of the space of finite signed Borel measures
on M±, namely the trivial measure that assigns zero to every Borel subset of M±.
54
Published as a conference paper at ICLR 2021
By Lemma G.1, we have
P
≤ P
N?
N - p?
≥ 1 - 2e-2d
(B.85)
Using that N - N+ = N- and 1 - p+ = p-, the bound (B.85) implies if N ≥ 2√d/ min{p+,p-}
P 'p? ≤ N ≤ 1 -p?
≥ 1 - 2e-2d
(B.86)
Now fix an arbitrary f ∈ Lip(M). For either ? ∈ {+, -}, we can write
L(X)dμN (X) = max{⅛Γ NmJ (Xi)
max{1, PiN=1 1xi∈M*}
N
1xi∈M*f(Xi),
i=1
1
and since M+ and M- are separated by a positive distance ∆ > 0, we have that Xi 7→ 1xi∈M* are
continuous functions on M. Since f is continuous on M by the same reasoning and the fact that
M is compact, it follows that the functions (xι,..., XN) → JM f (x) dμN(x) are continuous on
M×∙∙∙×M as well, and in particular for any t > 0 the sets
Z
M?
f (X)T TmJH (X)l>t
are open in M, and so is their union over all f ∈ Lip(M). By conditioning, we can then apply
(B.86) to write
[ Z
ip(M)	M?
f (X)dμ∞^
f ∈Lip(M)
p?
TMfXM(X) >t
dN(1-p*)/2e
≤ 2e-2d +	X P
k=bNp*/2c
U
f ∈Lip(M)
Rm* f (x) W
Rm* f (X) dμN(X)
>t
N? = k P[N? = k].
(B.87)
Conditioned on {N? = k} with 0 < k < N, the measure μN is distributed as an empirical measure
of sample size k from the probability measure μ∞∕p? supported on M?. For [Np*∕2[ ≤ k ≤
dN(1 - p?)/2e, any δ > 0 and any d ≥ 1 we have for both possible values of?
√de1"δ len(M?) < √de1"δ len(M?)
k1∕(2+δ)
NHL
V2de14/6 len(M?)
(Np?)1"2")
and so an application of Lemma B.16 thus gives for any 0 < δ ≤ 1 and any d ≥ 2
p w fdμ∞(X), d〃N) >
p?
Vde14/6 len(M?)
(Np*)1"2+δ)
N? = k
≤ e-d
P
≤
Combining this last bound with (B.83) and (B.87) gives
P
U
f ∈Lip(M)
f(x)
dμ∞(x)
p*
-∕m* f (X) dμN(X)
「1 儿*kp len(M?)
>	N 1∕(2 + δ)
p*
≤ 3e-d
where we used max{p+,p-} ≤ 1 to remove the exponent of 1/(2 + δ) on these terms. Taking
a max over the Lipschitz constants and combining this bound with (B.84) and (B.85) and a union
bound, we obtain
P
IRM f(X)d〃g(X)- RM f (X)dμN (X)I
2kf kL∞(M)√d
U 1 > .一
f∈Lip(M) I	e	Cμ∞
I +--------------
N	ll ll
,M√d max*∈{+,-}∣fL*∣Lip
N 1∕(2 + δ)
≤ 8e-d
where the constant is defined as in the statement of the lemma.
□
55
Published as a conference paper at ICLR 2021
Lemma B.14. Let d0 = 1. There is an absolute constant C > 0 such that for any function f :
M → R with f M Lipschitz with respect to the Riemannian distances on M±, one has
kf kL∞ ≤ Cmax
PmaXkfkL2∞ (M)
_______________μ___________
Pmin(min {μ8(M+),μ8(M-D)I/2ɜ
kf kLμ3∞(M)max*c{+，-}lfL*IL：
Pm/3
Proof. For any T > 0 and a nonconstant Lipschitz function f : [0, T] → R, we will establish the
inequality
kfkL∞ ≤ C max I k√L2, kf kL/3kfkL/3},	(B.88)
where the constant C > 0 is absolute. We can use this result to establish the claim. We start by
writing
kf kL∞ =?哪XJm M*k，
and for ? ∈ {+, -}, we have
MMJIL∞ = kf ◦ Y*kL∞,	(B.89)
where γ? : [0, len(M?)] → M? are the smooth unit-speed curves parameterized with respect to
arc length parameterizing the manifolds. Similarly, the curves’ parameterization with respect to arc
length implies
kf ◦ γ*hip ≤∣∣f∣M*Lp.	(B.90)
Applying (B.88) with (B.89) and (B.90), we obtain
Mm*IIl∞ ≤ Cmax{PS⅛，
kf ◦ Y?kL/3 BnM* BLC
For the first term in the max, we have
kf。Y*kL?
len(M?)
1	len(M* )
=IEJ L	f。γ?⑴2 dt
f ◦ γ*(t)2ρ? ◦ γ*(t)dt
(+\2	(+∖p? ◦ Y?(t) - len(M*),,
◦ Y? (t) P? ◦ Y? (t)-------77?~~L dt
ρ? ◦ γ? (t)
using the triangle inequality. For the second term in the last bound, we note that
len(M*)
f。Y*(t)2ρ?。Y*(t)dt
len(M+)
f。Y+⑴2P+。Y+⑴ dt
len(M- )
f 。 Y- (t)2ρ- 。 Y- (t) dt
+
0
≤ kfkLμ∞(M)，
(B.91)
56
Published as a conference paper at ICLR 2021
and for the first term, we have
max
t∈[0,len(M?)]
ρ? ◦ γ?⑴-ien(M?)
ρ? ◦ γ?⑴
IC C NW _	ρ? °γ?⑶ I +	I	ρ*oγ?⑶	_ i	I
lρ? Y?(t)	μ∞(M*) 1 +	|	μ∞(M?) len(M?)1
max
t∈[0,len(M? )]	ρ? ◦ γ? (t)
≤ 1 — μ∞(M?) .	Pmax
一μ∞(M?)十 μ∞(M?)Pmin
≤	2ρmax
一μ∞(M?)Pmin ,
(B.92)
where in the first inequality We used the triangle inequality, and for the second We used that ρ? ◦y? in-
tegrates to μ∞(M?) over [0, len(M?)], which implies that there exists at least one t ∈ [0, len(M?)]
at which ρ? ◦ γ?(t) ≥ μ∞(M?)/ len(M?), so that the maximum of the difference in the second
term on the RHS of the first inequality is bounded by the maximum of the density term. Thus, by
Holder,s inequality and (B.91) and (B.92), we have
,len(M?)	P? ◦ Y?(t) — I-ΓT7~∖
f ◦…◦ Y?(t)	P? ◦ γ.(ltT) dt
3ρmax
Pmin min {μ∞(M+), μ∞(M-)}
kf kLμ∞ (M)
Similarly, for the second term in the max, we have
1/3
f ◦ γ- (t)2 dt
len(M- )
1/3
f ◦ γ- (t)2P- ◦ γ- (t) dt
Thus, we have
IIfIM*I∣L∞ ≤ Cmax
PmaXllf kLμ∞ (M)
Pmin (min {μ∞(M+),μ∞(M-)})1/2，
kf 号(M)f∣M*ll
Pl-
1/3
Lip
0
≤
0
and taking a maximum over ? ∈ {+, —} establishes the claim.
To prove (B.88), consider first the trivial case where kf kL∞ = 0: here the LHS and RHS of (B.88)
are identical, and the proof is immediate. When kf kL∞ > 0, the Weierstrass theorem implies that
there exists t ∈ [0, T] such that |f (t)| = kfkL∞; we consider the case sign(f (t)) > 0. For any
t0 ∈ [0, T], we can write by the Lipschitz property
f(t0) ≥ kfkL∞ —kfkLip|t—t0|,
and the RHS of the previous bound is nonnegative on the intersection of the interval [t —
kf kL∞ kfkL-i1p, t+ kf kL∞ kf kL-i1p] with the domain [0, T] (with standard extended-valued arithmetic
57
Published as a conference paper at ICLR 2021
conventions when kf kLip = 0). This gives the bound
min t+
kf k2L2 ≥	k
max t- k
kfkL∞ Tl
kfkLip ,T ʃ
kfkL∞ oO
kfkLip ,01
(kfkL∞ - kf kLip|t - t0|)2 dt0
fmin{ kkfkL∞ ,T-tθ
kf kLip
'max{-f∞ ,-t}
kf kLip
(kfkL∞ -kf kLip∣t0∣)2 dt0,
where the second line follows from the changes of variables t0 7→ t0 + t. The integrand on the
RHS of the second line in the previous bound is even-symmetric, and max -
-min I kfkL∞ ,t}, so We can discard one side of the interval of integration to get
kf kL∞
kfkLip,
-t
z∙min{ kfkL∞ ,T-tθ
kfkLip
Jmaxn-f∞ ,-to
kf kLip
(kfkL∞ - kf kLip∣t0∣)2 dt0
∕*min{ k∣fk∣L∞ ,max{t,τ-t}0	Q
≥	k p	；(kf kL∞ -kf kLipt0)2 dt0.
0
(B.93)
(B.94)
We proceed analyzing tWo distinct cases. First, if kf kL∞ ≤ max{t, T - t}kf kLip, then We must
have kf kLip > 0; integrating the RHS of (B.94), We obtain
kf k2L2 ≥
kfkL∞
3kfkLip,
or equivalently
kfkL∞ ≤ 31/3kfkL/23kfkL/3.	(B.95)
Next, We consider the case kf kL∞ > max{t, T - t}kf kLip. We split on tWo sub-cases: When
kf kLip = 0, integrating (B.94) gives
kfkL2 ≥kfkL∞ max{t,T - t}≥ Tf∞,
Where We used max{t, T - t} ≥ T/2. When kf kLip > 0, integrating (B.94) gives
kf 隹 ≥ w1r- (kf kL∞ - (kf kL∞ - kfkLip max{t, T - t})3)
3kf kLip
= maχ{t3τ - t} XX kfkL∞k (kfkL∞ -kfkLip maχ{t,τ - t})k
k=0
≥ TkfkL∞
一 6	,
(B.96)
(B.97)
Where the second line uses a standard algebraic identity, and the third line uses max{t, T-t} ≥ T/2
together With the definition of the case to get that kf kL∞ - kf kLip max{t, T - t} > 0 in order to
discard all but the k = 0 summand. Combining (B.97) and (B.96), We obtain for this case
kfkL∞ ≤ ^6√fc,	(B.98)
and combining (B.95) and (B.98) gives unconditionally
kfkL∞ ≤ max(√6√Tl2, 31/3kf kL/3kf kL/3),
Which establishes (B.88). For the case sign(f (t)) < 0, apply the preceding argument to -f to
conclude. See (Brezis, 2011, Exercise 8.15) for a sketch of a proof that leads to more general
versions of (B.88).
□
58
Published as a conference paper at ICLR 2021
Lemma B.15. For any p ∈ N, if C ≥ (4p)4p, then one has
n ≥ Clogpn if n ≥ 2pC logp(2pC).
Proof. We first give a proof for p = 1, then build off this proof for the general case. Consider
the function f(x) = Cx 一 log x. We have f0 (x) = C 一 1/x, which is nonnegative for every
x ≥ 1/C, so in particular f is increasing under this condition. By concavity of the logarithm, we
have log x ≤ log(2/C) + (C/2)(x 一 2/C), whence
f(x) ≥ 1 + Cx/2 一 log(2/C).
The RHS of this bound is equal to zero at x = (2/C)(log(2/C) 一 1), and
2
c
1 O C ≤ 2e-3/2.
c
In particular, we have f(x) ≥ 0 for every x ≥ (2/c) log(2/c). Rearranging this bound, we can assert
the desired conclusion that if C ≥ 3, then n ≥ C log n for every n ≥ 2C log 2C . Equivalently, we
have for all such n that Cn-1 logn ≤ 1. Next, we consider the case ofp > 1. We will show
C出≤ 1
n
under suitable conditions. Let us consider the choice n = KC logp KC, where K > 0 is a constant
we will specify below. Consider the function f (x) = Cx-1 logp x, which satisfies
logp-1 (x)(p - logp-1 (x))
f0(x) = C
x2
In particular, f is decreasing as soon as p ≤ logp-1(x). Now, we can calculate
f(KC logp KC) = K (ι+⅛gog∣C )p,
and by our result for the case p = 1, we have for allp ≥ 2
P loglogKC ≤ 1 if log KC ≥ 4p log4p.
log KC
This condition is satisfied for KC ≥ (4p)4p, so if we set K = 2p, we obtain the above conclusion
when C ≥ (4p)4p. Under these conditions, we then get
f(KClogpKC) ≤ 1.
Similarly, we have logp-1(KClog KC) ≥ logp-1((4p)4p) = (4p)p-1 logp-1(4p), which is larger
than p because 4p ≥ e. It follows that f(x) ≤ 1 for every x ≥ KClog KC, which completes the
proof.	□
Lemma B.16 (Concentration of Empirical Measure in Wasserstein Distance (Weed & Bach, 2019)).
Let do = L For either ? ∈ {+, 一}, let μ be a Borel probability measure on M?, and write μN
for the empirical measure corresponding to N i.i.d. samples from μ. Thenfor any d ≥ 1 and any
0 < δ ≤ 1, one has
P W (μ,μN) ≤
Vde14/6 len(M?)
N 1∕(2+δ)
≥ 1 - e-2d
where the 1-Wasserstein distance is taken with respect to the Riemannian distance.
Proof. The proof is a direct application of the results of (Weed & Bach, 2019) on concentration
of empirical measures in Wasserstein distance. For the duration of the proof, we will work on the
metric space
(M?, len(M?)T distM? (∙)), i.e.,the same metric space scaled to have unit diameter; We will then
obtain the result in terms of the unscaled metric by the definition of the 1-Wasserstein distance.
59
Published as a conference paper at ICLR 2021
Because d0 = 1 and M? can be given as a unit-speed curve parameterized with respect to arc length,
we have for any Borel S ⊂ [0, 1] and any ε> 0
Nε(S) ≤ 1,
ε
where Nε(S) denotes the ε-covering number of S by closed balls in the rescaled metric. Following
the notation of (Weed & Bach, 2019, §4.1), we then obtain for any s > 2
dε(μ,ε"(I))
loginf{Nε(S) I μ(S) ≥ 1 -ε"(S-2)}
.
- log ε
Invoking (Weed & Bach, 2019, Proposition 5), we obtain after some simplifications of the constants
that for any 0 < δ ≤ 1 (putting s = δ + 2 in the previous estimates)
E[W (μ,μN)] ≤ 31^δN-"2+6+36NT/2 ≤ e14/6N-1/(2+δ),
where the final inequality worst-cases constants for convenience. Using (Weed & Bach, 2019,
Proposition 20), we have
P W(μ,μN) + E[W(μ,μN)] ≥ ʌ/N] ≤ e-2d
and hence
P
∖Γde14∕δ
W") ≥ NTWy
≤P 卜 (μ, μN) ≥ Ne∕(2+δ)+rN]
≤P
W(μ,μN) + E [W(μ,μN)] ≥
if d ≥ 1.
□
Lemma B.17. Let n, m ∈ N. Let F : Rn → Rm be 1-nonnegatively homogeneous, and suppose
there exist M, L ≥ 0 such that
1.	kFSn-1k2L∞ ≤M;
2.	F Sn-1 is L-Lipschitz.
Then for any x, x0 ∈ Rn, one has
kF(x)-F(x0)k2≤(2L+M)kx -x0k2,
so that F is (2L + M)-Lipschitz.
Proof. For any numbers a, b ≥ 0 and any u, v ∈ Rm, one has by the triangle inequality
kau - bvk2 ≤ min{aku - vk2 + |a - b|kvk2, bku - vk2 + |a - b|kuk2}.
Using an elementary property of the min and the max, we thus have
kau - bvk2 ≤ min{a, b}ku - vk2 + max{kuk2, kvk2}|a - b|.
(B.99)
Now we proceed to show the claim. Noting that the case where both x, x0 are zero is trivial, first
consider the case where x is nonzero and x0 is zero. By nonnegative homogeneity, it suffices to
proceed as
kF (x) - F (x0)k2 = kF (x)k2 = kxk2F
Xɪ)∣[≤ MkX∣2 = Mkx -x0k2
to conclude; for the inequality we used the boundedness assumption on F . Now fix x, x0 ∈ Rn
nonzero. The inequality (B.99) can be applied to get
kF (x) - F (x0)k2
2,
60
Published as a conference paper at ICLR 2021
where in the inequality we also applied the `2 triangle inequality. Using the assumed properties of
F , we thus have
x	x0
kF(X)- F(x0)k2 ≤ Lmin{kxk2,kx0k2}现-PT^ 2 + Mkx - Rb
By a classical inequality (e.g. proved in (E.15)), one has
x _ x0	≤ 2 kx - x0k2
kxk2 llx0k2 2 - maχ{kxk2, kx0k2} ,
whence
kF(x) - F(x0)k2 ≤ (2L + M)kx - x0k2,
as was to be shown.	□
C S keleton Analysis and Certificate Construction
In this section, we construct a certificate g for the certificate problem (B.1) in the context of a simple
model geometry. We also collect technical estimates relevant to the analysis of the skeleton ψ .
We point to Appendix A.5.2 for a summary of the operator and function definitions relevant to the
certificate problem that we will use below. We will use the notation
θ[g](x)=M
ψ ◦ ∠(x, x0)g(x0) dμ∞(x0)
in this section; We call explicit attention to this notation to avoid confusion with the kernel ΘΘ
ψ1 ◦ ∠ that we have defined in the main text for convenience of exposition.
C.1 Certificate Construction
To construct a certificate, it suffices to solve the integral equation
ʌ	△一 r
Z = Θ[g]	(C.1)
for a function g ∈ L∞ (M) and obtain estimates on the norm of g. It is useful to consider separately
the contributions of integration over the class manifolds M± in the action of the operator Θ: we
can write for any g
Θ[g](x) = [ ψ ◦ ∠(x, x0)g(x0)dμ∞(x0) +(
ψ ◦ ∠(x, x0)g(x0)dμ∞(x0),
and it then makes sense to further subdivide based on whether the evaluation point x lies in M+
or M-, and to introduce the density ρ explicitly by a change of variables. With a slight abuse of
notation, we will write dxT to denote the Riemannian measure on M+ and M-, for concision.
Because the kernel ψ ◦ ∠ is symmetric, if we define an operator Θ + : L2(M+) → L2 (M+) by
ʌ - -,,
θ+[g+](x)
M+
ψ ◦ ∠(x, xT)g+(xT) dxT,
an operator Θ- : L2(M-) → L2(M-) by
Θ -
[g-](x) =
M
ψ ◦ ∠(x, xT)g- (xT) dxT,
and an operator Θ± : L2(M+) → L2(M-) by
Θ±[g+ ](x) = [ ψ ◦ ∠(x, x0)g+(x0)dx0,
M+
then we can write the certificate system (C.1) equivalently as the 2 × 2 block operator equation
r O
■ ʌ	ʌ
Θ + Θ ±
ʌ	ʌ
Θ ± Θ -
ρ+g+
ρ-g-
where we write ρ+ and ρ- for the restriction of the density ρ to M+ and M-, respectively, and
where the adjoint operation is viewed as occurring with operators between L2 (M+) and L2 (M-)
(both Hilbert spaces). We will make use of this notation in the sequel.
61
Published as a conference paper at ICLR 2021
C.1.1 Two Circles
The two circles geometry is a highly-symmetric geometry where M+ and M- are coaxial circles
in the upper and lower hemispheres of S2, each of radius 0 < r < 1. Here we note that since the
skeleton ψ depends only on the angle between points of Sn0-1, the particular embedding of this
geometry into Sn0-1 is irrelevant, and it is without loss of generality to consider the geometry in S2
once we have restricted ourselves to this configuration. We have unit-speed charts, for t ∈ [0, 2πr]
γ+(t)
r cos t/r
r sin t/r
γ-(t)
r cos t/r
r sin t/r
which implies specific forms of the spherical distances
∠ (γ+(t),γ+(t0)) = cos-1 卜 2 cos t~-- +(1 - r2))	(C.2)
and
∠ (γ+(t), γ-(t0)) = cos-1 (r2 cos -——— —(1 — r2)
r
(C.3)
with the analogous results for the remaining possible combinations of domains, by symmetry. Be-
cause ζ is piecewise constant on each connected component of M, there are constants C+ , C- such
that C+ = ζ on M+ and C- = ζ on M-. The block-structured system we are interested in solving
is then
-	-1	I- ʌ	ʌ -1 I-
C+	= Θ + Θ ± 1 Γρ+g+
C-∖	[θ± Θ」[ρ-g-
(C.4)
where subscripts are used to denote the domain of each component of the certificate. The coordinate
representations (C.2) and (C.3) show that each of the operators appearing in the 2 × 2 matrix in (C.4)
is invariant on the circle; we can obtain some useful simplifications by identifying these operators
with their coordinate representations. Defining
fr (t) = cos-1 (r2 cos t + (1 — r2)),
gr (t) = cos-1 (r2 cos t — (1 — r2)),
and (self-adjoint) operators on 2π-periodic functions g by
2π
A[g](t) =
0
ψ ◦ fr (t — t0)g(t0) dt0,
2π
X [g](t) =
0
ψ ◦ gr (t — tθ)g(tθ)dt0,
by a change of coordinates, it is equivalent to solve the system
r-1C+	A X ρ+g+
r-1 C-	X A ρ-g-
(C.5)
where we have identified ρ+ and ρ- with their coordinate representations, and with an abuse of
notation used the same notation for the certificate as in (C.4). We can use symmetry properties to
determine
gr (t) = π — fr (t — π),
so for purposes of analysis we need only consider fr . Each of the invariant operators in (C.5)
diagonalizes in the Fourier basis, and because the target ζ is a piecewise constant function, we only
need to use the first Fourier coefficient. In other words, we can solve this system by first inverting the
invariant operator, which responds to only the constant component of the target, and then inverting
the density multiplication operators. This approach is made precise in the following lemma.
Lemma C.1. There is an absolute constant K > 0 such that if L ≥ max{K, (π∕2)(1 — r2)-1/2}
and r ≥ 2, then the SyStem (C.4) has a solution that satisfies
64∣∣Z∣I
≤ U l∣L∞(M)
—nπ1/2Pmin
62
Published as a conference paper at ICLR 2021
Proof. Following the discussion by (C.5), it is equivalent to solve the system in the Fourier basis,
with only the DC component. We thus start by solving the system
r-1C+
r-1C-
2R0πψ ◦	fr(t) dt	2 R0π ψ ◦ gr(t) dt	G+
2R0πψ ◦gr(t)dt	2R0πψ ◦ fr(t)dt	G-	,
where G+ and G- are constants that we will show exist. This is a 2 × 2 system, and the matrix is
symmetric, with minimum eigenvalue 2 0π(ψ ◦ fr — ψ ◦ gr)(t) dt. Using Lemma C.2, we have if
L ≥ max{K, (π∕2)(1 — r2)-1∕2} and r ≥ 2
2 [ (ψ ◦ fr — ψ ◦ gr)(t)dt ≥ 鲁,
0	32r
so the 2 × 2 matrix is invertible, and by an operator norm bound on its inverse we have the regularity
estimate
(G+ + G-)1∕2≤ ∏n (C+ + C-)1/2.
It follows that the function
g+
g-
「G+1
G-
_ P- .
solves the system (C.4). We conclude
P+ ◦ Y+(t)dt +
G-	2
----ρ-	P- ◦ γ-(t)dt
◦ γ- (t)
Taking square roots on both sides of the expression resulting from the last inequality will give the
claim, after we simplify the expression	C+2 + C-2 . Since
√C+ + C- ≤ √2max{C+,C-} = √1ζIL"
we can conclude after adjusting constants.
□
LemmaC.2. There exists an absolute constant K > 0 such that if L ≥ max{K, (π∕2)(1-r2)-1/2}
and if r ≥ 11,, one has
2 [	(ψ ◦ fr — ψ ◦ gr)(t)dt ≥ πn.
[0,π]	32r
Proof. Write σr = ψ ◦ fr — ψ ◦ gr for brevity, which is nonnegative, by Lemma C.3. We consider
the tangent line to the graph of σr at 0; by Lemma C.3, this line has the form t 7→ σr(0) — tnrL(L +
1)∕4π, and its graph hits the horizontal axis at t = 4πσr(0)∕nrL(L + 1). Using that σr(0) ≤
ψ(0) = nL∕2, we see that this point of intersection is no larger than 2π∕r(L + 1), which can be
made less than K by choosing L ≥ K0, where K > 0 is the absolute constant appearing in the
convexity bound of Lemma C.3, and K0 > 0 is an absolute constant. Under this condition, we
obtain using Lemma C.3
σr (t) ≥ σr (0) — tnrL(L + 1)∕4∏,
and so
σr (t) dt ≥	(σr (0) — ntrL(L + 1)∕4π) dt
2πσr (0)2
nrL(L + 1).
We have σr(0) = nL∕2 — ψ(cos-1 (2r2 — 1)), and using the estimate of Lemma C.20, we get
nL 1 + Lν ∕2π
ψ(V) ≤ ZR⅛.
63
Published as a conference paper at ICLR 2021
Together with the estimate cos-1 (2r2 一 1) ≥ 2√1 — r2, We obtain
σr(0) = nL - ψ(cos-1(2r2 - 1)) ≥ nL	三
2	2 π + 2L 1 一 r2
nL
≥ ɪ,
where the final inequality requires the choice L ≥ ∏∕2√1 — r2. Thus, we have shown
πn
LE(t)dt ≥ 64r,
as claimed.
□
Lemma C.3. There is an absolute constant 0 < K ≤ π∕2 such that if L ≥ 3, one has for all
r ∈ (0, 1):
(i)	ψ ◦ fr 一 ψ ◦ gr ≥ 0 on [0, π];
(ii)	(ψ ◦ fr — ψ ◦ gr )o(0) = —nrL(L + 1)∕4π;
(iii)	ψ ◦ fr 一 ψ ◦ gr is convex on [0, K].
Proof. In this proof, we will make use of basic results on the skeleton ψ, namely Lemmas E.5,
C.17 and C.18 without making explicit reference to them. Property (i) follows from the fact that ψ
is decreasing, cos-1 is decreasing, and the definitions of fr and gr . We note that fr is smooth on
(0, π); to prove property (ii), it will suffice to show that fr admits a right derivative at 0 and π and
apply the chain rule. We have if t ∈ (0, π )
r2 sin t	1	r sin t
f 0 (t)=—	=—	—
r	，1 — (r2 cost +(1 — r2))2	√2 + r2(cost — 1) √1 — cost
after some rearranging, and by periodicity and symmetry properties of fr , we have
lim gr0 (t) = lim fr0 (t) = 0.
t&0 r	t%π r
We Taylor expand sin t(1—cos t)-1/2 in a neighborhood of zero to evaluate the derivatives there. We
have Sint = t—13∕6+O(t5) and 1—cos t = t2/2(1 — t2/2+O(t4));bythebinomial series, we have
(1 — cos t)-1/2 = √2∕t(1+12∕4 + O(t4)),whence sin t(1 — cos t)-1/2 = √2 + √2t2∕12 + O(t4),
and
lim fr0 (t) = r.
t&0
Thus
(ψ ◦ fr — ψ ◦ gr )0(0) = Ψ0(0)fr (O) = — "r "I" + O .
4π
For property (iii), now consider t ∈ [0, π∕2] when necessary. The chain rule gives
(ψ ◦ fr — ψ ◦gr)00 = [(ψ0 ◦ fr)fr00 — (ψ0 ◦gr)gr00] + [(ψ00 ◦ fr)(fr0)2 — (ψ00 ◦gr)(gr0)2],
and we have if t ∈ (0, π)
fr00(t)
r4(1 — cos t) cost — (r2 cost + (1 — r2))
2	2、3/2
1 — (r2 cost + (1 — r2))
after some rearranging of the numerator. We have 1 — cos t ≥ 0, and so the estimate r2 cos t + (1 —
r2) ≥ cost (with equality only att = 0) yields fr00(t) ≤ 0 (with a strict inequality if 0 < t < π). By
symmetry, this implies that gr00 ≥ 0, and using that ψ0 ≤ 0, we obtain
(ψ ◦ fr — ψ ◦ gr)00 ≥ (ψ00 ◦ fr)(fr0)2 — (ψ00 ◦ gr)(gr0 )2.
By symmetry, we have gr(t) = fr(π — t) on [0, π], and because fr is strictly concave we know as
well that fr0 is strictly decreasing; it follows that fr0 — gr0 is also strictly decreasing, and its unique
zero satisfies the equation
1 — cos t	2 — r2 (1 + cos t)
1 + cos t	2 — r2 (1 — cos t) .
64
Published as a conference paper at ICLR 2021
Noting that t = n/2 satisfies this equation, We conclude that f ≥ g； on [0, n/2], so that on this
interval we have
(ψ ◦ fr - ψ ◦ gr)00 ≥ (gr0)2 ((ψ00 ◦ fr) - (ψ00 ◦gr)) .
...
By Lemma C.19, if L ≥ 3 there is an absolute constant K > 0 such that ψ ≤ 0 on [0, K]. The
previous bound then yields
(ψ ◦ fr - ψ ◦ gr )00 ≥ 0,
as claimed.	□
C.2 Auxiliary Results
C.2. 1 Geometric Results
Lemma C.4. Let M be a complete Riemannian submanifold of the unit sphere Sn0-1 (with respect
to the spherical metric induced by the euclidean metric on Rn0) with finitely many connected com-
ponents K. If d0 = 1, assume moreover that each connected component of M is a smooth regular
curve. Then for every 0 < ε ≤ 1, there is a ε-net for M in the euclidean metric ∣∣∙∣∣2 having car-
dinality no larger than (CM /ε)d0, where CM ≥ 1 is a constant depending only on the diameters
supx,x0∈Mi distMi (x, x0) and, when d0 ≥ 2, additionally on the extremal Ricci curvatures ofMi.
Moreover these nets have the property that if X ∈ M is given, there is a point in the net X within
euclidean distance ε of X such that X lies in the same connected component of M as x.
Proof. Consider a fixed connected component Mi With i ∈ [K]. We Write the Riemannian distance
of Mi as distMi ; because Mi is a Riemannian submanifold of Rn0, We have distMi (X, y) ≥
kX - yk2 for every X, y in Mi. Because distMi (X, y) ≥ kX - yk2, it suffices to estimate the
covering number in terms of the Riemannian distance. We Will consider distinctly the cases d0 = 1
and d0 ≥ 2, starting With d0 = 1.
When d0 = 1, We have assumed that Mi are regular curves, so it is Without loss of generality to
assume they are moreover unit-speed curves parameterized by arc length, With lengths len(Mi). It
follows that we can obtain an ε-net for Mi in terms of distMi having cardinality at most len(Mi )∕ε
When 0 < ε ≤ 1, and by the submanifold property these sets also constitute ε-nets for Mi in terms
of the `2 distance. Covering each connected component Mi in this way gives a ε-net for M by
taking the union of each connected component’s net.
When d0 ≥ 2, we make use of standard results relating the covering number to the curvature and di-
ameter of M. Let diam(Mi) = supx,x0∈M distMi (X, X0), and let Rici denote the Ricci curvature
tensor of Mi (recall that we assume the metric on M is the one induced by the euclidean metric).
Then because M is compact, (1) maxi∈[K] diam(Mi) < +∞; and (2) because Rici is moreover
continuous, there are constants ki > 0 such that Rici ≥ -(d0 - 1)ki for each i ∈ [K]. Applying
Lemma C.5, it follows that for any ε > 0, there is a ε-net for Mi in terms of distMi with cardinality
no larger than (CmJe)"0, where CMi . diam(Mi)e2 diam(Mi)√ki.
Thus, for any i ∈ [K], any d0 ≥ 1 and any 0 < ε ≤ 1, we can conclude that there is a ε-net for Mi
in the euclidean metric having cardinality no larger than (CMi /ε)d0, where
C _ Jlen(Mi)	do = 1
Mi = [l6diam(Mi)e2diam(Mi)√ki d0 ≥ 2.
Taking the union of these nets and applying Lemma G.10 for simplicity, we conclude that for any
d0 ≥ 1 and any 0 < ε ≤ 1, there is a ε-net for M in the euclidean metric having cardinality no
larger than (Cm/e)d0, where
∫1 + PK=1 Ien(Mi)
[1 + 16 PK=i diam(Mi)e2 diam(Mi)√ki
d0 = 1
d0 ≥ 2.
The additional property claimed is satisfied by our construction of the nets.
□
Lemma C.5. Given k > 0 and integer d ≥ 2, suppose that M is a d-dimensional complete Rie-
mannian manifold with Ricci curvature tensor satisfying Ric ≥ -(d - 1)k. Then for any r, e > 0
65
Published as a conference paper at ICLR 2021
and any p ∈ M, there exists an ε-net (measured in the Riemannian distance distM) of the metric
ball {x ∈ M | distM(p, x) ≤ r} with CardinaUty at most Omgd where CM > 0 is a constant
depending only on k and r.
Proof. The proof is essentially an application of (Zhu, 1997, Lemma 3.6) together with some cal-
culations on volumes of geodesic balls in hyperbolic space that we record here for completeness,
although they are classical. For any r > 0 and any p ∈ M, write
Br(p) = {x ∈ M | distM(p, x) ≤ r}.
Fix p ∈ M and r, ε > 0. The hypotheses of the lemma make (Zhu, 1997, Lemma 3.6) applicable,
whence
inf{card(S) S ⊂ Br(P),Br (P) ⊂ [星⑺} ≤ Vo(B*),
where card(S) denotes the cardinality of a set S, and for all ε > 0, vol(Bk(ε)) denotes the volume
of a geodesic ball of radius r in the d-dimensional simply-connected hyperbolic space of constant
sectional curvature -k; these spaces are homogeneous and isotropic so the base point does not
matter (c.f. (Lee, 2018, Proposition 3.9)). In particular, we can calculate these volumes in any
model of hyperbolic space and anchored at any base point; We choose the Poincare ball model and
the base point 0, where the maximal unit-speed geodesics take the simple form
Y (t) = k-1/2v tanh —
for v ∈ Sd and t ∈ R (Lee, 2018, Theorem 3.7, Proposition 5.28). Integrating the volume form in
coordinates, We then get for any ε > 0
vol(Bk(ε))= /	( / J； M Ydx
J(k-1/tanh √kε∕2))Bd ∖1∕k - kxk2 J
=k-d/2 I-	(-ɪ Y dx
7(tanh √kε∕2)Bd ∖1 - kxk2∕
Where the second line changes coordinates x 7→ k-1/2x. Changing to polar coordinates in the last
expression, We get
vol(Bk(ε)) = k-d/2 vol(Sd-1) [	XdT () dx,
7[0,tanh √kε∕2]	∖1 - x J
and then changing coordinates x7→ tanh x, We obtain after applying several trigonometric identities
vol(Bk(ε)) = k-d/2 vol(Sd-1) [	2sinhd-1(2x) dx
J[0,√kε∕2]
k-d/2 vol
(SdT) /
J [0,√kε]
sinhd-1(x) dx,
Whence
vol(Bk(2r)) = R[o,2r√k] SinhdT(X) dχ
vol(Bk(ε/4))	R[0,ε√k∕4] SinhdT (X)dχ.
We have bounds x ≤ sinh x ≤ xex for nonnegative x,9 Which gives after integration
vol(Bk(2r)) ≤ R[0,2r√k] χd-1e(dT)X dx
VOI(Bk (ε∕4)) —	R[0,ε√k∕4] XdT dx
(2r√k)d R[0 1] χd-1e2r√k(d-1)χ dx
≤	(ε√k∕4)d
116re2r√k∖d
≤	—，
9The loWer bound is implied by cosh x ≥
e-2x) and using e-x ≥ 1 - x.
1; the upper bound folloWs from Writing sinh x = 0.5ex (1 -
66
Published as a conference paper at ICLR 2021
where in the second line We change coordinates X → (2r√k)χ, and then use L∞ control of the
(monotone increasing) integrand in the second line to move to the expression in the third line. □
Remark C.6. The constant CM in Lemma C.5 can be sharpened if more is known about the cur-
vature of M: if Ric ≥ 0, the exponential dependence on curvature and diameter can be removed
(intuitively, taking k & 0 “recovers” this from the proved result), and if Ric > 0, the dependence
on diameter can be completely removed using Myers’ theorem (Zhu, 1997, Theorem 3.4(1)).
Lemma C.7. For any x, x0, x, X0 in Sn0-1, one has
∣∠(x, x0) - ∠(X, X0)∣ ≤ √2∣kx - x0k2 - kx - X0k2∣.
Proof. Writing ∠(x, x0) = cos-1 hx, x0i = cos-1(1-(1/2)kx-x0k22), consider the function f(x)
cos-1(1 - (1∕2)x2) for X ∈ [-√2, √2], which is differentiable except possibly at 0. We calculate
f0(x)
X
sign X
q- 4 x2
and taking limits at 0 shows that f admits left and right derivatives on all of [-√2, √2]. f0 is even-
symmetric, so by checking values at 0 and √2 we conclude that |f 0∣ ≤ √2, which shows that f is
√2-Lipschitz. The claim follows.	□
Lemma C.8. Let d0 = 1. Choose L so that L ≥ Kκ2Cλ, where κ and Cλ are respectively
the curvature and global regularity constants defined in Section 2.1, and K, K0 > 0 are absolute
constants. Then
/	dμ∞ (x0)	Cρmaχ(len(M+) + len(M-))
x∈up± JM (1 + (L∕π)∠(x, X0))2 ≤	L	,
where C is an absolute constant and M± denotes either M+ or M-.
Proof. Recall that γ+, γ- denote unit-speed curves parameterized with respect to arc length whose
images are M+, M-. For convenience, define g(ν) = 1∕(1 + Lν∕π). We have
SUP R (g(∠(χ, XO)))2 dμ∞(χ0)
SUP / (g(∠(χ, χ0)))2 dμ∞(χ0) ≤ ^x∈m±m+	0	2	∞ 0	(Cs)
χ∈M±J	+ sup J (g(∠(x, x0))) dμ∞(x0).
M	x∈M± M-
First, we note that |g| is strictly decreasing. We claim that for any x ∈ M-, there is a x? ∈ M+
such that ∠(x?, x0) ≤ ∠(x, x0) for all x0 ∈ M+; it is easy to see this is the case by choosing x? to
achieve the minimum in minx0∈M+ ∠(x, x0) and arguing by contradiction. By monotonicity of the
integral, this implies
SUP
x∈M±
(g(∠(x, x0)))2
M+
dμ∞(x0) ≤
SUP	(g(∠(x, x0)))2
x∈M+
M+
dμ∞(x0),
(C.7)
and similarly for the term involving integration over M-. Therefore
SUP
x∈M±
(g(∠(x, x0)))
M
dμ∞(x0) ≤
sup R (g(∠(x, X0)))2 dμ∞(x0)
x∈M+ M+
+ sup R (g(∠(x, X0)))2 dμ∞(x0),
x∈M- M-
(C.8)
2
and it suffices to analyze these two terms. We bound the first term, since the second can be bounded
by an identical argument. By compactness, the supremum in this term is attained at some X ∈ M+ .
Taking t such that γ+(t) = X, we can write
sup
x∈M+
J； g(∠(X, X0))2 dμ∞(X0)
≤ ρmax
S+
g(∠(γ(t), γ(s)))2 ds.
(C.9)
0
67
Published as a conference paper at ICLR 2021
We split the interval [0, S+] into two disjoint sub-intervals [0, S+] ∩ [t - K"√L, t + K"√L] and
[0, S+] \ [t - KT/√L,t + KT/√L], corresponding to “large scale” and “small scale” behavior,
where Kλ is the global regularity constant defined in (A.2). If we now assume 圭 ≤ 震,then from
(A.2) we obtain
∠(x, x0) ≤ √^= ⇒ distM(x, χ0) ≤ √=
and hence
0	Kλ	0	1
distM(x, x0) > √= ⇒ ∠(x, x0) > √=.
From the definition of g it follows that
1
π
1 + √L∕π ≤ ~√L
Since |g| is a monotonically decreasing function we can bound the second integral in (C.9), obtaining
/
(g(∠(γ(s), Y(t*)))2 ds ≤ len(M+)C0/L.
(C.10)
s∈[0,S+]∖[t*-√√L ,t* + √√λ ]
We next consider the remaining interval of integration in (C.9). Defining
S++ = min
min
and ν±(s) = ∠(γ+ (t* ± s), γ+(t*)), the integral of interest can be written as
S++
Pmax	/	(g(∠(γ(s),γ(t*))))2 ds =	Pmaxj (g("+(s)))2 ds
S∈[0,S+]∩[t*-√√τ ,t* + √L ]	s = 0
(C.11)
S+-
+Pmax / (g(ν-(s)))2 ds.
s=0
It will be sufficient to consider the first integral here since the second one can be bounded in an
identical fashion. We aim to show that the integral above is not too large. This will be the case if
ν+(s) stays very small for a large range of values of s. To show that this is does not occur, we will
use our bounds on the curvature of M to bound ν+ (s) uniformly from below, which will in turn
provide an upper bound on the integral. We will require an application of Lemma C.9, which will
be applicable if S+ ≤ ∏. If L ≥ κ∏KKτ We have
S+ ≤ K ≤ -.
+ LL κ
It follows immediately that Lemma C.9 applies to any restriction of γ+ of length no larger than ∏.
Next define by Y : [0, S+] → Sn0-1 an unit-speed arc of curvature κ, and V(S) = ∠(γ(0), Y(s)).
We claim that
∀s ∈ [0, S++] :	ν+ (s) ≥ νV(s).	(C.12)
The proof is by contradiction. Assume there is some r such that
ν+ (r) < νV(r).	(C.13)
Now define by Yr : [0,r] → Sn0-1 a restriction of γ+ such that Yr (0) = γ+(t*), Yr (S) = γ+(t* +
s), by Yr an arc with curvature K and the same endpoints as Yr, and by Yr a restriction of Y with
len(YVr) = len(Yr ) = r.
Note that ∠(YVr(0), YVr(s)) = νV(r). However, an application of Lemma C.9 gives
len(Yr) ≤ len(Yr) < len(Yr)
68
Published as a conference paper at ICLR 2021
where the second inequality is because Yr and Yr have identical curvature at every point, and by
assumption (C.13) the endpoints of Yr are a greater geodesic (and hence euclidean) distance from
each other than the endpoints of Yr (which are a distance ν+(r) apart). This inequality contradicts
the equality above it, and we conclude that no such r exists, and (C.12) holds.
We have that |g | is a monotonically decreasing function, hence we can write for the first integral in
(C.11)
S++
(g(ν+(s)))2
s=0
S++
ds ≤ / (g(*(S)))2
s=0
dS.
We now bound this integral. Since Y is an arc with curvature κ, from the proof of Lemma C.3 We
have that V is concave, and since ν(0) = 0 We can write
νV(S) ≥
and since |g | is monotonically decreasing
叮S,
S+	,
S++
(g(νV(S)))2 dS
s=0
s+	ν(s+)
V(s+ )1 + LV(S+)∕∏
见S+)
S+
=VS+) J(g(S))2 ds
s=0
S++
≤∏
-LV(S+)
where we used the definition of g. It remains to show that S++ and νV(S++ ) are close. Since YV is an
arc with curvature κ and length S++, if we additionally assume L ≥ Kκ2Cλ for some K chosen so
that "⑼-J(S+)k2 ≤ 孚 ≤ 吟 ≤ 1 ,we obtain
2	2	2L 2
YV(0)-YV(S++)2 ≤S++
=2sin-ι (κ∣∣Y(0) -Y(S+)∣∣2!
2
≤ ∣∣Y(0)- Y(s+)∣∣2 + ZUY(O)- Y(s+)U3
HlY(O) - y(s+)∣∣2 - s+I≤ K UY(O) - y(s+ 升 2 ≤ K (s+ )3 ≤ κ2 K s+
4	4	4L
where in the first line we used sin-1(x) ≤ x + x3 for x. Since
UUYV(O)-YV(s++)UU2 ≤∠(YV(O),YV(s++))=νV(s++) ≤s++
we obtain
IV(S+)- s+∣≤ KKs+
and hence
s+	s+	1
-----；-、--------------- - --------.
V(S+) — S+ -竽KS+	1 -竽K
We now choose L ≥ Kκ2Kτ2 for some K, so that the above term is smaller than 2. We therefore
have
Si
/ (g(V(s)))2 ds ≤ C/L
s=0
for some C. We can bound the second integral in (C.11) in an identical fashion. Combining this
result with (C.10) and recalling (C.9), we obtain
sup
x∈M+
(g(∠(x, x0)))2
M+
dμ∞(x0) ≤ C0Pmax(len(M+)+len(M-))∕L
69
Published as a conference paper at ICLR 2021
for some constant, which completes the proof.
□
Lemma C.9. Given a smooth, simple open curve in Rn of length S with unit-speed parametrization
γ : [0, S] → Rn such that for some κ > 0
1.	kγl∣2 ≤ K
2.	S ≤ K
define by Y an arc of any circle of radius 1 such that Y(0) = γ(0), Y(S) = γ(S), S ≤ ∏ 10. We
then have
S ≤ S
Proof. This result is a generalization of a well known comparison theorem of Schur’s to higher
dimensions following the proof in (Sullivan, 2008), where we additionally specialize to the case
where one of the curves is an arc.
Given a curve Y satisfying the conditions of the lemma, We first consider an arc Y of a circle of
radius 1 and length S, with a unit-speed parametrization. At the midpoint of this arc, the tangent
vector Y0(S) is parallel to Y(S) 一 Y(0), hence
S
(2),/Y 0 ⑴dt).
0
kY(S)- Y(0)k2 =(Y 0( S), Y(S)- Y(0)
Similarly, for the curve Y we have
kY(S)- Y(0)k2 ≥(Y0(S), Y(S)-Y⑼)=*Y'(2), /Y0(t)dt+ .
Denoting the angle between tangent vectors hY0(a), Y0(b)i = Cos θ(a, b), we use the fact that for
any smooth curve with unit-speed parametrization kY00(t)k2 = I dθ (t,s)s=t I =∣θ0(t)∣. This gives
for any t ∈ [0, S/2]
Y0 (2),Y0( S+ t)) =Cos
≥ cos
≥ cos
(S+t	∖
/ θ0(t0)dt J
W	1
(2+t	∖
/ ∣θ0(t0)l dt0∣
2
TZtdt)=Cos
∖	2	/
cos
(S+t
/ kY00(t)∣2 dt0
∖ 2
S++t	'
/ kY00(t)∣2 dt0
∖ 2	.
Y 0( 2), Y 0( 2+1)
where we have used monotonicity of cos over the relevant range which is ensured by assumption 2,
and a similar argument follows for t ∈ (0, -S/2]. Combining these inequalities gives
kY(S) - Y(0)∣2 ≥kY(S)- Y(0)∣2.
We have shown that, unsurprisingly, if the curvature of Y is bounded and it is not too long, then the
distance between its endpoints is greater than that of a curve of equal length but larger curvature -
namely the arc Y. We now consider the arc Y defined in the lemma statement. If S > S, due to
assumption 2 this would imply
kY(S) - Y(0)k2 > 卜(S)- Y(0)∣2 = kY(S) - Y(0)∣2
. 1∙ . ∙	. 1 ♦	1 ∙ .	1 1	τ. ∕' 11	. C ， X
contradicting the inequality proved above. It follows that S ≤ S .
□
10For any circle and choice of endpoints there will be two such arcs, and the last condition implies that we
choose the shorter of the two.
70
Published as a conference paper at ICLR 2021
C.2.2 Analysis of the Skeleton
Notation. Define 夕⑼=Id, and for ' ∈ N define 夕(')as the '-fold composition of 夕 with itself,
where
夕(V) = cos-1 ((1 — π-1ν) cos V + π-1 Sin V)
is the heuristic angle evolution function. We will make use of basic properties of this function such
as smoothness (established in Lemma E.5) below. In this section, we will study the skeleton
L-1	L-1
ψι(ν) = 2 X cosd')(ν) Y (1 - π-1d'0)(ν)),	V ∈ [0,π],
乙 '=0	'0='
where we have not included the additive factor cos 夕(L) (V), as it is easily removed along the lines
of Theorem B.2. We define
L-1
ξ(')(V) = Y (1 - π-1 d()(V)),	' = 0,...,L - 1,
` ='
so that
L-1
Ψi(v) = 2 X cos d')(V)ξ(')(V).	(C.14)
'=0
We will also establish a convenient approximation to the skeleton. Define
L-1
Mv )=2 x u).
乙'=0
Lemma C.10 implies that ψ is convex; it is less trivial to obtain the same for ψ1. We will prove
several estimates below for the terms ξ(') and their derivatives that can be used to immediately
obtain useful estimates for ψ and its derivatives.
Lemma C.10. For each ' = 0,1,...,L, thefunCtions 夕(') are nonnegative, strictly increasing, and
Concave (positive and strictly Concave on (0, π)); if 0 ≤ ' < L, thefunCtionS ξ ⑶,are nonnegative,
strictly decreasing, and convex (positive and strictly convex on (0, π)).
Proof. These claims are a consequence of some general facts for smooth functions that we articulate
here so that we can rely on them often in the sequel. First, we have for any smooth function f :
(0, π) → R
(f ◦ f )0 = (f0 ◦ f )f0,
(f ◦ f )00 = (f0 ◦ f )f00 + (f0)2(f00 ◦ f).
These equations show that if f > 0, f0 > 0, and f00 < 0, then f ◦ f also satisfies these three
properties. Lemma E.5 shows that 夕 satisfies these three properties on (0, ∏); We conclude from the
mean value theorem and a simple induction the same for 夕('), as claimed. Meanwhile, if f, g are
smooth real-valued functions on (0, π), we have
(f g)0 = f0g + g0f,
(fg)00 = f00g + g00f + 2f0g0.
Thus, if f and g are both positive, strictly decreasing, strictly convex functions on (0, π), then fg
also satisfies these three properties. Lemma E.5 implies that 0 < 1 - ∏-1 夕(') < 1 on (0, ∏), and the
first and second derivatives are scaled and negated versions of those of 夕 ('); we conclude by another
induction that the same three properties apply to the functions ξ(').	□
Lemma C.11. There is an absolute constant C > 0 such that ifL ≥ 12 and n ≥ L, then one has
Cn
kψ1 - ψkL∞ ≤ ~L∙
71
Published as a conference paper at ICLR 2021
Proof. We have from the triangle inequality
kψι - ψkL∞ ≤ sup ](2 X∣cosd')(V) - 1∣ξ(')(V j
L-1
≤ 2 X SUp (∣cos 中⑻(V) - 1∣ξ(')(ν))
2 '=0 ν∈[0,π]
where We use Lemma C.10 to take ξ(') outside the absolute value. Notice that (CoS 夕(')一 1)ξ(') ≤
0, so to control the L∞ norm of this term it suffices to bound it from below. We will show the
monotonicity property
(CoS 芦 一 1)ξ⑶ 一(CoS d'+1) — 1)ξ('+1) ≥ 0,	(C.15)
from which it follows
kΨι 一 ΨkL∞ ≤ nL sup ∣cosdL-1)(ν) — 1∣,
2 ν∈[0,π]
using also ξ(L-1)(ν) ≤ 1. Since cosX ≥ 1 一 (1∕2)x2, and since Lemma C.12 gives that 夕(L-I) ≤
C/(L 一 1) (and also estimates the constant), we have as soon as L ≥ 1 + C/√2
kψ1 一 ψkL∞ ≤
C 2 nL
4(L 一 1)2
which gives the claim provided L ≥ 2and n ≥ L. So to conclude, we need only establish (C.15).
To this end, write the LHS of (C.15) as
(cos 夕⑶ - 1)ξ(') — (cos d'+1) - 1)ξ('+1) = (cos 夕⑶一CoS d'+1)) — —— (cos 夕⑶-1) ξ('+1)
π
to notice that it suffices to prove nonnegativity of the bracketed quantity. In addition, since ` ≥ 0
and —(V) ≤ V by Lemma E.5, we can instead prove the inequality
x
(cosX - cos —(x))-----(cosX - 1) ≥ 0
for all x ∈ [0, π]. Using the closed-form expression for cos —(x) in Lemma E.2, we can plug into
the previous inequality and cancel to get the equivalent inequality
X 一 sin X ≥ 0.
But this is immediate from the concavity estimate sin X ≤ x, and (C.15) is proved.	□
Lemma C.12. If ` ∈ N0, one has the “fluid” estimate for the angle evolution function
—⑶(V) ≤
V
1 + c'ν,
where c > 0 is an absolute constant. In particular, if' ∈ N one has —(') ≤ 1∕c'.
Proof. The second claim follows from the first claim and 1 + c'ν ≥ c£v, so we will focus on
establishing the first estimate. The proof is by induction on ` ∈ N, since the case of ` = 0 is
immediate. By Lemma E.5, there is a constant c1 > 0 such that —(V) ≤ V(1 一 c1V), and using the
numerical inequality X(1 一 X) ≤ X(1 + X)-1, valid for X ≥ 0, we get
—(V) ≤	,	(C.16)
1	+ c1 V
which establishes the claim in the case ` = 1. Assuming the claim holds for ` 一 1, we calculate
—(')(V) ≤	—(j) (V)	≤	Y-1)"
^ 1 + ci—('T)(V) - 1 + Clι+cι(Z-i)ν ,
where the first inequality uses (C.16), and the second inequality uses the induction hypothesis and
the relation X(1 + X)-1 = 1 一 (1 + X)-1 to see that X 7→ X(1 + c1X)-1 is increasing. Clearing
denominators in the numerator and denominator of the RHS of this last bound, we see that it is equal
to v∕(1 + 'v∕π), and the claim follows by induction.
□
72
Published as a conference paper at ICLR 2021
Lemma C.13. If ` ∈ N0, the iterated angle evolution function satisfies the estimate
d')(ν) ≥
ν
1 + 'ν∕π
Proof. The proof is by induction on ` ∈ N, since the case ` = 0 is immediate. The case ` = 1
follows from Lemma C.14. Assuming the claim holds for ` - 1, we calculate
H)(V) ≥
夕('-1)(ν)
-----------------≥-------
1 + φ('-1')(ν )∕π - 1 +
_____V_____
1+('-1)ν∕π
1 ____V_____
π 1+('-1)ν∕π
where the first inequality applies Lemma C.14, and the second uses the fact that the RHS of the
bound in Lemma C.14 is strictly increasing and the induction hypothesis. Clearing denominators in
the numerator and denominator of the RHS of this last bound, We see that it is equal to ν∕(1+ 'ν∕∏),
and the claim follows by induction.	□
Lemma C.14. It holds
ψ(ν) ≥
ν
1 + ν∕π
Proof. After some rearranging using Lemma E.2, it suffices to prove
1	- V) cos v + sinν ≤ cos (^nV-
π	π	π+ν
(C.17)
Using Lemma E.5, we see that both the LHS and RHS of this bound are nonincreasing. We will
prove the estimate in three stages, using “small angle”, “large angle”, and “intermediate angle”
estimates of the quantities on both sides of (C.17). Since πV∕(π + V) ∈ [0, π∕2], we can use
standard estimates for cos to get RHS estimates
cos
πV
π+V
2
πV
π + V)
(C.18)
≥
1
2
and
πV	π - V
CoS ---- ≥ ------
π+V	π+V
(C.19)
As for the LHS, we can obtain an estimate near V = π in a straightforward way. Transforming the
domain by V 7→ π - V, it suffices to get estimates on sinV - Vcos V near V = 0, then divide by π.
Using cos V ≥ 1 - (1∕2)V 2 and sinV ≤ V, it follows that sinV - Vcos V ≤ (1∕2)V 3. We conclude
cos v +Sinv ≤ -l(π - V)3.
π 2π
(C.20)
We will develop a second-order approximation to the LHS near 0 for the small-angle estimates. The
first, second, and third derivatives of the LHS are (1 - V∕π) sinV, (1∕π) sinV - (1 - V∕π) cos V,
and (2∕π) cos V + (1 - V∕π) sinV, respectively. To bound the third derivative, we will use the
estimate cos V ≤ 1 - V2∕3 on [0, π∕2]. To prove this, note that Taylor’s formula implies the bound
cos V ≤ 1 - V2∕3 on [0, cos-1(2∕3)]; because cos is concave on [0, π∕2], we also have the tangent
line bound cos(v) ≤ —v√5∕3 + (2∕3 + √5cos-1(2∕3)∕3) on [0, π∕2]. We can then solve for the
zeros of the quadratic polynomial 1 一 v2∕3 + (√5∕3)v 一 (2∕3 + √5cos-1(2∕3)∕3); a numerical
evaluation shows that both roots are real and outside the interval [cos-1(2∕3), π∕2]. Since the tangent
line touches the graph of cos at v = cos-1(2∕3), this proves that cos v ≤ 1 一 v2∕3 on [0, π∕2]. We
can therefore write
2	cos v + (π 一 v) sinv ≤ 2(1 一 v2∕3) + v(π 一 v),	v ∈ [0, π∕2].
The RHS of this inequality is a concave quadratic; we calculate its maximum analytically as 2 +
3π 2 ∕20. Meanwhile, if v ∈ [π∕2, π], we have 2cos v ≤ 0, and (π 一 v) sinv ≤ π∕2. We conclude
that (2∕π) cos v + (1 一 v∕π) sinv ≤ 2 + 3π2∕20 on [0, π]. Writing c = 1∕(3π) + π∕40, this implies
an estimate
2
(1 一 一) cos V + si— ≤ 1-+ cv3.	(C.21)
π	π2
73
Published as a conference paper at ICLR 2021
Finally, we will need some estimates for interpolating the small and large angle regimes. We note
that the second derivative (1∕π) sin V - (1 - ν∕π)cos V of the LHS of (C.17) is nonnegative if
V ≥ π∕2, because cos ≥ 0 here; meanwhile, the third derivative (2∕π) cos V +(1 — ν∕π) Sin V of
the LHS of (C.17) is nonnegative if 0 ≤ V ≤ n/2, since cos ≥ 0 here, and it follows that the second
derivative is increasing on [0,∏∕2]. Checking numerically that the value of the second derivative
at 1.42 is positive, we conclude that the LHS of (C.17) is convex on [1.42, π]. In addition, we use
calculus to evaluate the first and second derivative of the RHS of (C.18) as -v∏3∕(∏ + V)3 and
-π3(π - 2v)∕(π + V)4, respectively; this shows that the RHS of (C.18) is convex for V ≥ π∕2, and
concave for V ≤ n/2. Taking a tangent line to the graph of the RHS of (C.18) at n/2, it follows that
the function
(x) = 1 - (n2/2)V2/(n + V)2 x ≤ n/2
g	-(4n/27)V + (1 + n2/54) x ≥ n/2
(C.22)
is a concave lower bound for the RHS of (C.18) on [0, n].
We proceed to using the estimates developed in the previous paragraph to prove (C.17). We first
argue that for V in a neighborhood of 0, we have
1 - V2/2 + cV3 ≤ 1 - (n2/2)V2/(n + V)2,
which will in turn prove (C.17) in the same neighborhood. Cancelling and rearranging, it is equiva-
lent to show
(2/n - 2c) - (4c/n - 1/n2)V - (2c/n2)V2 ≥ 0.
The LHS is a concave quadratic, with value 2/n - 2c > 0 at 0; we calculate its two distinct roots
numerically as lying in the intervals [-5.1, -5] and [1.42, 1.43], respectively. It follows that (C.17)
holds for V ∈ [0, 1.42]. Next, we argue that for V in a neighborhood ofn, we have
1	3 n-V
(π- - V) ≤ 一:^,
2n	n + V
which will in turn prove (C.17) in the same neighborhood. Transforming with V 7→ n - V and
rearranging, it is equivalent to show V2(2n - V) ≤ 4n2 in a neighborhood of0. The LHS of this last
inequality is 0 at 0, and nonnegative on [0, n]; its first and second derivatives are V(4n - 3V) and
4n - 6V, respectively, which shows that it is a strictly increasing function of V on [0, n]. Verifying
numerically the three distinct real roots of V3 - 2nV2 + 1 = 0 and transferring the result back via
another transformation V 7→ n - V, we conclude that (C.17) holds on [n - 1.1, n]. To obtain that
(C.17) holds on [1.42, n - 1.1], we use that the function g defined in (C.22) is a concave lower bound
for the RHS of (C.18), so that it suffices to show that the LHS of (C.17) is upper bounded by g on
[1.42, n - 1.1]. The LHS of (C.17) is convex on [1.42, n], so it follows that it is sufficient to show
that the values of the LHS of (C.17) at 1.42 and at n - 1.1 are upper bounded by those of g at the
same points. Confirming this numerically, we can conclude the proof.
□
Lemma C.15. If ` ∈ N0, one has
卜 (')(V )1 ≤ 1 +(1/2)'V，
where c > 0 is the absolute constant also appearing in Lemma E.5 (property 4), and in particular
c/2 is equal to the absolute constant appearing in Lemma C.12. In particular, if` ∈ N and V ∈ [0, n]
we have the estimate
∣v*(V)∣ ≤ 号
Proof. The case of ' = 0 follows directly (as an equality) from 夕(0)(v) = V. Now We assume
' ∈ N. Smoothness of 夕(')follows from Lemma E.5. Applying the chain rule and an induction, we
have
`-1
9⑶=Q ◦ d'-1)) SCT)= γ 9 ◦ d'0),	(C.23)
'0=0
and applying the chain rule also gives
9(')=(9('T)) 2(9。9('T)) +(9('-1))(9 ”(`t) .	(C.24)
74
Published as a conference paper at ICLR 2021
By Lemma E.5, We have ° > 0 on [0,∏]), and the formula (C.23) then implies that °(') > 0 on
[0, π]) as Well. Considering only angles in this half-open interval and distributing, it folloWs
*
0 ◦ °('-1)
1
0 ◦ 0(
0 C	('-1) I	1
铲◦ 0	+070
一	°('-1)
^-I) (°('T))2
°(J)
J) (°('-1))2 .
Applying an induction using the previous formula and distributing in the result, we obtain
°⑶	_ X
港y=N
1
Q'-='0+1 ° ◦ °('00)
⅛ ◦ 0('0)
°2
(C.25)
By Lemma E.5, We have 0 < ° ≤ 1 on [0,∏) and 0 ≤ 0. Thus
—
'-1
≥ - X °。°(').
'0=0
When ' > 0, We have 0('0) ≤ n/2, and by Lemma E.5, we have ° ≤ -c < 0 on [0, ∏∕2]; thus,
-°。°('0) ≥ C if ' > 0. When ' = 0, we can use the fact that ° ≤ 0 on [0, ∏] to get a bound
° ≤ -c1[0,∏∕2]. Weconclude
°(')	、" r、 T
-(°('))2 ≥ c(' - I) + c⅜,∏∕2]∙
Next, We notice using the chain rule that
(C.26)
and using (C.23) and Lemma E.5, we have that °(`)(0) = 1. For any V ∈ [0, ∏), we integrate both
sides of (C.26) from 0 to ν to obtain using the fundamental theorem of calculus
1ν
°(') (V) - 1 ≥ c(' - I)V + CJQ 1[0,∏∕2]⑴ dt
=c(' — 1)ν + cmin{ν, π∕2}
c'ν
≥ F,
where in the final inequality we use the inequality min{V, π∕2} ≥ V∕2, valid for V ∈ [0, π]. Rear-
ranging, we conclude for any 0 ≤ V < π
°(') (ν) ≤
1
1 + (c∕2)'ν
and noting that the LHS of this bound is equal to 0 at V = π and the RHS is positive, we conclude
the claimed bound for every V ∈ [0, π]. The second estimate claimed follows by multiplying this
bound by V on both sides, and using 1 + (c∕2)'ν ≥ (c∕2)'ν.	□
Lemma C.16. If ` ∈ N, one has
Q)(V)1 ≤ i+⅛ν (1 + W log(I + (C/8)('- 1)V)),
where C > 0 is an absolute constant, and C > 0 is the absolute constant also appearing in
Lemma E.5 (property 4), and in particular C∕2 is equal to the absolute constant appearing in
Lemma C.12. If V ∈ [0, π], the RHS of this upper bound is a decreasing function of V, and moreover
we have the estimates
|°(')| ≤ C',
V 2°(')(V )∣≤ 1√C⅛
1 + ") ≤ 8πC +
Cn ) c c'
64C log '
-C2'-
75
Published as a conference paper at ICLR 2021
Proof. Smoothness follows from Lemma E.5; we make use of some results from the proof of
Lemma C.15, in particular (C.23) and (C.25). We treat the case of ` = 1 first. By Lemma E.5,
We have |0| ≤ C for an absolute constant C > 0, and since 1/(1 + (c∕2)ν) ≥ 1/(3/2) = 2/3 by
the numerical estimate of the absolute constant c > 0 in Lemma E.5, it follows
I0(ν )∣≤
3C/2
1 + (c/2)v
Which establishes the claim When ` = 1 (after Worst-casing constants if necessary). Next, We assume
' > 1. Multiplying both sides of (C.25) by (S('))2 and cancelling using (C.23), we obtain
..(')=X Q'-=0 Q")2 Si
S h Q'-=,+ISos(S(S。钟)2
'-1 / '0-1	2∖ ' '-1	∖
=X Y (S ◦ S('00))	Y S ◦ S('00) SWO	(C.27)
'0 = 0 ξ'00=0	' ∖'00='0 + 1	)
where the last equality holds at least on [0, π), by Lemmas E.5 and C.15, and where empty products
are defined to be 1. If ' > 0, we have S('0 ≤ n/2 and by Lemma E.5 we have that ∣S∣ ≤ C and
S ≥ C > 0 on [0, n/2] for absolute constants C, C0 > 0. Separating the ' = 0 summand, this gives
a bound
`-1	`-1
∣S(')∣ ≤ C Y S ◦ S('0) + C S(')X S⑺	(C.28)
V0 = 1	c c	'0 = 1
By Lemma C.15, we have S(V) ≤ 1/(1 + (c/2)v), and by Lemma E.5, we have S(V) ≤ V, hence
S(`0)(ν) ≤ ν. Using concavity of s, nonincreasingness of S and nondecreasingness of s('0) (which
follow from Lemma E.5) and a simple re-indexing, we can write
'-1 Y S ◦ S(')(V)= '0=1	'-2	'-2 二 Y S ◦ S(' +1)(ν) = Y S ◦ S(' ) ◦ s(v) '0=0	'0=0 '-2
≤ ∏ S(S('0)(v/2))
'0=0
=S ('-1)(v/2)
/	1
≤ 1 + (c/4)(' - 1)ν
1
≤ 1 + (c/8)'v
where the third-to-last line follows from (C.23), the second-to-last line follows from Lemma C.15,
and the last line follows from the inequality ` - 1 ≥ `/2 if ` ≥ 2. Following on from (C.28), we
conclude by an application of Lemma C.15
∣S(')(ν)∣ ≤ -C— + -C/c— X —1—
lS ( )∣ ≤ 1 + (c/8)'v + 1 + (c/2)'v E 1 + (c/2)'0v
< C 1	1 X 1	!
≤ c0 V + (c/8)'v '0=0 1 + (c/8)'0v),
where the last line simply worst-cases the constants. For any `0 ∈ N0, the function x 7→ 1/(1 +
(c/8)'0x) is nonincreasing, so we can estimate the sum in the previous statement using an integral,
76
Published as a conference paper at ICLR 2021
obtaining
k(') (V )1 ≤	CCd
丫 ( )1 ≤ 1 + (c∕8)'ν
≤	C∕c0
- 1 + (c∕8)'ν
'-1	1 八
------dx
1 + cν x
1 +11rlog(1 +(c/8)('-
(c∕8)ν
after evaluating the integral—we define the quantity inside the parentheses on the RHS of the final
inequality to be ` - 1 when ν = 0, which agrees with the integral representation in the previous line
and with the unique continuous extension of the function on (0, ∏] to [0, ∏]——which establishes the
first claim.
We now move on to the study of the bound we have derived. For decreasingness, we note that the
functions
C∕c0	1
V → 1 + (c∕8)'V ν→ 1+(C∕8> log(1 + (C/8)(' - I)V)，
(C.29)
whose product is equal to our upper bound, are evidently both smooth nonnegative functions of V at
least on (0, π], so that by the product rule for differentiable functions it suffices to prove that these
two functions are themselves decreasing functions of V. The first function is evidently decreasing
as an increasing affine reparameterization of V 7→ 1∕V; for the second function, after multiplying
by the constant ` - 1 and rescaling by a positive number (when ` = 1, the function is identically
zero on (0, π], and the function’s continuous extension as defined above equals 0 at 0 as well), we
observe that it suffices to prove that x 7→ x-1 log(1+x) is a decreasing function ofV on (0, ∞). The
derivative of this function is x 7→ (x - (1 + x) log(1 + x))∕(x2(1 + x)), so it suffices to show that
x - (1 + x) log(1 + x) ≤ 0. Noting that the function x 7→ xlogx is convex (its second derivative is
1∕x), it follows that x - (1 +x) log(1 +x) is concave as a sum of concave functions, and is therefore
has its graph majorized by its supporting hyperplanes; its derivative is equal to - log(1 + x), which
equals 0 at 0, and we therefore conclude from our previous reduction that the second function in
(C.29) is decreasing, and that our composite upper bound is as well. For the remaining estimates,
we use the concavity estimate log(1 + x) ≤ x to obtain from our previous result
…≤ "⅛ν ≤ C
since the function x 7→ C∕(1 + cx) is nonincreasing for any choice of the constants. Next, we use
the expression we have derived in the first claim to obtain
IV20⑶(V)1 ≤ 1 q CVaw (V + T‰ log(1 + (c/8)(' - I)V)).
I	I 1 + (c∕8)'V ∖	(c∕8)	)
For any K > 0, the function x 7→ x∕(1 + Kx) is nondecreasing, and using the numerical estimate
π(c∕8) < 1 that follows from Lemma E.5, We obtain in addition 1 + π(c∕8)(' _ 1) ≤ ' for ' ∈ N.
Thus
V20(')(V)∣ ≤---Cn ——(1 +
+ 「- 1 + (c∕8)'π V
8πC	64C log '
≤ -Cr + -c2' —,
as claimed.
□
Lemma C.17. One has for every ` ∈ {0, 1, . . . , L}
0(')(0)=0;	0(`)(0)=1;	0(')(0)=-3∏,
and for every ` ∈ [L]
0 (')(∏) = 0(')(∏) = 0.
Finally, we have 0(0)(π) = 1 and 0(0)(n) = 0.
77
Published as a conference paper at ICLR 2021
Proof. The claims are consequences of Lemma E.5 when ' = 1, and of 4⑼ =Id for smaller ';
assume ' > 1 below. The claim for 夕(')(0) follows from the fact that 夕(0) = 0 and induction. For
the claim about S(') (0), We calculate using the chain rule
S (')(0) = S(d'T)(0)2 CT)(0)
=S(0)S (J)(0)
=S (J)(0).
By induction and Lemma E.5, We obtain S(')(0) = 1. The claim about S(')(π) follows from the
same argument. For the remaining claims about S('), We calculate using the chain rule
S(')= (S ('T))2S ◦ S('T) +(S('T))S ◦ S('T),
whence
0(')(0) = 0(0)+ 0('T)(0).
Using Lemma E.5 to get 0(0) = -2∕(3π), this yields
*(0) = W.
Similarly, since we have shown S(`-1)(π) = 0, we obtain S(')(n) = 0.
□
Lemma C.18.
Forfirst and second derivatives of ξ('), one has
L-1
L-1
-π-1 ES也)∏ (1-∏-1S%')
and
(C.30)
L-1
-∏-1X
L-1
S) ∏ (1
'00='
.	' 00 =' 0
L-1
-1 Sf - ∏-1S ('0) X S ('")
` 00 ='
'0='
L-1
∏	(1-∏
-1s”
(C.31)
` ='

一π
'='
'0='
'”=20
'"='
'〃'='£〃='〃
where empty sums are interpreted as zero, and empty products as 1. In particular, one calculates
ξ⑶(0) = 1;
and
ξ(')(0) = - L-
π
ξ(')(0)
(L - 2)(L - ' - 1) L(L - 1) - '(2 - 1)
π2	+	3π2
ξ(0)(π)= 0;	ξ(')(∏) = -1 ξ(I) (∏)1'=0;	ξ(')(π) = 0.
π
Proof. The two derivative formulas are direct applications of the Leibniz rule to ξ⑶.The claims
about values at 0 follow from plugging the results of Lemma C.17 into our derivative formulas
and the definition of ξ('). For values at π, we first note that S(O) (∏) = ∏, from which it follows
ξ(0)(π) = 0. Next, we use Lemma C.17 to get that S(')(n) = 0 for all ' ∈ {0,1,..., L} and
S(')(π) = l'=0 to get ξ(')(π) = -π-1ξ(I)(π)1'=0. For ξ<')(π), we have
L-1
F') = π-2 X SN) X SI%)	∏	(1 - π-1S('000)(π))
'0='	`00='0	'000='00,'000='0
L-1
=π-21'=0 X S('0)(π)	∏	(1 - π-1S('000)(π)).
'0=1	'00='0,'00=0
If L = 1, the sum in the last expression is empty, and this quantity is 0. If L > 1, the sum is
nonempty, and every summand is equal to zero by Lemma C.17. We conclude ξ(`) (π) = 0.	□
78
Published as a conference paper at ICLR 2021
Lemma C.19. If L ≥ 3, there exists an absolute constant 0 < C ≤ π∕2 such that on the interval
[0, C], one has for every ` = 0, 1, . . . , L - 1
.ξ..(`) ≤ 0.
Proof. We consider functions only on [0, π∕2] in this proof. Following the calculations in the proof
of Lemma C.15, we have the expression
© °d'τ)y0	(C.32)
=(° ◦ d'-1)) .S.('-1) + 3 Q ◦ d'T)) S('-1)0('T) + (O ◦ d'-1)) G'-1))3 .	(C.33)
Using as well Lemma E.5, we have first and second derivative estimates
o ≤ S (') ≤ 1
and
-C2' ≤ S(') ≤ -c2'.
By Lemma E.5, .S.. extends to a continuous function on [0, π∕2], so in addition there exists a δ > 0
such that on [0, δ] we have
...	1
S ≥ - 2∏2	(C.34)
We lower bound (C.33) on [0, δ] using these estimates. For ` = 1, we can do no better than (C.34).
For ` > 1, we can write
S ◦ S('-1))	≥ (S ◦ s('-1)) 0('-1) + 3S('-1) ( (S ◦ S('-1)
≥ (S ◦ S('-1)) S.*1) + 3S('-1) ( c2(' - 1)
)S('-1) - 6⅛ (S(J))2
6∏2 ).
We have the numerical estimate c2 = 0.14 from Lemma E.5, and we check numerically that
(0.14)2 > 1∕6π2. This implies that on [0, δ] and for every ` ≥ 2, .S..(`) is lower bounded by a
positive number plus a scaled version of。('-1). We check precisely using the original formula
(C.33) and Lemma E.5 for ` = 2
S⑵(0) = 2S.(0)+3S(0)2 = 7⅛ > 0,
3π2
so that in particular
0(2)(0) + S(I)(O)=工 > 0.
3π2
By continuity, it follows that there is a neighborhood [0, δ0] on which we have .S..(2) + .S..(1) > 0.
Thus, on [0, min{δ, δ 0}], we guarantee that simultaneously
S(') > 0 if ' ≥ 2; S⑵ +。⑴ > 0.
Now We consider the third derivative of the skeleton SUmmandS ξ('). Following the calculations of
Lemmas C.10 and C.18, in particular applying the Leibniz rule, we observe that every term in the
sum defining ξ(') that does not involve a third derivative of one of the factors (1 - (1∕∏)S(`0))
will be nonpositive, because (1 - (1∕∏)S('0)) ≥ 0, S('0) ≥ 0, and S('0) ≤ 0. Meanwhile, by our
calculations above, on the interval [0, min{δ, δ 0}], the only terms that can be positive are those with
' =0 or ' = 1 where we differentiate the '0 = 1 factor three times, i.e., the '0 = 1 term in the sum
'0='
'00 ='
`00='0
L-1	L-1
-1X .S") Y
1
—
s('00)
π
79
Published as a conference paper at ICLR 2021
with ` = 0 or ` = 1. We will compare the `0 = 1 summand with the `0 = 2 summand: we have that
the sum of these two terms equals
—
1
π
∖
1 -三!
L-1
Y
'00='
∖'00 = 1,2
G(I-	)+泮—)).
(C.35)
/
At 0, the quantity inside the right parentheses is equal to φ + φ(2) > 0, by our calculations above.
Thus, by continuity, there is a possibly smaller δ00 > 0 such that on [0, δ00], the sum of terms (C.35)
is negative. We conclude that on [0, min{δ, δ0, δ00}], we have for every ` ≥ 0
.ξ..(`) ≤ 0,
and since we have chosen the neighborhood sizes δ, δ0 , δ00 independently of the depth L, we can
conclude.	□
Lemma C.20. For all ` ∈ {0, . . . , L - 1}, one has
ξ(')(ν) ≤ ⅛LV∕Π
Proof. We have
L-1
ξ(')(ν)= Y
'0='
L-'
(C.36)
where the first inequality applies the AM-GM inequality, and the second uses the standard exponen-
tial convexity estimate. Using Lemma C.13, we have
L-1
-X *(V) ≤
'0='
L-1
-
'0='
1 + '0ν∕π
Lν
≤-/ τ+^0ν∕πd',
ν
where the last inequality uses the fact that' → ν∕(1 + '0ν∕∏) is nonincreasing for every V ∈ [0, ∏]
together with a standard estimate from the integral test. We calculate
L V 0	1 + LV∕π
/ ETn d'= πlog(E∕∏)
which gives the claim after substituting into (C.36).	□
Lemma C.21. For all ` ∈ {0, . . . , L - 1}, one has
(V)| ≤ 3
L - '
1 + Lν∕π
Proof. Using Lemma C.18, we have
ξ⑴]	ξ⑶
----1'=0 ----
ππ
L-1
X
'0 = max{',1}
where we directly treat the case ` = 0 to avoid dividing by zero at V = π. The triangle inequality
and Lemmas E.5 and C.20 then give
∣ξ(')(ν)∣ ≤ 2(」/ 1'=0 + ξ(') (ν)	IX	中 C)(V) I .
π 1 + LV∕π
∖	'0 = max{',1}	)
80
Published as a conference paper at ICLR 2021
Using Lemma C.15, We have
L-1
L-1
∑>⑹(V) ≤∑
fL-\	1
L 1 + c'0V d',
'='
'='
1
1
1 + c' V _ 1 + c'ν +
where the last inequality uses the fact that' → 1/(1 + CCV) is nonincreasing for every V ∈ [0, π]
together With a standard estimate from the integral test. Evaluating the integral, We obtain
v ° W)(v ) ≤ -ɪ + Log (1+C(L —I)V),
() ≤ 1 + c'V + CV g V 1 + cCV ),
where the second term on the RHS is defined at V = 0 by continuity. Using the standard concavity
estimate log(1 + x) ≤ x, we have
ɪ log ( 1 + C(L — I)V ) =Ilog (1 + (L - ' - I)CV ) ≤ L 一 °- 1,
CV 1	1 + c°v J CV 1	1 + c°v J 1 + c°v ，
whence
Σ *)(ν) ≤ I
' ='
Combined with the result of Lemma C.20, we conclude
ξ(') (V) lT °例I(V) ≤ ɪ -4-^.
z—c	cπ 1 + Lν∕π
`='
The numerical estimate C = 0.07 in Lemma E.5 then allows us to conclude
(C.37)
M)(V)I
S]
≤
as claimed.
□
Lemma C.22. One has
IΨ1 (V )1
and
5nL2
1 + Lv∕π，
IΨ0 (V )I
(3∕2)nL2
1 + Lv∕π .
≤
≤
Proof. We calculate using the chain rule
L-1
Ψ1 = 2 V ξ⑶ cos ° ⑶一 ξ(')° (') sin °(2),
2 '=0
and the triangle inequality gives
L-1
IΨ1 i≤ n v∣m1+售”⑶
乙'=0
Applying Lemmas C.15, C.20 and C.21 and Lemma E.5 to estimate the constant c in Lemma C.15,
we then obtain
IΨ1 (ν )∣≤
L-1
2(1+ 1ν∕π) V 3(L-4) +
L-1
1 + 4ν∕π
1 + 4ν∕(5π)
n
2(1 + Lν∕π)
n
2(1 + Lν∕π)
5nL2
1+ Lν∕π.
£ 3(L - 4) + 1+4
2=0
∕3L2	Λ
⅛+5l
4ν∕(5π)
1 + 4ν∕(5π)
≤
≤
≤
The proof of the second claim is nearly identical, since in this case we need only use the bounds on
□
81
Published as a conference paper at ICLR 2021
Lemma C.23. There are absolute constants c,C > 0 such that for all' ∈ {0,...,L — 1}, one has
≤ CL(L — 4)(1 + Sg + C	(L - 4)2
一 (1 + CLV)2	(1 + CLV)(1 + c4ν)'
Proof. By Lemmas E.5 and C.18, we can write
L-1
X
'0=max{1,2}
(
L-1	.(,)	L-1	L-1
2ξ⑴ 1'=O X —+1)	X	X
'0 = 1 1---π~	'0=max{1,'} '00 = max{1,'}
∖	'0='
Focusing first on the second term, We have using Lemma E.5, (C.37) and Lemma C.20
L-1	.(`)	L-1	L-1
2d1*=0 X —+1) X X
'0 = 1 1-π~	'0=max{1,'} '00 = max{1,'}
'0='
L-1
≤4ξ⑴1'=o X中⑹
20 = 1
L-1	L-1
+ 41)	X X	中('%('").
'0=max{1,'} '00=max{1,'}
'0='
We can then write using nonnegativity
L-1 L-1
X X中⑺中(S
'=' '〃='
'0='
L-1 L-1
≤ XX 中 W M('")
"=''//='
and using (C.37) and Lemma C.20, we obtain thus
L-1	L-1	L-1
ξ(I)1'=o X 中W)+ ξ⑶	X	X	中WN('")≤
'0=1	'0 = max{1,'} '00=max{1,'}
'0 ='
3	(L - 4)2
cπ (1 + Lν∕π)(1 + c4ν)
Regarding the first term, we have using Lemma C.16
L-1	L-1
X l*) l≤ C X
'0='	'0='
4
1 + (c∕4)40ν
≤ C L(L - 4)
≤	1 + (c∕4)Lν,
—
1
ξ⑶
++π
π
*)
I -心
π
because the function 40 1 40/(1 + CCV) is nondecreasing. Applying also Lemma C.20, we obtain
using the triangle inequality and worst-casing constants
∣ξ∙(') I ≤ C L(L -4)(1 + 4ν∕π) + C	(L - 4)2
I I - 1	(1 + CLV)2	2 (1 + cLν)(1 + c4ν).
□
Lemma C.24. One has
lΨ10(ν )∣≤
CnL3
1 + cLν，
and
∣ψ00(ν )∣≤
CnL3
1 + cLν，
where c, C > 0 are absolute constants.
82
Published as a conference paper at ICLR 2021
Proof. We calculate using the chain rule
L-1	2
Ψ10 = 2 X N) cos d') - 2ξ⑶S⑶Sin ^⑶-ξ⑶0⑶Sin芦-g Q⑶)Cos中⑻,
2 '=0
and the triangle inequality gives
L-1	2
M ≤ 2 X £⑶+2代叩⑶+ξ(I川+ξ⑶G⑶).
'=0
Using Lemmas C.15, C.16, C.20, C.21 and C.23 and worst-casing constants for convenience, we
obtain from the last estimate
L-1
lψ10(ν)| ≤ CnX
'=0
L(L-')(1+'ν∕π) +	(L-')2
(1+cLν)2	+(1 + cLν)(1+c'ν)
_______L-'_______|_ 1+'ν∕π (	1
(1+Lν∕π)(1+c'ν)十 1+Lν∕π y (1+c'ν)2
CnL3
≤ ------,
- 1 + CLV
where in the second line we made some estimates along the lines of the proof of Lemma C.22 and
worsened the constant C. The proof for ψ follows from the same argument, since in this case we
have the same sum of ξ(') terms but none of the extra residuals.	□
D Concentration at Initialization
D. 1 Notation and Framework
We recall the expression for the neural tangent kernel, as summarized in Appendix A.5.2:
θ(x, χ0) = D fθo(x), v fθo (χ0 )E
L-1
= αL(x), αL(x0) + Xα'(x), α'(x0)β'(x), β'(x0),
'=0
The objective of this section is to establish supporting results for the proof of Theorem B.2, which
gives uniform concentration of Θ(x, x0) over M × M around the deterministic skeleton kernel. We
take a pointwise-uniformize approach to proving this result: Appendix D.2 establishes concentration
results for the constituents of Θ(x, x0) when x, x0 are fixed, and Appendix D.3 develops results that
control the number of local support changes near points in a discretization of M × M in order
to provide a suitable stand-in for the continuity properties necessary to uniformize these pointwise
results. We collect relevant technical results and their proofs in Appendix D.4.
D.2 Pointwise Concentration
We fix (x, x0 ) in this section, and generally suppress notation involving the specific points for con-
cision. We separate our analysis into two distinct sub-problems: “forward concentration”, which
consists of the study of the correlations hα'(x), α'(x0)i, and “backward concentration”, which
consists of the study of the backward feature correlations hβ'(x), β'(x0)i. Forward concentration
is a prerequisite of our approach to backward concentration, so we begin there.
D.2.1 Forward Concentration
Notation. For ` = 0, 1, . . . , L, define random variables z1' = kα'(x)k2 and z2' = kα'(x0)k2.
With the convention 0 ∙ +∞ = 0, We define for ' = 0,...,L, random variables ν` by
'	-1	α'(x)	α'(x0)
V = CoS V1z'>01z'>0∖ kα'(x)k2 , kα'(χ0)k2 / - 1{z'=0}∪{z'=0}).
These definitions guarantee that ν' = π Whenever either feature norm zi' vanishes. These random
variables are significant toWard controlling Θ(x, x0) because, for each `
hα'(x), α'(x0)i = z1'z2' CoS V'.
83
Published as a conference paper at ICLR 2021
Let us define pairs of gaussian vectors g', g' 〜i.i.d. N(0, (2∕n)I) that are independent of every-
thing else in the problem. For ' ≥ 1, we have by rotational invariance of the Gaussian distribution
and the probability chain rule
z' =IIWaJ(x)]J = ∣ ∣[g1 LMτ.
Since a0(x) =x and ∣∣x∣∣2 = 1, we have by an induction with analogous definitions
`
z' = Π
20 = 1
⑷+
Similarly, we have
'
z2 = ∏
20 = 1
⑷十
As for the angles, we have by rotational invariance
z2z2 = ∣∣ [W2ɑ2-1(x)] + ∣∣2∣∣[W2α2-1(x0)] + ∣∣2
=∣∣ [g2 ]+∣∣2∣∣ Wicos ν 2-1 + g2 Sin /-I [就-乜2-1,
so that an inductive argument gives
z2z2 = (∏ ㈤十)(∏ [gfcosVj+a2sin∕τ]
We will write
2
苕=∏
20 = 1
2
z2 = ∏
20=1
[gf cos ν20-1
+ gf sin v2°-1] +
肛
2
and similarly
/ [g2] +	[g2 cos V2-1 + g2 sin v2-1]十	∖
,ziz2>0∖∣∣[g2 ] + ∣∣2，∣∣[g2 cos v2-1 + g2 sin v 2-1] + ∣∣2/	{Z1=0}∪{Z2=0}
so that we obtain for the angles by a similar inductive argument
V2 = P2.
(D.1)
For technical reasons, it will be convenient to consider an auxiliary angle process, defined for ' ≥ 1
as
- -ι ( f 2 2)/ [g1]+ 团cosv2-1 + g2Sin"-1]+ ∖1
「 91 92 ∖ ∣∣[g2] + H2，∣∣Cg2cosVeT + a2Sin21] + ∣∣2),
where we define with notation from Appendix E.1
E= ∩ {(91, g2) I ∀V ∈ [0, 2π],1 ≤ Mn]∖{i}[g1 cos V + g? sin v]+∣∣2 ≤ 2∣,
i∈[n]
and V0 = V0 = (x, x0〉. We then observe
(D.2)
22
∏ 除(g2,g20)≤ ∏ q'>0,
20=1	20=1
since the inductive structure of P，implies that all feature norms are nonvanishing if and only if
the top-level feature norms PL are nonvanishing, and since the statement Q20=11ε(g2, g2) = 1
84
Published as a conference paper at ICLR 2021
implies by definition that zL ≥ 2-L and zL ≥ 2-L. By Lemma E.16, as long as n ≥ 21 the event
E has overwhelming probability, and in particular a union bound implies
``
PY
1z' z' >0 = 1 ≥P Y 1e (g10, g20) =1 ≥ 1 - CLe-cn,	(D.3)
£=1	」	L'0 = 1	.
so that
P[∀' = 1, 2,...,L,^' =叫 ≥ 1 - CLe-cn.	(D.4)
We can therefore pass from ν' to ^' with negligible error.
From the expression for ^', We see that the angles ^0 → ^1 → ∙∙∙ → VL form a Markov chain,
and we will control them using martingale techniques. For ' = 0,1,...,L, we write F' to denote
the σ-algebra generated by the gaussian vectors (g1, g21, g12, g22,..., g', g2), so that (F0,..., FL)
is a filtration, and the sequences of random variables (V1,..., VL) and (ν1,..., VL) are adapted to
(F1 , . . . , FL ). Moreover, with these definitions we have
E[^' I F'-1] = 0(^'-1),
where @ is the angle evolution function defined in Appendix E.1, which is well-approximated by the
function
(see Lemmas E.1 and E.2). In the sequel, we will employ the notation 夕(')to denote the '-fold
composition of 夕 with itself. By Lemma E.5, the function 夕 is smooth, and the chain rule implies
the same for 夕(');we will employ the notation S(') and 0(')for the first and second derivatives of
夕('), respectively.
Main results.
Lemma D.1. There are absolute constants c, C, C0 > 0 and absolute constants K, K 0 > 0 such
that for any d ≥ K, if n ≥ K0 max{1, d4 log4 n, d3 L log3 n} then one has for any ` = 1, . . . , L
P
∣(α'(x), α'(x0)) — cos0(')(∠(x, x0))∣
> C d3' log3 n
n
≤ C0n-cd.
Proof. We have
(α'(x), α'(x0)> = z'z' cos V',
and the triangle inequality (applied twice) then yields
∣(α'(x), α'(x0)> — cos s(')(V0)∣ ≤ ∣cos v'∣ ∣z'ZzI — 11 + ∣cos v' — cos 0⑶(V(O
≤∣z'∣∣z'- 1∣ + ∣z' - 1∣ + ∣ν' - 0(')(ν0)∣,
where we also use |cos| ≤ 1 and that cos is 1-Lipschitz. Since z' = Zi for i = 1,2, we obtain using
Lemma D.2 and the choice n ≥ KdL
P
∣z'-
1∣ > C
C 0'e-d,
and as long as n ≥ C2dL, we obtain on one of the same events
P[z' ≤ 2] ≥ 1 - C0'e-d.
By a union bound, we obtain
P
∣z'∣∣z' - 1∣ + ∣z' - 1∣ ≤ 3C
≥ 1 - 2C0'e-d,
85
Published as a conference paper at ICLR 2021
so that if we put d0 = dlog n and therefore choose n ≥ C2dL log n, we have
P ∣z'∣∣z' - 1∣ + ∣z' - 1∣ ≤ 3C'dlogn ≥ 1 - 2C04n-d ≥ 1 - 2C0n-d,
with the second bound holding if d≥ 1 and n ≥ L. For the remaining term, we have by the triangle
inequality
∣ν' - *(ν0)∣≤∣ν'- ^'∣ + ∣V'-*(ν0)∣.
By (D.4), the first term on the RHS of the previous expression is equal to zero with probability at
least 1 - CLe-cn as long as n ≥ 21. The second term can be controlled with Lemma D.3 provided
we select n, L, dto satisfy the hypotheses of that lemma. We thus obtain via an additional union
bound
P ∣(α'(x), α'(x0)) - cos d')(ν0)∣ > 3cJ d log n + C0 ^d logɜ n I ≤ C 00n-cd+C 0004e-c0n
If n ≥ (2∕c0)lοg L and n ≥ (2c∕c0)dlog n, We have C00n-cd + C0"'e-c0n ≤ (C00 + C000)n-cd.
The previous bound then becomes
P ∣(α'(x), α'3)>-cos d')(ν0)∣ > 3C /^ + C C jd3⅛^ | ≤ (C 〃 + C C”…
and if We Worst-case the dependence on ` and din the residual in the previous bound, We obtain
∣(α'(x),α'(XO)〉-
cos*(ν0)∣> (3C + C0) jd3^
≤ (C00 + C000)n-cd,
as claimed.
Lemma D.2. There are absolute constants c, C, C0 > 0 and an absolute constant K > 0 such that
for i = 1, 2, every ` = 1, . . . , L, and any d> 0, if n ≥ max{K d`, 4}, then one has
∣z' - 1∣>C 山 ≤C …
Proof. Because z' == z`, it suffices to show
`
-1+ Y	[g，i
'0 = 1
>C
C 0IeTcd
(D.5)
The proof will proceed by showing concentration of the squared quantity Q'o=ι
[g10]+
2
around
2
1, so that we can appeal to results like Lemma D.26, and then conclude by applying an inequality for
the square root to pass to the actual quantity of interest. To enter the setting of Lemma D.26, it makes
sense to normalize the factors in the product by their degree, but we must avoid dividing by zero. We
have Q'o=1 [g'L
0, we can write
=0 if and only if Q'0=1
0
`
Y	[gi0i
'0 = 1
`
2= Y [g'0i
2 V0=1
hg'0i+
2	1/2
=0, and whenever Q'o=ι
2
+
2
hg'0i+
6=
2
(D.6)
(D.7)
P
P
P
+
Y n
0 = 1

+
2
□
86
Published as a conference paper at ICLR 2021
using 0-homogeneity of the '0 “norm”. This leads to an extra product-of-degrees term; We will make
use of Lemma D.27 to show that the product of degrees itself concentrates. We will also show that
the event where a degree is zero is extremely unlikely and proceed with the degree-normalized main
term by conditioning. By symmetry, the random variables ∣∣ [gf]十 ∣∣0 are i.i.d. sums of n Bernoulli
random variables with rate 11. By Lemma G.1, we then have
HMf] + B0 <n/2-t] ≤ e-2t"
and so
⑷+
P ∃'0∈{1,...,'} ：	∖g(∖
P min
f0 = 1,...,f
< n/2 — t
0
+
< n/2 — t
0
≤'p[ I ∣[gf] + ∣∣0<n∕2 - t] ≤ 'e-2t”
where the first inequality applies a union bound. Putting t = n∕4, we conclude
P
min
f0 = 1,...,f
㈤+
< n/4 ≤ 'e-n∕8,
0
so that whenever n ≥ 16log ', we have ∣∣ Igf] ∣∣0 ≥ n/4 for every C ≤ ' with probability at least
1 - e-n/16. This gives us enough to begin working on showing concentration of the squared version
of (D.5): partitioning, we can use the previous simplified bound to write
一	f
P -1+ ∏	[gf0 ]
,	f0 = 1
2

(D.8)
+
2
≤ e-n/16 + P
min
f0 = 1,...,f
㈤+
f
≥ n/4, -1+ ∏ [gf,]
(D.9)
f0 = 1
0
+
2
2
Using (D.7) and the triangle inequality, we can write whenever no terms in the product vanish
`
-1+ ∏ [gf0 ]
f0 = 1
(YL nBLII0)
`
Y
f0 = 1
P [gf]+∣∣
(YL n∣M+II0)
(YL m]+Ij
`
Y
f0 = 1
-1
1
P [gf,]+
-1
-1
(D.10)
+
2
2
≤
+
1
Moreover, we have by Lemma D.27
f
P -1 +
∏ n [gf0 ]
cd
f0 = 1
n
+
0
as long as n ≥ 128d2. Choosing in addition n ≥ 4d' and using nonnegativity, this implies
f
P
∏ 2 [g10 ]
> 2 ≤ 4'e-cd
f0 = 1
+
0
occurring on the same event. Combining the previous two bounds with (D.10) and (D.9) via another
partition, we get
一	`
P -1+ ∏
,	f0=1
㈤+
> C
e-n/16 + 4'e-cd
2
2
mine=1,...,f
+P
[g1+
≥ n/4,
0
-1 + Qi
> (C/2 + 2)qf ，
(D.11)
1
E+
2
2
87
Published as a conference paper at ICLR 2021
where we use here that on the event {mine=ι,…,` ∣∣ [g'] ∣∣o ≥ n/4}, the quantity Q'0=1
[g'0] +
is nonzero almost surely, which allowed us to invoke the identities (D.7). For (k1, . . . , k`) ∈ [n]`,
We define events Ek1,..., Ek by
Conditioning and then relaxing the bounds, we can write
min
'0 = 1,…,`
㈤+
≤XP
(k1,...,kk)∈[n]k
k'0 ≥dn∕4e
-1 + Q'o
≥ n/4, -1 +
0
1
`
`
Y
'0 = 1
P2 [g'0]
k1	k`
1 ,..., `
Conditioned on	Ek1,..., Ekk
Q'o=ιkPf [g'0i+k2∕kPf [g'0i+k
with	k`0
0,	the random variable
0 is distributed as a product of independent degree-normalized
standard χ2 random variables with minimum
Lemma D.26 then yields immediately
degree min{kι,...,k'}.	An application of
`
-	1 + Y
'0 = 1
1
ρ2 [gi0]+
+
2
`
-1 + Y
'0 = 1
>	C 0∖ I-
n
≤ C00'e-cd
as long as n ≥ K00 d', whence
min
'0 = 1,…,`
ML
≥ n/4,
0
>	C 0∖ I-
n
P
P
P
2
2
1
1
>
PwO
`
2
2
≤ C00'e-cd
Combining this previous bound with (D.11) yields
`
P -1+ Y	[g'0i
,	'0 = 1
>C
e-n/16 + C 0'e-cd
2
+
2
where We worst-cased constants in the probability bound. If We choose n ≥ 4C2 *d', we have
C ,d'/n ≤ 1/2, and We obtain on the event in the previous bound
`
P -1+ Y	[g]
,	'0=1
1
> 2
2
+
≤ e-n/16 + C0'e-cd
2
In particular, on the complement of the event in the previous bound, the product lies in [1/2, 3/2].
To conclude, we can linearize the square root near 1 to obtain an analogous bound for the product
of the norms. Taylor expansion of the smooth function x 7→ x1/2 about the point 1 gives
√x - 1 = 2(χ -I) - 8 k-3/2 (χ -I)2,
where k lies between X and 1. In particular, if X ≥ 2, we have
2(X -I) - √2 (χ -I)2 ≤ √χ -1 ≤ 2(X -I),
so that
(√χ -I) - 2(X -I) ≤ √2(x -I)2.
88
Published as a conference paper at ICLR 2021
Thus, when X ≥ 2 We have by the triangle inequality
∣√x- 1| ≤ √2(X -1)2 + 2|x - 1|.
from which we conclude based on a partition and our previous choices of large n
`
P -1+ Y	[g'0i
,	'0 = 1
+
2
> 20yd'] ≤ 2e-n/16 + 2C0'e-cd
which yields the claimed probability bound when n ≥ 16d.
□
Lemma D.3. There are absolute constants c, C, C0 > 0 and absolute constants K, K0 > 0 such
that for any Lmax ∈ N and anyd ≥ K, if n ≥ K0 max{1, d4 log4 n,d3Lmax log3 n}, then one has
P ∃L ∈ [Lmax]
∣VL - dL)(ν0)∣ > Co jd3 InL n	≤ CnYd
(D.12)
Proof. The proof uses a recursive construction involving L∈ [Lmax]. Before beginning the main
argument, we will define the key quantities that appear and enforce bounds on the parameters to
obtain certain estimates. For each L∈ [Lmax], we define the event
El1—L)(V 0)∣>Co ∕d3⅛P
where C0 > 0 is an absolute constant whose value we will specify below, so that EL ∈ FL, and our
task is to produce an appropriate measure bound on SL∈[L ] EL. For notational convenience, we
also define Eo = 0. For each L ∈ [Lmax] and each ' ∈ [L], we define
∆L =q(LT)(^')-产-'+I)(^'-1),
so that for every L, ∆1L, . . . , ∆LL is adapted to the sequence F1, . . . , FL, and we have the decom-
position
L
VL - N)(V0) = X ∆L.
'=1
In particular, we have
EL={∣x “COsdil
The sequences (Δl')'∈l are not quite martingale difference sequences, but we will show they are
very nearly so: writing
∆L = (∆L - E[∆L ∣ F'-1])+E[∆L ∣ F'-1],
|
^{z
∆ L
}
we have that (∆L)'∈l is a martingale difference sequence, which can be controlled using trun-
cation and martingale techniques, and the extra conditional expectation term can be controlled
analytically. In particular, we have the following estimates: by Lemma D.24, we have if n ≥
max{Kι log4 n, K2Lmaχ} that for every L ∈ [Lmaχ] and every ' ∈ [L]
∣E[∆L∣F'-1]∣ ≤ Cil0gn	；：；	1 (1 + log L) + C =；	(D.13)
I l 1 n 1 + (co∕64)(L — ')^' 1	n2
by the first result in Lemma D.25 we have for every d ≥ max{K3, 6/c1} that if n ≥ K4d4 log4 n,
then for every L ∈ [Lmax] and every ` ∈ [L] (and after worsening constants)
p]∣δl∣ > 2。3不 1 + a/6：； - ')V'-1 + 2C2 ∣F'-1# ≤ C5n-c1 d；	(D.14)
89
Published as a conference paper at ICLR 2021
and by the second result in Lemma D.25, we have by our previous choices of n, d, and Lmax that
for every L ∈ [Lmax] and every ` ∈ [L] (after worsening constants)
Eh(∆L)2∣F'τi ≤ 4C3H
ν'-1
1 + (co∕64)(L - ')V'-1
2 + C4.
(D.15)
The main line of the argument will consist of showing that a measure bound of the form (D.12) on
S'∈[l-i] E' implies one of the same form on U'∈[l] E'. For any L ∈ [Lmax], on the event EL We
have
VL ≤ dL)(^0) + C0i∣^0g3n
nL
V 2	I d3 log3 n
≤ 标+C0V ~^r~
3
≤ -亍,
c0L
(D.16)
Where the second inequality folloWs from Lemma C.12, and the third folloWs from the choice n ≥
(C0c0)2d3L log3 n. In particular, if We make the choice n ≥ (C0c0)2d3Lmax log3 n, We have
(D.16) on ELc for every L ∈ [Lmax]. Accordingly, for every L ∈ [Lmax] and every ` ∈ [L] We define
truncation events GL by
GL = ( M ≤ 2C3严①…/6；'-；	+ 2⅞" E'-1.	(D.17)
I 1	1	V n 1 + (co∕64)(L — ')^' 1	n2
We have GL ∈ F', and a union bound and (D.14) imply
c
PlurL
FL-1
≤ C5Ln-c1d + P U	E'0 FL
.'0∈[L-1]
-1
=c5Ln-c1d + 1S'O∈[L-1]E'0,
where the second line uses the fact that E' ∈ F J In particular, taking expectations recovers
∩GL
.'∈[L]
≤ C5Ln-c1d + P U	E'o .
'0∈[L-1]
(D.18)
In addition, by (D.16) we have on Ec-I
ν'-1
1 + (co∕64)(L - ')V'-1 ≤
c0 (` - 1) + (3∕64)(L - `)
co (3∕64)L + (61/64)' - 1
64
co(L - 1)
128
coL,
where the final inequality requires L ≥ 2. Thus, when L ≥ 2, we have on GL that
M≤ 25≡ K+2C2
512C3	d log n
(D.19)
c0
~"{Z
2K0
nL2 ,
P
≤
3
3
1
1
≤
≤
90
Published as a conference paper at ICLR 2021
where the final inequality holds when d ≥
L ≥ 2, on E'-ι we have by (D.15)
1 and n ≥ (。2。0/128。3)2/3L2/3. Similarly, when
山l)[f「黑十C4
217C2 dlog n _ 2 κ2 dlog n
≤ -C0-^F	K0 ^L^
(D.20)
where the second inequality holds when d ≥ 1 and n ≥ (C402∕217C2)1∕3L2/3; and in the same
setting we have by (D.13)
∣E[∆L I 尸-1]∣≤
≤
128Cι (1 + log L) log n	C2
co	nL	n2
256Cι (1 + log L) log n
co	nL ，
(D.21)
where the second inequality holds when n ≥ (C2c0∕128C1)L. In particular, if we enforce these
conditions with LmaX in place of L, we have that (D.19) to (D.21) hold for all 2 ≤ L ≤ LmaX (with
(D.20) and (D.21) holding on Ec_1).
We begin the recursive construction. We will enforce Co = max{4πC3, 6K0} for the absolute
constant in the definition of e`. The main tool is the elementary identity
P
U Ee
'∈[L]
U e` + P EL ∩ ∩ E：
'∈ [L — 1]
'∈ [L — 1]
(D.22)
P
which allows us to leverage an inductive argument provided we can control P[El ∩ ∩'∈[l—1] ElC],
the probability that the L-th angle deviates above its nominal value subject to all prior angles being
controlled. The case L = 1 can be addressed directly: (D.14) gives
P ∣ ∆11 > 2πC3
2C2
n2
≤ C5n-cιd
and as long as d ≥ 1 and n ≥ (C2∕πC3)2/3, this implies
P ∆11
,「 Idlog n
> 4πC3V 丁
≤ C5n—cιd
(D.23)
This gives a suitable measure bound on E1, after choosing d ≥ 1 and n ≥ e so that d3 log3 n ≥
d log n. We now assume L ≥ 2. By the triangle inequality, we have
L
L
L
X ∆L ≤
e=1
and we therefore have for any t > 0
p∣{∣x δl
≤P
∑∆ L +∑ ∣e[δL∣f"1]∣ ,
(D.24)
2=1
2=1
>t}
'∈ [L — 1]
L
∑∆ L +∑ ∣ e[δL∣ 尸—1]|
2=1
P 1∩'∈[L-1]EC
e=1
L
X ∆ L +1∩
e=1
∣'∈[L-1]
∣>“∩	∩ E
' e∈[L—1]
L
空 X ∣ e[δl∣fe-1]∣>t
e=1	.
(D.25)
∩
∩空
L
By (D.21), we have
1∩g∈[L-1]
L
空 X ∣e[δL∣f'T]∣≤
2=1
256C1 (1 + log L) log n
c0
(D.26)
n
91
Published as a conference paper at ICLR 2021
For the remaining term, we have by the triangle inequality
E
-
1
eL
△
E
.
πj
g
卫"
∆llʃ
]
1
-
eF

By (D.17), an integration of (D.14), and a union bound, We have
-	L	-
P 1∩'e[L-11EcΣ δL - 故1 冤 > 0
,	2=1	.
≤ P
u)
∕∈[L] I
I ∆L I > 2C3
/ d log n	VeT
∖^+ l + (c0∕64)(L - OwT
(D.28)
≤ C5Ln-。，
and We have
L
X E [∆L% ∣F'T] - E[∆L∣F'T]
e=ι
L
≤ X e[ I δL I 1M)c∣FJ]
e=ι
≤ πC5Ln~c1d + π E I%,
e=ι
where the first line uses linearity of the conditional expectation and the triangle inequality for sums
and for the integral; the second line uses the worst-case bound of π on the magnitude of the incre-
ments ∆L; the third line uses (D.17); and the fourth line uses a union bound, Ee-1 ∈ Fe-1, and
(D.14). Multiplying both sides of the final bound by 1Te[j.耳 EC, we conclude
L
1∩'∈[ L-IlEc X E [δL1 冤 IFeτ] - e[δL I FeT] ≤ 1∩'∈[ J1E”C5Lnfd ≤ ∏C5 Ln-C1d.
e=ι
(D.29)
For the remaining term in (D.27), we first observe
e](δL% -e[δL1g' Ife-1])2 FeT ≤e[(δL)2 1 冤 IFeTi
≤ e[n)]f`t],
where the first line uses the centering property of the L2 norm, and the second line uses (∆L)2 ≥ 0
to drop the indicator for GL. For notational simplicity, we define
L
VL = X E
冤-E [δL1 兆 i FeT])
Fe-1 ,
e=ι
so that our previous bound and (D.20) imply
∩空U
e∈ [L—1]
≤ 2K2 号
nL
92
Published as a conference paper at ICLR 2021
This implies that for any t > 0
'∩g∈ [L-1] Ec
L
X ∆L1 冤-e [∆L% |f'—1]
2=1
pMH∩]
L
X ∆L% - E [∆L1 冤 F-1]
2=1
>t)j
≤ P
X∆L%-E禺% IFeTi|>,#.
P
> t
The previous term can be controlled using Lemma G.5 and (D.19):
因％但 Ti>t}]
P
L
X ∆L1 窕一E
2=1
≤ 2 exp —
t2∕2
2K2 普 十 (2Ko∕3)t∕⅞∣n广
Setting t = 3Ko Jd3 log3 n∕nL, we obtain
^^∩g∈[L-1] Ec
2=1
/ 0	9 9 d2 log2 n
≤ 2 exp I---------ʃj---
—	4 I 4 1+ d log n
∖ ɪ 1	Ll
≤ 2n—(9/8)d,
L
X ∆L1 光-E[∆Lιei IF'-1]
> 3孙三
nL
(D.30)
P
where the last line uses the bounds L ≥ 1 and dlogn∕(1 + dlogn) ≥ 2 if d ≥ 1 and n ≥ e.
Combining (D.28) to (D.30) in (D.27) via a union bound, we obtain
P
'∩g∈[L-i] Ec
L
X ∆ L > 3Ko
2=1
l∕d3^≠ + πC5Ln-cι ’
nL
≤ CsLn-cιd + 2n-(9∕8)d.
Applying this result and (D.26) to (D.25) via a union bound, We obtain
P
L
X∆L >3Ko
2=1
J d3log3 n
V nL
+ πC5Ln-s’十①(1+l°gL)IOgn
co
∩	∩ &
'∈ [L — 1]
n
≤ C5Ln-c1d + 2n-(9/8)d.
If d ≥ 2∕c1 and n ≥ Lmax, We have C5Ln-c1d ≤ Csn-cid/2; under these condition on d and
n, we have πCsLn-c1d ≤ πc5n~~1, and so πCsn-c1d/2 + (256C1∕co)(1 + logL)(logn)∕n ≤
C(1 + log L)(log n)∕n; and if d ≥ 1 and n ≥ Lmax, we have
3Ko∖ 0P
nL
、人1 + log L)log n
≥ C--------------
n
provided n
to
P
≥ C0(C∕3Ko) 2Lmax log Lmax. Under these conditions, our previous bound simplifies
> 6Kosd^}
∩	∩	e`
2∈ [L — 1]
≤ (2 + C5)n
—min{c1∕2,9∕8}d
93
Published as a conference paper at ICLR 2021
In particular, applying this bound to (D.22), we have shown that for any L ≥ 2
P
U E'
'∈[L]
U	E'
'∈ [L — 1]
+ (2 + C5 )n-
min{c1/2,9/8}d
P
Unraveling the recursion with (D.23) (and worst-casing the constants there), we conclude
P U e`
'∈[L]
≤ (2 + C5)Ln- min{c1/2,9/8}d
which proves the claim, after possibly choosing n to be larger than another absolute constant multi-
Ple of LmaX to remove the leading L factor.	□
D.2.2 Backward Feature Control
Having established concentration of the feature norms and the angles between them, it remains to
control the inner Products of backward features that aPPear in Θ. The core of the technical aPProach
will once again be martingale concentration. We establish the following control on the backward
feature inner Products:
Lemma D.4. Fix x, x0 ∈ Sn0-1 and denote ν = ∠(x, x0). If n ≥ max {KL log n, K0Ldb, K00},
db ≥ K000 log L for suitably chosen K, K0 , K00 , K000 then
P
∖{∣∣β'(x)∣∣2 ≤ Cn} ≥ 1 -
e-c n
2=0
If additionally n, L, d satisfy the requirements of lemmas D.3 and E.16, we have
P
L\-1
L'=o I
L-1
(β'(X), β'(X0)〉- 2 Y
i='
where 夕(i) denotes i applications ofthe angle evolutionfUnction defined in lemma E.2, and c > 0, C
are absolute constants.
Proof. For ' ∈ [L], write F' for the σ-algebra generated by all the weights up to layer ' in the net-
work, i.e., W1,..., W', with F0 given by the trivial σ-algebra. Consider some
for 0 ≤ `0 ≤ L - 1. Defining
(β'0(x),β'0(xo))
Γ':'0 (x) = Pl'(x)W 'Pl'-ι(x)…Pl'0(x)W '0,
BXX00 = Γ':'0+2 (X)PI"i (χ)Pi'θ+ι(χo )Γ'*0+2*(x0),
for ' ∈ {'0 + 1,..., L}, and setting r'0+1:'0+2(x) = I,B：* = ɪI, We define the event
EB+1:'0 = {∣∣BLX0∣∣2 ≤ C2nL∣	∩	n∣∣BLXo0∣∣ ≤ CL}	∩	{trhBLXo]≤ Cn}.
Since (β0 (x), β'0(x0)) = WL+1BLX' WL+1* is a Gaussian chaos in terms of the WL+1 vari-
ables (and recalling WL+1 〜N(0, I)) and EB is FL-measurable, the Hanson-Wright inequality
iid	B
(lemma G.4) gives
P [igL + 1:'0 ∣(β'0(x),β'0(x0)E - tr IBLxOOil ≥ C√tnLi
94
Published as a conference paper at ICLR 2021
Using lemma D.28 to bound P [(瓯+1*) ] from above gives
P [∣(β'z (x), β' (x,)) -tr [b 翳i> C √tnL]
≤P [1EL十Ie
(x), β'0
+ P 1(EL+1:', y∣Dβ' (x), β'
≤p[ιEL+ι0 ∣d* (x), e`(x0))
≤2e-ct + Cn-cn ≤ C0e-c"t
)c]
(D.31)
for appropriately chosen constant, if t < n log n/L. Choosing t
using the bound on tr [BL/] from lemma D.28 We obtain
n/L in the bound above and
P	]M'(x)∣∣2 ≥2Cn]	≤ P	]M'(x)∣∣2 - tr [B鼠	> Cn]+ P [tr [B⅛x]	> Cn]
≤ CeTL + C0nL2e-c”仝 ≤ C00nL2e-c"L
for appropriate constants. Taking a union bound over the possible values of QJ proves the first part
of the lemma.
We next control
tr [bLX0] - 2L∏1
L 」	'='
using martingale concentration (in a similar
manner to the control of the angles established in previous sections). We Write
tr
H)(V)
π
(D.32)
)tr [bX£]) ≡ E ∆' (D.33)
'	'	'='+1
(note the change in the indexing). Consider the filtration F0 U … U Fl and adapted sequence
∆' = ∆' - E[∆'∣F'-1] ,	(D.34)
so that
LLL
E ∆' = E ∆' + E E [∆'∣F'T] .	(D.35)
'=' + 1	'=' + 1	'=' + 1
We begin by considering the first term in the sum since it takes a distinct form. Denoting by W' +1
the i-th column of W'0+1, rotational invariance of the Gaussian distribution gives
tr [Bx+1：[	=tr [马' 0十ι(χ)pi20十ι(χ 0)]
=tr [PW'0+1 α' 0 (x)>0PW'0+1α' 0 (x0)>0]
=tr PW'0 + 1>0PW'0 + 1 cos V +W'0 + 1 sin V >0
(:,1)	(:,1)	(：,2)
and hence
E [ tr [b*[ I Fl= wE+1tr [B*1 = ng1E2%1>0%1 cos ν'0 +g1 sin ν'0 >0
where (g1, g2)〜N(0,1). Moving to spherical coordinates, we obtain
E tr
w `0+1
∞ π∕2
e-r2∕2rdrdθ
0 - 2 +ν'0
n
2
95
Published as a conference paper at ICLR 2021
We now note that conditioned on F', tr PW0 >qPw0 cθs ^+w0 Sin ^>0 is a sum of n in-
L "(:,1)"」	"(：，1) ~2 “一∙ (：，2)
dependent variables taking values in {0,1}. An application of Bernstein,s inequality for bounded
random variables (lemma G.3) then gives
p [∣∆'H > √nd∣
for some c0, where We used the fact that the angle evolution function 夕 is bounded by π∕2. Note
also from Lemma D.3 that
(D.37)
for some constant c, where we assumed d> K log n for some K.
Having controlled the first term in (D.35), we now proceed to bound the remaining terms. We define
events
{gj⅛gj(x0儿 > 0)	∩	{以J)(V)-∕τ∣≤ Cq⅞^∣}
喑'=	∩	{tr [bXU[≤ Cn}	∩	{同"1：[|： ≤ C2n'}	，
∩	{同川≤ C'}
(which from lemma D.28 hold with high probability). Note that as a consequence of the first event
in El' the angle V' is well-defined. Note that £华 is F`_1 -measurable.
We will first control (D.35) by considering each summand truncated on the respective event EBJ
Our task is therefore to control
L	L
X
1?铲0∆' + X IE铲E∆'∣F'T.
'=' + 2	'=' + 2
Since
E [1?铲∆g] = E [e [1?铲∆'∣ F'-1]] = E [1?铲E [∆'∣ F'-1f∣ =0,
the first sum is over a zero-mean adapted sequence and hence a martingale, and can thus be con-
trolled using the Azuma-Hoeffding inequality. We will first show that the remaining term is small.
We begin by computing
1?铲EtrhBxT ∣F'-1 =吃tr [1?铲B^'W'*Pw4-i(“)>0Pw`a'-i(x)>0W']
where we used the fact that E伊'∈ F'-1 and is thus independent of W'.
There exists a matrix R such that
Ra'-1(x) = ∣∣a'-1(x)∣∣2 bi, Ra'-1(x0) = ∣∣a'-1(x0)∣∣2 (bi cos V'-1 + b2 sin ν'-1).
Rotational invariance of the Gaussian distribution gives
W'a'-1(x) = W21) ∣∣ɑ'(x)∣∣2 ,
W'α'-1(x0) = ∣∣a'T(x0)∣∣2 (w'yosV'-1 + W'2) sin VeT),
96
Published as a conference paper at ICLR 2021
where we denote by Wj the i-th column of W'. Defining BXx产'=RBxXy R* we have
Etr [bXX'J 尸T =出tr [1?铲BXXIaW'^Pw^>oPw^ cos£】+吗':,2) Sinν'-1>0W']
=1E铲 BXXjL TEgXWki1W1>O1W1 cos ν'-1+W2 sin ν'-1>0Wkj
B	'	'	1 1	1 1	2 2
ijk
n
=1EBg' X BXXjL WEg nWli1 W'1 > 01 W'1 cos ν"1+W'2 sin νg-1>0 Wfj
i,j=1
n
=X 1e 铲 BXXj 产 Qj.
i,j=1
If i ∈ {1,2} we get (with the square brackets denoting indicators)
QjI =吃2δij [Wj > 0] [Wf1 cos νfτ + Wl2 sin νf-1 > 0]
If i ∈ {1,2} then the Qj1 = 0 only if j ∈ {1, 2}. In these cases we have
Q111
=E n (Wf1)2 [Wf1 > 0] [Wf1 cos νf-1 + Wf2 sin VeT > 0]
W g
=2 E g2 [g1 > 0] [g1 cos VeTI + g2 sin VeTI > 0]
Wg	L
where (g1, g2)〜N(0,1). Moving to spherical coordinates, we obtain
∞ π∕2
Qff1 = Lji /	e-r2∕2r3 cos2 θdrdθ
0 - 2 + νg-1
π — ve-1 + sin Ve-1 cos Ve-1
π
and similarly
∞ π∕2
Ce-I	1 ?	- -r2/2 3 ∙ 2qj JQ	π — Ve-1 — sinVe-1 cosVe-1
Q$2 1 = — e r /2r3 sin2 θdrdθ = --------------------------------
0 - 2 +ν
Qf-1 = Q2-1 = E nW'1 [Wf1 > 0] [Wf1 cos VeT + W^ sin VeT > 0] Wf2
W g
∞ π∕2
π J - L
e-M∕2r3 sin θ cos θdrdθ = ɪ
2π
π∕2
sin θ cos θdθ
2 +νg-1
sin2
e-1
2π
V

Combining terms and using tr [b：x卜e[ = tr [BXX卜e] we obtain
hence
/ π — Ve-1
1e铲 E [tr [bXXJ |Fe-1] = 1e铲
π
e-1
Sm Ve 1
+
U [bXxW]
e-1
cos Ve 1
π
sin2 Ve-1
2π
1厘：2, E
E B	W g
KT(V)
π
5 e-1：e
BXX011
5 e-1：e0
bxx022
5e-1：e' , 5e-1：ezA
bxx012 十 bxx021 J
)tr [BXX,1*[
—
∖
/
=1?伊0
tr [BXχ臼
π	XX
ISin νg-1 cos νg-1 (5 e-1：e0	5e-1：e0
十	π	(bxx011 — bxx022
i sin2 νg-1 5 5e-1：e' _|_ 5e-1：e)
+	2∏	I bXX0 12 + bxx021
97
Published as a conference paper at ICLR 2021
On EBJthe bound on ∣，- 1(ν) - ν`-11 and lemma C.12 give V'_1
event .maχjBXχ1i'] ≤ IBxxIH ≤ C' a.s.. Itfollows that
≤ C a.s.. Additionally, on this
叮告Jtr 但驾]-(I- ^)) tr 怛祟[]∣	(D.38)
≤ C2 Sd3⅛^ + 2c2 + C ≤ CYd3⅛^	(D.39)
V '	π π' V '
almost surely, and hence restoring a constant factor with magnitude bounded by 1, we have
E
W '
—)tr [B J]
Using lemma D.28 to bound P
[(”
from above then gives
P ∣ E∆'∣F'-1 ∣ > C'dnlol°g3 n < P [(eB')c] ≤ C0n-cd.
(D.40)
(D.41)
(D.42)
(D.43)
An application of the triangle inequality and union bound then give
P X E∆'∣F'-1 > C0 dLLn log3 n
, '='0+2	一
一 L
≤P X ∣E∆'∣F'-1 ∣
_'='0+2
L -
≤ X P ∣E∆'∣F'-1 ∣
'='0+2
> C0 Jd3Ln log3 n
〜/ d3n log3 n
>c
L
≤XP
'=20+2
c]
for some constants c, C.
≤CLn-cd
(D.44)
L _
We proceed to control the remaining terms in (D.35), namely P ∆'. Aiming to apply martingale
'='0 + 2
concentration, we require an almost sure bound on the summands, which we achieve by truncation.
Towards this end, We define an event
&=1∣∆e∣≤ C√d' + 0'产三
Combining (D.43) and the result of lemma D.29 (after taking an expectation) we have
P [G'] ≥ 1 - P
∣E∆'∣F'_1∣ > C ,yd3nlJg3n - P [∣∆'∣ > C√d']
≥ 1 - C,,n-cd - C,,,e-c0d ≥ 1 - C""e-cd	(D.45)
98
Published as a conference paper at ICLR 2021
for appropriate constants. We now decompose the sum that We would like to bound:
L
X δ'一 δ'1G'
'=20 + 2
X-----------V------------}
L
X &
'=20 + 2
∑1
L
+ X ∆'1G'- E[∆'1g∕F'T]
'='0 + 2
(D.46)
∑2
L
X E[Δ'1g∕F'T] - E[∆'∣F'T]
≤
+
'='+2
"SZ
J
∑3
Since each summand in Σ1 are equal to zero on the respective truncation event, a union bound and
(D.45) give
L
P X ∆' - ∆'1G' > 0
, '='0+2	.
L
≤ p U灸
乂='0 + 2	.
L
≤ X P [Gc] ≤ LCe-Cd
'='0 + 2
(D.47)
for some constants. The term Σ2 is a sum of almost surely bounded martingale differences. We can
apply the Azuma-Hoeffding inequality (lemma G.8) directly to conclude
P X ∆'1G' - EΔ'1g∕F't >d2 y/nL log3 n log L
, '='0 + 2	一
f	∖
d4nL log3 n log L
≤ eχp------L—7-------------/	、2
2 P (C√d' + C0 √d3 n log3 n )
∖	'='0+2 ∖	V	))
≤ e-cd.
(D.48)
(D.49)
Considering a single summand in Σ3, Jensen,s inequality and the Cauchy-Schwarz inequality give
I E [ ∆'1G' - ∆'∣ F'_1] I = I E [ ∆'1Gc I F'-1] I
≤ E[∣∆' 11sc	IF'_1]	≤	(E[ 1sc	IF'-1])1/2(E[∆2	IF'-1])1/2.	(D.50)
a.s.	a.s.
This is an F'_1-measurable function, and we can show that it is small on the event EB'0 ∈ F'-1.
To control the first factor, we note that
⅞rE[ % I F'-1]
=E [ 1Gc∩Eg'z i F' 1]
=p [ ]∣∆'∣ > c√d' + c0 jd3nl'g3n } ∩ eB' f'_1
< P { ∣ ie铲 ∆' ∣ > c√d' + c0qd3n l73 n} ∩eB'0 f'-1
W	+p[{卜(Ein。∆' I > 0} ∩EB',∣ F'-1]
≤P 必'0 ∆' ∣> C √' + C oSd⅛n F'-1
P [ | 1E铲 ∆' ∣ > c√d'∣ f'-1]
≤ +P IE皆 E∆'∣F'-1∣ > C0q d3n log3 n F'-1
≤ P [∣1Ey∆' ∣ > C√d'] ≤ C0e-cd
(D.51)
99
Published as a conference paper at ICLR 2021
where to obtain the second to last line we used the definition of ʌ`, then used Lemma D.29 and
(D.40) to bound the first and second term almost surely.
We proceed to control the second factor in (D.50), by bounding
IE铲 E [ ∆2∣F'T]
Y1(1-T / "tr [*-(l- -) tr "犷
a≤ %〃叔](tr MO] - (1 - ^^) tr Kx1：l]
[	(1"tr KxO ]- WJtr KxO ]]])2	一
≤ 4 E	2	•
元” [ + &铲]/tr [Bx：x： ]] -(1- 4 )tr 囱/)J
Using (D.38) and (D.148) to bound the integrand above, we have
P IE铲E[∆2∣F'T] >C (d' + Idnlog3n) ≤ C'e-cd
for appropriate constants. Combining (D.51) and the above bound gives
P
IE 铲 ∣E [ % ʌ`- ∆e∣F'T]∣
Yd + — Ld
≤ C0e-c0d
for some c, C, C, C0, and using lemma D.28
P
∣E [ 1seʌ` - ∆'∣F'-1]∣
>C—P Ld
≤ C,e-c" + P [(E铲 H
≤ CCe-CcId + C00n-c"d ≤ C"e-c"d
for appropriate constants. An application of the triangle inequality and a union bound (and intro-
ducing some slack to simplify the expression) then gives
P X E [IGʌ` - ʌ`l F'-1] > CL,d3nlog3 ne-cd ≤ C0Le-cd
, '='0+2	.
for some constants. Combining this bound with (D.47) and (D.48) gives
Γ L	______________ _______________ 1
P	^X ʌ` > d2 JnL log3 n log L + CLJmOg3ne-cd
, '='0+2	.
≤ C0Le-c'd + e-cd + C"Le-c"d ≤ C"0Le-c'"d
P
L
X ʌ`
'='0+2
> Cd2 Ln log3 n log L
≤ C0Le-cd.
where in the last inequality we assumed K log L ≤ d. Combining this with (D.44), we obtain
P
L
X ʌ`
'='0+2
> Cd2 Ln log3 n log L
≤ C00Ln-c0d + C000Le-c”d ≤ C0LeTcd
for appropriate constants. This bound all the terms in the sum (D.32) aside from the first one. The
first term is bounded in (D.36), (D.37), and the fluctuations due to the last layer are bounded in
(D.31). Combining all of these gives
P
W⑺,β"(x0))-
Cd2 JLn log3 n log L
100
Published as a conference paper at ICLR 2021
≤P ∣Dβ'0(x), β'0(x0)E - tr hBLx01:'0i I > CCd2 qLnlog3 nlog L
+ P ∣∆'o+ι∣ ≤ Ccd2 JLnlog3 nlogL + P
X ∆' ≤ CC d2qLn log3 n log L
'='0 + 2
L
+ P X E∆'∣F'-1 ≤ (Cd2qLnlog3 nlog L
, '='0+2	.
≤ C 0Le-cd
after worsening constants. A final union bound over `0 and assuming d ≥ K log L gives
P
L-1
\
_'0=0
{ Dee,(x), β'(x0))—
Cd2 qLn log3 n log L U ≥
1-C 0e-cd
for appropriately chosen c, C0, K. If We additionally assume n > L We obtain the desired result. □
D.3 Uniformization Estimates
D.3.1 Nets and Covering Numbers
We appeal to Lemma C.4 to obtain estimates for the covering number of M, Which We Will use
throughout this section. In the remainder of this section, We Will use the notation Nε to denote
the ε-nets for M constructed in Lemma C.4, and for any X ∈ Nε, we will also use the notation
Nε(x) = B(X, ε)∩M□, where □ ∈ {+,-} is the component of X, to denote the relevant connected
neighborhood of the specific point in the net we are considering. Here we are implicitly assuming
that M± are themselves connected, but this construction evidently generalizes to cases where M±
themselves have a positive number of connected components, as treated in Lemma C.4. Focusing
on this simpler case in the sequel will allow us to keep our notation concise.
D.3.2 Controlling Support Changes Uniformly
The quantities we have studied in Appendix D.2 are challenging to uniformize due to discontinuities
in the support projections p`(.). We will get around this difficulty by carefully tracking (with high
probability) how much the supports can change by when we move away from the points in our net
Nε . It seems intuitively obvious that when ε is exponentially small in all problem parameters, there
should be almost no support changes when moving away from our net; the challenge is to show that
this property also holds when ε is not so relatively small.
Introduce the following notation for the network preactivations at level `, where ` ∈ [L]:
ρ'(x) = W' α'-1(x),
so that α'(x) = [ρ`(x)] + . We also let F' denote the σ-algebra generated by all weight matrices up
to level ` in the network, and let F0 denote the trivial σ-algebra.
Definition D.1. Let ε, ∆ > 0, and let X ∈ N. For ' ∈ [L], a feature (α'(X))i is called ∆-risky if
∣(ρ'(X))i∣ ≤ ∆; otherwise, it is called ∆-stable. If for all X ∈ M(X) we have
∀'0 ∈ ['], ∣∣p'(x) - p'(x)∣∣∞ ≤ ∆,
we say that stable sign consistency holds UP to layer '. We abbreviate this condition as SSC(', ε, ∆)
at X, with the dependence on X, ε, and ∆ suppressed when it is clear from context.
If SSC(') holds at X and if (α'0(X))i is stable, we can write for any X ∈ N(X)
sign ((P'0(X))i) = sign ((P'0 (X))i + ((P'0 (X))i - (ρ'(X))i)) = sign ((P'0(X))i),
so that no stable feature supports change on Nε(X), and we only need to consider changes due to
the risky features. Moreover, observe that
P[(ρ'(X))i ∈ {±∆}] = E[P[kα'-1(X)k2hei,gi ∈ {±∆} I F'-1]] = 0,	(D.52)
101
Published as a conference paper at ICLR 2021
where g 〜N(0, Mn)I) is independent of everything else in the problem, since ∆ > 0. It follows
that when considering the network features over any countable collection of points X ∈ M, we have
almost surely that the risky features are witnessed in the interior of [-∆, +∆].
Below, we will show that with appropriate choices of ε and ∆, with very high probability: (i)
each point in the net X has very few risky features; and (ii) SSC(L) holds uniformly over the net
under reasonable conditions involving n, L, d. We write Re(X, ∆) U [n] for the random variable
consisting of the set of indices of ∆-risky features at level' with input X ∈ Nε.
Lemma D.5. There is an absolute COnStant K > 0 such that for any X ∈ M and any d > 0, if
n ≥ max{KdL, 4} and ∆ ≤ dlog n/(6n3/2L), then one has
L L	-
P X∣Re(X,∆)∣ > dlogn ≤ 2n-d + L2e-cn∕L.
一e=ι	_
Proof. For any X ∈ Nε, Lemma D.2 (with a suitable choice of d in that context) gives
P ]∣3e(X)∣∣2- 1∣ > 2] ≤ C'e-c 节,
so that if additionally n ≥ (2/c)' log(C), one has
p]∣3'(x)∣∣2- 1∣> 2] ≤Cei芝.
(D.53)
Let Ge = {1/2 ≤ ∣∣ae(X)k2 ≤ 2}, so that Ge is Fe-measurable, and G = ∩e∈[L—1]煲；then by
(D.53) and a union bound, we have P[G] ≥ 1 - L2e-cn∕L. We also let Go = 0c. For i ∈ [n] and
C ∈ [L], consider the random variables Xie = ∣ (Pe(X))i ∣, and moreover define
Xie= ∣∣∕⅛)∣∣2 1g'-1 .
We have Ei e 1χii<∆ = Ee∣Re(X)∣, which is the total number of ∆-risky features at X, and the
corresponding sum with the random variables Xie is thus an upper bound on the number of risky
features at x. Notice that Xie and Xie are Fe-measurable, and additionally notice that on G, we
have Xie/2 ≤ Xie ≤ 2Xie. For any K ∈ {0,1,.. .,nL - 1, nL}, we have by disjointness of the
events in the union and a partition
P X 1Xi'<∆ >κ ≤ L2L/L + X P G∩ ∖χ 1Xi'<∆ = k∖∖
i,e	k=κ+ι	( i,e_|
≤ L2L/L + X P G∩ {Xlx3 =",
k=κ+1	I i,e	I
so it is essentially equivalent to consider the Xie . By another partitioning we can write
P G∩ E1Xi'<2∆ = k
I i,e
Σ
S∈{0,1}n×L :
L
π
,e=i
n
π1
i=1
1Xi'≤2∆ =Sig
E
kSkF =k
)
where {0,1}n×L is the set of n × L matrices with entries in {0,1}. Using the tower rule and
FL-1-measurability of all factors with C < L, we can then write
Ln
E ∏IJnI&≤2∆=Si'
_e=1	i=1
Ln
E E ∏	1G'-1∏ 11Xi'<2∆=Si'
e=1	i=1
IFjl
EMn1	Π1k<2∆=Si) ) "1 E ]Π 11 …∆ = SiL
e=1	i=1	i=1
Fj;
102
Published as a conference paper at ICLR 2021
We study the inner conditional expectation as follows: because PL(X) = WLaLT (x), We can
apply rotational invariance in the conditional expectation to obtain
n
1Gl-IE Π 11⅛<2∆=SiL	FLT
_i=1
n
IGL-I E Π 11∣(wL)i∣1gg-ι<2∆ = SiL	FLI
_i=1
n
1Gl-IE ∏ 11∣(wL)i∣<2∆=SiL FL-
_i=1	.
where WL 〜N(0, (2∕n)I) is the first column of WL, and the last equality takes advantage of the
presence of the indicator for lg`-i multiplying the conditional expectation. We then write using
independence
n
E Π 11∣(WL )i∣<2∆=SiL FLI
_i=1	.
n
P ∩{1∣(wL)i∣≤2∆ =SiL}∖F l T
_i=1
n
∏ P[1∣(wL)i∣≤2∆ = SiL ∖ FL-1],
i=1
and putting PL = P[∣(wl)i∣ ≤ 2∆], we have by identically-distributedness
nn
∏ P[1∣(wL)i∣≤2∆ = SiL ∖ FL-1 ] = ∏PLiL (1 - PL)1-SiL .
i=1	i=1
After removing the indicator for Gl-i by nonnegativity of all factors in the expectation, this leaves
us with
Ln
E Π 1G'-1Π1k<2∆ = Si'
_'=1	i=1
Cn	、	「∕L-1	n
ΠpLiL (1 - PL)I-SiL E Π 1G`-1Π 1l"2∆=Si'
i=1	)	L∖'=1	i=1
.
This process can evidently be iterated L -1 additional times with analogous definitions——we observe
that the fact that all weight matrices W' have the same column distribution implies that pi =…=
Pl, so we write P = pi henceforth——and by this we obtain
Ln
E Π1G'-ιΠ11χi'<2∆=Si'
_2=1	i=1
Ln
≤ ΠΠ PSiL (1 - P)I-SiL ,
'=1 i=1
and in particular
P G∩ 后IM∆ = k∖	≤	X	ΠΠPSiL(I-P)I-SiL.
[i,'S∈{0,1}n×L : ∣∣SkF = k'=1 i=1
For i ∈ [n] and ' ∈ [L], let 匕' denote nL i.i.d. Bern(P) random variables; we recognize this last
sum as the probability that Piie 匕' =k. In particular, using our previous work we can assert for
any t > 0	，
P ∑ 1χi'≤∆ > 11 ≤ PI	Ke >t∣ + L2e-cn/L,
so to conclude it suffices to articulate some binomial tail probabilities and estimate P. We have
P = P[∣(wL)i∣≤ 2∆]
(D.54)
and we can write with the triangle inequality and a union bound
P fYi' >t ≤ P fYi' - E[Yie] >t + P £E[Ke]>t
103
Published as a conference paper at ICLR 2021
By (D.54), We have Pi ` E[Kg] ≤ n3/2LA. We calculate using independence
EKX Yie- E[Ke) ] ≤ X EM ≤ n3/LA,
so an application of Lemma G.3 yields
P X Ke- EM >t ≤ 2exP (-n3∕2LA +1/3 )∙
i,e
For any d > 0, if we choose t = d log n and enforce A ≤ dlog n/(6n3/2L), we obtain
PXYie > dlog n ≤ 2n-d,
i,e
from which we conclude as sought
P ^X 1"≤∆ > dlogn ≤ 2n-d + L2e-cn^L.
i,e
□
The next task is to study the stable sign condition at a point X as a function of ε and A, assuming
A at least satisfies the hypotheses of Lemma D.5. In particular, we will be interested in conditions
under which we can guarantee that SSC(' - 1) holding implies that SSC(') holds. Let Se(x, A)=
[n] \ Re(X, A) denote the A-stable features at level' with input X, and define for 0 ≤ ' ≤ ' ≤ L
TXe0 = pS'(x)P'(x)W eBj (x)Pj(X)W e-1 ... Pse, + 1 (x)P" + ι(x)W e0 + 1;
Φχe0 = w eτχτ,e0,
so that ΦX,e x carries an input x ∈ M(X) applied at the features at level ' (in particular, 0 = 0
corresponds to ɑ0 (x) = x, the network input) to the preactivations at level' in a network restricted
to only the stable features at x. We can write
Pe(X) = W ePfJ(X)We-1... Ph(X)W 1x;
αe(x) = Ple(x)W ePfj(X)We-1... & (X)W 1x,
which gives us a useful representation if we disregard all levels with no risky features: let r =
PL=1 1∣R'(x,δ)∣>o be the number of levels in the network with risky features, and let '1 < '2 <
…< 'r denote the levels at which risky features occur. If no risky features occur at a level', we of
course have PSg(X) = I. Assume to begin that' > 'r, and start by writing
Pe(X) = φX,er (Psg, (X) + PRer (X)) Pfgr (x )小+"-1 (Ps. 1 (X) + Pr.i(X)) Pfgr-1(x) ...
...ΦX2,e1 (PSgI(X) + Pr1i(X)) PfgI(x)ΦX1,0.
Now we distribute from left to right, and recombine everything to right on the term corresponding
to the projection onto the risky features at 'r ; this gives
Pe(X) = φXer PRgr (X) aer (X) + φX,e'T (PSgr-1 (X) + PRgr-I(X)) Pfgr-I (x)...
... ΦX2,e1 (PSgI (X) + PRg1 (X)) Pfg1 (x)ΦX1 ,0.
We can write
φX,er PRgr (X)α'r (X) = φX,'l Rgr (X)α'r (X) I Rgr (X),
104
Published as a conference paper at ICLR 2021
where the restriction notation emphasizes that we are considering a column submatrix of the transfer
operator induced by the risky features. Iterating the previous argument, we obtain
r
ρ'(X) = φX,0χ + X φX,'i∣R'. (x)α'i (x)∣R'. (x).
i=1
It is clear that an analogous argument can be used in the case where ` ≤ `r by adapting which risky
features can be visited: we can thus assert
ρ'(X) = φX,0χ +	X	φX,'i∣R'i (χ)α'i(X)∣R'i(χ).	(D.56)
i∈[r] : 'i<'
Furthermore, We note that under SSC(' - 1), no stable feature supports change on M(x), and so
one has for every X ∈ Nε(x)
φ','0 = φ','0
ɪ X ɪ X ,
so under SSC(' - 1) we have by (D.56)
p(x) - ρ'(X) = φX,0 (X - x)+ X	φX,'i∣R' (X) (α'i(X) ∣R'i(x)- α'i(X) ∣R'i(x)).
i∈[r] : 'i <'	八>
The ReLU [∙] + is 1 -LiPSchitz with respect to ∣∣∙∣∣ ∞, and by monotonicity of the max under restriction
and SSC(' - 1) we have
卜 `i(X)∣Rq(χ)- α'i (X)L'i (x)B∞ ≤ M(X)0(X)-椁(X)∣R'i(χJL
≤ ∣∣ρ'i(X)- ρ'i(X)IL ≤ δ
Thus, by the triangle inequality, we have under SSC(' - 1) a bound
∣∣ρ'(X)- p'(x)l ≤ ε∣∣φx,0∣∣'2-'∞+δ X	φx,'i∣R (X)
→X
i∈[r]: 'i<'	八)
(D.57)
'∞ →'∞
This suggests an inductive approach to establishing SSC(') provided we have established it at pre-
vious layers—we just need to control the transfer coefficients in (D.57).
Lemma D.6. There are absolute constants c, c0 , C, C0 , C00 , C000 > 0 and absolute constants
K,K 0 > 0 such that for any 1 ≤ ' < ' ≤ L, any d ≥ K log n and any X ∈ Sn0-1, if ∆ ≤ cn-5/2
and n ≥ K0 max{d4L, 1}, then one has
pkij「C (1+rno)] ≥ 1 - C 00e-cd,
and for any fixed S ⊂ [n], one has
p"∣∣φx,'0∣s∣∣'∞-'∞ ≤ (C0Sr# ≥1 - C 0"d.
Proof. We will use Lemmas D.14 and D.23 to bound the transfer coefficients, so let us first verify
the hypotheses of these lemmas. In our setting, the transfer matrices differ only from the ‘nominal’
transfer matrices by restriction to the stable features at X; we have S'(X) ∩ 4(X) = [n] \ R'(X),
which is an admissible support random variable for Lemmas D.14 and D.23, and in particular
∣∣(pS'(X)pi'(X) - PI'(X)) p'(x)∣∣2 = ∣∣pR'(X)α'(X) ∣∣2 ≤ √n∆
by Lemma G.10 and the definition of R'(X). Additionally, using Lemma D.5, we have if d ≥ 1, n ≥
KdL, and ∆ ≤ cd/n5/2, there is an event E with measure at least 1 - 2e-d - L2e-cn/L on which
there are no more than d risky features at X. Worsening constants in the scalings of n if necessary
and requiring moreover d ≥ K0 logn and n ≥ K00d4, it follows that we can invoke Lemmas D.14
and D.23 to bound the probability of events involving transfer coefficients multiplied by 1E . Let
us also check the residuals we will obtain when applying Lemma D.23: in the notation there, the
vector d has as its '-th entry R'(x), and so we have bounds ∣∣d∣∣ 1/2 ≤ IldII2 and IldllI = P R'(x),
105
Published as a conference paper at ICLR 2021
which means on the event E, the residual is dominated by the CVd4nL term in the scalings We have
assumed.
The '2 → '∞ operator norm of a matrix is the maximum '2 norm of a row of the matrix, and the
'∞ → '∞ operator norm is the maximum '1 norm of a row. Thus
牍 χ,1j∞=i=m,axnkφx,12
=i=maU(W'Mχτ0 B2
where (W')* is the i-th row of W', which is no-dimensional when ' = 1 and n-dimensional
otherwise. In particular, we have
牍 x,1j∞=i=m,axnU(W1w2,
and so taking a square root and applying Lemma G.2 and independence of the rows of W1, we have
p[Bφx!'2→'∞ ≤2(I+rno)] ≥1 - 2ne-cn,
for c > 0 an absolute constant. When ' > 1, we can write
i=m,aχn∣∣(W' )rτχ-112 = i=m,aχn∣∣(W' )∙⅛1,1piι(χ)W1∣∣2
≤ W gaxn∣∣(W')α1,1 P9∣∣2,
where the second line applies Cauchy-Schwarz. Using, say, rotational invariance, Gauss-Lipschitz
concentration, and Lemma E.48 (or (Vershynin, 2018, Theorem 4.4.5)), we have
PllW 1∣∣ >C(1 + yn0) ≤ 2e-cn
for absolute constants c,C > 0. On the other hand, note that k(W')*τX-1,1PIι(χ) ∣∣2 has the same
distribution as the square root of one of the index-0 diagonal terms studied in Lemma D.23 in a
network truncated at level ' - 1 instead of L and scaled by 2/n; and so applying this result together
with a union bound and the choice n ≥ max{K, K0d4L} for absolute constants K, K0 > 0 gives
P 1e . max ∣∣(W ')；TxTIPI垓)∣∣ >C0 ≤ C 00ne-c0d
i=1,...,n	2
where C0, c0, C00 > 0 are absolute constants. We conclude by another union bound
p[∣∣Φx,0∣∣e2 ' ≤ C(1 + yn0) ≥ 1 - 2e-cn - CneiCid - C00L2e-c0n/L.
We can reduce the study of the partial risky propagation coefficients to a similar calculation. We
have
∣∣φx,'0U∣'∞→'∞=HX,n∣∣(W')；"TS) ∣∣1,
where by construction we have that ' > '0. In the case ' = '0 + 1, the form is slightly different; we
have
Φx + 1,' I ∣∣	= max
∣S∣∣'∞→'∞	j = 1,…,n
≤ |S | max
1	j=1,...,n
where the inequality uses Lemma G.10. The classical estimate for the gaussian tail gives
P I(W'0 + 1)jkl> V2d
≤ 2e-d,
(D.58)
for each k ∈ [n], so a union bound gives
106
Published as a conference paper at ICLR 2021
and We conclude
p 惮+T'j∞ ≤^∣⅛ ≥1 -2e-d/2,
where the final bound holds if d ≥ 2 log n. Next, we assume ' > ' + 1. In this case, Lemma G.10
gives
HO
Sll28→'∞
HX,J(W')"τχτ[JL
≤∣S Max,J(W`)；((TxTIS))∣∣∞
For the second term on the RHS of the inequality, we write
HX,J(We)HTl SL= HX,n Id(W)TxT'e I
then apply rotational invariance of the distribution of (WDj and Fe_1-measurability of Tx-1,e
to obtain
max max ∣(WejTxTEek 1 = max	max
j=1,…,n k∈s '	'	j=1'…,n k∈s： ∣∣τX-1,'zefc∣∣2>0
∣(W ')；TxTg efc I
j=maxn ImaX 1 gj 1BtX^1,'zekj2
j 1 ,...,n k ∈ S	2
where g 〜 N(0, (2∕n)I) is independent of everything else in the problem. We have by
Lemma D.14 based on our previous choices of n and d
p[1E∣∣Tx-1,'zek∣∣2 ≤ Ci ≥ 1 - Ce-Cn/L,
and (D.58) applied to g controls the remaining term. Taking a union bound over [n] in these two
estimates and partitioning with E, we conclude
P
HX,n∣∣(We)“TxTl S)∣∣∞ >c rnj ≤ 2ne-d ÷ C 0ne-cn/L+2e-d+L"n/L
and thus
> C|S |
C0e-d∕2 ÷ C00n2e-cn/L,
P
where the last bound holds if d ≥ 2 log n. Choosing n ≥ KL log n for a suitable absolute constant
K > 0 allows us to simplify the residual terms in the probability bounds to the forms we have
claimed.	□
Lemma D.7. There is an absolute COnStant c > 0 and absolute constants k, k!, K, KK > 0 such that
for any d ≥ K log n, if n ≥ KK max(d4L, 1}, ∆ ≤ kn-5/2, and ε ≤ k0∆ (1 ÷ Pfn) ', then one
hasfor any X ∈ Nε
P
{SSC(L) holds at X} ∩
| Re(X, ∆)| ≤ d
e-cd
Proof. We start by constructing a high-probability event on which we have control of every possible
propagation coefficient. For any d ≥ K log n, choosing ∆ ≤ Cn-5/2 and n ≥ K0d4L and applying
the first conclusion in Lemma D.6 and a union bound, we have
P ∃' ∈[L], Bφx1'2→e∞ >C1(1÷	≤Ce-Cd
(D.59)
and under the same hypotheses, for any 1 ≤ ' < ' ≤ L and any S U [n], the second conclusion in
Lemma D.6 gives
P kn SIL- >C21s1rnj ≤ C …
107
Published as a conference paper at ICLR 2021
Using Lemma D.5, we have if n ≥ max{K dL, 4} and ∆ ≤ K0 /n5/2
L
P X∣R'(X, ∆)∣ > d ≤ 2e-d + L2e-cn/L.	(D.60)
一'=1	.
Denote the complement of the event in the previous bound as E . On E , there are no more than
d levels in the network with risky features. There are at most Pk=O ⑺ Ways to choose a subset
S ⊂ [n] with cardinality at most dde; using n ≥ e and d ≥ 1, we have
dde
X n ≤ 1 + ddendde ≤ 4dn2d.
k=0
In addition, there are at most L2 ways to pick two indices 1 ≤ `0 < ` ≤ L. Using n ≥ L, this yields
at most 4dn2+2d ≤ n8d items to union bound over, i.e.,
Juu	(牍山1一>021哈"CL8	(D∙61)
S⊂[n] 1≤'<'0≤L I	)
L∣S∣≤dd]	」
if d ≥ K logn and n ≥ max{K0d4L,n0}. Denote the complement of the union of the events in
the bounds (D.59) to (D.61) and E as G; taking additional union bounds and worst-casing absolute
constants, we have shown
P[G] ≥ 1 - Ce-cd.
If we enumerate the levels of the network that have risky features as 1 ≤ '1 < …< 'r ≤ L, it
follows from our previous counting argument that on G, we have transfer coefficient bounds (for any
` ∈ [L] and any `i < `)
牍χ'1'2_'∞ ≤ CI(I + Vnn0),	φx,'i∣R`i(x) '∞→'∞ ≤ c2lR'i(X)Mn
Now we begin the induction. Let X ∈ Nε(x) For SSC(1), we have from the definitions
IlPI(X)-PI(X)L ≤ ε∣∣φx,0∣∣'2 →'∞ ≤CI (I+rm )ε,
where the last inequality holds on G. So we have SSC(1) on G if ε ≤ ∆(Cι(1 + Pn))-1.
Continuing, we suppose that we have established SSC(' - 1) on G. We can therefore apply (D.57)
together with our transfer coefficient bounds to get
∣∣ρ'(X)-P'(x)∣∣∞ ≤ CI(I + rn)ε + c2δ↑J~n	X	|R'i(X)I
i∈[r] : 'i<'
≤ C1(1 + 产)ε + C2∆rd3.
nn
Notice that the last bound does not depend on `. Thus, if we choose ε ≤ ∆(2C1(1+ √nn0))-1 and
n ≥ 4C2d3, we obtain ∣∣p'(x) - ρ'(X) ∣∣∞ ≤ ∆; by induction, we can conclude that SSC(L) holds
on G, which implies the claim; we obtain the final simplified probability bound by worsening the
constant in the exponent.	□
D.3.3 Uniformizing Forward Features Under SSC
Under the SSC(L) condition, we can uniformize forward and backward features. A prerequisite of
our approach, which we also used to establish SSC(L) in the previous section, is control of certain
residuals that appear when a small number of supports can change off the nominal forward and
backward correlations. These estimates are studied in the next section, Appendix D.3.4.
In previous sections, most of our results (e.g. Lemma D.1) feature a lower bound of the type n ≥ K
in their hypotheses. After uniformizing, we will discard this hypothesis using our extra assumption
108
Published as a conference paper at ICLR 2021
that n0 ≥ 3, which gives us a lower bound on the logarithmic terms of the form log(Cnn0) that
appear as lower bounds on d after uniformizing, and the fact that our lower bounds on n always
involve a polynomial in d. Thus, by adjusting absolute constants, we can achieve the same effect as
previously.
Lemma D.8. There are absolute constants c, C > 0 and an absolute constant K, K0 > 0 such that
for any d ≥ Kd0 log(nn0CM), if n ≥ K0d4L then one has
P
\	{SSC(L, n-3n-1∕2,Cn-3) holds at x} ∩ < £|R'(X, Cn-3)∣ ≤ d > I
x∈N -3 -1/2	l'=1	J
n-3n0
≥ 1 - e-cd
Proof. Following the discussion in Appendix D.3.1, if 0 < ε ≤ 1 then ∣Nε∣ ≤ ed0Iog(CM左)；
to apply Lemma D.7 We at least need ∆ ≤ kn-5/2 and ε ≤ k0∆(1 + pn^^) , so it SUf-
fices to put ∆ = Cn-3 when n is chosen larger than an absolute constant, and require ε ≤
min{l,k0Cn-5/2(1 + Pfn) 1}. Fixing ε
n-3n0-1/2, which again is admissible when n is
sufficiently large compared to an absolute constant, for any d ≥ Kd0 log(nn0CM), we choose
n ≥ K max{1, d4L} and take a union bound to obtain the claim (using here that CM ≥ 1).	□
Lemma D.9. There is an absolute constant c > 0 and absolute constants K, K0 , K00 > 0 such that
for any d ≥ Kd0 log(nn0CM), ifn ≥ Kd4L, then one has
P ∩	∀' ∈ [L], Ikα'(x)k2 -
x∈M
Proof. Let X ∈ Nn-3n-1∕2. Lemma D.2 and a union bound give
P ∃' ∈ [L] : l∣∣α'(x)∣∣2 - 1i > 1 ≤ CCLLnL ≤ e-cd
ifn ≥ KdL and d ≥ K0 log n. If additionally d ≥ K0d0 log(nn0CM), we obtain by the discussion
in Appendix D.3.1 and another union bound
P
U
x∈N -3 -1/2
n-3n0
{∃'∈ [l] ： ∣∣Mx)∣∣2-
≤ e-cd.
Let E denote the event studied in Lemma D.8; choose d ≥ Kd0 log(nn0CM) and n sufficiently
large to make the measure bound applicable. A union bound gives
P
EC ∪ U ∃ ∃' ∈ [L]:
X∈N -3 -1/2 I
n n0
-1∣ > 4
≤ e-cd.
Let G denote the complement of the event in the previous bound. For any x ∈ M, we can find a
point X ∈ Nn-3n-1∕2 ∩Nn-3n-1∕2 (x). On G, SSC(L,n-3n-1/2,Cn-3) holds at every point in the
net N 3 -1/2, which implies that on G
n- n0
∀' ∈ [L], ∣∣ρ'(x)- ρ'(X)∣∣∞ ≤ (C,	(D.62)
and by the 1-Lipschitz property of [ ∙ ]+ and Lemma G.10, this also implies that on G
C
∀' ∈[L]，∣∣α (X)- α (X)∣∣2 ≤ n5/2.
109
Published as a conference paper at ICLR 2021
Choosing n ≥ (4C)2/5, the RHS of this bound is no larger than 1/4. We write using the triangle
inequality
∣kα'(x)k2 - 1∣≤ ∣kα'(x)k2 -kα'(x)k2∣ + ∣kα'(x)k2 - 1∣.
Using the triangle inequality again, the first term on the RHS is no larger than 1/4 for any ` on G.
The second term is also no larger than 1/4 on G by control over the net. We conclude that on G
∀' ∈ [L], ∣∣∣α'(x)∣∣2- 1∣ ≤ 2.
This implies that the event G is contained in the set
\ 卜' ∈ [L], ∣kα'(x)k2 - 1
x∈M
which is closed, by continuity of ∣∣ ∙ ∣∣2 and of the features as a function of the parameters, and is
therefore also an event. The claim follows.	□
Lemma D.10. There are absolute constants c, C > 0 and absolute constants K, K0 > 0 such that
for any d ≥ Kd0 log(nn0CM), if n ≥ K0d4L, then one has
P
∩
(x,x0)∈M×M
{∀' ∈ [L], ∣<α'(x), α'(x0)> -
cosd')(∠(χ, χ0))∣ ≤
Proof.
Let x, X0 ∈ Nn-3n-ι∕2. Lemma D.1 and a union bound give
P ∃' ∈ [L]
∣(α'(X), α'(X0)) — cos	(∠(X, X0)) ∣
if d ≥ K log n and n ≥ max{K 0 d3 L, K00d4, K000}. If additionally d ≥ Kd0 log(nn0CM ), we
obtain by the discussion in Appendix D.3.1 and another union bound
P
U	[∃' ∈ [L] : ∣<α'(X), α'(X0)>-Cos 中⑻(∠(X, X0))∣ > eʌ/dn'l
(X,X0)∈N ×21	I	J
,	n3 √n0
≤ e-cd
where with an abuse of notation we write S ×2 to denote S × S for a set S. Let E1 denote the event
studied in Lemma D.8, and let E2 denote the event studied in Lemma D.9; choose n sufficiently
large to make the measure bounds applicable. A union bound gives
P
Ec ∪ E2c ∪ U ∃3∈ ∈ [L] : ∣(α'(X), α'(X0)) - cos 夕⑶(∠(X, X0))∣ > C∖J~~~ ∖
(x,x0)∈N ×21	I	J
.	n3√n0^	ι
≤ e-cd
after adjusting constants. Let G denote the complement of the event in the previous bound. For
any (x, x0) ∈ M × M, We can find a point X ∈ 柒-九-"∩ Nn-之厂/2 (x) and a point
X0 ∈ Nn-3n-1∕2 ∩ Nn-3n-1/2(x0).On G, SSC(L, n-3n-1/2, Cn-3) holds at every point in the
net Nn-3n-1/2, which implies that on G
∀' ∈ 4∣∣ρ'(X)- ρ'(X)L ≤ ^, and ∀' ∈ 4∣∣ρ'(XO)- ρ'(XO)L ≤ nC3,
and by the 1-Lipschitz property of [ ∙ ]+ and Lemma G.10, this also implies that on G
CC
∀' ∈ [L],	∣∣α'(X) -	α'(X)∣∣2 ≤	npi,	and	∀' ∈ [L], ∣∣α'(X	) -	α'(X	)∣∣2 ≤	n^.	(D.63)
110
Published as a conference paper at ICLR 2021
For any ` ∈ [L], we write using the triangle inequality
∣ Q(x), α'(x0)〉— cos*(∠(x, x0)) ∣ ≤ ∣ (a'(x), α'(x))〉— Q(x), α'(x)))∣
+ S'(x), α'(x X))一 Q(x), α'(xz)) ∣
+ (α'(x), α'(xz)) — cosd')(/(x, x0)) ∣	(	)
+ ∣cos g(')(∠(x, x0)) — cos g(')(∠(x, x0)) ∣ .
Using Cauchy-Schwarz, We have on G
∣(α'(x), α'(x,)> — <α'(χ), α'(x,)>∣ ≤ ∣∣α'(x) — α'(x) ∣∣2 ∣∣α'(x,) ∣∣2 ≤ nC,
with the same bound holding for the second term in (D.64) by an analogous argument. For the third
term, we have on G
∣ (α'(x), α'(x0)) — cos 4⑶(∠(x, x0)) ∣ ≤ C^dn'.
For the last term, we use I-Lipschitzness of cos and I-Lipschitzness of the 夕(`), which follows from
Lemma E.5 and the chain rule, to obtain
∣cos d')(∠(x, x0)) — cos 夕⑶(∠(x, x0)) ∣ ≤ ∣∠(x, XZ) — ∠(x, x0)∣.
Using Lemma C.7 and several applications of the triangle inequality, we get
∣∠(x,xz) — ∠(x,x0)∣ ≤ √2∣∣∣x — xz∣∣2 一 ||x — xzI∣2∣
≤√2∣∣(x - XZ) —(X - XZ)II2
≤ √2∣x — X∣∣2 + √2∣xz — Xz∣∣2 ≤ ~n32,
and so returning to (D.64), we have shown
≤ (C + C0)J先
n
∣(α'(x), α'(xz)) — cos ^(')(Z(x, x0))∣ ≤ C
for every ` ∈ [L]. This implies that the event G is contained in the set
∩	卜' ∈ [L], ∣<α'(x), α'(xz)) — cos(∠(x, x)))∣ ≤ C
(χ,χ0)∈M×M I
d3'
n
which is closed, by continuity of the inner product and of the features as a function of the parameters,
and is therefore also an event. The claim follows.
□
Lemma D.11. Assume n, L, d satisfy the requirements oflemma D.10 and additionally d ≥ 1, n ≥
K√L for some K. Then
P [kfθoIl∞ ≤√d] ≥ 1 — e-cd
p[∣∣Z∣∣L∞ ≤ √d] ≥ 1 — e-cd.
Define
Z(X) = —f*(x) + /fθo (x')dμ∞(x').
M
Then under the same assumptions
P
Ld2 + d5/2V L
≥ 1 — e-cd
for some numerical constant c.
111
Published as a conference paper at ICLR 2021
Proof. At some x ∈ M, we note that
fθ0 (x) = WL+1αL(x) =d g αL(x)2	(D.65)
where g is a standard normal independent of the other variables in the problem. Similarly
fθo(X)- /fθo(x0)dμ∞(x0) = WL+[αL(x) - /αL(x0)dμ∞(x0)
=g0 αL(x) - ∕αL(x0)dμ∞(x0),
M 2
(D.66)
where g0 is also standard normal. With respect to the randomness of WL+1 , these two objects
2
are Gaussian processes with variances IlaL(X)b and αL(x) - J αL(x0)dμ∞(x0) respectively.
M 2
We next note that
I2
aL(x) — / αL(x0)dμ∞(x0)
M	I2
I	I2
=/ aL(x) — aL(x0)dμ∞(x0)
IM	I2
≤ /1IaL(X)- aL(XO)I∣2 dμ∞(χ0)
M
=/ ∣∣aL(X)∣∣2 + IIaL(X0)∣∣2- 2 (aL(x), aL(X')〉dμ∞(χ0)
M
≤ sup ∣∣aL(X)∣∣22 + ∣∣aL(X0)∣∣22 - 2aL(X),aL(X0)
x∈M
/
≤ SuP
x∈M
\
∣∣aL (X)∣∣22
+ I∣aL(X0)∣∣2- 2 Sl(x), aL(X0))
-(2 — 2cos夕(L)(V(x, X0)))
+ ∣2 — 2cos夕(L)(V(x, X0))I	)
where the first inequality comes from an application of Jensen’s inequality. Assuming n, d satisfy
the requirements of lemma D.10 and denote the event defined in it by G. On G, angles between
features concentrate uniformly around a simple function of the angle evolution function 夕，in the
sense that, for all X ∈ M simultaneously,
∣∣∣aL(X)II2 + IIaL(X0)∣∣2- 2(aL(X), aL(X，)')- (2 - 2cos dL)(V (x, XO)))I
≤|IIaL(X)II2- 1∣ + MaL(XO)∣∣2- 1∣+2∣(aL(X),aL(X0)〉-cosdL)(V(x,XO))I	(D.67)
for some constant CO. From lemma C.12, there exists a constant c0 > 0 such that for all V ∈ [0, π],
o ≤ aL)(V) ≤ ɪ.
c0L
Using cosx ≥ 1 - x2/2 and the above bound gives
1 ≥ cos dL)(V) ≥ 1 - W(L2(V))2 ≥ 1 - 2⅛
2	2c0 L
and thus
2 - 2cos夕(L)(V(x, xo))∣ ≤ CL.
112
Published as a conference paper at ICLR 2021
Combining the above bound with D.67 and recalling the probability of G holding, we have
P CsupMaL(X)112 + 1IaL(X/∣2-2SL(X),αL(XO))| >c2L2+ C0JdL ≤e-cd.
(D.68)
On the same event we have
P sup IIaL(X)II22 > 2 ≤ e-cd.
x∈M
Thus on G the variances of the Gaussian processes (D.65), (D.66) are uniformily bounded by 2 and
c2⅛2 + C 0 JdnL respectively.
Writing for concision in the subsequent expression
E* ʃ ιfθo(X)—Z fθo(XO)dμ∞(XO) ≤ ɪ ;L+r -n
∖ 1	M
taking a union bound over all points on the net Nn-3n-1/2 gives
P
x∈Nn-3n-1∕2
n	n0
{∣fθo (X)∣≤√d}∩E*
(D.69)
∩
G
≥1-∣N-3„-ι∕2∣e-cd ≥ 1-e-c0d,
n n0
for some constants, since d was chosen to satisfy the conditions of lemma D.10.
In addition, We see from (D.63) that on the same event, for every X ∈ M there exists x ∈
such that
lfθo(X)- fθo(X)I = fθ0(X)- /feo(X0)d〃8(XO)- fθ0(X)- /fe0(X0)d〃g(XO)
∣M	M
=∣ WL+1 (αL(X) — aL(X)) ∣
≤I∣WL+1∣∣2 IIaL(X)-aL(X)∣∣2 ≤ CJW+⅛.
Bernstein,s inequality also gives P [∣∣ WL+1∣∣2 > C√n] ≤ e-cn for some constants. Denoting the
complement of this event by E we have that on E∩G, for every X ∈ M there exists X ∈ 鼠一八7/2
such that
kfθo(x) - fθo(X)k2 ≤ n ≤ ɪ
fθo (X) - /fθ0 (x0)dμ∞(x0) - fθo (X) - /fθo (χ0)dμ∞(χ0)
where we assumed d ≥ 1, n ≥ K√L for some K. Combining the above bound with (D.69) and
taking a union bound over the complements of E , G gives
P \ {lfθ0(X)I ≤ √d0 ∩ ∖ ∣fθ0(X)- f fθo(XO)dμ∞(XO)
一 x∈M	H	M
≥1 -e-cd-P[Gc] -P[Ec]
≥1 - e-c0d - e-c00n ≥ 1 - e-c000d.
From the first result, we also obtain that with the the same probability kζ kL∞ ≤ 1 + √d. By
worsening the constant in the tail we can simplify this to ∣∣Z∣∣l∞ ≤ √d.
113
Published as a conference paper at ICLR 2021
Defining
Z(χ) = -f*(x) + / fθo (χ0)dμ∞(χ0),
M
since Z(x) - Z(x) = fθ° (x) - R fθ0 (x0)dμ∞(x0), it follows that
M
□
Lemma D.12. For some integer d0, assume n, L, d satisfy the requirements of lemmas D.8 and
D.14, meaning that there exist absolute constants K, K0, K00, K000, K 0000 > 0 such that for any
d ≥ max{K d0 log(nn0CM), K0 log L}, if n ≥ max{K 00 d4 L, K000L log n, K0000} then
1.	If do = 1 and n ≥ K00000 max ∣d2L, (Cκ) / , κ2/5 j where K00000 is some absolute con-
stant. κ and cλ are the extrinsic curvature and injectivity coefficient defined in Section 2.1,
then on an event of probability at least 1 - e-cd, one has
MjM±%p ≤ C
for a numerical constant c, and where the Lipschitz seminorm is taken with respect to the
Riemannian distance on M±.
2.	IfM = Sn0-1 so that d0 = n0 - 1, then on an event of probability at least 1 - e-cd, one
has
l∣fθθlsnθ-lhp ≤√d
for a numerical constant c.
Proof. We recall
fθ0 (x) = W L+1αL (x).
Let M? denote a connected component of M. Let x1, x2 ∈ M?, and fix a smooth unit-speed
geodesic γ : [0, distM?(x1, x2)] → M? such that γ(0) = x1 and γ(distM? (x1, x2)) = x2. The
absolute continuity of fθ0 M ◦ γ follows from an argument almost identical to the one employed
in the proof of Lemma B.8, and we obtain in particular the bound
distM? (x1,x2)
lfθo(χι)-fθo(X2)l = ∖jo	{γ0(t), (W1)*β0(γ(t))>dt.
Because γ is a unit-speed geodesic, we have for allt
PTγ(t)M? Y0⑴=(Y0⑴Y0⑴*) Y0⑴=Y0⑴，
and so in particular, by the triangle inequality and Cauchy-Schwarz
lfθo(xι) - fθo(x2)l ≤ distM?(xι, X2)sup ∣∣PTχM? (W 1)* β0(x)∣∣2.	(D.70)
This implies
llfθ0∖M*k ≤ χ∈uM*llpTχM*W1*β0(X)Il2 .
We next write
W1 =W1xx*+W1(I-xx*) =G1+H1.
TxM? can be identified with a linear subspace of Rn0 of dimension d0. Since it is also a subspace
ofTxSn0-1, PTxM?x = 0 and hence
PTx M? W 1* = PTxM? H 1* = PTχM*(I - XX*) W 1* = PTxM? W 1*
114
Published as a conference paper at ICLR 2021
where W 1* is a copy of W 1* that is independent of all the other variables in the problem (since
β0(x) depends only on G1).
We first consider the case d0 = n0 - 1, and subsequently the case d0 = 1. We note that
∣∣PtxM? W 1*β0(x)∣∣2 ≤ IW 1*β0(x)∣∣2 = XX (Wi1*β0(x))2 ,	(D.71)
2	2 i=1
Considering a single summand in the above expression, repeated application of the rotational invari-
ance of the gaussian distribution gives
(Wi1*β0(x))2
d 2l∣β0(χ)∣l2 2
=	n	gi,I(x)
=n IIWL+N2(X)PIi(X)II2 g2,I(x)
≤ n∣∣WL+N2(χ)∣∣2 g2,i(x)
=n∣∣i(χ)WL+1∣∣2 g2,i(x)
=n∣∣i(x)eι∣∣2∣∣WL+1∣∣2 g2,i(x)	(D.72)
where gi,I(x) is a standard normal variable that depends on i and the support patterns I(x) =
{I1(x), . . . , IL(x)}, since β0(x) depends on x only through I(x) Similarly, the dependence on x
in the first factor in (D.72) is only throughI(x). We now show how to control such terms uniformly
on M?.
Define a net Nn-3n-1/2 as in Appendix D.3.1. According to Lemma C.4, Nn-3n-1/2	≤
e3 log(CM? nn0)d0 . Assume n, L, d satisfy the requirements of Lemma D.8 and denote this event
defined in that lemma by E . We also define sets of support patterns
J (X)
L
{J1,...,JL} X ∣J' θ I'(X)∣ ≤ d
'=1
(D.73)
J
,
J(Nn-3n-i∕2 )= U J(K
CI	x∈Nn-3n-1∕2
n n0
On E, U {I(x)} ⊆ J(Nn-3n-i/2), and additionally for any X ∈ M?, then there exists some
x∈M?	n n0
x ∈ Nn-3n-1∕2 such that X ∈ Nn-3冗-1/2 (X) and I(x) ∈ J(x). We now show that on E, the
supports I(X) satisfy the requirements of Lemma D.14 with δs = d, Ks = Cn-5/2, with the anchor
point in the statement of that lemma chosen to be X. The value of δs is satisfied by the supports at
every point on the manifold on E from the definition of this event. From the definition of the stable
sign consistency property (SSC) in Appendices D.3.1 and D.3.2, the only features whose sign can
differ between X to X are the risky features, and from the bound on their norm in the definition of
SSC(L, n-3n0-1/2, Cn-3) we obtain for all `
CC
II(PJ'-Pi'(χ)) P (x)∣∣l∞ ≤ n ⇒ II(PJ'-Pg) P (x)∣∣2 ≤ n^/2
where in the last inequality we used Lemma G.10. It follows that if n ≥ KLd for some K, the
requirements of Lemma D.14 are satisfied ifwe make the choice E = EδK.
We would next like to apply Lemma D.14 for every possible support pattern in J(Nn-3冗-1/2),
which requires that We first bound the cardinality of this set. Note that J (X) is the . Thus
d
IJ(x)∣ ≤ X ( Lin) ≤ ［力
i=0
d
≤ (Ln)Cd
115
Published as a conference paper at ICLR 2021
for some C. Using the bound on the cardinality of the net from Lemma C.4, the size of this set can
be bounded, giving
「d] /	∖
J(Nn-3n-1/2)∣ ≤ W-3n-ι∕2∣X ( n ≤ ≤ e3log(CM?nn0)d0+Clog(Ln)d.	(D.74)
We can now apply Lemma D.14 with E = Eδκ to bound ||r':2(x)ei∣∣2 for all ' on E, taking a
union bound over all possible supports. Bernstein’s inequality and an exponential tail bound can be
used to bound the second factor and third factors in (D.72) respectively. Using@.74) to bound the
number of supports we need to uniformize over (since on E, U {I(x)} ⊆ J(Nr-3r-1∕2)) and
x∈M?	n n0
the bound on the size of the net in Lemma C.4 and Appendix D.3.1, we obtain
P 卜X ∈ M?:2 1E llrL:2(x)ei|l21∣WLT∣2g2,i(χ) ≤d
=P	xx e Nn-3no1/2,	. 21 ° ||rL：2(X)e ∣∣2 ll wl+i ∣∣2。2	≤ d
=P	∀X ∈ N-3n-1/2 (x) : n IE ∣∣γ (x)e1∣∣2 ∣∣w ∣∣2 gi,I(x) ≤ d
≥1-∣N	3 -1/2 ∣eclog⑺de-cn	- ∣N 3 -1/2	IeCIOgS)de-c0d	- e-c”n
∣ r-3r0	∣	∣ r-3r0	∣
≥1 - e3 log(CM?nn0)d0 + C log(n)d-cL - e3 log(Cm?nno)do + C log(n)d-c0d -『d0n
(D.75)
≥1
where we assume d ≥ K log(CM? nn0)d0, n ≥ K0Ld2 for some K, K0. Since according to
Lemma D.8 the event E holds with probability greater than 1 - ecd for some c, we can remove
the indicator in the bound above by assuming d ≥ K for some absolute constant K and worsening
the constant in the bound.
We can now complete the proof for d0 = n0 - 1. Since we are interested in bounding the sum (D.71)
n0
uniformly, we can bound	gi2I(x) as well using Bernstein’s inequality and uniformizing as above
i=1
obtain
2	n0
P ∀X ∈M?: - 1E ∣∣rL"(χ)eι∣∣21∣WLT∣2Xg2,i(χ) ≤ C(n0 + d)
n	i=1
=P	∀x∈∈ANn-3n-12	: 21E ∣∣ΓLD(x)e1∣∣2 ∣∣Wl+1∣∣2 Xg21zG< C(n0 + d)
∀x ∈ N 3 -1/2 (x)	n EH	1 1∣∣2	∣∣2	gi,I(X)-	0
n-3n0	i=1
≥1-∣N 3 -1/21 eclog(n)de-cn - ∣N 3 -1/2 ∣ec log(n)de-c0d - e-c0n
∣ n-3n0	∣	∣ n-3n0	∣
≥1 - e3 log(Cm?nn0)d0+C log(n)d-cL - e3 log(Cm?nno)do+C log(n)d-c0d - 6 —c00n
≥1 - e-c000d
where we assume d ≥ K log(CM? nn0)d0, n ≥ K0Ld2 for some K, K0. As above, we can remove
the indicator in the bound above by assuming d ≥ K for some absolute constant K and worsening
the constant in the bound. Worsening constants in the failure probability, we can replace the residual
in the above expression by d. Using (D.70), we obtain that with the same probability the Lipschitz
constant of fθ° on Sn0-1 is bounded by √d.
We now consider d° = 1. Recall that for any X ∈ M?, then there exists some x ∈ ^―冗-" such
that x ∈ Nn-3n-1/2 (X) where ^一冗-" is the net defined earlier. The gradient vector at X takes
the form
PTxMW 1*β0(x) = PTxMVW 1*β0(x) + (PTxM - PτχM) W 1*β0(x).	(D.76)
We proceed to bound the first term in the above equation uniformly over M? . Since in the d0 =
1 case TχM? can be identified with a linear subspace of Rn0 of dimension 1, we can write the
116
Published as a conference paper at ICLR 2021
projection operator as
PTxM? = VxvX	(D.77)
for some unit norm vχ. We then obtain from rotational invariance of the gaussian distribution that
IIPTxMW 1*β0 (χ)∣∣2	=IIvxv 京 ww 1*βo(χ)∣∣2
=2∣∣β0(χ)∣∣2 g2
nx
≤ n2∣∣r3(χ)eι∣∣2∣∣wL+1∣∣2 g2,
where gχ is a standard normal variable and the last bound comes from a calculation identical to
(D.72). Under the same assumptions on d, L, n as before, we can bound this expression uniformly
using (D.75), and additionally take a union bound over the net to account for all possible choices of
x. This gives
P	∀x ∈ Nn-3n-1/2,	: 21 尸 ∣∣ΓL2(x)e∙∣ ∣∣2 ∣∣ WL+1∣∣2 2- ≤ d
P	∀χ ∈Nn-3n-ι∕2(x) : n1E ∣∣γ	(x)e1∣∣21∣w ∣∣2 gx ≤ d
≥1 - Nn-3n0-1/2 e-c0d
≥1 - e3 log(CM? nn0)d0-c0d
≥1 - e-c00d
where we assume d ≥ K log(CM?nn0) for some K. This gives control of the first term in (D.76)
uniformly on M.
We now turn to controlling the second term in (D.76). For some x, choose x ∈ 纥-九-⑺ such
that X ∈ Nn-3冗-1/2 (x). Define a unit-speed curve Y : [0,s] → M such that Y(0) = x, Y(S) = x.
Since the curvature ofM is bounded by κ, we have
∀s0∈ [0, s] : kY00(s0)k ≤ κ.
Denote by r the geodesic distance between x and x0 . Since the euclidean distance between them is
bounded byn-3n0-1/-, assuming n > K for some K implies that r < C0n-3n0-1/-for some C0.
If We now demand n3 ≥ C0-κ which implies，笈 ≤ CT, (A.2) gives
cλ	n3 n0	κ
C
S ≤	1/2,
n n0
for some C > 0. For vx, vx defined as in (D.77) we have Y0(0) = vx, Y0(s) = vx. Combining the
previous two results, it follows that
∣∣vx -vx∣∣2 = kY0(O) - Y 0(s)k-
s
Y00(S0)dS0
s0=0
Cκ
≤ SK ≤ ----1/2.
n3n0

A straightforward calculation then gives
kPTxM - PTxMk
∣∣vxvx* — vxvx*∣∣ = 1 ∣∣vx- vx∣∣2 ∣∣vx + vx∣∣2
≤ ∣∣vx-vx∣∣2 ≤
Cκ
If we now use Lemma D.13 to control the norms of the backward features uniformly, a standard
bound on the norm of a Gaussian matrix to give P [∣∣ W1∣∣>c°+pno)]
≤ e-cn, and assume
n ≥ κ2∕5 we obtain that
P h∀x ∈ Nn-3n-1∕2 , X ∈ Nn-3n-1∕2 (x) : I(PTXM - PTXM) W 1*β0(x)∣ ≤ Ci
n	n0	n n0	x	x
≥ 1 - e-cd - e-c0n ≥ 1 - e-c00d.
117
Published as a conference paper at ICLR 2021
Combining the above with (D.75) and using (D.76) and taking a union bound over the failure prob-
ability of E which results in a worsening of constants completes the proof. We can additionally
rescale d to obtain a final bound on the LiPSChitz constant of √d instead of C√d, which also results
in a worsening of constants.
□
Lemma D.13. There are absolute constants c, C > 0 and absolute constants K1 , . . . , K4 > 0 such
that for any d ≥ Kd0 log(nn0CM), if n ≥ K0d4L, then there exists an event E such that
1.	On E, we have
∀' ∈ [L], <β'-1(x), β'-1(x0)>- 2 γi(1- d(0(∠∏x XO)) )| ≤ C √d4nL
simultaneously for every (x, x0) ∈ M × M;
2.	P[E] ≥ 1 - e-cd.
Proof. Let E1 denote the event studied in Lemma D.8, with C0 denoting the absolute constant ap-
pearing in the SSC(L) condition there; choose d ≥ Kd0 log(nn0CM) and n sufficiently large to
make the measure bound applicable. We will need to apply Lemma D.23 together with a derandom-
ization argument to prove the claim; we appeal to the same residual checks at the beginning of the
proof of Lemma D.6 to see that on Ei, the dominating residual in Lemma D.23 under the scalings
of d and n We enforce here is of size C√d4nL.
For any subset S ⊂ [L] X [n], We write s` = {i ∈ [n] | (', i) ∈ S}, and We define S(S)=
{-1, +1} | S1 | × …×{-1, +1} | SL | for the set of “lists” of sign patterns with sizes adapted to these
projections of S, with the convention {-1, +1}0 = {0}. If Σ = {σ1, . . . , σL} ∈ S(S) is such a
list of sign vectors and ∆ ≥ 0, we define
I'(x, S, ς,	= SUPP (1ρ'(x)>Pi∈S'((σ')i∆)ei),
which is a sort of two-sided robust analogue of the support of α'(x): notice that when S = 0 we
have l`(x, S, Σ, ∆) = I'(x). We also define for ' = 0,1,...,L - 1
βS ∑∆ (x) = (W L+iPf (S S ∑∆∖ W LPI	S S ∑∆∖... W '+2P*? (…∑∆∖Y,
s,ς,δ'	y	IL(X,s,ς,δ)	IL—i(x,s,ς,δ)	I'+ι (x ,S, ς, △) J
a generalized backward feature induced by these robust support patterns. Writing for concision
βS-,Σ,C0n-3 (X), βS0,Σ0,Con-3 (XO)E
SX,x0,S,S0,∑,∑0 = ∃ ∃' ∈ [L]
-n QL-I	11 - W('0)(/(X,x0))
> Ci -∖∕d4nL log4 n
where Ci > 0 is an absolute constant we will specify below to make the event hold with high
probability, we then define the event11
E2 =	U U U	SX,X0,S,S0,∑,∑0,
X∈Nn-3 S⊂[L] × [n] Σ∈S(S)
X0∈Nn-3 S0⊂[L]×[n] Σ0∈S(S0)
iτ ∣S∣≤d,∣S0∣≤d
There are no more than Pd=0 (nL) ≤ n4d ways to choose the subset S in this union, and for
a fixed S there are no more than 2d ways to choose the sign pattern Σ. Thus, there no more than
11To see that this set is indeed an event, use that βS,∑,∆ (x) is a continuous function of the network weights
except with respect to the support projections; but x 7→ 1x>0 is increasing, hence Borel-measurable, and so
the set consists of a finite union of Borel-measurable sets.
118
Published as a conference paper at ICLR 2021
exp(10d log n+ 12d0 log(nn0CM)) elements in the union, and under the condition on d this number
is no larger than n11d. For concision, write
ξ`(x,χ0) = 2Li(I- *(∠Jχ,x0))!.
" '0=' ∖	π	)
For any instantiation of these parameters, Lemma D.23 and a union bound give
Ph∃' ∈ [L] : KβS,Σ,Con-3(x), βS0,Σ0,C0n-3(XO)E-ξ'-1(X，XO)I > C√d4nLi
≤ p[ec] + p[∃' ∈ [l] : ∣ieiDeS-1,c0n-3(X),βS-,∑o,c0n-3(x0)E T'-ι(χ,χ0)| > C√dnL]
≤ e-cd
for any d ≥ K log n and n ≥ KOd4L. Thus, if we set C1 = C and enforce d ≥
Kd0 log(nn0CM)/ log n and n ≥ max KOd4L log4 n, we have by a union bound
P[E1 ∪ E2] ≤ n-cd.
Let G = Ec ∩ Ec. For any (x, x0) ∈ M× M, we can find a point X ∈ Nr-3 n-1/2 ∩Nr-3r-ι∕2 (x)
and a point X0 ∈ N∏-3n-1/2 ∩ Nn-3n-1∕2 (xo). On G, SSC(L, n-3n-1/2, Cn-3) holds at every
point in the net Nr-3r-1/2, and there are no more than d Cn-3-risky features at any point in the net
Nr-3 r-1/2, and in addition, following (D.52), we have almost surely on G that all risky features are
realized for magnitudes in (-∆, +△). This implies that on G, the support sets F'∈[L] I'(x) at any
point X ∈ Nn-3n-1∕2 (X) differ by the support sets F'∈[L] Ig(X) at the base point in the net by no
more than d entries, consisting only of a subset of the risky features at X; the analogous statement is
of course true for x0 and X0. At the same time, notice that on the event Ec We have constructed, We
have control of every possible backward feature inner product obtained by modifying the supports
at the base points X, X0 at no more than d risky features (each), since, for example, if (ρ`(X))i is
risky, then 1(ρ'(χ))i>∆ corresponds to “turning off” the feature, and 1(ρ'(χ))i>-∆ corresponds to
“turning on” the feature. Formally, We have established that on G
∀' ∈ [L],
L-1
(β'-ι(X),β'-l(Xo))- nn ∏
2 '0='-1
1 - d' )(∠(x, XO))) | ≤ CIqd4nLlog4 n
We can use differentiability properties for the remaining link: folloWing the proof of Lemma D.10,
we have
∣∠(x, x0) - ∠(χ, χ0)∣ ≤ √2∣∣χ - x∣∣2 + √2∣∣χ0 - x0k2 ≤ 2n32,
so we just need a Lipschitz property for the function q(ν) = (n/2) QL='(1 - π-1 夕('0)(v)). For
this we appeal to Lemma E.5, which shows that the function 夕 is smooth, increasing and concave;
therefore by the chain rule, the functions 夕(')are increasing and concave, and by the Leibniz rule, q
is decreasing and convex. It therefore suffices to calculate q0(0); this is done in Lemma C.18, which
gives qo(0) = -n(L - ')∕(2π), and in particular ∣q0(0)| ≤ cnL. It follows
L-1
2 ∏	1 -
'0=' ∖
y('0)(∠(X, X0))
π
L-1
'0='
1-
d'0)(∠(x, X0))
π
-n ∏
so that by the triangle inequality
∀' ∈ [L], <β'-1(x), β'-1(x0)> - 2 ∏ (1 - d')(∠(x, XO))) | ≤ 2CMd"nLlog4 n,
where the residual simplification is valid when n ≥ KL. We conclude that the set
\	{∀' ∈ [L], Kβ'-1(x), β'-1(x0)) - ξ'-i(X, x0)1 ≤ 2Cι Jd4nLlog4 n
(x,x0)∈M×M
contains the event G, which satisfies the claimed properties and completes the proof (after rescaling
d by 1/ log n, which updates the lower bound on d).	□
119
Published as a conference paper at ICLR 2021
D.3.4 Small S upport Change Residuals
In this section, we prove generalized versions of our pointwise concentration lemmas for back-
ward feature correlations and the matrices defining the propagation coefficients used in our study of
SSC(L).
Lemma D.14. Assume n ≥ max {KL log n, K0Ld, K00}, d ≥ K000 log L for suitably chosen
K, K0 , K00 , K000 and integer L, and choose 1 ≤ `0 ≤ ` ≤ L. Define an anchor point x ∈ M
and denote Ii(x) = supp αi0(x) > 0 for `0 ≤ i ≤ `.
Choose some δs,K > 0 and let J = {J',..., J'} denote a collection of support sets such that
each Ji ⊂ [n] depends on the network parameters only through the pre-activation ρi0(x). We define
events implying that the supports at J are close to those at x:
Eδ = ∩ {∣Ji θ Ii(χ)∣≤ δs},
'0≤i≤'
EK = \ {∣∣(PJi- PIi(X)) ρi(x)∣∣2 ≤ Ks},
'0≤i≤'
EδK = Eδ ∩ EK .
Define
Γj'0 = Pj' W 'Pj'-1 ... Pj'0 W '0,
and fix a unit norm vector Vf. If Ks ≤ 2 L-3/2 , δs ≤ L, then
ph1Eδκ∣∣rJ'0Vf∣∣2 ≤ Ci ≥ 1-e-cn,
and
P[lEδκ∣∣Γj'0∣∣ ≤ C√∑i ≥ 1-e-cn.
Fora vector g, gi 〜逋 N (0,1) ,defining Hi = Wi (I 一 αi-1(x)αi-1(x)*) for i ∈ [L] and
ΓHJ = Pj'H'Pj'-1... Pj'0 HH
we have
P [lEδκ ∣∣ (rJ'0 - ΓHJ) g∣∣2 > C√dL] ≤ e-cd
for some numerical constants c, C.
Proof. In the following, we will denote by vf ∈ Sn-1 a fixed unit norm vector and by vu ∈ Sn-1
a random vector uniformly distributed on Sn-1. When there is no need to distinguish between the
two we will denote either by vp .
Our strategy in bounding 1ejk ∣∣ΓJ'0∣∣ will be first to bound 1ejk ∣∣ΓJ^0 Vf ∣∣ with sufficiently high
probability, and then apply an ε-net argument to uniformize the result (lemma D.20) and get control
of the operator norm. In achieving the first goal, we will rely heavily on a decomposition of the
weight matrices into terms that are conditionally independent given the pre-activations. We will also
utilize martingale concentration to control the terms that result from this decomposition.
Denoting Si = span αi(x) for i ∈ [L], we decompose the weight matrices into
Wi = WiPSi-1 + W iPSi-1⊥ =. Gi +Hi.
Note that H1, . . . , HL are conditionally independent given σ(G1, . . . , GL) (by which we denote
the sigma algebra generated by G1, . . . , GL). Since the pre-activations obey
ρi(x) = Wiαi-1(x) = Giαi-1(x)
120
Published as a conference paper at ICLR 2021
and the features are deterministic functions of the pre-activations, both α1 (x), . . . , αL(x) and
ρ1(x), . . . , ρL(x) are measurable with respect to σ(G1, . . . , GL).
We define events
`
EP = \ {∣∣pi(x)∣∣2 ≤ C}, EδKρ = Eδκ ∩Eρ
i='0
(D.78)
and aim to control 几勺 ∣∣Γjj'0(x)∣∣. Since the supports J depends on the weights only through
the pre-activations and are thus also σ(G1, . . . , GL)-measurable, this truncation does not affect the
conditional independence of { H'0,..., H' }. It will often be convenient to utilize the rotational
invariance of the Gaussian distribution to replace all occurrences ofH i in a given expression by
WiPSi-1⊥ where Wi is a fresh copy of Wi independent of all the other variables in the problem,
which will not change the distribution of the original expression.
For `0 ≤ i ≤ `, `0 ≤ j ≤ i + 1 it will also be useful to denote
FiHJ = PJiH HPJi-I …PJj Hj, Γj = PJi GPJi-I …PJjGj
where We use the convention ΓGJ1 = ΓH J1 = I. Decomposing the weight matrices at every layer
gives
∣∣rJ'0vp∣∣2 = ∣∣PJ' (G'+H')... PJ'0 (G'0+H '0) vp∣∣2
≤	X	∣∣PJ'M'…PJ'0M'0Vp∣∣2.	(D.79)
(M ',...,M '0 )∈(G',H')私…候(GJH'0)
We next define
Qi(x) = PJi - PIi(x) .
(D.80)
In accounting for all the terms in the decomposition (D.79), there will be two simplifications that we
use repeatedly. One is
Hi+1PjτPi(X) = Wi+1 ( I - ai?%* ) (Pai(X)>o + Qi(X)) Pi(x) = Hi+1Qi(x)ρi(x)
kαi(x)k2
(D.81)
where we used Pαi(x)>0Pi(X) = Pi(X) + = αi(X), from which it follows that
Hi+1PJiGi
=Wi+1 (I - HlX) ) (Pai(X)>0 + Qi(X)) Pk(Xi)lx；?
=Hi+1Qi(X)Gi.
(D.82)
We also have
Gi+1PJiGi
=Gi+1(Pii(x)+ Qi(X)) Gi
=Wi+1ai(X)ai(X)* (Pi,(X)+ Qi(X)) Wiai-1(X)ai-1((X)*
kai(X)k2 -(X) W1))	kai-1(X)k2
∣∣ai(x)∣∣2 Λ +
kai-1(χ)k21十
αi(X)*
kai(x)k2
Qi(X)Wi a-(X)) Wi(Xa]xaa-1(Xχ)2
. Wi+1αi(X)αi1(X)*
--Q ----------------
=i kai(x)k2 kai-l(x)k2 ,
and thus
Γi j
ΓGJ
i1
Ysk
k=j
PJi W iai-1(X)aj-1(X)*
kai-1(X)∣∣2 kaj-1(X)∣∣2
Y	PJi Pi(X)ajτ(X)*
kj kai-1(X)k2 kaj-1(X)k2.
(D.83)
121
Published as a conference paper at ICLR 2021
We refer to such a product as a G-chain. We proceed to expand (D.79) into terms with different
combinations of matrices ΓGj and ΓHj . There will be 2'-' terms in total, and We denote the set
of terms with r G-chains by Gr,p (with the subscript p ∈ {u, f} denoting the choice of vector vp).
We can clearly label each term by the start and end index of each G-chain, which may not be distinct.
We denote each such term by g(rip ,i ,...,i ) where
' ≤	iι ≤ i2 ≤	i3 — 2 ≤ i4 — 2 < i5 — 4 ≤ …≤ i2m-1 - 2m + 2 ≤	i2m	— 2m + 2 ≤	...
一 — 一 ≤i2r-1 - 2r + 2 ≤l2r - 2r + 2 ≤ ' — 2r + 2.	一
(D.84)
The constraints above ensure that every two G-chains are separated by at least one Hi matrix. To
lighten notation, we denote a set of indices obeying the constraints by (i1,...,i2r) ∈ Cr (','0). The
maximal number of G-chains possible is bounded by r ≤「(' -'0) /2.
Since the g(rip ,i ,...,i ) are non-negative, we have
('-'0)/2
1EδKρ"j'0 VP]? ≤ 1EδKρ (γHJ VP]/	X	X	g(Zi2,...,i2r).	(D.85)
r=1	(i1,...,i2r)∈Cr(','0)
Considering first the form of the terms in Gr,p, using (D.83) and (D.81) and recalling that ΓHjhm
I, we have
r,P	]	'：i2r +1 i2r ：i2r-1	i2r-1 -1：i2r-2 +1	i4 ：i3 i3 -1：i2 +1	i2 ：i1	i1 -1：'0	]
g(i1,i2,...,i2r)	= ]ΓHJ	ΓGJ	ΓHJ	...ΓGJ ΓHJ	ΓGJ ΓHJ VP]2
1EδKρ
|
r'：i2r + 1 PJi2rPi2r (X)
HJ	kαi2rT(X)k2
2
sz
=ai2r
r-1	i2m+2 -1
*Y1EδKρ	Y Sk
m=1	k=i2m+1 +1
I___________________
αi2m+1 (χ)*rHj+1 Ti2m + 1PJi2m ρi2m (x)
kαi2m+(x)k2 kαi2m-1(x)k2
"{^^^^^^^^™
.~
=b√ _	_ √ _
= i2m+2,i2m+1 ,i2m
i2 -1	0
Q Skαi1(x)iTHj1* Vp
* 1Eδ.
k=i+1
Kρ
kαi(x)k2
{z^^
:ci2,i1
r-1
= ai2r	i2m+2,i2m+1,i2m ci2,i1 .
m=1
(D.86)
The magnitudes the factors in this expression are bounded in the following lemma:
Lemma D.15. For ak, Bqij ,Cps defined in (D.86), RU = y d, Rf = 1 and ' ≤ k < ', ' + 2 ≤
j +2 ≤ i ≤ q ≤ `, `0 < S ≤ t ≤ `
a`
P [ak > Ks]
∣bqij I > √Ks
K'o | > CRp
% > qd
≤ C a.S.,
≤	C 0e-c L,
≤	C 0e-cL,
≤	2e-cd + e-c0n ,
≤	C 0e-cL + 2e-cd
for some constants c, c0 , C, C0 and d ≥ 0.
P
P
P
}
}
122
Published as a conference paper at ICLR 2021
Proof: Deferred to D.3.4.
We will use these results in order to bound 1EδK
vp	using (D.85). While the sum over most
of these terms can be controlled using the triangle inequality and the lemma above, there is a subset
which will require special treatment since they are typically larger. These are the terms where the
leftmost or rightmost chain is a G-chain (meaning i2r = ` or i1 = `0 respectively) and they will
be controlled using martingale concentration. The or above is exclusive, since we can bound terms
with i2r = ` and i1
广 →	→
r,p , r,p ,
`0 using a triangle inequality. We denote these three sets of terms by
r,p respectively, and elements in them by 句r,p, →r,p, →r,p for clarity when needed.
Arranging the remaining terms into sets denoted Gr,p, the sum in (D.85) decomposes into
S0)/2]
g(ri1,i2,...,i2r)
r=1	(il,…,i2r)∈Cr (','0)
g')∕2]
X
r=1
Qr,p∈{Gr,p,G-r,p W r,p , Er,p } g" ∈ Qr，p
gr,p
We consider first terms in G-r,p (and hence with i2r = '). We denote such terms by
(D.87)
Σ
We show
r-2
g (il,i2,…,i2r-1 ,') = a'b',i2r-1,i2r-2 " bi2m+2 ,i2m + 1 ,i2m /,ij
m=1
Lemma D.16. ForP ∈ {f, u} and RU = Jd, Rf = 1
i.
ii .
S0"
X X	芍r,p
r=1 方 r,p∈言 r,p
≤ Ce-Cd + C0e-c0 n
(D.88)
P
P
S0)/2]	-
X X	→r，p	>CRp	≤ Ce-Cd + C0e-c0 n
r=2	-→g r,p∈-→Gr,p
(D.89)
for absolute constants c, C, C0, and where d ≥ K log L for some constant K.
Proof: Deferred to D.3.4.
Turning next to bounding the terms in →r,p,
we first define an event
{∣a'l ≤ C}
∩ ∩ {∣≡P1'0∣≤CRp}
'0<iι≤'

and from lemma D.15 and a union bound obtain
P [WCi ≤ L3C0e-cn + L(2e-cd + e-c0n) ≤ CC0e-L + 2e-c"d
123
Published as a conference paper at ICLR 2021
assuming n ≥ KL log L, d ≥ K0 log L for some K, K0. It follows that
1 → E 可 r,p
→	∈→
g r,p∈ 5 r,p
g')/2]
1→ X	X
r=1	(i2 ,…,i2r-1 )∈Cr-1 (e,g)
r-2
a'b',i2r-1 ,i2r-2 ] ] bi2m+2 ,i2m +1 ,i2m ,i2,20
m=1
g')/2]
≤X	X
r=1	(i2,…,i2r-1)∈Cr-1(',')
g')/2]
≤ X	L2r-2
r=1
r-1
Rp
r-2
1→ a'b',i2r-1,i2r-2 ^^2m+2 ,i2m+1 ,i2m ci2 ,20
m=1
(W	3/2、r-1	I-(KSL3/2)L/2
E	(KSL	)	Rp ≤ 一1 - K L3/2 一 Rp ≤ 2Rp.
r=1	S
where We used L3/2K§ ≤ 1. We also bound the number of summands in	P	by
(i2,…,i2r-1)∈Cr-1(',')
L2r-2 which is tight for small r. It follows that
→	∈→
g r,p ∈ 5 r,p
→	∈→
g r,p ∈ 5 r,p
+ P(I- 1→ ) Σ → r,
∖p
→	∈→
g r,p ∈ 5 r,p
P [→Ci ≤ Ce-cn + 2e-c0d
(D.90)
P
E →r,p > 2Rp
≤ P
1→	ɪ2	→r,p > 2RP
> 0
for appropriate constants. It remains to bound the terms in Gr,p by a similar argument. Defining
E = ∩	{∣ai11 ≤ Ks}∩	∩
` ≤i1<'	'0 + 2≤i1+2≤i2≤i3≤'
∩	∩	( %1I ≤
'0<i1≤i2≤' I
truncating on this event gives
⅜ X	gr,p ≤ ⅜ X	Igr,p I ≤ (L3/2KS)
gr,p∈GT,P
gr,p∈ Gr
,P
r严≤ 2产
nn
and bounding the probability of this even from below using lemma D.15 and a union bound gives
P
E	gr,p
gr,p∈Gr,p
dL
> 2V募
≤P
1E Σ	gr,p
gr,p∈Gr,p
>2
≤ Ce-cn + 2e-c'd
124
Published as a conference paper at ICLR 2021
Combining the bound above with (D.90) and the results of lemma D.16 and worsening constants,
the sum of all terms containing matrices Gi is bounded by
P
gr,p
gr,p ∈Gr,p
p
Qr,p∈{ Gr,p, G r,p O
gr,p∈Qr,p
gr,p
+P
Qr,p ∈n G r,p , G r,p o
gr,p > CRp
gr,p∈Qr,p
Σ
≤C 0e-cn + C 00e-c0d.
(D.91)
Bounding the first term in (D.85) using lemma D.18, setting P = f above and choosing d = L gives
> c] ≤ C0e-c0 n.
We then apply lemma D.20 to obtain
P [lEδκ. ∣∣ΓJ[∣ >C √L] ≤ C 0e-c0n.
Recalling (D.78), to obtain our final bound on the operator norm it remains to control the probability
of Eρ. We consider some `0 ≤ i ≤ ` and assume αi-1(x) 6= 0 (otherwise ρi(x)2 ≤ C with
probability 1). Defining an orthogonal matrix R such that Rαi-1(x) = αi-1(x)2 eb1, rotational
invariance of the Gaussian distribution gives
IlPi(XM2 = α^i-1(x)*Wi*Wiαi-1(x) = ∣∣αi-1(x)∣∣2 ||w(i：,i』2 ,
WEiρi(x)22 = 2αi-1(x)22.
Since IIIW(i:,1) III is a sum of independent sub-exponential random variables with sub-exponential
norm bounded by C, Bernstein,s inequality (lemma G.2) and D.2 give
Ph∣∣Pi(χ)∣∣2 >Ci ≤P]∣∣Pi(χ)∣∣2-∣∣ɑi-1(χ)∣∣2 > Cl∣∣αi-1(χ)∣∣2 ≤ C
+P ∣∣αi-1(X)∣∣2 > C
≤ 2e-cn + C0e-cn ≤ C00e-c0n
for appropriate constants. Taking a union bound over i gives
P [Eρ] ≥ 1 - CC0Le-n ≥ 1 - C00e-c"n
for a suitable chosen constant c00, where we used n ≥ KLlogL for some K.
We then have
P h1EδK ∣∣γJ'0Vf ∣∣2 > ci ≤ P h1EδK∩Eρ ∣∣γJ'0Vf ∣∣2 > ci + P h1EδK∩Ec ∣∣γJ'0Vf ∣∣2 > 0i
≤ P [lEδκ∩Eρ ∣∣ΓJ'0Vf∣∣2 > Ci + P [Ec] ≤ Ce-Cn + C0e-c0n ≤ C00e-c"n
for appropriate constants, and similarly
P[lEδκ∣∣Γj'0∣∣ >c√Li ≤ C00e-c"n.
This concludes the proof of the first two statements. For the final result, we consider a vector g with
gi 〜iid N(0,1). Bernstein,s inequality gives P [∣∣g∣∣2 > 2n] ≤ e-cn and since
g =d Vu kg k2
125
Published as a conference paper at ICLR 2021
where vu is uniformly distributed on Sn_1, we can use D.91 setting p = u to obtain
P[∣∣(巧:'(x)-FHJ(x))g I I 2 >c√dL] ≤P ∣∣(琦'(χ)-FHJ⑺)vu ∣ ∣ 2 >C2冲#
+ P[kgk2 > 2√n]
≤ e-cn + C'e-c'd + C00e-c”n ≤ C"'e-l0"'d.
for appropriate constants, where we assumed n > KLd for some K.	□
Corollary D.17. Defining
Γ* (x) = Pie W ePιe-1 ... Pιe, W '0,
under the same assumptions on n, L in D.14 we have
P h I ∣ Γ'*' (X)V ∣ I 2 ≤ C] ≥ 1 -e-cn
P [ ∣ ∣ Γ'*' (x) ∣ ∣ ≤ C√L] ≥ 1 - e-cn
for some numerical constants c, C.
Lemma D.18. Fix a collection of supports J = {Je>... J'} for 1 ≤ ` ≤ ` ≤ L that satisfy the
assumptions of lemma D.14 and denote by VP a unit norm vector. Define an ^vent
EH = {1Eδ ∣∣ΓHJVp∣∣2 ≤ C} ∩ {1Eδ ∣∣ΓHJ∣∣ ≤ C√L} ∩ {1Eδ ∣∣ΓHJ∣∣F ≤ Cnj .
If n ≥ KL log n for some constant K then
P [Ef0] ≥ 1 - C0e-cn
where c, C, CC are absolute constants.
Proof. In the following, we denote by Wi an independent copy of Wi, and by Wj §)the j-th
column of this matrix. Note that due to rotational invariance of the Gaussian distribution we can
replace every occurrence of Hi in an expression by WiPsi-ι± without altering the distribution of
the expression, which we will do presently. We can repeatedly use this rotational invariance to give
VPrHJ ΓHJ VP= VP H ',*Pj', γJγJ1 Pje，H H Vp
d 2,*P /	W'/*Pτ r'：'/ + 1*γ':' / + 1Pτ W'/ P /	2,
=vPPSe 0-1⊥ w	PJeOrHJ rHJ PJe> W PSe 0-1⊥VP
and rotational invariance of the Gaussian distribution gives
VPrHJTHJVP = IlPSeuVp∣∣2 W^)Pje,ΓHJ1*ΓHJ1Pje,W^)
= IlPSe 0⊥ VpI2 WH,1)Pje,Pseo+ι⊥ W‘+1*唱，2*唱；+%〃十]W'0+1Pse0+ι⊥Pj, W^)
=IPs'，⊥ Vp∣∣2 ∣∣Pse0+1⊥ J W^)[ W'犷儿+iγHJ2*γHJ2 J+1 WS)I
and continuing in a similar fashion we obtain
'T	C	C
VPrHJTHJVP = IlPSeuVpk2 ∏ ∣∣Psi+1⊥PJiW(i,1)∣∣2 ∣∣PjeW(',1)∣∣2
i='0
'	2
≤ ∏ ∣∣PjiWi.1)∣∣2 a.s.
i=H,
126
Published as a conference paper at ICLR 2021
where in the last inequality we used the fact that multiplication by Psi⊥ cannot increase the norm
of a vector. Denoting by {χi} a collection of independent standard chi-squared distributed random
variables where Xi has ∖Ji∖ degrees of freedom, we have
'	'
∏ ∣piWM2 = ∏ - Xi∙
i='	i='
Define
EL{段"(χ)∖≥ 4} ∩ {∏ -j≡≤2) ∙
Denoting δi = JJi ㊀ Ii(x)∖ , on EI we have
n n
min
'0≤i≤'
n
∖ji∖ ≥ 4 -
(D.92)
L ≥ 8 .
∏2 ∖ Ji∖
n
i='0
V ∏ 2 (∖∕i∖ + δi) V ∏ 2 (∖∕i∖ + n) = ∏ 2 ∖Ii∖ Λ
—ɪɪ n — ɪɪ n	ɪɪ n k
i='	i='	i='0	、
≤ ∏ -≡ (1 + 4) ≤ e4 ∏ -≡≤ 2e4.
nL	n
i='0	∖	/	i='0
1 + l∖I~∖
where we used the assumption δi ≤ L and assumed n ≥ 8L. It follows that
P
' 2
∏ -Xi
n
i='
∏ 2 ∖ji∖
-U 丁
i='
> 1 Eδ ∩ EI
=P
≤P
`
∏ X - 1
U ∖ji∖
'
∏ X - 1
U ∖ji∖
'
∏n
∩EI
i='0 Iil	.
> TTT Eδ ∩ EI .
An application of lemma D.26 and (D.92) then gives
P
`
∏ X -1
U ∖Ji∖
1
＞参
Eδ ∩EI
≤ CLe-cn ≤ Ce-c'n
(D.93)
for appropriate constants, assuming n ≥ KL log L for some K. Using D.30 to bound P [Ef] we thus
have
P [1EδVprHjrHJvp > 1 + 2e4]
≤P
电 ∏ 2 Xi > 1+ ∏ 叫
δ ɪnn	LLn
, i='	i='0
≤P
≤P
' 2
∏ —Xi >
n
i='0
1+ ∏出
n
i='0
Eδ
' 2
∏ —Xi >
n
i='0
1+ ∏出
n
i=i'
Eδ ∩EI
+ P [EIc]
≤ Ce-Cn + C0e-c'n ≤ C00e-c" n
for some constants. Having shown
P [iEδVPrHJrHJVP >c] ≤ C0e-cn
for some fixed VP = Vf we can now apply lemma D.20 to obtain
P [1EJrHH > C√L] ≤ CC0Le-n ≤ C"e-c"n.
127
Published as a conference paper at ICLR 2021
where we used n ≥ KL log L for some K. Choosing vp = ebi for i ∈ [n] and taking a union bound,
one obtains
2n
P iEδ ∣∣γHJ∣∣f > Cn = P [iEδtr [rH>Hj] > Cn] = P £电由HJrHJbi > Cn
i=1
n
≤ XP [lEδmHJrHJbi >c] ≤ nC00e-c"n ≤ CCeT
i=1
for some constants, where we used n ≥ KL log n for an appropriate constant K . A final union
bound over the last three events gives the desired result.	□
Proofoflemma D.15. We first consider the terms <⅛. For k = ', the definition of EδKρ in (D.78)
gives
1	∣∣rHjipj'ρ'(x)∣∣2 = 1 Haρ'(χ)∣∣2 ≤
a EδKρ kα'-1(χ)k2	= EδKρ kα'-1(χ)k2 ≤	..
(D.94)
In order to handle the case `0 ≤ k < ` , we use (D.81) and obtain that for any 2 ≤ j ≤ i ≤ L,
rij P	PjT(X)
HJ Jikaj-2(x)k2
riH:jJ+1PJjHjPJj-1
PjT(X)
kaj-2 (x)k2
riH:jJ+1PJjHjQj-1(x)
PT(X)
ka"(x)k2
=riHj+1Pjj WWj Psj-1⊥ QjT(X)PT(X)
d
rHJ1PJjW(jJ)
IlPSj-1⊥ QjT(X)PT(X) ∣∣2
kaj-2(X)k2
j
where Wj is an independent copy of Wj, and we denote by W(j:,1) the first column of Wj, and we
used the rotational invariance of the Gaussian distribution. Truncating on the event EHi,j+1, which
j
does not affect the distribution of W(j:,1), we have
彳EE II1EHj+1 rH+1PJjWj,1)∣∣2 = n 1EHj+1 tr hPJjrH+1*rHj1i
W(:,1)	2
≤ n 1Ei,j+1 tr hrH+1* rHj1i
=n 1EHjT∣rHJIIIF ≤C 0
almost surely for some constant C0, and the Hanson-Wright inequality (lemma G.4) gives
P ]∣∣1EHj+ι rHJ1PjjW(j,i)∣∣2> 1+C 0
≤ 2 exp
≤ 2 exp
for some constant c , where we used ∣∣1Ei,j+1ΓHJ1*ΓHJ1∣∣F ≤ II1Ei,j+ι rHJ11∣ ∣∣rHJ11∣ ≤
Cn(i - j + 1), and the fact that multiplying a matrix by PJj cannot increase its norm. Writing for
concision in the subsequent expression
A=IIIrHJ1PJjW(jJ)IL - 1Ei,j+ι IrHJ1PJj %j)∣∣2∣
128
Published as a conference paper at ICLR 2021
it follows that
PhkHJ+1PjjW(j,i)∣∣2 > C 00i ≤ PhIEiHj+ι IIrHJ+1PjjWj,i)∣∣2 > C00 i+P[A> 0]
≤ 2exp (-c0n) + C exp (-c00n) ≤ C0 exp (-4)
for appropriate constants, where we used D.18. Since on EδKρ we have
PSj⊥ Qj(X) j⅛
Qj (X) PJT(X)
Q ( )kɑJ-2(x)k2
≤ 2Ks ,
2
≤
2
we obtain
hence
P 1EδKρ rHJPJj-I 卷-2 ((X))k2
> 2C00Ks ≤ C0 exp
2
(D.95)
P [ak > Ks] ≤ C exp (-c0 n)
(D.96)
n
for appropriate constants.
-I-V T	.	.	. 11 ∙	. 1 7	TL T . . )
We now turn to controlling the bqij . Note that
∖q
1EδKρ ∖∖	sk
k=i
1	kαq (x)k2
EδKρ kαi-1(x)k2
Yq	1+
k=i
αk(x)*
kak(X)k2
Qk(x)Wkαk-1(x)
(D.97)
≤ 3(1 +2KJ )q-i ≤ 3e2KJ L ≤ 9 a.s.
where in the last inequality we used 2KJ L< 1. Additionally, we have
1	ai(X)* ri-1j+1 P	Pj(X)
EδKρ kai(X)*k2 HJ	Jjkaj(X)k2
=d 1EδKρ
1EδKρ
ai(X)*PJi-ι
kai(X)*k2
ai(X)*PJi-ι
kai(X)*k2
W i-1psi-2⊥ MF ɪ
W i-1u = σg
where Wi-1 is an copy of Wi-1 that is independent of all the other variables, We defined
U = PSi-2⊥ Γi-γj+1 PJ U Pj(X)U
HJ	Jjkaj (X)k2
and g is a standard normal variable. In the above expression,
σ2 = lEδKρn ∣∣ai(X)*PJi-ι/ ∣∣ai(X)*∣∣2∣∣2 ku∣∣2 ≤ 如/
Note also that riH-J2:j +1 is well-defined since i ≥ j - 1.
We therefore have
p [∖1EδKρ k⅛⅞⅛ riHjj+1pJj j⅛
≤ P [lEδKρ kuk2 >Ks] + p∖∖g∖∣n Ks >
≤ C0e-cn + 2e-c0 L ≤ C00e-cn
2 kuk2
n
(D.98)
where we used (D.95) and the Gaussian tail probability to bound the first and second terms in the
second line respectively. Combining the above with (D.97) we obtain
P
∖bqij∖ > √s	≤ C00e-cn.
(D.99)
129
Published as a conference paper at ICLR 2021
We now turn to controlling cp-i. If i ≥ ' We have
j-1	.
∏ Skai+1(x)*
cP,i+1 = 1ESKp
k=i+2
∣∣ai+S∣∣2
j-1	, T
(D.100)
=IESKP
∏ Skαi+1(x)*Pji
k=i+2
∣∣ai+i(x)*∣∣2
Wi PSi-1⊥ T J VP = σg
where g is a standard normal and
2 F 2 ( j-
σ = 1Esκp n ∏ Sk
k=i+2
2
IPSiT⊥rHfJ' vp||2 ≤ 1ESKp
2C
for some constant C where We used (D.97). We also have (r-'Vp
D.18 and a Gaussian tail bound then give
≤ C on ElW . Lemma
P I≡P,i+1I >
1ESKpCEi-1,“
j∏1 « αi+1(x)*Γ¾J V
工“ kαi+1(X)*k2
、jτ
∏ Sk
k k=i+2
> √d
αi+1(x)*rHj V
kai+i(x)*∣∣2
THJ VP
n
FHfJe vp∣∣2 a∙s∙
2
2
P
+P (1EδK. - 1Eδκ.∩E31,”
> 0
≤ P ]ΠCg > /I] + p[(ELe)Ci ≤ 2e-cd + Ce-c0n
for appropriate constants.
Additionally, if i = ' — 1 we have from (D.97) for some fixed VP = Vf
(D.101)
j-1
IfI= 1ESKp Π
k=20 + 1
j-1
Wk. Π
k=0 + 1
j-1
F. Π
k=' + 1
α’(χ)* γ0-1:'-.
Skpf⅛ γhj Vf
ae0 (x)*
Sk W (到 2 Vf
Sk ≤ 9 a.s.
(D.102)
If however VP = VU is drawn from Unif(Sn-1), if we denote by g a vector with independent
standard Gaussian entries we have
α',(χ)* V =蕾 V
IESKP kα”(x)k2	e1
From Bernstein,s inequality it follows that P [∣∣g∣∣2 < 外 ≤
tail bound gives
d	gι
=----.
回2
e-cn. Combining this with a Gaussian
P
d
> V 2
g1
≡7
d
> Vn
≤ P [kgk2 <2]
+ P ∣gιl
≤ e-cn + 2e-c0d
for some constants c, c0. From (D.97) it follows that
P I j I
Id
> Vn
一	j-1
P	1ESKp
k=20 + 1
α' (x)*
d
> Vn
≤ e-cn + 2e-c0d
Sk Exl7VU
for appropriate constants.
□
130
Published as a conference paper at ICLR 2021
Proofoflemma D.16. Part (i). We denote the set of all such terms with r G-chains
sidering first the contribution from the terms with a single G-chain, denoted t?
by G-r,p. Con-
ip, We have
`
X 芍1,p = a' X %
方 1∙p∈⅛ip	3=', + 1
where
'	'
X % = X 1EδK
j=20+1	j=20+1
'-1	.	- -I .«/
∏	Skaj(x)*ΓHj' vp
k=j + 1
Il aj (x)k2
P
Denoting by σ(A1,..., Ak) the sigma-algebra generated by a the random variables Ai,..., Ak, we
define a filtration
F'-1= σ (vp, ρ1(x),..., PL(X)),
F=σ (vp, ρ1(x),..., pL(x), H',..., H j , j = ',...,0.
(D.103)
i 1+i	∖
The sequence {Xi} = < E C',j > is adapted to the filtration, and since the summands are linear
[j='0+1 ' J
in the zero mean
sequence is
{Hk } the sequence is a martingale (E Xi+ι | Fi = Xi). The martingale difference
2-1	0
∏ Skai+1(x)*:THJvp
Z = Xi- XiT = δp,i+1 = 1EδKP I" gi+1(χ)k2
giving
'
X % = x'-i
j=20 + 1
2-1
2-1
∑ ∆i+X'' = E ∆i + %，+i.
j='+1
j=20+ι
We cannot control this sum directly because we do not have almost sure control of the martingale
differences. To remedy this, we recall the event E"1' +1 defined in lemma D.18, and decompose
the sum of interest into
2-1
X ∆i
j='0+1
2-1
E a -
j='0 + 1
2-1
+ X 1Ei-1,'° + 1 Z
j='0+1
(D.104)
<
Notice that the second sum is also a sum of zero-mean martingale differences. Using (D.100), we
have
IEi-Ie+ι∆i = 1Ei-ι,'0+1 σg
EH	EH
where g 〜N(0,1) and 1 ei-1,'z + 1 σ2 = 1 ei-1,'z + 1
EH	EH
for some constant C. It follows that
≤ exp (cnλ2) Vλ, a.s.
2-1
π
k=i+1
vp
2
2
≤ n almost surely
and we can apply Freedman,s inequality for martingales with sub-Gaussian increments (lemma G.7)
to conclude that for some d ≥ 0
P
2-1
TIEi-Ie+1 ∆i
EH
j='
≤ 2 exp
As for the first term in (D.104), using lemma D.18 we have
P
2-1
SXJ ∆i - 1 Ei-1,'0 + 1 ∆i
EH
j="
XP [(e,1,'+1 )] ≤ LC0e-cn ≤ CIe-L
i=1
> 0
≤
131
Published as a conference paper at ICLR 2021
for appropriate constants, where We assumed n ≥ KL log L for some K. Combining the above with
(D.94), and using (D.101) to give P [卜'4金十/ > C]
the triangle inequality, we have
≤ C0e-cn for some constants and applying
P E 芍 1,p > C√d
方 1∙p∈<5ip
'-1
≤ P I ⅛¾',+1 ∣ + IM X ∆i >C √d
'	j='0+1
(D.105)
≤ C0e-cn + C00e-c'智
for appropriate constants.
Having controlled the sum of terms in 1-ιp, we next consider a sum over the terms in G-r,p for
r ≥ 2. The argument will be very similar to the t? ip case, with some additional technical details.
Note that since different G-chains must be separated by an Hi matrix for some i and we consider
only terms with ii ≥ ' + 1, the minimal starting index of the r-th chain (indexed by j below for
clarity) is ' +1 + 2(r - 1). The sum of all possible terms is thus
亍r,p
=a'
方 r*∈G-r,p
Σ
' + 2r - 1 ≤ j ≤ ',
(i1,∙∙∙, i2r-2) ∈ Cr-1(20 + 1,j - 2)
r-2
b',j,i2r-2 ɪ ɪ ,i2m十2,i2m+1 ,i2m Ci)2,i1
m=1
Σ
'
=X	pr,j
j=20 + 2r-1
The constraints on the indices i1,..., i2r-2 are similar to those in (D.84), with the starting index
reflecting the constraint i1 > ' in the definition of G-r,p. We once again define the filtration Fj as
in (D.103) for ' - 1 ≤ j ≤ '. Noting that a`, bfc,ι,m = 1eskp ∏ Sq 0 心窝白；皿Jj Jx) and
k∏1 Sqal(x)*rH18 %
= 1EδKρq "+ 1 gl(x)∣∣2
are all Fl-1-measurable, the index constraints imply that
i+1
Xr = X %
j=20 + 2r-1
♦ -r~d	FI	i .1	.1	r T7-<r'l ∙	1 . 1 . . < r∙ ι .	T	♦	ι ∙	r∙
is Fi-measurable and thus the sequence {X1} is adapted to the filtration. %叶1,选「2 is a linear func-
tion of the zero-mean variables Hi for any choice of i2r_2, and we can replace Hi with WZPSi-1⊥
where Wi is an independent copy of Wi without altering the distribution of X；. Since bkιm for
k ≤ i2r-2 is independent of the WW for any choice of l, m, it follows that p' i+1 is also a linear
function of the variables in Wi which have zero mean. Consequently
i
E χr∣Fi-1 = X pr,j = X[-1,
j='0+2r-1
hence {Xi} is a martingale sequence. Defining martingale differences
∆r = Xr- Xr-I=及,+1
we have
`	2-1
X %=X ∆
j='0+2r-1	i='0+2r-2
(D.106)
We define an event fʌ ∈ Fi by
{∣m≤C}∩	∩	{ kwhk}∩	∩	[博2∙d≤Cqd}
E∆ =	i1+2<i2≤i3<ji	i-1 i1 ≤i2≤i I	(	(D.107)
∩i ∩i{3κρ ∣∣F%pji1-110Pi⅛M⅛ ∣∣2 ≤ CKj
132
Published as a conference paper at ICLR 2021
for iι ≥ 0 + 1 and decompose the sum in (D.106) into
'-1
Σ ∆
i=20 + 2r-2
2-1
≤ X S -1* S
i='0 + 2r-2
2-1
+ X 3 S
i=20 + 2r-2
(D.108)
In order to control the second term, we note that
%广 S = 1Ei-1 pr,i+1
=ιEr1 a`	E	,
(i1,...,i2r-2)∈Cr-1('z+1,i-1)
r-2
∏ ∏ bi2m+2,i2m+1 ,i2m %i1
m=1
〜
r r — 2
=IEi-I Ia	£	1EδKρ
(μ，…混7 —2)∈CL1(g'+1,i-1)
'∏1 Sq "
q=i+2
,+ 1(x)*rHiJ-2 + 1Pji2,-2 PJ (x)
-^gi+1(x)k2∣∣
r-2~
ai2r — 2-1(x)∣∣2
* Π 0i2m+2 ,i2m+1 ,i2m Ci)2,i1
m=1
〜
and using Γij-2+1 = PJiHiΓ^i2r-2+1 =
dependent copy of Wi gives
—2+1 where Wi is an in-
σg
where g 〜N(0,1) and
Pj(i) W iPs-ι⊥ ΓJ
1E1-1 S =
σ
EδKρ∩E 丁1
≤v 21εsκpnεi-1
*
max
2-1
∏ Sq
q=i+2
2-1
∏ Sq
q=i+2
a`
a`
2-1
Π Sq
q=i+2
i1 +2≤i2 ≤i3 ≤i-1
≤ C√dLL2r-2
a.s. n
Σ
(i1,…,i2r—2)
∈Cr- 1 (2'+1,i - 1)
Σ
(i1 ,…,i2r—2)
∈Cr- 1 (20+1,i - 1)
GgL2r-2 max 1
i1 ≤i-1
(1EδKρ∩E 丁1 校 3i2i1
r-1_	√∕dL
——C-----
n
PSi-1⊥ rHj：i2r-2 + 1pji2,— 2 Pi2-2 (x)
klai2L2T(X)Il2
r-2〜
* Π bi2m+2,i2m+1 ,i2m cT2,i1
m=1
IIrHJ"—2+1Pji2,-2 Pj (χ)∣∣2
gi2-2—1(x)k2
r-2
TlM	pp
π 'i2m+2 ,i2m+1 ,i2m ci2 ,i1
m=1
,krHj'i1 Pji1-1 PiIT(X)∣2
EδKρ∩EΓ1	ll«i1-2(x)k2
r-2
i1 ≤m≤L1lEδκρ∩Ej1 度2 i1∣
r-1
≤
EδKρ∩E∆-1
〜
2
*
In the last inequality we used the definition of fʌ and the assumption L3/2KS ≤ 1. It follows that
E
EΓ1
i-1]	(	cn2λ2	ʌ
F ≤ exp ------------------马-H Vλ, a.s.
d -	IdL (L3∕2Ks)2r-2 ),
and We can apply Freedman,s inequality for martingales with sub-Gaussian increments (lemma G.7)
to conclude
一 '-1
P X	1” ʌi
_ i='0 + 2r-2
(D.109)
It remains to bound the first term in (D.108). Using lemma D.15, (D.95) and taking a union bound
over i1, i2, i3 in (D.107) we have
P [E∆] ≥ 1 - CL3e-cn - C0L2 (e-cn + e-c'd) ≥ 1 - C"e-c"n - C∕%-c"d
133
Published as a conference paper at ICLR 2021
where we assume n ≥ KL log L and d ≥ K0 log L for some K, K0. An additional union bound
over i gives
一 '-1	-
P X ∆r-1” = > 0
_ i='0+2r-2	-
'-'
≤ XP [(E∆τ1)c]
i=1
≤ LC0 (e-cn - e-c'd
≤
for appropriate constants. Combining the above with (D.109) and recalling (D.106) gives
≤ Ce-cn + C0e-c'd
for some constants. L3/2KS ≤ ɪ implies
「(j0)何 /	、r-1	(-"2]-2
X	(L3/2KS)	= L3/2KS	X	(L3/2KS)
r=2	r=0
A final union bound over r and a rescaling of d gives
P
Σ
r=2
dL
>Vv
=P
Σ亍r
引r ∈C-r
≤CLe-cn + C0LeTcd ≤ C00e-c"n + C0"e-c"d
_	(D.110)
for appropriate constants, again assuming assume n ≥ KL log L and d ≥ K0 log L for some K, K0.
Combining the above with equation (D.105) and worsening constants gives
P
Σ
r = 1
Σ亍r
亍r ∈K
dL
>Vv
≤ Ce-cL + C0e-c'd
for appropriate constants.
Part (ii). We consider terms in the sets →r,p (with i1 = 20 and i2r ≤ ` - 1). In contrast to
the previous section, the bounds on these terms will differ based on the value of the p subscript
(denoting whether we use a fixed vector Vf or a random vector vu). We first consider G 1,p, noting
2-1
X 方 1,p = X a 弓Q
句 1,p ∈t-1p	j =
Lemma D.15 and a union bound give
P
2-1	2-1
∩ 为 ≤ Ks ∩ ∩∣ f I
j=	j=
2-1
≤C∩ ∩ I 说。∣≤C
j='
≥ 1 - LC0e-cL - L (2e-c'd0 - e-c"n)
≥ 1 - C00e-c"'n - 2e-c”"d0
134
Published as a conference paper at ICLR 2021
for appropriate constants, where we assume n ≥ KL log L and d0 ≥ K0 log L for some constants
K, K0 . With the same probability we have
E 亍 1p ≤ E	囱 1p∣ ≤ CLKsRp ≤ CRp	(D.111)
方 1p∈G-ip	方 1p∈G-ip
where we defined
and used LKJ ≤ 1.
We next consider sums of terms in -→G r,p for r > 1. In controlling the sum of these terms, the
proof will proceed along similar lines to the previous section. The main tool we will be utilizing is
martingale concentration. Recall that since i2r ≤ ` - 1 and every two G-chains are separated by a
matrix Hi, the starting index of the final G-chain is no larger than ` - 2r + 1. We thus have
r-1
-→g r,p
→-g r,p∈→-G r,p
Σ
`0 ≤ j ≤ ` - 2r + 1,
(i3, . . . , i2r) ∈ Cr-1 (j + 2, ` - 1)
8近27 Y Y bi2m+2,i2m+1 ,t2m i4 ,i3 ,j cp,'0
m=2
Define a filtration
'-2r + 1
=X ρr,p.
j='0
F0 = σ (up, ρ1 (x),...,ρL(X)),
Fj=σ (up, ρ1(x),..., ρL(x), H',..., H '-j+1) , j ∈ [' - '0 + 1]
(note the reversed indexing convention compared to the filtration defined in (D.103)). Since PrrP is
F `-j -measurable (as can be seen from (D.86)), we can define
`
XF= X j
j='-i
and it follows that Xir,p is Fi-measurable. Recalling from (D.86) that
I
bi4,i3,j
i4-1
1EδKρ	sk
k=i3+1
αi3 (x)*rHj1j+1Pj jρj(x)
kαi3(x)k2 kαr-1(x)∣∣2
and hence PrP is linear in the zero-mean variables Hj+1, We have
``	`
EXr+ι∣Fi=E χ Pr IFi= χ Pr +	EH建-=X Pr=Xi
,...,
j='-i-1	j='-i	j='-i
and thus the sequence {Xir,p } is a martingale With respect to this filtration. Defining martingale
differences ∆r,p = XF - Xr-I = Pr-Pi the sum of interest can be expressed as
'-2r+1	'-'0
X PrP= X ∆r,p
i='0	i=2r-1
(D.112)
135
Published as a conference paper at ICLR 2021
We now define an event which we will shortly show holds with high probability:
{∖aiJ<Ks)
∩
(⅛3 ； ■ ■ ■ ;^2r )	— 1
≤ C√L
∩ ∕1 伊SjQJlPJQ升2 < 2κ
nllf^—(到 2— *
Truncating the martingale difference on such an event gives
唯一 △严
(D.113)
r —1
~"卫?丁1	A I	Mr	十 2^2^ 十 1,22小加4N3,2-24一£
(i3 ； ■ ■ ■ 7^2r )	- 1 (β — ^i^∣^2,g— 1) TTI=Q1
=
x V a. TT6. .	. 1£	∏1 J3*rτ/f∣Pj-pi⑺SP
for a standard normal g, where we used
ri3-ι^-i+ιp Pl ⑺
HJ JjgIT (到 2
r⅛31J+2pJ+∣ H'τ+>j -而
Γi^-i+2Pj^+1He-i+iQ,
Jjg…⑺∣∣2
with We~z+1 an independent copy of We~i+1 and we have defined
√-	r — 1 〜
n^ε^~1∏εδκp	Σ	⅛2r Π 6遁小十2履2小十1N2小4—3金
OP _	(^3j-∙∙7^2r)∈Cr-1 (^―⅛ + 2j^-1)	Tn=2
"_	JI)ɪ*L…巧…［归…Q「…成
lla^3 (^)l∣2	HaJTw川2	^
Note that from (D.113), if we define
136
Published as a conference paper at ICLR 2021
the standard deviation σp can be bounded as
σp ≤
a.s
≤ CRp
L LLn
where in the first inequality We used a triangle inequality, bounded the number of summands by
L2r-2. In the second inequality we used L3/2KS ≤ ɪ.
Writing the sum in D.112 as
'-'
,p
i=2r-1
'-'
≤ X (1- 1E∆-1 )*p
i=2r-1
'—
≤ X 3NirP
i=2r-1
)∀λ,α.s.
`-
P X 3 ∆'p
i=2r-1
and recognizing that the second sum is over a zero-mean adapted sequence that obeys
E [ exp (λ1E∆-1 △, IFiTi ≤ exp (R2 (l3ZKs)2-2
an application of Freedman,s inequality for martingales with sub-Gaussian increments (lemma G.7)
gives
> RP (L3/2KjT ≤ 2eχp (高)≤2L.
Turning now to controlling the probability of E^-1 holding, we use lemmas D.15, D.18, the defini-
tion of KJ and a union bound to conclude
P [(E∣Γ1)c] ≤ L3Ce-cn + L (2e-c'd1 + e-c"n) + L2C0e-c'"L ≤ C00e-c""L + e-c'd1
for appropriate constants, where we assumed n ≥ KL log L,dι ≥ K log L for some K, K0. Com-
bining the previous two results gives
r-1"∣	Γ '-'	r-ι
> Rp (l3∕2Ks)-	= P X XP > Rp (L3/2Ks) 一
_	i=2r-1
兽	r	、r-1]
≤ P E 1£i-i∆r,p > Rp(L3/2Kj	+ P
i=2r-1
≤ 2e-cn + LP [(E∆-1)c] ≤ Ce-c' L + e-c”d1
S')∕21	r-1
for some constants. Noting as before that E	(L3/2KS)	≤ 2, using (D.111) to bound the
r=2
terms with r = 1, and setting d0 = di we obtain
-2-2r + 1
P X FirP
i=20
'—'
X (1-y1”产
i=2r-1
X X	→r，p > CRp	≤ LC (e-cL + e-c'd1) ≤ C (e-c" L + e-c'"d1)
r = 2	→r* ∈→r,p
for appropriate constants, where we used again n ≥ KL log L,di ≥ K log L for some K, K0.	□
Lemma D.19. (Horn et al., 1994) Given a semidefinite matrix A ,for any partitioning
(Aii	A12	...	Aib ∖
A21	A22
A =	.	.
.	.
∖ Abi	Abb)
b
we have IlAk ≤ E IlAii∣∣.
i=i
S
> 0
P
137
Published as a conference paper at ICLR 2021
Lemma D.20. Given a semidefinite matrix A and unit norm v, if
P [v* Av ≤ C0] ≥ 1 — C'p exp (―ci n)
and n > 2log(9)', then
P[kAk ≤ C000'] ≥ 1 — C00'p+1exp (—c0n)
for some constants c, c0 , C, C00 , C000.
Proof. We partition A into blocks of size c2n for an appropriately chosen c?. There are - such
`	c2
blocks, and we similarly partition the coordinates {1,...,n} into - sets Ki = {1 + (i — 1) c2n :
c2	`
ic2n} for i ∈ [C].
We proceed to bound the operator norm of the diagonal blocks using a standard ε-net argument
c2n
(Vershynin, 2018). The set of unit norm vectors supported on some Ki forms a sphere S ɪ. We can
thus construct a 1 -net Ni on this sphere with at most elog(9)c2' points. A standard argument gives
IlAiiIl ≤ C sup ∣∣χ"AiiX∣∣.
x∈Ni
We control the RHS by a taking a union bound over the net, finding
P sup ∣∣χ"AiiX∣∣ ≤ C0
x∈Ni
P sup ∣∣x*Ax∣ ≤ C0
x∈Ni
≥ 1 — ∣Ni∣ C'p exp (—cin) ≥ 1 — C'p exp ((log(9)c2 — ci) '
We now choose c? to satisfy log(9)c2 =号,and the blocks will still have non-zero size because We
assume n > 2log(9)'. Taking a union bound over the ɪ blocks and using Lemma D.19 gives
c1	c2
`
c2
∣Ak≤ X ∣Aiik≤ C'
i=i
w.p. P ≥ 1 — C0'p+1 exp (—c') for some constants c, C, C0.
□
Lemma D.21. Assume n ≥ max {KLlogn, K0Ldb, K00}, db ≥ K000 log L for suitably chosen
K, K0, K00, K000. Define J as in Lemma D.14. For x ∈ Sn0 -i and
βJ = (W l+1Pjl WL... W '+2Pj'+ι)*,
denote	_
di = ∣Ii(x)㊀ Ji| , d = (di,..., d，L),
and dmin = mindi. We then have
P
iEδκ ∣∣βJ — β'(χ)∣∣2 >C√dbL + C
≤ e-c max{dmin,i}s + e
+ 2∣d∣2Ls +
+ n +
-c0 L + e-c0d∣b
for absolute constants c, c0, c00, C, C0, C00, C000, where the event EδK is defined in lemma D.14. Other
useful forms of this result are
P
lEδK ∣∣βJ - β'(x)∣∣2
∣∣d∣∣
> C√dbL + C t Lns ( L2 s + ɪɪ +
Ldb∣∣d∣∣ 1+CL G ④
n
L
≤ e-cs + e-c0n + e-c00db + ^Xe-Csi max{di,1}
where si ≥ 1.
138
Published as a conference paper at ICLR 2021
Proof. Denoting by Hi the weight matrices projected onto the subspace orthogonal to the fea-
tures as in lemma D.14, we define
βH (x) = H '+1*βH (x) = (W L+1PiL(X)H L ... H '+2Pi'+ι(χ) H '+1)*
βH j = H '+1*βH j = (W l+1Pjl H L ... H '+2Pj'+ι H '+1)*
for ` = 0, . . . , L- 1. Note the additional matrix compared to the standard definition of the backward
features. Control of the norm of the difference between them can then be used to control the back-
ward features and LiPschitz constant of the network. Note also that H' may not be a square matrix
(and indeed in the case of the Lipschitz constant it will be rectangular). We denote the number of
columns of H'+1 by n`-i.
Writing
iEδκ ∣∣βj - β'(χ)∣∣2 ≤ iEδκ ∣∣βHJ - βH(χ)∣∣2 + iEδκ ∣∣βj -βHJ(χ)∣∣2
+ 1EδK ∣∣β'(X)- βbH (x)∣∣2 ,
(D.114)
we begin by bounding the first term. For ΓHj(x), ΓHjj defined as in D.14 and
Qi(x) = PJi - PIi(x),	(D.115)
we have
lEδκ∣∣βH J - βH (x)∣∣2
∣L
=lEδκ Wl+1 X ΓL1i+1Qi(x)HiΓi-J'+1
i='+1
=iEδκ∣∣wL+1 (r-'+1-r-'+1(x))∣∣2
∣ L ∣2
=. ∣∣ X bi ∣∣ .
i='+1	2
2
2
We first bound kbi k22 . RePeated use of the rotational invariance of the Gaussian distribution in a
similar manner to the Proof of lemma D.18 gives
kbik2 = lEδκ ∣∣WL+1 Γ-i+1Qi(x)HiΓi-J'+1∣∣2
d n	1 ~Γ	11	τrk+1-τ	P 11 2 11	IJ^i+1 F	Ci(Q、11	1 ~T	11 τrk + 1-τ P	11	11 τr'+1	11 2
=2 11 ∣∣H(I,：)1EδκPIk(X)∣∣21∣H(Ic1EδκQ (X)∣∣2 11 ∣∣H(I,：)1EδκPJk∣∣21∣H(Ic∣∣2
k=i+1∣	d	/	k='+1∣	V	/
=. ξIk (x)	=. ξJk
where We defined H&+)1 = ^WWL+1. Denoting by Wk an independent copy of Wk, rotational
invariance gives
ξJk ≤ ∣∣ W(l+) 1Eδκ PJk ∣∣2 = nχk
where Xk is a standard chi-squared distributed random variable with ∣suppdiaglEδκ Pjk | degrees of
freedom that is independent of all the other variables in the problem, and similarly for ξIk(X).
A product of such terms was bounded in lemma D.18, from which we obtain
L	i-1
P 2 Y ξIk(χ) Y ξjk >Cn ≤ e-cL.	(D.116)
_ k=i+1	k='+1	_
We similarly have
∣Hi+1)1Eδκ Qi(X)∣∣2 a≤j∣1Eδκ Qi(X)W(k+"2.
Recalling (D.115) and since
di = suppdiagQi(X)
we recognize that
∣∣1Eδκ Qi(X)W(k+)1*∣∣2 = 1Eδκ n Xi
139
Published as a conference paper at ICLR 2021
where χi is a standard chi-squared distributed random variable with di degrees of freedom. If di = 0
this variable is identically 0. Otherwise, di ≥ 1 and Bernstein’s inequality gives
P[χi	-di	> Csdi]	≤ 2e-csdi	⇒P[χi	>	C0sdi]	≤	2e-csdi ≤	2e-cs max{di,1}	(D.117)
for some constants and s ≥ 1.
Clearly this result also holds if di = 0. Similarly,
同协2 is
bounded almost surely by n2χ`+ι where χ`+ι has n`-i degrees of freedom. Bernstein,s inequality
gives P ∣∣h'm∣∣2 > Cnt ≤ e-ct for t > Kn'-ι for some K. Combining these results with
(D.116) and taking a union bound, we obtain
LL
P X kbik2 >C-1 X Sidi
,i='+1	i='+1	.
L
≤2X
i='+1
L
≤2X
i='+1
e-csi maχ{di,1} + 2L(e-ct + C JO L)
e—Csi maχ{di,1} + e-c000 t + e-c0000 Ln
(D.118)
for appropriate constants, assuming t
simplified to
≥ K log L, n ≥ K0L log L for some K, K0, which can be
LL
P kbik2 >C 1 ts P di
i='	i='+1
-≤ 2Le-cs + e-c00n' +
≤ 2 P e-cs max{di,1} + g —c00θn't + e-c〃〃 Ln
e-c0000 Ln ≤ e-c0s + e-c00n' + e-c”"n
(D.119)
assuming S ≥ K00 log L for some K00.
We next bound |hbi, bji| for ` ≤ j < i ≤ L. Once again using rotational invariance starting from
the last layer weights, we obtain
hbi, bji =lEδκ WL+1 ΓHi+1(x)Qi(x)HTH-J'+1ΓHJ++1*Hj*Qj(x)rHj+1*(x)WL+1
L
=nlEδκ Y ξik(x)Hi+,1)Qi(x)HiΓ直二ΓJ二Hj*Qj(x)Γ铲1*(X)Hi
k=i+2	`z
■+I*
:,1)
=φi-1j-1
P
(where we interpret an empty product as unity). As before, we find using lemma D.18 that
L
P lEδκ n Y ξik(x) >Cn ≤ C0e-cLn ∙
k=i+2
(D.120)
We proceed to bound the remaining factors in hbi, bji, by first writing
L
hbi, bji = lEδκ 2 Y ξik(X)Hi+1)Qi(X)HiΦi-1:j-1Hj*Qj(x)Γ铲1*(x)Hi+11)*
k=i+2
L	di dj
=1EδK 2 Y ξlk(X)XX Hi+1i)SkiH(ki,)φi-1j-1Hj：*kj )Skj Hj+1*) l∣ui+1jτ∣2
k=i+2	ki =1kj =1
where ui+1j+1 = PI+ι ΓH+2*H i+1* and SkE ∈ {-l, 1} are the signs of the elements in Qm(X)
j+1 H	(:,1)	m
for m ∈ {i, j}. In the above expression, km index the entries on which diagQm is supported, and
we denote dm = |suppdiagQm | and use the permutation symmetry of the Gaussian distribution to
set these to be [dm].
If i > j + -, defining Hcj+1 = Wc j+1PSj⊥ where Wcj+1 is an independent copy of W j+1, with
ΓH-J'+1 denoting the matrix Γ^-J'+1 with Hj1+:) in place of Hj+:), and writing for concision
Ξki,kj — Hi+1 Hi	Γi-1j+2Pτ	r H j Hj+1 - Cj + 1 ʌ φjj-1 Hj*	Hj+1* ∣∣ui+1j+1∣∣
f,j = H(1,ki)H(ki,:)rHJ	PJj+ 1(:,1) [H(1,:)	H(1,:)J φ	H(:,kj )H(kj ,1) ∣∣u	∣∣2
140
Published as a conference paper at ICLR 2021
and
币ki,kj 一 fʃi+1 Hi	bi — 1：'+1 pj-1：'+1* τrj*	frj + 1* IL i+1j+1∣∣
ψi,j — H(1,ki) H(ki,:)rHJ	γHJ	H(：,kj )H(kj,1) Ilu	l∣2
we have
di	dj
hbi, bji =
lEδκ 2 ∏ ξlk(x) Σ Σ
k=i+2
L
ki =1kj =1
di	dj
ki ,jj
Ξi,j
+iEδκ n π ξik (X)E ∑ψ;
k=i+2
ki =1kj =1
ki,kj
i,j
(D.121)
L
n
2
+
where we used the invariance of the Gaussian distribution to reflections around the mean, {jm} =d
{W mPSm-ι⊥ }, and the independence between the { Wm } variables and the sign variables {skm }
to absorb the latter into the former. Making a separate definition for concision
di
1Eδκ X Hi+ii)Hiki,：)r-Jj+2 Pjj+i(：,i)
ki=1
|
=. B1i,j
}
we first consider the term
/
dj
1E, KX H j+1 Φjj-1H j*k Hj j+1l∖
EδK	(1,:)	(:,kj )	(kj ,1)
kj=1
∖
|
}
Ai1,j =d B1i,j
=. B2i,j
dj
-1e6 KX Hcj+1 Φjj-1H j∖ Hj j+1；、
EδK	(1,:)	(:,kj )	(kj ,1)
kj=1
1EδK ui+1:j+12.
'--------------}
{z^^^
=. B4i,j
|
}
∖
=. B3i,j
/
Lemma D.22 gives
PhB4i,j >Ci = P 1EδK IIui+1：j+1II2 >C ≤
C000e-c" L
(D.122)
We next consider B3i,j . Writing
dj	dj
Bij — 1 X Hj+1 Φjj-1H j； H j+1； = ιr	X Hj+1 Φjj-1H j； PsiW j+1；
B3 = 1Eδκ 乙 H(1,Dφ H(：,kj )H(kj,1) = 1Eδκ 乙 H(1,：)Φ H(：,kj )PSj ⊥ W(kj,1)
kj=1	kj=1
First, since the variables {W(k+11)}
a Gaussian tail bound gives
are indePendent of {1Eδκ Hj+1φjj-1Hj：；kj ) (PJ` )(kj ,kj ) },
dj	uu	dj	2
P	^^Cj+1 φjj-1	Hj；	Hj+1；	>	2d	ι「	(Cj+1 φjj-1Hj；	(PT	)	)
2^H(1,Jφ	H(,kj)H(kj,1) > ` n 乙 EδK (H(1,Dφ	H(,kj) (J)(kj,kj)7
kj =1	kj=1
≤ e-cd
(D.123)
for some constants and d ≥ K for some K.
141
Published as a conference paper at ICLR 2021
Two applications lemma D.22 give
*	2	1
p X 1Eδκ (C+φjjTH黑)(PJ)(M)) >Cdnt
kj = 1
≤X P 除(码产-旧黑)(SM))2 > Cn t
kj = 1 L	-
≤ dj 卜-CL + e-c0t) ≤ e-c〃 L + e-c"t
assuming t ≥ K log n, n ≥ K0L log n for some K.
Combining this bound with (D.123) we obtain
P IBij > CPddjt ≤ e-cd + e-c0L + e-c"t	(D.124)
for appropriate constants.
We now turn to bounding Bij. Define by Qj a matrix such that Qab = I Qab(X)I . Then
Bij = 1εs KWjl+1Psj⊥ Φj : j-1H j*Qj Pj Wj+1*.
2	EδK	(1, ：) Sj	S Sj (: ,1)
In order to bound this term using the Hanson-Wright inequality, we first note that since
∣∣Psj⊥ Φjj-1H j*Qj ps3-⊥∣∣ ≤ ∣∣Φjj-1H j*∣∣ ≤ ∣∣γH+1∣∣ IIrHj=+1] IlH j*∣∣,
∣∣Psj⊥Φj j-1Hj*QjPs,⊥∣∣2 ≤ ∣∣Φjj-1Hj*∣∣2 ∣∣Qj∣∣2 = ∣∣φjj-1Hj*∣∣2dj,
we can use lemma D.14, a standard ε-net argument to control the operator norm of a Gaussian matrix
and a union bound to obtain
P
{ ∣ ∣ 1EδκPsj⊥Φj j-1Hj*QjPsJ∣ ≤ cl}
∩ {∣∣1EδκPsj⊥Φj j-1Hj*QjPsj⊥ ∣∣2 ≤ CL2dj
≥ 1 - e-cn + e-Cn ≥ 1 - e-c” L
We also have
ETiZ j + 1 TD 不 j:j-1 TU^7* /ɔj ^D TJZ j+1*
〜 W(1,:)Psj⊥ Φ H Q Psj⊥ W(：,1)
ntr [Ps3-⊥Φjj-1 Hj*QjPsj⊥]
DJj
2 X 虱 Ps⊥ γHJ1γhJ=+1*
kj = 1
H Fj
and using lemmas D.14 and D.22 gives
dj	j
P X bkj Psj⊥ γHJ1γHJ*+1*H j*bkj ≤ Cdj	≥ 1 - dj e-c n ≥ 1-e-c0L.
Ikj =1	I
assuming n > KL log n for some K. Denoting the union of these two events by G, an application
of the Hanson-Wright inequality (lemma (G.4)) gives
P
≤ C exp
(D.125)
for appropriate constants and s2 ≥ 0, and an additional union bound gives
> S2 +
2Cdj
n
≤ C exp
_ L
+ e-L.
(D.126)
142
Published as a conference paper at ICLR 2021
We next turn to bounding
Rotational invariance of the Gaussian distribution gives
di
Bi,j = 1Eδκ X H(t,ki)Hlki ,0rJ'+2PJj + ιc,1)
ki=1
di
=1Eδκ X Hi+bWiki,ιj∣ PJi-IrHJj+2Pjj+ι("M∣2
ki=1
since PJi-IrHJj+2。『升1(：,1)and W工田 are independent.
Since Hi++1), Wi1 k)are both SUb-GaUssian with SUb-GaUssian norm bounded by C, the Prod-
uct of two such variables is a sub-exponential variable with sub exponential norm satisfying
国[1i)Wiki,i)Bψι
≤ Cfor some COnstants. Thus the fi∙st sum above is a sum
of independent,
zero-mean sUb-exponential random variables, and Bernstein’s ineqUality gives
di	n2s2
P X Hi+1i)Wiki,i) >S1 ≤ 2e-c min{ FL ,ns1}	(D.127)
ki=1
for s1 ≥ 1 and some constant c.
Since(3kPJi-IrHJj+2Pjj+i(：,i)( ≤ ∣∣lEδκrΗjj+2bι( we can apply lemmaD.14 to ob-
tain
P [∣∣1EδκPJi-IrH∙Jj+2pjj+ι("i)∣∣2 > C ≤ C0e-cn
for appropriate constants. Combining the last two resUlts gives
22
PnBi，j] > Csι] ≤ e-cmin{F,ns1} + e-c0n	(D.128)
for some constants.
Combining the above with (D.122), (D.124) and (D.126), we have
P "∣A1j∣≥ C fs2 + 2dj + Pddjt-! si
n n	(D.129)
2 2	000	n2 s22 ns2
≤ e-cmin{Y，nsi} + e-n + e-c00d + e-c min(丐Fj + 产飞
In the above proof We assumed i > j + 1. If instead i = j + 1 We simply set rH-J'+1 = rH-J'+1
in the expression for Ai2，j in (D.121) and we have hbj+1, bji = Aj2+1，j.
ij	d
We now turn to controlling the term A」. Since i > j, Hika ：)= Wiki ：)PSi-1⊥ and
PSi-1⊥rH-J'+1rH-J：'+1*Hj*k)is independent of W(k ：), rotational invariance of the Gaussian
distribUtion gives
di
A2j = X Hi+1、Wik n
2	(1，ki )	(ki ，1)
ki=1
|---------------}
× 1EδK
{z
=. C1i
/ dj	∖	。130)
I X ∣∣PSi-1⊥rΗJ'+1rHJ5Hj%)∣∣2 H+1；)) ∣∣ui+1j+1∣∣2∙
kj=1
^z∖ιf^
=. C2i,
We bound ∣∣C1i ∣∣ using (D.127).
143
Published as a conference paper at ICLR 2021
It remains to control ∣C2,j∣. Since Hj+1；)== (Psj⊥ )(k.的.)Wj"+1.)and Wj"+1.)are independent of
(PSj⊥ )(储 /)∣∣Psi-ι⊥ Γ H-J'+1rHJ:'+1；Hj；k .)|| , the second factor in (D.130) is also zero-mean,
and it follows that
P
1 PP P p 、	∣∣ p .	Γi-1:'+1rj —1:'+1； Hj；	∣∣ WWj+1
1Eδκ T (PSj⊥ )(kj,kj) ∣∣pSi-1⊥ γ HJ	γHJ	H(∙,kj )∣∣2 W(1,kj)
kj = 1	______
> S 组 P 11EδK (psj⊥ )(kj,kj ) ∣∣PSi-ι⊥ γ HJ'+1rHT+1*Hj% )∣∣2
≤ C0e-cd
for some constants and d
∣∣Γ HJ'+1∣∣2∣∣rHT+1*Hj%)
a union bound gives
≥	0.	Since ∣∣PSi-1⊥ΓHJ'+1rHJ*+1*Hj*k J∣2	≤
∣ S HJ HJ	(:,kj) ∣2
2
, applying lemmas D.22 and D.14 total of dj times and taking
dj
P X 1Eδκ (psj⊥)(kj,kj) ∣∣PSi-1⊥rHJ'+1rHJ:'+1*Hj：：kj)∣∣2 > Cdr
kj=1
≤ dj 卜-CL + e-c0t) ≤ e-c0 L + e-c0t
where we assumed n ≥ KL log n, t ≥ K0 lognfor some constants. Combining the above three
results with (D.122) and taking a union bound, we obtain
P	∣A∣,j∣	> Cs1	,d*-1Lt	≤	e-cd +	e-c0 L +	e-c00t	十1』0 0 +	-d'00 min{ ns ,ns1}
for appropriate constants.
Taking a union bound over this result as well as (D.129) and (D.120) allows us to bound the inner
product by
P kbi, bji∣ ≥ Cns1 (s+ + dj + Pdjdn'-1Lt∖
nn
≤
2 2	000	L2 s22 Ls2
e-c min{ Y ,nsι} + e-c0 L + e-加 + e-c mint M,	+ 已"
(D.131)
for some constants, again assuming n ≥ KLd . At this point we obtain a bound on the sum of
these inner products that will be useful in an application where the {di } are expected to be small.
Subsequently, we will derive a different expression that will be useful when they are large.
We now choose s1 = dis ,s2 = djLs ,t = ^n- for some S ≥ 1, which gives
n	n	n`-1

P |hbi,bji| ≥Cdis
+ d +
≤ C0e-cmin{di,di}s + c00e-c0L + C000e
-C00 d
for appropriately chosen constants. Note that if di = 0 or dj = 0 then |hbi, bji| is identically zero,
hence we can replace the term min{di, di} in the tail above by max{1, min{di, di}} and the result
will still hold if di = 0 or dj = 0. Lower bounding the second expression by dmin = mindi gives
P |hbi,bji| ≥ Cdis
+
C 0 e-c maχ{dmin,1}s + c He-C L + C 000 e-c0 d
144
Published as a conference paper at ICLR 2021
Recalling the definition of d in the lemma statement, an additional union bound over the values of
i,j in the expression above combined with (D.119) gives
P	"iEδκ	同 J	- βbH (χ)∣∣2 > CsU矶 + 2i⅛1Ls + rLd 同1/2)#
≤P	1Eδκ	∣∣∕bHJ-βbH(X)Il2 > Cs x d n2jS+r-j!!+Cs x d
_	i,j='+1,i=j	∖	)	i='+1 _
≤ L (C0e-c max{dmin,1}s + C00g-c' n + C000£-0〃&)
≤ C!e-c00 max{dmin,1}s + C00e—c0000 L + C000e-c0000 d
CJOS + C 00e-c0000 n + C000e-c0000 d
(D.132)
for appropriate constants, where we assumed d≥ K log L, s ≥ max{1, K0 logL}, n ≥ K00L logL
for some K, K0, K00. Taking a square root gives a bound on the first term in (D.114).
We next consider a different bound for this term that will be useful when the {di} are large. Our
starting point will be D.131. Ifwe set s1 = s, s2 =Ls and use (D.118) we obtain
P 卜Eδκ ∣∣βHJ -βH(χ)∣∣2 > CLns(L2s + 巴 + √Ldt ∣∣d∣∣1/21 + C- X sidi
2	n	n	1/2	n
L	∖	i	i='+ι	.
≤
P
1EδK
-βH(x)∣∣2 > Cns X	(Ls +
2	i,j='+1,i=j ∖
-L
+ C ― / j sidi
n
i='+1


≤
2	0	n2s2
L2 C exp -Cmin{ -ττ=τι—
V 飞 ∣∣d∣∣∞
,ns}	+ C 00e-≡0 L + C 000e-≡00d
L
+): e-cSi max{di,1} + e-c000 t
i='+1
≤
L
e-cns + e-c0L + e-c00d + ^X e-c000 si maχ{di,1} + e-c0000 t
i='+1
for appropriate constants under similar assumptions on, L, d.
(D.133)
To bound the remaining terms in (D.114), since
1EδK ∣βJ - βbHJ∣∣2 ≤ 1EδK ∣∣WL+1 TJ:'+1 -γH+1)∣∣2 ∣∣h'+1∣∣
=iEδκ∣∣(rJ'+1-rH'+1) WL+1*∣∣2∣∣H '+1∣∣
and we can apply lemma D.14 and an ε-net argument to bound the first and second factors respec-
tively, to conclude
P [lEδκ ∣∣βJ - βHj∣∣2 > C√dLi ≤ C0e-cd + Cec0n ≤ e-cd
for some d such that d ≥ K log L and assuming n > K0d. An identical result holds for the last term
in (D.114) where we simply choose Ji = Ii(x) for all i. In conclusion, using (D.132) we have
3κ∣∣βJ - β'(χ)∣∣2
P
> C √dL+Cjs (∣∣d∣∣ι + 卬 + qi∣∣d∣∣ι∣∣d∣∣1∕2)]
≤ C0e-cs + C00e-c0L + C000e-c00d
(D.134)
145
Published as a conference paper at ICLR 2021
for appropriate constants, while ifwe use (D.133) instead we obtain
P
iEδ∕βJ-β'(χ)∣L >C√dL + C
≤ e-cs
+ e-c0 L + e-
c000 si max{di ,1} + e-c0000 t
ll5lk
+
s
-d
1-21-2
n
(D.135)
It remains to transfer control from ∣ 卜 H J - βH (x)∣∣ to ∣∣ βH J - βH (x)∣∣2. Note that
IIeH J-βbH (χ)∣∣2 = ∣∣H i (βH J -βH (χ))∣∣2 = ∣∣PS'⊥W^)*∣∣2 ∣∣βH j -βH (χ)∣∣2
where if ' = 0 We define Pso⊥ = In。”. Since ^E∣ ∣∣Ps'⊥ W'用[=atr [P5'⊥] = 2(n-1),
Bernstein’s inequality gives (assuming n > K for some K)
∣∣βbH j - eH (χ)∣∣2
∣∣ps'⊥W3*∣∣2
and hence with the same probability
∣∣βHj - βH(X)∣∣2 ≤
≤ C ∣∣eH j - βbH (x)∣∣2.
The bounds (D.134), (D.135) also apply to ∣∣βH J - βH (x)b up to a constant factor, with the same
probability up to a e-cn term which we can absorb into the existing tail by demanding n ≥ KL for
some K.	□
Lemma D.22. For any ` + 1 < m ≤ j + 1, k ∈ [n], if n ≥ KLfor some K then
P h1Eδκ BHjMrHJB2 >ci ≤ e-cn
and if m = ` + 1
P 1Eδκ∣∣H+jrHJ1∣∣2>C
]≤ e-cL + e-c0t
assuming t ≥ K'n`- for some K0.
Proof. If j + 1 > m,
1EδK ∣∣Hj+1∏J∣∣2
=lEδK ∣∣ Wj+) Psj⊥ ΓjHJ+1Pjm W mPsm-1⊥∣∣2
=3k∣∣wj+) psj⊥ rHJ+1pJm I2 1^wm∕2
=∣∣Psj⊥rHm+ιbι∣∣2∣∣wKtUWM2.
=1EδK ∣W(jl+) pSj ⊥ rHJ+1pJm H m∣∣2
≤1EδK ∣∣w(jl+) pSj⊥ rHJ+1pJm W m∣∣2
≤1EδK ∣∣pSj⊥rHJ+1w(j+)*∣∣2∣∣W(%∣∣2
TfCnthe CtherhQnrl 彳-k 1 — ∣ WehQvenC	∣∣ M^j + 1 ^Γjγm ∣∣ 一 ∏c	∣∣ M^j+1 ∣∣ V ∣∣ 历 j + 1∣∣
If on the other hand j + 1 = m, we have 1Eδκ ∣∣h(i,:)1 hj∣∣2 = 1Eδκ ∣∣h(i,:) ∣∣2 ≤ ∣∣ w(i,：)∣b
Bernstein,s inequality gives P [∣∣Wjι+)*∣∣ > °] ≤ C 0e-cn and P [∣∣W'+.)∣∣ > C ^nt ] ≤ 2e-ct
for t ≥ 1, while lemma D.14 gives
P[∣∣lEδκΓHJ+1bι∣∣2>ci ≤ C0e-cn.
Taking union bounds gives the desired results.
□
146
Published as a conference paper at ICLR 2021
Lemma D.23 (Generalized backward features inner product concentration). Fix x, x0 ∈ Sn0-1,
V = ∠(x, x0). Define a collection of support sets J, generaIiZed backward features βJ, a COnStant
δs and ^vent Eδκ as in lemma D.14. Assuming n ≥ max {KL log n, K0}, d ≥ K00 log n for suitably
chosen K, K0, K00, we have
P ∃' ∈ [L]:
3k E, βJ,〉-2 LQ1 (ι- 4)
',='
>	C (d2√Ln + qdδsLn + d3∕2δs (1 + √n) L5/2
≤ C0e-cd
for absolute constants c, C, C0. If additionally we have P [Eδκ] ≥ 1 — e~c'd then the same result
holds without the truncation on 1εδκ, With worse constants.
Proof. Note that
3κ s,βj，〉-n YI(I- T )∣
≤ I 1Eδκ (βj - β'(x), βj，〉1 + I 1Eδκ <β'(x), βj，- e'(x0)〉I
+ 卜K <β'(x), MX0)〉- 2 ∏ (1- - )|
3κ IIeJ, (x')∣∣2 l∣βJ - β'(x)l∣2+ 1εδκ IF(X)I∣2 l∣βJ，- β'(x0)l∣2
≤	+ iεδκ(阳x), β'(x0)> - 2LQ1 (1 - ⅛1)
==£
(D.136)
In order to bound the first two terms, We use rotational invariance of the Gaussian distribution twice
to obtain
1Eδκ∣∣βJ,∣∣2 = 1Eδκ IWL+1ΓJ(+)pj'(X)∣∣2
≤ iεδκ ∣∣WL+1Γ尹1 ∣∣ 2 = iεδκ ∣∣ΓJ"1WL+1 ∣∣ 2 = ∣∣WL+1 ∣∣ 2 iεδκ ∣∣ Γj"1b1 ∣∣ 2.
a.s.
Bernstein,s inequality gives P [∣ ∣ WL+1∣∣2 > CnI ≤ 2e-cn , while 1εδκ ∣∣ΓjLb11∣2 can be
bounded using D.14 to give
P [1εδκ HeJ，H2 > Cni ≤ C0e-cn + C00e-c0n ≤ C000e-c"n
for appropriate constants. Using lemma D.21 to bound 1ε6κ ∣ ∣ βJ 一 β`(x) 11 2 We obtain
P iε6κ ∣∣eJ，(x0)∣∣2 ∣∣eJ -e'(x)∣∣2 > C√dLn+C0jdδsLn+d3/%, (1 + √n) L5/2
≤C00e-cn + C000e-c'd ≤ C0000e-c"d
for some constants, assuming n ≥ KLd for some K. Bounding the second term in (D.136) in an
identical fashion and the last term in (D.136) using Lemma D.4 we obtain
P
iεδκ〈ej, ej ,〉- n LQ1 (1- 2)
',='
>	C W√Ln + qdδsLn + d3∕2δs (1 + √n) L5/2
≤P
∣iε6κ〈ej, ej ,〉-2 LQ： (1- S))
> C0 √∕du+ + 4dδsLn + d3∕2δs (1 + √n) L5/2) + C0d2√Ln
147
Published as a conference paper at ICLR 2021
P
≤
^ l1EδK IleJ，l∣2 llβJ — β (x)l∣2 + 1EδK IleJ l∣2 UeJ，一 β 3升2「
> C' √ddn+ + .dδsLn + d3∕2δs (1 + √n) L5∕2)
+p [∣iEδκ(ej, βJ，〉- 2L∏1 (ι -员¥V)) > c0d2√Ln
≤ C"e-cd + C",e-c'd
< CWe-Ccid
for appropriate constants assuming d ≥ 1. Taking a union bound over all possible choices of
` ∈ [L] and using d ≥ K log L for some K gives the desired result. If We additionally have
P [E^k] ≥ 1 — e-c'"d for some cπ0, we can write
(ej, eJo〉-1 ∏ (ι - -) I = W (eJ，eJ，〉- 2 ∏ (ι - —) ∣
+ ∣(1 - 1Eδκ ) (eJ, eJ 0〉l
and since the last term is zero w.p. ≥ 1 - e-c d we obtain the same result as in the truncated case,
with possibly worse constants.	□
D.4 Auxiliary Results
Lemma D.24. There are absolute constants c1, C, C 0 > 0 and absolute constants K, K> > 0 such
thatfor any L ∈ N, if n ≥ max{K log4 n, K 0L}, then for every ` ∈ [L] one has
∣ e[N-'W) - N-'+1WT) ∣ 尸-1i ∣≤ C log^	/6：] ”(1 + log L) +(C.
IL	I Jl n 1 + (co/64)(L — ')ν' 1	n2
The constant ci is the absolute constant appearing in Lemma E.1.
Proof. The case of ` = L follows immediately from Lemma E.1 with an appropriate choice of
d ≥ K" for K" > 0 some absolute constant. Henceforth we assume ` ∈ [L - 1]. We Taylor expand
(with Lagrange remainder) the smooth function 夕(L-`)about the point 夕(V`-1), obtaining for any
t ∈ [0,π]
dL-')(t) = dL-'+1)(^'-i) + 中(L-')W俨-i)) (t -以V'-1)) + ^L^ (t -。俨-1))2,
where ξ is some point of [0, π] lying in between t and 夕(^'-i). In particular, putting t = ^', we
obtain
dL-')(^')-dL-'+1)(^'-i) = °(L-')W(V'T))仍-以V'-1)) + 加；⑹ 铲一以V'-1))2,
where ξ is some point of [0, π] lying in between V' and °(^`-1). By (C.23) and (C.26), we have
that °(L-')< 0, whence
°(L-')(^') - °(L-'+1)(^'T) ≤ °(L-')(°(^'T)) (^' - °(^'T)) .	(D.137)
Using Lemma E.5 and an induction, we have that °(L-')is decreasing, and moreover by the con-
cavity property we have °(V`-1) ≥ V`-1∕2. An application of Lemmas E.1 and C.15 then yields
E [°(L-')(^')- °(L-'+"O'-1)
F'-1] ≤ (c^'-1 l°g-n + C0n-cιd
1
1 + (co∕4)(L - 4)^'-1
log n	^'-1
- n 1 + (co ∕4)(L — 2)^'-1
+ C 0n-cιd,
as long as d ≥ K and n ≥ K d4 log4 n. In particular, we can choose d = max{K, 2∕c1} to obtained
the claimed error for the upper bound. Next, for the lower bound, we make use of the estimate
°(L-')
(V) ≥ -
J
1 + (co∕8)(L - 2)v
(1 + (Σ0⅛>log(1 + (Co/8)(L -'- I)V)),
_ - /
{z
f(ν)
C
148
Published as a conference paper at ICLR 2021
which follows from Lemma C.16 and S(LT) ≤ 0; by that lemma, we have that f is increas-
ing. By Lemma E.3, as long as n ≥ K0 log4 n, there is an event E on which ∣^` - 夕(V'-1)∣ ≤
C^'-1 piog n/n + C0n-3 and which satisfies P[E ∣ F'-1] ≥ 1 — C00n-3. In particular, on the
event E we have V` ≥ ^`-1∕4 — C0∕n3 provided n ≥ 16C2 log n, and so on the event E we have
ξ ≥ min{s(^'-1), ^'-1∕4 — C0∕n3} ≥ V'-1∕4 — C0∕n3. We can thus write
dLT)(^')- dLτ+I)(^'T)
≥ 中(LT)W俨T))伊-以VeT))十 f2)伊-以^-1))2
=S(L-)(s(V'T))仍一以VeT))十(1e 十 if)号仍一以VeT))2
≥ S(L-)(s(Ve-1))伊-S(VeT))十 IE f(-号)(Ve - s(^e-1))2 - (2C"π2L)1Ec
≥ S(L-)(S(VeT)) (^e - S(VeT))+ f (-言) (Ve - S(VeT))2 - &C"'π2L)1εC
where the inequality in the third line follows from boundedness of the angles and the magnitude
estimate on f in Lemma C.16, together with our estimate on ξ on E, and the inequality in the final
line is a consequence of f ≤ 0, which allows us to drop the indicator for E and obtain a lower bound.
Taking conditional expectations using the previous lower bound and applying Fe-1-measurability
of ^e-1 and boundedness of the angles together with our conditional measure bound on EC, we
obtain
e[s(L-e)(^) - S(L-e+1)(^e-1) I Fe-1] ≥ -C
log n
Ve-1
n 1 + (co ∕4)(L — 2)^e-1
C0	C5L
-  - --Z-
n2	n3
+ f(3-旨)E[(Ve - S(VeT))2 I Fe-1j,
where we also apply the complementary bound obtained by our previous work following (D.137).
Since the CL estimate in Lemma C.16 applies also to f, and since f ≤ 0, an application of
Lemma E.4 with an appropriate choice of d and the choice n ≥ K0 log4 n then yields (with a
larger absolute constant C0)
EIS(L-eW)-
S(L-e+1)
Fe-1i ≥ _Cl°gn________匕1_________
n - n 1 + (co ∕4)(L — 2)^e-1
C0	CβL
-  - --Z-
n2	n3
+ C7 logn (VeT)2 f
n
If we choose n ≥ (Ce∕C0)L, we can simplify this last estimate to
EhS(L-e)(V) - S(L-e+I)(VeT) ∣ FeTi ≥
log n	Ve-1	2C0
1 + (co∕4)(L - 2)Ve-1 -方
C7 log n
n
+
To conclude, we divide our analysis into two cases: when Ve-1 ≥ 8C4∕n3, we have ^e-1∕4 -
C4n-3 ≥ ^e-1∕8, and so
1 + 8log(L - 2)
co∏
where the last inequality follows from Lemma C.16. On the other hand, when ^e-1 ≤ 8C4∕n3, the
CL estimate in Lemma C.16 implies
64CC2 L
≥------ɪ
一	n6
64CC2L
≥	n3
2C0
≥------
≥	n2 ,
149
Published as a conference paper at ICLR 2021
where the last estimate holds when n ≥ (32CC2/C0)L. Adding these two estimates together, we
obtain one that is valid regardless of the value of V`-1, and choosing n ≥ C7 log n to combine the
residuals, we obtain (after worst-case adjusting the constants)
EhdL-')(V') - dL-'+I)(V'-1) J F'-1] ≥ - W -
C8 log n ^'-1 (1 + log(L - 4))
n 1 + (c0∕64)(L - 2)v'-1
Combining with our previous work, we obtain
JEFL-')(V')-加-'+I)(V'-1)
f'-i] I ‹ Cl°gn	P1 (I+ logL)	+ Coɪ
Jl - n 1 + (co∕64)(L - 4)^'-1 +	n2
after worst-casing constants.
Lemma D.25. There are absolute constants ci, C, C C, C", C "0 > 0 and absolute constants K, K0 >
0 such that for any d ≥ K, if n ≥ K 0d4 log4 n, thenfor every L ∈ N and every ' ∈ [L] one has
。…(^'-i) l-4 ι+(co2CVL--"-i
+ 2C ,n-cιd∕2
F'-1
and
≥ 1 - C'"n-cιd,
E [(dL-')(V') - dL-'+1)(V'-1))2
F'-i] - 4C2中(1 + (co∕8)(L- ')^'-ι
+ C00n-cι d/2.
The constant ci is the absolute constant appearing in Lemma E.1.
Proof. We will fix the meaning of the absolute constants C, C0, CN > 0 throughout the proof below.
By Lemma E.3, we have if d ≥ K and n ≥ K d4 log4 n that for every ' ∈ [L]
P I ^' - y(^'-i) I - C^'-iyd-l°g-n + Cn-Cid F'-1 ≥ 1 - C00n-cιd.	(D.138)
By Lemma C.15, we have the estimate
卜⑶⑴ I - 1 + (c0∕2)'t,
valid for any ' ∈ No. Writing Ξe = ^' -夕(^'-1) so that ^ =夕(^'-1) + Ξ', we have that (Ξ^) is
adapted to (F'), and by the fundamental theorem of calculus
1	1	∣ 产(^'-1)	出
I 加-')俨)-加-'+1)(^'T) = I	…/工 N .
I	I	Pw(V'-1)+Ξ' 1 + (c0/2)(L - ')t
The integrand is nonnegative, so by Jensen,s inequality we have
产-')(^)-夕(L-'+1) (^'-1)
、2	严(V
)-∣Ξ'∣
W	Λ(^'-i)+ξ' (1 + (co∕2)(L - 4)t)
'j)
dt
2,
□
P
∣ 加")-
and an integration then yields
2
夕(L-')(^)-夕(L-'+D(^'T))
(Ξ')2
(D.139)
-|1 + (co∕2)(L - 'W(^'-1)∣∣1 + (co∕2)(L - 4)(以^'-1) +Ξ^)∣.
Choosing d ≥ 1∕c1, we can guarantee that whenever V ≥ Cn-C1d/2, one has
CvJX + Cn-cιd - 2Cv
n
(D.140)
150
Published as a conference paper at ICLR 2021
and choosing n ≥ 64C2dlog n, We can guarantee that
2 - 2。"4
V
≥ 4 ,
(D.141)
In particular, the last condition guarantees 2C，d log n/n ≤ 1/4. By concavity of 夕 via Lemma E.5,
we have 夕(V'-1) ≥ ν'-1∕2, and using (D.138) to obtain
P Fl ≤ C铲-1∖∕⅛n + C0n-cιd F'-1 ≥ 1 - C00n-c叫
we have by (D.140) and (D.141) as well as the concavity lower bound on φ
P[(X^'T) +Ξ' ≥ ν'-1∕4 ∣ F'-1] ≥ 1 - C00n-cιd
as long as ^`-1 ≥ (C0∕C)n-cιd/2. In particular, plugging these bounds into (D.139) and taking
square roots, we obtain by a union bound
P
dL-')(^')-
V'-1
1 + (co∕8)(L - ')V'-1
≥ 1 - 2C00n-cd
F'-1
whenever V'-1 ≥ (C0/C)n-c1d/2. Meanwhile, when V'-1 ≤ (C0/C)n-c1d/2, if we choose n ≥
d log n we have
CV'-1
+ C0n-cιd ≤ 2C0n-c1d/2,
and we can use the 1-Lipschitz property of 夕(L-'), which follows from Lemma E.5, to obtain using
(D.138)
p[∣ 夕(L-')(V')-夕(L-'+1)(V'-1) ∣ ≤ 2C0n-cιd/2 ∣ F'-1i
≥P
+ C0n-cιd F'-1
≥ P ∣ ^' - 9(V'T) ∣ ≤ CV'-1 ydɪ0gn + C0n-cιd ∣ F'-1
≥ 1 - C00n-cιd.
Because |夕(L-')(V')-夕(L-'+1)(^'-1)∣ ≥ 0, we can then obtain using a union bound
∣ 加-')(V')-
“l-'+1)(V'T)
2C^'-1
1 + (co∕8)(L - DVeT
2C0
+而乐
F'-1
≥ 1 - 3C00n-c1 d,
which holds regardless of the value of ^'-1. We can then obtain the second bound using this one,
via a partition of the expectation: let
E = I ∣ "l-')(^')- dL-'+1)(^'-1)
d log n
n
2CV'-1
1 + (co∕8)(L - ()^'-1
+ 2C 0n-c1d∕2 },
P
so that E ∈ F', and P[E ∣ F'-1] ≥ 1 - 3C00n-c1d by our work above. Then we have
E (JLT)(V')-产-'+I)
2
(^'-1))	F'-1
≤ E (dL-')(^') - dL-'+1)
(^'-1)) IE F'-1
+ π2E[1Ec ∣ F'-1]
≤ E 2C
V'-1
1 + (co∕8)(L - ()^'-1
+ 2C0n-c1d∕2 )
F'-1
+ C 000n-cιd
V'-1
1 + (co∕8)(L - (IWT
+ 2C0n-cid/2 ) + C000n-c1d
≤ 2≠^
2
151
Published as a conference paper at ICLR 2021
where the first inequality uses the triangle inequality to obtain (夕(L-')(^')-夕(L-'+D(^`-1))2 ≤
π2 ; the second inequality applies the definition of E , uses nonnegativity to drop the indicator in
the first term, and applies the conditional measure bound on Ec ; and the final inequality inte-
grates. Using the fact that our previous choices of large n imply 2C，d log n/n ≤ 1/4, and that
| i+(cci∕8)(l-')^'-i | ≤ ∏, We can distribute the square in this final bound and worst-case constants
to obtain
E [(dL-')(V') - dL-'+I)(V'-1))2
F'-1
≤ 4C2* (1 + (co∕8)(L- ')V'-ι
+ C0000n-c1d/2
as claimed.
□
Lemma D.26. Let X1 , . . . , XL be independent chi-squared random variables, having respectively
dι,...,dL degrees offreedom. Write dmin = mini∈ L d and let ξi = ∙J- Xi. Then there are absolute
constants c,C > 0 and an absolute constant 0 < K ≤ ɪ such that for any 0 < t ≤ K, one has
L
P -1 +Yξi
i=1
> t ≤ CLe-cdmint2/L
In particular, there are absolute constants C0 , C00 > 0 and an absolute constant K0 > 0 such that
for any d > 0, if dmin ≥ K0dL then one has
P
L
-1 + Yξi
i=1
Proof. For any t ≥ 0, we have by the AM-GM inequality
L
P Y ξi > 1 + t = P
YY ξj"> (1+ ^ L
≤P
L
L Xξi > (i + t)1/L
L i=1
By convexity of the exponential, we have (1 + t)1/L ≥ 1 + L log(1 +1), and by concavity of the
logarithm we have log(1 + t) ≥ t log 2 ift ≤ 1. This implies
L
P Y ξi > 1+t
i=1
L
≤P -L+Xξi > Kt,
i=1
where K = log(2). Decomposing each Xi into a sum of di i.i.d. squared gaussians and applying
Lemma G.2, we obtain
L
P -L + X ξi >t
i=1
t2	t
≤2exp (-c minI PL=12 ,Cm^j
≤ 2exp (-c0dmin min{t2∕CL,t})
(D.142)
2eχp (-c00dmn-
where the last inequality holds provided t ≤ CL, where C > 0 is an absolute constant. Thus, as
long as t ≤ CL/K, we have suitable control of the upper tail of the product Qi ξi . For the lower
tail, writing log(0) = -∞, we have for any 0 ≤ t < 1
L
P Y ξi < 1-t
L
P X log ξi < log(1 - t)
i=1
L
≤P Xlogξi < -t
i=1
where the inequality uses concavity of t 7→ log(1 - t). By Lemma G.2, we have for each i ∈ [L]
and every 0 ≤ t ≤ C (where C > 0 is an absolute constant)
P[∣ξi - 1| <t] ≤ 2e-cdit2,
≤
152
Published as a conference paper at ICLR 2021
so that by a union bound and for t ≤ C√L, we have with probability at least 1 - 2Le-cdmint2/L
that 1 - t∕√L ≤ ξi ≤ 1 + t/VL for every i ∈ [L]. Meanwhile, Taylor expansion of the smooth
function x 7→ log x in a neighborhood of 1 gives
log X =(X - I) - 2k2 (X - 1)2,
where k is a number lying between 1 and x. In particular, if X ≥ 1 we have log X ≥ (x - 1) - 2(x -
1)2, whence for t ≤ min{C√L, 2}
P
L
Y ξi < 1 - t
i=1
≤ 2Le-cdmint2/L + P -L
L
+Xξi < -t+2t2
i=1
≤
Lt
2Le-cdmint/L + P -L + y^ξi < --
where the final inequality requires in addition t ≤ 1. An application of (D.142) then yields the
claimed lower tail provided t ≤ CL, which establishes the first claim. For the second claim, we
consider the choice t =，dL/cdmin, for which we have t ≤ K whenever dmi∏ ≥ dL/cK2, and
cdmint2/L = d.
Lemma D.27. Let Xι,...,XL be independent Binom(n, 1) random variables, and write ξi
2Xi. Thenforany 0 < t ≤ 1, one has
□
L
P -1 +Yξi
i=1
>t
≤ 4Le-nt2/8L.
In particular, for any d > 0, if n ≥ 128dL then one has
L
P -1 +Yξi
i=1
Proof. The proof is very similar to that of Lemma D.26. For any t ≥ 0, we have by the AM-GM
inequality
P
L
Y ξi > 1 + t
i=1
YY ξ)"L> (1+ t)1/L
≤P
L
L X ξi > (1 + t)1/L
L i=1
P
By convexity of the exponential, We have (1 + t)1/L ≥ 1 + L log(1 +1), and by concavity of the
logarithm we have log(1 + t) ≥ t log 2 ift ≤ 1. This implies
L
L
P Y ξi >
i=1
1 + t ≤ P -L + X ξi > Kt, ,
i=1
where K = log(2). Decomposing each Xi into a sum of n i.i.d. Bern( 1) random variables and
applying Lemma G.1 twice, we obtain
L
P	-L+Xξi
i=1
>t
≤ 2e-nt2/2L.
(D.143)
This gives suitable control of the upper tail of the product i ξi. For the lower tail, writing log(0)
-∞, we have for any 0 ≤ t < 1
P
L
Y ξi < 1 - t
i=1
L
X log ξi < log(1 - t)
i=1
≤P
L
X log ξi < -t ,
i=1
P
where the inequality uses concavity oft 7→ log(1 - t). By Lemma G.1, we have for each i ∈ [L]
P[∣ξi - 1| <t] ≤ 2e-nt2/2,
153
Published as a conference paper at ICLR 2021
so that by a union bound, we have that 1 -1/√L ≤ ξ ≤ 1+1/√L for every i ∈ [L] with probability
at least 1 — 2Le-nt/2L. Meanwhile, Taylor expansion of the smooth function X → log X in a
neighborhood of 1 gives
log X =(X - I) - 2k2 (x - 1)2,
where k is a number lying between 1 and x. In particular, if x ≥ ɪ We have log x ≥ (x — 1) - 2(x -
1)2, whence for t ≤ 1/2
-L	-
p ∏ ξ < 1 -1
_i=1	.
L
≤ 2Le-n产/2L + P -L + X ξi < -t + 2t2
_	i=1
≤ 2Le-n产/2L + P -L + X ξi < -1 ,
_	i=1	_
where the final inequality requires in addition t ≤ 1/4. An application of (D.143) then yields the
claimed lower tail, which establishes the first claim. For the second claim, we consider the choice
t =，8dL/n, for which we have t ≤ ɪ whenever n ≥ 128dL, and nt2/8L = d.	□
E铲={∣y ∣∣F ≤ c 2n(j)
Lemma D.28. For 1 ≤ ' < ' ≤ L — 1 define events
∩	{gx∕]l≤ C(' - ',)}
∩	{tr [bX∕]≤ Cn}
and
E铲={ 3'T(x) I I 2∣∣ɑ'-1(x/)∣∣2 >。}	∩	卜 T)(V)-∕τ∣≤ Ct 冷n
∩	E管.
If n, L satisfy the assumptions of corollary D.17 then
P ∣⅛[ ≥ 1 - C'n(' - '0)2e-c壹.
If n, L additionally satisfy the conditions of lemmas D.3, E.16 and n ≥ C"L log(n) (log(L) + d),
then
P [eB] ≥ 1 - C0n-cd.
where c, C, Cz, CH are absolute constants.
Proof. Since
n
tr 怛罪：[=Xe丁τ*'+2(x叫+epi”+k广1:,+2*3)βi,
i=1
applying corollary D.17 2n times gives
P ∩	{ I ∣ Γ'T*'+2(z)ei∣∣2 ≤ √C} ≥ 1 - C0n(' - `)2e-c4
z∈{x,x0},i∈[n]
⇒ P Itt IBxXI：[ ≤ CnI ≥ 1 - C n(` - `)2e-c缶.
With the same probability we also have
max ∣∣r'-1:'0+2(z)∣∣ = max 严[γ'T''+2"(n)Γ'T''+2(n)] ≤ Cn
154
Published as a conference paper at ICLR 2021
and
P max ∣∣Γ'τ*'+2(z)∣∣ ≤ √C(' - '0) ≥ 1 - C〃(' - 40)3e-c壬
z∈{x,x0} Il	Il
from which it follows that
P h I WXI:'°|| ≤ C(' - ')] ≥ 1 - C〃(' - ')3e-c金
and
P I IBXX/F ≤ C2n(' - ')
≥ P max}||r'T：'0+2(z)112 max } ∣∣Γ'T'0+2(x)∣∣2 ≤ C2n('- ,)"∣
≥ 1 - C00(' - ')3e-c4 - C0n(' - 0)2e-c士
≥ 1 - C"'n(' - `)2e-c士.
It follows that £铲 holds with the same probability.
From lemma E.16,
P [ ∣ ∣ a'-1(x) ∣ ∣ 2 ∣∣a'T(x0)∣∣2 > 0 ∩ ν`-1 = b'-1] ≥ 1 - C0'e-Cn
for some constants c, C0. Here bg-1 is the auxiliary angle process defined in (D.2). Using D.3, We
obtain
P IdeT)(V) - ∕一1∣≤ C S d3lng ] ≥ P IdeT)(V)-ν'-1∣ ≤ C S 序了 n E +P [E c]
≥ 1 - C"0'e-cn - Cπn-cd ≥ 1 - C0n-cd
for an appropriate choice of c, C0.
We conclude that
P [eB] ≥ 1 - Cze-c°n - C"n'2e-c”登-Cnn-c，，d
≥ 1 - Cn-Cd
for appropriately chosen constants, where we used n ≥ C"" `log(n) (log(') + d).	□
Lemma D.29. For ʌ` defined in (D.34) and E&° defined in lemma D.28 we have
P [∣ιE皆ʌ`l > c√d'∣ Fe-1]
≤ Ce-cd.
a.s.
for some constants c, C, C
Proof.
IE铲，ʌ`	=IE今，(ʌ` - E∆e∣Fe-1)
=⅞r Yt-F ) (tr [BX：X： i-吃 tr [B匐)，
and denoting 刊⑦，=Pg(X)Pg 3)we have
tr [bX" - Wgtr [bX" = tr B^e' (W f,, W ` - WyW e*PXχ, W e])
Defining S` = span{ae(x), αe(x 0)} we decompose We into a sum of two independent terms as
We = W ePs'-ι + W ePsg-1⊥ ≡ Gg + H `.
155
Published as a conference paper at ICLR 2021
Note that each H' is independent of every other random variable in the problem conditioned on the
features. 1£g：g，tr [b^XJ thus decomposes into a sum of four terms, which We proceed to consider
individually and show that they concentrate.
The all Gg term is
dim Sg-I
IE铲tr 怛罪*'G'*⅛G'] = IE铲	X	ugτ*⅛1 :g u'Tu'τ*W'i⅛W'u'τ
B	B i,j = 1
where {ug-1} is an orthonormal basis of S`-1. If a'-1(x) = a`-1(x0) we choose
/ g-1 g--l∖ ― ( α'-1(x)	PagT(X)⊥α' 1(χ0) x
(U1 , u2 ) =( Kx)k2 , IIPaJ(X)⊥α'-1 ① Il2 ),
(which are well-defined on EBg j.Using rotational invariance of the Gaussian distribution, we have
遍 W 'τ*pg-1+1W '-1uj
d g-1* ŋ* τɪr'-1* D	D	TV'—1 D„,'— 1
=Ui	RW	PWg-1Rag-1(x0)>0pWg-1Rαg-1(x)>0 W	RUj
=^∖Pg∖ cos νg-1+g2 Sin νg-1>0gi, Pgi >0gj)
where gi 〜同 N(0, 21). If a'-1(x) = a`-1(x0) then dim Sg-1 = 1 and we simply choose
u1-1 = k；-I((X))k and end up with an identical expression, with Vg-1 = 0. Since Pgi>0gj and
Pgi cos νg-ι+g2 sin ν"i>0gi are vectors of independent sub-Gaussian random variables with sub-
Gaussian norm bounded by Jn, their inner product is a sum of independent sub-exponential vari-
ables with sub-exponential norm bounded by S for some constant C. Momentarily abbreviating
V= g1 cos ν`-1 + g2 sin Vg-1, Bernstein,s inequality then gives
P	{Pv>0gi, Pg1>0gji - E hPV>0gi,马1>。gj > Jd 尸T	≤ 2e-cd	(d.144)
gi ,g2	V n	a.s.
for some constant c. Since on EBj ∣∣B'x1 *]∣ ≤ C', we obtain
dim Sg-1
Krtr [bgx1 :'0G'*Pχgχ0G'] I ≤ C' X	u'-1*W'*P'χ,W'uj-1
i,j = 1
almost surely and thus
P 必〃tr [b'x1='g'*⅛G'[ I > C,*∣ 产T
≤ 2e-cd
a.s.
for some C0, and hence
P
%"tr [b'x1''g'*P&G']
-WΛ 铲tr [b'x1"z g'*P'x, g']
≤ 2CC 沟 F'-1
≤ 2e-cn.
a.s.
(D.145)
tr [b'" also contains the terms
tr [8'.1：'七'*刊.0H'] + tr [b:/'H'*P^G'].
Considering the first of these (since the second can be treated in an identical fashion), we recall that
H' is independent of all the other random variables in the problem conditioned on the features, and
we thus have
IEgetr [B'-1：:'G:*Hx,H'] = 1?`g,tr ∖b^^:*P'x'W'Ps-1⊥]
ER	XX	Xx	ER	XX	XX	2
dim SgT
=X 1e 铲 v'* W 'w'
i=1
156
Published as a conference paper at ICLR 2021
where W' is an independent copy of W', v' = 刊苏u', Wi = Ps'-ι⊥ BxxI:'u'. Hence
conditioned on all the other variables, v'*Wiw' is a zero-mean Gaussian with variance
NUknkwi"21ε 铲.Again from the bound on IBMaI implied by EBJ we have
2帆阴陷|
2
~ 1?伊0
almost surely. Noting that Egtr 怛仁产‘G" P% Hi]
Gaussian tail bound gives
dim S'-1
EE tr P	v'*W'w'
Ge WW'	i	i
P IE铲 tr [Bxx1='G'*P^Hi]-吃IE铲 tr 怛仁产七'*或,Hi]	> √ Fi-1
≤ 2e-cn .
a.s.
The final term in tr
[b留
is
0, a
(D.146)
n
tr 但祟。He*P%Hi] = tr 怛罪*%…W'*P& WiPs'-ι⊥].
Due to the independence of Wi from the remaining random variables, this is simply a Gaussian
chaos in n2 variables. The Hanson-Wright inequality (lemma G.4) gives
P	IE铲 tr [b'x 1：£，Hi*p`x,Hi]-吃IE铲 tr 但祟’Hi*P'X,Hi]	≥ t Fi-1
≤ 2 exp
a.s.
-cnt min
∖
≤ 2 exp
a.s.
(-cnt min J t-ι 1)
k ' In, ʃ
where in the last inequality we used the definition of EBJ It follows that
P	1e“tr [B'-1：i,Hi*PiX,Hi] - E “tr [B'.产'Hi*P'X,Hi] > 2√d` FiT
eb	XX	X X W w` eb	X X	X X
P [ IE':〃tr [B'-1：i，Hi*pix,Hi] - E IE“tr [bi-1='Hi*P'X,Hi] > √d' FiT
EB LX X	X X J	ʃʃ ` EB	LX X	X X	J
≤
"."+P	弟IE铲 tr [bix1='H'*piX,Hi]-吃IE铲 tr [bix1='H'*P'x,Hi] > √d' FeT
P [ IE':〃tr [B'-1：i 'He*piX,Hi] - E IE“tr [b'-1：' 'H'*P'x,Hi] > √d' FiT
EB L XX	xx J	ʃʃ` EB	L XX	xx J
tr 回〃]-弟tr [Pix,] > √d' FiT
a.s.
+P
1e铲,
2tr
"1⊥
1：i
/
2-1⊥
≤
n
≤ Ce-cd
a.s.
(D.147)
where in the last inequality we used (D.144) and the properties of EBi：i . Collecting terms and using
(D.145), (D.146), (D.147) we obtain
P I?铲 tr [BX：Xj - tr 怛用 >C √d' FiT	≤ C 0e-cd	(D.148)
157
Published as a conference paper at ICLR 2021
and hence
［卜
[明 -
a.s.
Et tr IBxxj >C √d' F'-1
(D.149)
Lemma D.30. For x ∈ Sn0-1 and Q ∈ [L], denote I'(x) = supp(α'(x) > 0). If n ≥ K then
P min ∣I'(x)∣ ≥ n ≥ 1 - 2LCe-cn
and for any 0 ≤ t ≤ 1
一 L
π
.'=1
2 ∣I'(x)∣
n
-1≥t
≤ 2 exp (-cg2
P
P
□
where c, c0, C, K are absolute constants.
Proof. Consider the activations at layer Q. From lemma E.16, if n ≥ K We have
P [∣∣a'-1(x)∣∣2 > 0] ≥ 1 - Cef.
Rotational invariance of the Gaussian distribution gives a'(x)	=	[W'a'-1(x)]十
∣∣a'-1(x)∣∣2 [wj J . It follows that
E ∣I'(x)∣ ∣∣α'-1(x)∣∣2 > 0
∣∣α'-1(X)∣∣2 > 0
∣∣a'-1(X)∣∣2 >0
From the symmetry of the Gaussian distribution
E ∣I'(x)∣ ∣∣α'-1(x)∣∣2 > 0
n
2
Since this variable is a sum of n independent variables taking values in {0,1}, an application of
Bernstein,s inequality for bounded random variables (lemma G.3) gives
pH∣I'(x)∣- n∣>4] ≤P M(X)I- 2>n ∣∣α'-1(X)∣∣2 >0 + p[∣∣α'-1(X)∣∣2=0]
≤ 2eχp (-c' nn+n⅛ )+ce-cn≤ C -
for appropriate constants. A union bound gives
L
P ∩{∣∣I'(x)∣- 2>n} ≤ 2LC0e-c"n
.'=1
158
Published as a conference paper at ICLR 2021
from which
P min ∣I'(x)∣ ≥ n ≥ 1 - 2LC0e-c"n
follows.
To prove the second inequality, we use the AM-GM inequality which gives
L L 9lr ,、、1〃	2P ∣i'(χ)∣
Y 2 lI'(X)I )	≤ '=1
IIn	n nL
、'=i	)
and hence
P
L
Y
1=1
2 ∣I'(x)I
n
≥1+t
L	1/L
Y 2≡!
、'=1	)
≥ (1 + t)1/L
P
≤ P [XT 2JIIχ!≥ L (1+ 及L
L'=1	n
Convexity of the exponential gives (1+ t)1/L ≥ 1 + L log(1+1) and for t ≤ 1 we have log(1+1) ≥
t log 2, giving
L
Y
,'=1
2 ∣I'(x)I
n
≥1+t
≤P
2 ∣I'(x)I
n
- L ≥ t log 2
We note that
L
X
∙'=1
2 ∣I'(x)I
n
P
where b' = 2θ', θ' 〜同 Bern( 11) and E'
{maxb'-1 = θ} is the event that the features at layer
nn
' -1 are not identically 0. Since P 1e' b' ≤ P b' a.s. We have
P [XT 2j⅞xi-L ≥ t log2∣≤ P [XTX b' - L ≥ t log2 .
'=1 n	'=1 i=1
Since this is a sum of independent bounded random variables, an application of Bernstein’s inequal-
ity for bounded random variables (lemma G.3) gives
Ln
P	TTbi'-L≥t
'=1 i=1
t2
≤ 2 exp -c---ʒ----5—
≤ Pl	P E(b')2 + 21
2 exp (-c0nt2
for some absolute constant c0, where we used L ≥ 1 ≥ t. Hence
P
L
Y
'=1
2 ∣I'(x)I
n
-1≥t
≤ 2 exp
□
E S harp Bounds on the One-Step Angle Process
In this section, we characterize the process by which angles between features for different pairs
of points evolve as they are propagated across one layer of the zero-time network. This section is
self-contained, and as such it will occasionally overload notation used elsewhere in the document
for different local purposes. In particular, we will use the notation σ(x) = [x]+ for the ReLU in this
section (and only in this section), and σ(g) = 1g>o for its weak derivative.
159
Published as a conference paper at ICLR 2021
E.1 Definitions and Preliminaries
Let n ∈ N, with n ≥ 2. Let gι and g2 be i.i.d. N(0, (2∕n)I) random vectors; We use μ to denote
the joint law of these random variables. We write G ∈ Rn×2 for the matrix with first column g1 and
second column g2, and g1, . . . , gn for the n rows of G. If S ⊂ [n] is nonempty and A ∈ Rn×m, we
write AS ∈ RlSl×m to denote the submatrix of A consisting of the rows indexed by S in increasing
index order. In such situations Sc will always denote the complement relative to [n].
For 0 ≤ ν ≤ 2π, define random variables
vν(g1,g2) = σ (g1 cosν + g2 sinν) ,
and
VV(gι, g2) = σ(gι cos V + g2 Sin V) Θ (g2 Cos V - gι Sin V).
Because VV separates over coordinates of its arguments and has each of its coordinates the product
of a nondecreasing function and a continuous function, it is Borel measurable. A key property that
we will use throughout this section is that the joint distribution of (g1, g2) is rotationally invariant;
in particular, it is invariant to rotations of the type
G 7→ G
cos V
sin V
sin V
- cos V
where V ∈ [0, 2π]. Since we can write
cos V
sin V
cos V
sin V
- sin V
cos V
where all of the R2 vectors appearing above are elements of S1 , it follows by applying rotational
invariance and the specific rotation given above that
(VV, VV) = (V0, -V0).
This equivalence is useful for evaluating expectations and differentiating with respect to V.
If 0 < c ≤ 0.5 and m ∈ N0 with m < n, define an event
Ec,m = ∩	∩ {(gl, g2) I c ≤ kIScVV(gl, g2)k2 ≤ c-1}.
S⊂[n] V∈[0,2π]
|S|=m
For each c, m, the set Ec,m is closed, since kAVV k is a continuous function of (g1, g2) ∈ Em for any
linear map A. We further define
E0,m =	E1/(2k),m,
k∈N
so that
E0,m =	{(g1,g2) | 0 < kISc VV (g1, g2)k2},
S⊂[n] V∈[0,2π]
|S|=m
and E0,m is Borel measurable. If c is omitted, we take the constant c in the definition to be 0.5. On
Ec,m we guarantee that kVV k0 ≥ m uniformly on [0, π]. Define a function XV by
XV = lEι(占,FV ).
1	kV0k2 kVVk2
On E1 , we guarantee that VV 6= 0 for every V, so XV is well defined; because E1 is Borel measurable,
we have that XV is Borel measurable, and moreover |X“| ≤ 1, so XV ∈ Lpμ for every P ≥ 1. Finally,
define for 0 ≤ V ≤ π
O(V) = E [cos-1 Xv],	2(V)=Cos-1 E [hV0,VVi].
g1 ,g2	g1 ,g2
160
Published as a conference paper at ICLR 2021
E.2 Main Results
Lemma E.1. There exist absolute constants c, C, C0 > 0 and absolute constants K, K0 > 0 such
that if d ≥ K and n ≥ K0d4 log4 n, then one has
历(V)-爪V)| ≤ CVlogn + C0n-cd
n
Proof. Using the triangle inequality, we can write
|o(V)-2(V )| ≤ IO(V) - cos-1 E[Xν]∣ + I cos-1 E[Xν]-2(V )|.
Choose n sufficiently large to satisfy the hypotheses of Lemmas E.6 and E.7; applying these lemmas
to bound the first and second terms, we conclude the claimed result (after choosing n larger than an
absolute constant multiple of d log n so that the n-cd error dominates the e-c n error).	□
Lemma E.2. One has
θ(V)=cos-i ɑi - V) cos V +SinV).
Proof. See (Cho & Saul, 2009).	□
Lemma E.3. There exist absolute constants c, C, C0 , C00 > 0 and absolute constants K, K0 > 0
such that ifd ≥ K and n ≥ K0d4 log4 n, then one has with probability at least 1 - C 00 n-cd
1cos-1 XV - o(v)i ≤ CVJdlogn + C0n-cd.
The constant c is the same as the constant appearing in Lemma E.1.
Proof. Under our hypothess, the second result in Lemma E.6 together with Lemma E.1 and the
triangle inequality imply the claimed result (after worst-casing multiplicative constants).	□
Lemma E.4. There exist absolute constants c, C, C0 > 0 and absolute constants K, K0 > 0 such
that ifd ≥ K and n ≥ K0d4 log4 n, then one has
Eh(COS-1 Xν - o(v))[ ≤ CV2 d-l°g-n + C0n-cd.
The constant c is the same as the constant appearing in Lemma E.1.
Proof. Under our hypotheses, Lemma E.3 is applicable; we let E denote the event corresponding
to the bound in this lemma. By boundedness of cos-1, nonnegativity of XV, and φ ≤ n/2 from
Lemma E.2, we have kcos-1 Xν - O(V)kL∞ ≤ π. Thus
Eh(COS-1 XV — o(v))2i ≤ e[1e (cos-1 XV — o(v))2] + C00π2n-cd
≤ 卜Vrdlogn + C0n-cd! + C00∏2n-cd
≤ C2V2 生邺 + C000n-cd,
n
as claimed.	□
Lemma E.5. One has
1.	o ∈ C∞(0, π), and S and 0 extend to Continuousfunctions on [0, π];
2.	s(0) = 0 and s(π) = π∕2; 0(0) = 1, 0(0) = -2∕(3π), and。(0) = -1∕(3π2); and
θ(π) = 0(π) = 0;
3.	0 is concave and strictly increasing on [0, π] (strictly concave in the interior);
161
Published as a conference paper at ICLR 2021
4.	0 < —c < 0 for an absolute constant c > 0 on [0, π∕2];
5.	0 <0 < 1 and 0 >0 ≥ —C on (0, π) for some absolute constant C > 0;
6.	ν(1 — C1ν) ≤ 0(ν) ≤ ν(1 — c1ν) on [0, π] for some absolute constants C1, c1 > 0.
Proof. Deferred to Appendix E.4.
□
E.3 Supporting Results
E.3.1 Core Supporting Results
Lemma E.6. There exist constants c, C, C0 , C00 , C000 , C 0000 > 0 and an absolute constant K > 0
such that for any d ≥ 1, ifn and d satisfy the hypotheses of Lemmas E.9 and E.10 and moreover
n ≥ Kd log n, then one has
E [cos-1 Xν] — cos-1 E [Xν] ≤ CVɪog n + C0n-cd,
g1 ,g2	g1 ,g2	n
and with probability at least 1 — C00n-cd, one has
I cos-1 XV — E[cos-1 Xν]| ≤ C000V,dl0gn + C0000n-cd.
Proof. Fix v ∈ [0,π]. The function cos-1 is smooth on (一δ, 1) if 0 < δ < 1, and Taylor expansion
with Lagrange remainder on this domain about the point E[Xν] (by Lemma E.23, we have 0 ≤
E[Xν] < 1 if V > 0; we will handle V = 0 separately below) gives
cos-1 (x) = cos-1 E[Xν] —
1	ξ2
I	(X — E[Xν])-ξ—F (X — E[Xν])2,
√1 — E[Xν]2	2(1 — St3/' V VJ； ,
where ξ lies between X and E[Xν]. Using the fact that Xν 6= 1 almost surely if V > 0, which is
established in Lemma E.23, we plug in X = Xν to get
cos-1 E[Xv] - CoS-I(XV) = √1 一 E[χ下(X - EXVD + 2 (1 一^(XV))2)3/2 (XV - E[XV])2 ,
ν	(E.1)
where we now express ξ as a function of XV . From Jensen’s inequality it is clear
E[cos-1 XV] ≤ cos-1 E[XV],	(E.2)
so all that remains is to obtain a matching upper bound for the righthand side of (E.1). We will
make use of the following facts, proved in subsequent sections: there are absolute constants Ci > 0,
i ∈ [6], and ci > 0, i ∈ [5], such that
1.	E[XV] ≤ 1 — c5V2 + C1e-c1n. (Lemma E.8)
2.	For each V, Var[XV] ≤ C5V4 log n∕n + C2e-c2n. ( Lemma E.9)
3.	With probability at least 1 — C3n-c3d, one has |X“ — E[Xv]∣ ≤ CqV2 √dlog n/n +
C4e-c4n. (Lemma E.10)
Let E denote the event on which property 3 holds. Combining properties 1 and 3, we obtain with
probability at least 1 — C3n-c3d
XV ≤ 1 — (c5/2)V2 + C1e-c1n + C4e-c4n,
provided n is chosen larger than an absolute constant multiple of dlogn. Thus, defining
4
Vo = — (C1e-c1n + C4e-c4n),
c5
162
Published as a conference paper at ICLR 2021
we obtain for ν ≥ ν0
E[Xν] ≤ 1 —4ν2,	XV ≤ 1 —4V2,	(E.3)
with the second bound holding with probability at least 1 - C3n-c3d. Considering first 0 ≤ ν ≤ ν0,
we obtain using the triangle inequality, Lemma E.20 and property 3
cos-1E[Xν] -Ecos-1(Xν)	≤ E1Ecos-1E[Xν] - cos-1(Xν)
+ E1E c cos-1 E[Xν] - cos-1 (Xν)
≤ e[1ep∣Xν — E[Xν]|i + E[1ec∏∕2]
≤ Ce-cn + C0n-c0d,	(E.4)
(E.5)
(E.6)
(E.7)
with the final inequality following from the triangle inequality for the `2 norm and the fact that
ν ≤ ν0. Meanwhile, if ν ≥ ν0, we have by (E.3)
0 ≤ ξ(Xν) ≤ max{Xν, E[Xν]} ≤ 1 - c5V
with probability at least 1 - C3n-c3d. Using 1 - x2 = (1 + x)(1 - x) and E[Xν] ≥ 0, ξ(Xν) ≥ 0,
we have under this condition on ν
1	12
≤	= ≤	,	= ≤ 一
√1 - E[Xν]2 - √1 - E[Xν] — C5V
and similarly
ξ(Xν)	4 π
2(1-ξ(Xν)2)3/2 ≤ C5V3IE + 2IEE
Applying (E.6) and taking expectations in (E.1), we obtain by property 2
cos-1 E[Xν] - E[cos-1 Xν] ≤ CVlogn + C0e-cn + C00n-c3d
n
Together, (E.2), (E.4) and (E.7) establish the first claim provided n is chosen larger than an absolute
constant multiple of d log n.
For the second claim, we begin by using the triangle inequality to write
cos-1 Xν - Ecos-1 Xν ≤ cos-1 Xν - cos-1 E[Xν] + cos-1 E[Xν] - Ecos-1 Xν ,
and then observe that our proof of the first claim implies suitable control of the second term. For the
first term, if V ≤ V0 we use Lemma E.20 to immediately obtain with probability at least 1 -C3n-c3d
that this term is at most Ce-cn . For V ≥ V0, we apply property 3 and the bounds (E.5) and (E.6) in
the expression (E.1) to obtain with probability at least 1 - C3n-c3d
Icos-I XV - cos-1 EXV]∣ ≤ CVrdɪθgn + C0νdlogn,
which is of the claimed order when n is chosen larger than an absolute constant multiple of dlog n.
□
Lemma E.7. There exist absolute constants c, C, C0, C00 > 0 such that if n ≥ C log n, one has
中(V) - cos-1 E [Xν] ≤ C0e-cn + C00V.
∣	g1 ,g2	∣	n
Proof. Write f(ν) = cos 夕(ν), and
h(V) = E[XV] - f(V),
so that h is the residual between the two terms whose images we are trying to tie together. We will
make use of the following results:
1. The function cos-1 is ɪ-Holder continuous on [0,1], so that ∣cos-1 X — cos-1 y∣ ≤ '∣X — y∣
ifx,y ≥ 0. (Lemma E.20)
163
Published as a conference paper at ICLR 2021
2.	For V ∈ [0,π], we have 1 - 1V2 ≤ f(ν) ≤ 1 - c2v2. (LemmaE.14)
3.	For all 0 ≤ V ≤ π, ∣h(ν)| ≤ Cιe-c1n + C2ν2∕n. (LemmaE.15)
We choose n large enough that the hypotheses of Lemma E.15 are satisfied. Define ν0 =
2，Ci/c2e-c1n/2. We split the analysis into two sub-intervals: I、:= [0,ν0], and I2 := [ν0,π].
Choosing n larger than an absolute constant multiple of log n, we guarantee that I1 and I2 both have
positive measure.
On I1, we proceed as follows:
I cos-1 f - cos-1(f + h)∣ ≤ pp∣h∣
≤ pp∕Cιe-c1n + C2ν2/n
≤ JCIe-CIn + 4C1C2c-1e-cιn
1
≤ Ce- 2 c1n.
The first inequality uses Holder continuity of cos-1, the second uses our bound on the residual, the
third uses the definition of I1 , and the fourth worst-cases the constants.
On I2 , we calculate
V2
|f + h| ≤ |f | + |h| ≤ CIe c1n + C2-+1 - CWV,
n
using the triangle inequality and our bounds on |h| and f. Using the conditions V ≥ V0 and choosing
n ≥ 4C2/c2, we can rearrange to get
C1e-c1n + C2 ν2 ≤ c2V2,
n2
which implies |f + h| ≤ 1 - c2V2/2. By the control f(V) ≤ 1 - c2V2, valid on I2, we get that both
f and f + h are bounded above by 1 - c2V2/2 on I2 ; moreover, because f ≥ 0 and f + h ≥ 0, we
can apply local Lipschitz properties of cos-1 on I2 . This yields
1cos-1 f - cos-1(f + h)〔 ≤ /	|h|
1/1 - (SUpI2 max{f, f + h})
≤ C1e-c1n + C2V2 /n
≤ ∕ι -(1 - (c2∕2)Vψ
_	C1e-cιn	+	C2V2/n
q1 c2ν2(2 -1 c2ν2)	q2c2ν2(2 - 2c2ν2)
≤ CV-1e-c1n + C0V/n
1
≤ Ce-2 c1n + C0v/n.
Above, the first inequality is the instantiation of the local Lipschitz property; the second applies our
upper and lower bounds on f and f + h derived above, and our bound on the residual |h|; the fourth
applies the bound 0 ≤ f (ν) ≤ 1 - 2c2ν2 to conclude 2 - 1 c2ν2 ≥ 1 on I2, and cancels a factor
of v in the second term; and in the last line, We apply V ∈ I2 to get V ≥ 2，C1/c2e-C1n/2, which
allows us to cancel the V-1 factor in the first term of the previous line.
To wrap up, we can choose the largest of the constants appearing in the bounds derived for I1 and
I2 above and then conclude, since I1 ∪ I2 = [0, ∏] under our condition on n.	□
E.3.2 Proving Lemma E.6
Lemma E.8. There exist absolute constants c, c0 , C, C0, C00 > 0 such that if n ≥ C and if n is
sufficiently large to satisfy the hypotheses of Lemma E.15, one has
1 - C00V2 - C0e-c0n ≤ E [Xν] ≤ 1 - cV2 + C0e-c0n .
g1 ,g2
164
Published as a conference paper at ICLR 2021
Proof. By the triangle inequality, we have
|cos 夕(V) | -∣E[Xν] — Cos 2(V) | ≤ E[Xν] ≤ |cos 夕(V) | 十 ∣E[Xν] — Cos 2(V) |.
Applying Lemmas E.14 and E.15 with m = 0, we get
1 - C00V2 - Ce-c0n - C0V2/n ≤ E[Xν] ≤ 1 - cV2 + Ce-c0n + C0V2/n,
which proves the claim if We choose n ≥ 2C0/c.	□
Lemma E.9. There exist absolute constants c, C, C0 > 0 such that if n satisfies the hypotheses of
Lemmas E.11 and E.12, then one has for each V ∈ [0, π]
VarXM ≤ CV4log n + C0e-cn.
n
Proof. We use the following elementary fact for a random variable with finite first and second mo-
ments, easily proved using Var[Xν] = E[Xν2] - E[Xν]2 and Fubini’s theorem: in this setting one
has
Var[Xν] = E[Var[Xν(gι, ∙)]] +Var[E[Xν(∙,g2)]].
g1	g2
ByLemma E.11, there is an event E of probability at least 1 - Ce-Cn on which VarXV(gι, ∙)] ≤
C0V4 /n + C00e-c0n. Invoking as well Lemma E.12, we obtain
Var[Xν] ≤ E[(1e + 1eC)Var[Xν(gι, ∙)]] + C“V4 logn + C0000e-c”n
g1	n
≤ CVnogn + C0e-cn + P[Ec]1/2 E [Var[Xν(gι, ∙ )]2]1/2
≤ CV4产 + C0e-cn,
as claimed, where in the second line we applied nonnegativity of the variance and the Schwarz
inequality, and in the third line we used the fact that kX kL2 ≤ kX kL∞ for any random variable X
in L∞.	□
Lemma E.10. There exist absolute constants c, c0, C, C0, C00 > 0 and absolute constants K, K0 > 0
such that for any d ≥ 1 such that n and d satisfy the hypotheses of Lemmas E.11 and E.13 and
n ≥ max{K log n, K0d}, for any V ∈ [0, π], one has
PXV - E [XV] ≤ C00V2Jdlogn + Ce-Cn ≥ 1 - C0n-c0d.
g1 ,g2	n
Proof. By Lemma E.11, we have
P XV - E[Xν] ≤ C00V2aI- + Ce-Cn
g2	n
≥ 1 - C0e-C0d.
Let ψ = ψ0.25 denote the cutoff function defined in Lemma E.31, and write
YV(g1, g2)
vo (gι, g2)VV (gι, g2)
ψ (kv0(g1,g2)k2), ψ (kV"(gl,g2)k2)
By Lemma E.13, we have
P
E [YV] - E [YV]
g2	g1 ,g2
≤ C00V2
+ Cne-Cn
≥ 1 - C0n-C0d
We have XV = YV on the event E1, by Lemma E.16, and we thus calculate using the triangle
inequality
E	[YV]	- E	[XV]	≤ E	[|XV -YV|]	= E	1E1c YV	≤ Cne-Cn,
g1 ,g2	g1 ,g2	g1 ,g2	g1 ,g2	1
165
Published as a conference paper at ICLR 2021
where the last inequality uses Holder,s inequality and the measure bound in Lemma E.16. Again
using the triangle inequality, we have
E[Xν] - E[Y；] ≤ E[∣Xν - Yν|],
g2	g2	g2
and so using our previous calculation and Markov’s inequality, we can assert
P E [Yν] - E [Xν] ≤ Cne-cn/2 ≥ 1 - e-cn/2 .
g2	g2
The claim then follows from the triangle inequality, a union bound, and a choice of n larger than an
absolute constant multiple of log n and an absolute constant multiple of d.	□
Lemma E.11. There exist absolute constants c, c0, c00, c000, C, C0, C00, C000, C4, C5 > 0, and absolute
constants K, K0 > 0 such that for any d ≥ 1, if n ≥ max{K d, K0 log n}, then for every ν ∈ [0, π]
one has with probability at least 1 - C e-cn
VarXV(gι, ∙)] ≤ C4ν4 + C0e-c0n,
n
and with (g1, g2) probability at least 1 - C00e-c00d one has
XV — E[Xν] ≤ C5ν2∖∕d + C000e-c'00n.
g2 n
Proof. Fix ν ∈ [0, π]. Let E1 = E0.5,1 denote the event in Lemma E.16 which is in the definition
of XV. We start by treating the case ofν = 0 or ν = π. We have Xπ = 0 deterministically, so the
variance is zero and it equals its partial expectation over g2 with probability one. For the other case,
one has X0 = 1E1 ; we have
Var[X0(g1, ∙)] = E[1ei] - E[1ei]2 ≤ (1 - E[1eJ),
g2	g2	g2
and since E[1E1] = 1 - Cne-cn by Lemma E.16, we obtain by Markov’s inequality
PhVar[X0(g1, ∙)] ≥ Cne-cn/2i ≤ e-cn/2.
This gives a suitable bound on the variance with suitable probability. For deviations, we note that
E X0 - E [X0] = 0,
g2
and following our previous variance inequality but taking expectations over both g1 and g2 gives
Var[X0] ≤ Cne-cn , which implies by Chebyshev’s inequality
P X0 - E [X0] ≥ √Cne-cn/2 ≤ e-cn/2
g2
which is a suitable deviations bound that we can union bound with the event constructed below,
which controls deviations uniformly for the remaining values of ν. We therefore assume below that
0 < ν < π.
Let ψ(χ) = max{χ, 1}, which is continuous and differentiable except at X = ∣, with derivative
ψ0(x) = 1χ>ι∕8. We note in addition that X ≤ ψ(χ), and since ψ ≥ 8 We have for X ≥ 0 the bound
x∕ψ(x) ≤ 1. Define
YV(g1, g2)
hv0(g1, g2), VV (gι, g2)i
Ψ(IW0(g1, g2)k2)Ψ(kvν (gι, g2)k2)
We first show that it is enough to prove the claims for YV, which will be preferable for technical
reasons. On E1, we have YV = XV. We have |YV| ≤ 1, and we calculate
E [(Y；	- XV)2]	= E [1ec (YV	- XV)2]	≤ E	[1ec]1/2	E	[(Y；	- XV)4]1/2	≤ C E	[电]1/2,
g2	g2	g2	g2	g2
166
Published as a conference paper at ICLR 2021
where the first inequality uses the SchWarz inequality, and the last inequality uses that |X“ | ≤ 1 and
the triangle inequality, and where C > 0 is an absolute constant. We have by Tonelli’s theorem and
Lemma E.16
E E 1E1c 1/2 ≤ Cne-cn,
g1 g2
so Markov’s inequality implies
P E 1Ec1/2 ≥ Cne-cn/2 ≤ e-cn/2.
g2	1
Thus, with probability at least 1 - e-cn/2, we have
E(Yν - Xν)2 ≤ C0ne-cn/2,
g2
so that an application of Lemma E.32 yields that with probability at least 1 - e-cn/2
Var[Xν(gι, ∙)] ≤ Var[YV(gι, ∙)] + C00ne-c0n,
where we have worst-cased constants and the exponent on n. For deviations, we write using the
triangle inequality
Xν - E [Xν]
g2
≤ ∣Xν — YL| + YV — E [YV] + E [YV] — E [Xν]
g2	g2	g2
and then note that the first term is identically zero on the event E1 , which has probability at least
1 - Ce-cn, whereas for the third term, we have
E [Yν] — E[Xν] ≤ E h(YV - XV)2i1/2 ≤ CInL/,
g2	g2	g2
where the first inequality uses the triangle inequality and the Lyapunov inequality, and the second
inequality holds with probability at least 1 - e-cn/2, and leverages the argument we used to control
the difference in variances. Ultimately taking union bounds, we can conclude that it sufficient to
prove the claimed properties for Yν .
With 0 < ν < π fixed, we introduce the notation
ug1 = v0(g1);	vg1,g2 = vν(g1,g2),
so that
Y = /	ugl	vgl,g2	∖
V ∖ψ (kugι k2) , ψ (kvgl,g2 k2)/
For fixed gι, we will write YV (g2) = YV (gι, g2) with an abuse of notation. For g ∈ Rn arbitrary and
g2 fixed, we consider the function f (t) = YV(g2 + tg) for t ∈ [0,1]. Writing f for the derivative
of f where it exists, at any point of differentiability, we calculate by the chain rule
f0(t) = hVg2 Yv (g2 + tg), gi,
where
Vg2 YV (g2)
sin ν
ψ(kugι k2)ψ(kvg1,g2k2)
(I ψ0(kvgι,g2 k2)vgι,g2vg1,g2 ʌ(1	n
√ — Ψ(kVg1,g2 k2)kVg1,g2 k2 ) (Ivg"2 >0 0 ug1
Using the fact that
1vg1,g2 >0	ug1 = P{vg1,g2>0}ug1 ,
where P{vg ,g >0} is the orthogonal projection onto the coordinates where vg1,g2 is positive, to-
gether with the fact that
vg1,g2 vg1,g2 P{vg1,g2 >0} = P{vg1,g2 >0} vg1,g2 vg1,g2 ,
we can also write
▽g2 YV (g2)
sin ν
ψ(kugι k2)ψ(kvgι,g2 k2){vg1,g2 >0}
I _ ψ0(Hvg1,g2 k2)Vgl,g2 %,g2 )
- Ψ(kvg1,g2 k2)kvg1,g2 k2 ) g1.
(E.8)
167
Published as a conference paper at ICLR 2021
We next argue that f does not fail to be differentiable at too many points of [0, 1]. Because ψ > 0, it
will suffice to ShoWthat(i) t → Vg1,g2+tg and (ii) t → Ψ(∣Wg1,g2+tg∣∣2) are differentiable at all but a
set of isolated points in [0,1]. For the latter function, we note that at any point where ∣∣Vgι g +tg ∣∣2 <
1, by continuity we have that t → Ψ(∣∣Vg1,g2+tg∣∣2) is locally constant, and therefore differentiable
at such points. At other points, by Lemma E.21 it suffices to characterize t → ∣∣Vg1,g2+tgk2 as
differentiable at all but isolated points, and because ∣∣Vg1,g2+tgk2 ≥ 8 by assumption, the norm
is differentiable and by the chain rule it suffices to characterize differentiability of each coordinate
of t → Vgi ,g2 +tg, which settles the question of all-but-isolated differentiability of (i) as well. We
have Vgi,g2+tg = σ(gι cos V + g2 Sin V + tg Sin V), so again by Lemma E.21, we conclude from
differentiability of t → gι cos V + g? sin V + tg sin V that t → Vg1,g2+tg is differentiable at all but
isolated points, and consequently so is f . In particular, f is differentiable at all but countably many
points of [0, 1]. Next, we show that f0 has suitable integrability properties. Indeed, we calculate
using (E.8)
∣Vg2YV(g2)k2 ≤ 8v∣∣ I -
ψ0(IVg1,g2 k2)Vgl,g2 vgi,g2 A	ugi
ψ(kvgi,g2 k2)kvgι,g2 ∣2	ψ ψ(kugi ∣2)
2
8v ≠ — Ψ0(kvg1,g2 k2)YV (g2)2,
(E.9)
where we used Cauchy-Schwarz and ψ ≥ 8 in the first inequality and distributed and applied
(ψ0)2 = ψ0 and the estimate χ∕ψ(χ) ≤ 1 in the second inequality. In particular, this implies that
∣f0(t)∣ ≤ C∣g∣2, which is a t-integrable upper bound for every g. Because YV(gι, ∙) is continuous
by continuity of σ, ψ, and the fact that ψ becomes constant whenever ∣∣Vgι g ∣∣2 < 81, we can apply
(Cohn, 2013, Theorem 6.3.11) to get
YV (g2 + g)=
YV(g2) +
0
hVg2 YV(g2 + tg), gi dt,
and since g was arbitrary, for any g2 ∈ Rn we can put g = g2 一 g2 to get
YV (g20 ) = YV(g2) +
Z hVg2 YV (tg20
0
+ (1 - t)g2 ), g20 - g2i dt.
Performing the expansion with g2 and g20 reversed and applying the triangle inequality and Cauchy-
Schwarz then implies the estimate
|YV (g20) - YV(g2)| ≤ ∣g20 -g2∣2Z ∣Vg2YV(tg20 + (1 - t)g2)∣2 dt.
0
(E.10)
This relation is enough to conclude the result for angles satisfying V ≥ co, where 0 < co ≤ n/4
is an absolute constant. Indeed, (E.9) and (E.10) imply that YV is C-Lipschitz, where C > 0 is an
absolute constant; so the Gaussian POinCare inequality implies
and Gauss-Lipschitz concentration implies for any d ≥ 0
Because V ≥ co, we can adjust these bounds to involve V4 and V2 (respectively) while only paying
increases in the constant factors. We proceed assuming 0 < V ≤ co .
Let 0 ≤ Tgi ≤ 1 denote a median of YV(gi, ∙), i.e., a number satisfying Pg2 [YV ≥ Tgγ] ≥ 2 and
Pg2 [YV ≤ Tgi ] ≥ 1, and for each 0 ≤ s < Tgγ define
ws(g2) = max{YV (g2), τgi - s}.
For any 0 ≤ s < Tgi , notice that ws ≥ YV , which implies that Plws ≥ τgι] ≥ P[YV ≥ τgι] ≥ 2,
because Tgi is a median of YV ； and similarly P[ws ≤ Tgγ ] ≥ P [YV ≤ Tgγ ] ≥ 2, so that Tgi is also a
median ofws. The fact that ws ≥ YV implies for any t > 0 that P[YV - Tgi > t] ≤ P[ws - Tgi > t],
168
Published as a conference paper at ICLR 2021
and additionally ifYν ≤ τg1 -s we have ws = τg1 -s, so that P[Yν -τg1 ≤ -s] ≤ P[ws-τg1 ≤ -s].
In particular, the tails of Yν can be controlled in terms of those of ws for appropriate choices of s.
Additionally, by Lemma E.21, We have that for each s, t → Ws (g2 + tg) is differentiable at all but
countably many points of [0,1], and has derivative there equal to t → hg, Ng?ws(g2)i, where
▽g2 ws(g2) = lWs(g2)>Tg1-sNg2 YV (g2),
which, following from (E.9), satisfies a strengthened gradient norm estimate
l∣Vg2 ws(g2)k2 ≤ 8νlws(g2)>τg1-s ʌ/1 - ψ0(kvgι,g2 ∣2)YV (g2)2
≤ 8ν J1 一 ψ0(kvgi,g2 k2)(Tgi — S)2.
In particular, we obtain a nearly-Lipschitz estimate of the form (E.10):
|ws (g20 ) - ws (g2 )|	≤ ∣g20	- g2 ∣2 Z	8ν J1 -	ψ0(Ivgi,tg? + (1-t)g2)kG(TgI	-	S)2	dt.
For each gι, we define a set Sg、= {g2 | kvg1,g21∣2 ≥ 4}. Noting that the function
(E.11)
(E.12)
g2 7→
∣∣σ(gι Cos V + g2 Sin V)k2 is a convex I-LiPschitz function (given that |sin ν| ≤ 1), we have by
Gauss-Lipschitz concentration
P ∣vg1,g2∣2 ≤ E[∣vg1,g2∣2]-t ≤e-cnt2,
g2	g2
and by Jensen’s inequality
E [kvgl,g2 k2] ≥ |cos VIkugIk2 ≥ " √j"2 ,
g2	2
where the last line holds because V ≤ n/4. By Lemma E.16, there is a gι event E having probability
at least 1 一 Ce-Cn on which kugι k2 ≥ 2, so that for any gι ∈ E, we have by a suitable choice of t
in our Gauss-Lipschitz bound Pg2 [Sg1] ≥ 1 -e-cn. Thus, using the first line of (E.11), the Gaussian
POinCare inequality and the Lipschitz property of Ws (which follows from (E.12) after bounding by
an absolute constant) and Rademacher’s theorem on a.e. differentiability of Lipschitz functions, we
have whenever g1 ∈ E
Var[ws] ≤ 2 E [k^ws(g2)k2] ≤ — E [。一 Ψ0(kvgι,g2 k2)YV(g2)2)]
n g2	n g2
128V2
≤ ——E [1e O — Ψ0(kvgι,g2k2)YV(g2)2)]
n g2
+ E [1eC(1一 Ψ0(kvgι,g2k2)YV(g2)2)]
g2
256V 2
≤ ——E[1 一 YV(g2)]+ Ce-cn,	(E.13)
n g2
where we also make use of the fact that 0 ≤ Yν ≤ 1. Now, we calculate for g1 ∈ E and g2 ∈ Sg1
1
2
Yν
ugl	vgl,g2
------π~ 一 ---------π-
kug1 k2 kvg1,g2 k2
2
2
≥
1 _ 2 kugl - vgl,g2 k2
≡2
≥ 1 一 8kug1 一 vg1,g2 k22
≥ 1 一 8kg1 一 (g1 cosV + g2 sinV)k22,
(E.14)
where the second inequality uses g1 ∈ E, the third uses nonexpansiveness ofσ, and the first requires
a proof; we will show that for any nonzero vectors x, y ∈ Rn, one has
X_______y ≤ 2 kx 一 yk2
kχk2	kyk2 2 ≤ kyk2
(E.15)
169
Published as a conference paper at ICLR 2021
To see this, write θ for the angle between x and y, and distribute to obtain equivalently
-2l∣yk2(1 + cosθ) ≤ Ilxk2 - 2kχk2kyk2COSθ.
Divide through by kxk22, write K = kyk2kxk2-1, and rearrange to obtain the equivalent expression
K2(1 + cos θ)) - 4K cos θ + 2 ≥ 0.
It suffices to minimize the LHS of the previous inequality with respect to K subject to the constraint
K > 0 and then study the resulting function of θ to ascertain the validity of the bound. Given that
1 + cos θ ≥ 0, the LHS is a convex function of K, with minimizer K = 2cos θ(1 + cos θ)-1, and
therefore for any θ ≥ n/2, the LHS subject to the constraint K > 0 is minimized at K = 0, where
the inequality is easily seen to be true. If θ < n/2, we have that the minimizer is positive, and We
verify that after substituting the bound becomes
1 + cos θ ≥ 2 cos2 θ,
which is also seen to be true for θ < n/2, for example by showing that the polynomial X →
-2x2 + x + 1 is nonnegative on [0, 1]. This proves the inequality, so returning to (E.14), we have
Yν ≥ 1 - 8((1 - cosν)2kg1k22 + sin2 νkg2k22 - 2(sinν)(1 - cosν)hg1,g2i)
≥ 1 - 8((1 - cosν)2kg1k22 + sin2 νkg2k22 - 2(sinν)(1 - cosν)kg1k2kg2k2)
using Cauchy-Schwarz in the second inequality. By Gauss-Lipschitz concentration (e.g. following
the proof of the third assertion in Lemma E.17), there is a g1 event E0 and a g2 event E00, each with
probability at least 1 - Ce-cn, on which we have (respectively) kgik2 ≤ 2 for i = 1, 2. Then using
(sin ν)(1 - cos ν) ≥ 0, we obtain that when g1 ∈ E ∩ E0 and when g2 ∈ Sg1 ∩ E00
Yν ≥ 1 - 32((1 - cos ν)2 + sin2 ν) = 1 - 64(1 - cos ν) ≥ 1 - 32ν2,
where the final inequality uses the standard estimate cos ν ≥ 1 - 0.5ν2, which can be proved via
Taylor expansion. By a union bound, we can assert that with g1-probability at least 1 - Ce-cn, with
conditional (in g2 ) probability at least 1 - C0e-c0n we have Yν ≥ 1 - 32ν2, so that in particular,
by nonnegativity of Yν, and choosing n larger than an absolute constant, we guarantee with g1-
probability at least 1 - Ce-cn
E [Yν] ≥ 1 - 32ν2 - C0e-cn,	τg1 ≥ 1 - 32ν2 .	(E.16)
g2
Plugging the mean estimate into (E.13), we conclude with probability at least 1 - C00e-c0n
Cν4
Var[ws] ≤ ——+ C0e-cn.
n
(E.17)
We could have just as well applied this exact argument to Yν instead of ws, so we conclude the
claimed variance bound from this expression. We have stated the result in terms of the truncations
ws so that it can be applied towards deviations control in the sequel. As an immediate application,
we use the fact that any median is a minimizer of the quantity c 7→ E[|X - c|] for any integrable X
and c ∈ R to get with probability at least 1 - C00e-c0n
E[ws] -	τg1	≤ E[|ws	- τg1 |]	≤ E	ws - E[ws]
g2	g2	g2	g2
≤ √Var[ws] ≤
(CV + C 0e-cn,
n
(E.18)
where we also applied Jensen’s inequality for the first inequality and the Lyapunov inequality for
the third. In particular, the same argument yields
Cν2
E [YV] — Tgi ≤ —+ + C e .	(E.19)
g2 n
We turn to removing the t dependence in (E.12) without sacrificing the dependence on τg1 . To
obtain a Lipschitz estimate on the subset Sgi we need to control the norm of Vg2 Ws on the line
segment between g2, g20 ∈ Sg1 . For this, write σy(x) = max{x - y, 0} for any y ∈ R, and make
the following observations:
170
Published as a conference paper at ICLR 2021
1.	vg1,g2 = (sinν)σ-g1 cotν(g2), so that
Yν(g2)
Ugi(Sin V)σ-gι cotV(g2)	∖.
ψ (kugi k2), ψ (H(Sin ν)σ-gι cot V (g2)k2')/
2.	for any x, y, σy (x) = max{x, y} - y; x 7→ max{x, y} is the projection onto the convex
set {x | xi ≥ yi ∀i}, so in particular x 7→ σy(x) is nonexpansive, has convex range, and
satisfies σy (σy (x) + y) = σy(x); and thus
3.	for any g2, YV(g2) = YV (σ-g1 cotV(g2) - g1 cot ν).
WeWrite g2 = σ∏ Cot V (g2) — gι Cot V, g2 = σ∏ Cot V(g2) — gι Cot ν, so that (E.12) becomes
∣ws(g2) — ws(g2)l = ∣ws(g2) — ws(g2)l
≤ kg2 — g2k2 Z 8νJ1 — ψ0 (kvgi,t 冕+(i-t)gz)∣^(TgI - S)2dt
≤ kg2 — g2k2 Z 8νJ1 — ψ0 (kvgi,t 冕十(i-t)g2)kG(TgI - S)2 dt,
Where the second line folloWs from nonexpansiveness and translation invariance of the distance.
Having reduced to the study of points along the segment between g2 and g2, we now observe
σ-gι cot v (tg2 + (1 — t)g2) = σ (tσ-gι cot V (g2) + (1 — t)σ-gι cot V (g2 ))
= tσ-g1 cot V (g2) + (1 — t)σ-g1 cot V (g2),
because σ-g1 cot V has image included in the nonnegative orthant, which is convex. It then follows
from (1) above that
kvgι,tg2 + (1-t)而 k2 = (Sin V )ktσ-gι cot V (g2) + (1 — t)σ-gι cot V (g2)k2
= tvg1 ,g2 + (1 — t)vg1 ,g20 2 ,
and in particular
tvg1 ,g2 + (1 —t)vg1,g20 22
=t2kvg1,g2k22+2t(1—t)hvg1,g2,vg1,g20i+(1—t)2kvg1,g20k22
≥ ɪ (t2 + (1 —1)2) ≥ ɪ,
一 16 I '	' ' - 32,
where the first inequality uses that σ ≥ 0 and g2, g20 ∈ Sg1, and the second minimizes the
convex function of t in the previous bound. We conclude that g2 , g20 ∈ Sg1 implies that
∣∣Vgι,tg/ +(i-t)g2 k2 > 8 for every t ∈ [0,1], and consequently (E.12) becomes (after an additional
simplification of the quantity under the square root using Tg1 ≤ 1)
∣Ws(g2) — Ws(g2)l ≤ 16ν个 1 — (Tgi — S)I∣g2 — g2k2,	(E.20)
so that Ws is 16ν，1 — (τgι — S)-Lipschitz on Sgi. Then by an application of the median bound
in (E.16), if 0 ≤ s < 1 — 32ν2, with gι probability at least 1 — Ce-Cn we have that Ws is
16ν√32ν2 + S-Lipschitz on Sgi. For the previous assertion to be nonvacuous, we need to take V
small; in particular, we have 1 — 32ν2 > ɪ if ν < 1/8, which we can take to be the value of the ab-
solute constant c° we left unspecified previously. Then for each such s, define Ls = 16ν√32ν2 + S,
and define
Ws(g2)= SUp {ws(g2) — Lskg2 — g2k2}.
g20 ∈Sgi
Then Ws is Ls-Lipschitz on Rn, and satisfies Ws = Ws on Sgi (Evans & Gariepy, 1991, §3.1.1
Theorem 1). By the Gaussian POinCare inequality, we obtain immediately Var[Ws] ≤ Ls, and using
Ws = Ws on Sgi, we compute
E [Ws — Ws] = E	[Ws — Ws]
g2	g2 ∈Sgc i
≤ E [lsg] ∣Ws — Ws |]
≤ p [Sgi ]1/2kWs — Ws∣L2
g2
≤ Ce-cn (∣Ws∣L2 + kWs∣L2) ≤ C0e-cn,
(E.21)
171
Published as a conference paper at ICLR 2021
where the second inequality follows from the Schwarz inequality, the third holds given that g1 ∈ E
and by the MinkoWski inequality, and the final uses that Ws and Ws are both LiPschitz with Lips-
chitz constants bounded above by absolute constants together with the Gaussian Poincare inequality.
Meanwhile, by Gauss-Lipschitz concentration, we obtain a Bernstein-type lower tail
P Ws ≤ E[Ws] - S
g2
cns2
≤ exp - V2(32ν2 + S)),
(E.22)
and for the upper tail, it will be sufficient to consider Wo, which satisfies a subgaussian tail (for any
t≥0)
P Wo ≤ E[Wο] — t] ≤ exp (---------4-) .	(E.23)
Using the results (E.18), (E.19), (E.21), and the fact that Ws = Ws on Sg、, we get
P Yν - E [Yν] ≤ -S
g2	g2
≤ P Ws - E[Ws] ≤ C，+ C0e-cn - S
g2	g2	n
+gP2Sgc1 .
(E.24)
Using d ≥ 1, we put S = 2Cν2 y/d/n + C0e-cn in this bound; using that ν < 1/8, and in particular
1 - 32ν2 > 1, we can choose n larger than an absolute constant multiple of d to guarantee that for
all 0 ≤ v < 1/8, this choice of S is less than 1 - 32ν2, and that Cν2 ʌ/d/n ≤ 32ν2. Together with
the lower tail bound (E.22), these facts imply
P
g2
YV - E [YV] ≤ -2Cv2Jd - C0e-cn
g2	n
≤P
g2
Ws — E[Ws] ≤ -Cv2
g2
≤ e-c00d
+ C00e-c0n.
Meanwhile, for the upper tail, we have for any t ≥ 0
P YV - E [YV] ≥ t
g2	g2
≤ P Wo - E[Wο] ≥ t - C^V= - C0e-cn
g2	g2	n
+gP2Sgc1,
(E.25)
and if we put t = 2Cv2 ,d/n + C0ecn, our previous requirements on n and the upper tail bound
(E.23) yield
P YV - E [YV] ≥ 2Cv2Jd + C0e-cn ≤ e-c0"d + C00e-c0n.
g2	g2	n
Combining these two bounds gives control of absolute deviations about the mean. By independence,
we conclude
P
g1 ,g2
Yv - E [YV ] ≤ 2Cv 2Jd + C 0e-c0"n ≥ (1 - 2e-cd - Ce-c0n)(1 - C 0e-c"n)
g2	n
≥ 1 - 2e-cd - Ce-c0n - C0e-c00n
To conclude, we have shown that for every v ∈ [0, π] one has with probability at least 1 - Ce-cn
C0v4	0
Var[Xν(gι, ∙)] ≤ — + C00ne-cn,
n
and with (g1, g2 ) probability at least 1 - 2e-c00d + C000
ne-c000n one has
XV - E[Xν] ≤ C0000VV∖/d + C00000ne-c”"n.
g2 n
To simplify these bounds, we may in addition choose n larger than an absolute constant multiple of
log n, and n larger than an absolute constant multiple of d, to obtain that with probability at least
1 - Ce-cn
VarXV(gι, ∙)] ≤ 出 + C0e-c0n,
n
and with (g1, g2 ) probability at least 1 - C00e-c00d one has
XV - E[Xν] ≤ C5v2aB + C000e-c0"n,
g2	n
which was to be shown.
□
172
Published as a conference paper at ICLR 2021
Lemma E.12. There exist absolute constants c, C, C0 > 0 and an absolute constant K > 0 such
that if n ≥ K log4 n, then for every ν ∈ [0, π] one has
Var[E[Xν J g2)]k Cν4nlogn+C 0e-cn.
Proof. Define
Y (	) =	hvθ(gl, g2), VV(gl, g2)i
V g1, g2	Ψ(l∣Vθ(gl, g2)k2)Ψ(kVν (gl, g2 )k2) ,
where ψ = ψ0.25 is as in Lemma E.31. Then by Cauchy-Schwarz and property 2 in Lemma E.31
(the case where either kv0k2 = 0 or kvV k2 = 0 is treated separately, since in this case YV = 0), we
obtain |YV | ≤ 4, and
E (E[Xν] - EM。= E (E [lEc “11 hv0, VVi II、D
g1	g2	g2	g1	g2	ψ(kV0k2)ψ(kVVk2)
≤ E "(1	hv0, VVi	Y#
-g1Eg2[l Ecψ(kv0k2)ψ(kvνk2)人
≤ 16μ(Em) ≤ Cne-cn,
where we use the fact that if (g1, g2) ∈ Em then kvνk2 ≥ 2 for every 0 ≤ ν ≤ π and hence
ψ(kVVk2) = kVV k2 in the first line, apply Jensen’s inequality in the second line, and combine our
bound on YV With Holder,s inequality and the measure bound in Lemma E.16 in the third line. An
application of Lemma E.32 then yields
Var E[Xν(∙,g2)]
g2
≤ Var E[Υν(∙, g2)]
g2
+ Cne-cn ≤ Var EM(∙,g2)] + Ce-Cn/2,
g2
Where the last inequality holds When n is chosen to be larger than an absolute constant multiple of
log n. It thus it suffices to control the variance of YV . Applying Lemma E.26, We get for almost all
g1 ∈ Rn
E [YV(g1, g2)]
g2
kv0k2
Ψ(M k2)2
+
E [(Ξ1 + Ξ2 + Ξ3 + Ξ4 + Ξ5 + Ξ6)(s,g1,g2)] ds dt,
0	0 g2
Where We folloW the notation defined in Lemma E.13. We start by removing the term outside of the
integral from consideration. We have as above |YV| ≤ 4, so that |Eg2 [YV]| ≤ 4. Moreover, folloWing
the proof of the measure bound in Lemma E.16, but using only the pointWise concentration result,
We assert that if n ≥ C an absolute constant there is an event E on Which 0.5 ≤ kV0k2 ≤ 2 With
probability at least 1 - 2e-cn With c > 0 an absolute constant. This implies that ifg1 ∈ E We have
kvok2
Ψ(kv0k2)2
and since
kvok2
ψ(kv0k2)2
≤ 4,
by the same argument used for YV, We can calculate
kvo k2
Ψ(Mk2)2
-1
kvok2
Ψ(Mk2)2
- 1	1Ec
≤ 5k1EckL2 ≤ Ce-cn,
L2
by the MinkoWski inequality and the triangle inequality. An application of Lemma E.32 implies that
it is therefore sufficient to control the variance of the quantity
f(ν, g1)
1+
V tE[(Ξ1+Ξ2+Ξ3+Ξ4+Ξ5+Ξ6)(s,g1,g2)]dsdt.
0	0 g2
By Lemma E.37, the Lyapunov inequality, and Fubini’s theorem, We have
(f (ν, g1) - E[f (ν, g1)]
E[Ξi(s,g1,g2)] - E [Ξi(s,g1,g2)]	dsdt
i=1 g2	g1,g2
173
Published as a conference paper at ICLR 2021
Using the elementary inequality
2
g(s) ds dt
≤ ν	νtdt	tg2(s)ds,
valid for any square integrable g : [0, π] → R and proved with two applications of Jensen’s inequal-
ity, and Lemma E.37, we obtain
ZνZt6
E[Ξi(s,g1,g2)] -
i=1 g2
E [Ξi(s,g1,g2)]	ds dt.
g1 ,g2
Thus, again by Lemma E.37, the Lyapunov inequality, Fubini’s theorem, and compactness of [0, π],
we have
ZνZt6
Var	E[Ξi(s,g1,g2)] ds dt.	(E.26)
We can control the variance under the integral using a combination of Lemmas E.35 and E.37,
together with the deviations control given by Lemmas E.39, E.41 to E.44 and E.46, since we have
chosen n according to the hypotheses of Lemma E.13. In particular, these lemmas furnish deviation
bounds of size at most	_______
Ci (Jdogn + n-cid) + C0ne-cin
that hold with probabilities at least 1-Ci00n-c0i0d-Ci000ne-c0i00n, for any d ≥ 1 larger than an absolute
constant and suitable absolute constants specified above. We can simplify these bounds as follows:
first, choose n such that n ≥ (2/c0i00) log n for each i, which guarantees that the bounds hold with
probability at least 1 - Ci00n-c0i0d- Ci000e-c0i00n/2. Next, choose n ≥ (2c0i0/c0i00)dlog nfor all i, which
implies that the bounds hold with probability at least 1 - 2 max{Ci00, Ci000}n-c0i0d. Similarly, we
also choose n such that n ≥ (2/c0i) log n for each i, which guarantees that the error terms that are
exponential in n in the bounds are upper bounded by Ci0e-c0in/2, and, choose n ≥ (2ci/c0i)dlog n
for all i, which implies that for all i
Ci ( dogn+ + n-cid) + C0ne-cin ≤ CNd^n + 2max{Ci,C0}n-cid.
Finally, we make the particular choice d = 4/ mini{ci, c0i0}, or the minimum required value of d,
whichever is larger, so that there are absolute constants C, C0 , C00 > 0 such that with probability at
least 1 - C00n-4 we have for all i
E[Ξi(ν,g1,g2)] - E [Ξi(ν,g1,g2)]
g2	g1 ,g2
≤ C,手 + C onT ≤ 2C,号
where the last inequality holds when n is larger than an absolute constant. With these bounds, we
can now invoke Lemma E.35 with Lemma E.37 to get
6
Var X E[Ξi(s,g1,g2)]
i=1 g2
≤ C 3 + C ≤ C - l0gn,,
n	n2	n
for different absolute constants C, C0 , C00 > 0, and where the last inequality again holds n is larger
than an absolute constant. Plugging back into (E.26) and evaluating the integrals, we get
Var[f(ν, ∙)] ≤ CV4Iogn,
n
which is enough to conclude.	□
Lemma E.13. Write
Yν (g1, g2)
hvθ(gl, g2 ), VV (gl, g2)i
Ψ(l∣Vθ(gl, g2)k2)Ψ(kVν(gl, g2)k2) ,
where ψ = ψ0.25 is as in Lemma E.31. There exist absolute constants c, c0, C, C0, C00 > 0 and
absolute constants K, K0 > 0 such that for any d≥ 1, if n ≥ Kd4 log4 nand ifd≥ K0, then there
is an event E such that
174
Published as a conference paper at ICLR 2021
1.	One has	_______
∀ν ∈ [0,π], E [Yν] - E [YV] ≤ C00ν2A /dlogn + Ce-Cn
g2	g1 ,g2	n
ifg1 ∈ E;
2.	One has
P[E] ≥ 1 - C0n-c0d.
Proof. Fix d > 0, and write
f(ν,g1) = E[Yν(g1,g2)].
g2
Applying Lemma E.26, we get for almost all g1 ∈ Rn
f(ν, g1)
kv0k22
ψ(kv0k2)2
+
E[(Ξ1 + Ξ2 + Ξ3 + Ξ4 + Ξ5 + Ξ6)(s,g1,g2)] ds dt, (E.27)
g2
where
n
Ξ1(s,g1,g2) =
σ(g1i)3ρ(-g1i cot s)
i=1
ψ(kv0k2)ψ(kvsl∣2)sin3 s
Ξ2(s,g1,g2)
hv0,vsiψ0(kvsk2)kvsk2
hv0, vsi
Ξ3(s,g1,g2)
ψ(kV0k2)ψ(kVsk2)2	ψ(kV0k2)ψ(kVsk2)
hvo, vsihvs, V s i2ψ00(kvsk2)
Ξ4(s,g1,g2) = -2
Ξ5(s,g1,g2)
ψ(kv0k2)ψ(kvsk2 )2kvsk2
> hvo, Vsihvs, Vsiψ0(kvsk2)
'ψ(kv0k2)ψ(kvsk2)2∣∣Vsk2
hV0, VsikVsk2ψ0(IVsk2)
ψ(kv0k2)ψ(kvsk2)2kvsk2
Ξ6(s,g1,g2) = 2
hvo, Vsihvs, Vsi2ψ0(kvsk2) + hvo, Vsihvs, Vsi2ψ0(kvsk2)
ψ（Mk2加1风心）31风口2
ψ(kv0k2)ψ(kvsk2)2kvsk3.
—
—
—
Here we put Ξ1 (0, g1, g2) = Ξ1 (π, g1, g2) = 0, which does not affect the integral and which is
equal to the limits limv&o Ξι(ν, gι, g2) = limν%∏ Ξι(ν, gι, g2) for every (gι, g2).
Momentarily ignoring measurability issues, it is of interest to construct g1 events Ei of suitable
probability on which we have
sup	E[Ξi(ν,g1,g2)] - E [Ξi(ν,g1,g2)] ≤ Ci
ν ∈[0,π]	g2
g1 ,g2
(Jdogn + n-cij + COne-Cin (E.28)
for each i = 1, . . . , 6, and a g1 event E7 on which we have
kv0 k22
ψ(kV0k2)2
-E
g1
kv0k22
ψ(kv0k2)2
We can then consider the event E = Ti7=1 Ei, possibly minus a negligible set on which (E.27) fails
to hold, which has high probability via a union bound and on which we have simultaneously for all
ν ∈ [0,π]
f(ν,g1) - E[f(ν,g1)] ≤
g1
-E
g1
kv0k22
ψ(kv0k2)2
kv0k22
ψ(kV0k2)2
6
+
≤ Cν
3 + n-cd + C 0ne-c0n
n
E[Ξi(s,g1,g2)] - E [Ξi(s,g1,g2)] dsdt
g2	g1 ,g2
175
Published as a conference paper at ICLR 2021
by FUbini's theorem and Lemma E.37, the triangle inequality (for | ∙ | and for the integral), (E.28),
and using ν2 ≤ π2 and worst-casing the remaining constants.
To establish the bounds (E.28), we will employ lemma Lemma E.48, which shows that it is sufficient
to obtain pointwise control and show a suitable s-Lipschitz property for each i ∈ [6]; following the
lemma, these properties also imply Lebesgue measurability of the suprema immediately.
Reduction to product space events. Fix ν. By the triangle inequality, we have for each i =
1,...,6
E[Ξi(ν, g1, g2)] - E [Ξi(ν,g1,g2)] ≤ E Ξi(ν,g1,g2) - E [Ξi(ν,g1,g2)] .	(E.29)
g2	g1 ,g2	g2	g1 ,g2
Suppose we can construct (g1, g2) events Ei0 such that
1.	If (g1 , g2) ∈ Ei0, then
Ξi(ν, g1, g2) - E [Ξi(ν,g1,g2)]
g1 ,g2
≤ Ci (rdlngn +n-Cid)+C0ne
-c0in ;
2.	One has P[Ei0] ≥ 1 - Ci00n-c0i0d - Ci000ne-c0i00n .
Then for each such i, we can write
E	Ξi(ν,g1,g2) - E [Ξi (ν, g1, g2)]
g2
g1 ,g2
E
g2
≤ Ci
+ n-cid	+ Ci0ne-c0in
+ 1(Ei0)c	Ξi(ν,g1,g2) - E [Ξi(ν, g1, g2)]
i	g1 ,g2
+ E 1(Ei0)cΞi(ν,g1,g2) -
g2
E [Ξi(ν, g1 , g2)]
g1 ,g2
(E.30)
using nonnegativity of the integrand and boundedness of the indicator for Ei0 in the second line.
The random variable remaining in the second line is nonnegative, and by Fubini’s theorem (with
Lemma E.37 for joint integrability) and the Schwarz inequality we have
EE
g1 g2
1(Ei0)cΞi(ν, g1, g2) - E [Ξi(ν,g1,g2)]
i	g1 ,g2
2 1/2
≤ E	1(E0)c1/2 E	Ξi (νΞ, g1 , g2)
g1,g2	i g1,g2	- Eg1,g2 [Ξi(ν, g1, g2)]
≤ C	Ci00n-c0i0d+Ci000ne-c0i00n1/2,
where the second line applies Lemma E.37 and the Lyapunov inequality. We can replace this last
inequality with one equivalent to the measure bound on (Ei0)c using subadditivity of the square root
and reducing the constants c0i and c0i0 by a factor of 2. Using this last inequality, Markov’s inequality
implies for any t ≥ 0
P E 1(E0)c Ξi(ν,gι,g2)- E [Ξi(ν,gι,g2)]	≥ Cn-2ci0d + C0n1/2e-2小
g2	i	g1 ,g2
≤ Cn- 1 ci0d + C0n1/2e-2ci"n,
which, together with (E.29) and after worst-casing some exponents and constants, implies that there
is a g1 event Ei that satisfies (the constants C and C0 are scoped across properties 1 and 2)
176
Published as a conference paper at ICLR 2021
1.	If g1 ∈ Ei, then
+ (Ci + C )n-2 Cid
E [Ξi (ν, g1 , g2)] - E [Ξi (ν, g1 , g2)] ≤ Ci
g2	g1 ,g2
+ (C0 + C 0)ne- 1 min{ci，ci00}n；
1 00 7	1 000 一
2.	One has P[Ei] ≥ 1 - Cn-2Cid - C0ne-2Ci n.
Thus, we can pass from (g1, g2) events to g1 events with only a worsening of constants, and it
suffices to construct the events Ei0 .
Additionally, we can leverage this same framework to pass ν-uniform control from the product space
to g1-space. Suppose we can construct (g1, g2) events Ei0 such that
1.	If (g1 , g2) ∈ Ei0, then
∀ν ∈ [0,π], Ξi(ν,g1,g2) - E [Ξi(ν, g1, g2)]
g1 ,g2
≤ Ci+…
+ Ci0ne-C0in;
2.	One has P[Ei0] ≥ 1 - Ci00n-C0i0d - Ci000ne-C0i00n .
Then following (E.30), we can assert
∀ν ∈ [0, π], E Ξi(ν,g1,g2) - E [Ξi (ν, g1, g2)]
g2	g1 ,g2
≤ Ci
+ Ci0ne-C0in + E
g2
1(Ei0)cΞi(ν,g1,g2) - E [Ξi(ν, g1, g2)]
i	g1 ,g2
To get uniform control of this last random variable, we can use Lemma E.37, which tells us that we
have a bound
∀ν ∈ [0, π], E Ξi(ν, g1, g2) - E [Ξi(ν,g1,g2)]
g2	g1 ,g2
≤ Ci ( n + + n-cij + COne-cin + E [1(Ei)C fi(g1, g2 )],
(E.31)
where fi is in L4(Rn × Rn), and has L4 norm bounded by an absolute constant Ci > 0. Then
Fubini’s theorem and the Schwarz inequality allow us to assert
E [1(Ei0)cfi(g1,g2)] ≤ Ci E [1(Ei0)c]1/2,
g1 ,g2	i	g1 ,g2	i
which can be controlled exactly as in the pointwise control argument. In particular, an application
of Markov’s inequality gives
P E [1(E0)c fi(gι, g2)] ≥ Cn- 1 ci0d + C0n1/2e- 1 Wrn ≤ Cn-2ci0d + C0n1/2e- 1 ci"n,
g2	i
so that, returning to (E.31), we have uniform control of the quantity |Eg2 [Ξi(ν, g1, g2)] -
Eg1,g2 [Ξi(ν, g1, g2)]| on an event of appropriately high probability. In particular, we have incurred
only losses in the constants compared to the pointwise case.
177
Published as a conference paper at ICLR 2021
Approach to Lipschitz estimates. We will use this framework for controlling the Ξ1 and Ξ5
terms only. Accordingly, the sections for those terms below will produce results of the following
type, for absolute constants ci, c0i, c0i0, c0i00, Ci, Ci0, Ci00, Ci000, Ci0000 > 0 for i = 1, 2, and parameters
d ≥ 1, δ > 0 such that d and δ are larger than (separate) absolute constants and n satisfies certain
conditions involving d:
1.	For each ν ∈ [0, π] fixed, with probability at least 1 - C1000n-c010d - C10000ne-c0100n, we have
that
|E[Ξi(ν,gι,g2)- E[Ξi(ν,gι,g2)]]∣ ≤ ClPdlogn/n + Cjn-c1d + Cl0ne-c1n;
g2
2.	With probability at least 1 - C200e-c02n - C2000n-δ, we have that |Eg2 [Ξi(ν, g1, g2) -
E[Ξi(ν,gι,g2)]]| is (C2 + C'n1+δ)-Lipschitz.
We show here that We can use these properties to obtain uniform concentration of the relevant quanti-
ties. Write M = Ci，d log n/n + Cjn-c1d + C10ne-c1n; we are interested in showing that uniform
bounds of sizes close to M hold with probability not much smaller than that of the pointwise bounds.
By Lemma E.48, it follows from the assumed properties that for any 0 < ε < 1 one has
nj+δ
P sup	E[Ξi(ν,gj,g2) - E[Ξi(ν,gj,g2)]] ≤ M + ε C2 + C20
ν∈[0,π] g2
≥ 1 -	Cj000n-c010d + Cj0000ne-c0100n	Kε-j
—
where K > 0 is an absolute constant. To make the RHS of the bound on the supremum of
size comparable to M, it suffices to choose ε = Ci，dlogn∕n∕(C2 + C2n1+δ). We have
C2 + C20 nj+δ ≤ K0nj+δ for K0 > 0 an absolute constant, and so we have ε T ≤ K0n3S+δ
for K0 > 0 another absolute constant. This gives
Ci000n-c010d + Ci0000ne-c0100n ε-i ≤ K0n3S+δ (C000e-c10dlogn + C0000e-c1"/2n)
≤ κ0n3S+δe-cι0d log n
≤ K0n-c010d/2 ,
where K0 > 0 is an absolute constant whose value changes from line to line; and where the first
inequality assumes that n ≥ (2/c0i00) log n, the second inequality assumes that n ≥ (2c0i0/c0i00)dlog n,
and the third assumes that δ ≤ c0i0d/2 - 3/2. Choosing d so that the value c0i0d/2 - 3/2 is larger than
the minimum value for δ (i.e., larger than an absolute constant), then choosing δ = c0i0d/2 - 3/2,
and finally choosing d ≥ 6/c0i0, we obtain
P sup	E[Ξi(ν,gi,g2) - E[Ξi(ν,gi,g2)]] ≤ 2M
ν∈[0,π] g2
≥ 1-Kn-c010d/2-C200e-c02n-C2000n-c010d/4,
where K > 0 is an absolute constant, which is an acceptable level of uniformization.
Completing the proof. To obtain the desired control, we apply the uniform framework for the
terms Ξi , i = 2, 3, 4, 6; and the pointwise with Lipschitz control framework for the terms Ξi , i
1, 5. We also establish high probability control of the zero-order term in Lemma E.38. The events
we need for the pointwise framework terms are constructed in Lemmas E.39, E.40, E.44 and E.45.
The events we need for the uniform framework are constructed in Lemmas E.41 to E.43 and E.46.
Because n and d are chosen appropriately by our hypotheses here, we can invoke each of these
lemmas to construct the necessary sub-events and obtain an event E which satisfies
1. One has
∀ν ∈ [0, π],
E [Yν] - E [Yν]
g2	g1 ,g2
≤ Cν
d log n
n
+ n-cd
+ C0ne-c0n
if gi ∈ E ;
178
Published as a conference paper at ICLR 2021
2.	One has
P[E] ≥ 1 - C00n-c00d - C000ne-c000n.
We can adjust d and n slightly to obtain an event with the properties claimed in the statement of the
lemma. Indeed, choosing n to be larger than an absolute constant multiple of log n, we can obtain
C0ne-c0n ≤ C0e-c0n/2 and C000ne-c000n ≤ C 000 e-c000 n/2 ; choosing n to be larger than an absolute
constant multiple of dlog n, we can obtain C00n-c00d + C 000 e-c000 n/2 ≤ 2C00n-c00d; and choosing
d to be larger than an absolute constant, We can assert ʌ/dlog n/n + n-cd ≤ 2ʌ/dlog n/n. This
turns the guarantees of E into the guarantees claimed in the statement of the lemma, and completes
the proof.
□
E.3.3 Proving Lemma E.7
Lemma E.14. One has bounds
1	一 V- ≤ cos 夕(V) ≤ 1 一 cν2, V ∈ [0,π].
Proof. Write f (V) = cos 夕(V) = cos V + π-1 (sin V 一 V cos V), where the last equality follows from
Lemma E.2. We start by obtaining quadratic bounds on f(V) for V ∈ [0, 0.1]. In particular, We Will
show
1 一 1V2 ≤ f(v) ≤ 1 一 1V2,	V ∈ [0,0.1].	(E.32)
We readily calculate
f0 (V) = 一 sin V + π-1V sin V,
f00(V) = 一 cosV + π-1(VcosV + sinV).
Taylor expanding at V = 0 gives
1 + inft∈[0,0.1] 尸⑴ ν2 ≤ f(ν) ≤ 1 + supt∈[0,0∙1] 尸⑴ v2.
We have f 00(0) = 一1, and sin V ≤ sin 0.1 on our interval of interest by monotonicity. The derivative
of V cos V is cos V 一 V sin V ; V sin V is increasing as the product of two increasing functions (given
V ≤ 0.1), and one checks that cos(0.1) 一 0.1 sin(0.1) > 0; therefore V cos V ≤ 0.1 cos(0.1) on our
domain of interest. One checks numerically
—cos(0.1) + π-1(0.1 cos(0.1) + sin(0.1)) < — 2 < 0,
and this establishes f (ν) ≤ 1 — ɪν2 on [0,0.1]. If V ≤ n/2, we have cos ≥ 0 and sin ≥ 0, so that
vcos v + sin v ≥ 0 on this domain. This implies f 00(ν) ≥ — cos V ≥ —1 for 0 ≤ V ≤ π∕2, which
proves inft∈[o,∏∕2] f 00(t) = -1, and establishes the lower bound on [0, ∏∕2].
To obtain (possibly) looser bounds on [0, π], we use a bootstrapping approach. The lower bound is
more straightforward; to assert the lower bound on [0, π], we evaluate constants numerically to find
that the lower bound,s value at ∏∕2 is 1 — ∏2∕8 < 0, and given that f ≥ 0 by Lemma E.5 and
the concave quadratic bound is maximized at V = 0, it follows that the bound holds on the entire
interval.
For bootstrapping the upper bound, we note that the equation
f 0(ν) = — sin v + π-1ν sin V = sin V(V — 1
shows immediately that f is a strictly decreasing function of V on (0, π). Therefore f(V) ≤ f (0.1)
on [0.1, π], and so the quadratic function V 7→ 1 — π-2 (1 — f(0.1))V2, which is lower bounded
by 1 — V2∕4 on [0, π] by the fact that both concave quadratic functions are maximized at 0 and the
verification 1 — π2∕4 < 0 ≤ f (0.1), is an upper bound for f on all of [0, π]; so the claim holds with
□
c= π-2(1 — f (0.1)).
179
Published as a conference paper at ICLR 2021
Lemma E.15. There exist absolute constants c, C, C0 , C00 > 0 such that if n ≥ C log n, then one
has
E [Xν] — cos 夕(V) ≤ C0e-cn + C00ν2/n.
g1 ,g2
Proof. Write h(ν)
formula
cos 夕(V) — E[Xν]. By Lemmas E.24 and E.25, We have a second-order Taylor
h(ν) = h(0) + h0(0) + Z h00(s) ds dt.
We calculate ho(0) = 0, since E[hvo, Vo〉] = E[<σ(gι), g2〉] = 0, and PV⊥vo = 0. We also have
h(0) = E[kvok2] — E[lEm] = μ(Emm) (writing m = 1), so this formula yields
c	V2
Ih(V)| ≤ μ(Em) + ɪ
esssup|h00(V0)|,
ν0 ∈[o,π]
and we see that it suffices to bound h00. We will use the (Lebesgue-a.e.) expression
ιz√0/— M∕∙	∙ ∖ι IirL /	1	(V	VV说、∙	1	(v	Vo琢、∙ ∖]
|h (V)I = E[hvν,Voi]- E[1Em∖ Kh I -PII卜ν,而(I -MI卜0∕J .
Distributing over the inner product and applying rotational invariance to combine the two cross
terms, then using the triangle inequality, we obtain the bound
Ih00(V)I ≤
EKV V, V oi]—
1	ho, VVi
.Em kV0k2kVνk2
{z^^^
Ξ1(V)
2E
I^
1	hV0, VVihVν, VVi'
.Em	kV0k2kVVk2
{^^^^^^^^^^^^^
Ξ2(V)
E
+
E
J
+
1	(V 0, VoihVo, VV)(Vv , V V〉]
.Em	kVok3kVV∣∣3	J
_ - /
{z
Ξ3(V)
We proceed by giving magnitude bounds for Ξi(V), i = 1,2, 3. Because we are working with
expectations, it suffices to fix one value V ∈ [0, π] and prove pointwise V-independent bounds; we
will exploit this in the sequel to easily define extra good events without having to uniformize, and
we will generally suppress the notational dependence of Ξi on V as a result. We will also repeatedly
use the fact that we have μ(ΕC) ≤ Cne-Cn for some absolute constants c, C > 0 by Lemma E.16.
We will accrue a large number of additive C/n and C0npm e-cn errors as we bound the Ξi terms; at
the end of the proof we will worst-case the constants in each additive error and assert a bound of the
form claimed.
Ξι control. Let E = {∣∣Vv∣∣2 ≤ 2} ∩ {∣∣Vo∣∣2 ≤ 2}. By Lemma E.17 and a union bound, we have
μ(Ec) ≤ Ce-Cn Define an event Ei = Em ∩ E. The first step is to pass to the control of
e1 := E |1EihVV, Voi (1 — τ--r ).
1	kVok2kVVk2
The triangle inequality gives
月-ξi∣ ≤ 叫 1Ec hV V,V oi]| TE [1Em∖EE∖ 氤,氤力
The first term is readily controlled from two applications of the Schwarz inequality, a union bound,
and rotational invariance together with Lemma E.29:
∣E[1Ec(VV, Voi] | ≤ EflEc] 1∕2E[kVv∣∣2] 1∕4E[kVok4]1/4
≤ (μ(Em)+ Ce-Cn )1/2 E[kV o k4]1/2
≤ (Cne-Cn + C0e-c0n) 1/2 (l + C) /
≤ Cn1/2e-Cn,
180
Published as a conference paper at ICLR 2021
where in the last line we require n to be at least the value of a large absolute constant. The calculation
is similar for the normalized term, except we also apply the definition of Em to get some extra
cancellation:
E 1Em∖EP⅛0⅛. ≤ E 1Em∖Ek⅛⅛一 ≤ 4E[1Em\Elhvν,V0iI]
≤ 4E[1ec∣hVV, Voil]
≤ 4E[1eC]1/2E[kVνk2]1∕4E[kv0k2]1∕4
C0 1/2
≤ Ce-Cn M+- ʌ ≤ Cef,
where in the last line we apply our bounds from the first term and use n ≥ 1 to obtain the final
inequality. Next, Taylor expansion of the smooth convex function x 7→ x-1/2 on the domain x > 0
about the point x = 1 gives
x-1/2 * = 1 —( (x — 1) + Z J (x — t)t-5/2 dt.
Given that Em guarantees IlVVIl 2 ≥ 2, we can apply this to get a bound
1E1 (1 -IKINKh )
1	3	kv0k22kvνk22
=1E1 12 (kv0k2kvν k2-1) - 4 J	(∣v0k2kvν∣∣2
(E.33)
- t)t-5/2 dt .
On E0, we also have IV0I2-2 IVV I2-2 ≤ 24, so we can control the integral residual as
3	kv0k22kvνk22	2
0 ≤ 1E1 4 /	(kv0k2kvν k2 — t)t-5/2 dt≤ 1E1 384 (kv0 ∣∣2kvν k2 - 1),
where we replace the tighter bound that we get in the case IV0 I22 IVV I22 ≥ 1 with the worst-case
bound from the other case. This gives bounds
1E1 (2 (kv0k2kvν∣∣2 - 1) - 384 (kv0k2kvν∣∣2 - 1) ) ≤ 1E1 (1 - kv k kv k )
02 V2
≤ 1E12 (kv0k2kvν∣l2 -1).
Given that k V νk2 ≤ 2 on E00, it follows |〈V 0, V V i∣ ≤ 4 on Eι,so that〈V 0, V V〉+4 ≥ 0 here. Writing
1E1 hV0, VVi (1 - kV0k21∣Vνk2 )
=1E1 ](hV0, VVi + 4) (1 - kV0k2I∣Vvk2) - 4 (1 - M⅛Vh)
we can apply nonnegativity to obtain upper and lower bounds
el ≤ E]1E1hV0,VVi (2 (Mk2kV"k2 -1) +4c(kV0k2kV"k2 -1)2);
eι ≥ E}EιhV0,VVi (2 (kV0k2kV"k2 -1) - 5C (kV0k2kV"k2 -1)2),
where C = 384.
181
Published as a conference paper at ICLR 2021
We continue with bounding the quadratic term arising in the previous equation. We have
∣e[1ei(V0,VVi (kvok2∣Wνk2 - ι)2i∣ ≤ 4E[(kvok2kvνk2 - 1)2i
=4Ekv0k24kvνk24-2kv0k22kvνk22+1
≤ 4 (1- 2E[Mk2∣Mk2] + E[Mk2])
≤ 4(1 - 2(1 - (CnT + C0e-cn))2 +(1 + (C
≤ CnTe-Cn + C0e-cn + (C-.
n
The first inequality applies the triangle inequality for the integral, the definition of E1 and Cauchy-
Schwarz, then drops the indicator for E1 because the remaining terms are nonnegative; the sec-
ond line is just distributing; the third line rearranges and applies the Schwarz inequality; and the
fourth inequality applies Jensen’s inequality and Lemma E.18 to control the second term (to apply
this lemma, we need to choose n larger than an absolute constant; we assume this is done), and
Lemma E.29 to control the third term. Since n ≥ 1, this gives a C/n + C0e-Cn bound on the
quadratic term.
Next is the linear term; our first step will be to get rid of the indicator. By the triangle inequality, it
suffices to get control of the corresponding term with the indicator for E1c instead; we control it as
follows:
IE[1Ec hv0, VVi (kv0k2kvνk2 - 1)]∣
≤ E[lEc]1∕2E[hV0,VVi2 (kvok2kvνk2 - 1)2i1/2
0 1/2	1/2
≤ (Cne-Cn + C0e-cn)	EUV0囱忖νk2 (Mk2∣Mk2 - 1)]
≤ (Cne-Cn + C0e-c'n) 1/2 E[kvok2kvνk2kvok2kvνk4 + kvok2kvνk2]1/2
≤ (Cne-Cn + C0e-c0n) 1/2(E[||V0|图"E[Mk26]1/4 + E[∣∣Vok2] 1/2)
≤ (Cne-Cn + C ,in)1” + C1)山	C2)“十( + C3 厂)
≤ Cn1/2e-Cn+C0e-C0n.
The first line is the Schwarz inequality; the second line is the good event measure bound and Cauchy-
Schwarz; the third line distributes and drops the cross term, given that all factors are nonnegative;
the fourth line applies subadditivity of the square root function, then the Schwarz inequality to the
resulting separate terms; the fifth line applies Lemma E.29; and the last line again uses square root
subadditivity and treats the remaining terms as multiplicative constants, since n ≥ 1. Therefore
passing to the linear term without the indicator incurs only an additional exponential factor. Pro-
ceeding, we drop the indicator and distribute to get for the linear term
E[hV0, VVi (kvok2kvνk2 - 1)] = E[hV0, VVikvok2kvνk2] - EKV0, VV)]；
it is of interest to apply Lemma E.30 to these two terms to get the proper cancellation, and for
this we just need to check that the coordinates of each factor in the product have subexponential
moment growth with the proper rate. For even powers of '2 norms of VV, this follows immediately
from Lemma G.11 after scaling by，2/n; for the inner product term, the coordinate functions are
σ(gii)g2i<σ(gii cos V + g2i Sin ν)(g2i cos V — gii Sin V), and We have from the Schwarz inequality
and rotational invariance
E[∣σ(gii)g2iσ(gii cos V + g2i sin ν)(g2i cos V - gii sin ν)∣k] ≤ E[σ(gii)g∣k],
which has subexponential moment growth with rate Cn-1 by Lemma E.17 and Lemma G.11 after
rescaling by，2/n. These formulas also show that when k = 1, we have a bound of precisely n-i.
This makes Lemma E.30 applicable, so we can assert bounds
∣E[hV0, VVi (∣∣V0k2kVV∣∣2 - 1)] - (n3E[(V0)1 (VV)1]E[σ(gπ)2] 2 - nE[(V0)1(VV)i]) ∣ ≤ C
182
Published as a conference paper at ICLR 2021
Because Eσ(g11)22 = n-2, this is enough to conclude a C/n bound on the magnitude of the
linear term. Thus, in total, we have shown
∣Ξι∣ ≤ C + C0e-cn + C00n1/2e-c0n
n
where we combine the different constant that appear in the various exponential additive errors
throughout our work by choosing the largest magnitude scaling factor and the smallest magnitude
constant in the exponent to assert the previous expression.
Ξ2 control. The approach is similar to what we have used to control Ξ1 . We start with exactly the
same E1 event definition, and as previously define
Ξe 2 = E
hv 0, VV ihvν, V V ikvo ∣∣2^
kvok3kvνk3
and then calculating
.~
∣Ξ2 - Ξ2∣
E 1E
hV0, VVihVν, VVikvok2^
m\E -Mk3∣Vνk3
≤ 26E [1Em∖E KV0, VVihvν, VVi|k v0 k2]
≤ 26E[1ec KV 0, VV)(Vv , V V ilk V0 k 2]
≤ 26E[1ec]1∕2E[hV0, VVi4] 1∕4E[hV", VVi8] 1∕8E[kV0k2]1/8
≤ 26E[1ec]"2E[kV0k2] 1∕8E[kV"k2] 1∕8E[kVVk26] 1∕16E[kV”k26]“词近图"8
≤ Ce-cn + C0n1/2e-c0n,
using the same ideas as in the previous section, plus several applications of the Schwarz inequality
and a final application of Lemma E.29. We can therefore pass to Ξ2
with a small additive error.
Next, we Taylor expand in the same way as previously, except that larger powers in the denominator
force the constant in our residual bound to be 3 ∙ 227, and the event Ei now gives Us a bound
KV0, VV)(Vv, VVikV0k2∣ ≤ 26 on the numerator, which we add and subtract as before to exploit
nonnegativity. We get
Ξ2 ≤ E 卜 EihV 0, Vv ihVV, V V ikV0k2 (1 (3-^116^112) + (26 + 1)。( k V0 k 6 k V” k 6 -1)2)；
Ξ2 ≥ e]ieKV 0, Vv ihVν, V V ikV0k2 (1 (3 -kV0k2kVνk6) - 26C (kV0k2kVν k2 - 1)2 )],
with C = 3 ∙ 227. Proceeding to control the quadratic term, we have
同 IEihV 0, Vv ihVν, V v iMk2(kV0k6kVνk6 - 1)1|
≤ 43E[(kV0k6kVνk2 - l)2i
=26E[kV0k122kVVk122-2kV0k62kVVk62+1]
≤ 26 (1 - 2E[∣V0∣6∣Vvk6] + E[kV0k24])
≤ 26(1 - 2(1 - (CnT + C0e-cn))6 +(1 + C00nT))
3
≤ Cn-1 + X (	) (C0n-i + C00e-cn)2kτ
k=1 2k-1
3 2k-1
≤ Cn-1 + C0XX
n-(2k-1-j)e-cnj
k=1 j=0
≤ Cn-1 + C0e-cn.
The justifications for the first four lines are identical to those of the previous section. In the last three
lines, we use the binomial theorem twice to expand the sixth power term, and we assert the final line
183
Published as a conference paper at ICLR 2021
by the fact that k > 0, so that each term in the sum corresponding to a j = 0 has a positive inverse
power of n attached, and when j = 2k - 1 we pick up an exponential factor. Moving on to the
linear term, as in the previous section we start by dropping the indicator. We control the residual as
follows:
∣E[1Echv 0, VV ihvν, V V ikv0 k2 (Mk6kvνk2 - 3)] I
≤ E[iEc ]1/2 EhkV 0k2kv νk2Mk2lMk4 (Mk2kvνk6 - 3)[ 1/2
≤ E[iEc ]1/2 E[kV 0k2kV V k2kvok14kvν k16 + 3kV 0k2 kV νk2Mk2kVνk4]1∕2
≤ E[lEc]1/2(E[kV0k2kVVk2kvok24kvνk26] / +3E[kV0k2kVνk2kvok2kvνk2] /)
≤ Ce-cn + C0n1/2e-c0n.
The justifications are almost the same as the previous section, although we have compressed some
steps into fewer lines here and we have omitted the final simplifications which follow from applying
the Schwarz inequality to each of the two expectations in the second-to-last line 3 times and then
applying Lemma E.29. Dropping the indicator and distributing now gives:
W[", 、、 7、、 2 \||„ ∣∣2 (||„ ∣∣6∣∣,, ∣∣6	R)]— E[hV。，VV ihvν, V V ik v0 k 2 k v0 k 2 k vν k6]
Ehv 0, VV ihVV, V V ikV0k2 (kV0k2kVV k2 - 3)J =	-3E[(V 0, Vv ihVV, VV ikV0k2];
to apply Lemma E.30, we check the two new coordinate functions that appear in this linear term:
forhV0, Vvi, We have
E[∣σ(g1i)g2iσ(g1i cos V + g2i Sin ν)∣k] ≤ E[σ(g1i)g2k] 1/2E[a(g1i)2k] 1/2,	(E.34)
and forhVV, VVi, we have likewise
E[∣σ(g1i cos v + g2i sin ν)(g2i cos V - g1 sin ν)∣k] ≤ E[σ(g1i)g2k] 1/2E[a(g1i)2k] 1/2, (E.35)
both by the Schwarz inequality and rotational invariance. As before, an appeal to Lemmas G.11
and E.17 implies that these two coordinate functions satisfy the hypotheses of Lemma E.30, so we
have a bound
E[〈V0, VV)〈Vv, Vvi∣∣Vo∣∣2 (∣∣Vok2kVν∣∣2 - 3)] - n9E[(Vo)1(VV)1]E[(VV)1(Vν)1]E[σ(w11)2]7
+ 3n3E[(V0)1(VV)1]E[(VV)i(vv)1]E[σ(w11)2] ≤ C.
Noticing that
EKVV, V v i] = -E[(V0, V 0)] = -E[hσ(g1), g2i] = 0,
by rotational invariance and independence, we conclude by identically-distributedness of the coor-
dinates of VV and VV
n9E[(V0)1(vν)1]E[(Vv)1(vν)1]E[σ(g11)2]7 - 3n3E[(V0)1(VV)1]E[(VV)1(vν)1]E[σ(g11)2] = 0,
which establishes the desired control on Ξ2. Thus, in total, we have shown
∣Ξ2∣ ≤ C + CCe-Cn + C00n1∕2e-c0n,
n
where we combine the different constant that appear in the various exponential additive errors
throughout our work by choosing the largest magnitude scaling factor and the smallest magnitude
constant in the exponent to assert the previous expression.
Ξ3 control. The argument for control of this term is very similar to the previous section, since the
degrees of the denominators now match. We start by defining
=(V0, V0)hv0, Vv)hvν, Vv)^
ξ3 = E g-WHMl-],
184
Published as a conference paper at ICLR 2021
with the same E1 event as previously, and then calculating
.~
IΞ3 - Ξ3l
E
& 0, VθihVν, V V ihv0, VV i
Mk3kVνk2
≤ 26E[lEm∖EKV0, V0ihVν, VVihvo, VVil]
≤ 26E[1ecKV0, VoihVv, VVi(V0, VVi|]
≤ 26E[1ec]1/2E[hV0, V0i4] "e[hVv, VVi8] 1∕8E[hV0, VVi8]1/8
≤ 26e[1ec ]1/2E[kV 0 k8] 1∕8E[kV0k8] 1∕8E[∣∣V ”k26]“诃同屹6] 1/1^^1126] 1/8
≤ Cn1/2e-cn + Ce-c0n,
using the same ideas as in the previous section. We can therefore pass to Ξ3 with an exponentially
small error. Next, we Taylor expand in the same way as previously, obtaining
e≡3 ≤ E [1Eι hV0, vv ihV 0, V0iVV, V V i (2 (3 - kV0k6kVV k6) + (43 + 1)C(kV0k2kVV k6 - 1)2)]；
Ξ3 ≥ E 卜E1hV0, VVi(V0, V0ihVV, VVi (1(3 - kV0k2kVVk6) - 43C (kV0k6kVV∣∣6 - I))],
with C = 3 ∙ 227. Proceeding to control the quadratic term, We notice
同1" 0, V0ihVV, V V ihV0, Vv i (忡0||6版|[6 - l)] | ≤ 43E [ ( k V0 k 6 k V“ k 6 - 1)2i
= Cn-1 + C0e-cn,
since the final term was controlled in the previous section. Moving on to the linear term, as in the
previous section we start by dropping the indicator. We control the residual as follows:
∣E[lEchV 0, V0ihVν, V V ihV0, Vv i (kV0 k2∣∣Vνk6 - 3)] ∣
≤ E[iEc ]1/2 EhkV 0k2kV νk2kV0k2kVνk4 (kV0k2kVν k6 - 3)2i1/2
≤ E[lEc]1/2E[kV0k2kVνk2kV0k26kVνk16 + 3kV0k2kVVk2kV0k2kVνk2]1/2
≤ E[iEc ]1/2(E[kV 0k2kV V k2kV0k26kVν k26]1/2 + 3E[kV。]那 “||2忡0口4版||2 ]1/2)
≤ Ce-cn + C0n1/2e-c0n,
by the same argument as in the previous section. Dropping the indicator and distributing now gives:
E[(V0, V0ihVν, VVi(V0, VVi (∣∣V0k2kVνk2 - 3)]
E[(V0, V0ihVν, VVi(V0, VvikV0k2∣∣Vνk2]
-3E[(V0, V0ihVν, VVi(V0, VVi];
to apply Lemma E.30, we check the one new coordinate function that appears in this linear term: for
hV0 , VV i, we have
E[∣σ(g1i)σ(g1i Cos V + g2i Sin V)∣k] ≤ E[σ(g1i)2k],	(E.36)
by the Schwarz inequality and rotational invariance. As before, an appeal to Lemmas G.11 and E.17
implies that this coordinate function satisfies the hypotheses of Lemma E.30, so we have a bound
E[(V0, V0ihVν, VVi(V0, Vvi (∣∣V0k6kVνk6 - 3)]
-n9E[(V0)1(V0)1]E[(VV)1 (VV)1]E[(Vν)1(V0)1 ]E[σ(g11)2]6 .
+3n3E[(V 0)1(V0)1 ]E[(V V )1 (vv )1]E[(Vν )i(v0 )1]
n-1
As in the previous section, using that E[hVν, VVi] = 0 then allows Us to conclude the desired control
on Ξ3 . Thus, in total, we have shown
∣Ξ3∣ ≤ C + C0e-cn + C00n1/2e-c0n,
n
where we combine the different constant that appear in the various exponential additive errors
throughout our work by choosing the largest magnitude scaling factor and the smallest magnitude
constant in the exponent to assert the previous expression.
185
Published as a conference paper at ICLR 2021
To wrap up, we take the largest of the scaling constants in the estimates we have derived, and the
smallest of the constants-in-the-exponent that we have derived, in order to assert
∣h00(ν)| ≤ C + C0n1/2e-cn.
n
Matching constants in the exponent and choosing n larger than an absolute constant multiple of
log n, it follows
∣h(ν)| ≤ Ce-cn + C0 —,
n
which was to be proved.	□
E.3.4 General Properties
Lemma E.16. Consider the event
Ec,m = ∩	∩ {(gl, g2) I c ≤ kISc VV (gl, g2)k2 ≤ c-1}.
S⊂[n] ν∈[0,2π]
|S|=m
Suppose n ≥ max{2m, m + 20}. Then we have the following properties:
1.	μ(Ec,m) ≤ Cnme-Cn；
2.	We have Ec,m = Ec,mQ for every Q ∈ O(2), so that in particular 1Ecm (GQ) =
1Ec,m (G).	,
Above, O(n) denotes the set of n × n orthogonal matrices.
Proof. We will show the second property first. For each c > 0, if Q ∈ O(2), notice that
Ec,mQ= \	\ GQIIIIc<IScσGcsionsνν	< c-1
S⊂[n] ν∈[0,2π]	2
|S|=m
=\	\ {G∣c< kIscσ (GQ*u)k2 <c-1}
S⊂[n] u∈S1
|S|=m
= Ec,m ,
since the vector [cos ν, Sin V]* ∈ S1, and O(2) acts transitively on S1. This proves the second
property when c > 0; the result for c = 0 is obtained by applying the preceding argument to each
set in the infinite union defining the c = 0, m event.
For the measure bound, we observe that Ec,m ⊂ Ec0,m if c ≥ c0, so it suffices to bound the measure
of the complement for the particular choice C = ɪ. We start by controlling pointwise the measure of
the complement of the event
E0.6,m,u = \ {G|0.6 < kIScσ(Gu)k2 < 5/3}
S⊂[n]
|S|=m
for each u ∈ S1 , then uniformize over the one-dimensional manifold S1 ; we need to begin with
C = 0.6 instead of C = 2 to survive some loosening of the bounds when We uniformize. We have
Ec.6,m,u = U {G∣kIscσ (Gu)k2 ≤ 0.6}∪{G | kIscσ (Gu)∣b ≥ 5/3},
S⊂[n]
|S|=m
so that a union bound implies
μ (Ec.6,m,u) ≤ X P[kIscσ (Gu)k2 ≤ 0.6] + P[kIscσ (Gu)∣b ≥ 5/3]
S⊂[n]
|S|=m
≤ (m) (P[UI[m]cσ (gl)∣∣2 ≤ 0∙6] +P[∣∣I[m]cσ (g1)∣∣2 ≥ 5/3]) ,	(E.37)
186
Published as a conference paper at ICLR 2021
where the final inequality follows from right-rotational invariance of μ and identically-
distributedness of the coordinates of gι. Let g ∈ Rn-m be distributed as N(0, (2∕n)I), so that
σ(g) has the same distribution as I[m]cσ (gι) By GaUSS-LiPSchitz concentration (Boucheron et al.,
2013, Theorem 5.6), we have
P[kσ(g)k2 ≥ E[kσ(g)k2]+ t] ≤ e-cnt2,	P[kσ(g)k2 ≤ E[∣∣σ(g)∣∣2] -1] ≤ e-cnt2,
since σ is 1-LiPschitz and nonnegative homogeneous. After rescaling, we aPPly Lemma E.19 to get
≤ E[kσ(g)k2] ≤
Plugging these estimates into the Gauss-LiPschitz bounds gives
P[kσ(g)k2 ≥ 1+ t] ≤ e-cnt2,
kσ(g)k2 ≤
≤ e-cnt2
Putting t = 2/3 in the uPPer tail bound gives the control we need for one half of (E.37). For the
lower tail, we note that the assumPtion n ≥ max{2m, m + 20} yields the estimates
1
≥√2,
2	<	2	< 1
ʌ/nʌ/n — m - n — m ~ 10'
so that
—
√n√n — m
—t ≥ -— - - - t,
≥ √2	10	,
and one checks numerically that 2-1/2 - (1/10) > 0.6. Putting therefore t
in the lower tail bound yields
2-1/2 - (1/10) - 0.6
P[kσ(g)∣∣2 ≤ 0.6] ≤ e-cn.
Plugging these results into (E.37) gives the Pointwise measure bound
μ (EC∙6,m,u) ≤ 2U卜-Cn
for some constant c > 0.
For uniformization, fix S ⊂ [n] with |S| = m and consider the function fS : R2 → R defined by
fS(u) = kIScσ (Gu)k2.
By Gauss-LiPschitz concentration, we have
P[kGk >E[kGk]+t]≤e-cnt2,
and by (Rudelson & Vershynin, 2011, Theorem 2.6), we have
2
e[∣∣g∣∣] ≤ √2+√n ≤ 4.
Let E = {∣∣G∣∣ ≤ 5}; then it follows that μ(E) ≥ 1 - e-cn. On E, for every S, We have that fs is
a 5-LiPschitz function of u. Let Tε ⊂ S1 be a family of sets with the ProPerty that u ∈ S1 imPlies
that there is u0 ∈ Tε such that ku0 - uk2 ≤ ε for each ε > 0; by standard results (Vershynin, 2018,
Corollary 4.2.13), T exists and We have ∣Tε| ≤ (1 + 2ε-1)2. Define
E0.6,m,ε = \ E0.6,m,u.
u∈Tε
Then a union bound together with our Pointwise concentration result gives
μ (Ec.6,m,ε) ≤ 2(m) (1 + ε) e-cn.
On E ∩ E0.6,m,ε, for any u ∈ S1 and any S, there is u0 ∈ Tε such that |fS (u) - fS(u0)| ≤ 5ε. But
since on this event 0.6 ≤ fS(u0) ≤ 5/3, we conclude 0.6 - 5ε ≤ fS (u) ≤ 5/3 + 5ε, and therefore
the choice ε = 1/50 gives 0.5 ≤ fS (u) ≤ 2. This imPlies
E ∩ E0.6,m,1/50 ⊂ E0.5,m.
P
2
187
Published as a conference paper at ICLR 2021
Thus, by a union bound and our previous results, we have
μ (Ec.5,m) ≤ μ (EC ∪ Ec.6,m,1∕50
≤ μ (Ec.6,m,1∕50 ) + e cn
≤ 2 ∙1502 ( n )e-c0n + e-cn
m
which is the desired measure bound.
□
Lemma E.17. We have for each fixed ν ∈ [0, π] that:
1.
2.
3.
The coordinates of VV have Subgaussian moment growth
EM )p]≤ 2 (2p 广；
The event {∣∣V ν∣∣2 ≤ 2} has probability at least 1 一 e-cn;
The event {∀ν ∈ [0, ∏] ∣∣V v k2 ≤ 4} has probability at least 1 — e-c0n
Proof. We have that the coordinates of VV are i.i.d., and
(V v )i = σ(g1i)g2i,
by rotational invariance. By independence ofg1 and g2, we compute
1	2p/2
E[(VV)P] = E[σ(gii)gPi] = 2E[gPi] ≤ 2np72Pp/2,
for each P ≥ 1; the last inequality follows from Lemma G.11. This shows that the coordinates of VV
are independent SUbgaUSSian random variables with scale parameters at most C，2/n, so We have a
tail bound (Vershynin, 2018, Theorem 3.1.1)
P[kVvk2 ≥ 1+ t] ≤ e-cnt2,
also taking into account that E[(VV)2] = 1/n. This shows that the event E00 = {∣∣Vv∣∣2 ≤ 2} has
probability at least 1 一 e-cn .
For the third assertion, We use the triangle inequality to get ∣∣Vv∣∣2 ≤ ∣∣g21∣2 + ∣∣g2∣∣2, which has
RHS independent of ν; then applying Gauss-Lipschitz concentration gives for t ≥ 0
Phkgik2 ≥√2 + t] ≤ e-cnt2,
using that E[kgik2] ≤ ,E[kgik2]. Putting t = 0.5 in this bound and applying a union bound, we
conclude that there is an event of probability at least 1 一 e-cn on which kvV k2 ≤ 4 uniformly in
V.	□
Lemma E.18. There exists an absolute constant C > 0 such that if n ≥ C, one has
C0
1---------Ce ≤ E [∣∣v0∣∣2∣∣vν∣∣2] ≤ 1,
g1 ,g2
n
where c, C0 , C00 > 0 are absolute constants.
Proof. For the upper bound, we apply the Schwarz inequality to get
E[kV0k2kVVk2] ≤ E[kV0k22]1/2E[kVVk22]1/2 ≤1,
by rotational invariance and Lemma G.11. For the lower bound, we will truncate and linearize the
product using logarithms. Let E = E0.5,0; by Lemma E.16, as long as n ≥ 20 we have μ(Ec) ≤
Ce-cn. Define X = kV0k2kVVk21E + 1EC, so that
X(G) = kV0(G)k2kVV(G)k2 G∈E,
1	otherwise.
188
Published as a conference paper at ICLR 2021
We calculate
∣E[kv0k2kvνk2] - EX]| ≤ μ(EC) + E[1e]1/2E[Mk4]1/2
≤ Ce-cn+C0e-c0n(1+C0/n)1/2
using the triangle inequality, the Schwarz inequality, rotational invariance, and Lemmas E.16
and E.29. It follows
E[kv0k2kvνk2] ≥ E[X] - C0e-cn,
so it suffices to prove the lower bound for X instead. Factoring as X = (kv0k21E +1Ec)(kvνk21E +
1Ec), we apply concavity of x 7→ log x, Jensen’s inequality, and convexity of x 7→ ex to get
EX] ≥ exp (E[log(∣∣v0∣∣2lE + 1eJ] + 叫l0g(∣∣Vν∣∣2lE + 1eJ])
≥ 1 + E[log(∣W0k2lE + 1e C)] + E[l0g(∣∣Vνk2lE + 1e C)]
≥ 1 + 2E [log(kv0k2lE + 1ec )]
where the last equality is due to rotational invariance. Now write Y = kv0 k21E + 1EC, so that by
the definition of E We have Y ≥ ɪ. Taylor expansion with Lagrange remainder of the logarithm
about E[Y] ≥ 1 gives
1	12
log(Y) = logE[Y] - EY] (Y - E[Y]) - 2ξ(Y^ (Y - E[Y])2
for some ξ(Y) between E[Y] and Y. Using Y ≥ ɪ and taking expectations on both sides, we get
E[log Y] ≥ log E[Y] - 2Var[Y].
Moreover, we have
|E[Y] - E[kv0k2]| ≤Ce-cn+E[1ECkv0k2] ≤ Ce-cn + C0e-c0n,
by the Schwarz inequality, and this extra exponential error can be rolled into the exponential error
accrued via our use of X. In particular, we have
1 - 2 - Ce-Cn ≤ E[Y] ≤ 1 + Ce-Cn
n
by Lemma E.19. Since n ≥ 20, if we also enforce n ≥ C1 := c-1 log(5C/2) we have 2/n +
Ce-Cn ≤ 2; it follows by concavity of x → log(1 - x) that we have a bound
log ( 1 - 2 - Ce-Cn) ≥ -2log(2) ( 2 + Ce-Cn
nn
which has the form claimed. It remains to upper bound Var[Y]; using that Y2 = kv0k221E + 1EC,
we have
Var[Y] = E[Y2] - E[Y]2 ≤ 1 + Ce-Cn - (1 - 2 -
n
Ce-Cn + 2(2+ Ce-Cn
n
+ Ce-Cn2
2
≤ 4 + 3Ce-cn
n
which is sufficient to conclude
□
Lemma E.19. One has
1 - 2 ≤ E [kvνk2] ≤ 1.
n	g1 ,g2
Proof. By rotational invariance, it is equivalent to characterize the expectation of kσ(g1)k2. By the
Schwarz inequality, we have
E[kv0k2] ≤ E[kv0k22]1/2 = 1,
189
Published as a conference paper at ICLR 2021
by Lemma G.11. For the lower bound, We apply the Gaussian Poincare inequality (BoUcheron et al.,
2013, Theorem 3.20) and the 1-Lipschitz property of g 7→ kσ(g)k2 to get
nE[(kv0k2 -E[kv0k2])2] ≤ 1,
so that after distributing and applying E[kv0k22] = 1, we see that
1 - 2 ≤ E[kv0k2]2.
n
Because n ≥ 2, it follows
E[kv0k2] ≥
where the last bound holds because 1 - 2n-1
一 ≥ 1——
nn
≤ 1.
y1—
2
2
□
Lemma E.20. If 0 ≤ x, y ≤ 1, we have
|cos-1 x - cos-1 y | ≤	|x - y |.
Proof. Let 0 ≤ x, y ≤ 1, and assume to begin that x ≤ y. We apply the fundamental theorem of
calculus and knowledge of the derivative of cos-1 to get
P
cos-1 x - cos-1 y =
y1
I	dt
√1-t2
The integrand is nonnegative, so cos-1 X - cos-1 y ≥ 0. Writing √1 -12 = √1 - t√1+1 and
using x ≥ 0, we get
cos-1 x - cos-1 y ≤
This shows that |cos-1 X-Cos-I y| ≤ |√1 - X-√1 - y| whenX ≤ y. Analmost-identicalargument
establishes the same when y ≤ x, via the inequalities 0 ≥ cos-1 X - cos-1 y ≥ - (√1 - X - √1 - y).
So we have shown	_____ __________
|cos-1 X — cos-1 y| ≤ |√Γ-^x —，1 — y|
for arbitrary 0 ≤ X ≤ 1 and 0 ≤ y ≤ 1. Now notice
∣√1 - X - pl - y∣2 ≤ ∣√1 - X - pl - y∣∣√1 - X + pl - y|
≤ |(1 -X) - (1 -y)| = |X-y|,
which establishes |cos-1 X - cos-1 y| ≤ ,|X - y|.	□
E.3.5 Differentiation Results
Lemma E.21. For a < b, let f : [a, b] → R be a continuous function that is differentiable on (a, b)
except at a set of isolated points in (a, b), and let c ∈ R. Then max{f, c} is differentiable except at
a set of isolated points in (a, b).
Proof. Let A ⊂ (a, b) denote the set of points of differentiability of f, and let B ⊂ (a, b) denote the
set of points of nondifferentiability of max{f, c}. Because finite unions of isolated sets of points in
(a, b) are isolated in (a, b), it suffices to consider only points X ∈ A.
Fix X ∈ A, and consider the case f (X) 6= c. Then because f is continuous, there is a neighborhood
of X on which f 6= c. If f > c on this neighborhood, then we have max{f, c} = f on this
neighborhood; if f < c, then we have max{f, c} = c. In either case, this implies that max{f, c} is
differentiable at X, and thus X is not in B .
Next, consider the case where f(X) = c. First, suppose f0(X) > 0; then by Rolle’s theorem, we can
find a neighborhood of X on which f(X0) > c if X0 > X and f(X0) < c if X0 < X. Possibly shrinking
this neighborhood, we can assume every point of the neighborhood is a point of differentiability of
190
Published as a conference paper at ICLR 2021
f. Thus, for x0 < x in this neighborhood, we have max{f (x0), c} = f(x0), and for x0 > x, we have
max{f (x0), c} = c. We conclude that max{f, c} is differentiable at all points of this neighborhood
except x, and in particular x is an isolated point in B . A symmetric argument treats the case where
f0 (x) < 0, with the same conclusion.
On the other hand, if f0 (x) = 0, we can write f(x0) = c + o(|x0 - x|) for x0 in a neighborhood
of x, which implies max{f (x0), c} = max{c, c + o(|x0 - x|)} = c ± o(|x0 - x|). In particular,
|max{f(x0), c} - max{f (x), c}| = o(|x0 - x|), which shows that max{f, c} is differentiable at
x, and thus x is not in B . This shows that every point of A ∩ B is isolated in A ∩ B , and we can
therefore conclude that max{f, c} is differentiable except at isolated points of (a, b).	□
Lemma E.22. For 0 ≤ ν ≤ π, consider the function
虱 V )=	E	[1ei φ(ν, gι, g2)],
gι ,g2~i.i.d.N(0,(2∕n)I)
where
-1	hv0, vνi
φ(V, gl, g2) = cos	U~~∏-∏~~∏-.
kv0k2kvνk2
Then 0 is absolutely continuous on [0, π], and satisfies the first-order Taylor expansion
0(V)
0(0) -「E
0 g1 ,g2
and moreover 0 is 1 -Lipschitz.
Proof. At points of (0, π) where each of the functions composed in φ is differentiable, the chain
rule gives for the derivative of the integrand as a function of V
φ0(V,g1,g2)
/_vo_____」It - VVVV ∖ V ∖
∖kv0k2, Ek? (I	idk21 vν∕
xx* ʌ
kxiJ,
(E.38)
where we have used the result
I-
valid for any x 6= 0. Because E1 guarantees that vν 6= 0 for all V ∈ [0, π], we see that the integrand
φ is continuous. Similarly, given that ∣∣Vν∣∣2 ≥ 1 on Ei, We note that there arejust two obstructions
to differentiability:
1.	The inverse cosine is not differentiable at {±1};
2.	The activation σ is not differentiable at 0.
First we characterize the issue of nondifferentiability with regards to the inverse cosine. We note
that cos φ(V, g1, g2) = 1 if and only if the Cauchy-Schwarz inequality is tight, which is equivalent
to v0 and vν being linearly dependent. Suppose we have (g1, g2) ∈ E1 and V0 ∈ (0, π) such that
v0(g1, g2) and vν0 (g1, g2) are linearly dependent. Because two vectors u1, u2 ∈ Rn have σ(u1)
and σ(u2) linearly dependent if and only ifσ(u1) and σ(u2) have the same support and are linearly
dependent on the support, and given that kvν k0 > 1 for each V, we have that there is a 2 × 2
submatrix of GMν0 having positive entries and rank 1 (since the rank is zero if and only if the
submatrix is zero), where
Mν
1 cos V
0 sin V .
191
Published as a conference paper at ICLR 2021
Write the corresponding 2 × 2 submatrix of G as X. Because rank Mν0 = 2 by ν0 ∈ (0, π), we
have rank X = 1. On the other hand, if G 〜i.i.d. N(0, 2/n), We have
P[G has a singular 2 × 2 minor] ≤	P rank
1≤i<j ≤n
= 0,
G1i	G2i
G1j	G2j
<2
Where the first line is a union bound, and the second line uses the fact that 2 × 2 submatrices of G
are i.i.d. N(0, 2/n), and that the complement of the set of full-rank 2 × 2 matrices is a positive-
codimensional closed embedded submanifold of R2×2. It folloWs that the subset of E1 of matrices
having no singular 2 × 2 minor has full measure in E1, and We conclude that for almost all (g1, g2),
We have cos φ(ν, g1, g2) < 1 for every ν ∈ (0, π). Next, We characterize nondifferentiability due
to the activation σ ; by the chain rule, it suffices to consider nondifferentiability of vν as a function
of ν, and then Lemma E.21 implies that for every (g1, g2), vν is differentiable at all but at most
countably many points of [0, π]. Next, We observe that Whenever vν is nonvanishing, one has
1	(I _ VVV^ A . ∖ ≤ kPVVVνk2 Il (I _ VVVV A vo
kVνk2 I kVν k2J ν/ ≤ kVνk2 心 kVν k2J kV0k2 2
="EV V νk2 J- D q - E2
="Vν "2 V1	∖kvθk2 Tv” k2∕ ,
Where the first inequality is due squaring the orthogonal projection and Cauchy-SchWarz, and the
second equality folloWs from distributing to evaluate the squared norm, cancelling, and taking square
roots. Using the fact that orthogonal projections have operator norm 1, We thus conclude
lφ0 (V g1，g2)l≤k⅛h ≤ CkV V k2，	(E.39)
Where the last inequality is valid Whenever (g1, g2) ∈ E1. Since
"Vν∣∣2 = ∣∣<σ(gι cos V + g2 Sin V) Θ (g2 Cos V - gι Sin ν)∣∣2
≤ kg2 cos ν - g1 sin ν k2
≤ "g2" + "g1"2,
and this upper bound is jointly integrable in V and (g1, g2) over [0, π] × Rn × Rn, We can apply
(Cohn, 2013, Theorem 6.3.11) to obtain that Whenever (g1, g2) ∈ E1 minus a negligible set, We have
for every V ∈ [0, π]
φ(V,g1,g2)
φ(0,g1,g2) +	φ0(t, g1, g2) dt.
0
In particular, multiplying by the indicator for E1, taking expectations over (g1, g2), and applying the
previous joint integrability assertion for φ0 together With Fubini’s theorem yields
V
E [φ0(t,g1,g2)]dt,
g1 ,g2
0(V) = 0(。)+ I
0
192
Published as a conference paper at ICLR 2021
so to conclude the Lipschitz estimate, it suffices to obtain a suitable estimate on Eg1,g2 [φ0(ν, g1, g2)].
In light of (E.39) we calculate more precisely
kPVν V νk2
kvνk2
kP⊥ V0 k2
Ilv0k2
J	KI-σk⅛* 卜 σ(gι) θ g2)(]
E 1E1	西见
≤E
W)k0>ι H Y F 0 g2"21
NI-σk⅞⅜n "1)Q g2)∣∣2
kσ(gl)k2
Iσ(g1)I0 = k
XLG x~χEk-i)[X]γ胤)
1
Y
In the first line, we apply rotational invariance and unpack notation; in the second line, we use non-
negativity of the integrand to pass to the containing event where V0 is at least 2-sparse; and in the
third line, we condition on the size of the support of g1 . In the fourth line, we use several facts; first,
We note that P⊥(σ(gι) 0 g2) = P⊥Pσ(g1)>0}g2 for any g2 ∈ Rn, and that the commutation
relation Pv⊥0 P{σ(g1)>0} = P{σ(g1)>0}Pv⊥0 implies that the operator Pv⊥0 P{σ(g1)>0} is itself an or-
thogonal projection, With range equal to the (IV0I0 - 1)-dimensional subspace consisting of vectors
With support supp(V0) orthogonal to V0. In particular, σ(g1) and Pv⊥0P{v0>0}g2 are independent
gaussian vectors, and conditioned on the size of the support of σ(g1) the quantities Iσ(g1)I2 and
IPv⊥ P{v0>0}g2 I2 are distributed as independent chi random variables With (respectively) k and
k - 1 degrees of freedom. An application of Lemma G.9 then gives
E"lΕι kp⊥νVVk2# ≤ 1,	(E.40)
1	IVνI2
which is sufficient to conclude.	□
Lemma E.23. The random variable Xν satisfies the following regularity properties:
1.	If 0 < ν ≤ π, we have Xν < 1 almost surely.
2.	If (g1, g2) ∈ E1, then Xν is absolutely continuous on [0, π], with a.e. derivative
X = /上___________L (I--VνVlʌ V ∖
V	∖kv0k2,kvνk2l	kvνk2j ν/,
and moreover we have Eg1,g2 [|Xv|] ≤ 1, So the analogous differentiation result applies to
Eg1 ,g2 [Xν ].
Proof. The first claim is a corollary of the proof of differentiability of the inverse cosine part of 0
in Lemma E.22 and the observation that Xπ = 0. The second claim is also a direct consequence of
the proof of Lemma E.22 and Fubini,s theorem.	□
Lemma E.24. Consider the function
f(ν) = E [Xν] = E
g1 ,g2
g1 ,g2
V0	VV
kv0k2, kvνk2
Then f is continuously differentiable, with derivative
E
g1 ,g2
V0	1
Ilv0k2 , kvνk2
I-
VV VV )
kVν k2；
f0(ν)
193
Published as a conference paper at ICLR 2021
Moreover, f0 is absolutely continuous, with Lebesgue-a.e. derivative
f00(ν)
vνvL∖V ɪ(1 -vovi∖
kvνk2J ν, IW0k2l kv0k2J
Proof. The expression for f0 is a direct consequence of Lemma E.23. To see that f0 is actually
continuous, apply rotational invariance of the Gaussian measure and of 1E1 by Lemma E.16 to get
f0(ν)
-E
g1 ,g2
VV	1
,
then notice that this expression is an integral of a continuous function of ν, which is therefore
continuous. Moreover, the ν dependence in this expression for f0 mirrors exactly that of f ; in
particular, the integrand
is absolutely continuous whenever (g1, g2) ∈ E1 by Lemma E.23, with a.e. derivative
—
1
kvνk2
I-3 K,
kVν k2J V, kv0 k2
I-
V0Vθ
V0
We can therefore conclude the claimed expression for f00 provided we can show absolute integra-
bility over E1 of this last expression, using Fubini’s theorem in a way analogous to the argument in
Lemma E.22. But
g1 ,g2
E
—
VVVV ʌ	V0
百),而
I-
v0vO ʌ \
M )1
≤ 4 E	[1Eι IIPvVVν∣∣2∣IPVoV0∣I2]
g1 ,g2
≤ 4E[kV0k2i =4,
using, in sequence, Cauchy-Schwarz and the lower bound in the definition of E1 ; the operator norm
of orthogonal projections being 1, the Schwarz inequality, nonnegativity of the integrand, and rota-
tional invariance; and Lemma E.17. We can therefore conclude the claimed expression for f00 and
complete the proof.	□
Lemma E.25. For the heuristic cosine angle evolution function
cos 2(V) = E [(V0, VVi],
g1 ,g2
we have the following integral representations for its continuous derivatives:
(Cos ◦2)0(V)= E [(V0, VVi]
g1 ,g2
(Cos ◦2)00(V) = - E [(V0, VVi].
g1 ,g2
Proof. The proof follows exactly the arguments of Lemma E.24, but with a simpler integrand and
different integrability checks; the continuity assertion relies on Lemma E.5. Indeed, this approach
gives that (vo, VVi is absolutely continuous, with LebesgUe-a.e. derivative (vo, VVi; We check
E [|(V0,VVi|] ≤ E [kV0k2]1/2 E [kVok2]1/2 ≤ 1
g1 ,g2	g1 ,g2	g1 ,g2
by Cauchy-Schwarz, the Schwarz inequality, rotational invariance, and Lemma E.17. This verifies
the claimed expression for (Cos ◦夕)0. For the second derivative, we apply rotational invariance to
get
(Cos ◦2)0(ν) = - E [(Vv, V0i],
g1 ,g2
which has an absolutely continuous integrand, with Lebesgue-a.e. derivative
一(V0, VV).
Checking absolute integrability, we have as before
E [|(v0,VVi|] ≤ E [kVok2] ≤ 1
g1 ,g2	g1 ,g2
by Cauchy-Schwarz, the Schwarz inequality, rotational invariance, and Lemma E.17. This estab-
lishes the claimed expression for (Cos 3)00.	□
194
Published as a conference paper at ICLR 2021
Lemma E.26. Let ψ : R → R be defined by ψ(x) = ψ0.25 (x), where ψ0.25 is the function con-
structed in Lemma E.31. Then the function
f(ν, g1) = E
g2
hv0, VVi
ψ(kv0k2)ψ(kvν k2 )
satisfies for all ν ∈ [0, π] and Lebesgue-a.e. g1 the second-order Taylor expansion
f(ν, g1)
kv0k2
Ψ(kv0k2)2
n
X
i=1
σ(gii)3ρ(-gii cot S)
ψ(kvok2)ψ(kvil∣2)sin3 S
_ E Γ	hv0, VSi _ hv0, vsiψ0(IlvSk2)kvsk2-
E [ψ(kv0k2)ψ(kvsk2) ψ(kvok2)ψ(kvsk2)2 -
_ E Γ+ hv0, vs ihvs, V Si ψ00 (IlvSk2) 一
E Γ ψ(kvθki)Ψ(kvsk2)2 kvs ki 一
+ E L 2 hv0, v sihvs, v siψ0(IIvSk2) _ hv0, vsikv S∣∣2ψ'(IIvSk2 ) ]
+ E[ Ψ(kv0k2)ψ(kvSk2)2kvSk2 ψ(kv0k2)ψ(kvSk2)2kvSk2J
+ E ∣2 hv0, vSihvS , v Si2ψ0(IIvSk2) + hv0, vSihvS, v Si2ψ0(IIvSk2) ] ! d
+E[ ψ(kv0k2)ψ(kvSk2)3kvSk2 + ψ(kv0k2)ψ(kvSk2)2kvSk2 U
where previously-unspecified notation in this expression is introduced in (E.44).
Proof. Take gι ∈ Rn such that f (ν, ∙) exists and is gι-integrable; by FUbini's theorem such gι
have full measure in Rn. Because ψ > 0 and ψ(kvν k) is locally (as a function of ν) constant when-
ever kvνk < 41, we need only consider nondifferentiability of σ when assessing differentiability of
f (∙, g1). By Lemma E.21, we conclude that f (∙, g1) is differentiable at all but at most countably
many points of (0, π); since ψ > 0 and ψ is smooth, f is continuous, and we can therefore ap-
ply Lebesgue differentiation theorems (Cohn, 2013, Theorem 6.3.11) to f provided we satisfy the
standard derivative product integrability checks. Writing
φ(ν, g1, g2)
hv0, vνi
ψ(kv0k2)ψ(kvν k2)
the chain rule gives (at points of differentiability)
φ0(ν, g1, g2)
/	v0	. ∖	/ hv0, vνiΨ0(kvνk2)vν	.
∖ψ(kv0k2 )Ψ(kvν k2) , vV/ - ∖ψ(kvθk2)Ψ(kvν k2)2kvν k2 , v'
In this expression, we follow the convention 0/0 = 0 to account for the possibility that kvν k2 = 0
(in this case, the ψ0 term handles the denominator). For product integrability, we Lemma E.31 to
get ∣ψ01 ≤ C for some absolute constant C > 0 together with Cauchy-Schwarz and the triangle
inequality to get
∣φ0 (ν, g1, g2)| ≤ I6kv0k2kv V k2 + 64C kv0k2kvν k2 kv V k2,
and applying the Schwarz inequality, rotational invariance (to eliminate ν dependence in the re-
sulting expectations) and Lemma E.17, we conclude that φ0 is jointly absolutely integrable over
[0, ∏] X (Rn×2, μ 0 μ). We have therefore a first-order Taylor expansion
f(ν,g1) = f(0, g1)
/ ∖
We have
ZV
0
+
E ∖(	v0	v∖ ] - E ∖( hv0, vtiψ0(kvtk2)vt v ∖]
E[∖ψ(kv0k2)Ψ(kvtk2)' 'A E[∖ψ(kv0k2)Ψ(kvtk2)2kvtk2 , 'A
X-----------{z-------------} X----------------{z---------------}
Ξ1(V)	Ξ2(V)
dt.
f(0, g1) = E
g2
.kv°k2	] =	kv0k2
≠(kv0k2)2J = Ψ(kv0k2)2,
195
Published as a conference paper at ICLR 2021
since v0 depends only on g1 . Next, we show t-differentiability of the inner expectation. Our aim
is to apply Lemma E.27 to differentiate Ξ1 and Ξ2. We first focus on Ξ1; distributing and applying
linearity, we have
n
Ξ1 (ν) = X E
i=1 g2
σ(g1i)(g2i cos ν - g1i sin ν)
Ψ(Mk2)Ψ(kVνk2)	σ(g1i cos V
+2i sin ν)
We have shown absolute integrability of the quantity inside the expectation above; we can therefore
apply Fubini’s theorem and the previous definition to write
Xn	σ(g1i)(g2i cos ν -g1i sin ν)
E E 77η-7------------VhTTTh―7--------TIr∖σSi' cos V + 92i sin V) . (E.41)
i=1 (g2j):j6=i g2i ψ(kv0(g1, g2)k2)ψ(kvν(g1, g2)k2)
For each i ∈ [n], write πi : Rn → Rn-1 for the linear map that deletes the i-th coordinate from its
input, and let ∏ : R X Rn-I → Rn be the linear map SUch that ∏(gi, ∏i(g)) = g. With g2 fixed (in
the context of (E.41)), if we define
f(	)= _____________σ(gii)(gcos V — gii sin V)______________
1	'g	Ψ(kv0(g1,∏i(g,∏i(g2)))k2)Ψ(IWν(gι,∏i(g, ∏i(g2)))k2),
then we can write
n
Ξi(v )=£	E	E[fι(V,g2i )σ(gii cos V + g2i sin V)].
i=1 (g2j ):j 6=i g2i
Thus, to differentiate Ξ1, it suffices to check the regularity of f1(V,g ) and apply Lemma E.27. As
before, ψ > 0 and ψ smooth implies that f1 is continuous on [0, π] × R. For integrability of f, we
appeal to the Fubini’s theorem justification that we applied previously. For absolute continuity, we
apply Lemma E.21 to get that the derivative of f with respect to V is, by the chain rule,
f10 (V, g) = -σ(g1i)
1i cos V +g sin V
ψ(kv0k2)ψ(kvν k2)
(gcos V — gii sin V)ψ0(kvνk2)hvν, VVi
+ 一Ψ(kvθk2)Ψ(kVν k2)2kVν k2
at all but at most countably many values of V; and the triangle inequality, Cauchy-Schwarz, and
Lemma E.31 yield
lf1 (V,g)| ≤ σ(gii) (16(|gii| + |g|) + 64C(IgI + 扇|)|忖νk2)
≤σ (g1i)(|g| + |g1i|) (16 + 64C(kg1k2 + kg2k2))
≤σ	(g1i)(IgI + Ig1iI)(16+64C(kg1k2+ kπi(g2)k2 + IgI)),	(E.42)
(we apply square root subadditivity in the last line) which is jointly integrable over [0, π] × R,
and moreover over [0,∏] × Rn. We conclude absolute continuity of fi( ∙ ,g) and the integrability
property of f10. Finally, for the growth estimate, we obtain an estimate for f1 similar to the one we
just obtained for f10 as follows:
If1(V,g)I ≤ 16Ig1iI(IgI + Ig1iI);
(E.43)
the RHS of the final inequality above is a linear function of IgI, and when IgI ≥ 1 we can therefore
obtain If1(V, g)I ≤ 16(Ig1iI + Ig1iI2)IgI, which is a suitable growth estimate with p = 1. Then as
long as g1i 6= 0 for all i (such g1 form a set of measure zero, which we can neglect), we can apply
Lemma E.27 to get
n
ξI(V )=X(g2jEj=i
E [f1(0,g2i )σ(gii)] +
g2i
Eg2i [fi (t, g2i)σ(gii cos t + g2i sin t)]
fl (t,-gii Cot t)ρ(-gii Cot t)
-g1i	Sin2 t
dt
The estimates (E.42) and (E.43) show, respectively, that f10 and f1 are absolutely integrable functions
of (V, g2 ). We have
f1 (t, -g1i cot t)
(g1i)2
ψ(kvθ(gi, g2)k2)ψ(kvt (gi,∏i(-gii cot t,∏i (g2)))k2)sin t,
so that Lemma E.31 and nonnegativity give
—
g1i
f1 (t, -g1i cot t) ρ(-g1i cot t)
sin21
≤ 16[I； ρ(-gii cott).
196
Published as a conference paper at ICLR 2021
As in the proof of Lemma E.37, in particular using the estimates (E.52) (E.53) to control the magni-
tude of the RHS for all values of t, we can conclude that the Dirac term is absolutely integrable over
[0, π] × Rn . An application of Fubini’s theorem then allows us to re-combine the split integrals in
the previous expression:
n
Ξι(ν) = X E[fι(0,g2i)σ(gii)] +
i=1 g2
We notice that
Eg2 [f0 (t,g2i)σ(gii cos t + g2i Sin t)] 、d
-g1ip( Sg1^0 t) Eg2 [f1 (t, -g1i Cot t)])
	-	σ(g11 Cos V + g21 sin V)	- . . . σ(gl(i-1) CoS V + g2(i-1) sin V)
Vt(gl,∏i(-gli Cot t,∏i(g2)))=	0 σ(gi(i+i) Cos V + g2(i+i) sin V)
σ(g1n cosν + g2n sinν)
and thus motivated introduce the notation
gi(t, gl, g2)= ∏i(-gli cot t,∏i(g2));
vi(gl, g2) = Vt(gl,gi(t, gl, g2)).
(E.44)
We can then write
f1 (t, -gli Cot t) p(-gli Cot t) _	σ(gli)i3p(-gli Cot t)
sin2 t	Ψ(kv0k2)Ψ(kvik2)sin31
Finally, we apply linearity of the integral to move the summation over i back inside the integrals,
obtaining
-/m I_ hvo, V0i -
T(V)= E [ψ(kvθk2)2 -
n
X
i=1
σ(gii)3ρ(-gii Cot t)
ψ(kv0k2)ψ(kvik2)sin3 t
〈V0,Vt〉____
3(kv0k2)3(kvtk2)
hv0,vthvt,vt'iψ (Ilvtk2)
3(kv0k2)3(kvtk2)2kvtk2
dt
Noting that, in the zero-order term, the only g2 dependence is in V0 = σ(gι) Θ g2, we apply
independence of g1 and g2 to obtain finally
Ξ1(ν)=	νE
0 g2
-ZνE
0 g2
n
X
i=1
σ(gii )3ρ(-gii Cot t)
ψ(kv0k2)ψ(kvik2)sin31
ψ(kv0k2)ψ(kvtk2) +
dt
(VO, Vtihvt, Vtiψ'(∣∣vtk2) A
Ψ(kv0k2)Ψ(kVtk2)2kVtk2J
dt
We run the same type of argument on Ξ2 next. Distributing and applying linearity, we have
n
Ξ2(ν) = V" E [Im<σ(gii Cos V + g2i sin V)A],
g2
i=1
where in the previous expression
A =(V0, VViσ(gii CoS V + g2i Sin V)(g2i CoS V — g* Sin V)ψ'(∣∣Vνk2)
他(%0心)砂(%"||2)2|跖||2	.
By the preceding (product) absolute integrability check when taking first derivatives, we can apply
Fubini’s theorem to split the integral as we did with Ξ1 . We define, with g2 fixed, the function
f (	) = B________________(Vθ(gl), VV(gl,∏i(g,∏i(g2)))i________________
2	"g	Ψ(kV0(gl)k2)Ψ(kVν(gl,∏i(g,∏i(g2)))k2)2kVν(gl,∏i(g,∏i(g2)))k2
197
Published as a conference paper at ICLR 2021
where in the previous expression
B = σ(gn cos V + g Sin V)(g cos V - gι Sin V)ψ0(∣∣Vν(g1,∏i(g,∏i(g2)))k2),
so that
n
Ξ2(ν )=£	E	E [f2(ν,g2i )σ(gn cos v + g2i sin V)].
i=1 (g2j ):j 6=i g2i
Now we check that the hypotheses of Lemma E.27 are satisfied for f2 . The continuity argument is
identical to that employed for f1, as is the joint absolute integrability property of f2 . For absolute
continuity, we again use ψ > 0, ψ smooth, and Lemma E.21 to obtain the derivative at all but finitely
many points of [0, π] (by the chain rule and the Leibniz rule) as
f0( I= hvo, VViσ(gii cos V + gsin V)(gcos V - gu sin V)ψ0(∣∣Vνk2)
f2(V，g)=	Ψ(kv0k2)Ψ(kvν k2)2kvν k2
hvo, VViσ(gii cos V + g sin V)(g cos V - gu sin V)2ψ0(∣∣Vνk2)
+	Ψ(kv0k2)Ψ(kVν k2)2kVν k2
hvo, vViσ(g1i cos V + g sin V)(g1i cos V + g sin V)ψ0(kvVk2)
ψ(kv0k2 )ψ(kvν k2)2kvν k2
hvo, VViσ(gii cos V + g sin V)(g cos V - gι sin V)ψ0(∣∣Vν∣∣2)hvν, VVi
-2-------------------------------------Σ--------------------------
ψ(kv0k2)ψ(kvν k2)3kvν k2
hvo, VViσ(gii cos V + gsin V)(gcos V - gι sin V)ψ0(∣∣vν∣∣2)hvν, VVi
---------------------------------------:------Z-------------------
Ψ(kv0k2)ψ(kvV k2)2kvV k2
hvo, VViσ(gii cos V + gsin V)(gcos V - gι sin V)ψ00(kvVk2)hvV, VVi
+	ψ(kvo k2)ψ(kvV k2)2kvV k2	.
Because ψ0 or ψ00 and our convention handle cancellation in the case where kvV k2 = 0, we can
proceed when necessary with the convenient estimate
σ(g1i cos V + g sin V)
∣∣Vv(gl,∏i(g, ∏i(g2)))k2
≤ 1,
which follows from the fact that ∣u∣∞ ≤ ∣u∣2 for any u ∈ Rn. As with Ξ1, we then estimate
the magnitude of f20 using Lemma E.31, Cauchy-Schwarz, the triangle inequality, and square-root
subadditivity (skipping some steps that we wrote out in the Ξ1 estimate):
If2(v,g)| ≤ 64C(∣g∣ + ∣gii∣)∣vo∣2 (kvVk2(2+ CI) + (|g| + ∣gii|)(2 + 8∣v“|切)
≤ 64C(|g| + ∣gii∣)kg1k2( ι(kg1k2l +，既k2+ 吁 I、F) - J ,
+(|g| + |g1i|) (2 + 8(∣g1∣2 + ∣πi(g2)∣2 + |g|))
(E.45)
which is jointly integrable over [0, π] × R, and moreover over [0, π] × Rn. We conclude absolute con-
tinUity of f2( ∙ ,g) and the integrability property of f2. For the growth estimate, We argue similarly
to our bound on f20 to get
If2(ν,g)∣ ≤ 64CkVOk2(∣g∣ + ∣gii∣)2
≤ 64CkgIk2 (|g|2 + 2∣gii∣∣g∣ + ∣gii∣2);	(E.46)
the RHS in the final inequality is a quadratic function of |g |, and we therefore obtain a suitable
growth estimate with p = 2 and C0 = 64Ckg1 k(1 + 2|g1i| + |g1i|2) as soon as |g| ≥ 1. We can
therefore apply Lemma E.27 to get that for all but a negligible set ofg1 that
S	∖1,∕v( Eg2i[f2 (t,g2i)σ(g1i cos t + g2i sin t)] V,'
ξ2 (V) = / v E	E [f2(0, g2i)σ(g1i)]+	I	C f2(t,-gii Cot t)p(-gii Cot t)	) dt .
i=1 (g2j ):j=i Lg2i	o o ∖	g1i	sin2 t	).
The estimates (E.45) and (E.46) show, respectively, that f20 and f2 are absolutely integrable functions
of (V, g2). Because σ(g1i cos V - g1i cot Vsin V) = 0, we have (fortuitously)
f2 (t, -g1i cot t) = 0,
198
Published as a conference paper at ICLR 2021
so that there is no Dirac term in the derivative expression for Ξ2. An application of Fubini’s theorem
then allows us to re-combine the split integrals in the previous expression:
Ξ2(ν) = V" E[f2(0,g2i)<σ(gii)] + / ( E[f2(t,g2i)σ(gii cost + g2i Sint)] ) dt.
i=1 g2	0	g2
We have by linearity of the integral
n
X E [f2(0, g2i)σ(gii)]
i=1 g2
<v0, V oikvoW'dvok),
ψ(kvok)3
0,
where the last equality applied independence of g1 and g2, as in the zero-order term of Ξ1. Finally,
we apply linearity of the integral to move the summation over i back inside the remaining integrals,
obtaining
ξ ( ) =广(E I" hv0, Vtihvt, Vtiψ0(kvtk2) + hv0, Vtikvtk2ψ0(kvtk2)-
-2( ) = J0 IE [ψ(kv0k2)Ψ(Mk2)2Mk2 + Ψ(kv0k2)Ψ(kvtk2)2∣Mk2-
+ E "_ hv0, vtiψ0(kvtk2)kvtk2 _ 2 hv0, Vtihvt, V ti2ψ0 (IMk2) ^
+ E[	ψ(kV0k2)ψ(∣M k2)2	ψ(kV0k2)ψ(∣M ∣∣2)3∣Mk2 一
+ E L hV0, Vtihvt, V /2少(帕讨2 ) + hV0, Pthvt V /2少0(|心||2) ] ! dt
+ g2[ Ψ(kVθk2)Ψ(kVtk2)2kVtk2 + Ψ(kVθk2)Ψ(kVtk2)2kVtk2 V
Since f(ν, g1) = f(0, g1) + R0ν Eg2 [Ξ1(t)	Ξ2(t)] dt, the claim follows.
□
Lemma E.27. Let μ denote the distribution ofa N(0, (2/n)) random variable, and let P denote its
density. Let u ∈ R and u 6= 0, and let f : [0, π] × R → R satisfy:
1.	f is continuous in its second argument with its first argument fixed;
2.	f is absolutely continuous in its first argument with its second argument fixed, with a.e.
derivative f0;
3.	f and f0 are absolutely integrable with respect to the product of Lebesgue measure and μ
over [0, π] × R;
4.	There exist p ≥ 1 and C > 0 constants independent ofx such that |f (ν, x)| ≤ C |x|p
whenever |x| ≥ 1.
Consider the function
q(ν) = f f (ν,x)σ(u cos V + X sin V) dμ(x).
R
Then q is absolutely continuous, and the following first-order Taylor expansion holds:
q(ν) = q(0) + 厂(if©- "t t2 PLU "t t)
0	sin2 t
+ / f0(t,x)σ(ucost + xsint)
R
dt.
Proof. For m ∈ N, define
0
σm(x) = < mx
11
x≤0
0 ≤ x ≤ m-1
x ≥ m-1.
Then 0 ≤ σm ≤ 1; σm is continuous, hence Borel measurable; σm → σ pointwise as m → ∞; and
σm is differentiable on R except at X ∈ {0, m-1}, with derivative σm = m10≤χ≤m-ι. Moreover,
we have
/
R
m10≤x≤m-1 dx
1,
and the first-order Taylor expansion
σ m(x) = /	m1θ≤χθ≤m-ι
0
dx0.
199
Published as a conference paper at ICLR 2021
Define
qm(ν) =
R
f (ν, x)σm(u cos V + X Sin V) dμ(x).
Then at every ν ∈ [0, π], we have by assumption
f(ν,x)σm(Ucos V + xsin ν) | dμ(x) ≤ / |f (ν,x)∣ dμ(x) < +∞,
RR
so that the dominated convergence theorem implies
lim qm(V) = q(V).
m→∞
By the chain rule, the expression σm(x) = 一 max{-mmax{x, 0}, —1}, and Lemma E.21, V →
σm(u cos V + x sin V) is an absolutely continuous function of V ∈ [θ, ∏], and we therefore have by
the product rule for AC functions on an interval (Cohn, 2013, Corollary 6.3.9)
qm (V) = qm (0)
+ / dμ(x) / dt f0(t,x)σm(ucost + Xsint)
R0
+ mf (t, x)(x cos t - u sin t)10≤u cos ν+x sin ν≤m-1
We have
∣f0(t, x)σm(u cost + xsint)∣ dt dμ(x) ≤
∣f0(t,x)∣ dt dμ(x) < +∞,
by assumption, and
f (t, x)(x
R
1/2
by the growth assumption on f and the Schwarz inequality. Applying compactness of [0, π] and
the lack of V dependence in the final inequality above, an application of Fubini’s theorem therefore
yields
qm (V) = qm (0)
+	/ dμ(x)dt f0(t,x)σm(u cos t + X sin t)
0R
+ mf (t, x)(x cos t - u sin t)10≤u cos ν+x sin ν ≤m-1
By dominated convergence and the first of the preceding two product integrability checks, it is clear
lim / f f0(t,x)σm(ucost + Xsint)dμ(x)dt = / f f0(t,x)σ(ucost + Xsint)dμ(x)dt.
m→∞ 0 R	0 R
For the second term, we need to proceed more carefully. For k ∈ N sufficiently large for the integral
to be over a nonempty interval, we consider
qm,k (V)= I	dt I mf(t,X)(X cos t - U sin t) / e 2c2 10≤u cos t+x sin t≤m-1 dx,
k-1	R	2πc2
which is a truncated version of the integral constituting the second term in qm, with a change of
variables applied to explicitly show the density corresponding to μ, and where We write c2 = 2/n.
200
Published as a conference paper at ICLR 2021
In particular, by the calculation used to apply Fubini’s theorem in this context previously, we have
by dominated convergence
lim qm,k(ν)
k→∞
Z0νZR
mf (t, x)(x cos t -
u sin t)10≤u
cos t+x sin t≤m-1
dμ(x) dt.
By the product integrability assumption on f and Fubini’s theorem, we can consider the inner R-
integral for fixed t, and due to our truncation we have 0 < t < π; we therefore change variables
x 7→ x sin-1 t in the inner integral to get
qm,k(V)=Zk-ι	T f s⅛) (XSco⅛ -U) √⅛e
If 0 < t < π and x ∈ R, define

x coS t	1
g(t, x) = f (t, SinT) (XN -UJ √πc2e
X2
2c2 sin2 t 1θ≤u cos t+x≤m-ι dx.
χ2
2c2 sin2 t

so that, after an additional change of variables x 7→ x - U coS t, we obtain
ν-k-1
qm,k(ν) = m	dt	g(t,x - U coS t) 10≤x≤m-1 dx.
Using the growth estimate for f, we have
|X - U coSt|p|X coSt - U|
|g(t, X — U cost)| ≤ C--------sinp+21----------exp I 一
(x - u coS t)2
2c2 sin21
where C > 0 depends only on c. We are going to bound this quantity under the assumption that
|x| ≤ |u|/2, where We use the assumption |u| > 0. First, note that when n/4 ≤ t ≤ 3∏∕4, We have
Sin t ≥ 1/√2, and we always have Sin t ≤ 1 for 0 ≤ t ≤ π; Soin this regime
|g(t, X - U coS t)| ≤ C 2p/2+1 |X - U coS t|p|X coSt - U| exp -
(x - u coS t)2
2C2
which is a continuous function of (t, x), and is therefore bounded by a constant depending only on
c, f, U over the compact set [∏∕4,3∏∕4] X [-u∕2, u∕2]. Next, we consider the case 0 < t ≤ ∏∕4; by
the symmetry Sin(π - t) = Sin t, controlling |g(t, x - u coS t)| in this regime implies control ofit in
the regime 3π∕4 ≤ t < π. Here, we note that by our assumption on t and the triangle inequality
|X - U coS t| ≥ |U||coS t| - |X|
≥ ∣U∣(∣COSt| - 2) ≥ K|u|,
where we can take K = 2-1/2 - 2-1 > 0. Applying the triangle inequality and the condition on |X|
gives
ιg(t,χ - u cos t)| ≤ C(3∕2)p+ι snρ+⅛ exp (-2K⅛)，
which only depends on t. For any constants c0 , C0 > 0, the continuous map y 7→ C|y|p+2e-c0y2 is
a bounded function of y ∈ R by L'H6pitaTs rule applied to determine limy→±∞∣y∣pe-y = 0 for
any p > 0. It follows that there is a constant M ≥ 0 depending only on c, U, p such that |g(t, X -
U coS t)| ≤ M whenever 0 ≤ tπ∕4; we obtain the result for t = 0 by the previous limit calculation.
Applying symmetry and taking the sum of our two bounds then yields |g(t, X - U coS t)| ≤ M0 for
M0 ≥ 0 not depending on k, m whenever (t, X) ∈ [0, π] × [-U∕2, U∕2].
Now, we have after one additional change of variables X 7→ Xm-1
qm,k (ν)
ν-k-1
k-1
dt
L g(t
Xm-1 - U coSt 10≤x≤1 dX.
We can invoke our M0 bound when XmT ≤ ∣u∣∕2, and the indicator enforces |x| ≤ 1; thus, taking
m ≥ 2∕∣u∣ (here we use |u| > 0 critically) implies
ν-k-1
k-1
dt ∕∣g (t
R
Xm-1 - U coSt 10≤x≤1 dX ≤ M0	dt < +∞,
k-1
201
Published as a conference paper at ICLR 2021
so that by dominated convergence, we have
lim
k→∞
qm,k(V) = / 小t
xm-1 - ucost 10≤x≤1 dx.
By the same estimate together with second-argument continuity of f, hence of g, we have by the
dominated convergence theorem
lim
m→∞
lim
k→∞
qm,k (ν)
ν	ν f (t, -u cot t)	1
/ g也-U Cos t)dt = -U / —嬴η — √2∏c2
Combining with our results on qm and the first term, we conclude
q(ν) = q(0)
「(f (t,-u Cot t)	1
+ 0o	( U	sin21	√2ΠC2 e
as claimed.

u2 cot2 t
-2C2-
+ f f0(t,x)σ(u cos t + X Sin t)
R
□
E.3.6 Miscellaneous Analytical Results
Lemma E.28. If m > 0, then @ is 1 -Lipschitz.
Proof. We recall
O(V) =	E	[cos-1 Xν].
gι ,g2~i.i.d.N(0,(2∕n)I)
Considering instead the related function 0 defined by
O(ν )=	E	[1ei φ(ν, gι, g2)],
gι ,g2~i.i.d.N(0,(2∕n)I)
where
-1	hv0 , vνi
φ(ν, gι, g2) = cos	∙π_EI-π-,
kv0 k2kvνk2
we notice
0(V) = 0(V) + (π∕2)μ(Ec)∙
It is therefore equivalent to show that 0 is I-LiPschitz; but this follows from Lemma E.22.	□
Lemma E.29 (Even Moments). If k ∈ N and k ≤ n, one has
∣E[kvνk2k] - 1∣ ≤ Ckn-1,	∣E[kVνk2k] - 1∣ ≤ Ckn-1,
where Ck ≤ (k - 1)24k-1(2k - 1)!!.
Proof. First notice that the claim is immediate if k = 1, since E kvν k22 = 1. We therefore Proceed
assuming k > 1. Also notice that Lemmas G.11 and E.17 show that VV and VV have matching even
moments, so it suffices to Prove the claim for vν. By rotational invariance, we can write
k
E[kvνk2k] = n
E
gi 〜N (0,1)
kk
⅛ X E∣Y σ(gij )2 ,
1≤i1,...,ik≤n	j=1
where the last sum is taken over all elements of [n]k. We sPlit this sum into a sum over terms whose
exPectations contain no rePeated indices, and a sum over all other terms. There are exactly k! nk
ways to choose a k-multi-index from an alPhabet of size n without rePetitions—select the k distinct
202
Published as a conference paper at ICLR 2021
indices, then arrange them in every possible way—and multi-indices without repetitions correspond
to terms in the sum where the expectation factors completely, by independence, so we can write
k
E[kvνk2k] = n
(
k!(n)E[σ(gJ]k + X E
' ,	1≤iι,…,ik≤n
only repeated indices
∖
/
k
Y σ(gij )2
j=1
We will prove the elementary estimate
nk - k! n ≤ (k - 1)2nk-12k-2.	(E.47)
Assuming it for the time being, we use that Eσ(g1)2k = 2-k to conclude
(2∕n)kk(n)E[σ(gι)2] k - 1 ≤ (k - 1)22k-2n-1.
Next we study the expectation-of-products arising in the sum. The expectation factors over distinct
indices; we can classify repeated indices in a multi-index by partitions j1 +. . . jm = k, where each jl
is a positive integer. Formally, for each multi-index (i1, . . . , ik), there is a partition j1 + . . . jm = k
such that
km
E Y σ(gij)2 = YEσ(gip(l))2jl],
j=1	l=1
where p : [m] → [k] is injective. We can evaluate these expectations using the result E σ(g1)2k =
2(2k - 1)!!, because the coordinates of g are i.i.d.:
m
YEσ(gip(l))2jl]
l=1
m
2m Y⑵i- 1)!!.
i=1
We claim that
1m	1
2m Y⑵i-1)!! ≤ 2(2k -1)!!，
i=1
which is the expectation obtained from a term with all indices equal, whence
(E.48)
kk
n X E Y σ(gij)
1≤i1,...,ik ≤n j=1
only repeated indices
≤ nknk-1(k - 1)22k-2E[σ(gι)2k]
=((k - 1)222k-3(2k - 1)!!)n-1
by (E.47), which gives a bound on the number of terms in the sum. Noticing that this constant is
larger than (k - 1)22k-2, we can conclude the claimed estimate on Ck provided we can justify
(E.48). For this, it suffices to show
I ≤ 2m-ι	(2k - 1)!!
1 ≤ 2	Qi=ι(2ji - 1)!!.
Observe that m ≥ 1 for any partition, so 2m-1 ≥ 1 and we need only study the second term on the
righthand side. We write this term as
(2k -1)!!	=	Qk=ι(2i-1)
Qi=ι(2ji-1)!!	Qi=I Qj= ι(2l -1).
The fact that jι T-+ jm = k implies that there are k factors in the denominator, so We can PUt the
factors in the numerator and denominator into one-to-one correspondence. Consider the ordering of
the factors in the denominator (Qlj=1 1(2l - 1)) . . . (Qlj=m1(2l - 1)). Then
k
Qk=ι(2i- 1)
Qj= ι(2i - 1)
(2i - 1).
i=j1 +1
203
Published as a conference paper at ICLR 2021
Ifj1 = k, then this product is empty and m = 1, so the claim is established. If not, then we proceed
to the next group of factors in the denominator: we get
Qk=ji+ι(2i- 1) ≥ 1
Qj= ι(2i- 1) 一 ,
because j1 > 0 implies that every term in the numerator (ordered in ascending order) is larger than
the corresponding term in the denominator. This gives the claim in the case m = 2; for m > 2, we
conclude the claim by induction.
To close the loop, we prove (E.47). Using simple algebra, we observe
nk - k! n = nk - n(n - 1) . . . (n - k + 1)
and we note bounds
≤ 1.
Working on the upper bound first, we obtain with the help of the binomial theorem
1 -匕 YT
n
=X (k-1)(-1，)j
< k - 1 XX (k - I) (k - 1 )j
≤ ~n~ j=o υ + 1J (丁),
where the last expression removes cancellation by making each term in the sum nonnegative, then
applies a change of index. With the identity kj+-11 = (k - 1)/(j + 1) k-j 2 , we proceed as
k - 1 XX (k - I) (k - 1 )j_ (k - 1)2 XX (k - 2λ 1 (k - 1 Y
n j=0 V + 1√ I n ) - n	j=0 I j j++ 1 I n )
(k - 1)2 XX (k - 2) ( k - 1 Y
n j=0 k j 八 n )
(k - 1)2 (I + k-1 )k-2
n ∖ n ),
given that 1/(j + 1) ≤ 1. Since n≥ k, this gives
nk - k!(n) ≤ (k - 1)2nk-12k-2.
The upper bound on the product gives immediately nk - k! nk ≥ 0, which completes the proof.
□
Lemma E.30 (Mixed Moments). Let g1, . . . , gn denote the n (i.i.d. according to N (0, (2/n)I2))
rows of the matrix G. Let k ∈ [n], and for each 1 ≤ j ≤ k let fj : R2 → R be a function such that
1.	E[|fj(g1)|p]1/p ≤ Cn-1 p, with C > 0 an absolute constant and p ≥ 1;
2.	E|fj(g1)| ≤ n-1.
204
Published as a conference paper at ICLR 2021
Consider the quantities
k / n	∖ 1	k
a = En X fj (gi) I; B = nkγ Efj (g1)].
/=1 %=ι	/ _|	j=ι
Then one has ∖A — B| ≤ Cn-1, with the COnStant depending only on k.
Proof. Start by writing
k
a = X E n f (gj)
1≤iι,…,ik ≤n j = 1
kk
=k! n nEfj(g1)]+ X E nfj(gij)
' j j = 1	1≤iι,…,ik ≤n	j=1
only repeated indices	,
n-kk!	n B + X E
' 1	1≤iι,…,ik≤n
only repeated indices
k
n f (gj)
j=1
as in Lemma E.29. Applying the triangle inequality and the first moment assumption on the func-
tions fj , we get
n-kk!
|B|
—1
≤ (k — 1)22k-2n-1,
with the last inequality following from the estimate (E.47). For the remaining term, We have by the
triangle inequality
k
X E n fj (gj
1≤iι,…,ik ≤n	j=1
only repeated indices
≤ nk — k! (n)	sup E
∖k∕	(iι,…,ik)⊂[n]k
k
n f (gj)
j=1
≤ (k — ι)2nk-12k-2	sup E
(iι,---,ik )⊂[n]k
k
n fj (gj
j=1
using again (E.47) to control the number of terms in the sum. To control the supremum, we apply
the Schwarz inequality k — 1 times to get
E
ɪ! fj (gij )I I ≤ Ef1(gi1 )2]1/2 E
k
n fj (gj
j=2
1/2
≤...
(k-1 r	ι2-j∖	r	-∣ 2-(k-1)
∏ Efj (gij 产]I Efk (gik 产1]
By the subexponential assumption on the functions fj , we have moment growth control, and we
therefore have a bound
E
ɪ! fj(gij[ J ≤ (UCInT2j) Cm-12k-1
=Ck n-k2(kT)+Pk-L j = Ck n-k 2 j(k-1)(k+2)
205
Published as a conference paper at ICLR 2021
and consequently
k
X E Y fj (gij)
1≤i1,...,ik≤n	j=1
only repeated indices
≤ Ck(k -1)221 k(k+3)n-1,
which proves the claim.
□
Lemma E.31. For any 0 < c ≤ 1 ,there exists a smooth function ψc : R → R satisfying
1.	ψc(x) = x ifx ≥ 2c and ψc(x) = c ifx ≤ c, and ψc is between c and 2c ifc ≤ x ≤ 2c;
2.	ψc(x) ≥ 1X;
3.	There are constants Mι,M2 > 0 depending only on C such that ∣ΨC| ≤ Mi and ∣ΨC0∣ ≤ M2.
1
Proof. The function f (x) = 1χ>0e-X is smooth on R, and satisfies 0 ≤ f ≤ 1 and f = 0 if X ≤ 0.
The function
rk f f	f (X)
φc(x) = f (X) + f (c - x)
is therefore smooth, satisfies 0 ≤ φc ≤ 1, and satisfies φc(X) = 0 if X ≤ 0 and φc(X) = 1 ifX ≥ c.
Simplifying using the definitions, we can write
O,,)=L
X≤0
0<X<c
X ≥ c.
It follows that X 7→ Xφc(X) is zero when X ≤ 0, X when X ≥ c, and in between otherwise. Thus, the
function ψc(X) = c + (X - c)φc(X - c) satisfies property 1.
For property 2, we note that ψc(X) = c+ (X - c)φc(X - c) implies that ψc ≥ c, since φc(X - c) = 0
whenever X ≤ C and φc ≥ 0. Since ψc(χ) = X when X ≥ 2c, We can then conclude ψc(χ) ≥ 11 x,
since 1 X ≤ C when X ≤ 2c and 1 X ≤ X when X ≥ 2c.
For property 3, we note that by property 1, ψc0 (X) = 1 if X ≥ 2c and ψc0 (X) = 0 if X ≤ 0;
consequently ψc00(X) = 0 if X 6∈ [0, 2c], and it suffices to control ψc0 and ψc00 in this region. By
translation equivariance of the derivative, it then suffices to control the derivatives of h(X)
for 0 < X < c. We calculate
Xφc(X)
and
φ0c(X)
φ0c0(X)
h0(X) = Xφ0c(X) + φc(X),
h00(X) = Xφ0c0(X) + 2φc(X),
f(c - X)f0(X) - f(X)f0(c - X)
(f(X) + f(c - X))2
(f (X) +f(c-X)) (f(c - X)f00(X) + f(X)f00(c - X) - 2f0(X)f0(c - X))
-2
(f(X) + f(C - X))3
(f0(X) - f0(C - X))(f(C - X)f0(X) - f(X)f0(C - X))
(f(X) + f(c - X))3
(E.49)
(E.50)
(E.51)
Completely ignoring possible cancellation, we see that it suffices to get a lower bound on f(X) +
f(c - X) and upper bounds on f0 and f00 to bound |h0| and |h00|. We calculate
、	1 I .
f (X) + f (C - X) = X1e X 1χ>0 -
1
(c — x)2
1
e- c-x 1χ<c,
and since f(X) > 0 if X > 0 and C > 0, we see that any solution of f0(X) - f0(C - X) = 0 must
occur for X ∈ (0, C), which implies as well C - X ∈ (0, C). Writing g(X) = X2e-x and using
CT < XT < ∞ for x ∈ (0, c), we note from our previous work that f 0(x) — f0(c — x) = 0 ^⇒
206
Published as a conference paper at ICLR 2021
g(x-1) = g((c - x)-1). We calculate g0(x) = xe-x(2 - x), so that if x > 2 then g0 (x) < 0, which
implies that g is injective on (2, ∞). By assumption, we have c-1 > 2; consequently there is at
most one solution to f0(x) - f(c - x) = 0 in 0 < x < c, and given that X = 1C is a solution, there
is exactly one solution. We check
2f (c/2) < f (0)+ f(c) O log2 < 1/c,
where the first RHS is the value of f(x) + f(c - x) at both x = 0 and x = c, and since 1/c ≥ 2, we
conclude that f(x) + f(c - x) ≥ 2f (c/2) > 0. Next, we use
f O(X) = ~e e X 1x>0,
x2
f00(x)
(X4e-1
-4 e-1
x3
1x>0,
together with the bound xpe-x ≤ ppe-p forp > 0, which is proved by differentiating x 7→ xpe-x,
equating to zero, and comparing the values of the function at x = 0, x = p, and x → ∞, to obtain
with the triangle inequality
∣f0(x)∣ ≤ 4/e2,	∣f00(x)∣ ≤ 44e-4 + 2 ∙ 33e-3.
Combining these bounds with our lower bound on f(x) + f(c - x) and repeatedly applying the
triangle inequality and modulus bounds in (E.50) and (E.51), then subsequently in (E.49) (using
also |x| ≤ c), we conclude the claimed bounds on ∣ΦC∣ and ∣ΦC0∣.	□
LemmaE.32. Let Z,Z ∈ L2 be square-integrable random variables. Suppose that Z ≤ C a.s. and
∣∣Z — Z∣∣l2 ≤ M. Then
Var[Z] ≤ Var[Z] + CM + M2.
Proof. This is a simple consequence of the triangle inequality and the centering inequality for the
L2 norm. We have
IIZ - E[Z]I∣L2 ≤ IlZ - Z - E[Z - Z]kL2 + IlZ - E[z]l∣L2,
and additionally
∣Z - Z - E[Z - Z]∣L2 ≤∣Z - Z∣L2 ≤ M,
so that, after squaring, we get
Var[Z] ≤ Var[Z]+ M∣Z - E[Z]∣∣l2 + M2
≤ Var[Z]+ M∣∣Z∣∣L2 + M2
≤ Var[Z]+ CM + M2,
by centering and the a.s. boundedness assumption.	□
Lemma E.33. Let X, Y be square-integrable random variables, and let d > 0. Suppose |X | ≤ M1
a.s., and suppose P[|Y — 1| ≥ CPd/n] ≤ C0e-cd and ∣∣Y — 1∣L2 ≤ M2. Then one has with
probability at least 1 - C0e-cd
|XY - E[XY]| ≤ |X - EX]| + 2CM1 色 + √C0M1M2e-cd/2.
Proof. We apply the triangle inequality:
|XY -E[XY]| ≤ |XY -X| + |X -E[X]| + |E[X] -E[XY]|
≤ M1|Y - 1| + M1E[|Y - 1|] + |X - E[X]|,
where the second inequality also applies Jensen’s inequality. We have
E[|Y - 1|] = Eh(1∣Y-ι∣≥c√dn-1 + 1∣γ-ι∣<c√d∕n) IY - 1|i
≤ C r/n + Eh1∣γ-ι∣≥c√d∕nlY - 11i
≤ C /d + Ehl∣γτ≥c√∕ni1/2Eh(Y - 1)2i1/2
≤ CJd + √C0e-cd/2M2,
207
Published as a conference paper at ICLR 2021
where we apply the Schwarz inequality in the third line. Consequently, with probability at least
1 — C0e-cd, we have
|XY — E[XY]| ≤∣X — E[X]| + 2CM1y / + √C0M1M2e-cd/2,
as claimed.
□
Lemma E.34. For i = 1,...,n, let Xi,匕 be random variables in L4, and let d > 0 and δ >
0. Suppose Xi ≥ 0 for each i and En=IkXikL2 ≤ M ,and suppose P [Vi ∈ [n], ∣ 匕—1∣ ≥
C，d/n] ≤ δ and for each i, ∣∣Yi — 1∣∣l4 ≤ M2. Moreover, suppose that Cydln ≤ 1. Then one
has with probability at least 1 — δ
n
X XiYi — E[XZ]
i=1
n
≤ 2 X Xi — E[Xi]
i=1
+ 2CM3
J++δ1∕4M2M3.
n
Proof. The proof is a minor elaboration on Lemma E.33. We apply the triangle inequality:
n
X XiYi — E[XiYi]
i=1
n	I	I n
X XiYi — Xi I + I X Xi- E[Xi]
i=1	I	I i=1
n
+ X E[Xi] — E[XiK]
i=1
≤
n + X E[∣Xi∣∣K — 1∣] +
i=1
where the second line holds with probability at least 1 — δ.
inequality together with nonnegativity of the Xi gives
n
X∣Xi∣
i=1
n
X Xi
i=1
n
≤ X Xi — E[Xi]
i=1
n
X Xi — E[Xi]
i=1
Another application of the triangle
n
+ X E[Xi]
i=1
n
≤ M3 + X Xi — E[Xi]
i=1
where the second line applies the Lyapunov inequality. By the Schwarz inequality and the Lyapunov
inequality, we have
n	Γ~7 n	n
XE[∣Xi∣∣匕-1∣] ≤ cV-XE[∣Xi∣] + XE[1∣…>。√d/n∣χi∣∣匕—1∣]
i=1	i=1	i=1
≤ CM3
-++δv4M2M3.
V n
Consequently, with probability at least 1 — δ, we have
n
X XiK - E[Xi 匕]
i=1
n
≤ 2 X Xi - E[Xi]
i=1
+ 2CM3
ʌ/-+δv4M2M3
V n
as claimed, where we use that C ʌ/d/n ≤ 1 here.
□
Lemma E.35. Let k ∈ N, and let Xi,..., Xk be integrable random variables satisfying ∣Xi 一
E[Xi]kL4 ≤ Mi for some constants Mi > 0. Suppose moreover that with probability at least 1 — δi,
one has ∣Xi — E[Xi]∣ ≤ Ni for some constants Ni > 0. Then one has
一 k
Var X Xi
i=i
k
≤〉： NiNj + p∕δi + δj Mi Mj.
ij = 1
208
Published as a conference paper at ICLR 2021
Proof. We start from the formula
k
n
Var	Xi
i=1
Var[Xi] +2	cov[Xi, Xj],
i<j
where cov[Xi,Xj] = E[XiXj] - E[Xi]E[Xj] = E[(Xi - E[Xi])(Xj - E[Xj])]; one establishes
this formula by distributing in the definition of the variance. By assumption, there are events Ei on
which |Xi - E[Xi]| ≤ Ni and such that P[Ei] ≥ 1 - δi . Partitioning the expectation, we therefore
have
Var[Xi] = E[(Xi - E[Xi])2] ≤ Ni2+E[1Eic(Xi-E[Xi])2]
≤ Ni2+E[1Eic]1/2E[(Xi -E[Xi])4]1/2
≤ Ni2 + pδiMi2,
where the first line uses nonnegativity of the integrand to discard the indicator after applying the
deviations bound, the second line applies the Schwarz inequality, and the third line uses fourth
moment control. For the covariance terms, we apply Jensen’s inequality to obtain
|cov[Xi,Xj]| = |E[XiXj] -E[Xi]E[Xj]| ≤ E[|Xi - E[Xi]||Xj -E[Xj]|],
so that, again partitioning the outermost expectation and applying our assumptions, we get
|cov[Xi, Xj]| ≤ Ni2 + E[1Eic∪Ejc |Xi - E[Xi]||Xj -E[Xj]|]
≤ Ni + E[1ec∪ec]1/2E[(Xi - EXi])4]1/4E[(Xj - E[Xj])4]1/4
≤ NiNj + ∖/ + + δjMiMj,
where in the first line we again use nonnegativity of the integrand to discard the indicator after
applying the deviations bound, in the second line we apply the Schwarz inequality twice, and in the
third line we use a union bound to control the indicator. Since δi ≤ 2δi , we conclude the claimed
expression.
Lemma E.36. If C > 0 and p > 0, the function g(t) = tpe-Ct2 for t ≥ 0 satisfies the bound
g(t) ≤ (p/(2Ce))p/2.
Proof. The function g is smooth has derivatives g0(t) = tp-1e-Ct2 (p - 2Ct2) and g00 (t) =
tp-2e-Ct2 (p(p - 1) - 2(4p - 1)Ct2 + 4C2t4). It therefore has at most two critical points, one
possibly at t = 0 and one at t =，p/(2C), and these points are distinct when p > 0 and C > 0. We
check the sign of g" at the second critical point; since，p/(2C) > 0 we need only check the value
of (P(P - 1) - 2(4p - 1)Ct2 + 4C2t4) evaluated at t = 'p∕(2C), which is -2p2 < 0. Then since
limt→土∞ g(t) = 0 and g(0) = 0, We conclude that g(t) ≤ g(,p∕(2C)), which gives the claimed
bound.	□
Lemma E.37. Following Lemma E.26, consider the random variables
σ(g1i)3ρ(-g1i cot s)
ψ(kv0k2)ψ(kvi∣∣2)sin3 S
Ξ2(ν, g1, g2)
hv0, vsiψ0(∣vs∣2)∣vs∣2
Ξ3(ν, g1, g2)
ψ(∣v0∣2)ψ(∣vs∣2)2	ψ(∣v0∣2)ψ(∣vs∣2)
hv0, Vsihvs, Vsi2ψ00(kvsk2)
Ξ4(ν, g1, g2) = -2
Ξ5(ν, g1, g2)
ψ(Iv0k2)ψ(IIvsk2)2kvsk2
( hvo, Vsihvs, Vsiψ0(kvsl∣2)
jψ(kv0k2)ψ(kvs k2)2kvsk2
hv0, VsikVsk2ψ0(IVsk2)
Ξ6(ν, g1, g2) = 2
ψ(kV0k2)ψ(kVsk2)2kVsk2
(V0, VsihVs, V si2ψ0(kVsk2)
(V0, VsihVs, Vsi2ψ0(kVsk2)
ψ(Wθk2)ψ(IIVs k2)3kVsk2
ψ(kV0k2)Ψ(kVsk2)2kVsk3 ,
+
209
Published as a conference paper at ICLR 2021
where Ξι( ∙, gι, g2) is defined at {0,∏} by continuity (following the proof of Lemma E.27, it is 0
here). Then for each i = 1, . . . , 6, one has:
1.	For each i, there isa μ0μ-integrablefUnction f : Rn XRn → R such that ∣Ξi(∙, gι, g2)一
E[Ξi( ∙, gι, g2)]∣ ≤ fi(gι, g2);
2.	There is an absolute constant Ci > 0 such that for every 0 ≤ ν ≤ π, one has kfi kL4 ≤ Ci,
so that in particular ∣∣Ξi(ν, ∙, ∙) — E[Ξi (ν, ∙, ∙ )]∣∣l4 ≤ Ci.
Proof. First we reduce to noncentered fourth moment calculations. If X is a random variable with
finite fourth moment, we have by Minkowski’s inequality
∣X - E[X]∣L4 ≤∣X∣L4 + |E[X]|,
so that the triangle inequality for the expectation and the Lyapunov inequality imply
∣X - E[X]∣L4 ≤ 2∣X∣L4 .
We can therefore control the noncentered fourth moments of the random variables Ξi and pay only
an extra factor of 2 in controlling the centered moments. For the proofs of property 1, we have
similarly |X - E[X]| ≤ |X| + E[|X|] from the triangle inequality, so that it again suffices to prove
property 1 for the noncentered random variables
∣Ξi∣.
Ξ1 control. If ν = 0 or ν = π, the integrand is identically zero; we proceed assuming 0 < ν < π .
Using ψ ≥ 4, we have
0 ≤ Ξ1(ν,g1,g2) ≤
n
16X
i=1
σ(g1i)3ρ(-g1i cot ν)
sin3 ν
For property 1, by elementary properties of cos We have for 0 ≤ V ≤ π∕4 and 3π∕4 ≤ V ≤ π that
cos2 V ≥ 2, so
ρ(-g1icotV) ≤
This gives
σ(gn 平 p(-gii Cot V) ≤ |gii|3P(-gii Cot V) = 2K K1/2I gii I3e-K∣sτniν∣2
sin3 V	—	sin3 V	Vn I Sin VI	,
where we define K = n∕8. By Lemma E.36, we have that g ≤ g(√3∕2K) = CK-3/2, where
C > 0 is an absolute constant. We conclude
σ(gii)3P(-gii Cot V) . nj	m °、
--------sin3 V------- ≤ C∕n,	(E.52)
provided V is not in [π∕4,3π∕4]. On the other hand, if π∕4 ≤ V ≤ 3π∕4, we have sin V ≥ 1/√2, so
that
σ(g1i)3ρ(-g1i Cot V) ≤ C√nσ(gii)3,	(E.53)
sin V
where C > 0 is an absolute constant. Since these V constraints cover [0, π], we have for all V and
all g1 (by the triangle inequality)
∣Ξi(v,gι,g2)∣ ≤ C + C0n3/2b(gii)3,
where C, C0 > 0 are absolute constants, and by Lemma G.11, we have
E[C + C 0n3∕2σ(gii )3] = C + C00,
where C00 > 0 is an absolute constant. This proves property 1 with f1(g1, g2) = C+C 0n3∕2σ(gii)3,
with different absolute constants, and property 2 follows from Lemma G.11 after applying the
Minkowski inequality and calculating the integral, which has the necessary cancellation of the n3/2
factor.
210
Published as a conference paper at ICLR 2021
Ξ2 control. By Lemma E.31, We have ∣ψ0∣ ≤ C for an absolute constant C > 0 and χ∕ψ(χ) ≤ 2.
Cauchy-Schwarz then implies
hvo, Vsiψ0(kVsk2)kVsk2
ψ(Mk2泗kvsk2)2
In an exactly analogous manner, We have
hv0, Vsi
ψ(kv0k2)ψ(kvsk2)
≤ 8C.
≤ 4.
Both bounds satisfy the requirements of property 1, With f2 (g1, g2) = 16C + 8. The triangle
inequality and Minkowski,s inequality then implies ∣∣Ξ1(ν, ∙, ∙ )||工4 ≤ C0.
Ξ3 control. By Lemma E.31, we have ∣ψ00∣ ≤ C for an absolute constant C > 0, ψ ≥ ɪ, and
x∕ψ(x) ≤ 2. Cauchy-Schwarz then implies
hv0, vsihvs, Vsi2ψ00(kvsk2)
ψ(kv0k2)ψ(kvsk2)2kvsk2
≤ 16CkV sk2,
and the triangle inequality gives ∣Vs∣2 ≤ ∣∣gι∣2 + ∣∣g2∣2 + 2kgι∣2∣g2∣2, whose expectation is
bounded by 4, by the Schwarz inequality and Lemma G.11. We can therefore take f3(g1, g2) =
C+ C0(∣g1∣2 + ∣g2∣2)2, and we have
(∣g1∣2 + ∣g2∣2)2L4 = ∣∣g1∣2 + ∣g2∣2∣2L8 ≤(∣∣g1∣2∣L8+∣∣g2∣2∣L8)2 ≤C,
where C > 0 is a (new) absolute constant, by the Minkowski inequality and lemmas Lemmas G.10
and G.11. This establishes property 2.
Ξ4 control. By Lemma E.31, we have ∣ψ0∣ ≤ C for an absolute constant C > 0, ψ ≥ 1, and
x∕ψ(x) ≤ 2; Cauchy-Schwarz then implies
2 hvo, Vsihvs, Vsiψ0(kvsk2)
ψ(kv0k2)ψ(kvsk2)2kvsk2
≤ 64CkVs∣2.
Following the argument for Ξ3 exactly, we conclude property 1 and 2 from this bound with a suitable
modification of the constant.
Ξ5 control. We have
hV0, VsikV slB^dWsl^
MIV0k2W(kVsk2)2kVsk2
≤ 32CkVsk2,
following exactly the setup and instantiations in the argument for Ξ4. Following the argument for Ξ3
exactly, we conclude property 1 and 2 from this bound with a suitable modification of the constant.
Ξ6 control. The triangle inequality gives
∣Ξ6(s, gl, g2)| ≤ 2
(V0, VsihVs, V si2ψ0(kVsk2)
他(kV0k2W(kVs l|2)3kVsk2
(V0, VsihVs, Vsi2ψ0(kVsk2)
ψ(kV0 k2)Ψ(kVsk2)2kVsk2
+
and following the setup of Ξ4 and Ξ5 control gives ∣Ξe(ν,gι,g2)| ≤ 128CkVνk2 +32CkVν∣∣2∙
Following the argument for Ξ3 exactly, we conclude property 1 and 2 from this bound with a suitable
modification of the constant.	□
Lemma E.38. In the notation of Lemma E.13, there are absolute constants c, c0, C > 0 and an
absolute constant K > 0 such that if n ≥ K , there is an event with probability at least 1 - 2e-cn
on which one has
kVok2	_ E Γ kVok2 .
ψ(kV0k2)2	[ψ(kV0k2)2.
≤ Ce-c n
Proof. There is no ν dependence in this term, so we need only prove a single bound. Following
the proof of the measure bound in Lemma E.16, but using only the pointwise concentration result,
we assert that if n ≥ C an absolute constant there is an event E on which 0.5 ≤ kV0k2 ≤ 2 with
probability at least 1 - 2e-cn with c > 0 an absolute constant. This implies that ifg1 ∈ E we have
1,
Ψ(kV0k2)2
211
Published as a conference paper at ICLR 2021
which we can use together with nonnegativity of the integrand to calculate
E
kv0 k22
ψ(kv0k2)2
E[1E] +E 1Ec
≥ E[1E] ≥ 1 - 2e
(Mk2 A2
U(kvθk2)7
-cn
whence
kv0k2
ψ(kv0k2)2
-E
kv0k22
. ≤ 2e
[Ψ(kv0k2)" 一
-cn
whenever g1 ∈ E . Similarly, we calculate
E
kv0 k22
ψ(kv0k2)2
E[1E] + E 1Ec
IW0k2 Y
Ψ(M k2)7
≤ 1 + E[1Ec]1/2E
Mk2 ;
Ψ(kvθk2)7
1/2
≤ 1 + 16Ce-cn
applying the Schwarz inequality, property 2 in Lemma E.31, and the measure bound on E, with
c0 , C0 > 0 absolute constants, whence
E
kv0k22
ψ(kv0k2)2
「≤ 16C-
—
whenever g1 ∈ E . Worst-casing constants, we conclude
kvok2 b
--------——IE
Ψ(kvθk2)2
kv0k22
ψ(kv0k2)2
≤ Ce-cn
when g1 ∈ E , which is sufficient for our purposes.
□
Lemma E.39. In the notation of Lemma E.13, if d ≥ 1, there are absolute constants
c, c0 , c00 , c000 , C, C0, C00 , C000 , C 0000 > 0 and absolute constants K, K0 > 0 such that if n ≥
Kd4 log4 n and d ≥ K0, there is an event with probability at least 1 - C 000 n-c00 d/2 - C0000ne-c000n
on which one has
1ξI(V, g1, g2) - e[ξI(V, g1, g2)]| ≤ C∖ ----+ C0n-cd + C"ne-c n
n
Proof. If ν ∈ {0, π}, then Ξ1(ν, g1, g2) = 0 for every (g1, g2); we therefore assume 0 < ν < π
below.
We will apply Lemma E.34 to begin, with the instantiations
Xi
σ(g1i)3ρ(-g1i cot ν)
sin3 ν
Yi
ψ(kv0k2)ψ(kvνi k2),
1
since then Ξ1 (ν, g1, g2) = Pi XiYi. We have Xi ≥ 0; writing k2 = 2/n, we calculate
E[Xi] = √8πk2;
2
=——Sin V
πn
i 熹;eχp (-2k2 总A dg
R Sin V	2 Sin V
(E.54)
212
Published as a conference paper at ICLR 2021
where the second line uses the change of variables g 7→ g sin ν and Lemma G.11. Additionally, we
have
E[Xi2] = k∏ √1π L sin6νexp (-2 g2(1+2cot2 V))dg
k4 sin ν 1	6	1 2	2
k √2∏ L g exp 卜 2g (1 + cos V ))dg
k4 sin v 1
4π(1 + cos2 v)7/2 √2π
15sinV
πn2(1 + cos2 v)7/2
g6e-g2/2
R
dg
(E.55)
where in the second line We change variables g → g sin v, in the third line We change variables
g → g/√1 + cos2 v, and in the fourth line we use Lemma G.11. We can calculate the derivative
of the map g(v) = (1 + cos2 v)-7/2 sinv as g0(v) = cos(v)(1 + cos2 v)-7 [(1 + cos2 v)7/2 +
7 sin2(v)(1 + cos2 v)5/2], which evidently has the same sign as cos(v); so g is strictly increasing
below n/2 and strictly decreasing above it, and is therefore maximized at g(∏∕2). We conclude the
bound
E[Xi2] ≤ —2 ,
πn2
(E.56)
which shows that ikXikL2 = O(1). Next, we have Yi ≤ 16 by Lemma E.31, soby the Minkowski
inequality kYi- 1kL4 ≤ 17 for each i, and it remains to control deviations. We consider the event
E = E0.5,1 in the notation of Lemma E.16, which has probability at least 1- Cne-cn and on which
we have 2 ≤ kvνk2 ≤ 2 for all i ∈ [n] and in particular ɪ ≤ ∣∣v0k2, and thus by LemmaE.31
for all i ∈
Yi =------1-----
i	kv0k2kvν∣2
[n]. By Taylor expansion with Lagrange remainder of the smooth function x 7→ x-1 on
the domain x > 0 about the point 1, we have
1
x
1 - (X - I) + 73(X - I)2,
where ξ lies between 1 and x. If (g1 , g2) ∈ E, then for all i ∣v0∣32∣vνi ∣32 ≥ (1/64), and we can
therefore assert
(∣∣V0 ∣2∣vV ∣2 - 1) - 64 (kv0k2∣* ∣2 - 1)2 ≤ 1 - Yi ≤ (kv0k2kvV ∣2 - 1) .	(E.57)
By Gauss-Lipschitz concentration, we have P[∣∣∣v0k2 - E[kv0k2]∣ ≥ t] ≤ 2e-cnt2 and P[∣∣v0∣2 -
E[∣WVl∣2]| ≥ t] ≤ 2e-cnt2. LemmaE.19 implies that 1 - 2∕(n- 1) ≤ E[∣vV∣2] ≤ 1 and 1 - 2/n ≤
E[∣v0∣2] ≤ 1, so we can conclude when n ≥ d and when n is larger than a constant that
∣∣∣v0∣∣2 -	1l≤ Cyn;	∀i	∈	[n],	∣kvVl∣2 - 1∣ ≤	C∖∣n
with probability at least 1 - C0ne-d, by a union bound. Using then the fact that ∣vνil2≤2 for all
i on the event E together with the previous estimates and (E.57), we obtain with probability at least
1 - C 00 ne-cn - C 000 ne-d (via a union bound with the measure ofE) that for all i,
C rd - C0 d ≤ 1 - Yi ≤ C rd.
nn	n
As long as n ≥ d, we conclude that with the same probability, for all i we have |Yi - 1| ≤ C ,d∕n.
We can therefore apply Lemma E.34 to get that with probability at least 1 - C00ne-cn - C000ne-d
we have
∣ n σ(g1i)3ρ(-g1icotv)	σ(g1i)3ρ(-g1icotv) ∣
∣ξi(v,gι,g2) - E[Ξ1(v,gι,g2)]∣ ≤ 2 工----------F--------------E ---------F----------
i=1
+ CJ- + (C 00)1∕4ne-cn∕4 + (C000) 1/4 ne-d∕4,	(E.58)
n
213
Published as a conference paper at ICLR 2021
where we also used the triangle inequality for the `4 norm to simplify the fourth root term, together
with n ≥ 1. For ν ∈ [0, π], we define fν : R → R by
fν(g)
σ(g)
√2πk sin3 V
exp
so that the task that remains is to control | i fν(g1i)- E[fν (g1i)]|. We start by applying
Lemma E.36 to obtain an estimate
C
V g - n∣cos ν∣3,
where C > 0 is an absolute constant. When 0 ≤ V ≤ n/4 or 3∏∕4 ≤ V ≤ ∏, we have therefore
fν(g) ≤ C/n. Meanwhile, if π∕4 ≤ V ≤ 3π∕4, we have f (g) ≤ C0√nσ(g)3, so we can conclude
fν(g) ≤ C/n + C0√nσ(g)3 for all V, which shows that f (g) is not much larger than C0√nσ(g)3.
Next, let g 〜N(0,1), so that g == kg; we have for any t ≥ 0
P [C0√nσ(g)3 ≥ t] = p[σ(g) ≥ C00 (nt)1/3i ≤ exp (-2 (C00)2 (nt)2/3),
where we use the classical estimate P[gg ≥ t] ≤ e-t2/2, valid for t ≥ 1, and accordingly require
t ≥ (C00)-3n-1. In particular, there is an absolute constant C00 > 0 such that we have
P
C0√nσ(g)3 ≥
P σ(gg) ≥
≤ exp
≤ e-d,
where the last inequality holds in particular when n ≥ 8d4 (and this condition implies what is
necessary for the second to last to hold when d ≥ 1). Returning to our bound on fν, we note that
when n ≥ (C/C00)2d, we have that
fν(g) -√= ≤ C + C0√nσ(g)3 -√C0 ≤ C0√nσ(g)3 - √C=,
nd n	nd	nd
from which we conclude that when our previous hypotheses on n are in force
P fν (g) ≥√y
≤ e-d
(E.59)
We are going to use this result to control | i fν (g1i) - E[fν (g1i)]| using a truncation approach.
Define M = 2C00∕√nd, where C00 > 0 is the absolute constant in (E.59). We write using the
triangle inequality
n
X fν(g1i) - E[fν(g1i)]
i=1
n
≤	fν (g1i ) - fν (g1i )1fν (g1i)≤M
i=1
n
+	fν(g1i)1fν(g1i)≤M - E[fν (g1i)1fν (g1i)≤M ]
i=1
n
+ X E[fν (g1i)1fν (g1i)≤M ] - E[fν(g1i)]
i=1
By (E.59) and a union bound, we have with probability at least 1 - ne-d
n
fν (g1i) - fν (g1i)1fν (g1i)≤M = 0.
i=1
Moreover, we calculate
n
X E[fν (g1i)1fν (g1i)≤M] - E[fν (g1i)]
i=1
n
≤ XE[fν(g1i)1fν(g1i)>M]
i=1
n
≤ X P[fν (g1i) >M]1∕2kfν (g1i)kL2
i=1
≤ Ce-d/2
214
Published as a conference paper at ICLR 2021
for an absolute constant C > 0, using in the second line the Schwarz inequality, and in the third
line (E.56) and (E.59). The second term can be controlled with Lemma G.3, together with the
observation that
n
X E [(1fν (gii)≤M fν (gIi)- E[1fν (gii)≤M fν (g1i)])2]
i=1
n
= X E[1fν (g1i)≤M fν (g1i)2 ] - E[1fν (g1i)≤M fν (g1i)]
i=1
n
≤ X E[fν(g1i)2]
i=1
≤ C/n,
where the last inequality is due to (E.56). Lemma G.3 thus gives for any t ≥ 0
n
P X
fν (g1i)1fν (g1i)≤M - E[fν (g1i)1fν (g1i)≤M ] ≥ t
i=1
≤ 2exp (- Cn-t+Mt∕3 J
It follows that there is an absolute constant C0 > 0 such that
P
n
fν(g1i)1fν(g1i)≤M - E fν(g1i)1fν(g1i)≤M
i=1
and therefore with probability at least 1 - 2ne-d (by a union bound) we have
n
X fν (g1i) - E[fν (g1i)]
i=1
≤ C0A口 + C00e-d/2.
n
Combining with (E.58) using a union bound and worst-casing constants in the exponent, we con-
clude that with probability at least 1 - C000ne-c00d - C0000ne-c000n, we have
∣Ξι(ν,gι,g2) - E[Ξι(ν,gι, g2)]∣ ≤ Cjd + C0e-cd + C00ne-c0n.
n
Aggregating our hypotheses on n, there are absolute constants C1, C2, C3 > 0 such that we have
to satisfy n ≥ max{Cd, C0d4, C00}. Moreover, to be able to assert ne-c00d ≤ e-c00d/2 , we have
to satisfy d ≥ 2∕c00log n. Introducing an auxiliary d > 0 and setting d = dlog n, We have to
satisfy n ≥ max{ Cdlog n, C0d4 log4 n, C00} and d ≥ 2∕c00. Choosing n in this way, We can finally
conclude that With probability at least 1 - C000n-c00d/2 - C0000ne-c000n, We have
∣Ξι(ν,gι,g2) - E[Ξι(ν,gι,g2)]∣ ≤ C∖ dlogn + C0n-cd + C00ne-c0n
n
which is the desired type of bound.
□
Lemma E.40. In the notation of Lemma E.13, there are absolute constants c, C, C0, C00 > 0 such
that for any δ ≥ 3∕2, we have
P E[Ξ1(ν, g1,g2)] - E [Ξ1(ν,g1,g2)] is C + C0n1+δ-Lipschitz ≥ 1 - 2e-cn - C00n-δ.
g2	g1 ,g2
Proof. Write f(ν, g1) = Eg2 [Ξ1(ν, g1, g2)]; it will suffice to differentiate f and E[f] with respect
to ν, bound the derivatives on an event of high probability, and apply the triangle inequality to obtain
a high-probability LiPSchitz estimate for |Eg2 [Ξι(ν, gι, g2)] - Egi,g2 [Ξι(ν, gι, g2)]∣.
Define k = ,2∕n. For fixed (gι, g2), the function
n
q(ν, g1, g2) =
i=1
σ(gii)3ρ(-gii Cot V)
ψ(kv0 l∣2)ψ(kvV l∣2)sin3 V
215
Published as a conference paper at ICLR 2021
is differentiable at all but at most n points of (0, ν), using Lemma E.31 to see that the only obstruc-
tion to differentiability is the function σ in the term kvνi k2 ; and there has derivative
/
∖
q0(V, g1,g2)=X 'Ik?)
g1i Cos V
k2Ψ(IWV k2)sin6 v
Ψ0(k 球 k2)h 球,吸 i
ψ(kvν l∣2)2kvν l∣2 sin3 V
_ q______Cos V_____
一亦 Ψ(∣vV k2)sin4 V
exp (-2k2 g2i cot2 V
)
∖
—
The triangle inequality and Lemma E.31 yield
n
IqO(V,gι,g2)| ≤ √== X|gii|3
2πk2 i=1
4g12i
k2 sin6 v
16CkvVk2 +
sin3 V
s⅛)exp (-+ g2i cot2 V
(E.60)
for C > 0 an absolute constant. We have ∣∣VV∣∣2 ≤ ∣∣g1k2 + ∣∣g2∣∣2 by the triangle inequality, so
to obtain a (ν, g2)-integrable upper bound it suffices to remove the ν dependence from the previous
estimate. We argue as follows: if 0 ≤ V ≤ n/4 or 3∏∕4 ≤ V ≤ ∏, we have cos2 V ≥ 2, and so for
any p ≥ 3
exP (- 212 g2i cot2 V)
sinp ν
≤ exp g -gl⅛—ɪ ) sin-p ν.
4k2 sin2 t
(E.61)
+
By Lemma E.36, where we put C = g12i /4k2 and therefore have to require that g1i 6= 0 for all
i ∈ [n] (a set of measure zero in Rn), this yields
∣q0(ν,gι,g2)∣ ≤ Ckg2k2,
(E.62)
where C > 0 is a constant depending only on n and g1. In cases where g1i = 0 for some i, we note
that the bound (E.60) is then equal to zero, which also satisfies the estimate (E.62). On the other
hand, when π∕4 ≤ V ≤ 3π∕4, then Sin t ≥ 2-1/2, and we can assert for any P ≥ 3
eχp(-212g2 cot2 V) ≤ /2
Sinp V	—	.
By the triangle inequality, this too implies
|q0(V,g1,g2)| ≤ C0kg2k2,
where C0 > 0 is a constant depending only on n and g1. Invoking then Lemma G.9, we conclude
that q0 is absolutely integrable over [0, π] × Rn, so that an application of Fubini’s theorem and (Cohn,
2013, Theorem 6.3.11) gives the Taylor expansion f(V, g1) = f(0, g1) + 0V Eg2 [q0(t, g1, g2)] dt.
Next, we show also that q0 is absolutely integrable over [0, π] × Rn × Rn, which implies that
E[f (V, g1)] = E[f (0, g1)] + R0V E[q0(t, g1, g2)] dt as well. Starting from (E.60), we have
E[|q0(V, g1, g2)|]
≤ E ]√⅛ X lg1il3
k2 sin6 V +
16C(kgik2 + kg2 k2)
sin3 V
-τ12-"
sin V
+
and the expectation factors over g1i, g1i , g2i , so we can separately compute the g1i integrals first. For
the first of the three terms on the RHS of the previous expression, we have
E
g1i
|g1i|5	1	1 2 十2
Sin6V exp(一页g1i Cot V
1 I ∣g∣5	1	1 27.2 Aj
√2πk2 L QTexp (-页g/SinV 尸g
√⅛ ∕lgl5exp (-2⅛g2) dg，
(E.63)
after the change of variables g 7→ g sin V in the integral, which is valid whenever 0 < V < π. To take
care of the case where V = 0 or V = π, we can use the estimate (E.61), valid for V sufficiently close
to 0 or π, and the assumption g1i 6= 0 for all i to conclude that limV&0 q0(V, g1, g2 ) = 0 for any
such fixed (g1, g2), and by symmetry the analogous result limV%π q0(V, g1, g2) = 0; and whenever
for some i we have g1i = 0, we use (E.60) to see that the term in the sum involving g1i poses no
problems as V & 0 or V % π because it is identically 0. Returning to the integral (E.63), we have
after a change of variables
|g|5 exp
√2π 挑15exp (-2g2)dg=Ck5,
216
Published as a conference paper at ICLR 2021
where C > 0 is an absolute constant, and where we use Lemma G.11 for the last equality. The
remaining two terms can be treated using the same argument: we get
E W- exp (- 12gg2 cot2 V) = C0k3
g1i sin3 ν	2k2
(after using |sin ν∣ ≤ 1) and
E ⅛- exp (- 12g g2i cot2 v)] = C00k3
g1i sin4 ν	2k2
for absolute constants C0 , C00 > 0. Combining these estimates gives
Cn
E[∣q0(v,gι,g2)∣] ≤ n£gE[kglk2 + kg2k2],
and using Lemma G.9 (or equivalently Jensen’s inequality) gives finally
E[∣q0(v,gι,g2)∣] ≤ Cj 冗 1 ≤ C.
To conclude, we need to show that Eg2 [q0(ν, g1, g2)] is uniformly bounded by a polynomial in n
with high probability. For this we start from the estimate (E.60) and apply the argument following
that, but with more care in tracking the constants: if V is within n/4 of either 0 or ∏, We can assert
0	C n C1k4	3 i	i	C3 k4
∣q (V, g1, g2)∣ ≤ k ɪj ∣g]∙∣ + C2k (kg1k2 + kg2k2) + 囱 ∣
whenever g1i = 0 for every i (a set of full measure); and when V is within n/4 of n/2, we can assert
∣q0(ν,gι,g2)∣ ≤ kX 1 kgii' + C2∣gii∣3(kgil∣2 + llg21∣2) + C3∣gii∣3,
i=1
where Ci , Ci0 > 0 are absolute constants. By the triangle inequality, independence, and Lemma G.9,
when we consider ∣Eg2 [q0(V, g1, g2)]∣, the term E[lg2i l2] is bounded by an absolute constant. Ad-
ditionally, by Gauss-Lipschitz concentration and Lemma G.9, we have that simultaneously for all i
lg1i l2 ≤ lg1 l2 ≤ 2 with probability at least 1 - 2e-cn. Moreover, since lg1 l∞ ≤ lg1l2 we also
have control of the magnitude of each ∣g1i ∣ on this event, so with probability at least 1 - 2e-cn we
have for every V
E [q0(ν, gl, g2)] ≤ C X * + C2k3 + C +C4
g2	k i=1 ∣g1i ∣	k2
for absolute constants C, Ci > 0. If X 〜N(0,1), we have for any t ≥ 0 that P[∣X∣ ≥ t] ≥ 1 一 Ct,
where C > 0 is an absolute constant; so if Xi 〜i.i.d. N(0,1), we have by independence and if t is
less than an absolute constant P[∀i, ∣Xi ∣ ≥ t] ≥ (1 - Ct)n ≥ 1 - C0nt, where the last inequality
uses the numerical inequality e-2t ≤ 1 - t ≤ e-t, valid for 0 ≤t ≤ 2. From this expression, we
conclude that when 0 ≤ t ≤ cn-1/2 for an absolute constant c > 0, we have
P[∀i ∈ [n], ∣g1i∣ ≥ t] ≥ 1 - Cn3/2t,
so choosing in particular t = cn-(δ+2) for any δ > 0, we conclude that P[∀i ∈ [n], ∣gii∣ ≥
Cn-3/-] ≥ 1 一 C0n-δ. Consequently, for any δ > 0 we have with probability at least 1 一
C0n-δ - 2e-cn
n
E [q0(ν, gι, g2)] ≤ γ SX Cιk4n3∕2+δ + C2k3 + -p3 + C4,
g2	k	k
i=1
and since k = p2/n, this yields ∣Eg2 [q0(ν, gι,g2)]∣ ≤ Cιn1+δ + C2 + C3n5/2 + C4n3/2 with the
same probability. Consequently we can conclude that for any δ ≥ 3/2, we have
P E[Ξ1(ν,gι,g2)] 一 E [Ξι(ν,gι,g2)]is C + C0n1+δ-Lipschitz	≥ 1 一 2e-cn - C00n-δ.
g2	g1 ,g2
□
217
Published as a conference paper at ICLR 2021
Lemma E.41. In the notation of Lemma E.13, if d ≥ 1, there are absolute constants c, c0C, C0 > 0
and an absolute constant K > 0 such that if n ≥ K, there is an event with probability at least
1 - C e-cn on which
∀ν ∈ [0,π], ∣Ξ2(ν,gι,g2) - E[Ξ2(ν,gι,g2)]∣ ≤ C0e-c0n.
Proof. Let E denote the event E0.5,0 in Lemma E.16; then by that lemma, E has probability at least
1 - Ce-cn as long as n ≥ C0, where c, C, C0 > 0 are absolute constants, and for (g1, g2) ∈ E, one
has for all ν ∈ [0, π]
Ξ2(ν,g1,g2) = 0.
This allows us to calculate, for each ν ,
E[Ξ2(ν,gι,g2)] = E[1ecΞ2(ν,gι,g2)] ≤ E[1eC]1/2kΞ2(ν, ∙ )kL2 ≤ C0e-c0n,
after applying Lemma E.37 and Lyapunov’s inequality and worst-casing constants. We conclude
that with probability at least 1 - Ce-cn
∀ν ∈ [0,π], ∣Ξ2(ν,gι,g2) - E[Ξ2(ν,gι,g2)]∣ ≤ C0e-c0n.
□
Lemma E.42. In the notation of Lemma E.13, if d ≥ 1, there are absolute constants c, c0C, C0 > 0
and an absolute constant K > 0 such that if n ≥ K, there is an event with probability at least
1 - C e-cn on which
∀ν ∈ [0,π], ∣Ξ3(ν, gι,g2) - E[Ξ3(ν,gι, g2)]∣ ≤ C0e-c0n.
Proof. The argument is identical to Lemma E.41. Let E denote the event E0.5,0 in Lemma E.16;
then by that lemma, E has probability at least 1 - Ce-cn as long as n ≥ C0, where c, C, C0 > 0 are
absolute constants, and for (g1, g2) ∈ E, one has for all ν ∈ [0, π]
Ξ3(ν,g1,g2) = 0.
This allows us to calculate, for each ν ,
E[Ξ3(ν,gι,g2)] = E[1ecΞ3(ν,gι,g2)] ≤ E[1eC]1/2kΞ3(ν, ∙ )kL2 ≤ C0e-c0n,
after applying Lemma E.37 and Lyapunov’s inequality and worst-casing constants. We conclude
that with probability at least 1 - Ce-cn
∀ν ∈ [0,π], ∣Ξ3(ν, gι,g2) - E[Ξ3(ν,gι, g2)]∣ ≤ C0e-c0n.
□
Lemma E.43. In the notation of Lemma E.13, if d ≥ 1, there are absolute constants c, C, C0, C00 >
0 and absolute constants K, K0 > 0 such that if n ≥ Kd log n and d ≥ K0, there is an event with
probability at least 1 - C e-cn - C0n-d on which one has
∀ν ∈ [0, π], 1ξ4 (V, g1, g2) - e[ξ4(V, g1, g2)]| ≤ C 0θ 4 ； I
Proof. We are going to control the expectation first, showing that it is small; then prove that ∣Ξ4∣
is small uniformly in V. Let E denote the event E0.5,0 in Lemma E.16; then by that lemma, E has
probability at least 1 - Ce-cn as long as n ≥ C0, where c, C, C0 > 0 are absolute constants, and
for (g1 , g2 ) ∈ E, one has for all V ∈ [0, π]
「/	、	9hv0, VV ihvν, VV i
二4(v, gl, g2) = -2 —∏~~∏-∏~~^3—.
kV0k2kVVk32
Thus, if we write
—	h hv h	√V0, VvihVν, Vvi
Ξ4(V, gι, g2) = -21e(gι, g2) —π—r-π—,
kV0k2kVvk32
218
Published as a conference paper at ICLR 2021
we have Ξ4 = Ξ4 for all ν whenever (g1, g2) ∈ E, so that for any ν
∣E[Ξ4(ν, gι, g2)]∣ = ∣E[Ξ4(ν, gι, g2)] + E[1ecΞ4(ν, gι, g2)]
-■~ ， 一. 一一
≤ ∣E[Ξ4(ν,gι,g2)]∣ + Ce-cn,
where the second line uses the triangle inequality and the Schwarz inequality and Lemma E.37
together with the Lyapunov inequality. We proceed with analyzing the expectation of Ξ4 . Using the
Schwarz inequality gives
∣E∣Ξ4(ν,gι, g2)i ∣ ≤ 2E[hvo, VVi2hvν, VVi2]1/2E
Γ 1e ]
J∣vok2kvν k2 一
1/2
≤ 32E[hv0, VVi2hvν, VVi2]1/2,
and the checks at and around (E.34) and (E.35) in the proof of Lemma E.15 show that we can apply
Lemma E.30 to obtain
E[hvo, VVYhhvV, VVi2]
-n4 ( E[σ(g11)σ(g11 Cos V + g21 Sin V)(g21 Cos V — gu Sin V)]2
1	*E[σ(g11 cos V + g21 Sin V)(g21 Cos V — gιι Sin ν)]2
≤ C/n.
But we have using rotational invariance that E[σ(g11 Cos V + g21 sin V)(g21 Cos V — g11 sin V)] = 0,
which implies
∣E[(V0, V V YhVv , V V i2 ] ∣ ≤ C/n,
from which We conclude
∣E[Ξ4(V,gι,g2)]∣ ≤ C∕√n.
Next, we control the deviations of Ξ4 with high probability. By Lemma E.17, there is an event Ea
with probability at least 1 — e-cn on which ∣Vν∣∣2 ≤ 4 for every V ∈ [0,∏]. Therefore on the
event Eb = E ∩ Ea, which has probability at least 1 — Ce-cn by a union bound, we have using
Cauchy-Schwarz that for every V
∣Ξ4(V,gι,g2)∣ ≤ 256∣hvν,Vvi|.
The coordinates of the random vector VV Θ VV are σ(gι cos V + g2i sin V)(g2i cos V — gu sin V), and
we note
E[σ(gii cos V + g2i sin V)(g2i cos V — gu sin v)] = —E[σ(gii)g2i] = 0,
by rotational invariance. Moreover, the calculation (E.35) together with Lemmas G.11 and E.17
demonstrates subexponential moment growth with rate C/n, so Lemma G.2 implies for t ≥ 0
P[hvν, VVi ≥ t] ≤ 2e-cnt min{c0t,1}.
For large enough n, this gives
P [hvν, V V i≥ eʌ/dɪogn1≤ 2n-2d.
n
We turn to the uniformization of this pointwise bound. The map V 7→	i σ(g1i cos V +
g2i sin V)(g2i cos V — g1i sin V) is continuous, and differentiable at all but finitely many points of
[0, π] (following the zero crossings argument in the proof of Lemma E.22) with derivative
V → fσ(gii cos V + g2i sin ν)(g2i cos V — gι sin ν)2 — σ(gι cos V + g?i sin V)2,
i
which is evidently integrable using the triangle inequality and Lemma G.11. In particular, we can
write the derivative as ∣Vν∣∣2 — ∣∣vo∣∣2∙ Thus, by (Cohn, 2013, Theorem 6.3.11), to get a LiPsChitz
estimate on v → hvν, V V i it suffices to bound the magnitude of the derivative v → ∣V ν∣∣2 — ∣∣vok2.
But this is immediate, since on the event Eb we have ∣∣Vν∣∣2 — ∣∣vo∣2∣ ≤ 20. It thus follows from
Lemma E.48 that with probability at least 1 — Ce-cn — C0n-2d+1/2
we have
∀V ∈ [0,π], hvν, VVi ≤ C00
dlogn
n
(E.64)
219
Published as a conference paper at ICLR 2021
As long as d ≥ 2, We have that this probability is at least 1 - Ce-Cn - C0n-d, and so the triangle
inequality and a union bound yield finally that with probability at least 1 - Ce-cn - C0n-d
∀ν ∈ [0,π], ∣Ξ4(ν,gι,g2) - E[Ξ4(ν,gι,g2)]∣ ≤ C00
□
Lemma E.44. In the notation of Lemma E.13, if d ≥ 1, there are absolute constants
c, c0, c00, C, C0, C00, C000, C 0000 > 0 and an absolute constant K > 0 such that if n ≥ Kdlogn,
there is an event with probability at least 1 - C e-cn + C0e-d on which one has
∣Ξ5(ν,gι,g2) - E[Ξ5(ν,gι,g2)]∣ ≤ C"∖ d + C000e-c0d + C0000e-c"n
n
Proof. Fix ν ∈ [0, π]. Let E denote the event E0.5,0 in Lemma E.16; then by that lemma, E has
probability at least 1 - Ce-cn as long as n ≥ C0, Where c, C, C0 > 0 are absolute constants, and
for (g1 , g2 ) ∈ E, one has for all ν ∈ [0, π]
Ξ5 (ν, g1, g2)
(Vo, VVi∣∣Vνk2
kv0k2kvνk3 .
—
Thus, if We Write
=/	h h h h hVθ, VV i∣W V k2
ξ5 (V, gl, g2) = -1E (gl, g2) -∏~~∏-∏-f732
kV0k2kVVk32

we have Ξ5 = Ξ5 for any ν whenever (g1, g2) ∈ E, so that by the triangle inequality, for any ν
∣Ξ5(ν, gι, g2) - E[Ξ5 (ν, gι, g2)]∣ ≤ ∣Ξ5(ν, gι, g2) - Ehe5(v, gι, g2)i I
+ E[Ξ5(ν,g1,g2)] - EhΞe5(ν, g1, g2)i
≤ ∣∣∣Ξe5(ν, g1, g2) - EhΞe5(ν, g1, g2)i∣∣∣
+ E 1Ec∣∣Ξ5(ν,g1,g2) - Ξe5(ν, g1, g2)∣∣
≤ ∣∣∣Ξe5(ν, g1, g2) - EhΞe5(ν, g1, g2)i∣∣∣ + Ce-cn,
where the second line uses the triangle inequality, and the third line uses the Schwarz inequality and
Lemma E.37 together with the Lyapunov inequality.
So, we can proceed analyzing Ξ5 . First, we aim to apply Lemma E.33 with the choices
X= _1 hv0, VVi . Y kvνk2
=E kv0k2kVν k2 ;	= EkvVk2 ,
since XY = Ξ5(ν, ∙, ∙); SqUare-integrab山ty of X and Y is evident from the definition of 1e, and
We have |X | ≤ 1 by Cauchy-SchWarz. To control Y, We start by noting
kY - 1kL2 ≤ 1 + kYkL2 ≤ 1 + 4E[kVνk2]1/2 ≤ 1 + 4√1+C,
Where C > 0 is an absolUte constant; the first ineqUality is the MinkoWski ineqUality, the second
Uses the property of E and drops the indicator by nonnegativity, and the third applies Lemma E.29,
and discards the n-1 factor. For deviations, We start by noting that E[kvνk22] = 1, and that by
Lemmas G.2 and G.11, We have
Pkvνk22 - 1 ≥ t ≤ 2e-cnt min{Ct,1}.
It follows that there exists an absolute constant C0 > 0 such that, putting t = C0 Yd/n and choosing
n ≥ (C0/C)2d, We have
kvν k22 - 1 ≥ C0
P
(E.65)
220
Published as a conference paper at ICLR 2021
Moreover, by LemmaE.17, We can run a similar argument on ∣∣Vνk2 to get that if n is larger than a
constant multiple of d
P Ikvνk2 - 1∣ ≥ cjd ≤ 2e-d
(E.66)
Next, Taylor expansion With Lagrange remainder of the smooth function x 7→ x-1 on the domain
x > 0 about the point 1 gives
1
x
1 - (X - I) + 73(X - I)2,
(E.67)
Where ξ lies betWeen 1 and X. If (g1, g2) ∈ E, then kvν k26 ≥ (1/64), and We can therefore assert
1
1 - (kvν∣∣2 - 1) ≤ I® ∣∣2 ≤ 1 - (kvν∣∣2 - 1) + 64 (IwVIl2 - 1)
With probability at least 1 - Ce-cn . Using a union bound together With (E.65) (and changing the
constant to C), We have With probability at least 1 - 2e-cd - C0e-c0n that
-CVn - 64C 2 n ≤1 - Pn ≤ CVn
Given that n ≥ d, it folloWs that With the same probability We have
-C(1+64C)
1
≤ CU
n
Which implies that With probability at least 1 - 2e-d - C0e-cn, We have
1 - ɪ
kVνk2
≤ CJd
n
NoW, the triangle inequality gives
kv νk2
kvνk2
-1
kvνk2	1
-----Tr - -----Tr
kvν k2 IWVk2
ɪ - 1
kvν k2
When (g1,g2) ∈ E, We have kvV k22
C0e-cn We have
and since
舄2 IkV ν k2 -1∣ +
ɪ - 1
kVνk2
≥ 4, so, by a union bound, with probability at least 1 一 4e-d —
kvV k2
-----K - 1
kvν k2
≤ 4C",
(gι,g2) ∈ E =⇒ Y = k⅛,
kvν k2
another union bound and the measure bound on E let us conclude that with probability at least
1 - 4e-d - C0e-cn, We have
IY - 1I ≤ 4Ci/-.
n
If we choose n ≥ (1/c)(d + log C0/4), we have 4e-d + C0e-cn ≤ 8e-d, so the previous bound
occurs with probability at least 1 - 8e-d. We can now apply Lemma E.33 to get with probability at
least 1 - 8e-d
∣ξ 5 -华5卜 1E( p⅛, ⅛) - E [1E (血,P⅛)
+ C∖∣~d + Ce-Id2.
n
Next, we attempt to apply Lemma E.33 again, this time to X = 1E hv0, vVi and Y =
1E (kv0 k2kvVk2)-1. Using the definition ofE, we have IXI ≤ 4 and kY - 1kL2 ≤ kY kL2 + 1 ≤ 5,
≤
221
Published as a conference paper at ICLR 2021
where the second bound also leverages the Minkowski inequality; so we need only establish devia-
tionsof Y. APPlyingagain(E.67), and using (gι,g2) ∈ E implies ∣∣v0k2∣∣vν∣∣2 ≥ 4, we get
21
(IIv0k2kvνk2 -I)- 64(Mk2kvνk2-1) ≤ 1-	≤ (Mk2kvνk2 - I)(EM
with Probability at least 1 - Ce-cn. Using Lemma G.11 and (Vershynin, 2018, Theorem 3.1.1), we
can assert for any ν ∈ [0, π] and any t ≥ 0
P[∣kvνk2 -1∣≥ t] ≤ 2e-cnt2,
which imPlies that there exists an absolute constant C > 0 such that for any d > 0
P
lkvνk2 - 1l≥ C
In Particular, when n ≥ d, we can assert that kvνk2 ≤ 1 + C with Probability at least 1 - 2e-d. By
the triangle inequality and a union bound, it follows
∣kv0∣∣2∣∣vν∣∣2 - 1l≤ kv0∣∣2∣kvν∣∣2 - 1| + lkv0k2 - 1|
≤ C rd
n
with Probability at least 1 -6e-d. Then a union bound gives that with Probability at least 1 - 6e-d -
C0e-cn, (E.68) leads to
1
Ilv0k2kvν k2
≤ CJd,
n
and using n ≥ dand worst-casing constants imPlies that with the same Probability
1______1—
Ilv0k2kvν k2
≤ CJd
n
Then since (g1, g2) ∈ E =⇒ Y = (Iv0I2IvνI2)-1, another union bound gives that with Prob-
ability at least 1 一 6e-d — C0e-cn We have |Y 一 1| ≤ Cyd/n. As in the previous step of the
reduction, we can choose n ≥ (1/c)(d + log C0/6) to get that 6e-d + C0e-cn ≤ 12e-d, so that the
previous bound occurs with probability at least 1 一 12e-d. We can thus apply Lemma E.33, a union
bound, and our previous work to get that with probability at least 1 一 20e-d
∣Ξ 5 一 旧[司 ≤ |1e hvo, vν i 一 E[1e hv0, vν i]| + CJd + C 0e-d/2.
Whenever (g1 , g2 ) ∈ E, we have by the triangle inequality, the Schwarz inequality, and Lem-
mas E.16 and E.29 that
|1ehv0,vνi - E[1ehv0, vνi]| ≤ Ihv0, vνi - E[hv0, vνi]| + ∣E[hv0,vνi] 一 E[1ehvo, vνi]|
≤ Ihvo, vν)一 E[hvo, vνi]| + Ce-cn,
allowing us to drop the indicator. We have hv0, vνi = Pi σ(g1i)σ(g1i cos ν + g2i sin ν), which is
a sum of independent random variables; following the argument at and around (E.36), we conclude
moreover that these random variables are subexponential with rate C/n, where C > 0 is an absolute
constant. We therefore obtain from Lemma G.2 the tail bound
P[∣hv0, vν)一 E[hvo, vνi]| ≥ t] ≤ 2e-cntmin{ct,1},
which, fora suitable choice of absolute constant C0 > 0 and choosing n ≥ C0d, yields the deviations
bounds
P Ihvo,vνi— E[hvo,vνi]∣≥ C∖∣~n~^ ≤ 2e-d
222
Published as a conference paper at ICLR 2021
Taking a final union bound (since we assumed throughout that (g1, g2) ∈ E) gives that with proba-
bility at least 1 - Ce-cn + C0e-d,
one has
∣Ξ5(ν,gι,g2) - E[Ξ5(ν,gι,g2)]∣ ≤ CC0∖∕d + C000e-c0d + C0000e-c"n,
n
which is sufficient to conclude pointwise concentration as claimed for sufficiently large n after we
putd =d0 log n and include extra log n factors in any points where we need to choose n larger than
d.
Lemma E.45. In the notation of Lemma E.13, there are absolute constants c, C, C0, C00, C000 > 0
such that for any δ ≥ 11, one has
P E[Ξ5(ν, g1, g2)] - E [Ξ5(ν, g1, g2)] is C + C0n1+δ-Lipschitz ≥ 1 - C00e-cn - C000n-δ
g2	g1 ,g2
as long as δ ≥ 1.
Proof. We will differentiate with respect to ν the function
f(V, g1) = - E
g2
Yv0, VVikvνk2ψ0(IIvVk2)-
.Ψ(kvθk1)Ψ(kVν k1)2kVν k2_ ,
and construct an event on which f0 has size poly(n). We need to also differentiate the function
E[f (∙, gι)]; for this We will additionally show that f 0(ν, ∙) is absolutely integrable over the product
[0, π] ×Rn × Rn, which allows us to apply Fubini’s theorem to move both the g1 and g2 expectations
under the ν integral in the first-order Taylor expansion we obtain. In particular, the derivative of
E[f (∙, gι)] will in this way be shown to be E[f 0( ∙, gι)], so that linearity and the triangle inequality
imply a poly(n) magnitude bound for the derivative of Eg2 [Ξ5] - E[Ξ5].
Define
hv0, vνiψ0(kvνk1)(g2i cos V — gii Sin V)2
qi(ν, g1, g2)=	Ψ(kvθk1)Ψ(kvν k1)2kvν k2	,
so that, for almost all g1,
n
f(ν, gι) = —V' E [qi(ν, gι, g2)σ(gii cos V + g2i sin V)].
g2
i=1
For each fixed (g1 , g2 ) and each i, the only obstructions to differentiability of qi in V arise from
the function σ (using smoothness of ψ from Lemma E.31 and the fact that it is constant whenever
kvν k is small enough that nondifferentiability of ∣∣ ∙ ∣∣1 could pose a problem); following the zero-
crossings argument of Lemma E.22, qi fails to be differentiable at no more than n points of [0, π],
and otherwise has derivative
qi0(V, g1, g2)
1 h hv0, vViψ0(kvν k2)(g2i cos V — gii sin V)2
Ψ(kv0k2)∖	Ψ(kvνk2)2kvνk2
hv0, vνihvν, vViψ00(kvν∣2)(g2i cos V — gii Sin v)2
+	ψ(kvν k2)2kvν k2
hv0,vViψ0(∣vV∣2)(g2icosV — gii sin V)(gii cos V +g2isinV)
-2-----------------------------:-------------------------
ψ(kvν k2)2kvν ∣2
oψ0(kvνk2)2hvν, vVihv0, vνi(g2i cos V — gii sin ν)2
-2------------------------∑-----Z--------------
Ψ(kvV k1)3kvV k2
ψ0(kvVk2)hvV, vVihv0, vVi(g2i cos V — gii sin V)2、
Ψ(kvV k2)2kvV k3	Γ
(E.69)
by the chain rule and the product rule. To conclude absolute continuity of qi(∙, gi, g1), we need
to show that qi0 is integrable; this follows from Cauchy-Schwarz, the integrability of ∣v0 ∣2, ∣vV ∣2,
223
Published as a conference paper at ICLR 2021
kVν∣∣2 (Lemma E.17), the triangle inequality, and the Lemma E.31 estimates ψ ≥ 1, ∣ψ0∣ ≤ C,
∣Ψ00∣ ≤ C0, and ∣ψ0(χ)∕χ∣ ≤ C00 for any X ∈ R (to see this last estimate, note that ∣ψ01 is bounded
on R, and use that ψ is constant whenever X ≤ 4). Then (Cohn, 2013, Theorem 6.3.11) implies that
qi( ∙, gι, g2) is absolutely continuous with a.e. derivative qi. Next, We can write
n
f (ν, gι) = -£ E E [qi(ν, gι, g2)σ(gii cos V + g2i Sin ν)]
i=1 g2j :j6=i g2i
using Lemma E.37 to see that Fubini’s theorem can be applied. Our aim is now to apply
Lemma E.27, so we need to check its remaining hypotheses. First, continuity of qi(ν, ∙) follows
from continuity of σ , smoothness of ψ, and the fact that the denominator never vanishes. Joint ab-
solute integrability of qi and qi0 follows from our verification of absolute integrability of qi0 above,
which produces a final upper bound that does not depend on ν (which is therefore integrable over
[0, π] as well); the corresponding result for qi follows from Lemma E.37. Last, we need the growth
estimate. We have from Lemma E.31
∣qi(ν, gι, g2)| ≤ 32C(g2i cos V - gii sin Vy ≤ 32C(∣g2i| + ∣gii|)2 ≤ 32C∣gii∣(1 + |g2i|)2,
which is evidently quadratic in |g2i | once |g2i | ≥ 1. Consequently we can apply Lemma E.27 to
differentiate f (∙, gi);we get at almost all gι
n
f(ν, gι) = - Xl E E [qi (0, gι, g2)σ(gii)]
i=1 g2j :j 6=i g2i
+ E	∣"∕"dt( Eg2i [q0(t, gι, g2 )σ(gii cos t + g2isin t)] λβ
g2j:j6=i	0	-g1iqi(t,g1,ge2i)ρ(-g1icott)sin-2 t
where ge2i is the vector g2 but with its i-th coordinate replaced by -g1i cot t, and where ρ is the pdf
of a N (0, 2∕n) random variable. The changes in ge2i drive updates to the terms in qi as follows: we
have σ(g1i cos V + g2i sin V) becoming 0, and g2i cos V - g1i sin V becoming -g1i∕ sin V. Thus, we
have
-g1iqi(t,g1,ge2i)ρ(-g1i cot t) sin-2 t
g3ihv0, viiψ0(kvik2)ρ(-gii cott
他(忡0心)他(口咽2)2忖心sin4 t
where the notation vti is in use in the Ξ1 control section and is defined in Lemma E.26, and v0i is de-
fined here similarly (the Rn-1 vector which is the projection ofv0 onto all but the i-th coordinates).
Using Lemma E.31, we can further assert
IgIiqi(t,gi,e2)ρ(-giicott)sin-21∣ ≤ 16Clg1il " g1 Cott)	(E.70)
sin4 t
where we use that kv0i k2 ≤ kv0k2. For each fixed gi having no coordinates equal to zero, we write
Ki = |gii| > 0; if 0 ≤ t ≤ π∕4 or 3π∕4 ≤ t ≤ π, we have cos21 ≥ 1, and so
ρ(-gιcot^tt ≤ JΞsin-41exp (Kinɪ
sin41	^V4π	PV 8 sin21
Using Lemma E.36, we have
ρ(-gii Cot t) ≤
-sin41_ _
On the other hand, when π∕4 ≤ t ≤ 3π∕4, then sin t ≥ 2-i/2, and we can assert
ρ(-gii4cott ≤ 8pn∕π.
sin4 t
We conclude for any t
∣giiqi(t, gi, e2)p(-gii cot t) sin-21∣ ≤ C∕(Kin3/2) + C0√nK3	(E.71)
224
Published as a conference paper at ICLR 2021
for absolute constants C, C0 > 0, and this upper bound is integrable jointly over t and g2 . We have
checked previously the joint integrability of the qi0 terms when applying Lemma E.27, so we can
therefore apply Fubini’s theorem to get g1-a.s.
f (ν, g1) = - E
g2
n
Eqi(O, gι, g2^)σ(gii)
i=
νn
-Z0 Xi=1 gE2
qi(t, gι, g2)<σ(gii cost + g2i Sint)
-g1iqi(t,g1 , ge2i)ρ(-g1i cot t) sin-2 t
dt.
Consequently, to conclude a LiPschitz estimate for f (∙, gι) it suffices to control the quantity under
thet integral in the previous expression. We will start by controlling the second term using Markov’s
inequality. Following (E.70), we calculate
E [∣giiqi(t, gι, g2)p(-gii cott) sin-21∣] ≤ 8C∖ n E
g1 ,g2	π g1
∣gii∣3 exp (-4 ⅛⅛)'
sin41
4Cn
π
4Cn
π
f 旦 exP
R sin4 t
(|g|3 exp (-4g2) dg,
—
n g2 "
4N dg
where the last line follows from the change of variables g 7→ g sin t in the integral. We can evaluate
this integral with Lemma G.11, which gives a bound
E [∣g1iqi(t,g1 , ge2i)ρ(-g1i cot t) sin-2 t∣] ≤
g1 ,g2
128C
πn
and therefore a bound of C0 > 0 an absolute constant on the sum over i. As a byProduct of this
estimate, we can assert that the second term is jointly integrable over [0, π] × Rn × Rn, which allows
us to apply Fubini,s theorem and obtain the same differentiation result for E[f (∙, gι)]. Meanwhile,
beginning from (E.71), we can write using the triangle inequality
E
g2
n	∣nC
^q Stiqi(t, gι, g2)ρ(-gii cot t) sin-21 ∣ ≤ Σ ∣gjn3∕2
+ C 0√n∣g1i∣3.
By Gauss-Lipschitz concentration and Lemma G.9, we have that kg1 k2 ≤ kg1 k2 ≤ 2 with prob-
ability at least 1 - 2e-cn, and since kg1 k∞ ≤ kg1 k2, we conclude with the same probability that
∣gti∣ ≤ 2 simultaneously for all i. Meanwhile, if X 〜N(0,1), We have for any t ≥ 0 that
P[∣X∣ ≥ t] ≥ 1 - Ct, where C > 0 is an absolute constant; so if Xi 〜i.i.d. N(0,1), we have by
independence and ift is less than an absolute constant P[∀i, ∣Xi∣ ≥ t] ≥ (1 - Ct)n ≥ 1 - C0nt,
where the last inequality uses the numerical inequality e-2t ≤ 1 - t ≤ e-t, valid for 0 ≤ t ≤ t.
From this expression, we conclude that when 0 ≤ t ≤ cn-1∕2 for an absolute constant c > 0, we
have
P[∀i ∈ [n], ∣g1i∣ ≥t] ≥ 1-Cn3∕2t,
so choosing in particular t = cn-(δ+2) for any δ > 0, we conclude that P[∀i ∈ [n], ∣gii∣ ≥
cn-3∕2-δ] ≥ 1 - C0n-δ . Then with probability at least 1 - C0n-δ - 2e-cn, we have
E
g2
Xg1iqi(t,g1	, gg2i)ρ(-g1i cot t) sin-2 t ∣∣∣ ≤ Cn1+δ + C0n3∕2,
so as long as δ ≥ t, we have
P
E
g2
Xgtiqi(t,gt,gg2i)ρ(-gti cot t) sin-2 t ∣∣∣ ≥ Cnt+δ
≤ C0n-δ + 2e-cn .
225
Published as a conference paper at ICLR 2021
Proceeding now to the qi0 term, from the expression (E.69) we get
n
qi0 (ν, g1,g2)σ(gii cos V + g2i Sin V)
i=1
=	1 h hv0, VViψ0(kvνk2)kvνk2	hv0, VVi(V”, VViψ00(kvνk2)kvνk2
=ψ(kv0k2) [	ψ(kvνk2)2kvνk2	+	ψ(kvνk2)2kvνk2
_2 hv0, VV iψ0(∣∣Vνk2)hV V, VV i _ 2 ψ0(∣∣Vνk2)2hVν, V V ihv0, VV ikV νk2
Ψ(kVV k2)2kVV k2	Ψ(kVV k2)3kVV k2
ψ0(kV"k2)hVV, V V)(V0, VV ikV v∣∣2 !
Ψ(kVV k2)2kVV k2	.
(E.72)
Using the triangle inequality, Cauchy-Schwarz, and Lemma E.31, we obtain
hV0, VViψ0(IIVVk2)kVVk2 + hV0, VVihVV, VViψ00(IlVVk2)kVVk2 ≤ CMk3
Ψ(kV0k2)Ψ(kVV k2)2kVV k2 +	Ψ(kV0k2)ψ(kVV k2 )2kVV k2	≤ k V k2
(using also the fact that ψ0(x) = 0 and ψ00(x) = 0 whenever x is sufficiently near to 0); and
(V0, VViψ0(kVV∣∣2)(VV, VVi
~Ψ(kVV k2)2kVV k2-
I ψ0(kVVk2)2hVV, VVi(V0, VVikVV∣∣2
+	Ψ(kVV k2 )3kVV k2
≤ CkV V k2 + C 0kV V k2,
I ψ0(kVVk2)hVV, V V i(V0, VV ikV V∣∣2
+	Ψ(kVV k2)2kVV k2
from which we conclude
n
£q0 (ν, gι, g2)σ(gii cos V + g2i sin V) ≤ CkV v k2 + C 0∣∣V “k3
i=1
for some absolute constants C, C0 > 0. By Lemma E.17, there is an event E of probability at least
1 一Ce-Cn on which we have ∣∣Vνk2 ≤ 4 for every ν. Moreover, we have from the triangle inequality
that kVvk2 ≤ ∣∣g1k2 + ∣∣g2k2, which is independent of V; and in particular We have
n
Eqi(V, gι, g2)σ(gii cos V + g2i sin V)
i=1
2
≤ (C(IgIk2 + kg2k2) + C0(kg1k2 + kg2k2)3)2 ,
which is a polynomial in kg1 k2 and kg2 k2 by the binomial theorem. Thus, applying independence,
Lemma G.10, Lemma G.11 yields that there is an absolute constant C00 > 0 such that
E [(C(IlgIk2 + Ilg2k2) + CO(IIgIk2 + kg2k2)3)2] ≤ CJ
g1 ,g2
Therefore, as in the framework section of the proof of Lemma E.13, we can use the inequality
E
g2
n
£di (V, gl, g2)σ(g1i cos V
i=1
+ g2i sin
together with the partition
n
Eqi(V, gι, g2)σ(gii cos V + g2i sin V),
i=1
(E.73)
n
E T q0(v, gι, g2)σ(gii cos V + g2i sin v)
g2
i=1
n
≤ C0 + E 1(E0)c	qi0(V, g1,g2)σ(gii cos V + g2i sin v)
g2
i=1
(E.74)
and this last expression can be used to obtain a g1 event of not much smaller probability 1 一 Ce-cn
on which the LHS of (E.74), and hence the LHS of (E.73), is controlled by an absolute constant
226
Published as a conference paper at ICLR 2021
uniformly in ν (in particular, using Markov’s inequality as in the framework section of the proof of
Lemma E.13). Consequently, one more application of the triangle inequality gives that
P E[Ξ5(ν,g1,g2)] - E [Ξ5(ν, g1, g2)] is C + C0n1+δ-Lipschitz	≥ 1 - C00e-cn - C000n-δ
g1 ,g2
as long as δ ≥ 2.
Lemma E.46. In the notation of Lemma E.13, if d ≥ 1, there are absolute constants c, C, C0, C00 >
0 and absolute constants K, K0 > 0 such that if n ≥ Kd log n and d ≥ K0, there is an event with
probability at least 1 - C e-cn - C0n-d on which one has
∀ν ∈ [0,∏], ∣Ξ6(ν, gι, g2)- E[Ξ6(ν, gι, g2)]∣ ≤ C00
Proof. The argument is extremely similar to Lemma E.43, since both terms have small expectations
and deviations essentially determinable by the same mean-zero random variable.
We are going to control the expectation first, showing that it is small; then prove that ∣Ξ6∣ is small
uniformly in ν. Let E denote the event E0.5,0 in Lemma E.16; then by that lemma, E has probability
at least 1 - Ce-cn as long as n ≥ C0, where c, C, C0 > 0 are absolute constants, and for (g1, g2) ∈
E, one has for all ν ∈ [0, π]
Thus, if we write
Ξ6(ν, g1, g2) = 3
hv0, VV ihvν, V V i2
Ilv0k2kvν k5
Ξ6(ν,g1,g2) = 31E(g1,g2)
hv0, VVihVν, Vvi2
Ilv0k2kvv k5
we have Ξ6 = Ξ6 for all ν whenever (g1, g2) ∈ E, so that for any ν
∣E[Ξ6(ν, gι, g2)]∣ = ∣E[Ξ6(ν, gι, g2)] + E[1ec Ξ6(ν, gι, g2)]
≤ ∣E[Ξ6(ν,gι,g2)]∣ + Ce-cn,
where the second line uses the triangle inequality and the Schwarz inequality and Lemma E.37
together with the Lyapunov inequality. We proceed with analyzing the expectation of Ξ6 . Using the
Schwarz inequality gives
∣e[ξ6(v, gι,g2)i ∣ ≤ 3E[hvo, VVi2hVv, VVi4]1/2E
1E
[∣V0k2kvvk10
1/2
≤ 192E[hV0, VV〉2〈Vv, VVi4]1/2
and the checks at and around (E.36) in the proof of Lemma E.15 show that we can apply Lemma E.30
to obtain
E[hV0, VV〉2(Vv, VVi4]
-n6E[σ(g11)σ(g11 cos V + g21 Sin V)]2E[σ(g11 cos V + g21 Sin V)(g21 Cos V — gιι Sin ν)]4∣ ≤ 一.
n
But we have using rotational invariance that E[σ(g11 coS V + g21 Sin V)(g21 coS V - g11 Sin V)] = 0,
which implies
∣E[hVo, VV〉2〈Vv, VVi4] ∣ ≤ C/n,
from which we conclude for all V
∣e[Ξ6(v, gι, g2)]∣≤ c∕√n.
Next, we control the deviations of Ξ6 with high probability. By Lemma E.17, there is an event Ea
with probability at least 1 - e-cn on which kV Vk2 ≤ 4 for every V ∈ [0, π]. Therefore on the
227
Published as a conference paper at ICLR 2021
event Eb = E ∩ Ea, which has probability at least 1 - Ce-cn by a union bound, we have using
Cauchy-Schwarz that for every ν
∣Ξ6(ν, gι, g2)| ≤ 6144KvV, V V i|.
Using the high probability deviations bound established in (E.64), it follows that if n is large enough
then with probability at least 1 - Ce-cn - C0n-2d+1/2
we have
∀ν ∈ [0,∏], ∣Ξ6(ν, gι, g2)| ≤ C00
As long as d ≥ 2, We have that this probability is at least 1 - Ce-Cn - C0n-d, and so the triangle
inequality yields finally that with probability at least 1 - Ce-cn - C0n-d
∀ν ∈ [0,∏], ∣Ξ6(ν, gι, g2)- E[Ξ6(ν, gι, g2)]∣ ≤ CC0
□
Lemma E.47. Consider the function
g(ν) = -(π2 - [(π - ν) cos ν+sin ν]2)[(π -ν) cos ν-sin ν] + (π - ν)2 [(π - ν) cos ν+sin ν] sin2 ν,
which is the negated numerator of 0. Then if 0 ≤ V ≤ π∕2, one has a bound
止V3 - 83-V4 ≤ g(ν),
3	24 - gJ,
and the lower bound is positive if 0 < ν ≤ π∕2.
Proof. To see that the loWer bound is positive under the stated condition, Write
the quantity in parentheses is positive in a neighborhood of zero by continuity, and in fact one
calculates for its unique zero νo = 48π2∕249, and one verifies numerically that 48π2∕249 > 1.9 >
π∕2. We conclude that the bound is positive for 0 <ν< 1.9 by continuity.
To establish the bound, We employ Taylor expansion of the numerator, Which is a smooth func-
tion on (0, π) With continuous derivatives of all orders on [0, π], in a neighborhood of zero. In
our development in the proof of Lemma E.5, We shoWed that the analytic function -g(V) =
-(2∏2∕3)ν3 + O(ν4) near zero, so Taylor,s theorem with Lagrange remainder implies
2π3 V 3 + V4
3	+ 24
inf
ν∈[0,π∕2]
g(4) (V) ≤ g(V),
and so it suffices to get suitable bounds on the fourth derivative of g. We will develop the bounds
rather tediously. Start by distributing in g to write
g(V) = V3 (-cosV) + V2 (3π cos V + sinV) +V cos V - 2π2 cosV - 2πsinV - cos
X---{------} X---------------{--------}	'-----------------------L
g3(V)	g2(V)	g1(V)
+ π cos3 V + 2π2 sin V - sin3 V - π cos V .
X-----------------------------------------------/
3 V)
^^{^™
g0(V)
Using the Leibniz rule, we have for the fourth derivative
g(4) (V) =	V3	g3(4)(V)	+	V2	g2(4)(V)	+ 12g3(3)(V)	+ V	g1(4)(V) + 8g2(3)(V)	+ 36g3(2)
+ g0(4)(V) + 4g1(3)(V) + 12g2(2)(V) + 24g3(1)(V) .
228
Published as a conference paper at ICLR 2021
To calculate these derivatives, we just need to differentiate sin, cos, and their third powers. Write
c(ν) = cos3 (ν) and s(ν) = sin3 (ν); using the elementary calculations
c(1)(ν) = 3s(ν) - 3 sin ν,	c(2) (ν) = 6 cos ν - 9c(ν),
c(3) (ν) = 21 sin ν - 27s(ν),	c(4) (ν) = 60 cos ν + 81c(ν);
s(1)(ν) = 3cosν - 3c(ν),	c(2) (ν) = 6sinν - 9s(ν),
c(3) (ν) = 27c(ν) - 21 cos ν,	c(4) (ν) = 60 sin ν + 81s(ν),
(E.75)
one can calculate the results
g3(4) (ν) = - cos ν,	g2(4) (ν) = 3π cos ν + sin ν,
g1(4) (ν) = (61 - 2π2) cos ν - 2π sin ν - 81 cos3 ν,
g0(4) (ν) = (2π2 - 60) sin ν + 50π cos ν + 81π cos3 ν - 81 sin3 ν;
and
g3(3) (ν) = - sin ν,	g2(3) (ν) = 3π sin ν - cos ν,
g1(3) (ν) = (7 - 2π2) sin ν + 2π cos ν - 27 cos2 ν sin ν;
and
g(2) (v) = cos V g22 (v) = —3π cos V — sin V;
and finally
g3(1) (ν) = sin ν.
Plugging back into (E.75) and canceling, we get
g(4)(ν) = ν3	(―Cos v)	+ v2	(3π Cos v  11sin V)	+ν	(22π Sin V + (89 —	2π2) Cos V  81 cos3
X—{—'	|
h3(ν)
^^{^^
h2(ν)
}|
^z^^^
h1(ν)
V)
.}
+(27 sin3 v + 81π cos3 V + 31π Cos V — (6π2 + 128) sin V).
।---------------------------------------/
^z'∙∕'^
h0(ν)
Since V > 0, we can leverage lower bounds on each hi term. We have trivially |h3 | ≤ 1, so that
|v3h3(v)| ≤ ∏3∕8. WeWillstUdy VhI(V) + h0(v) together to get a better bound. Wehave
VhI(V) + ho(v) = (22πv — (6π2 + 128)) sin V + 27sin3 V + ((89 — 2π2)v + 31π) cos V
+ (81π — 81V) cos3 V
≥ (22πv — (6π2 + 128)) sin V + 27sin3 V + ((89 — 2π2)v + 31π) cos v,
|---------------------------------{-------------------------------}
q(ν)
(E.76)
using v ≤ π∕2 and cos ≥ 0 on this domain. We will show that the RHS of the final inequality,
denoted q, is a decreasing function of V, and is therefore lower bounded by its value at V = n/2 on
our interval of interest. We calculate
q0 (V) = 9π sinV + (42 — 8π2) cos V + 22πV cos V — (89 — 2π2)V sin V — 81 cos3 V.
Reordering terms, we can write
q0(V) =	—81	cos3 V +	9π	— (89 —	2π2) V	sin V —	(8π2	— 42) —	22π V	cos V. (E.77)
U} l-Cz^ )	∖l-cz^ lcz})
We can estimate numerically
69 ≤ C2 ≤ 70; 69 ≤ C4 ≤ 70; C2 > C4 ,
which shows that C1, C2, C3, C4 > 0 and both of the linear prefactors are decreasing functions of
v. We have on all of (0,π∕2) by concavity of sin
(C1
— C2 V) sin V ≤ V
229
Published as a conference paper at ICLR 2021
using in particular Sin V ≤ V and Sin V ≥ (2∕π)ν. Using similarly concavity of cos on this domain,
in particular the inequalities cos V ≤ π∕2 - V and cos V ≥ 1 - (2∕π)ν, we have
-(C3 - C4 V) coS V ≤ -
(C4V2- (2C3+CF)V+C3
In total, we have a bound
q0(V) ≤ -81 cos3 V - (2C2 + C4) V2 + (2C3 + πC4 + Ci) V - C3.
We calculate the maximizer of the concave quadratic function of V in the previous bound via differ-
entiation; plugging in, we get
q0(V) ≤ -81 cos3 V + (2 +C22ζ + C0 - C3.
4 (^∏2 + C4)
A numerical estimate gives
(弩 + 争 +Ci)2
4 (苧 + C4)
- C3 ≤ 20,
and using that - cos3 is strictly decreasing for v < ∏, we can therefore guarantee q0 ≤ 0 as long as
V ≤ cos-1 P20/81. Writing C = cos-1 P20/81, we estimate numerically 0.90 ≥ C ≥ 0.89, so that
this bound is nonvacuous. For V ≥ c, we apply again concavity of cos to develop the lower bound
π∕2 - V
cos v ≥ --------- cosc, v ∈ [c,π∕2].
π∕2 - C
Using this to estimate the - cos3 term in our upper bound for q0, we obtain a bound
q0(V) ≤ -20
V - C3,
C ≤ V ≤ π∕2.
We define D = 20∕(π∕2 - C)3, A = 2C2∕π +C4, B = 2C3∕π + πC4∕2 + C1, andC = C3, so
that the RHS can be written as -D(π∕2 - V)3 - AV2 + BV - C. Differentiating once and equating
to zero results in the quadratic equation
/	ʌ
3D ν2 - (3A + π) V + (3D + π2/4)	=0,
'--{Z--}	'--------} I
MN
which has roots M/2 ± 2 √M2 - 4N. Numerically estimating the constants, we get that the two
roots lie in [0.99, 1] and [3.3, 3.4], so that we need only consider the smaller root. Differentiating
once more to determine the class of the critical point, we find for the second derivative at M∕2 -
1 √M2 - 4N
-3DPM2 - 4N < 0,
so that M/2 - 1 √M2 - 4N is a maximizer for our cubic bound, and the bound is increasing for
arguments less than this point and decreasing for arguments greater than it; we can conclude that the
zero in [3.3, 3.4] is a minimizer, so that our bound can be ascertained negative by checking its value
at M/2 - 1 √M2 - 4N. We find using a numerical estimate
-20
T I________ ∖ 3
n/2 - (M/2 - 2√M2 - 4N) ʌ
2C2
π
n/2 — C	I
(M/2 - 1PM2 - 4N)2
+ (2C3 + πC4 + C) (M/2 - 1PM2 - 4N) - C3 ≤ -1.7 < 0,
230
Published as a conference paper at ICLR 2021
which proves that q0 ≤ 0 on [c, ∏∕2]. This shows that our lower bound on νhι(ν) + ho(ν) in (E.76)
is nonincreasing on [0, ∏∕2], so that We can assert
VhI(V) + ho(ν) ≥ (22π(π∕2) — (6π2 + 128)) sin(π∕2) + 27sin3(π∕2)
+ ((89 — 2π2)(π∕2) + 31π) cos(π∕2)
= 5π2 — 101.
It remains to bound V2h2(V) = V2(3π cos V — 11 sin V). On [0, π∕2], cos is decreasing and sin is
increasing, so 3π cos V — 11 sin V is decreasing here; it is positive at V = 0 and negative at V = π∕2,
so that by continuity it has a unique zero in (0, π∕2). Denote this zero as V0; then using that V2 ≥ 0
with no zeros in the interior, we can write
and
inf	V2h2(V) ≥
νo≤ν≤π∕2
inf
0≤ν≤ν0
V2 h2 (V) ≥ 0,
sup V2
ν0 ≤ν≤π∕2
νo≤iVfπ∕2 h2(V)
≥ (π∕2)2 (3π cos(π∕2) — 11 sin(π∕2))
11π2
4
which gives the bound V2h2(ν) ≥ -11π2∕4 on [0, π∕2]. Putting it all together, We have
g(4)(ν) ≥ — ɪɪn——+ 5π2 — 101 — π3∕8 ≥ —83,
where the last inequality follows from a numerical estimate of the constants.
Lemma E.48 (Uniformization). Let (Ω, F, P) be a complete probability space. For some t ∈ R,
δt ≥ 0, S ⊂ Rd, and event E ∈ F, suppose that f : S X Ω → R is second-argument measurable
and satisfies
1.	For all X ∈ S, P[f (x, ∙) ≤ t] ≥ 1 — δt;
2.	For all g ∈ E, f (∙, g) is L-Lipschitz;
3.	There is M > 0 such that supx∈S kxk2 ≤ M.
Then g 7→ supx∈S f(x, g) is measurable, and for every ε > 0, one has
P sup f(x, ∙) ≤ t + Lε ≥ 1 — δt(1 + ^^) — P[E].
x∈S	ε
(E.78)
Proof. Because S is a subset of the separable metric space (Rd, ∣∣∙ ∣∣2) and all sample trajectories
f (∙, g) are assumed (Lipschitz) continuous, the supremum in the definition of g → suPχ∈s f (x, g)
can be taken on a countable subset ofS, and the resulting function ofg is measurable (e.g., (Ledoux
& Talagrand, 1991, §2.2 p. 45)). By (Vershynin, 2018, Proposition 4.2.12) and boundedness of S,
for every ε > 0 there exists an ε-net of S having cardinality at most (1 + 2M∕ε)d; denote these
nets as Nε . Since each Nε is finite, we may also define for each x ∈ S a point xε such that
∣x — xε∣2 ≤ ε; then for every g ∈ E, we have |f (x, g) — f(xε, g)| ≤ Lε. We define a collection
of events Eε by
Eε = {g ∈ Ω | ∀x ∈ Nε,f(x, g) ≤ t}.	(E.79)
The triangle inequality then implies that ifg ∈ Eε ∩E, then for all x ∈ S, one has f(x, g) ≤ t+ Lε.
Consequently, several union bounds yield
P sup f (x, ∙) > t + Lε
x∈S
≤ P sup f(x, g) ≤ t + P[E]
x∈Nε
≤ δt(1 + =)d + P[E],
(E.80)
as claimed.
□
□
231
Published as a conference paper at ICLR 2021
E.4 Deferred Proofs
Proof of Lemma E.5. The function cos-1 is C∞ on (-1, 1), and because f(V) := cos 0(V) is smooth
and satisfies f0(V) = (π-1V - 1) sinV < 0 if V < π with f(0) = 1 and f(π) = 0, we see that 0 is
C∞ on (0, π) by the chain rule. This also shows s(0) = cos-1(l) = 0 and s(π) = cos-1 (0) = π∕2.
Direct calculation gives
r ( I	(∏ - V)2 sin2 V
S(V) = V ∏2-((∏ -V)cos V + sin ν)2
(E.81)
and
(π2 - [(π - V) cosV + sinV]2)[(π - V) cosV - sin V]
(π2 - [(π - V) cos V + sin V]2)3/2
(π - V)2[(π - V) cosV + sin V] sin2 V
(E.82)
(π2 - [(π - V) cosV + sinV]2)3/2
Calculating endpoint limits using these expressions will suffice to show the derivatives are continu-
ous on [0, π] and give the claimed values there. We have
V&0(S(V))2
(π - V)2 sin2 V
lim---------------------------2
V\0 π2 - ((π - ν) cos v + sin V)
ɪ.	2(π - v) sin v[(π - V)Cos V - sin V]
v&o (-2)[(π - ν) cos v + sin V][cos V - (π - V) sin V - cos V]
(π - V) cos V - sin V
=lim ---------------------= 1,
v&0 (π — v) cos v + sin V
by L'H6pitaTs rule，whereas a direct evaluation gives
lim (S(V ))2 = -02 =0.
ν∖0	∏2
Continuity of the square root function gives the claimed results for S. Again by direct calculation，
we find
lim (S(V))2 =:=0.
ν∖0' ' 7	∏3
Since S2 is meromorphic in a neighborhood of 0 with，as We have shown，a removable singularity
at 0, it is actually analytic, and we can calculate further derivatives at 0 by expanding it locally at 0.
We use the expansions sin V = V - V3∕6 + O(V5) and cos V = 1 - V2∕2 + V4∕24 + O(V6) near 0
to calculate
and
π2⅞3 V2 +O(V3)
3π2
2 (ι- 3Πv - 1 v 2+O(V 3)),
V-
from which it follows
「，、、2	(l 2	π2 - 3
(S(V)) = 1 - -v —
π	3π2
By the geometric series, we then obtain
V2 + O(V3)) (1 - 3∏v - 3V2 + O(V3))
(0(ν ))2
1 - 3∏v + 9⅛V2 + O(V3).
0(V)
—
Taking the square root of this expression and applying the binomial series, we thus have
S(V) = 1 - 2-V -
3π
焉 V 2 + O(V 3),
6π2
from which we read off
V&00(V)
lim .0..(V)
V&0
1
3π2.
—
2
3∏;
—
232
Published as a conference paper at ICLR 2021
It is clear from the analytical expression for S and the mean value theorem that φ is strictly increasing
on [0, π], since (π - ν) sin ν > 0 if 0 < ν < π. To prove strict concavity for ν ∈ (0, π), we start
by simplifying notation. Consider the function Sr(ν) = S(π - ν), which satisfies by the chain rule
Sr (V) = S(π - V). Because Sr is strictly concave if and only if S is strictly concave, it suffices to
prove that S(∏ - V) < 0. We note
S(π — v) < 0 ^⇒ (π2 — [ν cos V — Sin V]2)(- Sin V — V cos V) < ν2 sin2 V(Sin V — V cos V).
Multiplying both sides of the latter inequality by sinV - Vcos V, dividing through by (V cos V -
sin V)2 (which is positive on (0, π), since it equals cos2 S composed with a reversal about π), and
distributing and moving terms to the RHS gives the equivalent condition
π2
V2 cos2 V — sin2 V
(V cos V — sin V)2
< V2 — sin2 V,
and canceling once more gives equivalently
V cos V + sin V	V2 — sin2 V
--------;—< ------2——
V cos V — sin V	π2
(E.83)
Using Vcos V — sin V < 0, which follows from its derivative —V sin V being negative on (0, π), and
writing g(V) = π-2 (V2 — sin2 V), we have equivalently V cos V + sin V > g(V)(V cos V — sin V), and
rearranging gives the inequality
(1 — g(V))V cos V + g(V) sin V > — sin V.	(E.84)
Strict concavity of sin on (0, π) gives sin V < V, and 0 < g(V) < 1 follows after squaring; so the
LHS is a convex combination of Vcos V and sin V, which in particular satisfies |(1 — g(V))Vcos V +
g(V) sin V| ≤ max{|sin V|, |V cos V|}. As argued before, we have sin V — V cos V > 0 if V ∈ (0, π);
moreover, because v > 0 We have V cos v > 0 if V ∈ (0,π∕2) and V cos V < 0 if V ∈ (π∕2,π). We
can numerically determine sin(5π∕8) + (5π∕8)cos(5π∕8) > 0, and given that 5π∕8 ≥ 1.95 〉 π∕2,
it folloWs
|(1 — g(V))Vcos V + g(V) sin V| < |sin V|,	0 < V ≤ 1.95,
Which implies (E.84) When 0 < V ≤ 1.95. Recalling that We are arguing for Sr in this setting, We
translate our results back to S and conclude that S(V) < 0 if π — 1.95 ≤ V < π. To address the
case where 0 <v<∏ — 1.95, we employ Lemma E.47; it allows us to conclude S < 0 provided
0 < v ≤ ∏∕2, and a numerical estimate gives that ∏ — 1.95 ‹ ∏∕2, so that we have S < 0 for all
0 < V < π. Taking limits in S gives concavity at the endpoints {0, π} as well.
To bound S away from zero on [0, ∏∕2], we apply Lemma E.47 to assert
-ɪ v3 + -8⅛ V 4
S(V) ≤ ^n---------24π⅛^, 0 < V ≤ π∕2.
(1 —cos2S(V))3/2
The numerator in the last expression is nonpositive if 0 ≤ V ≤ π∕2, and using the lower bound in
Lemma E.14 on [0, π∕2], we have
1
1
1 — cos2 s(v) ~ 1 — max2{1 — 1 v2,0}， v〉°.
From nonpositivity of the numerator, it follows
_J_ v3 + _83_ V 4
S(V) ≤ -----3π_^24π3-----
(1 — max2{1 — 1V2, 0})
3/2 ,
0 < V ≤ π∕2.
(E.85)
We have 1 — 2 v2 ≥ 0 as long as 0 ≤ V ≤ √2; so after removing the max, distributing, and
cancelling, we have
__L + _83_ V
S(V) ≤「1 243/2 , 0 <V ≤√2.
(1 — 4 V2)
The denominator of this last expression is nonnegative and has singularities at ±2, and is clearly
even symmetric; so it is maximized on 0 < v ≤ √2 at √2, and we have
,.	2(	2	83	、	_	L
S(V) ≤ √8 —— + V ,	0 < v ≤ √2∙
3π	24π3
233
Published as a conference paper at ICLR 2021
Taking limits V & 0, we can assert this bound on [0, √2], and the bound is clearly an increasing
function of V, from which it follows
SUp0(V) ≤ √8--2-+8342)≤ -0.15,
ν∈[o,√2]	∖ 3n	24n3y
where the last inequality follows from a numerical estimate of the constants. On the other hand,
when √2 < v ≤ n/2, we have from (E.85) that
2 .	83	. 一
0(V) ≤ 一1V + ν ,	√2 ≤ V ≤ n∕2∙
3n 24n3
Ifwe differentiate the degree four polynomial on the RHS of this bound and solve for critical points,
we find a double critical point at V = 0 and a critical point at V = 12n2/83; a numerical estimate
confirms that this critical point lies in the interior of [√2, n/2]. The second derivative of the RHS
is -(4/n)V + 83/(2n3)V2, and plugging in V = 12n2/83 gives a value of -48n/83 + 144n/83,
which is positive; hence the RHS is maximized on the boundary, i.e.,
,、	2 o 83 4	2 25/2	83 n2	83n ] 厂	,
0(ν) ≤------ν3	H---v4	≤ max<-------1——-,-----1----,,	√2	≤ V ≤ n/2.
0( ) — 3n	+ 24n3	— I 3n +6n3, 12 + 384 l,	/
A numerical estimate shows that the RHS of the last inequality is no larger than -0.14. Since the
intervals we have proved a bound over cover [0, n/2], this proves the claim with C = -0.14.
The bound 0 < 1 on (0, n) follows from the fact that φ is strictly concave on (0, n) and the mean
value theorem; we have already shown 0 > 0 in proving strict increasingness of 0. Similarly, the
proof of strict concavity in the interior has already established 0 < 0. To obtain the lower bound on
0, we use that 0 is continuous on [0, n] and the Weierstrass theorem to assert that there is C ≥ 0
such that 0 ≥ -C on [0, n]; because 0(0) = 0, we actually have C > 0.
For the quadratic model, we use our previous results and Taylor expand 0 about 0; we get immedi-
ately
2 infν∈[0,∏] 0(V)
夕(V) ≥ V + ν
≥ V - (C/2)V2.
2
For the upper bound, we can assert immediately on [0, n/2] a bound
0(V) ≤ V - cV2,
where C = 0.07 suffices. To extend the bound to V ∈ [n/2, ∏], We employ a bootstrapping argument;
because 0 is concave, we have a bound
0(v) ≤ 0(n/2) + 0(n/2)(v - n/2)
=cos-1 n-1 + / ?2 1 (v - n/2),
n2 - 1
where the second line plugs into the formulas for 0 and 0. We will show that the graph of V - cv2
lies entirely above the graph of the RHS of this inequality. This condition is equivalent to
-CV2 + (1 - T2 ) v + ( (n/2)2 - cos-1 n-1) ≥ 0;
V √n2-ι) v√n2-ι	)一
the LHS of this inequality is a concave quadratic with maximizer v? = 1/(2c)(1 - √∏2-ι), and
numerical estimation of the constants gives V? ≥ n. Since V? is outside [n/2, n] and the quadratic is
concave, we conclude that the bound is tightest at the boundary point n/2, and one checks numeri-
cally
-cn2/4 + (l -√n=) n/2 + (√n/== - cos-1 n-1) ≥ 0.15 > 0,
n2 - 1	n2 - 1
which establishes that the bound 0(V) ≤ V - CV2 actually holds on all of [0, n]. This completes the
proof of all of the claims.	□
234
Published as a conference paper at ICLR 2021
F Controlling Changes During Training
F.1 Preliminaries
We now consider the changes in the integral operator Θk during gradient descent. In this section
we restore the iteration subscript (that is dropped in other sections to lighten notation) to various
quantities. Θk changes during training as a result of both smooth changes in the features at all
layers and non-smooth changes in the backward features {β'(x)} due to the non-smoothness of the
derivative of the ReLU function.
Because of the difficulty of reasoning precisely about the changes in Θt, we will bound these rather
naively by controlling Θt over all possible support patterns of the features given a bound on the
norm change of the pre-activations.
We now define a trajectory in parameter space that interpolates between the iterates of gradient
descent, given for any k0 ∈ {0, . . . , k} and s ∈ [0, 1] by
θN+s = θN -TSjLn(θN),	(F.1)
(with the formal derivative j defined in Appendix A.1). We will henceforth use k0 to denote an
integer indexing the iteration number and t to denote a continuous parameter taking values in [0, k]
(such that k0 = btc , S = t - btc ). Quantities indexed by t are ones where the parameters take
the value θtN . To lighten notation, we will drop the N superscript when referring to time-indexed
quantities (aside from ζkN and ΘkN ), but all such quantities depend on the parameters as defined by
(F.1).
Instead of considering the change in the features {α'(x)} directly, it will be more convenient to
work in terms of the pre-activations, which are given at layer ` by
ρ'(x) = W' Pi'-ι,t (χ)Wt'-1Pi'-2,t (χ)Wt'-2... Piι,t(χ)Wt1x.
We define a maximal allowable change in the pre-activation norm by
η
(F.2)
for q ≥ 0 and a constant Cη to be specified later, where the scaling is chosen with foresight. We can
then define a maximal number of iterations such that the pre-activation norms at all layers along the
trajectory (F.1) change by no more than η. This number kη must satisfy
SUp	∣∣ρ'(x)- PO(X)I∣2 ≤ η	(F.3)
t∈[0,kη ],x∈M,'∈[L]
for η given by (F.2). Our goal will be to show that we can in fact train for long enough so as to
reduce the fitting error without exceeding kη iterations.
F.2 Changes in Feature Supports During Training
Recalling the definition of the feature supports at layer ', time t and X ∈ M by I',t(x) =
supp(α'(x) > 0) ⊆ [n], we denote by Zt(X) = (I1,t(x),..., lL,t(x)) the collection of these
support patterns at all layers. We would next like to relate the smooth changes in the pre-activation
norms to the non-smooth changes in the supports of the features. We denote by J = (J1, . . . , JL)
a collection of support patterns with Ji ∈ [n]. We now consider sets of support patterns that are not
too different from those at initialization, as defined by
B(y, η) = {supp (y + v > 0) | kvk2 ≤ η} ,	(F.4)
Jη(X)=㊈ B(ρ0(x),η),	(F.5)
'∈[L]
Jη(M) = U Jη(x).	(F.6)
x∈M
Note that B(ρ0(x), η) is simply the set of supports of the positive entries of ρ0(x) + V for every
possible perturbation v of norm at most η. We consider all possible perturbations due to the complex
235
Published as a conference paper at ICLR 2021
nature of the training dynamics. As a result of this worst-casing, the scaling we will require of the
depth and width of the network in order to guarantee that the changes during training are sufficiently
small is expected to be suboptimal.
For a given general support pattern J , we define generalized backward features and transfer matrices
βJt =	(w^Nl+1Pjl WNL... WtN'+2Pj'+ι) *,
Γ Jt0 = WePJ'_1 WN'-1... Pj`o WN'0
(F.7)
where the weights are given by (F.1) (and thus β'(x) = βN'χ)t). By controlling these objects for
every possible set of supports J that can be encountered during training, we can control the smooth
changes in the features themselves. A first step towards this end is understanding how many such
support patterns we expect to see given the constraint in (F.2).
In order to bound the number supports that can be encountered during training, we need to control
the diameter of B(ρ0(x),η). This can be done by defining
δη(PO(X)) = "max 卜UPP(PO(X) > o) θ SUPP(PO(X) + V > o) ∣	(F.8)
kvk2≤η
where θ denotes the symmetric difference. Since the Pre-activation at a given layer are GaUssian
variables conditioned on all the previous layer weights, bounding the size of δη (PO(X)) can be
redUced to showing concentration ofa certain fUnction of GaUssian order statistics. This is achieved
in the following lemma :
Lemma F.1. For η given by (F.2), if n, L, d satisfy the requirements of lemma F.6 and n > d5 for
some constant K, then for a vector g ∈ Rn, gi 〜以 N (0,1) we have
P [δη (g) > Cnη2∕3] ≤ C0e-cd
for some constants c, C, C0.
Proof. Let
|g|(1) ≤ |g|(2) ≤ …≤ |g|(n)
denote the order statistics of the magnitudes of the elements ofg. We will show that bounding δη(g)
can be reduced to understanding what is the smallest k such that
|g|2i)+	+ |g|2k)≥ η2.
We denote this value of k by kη. Define indices ji by |gJi | = |g|(i) (and breaking ties arbitrarily in
case several order statistics are equal). To see that
kη - 1 ≤ δη (g) ≤ kη	(F.9)
kη-1
it suffices to note that since P |g|(2k) < η2 one can choose ε > 0 small enough such that
i=1
kη-1
y = g -	(1 +ε)gJieJi ∈ BE (g, η),
i=1
which will give ds(g, y) = kη - 1 ⇒ δη ≥ kη - 1. To Prove the second inequality, consider
δη
y = g - gJi eJi. Clearly for any y0 such that ds(g, y0) = δη we have kg - yk2 ≤ kg - y0k2.
Since there exists at least one such y0 ∈ BE (g, η), it follows that kg - yk2 ≤ kg - y0k2 ≤ η, and
hence the smallest k such that P ∣∣g(i) ∣∣2 ≥ η2 must obey k ≥ δη.
i=1
For η defined in (F.2), we can satisfy the requirement on η in lemma F.6 by requiring n > d5 for
some K. APPlying this lemma, we find that there is a constant K0 such that for k = K0nη2∕3 we
have
k
P X |g|(2i) ≥ η2 ≥ 1 - C0e-cd
i=1
236
Published as a conference paper at ICLR 2021
from Which it folloWs immediately that
Phkn ≤ ∖KO0nη2r3mi ≥ 1 - C0e-cd.
Choosing some constant C such that ∣-K0nη2∕3] ≤ Cnη2/3 and using (F.9) allows us to bound
□
δη(g) with the same probability.
With this result in hand, We can control the objects in (F.7) for all the supports in Jη (M).
Lemma F.2. Assume d, L, n satisfy the assumptions of lemmas D.2, F.1, D.8, D.14 and additionally
n ≥ maxnKdL9+2q,K0(logn)3/2 ,C03Cη2L6+2qo ,
for some constants K, K0 , C0, where q is the constant in (F.2).
Then
i)for η, Jn(x) defined in (F.2),(F.5), on an event ofprobability at least 1 一 e-cd, simultaneously
SUP sup sup I∣ρ0(x)∣∣2 ≤ C2,
x∈MJ∈Jn(x) '∈[L]
1≤'0<'
sup sup sup ∣lβ'j"1∣l ≤ C2√n,
x∈MJ∈J n (x) '∈[L] 11	, 112
1≤'0<'
sup sup sup ∣∣ΓJ'0l ≤ C2√L.
x∈MJ∈J n (x) '∈[L] 11	, 11
1≤'0<'
ii)	for Tη defined in (F.3), on an event of probability at least 1 - e-cd,
SupT	MI-(X),0 -βi-(X),0∣∣2 ≤ CCη/3 lo/LiL3+2^5/12
x∈	, ∈[ , η], ∈[ ]
for some constants c, C.
Proof. Deferred to F.5.
□
F.3 Changes in Features During Training
We can now bound the smooth changes during training:
Lemma F.3 (Smooth changes during training). Set the step size τ and a bound on the maximal
number of iterations kmax such that
k _ Lq
kmaxτ =------
n
for some constant q. Assume n, L, d satisfy the requirements of lemmas F.2, and in particular n ≥
KdL9+2q for some K. Assume also that given some k ≤ kmax - 1, for all k0 ∈ {0, . . . , k},
∣∣ζN∣∣L2 ≤ c√d.	(F.10)
μN
Then on an event of probability at least 1 - e-cd, one has simultaneously
sup	∣∣ρko(X)-PO(X)∣∣2 ≤ C0L3∕2+q©,
x∈M,'∈[L], k0∈{O,...,k + 1}	Y n
sup	(∣∣βk- 1(x) -β'-1(x)∣∣2 - ∣∣βI-0l0(x) -βI-01(x)∣∣ ) ≤ C0√dL3”,
χ∈M,'∈[L], k0∈{O,...,k+1} v	11 k	1127
for some constants c, C, C0.
237
Published as a conference paper at ICLR 2021
Proof. We will bound the smooth changes in the network features during gradient descent with
respect to either the population measure μ∞ or the finite sample measure μN. We denote a measure
that can be one of these two by μN.
For any collection of supports J ∈ Jη (M), define generalized backward features and transfer
matrices at t by βJt, Γ Jt. These are obtained by setting the network parameters to be θN according
to (F.1), but setting all the support patterns to be those in J.
We then define for any t ∈ [0, k + 1],
Pt	=	SUp	∣∣ρ'o (X)-PO(X)∣∣2 +	SUp	∣∣p0(X)Il2,
χ∈M,'∈[L],t0∈[0,t]	χ∈M,'∈[L]
βη	=	上Up	∣∣βJto- βJ 0∣∣2 + SUP	∣∣βJ 0∣∣2,
'∈[L],J∈J η (M),t0∈[0,t]	'∈[L],J∈J η (M)
Γ =	Sup	∣Γ JO- Γ j`0 ∣∣ + sup_	∣∣ΓJ
'0≤'∈[L],J∈Jη(M),t0∈[0,t]	'0≤'∈[L],J∈Jη(M)"
(F.11)
We have for all k0 ≤ k + 1,
∣∣ρko(X)- P0(x)∣∣2 ≤PtO-Pt,	(F.12)
while
∣∣β' o(X)- β'(X)∣∣2	=∣∣βiko(χ),k0 -βi0(χ),0∣∣2
≤ ∣∣βiko(χ),k0- βiko(χ),0∣∣2 + ∣∣βiv(χ),0 - βi0(χ),0∣∣2	(F.13)
≤βk0- βη + ∣∣βiMx),。-β0(χ),0∣∣2.
It follows that we can control the difference norms of the pre-activations and backward features
by controlling the magnitudes of ρto ,βto. In order to control these, we also note that for any t ∈
[0, k + 1],
∣∣α'(X)∣∣2 ≤ ∣∣ρ'(X)∣∣2 ≤ ∣∣ρ'(X)- ρ0(X)∣∣2 + ∣∣ρ0(X)∣∣2 ≤ Pn,	(F.14)
and similarly
∣∣βjt∣∣2	≤βn,
∣∣γJ0∣∣	≤rn.
(F.15)
In particular, the above bounds hold when J = It (X). We would now like to understand how the
quantities (ρt,, βto, Γto) evolve under gradient descent. Towards this end, for any k0 ∈ {0,...,k}
and s ∈ [0, 1] we compute at any point of differentiability
0
∂s ρk0+s(X)
〜 C .
∂p'(x)
-T ∂θ
*
十 L (θN)
θlst q LN (θkN)
*
W))十LN(θN)
(⅛⅛
-TI 一∂θ
-XXXTX ∂ρko+s(x) ∂LN(θN)
T ⅛1 j=11=1	d吗	dWii
`
-TX /	Sk-+s(x), αk- 1(x0)) Γk朋 1(x)Pii,k0+s(χ)βk- 1(X0)ZN(x0)dμN(x0).
i=1 xO ∈M
238
Published as a conference paper at ICLR 2021
Using (F.14) and (F.15) then gives
Λ
∂SPk0+s(x)	≤τL(Pk，+s) βk0+srk0+s / ∣ζN(XO)IdμN(XO)
2	x0∈M
ML®，+S) β Z+sΓ‰s I**
μN
≤ C√dτL (Pk0+s)2 βZ+s^0+s,
where we used Jensen’s inequality in the second line and our assumption that the error up to iteration
k has bounded Lj^ norm, and We additionally assumed P ,β, Γη ≥ 1. Arguing as in the proof of
Lemma B.8 for absolute continuity, it follows that
btc-1	I	I
∣∣ρ'(X)-PO(X)II2	≤ X ||pk，+i(X)-Pko(x)||2 + ∣∣ρ'(χ)-Pbtc(X)|「
k0=0
btc-1
+s
k0=0
0
btc-1 1 I
≤X Z IIII
k0=0 0 I
(X)dsI +
I)
Λ
∂s ρk0+s(X)
ds +
)
It-btc
IIII Z
I0
t-btc
Z
0
0
∂S Pbtc+s(x)ds
λ
∂Spbtc+s (X)
ds
)
(F.16)
≤c √dτtL (ρ? )2 βη rη
Since the above holds for all choices of X, ` simultaneously, We conclude that
褶-P ≤ C√dτtL (P)2 βηΓη.
(F.17)
An analogous calculation for the other quantities in (F.11) gives the folloWing set of coupled differ-
ence inequalities:
(pη - ρo ∖	( pη ∖
βη - β	≤ C √dLτtρo βθ ΓO	βη
∖γ: - τoJ	山
Instead of solving (F.18), we obtain sufficient control by defining k* s.t.
(F.18)
∀t ∈	[0,k*]	:	PO	≤	2p0	∧	βη	≤	2β0	∧ Γ ≤ 2Γ0.	(F.19)
For any t ∈ [0, k*], we obtain a sufficient condition for satisfying the above constraint using (F.18),
namely
PO + C0√dτtL (PO)2 βΓO ≤2ρO
1	(F.20)
⇔ Tt ≤------------f f
-C 0√dLρθ βO ΓO
for some constant C0. Using the bounds for βl° - βo and Γ° - Γ° in (F.18) to satisfy the second and
third condition in (F.19) gives an identical constraint on τt.
In order to control these quantities at t = 0 we define an event
G=
χ∈M,
J∈J η (x),
1≤'0≤'∈[L]
{ PO(X)U2 ≤ C2}
∩ { βJ,1 2 ≤ C2√n}
∩ n γ j`o ≤ C2√Lo,
(F.21)
the probability of which can be controlled using lemma F.2. On G, the upper bound on τt in (F.20)
is at least
1	、	1
C0√dLρ°βOrO ≥ C00√dL3/2√n.
(F.22)
1
~
X 片 Pko
0
)
239
Published as a conference paper at ICLR 2021
for some C00 .
We would now like to pick τkmax, and ensure that any t ∈ [0, k + 1] satisfies the constraint above if
k + 1 ≤ kmax. The analysis also assumes that τ kmax ≤ Tη for which (F.3) holds. We will then pick
the scaling factor Cη for the pre-activation norm bound in (F.2) in order to satisfy that constraint as
well. We choose
TkmaX = ---.	(F.23)
n
In order to ensure that kmaχ ≤ k holds, We use (F.20) and (F.22), and require
Lq /	ι
^n ≤ C00√dL3r2√n
Which is satisfied by demanding n ≥ KdL3+2q for some constant K. Using (F.17) and (F.22), on G
We have
SUp	∣∣ρ'(x)- PO(X)I∣2 ≤ρη - ρη
t∈[0,k+1],x∈M,'∈[L]
≤ C 0τt√dL (P )2 βη γ
≤ C00τt√*3/√
≤ C00τkmaχ√dL3/2√n.
In order to ensure that kmaX ≤ kη We therefore require
C00τkmaχ√dL3∕2√n ≤ η,
Which using (F.2) and (F.23) is equivalent to
C 00 √dLq+3/2
√n
Lq+3/2
≤ Cn -=
and thus the constraint can be satisfied by choosing Cn = C00√d. Note that the constant C2 in (F.21)
(Which enters C 00) is set in lemma F.2 Which takes Cη as input (despite this, C2 is independent
of Cn). This lemma holds as long as n ≥ C03Cn2L6+2q, Which We can guarantee by demanding
n ≥ C0 (√C00)2 L6+2q.
We have thus ensured that our choice of kmaχ satisfies kmaχ ≤ min {k*,kn}. We then obtain from
the constraints in (F.19), the inequalities in (F.18) and the definition of G, that on this event
ʌ/dr 3/2+q
SUp	矶0 一 Pn ≤ C00τkmaχ√dL3∕2√n ≤ C00--------『—,
k0∈{0,...,k+1}	n
sup	EkO- β ≤ C00TkmaxVdL3/2n ≤ C00 VdL3/2+q.
k0∈{0,...,k+1}
Then using (F.12) and (F.13), We obtain on an event of probability at least 1 - e-cd simultaneously
sup	11 Pio (X)-PO(X) ∣∣2 ≤ C 0L3/2+qJd
x∈M,'∈[L], k0∈{0,...,k + 1}	Y n
sup	(∣∣βk- 1(x)	-β'-1(χ)∣∣2	- ∣∣βI-00(χ)	-βI-01(χ)∣∣J	≤ C0√dL3∕2+q.
χ∈M,'∈[L], k0∈{O,...,k+1}	'	11 k	1127
□
The combination of the last tWo lemmas alloWs us to control the changes in all the forWard and
backWard features uniformly:
240
Published as a conference paper at ICLR 2021
Lemma F.4. Assume n, L, d, k satisfy the requirements of lemmas F.2 and F.3, and additionally
n ≥ KL36+8qd9 for some K. Then one has simultaneously on an event of probability at least
1 - e-cd
sup	∣∣α'(x)-α0(χ)∣∣2 ≤ CL3/2+qJd
χ∈M,t∈[0,k+1],'∈[L]	V n
sup	∣∣β'-1(x) - β'-1(x)∣∣2 ≤ Clog3/4(L)d3/4L3+2q/3n5/12,
x∈M, t∈[0,k + 1],'∈[L]
sup	∣∣α'(x)∣∣2 ≤ C,
x∈M,t∈[0,k+1],'∈[L]
sup	∣∣β'-1(x)∣∣2 ≤ C√n,
x∈M,t∈[0,k+1],'∈[L]
for some constants c, C.
Proof. Combine the results of lemmas F.2 and F.3 and take a union bound, using the triangle in-
equality to obtain the second two bounds. The assumption n ≥ KL36+8qd9 is required in showing
∣∣β'-1(χ)∣∣2 ≤ C√n.	□
F.4 CHANGES IN ΘkN DURING TRAINING
With these results in hand, control of the changes in ΘkN during training is straightforward.
Lemma F.5 (Uniform control of changes in Θ during training). Denoting the gradient descent step
size by τ, choose some kmax such that
k — Lq
kmaxτ =-----
n
for some constant q. Assume also that given some k ≤ kmax - 1, for all k0 ∈ {0, . . . , k},
∣∣ZN∣∣L2 ≤√d.	(F.24)
μN
Define
L-1
θ(x, XO) =(aL(X), αL(x0» + P (α0(x), α0(χ0"<β'(X), β'(χ0”,
'=0
∆N =	sup	∣ΘN0(x, x0) - Θ(x, x0) I .
(x,x0)∈M×M,
k0∈{0,...,k}
Assume n	≥ KL36+8qd9,d ≥ K0d0 log (nn0CM) for constants K, K0. Then on an event of
probability at least 1 - e-cd
∆N ≤ Clog3/4(L)d3/4L4+2q/3n11/12
for some constants c, C.
Proof. Recall that
ΘkN(x, x0)
1
Z
s=0
_ ~ .
∂fθ (x)
∂ θ
_ ~
f (X)
∂θ
θN	θN
k+s	k
(x), αk (x0)〉Bk+s(x), β (x0)〉ds
with the convention βtL(x) = 1 for all t, x, and the parameters θtN given by (F.1). We thus have
∣∣ΘkN(x,x0) - Θ(x,x0)∣∣ ≤ XZ
'=0S=0
<αk+s(x), αk (x0)〉<β'+s(x), β'(x0)>
-<α0(x), α0(x0)> <β' (x), β' (x0)〉
ds.
241
Published as a conference paper at ICLR 2021
We consider a single summand in the above expression. On the event defined in lemma F.4, for all
x, x0 ∈ M, ` ∈ {0, . . . , L},
Kak+s(X), αk(XO)〉Bk+s(X), β (XO)〉-〈a0(X), α0(XO)〉(β'(X), β'(XO)〉|
(Kak+s(X)- a0(X), ak(X0)〉Gk+s(X), βk(X0)〉|、
≤	+ Ka0(X), ak(XO)- a0(X0)) (β'+s(x), β' (x')>∣
一+ Ka0(χ), a0(χ')> 回+s(X)- β'(X), β (xO)〉|
1+ Ka0(χ), a0(xO)〉(β'(X), β'(XO)- β'(xO)〉|	)
≤C n n∣∣ak+s(X)- aO(X)Il2 + n∣∣ak(XO)- a0(χ')∣∣2	!
—l+√n∣∣βk+s(χ) -β'(X)∣∣2 + √n∣∣βk(XO)-β' (XO)IIj
≤Co(L3/2+q√dn + log3/4(L)d3/4L3+2q/3n11/12)
≤COO log3/4(L)d3/4L3+2q/3n11/12,
for some constants. Summing this bound over ' gives the desired result.	□
F.5 Auxiliary Lemmas and Proofs
Lemma F.6. Consider a collection of n i.i.d. variables Xi = g2,gi 〜N(0, n1) and denote the
order statistics by X(i)(so that X⑴ ≤ X(2)...). For any d ≥ Ko log n, n ≥ KOOd3, η > Cnd3∕4
and integer Knη2^3 ≤ k ≤ n, where K, Ko, Koo are appropriately chosen absolute constants, we
have
k
P XX(i) ≥ η2 ≥ 1 - COe-cd,
i=1
where c, C, CO are absolute constants.
Proof. We will relate sums of order statistics ofXi to functions of uniform order statistics and show
that these concentrate. We denote the CDF of the Xi and its inverse by F and F -1 respectively. We
use
(X(1),..., X(k)) =d(F-1(U(1)),...,F-1(U(k)))
where U(i)are order statistics with respect to Unif(0,1) (David, 2011). Since Xi 〜 n匕,Yi 〜 χ2
we have
nx
F (X)= erf(ʌ/ɪ)
F-1(t) = 2(erf-1(t))2 ≥ c012
nn
where in the inequality we used the series representation of erf-1. This gives
kk	k
XX(i) = XFT(U⑴)≥ nXUE
i=1	i=1	i=1
The joint PDF of the first k order statistics for any distribution admitting a density is given by
f(1)...(k)(x1, ..., xk)
n!
(n — k)!
k
(1 - F(xk))n-k Yf(xi)
i=1
242
Published as a conference paper at ICLR 2021
where x1 ≤ x2 ≤ ... ≤ xk (David, 2011). Applying this to the uniform order statistics, we can
compute the mean of the summands
EU(2i)
u2 uk 1	1
n!	2	n-k	n!i(i + 1)	k+1	n-k
= (n-k! J …JJ u∙ (I-Uk)	duk …du1 = (n - k)!(k +1)! J Uk	(I-Uk)	duk
i(i + 1)
(n + 2)(n + 1)
k
EXU(2i)
i=1
k(k + 1)(k + 2)	Cik3
3(n + 2)(n + 1) ≥ n2
In order to show concentration, We appeal to the Renyi representation of order statistics (BoUcheron
k
et al., 2012). This allows Us to write P U(2i) as a Lipschitz fUnction of independent exponential
i=1
random variables, and we can then apply standard concentration resUlts for sUch fUnctions (Tala-
grand, 1995). This representation is dUe to a UsefUl property UniqUe to the exponential distribUtion
whereby the differences between order statistics are independent exponentially distribUted variables
themselves when properly normalized.
If we define by Ei , ..., En a collection of independent standard exponential variables, the Renyi
representation of the Uniform order statistics gives
(U(i), ..., U(k)) =d (1 -exp
E),...,1 - exp (-xX n—‰ )).
We now trUncate the (Ei , ..., Ek ), so that w.p. P ≥ 1 - ke-K we have ∀i : Ei ∈ [0, K], and
k
denote this event by EK. Using K < n, it is evident that P Ui) is equal in distribution to a convex
i=i
function of (Ei , ..., Ek ) after truncation (which can be seen by calculating second derivatives). The
Lipschitz constant of this function is bounded by n4kk = λ.
If we define rescaled variables Ei = λEi then with the same probability they take values in [0, Kλ].
k
_ 〜
〜
=1
U(2i) written in terms of Ei is now 1-Lipschitz and convex, and we can apply Talagrand’s concen-
tration ineqUality (Talagrand, 1995) to obtain
Setting t = 5n⅛
k
X1EK
i=i
ci k2(n-k)
-8n2K-
- E1EK
U21U≥ ≥ tKλ ≤ C exp (—ct2).
=1
, if we now assUme
C2nη2/3 ≤ k ≤ c0n
P
k
for some c0 < 1 we obtain
k
k
P
=1
1EK U(2i) -E	1EK U(2i)
=1
Cik3
≥ ^2ny
≤C exp (-n⅛) ≤C exp (-
c00n2η8/3
K2
We would also like to ensure that the truncation does not cause a large deviation in the mean. We
have
kk
E XU(2i) - 1EK XU(2i)
{U(i)} i=i	i=i
忠士 (1 - exp (-XX nj
i=i	j =i
=1
1EK	1-exp -
j=1
Ej
n-i+1
k

2
243
Published as a conference paper at ICLR 2021
2
lk
≤	{EEi }1Em >k
m=1{ i}	i=1
「exp (-占 n⅛
l
≤ k X	{EE }1 Em>K = k2 E 1E1>K
m=1{Ei}	{Ei}
k2e-K.
k
Since we would like this to be small compared to EP U(2i)
i=1
≥ c1k23 We can require K > log 4n2
n	c1k
kk
Which gives E P U(2i) - 1EK P U(2i)
{U(i)}i=1	i=1
< C1n3. We can then choose the constant c2 such that with
probability P ≥ 1 一 exp (log k 一 K) 一 C exp (— CnK28，3
kk
xX(i)≥ n ιEκ XU% ≥ 三
i=1	n i=1	n
C0
n
k	c k3	k	k
EXU(i) - %T + E1EK XUi)- EXU(i))
i=1	i=1	i=1
≥ c0c1k3
≥	4n2
≥ η2.
The upper bound on k can then be removed since the inequality then applies to all larger k automat-
ically. If we now set η according to equation (F.2), and choose K = d ≥ K0 log n and n satisfying
n ≥ K00d3 for appropriate constants K0 , K00 we obtain
k
P XX(i) ≥ η2
i=1
≥ 1 一 exp (log k 一 d) 一 C exp 一
cC8/3L4+8q/3n2/3
d2
≥ 1 一 C0e-C00d
and due to our choice of η, this result holds for all k ≥ Cnη2/3 ≥ CC^3n2/3L1+2q/3.	□
Proofoflemma F2. i) We begin by controlling the pre-aCtivatiOn norms. Considering a point X ∈
Nn-3 n-1/2, where Nn-3n-1/2 is the net defined in Appendix D.3.1, rotational invariance of the
Gaussian distribution gives
I∣ρ0(x)∣∣2 = α0τ*(x)w'*w0⅛0T(x) = 30T(x)∣∣2∣∣(w')("iJ∣2
where (W0f)( 、is the first column of W'. Bernstein,s inequality then gives
(:,1)
P [∣∣P0(X)∣∣2 ≤ C∣∣α0T(X)∣∣2i ≥ 1 — C0e-cn
for appropriate constants. As discussed in Lemma D.8, ifwe choose d to satisfy the requirements of
this lemma then N 3 -1/2 ≤ eC00d for some constant. We can then uniformize over the net using
n-3n0
a union bound, obtaining
P [∀X ∈ Nn-3n-1/2 :	∣∣P0(X)∣∣2 ≤ C I∣α0-1(X)∣∣2] ≥ 1 — C0eC"d-cn ≥ 1 一 Ce-F
for some c0, assuming n ≥ Kd. We now need to control the feature norms and pre-activation norms
off of the net. From (D.62) and lemma G.10 we obtain that for d satisfying the requirements of
lemma D.9,
-	Vx ∈M,' ∈ [L] : ∃χ ∈ Nn-3n-ι∕2 ∩Nn-3n-1∕2(x)	-
P	s.t. 0	0	≥ 1 一 e-Cd.
一 {∣∣ρ0(X)-ρ0(χ)∣∣2 ≤ Cn-5/2} ∩ {∣∣∣α0-1(X)∣∣2 -1∣ ≤ 1} _
By taking a union bound over the above two results, we obtain
P [Vx ∈ M,' ∈ [L]:	∣∣ρ0(x)∣∣2 ≤ C] ≥ 1 — C0e-c0d	(F.25)
244
Published as a conference paper at ICLR 2021
for some constants
We next turn to controlling the generalized backward features and transfer matrices. Our first task is
to bound the number of support patterns that can be encountered, namely ∣ Jη(M)∣. In order to do
this it will be convenient to introduce a set that contains Jη (M) and is easier to reason about. We
define a metric between supports by
dsupp(S,S0) = ∣S ㊀ S0I
and denote by Bs(S, δ) ⊂ P([n]) a ball defined with respect to this metric, where δ ∈ {0} ∪ [n] and
P(A) is the power set ofa set A. For δη(y) and B(y, η) defined in (F.8) and (F.4) respectively, it is
clear that
B(y, η) ⊆ Bs(supp(y > 0), δη(y))
and consequently
Jη(M) ⊆ U 0 Bs(supp(ρ0(x) > 0),b”(ρ0(x))).	(F.26)
x∈M =1
We will aim to control the volume of this set, which we will achieve by controlling it first on a net.
This will require transferring control between different nearby points.
For any S, S0 ∈ [n] and δ ∈ {0} ∪ [n], the triangle inequality implies
Bs(S,δ) ⊆Bs(S0,δ+ds(S,S0)).
For some p ∈ BE (g, r), we also have
δη(p) = max ds (p, y) ≤ ds (p,g) + max	ds (g, y)
y∈BE (p,η)	y∈BE (p,η)
≤ds (p, g) +	max	ds (g, y)
y∈BE (g,η+r)
=ds (p, g) + δη+r (g)
where we used BE (p, η) ⊆ BE (g, η + r). It follows that
Bs(supp(p > 0), δη (p)) ⊆Bs(supp(g > 0), δη(p) + ds(p, g))
⊆Bs (supp(g > 0), δη+r(g) + 2ds (p, g)).
(F.27)
(F.28)
From (D.62) and lemma G.10 we obtain that for d satisfying the requirements of lemma D.8,
「	∀x ∈M,' ∈ [L] : ∃x ∈ N 3 -1/2 ∩N 3 -1/2(x)	]
n-3n0	n-3n0
P	s.t.	≥ 1 - 6e-d/2,	(F.29)
,{∣∣P0(X)- P0(x)∣∣2 ≤ Cn-5/2} ∩ {ds(PO(X),ρ0(X)) ≤ d} 一
L
since under the assumptions of the lemma ds(ρ0(x),ρ0(X)) ≤ P ∣R' (x,Cn-3)∣, with
'=1
r`(X, Cn-3) denoting the number of risky features as defined in section D.3.1. We denote this
event by Eρ .
On Eρ , we can transfer control of the ball of feature supports from a point on the net to any point on
the manifold. For some ', X We denote by x the point on the net that satisfies the above condition.
Considering (F.28), We choose g = ρ0(X), P = p0(x), r = Cn-5/2 and η = CnL3/2+qn-1/2,
obtaining
Bs(SUPP(PO(X) > 0),δn(PO(X)))
⊆ Bs(SUPP(PO(X) > 0),δn+Cn-5∕2(PO(X))+ 2ds(PO(X),ρ0(X)))	(F.3O)
⊆ Bs(SUPP(PO(X) > 0), δ2n(pO(X)) + 2d),
where We assumed CnL3/2+qn2 > C.
We next turn to controlling 52『(pO(x)), which is now a random variable, for all ' ∈ [L], x ∈
N-n-1/2. From lemma F.1 we have for a vector g with gi 〜同 N(0,1),
P[δ2n(g) ≥ ɑɔnn2/3] ≤ C0e-cd.
245
Published as a conference paper at ICLR 2021
Considering a vector ρ0(x) for some ' ∈ [L], x ∈ ^—k1/2, we have
ρ0(x) ~N(0, 2∣∣α0-1(x)∣∣2 n-1).
Lemma D.2 then gives
P h√2∣∣α0-1(x)∣∣2 < l] ≤ C'e-cd ≤ Ce-Cd
for some constants, assuming d > K log L for some K. Since on the complement of this event we
have √2η ∣∣α0-1(X)II- ≤ 2η, lemma F.1 and a rescaling gives
P hδ2η(PO(X)) ≥。0九产3] = P hδ√2ηkα'-1(x)k-1 (g) ≥ C0nη2∕3i
≤ P hδ2η(g) ≥ Conn2/3i + P [√2 ∣∣α'-1(X) ∣∣2 < l]	(F∙31)
≤ Ce-cd + C0e-c0d ≤ C00e-c00d.
for some constants. Taking a union bound over Nn-3n-1/2 and [L] we obtain
P h∃X ∈ Nn-3n-1∕2,' ∈ [L] s.t. δ2η(ρ0(x)) ≥ Conn2/3i ≤∣Nn-3n-1∕2∣ LCe-Cd ≤ C0e-cd
(F.32)
under the same assumptions on d as in lemma D.8, and additionally assuming d ≥ K log L for some
K.
Since n, d, η satisfy the assumptions of lemma F.1, We have nη2/3 ≥ C0n1/2d3/4 ≥ C0d for some
C0 and hence
P h∃X ∈	Nn-3n-1∕2,' ∈	[L]	s.t.	δ2η (ρ0(X))	+	2d	≥	Cinn2/3]	≤ Ce-Cd	(F.33)
for some constants c, C, C1. Denoting the complement of above event by EδN, we find that on
EP ∩ EN, for every x we can find x ∈ '尸丁r、/2 ∩ %「3丁丁1/2 (x) such that
Bs(SUPP(P0(x) > 0),δη(ρ0(x))) ⊆ Bs(SUPP(ρ0(x) > 0)*2〃(ρ0(x)) +2d)
⊆ Bs(SUPP(P0(X) > 0),Cιnη2/3),
where we used (F.30). On EP ∩ EN, we can thus bound the size of the set that contains J〃, denoting
its size by
Sn = Vol U 0 Bs(Sign(P0(x)),δη(ρ0(x))).
χ三M ' 1
We first note that for any p,
dCinn2/3e /	∖
VolBs(p, C1nη2/3) ≤	X ( n ) ≤ C∣"C1nη2∕3] ndc1 n^/l ≤ C/"C"/3
i=0
for appropriate constants, assuming nη2/3 > K log(nη2/3) for some K. It follows that on EP ∩ EN,
Sn = Vol [ 0 Bs(SUPP(P0(x)),δn(ρ'(x))) ≤ Vol [ 0 Bs(SUPP(P0(X)),C1nn2/3)
χ∈M ' 1	χ∈M ' 1
L
≤Y X	VolBs (supp(P0(x)), C1nη2/3)
'=1X∈N -3 -1/2
n-3 n0
≤ C0 N	-1/2 eCdLnn2/3 ≤ C0eC00dLnn2/3
n-3n0
for appropriate constants, since nη2/3 ≥ C000d and d satisfies the assumptions of lemma D.8. Since
after worsening constants we have P EP ∩ EδN ≤ C0e-Cd, we obtain
P hSn > C0eC00dLnn2/3i ≤ C0e-Cd	(F.34)
246
Published as a conference paper at ICLR 2021
for some constants.
We would next like to employ lemma D.14 in order to control the quantities of interest for a single
J ∈ Jη(M), and then take a union bound utilizing the upper bound above on IJη∣. This will
require controlling the event EδK in the lemma statement with an appropriate choice of the constants
δs,Ks. As in other sections, we use the convention ΓjJ+1 = I for any ' ∈ [L].
At a given collection of supports J ∈ Jη(X) for some X ∈ M, we choose X as the anchor point in
lemma D.14.
From (F.27) We have, for any X ∈ N _3 -1/2,
n- n0
δη(PO(X)) ≤ ds (PO(X),P0(X)) + δη+kρ0(χ)-ρ0(x)∣∣2(PO(X)).
Then using (F.29) we obtain to bound the two terms in the RHS gives
P h∀x ∈M,' ∈ [L] : ∃X ∈ Nn-3n-1∕2 ∩ Nn-3n-1∕2 (x) s.t. δη(ρ0(x)) ≤ d + 62〃(PO(X))]
≥ 1 - 6e-d/2.
where we used η = Cη L3/2+q n-1/2 and d satisfies the requirements of lemma D.8. Using (F.33)
to bound d + δ2η(PO(X)) uniformly on ^-3^1/2 and ', and combining the failure probabilities of
these events by a union bound, we obtain
P h∃X ∈ M s.t δη(PO(X)) > C1nη2∕3i ≤ 6e-d∕2 + Ce-Cd ≤ C0e-c0d
for some constants. Since 6〃(PO(X)) ≥ 14 ㊀ I^(X)I for any j` ∈ J ∈ Jn(x), implies directly
that
P h∀X ∈ M,J' ∈J∈Jn(x) : ∣ Je θ l`e(k)l ≤ Cιnη2/3] ≥ 1 — C0e-c0d.	(F.35)
In the notation of lemma D.14 we denote this event by Eδ, and choose 6s = C1nη2∕3.
From the definition of J〃, for every X ∈ M and j` that is an element of J ∈ J〃(x),
j` = supp (pO (x) + V > 0)
for some v such that kvk2 ≤ η. We now consider the vector
W = (PJ` - pi'(x)) Po(X).
Note that for any element of Wi that is non-zero, we must have ∣v∕ ≥ ∣pO(x%∣ (since the perturbation
must change the sign of this element), in which case we have ∣w∕ = ∣ρ0(X)i ∣. Denoting the set of
indices of these non-zero elements by Q, we have
kwk2 = Xw2 = X(ρ0(X)i)2 ≤ Xv ≤kvk2 ≤ η2.
i∈Q	i∈Q	i∈Q
This holds for all ` ∈ [L]. Thus if we set Ks = η for Ks, the event EK in lemma D.14 holds with
probability 1. We therefore choose
EδK = Eδ
with Eδ defined in (F.35). In order to apply D.14 we must also ensure
δs = Conη2/3 ≤ n, Ks = η ≤ ∙∣L-3/2.
L2
C L3∕2+q
Setting η = η √η— as per (F.2), we can satisfy these requirements by demanding n ≥
CO3C〃2L6+2q.
We are now in a position to apply lemma D.14 to control the objects of interest. We use rotational
invariance of the Gaussian distribution repeatedly to obtain
lEδκllβJ,0U2 =3κ ∣∣W0L+1Γ%+2Pj'+ι∣∣2 ≤ lEδκ∣∣W0L+1Γ%+2∣∣2
a.s.
=iEδκ Uγ%+2wol+1*∣∣2 = iEδκ ∣∣r%+2eι∣∣2∣∣W0L+1*∣∣2.
247
Published as a conference paper at ICLR 2021
Recalling that WL+1 〜N(0,1), we use Bernstein,s inequality to obtain P [∣∣ WL+1∣∣2 > C√n] ≤
C 0e-cn, and another application of lemma D.14 gives P [九衣 ||rj:'+2ei |卜 > C ] ≤ C 00e-c0 n for
some constants. Hence after worsening constants
P [lEδκ ∣∣βJ,0∣∣2 > C√n] ≤ C0e-cn.	(F.36)
We also obtain
F ∣∣ J'0∣∣ = F ∣∣w0Γ-i*0τpj'o∣∣ t≤s.3κ ∣∣w'∣∣ ∣∣rJt'0-1∣∣
P [lEδκ ∣∣ΓJ0∣∣ > C√L] ≤ C0e-cn + C00e-c0n ≤ C000e-c"n
where we usedan ε-net argument to bound ∣∣Wf∣∣ and lemma D.14 to bound Eδκ ∣∣Γ'-1:'0-11∣. We
now combine this result with (F.36). It remains to uniformize this result over the choice of` and J .
Combining (F.26) and (F.34) gives
P h Jη(M)I > C0ec"dLnη2[ ≤ C0e-cd.	(F.37)
C L3/2+q
Denoting the complement of this event by EJ, and setting η = η √κ, on this event We have
P ∀J∈Jη(M),'0 <' ∈ [L],
≥ 1 - C0ec'0dLnn2/3-cn ≥ 1 -
:	n1Eδκ ∣ γJo∣ ≤ c√lo	J
∩ n1Eδκ ∣βj,o ∣2 ≤C √no
C0eC00cn/3dL2+2q/3n2/3 - cLn ≥ 1 - Coe-c0 n
assuming n ≥ KL9+2qd for some constant K. Taking a union bound over the probabilities of EJ
or EKδ not holding, we finally obtain
P
∀J∈J η (M),'0 <' ∈ [L],
n∣rJo∣ ≤
n ∣J,012
≥ 1 — C0e-c0n - P [EJ] - P[Eδκ]
∩
≥ 1 - C0000e-c0000d
for appropriate constants, where we used (F.35) to bound P [EδcK], and in the last inequality we used
n ≥ KLd for some K. Combining this with (F.25) and taking a union bound gives the desired
result.
ii) We will control ∣∣βIo⑺ 0 - β/χ) °∣∣ using lemma D.21. For t ∈ [0,Tn] We note that by
definition of Tn and Jη (x),
Zt(X) ∈Jn (x).
As noted in the previous section, if we set d to satisfy lemma D.8 and n ≥ KdL9+2q for some K,
then the requirements of lemma D.14 are satisfied with
δs = Conη2/3, Ks = η.
and
P [EδK] = P [Eδ] ≥ 1 - Ce-cd
where the last bound uses the definition of Eδ in (F.35). From the definition of d in lemma D.21, on
the event EδK we have
∣∣d∣∣∞ ≤ δs ≤ Conη2/3.
248
Published as a conference paper at ICLR 2021
Thus for some fixed t ∈ [0, Tn], if We denote d = ∣Ii,t(x)㊀ Ii,o(x)∣ for i ∈ [L], We can apply the
second result of lemma D.21, choosing
d0 = d log L,
s = Kd0L2+2q/3n-1/3,
db = K0d0L2+2q/3n2/3 ,	(F.38)
_ K000doL2+2q/3n2/3
si	max{1, di}
for some appropriately chosen constants K, K0, K000.	Assuming n ≥	dL2 and
n1/12 A/L3+2q/3d1/4 ≥ K for some constant K to simplify the result, we obtain
P [lEδκ 忸10(χ),0 -βIt(χ),0∣∣2 > K00Cn/3n5/12L3+2q/3d0/4i
≤ C0e-K，，，d0L2+2q/3n2/3 + C00e-c0L.
The constants K, K0 are chosen such that this result can be uniformized over the set of possible
supports IJn (M)I and [L]. Since on the event EJ defined in (F.37) the size of this set is bounded,
We have
P	∀x ∈M,t ∈	[0,Tn ],'	∈	[L]	:	1EδK	llβI0(x),0	- βIt(x),0ll2	Ej	≥ 1 - C 0e-cd0 L2+2q/3n2/3
_	≤K 00Cn/3n5/12L3+2q/3d0/4	_
for some constant c, C, C0, assuming n ≥ K 0000 L9+2q d for some constant K0000. Taking a union
bound over the complements of EJ and EδK using (F.37) and (F.35), We have
x ∈M,
P ∀ t ∈ [0, Tn],
L ' ∈ [L]
I∣βl-(X),0 - βI-(X),0∣∣2 ≤ K "C"5'1 log3/4(L)L3+2q/3d3/4
≥1 - C0e-cd0L2+2q/3 n2/3 - C00e-c0d
≥1 - C000e-c00d
for appropriate constants, assuming log(L)L2+2q/3n2/3 > K for some constant K.	□
G Auxiliary Results
Lemma G.1 (Hoeffding’s Inequality (Vershynin, 2018, Theorem 2.2.6)). Let X1, . . . , XN be in-
dependent random variables. Assume that Xi ∈ [mi , Mi] for every i. Then for any t > 0, we
have
N
P X(Xi -E[Xi]) ≥t
i=1
≤ exp
2t1
P=I(ML mi)2
Lemma G.2 (Bernstein’s inequality (Vershynin, 2018, Theorem 2.8.1)). Let X1, . . . , XN be inde-
pendent mean-zero subexponential random variables. Then, for every t ≥ 0, one has
P_X Xi ≥ t ≤ 2exp(-c min(∑N⅛i<, maxi ItXi kψι )),
where c > 0 is an absolute constant, and ∣∣ ∙ ∣∣ψι = inf{t > 0 | E[e| ∙|/t] ≤ 2} is the subexponential
norm.
Lemma G.3 (Bernstein’s inequality for bounded RVs - (Vershynin, 2018) Thm. 2.8.4). For
X1 , ..., Xn independent, zero mean random variables such that ∀i : |Xi | < K, and every t ≥ 0, we
have
P
n
XXi II ≥ t
i=1 I
≤ 2 exp
—
n
where σ2 = PEXi2.
i=1
249
Published as a conference paper at ICLR 2021
Lemma G.4 (Hanson-Wright Inequality (Vershynin, 2018, Theorem 6.2.1)). Letg be a vector of n
i.i.d., mean zero, sub-Gaussian variables and A be an n × n matrix. Then for any t > 0, we have
B
P[∣g*Ag - Eg*Ag∣ ≥ t] ≤ 2exp
, ʃ
-c min
t2	t
K4 kAkF ,K2W
where max Ilgikψ2 ≤ K (with ∣∣∙kψ2 denoting the Sub-Gaussian norm).
Lemma G.5 (Freedman’s Inequality (Freedman, 1975, Theorem 1.6)). Let (∆i, Fi) be a sequence
of martingale differences, with
and suppose that
E∆i Fi-1 = 0,
∣∆i∣ ≤ R a.s..
Define the quadratic variation
L
VL = XE[(∆i)2 I Fi-1].
i=1
Then
∃i = 1 . . . L s.t.
i
X ∆
'=1
> t and V i ≤ σ2
≤ 2 exp -
t2/2	ʌ
σ2 + Rt/3 ).
P
Lemma G.6 (Moment control Freedman's (de la Pena, 1999)). Let (∆i, Fi) be a sequence ofmar-
tingale differences, with
E ∆i II Fi-1 = 0,
and suppose that
E [(∆i)k	∣	FiTi	≤ £E	[(∆i)2	∣	FiTi	Rk-2	∀k,	a.s..
Set
j
Vj = X E [(∆i)2 ∣ FiTL
i=1
Then
∃i = 1 . . . j s.t.
i
X ∆
'=1
> t and Vi ≤ σ2
≤ 2exp (-2t-/2^
σ2 + Rt
P
Lemma G.7 (Martingales with subgaussian increments). Let (∆i, Fi) be a sequence of martingale
differences, and suppose that
λ2V2
E [exp (λ∆i) ∣ Fi 1] ≤ exp ( --— ) , ∀ λ, a.s.
Then
∣L ∣
P ∣∣X ∆i ∣∣ > t ≤ 2 exp
∣ i=1	∣
Proof. By assumption, E[∆i] = 0 for each i ∈ [L]. We calculate using standard properties of the
conditional expectation
Eheλ PiL=1 ∆i i = EhEheλ PiL=1 ∆i ∣∣∣FL-1ii
=EheλPL-II δEhehL I FL-1]] ≤ eλ2V2∕-EheλPL-II △].
Moreover, one has E[eia1 | F0] = E[eia1 ] ≤ eλ2V2/2. An induction therefore implies
Eheλ PiL=1 ∆i i ≤eλ2LV2∕2,
and the result follows from standard equivalence properties of subgaussian random variables (Ver-
shynin, 2018, Proposition 2.5.2).	□
250
Published as a conference paper at ICLR 2021
Lemma G.8 (Azuma-Hoeffding Inequality (Azuma, 1967)). Let (∆i, Fi) be a sequence of martin-
gale differences, and suppose that
∆i ≤ Ri a.s..
Then
/	∖
L
P X∆i > t
, '=1	.
∖ '=1 √
-t2
L-
≤ 2 exp
Lemma G.9 (Chi and Inverse-Chi Expectations). Let X 〜χ(n) be a Chi random variable with n
degrees of freedom, equal to the square root of the sum of n independent and identically distributed
squared N (0, 1) random variables. Then
E[X]
Γ( 1 (n +1))
Γ( 2 n)
and, if n ≥ 2,
E[X-1]
1 Γ( 1 (n - 1))
√2	r(2n)
Proof. We use the fact that the density of X is given by
P(X) = 1x≥θ(x)2n∕2-1r( 1 n) XnTe-X2/2,
which can be proved easily using the Gaussian law and a transformation to spherical polar coordi-
nates (Muirhead, 1982, Theorem 2.1.3). The expectation of X then results from a simple sequence
of calculations using the change of variables formula:
E[X] =	、∞ Xne-X2/2 dx
L J 2n/2Γ( 2n) J0
= -L1- Z∞ Xn/2T/2e-x/2 dx
2n/2Γ( 2n) J0
-ɪ Z∞ x(n/2+1/2)Te-X dx
Γ(2n) J0
√2r(1 (n + 1))
Γ(1n).
Now we study X-1. By the change of variables formula, its density is given by
ρ0(x) = 1χ≥o(x) —SI /1-7x-ne-1∕(2χ2)
x≥0' 々n/2Tr(2n)
A similar sequence of calculations then yields
E[X-1]=	、Z x-ne-1/(2x2) dx
[	]	2n/2r( 1 n) J0
,Ji、「x-2(n+1)e-1/(2X) dx
2n/2r(2n) J0
1
2n∕2Γ( 2 n)
∞	1	1
X2(nT)Te-2x dx
0
∞1
— / x2(I)Te-X dx
√2Γ(2n) J0
1 Γ( 1 (n - 1))
√2	r(2n),
provided n > 1.
□
251
Published as a conference paper at ICLR 2021
Lemma G.10 (Equivalence of `p Norms). Let 1 ≤ p ≤ q ≤ +∞. Then for every x ∈ Rn one has
kxkq ≤ kxkp ≤ n1/p-1/qkxkq.
Lemma G.11 (Gaussian Moments). Let P ≥ 1, and let g 〜N(0,1) be a Standard normal random
variable. Then
E[∣g∣p] = 2p/2 rΓ≡p ；	E[[g]+] = 2 E[∣g∣p],
where [x]+ = max{x, 0}. In particular E[|g|p] ≤ pp/2, So that g iS SubgauSSian and g2 iS Subexpo-
nential.
252