Published as a conference paper at ICLR 2021
Uncertainty-aware Active Learning for Opti-
mal Bayesian Classifier
Guang Zhao1 , Edward R. Dougherty1 , Byung-Jun Yoon1,3, Francis J. Alexander3, & Xiaoning Qian1,2
guangzhao@tamu.edu, falexander@bnl.gov,
{edward,bjyoon,xqian}@ece.tamu.edu
1Department of Electrical & Computer Engineering, 3Computational Science Initiative,
2Department of Computer Science & Engineering, Brookhaven National Laborator
Texas A&M University
College Station, TX 77843, USA
Upton, NY 11973, USA
Ab stract
For pool-based active learning, in each iteration a candidate training sample is
chosen for labeling by optimizing an acquisition function. In Bayesian classifica-
tion, expected Loss Reduction (ELR) methods maximize the expected reduction
in the classification error given a new labeled candidate based on a one-step-look-
ahead strategy. ELR is the optimal strategy with a single query; however, since
such myopic strategies cannot identify the long-term effect of a query on the clas-
sification error, ELR may get stuck before reaching the optimal classifier. In this
paper, inspired by the mean objective cost of uncertainty (MOCU), a metric quan-
tifying the uncertainty directly affecting the classification error, we propose an
acquisition function based on a weighted form of MOCU. Similar to ELR, the
proposed method focuses on the reduction of the uncertainty that pertains to the
classification error. But unlike any other existing scheme, it provides the critical
advantage that the resulting Bayesian active learning algorithm guarantees conver-
gence to the optimal classifier of the true model. We demonstrate its performance
with both synthetic and real-world datasets.
1	Introduction
In supervised learning, labeling data is often expensive and highly time consuming. Active learning
is one field of research that aims to address this problem and has been demonstrated for sample-
efficient learning with less required labeled data (Gal et al., 2017; Tran et al., 2019; Sinha et al.,
2019). In this paper, we focus on pool-based Bayesian active learning for classification with 0-
1 loss function. Bayesian active learning starts from the prior knowledge of uncertain models.
By optimizing an acquisition function, it chooses the next candidate training sample to query for
labeling, and then based on the acquired data, updates the belief of uncertain models through Bayes’
rule to approach the optimal classifier of the true model, which minimizes the classification error.
In active learning, maximizing the performance of the model trained on queried candidates is the ul-
timate objective. However, most of the existing methods do not directly target the learning objective.
For example, Maximum Entropy Sampling (MES) or Uncertainty Sampling, simply queries the can-
didate with the maximum predictive entropy (Lewis & Gale, 1994; Sebastiani & Wynn, 2000; Muss-
mann & Liang, 2018); but the method fails to differentiate between the model uncertainty and the
observation uncertainty. Bayesian Active Learning by Disagreement (BALD) seeks the data point
that maximizes the mutual information between the observation and the model parameters (Houlsby
et al., 2011; Kirsch et al., 2019). Besides BALD, there are also other methods reducing the model
uncertainty in different forms (Golovin et al., 2010; Cuong et al., 2013). However, not all the model
uncertainty will affect the performance of the learning task of interest. Without identifying whether
the uncertainty is related to the classification error or not, these methods can be inefficient in the
sense that it may query candidates that do not directly help improve prediction performance.
1
Published as a conference paper at ICLR 2021
(a) Predictive probability of class 1
(b) Error regret comparison among methods
Figure 1: (a) Predictive probability of class 1 under uncertainty: the red lines indicate the upper
and lower bounds of the predictive probability; the blue dash line is the mean of the predictive
probability; the green dash line indicates that the probability is equal to 0.5. (b) Active learning
performance comparison.
In this paper we focus on the active learning methods directly maximizing the learning model per-
formance. There exist such active learning methods by Expected Loss Reduction (ELR) that aim to
maximize the expected reduction in loss based on a one-step-look-ahead manner (Roy & McCallum,
2001; Zhu et al., 2003; Kapoor et al., 2007). The ELR methods can focus on only the uncertainty
related to the loss function to achieve sample-efficient learning. In fact, ELR is the optimal strategy
for active learning with a single query (Roy & McCallum, 2001). However, a critical shortcoming of
previous ELR schemes is that none of them provide any theoretical guarantee regarding their long-
term performance. In fact, since these methods are myopic and cannot identify the long-term effect
of a query on the loss functions, without special design on the loss function, they may get stuck
before reaching the optimal classifier. To the best of our knowledge, there is currently no method
that directly maximizes the model performance while simultaneously guaranteeing the convergence
to the optimal classifier.
Fig. 1a provides an example of binary classification with one feature where both BALD and ELR
methods fail. In the figure, the red lines indicate the upper and lower bounds of the prediction prob-
ability of class 1, illustrating the model with higher probability uncertainty on the sides (x → ±4)
than that in the middle (x = 0). Querying candidates on the sides will provide more information of
the model parameters, and therefore is preferred in BALD. However, since the possible probabilities
on the sides are always larger than or less than 0.5, querying candidates on the sides will not help
reduce the classification error. On the other hand, ELR queries candidates that help reduce the clas-
sification error the most, so it prefers data in the middle whose optimal labels are uncertain given
the prior knowledge. The performance shown in Fig. 1b agrees with our analysis. Fig. 1b shows the
performance averaged over 1000 runs, with more details and discussions of the example included in
Appendix C. BALD performs inefficiently at the beginning by querying points on both sides. On the
other hand, the ELR method performs the best at the beginning, but becomes inefficient after some
iterations (〜100), indicating some of its runs get stuck before reaching the optimal classifier. In this
paper, we consider the algorithm to “get stuck” when the acquisition function value is 0 for all the
candidates in the pool and the algorithm degenerates to uniform random sampling.
In this paper, we analyze the reason why ELR methods may get stuck before reaching the optimal
classifier, and propose a new strategy to solve this problem. Our contributions are in four parts: 1.
We show that ELR methods may get stuck, preventing active learning from reaching the optimal
classifier efficiently. 2. We propose a novel weighted-MOCU active learning method that can focus
only on the uncertainty related to the loss for efficient active learning and is guaranteed to converge
to the optimal classifier of the true model. 3. We provide the convergence proof of the weighted-
MOCU method. 4. We demonstrate the sample-efficiency of our weighted-MOCU method with
both synthetic and real-world datasets.
2	Background
Optimal Bayesian classifier. Consider a classification problem with candidates x ∈ X and class
labels y ∈ Y = {0, 1, . . . , M - 1}. The predictive probability p(y|x, θ) is modeled with parameters
2
Published as a conference paper at ICLR 2021
θ. Assume θ is uncertain with a distribution π(θ) within the uncertainty class Θ. The classification
problem is to find a classifier ψ : X → Y, which assigns a predicted class label to a given candidate.
The expected 0-1 loss of the classifier ψ for a candidate x, dependent on θ, is defined as Cθ(ψ, x),
which can be derived to be the classification error: Cθ(ψ,χ) = 1 - p(y = ψ(χ)∣χ, θ). The op-
timal classifier with θ, ψθ is defined as the classifier minimizing the classification error: ψθ(x) =
arg maxy p(y|x, θ). So we have: Cθ(ψθ, x) = minψ Cθ (ψ, x) = miny {1 - p(y |x, θ)}. When there
is model uncertainty with π(θ), an Optimal Bayesian Classifier (OBC) ψπ(θ) is the classifier that has
the minimum expected loss over π(θ) (Dalton & Dougherty, 2013):
Eπ(θ)[Cθ(ψπ(θ), x)] = minEπ(θ)[Cθ(ψ,x)] = myin{1 -p(y|x)}	(1)
where p(y|x) = Eπ(θ) [p(y|x, θ)] is the predictive distribution. It’s easily to see ψπ(θ) (x) =
arg maxy p(y|x).
Active learning. Active learning collects the training dataset D in a sequential way. For pool-
based active learning, in each iteration, we choose a candidate x from the set of potential training
samples X to query for the class label by optimizing an acquisition function U (x). Then, in the
Bayesian setting, by including the observed data pair (x, y) to D, we update the posterior distri-
bution based on Bayes’ rule. In each iteration, the acquisition function depends on the posterior
distribution of model parameters π(θ∣D). In the following discussion, to simplify notations, we
omit D from the notations and use π(θ) and p(y|x) to respectively denote the posterior and pre-
dictive distributions conditioned on D. When a new observed data point is included, the distri-
butions are updated by Bayes' rule and the total probability rule as: ∏(θ∣χ, y)= "凿状⑨ and
p(y0 lx0,χ,y) = E∏(θ∣χ,y)[p(y0lx0,θ)].
The acquisition function of ELR methods in the Bayesian setting can be defined by the expected
OBC prediction error reduction after observing the new pair (x, y) (Roy & McCallum, 2001):
U (x) = Ep(x0 ) {Eπ(θ) [Cθ (ψπ(θ) , x )] - Ep(y∣x) [Eπ(θ∣x,y) [Cθ (ψπ(θ∣x,y) , x )]]},	(2)
where p(x0) is the distribution over X, independent of θ and D. ELR methods assume that we use
OBC as the classifier, and in each iteration we should choose the query that maximize the decrease
in OBC prediction error. The first term in (2) is the OBC prediction error of ψπ(θ), and the second
term is the expected prediction error of ψπ(θ∣x,y), the one-step-look-ahead OBC, with respect to
p(y|x). In the following section, we analyze why this acquisition function is sample-efficient as
it directly targets at classification error reduction while ignoring irrelevant uncertainty with respect
to the learning task; but it may get stuck before converging to the true optimal classifier (optimal
classifier of the true model).
3	MOCU-based active learning
3.1	Mean objective cost of uncertainty
To analyze ELR methods, we borrow the idea of the Mean Objective Cost of Uncertainty (MOCU)
for active learning with respect to the corresponding posterior π(θ). MOCU is a general objective-
oriented uncertainty quantification framework (Yoon et al., 2013). For active learning, MOCU can
be defined as the expected loss difference between the OBC and the optimal classifier:
M(π(θ)) = Ep(x0)[Eπ(θ)[Cθ(ψπ(θ), x0) - Cθ(ψθ,x0)]]	(3)
= Ep(x0)[myi0n{1 - p(y0|x0)} - Eπ(θ)[myi0n{1 - p(y0|x0, θ)}]].	(4)
The second line is derived by the definition of ψθ and (1). The first term in (3) is the OBC error as
the loss. In the second term, ψθ is the optimal classifier with a specific θ. For the terms inside the
expectation operator, we have Cθ(ψπ(θ), x0) - Cθ(ψθ, x0) ≥ 0. Therefore, the second term in (3) is
a lower bound of the OBC prediction error. MOCU captures the difference between the OBC error
and its lower bound. When MOCU is 0, the OBC converges to the true optimal classifier and we
cannot reduce the OBC prediction error further. In that case, we say that OBC has reached the true
optimal classifier.
3
Published as a conference paper at ICLR 2021
As in ELR methods, we can define an acquisition function by the reduction of MOCU in a one-step-
look-ahead manner:
UMOCU(x;∏(θ)) = M(∏(θ)) - Ep(y∣χ)[M(∏(θ∣χ,y))].	(5)
We can show that the second term in (3), the lower bound of the OBC error, is cancelled in (5). The
acquisition function (5) hence captures the expected reduction of the OBC error given new data and
is equivalent to the ELR acquisition function (2). Expanding the second term in (5), we have:
Ep(y∣x) [M(n(0|x,y))] = Ep(x0) {Ep(y |x) [Eπ(θ∣x,y) [Cθ (ψπ(θ∣x,y), x ) - Cθ (ψθ, x )]]}.	(6)
Since Py p(y∣χ)∏(θ∣χ, y) = ∏(θ), as X is assumed to be independent of θ so that we have ∏(θ∣χ)=
π(θ), we can rewrite the first term in (5) as:
M(π(θ)) = Ep(x0){Ep(y|x)[En(6|x,y)[C6 (ψπ(θ),x0) - Cθ (ψθ ,x0)]]}.	⑺
Combining (6) and (7) and canceling the Cθ(ψθ, x0) terms (the lower bound of the OBC error), (6)
can be derived as:
U MOCU(x； ∏(θ)) = Ep(χΟ){Ep(y∣χ)[E∏(θ∣χ,y)[Cθ (ψ∏(θ),x') — Cθ ( Ψ∏ (θ | X,y ) , x')]] },	⑻
which is just the ELR acquisition function in (2). Therefore, we can conclude that MOCU-based
methods are equivalent to ELR methods.
Another property we can observe from (8) is that UMOCU(x; π(θ)) ≥ 0. By definition,
ψ∏(θ∣x,y) is the OBC with the minimum expected classification error over π(θ∣x,y). Therefore,
E∏(θ∣χ,y)[Cθ(Ψ∏(θ∣χ,y),x0)] ≤ E∏(θ∣x,y) Qθ(ψ∏(θ),x0)] and we have UMOCU(x; π(θ)) ≥ 0, indicat-
ing collecting new data will reduce MOCU.
3.2	Analysis of ELR methods
In the following analysis, we assume that Θ contains the true model θr and π(θr) > 0. We first
analyze ELR methods by the MOCU reduction to show that ELR and MOCU-based active learning
ignores the uncertainty irrelevant to the OBC prediction. By that, we indicate that not all the model
uncertainties directly affect the OBC prediction. Denote the contribution to the MOCU at point
x as K(x, π(θ)) = Eπ(θ)[Cθ(ψπ(θ), x) - Cθ(ψθ,x)], so that M(π(θ)) = Ep(x)[K(x, π(θ))]. If
K(x, π(θ)) =	0,	then we have	∀θ	∈ supp(π),	ψθ (x)	=	ψπ(θ) (x),	i.e.	arg maxy p(y|x, θ)	=
arg maxy p(y|x). This means that for all the possible models, the optimal predictions are the same,
and the OBC prediction on x will not be affected by the remaining uncertainty of p(y|x, θ), if any.
In fact, K(x, π(θ)) = 0 does not necessarily mean that there is no uncertainty associated with
p(y|x, θ), for which it requires that the value of p(y|x, θ) is the same ∀θ ∈ supp(π), apparently
a stronger statement than K(x, π(θ)) being 0. Therefore, not all the uncertainties of p(y|x, θ) are
captured in MOCU when K(x, π(θ)) = 0. We consider the uncertainty inp(y|x, θ) to be “objective-
irrelevant” to the OBC prediction if K(x, π(θ)) = 0. In the active learning procedure, when a new
observation is obtained, it reduces the uncertainty of the parameter θ; and as a result, it reduces
the uncertainty of p(y|x, θ) for each x ∈ X . If an observation only reduces objective-irrelevant
uncertainty, the value of MOCU will not change. For example, in Fig. 1a, the uncertainty ofp(y|x, θ)
in the region close to x = ±4 is objective-irrelevant. Evaluating points at x → ±4 will only reduce
irrelevant uncertainty and it will not be considered in either MOCU- or ELR-based methods. That
explains why in the first several active learning iterations, the ELR or MOCU-based active learning
can be more efficient than the methods guided by total uncertainty reduction, such as BALD.
Now we explain why ELR methods may get stuck before the OBC converges to the true optimal
classifier. When we have ∀x ∈ X , UMOCU(x; π(θ)) = 0 and assume the tie is broken randomly, the
acquisition function will suggest any random candidate in the pool. When that happens, we say that
ELR methods get stuck if the OBC has not reached the true optimal classifier; i.e., M(π(θ)) is still
larger than 0.
Since p(y0|x0) = Eπ(θ) [p(y0|x0, θ)] is a linear function of π(θ), the term miny0 {1 - p(y0|x0)} in (4)
is the minimum among M linear functions, and thus a concave piece-wise linear function. Within
each linear piece, ψπ(θ) (x0) = arg maxy0 p(y0|x0) are the same for different π(θ). The second term
Eπ(θ) [miny0 {1 - p(y0 |x0, θ)}] in (4) is a linear function of π(θ). Subtracting it from the first term
and averaging the resulting difference overp(x0) maintain the concavity and the piece-wise linearity.
4
Published as a conference paper at ICLR 2021
Figure 2: MOCU and weighted-MOCU functions of a binary classification problem with Θ
{θ1,θ2}.
Therefore, MOCU defined in (4) is a concave piece-wise linear function of π(θ). Moreover, within
a linear piece of MOCU, ψπ(θ) (x0) = arg maxy0 p(y0|x0), i.e. the OBC prediction, is the same
for each of x0 ∈ X . To gain some intuition, we study a binary classification problem with the
uncertainty class of two possible models Θ = {θ1, θ2} and a candidate pool of two training samples
to query: X = {x1, x2}. Further details of the model setup can be found in Appendix D. Since
π(θ1) = 1 - π(θ2), we can express the MOCU function as a univariate function of π(θ1) as shown
in Fig. 2. It is clear that the MOCU function is a concave piece-wise linear function.
Since ∏(θ) = Ep(y∣x)[∏(θ∣x, y)], from (5), the acquisition function is defined as
M[Ep(y∣x)[∏(θ∣χ,y)]] - Ep(y∣x)[M(∏(θ∣x,y))]. Based on the concavity of MOCU M(∙) and
Jensen’s inequality, we have the acquisition function UMOCU(x; π(θ)) ≥ 0. The equality holds if for
all y ∈ Y, π(θ∣x, y) falls into the same linear piece OfMOCU. In this case, the single query (x, y)
cannot provide enough evidence to shift the OBC prediction, so that arg maxy0 p(y0 |x0, x, y) =
arg maxy0 p(y0 |x0) for each of x0 ∈ X, even though p(y0|x0, x, y) 6= p(y0|x0). In Fig. 2, we
have shown in the binary classification problem there exists such a case that ∏(θι∣χι,yι = 0)
and ∏(θι∣xι, yι = 1) are within the interval of the same linear piece of the corresponding MOCU
function. When MOCU is larger than 0, if all candidates cannot provide enough evidence to change
the OBC predictions, ELR and MOCU-based methods will get stuck before converging to the true
optimal classifier. This is due to the myopic nature of the acquisition function ignoring the long-term
effect of querying each candidate.
In summary, ELR methods are efficient by ignoring objective-irrelevant uncertainty. But if sampling
one data point can only provide little information and cannot help improve OBC prediction in the
current iteration, they will ignore its long-term effect on prediction performance. As a result, they
may get stuck before converging to the optimal classifier. To keep the efficient sampling property by
ignoring objective-irrelevant uncertainty but avoid getting stuck, we propose a one-step-look-ahead
acquisition function based on a weighted version of MOCU, which can capture the change of the
predictive probability from one-step query candidates. If that change can potentially shift the OBC
predictions in the long run, our acquisition function will have a positive value, and thereby avoid the
issues that ELR methods suffer from.
3.3	Weighted MOCU-based active learning
In this section, we propose a modified MOCU-based acquisition function that has the theoretical
guarantee to converge to the optimal classifier. Specifically, we propose a modified MOCU function
that multiplies a weight with each loss difference between the OBC ψπ(θ) and the optimal classifier
5
Published as a conference paper at ICLR 2021
ψθ in the original MOCU definition:
Mw(π(θ)) = Ep(x0){Eπ(θ){w(π(θ), x0, θ)[Cθ (ψπ(θ) , x0) - Cθ(ψθ, x0)]}},	(9)
where w(π(θ), x0, θ) > 0 is the weighting function. The corresponding acquisition function is:
UW (x; n(θ)) = Mw (∏(θ))- Ep(y∣x)[Mw (∏(θ∣χ,y))]∙	(10)
In (9), as more data are collected and the model parameter distribution π(θ) changes, w(π(θ), x0, θ)
will change accordingly. The change of w(π(θ), x0, θ) cannot affect the value of the weighted
MOCU if Cθ (ψπ(θ), x0) - Cθ(ψθ, x0) = 0, ∀θ ∈ supp(π(θ)), indicating the uncertainty at x0 is
objective-irrelevant. This makes sure that the acquisition function based on the weighted MOCU
will inherit the property of MOCU-based active learning to directly target at classification error re-
duction while ignoring irrelevant uncertainty. On the other hand, by introducing the predictive prob-
ability into the weighting functions, the probability change from one-step samples can be captured
by the weighted-MOCU based acquisition function such that it can have theoretical convergence
guaranteed to the optimal classifier as shown below.
We would like to emphasize that there are also active learning algorithms, such as the ones based on
the cyclic sampling and -greedy policies (Hoang et al., 2014), that can almost surely converge to the
true model, and as a result, the OBC converges to the true optimal classifier. However, these policies
focus on the total uncertainty reduction to derive the full knowledge of the true model, which is
unnecessary and therefore inefficient, since we only need the knowledge of the true optimal classifier
if the classification performance is the primary concern. Unlike such policies, our weighted-MOCU
based policy directly reduces the objective uncertainty affecting classification, and as a result, it is
much more efficient by focusing only on those queries that are helpful for improving the prediction.
As a result, our proposed algorithm guarantees efficiency both in the short term as well as in the
longer term.
In the following, we design a weighting function to make Mw (π(θ)) = 0 if and only if ∀x ∈
X , Uw (x; π(θ)) = 0 and show that active learning based on this weighted MOCU converges to the
optimal classifier. Specifically, we propose the following weighting function:
w(π(θ),x0, θ) = 1 — C ∙ K(x , ∏(θ)), with	(11)
K(x0, π(θ)) = Eπ(θ)[Cθ(ψπ(θ), x0) - Cθ(ψθ,x0)]	(12)
= mi0n Eπ(θ)[1 — p(y0|x0, θ)] — Eπ(θ)[mi0n(1 — p(y0|x0, θ)]	(13)
= Eπ(θ)[ma0 x p(y0|x0, θ)] — ma0 x p(y0|x0),	(14)
where 0 < c ≤ 1 is a parameter controlling the approximation of the weighted MOCU to the
original MOCU, with smaller c giving a better approximation. The choice of c depends on the
specific classification problem and the total query budget. Methods using a smaller c approximate
the ELR methods better, hence they will perform well in the first several iterations but may converge
slowly in the long run. On the other hand, when cis closer to 1, the acquisition function weighs more
heavily on long-term benefits. It is clear that K(x0, π(θ)) ≥ 0 by (13). For binary classification,
maxy0 p(y0 |x0) ≥ 0∙5. As Eπ(θ) [maxy0 p(y0|x0, θ)] ≤ 1, from (14), we have K(x0, π(θ)) ≤ 0∙5,
demonstrating that the weighting function in (11) satisfies the requirement w(π(θ), x0, θ) ≥ 0∙5 > 0.
Note that this simple weighting function does not change with respect to the model parameter values.
Substituting it into the weighted MOCU expression, we have:
MW(∏(θ)) = Ep(χ0){(1 — cK(x0,∏(θ))) ∙ K(x0,∏(θ))},	(15)
which is a strictly concave function of K. We also illustrate the weighted-MOCU function in Fig. 2
for the same example in Section 3.2. As shown in the figure, a smaller c provides better approx-
imation to the MOCU function, and all the weighted MOCU functions are strictly concave func-
tions of π(θ1) instead of being piece-wise linear, which guarantees that the acquisition function
UW (xi； ∏(θ)) is positive. In general, weighted MOCU is strictly concave along most of the direc-
tions and only changes linearly along the directions that K(x, π(θ)) is constant for x ∈ X, which
correspond to the queries that only reduce irrelevant uncertainties. Such a property can guarantee
the convergence to the true optimal classifier.
6
Published as a conference paper at ICLR 2021
Before presenting the theoretical convergence guarantee of the weighted-MOCU based active learn-
ing, we summarize the computation of our weighted-MOCU based acquisition function in Algo-
rithm 1, which can replace ELR and MOCU-based acquisition functions in Bayesian active learning
algorithms with the pseudo-code given in Appendix B. We estimate the computational complexity
of Algorithm 1 for the discrete feature and parameter spaces. Assume that the size of the discrete
feature space is Nx = |X| and the size of the uncertainty set of classifiers is N = ∣Θ∣. We study
the complexity of calculating the weighted MOCU. In the Wmocu function, the OBC error evalu-
ation in line 19 is called for O(NxNθ) times. In ACQUISITIONFUN, WMOCU is called for constant
times. Hence, the total complexity of calculating the acquisition function in weighted-MOCU based
active learning is O(NxNθ). Compared with the ELR method, there is O(Nx) additional computa-
tion associated with computing the weight (1 - cK) in line 26. Hence, the incurred computational
complexity is of the same order as the original ELR and MOCU-based methods.
Algorithm 1 Calculation for Weighted-MOCU based Acquisition Function
1:	function ACQUISmONFUN(x,∏θ∣d,c)
2:	Wmocu-current =WMOCU(∏θ∣d )
3:	WmocuJnext = 0
4:	for y in {0, 1} do
5:	for θ in Θ do
6:	Generate array p(θ,y∣D,x) = ∏θ∣d ∙ p(y∣x, θ)
7:	end for
8:	p(y|D, x) = Pθ p(θ, y|D, x)
9:	πθ∣D,x,y = p(θ, y|D, X)Ipy∖d, x)
10:	Wmocujnext = WmoCu_next + p(y∣D, x) ∙ WMΟCU(∏θ∣D,x,y, c)
11:	end for
12:	return WmocU_Current — WmoCu,next
13:	end function
14:	function Wmocu(∏θ∣d,c)
15:	Wmocu = 0
16:	for x0 in X do
17:	bayesian _er r or = 0
18:	for θ in Θ do
19:	bayesian_error = bayesian_error + ∏θ∣d ∙ (1 — maxy0p(y0∣x0, θ))
20:	end for
21:	for y0 in {0, 1} do
22:	p(y0lD,x0) = Pθ πθ∖d ∙p(y0lx0,θ)
23:	end for
24:	obc_error = 1 — maxyo p(y0∣D, x0)
25:	K = obc_error — bayesian_error
26:	WmocU = Wmocu + p(x0) ∙ [(1 — cK)K]
27:	end for
28:	return Wmocu
29:	end function
Theoretical convergence guarantee. Now we show that if active learning for a binary classifica-
tion problem is guided by the acquisition function defined by (10) and (11), MOCU will converge to
0 almost surely and hence the procedure will converge to learning the optimal classifier of the true
model. We assume that both X and Θ are discrete with finite elements; the true model parameter
θr ∈ Θ and the prior distribution π0(θ) over Θ satisfies π0(θr) > 0. We denote the posterior by
πn (θ) and predictive probability pn(y|x) in the n-th weighted MOCU based active learning itera-
tion, respectively. In the following, we give important lemmas first. All the proofs of the presented
lemmas can be found in Appendix A.
Lemma 1 Given π (θ), M(π(θ)) = 0 if and only ifMw(π(θ)) = 0.
Lemma 1 indicates that if Mw(π(θ)) = 0, the OBC ψπ(θ) converges to the optimal classifier ψθr as
explained in the first paragraph in Section 3.1.
7
Published as a conference paper at ICLR 2021
Lemma 2 Define G(x0, π(θ)) = (1 - cK(x0, π(θ)))K(x0, π(θ)), 0 < c ≤ 1. G(x0, π(θ)) is a
concave function of π(θ).
It is important to choose a weighting scheme that renders a concave function G as it guarantees the
acquisition function to be larger than or equal to 0, so that adding a new observation helps to reduce
weighted MOCU to effectively guide active learning.
Lemma 3 ∀x ∈ X , Uw (x; π(θ)) ≥ 0.
Lemma 4 At the n-th active learning iteration, if Uw (x; πn(θ)) = 0, ∀x ∈ X, Mw(πn(θ)) = 0.
This lemma states that if the acquisition function values of all candidates with respect to π(θ) are 0,
the weighted MOCU is 0. By Lemma 1, so is MOCU. With these, we can conclude that the OBC
with respect to π(θ) has converged to the optimal classifier. This is significant when comparing with
original ELR and MOCU-based methods as we have shown that this is not the case for them, which
may get stuck earlier and therefore lose the long-term efficiency.
Lemma 5 If following some policy a candidate x is measured infinitely often almost surely, then
limn→∞ Uw (x; πn (θ)) = 0 almost surely.
Intuitively, if a candidate has been measured many times, there is no benefit to measure it again.
With these lemmas, we can prove the convergence of weighted-MOCU based active learning:
Theorem 1 Assume that both X and Θ are discrete with finite elements, the true model parameter
θr ∈ Θ and the prior distribution π0 (θ) over Θ satisfies π0(θr) > 0; then for the active learning
algorithm defined by the acquisition function (10), we have limn→∞ M(πn(θ)) = 0 almost surely.
Proof. As the number of active learning iterations n → ∞, following the acquisition func-
tion (10), some of the candidates can be measured infinite times. Define XA ⊂ X as the set
whose candidates have been measured infinite times. Denote the measuring sequence of the can-
didates following (10) as {χn}, We have: ∃N, s.t. ∀n > N,Xn ∈ Xa. Based on Lemma 5,
limn→∞ Uw(xn; πn(θ)) = 0.
On the other hand, since with the weighted MOCU
Uw(xn; πn(θ)) = maxx∈X Uw (x; πn(θ)), then
limn→∞ Uw(xn; πn(θ)) = 0 indicates that ∀x ∈ X,
U w (x; πn (θ)) uniformly converges to 0. Based on
Lemma 4, limn→∞ Mnw = 0 and we can conclude
the proof with Lemma 1.
4 Empirical results
Figure 3: The expected OBC error regret
comparison between different active learning
algorithms on binary classification.
We benchmark our weighted-MOCU method with
other active learning algorithms, including random
sampling, MES (Sebastiani & Wynn, 2000), BALD
(Houlsby et al., 2011) and ELR (Roy & McCallum, 2001), on both simulated and real-world classi-
fication datasets. In the following experiments, we set c = 1 for the weighted MOCU function. The
code for our experiments is made available at https://github.com/QianLab/WMOCU_AL.
Simulated experiments. In addition to the one-dimensional simulated example introduced in Sec-
tion 1, we test our model on a similar simulation setting as the block in the middle dataset in (Houlsby
et al., 2011), where noisy observations with flip error are simulated in a block region on the deci-
sion boundary. We generate data based on a two-dimensional Bayesian logistic regression model:
p(y = 1|x, w,b) = 1+exp(-WTx-b) with X ∈ [-4,4]2. The block region is within [-0.5,0.5]2
with the flip error rate equal to 0.3. For the model parameter prior, wι 〜U(0.3,0.8) is uniformly
distributed and w2 〜U(-0.25,0.25) and b 〜U(-0.25,0.25); wι, w2 and b are independent.
We randomly sample 100 particles from the parameter prior with one of the particles as the true
model parameter. The five active learning algorithms are compared for 500 iterations by the OBC
8
Published as a conference paper at ICLR 2021
error with respect to the testing data generated from the true model. We repeat the simulations for
500 runs and plot the average performance with standard deviation bars in Fig. 3. The error regret
is defined as the error difference between the OBC and the true optimal classifier. From the figure,
MES simply chooses the candidates with the predic-
tive probability closest to 0.5, it can sample many
noisy observations from the block region. ELR per-
forms well in the first several iterations but poorly
after 200 samples. Our weighted MOCU performs
the best.
We have also benchmarked our weighted-MOCU
based method with other active learning meth-
ods for a synthetic multi-class classification prob-
lem. We assume that the probabilistic model
p(y∣x,σ2) = fy(x,σ2)/PyO f (x, σy20) with X ∈
[-2, 2]2, y ∈ {0, 1, 2} and fy = exp(-(x -
my)2∕2σy). We set my to be (0, 0), (1, 0), (0,1)
Figure 4: The expected OBC error regret
comparison between different active learning
algorithms on 3 class classification.
for y = 0,1,2 respectively; and σj 〜 U(1,5) being the uncertain parameters. Same as
the previous binary classification experiment, we test for 300 runs and plot the average per-
formance with standard deviations in Fig. 4. We can observe that ELR performs poorly in
the long run while our Weighted MOCU has better empirical performance on par with BALD
More results and discussion are in Appendix D&E.
Real-world benchmark experiments. We also
present the results on the UCI User Knowledge
dataset (Kahraman et al., 2013). The dataset in-
cludes 403 samples assigned to 4 classes (High,
Medium, Low, Very Low) with each sample having
five features in [0, 1]5. We have grouped the sam-
ples into two classes with 224 samples in High or
Medium, 179 in Low or Very Low. We consider the
first and fifth features for classification and equally
divide the feature space into 4 × 4 bins. For the i-th
bin, the probability of candidates belonging to High
or Medium is denoted by θ%, 1 ≤ i ≤ 16 and θ∕s
are independent and θi 〜 Beta(ai, βi), with hyper-
0.6
0.5
0.4
0.3
0.2
0.1
Figure 5: Classification error rate compari-
son on UCI User Knowledge dataset
βi = 10 in
2 if the true frequency of High or
parameters αi and βi . We present the results with the uncertainty class by setting αi
eight randomly chosen bins and for the other bins, αi = 5, βi
Medium in the i-th bin is lower than 0.5 and αi = 2, βi = 5 otherwise. We have randomly drawn
150 samples from each class as the candidate pool and perform the five different active learning al-
gorithms. We repeat the whole procedure 150 times and the average error rates are shown in Fig. 5.
While ELR clearly gets stuck in this setup, our Weighted MOCU method can converge to the opti-
mal classifier with less samples than all the competing methods. BALD performs poorly as the bins
with α = β = 10 have less uncertainty but have more impact on OBC prediction and BALD fails
to identify that. More comprehensive results and discussion, including results on the UCI Letter
Recognition dataset (Dua & Graff, 2017), can be found in Appendix F.
5 Conclusions
We have identified potential convergence problems of existing ELR methods and proposed a novel
active learning strategy for classification based on weighted MOCU. Our weighted MOCU directly
targets at decreasing the classification error and ignores uncertainty irrelevant to the classification
performance. More critically, it can capture continuous change in objective-relevant uncertainty.
Hence, our new active learning can be efficient both at the beginning and in the long run with the
guarantee of converging to the optimal classifier. Empirical results have demonstrated active learn-
ing guided by weighted MOCU leads to sample-efficient learning. Future work includes theoretical
analysis of MOCU-guided active learning for multi-class classification, as well as developing opti-
mization methods for active learning in continuous space.
9
Published as a conference paper at ICLR 2021
Acknowledgments
X. Qian was supported in part by the National Science Foundation (NSF) Awards 1553281, 1812641,
1835690, and 1934904. B.-J. Yoon was supported in part by the NSF Award 1835690. The work
of E. R. Dougherty and F. J. Alexander was supported by the U.S. Department of Energy, Office of
Science, Office of Advanced Scientific Computing Research, Mathematical Multifaceted Integrated
Capability Centers program under Award DE-SC0019303.
References
Nguyen Viet Cuong, Wee Sun Lee, Nan Ye, Kian Ming A Chai, and Hai Leong Chieu. Active
learning for probabilistic hypotheses using the maximum gibbs error criterion. In Advances in
Neural Information Processing Systems,pp. 1457-1465, 2013.
Lori A Dalton and Edward R Dougherty. Optimal classifiers with minimum expected error within
a bayesian framework—part i: Discrete and gaussian models. Pattern Recognition, 46(5):1301-
1314, 2013.
Dheeru Dua and Casey Graff. UCI machine learning repository, 2017. URL http://archive.
ics.uci.edu/ml.
Yarin Gal, Riashat Islam, and Zoubin Ghahramani. Deep bayesian active learning with image data.
In Proceedings of the 34th International Conference on Machine Learning-Volume 70, pp. 1183-
1192. JMLR. org, 2017.
Andrew Gelman, John B Carlin, Hal S Stern, David B Dunson, Aki Vehtari, and Donald B Rubin.
Bayesian data analysis. CRC press, 2013.
Daniel Golovin, Andreas Krause, and Debajyoti Ray. Near-optimal bayesian active learning with
noisy observations. In Advances in Neural Information Processing Systems, pp. 766-774, 2010.
Trong Nghia Hoang, Bryan Kian Hsiang Low, Patrick Jaillet, and Mohan Kankanhalli. Nonmyopic
-bayes-optimal active learning of gaussian processes. 2014.
Neil Houlsby, Ferenc Huszar, ZoUbin Ghahramani, and Mate Lengyel. Bayesian active learning for
classification and preference learning. arXiv preprint arXiv:1112.5745, 2011.
H Tolga Kahraman, Seref Sagiroglu, and Ilhami Colak. The development of intuitive knowledge
classifier and the modeling of domain dependent data. Knowledge-Based Systems, 37:283-295,
2013.
Ashish Kapoor, Eric Horvitz, and Sumit Basu. Selective supervision: Guiding supervised learning
with decision-theoretic active learning. In IJCAI, volume 7, pp. 877-882, 2007.
Andreas Kirsch, Joost van Amersfoort, and Yarin Gal. Batchbald: Efficient and diverse batch acqui-
sition for deep bayesian active learning. In Advances in Neural Information Processing Systems,
pp. 7024-7035, 2019.
David D Lewis and William A Gale. A sequential algorithm for training text classifiers. In SIGIR’94,
pp. 3-12. Springer, 1994.
Stephen Mussmann and Percy Liang. On the relationship between data efficiency and error for
uncertainty sampling. In Jennifer Dy and Andreas Krause (eds.), Proceedings of the 35th In-
ternational Conference on Machine Learning, volume 80 of Proceedings of Machine Learning
Research, pp. 3674-3682, Stockholmsmassan, Stockholm Sweden, 10-15 Jul 2018. PMLR.
N Roy and A McCallum. Toward optimal active learning through sampling estimation of error
reduction. int. conf. on machine learning, 2001.
Paola Sebastiani and Henry P Wynn. Maximum entropy sampling and optimal bayesian experimen-
tal design. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 62(1):
145-157, 2000.
10
Published as a conference paper at ICLR 2021
Samarth Sinha, Sayna Ebrahimi, and Trevor Darrell. Variational adversarial active learning. In The
IEEE International Conference on Computer Vision (ICCV), October 2019.
Toan Tran, Thanh-Toan Do, Ian Reid, and Gustavo Carneiro. Bayesian generative active deep learn-
ing. In Kamalika Chaudhuri and Ruslan Salakhutdinov (eds.), Proceedings of the 36th Interna-
tional Conference on Machine Learning, volume 97 of Proceedings of Machine Learning Re-
search,pp. 6295-6304, Long Beach, California, USA, 09-15 JUn 2019. PMLR.
Byung-Jun Yoon, Xiaoning Qian, and Edward R Dougherty. Quantifying the objective cost of
Uncertainty in complex dynamical systems. IEEE Transactions on Signal Processing, 61(9):2256-
2266, 2013.
Xiaojin ZhU, John Lafferty, and ZoUbin Ghahramani. Combining active learning and semi-
sUpervised learning Using gaUssian fields and harmonic fUnctions. In ICML 2003 workshop on the
continuum from labeled to unlabeled data in machine learning and data mining, volUme 3, 2003.
11
Published as a conference paper at ICLR 2021
Uncertainty-aware Active Learning for OBC:
Appendix
In this appendix, we provide proofs of the lemmas, the pseudo-code of active learning algorithms,
as well as more detailed descriptions of our experiments, additional results, and discussions on the
weighted MOCU for multi-class classification.
A.	Proofs of lemmas
Proof of Lemma 1. Based on (3), since Cθ (ψπ(θ) , x0) - Cθ (ψθ , x0) ≥ 0, so M(π(θ)) = 0 iff
Cθ (ψπ(θ), x0) - Cθ(ψθ, x0) = 0 ∀x0 ∈ X, ∀θ ∈ supp(π). In addition, in (9), w(π(θ), x0, θ) > 0, so
Cθ (ψπ(θ), x0) - Cθ(ψθ, x0) = 0 ∀x0 ∈ X, ∀θ ∈ supp(π) iff Mw(π(θ)) = 0, which concludes the
proof.
Proof of Lemma 2. In the following proof, we omit the argument x0 in G and K for simplicity.
Owing to the concavity of the min operator, miny0 Eπ(θ) [1 - p(y0|x0, θ)] is a concave function of
π(θ). With Eπ(θ) [miny0 (1 - p(y0|x0, θ)] being a linear function of π(θ), based on (13), K(π(θ))
equals to a concave function subtracting a linear function and thus is also a concave function.
As analyzed in Section 3.2, 0 ≤ K(π(θ)) ≤ 0.5. We define T (κ) = (1 - cκ)κ, κ ∈ [0, 0.5],
a strictly increasing and strictly concave function with 0 < c ≤ 1. G(π(θ)) = T [K(π(θ))] is a
composite function ofT and K. So we conclude the proof with the property of the concavity for the
composite functions:
T [K(λπ1(θ) + (1 - λ)π2(θ))] ≥ T [λK(π1(θ)) + (1 - λ)K(π2(θ))]
≥ λT [K(π1(θ))] + (1 - λ)T [K(π2(θ))].	(16)
The first inequality is because T is increasing and K is concave; and the second inequality holds as
T is a concave function.
Proof of Lemma 3. Since π(θ) = Pyp(y∣x)π(θ∣x,y), by Jensen's inequality, We have
G(x0,π(θ)) ≥ Ey∣χ[G(x0,π(θ∣x,y))] as G is a concave function. So the weighted MOCU ac-
quisition function:
UW(x;n(θ))= Eχ0[G(x0,∏(θ))]- Eχ0[Ey|x[G(x0,π(θ∣x,y))]] ≥ 0.	(17)
Proof of Lemma 4. We will prove the contrapositive of the lemma: assuming Mw (πn (θ)) > 0,
∃x ∈ X s.t. Uw (x; πn(θ)) > 0.
Based on (15), Mw (πn (θ)) > 0 indicating ∃x ∈ X s.t. K(x, πn(θ)) > 0. It is sufficient to
show that if K(x, πn(θ)) > 0, then Uw (x; πn(θ)) > 0. To prove that, we only need to prove
G(x,πn(θ)) > Epn(y∣χ) [G(x, πn(θ∣x, y))]; then by (17), UW(x; πn(θ)) > 0.
Since G is a concave function, we know G(x,πn(θ)) ≥ Epn(y∣χ)[G(x, ∏n(θ∣x, y))]. With πn(θ)=
Py pn(y∣x)πn(θ∣x, y), we can rewrite (16) as:
T[K(x,∏n(θ))] ≥ T[Epn(y∣x)[K(χ,∏n(θ∣χ,y))]] ≥ Epn(y∣χ)[T[K(χ,∏n(θ∣χ,y))]].
The second equality holds only if ∀y ∈ {0,1}, K(x,πn(θ∣x,y)) = K(x,πn(θ)), which
means that to prove G(χ,∏n(θ)) > Ey∣χ[G(χ, ∏n(θ∣χ,y))], we just need to show ∃y ∈
{0,1}, K (x,πn(θ∣x,y)) = K (x,πn (θ)). Inthe following proof, we will show if K (x,πn(θ)) > 0,
then ∃y ∈ {0,1}, s.t. K(x, πn(θ∣x, y)) = K(x, πn(θ)).
Denote y = argmaxy pn(y∣x). By (14) we have:
K(x,∏n(θ)) =	X	∏n(θ)[maxp(y∣x,θ) -p(y∣x, θ)].	(18)
y
θ∈supp(πn)
Since K(x,πn(θ)) > 0, the parameter set Θn = {θ ∈ supp(πn) : argmaxyp(y∣x, θ) = y} is not
empty. We only keep the nonzero terms in K :
K(x,∏n(θ)) = X ∏n(θ)[maxp(y∣x,θ)-p(y∣x,θ)].	(19)
y
θ∈Θo
12
Published as a conference paper at ICLR 2021
For binary classification, y = argmaXypn(y∖x), indicating that the predictive probability
pn(y∣x) ≥ 0.5. For θ ∈ Θo, p(y∖x,θ) < 0.5, we have: if θ ∈ Θo, πn(θ∖x,仍="产肥；')<
πn (θ).
If We observe (x, y) in (n+1)-th iteration, the updated posterior predictive probability
pn(y∖x, {x, y}) ≥ pn(y∖x) ≥ 0.5 and therefore max#pn(y∖x, {x, y}) = y. Hence,
K(x,Πn(θ∣x,y)) = X Πn(θ∣x,仍[maxp(y∣x,θ) -p(y∣x,θ)] < K(x,πn(θ)).	(20)
y
θ∈Θo
Since K(πn(θ∣x, y), x) = K(πn(θ), x), we have G(x, πn(θ)) > Epn(y∣x)[G(x, ∏n(θ∣x, y))] and
UW(x;∏n(θ)) = Ep(χθ)[G(x0,∏n(θ))] - Ep(χθ)[Epn(y∣χ)[G(x0,πn(θ∣x,y))]]
≥ p(x)[G(x, πn(θ)) - Epn(y∣x)[G(x, πn(θ∖x, y))]] > 0.	(21)
This concludes our proof.
Proof of Lemma 5. Adding a new data point (x, y) to D, the posterior change is: πn(θ∖x, y) =
πnp)pyyXχ,θ). Define Θx = {θ ∈ Θ : p(y∣x,θ) = p(y∣x, θr)}. Denote Nx(n) as the times
of the candidate x being queried at the n-th iteration. Based on the posterior consistency the-
ory we have Pθ∈Θ πn (θ) -a-.s→. 1 as Nx(n) → ∞ (Gelman et al., 2013). Since pn(y∖x) =
Pθ∈Θ πn(θ)p(y∖x, θ), we have limn→∞ pn (y∖x) -a-.s→. p(y∖x, θr). Hence limn→∞ πn(θ∖x, y) -
πn (θ) = 0 almost surely, which indicates limn→∞ Uw (x; πn(θ)) = 0 almost surely.
B.	Weighted-MOCU based active learning & computational complexity
The pseudo-code of the general active learning procedure is provided in Algorithm 2. The function
AcquisitionFun can be acquisition functions of various methods, including weighted-MOCU,
ELR, BALD, etc.
Computational complexity We study the complexity of the complete active learning procedure.
As we analyzed in the main text for the computation of the weighted MOCU acquisition function,
the WMOCU function is called for O(NxNθ) times. In ACQUISITIONFUN, WMOCU is called for
constant times. Finally, in the main procedure, in each iteration, AcquisitionFun is called for
each x. Hence, the total complexity of Weighted MOCU-based active learning is O(TNx2Nθ).
0.00
4 3 2 1
∙0∙0∙0∙0
uoelu」u 二 en4nE
-4	-3	-2	-1	0	1	2	3	4
×
0.00007
0.00006
0.00005
0.00004
0.00003
0.00002
0.00001
0.00000
-4	-3	-2	-1	0	1	2	3	4
×
(a) Acquisition function of BALD	(b) Acquisition function of ELR
Figure S1. The acquisition functions based on the model (22).
C. Details of the one-dimensional active learning example in Introduction
The example in the Introduction of the main text is a binary classification problem with y ∈ {0, 1}
based on only one feature x ∈ [-4, 4]. The underlying discriminative model is based on:
pc(y = 1|x, a, b)
S(x)
(x, a, b)
S(x) + (x, a, b)
0.61Z(Xb
+ 0.2
a exp(-x2) + b[exp(-(x - 4)2) + exp(-(x + 4)2)],
(22)
13
Published as a conference paper at ICLR 2021
Algorithm 2 General active learning procedure
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
function MAINPROCEDURE( )
Set a discrete candidate set X, the probability array px, and iteration number T
Set the discrete parameter set Θ and the corresponding probability array πθ
Initialize the data set D = 0
πθ∣D = πθ
for t = 1 to T do
for x in X do
Store ACQUISITIONFUN(x, ∏θ∣d) to the array UX
end for
Optimize UX and find the maximum point x*
Obtain the label y* corresponds to x* and update D = D ∪ {χ*, y*}
for θ in Θ do
Update ∏θ∣d H ∏θ∣d ∙ p(y*∣χ*,θ)
end for
X = X/{x*}
end for
end function
where θ = (a, b)T is the uncertain parameter vector, with a and b independently uniformly dis-
tributed on the intervals [-0.1, 0.1] and [-0.2, 0.2] respectively. The discriminative model equals
to a sigmoid function S(x) plus the perturbation (x, a, b), a mixed Gaussian function that changes
with a and b, the uncertainty class of classifiers can be constructed by such deviations on S(x).
The discriminative model has higher uncertainty near x ± 4, which depends on the value of b, than
the uncertainty near x = 0, which depends on a. Value of a and b has negligible influence on the
p(y = 1|x) near x ± 4 and x = 0, respectively. So by observing data at x = ±4, the uncertainty on
pc(y = 1|x = 0) will not be reduced significantly.
In Figs. S1(a) and (b), we show how the acquisition functions of BALD and ELR change with
respect to x. It is clear that the acquisition function of BALD at x = ±4 should have the largest
value sincep(y|x) has the highest uncertainty. On the other hand, since p(y|x = ±4) is always above
or below 0.5, the specific value of p(y|x, a, b) will not affect the corresponding optimal Bayesian
classifier (OBC) and therefore the loss reduction in Fig. S1(b) at x = ±4 is always 0; the acquisition
function of ELR around x = 0 can be larger than 0, since knowing the specific value of p(y|x =
0, a, b) can reduce the classification error.
D.	Details of the binary classification example in Section 3.2
In the binary classification problem, Θ = {θ1, θ2}, X = {x1, x2}. The probabilistic model setting
for the two candidates is symmetric:
p(y1|x1, θ1) = (0.6, 0.4),p(y1 |x1, θ2) = (0.3, 0.7)
p(y2|x2, θ1) = (0.7, 0.3),p(y2|x2, θ2) = (0.4, 0.6)
There are three intervals corresponding to the linear function pieces of MOCU in Fig. 2: [0, 0.33],
(0.33, 0.67] and (0.67, 1]. In the three intervals, ψπ(θ) (x1), the OBC predictions of x1 are 1, 1 and
0, respectively; ψπ(θ) (x2), the OBC predictions of x2 are 1, 0, and 0, respectively.
In Fig. 2 We set the prior ∏(θι) = 0.15, then based on the Bayes's rule We can obtain the Pos-
terior with the observations of (x1, y1). Based on the observation result of y1, the posteriors are
∏(θι∣xι,yι = 0) = 0.2609 and ∏(θι∣χι,yι = 1) = 0.0916, both of which fall into the first linear
piece of MOCU.
E.	Multi-class classification
Although We have shoWn in the main text that our Weighted-MOCU can achieve good empirical
performance of converging to OBC With the simulated multi-class classification experiment, active
learning for multi-class classification problems can be complicated. The Weighting function (10)
adopted in the main text may not have the same theoretical convergence guarantee to the optimal
14
Published as a conference paper at ICLR 2021
classifier if applied to multi-class classification problems. Here we just show a counter example, for
which Lemma 4 does not hold if using the same weighting function.
Assume a three-class classification problem y ∈ {0, 1, 2}. The candidate pool only has one candi-
date X = {x} and the parameter set Θ = {θ1, θ2, θ3}. In addition we set the probabilistic model
p(y|x, θ) and the prior π(θ) as shown in Tables S1 and S2, and calculate the posterior and posterior
predictive probabilities. In the tables, yo denotes the one-step-look-ahead observation correspond-
ing to x, and x is omitted for simplicity. Without loss generality, we just set the weighted MOCU
parameter c = 1.
	p(y∣θι)	p3^	。3|甸	P(J)	p(y|yo = O)	p(y|yo = I)	p(y|yo = 2)
y=0	-04-	-0.4-	-04-	-01^	04	04	0.4
y=1	-03-	-01-	-05-	-0.3-	03	0.327	0.273
y=2	0.3	0.5	0.1	~03~	0.3	一	0.273	-	0.327
Table S1. The probabilities of p(y|x, θ) and p(y|x, yo).
		π(θ)	π(θ∣yo = 0)	πMyo = I)	π(θlJo = 2)
θ	二 θι	0.8	0.8 二	08	0.8 二
θ	二 θ	0.1	01	017	003
θ	二 θ3	0.1	0.1	-	0.03 一	0.17	—
Table S2. The prior and posterior of π(θ).
Here two properties in the setting are worth mentioning:
1.	π(θ1) is close to 1 and as a result ∀yo ∈ {0, 1, 2}, we have maxy p(y) = maxy p(y|yo) =
maxy p(y∣θι) = 0.4；
2.	p(y∣θ2) and p(y∣θ3) are symmetric and ∏(θ2) = ∏(θ3), as a result ∀yo ∈ {0,1,2}, ∏(θι)=
∏(θι∣yo) = 0.8 and therefore E∏(θ)[maxy0p(y∣θ)] = E∏(θ∣yo)[maxyθp(y∣θ)] = 0.8 X 0.4 + 0.2 X
0.5 = 0.42.
Recall that the K function and weighted MOCU are:
K (n(θ)) = E∏(θ)[mα X p(y∣θ)] — ma X p(y),	(
Mw(∏(θ)) = [1 — K(∏(θ))] ∙ K(∏(θ)).	(
Therefore, we have ∀yo ∈ {0,1,2}, K(∏(θ)) = K(∏(θ∣yo)) = 0.02 and Mw(∏(θ))
Mw(∏(θ∣yo)) > 0. On the other hand,
U w (∏(θ)) = Mw (∏(θ)) — Ep(yo)[Mw (∏(θ∣yo))] = 0,	(
(23)
(24)
(25)
which means that the algorithm may get stuck. Here we just give an extreme case where only one
candidate is in the search pool, but it is straightforward to build a more practical example based on
what we have shown here.
We can see from the example that, unlike in the cases of binary classification problems, the weighting
function 1 — cK may remain unchanged for a single observation in multi-class problems. Because
of this, the weighted-MOCU algorithm may get stuck. Since OBC prediction is the maximum of the
predictive distribution p(y|x), the weight function is introduced to capture the changes ofp(y|x), as
that indicates the potential shift of OBC prediction in the long run. K is a function of maXy p(y|x),
in binary case, maXyp(y|x) must change as p(y|x) changes. However, in multi-class problems, the
probability of the optimal label maXy p(y|x) may remain unchanged, when the probability of other
labels change, just like in the example above where maXy p(y) = maXy p(y|yo = 1). In the next
section, we propose a weighting function that can capture the change of any element in p(y|x).
F.	Another Weighted MOCU Scheme for Multi-class Classification
To extend the weighted MOCU scheme suit for the multi-class problem, we propose a weight func-
tion that can capture the change of p(y|x). The weighting function is defined as the softmax of
15
Published as a conference paper at ICLR 2021
p(y|x):
w(π(θ), x0, θ)
exp(maxy p(y|x))
PieXp(p(yi∣x))
(26)
where p(y|x) is the posterior predictive distribution at the current active learning iteration. We
compare this Weighted MOCU with other active learning algorithms empirically on the synthetic
three-class classification problem and the performance comparison is shown in Fig. S2. This new
Weighted MOCU (Weighted MOCU2) performs slightly better than other algorithms on this multi-
class classification problem.

IaJB」0」」0
10-3 -
—I- random
MES
T- BALD
—|— ELR
—I- Weighted_MOCU
—I- Weighted_MOCU2
l¾ r
ιo-4 -
O	IOO 200	300	400	500
Iteration number
Figure S2. The expected OBC error regret comparison between different active learning algorithms
for the three-class classification problem.
G.	Additional synthetic experiments
We run the same synthetic experiment of Fig. 3 with a different prior setting: wι 〜 U(0.3,0.8),
w2 〜U(-0.02,0.02) and b 〜U(-0.25,0.25), and the results is shown in Figure S3. The Perfor-
mance shows that only our Weighted MOCU method performs better than the random benchmark.
Here we benchmark different active learning strategies for OBC with another synthetic example.
Assume the classification problem with two dimensional input features x = (x1, x2) ∈ R2 and
binary class labels y ∈ {0, 1}. The computational model is derived by a decision boundary in
a quadratic form: x2 = ax12 + bx1 + c, i.e. p(y = 1|x, a, b, c) = 1(x2 > ax12 + bx1 + c).
The parameter vector θ = (a, b, c) ∈ R3 is uncertain and the true model is characterized by a true
parameter θ*. Unlike Monte Carlo sampling in the main text, here We consider a discrete grid setting
for both input space and parameter space with discretization for each variable as follows:
1. x1 ranges in [-0.5, 0.5] with increment 0.05
2. x2 ranges in [0, 2] with increment 0.1.
3.	a ranges in [-4.3, -3.8] with increment 0.05,
4.	b ranges in [-0.25, 0.25] with increment 0.05,
5.	c ranges in [1, 2] with increment 0.05.
For now, we simply assume that the distributions over the feature space and parameter space are
all uniform to illustrate the effectiveness of MOCU-based active learning. With prior knowledge
of the system of interest, knowledge-driven prior should be incorporated. Following the weighted-
MOCU based active learning algorithm in Algorithm 1, we can sequentially query the true system
and reduce the model uncertainty in a way that maximally reduces the classification error of the
corresponding OBC.
16
Published as a conference paper at ICLR 2021
Figure S3.	The expected OBC error regret comparison between different active learning algorithms
on binary classification.
Now we assume that when querying the system, the class label is given with a heterogeneous random
flipping error with the error probability being a function ofx1: p(y = 1|z = 0) = p(y = 0|z = 1) =
0.3 × (1 - 4x12) + 0.1. Therefore, when x1 = 0, the flipping error is 0.4; and when x1 = ±0.5, the
flipping error is 0.1. We have implemented the same methods as in the main text with 50 iterations
and 100 runs, The active learning results are illustrated in Fig. S4. As we can see, in this figure,
MES does not perform well as it cannot differentiate between model uncertainty and observation
error. ELR performs similarly to BALD and our weighted-MOCU based method at the beginning,
but then it gets stuck before finding the true boundary. BALD and our weighted MOCU perform
similarly. This is because in this setting p(y|x, θ) is either 1 or 0, so there is no irrelevant uncertainty
with which p(y|x, θ) is always larger or smaller than 0.5 but the value is uncertain.
In addition to the average performance comparison, we deliberately choose one of the runs in which
the ELR method gets stuck to better illustrate the difference between the existing ELR methods
and the proposed weighted-MOCU based method. In this run, the randomly chosen parameters are
(a = -3, b = 0, c = 1.9). Fig. S5(a) shows the error regret (the OBC error minus the true opti-
mal classifier error) comparison, in which ELR gets stuck and the weighted-MOCU based method
reaches 0. Notice that the y-axis is in the logarithm scale, so the vertical line in the WMOCU plot
implies that the value turns to 0. Error regret equals to 0 indicates that the OBC classifier equals to
the true optimal classifier, but in practice we don’t know the true optimal classifier, so we need the
value of MOCU to quantify the expected error difference between OBC and the optimal classifier
of each θ = (a, b, c). Fig. S5(b) shows the changes of MOCU value during the two active learn-
ing procedures. Not surprisingly, the MOCU value during the iterations of the ELR method also
gets stuck, while the MOCU value in the iterations of the weighted-MOCU method continues to de-
crease. Fig. S5(c) shows the changes of the maximum value of acquisition function in each iteration.
The acquisition function of ELR decrease to 0 after 22 iterations, and that explains why ELR gets
stuck. On the other hand, the maximum acquisition function of WMOCU is always positive as the
corresponding MOCU is positive, until it gets close to 10-16, which is the rounding error in floating
point arithmetic. In theory, as the observation is noisy, we can not be sure of the optimal prediction.
Therefore, the MOCU and the acquisition function of weighted-MOCU should always be positive,
which is demonstrated in the figures.
We have also performed an experiment to show the algorithm performance change under different
noise levels. We set the flipping error rate as p(y 6= z|x) =	× (1 - 4x12) + , 0 ≤	≤ 0.25.
Therefore, when x1 = 0, the flipping error is 2; and when x1 = ±0.5, the flipping error is .
We perform the same methods with 100 iterations and 100 runs on the noise level = 0.05 and
= 0.25. The resulting active learning performance curves are illustrated in Fig. S6. We can
17
Published as a conference paper at ICLR 2021
12 3
- - -
Ooo
111
」QJ」①
10-4
O
Iteration number
Figure S4.	The expected OBC error comparison between different active learning algorithms in the
setting with heterogeneous observation error.
O O
1 1
∙!6.!」0」.l
0	10	20	30	40	50
iteration number
(a) Error regret
W
4 β B
- - -
Ooo
111
Bos
0	10	20	30	40	50
Iteration number
(b) MOCU value
ɪ01010-10-
uo-un* Uonbue XeW
0	10	20	30	40	50
iteration number
(C) Acquisition function
Figure S5. Comparison of ELR and weighted MOCU on a specific run
—I- random
MES
—BALD
T- ELR
Weighted MOCU
1 2
O O
1 1
∙!63∙i」0j」3
0	20	40	60	80	100	0	20	40	60	80	100
Iteration number	Iteration number
(a) Noise level e = 0.05	(b) Noise level e = 0.25
Figure S6.	Active learning algorithm performance comparison with different noise levels
see from the figure that the performance of MES degrades significantly with high noise while the
performance of other methods does not appear to be very sensitive to the increasing noise level. .
H. Real-world benchmark experiment s.
We here present the complete results on the UCI User Knowledge dataset (Kahraman et al., 2013).
In addition to the uncertainty class setup in the main text, we have tested two other setups of hyper-
parameter values: 1) ‘uniform prior’ with αi = βi = 1, and 2) ’good prior’ with αi = βi = 10 in
eight bins chosen randomly, for other bins αi = 5, βi = 2 if the true frequency of High or Medium
18
Published as a conference paper at ICLR 2021
Figure S7.	Classification error rate comparison on UCI User Knowledge dataset
(a) Performance of letter E vs. F classification (b) Performance of letter P vs. D classification
Figure S8. Classification error rate comparison on UCI Letter Recognition dataset
in the i-th bin is higher than 0.5 and αi = 2, βi = 5 if the frequency is lower than 0.5. We also
randomly draw 150 samples from each class as the candidate pool and perform the five different
active learning algorithms. We repeat the whole procedure 150 times and the average error rates
are shown in Fig. S7. In both Fig. S7a and Fig. S7b, ELR performs the best in these two setups
while our Weighted MOCU performs similarly. BALD performs reasonably in Fig. S7a but it again
performs poorly in Fig. S7b. This is because the bins with α = β = 10 have less uncertainty but
have more impact on OBC prediction and BALD fails to identify that in this setup again.
We also present the results on the UCI Letter Recognition dataset (Dua & Graff, 2017). Letter
Recognition is a multi-class classification dataset with each sample having 16 numerical features
generated from typed images of the capital letters in the English alphabet. We select two pairs of
hard-to-distinguish letters: E vs. F and D vs. P. The total number of training samples is 1543 and
1608 for E vs. F and D vs. P, respectively. Active learning algorithms are applied with Bayesian
logistic regression models. We randomly take 100 data points first to construct the prior, and use the
rest of the data as the pool to test the five active learning algorithms. For prior construction, we train
a logistic regression model on the 100 data points and take the trained parameters as the mean of a
normal distributed prior with the variance equal to 1. Then we sample 1000 particles from the prior
as the uncertain parameter set. We repeat the whole procedure 100 times and the average error rates
are shown in Fig. S8. Unlike the synthetic datasets, the real-world datasets have no corresponding
true models. We can only find the optimal models that approximate the data best. However, we
can still see the trends of different algorithms. Compared with random sampling, all the algorithms
quickly converge to the optimal models. ELR performs the best in the first several iterations, while
converges slowly in the latter iterations. Our weighted MOCU based method is again demonstrated
to converge faster than other competing methods.
It is clear from all our experiments for both simulated and real-world data that, in addition to its
theoretical guarantee for active learning with OBC, our weighted MOCU method has achieved con-
sistently better or similar empirical performance compared to the best performing ones among the
19
Published as a conference paper at ICLR 2021
existing pool-based active learning methods, approaching the corresponding OBCs faster with fewer
labeled samples.
20