Published as a conference paper at ICLR 2021
The Risks of Invariant Risk Minimization
Elan Rosenfeld, Pradeep Ravikumar, Andrej Risteski
Machine Learning Department
Carnegie Mellon University
elan@cmu.edu, pradeepr@cs.cmu.edu, aristesk@andrew.cmu.edu
Ab stract
Invariant Causal Prediction (Peters et al., 2016) is a technique for out-of-distribution
generalization which assumes that some aspects of the data distribution vary across
the training set but that the underlying causal mechanisms remain constant. Re-
cently, Arjovsky et al. (2019) proposed Invariant Risk Minimization (IRM), an
objective based on this idea for learning deep, invariant features of data which
are a complex function of latent variables; many alternatives have subsequently
been suggested. However, formal guarantees for all of these works are severely
lacking. In this paper, we present the first analysis of classification under the IRM
objective—as well as these recently proposed alternatives—under a fairly natural
and general model. In the linear case, we give simple conditions under which the
optimal solution succeeds or, more often, fails to recover the optimal invariant
predictor. We furthermore present the very first results in the non-linear regime: we
demonstrate that IRM can fail catastrophically unless the test data are sufficiently
similar to the training distribution—this is precisely the issue that it was intended
to solve. Thus, in this setting we find that IRM and its alternatives fundamentally
do not improve over standard Empirical Risk Minimization.
1	Introduction
Prediction algorithms are evaluated by their performance on unseen test data. In classical machine
learning, it is common to assume that such data are drawn i.i.d. from the same distribution as the
data set on which the learning algorithm was trained—in the real world, however, this is often not the
case. When this discrepancy occurs, algorithms with strong in-distribution generalization guarantees,
such as Empirical Risk Minimization (ERM), can fail catastrophically. In particular, while deep
neural networks achieve superhuman performance on many tasks, there is evidence that they rely on
statistically informative but non-causal features in the data (Beery et al., 2018; Geirhos et al., 2018;
Ilyas et al., 2019). As a result, such models are prone to errors under surprisingly minor distribution
shift (Su et al., 2019; Recht et al., 2019). To address this, researchers have investigated alternative
objectives for training predictors which are robust to possibly egregious shifts in the test distribution.
The task of generalizing under such shifts, known as Out-of-Distribution (OOD) Generalization,
has led to many separate threads of research. One approach is Bayesian deep learning, accounting
for a classifier’s uncertainty at test time (Neal, 2012). Another technique that has shown promise is
data augmentation—this includes both automated data modifications which help prevent overfitting
(Shorten & Khoshgoftaar, 2019) and specific counterfactual augmentations to ensure invariance in
the resulting features (Volpi et al., 2018; Kaushik et al., 2020).
A strategy which has recently gained particular traction is Invariant Causal Prediction (ICP; Peters
et al. 2016), which views the task of OOD generalization through the lens of causality. This framework
assumes that the data are generated according to a Structural Equation Model (SEM; Bollen 2005),
which consists of a set of so-called mechanisms or structural equations that specify variables given
their parents. ICP assumes moreover that the data can be partitioned into environments, where each
environment corresponds to interventions on the SEM (Pearl, 2009), but where the mechanism by
which the target variable is generated via its direct parents is unaffected. Thus the causal mechanism
of the target variable is unchanging but other aspects of the distribution can vary broadly. As a result,
learning mechanisms that are the same across environments ensures recovery of the invariant features
which generalize under arbitrary interventions. In this work, we consider objectives that attempt to
1
Published as a conference paper at ICLR 2021
learn what we refer to as the “optimal invariant predictor”—this is the classifier which uses and is
optimal with respect to only the invariant features in the SEM. By definition, such a classifier does
not overfit to environment-specific properties of the data distribution, so it will generalize even under
major distribution shift at test time. In particular, we focus our analysis on one of the more popular
objectives, Invariant Risk Minimization (IRM; Arjovsky et al. (2019)), but our results can easily be
extended to similar recently proposed alternatives.
Various works on invariant prediction (Muandet et al., 2013; Ghassami et al., 2017; Heinze-Deml
et al., 2018; Rojas-Carulla et al., 2018; Subbaswamy et al., 2019; Christiansen et al., 2020) consider
regression in both the linear and non-linear setting, but they exclusively focus on learning with fully
or partially observed covariates or some other source of information. Under such a condition, results
from causal inference (Maathuis et al., 2009; Peters et al., 2017) allow for formal guarantees of the
identification of the invariant features, or at least a strict subset of them. With the rise of deep learning,
more recent literature has developed objectives for learning invariant representations when the data
are a non-linear function of unobserved latent factors, a common assumption when working with
complex, high-dimensional data such as images. Causal discovery and inference with unobserved
confounders or latents is a much harder problem (Peters et al., 2017), so while empirical results seem
encouraging, these objectives are presented with few formal guarantees. IRM is one such objective
for invariant representation learning. The goal of IRM is to learn a feature embedder such that the
optimal linear predictor on top of these features is the same for every environment—the idea being
that only the invariant features will have an optimal predictor that is invariant. Recent works have
pointed to shortcomings of IRM and have suggested modifications which they claim prevent these
failures. However, these alternatives are compared in broad strokes, with little in the way of theory.
In this work, we present the first formal analysis of classification under the IRM objective under a
fairly natural and general model which carefully formalizes the intuition behind the original work.
Our results show that despite being inspired by invariant prediction, this objective can frequently be
expected to perform no better than ERM. In the linear setting, we present simple, exact conditions
under which solving to optimality succeeds or, more often, breaks down in recovering the optimal
invariant predictor. We also demonstrate another major failure case—under mild conditions, there
exists a feasible point that uses only non-invariant features and achieves lower empirical risk than
the optimal invariant predictor; thus it will appear as a more attractive solution, yet its reliance on
non-invariant features mean it will fail to generalize. As corollaries, we present similar settings where
all recently suggested alternatives to IRM likewise fail. Futhermore, we present the first results in
the non-linear regime: we demonstrate the existence of a classifier with exponentially small sub-
optimality which nevertheless heavily relies on non-invariant features on most test inputs, resulting
in worse-than-chance performance on distributions that are sufficiently dissimilar from the training
environments. These findings strongly suggest that existing approaches to ICP for high-dimensional
latent variable models do not cleanly achieve their stated objective and that future work would benefit
from a more formal treatment.
2	Related work
Works on learning deep invariant representations vary considerably: some search for a domain-
invariant representation (Muandet et al., 2013; Ganin et al., 2016), i.e. invariance of the distribution
p(Φ(x)), typically used for domain adaptation (Ben-David et al., 2010; Ganin & Lempitsky, 2015;
Zhang et al., 2015; Long et al., 2018), with assumed access to labeled or unlabeled data from the target
distribution. Other works instead hope to find representations that are conditionally domain-invariant,
with invariance of p(Φ(x) | y) (Gong et al., 2016; Li et al., 2018). However, there is evidence that
invariance may not be sufficient for domain adaptation (Zhao et al., 2019; Johansson et al., 2019).
In contrast, this paper focuses instead on domain generalization (Blanchard et al., 2011; Rosenfeld
et al., 2021), where access to the test distribution is not assumed.
Recent works on domain generalization, including the objectives discussed in this paper, suggest
invariance of the feature-conditioned label distribution. In particular, Arjovsky et al. (2019) only
assume invariance of E[y | Φ(x)]; follow-up works rely on a stronger assumption of invariance of
higher conditional moments (Krueger et al., 2020; Xie et al., 2020; Jin et al., 2020; Mahajan et al.,
2020; Bellot & van der Schaar, 2020). Though this approach has become popular in the last year, it is
somewhat similar to the existing concept of covariate shift (Shimodaira, 2000; Bickel et al., 2009),
2
Published as a conference paper at ICLR 2021
which considers the same setting. The main difference is that these more recent works assume that
the shifts in p(Φ(x)) occur between discrete, labeled environments, as opposed to more generally
from train to test distributions.
Some concurrent lines of work study different settings yet give results which are remarkably similar
to ours. Xu et al. (2021) show that an infinitely wide two-layer network extrapolates linear functions
when the training data is sufficiently diverse. In the context of domain generalization specifically,
Rosenfeld et al. (2021) prove that ERM remains optimal for both interpolation and extrapolation in
the linear setting and that the latter is exponentially harder than the former. These results mirror our
findings that none of the studied objectives outperform ERM.
3	Model and Informal Results
We consider an SEM with explicit separation of invariant features zc, whose joint distribution with the
label is fixed for all environments, and environmental features ze (“non-invariant”), whose distribution
can vary. This choice is to ensure that our model properly formalizes the intuition behind invariant
prediction techniques such as IRM, whose objective is to ensure generalizing predictors by recovering
only the invariant features—we put off a detailed description of these objectives until after we have
introduced the necessary terminology.
We assume that data are drawn from a set of E training environments E = {e1, e2, . . . , eE} and that
we know from which environment each sample is drawn. For a given environment e, the data are
defined by the following process: first, a label y ∈ {±1} is drawn according to a fixed probability:
1,	w.p. η
-1, otherwise.
Next, both invariant features and environmental features are drawn according to a Gaussian:1
Zc 〜N(y ∙ μc,σ2I),	Ze 〜N(y ∙ μe,σ2I),
(1)
(2)
with μc ∈ Rdc ,μe ∈ Rde —typically, for complex, high-dimensional data We would expect E <
dc	de. Finally, the observation x is generated as a function of the latent features:
x = f (Zc, Ze).
(3)
The complete data generating process is displayed in Figure 3.1. We assume f is injective, so that it
is in principle possible to recover the latent features from the observations, i.e. there exists a function
Φ such that Φ(f(Zc, Ze)) = [Zc, Ze]T. We remark that this our only assumption on f, even when
it is non-linear. Further, note that we model class-conditional means as direct opposites merely
for clarity, as it greatly simplifies the calculations. None of our proofs require this condition: it is
straightforward to extend our results to arbitrary means, and the non-linear setting also allows for
arbitrary covariances. In fact, our proof technique for non-linear f could be applied to any distribution
that sufficiently concentrates about its mean (e.g., sub-Gaussian). We write the joint and marginal
distributions as pe(x, y, Zc, Ze). When clear from context, we omit the specific arguments.
Remarks on the model. This model is natural and flexible; it generalizes several existing models
used to analyze learning under the existence of adversarial distribution shift or non-invariant cor-
relations (Schmidt et al., 2018; Sagawa et al., 2020). The fundamental facet of this model is the
constancy of the invariant parameters η, μc, σc,f across environments—the dependence of μe, σe on
the environment allows for varying distributions, while the true causal process remains unchanged.
Here we make a few clarifying remarks:
•	We do not impose any constraints on the model parameters. In particular, we do not assume a
prior over the environmental parameters. Observe that μc, σ2 are the same for all environments,
1Note the deliberate choice to have ze depend on y. Much work on this problem models spurious features
which correlate with the label but are not causal. However, the term “spurious” is often applied incongruously; in
recent work, the term has been co-opted to refer to any feature that correlates with the label but does not cause it.
Thus there is a subtle distinction: if we allow for anti-causality, i.e. the label causing the features, the resulting
correlation is not spurious. We therefore avoid using the term “spurious” in this work.
3
Published as a conference paper at ICLR 2021
hence the subscript indicates the invariant relationship. In contrast, with some abuse of notation,
the environmental subscript is used to indicate both dependence on the environment and the index
of the environment itself (e.g., μ% represents the mean specific to environment i).
•	While we have framed the model as y causing zc, the causation can just as easily be viewed in the
other direction. The log-odds of y are a linear function of zc—this matches logistic regression with
an invariant regression vector βc = 2μjσ2 and bias βo = log I-Ln. We present the model as above
to emphasize that the causal relationships between y and the zc , ze are a priori indistinguishable,
and because we believe this direction is more intuitive.
We consider the setting where we are given infinite samples from
each environment; this allows us to isolate the behavior of the
objectives themselves, rather than finite-sample effects. Upon
observing samples from this model, our objective is thus to learn
a feature embedder Φ and classifier2 β to minimize the risk on an
unseen environment e:
Re(Φ,β) := E(x,y)〜pe h'(σ(βTΦ(x)),y)].
The function ` can be any loss appropriate to classification: in this
work we consider the logistic and the 0-1 loss. Note that we are
not hoping to minimize risk in expectation over the environments;
this is already accomplished via ERM or distributionally robust
optimization (DRO; Bagnell 2005; Ben-Tal et al. 2009). Rather,
we hope to extract and regress on invariant features while ignoring
environmental features, such that our predictor generalizes to all
Figure 3.1: A Bayesian network
depicting our model. Shading in-
dicates the variable is observed.
unseen environments regardless of their parameters. In other words, the focus is on minimizing risk
in the worst-case. We refer to the predictor which will minimize worst-case risk under arbitrary
distribution shift as the optimal invariant predictor. To discuss this formally, we define precisely
what we mean by this term.
Definition 1. Under the model described by Equations 1-3, the optimal invariant predictor is the
predictor defined by the composition of a) the featurizer which recovers the invariant features and b)
the classifier which is optimal with respect to those features:
φ*(X)= 0 0 ◦ f-1(x) = [zc],
ʌ
β*
βc
β0
2μJσ2]
log 士.
Observe that this definition closely resembles Definition 3 of Arjovsky et al. (2019); the only
difference is that here the optimal invariant predictor must recover all invariant features. As Arjovsky
et al. (2019) do not posit a data model, the concept of recovering “all invariant features” is not well-
defined for their setting; technically, a featurizer which outputs the empty set would elicit an invariant
ʌ
predictor, but this would not satisfy the above definition. The classifier β* is optimal with respect
to the invariant features and so it achieves the minimum possible risk without using environmental
features. Observe that the optimal invariant predictor is distinct from the Bayes classifier; the Bayes
classifier uses environmental features which are informative of the label but non-invariant; the optimal
invariant predictor explicitly ignores these features.
With the model defined, we can informally present our results; we defer the formal statements to
first give a background on the IRM objective in the next section. With a slight abuse of notation, we
ʌ
identify a predictor by the tuple Φ, β which parametrizes it. First, we show that the usefulness of
IRM exhibits a “thresholding” behavior depending on E and de :
Theorem 3.1	(Informal, Linear). For linear f, consider solving the IRM objective to learn a linear Φ
ʌ _____________________________________ ʌ
with invariant optimal classifier β. If E > de, then Φ, β is precisely the optimal invariant predictor;
it uses only invariant features and generalizes to all environments with minimax-optimal risk. If
ʌ
E ≤ de, then Φ, β relies upon non-invariant features.
In fact, when E ≤ de it is even possible to learn a classifier solely relying on environmental features
that achieves lower risk on the training environments than the optimal invariant predictor:
2Following the terminology of Arjovsky et al. (2019), We refer to the regression vector β as a “classifier” and
the composition of Φ, β as a “predictor”.
4
Published as a conference paper at ICLR 2021
ʌ
Theorem 3.2	(Informal, Linear). For linear f and E ≤ de there exists a linear predictor Φ, β which
uses only environmental features, yet achieves lower risk than the optimal invariant predictor.
Finally, in the non-linear case, we show that IRM fails unless the training environments approximately
“cover” the space of possible environments, and therefore it behaves similarly to ERM:
ʌ
Theorem 3.3 (Informal, Non-linear). For arbitrary f, there exists a non-linear predictor Φ, β which
is nearly optimal under the penalized objective and furthermore is nearly identical to the optimal
invariant predictor on the training distribution. However, for any test environment with a mean
sufficiently different from the training means, this predictor will be equivalent to the ERM solution on
nearly all test points. For test distributions where the environmental feature correlations with the
label are reversed, this predictor has almost 0 accuracy.
Extensions to other objectives. Many follow-up works have suggested alternatives to IRM—some
are described in the next section. Though these objectives perform better on various baselines,
there are few formal guarantees and no results beyond the linear case. Due to their collective
similarities, we can easily derive corollaries which extend every theorem in this paper to these
objectives, demonstrating that they all suffer from the same shortcomings. Appendix E contains
example corollaries for each of the results presented in this work.
4	Background on IRM and its Alternatives
During training, a classifier will learn to leverage correlations between features and labels in the
training data to make its predictions. If a correlation varies with the environment, it may not be
present in future test distributions—worse yet, it may be reversed—harming the classifier’s predictive
ability. IRM (Arjovsky et al., 2019) is a recently proposed approach to learning environmentally
invariant representations to facilitate invariant prediction.
The IRM objective. IRM posits the existence of a feature embedder Φ such that the optimal
classifier on top of these features is the same for every environment. The authors argue that such
a function will use only invariant features, since non-invariant features will have different joint
distributions with the label and therefore a fixed classifier on top of them won’t be optimal in all
environments. To learn this Φ, the IRM objective is the following constrained optimization problem:
1
min YjRe(Φ, ∕β')	s.t. β ∈ arg min Re(Φ,β) ∀e ∈ E.	(4)
φ,β	|E| e∈E	β
This bilevel program is highly non-convex and difficult to solve. To find an approximate solution, the
authors consider a Langrangian form, whereby the sub-optimality with respect to the constraint is
expressed as the squared norm of the gradients of each of the inner optimization problems:
min
Φ,β
(5)
Assuming the inner optimization problem is convex, achieving feasibility is equivalent to the penalty
term being equal to 0. Thus, Equations 4 and 5 are equivalent if we set λ = ∞.
Alternative objectives. IRM is motivated by the existence of a featurizer Φ such that E[y | Φ(x)]
is invariant. Follow-up works have proposed variations on this objective, based instead on the strictly
stronger desideratum of the invariance of p(y | Φ(x)). Krueger et al. (2020) suggest penalizing the
variance of the risks, while Xie et al. (2020) give the same objective but taking the square root of
the variance. Many papers have suggested similar alternatives (Jin et al., 2020; Mahajan et al., 2020;
Bellot & van der Schaar, 2020). These objectives are compelling—indeed, it is easy to show that the
optimal invariant predictor constitutes a stationary point of each of these objectives:
Proposition 4.1. Suppose the observed data are generated according to Equations 1-3. Then the
ʌ
(parametrized) optimal invariant predictor Φ*, β * is a Stationary point for Equation 4.
The stationarity of the optimal invariant predictor for the other objectives is a trivial corollary.
However, in the following sections we will demonstrate that such a result is misleading and that a
more careful investigation is necessary.
5
Published as a conference paper at ICLR 2021
5	The Difficulties of IRM in the Linear Regime
In their work proposing IRM, Arjovsky et al. (2019) present specific conditions for an upper bound
on the number of training environments needed such that a feasible linear featurizer Φ will have an
ʌ
invariant optimal regression vector β. Our first result is similar in spirit but presents a substantially
stronger (and simplified) upper bound in the classification setting, along with a matching lower
bound: we demonstrate that observing a large number of environments—linear in the number of
environmental features—is necessary for generalization in the linear regime.
Theorem 5.1 (Linear case). Assume f is linear. Suppose we observe E training environments. Then
the following hold:
1.	Suppose E > de. Consider any linear featurizer Φ which is feasible under the IRM objective (4),
ʌ
with invariant optimal classifier β 6= 0, and write Φ(f (zc, ze)) = Azc + Bze. Then under mild
ʌ
non-degeneracy conditions, it holds that B = 0. Consequently, β is the optimal classifier for all
possible environments.
2.	If E ≤ de and the environmental means μe are linearly independent, then there exists a linear
Φ 一where Φ(f (zc, Ze)) = Azc + Bze with rank (B) = de + 1 一 E -which is feasible under the
ʌ
IRM objective. Further, both the logistic and 0-1 risks of this Φ and its corresponding optimal β
are strictly lower than those of the optimal invariant predictor.
Similar to Arjovsky et al. (2019), the set of environments which do not satisfy Theorem 5.1 has
measure zero under any absolutely continuous density over environmental parameters. Further details,
and the full proof, can be found in Appendix C.1. Since the optimal invariant predictor is Bayes
with respect to the invariant features, by the data-processing inequality the only way a predictor
can achieve lower risk is by relying on environmental features. Thus, Theorem 5.1 directly implies
that when E ≤ de, the global minimum necessarily uses these non-invariant features and therefore
will not universally generalize to unseen environments. On the other hand, in the (perhaps unlikely)
case that E > de, any feasible solution will generalize, and the optimal invariant predictor has the
minimum (and minimax) risk of all such predictors:
Corollary 5.2. For both logistic and 0-1 loss, the optimal invariant predictor is the global minimum
of the IRM objective if and only if E > de.
Let us compare our theoretical findings to those of Arjovsky et al. (2019). Suppose the observations x
lie in Rd . Roughly, their theorem says that for a learned Φ of rank r with invariant optimal coefficient
ʌ ʌ
β, if the training set contains d 一 r + d/r “non-degenerate” environments, then β will be optimal
for all environments. There are several important issues with this result: first, they present no result
tying the rank of Φ to their actual objective; their theory thus motivates the objective, but does not
provide any performance guarantees for its solution. Next, observe when x is high-dimensional (i.e.
d de + dc)—in which case Φ will be comparatively low-rank (i.e. r ≤ de + dc)—their result
requires Ω(d) environments, which is extreme. For example, think of images on a low-dimensional
manifold embedded in very high-dimensional space. Even when d = dc + de , the “ideal” Φ which
recovers precisely zc would have rank dc, and therefore their condition for invariance would require
E > de + de/dc, a stronger requirement than ours; this inequality also seems unlikely to hold in most
real-world settings. Finally, they give no lower bound on the number of required environments—prior
to this work, there were no existing results for the performance of the IRM objective when their
conditions are not met. We also run a simple synthetic experiment to verify our theoretical results,
drawing samples according to our model and learning a predictor with the IRM objective. Details
and results of this experiment can be found in Appendix C.2. We now sketch a constructive proof of
part 2 of the theorem for when E = de :
Proof Sketch. Since f has an inverse over its range, we can define Φ as a linear function directly over
the latents [zc, ze]. Specifically, define Φ(x) = [zc, pTze]. Here, p is a unit-norm vector such that
∀e ∈ E, PTμe = σ2μ; μ is a fixed scalar that depends on the geometry of μe, σ2—such a vector exists
so long as the means are linearly independent. Observe that this Φ also has the desired rank. Since this
is a linear function ofa multivariate Gaussian, the label-conditional distribution of each environment’s
non-invariant latents has a simple closed form: PTze | y ~N(y ∙ PTμe, kpk2σ2) = N(y ∙ σ2μ,σ2)∙
6
Published as a conference paper at ICLR 2021
For separating two Gaussians, the optimal linear classifier is Σ-1(μ1 一 μo)—here, the optimal
classifier on PTZe is precisely 2", which does not depend on the environment (and neither do the
optimal coefficients for zc). Though the distribution varies across environments, the optimal classifier
is the same! Thus, Φ directly depends on the environmental features, yet the optimal regression vector
ʌ
β for each environment is constant. To see that it has lower risk than the optimal invariant predictor,
note that this classifier is Bayes with respect to its features and that the optimal invariant predictor
uses a strict subset of these features, and therefore it has less information for its predictions. □
A purely environmental predictor. The precise value of μ in the proof sketch above represents
how strongly this non-invariant feature is correlated with the label. In theory, a predictor that achieves
a lower objective value could do so by a very small margin—incorporating an arbitrarily small amount
of information from a non-invariant feature would suffice. This result would be less surprising, since
achieving low empirical risk might still ensure that we are “close” to the optimal invariant predictor.
Our next result shows that this is not the case: there exists a feasible solution which uses only the
environmental features yet performs better than the optimal invariant predictor on all e ∈ E for which
μ is large enough.
Theorem 5.3. Suppose we observe E ≤ de environments, such that all environmental means are
ʌ
linearly independent. Then there exists a feasible Φ, β which uses only environmental features
and achieves lower 0-1 risk than the optimal invariant predictor on every environment e such that
σeμ >σ-1kμck2 and 2σejlσ-1kμc∣∣2 ≥ ∣βo∣.
The latter of these two conditions is effectively trivial, requiring only a small separation of the means
and balance in class labels. From the construction of μ in the proof of Lemma C.1, we can see
that the former condition is more likely to be met when E de and in environments where some
non-invariant features are reasonably correlated with the label—both of which can be expected to hold
in the high-dimensional setting. Figure C.2 in the appendix plots the results for a few toy examples
for various dimensionalities and variances to see how often this condition holds in practice. For all
settings, the number of environments observed before the condition ceases to hold is quite high—on
the order of de 一 dc .
6	The Failure of IRM in the Non-Linear Regime
We’ve demonstrated that OOD generalization is difficult in the linear case, but it is achievable given
enough training environments. Our results—and those of Arjovsky et al. (2019)—intuitively proceed
by observing that each environment reduces a “degree of freedom” of the solution, such that only
the invariant features remain feasible if enough environments are seen. In the non-linear case, it’s
not clear how to capture this idea of restricting the “degrees of freedom”—and in fact our results
imply that this intuition is simply wrong. Instead, we show that the solution generalizes only to test
environments that are sufficiently similar to the training environments. Thus, these objectives present
no real improvement over ERM or DRO.
Non-linear transformations of the latent variables make it hard to characterize the optimal linear
classifier, which makes reasoning about the constrained solution to Equation 4 difficult. Instead
we turn our attention to Equation 5, the penalized IRM objective. In this section we demonstrate a
foundational flaw of IRM in the non-linear regime: unless we observe enough environments to “cover”
the space of non-invariant features, a solution that appears to be invariant can still wildly underperform
ʌ
on a new test distribution. We begin with a definition about the optimality of a coefficient vector β :
ʌ
Definition 2. For 0 < γ < 1, a coefficient vector β is γ-close to optimal for a label-conditional
feature distribution Z 〜N(y ∙ μ, Σ) if
βTμ ≥ (1 一 γ)2μTΣ-1μ.
Since the optimal coefficient vector is precisely 2Σ 1μ, being γ-close implies that β is reasonably
aligned with that optimum. Observe that the definition does not account for magnitude—the set of
vectors which is γ-close to optimal is therefore a halfspace which is normal to the optimal vector.
One of our results in the non-linear case uses the following assumption, which says that the observed
environmental means are sufficiently similar to one another.
7
Published as a conference paper at ICLR 2021
Assumption 1. There exists a 0 ≤ γ < 1 such that the ERM-optimal classifier for the non-invariant
features,
βe;ERM := arg min ∣E∣ X Ez°,ze,y〜pe ['(σ(βTZc + βTZe + βo), y)] ,	(6)
βe	| | e∈E
is γ-close to optimal for every environmental feature distribution in E.
This assumption says the environmental distributions are similar enough such that the optimal
“average classifier” is reasonably predictive for each environment individually. This is a natural
expectation: we are employing IRM precisely because we expect the ERM classifier to do well on
the training set but fail to generalize. If the environmental parameters are sufficiently orthogonal, we
might instead expect ERM to ignore the features which are not at least moderately predictive across
all environments. Finally, we note that if this assumption only holds for a subset of features, our
result still applies by marginalizing out the dimensions for which it does not hold.
We are now ready to give our main result in the non-linear regime. We present a simplified version,
assuming that that σe2 = 1 ∀e. This is purely for clarity of presentation; the full theorem is presented
in Appendix D. We make use of two constants in the following proof-the average squared norm
of the environmental means, kμk2 := E Pe∈E kμek2; and the standard deviation of the response
variable of the ERM-optimal classifier, germ ：= Vzkβck2σ2 + kβepRM∣∣2σ2.
Theorem 6.1 (Non-linear case, simplified). Suppose we observe E environments E =
{e1, e2 , . . . , eE }, where σe2 = 1 ∀e. Then, for any > 1, there exists a featurizer Φ which,
combined with the ERM-optimal classifier β = [βc, βe;erm, βo]T, satisfies thefollowing properties,
where we define p := exp{-de min( - 1, ( - 1)2)/8}):
ʌ
1.	The regularization term of Φ, β as in Equation 5 is bounded as
E X k%Re(Φe, β)k2 ∈ O (p2 (Cede + PI)),
e∈E
for some constant ce that depends only on .
ʌ
2.	Φe, β exactly matches the optimal invariant predictor on at least a 1- pe fraction of the training
set. On the remaining inputs, it matches the ERM-optimal solution.
Further, for any test distribution, suppose its environmental mean μE+ι is SUfficientlyfarfrOm the
training means:
∀e ∈ E, min ∣∣μE+ι - y ∙ μe∣∣2 ≥ (√e + δ) VZde	(7)
y∈{±1}
for some δ > 0, and define q := √E exp{-δ2}. Then thefollowing holds:
ʌ
3.	Φe, β is equivalent to the ERM-optimal predictor on at least a 1- q fraction of the test distribution.
4. Under Assumption 1, suppose it holds that μE+ι = 一 ∑e∈E ɑeμe for some set of coefficients
{αe }e∈E . Then so long as
X ae kμek2 ≥ kμck2∕σ2 + lβ0l∕2 + σERM ,	(8)
e∈E	1- γ
ʌ
the 0-1 risk ofΦe, β on the new environment is greater than .975 - q.
We give a brief intuition for each of the claims made in this theorem, followed by a sketch of the
proof—the full proof can be found in Appendix D.
1. The first claim says that the predictor we construct will have a gradient squared norm scaling
as pe2 which is exponentially small in de . Thus, in high dimensions, it will appear as a perfectly
reasonable solution to the objective (5).
8
Published as a conference paper at ICLR 2021
2.	The second claim says that this predictor is identical to the invariant optimal predictor on all
but an exponentially small fraction of the training data; on the remaining fraction, it matches
the ERM-optimal solution, which has lower risk. The correspondence between constrained and
penalized optimization implies that for large enough de , the “fake” predictor will often be a
preferred solution. In the finite-sample setting, we would need exponentially many samples to
even distinguish between the two!
3.	The third claim is the crux of the theorem; it says that this predictor we’ve constructed will
completely fail to use invariant prediction on most environments. Recall, the intent of IRM is to
perform well precisely when ERM breaks down: when the test distribution differs greatly from
the training distribution. Assuming a Gaussian prior on the training environment means, they will
have separation in O(ʌ/dɪ) with high probability. Observe that q will be vanishingly small so
long as δ ≥ polylog(E). Part 3 says that IRM fails to use invariant prediction on any environment
that is slightly outside the high probability region of the prior; even a separation of Ω(√de log E)
suffices. If we expect the new environments to be similar, ERM already guarantees reasonable
performance at test-time; thus, IRM fundamentally does not improve over ERM in this regime.
4.	The final statement demonstrates a particularly egregious failure case of this predictor: just like
ERM, if the correlation between the non-invariant features and the label reverses at test-time, our
predictor will have significantly worse than chance performance.
Proof Sketch. We give a construction which is almost identical to the optimal invariant predictor
on the training data yet behaves like the ERM solution at test time. We partition the environmental
feature space into two sets, B, Bc. B is the union of balls centered at each μe, each with a large
enough radius that it contains most of the samples from that environment; thus B represents the vast
majority of the training distribution. On this set, define Φ(x) = [zc], so our construction is equal to
the optimal invariant predictor. Now consider Bc = Rde \ B. We use standard concentration results
to upper bound the measure of Bc under the training distribution by p. Next, we show how choosing
Φ(x) = f-1(x) = [zc, ze]T on this set results in the sub-optimality bound, which is of orderp2. It is
also clear that our constructed predictor is equivalent to the ERM-optimal solution on Bc . Thus, our
predictor will often have lower empirical risk on Bc, countering the regularization penalty.
The second part of the proof shows that while B has large measure under the training environments,
it will have very small measure under any moderately different test environment. We can see this by
considering the separation of means (Equation 7); the measure of each ball in B can be bounded by
the measure of the halfspace containing it; if each ball is far enough away from μE+ι, then the total
measure of these halfspaces must be small. At test time, our predictor will therefore match the ERM
solution on all but q of the observations (part 3). Finally, we lower bound the 0-1 risk of the ERM
predictor under such a distribution shift by analyzing the distribution of the response variable. The
proof is completed by observing that our predictor,s risk can differ from this by at most q.	□
Theorem 6.1 shows that it’s possible for the IRM solution to perform poorly on environments which
differ even moderately from the training data. We can of course guarantee generalization if the
training distributions “cover” (or approximately cover) the full space of environments in order to tie
down the performance on future distributions. But in such a scenario, there would no longer be a
need for ICP; we could expect ERM or DRO to perform just as well. Once more, we find that our
result trivially extends to the alternative objectives; we again refer to Appendix E.
7 Conclusion
Out-of-distribution generalization is an important direction for future research, and Invariant Causal
Prediction remains a promising approach. However, formal results for latent variable models are
lacking, particularly in the non-linear setting with fully unobserved covariates. This paper demon-
strates that Invariant Risk Minimization and subsequent related works have significant under-explored
risks and issues with their formulation. This raises the question: what is the correct formulation for
invariant prediction when the observations are complex, non-linear functions of unobserved latent
factors? We hope that this work will inspire further theoretical study on the effectiveness of IRM and
similar objectives for invariant prediction.
9
Published as a conference paper at ICLR 2021
Acknowledgements
We thank Adarsh Prasad, Jeremy Cohen, and Zack Lipton for helpful feedback. Special thanks to
Adarsh Prasad for noticing our initial formatting error. E.R. and P.R. acknowledge the support of
NSF via IIS-1909816, IIS-1955532 and ONR via N000141812861.
References
Martin Arjovsky, Leon Bottou,Ishaan Gulrajani, and David Lopez-Paz. Invariant risk minimization.
arXiv preprint arXiv:1907.02893, 2019.
J Andrew Bagnell. Robust supervised learning. In Proceedings of the 20th national conference on
Artificial intelligence-Volume 2,pp. 714-719, 2005.
Sara Beery, Grant Van Horn, and Pietro Perona. Recognition in terra incognita. In Proceedings of the
European Conference on Computer Vision (ECCV), pp. 456-473, 2018.
Alexis Bellot and Mihaela van der Schaar. Generalization and invariances in the presence of
unobserved confounding. arXiv preprint arXiv:2007.10653, 2020.
Shai Ben-David, John Blitzer, Koby Crammer, Alex Kulesza, Fernando Pereira, and Jennifer Wortman
Vaughan. A theory of learning from different domains. Machine learning, 79(1-2):151-175, 2010.
Aharon Ben-Tal, Laurent El Ghaoui, and Arkadi Nemirovski. Robust optimization, volume 28.
Princeton University Press, 2009.
Steffen Bickel, Michael Bruckner, and Tobias Scheffer. Discriminative learning under covariate shift.
Journal of Machine Learning Research, 10(9), 2009.
Gilles Blanchard, Gyemin Lee, and Clayton Scott. Generalizing from several related classification
tasks to a new unlabeled sample. Advances in neural information processing systems, 24:2178-
2186, 2011.
Kenneth A Bollen. Structural equation models. Encyclopedia of biostatistics, 7, 2005.
Rune Christiansen, Niklas Pfister, Martin Emil Jakobsen, Nicola Gnecco, and Jonas Peters. A causal
framework for distribution generalization. arXiv preprint arXiv:2006.07433, 2020.
Yaroslav Ganin and Victor Lempitsky. Unsupervised domain adaptation by backpropagation. In
International conference on machine learning, pp. 1180-1189. PMLR, 2015.
Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo Larochelle, FrangoiS
Laviolette, Mario Marchand, and Victor Lempitsky. Domain-adversarial training of neural networks.
The Journal of Machine Learning Research, 17(1):2096-2030, 2016.
Robert Geirhos, Patricia Rubisch, Claudio Michaelis, Matthias Bethge, Felix A Wichmann, and
Wieland Brendel. Imagenet-trained cnns are biased towards texture; increasing shape bias improves
accuracy and robustness. arXiv preprint arXiv:1811.12231, 2018.
AmirEmad Ghassami, Saber Salehkaleybar, Negar Kiyavash, and Kun Zhang. Learning causal
structures using regression invariance. In Advances in Neural Information Processing Systems, pp.
3011-3021, 2017.
Mingming Gong, Kun Zhang, Tongliang Liu, Dacheng Tao, Clark Glymour, and Bernhard Scholkopf.
Domain adaptation with conditional transferable components. In International conference on
machine learning, pp. 2839-2848, 2016.
Christina Heinze-Deml, Jonas Peters, and Nicolai Meinshausen. Invariant causal prediction for
nonlinear models. Journal of Causal Inference, 6(2), 2018.
Andrew Ilyas, Shibani Santurkar, Dimitris Tsipras, Logan Engstrom, Brandon Tran, and Aleksander
Madry. Adversarial examples are not bugs, they are features. In H. Wallach, H. Larochelle,
A. Beygelzimer, F. dAlche-Buc, E. Fox, and R. Garnett (eds.), Advances in Neural Information
Processing Systems 32, pp. 125-136. Curran Associates, Inc., 2019.
10
Published as a conference paper at ICLR 2021
Wengong Jin, Regina Barzilay, and Tommi Jaakkola. Domain extrapolation via regret minimization.
arXiv preprint arXiv:2006.03908, 2020.
Fredrik D Johansson, David Sontag, and Rajesh Ranganath. Support and invertibility in domain-
invariant representations. arXiv preprint arXiv:1903.03448, 2019.
Divyansh Kaushik, Eduard Hovy, and Zachary Lipton. Learning the difference that makes a difference
with counterfactually-augmented data. In International Conference on Learning Representations,
2020.
David Krueger, Ethan Caballero, Joern-Henrik Jacobsen, Amy Zhang, Jonathan Binas, Remi Le Priol,
and Aaron Courville. Out-of-distribution generalization via risk extrapolation (rex). arXiv preprint
arXiv:2003.00688, 2020.
Frank R Kschischang. The complementary error function. 2017. URL https://www.comm.
utoronto.ca/frank/notes/erfc.pdf.
Ya Li, Xinmei Tian, Mingming Gong, Yajing Liu, Tongliang Liu, Kun Zhang, and Dacheng Tao.
Deep domain generalization via conditional invariant adversarial networks. In Proceedings of the
European Conference on Computer Vision (ECCV), pp. 624-639, 2018.
Mingsheng Long, Zhangjie Cao, Jianmin Wang, and Michael I Jordan. Conditional adversarial
domain adaptation. In Advances in Neural Information Processing Systems, pp. 1640-1650, 2018.
Marloes H Maathuis, Markus Kalisch, Peter Buhlmann, et al. Estimating high-dimensional interven-
tion effects from observational data. The Annals of Statistics, 37(6A):3133-3164, 2009.
Divyat Mahajan, Shruti Tople, and Amit Sharma. Domain generalization using causal matching.
arXiv preprint arXiv:2006.07500, 2020.
Krikamol Muandet, David Balduzzi, and Bernhard Scholkopf. Domain generalization via invariant
feature representation. volume 28 of Proceedings of Machine Learning Research, pp. 10-18,
Atlanta, Georgia, USA, 17-19 Jun 2013. PMLR. URL http://proceedings.mlr.press/
v28/muandet13.html.
Radford M Neal. Bayesian learning for neural networks, volume 118. Springer Science &amp;
Business Media, 2012.
Judea Pearl. Causality. Cambridge university press, 2009.
J Peters, D Janzing, and B Scholkopf. Elements of causal inference-foundations and learning
algorithms. 2017.
Jonas Peters, Peter Buhlmann, and Nicolai Meinshausen. Causal inference by using invariant
prediction: identification and confidence intervals. Journal of the Royal Statistical Society, 2016.
Benjamin Recht, Rebecca Roelofs, Ludwig Schmidt, and Vaishaal Shankar. Do imagenet classifiers
generalize to imagenet? arXiv preprint arXiv:1902.10811, 2019.
Mateo Rojas-Carulla, Bernhard Scholkopf, Richard Turner, and Jonas Peters. Invariant models for
causal transfer learning. The Journal of Machine Learning Research, 19(1):1309-1342, 2018.
Elan Rosenfeld, Pradeep Ravikumar, and Andrej Risteski. An online learning approach to interpola-
tion and extrapolation in domain generalization. arXiv preprint arXiv:2102.13128, 2021.
Shiori Sagawa, Aditi Raghunathan, Pang Wei Koh, and Percy Liang. An investigation of why
overparameterization exacerbates spurious correlations. In Proceedings of the 37th International
Conference on Machine Learning, 2020.
Ludwig Schmidt, Shibani Santurkar, Dimitris Tsipras, Kunal Talwar, and Aleksander Madry. Ad-
versarially robust generalization requires more data. In S. Bengio, H. Wallach, H. Larochelle,
K. Grauman, N. Cesa-Bianchi, and R. Garnett (eds.), Advances in Neural Information Processing
Systems 31, pp. 5014-5026. Curran Associates, Inc., 2018.
11
Published as a conference paper at ICLR 2021
Hidetoshi Shimodaira. Improving predictive inference under covariate shift by weighting the log-
likelihood function. Journal of statistical planning and inference, 90(2):227-244, 2000.
Connor Shorten and Taghi M Khoshgoftaar. A survey on image data augmentation for deep learning.
Journal of Big Data, 6(1):60, 2019.
Jiawei Su, Danilo Vasconcellos Vargas, and Kouichi Sakurai. One pixel attack for fooling deep neural
networks. IEEE Transactions on Evolutionary Computation, 23(5):828-841, 2019.
Adarsh Subbaswamy, Peter Schulam, and Suchi Saria. Preventing failures due to dataset shift:
Learning predictive models that transport. In The 22nd International Conference on Artificial
Intelligence and Statistics, pp. 3118-3127. PMLR, 2019.
Riccardo Volpi, Hongseok Namkoong, Ozan Sener, John C Duchi, Vittorio Murino, and Silvio
Savarese. Generalizing to unseen domains via adversarial data augmentation. In Advances in
neural information processing systems, pp. 5334-5344, 2018.
Chuanlong Xie, Fei Chen, Yue Liu, and Zhenguo Li. Risk variance penalization: From distributional
robustness to causality. arXiv preprint arXiv:2006.07544, 2020.
Keyulu Xu, Mozhi Zhang, Jingling Li, Simon Shaolei Du, Ken-Ichi Kawarabayashi, and Stefanie
Jegelka. How neural networks extrapolate: From feedforward to graph neural networks. In
International Conference on Learning Representations, 2021. URL https://openreview.
net/forum?id=UH-cmocLJC.
Kun Zhang, Mingming Gong, and Bernhard Scholkopf. Multi-source domain adaptation: a causal
view. In Proceedings of the Twenty-Ninth AAAI Conference on Artificial Intelligence, pp. 3150-
3157, 2015.
Han Zhao, Remi Tachet Des Combes, Kun Zhang, and Geoffrey Gordon. On learning invariant
representations for domain adaptation. In International Conference on Machine Learning, pp.
7523-7532, 2019.
12
Published as a conference paper at ICLR 2021
A Additional Notation for the Appendix
To avoid overloading, we use φ, F for the standard Gaussian PDF and CDF respectively. We write
SC to denote the set complement of a set S. We write | ∙ | to denote entrywise absolute value.
B Proof of Proposition 4.1
Recall the IRM objective:
T
min	E(x,y)〜p(x,y)[-log σ(y ∙ β φ(X))]
Φ,β
∂T
subject to --E(x ygp e [—log σ(y ∙ βT Φ(x))] = 0. ∀e ∈ E.
∂β
Concretely, we represent Φ as some parametrized function Φθ, over whose parameters θ we then
optimize. The derivative of the negative log-likelihood for logistic regression with respect to the β
coefficients is well known:
∂∂^ h- logσ(y ∙βφθ(X))]
(σ(βτ Φθ (χ)) — 1{y = 1})Φθ (x).
Suppose we recover the true invariant features Φθ (x) = Zc and coefficients β = 10j (in other
words, we allow for the introduction of new features). Then the IRM constraint becomes:
0 ==E(x,y)~pe [— log σ(y ∙ βτΦθ(x))]
∂β
∂
=P p (Zc) E p (y | Zc)~^ [-logσ(y ∙ βτz°)] dz°
Z	y∈{±1}	∂β
pe(Zc)Φθ(X)
Z
σ(βτ Zc )(σ(βτ Zc)- 1) + (1 — σ(βTZc))σ(βτ Zc)
dZc.
ʌ
Since β is constant across environments, this constraint is clearly satisfied for every environment, and
ʌ
is therefore also the minimizing β for the training data as a whole.
Considering now the derivative with respect to the featurizer Φθ :
∂θ h- logσ(y ∙ βτΦθ(x))i = (σ(βτΦθ(x)) — 1{y = 1})%^Φθ(x).
Then the derivative of the loss with respect to these parameters is
σ(βτ Zc)(σ(βτ Zc) — 1) + (1 — σ(βτ Zc))σ(βτ Zc) dZc = 0.
So, the optimal invariant predictor is a stationary point with respect to the feature map parameters as
well.
C Results from Section 5
C.1 Proof of Theorem 5.1
We begin by formally stating the non-degeneracy condition. Consider any environmental mean μe,
and suppose it can be written as a linear combination of the others means with coefficients αe:
μe =)： αi μi∙
i
13
Published as a conference paper at ICLR 2021
Then the environments are considered non-degenerate if the following inequality holds for any such
set of coefficients:
αie 6= 1,
i
(9)
and furthermore that the following ratio is different for at least two different environments a, b:
∃αa, αb.
σ - Pi αaσ2
1 - Pi αa
σ - Pi αbσ2
1 - Pi αb
(10)
The first inequality says that none of the environmental means are are an affine combination of the
others; in other words, they lie in general linear position, which is the same requirement as Arjovsky
et al. (2019). The other inequality is a similarly lax non-degeneracy requirement regarding the relative
scale of the variances. It is clear that the set of environmental parameters that do not satisfy Equations
9 and 10 has measure zero under any absolutely continuous density, and similarly, if E ≤ de then the
environmental means will be linearly independent almost surely.
We can now proceed with the proof, beginning with some helper lemmas:
Lemma C.1. Suppose we observe E environments E = {e1, e2, . . . , eE}, each with environmental
mean of dimension de ≥ E, such that all environmental means are linearly independent. Then there
is a unique unit-norm vector p such that
PTμe = σ2 μ ∀e ∈ E,	(11)
where μ is the largest scalar which admits such a solution.
Proof. Let vι, v2,...,ve be a set of basis vectors for span{μι, μ2,..., μE}. Each mean can then
be expressed as a combination of these basis vectors: ui = PjE=1 αij vj . Since the means are linearly
independent, we can combine these coefficients into a single invertible matrix
-a11	α21	...	αE1 ^
α12	α22	. . .	αE2
U =	.	.	.	^^
.	..	.
α1E α2E	. . . αEE
We can then combine the constraints (11) as
「σ2 ]
σ22
U T Pa = σ ,.,
.
.
σE2
where Pα denotes our solution expressed in terms of the basis vectors {vi}iE=1. This then has the
solution
Pα = U-Tσ.
This defines the entire space of solutions, which consists of Pα plus any element of the remaining
(de - E)-dimensional orthogonal subspace. However, we want P to be unit-norm—observe that the
current vector solves Equation 11 with μ = 1, which means that after normalizing We get μ = ɪpɪ.
Adding any element of the orthogonal subspace would only increase the norm of p, decreasing μ.
Thus, the unique maximizing solution is
一 —U-tσ	…1
Pa = ^∖∖~ττ^^T~H-,	with μ = 7777^^T~1•
kU-Tσk2	kU-Tσk2
Finally, Pa has to be rotated back into the original space by defining P = P3 PaiVi.	口
Lemma C.2. Assume f is linear. Suppose we observe E ≤ de environments whose means are
linearly independent. Then there exists a linear Φ with rank(Φ) = dc + de + 1 - E whose output
depends on the environmental features, yet the optimal classifier on top of Φ is invariant.
14
Published as a conference paper at ICLR 2021
Proof. We will begin with the case when E = de and then show how to modify this construction for
when E < de. Consider defining
Φ
I
0
with
—— 0 ——
M =
.
.
.
—— 0 ——
Here, p ∈ Rdc is defined as the unit-norm vector solution to
T2
p μe = σe μ ∀e
such that μ is maximized—such a vector is guaranteed to exist by Lemma C.1. Thus We get
Φ(x) = Tc , which is of rank d + 1 as desired. Define Ze = PTZe, which means that Ze | y 〜
p ze
N(y ∙ σ2μ,σ2). For each environment we have
P(y | zc, Ze)
P(Zc,ze,y)
P(Zc,Ze)
_________________σ(y ∙ βTZc)P(Ze | y ∙ σe2μ,σ2D__
[σ(y ∙ βTZc)P(Ze | y ∙ σe2μ, σ2) + σ(-y ∙ βTZc)P(Ze | -y ∙ σe2μ,σ2)]
_________________________________________________σ(y ∙ βTZc)exp(y ∙焉”)_
[σ(y ∙ βτZc)exp(y ∙ Zeμ) + σ(-y ∙ βτZc)exp(-y ∙ Zefi)]
1
1 + exp(-y ∙ (βTZc + 2iei))'
The log-odds of y is linear in these features, so the optimal classifier is
ʌ
β
βc
2μ
which is the same for all environments.
Now we show how to modify this construction for when E < de . If we remove one of the environ-
mental means, Φ trivially maintains its feasibility. Note that since they are linearly independent, the
mean which was removed has a component in a direction orthogonal to the remaining means. Call
this component P0 , and consider redefining M as
T
P
0T
P0T
0
M
L 0 一.
The distribution of Zie in each of the remaining dimensions is normal with mean 0, which means a
ʌ
corresponding coefficient of 0 is optimal for all environments. So the classifier β remains optimal
for all environments, yet we’ve added another row to M which increases the dimensionality of its
span, and therefore the rank of Φ, by 1. Working backwards, we can repeat this process for each
additional mean, such that rank(Φ) = dc + 1 + (de - E), as desired. Note that for E = 1 any Φ will
be vacuously feasible.	□
Lemma C.3. Suppose we observe E environments E = {e1, e2, . . . , eE} whose parameters satisfy
the non-degeneracy conditions (9, 10). Let Φ(x) = AZc + BZe be any feature vector which is a
ʌ
linear function of the invariant and environmental features, and suppose the optimal β on top of Φ is
ʌ
invariant. If E > de, then β = 0 or B = 0.
15
Published as a conference paper at ICLR 2021
Proof. Write Φ = [A|B] where A ∈ Rd×dc, B ∈ Rd×de and define
μe = Φ
Σ e = Φ
μc
μe
σc2Idc
0
Aμc + Bμe,
σc2AAT + σe2BBT.
Without loss of generality We assume Σ is invertible (if it is not, We can consider just the subspace in
which it is—outside of this space, the features have no variance and therefore cannot carry information
about the label). By Lemma F.2, the optimal coefficient for each environment is 2∑-1“e. In order
ʌ
for this vector to be invariant, it must be the same across environments; We Write it as a constant β.
ʌ
Suppose μe = 0 for some environment e—then the claim is trivially true with β = 0. We therefore
proceed under the assumption that μe = 0 ∀e ∈ E.
With this fact, We have that ∀e ∈ E ,
β = 2(σ2AAT + σ2BBT )-1(Aμ0 + Bμe)
0 (σ2AAT + σ2BBT)β = 2Aμc + 2Bμe
^⇒ σ2BBTβ - 2Bμe = 2Aμc - σ∣AATβ.	(12)
Define the vector V = 2Aμc - σ∣ AATβ. We will show that for any β, A, with probability 1 only
B = 0 can satisfy Equation 12 for every environment. If E > de , then there exists at least one
environmental mean which can be written as a linear combination of the others. Without loss of
generality, denote the parameters of this environment as (μ, σ2) and write μ = Pi= 1 3出》However,
note that by assumption the means lie in general linear position, and therefore we actually have at
least de sets of coefficients α for which this holds. Rearranging Equation 12, we get
σ2BBTβ - V = 2Bμ
de
=αi2Bμi
i=1
de
=X α∕σ2BBTβ - VL
i=1
and rearranging once more yields
(σ2 - X αiσ2) BBTβ=(1 - X α) v.
By assumption, (1 - P αi) is non-zero. We can therefore rewrite this as
αBBT β = v,
where α = σ i-ξ：* is a scalar. As the vectors BBTβ and V are both independent of the
environment, this can only hold true if a is fixed for all environments or if both BBTβ, V are 0. The
former is false by assumption, so the the latter must hold.
As a result, we see that Equation 12 reduces to
Bμe = 0 ∀e ∈ E.
As the span of the observed μe is all of Rde, this is only possible if B = 0.	口
We are now ready to prove the main claim. We restate the theorem here for convenience:
Theorem 5.1 (Linear case). Assume f is linear. Suppose we observe E training environments. Then
the following hold:
16
Published as a conference paper at ICLR 2021
1.	Suppose E > de. Consider any linear featurizer Φ which is feasible under the IRM objective (4),
ʌ
with invariant optimal classifier β 6= 0, and write Φ(f (zc, ze)) = Azc + Bze. Then under mild
ʌ
non-degeneracy conditions, it holds that B = 0. Consequently, β is the optimal classifier for all
possible environments.
2.	If E ≤ de and the environmental means μe are linearly independent, then there exists a linear
Φ 一where Φ(f (zc, Ze)) = Azc + Bze with rank (B) = de + 1 一 E -which is feasible under the
ʌ
IRM objective. Further, both the logistic and 0-1 risks of this Φ and its corresponding optimal β
are strictly lower than those of the optimal invariant predictor.
Proof. 1. Since Φ, f are linear, we can write Φ(x) = Azc + Bze for some matrices A, B.
Assume the non-degeneracy conditions (9, 10) hold. By Lemma C.3, one of B = 0 or
ʌ ʌ
β = 0 holds. Thus, Φ, β uses only invariant features. Since the joint distribution pe(zc, y) is
invariant, this predictor has identical risk across all environments.
2. The existence of such a predictor is proven by Lemma C.2. It remains to show that the risk
of this discriminator is lower than that of the optimal invariant predictor. Observe that these
features are non-degenerate independent random variables with support over all of R, and
therefore by Lemma F.1, dropping the ze term and using
φ(X) = [zc],	β= βc
results in strictly higher risk. The proof is completed by noting that this definition is precisely
the optimal invariant predictor.	□
C.2 Experiments for Theorem 5.1
To corroborate our theoretical findings, we run an experiment on data drawn from our model to see at
what point IRM is able to recover a generalizing predictor. We generated data precisely according to
our model in the linear setting, with dc = 3, de = 6. The environmental means were drawn from a
multivariate Gaussian prior; we randomly generated the invariant parameters and the parameters of the
prior such that using the invariant features gave reasonable accuracy (71.9%) but the environmental
features would allow for almost perfect accuracy on in-distribution test data (99.8%). Thus, the goal
was to see if IRM could successfully learn a predictor which ignores meaningful covariates ze , to the
detriment of its training performance but to the benefit of OOD generalization. We chose equal class
marginals (η = 0.5).
Figure C.1 shows the result of five runs of IRM, each with different environmental parameters but
the same invariant parameters (the training data itself was redrawn for each run). We found that
optimizing for the IRM objective was quite unstable, frequently collapsing to the ERM solution
unless λ and the optimizer learning rate were carefully tuned. This echoes the results of Krueger
et al. (2020) who found that tuning λ during training to specific values at precisely the right time
is essential for good performance. To prevent collapse, we kept the same environmental prior and
found a single setting for λ and the learning rate which resulted in reasonable performance across
all five runs. At test time, we evaluated the trained predictors on additional, unseen environments
whose parameters were drawn from the same prior. To simulate distribution shift, we evaluated the
predictors on the same data but with the environmental means negated. Thus the correlations between
the environmental features ze and the label y were reversed.
Observe that the results closely track the expected outcome according to Theorem 5.1: up until
E = de, IRM essentially matches ERM in performance both in-distribution and under distribution
shift. As soon as we cross that threshold of observed environments, the predictor learned via IRM
begins to perform drastically better under distribution shift, behaving more like the optimal invariant
predictor. We did however observe that occasionally the invariant solution would be found after
only E = de = 6 environments; we conjecture that this is because at this point the feasible-yet-not-
invariant predictor with lower objective value presented in Theorem 5.1 is precisely a single point, as
opposed to a multi-dimensional subspace, and therefore might be difficult for the optimizer to find.
17
Published as a conference paper at ICLR 2021
Figure C.1: Performance of predictors learned with IRM (5 different runs) and ERM (dashed lines) on
test distributions where the correlation between environmental features and the label is consistent (no
shift) or reversed (shift). The dashed green line is the performance of the optimal invariant predictor.
Observe that up until E = de, IRM consistently returns a predictor with performance similar to
ERM: good generalization without distribution shift, but catastrophic failure when the correlation is
ʌ
reversed. In contrast, once E > de, IRM is able to recover a Φ, β with performance similar to that of
the invariant optimal predictor.
C.3 Proof of Theorem 5.3
Theorem 5.3. Suppose we observe E ≤ de environments, such that all environmental means are
ʌ
linearly independent. Then there exists a feasible Φ, β which uses only environmental features
and achieves lower 0-1 risk than the optimal invariant predictor on every environment e such that
σeμ > σ-1 kμc∣∣2 and ZJeμσ-1 ∣∣μc∣∣2 ≥ ∣βo|.
Proof. We consider the non-invariant predictor constructed as described in Lemma C.2, but dropping
the invariant features and coefficients. By Lemma F.2, the optimal coefficients for the invariant and
non-invariant predictors are
ʌ
βcaus
2σ-2μc
β0
and
ʌ
βnon-caus
2μ'
β0
respectively. Therefore, the 0-1 risk of the optimal invariant predictor is precisely
ηP(2σ-2μTZc + βo < 0) + (1 — η)P(-2σ-2μTZC + βo > 0)
=ηF (一σ-1 kμc l∣2 - 2f0 σc∖ ) + (1 - η)F (一σ-1 kμc l∣2 + 2”C ),
2kμc l∣2	2kμc l∣2√
where F is the Gaussian CDF. By the same reasoning, the 0-1 risk of the non-invariant predictor is
ηF (一σeμ	- /0〜)+ (I - η)F	(一σeμ	+ /0〜).
1	2σe μj	I	IQe μj
Define α = σ-1 ∣∣μc∣∣2 and Y = σeμ. By monotonicity of the Gaussian CDF, the former risk is higher
than the latter if
β0 v %
α + 2α ≤ Y + 2γ,
β0	β0
α - 2ɑ<γ — 2γ∙
(13)
(14)
Without loss of generality, we will prove these inequalities for β0 ≥ 0; an identical argument proves
it for β0 < 0 but with the '≤' and '〈’swapped.
18
Published as a conference paper at ICLR 2021
Suppose γ > α (the first condition). Then Equation 14 is immediate. Finally, for Equation 13,
observe that
Y + β ≥ α + β
2γ	2α
^⇒ Y —
>包 _ β0 _ (Y - α)βo
0 - 2α	2γ
2γα
y⇒ 2γα ≥ βo,
which is the second condition.
□
C.4 Simulations of Magnitude of Environmental Features
As discussed in Section 5, analytically quantifying the solution μ to the equation in Lemma C.1 is
difficult; instead, we present simulations to give a sense of how often these conditions would hold in
practice.
For each choice of environmental dimension d© we generated a “base” correlation b 〜 N(0,Ide)
as the mean of the prior over environmental means μe . Each of these μe was then drawn from
N(b, 4Ide)—thus, while they all came from the same prior, the noise in the draw of each μe was
significantly larger than the bias induced by the prior. We then solved for the precise value σeμ, with
the same variance σe2 for all environments, chosen as a hyperparameter. The shaded area represents a
95% confidence interval over 20 runs.
The dotted lines are √dC. If We imagine the invariant parameters are drawn from a standard Gaussian
prior, then this is precisely E[σ-1kμck2]. Thus, the point where σeμ crosses these dotted lines is
approximately how many environments would need to be observed before the non-invariant predictor
has higher risk than the optimal invariant predictor. We note that this value is quite large, on the order
of de - dc.
Figure C.2: Simulations to evaluate。©“ for varying ratios of d. When σ2 = 1 the value closely
dc	e
tracks dde - E, and the crossover point is approximately d© - σ2dc. These results imply the
conditions of Theorem 5.3 are very likely to hold in the high-dimensional setting.
D Theorem 6.1 and Discussion
D.1 Proof of Theorem 6.1
We again begin with helper lemmas.
19
Published as a conference paper at ICLR 2021
Our featurizer Φ is constructed to recover the environmental features only if they fall within a set
Bc . The following lemma shows that since only the environmental features contribute to the gradient
penalty, the penalty can be bounded as a function of the measure and geometry of that set. This is
used together with Lemmas F.3 and F.4 to bound the overall penalty of our constructed predictor.
Lemma D.1. Suppose we observe environments E = {e1, e2, . . .}. Given a set B ⊆ Rde, consider
the predictor defined by Equation 19. Then for any environment e, the penalty term of this predictor
in Equation 5 is bounded as
2
kVβRe(Φ,β)k2 ≤ P(Ze ∈Bc)E[∣Ze∣∣ Ze ∈ Bc].
2
Proof. We write out the precise form of the gradient for an environment e:
VeRe
(φ,β)= L×Ze
Pe(zc,Ze) [σ(βTΦ(f(zc, Ze))) - pe(y =1 | zc, Ze)]
Φ(f (Zc, Ze)) d(Zc, Ze).
Observe that since Zc ⊥⊥ Ze | y, the optimal invariant coefficients are unchanged, and therefore the
gradient in the invariant dimensions is 0. We can split the gradient in the environmental dimensions
into two integrals:
pe(Zc, Ze) σ(βcT Zc + β0) -pe(y
Zc×B
1 | Zc, Ze) [0] d(Zc, Ze)
/
Zc×Bc
+
pe(Zc, Ze) [σ(βTZc + βTERMZe + βo) 一 σ(βTZc + βeZe + /。)]院]d(Zc,Ze).
Since the features are 0 within B, the first term reduces to 0. For the second term, note that
∀ x,y ∈ R, ∣σ(x) 一 σ(y)∣ ≤ 1, and therefore
%Re
(Φ,β)l≤ /
Zc ×Bc
pe(Zc, Ze)[|Ze|] d(Zc, Ze).
We can marginalize out Zc, and noting that we want to bound the squared norm,
kvβRe(φ,β)k2 ≤ llʌ Pe(Ze)[|Ze|] dZe
2
2
P(Ze ∈ Bc)E[|Ze| | Ze ∈Bc]
2
2
□
This next lemma says that if the environmental mean of the test distribution is sufficiently separated
from each of the training means, with high probability a sample from this distribution will fall outside
ʌ
of Br, and therefore Φ , β will be equivalent to the ERM solution.
Lemma D.2. For a set of E environments E = {e1, e2, . . . , eE} and any > 1, construct Br
as in Equation 18 and define Φ using Br as in Equation 19. Suppose we now test on a new
environment with parameters (μE+ι,σE+J, and assume Equation 15 holds with parameter δ.
2
Define k 二 mine∈E 2e . Then with probability ≥ 1----------2=τ exp{-kδ2} over the draw of an
σE+1	kπδ
observation from this new environment, we have
Φ(x)=f-1(x)= Zc
Proof. By Equation 15 our new environmental mean is sufficiently far away from all the label-
conditional means of the training environments. In particular, for any environment e ∈ E and any
label y ∈ {±1}, the '2 distance from that mean to μE+ι is at least (√l + δ)σe√de.
Recall that Br is the union of balls ±Be, where Be is the ball of '2 radius ʌ/eofde centered at μe. For
each environment e, consider constructing the halfspace which is perpendicular to the line connecting
20
Published as a conference paper at ICLR 2021
μe and μE+ι and tangent to Be. This halfspace fully contains Be, and therefore the measure of Be is
upper bounded by that of the halfspace.
By rotational invariance of the Gaussian distribution, We can rotate this halfspace into one dimension
and the measure will not change. The center of the ball is (√e + δ)σe√de away from the mean μE+ι,
so accounting for its radius, the distance from the mean to the halfspace is δσe √de. The variance of
the rotated distribution one dimension is σE2 +1de, so the measure of this halfspace is upper bounded
by
ι-φ( δσe√de ] ≤φ(-√kδ)
∖∖∕σE+1 de )
≤ -7=- exp{-kδ2},
kπδ
using results from Kschischang (2017). There are 2E such balls comprising Br, which can be
combined via union bound.	口
With these two lemmas, we now state the full version of Theorem 6.1, with the main difference being
that it allows for any environmental variance.
Theorem D.3 (Non-linear case, full). Suppose we observe E environments E = {e1, e2, . . . , eE}.
Then, for any > 1, there exists a featurizer Φ which, combined with the ERM-optimal classifier
β=[βc,βe;ERM, β0]T, satisfies the following properties, where we define p,de := exp{-de min(( -
1), ( - 1)2)/8}:
1.	Define σ2mχ = maxe σ2. Then the regularization term of Φe, β is bounded as
E X ∣VβRe(Φe,β)k2 ∈O (PZde
E e∈E
edeσ41ax eχp{2eσ21aχ} + ∣∣μk2
ʌ
2.	Φ, β exactly matches the optimal invariant predictor on at least a 1 - p,de fraction of the
training set. On the remaining inputs, it matches the ERM-optimal solution.
Further, for any test distribution with environmental parameters (μE+ι, σE+ι), suppose the environ-
mental mean μE+ι is SUfficientlyfarfrOm the training means:
∀e ∈ E, min kμE+1 - y ∙ Me∣∣2 ≥ (√e + δ)σe ʌ/de
y∈{±1}
for some δ > 0. Define the constants:
(15)
σe2
k = min 2 e
e∈E σE+1
2E
q = G—C exp{-kδ }∙
kπδ
Then the following holds:
ʌ
3.	Φ , β is equivalent to the ERM-optimal predictor on at least a 1 - q fraction of the test
distribution.
4.	Under Assumption 1, suppose it holds that
μE+1 = ->： αeμe
e∈E
for some set of coefficients {αe}e∈E. Then for any c ∈ R, so long as
(16)
V kμek
e∈E αF
2. ≥ kμck2∕σ2 + 廊|/2 + cσERM
1-γ
(17)
ʌ
the 0-1 risk of Φ, β is lower bounded by F (2c) - q.
21
Published as a conference paper at ICLR 2021
Proof. Define r = ʌ/eɑldɪ and construct Br ⊂ Rde as
Br
UBr(μe)
e∈E
UBr(-μe)，
e∈E
(18)
∪
where Br (α) is the ball of '2-norm radius r centered at a. Further construct Φe using Br as follows:
Φ(x)
zc
0
zc
ze
, ze ∈ Br
and
, ze ∈ Brc ,
βc
βe
β0
(19)
ʌ
β
Without loss of generality, fix an environment e.
1. By Lemma D.1, the squared gradient norm is upper bounded by
2
kVβRe(Φe,β)k2 ≤ P(Ze ∈ Br)E[∣Ze∣ | Ze ∈ Br] ∙	(20)
2
Define Be := Br (μe), and observe that Br ⊆ Bc Since |ze| is non-negative,
P(Ze ∈ Br)E[∣Ze∣∣ Ze ∈ Br] ≤ P(Ze ∈ Br)E[∣Ze∣ | Ze ∈ Br]
(this inequality is element-wise). Plugging this into Equation 20 yields
2
∣∣VβRe(Φe,β)k2 ≤ P(Ze ∈ Br)E[∣Ze∣ | Ze ∈ Br]
2
2
= [P(Ze ∈ Ber)]2E[|Ze| | Ze ∈ Ber] .
2
Define p = P(Ze ∈ Brr) ≤ P(Ze ∈ Ber). By Lemma F.3,
p ≤ p,de = e-de min((-1),(-1)2)/8.
Combining Lemmas F.4 and F.5 gives
E[∣Ze∣ I Ze ∈ Br] 2 ≤ 2de [σ	S) 1 + 2∣∣μek2
2	F (-r/ d)
≤ deσe exp {2e(σ∣ - 1/2)} [eσ∣ + l] + 2|儿]|2.
Putting these two bounds together, we have
kvβRe(φe,β)k2 ∈ O (p2,de edeσ41ax exP{2eσmaχ} + k〃ek2 ),
and averaging this value across environments gives the result.
ʌ
2.	Φ , β is equal to the optimal invariant predictor on Br and the ERM solution on Brr . The
claim then follows from Lemma F.3.
3.	This follows directly from Lemma D.2.
4.	With Equation 16, we have that
βeERMμE+1 = -	αeβe*RMμe
e∈E
j kμ	k	kμek2
≤-2(I - Y) Tae7厂
e∈E	σe
≤ -2(1 - Y) kμrk2∕σ2 + 闭/2 + cσERM
1 - Y
=-(2|八||2/靖 + lβ0l + 2cσERM).
22
Published as a conference paper at ICLR 2021
where we have applied Assumption 1 in the first inequality and Equation 17 in the second.
Consider the full set of features Φ(x) = f-1 (x), and without loss of generality assume
y = 1. The label-conditional distribution of the resulting logit is
βTZC + βTERMze + Bθ 〜N (βTμc + βTERMμE+1 + Bθ, σERM) ∙
Therefore, the 0-1 risk is equal to the probability that this logit is negative. This is precisely
F -_βTμc + βTERMME+ι + β ! ≥ F ((2∣∣μc∣∣2∕σ2 + |/。| + 2cgerm) — 2∣∣μc∣∣2∕σ2 一 同|
σERM
σERM
=F 2 2cσERM A
σERM
= F (2c).
Observe that by the previous part, Φ 6= f-1 on at most a q fraction of observations, so
the risk of our predictor Φ, β can differ from that of f-1, β by at most q. Therefore our
predictor’s risk is lower bounded by F (2c) - q. In particular, choosing c = 1 recovers the
□
statement in the main body.
D.2 Discussion of Conditions and Assumption
To see just how often we can expect the conditions for Theorem D.3 to hold, we can do a rough
approximation based on the expectations of each of the terms. A reasonable prior for the environ-
mental means is a multivariate Gaussian N(m, Σ). We might expect them to be very concentrated
(with Tr(Σ) small), or perhaps to have a strong bias (with kmk22 Tr(Σ)). For simplicity we treat
the variances σc2 , σe2 as constants. Then the expected separation between any two means from this
distribution is
E[kμι — μ2k2] = Ex〜N(0,2∑)[kxk2] ≈ P2Tr(∑).
In high dimensions this value will tightly concentrate around the mean, which is in O(ʌ/dɪ) On the
other hand, even a slight deviation from this separation, to Ω(√de logE), means δ ∈ Ω(√logE),
which implies q ∈ O(1∕E); this is plenty small to ensure worse-than-random error on the test
distribution.
Now we turn our attention to the second condition (17). The expected squared norm of each mean is
de, and in high dimensions we expect them to be reasonably orthogonal (as a rough approximation;
this is technically not true with a non-centered Gaussian). Then so long as Pi αi ∈ Ω(1), the
left-hand side of Equation 17 is approximately de. On the other hand, treating Y as a constant,
the right-hand side is close to dc + √d + de ∈ O(d + √de). Thus, Equation 17 is quite likely
to hold for any mean μE+ι with the same scale as the training environments but with reversed
correlations—again, this is exactly the situation where IRM hopes to outperform ERM, and we have
shown that it does not.
We can also do a quick analysis of Assumption 1 under this prior: the ERM-optimal non-invariant
coefficient will be approximately 2m∕σ∣ with high probability, meaning f3τμ ≈ 2∣∣mk2∕σ2 for every
environment. Thus, this vector will be γ-close to optimal with γ ≈ 0 for every environment with
high probability.
E Extensions to Alternative Objectives
E.1 Extensions for the Linear Case
Observe that the constraint of Equation 4 is strictly stronger than that of Bellot & van der Schaar
(2020); when the former is satisfied, the penalty term of the latter is necessarily 0. It is thus trivial to
extend all results in the Section 5 to this objective. As another example, consider the risk-variance-
penalized objective of Krueger et al. (2020):
min 占 X Re&，β) + λVare∈E(Re&, β)) ,	(21)
φ,β |E| e⅛	`	)
23
Published as a conference paper at ICLR 2021
It is simple to extend Theorem 5.1 under an additional assumption:
Corollary E.1 (Extension to Theorem 5.1). Assume f is linear. Suppose we observe E ≤ de
environments with linearly independent means and identical variance σe2. Consider minimizing
ʌ
empirical risk subject to a penalty on the risk variance (21). Then there exists a Φ, β dependent on
the non-invariant features which achieves a lower objective value than the optimal invariant predictor
for any choice of regularization parameter λ ∈ [0, ∞].
Proof. Consider the featurizer Φ constructed in Lemma C.2. If the environmental variance is constant,
then the label-conditional distribution of the environmental features,
Ze | y -N(y ∙ μσ2,σe),
ʌ
is also invariant. This implies that the optimal β also has constant risk across the environments,
meaning the penalty term is 0, and as a result the objective does not depend on the choice of λ. As
in 5.1, invoking Lemma F.1 implies that the overall risk is lower than that of the optimal invariant
predictor.	口
As mentioned in Section 5, this additional requirement of constant variance is due to the assumptions
underlying the design of the objective—REx expects additional invariance of the second moment
Var(y | Φ(x)), in contrast with the strictly weaker invariance of E[y | Φ(x)] assumed by IRM. This
might seem to imply that REx is a more robust objective, but this does not convey the entire picture.
The conditions for the above corollary are just one possible failure case for REx; by extending
Theorem 5.3 to this objective, we see that REx is just as prone to bad solutions:
Corollary E.2 (Extension to Theorem 5.3). Suppose we observe E ≤ de environments, such
ʌ
that all environmental means are linearly independent. Then there exists a Φ, β which uses only
environmental features and, under any choice of λ ∈ [0, ∞], achieves a lower objective value than
the optimal invariant predictor under 0-1 loss on every environment e such that μ > σ-1 口小/以 +
lβo∣
2σ-1 ∣∣μck2 ,
Proof. We follow the proof of Theorem 5.3, except when solving for p as in Lemma C.1 we instead
find the unit-norm vector such that
pTμe = σeμ ∀e ∈ E.	(22)
Observe that by setting Φ(χ) = [pTZe] and β = [1], the 0-1 risk in a given environment is
nF(-μσe∕σe) + (1 - η)F(-μσe∕σe) = F(-μ),
which is independent of the environment. Further, by carrying through the same proof as in Theo-
rem 5.3, we get that this non-invariant predictor has lower 0-1 risk so long as
α +回
2α
≤ μ,
where α = σ-1kμc∣∣2
□
Though μ here is not exactly the same value because of the slightly different solution (22), it depends
upon the geometry of the training environments in the same way—it is the same as taking the square
root of each of the variances. We can therefore expect this condition to hold in approximately the
same situations, which we empirically verify by replicating Figure C.2 with the modified equation
below.
E.2 Extensions for the Non-Linear Case
The failure of these objectives in the non-linear regime is even more straightforward, as we can keep
unchanged the constructed predictor from Theorem 6.1. Observe that parts 2-4 of the theorem do not
involve the objective itself, and therefore do not require modification.
To see that part 1 still holds, note that since the constructed predictor matches the optimal invariant
predictor on 1 - p of the observations, its risk across environments can only vary on the remaining p
fraction: thus the centered 0-1 risk is bounded between 0 and p. It is immediate that the variance
of the environmental risks is upper bounded by p42 ∈ O(p2). Applying this argument to the other
objectives yields similar results.
24
Published as a conference paper at ICLR 2021
Figure E.1: Simulations to evaluate μ for varying ratios of de. When σ2 = 1 the value closely tracks
√de - E, and the crossover point is approximately de - σ2dc. Due to the similarity of Equation 22
to Equation 11, it makes sense that the results are very similar to those presented in Figure C.2.
F	Technical Lemmas
Lemma F.1. Consider solving the standard logistic regression problem
Z 〜p(z) ∈ Rk,
+1 w.p. σ(βT z),
y	-1 w.p. σ(-βT z).
Assume that none of the latent dimensions are degenerate—∀S ⊆ [k], P(βTZS = 0) > 0, and no
feature can be written as a linear combination of the other features. Then for any distribution p(z),
any classifier f(Z) = σ(βSTZS) that uses a strict subset of the features S ( [k] has strictly higher
risk with logistic loss than the Bayes classifier f * (Z) = σ(βTz). This additionally holdsfor 0-1 loss
if β-T S Z-S has greater magnitude and opposite sign of βST ZS with non-zero probability.
Proof. The Bayes classifier suffers the minimal expected loss for each observation z. Therefore,
another classifier has positive excess risk if and only if it disagrees with the Bayes classifier on a set
of non-zero measure. Consider the set of values Z-S such that β-T S Z-S 6= 0. Then on this set we
have
f* (βTZ) = σ(βSTZS +β-TSZ-S) 6= σ(βST ZS) = f(Z).
Since these values occur with positive probability, f has strictly higher logistic risk than f*. By the
same argument, there exists a set of positive measure under which
f* (βT Z) = sign(βST ZS + β-TSZ-S) 6= sign(βST ZS) = f(Z),
and so f also has strictly higher 0-1 risk.	□
Lemma F.2. For any feature vector which is a linear function of the invariant and environmental
features Z = AZc + BZe, any optimal corresponding Coefficientfor an environment e is oftheform
2(AAT σc2 + BBTσe2 )+ (Aμc + Bμe),
where G+ is a generalized inverse of G.
25
Published as a conference paper at ICLR 2021
Proof. We begin by evaluating a closed form for pe(y | Z). We have:
pe(y | Azc + Bze = Z)
_p(Azc + Bze = Z | y)p(y)
Pe(Azc + Bze = z)
=____________Pe (Azc + Bze = z | y)__________
Pe(Azc + Bze = z | y) + Pe(Azc + Bze = Z |-y)
_	1
1 _i_ Pe(Azc+ Bze = ZI - y)
十 pe(Azc+Bze=Z∖y)
Now We need a closed form expression for p(Azc + Bze = z | y). Noting that zc ⊥⊥ ze | y, this is a
convolution of the two independent Gaussian densities, which is the density of their sum. In other
words,
μ	∑
ζ----}^---{ z-------A-------{
Azc + Bze | y 〜N(y ∙ (Aμc + Bμe), AATσ7 + BBTσe)∙
Thus,
Pe(Azc + Bze	= Z | y)	= -_1 /2	exp I- 1(z	- y ∙ μ)T∑ +(z - y	∙ μ) J	.
(2π∣Σ |)k/2 I 2	J
Canceling common terms, we get
Pe (y = 1 1 Azc + Bze = z)= 1 , pe(A」Bze=R
+ Pe(Azc+Bze=2∖y)
_	1
1 + exp {-y ∙ 2ZtΣ+μ}
=σ (y ∙ 2ZtΣ+μ).
Therefore, given a feature vector z, the optimal coefficient vector is 2Σ+μ.	口
Lemma F.3. For any environment e with parameters μe, σ2 and any e > 1, define
B := B√σ2de(μe),
where Br (α) is the ball of '2 -norm radius r centered at a. Thenfor an observation drawn from Pe,
we have
P (ze ∈ Bc) ≤ exp ʃ-demin((e- 1)，(,- 1)2) 1 .
ze~pe	[	8	J
Proof. Without loss of generality, suppose y = 1. We have
P(ze ∈ B) ≥ P	(Ilze - μek2 ≤ 7*d
ze ~N (μe,σei) ∖	■
= P	(kzek2 ≤ √eσ2de^
ze~N(0,σ2I) '	)
= P	(kzek2 ≤ ede).
ze ~N(0,I)
Each term in the squared norm of ze is a random variable with distribution χ21, which means their
sum has mean de and is sub-exponential with parameters (2√de, 4). By standard sub-exponential
concentration bounds we have
P
ze~N(0,I)
(kzek2 ≥ede) ≤ exp 卜demin((e-81),(C- 1)2) }
which immediately implies the claim.
□
26
Published as a conference paper at ICLR 2021
Lemma F.4. Let Z 〜 N (μ, σ2Id) be a multivariate isotropic Gaussian in d dimensions, and for
some r > 0 define B as the ball of '2 radius r centered at μ. Then we have
2
E[|z| | z ∈ Bc]	≤ 2d
2
σ NEL
F (-r∕√d)
2
+ 2kμk2,
where φ, F are the standard Gaussian PDF and CDF.
Proof. Observe that
E	[∖z∖ ∖ z∈Bc]
Z 〜N (μ,σ2Id)
E
:~N (μ,σ2Id)
E
CN (0,σ2Id)
E
CN (0,σ2Id)
[|z||kz -μk2 > r]
[|z + μ∖ | kzk2 >r]
[|z| | kzk2 >r] + ∖μ∖.
z
z
≤
z
Now, consider the expectation for an individual dimension, and note that ∖z∕ > 力 ∀i =⇒ ∣∣zk2 >
r. So because the dimensions are independent, conditioning on this event can only increase the
expectation:
∖zi∖ ∖ ∖zi∖ >
zCN (E0,σ2Id)[∖zi∖ ∖ ∣z∣2 > r] ≤ ziCNE(0,σ2) ∖
E
ziCN (0,σ2 )
zi ∖ zi >
where the equality is because the distribution is symmetric about 0. This last term is known as the
conditional tail expectation of a Gaussian and is available in closed form:
E
ziCN (0,σ2 )
zi ∖ zi >
σΦ(F-1(α))
1-α
where α = F(r∕√d). Combining the above results, squaring with (a + b)2 ≤ 2(a2 + b2), and
summing over dimensions, we get
2
≤
2
E[∖z∖ ∖ z∈Bc]
d
2X E
i=1 ziCN (0,σ2 )
zi ∖ zi >
2
+ 2kμk2
2d
σ φ(r邛
F (-r∕√d)
2
+ 2kμk2,
as desired.
□
Lemma F.5. For σ, e > 0, define r = √σ. Then
2
-Φ(r)-
F (-r)_
≤ 2eχp {2e(σ2 - 1/2)} [∈σ2 + 1] ∙
Proof. We have
“√2∏exp{--2O
and
F(-r) ≥ _2exp{-2σ2}
一 √π(√2σ + √2σ2 + 2)
(see Kschischang (2017)). Dividing them gives
≤ ∖ ≤ √fe exp{2(σ2 - 1∕2)} h√2σ + p∕2σ2 + 2].
F (-r)	2 2
Squaring and using (a + b)2 ≤ 2(a2 + b2) yields the result.
□
27