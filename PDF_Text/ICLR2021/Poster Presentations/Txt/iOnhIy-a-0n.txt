Published as a conference paper at ICLR 2021
Accelerating Convergence of Replica Ex-
change Stochastic Gradient MCMC via Vari-
ance Reduction
Wei Deng *
Department of Mathematics
Purdue University
West Lafayette, IN, USA
weideng056@gmail.com
Qi Feng *
Department of Mathematics
University of Southern California
Los Angeles, CA, USA
qif@usc.edu
Georgios Karagiannis
Department of Mathematical Sciences
Durham University
Durham, UK
georgios.karagiannis@durham.ac.uk
Guang Lin
Departments of Mathematics &
School of Mechanical Engineering
Purdue University
West Lafayette, IN, USA
guanglin@purdue.edu
Faming Liang
Departments of Statistics
Purdue University
West Lafayette, IN, USA
fmliang@purdue.edu
Ab stract
Replica exchange stochastic gradient Langevin dynamics (reSGLD) has shown
promise in accelerating the convergence in non-convex learning; however, an ex-
cessively large correction for avoiding biases from noisy energy estimators has
limited the potential of the acceleration. To address this issue, we study the vari-
ance reduction for noisy energy estimators, which promotes much more effective
swaps. Theoretically, we provide a non-asymptotic analysis on the exponential
convergence for the underlying continuous-time Markov jump process; moreover,
we consider a generalized Girsanov theorem which includes the change of Poisson
measure to overcome the crude discretization based on the GronWall's inequality
and yields a much tighter error in the 2-Wasserstein (W2) distance. Numerically,
We conduct extensive experiments and obtain state-of-the-art results in optimiza-
tion and uncertainty estimates for synthetic experiments and image data.
1	Introduction
Stochastic gradient Monte Carlo methods (Welling & Teh, 2011; Chen et al., 2014; Li et al., 2016)
are the golden standard for Bayesian inference in deep learning due to their theoretical guarantees
in uncertainty quantification (Vollmer et al., 2016; Chen et al., 2015) and non-convex optimization
(Zhang et al., 2017). HoWever, despite their scalability With respect to the data size, their mixing
rates are often extremely sloW for complex deep neural netWorks With rugged energy landscapes (Li
et al., 2018). To speed up the convergence, several techniques have been proposed in the literature
in order to accelerate their exploration of multiple modes on the energy landscape, for example,
dynamic temperatures (Ye et al., 2017) and cyclic learning rates (Zhang et al., 2020), to name a
feW. HoWever, such strategies only explore contiguously a limited region around a feW informative
modes. Inspired by the successes of replica exchange, also knoWn as parallel tempering, in tradi-
tional Monte Carlo methods (SWendsen & Wang, 1986; Earl & Deem, 2005), reSGLD (Deng et al.,
* Equal contribution
1
Published as a conference paper at ICLR 2021
2020) uses multiple processes based on stochastic gradient Langevin dynamics (SGLD) where inter-
actions between different SGLD chains are conducted in a manner that encourages large jumps. In
addition to the ideal utilization of parallel computation, the resulting process is able to jump to more
informative modes for more robust uncertainty quantification. However, the noisy energy estimators
in mini-batch settings lead to a large bias in the naive swaps, and a large correction is required to
reduce the bias, which yields few effective swaps and insignificant accelerations. Therefore, how to
reduce the variance of noisy energy estimators becomes essential in speeding up the convergence.
A long standing technique for variance reduction is the control variates method. The key to reduc-
ing the variance is to properly design correlated control variates so as to counteract some noise.
Towards this direction, Dubey et al. (2016); Xu et al. (2018) proposed to update the control variate
periodically for the stochastic gradient estimators and Baker et al. (2019) studied the construction
of control variates using local modes. Despite the advantages in near-convex problems, a natural
discrepancy between theory (Chatterji et al., 2018; Xu et al., 2018; Zou et al., 2019b) and practice
(He et al., 2016; Devlin et al., 2019) is whether we should avoid the gradient noise in non-convex
problems. To fill in the gap, we only focus on the variance reduction of noisy energy estimators to
exploit the theoretical accelerations but no longer consider the variance reduction of the noisy gra-
dients so that the empirical experience from stochastic gradient descents with momentum (M-SGD)
can be naturally imported.
In this paper we propose the variance-reduced replica exchange stochastic gradient Langevin dynam-
ics (VR-reSGLD) algorithm to accelerate convergence by reducing the variance of the noisy energy
estimators. This algorithm not only shows the potential of exponential acceleration via much more
effective swaps in the non-asymptotic analysis but also demonstrates remarkable performance in
practical tasks where a limited time is required; while others (Xu et al., 2018; Zou et al., 2019a)
may only work well when the dynamics is sufficiently mixed and the discretization error becomes a
major component. Moreover, the existing discretization error of the Langevin-based Markov jump
processes (Chen et al., 2019; Deng et al., 2020; Futami et al., 2020) is exponentially dependent on
time due to the limitation of GrGnwaTs inequality. To avoid such a crude estimate, We consider
the generalized Girsanov theorem and a change of Poisson measure. As a result, we obtain a much
tighter discretization error only polynomially dependent on time. Empirically, we test the algorithm
through extensive experiments and achieve state-of-the-art performance in both optimization and
uncertainty estimates.
(a) Gibbs measures at
three temperatures τ .
(b) Sample trajectories on
a energy landscape.
(c) Faster exponential
convergence in W2
Figure 1: An illustration of replica exchange Monte Carlo algorithms for non-convex learning.
2 Preliminaries
A common problem, in Bayesian inference, is the simulation from a posterior P(β∣X) H
P(β) QN=i P(Xi∣β), where P(β) is a proper prior, QN=I P(xi∣β) is the likelihood function and
N is the number of data points. When N is large, the standard Langevin dynamics is too costly
in evaluating the gradients. To tackle this issue, stochastic gradient Langevin dynamics (SGLD)
(Welling & Teh, 2011) was proposed to make the algorithm scalable by approximating the gradient
through a mini-batch data B of size n such that
βk = βk-1 - ηk: X VL(XiIei) + p2ηkτξk，
i∈Bk
(1)
2
Published as a conference paper at ICLR 2021
where βk ∈ Rd , τ denotes the temperature, ηk is the learning rate at iteration k, ξk is a standard
Gaussian vector, and L(∙) := - logP(β∣X) is the energy function. SGLD is known to converge
weakly to a stationary GibbS measure ∏(β) 8 exp (-L(β)∕τ) as ηk decays to 0 (Teh et al., 2016).
The temperature τ is the key to accelerating the computations in multi-modal distributions. On the
one hand, a high temperature flattens the Gibbs distribution exp (-L(β)∕τ) (see the red curve in
Fig.1(a)) and accelerates mixing by facilitating exploration of the whole domain, but the resulting
distribution becomes much less concentrated around the global optima. On the other hand, a low
temperature exploits the local region rapidly; however, it may cause the particles to stick in a local
region for an exponentially long time, as shown in the blue curve in Fig.1(a,b). To bridge the gap
between global exploration and local exploitation, Deng et al. (2020) proposed the replica exchange
SGLD algorithm (reSGLD), which consists of a low-temperature SGLD to encourage exploitation
and a high-temperature SGLD to support exploration
βk1) = βk-ι - ηkNn X VL(Xilβk-ι) + P^ξk1)
i∈Bk
βk2) = βk-ι - ηkNn X VL(Xi∣βk-ι) + p2ηkτ(2)ξk2),
i∈Bk
where the invariant measure is known to be π(β⑴,β⑵)8 exp f-",U - L(β二)
τ (1)	τ (2)
as ηk → 0
and τ (1) < τ (2). Moreover, the two processes may swap the positions to allow tunneling between
different modes. To avoid inducing a large bias in mini-batch settings, a corrected swapping rate S
is developed such that
b=eχp n (τ1)-击)(N X L(χi∣βk1)) - Nn X L(χi∣βk2)) - ⅛-F≡2)},
i∈Bk	i∈Bk
where b2 is an estimator of the variance of Nn Pii∈Bk L(XiIekI)) 一 N Pi∈Bk L(xi∣βk2)) and F is
the correction factor to balance between acceleration and bias. In other words, the parameters switch
the positions from (βk(1), βk(2)) to (βk(2), βk(1)) with a probability r(1∧ Sb)ηk, where the constant r is
the swapping intensity and can set to ɪ for simplicity.
ηk
From a probabilistic point of view, reSGLD is a discretization scheme of replica exchange Langevin
diffusion (reLD) in mini-batch settings. Given a smooth test function f anda swapping-rate function
S, the infinitesimal generator LS associated with the continuous-time reLD follows
LS f(β ⑴,β ⑵)=-hVe(i)f(β? β ⑵),VL(β(1))i - hVe(2)f(β(1), β ⑵),VL(β(2))i
+ T⑴∆β(i) f (β⑴,β⑵)+ T⑵∆β(2) f (β⑴,β⑵)+ rS(β⑴,β(2)) ∙ (f (β⑵,β叭-f (β⑴,β⑵))，
where the last term arises from swaps and △,(.)is the the Laplace operator with respect to β(∙). Note
that the infinitesimal generator is closely related to Dirichlet forms in characterizing the evolution
of a stochastic process. By standard calculations in Markov semigroups (Chen et al., 2019), the
Dirichlet form ES associated with the infinitesimal generator LS follows
ES Cf)=J
I
(1)kVβ(1)f(β(1),β(2))k2+T (2)kVβ(2) f (β(1), β(2))k2)dπ(β(1), β(2))
-__-
*^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^~^~{^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^—
vanilla term E (f )
+r Z s(β(ι), β⑵)∙f(β ⑵,万⑴)—f(β∖ β ⑵))九∏(β⑴,β ⑵),
I	、z	J
(2)
^^^^^{^^^^^^≡
acceleration term
which leads to a strictly positive acceleration under mild conditions and is crucial for the expo-
nentially accelerated convergence in the W2 distance (see Fig.1(c)). However, the acceleration
depends on the swapping-rate function S and becomes much smaller given a noisy estimate of
Nn Pi∈B L(xi∣β) due to the demand of large corrections to reduce the bias.
3
Published as a conference paper at ICLR 2021
3 Variance Reduction in Replica Exchange Stochastic Gradient
Langevin Dynamics
The desire to obtain more effective swaps and larger accelerations drives us to design more efficient
energy estimators. A naive idea would be to apply a large batch size n, which reduces the variance
of the noisy energy estimator proportionally. However, this comes with a significantly increased
memory overhead and computations and therefore is inappropriate for big data problems.
A natural idea to propose more effective swaps is to reduce the variance of the noisy energy estimator
L(B∣β(h)) = Nn Pi∈B L(xi∣β(h)) for h ∈ {1,2}. Considering an unbiased estimator L(B∣∕b(h))
for PN=I L(xi∣β(h)) and a constant c, We see that a new estimator L(B∣β(h)), which follows
L(BIeS)) = L(B∣β㈤)+ C 卜(B®h)) - XXL(xi∣β(h))) ,	(3)
is still the unbiased estimator for PN=I L(xi∣β(h)). By decomposing the variance, we have
Var(e(B∣β(h))) = Var (L(B∣β(h))) + c2Var(L(B|/b(h))) + 2cCov(L(B|e(h)),L(B|/b(h))).
In such a case, Var(L(B∣β(h))) achieves the minimum variance (1 - ρ2)Var(L(B∣β(h))) given
COV(L(BIes) ),L(B∣3⑸))
Var(L(B|3Ih)))
c? :
,where Cov(∙, ∙) denotes the covariance and P is the correlation
coefficient of L(B∣β(h)) and L(B∣∕b(h)). To propose a correlated control variate, we follow Johnson
& Zhang (2013) and update β(h) = Mb互C every m iterations. Moreover, the optimal c? is often
unknown in practice. To handle this issuem, a well-known solution (Johnson & Zhang, 2013) is to
fix c = -1 given a high correlation ∣ρ∣ of the estimators and then we can present the VR-reSGLD
algorithm in Algorithm 1. Since the exact variance for correcting the stochastic swapping rate
is unknown and even time-varying, we follow Deng et al. (2020) and propose to use stochastic
approximation (Robbins & Monro, 1951) to adaptively update the unknown variance.
Variants of VR-reSGLD The number of iterations m to update the control variate βb(h) gives
rise to a trade-off in computations and variance reduction. A small m introduces a highly correlated
control variate at the cost of expensive computations; a large m, however, may yield a less correlated
control variate and setting c = -1 fails to reduce the variance. In spirit of the adaptive variance in
Deng et al. (2020) to estimate the unknown variance, we explore the idea of the adaptive coefficient
cek = (1 - γk)cek-m + γkck such that the unknown optimal c? is well approximated. We present the
adaptive VR-reSGLD in Algorithm 2 in Appendix E.2 and show empirically later that the adaptive
VR-reSGLD leads to a significant improvement over VR-reSGLD for the less correlated estimators.
A parallel line of research is to exploit the SAGA algorithm (Defazio et al., 2014) in the study of
variance reduction. Despite the most effective performance in variance reduction (Chatterji et al.,
2018), the SAGA type of sampling algorithms require an excessively memory storage of O(N d),
which is too costly for big data problems. Therefore, we leave the study of the lightweight SAGA
algorithm inspired by Harikandeh et al. (2015); Zhou et al. (2019) for future works.
Related work Although our VR-reSGLD is, in spirit, similar to VR-SGLD (Dubey et al., 2016;
Xu et al., 2018), it differs from VR-SGLD in two aspects: First, VR-SGLD conducts variance re-
duction on the gradient and only shows promises in the nearly log-concave distributions or when the
Markov process is sufficiently converged; however, our VR-reSGLD solely focuses on the variance
reduction of the energy estimator to propose more effective swaps, and therefore we can import the
empirical experience in hyper-parameter tuning from M-SGD to our proposed algorithm. Second,
VR-SGLD doesn’t accelerate the continuous-time Markov process but only focuses on reducing the
discretization error; VR-reSGLD possesses a larger acceleration term in the Dirichlet form (2) and
shows a potential in exponentially speeding up the convergence of the continuous-time process in
the early stage, in addition to the improvement on the discretization error. In other words, our al-
gorithm is not only theoretically sound but also more empirically appealing for a wide variety of
problems in non-convex learning.
4
Published as a conference paper at ICLR 2021
Algorithm 1 Variance-reduced replica exchange stochastic gradient Langevin dynamics (VR-
reSGLD). The learning rate and temperature can be set to dynamic to speed up the computations. A
larger smoothing factor γ captures the trend better but becomes less robust. T is the thinning factor
to avoid a cumbersome system.
Input The initial parameters β0(1) andβ0(2), learning rate η, temperatures τ(1) and τ(2), correction
factor F and smoothing factor γ.
repeat
Parallel sampling Randomly pick a mini-batch set Bk of size n.
βkh) = βkh)ι - ηNn X ^L(xi∣β(h)ι) + p2ητ㈤ξkh), for h ∈ {1, 2}.	(4)
n i∈Bk
Variance-reduced energy estimators Update L(h) = PN=ι L (χi∣β)) k J) every m iterations.
L(Bk W)) = N X [L(Xi∣βkh))- L(XiIembk」)i +Lb(h), forh ∈ {1, 2}.	(5)
i∈Bk	m
if k mod m = 0 then
Update e2 = (1 — γ)e2-m + γσ2, where σk is an estimate for Var (L(Bk ∣βk1)) — L(Bk∣βk2)))∙
end if
Bias-reduced swaps SWaP βk+ι and βkh if u < Seη,m,n, where U 〜Unif [0,1], and Seη,m,n follows
Sη,m,n = eχp {(τ(i) - τ12) ) (L(Bk+ι∣βk+1) - L(Bk+ι∣βk+1) - F (7⅛) - τ⅛)) embkc)}.
m (6)
until k = kmax .
Output: The low-temperature process {βi(T1)}ib=km1ax /Tc , where T is the thinning factor.
4 Theoretical properties
The large variance of noisy energy estimators directly limits the potential of the acceleration and
significantly slows down the convergence compared to the replica exchange Langevin dynamics. As
a result, VR-reSGLD may lead to a more efficient energy estimator with a much smaller variance.
Lemma 1 (Variance-reduced energy estimator) Under the smoothness and dissipativity assump-
tions 1 and 2 in Appendix A, the variance of the variance-reduced energy estimator e(B∣β(h)),
where h ∈ {1, 2}, is upper bounded by
Var 伍(BIeS))) ≤ min {θ (m2η) , Var(N X L(XiIeS))) +Var(N X L(x∕β■㈤))},
n	n i∈B	n i∈B
where the detailed O(∙) constants is Shown in Lemma B1 in the appendix.
The analysis shows the variance-reduced estimator Le(BIe(h)) yields a much-reduced variance given
a smaller learning rate η and a smaller m for updating control variates based on the batch size
n. Although the truncated swapping rate Sη,m,n = min{1, Sη,m,n} still satisfies the “stochastic”
detailed balance given an unbiased swapping-rate estimator Snmn (Deng et al., 2020) *, it doesn't
mean the efficiency of the swaps is not affected. By contrast, we can show that the number of swaps
may become exponentially smaller on average.
Lemma 2 (Variance reduction for larger swapping rates) Given a large enough batch size n, the
variance-reduced energy estimator Le(Bk Iek(h)) yields a truncated swapping rate that satisfies
E[S%m,n] ≈ min {1,S(β⑴,β(2))(θ G) + e-O(吟+击))},	⑺
^ Andrieu & Roberts (2009); Quiroz et al. (2019) achieve a similar result based on the unbiased likelihood
estimator for the Metropolis-hasting algorithm. See section 3.1 (Quiroz et al., 2019) for details.
5
Published as a conference paper at ICLR 2021
where S(β(1), β(2)) is the deterministic swapping rate defined in Appendix B. The proof is shown
in Lemma.B2 in Appendix B. Note that the above lemma doesn’t require the normality assump-
tion. As n goes to infinity, where the asymptotic normality holds, the RHS of (7) changes to
min n1,S(β⑴,β⑵)e-O(畸)}
which becomes exponentially larger as we use a smaller up-
date frequency m and learning rate η. Since the continuous-time reLD induces a jump operator
in the infinitesimal generator, the resulting Dirichlet form potentially leads to a much larger accel-
eration term which linearly depends on the swapping rate Sη,m,n and yields a faster exponential
convergence. Now we are ready to present the first main result.
Theorem 1	(Exponential convergence) Under the smoothness and dissipativity assumptions 1 and
2, the probability measure associated with reLD at time t, denoted as νt, converges exponentially
fast to the invariant measure π :
W2(νt,π) ≤ D0 exp -t 1 + δSη,m,n /cLS ,	(8)
where D0 is a constant depending on the initialization, δSη,m,n
inft>0
ESη,m,n (qddΠ~ )
-1
depends on Sη,m,n, ESη,m,n and E are the Dirichlet forms based on the swapping rate Sη,m,n
are defined in (2), cLS is the constant of the log-Sobolev inequality for reLD without swaps.
≥0
and
We detail the proof in Theorem.1 in Appendix B. Note that Sη,m,n = 0 leads to the same perfor-
mance as the standard Langevin diffusion and δsη,m,n is strictly positive when 普 is asymmetric
(Chen et al., 2019); given a smaller η and m or a large n, the variance becomes much reduced
according to Lemma 1, yielding a much larger truncated swapping rate by Lemma 2 and a faster
exponential convergence to the invariant measure π compared to reSGLD.
Next, We estimate the upper bound of the 2-Wasserstein distance W(μk,Vk”), where μk denotes
the probability measure associated with VR-reSGLD at iteration k. We first bypass the Gronwall
inequality and conduct the change of measure to upper bound the relative entropy DκL(μk∣νkη)
following (Raginsky et al., 2017). In addition to the approximation in the standard Langevin diffu-
sion Raginsky et al. (2017), we also consider the change of Poisson measure following Yin & Zhu
(2010); Gikhman & Skorokhod (1980) to handle the error from the stochastic swapping rate. We
then extend the distance of relative entropy DκL(μk ∣νkη) to the Wasserstein distance W2(μk, Vkn)
via a weighted transportation-cost inequality of Bolley & Villani (2005).
Theorem 2	(Diffusion approximation) Assume the smoothness, the dissipativity and the gradient
assumptions 1, 2 and 3 hold. Given a large enough batch size n, a small enough m and η, we have
W2(μk,Vkn) ≤θ(dk3/2η(η"4 + δ1/4 + (*η) / )),	(9)
where δ is a constant that characterizes the scale of noise caused in mini-batch settings and the
detail is given in Theorem 2 in Appendix C . Here the last term O((咚η)"8) comes from the
error induced by the stochastic swapping rate, which disappears given a large enough batch size n
or a small enough update frequency m and learning rate η. Note that our upper bound is linearly
dependent on time approximately, which is much tighter than the exponential dependence using
the Gronwall inequality. Admittedly, the result without swaps is slightly weaker than the diffusion
approximation (3.1) in Raginsky et al. (2017) and we refer readers to Remark 3 in Appendix C.
Applying the triangle inequality for W2(μk, Vkη) and W2(νkn, ∏) leads to the final result
Theorem 3	Assume the smoothness, the dissipativity and the gradient assumptions 1, 2 and 3 hold.
Given a small enough learning rate η, update frequency m anda large enough batch size n, we have
W2(μk,∏) ≤ o(dk3∕2η(η1∕4 + δ1∕4 +
This theorem implies that increasing the batch size nor decreasing the update frequency m not
only reduces the numerical error but also potentially leads to a faster exponential convergence of the
continuous-time dynamics via a much larger swapping rate Sn,m,n.
6
Published as a conference paper at ICLR 2021
(a) Trace plot for β(1)
(b) Trace plot for β(1)
(c) Paths of log10 σe2
(d) Contour of log10 σe2
Figure 2: Trace plots, KDEs of β(1), and sensitivity study of σe2 with respect to m, η and n.
5	Experiments
5.1	Simulations of Gaussian Mixture Distributions
We first study the proposed variance-reduced replica exchange stochastic gradient Langevin dynam-
ics algorithm (VR-reSGLD) on a Gaussian mixture distribution (Dubey et al., 2016). The distribu-
tion follows from x∕β 〜0.5N(β, σ2) + 0.5N(φ 一 β, σ2), where φ = 20, σ = 5 and β = —5. We
use a training dataset of size N = 105 and propose to estimate the posterior distribution over β. We
compare the performance of VR-reSGLD against that of the standard stochastic gradient Langevin
dynamics (SGLD), and replica exchange SGLD (reSGLD).
In Figs 2(a) and 2(b), we present trace plots and kernel density estimates (KDE) of samples generated
from VR-reSGLD with m = 40, τ⑴=10 t, τ⑵=1000, η =1e — 7, and F = 1; reSGLD adopt
the same hyper-parameters except for F = 100 because a smaller F may fail to propose any swaps;
SGLD uses η = 1e — 7 and τ = 10. As the posterior density is intractable, we consider a ground
truth by running replica exchange Langevin dynamics with long enough iterations. We observe that
VR-reSGLD is able to fully recover the posterior density, and successfully jump between the two
modes passing the energy barrier frequently enough. By contrast, SGLD, initialized at β0 = 30,
is attracted to the nearest mode and fails to escape throughout the run; reSGLD manages to jump
between the two modes, however, F is chosen as large as 100, which induces a large bias and
only yields three to five swaps and exhibits the metastability issue. In Figure 2(c), we present the
evolution of the variance for VR-reSGLD over a range of different m and compare it with reSGLD.
We see that the variance reduction mechanism has successfully reduced the variance by hundreds
of times. In Fig 2(d), We present the sensitivity study of σ2 as a function of the ratio n/N and the
learning rate η; for this estimate we average out 10 realizations of VR-reSGLD, and our results agree
with the theoretical analysis in Lemma 1.
5.2	Non-convex optimization for image data
We further test the proposed algorithm on CIFAR10 and CIFAR100. We choose the 20, 32, 56-layer
residual networks as the training models and denote them by ResNet-20, ResNet-32, and ResNet-
56, respectively. Considering the wide adoption of M-SGD, stochastic gradient Hamiltonian Monte
Carlo (SGHMC) is selected as the baseline. We refer to the standard replica exchange SGHMC
algorithm as reSGHMC and the variance-reduced reSGHMC algorithm as VR-reSGHMC. We also
include another baseline called cyclical stochastic gradient MCMC (cycSGHMC), which proposes
a cyclical learning rate schedule. To make a fair comparison, we test the variance-reduced replica
exchange SGHMC algorithm with cyclic learning rates and refer to it as cVR-reSGHMC.
We run M-SGD, SGHMC and (VR-)reSGHMC for 500 epochs. For these algorithms, we follow
a setup from Deng et al. (2020). We fix the learning rate ηk(1) = 2e-6 in the first 200 epochs and
decay it by 0.984 afterwards. For SGHMC and the low-temperature processes of (VR-)reSGHMC,
we anneal the temperature following τk(1) = 0.01/1.02k in the beginning and keep it fixed after the
burn-in steps; regarding the high-temperature process, we set ηk(2) = 1.5ηk(1) and τk(2) = 5τk(1). The
initial correction factor F0 is fixed at 1.5e5. The thinning factor T is set to 256. In particular for
tWe choose T(1) = 10 instead of 1 to avoid peaky modes for ease of illustration.
7
Published as a conference paper at ICLR 2021
(a) CIFAR10: Original
v.s. proposed (m=50)
40
= m=50 & n=256
m=inf & n=256
200 300 400 500
Epochs
(b) CIFAR100: Original
v.s. proposed (m=50)
Variance reduction
(c)
setups on CIFAR10
(d) Variance reduction
setups on CIFAR100
Figure 3: Variance reduction on the noisy energy estimators on CIFAR10 & CIFAR100 datasets.
cycSGHMC, we run the algorithm for 1000 epochs and choose the cosine learning rate schedule
with 5 cycles; ηo is set to 1e-5; We fix the temperature 0.001 and the threshold 0.7 for collecting the
samples. Similarly, we propose the cosine learning rate for cVR-reSGHMC with 2 cycles and run
it for 500 epochs using the same temperature 0.001. We only study the low-temperature process for
the replica exchange algorithms. Each experiment is repeated five times to obtain the mean and 2
standard deviations.
We evaluate the performance of variance reduction using VR-reSGHMC and compare it with reS-
GHMC. We first increase the batch size n from 256 to 512 for reSGHMC and notice that the re-
duction of variance is around 2 times (see the red curves in Fig.3(c,d)). Next, we try m = 50 and
n = 256 for the VR-reSGHMC algorithm, which updates the control variates every 50 iterations.
As shown in Fig.3(a,b), during the first 200 epochs, where the largest learning rate is used, the vari-
ance of VR-reSGHMC is slightly reduced by 37% on CIFAR100 and doesn,t make a difference on
CIFAR10. However, as the learning rate and the temperature decrease, the reduction of the variance
gets more significant. We see from Fig.3(c,d) that the reduction of variance can be up to 10 times on
CIFAR10 and 20 times on CIFAR100. This is consistent with our theory proposed in Lemma 1. The
reduction of variance based on VR-reSGHMC starts to outperform the baseline with n = 512 when
the epoch is higher than 370 on CIFAR10 and 250 on CIFAR100. We also try m = 392, which
updates the control variates every 2 epochs, and find a similar pattern.
For computational reasons, we choose m = 392 and n = 256 for (c)VR-reSGHMC and compare
them with the baseline algorithms. With the help of swaps between two SGHMC chains, reSGHMC
already obtains remarkable performance (Deng et al., 2020) and five swaps often lead to an optimal
performance. However, VR-reSGHMC still outperforms reSGHMC by around 0.2% on CIFAR10
and 1% improvement on CIFAR100 (Table.1) and the number OfSWaPS is increased to around a
hundred under the same setting. We also try cyclic learning rates and compare cVR-reSGHMC with
cycSGHMC, we see cVR-reSGHMC outperforms cycSGHMC significantly even if cycSGHMC is
running 1000 epochs, which may be more costly than cVR-reSGHMC due to the lack of mechanism
in parallelism. Note that cVR-reSGHMC keeps the temperature the same instead of annealing it as
in VR-reSGHMC, which is more suitable for uncertainty quantification.
Table 1: Prediction accuracies (%) based on Bayesian model averaging. In par-
ticular, M-SGD AND SGHMC RUN 500 EPOCHS USING A SINGLE CHAIN； CYCSGHMC RUN
1000 EPOCHS USING A SINGLE CHAIN； REPLICA EXCHANGE ALGORITHMS RUN 500 EPOCHS
USING TWO CHAINS WITH DIFFERENT TEMPERATURES.
Method	CIFAR10			CIFAR100		
	ResNet20	ResNet32	ResNet56	ResNet20	ResNet32	ResNet56
M-SGD	94.07±0.11	95.11±0.07	96.05±0.21	71.93±0.13	74.65±0.20	78.76±0.24
SGHMC	94.16±0.13	95.17±0.08	96.04±0.18	72.09±0.14	74.80±0.19	78.95±0.22
-reSGHMC	94.56±0.23	95.44±0.16	96.15±0.17	73.94±0.34	76.38±0.23	79.86±0.26
VR-reSGHMC	94.84±0.11	95.62±0.09	96.32±0.15	74.83±0.18	77.40±0.27	80.62±0.22
cycSGHMC	94.61±0.15	95.56±0.12	96.19±0.17	74.21±0.22	76.60±0.25	80.39±0.21
cVR-reSGHMC	94.91±0.10	95.64±0.13	96.36±0.16	75.02±0.19	77.58±0.21	80.50±0.25
8
Published as a conference paper at ICLR 2021
Regarding the training cost and the treatment for improving the performance of variance reduction
using adaptive coefficients in the early period, we refer interested readers to Appendix E.
For the detailed implementations, we release the code at https://github.com/WayneDW/
Variance_Reduced_Replica_Exchange_Stochastic_Gradient_MCMC.
5.3	Uncertainty Quantification for unknown samples
A reliable model not only makes the right decision among potential candidates but also casts doubts
on irrelevant choices. For the latter, we follow Lakshminarayanan et al. (2017) and evaluate the
uncertainty on out-of-distribution samples from unseen classes. To avoid over-confident predictions
on unknown classes, the ideal predictions should yield a higher uncertainty on the out-of-distribution
samples, while maintaining the accurate uncertainty for the in-distribution samples.
Continuing the setup in Sec.5.2, we collect the ResNet20 models trained on CIFAR10 and quantify
the entropy on the Street View
House Numbers (SVHN) dataset,
which contains 26,032 RGB test-
ing images of digits instead of ob-
jects. We compare cVR-reSGHMC
with M-SGD, SGHMC, reSGHMC,
and cSGHMC. Ideally, the predic-
tive distribution should be the uni-
form distribution and leads to the
highest entropy. We present the em-
pirical cumulative distribution func-
tion (CDF) of the entropy of the pre-
dictions on SVHN and report it in
Fig.4. As shown in the left figure,
Figure 4: CDF of entropy for predictions on SVHN via CI-
FAR10 models. A temperature scaling is used in calibrations.
M-SGD shows the smallest probability for high-entropy predictions, implying the weakness of
stochastic optimization methods in uncertainty estimates. By contrast, the proposed cVR-reSGHMC
yields the highest probability for predictions of high entropy. Admittedly, the standard ResNet mod-
els are poorly calibrated in the predictive probabilities and lead to inaccurate confidence. To alleviate
this issue, we adopt the temperature-scaling method with a scale of 2 to calibrate the predictive dis-
tribution (Guo et al., 2017) and present the entropy in Fig.4 (right). In particular, we see that 77%
of the predictions from cVR-reSGHMC yields the entropy higher than 1.5, which is 7% higher than
reSGHMC and 10% higher than cSGHMC and much better than the others.
For more discussions of uncertainty estimates on both datasets, we leave the results in Appendix F.
6	Conclusion
We propose the variance-reduced replica exchange stochastic gradient Langevin dynamics algorithm
to accelerate the convergence by reducing the variance of the noisy energy estimators. Theoretically,
this is the first variance reduction method that yields the potential of exponential accelerations
instead of solely reducing the discretization error. In addition, We bypass the GronWall inequality
to avoid the crude numerical error and consider a change of Poisson measure in the generalized
Girsanov theorem to obtain a much tighter upper bound. Since our variance reduction only conducts
on the noisy energy estimators and is not applied to the noisy gradients, the standard hyper-parameter
setting can be also naturally imported, Which greatly facilitates the training of deep neural Works.
Acknowledgment
We Would like to thank Maxim Raginsky and the anonymous revieWers for their insightful sugges-
tions. Liang’s research Was supported in part by the grants DMS-2015498, R01-GM117597 and
R01-GM126089. Lin acknoWledges the support from NSF (DMS-1555072, DMS-1736364), BNL
Subcontract 382247, W911NF-15-1-0562, and DE-SC0021142.
9
Published as a conference paper at ICLR 2021
References
Christophe Andrieu and Gareth O. Roberts. The Pseudo-Marginal Approach for Efficient Monte
Carlo Computations. Annals of Statistics, 37:697-725, 2009.
Jack Baker, Paul Fearnhead, Emily B. Fox, and Christopher Nemeth. Control Variates for Stochastic
Gradient MCMC. Statistics and Computing, 29:599-615, 2019.
Dominique Bakry, Ivan Gentil, and Michel Ledoux. Analysis and Geometry of Markov Diffusion
Operators. Springer, 2014.
Amel Bentata and Rama Cont. Mimicking the Marginal Distributions of a Semimartingale. arXiv
preprint arXiv:0910.3992, 2009.
Francois Bolley and Cedric Villani. Weighted Csiszar-KUllback-Pinsker Inequalities and Ap-
plications to Transportation Inequalities. Annales de la Faculte des sciences de Toulouse :
Mathematiques, Serie. 6, 14(3):331-352, 2005.
Niladri Chatterji, Nicolas Flammarion, Yi-An Ma, Peter Bartlett, and Michael Jordan. On the The-
ory of Variance Reduction for Stochastic Gradient Monte Carlo. In Proc. of the International
Conference on Machine Learning (ICML), 2018.
Changyou Chen, Nan Ding, and Lawrence Carin. On the Convergence of Stochastic Gradient
MCMC Algorithms with High-order Integrators. In Advances in Neural Information Process-
ing Systems (NeurIPS), pp. 2278-2286, 2015.
Tianqi Chen, Emily B. Fox, and Carlos Guestrin. Stochastic Gradient Hamiltonian Monte Carlo. In
Proc. of the International Conference on Machine Learning (ICML), 2014.
Yi Chen, Jinglin Chen, Jing Dong, Jian Peng, and Zhaoran Wang. Accelerating Nonconvex Learning
via Replica Exchange Langevin Diffusion. In Proc. of the International Conference on Learning
Representation (ICLR), 2019.
Aaron Defazio, Francis Bach, and Simon Lacoste-Julien. SAGA: A Fast Incremental Gradient
Method with Support for Non-Strongly Convex Composite Objectives. In Advances in Neural
Information Processing Systems (NeurIPS). 2014.
Wei Deng, Qi Feng, Liyao Gao, Faming Liang, and Guang Lin. Non-Convex Learning via Replica
Exchange Stochastic Gradient MCMC. In Proc. of the International Conference on Machine
Learning (ICML), 2020.
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. BERT: Pre-training of Deep
Bidirectional Transformers for Language Understanding. In Proc. of the Annual Meeting of the
Association Computational Linguistics (ACL), 2019.
Jing Dong and Xin T. Tong. Spectral Gap of Replica Exchange Langevin Diffusion on Mixture
Distributions. ArXiv 2006.16193v2, July 2020.
Avinava Dubey, Sashank J. Reddi, BarnabaS Poczos, Alexander J. Smola, Eric P. Xing, and
Sinead A. Williamson. Variance Reduction in Stochastic Gradient Langevin Dynamics. In Ad-
vances in Neural Information Processing Systems (NeurIPS), 2016.
David J. Earl and Michael W. Deem. Parallel Tempering: Theory, Applications, and New Perspec-
tives. Phys. Chem. Chem. Phys., 7:3910-3916, 2005.
A.	Eizenberg and M. Freidlin. On the Dirichlet Problem for a Class of Second Order PDE Systems
with Small Parameter. Stochastics and Stochastic Reports, 33:111-148, 1990.
Futoshi Futami, Issei Sato, and Masashi Sugiyama. Accelerating the Diffusion-based Ensemble
Sampling by Non-reversible Dynamics. In Proc. of the International Conference on Machine
Learning (ICML), 2020.
Iosif I. Gikhman and Anatoli V. Skorokhod. The Theory of Stochastic Processes I. Springer, 1980.
10
Published as a conference paper at ICLR 2021
Chuan Guo, Geoff Pleiss, Yu Sun, and Kilian Q. Weinberger. On Calibration of Modern Neural
Networks. In Proc. of the International Conference on Machine Learning (ICML), 2017.
Istvan Gyongy. Mimicking the One-dimensional Marginal Distributions of Processes Having an Ito
differential. Probability theory and related fields ,71(4):501-516,1986.
Reza Harikandeh, Mohamed Osama Ahmed, Alim Virani, Mark Schmidt, Jakub Konecny, and Scott
Sallinen. Stop Wasting My Gradients: Practical SVRG. In Advances in Neural Information
Processing Systems (NeurIPS), 2015.
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep Residual Learning for Image
Recognition. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR),
2016.
Rie Johnson and Tong Zhang. Accelerating Stochastic Gradient Descent using Predictive Variance
Reduction. In Advances in Neural Information Processing Systems (NeurIPS). 2013.
Balaji Lakshminarayanan, Alexander Pritzel, and Charles Blundell. Simple and Scalable Predictive
Uncertainty Estimation using Deep Ensemble. In Advances in Neural Information Processing
Systems (NeurIPS), 2017.
Holden Lee, Andrej Risteski, and Rong Ge. Beyond Log-concavity: Provable Guarantees for Sam-
pling Multi-modal Distributions using Simulated Tempering Langevin Monte Carlo. In Advances
in Neural Information Processing Systems (NeurIPS), 2018.
Chunyuan Li, Changyou Chen, David Carlson, and Lawrence Carin. Preconditioned Stochastic
Gradient Langevin Dynamics for Deep Neural Networks. In Proc. of the National Conference on
Artificial Intelligence (AAAI), pp. 1788-1794, 2016.
Hao Li, Zheng Xu, Gavin Taylor, Christoph Studer, and Tom Goldstein. Visualizing the Loss Land-
scape of Neural Nets. In Advances in Neural Information Processing Systems (NeurIPS), 2018.
J.C. Mattingly, A.M. Stuartb, and D.J. Highamc. Ergodicity for SDEs and Approximations: Locally
Lipschitz Vector Fields and Degenerate Noise. Stochastic Processes and their Applications, 101:
185-232, 2002.
B.	0ksendal. Stochastic Differential Equations: An Introduction with Applications. Springer, 2003.
Matias Quiroz, Robert Kohn, Mattias Villani, and Minh-Ngoc Tran. Speeding Up MCMC by Effi-
cient Data Subsampling. Journal of the American Statistical Association, 114:831-843, 2019.
Maxim Raginsky, Alexander Rakhlin, and Matus Telgarsky. Non-convex Learning via Stochastic
Gradient Langevin Dynamics: a Nonasymptotic Analysis. In Proc. of Conference on Learning
Theory (COLT), June 2017.
Herbert Robbins and Sutton Monro. A Stochastic Approximation Method. The Annals of Mathe-
matical Statistics, 22(3):400-407, 1951.
Robert H. Swendsen and Jian-Sheng Wang. Replica Monte Carlo Simulation of Spin-Glasses. Phys-
ical Review Letters, 57:2607-2609, 1986.
Yee Whye Teh, Alexandre Thiery, and Sebastian Vollmer. Consistency and Fluctuations for Stochas-
tic Gradient Langevin Dynamics. Journal of Machine Learning Research, 17:1-33, 2016.
Sebastian J. Vollmer, Konstantinos C. Zygalakis, and Yee Whye Teh. Exploration of the (Non-)
Asymptotic Bias and Variance of Stochastic Gradient Langevin Dynamics. Journal of Machine
Learning Research, 17(159):1-48, 2016.
Max Welling and Yee Whye Teh. Bayesian Learning via Stochastic Gradient Langevin Dynamics.
In Proc. of the International Conference on Machine Learning (ICML), pp. 681-688, 2011.
Pan Xu, Jinghui Chen, Difan Zou, and Quanquan Gu. Global Convergence of Langevin Dynamics
Based Algorithms for Nonconvex Optimization. In Advances in Neural Information Processing
Systems (NeurIPS), 2018.
11
Published as a conference paper at ICLR 2021
Nanyang Ye, Zhanxing Zhu, and Rafal K.Mantiuk. Langevin Dynamics with Continuous Tempering
for Training Deep Neural Networks. In Advances in Neural Information Processing Systems
(NeurIPS), 2017.
George Yin and Chao Zhu. Hybrid Switching Diffusions: Properties and Applications. Springer,
2010.
Ruqi Zhang, Chunyuan Li, Jianyi Zhang, Changyou Chen, and Andrew Gordon Wilson. Cyclical
Stochastic Gradient MCMC for Bayesian Deep Learning. In Proc. of the International Conference
on Learning Representation (ICLR), 2020.
Yuchen Zhang, Percy Liang, and Moses Charikar. A Hitting Time Analysis of Stochastic Gradient
Langevin Dynamics. In Proc. ofConference on Learning Theory (COLT), pp. 1980-2022, 2017.
Dongruo Zhou, Pan Xu, and Quanquan Gu. Stochastic Nested Variance Reduction for Nonconvex
Optimization. Journal of Machine Learning Research, 20:1-47, 2019.
Difan Zou, Pan Xu, and Quanquan Gu. Sampling from Non-Log-Concave Distributions via
Variance-Reduced Gradient Langevin Dynamics. In Proc. of the International Conference on
Artificial Intelligence and Statistics (AISTATS), 2019a.
Difan Zou, Pan Xu, and Quanquan Gu. Stochastic Gradient Hamiltonian Monte Carlo Methods with
Recursive Variance Reduction. In Advances in Neural Information Processing Systems (NeurIPS),
2019b.
12
Published as a conference paper at ICLR 2021
A	Preliminaries
Notation We denote the deterministic energy based on the parameter β by L(β) = PN=I L(xi ∣β)
using the full dataset of size N . We denote the unbiased stochastic energy estimator by
Nn Pi∈B L(xi∣β) using the mini-batch of data B of size n. The same style of notations is also
applicable to the gradient for consistency. We denote the Euclidean L2 norm by ∣∣ ∙ k. To prove the
desired results, we need the following assumptions:
Assumption 1 (Smoothness) The energy function L(x∕∙) is CN -smoothness if there exists a con-
stant CN > 0 such that ∀βι, β2 ∈ Rd, i ∈ {1, 2, .…,N},we have
∣VL(xi∣βι) - VL(xi∣β2)k ≤ CNkβι - β2k.	(10)
Note that the above condition further implies for a constant C = NCN and ∀β1 , β2 ∈ Rd, we have
∣VL(β1)-VL(β2)∣ ≤C∣β1-β2∣.	(11)
The smoothness conditions (10) and (11) are standard tools in studying the convergence of SGLD
in (Xu et al., 2018) and Raginsky et al. (2017), respectively.
Assumption 2 (DiSSipativity) The energyfunction L(∙) is (a, b)-dissipative if there exist constants
a > 0 and b ≥ 0 such that ∀β ∈ Rd, hβ, VL(β)i ≥ a∣β∣2 - b.
The dissipativity condition implies that the Markov process is able to move inward on average
regardless of the starting position. It has been widely used in proving the geometric ergodicity of
dynamic systems (Mattingly et al., 2002; Raginsky et al., 2017; Xu et al., 2018).
Assumption 3 (Gradient oracle) There exists a constant δ ∈ [0, 1) such that for any β, we have
E[∣VLe(β) - VL(β)∣2] ≤ 2δ(C2∣β∣2 + Φ2),	(12)
where Φ is a positive constant. The same assumption has been used in Raginsky et al. (2017) to
control the stochastic noise from the gradient.
B Exponential accelerations via Variance reduction
We aim to build an efficient estimator to approximate the deterministic swapping rate S(β(1), β(2) )
S(β ⑴,β⑵)=e( τ(1)- τ12)) (PN=IL(XiIe(I))-PN=IL(XiIe⑶力
(13)
In big data problems and deep learning, it is too expensive to evaluate the energy PN=I L(xi∣β) for
each β for a large N. To handle the computational issues, a popular solution is to use the unbiased
stochastic energy N Pii∈B L(xi∣β) for a random mini-batch data B of size n. However, a naive
replacement of PN=I L(x∕β) by N Pi∈B L(xi∣β) leads to a large bias to the swapping rate. To
remove such a bias, we follow Deng et al. (2020) and consider the corrected swapping rate
b(β(I), β⑵)=e( τ1) - τ12))(Nn Pi∈B L(XiIe(I))-Nn Pi∈B L(XiIe⑶)一(τ1) - τ⅛))号)，	(14)
where b2 denotes the variance of N Pi∈B L(XiIe(I)) — N Pi∈B L(xi∣β(2)). * Empirically, b2 is
quite large, resulting in almost no swaps and insignificant accelerations. To propose more effective
swaps, we consider the variance-reduced estimator
NN
L(Bk∣βk) = ~n X (L(XiIek) — L(XJembmk」))+ XL(XJembmC) ,	(15)
i∈Bk	i=1
where the control variate em^kC is updated every m iterations. Denote the variance of L(BIe(I))一
Le(B|e(2)) by σe2. The variance-reduced stochastic swapping rate follows
Sη,m,n(e ⑴,e(2)) = e( τ(1) - τ(2) )(L(BIe(I))-L(BIe⑵)-(τ(1) - τ(2) ) σ2 ).	(16)
*We only consider the case of F = 1 in the stochastic swapping rate for ease of analysis.
13
Published as a conference paper at ICLR 2021
Using the strategy of variance reduction, we can lay down the first result, which differs from the ex-
isting variance reduction methods in that we only conduct variance reduction in the energy estimator
for the class of SGLD algorithms.
Lemma B1 (Variance-reduced energy estimator) Under the smoothness and dissipativity as-
sumptions 1 and 2, the variance of the variance-reduced energy estimator L(BkIekh)), where
h ∈ {1, 2}, is upper bounded by
Var (L(Bk Iekh))) ≤ TnDR ( T (2C 2ψd,τ ⑵,C,a,b+ 2Q2)+4t ⑵ d) .	(17)
where DR = CR+maxi∈{i,2,…，n} N∣∣VL(xi∣β?)k + Cb and R is the radius ofa sufficiently large
ball that contains ek(h) for h ∈ {1, 2}.
Proof
Var (L(BkIekh))
=E
i∈Bk
=E
i∈Bk
N2
滔E
i∈Bk
X	L(XiIekh)) - L
n X	L(XiIekh))- L
n X	L(XiIekh))- L
m
N
+ X L d∣ 喟 mk C)-X L(XjIekh,J]
LaM mk c) - X L(XjIekh) j
L (Xj∣e(h)mkC) - XL(XjIekh))
-N XL(XjIekh))- X
j=1
L xj
j=1
=N X E KL(XiIekh)) - L (χi∣emh)mkc
≤N2 X J(L(XiIekh)) - L 卜MmC
N
2
2
2
(18)
where the last equality follows from the fact that E[(Pin=1 xi)2] = Pin=1 E[xi2] for independent
variables {xi}in=1 with mean 0. The first inequality follows from E[(x - E[x])2] ≤ E[x2] and the
last inequality follows from LemmaD1, where DR = CR + maxi∈{i,2, ∙ ,n} NkVL(x∕e*)k + C
and R is the radius of a sufficiently large ball that contains ek(h) for h ∈ {1, 2}.
Next, We bound E Iekh) — β(h)as follows
E Kkh)-e(h) mk」『]≤ E
X	(ej+)1 - ejh))∣l ≤ m X E ]∣∣(ej+)ι-ejh))∣∣2].(i9)
j=mb m C	I _| j=mb m C	L	」
14
Published as a conference paper at ICLR 2021
For each term, we have the following bound
E 概+)1 -βjh)∣∣2 =E UnNn X VL(Xi ∣βkh)) + p2ηT(h) ξj]
≤2nnNN2 X E [∣VL(xi∣βkh))『]+4nτ(2)d
i∈Bk
≤ 2n2 (2C 2E[kβkh)k2] + 2Q2) + 4nτ ⑵ d
2η2
≤----(2C ψd,τ⑶,C,a,b + 2Q ) + 4nτ	d,
n	,τ , ,a,
(20)
where the first inequality follows by E[ka + bk2] ≤ 2E[kak2] + 2E[kbk2], the i.i.d of the data points
and τ(1) ≤ τ(2) for h ∈ {1, 2}; the second inequality follows by Lemma D2; the last inequality
follows from Lemma D3.
Combining (18), (19) and (20), we have
Var (L(Bk ∣βkh))) ≤ TnDR ( nn( (2C 2ψd,τ ⑵,C,a,b+ 2Q2)+4τ ⑵ d) .	QI)
■
SinCe Var (L(Bk ∣βkh))) ≤ Var (Nn Pi∈B L(XiIek)) + Var (Nn Pi∈B L(XJemb m c)) by defi-
nition, Var (L(Bk Iekh))) is upper bounded by O (min{b2, mnη}), which becomes much smaller
using a small learning rate n, a shorter period m and a large batCh size n.
Note that Seη,m,n(e(1), e(2)) is defined on the unbounded support [0, ∞] and
E[Seη,m,n(e(1), e(2))] = S(e(1), e(2)) regardless of the scale of σe2. To satisfy the (stochas-
tic) reversibility condition, we consider the truncated swapping rate min{1, Seη,m,n(e(1), e(2))},
which still targets the same invariant distribution (see section 3.1 (Quiroz et al., 2019) for details).
We can show that the swapping rate may even decrease exponentially as the variance increases.
Lemma B2 (Variance reduction for larger swapping rates) Given a large enough batch size n,
(h)
the variance-reduced energy estimator L(Bk ∣ek ) yields a truncated swapping rate that satisfies
E[min{1,Sη,m,n(β⑴,β⑵)}] ≈ min {l,S(β⑴,β⑵) (θ (n2) + e7号 + n12)) }. (22)
Proof
By central limit theorem, the energy estimator N Pii,∈B L(XiIek) converges in distribution to a
normal distributions as the batch size n goes to infinity. In what follows, the variance-reduced
estimator L(Bk∣ek) also converges to a normal distribution, where the corresponding estimator is
denoted by L(BkIek). Now the swapping rate Sη,m,n(∙, ∙) based on normal estimators follows
Sη,m,n(e ⑴,e ⑵)=e( τ(⅛ - τ(⅛ )(e(B|e(1))-L(B1e ⑵)-(τ(Γ) - τ(⅛ ) σ2 ),	(23)
where σ2 denotes the variance of L(B∣e⑴)一 L(B∣e⑵).Note that Sη,m,n(e⑴,e(2)) fol-
lows a log-normal distribution with mean logS(e(1),e(2)) 一 (为 一 为)2 σ22 and variance
(为 一 为)2 σ2 on the log-scale, and S(e(1), e(2)) is the deterministic swapping rate defined
in (13). Applying Lemma D4, we have
E[min{1, Sη,m,n(e(1), e(2))}] =O
S(e(1), e(2)) exp
(一(为 一 τ⅛^)2 σ2 )!
(24)
Moreover, σ2 differs from e2, the variance of L(B∣e⑴)一 L(B∣e(2)), by at most a bias of
O(nI) according to the estimate of the third term of (S2) in Quiroz et al. (2019) and e2 ≤
15
Published as a conference paper at ICLR 2021
Var (L(Bk Iβk1))) + Var (L(Bk Iβk2))), where both Var (L(Bk Iβk1))) and Var (L(Bk Iβk2))
are upper bounded by m2ηDR (驾(2C2Ψd,τ(2),c,a,b + 2Q2) +4τd) by Lemma B1,it follows that
E[min{1, Sη,m,n(β⑴,。⑵川 ≤ S(β⑴,5* 2))e-°(m+n2).	(25)
Applying min{1, A + B}≤ min{1, A}+ IBI, we have
E[min{1, Seη,m,n(β(1), β (2))}]
=E [ min {1, Sη,m,n(β⑴,户⑵)-Sη,m,n(β⑴,β(2))+ Sη,m,n(β⑴,户⑵)}]
'----------------------{-------------} '-----{-----}
B	A	(26)
Sη,m,n(β⑴，52))∣i + E[min{1, Sη,m,n(β⑴,。⑵)}]
} '{}
see formula (25)
≤E Seη,m,n(β	(1), β(2)) -
'------------------------------
I
By the triangle inequality, we can further upper bound the first term I
E hSeη,m,n(β (1),β (2)) - Sη,m,n(β(1), β (2)i
≤	E[Seη,m,n(β(1), β(2))] -S(β	(1),β	(2)) +	S(β(1), β	(2))	- E[Sη,m,n(β(1), β(2))]
'-------------------"-------------------'	'-------------------"-------------------'	(27)
I1	I2
=S(β⑴,β(2))O (*) + S(β⑴,β(2))O (W),
where I1 and I2 follow from the proof of S1 without and with normality assumptions, respectively
(Quiroz et al., 2019).
Combining (26) and (27), we have
E[min{1,Sη,m,n(β⑴,52))}] ≈ min {l,S(β⑴,52)) (θ () + e-O(畸 + n2)) }. (28)
This means that reducing the update period m (more frequent update the of control variable), the
learning rate η and the batch size n significantly increases min{1, Ser∣,m,n} on average. ■
The above lemma shows a potential to exponentially increase the number of effective swaps via
variance reduction under the same intensity r. Next, we show the impact of variance reduction in
speeding up the exponential convergence of the corresponding continuous-time replica exchange
Langevin diffusion.
Theorem 1 (Exponential convergence) Under the smoothness and dissipativity assumptions 1 and
2, the replica exchange Langevin diffusion associated with the variance-reduced stochastic swap-
Ping rates Sη,m,n(∙, ∙) = min{1, Sη,m,n (∙, ∙)} converges exponential fast to the invariant distribu-
tion π given a smaller learning rate η, a smaller m or a larger batch size n:
W2(νt,π) ≤ D0 exP {-t(1 + δSη,m,n、/CLS } ,	(29)
where Do = ,2cLSD(VOIIn)，δSη,m,n
inft>0
- 1 is a non-negative constant de-
pending on the truncated stochastic swapping rate Sη,m,n(∙, ∙) and increases with a smaller learning
rate η, a shorter period m and a large batch size n. CLS is the standard constant of the Iog-SoboleV
inequality asscoiated with the Dirichlet form for replica exchange Langevin diffusion without swaps.
Proof Given a smooth function f : Rd × Rd → R, the infinitesimal generator LSη,m,n associated
with the replica exchange Langevin diffusion with the swapping rate Sη,m,n = min{1, Sη,m,n }
follows
LS …f(β ⑴,户⑵)=-Bea f(。⑴,β(2)), VL(β (I))i-hVβ ⑵ f(。⑴,52)), VL(52))i
+ τ (1)∆β(1) f (β (1),β (2))+τ(2)∆β(2)f(β(1),β	(2))
+ rSη,m,n(β⑴,。(2)) ∙(f (β(2), β(1)) — f (51),52))),
(30)
16
Published as a conference paper at ICLR 2021
where Ve(h)and 丛仔(h are the gradient and the LaPlace operators with respect to β(h),respectively.
Next, we model the exponential decay of W2 (νt , π) using the Dirichlet form
ESη,m,n(f) =	ΓSη,m,n(f)dπ,	(31)
where Γsη,m,n (f) = 2 ∙ Lsη,m,n (f2) - fLsη,m,n (f) is the Carre du Champ operator. In particular
for the first term 2Lsη,m,n (f2), We have
2 LSη,m,n (f(β ⑴,β(2) )2)
=- hf(β(1),β(2))Vβ(1)f(β(1),β(2)),Vβ(1)L(β(1))i+τ(1)kVβ(1)f(β(1),β(2))k2
+ τ(1)f(β(1), β(2))∆β(1) f(β(1), β(2))
-hf(β(1),β(2))Vβ(2)f(β(1),β(2)),Vβ(2)L(β(2))i+τ(2)kVβ(2)f(β(1),β(2))k2
+ τ(2)f(β(1), β(2))∆β(2) f(β(1), β(2))
+ 2Snm,n(β⑴,β(2))(f2(β(2), β(1)) — f2(β⑴,β(2))).
Combining the definition of the Carre du Champ operator, (30) and (B), We have
ΓSη,m,n (f(β(1), β(2)))
=1 LSη,m,n (f2(β ⑴,β ⑵))一f(β ⑴,β ⑵)LSη,m,n (f(β ⑴,β ⑵))
=T ⑴ kVe(i)f (β ⑴,β(2))k2 + T ⑵ We ⑵ f (β ⑴,β(2))k2
+ 2 Sη,m,n(β ⑴,β ⑵)(f(β ⑵,β(1)) — f(β(1), β ⑵))2.
(32)
Plugging (32) into (31), the Dirichlet form associated with operator LSη,m,n follows
ESη,m,n (f )
V
(1)kVβ(1)f(β(1), β(2))k2 + T(2)kVβ(2)f(β(1), β(2))k2dπ(β(1), β(2))
— 一一	J
{z
vanilla term E(f)
+ W Z Sη,m,n(β ⑴,β⑵)∙ (f(β ⑵,β(1)) — f(β(1), β ⑵))2d∏(β ⑴,β ⑵),
V--------------------------------------------------------------------------------------'
"{^^^^^^~
acceleration term
(33)
where f corresponds to
dνt
dπ(β⑴,β⑵).
Under the asymmetry conditions of
Vt
π(βι,β(2))
and Sη,m,n
> 0,
the acceleration term of the Dirichlet form is strictly positive and linearly dependent on the
swapping rate Sη,m,n. Therefore, ESη,m,n (f) becomes significantly larger as the swapping rate
Sη,m,n increases significantly. According to Lemma 5 (Deng et al., 2020), there exists a constant
δsη,m,n = inft>o '内,mj^/ɪ) 一 1 depending on S%m,n that satisfies the following log-Sobolev
inequality for the unique invariant measure π associated with variance-reduced replica exchange
Langevin diffusion {βt}t≥0
D(VtIIn) ≤ 21+cS — ESη,m,n (J dνt )，
η,m,n
where δSη,m,n increases rapidly with the swapping rate Sη,m,n. By virtue of the exponential decay
of entropy (Bakry et al., 2014), we have
D(νt∣∣π) ≤ D(νo∣∣π)e-2t(1+δsη,m,n)/cLS,
where cLS is the standard constant of the log-Sobolev inequality asscoiated with the Dirichlet form
for replica exchange Langevin diffusion without swaps (Lemma 4 as in Deng et al. (2020)). Next,
we upper bound W2(νt, π) by the Otto-Villani theorem (Bakry et al., 2014)
W2(νt,∏) ≤ P2cLSD(νt∣∣π) ≤ P2cLSD(μo∣∣∏)e-t(1+δSη,m,n)/cLS,
17
Published as a conference paper at ICLR 2021
where δsη,m,n > 0 depends on the learning rate η, the period m and the batch size n. ■
In the above analysis, we have established the relation that δSη,m,n
inft>0 ^qqVt - 1
depending on Sη,m,n may increase significantly with a smaller learning rate η, a shorter period m
and a large batch size n. For more quantitative study on how large δSη,m,n is on related problems,
we refer interested readers to the study of spectral gaps in Lee et al. (2018); Dong & Tong (2020);
Futami et al. (2020).
C Discretization error
Consider a complete filtered probability space (Ω, F, F = (Ft)t∈[o,τ], P) which supports allthe ran-
dom subjects considered in the sequel. With a little abuse usage of notation, the probability measure
P (component wise if P is joint probability measure with mutually independent components) would
always denote the Wiener measure under which the process (Wt)0≤t≤T is a P-Brownian motion.
To be precise, in what follows, we shall denote P := PW × N, where PW is the infinite dimen-
sional Wiener measure and N is the Poisson measure independent of PW and has some constant
jump intensity. In our general framework below, the jump process α is introduced by swapping the
diffusion matrix of the two Langevin dynamics and the jump intensity is defined through the swap-
ping probability in the following sense, which ensures the independence of PW and NS in each
time interval [iη, (i + 1)η], for i ∈ N+. The precise definition of the Replica exchange Langevin
diffusion (reLD) is given as below. For any fixed learning rate η > 0, we define
dβt = -VG(βt)dt + ∑(αt)dWt,
(34)
P (α(t) = j∣α(t - dt) = l, β(]t∕ηJη) = β) = rS(β)η1{t=bt∕ηCη} + o(dt), for l = j,
where VG(β):
VL(β(1t)), and 1t=bt∕ηcη is the indicator function, i.e. for every t = in with
i ∈ N+, given β(iη) = β, We have P (α(t) = j∣α(t 一 dt) = l) = rS(β)η, where S(β) is defined
as min{1, S(β(1), β(2))} and S(β(1), β(2)) is defined in (13). In this case, the Markov Chain α(t)
is a constant on the time interval [∖t∕ηCη, bt/nCn + η) with some state in the finite-state space {0,1}
and the generator matrix Q follows
-rS(β)nδ(t - bt/ncn) rS(β)nδ(t - bt/ncn)
rS(β)nδ(t - bt/ncn)	-rS(β)nδ(t - bt/ncn) ,
Dirac delta function. The diffusion matrix
where δ(∙) is a
0 A	(√2T(2) Id	0 N
√2T(2)IJ , l 0	√2T(1)IJ j
Σ(αt) is thus defined as (Σ(0), Σ(1)) :=
From our definition and following Yin
& Zhu (2010)[Section 2.7], the generator matrix Q will depend on the initial value at each time
interval [in, (i + 1)n). The distribution of process (βt)0≤t≤T is denoted as νT := PG × NS which
is absolutely continuous with respect to the reference measure P := PW × N, under which W
is Brownian motion and α(∙) is a Poisson process with some constant jump intensity. This fact
follows from the result in Gikhman & Skorokhod (1980)[VII, Section 6, Theorem 2] and Yin & Zhu
(2010)[Section 2.5, formula (2.40)]. The motivation of only considering the positive swapping rate
+
in in, fori ∈ N+, and zero elsewhere is due to our construction of the discretized process β as shown
below (see equation 35). A simple illustration of the idea can be seen from the auxiliary process
construction in Yin & Zhu (2010)[Section 2.5], following which we want to make sure the stopping
time of β and β happening at the same time. Otherwise, it is unlikely (and also unreasonable) to
derive the Radon-Nikodym derivative of the two process β and β. Thus, we should think of the
process is concatenated on the time interval [in, (i + 1)n) up to time horizon T. Similarly, we
consider the following Replica exchange stochastic gradient Langevin diffusion, for the same
learning rate n > 0 as above, we have
-„ -------- , -„ . , _ . .
dβη = -VG(βft∕ηCη )dt + £(&1〃用刀)dWt,
(35)
P (α(t) = j∣e(t - dt) = l,β(bt∕ηCη) = β) = rS(β)η1{t=bt∕ηCη} + o(dt), for l = j,
18
Published as a conference paper at ICLR 2021
EharaV冷• — (" L(β	D nd e(e∖ — min∕1 W <e(1) e⑵、Iq nd W	( e(1) 万⑵、i0
where V G(β) ：= ("L(e(2) ) J and S (β) = min{ 1, Sη,m,n(β , β ) } and Sη,m,n(β , β ) is
shown in (16). The distribution of process (βt)o≤t≤τ is denoted as μτ := PG X NS, where e is a
Poisson process withjump intensity rS(β)ηδ(t - [t∕ηCη) on the time interval [[t∕ηCη, [t∕ηCη+η).
Note that β andβ are defined by using the same P-Brownian motion W, but with two different
jump intensity on the time interval [bt∕ηcη, bt∕ηcη + η). Notice that, if there is no jump, the
construction ofβ based onβ follows from the fact that they share the same marginal distributions
as shown in GyOngy (1986), where one can find the details in Raginsky et al. (2017). Given thejump
process α and αW introduced into the dynamics ofβ andβ , the construction is more complicated.
Thanks to Bentata & Cont (2009), we can carry on the similar construction in our current setting.
We then introduce the following Radon-Nikodym density for dντ∕dμτ. In the current setting, the
change of measure can be seen as the combination of two drift-diffusion process and two jump
process simultaneously. We first introduce some notation. For each vector A ∈ Rn , we denote
∣∣Ak2 := A*A. Furthermore, We introduce a sequence of stopping time based on our definition of
+
process β andβ . For j ∈ N+, we denote ζj0 s as a stopping times defined by ζj+1 := inf {t > ζj :
α(t) 6= α(ζj )} and N(T) = max{n ∈ N : ζn ≤ T}. It is easy to see that for any stopping time
ζi, there exists l ∈ N+ such that ζj = lη. Similarly, we have the stopping time for the process β
by Zj+ι := inf{t > Zj : α(t) = α(Zj)} and ɑ(t) follows the same trajectory of α(t). To serve the
purpose of our analysis, one should think of the process β as the auxiliary process to the process β ,
see similar constructions in Yin & Zhu (2010)[Section 2.5, formula (2.39)]. The difference is that
both of our process β andβ are associated with jump process jumping at time iη, for some integer
i ∈ N+, instead of jumping at any continuous time. We combine approximation method from Yin
& Zhu (2010)[Section 2.7] for non-constant generator matrix Q and the density representation for
Markov process in Gikhman & Skorokhod (1980)[VII, Section 6, Teorem 2] to get the following
Lemma C1 Let {Zj∣j ∈ {0,1,…，N (T)}} be a Sequence of stopping time defined by α. Let
k ∈ N+ be an fixed integer such that kη ≤ T ≤(k + 1)η. For each fixed learning rate η > 0 and
for any ε > 0, the Radon-Nikodym derivative of dμτ∕dντ is given as below,
dμτ
dνT
(αW(ζj))VGW(βt) - Σ-1(α(ζj))VG(βt) dWtG
1 N(T)	ζj+1∧T	2
-G 三(	∣∣∑-1(e(Zj))vG(βt) - ∑-1(α(Zj))VG(βt)∣∣ dt)
N(T)) ζj+1∧T-ε
× exp《-t /	rδ(t -bt∕ηCη)[S(βbt∕ηCη) - $同“〃」〃)]ηdt
I j=0 Jcj

×Π
N(T) S(βζj)
j=0 S(βζ^).
Proof Recall that ζj is stopping time defined by α (same as defined by αW), i.e. ζj+1 := inf{t >
Zj : a(t) = α(Zj)}, for j = 0,1,…，N(T), and for each Zj, there exists l ∈ {0,1,…，k} such
that ζj = lη. We now follow Gikhman & Skorokhod (1980)[VII, Section 6, Theorem 2] to derive
the Radon-Nikodym density for dμτ ∕dντ. In this case, if the generator matrix Q is constant, i.e. the
jump intensity is constant, we can follow the similar construction from Yin & Zhu (2010)[Formula
(2.40)], see also Eizenberg & Freidlin (1990)[Formula(3.13)]. Next, we adjust our setting to the case
that we can treat our generator matrix as constant on each time interval [Zj, Zj+1), then the existing
results apply to our case for the density with respect to the Poisson measure (jump process α and
e
αW), i.e. dNS ∕dNS. Furthermore, once the generator matrix Q is constant, then the measure PG ( or
ee
PG) is independent to NS (or NS). We show the following steps to give a clear outline of our proof.
Step 1: For each stopping time interval [Zj, Zj+1), no jump would occur after the initial point at
time Zj and the diffusion matrix Σ and Σ keep the same, thus we can apply the generalized Girsanov
e
theorem to get the Randon-Nikodym derivative for dPG∕dPG.
ee
Step 2: In order to combine the the two density of dNS ∕dNS and dPG∕dPG, we need the inde-
pendent property of the two measures on the same time interval, then we directly get the density
19
Published as a conference paper at ICLR 2021
following from Gikhman & Skorokhod (1980)[VII, Section 6, Theorem 2]. Different from the work
mentioned above, we will first write all the density on each time interval [iη, (i + 1)η) to incor-
porate the independent requirement mentioned above. Notice that the relative change of density
e
for dNS /dNS would only depends on the left end point, since the jump intensity would change
its values at the initial value of interval [iη, (i + 1)η), which is a standard idea to deal with gen-
erator matrix Q depending on the initial value instead of a constant matrix case. (See Yin & Zhu
(2010)[Section2.7] for similar treatments).
Step 3: In general, the stopping time interval could contain several time interval with length η,
however the jump intensity should only depend on the left end point for each time interval [iη, (i +
1)η). Based on the above set up, we now derive the Radon-Nikodym derivative. First notice that,
on each period [ζj, ζj+1), the matrix Σ is fixed and is evaluated at Σ(α(ζj)), which is the same
for Σ(αe(ζj)). In particular, Σ(α(ζj)) = Σ(αe(ζj)) is a constant diagonal matrix. According to our
ee
definition dντ = dPG X dNS and dμτ = dPG X dNS, We write the Radon-Nikodym derivative on
each of the time interval [iη, (i + 1)η) and concatenate them together. We consider the swapping of
the diffusion matrix first where a similar construction can be found in Yin & Zhu (2010)[Formula
(2.40)], we get the following Radon-Nikodym derivative, for any ε > 0,
dNS
dNS
N(T)	(j+1)η∧T -ε
exP 1 - Σ /	rδK- b”ηCn)(SGeβbt∕η") - SIeebt))ηdt}
j=0 jη

XΠ
N(T) S(βZj)
j=0 S(βZ^).
(36)
e
Next, we show the density for dPG/dPG as below. On each interval [ζj, ζj+1), given initial value
(ej, ej), the matrix Σ(α(ζj)) and Σ(αe(ζj)) are always the same, since no jump would happen. In
particular, in this continuous case the integral on [ζj, ζj+1) and [ζj, ζj+1] are the same. Thus we
have the following Radon-Nikodym derivative
dPGe =exp (NX)∕+1∧T h∑-1(e(Zj))VGe(βt) - ∑-1(α(Zj))VG(βt)]dWG
1 N(T)	ζj+1∧T	2
— 2 ∑	∣∣∑-1(e(Zj))VG(βt)-Σ-1(α(Zj))VG(βt)∖∖ dt).	(37)
2 j=0 ζj
Notice that matrix Σ is diagonal square matrix, thus we have Σ = Σ*. Recall that W is a P-
Brownian motion, assuming there is no jump in the dynamic for e, then according to the Gir-
sanov theorem (see an example in Theorem 8.6.6 and Example 8.6.9 (0ksendal, 2003)) with Radon-
Nikodym derivative dPG/dP, we have the PG-Brownian motion, denoted as WG, which follows
WtG := Wt +
Zt
0
Σ-1(αs)(VG(es))ds.
(38)
e
This fact holds true on each of the time interval [ζj, ζj+1]. Multiplying the two density dPG/PG and
e
dNS /dNS, we complete the proof.
Remark 1 Notice that, if we keep the constant diffusion matrix without jump, then the Randon-
Nikodym derivative dμτ/dντ has been used in the stochastic gradient descent setting, for example
Raginsky et al. (2017). However, the notation of the Brownian motion has been used freely, we try
to make it consistent in the current setting. Namely, for constant diffusion matrix Σ, we have
dPG
dPG
exp
Σ-1VGe(ees) - Σ-1VG(es) dWsG
0
- 2 Zo
Σ-1VGe(ees) - Σ-1VG(es)2ds,
(39)
where WG is a PG-Brownian motion as shown in equation 38, not a P-Brownian motion W.
20
Published as a conference paper at ICLR 2021
Remark 2 The density dμT that we derived above is so far the best we can do. Ifone would like
to use the continuous time control α(t) with continuous jump intensity S(β(t)) instead of jumping
at the initial point with a fixed rate, then we can not even write the Randon-Nikodym derivative
anymore, since a(t) and e(t) will define different stopping time, i.e. jump at different time and μτ
is not absolutely continuous with respect to νT.
Based on the above lemma, we further get the following estimates.
Lemma C2 Given a large enough batch size n or a small enough m and η, we have the bound of
the KL divergence of DκL(μτ∣ντ) as below,
Dkl(Pt|vt) ≤ (Φo + Φιη)kη + N(T)Φ2,
with
Φ0
Φ1
八	L A	rδΦ2
O	√ηd)+ 折,
(C 2"TS+CSd [τ ⑴+T ⑵])
Φ2 = O
Proof By the very definition of the KL-divergence, we have
DκL(μτ∣ντ) = - d dντ log μT-
dνT
=-EVTh log(dμ-/dν-) ∣(β, β) = (β, e)i.
5T 1	11 1	.1	11	-I-I . ττn	ττn Γ I / zɔ ?i\	/ C 7⅛∖ T ι	C
We shall keep the convention below and denote EVT,β = EVT[∙∣(β,β) = (β,β)], where β =
(β⑴，β⑵)∈ R2d and β = (β⑴，β⑵)∈ R2d denotes the values at each time iη, i = 0,1,…，k.
Plugging Lemma C1 in the above equation and we unify the notation by using time intervals of the
type [iη, (i + 1)η]. To be precise, we get
dPGe =exp (X/(i+1)η h∑-1(e(iη))vG(βt) - ∑-1(α(iη))VG(βt)]dWG
+
Σ-1(αe(kη))vGe(βt) -
kη
Σ-1(α(kη))vG(βt) dWtG
1 k-1	(k+1)η	2
-2∑^	∣∣∑-1(e(iη))vG(βt) - ∑-1(α(iη))VG(βt)∣∣ dt
- 1 Zkn
Σ-1(αe(kη))vGe(βt) - Σ-1(α(kη))vG(βt)2dt.
(40)
The above equality follows from the fact that each time interval [ζj, ζj+1] always contain exactly
some sub-interval [iη, (i + 1)η]. Namely, we have [ζj, ζj+1] = [iη, (i + 1)η] ∪ [(j + 1)η, (j + 2)η] ∪
… ∪ [lη, (l + 1)η], for some i,l ∈ {0,1,…，k}. In particular, the matrix Σ keep the same on
each interval [iη, (i + 1)η], for some i ∈ {0,1, ∙∙∙ ,k}. Similarly, We expand the Radon-Nokodym
e
derivative for dNNs on the time interval of length η. Based on our definition ofjump intensity, we get
dNSe	N(-)	(j+1)η∧- -ε
dNS =eχp I -工	rδ(t - Lt/ncn)(S(eLt/nCn) - sG⅜∕nCn))ηdt
dN	j=0 jη
-Z-rδ(s
......≈ , ≈ 、 , _ 一 _ 1
-LS^cη)(S(βkn) - S(Bkn))ηds}
× ΠN(-)
× Πj=0
exp
-Xk
i=0
r(Se(βein) - S(βin ))η
× ΠN(-)
× Πj=0
S(βZj)
SleZj
(41)
21
Published as a conference paper at ICLR 2021
Without loss of generality, we shall only consider the sum Pik=-01 and skip the interval [kη, T].
Notice that on each time interval [iη, (i + 1)η), the control α(iη) and αe(iη) are fixed, thus the
two component of the measure dνT,β are independent. Taking into account the fact that WG is
PG-Brownian motion, thus we apply the martingale property and arrive at
Dkl(Pt |vt )
=Eντ,β h 2 X Γn∣∣
k-1
∑-1(e(iη))vG(βt) - ∑-1(α(iη))VG(βt)∣∣2dti
N(T)
+EνT,β X[Se(βeiη) - S(βiη)]η - X	log Se(βeζj) - log S(βζj)
i=0
j=0
1 k-1	(i+1)η ∣	∣2
≤2EEVT,β[/	∣∣∑-1 (e(iη))VG(βt)-∑-1(α(iη))VG(βt)∣∣ dt∖
`—-------------------------------------------------------}
k-1
{^^^^^^™
I
N(T)
+ XEVT,β [r∣e(βiη) - SRn)∣η] + X EVT,β [| logS(BZj)- logS(βζ31
i=0
{z
J
，ιj=0
{z
K
}
We then estimates the three terms I, J , K in order as below.
Estimate of I: Due to the fact that every interval [iη, (i
j ∈ {0,1, ∙∙∙,N(T)}, We know that the control a and
+
α
1)η) ⊂ [ζj , ζj+1) for some
are the same in the interval
[iη, (i + 1)η] and the diffusion matrix Σ is just constant matrix. Thus, we know that ma-
trix Σ-1 (αe(iη)) = Σ-1 (α(iη)), which takes one of the form from (Σ-1 (0), Σ-1 (1)) :=
Id 0
√2T(2) Id)，
Id
. If Σ-1 (α(iη)) = Σ-1(0), we get
∣∣∣Σ-1(αe(iη))VGe(βt) - Σ-1(α(iη))VG(βt)∣∣∣2
d	2d
=X 2τ⑴ VjG(βt) -VjG(βt)∣2 + X 2τw|VjG(βt) -VjG(βt)∣2
j=1 τ	j=d+1 τ
1	2d	1
≤亦 E VjG(βt) - VjG(βt)∣2 ≤ —(1)kVG(βt) - VjG(βt)k2.
2τ	j=1	2τ
Here VG(β) := VVLL((ββ((12)))) and VGe(β) :
will result in the same estimates. We thus get
VLe(β(1))
VLe(β(2))
. The other matrix
form of Σ-1(1)
k-1	(i+1)η	2
I≤ K X EVT ,β[Ji	∣∣VG(βt) -VG(βt)∣∣ dt]
On each fixed interval, for t ∈ [kη, (k + 1)η) , we have PG-Brownian motion and PG-Brownian
motion (See examples in Theorem 8.6.6 and Example 8.6.9 (0ksendal, 2003)),
dWtG =dWt + Σ-1(αt)(VG(βt))dt.
-"W
dWtG =dWt + Σ-1(αt)(VGe(βet))dt.
Plugging the PG (and PG)-Brownian motions to the original dynamics (34) and (35), we have
dβt = Σ(αt)dWtG, and dβet = Σ(αt)dWtG .
22
Published as a conference paper at ICLR 2021
On each interval [iη, (i+1)η), Σ(αt) is a constant matrix, thus we know that the probability distribu-
tion of {βt}t∈[kη,(k+1)η) and {βt}t∈[kη,(k+1)η) are the same and we denote as L(βt) = L(βt). The
e
difference is that βt is driven by PG-Brownian motion and βt is driven by PG-Brownian motion,
which implies that, for t ∈ [iη, (i + 1)η), we have
EVT,β h∣∣VGe(βt) -VG(βt)∣∣2i = EμT,zeh∣∣VGe(βt) -VG(βt)∣∣2i.	(42)
Thus, we have the following estimates,
1	k-1	(i+1)η ∣	∣2
I≤ 4τ(1) ∑Eμτ ,β[Jιη	∣vG(βt) -vG(βbt∕nCn )∣∣ 叫
1 k-1	(i+1)η ∣	∣2
+ 4τ(1)£E“t,e[∕	∣∣vG(βbtΛηcη)-VGMb〃ηcη)∣∣ dtJ
C2 k-1	(i+1)η ∣	∣2
≤4T(1)∑Eμτ,βlJin	∣∣βt-βiη)∣∣ dt∖ ∙∙∙I1
1 k-1	(i+1)η ∣	∣2
+ 4T(1) ΣEμτ ,e[∕	∣∣VGGβbt∕nCn)-VGGβbt∕nCn )∣∣ 叫∙∙∙I2∙
e
We now estimate the two terms I1 and I2 separately. Notice that, following our notation of PG-
Brownian motion, for t ∈ [iη, Gi + 1)η), we have
βet - βeiη =ΣGαt)GWtGe-WiGηe) =ΣGαt)GWtGe-WiGηe),
....	-.	.	.	---	,	-.M	. . ,	-C‹√∖∕CZ
which implies that (recall that dμτ = dPG X NS and Σ ∈ R2d×2d),
E*τ,β[kβt — βink2] ≤ 2τ⑴dη + 2τ(2)dη ≤ 4τ⑵邮.
We thus conclude that,
2 τ(2)	2
Ii ≤ C ~7kd kdη .
τ(1)
As for the term I2, according to Assumption 3, we obtain that
k-1
I2 ≤4⅛y XEμτ,水2kβink2 十叫
τ i=0
Now, WejUstneed to estimate E*『R[∣∣βkn∣∣2] L On each interval [iη, Gi + 1)η], under the measure
dμτ 京 we have
βe(i+1)η = βeiη + ΣGαGiη))GW(i+1)η - Wiη ),
which implies that
Eμτ,3[kβ(i+1)n k2]
=Eμτ 别% k2]+ Eμτ ,βKβg , W(G+1)n — WiG i]+ Eμτ ,方[k W(G+1)n — WiG k,
=E"τ Hkein k2] + [2τ(I) +2τ (2)]dη
e	e	ee
The last equality follows from the independence of βekn and W(Gk+1)n — WkGn, and WG is a PG-
Brownian motion. By induction, we get
Eμτ,3[kβink2] ≤ 2id[τ(I) + τ⑵]η ≤ 2kd[τ(I) + τ⑵].
tIn principle, the Wiener measure W under PG is not a Brownian motion, thus the uniform L2 bound used
in Lemma.3 may not be appropriate. Instead, we estimate the upper bound using a slightly weaker result.
23
Published as a conference paper at ICLR 2021
We conclude that,
I ≤ 黑(2C2[τ⑴ + T(Nkdn + Φ2),
which implies that
I≤ -knτ(2SC 2[τ ⑴ + T (2)]kdη + δΦ2) + C2 τ2 kdη2.
4τ(1)	τ(1)
Estimate J : According to our definition of the swapping probability, we have, for each i,
Se(βeiη) = min{1, Seη,m,n(βei(η1), βei(η2))},	S(βiη)=min{1,S(βi(η1),βi(η2))},
11
which means |S(β^η) - S(β^η)| ≤ 1. Denote CT = |^⅛) - τ⅛)I，we have
Sn,m,n(β(11, β(η)) =exp gτ(L(BeηIβ^) - L(BinIβQ) — CTɪ)
S(βi(η1),βi(η2))=expCτ(L(βi(η1))-L(βi(η2))).
Applying Taylor expansion for the exponential function at CT(L(βk(1η)) - L(βk(2η))), we have
EVT ,β [∣sn,m,n(⅛), β(n)) - s(βin), β(n))∣]
2
.Eντ,β [S(β(n), β(n))∣Cτ(L(BknIβ(n)) - L(Bkn同；)))— CT3-Cτ(L(%) - L(β(2))∣ + higher order term]
σ 2
≤Eντ,β[∣Cτ(L(Biη∣β(n)) - L(Bin同)))- CT工-Cτ(L(βi/ - L(β^))∖+。(e2)]
where the last inequality follows from S(βi(n1), βi(n2)) ≤ 1. Combining Lemma B1, we thus get the
following estimates,
k-j
J = XEVT,β rISen,m,n(eein) - S(ein)Iη
i=0
k-j	2
≤ rη X EVT,β[∣CT(L(Bin 同))-L(Bin 肃))- CT % -。其乙同))
i=0	2
- L(βi(n2)))∣∣ + O(σe2)i
≤ rkηO(Cre + e2) = rkηO ( (^^η)	d
where the last inequality follows from the Jensen’s inequality and the last order holds given a large
enough batch size n or a small enough m and η.
Estimate K: We now estimate the last term K, we have
N(T)
K = X EVT ,β h∣ log Sn,m,n(βZj ) - log S(βZj)∣i
j=0
N (T )	2
≤Cτ X EVT,β[∣[L(Bζ∕βZj)) - L(BZjIeZj))- CTσr] - [L(βZj)) - L(β(2))]∣]
j=0
N(T)
≤N(T)C2Eντ,β [σ2∕2] + CT X Var[L(Bζj∣β(I))- L(BZjIeZj))]1/2
j=j
≤ NT 产2 + N(T )Ct e
24
Published as a conference paper at ICLR 2021
Combining Lemma B1 again, we conclude with
K ≤ CT N(T)σ2 + N(T)Cτ万=N(T)O
Combining the estimates ofI, J, and K, we complete the proof.
e
Remark 3 After the change of measure, the expectation is under the new measure PG (or PG)
instead of the Wiener measure P. In the estimate of term I, similar L2 estimates of the term
Eμτ 3[∣∣β(i+i)η ∣∣2] has been obtained in Raginsky etal. (2017)[ProofofLemma 7]when there is no
e
swap. The difference is we write the dynamic of β(i+1)η with respect to the PG-Brownian motion
ee
WG instead of the P-Brownian motion W. In principle, W under PG is not a Brownian motion.
We then extend the distance of relative entropy DκL(μτ∣ντ) to the Wasserstein distance
W2 (μτ, VT) via a weighted transportation-cost inequality of Bolley & Villani (2005).
Theorem 2 Given a large enough batch size n or a small enough m and η, we have
W2(μτ, VT) ≤ O (dk3/2n (n1/4 + δ1/4 + (mn~η))).
(43)
Proof Before we proceed, we first show in Lemma.D5 that VT has a bounded second moment;
the L2 upper bound of μτ is majorly proved in Lemma.C2 (Chen et al., 2019) except that the slight
difference is that the constant in the RHS of (C.38) Chen et al. (2019) is changed to account for the
stochastic noise. Then applying Corollary 2.3 in Bolley & Villani (2005), we can upper bound the
two Borel probability measures μτ and VT with finite second moments as follows
W2(μτ, VT ) ≤ CV
PDKLg |VT) + (DKLBTIVT))1"
(44)
2	1/2
where CV = 2infλ>o(1(3 + log RRd eλkwk V(dw)))	. Applying LemmaD6, We have
W2(μT, VT) ≤(12 + 8 (κ0 + 2b + 4dτ⑵)kη^ (DKL(μT|vt) + PDkl(nt|vt)).
Combining Lemma.C2 and NN(T) ≤ N(T) and taking η ≤ 1, kη > 1, and λ = 1, we have
W2(μT,,0,VTβ) ≤(12 + 8 卜0 + 2b + 4dτ⑵))kη ((Φ0 + Φι√η)kη + N(T)Φ2),
where Φi = Φi + √Φi for i ∈ {0,1,2}. In what follows, we have
W式μTβ, VT,β) ≤ (Ψo + Ψι√η) (kη)2 + Ψ2kηN(T),
where Ψi =(12 + 8 (κ0 + 2b + 4dτ⑵))Φi for i ∈ {0,1, 2}.
By the orders of Φ0, Φ1 and Φ2 defined in Lemma.C2, we have
W2M,β*τ,β) ≤ O 卜k3η2 (η1∕2+ δ1∕2+ (mη)	+ N(T) (mη)))
≤ O 卜 2k3η2 0/2 + S1/2 + (£ η) ”J),
where NkP can be interpreted as the average swapping rate from time 0 to T and is of order O(1).
Taking square root to both sides of the above inequality lead to the desired result (43).
25
Published as a conference paper at ICLR 2021
D Proof of Technical Lemmas
Lemma D1 (Local Lipschitz continuity) Given a d-dimensional centered ball U ofradius R, L(∙)
is Dr-Lipschitz continuous in that ∣L(x∕βι) — L(x∕β2)∣ ≤ DNR∣∣βι 一 β2k for ∀βι, β2 ∈ U and
any i ∈{1,2, ∙∙∙ ,N}, where DR = CR + maxi∈{i,2,…,n } N ∣∣VL(xi∣β*)∣∣ + Cb.
Proof
For any β1 , β2 ∈ U, there exists β3 ∈ U that satisfies the mean-value theorem such that
IL(XileI)- L(XiIe2» = "L(Xile3b61 - β2i ≤ ∣∣VL(χilβ3)k ∙ |同 一。2 k ,
Moreover, by Lemma D2, we have
∣L(xi∣βι) — L(XiIe2)∣ ≤ kVL(xi∣β3)k∙kβι - β2∣ ≤ CRN+Q ∣βι —。21.・
Lemma D2 Under the smoothness and dissipativity assumptions 1, 2, for any e ∈ Rd, it follows
that
∣VL(xi∣β)k≤ Nkβk + Q.	(45)
where Q = maxi∈{i,2,…,n} N∣VL(xi∣β*)k + bC.
Proof According to the dissipativity assumption, we have
hβ?, VL(β*)i≥ akβ*k2-b,	(46)
where β? is a minimizer of VL(∙) such that VL(β?) = 0. In What follows, We have kβ*∣ ≤ b.
Combining the triangle inequality and the smoothness assumption 1, we have
∣VL(Xi∣β)k ≤Cnke — β?k + ∣∣VL(xi∣β*)k ≤ CNkβk + 2 + kVL(xi∣β*)k∙	(47)
a
Setting CN = N as in (11) and Q = maxi∈{i,2,…,n} ∣VL(xi∣β*)k + 等 completes the proof. ■
The following lemma is majorly adapted from Lemma C.2 of Chen et al. (2019), except that the
corresponding constant in the RHS of (C.38) is slightly changed to account for the stochastic noise.
A similar technique has been established in Lemma 3 of Raginsky et al. (2017).
Lemma D3 (Uniform L2 bounds on replica exchange SGLD) Under the smoothness and dissi-
pativity assumptions 1, 2. Given a small enough learning rate η ∈ (0,1 ∨ C2), there exists a
positive constantΨd,τ(2),C,a,b < ∞ such that supk≥1 E[∣ek∣2] < Ψd,τ(2),C,a,b.
Lemma D4 (Exponential dependence on the variance) Assume S is a log-normal distribution
σ2
with mean U — 2σ2 and variance σ2 on the log scale. Then E[min(1, S)] = O(eu-ɪ), which
is exponentially smaller given a large variance σ2.
Proof For a log-normal distribution S with mean U — ɪσ2 and variance σ2 on the log scale, the
probability density fs(S) follows that s√1^ exp { — (log S、：+2σ)}. In What follows, we have
E[min(1, S)] = / min(1, S)fs(S)dS = / min(1,S)——ɪ exp < 一
0	0	S 2πσ2
(log S — U + 1 σ2)2
2σ2
dS
26
Published as a conference paper at ICLR 2021
By change of variable y = log S-；+ 2σ where S = eσy+u-2σ2 and y = 一U + 2 given S = 1, it
follows that
E[min(1, S)]
广 S 1_____exp
Jo	S √2πσ2
(IOg S - u2+ 1 σ2产卜S + 广
1	( (log S 一 U + 2σ2)2
S√2πσ2 exp 一	百
dS
—
uσ
「σ + 2
-∞
1	y2	1 2∣	f∞	1	I 1 2	y2	1 2,
/	e-ɪσeu-2σ +σydy+	e-σy-u+2σ e-ɪσeu-2σ +σydy
√2∏σ2	J-σ+σ √2∏σ2
e
u
e
u
uσ
「σ+2
-∞
1	(y-σ)2 7	1
,__e 2 dy +-------
√2∏	σ
Z∞
Z∞
-U
σ
+
2
ɪ e-z2 dz +1 Z
√2π	σ J- U+2
σ
2
≤eu「ɪe-z2 dz +1「
J-U+2 v2π	σ J-U+2
≤ (eu+1〉

-2
2
.eu-苫,
where the last equality follows from the change of variable z = σ 一 y and the second last inequality
-2
follows from the exponential tail bound of the standard Gaussian variable P(y > e) ≤ eF. ■
Lemma D5 (Uniform L2 bound on replica exchange Langevin diffusion) For all η ∈ (0, 1 ∧
4CC2), we have that
E[k(βt(1),βt(2))k2] ≤E[ekβ0(1),β0(2)k2]+
b + 2dτ ⑵
a
Proof Consider Lt(βt) = kβtk2, where βt = (βt(1), βt(2)) ∈ R2d. The proof is marjorly adapted
from Lemma 3 in Raginsky et al. (2017), except that the generalized Ito formula (formula 2.7 in
page 29 of Yin & Zhu (2010)) is used to handle the jump operator, which follows that
dLt = 一 2hβt, VG(βt)i + 2d(τ⑴ + T(2))dt + 2βTΣ(αt)dW(t)
+ rSη,m,n(β(1), β(2)) ∙(Lt(β⑵,β(1)) - Lt(β卜,β(2))) +Mι(t) + M2(t),
、---------------------------{--------------------------}
Jump-inducing drift
VL(β(1))
VL(β(2))
where VG(β) :
and M1 (t) and M2 (t) are two martingales defined in formula 2.7
in Yin & Zhu (2010)). Due to the definition of Lt(βt), we have Lt(βt(1), βt(2)) = Lt(βt(2), βt(1)),
which implies that the Jump-inducing drift actually disappears. Taking expectations and applying
the margingale property of the Ito integral, We have the almost the same upper bound as Lemma 3
in Raginsky et al. (2017). Combining E[kβ0k2] ≤ logE[ekβ0k2] completes the proof.
Lemma D6 (Exponential integrability of replica exchange Langevin diffusion) For all T ≤ a,
it follows that
logE[ek(βt(1),βt(2))k2] ≤ logE[ek(β0(1),β0(2))k2] +2(b + 2dT (2))t.
、----------{----------}
κ0
Proof The proof is marjorly adapted from Lemma 4 in Raginsky et al. (2017). The only difference
is that the generalized Ito formula (formula 2.7 in Yin & Zhu (2θ10)) is used again as in Lemma
D5. Consider L(t, βt) = ekβt k2, where β = (βt(1), βt(2)) ∈ R2d. Due to the special structure that
L(t, βt) is invariant under the swaps of (βt(1), βt(2)), the generator of L(t, βt) with swaps is the
same as the one without swaps. Therefore, the desired result follows directly by repeating the steps
from Lemma 4 in Raginsky et al. (2017).
27
Published as a conference paper at ICLR 2021
Algorithm 2 Adaptive variance-reduced replica exchange SGLD. The learning rate and temperature
can be set to dynamic to speed up the computations. A larger smoothing factor γ captures the trend
better but becomes less robust.__________________________________________________________________
Input Initial parameters β0(1) and β0(2), learning rate η and temperatures τ(1) and τ(2), correction factor F.
repeat
Parallel sampling Randomly pick a mini-batch set Bk of size n.
βkh) = βkh)ι - ηNn X VL(Xi∣βk-)ι) + P2ητ(h)ξkh), for h ∈ {1, 2}.
i∈Bk
Variance-reduced energy estimators Update L(h) = PN=I L (xi∣β(h) k J ) every m iterations.
L(BkIekh)) = N X L(XiIekh))+ e ∙
i∈Bk
NNXL 卜Mmkc) - L(h)
for h ∈ {1, 2}.
if k mod m = 0 then
Update σek2 = (1 - γ)σek2-m + γσk2, where σk2 is an estimate for Var Le (Bk Iek(1)) - Le(BkIek(2))
Cov
Update cek
(1 - γ)eck-m + γck, where ck is an estimate for -
(L(BIekh)),L(B∣β((h" C))
Var (L(BIeS) k C))
m
end if
Bias-reduced swaps SWaP βk+ι and βk+ι if u < S>η,m,n, where U 〜Unif [0,1], and Seη,m,n follows
Sη,m,
exp {(τ⅛y - τ⅛y^ ^L(Bk+i|ek+i) - L(Bk+i|ek+i)
F (为■
■—
n
until k
= kmax.
Output: {ei(T1) }ib=km1 ax /Tc , where T is the thinning factor.
E More Empirical S tudy on Image Clas sification
E.1 Training cost
The batch size of n = 512 almost doubles the training time and memory, which becomes too
costly in larger experiments. A frequent update of control variates using m = 50 is even more
time-consuming and is not acceptable in practice. The choice of m gives rise to a tradeoff between
computational cost and variance reduction. As such, we choose m = 392, which still obtains
significant reductions of the variance at the cost of 40% increase on the training time. Note that
when we set m = 2000, the training cost is only increased by 8% while the variance reduction can
be still at most 6 times on CIFAR10 and 10 times on CIFAR100.
E.2 Adaptive coefficient
We study the correlation coefficient of the noise from the current parameter βk(h), where h ∈ {1, 2},
and the control variate β(h)卜	As shown in Fig.5, the correlation coefficients are only around -0.5
mb m C
due to the large learning rate in the early period. This implies that VR-reSGHMC may overuse the
noise from the control variates and thus fails to fully exploit the potential in variance reduction. In
spirit to the adaptive variance, we try the adaptive correlation coefficients to capture the pattern of
the time-varying correlation coefficients and present it in Algorithm 2.
As a result, we can further improve the performance of variance reduction by as much as 40% on
CIFAR10 and 30% on CIFAR100 in the first 200 epochs. As the training continues and the learning
rate decreases, the correlation coefficient is becoming closer to -1. In the late period, there is still
10% improvement compared to the standard VR-reSGHMC.
28
Published as a conference paper at ICLR 2021
In a nut shell, We can try adaptive coefficients in the early period when the absolute value of the
correlation is lower than 0.5 orjust use the vanilla replica exchange stochastic gradient Monte Carlo
to avoid the computations of variance reduction.
⑶ CIFAR10&m=50
(b) CIFAR100&m=50
(c) CIFAR10 & m=392 (d) CIFAR100 & m=392
Figure 5: A study of variance reduction techniques using adaptive coefficient and non-adaptive
coefficient on CIFAR10 & CIFAR100 datasets.
F More Empirical Study on Uncertainty Quantification
To avoid sacrificing the prediction power for the known classes, we also include the uncertainty
estimate on CIFAR10 using the Brier score (BS) * and compare it with the estimates on SVHN.
The optimal BS scores on the seen CIFAR10 dataset and the unseen SVHN dataset are 0 and 0.1,
respectively. As shown in Table.2, we see that the scores before calibration in the seen CIFAR10 is
much lower than the ones in the unseen SVHN. This implies that all the models perform quite well in
terms of what it knows, although cSGHMC are slightly better than the alternatives. To alleviate this
issue, we propose to calibrate the predictive probability through the temperature scaling (Guo et al.,
2017) and obtain much better results. Regarding the BS score on the unseen dataset, we see that M-
SGD still performs the worst for frequently making over-confident predictions; SGHMC performs
better but is far away from satisfying. reSGHMC obtains much better performance by allowing
interactions between different chains. However, the large correction term affects the efficiency of
the swaps significantly. In the end, our proposed algorithm increases the efficiency of the swaps via
variance reduction and further improves the highly-optimized BS score based on reSGHMC from
0.29 to 0.27, which is much closer to the ideal 0.1. Note that the accurate uncertainty estimates of
cVR-reSGHMC on the seen dataset is still maintained. Together with the lowest BS score in the
unseen SVHN dataset, cVR-reSGHMC shows its strength in uncertainty quantification.
TABLE 2: UNCERTAINTY ESTIMATES ON SVHN USING CIFAR10 MODELS.
METHOD	Brier Score (before calibration)		Brier Score (after calibration)	
	CIFAR10 (seen)	SVHN (unseen)	CIFAR10 (seen)	SVHN (unseen)
M-SGD =	0.090±0.00F=	0.48±0.02=	0.098±0.00F=	0.33±0.oL
SGHMC	0.089±0.001	0.47±0.02	0.099±0.001	0.31±0.02
-reSGHMC-	0.086±0.002	^^0.41±0.03-	0.097±0.001	^^0.29±0.02-
cSGHMC	0.084±0.001	0.43±0.02	0.092±0.001	0.30±0.02
cVR-reSGHMC	0.085±0.001	0.38±0.02	0.094±0.001	0.27±0.02
G Modified Example 5.1
We revisit Example 5.1, and re-run the procedures with temperature T⑴ =1.0. In Fig. 6, we present
trace plots and kernel density estimates (KDE) of samples generated from VR-reSGLD, reSGLD,
and SGLD. In particular, we run VR-reSGLD with m = 40, τ⑴=1, τ⑵=500, η = 1e - 5, and
F = 1; reSGLD with the same hyper-parameters as VR-reSGLD except for F = 500; and SGLD
with η = 1e - 5 and T = 1. Note that here, we run reSGLD with a greater F than in Example
5.1 in order to prohibit the drastic reduction of the swapping rate which is caused by the pickier
target density. As in Example 5.1, for the ground truth, we run replica exchange Langevin dynamics
*BS = N PN=I PRι(fj — Oij )2, where 力 is the predictive probability and oi is actual output of the
event which is 1 if it happens and 0 otherwise; N is the number of instances and R is the number of classes.
29
Published as a conference paper at ICLR 2021
VR-reSGLD
Ground truth
0	400	800
epoch
(a)	Trace plot for VR-reSGLD and
ground truth
(b)	Trace plot for SGLD, reSGLD and
ground truth
a
Figure 6: Trace plots and KDEs of β(1)
with long enough iterations. In Figs 6(a) and 6(b), we observe that, even though the distribution of
interest has a pickier density, our proposed algorithm VR-reSGLD was able to detect both modes
and acceptably jump between them. On the other hand, the competitor algorithm SGLD was trapped
in the first mode visited and never escaped. reSGLD was able to jump some times between modes
only after considering a substantial factor F = 500 which, according to the theory, introduces bias.
30