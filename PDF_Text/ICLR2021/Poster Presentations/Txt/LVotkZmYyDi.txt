Published as a conference paper at ICLR 2021
Proximal Gradient Descent-Ascent: Variable
Convergence under K匕 Geometry
Ziyi Chen, Yi Zhou	Tengyu Xu, Yingbin Liang
Department of ECE	Department of ECE
University of Utah	The ohio State University
Salt Lake City, UT 84112, USA	Columbus, oH 43210, USA
{u1276972,yi.zhou}@utah.edu	{xu.3260,liang.889}@osu.edu
Ab stract
The gradient descent-ascent (GDA) algorithm has been widely applied to solve
minimax optimization problems. In order to achieve convergent policy parameters
for minimax optimization, it is important that GDA generates convergent variable
sequences rather than convergent sequences of function values or gradient norms.
However, the variable convergence of GDA has been proved only under convexity
geometries, and there lacks understanding for general nonconvex minimax opti-
mization. This paper fills such a gap by studying the convergence of a more general
proximal-GDA for regularized nonconvex-strongly-concave minimax optimiza-
tion. Specifically, we show that proximal-GDA admits a novel Lyapunov function,
which monotonically decreases in the minimax optimization process and drives the
variable sequence to a critical point. By leveraging this Lyapunov function and
the KE geometry that parameterizes the local geometries of general nonconvex
functions, we formally establish the variable convergence of proximal-GDA to a
critical point x*, i.e., Xt → χ*,yt → y*(χ*). Furthermore, over the full spectrum
of the KE-parameterized geometry, we show that proximal-GDA achieves different
types of convergence rates ranging from sublinear convergence up to finite-step
convergence, depending on the geometry associated with the KE parameter. This
is the first theoretical result on the variable convergence for nonconvex minimax
optimization.
1 Introduction
Minimax optimization is a classical optimization framework that has been widely applied in various
modern machine learning applications, including game theory Ferreira et al. (2012), generative
adversarial networks (GANs) Goodfellow et al. (2014), adversarial training Sinha et al. (2017),
reinforcement learning Qiu et al. (2020), imitation learning Ho and Ermon (2016); Song et al. (2018),
etc. A typical minimax optimization problem is shown below, where f is a differentiable function.
min max f(x, y).
x∈X y∈Y
A popular algorithm for solving the above minimax problem is gradient descent-ascent (GDA), which
performs a gradient descent update on the variable x and a gradient ascent update on the variable
y alternatively in each iteration. Under the alternation between descent and ascent updates, it is
much desired that GDA generates sequences of variables that converge to a certain optimal point,
i.e., the minimax players obtain convergent optimal policies. In the existing literature, many studies
have established the convergence of GDA-type algorithms under various global geometries of the
objective function, e.g., convex-concave geometry (f is convex in X and concave in y) NediC and
ozdaglar (2009), bi-linear geometry Neumann (1928); Robinson (1951) and Polyak-Eojasiewicz (PE)
geometry Nouiehed et al. (2019); Yang et al. (2020). Some other work studied GDA under stronger
global geometric conditions of f such as convex-strongly-concave geometry Du and Hu (2019) and
strongly-convex-strongly-concave geometry Mokhtari et al. (2020); Zhang and Wang (2020), under
which GDA is shown to generate convergent variable sequences. However, these special global
function geometries do not hold for modern machine learning problems that usually have complex
models and nonconvex geometry.
1
Published as a conference paper at ICLR 2021
Recently, many studies characterized the convergence of GDA in nonconvex minimax optimization,
where the objective function is nonconvex in x. Specifically, Lin et al. (2020); Nouiehed et al. (2019);
Xu et al. (2020b); Bot and Bohm (2020) studied the convergence of GDA in the nonconvex-concave
setting and Lin et al. (2020); Xu et al. (2020b) studied the nonconvex-strongly-concave setting. In
these general nonconvex settings, it has been shown that GDA converges to a certain stationary point
at a sublinear rate, i.e., kG(xt)k ≤ t-α for some α > 0, where G(xt) corresponds to a certain
notion of gradient. Although such a gradient convergence result implies the stability of the algorithm,
namely, limt→∞ kxt+1 - xt k = 0, it does not guarantee the convergence of the variable sequences
{xt }t , {yt }t generated by GDA. So far, the variable convergence of GDA has not been established
for nonconvex problems, but only under (strongly) convex function geometries that are mentioned
previously Du and Hu (2019); Mokhtari et al. (2020); Zhang and Wang (2020). Therefore, we want
to ask the following fundamental question:
•	Q1: Does GDA have guaranteed variable convergence in nonconvex minimax optimization? If so,
where do they converge to?
In fact, proving the variable convergence of GDA in the nonconvex setting is highly nontrivial due to
the following reasons: 1) the algorithm alternates between a minimization step and a maximization
step; 2) It is well understood that strong global function geometry leads to the convergence of GDA.
However, in general nonconvex setting, the objective functions typically do not have an amenable
global geometry. Instead, they may satisfy different types of local geometries around the critical
points. Hence, it is natural and much desired to exploit the local geometries of functions in analyzing
the convergence of GDA. The Kurdyka-匕OjasieWiCz (K匕)geometry provides a broad characterization
of such local geometries for nonconvex functions.
The Kurdyka-Eojasiewicz (KE) geometry (see Section 2 for details) Bolte et al. (2007; 2014)
parameterizes a broad spectrum of the local nonconvex geometries and has been shoWn to hold for a
broad class of practical functions. Moreover, it also generalizes other global geometries such as strong
convexity and PE geometry. In the existing literature, the KE geometry has been exploited extensively
to analyze the convergence rate of various gradient-based algorithms in nonconvex optimization, e.g.,
gradient descent Attouch and Bolte (2009); Li et al. (2017) and its accelerated version Zhou et al.
(2020) as well as the distributed version Zhou et al. (2016a). Hence, we are highly motivated to study
the convergence rate of variable convergence of GDA in nonconvex minimax optimization under
the KE geometry. In particular, we want to address the following question:
•	Q2: How does the local function geometry captured by the KL parameter affects the variable
convergence rate of GDA?
In this paper, we provide comprehensive answers to these questions. We develop a new analysis
framework to study the variable convergence of GDA in nonconvex-strongly-concave minimax
optimization under the KE geometry. We also characterize the convergence rates of GDA in the full
spectrum of the parameterization of the KE geometry.
1.1	Our contributions
We consider the following regularized nonconvex-strongly-concave minimax optimization problem
xm∈Rinm my∈aYx f(x,y)+g(x)-h(y),	(P)
where f is a differentiable and nonconvex-strongly-concave function, g is a general nonconvex
regularizer and h is a convex regularizer. Both g and h can be possibly nonsmooth. To solve
the above regularized minimax problem, we study a proximal-GDA algorithm that leverages the
forward-backward splitting update Lions and Mercier (1979); Attouch et al. (2013).
We study the variable convergence property of proximal-GDA in solving the minimax problem
(P). Specifically, we show that proximal-GDA admits a novel Lyapunov function H(x, y) (see
Proposition 2), which is monotonically decreasing along the trajectory of proximal GDA, i.e.,
H(xt+1, yt+1) < H(xt, yt). Based on the monotonicity of this Lyapunov function, we show that
every limit point of the variable sequences generated by proximal-GDA is a critical point of the
objective function.
Moreover, by exploiting the ubiquitous KE geometry of the Lyapunov function, we prove that the
entire variable sequence of proximal-GDA has a unique limit point, or equivalently speaking, it
2
Published as a conference paper at ICLR 2021
converges to a certain critical point x*,i.e., Xt → x*,yt → y*(x*) (see the definition of y* in Section
2). To the best of our knowledge, this is the first variable convergence result of GDA-type algorithms
in nonconvex minimax optimization.
Furthermore, we characterize the asymptotic convergence rates of both the variable sequences and
the function values of PrOximaI-GDA in different parameterization regimes of the KE geometry.
Depending on the value of the KE parameter θ, We show that PrOximal-GDA achieves different
types of convergence rates ranging from sublinear convergence up to finite-step convergence, as we
summarize in Table 1 below.
Table 1: Convergence rates of proximal-GDA under different parameterizations of KE geometry.
Note that t0 denotes a sufficiently large positive integer.
KE parameter	Function value convergence rate	Variable convergence rate
θ=1	Finite-step convergence	Finite-step convergence
θ ∈(2, I)	O(exp ( - [2(1 - θ)]t0-t)) Super-linear convergence	O(exp ( - [2(1 - θ)]t0-t)) Super-linear convergence
θ = 2	O((1 + ρ)t0-t),ρ> 0 Linear convergence	O((min {2,1 + ρ})(t0-t"2),ρ > 0 Linear convergence
θ ∈(0,2)	O((t - to)- 1-12θ) Sub-linear convergence	O((t - to)- 1-θ2θ) Sub-linear convergence
1.2	Related work
Deterministic GDA algorithms: Yang et al. (2020) studied an alternating gradient descent-ascent
(AGDA) algorithm in which the gradient ascent step uses the current variable xt+1 instead of xt .
Bot and Bohm (2020) extended the AGDA algorithm to an alternating proximal-GDA (APGDA)
algorithm for a regularized minimax optimization. Xu et al. (2020b) studied an alternating gradient
projection algorithm which applies `2 regularizer to the local objective function of GDA followed
by projection onto the constraint sets. Daskalakis and Panageas (2018); Mokhtari et al. (2020);
Zhang and Wang (2020) analyzed optimistic gradient descent-ascent (OGDA) which applies negative
momentum to accelerate GDA. Mokhtari et al. (2020) also studied an extra-gradient algorithm
which applies two-step GDA in each iteration. Nouiehed et al. (2019) studied multi-step GDA
where multiple gradient ascent steps are performed, and they also studied the momentum-accelerated
version. Cherukuri et al. (2017); Daskalakis and Panageas (2018); Jin et al. (2020) studied GDA in
continuous time dynamics using differential equations. Adolphs et al. (2019) analyzed a second-order
variant of the GDA algorithm.
Stochastic GDA algorithms: Lin et al. (2020); Yang et al. (2020); Bot and Bohm (2020) analyzed
stochastic GDA, stochastic AGDA and stochastic APGDA, which are direct extensions of GDA,
AGDA and APGDA to the stochastic setting respectively. Variance reduction techniques have been
applied to stochastic minimax optimization, including SVRG-based Du and Hu (2019); Yang et al.
(2020), SPIDER-based Xu et al. (2020a), STORM Qiu et al. (2020) and its gradient free version
Huang et al. (2020). Xie et al. (2020) studied the complexity lower bound of first-order stochastic
algorithms for finite-sum minimax problem.
K匕 geometry: The KE geometry was defined in Bolte et al. (2007). The KE geometry has been
exploited to study the convergence of various first-order algorithms for solving minimization problems,
including gradient descent Attouch and Bolte (2009), alternating gradient descent Bolte et al. (2014),
distributed gradient descent Zhou et al. (2016a; 2018a), accelerated gradient descent Li et al. (2017).
It has also been exploited to study the convergence of second-order algorithms such as Newton’s
method Noll and Rondepierre (2013); Frankel et al. (2015) and cubic regularization method Zhou
et al. (2018b).
3
Published as a conference paper at ICLR 2021
2 Problem Formulation and K匕 Geometry
In this section, we introduce the problem formulation, technical assumptions and the Kurdyka-
Eojasiewicz (KE) geometry. We consider the following regularized minimax optimization problem.
xm∈Rinm my∈aYx f(x,y)+g(x) -h(y),	(P)
where f : Rm × Rn → R is a differentiable and nonconvex-strongly-concave loss function, Y ⊂ Rn
is a compact and convex set, and g, h are the regularizers that are possibly non-smooth. In particular,
define Φ(x) := maxy∈Y f(x, y) - h(y), and then the problem (P) is equivalent to the minimization
problem minx∈Rm Φ(x) + g(x).
Throughout the paper, we adopt the following standard assumptions on the problem (P).
Assumption 1. The objective function of the problem (P) satisfies:
1.	Function f (∙, ∙) is L-smooth andfunCtion f (x, ∙) is μ-strongly concave;
2.	Function (Φ + g)(x) is bounded below, i.e., inf x∈Rm (Φ + g)(x) > -∞;
3.	For any α ∈ R, the sub-level set {x : (Φ + g)(x) ≤ α} is compact;
4.	Function h is proper and convex, and function g is proper and lower semi-continuous.
To elaborate, item 1 considers the class of nonconvex-strongly-concave functions f that has been
widely studied in the existing literature Lin et al. (2020); Jin et al. (2020); Xu et al. (2020b;a); Lu
et al. (2020). Items 2 and 3 guarantee that the minimax problem (P) has at least one solution, and
the variable sequences generated by the proximal-GDA algorithm (See Algorithm 1) are bounded.
Item 4 requires the regularizer h to be convex (possibly non-smooth), which includes many norm-
based popular regularizers such as `p (p ≥ 1), elastic net, nuclear norm, spectral norm, etc. on the
other hand, the other regularizer g can be nonconvex but lower semi-continuous, which includes all
the aforementioned convex regularizers, `p (0 ≤ p < 1), Schatten-p norm, rank, etc. Hence, our
formulation of the problem (P) covers a rich class of nonconvex objective functions and regularizers
and is more general than the existing nonconvex minimax formulation in Lin et al. (2020), which
does not consider any regularizer.
Remark 1. We note that the strong concavity of f (x, ∙) in item 1 can be relaxed to concavity, provided
that the regularizer h(y) is μ-StrOngIy convex. In this case, we can add _2 ∣∣yk2 to both f (x, y) and
h(y) such that Assumption 1 still holds. For simplicity, we will omit the discussion on this case.
By strong concavity of f (x, ∙), it is clear that the mapping y*(x) := argmaxy∈γ f (x, y) — h(y)
is uniquely defined for every X ∈ Rm. In particular, if x* is the desired minimizer of Φ(x), then
(x*, y* (x*)) is the desired solution of the minimax problem (P).
Next, we present some important properties regarding the function Φ(x) and the mapping y*(x). The
following proposition from Bot and Bohm (2020) generalizes the Lemma 4.3 of Lin et al. (2020) to
the regularized setting. The proof can be found in Appendix A. Throughout, we denote K = L∕μ as
the condition number and denote Vif (x, y), V2f (x, y) as the gradients with respect to the first and
the second input argument, respectively. For example, with this notation, Vf(x, y*(χ)) denotes the
gradient of f(x, y*(x)) with respect to only the first input argument x, and the x in the second input
argument y* (x) is treated as a constant.
Proposition 1 (Lipschitz continuity of y* (x) and VΦ(x)). Let Assumption 1 hold. Then, the mapping
y*(x) and the function Φ(x) satisfy
1.	Mapping y* (x) is κ-Lipschitz continuous;
2.	Function Φ(x) is L(1 + κ)-smooth with VΦ(x) = V1f(x, y*(x)).
As an intuitive explanation of Proposition 1, since the function f(x, y) - h(y) is L-smooth with
respect to x, both the maximizer y*(x) and the corresponding maximum function value Φ(x) should
not change substantially with regard to a small change ofx.
Recall that the minimax problem (P) is equivalent to the standard minimization problem
minx∈Rm Φ(x) + g(x), which, according to item 2 of Proposition 1, includes a smooth nonconvex
function Φ(x) and a lower semi-continuous regularizer g(x). Hence, we can define the optimiza-
tion goal of the minimax problem (P) as finding a critical point x* of the nonconvex function
Φ(x) + g(x) that satisfies the necessary optimality condition 0 ∈ ∂(Φ + g)(x*) for minimizing
nonconvex functions. Here, ∂ denotes the notion of subdifferential as we elaborate below.
4
Published as a conference paper at ICLR 2021
Definition 1. (Subdifferential and critical point, RockafeUarand Wets (2009)) The Frechet Subdifer-
ential ∂h of function h at x ∈ dom h is the set of u ∈ Rd defined as
bh(x) := nu : liminf h(Z)-h(X)- UI(Z -X) ≥ 0o,
z6=x,z→x	kz - xk
and the limiting subdifferential ∂h at X ∈ dom h is the graphical closure of ∂h defined as:
∂h(X) := {u : ∃Xk → X, h(Xk) → h(X), uk ∈ ∂ h(Xk), uk → u}.
The set of critical points of h is defined as crit h := {X : 0 ∈ ∂h(X)}.
Throughout, we refer to the limiting subdifferential as subdifferential. We note that subdifferential
is a generalization of gradient (when h is differentiable) and subgradient (when h is convex) to the
nonconvex setting. In particular, any local minimizer of h must be a critical point.
Next, We introduce the Kurdyka-Eojasiewicz (KE) geometry of a function h. Throughout, the
point-to-set distance is denoted as distn(χ) := infu∈ω IlX - u∣∣.
Definition 2 (KE geometry, Bolte et al. (2014)). A proper and lower semi-continuous function h is
said to have the KL geometry iffor every compact set Ω ⊂ domh on which h takes a constant value
hΩ ∈ R, thereexist ε,λ > 0 such that for all X ∈ Ω and all X ∈ {z ∈ Rm : distn(z) < ε,hΩ <
h(z) < hΩ + λ}, the following condition holds:
夕0 (h(X)- hn) ∙ dist∂h(x)(0) ≥ 1,	(1)
where 夕0 is the derivative offunction 夕:[0, λ) → R+, which takes theform 夕(t) = Ctθ for certain
universal constant c > 0 and KL parameter θ ∈ (0, 1].
The KE geometry characterizes the local geometry of a nonconvex function around the set of critical
points. To explain, consider the case where h is a differentiable function so that ∂h(∕) = Vh(X).
Then, the KE inequality in eq. (1) becomes h(∕) - hΩ ≤ O(∣Vh(X)k 1-θ), which generalizes the
Polyak-Eojasiewicz (PL) condition h(∕) - hΩ ≤ O(∣Vh(X)k2) Eojasiewicz (1963); Karimi et al.
(2016) (i.e., KE parameter θ = 1). Moreover, the KE geometry has been shown to hold for a
large class of functions including sub-analytic functions, logarithm and exponential functions and
semi-algebraic functions. These function classes cover most of the nonconvex objective functions
encountered in practical machine learning applications Zhou et al. (2016b); Yue et al. (2018); Zhou
and Liang (2017); Zhou et al. (2018b).
The KE geometry has been exploited extensively to analyze the convergence of various first-order
algorithms, e.g., gradient descent Attouch and Bolte (2009); Li et al. (2017), alternating minimization
Bolte et al. (2014) and distributed gradient methods Zhou et al. (2016a). It has also been exploited to
study the convergence of second-order algorithms such cubic regularization Zhou et al. (2018b). In
these works, it has been shown that the variable sequences generated by these algorithms converge to
a desired critical point in nonconvex optimization, and the convergence rates critically depend on
the parameterization θ of the KE geometry. In the subsequent sections, we provide a comprehensive
understanding of the convergence and convergence rate of proximal-GDA under the KE geometry.
3 Proximal-GDA and Global Convergence Analysis
In this section, we study the following proximal-GDA algorithm that leverages the forward-backward
splitting updates Lions and Mercier (1979); Attouch et al. (2013) to solve the regularized minimax
problem (P) and analyze its global convergence properties. In particular, the proximal-GDA algorithm
is a generalization of the GDA Du and HU (2019) and projected GDA NediC and Ozdaglar (2009)
algorithms. The algorithm update rule is specified in Algorithm 1, where the two proximal gradient
steps are formally defined as
ProXnxg(Xt - ηχVιf(Xt,yt)) ：∈ argmin {g(u) + *Ik
ProXnyh (yt + ηy V2f (Xt,yt)) := argmin {h(v) + ɪ∣∣
v∈Y	2ηy
u - Xt + ηxV1f(Xt,yt)I2
v -yt - ηyV2f(Xt,yt)I2
,
o,
(2)
(3)
5
Published as a conference paper at ICLR 2021
Algorithm 1 Proximal-GDA
Input: Initialization xo, yo, learning rates ηχ,ηy.
for t = 0, 1,2, . . .,T - 1 do
xt+1 ∈ proxηxg(xt - ηχJf(xt ,yt)),
yt+ι =proχηy h(yt + ηy Sf (Xt ,y。).
end
Output: xT , yT .
Recall that our goal is to obtain a critical point of the minimization problem minx∈Rm Φ(x) + g(x).
Unlike the gradient descent algorithm which generates a sequence of monotonically decreasing
function values, the function value (Φ + g)(xk) along the variable sequence generated by proximal-
GDA is generally oscillating due to the alternation between the gradient descent and gradient ascent
steps. Hence, it seems that proximal-GDA is less stable than gradient descent. However, our next
result shows that, for the problem (P), the proximal-GDA admits a special Lyapunov function that
monotonically decreases in the optimization process. The proof of Proposition 2 is in Appendix B.
Proposition 2. Let Assumption 1 hold and define the Lyapunov function H(z) := Φ(x) + g(x) +
(1 — 4κ2 )∣∣y — y*(x)k2 with Z := (x,y). Choose the learning rates such that & ≤ ^5+3)2，ηy ≤ L.
Then, the variables zt = (xt, yt) generated by proximal-GDA satisfy, for all t = 0, 1, 2, ...
H(Zt+1) ≤ H(Zt)	-	2kxt+ι -	xtk2 —	-~2(kyt+ι -	y*(xt+1)k2 +	kyt	-	y*(Xt)k2).	(4)
4κ
We first explain how this Lyapunov function is introduced in the proof. By eq. (19) in the supplemen-
tary material, we established a recursive inequality on the objective function (Φ + g)(Xt+1). One
can see that the right hand side of eq. (19) contains a negative term -kXt+1 - Xtk2 and an undesired
positive term ∣∣y*(xt) - ytk2. Hence, the objective function (Φ + g)(xt+ι) may be oscillating and
cannot serve as a proper Lyapunov function. In the subsequent analysis, we break this positive term
into a difference of two terms ∣∣y*(χt) - yt∣2 - ∣∣y*(xt+ι) - yt+11∣2, by leveraging the update of yt+1
for solving the strongly concave maximization problem. After proper rearranging, this difference
term contributes to the quadratic term in the Lyapunov function.
We note that the Lyapunov function H(Z) is the objective function Φ(X) + g(X) regularized by the
additional quadratic term (1 -+)∣y - y*(χ)∣2, and such a Lyapunov function clearly characterizes
our optimization goal. To elaborate, consider a desired case where the sequence Xt converges to
a certain critical point x* and the sequence yt converges to the corresponding point y*(x*). In
this case, it can be seen that the Lyapunov function H(Zt) converges to the desired function value
(Φ + g)(x*). Hence, solving the minimax problem (P) is equivalent to minimizing the Lyapunov
function. More importantly, Proposition 2 shows that the Lyapunov function value sequence {H(Zt)}t
is monotonically decreasing in the optimization process of proximal-GDA, implying that the algorithm
continuously makes optimization progress. We also note that the coefficient (1 -击)in the Lyapunov
function is chosen in a way so that eq. (4) can be proven to be strictly decreasing. This monotonic
property is the core of our analysis of proximal-GDA.
Based on Proposition 2, we obtain the following asymptotic properties of the variable sequences
generated by proximal-GDA. The proof can be found in Appendix C.
Corollary 1. Based on Proposition 2, the sequences {xt, yt}t generated by proximal-GDA satisfy
lim ∣xt+1 - xt ∣ = 0,
t→∞
lim ∣yt+1 - yt∣ = 0, lim ∣yt - y*(xt)∣ = 0.
t→∞	t→∞
The above result shows that the variable sequences generated by proximal-GDA in solving the
problem (P) are asymptotically stable. In particular, the last two equations show that yt asymptotically
approaches the corresponding maximizer y*(xt) of the objective function f(xt, y) + g(xt) - h(y).
Hence, if xt converges to a certain critical point, yt will converge to the corresponding maximizer.
Discussion: We note that the monotonicity property in Proposition 2 further implies the convergence
rate result min0≤k≤t ∣xk+1 - xk∣ ≤ O(t-1/2) (by telescoping over t). When there is no regularizer,
6
Published as a conference paper at ICLR 2021
this convergence rate result can be shown to further imply that min°≤k≤t ∣∣VΦ(χk)k ≤ O(t-1/2),
which reduces to the Theorem 4.4 of Lin et al. (2020). However, such a convergence rate result
does not imply the convergence of the variable sequences {xt}t , {yt }t. To explain, we can apply
the convergence rate result ∣xt+1 - xt∣ ≤ O(t-1/2) to bound the trajectory norm as ∣xT ∣ ≤
∣x0∣ + PtT=-01 ∣xt+1 - xt∣ ≈ ：√T, which diverges to +∞ as T → ∞. Therefore, such a type of
convergence rate does not even imply the boundedness of the trajectory. In this paper, our focus is to
establish the convergence of the variable sequences generated by proximal-GDA.
All the results in Corollary 1 imply that the alternating proximal gradient descent & ascent updates of
proximal-GDA can achieve stationary points, which we show below to be critical points.
Theorem 1 (Global convergence). Let Assumption 1 hold and choose the learning rates ηx ≤
k3(l+3)2，ηy ≤ L. Then，Proximal-GDA satisfies thefollowingproperties.
1.	ThefUnction value SeqUence {(Φ + g)(xt)}t converges to a finite limit H * > 一∞;
2.	The sequences {xt}t, {yt}t are bounded and have compact sets of limit points. Moreover, (Φ +
g)(x* ) ≡ H* for any limit point x* of{xt}t;
3.	Every limit point of{xt}t is a critical point of (Φ + g)(x).
The proof of Theorem 1 is presented in Appendix D. The above theorem establishes the global
convergence property of proximal-GDA. Specifically, item 1 shows that the function value sequence
{(Φ + g)(xt)}t converges to a finite limit H*, which is also the limit of the Lyapunov function
sequence {H(zt)}t. Moreover, items 2 & 3 further show that all the converging subsequences of
{xt }t converge to critical points of the problem, at which the function Φ + g achieves the constant
value H* . These results show that proximal-GDA can properly find critical points of the minimax
problem (P). Furthermore, based on these results, the variable sequences generated by proximal-GDA
are guaranteed to enter a local parameter region where the KUrdyka-七OjaSieWiCz geometry holds,
which we exploit in the next section to establish stronger convergence results of the algorithm.
4	Variable Convergence of PROXIMAL-GDA under K匕 Geometry
We note that Theorem 1 only shows that every limit point of {xt}t is a critical point, and the sequences
{xt, yt}t may not necessarily be convergent. In this section, We exploit the local KL geometry of the
Lyapunov function to formally prove the convergence of these sequences. Throughout this section,
we adopt the following assumption.
Assumption 2. Regarding the mapping y* (x), the function ∣y*(x) 一 y∣2 has a non-empty subdiffer-
ential, i.e., ∂χ(∣y*(x) - y∣2) = 0.
Note that in many practical scenarios y* (x) is sub-differentiable. In addition, Assumption 2 ensures
the sub-differentiability of the Lyapunov function H (z) := Φ(x) + g(x) + (1 一 击)ky 一 y* (x)∣2.
We obtain the following variable convergence result of proximal-GDA under the KL geometry. The
proof is presented in Appendix E.
Theorem 2 (Variable convergence). LetAssumption 1 & 2 hold and assume that H has the KL ge-
ometry. Choose the learning rates ηx ≤ ^5+3)2 and ηy ≤ L. Then, the SeqUence {(xt,yt)}t
generated by proximal-GDA converges to a certain critical point (x*, y* (x*)) of(Φ + g)(x), i.e.,
xt →t x*,	yt →t y* (x*).
Theorem 2 formally shows that proximal-GDA is guaranteed to converge to a certain critical point
(x*, y*(x*)) of the minimax problem (P), provided that the Lyapunov function belongs to the large
class of KL functions. To the best of our knowledge, this is the first variable convergence result of
GDA-type algorithms in nonconvex minimax optimization. The proof logic of Theorem 2 can be
summarized as the following two key steps.
Step 1: By leveraging the monotonicity property of the Lyapunov function in Proposition 2, we
first show that the variable sequences of proximal-GDA eventually enter a local region where the
KL geometry holds;
Step 2: Then, combining the KL inequality in eq. (1) and the monotonicity property of the Lyapunov
function in eq. (4), we show that the variable sequences of proximal-GDA are Cauchy sequences and
hence converge to a certain critical point.
7
Published as a conference paper at ICLR 2021
5	Convergence Rate of PROXIMAL-GDA under K匕 Geometry
In this section, We exploit the parameterization of the KE geometry to establish various types of
asymptotic convergence rates of proximal-GDA.
We obtain the folloWing asymptotic convergence rates of proximal-GDA under different parameter
regimes of the KE geometry. The proof is presented in Appendix F. In the sequel, We denote t0 as a
sufficiently large positive integer, denote c > 0 as the constant in Definition 2 and also define
M := max {g('~ + (L + 4κ1 2 3 4)(1 + K)) ,4κ2(L + 4κ)20.	(5)
Theorem 3 (Funtion value convergence rate). Under the same conditions as those of Theorem 2, the
Lyapunovfunction value Sequence {H (zt)}t converges to the limit H * at the following rates.
1.	IfKL geometry holds with θ = 1, then H (Zt) J H * within finite number of iterations;
2.	IfKL geometry holds with θ ∈ (2, 1), then H (Zt) J H * Super-linearly as
H (Zt)- H * ≤ (2Mc2)-2θ-1 exp ( - (2(11-^ )'-t) ∀t ≥ to；	⑹
3.	IfKL geometry holds with θ = 2, then H (Zt) J H * linearly as
H (Zt)- H * ≤ (l + 2M2 )t0-t(H (zto) — H *), ∀t ≥ to；	⑺
4.	IfKL geometry holds with θ ∈ (0, 2), then H (Zt) J H * sub-linearly as
H(Zt)- H * ≤ [C (t - to)]— 1—2θ, ∀t ≥ to.	(8)
where C = min [^Mi2, d-0(I-2θ)(1 - 2-(1-物)]> 0.
It can be seen from the above theorem that the convergence rate of the Lyapunov function of
proximal-GDA is determined by the KE parameter θ. A larger θ implies that the local geometry
of H is ‘sharper’, and hence the corresponding convergence rate is orderWise faster. In particular,
the algorithm converges at a linear rate when the KE geometry holds with θ = 2 (see the item
3), Which is a generalization of the Polyak-EojasieWicz (PL) geometry. As a comparison, in the
existing analysis of GDA, such a linear convergence result is established under stronger geometries,
e.g., convex-strongly-concave Du and Hu (2019), strongly-convex-strongly-concave Mokhtari et al.
(2020); Zhang and Wang (2020) and two-sided PL condition Yang et al. (2020). In summary, the
above theorem provides a full characterization of the fast convergence rates of proximal-GDA in the
full spectrum of the KE geometry.
Moreover, we also obtain the following asymptotic convergence rates of the variable sequences that
are generated by proximal-GDA under different parameterization of the KE geometry. The proof is
presented in Appendix G.
Theorem 4 (Variable convergence rate). Under the same conditions as those of Theorem 2, the
sequences {xt, yt}t converge to their limits x*, y*(x*) respectively at the following rates.
1. If KL geometry holds with θ = 1, then (xt, yt) → (x*, y*(x*)) within finite number of itera-
tions;
2. IfKL geometry holds with θ ∈ (1, 1), then (xt,yt) → (x*,y*(x*)) SUper-Iinearly as
max {kxt-x*k,kyt-y*(x*)k} ≤ o( exp (-(2(1) θ)广0)), ∀t ≥ to；	(9)
3. IfKL geometry holds with θ = 2, then (xt, yt) → (x*,y*(x*)) linearly as
max {kxt- x*k,kyt- y*(x*)k} ≤o((min {2, 1 + 2M2})(0 ” ),	∀t ≥ to；(⑼
4. IfKL geometry holds with θ ∈ (0, ɪ), then (xt, yt) → (x*,y*(x*)) sub-linearly as
max {kxt - x*k, kyt - y*(x*)k} ≤θ((t - to)-T-2), ∀t ≥ to.	(11)
8
Published as a conference paper at ICLR 2021
To the best of our knowledge, this is the first characterization of the variable convergence rates of
ProXimal-GDA in the full spectrum of the K匕 geometry. It can be seen that, similar to the convergence
rate results of the function value sequence, the convergence rate of the variable sequences is also
affected by the parameterization of the KE geometry.
6 Conclusion
In this paper, we develop a new analysis framework for the proXimal-GDA algorithm in nonconveX-
strongly-concave optimization. Our key observation is that proXimal-GDA has a intrinsic Lyapunov
function that monotonically decreases in the minimaX optimization process. Such a property demon-
strates the stability of the algorithm. Moreover, we establish the formal variable convergence of
proXimal-GDA to a critical point of the objective function under the ubiquitous KE geometry. Our
results fully characterize the impact of the parameterization of the KE geometry on the convergence
rate of the algorithm. In the future study, we will leverage such an analysis framework to eXplore the
convergence of stochastic GDA algorithms and their variance-reduced variants.
Acknowledgement
The work of T. Xu and Y. Liang was supported partially by the U.S. National Science Foundation
under the grants CCF-1900145 and CCF-1909291.
References
Adolphs, L., Daneshmand, H., Lucchi, A., and Hofmann, T. (2019). Local saddle point optimization:
A curvature eXploitation approach. In Proc. International Conference on Artificial Intelligence and
Statistics (AISTATS), pages 486-495.
Attouch, H. and Bolte, J. (2009). On the convergence of the proXimal algorithm for nonsmooth
functions involving analytic features. Mathematical Programming, 116(1-2):5-16.
Attouch, H., Bolte, J., and Svaiter, B. F. (2013). Convergence of descent methods for semi-algebraic
and tame problems: proXimal algorithms, forward-backward splitting, and regularized gauss-seidel
methods. Mathematical Programming, 137(1-2):91-129.
Bernhard, P. and Rapaport, A. (1995). On a theorem of danskin with an application to a theorem of
von neumann-sion. Nonlinear Analysis: Theory, Methods & Applications, 24(8):1163-1181.
Bolte, J., Daniilidis, A., and Lewis, A. (2007). The Eojasiewicz inequality for nonsmooth subanalytic
functions with applications to subgradient dynamical systems. SIAM Journal on Optimization,
17:1205-1223.
Bolte, J., Sabach, S., and Teboulle, M. (2014). ProXimal alternating linearized minimization for
nonconveX and nonsmooth problems. Mathematical Programming, 146(1-2):459-494.
Bot, R. I. and Bohm, A. (2020). Alternating proximal-gradient steps for (stochastic) nonconvex-
concave minimaX problems. ArXiv:2007.13605.
Cherukuri, A., Gharesifard, B., and Cortes, J. (2017). Saddle-point dynamics: conditions for
asymptotic stability of saddle points. SIAM Journal on Control and Optimization, 55(1):486-511.
Daskalakis, C. and Panageas, I. (2018). The limit points of (optimistic) gradient descent in min-max
optimization. In Proc. Advances in Neural Information Processing Systems (NeurIPS), pages
9236-9246.
Du, S. S. and Hu, W. (2019). Linear convergence of the primal-dual gradient method for convex-
concave saddle point problems without strong convexity. In Proc. International Conference on
Artificial Intelligence and Statistics (AISTATS), pages 196-205.
Ferreira, M. A. M., Andrade, M., Matos, M. C. P., Filipe, J. A., and Coelho, M. P. (2012). Minimax
theorem and nash equilibrium.
9
Published as a conference paper at ICLR 2021
Frankel, P., Garrigos, G., and Peypouquet, J. (2015). Splitting methods with variable metric for
KUrdyka-EojasieWicz functions and general convergence rates. Journal OfOptimization Theory
andAPPlications ,165(3):874-900.
GoodfelloW, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A.,
and Bengio, Y. (2014). Generative adversarial nets. In Proc. Advances in Neural Information
Processing Systems (NeurIPS), pages 2672-2680.
Ho, J. and Ermon, S. (2016). Generative adversarial imitation learning. In Proc. Advances in Neural
Information Processing Systems (NeurIPS), pages 4565-4573.
Huang, F., Gao, S., Pei, J., and Huang, H. (2020). Accelerated zeroth-order momentum methods
from mini to minimax optimization. ArXiv:2008.08170.
Jin, C., Netrapalli, P., and Jordan, M. I. (2020). What is local optimality in nonconvex-nonconcave
minimax optimization?
Karimi, H., Nutini, J., and Schmidt, M. (2016). Linear Convergence of Gradient and Proximal-
Gradient Methods Under the Polyak-Lojasiewicz Condition, pages 795-811.
Kruger, A. Y. (2003). On fr6chet subdifferentials. Journal OfMathematical Sciences,116(3):3325—
3358.
Li, Q., Zhou, Y., Liang, Y., and Varshney, P. K. (2017). Convergence analysis of proximal gradient
With momentum for nonconvex optimization. In Proc. International Conference on Machine
Learning (ICML), volume 70, pages 2111-2119.
Lin, T., Jin, C., and Jordan, M. I. (2020). On gradient descent ascent for nonconvex-concave minimax
problems.
Lions, P.-L. and Mercier, B. (1979). Splitting algorithms for the sum of tWo nonlinear operators.
SIAM Journal on Numerical Analysis, 16(6):964-979.
EojasieWicz, S. (1963). A topological property of real analytic subsets. Coll. du CNRS, Les equations
aux derivees Partielles, page 87-89.
Lu, S., Tsaknakis, I., Hong, M., and Chen, Y. (2020). Hybrid block successive approximation for
one-sided non-convex min-max problems: algorithms and applications. IEEE Transactions on
Signal Processing.
Mokhtari, A., Ozdaglar, A., and Pattathil, S. (2020). A unified analysis of extra-gradient and optimistic
gradient methods for saddle point problems: Proximal point approach. In Proc. International
Conference on Artificial Intelligence and Statistics (AISTATS), pages 1497-1507.
Nedic, A. and Ozdaglar, A. (2009). Subgradient methods for saddle-point problems. Journal of
oPtimization theory and aPPlications, 142(1):205-228.
Neumann, J. v. (1928). Zur theorie der gesellschaftsspiele. Mathematische annalen, 100(1):295-320.
Noll, D. and Rondepierre, A. (2013). Convergence of linesearch and trust-region methods using
the Kurdyka-EojasieWicz inequality. In Proc. ComPutational and Analytical Mathematics, pages
593-611.
Nouiehed, M., Sanjabi, M., Huang, T., Lee, J. D., and Razaviyayn, M. (2019). Solving a class of
non-convex min-max games using iterative first order methods. In Proc. Advances in Neural
Information Processing Systems (NeurIPS), pages 14934-14942.
Qiu, S., Yang, Z., Wei, X., Ye, J., and Wang, Z. (2020). Single-timescale stochastic nonconvex-
concave optimization for smooth nonlinear td learning. ArXiv:2008.10103.
Robinson, J. (1951). An iterative method of solving a game. Annals of mathematics, 54(2):296-301.
Rockafellar, R. T. (1970). Convex analysis. Number 28. Princeton university press.
10
Published as a conference paper at ICLR 2021
Rockafellar, R. T. and Wets, R. J.-B. (2009). Variational analysis, volume 317. Springer Science &
Business Media.
Sinha, A., Namkoong, H., and Duchi, J. C. (2017). Certifying some distributional robustness with
principled adversarial training. In Proc. International Conference on Learning Representations
(ICLR).
Song, J., Ren, H., Sadigh, D., and Ermon, S. (2018). Multi-agent generative adversarial imitation
learning. In Proc. Advances in Neural Information Processing Systems (NeurIPS), pages 7461-
7472.
Xie, G., Luo, L., Lian, Y., and Zhang, Z. (2020). Lower complexity bounds for finite-sum convex-
concave minimax optimization problems.
Xu, T., Wang, Z., Liang, Y., and Poor, H. V. (2020a). Enhanced first and zeroth order variance
reduced algorithms for min-max optimization. ArXiv:2006.09361.
Xu, Z., Zhang, H., Xu, Y., and Lan, G. (2020b). A unified single-loop alternating gradient projection
algorithm for nonconvex-concave and convex-nonconcave minimax problems. ArXiv:2006.02032.
Yang, J., Kiyavash, N., and He, N. (2020). Global convergence and variance reduction for a class of
nonconvex-nonconcave minimax problems.
Yue, M., Zhou, Z., and So, M. (2018). On the Quadratic Convergence of the Cubic Regularization
Method under a Local Error Bound Condition. ArXiv:1801.09387v1.
Zhang, G. and Wang, Y. (2020). On the suboptimality of negative momentum for minimax optimiza-
tion. ArXiv:2008.07459.
Zhou, Y. and Liang, Y. (2017). Characterization of Gradient Dominance and Regularity Conditions
for Neural Networks. ArXiv:1710.06910v2.
Zhou, Y., Liang, Y., Yu, Y., Dai, W., and Xing, E. P. (2018a). Distributed Proximal Gradient Algorithm
for Partially Asynchronous Computer Clusters. Journal of Machine Learning Research (JMLR),
19(19):1-32.
Zhou, Y., Wang, Z., Ji, K., Liang, Y., and Tarokh, V. (2020). Proximal gradient algorithm with
momentum and flexible parameter restart for nonconvex optimization. In Proc. International Joint
Conference on Artificial Intelligence, IJCAI-20, pages 1445-1451.
Zhou, Y., Wang, Z., and Liang, Y. (2018b). Convergence of cubic regularization for nonconvex
optimization under kl property. In Proc. Advances in Neural Information Processing Systems
(NeurIPS), pages 3760-3769.
Zhou, Y., Yu, Y., Dai, W., Liang, Y., and Xing, P. (2016a). On convergence of model parallel proximal
gradient algorithm for stale synchronous parallel system. In Proc. International Conference on
Artificial Intelligence and Statistics (AISTATS, volume 51, pages 713-722.
Zhou, Y., Zhang, H., and Liang, Y. (2016b). Geometrical properties and accelerated gradient solvers
of non-convex phase retrieval. In Proc. 54th Annual Allerton Conference on Communication,
Control, and Computing (Allerton), pages 331-335.
11
Published as a conference paper at ICLR 2021
Supplementary material
A Proof of Proposition 1
Proposition 1 (Lipschitz continuity of y* (x) and VΦ(x)). LetAssumPtion 1 hold. Then, the mapping
y*(x) and thefunction Φ(x) satisfy
1.	Mapping y*(x) is K-Lipschitz continuous;
2.	Function Φ(x) is L(1 + κ)-smooth with VΦ(x) = Vf (x, y*(x)).
Proof. We first prove item 1. Since f(x, y) is strongly concave in y for every x and h(y) is convex,
the mapping y*(x) = argmaxy∈γ f (x, y) - h(y) is uniquely defined. We first show that y*(x) is a
Lipschitz mapping. Consider two arbitrary points x1,x2. The optimality conditions of y*(xι) and
y* (x2) imply that
hy - y*(x1), V2f(x1, y*(x1)) - u1i ≤ 0,	∀y ∈ Y, u1 ∈ ∂h(y*(x1)),	(12)
hy - y*(x2), V2f(x2,y*(x2)) - u2i ≤ 0,	∀y ∈ Y, u2 ∈ ∂h(y*(x2)).	(13)
Setting y = y* (x2) in eq. (12), y = y* (x1) in eq. (13) and summing up the two inequalities, we
obtain that
hy*(x2) - y*(x1), V2f(x1, y*(x1)) - V2f (x2, y*(x2)) - u1 +u2i ≤ 0.	(14)
Since ∂h is a monotone operator (by convexity), we know that hu2 - u1, y*(x2) - y* (x1)i ≥ 0.
Hence, the above inequality further implies that
hy*(x2) - y*(x1), V2f(x1, y*(x1)) - V2f (x2, y*(x2))i ≤ 0.	(15)
Next, by strong concavity of f (xi, ∙), we have that
hy*(χ2) - y*(χι), V2f (χ1,y*(χ2)) -V2f (χι,y*(χι))i + μ∣∣y*(χι) - y*(χ2)k2 ≤ 0.	(16)
Adding up the above two inequalities yields that
μky*(χι) - y*(χ2)k2 ≤ hy*(χ2) - y*(XI), V2f(X2,y*(Xz))- V2f(Xι,y*(Xz))i
≤ ky* (x2) -y*(x1)kkV2f(x2,y*(x2)) -V2f(x1,y*(x2))k
≤ Lky*(Xz) -y*(X1)kkXz -X1k.
The above inequality shows that ky*(X1) - y*(Xz)k ≤ κkXz - X1 k, and item 1 is proved.
Next, we will prove item 2.
Consider An = {y*(X) : X ∈ Rm, kXk ≤ n} ⊂ Y. Since h is proper and convex, h(y0) < +∞
for some y0 ∈ Y . Since f is L-smooth, its value is finite everywhere. Hence, for any X ∈ Rm ,
Φ(X) = maxy∈Y f(X, y) - h(y) ≥ f(X,y0) - h(y0) > -∞, so h(y* (X)) = f(X, y* (X)) - Φ(X) <
+∞. Therefore, based on Corollary 10.1.1 of Rockafellar (1970), h(y) is continuous on An and
thus f(X, y) - h(y) is continuous in (X, y) ∈ Rm × An. Also, V1f(X, y) is continuous in (X, y) ∈
Rm × An since f is L-smooth. For any sequence {Xk} such that kXkk ≤ n and y*(Xk) → y ∈ Y,
y = y* (X0) for any limit point X0 of {Xk} (there is at least one such limit point since kXkk ≤ n)
since we have proved that y* is continuous. As kX0 k ≤ n, y ∈ An . Hence, An is closed. As
An is included in bounded Y , An is compact. Therefore, based on the Danskin theorem Bernhard
and Rapaport (1995), the function Φn(X) := arg maxy∈An f(X, y) - h(y) is differntialable with
VΦn(X) = V1f(X, y*(X)). On one hand, Φn(X) ≤ Φ(X) since An ⊂ Y. On the other hand, when
kXk ≤ n, y*(X) ∈ An, so Φ(X) = f(X, y*(X)) - h(y* (X)) ≤ Φn(X). Hence, when kXk ≤ n,
Φ(X) = Φn(X) and thus VΦ(X) = VΦn(X) = V1f(X, y* (X)). Since n can be arbitrarily large,
VΦ(X) = V1f(X, y* (X)) for any X ∈ Rm.
Next, consider any X1 , Xz ∈ Rm, we obtain that
kVΦ(Xz) - VΦ(X1)k =kV1f(Xz, y*(Xz)) - V1f (X1, y*(X1))k
≤LkXz - X1k + Lky*(Xz) - y*(X1)k
≤LkXz - X1k + LκkXz - X1k
=L(1 + κ)kXz -X1k,
which implies that Φ(X) is L(1 + κ)-smooth.
□
12
Published as a conference paper at ICLR 2021
B Proof of Proposition 2
Proposition 2. Let Assumption 1 hold and define the Lyapunov function H(z) := Φ(x) + g(x) +
(1 一 4κ2 )∣∣y — y*(x)k2 with Z := (x,y). Choose the learning rates such that & ≤ ^5+3)2，ηy ≤ L.
Then, the variables zt = (xt, yt) generated by proximal-GDA satisfy, for all t = 0, 1, 2, ...
H(zt+1) ≤ H(Zt) — 2kxt+l — χtk2 — 4K2 (kyt+1 — y*(Xt+1)k2 + kyt — y*(xt)k2).	(4)
Proof. Consider the t-th iteration of proximal-GDA. By smoothness of Φ we obtain that
φ(χt+1) ≤ φ(Xt) + hxt+1 一 xt, Vφ(xt)i +--( ；—，kxt+ι 一 xtk2.	(17)
On the other hand, by the definition of the proximal gradient step of xt, we have
g(xt+1) + W—kxt+1 - Xt + ηxvif (xt,yt)k2 ≤ g(Xt) + W—IInxVIf(Xt,yt)∣2,
2ηx	2ηx
which further simplifies to
g(Xt+1) ≤ g (Xt) 一 7；—kXt+1 - Xtk2 一 hXt+1 - Xt, VIf (Xt, yt)i .	(18)
2ηx
Adding up eq. (17) and eq. (18) yields that
Φ(Xt+1) + g(Xt+1)
≤ φ(x∕+g(Xt)一 (2n—^^^2—)) kXt+i 一 Xtk2+hXt+i 一 Xt, vφ(χt) -VIf(Xt, yt)i
=Φ(Xt) + g(Xt)—(圭—L(1+κ) )kXt+ι — Xtk2 + kXt+1 — XtkkVΦ(Xt) — Vif (Xt, yt)k
=φ(xD	+ g(Xt)	一	(21-	-	L(12+ K))|lXt+i	—	xM2 +	|lXt+i - XtkkVIf(Xt,y*(Xt))	— VIf(Xt,yt)∣∣
≤ φ(χt)	+ g(Xt)	一	(21-	-	L(12+ K))kxt+ι	—	χtk2 +	Lkxt+ι 一 χtk∣∣y*(Xt)	— ytll∙
≤ φ(Xt) + g(Xt) 一	(2n	^^2^~-	2-)	kxt+ι	一	χtIl2 +	2κ2ky*(Xt)	一	ytk2	(19)
Next, consider the term ∣∣y*(xt) — ytk in the above inequality. Note that y*(χt) is the unique
minimizer of the strongly concave function f(Xt, y) — h(y), and yt+1 is obtained by applying one
proximal gradient step on it starting from yt . Hence, by the convergence rate of proximal gradient
ascent algorithm under strong concavity, We conclude that with ny ≤ L,
kyt+i—y*(χt)k2 ≤(1—K-1)kyt—y*(χt)k2∙	(20)
Hence, we further obtain that
ky*(χt+i) —	yt+1∣∣2	≤	(1 + κ-1) kyt+1	— y*(χt)∣∣2	+ (1 +	K)ky*(χt+1) — y*(Xt)k2
≤	(1 一 κ-2)Ilyt 一	y"(χt)∣∣2 +	κ2(1 +	K)IlXt+1 — χt∣∣2.	(21)
Adding eqs. (19) & (21), we obtain
Φ(Xt+1) + g(Xt+1)
≤ φ(Xt)+g(χt) — (2n	幺f 一 人2	κ2(1+K))∣∣χt+1 一 χt∣∣2
+ (1 一 2K2) ky*(Xt) - ytk2 — ky*(χt+1) - yt+1∣∣2
13
Published as a conference paper at ICLR 2021
Rearranging the equation above and recalling the definition of the Lyapunov function
H(z) := Φ(x) + g(x) + (1 - 4K2)ky -y*(χ)∣∣2, We have
H(Zt+1) ≤H(Zt) — (2η	( 2^，—2	κ2(1+K))∣∣xt+ι -Xt∣∣2
-~r~2(ky*(Xt) - ytk2 + lly*(χt+ι) - yt+ιk2)
4κ
When ηx < κ-3 (L + 3)-2, using κ ≥ 1 yields that
1	L(1 + κ)
--------------
2ηx	2
L2K2
2
- κ2(1 + κ)
≥ 2κ3(L + 3)2 - 2(2K)K2 —2— κ2(2K)
=1 k3[(L + 3)2 - 2L - L2 - 4]
=1K3 (4L + 5) > 2
(22)
(23)
As a result, eq. (4) can be concluded by substituting eq. (23) into eq. (22).
□
C Proof of Corollary 1
Corollary 1. Based on Proposition 2, the sequences {Xt, yt}t generated by proximal-GDA satisfy
lim kXt+ι —	Xtk	=	0,	lim	kyt+ι —	ytk	=	0,	lim	kyt	— y*(Xt)k	=	0.
t→∞	t→∞	t→∞
Proof. To prove the first and third items of Corollary 1, summing the inequality of Proposition 2 over
t = 0, 1, ..., T - 1, We obtain that for all T ≥ 1,
T-1	1
X [2kxt+1 - xtk2 + 4K2 (kyt+1 - y*(xt+1 )k2 + kyt - y*(xt)k2)]
t=0
≤ H(Z0)
- H(ZT)
≤ H(Z0) - Φ(XT) +g(XT)
≤ H(zo) 一 inf (Φ(x) + g(x)) < +∞.
x∈Rm
Letting T → ∞, We conclude that
∞
X [2kxt+1 - xtk2 + 4K2 (kyt+1 - y"(xt+l)k2 + kyt - y* (Xt )k2)] < +∞.
Therefore, we must have limt→∞ kXt+ι — Xtk = limt→∞ Ilyt — y*(Xt)k =0.
To prove the second item, note that
eq. (20)	/------------ t
kyt+ι 一 ytk ≤ kyt+ι — y*(Xt)Il + kyt — y*(Xt)Il	≤	(VZr-K-1 + 1)∣∣yt — y*(χt)k → 0.
□
D Proof of Theorem 1
Theorem 1 (Global convergence). Let Assumption 1 hold and choose the learning rates ηx ≤
^(^+3)2, ηy ≤ L. Then, Proximal-GDA satisfies thefollowingproperties.
14
Published as a conference paper at ICLR 2021
1.	Thefunction value SeqUence {(Φ + g)(xt)}t converges to a finite limit H * > 一∞;
2.	The sequences {xt}t, {yt}t are bounded and have compact sets of limit points. Moreover, (Φ +
g)(x* ) ≡ H* for any limit point x* of {xt}t;
3.	Every limit point of {xt}t is a critical point of (Φ + g)(x).
Proof. We first prove some useful results on the Lyapunov function H(z). By Assumption 1 we know
that Φ+g is bounded below and have compact sub-level sets, and we first show that H(z) also satisfies
these conditions. First, note that H(Z) = Φ(χ) + g(χ) +(1 — 击)ky — y*(χ)k2 ≥ Φ(χ) + g(x).
Taking infimum over x, y on both sides We obtain that infχ,y H(Z) ≥ infχ Φ(x) + g(x) > 一∞. This
shows that H(z) is bounded below. Second, consider the sub-level set Zα := {z = (x, y) : H(z) ≤
α} for any α ∈ R. This set is equivalent to {(x, y) : Φ(x) + g(x) + (1 - 412)ky - y*(x)k2 ≤ α}∙
For any point (x, y) ∈ Zα, the x part is included in the compact set {x : Φ(x) + g(x) ≤ α}.
Therefore, the x in this set must be compact. Also, the y in this set should also be compact as it is
inside the co-coercive function ky 一 y*(x)k2. Hence, We have shoWn that H(Z) is bounded beloW
and have compact sub-level set.
We first shoW that {(Φ + g)(xt)}t has a finite limit. We have shoWn in Proposition 2 that {H(Zt)}t
is monotonically decreasing. Since H(Z) is bounded beloW, We conclude that {H(Zt)}t has a finite
limit H * > -∞, i.e., limt→∞(Φ + g)(χt) +(1 — +) kyt — y*(xt )k2 = H *. Moreover, since
kyt 一 y*(xt)k →t 0, We further conclude that limt→∞(Φ + g)(xt) = H*.
Next, We prove the second item. Since {H(Zt)}t is monotonically decreasing and H(Z) has compact
sub-level set, We conclude that {xt}t, {yt}t are bounded and hence have compact sets of limit points.
Next, We derive a bound on the subdifferential. By the optimality condition of the proximal gradient
update of xt and the summation rule of subdifferential in Corollary 1.12.2 of Kruger (2003), We have
0 ∈ ∂g(xt+ι) + ɪ(xt+ι — Xt + ηχ^ιf(xt,yt)).
ηx
Then, We obtain that
一(Xt- χt+ι) -NIf(Xt,yt) + Vφ(χt+ι) ∈ d(φ + g)(xt+1),	(24)
ηx
Which further implies that
dist∂(Φ+g)(xt+ι)(O) ≤ —kxt+1 - xtk + ∣∣Vιf (χt, yt) - Vφ(χt+I)k
ηx
=-kχt+ι - χtk + Uf (χt,yt) - Vif (χt+ι, y*(χt+ι))k
ηx
≤ —kχt+1 - χtk + L(IlXt+1 - χtk + ky*(χt+ι) - ytk)
ηx
≤ (+ + L)kχt+ι — χtk + L(ky*(Xt+ι) — y*(χt)k + ky*(Xt) — ytk)
≤(n—HL(I+κ)) kχt+ι - χtk+Lky*(χt) - ytk.
Since We have shoWn that kχt+1 - χt k →t 0, ky* (χt) - yt k →t 0, We conclude from the above
inequality that dist∂(Φ+g)(xt) (0) →t 0. Therefore, We have shoWn that
一(χt-ι - χt) - VIf(Xt-ι,yt-ι) + Vφ(χt) ∈ d(φ + g)(χt),
ηx
and — (χt-1 - χt) -VIf(Xt-1, yt-1) + vφ(χt) → 0.	(25)
ηx
NoW consider any limit point χ* of χt so that χt(j ) →j χ* along a subsequence. By the proximal
update of χt(j), We have
g(χt(j)) + ʒ- kχt(j) - χt(j)-1k2 + hχt(j) - χt(j)-1, VIf(Xt(j)-1,yt(j)-l)i
2ηx
15
Published as a conference paper at ICLR 2021
≤ g(x*) + 21X kx*
-xt(j)-1k2 + hx* - xt(j)-1, Nlf(xt(j)-1,yt(j)-iyi.
Taking limsup on both sides of the above inequality and noting that {χt}t, {yt}t are bounded, Vf is
LiPSchitz, ∣∣xt+ι — Xtk →→ 0 and xt(j)→ x*, We conclude that limsupj g(xtj)) ≤ g(x*). Since g
is loWer-SemiCOntinuous, we know that liminf j g(xtj)) ≥ g(x*). Combining these two inequalities
yields that limj g(xtj)) = g(χ*). By continuity of Φ, we further conclude that limj (Φ + g)(xtj))=
(Φ + g)(χ*). Since we have shown that the entire sequence {(Φ + g)(χt)}t converges to a certain
finite limit H*, we conclude that (Φ + g)(x*) ≡ H* for all the limit points x* of {xt}t.
Next, we prove the third item. To this end, we have shown that for every subsequence xtj) → x*,
we have that (Φ +	g)(xt(j))	→j	(Φ +	g)(x*)	and there exists	ut	∈	∂(Φ +	g)(xt) such that ut	→t 0
(by eq. (25)). Recall the definition of limiting sub-differential, we conclude that every limit point x*
of {xt}t is a critical point of (Φ + g)(x), i.e., 0 ∈ ∂(Φ + g)(x*).
□
E Proof of Theorem 2
Theorem 2 (Variable convergence). LetAssumption 1 &2 hold and assume that H has the KL ge-
ometry. Choose the learning rates ηχ ≤ k3(l+3)2 and ny ≤ L. Then, the sequence {(xt,yt)}t
generated by proximal-GDA converges to a certain critical point (x*, y* (x*)) of (Φ + g)(x), i.e.,
xt →t x*, yt →t y* (x*).
Proof. We first derive a bound on ∂H (z). Recall that H (Z) = Φ(χ)+g(χ)+(l — 4⅛)∣∣y-y
and that ky*(x) - yk2 has non-empty subdifferential ∂χ(ky*(x) - yk2). We therefore have
∂χH(Z) ⊃ ∂(Φ + g)(x)+(1 - 4K2)∂χ(∣∣y*(x) -yk2),
VyH(Z) = -(2 - 21κ2)(y*(χ) - y),
where the first inclusion follows from the scalar multiplication rule and sum rule of sub-differential,
see Proposition 1.11 & 1.12 of Kruger (2003). Next, we derive upper bounds on these sub-differentials.
Based on Definition 1, we can take any u ∈ ∂bχ(ky*(x) - yk2) and obtain that
0 ≤ lim inf
z6=χ,z→χ
ky*(z) — yk2 — ky*(χ) — yk2 — u|(z — χ)
kz-xk
≤ liminf [y*(z) — y*(χ)]l[y*(z) + y*(χ) — 2y] — UT(Z — χ)
z6=χ,z→χ	kZ - xk
≤ lim inf
z6=χ,z→χ
ky*(z) — y*(χ)kky*(z) + y*(χ) — 2yk — UT(Z — χ)
kz - xk
≤) liminf [κky*(Z) + y*(x) - 2yk - UP(Z∙-x)i
z6=χ,z→χ	kZ - xk
(=)2κky*(x) - yk - limsup u” ([ x)
z6=χ,z→χ kZ - xk
(i=ii)2κky*(x) - yk - kUk
(26)
where (i) and (ii) use the fact that y* is κ-Lipschitz based on Proposition 1, and the limsup in (iii) is
achieved by letting Z = x + σU with σ → 0+ in (ii). Hence, we conclude that kUk ≤ 2κky*(x) - yk.
Since ∂χ(ky*(x) - yk2) is the graphical closure of ∂bχ(ky*(x) - yk2), we have that
dist∂χ(ky* (x)-y k2) (O) ≤ 2κky (X) - yk.
16
Published as a conference paper at ICLR 2021
Then, utilizing the characterization of ∂(Φ + g)(x) in eq. (24), We obtain that
dist∂H(zt+ι)(0)
≤ dist∂χH(m)(0) + ∣NyH(zt+ι)∣∣
≤ dist∂(Φ+g)(xt+ιN0) + (1 -不)dist%(|1y*(xt+i)-yt+ik2)(0)+ (2-京)ky*(xt+1) -yt+ιk
≤ ηllxt+ι - XtIl + ∣∣Vι∕(xt,yt) - ▽①(xt+I)Il + (2 - 2^2) (1 + κ)ky*(Xt+1) - yt+ι∣∣
≤ (n- + L)IlXt+1 - XtIl + L∣∣y*(xt+1) - yt∣∣ + 2(1 + κ)∣∣y*(xt+1) - yt+ιIl
(ii) 1 1	、
≤ n-—+L(I + K))IlXt+1 - Xtll + LIly*(Xt) - ytll
+ 2(1 + K) [p1 - K-2∣∣y*(Xt) - ytll + κ∙√(1 + K)∣∣Xt+1 - XtIli
(iii)
≤
(n—H(L + 4κ2)(1 + K))IlXt+1 - Xtll + (L + 4κ)∣∣y*(Xt) - yt∣∣∙
(27)
where (i) uses Proposition 1 that VΦ(Xt+1) = V1∕(Xt+1,y*(Xt+1)) and that y* is K-Lipschitz, (ii)
uses eq. (21) and the inequality that √α + b ≤ √α + √b (a, b ≥ 0) and (iii) uses K ≥ 1.
Next, we prove the convergence of the sequence under the assumption that H(Z) is a KE function.
Recall that we have shown in the proof of Theorem 1 that: 1) {H(zt)}t decreases monotonically to
the finite limit H*; 2) for any limit point X*,y* of {Xt}t, {yt}t, H(∕*,y*) has the constant value
H*. Hence, the KE inequality (see Definition 2) holds after sufficiently large number of iterations,
i.e., there exists t0 ∈ N+ such that for all t ≥ t0,
d(H(zt)- H * )diStdH (zt)(0) ≥ 1.
Rearranging the above inequality and utilizing eq. (27), we obtain that for all t ≥ t0,
,(H(zt)- H*)
〉	1
一dist∂H(Zt) (0)
≥ [(n—H(L + 4K2)(1 + K))IlXt - Xt-Ill + (L + 4K)||y*(Xt-I) - yt-1∣∣i
By concavity of the function 夕(see Definition 2), we know that
夕(H(Zt)- H*)-夕(H(zt+1)- H*)
≥ 夕 0(H(Zt)- H*)(H(Zt)- H(Zt+1))
≥___________________|lXt+1 - Xt||2 + ⅛^Ilyt - y*(Xt)||2_________________
(ηχ + (L + 4k2)(1 + K))IlXt - Xt-1 Il + (L + 4K)||y*(Xt-I) - yt-1∣∣
(28)
(29)
≥
1 [|如+1- XtIl+ * ι∣yt- y*(Xt)Ili
(ηχ + (L + 4k2)(1 + K))IlXt - Xt-1∣∣ + (L + 4K)||y* (Xt-I) - yt-1∣∣
where (i) uses Proposition 2 and eq. (28), (ii) uses the inequality that α2 + b2 ≥ ɪ(a + b)2.
Rearranging the above inequality that
[||Xt+1 - Xtk + 2K∣∣yt - y*(Xt)Ili
≤ 2[^(H(Zt) - H*) - °(H(Zt+1) - H*)]
[(n—H(L + 4k2)(1 + K)) ||Xt - Xt-Ik + (L + 4K)||y* (Xt-I) - yt-1∣∣]
≤ [°k(H(Zt) - H*)-以H(Zt+1) - H*)]
17
Published as a conference paper at ICLR 2021
+c (n-+(L+4κ2)(1+K)) kxt - xt-1k+c(L+4κ)ky*(xt-ι) - yt-ιki
where the final step uses the inequality that 2ab ≤ (Ca + C)2 for any a, b ≥ 0 and C > 0 (the value
of C will be assigned later). Taking square root of both sides of the above inequality and telescoping
over t = t0, . . . , T - 1, we obtain that
T-1	T-1
X kχt+ι - Xtk + 2κ X kyt - y*(xt)k
t=t0	t=t0
1	1	T-1
≤ C2[H(zto) - H*] - C中[H(ZT) - H*] + c (--------H(L + 4κ2)(1 + K)) X kxt - xt-ιk
ηx	t=t0
1	T-1
+ C (L + 4κ) X ky*(xt-1) - yt-1k
t=t0
T-2
≤ ɪ [H(ZtO ) - H*]θ + C (	+(L + 4κ2)(1 2 3 + K)) X kxt+1 - xtk
θ	C ηx	t=t0 -1
T-2
+c(L+4κ)	X	ky*(xt) - ytk
t=t0 -1
where the final steps uses 夕(S) = C sθ and the fact that H (ZT) 一 H * ≥ 0. Since the value of
C > 0 is arbitrary, We can select large enough C such that C (n- + (L + 4κ)2(1 + K)) < ɪ and
CC(L + 4κ) < 2K. Hence, the inequality above further implies that
2 X kxt+1 - xtk ≤ ɪ [H (ZtO ) - H *]θ + 2 kxto - xto-1k + 2- ky*(xt0-1) - yt0-1k < +∞.
2	2	2K
t=tO
Letting T → ∞, we conclude that
∞
kxt+1 - xt k< + ∞.
t=1
Moreover, this implies that {xt}t is a Cauchy sequence and therefore converges to a certain limit, i.e.,
xt →t x* . We have shown in Theorem 1 that any such limit point must be a critical point of Φ + g .
Hence, we conclude that {xt}t converges to a certain critical point x* of (Φ + g)(x). Also, note that
ky*(xt) - ytk →t 0, xt →t x* and y* is a Lipschitz mapping, so we conclude that {yt}t converges to
y*(x*).
□
F Proof of Theorem 3
Theorem 3 (Funtion value convergence rate). Under the same conditions as those of Theorem 2, the
Lyapunov function value sequence {H (Zt)}t converges to the limit H* at the following rates.
1. IfKL geometry holds with θ = 1, then H (Zt) J H * within finite number of iterations;
2. IfKL geometry holds with θ ∈ (2, 1) ,then H (Zt) J H * Super-linearly as
H (Zt)- H * ≤ (2Mc2)-2θ-1 exp ( - (2(τ1-1y )t-t0), ∀t ≥ to；	(6)
3. IfKL geometry holds with θ = 2, then H (Zt) J H * linearly as
H (Zt)- H * ≤ (l + U )t0-t(H (ZtO) - H *), ∀t ≥ to；	⑺
2Mc2
18
Published as a conference paper at ICLR 2021
4.	IfKL geometry holds with θ ∈ (0, 1) ,then H (Zt) J H * Sub-Hnearly as
1
H(Zt)-H * ≤ [C(t-to)]— E, ∀t ≥ to.	(8)
where C = min [⅛Mθ∙, d-(1-2θ)(1 - 2-(1-2θ))i > 0.
Proof. Note that eq. (27) implies that
dist∂H(zt+ι)(O)2 ≤2( η- ^+ (L + 4κ2)(1 + K)) kxt+1 - Xt k2 + 2(L + 4K)2ky*(Xt)- ytk2,
x	(30)
Recall that We have shown that for all t ≥ to, the KE property holds and We have
k0(H(Zt)- H*)]2dist∂H(zt)(0) ≥ 1.
Throughout the rest of the proof, We assume t ≥ to . Substituting eq. (30) into the above bound yields
that
1 ≤2[d(H (Zt)- H *)]2h(: + (L + 4κ2)(1 + κ))2∣xt - Xt-Ik2
+(L + 4K)2ky*(Xt-1) - yt-1 k2 i.
≤2M[ψ0(H(Zt)- H*)]2 [2∣∣xt - Xt-Ik2 + 4K2∣∣y*(xt-ι) - yt-ιk1	(31)
Where the second inequality uses the definition of M in eq. (5).
Substituting eq. (4) and 夕0(s) = csθ-1 (c > 0) into eq. (31) and rearranging, we further obtain that
[c(H(Zt) - H*)θ-1]-2 ≤ 2M[H(Zt-1) - H(Zt)]
Defining dt = H(Zt) - H*, the above inequality further becomes
dt-1 - dt ≥ 2MMc2 d2(1-θ).	(32)
Next, we prove the convergence rates case by case.
(Case 1) If θ = 1, then eq. (32) implies that dt-ι - dt ≥ 2M^ > 0 whenever dt > 0. Hence, dt
achieves 0 (i.e., H(Zt) achieves H*) within finite number of iterations.
(Case 2) If θ ∈ (2, 1), since dt ≥ 0, eq. (32) implies that
dt-ι ≥ 2Mc2 d2(i),	(33)
which is equivalent to that
1
(2Mc2)2θ-ι dt ≤ [(2Mc2)2θ-ι dt-1] 2(1-θ)	(34)
Since dt J 0, (2Mc2)2θ-1 dt` ≤ e-1 for sufficiently large tι ∈ N+ and tι ≥ to. Hence, eq. (34)
implies that for t ≥ t1
[1	]t-t1
(2Mc2)2θ-ιdt ≤ [(2Mc2)2θι dtJ 2(1-θ)
≤exp{- h Jyit]
Note that θ ∈ (2, 1) implies that 2(1—6)> 1, and thus the inequality above implies that H(Zt) J H*
at the super-linear rate given by eq. (6).
19
Published as a conference paper at ICLR 2021
(Case 3) If θ = 2
dt-ι- dt ≥ 2M1c2 dt,	(35)
which implies that d ≤(1 + 2Mc2) Tdt-1. Therefore, d J 0 (i.e., H(Zt) J H*) at the linear rate
given by eq. (7).
(Case 4) If θ ∈ (0, 2), consider the following two subcases.
If dt-ι ≤ 2dt, denote ψ(s) = ɪ-^s-(1-2θ), then
dt-1	dt-1	(i)
ψ(dt) - ψ(dt-1) =	-ψ0(s)ds =	s-2(1-θ)ds ≥ dt--1( - )(dt-1 - dt)
dt	dt
(ii)	1	( dt ∖2(1-θ)、	1	、	1
≥ 2MC ldt-1J	≥ 23-2θMc2 ≥ 8Mc2
where (i) uses dt ≤ dt-1 and -2(1 - θ) < -1, and (ii) uses eq. (32).
If dt-1 > 2dt
ψ(dt) — Ψ(dt-i) =1-12θ(d-(1-2θ) — d--1-2θ)) ≥ 1-12θ(d-(Tθ) - (2dt)-(1-2θ))
1 — 2-(I-2θ)	(i-2θ)	1 — 2-(I-2θ)	(i-2θ)
≥	1 — 2θ	dt	≥	1 — 2θ	dto	.
(36)
(37)
where we use —(1 — 2θ) < 0, dt-1 > 2dt and dt ≤ dt0.
Hence,
1	1	2-(1-2θ)	C
Mdtt- ψ(dtτ) ≥ min [折，-1 — 2θ 叽 2 ] = T-2Θ > 0，	(38)
which implies that
CC
ψ(dtt ≥ ψ(dt0t + 1 — 2θ(t — to) ≥ 1 — 2θ (t — to)
By substituing the definition of ψ, the inequality above implies that H (Zt) J H * in a sub-linear rate
given by eq. (8).	□
G Proof of Theorem 4
Theorem 4 (Variable convergence rate). Under the same conditions as those of Theorem 2, the
sequences {xt, yt}t converge to their limits x*, y*(x*) respectively at the following rates.
1. IfKL geometry holds with θ = 1, then (xt, yt) → (x*,y*(x*)) within finite number of itera-
tions;
2. IfKL geometry holds with θ ∈ (ɪ, 1), then (xt,yt) → (x*,y*(x*)) Super-linearly as
max {kxt — x*k,kyt — y*(x*)k} ≤θ(exp (—(2(1 ) θ) )t-t0)),	∀t ≥ to；	(9)
3. IfKL geometry holds with θ = 1, then (xt, yt) → (x*,y*(x*)) linearly as
max {kxt — x*k,kyt— y*(x*)k} ≤θ((min {2,1 + 2MC2})(。" ), ∀t ≥ to； (10)
4. IfKL geometry holds with θ ∈ (0,11), then (xt, yt) → (χ*,y*(χ*)) sub-linearly as
max {kxt — x*k, kyt — y*(x*)k} ≤θ((t — to)- 1- 2 3 4θ2θ), ∀t ≥ to.	(11)
20
Published as a conference paper at ICLR 2021
Proof. (Case 1) If θ = 1, then based on the first case of Appendix F, H (Zt) ≡ H * after finite number
of iterations. Hence, for large enough t, Proposition 2 yields that
2kxt+1 - xtk2 + 4K2 (kyt+1 - y* (Xt+1) k2 + kyt - y* (Xt) k2) ≤ H(Zt)- H(Zt+1) = 0,	(39)
which implies that xt+1 = xt and yt = y* (xt) for large enougth t. Hence, xt → x* and yt → y*(x*)
within finite number of iterations.
(Case 2) If θ ∈ (2, 1), denote At = ∣∣χt+ι - Xtk + 2K kyt - y*(xt)k. Then, based on the definition
of M in eq. (5), we have
(η—+ (L+4κ2)(1+κ))kxt—xt-ιk+(L+4κ)ky*(Xt-I)- yt-ιk ≤ √2MAt-ι.	(4o)
Hence, eqs. (28) & (40) and "(s) = csθ-1 imply that
C(H(Zt)- Η*)θ-1 ≥ (√2MAt-ι)-1,
which along with θ - 1 < 0 implies
H(Zt)- H * ≤ (c√2MAt-ι) 1-θ.	(41)
Then, eqs. (29) & (40) imply that
夕(H(Zt)- H*)-夕(H(Zt+1) - H*) ≥
kxt+ι - xtk2 + 412kyt - y*(Xt)Il2
2√2MAt-ι
Using the inequality that a2 + b2 ≥ 2(a + b)2 and recalling the definition of At and 夕(S) = Csθ, the
above inequality further implies that
C(H(Zt)-H*)θ- C(H(Zt+°-H*)θ ≥ 4√2MA-7.
Substituting eq. (41) into eq. (42) and using H(Zt+1) - H* ≥ 0 yield that
A2 ≤ 4(c√2MAt-1)1-θ,
θ
which is equivalent to that
1
C1At ≤ (C1At-1)…
(42)
(43)
where
C1 = (4∕θ) 2θ-1 (c√2M) 2θ-1.
Note that eq. (43) holds for t ≥ t0. Since At → 0, there exists t1 ≥ t0 such that C1At1 ≤ e-1.
Hence, by iterating eq. (43) from t = t1 + 1, we obtain
CIAt ≤eχp h- (2(τ1z^))	i, ∀t ≥ t1 + 1.
Hence, for any t ≥ t1 + 1,
1
Clexp
1
Clexp
∞∞
x As ≤ Ci x
s=t	s=t
])
21
Published as a conference paper at ICLR 2021
≤)C11 exph-(2(I⅛)t t1iXXexph1-(2(I⅛)s ti
=C11exp h- (2(i⅛广t1i XXexp h1 - (2(i⅛)si
臭{ exp h - (2(1⅛ Lio,	(44)
where (i) uses the inequalities that 2ʊ-j > 1 and that S ≥ t ≥ ti + 1, and (ii) uses the fact
that P∞=ο exp [l - Q(M)) ] < +∞ is a positive constant independent from t. Therefore, the
convergence rate (9) can be directly derived as follows
T-i
∣∣xt — x*k =Iimsup Ilxt - XTk ≤ limsupV' l∣Xs+ι - Xsk
T→∞	T→∞ s=t
T-i
≤liT→s∞∞pXAs ≤O{exph-(2(Γ-θ))	ɪio,
(45)
and
(i)
kyt-y*(χ*)k ≤kyt-y*(χt)k + ∣∣y*(χt) — y*(χ*)k ≤ 2κAt + Kkxt-x*∣∣
∞	(ii)	1	t-t1
≤2κΣSAs + Kkxt - x k ≤ O{ eχP [- (2(1 - θ) ) ]ʃ,
where (i) uses the Lipschitz property of y* in Proposition 1, and (ii) uses eqs. (44) & (45).
(Case 3 & 4) Notice that eq. (42) still holds if θ ∈(0,1 ]. Hence, if At ≥ 2At-ι, then eq. (42)
implies that
At ≤
8^2M [(H (Zt)- H *)θ - (H (zt+ι) - H * )θ ].
θ
Otherwise, At ≤ 2At-1. Combining these two inequalities yields that
At ≤ 8c^2M [(H(Zt)- H*)θ - (H(zt+ι) - H*)θ] + 1 At-i.
θ2
Notice that the inequality above holds whenever t ≥ t0 . Hence, telescoping the inequality above
yields
XX As ≤ 8c√2M [(H (Zt)-H *)θ - (H (ZT +ι) - H *)θ ] +2 XX As, ∀t ≥ to,	(46)
s=t	s=t-i
which along with AT ≥ 0, H(ZT+i) - H* ≥ 0 implies that
1T
2 X As ≤
s=t
8c √2M
θ
(H(Zt)- H*)θ + 2At-i,
Letting t = t0 and T → ∞ in the above inequality yields that Ps∞=t As < +∞. Hence, by letting
T → ∞ and denoting St = Ps∞=t As in eq. (46), we obtain that
St ≤
8c √2M
θ
(H(Zt) - H*)θ + 2St-i,
∀t ≥ t0 ,
which further implies that
St ≤
2⅛0St0 + 8c√2M XX 2-(H(Zs) - H*)θ
s=t0+i
(47)
22
Published as a conference paper at ICLR 2021
(Case 3) If θ = 1/2, eq. (7) holds. Substituting eq. (7) and θ = 1/2 into eq. (47) yields that
1	,________________ Jt^	1	/	1	、(to-s)/2
St ≤2t-toSto + 8cP2MH(ZtO) - H*]	E	2- (1 + 2Mc2J
s=t0 +1
≤ ɪ S + C XX (1 ,	1「
―2t-t0 to	2ts"4	8Mc”
(48)
where
~	1-Γ―:——：-----7 1	1 λ to/2
C2 = 8c ,2M[H (%)-H *] (1 + 2Mc2 )	(49)
is a positive constant independent of t.
Notice that when 4 + 8m^ ≥ 1,
t 1	1	-s/2
E (4 + 8MC2)	≤t -10
s=to+1
and When 1 + 8MMc2 < 1,
X (1 + 8⅛F2
s=to+1
4+
1 ʌ-t/2 1 - (4 +
8Mc2
1-
~ ≤Oh(4+
(t-to)/2
1
8Mc2
-t/2i
Since either of the two above inequalities holds, combining them yields that
X (4 + 8M2 )"2≤O{ max I- to, (4 + 8M2 11}
s=to +1
Substituing the above inequality into eq. (48) yields that
St ≤2-0Sto + On max h2-t(t- to),(1 + 2MC2)-"2i}
W min (2,1 + 2⅛F)
Hence,
(i) ∞	1	-t/2
kxt - χ*k ≤ EAs = St ≤ O{ [min (2,1 + 2MC2)]	},
s=t
where (i) comes from eq. (45). Then,
kyt -y*(χ*)k ≤kyt -y*(χt)k + ky*(χt) -y*(χ*)k ≤ 2κAt + Kkxt- x*k
≤2κSt + Kkxt- x*k ≤ Onhmin (2,1 + 2M^)] / }.
The two above inequalities yield the linear convergence rate (10).
(Case 4) If θ ∈ (0, 4), then eq. (8) holds. Substituting eq. (8) into eq. (47) yields that for some
constant C3 > 0,
C 1 C	8c√2M 匚	C3 ,	、__J
St ≤2-oSto + —θ — Σ	2-s(s - t0) 1-2θ
s=to+1
1 S	8cC3 √2M
≤ 2t-to to +	2t-to θ
(i)	1 S	8cC3 √2M
=2t-to	to +	2t-to θ
t-to
X	2ss
s=1
t1
θ
1-2θ
2ss-
s=1
θ	8cC3√2M t-t0	S __J
1-2θ +2s S 1-2θ
+	2t-to θ 乙 2
s=t1 +1

23
Published as a conference paper at ICLR 2021
1	8cCβ√2M X^ 9s	8cCβ√2M X0	§(t — to、- ι-⅛θ
≤ 2t-t0 t0 +	2t-to θ	22 +	2t-toθ	2 2 I 2 )
s=1	s=tι+1
(≤) ɪ S , 8CC3√2M g + 1 , 8CC3√2M (t-tθ「占 2i0 + l
0 2t-t0 t0 +	2i θ	+	2t-t0 θ	V 2 √
=O [2⅛ ,声\ , (t - to)-&S] = 0[(t - to)-鼻],	(50)
where (i) denotes tι = [(t — to)∕2j, (ii) uses the inequality that P：=；； + 1 2s < P：=]0 2s < 2t-t0+1.
Therefore, the sub-linear convergence rate eq. (11) follows from the following inequalities.
kxt - x*k ≤ St ≤ O[(t — to)-』],
and
kyt -y*(χ*)k ≤kyt -y*(χt)k + ∣∣y*(χt) -y*(χ*)k ≤ 2kA； + Kkxt- χ*k
≤2κSt+ Kllxt- x* Il ≤ O [(t- to) 1-2θ ].
□
24