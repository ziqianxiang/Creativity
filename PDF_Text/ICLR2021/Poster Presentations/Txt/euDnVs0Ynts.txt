Published as a conference paper at ICLR 2021
Robust Learning of Fixed-Structure Bayesian
Networks in Nearly-Linear Time
Yu Cheng
Department of Mathematics (MSCS)
University of Illinois at Chicago
yucheng2@uic.edu
Honghao Lin
Institute for Theoretical Computer Science
Shanghai University of Finance and Economics
Guilan3010@gmail.com
Ab stract
We study the problem of learning Bayesian networks where an -fraction of the
samples are adversarially corrupted. We focus on the fully-observable case where
the underlying graph structure is known. In this work, we present the first nearly-
linear time algorithm for this problem with a dimension-independent error guar-
antee. Previous robust algorithms with comparable error guarantees are slower
by at least a factor of (d/), where d is the number of variables in the Bayesian
network and is the fraction of corrupted samples. Our algorithm and analysis are
considerably simpler than those in previous work. We achieve this by establish-
ing a direct connection between robust learning of Bayesian networks and robust
mean estimation. As a subroutine in our algorithm, we develop a robust mean
estimation algorithm whose runtime is nearly-linear in the number of nonzeros in
the input samples, which may be of independent interest.
1	Introduction
Probabilistic graphical models (Koller & Friedman, 2009) offer an elegant and succinct way to
represent structured high-dimensional distributions. The problem of inference and learning in prob-
abilistic graphical models is an important problem that arises in many disciplines (see Wainwright
& Jordan (2008) and the references therein), which has been studied extensively during the past
decades (see, e.g., Chow & Liu (1968); Dasgupta (1997); Abbeel et al. (2006); Wainwright et al.
(2006); Anandkumar et al. (2012); Santhanam & Wainwright (2012); Loh & Wainwright (2012);
Bresler et al. (2013; 2014); Bresler (2015)).
Bayesian networks (Jensen & Nielsen, 2007) are an important family of probabilistic graphical mod-
els that represent conditional dependence by a directed graph (see Section 2 for a formal definition).
In this paper, we study the problem of learning Bayesian networks where an -fraction of the sam-
ples are adversarially corrupted. We focus on the simplest setting: all variables are binary and
observable, and the structure of the Bayesian network is given to the algorithm.
Formally, we work with the following corruption model:
Definition 1.1 (-Corrupted Set of Samples). Given 0 < < 1/2 anda distribution family P on Rd,
the algorithm first specifies the number of samples N, and N samples X1, X2, . . . , XN are drawn
from some unknown P ∈ P. The adversary inspects the samples, the ground-truth distribution P,
and the algorithm, and then replaces N samples with arbitrary points. The set of N points is given
to the algorithm as input. We say that a set of samples is -corrupted ifit is generated by this process.
This is a strong corruption model which generalizes many existing models. In particular, it is
stronger than Huber’s contamination model (Huber, 1964), because we allow the adversary to add
bad samples and remove good samples, and he can do so adaptively.
Our goal is to design robust algorithms for learning Bayesian networks with dimension-independent
error. More specifically, given as input an -corrupted set of samples drawn from some ground-
truth Bayesian network P and the graph structure of P, we want the algorithm to output a Bayesian
network Q, such that the total variation distance between P and Q is upper bounded by a function
that depends only on (the fraction of corruption) but not d (the number of variables in P).
1
Published as a conference paper at ICLR 2021
In the fully-observable fixed-structure setting, the problem is straightforward when there is no cor-
ruption. We know that the empirical estimator (which computes the empirical conditional probabil-
ities) is sample efficient and runs in linear time (Dasgupta, 1997).
It turns out that the problem becomes much more challenging when there is corruption. Even for
robust learning of binary product distributions (i.e., a Bayesian network with an empty dependency
graph), the first computational efficient algorithms with dimension-independent error was only dis-
covered in (Diakonikolas et al., 2019a). Subsequently, (Cheng et al., 2018) gave the first polynomial-
time algorithms for robust learning of fixed-structured Bayesian networks. The main drawback of
the algorithm in (Cheng et al., 2018) is that it runs in time Ω(Nd2∕e), which is slower by at least a
factor of (d/) compared to the fastest non-robust estimator.
Motivated by this gap in the running time, in this work we want to resolve the following question:
Can we design a robust algorithm for learning Bayesian networks in the fixed-
structure fully-observable setting that runs in nearly-linear time?
1.1	Our Results and Contributions
We resolve this question affirmatively by proving Theorem 1.2. We say a Bayesian network is c-
balanced if all its conditional probabilities are between c and 1 - c. For the ground-truth Bayesian
network P , let m be the size of its conditional probability table and α be its minimum parental
configuration probability (see Section 2 for formal definitions).
Theorem 1.2 (informal statement). Consider an E-corrupted set of N = Ω(m∕e2) samples drawn
from a d-dimensional Bayesian network P. Suppose P is c-balanced and has minimum parental
configuration probability α, where both c andα are universal constants. We can compute a Bayesian
network Q in time O(N d) such that dTV (P, Q) ≤ E ln(1/E). * 1
For simplicity, we stated our result in the very special case where both C and a are Ω(1). Our
approach works for general values of α and c, where our error guarantee degrades gracefully as α
and c gets smaller. A formal version of Theorem 1.2 is given as Theorem 4.1 in Section 4.
Our algorithm has optimal error guarantee, sample complexity, and running time (up to logarithmic
factors). There is an information-theoretic lower bound of Ω(e) on the error guarantee, which holds
even for Bayesian networks with only one variable. A sample complexity lower bound of Ω(m∕e2)
holds even without corruption (see, e.g., (Canonne et al., 2017)).
Our Contributions. We establish a novel connection between robust learning of Bayesian net-
works and robust mean estimation. At a high level, we show that one can essentially reduce the
former to the latter. This allows us to take advantage of the recent (and future) advances in robust
mean estimation and apply the algorithms almost directly to obtain new algorithms for learning
Bayesian networks.
Our algorithm and analysis are considerably simpler than those in previous work. For simplicity,
consider learning binary product distributions as an example. Cheng et al. (2018) tried to remove
samples to make the empirical covariance matrix closer to a diagonal matrix (since the true covari-
ance matrix is diagonal because each coordinate is independent). They used a “filtering” approach
which requires proving specific tail bounds on the samples. In contrast, we show that it suffices
to use any robust mean estimation algorithms which minimize the spectral norm of the empirical
covariance matrix (regardless of whether it is close to being diagonal or not).
As a subroutine in our approach, we develop the first robust mean estimation algorithm that runs
in nearly input-sparsity time (i.e., in time nearly linear in the total number of nonzero entries in the
input), which may be of independent interest. The main computation bottleneck of current nearly-
linear time robust mean estimation algorithms (Cheng et al., 2019a; Depersin & Lecue, 2019; Dong
et al., 2019) is running matrix multiplication weight update with the Johnson-Lindenstrauss lemma,
which we show can be done in nearly input-sparsity time.
1
1Throughout the paper, we use O(f) to denote O(f polylog(f)).
2
Published as a conference paper at ICLR 2021
1.2	Related Work
Bayesian Networks. Probabilistic graphical models (Koller & Friedman, 2009) provide an ap-
pealing and unifying formalism to succinctly represent structured high-dimensional distributions.
The general problem of inference in graphical models is of fundamental importance and arises in
many applications across several scientific disciplines (see Wainwright & Jordan (2008) and refer-
ences therein). The problem of learning graphical models from data (Neapolitan, 2003; Daly et al.,
2011) has many variants: (i) the family of graphical models (e.g., directed, undirected), (ii) whether
the data is fully or partially observable, and (iii) whether the graph structure is known or not. This
learning problem has been studied extensively (see, e.g., Chow & Liu (1968); Dasgupta (1997);
Abbeel et al. (2006); Wainwright et al. (2006); Anandkumar et al. (2012); Santhanam & Wainwright
(2012); Loh & Wainwright (2012); Bresler et al. (2013; 2014); Bresler (2015)), resulting in a beau-
tiful theory and a collection of algorithms in various settings.
Robust Statistics. Learning in the presence of outliers has been studied since the 1960s (Huber,
1964). For the most basic problem of robust mean estimation, it is well-known that the empirical
median works in one dimension. However, most natural generalizations of the median to high
dimensions (e.g., coordinate-wise median, geometric median) would incur an error of Ω(e√d), even
in the infinite sample regime (see, e.g., Diakonikolas et al. (2019a); Lai et al. (2016)). After decades
of work, sample-efficient robust estimators have been discovered (e.g., the Tukey median (Tukey,
1975; Devroye & Gyorfi, 1985; Chen et al., 2018)). However, the TUkey median is NP-Hard to
compute in the worse case (Johnson & Preparata, 1978; Amaldi & Kann, 1995) and many heuristics
for approximating it perform poorly as the dimension scales (Clarkson et al., 1993; Chan, 2004;
Miller & Sheehy, 2010).
Computational Efficient Robust Estimators. Recent work (Diakonikolas et al., 2019a; Lai et al.,
2016) gave the first polynomial-time algorithms several high-dimensional unsupervised learning
tasks (e.g., mean and covariance estimation) with dimension-independent error guarantees. After
the dissemination of (Diakonikolas et al., 2019a; Lai et al., 2016), algorithmic high-dimensional
robust statistics has attracted a lot of recent attention and there has been a flurry of research that
obtained polynomial-time robust algorithms for a wide range of machine learning and statistical
tasks (see, e.g., Balakrishnan et al. (2017); Charikar et al. (2017); Diakonikolas et al. (2017a;b);
Steinhardt et al. (2018); Diakonikolas et al. (2018); Hopkins & Li (2018); Kothari et al. (2018);
Prasad et al. (2020); Diakonikolas et al. (2019b); Klivans et al. (2018); Diakonikolas et al. (2019c);
Liu et al. (2020); Cheng et al. (2020); Zhu et al. (2020)). In particular, the most relevant prior
work is (Cheng et al., 2018), which gave the first polynomial-time algorithms for robust learning of
fixed-structure Bayesian networks.
Faster Robust Estimators. While recent work gave polynomial-time robust algorithms for many
tasks, these algorithms are often significantly slower than the fastest non-robust ones (e.g., sample
average for mean estimation). Cheng et al. (2019a) gave the first nearly-linear time algorithm for
robust mean estimation and initiated the research direction of designing robust estimators that are
as efficient as their non-robust counterparts. Since then, there have been several works that develop
faster robust algorithms for various learning and statistical tasks, including robust mean estimation
for heavy-tailed distributions Dong et al. (2019); Depersin & LecUe (2019), robust covariance esti-
mation Cheng et al. (2019b); Li & Ye (2020), robust linear regression Cherapanamjeri et al. (2020a),
and list-decodable mean estimation Cherapanamjeri et al. (2020b); Diakonikolas et al. (2020).
Organization. In Section 2, we define our notations and provide some background on robust learn-
ing of Bayesian networks and robust mean estimation. In Section 3, we give an overview of our
approach and highlight some of our key technical results. In Section 4, we present our algorithm for
robust learning of Bayesian networks and prove our main result.
2	Preliminaries
Bayesian Networks. Fix a d-node directed acyclic graph H whose nodes are labelled [d] =
{1, 2, . . . ,d} in topological order (every edge goes from a node with smaller index to one with
larger index). Let Parents(i) be the parents of node i in H. A probability distribution P on
3
Published as a conference paper at ICLR 2021
{0, 1}d is a Bayesian network (or Bayes net) with graph H if, for each i ∈ [d], we have that
PrX〜P [Xi = 1 | Xi,..., Xi-ι] depends only on the values Xj where j ∈ Parents(i).
Conditional Probability Table. Let P be a Bayesian network with graph H. Let Γ = {(i, a) :
i ∈ [d], a ∈ {0,1}|Parents(i)|} be the Set of all possible parental configurations. Let m = ∣Γ∣. For
(i, a) ∈ Γ, the parental configuration Πi,a is defined to be the event that X(Parents(i)) = a. The
conditional probability table P ∈ [0,1]m of P is given by pi,a = PrX〜P [X (i) = 1 | ∏i,a].
In this paper, we often index p as an m-dimensional vector. We use the notation pk and the associated
events Πk, where each k ∈ [m] stands for an (i, a) ∈ Γ lexicographically ordered.
Notations. For a vector v, let ∣∣vk2 and ∣∣v∣∣∞ be the '2 and '∞ norm of V respectively. We write
√v and 1/v for the entrywise square root and entrywise inverse of a vector V respectively. For two
vectors x and y, we write x>y for their inner product, and x ◦ y for their entrywise product.
We use I to denote the identity matrix. For a matrix M, let Mi be the i-th column of M, and let
∣M∣2 be the spectral norm of M. For a vector v ∈ Rn, let diag(v) ∈ Rn×n denote a diagonal
matrix with v on the diagonal.
Throughout this paper, we use P to denote the ground-truth Bayesian network. We use d for the
dimension (i.e., the number of nodes) of P, N for the number of samples, for the fraction of
corrupted samples, and m = Pid=1 2|Parents(i)| for the size of the conditional probability table ofP.
We use p ∈ Rm to denote the (unknown) ground-truth conditional probabilities of P, and q ∈ Rm
for our current guess ofp.
Let G? be the original set of N uncorrupted samples drawn from P. After the adversary corrupts an
-fraction of G?, let G ⊆ G? be the remaining set of good samples, and B be the set of bad samples
added by the adversary. The set of samples S = G ∪ B is given to the algorithm as input. Let
X ∈ Rd×N denote the sample matrix whose i-th column Xi ∈ Rd is the i-th input sample. Abusing
notation, we sometimes also use X as a random variable (e.g., a sample drawn from P).
We use πP ∈ Rm to denote the parental configuration probabilities of P. That is, πkP =
PrX〜P[X ∈ ∏k]. For a set S of samples, We use ∏S ∈ Rm to denote the empirical parental
configuration probabilities over S: πkS = PrX [X ∈ Πk] where X is uniformly drawn from S.
Balance and Minimum Configuration Probability. We say a Bayesian network P is c-balanced
if all conditional probabilities of P are between c and 1 - c. We use α for the minimum probability
of parental configuration of P: α = mink πkP.
In this paper, We assume that the ground-truth Bayesian network is c-balanced, and its minimum
parental configuration probability α satisfies that α = Ω((e VZln(1/c))2/3CT/3)). Without loss of
generality, we further assume that both c and α are given to the algorithm.
2.1	Total Variation Distance between Bayesian Networks
Let P and Q be two distributions supported on a finite domain D . For a set of outcomes A, let
P(A) = PrX〜P [X ∈ A]. The total variation distance between P and Q is defined as
dTV (P, Q) = max |P (A) - Q(A)| .
A⊆D
For two balanced Bayesian networks that share the same structure, it is well-known that the closeness
in their conditional probabilities implies their closeness in total variation distance. Formally, we use
the following lemma from Cheng et al. (2018), which upper bounds the total variation distance
between two Bayesian networks in terms of their conditional probabilities.
Lemma 2.1 (Cheng et al. (2018)). Let P and Q be two Bayesian networks that share the same
structure. Let p and q denote the conditional probability tables of P and Q respectively. We have
(dτv (" ≤2 X qπPπQ (Pk+qρ)(- -kPk-a.
4
Published as a conference paper at ICLR 2021
2.2	Expanding the Distribution to Match Conditional Probability Table
Lemma 2.1 states that to learn a known-structure Bayesian network P, it is sufficient to learn its
conditional probabilities p. However, a given coordinate of X 〜P may contain information about
multiple conditional probabilities (depending on which parental configuration happens).
To address this issue, we use a similar approach as in Cheng et al. (2018). We expand each sample X
into an m-dimensional vector f(X, q), such that each coordinate of f(X, q) corresponds to an entry
in the conditional probability table. Intuitively, q ∈ Rm is our current guess for p, and initially we
set q to be the empirical conditional probabilities. We use q to fill in the missing entries in f (X, q)
for which the parental configurations fail to happen.
Definition 2.2. Let f(X, q) for {0, 1}d × Rm → Rm be defined as follows:
f(X )	Xi - qi,a X ∈ Πi,a
f (X, q)i,a = 0	otherwise
When X 〜 P and q = p, the distribution of f (X,p) has many good properties. Using the condi-
tional independence of Bayesian networks, we can compute the first and second moment of f(X,p)
and show that f(X, p) has subgaussian tails.
Lemma 2.3. For X 〜P and f (X, P) as defined in Definition 2.2, we have
(i) E(f (X, p)) = 0. (ii) Cov[f (X, p)] = diag(πP ◦ p ◦ (1 - p)).
(iii) For any unit vector V ∈ Rm, we have PrX〜P [∣v>f (X,p)| ≥ T] ≤ 2exp(-T2/2).
We defer the proof of Lemma 2.3 to Appendix A. A slightly stronger version of Lemma 2.3 was
proved in Cheng et al. (2018), which discusses tail bounds for f(X, q). For our analysis, Lemma 2.3
is sufficient.
For general values of q, we can similarly compute the mean of f(X, q):
Lemma 2.4. Let πp denote the parental configuration of P. For X 〜P and f (X, q) as defined in
Definition 2.2, we have E[f (X, q)] = πP ◦ (p - q).
2.3	Deterministic Conditions on Good Samples
To avoid dealing with the randomness of the good samples, we require the following deterministic
conditions to hold for the original set G? of N good samples (before the adversary’s corruption).
We prove in Appendix A that these three conditions hold simultaneously with probability at least
1 — T if we draw N = Ω(m log(m/T)/e2) samples from P.
The first condition states that we can obtain a good estimation of p from G? . Let pG? denote the
empirical conditional probabilities over G? . We have
∣∣√πP◦ (p - PG?)∣∣2 ≤ O(e) .	(1)
The second condition says that we can estimate the parental configuration probabilities πP from any
(1 - 2)-fraction of G?. Formally, for any subset T ⊂ G? with |T| ≥ (1 - 2)N, we have
∣πT-πP∣∞≤O().
(2)
The third condition is that the empirical mean and covariance of any (1 - 2)-fraction of G? are
very close to the true mean and covariance of f(X, p). Formally, for any subset T ⊂ G? with
|T| ≥ (1 - 2e)N, We require the following to hold for δι = Eʌ/lnl/e and δ2 = E ln(1∕e):
∣T∣ Xf (Xi,P)	≤ O(δι) ,
ITI i∈T
ITT X f(Xi,PIf(Xi,pτ - ς
|T| i∈T
≤ O(δ2) ,	(3)
2
2
where Σ = Cov[f (X, P)] = diag(πP ◦ P ◦ (1 - P)).
5
Published as a conference paper at ICLR 2021
2.4	Robust Mean Estimation and Stability Conditions
Robust mean estimation is the problem of learning the mean of a d-dimensional distribution from
an -corrupted set of samples. As we will see in later sections, to robustly learn Bayesian networks,
we repeatedly use robust mean estimation algorithms as a subroutine.
Recent work (Diakonikolas et al., 2019a; Lai et al., 2016) gave the first polynomial-time algorithms
for robust mean estimation with dimension-independent error guarantees. The key observation in Di-
akonikolas et al. (2019a) is the following: if the empirical mean is inaccurate, then many samples
must be far from the true mean in roughly the same direction. Consequently, these samples must
alter the variance in this direction more than they distort the mean. Therefore, if the empirical co-
variance behaves as we expect it to be, then the empirical mean provides a good estimate to the true
mean.
Many robust mean estimation algorithms follow the above intuition, and they require the following
stability condition to work (Definition 2.5). Roughly speaking, the stability condition states that
the mean and covariance of the good samples are close to that of the true distribution, and more
importantly, this continues to hold if we remove any 2-fraction of the samples.
Definition 2.5 (Stability Condition (see, e.g., Diakonikolas & Kane (2019))). Fix 0 < e < 1. Fix
a d-dimensional distribution X with mean μχ. We say a set S of samples is (e, β, γ)-stable with
respect to X, iffor every subset T ⊂ S with |T | ≥ (1 - 2)|S |, the following conditions hold:
(i)	U而 Px∈t (X - μx)∣∣2 ≤ β , (ii) U而 Px∈t (X - μx) (X - μx)> - I∣∣2 ≤ γ .
Subsequent work (Cheng et al., 2019a; Dong et al., 2019; DePersin & Lecue, 2019) improved the
runtime of robust mean estimation to nearly-linear time. Formally, we use the following result
from Dong et al. (2019). A set S is an -corrupted version ofa set T if |S| = |T | and |S\T | ≤ |S|.
Lemma 2.6 (Robust Mean Estimation in Nearly-Linear Time (Dong et al., 2019)). Fix a set ofN
samples G? in Rd. Suppose G? is (, β, γ)-stable with respect to a d-dimensional distribution X
with mean μχ ∈ Rd. Let S be an E-corrupted version of G?. Given as input S, G β, Y, there exists
an algorithm that can output an estimator μ ∈ Rd in time O(Nd), such that with high probability,
kμ - μX k2 ≤ Q√γ + B + Eplog 1/E).
As we will see later, a black-box use of Lemma 2.6 does not give the desired runtime in our setting.
Instead, we extend Lemma 2.6 to handle sparse input such that it runs in time nearly-linear in the
number of non-zeros in the input (see Lemma 3.3).
3	Overview of Our Approach
In this section, we give an overview of our approach and highlight some of our key technical results.
To robustly learn the ground-truth Bayesian network P, it is sufficient to learn its conditional prob-
abilities p ∈ Rm . At a high level, we start with a guess q ∈ Rm for p and then iteratively improve
our guess to get closer to p. For any q ∈ Rm , we can expand the input samples into m-dimensional
vectors f(X, q) as in Definition 2.2. We first show that the expectation of f(X, q) gives us useful
information about (p - q).
Recall that πP is the parental configuration probabilities of P . By Lemma 2.4, we have
EX〜p[f (X, q)] = ∏P ◦ (p - q).
Note that if we had access to this expectation and the vector πP, we could recover p immediately:
We can set q0 = E[f (X, q)] ◦ (1∕∏p) + q which simplifies to q0 = p.
Note that since S is an E-corrupted set of samples ofP, we know that {f(Xi, q)}i∈S is an E-corrupted
set of samples of the distribution f (X, q) (with X 〜 P). Therefore, we can run robust mean
estimation algorithms on {f(Xi, q)}i∈S to learn E[f (X, q)]. It turns out a good approximation of
E[f (X, q)] can help us improve our current guess q.
There are two main difficulties in getting this approach to work.
6
Published as a conference paper at ICLR 2021
The first difficulty is that, to use robust mean estimation algorithms, we need to show that f (X, q)
satisfies the stability condition in Definition 2.5. This requires us to analyze the first two moments
and tail bounds of f(X, q). Consider the second moment for example. Ideally, we would like to
have a statement of the form Cov[f (X, q)] ≈ Cov[f (X, p)] + (p - q)(p - q)>, but this is false
because we only have f (X, p)k - f(X, q)k = (p - q)k if the k-th parental configuration happens
for X. Intuitively, the “error” (p - q) is shattered into all samples where each sample only gives d
out of m coordinates of (p - q), and there is no succinct representation for Cov[f (X, q)].
The second difficulty is that f(X, q) is m-dimensional. We cannot explicitly write down all the sam-
Ples {f (Xi, q)}N=ι, because this takes time Ω(Nm), which could be much slower than our desired
running time of O(N d). Similarly, a black-box use of nearly-linear time robust mean estimation
algorithms (e.g., Lemma 2.6) runs in time Ω(Nm), which is too slow.
In the rest of this section, we exPlain how we handle these two issues.
Stability Condition of f(X, q). Because the second-order stability condition in Lemma 2.3 is
defined with resPect to I, we first scale the samPles so that the covariance of f(X, p) becomes I.
Lemma2.3 shows that Cov[f (X,p)] = diag(πp ◦ P◦ (1-p)). To make it close to I, we can multiply
the k-th coordinate of f(X, p) by (πkPpk (1 - pk))-1/2. However, we do not know the exact value
of πP or p, instead we use the corresponding empirical estimates πS and qS (see Algorithm 1).
Definition 3.1. Let πs and qs denote the parental configuration probabilities and conditional means
estimated over S. Let S = 1/ √(πs0qs0(l-7s)). Throughout this paper Jor a vector V ∈ Rm,
we use v ∈ Rm to denote V ◦ S. In particular, we have Xi = Xi ◦ S (and similarly P, q, f (x, q)).
Now we analyze the concentration bounds for f(X, q). Formally, we prove the following lemma.
Lemma 3.2. Assume the conditions in Section 2.3 hold for the original set of good samples G?.
Then, for δι = E ʌ/logl/e and δ2 = E log(l/e), the set of samples {∕(Xi, q)h∈G? is
(3 O ( √α + E kp — q∣∣2), O (-- + B + √B) ) -stable,
where B = ∣∣√πp◦ (P — q)k2.
We provide some intuition for Lemma 3.2 and defer its proof to Appendix B.
For the first moment, the difference between E[f (X, q)] and the empirical mean of f(X, q) comes
from several places. Even if q = P, we would incur an error of δ1 from the concentration bound in
Equation equation 3, which is at most δ1(--)-1/2 after the scaling by S. Moreover, on average πkP
fraction of the samples gives us information about (P — ^)k. Since an E-fraction of the samples are
removed when proving stability, we may only have (πkP - E)-fraction instead, which introduces an
error of E ∣p — q∣2. This is why the first-moment parameter is (δι(αc)-1/2 + E ∣p — q∣b).
For the second moment, after the scaling, we have Cov[f (X, P)] ≈ I. Ideally, we would like to
prove Cov[f(X, q)] ≈ I + (∏p ◦ (P — q))(∏P ◦ (P — q))>, but this is too good to be true. For two
coordinates k = ', whether a sample gives information about (P- ^)k or (P- ^)' is not independent.
We can upper bound the probability that both parental configurations happen by min(∏p, ∏p). If
they were independent we would have a bound of ∏p∏p. The difference in these two upper bounds
is intuitively why √πp appears in the second-moment parameter. See Appendix B for more details.
Robust Mean Estimation with Sparse Input. To overcome the second difficulty, we exploit the
sparsity of the expanded vectors. Observe that each vector f(X, q) is guaranteed to be d-sparse
because exactly d parental configuration can happen (see Definition 2.2). The same is true for
f(X, q) because scaling does not change the number of nonzeros. Therefore, there are in total
O(N d) nonzero entries in the set of samples {f (X, q)}i∈S.
We develop a robust mean estimation algorithm that runs in time nearly-linear in the number of
nonzeros in the input. Combined with the above argument, if we only invoke this mean estimation
algorithm polylogarithmic times, we can get the desired running time of O(Nd).
7
Published as a conference paper at ICLR 2021
Lemma 3.3. Consider the same setting as in Lemma 2.6. Suppose kX k2 ≤ R for all X ∈ S. There
is an algorithm Amean With the same error guarantee that runs in time O(log R ∙ (nnz(S) + N + d))
where nnz(S) is the total number of nonzeros in S. That is, given an -corrupted version of an
(e, β, γ) -stable set of N samples w.r.t. a d-dimensional distribution with mean μχ, the algorithm
Amean OutPutS an estimator μ ∈ Rd in time O (log R ∙ (nnz(S) + N + d)) such that with high
probability, kμ 一 μχ|卜 ≤ O(√eγ + β + Cʌ/logl/e).
We prove Lemma 3.3 by extending the algorithm in Dong et al. (2019) to handle sparse input. The
main computation bottleneck of recent nearly-linear time robust mean estimation algorithms (Cheng
et al., 2018; Dong et al., 2019) is in using the matrix multiplicative weight update (MMWU) method.
In each iteration of MMWU, a score is computed for each sample. Roughly speaking, this score in-
dicates whether one should continue to increase the weight on the corresponding sample. Previous
algorithms use the Johnson-Lindenstrauss lemma to approximate the scores for all N samples si-
multaneously. We show that the sparsity of the input vectors allows for faster application of the
Johnson-Lindenstrauss lemma, and all N scores can be computed in time nearly-linear in nnz(S).
We defer the proof of Lemma 3.3 to Appendix C.
4 Robust Learning of Bayesian Networks in Nearly-Linear Time
In this section, we prove our main result. We present our algorithm (Algorithm 1) and prove its
correctness and analyze its running time (Theorem 4.1).
Theorem 4.1. Fix 0 < C < C0 where C0 is a sufficiently small universal constant. Let P be a
c-balanced Bayesian network on {0, l}d with known structure H. Let α be the minimum parental
configuration probability of P. Assume α = C(c2/3c-1/3).
Let S be an c-corrupted set of N = Ω(m∕c2) samples drawn from P. Given H, S, c, c, and a,
Algorithm 1 outputs a Bayesian network Q in time O(Nd) such that, with probability at least 9/l0,
dTV(P,Q) ≤ O(c,∣og(1∕c)∕√OC).
The c and α terms in the error guarantee also appear in prior work (Cheng et al., 2018). Removing
this dependence is an important technical question that is beyond the scope of this paper.
Theorem 4.1 follows from three key technical lemmas. At the beginning of Algorithm 1, we first
scale all the input vectors as in Definition 3.1. We maintain a guess q for p and gradually move it
closer to p. In our analysis, We track our progress by the '2-norm of πp ◦ (P — q).
Initially, We set q to be the empirical conditional mean over S. Lemma 4.2 proves that
∣∣∏p ◦ (P — q0)∣∣2 is not too large for our first guess. Lemma 4.3 shows that, as long as q is still
relatively far from p, we can compute a new guess such that ∣∣∏p ◦ (P — q)b decreases by a con-
stant factor. Lemma 4.4 states that, when the algorithm terminates and ∣∣∏p ◦ (P — q)∣∣2 is small,
we can conclude that the output Q is close to the ground-truth P in total variation distance.
In the following three lemmas, we consider the same setting as in Theorem 4.1 and assume the
conditions in Section 2.3 hold.
Lemma 4.2 (Initialization). In Algorithm 1, we have
I∣∏p ◦ (P — q0)∣∣2 ≤ O(c√d∕√αc).
Lemma 4.3 (Iterative Refinement). Fix an iteration t in Algorithm 1. Assume the robust mean
estimation algorithm Amean succeeds. If ∣∣πp ◦ (P — qt)∣∣2 ≤ Pt and Pt = Ω(c/log(1∕c)∕√OC),
then we have ∣∣πp ◦ (P — qt+1)∣∣2 ≤ cιρt for some universal constant ci < 1.
Lemma 4.4. Let Q be a Bayesian network that has the same structure as P. Suppose that (1) P is
C-balanced, (2) α = Ω(r + c∕c), and (3) ∣∣πp ◦ (P — q)∣∣2 ≤ r∕2. Then we have dτv(P, Q) ≤ r.
We defer the proofs of Lemmas 4.2, 4.3, and 4.4 to Appendix D and we first prove Theorem 4.1.
Proof of Theorem 4.1. We first prove the correctness of Algorithm 1.
8
Published as a conference paper at ICLR 2021
Algorithm 1: Robustly Learning Bayesian Networks
Input : The dependency graph H of a c-balanced Bayesian network P with minimum
parental configuration α, an E-CorrUPted set S of N = Ω(m∕e2) samples {Xi}N=ι
drawn from P, and the values of , c and α.
Output: A Bayesian network Q such that, with probability at least 9/10,
dTV(P,Q) ≤ O(EpogE/√0c).
Compute the empirical probabilities πS where πS(i, a) = PrX∈S [Πi,a];
Compute the empirical conditional probabilities qS where qS (i, a) = PrX∈S [X (i) = 1 | Πi,a];
Compute the scaling vector s = 1/，(πs ◦ qs ◦ (1 — qs));
Let T = O(log d) and q0 = qS;
Let ρ0 = O(e√d/√0c). (We maintain upper bounds Pt s.tjπp ◦ (P - qt)b ≤ Pt for all t);
for t = 0 to T — 1 do
βt =O(EPt/α), Yt =O((Pt)2/α + ρt∕√α);
Solve a robust mean estimation problem. Let V = Amean ({f(Xi, qt')i∈s}, e, βt, γt);
qt+1 = V ◦ (1/s) ◦ (1/nS) + qt;	ρt+1 = cιpt;
return the Bayesian network Q with graph H and conditional probabilities qT ;
The original set of N = Ω(m log(m/E”E2) good samples drawn from P satisfies the conditions in
Section 2.3 with probability at least 1 - 20. With high probability, the robust mean estimation oracle
Amean succeeds in all iterations. For the rest of this proof, we assume the above conditions hold,
which by a union bound happens with probability at least 9/10.
From Lemma 4.2, we have the following condition on the initial estimate q0 .
IlnP ◦ (P - q0)∣∣2 = o(E√d/√0c).
We start with an upper bound ρ0 of ∣∣πp ◦ (P - q0)∣∣2 = O(E√d/√αc). By Lemma 4.3, in each
iteration, if ρt = Ω(eʌ/lθg(ɪ/e)/√0c), we can obtain a new estimate qt+1 and an upper bound ρt+1
on ∣∣np ◦ (P - qt)∣∣2 such that ρt+1 is smaller than ρt by a constant factor. Hence after O(log(d))
iterations, we can get a vector qt such that
∣∣∏p ◦ (P - qt)∣∣2 =O(E√log(1/E)/√0c).
Let Q be the Bayesian network with conditional probability table qt . The assumption that α =
Ω(E2/3CT/3) allows us to apply Lemma 4.4 with r = O(E，log(1/E)/√αc), which gives the
claimed upper bound on dTV (P, Q).
Now we analyze the runtime of Algorithm 1. First, qS and πS can be computed in time Oe(N d)
because each sample only affects d entries of q. We do not explicitly write down f (X, q). In each
iteration, we solve a robust mean estimation problem with input
{ f(Xi, qt)}	, which takes time
O(N d). This is because there are N input vectors, each vector is d-sparse, and the robust mean
estimation algorithm runs in time nearly-linear in the number of nonzeros in the input (Lemma 3.3).
We can compute qt+1 = V ◦ (1/s) ◦ (1/nS) + qt in time in time O(m).
Since there are O(log d) iterations, the overall running time is
Oe(Nd) + O(log d) Oe(Nd) + O(m) = Oe(Nd) .
□
Acknowledgments
Part of this work was done while Yu Cheng was visiting the Institute of Advanced Study. Part of this
work was done while Honghao Lin was an undergraduate student at Shanghai Jiao Tong University.
9
Published as a conference paper at ICLR 2021
References
P. Abbeel, D. Koller, and A. Y. Ng. Learning factor graphs in polynomial time and sample complex-
ity. J. Mach. Learn. Res.,7:1743-1788, 2006.
E. Amaldi and V. Kann. The complexity and approximability of finding maximum feasible subsys-
tems of linear relations. Theoretical Computer Science, 147:181-210, 1995.
A. Anandkumar, D. J. Hsu, F. Huang, and S. Kakade. Learning mixtures of tree graphical models. In
Proc. 26th Advances in Neural Information Processing Systems (NeurIPS), pp. 1061-1069, 2012.
S. Balakrishnan, S. S. Du, J. Li, and A. Singh. Computationally efficient robust sparse estimation in
high dimensions. In Proc. 30th Conference on Learning Theory (COLT), pp. 169-212, 2017.
G. Bresler. Efficiently learning Ising models on arbitrary graphs. In Proc. 47th Annual ACM Sym-
posium on Theory of Computing (STOC), pp. 771-782, 2015.
G. Bresler, E. Mossel, and A. Sly. Reconstruction of Markov random fields from samples: Some
observations and algorithms. SIAM J. Comput., 42(2):563-578, 2013.
G. Bresler, D. Gamarnik, and D. Shah. Structure learning of antiferromagnetic Ising models. In
Proc. 28th Advances in Neural Information Processing Systems (NeurIPS), pp. 2852-2860, 2014.
C. L. Canonne, I. Diakonikolas, D. M. Kane, and A. Stewart. Testing Bayesian networks. In Proc.
30th Conference on Learning Theory (COLT), volume 65, pp. 370-448, 2017.
T. M. Chan. An optimal randomized algorithm for maximum Tukey depth. In Proc. 15th ACM-SIAM
Symposium on Discrete Algorithms (SODA), pp. 430-436, 2004.
M. Charikar, J. Steinhardt, and G. Valiant. Learning from untrusted data. In Proc. 49th Annual ACM
Symposium on Theory of Computing (STOC), pp. 47-60, 2017.
M. Chen, C. Gao, and Z. Ren. Robust covariance and scatter matrix estimation under Huber’s
contamination model. The Annals of Statistics, 46(5):1932-1960, 2018.
Y. Cheng, I. Diakonikolas, D. M. Kane, and A. Stewart. Robust learning of fixed-structure Bayesian
networks. In Proc. 32nd Advances in Neural Information Processing Systems (NeurIPS), pp.
10304-10316, 2018.
Y. Cheng, I. Diakonikolas, and R. Ge. High-dimensional robust mean estimation in nearly-linear
time. In Proc. 30th ACM-SIAM Symposium on Discrete Algorithms (SODA), pp. 2755-2771,
2019a.
Y. Cheng, I. Diakonikolas, R. Ge, and D. P. Woodruff. Faster algorithms for high-dimensional
robust covariance estimation. In Proc. 32nd Conference on Learning Theory (COLT), pp. 727-
757, 2019b.
Y. Cheng, I. Diakonikolas, R. Ge, and M. Soltanolkotabi. High-dimensional robust mean estimation
via gradient descent. In Proc. 37th International Conference on Machine Learning (ICML), pp.
1768-1778, 2020.
Y. Cherapanamjeri, E. Aras, N. Tripuraneni, M. I. Jordan, N. Flammarion, and P. L. Bartlett. Optimal
robust linear regression in nearly linear time. arXiv preprint arXiv:2007.08137, 2020a.
Y. Cherapanamjeri, S. Mohanty, and M. Yau. List decodable mean estimation in nearly linear
time. In Proc. 61st IEEE Symposium on Foundations of Computer Science (FOCS), pp. 141-
148, 2020b.
C. Chow and C. Liu. Approximating discrete probability distributions with dependence trees. IEEE
Trans. Inf. Theor., 14(3):462-467, 1968.
K. L. Clarkson, D. Eppstein, G. L. Miller, C. Sturtivant, and S.-H. Teng. Approximating center
points with iterated Radon points. In Proc. 9th Annual Symposium on Computational Geometry
(SoCG), pp. 91-98, 1993.
10
Published as a conference paper at ICLR 2021
R.	Daly, Q. Shen, and S. Aitken. Learning Bayesian networks: approaches and issues. The Knowl-
edge EngineeringReview, 26:99-157, 201LISSN 1469-8005.
S.	Dasgupta. The sample complexity of learning fixed-structure Bayesian networks. Machine Learn-
ing, 29(2-3):165-180, 1997.
J. DePersin and G. Lecue. Robust SUbgaUssian estimation of a mean vector in nearly linear time.
arXiv preprint arXiv:1906.03058, 2019.
L. Devroye and L. Gyorfi. Nonparametric Density Estimation: The Li View. John Wiley & Sons,
1985.
I. Diakonikolas and D. M. Kane. Recent advances in algorithmic high-dimensional robust statistics.
arXiv preprint arXiv:1911.05911, 2019.
I. Diakonikolas, G. Kamath, D. M. Kane, J. Li, A. Moitra, and A. Stewart. Being robust (in high di-
mensions) can be Practical. In Proc. 34th International Conference on Machine Learning (ICML),
PP. 999-1008, 2017a.
I. Diakonikolas, D. M. Kane, and A. Stewart. Statistical query lower bounds for robust estima-
tion of high-dimensional Gaussians and Gaussian mixtures. In Proc. 58th IEEE Symposium on
Foundations of Computer Science (FOCS), PP. 73-84, 2017b.
I. Diakonikolas, D. M. Kane, and A. Stewart. List-decodable robust mean estimation and learning
mixtures of sPherical Gaussians. In Proc. 50th Annual ACM Symposium on Theory of Computing
(STOC), PP. 1047-1060, 2018.
I. Diakonikolas, G. Kamath, D. M. Kane, J. Li, A. Moitra, and A. Stewart. Robust estimators in
high dimensions without the comPutational intractability. SIAM Journal on Computing, 48(2):
742-864, 2019a.
I. Diakonikolas, G. Kamath, D. M. Kane, J. Li, J. Steinhardt, and A. Stewart. SEVER: A robust
meta-algorithm for stochastic oPtimization. In Proc. 36th International Conference on Machine
Learning (ICML), PP. 1596-1606, 2019b.
I. Diakonikolas, W. Kong, and A. Stewart. Efficient algorithms and lower bounds for robust linear
regression. In Proc. 30th ACM-SIAM Symposium on Discrete Algorithms (SODA), PP. 2745-2754,
2019c.
I. Diakonikolas, D. M. Kane, D. Kongsgaard, J. Li, and K. Tian. List-decodable mean estimation in
nearly-PCA time. arXiv preprint arXiv:2011.09973, 2020.
Y. Dong, S. B. HoPkins, and J. Li. Quantum entroPy scoring for fast robust mean estimation and
imProved outlier detection. In Proc. 33rd Advances in Neural Information Processing Systems
(NeurIPS), PP. 6065-6075, 2019.
S. B. HoPkins and J. Li. Mixture models, robustness, and sum of squares Proofs. In Proc. 50th
Annual ACM Symposium on Theory of Computing (STOC), PP. 1021-1034, 2018.
P. J. Huber. Robust estimation ofa location Parameter. Ann. Math. Statist., 35(1):73-101, 03 1964.
F. V. Jensen and T. D. Nielsen. Bayesian Networks and Decision Graphs. SPringer Publishing
ComPany, IncorPorated, 2nd edition, 2007.
D. S. Johnson and F. P. PreParata. The densest hemisPhere Problem. Theoretical Computer Science,
6:93-107, 1978.
A. Klivans, P. Kothari, and R. Meka. Efficient algorithms for outlier-robust regression. In Proc. 31st
Conference on Learning Theory (COLT), PP. 1420-1430, 2018.
D. Koller and N. Friedman. Probabilistic Graphical Models: Principles and Techniques - Adaptive
Computation and Machine Learning. The MIT Press, 2009.
11
Published as a conference paper at ICLR 2021
P. K. Kothari, J. Steinhardt, and D. Steurer. Robust moment estimation and improved clustering via
sum of squares. In Proc. 50th Annual ACM Symposium on Theory of Computing (STOC), pp.
1035-1046, 2018.
K.	A. Lai, A. B. Rao, and S. Vempala. Agnostic estimation of mean and covariance. In Proc. 57th
IEEE Symposium on Foundations of Computer Science (FOCS), 2016.
J. Li and G. Ye. Robust Gaussian covariance estimation in nearly-matrix multiplication time. In
Proc. 34th Advances in Neural Information Processing Systems (NeurIPS), 2020.
L.	Liu, Y. Shen, T. Li, and C. Caramanis. High dimensional robust sparse regression. In Proc. 23rd
International Conference on Artificial Intelligence and Statistics (AISTATS), pp. 411-421, 2020.
P. L. Loh and M. J. Wainwright. Structure estimation for discrete graphical models: Generalized
covariance matrices and their inverses. In Proc. 26th Advances in Neural Information Processing
Systems (NeurIPS), pp. 2096-2104, 2012.
G.L. Miller and D. Sheehy. Approximate centerpoints with proofs. Comput. Geom., 43(8):647-654,
2010.
R. E. Neapolitan. Learning Bayesian Networks. Prentice-Hall, Inc., 2003.
A. Prasad, A. S. Suggala, S. Balakrishnan, and P. Ravikumar. Robust estimation via robust gradient
estimation. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 82(3):
601-627, 2020.
N. P. Santhanam and M. J. Wainwright. Information-theoretic limits of selecting binary graphical
models in high dimensions. IEEE Trans. Information Theory, 58(7):4117-4134, 2012.
J. Steinhardt, M. Charikar, and G. Valiant. Resilience: A criterion for learning in the presence
of arbitrary outliers. In In Proc. 9th Innovations in Theoretical Computer Science Conference
(ITCS), pp. 45:1-45:21, 2018.
J. W. Tukey. Mathematics and picturing of data. In Proceedings of ICM, volume 6, pp. 523-531,
1975.
R. Vershynin. Introduction to the non-asymptotic analysis of random matrices. arXiv preprint
arXiv:1011.3027, 2010.
M. J. Wainwright and M. I. Jordan. Graphical models, exponential families, and variational infer-
ence. Found. Trends Mach. Learn., 1(1-2):1-305, 2008.
M. J. Wainwright, P. Ravikumar, and J. D. Lafferty. High-dimensional graphical model selection
using `1 -regularized logistic regression. In Proc. 20th Advances in Neural Information Processing
Systems (NeurIPS), pp. 1465-1472, 2006.
B. Zhu, J. Jiao, and J. Steinhardt. Robust estimation via generalized quasi-gradients. arXiv preprint
arXiv:2005.14073, 2020.
12
Published as a conference paper at ICLR 2021
A Deterministic Conditions on Good Samples
In this section, we will first prove Lemma 2.3, then we prove that the deterministic conditions in
Section 2.3 hold with high probability if we take enough samples.
Lemma A.1. For X 〜P and f (X,p) as defined in Definition 2.2, we have
(i)	E(f (X, p)) =0.
(ii)	Cov[f (X, p)] = diag(πP ◦ p ◦ (1 - p)).
(iii)	For any unit vector V ∈ Rm, we have PrX〜P [∣v>f (X,p)| ≥ T] ≤ 2exp(-T2/2).
Proof. We first claim that EX〜p[f (X,p)k∣f (X,p)ι,…，f (X,p)k-ι] = 0 for all k ∈ [m]. Let k =
(i, a), conditioned on f(X,p)1, ..., f (X, p)k-1, the event πi,a may or may not happen. A simple
calculation shows that in both cases, We have EX〜P[f (X,p)k|f (X,p)ι,…，f (X,p)k-ι] = 0.
For (i), we have E[f (X, p)] = πP ◦ p + (1 - πP) ◦p - p = 0.
For (ii), we first show that for any (i, a) 6= (j, b), we have E[f(X, p)i,af(X, p)j,b] = 0. For the
case i = j, we can see at least one of Πi,a and Πj,b does not occur, so f(X, p)i,af (X, p)j,b is
always 0. For the case i 6= j, we assume without loss of generality that i > j, then we have
E[f(X,p)i,a|f(X,p)j,b] =0.
For all (i, a) ∈ [m], we have E[f (X,p)2,a] = ∏PaE[(X - Pi,a)2∣∏i,a] = ∏PaPi,a(1 - Pi,a) Com-
bining these two, we get Cov[f (X, p)] = diag(πP ◦ p ◦ (1 - p)).
For (iii), we recall that EX〜P[f (X,p)k |f (X,p)ι,..., f (X,p)k-ι] = 0, thus the sequence
Pk=I Vkf(X,q)k for 1 ≤ ' ≤ m is a martingale, and we can apply Azuma’s inequality. Note
that |vk| ≥ |Vkf(X,p)k∣, hence we have PrX〜P [∣v>f (X,p)∣ ≥ T] ≤ 2exp(-T2/2 ∣∣vk2)=
2exp(-T 2/2).	□
The conditions in Equations equation 1 and equation 2 are proved in Lemma A.2, and the conditions
in Equation equation 3 are proved in Corollary A.4.
LemmaA.2. Let P be a Bayesian network. Let G? be a setof Ω((m log(m/T))/e2) samples drawn
from P. Let πG? and pG? be the empirical parental configuration probabilities and conditional
probabilities of P given by G?. Then with probability 1 - τ, the following conditions hold:
(i)	For any subset T ⊂ G? with |T| ≥ (1 - 2)N, we have
πT-πP∞≤O() .
(ii)
∣∣√∏P ◦ (p - PG?)∣∣2 ≤ O(e).
Proof. For (i), first consider the case of T = G? and fix an entry 1 ≤ k ≤ m in the conditional
probability table. Because each sample is drawn independently from P, by the Chernoff bound, we
have that when N = Ω(log(m")/e2), ∣πf - πG? | ≤ E holds with probability at least 1 - 丁/m.
Hence, after taking an union bound over k, we have that∣πT - πP∣∞ ≤ E holds with probability
at least 1 - τ. Now for a general subset T ⊂ G?, notice that removing O(E)-fraction of samples can
change πT by at most O(E). Thus, condition (i) holds with probability at least 1 - τ.
For (ii), for any k = (i, a), note that pkG? is estimated from πkG? N samples. In these samples, the
parental configuration ∏k happens and the value of Xi is decided independently. By the Chernoff
bound and the union bound, we get that when N = Ω((m log(m/T))/e2), |pG? - Pk | ≤ "JmnG?
holds for every k with probability at least 1 - τ, which implies
∣∣√πG? ◦ (p - PG? )∣∣2 ≤ O(e).
Combining this with ∣∣πP - ∏G* ∣∣∞ ≤ e, we get that condition (ii) holds.	□
13
Published as a conference paper at ICLR 2021
To prove Equation equation 3, we use the following concentration bounds for subgaussian distribu-
tions. Recall that a distribution D on Rd with mean μ is SUbgaUssian if for any unit vector V ∈ Rd
We have Prx 〜D [|〈v, X — μi∣ ≥ t] ≤ exp(-ct2), where C is a universal constant.
Lemma A.3. Let G? be a set of N = Ω((e √logl∕e)-2(d + log(1∕τ))) samples drawn from a
d-dimensional Subgaussian distribution with mean μ and covariance matrix Σ W I. Here A W B
means that B - A is a positive semi-definite matrix. Then, with probability l - τ, the following
conditions hold:
For δι = cι(e ʌ/logl/e) and δ2 = q(e logl/e) where ci is an universal constant, we have that for
any subset T ⊂ G? with |T | ≥ (l - 2)N,
∣T∣ X(Xi- μ)
i∈T
≤ δ1 ,
2
团 X(Xi - M)(Xi - μ)> - ς
∣T ∣ i∈T
≤ δ2	(4)
2
A special case of Lemma A.3 where Σ = I is proved in Diakonikolas et al. (2019a). The proof
for the general case where Σ W I is almost identical. In particular, the concentration inequali-
ties used in Diakonikolas et al. (2019a) for subgaussian distributions still hold when Σ W I (see,
e.g., Vershynin (2010)).
From Lemma A.3 and 2.3, we have the following corollary:
Corollary A.4. Let G? be a set of N = Ω((e∙∖∕log1∕e)-2(m + log(1∕τ))) samples drawn P.
Then, with probability 1 一 T, the following conditions to hold: For δι = q(e ʌ/logl/e) and δ2 =
c1(log l/), where c1 is an universal constant, we have that for any subset T ⊂ G? with ∣T ∣ ≥
(1 - 2)N,
卷 X f(Xi,p)	≤ O(δi),
i∈T
2
∣T∣ X f (Xi,p)f (Xi,p)τ 一 ς ≤ O(δ2) ,
i∈T	2
(5)
where Σ = Cov[f (X, p)] = diag(πP ◦ p ◦ (1 一 p)).
-.ʌ	1~,	/ -r r- ∖
B S TAB ILITY CONDITION OF f (X, q)
T .< ∙	. ∙	. 1	. 1 ∙1 ∙ .	∙>♦,♦	i' .Λ	1	2∕PT- ∖ ZT	C C∖ T-I	11 . 1
In this section, we prove the stability condition for the samples f(X, q) (Lemma 3.2). Recall the
1 C ∙ . ∙	i' 2 / Fk ∖ i'	1 ʌ C ∙ . ∙	CC	∙> C <	-»-v T r∙	.	. T	CC
definition of f(X, q) from Definitions 2.2 and 3.1. We first restate Lemma 3.2.
Lemma 3.2. Assume the conditions in Section 2.3 hold for the original set of good samples G?.
Then, for δι = E ʌ/logl/e and δ2 = E log(l/e), the set of samples {∕(Xi, q)h∈G? is
e, O ( √α + E ∣∣p 一 q∣∣2), O (-- + B + √B) ) -stable,
where B = ∣∣√∏p◦ (P — q)∣2.
I-V T	∙ 11	.1	. F ∙ 1 ∙ .	i' f / TT- ∖ EI	. Λ ∙1 ∙ .	i' 2 / F7 ∖ C 11	1 ∙	. 1	5 T ♦ . Λ
We will prove the stability of f(X, q). The stability of f(X, q) follows directly. We introduce a
matrix CD,q which is crucial in proving the stability of f(X, q). Intuitively, the matrix CD,q is
related to the difference in the covariance of f(X,p) and that of f(X, q) on the sample set D.
Definition B.1. For any set D of samples {Xi}i∈D, we define the following m × m matrix
CD,q = TDT X(f (Xi,p) - f (Xi, q))(f (Xi,p) — f (Xi, q))> ∙
∣D∣ i∈D
Observe that for x ∈ {0, 1}d with x ∈/ Πk, we have f(x, p)k = f(x, q)k = 0. On the other hand, if
X ∈ Πk for some k = (i,a), we have f(x,p)k — f (x, q)k = (Xi — Pk) — (Xi — qk) = qk — Pk.
In the very special case where all parental configurations happen (i.e., a binary product distribution),
we would have CD,q = (P — q)(P — q)τ. However, in general the information related to (P — q) is
spread among the samples. We show that even though CD,q does not have a succinct representation,
we can prove the following upper bound on the spectral norm of CD,q .
14
Published as a conference paper at ICLR 2021
Lemma B.2. kCD,qk2 ≤ PkπkD(pk - qk)2 .
Proof. For notational convenience, let C = CD,q. For every 1 ≤ k, ` ≤ m, we have
∣Ck,'∣ = ∣(Pr[∏k ∧ n`])(pk - qk)(p` - q')∣ ≤ min{∏D,∏D}∙ |(pk - qk)(p` - q')∣
≤ (qπD|(Pk -qkX)∙ (qπD|(P' -q'X)
We can upper bound the spectral norm of C in term of its Frobenius norm:
kC k2 ≤ kC kF = X C2,' ≤ X(∏D (Pk-qk)2)(∏D (p`-g`)2) ≤ (X ∏D (Pk- qk )) ∙
, , □
The following lemma essentially proves the stability of f(X, q), except that in the second-order
condition, we should have Cov(f (X, q)) instead of Σ. We will bridge this gap in Lemma B.4.
Lemma B.3. Assume the conditions in Section 2.3 hold. For δι = E ʌ/ɪogɪ/e and δ2 = E log(1∕e),
we have that for any subset T ⊂ G? with |T| ≥ (1 - )|G?|,
≤ O(δ1 + E kp - qk2) , and
2
面 X(f (Xi q) - πP ◦ (P - q))
i∈T
ɪ X(f(Xi, q) - ∏p ◦ (P - q))(f (Xi,q) - ∏p ◦ (p - q))> - ∑
|T | i∈T
where B = ∣∣√πp◦ (p — q)∣∣ ≤ 1 ∣∣∏P ◦ (p — q)∣∣2, and ∑ = diag(π
covariance of f(X, P) .
≤ O(δ2 + B + √B)
2
P ◦ P ◦ (1 - P)) is the true
Proof. For the first moment, we have
|T| X(f (Xi, q) - πP ◦ (p - q))
|T | i∈T
|T| X(f (Xi,p) + f (Xi, q) - f (Xi,p) - πP ◦ (p - q))
| | i∈T
T X f(xi,p)	+
| | i∈T	∣2
≤
团 X(f (Xi q) - f (Xi,p) - πP (p - q))
|T | i∈T
2
TX f (XMp)	+ ∣∣(πT - πP) ◦ (p - q)∣∣2 = O(δι +E kp - qk2) ∙
|T | i∈T	∣2
For the second moment, consider any unit vector v ∈ Rm . We have
v> (力 X f(Xi, q)f(Xi, q)>) v =力 Xhf(Xi, q), vi2
=ɪ X(hf(Xi,p),v>2 +(“Xi,p) - f (Xi,q),vi2 +2hf(Xi,p),vihf (Xi,p) - f (Xi,q),vi)
|T| i∈T
15
Published as a conference paper at ICLR 2021
where the last inequality follows from the Cauchy-Schwarz inequality. Therefore, we have
|T| X f (Xi Gf(Xi q)T - ς
|T | i∈T
2
≤
团 X f (Xi,p)f (Xi,P)T - ς
|T| i∈T
2
+
团 X(f (Xi, P)- f (Xi q))(f (Xi, P)- f (Xi q))T
|T| i∈T
2
+2
∖ 团 X f (Xi,P)f (Xi,p)T
∣T ∣ i∈T
2
∣T∣ X(f (Xi, P)- f (Xi, q))(f (Xi, P)- f (Xi, q))T
∣T ∣ i∈T
2
≤ δ2 + IICT,q l∣2 + * 2 * *P1 + δ2 JllCT,q ∣∣2 = O (δ2 + ∣∣CT,q ∣∣2 + J∣∣CT,q ∣∣2)
Finally, We show that the second moment matrix 击 Pii∈τ f (Xi, q)f (Xi, q)τ is not too far from
the empirical covariance matrix of f(X, q).
ɪ Xf (Xi, q)f (Xi, q)τ - ɪ X(f(Xi, q) - ∏p ◦ (p - q))(f (X，q) - ∏p ◦ (p - q))τ
i∈T	i∈T
2
≤2
∣Tl X(f(Xi,q)- ∏P
|T| i∈T
◦ (P - q))	lπP ◦ (P - q)l2 + lπP ◦ (P - q)l22
2
≤ O ((δ1 + kP - qk2) kπP ◦ (P - q)k2) ≤ O kπP ◦ (P - q)k22 .
Putting everything together and using Lemma B.2, we conclude this proof.
□
O(Oc).
The stability of f(X, q) follows from the stability of f(X, q) (Lemma B.3), scaling all samples by
s, and replacing Σ with I in the second-order condition using Lemma B.4.
Lemma B.4. Assume the conditions in Section 2.3 hold. Then after scaling, we have
ς TIL ≤
where Σ is the covariance matrix of f(X, P).
Proof. We recall that πPPk(1 - Pk) ≥ 2∏P min(Pk, 1 一 Pk) = Ω(αc). Because ∣∣s∣∞ =
O(1/√0c), it suffices to show that
∣Cov(s ◦ f (X,P)) - 112 ≤ O(E).
In other words, we need to show
∣∣∏p ◦ p ◦ (1 -p) - ∏S ◦ qs ◦ (1 - qs)∣∣∞ = O(e).
Let πG? and PG? be the empirical parental configuration probabilities and conditional probabilities
of P given by G? . We first prove that
∣∣∣πG? ◦ PG? ◦ (1 - PG? ) - πS ◦ qS ◦ (1 - qS)∣∣∣	= O(E) .
Note that ∣πG? - πS∣∞ = O(E) and qkS(1 - qkS) < 1, so it is sufficient to show that
∣∣∣πG? ◦ PG? ◦ (1 - PG? ) - πG? ◦ qS ◦ (1 - qS)∣∣∣	= O(E) .
16
Published as a conference paper at ICLR 2021
We have
πG? ◦ pG? ◦ (1 - pG? ) - πG? ◦ qS ◦ (1 - qS)
∞
=	πG? ◦ pG? -	πG?	◦	qS	- πG? ◦ (pG? + qS) ◦	(pG?	- qS)	≤ 3	πG?	◦	(pG?	-	qS)
Let nk denote the number of times that the event Πk happens over G?, and let tk be the number
of times that X(i) = 1 when Πk = Πi,a happens. Because S is obtained by changing at most N
samples in G?, we can get
l∏G?。…)ι≤ N ∙ (T - ⅛
nk(nk + tk)eN ≤ 2nkEN
Nnk (nk — eN ) — 0.5Nnk
4E .
The last inequality follows from tk ≤ nk and nk - EN ≥ 0.5nk (because we assume the minimum
parental configuration probability is Ω(e)).
This concludes πG? ◦ pG? ◦ (1 - pG? ) - πS ◦ qS ◦ (1 - qS)∞ = O(E).
Similarly, in order to prove that
πP ◦ p ◦ (1 - p) - πG? ◦ pG? ◦ (1 - pG? )	= O(E) .
We just need to show πP ◦ (p - pG?)2 = O(E), which is follows from (ii) in Lemma A.2.
An application of triangle inequality finishes this proof.	□
We are now ready to prove Lemma 3.2.
ProofofLemma 3.2. By Lemma B.3 and the fact that ks∣∣∞ = O(1∕√0c), We know that for any
subset T ⊂ G? with |T| ≥ (1 - E)|G?|, we have
卷 Xf(Xi㈤-∏P
|T | i∈T
T X(Z(Xi, q) - πP
i∈T
◦(P — q))	≤ O(√αc +e kP — q∣l2), and
2
,	..,ʌ ,	.	C
◦ (p — q))f(Xi,q) — ∏P
◦ (P — q))> — ∑	≤ O(" + B + √B)
αc
2
ʌ
where B = ∣∣√πp ◦ (P — q)∣∣ , and Σ is the true covariance of f(X,p). This is because the scaling
is applied to all vectors on both sides of the inequalities, so we only need to scale the scalars δ1 and
δ2 appropriately.
We conclude the proof by replacing Σ in the second-order condition with I using Lemma B.4.	□
C	Robust Mean Estimation with Sparse Input
In this section, we give a robust mean estimation algorithm that runs in nearly input-sparsity time.
We build on the following lemma, which is essentially the main result of Dong et al. (2019).
Lemma C.1 (essentially Dong et al. (2019)). Given an E-corrupted version ofan (E, β, γ)-stable set
S of N samples w.r.t. a d-dimensional distribution with mean μχ. Suppose further that ∣∣X ∣∣2 ≤ R
for all X ∈ S, there is an algorithm outputs an estimator μ ∈ Rd such that with high probability,
kμ — μx∣∣2 ≤ O(√γ + β + CPlog 1/E).
Moreover, this algorithm runs in time O((nnz(S) + N + d + T(Oapx)) ∙ log R), where nnz(S) is the
total number of nonzeros in the samples in S and T (Oapx)) is the runtime ofan approximate score
oracle defined in Definition C.2.
17
Published as a conference paper at ICLR 2021
Lemma C.1 is different from the way it is stated in Dong et al. (2019). This is because we use a
more concise stability condition than the one in Dong et al. (2019). We will show that Lemma C.1
is equivalent to the version in Dong et al. (2019) in Appendix C.1.
The computational bottleneck of the algorithm in Dong et al. (2019) is logarithmic uses of matrix
multiplicative weight update (MMWU). In each iteration of every MMWU, they need to compute a
score for each sample. Intuitively, these scores help the algorithm decide whether it should continue
to increase the weight on each sample or not.
We define some notations before we formally define the approximate score oracle. Let ∆N = {w ∈
RN : 0 ≤ wi ≤ 1, P wi = 1} be the N -dimensional simplex. Given a set ofN samples X1, ..., XN
and a weight vector W ∈ Δn, let μ(w)= * P WiXi and Σ(w) = P Wi(Xi - μ(w))(Xi -
μ(w))> denote the empirical mean and covariance weighted by w.
Definition C.2 (Approximate Score Oracle). Given as input a set of N samples X1, . . . , XN ∈ Rd,
a sequence of t + 1 = O(log(d)) weight vectors W0, . . . , Wt ∈ ∆N, and a parameter α > 0, an
approximate score oracle Oapx outputs (1 ± 0.1)-approximations (τei)iN=1 to each of the N scores
Ti = (Xi- μ(wt))>U(Xi- μ(wt))
for
U = eχp(α Pt=0 ς(Wi))
trexp(α Pt-I Σ(wi))
In addition, Oapx outputs a scalar qe such that
|qe - q| ≤ 0.1q + 0.05 Σ(Wt) - I 2 , where q = hΣ(Wt) - I, Ui .
These scores are computed using the Johnson-Lindenstrauss lemma. Our algorithm for computing
these scores are given in Algorithm 2.
Let r = O(log N log(1∕δ)), ' = O (log d), and Q ∈ Rr×d bea matrix with i.i.d entries drawn from
N(0, 1/r). Algorithm 2 computes an r × d matrix
A = Q ∙ P'(2 X Σ(wi)).	⑹
where P'(Y) = Pj=° 今Yj is a degree-' Taylor approximation to exp(Y).
The estimates for the individual scores are then given by
τi = tr(⅛ ^A(Xi - μ(wt))^2	⑺
and the estimate for q is given by
N
qe=X(τei-1) .	(8)
i=1
Algorithm 2: Nearly-linear time approximate score computation
Input: A set S of N samples X1, . . . , XN ∈ Rd, a sequence of weight vectors W0, ..., Wt, a
parameter α, and a failure probability δ > 0.
Let r = O (log N log(1∕δ)) and ' = O (log d);
Let Q ∈ Rr×d have entries drawn i.i.d. from N(0, 1/r);
Compute the matrix A ∈ Rr×d as in Equation equation 6;
return (τei)iN=1 given by Equation equation 7 and qe given by Equation equation 8;
The correctness of Algorithm 2 was proved in Dong et al. (2019).
Lemma C.3 (Dong et al. (2019)). With probability at least 1 - δ, the output of Algorithm 2 satisfies
∣q — q| ≤ 0.1q + 0.05 ∣∣∑(wt)—“卜 and Ieei — τi∣ ≤ 0.1Ti for all 1 ≤ i ≤ N.
18
Published as a conference paper at ICLR 2021
Consequently, we only need to analyze the runtime of Algorithm 2.
Lemma C.4. Algorithm 2 runs in time O(t ∙ (N + d + nnz(S)) ∙ log(1∕δ)).
Proof. We first show that matrix A ∈ Rr×d can be computed in time
O(t ∙ (N + d + nnz(S)) ∙log1∕δ).
We will multiply each row of Q (from the left) through the matrix polynomial to obtain A. Let
v> ∈ R1×d be one of the rows of Q and let w ∈ RN be any weight vector. Observe that we can
compute all (v> (Xi - μ(w)))N=I in time
O X nnz(Xi) + N + d = O(nnz(S) + N + d) .
This is because We can compute μ(w) and v>μ(w) just once, and then compute v>Xi for every i
and subtract v>μ(w) from it.
Then, We can compute
v>∑(w) = v> (X Wi(Xi- μ(w))(Xi - μ(w))>)
NN
=X Wi (v>(Xi - μ(w))) X> - (X Wi (v>(Xi - μ(w)) ) μ(w)>
i=1	i=1
as the sum of N sparse vectors subtracting a dense vector in time O(nnz(S) + N + d).
Therefore, for any V ∈ Rm, we can evaluate v> Pt-1 Σ(wi) in time O(t ∙ (nnz(S) + d + N)).
Because P' is a degree-' matrix polynomial of Pt-1 Σ(wi), we can use Horner,s method for poly-
nomial evaluation to compute v>P' (-2 Pt=0 Σ(wi)) in time O('∙t∙ (nnz(S) + d+N)). We need
to multiply each of r rows of A through, we can compute A in time O(r ∙' ∙ t ∙ (nnz(S) + d + N)).
It remains to show that (τei)iN=1 and qe as defined in Equations 7 and 8 can be computed quickly.
Note that tr(AA> ) is the entrywise inner product of A with itself, so it can be computed in time
O(rd). The vectors (A(Xi - μ(wt)))N=ι can be computed in time O (r ∙ (Pi nnz(Xi) + d))=
O(r ∙ (nnz(S) + d)), because each AXi can be compute in time O(r ∙ nnz(Xi)) and Aμ(wt) can be
computed only once in time O(rd). Because r = O(log N log(1∕δ)), we can compute all τei in time
O(r ∙ (nnz(S) + d)). Given the τi's, q can be computed in O(N) time.
Recall that r = O(log N log(1∕δ)) and ` = O(log d). Putting everything together, the overall
runtime of the oracle is
O(r∙' ∙t ∙ (nnz(S) + d + N)) + O(r∙ (nnz(S) + d) + N) = O(t ∙ (nnz(S) + d + N )∙log(1∕δ)) . □
By Lemma C.4 and the fact that t = O(log d) and δ = 1∕ poly(d), we can implement an approxi-
mate score oracle that succeeds with high probability and runs in time O(nnz(S) + N + d).
Lemma 3.3 follows from Lemma C.1 and the correctness and the runtime of the approximate score
oracle (Lemmas C.3, and C.4). (Note that we have nnz(S) = Nd, N = N, and d = m when
invoking these lemmas.)
C.1 Proof of Lemma C.1
In this section, we will show the equivalence between Lemma C.1 and Lemma C.6. Lemma C.6 is
a restatement of the result of Dong et al. (2019) using their stability notations.
We first state the stability condition used throughout Dong et al. (2019).
Definition C.5 (Dong et al. (2019)). We say a set of points S is (,γ1,γ2,β1,β2)-good with respect to
a distribution D with true mean μ if the following two properties hold:
19
Published as a conference paper at ICLR 2021
•	kμ(S)- μk2 ≤ γ1, I 由 Pi∈S (Xi - μ(S))(Xi - μ(S))> - IH2 ≤ γ2 .
•	For any subset T ⊂ S so that |T | = 2|S|, we have
力 X xi-μ
i∈T
≤ β1,
2
面 X (Xi- μ(S))(Xi - μ(S))> -I
|T | i∈T
≤ β2 .
2
Then, Dong et al. (2019) showed the following result.
Lemma C.6. Let D be a distribution on Rd with unknown mean μ. Let 0 < e < ∈o for some
universal constant 0. Let S be a set of N samples with S = Sg ∪ Sb\Sr where |Sb |, |Sr| ≤ |S|,
and Sg is (, γ1, γ2, β1, β2)-good with respect to D. Let Oapx be an approximate score oracle for S.
Suppose kX k2 ≤ R for all X ∈ S. Then, there is an algorithm QUEScoreFilter(S, Oapx, δ) that
outputs a μ such that with high probability,
kμ - μk2 ≤ O(Eplog ∖/ + peξ + YI),
where
ξ = γ2 + 2γ12 + 4E2β12 + 2Eβ2 + O(E log 1/E) .
Moreover, QUEScoreFilter makes O(log Rlog d) calls to the score oracle Oapx, and the rest of the
algorithm runs in time O(N log(R)).
We first show the connection between our stability notion (Definition 2.5) and theirs (Definition C.5).
Lemma C.7. Fix a d-dimensional distribution D with mean μ, if a set S of N samples is (e, β, γ)-
stable with respect to D, then S is (e, β, γ,β∕e, γ∣e + 3β2∕e2)-good with respect to D.
Proof. For any subset T ⊂ S with |T| = 2E|S|, we have
1
m
μ
21Eμ
1 -2E
+ F^
2
-μ -
—
2
μ
(1-⅛N iXτXi-μ
2
2
≤ ɪ β + ɪβ = β
2E 2E E
The last line follows from the assumption that S is (E, β, γ)-stable with respect to D.
Similarly, we have
|T| X (Xi - μ) (Xi - μ)>
i∈T
- I HH
H2
=	2⅛(n1 X (Xi	- μ)(Xi	-	μ)>	- I) - (12：" ((1-Ie)N	X (Xi	- μ)(Xi	-	μ)T - I)
i∈S	i∈S∖T
≤ 2⅛	N X (Xi	- μ) (Xi	-	μ)>	- I + ⅛R H (1-1e)N	X	(Xi	-	μ)(Xi	- μ)>	- I
H	i∈S	H2	H	i∈S∖T	H2
2
≤ 2bγ+2bγ=E
20
Published as a conference paper at ICLR 2021
Notice that
面 X (Xi- μ(S))(Xi- μ(S))T
|T| i∈T
=团 X (Xi - μ)(Xi - μ)> + (μ - μ(S))(M - μ(S))T
|T| i∈T
+ (μ	- μ(S))	(|T| X Xi	-	μ)	+	(|T|	X Xi	- μ)	(μ - μ(S))T	.
Combining the above two inequalities, by the triangle inequality, we get
|T| X (Xi- μ(S))(Xi- μ(S))T - I
|T| i∈T
≤ ~γ+kμ -μ(S )k2+~~ ∣∣μ -μ(S )k2
2
_7 Je2
=7 + W .
□
When S is (7 β, Y)-Stable, by Lemma C.6, We know that S is (7 γ = β,γ2 = γ, βι = β∕e, β2 =
γ∕e + 3β2∕72)-good. The parameter ξ in Lemma C.7 is
ξ = 3γ + 6β2 +6β2∕7,
and error guarantee in Lemma C.7 translates to √7ξ + γι = O(√7γ + β), which is exactly what is
needed in Lemma C.6.
D Omitted Proofs from Section 4
In this section, we prove the technical lemmas in Section 4. We restate each lemma before proving
it.
Lemma 4.2 states that the (scaled) initial estimation is not too far from the true conditional proba-
bilities p.
Lemma 4.2. Consider the same setting as in Theorem 4.1. Assume the conditions in Section 2.3
hold. In Algorithm 1, we have
IInP ◦ (P — q0)∣∣2 ≤ O(e√d∕√αC).
Proof. Recall that q0 = qs is the empirical conditional probabilities over S, and V = V ◦ S where S
is the scaling vector with ∣∣s∣∣∞ ≤ O(1∕√αc).
Let πG? and pG? be the empirical parental configuration probabilities and conditional probabilities
given by G? .
We first show that
∣∣πG? -πS∣∣2 ≤ 7√2d.
Let nkG? and nkS denote the number of times that Πk happens in G? and S. Note that changing one
sample in G? can increase or decrease nkG? by at most 1. Moreover, in a single sample, exactly d
parental configuration events happen, so changing a sample can affect at most 2d nkG? ’s. Since S is
obtained from G? by changing 7N samples, we have |nkG? - nkS| ≤ 7N for all k, and Pk |nkG? -
nS| ≤ 2edN. Together they imply ∣∣πG? 一 ∏s∣∣2 ≤ e√2d.
By a similar argument, we can show that
∣∣πG? ◦ pG? - πs ◦ qs∣∣ ≤ e√2d ,
because πkG? pkG? is the probability that Πk happens and X(k) = 1 over G?.
21
Published as a conference paper at ICLR 2021
By the triangle inequality, we have
∣∣πG? ◦ (pG? — qS) U ≤ ∣∣∏G? ◦ PG? — ∏S ◦ qS∣∣ + ∣∣∏G? - ∏S∣∣ ≤ 3e√d .
Using the condition in Equation equation 1 from Section 2.3, i.e., πG? ◦ (pG? - p)2 ≤ O(), we
get
∣∣∏G? ◦ (p — qS)∣∣2 ≤ O(e√d).
Now by Equation equation 2 from Section 2.3 and the assumption that the minimum parental con-
figuration probability mink ∏p = α = Ω(e), We have πp ≤ πG? + O(C) ≤ O(πG?), and hence
∣∣∏P ◦ (p — qS)∣∣2 ≤ O(e√d).
After scaling by s, We have
∣∣πG? ◦ (P — qS)∣L ≤ O(c√d∕√αc) .	□
Lemma 4.3 shoWs that, When q is relatively far from p, the algorithm can find a neW q such that
∣∣∏p ◦ (P — q) ∣∣2 decreases by a constant factor.
Lemma 4.3. Consider the same setting as in Theorem 4.1. Assume the conditions in Section 2.3 hold.
Fix an iteration t in Algorithm 1. Assume the robust mean estimation algorithm Amean succeeds. If
∣∣πp ◦ (P — qt) ∣∣2 ≤ Pt and Pt = Ω(c /log(1∕c)∕√ΟC) ,then we have
∣∣πP O(P — qt+1)∣∣2 ≤ cιρt
for some universal constant c1 < 1.
Proof. We assume Pt > c4(c/log(1∕c)∕√ΟC) and a > c5C for some sufficiently large universal
constants c4 and c5 .
Because ∣∣∏p ◦ (P — ^t)∣∣2
≤ Pt, Lemma 3.2 shoWs that
{∕dqt)} i∈G?
C,O
C ∙√log1∕c
√αc
+ ∣Pt
is
C log 1∕C
αc
-stable.
O
By Lemma 3.3, the robust mean estimation oracle Amean, Which We assume to succeed, outputs a
ν ∈ Rm such that, for some universal constant c3,
C √log(1∕c)
√αc
≤ c3
From Section 2.3, We have∣πS — πP ∣∞= O(C), Which implies
∣∣(πS -TP)。(P - qt)∣∣2 ≤ ∣∣∣πP O(P - qt)∣∣2 ≤ αpt.
By the triangle inequality, We have
∣ν - ∏S ◦ (P - qt)∣∣2 ≤(-√3f + -⅜ + c3c+1 + Cl) Pt.
c5 c4	c5	c4
Algorithm 1 sets qt+1 = V。(1∕πS) + qt, which is equivalent to
∏S。(P — qt+1) = ∏S。(P — qt) — v .
22
Published as a conference paper at ICLR 2021
Since ∣∣πs - πp∣∣∞ = O(E) and α = Ω(e), we have
πiP ≤ 1.1πiS ∀1 ≤ i ≤ m .
Putting everything together, letting ci = 1.1 ( c3= + c3= + c3+1 + C3 ), we have
c5 c4	c5	c4
∣∣πP O(P - qt+1 )∣∣2 ≤ 1.1 ∣∣πS O(P - qt+1)∣∣2 < 1.1 (√c= + √√= + c3c+1 + c3) Pt = ciρt.
Because c4 and c5 can be sufficiently large, We have ci < 1 as needed.	□
Lemma 4.4 shows that when the algorithm terminates, we can conclude that the output Q is close to
the ground-truth P in total variation distance.
Lemma 4.4. Consider the same setting as in Theorem 4.1. Assume the conditions in Section 2.3
hold. Let Q be a Bayesian network that shares the same structure with P. Suppose that (1) P is
C-balanced, (2) α = Ω(r + e/c), and (3) ∣∣πp ◦ (P — q)∣∣2 ≤ r/2. Then we have
dTV (P, Q) ≤ r .
Proof of Lemma 4.4. We have (Pk + qk)(2 - Pk - qk) ≥ Pk(1 - Pk). Hence,
PTQ	(Pk - qk)2	V q ∕στPTQTP (Pk - qk 产
k k k (Pk + qk)(2 - Pk - qk) ≤ V π k k πk ∏PPk (1 - Pk) ,
From the proof ofLemma B.4, we know ∣πpPk (1 -Pk) - 31 = O(e) and πpPk (1 -Pk) ≥ ∏Ppk =
sk	2
Ω(r), so we have
x q 唬 πQπP πPPk-IqkPQ ≤ 1.1 x q 唬 πQ πP (Pk - qk )2sk
=1.1 X ∕πP πQ πP (Pk- qk )2.
k
It suffices to show that ∣πp - πQ | ≤ r, which implies πQ ≤ 1.1πkP and further implies
dτv(P,Q) ≤ 2∣∣∏P ◦ (P - q)∣∣2 .
Let P≤i and Q≤i be the distributions of the first i coordinates of P and Q respectively. We prove
∣πp - ∏Q∣ ≤ r by induction on i. Suppose that for 1 ≤ j < i and all a0 ∈ {0, 1}|Parents(j)|,
∣∏Pao	- ∏Qao |	≤	r,	then we have	dτV(P≤(i-i), Q≤(i-i))	≤	r.	Because that events	Πi,a	only
depends on j < i, ∣∏Pa - ∏QJ ≤ dτv(P≤(i-i), Q≤(i-i)) ≤ r for all a. Consequently, we have
dτv(P, Q) = dτv(P≤d, Q≤d) ≤ r.	口
23