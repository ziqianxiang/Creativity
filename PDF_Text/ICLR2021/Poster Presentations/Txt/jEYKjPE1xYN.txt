Published as a conference paper at ICLR 2021
Symmetry-Aware Actor-Critic for 3D
Molecular Design
Gregor N. C. Simm,1 Robert Pinsler,1 Gabor Csanyi,1 & Jose Miguel Hernandez-Lobato1,2
1	Department of Engineering, University of Cambridge, Cambridge, UK
2	Alan Turing Institute, London, UK
{gncs2,rp586,gc121,jmh233}@cam.ac.uk
Ab stract
Automating molecular design using deep reinforcement learning (RL) has the po-
tential to greatly accelerate the search for novel materials. Despite recent progress
on leveraging graph representations to design molecules, such methods are fun-
damentally limited by the lack of three-dimensional (3D) information. In light
of this, we propose a novel actor-critic architecture for 3D molecular design that
can generate molecular structures unattainable with previous approaches. This is
achieved by exploiting the symmetries of the design process through a rotationally
covariant state-action representation based on a spherical harmonics series expan-
sion. We demonstrate the benefits of our approach on several 3D molecular design
tasks, where we find that building in such symmetries significantly improves gen-
eralization and the quality of generated molecules.
1	Introduction
The search for molecular structures with desirable properties is a challenging task with important
applications in de novo drug design and materials discovery (Schneider et al., 2019). There exist a
plethora of machine learning approaches to accelerate this search, including generative models based
on variational autoencoders (VAEs) (Gdmez-Bombarelli et al., 2018), recurrent neural networks
(RNNs) (Segler et al., 2018), and generative adversarial networks (GANs) (De Cao & Kipf, 2018).
However, the reliance on a sufficiently large dataset for exploring unknown regions of chemical
space is a severe limitation of such supervised models. Recent RL-based methods (e.g., Olivecrona
et al. (2017), J0rgensen et al. (2019), Simm et al. (2020)) mitigate the need for an existing dataset of
molecules as they only require access to a reward function.
Most approaches rely on graph representations of molecules, where atoms and bonds are represented
by nodes and edges, respectively. This is a strongly simplified model designed for the description
of single organic molecules. It is unsuitable for encoding metals and molecular clusters as it lacks
information about the relative position of atoms in 3D space. Further, geometric constraints on the
design process cannot be included, e.g. those given by the active site ofan enzyme. A more general
representation closer to the physical system is one in which a molecule is described by its atoms’
positions in Cartesian coordinates. However, it would be very inefficient to naively learn a model
based on this representation. That is because molecular properties such as the energy are invariant
(i.e. unchanged) under symmetry operations like translation or rotation of all atomic positions. A
model without the right inductive bias would thus have to learn those symmetries from scratch.
In this work, we develop a novel RL approach for designing molecules in Cartesian coordinates
that explicitly encodes these symmetry operations. The agent builds molecules by consecutively
placing atoms such that if the generated structure is rotated or translated, the agent’s action is rotated
and translated accordingly; this way, the reward remains the same (see Fig. 1 (a)). We achieve
this through a rotationally covariant state representation based on spherical harmonics, which we
integrate into a novel actor-critic network architecture with an auto-regressive policy that maintains
the desired covariance. Building in this inductive bias enables us to generate molecular structures
with more complex coordination geometry than the class of molecules that were attainable with
previous approaches. Finally, we perform experiments on several 3D molecular design tasks, where
1
Published as a conference paper at ICLR 2021
we find that our approach significantly improves the generalization capabilities of the RL agent and
the quality of the generated molecules.
Figure 1: (a) Illustration of a rotation-covariant state-action representation. If the structure is rotated
by R, the position x of the action transforms accordingly. (b) Rollout with bag B0 = SOF4 . The
agent builds a molecule by repeatedly taking atoms from the bag and placing them onto the 3D
canvas. Bonds connecting atoms are only for illustration and not part of the MDP.
In summary, our contributions are as follows:
•	we propose the first approach for 3D molecular design that exploits symmetries of the
design process by leveraging a rotationally covariant state representation;
•	we integrate this state representation into an actor-critic neural network architecture with
a rotationally covariant auto-regressive policy, where the orientation of the atoms to be
placed is modeled through a flexible distribution based on spherical harmonics;
•	we demonstrate the benefits of our approach on several 3D molecular design tasks, includ-
ing a newly proposed task that showcases the generalization capabilities of our agent.
2	Background
2.1	Reinforcement Learning for Molecular Design
In the standard RL setting (Sutton & Barto, 2018), an agent interacts with the environment to max-
imize its reward. Formally, such an environment is described by a Markov decision process (MDP)
M = (S, A, T, μo ,γ, r) with states St ∈ S, actions a± ∈ A, transition dynamics T : S × A → S,
initial state distribution μ0, discount factor Y ∈ (0,1], and reward function r : S × A → R.
The goal is to learn a stochastic policy ∏(at∣st) that maximizes the expected discounted return
J(θ) = Eg。〜μo[Vπ(so)], where the value function VK(St) = En[PT=tγt0r(st0, at0)|st] is defined
as the expected discounted return when starting from state St and following policy π.
Following Simm et al. (2020), we design molecules by iteratively picking atoms from a bag and
positioning them on a 3D canvas. Such a sequential decision-making problem is described by an
MDP where the state St = (Ct , Bt ) comprises both the canvas Ct and the bag Bt. The canvas
Ct = C0 ∪ {(ei , xi)}it=-01 is a set of atoms with chemical element ei ∈ {H, C, N, O, . . . } and position
xi ∈ R3 placed up to time t - 1, where C0 can either be empty or contain a set of initially placed
atoms. The number of atoms on the canvas is denoted by |Ct |. The bag Bt = {(e, m(e))} is a
multi-set of atoms yet to be placed, where m(e) is the multiplicity of the element e. Each action
at = (et , xt ) consists of the element et ∈ Bt and position xt ∈ R3 of the next atom to be added
to the canvas. Placing an atom through action at in state St is modeled by a deterministic transition
function T (St, at) that yields the next state St+1 = (Ct+1, Bt+1) with Bt+1 = Bt\et.
The reward function r(St, at) = -∆E(St , at) is given by the negative energy difference between
the resulting structure described by Ct+1, and the sum of energies of the current structure Ct and a
new atom of element et placed at the origin, i.e. ∆E(St, at) = E(Ct+1) - [E(Ct) + E({(e, 0)})].
Intuitively, the reward encourages the agent to build stable, low-energy structures. We evaluate the
energy using the fast semi-empirical Parametrized Method 6 (PM6) (Stewart, 2007) as implemented
in S parrow (Husch et al., 2018; Bosia et al., 2020); see Appendix A for details.
2
Published as a conference paper at ICLR 2021
An example of a rollout is shown in Fig. 1 (b). At the beginning of the episode, the agent observes
the initial state (Co, Bo)〜 μ0(s0), e.g. Co = 0 and Bo = SOF41. The agent then iteratively
constructs a molecule by placing atoms from the bag onto the canvas until the bag is empty.2
2.2	Rotationally Covariant Neural Networks
A function f : X 7→ Y is invariant under a transformation operator Tg : X 7→ X if f(Tg [x]) =
f (x) for all x ∈ X , g ∈ G, where G is a mathematical group. In contrast, f is covariant with
respect to Tg if there exists an operator Tg0 : Y 7→ Y such that f(Tg [x]) = Tg0 [f (x)]. To achieve
rotational covariance, it is natural to work with spherical harmonics. They are a set of complex-
valued functions Y'm : S2 → C with ' = 0,1,2,... and m = —', —' + 1,...,' — 1,' on the unit
sphere S2 in R3 . The first few spherical harmonics are in Appendix B. They are defined by
Y*,0 = (-1)m∖j'++1(' — m)! Pm(COs⑵)eim:中 ∈ [0, 2π],	e ∈ [0,π],	(1)
4π (` + m)!
where Pm denotes the associated normalized Legendre polynomials of the first kind (Bateman,
1953), and each Ym is normalized such that /∫∣Y'm(O,2)12 sinHdHd夕=1. Any square-integrable
function f : S2 7→ C can be written as a series expansion in terms of the spherical harmonics,
∞	`
f(χ) = XX fmγm(χ),	⑵
'=0 m=-'
where X = (O,夕)∈ S2. The complex-valued coefficients {fm} are the analogs of Fourier coeffi-
cients and are given by fmm = f f (X)Y'm* (X)Ω(dX). Such a function f can be modeled by learning
the coefficients {fm} using Cormorant (Anderson et al., 2019), a neural network architecture
for predicting properties of chemical systems that works entirely in Fourier space. A key feature
is that each neuron is covariant to rotation but invariant to translation; further, each neuron explic-
itly corresponds to a subset of atoms in the molecule. The input of Cormorant is a spherical
function f0 : S2 → Cd and the output is a collection of vectors f = {fo,fι,...,fL}, where each
f` ∈ T X (2' +1) is a rotationally covariant vector with T channels. That is, if the input is rotated by
R ∈ SO(3), then each f` transforms as f` → De(R)f', where D(R) : SO(3) → C(2'+1)×(2'+1)
are the irreducible representations of So(3), also called the Wigner D-matrices.
3	C ovariant Policy for Molecular Design
An efficient RL agent needs to exploit the symmetries of the molecular design process. Therefore,
we require a policy π(a∣s) with actions a = (e,x) that is covariant under translation and rotation
with respect to the position x, i.e., x should rotate (or translate) accordingly if the atoms on the
canvas C are rotated (or translated). In contrast, the policy needs to be invariant to the element e, i.e.
the chosen element remains unchanged under such transformations (see Fig. 1 (a)). Since learning
such a policy is difficult when working directly in global Cartesian coordinates, we instead follow
Simm et al. (2020) and use an action representation that is local with respect to an already placed
focal atom. If the next atom is placed relative to the focal atom, covariance under translation of x is
automatically achieved and only the rotational covariance remains to be dealt with.
As shown in Fig. 2, we model the action a through a sequence of sub-actions: (1) the index
f ∈ {1, . . . , |C|} of the focal atom around which the next atom is placed,3 (2) the element
e ∈ {1, . . . , Ne} of the next atom from the set of available elements, (3) a distance d ∈ R+ be-
tween the focal atom and the next atom, and (4) the orientation X = (O,夕)∈ S2 of the atom on a
unit sphere around the focal atom. Denoting xf as the position of the focal atom, we obtain action
a = (e, x) by mapping the local coordinates (X, d, f) to global coordinates X = Xf + d ∙ X, where
1Shorthand for {(S, 1), (0,1), (F, 4)}.
2Hereafter, we drop the time index when it is clear from the context.
3Ifthe canvas C0 is empty, the agent selects an element e0 ∈ B0 and places it at the origin, i.e. a0 = (e0, 0).
3
Published as a conference paper at ICLR 2021
x is now covariant under translation and rotation. We choose these sub-actions using the following
auto-regressive policy:
π(a∣s) = π(x,d,e,f |s) = p(X∣d,e,f, s)p(d∣e,f, s)p(e∣f, s)p(f∣s).	(3)
Figure 2: Action representation of the auto-regressive policy. The agent chooses focal atom f,
element e, distance d, and orientation x. We then map back to global coordinates X to obtain action
a = (e, x). Bonds between atoms are only for illustration.
A novel actor-critic neural network architecture that implements this policy is illustrated in Fig. 3.
In the following, we discuss its state embedding, actor, and critic networks in more detail.
3.1	State Embedding
The state embedding network transforms canvas C and bag B to obtain a rotationally covariant and
translationally invariant representation. For that, we concatenate a vectorized representation of the
bag with each atom on the canvas and feed it into CORMORANT, i.e. scov — CORMORANT(C, B),
where scov = {s'ov}Lmx, s'ov ∈ ClCl×τ×(2'+1), and T is the number of channels. For the sake of
exposition, we assume a single channel for each element in the bag, i.e. τ = Ne (cf. Fig 3); in
practice, we use up to four channels per element.
However, not every sub-action in Eq. (3) should transform equally under rotation and translation.
While the orientation X needs to be COVariant under rotation, the choice of focal atom f, element e,
and distance d have to be invariant to rotation and translation. For these sub-actions, we additionally
require an invariant state representation. To obtain such a representation sinv ∈ RlCl×k, We employ a
combination of transformations from Anderson et al. (2019) as listed in Appendix C (e.g. for ` = 0,
one can simply select the ScoV0 component), which we collectively denote as Tinv.
3.2	Actor
Focal Atom and Element The distribution p(f |s) over the focal atom f is modeled as cate-
gorical, f 〜Cat(f; hf), where hf are the logits for each atom in C predicted by a multi-layer
perceptron (MLP). Likewise, the distribution over the element e is given by p(e|f, s) = Cat(e; he)
with he = MLPe(sifnv), where sifnv is the invariant representation for the focal atom. Since the num-
ber of possible focal atoms f increases and the set of available elements e decreases during a rollout,
we mask out invalid focal atoms f ∈/ {1, . . . , |Ct|} and elements e ∈/ Bt by setting their probabilities
to zero and re-normalizing the categorical distributions. The agent does nOt make use of chemical
concepts like bond connectivity to aid the choice of the focal atom.
Distance We select the channel τe corresponding to element e from scfov to obtain scfo,ve :=
{scove}'=o,…,Lmax and Sfve J TnV(Sfoe). Then we model the distribution over the distance d be-
tween the focal atom and the next atom to be placed as a mixture of M Gaussians, p(d|e, f, s) =
PM=I ∏m N(μm,σm), where ∏m is the mixing coefficient of the m-th Gaussian N(μm,σm). The
mixing coefficients and the means are predicted by a mixture density network (MDN) (Bishop,
1994), i.e. {∏m,μm}M=ι = MDN(Sf[). The standard deviations {σm/}M=ι are global parameters.
We guarantee that the sampled distances are positive by clipping values below zero.
Combining Invariant and Covariant Features The choice of distance d can significantly affect
the orientation X of the atom. For example, if d has the length of a triple bond, then X will be very
different from if it was a single bond. Thus, we condition Scfo,ve on distance d through a non-linear
and learnable transformation that preserves rotational covariance. We then use this representation
4
Published as a conference paper at ICLR 2021
Critic
sinv- MLPφ - E →∣ I I I ∣-MLPp->y
Figure 3: Illustration of the state embedding, actor, and critic networks. Both canvas C and bag B are
fed to the state embedding network CORMORANT to obtain rotation-covariant (scov) and -invariant
(sinv) state representations. The actor network then samples the different sub-actions highlighted in
bold. The critic takes the invariant representation sinv to compute a value V .
to model a spherical distribution over x. Kondor & Trivedi (2018) showed that a linear transfor-
mation with learnable parameters is only covariant if the operation combines fragments with the
same `. Further, the Clebsch-Gordan (CG) non-linearity allows one to combine two covariant fea-
tures such that the result is still covariant. Thus, we obtain a rotationally covariant representation
r ：= {r'}'=0,…,Lmax - Tcov (d, scfo,ve) conditioned on all previous sub-actions as follows:
r` =	[scfVe	㊉ d∙s'fVe	㊉(d∙sfoe	㊈Cg	d∙sfoe)'[∙ W'	∀',	(4)
where ㊉ denotes the appropriate concatenation of matrices, and W' is a learnable complex-valued
matrix. As in Anderson et al. (2019), We perform the CG product ③Cg only channel-wise to reduce
computational complexity.
Orientation Next, we utilize r to obtain a rotationally covariant spherical distribution for the
orientation X based on the series expansion in Eq. (2). Taking inspiration from commonly used
distributions (Jammalamadaka & Terdik, 2019), we propose to use the following expression:
2	,	(5)
Lmax '
p(X∣d,e,f, s) = z exp -βG XXrm Ym(X)I
k '=0 m=-'
where β ∈ R is a scaling parameter, and the term 1∕√k with k = PL=O Pm=_'忙片|2 regularizes
the distribution so that it does not approach a delta function. The normalization constant Z is esti-
mated via Lebedev quadrature (Lebedev, 1975; 1977). We sample from the distribution in Eq. (5)
using rejection sampling (Bishop, 2009) with a uniform proposal distribution q(X) = (4π)-1. Note
that in contrast to more commonly used parametric distributions (e.g. von Mises-Fisher), this for-
mulation allows to model multi-modalities. We discuss alternatives to Eq. (5) in Appendix D.
5
Published as a conference paper at ICLR 2021
3.3	Critic
The critic needs to compute a value V for the state s that is invariant under translation and rotation.
Given sinv, we apply a permutation-invariant set encoding (Zaheer et al., 2017) of the atoms, i.e.
/ 1C1	ʌ
V(S) = MLPP I 工MLPφ(sinv)卜	⑹
Finally, we use PPO (Schulman et al., 2017) to learn the parameters of the actor-critic architecture.
To encourage sufficient exploration, we add an entropy regularization term over the categorical sub-
action distributions of the auto-regressive policy. For offline evaluation, we evaluate the policy
without any exploration by choosing the most probable action. While the mode of the distributions
for f and e is available in closed form, we approximate the global mode of the distributions over d
and X by evaluating the density at S samples and picking the one with the highest density.
4 Related Work
Reinforcement Learning for Molecular Design There exists a large variety of RL-based ap-
proaches for molecular design using either string- or graph-based representations of molecules
(Olivecrona et al., 2017; Guimaraes et al., 2018; Putin et al., 2018; Neil et al., 2018; Popova et al.,
2018; You et al., 2018; Zhou et al., 2019). However, the choice of representation limits the molecules
that can be generated to a (small) region of chemical space for which the representation is applicable,
i.e., single organic molecules. Such representations also prohibit the use of reward functions based
on quantum-mechanical properties; instead, heuristics are often used. Lastly, geometric constraints
on the design process cannot be imposed as the representation does not include any 3D information.
Molecular Design in Cartesian Coordinates Another down-
side of string- and graph-based approaches is their neglect of
information encoded in the interatomic distances. In light of
this, Gebauer et al. (2018; 2019) proposed a supervised gener-
ative neural network for sequentially placing atoms in Cartesian
coordinates. While the model respects local symmetries by con-
struction, atoms are placed on a 3D grid. Similar to other su-
pervised approaches, one further requires a dataset that covers
the particular class of molecules to be generated. Hammer and
coworkers (J0rgensen et al., 2019; Meldgaard et al., 2020) em-
ployed a Deep Q-Network (Mnih et al., 2015) to build planar
compounds and crystalline surfaces by placing atoms on a grid.
Recently, Simm et al. (2020) presented an RL formulation for
molecular design in continuous 3D space. The agent models the
position of the next atom to be placed in internal coordinates—
i.e. the distance, angle, and dihedral angle with respect to already
existing atoms—which are invariant under translation and rota-
tion. By mapping from internal to Cartesian coordinates, they
then obtain a policy that is covariant under these symmetry oper-
ations. However, as shown in Fig 4, the angle and dihedral angle
are only defined with respect to two reference points, which are
Figure 4: Example of two con-
figurations (a) and (b) that the
agent by Simm et al. (2020) can-
not distinguish. While the values
for distance d, angle α and dihe-
dral angle ψ are the same, choos-
ing different reference points (in
red) leads to a different action.
This is particularly problematic
in symmetric states, where one
cannot uniquely determine these
reference points.
chosen to be the two closest points to a focal atom. In highly symmetric states, e.g. as commonly
encountered in materials, this representation fails to distinguish different configurations as one can-
not uniquely select the two closest atoms as reference points anymore. In contrast, we do not rely
on such reference points as the agent directly samples the orientation from a spherical distribution.
Covariant Neural Networks in Chemical Science Prior work employed rotationally covariant
neural networks to predict translation- and rotation-invariant physical properties (Thomas et al.,
2018; Kondor et al., 2018; Weiler et al., 2018; Anderson et al., 2019; Miller et al., 2020; Finzi
et al., 2020; Fuchs et al., 2020), e.g. scalars such as the electronic energy. In contrast, we propose
a translation-invariant and rotation-covariant neural network architecture for generating molecules.
For a more general treatment of covariance (or equivariance) in RL, see van der Pol et al. (2020).
6
Published as a conference paper at ICLR 2021
5 Experiments
We perform experiments to answer the following questions: (1) is the agent able to learn how to
build highly symmetric molecules in Cartesian coordinates from scratch, (2) can we increase the
validity, diversity, and stability of generated molecules, and (3) does our approach lead to improved
generalization? We address (1) and (2) by evaluating the agent on a diverse range of tasks from the
MOLGYM benchmark suite (Simm et al., 2020), and (3) on a newly proposed stochastic-bag task
(see Section 5.1) where bags are sampled from a distribution over bags. In Appendix G, we show
with an additional experiment that the agent can learn to place water molecules around a given solute
to form a solvation shell.4
We compare our approach (Covariant) against the RL agent proposed by Simm et al. (2020),
which iteratively builds molecules on a 3D canvas by working in internal coordinates (Internal).
As an additional baseline, we consider a classical, optimization-based agent (Opt) with access to
a black-box function that yields the energy E(C) and the atomic forces F (C) for a given canvas.5
The agent constructs molecules by alternating between randomly placing an atom and optimizing
the structure. Moreover, the agent applies several heuristics inspired by fundamental chemical con-
cepts to guide the placement of atoms. To make the comparisons fair, we grant Opt a comparable
computational budget in terms of the total number of energy computations. Finally, for some exper-
iments, the best possible performance based on quantum-chemical calculations can be reported. See
Appendices E and F for more details on the baselines and experimental settings, and Appendix H
for an additional runtime comparison between the agents.
5.1	Stochastic-Bag Task
In Simm et al. (2020), a set of molecular design tasks was introduced: the single-bag task assesses
an agent’s ability to build single stable molecules, whereas the multi-bag task focuses on building
several molecules of different composition and size at the same time. A limitation of these tasks is
that the initial bags were selected such that they correspond to known formulas, which in practice
might not be known a priori. In the stochastic-bag task, we relax this assumption by sampling from
a more general distribution over bags. Before each episode, we construct a bag B = {(e, m(e))}
by sampling counts (m(eι),…，m(emaχ))〜MUlt(Z,pe), where the bag Size Z is sampled uniformly
from the interval [ζmin, ζmax]. Here, we obtain an empirical distribution pe from the multiplicities
m(e) of a given bag B*. For example, with B* = {(H, 2), (0,1)} We obtain PH = 2 and PO= 1.
Since sampled bags might no longer correspond to valid molecules when placed completely, we
discard bags where the sum of valence electrons over all atoms contained in the bag is odd. This
ensures that the agent can build a closed-shell system.
5.2	Results
Building Highly Symmetric Molecules First, we evaluate the ability to build stable molecules
featuring high symmetry and coordination numbers (e.g. trigonal bipyramidal, square pyramidal,
and octahedral) on the single-bag task with bags SOF4, IF5, SOF6, and SF6. As shown in Fig. 5 (a),
COVARIANT can solve the task for SOF4 and IF5 within 30 000 to 40 000 steps, whereas INTERNAL
fails to build low-energy configurations as it cannot distinguish highly symmetric intermediates
(cf. Fig. 4). Further results in Fig. 5 (b) for SOF6 and SF6 show that COVARIANT is capable of
building such structures. Likewise, Opt found the optimal structures for all four bags. While the
constructed molecules are small in size, they would be unattainable with graph- or string-based
methods as such representations lack important 3D information. For example, RDKit (Landrum,
2019), a state-of-the-art library for 3D structure generation of organic molecules, failed at this task.
Validity, Diversity, and Stability of Generated Molecules Since string and graph representa-
tions are not well-suited for designing molecules with complex 3D structure, it is difficult to directly
compare to most prior work. To still enable comparisons, we follow the GuacaMol benchmark
(Brown et al., 2019) and report the chemical validity, diversity, and stability of the molecules gen-
erated by the agents for different experiments. A generated structure is considered valid if it can
be successfully converted to a molecular graph by the tool XYZ2Mol (Jensen, 2019; Kim & Kim,
4Source code of the agent and environment is available at https://github.com/gncs/molgym.
5For the calculation of E(C) and F (C) we employ PM6; the same method as in the reward function.
7
Published as a conference paper at ICLR 2021

(a) ι.o -
0.8 -
0.6 -
0.4 -
0.2 -
0.0 -
-0.2 -
-0.4 -
-0.6 -
0
10	20	30
Steps x1000
40
0.8 -
0.6 -
0.4 -
0.2 -
—Covariant
Internal
0.0 -
-0.4 -
-0.6 -
-0.8 -
Steps x 1000
Figure 5: (a) Average offline performance on the single-bag task with bags SOF4 (left) and IF5
(right) across 10 seeds. In the lower right, molecular structures generated by the agents are shown.
Dashed lines denote the optimal return for each experiment. Error bars show two standard devia-
tions. (b) Further molecular structures generated by COVARIANT, namely SOF6 and SF6.
Table 1: Validity, diversity, and stability (RMSD in A) of generated structures.
Task	Experiment	Opt	Validity (↑ is better)		Diversity (↑)			RMSD Q)	
			Internal	C ovariant	Opt	Internal Covariant		Internal	Covariant
	C3H5NO3	0.06	0.70	0.90	19	35	65	0.32	0.30
	C4H7N	0.10	0.80	0.70	35	18	25	0.26	0.29
Single-bag	C3H8O	0.06	0.90	0.80	2	4	8	0.42	0.22
	C7H10O2	0.05	0.50	0.80	10	21	85	0.80	0.76
	C7H8N2O2	0.03	0.60	0.70	5	58	118	0.57	0.52
Multi-bag		0.54	0.78	0.89	22	19	42	0.04	0.04
Stochastic-bag	C7H10O2	0.05	0.40	0.60	10	26	59	0.65	0.71
	C7H8N2O2	0.03	0.10	0.80	5	28	84	0.95	0.88
Stochastic-bag (gen.)	C7H10O2	0.00	0.00	0.13	0	38	68	n/a	1.02
	C7H8N2O2	0.00	0.05	0.30	0	40	227	1.24	1.15
2015). The validity reported in Table 1 is the ratio of valid molecules generated during offline evalu-
ation at the end of training over 10 seeds. Two molecules are considered identical if their molecular
graphs yield the same SMILES strings under RDKIT. The diversity shown in Table 1 is the total
number of unique and valid structures generated during offline evaluation during training over 10
seeds.6 In the two stochastic-bag experiments, the agents are trained on bags of sizes from the
interval [16,22] sampled with B* = C7H8N2O2 and C7H10O2, respectively. Finally, to assess the
stability of the generated molecules, valid structures generated in the last iteration underwent a struc-
ture optimization using the PM6 method (see Appendix A for details). Then, the root-mean-square
deviation of atomic positions (RMSD, in A) between the original and the optimized structure was
computed. In Table 1, the median RMSD is given per experiment.
Results are listed in Table 1. We observe that Covariant significantly outperforms the other agents
on most experiments both in terms of validity and diversity. The difference is particularly large for
the more challenging stochastic-bag tasks, where COVARIANT does similarly well as on the single-
bag experiments. This finding is confirmed in Fig. 6 (a), showing that the exact stoichiometry
does not need to be known a priori for the agent to build valid molecules. Moreover, the structures
generated by Covariant are overall slightly more stable compared to Internal. In contrast, Opt
often fails to build valid structures. Inspection of the generated structures reveals that for larger bags
the agent tends to build multi-molecular clusters, which are considered invalid in this experiment.
The stability for Opt is omitted as all of its valid structures are stable by definition.
Compared to graph-based approaches (e.g., Jin et al. (2017); Bradshaw et al. (2019a); Li et al.
(2018b;a); Liu et al. (2018); De Cao & Kipf (2018); Bradshaw et al. (2019b)), the average validity
6For a fairer comparison in the stochastic-bag task, we use the structures generated during offline evaluation,
instead of those generated during training as in Simm et al. (2020).
8
Published as a conference paper at ICLR 2021
and diversity achieved by Covariant are still relatively low. This can partly be explained by
the fact that state-of-the-art graph-based approaches have the strict rules of chemical bonding in
organic molecules encoded into their models. But as a result, they are limited to generating single
organic molecules and cannot build molecules for which these rules do not apply (e.g., hypervalent
iodine compounds such as IF5). In terms of stability, the supervised generative model by Gebauer
et al. (2019) reported an average RMSD of approximately 0.25 A. While their approach and the
considered molecules are significantly different from ours, this suggests that the generated structures
are more stable compared to Covariant. Nonetheless, the RL approach presented in this work
remains particularly attractive if no dataset exists on which such a supervised model can be trained.
Generalization To evaluate the generalization capabilities of all agents to unseen bags, we train
on a distribution over bags with B* = C7H10O2 and C7H8N2O2, and test on sets of larger, out-
of-distribution bags {C6H14O3, C7H16O, C7H16O2, C8H18O}, and {C8H12N2O,C6H12N2O3,
C7H14N2 O, C7H14N2O2 } respectively. As shown in Fig. 6 (b), COVARIANT obtains higher av-
erage returns with lower variance compared to Internal on C7H10O2, while performing only
slightly worse than the agent trained directly on the test bags (purple). Results for C7H8N2O2
are in Appendix G. Although the difference in performance seems to be marginal, we stress that
chemical validity is often determined by the last 10% of the returns. Indeed, Table 1 and Fig. 9
in Appendix G highlight the higher quality of the structures generated by Covariant, indicating
better generalization to unseen bags of larger size. Opt fails at this task.
(a) 4 -
3 -
2 -
1 -
0 -
Covariant
Covariant
0	25	50	75	100 125 150 175
Steps X 1000
(b)
4 -
2
Steps X1000
Figure 6: Average offline performance on the stochastic-bag task with B* = C7H10O2 evaluated on
(a) C7H10O2 and (b) larger, unseen bags {C6H14O3, C7H16O, C7H16O2, C8H18O} over 10 seeds.
For comparison, we show an agent trained only on the test bags (purple). Error bars are two standard
deviations. Molecular structures generated by Covariant (Stochastic) are shown.
6 Conclusion
We proposed a novel covariant actor-critic architecture based on spherical harmonics for design-
ing highly symmetric molecules in 3D. We showed empirically that exploiting symmetries of the
molecular design process improves the quality of the generated molecules and leads to better gener-
alization. In future work, we aim to employ more accurate quantum-chemical methods (e.g., density
functional theory) required for building transition metal complexes or structures in which weak inter-
molecular interactions are important. For that, however, the sample-efficiency of our agent needs to
be improved. Finally, we aim to explore reward functions specifically tailored towards drug design.
Acknowledgements
We thank A. J. Tripp and K. T. Jensen for useful discussions and feedback. RP receives funding
from iCASE grant #1950384 with support from Nokia. JMHL acknowledges support from a Turing
AI Fellowship under grant EP/V023756/1. This work has been performed using resources operated
by the University of Cambridge Research Computing Service (funded by grant EP/P020259/1).
9
Published as a conference paper at ICLR 2021
References
Brandon Anderson, Truong Son Hy, and Risi Kondor. Cormorant: Covariant Molecular Neural
Networks. In Advances in Neural Information Processing Systems 32, pp. 14537-14546. Curran
Associates, Inc., 2019.
Harry Bateman. Higher Transcendental Functions, volume I-III. McGraw-Hill Book Company,
New York, 1953.
Christopher M Bishop. Mixture density networks. Technical report, Aston University, 1994.
Christopher M. Bishop. Rejection sampling. In Pattern Recognition and Machine Learning, Infor-
mation Science and Statistics, pp. 528-530. Springer, New York, 2009. ISBN 978-0-387-31073-2.
Francesco Bosia, Tamara Husch, Alain C. Vaucher, and Markus Reiher. QCScine Sparrow: Release
2.0.1. https://doi.org/10.5281/zenodo.3907313, 2020.
John Bradshaw, Matt J. Kusner, Brooks Paige, MarWin H. S. Segler, and Jose MigUel Herngndez-
Lobato. A generative model for electron paths. In International Conference on Learning Repre-
sentations, 2019a.
John Bradshaw, Brooks Paige, Matt J Kusner, Marwin Segler, and Jose Miguel Herngndez-Lobato.
A Model to Search for Synthesizable Molecules. In Advances in Neural Information Processing
Systems, pp. 7935-7947, 2019b.
Nathan Brown, Marco Fiscato, Marwin H.S. Segler, and Alain C. Vaucher. GuacaMol: Benchmark-
ing Models for de Novo Molecular Design. J. Chem. Inf. Model., 59(3):1096-1108, 2019.
Nicola De Cao and Thomas Kipf. MolGAN: An implicit generative model for small molecular
graphs. arXiv preprint arXiv:1805.11973, 2018.
Marc Finzi, Samuel Stanton, Pavel Izmailov, and Andrew Gordon Wilson. Generalizing Convo-
lutional Neural Networks for Equivariance to Lie Groups on Arbitrary Continuous Data. arXiv
preprint arXiv:2002.12880, 2020.
Fabian B Fuchs, Daniel E Worrall, Volker Fischer, and Max Welling. SE (3)-transformers: 3D
roto-translation equivariant attention networks. arXiv preprint arXiv:2006.10503, 2020.
Niklas W. A. Gebauer, Michael Gastegger, and Kristof T. Schutt. Generating equilibrium molecules
with deep neural networks. arXiv preprint arXiv:1810.11347, 2018.
Niklas W. A. Gebauer, Michael Gastegger, and Kristof T. Schutt. Symmetry-adapted generation
of 3D point sets for the targeted discovery of molecules. In Advances in Neural Information
Processing Systems, pp. 7564-7576, 2019.
Rafael Gdmez-Bombarelli, Jennifer N. Wei, David Duvenaud, JoSe Miguel Herngndez-Lobato,
Benjamin Sgnchez-Lengeling, Dennis Sheberla, Jorge Aguilera-Iparraguirre, Timothy D. Hirzel,
Ryan P. Adams, and Algn Aspuru-Guzik. Automatic Chemical Design Using a Data-Driven Con-
tinuous Representation of Molecules. ACS Cent. Sci., 4(2):268-276, 2018.
Gabriel Lima Guimaraes, Benjamin Sanchez-Lengeling, Carlos Outeiral, Pedro Luis Cunha Farias,
and Algn Aspuru-Guzik. Objective-Reinforced Generative Adversarial Networks (ORGAN) for
Sequence Generation Models. arXiv preprint arXiv:1705.10843, 2018.
J. D. Hunter. Matplotlib: A 2D graphics environment. Comput. Sci. Eng., 9(3):90-95, 2007.
Tamara Husch and Markus Reiher. Comprehensive Analysis of the Neglect of Diatomic Differential
Overlap Approximation. J. Chem. Theory Comput., 14(10):5169-5179, 2018.
Tamara Husch, Alain C. Vaucher, and Markus Reiher. Semiempirical molecular orbital models
based on the neglect of diatomic differential overlap approximation. Int. J. Quantum Chem., 118
(24):e25799, 2018.
S. Rao Jammalamadaka and GyOrgy H. Terdik. Harmonic analysis and distribution-free inference
for spherical distributions. J. Multivar. Anal, 171:436-451, 2019.
10
Published as a conference paper at ICLR 2021
Jan Jensen. XYZ2Mol. https://github.com/jensengroup/xyz2mol, 2019.
Wengong Jin, Connor Coley, Regina Barzilay, and Tommi Jaakkola. Predicting Organic Reaction
Outcomes with Weisfeiler-Lehman Network. In Advances in Neural Information Processing Sys-
tems,pp. 2607-2616, 2017.
Mathias S. J0rgensen, Henrik L. Mortensen, S0ren A. Meldgaard, Esben L. Kolsbjerg, Thomas L.
Jacobsen, KnUd H. S0rensen, and Bj0rk Hammer. Atomistic structure learning. J. Chem. Phys.,
151(5):054111, 2019.
Yeonjoon Kim and Woo Youn Kim. Universal Structure Conversion Method for Organic Molecules:
From Atomic Connectivity to Three-Dimensional Geometry. Bull. Korean Chem. Soc., 36(7):
1769-1777, 2015.
Risi Kondor and Shubhendu Trivedi. On the Generalization of Equivariance and Convolution in
Neural Networks to the Action of Compact Groups. In International Conference on Machine
Learning, pp. 2747-2755. PMLR, 2018.
Risi Kondor, Zhen Lin, and Shubhendu Trivedi. Clebsch- Gordan Nets: A Fully Fourier Space
Spherical Convolutional Neural Network. In S. Bengio, H. Wallach, H. Larochelle, K. Grauman,
N. Cesa-Bianchi, and R. Garnett (eds.), Advances in Neural Information Processing Systems 31,
pp. 10117-10126. Curran Associates, Inc., 2018.
Gregory Landrum. RDKit 2019.09.3. http://www.rdkit.org/, 2019. (Accessed: 22. January 2019).
V. I. Lebedev. Values of the nodes and weights of ninth to seventeenth order gauss-markov quadra-
ture formulae invariant under the octahedron group with inversion. Zh. Vychisl. Mat. Mat. Fiz.,
15(1):44-51, 1975.
V. I. Lebedev. Spherical quadrature formulas exact to orders 25-29. Sibirsk. Mat. Zh., 18(1):99-107,
1977.
Yibo Li, Liangren Zhang, and Zhenming Liu. Multi-objective de novo drug design with conditional
graph generative model. J. Cheminf., 10(1):33, 2018a.
Yujia Li, Oriol Vinyals, Chris Dyer, Razvan Pascanu, and Peter Battaglia. Learning Deep Generative
Models of Graphs. arXiv preprint arXiv:1803.03324, 2018b.
Qi Liu, Miltiadis Allamanis, Marc Brockschmidt, and Alexander Gaunt. Constrained Graph Vari-
ational Autoencoders for Molecule Design. In Advances in Neural Information Processing Sys-
tems, pp. 7795-7804, 2018.
Wes McKinney. Data Structures for Statistical Computing in Python. In Stefan van der Walt and
Jarrod Millman (eds.), Proceedings of the 9th Python in Science Conference, pp. 51-56, 2010.
S0ren A. Meldgaard, Henrik L. Mortensen, Mathias S. J0rgensen, and Bj0rk Hammer. Structure
prediction of surface reconstructions by deep reinforcement learning. J. Phys.: Condens. Matter,
32(40):404005, 2020.
Benjamin Kurt Miller, Mario Geiger, Tess E. Smidt, and Frank Noe. Relevance of Rotationally
Equivariant Convolutions for Predicting Molecular Properties. arXiv preprint arXiv:2008.08461,
2020.
Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Andrei A. Rusu, Joel Veness, Marc G. Belle-
mare, Alex Graves, Martin Riedmiller, Andreas K. Fidjeland, Georg Ostrovski, Stig Petersen,
Charles Beattie, Amir Sadik, Ioannis Antonoglou, Helen King, Dharshan Kumaran, Daan Wier-
stra, Shane Legg, and Demis Hassabis. Human-level control through deep reinforcement learning.
Nature, 518(7540):529-533, 2015.
Daniel Neil, Marwin Segler, Laura Guasch, Mohamed Ahmed, Dean Plumbley, Matthew Sellwood,
and Nathan Brown. Exploring Deep Recurrent Models with Reinforcement Learning for Molecule
Design. OpenReview, 2018. URL https://openreview.net/forum?id=HkcTe-bR-.
11
Published as a conference paper at ICLR 2021
Marcus Olivecrona, Thomas Blaschke, Ola Engkvist, and Hongming Chen. Molecular de-novo
design through deep reinforcement learning. J. Cheminf., 9(1):48, 2017.
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor
Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas Kopf, Edward
Yang, Zachary DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner,
Lu Fang, Junjie Bai, and Soumith Chintala. PyTorch: An Imperative Style, High-Performance
Deep Learning Library. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d’Alche-Buc, E. Fox,
and R. Garnett (eds.), Advances in Neural Information Processing Systems 32, pp. 8026-8037.
Curran Associates, Inc., 2019.
Mariya Popova, Olexandr Isayev, and Alexander Tropsha. Deep reinforcement learning for de novo
drug design. Sci. Adv., 4(7):eaap7885, 2018.
Evgeny Putin, Arip Asadulaev, Yan Ivanenkov, Vladimir Aladinskiy, Benjamin Sanchez-Lengeling,
Aldn Aspuru-Guzik, and Alex Zhavoronkov. Reinforced Adversarial Neural Computer for de
Novo Molecular Design. J. Chem. Inf. Model., 58(6):1194-1204, 2018.
Petra Schneider, W. Patrick Walters, Alleyn T. Plowright, Norman Sieroka, Jennifer Listgarten,
Robert A. Goodnow, Jasmin Fisher, Johanna M. Jansen, Jos6 S. Duca, Thomas S. Rush, Matthias
Zentgraf, John Edward Hill, Elizabeth Krutoholow, Matthias Kohler, Jeff Blaney, Kimito Funatsu,
Chris Luebkemann, and Gisbert Schneider. Rethinking drug design in the artificial intelligence
era. Nat. Rev. Drug Discovery, pp. 1-12, 2019.
John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov. Proximal policy
optimization algorithms. arXiv preprint arXiv:1707.06347, 2017.
Marwin H. S. Segler, Thierry Kogej, Christian Tyrchan, and Mark P. Waller. Generating Focused
Molecule Libraries for Drug Discovery with Recurrent Neural Networks. ACS Cent. Sci., 4(1):
120-131, 2018.
Gregor NC Simm, Robert Pinsler, and Jos6 Miguel Herndndez-Lobato. Reinforcement learning
for molecular design guided by quantum mechanics. In International Conference on Machine
Learning, 2020. URL http://arxiv.org/abs/2002.07717.
James J. P. Stewart. Optimization of parameters for semiempirical methods V: Modification of
NDDO approximations and application to 70 elements. J. Mol. Model., 13(12):1173-1213, 2007.
Richard S Sutton and Andrew G Barto. Reinforcement learning: An introduction. MIT press, 2018.
Nathaniel Thomas, Tess Smidt, Steven Kearnes, Lusann Yang, Li Li, Kai Kohlhoff, and Patrick
Riley. Tensor field networks: Rotation- and translation-equivariant neural networks for 3D point
clouds. arXiv prepint arXiv:1802.08219, 2018.
Elise van der Pol, Daniel E Worrall, Herke van Hoof, Frans A Oliehoek, and Max Welling.
MDP homomorphic networks: Group symmetries in reinforcement learning. arXiv preprint
arXiv:2006.16908, 2020.
Maurice Weiler, Mario Geiger, Max Welling, Wouter Boomsma, and Taco S Cohen. 3D Steerable
CNNs: Learning Rotationally Equivariant Features in Volumetric Data. In S. Bengio, H. Wal-
lach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett (eds.), Advances in Neural
Information Processing Systems 31, pp. 10381-10392. Curran Associates, Inc., 2018.
Jiaxuan You, Bowen Liu, Zhitao Ying, Vijay Pande, and Jure Leskovec. Graph Convolutional Policy
Network for Goal-Directed Molecular Graph Generation. In Advances in Neural Information
Processing Systems, pp. 6410-6421, 2018.
Manzil Zaheer, Satwik Kottur, Siamak Ravanbakhsh, Barnabas Poczos, Russ R Salakhutdinov, and
Alexander J Smola. Deep sets. In Advances in Neural Information Processing Systems, pp.
3391-3401, 2017.
Zhenpeng Zhou, Steven Kearnes, Li Li, Richard N. Zare, and Patrick Riley. Optimization of
Molecules via Deep Reinforcement Learning. Sci. Rep., 9(1):1-10, 2019.
12
Published as a conference paper at ICLR 2021
A	Reward Calculation
In the reward function, the energy E has to be computed using quantum-chemical methods. For that,
we use the fast semi-empirical Parametrized Method 6 (PM6) (Stewart, 2007). In particular, we use
the implementation in the software package Sparrow (Husch et al., 2018; Bosia et al., 2020). For
each calculation, a molecular charge of zero and the lowest possible spin multiplicity are chosen.
All calculations are spin-unrestricted.
Limitations of semi-empirical methods are highlighted in, for example, recent work by Husch &
Reiher (2018). More accurate methods such as approximate density functionals need to be employed
especially for systems containing transition metals.
Further, We enforce that atoms are not placed too close (< 0.6 A) nor too far away from each other
(> 2.0 A). If the agent places an atom outside these boundaries, the minimum reward of -0.6 is
awarded and the episode terminates. Further, the environment encourages the agents to build single
molecular structures by terminating the episode and return a reward of -0.6 if elements forming
stable bimolecular compounds (e.g, H2) are placed too far away from other atoms on the canvas.
B S pherical Harmonics
The spherical harmonics form an orthonormal basis of the Hilbert space of square-integrable func-
tions L2C(S2). The first few spherical harmonics are given by:
Y00(3 = 2⅛
YJ3=屋 sin …、YNyy二 CoS H, Ym
(7)
ɪ sin Hei： (8)
—
Y2^2(H, φ) =	sin2 He-i2φ,	Y^^ 1(H") =，F CosHsinHe-iφ,
Y20 (H, Ψ) = ʌ/16∏ (3cos2 H - 1),
(9)
Y1 (也⑼
—
J Cos H sin Hei：	γ2(H,夕)=，- sin2 Hei2%
The spherical harmonics are normalized such that:
∣Y'm(H,夕)|2 SinHdHd夕=1	∀',m.
(10)
C Calculation of Invariant Features
One can obtain scalar invariats from the covariant features f (Anderson et al., 2019):
El ,1	. f> Γ∖ >≈	/ P∖	2
• Take the component' = 0: ξι(f) = f'=o.
.	一	一	一	・一.	, O
~ , A
~ , A
~ , A
• Calculate the scalar product with itself: ξ2(f') = Re[ξ2(f)] + Im[ξ2(f)], where ξ2(f)
P'	(-1)m^m f-m
乙m=-'( 1) f' J'	.
• Calculate the SO(3)-invariant norm: ξ3(f) = Pm=-` fm(勿),where * denotes the
complex conjugate.
L
The invariant components are then concatenated f inv J TnV = ξι(f)㊉(㊉ g=0 ξ2(f')㊉ ξ3(f')).
13
Published as a conference paper at ICLR 2021
D Probability Distribution for Orientation
In the main paper, We propose the expression in Eq. (5) for the distribution p(x∣d, e, f, s). An
alternative, equally valid expression is
P(X|d, e,f, S)=
Lmax `
X X √krmγm(χ)
'=0 m=-' Vk
(11)
where the term 1∕√k with k = PLmx Pm=-'l^m∣2 normalizes the distribution. We found exper-
imentally that an agent using this expression performs Worse When generating molecular structures
featuring complex geometries. We hypothesize that this is because the distribution cannot get peaked
enough for Lmax ≤ 5. As larger Lmax would result in a significant increase in computational com-
plexity, we chose the expression in Eq. (5) over that in Eq. (11).
The normalization constant Z in Eq. (5) is estimated via Lebedev quadrature with 1730 angular grid
points (Lebedev, 1975; 1977). We sample from the distribution in Eq. (5) using rejection sampling
(BiShop, 2009) with a uniform proposal distribution q(X) = 4∏. In rejection sampling, one first
draws a sample from Xo from q(X). Then, one generates a random number uo from the uniform
distribution over [0, Mq(Xo)], where M is such that Mq(X) ≥ p(X∣d, e, f, s). We determine M by
evaluating p(X∣d, e, f, s) on a uniform grid on S2 employing a Fibonacci ‘sunflower, grid. Finally,
if uo > p(X∣d, e, f, s) then the sample is accepted.
We ran an experiment to compare the Covariant agent as described in the main paper with an
agent employing Eq. 11 for the distribution p(X∣d, e, f, s). In Fig. 7, the hypothesis that the distri-
bution in Eq. 11 cannot get narrow enough is confirmed. After 40 000 steps, the online performance
of the alternative agent Covariant (Alt.) converges to around 0.5, which is significantly lower
compared to Covariant. Note that the difference is smaller when considering the offline return
because the estimated global mode for each distribution could still be similar.
1.0 -
0.8 -
0.6 -
0.4 -
0.2 -
0.0 -
-0.2 -
-0.4 -
0	10	20	30	40	50
Steps x 1000
Figure 7: Comparison of Covariant agent (red) with an agent employing alternative distribution
for the orientation X (green). The average online performance on the single-bag task with B = SF6
across 5 seeds is shown. Dashed lines denote the optimal return for the experiment. Error bars
indicate two standard deviations.
U」n4①= Φ⊂--⊂O ΦCTra<-φ><
E	Baselines
E.1 Opt Agent
Below, we detail the algorithm of the Opt agent. At the beginning of each experiment, the agent
is given a canvas Co, a bag Bo, and a black-box function that can compute the energy E(C) and the
atomic forces F (C ) for a given canvas. We assume a total charge of zero and a low-spin configura-
tion. At the end of each experiment, we compute the total reward obtained for the final structure on
canvas CT and report the total number of energy and gradient computations.
14
Published as a conference paper at ICLR 2021
1.	If the canvas Ct is not empty, randomly choose a focal atom f from the list of available
atoms on the canvas. An atom is considered available if its number of neighbors is less
than a predefined number that depends on its element (e.g., one for hydrogen and four for
carbon). TWo atoms on the canvas are neighbors if their Euclidean distance is below 1.5 A.
If there are no available atoms on the canvas, a focal atom is randomly chosen from the list
of atoms on the canvas.
2.	Randomly choose an element et from the bag Bt .
3.	Randomly place the atom at = (et, xt) on a sphere with radial distance d = 1.1 A around
xf to obtain Ct+1,raw. If the canvas is empty, place the atom at the origin.
4.	Optimize only the position of at using F to obtain Ct+1,opt.
5.	Compute the energy difference ∆E(t) = E(Ct+1,opt) - [E(Ct) + E({et , 0})].
6.	If ∆E(t) > 0, return et to the bag and go back to step 1.
7.	Optimize canvas Ct+1,opt using F to obtain Ct+1.
8.	Increment t by 1.
9.	If the bag is not empty, go back to step 1.
In the experiments, the different agents need to be given a comparable computational budget to
ensure a meaningful comparison of their performance. This is difficult as they use different compu-
tational resources: Opt runs on a CPU whereas Internal and Covariant perform many of their
computations on a GPU. However, we found experimentally that the quantum-chemical calculations
are the most computationally expensive ones. These calculations are performed in the same way
for all approaches. Therefore, we believe that by granting each approach the same number of PM6
calculations we achieve a fair comparison.
E.2 Optimal Return
The optimal return for the single-bag tasks was derived in the following way. First, we obtained
molecular structures for the complexes SOF4, IF5 , SF6, and SOF6. Subsequently, we performed a
structure optimization using the PM6 method. Since the undiscounted return is path-independent,
we determined the return R(s) by computing the total interaction energy in the canvas C, i.e.
R(S)= It E ({ei, 0})1 — E (C).
(12)
i=1
F	Experimental Details
F.1 Computing Infrastructure
Experiments were run on an Intel Xeon E5-2650 v4 2.2GHz 12-core processor (96GiB RAM) and
an Nvidia P100 GPU (16GiB). Our agent is implemented in the deep learning framework PyTorch
(Paszke et al., 2019). Data analysis was performed with the Python libraries matplotlib (Hunter,
2007) and pandas (McKinney, 2010).
F.2 Implementation Details
The model architecture is summarized in Table 2, where the dimensions of Sinv and Sifn,ve are
dinv = (Lmax + 2) ∙ T ∙ 2 and dfv = (Lmax + 2) ∙ Te ∙ 2, respectively. If possible, we made
similar architectural choices as Simm et al. (2020), e.g. regarding the number of hidden units/layers,
activation functions, and initialization schemes. We initialize the biases of each network with 0 and
each weight matrix as a (semi-)orthogonal matrix. After each hidden layer, a ReLU non-linearity is
employed. As explained in the main text, both MLPf and MLPe use a masked softmax activation
function to guarantee that only valid actions are chosen. To model the distance d, we employ a Gaus-
sian mixture model consisting of M = 3 Gaussians. As we treat the standard deviations {σm }3m=1
15
Published as a conference paper at ICLR 2021
Table 2: Model architecture for actor and Critic networks.
Network	Dimensions per layer	output activation
MLPf	dinv, 128,1	masked softmax
MLPe	dinv, 128, emax	masked softmax
MDN	difn,ve,128,6	linear (∏m), tanh (μm,)
MLPφ	dinv, 128, 128	linear
MLPρ	128, 128, 1	linear
as global parameters, the MDN has 6 outputs. Further, we rescale the means μm, ∈ [-1,1] to
μm ∈ [dmin, dmax]. If the sampled distance is negative, we clip the value at 0.001.
Hyperparameters for Cormorant are listed in Table 3. In our experiments, we found it important
to use multiple filters τe per element (e.g. 4) and to set Lmax = 4. This gives the model enough
flexibility to represent complex spherical distributions while remaining computationally tractable.
For more details on Cormorant, see the original work (Anderson et al., 2019). Further hyperpa-
rameters used in our experiments are in Table 4. PPO is known to be relatively robust with respect
to the choice of hyperparameters, and we found the default values to be sufficient in most cases.
Within the actor, the scaling parameter β is important to avoid that the spherical distribution ap-
proaches a delta distribution. Note that values of β can vary significantly across experiments and
might require some tuning. Lastly, the right number of samples S for the global mode estimation of
the spherical distribution generally depends on the shape of the distribution. In particular, we would
expect that more samples are required as the distribution becomes more peaked. Since we avoid
pathological behaviors by scaling the distribution with β, we found S = 1024 to be sufficient for all
our experiments.
Table 3: Hyperparameters for Cormorant (Anderson et al., 2019) used in all experiments.
Hyperparameter	Value
Number of Clebsch-Gordan layers	3
Lmax in spherical harmonics series expansion	4
Number of filters τe per element	4
Number of filters T	Te ∙ Ne
Table 4: Hyperparameters for the single-bag, multi-bag and stochastic-bag tasks. Values in paren-
theses were only used for the single-bag task. For further details on how the PPo hyperparameters
are defined, please refer to Schulman et al. (2017).
Hyperparameter	Search Set	Value
Range [dmin, dmax] (A)	—	[0.95, 1.80]
Number of workers	—	10
PPo clipping	—	0.2
PPo gradient clipping	—	0.5
PPo GAE parameter λ	—	0.95
PPo value function coefficient c1	—	1
PPo entropy coefficient c2	{0.01, 0.05}	0.01
Number of optimization epochs	—	7
Adam stepsize	—	3∙10-4
Discount factor γ	—	0.99
Time horizon T	—	20 ∙ |B|
Distance clipping	—	0.001
Scaling factor β	{-100, -10, -1, 1, 10, 100}	100 (-10)
Number of samples S for mode estimation	—	1024
16
Published as a conference paper at ICLR 2021
G Additional Results
(a)
4 -
3 -
2 -
1 -
0 -
0
50	100	150	200	250
Steps x 1000
UJmBa①6e」①><
(b)
4 -
3 -
2 -
1 -
0 -
0
50
100	150
Steps x 1000
200
Figure 8: Average offline performance on the stochastic-bag task with B* = C7H8N2O2 evaluated
on (a) C7H8N2O2 and (b) larger, unseen bags {C6H14O3, C7H16O, C7H16O2, C8H18O} across 10
seeds. For comparison, we show an agent that is trained only on the test bags (purple). Error bars
indicate two standard deviations.
In Fig. 9, a selection of molecular structures generated by the three agents during offline evaluation
is shown. The agents are trained on a distribution over bags with B* = C7H10O2 and tested on
sets of larger, out-of-distribution bags {C6H14O3 , C7H16O, C7H16O2 , C8H18O} (cf. Fig. 6 in the
main text). From visual inspection of the structures, it can be seen why Opt fails at this task: it
tends to generate molecular clusters, often containing H2. Similarly, Internal commonly builds
H2O molecules instead of constructing a single organic molecule out of the atoms in the bag. By
contrast, Covariant often builds valid molecules. Further, its generated structures are more often
“branched” than those of Internal, indicating a higher degree of complexity.
Figure 9: Selection of molecular structures generated by (a) Opt, (b) Internal, and (c) Covari-
ANT during the last offline evaluation. The agents are trained on a distribution over bags with B* =
C7H10O2 and tested on the out-of-distribution bags {C6H14O3 , C7H16O, C7H16O2 , C8H18O}.
Next, we assess the ability of Covariant to generate solvation clusters—a type of molecular struc-
ture that cannot be built with graph-based approaches. Following Simm et al. (2020), we task the
agent to place 5 water molecules around a formaldehyde molecule that is already on the canvas at
the beginning of each episode. In addition, the reward function is augmented with a penalty term for
placing atoms far away from the center, i.e. r(st, at) = -∆E-ρkxk2, where ρ is a hyper-parameter
that is set to 0.01 (see Simm et al. (2020) for details). Therefore, the agent needs to place the water
molecules such that hydrogen bonds can be formed between water molecules and between water
molecules and the solute.
17
Published as a conference paper at ICLR 2021
U-Jn.Maα ΦCTro^φ><
0	25	50	75	100	125	150
Steps x 1000
Figure 10: Average offline performance on the solvation task with 5 H2O molecules and formalde-
hyde as the solute across 10 seeds. Error bars show two standard errors. The dashed line denotes the
optimal return. A selection of molecular clusters generated by the Covariant agent is shown.
From Fig. 10, it can be seen that Covariant can solve this task by constructing stable H2O
molecules and placing them in the vicinity of the solute. From visual inspection of the generated
structures, it can be observed that in many cases Covariant arranges the molecules such that in-
termolecular bonds can be formed. However, it should be noted that the quantum-chemical method
used in the reward function is not very well suited for modeling these interactions. Finally, Fig. 10
shows that while Internal learns faster at the beginning of training, Covariant is slightly out-
performing Internal towards the end.
H Runtime Evaluation
We compared the runtimes between OPT, INTERNAL, and COVARIANT. For instance, for the single-
bag task with the bag C3H5NO3, T = 240 steps of the last rollout took COVARIANT and INTERNAL
on average 12 and 11 seconds (s), respectively. The final offline evaluation took the agents on
average 4 and 1s, respectively. This speed difference is mainly due to the relatively slow rejection
sampling procedure in Covariant. Each iteration, policy optimization took on average 2 and
6s for the agents Covariant and Internal, respectively. In this case, Internal is slower than
Covariant as it performed around twice as many epochs during optimization due to early stopping.
Since there is no training for Opt, this agent was overall faster than the others. Further, we note
that the largest fraction of time was spent on the quantum-chemical calculations which are the same
for all agents. The time the quantum-chemical calculation takes to converge depends not only on
the size but also on the geometry of the input structure. The entire experiment took Covariant
approximately 4 hours, Internal 5 hours, and Opt 3 hours.
18