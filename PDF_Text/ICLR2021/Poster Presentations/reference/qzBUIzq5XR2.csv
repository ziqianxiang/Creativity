title,year,conference
 Building machinesthat learn and think for themselves,2017, Behavioral and Brain Sciences
 Learning to infer graphics programsfrom hand-drawn images,2018, In NeurIPS
 Generating new concepts with hybrid neuro-symbolic models,2020, InCogSci
 Model-agnostic meta-learning for fast adaptation of deepnetworks,2017, In ICML
 Synthesizing programsfor images using reinforced adversarial learning,2018, In ICML
 Few-shot learning with graph neural networks,2018, In ICLR
 A rational analysis ofrule-based concept learning,2008, Cognitive Science
 Concepts in a probabilistic languageof thought,2015, In E
 Generating sequences with recurrent neural networks,2013, arXiv preprintarXiv:1308
 Neural turing machines,2014, arXiv preprint arXiv:1410
 Multi-object representation learning with iterative variational inference,2019, InICML
 DRAW: A recurrent neuralnetwork for image generation,2015, In ICML
 A neural representation of sketch drawings,2018, In ICLR
 The Variational Ho-moencoder: Learning to learn high capacity generative models from few examples,2018, In UAI
 Learning to learn generative programs withMemoised Wake-Sleep,2020, In UAI
 Stacked Capsule Autoencoders,2019, InNeurIPS
 Generalization without systematicity: On the compositional skillsof sequence-to-sequence recurrent networks,2018, In ICML
 Human-level concept learning throughprobabilistic program induction,2015, Science
 Building machines that learnand think like people,2017, Behavioral and Brain Sciences
 The Omniglot challenge: A 3-yearprogress report,2019, Behavioral Sciences
 Deep learning,2015, Nature
 Visual presentation of single lettersactivates a premotor area involved in writing,2003, Neuroimage
 The Algebraic Mind: Integrating Connectionism and Cognitive Science,2003, MITPress
 Letting structure emerge: Connectionist and dynamical systems approaches tocognition,2010, Trends in Cognitive Science
 The big book of concepts,2002, MIT Press
 The role of theories in conceptual coherence,1985, PsychologicalReview
 Learning compositional rulesvia neural program synthesis,2020, arXiv preprint arXiv:2003
 The logical primitives of thought:Empirical foundations for compositional cognitive models,2016, Psychological Review
 Neural programmer-interpreters,2016, In ICLR
 One-Shot generalizationin deep generative models,2016, In ICML
 Attentive recurrent comparators,2017, In ICML
 Prototypical networks for few-shot learning,2017, In NeurIPS
 HOUDINI: Lifelonglearning as program synthesis,2018, In NeurIPS
 Neural-symbolic VQA:Disentangling reasoning from vision and language understanding,2018, In NeurIPS
