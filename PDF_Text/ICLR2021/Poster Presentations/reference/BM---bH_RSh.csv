title,year,conference
 Proximal mean-field for neural network quantization,2019, In Proceedings of the IEEE International Conference onComputer Vision
 Estimating or propagating gradients throughstochastic neurons for conditional computation,2013, arXiv preprint arXiv:1308
 Distributed optimization and statistical learning via thealternating direction method of multipliers,2011, Now Publishers Inc
 The lottery tickets hypothesis for supervised and self-supervised pre-training incomputer vision models,2020, arXiv preprint arXiv:2012
 The lottery ticket hypothesis for pre-trained bert networks,2020, arXiv
 Long live the lottery:The existence of winning tickets in lifelong learning,2021, In International Conference on LearningRepresentations
 Gans can play lottery tickets too,2021, InInternational Conference on Learning Representations
 Autogan-distiller: Searching to compress generative adversarial networks,2020, arXiv preprint arXiv:2006
 Mixed dimen-sion embeddings with application to memory-efficient recommendation systems,2019, arXiv preprintarXiv:1909
 Amc: Automl for modelcompression and acceleration on mobile devices,2018, In Proceedings of the European Conference onComputer Vision (ECCV)
 Session-basedrecommendations with recurrent neural networks,2015, arXiv preprint arXiv:1511
 Distilling the knowledge in a neural network,2015, arXivpreprint arXiv:1503
 An efficient group recommendationmodel with multiattention-based neural networks,2020, IEEE Transactions on Neural Networks andLearning Systems
 Adam: A method for stochastic optimization,2014, arXiv preprintarXiv:1412
 Pruning filters forefficient convnets,2016, arXiv preprint arXiv:1608
 Metapruning: Meta learning for automatic neural network channel pruning,2019, In Proceedingsof the IEEE International Conference on Computer Vision
 Goodstudents play big lottery better,2021, arXiv preprint arXiv:2101
 Feature selection for fm-based context-aware recommendation systems,2017, In 2017 IEEE International Symposium on Multimedia (ISM)
 Importance estimation forneural network pruning,2019, In Proceedings of the IEEE Conference on Computer Vision and PatternRecognition
 Deep learning recommendationmodel for personalization and recommendation systems,2019, CoRR
 Stochastic proximal gradient descent with acceleration techniques,2014, In Advances inNeural Information Processing Systems
 Model compression via distillation and quantiza-tion,2018, arXiv preprint arXiv:1802
 Efficient dc algorithm for constrained sparseoptimization,2017, arXiv preprint arXiv:1701
 Similarity-preserving knowledge distillation,2019, In Proceedings of theIEEE International Conference on Computer Vision
 Learning structured sparsity in deepneural networks,2016, In Advances in neural information processing systems
 Deepk-means: Re-training and parameter sharing with harder cluster assignments for compressing deepconvolutions,2018, In International Conference on Machine Learning
 Session-basedrecommendation with graph neural networks,2019, In Proceedings of the AAAI Conference on ArtificialIntelligence
 Ecc: Platform-independent energy-constrained deep neuralnetwork compression via a bilinear regression model,2019, In Proceedings of the IEEE Conference onComputer Vision and Pattern Recognition
