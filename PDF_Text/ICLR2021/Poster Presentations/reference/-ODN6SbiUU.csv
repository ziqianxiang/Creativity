title,year,conference
 Laplacian eigenmaps and spectral techniques for embedding andclustering,2002, In Advances in neural information processing systems
 Mixmatch: A holistic approach to semi-supervised learning,2019, In H
 Remixmatch: Semi-supervised learning with distribution matching and augmentationanchoring,2020, In International Conference on Learning Representations
 Semi-supervised classification by low density separation,2005, InAISTATS
 Semi-Supervised Learning,0262, The MITPress
 A simple framework forcontrastive learning of visual representations,2020, arXiv preprint arXiv:2002
 Bigself-supervised models are strong semi-supervised learners,2020, Advances in Neural InformationProcessing Systems
 Randaugment: Practical dataaugmentation with no separate search,2019, CoRR
 The comparison and evaluation of forecasters,1983, 1983
 Improved regularization of convolutional neural networkswith cutout,2017, arXiv preprint arXiv:1708
 Dropout as a bayesian approximation: Representing modeluncertainty in deep learning,2016, In Maria Florina Balcan and Kilian Q
 Shake-shake regularization,2017, arXiv preprint arXiv:1705
 Dropblock: A regularization method for convolutionalnetworks,2018, In S
 Semi-supervised learning by entropy minimization,2005, In Advancesin neural information processing systems
 Practical variational inference for neural networks,2011, In J
 Iterative label improvement: Robusttraining by confidence based filtering and dataset partitioning,2020, arXiv: Learning
 Deep residual learning for imagerecognition,2016, In Proceedings of the IEEE conference on computer vision and pattern recognition
 Videossl: Semi-supervisedlearning for video classification,2020, arXiv preprint arXiv:2003
 Transductive inference for text classification using support vector machines,1999, InIcml
 Dual student: Breakingthe limits of the teacher in semi-supervised learning,2019, In The IEEE International Conference onComputer Vision (ICCV)
 Learning multiple layers of features from tiny images,2009, 2009
 Simple and scalable predictiveuncertainty estimation using deep ensembles,2017, In I
 Principled hybrids of generativeand discriminative models,2006, In 2006 IEEE Computer Society Conference on Computer Vision andPattern Recognition (CVPRâ€™06)
 Pseudo-label : The simple and efficient semi-supervised learning method for deepneural networks,2013, 2013
 Deep metric transfer for label propagation withlimited annotated data,2019, In Proceedings of the IEEE International Conference on Computer VisionWorkshops
 Sgdr: Stochastic gradient descent with warm restarts,2017, In InternationalConference on Learning Representations (ICLR) 2017 Conference Track
 Structured and efficient variational deep learning with matrixgaussian posteriors,2016, In Maria Florina Balcan and Kilian Q
 Smooth neighbors on teacher graphs forsemi-sUpervised learning,2018, CVPR
 Predictive Uncertainty estimation via prior networks,2018, In Advancesin Neural Information Processing Systems
 Effective self-training for parsing,2006, InProceedings of the Human Language Technology Conference of the NAACL
 VirtUal adversarial training: AregUlarization method for sUpervised and semi-sUpervised learning,2018, IEEE Transactions on PatternAnalysis and Machine Intelligence
 Uncertainty-aware self-training for few-shot textclassification,2020, Advances in Neural Information Processing Systems
 UnsUpervised learning of visUal representations by solving jigsawpUzzles,2016, In European Conference on Computer Vision
 RealisticevalUation of deep semi-sUpervised learning algorithms,2018, In S
 RealisticevalUation of deep semi-sUpervised learning algorithms,2018, In Advances in Neural InformationProcessing Systems
 TransdUctivesemi-sUpervised deep learning Using min-max featUres,2018, In The European Conference on ComputerVision (ECCV)
 Prototypical networks for few-shot learning,2017, InAdvances in neural information processing systems
 Fixmatch: Simplifying semi-sUpervised learning withconsistency and confidence,2020, arXiv preprint arXiv:2001
 Ucf101: A dataset of 101 hUman actionsclasses from videos in the wild,2012, arXiv preprint arXiv:1212
 Mean teachers are better role models: Weight-averaged consistencytargets improve semi-supervised deep learning results,2017, In I
 Efficient objectlocalization using convolutional networks,2015, In Proceedings of the IEEE Conference on ComputerVision and Pattern Recognition
 Interpolationconsistency training for semi-supervised learning,2019, In IJCAI
 Matching networks for oneshot learning,2016, In Advances in neural information processing systems
 Regularization of neuralnetworks using dropconnect,2013, In International conference on machine learning
 A baseline for multi-label image classification usingan ensemble of deep convolutional neural networks,2019, In 2019 IEEE International Conference onImage Processing (ICIP)
 3d semi-supervised learning with uncertainty-aware multi-view co-training,2020, In The IEEE Winter Conference on Applications of Computer Vision
 Self-training with noisy studentimproves imagenet classification,2019, arXiv preprint arXiv:1911
 Distance-based learning from errors forconfidence calibration,2020, In International Conference on Learning Representations
 Unsupervised word sense disambiguation rivaling supervised methods,1995, In 33rdAnnual Meeting of the Association for Computational Linguistics
 Probabilistic end-to-end noise correction for learning with noisy labels,2019, InProceedings of the IEEE Conference on Computer Vision and Pattern Recognition
 Wide residual networks,2016, In Edwin R
 mixup: Beyond empiricalrisk minimization,2018, In International Conference on Learning Representations
 Rectifying pseudo label learning via uncertainty estimation for domainadaptive semantic segmentation,2020, arXiv preprint arXiv:2003
 Time-consistent self-supervision for semi-supervisedlearning,2020, 2020
 Semi-supervised learning literature survey,2005, Technical report
 The results are shown in the table 10,2017, Ourmethod achieves an error rate of 28
