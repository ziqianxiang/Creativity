title,year,conference
 Emnist: an extension ofmnist to handwritten letters,2017, arXiv preprint arXiv:1702
 Detection of inflUential observation in linear regression,1977, Technometrics
 Calibrating noise to variance in adaptive data analysis,2018, InConference On Learning Theory
 Explaining and harnessing adversarialexamples,2015, In International Conference on Learning Representations
 EvalUation of neUral architectUres trained with sqUare loss vs cross-entropy in classification tasks,2020, arXiv preprint arXiv:2006
 NeUral tangent kernel: Convergence and gen-eralization in neUral networks,2018, In S
 Dogs vs,2013, Cats
 Not all samples are created equal: Deep learning withimportance sampling,2018, volume 80 of Proceedings ofMachine Learning Research
 Wide neural networks of any depth evolve as linear modelsunder gradient descent,2019, In Advances in neural information processing systems
 Very sparse random projections,2006, In Proceedingsof the 12th ACM SIGKDD international conference on Knowledge discovery and data mining
 Learning word vectors for sentiment analysis,2011, In Proceedings of the 49th Annual Meetingof the Association for Computational Linguistics: Human Language Technologies
 Glove: Global vectors for wordrepresentation,2014, In Empirical Methods in Natural Language Processing (EMNLP)
 Information-theoretic analysis of stability and bias of learning algorithms,2016, In 2016 IEEE Information TheoryWorkshop (ITW)
 Fisher information and stochastic complexity,0018, IEEE Transactions on InformationTheory
 Information in infinite ensembles of infinitely-wideneural networks,2020, volume 118 of Proceedings of The 2nd Symposium on Advances in ApproximateBayesian Inference
 Opening the black box of deep neural networks via informa-tion,2017, arXiv preprint arXiv:1703
 Intriguing properties of neural networks,2014, In International Conference onLearning Representations
 An empirical study of example forgetting during deep neural networklearning,2019, In International Conference on Learning Representations
 Unbiased look at dataset bias,2011, In CVPR 2011 
 Deltagrad: Rapid retraining of machine learn-ing models,2020, arXiv preprint arXiv:2006
 Data valuation using reinforcement learning,2019, arXivpreprint arXiv:1909
 Pre-dicting training time without training,2020, Advances in Neural Information Processing Systems 33
 This is unavoidable as one example can be moreinformative for one algorithm and less informative for another,1000, Nevertheless
