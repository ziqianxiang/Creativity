title,year,conference
 Learning to learn by gradient descent by gradientdescent,2016, In Advances in neural information processing systems
 Mixed equilibria and dynamical systems arising from fictitiousplay in perturbed games,1999, Games and Economic Behavior
 Curriculum learning,2009, InProceedings of the 26th annual international conference on machine learning
 Learning to optimize in swarms,2019, InAdvances in Neural Information Processing Systems
 Training stronger baselines for learning to optimize,2020, arXiv preprint arXiv:2010
 Automated synthetic-to-real generalization,2020, In International Conference on Machine Learning
 Training gans withoptimism,2018, In International Conference on Learning Representations (ICLR 2018)
 Halpern iteration for near-optimal and parameter-free monotone inclusion andstrong solutions to variational inequalities,2020, arXiv preprint arXiv:2002
 Linear convergence of the primal-dual gradient method for convex-concavesaddle point problems without strong convexity,2019, In The 22nd International Conference on ArtificialIntelligence and Statistics
 Unsupervised domain adaptation by backpropagation,2014, arXivpreprint arXiv:1409
 A varia-tional inequality perspective on generative adversarial networks,2018, arXiv preprint arXiv:1802
 Nightmare at test time: robust learning by feature deletion,2006, InProceedings ofthe 23rd international conference on Machine learning
 Fixed points of nonexpanding maps,1967, Bulletin of the American MathematicalSociety
 K-beam minimax: Efficient optimization for deep adversariallearning,2018, arXiv preprint arXiv:1805
 Safeguarded learned convexoptimization,2020, arXiv preprint arXiv:2003
 Learning to defense by learningto attack,2018, arXiv preprint arXiv:1811
 Mentornet: Learningdata-driven curriculum for very deep neural networks on corrupted labels,2017, arXiv preprintarXiv:1712
 Gradient-based meta-learning with learned layerwise metric andsubspace,2018, arXiv preprint arXiv:1801
 Halo: Hardware-awarelearning to optimize,2020, In European Conference on Computer Vision
 Learning to optimize,2016, arXiv preprint arXiv:1606
 Interaction matters: A note on non-asymptotic local convergenceof generative adversarial networks,2019, In The 22nd International Conference on Artificial Intelligenceand Statistics
 On gradient descent ascent for nonconvex-concaveminimax problems,2019, arXiv preprint arXiv:1906
 Near-optimal algorithms for minimax optimization,2020, arXivpreprint arXiv:2002
 Distributed sparse linearregression,2010, IEEE Transactions on Signal Processing
 A unified analysis of extra-gradient andoptimistic gradient methods for saddle point problems: Proximal point approach,2019, arXiv preprintarXiv:1901
 Zur theorie der gesellschaftsspiele,1928, Mathematische annalen
 Game theoretic optimization via gradient-based nikaido-isoda function,2019, In Kamalika Chaudhuri and Ruslan Salakhutdinov (eds
 Ode analysis of stochastic gradient methods with optimismand anchoring for minimax problems and gans,2019, arXiv:1905
 On solving minimax optimization locally: Afollow-the-ridge approach,2019, arXiv preprint arXiv:1910
 Towards privacy-preserving visualrecognition via adversarial training: A pilot study,2018, In Proceedings of the European Conference onComputer Vision (ECCV)
 Privacy-preservingdeep action recognition: An adversarial learning framework and a new dataset,2020, IEEE Transactionson Pattern Analysis and Machine Intelligence
