title,year,conference
 Star-caps: Capsule networks with straight-through attentiverouting,2019, In Advances in Neural Information Processing Systems
 Obfuscated gradients give a false sense of se-curity: Circumventing defenses to adversarial examples,2018, In International Conference on MachineLearning (ICML)
 Adversarial examples are not easily detected: Bypassing tendetection methods,2017, In Proceedings of the 10th ACM Workshop on Artificial Intelligence andSecurity
 Towards evaluating the robustness of neural networks,2017, In 2017ieee symposium on security and privacy (sp)
 Boost-ing adversarial attacks with momentum,2018, In Proceedings of the IEEE conference on computervision and pattern recognition (CVPR)
 Robust physical-world attacks on deep learningvisual classification,2018, In Proceedings of the IEEE Conference on Computer Vision and PatternRecognition
 Explaining and harnessing adversarialexamples,2015, In International conference on learning representations (ICLR)
 Interpretable graph capsule networks for object recognition,2020, 2020b
 Self-routing capsule networks,2019, In Advancesin Neural Information Processing Systems (NeurIPS)
 Learning multiple layers of features from tiny images,2009, 2009
 Adversarial examples in the physical world,2017, InInternational Conference on Learning Representations (ICLR)
 Towardadversarial robustness via semi-supervised robust training,2020, arXiv preprint arXiv:2003
 Efficient jointgradient based attack against sor defense for 3d point cloud classification,2020, In Proceedings of the28th ACM International Conference on Multimedia
 On the vulnerability of capsulenetworks to adversarial attacks,2019, 2019
 Readingdigits in natural images with unsupervised feature learning,2011, 2011
 Multi-level densecapsule networks,2018, In Asian Conference on Computer Vision
 Foolbox: A python toolbox to benchmarkthe robustness of machine learning models,2017, In Reliable Machine Learning in the Wild Workshop
 Sparse unsupervised capsules gen-eralize better,2018, arXiv preprint arXiv:1804
 Accessorize to a crime:Real and stealthy attacks on state-of-the-art face recognition,2016, In Proceedings of the 2016 acmsigsac conference on computer and communications security
 Very deep convolutional networks for large-scale imagerecognition,2015, In International Conference on Learning Representations (ICLR)
 Is robustnessthe cost of accuracy? - a comprehensive study on the robustness of 18 deep image classificationmodels,2018, In European Conference on Computer Vision (ECCV)
 Intriguing properties of neural networks,2014, In International conference onlearning representations (ICLR)
 Capsules withinverted dot-product attention routing,2020, In International Conference on Learning Representations(ICLR)
 Feature squeezing: Detecting adversarial examples in deepneural networks,2017, arXiv preprint arXiv:1704
 Cappronet: Deep feature learning via orthogo-nal projections onto capsule subspaces,2018, In Advances in Neural Information Processing Systems(NeurIPS)
