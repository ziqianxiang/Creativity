title,year,conference
 Compress: Self-supervisedlearning by compressing representations,2020, Advances in Neural Information Processing Systems
 Variationalinformation distillation for knowledge transfer,2019, In Proceedings of the IEEE Conference onComputer Vision and Pattern Recognition
 Deep clustering for unsuper-vised learning of visual features,2018, In Proceedings of the European Conference on Computer Vision(ECCV)
 Learning efficientobject detection models with knowledge distillation,2017, In Advances in Neural Information ProcessingSystems
 A simple framework forcontrastive learning of visual representations,2020, arXiv preprint arXiv:2002
 Bigself-supervised models are strong semi-supervised learners,2020, arXiv preprint arXiv:2006
 Improved baselines with momentumcontrastive learning,2020, arXiv preprint arXiv:2003
 On the efficacy of knowledge distillation,2019, In Proceedings ofthe IEEE International Conference on Computer Vision
 Imagenet: A large-scalehierarchical image database,2009, In 2009 IEEE conference on computer vision and pattern recognition
 Self-supervised representation learning by rotation featuredecoupling,2019, In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition
 Unsupervised representation learning bypredicting image rotations,2018, arXiv preprint arXiv:1803
 Noise-contrastive estimation: A new estimation principlefor unnormalized statistical models,2010, In Proceedings of the Thirteenth International Conference onArtificial Intelligence and Statistics
 Deep residual learning for imagerecognition,2016, In Proceedings of the IEEE conference on computer vision and pattern recognition
 Mask r-cnn,2017, In Proceedings oftheIEEE international conference on computer vision
 Data-efficient image recognition with contrastive predictive coding,2019, arXivpreprint arXiv:1905
 Distilling the knowledge in a neural network,2015, arXivpreprint arXiv:1503
 Searching for mobilenetv3,2019, InProceedings of the IEEE International Conference on Computer Vision
 Mobilenets: Efficient convolutional neural networks formobile vision applications,2017, arXiv preprint arXiv:1704
 Revisiting self-supervised visual representa-tion learning,2019, In Proceedings of the IEEE conference on Computer Vision and Pattern Recognition
 Lit: Learned intermediaterepresentation training for model compression,2019, In International Conference on Machine Learning
 Learning multiple layers of features from tiny images,2009, 2009
 Prototypical contrastivelearning of unsupervised representations,2020, arXiv preprint arXiv:2005
 Microsoft coco: Common objects in context,2014, In Europeanconference on computer vision
 StructuredknoWledge distillation for semantic segmentation,2019, In Proceedings of the IEEE Conference onComputer Vision and Pattern Recognition
 Apprentice: Using knoWledge distillation techniques to improveloW-precision netWork accuracy,2017, arXiv preprint arXiv:1711
 Rectified linear units improve restricted boltzmann machines,2010, InICML
 Unsupervised learning of visual representations by solving jigsaWpuzzles,2016, In European Conference on Computer Vision
 Representation learning With contrastive predictivecoding,2018, arXiv preprint arXiv:1807
 Model compression via distillation and quantiza-tion,2018, arXiv preprint arXiv:1802
 Faster r-cnn: ToWards real-time objectdetection With region proposal netWorks,2015, In Advances in neural information processing systems
 Fitnets: Hints for thin deep nets,2014, 2014
 Mo-bilenetv2: Inverted residuals and linear bottlenecks,2018, In Proceedings of the IEEE conference oncomputer vision and pattern recognition
 Patient knowledge distillation for bert modelcompression,2019, arXiv preprint arXiv:1908
 Efficientnet: Rethinking model scaling for convolutional neuralnetworks,2019, arXiv preprint arXiv:1905
 Contrastive multiview coding,2019, arXiv preprintarXiv:1906
 Well-read students learn better:On the importance of pre-training compact models,2019, arXiv preprint arXiv:1908
 Understanding contrastive representation learning through align-ment and uniformity on the hypersphere,2020, arXiv preprint arXiv:2005
 Unsupervised feature learning via non-parametric instance discrimination,2018, In Proceedings of the IEEE Conference on Computer Visionand Pattern Recognition
 Sun database:Large-scale scene recognition from abbey to zoo,2010, In 2010 IEEE computer society conference oncomputer vision and pattern recognition
 Joint unsupervised learning of deep representationsand image clusters,2016, In Proceedings of the IEEE Conference on Computer Vision and PatternRecognition
 Paying more attention to attention: Improving the perfor-mance of convolutional neural networks via attention transfer,2016, arXiv preprint arXiv:1612
 Colorful image colorization,2016, In Europeanconference on computer vision
 Range loss for deep facerecognition with long-tailed training data,2017, In Proceedings of the IEEE International Conference onComputer Vision
