title,year,conference
 Obfuscated gradients give a false sense ofsecurity: Circumventing defenses to adversarial examples,2018, arXiv preprint arXiv:1802
 Certi-fying geometric robUstness of neUral networks,2019, In Advances in Neural Information ProcessingSystems
 Adaptive neural networksfor efficient inference,2017, arXiv preprint arXiv:1702
 Certified adversarial robustness via randomizedsmoothing,2019, In Proceedings of the 36th International Conference on Machine Learning
 Certification of semantic perturbations viarandomized smoothing,2020, arXiv preprint arXiv:2002
 Ai2: Safety and robustness certification of neural networks with abstract interpreta-tion,2018, In 2018 IEEE Symposium on Security and Privacy (SP)
 On the effectiveness of intervalbound propagation for training verifiably robust models,2018, arXiv preprint arXiv:1810
 Reluplex: Anefficient smt solver for verifying deep neural networks,2017, In International Conference on ComputerAided Verification
 Deciding how to decide: Dynamic routing in artificial neuralnetworks,2017, arXiv preprint arXiv:1703
 Differentiable abstract interpretation for prov-ably robust neural networks,2018, In International Conference on Machine Learning
 Practical black-box attacks against machine learning,2017, In Proceedings of the 2017 ACMon Asia conference on computer and communications security
 Certified defenses against adversarial exam-ples,2018, In International Conference on Learning Representations
 Provably robust deep learning via adversarially trained smoothed classifiers,2019, arXivpreprint arXiv:1906
 A convex relaxationbarrier to tight robustness verification of neural networks,2019, In Advances in Neural InformationProcessing Systems
 Learning formeta-recognition,2012, IEEE Transactions on Information Forensics and Security
 Beyond the single neuronconvex barrier for neural network certification,2019, In Advances in Neural Information ProcessingSystems
 Efficientnet: Rethinking model scaling for convolutional neuralnetworks,2019, arXiv preprint arXiv:1905
 Branchynet: Fast inferencevia early exiting from deeP neural networks,2016, In 2016 23rd International Conference on PatternRecognition (ICPR)
 Evaluating robustness of neural networks with mixedinteger Programming,2017, arXiv preprint arXiv:1711
 On adaPtive attacks toadversarial examPle defenses,2020, arXiv preprint arXiv:2002
 Efficient formal safetyanalysis of neural networks,2018, In Advances in Neural Information Processing Systems
 Scaling Provable adversarialdefenses,2018, In Advances in Neural Information Processing Systems 31
 Automatic Perturbation analysis on general comPutational graPhs,2020, arXivpreprint arXiv:2002
 Efficient neural net-work robustness certification with general activation functions,2018, In Advances in neural informationprocessing systems
 Towards stable and efficient training of verifiably robust neural networks,2020, InInternational Conference on Learning Representations
