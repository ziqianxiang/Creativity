title,year,conference
 Variational option discoveryalgorithms,2018, arXiv preprint arXiv:1807
 An optimistic perspective on offlinereinforcement learning,2020, In International Conference on Machine Learning
 Model-based offline planning,2020, arXiv preprintarXiv:2008
 The option-critic architecture,2017, In Proceedings ofthe AAAI Conference on Artificial Intelligence
 Openai gym,2016, arXiv preprint arXiv:1606
 Deep reinforcement learn-ing in a handful of trials using probabilistic dynamics models,2018, arXiv preprint arXiv:1805
 Ecologicalreinforcement learning,2020, arXiv preprint arXiv:2006
 Reinforcement learning in pomdps withoutresets,2005, 2005
 Leave no trace: Learning toreset for safe and autonomous reinforcement learning,2017, arXiv preprint arXiv:1711
 Diversity is all you need:Learning skills without a reward function,2018, arXiv preprint arXiv:1802
 Online meta-learning,2019, InInternational Conference on Machine Learning
 D4rl: Datasets for deepdata-driven reinforcement learning,2020, arXiv preprint arXiv:2004
 Variational intrinsic control,2016, arXivpreprint arXiv:1611
 Learning latent dynamics for planning from pixels,2019, In International Conference onMachine Learning
 Fast task inference with variational intrinsic successor features,2019, arXiv preprintarXiv:1906
 Model-predictive policy learning with uncer-tainty regularization for driving in dense traffic,2019, arXiv preprint arXiv:1901
 Uncertainty-awarereinforcement learning for collision avoidance,2017, arXiv preprint arXiv:1702
 Options of interest: Temporal abstraction with interest functions,2020, In Proceedings of theAAAI Conference on Artificial Intelligence
 Morel: Model-based offline reinforcement learning,2020, arXiv preprint arXiv:2005
 Overcom-ing catastrophic forgetting in neural networks,2017, Proceedings of the national academy of sciences
 Conservative q-learning for offlinereinforcement learning,2020, arXiv preprint arXiv:2006
 Model-ensembletrust-region policy optimization,2018, arXiv preprint arXiv:1802
 Adaptive online planning for continual lifelong learn-ing,2019, arXiv preprint arXiv:1912
 The general problem of the stability of motion,1992, 1992
 Prediction and control with temporal segmentmodels,2017, In International Conference on Machine Learning
 Data-efficient hierarchical reinforce-ment learning,2018, arXiv preprint arXiv:1805
 Deep online learning via meta-learning:Continual adaptation for model-based rl,2018, arXiv preprint arXiv:1812
 Deep dynamics modelsfor learning dexterous manipulation,2020, In Conference on Robot Learning
 Benchmarking safe exploration in deep reinforcementlearning,2019, arXiv preprint arXiv:1910
 Experiencereplay for continual learning,2018, arXiv preprint arXiv:1811
 Progressive neural networks,2016, arXiv preprintarXiv:1606
 Dynamics-aWareunsupervised discovery of skills,2019, arXiv preprint arXiv:1907
 Learning off-policy With online planning,2020, arXivpreprint arXiv:2008
 Reinforcement Learning: An Introduction,2018, 2018
 Improving multi-step prediction of learned timeseries models,2015, In Proceedings of the AAAI Conference on Artificial Intelligence
 Exploring model-based planning With policy netWorks,2019, arXiv preprintarXiv:1906
 Unsupervised control through non-parametric discriminative reWards,2018, arXivpreprint arXiv:1811
 Model predictive path integral controlusing covariance variable importance sampling,2015, arXiv preprint arXiv:1509
 Deep reinforcement learning amidst lifelong non-stationarity,2020, arXiv preprint arXiv:2006
 Mopo: Model-based offline policy optimization,2020, arXiv preprintarXiv:2005
 Cautious adapta-tion for reinforcement learning in safety-critical settings,2020, In International Conference on MachineLearning 
 The ingredients of real-world robotic reinforcement learning,2020, arXivpreprint arXiv:2004
