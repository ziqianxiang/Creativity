title,year,conference
 Unsupervisedlabel noise modeling and loss correction,2019, arXiv preprint arXiv:1904
 Confidence scoresmake instance-dependent label-noise learning possible,2020, arXiv preprint arXiv:2001
 Coherent gradients: An approach to understanding generalization in gradientdescent-based optimization,2020, In International Conference on Learning Representations
 Co-teaching: Robust training of deep neural networks with extremely noisy labels,2018, InAdvances in neural information processing systems
 Deep self-learning from noisy labels,2019, In Proceedingsof the IEEE International Conference on Computer Vision
 Cor-recting sample selection bias by unlabeled data,2007, In Advances in neural information processingsystems
 Mentornet: Learningdata-driven curriculum for very deep neural networks on corrupted labels,2017, arXiv preprintarXiv:1712
 Nlnl: Negative learning for noisylabels,2019, In Proceedings of the IEEE International Conference on Computer Vision
 Imagenet classification with deep convo-Iutional neural networks,2012, In Advances in neural information processing Systems
 Learning to learn from noisy la-beled data,2019, In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition
 Dividemix: Learning with noisy labels as semi-supervised learning,2020, In International Conference on Learning Representations
 Learning fromnoisy labels with distillation,2017, In Proceedings of the IEEE International Conference on ComputerVision
 Machine-learning aided peer prediction,2017, In Proceedings of the 2017ACM Conference on Economics and Computation
 Peer loss functions: Learning from noisy labels without knowing noiserates,2020, In Proceedings of the 37th International Conference on Machine Learning
 A bi-level formulation for label noise learning with spectralcluster discovery,2020, In International Joint Conference on Artificial Intelligence
 Noise tolerance under risk minimization,2013, IEEE transactions oncybernetics
 Learning withnoisy labels,2013, In Advances in neural information processing systems
 Self: Learning to filter noisy labels with self-ensembling,2019, arXiv preprint arXiv:1910
 Confident learning: Estimating uncertainty indataset labels,2019, arXiv preprint arXiv:1911
 Makingdeep neural networks robust to label noise: A loss correction approach,2017, In Proceedings of theIEEE Conference on Computer Vision and Pattern Recognition
 Training deep neural networks on noisy labels with bootstrapping,2014, arXiv preprintarXiv:1412
 Learning adaptive loss for robustlearning with noisy labels,2020, arXiv preprint arXiv:2002
 When training and test sets are different: characterizing learning transfer,2009, Datasetshift in machine learning
 Joint optimization frame-work for learning with noisy labels,2018, In Proceedings of the IEEE Conference on Computer Visionand Pattern Recognition
 Learningfrom noisy large-scale datasets with minimal supervision,2017, In Proceedings of the IEEE Conferenceon Computer Vision and Pattern Recognition
 Symmetric cross en-tropy for robust learning with noisy labels,2019, In Proceedings of the IEEE International Conferenceon Computer Vision
 Parts-dependent label noise: Towards instance-dependentlabel noise,2020, arXiv preprint arXiv:2006
 Learning from massive noisylabeled data for image classification,2015, In Proceedings of the IEEE Conference on Computer Visionand Pattern Recognition
 Unsupervised dataaugmentation,2019, arXiv preprint arXiv:1904
 L_dmi: An information-theoretic noise-robust loss function,2019, NeurIPS
 Searching to exploit memo-rization effect in learning with noisy labels,2020, In Proceedings of the 37th International Conferenceon Machine Learning
 Dual T: Reducing estimation error for transition matrix in label-noise learning,2020, InAdvances in Neural Information Processing Systems
 Understandingdeep learning requires rethinking generalization,2016, arXiv preprint arXiv:1611
 mixup: Beyond em-pirical risk minimization,2018, In International Conference on Learning Representations
 Self-paced robust learn-ing for leveraging clean labels in noisy data,2020, In AAAI
 Generalized cross entropy loss for training deep neural networkswith noisy labels,2018, In Advances in neural information processing Systems
 A second-order approach to learning with instance-dependent label noise,2021, In The IEEE Conference on Computer Vision and Pattern Recognition(CVPR)
 Clusterability as an alternative to anchor points whenlearning with noisy labels,2021, arXiv preprint arXiv:2102
 Explaining memorization and general-ization: A large-scale study with coherent gradients,2020, arXiv preprint arXiv:2003
 Batch-size is set to 32,2020, The initial learning rate is set as 0
