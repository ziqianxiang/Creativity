title,year,conference
 Residual algorithms: Reinforcement learning with function approximation,1995, InMachine Learning Proceedings 1995
 Perfor-mance of Q-learning with linear function approximation: Stability and finite-time analysis,2019, arXivpreprint arXiv:1905
 Finite sample analysis of two-timescale stochastic approximation with applications to reinforcement learning,2018, Proceedings ofMachine Learning Research
 SAGA: A fast incremental gradientmethod with support for non-strongly convex composite objectives,2014, In Proc
 Stochastic variance reductionmethods for policy evaluation,2017, In Proc
 Spider: Near-optimal non-convexoptimization via stochastic path-integrated differential estimator,2018, In Proc
 Finite-time performance bounds and adaptive learning rateselection for two time-scale reinforcement learning,2019, In Proc
 Variancereduction for deep q-learning using stochastic recursive gradient,2020, arXiv:2007
 Accelerating stochastic gradient descent using predictive variancereduction,2013, In Advances in neural information processing systems
 A simple proximal stochastic gradient method for nonsmooth nonconvexoptimization,2018, In Advances in neural information processing systems
 Finite-sampleanalysis of proximal gradient td algorithms,2015, In Proc
 Toward off-policylearning control with function approximation,2010, In Proc
 Human-level control through deep reinforcement learn-ing,2015, Nature
 In Proc,2016, International Conference onMachine Learning (ICML)
 Online Q-learning using connectionist systems,1994, Technical Report
 Masteringthe game of Go with deep neural networks and tree search,2016, nature
 Finite-time error bounds for linear stochastic approximationandtd learning,2019, In Conference on Learning Theory
 Fast gradient-descent methods for temporal-difference learn-ing with linear function approximation,2009, In Proc
 Variance-reduced q-learning is minimax optimal,2019, arXiv:1906
 A multistep lyapunov approach for finite-time analysis of biased stochastic approximation,2020, arXiv:1909
 Finite sample analysis of thegtd policy evaluation algorithms in markov setting,2017, In Proc
 A finite time analysis of two time-scale actorcritic methods,2020, arXiv preprint arXiv:2005
 A finite-time analysis of q-learning with neural network function ap-proximation,2019, arXiv preprint arXiv:1912
 Two time-scale off-policy TD learning: Non-asymptotic analysis over Markovian samples,2019, In Proc
 Reanalysis of variance reduced temporaldifference learning,2020, In Proc
 On convergence of some gradient-based temporal-differences algorithms for off-policylearning,2017, arXiv preprint arXiv:1712
 Finite-sample analysis for SARSA with linearfunction approximation,2019, In Advances in Neural Information Processing Systems
