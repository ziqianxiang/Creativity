title,year,conference
 Neural network learning: Theoretical foundations,2009, cambridgeuniversity press
 A theoretical analysis of contrastive unsupervised representation learning,2019, arXiv preprintarXiv:1902
 Mine: mutual information neural estimation,2018, arXiv preprintarXiv:1801
 Generative pretraining from pixels,2020, In Proceedings of the 37th InternationalConference on Machine Learning
 A simple framework forcontrastive learning of visual representations,2020, arXiv preprint arXiv:2002
 Big self-supervised models are strong semi-supervised learners,2020, arXiv preprint arXiv:2006
 De-biased contrastive learning,2020, arXiv preprint arXiv:2007
 Bert: Pre-training of deepbidirectional transformers for language understanding,2018, arXiv preprint arXiv:1810
 Unsupervised representation learning bypredicting image rotations,2018, arXiv preprint arXiv:1803
 Learning deep representations by mutual information estimationand maximization,2018, arXiv preprint arXiv:1808
 Long short-term memory,1997, Neural computation
 Multilayer feedforward networks are universal aPProxi-mators,1989, Neural Networks
 Batch normalization: Accelerating deeP network training byreducing internal covariate shift,2015, arXiv preprint arXiv:1502
 Supervised contrastive learning,2020, arXiv preprintarXiv:2004
 Human-level concept learningthrough probabilistic program induction,2015, Science
 Selective kernel networks,2019, In Proceedings ofthe IEEE conference on computer vision and pattern recognition
 Putting an end to end-to-end: Gradient-isolatedlearning of representations,2019, In Advances in Neural Information Processing Systems
 Estimating divergence functionalsand the likelihood ratio by convex risk minimization,2010, IEEE Transactions on Information Theory
 A family of statistical symmetric divergences based on jensenâ€™s inequality,2010, arXivpreprint arXiv:1009
 On the chi square and higher-order chi distances for approximatingf-divergences,2013, IEEE Signal Processing Letters
 Unsupervised learning of visual representations by solving jigsawpuzzles,2016, In European Conference on Computer Vision
 f-gan: Training generative neural samplersusing variational divergence minimization,2016, In Advances in neural information processing systems
 Representation learning with contrastive predic-tive coding,2018, arXiv preprint arXiv:1807
 Wasserstein dependency measure for representation learning,2019, In Advances in NeuralInformation Processing Systems
 Librispeech: an asr corpusbased on public domain audio books,2015, In 2015 IEEE International Conference on Acoustics
 On varia-tional bounds of mutual information,2019, arXiv preprint arXiv:1905
 Understanding the limitations of variational mutual informationestimators,2019, arXiv preprint arXiv:1910
 Contrastive multiview coding,2019, arXiv preprintarXiv:1906
 Whatmakes for good views for contrastive learning,2020, arXiv preprint arXiv:2005
 De-mystifying self-supervised learning: An information-theoretical framework,2020, arXiv preprintarXiv:2006
 Neural methods for point-wise dependency estimation,2020, arXiv preprint arXiv:2006
 On mutualinformation maximization for representation learning,2019, arXiv preprint arXiv:1907
 Attention is all you need,2017, In Advances in neural informationprocessing systems
 Deep graph infomax,2019, In ICLR (Poster)
 Rel-ative density-ratio estimation for robust distribution comparison,2013, Neural computation
 Large batch training of convolutional networks,2017, arXivpreprint arXiv:1708
