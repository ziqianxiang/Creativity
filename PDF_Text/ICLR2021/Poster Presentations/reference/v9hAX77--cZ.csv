title,year,conference
 Learning to represent programswith graphs,2018, In International Conference on Learning Representations
 Generativecode modeling with graphs,2018, In International Conference on Learning Representations
 CODIT: Code editingwith tree-based neural models,2020, IEEE Transactions on Software Engineering
 Three models for the description of language,1956, IRE Transactions on informationtheory
 EditNTS: An neuralprogrammer-interpreter model for sentence simplification through explicit editing,2019, In Proceedingsof the 57th Annual Meeting of the Association for Computational Linguistics
 Sentence simplification as tree transduction,2013, In Proceedings ofthe second workshop on predicting and improving text readability for target reader populations
 Learning non-monotonic automatic post-editingof translations from human orderings,2020, In Proceedings of the 22nd Annual Conference of theEuropean Association for Machine Translation
 Search engine guided neural machinetranslation,2018, In Proceedings of the AAAI Conference on Artificial Intelligence
 Insertion-based decoding with automatically inferred gen-eration order,2019, Transactions of the Association for Computational Linguistics
 Levenshtein transformer,2019, In Advances in NeuralInformation Processing Systems
 Generating sentences byediting prototypes,2018, Transactions of the Association for Computational Linguistics
 Fact-based text editing,2020, In Proceedings of the 58th AnnualMeeting of the Association for Computational Linguistics
 Deterministic non-autoregressive neural se-quence modeling by iterative refinement,2018, In Proceedings of the 2018 Conference on EmpiricalMethods in Natural Language Processing
 Gated graph sequence neuralnetworks,2015, arXiv preprint arXiv:1511
 Learningto update natural language comments based on code changes,2020, In Proceedings of the 58th AnnualMeeting of the Association for Computational Linguistics
 Seq2Edits: Sequence transduction using span-level edit op-erations,2020, In Proceedings of the 2020 Conference on Empirical Methods in Natural LanguageProcessing (EMNLP)
 Insertion transformer: Flexiblesequence generation via insertion operations,2019, In International Conference on Machine Learning
 Learning to map context-dependent sentences to exe-cutable formal queries,2018, In Proceedings of the 2018 Conference of the North American Chapter ofthe Association for Computational Linguistics: Human Language Technologies
 Pointer networks,2015, In Advances in neuralinformation processing systems
 The zephyr abstractsyntax description language,1997, In DSL
 Non-monotonic sequentialtext generation,2019, In International Conference on Machine Learning
 TRANX: A transition-based neUral abstract syntax parserfor semantic parsing and code generation,2018, In Proceedings of the 2018 Conference on EmpiricalMethods in Natural Language Processing: System Demonstrations
 NeUral networks for modeling soUrcecode edits,2019, arXiv preprint arXiv:1904
