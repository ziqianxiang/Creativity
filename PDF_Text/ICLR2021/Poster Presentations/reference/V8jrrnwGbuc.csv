title,year,conference
 Sgd learns over-parameterizednetWorks that provably generalize on linearly separable data,2017, arXiv preprint arXiv:1710
 Coherent gradients: An approaCh to understanding generalization in gradient desCent-basedoptimization,2020, ICLR
 Linear readout of objeCt manifolds,2016, Physical Review E
 ClassifiCation and geometry of general perCeptualmanifolds,2018, Physical Review X
 Separability and geometry of objeCtmanifolds in deep neural netWorks,2019, bioRxiv
 GeometriCal and statistiCal properties of systems of linear inequalities With appliCations inpattern reCognition,1965, IEEE transactions on electronic computers
 Imagenet: A large-sCale hierarChiCalimage database,2009, In 2009 IEEE conference on computer vision and pattern recognition
 Understanding the diffiCulty of training deep feedforWard neural netWorks,2010, InProceedings of the thirteenth international conference on artificial intelligence and statistics
 Deep residual learning for image reCognition,2016, InProceedings of the IEEE conference on computer vision and pattern recognition
 Neural tangent kernel: Convergence and generalization inneural netWorks,2018, In Advances in neural information processing systems
 Similarity of neural netWorkrepresentations revisited,2019, arXiv preprint arXiv:1905
 Learning multiple layers of features from tiny images,2009, Technical report
 Imagenet classification With deep convolutional neural,2014, In NeuralInformation Processing Systems
 An analytic theory of generalization dynamics and transfer learning indeep linear netWorks,2018, arXiv preprint arXiv:1809
 Wide neural netWorks of any depth evolve as linear models under gradient descent,2019, InAdvances in neural information processing systems
 Learning overparameterized neural netWorks via stochastic gradient descent onstructured data,2018, In Advances in Neural Information Processing Systems
 Insights on representational similarity in neural networks withcanonical correlation,2018, In Advances in Neural Information Processing Systems
 Deep doubledescent: Where bigger models and more data hurt,2019, arXiv preprint arXiv:1912
 In search of the real inductive bias: On the role ofimplicit regularization in deep learning,2014, arXiv preprint arXiv:1412
 Sensi-tivity and generalization in neural networks: an empirical study,2018, In International Conference on LearningRepresentations
 Svcca: Singular vector canonicalcorrelation analysis for deep learning dynamics and interpretability,2017, In Advances in Neural InformationProcessing Systems
 Exact solutions to the nonlinear dynamics of learningin deep linear neural networks,2013, arXiv preprint arXiv:1312
 Untangling in invariant speech recognition,2019, In Advances in Neural Information Processing Systems
 Robustnessmay be at odds with accuracy,2019, In International Conference on Learning Representations
 Towards understandinglearning representations: To what extent do different neural networks learn the same representation,2018, InAdvances in Neural Information Processing Systems
 Understanding deep learningrequires rethinking generalization,2016, arXiv preprint arXiv:1611
