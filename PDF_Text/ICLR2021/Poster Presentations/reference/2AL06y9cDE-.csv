title,year,conference
 On the theory of dynamic programming,1952, Proceedings of the National Academyof Sciences of the United States of America
 Towards evaluating the robustness of neural networks,2017, In 2017ieee symposium on security and privacy (sp)
 A rotation and atranslation suffice: Fooling cnns with simple transformations,2017, arXiv preprint arXiv:1712
 Explaining and harnessing adversarialexamples,2014, arXiv preprint arXiv:1412
 Stable architectures for deep neural networks,2017, Inverse Problems
 A mean-field optimal control formulation of deep learning,2018, arXivpreprint arXiv:1807
 Adversarial perturbations of deep neuralnetworks,2017, 2017
 The robust manifolddefense: Adversarial training using generative models,2017, arXiv preprint arXiv:1712
 On the geometry of adversarial examples,2018, arXiv preprintarXiv:1811
 Adam: A method for stochastic optimization,2014, arXiv preprintarXiv:1412
 Optimal control theory: an introduction,1970, Springer
 Differential dynamic programmingneural optimizer,2020, arXiv preprint arXiv:2002
 A differential game theoretic neuraloptimizer for training residual networks,2020, arXiv preprint arXiv:2007
 Towards robust neural networks viarandom self-ensemble,2018, In Proceedings of the European Conference on Computer Vision (ECCV)
 An overview of deep learning in medicalimaging focusing on mri,2019, ZeitschriftfurMedizinische Physik
 On detecting adversarialperturbations,2017, arXiv preprint arXiv:1702
 Deep neural networks are easily fooled: High confi-dence predictions for unrecognizable images,2015, In Proceedings of the IEEE conference on computervision and pattern recognition
 Defense-gan: Protecting classifiers againstadversarial attacks using generative models,2018, arXiv preprint arXiv:1805
 Pixeldefend:Leveraging generative models to understand and defend against adversarial examples,2017, arXivpreprint arXiv:1710
 Intriguing properties of neural networks,2013, arXiv preprint arXiv:1312
 Amata: An annealing mechanism for adversarialtraining acceleration,2019, 2019
 You only propagateonce: Accelerating adversarial training via maximal principle,2019, In Advances in Neural InformationProcessing Systems
