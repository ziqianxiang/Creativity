title,year,conference
 Copycat cnn: Stealing knowledge by persuading confession with random non-labeled data,2018, In 2018 International Joint Conference on Neural Networks (IJCNN)
 Explaining and harnessing adversarialexamples,2014, arXiv preprint arXiv:1412
 Deep anomaly detection with outlierexposure,2018, arXiv preprint arXiv:1812
 Maze: Data-free model stealing attackusing zeroth-order gradient estimation,2020, arXiv preprint arXiv:2005
 Defending against machine learningmodel stealing attacks using deceptive perturbations,2018, arXiv preprint arXiv:1806
 Adversarial learning,2005, In Proceedings of the eleventh ACMSIGKDD international conference on Knowledge discovery in data mining
 Towards reverse-engineering black-box neuralnetworks,2019, In Explainable AI: Interpreting
 Knockoff nets: Stealing functionalityof black-box models,2019, In Proceedings of the IEEE Conference on Computer Vision and PatternRecognition
 Prediction poisoning: Towards defensesagainst dnn model stealing attacks,2019, In International Conference on Learning Representations
 Practical black-box attacks against machine learning,2017, In Proceedings of the 2017 ACMon Asia conference on computer and communications security
 Recognizing indoor scenes,2009, In 2009 IEEE Conference on ComputerVision and Pattern Recognition
 Membership inference at-tacks against machine learning models,2017, In 2017 IEEE Symposium on Security and Privacy (SP)
 80 million tiny images: A large data set fornonparametric object and scene recognition,2008, IEEE transactions on pattern analysis and machineintelligence
 Stealing hyperparameters in machine learning,2018, In 2018IEEE Symposium on Security and Privacy (SP)
 Implementation and benchmarking of perceptual image hash functions,2010, 2010
