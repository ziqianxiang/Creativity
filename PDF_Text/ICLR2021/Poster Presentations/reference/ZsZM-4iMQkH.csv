title,year,conference
 A convergence theory for deep learning via over-parameterization,2018, arXiv preprint arXiv:1811
 A convergence analysis of gradient de-scent for deep linear neural networks,2019, In International Conference on Learning Representations
 Implicit regularization in deep matrixfactorization,2019, In Advances in Neural Information Processing Systems
 Gradient descent with identity initialization effi-ciently learns positive definite linear transformations by deep residual networks,2018, In InternationalConference on Machine Learning
 Implicit bias of gradient descent for wide two-layer neural networkstrained with the logistic loss,2020, arXiv preprint arXiv:2002
 Gradient descent finds globalminima of deep neural networks,2018, arXiv preprint arXiv:1811
 Gradient descent provably optimizesover-parameterized neural networks,2018, arXiv preprint arXiv:1810
 The implicit bias of depth: How incrementallearning drives generalization,2020, In International Conference on Learning Representations
 Characterizing implicit bias interms of optimization geometry,2018, In International Conference on Machine Learning
 Provable benefit of orthogonal initialization in opti-mizing deep linear networks,2020, In International Conference on Learning Representations
 Neural tangent kernel: Convergence and gen-eralization in neural networks,2018, In Advances in neural information processing systems
 Gradient descent aligns the layers of deep linear networks,2019, InInternational Conference on Learning Representations
 The implicit bias of gradient descent on nonseparable data,2019, InConference on Learning Theory
 A refined primal-dual analysis of the implicit bias,2019, arXiv preprintarXiv:1906
 Directional convergence and alignment in deep learning,2020, arXivpreprint arXiv:2006
 Implicit bias in deep linear classification: Initialization scale vs training accuracy,2020, arXivpreprint arXiv:2007
 Lexico-graphic and depth-sensitive margins in homogeneous and non-homogeneous deep models,2019, InInternational Conference on Machine Learning
 Convergence of gradient descent on separable data,2019, In The 22ndInternational Conference on Artificial Intelligence and Statistics
 Stochastic gradient descent on separabledata: Exact convergence with a fixed learning rate,2019, In The 22nd International Conference onArtificial Intelligence and Statistics
 Kernel and rich regimes in overparametrized models,2020, InConference On Learning Theory
 Global convergence of gradient descent for deep linearresidual networks,2019, In Advances in Neural Information Processing Systems
 Identitycrisis: Memorization and generalization under extreme overparameterization,2019, arXiv preprintarXiv:1902
 Stochastic gradient descent optimizesover-parameterized deep ReLU networks,2018, arXiv preprint arXiv:1811
