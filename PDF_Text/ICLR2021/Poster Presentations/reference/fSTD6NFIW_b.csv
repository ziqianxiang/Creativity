title,year,conference
 A closer look at memorization in deep networks,2017, In Proceedings of the 34thInternational Conference on Machine Learning
 Recognition in terra incognita,2018, In Vittorio Ferrari
 Generalizing from several related classificationtasks to a new unlabeled sample,2011, In Advances in Neural Information Processing Systems 24
 On the learning dynamics of deep neural networks,2018, 2018
 Domain-adversarial training of neuralnetworks,2016, J
 In search of lost domain generalization,2020, 2020
 Deep residual learning for image recog-nition,2016, In 2016 IEEE Conference on Computer Vision and Pattern Recognition
 Benchmarking neural network robustness to commoncorruptions and perturbations,2019, In 7th International Conference on Learning Representations
 SGD on neural networks learns functions of increasing complex-ity,2019, In Advances in Neural Information Processing Systems 32: Annual Conference on NeuralInformation Processing Systems 2019
 Removing spurious features can hurt accuracy and affect groupsdisproportionately,2021, In FAccT ’21: 2021 ACM Conference on Fairness
 Learning to generalize: Meta-learning for domain generalization,2018, In Sheila A
 Right for the wrong reasons: Diagnosing syntacticheuristics in natural language inference,2019, In Anna Korhonen
 Domain generalization via invariantfeature representation,2013, In Proceedings of the 30th International Conference on Machine Learning
 Generalization in deep networks: The role of distance frominitialization,2017, 2017
 Uniform convergence may be unable to explain general-ization in deep learning,2019, In Advances in Neural Information Processing Systems 32
 In search of the real inductive bias: Onthe role of implicit regularization in deep learning,2015, In 3rd International Conference on LearningRepresentations
 Exploring gener-alization in deep learning,2017, 2017
 On the sPectral bias of deeP neural networks,2018, 2018
 ”why should I trust you?”： Explaining thePredictions of any classifier,2016, In Proceedings of the 22nd ACM SIGKDD International Conferenceon Knowledge Discovery and Data Mining
 Distributionally robustneural networks for group shifts： On the importance of regularization for worst-case generaliza-tion,2020, 2020a
 An investigation of whyoverparameterization exacerbates spurious correlations,2020, 2020b
 Thepitfalls of simplicity bias in neural networks,2020, In Advances in Neural Information ProcessingSystems
 The im-plicit bias of gradient descent on separable data,2018, J
 Statistical learning theory,1998, Wiley
 Training behavior of deep neural network infrequency domain,2019, In Tom Gedeon
 mixup: Beyond empiri-cal risk minimization,2018, In 6th International Conference on Learning Representations
 Men also likeshopping: Reducing gender bias amplification using corpus-level constraints,2017, In Proceedingsof the 2017 Conference on Empirical Methods in Natural Language Processing
3 Cats vs,2007, Dogs example with colors independent of labelRecall that the dataset from Fig 1d consists of a scenario where the images of cats vs
