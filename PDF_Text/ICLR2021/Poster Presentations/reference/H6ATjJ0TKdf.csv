title,year,conference
 Net-trim: Convex pruning of deep neural networkswith performance guarantee,2017, In Advances in Neural Information Processing Systems
 Data-dependent coresetsfor compressing neural networks with applications to generalization bounds,2019, In InternationalConference on Learning Representations
 Compressing neural networks using the variational informationbottleneck,2018, In Proceedings of International Conference on Machine Learning
 Learning to prune deep neural networks via layer-wise optimalbrain surgeon,2017, In Advances in Neural Information Processing Systems
 Fast sparse ConvNets,2020, In IEEE Conference onComputer Vision and Pattern Recognition
 Rigging the lottery: Making all ticketswinners,2020, In Proceedings of International Conference on Machine Learning
 Linear mode connectivity and the lotteryticket hypothesis,2020, In Proceedings of International Conference on Machine Learning
 Sparse GPU kernels for deep learning,2020, In Proceedingsof the International Conference for High Performance Computing
 Comparing biases for minimal network construction with back-propagation,1988, In Advances in Neural Information Processing Systems
 Second order derivatives for network pruning: Optimal brain surgeon,1993, InAdvances in Neural Information Processing Systems
 Deep residual learning for image recognition,2016, In IEEEConference on Computer Vision and Pattern Recognition
 AMC: AutoML for model compression and accelerationon mobile devices,2018, In European Conference on Computer Vision
 Densely connectedconvolutional networks,2017, In IEEE Conference on Computer Vision and Pattern Recognition
 Pruning versus clipping in neural networks,1989, Physical Review A
 Learning multiple layers of features from tiny images,2009, Technicalreport
 Optimal brain damage,1989, In Advances in Neural InformationProcessing Systems
 Snip: Single-shot network pruning based on connectionsensitivity,2019, In International Conference on Learning Representations
 A signal propagation perspective for pruning neuralnetworks at initialization,2020, In International Conference on Learning Representations
 Runtime neural pruning,2017, In Advances in Neural InformationProcessing Systems
 Dynamic model pruning with feedback,2020, InInternational Conference on Learning Representations
 Rethinking the value of network pruning,2019, InInternational Conference on Learning Representations
 Bayesian compression for deep learning,2017, In Advances inNeural Information Processing Systems
 Building a larger annotated corpus of English: ThePenn treebank,1993, Computational Linguistics
 Pointer sentinel mixture models,2016, In InternationalConference on Learning Representations
 Scalable training ofartificial neural networks with adaptive sparse connec- tivity inspired by network science,2018, NatureCommunications
 Variational dropout sparsifies deep neural networks,2017, InProceedings of International Conference on Machine Learning
 One ticket to win them all: Generalizing lotteryticket initializations across datasets and optimizers,2019, In Advances in Neural Information ProcessingSystems
 Skeletonization: A technique for trimming the fat from a networkvia relevance assessment,1988, In Advances in Neural Information Processing Systems
 Data-indenpendent neural pruningvia coresets,2020, In International Conference on Learning Representations
 Reading digits in natural imageswith unsupervised feature learning,2011, In NeurIPS Deep Learning and Unsupervised Feature LearningWorkshop
 Norm-based capacity control in neural networks,2015, InConference on Learning Theory
 Movement pruning: Adaptive sparsity by fine-tuning,2020, arXivpreprint 2005
 The singular values of convolutional layers,2019, In InternationalConference on Learning Representations
 Efficientnet: Rethinking model scaling for convolutional neural networks,2019, InProceedings of International Conference on Machine Learning
 Robustness may be at odds withaccuracy,2019, In International Conference on Learning Representations
 AutoPrune: Automatic network pruning by regularizingauxiliary parameters,2019, In Advances in Neural Information Processing Systems
