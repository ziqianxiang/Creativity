title,year,conference
 Learning to represent programswith graphs,2018, In International Conference on Learning Representations
 code2seq: Generating sequences from struc-tured representations of code,2019, In International Conference on Learning Representations
 code2vec: Learning distributed repre-sentations of code,2019, Proceedings of the ACM on Programming Languages
 Learning python codesuggestion with a sparse pointer network,2016, arXiv preprint arXiv:1611
 Cross-lingual language model pretrain-ing,2019, In H
 Discriminative embeddings of latent variable models for struc-tured data,2016, In International conference on machine learning
 Transformer-xl: Attentive language models beyond a fixed-length context,2019, arXiv preprintarXiv:1901
 Convolutional neural networks ongraphs with fast localized spectral filtering,2016, In Advances in neural information processing systems
 Convolutional networks on graphs for learning molecularfingerprints,2015, In Advances in neural information processing systems
 Structured neural summa-rization,2019, In International Conference on Learning Representations
 Inductive representation learning on largegraphs,2017, In NIPS
 Long short-term memory,1997, Neural computation
 Open graph benchmark: Datasets for machine learning ongraphs,2020, In H
 Semi-supervised classification with graph convolutional net-works,2017, In International Conference on Learning Representations (ICLR)
 Predict then propagate:Graph neural networks meet personalized pagerank,2019, In International Conference on LearningRepresentations (ICLR)
 Diffusion improves graph learn-ing,2019, In Conference on Neural Information Processing Systems (NeurIPS)
 Directional message passing for molec-ular graphs,2020, In International Conference on Learning Representations (ICLR)
 Code completion with neural attention andpointer networks,2017, arXiv preprint arXiv:1711
 Gated graph sequence neuralnetworks,2015, arXiv preprint arXiv:1511
 Convolutional neural networks over tree struc-tures for programming language processing,2016, In Proceedings of the Thirtieth AAAI Conference onArtificial Intelligence
 Languagemodels are unsupervised multitask learners,2019, OpenAI Blog
 Modeling relational data with graph convolutional networks,2018, In Aldo Gangemi
 Self-attention with relative position representa-tions,2018, In Proceedings of the 2018 Conference of the North American Chapter of the Associationfor Computational Linguistics: Human Language Technologies
 Improved semantic representationsfrom tree-structured long short-term memory networks,2015, arXiv preprint arXiv:1503
 Attention is all you need,2017, In Advances in neural informationprocessing systems
 Graph Attention Networks,2018, International Conference on Learning Representations
 Pointer networks,2015, In Advances in neuralinformation processing systems
 Position-aware graph neural networks,2019, In KamalikaChaudhuri and Ruslan Salakhutdinov (eds
 Link prediction based on graph neural networks,2018, In Advances inNeural Information Processing Systems
