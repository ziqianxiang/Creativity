title,year,conference
 Variationalinformation distillation for knowledge transfer,2019, In CVPR
 How tobackdoor federated learning,2020, In AISTATS
 Label refinery:Improving imagenet classification through label progression,2018, In ICCV
 A new backdoor attack in cnns by training setcorruption without label poisoning,2019, In ICIP
 Model compression,2006, In SIGKDD
 Towards evaluating the robustness of neural networks,2017, In SP
 Detecting backdoor attacks on deep neural networks byactivation clustering,2019, In AAAI Workshop
 Deepinspect: A black-box trojandetection and mitigation framework for deep neural networks,2019, In IJCAI
 Invisiblepoisoning: Highly stealthy targeted poisoning attack,2019, In ICISC
 Targeted backdoor attacks on deeplearning systems using data poisoning,2017, arXiv preprint arXiv:1712
 Improved regularization of convolutional neural networkswith cutout,2017, arXiv preprint arXiv:1708
 Adversarialcamouflage: Hiding physical-world attacks with natural styles,2020, In CVPR
 Explaining and harnessing adversarialexamples,2014, In ICLR
 Badnets: Identifying vulnerabilities in themachine learning model supply chain,2019, IEEE Access
 Deep residual learning for image recog-nition,2016, In CVPR
 Knowledge transfer via distillationof activation boundaries formed by hidden neurons,2019, In AAAI
 Distilling the knowledge in a neural network,2014, InNeurIPS
 Like what you like: Knowledge distill via neuron selectivitytransfer,2017, arXiv preprint arXiv:1707
 Black-box adversarialattacks on video recognition models,2019, In ACMMM
 Imbalanced gradients: Anew cause of overestimated adversarial robustness,2020, arXiv preprint arXiv:2006
 Overcom-ing catastrophic forgetting in neural networks,2017, PNAS
 Universal litmus patterns:Revealing backdoor attacks in cnns,2020, In CVPR
 Invisiblebackdoor attacks on deep neural networks via steganography and regularization,2019, arXiv preprintarXiv:1909
 Rethinking thetrigger of backdoor attack,2020, arXiv preprint arXiv:2004
 Backdoor attack withsample-specific triggers,2020, arXiv preprint arXiv:2012
 Backdoor embeddingin convolutional neural network models via invisible perturbation,2020, CODASPY
 Fine-pruning: Defending against backdoor-ing attacks on deep neural networks,2018, In RAID
 Removing backdoor-based watermarks in neuralnetworks with limited data,2020, arXiv preprint arXiv:2008
 Trojaning attack on neural networks,2018, In NDSS
 Reflection backdoor: A natural backdoorattack on deep neural networks,2020, In ECCV
 Pay attention to the activations: a modularattention mechanism for fine-grained image recognition,2019, IEEE Transactions on Multimedia
 Privacyand robustness in federated learning: Attacks and defenses,2020, arXiv preprint arXiv:2012
 Characterizing adversarial subspaces usinglocal intrinsic dimensionality,2018, In ICLR
 Under-standing adversarial attacks on deep learning based medical image analysis systems,2020, PatternRecognition
 Input-aware dynamic backdoor attack,2020, In NeurIPS
 Defending neural backdoors via generative distributionmodeling,2019, In NeurIPS
 Fitnets: Hints for thin deep nets,2015, In ICLR
 Neural compatibilitymodeling with attentive knowledge distillation,2018, In SIGIR
 Intriguing properties of neural networks,2013, In ICLR
 Spectral signatures in backdoor attacks,2018, In NeurIPS
 Systematic evaluation of backdoor data poisoning attacks onimage classifiers,2020, In CVPR
 On theconvergence and robustness of adversarial training,2019, In ICML
 Improvingadversarial robustness requires revisiting misclassified examples,2020, In ICLR
 Skip connections matter:On the transferability of adversarial examples generated with resnets,2020, In ICLR
 Dba: Distributed backdoor attacks against feder-ated learning,2019, In ICLR
 Latent backdoor attacks on deep neuralnetworks,2019, In CCS
 Paying more attention to attention: Improving the perfor-mance of convolutional neural networks via attention transfer,2017, In ICLR
 mixup: Beyond empiricalrisk minimization,2018, In ICLR
 Bridging modeconnectivity in loss landscapes and adversarial robustness,2020, In ICLR
 Hearing lips: Im-proving lip reading by distilling speech recognizers,2020, In AAAI
