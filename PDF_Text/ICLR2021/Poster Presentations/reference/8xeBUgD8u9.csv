title,year,conference
 Expert gate: Lifelong learning witha network of experts,2017, In Proceedings of the IEEE Conference on Computer Vision and PatternRecognition
 Self-refreshing memory inartificial neural networks: learning temporal sequences without catastrophic forgetting,2004, ConnectionScience
 Progres-sive memory banks for incremental domain adaPtation,2020, In International Conference on LearningRepresentations
 Learning stochastic recurrent networks,2014, arXiv preprintarXiv:1411
 Net2Net: Accelerating Learning via KnowledgeTransfer,2016, In 4th International Conference on Learning Representations
 In C,2015, Cortes
 Mitigation of catastroPhic forgetting in recurrent neural networksusing a fixed exPansion layer,2013, In The 2013 International Joint Conference on Neural Networks(IJCNN)
 Continual Learning with Gated IncrementalMemories for sequential data Processing,2020, Proceedings of the 2020 International Joint Conferenceon Neural Networks (IJCNN 2020)
 Incremental Sequence Learning,2016, arXiv
 PredictingParameters in deeP learning,2013, In Advances in neural information processing systems
 Organizingrecurrent network dynamics by task-computation to enable continual learning,2020, Advances in NeuralInformation Processing Systems
 Finding structure in time,1990, Cognitive Science
 A unifying bayesian view of continual learning,2018, Bayesian DeepLearning Workshop at NeurIPS
 Using Pseudo-Recurrent Connectionist Networks to Solve the Problem ofSequential Learning,1970, ResearchGate
 Semi-distributed Representations and Catastrophic Forgetting in ConnectionistNetworks,1992, Connection Science
 Audio set: An ontology and human-labeled dataset foraudio events,2017, In Proc
 Neural turing machines,2014, arXiv preprintarXiv:1410
 Memory augmented neural networks withwormhole connections,2017, arXiv preprint arXiv:1701
 Sequence tagging with contextual and non-contextualsubword representations: A multilingual evaluation,2019, In Proceedings of the 57th Annual Meetingof the Association for Computational Linguistics
 Distilling the knowledge in a neural network,2015, arXivpreprint arXiv:1503
 Long short-term memory,1997, Neural computation
 Fearnet: Brain-insPired model for incremental learning,2018, InInternational Conference on Learning Representations
 Auto-encoding variational bayes,2014, In Yoshua Bengio and YannLeCun
 Overcoming catastrophic forgetting inneural networks,2017, Proc
 Class-agnostic continual learningof alternating languages and domains,2020, arXiv preprint arXiv:2004
 Gradient-based learning applied todocument recognition,1998, Proceedings of the IEEE
 Toward Continual Learning for Conversational Agents,2017, arXiv
 Compositional languagecontinual learning,2020, In International Conference on Learning Representations
 Learning without forgetting,2017, IEEE transactions on pattern analysisand machine intelligence
 Sentiment classification byleveraging the shared knowledge from a sequence of domains,2019, In International Conference onDatabase Systems for Advanced Applications
 Alleviating catastrophic forgetting usingcontext-dependent gating and synaptic stabilization,2018, Proceedings of the National Academy ofSciences
 The stability-plasticity dilemma: investigat-ing the continuum from catastrophic forgetting to age-limited learning effects,2013, Front
 Spectral normalization forgenerative adversarial networks,2018, In International Conference on Learning Representations
 Universal dependencies v1: A multilingual treebank collection,2016, In NicolettaCalzolari (Conference Chair)
 Pixel recurrent neural networks,2016, InMaria Florina Balcan and Kilian Q
 ContinUal learning of recUrrentneUral networks by locally aligning distribUted representations,2020, IEEE Transactions on NeuralNetworks and Learning Systems
 ContinUallifelong learning with neUral networks: A review,2019, Neural Networks
 Multilingual Part-Of-SPeech tagging withbidirectional long short-term memory models and aUxiliary loss,2016, In Proceedings of the 54thAnnual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)
 Languagemodels are unsuPervised multitask learners,2019, OpenAI Blog
 icarl:Incremental classifier and rePresentation learning,2017, In Proceedings of the IEEE conference onComputer Vision and Pattern Recognition
 Stochastic backProPagation andaPProximate inference in deeP generative models,2014, In Eric P
 Progressive neural networks,2016, CoRR
 Learning to Control Fast-Weight Memories: An Alternative to DynamicRecurrent Networks,1992, Neural Comput
 Kernel principal componentanalysis,1997, In International conference on artificial neural networks
 Bidirectional recurrent neural networks,1997, IEEE Transactions on SignalProcessing
 Toward training recurrent neural networks forlifelong learning,2020, Neural computation
 OvercomingCatastrophic Forgetting During Domain Adaptation of Neural Machine Translation,2019, ACL Anthology
 Generative replay with feedback connections as a generalstrategy for continual learning,2018, arXiv preprint arXiv:1809
 Three scenarios for continual learning,2019, arXiv
 Attention is all you need,2017, In Advances in neural informationprocessing systems
 Continuallearning with hypernetworks,2020, In International Conference on Learning Representations
 Continuous learning in a hierarchicalmultiscale neural network,2018, arXiv preprint arXiv:1805
 Task representations in neural networks trained to perform many cognitive tasks,2019, Natureneuroscience
 Lifelong learning with dynamicallyexpandable networks,2018, In International Conference on Learning Representations
