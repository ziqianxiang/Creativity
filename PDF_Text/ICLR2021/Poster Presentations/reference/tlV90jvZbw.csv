title,year,conference
 High-dimensional dynamics of gener-alization error in neural networks,2020, Neural Networks
 A continuous-time view of early stopping for leastsquares regression,2019, In The 22nd International Conference on Artificial Intelligence and Statistics
 A closer look at memorization in deep networks,2017, In International Conferenceon Machine Learning
 Reconciling modern machine-learning practice and the classical bias-variance trade-off,2019, Proceedings of the National Academyof Sciences
 A Model of Double Descent for High-dimensional Binary Linear Classification,2020, arXiv:1911
 Gradient Descent Finds GlobalMinima of Deep Neural Networks,2019, In International Conference on Machine Learning
 Gradient Descent Provably OptimizesOver-parameterized Neural Networks,2018, In International Conference on Learning Representations
 A Mathematical Introduction to Compressive Sensing,2013, SpringerBerlin Heidelberg
 Surprises in High-Dimensional Ridgeless Least Squares Interpolation,2019, arXiv:1903
 Compressive sensing with un-trained neural networks:Gradient descent finds the smoothest approximation,2020, In International Conference on MachineLearning
 Denoising and Regularization via Exploiting the Struc-tural Bias of Convolutional Generators,2020, In International Conference on Learning Representations
 Implicitregularization of random feature models,2020, In International Conference on Machine Learning
 Deep Neural Networks as Gaussian Processes,2018, In International Conference onLearning Representations
 Gradient Descent with Early Stoppingis Provably Robust to Label Noise for Overparameterized Neural Networks,2020, In InternationalConference on Artificial Intelligence and Statistics
 The generalization error of random features regression: Preciseasymptotics and double descent curve,2019, arXiv:1908
 DeepDouble Descent: Where Bigger Models and More Data Hurt,2020, In International Conference onLearning Representations
 Optimal Regularization CanMitigate Double Descent,2020, arXiv:2003
 Statistical Mechanics of Learning : Generalization,1995, In The Handbook of BrainTheory and Neural Networks
 Generalization Guaranteesfor Neural Networks via Harnessing the Low-rank Structure of the Jacobian,2019, arXiv:1906
 Random Features for Large-Scale Kernel Machines,2008, In Advancesin Neural Information Processing Systems 20
 On Early Stopping in Gradient DescentLearning,2007, Constructive Approximation
 Image recognition from raw labels collected withoutannotators,2020, arXiv:1910
