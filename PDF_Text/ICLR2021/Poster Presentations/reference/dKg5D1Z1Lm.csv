title,year,conference
 A distributional perspective on reinforcementlearning,2017, In International Conference on Machine Learning
 Openai gym,2016, arXiv preprint arXiv:1606
 Coindice:Off-policy confidence interval estimation,2020, In Advances in Neural Information Processing Systems
 Minimax-optimal off-policy evaluation with linear functionapproximation,2020, In International Conference on Machine Learning
 Reinforcement learning with Gaussian processes,2005, InProceedings ofthe 22nd international conference on Machine learning
 A kernel loss for solving the Bellman equation,2019, In Advancesin Neural Information Processing Systems
 Accountable off-policy evaluation withkernel Bellman statistics,2020, In International Conference on Machine Learning
 Batch mode reinforcementlearning based on the synthesis of artificial trajectories,2013, Annals of Operations Research
 Bayesian reinforcementlearning: A survey,2016, arXiv preprint arXiv:1609
 Bayesian reinforcementlearning: A survey,2016, arXiv preprint arXiv:1609
 Bootstrapping statisticalinference for off-policy evaluation,2021, arXiv preprint arXiv:2102
 Minimax confidence interval for off-policy evaluation and policyoptimization,2020, In Advances in Neural Information Processing Systems
 Doubly robust off-policy evaluation for reinforcement learning,2016, InProceedings of the 23rd International Conference on Machine Learning
 Statistical bootstrapping for uncertainty estimation in off-policyevaluation,2020, arXiv preprint arXiv:2007
 A maximum-entropy approach to off-policy evaluation in average-reward MDPs,2020, InAdvances in Neural Information Processing Systems
 Breaking the curse of horizon: Infinite-horizon off-policy estimation,2018, In Advances in Neural Information Processing Systems
 Representation balancing MDPs for off-policy policy evaluation,2018, InAdvances in Neural Information Processing Systems 31 (NeurIPS)
 Understanding the curse of horizon in off-policyevaluation via conditional importance sampling,2020, In International Conference on Machine Learning
 Black-box off-policy estimation for infinite-horizon reinforcement learning,2020, In International Conference on Learning Representations
 Dualdice: Behavior-agnostic estimation ofdiscounted stationary distribution corrections,2019, In Advances in Neural Information ProcessingSystems
 Algaedice:Policy gradient from arbitrary experience,2019, arXiv preprint arXiv:1912
 Concentration inequalities for markov chains by marton couplings and spectralmethods,2015, Electron
 Eligibility traces for off-policy policy evaluation,2000, Computer Science DepartmentFaculty Publication Series
 Temporal abstraction in reinforcement learning,2001, ProQuest Dissertations and Theses
 Eligibility traces for off-policy policyevaluation,2000, In Proceedings of the 17th International Conference on Machine Learning
 Sequential complexities and uniformmartingale laws of large numbers,2015, Probability Theory and Related Fields
 Proximal policyoptimization algorithms,2017, arXiv preprint arXiv:1707
 A hilbert space embedding fordistributions,2007, In Algorithmic learning theory
 Reinforcement Learning: An Introduction,1998, MIT Press
 Doubly robust bias reductionin infinite horizon off-policy estimation,2020, In International Conference on Learning Representations(ICLR)
 Off-policy interval estimation withlipschitz value iteration,2020, In Advances in Neural Information Processing Systems
 Safe reinforcement learning,2015, PhD thesis
 Data-efficient off-policy policy evaluation for reinforcementlearning,2016, In Proceedings of the 33rd International Conference on Machine Learning
 Batch stationary distribution estimation,2020, InInternational Conference on Machine Learning
 Interval estimation for reinforcement-learning algorithms incontinuous-state domains,2010, In Advances in Neural Information Processing Systems
 Q* approximation schemes for batch reinforcement learning: Atheoretical comparison,2020, In Conference on Uncertainty in Artificial Intelligence (UAI)
 Towards optimal off-policy evaluation for rein-forcement learning with marginalized importance sampling,2019, In Advances in Neural InformationProcessing Systems
 Offline policy selectionunder uncertainty,2020, arXiv preprint arXiv:2012
 Off-policy evaluation viathe regularized Lagrangian,2020, In Advances in Neural Information Processing Systems
 Asymptotically efficient off-policy evaluation for tabular reinforce-ment learning,2020, In Proceedings of the International Conference on Artificial Intelligence andStatistics (AISTATS)
 Near optimal provable uniform convergence in off-policyevaluation for reinforcement learning,2020, arXiv preprint arXiv:2007
 Gendice: Generalized offline estimation ofstationary values,2020, In International Conference on Learning Representations
 Gradientdice: Rethinking generalized offlineestimation of stationary values,2020, In International Conference on Machine Learning
