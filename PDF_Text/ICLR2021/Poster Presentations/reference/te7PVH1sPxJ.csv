title,year,conference
 Estimating the spectral density of large implicit matrices,2018, arXiv preprintarXiv:1802
 Un-derstanding and mitigating exploding inverses in invertible neural networks,2020, arXiv preprintarXiv:2006
 NeUral ordinarydifferential eqUations,2018, In Advances in neural information processing systems
 Optimal control via neural networks: A convexapproach,2019, In International Conference on Learning Representations
 De-scribing textures in the wild,2014, In Conference on Computer Vision and Pattern Recognition
 Approximation by superpositions ofa sigmoidal function,1989, Mathematics of control
 Nice: Non-linear independent components esti-mation,2014, arXiv preprint arXiv:1410
 Density estimation using real nvp,2017, InInternational Conference on Learning Representations
 Feature-wise transformations,2018, Distill
 Neural spline flows,2019, InAdvances in Neural Information Processing Systems
 Learning nor-malizing flows from entropy-kantorovich potentials,2020, arXiv preprint arXiv:2006
 Made: Masked autoencoderfor distribution estimation,2015, In Proceedings of the 32nd International Conference on MachineLearning
 Stochastic chebyshev gradient descent for spectral opti-mization,2018, In Advances in Neural Information Processing Systems
 Array program-ming with numpy,2020, Nature
 NeUral aUtoregressiveflows,2018, In International Conference on Machine Learning
 Solving ode with Universal flows: Approx-imation theory for flow-based models,2020, In ICLR 2020 Workshop on Integration of Deep NeuralModels and Differential Equations
 Densely connectedconvolUtional networks,2017, In Proceedings of the IEEE conference on computer vision and patternrecognition
 AUto-encoding variational bayes,2013, arXiv preprintarXiv:1312
 Glow: Generative flow with invertible 1x1 convolUtions,2018, InAdvances in neural information processing systems
 Im-proved variational inference with inverse aUtoregressive flow,2016, In Advances in neural informationprocessing systems
 Resnet with one-neUron hidden layers is a Universal approxi-mator,2018, In Advances in neural information processing systems
 Approximating spectral densities of large matrices,2016, SIAMreview
 Optimal transportmapping via inpUt convex neUral networks,2019, arXiv preprint arXiv:1908
 Spectral normalizationfor generative adversarial networks,2018, arXiv preprint arXiv:1802
 Neural im-portance sampling,2019, ACM Transactions on Graphics (TOG)
 Readingdigits in natural images with unsupervised feature learning,2011, 2011
 Ot-flow: Fast and accurate continu-ous normalizing flows via optimal transport,2020, arXiv preprint arXiv:2006
 Masked autoregressive flow for densityestimation,2017, In Advances in Neural Information Processing Systems
 Convex analysis,1970, Number 28
 Optimal transport for applied mathematicians,2015, Birkauser NY
 Auto-differentiating linear algebra,2017, arXiv preprint arXiv:1710
 2-wasserstein approximation via restricted convex potentialswith application to improved training for gans,2019, arXiv preprint arXiv:1902
 Python reference manual,1995, Centrum voor Wiskunde enInformatica Amsterdam
 Unconstrained monotonic neural networks,2019, In Advances inNeural Information Processing Systems
 Potential flow generator with l2 optimal transport regularityfor generative models,2019, arXiv preprint arXiv:1908
 Deep sets,2017, In Advances in neural information processing systems
 Monge-ampere flow for generative modeling,2018, arXiv preprintarXiv:1809
 Places: A 10 mil-lion image database for scene recognition,2017, IEEE Transactions on Pattern Analysis and MachineIntelligence
