title,year,conference
 Optimality and approximation with policygradient methods in markov decision processes,2019, arXiv preprint arXiv:1908
 Pc-pg: Policy cover directed exploration forprovable policy gradient learning,2020, arXiv preprint arXiv:2007
 Temporal-difference learning for nonlinear value function approximation in thelazy training regime,2019, arXiv preprint arXiv:1905
 A convergence theory for deep learning via over-parameterization,2018, arXiv preprint arXiv:1811
 Universal approximation bounds for superpositions of a sigmoidal function,1993, IEEE Transactionson Information Theory
 Global optimality guarantees for policy gradient methods,2019, arXiv preprintarXiv:1906
 Neural temporal-difference learning converges toglobal optima,2019, In Advances in Neural Information Processing Systems
 Fast global convergence of natural policygradient methods with entropy regularization,2020, arXiv preprint arXiv:2007
 Sparse optimization on measures with over-parameterized gradient descent,2019, arXiv preprintarXiv:1907
 On the global convergence of gradient descent for over-parameterized modelsusing optimal transport,2018, In Proceedings of the 32Nd International Conference on Neural InformationProcessing Systems
 Implicit bias of gradient descent for wide two-layer neural networks trainedwith the logistic loss,2020, arXiv preprint arXiv:2002
 On lazy training in differentiable programming,2019, In Advancesin Neural Information Processing Systems
 Approximation by superpositions of a sigmoidal function,1989, Mathematics of Control
 Gradient descent finds global minima of deepneural networks,2019, In International Conference on Machine Learning
 Barron spaces and the compositional function spaces for neural networkmodels,2019, arXiv preprint arXiv:1906
 Learning to walk viadeep reinforcement learning,2018, arXiv preprint arXiv:1812
 Soft actor-critic: Off-policy maximumentropy deep reinforcement learning with a stochastic actor,2018, In International Conference on Machine Learning
 Approximation capabilities of multilayer feedforward networks,0893, Neural Networks
 Neural tangent kernel: Convergence and generalization inneural networks,2018, In Advances in neural information processing systems
 Analysis of a two-layer neural network via displace-ment convexity,2019, arXiv preprint arXiv:1901
 Approximately optimal approximate reinforcement learning,2002, In Proceedingsof the Nineteenth International Conference on Machine Learning
 Wide neural networks of any depth evolve as linear models under gradient descent,2019, InAdvances in neural information processing systems
 On the global convergence rates ofsoftmax policy gradient methods,2020, arXiv preprint arXiv:2005
 A mean field view of the landscape of two-layerneural networks,2018, Proceedings of the National A
 Playing Atari with deep reinforcement learning,2013, In NIPS Deep Learning Workshop
 A rigorous framework for the mean field limit of multilayer neuralnetworks,2020, arXiv preprint arXiv:2001
 Mastering the game of Go without humanknowledge,2017, Nature
 Reinforcement Learning: An Introduction,2018, MIT Press
 Policy gradient methods forreinforcement learning with function approximation,2000, In Advances in neural information processing systems
 Grandmaster level in starcraft ii usingmulti-agent reinforcement learning,2019, Nature
 Neural policy gradient methods: Global optimalityand rates of convergence,2019, arXiv preprint arXiv:1909
 On the convergence of gradient descent training for two-layer relu-networks in the meanfield regime,2020, arXiv preprint arXiv:2005
 Multi-agent reinforcement learning: A selective overview oftheories and algorithms,2019, arXiv preprint arXiv:1911
 Can temporal-difference andq-learning learn representation? a mean-field theory,2020, arXiv preprint arXiv:2006
