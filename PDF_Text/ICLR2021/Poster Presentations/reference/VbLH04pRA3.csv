title,year,conference
 Optuna:A next-generation hyperparameter optimization framework,2019, In Proceedings of the 25rd ACMSIGKDD International Conference on Knowledge Discovery and Data Mining
 Convergence rates of efficient global optimization algorithms,2011, J
 Xgboost: A scalable tree boosting system,2016, In KDD
 Semi-sUpervised seqUence learning,2015, Advances in neural informationprocessing systems
 BOHB: RobUst and efficient hyperparameter op-timization at scale,2018, In Proceedings of the 35th International Conference on Machine Learning(ICML 2018)
 Bayesian optimization with local search,2020, In InternationalConference on Machine Learning
 An open soUrce aUtoml benchmark,2019, In AutoML Workshop at ICML 2019
 Sequential model-based optimization forgeneral algorithm configuration,2011, In Learning and Intelligent Optimization
 Non-stochastic best arm identification and hyperparameteroptimization,2016, In Artificial Intelligence and Statistics
 Multi-fidelitybayesian optimisation with continuous approximations,2017, In Proceedings of the 34th InternationalConference on Machine Learning
 Lightgbm: A highly efficient gradient boosting decision tree,2017, In Advances in NeuralInformation Processing Systems
 Fast bayesian op-timization of machine learning hyperparameters on large datasets,2017, In Artificial Intelligence andStatistics
 Bandit algorithms,2020, Cambridge University Press
 A system for massively parallel hyperparame-ter tuning,2020, In Proceedings of Machine Learning and Systems
 Hyperband:A novel bandit-based approach to hyperparameter optimization,2017, In ICLR’17
 Practical bayesian optimization of machinelearning algorithms,2012, In Advances in neural information processing systems
 Multivariate stochastic approximation using a simultaneous perturbation gradi-ent approximation,1992, IEEE transactions on automatic control
 Gaussian pro-cess optimization in the bandit setting: No regret and experimental design,2009, arXiv preprintarXiv:0912
 Frugal optimization for cost-related hyperparameters,2021, InAAAI’21
 On hyperparameter optimization of machine learning algorithms:Theory and practice,2020, Neurocomputing
