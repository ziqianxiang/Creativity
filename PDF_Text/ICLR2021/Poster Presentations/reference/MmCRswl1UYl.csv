title,year,conference
 Signature Verifi-cation using a” siamese” time delay neural network,1994, In Advances in neural information processingsystems
 Tabfact: A large-scale dataset for table-based fact verification,2019, InInternational Conference on Learning Representations
 Generating long sequences with sparsetransformers,2019, arXiv preprint arXiv:1904
 Bert: Pre-training of deepbidirectional transformers for language understanding,2019, In Proceedings of the 2019 Conference ofthe North American Chapter of the Association for Computational Linguistics: Human LanguageTechnologies
 Differentiable reasoning over a virtual knowledge base,2019, In InternationalConference on Learning Representations
 Cognitive graph for multi-hopreading comprehension at scale,2019, In Proceedings of the 57th Annual Meeting of the Associationfor Computational Linguistics
 Realm: Retrieval-augmented language model pre-training,2020, Proceedings of ICML 2020
 Tapas: Weakly supervised table parsing via pre-training,2020, ACL 2020
 Reformer: The efficient transformer,2020, ICLR
 Natural questions: abenchmark for question ansWering research,2019, Transactions of the Association for ComputationalLinguistics
 Latent retrieval for Weakly supervised opendomain question ansWering,2019, In Proceedings of the 57th Annual Meeting of the Association forComputational Linguistics
 Roberta: A robustly optimized bert pretrainingapproach,2019, arXiv preprint arXiv:1907
 Decoupled Weight decay regularization,2019, ICLR 2019
 KnoWledge guided textretrieval and reading for open domain question ansWering,2019, arXiv preprint arXiv:1911
 Totto: A controlled table-to-text generation dataset,2020, arXiv preprintarXiv:2004
 Kilt: a benchmark for knowl-edge intensive language tasks,2020, arXiv preprint arXiv:2009
 Languagemodels are unsupervised multitask learners,2019, OpenAI Blog
 Efficient content-based sparseattention with routing transformers,2020, arXiv preprint arXiv:2003
 Learning discriminative pro-jections for text similarity measures,2011, In Proceedings of the fifteenth conference on computationalnatural language learning
 Tabert: Pretraining for jointunderstanding of textual and tabular data,2020, ACL 2020
 Spider: A large-scale human-labeled dataset for complexand cross-domain semantic parsing and text-to-sql task,2018, In Proceedings of the 2018 Conferenceon Empirical Methods in Natural Language Processing
 Big bird: Transformers for longersequences,2020, arXiv preprint arXiv:2007
 Seq2sql: Generating structured queries fromnatural language using reinforcement learning,2017, arXiv preprint arXiv:1709
