Table 1: RIDE achieves the state-of-the-art results on CIFAR100-LT without sacrificing the per-formance of many-shot classes like all previous methods. Compared with BBN (Zhou et al., 2020)and LFME (Xiang et al., 2020), which also contain multiple experts (or branches), RIDE (2 experts)outperforms them by a large margin with fewer GFlops. The relative computation cost (averaged ontesting set) with respect to the baseline model and absolute improvements against SOTA (colored ingreen) are reported. f denotes our reproduced results with released code.去 denotes results copiedfrom (Cao et al., 2019) and the imbalance ratio is 100.
Table 2: RIDE achieves state-of-the-art results on ImageNet-LT (Liu et al., 2019) and obtainsconsistent performance improvements on various backbones. The top-1 accuracy and computationalcost are compared with the state-of-the-art methods on ImageNet-LT, with ResNet-50 and ResNeXt-50 as the backbone networks. Results marked with f are copied from (Kang et al., 2020). Detailedresults on each split are listed in appendix materials.
Table 3: RIDE outperforms previous state-of-the-art methods on challenging iNaturalist 2018(Van Horn et al., 2018) dataset, which contains 8,142 classes, by a large margin. Relative im-provements to SOTA result of each split (colored with gray) are also listed, with the largest boostfrom few-shot classes. Compared with previous SOTA method BBN, which also contains multi-ple “experts”, RIDE achieves more than 20% higher top-1 accuracy on many-shot classes. Resultsmarked with f are from BBN (Zhou et al., 2020) and Decouple (Kang et al., 2020). BBN's resultsare from the released checkpoint.
Table 4: Ablation studies on the effectiveness of each component on CIFAR100-LT. LDAM isused as our classification loss. The first 3 RIDE models only have architectural change withoutchanges in training method. The performance without LIndividual checked indicates directly applyingclassification loss onto the final model output, which is the mean expert logits. This is referred toas collaborative loss above. In contrast, if LIndividual if checked, we apply individual loss to eachindividual expert. The difference between collaborative loss and individual loss is described above.
Table 5: Comparison of different distillation methods. We transfer from a model based onResNet-32 with 6 experts to a model of the same type, except with fewer experts. We use CIFAR100-LT for the following comparison. No expert assignment module is used in the following experi-ments. Following the procedure for CRD (Tian et al., 2019), we also apply KD when we transferfrom a teacher to students with other distillation methods.
Table 6: Top-1 accuracy comparison with state-of-the-art methods on ImageNet-LT (Liu et al.,2019) with ResNet-10. Performance on Many-shot (>100), Medum-shot (≤100 & >20) and Few-shot (≤20) are also provided. Results marked with f are copied from (LiU et al., 2019). Results witht are from (Xiang et al., 2020).
Table 7: Top-1 accuracy comparison with state-of-the-art methods on ImageNet-LT (Liu et al.,2019) with ResNet-50. Performance on Many-shot (>100), Medum-shot (≤100 & >20) and Few-shot (≤20) are also provided. Results marked with f are copied from (Kang et al., 2020).
Table 8: Top-1 accuracy comparison with state-of-the-art methods on ImageNet-LT (Liu et al.,2019) with ResNeXt-50. Performance on Many-shot (>100), Medum-shot (≤100 & >20) andFew-shot (≤20) are also provided. Results marked with f are copied from (Kang et al., 2020).
