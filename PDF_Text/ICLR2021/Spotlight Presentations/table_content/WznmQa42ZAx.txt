Table 1: Comparison using the faithfulness goldstandard on the toy task. *as in Li et al. (2016).
Table 2: Retained edges for De Cao et al.â€™s (2019)question answering GNN by layer (k) and type.
Table 3: Percentages of paths with either 0, 1, or 2edges retained, split by path length and predicatetype, for the two models. For the LSTM+GNNmodel, at most one edge can be included per pathas only a single GNN layer is employed.
Table 4: WikiHop dataset statistics from Welbl et al. (2018): number of candidates and documentsper sample and document length. Table taken from De Cao et al. (2019).
Table 5: Performance of the three real-world models using the original input graphs, usingthe subgraphs retained after masking with GraphMask, and using only a randomly selected0/25/50/75/100% of the edges retained after masking with GraphMask. Dropping the edgesmarked superfluous by our technique does not impact performance; dropping the remaining edges,even if only a randomly selected 25% of them, significantly hurts the model.
Table 7: Mean percentage of the total attribution scoreallocated to each layer for the question answeringmodel, according to GNNExplainer, Integrated Gra-dients, and GraphMask.
Table 6: Performance of the question an-swering model with all edges in each in-dividual GNN layer dropped.
