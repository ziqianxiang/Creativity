Table 1: Accuracy(%) of different defense methods under attacks on IMDB (a) and SNLI (b). “First-order aprx” denotes Ebrahimi et al. (2018). “Adv l2-ball” denotes Miyato et al. (2017). “Axis-aligned” denotes Jia et al. (2019). “ASCC-defense” denotes the proposed method.
Table 2: Ablation study on the sparsity regularization term.
Table 3: Accuracy (%) of models initialized with different word vectors without any other defensetechnique. GloVe denotes the word vectors from Pennington et al. (2014). “First order V” denotesword vectors trained by Ebrahimi et al. (2018). “ASCC-V” denotes word vectors trained by ASCC-defense. We freeze the pre-trained word vectors during normal training.
Table 4: Vanilla accuracy(%) of different defense methods on IMDB (a) and SNLI (b).
Table 5: Vanilla and robust accuracy (%) of the proposed method on BERT (bert-base-uncased).
Table 6: Accuracy (%) of normally trained models initialized with and freezed by the proposedrobust word vectors. For example, pre-trained on LSTM means the word vectors are pre-trained byLSTM-based ASCC-defense and applied to CNN means the pre-trained word vectors are used toinitialize a CNN model to perform normal training.
