Table 1: Memory usage comparison (in GB) for a fixed compute overhead. At 10% Computeoverhead over PyTorCh, MONeT uses 2-3× less memory than PyTorCh. At the same overhead,MONeT Can train models using 1.2-1.8× less memory than CheCkmate.
Table 2: Solver time (in hours) to reach 5% close to optimal solution. MONeT-NoOp reaches a5% close-to-optimal solution 1.6×-117× faster than Checkmate. MONeT gets close to 5% of theoptimal solution only in a few hours, and up-to 16× faster than Checkmate for larger models.
Table 3: Memory ratio and overhead (%) over PyTorch for Gist and MONeT. MONET obtains1.4×-2.1× higher memory savings over Gist across models. Number in parenthesis after modelname shows the batch size.
Table 4: Notations used in paper with explanations. Notations with only i in subscript/superscriptgenerally relate to the forward pass, with only k relate to the backward pass, and with both i and krelate to the recomputation phase.
Table 5: Solver time (in hours) to reach 5% close to optimal solution. MONeT-NoOp reaches a5% close-to-optimal solution 1.6×-117× faster than Checkmate. MONeT gets close to 5% of theoptimal solution only in a few hours, and up-to 16× faster than Checkmate for larger models.
Table 6: Solver time (in hours) to reach 2% close to optimal solution. MONeT-NoOp reachesa 2% close-to-optimal solution 1.3×-139× faster than Checkmate. MONeT reaches a 2% close-to-optimal solution within few hours in most cases, and up to 27× faster than Checkmate for largermodels.
Table 7: ILP statistics for Checkmate, MONeT-NoOp, and MONeT. MONeT-NoOp has on av-erage 50% fewer constraints and 67% fewer variables than Checkmate. MONeT has slightly largernumber of constraints, on average 40% fewer variables than Checkmate.
