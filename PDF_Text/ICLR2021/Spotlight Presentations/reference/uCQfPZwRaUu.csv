title,year,conference
 Unsupervised state representation learning in atari,2019, In NeurIPS
 Learning with pseUdo-ensembles,2014, In NeurIPS
 Learning representations by maximizingmUtUal information across views,2019, In NeurIPS
 Agent57: OUtperforming the atari hUman benchmark,2020, In ICML
 A distributional perspective on reinforcementlearning,2017, In ICML
 Language models arefew-shot learners,2020, In NeurIPS
 A simple framework forcontrastive learning of visual representations,2020, In ICML
 Bigself-supervised models are strong semi-supervised learners,2020, In NeurIPS
 Learning invariances for policygeneralization,2018, arXiv preprint arXiv:1809
 Unsupervised visual representation learning bycontext prediction,2015, In ICCV
 Challenges of real-world reinforcementlearning,2019, In ICML
 Noisy networks for exploration,2018, In ICLR
 Anintroduction to deep reinforcement learning,2018, arXiv preprint arXiv:1811
 Deepmdp:Learning continuous latent space models for representation learning,2019, In ICML
 Bootstrap latent-predictive representations for multitask reinforcementlearning,2020, In ICML
 Learning latent dynamics for planning from pixels,2019, In ICML
 Dream to control: Learningbehaviors by latent imagination,2020, In ICLR
 Momentum contrast forunsupervised visual representation learning,2020, In CVPR
 Data-efficient image recognition with contrastive predictive coding,2019, arXivpreprint arXiv:1905
 Rainbow: Combiningimprovements in deep reinforcement learning,2018, In AAAI
 Learning deep representations by mutual information estimationand maximization,2019, In ICLR
 Batch normalization: Accelerating deep network training byreducing internal covariate shift,2015, In ICML
 Model basedreinforcement learning for atari,2019, In ICLR
 Temporal ensembling for semi-supervised learning,2017, In ICLR
 Stochastic latent actor-critic:Deep reinforcement learning with a latent variable model,2019, arXiv preprint arXiv:1907
 State representa-tion learning for control: An overview,2018, Neural Networks
 Human-level controlthrough deep reinforcement learning,2015, Nature
 Representation learning with contrastive predictivecoding,2018, arXiv preprint arXiv:1807
 Curl: Contrastive unsupervised representationsfor reinforcement learning,2020, In ICML
 rlpyt: A research code base for deep reinforcement learning inpytorch,2019, arXiv preprint arXiv:1909
 The bitter lesson,2019, Incomplete Ideas (blog)
 Mean teachers are better role models: Weight-averaged consistencytargets improve semi-supervised deep learning results,2017, In NeurIPS
 Deepmind control suite,2018, arXiv preprintarXiv:1801
 Contrastive multiview coding,2019, arXiv preprintarXiv:1906
 Deep reinforcement learning with double q-learning,2016, In AAAI
 Grandmaster level instarcraft ii using multi-agent reinforcement learning,2019, Nature
 Understanding contrastive representation learning throughalignment and uniformity on the hypersphere,2020, In Hal DaUme III and Aarti Singh (eds
 Duelingnetwork architectures for deep reinforcement learning,2016, In ICML
 Unsupervised dataaugmentation for consistency training,2019, arXiv preprint arXiv:1904
 Image augmentation is all you need: Regularizing deepreinforcement learning from pixels,2021, In International Conference on Learning Representations
