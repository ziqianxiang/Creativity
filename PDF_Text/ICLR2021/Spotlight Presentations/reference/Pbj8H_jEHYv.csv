title,year,conference
 Sorting out lipschitz function approximation,2019, InInternational Conference on Machine Learning
 Spectrally-normalized margin bounds forneural networks,2017, In Advances in Neural Information Processing Systems
 Towards evaluating the robustness of neural networks,2017, In 2017ieee symposium on security and privacy (sp)
 Semialgebraic optimizationfor lipschitz constants of relu networks,2020, Advances in Neural Information Processing Systems
 Maximum resilience of artificial neuralnetworks,2017, In International Symposium on Automated Technology for Verification and Analysis
 Parsevalnetworks: Improving robustness to adversarial examples,2017, arXiv preprint arXiv:1704
 Certified adversarial robustness via randomizedsmoothing,2019, arXiv preprint arXiv:1902
 Dawnbench: An end-to-end deep learning bench-mark and competition,2017, Training
 Reliable evaluation of adversarial robustness with an ensembleof diverse parameter-free attacks,2020, arXiv preprint arXiv:2003
 Efficientand accurate estimation of lipschitz constants for deep neural networks,2019, In Advances in NeuralInformation Processing Systems
 Regularisation of neural networksby enforcing lipschitz continuity,2018, arXiv preprint arXiv:1804
 Deep residual learning for imagerecognition,2016, In Proceedings of the IEEE conference on computer vision and pattern recognition
 Orthogonal recurrent neural networks with scaledcayley transform,2018, In International Conference on Machine Learning
 Provable benefit of orthogonal initialization inoptimizing deep linear networks,2020, In International Conference on Learning Representations
 Safety verification of deep neuralnetworks,2017, In International Conference on Computer Aided Verification
 Adam: A method for stochastic oPtimization,2014, arXiv preprintarXiv:1412
 Provable defenses against adversarial examPles via the convex outeradversarial PolytoPe,2017, arXiv preprint arXiv:1711
 LiPschitz constant estimation of neural networksvia sParse Polynomial oPtimization,2020, arXiv preprint arXiv:2004
 Trivializations for gradient-based oPtimization on manifolds,2019, arXiv preprintarXiv:1909
 Cheap orthogonal constraints in neural networks:A simPle Parametrization of the orthogonal and unitary grouP,2019, arXiv preprint arXiv:1901
 Efficient riemannian optimization on the stiefel manifold viathe cayley transform,2020, arXiv preprint arXiv:2002
 An approach to reachability analysis for feed-forward reluneural networks,2017, arXiv preprint arXiv:1706
 Complex unitary recurrent neuralnetworks using scaled cayley transform,2019, In Proceedings of the AAAI Conference on ArtificialIntelligence
 Spectral normalization forgenerative adversarial networks,2018, arXiv preprint arXiv:1802
 Resurrecting the sigmoid in deeplearning through dynamical isometry: theory and practice,2017, In Advances in neural informationprocessing systems
 Deep isometric learning forvisual recognition,2020, In International Conference on Machine Learning
 Certified defenses against adversarial exam-ples,2018, arXiv preprint arXiv:1801
 Weight normalization: A simple reparameterization to acceleratetraining of deep neural networks,2016, In Advances in neural information processing systems
 Exact solutions to the nonlinear dynamicsof learning in deep linear neural networks,2013, arXiv preprint arXiv:1312
 The singular values of convolutional layers,2018, arXivpreprint arXiv:1805
 Intriguing properties of neural networks,2013, arXiv preprint arXiv:1312
 Verifying neural networks with mixed integer programming,2017, arXivpreprint arXiv:1711
 Lipschitz-margin training: Scalable certificationof perturbation invariance for deep neural networks,2018, In Advances in neural information processingsystems
 On orthogonality and learningrecurrent networks with long term dependencies,2017, arXiv preprint arXiv:1702
 Scaling provable adversarialdefenses,2018, In Advances in Neural Information Processing Systems
 A closer look at accuracy vs,2020, robustness
 Wide residual networks,2016, arXiv preprint arXiv:1605
 Fixup initialization: Residual learning withoutnormalization,2019, arXiv preprint arXiv:1901
