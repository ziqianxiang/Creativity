title,year,conference
 Deep learning with differential privacy,2016, In Proceedings of the 2016 ACM SIGSACConference on Computer and Communications Security
 Ipguard: Protecting the intellectual prop-erty of deep neural networks via fingerprinting the classification boundary,2019, arXiv preprintarXiv:1910
 Adversarial examples are not easily detected: Bypassing tendetection methods,2017, In Proceedings of the 10th ACM Workshop on Artificial Intelligence andSecurity
 Towards evaluating the robustness of neural networks,2017, In 2017IEEE Symposium on Security and Privacy (SP)
 A downsampled variant of imagenet as analternative to the cifar datasets,2017, arXiv preprint arXiv:1707
 Cinic-10 is not imagenetor cifar-10,2018, arXiv preprint arXiv:1810
 Imagenet: A large-scale hi-erarchical image database,2009, In 2009 IEEE conference on computer vision and pattern recognition
 Boost-ing adversarial attacks with momentum,2018, In Proceedings of the IEEE conference on computervision and pattern recognition
 A guide to deeplearning in healthcare,2019, Nature medicine
 Tensorflow privacy,2020, 2019
 Explaining and harnessing adversarialexamples,2014, arXiv preprint arXiv:1412
 Identity mappings in deep residualnetworks,2016, In European conference on computer vision
 Distilling the knowledge in a neural network,2015, arXivpreprint arXiv:1503
 Have you stolen my model? evasion attacks against deep neuralnetwork watermarking techniques,2018, arXiv preprint arXiv:1809
 Evasion attacks against watermarking techniquesfound in mlaas systems,2019, In 2019 Sixth International Conference on Software Defined Systems(SDS)
 High-fidelity extraction of neural network models,2019, arXiv preprint arXiv:1909
 Adam: A method for stochastic optimization,2014, arXiv preprintarXiv:1412
 Delving into transferable adversarial exam-ples and black-box attacks,2016, arXiv preprint arXiv:1611
 Adversarial frontier stitching for remote neuralnetwork watermarking,2017, arXiv preprint arXiv:1711
 Adversarialrobustness toolbox v0,2018, 4
 Knockoff nets: Stealing functionalityof black-box models,2019, In Proceedings of the IEEE Conference on Computer Vision and PatternRecognition
 Practical black-box attacks against machine learning,2017, In Proceedings of the 2017 ACMon Asia conference on computer and communications security
 On the robustness of thebackdoor-based Watermarking in deep neural netWorks,2019, arXiv preprint arXiv:1906
 Very deep convolutional netWorks for large-scale imagerecognition,2014, arXiv preprint arXiv:1409
 DaWn: Dynamic adversarialWatermarking of neural netWorks,2019, arXiv preprint arXiv:1906
 Deeptest: Automated testing of deep-neural-netWork-driven autonomous cars,2018, In Proceedings of the 40th international conference onsoftware engineering
 Ensemble adversarial training: Attacks and defenses,2017, arXiv preprint arXiv:1705
 The spaceof transferable adversarial examples,2017, arXiv preprint arXiv:1704
 Embedding watermarksinto deep neural networks,2017, In Proceedings of the 2017 ACM on International Conference onMultimedia Retrieval
 Recent trends in deep learn-ing based natural language processing,2018, ieee Computational intelligenCe magazine
