title,year,conference
 Hindsight experiencereplay,2017, In I
 Active learning of inverse models with intrinsicallymotivated goal exploration in robots,2013, Robotics Auton
 Control What you can:Intrinsically motivated task-planning agent,2019, In H
 A simple frameWork forcontrastive learning of visual representations,2020, arXiv preprint arXiv:2002
 Bert: Pre-training of deepbidirectional transformers for language understanding,2018, arXiv preprint arXiv:1810
 Neural relational inference for interacting systems,2018, In ICML
 Learning actionable representations With goal-conditionedpolicies,2019, ArXiv
 Neural expectation maximization,2017, InAdvances in Neural Information Processing Systems
 Multi-object representation learningWith iterative variational inference,2019, Proceedings of the 36nd International Conference on MachineLearning
 Soft actor-critic: Off-policy maximum entropydeep reinforcement learning With a stochastic actor,2018, In ICML
 Soft actor-critic: Off-policy maxi-mum entropy deep reinforcement learning With a stochastic actor,2018, arXiv preprint arXiv:1801
 Momentum contrast forunsupervised visual representation learning,2019, arXiv preprint arXiv:1911
 beta-vae: Learning basic visual concepts with a constrained variationalframework,2017, In ICLR
 Scalable object-orientedsequential generative models,2019, arXiv preprint arXiv:1910
 Qt-opt: Scalable deepreinforcement learning for vision-based robotic manipulation,2018, arXiv preprint arXiv:1806
 Adam: A method for stochastic optimization,2015, CoRR
 Curiosity driven explo-ration of learned disentangled goal spaces,2018, In Aude Billard
 Challenging common assumptions in the unsupervised learning of dis-entangled representations,2019, In International Conference on Machine Learning
 Learning latent plans from play,2019, Conference on Robot Learning (CoRL)
 Visualreinforcement learning with imagined goals,2018, In Advances in Neural Information ProcessingSystems
 Planning with goal-conditionedpolicies,2019, In Advances in Neural Information Processing Systems 
 Unsupervised learningof goal spaces for intrinsically motivated goal exploration,2018, In International Conference on LearningRepresentations
 Languagemodels are unsupervised multitask learners,2019, 2019
 Disentangling the independentlycontrollable factors of variation by interacting with the world,2018, arXiv preprint arXiv:1802
 A perspective on objects and systematicgeneralization in model-based rl,2019, arXiv preprint arXiv:1906
 Attention is all you need,2017, In Advances in neural informationprocessing systems
 Unsupervised control through non-parametric discriminative rewards,2019, InInternational Conference on Learning Representations
 Deep sets,2017, In I
 7 show that SCALORâ€™s zwhere components are more disentangled and thus arebetter suited for the construction of independent RL sub-tasks,2019, In addition
