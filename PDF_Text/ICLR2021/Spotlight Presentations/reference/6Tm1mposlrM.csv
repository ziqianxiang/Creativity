title,year,conference
 The intriguing role of module criticalityin the generalization of deep networks,2020, In International Conference on Learning Representations
 Understanding and utilizingdeep neural networks trained with noisy labels,2019, CoRR
 AU-toaugment: Learning augmentation policies from data,2018, CoRR
 ImageNet: A Large-Scale HierarchicalImage Database,2009, In CVPR09
 Improved regularization of convolutional neural networkswith cutout,2017, CoRR
 Sharp minima can generalizefor deep nets,2017, arXiv preprint arXiv:1703
 Incorporating nesterov momentum into adam,2016, 2016
 Shake-shake regularization,2017, CoRR
 Deep pyramidal residual networks,2016, CoRR
 Deep residual learning for image recog-nition,2015, CoRR
 Simplifying neural nets by discovering flat minima,1995, InAdvances in neural information processing Systems
 Flat minima,1997, Neural Computation
 Batch normalization: Accelerating deeP network training byreducing internal covariate shift,2015, arXiv preprint arXiv:1502
 Neural tangent kernel: Convergence and gener-alization in neural networks,2018, CoRR
 Mentornet: Regularizingvery deeP neural networks on corruPted labels,2017, CoRR
 Fantasticgeneralization measures and where to find them,2019, arXiv preprint arXiv:1912
 AdaPtive estimation of a quadratic functional by model selec-tion,2000, Annals of Statistics
 Training recurrent neural networks by diffusion,2016, CoRR
 Readingdigits in natural images with unsupervised feature learning,2011, 2011
 Exploring general-ization in deep learning,2017, In Advances in neural information processing systems
 Un-supervised label noise modeling and loss correction,2019, CoRR
 Improved sample complexities for deep neural networks and robustclassification via an all-layer margin,2020, In International Conference on Learning Representations
 Fashion-mnist: a novel image dataset for benchmark-ing machine learning algorithms,2017, CoRR
 Shakedrop regularization,2018, CoRR
 Wide residual networks,2016, CoRR
 Understandingdeep learning requires rethinking generalization,2016, CoRR
 mixup: Beyond empiricalrisk minimization,2017, arXiv preprint arXiv:1710
 Generalized cross entropy loss for training deep neural networkswith noisy labels,2018, CoRR
