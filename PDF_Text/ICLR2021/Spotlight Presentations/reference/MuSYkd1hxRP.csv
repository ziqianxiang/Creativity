title,year,conference
 Adaptive stochastic natural gradient method for one-shot neural architecture search,2019, InProceedings of the 36th International Conference on Machine Learning
 Mirror descent and nonlinear projected subgradient methods forconvex optimization,2003, Operations Research Letters
 Differentiable sparse coding,2008, In Advances in NeuralInformation Processing Systems
 The relaxation method of finding the common point of convex sets and itsapplication to the solution of problems in convex programming,1967, USSR Computational Mathematicsand Mathematical Physics
 ProxylessNAS: Direct neural architecture search on target taskand hardware,2019, In Proceedings of the 7th International Conference on Learning Representations
 MANAS: Multi-agent neural architecture search,2019, arXiv
 AutoAugment:Learning augmentation strategies from data,2019, In Proceedings of the IEEE Conference on Conferenceon Computer Vision and Pattern Recognition
 Improved regularization of convolutional neural networkswith cutout,2017, arXiv
 NAS-Bench-201: Extending the scope of reproducible neural architecturesearch,2020, In Proceedings of the 8th International Conference on Learning Representations
 Bilevelprogramming for hyperparameter optimization and meta-learning,2018, In Proceedings of the 35thInternational Conference on Machine Learning
 MobileNets: Efficient convolutional neural networks formobile vision applications,2017, arXiv
 Squeeze-and-excitation networks,2018, In Proceedings of the IEEEConference on Computer Vision and Pattern Recognition
 sharpDARTS: Faster and more accurate differen-tiable architecture search,2019, arXiv
 Adam: A method for stochastic optimization,2015, In Proceedings ofthe 3rd International Conference on Learning Representations
 Learning multiple layers of features from tiny images,2009, Technical report
 Prune and replace NAS,2019, In Proceedings of the IEEEInternational Conference on Machine Learning and Applications
 StacNAS: Towards stable andconsistent differentiable neural architecture search,2019, arXiv
 Random search and reproducibility for neural architecture search,2019, InProceedings of the Conference on Uncertainty in Artificial Intelligence
 DARTS+: Improved differentiable architecture search with early stopping,2019, arXiv
 Progressive neural architecture search,2018, In Proceedingsof the European Conference on Computer Vision
 DARTS: Differentiable architecture search,2019, InProceedings of the 7th International Conference on Learning Representations
 ShuffleNet V2: Practical guidelinesfor efficient CNN architecture design,2018, In Proceedings of the European Conference on ComputerVision
 XNAS:Neural architecture search with expert advice,2019, In Advances in Neural Information ProcessingSystems
 Proximal algorithms,2013, Foundations and Trends in Optimization
 Efficient neural architecturesearch via parameter sharing,2018, In Proceedings of the 35th International Conference on MachineLearning
 Searching for activation functions,2017, arXiv
 Regularized evolution for imageclassifier architecture search,2019, In Proceedings of the 33rd AAAI Conference on Artificial Intelligence
 Online learning and online convex optimization,2011, Foundations and Trends inMachine Learning
 ShakeDrop regularization,2018, arXiv
 CARS: Continuous evolution for efficient neural architecture search,2020, In Proceedings of theIEEE Conference on Computer Vision and Pattern Recognition
 Efficient neural architecture search viaproximal iterations,2020, In Proceedings of the 34th AAAI Conference on Artificial Intelligence
 Evaluating thesearch phase of neural architecture search,2020, In Proceedings of the 8th International Conference onLearning Representations
 NAS-Bench-1Shot1: Benchmarking and dissecting one-shot neural architecture search,2020, In Proceedings of the 8th International Conference on LearningRepresentations
 On the convergence rate of stochastic mirror descent for nonsmoothnonconvex optimization,2018, arXiv
 Multino-mial distribution learning for effective neural architecture search,2019, In Proceedings of the IEEEInternational Conference on Computer Vision
 Learning transferable architecturesfor scalable image recognition,2018, In Proceedings of the IEEE Conference on Computer Vision andPattern Recognition
 Positivity and homogeneity are trivial,2021, For the triangle inequality
