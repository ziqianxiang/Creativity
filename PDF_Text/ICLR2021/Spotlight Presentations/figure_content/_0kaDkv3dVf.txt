Figure 1: An illustration of our proposed HW-NAS-BenchDespite the promising performance achieved by SOTA HW-NAS, there exist paramount challengesthat limit the development of HW-NAS innovations. First, HW-NAS requires the collection ofhardware efficiency data corresponding to (all) the networks in the search space. To do so, cur-rent practice either pre-collects these data to construct a hardware-cost look-up table or adoptsdevice-specific hardware-cost estimators/models, both of which can be time-consuming to obtainand impose a barrier-to-entry to non-hardware experts. This is because it requires knowledge aboutdevice-specific compilation and properly setting up the hardware measurement pipeline to collecthardware-cost data. Second, similar to generic NAS, it can be notoriously difficult to benchmarkHW-NAS algorithms due to the required significant computational resources and the differences intheir (1) hardware devices, which are specific for HW-NAS, (2) adopted search spaces, and (3) hy-perparameters. Such a difficulty is even higher for HW-NAS considering the numerous choices ofhardware devices, each of which can favor very different network structures even under the sametarget hardware efficiency, as discussed in (Chu et al., 2020). While the number of floating-point op-erations (FLOPs) has been commonly used to estimate the hardware-cost, many works have pointedout that DNNs with fewer FLOPs are not necessarily faster or more efficient (Wu et al., 2019; 2018;Wang et al., 2019b). For example, NasNet-A (Zoph et al., 2018) has a comparable complexity interms of FLOPs as MobileNetV1 (Howard et al., 2017), yet can have a larger latency than the latterdue to NasNet-A (Zoph et al., 2018)’s adopted hardware-unfriendly structure.
Figure 2: Illustrating the hardware-cost collection pipeline applicable to various hardware devices.
Figure 3: Kendall Rank Correlation Coefficient between real-measured/estimated hardware-cost indifferent devices considering the NAS-Bench-201 search space.
Figure 4:	Kendall Rank Correlation Coefficient between real-measured/estimated hardware-cost indifferent devices considering the FBNet search space.
Figure 5:	Accuracy vs. hardware-cost on different devices considering NAS-Bench-201, wherepoints in red denote the architectures with the optimal trade-offs between “accuracy on ImageNet16-120 vs. latency measured on Edge GPU”, of which the architectures represent the ground truth ofHW-NAS targeting Edge GPUs.
Figure 6: Comparison between the approximated and measured hardware-cost on CIFAR-100(Top) and ImageNet (Bottom), where the red line indicates the fitting line for all the measured data,and R2 represents the square of the Pearson Correlation Coefficient (Benesty et al., 2009).
