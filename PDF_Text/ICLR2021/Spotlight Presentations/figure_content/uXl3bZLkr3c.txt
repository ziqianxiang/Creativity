Figure 1: Predictions with lower entropy havelower error rates on corrupted CIFAR-100-C.
Figure 2: More corruption causes more loss andentropy on CIFAR-100-C. Entropy can estimatethe degree of shift without training data or labels.
Figure 3:	Method overview. Tent does not alter training (a), but minimizes the entropy of predictionsduring testing (b) over a constrained modulation ∆, given the parameters θ and target data xt .
Figure 4:	Tent modulates features during testing by estimating normalization statistics μ, σ andoptimizing transformation parameters γ, β. Normalization and transformation apply channel-wisescales and shifts to the features. The statistics and parameters are updated on target data without useof source data. In practice, adapting γ, β is efficient because they make up <1% of model parameters.
Figure 5: Corruption benchmark on ImageNet-C:error for each type averaged over severity levels.
Figure 6: Tent reduces the entropy and loss. Weplot changes in entropy ∆H and loss ∆L for all ofCIFAR-100-C. Change in entropy rank-correlateswith change in loss: note the dark diagonal andthe rank correlation coefficient of 0.22.
Figure 7: Adapted features on CIFAR-100-Cwith Gaussian noise (front) and reference featureswithout corruption (back). Corruption shifts fea-tures away from the reference, but BN reducesthe shifts. Tent instead shifts features more, andcloser to an oracle that optimizes on target labels.
Figure 8: Examples of each corruption type in the image corruptions benchmark. While synthetic,this set of corruptions aims to represent natural factors of variation like noise, blur, weather, anddigital imaging effects. This figure is reproduced from Hendrycks & Dietterich (2019).
Figure 9: Adaptation for semantic segmentation with simulation-to-real shift from GTA Richteret al. (2017) to Cityscapes Cordts et al. (2016). Tent only uses the target data, and optimizes over asingle image as a dataset of pixel-wise predictions. This episodic optimization in effect fits a custommodel to each image of the target domain. In only 10 iterations our method suppresses noise (see thecompletion of the street segment, in purple) and recovers missing classes (see the motorcycle andrider, center).
Figure 10: Adapted features on CIFAR-100-C with Gaussian noise (front) and reference featureswithout corruption (back). Corruption shifts the source features from the reference. BN shifts thefeatures back to be more like the reference. Tent shifts features to be less like the reference, and morelike an oracle that optimizes on target labels.
