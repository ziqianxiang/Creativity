Figure 1: Mean and standard deviation of per-class weight norms kwy k2 over 5 runs for a ResNet-32under momentum and Adam optimisers. We use long-tailed (“LT”) versions of CIFAR-10 andCIFAR-100, and sort classes in descending order of frequency; the first class is 100× more likely toappear than the last class (see §6.2). Both optimisers yield comparable balanced error. However, theweight norms have incompatible trends: under momentum, the norms are strongly correlated withclass frequency, while with Adam, the norms are anti-correlated or independent of the class frequency.
Figure 2: Results on synthetic binary classification problem. Our logit adjusted loss tracks theBayes-optimal solution and separator (left & middle panel). Post-hoc logit adjustment matches theBayes performance with suitable scaling (right panel); however, any weight normalisation fails.
Figure 3:	Comparison of balanced error for post-hoc correction techniques when varying scalingparameter T (c.f. (3), (9)). Post-hoc logit adjustment consistently outperforms weight normalisation.
Figure 4:	Comparison of per-group errors for loss modification techniques. We construct three groupsof classes: “Many”, comprising those with at least 100 training examples; “Medium”, comprisingthose with at least 20 and at most 100 training examples; and “Few”, comprising those with at most20 training examples.
Figure 5: Comparison of link functions for various losses assuming π = 0.2, with γ = 1 (left) andY = 8 (right). The balanced loss uses ωy = ∏1-. The unequal margin loss uses δy = 1 ∙ log 1∏π. Thebalanced + margin loss uses δ-1 = 1∏∏, δ+1 = 1, ω+1 = ∏.
Figure 6:	Comparison of link functions for various losses assuming π = 0.2, with γ = 1 (left) andγ = 8 (right). The balanced loss uses ωy = -1. The unequal margin loss uses δy = 1 ∙ log 1-πy.
Figure 7: Comparison of conditional Bayes risk functions for various losses assuming π = 0.2, withγ = 1 (left) and Y = 8 (right). The balanced loss uses ωy = ∏1. The unequal margin loss usesδy = Y ∙ log 1∏πy. The first balanced + margin loss uses δ-1 = ∏, δ+1 = 1, ω+1 = ∏. The secondbalanced + margin loss uses δ-1 = 1∏∏, δ+1 = 1, ω+1 = ∏.
Figure 8: Per-class error rates of loss modification techniques. For (b) and (c), we aggregate theclasses into 10 groups. ERM displays a strong bias towards dominant classes (lower indices). Ourproposed logit adjusted softmax loss achieves significant gains on rare classes (higher indices).
Figure 9: Post-hoc adjustment on Step-100 profile, CIFAR-10-LT and CIFAR-100-LT. Logit adjust-ment outperforms weight normalisation with suitable tuning.
Figure 10: Results on synthetic data with varying imbalance ratio.
