Figure 1: (a) K-rank graph local filters. Notation as in Sec. 2.1, and specifically, u is node index, c is channel index,k is basis index, and K is number of basis. M is the tensor in the GNN linear mapping (1) (2), decomposed intolearnable local basis Bk combined by learnable coefficients ak. (b) The first two figures shows the good propertyof landmarks for being invariant to pose and camera viewpoint changes. The third figure illustrates the graph webuilt on facial landmarks.
Figure 2: Plots: (a) Local graph Laplacian Lu := D-A on a neighborhood around node u. (b) Plots of the Dirichleteigenvectors on the local graph. The first Dirichlet eigenvector does not change sign on Nu and is envelope-like.
Figure 3: Up/down-wind classification. Plots: (a) Example data from two classes. (b) Learned shared basis onthe graph neighborhood of 3, corresponding to the last row in the table. (Table) Test accuracy by MPNN (Gilmeret al., 2017), WLN (Morris et al., 2019), ChebNet up to L=30 and L3Net K=1 and 3, as well as GAT with differentheads. Last row order 1 with star: L3Net with shared basis B(âˆ™,u) across all locations u.
Figure 4: (Plot) Icosahedral spherical meshes at level 2 and 1. (Table) Testing accuracies of sphere MNISTunder different mesh settings, (l1; l2; l3) stands for the mesh level used in each GNN layer. L3Net uses K=4, andneighborhood order (1;1;2;3). S2CNN (Cohen et al., 2018) on mesh (4;3;2) has accuracy 96.0.
