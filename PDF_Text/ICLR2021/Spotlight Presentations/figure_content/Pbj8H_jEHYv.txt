Figure 1: (Titles: cin â†’ cout). Our layer remains orthogonal in practice even for large convolutions(d, e), and is norm-preserving even when cout > cin (b, c); it is nonexpansive when cin > cout (a).
Figure 2: The provable robustness vs. clean accuracy tradeoff enabled by scaling the Lipschitzupper-bound for KWLarge.
Figure 3: The robustness/accuracy tradeoff from changing the Lipschitz upper bound for ResNet9.
Figure 4: Robustness vs. accuracy tradeoff from changing the Lipschitz upper bound for KWLarge.
Figure 5: Effect of varying 0 for Lipschitz margin training for KWLarge.
Figure 6: Our Cayley layer is particulaly efficient for inputs with small spatial dimension (widthand height, i.e., n) (see (a), (c)), large kernel size k (see (e)), and cases where the number of inputand output channels are not equal (cin 6= cout) (see (f)). For very large spatial size (image width andheight) (see (d)), or the combination of relatively large spatial size and many channels (see (b)),BCOP (Li et al., 2019) tends to be more efficient. Since convolutional layers in neural networks tendto decrease the spatial dimensionality while increasing the number of channels, and also often haveunequal numbers of input and output channels, our Cayley layer is often more efficient in practice.
