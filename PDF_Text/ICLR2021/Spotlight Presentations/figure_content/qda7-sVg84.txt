Figure 1: Jumping task: The agent (white block),learning from pixels, needs to jump over an obsta-cle (grey square). The challenge is to generalize tounseen obstacle positions and floor heights in testtasks using a small number of training tasks. Weshow the agent’s trajectories using faded blocks.
Figure 2: Jumping Task: Visualization of average performance of PSEs with data augmentation across differentconfigurations. We plot the median performance across 100 runs. Each tile in the grid represents a different task(obstacle position/floor height combination). For each grid configuration, the height varies along the y-axis (11heights) while the obstacle position varies along the x-axis (26 locations). The red letter > indicates the trainingtasks. Random grid depicts only one instance, each run consisted of a different test/train split. Beige tiles aretasks PSEs solved while black tiles are tasks PSEs did not solve when used with data augmentation. Theseresults were chosen across all the 100 runs to demonstrate what the average reported performance looks like.
Figure 3: Embedding visualization. (a) Optimal trajectories on original jumping task (visualized as colouredblocks) with different obstacle positions. We visualize the hidden representations using UMAP, where the colorof points indicate the tasks of the corresponding observations. Points with the same number label correspond tosame distance of the agent from the obstacle, the underlying optimal invariant feature across tasks.
Figure 4: Percentage (%) of red obstacle testtasks solved when trained, jointly with red andgreen obstacles, on the “wide” grid. We reportthe mean across 100 runs. Error bars show 99%confidence interval for the mean.
Figure 5: % of test tasks solvedusing PSEs computed using -suboptimal policies on the “wide”grid. We report the mean across 100runs. Error bars show one standardIn this section, we exhibit that PSM ignores spurious information deviation.
Figure 6: LQR generalization: Absolute test er-ror in LQR cost relative to the oracle (which hasaccess to true state), of various methods trainedwith nd distractors on 2 training environments.
