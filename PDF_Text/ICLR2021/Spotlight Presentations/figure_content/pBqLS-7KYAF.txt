Figure 1: Visual representations of different functions f defined in (3)-(5) (left) and their corre-sponding parameters a1 and ν (right) (a2 = 0 for each of these fs) defined in Assumption 1.
Figure 2: (Left) Histogram of eigenvalues of K (blue) versus the limiting spectrum and spikes(red). (Right) Eigenvectors of the largest (top) and second largest (bottom) eigenvalues of K(blue), versus the rescaled class label av/√n (red, from Corollary 2). f (t) = sin(t) - 3 cos(t) +3∕√e, P = 800, n = 6400, μ = 1.1 ∙ 1p∕√p, V = [-1n/2； ln/2] on Student-t data with K = 5.
Figure 3: (Left) Empirical alignment ∣Vτv∣2∕n (green crosses) and misclassification rate (purplecircles) in markers versus their limiting behaviors in lines, for f(t) = sign(t), as a function ofSNR ρ. (Right) Misclassification rate as a function of the truncation thresholds S of sparse f1(blue crosses) and binary f3 (red circles) with P = 4. Here, P = 512, n = 256, μ a N(0, Ip),v = [-1n/2; 1n/2] on Gaussian data. The results are obtained by averaging over 250 runs.
Figure 4: Clustering performance (left, a zoom-in in middle) and storage size (MB) (right) of f1(blue), f2 with M = 2 (green), f3 (red), and linear f(t) = t (black), versus the truncation thresholds, for SNR ρ = 2, c = 1/2 and n = 103, with 64 bits per entry for non-quantized matrices.
Figure 5: (Left) Proportion of nonzero entries with uniform versus selective sparsification f1 andtheir ratio r(s), as a function of the truncation threshold s. (Right) Comparison of 1%, 10% clas-sification error and phase transition (i.e., 50% error) curves between subsampling (green), uniform(blue) and selective sparsification f1 (red), as a function of sparsity level ε and SNR ρ, for c = 2.
Figure 6:	Performance of f1 (blue), f2 with M = 3 (green) and f3 (red) of the same storage size,versus SNR for c = 4 (left) and versus c for SNR ρ = 4 (middle). (Right) Optimal threshold sopt(green) and (ν∕a1)min (purple) of f2 versus M. Curves for linear f (t) = t are displayed in black.
Figure 7:	Clustering performance of sparse f1 and binary f3 (left and middle), proportion ofnonzero entries and computational time of the top eigenvector for f3 (right), as a function of thetruncation threshold s on the MNIST dataset: digits (0, 1) (left) and (5, 6) (middle and right) withn = 2 048 and performance of the linear function in black. Results averaged over 100 runs.
Figure 8: Functional inverse x(m) for m ∈ R\{{—c∕αι} ∪ {0}}, With f (t) = max(t, 0) — 1/λ∕2π,for c = 2 (above, with two edges) and c = 1/10 (bottom, with four edges). The support of ω canbe read on the vertical axes and the values ofx such that x0(m) = 0 are marked in green.
Figure 9: Eigenvalues of K with μ = 0 (blue) versus the limiting laws in Theorem 1 andCorollary 3 (red) for P = 3 200, n = 1 600 (left) and P = 400, n = 4 000 (right), withf (t) = max(t, 0) — 1/λ∕2∏ and Gaussian data. The values of X such that χ0(m) = 0 in Figure 8 aremarked in green.
Figure 10: Eigenvalues of K with μ = 0 (blue) versus the limiting laws in Theorem 1 andCorollary 3 (red) for Gaussian data, P = 1024, n = 512 and f(t) = ait + a2(t2 — 1)∕√2 witha1 = 1, a2 = 0 (left), a1 = 1, a2 = 1/2 (middle), and a1 = 0, a2 = 1 (right).
Figure 11: Eigenvalues of K with μ = 0 (blue) versus the limiting laws in Theorem 1 andCorollary 3 (red) for Gaussian data,P = 1024, n = 512 and f(t) = t ∙ 1∣t∣>√¾ with S = 0.1 (left),s = .75 (middle), and S = 1.5 (right).
Figure 12: Eigenvalues of K with μ = 0 (blue) versus the limiting laws and spikes in Theo-rem 1 and Corollary 1 (red) for Student-t (with 7 degrees of freedom, left), Gaussian (middle) andRademacher distribution (right), P = 512, n = 2 048, f (t) = max(t, 0) 一 1/√2π. Emphasis onthe non-informative spikes at different locations: at -2.10 for Student-t and -1.77 for Gaussian.
Figure 13:	Eigenvalues of K with μ = 0 (blue) versus the limiting laws and spikes in Corol-lary 3 and 1 (red) for P = 400, n = 6 000, with f(t) = max(t, 0) - 1/√2π and Gaussian data.
Figure 14:	Clustering performance (left), proportion of nonzero entries, and computational time ofthe top eigenvector (right, in markers) of sparse f1 and quantized f2 with M = 2, as a function ofthe truncation threshold s on the MNIST dataset: digits (0, 1) (left) and (5, 6) (middle and right)with n = 2 048 and performance of the linear function in black. Results averaged over 100 runs.
Figure 15: Clustering performance of sparse f1, quantized f2 (with M = 2) and binary f3 asa function of the truncation threshold s on: (left) Kuzushiji-MNIST class 3 versus 4, (middle)Fashion-MNIST class 0 versus 9, and (right) Kannada-MNIST class 4 versus 8, for n = 2 048 andperformance of the linear function in black. Results averaged over 100 runs.
Figure 16: Clustering performance of sparse f1, quantized f2 (with M = 2) and binary f3 asa function of the truncation threshold s on GoogLeNet features of the ImageNet datasets: (left)class “pizza” versus “daisy” and (right) class “hamburger” versus “coffee”, for n = 1 024 andperformance of the linear function in black. Results averaged over 10 runs.
