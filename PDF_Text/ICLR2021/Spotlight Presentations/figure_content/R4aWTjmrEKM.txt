Figure 1: Mixed-strategy opponent targeted in PSRO (top)and corresponding Q-Mixed opponent (bottom). (Left)shows the opponent policy Q-values, and (right) shows theresulting opponent policies and their BRs. In Mixed Oppo-nents, the BR expands the strategy space to include the Nashequilibrium of RPS (green dot), but in PSRO it does not.
Figure 2: PSRO compared against Mixed-Oracles on the Gathering-Small game. SumRegret overΠPSRO ∪ ΠEVAL is compared over PSRO epochs (left) and training timesteps (right).
Figure 3: PSRO compared against Mixed-Oracles on the Leduc-Poker game.
Figure 4: PSRO compared against Mixed-Opponents on the Gathering-Small game. SumRegret overΠPSRO ∪ ΠEVAL is compared over PSRO epochs (left) and training timesteps (right).
Figure 5: PSRO compared against Mixed-Opponents on the Leduc-Poker game.
Figure 6: Experiments on extension beyond two players and using shared hyperparameters.
