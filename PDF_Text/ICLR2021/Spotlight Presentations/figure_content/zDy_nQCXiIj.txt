Figure 1: Steerability without optimization. We determine meaningful trajectories in the latent space of a pre-trained GAN without using optimization.
Figure 2: User-prescribed spatial manipulations. We calculate directions in latent space whose effect on the tensor at the output of the first layer, is similar to applying transformation P on that tensor. 
Figure 3: Walks corresponding to geometric transformations. We compare our zoom and shift trajectories to those of the GAN steerability work (Jahanian et al., 2020). For linear paths, the methods are qualitatively similar, whereas for nonlinear walks, our methods are advantageous.
Figure 4: Quantitative comparison with (Jahanian et al., 2020). We show the probability densities of object areas and locations after 2 (top) and 5 (bottom) steps of walks for BigGAN-128. The step- size is the same for the linear walks, and matches the size of the first step of the nonlinear walk.

