Figure 1: Our image completion results w.r.t. different masks. Our method successfully bridgesdifferently conditioned situations, from small-scale inpainting to large-scale completion (left to right).
Figure 2: Illustration from modulation to co-modulation: (a) unconditional modulated generator;(b) vanilla image-conditional generator; (c) conditional modulated generator; and (d) co-modulatedgenerator. y, z represent the conditional input and the latent vector respectively; E , D, M representthe conditional encoder, the generative decoder, and the mapping network, respectively.
Figure 3: Robustness to sampling size. Dashed convergence lines are measured using 50k samples.
Figure 5: Effectiveness of capturing subtle dif-ferences. All metrics are measured using 10ksamples. P-IDS effectively reflects the amountof noise; FID and KID fail to respond within 29noisy pixels. Results are averaged over 5 runs;error bars indicate standard deviations.
Figure 4: Kernel Inception Distance (KID)still suffers from large variance. Although itachieves unbiased estimates, the huge varianceeven makes them often negative and hardly dis-tinguishable. Results are averaged over 5 runs;error bars indicate standard deviations.
Figure 6: User study results, P-IDS and FID plots of DeepFillv2 (retrained) and ours w.r.t. differentmasked ratios. P-IDS and FID are averaged over 5 runs; error bars indicate standard deviations.
Figure 7: Qualitative examples of state-of-the-art methods on large scale image completion:PatchMatch (Barnes et al., 2009), DeepFillv2 (Yu et al., 2019), and ours. The original images aresampled at 512×512 resolution from the FFHQ dataset (Karras et al., 2019a) within a 10k validationsplit (top) and the Places2 validation set (Zhou et al., 2017) (bottom). We refer the readers to theappendix for extensive qualitative examples.
Figure 8: The inherent stochasticity. Co-modulated GANs can easily trade-off betweenquality and diversity by tuning the truncation ψ .
Figure 9: Qualitative ablation study amongVanilla, conditional modulation (C-Mod), and ourco-modulation (Co-Mod) as in Figs. 2(b) to 2(d).
Figure 10: Co-modulation dominates condi-tional modulation (C-Mod) at all masked ratios,especially when the masked ratio becomes large.
Figure 11: Trade-off curve of our method be-tween quality (FID) and diversity (LPIPS) on theEdges2Handbags dataset.
Figure 12: Random samples of free-form masks.
Figure 13: Samples on Edges2Handbags.
Figure 15: Qualitative comparison between SPADE (Park et al., 2019) and ours for image-to-imagetranslation on the COCO-Stuff validation set (Caesar et al., 2018) (labels to photos).
Figure 16: Our image completion results w.r.t. different masks. Our method successfully bridgesdifferently conditioned situations, from small-scale inpainting to large-scale completion (left to right).
Figure 17: Our image completion results w.r.t. different masks. Our method successfully bridgesdifferently conditioned situations, from small-scale inpainting to large-scale completion (left to right).
Figure 18: Qualitative examples for image completion at 1024×1024 resolution. The original imagesare sampled from the FFHQ dataset (Karras et al., 2019a) within a 10k validation split.
Figure 19: Qualitative examples for image completion at 1024×1024 resolution. The original imagesare sampled from the FFHQ dataset (Karras et al., 2019a) within a 10k validation split.
Figure 20: Qualitative examples for image completion among PatchMatch (Barnes et al., 2009),DeepFillv2 (Yu et al., 2019), and ours. The original images are sampled at 512×512 resolution fromthe FFHQ dataset (Karras et al., 2019a) within a 10k validation split.
Figure 21: Qualitative examples for image completion among PatchMatch (Barnes et al., 2009),DeepFillv2 (Yu et al., 2019), and ours. The original images are sampled at 512×512 resolution fromthe FFHQ dataset (Karras et al., 2019a) within a 10k validation split.
Figure 22: Qualitative examples for image completion among PatchMatch (Barnes et al., 2009),DeepFillv2 (Yu et al., 2019), and ours. The original images are sampled at 512×512 resolution fromthe Places2 validation set (Zhou et al., 2017).
Figure 23: Qualitative examples for image completion among PatchMatch (Barnes et al., 2009),DeepFillv2 (Yu et al., 2019), and ours. The original images are sampled at 512×512 resolution fromthe Places2 validation set (Zhou et al., 2017).
