Figure 1: An illustration of the DASALC. FC is fully connected layer, ReLU is ReLU activation,and BN indicates batch normalization. Log1p Transform is applied when applicable. Softmax lossis short for softmax output with cross-entropy loss.
