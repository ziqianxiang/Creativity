Published as a conference paper at ICLR 2021
MARS: Markov Molecular Sampling for
Multi-objective Drug Discovery
Yutong Xie松，Chence Shit4, Hao Zhout*, YuWei Yangt, Weinan Zhangr Yong Yur Lei Lit*
^ByteDance AI Lab, Shanghai, China
University of Michigan, Ann Arbor, MI, USA
4Montreal Institute of Learning Algorithms, Montreal, Canada
^Department of Computer Science and Engineering, Shanghai Jiao Tong University, China
Ab stract
Searching for novel molecules with desired chemical properties is crucial in drug
discovery. Existing work focuses on developing neural models to generate ei-
ther molecular sequences or chemical graphs. However, it remains a big chal-
lenge to find novel and diverse compounds satisfying several properties. In this
paper, we propose MARS, a method for multi-objective drug molecule discov-
ery. MARS is based on the idea of generating the chemical candidates by iter-
atively editing fragments of molecular graphs. To search for high-quality candi-
dates, it employs Markov chain Monte Carlo sampling (MCMC) on molecules
with an annealing scheme and an adaptive proposal. To further improve sam-
ple efficiency, MARS uses a graph neural network (GNN) to represent and select
candidate edits, where the GNN is trained on-the-fly with samples from MCMC.
Experiments show that MARS achieves state-of-the-art performance in various
multi-objective settings where molecular bio-activity, drug-likeness, and synthe-
sizability are considered. Remarkably, in the most challenging setting where all
four objectives are simultaneously optimized, our approach outperforms previ-
ous methods significantly in comprehensive evaluations. The code is available at
https://github.com/yutxie/mars.
1	Introduction
Drug discovery aims to find chemical compounds with desired target properties, such as high drug-
likeness (Bickerton et al., 2012, QED). The problem is also referred to as molecular design, molec-
ular generation, or molecular search. The space of drug-like chemicals is enormous, approximate
1033 for realistic drugs that could ever be synthesized (Polishchuk et al., 2013). Therefore it is
very challenging to search for high-quality molecules from such a vast space — enumeration would
take almost forever. For a particular disease, finding the right candidates targeting specific proteins
further complicates the problem.
Instead of enumerating or searching from the immense chemical space, recent work utilizes deep
generative models to generate candidate molecules directly (Schwalbe-Koda & Gomez-Bombarelli,
2020). However, most prior work focuses on generating molecules concerning a single property
such as drug-likeness (QED) or octanol-water partition coefficient (logP) (Jin et al., 2018; You et al.,
2018; Popova et al., 2019; Shi et al., 2020; Zang & Wang, 2020). While in practical settings, typical
drug discovery requires consideration of multiple properties jointly (Nicolaou et al., 2012). For
example, to find drug-like molecules that are easy to synthesize and exhibit high biological activity
against the target protein. Naturally, multi-objective molecule design is much more challenging than
the single-objective scenario (Jin et al., 2020).
This paper studies the problem of multi-objective molecule design for drug discovery. An ideal solu-
tion should be efficient and meet the following criteria. C1: It should satisfy multiple properties with
high scores; C2: It should produce novel and diverse molecules; C3: Its generation process does not
*Work was done while Yutong Xie and Chence Shi were research interns at ByteDance. Corresponding to:
zhouhao.nlp@bytedance.com and lileilab@bytedance.com.
1
Published as a conference paper at ICLR 2021
rely on either expert annotated or wet experimental data collected from a biochemistry lab (since it
requires tremendous effort and hard to obtain). Existing molecule generation approaches are mainly
designed for the single objective setting, and they could not meet all criteria in the setting of mul-
tiple objectives. These methods belong to four categories: a) generating candidates from a learned
continuous latent space (Gomez-Bombarelli et al., 2018; Jin et al., 2018), b) through reinforcement
learning (You et al., 2018), c) using an encoder-decoder translation approach (Jin et al., 2019), or
d) optimizing molecular properties through genetic algorithms (Nigam et al., 2020). Current state-
of-the-art multi-objective molecular generation is a rationale-based method (Jin et al., 2020). In
this approach, the authors propose to build molecules by composing multiple extracted rationales,
and the model can generate compounds that are simultaneously active to multiple biological targets.
However, such an approach will result in quite complex molecules when we have many objectives.
This is because different objectives correspond to different rationales, and including all these ra-
tionales could lead to large molecules, which may be less drug-like and hard to be synthesized
practically.
In this paper, we propose MArkov moleculaR Sampling (MARS), a simple yet flexible method
for drug discovery. The basic idea is to start from a seed molecule and keep generating candidate
molecules by modifying fragments of molecular graphs from previous steps. It meets all the criteria
C1-3. In MARS, the molecular design is formulated as an iterative editing procedure with its total
objective consisting of multiple property scores (C1). MARS employs the annealed Markov chain
Monte Carlo sampling method to search for optimal chemical compounds, which allows for the
exploration of chemicals with novel and different fragments (C2). The proposal to modify molecular
fragments is represented using graph neural networks (GNNs), whose parameters are adaptively
learned. We used message passing neural networks (MPNNs) in practice (Gilmer et al., 2017), but
other GNNs can fit the framework as well. Furthermore, MARS utilizes the sample paths generated
on-the-fly to train the proposal network adaptively. Therefore, it does not rely on external annotated
data (C3). With such an adaptive learnable proposal, it keeps improving the generation quality
throughout the process.
We evaluate MARS and four other baselines, one latest method for each of the four method cate-
gories. The benchmark includes a variety of multi-objective generation settings. Experiments show
that our proposed MARS achieves state-of-the-art performance on five out of six tasks in terms of
a comprehensive evaluation consisting of the success rate, novelty, and diversity of the generated
molecules. Notably, in the most challenging setting where four objectives - bio-activities to two
different targets, drug-likeness, and synthesizability - are simultaneously considered, our method
achieves the state-of-the-art result and outperforms existing methods by 77% in the comprehensive
evaluation.
Our contributions are as follows:
•	We present MARS, a generic formulation of molecular design using Markov sampling,
which can easily accommodate multiple objectives.
•	We develop an adaptive fragment-editing proposal based on GNN that is learnable on the
fly with only samples self-generated and efficient in exploring the chemical space.
•	Experiments verifies our proposed MARS framework can find novel and diverse bioactive
molecules that are both drug-like and highly synthesizable.
2	Related Work
Recent years have witnessed the success of applying deep generative models and molecular graph
representation learning in drug discovery (Schwalbe-Koda & Gomez-Bombarelli, 2020; Guo &
Zhao, 2020). Existing approaches for molecular property optimization can be grouped into four
categories, including generation with a) Bayesian inference, b) reinforcement learning, c) encoder-
decoder translation models, and d) evolutionary and genetic algorithms. The first category is learning
continuous latent spaces for molecular sequences or graphs and generating from such spaces using
Bayesian optimization (BO) (GOmez-BOmbarelli et 京.，2018; Jin et al., 2018; Winter et al., 2019).
These methods rely heavily on the quality of latent representations, which imposes huge challenges
to the encoders when there are multiple properties to consider.
Unlike the first class, other work uses reinforcement learning (RL) to optimize desired objectives
directly in the explicit chemical space (De Cao & Kipf, 2018; Popova et al., 2018; You et al., 2018;
2
Published as a conference paper at ICLR 2021
Popova et al., 2019; Shi et al., 2020). However, the models are usually hard to train due to the high
variance of RL.
The third category directly trains a translation model that maps from an input molecule to a high-
quality output molecule (Jin et al., 2019; 2020). Although simple, such methods require many
high-quality labeled data, making them impractical in scenarios where the data is limited.
The last category of methods are evolutionary algorithms (EAs) and genetic algorithms (GAs) to
explore large chemical space with certain property (Nicolaou et al., 2012; Devi et al., 2015; Jensen,
2019; Ahn et al., 2020). In Nigam et al. (2020), the authors propose to augment GA by adding an
adversarial loss into the fitness evaluation to increase the diversity, and the augmented GA outper-
forms all other generative models in optimizing logP. Though flexible and straightforward, to make
the search process efficient enough, most GA and EA methods require domain experts to design
molecular mutation and crossover rules, which could be non-trivial to obtain.
Besides single property optimization, there is recent work to address the multi-objective molecule
generation problem. For example, Li et al. (2018) proposes to use a conditional generative model to
incorporate several objectives flexibly, while Lim et al. (2020) leverages molecular scaffolds to con-
trol the properties of generated molecules better. Among them, the current state-of-the-art approach
is a rationale-based method proposed by Jin et al. (2020). In this method, the authors propose to
build molecules by assembling extracted rationales. Despite its great success in generating com-
pounds simultaneously active to multiple biological targets, the combination of rationales might
hinder the synthesizability and drug-likeness of produced molecules, as they tend to be large as the
number of objectives grows. In contrast, our MARS framework turns the generation problem into a
sampling procedure, which serves as an alternative way compared with deep generative models, and
can efficiently discover bio-active molecules that are both drug-like and highly synthesizable.
Remotely related is recent work to generate molecules through sampling. Seff et al. (2019) defines
a Gibbs sampling procedure, in which the Markov chain alternates between randomly corrupting
the molecules and recovering the corrupted ones with a learned reconstruction model. However,
this method mainly focuses on generating molecules that follow the observed data distribution and
cannot be directly tailored for property optimization. Different from this work, MARS is built
upon the general MCMC sampling framework, which allows further enhancement with adaptive
proposal learning to edit molecular graphs efficiently. Actually, generating instances from a discrete
space with MCMC sampling methods is previously employed in various other applications, e.g.,
generating natural language sentences under various constraints (Miao et al., 2019; Zhang et al.,
2019; Liu et al., 2020; Zhang et al., 2020).
3	Proposed MARS Approach
In this section, we present the MArkov moleculaR Sampling method (MARS) for multi-objective
molecular design. We define a Markov chain over the explicit molecular graph space and design a
kernel to navigate high probable candidates with acceptance and rejection.
3.1	Sampling from the Molecular Space
Our proposed MARS framework aims at sampling molecules with desired properties from the chem-
ical space. Specifically, given K properties of interest, the desired molecular distribution can be
formulated as a combination of all objectives:
π(x)
Sl(x) ◦ S2(x) ◦ S3(x) ◦…。SK (x)
、---------------------V---------------------}
desired properties
(1)
where x is a molecule in the molecular space X. π(x) is an unnormalized distribution over molecules
integrating the desired properties. sk(x) is a scoring function for the k-th property and the “◦”
operator stands for a combination of scores (e.g., summation or multiplication). In practical drug
discovery, these terms could be related to the biological activity, drug-likeness, and synthesizability
of molecules (Nicolaou et al., 2012). This framework allows flexible configuration according to
various concrete applications. However, as the number of objectives grows, the joint distribution
π(x) will become more complex and intractable, making the sampling non-trivial.
3
Published as a conference paper at ICLR 2021
In MARS, we propose to sample molecules from the desired distribution Eq. 1 using Markov chain
Monte Carlo (MCMC) methods (Andrieu et al., 2003). Given a desired molecular distribution π(x)
as the unnormalized target distribution, we define a Markov chain on the explicit chemical space X
(i.e., each state of the Markov chain is a particular molecule) and introduce a proposal distribution
q(x0 | x) to perform state transitions.
x ,~q(x,∣x (I))
Propose
CN	NH2
N
x'~q(x IX ⑴)
Propose
F
R Reject
Λ(x ⑴,x，)
(d)
Initialize
H3C	CH3
- °)
(a)
* Accept
(A(Xgι),x') x(t) = x'
(C)
Figure 1: The framework of MARS. During the sampling process: (a) starting from an arbitrary initial molecule
x(0) in the molecular space X, (b) sampling a candidate molecule x0 ∈ X from the proposal distribution
q(x0 | x(t-1)) at each step, and (c/d) the candidate x0 is either accepted or rejected according to the acceptance
rate A(x(t-1), x0) ∈ [0, 1]. By repeating this process, we can generate a sequence of molecules {x(t)}t∞=0.
Specifically, as shown in Figure 1, the sampling procedure of MARS starts from an initial molecule
x(0) ∈ X . At each time step t, a molecule candidate x0 ∈ X will be sampled from the proposal
distribution q(x0 | x(t-1)), where x(t-1) denotes the molecule at time step t - 1. Then the proposed
candidate x0 could be either accepted x(t) = x0 or rejected x(t) = x(t-1) according to the acceptance
rate A(x(t-1) , x0) ∈ [0, 1] controlled by the target distribution π(x). By repeating this process, a
sequence of molecules {x(t) }t∞=0 can be generated. Such sequence of molecules will converge to
the target distribution π(x) if the proposal distribution and the acceptance mechanism are configured
properly.
The acceptance rate is calculated as follow:
A(x, x0) = min 1,
πα(x0)q(x∣x0)
πα (x)q(x0 |x)
(2)
where α is a coefficient that varies in different instantiations of MCMC algorithms. Here
to find molecules that globally maximize the target distribution, we employ an annealing
scheme (Laarhoven & Aarts, 1987) where α = 1/T and T is a temperature controlled by a
cooling schedule. In addition to this, other instantiations such as Metropolis-Hastings (MH) al-
gorithm (Metropolis et al., 1953) where α = 1 are also feasible under our general framework.
As for the proposal distribution q(x0 | x), it largely affects the sampling performance and should
be designed elaborately. In general, it is crucial that the proposal distribution q(x0 | x) and the
target distribution π(x0) are as close as possible to ensure high sampling efficiency. So we propose
using a proposal distribution qθ (x0 | x) with learnable parameters to capture the desired molecular
properties and develop a strategy to train the proposal throughout the sampling process adaptively.
The details will be described in the next section.
3.2	Adaptive Molecular Graph Editing Proposal
In this section we will examine in detail our proposed adaptive proposal distribution qθ (x0 | x). A
molecule is represented as a graph whose nodes are heavy atoms and edges are chemical bonds.
The proposal distribution is defined over molecular graph editing actions. We use the message
passing neural network (MPNN) to represent the proposal. Alternative parameterization schemes
such as other graph neural networks are also possible. To sample molecules with desired properties
effectively and efficiently, we also design a self-training strategy to learn the proposal MPNN during
sampling in an adaptive manner.
Molecular graph editing actions. To transform a molecule x into another molecule x0, we consider
two sets of graph editing actions, i.e., fragment adding and deleting. These actions are inspired by
fragment-based drug design (FBDD) methodology, whose success in drug discovery has been proved
in past decades (Kumar et al., 2012). In MARS, we define fragments as connected components in
4
Published as a conference paper at ICLR 2021
molecules separated by single bonds. To reduce the complexity of editing actions, we only consider
fragments with a single attachment position. Moreover, we also define a fragment vocabulary that
contains finitely many fragments, and only fragments in the vocabulary are allowed to be added onto
a molecule. Examples for fragment adding and deleting actions are shown in Figure 2.
Figure 2: Left: Examples of molecular fragments and a fragment vocabulary. Red dashed lines represents
cuttable bonds to extract fragments. Right: Examples of molecular graph editing actions.
Specifically, given a molecule x with n atoms and m bonds, we choose to add or delete a fragment
onto or from this molecule randomly with probability 1 for each set of actions. For the adding action,
suppose we have a probability distribution over atoms Padd(x, u) and a probability distribution over
fragments in the vocabulary Pfrag (x, u, k). Here u ∈ [n] is an indicator of the atom in x to which the
fragment is adding to and k ∈ [V] is an indicator of fragments in the vocabulary of size V . We can
compute the proposal distribution as follows:
q(χ0∣x) = 2 ∙ Padd(x,u) ∙ Pfrag(X,u,k)
(3)
where x0 is the molecule obtained by adding the k-th fragment onto the atom u in molecule x.
As for the deleting action, suppose we have a probability distribution over bonds1 Pdel(x, b) where
b ∈ [2m] is an indicator of bonds in x. We can compute the proposal distribution as follow:
q(x0∣x) = 2 ∙ Pdel (x, b)
(4)
where x0 is the molecule obtained by removing bond b and the attached fragment from molecule x.
Parameterizing with MPNNs. To better model the molecular graph editing actions, we propose
to use MPNNs to suggest the probability distributions (padd, pfrag, pdel) = Mθ (x) where Mθ is a
MPNN model specified by parameters θ, which has been proven powerful to predict chemical prop-
erties with molecular graphs (Gilmer et al., 2017). Given a molecule x, we compute the probability
distributions as follow:
hnuode = MPNN(x)u ∈ Rd	(5)
hebdge =Concat(hnvode,hnwode) ∈ R2d	(6)
Padd(x) =Softmax({MLPnode(hnuode))}un=1) ∈ [0, 1]n	(7)
Pfrag(x,u) = Softmax(MLP0node(hnuode)) ∈ [0, 1]|V |	(8)
Pdel(x) = Softmax({MLPedge(hebdge))}b2=m1) ∈ [0, 1]2m	(9)
where u is an atom indicators, {hnuode}nu=1 are node hidden representations, v, w are atoms connected
with bond b, {hebdge}b2=m1 are edge hidden representations, and MLPnode , MLP0node , MLPedge are multi-
layer peceptrons (MLPs), similar to Hu et al. (2020).
Adaptive self-training. To capture the desired properties and improve the sampling effective-
ness, we can train the editing model to increase the probability of suggesting high-quality candidate
1Molecular bonds are treated as directional to specify the fragments to drop from molecules.
5
Published as a conference paper at ICLR 2021
1
2
3
4
5
6
7
8
9
10
11
12
13
Algorithm 1: MARS
Set N initial molecules {xi(0)}iN=1 and initialize the molecular graph editing model Mθ
Create an empty editing model training dataset D = {}
for t = 1, 2, . . . do
for i = 1, 2, . . . , N do
Compute probability distributions (padd, pfrag, pdel) = Mθ (xi(t-1)) as Equations 7-9
Sample a candidate molecule x0 from the proposal distribution q(x0 | xi(t-1) ) defined with
probability distributions padd , pfrag , pdel as Equations 3-4
if u < A(x(t-1), x0) where U 〜U[o,i] then
I Accept the candidate molecule x(it) = x0
else
L Refuse the candidate molecule Xit) = χit-1)
if The candidate improves the objectives, i.e. π(x0) > π(xi(t-1) ) then
[ Adding the editing record (x(t-1), x0) into the dataset D
θnew 4——arg max log Me(D)
molecules. Here we propose to train the model on-the-fly during the sampling process in an adaptive
manner where the training data is collected from the sampling paths. By doing so, we can bypass
the difficulty of lacking training instances that satisfy all property constraints. Mainly, we collect
molecule candidates that improve our desired objectives and train the model Mθ in a maximum
likelihood estimation (MLE) manner (i.e., to maximize the probability of producing the collected
candidates). The overall MARS is described in Algorithm 1.
Discussion on convergence. Compared with standard MCMC algorithms, MARS still falls in
the Metropolis-Hastings algorithm but with an annealing scheme and an adaptive proposal, which
results in inhomogeneous transition kernels. The convergence of adaptive MCMC is discussed
in Rosenthal (2011). According to the diminishing adaptation condition, we can ensure conver-
gence by making the difference of proposals in consecutive iterations diminish to zero. MARS can
satisfy this condition by using an optimizer whose learning rate will shrink to zero eventually (e.g.,
Adam). Annealed MCMC is to find samples maximizing the target probability. The convergence of
annealed MCMC is discussed in Andrieu et al. (2003).
4	Experiments
4.1	Experiment Setup
Biological objectives. Following Jin et al. (2020), we consider the following inhibition scores
against two Alzheimer-related target proteins as the biological activity objectives. The score is given
by a random forest model 2 that predicts based on Morgan fingerprint features of a molecule (Rogers
& Hahn, 2010).
•	GSK3β: Inhibition against glycogen synthase kinase-3β.
•	JNK3: Inhibition against c-Jun N-terminal kinase-3.
Non-biological objectives. Following Jin et al. (2020), we adopt QED (Bickerton et al., 2012)
and synthetic accessibility (SA) (Ertl & Schuffenhauer, 2009) to quantify the drug-likeness and
synthesizability. We rescale the SA score (initially between 10 and 1) into [0, 1] such that molecules
with higher scores are more synthesizable.
Multi-objective generation setting. To evaluate the effectiveness of the proposed method for multi-
objective drug design, we also consider the following more challenging objective combinations:
2https://github.com/wengong- jin/multiobj-rationale
6
Published as a conference paper at ICLR 2021
•	GSK3β+JNK3: Jointly inhibiting GSK3β and JNK3. The combination may provide poten-
tial benefits for the treatment of Alzheimer’s disease reported by Hu et al. (2009); Martin
et al. (2013).
•	GSK3β∕JNK3+QED+SA: Inhibiting GSK3β or JNK3 while being drug-like and Syntheti-
cally accessible, which are quantified by QED and SA, respectively.
•	GSK3β+JNK3+QED+SA: Jointly inhibiting GSK3β and JNK3 while being drug-like and
synthetically accessible, which are quantified by QED and SA, respectively.
Baselines. We compare MARS with the following methods - the latest ones from four categories
mentioned in the related work (Sec. 2). GCPN (You et al., 2018) leverages RL to generate molecules
atom by atom, and the adversarial loss is incorporated in the objective to generate more realistic
molecules. JT-VAE (Jin et al., 2018) is a VAE-based approach that firstly generates junction trees
and then assembles them into molecules. It performs Bayesian optimization (BO) to guide molecules
towards desired properties. RationaleRL (Jin et al., 2020) is a state-of-the-art approach for multi-
property optimization, which generates molecules from combined rationales. GA+D (Nigam et al.,
2020) is a heuristic search method that applies the genetic algorithm (GA) to find molecules with
high property scores. An adversarial loss is incorporated in the fitness evaluation to increase the
diversity of generated molecules.
Evaluation metrics. Following Jin et al. (2020), we generate N = 5000 molecules for each
approach and compare the proposed method with the baselines on the following evaluation met-
rics: Success rate (SR) is the percentage of generated molecules that are evaluated as positive
on all given objectives (QED ≥ 0.6, SA ≥ 0.67, the inhibition scores of GSK3β and JNK3
≥ 0.5); Novelty (Nov) is the percentage of generated molecules with similarity less than 0.4
compared to the nearest neighbor xSNN in the training set (Olivecrona et al., 2017): Nov =
* Px∈G 1[sim(χ, XSNN) < 0.4]; Diversity (Div) measures the diversity of generated molecules,
which can be calculated based on pairwise Tanimoto similarity over Morgan fingerprints sim(x, x0)
as Div = n(n-i)Pχ=χθ∈G 1 - Sim(x, χ0); PM is the product of the above three metrics, which is
a more comprehensive evaluation of the proposed method. Intuitively, PM presents the percentage
of generated molecules that are simultaneously bio-active, novel and diverse, which are essential
criteria for molecules to be considered in building a suitable drug candidate library in early-stage
drug discovery (Huggins et al., 2011).
Implementation details. For the fragment vocabulary, we extract the top 1000 frequently appear-
ing fragments that contain no more than 10 heavy atoms from the ChEMBL database (Gaulton et al.,
2017) by enumerating single bonds to break. As for the sampling process, the unnormalized target
distribution is set as π(x) = Pk sk(x) where sk(x) is a scoring function for the above-mentioned
properties of interests, the temperature is set as T = 0.95bt/5c and we sample N = 5000 molecules
at one time. During sampling, the computation of q(x | x0) is ignored and we approximate A(x, x0)
with min{1, ∏α(x0)∕∏α(x)} to increase the computation efficiency. This is acceptable because
in practice q(x | x0) and q(x0 | x) is of order O(1) and A(x, x0) will be gradually bounded by
∏α(x0)∕∏α(x) as the temperature T decrease to zero. The sampling paths are all starting with an
identical molecule “C-C”, which is also adopted by previous graph generation methods for organic
molecules (You et al., 2018). The MPNN model has six layers, and the node embedding size is
d = 64. Moreover, for the model training, we use an Adam optimizer (Kingma & Ba, 2015) to
update the model parameters with an initial learning rate set as 3 × 10-4, the maximum dataset size
is limited as |D| ≤ 75, 000, and at each step, we update the model for no more than 25 times.
4.2	Main Results and Analysis
We perform ten independent runs for MARS. The quantitative results are summarized in Table 1 and
Table 2. From these tables, we observe that MARS outperforms all the baselines on five out of six
tasks in terms of PM. Furthermore, on the most challenging multi-objective optimization task, i.e.,
GSK3β+JNK3+QED+SA, it significantly surpasses the best baseline with a 77% improvement for
the product of metrics PM. Additional results are shown in Appendix A.
In comparing all these methods, the GA+D baseline is most similar to our MARS in terms of the
high novelty and PM score, as both methods focus on molecular space exploration. However, the
diversity score of GA+D drops a lot when optimizing multiple properties simultaneously, as GAs
are likely to get trapped in regions of local optima (Paszkowicz, 2009). RationaleRL is a very strong
7
Published as a conference paper at ICLR 2021
Table 1: Comparison of different methods on molecular generation with only bio-activity objectives. Results of
GA+D are obtained by running its open-source code. Results of other baselines are taken from Jin et al. (2020).
For MARS, we report the mean and standard deviation of 10 independent experiments.
Method	SR	GSK3β			SR	JNK3		PM	SR	GSK3β + JNK3		PM
		Nov	Div	PM		Nov	Div			Nov	Div	
GCPN	42.4%	11.6%	0.904	0.04	32.3%	4.4%	0.884	0.01	3.5%	8.0%	0.874	0.00
JT-VAE	32.2%	11.8%	0.901	0.03	23.5%	2.9%	0.882	0.01	3.3%	7.9%	0.883	0.00
RationaleRL	100.0%	53.4%	0.888	0.47	100.0%	46.2%	0.862	0.40	100.0%	97.3%	0.824	0.80
GA+D	84.6%	100.0%	0.714	0.60	52.8%	98.3%	0.726	0.38	84.7%	100.0%	0.424	0.36
MARS	100.0%	84.0%	0.718	0.60	98.8%	88.9%	0.748	0.66	99.5%	75.3%	0.691	0.52
				士 0.04				士 0.04				士 0.08
Table 2: Comparison of different methods on molecular generation with bio-activity, QED, and SA objectives.
Results of all baselines are obtained by running their open-source codes. For the results of MARS, we report
the mean and standard deviation of 10 independent experiments.
Method	SR	GSK3β + QED + SA		PM	SR	JNK3 + QED + SA		PM	GSK3β + JNK3 + QED + SA			
		Nov	Div			Nov	Div		SR	Nov	Div	PM
GCPN	0.0%	0.0%	0.000	0.00	0.0%	0.0%	0.000	^^0.00	0.0%	0.0%	0.000	~~0.00
JT-VAE	9.6%	95.8%	0.680	0.06	21.8%	100.0%	0.600	0.13	5.4%	100.0%	0.277	0.02
RationaleRL	69.9%	40.2%	0.893	0.25	62.3%	37.6%	0.865	0.20	75.0%	55.5%	0.706	0.29
GA+D	89.1%	100.0%	0.682	0.61	85.7%	99.8%	0.504	0.43	85.7%	100.0%	0.363	0.31
MARS	99.5%	95.0%	0.719	0.68	91.3%	94.8%	0.779	0.67	92.3%	82.4%	0.719	0.55
				± 0.03				± 0.02				± 0.05
baseline that performs better than MARS in the GSK3β+JNK3 setting. Nevertheless, when taking
the drug-likeness and synthetic accessibility into consideration, their performance falls short of ours
and fails to generate novel molecules. The performance of GCPN and JT-VAE remains relatively
low in most settings, as they are not tailored for multi-objective property optimization.
Visualization. We use t-SNE (van der Maaten & Hinton, 2008) to visualize the distri-
bution of generated positive molecules with the positive ones in the training set under the
GSK3β+JNK3+QED+SA setting. In the visualization, we use the ECFP6 fingerprints as suggested
in Li et al. (2018). As shown by Figure 3, most molecules generated by GA+D fall into two mas-
sive clusters, which aligns their low diversity. Molecules generated by RationaleRL also tend to
be clustered, with each cluster standing for a specific combination of rationales. By contrast, the
molecules generated by MARS are evenly distributed in the space with a range of novel regions
covered, which justifies our high novelty and diversity scores. We further visualize some molecules
generated by MARS with high property scores in Figure 4, indicating its ability to generate highly
synthesizable drug-like molecules that jointly inhibit GSK3β and JNK3. Additional examples of
sampled molecules are shown in Appendix C.
Generated by RationaIeRL
• Positive Samples
(a) RationaleRL
Generated by MARS
• Positive Samples
Generated by GA+D
• Positive Samples
(b) GA+D
(c) MARS
Figure 3: t-SNE visualization of generated molecules (gray) and positive molecules in the training set (blue).
Running time. The computing server has two CPUs with 64 virtual cores (2.10GHz), 231G mem-
ory (about 50G used), and one Tesla V100 GPU with 32G memory. In the GSK3β+JNK3+QED+SA
setting, MARS takes roughly T = 550 sampling steps and 12 hours in total to converge (including
the time used in proposing and evaluating molecules as well as MPNN model training). For other
baselines, RationaleRL takes 5.7 hours to fine-tune the model, and GA+D takes 278 steps and 2.2h to
8
Published as a conference paper at ICLR 2021
(0.91, 0.85, 0.78, 0.92)	(0.95, 0.76, 0.75, 0.88)	(0.85, 0.87, 0.74, 0.87)	(0.91, 0.71, 0.78, 0.90)
Figure 4: Sample molecules generated by MARS in the GSK3β+JNK3+QED+SA setting. The numbers in
brackets are GSK3β, JNK3, QED, and SA scores of each molecule respectively.
achieve its best performance. Compared to the conventional drug discovery process, which usually
takes months to years, the time we spent on molecular generation models is almost ignorable.
4.3	Effects of Proposal and Acceptance S trategy
To justify the contributions of the designed proposal and acceptance strategy, we compare them with
some naive ones and summarize the results of different combinations in Table 3. For acceptance
strategies, Annealed stands for annealed MCMC where the acceptance rate is computed as Equa-
tion 2 given α = 1/T, AlwaysAC stands for always accepting the candidate, i.e., A(x, x0) ≡ 1,
and HillClimb stands for accepting the candidate only when the overall score is improved, i.e.,
A(x, x0) = sign[s(x0) > s(x)]. For proposal strategies, Random stands for random proposal
where we randomly select atoms, bonds, and fragments to edit, and Adaptive stands for the adaptive
fragment-based graph editing model trained during the sampling process as described in Section 3.2.
Table 3: Results of different acceptance strategies and proposal strategies for molecular sampling.
AC Strategy	Proposal	SR	GSK3β + Nov	JNK3 Div	PM	GSK3∕ SR	+ JNK3 Nov	+ QED Div	+ SA PM
Annealed	Random	40.9%	94.9%	0.828	0.32	25.5%	80.4%	0.793	0.16
AlwaysAC	Adaptive	49.1%	88.4%	0.742	0.32	10.1%	94.6%	0.716	0.07
HillClimb	Adaptive	53.7%	96.1%	0.814	0.42	51.4%	86.6%	0.777	0.35
Annealed	Adaptive	99.5%	75.2%	0.688	0.52	92.3%	82.4%	0.719	0.55
The results in Table 3 indicate that proposals will influence the performance of MARS dramatically
(the first and the last row), especially when the number of objectives increases. The proposed adap-
tive proposal outperforms the random proposal and converges 4.6x faster in practice. By comparing
the last three rows, we find the Annealed strategy outperforms the other two strategies by a large
margin on both settings, as samples from such strategy are more likely to jump out of local opti-
mums. Another interesting observation is that even with the naive AlwaysAC or heuristic HillClimb
strategy, the MARS achieves comparable or even better performance than GA+D and RationaleRL
in some settings, e.g., HillClimb on GSK3β+JNK3+QED+SA optimization, which again proves the
effectiveness of the proposed proposal.
5	Conclusion and Future Work
This paper proposes a simple yet flexible MArkov moleculaR Sampling framework (MARS) for
multi-objective drug discovery. MARS includes a trainable proposal to modify chemical graph
fragments, which is parameterized by an MPNN. Our experiments verify that MARS outperforms
prior approaches on five out of six molecule generation tasks, and it is capable of finding novel
and diverse bioactive molecules that are both drug-like and highly synthesizable. Future work can
include further study of parameterization and training strategy of the molecular-editing proposal.
6	Acknowledgement
We would like to thank Meihua Dang for refactoring much of the MARS code. Meihua also per-
formed multiple experiments, which generates the results for the tables. We also thank Jiangjie
Chen, Yuxuan Song, Jingjing Xu, Weiying Ma, Hang Li, and anonymous reviewers for their con-
structive comments and suggestions.
9
Published as a conference paper at ICLR 2021
References
Sungsoo Ahn, Junsu Kim, Hankook Lee, and Jinwoo Shin. Guiding deep molecular optimization
with genetic exploration. In Advances in Neural Information Processing Systems 33: Annual
Conference on Neural Information Processing Systems, 2020.
Christophe Andrieu, Nando De Freitas, Arnaud Doucet, and Michael I. Jordan. An introduction to
mcmc for machine learning. Machine Learning, 50(1):5-43, 2003.
G. Richard Bickerton, Gaia V. Paolini, Jeremy Besnard, Sorel Muresan, and Andrew L. Hopkins.
Quantifying the chemical beauty of drugs. Nature Chemistry, 4(2):90-98, 2012.
Nicola De Cao and Thomas Kipf. MolGAN: An implicit generative model for small molecular
graphs. ICML 2018 workshop on Theoretical Foundations and Applications of Deep Generative
Models, 2018.
R. Vasundhara Devi, S. Siva Sathya, and Mohane Selvaraj Coumar. Evolutionary algorithms for de
novo drug design - a survey. Applied Soft Computing, 27:543-552, 2015.
Peter Ertl and Ansgar Schuffenhauer. Estimation of synthetic accessibility score of drug-like
molecules based on molecular complexity and fragment contributions. Journal of Cheminfor-
matics, 1(1):8-8, 2009.
Anna Gaulton, Anne Hersey, MichaI NoWotka, A. Patricia Bento, Jon Chambers, David Mendez,
Prudence Mutowo, Francis Atkinson, Louisa J. Bellis, Elena Cibrian-Uhalte, Mark Davies,
Nathan Dedman, Anneli Karlsson, Maria Paula Magarinos, John P. Overington, George Pa-
padatos, Ines Smit, and Andrew R. Leach. The chembl database in 2017. Nucleic Acids Research,
45, 2017.
Justin Gilmer, Samuel S. Schoenholz, Patrick F. Riley, Oriol Vinyals, and George E. Dahl. Neural
message passing for quantum chemistry. In Proceedings of the 34th International Conference on
Machine Learning, 2017.
Xiaojie Guo and Liang Zhao. A systematic survey on deep generative models for graph generation.
arXiv: Learning, 2020.
Rafael Gomez-Bombarelli, Jennifer Nansean Wei, David Duvenaud, Jose Miguel Hernandez-
Lobato, Benjamin SanChez-Lengeling, Dennis Sheberla, Jorge Aguilera-Iparraguirre, Timothy D.
Hirzel, Ryan Prescott Adams, and Alan Aspuru-Guzik. Automatic chemical design using a data-
driven continuous representation of molecules. ACS central science, 4(2):268-276, 2018.
Shuxin Hu, Aynun N. Begum, Mychica R. Jones, Mike S. Oh, Walter K. Beech, Beverly Hudspeth
Beech, Fusheng Yang, Pingping Chen, Oliver J. Ubeda, Peter C. Kim, Peter Davies, Qiulan Ma,
Greg M. Cole, and Sally A. Frautschy. Gsk3 inhibitors show benefits in an alzheimer’s disease
(ad) model of neurodegeneration but adverse effects in control animals. Neurobiology of Disease,
33(2):193-206, 2009.
Weihua Hu, Bowen Liu, Joseph Gomes, Marinka Zitnik, Percy Liang, Vijay S. Pande, and Jure
Leskovec. Strategies for pre-training graph neural networks. In Proceedings of the 8th Interna-
tional Conference on Learning Representations, 2020.
David John Huggins, Ashok Ramakrishnan Venkitaraman, and David Robert Spring. Rational meth-
ods for the selection of diverse screening compounds. ACS Chemical Biology, 6(3):208-217,
2011.
Jan H. Jensen. A graph-based genetic algorithm and generative model/monte carlo tree search for
the exploration of chemical space. Chemical Science, 10(12):3567-3572, 2019.
Wengong Jin, Regina Barzilay, and Tommi S. Jaakkola. Junction tree variational autoencoder for
molecular graph generation. In Proceedings of the 35th International Conference on Machine
Learning, 2018.
Wengong Jin, Kevin Yang, Regina Barzilay, and Tommi S. Jaakkola. Learning multimodal graph-to-
graph translation for molecule optimization. In Proceedings of the 7th International Conference
on Learning Representations, 2019.
10
Published as a conference paper at ICLR 2021
Wengong Jin, Regina Barzilay, and Tommi Jaakkola. Composing molecules with multiple property
constraints. In Proceedings of the 37th International Conference on Machine Learning, 2020.
Wengong Jin, Regina Barzilay, and Tommi S. Jaakkola. Hierarchical generation of molecular graphs
using structural motifs. In Proceedings of the 37th International Conference on Machine Learn-
ing, 2020.
Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In Proceedings
of the 3rd International Conference on Learning Representations, 2015.
Ashutosh Kumar, A Voet, and K. Y. J Zhang. Fragment based drug design: from experimental to
computational approaches. Current Medicinal Chemistry, 19(30):5128-5147, 2012.
P. J. M. Laarhoven and E. H. L. Aarts. Simulated Annealing: Theory and Applications. 1987.
Yibo Li, Liang Ren Zhang, and Zhenming Liu. Multi-objective de novo drug design with conditional
graph generative model. Journal of Cheminformatics, 10(1):33, 2018.
Jaechang Lim, Sang-Yeon Hwang, Seungsu Kim, Seokhyun Moon, and Woo Youn Kim. Scaffold-
based molecular design using graph generative model. Chemical Science, 11(4):1153-1164,
2020.
Xianggen Liu, Lili Mou, Fandong Meng, Hao Zhou, Jie Zhou, and Sen Song. Unsupervised para-
phrasing by simulated annealing. In Proceedings of the 58th Annual Meeting of the Association
for Computational Linguistics, 2020.
Ludovic Martin, Xenia Latypova, Cornelia M. Wilson, Amandine Magnaudeix, Marie-Laure Perrin,
Catherine Yardin, and Faraj Terro. Tau protein kinases: Involvement in alzheimer’s disease.
Ageing Research Reviews, 12(1):289-309, 2013.
Nicholas Metropolis, Arianna W. Rosenbluth, Marshall N. Rosenbluth, Augusta H. Teller, and Ed-
ward Teller. Equation of state calculations by fast computing machines. Journal of Chemical
Physics, 21(6):1087-1092, 1953.
Ning Miao, Hao Zhou, Lili Mou, Rui Yan, and Lei Li. CGMH: constrained sentence generation by
metropolis-hastings sampling. In Proceedings of the 33rd Conference on Artificial Intelligence,
2019.
C. A. Nicolaou, C. Kannas, and Erika Loizidou. Multi-objective optimization methods in de novo
drug design. Mini-reviews in Medicinal Chemistry, 12(10):979-987, 2012.
AkshatKumar Nigam, Pascal Friederich, Mario Krenn, and Alan Aspuru-Guzik. Augmenting ge-
netic algorithms with deep neural networks for exploring the chemical space. In Proceedings of
the 8th International Conference on Learning Representations, 2020.
Marcus Olivecrona, Thomas Blaschke, Ola Engkvist, and Hongming Chen. Molecular de-novo
design through deep reinforcement learning. Journal of Cheminformatics, 9(1):48-48, 2017.
W. Paszkowicz. Properties of a genetic algorithm equipped with a dynamic penalty function. Com-
putational Materials Science, 45(1):77-83, 2009.
Pavel G. Polishchuk, Timur I. Madzhidov, and Alexandre Varnek. Estimation of the size of drug-
like chemical space based on gdb-17 data. Journal of Computer-aided Molecular Design, 27(8):
675-679, 2013.
Mariya Popova, Olexandr Isayev, and Alexander E Tropsha. Deep reinforcement learning for de
novo drug design. Science Advances, 4(7), 2018.
Mariya Popova, Mykhailo Shvets, Junier Oliva, and Olexandr Isayev. Molecularrnn: Generating
realistic molecular graphs with optimized properties. arXiv: Learning, 2019.
David Rogers and Mathew Hahn. Extended-connectivity fingerprints. Journal of Chemical Infor-
mation and Modeling, 50(5):742-754, 2010.
11
Published as a conference paper at ICLR 2021
Jeffrey S. Rosenthal. Optimal proposal distributions and adaptive mcmc. In Handbook of Markov
Chain Monte Carlo, chapter 4. CRC Press, 2011.
Daniel SchWalbe-Koda and Rafael Gomez-Bombarelli. Generative models for automatic chemical
design. In Machine Learning Meets Quantum Physics. 2020.
Ari Seff, Wenda Zhou, Farhan Damani, Abigail Doyle, and Ryan P. Adams. Discrete object gen-
eration With reversible inductive construction. In Advances in Neural Information Processing
Systems 32: Annual Conference on Neural Information Processing Systems, 2019.
Chence Shi, Minkai Xu, Zhaocheng Zhu, Weinan Zhang, Ming Zhang, and Jian Tang. Graphaf:
a floW-based autoregressive model for molecular graph generation. In Proceedings of the 8th
International Conference on Learning Representations, 2020.
Laurens van der Maaten and Geoffrey Hinton. Visualizing data using t-sne. Journal of Machine
Learning Research, 9:2579-2605, 2008.
Robin Winter, Floriane Montanari, Andreas Steffen, Hans Briem, Frank Noe, and Djork-Arne Clev-
ert. Efficient multi-objective molecular optimization in a continuous latent space. Chemical
Science, 10(34):8016-8024, 2019.
Jiaxuan You, BoWen Liu, Zhitao Ying, Vijay S. Pande, and Jure Leskovec. Graph convolutional
policy netWork for goal-directed molecular graph generation. In Advances in Neural Information
Processing Systems 31: Annual Conference on Neural Information Processing Systems, 2018.
Chengxi Zang and Fei Wang. MofloW: An invertible floW model for generating molecular graphs.
In The 26th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, 2020.
Huangzhao Zhang, Hao Zhou, Ning Miao, and Lei Li. Generating fluent adversarial examples for
natural languages. In Proceedings of the 57th Annual Meeting of the Association for Computa-
tional Linguistics, Florence, Italy, 2019.
Maosen Zhang, Nan Jiang, Lei Li, and Yexiang Xue. Language generation via combinatorial con-
straint satisfaction: A tree search enhanced Monte-Carlo approach. In Proceedings of the Confer-
ence on Empirical Methods in Natural Language Processing, 2020.
12
Published as a conference paper at ICLR 2021
Appendix
A Property Scores of Sampled Molecules
The property score distributions of sampled N = 5000 molecules of the GSK3β+JNK3+QED+SA
setting are shown in Figure 5. The average of the metrics over the sampling path is shown in Figure 6.
i"uθo
0.0	0.2	0.4	0.6	0.8	1.0
(a)	GSK3β inhibition score distribution.
0.0	0.2	0.4	0.6	0.8	1.0
(b)	JNK3 inhibition score distribution.
X4"uθo
(c) QED score distribution.
Figure 5: Property score distributions of sampled N = 5000 molecules. The red lines are success thresholds.
X4"uθo
(d) SA score distribution.
Figure 6: MARS sampling curves (average of 10 runs) for the GSK3β+JNK3+QED+SA setting. SR: success
rate. Nov: novelty. Div: diversity. PM: product of the three metrics. Shaded area shows the standard deviations
over 10 independent runs.
13
Published as a conference paper at ICLR 2021
B S ingle Objective Generation
To study whether our proposed method is capable of single-objective molecular generation, we
also investigate how MARS performs on the drug-likeness (QED) and the penalized octanol-water
partition coefficient (penalized logP) optimization. The experiment results are shown in Table 4. In
the experiments, our approach can obtain the best performance on both QED and logP optimization.
And especially, MARS outperforms previous methods significantly in the logP generation task.
Table 4: Comparison of different methods on single-objective molecular generation. Results of other baselines
are taken from Shi et al. (2020) and Nigam et al. (2020).
Method	1st	QED 2nd	3rd	Penalized IogP		
				1st	2nd	3rd
GCPN (You et al., 2018)	0.948	0.947	0.946	7.98	7.85	7.80
JT-VAE (Jin et al., 2018)	0.925	0.911	0.91	5.30	4.93	4.49
GraphAF (Shi et al., 2020)	0.948	0.948	0.947	12.23	11.29	11.05
GB-GA (Jensen, 2019)	/	/	/	15.76 ± 5.71	/	/
GA+D (Nigam et al., 2020)	/	/	/	20.72 ± 3.14	/	/
MARS	0.948	0.948	0.948	44.99	44.32	43.81
Moreover, from the results, we also can see how these two previously widely used metrics (Jin et al.,
2018; You et al., 2018; Popova et al., 2019; Shi et al., 2020; Nigam et al., 2020) are questionable
for both scientific study and practical use. Most of the generative methods (i.e., GCPN, JT-VAE,
and GraphAF) can produce molecules with the highest possible QED score of 0.948, making the
top QED score metric hard to distinguish different methods. As for logP optimization, heuristic
search-based (i.e., GB-GA and GA+D) and sampling-based methods (i.e., MARS) can all easily
beat generative models. This is because penalized logP score will prefer larger molecules that gen-
erative models can hardly produce. However, such large molecules are unrealistic for practical drug
discovery, making the top penalized logP score metric problematic.
C Examples of Sampled Molecules
We also provide some examples of sampled molecules from the GSK3β+JNK3+QED+SA setting.
The numbers under molecule graphs are GSK3β, JNK3, QED, and SA scores, respectively.
14
Published as a conference paper at ICLR 2021
J¾fO Crχyiji C‰P-⅞> JAʧp O⅛rC
(y⅛ro QCfQ dcfp∙ OvQ dQ<g
Figure 7: 40 sampled molecules with highest average property scores.
Cr∙γyζ> Cr'∖yO Cr^rO ŋɔ^θ
0.91,0,85,0.78,0,92
0.90l 0.83, 0.78l 0,93
0.95,0,75,0.76,0,93
0.88,0,81,0.78,0.89
0.92,0,73,0.78,0,92
0.33,0,79,0.75,0 88
0.89,0,80,0.77,0,88
0.B5,0S7f0.74,0S7
0.83,0,77,0.78,0,90
0.31,0,80f0.74,0S7
■CryyJ^ <‰P-Q O⅛rO
0.83,0,75,0.78,0,91
0.9110,72,0.7β, 0,90
0.85,0,77,0.79,0,90
0.91,0.71,0.7aι0,90
0.83,0,74,0.80,0,88
f©
0.9210,69,0.7β, 0,89
0.89,0,71,0.78,0,88
0.83,0,71,0.79,0,88
0.83,0,70,0.79,0,88
0.83,0,69,0.79,0,88
0.83,0,69,0.79,0^7
0.83,0 68,0.79,0^7
0.83,0,67,0.79,0 07
0.87,0,67,0.79,0^7
0.87,0 66,0.79,0^7
0.87,0,65,0.79,0,86
0.87,0,64,0.79,0,86
0.87,0,64,0.80,0,86
0.87,0,63, 0.80,0,86
0.86,0,62, 0.80,0,86
0.86,0,62, 0.80,0,86
0.86,0,61,0.80,0,85
0.86,0,60, 0.80,0,85
0.86,0,60, 0.80,0,85
0.86,0,59, 0.80,0,85
O.	c‰Ao
0.86,0,58, 0.80,0,85
0.85,0,58,0.81,0,84
0.85,0.57,0.81,0,84
0.85,0,56,0.81,0,84
0.85,0,55,0.81,0,84


15
Published as a conference paper at ICLR 2021
¼ ∙-p J⅜<Q o*
Cr∖yO df¾yp	CxPʧ
0.87,0,55, 0.80,0,86
0.87,0,58,0.75,0,07
0.87,0,58,0.73,0,07
0.87,0,54,0.76,0,07
Figure 8: 40 sampled molecules with highest GSK3β scores.
0.87,0,61,0.75,0,81
0.91,0,85,0.78,0,92
Ob<Γ O A。
0.90l 0.83, 0.78l 0,93
0.30,0,60,0.74,0,85
0.89,0,60,0.74,0,86
0.89,0,71,0.78,0,88
CrnQ OYyO <MyO
0.83,0,77,0.78,0,90
0.83,0,75,0.78,0,91
0.83,0,74,0.80,0,88
0.88,0,59,0.75,0,85
0.83,0,60,0.75,0,82
0.88,0,56,0.70,0,83
0.88,0,62,0.60,0,85
0.88,0,69,0.79,0,87
0.88,0,68,0.79,0,87
0.80,0,67,0.79,0,87
CrX^ J¾fP QAQ
0.95,0,75l 0.76,0,93
0.33,0,79,0.75,0 88
0.92,0,73,0.78,0,92
0.9210,69,0.7β, 0,89
0.31,0,80f0.74,0S7
0.9110,72,0.7β, 0,90
0.91,0.71,0.7aι0,90
0.91,0,59,0.74,0,88
0.30,0,61,0.7110,82
0.89,0,80,0.77,0,88
0.89,0,62,0.75,0,85
0.83,0,71,0.79,0,88
0.83,0,70,0.79,0,88
0.83,0,69,0.79,0,88
0.88,0,81,0.78,0.89
0.87,0,67,0.79,0,07
0.87,0,66,0.79,0,07
0.87,0,65,0.79,0,86
0.87,0,60, 0.80,0,85
0.87,0,72,0.67,0,85



16
Published as a conference paper at ICLR 2021
0.52,0,91,0.76,0,88
0.61,0,90,0.75,0,84
0.60,0,90,0.73,0,88
0.51,0,90, 0.68,0.88
0.7110,85,0.58,0,84
0.69,0,85,0.56,0,83
0.65l 0.85l 0.56,0.82
0.62,0,85,0.73,0,86
0.62,0,83,0.77,0,07
0.62,0,83,0.59,0,86
0.60,0,83,0.77,0,83
0.57,0,83, 0.80,0,86
0.60,0,82,0.58,0,84
0.64,0,82,0.73,0,85
0.63,0,82,0.77,0,83
Figure 9: 40 sampled molecules with highest JNK3 scores.
0.60,0,82,0.75,0,84
0.91,0,85,0.78,0,92
0.59,0,85l 0.75,0,83
0.62,0,84,0.77,0,82
0.30l 0.83,0.78,093
<κPχO
0.55,0,83,0.76t 0,86
0.59,0,88,0.77,0,83
0.B5,0S7f0.74,0S7
0.55,0^7,0.76,0,91
0.62,0,86,0.77,0,84
0.59,0,85,0.74,0,84
0.57,0,85,0.73,0,84
0.54,0,85,0.73,0,88
0.54l0,84h0.71t0,ai
0.65,0,84,0.56,0,82
17
Published as a conference paper at ICLR 2021
0.70,0,61,0.9310,S7
0.67,0,58,0.92,0,76
0.6S, 0,54, 0.92,0,82
0.66,0.57,0.91,0,86
0.68,0,36, 0.91,0,71
0.54,0,64,0.31,0,78
0.60,0,42,0.90,0,01
0.62,0.57,0.30,0,86
0.59l 0.56, 0.90,0.85
0.74,0,62,0.30,0,86
Figure 10: 40 sampled molecules with highest QED scores.
0.64,0,59,0.92,0,69
0.6710,58,0.9210,ai
0.58l 0,59, 0.31,0,85
0.61,0,54, 0.91,0,83
0.69,0,63, 0.91,0,88
0.43,0,60,0.90,0,β7
0.69,0,60,0.34,0,86
0.60,0,33,0.94,0,70
0.72,0,65,0.34,0,80
0.6410,56,0.34,0,ai
0.61,0,59,0.93,0,85
0.6910,59,0.9310,a7
0.74,0,59,0.93,0,86
0.7110,55,0.92,0,83
0.74,0,60,0.92,0,86
0.6S, 0,63, 0.92,0,77
0.6410,56,0.92,0,89
0.69,0,61,0.92,0,90
0.43,0.71,0.9110,86
0.69,0,38, 0.9110,S7
0.62,0,60, 0.91,0,ai
0.60,0,56,0.91,0,82
0.63,0,65,0.91,0,84
0.71t0,59, 0.91,0,83
0.72,0,54,0.91,0,84
0.58,0,62,0.91,0,79
0.61,0.57,0.91,0,84
0.64,0,64, 0.31,0,80
0.65,0,56,0.94,0,84
0.36,0 49,0.90,0,84








18
Published as a conference paper at ICLR 2021
b>yθ GyyO c‰∙Ao	-O7>0
>Λcrσ cκPχ> J>cro
0.76,0,55l 0.74,0.90
0.4S, 0,64,0.75,0.90
0.59,0.54,0.78,0.90
0.64,0.45, 0.78,0.90
0.67,0.54, 0.78,0,89
0.31,0,85,0^,0,92	0,64,0,67,0.75,0.91
XWQ CnoXl
0.55,0.87,0.76,0.91
0.74,0.59l 0.75,0,91
0.74,0.59l 0.75,0,91
CnQro
0.34,0.59,0.80,0.91
0.60,0,62,0.78,0.91
0.72,0.52,0.78,0,91
CLCA oʌerɑ cλ∙Ao
0.71,0.59,0.79,0.90
0.72,0,57,0.76, 0.90
-Oyyζ> bvŋ bvŋ
0.69,0,61,0.92,0.90
0.601 0.54, 0.79,0.90
Figure 11: 40 sampled molecules with highest SA scores.
0.67,0,61,0.85,0,91
0.53,0,65,0.81,0,91
0.60,0.59,0.87,0.91
0.83,075,0.78,0,91
0.59,079,0.73,0.90
0.61,0.59,0.74,0.90
0.73,0,5B, 0.76,0.90
0.53,。80, 0.88, 0x90
0.85,0.77,0.79,0.90
0^,0,54,0.75,0.90
0.71,048,0.79,0.90
0.91,0.72,0.78,0.90
0^,0,77,0.78,0.90
0.74,0.72,0.76,0.90
0.6S, 0,61,0.78,0.90
0.72,0,57,0.73,0.90
dAθ ©Ao
0.91,0,71,0.70,0.90
0.671 0.56, 0.79,0.90
0.61,0,66,0.74,0,89
0.64,0.34,0.81,0,89
0.35,075,0.76,0,93
0.90, 0.83, 0.78,。93
19