Under review as a conference paper at ICLR 2018
Automatic Measurement on Etched Structure
in Semiconductor Using Deep Learning Ap-
PROACH
Anonymous authors
Paper under double-blind review
Ab stract
The fabrication of semiconductor involves etching process to remove selected ar-
eas from wafers. However, the measurement of etched structure in micrograph
heavily relies on time-consuming manual routines. Traditional image processing
usually demands a large number of annotated data and the performance is still
poor. We treat this challenge as segmentation problem and use deep learning
approach to detect masks of objects in etched structure of wafer. Then, we use
simple image processing to carry out automatic measurement on the objects. We
attempt Generative Adversarial Network (GAN) to generate more data to over-
come the problem of very limited dataset. We download 10 SEM (Scanning Elec-
tron Microscope) images of 4 types from Internet, based on which we carry out
our experiments. Our deep learning based method demonstrates superiority over
image processing approach with mean accuracy reaching over 96% for the mea-
surements, compared with the ground truth. To the best of our knowledge, it is
the first time that deep learning has been applied in semiconductor industry for
automatic measurement.
1	Introduction
Typically, massive processing phases during fabrication of semiconductor can be roughly catego-
rized into four manufacturing steps: deposition, removal, patterning, and modification. Particu-
larly for etching process, as one type of removal technologies, such as Reactive-ion etching (RIE)
(Ephrath, 1981), aims to remove selected areas from the surface of wafer so that other materials can
be deposited (Kato et al., 1999). As the density of semiconductor device are continually increas-
ing with miniaturization tendency in highly integrated circuits, features and size between etched
structure also become dramatically smaller and leads to higher aspect ratio (means ratio of height to
width), which in other words narrowing the horizontal width much faster than vertical height within
the structure (Chen et al., 2007). Therefore, the precision during removal and patterning phases is
quite crucial for semiconductor devices to ensure ultimate quality and reliability of products.
However, how to guarantee the precision and accuracy during fabrication process remains a big
challenge due to the following reasons: (1) Inaccurate measurement of critical dimensions, such
as wrongly localized key points or failure of removing some material in etched process, can result
in adverse consequence and impact on product yield and quality; (2) Even very slight deformation
on patterns or features with irregular shape or bend line can cause some device defects, e.g., non-
functionality or bad quality on next-generation products (Szkely & Van Bien, 1988; Iveland et al.,
2013; Zhang & Auston, 1992).
Till now, although with the advent of high-resolution image using AFM (Atomic Force Microscopy)
and advanced etched process like Deep Reactive-Ion Etching (DIRE) (Marty et al., 2005), the mea-
surements, such as etch line, space depth, width, profile angle, etc., are still carried out manually
by domain experts or process engineers. Such process requires considerable efforts and it is time-
consuming, subjective, and very hard to reproduce (Schroder, 2006). Traditional approaches like
thresholding (Tobin et al., 1999) and edge detecting (Feng et al., 2006) are basically utilizing con-
straints on image intensity or object appearance which require relatively large training sets. Conse-
quently, automatic measurement and profile characterization of etched structures in semiconductor is
1
Under review as a conference paper at ICLR 2018
Figure 1: Segmentation and object boundary detection (with red line) on SEM images of different
semiconductor wafers using traditional machine learning approach. The first two and the fourth SEM
images show several undetected boundaries, while the third one displays irregular shapes challenge.
(circled with yellow dotted line).
highly desirable for semiconductor industry to achieve consistent, efficient, and accurate evaluation
of the device quality, and at the same time reduce the demand for human beings.
With evolving of machine learning techniques, such as random forest (Shotton et al., 2008), SVM
(Fulkerson et al., 2009), AdaBoost (Lee et al., 2010), etc., they can be widely applied in many dif-
ferent domains, such as clinical, object recognition, image segmentation (Lee et al., 2010), etc. This
paper conducts preliminary study on segmentation of silicon SEM image by using traditional ma-
chine learning approaches. As results demonstrated in Fig. 1, image analytics using the traditional
methods are not so promising, which fail to detect several boundaries due to unknown variations
in images. Another challenge lies in irregular shapes resulted from unexpected variations, as the
traditional image processing searches the boundaries based on predefined patterns.
Recently, explosion of interests is drawn on deep learning approaches and many state-of-the-art
methods are leading the direction for automatic image segmentation and recognition in a broad
fields, such as clinical like tumors detection (Chen et al., 2016), arts like music (Wang & Wang,
2014), nature language processing (Collobert & Weston, 2008), to mention a few. However, till now
deep learning approach has not been used in etched structure detection for semiconductor wafer im-
ages yet. Although the aforementioned deep learning network can achieve promising performance
in segmentation and classification issues, it still suffers from learning abundant data without ground
truth or obtaining labeled training dataset with expensive and considerable efforts. Therefore, data
augmentation is crucial to achieve excellent results by training model with desired properties and
invariance with limited dataset. To address such puzzle, Goodfellow et al. (2014) designed Genera-
tive Adversarial networks (GAN) using adversarial process, which can be used to generate pseudo
images to reduce demand for labeled data.
In this paper, fully convolutional network, U-Net, is adopted to the new issue on profile characteri-
zation of etched structure in semiconductor SEM image. Problem from this domain is appropriate
to select U-Net for object boundary detection as following reasons: Firstly, the dataset for neu-
ronal structure segmentation (Ronneberger et al., 2015) and the SEM image used for etched struc-
ture segmentation are quite similar which are all in electron microscopic stacks. Next, replacing
fully connected layers with convolutional layers can generate seamless segmentation results with
smooth lines rather than jagged line (Lee & Yoo, 2008). Third, the output images generated are
with high resolution which resulting from replacement with upsampling operators, and this lays the
foundation of measurement on key point sets and critical dimension of chips after segmentation.
Furthermore, data augmentation is performed by using GAN to acquire pseudo images for training.
Other approaches for increasing sample dataset involve cropping, contrast, flipping, etc. Finally, key
point localization is performed to measure critical dimensions of etched structures in wafers.
Concluded from the aforementioned literatures and studies, this paper has the following contribu-
tions:
1.	Unlike the traditional boundary searching based on image processing, deep learning treats
the problem as a segmentation problem;
2
Under review as a conference paper at ICLR 2018
2.	Many data augmentations have been explored, such as varying contrasts, flipping, rotation,
adding salt-and-pepper, etc., in order to explore all potential variations;
3.	Cross-validation methods are used to avoid any potential data-leakage, e.g., if there are
three images of the same type, two out of three are used as training dataset and the remain-
ing one are used for testing; if there is only one image for a type, the image is cropped into
three smaller ones and again, two out of the three are used as training and the remaining
one is used for testing;
4.	GAN is also used to generate some data for training and around 0.5% improvement of
pixel-wise accuracy on testing dataset has been observed.
The rest of the paper is organized as following. In Section 2, some related work are discussed.
In section 3, we present the Network architecture of deep learning approach. Section 4, training
process and data augmentation are demonstrated. In section 5, experiments and results are further
discussed. Finally, conclusion has been drawn in section 6.
2	Related Work
Generally, on the basis of instruments used to scan semiconductor wafers for etched structure inspec-
tion, the technologies can be classified into three categories, which broadly are applied in practice,
covering optical imaging, Scanning Electron Microscope (SEM), and Optical Microscopy. Par-
ticularly, SEM with higher resolution comparing to the other two are able to observe geometric
features and shapes even in extreme environments, such as high vacuum, low temperature, etc.,
so that it appears widely applied in semiconductor industry for inspection of wafers (Tobin et al.,
1999). Conventionally, such inspection is manually done by process engineers using eyes. Due
to the drawbacks of unreliability, exhaustion, and bias from different expertise for manual inspec-
tion, many research work have been carried out for automatic inspection to reduce the traditional
manual inspection using eyes (Myron et al., 2006; Feng et al., 2006; Scaman & Economikos, 1995;
Dom & Brecher, 1995).
The research work on wafers inspection can be classified into two categories, direct and indirect
approaches. Direct approaches use reference images without flaws as benchmarks to compare with
inspected images, to generate computed difference for defect identification, e.g., golden template
using threshold for subtractive comparison, neighborhood template using dynamic reference image
on account of neighboring structure (Tobin et al., 1999). Although direct methods are relatively
fast with easy procedures, massive potential offset values can pose difficulty to adjust threshold
value with appropriateness. On the other hand, indirect approaches aim to compare two segmented
images with masks to indicate defect object, instead of using reference and inspected images. Such
segmentation step to differentiate insulator and conductor is also one crucial pre-requisite procedure
for further locating key point sets and measurement of critical dimensions in SEM images.
Regarding segmentation techniques for SEM images or within the field of semiconductor industry,
although Feng et al. (2006) adopted hybrid ridge detector rather than normal approach of edge de-
tector to avoid the effect of noise and double edge and demonstrated robustness to some extent, the
method still suffers from issues of computational intensity when generating coefficients for regres-
sion in polynomial with high orders. Based on this work, Lee & Yoo (2008) further proposed a
segmentation method according to global-local thresholding approach and watershed segmentation
algorithms on two types of SEM images, achieving relatively high accuracy. However, this method
may be efficient for semiconductor wafer inspection but can pose issues when conducting measure-
ment of critical dimensions with jagged line instead of smooth line for object boundary. Further-
more, requiring a large number of training dataset and annotated images can be another weakness
of these methods.
Referring to related deep learning networks, Krizhevsky et al. (2012) proposed a Convolutional
neural network named as AlexNet and won the champion of ImageNet 2012 image segmentation
and classification tasks. Later on, Long et al. (2015) presented a CNN without convolutional fully
connected layers aiming to obtain coarse labeling masks and pixel-wise classifications in 2015.
Ronneberger et al. (2015) proposed U-Net for biomedical image segmentation in electron micro-
scopic stacks and won several challenges like ISBI 2015. Such network is fast with short time of
3
Under review as a conference paper at ICLR 2018
Figure 2: The architecture of U-Net with an example of 572 × 572 pixels as input.
training and appears robust in segmentation even with very limited original dataset, which leads to
broad applications among different domains.
3	Network Architecture
Fully convolutional network which was proposed by Long et al. (2015) has raised extensive con-
cerns by training end-to-end with images as both input and output, to achieve state-of-the-art per-
formance, particularly for segmentation and semantic classification (Chen et al., 2016; Long et al.,
2015; Azimi et al., 2017). The key idea of Long et al. (2015) lies in replacing the max pooling
operation with up-sampling convolutional operations, which in turn supports the path of down sam-
pling. The down-sampling path aims to capture high resolution information while up-sampling
path targets at localizing features with pixel-wise manner. Inspired by Long et al. (2015), U-Net
(Ronneberger et al., 2015) demonstrates superiority particularly with limited training samples but
higher precision in masks. Such promising results are reached via utilizing massive feature channels
in up-sampling path and the corresponding network architecture is presented in Fig. 2.
The discriminating path (left half) and the localizing path (right half) together constitute the whole
U-shaped framework with a total of 23 convolutional layers and massive different operations
(Ronneberger et al., 2015). Referring to discriminating path in each dimension, a nonlinear acti-
vation ReLU and a 2 × 2 max pooling (stride=2) follows after 2 standard 3 × 3 convolutions. For
such convolutional layers, only valid part is utilized which represents a 1-pixel border lost in each
3 × 3 convolution to allow later large image processing in individual tiles. Batch normalization
using standard deviation and mean is further applied after each convolution to learn bias and scale
for higher accuracy. For max pooling operation, it conducts on each channel separately and doubles
the feature channels in each step. Consequently, discriminating path leads to a spatial contraction
with captured abstraction information increased and spatial information decreased.
Regrading localizing path, a sequence of a 2 × 2 up-sampling convolutional operation, two standard
3 × 3 convolutions each followed with a ReLU, and a shortcut connection from corresponding high-
resolution features in the discriminating path together constitute every step of the localizing path.
The high-resolution segmentation map with two channels for foreground and background separately
is generated after a 1 × 1 convolution with 64 channels as input. The overlap-tile strategy is also
conducted when output segmentation maps to ensure the seamless score masks (Ronneberger et al.,
2015).
4	Implementation
The semiconductor images with etched structures are publicly available on the official website of
Oxford Instruments (DAT). The silicon wafers adopted in this paper consist of 4 types with a total
of 10 raw pictures captured by Scanning Electron Microscope with diverse angels, as shown in Fig.
4
Under review as a conference paper at ICLR 2018
UUU
ooooo
(b)
(c)
(d)
Figure 3: Samples of Scanning Electron Microscope (SEM) micrograph on etched structures of 4-
type semiconductor wafers with measuring scale displayed at the right bottom (from left to right
represent Type A, B, C, D respectively), downloaded from Internet.
Figure 4: Examples of SEM images of etched structure generated using GAN.
3. For each type of etched structure, only two or three sample images are available with 8 〜33
objects included in one single image. Such limited training samples indicates data augmentation
are significantly crucial for further experiments. Each image also follows with a manual annotated
segmentation result showing ground truth of object boundary. Initial weights are known to be cru-
cial for deep learning framework like fully convolutional networks to avoid either none or excessive
contribution from network. Considering our network with ReLU activation, the initialization ap-
proach from the work of He et al. (2015) is applied to calibrate the unit variance. And such variance
is concluded to be 2/N, with N equals to 576 in our case.
4.1 Data Preparation and Augmentation
With very limited training dataset, data augmentation plays a crucial role in fighting overfitting while
preserving robustness. In our experiments with SEM image on etch structure of wafers, both generic
image augmentation approach and Generative Adversarial Net (GAN) are applied to enlarge the
training dataset. For traditional method, a combination of random cropping, horizontally flipping,
contrast adjusting, adding salt-and-pepper, etc., has been adopted to increase the number of training
Table 1: Preliminary experimental results using different data augmentation techniques.
Augmentation Method	Training ACC	Testing ACC
Traditional Approach	09941	0.9699
GAN + Traditional Approach	0.9874	0.9751
5
Under review as a conference paper at ICLR 2018
Figure 5: Etched structure of semiconductor wafers recorded with SEM. (a): Raw image segmen-
tation with ground truth; (b): Segmentation results using U-Net; (c): Measurement parameters on
critical dimension and key points. The read line is the ground truth and the blue line is the predicted
boundary.
images and objects to at least 44 times. GANs demonstrate efficiency in obtaining counterfeit images
using generator which in turn can fool the discriminative network (Goodfellow et al., 2014). Even
image with higher resolution can be generated during augmentation process. In order to choose the
appropriate augmentation approach to boost performance and accuracy, preliminary experiment is
conducted using both GAN and traditional augmentation approach to enlarge the dataset for U-Net
training. The sample SEM data for such experiment involving 2 raw images on one type of wafers
with each image containing 4 objects, and GAN would increase the original data to 2N in our case.
The SEM wafers images generated by GAN are shown in Fig. 4 and preliminary experimental
results are presented in Table 1.
Revealing from the results, although the created pictures are quite similar to the original one, cases
like disconnection in object boundary, double edge effect and some noise in background still appears
frequently to impede the learning process of U-Net. From Table 1, we can observe that accuracy
on training dataset decreases slightly and the result on testing dataset increases around 0.5%. With
GAN, we have more in the training dataset and it is reasonable that the result decreases. However,
less than 1% improvement is not significant. Besides, with dataset increasing dramatically by utiliz-
ing GAN, considerate efforts and expense are required to manually label the ground truth for newly
generated images. As a consequent, further experiment on different types of semiconductor wafers
only applied generic augmentation approach like clipping and flipping to extend the original dataset.
6
Under review as a conference paper at ICLR 2018
Table 2: Evaluation on U-Net performance w.r.t accuracy (ACC), IoU, and DM.
Data Category	Training Strategy	Training ACC	Testing ACC	Testing IoU	Testing DM
Type A	From scratch	0.9952	0.9655	0.9824	0.9657
Type B	Fine-tuning	0.9956	0.9613	0.9503	0.9053
Type C	Fine-tuning	0.9873	0.9595	0.9711	0.9439
Type D	From scratch	0.9977	0.9957	0.9976	0.9953
Trained Together	From scratch	0.9949	0.9423	0.9428	0.8929
5 Experimental Results
The distribution of 10 images is as follows: Type A (4 images), Type B (1 image), Type C (2 images),
and Type D (3 images). Cross-validation methods are used to avoid any potential data-leakage, e.g.,
if there are three images of the same type, two out of three are used as training dataset and the
remaining one are used for testing; if there is only one image for a type, the image is cropped into
three smaller ones and again, two out of the three are used as training and the remaining one is used
for testing. The input image tiles for training are 400 × 400 pixels while the output segmentation
maps are 400 × 400 too.
Our network is implemented under the open-source deep network library Keras, and the server
for experiments is equipped with Dual 8-Core Intel@Xeon Processors 2.4GHz, 128 GB memory,
4 × 2TB SATA3 hard disk, and 4× NvidiaTitan × 12GB GDDR5 GPU cards. The OS is Ubuntu
14.04 with Keras 2.0.7 installed and Tensorflow 1.0.0 as backend. The learning rate is adjusted to
be 0.0001 throughout implementation process and pixels of segmentation image are within zero to
one range generated by sigmoid activation function.
The final test accuracy extracts the best score over all epochs. With the purpose of boost performance
with limited dataset, transfer learning is applied to load the weights from pretrained models for
further fine turning purpose so as to increase the segmentation accuracy on similar dataset. The
training speed is quite fast with a single image just costing less than 1 second by our server. The
corresponding segmentation results are displayed in Fig. 5, which demonstrate superiority over
traditional machine learning approach compared with the results shown in Fig. 1.
In addition to the pixel-wise accuracy, Intersection over Union (IoU) (also known as Jaccard index)
and Dice metric (DM) are the most popularly used metrics to perform quantitative evaluation of
image segmentation results (Ronneberger et al., 2015). We also use IoU and DM to evaluate the
performance as shown in Equ. 1.
IoU(A,B) = a∩b and DM(A,B) = ''2A ∩ B),	(1)
(,)	A U B	( , )	(A + B),	()
where A is the predicted mask and B is the corresponding ground truth.
After comparing the performance of the pre-trained models and the models training from scratch,
the experimental results are presented in Table 2, where experiments are conducted on different
types of silicon wafer images and finally implemented on the whole dataset. The Type D SEM
image with a single circle is comparatively simple for learning comparing to the other 3 types to
achieve the highest accuracy with 99.57%, then follows Type A wafer with 96.55% accuracy which
indicates relatively clear and regular boundary. Type B ranks next as sunk object boundary appears
occasionally, and Type D obvious received least accuracy of 95.59% with uneven edge and diverse
ring shapes. In our case, the superiority of transfer learning is not so obvious due to diverse types
of SEM image rather than in similar shapes. Results on the whole dataset have been degraded to
94.23%, since U-Net cannot handle multiple different datasets simultaneously. Regarding metrics
of IoU and DM, we can observe that Type B has the worst performance and Type D has the best
performance, but the results are all more than 90%. Such results prove the hypothesis that U-Net
is significantly appropriate to conduct shape modeling on etched structure of semiconductor wafers
with SEM image, although such efficient networks which stem from clinical segmentation have not
been applied in semiconductor field yet.
Promising segmentation results laid the foundation of further measurement on critical dimensions
and key points of silicon wafers. Refer to the suggestions from domain experts, Type A and Type
B aim to identify the depth, width, and critical dimensions of etched structure, while diameter and
7
Under review as a conference paper at ICLR 2018
Table 3: Evaluation of results on measurement of etched structure (Pred. = Prediction, GT = Ground
Truth).______________________________________________________________________________
Category	Measurement	Max (um)		Min (um)		Average (um)		Variance	
		GT	Pred.	GT	Pred.	GT	Pred.	GT	Pred.
-Type A-	H1	0.387	0.387	0.365	0.361	0.373	0.376	0.005	0.005
	W1	0.183	0.187	0.126	0.152	0.149	0.171	0.002	0.001
	W2	0.265	0.269	0.234	0.226	0.248	0.250	0.001	0.002
	W3	0.378	0.256	0.100	0.243	0.234	0.250	0.006	0.002
	W4	0.104	0.108	0.083	0.083	0.092	0.091	0.004	0.006
-Type B-	H1	136.0	135.0	132.5	131.5	134.1	132.9	1.17	1.42
	W1	19.5	18.5	14.5	13.5	16.63	16.51	2.29	2.12
	W2	48.0	41.5	37.5	33.5	41.70	39.64	11.4	6.69
	W3	43.0	43.0	37.5	38.0	40.79	40.86	2.63	2.62
	W4	14.5	14.5	13.0	11.5	13.69	12.51	0.18	0.75
TyPeC	W1	24.0	24.0	17.6	17.6	20.60	20.88	2.23	2.53
	H1	22.4	24.8	16.0	16.0	20.73	21.03	1.93	2.73
	W2	44.8	44.8	36.8	36.0	40.95	40.63	4.18	3.55
	H2	46.4	46.4	40.0	40.0	43.61	42.83	2.72	2.40
TyPeD	w1	25.6	24.8	22.4	20.0	23.31	22.96	0.86	0.99
	H1	26.4	24.8	22.4	20.0	24.12	22.67	1.31	0.88
Table 4: Mean errors compared with ground truth measurements.
Type A Type B Type C Type D Over All
Mean Error~~268%	245%	398%	370%	32%-
recess for each hole are assessed for Type C and Type D wafers. The corresponding measurement
parameters are illustrated in Fig. 5. In this paper, we apply average, max, min, and variance to
quantify and evaluate the measurement results, which are demonstrated in Table 3. Further more, in
Table 4, we present the comparisons of our measurements with the ground truth and we can see that
less than 4% mean error or more than 96% mean accuracy has been achieved for all types in our
experiments.
The overall measurement results demonstrate acceptable variability based on opinions from semi-
conductor experts and can be further broadly applied in automatic measurement of etched structure
to ensure the quality and functionality of wafer products in the domain.
6 Conclusion
This paper has demonstrated deep learning methodes like fully convolutional network U-Net can be
further applied in the new issue of etched structure segmentation even with very limited dataset, and
have broad application prospects in semiconductor industry to replace the time-consuming manual
measurements. Segmentation results using deep learning approach illustrate superiority over tra-
ditional machine learning method to solve the puzzle of undetected boundary and irregular shape
problems. Although GAN is state-of-the-art deep learning technique, results in this paper indicate
generic data augmentation methods are even more efficient and powerful to enlarge dataset, and can
avoid additional manual labeling tasks. The superiority of transfer learning is not so apparent in our
case due to diverse data types. In addition to high accuracy in profile characterization, fast prediction
can also be guaranteed with testing time of less than 1 second on a single image.
References
Leading provider of high technology tools and systems for research and industry. - oxford instru-
ments. URL https://www.oxford-instruments.com/?src=tn.
Seyed Majid Azimi, Dominik Britz, Michael Engstler, Mario Fritz, and Frank Mcklich. Advanced
steel microstructure classification by deep learning methods. 2017.
8
Under review as a conference paper at ICLR 2018
Hao Chen, Xiaojuan Qi, Lequan Yu, and Pheng-Ann Heng. Dcan: Deep contour-aware networks
for accurate gland segmentation. In Proceedings of the IEEE conference on Computer Vision and
Pattern Recognition, pp. 2487-2496, 2016.
Xiaolin Chen, Srinivas D. Nemani, and Shankar Venkataraman. Novel deposition-
plasma cure cycle process to enhance film quality of silicon dioxide, 2007. URL
http://www.google.ch/patents/US20070281448.
Ronan Collobert and Jason Weston. A unified architecture for natural language processing: Deep
neural networks with multitask learning. In Proceedings of the 25th international conference on
Machine learning, pp. 160-167. ACM, 2008.
Byron E. Dom and Virginia Brecher. Recent advances in the automatic inspection of integrated
circuits for pattern defects. 8(1):5-19, 1995.
Linda M. Ephrath. Reactive ion ctching. US Patent 4,283,249, 8, 1981.
Hanying Feng, Jun Ye, and R. Fabian Pease. Segmentation-assisted edge extraction algorithms for
sem images. In Photomask Technology 2006, volume 6349, pp. 63491L. International Society for
Optics and Photonics, 2006.
Brian Fulkerson, Andrea Vedaldi, and Stefano Soatto. Class segmentation and object localization
with superpixel neighborhoods. In Computer Vision, 2009 IEEE 12th International Conference
on, pp. 670-677. IEEE, 2009.
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair,
Aaron Courville, and Yoshua Bengio. Generative adversarial nets. In Advances in neural infor-
mation processing systems, pp. 2672-2680, 2014.
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Delving deep into rectifiers: Surpassing
human-level performance on ImageNet classification. 2015.
Justin Iveland, Lucio Martinelli, Jacques Peretti, James S. Speck, and Claude Weisbuch. Direct
measurement of auger electrons emitted from a semiconductor light-emitting diode under elec-
trical injection: identification of the dominant mechanism for efficiency droop. 110(17):177406,
2013.
Tadahiro Kato, Hisashi Masumura, Sadayuki Okuni, and Hideo Kudo. Method of manufacturing
semiconductor wafers. (5942445), 1999.
Alex Krizhevsky, Ilya Sutskever, and Geoffrey E. Hinton. Imagenet classification with deep convo-
lutional neural networks. In Advances in neural information processing systems, pp. 1097-1105,
2012.
Jang Hee Lee and Suk In Yoo. An effective image segmentation technique for the sem image. In
Industrial Technology, 2008. ICIT 2008. IEEE International Conference on, pp. 1-5. IEEE, 2008.
Sang Hak Lee, Hyung Il Koo, and Nam Ik Cho. Image segmentation algorithms based on the
machine learning of features. 31(14):2325-2336, 2010. ISSN 0167-8655. doi: 10.1016/j.patrec.
2010.07.004.
Jonathan Long, Evan Shelhamer, and Trevor Darrell. Fully convolutional networks for semantic seg-
mentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,
pp. 3431-3440, 2015.
Frdric Marty, Lionel Rousseau, Bassam Saadany, Bruno Mercier, Olivier Franais, Yoshio Mita, and
Tarik Bourouina. Advanced etching of silicon based on deep reactive ion etching for silicon high
aspect ratio microstructures and three-dimensional micro-and nanostructures. 36(7):673-677,
2005.
L. Jeff Myron, Ecron Thompson, Ian McMackin, Douglas J. Resnick, Tadashi Kitamura, Toshiaki
Hasebe, Shinichi Nakazawa, Toshifumi Tokumoto, Eric Ainley, and Kevin Nordquist. Defect
inspection for imprint lithography using a die to database electron beam verification system. In
SPIE 31st International Symposium on Advanced Lithography, pp. 61510M-61510M. Interna-
tional Society for Optics and Photonics, 2006.
9
Under review as a conference paper at ICLR 2018
Olaf Ronneberger, Philipp Fischer, and Thomas Brox. U-net: Convolutional networks for biomed-
ical image segmentation. In International Conference on Medical Image Computing and
Computer-Assisted Intervention, pp. 234-241. Springer, 2015.
Michael E. Scaman and Laertis Economikos. Computer vision for automatic inspection of complex
metal patterns on multichip modules (MCM-d). 18(4):675-684, 1995.
Dieter K. Schroder. Semiconductor material and device characterization. John Wiley & Sons, 2006.
Jamie Shotton, Matthew Johnson, and Roberto Cipolla. Semantic texton forests for image catego-
rization and segmentation. In Computer vision and pattern recognition, 2008. CVPR 2008. IEEE
Conference on, pp. 1-8. IEEE, 2008.
Vladimir Szkely and Tran Van Bien. Fine structure of heat flow path in semiconductor devices: a
measurement and identification method. 31(9):1363-1368, 1988.
Kenneth W. Tobin, Thomas P. Karnowski, and Regina K. Ferrell. Image retrieval in the industrial
environment. In IS&T/SPIEs 11th International Symposium on Electronic Imaging: Science and
Technology, San Jose Convention Center, 1999.
Xinxi Wang and Ye Wang. Improving content-based and hybrid music recommendation using deep
learning. In Proceedings of the 22nd ACM international conference on Multimedia, pp. 627-636.
ACM, 2014.
X.-C. Zhang and D. H. Auston. Optoelectronic measurement of semiconductor surfaces and inter-
faces with femtosecond optics. 71(1):326-338, 1992.
10