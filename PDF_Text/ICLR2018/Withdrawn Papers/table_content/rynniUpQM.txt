Table 1: MNIST test error (%) with n labeled examples for different architectures at nBn=256. Note:SS is simple feedforward CNN encoder/decoder/discriminator and separate discriminator and RS isresidual CNN encoder/decoder/discriminator and separate discriminatorMethod/ Arch	Examples per Class					All	10	20	50	100	200	DCGAN Alexnet	53.39 ±	47.1 士	34.44 ±	24.55 ±	19.54 ±	8.17	4.22	3.63	2.13	1.56	1.1	Springenberg (2015)	-	-	-	1.39 ± 0.28	-	0.48Makhzani et al. (2015)	-	-	1.90 ± 0.1	-	-	0.85Salimans et al. (2016)		16.77 ±	2.21 ±	0.93 ±	0.9 ±		-	4.52	1.36	0.07	0.04	-MIDCGAN SS	1.51 ±	1.22 ±	1.13 ±	1.07 ±	0.99 ±	0.82	0.27	0.08	0.09	0.08	0.11	MIDCGAN RS	4.58 ±	1.72 ±	1.48 ±	1.17 ±	1.03 ±	0.68	2.65	0.69	0.43	0.13	0.07	Figure 3: Reconstruction of stencil digits from SVHN samples at epochs 3(left) and 2499 (right).
Table 2: SVHN test error (%) with n labeled examples for different architectures at nBn=2048.
Table 3: Object recognition accuracy using different databases and approaches.
Table 4: Effect ofbottleneck size on performance and comparison with the state-of-the-art at n=200.
Table 5: Test error (%) on MNIST at bottleneck size of 1024 for the two dicriminator types andstate-of-the-art.____________________________________________________________ArCh	______________n______________10	20	50	100Separate	2.832^^1.209^^1.103^^1.017Alexnet	8.045 4.473 2.426	1.727Salimans et al. Salimans et al. (2016) x	16.77	2.21	0.9312Under review as a conference paper at ICLR 2018Table 6: Effect of bottleneck size on performance and comparison with the state-of-the-art atn=1000.
Table 6: Effect of bottleneck size on performance and comparison with the state-of-the-art atn=1000.
