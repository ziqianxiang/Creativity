Table 1: Experimental DetailsModel	Dataset	Layer Sizes (base model)	Training Epochs	Adaptive Frequency (epochs)	NotesFully Connected	MNIST	64-64-64	20	2	Variational Autoencoder	MNIST	256-10-256	500	5	Used RMSProp, batch-size 256.
Table 2: Experimental Results- log Î±	Random Fixed SParse	Random SParse ChanneI-WiSe	AdaPtive SParse (best k)	Pruned	Wide Dense (more Params)Fully Connected (% Error)	Baseline: 2.9				0.5	2.6		2.3 (0.25)	2.4	2.21.0	2.5		2.3	1.8	1.91.5	2.6		2.2 (0.25)	1.7	1.92.0	2.5		2.3 (0.25)	1.9	1.9Variational Autoencoder (Loss)	Baseline: 105.9				0.5	105.5		103.2 (0.25)	102.1	100.81.0	108.2		103.5 (0.25)	104.4	100.7LSTM (Cross-entropy Loss)	Baseline: 1.178		Best Published result with same # Parameters: 1.161		0.5	1.154		1.114 (0.5)	1.122	1.1291.0	1.171		1.144 (0.5)	1.122	1.098Convolutional Network (% Error)	Baseline: 18.7				0.5	18.4	19.4	17.0 (0.25)	17.8	17.61.0	19.1	20.5	17.3 (0.5)	18.3	17.9ResNet-110 (% Error)0.51.0Baseline: 6.5
