Table 1: Analysis of robustness of the models to random Gaussian noise. The accuracy and the RCDscores are averaged over all 50,000 validation examples.
Table 2: Analysis of robustness of the models against fast gradient sign method and its variants. Weattack 5,000 images that are initially correctly classified with high confidence (> 0.9), the accuracyand RCD score are averaged over the corresponding 5,000 adversarial examples.
Table 3: Model robustness against LSA attack. We select 500 images that are initially correctlyclassified with high confidence (> 0.9), and we apply the LSA algorithm to search the correspondingadversarial examples for 150 steps. We report the averaged RCD over attack steps.
Table 4: An experimental analysis of robustness of the model to adversarial examples generated usinggradients from different routes. We attack 5,000 images that are initially correctly classified withhigh confidence (> 0.9). The accuracy and RCD score are averaged over the corresponding 5,000adversarial examples.
