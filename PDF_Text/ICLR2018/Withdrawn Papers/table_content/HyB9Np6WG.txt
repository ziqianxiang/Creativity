Table 1: Cosine Similarity of Centered Prepositionsprepositions	word2vec	GloVe	tensor(above, below)	-0:85-	0.78	0.22(above, beneath)	-040-	0.45	0.15(after, before)	-083-	0.70	0.44(after, during)	-0:56-	0.42	0.16(amid, despite)	-047-	0.37	0.12(amongst, besides)	-046-	0.37	0.21(beneath, inside)	0.55	0.47	0.29do not restrict word1 and word2 to be head- and child- words; instead we model a preposition’s1Under review as a conference paper at ICLR 2018interaction with all pairs of neighboring words via a slice of a tensor X - the slice is populated byword co-occurrences restricted to a context window of the specific preposition. Thus, the tensordimension is V × V × K where V is the vocabulary and K is the number of prepositions; sinceK ≈ 50, we note that V K .
Table 2: Paraphrasing of Prepositional PhrasesPhrase	involved in	made from	approved of	dreamed of	blocked off	sparked offParaphrase	included	produced	issued	wants	intercepted	prompted2	. Weighted Decomposition (WD): Based on ideas from the literature on word embedding algo-rithms, we also consider weighting different elements of the tensors differently in order to reducethe effect of the large dynamic range of the tensor values. Specifically, we employ the GloVe objec-tive function to our tensor model and minimize the objective function (2):N N K+1Lweighted = min3ΣΣΣωijk (hui, wj , qki + bUi + bWj + bQk - log(Xijk + 1))2 , (2),	,Q i=1 j=1 k=1where bUi is the scalar bias for word i in matrix U. Similarly, bWj is the bias for word j in matrixW , and bQk is for preposition k in matrix Q. Bias terms are learned to minimize the loss function.
Table 3: Dataset StatisticsFEC	# of sent	27119	# of prep	60279	error ratio	4.8CoNLL	# of sent	1375	# of prep	3241	error ratio	4.7SE	# of sent	5917	# of prep	15814	error ratio	38.2Table 4: Performance on Preposition SelectionDataset	Method	Precision	Recall	F1 scoreCoNLL	state-of-the-art	0.2592	0.3611	0.3017	word2vec	0.1558	0.1579	0.1569	GloVe	0.1538	0.1578	0.1558	OUr method (ALS)	0.3355	0.3355	0.3355	OUr method (WD)	0.3590	0.3684	0.3636SE	state-of-the-art	0.2704	0.2961	0.2824	word2vec	0.2450	0.2585	0.2516	GloVe	0.2454	0.2589	0.2520
Table 4: Performance on Preposition SelectionDataset	Method	Precision	Recall	F1 scoreCoNLL	state-of-the-art	0.2592	0.3611	0.3017	word2vec	0.1558	0.1579	0.1569	GloVe	0.1538	0.1578	0.1558	OUr method (ALS)	0.3355	0.3355	0.3355	OUr method (WD)	0.3590	0.3684	0.3636SE	state-of-the-art	0.2704	0.2961	0.2824	word2vec	0.2450	0.2585	0.2516	GloVe	0.2454	0.2589	0.2520	OUr method (ALS)	0.2958	0.3146	0.3049	OUr method (WD)	0.2899	0.3055	0.2975Dataset. We use training data from Cambridge First Certificate in English (FCE) exam, the samedata used by state-of-the-art on preposition error correction Prokofyev et al. (2014). As for test data,we use two datasets: CoNLL-2013 and Stack Exchange (SE) dataset. CoNLL dataset on prepositionerror correction is published by CoNLL 2013 shared task Ng et al. (2014), collected from 50 essayswritten by 25 non-native English learners at a university. SE dataset consists of texts generated bynon-native speakers on Stack Exchange website. Detailed statistics are shown in Table 3. We focuson the most frequent 49 prepositions listed in Appendix A.
Table 5: Ablation Analysis in Preposition Selectionremoved feature		left context embedding	Prep embedding	right context embedding	pair similarity	triple similarity	confusion scoreCoNLL	Precision	-0!558-	-0.2662-	-0.3TT7-	0.3247	0.3247	0.3506	-Recall-	-0!579-	-0.2697-	-0.3T58-	0.3289	0.3289	0.3553	F1 score	-0!569-	-0.2680-	-0.3T37-	0.3268	0.3268	0.3529SE	Precision	-0.2587-	-0.2796-	-0.2649-	0.2658	0.2647	0.1993	-Recall-	-0.2743-	-0.2964-	-0.2801	0.2818	0.2807	0.2114	F1 score	0.2663 一	0.2877	0.2726 —	0.2735	0.2725	0.2052Result. We compare our methods against baselines mentioned above in Table 4. As is seen, tensorembeddings achieve the best performance among all approaches. In particular, tensor with weighteddecomposition has the highest F1 score on CoNLL dataset, 6% improvement over the state of the art.
Table 6: Prepositional Attachment Disambiguation Dataset	instances	avg head candidates	head set size	prep set size	child set sizeTrain	35,359	3.7	10,395-	72	5,504TeSt	1,951	3.6	2,133	—	46	一	983	—Table 7: Accuracy in Prepositional Attachment Disambiguationclassifier	HPCD (enriching)	LRFR	OntoLSTM	FNN	FNN	FNN	FNNembedding method	GloVe	word2vec	Glove- extended	word2vec	GloVe	Our method (ALS)	Our method (WD)resources	pos tag, WordNet, VerbNet, syntactic parsing	pos tag, WordNet, VerbNet	pos tag, WordNet	pos tag	pos tag	pos tag	pos tagaccuracy	0.887	0.903	0.897	∙	0.866	0.858	0.883	0.892	-(1) embedding feature: candidate, preposition and child embedding;⑵ triple similariy triple sim(h,p, C) = kvhhv∙hVp∣,v⅛ck3;(3)	head-preposition similarity: sim(h, p)TYh VP	.
Table 7: Accuracy in Prepositional Attachment Disambiguationclassifier	HPCD (enriching)	LRFR	OntoLSTM	FNN	FNN	FNN	FNNembedding method	GloVe	word2vec	Glove- extended	word2vec	GloVe	Our method (ALS)	Our method (WD)resources	pos tag, WordNet, VerbNet, syntactic parsing	pos tag, WordNet, VerbNet	pos tag, WordNet	pos tag	pos tag	pos tag	pos tagaccuracy	0.887	0.903	0.897	∙	0.866	0.858	0.883	0.892	-(1) embedding feature: candidate, preposition and child embedding;⑵ triple similariy triple sim(h,p, C) = kvhhv∙hVp∣,v⅛ck3;(3)	head-preposition similarity: sim(h, p)TYh VP	.
Table 8: Ablation Analysis in Preposition Attachment Disambiguationremoved feature	head vector	prep vector	child vector	head-prep similarity	head-child similarity	triple similarity	POS	distanceaccuracy	0.843	0.871	0.880	0.877	0.885	0.873	0.850	0.872Result. We compare results and linguistic resources of different approaches in Table 7, where wesee that our simple classifier built on the tensor representations is within 1% of the state of the art;prior state of the art results have used significant linguistic resources enumerated in Table 7. Withthe same feedforward neural network as the classifier, our tensor-based approaches (both ALS andWD) achieve better performance than word2vec and GloVe.
Table 9: Paraphrasing of Phrasal Verbs	word2vec		GloVe		Tensor (WD)		addition	multiplication	addition	multiplication	addition	multiplicationsparked off	ignited	strip	came	beginning	led	promptedinvolved in	interested	spoof	having	came	featured	includedaccuse of	criticize	consists	involved	scrapped	posted	convictedapproved of	mandated	entering	given	followed	recommended	issuedstuck with	dragging 一	romanize	having	came	posted	stalledderived from	originates	modeled	based	came	reading	generatedresign from	withdraw	assaulted	leaving	came	march	retireattached to	desired	erect	take	followed	assigned	subordinatepassed down	-lifted-	captained	put	beginning	voted	deliveredadjust to	modify	decorate	help	took	lose	adaptregarded as	considered	depicts	known	last	considered	perceiveddiffer from	vary	diet	derived	took	vary	varytreated as	tolerated	co-founded	known	starting	employed	regarded11Under review as a conference paper at ICLR 2018Table 10: Paraphrasing of Phrasal Verbs	word2vec			GloVe			TenSOr(WD)	
Table 10: Paraphrasing of Phrasal Verbs	word2vec			GloVe			TenSOr(WD)		addition	multiplication	addition	multiplication	addition	multiplicationconform to	modify	coloured	make	set	comply	complycorrespond to	specify	nominate	give	last	represent	correlatereplied to	said	intercept	give	lost	posted	answeredblend in	mix	sort	place	starting	feature	mixswitched over	dropped	witness	having	beginning	kent	transferredcarried on	laid	shortlisted	taken	came	employed	keptswitched on	shifted	briefing	moved	came	kent	tappedcarried in	laid	alternated	came	came	featured	createdhanded in	taken	awarded	taken	came	aged	passedkicked in	knocked	fencing	went	last	scored	interceptedlocked in	sealed	vending	having	came	last	placedput in	brought	highlights	came	came	took	placesmashed in	shattered	offers	came	came	dated	crashinghanded over	stripped	disadvantaged	took	came	posted	triedblocked off	stopped	attire	cut	came	posted	interceptedscraped off	trap	stripe	turn	inspire	aged	rippedshook off	smashed	lease	struck	followed	aged	shattered
