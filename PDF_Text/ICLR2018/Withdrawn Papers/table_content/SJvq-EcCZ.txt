Table 1: Hyper-parameters of the BI-LSTM-CRF Framework (# refers to layer numbers for LSTM,and dimension size for embedding or state)Besides, there are other structures and strategies proposed for sequence labeling. Strubell et al.
Table 2: Performance Comparison between H-L-LSTM-CRF (referred as “H-L”) and B-L-LSTM-CRF (referred as “B-L”). Highlight refers to the winning setting between “H-L” and “B-L” . Thehidden dimension of character-level LSTM is marked as LSTM (#).
Table 3: Performance Comparison between H-C-LSTM-CRF (referred as “H-C”) and B-C-LSTM-CRF (referred as “B-C”). Highlight refers to the winning setting between “H-C” and “B-C”. Thefilter number of CNN is marked as CNN (#).
Table 4: Performance of Different Fine-tuning Strategy on CoNLL03	IV	OOTV	OOEV	OOBVRatio of Entity Word	14.03%	51.89%	0.05%	24.85%Number of Entity Word	5795	2077	6	284F1 score of Vanilla	91.15	92.12	100	78.42F1 score of Word-wise (ratio set to 0.2)	91.25	92.15	-100-	78.56F1 score of Word-wise (ratio set to 0.3)	91.24	92.21	-100-	78.41Table 5: Performance of Word-wise Dropout on CoNLL03are 8,625.3 and 7,649.6. Also, we found the CoNLL03 training corpus has about 21,009 differentwords (converted to lowercase), and setting λ to these two values would allow the model to fine-tunemost of frequent words. And by increasing the value of λ, we found the model would fine-tune lessembeddings, but the performance would drop to a lower value.
Table 5: Performance of Word-wise Dropout on CoNLL03are 8,625.3 and 7,649.6. Also, we found the CoNLL03 training corpus has about 21,009 differentwords (converted to lowercase), and setting λ to these two values would allow the model to fine-tunemost of frequent words. And by increasing the value of λ, we found the model would fine-tune lessembeddings, but the performance would drop to a lower value.
Table 6: Performance Comparison between H-C-LSTM-CRF (referred as “H-C”) and B-C-LSTM-CRF (referred as “B-C”). Highlight refers to the winning setting between “H-C” and “B-C”. Thefilter number of CNN is marked as CNN (#).
Table 7: Performance Statistics of Original LSTM-CNN-CRF Implementation on CoNLL03 NER.
