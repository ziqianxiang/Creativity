Table 2: Decoder architectureTable 1: Encoder architecturethat computes the jth feature of y ∈ Rn×Fout. The input x ∈ Rn×Fin has Fin features. The inputface mesh has Fin = 3 features corresponding to its 3D vertex positions. Each convolutional layerhas Fin × Fout vectors of Chebyshev coefficients θi,j ∈ RK as trainable parameters.
Table 1: Encoder architecturethat computes the jth feature of y ∈ Rn×Fout. The input x ∈ Rn×Fin has Fin features. The inputface mesh has Fin = 3 features corresponding to its 3D vertex positions. Each convolutional layerhas Fin × Fout vectors of Chebyshev coefficients θi,j ∈ RK as trainable parameters.
Table 3: Length of different expression sequences5Under review as a conference paper at ICLR 2018Figure 3: Qualitative results for mesh reconstruction on test set of interpolation experiment.
Table 4: Performance comparison with different error metrics on interpolation experiment. Meanerror is of the form [μ ± σ] with mean Euclidean distance μ and standard deviation σ. The medianerror and number of parameters in each model are also shown. All errors are in millimeters (mm).
Table 5: Quantitative evaluation of Extrapolation experiment. The training set consists of the restof the expressions. Mean error is of the form [μ ± σ] With mean Euclidean distance μ and standarddeviation σ. The median error and number of frames in each expression sequnece is also shown. Allerrors are in millimeters (mm).
Table 6: Comparison of FLAME and FLAME++. FLAME++ is obtained by replacing expressionmodel of FLAME with our mesh autoencoder. All errors are in millimeters (mm).
