Figure 1: Proposed Method. We use a fully convolutional autoencoder, with reconstruction andcluster hardening loss, discussed in section 2.3 and 2.4 respectively, which results in cluster friendlyfeature space without the risk of collapsing to degenerate solutions3.5	CLUSTERING CNN (CCNN)CCNN uses a clustering CNN (Hsu and Lin, 2017) to achieve joint clustering and representationlearning. One of the internal layers of the CCNN forms the feature space. At the same time, theCCNNâ€™s softmax layer predicts the cluster labels. Initially, features from k random images fromthe dataset are used to initialize the cluster centers. k-Means is performed on the features extractedfrom the input dataset to get corresponding cluster labels. Based on the assigned labels, and thelabels predicted by the softmax layer, the CCNN parameters can be updated using the clusteringclassification loss discussed in section 2.4. The extracted features of the minibatch are then furtherused to update the corresponding cluster centroids.
Figure 2: t-SNE visualizations for clustering on MNIST dataset in (a) Original pixel space, (b)Autoencoder hidden layer space and (c) Autoencoder hidden layer space with the proposed method.
Figure 3: t-SNE visualizations for clustering on COIL20 dataset in (a) Original pixel space, (b)Autoencoder hidden layer space and (c) Autoencoder hidden layer space with the proposed method.
