Figure 1: Origin image from MNIST,CIFAR10,IMAGENET dataset and their correspondingsaliency. For each four-grids sample, left parts display clean data and right parts display fake dataattacked by FGSM. Lower half in four-grids sample represent corresponding saliency for upper halfimages.
Figure 2: Deep neural network used in our implementation for different datasets, called MNIST-														NET-f,	MNIST-NET-D,(			UFAR10-NET-f, CIFAR10-NET-D, VGG16-f and VGG16-D in follow-										ing passage. MNIST-NET-f, MNIST-NET-D, CIFAR10-NET-f, CIFAR10-NET-D are trained from scratch, and left two are finetuned with VGG parameters from Caffe Model Zoo. All pooling opera- tions and activations are set to maxpooling and relu respectively, which are not shown in this figure Fast/mnist	Iterative"J/mnist	Iterative" 2)∕mnist														1	0.95	0.88	0.71	0.65	1	0.91	0.87	0.81	0.65	1	0.86	0.80	0.76	0.702 £ test 3	0.95	1.00	0.90	0.89	2 £ test 3	0.96	0.96	0.96	0.92	2 £test 3	0.88	0.91	0.92	0.88	0.96 I	1.00	0.99	1.00		0.97	0.98	I 0.99 I	J 0.98		0.90	0.93	bd	I 0.954	0.92	0.99	0.99	1.00	4	0.97	0.99	0.99	1.00	4	0.90	0.95	0.97	1.00	12	3	4 £ fit Fast/cifar10					12	3	4 £ fit Iterative"co)∕cifar10					12	3	4 £ fit Iterative( 12)/Cifar10			1	0.89	0.75	0.61	0.58	1	0.89	0.82	0.77	0.65	1	0.81	0.78	0.74	0.682 £ test 3	0.91	0.95	0.86	0.81	2 £ test 3	0.92	0.95	0.96	0.90	2 £ test 3	0.82	0.89	0.82	0.78	0.90	0.97	0.97	0.99		0.94 J	J 0.98	0.98	0.99		0.87	I 0.94	0.97	0.924	0.91 I	I 0.92	0.99	1.00	4	0.94	0.96	I 0.99 I	I 0.99	4	0.91	0.94	I 0.98 I	I 0.99	1	2 £	3 fit	4		1	2 £	3 fit	4		1	2 £	3 fit	4Figure 3: Accuracy metric on MNIST/CIFAR10 of detector trained for adversary with maximaldistortion e*t When tested on the same adversary with distortionFollowing Metzen et al.(2017b), We set e as minimal under the constraint that the classification ac-curacy is below 30%. Result in Figure 4 shows that FGSM and JSMA generalized not good enoughwith detector trained with iterative。2) and detector trained iterative(l∞), but iterative。2) based de-tector and iterative(l∞) based detector perform well to FGSM-based adversaries and JSMA-based6
Figure 3: Accuracy metric on MNIST/CIFAR10 of detector trained for adversary with maximaldistortion e*t When tested on the same adversary with distortionFollowing Metzen et al.(2017b), We set e as minimal under the constraint that the classification ac-curacy is below 30%. Result in Figure 4 shows that FGSM and JSMA generalized not good enoughwith detector trained with iterative。2) and detector trained iterative(l∞), but iterative。2) based de-tector and iterative(l∞) based detector perform well to FGSM-based adversaries and JSMA-based6Under review as a conference paper at ICLR 2018OT-Ie七 OASW ① >p4a--UlU/*js ①*jOo■199■OFastIterative。JIterative。2)
Figure 4: Accuracy metric on MNIST/CIFAR10 of detector trained for one adversary when testedon other adversaries. The maximal distortion of the adversary (when applicable) has been chosenminimally such that the predictive accuracy of the classifier is below 30%. Numbers correspond tothe accuracy of the detector on unseen test data.
Figure 5: Accuracy metric on IMAGENET subset of detector trained for adversary with maximaldistortion when tested on the same adversary with distortion test. Evaluation method is the same asMNIST/CIFAR10 evaluation settings.
Figure 6: Accuracy metric on IMAGENET subset of detector trained for one adversary when testedon other adversaries. Evaluation method is the same as MNIST/CIFAR10 evaluation settings.
Figure 7: Weighted summation of feature maps in 'relu2-1', 'relu4-1' and 'pooling5' in VGG16model. These three Weighted summation of feature maps roughly represent feature extracted byshallow layers, middle layers and deep layers. Visualization shows that shallow layers are robustenough to adversarial examples while middle layers start to extract wrong features, leading to deeplayers’ failure.
