Figure 1: MIDCGAN input (left) and generated mental image (right). The images are selected fromthe BigBird database (Singh et al., 2014).
Figure 2: The MIDCGAN architecture built with either feedforward convolutional or ResNet blocks.
Figure 3: Reconstruction of stencil digits from SVHN samples at epochs 3(left) and 2499 (right).
Figure 4: Reconstruction of stencil digits from MNIST samples at epochs 7(left) and 1500 (right).
Figure 5: MIDCGAN generated images (every third column) for test set of MNIST after the firstepoch (left) and the last epoch (right). Every first column is the input, every second column is thetarget and every third column is the generated image.
Figure 7: MIDCGAN generated images (every third column) for test set of SVHN. Every firstcolumn is the input, every second column is the target and every third column is the generatedimage.
Figure 8: DCGAN generated images (every third column) for validation set of BigBird after the firstepoch (last epoch is shown in the next figure). Every first column is the input, every second columnis the target and every third column is the generated image.
Figure 9: DCGAN generated images (every third column) for validation set of BigBird after the lastepoch (first epoch is shown in the previous figure). Every first column is the input, every secondcolumn is the target and every third column is the generated image.
Figure 10: MIDCGAN generated images (every third column) for test set of BigBird after the lastepoch. Every first column is the input, every second column is the target and every third column isthe generated image.
