Table 1: Hyper-parameter settingsMEM	TF-LSTM	DNC	So-LSTM		Parameter settings testedTuned parameters				Learning rate	0.0001	0.0001	0.0001	0.0001		0.00001, 0.00001, 0.00005, 0.0001r 0.0002λ 0.0005Optimizer	Adam	Adam RMSProp	Adam		Adam, RMSPropDiscount factor	0.99	0.99	0.99	0.99		0.60, 0.65, 0.70, 0.75, 0.80, 0.90, 0.99MEM init quadrance scale	50				20, 30, 40, 50, 60DNC read heads	2			工2,4Fixed parametersMemory size	50	2x50		Memory word size	54	60		LSTM size	2x128	2x128	2x128	2x128Training window length	32	32	32	32Gradient clip threshold	50	50	50	50Per-match reward	25	25	25	25Flip penalty	-0.005	-0.005	-0.005	-0.005Asynchronous workers	16	16	16	16Entropy cost coefficient	0.01	0.01	0.01	0.01agent using its optimal settings on a number of additional runs. Table 1 gives the hyper-parametersettings used on Concentration, both tuned and fixed. Key results are collected in Figure 3a.
