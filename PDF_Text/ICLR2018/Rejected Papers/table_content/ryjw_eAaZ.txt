Table 1: Mean classification accuracy [%] (and standard deviation) of structures learned fromMNIST images as a function of network depth and number of parameters (normalized). For com-parison, when a structure is not learned, networks with 2 and 3 dense layers, achieve 98.4% and98.75% accuracy, respectively (having the same size as learned structures at configuration “100%”).
Table 2: Benchmarks and vanilla topologies. MNIST-Man and SVHN-Man topologies were manu-ally created by us. MNIST-Man has two convolutional layer (32 and 64 filters each) and one denselayer with 128 neurons. SVHN-Man was created as a small network reference having reasonableaccuracy compared to Maxout-NiN. In the first row we indicate that in one experiment a structurefor MNIST was learned from the pixels and feature extracting convolutional layers were not used.
Table 3: Classification accuracy (%) and overall network size (normalized number of parameters).
Table 4: A summary of network sizes and classification accuracies (and standard deviations),achieved by replacing the deepest layers of common topologies (vanilla) with a learned structure.
