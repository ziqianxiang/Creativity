Table 1: MemN2N, RN, and RMN in terms of MemNN architectureOutput feature mapαit = Softmax((rt)Tmit) (r0 = q)MemN2N	ot = Pi αitmitrt+1 = ot + rtRN	r = gθ-MLP([mi, mj, q])______________________o = Ei rirt = gθ-MLP([mt, rt-1 ])(r0 = q)RMN	αit = Softmax(βtrit)rt = Pi αitmitGeneralizationmt = Wtmt-1mit = (1 - αit-1)mit-1proposed a new class of memory-augmented model called Memory Network (MemNN). MemNNcomprises an external memory m and four components: input feature map (I), generalization (G),output feature map (O), and response (R). I encodes the sentences which are stored in memory m.
Table 2: Test error on bAbI story-based tasks with 10k training samplesTask	MemNN	MemN2N	GMemN2N	DMN	DMN+	DNC	EntNet1	RN2	RMN1: Single Supporting Fact	ɪo	0.0	-O	0.0	0.0	0.0	0.1	0.0	0.02: Two Supporting Facts	0.0	0.3	0.0	1.8	0.3	0.4	2.8	8.3	0.53: Three Supporting Facts	0.0	9.3	4.5	4.8	1.1	1.8	10.6	17.1	14.74: Two Argument Relations	0.0	0.0	0.0	0.0	0.0	0.0	0.0	0.0	0.05: Three Argument Relations	2.0	0.6	0.2	0.7	0.5	0.8	0.4	0.7	0.46: Yes/No Questions	0.0	0.0	0.0	0.0	0.0	0.0	0.3	0.0	0.07: Counting	15.0	3.7	1.8	3.1	2.4	0.6	0.8	0.4	0.58: Lists/Sets	9.0	0.8	0.3	3.5	0.0	0.3	0.1	0.3	0.39: Simple Negation	0.0	0.8	0.0	0.0	0.0	0.2	0.0	0.0	0.010: Indefinite Knowledge	2.0	2.4	0.2	2.5	0.0	0.2	0.0	0.0	0.011: Basic Coreference	0.0	0.0	0.0	0.1	0.0	0.0	0.0	0.4	0.512: Conjunction	0.0	0.0	0.0	0.0	0.0	0.0	0.0	0.0	0.013: Compound Coreference	0.0	0.0	0.0	0.2	0.0	0.1	0.0	0.0	0.014: Time Reasoning	1.0	0.0	0.0	0.0	0.0	0.4	3.6	0.0	0.015: Basic Deduction	0.0	0.0	0.0	0.0	0.0	0.0	0.0	0.0	0.016: Basic Induction	0.0	0.4	0.0	0.6	45.3	33.1	52.1	4.9	0.917: Positional Reasoning	35.0	40.7	27.8	40.4	4.2	12.0	11.7	1.6	0.318: Size Reasoning	5.0	6.7	8.5	4.7	2.1	0.8	2.1	2.1	2.3
Table 3: bAbI story-based task visualization of α(a) Task 7(c) Task 3Seq.	Task7: Counting	α1 I	8	John grabbed the apple there .	0.02	0.009	John gave the apple to Mary .	0.08	0.1610	Mary passed the apple to John .	0.17	0.2411	Maryjourneyed to the hallway .	0.00	0.0113	Sandra went to the garden .	0.00	0.0014	Mary went to the kitchen .	0.00	0.0315	Mary picked up the football there .	0.29	0.2416	Mary picked up the milk there .	0.27	0.32USer input	How many objects is Mary carrying?		Answer	Two		Model answer	Two	[Correct]		(b) Task 14Seq.	Task 14: Time reasoning	α1 ~I_02- 0.00	0.01 0.00	0.00 0.13	0.98 0.00	0.00 0.66	0.02 0.01	0.00 0.06	0.001 2 3 4 5 6 7	Mary went back to the school yesterday . Fred went to the school yesterday . Julie went back to the kitchen yesterday . Fredjourneyed to the kitchen this morning . This morning julie journeyed to the school. This evening mary went back to the school . This afternoon julie went to the bedroom .	User input	Where was Julie before the school ?	Answer	Kitchen	
Table 4: Test error on bAbI dialog tasks 3Task	Plain				With Match				MemN2N	GMemN2N	RN3 4	RMN	MemN2N	GMemN2N	RN4	RMN1: Issuing API calls	ɪi	-O	0.0	0.0	^O	0.0	0.0	0.02: Updating API calls	0.0	0.0	0.5	0.0	1.7	0.0	0.0	0.03: Displaying options	25.1	25.1	26.6	25.1	25.1	25.1	27.1	25.14: Providing extra information	40.5	42.8	0.0	0.0	0.0	0.0	0.0	0.05: Conducting full dialogs	3.9	3.7	23.3	2.5	6.6	2.0	16.6	1.8Average error rates (%)	ɪ^	^T43	10.1	5.5	^617	5.4	8.7	5.41 (OOV): Issuing API calls	ɪ?	~n：6	17.8	16.8		0.0	1.5	0.02 (OOV): Updatining API calls	21.1	21.1	23.2	21.1	5.5	5.8	0.0	0.03 (OOV): Displaying options	25.6	24.7	27.2	24.9	24.8	24.9	29.8	25.14 (OOV): Providing extra information	42.4	43.0	0.0	0.0	0.0	0.0	0.0	0.05 (OOV): Conducting full dialogs	34.5	33.3	38.3	34.5	22.3	20.6	28.4	21.7Average error rates (%)	30.3	27.9	—	21.3	19.5	11.2	10.3	12.0	9.4The results in the Table 4 show that the RMN has the best results in any conditions. Without anymatch type, RN and RMN outperform previous memory-augmented models on both normal andOOV tasks. This is mainly attributed to the impressive result on task 4 which can be interpreted asan effect of MLP based output feature map.
Table 5: Test error of RMN on bAbI story-based QA dataset with different configurations	inner product	inner product With gate	inner product and absolute difference With tWo embedding matrices	MLPerror rate	29.4	―	25.9	11.2	1.2Performance of RN and RMN according to memory size Additional experiments were con-ducted with the bAbI story-based QA dataset to see how memory size affects both performance andtraining time of RN and RMN. Test errors with training time written in parentheses are summarizedin Table 6.
Table 6: Test error and training time of RN and RMN on bAbI story-based QA dataset with differentmemory sizememory size	RN	RMN20	2.0 (0.65 days)	1.5 (1.46 days)130	9.8 (9.47 dayS)~	1.2 (4.94 days)^^Effectiveness of the number of hops bAbI story based QA dataset differs in the number of sup-porting sentences by each task that need to be referenced to solve problems. For example, task 1, 2,and 3 require single, two, and three supporting facts, respectively. The result of the mean error ratefor each task according to the number of hops is in Table 7.
Table 7: Test error of RMN on bAbI story-based QA dataset with different number of hops	hop 1	hop 2	hop 3task 1 (1) 5	0.0	0.0	0.2task 2 (2)	62.0	0.5	2.1task 3 (3)	62.4	14.7	14.6task 10 (1)	0.0	0.0	3.65Number in parentheses indicates the number of supporting sentences to solve the task8Under review as a conference paper at ICLR 20186	ConclusionOur work, RMN, is a simple and powerful architecture that effectively handles text-based questionanswering tasks when large size of memory and high reasoning ability is required. Multiple accessto the external memory to find out necessary information through a multi-hop approach is similar tomost existing approaches. However, by using a MLP that can effectively deal with complex related-ness when searching for the right supporting sentences among a lot of sentences, RMN raised thestate-of-the-art performance on the story-based QA and goal-oriented dialog dataset. When compar-ing RN which also used MLP to understand relations, RMN was more effective in the case of largememory.
Table 8: Visualization of α on bAbI dialog task 1, 3, and 4 without match type(a)	Plain and OOV result of task 1Seq.	LocUtor	Task 1: Issuing API calls		―αι--1-	user	Good morning		0.012	bot	Hello What can i help you with today		0.013	user	Can you make restaurant reservation for eight people in cheap price range with british cuisine		0.234	bot	I'm on it		0.005	user	<silence>		0.146	bot	Where should it be		0.017	user	In madrid		0.258	bot	Ok let me look into some options for you		0.18User input		<silence>		Answer		APLcall british madrid eight cheap		Model answer		APLcall british madrid eight cheap	[Correct]	Seq.	Locutor	Task 1 (OOV): Issuing API calls		-αι--1-	user	Hi		0.012	bot	Hello what can i help you with today		0.013	user	May I have table with cantonese cuisine in cheap price range in seoul for two people		0.494	bot	I'm on it		0.105	user	<silence>		0.01
Table 9: Hyperparameters of Relation Memory Networks on bAbI dialog tasksTask	Story and Question Embedding	Word-lookup Embedding Dim	Hop	gθ	fφ	Activation	USe Batch Norm-1-	sum	128	~~L-	2048, 2048,1	2048, 2048, 4212	tanh	True2^.-	sum	128	~~L-	1024, 1024,1	1024,1024, 4212	tanh	True	sum	128	~~L-	1024, 1024,1024,1	1024, 1024, 1024, 4212	tanh	True4^	concatenation	50	~~L-	1024, 1024,1	1024,1024, 4212	tanh	True5	concatenation	64	2	4096, 4096,1	4096, 4096, 4212	tanh	TrueB Additional ResultsTable 10: Visualization of α1 and α2 on user input revised bAbI dialog task 3 without match typeSeq.	Locutor	Task 3: Displaying options	αι	α2-1 -	user	resto_8 r_phone resto_8_phone	0.00	0.012	user	resto_8 r_cuisine french	0.01	0.013	user	resto_8 r_address resto_8.address	0.01	0.014	user	resto_8 r」ocation madrid	0.01	0.015	user	resto_8 r_number two	0.00	0.016	user	resto_8 r_price moderate	0.00	0.017	user	resto_8 Jrating 8	0.01	0.398	user	resto二 r_phone resto_3_phone	0.01	0.019	user	resto_3 r_cuisine french	0.00	0.0110	user	resto_3 r_address resto_3.address	0.00	0.01
Table 10: Visualization of α1 and α2 on user input revised bAbI dialog task 3 without match typeSeq.	Locutor	Task 3: Displaying options	αι	α2-1 -	user	resto_8 r_phone resto_8_phone	0.00	0.012	user	resto_8 r_cuisine french	0.01	0.013	user	resto_8 r_address resto_8.address	0.01	0.014	user	resto_8 r」ocation madrid	0.01	0.015	user	resto_8 r_number two	0.00	0.016	user	resto_8 r_price moderate	0.00	0.017	user	resto_8 Jrating 8	0.01	0.398	user	resto二 r_phone resto_3_phone	0.01	0.019	user	resto_3 r_cuisine french	0.00	0.0110	user	resto_3 r_address resto_3.address	0.00	0.0111	user	resto_3 r」ocation madrid	0.00	0.0112	user	resto_3 r_number two	0.00	0.0113	user	resto_3 r_price moderate	0.00	0.0114	user	resto_3 r_rating 3	0.00	0.0115	user	resto_1 r_phone resto_1_phone	0.01	0.0116	user	resto_1 r_cuisine french	0.01	0.0117	user	resto_1 r_address resto_1 .address	0.01	0.0118	user	resto_1 r」ocation madrid	0.01	0.01
