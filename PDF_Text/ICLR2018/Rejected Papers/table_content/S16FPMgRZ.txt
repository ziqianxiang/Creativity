Table 1: Results obtained on ImageNet by adding a TCL to a VGG-19 architecture. We reduce thenumber of hidden units proportionally to the reduction in size of the activation tensor following thetensor contraction. Doing so allows more than 65% space savings over all three fully-connectedlayers (i.e. 99.8% space saving over the fully-connected layer replaced by the TCL) with no corre-sponding decrease in performance (comparing to the standard VGG network as a baseline).
Table 2: Results obtained with ResNet-50 on ImageNet. The first row corresponds to the standardResNet. Rows 2 and 3 present the results obtained by replacing the last average pooling, flatteningand fully-connected layers with a TRL. In the last row, we have also added a TCL.
Table 3: Results obtained with a ResNet-101 architecture on ImageNet, learning spatial pooling aspart of the TRL.
