Table 1: Classification errors [%] for different NN models. NN (real): Real-valued NNs with batchnormalization, dropout and ReLU activation function. NN STE: NNs with batch normalization,dropout, sign activation function, real-valued weights in the first layer and binary weights in theremaining layers. NN VI (our method): 3 bits for the first layer and ternary weights for the remain-ing layers. We evaluated the single most probable model, the probabilistic forward pass (pfp), thegeneral 3 bit distribution for the first layer, and the discretized Gaussian for the first layer.
Table 2: The fraction [%] of non-zero weights of the best performing single model for individuallayers and for all layers combined.
