Table 1: TWo Categories for Hidden VariablesCategory	Hidden Variable	DefinitionLatent Variable	α = (α1,α2,... , an)	Trend and seasonality	Z = (za, Zc) ~~	Anomaly and change pointsParameter	aι	The “mean” for the ini- tial trend and seasonal- ity	P = (Pa,Pc)	Probabilities for each point to be anomaly or change point	~σ = (σ e ,σo , σu,σr ,σv ,σw )-	Standard deviationThe discrepancy between these two categories is clearly captured by the joint likelihood function.
Table 2: Comparison of methodologies on ForecastingMethods	MAPE	MSE	MAEProposed	0.041 ± 0.027	1.03 ± 0.59	0.89 ± 0.53Proposed (pa = 0)	0.069 ± 0.068	1.71 ± 1.61	1.49 ± 1.44Proposed (pc = 0)	0.065 ± 0.058	1.67 ± 1.53	1.43 ± 1.35Proposed (pa = 0, pc = 0)	0.084 ± 0.079	2.15 ± 2.00	1.87 ± 1.77BSTS	0.162 ± 0.110	4.10 ± 2.81	3.59 ± 2.48STL	0.047 ± 0.039	1.18 ± 1.06	1.03 ± 0.95ARIMA	0.076 ± 0.050	1.88 ± 1.38	1.71 ± 1.24Holt-Winters	0.093 ± 0.082	2.35 ± 2.06	2.05 ± 1.84ETS	0.054 ± 0.042	1.37 ± 1.05	1.19 ± 0.94Prophet	0.082 ± 0.055	2.06 ± 1.33	1.78 ± 1.16(Z1,Z2,...,^n) are the estimated ones. ThenTPR =也；zi = 1∖ =1}|, FP = |{i ： Zi=0,^i = i}∣.
Table 3: Comparison of Change Point DetectionMethods	TPR	FPProposed	0.41 ± 0.26	0.34 ± 0.57Proposed (pa = 0)	0.14 ± 0.21	0.26 ± 0.60BCP	0.58 ± 0.22	29.84 ± 8.13CP	0.29 ± 0.22	1.71 ± 1.15Breakout	0.01 ± 0.04	0.53 ± 0.86Table 4: Comparison of Anomaly DetectionMethods	TPR	FPProposed	0.88 ± 0.12	0.58 ± 0.96Proposed (pc = 0)	0.87 ± 0.12	2.56 ± 1.49AnomalyDetection	0.32 ± 0.19	1.03 ± 1.94RAD	0.88 ± 0.11	19.33 ± 3.58tsoutlier	0.81 ± 0.14	4.76 ± 4.29In Table 4, we also compare the performance of our algorithm on anomaly detection with threeexisting common anomaly detection methods: the AnomalyDetection package by Twitter (2017),RAD by Netflix (2017) and Tsoutlier by Chen & Liu (1993). The comparison is listed in Table 4.
Table 4: Comparison of Anomaly DetectionMethods	TPR	FPProposed	0.88 ± 0.12	0.58 ± 0.96Proposed (pc = 0)	0.87 ± 0.12	2.56 ± 1.49AnomalyDetection	0.32 ± 0.19	1.03 ± 1.94RAD	0.88 ± 0.11	19.33 ± 3.58tsoutlier	0.81 ± 0.14	4.76 ± 4.29In Table 4, we also compare the performance of our algorithm on anomaly detection with threeexisting common anomaly detection methods: the AnomalyDetection package by Twitter (2017),RAD by Netflix (2017) and Tsoutlier by Chen & Liu (1993). The comparison is listed in Table 4.
Table 5: Comparison of Forecasting in Well-log DataMethods	MAPE	MSE	MAEProposed	0.031	5296	3120Proposed (pa = 0)	0.029	5252	2957Proposed (pc = 0)	0.033	5434	3409Proposed (Pa = 0,pc = 0)	0.038	5703	3908BSTS	0.250	32030	27210ARIMA	0.084	10480	8738ETS	0.037	6071	3860Prophet	0.159	19530	17480In this dataset there is no ground-truth of change point and anomaly point on their locations or evenexistence. However, from bottom panel of Figure 4, there are some obvious changes in the sequenceand they all successfully captured by our algorithm.
Table 6: Comparison of Forecasting in Internet traffic dataMethods	MAPE	MSE	MAEProposed	0.0837	0.1216	0.08414Proposed (Pa = 0)	0.0838	0.1215	0.08320Proposed (Pc = 0)	0.0934	0.1332	0.09296Proposed (Pa =0,pc = 0)	0.0934	0.1366	0.09223BSTS	0.2756	0.3087	0.27960STL	0.1014	0.1258	0.09910ARIMA	0.1409	0.1653	0.12580Holt-Winters	0.2495	0.2739	0.25270ETS	0.0893	0.1199	0.09362Prophet	0.1015	0.1405	0.11450From Figure 5 our proposed algorithm identifies one change point (the 576th point, indicated bythe vertical red dashed line), which can be confirmed that this is exactly the only one change pointexisting in this time series caused by the change of counting methods, by some external information.
