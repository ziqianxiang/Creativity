Table 1: The accuracy (%) of the experiments (training accuracy is in parentheses)	SoundNet	WaveRNN	SimPleNet-RNN	SimPleNet-CNN	SPecNetEmotion Test	48.7 (95.0)	48.0 (83.8)	49.2 (73.8)	52.9 (80.0)	42.3 (66.3)Gender Test	88.6 (99.4)	88.8 (98.8)	88.7 (96.3)	88.6 (98.1)	63.9 (78.1)Table 1 shows the results of our experiments, where we can observe that all waveform-based ap-proaches perform similarly in the speaker gender recognition test, but demonstrate differences in themore complex speaker emotion recognition test.1 For the emotion recognition test, the SimpleNet-CNN performs best, followed by SimpleNet-RNN. When comparing the models pair-wise, we ob-tain the following insights:1)	SimpleNet-RNN and WaveRNN have identical high-level layers, but SimpleNet-RNN performsbetter than WaveRNN, which shows that the concise front-end of SimpleNet is actually more ef-fective than the 16-layer front-end of WaveRNN. This empirically proves our finding described inSection 2.2 that the stacked convolutional layers, especially those after the pooling layers, are un-necessary and ineffective.
