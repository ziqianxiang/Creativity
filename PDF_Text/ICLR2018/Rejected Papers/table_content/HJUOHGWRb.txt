Table 1: Performance of the models on classification tasks (averaged over 5 runs; the std. are on the order of theleast significant digit). The subscripts denote the features on which the linear models are built: pixels (pxl),HOG (hog), bag-or-words (bow), topics (tpc), embeddings (emb), discrete attributes (att).
Table 2: Performance of the classical Cox and Aalen models, CRF-based models, and CENs that use LSTM orMLP for context embedding and CRF for explanations. The numbers are averages from 5-fold cross-validation;the std. are on the order of the least significant digit. @K denotes the temporal quantile, i.e., the time point suchthat K% of the patients in the data have died or were censored before that point.
Table 3:	Top-performing architectures used in our experiments on MNIST and IMDB datasets.
Table 4:	Top-performing architectures used in our experiments on CIFAR10 and Satellite datasets.
Table 5:	Top-performing architectures used in our experiments on SUPPORT2 and PhysioNet 2012 datasets.
