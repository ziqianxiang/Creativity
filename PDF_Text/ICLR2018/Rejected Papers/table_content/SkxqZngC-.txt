Table 1: Comparison of perplexity (lower is better) and topic coherence comparison (higher is better)of different topic models on 20News and RCV1-V2 datasets. The symbol ”-” indicates either themodel fails to converge within 24 hours, or the original paper does not provide the correspondingvalues.
Table 2: Number of effective topics learned by iTM-VAE-Prod on subsets of 20News dataset.
Table 3: Learned posterior distribution of α and number of effective topics learned by iTM-VAE-Gon subsets of 20News dataset.
Table 4: Top 10 words of topics learned by iTM-VAE-Prod without cherry picking.
Table 5: Top 10 words of some redundant topics learned by ProdLDA.
