Table 1: MNIST results of various models based on FNN-784-300-100-10. The number of parame-ters and FLOPs are shown as multiples of the baseline FNN trained by SGD, the specifics of whichare shown in parentheses. PR: Pruning and Retraining, GSP: Group Sparse Prior.
Table 2: Detailed structure information of various FNN ensembles based on FNN-784-300-100-10for MNIST.
Table 3: Model ablations for the new method SGLD+GSP+PR based on the medium LSTM LMsover PTB. The column of single model denotes the lowest PPL obtained by a single model in theensemble. The number of parameters and FLOPs are shown as multiples of the baseline mediumLSTM trained by SGD, the specifics of which are shown in parentheses. The grouping strategy isthe untied weight strategy by default, unless specified in parentheses. Tied W denotes tied weightstrategy and ISS denotes Intrinsic Sparse Structures as in Wen et al. (2017)Method	Model	Parameters	FLOPs	Single model		Ensemble					Dev.	Test	Dev.	TestSGD (Zaremba, 2014)	1	1 (19.8M)	1 (26.5M)	86.2	82.1	—	—SGD (Zaremba, 2014)	10	10×	10×	-	-	75.2	72.0SGLD	10	10 ×	10×	87.0	83.7	80.5	78.9SGLD+PR	10	1×	10×	103.8	100.2	91.1	89.4SGLD+GSP	10	10×	10×	98.8	97.0	88.0	86.9SGLD+GSP+R	10	10×	10×	80.0	76.3	70.8	69.1SGLD+GSP+P	10	1×	4×	103.8	101.9	96.1	94.7SGLD+GSP+PR	10	1×	4×	79.8	76.6	71.5	69.5SGLD+GSP+PR (tied W)	10	1×	4×	79.7	76.6	70.9	69.2SGLD+GSP+PR (ISS)	10	1×	3×	80.9	77.4	71.8	69.9(a)(b)
Table 4: Detailed structure information for various large LSTMs. The FLOPs of LSTM layer 1, L-STM layer 2 and softmax layer are shown in three columns respectively. The embedding layer is notlisted here since it is a table lookup process instead of matrix calculation. The results of our methodare the statistics from a single model sample from the ensemble trained by SGLD+GSP+PR. Thesize of the reduced LSTM model learned by our method with ISS is 365, 311 and 420 for embeddinginput, 1st LSTM layer and 2nd LSTM layer respectively. For shared embeddings (denoted as SE),the layer sizes are 456, 352 and 456 respectively.
Table 5: Comparison of various models based on LSTMs on PTB dataset. The number of parametersand FLOPs are shown as multiples of the baseline medium LSTM trained by SGD, the specificsof which are shown in parentheses. The bold line denotes the best result obtained with sharedembeddings (denote as SE).
