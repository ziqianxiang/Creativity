Table 1: Results on Chinese Gigaword. In row (B), we select the article’s first fifteen words as itssummary. Part (C) are the results obtained without paired data.
Table 2: Results on English Gigaword: In row (B-1), we select the article’s first eight words as itssummary. In row (B-2), we match the documents to their most relevant summaries with unsuper-vised method. Part (C) are the results obtained without paired data. In part (D), we pre-trainedthe generator on CNN/Diary. In part (E), we not only pre-trained on CNN/Diary but also used thesummaries from CNN/Diary as real data for the discriminator.
Table 3: Adversarial REINFORCE with/without self-critic with unsupervised training.
Table 4: Semi-supervised learning in Chinese Gigaword with different amounts of labeled data(10K, 50K, 100K).
Table 5: Semi-supervised learning in English Gigaword with different amounts of labeled data (10K,50K, 100K).
