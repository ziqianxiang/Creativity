Figure 1: Instantiation of the idea in a HRED (Decoder is not shown in the figure). When the encoderRNN encounters a NE, the representation of the dialog so far (htd-1), the sentence representation ofthe current user utterance so far (htx,,ie-n1c) and the NE type information are used to generate a neuralembedding (zine) on the fly and is stored in the NE-Table as key along with the NE xt,i associatedwith it stored as the value. Here the DB retrieval system generates a key to match the keys in the NE-Table to retrieve the value (e.g. EECS 545) it is interested in. It can for example match (exact) overan attributeâ€™s (e.g. Course Number) values in an external DB (along with other required actions) toretrieve information from the DB (e.g. the name of the faculty who teaches the course with coursenumber EECS 545).
Figure 2: Multiple-attention based neural retrieval mechanism. When the encoder RNN encountersa NE, it generates a key representation for it and stores it in the NE-Table. When the dialog man-ager/decoder RNN wants to retrieve information from the DB, it attends to the relevant rows andcolumns of the DB by generating attention key embeddings. While matching (to get the attentionscores), in the case of non-NE information in the DB, their neural embeddings are matched withthe key embeddings directly. For the NE information in the DB, exact matches are done using theNE values retrieved from the NE-Table, which in turn are retrieved by matching the attention keyembeddings with the key embeddings of the NEs in the NE-Table.
