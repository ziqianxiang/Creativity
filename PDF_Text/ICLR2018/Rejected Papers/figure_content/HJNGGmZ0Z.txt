Figure 1: The cosine distance matrix between six groups (three MSCOCO categories and pairwiseCombinationS of the three CategorieS) from the train dataSet. EaCh group iS repreSented by the averageimage feature of 25 randomly SeleCted imageS from the Category or Combination of CategorieS.
Figure 2: Visualization of the t-SNE projection of initial representational space (left) vs. the trans-formed representational space (right). See main text for a more detailed discussion.
Figure 3: Distributions over train and test sets Figure 4: Distributions over train and Flickr testWe evaluate the captions generated by our model with Resnet152 pool5 representation and by twoother state-of-the-art models pretrained on MSCOCO: a) Self-Critical (SC) (Rennie et al., 2016)based on self critical sequence training that uses reinforcement learning using metrics, and b) BottomUp and Top Down (TDBU) (Anderson et al., 2017) based on top-down and bottom-up attention usingobject region proposals. Both the state-of-the-art models are much more complex than the imageconditioned RNN based language model. The results are summarized in Table 3.
Figure 5: Example outputs from our system with different representations, the sub-captions indicatethe annotation along with the frequency in braces. We also show the CIDEr score and the differencein CIDEr score relative to the Bag of Objects representation.
