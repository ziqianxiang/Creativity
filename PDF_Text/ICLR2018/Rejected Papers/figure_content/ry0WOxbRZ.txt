Figure 1: Illustration of the IVE-GAN architecture.
Figure 2: Density plots of eight mixtures of Gaussians arranged in a ring. Panel (a) shows the truedata and panels (b-g) show the generator distribution at different iteration steps of training.
Figure 4: Three rows of MNIST samples. First row: original samples x from the MNIST trainingdataset. Second row: generated reconstructions G(E(x)) of the original samples x from a IVE-GANwith 16-dimensional latent space. Third row: generated reconstructions G(E(x)) of the originalsamples x from a IVE-GAN with 3-dimensional latent space.
Figure 5: Representation of the MNIST dataset using the 3-dimensional latent space learned by theIVE-GAN. The colors correspond to the digit labels.
Figure 6: Original samples x from the CelebA dataset, their random transformation T (x) and thegenerated reconstructions G(E(x)).
Figure 7: Generated samples with same randomly drawn latent representation Z 〜 PnoiSe verticallyand same randomly drawn noise component z0 〜 PnOiSe horizontally.
Figure 8: Visualization of the 2-dimensional t-SNE of the 1024-dimensional latent representation of10.000 CelebA images. (a): Example images for some of the high-density regions of the embedding.
Figure 9: Illustration of interpolation in the latent space between 3 pairs of original images re-spectively. The first and the last image in each row are original images from the CelebA dataset.
Figure 10: Samples and reconstructions on the CelebA dataset by ALI. Odd columns are originalsamples and even columns are corresponding reconstructions. Images taken from the original paper(Dumoulin et al., 2016).
Figure 11: Latent space interpolations on the CelebA dataset by ALI. Images taken from the originalpaper (Dumoulin et al., 2016).
