Figure 1: Solving complex tasks by planning in attributespace. Each state is mapped to a set of binary attributes (or-ange/purple dots). Our semi-parametric model comprises agraph over sets of attributes (e.g. “there is a blue block leftof the red block”), with edge weightings according to the prob-ability that a parametric policy network is able to transition be-tween adjacent pairs. The attributes themselves are manuallyspecified, but inferred from the observation through a neuralnetwork; and the graph structure and policy are learned duringtraining via random exploration of the environment. Given agoal attribute set (green), we use the graph to find the short-est path (red) to it in attribute space. The policy network thenexecutes the actions at each stage (gold arrows).
Figure 2: Left: Crafting mazebase game. Right: Colored switches game. See text for details.
Figure 3: Two examples of block stacking evaluation tasks. The initial/target states are shown in thefirst/last columns. Successful completions of our Attribute Planner model are shown in rows 1 and3. By contrast, the A3C baseline is unable to perform the tasks (rows 2 and 4).
Figure 4: Plans become stuck when states with different transitions map to the same properties. Inframe 4 of this example, the policy is directed to place the green block in front of the red and blueblocks, but this is impossible because the blue and red are already in the frontmost position.
