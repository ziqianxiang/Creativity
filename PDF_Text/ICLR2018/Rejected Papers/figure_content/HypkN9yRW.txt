Figure 1: Visualization of the DDRprog architecture. This configuration answers ”How many thingsare red or spheres?” by predicting [filter _red, fork, filter—Sphere, union, count]3	DDR ArchitectureThe purpose of the DDR framework is to naturally incorporate structured information into a neuralreasoning architecture. This is important when the given problem is hard without additional super-vision and allows the model to perform discrete, complex reasoning. Our framework addresses thedifficulty of combining discrete logic with clean, differentiable training and is capable of interfacingwith a broad range of data structures. Our framework is a clean fusion of two broad design pat-terns. Like IEP, we maintain a set of problem-specific neural modules to allow our model to learnrelevant program primitives. Like NPI, we interleave program prediction with program execution,differentiably learning modules when module arrangement is not known at test time.
Figure 2: Visualization of the DDRstack architecture with n = 1. This particular configurationevaluates the [NUM][NUM][OP] formatted expression [0.4, 0.8, /], which is 0.4/0.8=0.5. NUMtokens are embedded before being passed to the LSTM. OP tokens are used as an index to selectthe corresponding cell. LSTM predictions at each OP token are used to predict intermediate losses(there is only one for n = 1).
Figure 3: Left: Training curves for DDRstack (train/val overlapping, 17k parameters) and theLSTM128 baseline (255k parameters) on RPN10. Right: Generalization performance of DDRstackand the LSTM baseline to RPN30 after training on RPN10.
