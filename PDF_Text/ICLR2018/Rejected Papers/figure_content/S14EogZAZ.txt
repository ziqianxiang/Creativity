Figure 1: Target stacking: Given a target shape image, the agent is required to move and stack blocksto reproduce it.
Figure 2: Example scenes constructed by the learned agent.
Figure 3: Our proposed model GDQN which extends the Q-function approximator to integrate goalinformation.
Figure 4: Reward shaping used in target stacking. (a): overlap ratio to the target. The gray area inthe middle figure denotes the intersected foreground region between current and target scene, andthe overlap ratio is the ratio between the areas of the two. (b): distance under the distance transformof the target. The middle figure denotes the distance transform under the target shown in the left.
Figure 5: a: Navigation task in gridworld. Each color denotes a different episode, for each episode, arandom pair of starting and goal location are generated, the agent needs to reach the goal. b: Resultsfrom navigation task.
Figure 6: a: Targets for 2 blocks.b: Targets for 3 blocks. c: Targets for 4 blocks.
