Figure 1: Graphical models describing two of four possible generative processes for the two-contextcase. Again, we emphasize that the generative model is not specified until a is sampled. (a) c(1) isheld constant while c(2) varies. (b) Vice versa. Each edge in the model specifies a neural network,and multiple incoming edges concatenate their information for input to the receiving node. Eachnode outputs a parameterization of a distribution over its corresponding variable.
Figure 2:	Generated samples from rotated MNIST. (a) The model is asked to generate data sets withneither contexts held constant, yielding sets of random digits with random rotations. (b) The model isasked to generate data sets with both digit and rotation held constant.
Figure 3:	Conditional samples using rotated MNIST digits. The top two rows show the conditioningsets, while the bottom eight rows depict samples given these inputs. Note how the generated samplesexhibit the constant aspects of both conditioning sets.
Figure 4: Conditional samples of faces from CelebA. The top three rows depict data sets whichexhibit a shared context, namely smiling, wearing glasses, and wearing a hat, respectively. Thebottom seven rows are generated by calculating the mean of the approximate posterior over theconstant context for each conditioning data set, and sampling using these constant values. The goalis to generate data sets which are constant in all three contexts (i.e. smiling, wearing glasses, andwearing a hat). Note the model has only been trained on data sets with a single shared context, nevermultiple, and that we do not provide the model with information as to the nature of this context.
