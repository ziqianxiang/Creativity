Figure 1: Overview of our two-stage method for learning SSEs.
Figure 2: Illustration of different grouping strategies for LSTMs. In figure (a) and (b), the blacklines in each weight matrix represent non-zero elements and the yellow areas are rows and columnswith all zeros, as a result of group selection enforced by GSP. The horizontal arrows indicate theinput and hidden units used in calculations, and the vertical arrows point to those dimensions ofa gate to be updated. Thus it is enough to do calculations by the reduced matrix formed by theseblack rows and columns in the figure instead of the whole matrix. In figure (c), the dash white linesseparate each weight matrix of tied W matrix. Yellow lines indicate the weights associated with acertain hidden unit in LSTM layer l, which are removed simultaneously to reduce the hidden size ofh(l).
Figure 3: (a) The PPL curves along the learning of LSTM ensemble by SGLD+GSP+PR over thePTB development set. It is worthwhile to note that as the training proceeds, more models are aver-aged, which consistently improves the PPLs. (b) The PPLs over development set v.s. the number ofmodels in the LSTM ensembles by SGLD+GSP+PR.
Figure 4: The sparse structure patterns of the weight matrices from a sample LSTM model trainedby applying SGLD with GSP. Yellow areas are all zeros while black dots stand for non-zero weights.
