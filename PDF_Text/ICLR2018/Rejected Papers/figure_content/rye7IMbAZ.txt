Figure 1: Accuracy on Stanford Dogs 120 for L2-SP, according to the two regularization hyper-parameters α and β respecively applied to the layers inherited from the source task and the lastclassification layer (see Equation 3).
Figure 2: Classification accuracies of all tested approaches using ImageNet or Places 365 as sourcedatabases on four target databases. All -SP approaches outperform L2 . Related source task gainsmore performance for the target task.
Figure 3: Classification accuracies of fine-tuning with L2 and L2-SP on Stanford Dogs 120 (top) andCaltech 256 -30 (bottom) When freezing the first n layers ofResNet-101. The dashed lines representthe accuracies in Table 2, where no layers are frozen. ResNet-101 begins with one convolutionallayer, then stacks 3-layer blocks. The three layers in one block are either frozen or trained altogether.
Figure 4: R2 coefficients of determination with L2 and L2 -SP regularizations for Stanford Dogs 120training examples. Each boxplot summarizes the distribution of the R2 coefficients of the activationsafter fine-tuning with respect to the activations of the pre-trained network, for all the features in onelayer. ResNet-101 begins with one convolutional layer, then stacks 3-layer blocks. We display hereonly the R2 at the first layer and at the outputs of some 3-layer blocks.
