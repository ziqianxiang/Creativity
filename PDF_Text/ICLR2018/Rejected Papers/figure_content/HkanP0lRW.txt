Figure 1: (a) Each original image and mask is split by pixel producing a dataset comprising 512-dimensional image vectors with an associated mask scalar. (b) Uniform random undersampling isused to balance the dataset before being undergoing a 80/10/10 Training/Validation/Test split. (c)Median values of example trace (5) from the 48 hour collection dataset.
Figure 2: (a) The densely connected feed-forward neural network used in the classification task.
Figure 3: (a) Confusion matrix for the densely connected feed-forward neural network. (b) Samplecrops of original 48hr images, ground truth masks, generated masks and error. BG is coded 0; N+is coded 1; N- is coded 2. (c) Sample images from 48hr with dense network pixel classificationoverlaid. N+ is orange; N- is yellow; BG is transparent.
Figure 4: (a) The validation accuracy is plotted against the number of removed dimensions. Yellowvertical lines represent a point where the network is re-trained. The algorithm was halted after 20 re-training iterations; we set Ï„ = 0.005. (b) Individual frequencies labeled according to their removalorder. Frequencies increase left-to-right, top-to-bottom. Darker colors are those removed earlier.
