Figure 1: A diagram of the function of the Gaussian prototypical network. An encoder maps animage into a vector in the embedding space (dark circles). A covariance matrix is also output foreach image (dark ellipses). Support images are used to define the prototypes (stars), and covariancematrices (light ellipses) of the particular class. The distances between centroids, and encoded queryimages, modified by the total covariance of a class, are used to classify query images. The distancesare shown as dashed gray lines for a particular query point.
Figure 2:	An example of augmentation of class count by rotations. An original character (on theleft) is rotated by 90。, 180。, and 270。. Each rotation is then defined as a new class. This enhancesthe number of classes, but also introduces degeneracies for symmetric characters.
Figure 3:	Comparison of two methods of allocation of extra parameters. Allocating extra parametersto increase embedding space dimensionality (radius), or making a more precise covariance estimate(diagonal). The radius estimate (1 additional real number per embedding vector) outperforms thediagonal estimate with the same number of parameters.
Figure 4: The effect of down-sampling a part of the training set on k-shot test accuracy. The networktrained on purposefully damaged data outperforms the one trained on unmodified data, as it learnsto utilize covariance estimates better.
Figure 5: Predicted covariances for the original test set and a partially down-sampled version ofit. The Gaussian network learned to down-weight damaged examples by predicting a higher s, asapparent from the heavier tail of the yellow distribution. The distributions are aligned together, asonly the difference between the leading edge and a value influence classification.
