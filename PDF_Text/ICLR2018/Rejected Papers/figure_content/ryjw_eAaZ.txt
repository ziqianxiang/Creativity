Figure 1: An example of a structure learned by our algorithm (classifying MNIST digits). Neuronsin a layer may connect to neurons in any deeper layer. Depth is determined automatically. Eachgather layer selects a subset of the input, where each input variable is gathered only once. A neuralroute, starting with a gather layer, passes through densely connected layers where it may split (copy)and merge (concatenate) with other routes in correspondence with the hierarchy of independenciesidentified by the algorithm. All routes merge into the final output layer (e.g., a softmax layer).
Figure 2:	[a] An example of a Bayesian network encoding ground-truth conditional independencies(a DAG underlying observed data) and [b] a corresponding CPDAG (GX) constructed by testing onlymarginal independencies. Only A and B are marginally independent (d-separated in [a], A ⊥⊥ B),where C and D are marginally dependent (C ⊥6⊥ D) and therefore connected in [b]. Thus, nodes{C, D, E}, having the lowest topological order, form a descendant set XD = {C, D, E} and nodesA and B form two distinct ancestor sets, XA1 = {A}, XA2 = {B}—disjoint if {C, D, E} isremoved from the graph.
Figure 3:	[a] An example of a graph G (corresponding to GX in Figure 2-[b]). [b] A stochasticinverse generated by the algorithm presented by Stuhlmuller et al. (2013). [c] A stochastic inversegenerated by our method where the graph is a projection of a latent structure. A dependency inducedby a latent Q is described using a bi-directional edge HA - HB. [d]A discriminative structure GDhaving a class node Y that provides an explaining away relation for HA - HB. That is, the latentQ is replaced by an observed common child Y .
Figure 4:	An example trace of Algorithm 2 where p(X) is faithful to the DAG in Figure 3-[a].
Figure 5:	An example of [a] a structure G (the corresponding auxiliary graph GX is depicted inFigure 2-[a]), [b] its stochastic inverse GInv described as a projection of another latent structure,and [c] a corresponding discriminative model obtained by expressing dependency relations amonglatents (bi-directional edges) with an “explaining away” relation induced by a class node.
Figure 6: Accuracy as a function of network size. [a] MNIST, [b] SVHN. [c] CIFAR-10. Error barsrepresent 2 standard deviations.
