Figure 1: The generator of our ICW-GAN. The 128 dimensional encoding Z is drawn from a multi-variate normal distribution. The label vector is a one-hot encoding, i.e., the one entry that equalsone represents the class that the generated volume belongs to. It is concatenated to input and hiddenlayers and for each of these layers, a fully connected layer transforms the label vector to a volume.
Figure 2: The classifier (top) and critic (bottom) in our ACD-GANs. The classifier and the criticpossess a similar architecture but not identical in terms of the output and leveraging of labels. Thelabel is only employed in the critic, not in the classification stream. The way to transform the labelvector and the stride are identical to what we illustrated in Figure 1.
Figure 3: 2D projections of synthetic brain volumes generated using the proposed ICW-GAN. Thetraining dataset is collection 1952. The tag above each image sequence shows the class the pic-ture belongs to. Qualitative evaluation by experts suggests that the generated images are indeedqualitatively realistic.
Figure 4: Mean MS-SSIM scores between pairs of images within a given class for brain volumes of4.0× downsampling (left) and 2.0× downsampling (right). We calculated the MS-SSIM scores onlow resolution data of collection 1952 and synthetic data was generated using the ICW-GAN. Eachpoint represents an individual class. Values in horizontal axis are MS-SSIM scores computed onreal brain images, while values on the vertical axis are calculated using mixed images.
Figure 5: 2-D projections of synthetic brain volumes by ACD-GAN using training data from Col-lection 503 (4.0× downsampling). The left top tag is the class generated brain belongs to (details inthe supplement). Each class represents a picture being shown to the subjects. Linear normalizationis used and the lower threshold is 0.3.
Figure 6: Cartoon illustration of our 3-fold cross validation strategy.
Figure 8: This figure shows the trajectory of multiclass accuracy along with the number of artificialtraining samples resembling collection 1952 at the low resolution setup. In this case, we only usegenerated data from the ICW-GAN to train the deep net classifier. The horizontal axis represents thenumber of artificial data used for each class, while the vertical axis represents the accuracy value.
Figure 7: Training loss curve of the ICW-GAN on the low-resolution validation dataset of collection1952.
Figure 9: The projections of a generated brain volume (left) and its corresponding analysis report(right). The volume belongs to the class ‘Non-human sound, auditory.’6.6	Additional Multiclass Classification ResultsWe also examine our models using a multilabel classification strategy in low resolution data ofcollection 1952. As described before, one class in collection 1952 consists of several labels andthe collection has a total of 19 sub-labels. Instead of encoding the classes with a one-hot vectorof 45 dimensions, we encode them in 19 dimensions, each of which represents a sub-label. Thevalue in a dimension is 1 only if the sample possesses that label, otherwise, 0, i.e., a sample comeswith a 19 dimensional binary vector. This representation is demanding since the probability space issignificantly larger, specifically, 219 possibilities, for a classifier to learn and discriminate. We useSVM to train real and mixed training data (synthetic data obtained from ICW-GAN), both of which3The webpage of NeuroSynth is http://neurosynth.org/decode/12Under review as a conference paper at ICLR 2018Input	Accuracy	Macro F1	Precision	RecallReal	0.4838	0.57	0.76	0.48Real+Synth.	0.4992	0.57	0.75	0.49Table 7: Multilabel results for collection 1952 at 4.0× downsampling and synthetic data were fromthe ICW-GAN. Even in this highly demanding task, accuracy scores with mixed data (the secondrow) outperform the baseline (the first row).
Figure 10: Real images in collection 1952 at 4.0× downsampling with labels on top. Linear nor-malization is used and the lower threshold for plotting these images is 0.48.
Figure 11: 4.0× downsampled brain images in Collection 1952 generated by ICW-GAN with labelson top. The lower threshold for plotting these images is 0.3.
Figure 12: 8.0× downsampled brain images in collection 2138 generated by ICW-GAN. A lefttop tag is the class generated brains belong to and we list their corresponding categories in thesupplementary material as well.
Figure 13: 6.0× downsampled brain images in collection 503 generated by ICW-GAN and a left toptag represents the stimulating picture for subjects.
