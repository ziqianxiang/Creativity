Figure 1: Sequential Experiments (1 worker) with Hyperband running synchronous SHA. Hyper-band (by rung) records the incumbent after the completion of a SHA rung, while Hyperband (bybracket) records the incumbent after the completion of an entire SHA bracket. The average test erroracross 10 trials of each hyperparameter optimization method is shown in each plot. Dashed linesrepresent min and max ranges for each tuning method.
Figure 2: Limited-scale distributed experiments with 25 workers using asynchronous SHA. Foreach bracket, the average test error across 5 trials is shown in each plot.
Figure 3: Large-scale experiments that take on the order of weeks to run. The x-axis is measuredin units of average time to train a configuration, i.e. 4R indicates 4× the time to train an averageconfiguration. Due to the high computational cost, progress for a single trial is shown in each chart.
Figure 4: For a fixed time budget, we chart the estimated number (according to the Paleo performancemodel) of configurations evaluated by 128 Tesla K80s as a function of the number of GPUs used totrain each model. The dashed line for each color represents the number of models evaluated underperfect scaling, i.e. n GPUs train a single model n times as fast, and span the feasible range fornumber of GPUs per model in order to train within the allocated time budget. (a) Imagenet usingInception V3 takes 24 days to train on a single GPU. Hence, for a time budget of 6 days, the numberof GPUs per model must offer at least 4× speedup over a single GPU in order to be feasible. Underperfect scaling, 128 = 27 GPUs with 1/4 the time to train a model on a single GPU would be able totrain 25 models. The curve shows that using 8 = 23 GPUs per model achieves nearly linear scalingand increasing the number of GPUs per model decreases the total number of models that can beevaluated by 128 GPUs. (b) The same tradeoff curve for other time budgets is shown. As expected,smaller time budgets requires more GPUs per model, but the additional training speed comes at theexpense of fewer evaluated models.
