Figure 1: The proposed PrivyNet framework: the local NN is derived from pre-trained NNs forfeature extraction and the cloud NN is trained for the target learning task. Privacy and utility trade-offis controlled by the topology of the local NN.
Figure 2: Privacy and utility characterization flow.
Figure 3:	Impact of FEN topology on utility and privacy: (a) dependency of utility; (b) dependencyof privacy; (c) utility and privacy trade-off.
Figure 4:	Difference on utility and privacy for single channel in the 4th and 6th VGG16 layer.
Figure 5:	Comparison between the impact on utility and privacy of output channel selection and thenumber of FEN layers ((a) and (b)) and output depth ((c) and (d)).
Figure 6: Overall flow of PrivyNet to determine the FEN topology.
Figure 7: Privacy characterization: (a) small amount of samples are needed for the characterizationwith data augmentation; (b) and (c) very similar privacy characterization results can be acquired ondifferent datasets, which indicates IRN can be trained on public data.
Figure 8:	Relation between privacy and perfor-mance/storage with FEN topologies.
Figure 9:	Difference on utility and privacy in-duced by random output channel selection.
Figure 10: Utility and privacy relation for single	Figure 11: Comparison with random strategychannel: (a) m = 4, (b) m = 6.	on pruning the worst (a) 32 and (b) 64 channels.
Figure 12: The number of samples required for the LDA-based pruning (mini-batch size is 128).
Figure 13: Utility and privacy comparison for the three settings, including random selection withoutpruning (1st Set.), random selection after pure characterization-based pruning (2nd Set.) and randomselection after LDA-based pruning.
Figure 14:	Impact of pruning the first layer of FEN on (a) accuracy, (b) privacy, and (c) local compu-tation. The channel depths of the four convolution layers for the four settings are {64, 64, 128, 8}(baseline), {48, 64, 128, 8}, {32, 64, 128, 8}, {16, 64, 128, 8}, respectively.
Figure 15:	Impact of pruning each convolution layer step by step on (a) accuracy, (b) privacy, and(c) local computation. The channel depths of the four convolution layers for the four settings are{64, 64, 128, 8} (baseline), {32, 64, 128, 8}, {32, 32, 128, 8}, {32, 32, 64, 8}, respectivelyBy channel selection for intermediate layers, even if the attackers can know the pre-trained NN thatour FEN is derived from, it is still very hard to determine the number of layers for the FEN and thenumber of channels for each layer. In this way, the anonymity of the FEN can be well protected.
Figure 16:	Full VGG16 architecture.
Figure 17: IGN architecture from Google example1.
Figure 19: Determine IRN architecture.
Figure 18: Architecture of the IRN and the ResNet block.
Figure 20: Performance profiling for VGG16 on (a) a mobile class CPU; (b) a server class CPU; and(c) storage profiling (batch size is 1 and input size is (32, 32, 3)).
Figure 21: Example 1: Impact of number of layers and output depth on the quality of reconstructed im-ages: the output depths are {64,32,16,8,4, 2} for the first three rows and are {128,64,32,16,8,4,2}for the last three rows (original figures are selected from CIFAR-10 dataset).
Figure 22: Example 2: Impact of number of layers and output depth on the quality of reconstructed im-ages: the output depths are {64,32,16,8,4, 2} for the first three rows and are {128,64,32,16,8,4,2}for the last three rows (original figures are selected from CIFAR-10 dataset).
Figure 23: Example 3: Impact of output channel selection on the quality of reconstructed images,m = 6, D0 = 4.
Figure 24: Example 4: Impact of output channel selection on the quality of reconstructed images,m = 6, D0 = 16.
