Figure 1: Properties of hyperbolic space. a Multiple parallel lines passing through a single point. bAll tiles are of constant area in hyperbolic space, but shrink to zero area at the boundary of the disk inEuclidean space. c Hub and spokes graph. It is impossible to embed this graph in two-dimensionalEuclidean space and preserve the properties that (1) all spokes are the same distance from the hub,(2) all spokes are the same distance from each other, and (3) the distance between spokes along thecircumference is more than twice the distance to the hub. In hyperbolic space such embeddings exist.
Figure 2: a The skipgram architecture. The model predicts the context vertices from a single inputvertex. The final embedding is the set of learned weights W. b In the model updates, the vectorrepresentation of the context vertex vw0(nOew) is moved closer (blue) to the vector representation of theinput vertex vI , while all other vectors vw0(jnew) move further away (red). The magnitude of the changeis proportional to the prediction error.
Figure 3: Comparison between the embeddings of a complete 4-ary tree with three levels. Hyperbolicembeddings are able to represent the trees branching factor and position the root at the location of theshortest path length. The Euclidean embedding can not reproduce the isometries of the tree.
Figure 4: The two factions of the Zachary karate network are linearly separable when embeddedin 2D hyperbolic, but not Euclidean space. Both embeddings were run for 5 epochs on the sameintermediate random walks.
Figure 5: Each row contains a line plot of macro F1 score for predicting held-out vertex labelsfrom embedded representations using logistic regression together with the HyBed and 2D Euclideanembeddings. Error bars are standard errors from the mean over ten repetitions.
