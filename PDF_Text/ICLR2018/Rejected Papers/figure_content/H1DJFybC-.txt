Figure 1: (a): Model learns to convert hand drawings (top) into LATEX (rendered below). (b)Synthesizes high-level graphics program from hand drawing.
Figure 2: Both the paper and the system pipeline are structured around the trace hypothesisThe new contributions of this work are: (1) The trace hypothesis: a framework for going fromperception to programs, which connects this work to other trace-based models, like the NeuralProgram Interpreter (Reed & de Freitas, 2015); (2) A model based on the trace hypothesis thatconverts sketches to high-level programs: in contrast to converting images to vectors or low-levelparses (Huang et al., 2017; Nishida et al., 2016; Wu et al., 2017; Beltramelli, 2017; Deng et al., 2017).
Figure 3: Our neural architecture for inferring the trace set of a graphics program from its output.
Figure 4: Parsing LATEX output after training on diagramswith ≤ 12 objects. Model generalizes to scenes with manymore objects. Neither SMC nor the neural network aresufficient on their own. # particles varies by model: wecompare the models with equal runtime (≈ 1 sec/object)3Under review as a conference paper at ICLR 2018essary to parse complicated scenes, we compared the neural network with SMC against the neuralnetwork by itself or SMC by itself. Only the combination of the two passes a critical test of general-ization: when trained on images with ≤ 12 objects, it successfully parses scenes with many moreobjects than the training data. We compare with a baseline that produces the trace set in one shot byusing the CNN to extract features of the input which are passed to an LSTM which finally predictsthe trace set token-by-token (LSTM in Fig. 4). This architecture is used in several successful neuralmodels of image captioning (e.g., Vinyals et al. (2015)), but, for this domain, cannot parse clutteredscenes with many objects.
Figure 5: Left to right: Ising model, recurrent network ar-chitecture, figure from a deep learning textbook Goodfellowet al. (2016), graphical modelFigure 6: Near misses. Right-most: illusory contours (note:no SMC)3 Synthesizing graphics programs from trace setsAlthough the trace set of a graphics program describes the contents of a scene, it does not encodehigher-level features of the image, such as repeated motifs or symmetries. A graphics program betterdescribes such structures. We seek to synthesize graphics programs from their trace sets.
Figure 6: Near misses. Right-most: illusory contours (note:no SMC)3 Synthesizing graphics programs from trace setsAlthough the trace set of a graphics program describes the contents of a scene, it does not encodehigher-level features of the image, such as repeated motifs or symmetries. A graphics program betterdescribes such structures. We seek to synthesize graphics programs from their trace sets.
Figure 7: How close are the model’s out-puts to the ground truth on hand draw-ings, as we consider larger sets of sam-ples (1, 5, 100)? Distance to groundtruth trace set measured by the intersec-tion over union (IoU) of predicted vs.
Figure 8: How long does it typically take to synthesize a minimum cost program? Sketch: out-of-the-box performance of the Sketch (Solar Lezama, 2008) program synthesizer. Oracle: upper boundsthe performance of any search policy. Learned policy: a bias-optimal learned search policy runningon an ideal timesharing machine. ∞ = timeout. Red dashed line is median time. Learned policyevaluated using 20-fold cross validation.
Figure 9: Left: hand drawings. Cen-ter: interpretations favored by thedeep network. Right: interpretationsfavored after learning a prior overprograms. The prior favors simplerprograms, thus (top) continuing thepattern of not having an arrow is pre-ferred, or (bottom) continuing the“binary search tree” is preferred.
Figure 10: Top, white: hand drawings. Bottom, black: extrapolations produced by our system.
Figure 1: Left: hand drawing. Center: interpretation favored by the deep network. Right: interpreta-tion favored after learning a prior over programs. Our learned prior favors shorter, simpler programs,thus (top example) continuing the pattern of not having an arrow is preferred, or (bottom example)continuing the binary search tree is preferred.
Figure 2: PCA on features of the programs that were synthesized for each drawing. Symmetricfigures cluster to the right; “loopy” figures cluster to the left; complicated programs are at the top andsimple programs are at the bottom.
Figure 3: MDS on drawings using the learned distance metric, LIearned(∙∣∙). Drawings with similarlooking parts in similar locations are clustered together.
Figure 4: Our neural architecture for inferring the trace set of a graphics program from its output.
Figure 5: Example synthetic training dataexactly match the pixels in the target image. We use:{α, iflι[χ,y] > I2[χ,y]β, ifI1[x,y] < I2[x, y]	(12)0, ifI1[x,y] = I2[x, y]where α, β are constants that control the trade-off between preferring to explain the pixels in theimage (at the expense of having extraneous pixels) and not predicting pixels where they don’t exist(at the expense of leaving some pixels unexplained). Because our sampling procedure incrementallyconstructs the scene part-by-part, we want α > β. That is, it is preferable to leave some pixelsunexplained; for once a particle in SMC adds a drawing primitive to its trace that is not actually inthe latent scene, it can never recover from this error. In our experiments on synthetic data we usedα = 0.8 and β = 0.04.
