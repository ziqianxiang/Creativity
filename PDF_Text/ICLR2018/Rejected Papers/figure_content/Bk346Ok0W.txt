Figure 1: STAN model architecture for a setup with two video sensors.
Figure 2: Attention response of a two-sensor STAN model trained on audio (TIDIGITS, left) and video(GRID, right) to random walk noise (top), linear noise sweeps (middle) and noise bursts (bottom).
Figure 3: WER on (a) TIDIGITS and (b) GRID for clean and noisy test sets. The TIDIGITSresults are based on 5 parameter initializations, while the GRID results are based on 4 parameterinitializations.
Figure 4: Attention weights per channel averaged over all environments on ’et05_real’, CHiME-3.
Figure 5: Filter bank features (top) of the sample ’M05_443C020Q_BUS’ from CHiME-3 andattention response of STAN-default (middle) and STAN-shared (bottom). The channels are color-coded. For better visibility of the channel differences, the features plot has been clipped to the range-3 to 3. The attention generally follows the signal quality, with clear suppression of the attention onthe corrupted channels 1, 2 and 4. Note how the attention on channel 4 is initially high, but thensuppressed when the channel is temporarily corrupted after frame 120. The attention response ofSTAN-shared is more interpretable.
Figure 6: Partial WER computed up to the number of most corrupted samples for (a) STAN-defaultand (b) STAN-shared. The WER is given relative to the concatenation model. The advantage ofSTANs is especially large if samples suffer channel corruption.
Figure 7: Depiction of the random walk noise added during training. In (a), the cumulative sum of asequence of random variables forms a random walk. In (b), the random walk becomes bounded afterapplying the reflection operator φ in Eq. 4. On the four sub-panels in (c), a visualization of the noisedrawn at each time point. Each panel depicts a video frame from the GRID corpus, zero mean andunit variance normalized, mixed with a Gaussian noise source whose standard deviation correspondsto a vertical dotted line in (b).
Figure 8: Corrupted channels - none. This sample shows the native attention response when nochannel is corrupted, that could otherwise be interpreted as the bias towards channels. STAN-sharedseems to express no channel preference, while STAN-default prefers channels ch4 and ch5. Themerged representations appear smoother than the single channels.
Figure 9: Corrupted channels - ch2. This sample is representative for most of the real evaluation set:the backward channel 2 is slightly corrupted, while the other channels seem similar. Remarkably,STAN-shared is able to detect the backward channel although the attention module weights areshared across channels. It seems that the STAN-shared attention modules are able to simultaneouslycompute high attention scores on channels with high SNR and low attention scores on channels withlow SNR, even in the presence of natural noise.
Figure 10: Corrupted channels - ch5. Even though the preferred channel of STAN-default is corrupted,the attentional mechanism is able to tune in on the other channels, especially channel 4. The mergedrepresentations appear unaffected by the heavily corrupted channel 5.
Figure 11: Corrupted channels - ch2/6. Both STAN variants reduce their attention towards channel 6at the end of the sequence, where channel 6 seems most corrupted. Channel 2 is suppressed over thewhole sequence.
Figure 12: Corrupted channels - ch2/3/4. The attention roughly follows the signal quality, withclear suppression of the attention on the corrupted channels 2, 3 and 4. The attention responseof STAN-shared is more interpretable. The merged representations are less noisy than the singlechannels, while still resolving fine details as between frames 550 and 600.
Figure 13: Corrupted channels - ch1/2/4. This is the plot from the main section (Figure 5). Theattention roughly follows the signal quality, with clear suppression of the attention on the corruptedchannels 1, 2 and 4. Note how the attention on channel 4 is initially high, but then suppressed whenthe channel is temporarily corrupted after frame 120. The attention response of STAN-shared is moreinterpretable.
