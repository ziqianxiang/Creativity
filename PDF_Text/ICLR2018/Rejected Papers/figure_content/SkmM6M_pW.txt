Figure 1: Overview of our proposed Egocentric Spatial Memory Network. It consists of HeadDirection Unit, Boundary Vector Unit, Place Unit, and Grid Unit. See Section 3.1 for more details.
Figure 2: Architecture of our proposed Egocentric Spatial Memory Network. See Section 3.1 for theoverview of individual module.
Figure 3: Overview of maze layouts, with differing geometries, textures and lighting conditions.
Figure 4: Head direction prediction of three ex-ample paths in Maze 6,7,8 (normal lighting condi-tions) by accumulating the estimated egomotionsacross first 400 time steps. The dotted line is theprediction and the solid is the ground truth.
Figure 5: Example results of predicted local maps over first 32 time steps in Maze 6. Every 4 out of32 frames are shown (left to right columns). Row 1 shows the camera views. Row 2 shows the groundtruth with red arrows denoting the agent’s position and orientation from the top view. The whiteregion denotes free space while the black denotes unknown areas. Row 3 shows the correspondingtop-view predicted local maps where the red color denotes higher belief of the free space.
Figure 6: Evaluation of Local Mapper using Mean Squared Error (MSE), Correlation, MutualInformation (MI) across first 32 time steps in Maze 6, 7, 8 under normal (N), weak (W), and strong(S) illumination conditions. The predicted local maps are compared with the ground truth at t = 32.
Figure 7: Example observation pairs when the loop closure is detected. Row 1 are the anchors(current camera views). Row 2 are the camera views from the previously visited places where theloop closure is detected. Row 3 show the agent’s locations (red circle) on the ground truth maps. Row4 show the agent’s locations (white circle) on the predicted map with ground truth poses.
Figure 8: Example results of constructed globalmaps in the world coordinate in Maze 6 across1580 time steps. The topmost row shows theground truth. Row 2 and Row 3 show the cor-responding top-view accumulative belief of thepredicted global maps without and with loop clo-sure classification at t = 448 respectively.
Figure 9: Example results of predicted local maps over first 32 time steps in Maze 6. Frames #1,5, 9, 13, 17, 21, 25, 29, 32 are shown (left to right columns). The topmost row shows the cameraview. Row 2 shows the ground truth with red arrows denoting the agent’s position and orientationfrom the top view. The white region denotes free space while the black denotes unknown areas. Row3 shows the corresponding top-view accumulative belief of the predicted local maps where the redcolor denotes higher belief of the free space. Best viewed in color.
Figure 10: Example results of predicted local maps over first 32 time steps in Maze 7. Frames #1,5, 9, 13, 17, 21, 25, 29, 32 are shown (left to right columns). The topmost row shows the cameraview. Row 2 shows the ground truth with red arrows denoting the agent’s position and orientationfrom the top view. The white region denotes free space while the black denotes unknown areas. Row3 shows the corresponding top-view accumulative belief of the predicted local maps where the redcolor denotes higher belief of the free space. Best viewed in color.
Figure 11: Example results of predicted local maps over first 32 time steps in Maze 8. Frames #1,5, 9, 13, 17, 21, 25, 29, 32 are shown (left to right columns). The topmost row shows the cameraview. Row 2 shows the ground truth with red arrows denoting the agent’s position and orientationfrom the top view. The white region denotes free space while the black denotes unknown areas. Row3 shows the corresponding top-view accumulative belief of the predicted local maps where the redcolor denotes higher belief of the free space. Best viewed in color.
