Figure 1: Plot of the cumulative sum of the singular values of the optimal Z* matrix. We observethat the proposed GLO model has a better conditioned covariance matrix and therefore better fills thelatent space.
Figure 2: Reconstruction of training examples from the CelebA 128 × 128 dataset.
Figure 3: Reconstruction of training examples from the LSUN 64×64 dataset.
Figure 4: Generation of samples on the CelebA 128×128 dataset.
Figure 5: Generation of samples on the LSUN 64×64 dataset.
Figure 6: Interpolation of training examples on the CelebA 128×128 dataset.
Figure 7: Interpolation of training examples on the LSUN 64×64 dataset. Both GAN and GLOs usea DCGAN generator.
Figure 8: Illustration of the variation around principal components of the GLO latent space on theCelebA 128 × 128 dataset. The original image is in the middle and we move along a eigenvector inboth directions. We illustrate this process with the first 2 components as well as some later ones.
Figure 9: Illustration of feature arithmetic on CelebA. We show that by taking the average hiddenrepresentation of row a, substracting the one of row b and adding the one of row c, we obtain acoherent image. We show such interpolations with PCA, VAE and GLO.
Figure 10: Reconstruction of the examples from the LFW dataset.
