Figure 1: Estimated mutual information (Left) vs. true negative log likelihood (Right). Dashed linescorrespond to the same objective but with an upper bound on mutual information term. When mutualinformation increases, log likelihood gets worse. As soon as mutual information stops increasing,log likelihood starts to improve.
Figure 2: Estimated negative log likelihood under different β and λ values (lower is better). Forboth training set (left) and test set (right) the extra degree of freedom from λ improves performance(the curresponding curves are below the yellow one, for all values of β).
