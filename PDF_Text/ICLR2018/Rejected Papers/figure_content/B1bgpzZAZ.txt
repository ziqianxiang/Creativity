Figure 1: Distribution of different question types in the RACE-Mid (left) and RACE-High (right)portions of the datasetTraining Procedures: We tried two different ways of training the model. In the first case, wetrain the parameters of all the modules (encoder, interaction, elimination and selection) together. Inthe second case, we first remove the elimination module and train the parameters of the remainingmodules. We then fix the parameters of the encoder and interaction module and train only theelimination and selection module. The idea was to give a better chance to the elimination moduleto learn to refine the document representations (in other words, ensure that the entire learning isfocused on the elimination module). Of course, we also had to learn the parameters of the selectionmodule from scratch because it now needs to work with the refined document representations. Inpractice, we found that this pre-training step did not improve the performance by much. Hence, wereport results only for the first case (i.e., end-to-end training).
Figure 2: Performance of ElimiNet and Gated Attention Reader (GAR) on different question cate-gories in RACE-Full (top), RACE-Mid (bottom left) and RACE-High (bottom right). The categoriesin which our model outperforms GAR are marked with *.
Figure 3: Change in the probability of correct option and incorrect option (initially predicted withhighest score) over multiple passes of the elimination module. The two figures correspond to twodifferent examples from the test set. The corresponding passage, question and options are given inthe Appendix.
