Figure 1: Diagram illustrating the training procedure for locally disentangled factors. On the left wetrain an ALI network on each locally disentangled factor with shared parameters. On the right wetrain a global generator network to produce these disentangled latent factors.
Figure 2: Illustration of a simple task where using locally disentangled factors would be expectedto make training easier. In this case, we consider a video dataset where a given shape moves a littlebit in each frame. Each frame can be constructed exactly at the pixel level from two independentlatent factors: the shape of the object and its position. In the pixel space, a large fraction of thepixels have correlated values between different frames, but in the disentangled latent space, differentindependent aspects can be modeled separately (shape and movement).
Figure 3: Inception Scores on CIFAR after 8 epochs of training with three different models. Thebaseline (blue) is a GAN where the discriminator sees all of the pixels and the generator producesthe entire image. ldf with a pre-trained lower level (red) and ldf with training starting from scratchall train faster than the baseline GAN.
Figure 4: Unconditioned video generation samples trained using a joint model where a discriminatorconsiders all frames (left) and locally disentangled factors (right).
Figure 5: Real video sequences from the Pacman dataset (Cooper, 2017).
Figure 6: Unconditioned video generation samples where only 256 video samples are available (butthe locally disentangled factors model can use all of the individual frames to train the local model).
Figure 7: Unconditioned video generation samples with only 21 minutes of wall-clock training timeusing full video sequences. Baseline (left) and locally disentangled factors (right). The baseline runsfor 10 epochs.
