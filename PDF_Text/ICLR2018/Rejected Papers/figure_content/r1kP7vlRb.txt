Figure 1: The overview of partial reward functions. SeqGAN has only the yellow reward function.
Figure 2: HoW to calculate action-state value with partial reward function. The red token is theaction.
Figure 3: Overview of expert-based reward function training. An edited expert is produced fromexpert data by editing some tokens to another, and we treat it as fake data. A pseudo reward functionis the negative hamming distance, so it counts the number of tokens that are edited. Then qualityfunction can be calculated as above.
Figure 4: Plots of reward and NLL duringthe generator,s training ofPG_L_exp. We cansee that the generator is properly optimizedw.r.t. the reward function, and as the returnedreward increases, NLL decreases.
