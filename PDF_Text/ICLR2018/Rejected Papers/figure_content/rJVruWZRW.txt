Figure 1: (a) Conventional RNN unfolded in time. (b) Gated feedback RNN.(c) RNN with connec-tions across multiple preceding states. (d) Dense RNN integrated with (b) and (c). Hidden statesare represented in red. The connections used in current steps feedforward are highlighted in bold.
Figure 2: (a) The stable region from exploding gradient problem. The attention gate increasesthe stable region from 1 to 1/(KL). (b) The stable region from vanishing gradient problem. Theattention gate decreases the stable region from 1 to 1âˆ•(KL). (c) The approximation of the attentiongate to determine vanishing and exploding gradient boundary.
