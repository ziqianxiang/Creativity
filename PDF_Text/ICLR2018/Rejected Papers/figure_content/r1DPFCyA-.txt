Figure 1: left: Shared feature extractor Φφ and separate top linear layers W and W with correspondingsoftmax units on old and new classes. right: Graphical model for probabilistic k-shot learning.
Figure 2: Results for miniImageNet with ResNet-34 style architecture and 600 training images perclass. From left to right: accuracy and log likelihood (higher is better) for different k, ExpectedCalibration Error (ECE, lower is better) vs accuracy for 5-shot learning, and Calibration curve for5-shot learning. Results on other architectures can be found in Appendix E.2trained with all 600 examples per training class, and a simple isotropic Gaussian model on theweights for concept learning. Despite its simplicity, our method achieves state-of-the-art and beatsprototypical networks by a wide margin of about 6%. The baseline methods using the same featureextractor are also state-of-the-art compared to prototypical networks and both logistic regressionsshow comparable accuracy to our methods except for on 1-shot learning. In terms of log-likelihoods,Log Reg (C = 2σf2 ) fares slightly better, whereas Log Reg (cv) is much worse.
Figure 3: Comparison of different network architectures and training set sizes on the k-shot learningtask: VGG style network (trained on 500 images per class) and ResNet-34 style network (trained on500 and 600 images per class, respectively). Both, deeper networks and larger number of trainingimages, give rise to features that transfer better to k-shot learning.
Figure 4: Choice of regularisation constant for logistic regression for k-shot learning. Results forCreg = 2σf2 are drawn as black triangles. Dashed lines correspond to logistic regression with cross-validated (changing) regularisation constant. Colour brightness of the markers ranges from dark(C = 10-5) to bright (C = 10). ECE plots are provided in Appendix E.3.
Figure 5: Online learning with ResNet-34 features. Gauss (iso) and Log Reg (2σf2 ) strike a goodtrade-off between learning on new classes and forgetting of old classes. Unregularised Log Reg (MLE)and Log Reg (2σ2f , only new), which has not been trained in the presence of the old weights, eithercompletely forget the old classes or do not learn anything, respectively.
Figure 6:	t-SNE embedding of the CIFAR-100 weights W trained using a VGG style architecture.
Figure 7:	t-SNE embedding of the miniImageNet weights trained using a ResNet-34 architecture.
Figure 8: Extended results for the miniImageNet dataset utilising different network architecturesand representational training. top: a ResNet-34 trained with all 600 examples per class; middle: aResNet-34 trained with 500 images per class; bottom: a VGG style network trained with 500 imagesper class. We highlight that for all three architectures the order of the different methods as well as themain messages are the same. However, the general performance in terms of accuracy and calibrationdiffer between the architectures. The more complex architecture trained on most images performsbest in terms of accuracy, indicating that it learns better features for k-shot learning. Both ResNetsbehave very similarly on calibration whereas the VGG-style network performs better (lower ECE andhigher log likelihood as well as more diagonal calibration curve). This is in line with observations byGuo et al. (2017) that calibration of deep architectures gets worse as depth and complexity increase.
Figure 9: Choice of regularisation constant for logistic regression on k-shot learning. Note that allthree rows use the same raw data that are only visualised differently. Top: Summary of accuracy andcalibration in terms of log likelihood and Expected Calibration Error (ECE). Middle: detailed plotof ECE vs. accuracy. Bottom: detailed plot of log likelihood vs. accuracy. Results for Creg = 2σf2are drawn as black triangles. Dashed lines correspond to logistic regression with cross-validated(changing) regularisation constant. Colour brightness of the markers ranges from dark (C = 10-5) tobright (C = 10). In addition to Fig. 4 we also provide results for calibration in terms of ECE (loweris better), which are consistent with log likelihoods (higher is better): The Bayesian inspired choice ofthe regularisation parameter strikes a good balance between accuracy and calibration and consistentlyoutperforms cross-validated choice of the parameter.
Figure 10: Results on CIFAR-100 for VGG style architecture. We report accuracy, log-likelihood andcalibration for the methods and inference procedures presented in Tab. 8. With the exception of GMM(10, iso) and Laplace, all methods are similar terms of accuracy and log-likelihood. Gauss (integr.
