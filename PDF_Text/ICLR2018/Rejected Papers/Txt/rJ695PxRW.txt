Under review as a conference paper at ICLR 2018
Discovering Order in Unordered Datasets:
Generative Markov Networks
Anonymous authors
Paper under double-blind review
Abstract
The assumption that data samples are independently identically distributed is the
backbone of many learning algorithms. Nevertheless, datasets often exhibit rich
structures in practice, and we argue that there exist some unknown orders within
the data instances. Aiming to find such orders, we introduce a novel Generative
Markov Network (GMN) which we use to extract the order of data instances auto-
matically. Specifically, we assume that the instances are sampled from a Markov
chain. Our goal is to learn the transitional operator of the chain as well as the
generation order by maximizing the generation probability under all possible data
permutations. One of our key ideas is to use neural networks as a soft lookup table
for approximating the possibly huge, but discrete transition matrix. This strategy
allows us to amortize the space complexity with a single model and make the tran-
sitional operator generalizable to unseen instances. To ensure the learned Markov
chain is ergodic, we propose a greedy batch-wise permutation scheme that allows
fast training. Empirically, we evaluate the learned Markov chain by showing that
GMNs are able to discover orders among data instances and also perform com-
parably well to state-of-the-art methods on the one-shot recognition benchmark
task.
1	Introduction
Recent advances in deep neural networks offer great potentials for machines to learn automatically
without humans interventions. For instance, Convolutional Neural Networks (CNNs) (Krizhevsky
et al., 2012) provided an automated way for learning image feature representations. Compared to
hand-crafted ones such as SIFT and SURF, these hierarchical deep features demonstrate superior
performance in recognition (Xu et al., 2015; Finn & Levine, 2017) and transfer learning (Glorot
et al., 2011) problems. Another example would be learning to learn for automatic parameter esti-
mation. Andrychowicz et al. (2016) proposed to update model parameters without any pre-defined
update rule such as stochastic gradient descent (SGD) or ADAM (Kingma & Ba, 2014). Surpris-
ingly, this update-rule-free framework showed better performance and faster convergence on both
object recognition and image style transformation tasks. In our paper, we investigate the following
novel question: given an unordered dataset where instances may be exhibiting some implicit order,
can we order a dataset automatically according to this order?
We argue that such order often exists even when we are dealing with the data that are naturally
thought of as being i.i.d. sampled from a common though complex distribution. For example,
let’s consider a dataset consisting of the joint locations on the body of the same person taken on
different days. The data i.i.d. assumption is justified since postures of a person took on different
days are likely unrelated. However, we can arrange the data instances such that the joints follow an
articulated motion or a set of motions in a way that makes each pose highly predictable given the
previous ones. Although this arrangement depends on the person as ballerinas’ poses might obey
different dynamics than the poses of tennis players, the simultaneous inference on the pose dynamics
can lead to a robust model that explains the correlations among joints. To put it differently, if we
reshuffle the frames of a video clip, the data can now be modeled by an i.i.d. model. Nevertheless,
reconstructing the order leads to an alternative model where transitions between the frames are easier
to fit the links between the latent structures and observations. The ballerina’s dancing, if sampled
very sparsely, can be thought of as a reshuffled video sequence that needs to be reordered such that
a temporal model can generate it.
1
Under review as a conference paper at ICLR 2018
One naive and obvious way to find the order in a dataset is to perform sorting based on a predefined
distance metric; e.g., the Euclidean distance between image pixel values. However, the distance
metrics have to be predefined differently and empirically according to distinct types/characteristics
of the datasets at hand. A proper distance metric for one domain may not be a good one for other
domains. For instance, p-distance is a good measure for DNA/RNA sequences (Nei & Kumar,
2000) while it does not characterize the semantic distances between images. We argue that the key
component of the ordering problem lies in the discovery of proper distance metric in an automatic
and adaptive way.
To approach this problem, we propose to learn a distance-metric-free model to discover the ordering
in the dataset. More specifically, we model the data by treating them as if they were generated
from a Markov chain. We propose to simultaneously train the transitional operator and find the
best order by a joint optimization over the parameter space as well as all possible permutations.
We term our model Generative Markov Networks (GMNs). One of the key ideas in the design of
GMNs is to use neural networks as a soft lookup table to approximate the possibly huge but discrete
transition matrix. This strategy allows GMNs to amortize the space complexity using a unified
model. Furthermore, due to the differentiable property of neural networks, the transitional operator
of GMNs can also generalize on unseen but similar data instances. As an additional contribution, to
ensure the Markov chain learned by GMNs is ergodic, we propose a greedy batch-wise permutation
scheme that allows fast training.
One related task is one-shot recognition which has only one labeled data per category in the target
domain. Most of the work in this area considered learning a specific distance metric (Koch et al.,
2015; Vinyals et al., 2016; Snell et al., 2017) or category-separation metric (Ravi & Larochelle,
2017; Finn et al., 2017) for the data. During the inference phase, they computed either the smallest
distance or highest class prediction score between the support and query instances. Alternatively,
from a generative modeling perspective, we can first generate the Markov chain for the support
instances, then we fit the query instances into the Markov chain and decide the labels with the
highest log-likelihood.
Empirically, we evaluate the learned Markov chain by showing that GMNs are able to discover
implicit orders among data instances and also perform comparably well to state-of-the-art methods
on the benchmark one-shot recognition task.
2	Related Work
The literature on deep generative models and stochastic sampling is abundant. Due to the space
limit, we discuss the ones that are most relevant to our work.
Deep Generative Models: We consider two classes of deep generative models based on ances-
tral sampling and iterative sampling, respectively. Variational Autoencoders (VAEs) (Kingma &
Welling, 2013) and Generative Adversarial Networks (GANs) (Goodfellow et al., 2014) can be cast
as ancestral sampling-based methods. In the inference phase, these approaches generated one sam-
ple from the model by performing a single inference pass from the underlying graphical models. As
a comparison, methods based on iterative sampling performed multiple and iterative passes through
all the variables in the corresponding graphical models. Usually, these methods involved simulating
a Markov chain in the entire state space, and they aimed at improving quality of generated samples
by mixing the underlying chain. Recent works on this line of research included (Bengio et al., 2013;
2014; Sohl-Dickstein et al., 2015; Bordes et al., 2017; Song et al., 2017).
Our approach can be categorized as an iterative sampling-based model. However, it has three sig-
nificant differences comparing to previous works. First, all the existing works assumed that training
instances are i.i.d. sampled from the stationary distribution of a Markov chain. This assumption
is risky since, often the case, it is hard to measure whether a Markov chain has mixed or not. On
the contrary, we only assume that data instances are sampled from the chain, without expecting the
chain has mixed. As we will see later, the stationarity assumption in previous works often prevents
them from observing the implicit data relationships. Second, prior approaches were proposed based
on the notion of denoising models. In other words, their goal was generating high-quality images;
on the other hand, we aim at discovering orders in datasets. Third, to the best of our knowledge,
all the existing works were implicit models in the sense that they only admitted efficient sampling
2
Under review as a conference paper at ICLR 2018
schemes. In contrast, the proposed GMN is an explicit model where besides an efficient sampling
procedure, the model maintains a tractable likelihood function that can be computed efficiently.
One-Shot Learning: Deep one-shot learning approaches could be divided into two categories:
distance-metric-learning and categories-separation-metric-learning approaches. The former aimed
at either learning a similarity measurement between instance pairs (Koch et al., 2015) or applying
specific metric loss based on cosine distance (Vinyals et al., 2016)/ Euclidean distance (Snell et al.,
2017). These methods referred to nonparametric classifiers and relied heavily upon human design.
As a comparison, methods in the second category offered more generalities. Typically, this type
of methods tackled the problem using a meta-learning framework to train parametric classifiers.
Precisely, they considered two levels of learning: the first stage is to update base learners’ parameters
and the second stage is to update parameters for the meta learner. Recent works (Ravi & Larochelle,
2017; Kaiser et al., 2017; Finn et al., 2017) belonged to this category.
The methods mentioned above viewed one-shot recognition as a discriminative task; on the contrary,
we hold a generative perspective. Since we consider a Markov chain data generation assumption,
we can directly decide the labels for query instances by fitting them into the Markov chain (or the
orders we observe) generated from support instances. This generative nature significantly decreases
the difficulty of training as we no longer rely on any designed metric. More details will be covered
in Sec. 4.
3	Generative Markov Networks
Let {si}in=1 denote our training data which are assumed being generated from an unknown Markov
chain. Our goal is to jointly recover the unknown Markov chain as well as the order of generation
process. Note that since the generation order is unknown, even if the true Markov chain was given,
it would still be computationally intractable to find the optimal order that best fits our data. To get
around of this intrinsic difficulty, as we will see in Sec. 3.2 , we propose a greedy algorithm to find
an order given the current estimation of the transitional operator.
We denote the underlying data order to be a permutation over [n]: π = {π(t)}tn=1, where π(t)
represents the index of the instance that is generated at the t-th step of the Markov chain. In other
words, a Markov chain is formed as follows:
sπ(1) → sπ(2) → •…→ sπ(n)∙
We consider all the possible permutations π and arbitrary distribution over these permutations, which
leads to a joint log-likelihood estimation problem:
n
Im ⅛∏χiog(χ p (∏) p ({si}n=ι, ∏; θ))=ImaXlog(X P ⑺ P ⑴区⑴)Y t国阳品(一)；。))，
, π , π t=2
where P(I)(∙) is the initial distribution of the Markov chain and T(s0∣s; θ) is the transitional op-
erator parametrized by model parameters θ. Note that the effect of the initial distribution P⑴(∙)
diminishes with the increase of the data size n. Hence, without loss of generality, We assume P(I) (∙)
is uniform over all possible states, leading to the following optimization problem:
maxθ,∏ log I E P(∏) ∏T(s∏(t)∣s∏(t-i); θ) I , (1)
π∈Π(n)	t=2
where Π(n) is the set of all possible permutations over [n]. Unfortunately, direct optimization of (1)
is computationally intractable. For each fixed θ and P, the number of all possible permutations (i.e.,
∣∏(n)∣) is n!. To approximate this expensive function, We present an efficient greedy algorithm in
Sec. 3.3.
3.1	Parametrized transitional operator via Neural Networks
In practice, when the state space is huge, often we cannot afford to maintain the tabular transition
matrix directly, which takes up to O(d2 ) space, where d is the number of states in the chain. For
example, if the state refers to a binary image I ∈{0, 1}p, the size of the state space is d =2p
3
Under review as a conference paper at ICLR 2018
which is nearly infeasible to compute. Hence, before optimizing (1), we should first find a family of
functions to parametrize the transitional operator T(∙∣∙).
Being universal function approximators (Hornik et al., 1989), neural networks could be used to
approximate the discrete structures which led to the recent success of deep reinforcement learning
(Mnih et al., 2013). In our case, we utilize neural networks to approximate the discrete tabular
transition matrix. The advantages are two-fold: first, it significantly reduces the space complexity
by amortizing the space required by each separate state into a unified model. Since all the states
share the same model as the transitional operator, there is no need to store the transition vector for
each separate state explicitly. Second, neural networks allow better generalization for the transition
probabilities across states. The reason is that, in most real-world applications, states, represented as
feature vectors, are not independent from each other. As a result, the differentiable approximation to
a discrete structure has the additional smoothness properties, which allows the transitional operator
to have a good estimate even for the unseen states.
Let θ be the parameters of the neural networks and we can define
fθ(s, s0) = T(s0∣s; θ): Rp X Rp → [0,1]
to be the transition function that takes two states s and s0 as inputs and returns the corresponding
transition probability. Note that one can consider each discrete transitional operator as a lookup
table; for example, we use s and s0 to locate the corresponding row and column of the table and
read out its probability. From this perspective, the neural network works as a soft lookup table that
outputs the transition probability given two states (features).
3.2	Greedy Approximation of the Optimal Order
As mentioned above, the direct evaluation of eq. (1) is computationally intractable given P and θ .
Here, we develop a coordinate ascent style training algorithm to optimize eq. (1) efficiently. The key
insight comes from the following observation: for each fixed θ, there exists a point mass distribution
over Π(n) that achieves the maximum value for eq. (1). More precisely,
maxθ,∏ log E P(∏) ∏T(s∏(t)∣s∏(t-i); θ)	= maxθ log ( ∏T(s∏*(t)∣s∏*(t-i); θ)]
π∈Π(n)	t=2	t=2
with
n
π* = argmax E log T(s∏(t)∣s∏(t-i); θ).
π∈Π(n) t=2
We leave the proof in Supplementary. In other words, given each θ, the optimization problem over π
now reduces to finding the optimal permutation π* that gives the maximum likelihood on generating
the data. However, without further assumption on the structure of the transitional operator, this is
still a hard problem which takes time O(n!). Instead, we propose a greedy algorithm to approximate
the optimal order, which takes time O(n2 log n). We list the pseudocode in Alg. 1.
At first, Alg. 1 enumerates all the possible states appearing in the first time step. For each of the
following steps, it finds the next state by maximizing the transition probability at the current step,
i.e., a local search to find the next state. The final approximate order is then defined to be the
maximum of all these n orders. A naive implementation of this algorithm has time complexity
O(n3). However, we can reduce it to O(n2 log n) by pre-computing T(si|sj; θ), ∀i,j ∈ [n] and
sorting them so that the maximum finding operation in line 5 can be done in constant time.
Given the approximate order ∏, we then proceed to optimize the model parameter θ by gradient
based optimization. By now it should be clear that the whole algorithm is an instance of the famous
coordinate ascent algorithm, where we alternatively optimize over the order π and the model param-
eters θ. Since both optimizations over θ andπ will not decrease the objective function, the algorithm
is guaranteed to converge.
3.3	Batch-Wise Permutation Training
The O(n2 log n) computation to find the approximate order in Alg. 1 can be expensive when the
size of the data is large. In this section we provide batch-wise permutation training to avoid this
4
Under review as a conference paper at ICLR 2018
Algorithm 1 Greedy Approximate Order
Input: Input data {si}in=1 and transitional operator T(si|sj; θ)
1: v* 4-----∞
2: 3: 4: 5: 6: 7: 8: 9: 10 11 12 13	for i =1to n do πi(1) 4 i for j =2to n do πi (j) 4 maxk6∈{πi (1),...,πi (j-1)} T(sk | sπi (j-1) ; θ) end for Vi J Pn=2 log T (s∏i(j-1)∖s∏i(t); θ) if vi >v* then ∏ 一 ∏i :	v* J vi : end if : end for return π
Algorithm 2 Optimization with Batch-Wise Permutation Training
Input: {si}in=1, bo, b, t, γ
1: 2: 3: 4: 5: 6: 7: 8: 9: 10	Initialize θ(0), {xi(0)}ib=1 for k =1to ∞ do if k ≡ 1(mod t) then Sample {x(k)}b-bo 〜{si}红 {xi(k)}ib=1 = {{xi(k)}ib=-1bo, {xi(k-1)}ib=o1} end if Compute π(k) using the Greedy Approximate Order (Alg. 1) COmPUte vθk-1) log P ({χi}i=1; θ(kT))= dθ Pb=2 log T (χ^(k)(t)∖χ^(k-1)(t-i); θ(kT)) θ(k) = θ(k-1) + γvθk-1) log P({xi}b=ι; θ(k-1)) end for
issue. The idea is to partition the original training set into batches with size b and perform greedy
approximate order on each batch. Assuming b《n is a constant, the effective time complexity
becomes: O(b2 log b) ∙ n/b = O(nb log b), which is linear in n.
However, since training data are partitioned into chunks, the learned transitional operator is not
guaranteed to have nonzero transition probabilities between different chunks of data. In other words,
the learned transitional operator does not necessarily induce an ergodic Markov chain due to the
isolated states. To avoid this problem, we propose a simple strategy to enforce some samples are
overlapping between the consecutive batches. We show the pseudocode in Alg. 2. In Alg. 2, b means
the batch size, γ is the learning rate and b0 <bis the number of overlap states between consecutive
batches.
3.4	Introducing Stochastic Latent Variables via Variational Bayes Inference
In this section we give a detailed description on how to implement the transitional operator where
the state can be both discrete or continuous. At the first step, to prevent our GMNs from simply
memorizing all the training data and their transitions, we introduce stochastic latent variables z ∈ Rz
via Variational Bayes Inference (Wainwright et al., 2008). The evidence lower bound (ELBO) of the
log likelihood for the transitional operator (i.e., log T(s0|s; θ)) becomes:
log T(Sls; θ) ≈ Ez 〜Q(z∣sM [log P (s0∣s,z; ψ)] - KL^Q(z∣s; φ) || P (z)), (2)
where T(s0|s; θ) has been replaced by a distribution P(s0|s, z; ψ) parametrized by ψ, which allows
us to make the dependence of S on z. Moreover, KL is the KL-divergence, Q(z|S; φ) is an encoder
function parametrized by φ that encodes latent code z given current state S, and P(z) is a fixed
prior which we take its form as Gaussian distribution N (0, I). We use reparametrized trick to
draw Q(z∣s; φ) from Gaussian N(μQ,φ(s), σQ,φ(s)l) where μQ,φ(S) and σQ,φ(s) are learnable
functions.
Next, we consider two types of distribution family for P(S0|S, z; θ): Bernoulli and Gaussian.
5
Under review as a conference paper at ICLR 2018
GMN:

NN:
3133388E53553夕?IWqqQSIZ，口3333335665560053333333333
L
InTr 办**烈 *KK¼∙k⅜*wt =⅜rχ>⅝ /常、F* *、>、、»MbMMW 触加片» 枷* MK
耳彻萩＞越
Figure 1: For MNIST, Horse, and MSR-SenseCam datasets: the implicit order observed from GMN
and the oder implied from Nearest Neighbor sorting.
NN:
GMN:
NN:
If s ∈{0, 1}p (i.e., a binary image), we define log P(s0|s, z; ψ) as:
log P(s0|s, z; ψ)
s0 Θ log (gψ(s, Z)) +(1 - s0) Θ log(1
where Θ is element-wise multiplication and gψ(s,z)
If s ∈ Rp (i.e., a real-valued feature vector), we choose P(s0|s, z; ψ) to be fixed variance factored
Gaussian N
(〃P ,ψ (s,z),σP I)
where μp,ψ (s, z) : Rp+z → Rp and σp is a fixed variance. We
simply choose σP in all the experiments. log P(s0|s, z; θ) can thus be defined as
log P(s0|s, z; ψ)
-2⅛ 11s0
一μp,ψ (s,z)∣∣2 + const.,
where const. is not related to the optimization ofψ.
For simplicity, we specify θ = {ψ ∪ φ}. Therefore, the model parameters update for θ in (2) refers
to the updates for ψ and φ.
4	Experiments
4.1	Discovering Orders in Datasets
We perform experiments on ordering data in three datasets: MNIST (LeCun et al., 1990), Horse
(Borenstein & Ullman, 2002), and MSR-SenseCam (Jojic et al., 2010). We also provide another
experiment on Moving MNIST (Srivastava et al., 2015) in Supplementary. Among these datasets,
MNIST, Horse, and MSR-SenseCam do not have explicit orders. On the other hand, Moving MNIST
can be seen as a collection of short video clips, and thus each sequence of frames has an explicit
order. Due to the space limit, we only show partial ordering results. Please see Supplementary for
the full version.
<MNIST> MNIST (LeCun et al., 1990) is a well-studied dataset that contains 60,000 training
examples. Each example is a digit image with size 28x28. We rescale the pixel values to [0, 1].
Note that since MNIST contains a large number of instances, we perform the ordering in a randomly
sampled batch to demonstrate our results.
<Horse> Horse dataset (Borenstein & Ullman, 2002) consists of 328 horse images collected from
the Internet. Each horse is centered in a 30x40 image. For the preprocessing, the object-background
segmentation is applied, and the binary pixel value is set to 1 and 0 for object and background,
respectively. Examples are show in Supplementary.
<MSR_SenseCam> MSR-SenseCam (Jojic et al., 2010) is a dataset consisting of images taken by
SenseCam wearable camera. It contains 45 classes with approximately 150 images per class. Each
image has size 480x640. We resize each image into 224x224 and extract the feature from VGG-19
network (Simonyan & Zisserman, 2014). In this dataset, we consider only office category which has
362 images.
4.1.1	Implicit Orders in Datasets
We apply Alg. 2 to train our Generative Markov Networks. When the training converges, we plot
the images following permutation π in Alg. 1. Note that π can be seen as the implicit order sug-
gested by GMNs. For comparison, we also plot the images following nearest neighbor sorting using
6
Under review as a conference paper at ICLR 2018

GMN: T-J 么 2 2 X 3 义工 Z，「3 -,/N & ` R M S 3，Jz 7 1 Q 々 2 7 7 7 7 1 4 '〉9 二 8'『5 5 S ： 1 ,
NN：
GMN： Einzs:
NN:
Figure 2: For MNIST, Horse, and MSR-SenseCam datasets: data generation from the learned tran-
sitional operator in GMN and Nearest Neighbor search.
Euclidean distances. The parameters {boverlap, b, t} in Alg. 2 are {50, 500, 600}, {328, 328, 1},
and {362,362,1} for MNISt, Horse, and MSR-SenseCam, respectively. Network architectures for
parameterizing T(∙∣∙; θ) are specified in Supplementary.
The results are shown in Fig. 1. We first observe that data following the order suggested by our
proposed GMN have visually high autocorrelation. This result implies that our proposed GMN
can discover nice implicit orders for the dataset. Comparing to the strong ordering baseline Nearest
Neighbor sorting, one could hardly tell which one is better. Nevertheless, GMN is a distance-metric-
free model which requires no predefined distance metric. Moreover, the implicit order suggested by
GMN considers a generative modeling viewpoint: the order is the optimal permutation under the
Markov chain data generation assumption (see Sec. 3.2).
4.1.2	transitional operator as a Generative Model
Next, we examine the data generation using the learned transitional operator. Conditioned
on a given sample s, instead of sampling s0 〜 T(s0∣s; θ) directly, We sample s0 =
arg maxs↑∈{{si}~ι∖s} T(s*∣s; θ). We make this modification based on the reason that our model
aims at discovering datasets’ orders, while other iterative sampling models (Bengio et al., 2013;
2014; Sohl-Dickstein et al., 2015; Bordes et al., 2017; Song et al., 2017) intended to denoise gener-
ated samples. Similar to Sec. 4.1.1, we exploit nearest neighbor search using Euclidean distance for
comparison. More precisely, SNN = arg maxst∈{{si}i^ι∖s} d(s*,s) with d(∙, ∙) denoting Euclidean
distance.
Fig. 2 illustrates the sampling of GMN and Nearest Neighbor search. We can see that Nearest
Neighbor search is not able to perform efficient sampling since it would stick between two similar
images. On the other hand, our proposed GMN can perform consecutive sampling. This tremendous
difference implies the distinction between the discriminative (sampling by a fixed distance metric)
and the generative (sampling through the transitional operator in a Markov chain) model.
4.2	One-Shot Recognition
Now, we perform one-shot recognition task on the miniImageNet (Vinyals et al., 2016; Ravi &
Larochelle, 2017), which is a benchmark dataset designed for the evaluation of few-shot learning
(Vinyals et al., 2016; Ravi & Larochelle, 2017). Being a subset of ImageNet (Russakovsky et al.,
2015), it contains 100 classes and each class has 600 images. Each image is downsampled to size
84x84. As suggested in (Ravi & Larochelle, 2017), the dataset is divided into three parts: 64 classes
for training, 16 classes for validation, and 20 classes for testing. Identical to (Ravi & Larochelle,
2017), we consider the 5-way 1-shot problem. That is, from testing classes, we sample 5 classes
with each class containing 1 labeled example. The labeled examples refer to support instances.
Then, we randomly sample 500 unlabeled query examples in these 5 classes for evaluation. We
repeat this procedure for 10, 000 times and report the average with 95% confidence intervals in Tbl.
1.
4.2.1	Training Details
Instead of viewing one-shot recognition as a discriminative task, we hold it as a generative one. To
achieve this goal, we train our Generative Markov Networks on training classes and then apply it
to testing classes. More precisely, for each training episode, we sample 1 class from the training
7
Under review as a conference paper at ICLR 2018
Table 1: 5-way 1-shot recognition task for miniImageNet. 10, 000 episodes with 95% confidence intervals.		The results	are reported averagely in	
Model	Basic/ Advanced Model Discriminative/ Generative		ParametriC/Nonparametric	Accuracy
Meta-Learner LSTM (Ravi & Larochelle, 2017)	Basic	Discriminative	Parametric	43.44±0.77
Model-Agnostic Meta-Learning (Finn et al., 2017)	Basic	Discriminative	Parametric	48.70±1.84
Meta Networks (Munkhdalai & Yu, 2017)	Advanced	Discriminative	Parametric	49.21±0.96
Meta-SGD (Li et al., 2017)	Basic	Discriminative	Parametric	50.47±1.87
Temporal Convolutions Meta-Learning (Mishra et al., 2017)	Advanced	Discriminative	Parametric	55.71±0.99
Nearest Neighbor with Cosine Distance	Basic	Discriminative	Nonparametric	41.08±0.70
Matching Networks FCE (Vinyals et al., 2016)	Basic	Discriminative	Nonparametric	43.56±0.84
Siamese (Koch et al., 2015)	Basic	Discriminative	Nonparametric	48.42±0.79
mAP-Direct Loss Minimization (Triantafillou et al., 2017)	Basic	Discriminative	Nonparametric	41.64±0.78
mAP-Structural Support Vector Machine (Triantafillou et al., 2017)	Basic	Discriminative	Nonparametric	47.89±0.78
Prototypical Networks (Snell et al., 2017)	Basic	Discriminative	Nonparametric	49.42±0.78
Attentive Recurrent Comparators (Shyam et al., 2017)	Not Specified	Discriminative	Nonparametric	49.1
Skip-Residual Pairwise Networks (Mehrotra & Dukkipati, 2017)	Advanced	Discriminative	Nonparametric	55.2
Generative Markov Networks without fine-tuning (ours)	Basic	Generative	Nonparametric	45.36±0.94
Generative Markov Networks with fine-tuning (ours)	Basic	Generative	Nonparametric	48.87±1.10
classes and let {si }in=1 be all the data from this class. Then, we apply Alg. 2 with {boverlap ,b,t} =
{20, 100, 10}. We consider 3, 000 training episodes.
On the other hand, for each testing episode, we apply GMNs to generate a chain from each support
instance:
Sc 〜T(∙∣S0; θ),蜀〜T(•国;θ),…，疏〜T(•倒-1； θ),
where s0 is the support instance belonging to class C and Sc is the generated samples from the
Markov chain.
Next, we fit each query example into each chain by computing the average approximating log-
likelihood. Namely, the probability for generating the query sample sq in the chain of class c is
P (Sq IC) = k+1
k
T(Sq |S0； θ) + X log T(Sq&； θ))
i=1
In a generative viewpoint, the predicted class C for Sq is determined by
C = arg max P(Sq |c).
c
(3)
(4)
For fair comparisons, we use the same architecture specified in (Ravi & Larochelle, 2017) to ex-
tract 1600-dimensional features. We pretrain the architecture using standard softmax regression on
image-label pairs in training and validation classes. The architecture consists of 4 blocks. Each block
comprises a CNN layer with 64 3x3 convolutional filters, Batch Normalization (Ioffe & Szegedy,
2015) layer, ReLU activation, and 2x2 Max-Pooling layer. Then, we train our Generative Markov
Networks based on these 1, 600 dimensional features. Network architecture for parameterizing
T(∙∣∙; θ) is specified in Supplementary.
4.2.2	Results
For a comprehensive analysis, we also provide the variant of our GMN with fine-tuning. In other
words, we fine-tune GMN by applying Alg. 2 with {boverlap, b, t} = {20, 100, 10} on support and
query instances. Note that in eq. (3), k is chosen to be 1 and 5 for the non-fine-tuned and fine-tuned
version, respectively. We compare our proposed method and the related approaches in Tbl. 1, in
which Basic model refers the architecture in (Ravi & Larochelle, 2017) and Advanced models refer
to more complicated designs. Generally, itis not fair to compare the methods using different models;
therefore, we only discuss the methods using Basic model in the following.
First, we observe that the performance of GMN is comparable to other works. For example, the
best result of all methods is reported by Meta-SGD (Munkhdalai & Yu, 2017) with 50.47 ± 1.87.
Although GMN suffers from slight performance drop, it requires a much less computational budget.
The reason is that the meta-learning (parametric) approaches (Ravi & Larochelle, 2017; Finn et al.,
2017; Munkhdalai & Yu, 2017; Li et al., 2017; Mishra et al., 2017) rely on huge networks to manage
complicated intersections between meta and base learners, while parameters for GMN exist only
in θ which is a relatively tiny network. On the other hand, the best performance reported in the
distance-metric learning (nonparametric) approaches is Prototypical Networks (Snell et al., 2017)
with 49.42 ± 0.78. Sacrificing from little performance deterioration, our proposed GMN enjoys
8
Under review as a conference paper at ICLR 2018
more flexibility without the need of defining any distance metric as in (Vinyals et al., 2016; Koch
et al., 2015; Triantafillou et al., 2017; Snell et al., 2017; Shyam et al., 2017; Mehrotra & Dukkipati,
2017). More importantly, except for our proposed GMN, all the works belong to discriminative
models, which means they are optimized based on carefully chosen objectives for one-shot learning
purpose.
Next, our proposed GMN enjoys a significant improvement (45.36 ± 0.94 → 48.87 ± 1.10) from
fine-tuning over support and query instances. This result verifies that GMN is able to simulate the
Markov chain data generation process since the query instances can be better fitted in the chains
generated from the support instances.
5	Conclusion
In this paper, we argue that data i.i.d. assumption is not always the case in most of the datasets.
Often, data instances are exhibiting some implicit orders which may benefit our understanding and
analysis of the dataset. To observe the implicit orders, we propose a novel Generative Markov
Network which considers a Markov chain data generation scheme. Specifically, we simultaneously
learn the transitional operator as a generative model in the Markov chain as well as find the optimal
orders of the data under all possible permutations. In lots of experiments, we show that our model
is able to observe implicit orders from unordered datasets and also perform well on the one-shot
recognition task.
9
Under review as a conference paper at ICLR 2018
References
Marcin Andrychowicz, Misha Denil, Sergio Gomez, Matthew W Hoffman, David Pfau, Tom Schaul,
and Nando de Freitas. Learning to learn by gradient descent by gradient descent. In Advances in
Neural Information Processing Systems,pp. 3981-3989, 2016.
Yoshua Bengio, Li Yao, Guillaume Alain, and Pascal Vincent. Generalized denoising auto-encoders
as generative models. In Advances in Neural Information Processing Systems, pp. 899-907, 2013.
Yoshua Bengio, Eric Laufer, Guillaume Alain, and Jason Yosinski. Deep generative stochastic
networks trainable by backprop. In International Conference on Machine Learning, pp. 226-234,
2014.
Florian Bordes, Sina Honari, and Pascal Vincent. Learning to generate samples from noise through
infusion training. arXiv preprint arXiv:1703.06975, 2017.
Eran Borenstein and Shimon Ullman. Class-specific, top-down segmentation. In European confer-
ence on computer vision, pp. 109-122. Springer, 2002.
Chelsea Finn and Sergey Levine. Deep visual foresight for planning robot motion. In Robotics and
Automation (ICRA), 2017 IEEE International Conference on, pp. 2786-2793. IEEE, 2017.
Chelsea Finn, Pieter Abbeel, and Sergey Levine. Model-agnostic meta-learning for fast adaptation
of deep networks. arXiv preprint arXiv:1703.03400, 2017.
Xavier Glorot, Antoine Bordes, and Yoshua Bengio. Domain adaptation for large-scale sentiment
classification: A deep learning approach. In Proceedings of the 28th international conference on
machine learning (ICML-11), pp. 513-520, 2011.
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair,
Aaron Courville, and Yoshua Bengio. Generative adversarial nets. In Advances in neural infor-
mation processing systems, pp. 2672-2680, 2014.
Kurt Hornik, Maxwell Stinchcombe, and Halbert White. Multilayer feedforward networks are uni-
versal approximators. Neural networks, 2(5):359-366, 1989.
Sergey Ioffe and Christian Szegedy. Batch normalization: Accelerating deep network training by
reducing internal covariate shift. In International Conference on Machine Learning, pp. 448-456,
2015.
Nebojsa Jojic, Alessandro Perina, and Vittorio Murino. Structural epitome: a way to sum-
marize ones visual experience. In J. D. Lafferty, C. K. I. Williams, J. Shawe-Taylor, R. S.
Zemel, and A. Culotta (eds.), Advances in Neural Information Processing Systems 23,
pp. 1027-1035. Curran Associates, Inc., 2010. URL http://papers.nips.cc/paper/
4092-structural-epitome-a-way-to-summarize-ones-visual-experience.
pdf.
Eukasz Kaiser, Ofir Nachum, AUrko Roy, and Samy Bengio. Learning to remember rare events.
arXiv preprint arXiv:1703.03129, 2017.
Diederik Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint
arXiv:1412.6980, 2014.
Diederik P Kingma and Max Welling. Auto-encoding variational bayes. arXiv preprint
arXiv:1312.6114, 2013.
Gregory Koch, Richard Zemel, and Ruslan Salakhutdinov. Siamese neural networks for one-shot
image recognition. In ICML Deep Learning Workshop, volume 2, 2015.
Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classification with deep convo-
lutional neural networks. In Advances in neural information processing systems, pp. 1097-1105,
2012.
10
Under review as a conference paper at ICLR 2018
Yann LeCun, Bernhard E Boser, John S Denker, Donnie Henderson, Richard E Howard, Wayne E
Hubbard, and Lawrence D Jackel. Handwritten digit recognition with a back-propagation net-
work. In Advances in neural information processing systems, pp. 396-404, 1990.
Zhenguo Li, Fengwei Zhou, Fei Chen, and Hang Li. Meta-sgd: Learning to learn quickly for few
shot learning. arXiv preprint arXiv:1707.09835, 2017.
Akshay Mehrotra and Ambedkar Dukkipati. Generative adversarial residual pairwise networks for
one shot learning. arXiv preprint arXiv:1703.08033, 2017.
Nikhil Mishra, Mostafa Rohaninejad, Xi Chen, and Pieter Abbeel. Meta-learning with temporal
convolutions. arXiv preprint arXiv:1707.03141, 2017.
Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Alex Graves, Ioannis Antonoglou, Daan Wier-
stra, and Martin Riedmiller. Playing atari with deep reinforcement learning. arXiv preprint
arXiv:1312.5602, 2013.
Tsendsuren Munkhdalai and Hong Yu. Meta networks. arXiv preprint arXiv:1703.00837, 2017.
Masatoshi Nei and Sudhir Kumar. Molecular evolution and phylogenetics. Oxford university press,
2000.
Sachin Ravi and Hugo Larochelle. Optimization as a model for few-shot learning. ICLR, 2017.
Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng
Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, et al. Imagenet large scale visual
recognition challenge. International Journal of Computer Vision, 115(3):211-252, 2015.
Pranav Shyam, Shubham Gupta, and Ambedkar Dukkipati. Attentive recurrent comparators. arXiv
preprint arXiv:1703.00767, 2017.
Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for large-scale image
recognition. arXiv preprint arXiv:1409.1556, 2014.
Jake Snell, Kevin Swersky, and Richard S Zemel. Prototypical networks for few-shot learning. arXiv
preprint arXiv:1703.05175, 2017.
Jascha Sohl-Dickstein, Eric A Weiss, Niru Maheswaranathan, and Surya Ganguli. Deep unsuper-
vised learning using nonequilibrium thermodynamics. arXiv preprint arXiv:1503.03585, 2015.
Jiaming Song, Shengjia Zhao, and Stefano Ermon. A-nice-mc: Adversarial training for mcmc. arXiv
preprint arXiv:1706.07561, 2017.
Nitish Srivastava, Elman Mansimov, and Ruslan Salakhutdinov. Unsupervised learning of video
representations using LSTMs. In ICML, 2015.
Eleni Triantafillou, Richard Zemel, and Raquel Urtasun. Few-shot learning through an information
retrieval lens. arXiv preprint arXiv:1707.02610, 2017.
Oriol Vinyals, Charles Blundell, Tim Lillicrap, Daan Wierstra, et al. Matching networks for one
shot learning. In Advances in Neural Information Processing Systems, pp. 3630-3638, 2016.
Martin J Wainwright, Michael I Jordan, et al. Graphical models, exponential families, and variational
inference. Foundations and Trends® in Machine Learning, 1(1-2):1-305, 2008.
Kelvin Xu, Jimmy Ba, Ryan Kiros, Kyunghyun Cho, Aaron Courville, Ruslan Salakhudinov, Rich
Zemel, and Yoshua Bengio. Show, attend and tell: Neural image caption generation with visual
attention. In International Conference on Machine Learning, pp. 2048-2057, 2015.
11
Under review as a conference paper at ICLR 2018
Supplementary for
Discovering Order in Unordered Datasets:
Generative Markov Networks
Anonymous authors
Paper under double-blind review
1 Proof for Sec. 3.2
Here, we prove that
maxθ,π log	E P(π) ∩T(s∏(t)∣s∏(t-i); θ) = maxθ log I ɪɪ T(sπ*(t) lsπ*(t-1); θ)
π∈Π(n)	t=2	t=2
with
n
π* = argmax E log T(s∏(t)∣s∏(t-i); θ).
π∈Π(n) t=2
Proof:
For anyπ over Π(n), we have:
log (XP(π) YY T(s∏(t)∣s∏(t-1); θ)
π	t=2
≤ log (XP(∏) YY T(s∏*(t)∣s∏*(t-i); θ))
π	t=2
= log (XI(∏ = ∏*) YYT(Sn*(t) |sn*(t-1); θ)
π t=2
=log (YT(s∏*(t)∣s∏*(t-i); θ)),
where I(π = π*) is the indicator function that takes value 1 iff π = π* otherwise 0. Realize that
I(π = π*) also defines a valid distribution over Π(n), which proves our claim.
2 Example Images for Horse Dataset
Figure 1: RGB images of Horse Dataset.

k *W∙K 卜篁恢涧询**-FM 尿 MA" F N KZ>r∙K 界>r掰
Figure 2: Pre-processed images of Horse Dataset.
1
Under review as a conference paper at ICLR 2018
Horse dataset Borenstein & Ullman (2002) consists of images collected from Internet. Fig. 1 il-
lustrates these RGB images. Object-background segmentations are applied on these images and the
horses are centered in 30x40 images. The processed images are shown in Fig. 2.
3 FULL Ordering Results FOR MNIST, Horse, and MSRSenseCam
Fig. 3, 4, and 5 show the results of the implicit order observed from GMN the order implied from
Nearest Neighbor sorting. On the other hand, Fig. 6, 7, and 8 illustrate the sampling of GMN and
Nearest Neighbor search.
(a)
八 3 3∙<v∕q q q
35”777777
4B%2S十
000D633385
旦42 2 2 N2A∖2
623332Z4*0
GO O。OOOgH5
OC)OOoOOS22
(b)
Figure 3: For MNIST dataset: (a) implicit order observed from GMNs (b) order implied from nearest
neighbor sorting using Euclidean distance.
∕q∕3365dz
∕A∕83G5/ C<
∕qpoo3G5 ʃ ɔ
/7夕 X3&≤4*
/夕，4 3J3M¾
/ 夕 7N 3 / 5O2.6
/ y 74 3 / 3 ' *
/彳7又5厂g工&
—彳7幺0 U *2&
IG-770 歹 2τ-*⅛
- 9776 歹22 %
Iq775 歹 2ΛσD
∖q7z7SkJz-q
>Λ>、H *h B17)"XA„FFFFrFFFFFFFFFFrFfTTEK牖力 界
炉吩M、NMbM加、人加为独轴卜卜—小所加务—林4人人加・次内味卜方—为勾卜始言
招招 JhxK K WF a w'Xh、IhXXxXnXK K X 脑 jh w m ”*n*nr E Fr r F
(a)
FFAEWHmKEFrrF常XMKHrFM 询、相卜 >ιMXjh*∖ ⅜ ⅛ H
加掰* 声加 MXXh NX⅜r>r*M>τ>Γk>*XEM*⅝<W>n*K>rWM∙*>τEK›N'AMM
Wif^rTHFF窗T甯制方加KE√林片 ⅜ ⅜ > ⅛ ⅜ > ⅛ * ***麻 M *AH"X朴>r⅛4τ4
、人林 杵耳防&加加受火% ‰¼M KAXN乐"∙⅛r射篁―甘 *八学"—M>r廿力断MKKln
¼∙A*>r>rk⅝rkKX4>r⅝‰*⅝⅜><>⅜>r N	而 外商信”而冲 ffT∕WH"TTF∕∕⅜rZ XXX
(b)
Figure 4: For Horse dataset: (a) implicit order observed from GMNs (b) order implied from nearest
neighbor sorting using Euclidean distance.
2
Under review as a conference paper at ICLR 2018
Figure 5: For office category in SenseCam dataset: (a) implicit order observed from GMNs (b) order
implied from nearest neighbor sorting using Euclidean distance.
QiffQ IffQlffQJQlffQlffQlffQ QQ QQlffQlffQlffQlffQlffQQQlifQQQ Iff QQQlffQlffQlffQlffQlffQlff
匕	QKQiffGIOQl0QKbKGKQKQQQ	匕 QJQKQKQJQQQKQtQQQK
6 上 6 3 34646 上 6C6 3 646C6C6C64646C646C64646464646464646C
(β(a(β(a(β(t>(βlfi(βlf)(β(a(β(a(β(f>(βlΛ(θ(a(β(ff(β(i>(βla(β(β(β(a(βla(βli>(Ω(a(βlff(ffli>(βla(β(i>(βla(β(ff(β(a
QlffQiff GQQJQlffQlffQlffQlfiQlffQlffGlffQlffQlffQ L QQQlffQQQlffQltfQlffQ(ffQlfiQ4
6C6 6 646C6C6CG4646C6C64646C646464646C6464646C6C6464
6上64CC6上6上6C646C6上6C646C6C6上6C646C6上6上6上6乙6C6上6上
(b)
Figure 6: For MNIST dataset, data generation from (a) learned transition operator in GMNs (b)
nearest neighbor search using Euclidean distance.
4	Moving MNIST
<Moving MNIST> Moving MNIST (Srivastava et al., 2015) contains 10, 000 sequences each of
length 20 showing 2 digits moving in a 64x64 frame. We rescale the pixel values to [0, 1]. For each
training episode, we apply Alg. 2 to train GMN on one randomly chosen sequence with parameters
{boverlap, b, t} set as {0, 20, 10}. We consider 6, 000 training episodes. For evaluation, we randomly
sample a disjoint sequence from training sequences and observe the optimal permutation (implicit
order) from Alg. 1.
Fig. 9 illustrates the results for the implicit order observed from Generative Markov Networks, the
order inferred from Nearest Neighbor sorting using Euclidean distance, and the suggested explicit
order. We find that both the orders observed from GMN and NN sorting manifest smooth motions
for two digits in the frame. It is worth noting that our proposed GMN enjoys the freedom of not
defining any distance metric.
The sampling results for Moving MNIST dataset are shown in Fig. 10. We consider two approaches:
the proposed Generative Markov Networks and Nearest Neighbor search. We find that, by learning
the transition operator in a Markov chain as a generative model, GMN performs much better sam-
pling results than Nearest Neighbor search which is a discriminative model.
5	Network Architectures for Transition Operator
We elaborate the design of the transition operator in Fig. 11. In our design, U can be seen as a gating
mechanism between input Xt and the learned update X . More precisely, the output can be written
3
Under review as a conference paper at ICLR 2018
(a)
>vwv∣xwxrmEmrF>vn3KHrFM询片招卜imxw%h卜卜所掰意算加
HWhH 物 X>r>r¼∙M>τ>rk>*X降M-X>r*>rw*k 笫 Zw›TKKX'AkKFAnErE
FF*W为 制 K ■"办N"腑 K HyFMM、/*hXMX>∙∖W 卜 H M 加加片Z好XK 卜 ¼4H
>r>d标>Kk/XfK*—⅝√>n>r>r>r>r5■3•琳 X 七片 X H>T»>^>mXnF、rE
FFr F、FFFFFFFErFfTTET 舞粉舞W*N与bM 加 ¼⅜>r>⅝f¼HH>r^>?
"所》—样 AXA航冰•加尔卜内加 M ¼¼¼¼-h>ιι¼>^> >ι¼>r¼¼>>τ>^ n¼¼ ¼¼¼H¼
xxhkmkknx Ihm ”、中 >r>⅝r KXXENFF>v⅝v⅝⅝>mκM5Yfvι⅝FrF午 F
(b)
Figure 7: For Horse dataset, data generation from (a) learned transition operator in GMNs (b) nearest
neighbor search using Euclidean distance.
(a)
(b)
Figure 8: For office category in SenseCam dataset, data generation from (a) learned transition oper-
ator in GMNs (b) nearest neighbor search using Euclidean distance.
as
~ .
Xt+1 = U Θ X + (1 - U)Θ Xt,	(1)
where Θ denotes element-wise product. We specify each function f in TbL 1, 2, 3, 4, and 5. Note
that we omit the bias term for simplicity. We use ADAM (Kingma & Ba, 2014) with learning rate
0.001 and 0.2 dropout rate to train our T(∙∣∙; θ).
Table 1: Details of functions for MNIST experiments.
function	details
f1 784x512 FC layer With ReLU
f21	512x128 FC layer
f22	512x128 FC layer
f3 912x512 FC layer with ReLU
f41	512x784 FC layer with sigmoid
f42	512x784 FC layer With SigmOid
References
Eran Borenstein and Shimon Ullman. Class-specific, top-down segmentation. In European confer-
ence on computer vision, pp. 109-122. Springer, 2002.
Diederik Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint
arXiv:1412.6980, 2014.
Nitish Srivastava, Elman Mansimov, and Ruslan Salakhutdinov. Unsupervised learning of video
representations using LSTMs. In ICML, 2015.
4
Under review as a conference paper at ICLR 2018
Figure 9: For Moving MNIST dataset: (a) implicit order observed from GMNs (b) order implied
from nearest neighbor sorting using Euclidean distance (c) suggested explicit order.
(a)
(b)
Figure 10: For Moving MNIST dataset, data generation from (a) learned transition operator in
GMNs (b) nearest neighbor search using Euclidean distance.
Figure 11: Network design for T(∙∣∙; θ).
Table 2: Details of functions for Horse experiments.
function	details
f1 f21 f22 f3 f41 f42	1200x512 FC layer with ReLU 512x128 FC layer 512x128 FC layer 912x512 FC layer with ReLU 512x1200 FC layer with sigmoid 512x1200 FC 山yer With Sigmoid
Table 3: Details of functions for MSR-SenseCam experiments.
function	details
f1	4096x1024 FC layer with ReLU
f21	1024x256 FC layer
f22	1024x256 FC layer
f3	4352x1024 FC layer with ReLU
f41	1024x4096 FC layer with sigmoid
箕2	1024x4096 FC layer
Table 4: Details of functions for Moving MNIST experiments.
function	details
f1 4096x1024 FC layer With ReLU
f21	1024x256 FC layer
f22	1024x256 FC layer
f3 4352x1024 FC layer with ReLU
f41	1024x4096 FC layer with sigmoid
f42	1024x4096 FC layer with sigmoid
5
Under review as a conference paper at ICLR 2018
	Table 5: Details of functions for miniImageNet experiments.
function	details
fl f21 f22 f3 f41 f42	1600x1024 FC layer With ReLU 〃1024x512 FC layer With ReLU // 512x256 FC layer With ReLU 256x64 FC layer 256x64 FC layer 1664x256 FC layer With ReLU 256x512 FC layer With ReLU // 512x1024 FC layer With ReLU // 1024x1600 FC layer With sigmoid 256x512 FC layer With ReLU // 512x1024 FC layer With ReLU //1024x1600 FC layer
6