Under review as a conference paper at ICLR 2018
Generative Discovery of Relational Medical
Entity Pairs
Anonymous authors
Paper under double-blind review
Ab stract
Online healthcare services can provide the general public with ubiquitous access
to medical knowledge and reduce the information access cost for both individuals
and societies. To promote these benefits, it is desired to effectively expand the
scale of high-quality yet novel relational medical entity pairs that embody rich
medical knowledge in a structured form. To fulfill this goal, we introduce a gener-
ative model called Conditional Relationship Variational Autoencoder (CRVAE),
which can discover meaningful and novel relational medical entity pairs without
the requirement of additional external knowledge. Rather than discriminatively
identifying the relationship between two given medical entities in a free-text cor-
pus, we directly model and understand medical relationships from diversely ex-
pressed medical entity pairs. The proposed model introduces the generative mod-
eling capacity of variational autoencoder to entity pairs, and has the ability to
discover new relational medical entity pairs solely based on the existing entity
pairs. Beside entity pairs, relationship-enhanced entity representations are ob-
tained as another appealing benefit of the proposed method. Both quantitative and
qualitative evaluations on real-world medical datasets demonstrate the effective-
ness of the proposed method in generating relational medical entity pairs that are
meaningful and novel.
1	Introduction
Increasingly, people engage in health services on the Internet (Fox & Duggan, 2013). The healthcare
services can provide the general public with ubiquitous access to medical knowledge and reduce
the information access cost significantly. The relational medical entity pair, which consists of two
medical entities with a semantic connection between them, is an intuitive representation that distills
human medical reasoning processes in a structured form. The medical relationships discussed in this
paper are binary ones. For example, the Disease-C-a-u-s→e Symptom relationship indicates a “Cause”
relationship from a disease entity to a symptom entity that is caused by this disease, such as the
medical entity pairs <Synovitis, Joint Pain>. For the relationship Symptom-B-e-l-on-g-t→o Department,
we may have a relational medical entity pair such as <Stiffness of a Joint, Orthopedics>.
The ability to understand, reason and generalize is central to human intelligence (Oaksford & Chater,
2007). However, it possesses significant challenges for machines to understand and reason about
the relationships between two entities (Santoro et al., 2017). Real-world relational medical entity
pairs possess certain challenging properties to deal with: First, as the medical research develops,
many medical relationships among medical entities that were once neglected due to the underdevel-
oped medical knowledge now need to be discovered. An increasing number of relationships will
be formed among a large number of medical entities. Also, various linguistic expressions can be
used for the same medical entity. For example, Nose Plugged, Blocked Nose and Sinus Congestion
are symptom entities that share the same meaning but expressed very differently. Moreover, one
medical relationship may instantiate entity pairs with varying granularities or relationship strength.
C ause
For instance, Disease---→Symptom may include entity pairs like <Rhinitis, Nose Plugged> as
a coarse-grained entity pair, while < Acute Rhinitis, Nose Plugged>, <Chronic Rhinitis, Nose
Plugged> are considered fine-grained entity pairs. As for the relationship strength, <Cold, Fa-
tigue> has greater relationship strength than <Cold, Ear Infections> as cold rarely cause serious
complications such as ear infections.
1
Under review as a conference paper at ICLR 2018
To effectively expand the scale of high-quality yet novel relational medical entity pairs, relation ex-
traction methods (Culotta et al., 2006; Bach & Badaskar, 2007) are proposed to examine whether
or not a semantic relationship exists between two given entities given a context. Although the ex-
isting relation extraction methods (Agichtein & Gravano, 2000; Baeza-Yates & Tiberi, 2007; Sahay
et al., 2008; Yu & Lam, 2010; Chang et al., 2014; Wang et al., 2015) achieve decent performance in
identifying the relationship for given entity pairs, those methods require contexts such as sentences
retrieved from a large free-text corpus, from existing domain-specific knowledge graphs (Abacha &
Zweigenbaum, 2011), or from web tables and links (Lin et al., 2010). As medical relationships in
the real-world are becoming more and more complex and diversely expressed, existing relation ex-
traction methods suffer from the data sparsity problem where it is hard to obtain additional external
knowledge that covers all possible entity pairs, e.g. free-text corpus where two entities co-occur in
the same sentence with a relationship between them. Therefore, it is crucial and appealing for us
to discover meaningful relational medical entity pairs solely based on existing medical entity pairs,
without the requirement of a well-maintained context as an additional external knowledge.
Furthermore, most relation extraction methods adopt a discriminative approach that learns to dis-
tinguish entity pairs of one relationship from the other (Zeng et al., 2014; Lin et al., 2016), or to
identify meaningful entity pairs from randomly sampled negative entity pairs with no relationships
(Bordes et al., 2013; Socher et al., 2013). Those methods need to iterate over the combination of
all possible entity pairs and check each of them to discover new entity pairs. Such discriminative
approach is tedious and labor-intensive. It is challenging yet rewarding for us to understand med-
ical relationships intrinsically from the existing entity pairs. Specifically, in the medical domain,
the diversely expressed medical entity pairs offer great advantages for us to ultimately understand
medical relationships and discover high-quality relational medical entity pairs solely from existing
meaningful medical entity pairs.
Problem Studied: We propose a novel research problem called RElational Medical Entity-pair
DiscoverY (REMEDY), which aims at modeling relational medical entity pairs solely from the ex-
isting entity pairs. Also, it aims to discover meaningful and novel entity pairs pertaining to a certain
medical relationship in a generative fashion, without sophisticated feature engineering and the re-
quirement of external knowledge such as free-text corpora.
Proposed Model: A generative model named Conditional Relationship Variational Autoen-
coder (CRVAE) is introduced for relational medical entity pair discovery. It is unlikely to create
meaningful, novel relational medical entity pairs without intrinsically understanding each medical
relationship, more specifically, understanding the relationships between every two medical entities
that instantiate a particular relationship. CRVAE fully explores the generative modeling capacity
which roots in Bayesian inference while incorporating deep learning for powerful hands-free fea-
ture engineering. CRVAE is trained to encode each relational medical entity pair into a latent space
conditioned on the relationship type. The encoding process addresses relationship-enhanced entity
representations, interactions between entities as well as expressive latent variables. The latent vari-
ables are decoded to reconstruct entity pairs. Once the model is trained, we can sample directly from
the distribution of latent variables and decode them into high-quality and novel relational medical
entity pairs.
Overall, CRVAE has three notable strengths:
CRVAE models the intrinsic relations between medical entity pairs directly based on the ex-
isting meaningful relational medical entity pairs, without the requirement of additional external
contexts for entity pair extraction. Existing relation extraction methods usually rely on the free-text
corpus to decide whether a candidate entity pair it mentions is meaningful or not. The CRVAE only
utilizes the existing entity pairs and pre-trained word vector as initial entity representations which
are trained separately.
CRVAE is able to generate entity pairs for a particular relationship, even if it observes existing
entity pairs only for that particular relationship. Unlike most discriminative methods which harness
discrepancies among different relationships to distinguish the relationship of an entity pair from
the other, or from randomly constructed negative entity pairs with no relations. The CRVAE un-
derstands the intrinsic medical relation from diversely expressed medical entity pairs and discovers
meaningful, novel entity pairs of a particular relationship that we specified.
2
Under review as a conference paper at ICLR 2018
CRVAE generates novel entity pairs by a density-based sampling strategy in the generator. The
generator samples directly from the latent space based on the density of hidden parameters. With the
hands-free feature engineering by deep neural networks, the model is able to discover meaningful
and novel entity pairs which does not exist in the training data.
The contributions of this paper can be summarized as follows:
•	We study the Relational Medical Entity-pair Discovery (REMEDY) problem, which aims
to expand the scale of high-quality yet novel relational medical entity pairs without main-
taining large-scale context information such as the free-text corpus.
•	We propose a generative model named Conditional Relationship Variational Autoen-
coder (CRVAE) that discovers relational medical entity pairs for a given relationship, solely
from the diversely expressed entity pairs without sophisticated feature engineering.
•	We obtain relationship-enhanced entity representations as an appealing benefit of the pro-
posed model.
2	Conditional Relationship Variational Autoencoder
In this section, we introduce the Conditional Relationship Variational Autoencoder (CRVAE) model
for the REMEDY problem. The proposed model consists of three modules: encoder, decoder, and
generator. The encoder module takes relational medical entity pairs and a relationship indicator as
the input, trained to intrinsically understand each relationship by translating and mapping the entity
pair to a latent space as Qφ . The decoder is jointly trained to reconstruct the entity pairs as Pθ .
The generator model shares the same structure with the decoder, and it directly samples from the
learned latent variable distribution to creatively generate meaningful medical relational entity pairs
for a particular relationship. Figure 1 gives an overview of the proposed model.
囱A
区A
embedh transh
embedt trans
trans
ht
embed′
h
Encoder
Qφ (Z embedfι, embedt, r)
trans′h
P--P	Pθ [ embedfι, embed∖z '[	---
Latent Variables	Decoder
embedt
Figure 1: An overview of Conditional Relationship Variational Autoencoder (CRVAE) for Relational
Medical Entity-pair Discovery during training. The encoder module is show in green color and the
decoder module is show in blue. Model inputs are in white color.
The model takes a tuple <eh, et> and a relationship indicator r as the input, where eh and et are
head and tail medical entity of a relationship r. For example, eh =“Synovitis” and et=“Joint Pain”,
C ause
while the corresponding r is an indicator for Disease-→Symptom.
To effectively represent medical entities, pre-trained word embeddings that embody rich semantic
information can be obtained as initial entity representations for eh and et. For simplicity, Skip-gram
(Mikolov et al., 2013) is adopted to obtain 200-dimensional word embeddings trained separately and
unsupervisely on a publicly accessible medical corpus. After a table lookup on the pre-trained word
vector matrix Wembed ∈ RV ×DE where V is the vocabulary size (usually tens of thousands) and DE
is the dimension of the initial entity representation (usually tens or hundreds), embedh ∈ R1×DE
and embedt ∈ R1×DE are derived as the initial embedding of medical entities.
2.1	Encoder
With the initial entity representation embedh and embedt and their relationship indicator r, the
encoder first translates and then maps entity pairs to a latent space as Qφ(z∣embedh, embedt, r).
3
Under review as a conference paper at ICLR 2018
2.1.1	Translating for Relationship-enhancing
The initial embedding obtained from word embedding reflects semantic and categorical information.
However, it is not specifically designed to model the medical relationship among medical entities
(See observations in Section 3.4.3). To get entity representations that address relationship informa-
tion, the encoder learns to translate each medical entity from its initial embedding to a relationship-
enhanced embedding that distills relationship information. For example, a non-linear transformation
can be used: translate(x) = f (x∙Wtrans +btrans) where f can be an non-linear activation function
such as the Exponential Linear Unit (ELU) (Clevert et al., 2015). Wtrans ∈ RDE ×DR is the weight
variable and btrans ∈ R1×DR is the bias where DR is the dimension for relationship-enhanced
embeddings.
trans h = translate(embed_h), transt = translate(embed_t)	(1)
are obtained as relationship-enhanced embeddings for eh and et.
2.1.2	Mapping to Latent Variables
The relationship-enhanced entity representation transh and transt are concatenated transht =
[transh , transt] and mapped to the latent space by multiple fully connected layers. For ex-
ample, we can obtain a variable lht that addresses the relationship information, as well as en-
tity interactions from two medical entities, by applying three consecutive non-linear fully con-
nected layers on transht . As a variational inference model, we assume a simple Gaussian dis-
tribution of Qφ(z∖embedh, embed,r) for the relational medical entity pair <eh,et> with a re-
lationship r. Therefore, for each relational medical entity pair <eh, et> and a relationship in-
dicator r, a mean vector μ and a variance vector σ2 can be learned as latent variables to model
Qφ(z∣embedh, embedt, r):
μ =	[lht, r]	∙	Wμ	+ bμ,	σ2 =	[lht, r]	∙	Wσ	+ b。,	⑵
where a one-hot indicator r ∈ R1×lRl is used for the medical relationship r and |R| is the number of
all relationships. Wμ,Wσ ∈ R(Dlht+lRl)×DL are weight terms and bμ,bσ ∈ R1×DL are bias terms.
DL is the dimension for latent variables and Dlht is the dimension for lht. To stabilize the training,
we model the variation vector σ2 by its log form log σ2 (to be explained in Equation 15).
2.2	Decoder
Once We obtain latent variables μ, σ2 for an input tuple <eh, et> which has the relationship r, the
decoder uses latent variables and the relationship indicator r to reconstruct the relational medical
entity pair. The decoder implements the Pθ (embedh, embedt |z, r).
Given μ, σ2, it is intuitive to sample the latent value Z from the distribution N(μ, σ2) directly. How-
ever, such operator is not differentiable thus optimization methods failed to calculate its gradient. To
solve this problem, a reparameterization trick is introduced in Kingma & Welling (2014) to divert
the non-differentiable part out of the network. Instead of directly sampling from N(μ, σ2 ),we sam-
ple from a standard normal distribution E 〜N(0, I) and then convert it back to Z by Z = μ + σe. In
this way, sampling from does not depend on the network.
Similarly as the use of multiple non-linear fully connected layers for the mapping in the encoder,
multiple non-linear fully connected layers are used for an inverse mapping in the decoder. After the
inverse mapping we obtain trans0ht ∈ R1×2DR. The first DR dimensions of trans0ht are considered
as a decoded relationship-enhanced embedding for eh, while the last DR dimensions are for et:
trans0h = trans0ht [: DR] ,	trans0t = trans0ht [DR :] ,	(3)
where trans0h, trans0t ∈ R1×DR. trans0h and trans0t are further inversely translated back to the
initial embedding space RDE :
embedh = f (transh ∙ Wtransunv
+ btr
ans_inv
),
embed0t
f (tIranst ∙ ^^trans_inv
+ btr
ans_inv
),
(4)
where embed0h, embed0t ∈ R1×DE are considered as reconstructed representations for embedh and
embedt.
4
Under review as a conference paper at ICLR 2018
2.3	Training
Inspired by the loss function of the conditional variational autoencoder (CVAE) (Kingma et al.,
2014; Sohn et al., 2015), the loss function of CRVAE is formulated to minimize the variational
lower bound:
LCRVAE(embedh, embedt,r; θ, φ) =	(5)
—KL [Qφ (z∣embedh, embedt, r) ∣∣Pθ (z|r)] + E [log (Pρ (embedh, embedt∣z, r))],
where Qφ (z|embedh, embedt, r) is a simple Gaussian distribution used to approximate the un-
known true distribution Pθ (z|embedh, embedt, r). Pθ (z|r) describes the true latent distribution z
given a certain relationship r and E [log (Pθ (embedh, embedt|z, r))] estimates the maximum like-
lihood.
A closed-form solution for the first term can be derived as:
- 2 x (eχp (σ2)ι+μ2 -
l
1 - σl2,
(6)
where μ is the mean vector and σ2 is the variance vector. l in the subscript indicates the l-th dimen-
sion of the vector. Details for obtaining the closed-form solution are given in Appendix A
The second term penalizes the maximum likelihood, which is the conditional probability
Pθ(embedh, embedt|z, r) of a certain entity pair <eh, et> given the latent variable z and the re-
lationship indicator r. The mean squared error (MSE) is adopted to calculate the difference between
<embedh, embedt > and <embed0h, embed0t >:
E [log (Pθ (embedh, embedt|z, r))]
(∣∣embedh — embedh∣∣2 + ∖∖embedt — embed；||2),
E	(7)
where ∣∣∙k2 is the vector '2 norm. To minimize the Lcrvae, existing optimizers such as Adadelta
(Zeiler, 2012) can be used. Furthermore, a warm-up technique introduced in S0nderby & Raiko
(2016) can let the training start with deterministic and gradually switch to variational, by multiplying
β to the first term. The final loss function used for training is formulated as:
LCRVAE = _22 P (exp (σ2)ι + μ2 - 1 一 log σ2) + 2D1E
— embed0h ∖∖22 + ∖∖embedt — embed0t∖∖22 ,
(8)
where β is initialized as 0 and increase by 0.1 at the end of each training epoch, until it reaches 1.0
as its maximum.
2.4	Generator
When we have a certain relationship r in our mind that the generated relational medical entity pairs
should belong to, a density-based sampling method is introduced for the generator to sample Z from
the latent space given a certain relationship r.
Instead of using the latent variable z provided
by certain μ and log σ2 in the encoding process
from a certain eh , et and r, the generator tries
to sample Z directly from P⅛(Z|r) to get the la-
tent space value Z for a particular relationship
r. Once Z is obtained, the decoder structure
is used to decode the relational medical entity
pair. Figure 2 illustrates the generative process.
Density-based
Sampling
□ S %
PP (中)
Generator
D-
卜
e mbedh
embedt

⅛
r
The denser region in the latent space Pq(Z∣r)
indicates that more densely entity pairs are lo-
cated in the manifold. Therefore, a sampling
method that considers the density distribution
of Pq(Z∖r) samples more often from the denser
regions in the latent space so as to preserve the
Figure 2: The generator that generate meaningful,
novel relational medical entity pairs from the la-
tent space.
5
Under review as a conference paper at ICLR 2018
true latent space distribution of the sampled values. Specifically, for each relationship r, the density-
based sampling samples Z directly from Pθ(Z|r)〜N(0, I), when trained properly. The resulting
vectors ^mbedh and ^mbedt are mapped back to their entities in the initial embedding space R1 × DE,
namely ^h, and ^t, by finding the nearest neighbor of the initial entity representation using Wembed.
The `-2 distance measure is used for the nearest neighbor search.
3	Experiments
3.1	Dataset & Training Details
The dataset consists of 46.02k real-world relational medical entity pairs in Chinese from a Chinese
online healthcare forum www.xywy.com. The data set covers six different types of medical rela-
tionships. Table 1 shows the collection of relational medical entity pairs used in this study. 70%
data are used for training and 30% for validation.
Table 1: Sample Medical Relationships and relational medical entity pairs.
MEDICAL RELATIONSHIP	COUNT	RELATIONAL MEDICAL ENTITY PAIRS
Cause Disease 	→ Body Part	2320	‹三尖瓣闭锁（fr∕cM卯泊加5诚/诂耳勺），三尖瓣（械皿5口1dvalve） > ‹ 阴道癌（vaginal cancer）,生殖（r2口2壮式《加2 system） > ‹ 脑积水（hydrocephaly）,头部3ead） >
RelatedT o Disease 	→ Disease	4614	< 婴儿脑积水(in⅛nt hydroCephalus),先天性脑积水(congenital hydrocephalus) > < 尿道炎(urethritis),膀胱炎(cystitis) > <食滞胃脘(幻0n汇。〃 of food in the sto优ach),小儿消化不良«确加而indigestion) >
Disease -N-e-e→d Examine	4185	< 水杨酸类中毒(salicylates poisoning),尿常规(routine urianlysis) > < 法洛三联症(tetralogy triad),心电图(electrocardiogram, ECG) > < 附睾炎(epididymitis),提睾反射(CremaSteriC reflex) >
BelongT o Symptom 	→ Department	8595	‹ 关节强直(anchylosis, StiffneSS of a joint),骨科(orthopedics) > < 女性小腹疼痛(Female lower abdominal pain),妇科(gynecology) > < 吸吮反射消失(absent infant sucking reflex),新生儿科(neonatology) >
Cause Disease 	→ Symptom	16642	< 腹膜炎(peritonitis),腹部静脉怒张(abdominal venous engorgement) > < 尿道炎(urethritis),尿道痒感(urethra itching) > < 桡神经麻痹(radial nerve palsy),上肢无力(upper extremity weakness) >
RelatedT o Symptom 	→ Symptom	9662	‹ 脐周红肿(redness and swelling around the umbilicus),脐周肿胀(periumbilical swelling) > < 肌肉挫伤(muscular contusion),肌腱断裂(disinsertion) > ‹ 手指冻肿(^ngerS benumbed with cold),皮肤冻伤(skin frostbite) >
We use 200-dimensional word embeddings learned with the Skip-gram algorithm in Mikolov et al.
(2013), trained from 6 million text corpus on the Chinese online healthcare forum as the initial entity
representation. The vocabulary covers 126,270 words. We use Xavier initialization (Glorot & Ben-
gio, 2010) for weight variables and zeros for biases. A wide range of hyperparameter configurations
are tested with the proposed model. See Appendix B for detailed hyperparameter analysis.
3.2	Performance Evaluation
For each medical relationship, 1000 entity pairs are generated. Three evaluation metrics are intro-
duced to quantitatively measure the generated relational medical entity pairs: quality, support, and
novelty.
Quality Since it is hard for the machine to evaluate whether a relational medical entity pair is
meaningful or not, human annotation is involved in assessing the quality of the generated relational
medical entity pairs. A human annotation task is deployed on Amazon Mechanical Turk for anno-
tation (Task shown in Appendix C). Similar as the precision metric adopted in Bach & Badaskar
(2007), the quality1 is measured by:
quality =
# of entity pairs that are meaningful
# of all the generated entity pairs .
(9)
1 Note that metrics such as recall is not applicable in such generative discovery task as the total population
of positive samples is unknown.
6
Under review as a conference paper at ICLR 2018
Support Besides the quality metric, a support metric is developed to quantitatively measure the
degree of belongingness of a generated entity pair to a relationship. For each generated relational
medical entity pair <eh, ^t> and a candidate relationship rc, the support score is calculated by:
SUPPort<eiτ,et,rc>
1
1 + distance(embedh, embedt)
(10)
where distance(embedh, embedt) calculates the distance between the vector ^mbedh -embedt and
NNrc (embedh - embedt) using distance measure such as cosine distance. The NNrc implements
the nearest neighbor search over the embedh - embedt space on all the training data which has
the relationship rc . For each generated medical entity pair, the support scores for all the candidate
relationships are normalized so that they sum up to one:
normSuppθrt<^h,^t,rc> = IRsUpp0rt<eh,et,rc> .	(II)
P SUppOrt<^h,^t,r>
The relationship having the highest score is considered as the estimated relationship for <eh, ^t>
while the relationship r given during the generating process is considered as the ground truth for
<e^h, ^t>. The final support value is based on the accuracy of the estimated relationship and the
ground truth relationship.
Novelty The ability to generate novel relational medical entity pairs is one of our key contributions.
Due to different scope of medical knowledge among individuals, human annotators are not able to
precisely evaluate the novelty. We measure the novelty of the generation process by:
nOv elty
# of entity pairs that do not exist in the dataset
# of all the generated entity pairs
(12)
3.3	Baselines
Considering that no known methods are currently available for the REMEDY problem, we compare
the performance of the following models:
•	CRVAE-MONO: The proposed model which only takes one single type of relational med-
ical entity pairs in both training and generation. For each type of relationship, we train a
separate CRVAE only with entity pairs having that relationship.
•	RVAE: The unconditional version of the model CRVAE where the relationship indicator r
is not provided during model training and generation.
•	CRVAE-RAND: The proposed model CRVAE with a random sampling based generator.
Unlike the density-based sampling adopted in CRVAE, the generator of CRVAE-RAND
samples randomly from the latent space.
•	CRVAE: The proposed method where relational medical entity pairs that belong to all types
of relationships are used to train the model altogether. The training is conditioned on rela-
tionships and density-based sampling is used.
•	CRVAE-WA: The proposed method with the warm-up strategy introduced in Section 2.3.
3.4	Experiment Res ults
We summarize the performance of the proposed method, along with other alternatives, in Table 2.
CRVAE-MONO demonstrates the power of generative models in terms of learning the intrinsic
representation and generating new entity pairs only given one type of relationship during the training
(Quality: 0.6698, Support: 0.9550, Novelty: 0.5118). For CRVAE-RAND, although it generates
highly novel (0.9952) entity pairs that are not seen in the training data, the generated entity pairs are
of low quality (0.2550). By comparing CRVAE and CRVAE-RAND, we can see that the density-
based sampling enables the generation of high-quality entity pairs that results in +47.58% in quality
and +52.84% in support. The warm up technique adopted in CRVAE-WA is able to give CRVAE a
further performance boost, where all measures improve consistently (+4.09% in quality, +2.43% in
support and +5.11% in novelty).
7
Under review as a conference paper at ICLR 2018
Table 2: Performance of the proposed method with other baselines.
MODEL NAME	QUALITY	SUPPORT	NOVELTY	LOSS (TRAIN / VALID)
CRVAE-MONO	0.6698	0.9550	0.5118	47.3002 / 116.6739
CRVAE-RAND	0.2550	0.3764	0.9952	43.0954 / 83.6589
CRVAE	0.7308	0.9048	0.5682	43.0954 / 83.6589
CRVAE-WA	0.7717	0.9291	0.6193	33.4399 / 57.9470
As a qualitative measure, we also provide relational medical entity pairs generated by the proposed
model. For example, the entity pair <痢疾(dysentery), ½(intestine)> is generated given the medical
relationship Disease-aus→Body Part, while entity pairs such as < 阿米 巴痢疾(amebic dysentery),
½(intestine)> and <细菌性痢疾SaCteriR dysentery),胸部(Mest)> are found in the training data.
More entity pairs generated by the proposed method can be found in Appendix D.
3.4.1	Generative Modeling Capability
Unlike discriminative models which utilize the difference between instances of different classes
to discriminate instances from one class to another, the proposed method purely learns from the
existing relational medical entity pairs to generate new entity pairs. To validate such appealing
property, Table 3 compares the fine-grained quality, support and novelty of entity pairs generated by
CRVAE-MONO and CRVAE on each relationship.
Table 3: Quality, support and novelty metrics of the generated relational medical entity pairs by
CRVAE-MONO and CRVAE.
CRVAE-MONO	QUALITY	SUPPORT	NOVELTY	LOSS (TRAIN/VALID)
Disease-C-a-u-s→e Body Part	0.683	1.000	0.488	54.9830 / 126.7426
RelatedT o Disease	→Disease	0.689	0.870	0.483	51.5131 / 155.0721
Need Disease---→Examine	0.708	1.000	0.521	54.7635 / 136.4802
BelongT o Symptom	→Department	0.687	1.000	0.466	39.0959 / 72.5872
C ause Disease	→Symptom	0.587	0.940	0.573	37.3276 / 83.8797
RelatedT o Symptom	→Symptom	0.665	0.920	0.540	46.1180 / 125.2818
CRVAE				
Disease-C-a-u-s→e Body Part	0.756	0.999	0.724	
RelatedT o Disease	→Disease	0.691	0.744	0.867	
Need Disease---→Examine	0.757	0.981	0.871	43.0954 / 83.6589
BelongT o Symptom	→Department	0.768	0.995	0.613	
C ause Disease	→Symptom	0.702	0.882	0.927	
RelatedT o Symptom	→Symptom	0.711	0.828	0.888	
As shown in Table 3, the CRVAE-MONO on each relationship achieves a reasonable performance,
which shows the capability of generative models in understanding every single medical relationship
individually. Furthermore, when all types of entity pairs are trained and generated altogether in
CRVAE, we observe a consistent improvement in not only quality but also novelty.
3.4.2	Effectivenes s of Density-based Sampling
To validate the effectiveness of the density-based sampling for the generator, we compare the pro-
posed method with CRVAE-RAND where a random sampling strategy is adopted. From Table 2
we can see that the random sampling strategy in CRVAE-RAND tends to generate more entity pairs
that are not seen in the existing dataset. However, we observe a significant reduction in the quality
8
Under review as a conference paper at ICLR 2018
and support of the generated entity pairs when compared with CRVAE which adopts a density-based
sampling. The dense region in the latent space indicates that more densely entity pairs are located.
Therefore, in CRVAE, the quality and support of the generated entity pairs benefit from sampling
more often at denser regions in the latent space, resulting in less novel but higher quality entity pairs.
3.4.3	Effectivenes s of Relationship-enhancing Entity Adjustment
As mentioned in Section 2.1.1, the translating layer adjusts the original embedding to get
relationship-enhanced entity representations. In the experiments, we study the embedding spaces
before/after translation and observe that in the original embedding space, the Skip-gram tends to
put entities that share similar context (e.g. muscle strain and pull-up) in proximity. While after
relationship-enhancing, entities with similar functionalities in the same medical relationship are
nearby with each other (e.g. heart malformations and chromosome abnormalities). See Appendix E
for details.
3.4.4	Ability to Infer Conditionally
One of our key contributions is that with proper training, the proposed method can generate relational
medical entity pairs given a certain relationship. That is, the ability to infer new entity pairs for a
particular relationship. Besides seamlessly incorporating this idea in the model design, we also
visualize latent space of CRVAE and RVAE in order to show the conditional inference ability. See
Appendix F for details.
4	Related Works
Generative Models: Recent years have witnessed an increasing interests in the research topic of
generative models, which aims to generate observable data values based on some hidden parameters.
Various generative models have been developed, such as Generative Adversarial Networks (GANs)
(Goodfellow, 2016; Radford et al., 2015) and Variational Autoencoders (VAEs) (Kingma & Welling,
2013; Kingma et al., 2014; Sohn et al., 2015; Higgins et al., 2016; Nalisnick & Smyth, 2017). Unlike
GANs which generate data based on arbitrary noises, the VAE setting adopted in this paper is more
expressive for our task since it tries to model the underlying probability distribution of the data by
latent variables so that new data from that distribution can be sampled accordingly.
There are some generative models and applications considering data in different modalities, such
as generating images (Pu et al., 2016; Gregor et al., 2015; Dilokthanakul et al., 2016) or natural
language texts (Bowman et al., 2016; Marcheggiani & Titov, 2016; Hu et al., 2017; Xu et al., 2017).
As far as we know, the relational medical entity pair discovery problem we studied in this paper,
which suits the generative purpose, has not been studied in a generative perspective.
Relationship Extraction: There is another related research area that studies relation extraction,
which usually amounts to examining whether or not a relation exists between two given entities
(Culotta et al., 2006). Most relationship extraction methods require large amounts of high-quality
external information, such as a large text corpus (Baeza-Yates & Tiberi, 2007; Agichtein & Gravano,
2000; Sahay et al., 2008; Yu & Lam, 2010) and knowledge graphs (Wang et al., 2015; Chang et al.,
2014; Syed et al., 2010). However, it is tedious and time-consuming to check each possible pair over
all combinations of entities in the entity space. Thus, we propose an effective generative method that
generates meaningful and novel relational medical entity pairs directly. Also, it is time consuming
to collect and prepare a large corpus that covers all the mentions of those entity pairs, which makes it
difficult to apply those methods. In this work, our model does not rely on additional external corpus
for entity pair discovery.
Moreover, previous discriminative models usually need negative samples for supervised training.
For example, Socher et al. (2013) trains the model to distinguish entity pairs with a relationship
from randomly generated entity pairs as negative samples, while our model is can understand the
medical relationship only from rational relational medical entity pairs thus even works when being
fed with entity pairs having the same relationship type.
9
Under review as a conference paper at ICLR 2018
5	Conclusion
To effectively expand the scale of high-quality relational medical entity pairs which store the med-
ical knowledge, a novel generative model named Conditional Relationship Variational Autoen-
coder (CRVAE) is introduced for Relational Medical Entity-pair Discovery (REMEDY). The pro-
posed model fully explores the generative modeling ability while incorporates deep learning for
powerful hands-free feature engineering. Unlike traditional relation extraction tasks which require
additional contexts for extraction and need negative samples for discriminative training, the pro-
posed method learns to intrinsically understand the medical relations from diversely expressed med-
ical entity pairs, without the requirement of external context information. Moreover, it is able to
generate meaningful, novel entity pairs for a given type of medical relationship. The relationship-
enhanced entity representations have the potential to improve other NLP tasks. The performance of
the proposed method is evaluated on real-world medical data both quantitatively and qualitatively.
References
Asma Ben Abacha and Pierre Zweigenbaum. Automatic extraction of semantic relations between
medical entities: a rule based approach. Journal of biomedical semantics, 2(5):S4, 2011.
Eugene Agichtein and Luis Gravano. Snowball: Extracting relations from large plain-text collec-
tions. In Proceedings ofthe fifth ACM conference on Digital libraries,pp. 85-94. ACM, 2000.
Nguyen Bach and Sameer Badaskar. A review of relation extraction. Literature review for Language
and Statistics II, 2, 2007.
Ricardo Baeza-Yates and Alessandro Tiberi. Extracting semantic relations from query logs. In
Proceedings of the 13th ACM SIGKDD international conference on Knowledge discovery and
data mining, pp. 76-85. ACM, 2007.
Antoine Bordes, Nicolas Usunier, Alberto Garcia-Duran, Jason Weston, and Oksana Yakhnenko.
Translating embeddings for modeling multi-relational data. In Advances in neural information
processing systems, pp. 2787-2795, 2013.
Samuel R Bowman, Luke Vilnis, Oriol Vinyals, Andrew M Dai, Rafal Jozefowicz, and Samy Ben-
gio. Generating sentences from a continuous space. CoNLL 2016, pp. 10, 2016.
Kai-Wei Chang, Scott Wen-tau Yih, Bishan Yang, and Chris Meek. Typed tensor decomposition of
knowledge bases for relation extraction. 2014.
Djork-Ame Clevert, Thomas Unterthiner, and Sepp Hochreiter. Fast and accurate deep network
learning by exponential linear units (elus). arXiv preprint arXiv:1511.07289, 2015.
Aron Culotta, Andrew McCallum, and Jonathan Betz. Integrating probabilistic extraction models
and data mining to discover relations and patterns in text. In Proceedings of the main conference
on Human Language Technology Conference of the North American Chapter of the Association
of Computational Linguistics, pp. 296-303. Association for Computational Linguistics, 2006.
Nat Dilokthanakul, Pedro AM Mediano, Marta Garnelo, Matthew CH Lee, Hugh Salimbeni, Kai
Arulkumaran, and Murray Shanahan. Deep unsupervised clustering with gaussian mixture varia-
tional autoencoders. arXiv preprint arXiv:1611.02648, 2016.
John Duchi, Elad Hazan, and Yoram Singer. Adaptive subgradient methods for online learning and
stochastic optimization. Journal of Machine Learning Research, 12(Jul):2121-2159, 2011.
Susannah Fox and Maeve Duggan. Health online 2013. Washington, DC: Pew Internet & American
Life Project, 2013.
Xavier Glorot and Yoshua Bengio. Understanding the difficulty of training deep feedforward neural
networks. In Proceedings of the Thirteenth International Conference on Artificial Intelligence
and Statistics, pp. 249-256, 2010.
Ian Goodfellow. Nips 2016 tutorial: Generative adversarial networks. arXiv preprint
arXiv:1701.00160, 2016.
10
Under review as a conference paper at ICLR 2018
Karol Gregor, Ivo Danihelka, Alex Graves, Danilo Rezende, and Daan Wierstra. Draw: A recurrent
neural network for image generation. In Proceedings of the 32nd International Conference on
Machine Learning (ICML-15) ,pp.1462-1471, 2015.
Irina Higgins, Loic Matthey, Arka Pal, Christopher Burgess, Xavier Glorot, Matthew Botvinick,
Shakir Mohamed, and Alexander Lerchner. beta-vae: Learning basic visual concepts with a
constrained variational framework. 2016.
Zhiting Hu, Zichao Yang, Xiaodan Liang, Ruslan Salakhutdinov, and Eric P Xing. Toward controlled
generation of text. In International Conference on Machine Learning, pp. 1587-1596, 2017.
Diederik Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint
arXiv:1412.6980, 2014.
Diederik P Kingma and Max Welling. Auto-encoding variational bayes. arXiv preprint
arXiv:1312.6114, 2013.
Diederik P Kingma and Max Welling. Stochastic gradient vb and the variational auto-encoder. In
Second International Conference on Learning Representations, ICLR, 2014.
Diederik P Kingma, Shakir Mohamed, Danilo Jimenez Rezende, and Max Welling. Semi-supervised
learning with deep generative models. In Advances in Neural Information Processing Systems,
pp. 3581-3589, 2014.
Cindy Xide Lin, Bo Zhao, Tim Weninger, Jiawei Han, and Bing Liu. Entity relation discovery from
web tables and links. In Proceedings of the 19th international conference on World wide web, pp.
1145-1146. ACM, 2010.
Yankai Lin, Shiqi Shen, Zhiyuan Liu, Huanbo Luan, and Maosong Sun. Neural relation extraction
with selective attention over instances. In ACL (1), 2016.
Diego Marcheggiani and Ivan Titov. Discrete-state variational autoencoders for joint discovery and
factorization of relations. Transactions of the Association for Computational Linguistics, 4:231-
244, 2016.
Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. Efficient estimation of word represen-
tations in vector space. arXiv preprint arXiv:1301.3781, 2013.
Vinod Nair and Geoffrey E Hinton. Rectified linear units improve restricted boltzmann machines. In
Proceedings of the 27th international conference on machine learning (ICML-10), pp. 807-814,
2010.
Eric Nalisnick and Padhraic Smyth. Stick-breaking variational autoencoders. In ICLR, 2017.
Mike Oaksford and Nick Chater. Bayesian rationality: The probabilistic approach to human rea-
soning. Oxford University Press, 2007.
Yunchen Pu, Zhe Gan, Ricardo Henao, Xin Yuan, Chunyuan Li, Andrew Stevens, and Lawrence
Carin. Variational autoencoder for deep learning of images, labels and captions. In Advances in
Neural Information Processing Systems, pp. 2352-2360, 2016.
Alec Radford, Luke Metz, and Soumith Chintala. Unsupervised representation learning with deep
convolutional generative adversarial networks. arXiv preprint arXiv:1511.06434, 2015.
Saurav Sahay, Sougata Mukherjea, Eugene Agichtein, Ernest V Garcia, Shamkant B Navathe, and
Ashwin Ram. Discovering semantic biomedical relations utilizing the web. ACM Transactions
on Knowledge Discovery from Data (TKDD), 2(1):3, 2008.
Adam Santoro, David Raposo, David GT Barrett, Mateusz Malinowski, Razvan Pascanu, Peter
Battaglia, and Timothy Lillicrap. A simple neural network module for relational reasoning. arXiv
preprint arXiv:1706.01427, 2017.
Richard Socher, Danqi Chen, Christopher D Manning, and Andrew Ng. Reasoning with neural
tensor networks for knowledge base completion. In Advances in neural information processing
systems, pp. 926-934, 2013.
11
Under review as a conference paper at ICLR 2018
Kihyuk Sohn, Honglak Lee, and Xinchen Yan. Learning structured output representation using
deep conditional generative models. In Advances in Neural Information Processing Systems, pp.
3483-3491,2015.
CasPer Kaae S0nderby and COM TaPani Raiko. HoW to train deep variational autoencoders and
probabilistic ladder networks. In ICML, 2016.
Zareen Syed, Evelyne Viegas, and Savas Parastatidis. Automatic discovery of semantic relations
using mindnet. In LREC, 2010.
Tijmen Tieleman and Geoffrey Hinton. Lecture 6.5-rmsProP: Divide the gradient by a running
average of its recent magnitude. COURSERA: Neural networks for machine learning, 4(2):26-
31, 2012.
Chenguang Wang, Yangqiu Song, Dan Roth, Chi Wang, JiaWei Han, Heng Ji, and Ming Zhang. Con-
strained information-theoretic triPartite graPh clustering to identify semantically similar relations.
In IJCAI, PP. 3882-3889, 2015.
Weidi Xu, Haoze Sun, Chao Deng, and Ying Tan. Variational autoencoder for semi-suPervised text
classification. In AAAI, PP. 3358-3364, 2017.
Xiaofeng Yu and Wai Lam. Jointly identifying entities and extracting relations in encycloPedia
text via a graPhical model aPProach. In Proceedings of the 23rd International Conference on
Computational Linguistics: Posters, PP. 1399-1407. Association for ComPutational Linguistics,
2010.
MattheW D Zeiler. Adadelta: an adaPtive learning rate method. arXiv preprint arXiv:1212.5701,
2012.
Daojian Zeng, Kang Liu, SiWei Lai, Guangyou Zhou, Jun Zhao, et al. Relation classification via
convolutional deeP neural netWork. In COLING, PP. 2335-2344, 2014.
12
Under review as a conference paper at ICLR 2018
APPENDIX
A Deriving the closed-form solution
Inspired by the loss function of the conditional variational autoencoder (CVAE) Kingma et al.
(2014); Sohn et al. (2015), the loss function of CRVAE is formulated to minimize the variational
lower bound:
LCRV AE (embedh, embedt, r; θ, φ) =
—KL [Qφ (z∣embedh, embedt, r) ∣∣Pθ (z∣embedh, embedt, r)] + log (Pθ (embedh, embedt∖r)),
(13)
where the first term minimizes the KL divergence loss between the unknown true dis-
tribution Pθ (z ∖embedh, embedt , r) which is hard to sample from and a simple dis-
tribution Qφ (z∖embedh, embedt, r).	The second term models the entity pairs by
log (Pθ (embedh, embedt ∖r)). The above equation can be reformulated as:
LCRV AE(embedh, embedt, r; θ, φ) =	(14)
— KL [Qφ (z∖embedh, embedt, r) ∖∖Pθ (z∖r)] + E [log (Pθ (embedh, embedt ∖z, r))] ,
where Pθ (z ∖r ) describes the true latent distribution z given a certain relationship r and
E [log (Pθ (embedh, embedt∖z, r))] estimates the maximum likelihood. Since we want to sample
from Pθ(z∖r) in the generator, the first term aims to let to let Qφ(z∖embedh, embedt, r) to be as
close as possible to Pθ(z∖r) which has a simple distribution N(0, I) so that itis easy to sample from.
Furthermore, if Pθ(z∖r)〜 N(0,I) and Q(z∖embedh, embedt, r) 〜 N(μ,σ2), then a close-form
solution for the first term can be derived as:
—KL [Qφ (z∖embedh, embedt, r) ∖∖Pq (z∖r)] = —KL [N(μ, σ)∖∖N(0,I)]
=-1 (tr (σ2) + (μ)T μ - Dl - logdet (σ2)) = -2 X (σ2 + μ2 - i - logσl),	(15)
l
where l in the subscript indicates the l-th dimension of the vector. Since it is more stable to have
exponential term than a log term, we model log σ 2 as σ2 which results in the final closed-form of
Equation 15:
l
(16)
B	Hyperparameters
We train the proposed model with a wide range of hyperparameter configurations, which are listed
in Table 4. We vary the batch size from 64 to 256. The dimension DR for translating the initial
entity embeddings is set from 64 to 2048. We try two to seven hidden layers from transht to lht
and from [z, r] to trans0ht, with different non-linear activation functions. For each hidden layer, the
hidden unit number DH is set from 2 to 1024. The latent dimension DL is set from 2 to 200.
Table 4: Hyperparameter configurations.
HYPERPARAMETER VALUE
Batch Size DR DH DL Activation Optimizer	64, 128, 256 64, 128, 256, 512, 640, 768, 1024, 1280, 1536, 1792, 2048 2,4, 8, 16, 32, 64, 128, 256, 512, 640, 768, 1024 2, 3,4, 5, 10, 20, 50, 100, 200 ELU (Clevert et al., 2015), ReLU (Nair & Hinton, 2010), Sigmoid, Tanh Adadelta (Zeiler, 2012), Adagrad (Duchi et al., 2011), Adam (Kingma & Ba, 2014), RMSProp Tieleman & Hinton (2012)
Table 5 shows the top five configurations ranked by their validation losses. From the combinations
of those hyperparameter configurations, we find that for fully connected hidden layers from transht
to lht, a sequence of six consecutive layers: 1792×640×640×512×256×64 works the best for the
13
Under review as a conference paper at ICLR 2018
Table 5: Model performance on different hyperparameter configurations. {DH } is a set of unit
numbers for hidden layers in the encoder. For the decoder, hidden layers are organized in a reverse
order.
BATCH SIZE	DR	{Dh}	DL	ACT.	OPTIMIZER	LOSS (TRAIN/VALID)
64	640	1792×640×640×512×256× 64	200	elu	adadelta	43.0954/83.6589
64	640	1792×256×640×512×256×128	200	elu	adadelta	51.0695 / 86.9153
64	640	1792×256×640×512×256× 64	200	elu	adadelta	50.4392 / 88.6438
128	640	1792×640×768×512× 64×128	50	elu	adadelta	50.5997 / 89.0125
256	640	512×768×640×256×512	50	elu	adam	62.1955 / 89.2014
encoder with ELU as the activation function. For [z, r] to trans0ht in the decoder, such layer setting
is organized in a reverse order. A batch size of 64 and the Adadelta optimizer work the best for
our task. DR = 640 is used. The latent dimension DL = 200 is adopted for μ and σ2. Such
configuration achieves a training loss of 43.0954 and a validation loss of 83.6589.
C Task on Amazon Mechanical Turk
Instructions
Madarin Chinese reading ability is required to complet this task.
You will be given a medical relationship and a relational medical entity pair. Please read carefully and choose (Yes/No) whether the
relational medical entity pair belongs to the given medical relationship. If you are not sure about the answer, simply select Not Sure.
Sfmply missing one or more answers may result fπ the decline of your answer. Thank you!
!.Whether the given relational entity pair belongs to the given medical relationship??
Medical Relationship Relational Medical Entity Pairs
疾病-> 症状	V感冒，头疼A
O YeS
O No
O Not Sure
2	.Whether the given relational entity pair belongs to the given medical relationship??
Medical Relationship Relational Medical Entity Pairs
疾稿-A药物	V感冒，泰诺A
O YeS
O No
o Not Sure
3	.Whether the given relational entity pair belongs to the given medical relationship??
Want t□ work on this HIT? Want to see other HΓTs?
[ACCePtHIT J
Figure 3: The screenshot of the human annotation task on Amazon Mechanical Turk.
D Generated Relational Medical Entity Pairs
Table 6 shows meaningful entity pairs generated by the proposed method.
E Effectiveness of Relationship-enhancing Entity Adjustment
To show the effectiveness of relationship-enhancement, Table 7 shows the nearest neighbors of a
disease entity 生殖道畸形(genital tract malformation) and a symptom entity 肌肉拉伤(muscle
strain) in their original embedding space, as well as the space after relationship-enhancing.
From these cases we can see that the original entity representations trained with Skip-gram (Mikolov
et al., 2013) tend to put entities in proximity when they appear in similar contexts. In the first case,
the entity 生殖道畸形(genital tract malformation) is in close proximity to 不孕(infertility),不孕
症(acyesis). In the second case, entities that have similar context like 弓 I 体向上(pull-up) and 运动
量(amount ofexercise) are found near by the entity 肌肉拉伤(muscle strain).
14
Under review as a conference paper at ICLR 2018
Table 6:	Rational, meaningful relational medical entity pairs generated by the proposed method.
Disease-C-a-u-s→e Body Part
<	痢疾(力56加60),肠(intestine)>
‹ 脑瘤Srain tumor),头部(head) >
<	白细胞减少症(leukopenia),血液(yascularsystem) >
RelatedT o
Disease-------→Disease
‹ 食管异物(∕oreign body in esophagus),肠梗阻(bowel obstruction) >
<	脑挫裂伤(brain contusion),记忆障碍(amnesia) >
<	呼吸性酸中毒(respiratOryaCidosis),肺水肿(PUlmonary edema) >
Need
Disease---→Examine
<	尿毒症(M~加山)，尿常规(routine UrianIysis) >
<	细菌性脑膜炎SaCterial meningitis),头颅CT (Cranial CT) >
<	肠梗阻SoWelo加truction),腹部平片(a方dominalx-ray) >
BelongT o
Symptom------→Department
‹ 胎盘滞留(retainedplaCenta),产科(obstetrics) >
<	'水潴留fluidretention),肾内科(nephrology) >
<	鼻塞(stuffy nose),耳鼻咽喉科(otolaryngology) >
Cause
Disease---→Symptom
<	耳源性脑脓肿(otogenic brain abscess),耳痛(earache) >
<	神经炎(neuritis),手麻(numbness in the hands) >
‹ 开放性颅脑损伤(open head injury),意识模糊(loss ofconsciousness) >
RelatedT o
Symptom------→Symptom
<	乏力 (fatigue),四肢无力 feel wobbly and rough) >
<	关节痛(jointpain),关节活动受限他加注壮加加加仍〃^) >
<	雾视(blurred vision),眼睛不舒服(eye discomfort) >
The translation layer adjusts the original entity representation so that they are more suitable for the
Relational Medical Entity-pair Discovery task. The nearest neighbors in the adjusted space are not
necessarily entities that co-occur in the same context, but more relation-wise similar with the given
entity. For example,心脏畸形(heart malformations) and 染色体异常(Chromosome abnormalities)
may not be semantically similar with the given word 生殖道畸形(genital tract malformation), but
C ause
they may serve similar functionalities in a Disease-→Symptom relationship.
F	Ability to Infer Conditionally
Figure 4 shows the values of validation data after being mapped into the μ space using RVAE (left)
and CRVAE (right), respectively. The values are colored based on their ground truth relationship
indicators. The left figure indicates that when the relationship indicator r is not given during the
training/validation, RVAE is still able to map different relationships into various regions in the latent
space, while a single distribution models all types of relationships. Such property is appealing for an
unsupervised model, but since the relationship indicator r is not given, RVAE fails to generate entity
pairs having a particular relationship, unless we manually assign a boundary for each relationship
in the latent space. The right figure shows that when the relationship indicator r is incorporated
during the training, CRVAE learns to let each relationship have a unified latent representation. A
separate but nearly identical distribution is used to model each medical relationship. Such property
enables the generator of CRVAE to sample from a relationship-independent, unified latent space for
diversities regarding the generation, while the relationship indicator r given in CRVAE’s generator
provides categorical information on the type of relationship to generate.
15
Under review as a conference paper at ICLR 2018
Table 7:	The effectiveness of relationship-enhancing adjustment on entity representations.
•生殖道畸形(genital tract malformation)
NN in the relationship-enhanced space R1×DR	NN in the initial embedding space R1×DE
生殖道(genital tract)
生殖系统(reproductive system)
心脏畸形(heart malformations)
染色体异常(chromosome abnormalities)
生殖道肿瘤(reproductive tract tumors)
生殖器官(generative organs)
泌尿系畸形(urinary system malformations)
消化道畸形(gastrointestinal malformations)
生殖系统(reproductive system)
生殖道肿瘤(reproductive tract tumors)
泌尿系畸形(urinary system malformations)
不孕(infertility)
阴道闭锁(vaginal atresia)
生殖道(genital tract)
生殖器官(generative organs)
不孕症(acyesis)
•肌肉拉伤(muscle strain)
NN in the relationship-enhanced space R1×DR	NN in the initial embedding space R1×DE
拉伤(strain)
韧带拉伤(ligament strain)
扭伤(sprain)
足痛(footpain)
肌肉撕裂(muscle tear)
足底筋膜炎(plantar fasciitis)
关节扭伤(joint sprain)
劳损(repetitive strain injury, RSI)
拉伤(strain)
肌肉撕裂(muscle tear)
引体向上(pull-up)
扭伤(sprain)
肌肉疲劳(muscle fatigue)
腱鞘炎(tenosynovitis)
肌腱炎(tendonitis)
运动量(amount of exercise)
• symptom→department
disease → symptom
• symptom→symptom
• disease→bodypart
• disease→disease
•	disease→bodypart	∙	symptom→department
•	disease→disease	∙	disease → symptom
•	disease→examine	∙	symptom→symptom
Figure 4: The latent variable μ of RVAE (left) and CRVAE (right) on the validation data, presented
in a two-dimensional space after dimension reduction using Primary Component Analysis.
16