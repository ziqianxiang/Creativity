title,year,conference
 Neural learning in structured parameter spaces-natural riemannian gradient,1997, InAdvances in neural information processing systems
 Natural gradient works efficiently in learning,1998, Neural computation
 A new learning algorithm for blindsignal separation,1996, In Advances in neural information processing systems
 Adaptive method of realizing natural gra-dient learning for multilayer perceptrons,2000, Neural Computation
 Batch normalization: Accelerating deep network training byreducing internal covariate shift,2015, In International Conference on Machine Learning
 Eigenvalues of covariance matrices: Application toneural-network learning,1991, Physical Review Letters
 New perspectives on the natural gradient method,2014, arXiv preprint arXiv:1412
 Optimizing neural networks with kronecker-factored approximatecurvature,2015, In International Conference on Machine Learning
 Revisiting natural gradient for deep networks,2013, arXiv preprintarXiv:1301
 Automatic differentiation inpytorch,2017, 2017
 Deep learning made easier by linear transformationsin perceptrons,2012, In Artificial Intelligence and Statistics
 Accelerated gradient descent by factor-centering decomposition,1998, 1998
 Transformation invariance inpattern recognitiontangent distance and tangent propagation,1998, Neural networks: tricks of the trade
 Variance reduction for stochasticgradient optimization,2013, In Advances in Neural Information Processing Systems
 Adadelta: an adaptive learning rate method,2012, arXiv preprint arXiv:1212
 Understandingdeep learning requires rethinking generalization,2016, arXiv preprint arXiv:1611
