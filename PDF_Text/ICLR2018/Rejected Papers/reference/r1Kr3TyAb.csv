title,year,conference
 Learning long-term dependencies with gradientdescent is difficult,1994, IEEE transactions on neural networks
 Learning deep architectures for ai,2009, Foundations and trendsR in MachineLearning
 Learning to forget: Continual predictionwith lstm,1999, 1999
 Understanding the difficulty of training deep feedforward neuralnetworks-glorot10a,2015, pdf
 Convolutional neural networks at constrained time cost,2015, In Proceedingsof the IEEE Conference on Computer Vision and Pattern Recognition
 Delving deep into rectifiers: Surpassinghuman-level performance on imagenet classification,2015, In Proceedings of the IEEE internationalconference on computer vision
 Batch normalization: Accelerating deep network training byreducing internal covariate shift,2015, In International Conference on Machine Learning
 Imagenet classification with deep convo-lutional neural networks,2012, In Advances in neural information processing systems
 On data-drive saak transform,2017, arXiv preprint arXiv:1710
 Exact solutions to the nonlinear dynam-ics of learning in deep linear neural networks,2013, arXiv preprint arXiv:1312
 Transformation invariance inpattern recognitiontangent distance and tangent propagation,1998, Neural networks: tricks of the trade
 Highway networks,2015, arXivpreprintarXiv:1505
 Residual networks behave like ensembles ofrelatively shallow networks,2016, In Advances in Neural Information Processing Systems
 Wider or deeper: Revisiting the resnetmodel for visual recognition,2016, arXiv preprint arXiv:1611
 Wide residual networks,2016, CoRR
