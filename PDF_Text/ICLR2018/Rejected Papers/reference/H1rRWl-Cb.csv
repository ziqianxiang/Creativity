title,year,conference
 Information Dropout: Learning Optimal Representations Through NoisyComputation,2016, In Information Control and Learning
 Deep Variational InformationBottleneck,2017, In ICLR
 End-to-end Optimized Image Compression,2017, In ICLR
 Information maximization in noisy channels : A variational ap-proach,2003, In S
 Generating sentences from a continuous space,2016, CoNLL 2016
 Generative modeling of convolutional neural networks,2015, InICLR
 Language modeling with gatedconvolutional networks,2017, In Doina Precup and Yee Whye Teh (eds
 Made: Masked autoencoderfor distribution estimation,2015, In Francis Bach and David Blei (eds
 Generative adversarial nets,2014, In Z
 Î²-VAE: Learning Basic Visual Concepts with a Con-strained Variational Framework,2017, In ICLR
 Adam: A method for stochastic optimization,2015, In ICLR
 Auto-encoding variational Bayes,2014, In ICLR
 Human-level concept learningthrough probabilistic program induction,0036, Science
 Estimation of entropy and mutual information,2003, Neural Computation
 Adversarial symmetric variational autoencoder,2017, In I
 Variational inference with normalizing flows,2015, In FrancisBach and David Blei (eds
 Stochastic backpropagation andapproximate inference in deep generative models,2014, In Eric P
 Real-time adaptive image compression,2017, In ICML
 Pixelcnn++: Improving thepixelcnn with discretized logistic mixture likelihood and other modifications,2017, In ICLR
 Learning and generalization with the informa-tion bottleneck,0304, Theoretical Computer Science
 Opening the black box of deep neural networks via informa-tion,2017, CoRR
 How toTrain Deep Variational Autoencoders and Probabilistic Ladder Networks,2016, 2016
 Lossy image compression withcompressive autoencoders,2017, In ICLR
 Deep learning and the information bottleneck principle,2015, In 2015 IEEEInformation Theory Workshop (ITW)
 The information bottleneck method,1999, In The 37th annualAllerton Conf
 Conditional image generation with pixelcnn decoders,2016, In D
 Attention is all you need,2017, In I
 Understandingdeep learning requires rethinking generalization,2017, In ICLR
