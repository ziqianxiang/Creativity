title,year,conference
 Conversationalcontextual cues: The case of personalization and history for response ranking,2016, arXiv:1606
 QSGD: Randomized quantization forcommunication-optimal stochastic gradient descent,2016, arXiv:1610
 Practical secure aggregation for privacy preserving machinelearning,2017, In ACM Conference on Computer and Communications Security (ACM CCS)
 Project adam: Building anefficient and scalable deep learning training system,2014, In 11th USENIX Symposium on Operating SystemsDesign and Implementation (OSD114)
 Large scale distributed deep networks,2012, In NIPS
 Predicting parameters in deep learning,2013, InNIPS
 Large-scale learning with less ram viarandomization,2013, In ICML
 Reddit comments dataset,2016, BigQuery
 Federated optimization: Dis-tributed machine learning for on-device intelligence,2016, arXiv preprint arXiv:1610
 Learning multiple layers of features from tiny images,2009, Technical report
 AIDE: Fast and commu-nication efficient distributed optimization,2016, arXiv:1608
 Communication-efficient distributed optimization using anapproximate Newton-type method,2014, In ICML
 Privacy-preserving deep learning,2015, In Proceedings of the 22Nd ACM SIGSACConference on Computer and Communications Security
 Striving for simplicity:The all convolutional net,2014, arXiv:1412
 Distributed mean estimationwith limited communication,2017, In Proceedings of the 34th International Conference on Machine Learning
 Sketching as a tool for numerical linear algebra,1551, Foundations and Trends in TheoreticalComputer Science
 DiSCO: Distributed optimization for self-concordant empirical loss,2015, In ICML
