title,year,conference
 A distributional perspective on reinforcementlearning,2017, In Proceedings of the International Conference on Machine Learning
 Some asymptotic theory for the bootstrap,1981, The Annals ofStatistics 
 DISCO Nets: DISsimilarityCOefficients Networks,2016, In Advances in Neural Information Processing Systems
 Com-parison of Maximum Likelihood and GAN-based training of Real NVPs,2017, arXiv preprintarXiv:1705
 The empirical distribution function for dependent vari-ables: asymptotic and nonasymptotic results in Lp,2007, ESAIM: Probability and Statistics
 Training generative neuralnetworks via maximum mean discrepancy optimization,2015, In Proceedings of the Conference onUncertainty in Artificial Intelligence
 Data-driven distributionally robust optimization us-ing the Wasserstein metric: Performance guarantees and tractable reformulations,2015, MathematicalProgramming
 Learn-ing with a Wasserstein loss,2015, In Advances in Neural Information Processing Systems
 Distributionally robust stochastic optimization with Wassersteindistance,2016, arXiv preprint arXiv:1604
 Im-proved training of Wasserstein GANs,2017, arXiv preprint arXiv:1704
 Probabilistic backpropagation for scalablelearning of Bayesian neural networks,2015, In Proceedings of the International Conference on MachineLearning
 Image-to-image translation withconditional adversarial networks,2016, In Proceedings of the Conference on Computer Vision andPattern Recognition
 MMD GAN: Towards deeper understand-ing of moment matching network,2017, In Proceedings of the Neural Information Processing Systems
 Generative moment matching networks,2015, In Proceedingsof the International Conference on Machine Learning
 Wasserstein training of restrictedBoltzmann machines,2016, In Advances in Neural Information Processing Systems
 McGan: Mean and covariance feature matchingGAN,2017, In Proceedings of the International Conference on Machine Learning
 Integral probability metrics and their generating classes of functions,1997, Advances inAppliedProbability
 The methods of dis-tances in the theory of probability and statistics,2013, Springer
 Unsupervised representation learning with deepconvolutional generative adversarial networks,2015, arXiv preprint arXiv:1511
 Equivalence ofdistance-based and RKHS-based statistics in hypothesis testing,2013, The Annals of Statistics
 Rethink-ing the inception architecture for computer vision,2016, In Proceedings of the IEEE Conference onComputer Vision and Pattern Recognition
 The critic has trainable parameters onlyinside the deep network used for the transformation h,2017, From (4)
