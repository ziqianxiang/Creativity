title,year,conference
 Neural machine translation by jointlylearning to align and translate,2015, In ICLR 2015
 Graph con-volutional encoders for syntax-aware neural machine translation,2017, In Proceedings of the 2017Conference on Empirical Methods in Natural Language Processing
 Estimating or propagating gradientsthrough stochastic neurons for conditional computation,2013, arXiv preprint arXiv:1308
 On the shortest arborescence of a directed graph,1965, Science Sinica
 Learning to parse and translate improvesneural machine translation,2017, In Proceedings of the 55th Annual Meeting of the Association forComputational Linguistics (Volume 2: Short Papers)
 A theoretically grounded application of dropout in recurrentneural networks,2016, In NIPS
 Long short-term memory,1997, Neural computation
 Tying word vectors and word classifiers: Aloss framework for language modeling,2017, ICLR
 Categorical reparameterization with gumbel-softmax,2016, InInternational Conference on Learning Representations
 Adam: A method for stochastic optimization,2014, In InternationalConference on Learning Representations (ICLR)
 Learning structured text representations,2017, CoRR
 Effective approaches to attention-basedneural machine translation,2015, In Proceedings of the 2015 Conference on Empirical Methods inNatural Language Processing
 Using the output embedding to improve language models,2017, In Proceedingsof the 15th Conference of the European Chapter of the Association for Computational Linguistics:Volume 2
 Neural machine translation of rare words withsubword units,2016, In Proceedings of the 54th Annual Meeting of the Association for ComputationalLinguistics (Volume 1: Long Papers)
 Graph theory,1984, Cambridge University Press
 Attention is all you need,2017, In I
 Simple statistical gradient-following algorithms for connectionist reinforcementlearning,0885, Machine Learning
 Learning tocompose words into sentences with reinforcement learning,2017, International Conference on LearningRepresentations
