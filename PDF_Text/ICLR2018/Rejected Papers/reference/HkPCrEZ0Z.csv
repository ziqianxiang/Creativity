title,year,conference
 Openai gym,2016, arXiv preprint arXiv:1606
 Monte-carlo tree search,2010, Maastricht: Universiteit Maastricht
 Combining model-based and model-free updates for trajectory-centric reinforcementlearning,2017, arXiv preprint arXiv:1703
 Q-prop: Sample-efficient policy gradient with an off-policy critic,2016, arXiv preprint arXiv:1611
 Continuous deep q-learningwith model-based acceleration,2016, In International Conference on Machine Learning
 Learningcontinuous control policies by stochastic value gradients,2015, In Advances in Neural InformationProcessing Systems
 Auto-encoding variational bayes,2013, arXiv preprintarXiv:1312
 Continuous control with deep reinforcement learning,2015, arXivpreprint arXiv:1509
 Sample-basedinformationl-theoretic stochastic optimal control,2014, In Robotics and Automation (ICRA)
 Prediction and control with temporal segmentmodels,2017, arXiv preprint arXiv:1703
 Playing atari with deep reinforcement learning,2013, arXiv preprintarXiv:1312
 Neural network dy-namics for model-based deep reinforcement learning with model-free fine-tuning,2017, arXiv preprintarXiv:1708
 Markov decision processes,1983, Comap
 Backpropagation through time: what it does and how to do it,1990, Proceedings of theIEEE
