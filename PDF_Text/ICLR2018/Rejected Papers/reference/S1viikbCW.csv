title,year,conference
 Understanding intermediate layers using linear classifierprobes,2016, arXiv preprint arXiv:1610
 Network dis-section: Quantifying interpretability of deep visual representations,2017, In Computer Vision andPattern Recognition
 Real time image saliency for black box classifiers,2017, arXivpreprint arXiv:1705
 Graph-sparse lda: A topic modelwith structured sparsity,2015, In Aaai
 Visualizing higher-layerfeatures of a deep network,2009, University of Montreal
 European union regulations on algorithmic decision-making and a” right to explanation”,2016, arXiv preprint arXiv:1606
 Generating visual explanations,2016, In European Conference on Computer Vision
 Mind the gap: A generative approach tointerpretable feature selection and extraction,2015, In Advances in Neural Information ProcessingSystems
 Do decision biases explain too much,1989, HFES
 Inceptionism: Going deeper intoneural networks,2015, Google Research Blog
 Feature visualization,2017, Distill
 Svcca: Singularvector canonical correlation analysis for deep understanding and improvement,2017, arXiv preprintarXiv:1706
 “why should i trust you?”: Explain-ing the predictions of any classifier,2016, arXiv preprint arXiv:1602
 Mas-tering the game of go with deep neural networks and tree search,2016, 2016
 Smooth-grad: removing noise by adding noise,2017, arXiv preprint arXiv:1706
 Intriguing properties of neural networks,2013, arXiv preprintarXiv:1312
 Supersparse linear integer models for inter-pretable classification,2013, arXiv preprint arXiv:1306
 Visualizing and understanding convolutional networks,2014, InEuropean conference on computer vision
