title,year,conference
 Neural network learning: Theoretical foundations,2009, cambridge universitypress
 A unified architecture for natural language processing: Deep neuralnetworks with multitask learning,2008, In Proceedings of the 25th international conference on Machine learning
 Approximation by superpositions of a sigmoidal function,1989, Mathematics of Control
 Sgd learns the conjugate kernel class of the network,2017, arXiv preprint arXiv:1702
 Nearly-tight vc-dimension bounds for piecewise linear neuralnetworks,2017, arXiv preprint arXiv:1703
 Onlarge-batch training for deep learning: Generalization gap and sharp minima,2016, arXiv preprint arXiv:1609
 Learning multiple layers of features from tiny images,2009, 2009
 Imagenet classification with deep convolutional neuralnetworks,2012, In Advances in neural information processing systems
 Deep learning,2015, Nature
 On the ability of neural nets to expressdistributions,2017, arXiv preprint arXiv:1702
 The landscape of empirical risk for non-convex losses,2016, arXiv preprintarXiv:1607
 Path-sgd: Path-normalized optimization in deepneural networks,2015, In Advances in Neural Information Processing Systems
 Norm-based capacity control in neural networks,2015, InCOLT
 Exploring generalization indeep learning,2017, arXiv preprint arXiv:1706
 Spectral representations for convolutional neural networks,2015, InAdvances in Neural Information Processing Systems
 Failures of gradient-based deep learning,2017, InInternational Conference on Machine Learning
 Distribution-specific hardness of learning neural networks,2016, arXiv preprint arXiv:1609
 An overview of statistical learning theory,1999, IEEE transactions on neural networks
 Understanding deep learningrequires rethinking generalization,2016, arXiv preprint arXiv:1611
