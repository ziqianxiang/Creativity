title,year,conference
 Tensorflow: Large-scale machinelearning on heterogeneous distributed systems,2016, arXiv preprint arXiv:1603
 Neural machine translation by jointlylearning to align and translate,2015, International Conference on Learning Representations
 Empirical evaluation ofgated recurrent neural networks on sequence modeling,2014, arXiv preprint arXiv:1412
 Language modeling with gatedconvolutional networks,2016, arXiv preprint arXiv:1612
 Distributional structure,1954, Word
 Deep residual learning for image recog-nition,2016, In Computer Vision and Pattern Recognition
 Learning distributed representations of sentencesfrom unlabelled data,2016, arXiv preprint arXiv:1602
 Long short-term memory,1997, Neural computation
 Tying word vectors and word classifiers: Aloss framework for language modeling,2017, In International Conference on Learning Representations
 Batch normalization: Accelerating deep network training byreducing internal covariate shift,2015, In International Conference on Machine Learning
 Exploring thelimits of language modeling,2016, arXiv preprint arXiv:1602
 A convolutional neural network formodelling sentences,2014, In Association for Computational Linguistics
 Convolutional neural networks for sentence classification,2014, In Empirical Methods inNatural Language Processing
 Adam: A method for stochastic optimization,2014, arXiv preprintarXiv:1412
 Skip-thought vectors,2015, In Neural Information Processing Systems
 Recurrent convolutional neural networks for textclassification,2015, In AAAI
 A structured self-attentive sentence embedding,2017, International Conference onLearning Representations
 From amateurs to connoisseurs: Modeling the evolutionof user expertise through online reviews,2013, In World Wide Web
 Pointer sentinel mixturemodels,2016, arXiv preprint arXiv:1609
 Ensemble of gen-erative and discriminative techniques for sentiment analysis of movie reviews,2014, arXiv preprintarXiv:1412
 Distributed representa-tions of words and phrases and their compositionality,2013, In Neural Information Processing Systems
 Using the output embedding to improve language models,2016, arXiv preprintarXiv:1608
