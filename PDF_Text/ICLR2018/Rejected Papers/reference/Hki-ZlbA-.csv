title,year,conference
 Towards evaluating the robustness of neural networks,2017, IEEESymposium on Security and Privacy
 Adversarial examples are not easily detected: Bypassing tendetection methods,2017, arXiv preprint arXiv:1705
 Explaining and harnessing adversarialexamples,2014, arXiv preprint arXiv:1412
 Deepsafe: A data-driven approach for checkingadversarial robustness in neural networks,2017, arXiv preprint arXiv:1710
 On detecting adversarialperturbations,2017, In International Conference on Learning Representations
 Early methods for detecting adversarial images,2017, In InternationalConference on Learning Representations (Workshop Track)
 Learning with a strong adver-sary,2015, CoRR
 Policy compression for aircraftColliSion avoidance systems,2016, In Proc
 Towards proving the adversarialrobustness of deep neural networks,2017, In Proc
 Reluplex: An efficient SMT solver forverifying deep neural networks,2017, In Proc
 Adversarial examples in the physical world,2016, InInternational Conference on Learning Representations (Workshop Track)
 Deepfool: a simple andaccurate method to fool deep neural networks,2015, arXiv preprint arXiv:1511
 An abstraction-refinement approach to verification of artificial neuralnetworks,2010, In Proc
 Challenging SMT solvers to verify neural networks,2012, AI Communications
 Intriguing properties of neural networks,2014, 2014
 Ensemble adversarial training:Attacks and defenses,2017, arXiv preprint arXiv:1705
 Improving the robustness of deepneural networks via stability training,2016, In Proceedings of the IEEE Conference on Computer Visionand Pattern Recognition
