title,year,conference
 Adversarial transformation networks: Learning to generate adversarial exam-ples,2017, arXiv preprint arXiv:1703
 Towards evaluating the robustness of neural networks,2017, In Security andPrivacy (SP)
 Analysis of classifiersâ€™ robustness to adversarial perturba-tions,2015, arXiv preprint arXiv:1502
 Nightmare at test time: robust learning by feature deletion,2006, In Proceedingsof the 23rd international conference on Machine learning
 Minimax filter: Learning to preserve privacy from inference attacks,2016, arXiv preprintarXiv:1610
 Learning With a strong adversary,2015, arXivpreprint arXiv:1511
 Adversarial examples in the physical World,2016, arXiv preprintarXiv:1607
 Adversarial machine learning at scale,2016, arXiv preprintarXiv:1611
 Safetynet: Detecting and rejecting adversarial examplesrobustly,2017, arXiv preprint arXiv:1704
 A unified gradient regularization family for adversarialexamples,2015, In Data Mining (ICDM)
 Magnet: a two-pronged defense against adversarial examples,2017, arXiv preprintarXiv:1705
 On detecting adversarial perturba-tions,2017, arXiv preprint arXiv:1702
 Universal adversarialperturbations,2016, arXiv preprint arXiv:1610
 Anal-ysis of universal adversarial perturbations,2017, arXiv preprint arXiv:1705
 A learning approach to secure learning,2017, arXiv preprint arXiv:1709
 Distillation as a defense toadversarial perturbations against deep neural networks,2016, In Security and Privacy (SP)
 Automatic differentiation: Techniques and applications,1981, 1981
 Intriguing properties of neural networks,2013, arXiv preprint arXiv:1312
 Ensemble adversarialtraining: Attacks and defenses,2017, arXiv preprint arXiv:1705
