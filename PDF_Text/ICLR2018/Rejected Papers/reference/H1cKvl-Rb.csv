title,year,conference
 Exploration-exploitation tradeoff usingvariance estimates in multi-armed bandits,2009, Theor Comput
 Finite-time analysis of the multiarmed banditproblem,2002, Mach
 The arcade learning environ-ment: An evaluation platform for general agents,2013, J
 R-max-a general polynomial time algorithm for near-optimal reinforcement learning,2002, J
 OpenAI Gym,2016, arXiv preprint arXiv:1606
 Model based Bayesian exploration,1999, In UAI
 EX2: Exploration with exemplar models for deepreinforcement learning,2017, arXiv preprint arXiv:1703
 VIME:Variational information maximizing exploration,2016, In NIPS
 Adam: A method for stochastic optimization,2014, arXiv preprintarXiv:1412
 Simple and scalable predictiveuncertainty estimation using deep ensembles,2016, arXiv preprint arXiv:1612
 WhyM heads are better than one: Training a diverse ensemble of deep networks,2015, arXiv preprintarXiv:1511
 Ensemble sampling,2017, 2017
 Human-level controlthrough deep reinforcement learning,2015, Nature
 Why is posterior sampling better than optimism for reinforcementlearning,2016, arXiv preprint arXiv:1607
 Generalization and exploration via randomizedvalue functions,2014, arXiv preprint arXiv:1402
 Deep exploration viabootstrapped DQN,2016, In NIPS
 Count-based explorationwith neural density models,2017, arXiv preprint arXiv:1703
 Variance-based rewards for approximatebayesian reinforcement learning,2012, arXiv preprint arXiv:1203
 Pac model-freereinforcement learning,2006, In ICML
 A Bayesian framework for reinforcement learning,2000, In ICML
 Planning to be surprised: Optimal Bayesianexploration in dynamic environments,2011, In ICAGI
 Deep reinforcement learning with double Q-learning,2016, In AAAI
 Learning from delayed rewards,1989, PhD thesis
