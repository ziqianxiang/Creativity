title,year,conference
 Pixeldefend: Leveraging generative models to understand and defend against adversarialexamples,2018, International Conference on Learning Representations
 Synthesizing robust adversarial examples,2017, CoRR
 Adversarial examples are not easily detected: Bypassing tendetection methods,2017, arXiv preprint arXiv:1705
 Towards evaluating the robustness of neural networks,2017, InSecurity and Privacy (SP)
 Parsevalnetworks: Improving robustness to adversarial examples,2017, In Doina Precup and Yee Whye Teh (eds
 Detecting adversarialsamples from artifacts,2017, arXiv preprint arXiv:1703
 The dimension of almost sphericalsections of convex bodies,1977, Acta Mathematica
 Deep Learning,2016, MIT Press
 Explaining and harnessing adversarialexamples,2014, arXiv preprint arXiv:1412
 Batch normalization: Accelerating deep network training byreducing internal covariate shift,2015, In David Blei and Francis Bach (eds
 Adam: A method for stochastic optimization,2014, arXiv preprintarXiv:1412
 Dense associative memory is robust to adversarial inputs,2017, arXivpreprint arXiv:1701
 Generative adversarial trainer: Defense toadversarial perturbations with gan,2017, arXiv preprint arXiv:1705
 Foveation-based mechanismsalleviate adversarial examples,2015, arXiv preprint arXiv:1511
 On detecting adversarialperturbations,2017, arXiv preprint arXiv:1702
 Distillation as adefense to adversarial perturbations against deep neural networks,2016, In Security and Privacy (SP)
 Breaking the madry defense model with l1-based adversarialexamples,2017, arXiv preprint arXiv:1710
 Intriguing properties of neural networks,2014, In International Conference on LearningRepresentations
