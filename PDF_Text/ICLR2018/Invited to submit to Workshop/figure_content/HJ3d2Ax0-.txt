Figure 1: Shallow and deep recurrent networks, as described by eqs. 1 and 4, respectively.
Figure 2: Tensor Network representing the computation of a depth L = 3 RAC after T = 6 time-steps. See construction in appendix A.
Figure 3: A quick introduction to Tensor Networks (TNs). a) Tensors in the TN are represented bynodes. The degree of the node corresponds to the order of the tensor represented by it. b) A matrixmultiplying a vector in TN notation. The contracted index k, which connects two nodes, is summedupon, while the open index d is not. The number of open indices equals the order of the tensorrepresented by the entire network. All of the indices receive values that range between 1 and theirbond dimension. The contraction is marked by the dashed line.
Figure 4: a) The Tensor Network representing the calculation performed by a shallow RAC. b) ATensor Network construction of the recursive relation given an eq. 1. c) A presentation of the shallowRAC weights tensor in a standard MPS form.
Figure 5: a) The Tensor Network representing the calculation preformed by a depth L = 2 RACafter 4 time-steps. b) A Tensor Network construction of the hidden state h2,2 (see eq. 13), whichinvolves duplication of the hidden state h1,1 that is achieved by duplicating the input x1. c) TheTensor Network representing the calculation preformed by a depth L = 3 RAC after 3 time-steps.
Figure 6: Above: TN representing the computation of a depth L = 3 RAC after T = 6 time-steps,when choosing WI,2 to be of rank-1. See full TN, for general values of the weight matrices, in fig. 2.
