Figure 1: Intuition behind mode-collapsing behavior in single-observation discriminators withlogistic loss. The current generateddistribution (solid green line) coversonly one of the true distribution’smodes. Gradients with respect togenerated points x are weighted bythe term - D 喂(cyan dashed line),so gradients corresponding to pointsclose to the second mode will bedominated by those coming from thefirst mode.
Figure 2: Mixture of 4 Gaussians. GAN training leads to unrecoverable mode collapse, with only oneof the true distribution’s modes being recovered. The two distributional training approaches (bottom2 rows, λ = 0) capture all modes, and are able to recover from a missing mode (second column).
Figure 3: Total variation distances (in log-scale) between generated and true (uniform) label distribu-tions over 5 repetitions. DAN achieves the best and most stable mode frequency recovery.
Figure 4: Samples generated by DCGAN, DAN-S and DAN-2S trained on the CelebA dataset.
Figure 5: DAN-S and DAN-2S models and corresponding losses, where X = {χ(i)}B=ι 〜Pχ, Z{z⑴}B=1 〜Pz, Xi := {x(i)}Jι, X2 = {x(i)}B= B+1, Zi ：= {z(i)}iι and Z2 = {z⑴}^B十]uniformly from [-1, 1]256. For WGAN, the weight clipping parameter is set to 0.01. For WGAN-GP,λ the weight for the gradient penalty is set to 0.1. For DAN, the distributional adversaries have twoinitial hidden layers of size 32, after which the latent representations are averaged across the batch.
Figure 6: Results for mode recovery on distribution of a mixture of 4 Gaussians on a circle of radius6. The rightmost plot shows the true data distribution. With GAN training (the 1st row) the generatoris only able to capture the same single one of all modes. WGAN (rows 2) do not get stuck at the samesingle mode since they do not use the logistic loss, but the mode collapse still happens. WGAN-GPand DAN is able to constantly recover all 4 modes.
Figure 7: Results for mode recovery on distribution of a mixture of 8 Gaussians on a circle of radius2. The right-most plot shows the true data distribution. Since modes are closer, the generator in GANmay not get stuck at generating the same single mode, but oscillate between modes, as confirmedby the 1st row. WGAN (rows 2) do not get stuck at the same single mode since they do not use thelogistic loss, but the mode collapse still happens. WGAN-GP and DAN is able to constantly recoverall 8 modes.
Figure 8: WGAN (row 1) optimized using RMSProp with learning rate of 5 × 10-5, WGAN-GP(row 2) and DAN (row 3-4) optimized with Adam with learning rate of 10-4, β1 = 0.5 and β2 = 0.916Under review as a conference paper at ICLR 2018Figure 9: WGAN-GP (rows 1-3) and DAN (rows 4-5) optimized with Adam with learning rate of10-4, βι = 0.5 and β2 = 0.999. The first 3 rows show random runs for WGAN-GP - it does notconstantly recover all modes, even if we run it for longer time.
Figure 9: WGAN-GP (rows 1-3) and DAN (rows 4-5) optimized with Adam with learning rate of10-4, βι = 0.5 and β2 = 0.999. The first 3 rows show random runs for WGAN-GP - it does notconstantly recover all modes, even if we run it for longer time.
Figure 10: DAN-S with λ set to {0, 0.2, 0.5, 1, 2, 5} (top-down order).
Figure 11: DAN-2S with λ set to {0, 0.2, 0.5, 1, 2, 5, 10} (top-down order).
Figure 12: GAN, WGAN, WGAN-GP, DAN-S and DAN-2S on MNIST dataset.
Figure 13: GAN, WGAN, WGAN-GP, DAN-S and DAN-2S on Fashion MNIST dataset.
Figure 14: Performances (measured as TV distance between generated and true class distributions)on fashion-mnist of DAN’s with varying batch-sizes in {16, 32, 64, 128, 256, 512}. DAN-Sis more stable with small batch-sizes while DAN-2S is more stable and achieves better overallperformance in the large batch-size regime.
Figure 15: Total variation distances between generated and true (uniform) label distributions over5 repetitions. Performances are sorted in increasing order, i.e., better performing models stay onthe right. DAN achieves one of the best and most stable mode frequency recovery. While GMMNperforms slightly better than DAN, it suffers from poor generating quality as seen in Figure 16G	Experiment Details on CelebAWe use a publicly available implementation6 of DCGAN. The network architecture is kept as inthe default configuration. We preprocess the image data by first cropping each image to 160 × 160(instead of 108 × 108 in default setting) and then resize them to 64 × 64. The generator consists of afully connected linear layer mapping from latent space of [-1, 1]100 to dimension 8,192, followedby 4 deconvolution layers, three with ReLU activations and the last one followed by tanh. Thediscriminator is the “reverse” of generator, except that the activation function is Leaky ReLU thelast layer being a linear mapping and a Sigmoid activation to 1D value. Both adversaries in DANuse the same architecture except for the averaging layer of the distributional adversary, and shareweights of the pre-averaging layers.
Figure 16: GAN, WGAN, WGAN-GP, GMMN, DAN-S and DAN-2S on the SVHN dataset.
Figure 17: GAN, WGAN, WGAN-GP, GMMN, DAN-S and DAN-2S on the CIFAR10 dataset.
Figure 18: DCGAN, DAN-S and DAN-2S trained on the CelebA dataset. Both DAN-S and DAN-2Sdemonstrate much more diversity in generated samples compared to DCGAN.
