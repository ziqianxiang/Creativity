Figure 1: Examples of SCAN commands (left) and the corresponding action sequences (right).
Figure 2: HoW the seq2seq framework is applied to SCAN. The symbols <EOS> and <SOS> denote end-of-sentence and Start-of-sentence, respectively. The encoder (left) ends with the first <EOS> symbol, and thedecoder (right) begins with the <SOS> symbol.
Figure 3: Zero-shot generalizationafter training on a random subsetof the SCAN tasks. The overall-best network was trained on vary-ing proportions of the corpus (x-axis) and generalization was mea-sured on new tasks (y-axis). Eachbar shows the mean over 5 trainingruns with corresponding ±1 SEM.
Figure 4: Zero-shot generalization to commands with action sequence lengths not seen in training. Left: ac-curacy distribution by action sequence length; right: accuracy distribution by command length (only lengthsattested in the test set shown, in both cases). Bars show means over 5 runs of overall-best model with ±1 SEM.
Figure 5: Zero-shot generalization af-ter adding the primitive “jump” andsome compositional jump commands.
Figure 6: Phrase-structure grammar generating SCAN commands. We use indexing notation to allow infixing:D[i] is to be read as the i-th element directly dominated by category D.
Figure 7: Double brackets (JK) denote the interpretation function translating SCAN’s linguistic commands intosequences of actions (denoted by uppercase strings). Symbols x and u denote variables, the latter limited towords in the set {walk, look, run, jump}. The linear order of actions denotes their temporal sequence.
