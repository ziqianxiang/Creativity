Figure 1: Gradient descent fails to solvethe saddle point problem minx maxy xy.
Figure 2: Convergence analysis for the synthetic point alignment problem. Top row: The procedureof adversarial alignment in the primal discriminator weight space for points from A and B lying in atwo-dimensional plane does not converge to a single solution and oscillates over time. Middle row:In contrast, the proposed dual minimization adversarial objective steadily converges to an optimum.
Figure 3: (Best viewed in color) When trained on a point cloud matching task, the primal approachleads to an unstable solution that makes the decision boundary spin around data points when theyare almost aligned, whereas both the linear and kernel dual approaches lead to stable solutions thatgradually assign 0.5 probability of belonging to either A or B to all points, which is exactly thedesired behaviour. Yellow and blue points are the original point clouds, red points correspond topositions of yellow points after transformation MÎ¸ .
Figure 4: (Best viewed in color) Top row: Distribution of target test accuracies at different epochswith different objectives during SVHN-MNIST domain adaptation. The red dashed line representssource accuracy, therefore, a larger accuracy distribution mass to the right of (above) the red lineis better. These results suggest that our Dual objective leads to very minimal divergence fromthe optimal solution under the majority of learning rates and hyperparameter combinations. Theother methods have lower solution stability, in descending order: Improved WGAN, MMD, ADDA.
