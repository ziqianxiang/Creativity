Figure 1: End-to-end QA system with a symbolic knowledge store.
Figure 2: N-Gram Machine. The model contains two discrete hidden structures, the knowledgestorage and the program, which are generated from the story and the question respectively. Theexecutor executes programs against the knowledge storage to produce answers. The three learnablecomponents, knowledge encoder, knowledge decoder, and programmer, are trained to maximize theanswer accuracy as well as minimize the reconstruction loss of the story. Code assist and structuretweak help the knowledge encoder and programmer to communicate and cooperate with each other.
Figure 3: Visualization of the knowledge decoderâ€™s assessment of how informative the knowledgetuples are. Yellow means high and red means low.
Figure 4: Scalability comparison of MemN2N and NGM. Left: Answering time. Right: Answerquality. Story length is the number of sentences in each QA pair.
