Table 1: Properties of Divergences. Explicit and Implicit models refer to whether the density qÎ¸ (x) can becomputed. p is the number of parameters of the parametric discriminator. Sample complexity and computa-tional cost are defined and discussed in Section 3.1, while the ability to integrate desirable properties of the finalloss is discussed in Section 3.2. Although f-divergences can be estimated with Monte-Carlo for explicit models,they cannot be easily computed for implicit models without additional assumptions (see text). Additionally, bydesign, they cannot integrate a final loss directly. The nonparametric Wasserstein can be computed iterativelywith the Sinkhorn algorithm, and can integrate the final loss in its base distance, but requires exponentiallymany samples to estimate. Maximum Mean Discrepancy has good sample complexity, can be estimated ana-lytically, and can integrate the final loss in its base distance, but it is known to lack discriminative power forgeneric kernels, as discussed below. Parametric adversarial divergences have reasonable sample complexities,can be computed iteratively with SGD, and can integrate the final loss in the choice of class of discriminators.
