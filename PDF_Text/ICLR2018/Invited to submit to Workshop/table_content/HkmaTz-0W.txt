Table 1: Test errors of VGG-9 on CIFAR-10 with different optimization algorithms and hyper-parameters.
Table 2: Loss ValUeS and errorS for different architectureS.
Table 3: Test error for ResNet-56 with different optimization algorithms and batch-size/weight-decayparameters.	SGD	Adam bs=128^^bs=4096 bs=128^^bs=4096 WD = 0	-8.26	13.93	955	14.30 WD = 5e-4 5.89	10.59	7.67	12.36Figure 13: The loss landscape for DenseNet-121 trained on CIFAR-10. The final training error is0.002 and the testing error is 4.3716Under review as a conference paper at ICLR 2018m30≈s≈0*s*0累)」E0	50	1∞	150	200	250	300Epochs(d)	ResNet-CIFARm30≈s≈0*s*0(次)」E3O 50	1∞	150	200	250	300Epochs(e)	ResNet-CIFAR-noshortm30≈s≈0*s*0(次)」E30	50	1∞	150	200	250	3∞Epochs
