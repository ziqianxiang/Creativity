Table 1: Comparison of the models on convergence validation accuracy. Only RUM and the recentWeiNet are able to successfully solve the T = 50 Associative Recall task with a hidden state of 50.
Table 2: Question Answering task on bAbI dataset. Test accuracy (%) on LSTM, MemN2N, GORUand RUM. RUM outperforms LSTM/GORU and is outperformed only by MemN2N, which uses anattention mechanism.
Table 3: With FS-RUM-2 we achieve the state-of-the-art test result on the Penn Treebank task.
Table 4: Question Answering task on bAbI dataset. Test accuracy (%) on LSTM, MemN2N, GORUand RUM. RUM significantly outperforms LSTM/GORU and has a performance close to that ofMemoryNN, which uses an attention mechanism.
Table 5: Hyper-parameters for the Character Level Penn Treebank Task.
Table 6: Suggested learning rate pattern for training FS-RUM-2 with a standard Adam optimizer.
Table 7: FS-RUM-2(B)+LR is the baseline FS-RUM-2 except that the learning rate equals 0.003.
