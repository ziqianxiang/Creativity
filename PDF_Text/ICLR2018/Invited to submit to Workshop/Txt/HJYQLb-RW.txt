Under review as a conference paper at ICLR 2018
On the Limitations of First-Order
Approximation in GAN Dynamics
Anonymous authors
Paper under double-blind review
Ab stract
Generative Adversarial Networks (GANs) have been proposed as an approach to
learning generative models. While GANs have demonstrated promising perfor-
mance on multiple vision tasks, their learning dynamics are not yet well understood,
neither in theory nor in practice. In particular, the work in this domain has been
focused so far only on understanding the properties of the stationary solutions
that this dynamics might converge to, and of the behavior of that dynamics in this
solutions’ immediate neighborhood.
To address this issue, in this work we take a first step towards a principled study
of the GAN dynamics itself. To this end, we propose a model that, on one hand,
exhibits several of the common problematic convergence behaviors (e.g., vanishing
gradient, mode collapse, diverging or oscillatory behavior), but on the other hand,
is sufficiently simple to enable rigorous convergence analysis.
This methodology enables us to exhibit an interesting phenomena: a GAN with
an optimal discriminator provably converges, while guiding the GAN training
using only a first order approximation of the discriminator leads to unstable GAN
dynamics and mode collapse. This suggests that such usage of the first order
approximation of the discriminator, which is a de-facto standard in all the existing
GAN dynamics, might be one of the factors that makes GAN training so challenging
in practice. Additionally, our convergence result constitutes the first rigorous
analysis of a dynamics of a concrete parametric GAN.
1	Introduction
Generative modeling is a fundamental learning task of growing importance. As we apply machine
learning to increasingly sophisticated problems, we often aim to learn functions with an output
domain that is significantly more complex than simple class labels. Common examples include image
“translation” (Isola et al., 2017), speech synthesis (van den Oord et al., 2016), and robot trajectory
prediction (Finn et al., 2016). Due to progress in deep learning, we now have access to powerful
architectures that can represent generative models over such complex domains. However, training
these generative models is a key challenge. Simpler learning problems such as classification have a
clear notion of “right” and “wrong,” and the approaches based on minimizing the corresponding loss
functions have been tremendously successful. In contrast, training a generative model is far more
nuanced because it is often unclear how “good” a sample from the model is.
Generative Adversarial Networks (GANs) have recently been proposed to address this issue (Good-
fellow et al., 2014). In a nutshell, the key idea of GANs is to learn both the generative model and
the loss function at the same time. The resulting training dynamics are usually described as a game
between a generator (the generative model) and a discriminator (the loss function). The goal of the
generator is to produce realistic samples that fool the discriminator, while the discriminator is trained
to distinguish between the true training data and samples from the generator. GANs have shown
promising results on a variety of tasks, and there is now a large body of work that explores the power
of this framework (Goodfellow, 2017).
Unfortunately, reliably training GANs is a challenging problem that often hinders further research in
this area. Practitioners have encountered a variety of obstacles such as vanishing gradients, mode
collapse, and diverging or oscillatory behavior (Goodfellow, 2017). At the same time, the theoretical
underpinnings of GAN dynamics are not yet well understood. To date, there were no convergence
1
Under review as a conference paper at ICLR 2018
proofs for GAN models, even in very simple settings. As a result, the root cause of frequent failures
of GAN dynamics in practice remains unclear.
In this paper, we take a first step towards a principled understanding of GAN dynamics. Our general
methodology is to propose and examine a problem setup that exhibits all common failure cases of
GAN dynamics while remaining sufficiently simple to allow for a rigorous analysis. Concretely, we
introduce and study the GMM-GAN: a variant of GAN dynamics that captures learning a mixture
of two univariate Gaussians. We first show experimentally that standard gradient dynamics of the
GMM-GAN often fail to converge due to mode collapse or oscillatory behavior. Interestingly, this also
holds for techniques that were recently proposed to improve GAN training such as unrolled GANs
(Metz et al., 2017). In contrast, we then show that GAN dynamics with an optimal discriminator do
converge, both experimentally and provably. To the best of our knowledge, our theoretical analysis of
the GMM-GAN is the first global convergence proof for parametric and non-trivial GAN dynamics.
Our results show a clear dichotomy between the dynamics arising from applying simultaneous gradient
descent and the one that is able to use an optimal discriminator. The GAN with optimal discriminator
provably converges from (essentially) any starting point. On the other hand, the simultaneous gradient
GAN empirically often fails to converge, even when the discriminator is allowed many more gradient
steps than the generator. These findings go against the common wisdom that first order methods are
sufficiently strong for all deep learning applications. By carefully inspecting our models, we are able
to pinpoint some of the causes of this, and we highlight a phenomena we call discriminator collapse
which often causes first order methods to fail in our setting.
2	Generative Adversarial Dynamics
Generative adversarial networks are commonly described as a two player game (Goodfellow et al.,
2014). Given a true distribution P, a set of generators G = {Gu, u ∈ U}, a set of discriminators
D = {Dv, v ∈ V}, and a monotone measuring function m : R → R, the objective of GAN training
is to find a generator u in
arg min max Ex〜P[m(Dv(x))] + Ex〜Gu[m(1 - Dv (x))] .	(1)
u∈U	v∈V
In other words, the game is between two players called the generator and discriminator, respectively.
The goal of the discriminator is to distinguish between samples from the generator and the true
distribution. The goal of the generator is to fool the discriminator by generating samples that are
similar to the data distribution.
By varying the choice of the measuring function and the set of discriminators, one can capture a wide
variety of loss functions. Typical choices that have been previously studied include the KL divergence
and the Wasserstein distance (Goodfellow et al., 2014; Arjovsky et al., 2017). This formulation can
also encode other common objectives: most notably, as we will show, the total variation distance.
To optimize the objective (1), the most common approaches are variants of simultaneous gradient
descent on the generator u and the discriminator v . But despite its attractive theoretical grounding,
GAN training is plagued by a variety of issues in practice. Two major problems are mode collapse
and vanishing gradients. Mode collapse corresponds to situations in which the generator only
learns a subset (a few modes) of the true distribution P (Goodfellow, 2017; Arora & Zhang, 2017).
For instance, a GAN trained on an image modeling task would only produce variations of a small
number of images. Vanishing gradients (Arjovsky et al., 2017; Arjovsky & Bottou, 2017; Arora
et al., 2017) are, on the other hand, a failure case where the generator updates become vanishingly
small, thus making the GAN dynamics not converge to a satisfying solution. Despite many proposed
explanations and approaches to solve the vanishing gradient problem, it is still often observed in
practice (Goodfellow, 2017).
2.1	Towards a principled understanding of GAN dynamics
GANs provide a powerful framework for generative modeling. However, there is a large gap between
the theory and practice of GANs. Specifically, to the best of the authors’ knowledge, all theoretical
studies of GAN dynamics for parametric models simply consider global optima and stationary points
of the dynamics, and there has been no rigorous study of the actual GAN dynamics. In practice,
2
Under review as a conference paper at ICLR 2018
GANs are always optimized using first order methods, and the current theory of GANs cannot tell us
whether or not these methods converge to a meaningful solution. This raises a natural question, also
posed as an open problem in (Goodfellow, 2017):
Our theoretical understanding of GANs is still fairly poor. In particular, to the best of the authors’
knowledge, all existing analyzes of GAN dynamics for parametric models simply consider global
optima and stationary points of the dynamics. There has been no rigorous study of the actual GAN
dynamics, except studying it in the immediate neighborhood of such stationary points (Nagarajan &
Kolter, 2017). This raises a natural question:
Can we understand the convergence behavior of GANs?
This question is difficult to tackle for many reasons. One of them is the non-convexity of the GAN
objective/loss function, and of the generator and discriminator sets. Another one is that, in practice,
GANs are always optimized using first order methods. That is, instead of following the “ideal”
dynamics that has both the generator and discriminator always perform the optimal update, we
just approximate such updates by a sequence of gradient steps. This is motivated by the fact that
computing such optimal updates is, in general, algorithmically intractable, and adds an additional
layer of complexity to the problem.
In this paper, we want to change this state of affairs and initiate the study of GAN dynamics from an
algorithmic perspective. Specifically, we pursue the following question:
What is the impact of using first order approximation on the convergence of GAN dynamics?
Concretely, we focus on analyzing the difference between two GAN dynamics: a “first order”
dynamics, in which both the generator and discriminator use first order updates; and an “optimal
discriminator” dynamics, in which only the generator uses first order updates but the discriminator
always makes an optimal update. Even the latter, simpler dynamics has proven to be challenging
to understand. Even the question of whether using the optimal discriminator updates is the right
approach has already received considerable attention. In particular, (Arjovsky & Bottou, 2017)
present theoretical evidence that using the optimal discriminator at each step may not be desirable in
certain settings (although these settings are very different to the one we consider in this paper).
We approach our goal by defining a simple GAN model whose dynamics, on one hand, captures
many of the difficulties of real-world GANs but, on the other hand, is still simple enough to make
analysis possible. We then rigorously study our questions in the context of this model. Our intention
is to make the resulting understanding be the first step towards crystallizing a more general picture.
3	A Simple Model for Studying GAN Dynamics
Perhaps a tempting starting place for coming up with a simple but meaningful set of GAN dynamics
is to consider the generators being univariate Gaussians with fixed variance. Indeed, in the supple-
mentary material we give a short proof that simple GAN dynamics always converge for this class of
generators. However, it seems that this class of distributions is insufficiently expressive to exhibit
many of the phenomena such as mode collapse mentioned above. In particular, the distributions in
this class are all unimodal, and it is unclear what mode collapse would even mean in this context.
Generators. The above considerations motivate us to make our model slightly more complicated.
We assume that the true distribution and the generator distributions are all mixtures of two univariate
Gaussians with unit variance, and uniform mixing weights. Formally, our generator set is G , where
G
2 N(μ1, I) + 2 N(μ2, I) | μ1,μ2 ∈ R}.
(2)
For any μ ∈ R2,we let Gμ(x) denote the distribution in G with means at μι and μ2. While this is a
simple change compared to a single Gaussian case, it makes a large difference in the behavior of the
dynamics. In particular, many of the pathologies present in real-world GAN training begin to appear.
Loss function. While GANs are usually viewed as a generative framework, they can also be viewed
as a general method for density estimation. We want to set up learning an unknown generator
Gμ* ∈ G as a generative adversarial dynamics. To this end, We must first define the loss function
3
Under review as a conference paper at ICLR 2018
for the density estimation problem. A well-studied goal in this setting is to recover Gμ* (x) in total
variation (also known as L1 or statistical) distance, where the total variation distance between two
distributions P, Q is defined as
dτv(P, Q) = 1 I |P(x) - Q(χ)∣dχ = maxP(A) - Q(A) ,	(3)
2 Jω	A
where the maximum is taken over all measurable events A.
Such finding the best-fit distribution in total variation distance can indeed be naturally phrased as
generative adversarial dynamics. Unfortunately, for arbitrary distributions, this is algorithmically
problematic, simply because the set of discriminators one would need is intractable to optimize over.
However, for distributions that are structurally simple, like mixtures of Gaussians, it turns out we
can consider a much simpler set of discriminators. In Appendix B.1 in the supplementary material,
motivated by connections to VC theory, We show that for two generators Gμι, G*? ∈ G, We have
dτv(Gμι ,Gμ2 )= max Gμι (E) - Gμ? (E) ,	(4)
E=I1∪I2
where the maxima is taken over two disjoint intervals I1 , I2 ⊆ R. In other words, instead of
considering the difference of measure between the two generators Gμι, Gμ2 on arbitrary events,
we may restrict our attention to unions of two disjoint intervals in R. This is a special case of a
well-studied distance measure known as the Ak-distance, for k = 2 (Devroye & Lugosi, 2012; Chan
et al., 2014). Moreover, this class of subsets has a simple parametric description.
Discriminators. Now, the above discussion motivates our definition of discriminators to be
D = {I['ι,rι] + I['2,r2] ∣', r ∈ R2 s.t. '1 ≤ ri ≤ ' ≤ r2} .	(5)
In other words, the set of discriminators is taken to be the set of indicator functions of sets which can
be expressed as a union of at most two disjoint intervals. With this definition, finding the best fit in
total variation distance to some unknown Gμ* ∈ G is equivalent to finding μ minimizing
b = arg min max L(μ,',r) , where L(μ,',r) = Ex 〜GU * [D(x)] + Ex 〜Gμ[1 - D(x)]	(6)
μ	',T
is a smooth function of all three parameters (see the supplementary material for details).
Dynamics. The objective in (6) is easily amenable to optimization at parameter level. A natural
approach for optimizing this function would be to define G(b) = maxg,r L(b,', r), and to perform
(stochastic) gradient descent on this function. This corresponds to, at each step, finding the the
optimal discriminator, and updating the current μb in that direction. We call these dynamics the
optimal discriminator dynamics. Formally, given μb(0) and a stepsize ηg, and a true distribution
Gμ* ∈ G, the optimal discriminator dynamics for Gμ*, G, D starting at μ(0) are given iteratively as
'(t),r(t) = arg max L(μ(t),',r) , b(t+i) = b(t) — n VμL(b(t),'(t) ,r(t)) ,	(7)
`,r
where the maximum is taken over `, r which induce two disjoint intervals.
For more complicated generators and discriminators such as neural networks, these dynamics are
computationally difficult to perform. Therefore, instead of the updates as in (7), one resorts to
simultaneous gradient iterations on the generator and discriminator. These dynamics are called the
first order dynamics. Formally, given b(0),'(0),r(0) and a stepsize %, ηd, and a true distribution
Gμ* ∈ G, the first order dynamics for Gμ*, G, D starting at μ(0) are specified as
b(t+1) = b(t) - ηgVμL(b(t),'(t),r(t))	(8)
r(t+1) =	r(t)+ ndVrL(b(t),'(t),r(t))	,	'(t+i)	=	'(t)	+	ηdV'L(b(t),'(t),r(t))	.	(9)
Even for our relatively simple setting, the first order dynamics can exhibit a variety of behaviors,
depending on the starting conditions of the generators and discriminators. In particular, in Figure 1,
we see that depending on the initialization, the dynamics can either converge to optimality, exhibit
a primitive form of mode collapse, where the two generators collapse into a single generator, or
converge to the wrong value, because the gradients vanish. This provides empirical justification for
our model, and shows that these dynamics are complicated enough to model the complex behaviors
which real-world GANs exhibit. Moreover, as we show in Section 5 below, these behaviors are not
just due to very specific pathological initial conditions: indeed, when given random initial conditions,
the first order dynamics still more often than not fail to converge.
4
Under review as a conference paper at ICLR 2018
Parametrization We note here that there could be several potential GAN dynamics to consider
here. Each one resulting from slightly different parametrization of the total variation distance. For
instance, a completely equivalent way to define the total variation distance is
dTV(P, Q) = max |P (A) - Q(A)| ,	(10)
which does not change the value of the variational distance, but does change the induced dynamics.
We do not focus on these induced dynamics in this paper since they do not exactly fit within the
traditional GAN framework, i.e. it is not of the form (1) (see Appendix C). Nevertheless, it is an
interesting set of dynamics and it is a natural question whether similar phenomena occur in these
dynamics. In Appendix C, we show the the optimal discriminator dynamics are unchanged, and the
induced first order dynamics have qualitatively similar behavior to the ones we consider in this paper.
This also suggests that the phenomena we exhibit might be more fundamental.
(a) Converging behavior
First order dynamics, mode collapse
4
2
--Iefto
--Iefti
righto
rightl
—muhatθ
muhatl
0
《耳棒解端例MMMWM∙
* **γ*
3小'、，.、.…，心.其
0
1000	2000	3000	4000	5000	6000	7000	0000
(b) Mode collapse and oscillation
0	1000	2000	3000	4000	5000
(d) Vanishing gradient
Optimal discriminator dynamics
(c) Optimal discriminator
Figure 1: A selection of different GAN behaviors. In all plots the true distribution was G** with
μ* = (-0.5,0.5), and step size was taken to be 0.1. The solid lines represent the two coordinates of
b, and the dotted lines represent the discriminator intervals. In order: (a) first order dynamics with
initial conditions that converge to the true distribution. (b) First order dynamics with initial conditions
that exhibit wild oscillation before mode collapse. (c) Optimal discriminator dynamics. (d) First
order dynamics that exhibit vanishing gradients and converge to the wrong distribution. Observe that
the optimal discriminator dynamics converge, and then the discriminator varies wildly, because the
objective function is not differentiable at optimality. Despite this it remains roughly at optimality
from step to step.
4	Optimal Discriminator vs. First Order Dynamics
We now describe our results in more detail. We first consider the dynamics induced by the optimal
discriminator. Our main theoretical result is1:
1We actually analyze a minor variation on the optimal discriminator dynamics. In particular, we do not rule
out the existence of a measure zero set on which the dynamics are ill-behaved. Thus, we will analyze the optimal
5
Under review as a conference paper at ICLR 2018
Theorem 4.1. Fix δ > 0 sufficiently small and C > 0. Let μ* ∈ R2 so that ∣μ*∣ ≤ C, and
∣μ↑ — μ 却 ≥ δ. Then, for all initial points b(0) so that ∣b(0)∣ ≤ C forall i andso that ∣b10) — b20)∣ ≥ δ,
if we let η = Poly(1∕δ, e-C2) and T = Poly(1∕δ, e-C2), then if b(T) is specified by the optimal
discriminator dynamics, we have dτv (Gμ*, Gb(T)) ≤ δ.
In other words, if the μ* are bounded by a constant, and not too close together, then in time which is
polynomial in the inverse of the desired accuracy δ and e-C2, where C is a bound on how far apart
the μ* and μ are, the optimal discriminator dynamics converge to the ground truth in total variation
distance. Note that the dependence on e-C2 is necessary, as if the μ and μ* are initially very far apart,
then the initial gradients for the μb will necessarily be of this scale as well.
On the other hand, we provide simulation results that demonstrate that first order updates, or more
complicated heuristics such as unrolling, all fail to consistently converge to the true distribution, even
under the same sorts of conditions as in Theorem 4.1. In Figure 1, we gave some specific examples
where the first order dynamics fail to converge. In Section 5 we show that this sort of divergence
is common, even with random initializations for the discriminators. In particular, the probability
of convergence is generally much lower than 1, for both the regular GAN dynamics, and unrolling.
In general, we believe that this phenomena should occur for any natural first order dynamics for
the generator. In particular, one barrier we observed for any such dynamics is something we call
discriminator collapse, that we describe in Appendix A.
4.1	Analyzing the Optimal Discriminator Dynamics
We provide now a high level overview of the proof of Theorem 4.1. The key element we will need in
our proof is the ability to quantify the progress our updates make on converging towards the optimal
solution. This is particularly challenging as our objective function is neither convex nor smooth. The
following lemma is our main tool for achieving that. Roughly stated, it says that for any Lipschitz
function, even if it is non-convex and non-smooth, as long as the change in its derivative is smaller in
magnitude than the value of the derivative, gradient descent makes progress on the function value.
Note that this condition is much weaker than typical assumptions used to analyze gradient descent.
Lemma 4.2. Let g : Rk → R be a Lipschitz function that is differentiable at some fixed x ∈ Rk.
For some η > 0, let x0 = X — ηVf (x). Suppose there exists c < 1 so that almost all V ∈
L(x, x0), where L(x, y) denotes the line between x and y, g is differentiable, and moreover, we have
∣∣Vg(x) — Vg(v)k2 ≤ CkVg(X)k2. Then g(x0) — g(x) ≤ —η(1 — c)∣∣Vg(x)k2 .
Here, we will use the convention that μ1 ≤ μ2, and during the analysis, we will always assume for
simplicity of notation that μι ≤ b2. Also, in what follows, let f (μ) = fμ* (b) = dτv(Gμ, Gμ*) and
F(b, x) = Gμ* (x) — Gμ(χ) be the objective function and the difference of the PDFs between the
true distribution and the generator, respectively.
For any δ > 0, define the sets
Rect(δ) = {μ :向—μ*∣ < δ for some i,j} , Opt(δ) = {μ :向—μ*∣ < δ for all i}.
to be the set of parameter values which have at least one parameter which is not too far from optimality,
and the set of parameter values so that all parameter values are close. We also let B(C) denote the
box of sidelength C around the origin, and we let SeP(γ) = {v ∈ R2 : |v1 — v2| > γ} be the set of
parameter vectors which are not too close together.
Our main work lies within a set of lemmas which allow us to instantiate the bounds in Lemma
4.2. We first show a pair of lemmas which show that, explicitly excluding bad cases such as mode
collapse, our dynamics satisfy the conditions of Lemma 4.2. We do so by establishing a strong (in
fact, nearly constant) lower bound on the gradient when we are fairly away from optimality (Lemma
4.3). Then, we show a relatively weak bound on the smoothness of the function (Lemma 4.4), but
which is sufficiently strong in combination with Lemma 4.3 to satisfy Lemma 4.2. Finally, we rule
discriminator dynamics after adding an arbitrarily small amount of Gaussian noise. It is clear that by taking this
noise to be sufficiently small (say exponentially small) then we avoid this pathological set with probability 1,
and moreover the noise does not otherwise affect the convergence analysis at all. For simplicity, we will ignore
this issue for the rest of the paper.
6
Under review as a conference paper at ICLR 2018
out the pathological cases we explicitly excluded earlier, such as mode collapse or divergent behavior
(Lemmas 4.5 and 4.6). Putting all these together appropriately yields the desired statement. Our first
lemma is a lower bound on the gradient value:
Lemma 4.3. Fix C ≥ 1 ≥ Y ≥ δ > 0. Suppose μ ∈ Rect(0) ,and suppose μ*, μ ∈ B(C) and
μ* ∈ Sep(γ), b ∈ Sep(δ). There is some K = Ω⑴∙ (δe-C2/C)O⑴ so that ∣∣Vfμ* (b)k2 ≥ K.
The above lemma statement is slightly surprising at first glance. It says that the gradient is never
0, which would suggest there are no local optima at all. To reconcile this, one should note that the
gradient is not continuous (defined) everywhere.
The second lemma states a bound on the smoothness of the function:
Lemma 4.4. Fix C ≥ 1 and Y ≥ δ > 0 so that δ is sufficiently small. Let μ*,b, μ0 be such
that L(b,b0) ∩ Opt(δ) = 0, μ* ∈ SeP(Y), μ0, b ∈ Sep(δ), and μ*,b, μ0 ∈ B(C). Let K =
Ω(1) ∙ (δe-C2/C)O⑴ be the K for which Lemma 4.3 holds with those parameters. Ifwe have
IlbO — b∣∣2 ≤ Ω⑴∙ (δe-C2/C )O(1) for appropriate choices of constants on the RHS, we get
kVfμ*(b0) - Vfμ*(b)∣∣2 ≤ K/2 ≤ ∣∣Vfμ*(b)k2∕2.
These two lemmas almost suffice to prove progress as in Lemma 4.2, however, there is a major caveat.
Specifically, Lemma 4.4 needs to assume that μ and μ0 are sufficiently well-separated, and that they
are bounded. While the bi start out separated and bounded, it is not clear that it does not mode
collapse or diverge off to infinity. However, we are able to rule these sorts of behaviors out. Formally:
Lemma 4.5 (No mode collapse). Fix γ > 0, and let δ be sufficiently small. Let η ≤ δ/C for some C
large. Suppose μ* ∈ SeP(Y). Then, if μ ∈ Sep(δ), and μ0 = μ 一 ηVf** (b), we have b0 ∈ Sep(δ).
Lemma 4.6 (No diverging to infinity). Let C > 0 be sufficiently large, and let η > 0 be sufficiently
small. Suppose μ* ∈ B(C), and b ∈ B(2C). Then, ifwe let μ0 = μ — nVfμ*(μ),then b ∈ B(2C).
Together, these four lemmas together suffice to prove Theorem 4.1 by setting parameters appropriately.
We refer the reader to Appendix D for more details including the proofs.
5	Experiments
To illustrate more conclusively that the phenomena demonstrated in Figure 1 are not particularly rare,
and that first order dynamics do often fail to converge, we also conducted the following heatmap
experiments. We set μ* = (—0.5,0.5) as in Figure 1. We then set a grid for the μ, so that each
coordinate is allowed to vary from -1 to 1. For each of these grid points, we randomly chose
a set of initial discriminator intervals, and ran the first order dynamics for 3000 iterations, with
constant stepsize 0.3. We then repeated this 120 times for each grid point, and plotted the probability
that the generator converged to the truth, where we say the generator converged to the truth if the
TV distance between the generator and optimality is < 0.1. The choice of these parameters was
somewhat arbitrary, however, we did not observe any qualitative difference in the results by varying
these numbers, and so we only report results for these parameters. We also did the same thing for the
optimal discriminator dynamics, and for unrolled discriminator dynamics with 5 unrolling steps, as
described in (Metz et al., 2017), which attempt to match the optimal discriminator dynamics.
The results of the experiment are given in Figure 2. We see that all three methods fail when we
initialize the two generator means to be the same. This makes sense, since in that regime, the
generator starts out mode collapsed and it is impossible for it to un-“mode collapse”, so it cannot fit
the true distribution well. Ignoring this pathology, we see that the optimal discriminator otherwise
always converges to the ground truth, as our theory predicts. On the other hand, both regular first
order dynamics and unrolled dynamics often times fail, although unrolled dynamics do succeed more
often than regular first order dynamics. This suggests that the pathologies in Figure 1 are not so rare,
and that these first order methods are quite often unable to emulate optimal discriminator dynamics.
6	Related Work
GANs have received a tremendous amount of attention over the past two years (Goodfellow, 2017).
Hence we only compare our results to the most closely related papers here.
7
Under review as a conference paper at ICLR 2018
-1.0
Regular training
-0.5
0.0
0.5
1.0
-1.0	-0.5	0.0	0.5	1.0
1.0
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0.0
Unrolled Training
-1.0
Optimal training
-0.5
0.0
0.5
-0.5	0.0	0.5	1.0
Iro
0.9
0.8
0.7
0.6
0.5
0.4
0.3
l0∙0
Figure 2: Heatmap of success probability for random discriminator initialization for regular GAN
training, unrolled GAN training, and optimal discriminator dynamics.
The recent paper (Arora et al., 2017) studies generalization aspects of GANs and the existence of
equilibria in the two-player game. In contrast, our paper focuses on the dynamics of GAN training.
We provide the first rigorous proof of global convergence and show that a GAN with an optimal
discriminator always converges to an approximate equilibrium.
One recently proposed method for improving the convergence of GAN dynamics is the unrolled
GAN (Metz et al., 2017). The paper proposes to “unroll” multiple discriminator gradient steps in
the generator loss function. The authors argue that this improves the GAN dynamics by bringing
the discriminator closer to an optimal discriminator response. Our experiments show that this is not
a perfect approximation: the unrolled GAN still fails to converge in multiple initial configurations
(however, it does converge more often than a “vanilla” one-step discriminator).
The authors of (Arjovsky & Bottou, 2017) also take a theoretical view on GANs. They identify two
important properties of GAN dynamics: (i) Absolute continuity of the population distribution, and
(ii) overlapping support between the population and generator distribution. If these conditions do
not hold, they show that the GAN dynamics fail to converge in some settings. However, they do not
prove that the GAN dynamics do converge under such assumptions. We take a complementary view:
we give a convergence proof for a concrete GAN dynamics. Moreover, our model shows that absolute
continuity and support overlap are not the only important aspects in GAN dynamics: although our
distributions clearly satisfy both of their conditions, the first-order dynamics still fail to converge.
The paper (Nagarajan & Kolter, 2017) studies the stability of equilibria in GAN training. In contrast to
our work, the results focus on local stability while we establish global convergence results. Moreover,
their theorems rely on fairly strong assumptions. While the authors give a concrete model for which
these assumptions are satisfied (the linear quadratic Gaussian GAN), the corresponding target and
generator distributions are unimodal. Hence this model cannot exhibit mode collapse. We propose
the GMM-GAN specifically because it is rich enough to exhibit mode collapse.
The recent work (Grnarova et al., 2017) views GAN training through the lens of online learning. The
paper gives results for the game-theoretic minimax formulation based on results from online learning.
The authors give results that go beyond the convex-concave setting, but do not address generalization
questions. Moreover, their algorithm is not based on gradient descent (in contrast to essentially all
practical GAN training) and relies on an oracle for minimizing the highly non-convex generator loss.
This viewpoint is complementary to our approach. We establish results for learning the unknown
distribution and analyze the commonly used gradient descent approach for learning GANs.
7	Conclusions
We haven taken a step towards a principled understanding of GAN dynamics. We define a simple yet
rich model of GAN training and prove convergence of the corresponding dynamics. To the best of our
knowledge, our work is the first to establish global convergence guarantees for a parametric GAN. We
find an interesting dichotomy: If we take optimal discriminator steps, the training dynamics provably
converge. In contrast, we show experimentally that the dynamics often fail if we take first order
discriminator steps. We believe that our results provide new insights into GAN training and point
towards a rich algorithmic landscape to be explored in order to further understand GAN dynamics.
8
Under review as a conference paper at ICLR 2018
References
Martin Arjovsky and Leon Bottou. Towards principled methods for training generative adversarial
networks. In ICLR, 2017. URL https://arxiv.org/abs/1701.04862.
Martin Arjovsky, Soumith Chintala, and Leon Bottou. Wasserstein GAN. arXiv preprint
arXiv:1701.07875, 2017.
Sanjeev Arora and Yi Zhang. Do gans actually learn the distribution? an empirical study. arXiv
preprint arXiv:1706.08224, 2017.
Sanjeev Arora, Rong Ge, Yingyu Liang, Tengyu Ma, and Yi Zhang. Generalization and equilibrium
in generative adversarial nets (GANs). arXiv preprint arXiv:1703.00573, 2017.
Siu-On Chan, Ilias Diakonikolas, Rocco A Servedio, and Xiaorui Sun. Efficient density estimation
via piecewise polynomial approximation. In Proceedings of the 46th Annual ACM Symposium on
Theory of Computing, pp. 604-613. ACM, 2014.
Luc Devroye and Ggbor Lugosi. Combinatorial methods in density estimation. Springer Science &
Business Media, 2012.
Chelsea Finn, Paul Christiano, Pieter Abbeel, and Sergey Levine. A connection between gener-
ative adversarial networks, inverse reinforcement learning, and energy-based models. CoRR,
abs/1611.03852, 2016. URL http://arxiv.org/abs/1611.03852.
Walter Gautschi. How (un) stable are Vandermonde systems? Lecture Notes in Pure and Applied
Mathematics, 124:193-210, 1990.
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair,
Aaron Courville, and Yoshua Bengio. Generative adversarial nets. In Advances in neural informa-
tion processing systems, pp. 2672-2680, 2014.
Ian J. Goodfellow. NIPS 2016 tutorial: Generative adversarial networks. CoRR, abs/1701.00160,
2017. URL http://arxiv.org/abs/1701.00160.
Paulina Grnarova, Kfir Y. Levy, Aurelien Lucchi, Thomas Hofmann, and Andreas Krause. An online
learning approach to generative adversarial networks. arXiv preprint arXiv:1706.03269, 2017.
R.A. Hummel and B.C. Gidas. Zero Crossings and the Heat Equation. New York University., 1984.
Phillip Isola, Jun-Yan Zhu, Tinghui Zhou, and Alexei A Efros. Image-to-image translation with
conditional adversarial networks. In CVPR, 2017.
VA Markov. On functions deviating least from zero in a given interval. Izdat. Imp. Akad. Nauk, St.
Petersburg, pp. 218-258, 1892.
Luke Metz, Ben Poole, David Pfau, and Jascha Sohl-Dickstein. Unrolled generative adversarial
networks. In ICLR, 2017. URL http://arxiv.org/abs/1611.02163.
Vaishnavh Nagarajan and J. Zico Kolter. Gradient descent gan optimization is locally stable. arXiv
preprint arXiv:1706.04156, 2017.
Aaron van den Oord, Sander Dieleman, Heiga Zen, Karen Simonyan, Oriol Vinyals, Alex Graves,
Nal Kalchbrenner, Andrew W. Senior, and Koray Kavukcuoglu. Wavenet: A generative model for
raw audio. CoRR, abs/1609.03499, 2016. URL http://arxiv.org/abs/1609.03499.
9
Under review as a conference paper at ICLR 2018
Figure 3: Example of Discriminator Collapse. The initial configuration has μ* = {-2,2}, b =
{-1, 2.5}, left discriminator [-1, 0.2], and right discriminator [-1, 2.5]. The (multiplicative) step
size used to generate (c), (d), and (e) was 0.3.
A Discriminator Collapse: A Barrier for First Order Methods
As discussed above, our simple GAN dynamics are able to capture the same undesired behaviors that
more sophisticated GANs exhibit. In addition to these behaviors, our dynamics enables us to discern
another degenerate behavior which does not seem to have previously been observed in the literature.
We call this behavior discriminator collapse.
We first explain this phenomenon using language specific to our GMM-GAN dynamics. In our
dynamics, discriminator collapse occurs when a discriminator interval which originally had finite
width is forced by the dynamics to have its width converge to 0. This happens whenever this interval
lies entirely in a region where the generator PDF is much larger than the discriminator PDF. We will
shortly argue why this is undesirable.
In Figure 3, we show an example of discriminator collapse in our dynamics. Each plot in the
figure shows the true PDF minus the PDF of the generators, where the regions covered by the
discriminator are shaded. Plot (a) shows the initial configuration of our example. Notice that the
leftmost discriminator interval lies entirely in a region for which the true PDF minus the generators’
PDF is negative. Since the discriminator is incentivized to only have mass on regions where the
difference is positive, the first order dynamics will cause the discriminator interval to collapse to have
length zero if it is in a negative region. We see in Plot (c) that this discriminator collapses if we run
many discriminator steps for this fixed generator. In particular, these steps do not converge to the
globally optimal discriminator shown in Plot (b).
This collapse also occurs when we run the dynamics. In Plots (d) and (e), we see that after running the
first order dynamics - or even unrolled dynamics - for many iterations, eventually both discriminators
collapse. When a discriminator interval has length zero, it can never uncollapse, and moreover, its
contribution to the gradient of the generator is zero. Thus these dynamics will never converge to the
ground truth.
For general GANs, we view discriminator collapse as a situation when the local optimization
landscape around the current discriminator encourages it to make updates which decrease its rep-
resentational power. For instance, this could happen because the first order updates are unable to
wholly follow the evolution of the optimal discriminator due to attraction of local maxima, and thus
only capture part of the optimal discriminator’s structure. We view understanding the exact nature of
discriminator collapse in more general settings and interesting research problem to explore further.
10
Under review as a conference paper at ICLR 2018
B	Omitted details from Section 2
B.1	TWO INTERVALS SUFFICE FOR G
Here we formally prove (4). In fact, we will prove a slight generalization of this fact which will be
useful later on.
We require the following theorem from Hummel and Gidas:
Theorem B.1 ((Hummel & Gidas, 1984)). Let f be any analytic function with at most n zeros. Then
f ◦ N(0, σ2 ) has at most n zeros.
This allows us to prove:
Theorem B.2. Any linear combination F(x) of the probability density functions of k Gaussians with
the same variance has at most k - 1 zeros, provided at least two of the Gaussians have different
means. In particular, for any μ = V, thefunCtion F(x) = Dμ(x) 一 DV (x) has at most 3 zeroes.
Proof. If we have more than 1 Gaussian with the same mean, we can replace all Gaussians having
that mean with an appropriate factor times a single Gaussian with that mean. Thus, we assume
without loss of generality that all Gaussians have distinct means. We may also assume without loss
of generality that all Gaussians have a nonzero coefficient in the definition of F.
Suppose the minimum distance between the means of any of the Gaussians is δ. We first prove the
statement when δ is sufficiently large compared to everything else. Consider any pair of Gaussians
with consecutive means ν, μ. WLOG assume that μ > ν = 0. Suppose our pair of Gaussians has
the same sign in the definition of F. In particular they are both strictly positive. For sufficiently
large δ, we can make the contribution of the other Gaussians to F an arbitrarily small fraction of the
whichever Gaussian in our pair is largest for all points on [ν, μ]. Thus, for δ sufficiently large, that
there are no zeros on this interval.
Now suppose our pair of Gaussians have different signs in the definition of F . Without loss of
generality, assume the sign of the Gaussian with mean ν is positive and the sign of the Gaussian with
mean μ is negative. Then the PDF of the first Gaussian is strictly decreasing on (ν, μ] and the PDF of
the negation of the second Gaussian is decreasing on [ν, μ). Thus, their sum is strictly decreasing on
this interval. Similarly to before, by making δ sufficiently large, the magnitude of the contributions of
the other Gaussians to the derivative in this region can be made an arbitrarily small fraction of the
magnitude of whichever Gaussian in our pair contributes the most at each point in the interval. Thus,
in this case, there is exactly one zero in the intervale [μ, V].
Also, note that there can be no zeros of F outside of the convex hull of their means. This follows by
essentially the same argument as the two positive Gaussians case above.
The general case (without assuming δ sufficiently large) follows by considering sufficiently skinny
(nonzero variance) Gaussians with the same means as the Gaussians in the definition of F, rescaling
the domain so that they are sufficiently far apart, applying this argument to this new function,
unscaling the domain (which doesn’t change the number of zeros), then convolving the function with
an appropriate (very fat) Gaussian to obtain the real F, and invoking Theorem B.1 to say that the
number of zeros does not increase from this convolution.	□
B.2	THE FUNCTION L
In this section, we derive the form of L. By definition, we have
√2πL(b,', r) = √2π (Ex〜g** [D(x)]+ Ex〜g* [1 ― D(x)])
=√2π (/ Gμ* (x) - Gb(x)dx) + √2π ,
11
Under review as a conference paper at ICLR 2018
where I = [`1, r1] ∪ [`2, r2]. We then have
√2πL(b, ', r) = √2π ∣ ^X f Gμ* (x) — Gμ(x)dx + + √2π
i=1,2 `i
X X I ri e_5引2/2-e-5bj )2/2dx + √2∏.
i=1,2 j=1,2 `i
(11)
It is not to hard to see from the Fundamental theorem of calculus that L is indeed a smooth function
of all parameters.
C Alternative Induced Dynamics
Our focus in this paper is on the dynamics induced by, since it arises naturally from the form of the
total variation distance (3) and follows the canonical form of GAN dynamics (1). However, one
could consider other equivalent definitions of total variation distance too. And these definitions could,
in principle, induce qualitatively different behavior of the first order dynamics.
As mentioned in Section 3, an alternative dynamics could be induced by the definition of total
variation distance given in (10). The corresponding loss function would be
L0(μ, Qr)= lL(μ, Ur)I = lEχ~Gμ* [D(X)] + Eχ~G”[1- D(X)] I ,	(12)
i.e. the same as in (6) but with absolute values on the outside of the expression. Observe that this loss
function does not actually fit the form of the general GAN dynamics presented in (1). However, it
still constitutes a valid and fairly natural dynamics. Thus one could wonder whether similar behavior
to the one we observe for the dynamics we actually study occurs also in this case.
To answer this question, we first observe that by the chain rule, the (sub)-gradient of L0 with respect
to μ,', r are given by
VμL0(μ,1, r) = sgn (L(μ, 4, r)) V“L(〃,4, r)
V'L0(μ,4, r) = sgn (L(μ, 4, r)) V'L(μ,4, r)
VrL0(μ,4, r) = sgn (L(μ, 4, r)) VrL(μ,4, r),
that is, they are the same as for L except modulated by the sign of L.
We now show that the optimal discriminator dynamics is identical to the one that we analyze in the
paper (7), and hence still provably converge. This requires some thought; indeed a priori it is not
even clear that the optimal discriminator dynamics are well-defined, since the optimal discriminator
is no longer unique. This is because for any μ*,μ, the sets Ai = {x : Gμ*(x) ≥ Gμ(x)} and
A2 = {x : Gμ(χ) ≥ Gμ* (x)} both achieve the maxima in (10), since
I Gμ(x) — Gμ* (x)dx = -	Gμ(x) — Gμ* (x)dx .
A1	A2
(13)
However, we show that the optimal discriminator dynamics are still well-formed. WLOG assume
that A1 Gμ(χ) — Gμ* (x)dx ≥ 0, so that Ai is also the optimal discriminator for the dynamics We
consider in the paper. If we let `(i), r(i) be the left and right endpoints of the intervals in Ai for
i = 1, 2, We have that the update to μ induced by ('(1),r(i)) is given by
VμL0(μ,，⑴，r⑴)=VμL(μ,，⑴，r⑴),
so the update induced by (`(i), r(i)) is the same as the one induced by the optimal discriminator
dynamics in the paper. Moreover, the update to μ induced by ('(2),r(2)) is given by
V“L0(〃/2),r(2)) = sgn(L(〃,d2),r⑵))V“L(〃,d2),r⑵)
=-V“(—L(μ,，⑴,r⑴))
=VμL(μ,，⑴,r⑴),
12
Under review as a conference paper at ICLR 2018
where (a) follows from the assumption that JAl Gμ (x) - Gμ*(χ)dχ ≥ 0 and from (13), so it is also
equal to the the one induced by the optimal discriminator dynamics in the paper. Hence the optimal
discriminator dynamics are well-formed and unchanged from the optimal discriminator dynamics
described in the paper.
Thus the question is whether the first order approximation of this dynamics and/or the unrolled first
order dynamics exhibit the same qualitative behavior too. To evaluate the effectiveness, we performed
for these dynamics experiments analogous to the ones summarized in Figure 2 in the case of the
dynamics we actually analyzed. The results of these experiments are presented in Figure 4. Although
the probability of success for these dynamics is higher, they still often do not converge. We can thus
see that a similar dichotomy occurs here as in the context of the dynamics we actually study. In
particular, we still observe the discriminator collapse phenomena in these first order dynamics.
Figure 4: Heatmap of success probability for random discriminator initialization for regular GAN
training, unrolled GAN training with dynamics induced by 12
C.1 Why does discriminator collape still happen?
It might be somewhat surprising that even with absolute values discriminator collapse occurs. Orig-
inally the discriminator collapse occurred because if an interval was stuck in a negative region, it
always subtracts from the value of the loss function, and so the discriminator is incentivized to make
it disappear. Now, since the value of the loss is always nonnegative, it is not so clear that this still
happens.
Despite this, we still observe discriminator collapse with these dynamics. Here we describe one
simple scenario in which discriminator collapse still occurs. Suppose the discriminator intervals have
left and right endpoints ',r and L(μ,',r) > 0. Then, if it is the case that J] Gμ*(x) - Gμ(x)dx < 0
for some i = 1, 2. that is, on one of the discriminator intervals the value of the loss is negative, then
the discriminator is still incentivized locally to reduce this interval to zero, as doing so increases both
L(μ,', r) and hence L0(μ,', r). Symmetrically if L(μ,', r) < 0 and there is a discriminator interval
on which the loss is positive, the discriminator is incentivized locally to reduce this interval to zero,
since that increases L0(μ,', r). This causes the discriminator collapse and subsequently causes the
training to fail to converge.
D	Omitted Proofs from Section 4.1
This appendix is dedicated to a proof of Theorem 4.1. We start with some remarks on the proof
techniques for these main lemmas. At a high level, Lemmas 4.3, 4.5, 4.6 all follow from involved
case analyses. Specifically, we are able to deduce structure about the possible discriminator intervals
by reasoning about the structure of the current mean estimate μ and the true means. From there we
are able to derive bounds on how these discriminator intervals affect the derivatives and hence the
update functions.
To prove Lemma 4.4, we carefully study the evolution of the optimal discriminator as we make small
changes to the generator. The key idea is to show that when the generator means are far from the
true means, then the zero crossings of F (μb, x) cannot evolve too unpredictably as we change μb. We
do so by showing that locally, in this setting F can be approximated by a low degree polynomial
13
Under review as a conference paper at ICLR 2018
with large coefficients, via bounding the condition number of a certain Hermite Vandermonde matrix.
This gives us sufficient control over the local behavior of zeros to deduce the desired claim. By being
sufficiently careful with the bounds, we are then able to go from this to the full generality of the
lemma. We defer further details to Appendix D.
D.1 Setup
By inspection on the form of (11), We see that the gradient of the function fμ* (b) if it is defined must
be given by
dfμ* = _L_ X (e-(0ifi)2/2 _ e-3i-'i)2/2)
dbi = √2∏ i⅛J	厂
Here Ii = [`i , ri] are the intervals Which achieve the supremum in (4). While these intervals may not
be unique, it is not hard to show that this value is well-defined, as long as μ = μ*, that is, when the
optimal discriminator intervals are unique as sets.
ReCall Fμ* (bl, X) = Gμ* (X) - Gμ(X).
D.2 Basic Math Facts
Before we begin, we require the following facts.
We first need that the Gaussian, and any fixed number of derivatives of the Gaussian, are Lipschitz
functions.
Fact D.1. For any constant i, there exists a constant B such thatfor all x, μ ∈ R, d⅞ N(x, μ, σ2 =
1) ≤ B.
Proof. Note that every derivative of the Gaussian PDF (including the 0th) is a bounded function.
Furthermore, all these derivatives eventually tend to 0 whenever the input goes towards ∞ or -∞.
Thus, any particular derivative is bounded by a constant for all R. Furthermore, shifting the mean
of the Gaussian does not change the set of values the derivatives of its derivative takes (only their
locations).	□
We also need the following bound on the TV distance between two Gaussians, which is folklore, and
is easily proven via Pinsker’s inequality.
Fact D.2 (folklore). If two univariate Gaussians with unit variance have means within distance at
most ∆ then their TV distance is at most O(1) ∙ ∆.
This immediately implies the following, which states that fμ* is Lipschitz.
Corollary D.3. There is some absolute constant C so thatfor any μ, V, we have ∣fμ* (μ) 一 fμ* (ν) | ≤
Ckμ - νk2.
We also need the following basic analysis fact:
Fact D.4 (folklore). Suppose g : Rd → R is B-Lipschitz for some B. Then g is differentiable almost
everywhere.
This implies that fμ* is indeed differentiable except on a set of measure zero. As mentioned previously,
we will always assume that we never land within this set during our analysis.
D.3 Proof of Theorem 4.1 given Lemmata
Before we prove the various lemmata described in the body, we show how Theorem 4.1 follows from
them.
Proof of Theorem 4.1. Set δ0 be a sufficiently small constant multiple of δ. Provided we make the
nonzero constant factor on the step size sufficiently small (compared to δ0 /δ), and the exponent on δ
in the magnitude step size at least one, the magnitude of our step size will be at most δ0 . Thus, in any
14
Under review as a conference paper at ICLR 2018
step where b ∈ Opt(δ0), We end the step outside of this set but still in Opt(2δ0). By Lemma D.2, for
a sufficiently small choice of constant in the definition of δ0, the TV-distance at the end of such a step
will be at most δ.
Contrapositively, in any step where the TV-distance at the start is more than δ, we will have at the
start that μ ∈ Opt(δ0). Then, it suffices to prove that the step decreases the total variation distance
additively by at least 1/Poly(C, ec2,1∕δ) in this case. For appropriate choices of constants in
expression for the step size (sufficiently small multiplicative and sufficiently large in the exponent),
this is immediately implied by Lemma 4.4 and Lemma 4.2 provided that μ*,b, b0 ∈ B(2C) and
Ibi - b21 ≥ δ at the beginning of each step. The condition that we always are within B(2C) at the
start of each step is proven in Lemma 4.6 and the condition that the means are separated (ie., that we
don,t have mode collapse) is proven in Lemma 4.5.	□
It is interesting that a critical component of the above proof involves proving explicitly that mode
collapse does not occur. This suggests the possibility that understanding mode collapse may be
helpful in understanding convergence of Generative Adversarial Models and Networks.
D.4 Proof of Lemma 4.3
In this section we prove Lemma 4.3. We first require the following fact:
Fact D.5 ((Markov, 1892)). Let p(x) = Pid=0 cjxj be a degree d polynomial so that Ip(x)I ≤ 1 for
all X ∈ [—1,1]. Then max°≤j≤d ∣c7-1 ≤ (√2+1)d. More generally, if ∣p(x)∣ ≤ α forall X ∈ [-ρ, ρ],
then max0≤j≤d IcjρjI ≤ O(α).
We also have the following, elementary lemma:
Lemma D.6. Suppose b2 > μ* for all i. Then there is some x>μ2 so that Fμ* (μ, x) < 0.
We are now ready to prove Lemma 4.3
ProofofLemma 4.3. We proceed by case analysis on the arrangement of the μ and μ*.
Case 1: μ1 < bi and μ2 < μ2 In this case we have Fμ*(b, x) ≤ 0 for all X ≥ b2. Hence the
optimal discriminators are both to the left of μ2. Moreover, by a symmetric logic we have
Fμ*(b, x) ≥ 0 for all X ≤ μ↑, so the optimal discriminator has an interval of the form
Ii = [-∞, ri] and possibly I2 = [l2,r2] where ri <l2 <r2 < b2. Then it is easy to see
that 盟(b2) ≥ √2∏2/ ≥ √2∏e-2C2.
Case 2:	bi < μi and b2 < μ2 This case is symmetric to Case (1).
Case 3:	μi < μ↑ < μ2> < b2 By Lemma D.6, we know that Fμ*(μ, x) < 0 for some X ≥ b2, and
similarly Fμ*(b, x) < 0 for some X ≤ μi. Since clearly F(μ*)(b, x) > 0 for X ∈ [μ;,μg],
by Theorem B.2 and continuity, the optimal discriminator has one interval. Denote it by
I = [', r], so that we have ' ≤ μi and r ≥ μ2. Suppose ' ≥ bi. Then
∂f-(bi) =$(e-@-')2/2—e-@-r)2/2)
∂μbi	2π
=1 e-(μι-')2/2 (1 _ e-(μι-')(r-')e—(r-')2∕2∖
e	e	e
√2∏	V	/
≥ √⅛e-2C2 (1 —i2).
We get the symmetric bound on f^ (b2) if r ≤ b2. The final case is if ' <μi < b2 < r.
Consider the auxiliary function
H(μ) = e-('-μ)2∕2 — e-(r-μ)2/2 .
15
Under review as a conference paper at ICLR 2018
On the domain [', r], this function is monotone decreasing. Moreover, for any μ ∈ [', r], We
have
H0(μ) = (' - μ)e-(~~μ)/ - (r - μ)e-(r-*)2/2
≤ - r — ' e-(r-')2∕8
-	2
≤ -Ye-Y2∕8 .
_	2
In particular, this implies that H(bi) < H(&)— γ2e-γ2∕8∕2, so at least one of H(&)or
H (bi) must be γ2e-γ38∕4 in absolute value. Since d∂fμɪ (R) = H (bi), this completes the
proof in this case.
Case 4:	μ^ < μι < μ2 < μ2> By a symmetric argument to Case 3, we know that the optimal dis-
criminator intervals are of the form (一∞, r] and [', ∞) for some r < bi < μ2 < '. The
form of the derivative is then exactly the same as in the last sub-case in Case 3 with signs
reversed, so the same bound holds here.
□
D.5 Proof of Lemma 4.4
We now seek to prove Lemma 4.4. Before we do so, we need to get lower bounds on derivatives of
finite sums of Gaussians with the same variance. In particular, we first show:
Lemma D.7. Fix γ ≥ δ > 0 and C ≥ 1. Suppose we have μ2 , μb ∈ B(C), μ2 , μb ∈ Sep(γ), with
μb 6∈ Rect(δ), where all these vectors have constant length k. Then, for any x ∈ [-C, C], we have
that | dχiFμ*(μ, x)| ≥ Ω⑴∙ (δ∕C)O(1)e-C2/2 for some i = 0,..., 2k — L
Proof. Observe that the value of the ith derivative of Fμ* (μb, x) for any X is given by
di	1	2k
dχiFμ* (μ,x) = √2^ X Wj( - 1yHi(Zj)e-zj/2 ,
π j=i
where wj ∈ {-1∕k, 1∕k}, the zj is either x - μj2 or x - μbj, and Hi(z) is the ith (probabilist’s)
Hermite polynomial. Note that the (-1)i Hi are orthogonal with respect to the Gaussian measure
over R, and are orthonormal after some finite scaling that depends only on i and is therefore
constant. Hence, if we form the matrix Mij = (-1)iHi(x — Zj), if we define Ui = 躲Fμ* (μb, x) for
i = 0,..., 2k 一 1, we have that Mv = u, where Vj = -1= Wje-(X-Zj)2/2. By assumption, we have
IlvIl2 ≥ Ω(√k ∙ e-C2/2) = Ω(e-C2/2). Thus, to show that some Ui cannot be too small, it suffices
to show a lower bound on the smallest singular value of M. To do so, we leverage the following fact,
implicit in the arguments of (Gautschi, 1990):
Theorem D.8 ((Gautschi, 1990)). Let pr (Z) be family of orthonormal polynomials with respect to a
positive measure dσ on the real line for r = 1, 2, . . . , t and let Zi, . . . , Zt be arbitrary real numbers
with Zi 6= Zj for i 6= j. Define the matrix V given by Vij = pi (Zj ). Then, the smallest singular value
ofV, denoted σt(V ), is at least
σmin (V )
t	-i/2
X `r (y)2dσ(y)
r=i
where 'r(y) = Ils=r ZyU is the Langrange interpolating Polynomialfor the Zr.
Set pr = Hr-i t = 2k, and σ as the Gaussian measure; then apply the theorem. Observe that for any
i, j, we have |Zi - Zj| ≥ min(δ, γ) ≥ δ and |Zi| ≤ C. Hence the largest coefficient of any Lagrange
interpolating polynomial through the Zi is at most (C)2k-i with degree 2k _ 1. So, the square of
16
Under review as a conference paper at ICLR 2018
any such polynomial has degree at most 2(2k - 1) and max coefficient at most 2k( C )2(2kT) This
implies that
2k	2k
J X'r(y)2 dσ(y)= XJ 'r(y)2 dσ(y)
≤
2k	C
∑2(2k - 1) ∙ 2kU
r=1
2(2k-1)
max	ysdσ(y)
s∈[2(2k-1)] R
≤
O ⑴∙( C )	max
δ	s∈[4k]
O(1)
∞ yse-y2/2 dy
-∞
。⑴,仔
≤
Hence by Theorem D.8 we have that σmin(V) ≥ Ω(1) ∙ (C)O(1). Therefore, Wehavethatkuk2 ≥
Ω(1) ∙ (δ∕C)o(I)e-C2/2, which immediately implies the desired statement.	□
We next shoW that the above Lemma can be slightly generalized, so that We can replace the condition
b ∈ Rect(δ) with μ ∈ Opt(δ).
Lemma D.9. Fix C ≥ 1 ≥ Y ≥ δ ≥ Ξ > 0. Suppose we have μ*,b ∈ B(C), μ*,μ ∈ SeP(Y), with
b ∈ Opt(δ). Thenfor any X ∈ [—C, C], we have that | 备Fμ* (b,x)∣ ≥ Ω(1) ∙ (δe-C2/C)O⑴ for
some i = 0, . . . , 3.
Proof. Let Ξ be of the form Ω(1) ∙ (δe-C2/C)O(1), where we will pick its precise value later.
Lemma D.7 with δ in that Lemma set to Ξ and k = 2 proves the special case when μ ∈ Rect(Ξ).
Thus, the only remaining case is when bi is close to μ* for some i and far away for the other i.
Without loss of generality, we assume the first entries are the close pair. Then we have ∣bι - μ↑∖ ≤ Ξ
and ∣b2 - μ2l ≥ δ.
There are four terms in the expression for 条 Fμ* (b, x) corresponding to each of μι ,μ2,μ1,μ2.
Lemma D.7 with δ = Ξ and k
1 implies that the contribution of the μ2 and μ2 terms to at
least one of the 0th through 3rd derivatives has magnitude at least Ω(1) ∙ (δe-C2/C)O(1). FactD.2
and Lemma D.10 (below) imply that the contribution of the bi and μ2 terms to these derivatives
has magnitude at most 0(1) ∙ Ξ4. Thus, there exists a Ξ = Ω(1) ∙ (δ∕C)O(1)e-C2/2 such that the
magnitude of the contribution of these second two terms is less than half that of the first two, which
gives a lower bound on the magnitude of the sum of all the terms of Ω(1) ∙ (δ∕C)O(1)e-C2/2. □
We now show that any function which always has at least one large enough derivative—including its
0th derivaive—on some large enough interval must have a nontrivial amount of mass on the interval.
Lemma D.10. Let 0 < ξ < 1 and t ∈ N. Let F(x) : R → R be a (t + 1)-times differentiable
function such that at every point x on some interval I of length |I| ≥ ξ, F(x) ≥ 0 and there exists
an i = i(x) ∈ 0,...,t such that |名F(x)| ≥ B0 for some B0. Also suppose |ddt++rF(x)| ≤ B for
some B. Then,
F (x)dx ≥
B0 ∙ (Ω(1) ∙ ξ)t+i ∙ min[(B0∕B)t+2,1]
(t + 1)! ∙ (t + 1)
Proof. Let 0 < a < 1 be a non-constant whose value we will choose later. If I has length more
than aξ, truncate it to have this length. Let z denote the midpoint of I . By assumption, we know
i
that there is some i ∈ 0,...,t such that |备F(x)| > ξ. Thus, by Taylor,s theorem, we have that
F(b, x) ≥ p(χ - z) - (B∕(t + 1)!) ∙ |x - z∣t+i for some degree t polynomial P that has some
coefficient of magnitude at least B0/t!.
Thus, if we let G(y) = zy p(x)dx, then G(y) is a degree t + 1 polynomial with some coefficient
which is at least B0∕(t! ∙ t). By the nonnegativity of F on I, we have that G is nonnegative on
17
Under review as a conference paper at ICLR 2018
[-aξ∕2, aξ∕2]. By this and the contrapositive of Fact D.5 (invoked with α set to a sufficiently
small nonzero constant multiple of B), we have for some such y and some constant B 00 > 0 that
G(y) = |G(y)| ≥ B"(∣I∣∕2)t+1B0∕(t! ∙ t). Therefore, at this point, we have
yF(x)dx≥G(y)- y
zz
(B∕(t + 1)!) ∙ |x — z∣t+1dx
B00at+1(ξ∕2)t+1B0	B(aξ∕2)t+2
-------：--------- -------.-:------
t!∙t------------(t +1)!∙(t + 1)
(at+1(ξ∕2)t+1(B00B0- Bξa∕2) A
1	(t +1)!∙(t +1)	)
(at+1(ξ∕2)t+1(B00B0 - Ba∕2) )
(	(t +1)!∙(t +1)	. ■
If B0B00 ≤ B, we set a = B0B00∕B ≤ 1 which gives
yF(x)
z
dx ≥
((B0)t+2(Ω⑴∙ξ∕B)t+1 A
I	(t + 1)!∙(t +1)广
Otherwise, B0B00 ≥ B and we perform this substitution along with a = 1 which gives the similar
bound
F (x)dx ≥
(B0(Ω(1) ∙ξ)t+1 A
k(t + 1)!∙(t +1)广
Together, these bounds imply that we always have
F (x)dx ≥
z
B0 ∙ (Ω(1) ∙ ξ)t+1 ∙ min[(B0∕B)t+2,1]
(t + 1)! ∙ (t + 1)
This allows us to prove the following lemma, which lower bounds how much mass F can put on any
interval which is moderately large. Formally:
Lemma D.11. Fix C ≥ 1 ≥ Y ≥ δ > 0. Let K = Ω(1) ∙ (δe-C2∕C)O⑴ be the K for which
Lemma 4.3 is always true with those parameters. Let μ*, μ be so that b ∈ Opt(δ), b, μ* ∈ SeP(Y),
and μ*,b ∈ B(C). Then, there is a ξ = Ω(1) ∙ (δ∕C )O(I)e-C2 )O ⑴ Such that for any interval I of
length |I| ≥ ξ which satisfies I ∩ [-C — 2plog(100∕K), C + 2plog(100∕K)] = 0 and on which
F(b, x) is nonnegative, we have
∕∣f (b,χ)l
dx ≥ Ω(1) ∙ (δe-C2
∕C)O(1)ξO(1)
□
Proof. By Lemma D.9 with C in that lemma set to C + 2,log(100∕K), we get a lower bound of
Ω(1) ∙ (δe-C2 ∕C)O(I) on the magnitude of at least one of the 0th through 3rd derivatives of F(b, x)
with respect to x. Set ξ equal to a sufficiently small (nonzero) constant times this value.
By Fact D.1 there exists a constant B such that the magnitude of the fifth derivative of F(b, x) with
respect to x—which is a linear combination of four fifth derivatives of Gaussians with constant
coefficients—is at most B .
By Lemma D.10 applied to F(b, x) as a function of x, we have JI F(b, x)dx ≥ Ω(1) ∙ ξ6.	□
Now we can prove Lemma 4.4.
ProofofLemma 4.4. Let A = [C - 2,log(100∕K), C + 2,log(100∕K)] where K = Ω(1) ∙
(δe-C2 ∕C)O(1) is the K for which Lemma 4.3 is always true with those parameters.
18
Under review as a conference paper at ICLR 2018
Let Z± denote the set of all X ∈ A for which F(b0, x) and F(μ, x) have different nonzero signs.
Let Z+ denote the subset of Z± where F(b0, x) > 0 > F(b, x) and Z- denote the subset where
F(b0, x) < 0 < b, x). Then Z± = Z+ ∪ Z- and Z+, Z- are disjoint and Lebesgue-measurable. If
Vol(Z+) ≤ Vol(Z-), switch b and μ0 so that Vol(Z+) ≥ Vol(Z-).
Note that Z+ can be obtained by making cuts in the real line at the zeros of F(b0, x), F(b, x), and
F(b0, x) - F(b, x), then taking the union of some subset of the open intervals induced by these cuts.
By Theorem B.2, the total number of such intervals is O(1). Thus, Z+ is the union of a constant
number of open intervals. By similar arguments, Z- is also the union of a constant number of open
intervals.
We now prove that vol(Z +),ZT ≤ O(1) ∙ ∣∣b0 - bk：(1) ∙ (δe-C2/C)-O⑴.Since vol(Z+) ≥
vol(Z-),it suffices to prove vol(Z+) ≤ O(1) ∙ ∣μ0 — b|『(1) ∙ (δe-C2/C)-O⑴.Note also that by
Lemma D.2, each of these intervals has mass under F(b0, x) at most JR |F(b0, x) - F(b, x) |dx ≤
O(1) ∙ kb0 - μ∣ι. By Lemma D.11 and Lemma 4.3, each of these intervals has length at most
O(1) ∙ kb0 - b∣∣θ(1) ∙ (δe-C2/C)-O⑴.Since there are at most a constant number of such intervals,
this is also a bound on Vol(Z+) (and Vol(Z-)).
Let Y denote the set of X ∈ A on which both F(b, x) and F(b0, x) are nonnegative. Let X, X0
denote the x ∈ A for which F(b,x) and F(b0,x) are respectively positive. Let W, W0 denote,
respectively, the sets of endpoints of the union of the optimal discriminators for b, b0. Then the union
of the optimal discriminators for b, b0 are respectively Y ∪ Z- ∪ X ∪ W and Y ∪ Z+ ∪ X0 ∪ W0.
Furthermore, each of these two unions is given by some constant number of closed intervals and
more specifically, that X, X0 each contain at most two intervals by Lemma B.2. Thus, we have for
any i that
∂⅛…口
=	d，e(X-K)2/2dx - d ≠e(X-Gi)2/2dx
dx	dx
Y ∪Z+∪W0∪X0	Y ∪Z- ∪W∪X
≤	Z d-e(X-禹产/2dx - Z d-e(Xfi)2/2dx
dx	dx
Y ∪Z+∪W0∪X0	Y ∪Z- ∪W∪X
+ O(1) ∙∣bi -词,
19
Under review as a conference paper at ICLR 2018
by Lipschitzness, and so
∂d-TV(μ*,b) 口
dμi	∣μ I
= Z d-e(x-bi尸/2dx - Z d-e(x-μi尸/2dx
I	dx	dx
IZ+∪X0	Z-∪X
+。⑴∙∣bi - bi I
≤	/ -de(x-μi)2/2dx ± 4— ∙ K - d -de(x-b)2/2dx ± 4— ∙ K
J dx	100 J dx	100
I Z+	Z-
+。⑴∙∣bi- bi I
≤ Z — e(x-/)2/2dx
I	dx
Z+
/ 色e(Xii)2/2dx
I dx
Z-
8
+100 ∙ K + o⑴∙ lμi - bi|
≤ 2vol(Z+) sup -de(X-μi)2/2 +-8- ∙ K + O⑴∙∣bi -词
Ix∈R dx	I 100	i
≤。⑴∙ kb0 - bk?(I) ∙ (δe-C2/C)-O⑴ + 熹∙ K.
This bound also upper bounds ∣∣Vfμ* (μ0) - ▽/** (b)∣∣2 UP to a constant factor. Thus, if We choose
our step to have magnitude ∣∣μ0 - b∣2 ≤ Ω(1) ∙ (δe-C /C)o(I) with appropriate choices of constants,
We get
kVfμ*(b0) -Vfμ*(b)∣∣2 ≤ K/2 ≤ kVfμ*(b)k2∕2 ,
as claimed	口
D.6 Proof of Lemma 4.5
We now prove Lemma 3.4, which forbids mode collapse.
ProofofLemma 4.5. Since η ≤ δ, if ∣bι - b2∣ > 2δ then clearly b0 ∈ Sep(δ), since the gradient is
at most a constant since the function is Lipschitz. Thus assume WLOG that ∣bι - b21 ≤ 2δ ≤ γ∕50.
There are now six cases:
Case 1:	bi ≤ μ1 ≤ μ2) ≤ b2 This case cannot happen since we assume ∣bι - b2∣ ≤ 2δ ≤ γ∕50.
Case 2:	μ1 ≤ bi ≤ b2 ≤ μ2 In this case, by Lemma D.6, we know F is negative at -∞ and at +∞.
Since clearly F ≥ 0 when X ∈ [μ2,μ2], by Theorem B.2 and continuity, the discriminator
intervals must be of the form (-∞, r], [', ∞) for some r ≤ bi ≤ b2 ≤ '. Thus, the update
to bi is (up to a constant factor of √2π) given by e-('-μi)2/2 - e-(r-bi)2/2. The function
Q(X) = e-('-X)2/2 - e-(r-X)2/2 is monotone on X ∈ [r,'], and thus bi must actually move
away from each other in this scenario.
Case 3: μ2 ≤ bi ≤ μ2 ≤ b2 In this case we must have ∣μ2 - bi ∣ ≤ 2δ and similarly ∣μ2 - b2∣ ≤ 2δ.
We claim that in this case, the discriminator must be an infinitely long interval (-∞, m]
for some m ≤ bi. This is equivalent to showing that the function F(b, x) has only one
zero, and this zero occurs at some m ≤ bi. This implies the lemma in this case since then
the update to bi and b2 are then in the same direction, and moreover, the magnitude of the
update to bi is larger, by inspection.
20
Under review as a conference paper at ICLR 2018
We first claim that there are no zeros in the interval [bi, b2]. Indeed, in this interval, We
have that
√2∏Db(x) ≥ 2e-(Y/50)2/2
=2e-γ2∕5000
≥ 2 11 - γ2- + O(γ4)
≥	1	5000 + (Y )
≥ 2 I」得),
but
√2πDμ. (x) ≤ 1 + e-(γ-2δ)2/2
=I + e-(49γ∕50)2∕2
≤2-
Y
22
Hence Gμ(χ) ≥ G**(χ) for all X ∈ [b1,b2], and so there are no zeros in this interval.
Clearly there are no zeros of F when X ≥ μ2, because in that regime e-(x-μi)2/2 ≥
e-(x-**) / for i = 1,2. Similarly there are no zeros of F when X ≤ μ1. Thus all zeros of
F must occur in the interval [-μ^,bι].
We now claim that there are no zeroes of F on the interval [α + 10δ, bi], where a =
(μ: + bi)/2. Indeed, on this interval, we have
√2∏F(b, x) = e-(x-“*)2/2 - e-(χ-b2)2∕2 + e-(χ*)2/2 — e-(x-bi)2/2
≤ e-(x-μ*)2/2 - e-(x-b2)2/2 < 0
where the first line follows since moving μ2 to bi only increases the value of the function
on this interval, and the final line is negative as long as x > (μ^ + b2)/2, which is clearly
satisfied by our choice of parameters. By a similar logic (moving μ2 to μg), we get that on
the interval [μi,α - 10δ], the function is strictly positive. Thus all zeros of F must occur in
the interval [α - 10δ, α + 10δ].
We now claim that in this interval, the function F is strictly decreasing, and thus has exactly
one zero (it has at least one zero because the function changes sign). The derivative of F
with respect to X is given by
kdF ∕^、
v2π-(μ,x)
∂X
=(〃；-x)e-(x-"*)2/2 - (b2 - x)e-(x-b2)2/
+ (μ2, - x)e-(x-"*)2/2 - (b2 - x)e-(x-bbl)2/2 .
By Taylor’s theorem, we have
(〃；-x)e-(x-"*)2/2 - (b2 - x)e-(x-μb2)2/2
=-2re-α2/2 + O (H2(δ)e-(r-i0δ)32δ2),
where H is the second (probabilist's) Hermite polynomial, and r = ∣μ^ - α∣. Onthe other
hand, by another application of Taylor’s theorem, we also have
(μ2 - x)e-(x-"*)2/ - (b2 - x)e-(x-bl)2/2
=O (δH2(δ)e-(r-i0δ)32).
21
Under review as a conference paper at ICLR 2018
Thus, altogether we have
kdF ∕^、
v2π-(μ,x)
∂x
≤ -2re-a2/2
+ O (δH2(δ)e-(r-10δ)2/2)
<0
by our choice of δ, and since r = γ∕2 >δ∕25.
Case 4:	μι	≤ μ↑ ≤ μ2	≤	μ2>	This Case is symmetric to Case 3, and so We omit it.
Case 5:	μ2	≤ μ2 ≤ μι	≤	b2	In this case, We proceed as in the proof of Theorem	B.2. If the
Gaussians Were sufficiently skinny, then by the same logic as in the proof of Theorem B.2,
there is exactly one zero crossing. The lemma then folloWs in this case by Theorem B.1.
Case 6:	μι ≤ μ2 ≤ μ2 ≤ μ2 ThiS CaSe is symmetric to Case 5.
This completes the proof.	□
D.7 Proof of Lemma 4.6
We also shoW that no terribly divergent behavior can occur. Formally, We shoW that if the true means
are Within some bounded box, then the generators Will never leave a slightly larger box.
ProofofLemma 4.6. If μ ∈ B(C), then since f is Lipschitz and η is sufficiently small, clearly
μ0 ∈ B(C). Thus, assume that there is an i = 1, 2 so that ∣μbi∣ > C, and let μι be the largest such i
in magnitude. WLOG take μ2 > 0. In particular, this implies that μ2 > μ↑ for all i = 1,2. There are
now 3 cases, depending on the position of μι.
Case 1:	μι ≥ μ2: Here, as in Case 2 in Lemma 4.5,the optimal discriminator is of the form (-∞, r]
for some r ≤ Rι,b¾. In particular, the update step will be
μi = bi - ηe-(r-bi)2/2 < bi.
Thus, in this case our update moves us in the negative direction. By our choice of η, this
implies that 0 ≤ 竭 < b¾∙ Moreover, since bi ≥ μ2, this implies that ∣μb2∣ ≤ C, and thus
|bi| ≤ 2C. Therefore in this case we stay within the box.
Case 2:	μ2 ≤ bi ≤ μ2: AS in Case 1, we know that μι cannot leave the box after a single update, as
|bi | ≤ C. Thus it suffices to show that μ2 moves in the negative direction. By Lemma D.6,
we know there is a discriminator interval at -∞, and there is no discriminator interval at ∞.
Moreover, in this case, we know that F(μ, x) ≥ 0 for all X ≥ 讪 Thus, all discriminators
must be to the left of M Therefore, the update to b is given by
0
b = μ2
-η (e-(r2-b2)2/2 - e-('2-μ2)2∕2 + e-(n-μ2)2∕2),
for some ri ≤ '2 ≤ r? ≤ R2∙ Clearly this update has the property that 0 ≤ μ2 < b2, and so
the new iterate stays within the box.
Case 3:	μι ≤ μ2 In this case we must prove that neither bi nor b leave the box. The two arguments
are symmetric, so we will focus on μb2. Since η is small, we may assume that b2 > 3C∕2, as
otherwise μ2 cannot leave the box. As in Case 1, it suffices to show that the endpoints of the
discriminator intervals are all less than μb2. But in this case, we have that for all X ≥ b2, the
value of the true distribution at x is at most 2e-(x-C)2 /2, and the value of the discriminator
is at e-(x-b2)2/2 ≥ e-(x-1.5C)2/2. By direct calculation, this is satisfied for any choice of
C satisfying 2e5C2 /8 < e3C2 /4, which is satisfied for C ≥ 3.
□
22
Under review as a conference paper at ICLR 2018
E Single Gaussian
Although our proof of the two Gaussian case implies the single Gaussian case, it is possible to
prove the single Gaussian case in a somewhat simpler fashion, while still illustrating several of the
high-level components of the overall proof structure. Therefore, we sketch how to do so, in hopes
that it provides additional intuition for the proof for a mixture of two Gaussians.
In order to prove convergence, we can use the following.
1.	The fact that the gradient is only discontinuous on a measure 0 set of points.
2.	An absolute lower bound on the magnitude of the gradient from below over all points that
are not close to the optimal solution that we might encounter over the course of the algorithm
3.	An upper bound on how much the gradient can change if we move a certain distance.
Then, as long as we take steps that are small enough to guarantee that the gradient never changes by
more than half the absolute lower bound, we will get by Lemma 4.2 that we always make progress
towards the optimum solution in function value unless we are already close to the optimal solution.
The proof of these facts is substantially simplified in the single Gaussian case. Suppose we have a true
univariate GaUssian distribution with unit variance and mean μ*, along with a generator distribution
with unit variance and mean μ. Then the optimal discriminator for this pair of distributions starts
at the midpoint between their means and goes in the direction of the true distribution off to ∞ or
-∞. Therefore, unless the generator mean is within one step length of the true mean, it cannot
move away from the true mean. One can also argue that the gradient of μ with respect to the optimal
discriminator (ie., the gradient of total variation distance) is only discontinuous when μ = μ*, and
has magnitude roughly e(μ-(b+μ*)/2)2/2 for b = μ*. This implies the first two items. For the last
item, note that the midpoint ez2/2, which implies the gradient is Lipschitz as long as we are not at the
optimal solution, which gives bounds on how much the gradient can change if we move a certain
distance.
The preceding discussion implies convergence for an appropriately chosen step size, and all this can
be made fully quantitative if one works out the quantitative versions of the statements in the preceding
argument.
This analysis is simpler the the two Gaussians analysis in several respects. In particular, the proofs of
the second two items are substantially more involved and require many separate steps. For example,
in the two Gaussian case, the gradient can be 0 if mode collapse happens, so we have to directly prove
both that mode collapse does not happen and that the gradient is large if mode collapse doesn’t happen
and we aren’t too close to the optimal solution, which is a substantially more involved condition to
prove. Additionally, the gradient in the two Guassian case does not seem to be Lipschitz away from
the optimum like it is in the single Gaussian case. Instead, we will have to use a weaker condition
which is considerably more difficult to reason about. This is further complicated by the fact that the
optimal discriminators can move in a discontinuous fashion when we vary the generator means.
23