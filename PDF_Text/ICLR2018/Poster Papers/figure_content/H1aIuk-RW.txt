Figure 1: Visualization of the Theorem 1. Consider the set of selected points s and the pointsin the remainder of the dataset [n] \ s, our results shows that if s is the δs cover of the dataset,11 Pi∈[n] i(χi,yi,As) - ∣⅛ Pj∈s i(χj, y ； As)∣ ≤ o d) + OIq)Informally, given the initial labelled set (s0) and the budget (b), we are trying to find a set of pointsto query labels (s1) such that when we learn a model, the performance of the model on the labelledsubset and that on the whole dataset will be as close as possible.
Figure 2: Visualizations of the variables. Inthis solution, the 4th node is chosen as a cen-ter and nodes 0, 1, 3 are in a δ ball around it.
Figure 3:	Results on Active Learning for Weakly-Supervised Model (error bars are std-dev)CIFAR - 100CALTECH - 256SVHNCIFAR - 100 5 0 5 0 5 098 8 7 7 6 6)%( ycaruccA noitacfiissalC65'60 -55 -50 -45 -40 -35 -30-B- Random-*- EmPmcal-Unc.
Figure 4:	Results on Active Learning for Fully-Supervised Model (error bars are std-dev)We conducted experiments on active learning for fully-supervised models as well as active learning forweakly-supervised models. In our experiments, we start with small set of images sampled uniformlyat random from the dataset as an initial pool. The weakly-supervised model has access to labeledexamples as well as unlabelled examples. The fully-supervised model only has access to the labeleddata points. We run all experiments with five random initializations of the initial pool of labeled pointsand use the average classification accuracy as a metric. We plot the accuracy vs the number of labeledpoints. We also plot error bars as standard deviations. We run the query algorithm iteratively; in otherwords, We solve the discrete optimization problem minsk+-sk+ι∣≤b Eχ,y〜PZ [l(x, y; As0∪.. sk+1)]for each point on the accuracy vs number of labelled examples graph. We present the results inFigures 3 and 4.
Figure 5:	tSNE embeddings of the CIFAR datasetand behavior of uncertainty oracle as well as ourmethod. For both methods, the initial labeled poolof 1000 images are shown in blue, 1000 imageschosen to be labeled in green and remaining onesin red. Our algorithm results in queries evenlycovering the space. On the other hand, sampleschosen by uncertainty oracle fails to cover thelarge portion of the space.
Figure 6:	We compare our method with k-Center-Greedy. Our algorithm results in a small but im-portant accuracy improvement.
