Figure 1: Comparison of regular inputs, quantized inputs, and discretized inputs (16 levels, projectedto one dimension) on MNIST, adversarially trained with ε = 0.3. The x-axis represents the true pixelvalue of the image, and the y-axis represents the value that is passed as input to the network after theinput transformation has been applied. For real-valued inputs, the inputs to the network are affectedlinearly by perturbations to the input. Quantized inputs are also affected approximately linearly byperturbations where ε is greater than the bucket width. Discretizing the input, and then using learnedweights to project the discretized value back to a single scalar, we see that the model has learneda highly non-linear function to represent the input in a fashion that is effective for resisting theadversarial perturbations it has seen. When starting at the most common pixel-values for MNIST,0 and 1, any perturbation of the pixels (where ε ≤ 0.3) has barely any effect on the input to thenetwork.
Figure 2: Comparison of the convergence rate of various adversarially trained models on the SVHNdataset.
Figure 3: Loss for iterated white-box attacks on various models on a randomly chosen data pointfrom MNIST. By step 40, which is where we evaluate, the loss of the point found by iterative attackshas converged.
Figure 4: The effect of increasing the number of distinct discretization levels on the accuracy of themodel on MNIST and CIFAR-10. (4a) shows the accuracy on on MNIST for discretized modelstrained on a mix of legitimate and adversarial examples. (4b) shows the accuracy on CIFAR-10 fordiscretized models trained only on adversarial examples.
Figure 5: Comparison of the convergence rate of various adversarially trained models on theCIFAR-10 dataset. The discretized models use 16 levels per color channel. (5a) shows the ac-curacy on clean examples, while (5b) shows the accuracy on white-box PGD/LS-PGA examples, inwall-clock time.
Figure 6: Gradient norm for iterated white-box attacks on various models on a randomly chosendata point from MNIST. (6a) shows the gradient norm on discretized models as a function of stepsof LS-PGA, while (6b) shows the gradient norm on a vanilla model as a function of steps of PGD.
Figure 7: Linear extrapolation plot as in Goodfellow et al. (2014) for MNIST. (7a) shows the behav-ior of a vanilla model while (7b) for a discretized model using 16 levels and thermometer encoding.
Figure 8: Plot showing the accuracy of various adversarially trained models on MNIST with ε =0.3 (8a) and on CIFAR-10 with ε = 0.031 (8b), when attacked with increasing values of ε usingPGD/LS-PGA.
Figure 9: Church-window plots of clean-trained models on MNIST. The x-axis of each sub-plotrepresents the adversarial direction, while the y-axis represents a random orthogonal direction. Thecorrect class is represented by white. Every row in the plot contains a training data point chosenuniformly at random, while each column uses a different random orthogonal vector for the y-axis.
Figure 10: Church-window plots of adversarially-trained models on MNIST, trained on only adver-sarial examples. The x-axis of each sub-plot represents the adversarial direction, while the y-axisrepresents a random orthogonal direction. The correct class is represented by white. Every rowin the plot contains a training data point chosen uniformly at random, while each column uses adifferent random orthogonal vector for the y-axis. The ε bound for both axes is [-1.0, 1.0].
Figure 11: Church-window plots of adversarially-trained models on MNIST, trained using a mixof clean and adversarial examples. The x-axis of each sub-plot represents the adversarial direction,while the y-axis represents a random orthogonal direction. The correct class is represented by white.
Figure 12: Church-window plots of clean-trained models on CIFAR-10. The x-axis of each sub-plotrepresents the adversarial direction, while the y-axis represents a random orthogonal direction. Thecorrect class is represented by white. Every row in the plot contains a training data point chosenuniformly at random, while each column uses a different random orthogonal vector for the y-axis.
Figure 13: Church-window plots of adversarially-trained models on CIFAR-10, trained on onlyadversarial examples. The x-axis of each sub-plot represents the adversarial direction, while they-axis represents a random orthogonal direction. The correct class is represented by white. Everyrow in the plot contains a training data point chosen uniformly at random, while each column uses adifferent random orthogonal vector for the y-axis. The ε bound for both axes is [-1.0, 1.0].
Figure 14: Church-window plots of adversarially-trained models on CIFAR-10, trained using a mixof clean and adversarial examples. The x-axis of each sub-plot represents the adversarial direction,while the y-axis represents a random orthogonal direction. The correct class is represented by white.
