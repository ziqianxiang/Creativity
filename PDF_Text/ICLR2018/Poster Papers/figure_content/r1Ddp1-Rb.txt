Figure 1: Illustration of mixup, which converges to ERM as α → 0.
Figure 2: mixup leads to more robust model behaviors in-between the training data.
Figure 3:	Test errors for ERM and mixup on the CIFAR experiments.
Figure 4:	Classification errors of ERM and mixup on the Google commands dataset.
Figure 5: Effect of mixup on stabilizing GAN training at iterations 10, 100, 1000, 10000, and 20000.
