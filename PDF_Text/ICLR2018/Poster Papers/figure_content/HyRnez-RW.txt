Figure 1: Example from TriviaQA in which multiple mentions contain information that is usefulin inferring the answer. Only the italicized phrase completely answers the question (Krasner couldhave married multiple times) but contains complex coreference that is beyond the scope of currentnatural language processing. The last phrase is more easy to interpret but it misses the clue providedby the year 1945.
Figure 2: Cascaded model for reading comprehension. Input vectors are shown in green. Yellowrounded squares with dotted borders correspond to attention computation and attended vectors areshown in yellow. Submodels are shown in rounded squares with solid borders and the correspondingobjectives are shown in color-coded circles. Level 1 submodels are in grey, level 2 in red and level 3in blue. The ffnn operator is shown by the cross symbol within each submodel. The final objective,shown in the top black circle, is a linear interpolation of submodel objectives.
Figure 3: Analysis of model predictions. Left: Performance of the top k predictions of differentmodels on the human-validated Wikipedia development set. Right: Effect of truncation on perfor-mance. Oracle indicates the maximum possible performance for that truncation level.
Figure 4: Left: Distribution of answer frequencies in the document, for model predictions (blue),correct model predictions (green) and true answers (orange). Right: Speedup ratio of our approachcompared to a vanilla biLSTM that predicts start/end positions independently. As the documentlength increases, our approach can better take advantage of GPU parallelization.
