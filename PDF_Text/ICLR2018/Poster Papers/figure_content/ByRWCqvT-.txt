Figure 1: Overview of the transfer scheme with a learnable clustering objective (LCO). The LCOand pairwise similarity are the two key components of our approach and are described in section 4.
Figure 2: The concept for reconstructing clusters of unseen categories. The proposed approachfollows the arrows in the counter-clockwise direction, which converts cross-task transfer learning tocross-domain transfer learning. The colors of dots represent data of different categories. The hollowcircle and cross symbol represent similar and dissimilar data pairs. The G function and the clusterreconstruction (via constrained clustering) are the two key components in the diagram.
Figure 3: The similarity prediction network (the G function).
Figure 4: The constrained clustering network (CCN) for transfer learning across tasks. The input isunlabeled target data T . The cluster assignment block contains two fully connected layers and hasthe number of output nodes equal to k. The f described in section 4 is the backbone network plusthe cluster assignment block. To optimize LCO, the full pipeline in the diagram is used. After theoptimization, it uses another forward propagation with only f to obtain the final cluster assignment.
Figure 5: The network for transfer learning across domains. The input is the mix of S0 and T . Thearchitecture is a direct extension of CCN. We use CCN+ to represent the mandatory parts (upperbranch) which implements eq. (7). CCN++ includes the domain adaptation method (optional branch).
Figure 6: A diagram depicting the cross-task transfer experiment. TWo experiments follow this flow:Omniglotbg to OmniglOteval, and ImageNet882 to ImageNetng. Both have exclusive classesbetween source and target domain. In the ImageNet experiment, the backbone network is initializedwith the weights pre-trained with ImageNet882.
Figure 7: Comparison between domain adaptation approaches (a) Transferring semantic similarityfrom auxiliary data (our method), and (b) Minimizing the domain discrepancy. The diagram usesoffice-31 benchmark as the scenario of transferring.
Figure 8: The clustering performance with different pairwise density and number of clusters. A brightcolor means that the NMI score is close to 1 while black corresponds to 0. The density is definedas a ratio compared to the total number of pair-wise combinations in a mini-batch. The number ofclusters defines the final softmax output dimensionality. In each sub-figure, we show how the scoreschange w.r.t. the similar pair recall and dissimiliar pair recall.
