Figure 1: Consider a setup where the aim is to learn aclassifier to distinguish between two previously unseenclasses, goldfish and shark, given not only labeledexamples of these two classes, but also a larger poolof unlabeled examples, some of which may belong toone of these two classes of interest. In this work weaim to move a step closer to this more natural learningframework by incorporating in our learning episodesunlabeled data from the classes we aim to learn repre-sentations for (shown with dashed red borders) as wellas from distractor classes .
Figure 2: Example of the semi-supervised few-shot learning setup. Training involves iterating through trainingepisodes, consisting of a support set S, an unlabeled set R, and a query set Q. The goal is to use the labeleditems (shown with their numeric class label) in S and the unlabeled items in R within each episode to generalizeto good performance on the corresponding query set. The unlabeled items in R may either be pertinent to theclasses we are considering (shown above with green plus signs) or they may be distractor items which belongto a class that is not relevant to the current episode (shown with red minus signs). However note that the modeldoes not actually have ground truth information as to whether each unlabeled example is a distractor or not; theplus/minus signs are shown only for illustrative purposes. At test time, we are given new episodes consistingof novel classes not seen during training that we use to evaluate the meta-learning method.
Figure 3: Left: The prototypes are initialized based on the meanlocation of the examples of the corresponding class, as in ordinaryPrototypical Networks. Support, unlabeled, and query examples havesolid, dashed, and white colored borders respectively. Right: The refinedprototypes obtained by incorporating the unlabeled examples, whichclassifies all query examples correctly.
Figure 4: Model Performance on ∕7ere^ImageNet With different numbers of unlabeled items during test time.
Figure 5: Hierarchy of 庇Wdlmagenet categories. Training categories are highlighted in red and test categories in blue. Each category indicates the number of associated classesfrom ILSVRC-12. Best viewed zoomed-in on electronic version.
Figure 6: Model Performance on tieredImageNet With different number of unlabeled items during test time.
Figure 7: Mask values predicted by masked soft k-means on Omniglot.
