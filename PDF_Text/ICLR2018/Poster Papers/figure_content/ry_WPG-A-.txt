Figure 1: Information plane dynamics and neural nonlinearities. (A) Replication of Shwartz-Ziv &Tishby (2017) for a network with tanh nonlinearities (except for the final classification layer whichcontains two sigmoidal neurons). The x-axis plots information between each layer and the input,while the y-axis plots information between each layer and the output. The color scale indicatestraining time in epochs. Each of the six layers produces a curve in the information plane with theinput layer at far right, output layer at the far left. Different layers at the same epoch are connectedby fine lines. (B) Information plane dynamics with ReLU nonlinearities (except for the final layerof 2 sigmoidal neurons). Here no compression phase is visible in the ReLU layers. For learningcurves of both networks, see Appendix A. (C) Information plane dynamics for a tanh network ofsize 784 - 1024 - 20 - 20 - 20 - 10 trained on MNIST, estimated using the non-parametric kerneldensity mutual information estimator of Kolchinsky & Tracey (2017); Kolchinsky et al. (2017),no compression is observed except in the final classification layer with sigmoidal neurons. SeeAppendix B for the KDE MI method applied to the original Tishby dataset; additional results usinga second popular nonparametric k-NN-based method (Kraskov et al., 2004); and results for otherneural nonlinearities.
Figure 2: Nonlinear compression in a minimal model. (A) A three neuron nonlinear network whichreceives Gaussian inputs x, multiplies by weight wι, and maps through neural nonlinearity f (∙)to produce hidden unit activity h. (B) The continuous activity h is binned into a discrete variableT for the purpose of calculating mutual information. Blue: continuous tanh nonlinear activationfunction. Grey: Bin borders for 30 bins evenly spaced between -1 and 1. Because of the saturationin the sigmoid, a wide range of large magnitude net input values map to the same bin. (C) Mutualinformation with the input as a function of weight size w1 for a tanh nonlinearity. Informationincreases for small w1 and then decreases for large w1 as all inputs land in one of the two binscorresponding to the saturation regions. (D) Mutual information with the input for the ReLUnonlinearity increases without bound. Half of all inputs land in the bin corresponding to zero activity,while the other half have information that scales with the size of the weights.
Figure 3: Generalization and information plane dynamics in deep linear networks. (A) A linearteacher network generates a dataset by passing Gaussian inputs X through its weights and addingnoise. (B) A deep linear student network is trained on the dataset (here the network has 1 hiddenlayer to allow comparison with Fig. 4A, see Supplementary Figure 18 for a deeper network). (C)Training and testing error over time. (D) Information plane dynamics. No compression is observed.
Figure 4: Overtraining and information plane dynamics. (A) Average training and test mean squareerror for a deep linear network trained with SGD. Overtraining is substantial. Other parameters: Ni =100, P = 100, Number of hidden units = 100, Batch size = 5 (B) Information plane dynamics. Nocompression is observed, and information about the labels is lost during overtraining. (C) Averagetrain and test accuracy (% correct) for nonlinear tanh networks exhibiting modest overfitting (N = 8).
Figure 5: Stochastic training and the information plane. (A) tanh network trained with SGD. (B) tanhnetwork trained with BGD. (C) ReLU network trained with SGD. (D) ReLU network trained withBGD. Both random and non-random training procedures show similar information plane dynamics.
Figure 6: Simultaneous fitting and compression. (A) For a task with a large task-irrelevant subspacein the input, a linear network shows no overall compression of information about the input. (B)The information with the task-relevant subspace increases robustly over training. (C) However, theinformation specifically about the task-irrelevant subspace does compress after initially growing asthe network is trained.
Figure 7: Learning curves for (A) tanh neural network in 1 A and (B) ReLU neural network in 1 B.
Figure 8: Information plane dynamics for the network architecture and training dataset of Shwartz-Ziv & Tishby (2017), estimated with the nonparametric KDE method of Kolchinsky & Tracey(2017); Kolchinsky et al. (2017) and averaged over 50 repetitions. (A) tanh neural network layersshow compression. (B) ReLU neural network layers show no compression. (C) The soft-signactivation function, a double-saturating nonlinearity that saturates more gently than tanh, showsmodest compression. (D) The soft-plus activation function, a smoothed version of the ReLU, exhibitsno compression. Hence double-saturating nonlinearities exhibit the compression effect while single-saturating nonlinearities do not.
Figure 9:	Detailed tanh activation function results on MNIST. Row 1: Loss over training. Row2: Upper and lower bounds for the mutual information I(X; T ) between the input (X) and eachlayer’s activity (T ), using the nonparametric KDE estimator (Kolchinsky & Tracey, 2017; Kolchinskyet al., 2017). Dotted line indicates H(X) = log2 10000, the entropy of a uniform distribution over10,000 testing samples. Row 3: Binning-based estimate of the mutual information I(X; T ), witheach neuron’s activity discretized using a bin size of 0.5. Row 4: Gradient SNR and weight normdynamics. The gradient SNR shows a phase transition during training, and the norm of the weights ineach layer increases.
Figure 10:	Detailed ReLU activation function results on MNIST. Row 1: Loss over training. Row2: Upper and lower bounds for the mutual information I(X; T ) between the input (X) and eachlayer’s activity (T ), using the nonparametric KDE estimator (Kolchinsky & Tracey, 2017; Kolchinskyet al., 2017). Dotted line indicates H(X) = log2 10000, the entropy of a uniform distribution over10,000 testing samples. Row 3: Binning-based estimate of the mutual information I(X; T ), witheach neuron’s activity discretized using a bin size of 0.5. Row 4: Gradient SNR and weight normdynamics. The gradient SNR shows a phase transition during training, and the norm of the weights ineach layer increases. Importantly, this phase transition occurs despite a lack of compression in theReLU network, indicating that noise in SGD updates does not yield compression in this setting.
Figure 11: Alternative activation functions.
Figure 12: Entropy dynamics over training for the network architecture and training dataset ofShwartz-Ziv & Tishby (2017), estimated with the nonparametric k-nearest-neighbor-based method ofKraskov et al. (2004). Here the x-axis is epochs of training time, and the y-axis plots the entropy ofthe hidden representation, as calculated using nearest-neighbor distances. Note that in this setting, ifT is considered to be the hidden activity plus independent noise, the entropy is equal to the mutualinformation up to a constant (see derivation in text). Layers 0-4 correspond to the hidden layers ofsize 10-7-5-4-3. (A) tanh neural network layers can show compression over the course of training.
Figure 13: Effect of binning strategy on minimal three neuron model. Mutual information for thesimple three neuron model shown in Fig. 2 with bin edges bi ∈ tanh(linspace(-50, 50, N)). Incontrast to linear binning, the mutual information continues to increase as weights grow.
Figure 14: Effect of binning strategy on information plane dynamics. Results for the same tanhnetwork and training regime as 1A, but with bin edges bi ∈ tanh(linspace(-50, 50, N)). Measuredwith this binning structure, there is no compression in most layers.
Figure 15: Effect of binning at full machine precision. (A) ReLU network. (B) tanh network.
Figure 16: Histogram of neural activities in a tanh network during training. The final three layerseventually saturate in the top and bottom bins corresponding to the saturation limits of the tanhactivation function, explaining the compression observed in tanh. x-axis: training time in epochs.
Figure 17: Histogram of neural activities in a ReLU network during training. ReLU layers 1-5 havea roughly constant fraction of activities at zero, corresponding to instances where the ReLU is off;the nonzero activities disperse over the course of training without bound, yielding higher entropydistributions. The sigmoid output layer 6 converges to its saturation limits, and is the only layer thatcompresses during training (c.f. Fig. 1B). x-axis: training time in epochs. y-axis: Hidden activityvalue. Colormap: density of hidden layer activities across all input examples.
Figure 18: Information plane dynamics in a deep linear neural network. (A) Train and test errorduring learning. (B) Information plane dynamics. No compression is visible.
Figure 19: Effect of stochastic training in linear networks. (A) Information plane dynamics forstochastic gradient descent in a linear network (same setting as Fig. 4). (B) Information planedynamics for batch gradient descent.
Figure 20: Gradient SNR phase transition. (A) tanh networks trained in the standard setting ofShwartz-Ziv & Tishby (2017) show a phase transition in every layer. (B) ReLU networks also show aphase transition in every layer, despite exhibiting no compression.
Figure 21: Minimal model exhibiting gradient SNR phase transition. Here a three neuron linearnetwork (architecture 1 - 1 - 1) learns to approximate a teacher. Other parameters are teacherSNR = 1, number of training samples P = 100, learning rate .001. Left column: (A) The loss overtraining with SGD (minibatch size 1). (C) The resulting gradient SNR dynamics. Right column:(B) The loss over training with BGD. (D) The resulting gradient SNR dynamics averaging over alltraining samples (not minibatches, see text).
