Figure 1: Test error rate (%) vs. number of distinct labeled samples ever needing loss gradientcalculation (left) and number of training batches (right) on 20newsgroups (grey curves represents 10random trials of SGD).
Figure 2: Test error rate (%) vs. number of distinct labeled samples ever needing loss gradientcalculation (left) and number of training batches (right) on CIFAR10 (grey curves represents 10random trials of SGD).
Figure 3: Test error rate (%) vs. number of distinct labeled samples ever needing loss gradientcalculation (left) and number of training batches (right) on Fashion-MNIST (grey curves represents10 random trials of SGD).
Figure 4: Test error rate (%) vs. number of distinct labeled samples ever needing loss gradientcalculation (left) and number of training batches (right) on STL10 (grey curves represents 10 randomtrials of SGD).
Figure 5: Test error rate (%) vs. number of distinct labeled samples ever needing loss gradientcalculation (left) and number of training batches (right) on SVHN (grey curves represents 10 randomtrials of SGD).
Figure 6: Test error rate (%) vs. number of distinct labeled samples ever needing loss gradientcalculation (left) and number of training batches (right) on MNIST (grey curves represents 10 randomtrials of SGD).
Figure 7:	Number of distinct labeled samples ever needing loss gradient calculation vs. number oftraining batches for News20 (left), CIFAR10 (middle) and MNIST(right) (grey curves represents 10random trials of SGD).
Figure 8:	Number of distinct labeled samples ever needing loss gradient calculation vs. number oftraining batches for Fashion-MNIST (left), STL10 (middle) and SVHN (right) (grey curves represents10 random trials of SGD).
Figure 9: Training error rate (%) vs. number of distinct labeled samples ever needing loss gradientcalculation (left) and number of training batches (right) on 20newsgroups (grey curves represents 10random trials of SGD).
Figure 10: Training loss vs. number of distinct labeled samples ever needing loss gradient calculation(left) and number of training batches (right) on 20newsgroups (grey curves represents 10 randomtrials of SGD).
Figure 11: Test loss vs. number of distinct labeled samples ever needing loss gradient calculation(left) and number of training batches (right) on 20newsgroups (grey curves represents 10 randomtrials of SGD).
Figure 12: Training loss vs. number of distinct labeled samples ever needing loss gradient calculation(left) and number of training batches (right) on CIFAR10 (grey curves represents 10 random trials ofSGD).
Figure 13:	Test loss vs. number of distinct labeled samples ever needing loss gradient calculation(left) and number of training batches (right) on CIFAR10 (grey curves represents 10 random trials ofSGD).
Figure 14:	Training error rate (%) vs. number of distinct labeled samples ever needing loss gradientcalculation (left) and number of training batches (right) on MNIST (grey curves represents 10 randomtrials of SGD).
Figure 15: Training error rate (%) vs. number of distinct labeled samples ever needing loss gradientcalculation (left) and number of training batches (right) on Fashion-MNIST (grey curves represents10 random trials of SGD).
Figure 16: Training error rate (%) vs. number of distinct labeled samples ever needing loss gradientcalculation (left) and number of training batches (right) on STL10 (grey curves represents 10 randomtrials of SGD).
Figure 17: Training error rate (%) vs. number of distinct labeled samples ever needing loss gradientcalculation (left) and number of training batches (right) on SVHN (grey curves represents 10 randomtrials of SGD).
