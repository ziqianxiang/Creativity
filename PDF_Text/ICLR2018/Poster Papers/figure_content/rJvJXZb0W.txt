Figure 1: Overview. (a) The approach adopted by most prior work where given an input sentencethe model attempts to generate a context sentence. (b) Our approach replaces the decoder with aclassifier which chooses the target sentence from a set of candidate sentences.
Figure 2: Same encoder architecture trained using our objective and Skip-thought (ST) objectiveand performance on downstream tasks is compared after a given number of hours.
