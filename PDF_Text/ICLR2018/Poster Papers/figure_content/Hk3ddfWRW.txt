Figure 1: (a) 6-DOF IRB-120 robot and an example of a task configuration; (b) A schematic diagramof the I-SNN architecture.
Figure 2: Comparison of IDS and SNN algorithms. We plot three different errors during training (onthe training data), for the same model trained using IDS and SNN algorithm. Left: the respectivetraining loss for each method. Since the max in IDS upper bounds the softmax in SNN, the lossplot for IDS lower bounds SNN. Middle: the IDS loss on the training data, for both models. Sincethe SNN is trained on a different loss function (softmax), its performance is worse. This shows animportant point: if, at test time, we use optimistic sampling to sample z from best samples duringtraining, we should expect IDS to perform better than SNN. Right: the average log-likelihood lossduring training. The SNN wins here, since the softmax encourages to increase the likelihood of‘incorrect’ z values. This provides additional motivation for using optimistic sampling.
Figure 3: Raw histogram of the learned modes and failure cases for I-SNN architecture trained bySNN v.s. IDS algorithms.
Figure 4: (a) Most LfD approaches often learn multimodal representations as a function of currentstate (or history of states captured by a recurrent neural network). In such models, task level intentionis not guaranteed to be consistently inferred at every step throughout the task execution; (b) incontrast I-SNN samples and uniformly commits to the same mode at the task level throughout thetask execution.
Figure 5: Visualization of the stochastic Intention network: every row shows 5 snapshots of a tra-jectory generated by running the I-SNN trained by the IDS algorithm. Each run was generating byrandomly sampling an intention at the beginning and using it throughout the run. Smaller greencircles show the 32 coordinates outputted by the spatial softmax layer. The larger red circle showsthe top spatial softmax feature that received the highest weight from the soft attention generated bythe Stochastic Intention Network. Note that for each run, the model consistently attends to the samemode that it randomly selected at the beginning of the run.
Figure 6: Predict the Goal Domain: in an image with N randomly positioned, different coloredtargets, the task is to predict the center of one of the targets. The figure shows 9 random instancesof a domain with N = 5 targets. We also plot the training target positions (dark green dots, selecteduniformly among the targets), and the predictions of the trained I-SNN (yellow dots). Note that thepredictions do not have to match the training targets, but have to be centered on some target in theimage.
Figure 7: Results for Predict the Goal. We compare the CVAE with and without rate annealing,with different minibatch sizes, and with different sizes of the latent vector z to IDS with the sameparameters.
