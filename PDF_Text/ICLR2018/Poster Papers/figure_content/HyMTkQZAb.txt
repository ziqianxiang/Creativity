Figure 1: Optimization performance of our method compared to the baselines in perplexity-per-word on length-35 word sequences from Penn-TreeBank. All the methods used a mini-batch sizeof 200. K-FAC indep. uses the update in eqn. 6, K-FAC option1 uses eqn. 8, and K-FAC option2uses eqn. 9. (left) Training perplexity v.s. the number of updates. Dashed lines denote the trainingcurves for RNNs with 1024 LSTM units and solid lines denote the training curves for RNNs with650 LSTM units. (right) Training perplexity v.s. the wall-clock time.
Figure 2: Optimization performance in bit-per-character on length-100 character sequences fromPenn-TreeBank. batchsize indicates the mini-batch size used to train the baseline methods (ourmethod always used a mini-batch size of 200). K-FAC indep. uses the update in eqn. 6, K-FACoption1 uses eqn. 8, and K-FAC option2 uses eqn. 9. (left) Training perplexity v.s. the number ofupdates. (right) Training perplexity v.s. the wall-clock time.
Figure 3: Optimization performance for differentiable Neural Computers (DNC) on a repeated copytask. K-FAC indep. uses the update in eqn. 6, K-FAC option1 uses eqn. 8, and K-FAC option2 useseqn. 9. (left) Training cross entropy loss v.s. the number of updates. (right) Training cross entropyloss v.s. the wall-clock time.
Figure 4: Generalization performance of our method compared to the baselines in perplexity-per-word on length-35 word sequences from Penn-TreeBank. All the methods used a mini-batch size of200. K-FAC indep. uses the update in eqn. 6, K-FAC option1 uses eqn. 8, and K-FAC option2 useseqn. 9. (left) Validation perplexity v.s. the number of updates. The dashed lines correspond to theexperiments that used RNNs with 1024 LSTM units, and the solid lines correspond to experimentsthat used RNNs with 650 LSTM units. (right) Validation perplexity v.s. the wall-clock time.
