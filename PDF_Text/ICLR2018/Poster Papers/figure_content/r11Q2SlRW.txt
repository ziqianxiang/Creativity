Figure 1: Visual diagram of an unrolled Auto-Conditioned RNN (right) with condition length v = 4 and groundtruth length u = 4. It is the input at time step t. St is the hidden state. Ot is the output.
Figure 2: Motion change between subsequent frames of different motion styles, given as Euclidean distance inprediction results, at different frames. All acLSTM networks here are trained with condition length 5. Predictionsare generated with 10 frames (approximately 170 ms) of seed motion from test set. Results are averaged over 20random seed motions. Low value in motion change indicates the freezing of motion. Note that acLSTM andvanilla have exactly the same architecture - differences are due solely to training. Results averaged over 20 seedmotions.
Figure 3: Comparison between the vanilla LSTM and our method at 250,000 iterations of training. top: vanillaLSTM, bottom: acLSTM. The two synthesized motions are initialized with the same 10 frames of ground truthmotion. The motion generated by the vanilla LSTM freezes after around 60 frames. Our method does not freeze.
Figure 4: Motion sequences generated by acLSTM, sampled at various frames. Motion style from top to bottom:martial arts, Indian dancing, Indian/salsa hybrid and walking. All the motions are generated at 60 fps, and areinitialized with 10 frames of ground truth data randomly picked up from the database. The number at the bottomof each image is the frame index. The images are rendered with BVHViewer 1.1 (van Basten, 2017)When motion does stagnate, it recovers relatively quickly, and the motion never diverges or freezescompletely (see Figure 6). The short-term freezing could possibly be explained by "dead-times" in thetraining sequence, where the actor is beginning or ending a sequence which involves a rest position.
Figure 5: Sample frames from a 300+ second generated sequence. Note that no sequence in the training setexceeds 30 seconds of contiguous motion.
Figure 6: Example of the acLSTM recovering from short term stagnated motion.
Figure 7: Frames of alternative methods at latest failure-points out of 20 generated 1000-frame motion samples.
Figure 8: Selected frames of a rigged animation example using the martial arts network.
Figure 9: Motion change between subsequent frames using different condition lengths, given as Euclideandistance in prediction results, at different frames. Predictions are initialized with 10 frames (approximately 170ms) of seed motion from test set. Results are averaged over 20 random seed motions. All networks are trainedon the Indian dance dataset.
Figure 10: Detailed visual diagram of an unrolled Auto-Conditioned LSTM. It is the input at time step t. Ot isthe output state. Rectangles indicate the neural network layer. Circles indicate point wise operation. Trianglesindicate concatenation.
