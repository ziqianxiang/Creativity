Figure 1: Motion is estimated from the input images (It-k-1Q with a convolutional neural network(top left CDNN component). A warping scheme then displaces the last input image along this motionestimate to produce the future image. The error signal is calculated using the target future imageIt+ι, and is backprogated through the warping scheme to correct the CdNn. To produce multipletime-step forecasts, the predicted image is fed back in the CDNN in an autoregressive manner.
Figure 2: Architecture of the CDNN motion estimation component. For the estimated motion flowWt, colours correspond to the flow orientation and colour intensity to the flow intensityAs indicated in section 2, provided the underlying motion field is known, one can compute SSTforecasts. Let us introduce how the motion field is estimated in our architecture. We are looking fora vector field w which when applied to the geometric space Ω renders It close to It+ι, i.e. It+ι(χ) `It(X + w(x)), ∀x ∈ Ω. If It+ι were known, we could estimate w, but It+ι is precisely what weare looking for. Instead, we choose to use a convolutional-deconvolutional architecture to predict amotion vector for each pixel. As shown in figure 2, this network makes use of skip connections Heet al. (2015), allowing fine grained information from the first layers to flow through in a more directmanner. We use a Batch Normalization layer between each convolution, and Leaky ReLU (withparameter value set to 0.1) non-linearities between convolutions and transposed-convolutions. Weused k = 4 concatenated images It-k-1:t as input for training. We have selected this architectureexperimentally, testing different state-of-the-art convolution-deconvolution network architectures.
Figure 3: Warping scheme. To calculate the pixel value for time t+ 1 at position x, we first computeits previous position at time t, i.e. x - w. We then center a Gaussian in that position in order toobtain a weight value for each pixel in It based on its distance with x - w, and compute a weightedaverage of the pixel values of It . This weighted average will correspond to the new pixel value at xin It+1.
Figure 4: Sub regions extracted for the dataset. Test regions are regions 17 to 20.
Figure 5: From top to bottom: target, our model prediction, our model flow, numerical assimilationmodel , ACNN, ConvLSTM. Data correspond to daily temperatures from January 17 to January 23,20178Published as a conference paper at ICLR 2018model Bereziat & Herlin (2015), performs well but has a Slighthly lower performance than our reg-ularized model, although it incorporates more prior constraints. This shows that pure ML models,when conceived adequately and when trained with enough data, can be competitive with state ofthe art dedicated models. Regularizing the motion vector w notably increases the performance w.r.t.
Figure 6: Evaluation of our model’s accuracy in time on data from 2006 to 2010 using data from2011 to 2017 for training. Regions 17 to 20 were used for both periods. Each day, we produce dailyforecasts for 6 days ahead and calculate the associated mean square error.
