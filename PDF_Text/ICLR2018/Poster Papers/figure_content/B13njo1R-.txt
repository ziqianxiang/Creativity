Figure 1: Different curriculum learning process. The red box with a D in it denotes a distillationstep that combines policies. Each gray box denotes one iteration of learning a new policy. The largerred boxes with an Lterrain-type denotes a learning step where a new skill is learned.
Figure 2: Learning comparison over each of the environments. These plots show the mean and stdover 5 simulations, each initialized with different random seeds. The learning for PLAiD is splitinto two steps, with TL (in green) going first followed by the distillation part (in yellow).
Figure 3: These figures show the average reward a particular policy achieves over a number of tasks.
Figure 4: (a) The input features include both the character state shown as the red lines between theroot of the character and the characterâ€™s links and the terrain features shown as the blue arrows alongthe ground. (b) A diagram of method used to inject additional state features for the terrain.
Figure 6: The environments used to evaluate PLAiD.
Figure 7: Still frame shots of the pd-biped traversing the mixed environment.
Figure 8: (a) Shows that the MultiTasker can learn faster on steps, flat and incline than PLAiD(expert) learning the single task steps with TL.
