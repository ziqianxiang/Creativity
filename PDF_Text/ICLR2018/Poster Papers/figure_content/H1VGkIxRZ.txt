Figure 1: (a) ROC curves of base-line (red) and our method (blue)on DenSeNet-BC-100 network, whereCIFAR-10 and TinyImageNet (crop)are in- and out-of-distribution dataset,respectively.
Figure 2: (a)-(d) Performance of our method vs. MMD between in- and out-of-distribution datasets. Neuralnetworks are trained on CIFAR-100 and CIFAR-80, respectively. The out-of-distribution datasets are 1: LSUN(cop), 2: TinyImageNet (crop), 3: LSUN (resize), 4: is iSUN (resize), 5: TinyImageNet (resize) and 6:CIFAR-20.
Figure 3: (a)(b) Effects of temperature T when ε = 0. (c)(d) Effects of perturbation magnitude ε when T = 1.
Figure 4: (a)(b) Effects of perturbation magnitude ε on DenseNet when T is large (e.g., T = 1000). (c)(d)Effects of perturbation magnitude of ε on Wide-ResNet-28-10 when T is large (e.g., T = 1000). All networksare trained on CIFAR-10. Additional results on other metrics and Wide ResNet-40 are provided in Appendix B.
Figure 5: (a) Probability density of U1 under different datasets on DenseNet. (b) Expectations of U2 conditionedon U1 on DenseNet. (c) Probability density of the norm of gradient on DenseNet under temperature 1, 000.
Figure 6: Illustration of effectsof the input preprocessing.
Figure 7: Detection performance on DenseNet, Wide ResNet-28-10 and Wide ResNet-40-4 under differenttemperature, when input preprocessing is not used, i.e., ε = 0. All networks are trained on CIFAR-10.
Figure 8: Detection performance on DenseNet, Wide ResNet-28-10 and Wide ResNet-40-4 under differentperturbation magnitude, when temperature scaling is not used, i.e., T = 1. All networks are trained onCIFAR-10.
Figure 9:	Detection performance on DenseNet, Wide ResNet-28-10 and Wide ResNet-40-4 under differentperturbation magnitude, when the optimal temperature is used, i.e., T = 1000. All networks are trained onCIFAR-10.
Figure 10:	Expectation of the second order term U2 conditioned on the first order term U1 under DenseNet,Wide-ResNet-28-10 and Wide ResNet-40-4. All networks are trained on CIFAR-10.
Figure 11: Expectation of gradient norms conditioned on the softmax scores under DenseNet, Wide-ResNet-28-10 and Wide ResNet-40-4, where the temperature scaling is not used. All networks are trained on CIFAR-10.
Figure 12: Expectation of gradient norms conditioned on the softmax scores under DenseNet, Wide-ResNet-28-10 and Wide ResNet-40-4, where the optimal temperature is used, i.e., T = 1000. All networks are trained onCIFAR-10.
Figure 13: False positive rate (FPR) and true positive rate (TPR) under different thresholds (δ) when thetemperature (T) is set to 1, 000 and the perturbation magnitude (ε) is set to 0.0014. The DenseNet is trained onCIFAR-10.
Figure 14: Detection performance on Tiny-ImageNet (resize), LSUN (resize) and iSUN (resize) when parame-ters are tuned on six different out-of-distribution datasets. Each tuning set contains 1,000 images and each testset contains 9,000 images. Both DenseNet and Wide-ResNet are trained on CIFAR-10. Additional results onother datasets are provide in Table 10 and 11.
Figure 15:	FPR at TPR 95% under different tuning set sizes. The DenseNet is trained on CIFAR-10 and eachtest set contains 8,000 out-of-distribution images.
Figure 16:	(a) The test accuracy on the images having softmax scores above the threshold corresponding toa certain true positive rate. (b) The test accuracy on the images having softmax scores below the thresholdcorresponding to a certain true positive rate. All networks are trained on CIFAR-10.
Figure 17: Outputs of DenseNet on thirty classes for an image of apple from CIFAR-80 and an image of redpepper from CIFAR-20. The label “0” denotes the class “apple” and the label “49" denotes the class “orange".
