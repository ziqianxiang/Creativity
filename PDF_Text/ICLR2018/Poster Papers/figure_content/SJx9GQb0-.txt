Figure 1: Illustration of our mainidea. In addition to the gradientpenalty over xb, we also examine x0and x00 around the real data point xin each iteration.
Figure 2: Framework for the semi-supervised training. For clarity, we have omitted the generator.
Figure 4: Convergence curves of the discriminator cost: (a) GP-WGAN and (b) Our CT-GAN.
Figure 5: Generated samples by (a) GP-WGAN and (b) our CT-GAN. Here the generator is a smallCNN. See Figure 7 for the samples by a ResNet.
Figure 6: Histograms of the weights of the discriminators trained by (a) GP-WGAN and (b) CT-GAN, respectively.
Figure 7: Generated samples by our ResNet model: (a) Generated samples by unsupervised modeland (b) Generated samples by supervised model. Each column corresponds to one class in theCIFAR-10 dataset.
Figure 8: The maximum `2 norm of the gradients of the discriminator with respect to the input onCIFAR-10 testing set in each iteration of the training using 1000 CIFAR-10 training images.
Figure 9: CT (cf. Eq. (4)) over different iterations of the training using 1000 CIFAR-10 images. Ineach iteration, we randomly pick up two real data points to compute the CT.
Figure 10:	CT (cf. Eq. (5)) over different iterations of the training using 1000 CIFAR-10 images.
Figure 11:	The results of GP-WGAN+dropout.
Figure 12:	Convergence curves of the discriminator cost: (a) GP-WGAN, (b) GP-WGAN+Dropout,and (c) CT-GAN (ours).
Figure 13: Inception score of GP-WGAN and our CT-GAN with respect to iterations(a)	(b)Figure 14: Samples generated by GP-WGAN (a) and by CT-GAN (b), respectively.
Figure 14: Samples generated by GP-WGAN (a) and by CT-GAN (b), respectively.
Figure 15: Image samples generated by CT-GAN trained model using LSUN bedroom images.
