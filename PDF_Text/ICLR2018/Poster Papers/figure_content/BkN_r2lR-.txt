Figure 1: A schematic of our algorithm with illustrative images. (a) Distribution matching using anadversarial loss. Note that in fact this happens for both the A → B and B → A mapping directions.
Figure 2:	Inexact matching scenarios: Three examples of Shoes2Handbags matching. (a) Sourceimage. (b) AN-GAN analogy. (c) DiscoGAN + α iterations. (d) output of mapping by DiscoGAN.
Figure 3:	Supervised vs unsupervised image mapping: The supervised mapping is far more accu-rate than unsupervised mapping, which is often unable to match the correct colors (segmentationlabels). Our method is able to find correspondences between the domains and therefore makes theunsupervised problem, effectively supervised. (a) Source image. (b) Unsupervised translation usingCycleGAN. (c) A one to one method (Pix2Pix) as trained on AN-GAN’s matching, which wereobtained in an unsupervised way. (d) Fully supervised Pix2Pix mapping using correspondences. (e)Target image.
