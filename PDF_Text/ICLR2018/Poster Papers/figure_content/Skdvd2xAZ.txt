Figure 1: Toy regression uncertainty. Black dots are data points, the black line shows the noiselessfunction. The red line shows the deterministic prediction of the network, the blue line the meanoutput. Each shade of blue visualises one additional standard deviation. Best viewed on screen.
Figure 2: Predictive entropy on notMNIST ob-tained from different methods for the forward passon a network trained on MNIST.
Figure 3: Untargeted adversarial attack.
Figure 4: Targeted adversarial attack.
Figure 5: Inverse ecdf of the predictive entropy from Wide Residual Networks trained with andwithout Dropout on CIFAR100. For misclassifications, curves on top corresponding to higher un-certainty are desirable, and curves on the bottom for correct classifications.
Figure 6: Untargeted adversarial attack for Kronecker factored Laplace approximation with thecurvature calculated with and without data augmentation/approximating the activation Hessian.
Figure 7: Targeted adversarial attack for Kronecker factored Laplace approximation with the curva-ture calculated with and without data augmentation/approximating the activation Hessian.
Figure 8: Toy regression uncertainty. Black dots are data points, the black line shows the underlyingnoiseless function. The red line shows the deterministic prediction of the trained network, the blueline the mean output. Each shade of blue visualises one additional standard deviation.
