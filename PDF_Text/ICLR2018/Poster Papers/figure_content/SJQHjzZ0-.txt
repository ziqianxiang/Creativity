Figure 1: Log-likelihood estimated us-ing AIS for generators learned usingDCGAN at various points during train-ing, MNIST data set.
Figure 2: Misleading examples of Inception Scores.
Figure 3: Pairs of generated image sets for which human perception and metrics disagree. Here, weselected one such example for each metric for which the difference in that metric’s scores was high.
Figure 4: LS score evaluation ofW-DCGAN& LS-DCGAN w.r.t number of feature maps.
Figure 5: W-DCGAN trained with different num-bers of feature maps.
Figure 6: Samples from different LS-DCGAN architectures.
Figure 7: LS score evaluation with respect to a varying number of discriminator and generator updateson DCGAN, W-DCGAN, and LS-DCGAN.
Figure 8: LS score evaluation on W-DCGAN & LS-DCGAN w.r.t numberof data points.
Figure 9: GAN Topology for MNIST.
Figure 10: GAN Topology for CIFAR10.
Figure 11: MNIST & FashionMNIST Samples16Published as a conference paper at ICLR 2018Table 10: Hyper-parameters used for different experiments.
Figure 12: GAN evaluation using different architectures for the critic (Number of feature maps ineach layer of the CNN critic). Above figures are evaluated under negative least-square loss andFigures 13 are evaluated under Wasserstein distance.
Figure 13:	GAN evaluation using different critic’s architecture (Number of filter of critic’s convolu-tional network). Figure (a,b,c,d) are evaluation under Wasserstein distance.
Figure 14:	The participants are trained by selecting between random samples generated by GANsversus samples from data distribution. They get a positive reward if they selected the data samplesand a negative reward if they select the samples from the model. After enough training, they choosethe better group of samples among two randomly select set of samples.
Figure 15:	The fraction of labels that agree for each pair, depending on the number of labels for eachpair, presented as a histogram. By definition, if there is only one participant, that participant mustagree with themselves.
Figure 17: W-DCGAN trained(c) LS (the higher the better)(d) IW (the lower the better)Figure 16: Performance of W-DCGAN & LS-DCGAN with respectto number of filters.
Figure 16: Performance of W-DCGAN & LS-DCGAN with respectto number of filters.
Figure 18: Samples from different architectures of LS-DCGANfilters for both	number of filters for number of filters for	filters for bothdiscriminator and generator discriminator and generator discriminator and generator discriminator and generator(ref. (a) in Table 7). respectively (ref. (e) in respectively (ref. (f) in (ref. (d) in Table 7).
Figure 19:	Samples from different architectures of W-DCGAN.
Figure 20:	The performance of GANs trained with different numbers of feature maps.
Figure 21:	All pairs of generated image sets for which human perception and IW disagree, as inFigure 3.
Figure 22:	All pairs of generated image sets for which human perception and LS disagree, as inFigure 3.
Figure 23:	All pairs of generated image sets for which human perception and IS disagree, as inFigure 3.
Figure 24:	All pairs of generated image sets for which human perception and MMD disagree, as inFigure 3.
Figure 25: Performance of DCGAN, W-DCGAN, and LS-DCGAN trained with varying numbers ofdiscriminator and generator updates. These models were trained on CIFAR10 dataset and evaluatedwith IW and LS metrics.
Figure 26: Performance of DCGAN, W-DCGAN, and LS-DCGAN trained with varying numbers ofdiscriminator and generator updates. These models were trained on the MNIST dataset and evaluatedwith GC, LS, and IW metrics.
Figure 27: Samples at varying update ratios.
Figure 28: Performance of W-DCGAN & LS-DCGAN with respectto number of data points.
Figure 29: Interpolation be-tween the three final GANparameters trained using dif-ferent random seeds on CI-FAR10. Loss surfaCe valuesare amplified by 10 times inorder to illustrate the separa-tion of the terrains. LoCalzig-zag patterns are minorartifaCts from rendering.
Figure 30: SCores from training GANs on LSUN Bedroom dataset.
Figure 31: The training Curve of CritiCs to show that the training Curve Converges. IW distanCe Curvesin (a) inCrease beCause we used linear output unit for the CritiC network (by design ChoiCe). This Canbe simply bounded by adding a sigmoid at the output of the CritiC network.
