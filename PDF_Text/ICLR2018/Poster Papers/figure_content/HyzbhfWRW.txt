Figure 1:	Overview of the proposed attention mechanism.
Figure 2:	Attention introduced at 3 distinct layers of VGG. Lowest level attention maps appear tofocus on the surroundings (i.e., the rocky mountain), intermediate level maps on object parts (i.e.,harness and climbing equipment) and the highest level maps on the central object.
Figure 3: Attention maps from VGG-att2 trained on low-res CIFAR-10 dataset focus sharply on the objects inhigh-res ImageNet images of CIFAR categories; con-trasted here with the activation-based attention mapsof Zagoruyko & Komodakis (2016).
Figure 4: VGG-att2 trained onCUB-200 for fine-grained birdrecognition task: layer-10 learnsto fixate on eye and beak regions,layer-13 on plumage and feet.
Figure 5: Adversarial versions of a sample input imagefor log-linearly increasing Lâˆž norm from 1 to 16, es-timated for VGG and VGG-att2 trained on CUB-200.
Figure 6: Network fooling rate measuredas a percentage change in the predictedclass labels w.r.t those predicted for theunperturbed images.
Figure 7: Row 1 : Event-8 (croquet), Row 2 : Scene-67 (bar). Attention maps for models trained onCIFAR-100 (c100) are more diverse than those from the models trained on CIFAR-10 (c10). Notethe sharp attention maps in col. 7 versus the uniform ones in col. 4. Attention maps at lower levelsappear to attend to part details (e.g. the stack of wine bottles in the bar (row 2)) and at a higher levelon whole objects owing to a large effective receptive field.
Figure 8: Weakly supervised seg-mentation by binarising attentionmaps.
Figure 9: Jaccard scores (higher is better) for binarised attentionmaps from CIFAR-10/100 trained models tested on the ObjectDiscovery dataset.
Figure 10: Visual analysis of how a global feature vector obtained from a query image affects theattention patterns on the local image regions of another distinct target image.
