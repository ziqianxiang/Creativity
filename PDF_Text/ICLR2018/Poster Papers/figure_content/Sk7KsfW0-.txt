Figure 1: Concept: (a) Retraining models such as Elastic Weight Consoliation Kirkpatrick et al. (2017) retrainsthe entire network learned on previous tasks while regularizing it to prevent large deviation from the originalmodel. Units and weights colored in red denote the ones that are retrained, and black ones are ones that remainfixed. (b) Non-retraining models such as Progressive Network (Rusu et al., 2016) expands the network for thenew task t, while withholding modification of network weights for previous tasks. (c) Our DEN selectivelyretrains the old network, expanding its capacity when necessary, and thus dynamically deciding its optimalcapacity as it trains on.
Figure 2: Incremental learning of a dynamically expandable network: Left: Selective retraining. DEN firstidentifies neurons that are relevant to the new tasks, and selectively retrains the network parameters associatedwith them. Center: Dynamic network expansion. If the selective retraining fails to obtain desired loss below setthreshold, we expand the network capacity in a top-down manner, while eliminating any unnecessary neuronsusing group-sparsity regularization. Right: Network split/duplication. DEN calculates the drift œÅit for each unitto identify units that have drifted too much from their original values during training and duplicate them.
Figure 3:	Top row:Average per-task performance of the models over number of task t, averaged over fiverandom splits. The numbers in the legend denote average per-task performance after the model has finishedlearning (t = T). Bottom row: Accuracy over network capacity. The network capacity is given relative to thecapacity of MTL, which we consider as 100%.
Figure 4:	Effect of selective retraining. (a) shows AUROC over actual training time and (b) shows the numberof selected neurons by selective retraining. (c) Expansion performance. We report both the prediction AUROCand network capacity measured by the relative number of parameters to that of DNN-MTL on MNIST-Variancedataset. Reported numbers are mean and standard error for five random splits.
Figure 5:	Semantic drift experiment on the MNIST-Variation dataset. We report the AUROC of differentmodels on t = 1, t = 4, and t = 7 at each training stage to see how the model performance changes over timefor these tasks. Reported AUROC is the average over five random splits.
Figure 6: Results on the Permuted MNIST. Average per-task AUROC and network capacity of all modelsrelative to MTL on Permuted MNIST.
