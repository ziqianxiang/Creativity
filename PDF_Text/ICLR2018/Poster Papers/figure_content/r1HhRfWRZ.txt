Figure 1: Illustration of a preprogrammed grasp and release cycle of a single episode of the MPLhand. The target block is only perceivable to the agent through the constraints it imposes on themovement of the hand. Note that the shape of the object is correctly predicted even when the handis not in contact with it. That is, the hand neural network sensory model has learned persistentrepresentations of the external world, which enable it to be aware of object properties even when nottouching the objects.
Figure 2: Overview of our notation and definitions.
Figure 3: Top Left: A PreCo model generating single-step predictions and corrections, as in op-timal filtering. Bottom Left: A PreCo model making multi-step predictions. Right: Multi-steprollouts, from all timesteps, are used for fitting a PreCo model to a trajectory. Deterministic nodesare represented with diamonds and stochastic nodes are represented with circles.
Figure 4: Results for the passive data collection experiment. Black vertical lines mark timestepswhere the hand is fully open (solid) or fully closed (dashed). See the main text for a description ofthe different baseline models. The baseline models are end-to-end supervised on the shape classifi-cation task, whereas the PreCo states are learned without the shape information. Top: Classificationloss vs episode timestep for the diagnostic model and the three baselines. Lines show median loss av-eraged over 5000 test episodes. Middle: Cumulative distributions of loss at the indicated timesteps.
Figure 5: Left: Reward obtained by planning to achieve the max fingertip objective using dynam-ics models trained with different data collection strategies. Right: A frame from a planned maxfingertip trajectory.
Figure 6: Diagnostic comparison between active and passive data collection computed by directlycomparing loss values. The model trained with actively collected data outperforms its passive coun-terpart in regions of the grasp trajectory where the hand is not in contact with the block.
Figure 7: Examples of the hand behaving to maximize uncertainty about the future (top) or minimizeuncertainty (bottom). When the hand is trained to maximize uncertainty it engages in playful be-havior with the object. The body models learned with this objective, can then be re-used with novelobjectives, such as minimizing uncertainty. When doing so, we see that the hand avoids contact soas to minimize uncertainty about future proprioceptive and haptic predictions.
Figure 8: Left: The robotic hand setup. Center: Results on predicting block orientation with sensordata recorded from the shadow hand. The upper plot shows the median error as a function of timeand the bottom plot shows a bootstrap estimate of the probability that using the model features failsto improve on using sensor measurements directly. Error regions in both plots show 95% confidenceintervals, estimated by bootstrap sampling. Right: Predicted angles on test trajectories at step 40using only sensor readings (top) and model features (bottom). Green lines show predicted angles forindividual samples (rotated so ground truth is vertical). The solid and dashed red lines show 50 and75 percentile error cones, respectively.
Figure 10: A visualization of the model planning to minimize predicted entropy.
Figure 11: Detailed architecture diagrams of the components of the Preco model, along with labelsthat indicate different hyperparameters. A MLP sections of the models are parameterised with adepth and a hidden size, where a depth of d and a hidden size of k indicates d hidden layers of sizek. We do not count the output layer or the input layer in the depth parameter (so a depth of 0 isa single linear transform followed by an activation function). The output layers of the MLP partsof the model are all indicated separately in the diagrams. The three pieces shown here are attachedtogether in various ways, as shown in Figure 3 in the main body of the paper.
