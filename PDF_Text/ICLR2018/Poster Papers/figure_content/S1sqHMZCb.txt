Figure 1: Visualization of the graph structure of CentipedeEight in our environment. We usethis agent for testing the ability of transfer learning of our model. Since for this agent, each bodynode is paired with at least one joint node, we omit the body nodes and fill up the positionwith the corresponding joint nodes. By omitting the body nodes, a more compact graph isconstructed, the details of which are illustrated in the experimental section.
Figure 2: In this figure, we use Walker-Ostrich as an example of NerveNet. In the input model,for each node, NerveNet fetches the corresponding elements from the observation vector. NerveNetthen computes the messages between neighbors in the graph, and updates the hidden state of eachnode. This process is repeated for a certain number of propagation steps. In the output model, thepolicy is produced by collecting the output from each controller.
Figure 3: Results of MLP, TreeNet and NerveNet on 8 continuous control benchmarks from theGym.
Figure 4:	Performance of zero-shot learning on centipedes. For each task, we run the policy for 100episodes and record the average reward and average length the agent runs before falling down.
Figure 5:	(a), (b): Results of fine-tuning for size transfer experiments. (c), (d) Results of fine-tuningfor disability transfer experiments.
Figure 6: Results on zero-shot transfer learning on snake agents. Each tasks are simulated for 100episodes.
Figure 7:	Results of finetuning on snake environments.
Figure 8:	Results of Multi-task learning. We train the networks simultaneously on five differenttasks from Walker.
Figure 9: Diagram of the walk cycle. In the left figure, legs within the same triangle are usedsimultaneously. For each leg, we use the same color for their diagram on the left and their curves onthe right.
Figure 10:	Results of visualization of feature distribution and trajectory density. As can be seen fromthe figure, NerveNet agent is able to learn shareable features for its legs, and certain walk-cycle islearnt during training.
Figure 11:	Results of several variants of NerveNet for the reinforcement learning agents.
Figure 12: Schematic diagrams and auto-parsed graph structures of the InvertedPendulum andInvertedDoublePendulum.
Figure 13: Schematic diagrams and auto-parsed graph structures of the Walker2d and Reacher.
Figure 14: Schematic diagrams and auto-parsed graph structures of the SnakeSix and Swimmer.
Figure 15: Schematic diagrams and auto-parsed graph structures of the Ant.
Figure 16: SchematicHalfCheetah.
Figure 17: Schematic diagrams and auto-parsed graph structures of Walker-Ostrich andWalker-Wolf.
Figure 18: Schematic diagrams and auto-parsed graph structures of Walker-Hopper andWalker-HalfHumanoid.
Figure 19: Schematic diagrams and auto-parsed graph structures of Walker-Horse.
