Figure 1: Translating “A B C”to “X Y” using autoregressive andnon-autoregressive neural MT ar-chitectures. The latter generates alloutput tokens in parallel.
Figure 2: The architecture of the NAT, where the black solid arrows represent differentiable con-nections and the purple dashed arrows are non-differentiable operations. Each sublayer inside theencoder and decoder stacks also includes layer normalization and a residual connection.
Figure 3: BLEU scores on IWSLT de-velopment set as a function of sample sizefor noisy parallel decoding. NPD matchesthe performance of the other two decodingstrategies after two samples, and exceeds theperformance of the autoregressive teacherwith around 1000.
Figure 4:	Two examples comparing translations produced by an autoregressive (AR) and non-autoregressive Transformer as well as the result of noisy parallel decoding with sample size 100.
Figure 5:	A Romanian-English example translated with noisy parallel decoding. At left are eightsampled fertility sequences from the encoder, represented with their corresponding decoder inputsequences. Each of these values for the latent variable leads to a different possible output translation,shown at right. The autoregressive Transformer then picks the best translation, shown in red, aprocess which is much faster than directly using it to generate output.
Figure 6: The schematic structure of training and inference for the NAT. The “distilled data” containstarget sentences decoded by the autoregressive model and ground-truth source sentences.
Figure 7: The translation latency, computed as the time to decode a single sentence without mini-batching, for each sentence in the IWSLT development set as a function of its length. The autore-gressive model has latency linear in the decoding length, while the latency of the NAT is nearlyconstant for typical lengths, even with NPD with sample size 10. When using NPD with samplesize 100, the level of parallelism is enough to more than saturate the GPU, leading again to linearlatencies.
Figure 8: Learning curves for training and fine-tuning of the NAT on IWSLT. BLEU scores are onthe development set.
