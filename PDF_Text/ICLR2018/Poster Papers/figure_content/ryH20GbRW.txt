Figure 1: Illustration of the different computational aspects of R-NEM when applied to a sequence ofimages of bouncing balls. Note that γ , ψ at the Representations level correspond to the γ (E-step), ψ(Group Reconstructions) from the previous time-step. Different colors correspond to different clustercomponents (object representations).The right side shows a computational overview of ΥR-NEM, afunction that computes the pair-wise interactions between the object representations.
Figure 2: R-NEM applied to a sequence of 4 bouncing balls. Each column corresponds to a time-step,which coincides with an EM step. At each time-step, R-NEM computes K = 5 new representationsθk according to (4) (see also Representations in Figure 1) from the input x with added noise (bottomrow). From each new θk a group reconstruction ψk is produced (rows 2-6 from bottom) that predictsthe state of the environment at the next time-step. Attention coefficients are visualized by overlayinga colored reconstruction of a context object on the white reconstruction of the focus object (seeAttention in Section 4). Based on the prediction accuracy of ψ, the E-step (see Figure 1) computesnew soft-assignments γ (row 7 from bottom), visualized by coloring each pixel i according to theirdistribution over components γi. RoW 8 visualizes the total prediction by the network (Pk ψk ∙ Yk)and row 9 the ground-truth sequence at the next time-step.
Figure 3: Performance of each method on the bouncing balls task. Each method was trained ona dataset with 4 balls, evaluated on a test set with 4 balls (left), and on a test-set with 6-8 balls(middle). The losses are reported relative to the loss of a baseline for each dataset that always predictsthe current frame. The ARI score (right) is used to evaluate the degree of compositionality that isachieved.
Figure 4: Left: Three sequences of 15 time-steps ground-truth (top), R-NEM (middle), RNN (bottom).
Figure 5: R-NEM applied to a sequence of bouncing balls with an invisible curtain. The groundtruth sequence is displayed in the top row, followed by the prediction of R-NEM (middle) and thesoft-assignments of pixels to components (bottom). R-NEM models objects, as well as its interactions,even when the object is completely occluded (step 36). Only a subset of the steps is shown.
Figure 6: R-NEM accurately models a sequence of frames obtained by an agent playing SpaceInvaders. A group no longer corresponds to an object, but instead assumes the role of high-levelentities that engage in similar movement patterns.
