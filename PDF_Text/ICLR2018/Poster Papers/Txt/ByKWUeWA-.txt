Published as a conference paper at ICLR 2018
GANITE: Estimation of Individualized Treat-
ment Effects using Generative Adversarial
Nets
Jinsung Yoon
James Jordon
Department of Electrical and Computer Engineering Department of Engineering Science
University of California, Los Angeles
Los Angeles, CA 90095, USA
jsyoon0823@g.ucla.edu
University of Oxford
Oxford, UK
james.jordon@wolfson.ox.ac.uk
Mihaela van der Schaar
Department of Engineering Science, University of Oxford, Oxford, UK
Alan Turing Institute, London, UK
mihaela.vanderschaar@eng.ox.ac.uk
Ab stract
Estimating individualized treatment effects (ITE) is a challenging task due to the
need for an individual’s potential outcomes to be learned from biased data and
without having access to the counterfactuals. We propose a novel method for
inferring ITE based on the Generative Adversarial Nets (GANs) framework. Our
method, termed Generative Adversarial Nets for inference of Individualized Treat-
ment Effects (GANITE), is motivated by the possibility that we can capture the
uncertainty in the counterfactual distributions by attempting to learn them using a
GAN. We generate proxies of the counterfactual outcomes using a counterfactual
generator, G, and then pass these proxies to an ITE generator, I, in order to train
it. By modeling both of these using the GAN framework, we are able to infer
based on the factual data, while still accounting for the unseen counterfactuals.
We test our method on three real-world datasets (with both binary and multiple
treatments) and show that GANITE outperforms state-of-the-art methods.
1	Introduction
Individualized treatment effects (ITE) estimation using observational data is a fundamental problem
that is applicable in a wide variety of domains. For instance, (1) in understanding the heterogeneous
effects of drugs (Shalit et al. (2017); Alaa & van der Schaar (2017); Alaa et al. (2017)); (2) in
evaluating the effect of a policy on unemployment rates (LaLonde (1986); Smith & Todd (2005));
(3) in verifying which factor causes a certain disease (Hofler (2005)) and (4) estimating the effects
of pollution on the weather (Hannart et al. (2016)).
As explained in Spirtes (2009), the problem of ITE estimation differs from the standard supervised
learning problem. First, among the potential outcomes, only the factual outcome is actually observed
(revealed), counterfactual outcomes are not observed and so the entire vector of potential outcomes
can never be obtained. Second, unlike randomized controlled trials (RCT), observational studies are
prone to treatment selection bias. For instance, left ventricular assist device (LVAD) treatment is
mostly applied to high-risk patients with severe cardiovascular diseases before heart transplantation,
the distribution of features among these patients will be significantly different to the distribution
among non-LVAD treated patients (Kirklin et al. (2010)). The sample distribution can vary drasti-
cally across different choices of treatments and therefore, if we were to apply a supervised learning
framework for each treatment separately, the learned models would not generalize well to the entire
population.
Classical works in this domain solved the problem of estimating the average treatment effects from
observational data (Dehejia & Wahba (2002b); Lunceford & Davidian (2004)). These works account
1
Published as a conference paper at ICLR 2018
for the selection bias using propensity scores (the estimated probability of receiving a treatment) to
create unbiased estimators of the average treatment effect. Dehejia & Wahba (2002b) used a one-to-
one matching methodology to pair treated and control patients with similar features while Lunceford
& Davidian (2004) used propensity scoring weighing to account for the selection bias. More recent
works focus on individualized treatment effects (Chipman et al. (2010); Wager & Athey (2017);
Athey & Imbens (2016); Lu et al. (2017); Alaa & van der Schaar (2017); Porter et al. (2011); Johans-
son et al. (2016); Alaa et al. (2017); Louizos et al. (2017); Shalit et al. (2017)). Detailed qualitative
comparisons to these works will be discussed in the next subsection and numerical comparisons can
be found in Section 5.
In this paper, we propose a novel approach that attempts to not only fit a model to the observed
factual data, but also account for the unseen counterfactual outcomes. We view the factual outcome
as an observed label and consider the counterfactual outcomes to be missing labels. Missing labels
are generated by the well-known Generative Adversarial Nets (GAN) framework (Goodfellow et al.
(2014)). More specifically, the counterfactual generator of GANITE attempts to generate coun-
terfactual outcomes in such a way that when given the combined vector of factual and generated
counterfactual outcomes the discriminator of GANITE cannot determine which of the components
is the factual outcome. With the complete labels (combined factual and estimated counterfactual
outcomes), the ITE estimation function can then be trained for inferring the potential outcomes of
the individual based on the feature information in a supervised way. By also modelling this ITE
estimation function using a GAN framework, we are able not only to predict the expected outcomes
but also provide confidence intervals for the predictions, which is very important in, for example,
the medical setting.
Unlike many other state-of-the-art methods, our method naturally extends to - and in fact is defined
in the first place for - any number of treatments. We conduct experiments with three real-world
observational datasets (with both binary and multiple treatments), and GANITE outperforms state-
of-the-art methods.
1.1	Related Works
Previous works on ITE estimation can be divided into three categories. In the first, a separate model
is learned for each treatment; this approach does not account for selection bias and so each model
learned will be biased toward the distribution of that treatment’s population. In the second, the
treatment is considered a feature, with one model learned for everything, and the mismatch between
the entire sample distribution and treated and control distributions is adjusted in order to account for
selection bias. For instance, Chipman et al. (2010); Wager & Athey (2017); Athey & Imbens (2016);
Lu et al. (2017) used tree-based models, Porter et al. (2011) used doubly-robust methods, Dehejia
& Wahba (2002b); Lunceford & Davidian (2004), k-nearest neighbor (kNN) Crump et al. (2008)
used propensity and matching based methods, and Johansson et al. (2016); Shalit et al. (2017) used
deep learning approaches to solve the ITE problem under this one model methodology. Inherent to
the approach of learning a balanced representation is that the representation must trade off between
containing predictive information and reducing biased information. This is because often it will
be the case that information that is biased is also highly predictive (in fact in the medical setting
this is precisely why it is biased - because the doctors will assign treatments based on predictive
features). On the other hand, our framework is not forced to make this information trade-off - the
dataset we learn our final ITE estimator on contains the original dataset, and so contains at least
as much information as that one. In the experiment section, we show that our proposed framework
outperforms Shalit et al. (2017), particularly when the bias is high. In the third category, Alaa &
van der Schaar (2017); Alaa et al. (2017) used a multi-task model approach. Alaa et al. (2017)
used multi-task neural nets to estimate (1) the selection bias, (2) the controlled outcome and (3) the
treated outcome with shared layers across these three tasks. Alaa & van der Schaar (2017) used a
Gaussian Process approach in the multi-task model setting. Our work is perhaps most similar to
Alaa & van der Schaar (2017) since there, too, they attempted to account for the counterfactuals
and were similarly able to provide confidence in their estimates using credible intervals. They were
able to access counterfactuals through a posterior distribution which was then accounted for in the
learning of their model.
2
Published as a conference paper at ICLR 2018
2	Problem Formulation: Estimation of Individualized Treatment
Effects
Let X denote the s-dimensional feature space and Y the set of possible outcomes. Consider a
joint distribution, μ, on XX {0,1}k X Yk where k is the number of possible treatments. Suppose
that (X, T, Y)〜μ. We call X ∈ X the (s-dimensional) feature vector, T ≡ (Tl,…，Tk) ∈
{0, 1}k the treatment vector and Y ≡ (Y1, ..., YT) ∈ Yk the vector of potential outcomes (or the
Individualized Treatment Effects (ITE)). We assume that (with probability 1), there is precisely one
non-zero component of T and We denote by η the index of this component. Denote by μχ the
marginal distribution of X and by μγ (x) the conditional distribution of Y given X = x, for X ∈ X
(marginalized over T). This setting is known as the Rubin-Neyman causal model (Rubin (2005)).
We introduce two1 assumptions about the distribution μ in the Rubin-Neyman causal model.
Assumption 1. (Overlap) For all x ∈ X, for all i ∈ {1, ..., k},
0 < P(Ti = 1|X = x) < 1.
This assumption ensures that at every point in the feature space, there is a non-zero probability of
being given treatment i for every i.
Assumption 2. (Unconfoundedness) Conditional on X, the potential outcomes, Y, are indepen-
dent of T,
Y T|X.
This assumption is also referred to as no unmeasured confounding and requires that all joint influ-
ences on Y and T are measured. Note that this assumption means that μγ (x) no longer needs to be
marginalized over T, since, under this assumption, they are independent.
Assume now that we observe samples of (X, T, Yn) (whose joint distribution we denote by μf), so
that our dataset, D, is given by D = (x(n), t(n), yη(n) (n))nN=1. Importantly, we only observe the
component of the potential outcome vector that corresponds to the assigned treatment, we call this
the factual outcome, and refer to unobserved potential outcomes as counterfactual outcomes or just
counterfactuals. We denote by yf (n) and ycf (n) the factual outcome and (vector of) counterfactual
outcome(s), respectively. From this point forward, we omit the dependence on n for ease of notation.
In this setting, we wish to be able to draw samples from μγ (x) for any X ∈ X. We measure the
performance of the generator, I(x), using two different metrics depending on whether k = 2 (i.e.
binary treatments) or k > 2 (i.e. multiple treatments).
For k = 2 we use the expected Precision in Estimation of Heterogeneous Effects, P EHE, intro-
duced in Hill (2011), given by:
EPEHE = Ex〜μχ [ (Ey-μγ(x)做1 - J。] 一 Ey〜I(x) [y1 — y0])2]∙	(I)
For k > 2 we use the expected mean squared error:
EMSE
[llEy~μγ (χ) [y] - E^〜I(x)[y]||2i
(2)
where ∣∣∙∣∣ 2 is the standard '2 -norm in Rk.
In order to achieve this goal, we separate the problem into two parts. First, we attempt to generate
proxies for the unobserved counterfactual outcomes using a counterfactual generator (G) to create
a complete dataset. Then, using this proxy dataset, we learn the ITE generator, I.
3	GANITE: Generative Adversarial Nets for inference of
Individualized Treatment Effect estimation
3.1	Overview
The objective of GANITE is to generate potential outcomes for a given feature vector X. However,
due to the lack of counterfactual outcomes we are unable to learn the distribution of potential out-
comes directly. To account for these counterfactuals, we first attempt to generate samples, ycf, using
1All works cited in the Related Works section make this assumption.
3
Published as a conference paper at ICLR 2018
Captions
inpU Inputs
，一、
O J Outputs
©
(D
©
g
©
Feature vector
Treatment vector
Potential outcome vector
Factual outcome
Counterfactual outcome vector
RandomneSS vector
-----Back propagation
—.... Supervised loss inputs
-----Component I/O
CoUnterfactUal block
ITE block
Figure 1: Block Diagram of GANITE (y is sampled from G after G has been fully trained).
G, DG, DI are only operating during training, whereas I operates both during training and at run-
time.
a Counterfactual generator, G, from the distribution μγcf (x,t,yf) (the conditional distribution of
the counterfactual outcomes, Ycf given that X = x, T = t and Yn = yf) for each sample in our
dataset. We can then combine these proxy counterfactuals with the original dataset to obtain a com-
Plete dataset DD = {x(n),t(n), y(n)}nN=ι where y is the combination of yf and ycf (with y» = yf).
The ITE generator, I, can then be optimized using D.
We follow a conditional GAN framework similar to the one set out in Mirza & Osindero (2014)
to model the latter of these generators. For the former, we have to use a different discriminator in
order to capture the same idea. More specifically, GANITE consists of two blocks: a counterfactual
imputation block and an ITE block, each of which consists of a generator and a discriminator. We
describe each of these blocks and their components in more detail in the following subsection.
3.2	A Detailed Breakdown
Counterfactual generator (G): The counterfactual generator, G, uses the feature vector, x, the
treatment vector, t, and the factual outcome, yf, to generate a potential outcome vector, y. We let g
be a function g : X ×{0,1}k ×Y × [-1,1]k-1 → Yk and ZG 〜U((-1,1)k-1). We then define
the random variable G(x, t, yf) as
G(x,t,yf) = g(x, t, yf, zG)	(3)
The goal now is to find a function, g, such that G(x, t,yf)〜μγ(x, t, yf). We write y to denote
a sample of G and y to denote the vector obtained by replacing ijη with yf. Observe that the n-
th component of a sample from μγ (x,t,yf) will be yf, since we are sampling Y conditional on
Yη = yf .
Counterfactual discriminator (Dg): We introduce a discriminator, Dg, which maps pairs (x, y)
to vectors in [0,1]k with the i-th component, written Dg(x, y)i, representing the probability that
the i-th component of y is the factual outcome, equivalently the probability that n = i. This is
in contrast to the standard GAN framework in which the discriminator is given a single sample
from one of two distributions and it attempts to determine which distribution it came from. Here
the discriminator is given a sample consisting of components from two different distributions and
attempts to determine which components came from which distribution.
We train DG to maximize the probability of correctly identifying η. We then train G to maximize
the probability of DG incorrectly identifying η (equivalently we try to minimize the probability of
a correct identification - this is the adversarial method of learning between G and DG).
4
Published as a conference paper at ICLR 2018
Following the framework in Goodfellow et al. (2014), we note that this formulation is captured by a
minimax problem given by
min max E(χ,t,yf)〜“『[Ezg 〜U((-i,i)k)[tT log Dg(x, y) + (1 -t)Tlog(1- Dg(x, y))]] (4)
G DG
where log is performed element-wise and T denotes the transpose operator.
After training the counterfactual generator, we use it to generate the dataset D and pass this dataset
to the ITE block.
ITE generator (I): The ITE generator, I, uses only the feature vector, x, to generate a potential
outcome vector, y. Similar to our approach with G, let h be a function h : XX [-1,1]k → Yk and
ZI 〜U((-1,1)k). We define the random variable I(x) as
I(x) = h(x, zI)	(5)
and similarly, the goal is to find a function, h, such that I(x)〜 μγ(x). We write y to denote a
sample from I(x).
ITE discriminator (DI): Again, we introduce a discriminator, DI, but this time, since we have
access to a complete dataset D, we can use a standard conditional GAN discriminator - it takes a
pair (x, y*) and returns a scalar corresponding to the probability that y* was from the data DD (rather
than drawn from I). Again, we train the generator and discriminator in an adversarial fashion using
the following minimax criteria
min max Ex〜μχ [Ey* 〜μγ (x) [log Di(x, y*)]+ Ey* 〜I(χ) [log(1 — DI(x, y*))]]	(6)
I DI
where again log is taken element-wise.
4	GANITE: Optimization
In this section, we describe the empirical loss functions that are used to optimize each component of
GANITE. The Pseudo-code is summarized in the Appendix.
4.1	COUNTERFACTUAL BLOCK (G, DG):
Based on equation 4, the empirical objective of the minimax problem for G and DG can be defined
by
VCF(x(n), t(n), y(n)) = t(n)T log(DG(x(n), y(n))) + (1 - t(n))Tlog(I - Dg(xS), y(n))).
We also introduce the following ‘supervised’ loss in order to enforce the restriction that gη should
be equal to yf .
L(I(Iyf (n),yη(n)(n)) = MS) - yη(n)(n))2
More specifically, due to the structure of G, it outputs a full vector of potential outcomes, and
so it not only outputs counterfactuals, but also gives a value for the one factual that was used as
input. We account for this by using L(G to force the generated factual outcome to be close to the
actually observed factual outcome. This is because, as noted above, conditional on observing yf,
the component of y corresponding to yf should clearly be equal to yf.
With the above two objective functions, G and DG are iteratively optimized with kG minibatches
as follows:
kG
min -废 VCF(X(n),t(n), y(n))
DG
n=1
kG
nGnE [VCF (x(n),t(n), y(n)) + αLS(yf (n),yn(n)(n))]
n=1
where α ≥ 0 is a hyper-parameter.
5
Published as a conference paper at ICLR 2018
4.2	ITE BLOCK (I, DI):
After training the counterfactual block (G, DG), GANITE optimizes the ITE block (I, DI). Based
on equation 6, the empirical objective of the minimax problem for I and DI can be defined by
VITE(x(n), y(n), y(n)) = log(Dι(x(n), y(n))) + log(1 - Dι(x(n), y(n))).
Furthermore, in order to optimize the performance with respect to equations 1 and 2, we addition-
ally introduce supervised losses (for the respective cases of k = 2 (binary treatments) and k > 2
(multiple treatments)) that are defined as follows:
(k = 2) ： LS(y(n), y(n)) = ((yι(n) — yo(n)) — (yι(n) — yo(n)))2
(k> 2) : LS(y(n), yS)) = IIyS)- yS) ||2.
I and DI are then iteratively optimized with kI minibatches as follows:
kI
min — 72 Vite(x(n), y(n), y(n))
DI	n=1
kG
minɪ^ IVITE(x(n)，了⑺，VS))+ β^s 停⑺，y(n))J
n=1
where β ≥ 0 is a hyper-parameter.
Empirical justification for the inclusion of all the above losses can be found in Section 5.3 where we
explore the effect of training with and without each of the losses, see Table 6. We demonstrate there
that using a combination of both (for both G and I) gives the best performance. In addition to this,
by using a GAN loss for I we learn the conditional distribution of the potential outcomes rather than
just the expectations (which would be the case if we only used the supervised loss LIS . See Table 1
in Section 5.3). This allows us to capture the uncertainty of the outcomes, which is very important
in the medical setting when treatment decisions need to be made by doctors on the basis of these
types of estimations.
Due to the lack of ground truth, it is often difficult in causal inference tasks to optimize the hyper-
parameters. More specifically, we do not have access to the true loss function (either PEHE or MSE)
that we are trying to minimize, and so it is not possible to select hyper-parameters that minimise the
true loss. One of the advantages of GANITE, however, is that our target loss can be estimated
from the generated counterfactuals, unlike other methods such as in Shalit et al. (2017). Therefore,
we can directly optimize the hyper-parameters that minimize this estimated PEHE/MSE over the
hyper-parameter space - details of our hyper-parameter optimization and the achieved optimal hyper-
parameters are illustrated in the Appendix.
5	Experiments
5.1	Datasets
Due to the nature of the problem, it is very difficult to evaluate the performance of the algorithm
on real-world datasets - we never have access to the ground truth. Previous works, such as Shalit
et al. (2017); Louizos et al. (2017), use both semi-synthetic datasets (either the treatments or the
potential outcomes are synthesized) and datasets collected from randomized controlled trials (RCT)
to evaluate the ITE generator. We use two semi-synthetic datasets, IHDP and Twins, and one real-
world dataset, Jobs, to evaluate the performance of GANITE with various state-of-the-art methods.
These datasets are the same as the ones used in Shalit et al. (2017); Louizos et al. (2017). Below,
we give a detailed explanation of Twins. The details of IHDP and Jobs are well described in Shalit
et al. (2017); Hill (2011); Dehejia & Wahba (2002a) and the Appendix.
Twins: This dataset is derived from all births in the USA between 1989-1991 (Almond et al.
(2005)). Among these births, we only focus on the twins. We define the treatment t = 1 as being the
heavier twin (and t = 0 as being the lighter twin). The outcome is defined as the 1-year mortality.
For each twin-pair we obtained 30 features relating to the parents, the pregnancy and the birth:
marital status; race; residence; number of previous births; pregnancy risk factors; quality of care
6
Published as a conference paper at ICLR 2018
during pregnancy; and number of gestation weeks prior to birth. We only chose twins weighing
less than 2kg and without missing features (list-wise deletion). This creates a complete dataset
(without missing data). The final cohort is 11,400 pairs of twins whose mortality rate for the lighter
twin is 17.7%, and for the heavier 16.1%. In this setting, for each twin pair we observed both
the case t = 0 (lighter twin) and t = 1 (heavier twin); thus, the ground truth of individualized
treatment effect is known in this dataset. In order to simulate an observational study, we selectively
observe one of the two twins using the feature information (creating selection bias) as follows:
t|x ~ Bem(Sigmoid(WTX + n)) where WT ~ U((—0.1,0.1)30×1) and n ~ N(0,0.1).
5.2	Performance Metrics and Settings
We use four different performance metrics: expected Precision in Estimation of Heterogeneous
Effect (PEHE), average treatment effect (ATE) (Hill (2011)), policy risk (Rpol (π)), and average
treatment effect on the treated (ATT) (Shalit et al. (2017)). In this subsection, we only provide
definitions for PEHE and Rpol(π). ATE and ATT are explained (and reported) in the Appendix.
If both factual and counterfactual outcomes are generated from a known distribution (so that we are
able to compute the expectations of the outcomes, like in the IHDP dataset), and the treatment is
binary, the empirical PEHE (PEHE) can be defined as follows:
1N	2
ePEHE = N X (E(yi(n),yo(n))~μY(x(n))[yi(n) — y0(n)] — [y1 (n) — y0(n)])
n=1
where yι(n),yo(n) are treated and controlled outcomes drawn from the ground truth (μγ(x)) and
yι(n), yο(n) are their estimations.
If both factual and counterfactual outcomes are observed but the underlying distribution is unknown
(like in the Twins dataset), ^pehe can be defined as follows:
P EHE
1N	2
N X ([yi(n) — yo(n)] 一 [yι(n) — yo(n)])
n=1
If only factual outcomes are available but the testing set comes from a randomized controlled trial
(RCT), such as in the Jobs dataset, Policy risk (Rpol(π)) can be defined as follows (Shalit et al.
(2017)):
1N	k	1
Rpol⑺=N X [1 — (X [ ∣∏i ∩ Ti ∩ E|
n=1	i=1
yi(n) ×
x(n)∈Πi∩Ti∩E
l∏i ∩ E| 八i
|E|	〃
where Πi = {x(n) : i = argmaxy}, Ti = {x(n) : ti(n) = 1}, and E is the subset of RCT.
Each dataset is divided 56/24/20% into training/validation/testing sets. Hyper-parameters such as
the number of hidden layers α and β are chosen using Random Search (Bergstra & Bengio (2012)).
Details about the hyper-parameters are discussed in the Appendix. We run each algorithm 100 times
(except for the IHDP dataset, on which we run each algorithm 1,000 times which is the same setting
in Shalit et al. (2017)) with new training/validation/testing splits and report the mean and standard
deviation of the performances.
5.3	Experimental Results
In our first simulation we focus on demonstrating the effect that including each of the losses intro-
duced in Section 4 has on the performance of the algorithm. As is demonstrated below, inclusion of
all four losses gives the best results.
We generate a synthetic dataset as follows: we draw 10,000 10-dimensional feature vectors X 〜
N (010×1,0.5×(∑+∑τ)) where Σ ~ U (( —1,1)10×10). The treatment assignment is then generated
as t|x ~ Bern(Sigmoid(WTX + nt)) where wT ~ U((—0.1,0.1)10×1) and n ~ N(0,0.1). The
potential outcome vector is then generated as y|x 〜(WTX + ny)) where WT 〜 U((—1, 1)10×2)
and ny ~N (02×1,0.1 X 12×2). We use 8,000 instances for training and 2,000 instances for testing.
We repeat this 100 times and report the average ePEHE on the testing set.
7
Published as a conference paper at ICLR 2018
I I I I	PEHE	I	G	I		
	I	S loss only	GAN loss only	S and GAN loss ∣
I I S loss only	I .397 ± .011(15.6%)	.610 ± .017(45.1%)	.352 ± .012 (4.8%) ∣
I I I GAN loss only	I .607 ± .044(44.8%)	.513 ± .029 (34.7%)	.463 ± .015 (27.6%) ∣
I I SandGANloss	I .362 ± .011(7.5%)	.491 ± .030 (31.8%)	.335 ± .011 (-) I
Table 1: Performance with various combinations of GANITE (G: Counterfactual generator, I: ITE
generator, S loss: Supervised loss). Details of each cell are illustrated in the Appendix as Figures.
Figure 2: Performance comparison between GANITE and state-of-the-art methods as the selection
bias is varied (Kullback-Leibler divergence of treated with respect to controlled distributions)
Table 1 shows the performance of the GANITE architecture using different combinations of the four
losses in Section 4. For each generator component, we can use 3 different combinations of loss:
(1) Supervised loss (S loss) only (this reduces the corresponding component to a standard neural
network), (2) GAN loss only, (3) both S loss and GAN loss. The top-left most entry corresponds
to simply using a standard neural network to first impute the counterfactuals and then using another
standard neural network to learn an ITE estimator from the imputed dataset. As can be seen, this
already performs well, but by adding the GAN losses for both the imputation step and the estimation
step, a significant gain is shown (15.6%) (the bottom-right entry).
In Fig. 2 we show that GANITE is robust to an increased selection bias. We generate 10,000
10-dimensional treated samples from xι 〜 N(μι, 0.5 X (∑ + ΣT)) and controlled samples from
xo 〜N(μo, 0.5 × (∑ + ∑τ)) where Σ 〜U((-1,1)10×10). Fixing μo and varying μι, we generate
various datasets with different Kullback-Leibler divergences (KL divergences) of μ1 with respect to
μ0 . A higher KL divergence indicates a higher selection bias (a larger mismatch) between treated
and controlled distributions. As seen in Fig. 2, GANITE robustly outperforms state-of-the-art meth-
ods such as Shalit et al. (2017); Alaa & van der Schaar (2017) across the entire range of tested
divergences.
Binary treatments: In this section, we evaluate GANITE for estimating individualized treatment
effects for binary treatments. We use three datasets and report the PEHE both in-sample and out-
of-sample (for ATE and ATT see the appendix). We compare GANITE with least squares regres-
sion using treatment as a feature (OLS/LR1), separate least squares regressions for each treatment
(OLS/LR2), balancing linear regression (BLR) (Johansson et al. (2016)), k-nearest neighbor (k-NN)
(Crump et al. (2008)), Bayesian additive regression trees (BART) (Chipman et al. (2010)), random
forests (RForest) (Breiman (2001)), causal forests (C Forest) (Wager & Athey (2017)), balancing
neural network (BNN) (Johansson et al. (2016)), treatment-agnostic representation network (TAR-
NET) (Shalit et al. (2017)), counterfactual regression with Wasserstein distance (CFRW ASS) (Shalit
et al. (2017)), and multi-task gaussian process (CMGP) (Alaa & van der Schaar (2017)). We evaluate
both in-sample and out-of-sample performance in Table 2.
8
Published as a conference paper at ICLR 2018
Methods	Datasets (Mean ± Std)					
	IHDP (√PEHE)		TWins (√ ePEHE )		Jobs (Rpol(∏))	
	In-sample	Out-sample	In-sample	Out-sample	In-sample	Out-sample
	 GANITE	1.9 ± .4	2.4 ± .4	.289 ± .005	.297 ± .016	.13 ± .01	.14 ± .01
OLS/LRi	5.8 ± .3*	5.8 ± .3*	.319 ± .001*	.318 ± .007	.22 ± .00*	.23 ± .02*
OLS/LR2	2.4 ± .1	2.5 ± .1	.320 ± .002	.320 ± .003*	.21 ± .00*	.24 ± .01*
BLR	5.8 ± .3*	5.8 ± .3*	.312 ± .003*	.323 ± .018	.22 ± .01*	.25 ± .02*
k-NN	2.1 ± .1	4.1 ± .2*	.333 ± .001*	.345 ± .007*	.02 ± .00	.26 ± .02*
BART	2.1 ± .1	2.3 ± .1	.347 ± .009*	.338 ± .016	.23 ± .00*	.25 ± .02*
R Forest	4.2 ± .2*	6.6 ± .3*	.306 ± .002*	.321 ± .005	.23 ± .01*	.28 ± .02*
C Forest	3.8 ± .2*	3.8 ± .2*	.366 ± .003*	.316 ± .011	.19 ± .00*	.20 ± .02*
BNN	2.2 ± .1	2.1 ± .1	.325 ± .003*	.321 ± .018	.20 ± .01*	.24 ± .02*
TARNET	.88 ± .02	.95 ± .02	.317 ± .005*	.315 ± .003	.17 ± .01*	.21 ± .01*
CFRWASS	.71 ± .02	.76 ± .02	.315 ± .007*	.313 ± .008	.17 ± .01*	.21 ± .01*
CMGP	.65 ± .44	.77 ± .11	.320 ± .002*	.319 ± .008	.22 ± .03*	.24 ± .05
Table 2: Performance of ITE estimation with three real-world datasets. Bold indicates the method
with the best performance for each dataset. *: is used to indicate methods that GANITE shows a
statistically significant improvement over.
As can be seen in Table 2, GANITE achieves significant performance gains on the Twins and Jobs
datasets in comparison with state-of-the-art methods (both in-sample and out-of-sample 2). GANITE
achieves a much higher gain for individualized treatment effect estimations (such as WPEHE and
R-pot(∏)) than average treatment effect estimations (such as ^ate and EATT).On IHDP, GANITE
is competitive with BART and BNN but is outperformed by TARNET, CFRW ASS and CMGP. We
believe this is due to the fact that GANITE has a large number of parameters to be optimized and
IHDP is a relatively small dataset (747 samples). This belief is backed up by our significant gains
over these methods in both Twins and Jobs, where the number of samples is much larger, (11400
and 3212 samples, respectively).
Methods			Metric: MSEy			
	In Sample	Gain (%)	Out Sample	Gain (%)
	 GANITE	.0427 ± .0161	(-)	.0723 ± .0183	(一)
OLSzLRI	.0855 ± .0096	50.1%	.0871 ± .0142	17.0%
OLSzLR2	.0857 ± .0099	50.2%	.0883 ± .0147	18.1%
BLR	.0996 ± .0081*	57.1%	.1017 ± .0127	28.9%
KNN	.0930 ± .0101*	54.1%	.1008 ± .0236	28.3%
BART	.1097 ± .0084*	61.1%	.1037 ± .0283	30.3%
R Forest	.0442 ± .0069	3.4%	.0927 ± .0138	22.0%
C Forest	.1607 ± .0014*	73.4%	.1665 ± .0035*	56.6%
BNN	.0602 ± .0102	29.1%	.1031 ± .0145	29.9%
TaRNET	.0854 ± .0091	50.0%	.0879 ± .0030	17.7%
CFRWASS	.0896 ± .0036*	52.3%	.0894 ± .0057	19.1%
CMGP	.0844 ± .0073*	49.4%	.0793 ± .0191	8.3%
Table 3: Performance of multiple treatment effects estimations using Twins data. Bold indicates the
method with the best performance for each dataset. *: is used to indicate methods that GANITE
shows a statistically significant improvement over.
2Note that both “in-sample” and “out-sample” experiments evaluate the performance of I networks.
9
Published as a conference paper at ICLR 2018
Multiple treatments: GANITE is naturally defined for estimating multiple treatment effects. In this
subsection, we further preprocess the Twins data to create a dataset containing multiple treatments.
The multiple treatments are determined as follows: (1) t = 1: lower weight, female sex, (2) t = 2:
lower weight, male sex, (3) t = 3: higher weight, female sex, (4) t = 4: higher weight, male sex.
Therefore, we have 4 possible treatments for each sample.
We use the mean-squared error:
1N	2
MSEy = N × TIX X (yt(Xi) - yt(xi))
× | i | i=1 t∈Ti
as the performance metric to evaluate the multiple treatment effects (other metrics, such as PEHE, do
not have a natural extension to the multiple treatments setting). For comparison with state-of-the-art
methods, we naively extend BLR, C Forest, BNN, TARNET, CFRW ASS , and CMGP for multiple
treatments: one of the four treatments is selected as a control treatment and then the remaining three
create three separate binary ITE estimation problems (all against the same chosen control treatment).
As can be seen in Table 3 compared with Table 2 GANITE significantly outperforms other state-of-
the-art methods such as TARNET and CFRWASS (17.7% and 19.1% gains in terms of out sample
MSE, respectively). This is because, GANITE is designed for multiple treatments; the model is
jointly trained for all treatments. On the other hand, other methods are designed for binary treatments
and only naively extend to multiple treatments by training pairs of the available treatments.
5.4	Discussion
The experimental results provide various intuitions of the GANITE framework for ITE estimation.
First, GANITE can be easily extended to any number of treatments and performs well in this multiple
treatment setting. As can be seen in Section 4, however, a different loss for binary treatment and
multiple treatments must be used because PEHE is only defined for the binary treatment setting -
the MSE is not a natural generalisation of the PEHE and we believe exploration of possible loss
functions in this setting would be an interesting future work.
A further extension to this problem would be to consider a setting in which a patient may receive
several treatments (rather than just one). While this work can handle this problem naively (by
treating each combination of treatments as a separate ‘treatment’) we believe this would also be an
interesting problem to explore in a future work.
6	Conclusion
In this paper we introduced a novel method for dealing with the ITE estimation problem. We have
shown empirically that our method is more robust to large selection biases and performs better on
standard benchmark datasets than other state-of-the-art methods. Our method also achieves signifi-
cant performance gains over state-of-the-art when estimating ITE for multiple treatments because it
is able to jointly estimate the representations across the multiple treatments.
Acknowledgments
This work was supported by the Office of Naval Research (ONR) and the NSF (Grant number:
ECCS1462245, ECCS1533983, and ECCS1407712).
10
Published as a conference paper at ICLR 2018
References
Ahmed M Alaa and Mihaela van der Schaar. Bayesian inference of individualized treatment effects
using multi-task gaussian processes. NIPS, 2017.
Ahmed M Alaa, Michael Weisz, and Mihaela van der Schaar. Deep counterfactual networks with
propensity-dropout. ICML Workshop on Principled Approaches to Deep Learning, 2017.
Douglas Almond, Kenneth Y Chay, and David S Lee. The costs of low birth weight. The Quarterly
JournaIofEconomics,120(3):1031-1083, 2005.
Susan Athey and Guido Imbens. Recursive partitioning for heterogeneous causal effects. Proceed-
ings of the National Academy of Sciences, 113(27):7353-7360, 2016.
James Bergstra and Yoshua Bengio. Random search for hyper-parameter optimization. Journal of
Machine Learning Research, 13(Feb):281-305, 2012.
Leo Breiman. Random forests. Machine learning, 45(1):5-32, 2001.
Hugh A Chipman, Edward I George, Robert E McCulloch, et al. Bart: Bayesian additive regression
trees. The Annals of Applied Statistics, 4(1):266-298, 2010.
Richard K Crump, V Joseph Hotz, Guido W Imbens, and Oscar A Mitnik. Nonparametric tests for
treatment effect heterogeneity. The Review of Economics and Statistics, 90(3):389-405, 2008.
Rajeev H Dehejia and Sadek Wahba. Propensity score-matching methods for nonexperimental
causal studies. The review of economics and statistics, 84(1):151-161, 2002a.
Rajeev H Dehejia and Sadek Wahba. Propensity score-matching methods for nonexperimental
causal studies. The review of economics and statistics, 84(1):151-161, 2002b.
Vincent Dorie. Npci: Non-parametrics for causal inference, 2016.
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair,
Aaron Courville, and Yoshua Bengio. Generative adversarial nets. In Advances in Neural infor-
mation processing systems, pp. 2672-2680, 2014.
A Hannart, J Pearl, FEL Otto, P Naveau, and M Ghil. Causal counterfactual theory for the attribution
of weather and climate-related events. Bulletin of the American Meteorological Society, 97(1):
99-110, 2016.
Jennifer L Hill. Bayesian nonparametric modeling for causal inference. Journal of Computational
and Graphical Statistics, 20(1):217-240, 2011.
M Hofler. Causal inference based on CoUnterfactuals. BMC medical research methodology, 5(1):28,
2005.
Fredrik Johansson, Uri Shalit, and David Sontag. Learning representations for counterfactual infer-
ence. In International Conference on Machine Learning, pp. 3020-3029, 2016.
James K Kirklin, David C Naftel, Robert L Kormos, Lynne W Stevenson, Francis D Pagani,
Marissa A Miller, Karen L Ulisney, J Timothy Baldwin, and James B Young. Second intermacs
annual report: more than 1000 primary lvad implants. The Journal of heart and lung transplan-
tation: the official publication of the International Society for Heart Transplantation, 29(1):1,
2010.
Robert J LaLonde. Evaluating the econometric evaluations of training programs with experimental
data. The American economic review, pp. 604-620, 1986.
Christos Louizos, Uri Shalit, Joris Mooij, David Sontag, Richard Zemel, and Max Welling. Causal
effect inference with deep latent-variable models. NIPS, 2017.
Min Lu, Saad Sadiq, Daniel J Feaster, and Hemant Ishwaran. Estimating individual treatment effect
in observational data using random forest methods. arXiv preprint arXiv:1701.05306, 2017.
11
Published as a conference paper at ICLR 2018
Jared K Lunceford and Marie Davidian. Stratification and weighting via the propensity score in
estimation of causal treatment effects: a comparative study. Statistics in medicine, 23(19):2937-
2960, 2004.
Mehdi Mirza and Simon Osindero. Conditional generative adversarial nets. arXiv preprint
arXiv:1411.1784, 2014.
Kristin E Porter, Susan Gruber, Mark J Van Der Laan, and Jasjeet S Sekhon. The relative perfor-
mance of targeted maximum likelihood estimators. The International Journal of Biostatistics, 7
(1):1-34, 2011.
Donald B Rubin. Causal inference using potential outcomes: Design, modeling, decisions. Journal
of the American Statistical Association, 100(469):322-331, 2005.
Uri Shalit, Fredrik Johansson, and David Sontag. Estimating individual treatment effect: general-
ization bounds and algorithms. ICML, 2017.
Jeffrey A Smith and Petra E Todd. Does matching overcome lalonde’s critique of nonexperimental
estimators? Journal of econometrics, 125(1):305-353, 2005.
Peter Spirtes. A tutorial on causal inference. 2009.
Stefan Wager and Susan Athey. Estimation and inference of heterogeneous treatment effects using
random forests. Journal of the American Statistical Association, (just-accepted), 2017.
12
Published as a conference paper at ICLR 2018
Appendix
Pseudo-code of GANITE
Algorithm 1 Pseudo-code ofGANITE
while convergence of training loss of G and DG do
(1)	Counterfactual block optimization
Use kC minibatches, iteratively optimize G, DG by stochastic gradient descent (SGD)
kG
min - 72 VCF(x(n), t(n), VS))
DG
n=1
kG
mnX IVCF(X(n),t(n),y(n)) + αLG(yf(n),yn(n)(n))]
n=1
while convergence of training loss of I and DI do
(2)	ITE block optimization
Use kI minibatches, update I, DI by SGD
kI
min — E VITE(x(n), y(n), y(n))
DI	n=1
kG
π⅛n∑S IVITE (x(n)，y(n), y(n)) + βLIs (y(n), y(n))]
n=1
Detailed description of the datasets
IHDP
Hill (2011) provided a dataset for ITE estimation with the Infant Health and Development Program
(IHDP). The dataset consists of 747 children (t = 1: 139, t = 0 608) with 25 features. We generated
potential outcomes from setting A in the NPCI package Dorie (2016).
Jobs
Jobs data studied in LaLonde (1986) is composed of randomized data based on the National Sup-
ported Work program and non-randomized data from observational studies. We use a (random)
subset of the randomized data to evaluate the algorithms based on Rpol (π) and ATT. The dataset
consists of 722 randomized samples (t = 1: 297, t = 0: 425) and 2490 non-randomized samples
(t = 1: 0, t = 0: 2490), all with 7 features.
S ummary of the datasets
I	Data	I		Condition	I	Property ∣	
	I F I	CF	I Distribution ∣ RT-test	I T I	N	I S I
I	IHDP	I X I	X	I Known I	I Binary ∣	747	I 25 I
I	Jobs	I X I	X	I Unknown ∣ X	I Binary ∣	3212	I 7 I
I TWins-Binary	I X I	X	I Unknown ∣	I Binary ∣	11400	I 30 I
I Twins-Multiple	I X I	X	I Unknown ∣	I Multiple I	11400	I 30 I
Table 4: Summary of the datasets (N is the number of samples, s is the feature-dimension)
13
Published as a conference paper at ICLR 2018
	Datasets (Mean ± Std)					
Methods	IHDP (EATE)		Twins (^ate )		JobS(EATT )	
	In-sample ∣ Out-sample		In-sample	Out-sample	In-sample ∣ Out-sample	
	 GANITE	.43 ± .05	.49 ± .05	.0058 ± .0017	.0089± 0.0075	.01 ± .01	.06 ± .03
OLS/LR1	.73 ± .04*	.94 ± .06*	.0038 ± .0025	.0069 ± .0056	.01 ± .00	.08 ± .04
OLS/LR2	.14 ± .01	.31 ± .02	.0039 ± .0025	.0070 ± .0059	.01 ± .01	.08 ± .03
BLR	.72 ± .04*	.93 ± .05*	.0057 ± .0036	.0334 ± .0092*	.01 ± .01	.08 ± .03
k-NN	.14 ± .01	.90 ± .05*	.0028 ± .0021	.0051 ± .0039	.21 ± .01*	.13 ± .05
BART	.23 ± .01	.34 ± .02	.1206 ± .0236*	.1265 ± .0234*	.02 ± .00	.08 ± .03
R Forest	.73 ± .05*	.96 ± .06*	.0049 ± .0034	.0080 ± .0051	.03 ± .01	.09 ± .04
C Forest	.18 ± .01	.40 ± .03	.0286 ± .0035*	.0335 ± .0083*	.03 ± .01	.07 ± .03
BNN	.37 ± .03	.42 ± .03	.0056 ± .0032	.0203 ± .0071	.04 ± .01	.09 ± .04
TARNET	.26 ± .01	.28 ± .01	.0108 ± .0017*	.0151 ± .0018	.05 ± .02	.11 ± .04
CFRWASS	.25 ± .01	.27 ± .01	.0112 ± .0016*	.0284 ± .0032*	.04 ± .01	.09 ± .03
CMGP	.11 ± .10	.13 ± .12	.0124 ± .0051	.0143 ± .0116	.06 ± .06	.09 ± .07
Table 5: Performance of average treatment effect estimation. Bold represents the best performance.
*: statistically significant improvement of GANITE.
Performance metrics and the results of average treatment effect estimation
In this subsection, we use two different performance metrics for average treatment effect (ATE)
estimation: average treatment effect (ATE) (Hill (2011)), and average treatment effect on the treated
(ATT) (Shalit et al. (2017)).
If both factual and counterfactual outcomes are generated from a known distribution (and so we are
able to compute the expected value, such as in IHDP), the error of ATE (ATE) is defined as:
1N	1n 2
EATE = || N £Ey(n)〜μγ (x(n))[y (n)] - N Ey(n)||2
n=1	i=1
where y is the estimated potential outcome.
If both factual and counterfactual outcomes are observed but the underlying distribution is unknown
(like in Twins), EATE is defined as:
1N	1N
EATE = || N Ey(n) - N Ey(n)||2
n=1	n=1
If only factual outcomes are available (such as in Jobs), treatment is binary, and the testing set comes
from a randomized controlled trial (RCT), the true average treatment effect on the treated (ATT) is
defined as follows (Shalit et al. (2017)):
ATT
χi∈XX∩ EYI(Xi)- ∣ɪo⅛ XilLY0(Xi)
EATT = |ATT -
1
|T1 ∩ E|
X
YI(Xi)- Y0(Xi)I
Xi∈T1∩E
where T1is the subset corresponding to treated samples, T0is the subset corresponding to controlled
samples, andE is the subset corresponding to the randomized controlled trials.
Table. 5 shows the performance of the various algorithms with respect to these metrics.
As can be seen in Table 5, the GANITE achieves competitive performances for Average Treatment
Effect (ATE) estimation but not the best model to estimate ATE (except the Jobs dataset). However,
we do not believe that it is an important metric for distinguishing models where the task is predicting
14
Published as a conference paper at ICLR 2018
treatment effects on an individual level. The problem we address with GANITE is to estimate the
ITE. We used the ATE performance as a sanity check for our method - and believe it passes the
sanity check, being competitive with most other methods.
Hyper-parameter optimization
We optimize our hyper-parameters in GANITE by estimating the PEHE (MSE in the case of multiple
treatments) on the dataset generated by G and minimizing this with respect to the hyper-parameters.
The table below indicates specifics of this process, including the values we search over.
Table 6: Hyper-parameters of GANITE
Blocks	Sets of Hyper-parameters
Initialization	Xavier Initialization for Weight matrix, Zero initialization for bias vector.
Optimization	Adam Moment Optimization
Batch size (kG , kI)	{32, 64,128, 256}
Depth of layers	{1, 3, 5, 7, 9}
Hidden state dimension	{s, int(s/2), int(s/3), int(s/4), int(s/5)}
α, β	{0, 0.1,0.5,1, 2, 5,10}
For the hyper-parameter optimization of the benchmarks, we follow the hyper-parameter optimza-
tion code published in the github with their main code. For instance, the hyper-parameters of
CFRWASS are optimized using cfr_param_search.py file which is published in https:
//github.com/clinicalml/cfrnet
Optimal Hyper-parameters for each dataset
Table 7: Optimal Hyper-parameters of GANITE
Dataset	I Optimal Hyper-parameters			
IHDP	I kG	: 64, kI : 64, Depth of layers: 5, hdim : 8, α : 2, β : 5		
Jobs	IkG	: 128, kI	: 128, Depth of layers: 3, hdim: 4, α : 1, β :	5
Twins - Binary	I kG	: 128, kI	: 128, Depth of layers: 5, hdim : 8, α : 2, β :	2
Twins - Multiple	IkG	: 128, kI	: 128, Depth of layers: 7, hdim: 8, α : 1, β :	2
Additional Experiments
PERFORMANCE GAP BETWEEN G AND I
As explained in Section 4, I tries to learn the potential distribution that consists of factual outcomes
and counterfactual outcomes that are generated by G. To evaluate how well I is able to learn from
G, we compare the performance of G and I of the GANITE framework in Table 8 in terms of ITE
estimation. As can be seen in Table 8, the in-sample ITE estimation performance of GANITE (I)
is competitive with GANITE (G). It experimentally verifies that GANITE (I) learns well from the
outputs of GANITE (G).
Zero out the contribution of factual outcome and treatment
In this section, we use the trained G to compute ITE only with x. The learned function G needs
x, t, and yf as the inputs. Therefore, in order to compute ITE only with x, we should zero out the
contribution oft and yf in the G function. G tries to learn the conditional probability P(y|x, yf, t)
15
Published as a conference paper at ICLR 2018
I Methods	I	Datasets (Mean ± Std)	∣
I	I IHDP (√PEHE) I Twins (√^PEHE) I JobS (Rpoig) I
I GANrTE(I)	I	1.9 ± .4	I .289 ± .005 I .13 ± .01	∣
I GANITE (G)	I	1.4 ± .2	I .267 ± .004	∣	.10 ± .01	∣
Table 8: Performance comparison of in-sample ITE estimation between GANITE (I) and GANITE
(G) with three real-world datasets.
and what we want to compute is the conditional probability P(y|x). Therefore, zero out the impact
of t and yf can be done as follows.
P(y|x) =	P (y |x, t, yf)P (yf, t|x)dtdyf
The P (y|x, t, yf) is learned by G and P(yf, t|x) can be easily learned using supervised learning
framework (all the labels (yf, t) are available) with drop-out approach (to approximate the integral as
the sample mean of multiple samples). We use multi-layer perceptron (MLP) with multiple outputs
to learn the function P(yf, t|x). We called this as zero-out GANITE. We compare the performance
of zero-out GANITE to original GANITE in Table 9. As can be seen in Table 9, the performance of
original GANITE is marginally better than zero-out GANITE in three different datasets. We do not
believe that zero-out GANITE would be any simpler than our proposed structure - in both cases we
would still have 2 learning stages (Table 9 experimentally verifies this).
I	Methods	I	Datasets (Mean ± Std)			
	I	IHDP (√PEHE)	I	Twins (√^PEHE)		I	Jobs (Rpoi (∏))	I	
	I In-sample ∣ Out-sample ∣ In-sample	Out-sample	I In-sample ∣	Out-sample ∣
I	GANITE	I 1.9 ± .4 I 2.4 ± .4 I .289 ± .005	.297 ± .016	I .13 ± .01 I	.14 ± .01 I
I zero-out GANITE	I 2.2 ± .6 I 2.6 ± .7 I .297 ± .008	.308 ± .022	I .14 ± .02 I	.17 ± .01 I
Table 9: Performance comparison of ITE estimation between GANITE and zero-out GANITE with
three real-world datasets.
16
Published as a conference paper at ICLR 2018
Toy Example
Underlying potential outcome distributions
(b) Feature space (X)
Figure 3: (a) Underlying distribution of potential outcomes (Y), (b) Underlying distribution of
treatment assignments P (T |X), (c) Training data (factual outcomes) sampled from distributions
explained in (a) and (b), (d) Potential outcomes sampled from trained ITE generator (I).
-Aq SOEOsno p。S」0u。0
(JA) SOEO8no 0,ln6eL
Given samples With factual outcomes
0.2
0.4
0.6
0.8
1
0∙1
(c) Feature space (X)
Generated potential outcomes by I
0.2
0.4
0.6
0.8
1
(d) Feature space (X)
X T=0
O T=1
17
Published as a conference paper at ICLR 2018
Additional figures for Table 1
(a) G: S loss only, I: S loss only
(b) G: GAN loss only, I: S loss only
18
Published as a conference paper at ICLR 2018
(d) G: S loss only, I: GAN loss only
19
Published as a conference paper at ICLR 2018
(e) G: GAN loss only, I: GAN loss only
20
Published as a conference paper at ICLR 2018
(g) G: S loss only, I: S and GAN loss
21
Published as a conference paper at ICLR 2018
22