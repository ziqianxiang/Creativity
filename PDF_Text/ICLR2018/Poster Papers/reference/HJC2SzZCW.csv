title,year,conference
 Tensorflow: Large-scale machinelearning on heterogeneous distributed systems,2016, arXiv preprint arXiv:1603
 Spectrally-normalized margin bounds forneural networks,2017, In Advances in Neural Information Processing Systems
 Training a 3-node neural network is np-complete,1988, In MachineLearning: From Theory to Applications
 An analysis of deep neural networkmodels for practical applications,2016, CoRR
 Theloss surfaces of multilayer networks,2015, In Artificial Intelligence and Statistics
 Identifying and attacking the saddle point problem in high-dimensional non-convex opti-mization,2014, In NIPS
 Google vizier: A service for black-box optimization,1487, In Proceedings of the 23rd ACMSIGKDD International Conference on Knowledge Discovery and Data Mining
 Qualitatively characterizing neural network optimization prob-lems,2014, CoRR
 Explaining and harnessing adversarialexamples,2014, arXiv preprint arXiv:1412
 Towards deep neural network architectures robust to adversarialexamples,2014, arXiv preprint arXiv:1412
 Flat minima,1997, Neural Computation
 Ockham’s razor and bayesian analysis,1992, American Scientist
 A study of the effect of noiseinjection on the training of artificial neural networks,2009, In Neural Networks
 On large-batch training for deep learning: Generalization gap and sharp minima,2016, arXivpreprint arXiv:1609
 Adam: A method for stochastic optimization,2014, arXiv preprintarXiv:1412
 Convolutional deep belief networks on cifar-10,2010, 2010
 Adversarial machine learning at scale,2016, arXivpreprint arXiv:1611
 Deep neural networks as gaussian processes,2018, In International Conference on LearningRepresentations
 Bayesian interpolation,1991, 1991
 On the Number ofLinear Regions ofDeep NeuralNetworks,2014, Neural Information Processing Systems
 Universaladversarial perturbations,2016, arXiv preprint arXiv:1610
 In search of the real inductive bias: Onthe role of implicit regularization in deep learning,2015, Proceeding of the international Conferenceon Learning Representations workshop track
 Exploring gener-alization in deep learning,2017, CoRR
 Exponential expressivity in deepneural networks through transient chaos,2016, Neural Information Processing Systems
 Occam’s razor,2000, In NIPS
 Learning representations byback-propagating errors,1988, Cognitive modeling
 Robust large margin deepneural networks,2017, IEEE Transactions on Signal Processing
 Intriguing properties of neural networks,2013, arXiv preprint arXiv:1312
 Representation benefits of deep feedforward networks,2015, CoRR
 Robustness and generalization,2012, Machine learning
 Understanding deep learning requires re-thinking generalization,2016, International Conference on Learning Representations
