title,year,conference
 Towards principled methods for training generative adversarialnetworks,2017, In ICLR
 Wasserstein gan,2017, ICML
 Layer normalization,2016, arXiv:1607
 Manifold regularization: A geometric frame-work for learning from labeled and unlabeled examples,2006, JMLR
 The cramer distance as a solution to biased wasserstein gradi-ents,2017, CoRR
 The Cramer distance as a solution to biased Wasserstein gradi-ents,2017, arXiv:1705
 A kernel test of goodness of fit,2016, InICML 2016
 Good semi-suPervised learning that requires a bad gan,2017, arXiv:1705
 Adversarially learned inference,2017, ICLR
 Training generative neuralnetWorks via maximum mean discrePancy oPtimization,2015, In UAI
 Infinite-dimensional Optimization and Convexity,1983, The University ofChicago Press
 Generative adversarial nets,2014, In NIPS
 Measuring samPle quality with stein’s method,2015, In NIPS
 Im-proved training of wasserstein gans,2017, arXiv:1704
 Boundary-seeking generative adversarial networks,2017, arXiv:1702
 Batch normalization: Accelerating deep network training byreducing internal covariate shift,2015, Proc
 Amortisedmap inference for image super-resolution,2017, ICLR
 Learning multiple layers of features from tiny images,2009, Master’sthesis
 Improved semi-supervised learningwith gans using manifold invariances,2017, NIPS
 Gans for sequences of discrete elements withthe gumbel-softmax distribution,2016, arXiv:1611
 MMD GAN:towards deeper understanding of moment matching network,2017, NIPS
 Generative moment matching networks,2015, In ICML
 Stein variational descent as a gradient flow,2017, NIPS
 Stein variational gradient descent: A general purpose bayesian inferencealgorithm,2016, In Advances in Neural Information Processing Systems 29
 A kernelized stein discrepancy for goodness-of-fittests,2016, In Proceedings of the 33nd International Conference on Machine Learning
 Least squares generativeadversarial networks,2017, arXiv:1611
 Virtual adversarial training: aregularization method for supervised and semi-supervised learning,2017, arXiv:1704
 In Proc,2015, of 29th Conf
 Fisher gan,2017, arXiv:1705
 Mcgan: Mean and covariance feature matchinggan,2017, arXiv:1702
 Integral probability metrics and their generating classes of functions,1997, Advances inApplied Probability
 f-gan: Training generative neural samplersusing variational divergence minimization,2016, In NIPS
 Language generation with recur-rent generative adversarial networks without pre-training,2017, arXiv:1706
 Unsupervised representation learning with deepconvolutional generative adversarial networks,2015, arXiv:1511
 Adver-sarial generation of natural language,2017, arXiv:1705
 Regularization with stochastic transfor-mations and perturbations for deep semi-supervised learning,2016, In Advances in Neural InformationProcessing Systems
 Weight normalization: A simple reparameterization to accel-erate training of deep neural networks,2016, In Advances in Neural Information Processing Systems
 Unsupervised and semi-supervised learning with categorical generativeadversarial networks,2015, arXiv:1511
 AdversariallyregUlarized aUtoencoders for generating discrete strUctUres,2017, CoRR
