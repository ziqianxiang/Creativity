title,year,conference
 Multitask learning,1997, Machine Learning
 Catastrophic forgetting in connectionist networks,1999, Trends in cognitive sciences
 An Empirical Inves-tigation of Catastrophic Forgetting in Gradient-Based Neural Networks,2014, TR arXiv:1312
 A bit of progress in language modeling,2001, Comput
 Deep models under the GAN: in-formation leakage from collaborative deep learning,2017, CoRR
 Overcoming catastroPhic for-getting in neural networks,2016, CoRR
 Learning without forgetting,2016, CoRR
 CatastroPhic interference in connectionist networks: Thesequential learning problem,1989, The Psychology OfLearning and Motivation
 Semi-supervised knowledge transfer for deep learning from private training data,2017, In Proceedings of theInternational Conference on Learning Representations
 Using the output embedding to improve language models,2017, In Proceedingsof the 15th Conference of the European Chapter of the Association for Computational Linguistics:Volume 2
 Recurrent neural network training with dark knowl-edge transfer,2016, ICASSP 2016
 Efficient transferlearning schemes for personalized language modeling using recurrent neural network,2017, CoRR
