title,year,conference
 Evasion attacks against machine learning at test time,2013, In JointEuropean Conference on Machine Learning and Knowledge Discovery in Databases
 Towards evaluating the robustness of neural networks,2017, In IEEESymposium on Security and Privacy
 Adversarial examples are not easily detected: Bypassing tendetection methods,2017, arXiv preprint arXiv:1705
 A unified architecture for natural language processing: Deepneural networks with multitask learning,2008, In Proceedings of the 25th international conference onMachine learning
 Imagenet: A large-scalehierarchical image database,2009, In CVPR
 Robust physical-world attacks on machine learning models,2017, arXivpreprint arXiv:1707
 Explaining and harnessing adversarialexamples,2015, In International Conference on Learning Representations
 Towards deep neural network architectures robust to adversarialexamples,2014, arXiv preprint arXiv:1412
 Image-to-image translation withconditional adversarial networks,2017, CVPR
 Spatial transformer networks,2015, In NIPS
 Perceptual losses for real-time style transfer andsuper-resolution,2016, In European Conference on Computer Vision
 Measuring robustness of classifiers to geometric transformations,2017, Technical report
 ImageNet classification with deep convo-Iutional neural networks,2012, In Advances in neural information processing Systems
 The MNIST database of handwritten digits,1998, 1998
 Adversarial examples detection in deep networks with convolutional filterstatistics,2016, arXiv preprint arXiv:1612
 Delving into transferable adversarial exam-ples and black-box attacks,2017, In ICLR
 Deepfool: a simple andaccurate method to fool deep neural networks,2015, arXiv preprint arXiv:1511
 Universaladversarial perturbations,2016, arXiv preprint arXiv:1610
 Fast feature fool: A data independentapproach to universal adversarial perturbations,2017, arXiv preprint arXiv:1707
 Transferability in machine learning: fromphenomena to black-box attacks using adversarial samples,2016, arXiv preprint arXiv:1605
 Distillation as adefense to adversarial perturbations against deep neural networks,2016, In Security and Privacy (SP)
 Nonlinear total variation based noise removalalgorithms,1992, Physica D: Nonlinear Phenomena
 Intriguing properties of neural networks,2013, arXiv preprint arXiv:1312
 Intriguing properties of neural networks,2014, In International Conference onLearning Representations
 Rethink-ing the inception architecture for computer vision,2016, In Proceedings of the IEEE Conference onComputer Vision and Pattern Recognition
 Ensembleadversarial training: Attacks and defenses,2017, arXiv preprint arXiv:1705
 Feature squeezing: Detecting adversarial examples in deepneural networks,2017, arXiv preprint arXiv:1704
 Wide residual networks,2016, arXiv preprintarXiv:1605
 Learning deepfeatures for discriminative localization,2016, In Proceedings of the IEEE Conference on ComputerVision and Pattern Recognition
 View synthesisby appearance flow,2016, In ECCV
