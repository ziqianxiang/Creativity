title,year,conference
 Sparsely-connected neural networks: towardsefficient VLSI implementation of deep neural networks,2017, International Conference on LearningRepresentations (ICLR)
 A back-propagation algorithm with optimal use of hidden units,1989, In Advances inNneural Information Processing Systems
 Predicting parameters in deeplearning,2013, In Advances in Neural Information Processing Systems
 The Viterbi algorithm,1973, Proc
 Compressing deep convolutional net-works using vector quantization,2014, arXiv preprint arXiv:1412
 Comparing biases for minimal network construction withback-propagation,1989, In Advances in neural information processing systems
 Optimal brain surgeon and general networkpruning,1993, In Neural Networks
 Variational dropout and the local reparame-terization trick,2015, In Advances in Neural Information Processing Systems
 Optimal brain damage,1990, In D
 Viterbi-based efficient test data compression,2012, IEEE Trans
 Pruning filters forefficient convnets,2017, In International Conference on Learning Representations
 Implementing the Viterbi algorithm,1995, IEEE Signal Processing Magazine
 Bayesian compression for deep learning,2017, InAdvances in Neural Information Processing Systems 30 (NIPS 2017)
 Variational dropout sparsifies deep neuralnetworks,2017, arXiv preprint arXiv:1701
 VLSI architectures for modern error-correcting codes,2015, CRC Press
