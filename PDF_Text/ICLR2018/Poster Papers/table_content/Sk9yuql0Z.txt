Table 1: Top-1 classification accuracy on the clean images. We see that adding random resizing andrandom padding cause very little accuracy drop on clean (non-adversarial) images.
Table 2: Top-1 classification accuracy under the vanilla attack scenario. We see that randomizationlayers effectively mitigate adversarial effects for all attacks and all networks. Particularly, combiningrandomization layers with ensemble adversarial training (ens-adv-Inception-ResNet-v2) performsvery well on all attacks.
Table 3: Top-1 classification accuracy under the single-pattern attack scenario. We see that random-ization layers effectively mitigate adversarial effects for all attacks and all networks. Particularly,combining randomization layers with ensemble adversarial training (ens-adv-Inception-ResNet-v2)performs very well on all attacks.
Table 4: Top-1 classification accuracy under the ensemble-pattern attack scenario. Similar to vanillaattack and single-pattern attack scenarios, we see that randomization layers increase the accuracyunder all attacks and networks. This clearly demonstrates the effectiveness of the proposed ran-domization method on defending against adversarial examples, even under this very strong attackScenario.____________________________________________________________________________________Models	Inception-v3		ResNet-v2-101		IncePtion- ResNet-v2		ens-adv- IncePtion- ResNet-v2		target model	defense model	target model	defense model	target model	defense model	target model	defense modelFGSM-2	37.3%	41.2%	39.2%	44.9%	71.5%	74.3%	86.2%	88.9%FGSM-5	31.7%	34.0%	24.6%	29.7%	65.2%	67.3%	85.8%	87.5%FGSM-10	30.4%	32.8%	18.6%	21.7%	62.9%	64.5%	86.6%	87.9%DeePFool	0.6%	81.3%	0.9%	80.5%	0.9%	69.4%	1.6%	93.5%C&W	0.6%	62.9%	1.0%	74.3%	1.6%	68.3%	5.8%	86.1%image over the entire pattern number of all images. For the results presented in Table 4, we can seethat the adversarial examples generated under ensemble-pattern attack scenario are much stronger.
Table 5: Top-1 classification accuracy under one pixel padding scenario. This table shows that cre-ating different padding patterns (even 1-pixel padding) can effectively mitigate adversarial effects.
Table 6: Top-1 classification accuracy under one pixel resizing scenario. This table shows thatresizing image to a different scale (even 1-pixel scale) can effectively mitigate adversarial effects.
Table 7: Top-1 classification accuracy on clean images. We see that these four randomization meth-ods hardly hurt the performance on clean images. We use “++” to denote the addition of theproposed randomization layers, i.e., random resizing and random padding, and the results indi-cate that combined models still performs pretty good on clean images.
Table 8: Top-1 classification accuracy by using random brightness under the vanilla attack scenario.
Table 9: Top-1 classification accuracy by using random saturation under the vanilla attack scenario.
Table 10: Top-1 classification accuracy by using random hue under the vanilla attack scenario.
Table 11: Top-1 classification accuracy by using random contrast under the vanilla attack scenario.
Table 12: Top-1 classification accuracy on the clean images and the adversarial examples gener-ated under the vanilla attack scenario. Compared to the results in Tables 1 and 2, randomizationparameters applied here (i.e., resize between [267, 299), and pad to 299 × 299 × 3) is slightly worsethan the randomization parameters applied in the paper (i.e., resize between [299, 331), and pad to331 X 331 X 3).____________________________________________________________________________________________Models	IncePtion-v3	ResNet-v2- 101	Inception- ResNet-v2	ens-adv- Inception- ResNet-v2clean images	98.2%	97.5%	99T%	98.7%FGSM-2	63T%	650%	79.9%	95.0%FGSM-5	53.4%	48.3%	73.3%	94.0%FGSM-10	一	508%	405%	70.6%	93.4%DeepFool	97.2%	96.5%	96.0%	98.6%c&w	—	95.2% 一	95.2% 一	97.2% 一	97.8% 一Appendix C	Randomization Layers with Multiple IterationsIn this section, we show the relationship between the top-1 accuracy of the defense model and theiteration number performed on each image. Specifically, we choose ens-adv-Inception-ResNet-v2 +randomization layers as the defense model for the experiment. The same trend can be observed forother defense models.
