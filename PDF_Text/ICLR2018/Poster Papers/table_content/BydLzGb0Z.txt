Table 1: Average character error rate (CER, %) on WSJ dataset decoded with the beam size 10.
Table 2: Results for image captioning on the MS COCO dataset, the higher the better for all metrics(BLEU 1 to 4, METEOR, and CIDEr). We reimplement both Show&Tell (Vinyals et al., 2015) andSoft Attention (Xu et al., 2015) in order to add the twin cost. We use two types of images featuresextracted either with Resnet-101 or Resnet-152.
Table 3: (left) Test set negative log-likelihood for binarized sequential MNIST, where Hdenotes lower performance of our model with respect to the baselines. (right) Per-plexity results on WikiText-2 and Penn Treebank (Merity et al., 2017). AWD-LSTMrefers to the model of (Merity et al., 2017) trained with the official implementation athttp://github.com/salesforce/awd-lstm/.
