Table 1: Statistics and the examples of the datasets that Skim-RNN is evaluated on. SST refers to StanfordSentiment Treebank, SQuAD refers to Stanford Question Answering Dataset, CBT-NE refers to Named Entitydataset of Children Book Test, and CBT-CN refers to Common Noun of CBT.
Table 2: Text classification results on SST, Rotten Tomatoes, IMDb and AGNews. Results by standard LSTM,Skim-LSTM, LSTM-Jump (Yu et al., 2017), VCRNN (Jernite et al., 2017) and state of the art (SOTA). Evaluationmetrics are accuracy (Acc), skimming rate in % (Sk), reduction rate in the number of floating point operations(Flop-r) compared to standard LSTM, and benchmarked speed up rate (Sp) compared to standard LSTM. We usethe hidden size of 100 by default. SOTAs are from Kokkinos & Potamianos (2017), Miyato et al. (2017), Miyatoet al. (2017) and Zhang et al. (2015), respectively.
Table 3: A positive and a negative review from IMDb dataset. Black-colored words are skimmed (used smallerLSTM, d0 = 10), while blue-colored words are fully read (used bigger LSTM, d = 200).
Table 4: Results on Stanford Question Answering Dataset (SQuAD),using LSTM+Attention (2 layers of LSTM, d = 100, d0 = 20 bydefault) and BiDAF (d = 100, d0 = 50 by default).
Table 5: Question answering experiments with standard LSTM, Skim-LSTM, LSTM-Jump (Yu et al.,2017) and state of the art (SOTA) on NE and CN parts of Children Book Test (CBT). Hidden statesizes of all models are 200, except for LSTM-Jump, which used hidden state size of 512.
