Table 1: Fashion MNIST (attack = 8/25, defend = 32)NETWORK	TRAINING TECHNIQUE	CLEAN	RAND	FGSM	BIM	DEEP FOOL	CW	STRONGEST ATTACKResNet	Normal	93 / 93	89/71	38/24	00/00	06/06	20/01	00/00VGG	Normal	92 / 92	91 / 87	73/58	36/08	49/14	43/23	36/08	Adversarial FGSM	93/93	92 / 89	85 / 85	51/00	63/07	67/21	51/00	Adversarial BIM	92 / 91	92/91	84/79	76/63	82/72	81/70	76 / 63ResNet	Label Smoothing	93/93	91/76	73/45	16/00	29/06	33/14	16 / 00	Feature Squeezing	84 / 84	84/70	70 / 28	56/25	83/83	83/83	56 / 25	Adversarial FGSM + Feature Squeezing	88 / 88	87/82	80/77	70/46	86/82	84/85	70 / 46ResNet	Normal + PixeIDefend	88 / 88	88 / 89	85/74	83/76	87/87	87/87	83/74VGG	Normal + PixeIDefend	89 / 89	89 / 89	87/82	85/83	88/88	88/88	85 / 82ResNet	Adversarial FGSM + PixeIDefend	90 / 89	91/90	88/82	85/76	90/88	89/88	85 / 76	Adversarial FGSM +Adaptive PixelDefend	91 / 91	91/91	88/88	85/84	89/90	89/84	85 / 844.3	PixelDefend resultsWe carried out a comprehensive set of experiments to test various defenses versus attacks. Detailedinformation on experimental settings is provided in Appendix B. All experimental results are sum-marized in Tab. 1 and Tab. 2. In the upper part of the tables, we show how the various baselinedefenses fare against each of the attacks, while in the lower part of the tables we show how ourPixelDefend technique works. Each table cell contains accuracies on adversarial examples gener-ated with different attack. More specifically, for Fashion MNIST (Tab. 1), we tried attack = 8 and
Table 2: CIFAR-10 (attack = 2/8/16, defend = 16)NETWORK	TRAINING TECHNIQUE	CLEAN	RAND	FGSM	BIM	DEEP FOOL	CW	STRONGEST ATTACKResNet	Normal	92/92/92	92/87/76	33/15/11	10/00/00	12/06/06	07/00/00	07/00/00VGG	Normal	89/89/89	89/88/80	60/46/30	44/02/00	57/25/11	37/00/00	~37/00/00	Adversarial FGSM	91/91/91	90/88/84	88/91 / 91	24/07/00	45/00/00	20/00/07	~20/00/00	Adversarial BIM	87/87/87	87/87/86	80/52/34	74/32/06	79/48/25	76/42/08	~74/32/06ResNet	Label Smoothing	92/92/92	91/88/77	73/54/28	59/08/01	56/20/10	30/02/02	~30/02/01	Feature Squeezing	84/84/84	83/82/76	31/20/18	13/00/00	75/75/75	78/78/78	~13/00/00	Adversarial FGSM + Feature Squeezing	86/86/86	85/84/81	73/67/55	55/02/00	85/85/85	83/83/83	55/02/00ResNet	Normal + PixelDefend	85/85/88	82/83/84	73/46/24	71/46/25	80/80/80	78/78/78	~71/46/24VGG	Normal + PixelDefend	82/82/82	82/82/84	80/62/52	80/61/48	81/76/76	81/79/79	~80/61/48ResNet	Adversarial FGSM + PixelDefend	88/88/86	86/86/87	81/68/67	81/69/56	85/85/85	84/84/84	81/69/56	Adversarial FGSM + Adaptive PixelDefend	90/90/90	86/87/87	81/70/67	81/70/56	82/81/82	81/80/81	81/70/56to BIM attack itself. As in Tab. 2, it only gets 6% on BIM and 8% on CW when attack = 16. We alsoobserve that label smoothing, which learns smoothed predictions so that the gradient VXL(X, y) be-comes very small, is only effective against simple FGSM attack. Model-agnostic methods, such asfeature squeezing, can be combined with other defenses for strengthened performance. We observethat combining it with adversarial training indeed makes it more robust. Actually, Tab. 1 and Tab. 2show that feature squeezing combined with adversarial training dominates using feature squeezingalong in all settings. It also gets good performance on DeepFool and CW attacks. However, for iter-
