Table 1: These values are relative percentage changes in the average reward, where a value of 0 is noforgetting and a value of -1 corresponds to completely forgetting how to perform the task. A value> 0 corresponds to the agent learning how to better perform a task after training on other tasks.
Table 2: Final average reward for each method. Higher is better. Here, the final policy is aftertraining on gaps. the PLAiD method achieves on average higher values across tasks.
