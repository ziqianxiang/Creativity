Table 1: MNIST: Performance of the adversarially trained network against different adversariesfor ε = 0.3. For each model of attack we show the most successful attack with bold. The sourcenetworks used for the attack are: the network itself (A) (white-box attack), an indepentenly initializedand trained copy of the network (A')，architecture B from Tramer et al.(2017a) (B).
Table 2: CIFAR10: Performance of the adversarially trained network against different adversariesfor ε = 8. For each model of attack we show the most effective attack in bold. The source networksconsidered for the attack are: the network itself (A) (white-box attack), an independtly initialized andtrained copy of the network (A’), a copy of the network trained on natural examples (Anat).
Table 3: CIFAR10: black-box FGSM attacks. We create FGSM adversarial examples with ε = 8from the evaluation set on the source network, and then evaluate them on an independently initializedtarget network.
Table 4: CIFAR10: black-box PGD attacks. We create PGD adversarial examples with ε = 8 for 7iterations from the evaluation set on the source network, and then evaluate them on an independentlyinitialized target network.
Table 5: CIFAR10: white-box attacks for ε = 8. For each architecture and training method, we listthe accuracy of the resulting network on the full CIFAR10 evaluation set of 10,000 examples. TheFGSM random method is the one suggested by Tramer et al.(2017a), whereby We first do a smallrandom perturbation of the natural example, and the apply FGSM to that.
