Table 1: An approximate number of sentence pairs for each task.
Table 2: Evaluation of sentence representations on a set of 10 tasks using a linear model trained using each modelâ€™srepresentations. The FastSent and NMT En-Fr models are described in Hill et al. (2016), CNN-LSTM in Gan et al.
Table 3: Evaluation of word embeddings. All results were computed using Faruqui & Dyer (2014) with theexception of the Skipgram, NMT, Charagram and Attract-Repel embeddings. Skipgram and NMT results wereobtained from Jastrzebski et al. (2017)4. Charagram and Attract-Repel results were taken from Wieting et al.
Table 4: Supervised & low-resource classification accuracies on the Quora duplicate questiondataset. Accuracies are reported corresponding to the number of training examples used. The first6 rows are taken from Wang et al. (2017), the next 4 are from Tomar et al. (2017), the next 5 fromShen et al. (2017) and The last 4 rows are our experiments using Infersent (Conneau et al., 2017)and our models.
Table 5: Evaluation of sentence representations by probing for certain sentence characteristics and syntacticproperties. Sentence length, word content & word order from Adi et al. (2016) and sentence active/passive,tense and top level syntactic sequence (TSS) from Shi et al. (2016). Numbers reported are the accuracywith which the models were able to predict certain characteristics.
Table 6: COCO Retrieval with ResNet-101 featuresModel	STS12	STS13	STS14	STS15	STS16UnSuPerviSed/Transfer Approaches					SkiPthoUght+LN	30.8	24.8	31.4	31.0	-GloVe average	52.5	42.3	54.2	52.7	-GloVe TF-IDF	58.7	52.1	63.8	60.6	-GloVe + WR (U)	56.2	56.6	68.5	71.1	-Charagram-phrase	66.1	57.2	74.7	76.1	-Infersent	59.2	58.9	69.6	71.3	71.4+STN +Fr +De +NLI +L +STP	60.6	54.7	65.8	74.2	66.4Supervised Approaches					LSTM w/o output gates	51.0	45.2	59.8	63.9	-PP-PrQj	60.0	56.8	71.3	74.8	-Table 7: Evaluation of sentence representations on the semantic textual similarity benchmarks.
Table 7: Evaluation of sentence representations on the semantic textual similarity benchmarks.
Table 8: A query sentence and its nearest neighbors sorted by decreasing cosine similarity using our model.
