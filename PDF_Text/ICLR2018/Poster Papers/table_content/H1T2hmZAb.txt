Table 1: Classification error on CIFAR-10, CIFAR-100 and SVHN* using different complex activa-tions functions (zReLU, modReLU and CReLU). WS, DN and IB stand for the wide and shallow,deep and narrow and in-between models respectively. The prefixes R & C refer to the real andcomplex valued networks respectively. Performance differences between the real network and thecomplex network using CReLU are reported between their respective best models. All models areconstructed to have roughly 1.7M parameters except the modReLU models which have roughly2.5M parameters. modReLU and zReLU were largely outperformed by CReLU in the reported ex-periments. Due to limited resources, we havenâ€™t performed all possible experiments as the conductedones are already conclusive. A "-" is filled in front ofan unperformed experiment.
Table 2: Classification error on CIFAR-10, CIFAR-100 and SVHN* using different normalizationstrategies. NCBN, CBN and BN stand for a Naive variant of the complex batch-normalization, com-plex batch-normalization and regular batch normalization respectively. (R) & (C) refer to the use ofthe real- and complex-valued convolution respectively. The complex models use CReLU as activa-tion. All models are constructed to have roughly 1.7M parameters. 5 out of6 experiments using thenaive variant of the complex batch normalization failed with the apparition of NaNs during training.
Table 3: MusicNet experiments. FS is the sampling rate. Params is the total number of parameters.
Table 4: Speech Spectrum Prediction on TIMIT test set. CConv-LSTM denotes the Complex Con-volutional LSTM.
