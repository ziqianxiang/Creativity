Table 1: Examples mapping from continuous-valued inputs to quantized inputs, one-hot codes, andthermometer codes, with ten evenly-spaced levels.
Table 2: Comparison of adversarial robustness to white-box attacks on MNIST .
Table 3: Comparison of adversarial robustness to black-box attacks on MNIST .
Table 4: Comparison of adversarial robustness to white-box attacks on CIFAR-10 .
Table 5: Comparison of adversarial robustness to black-box attacks on CIFAR-10 .
Table 6: Comparison of adversarial robustness to white-box attacks on MNIST using 16 levels andwith various choices of the hyPerParameters ξ and δ for Algorithm 3. The models are evaluated onwhite-box attacks and on black-box attacks using a vanilla, clean trained model; both use LS-PGA.
Table 7: Comparison of adversarial robustness to white-box attacks on MNIST using a mix of cleanand adversarial examples.
Table 8: Comparison of adversarial robustness to black-box attacks on MNIST of various modelsusing a mix of clean and adversarial examples.
Table 9: Comparison of adversarial robustness on MNIST as the number of levels of discretizationis varied. All models are trained mix of adversarial examples and clean examples.
Table 10: Comparison of adversarial robustness to white-box attacks on CIFAR-10 of various modelsusing a mix of regular and adversarial training.
Table 11: Comparison of adversarial robustness to black-box attacks on CIFAR-10 of various modelsusing a mix of clean and adversarial examples.
Table 12: Comparison of adversarial robustness on CIFAR-10 as the number of levels of discretiza-tion is varied. All models are trained only on adversarial examples.
Table 13: Comparison of adversarial robustness on CIFAR-100. All adversarially trained modelswere trained on a mix of clean and adversarial examples.
Table 14: Comparison of adversarial robustness on SVHN.
