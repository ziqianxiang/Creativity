Table 1: Accuracy on adversarial examples generated with a FGSM misclassification attack on theMNIST test set with three values of E. Three different models were evaluated: A is full-precision,B is binary, and C is binary with a learned scalar. Models trained with, and without, adversarialtraining are shown. The ‘+’ suffix indicates the model was trained for the last 5 epochs with theprocedure from Kurakin et al. (2017a). All values averaged over four runs for models trained fromscratch.	________________________________________________________Model	KLayerI	E = 0.1	E = 0.2	E = 0.3A	64	74±4%	39±4%	22±5%	-128-	75±3%	34±2%	18±3%	-256-	74±1%	33±2%	17±3%B	64-	75±2%	64±3%	59±2%	-128-	85±1%	77±2%	70±2%	-256-	89±1%	83±1%	78±1%C	64-	56±7%	27±5%	15±3%	-128-	64±3%	26±9%	11±5%	-256-	73±2%	37±6%	16±3%A+	64	80±1%	62±1%	63±1%	-128-	83±1%	71±1%	72±1%	-256-	83±1%	71±2%	70±2%B+	64-	68±1%	32±5%	31±5%
Table 2: Accuracy on adversarial examples generated with a FGSM misclassification attack on theMNIST test set with three values of . Both full-precision (A+*) and scaled binary (C+*) modelswere trained with 40 iterations of PGD (Madry et al., 2017) for the last 5 epochs with with = 0.3.
Table 3: Carlini-Wagner L2 targeted attack on MNIST test set (90k images total) for binary modelsversus increasing capacity from left to right. All attacks were run for 100 iterations as all full-precision models were driven to have zero accuracy by this point. Models with ‘S’ prefix usedstochastic quantization.
Table 4: Accuracy of Oracle models on adversarial MNIST examples transferred from a Papernotet al. (2017b) style smooth substitute model black-box misclassification attack. Images from testset attacked with FGSM with = 0.3. FGSM adversarial training indicated by ’+’ suffix, and 20iterations of PGD training for 40 epochs by'+*' suffix.
Table 5: Accuracy of Oracle models on clean and adversarial CIFAR-10 examples transferred froma Papernot et al. (2017b) style smooth substitute model black-box misclassification attack withFGSM and E = 0.3. FGSM adversarial training indicated by'+' suffix.
Table 6: Error on clean MNIST test set for models with varying capacity and precision. A is full-precision, B is binary, and C is binary with a learned scalar applied to the ReLU in hidden layers. Allmodels were trained with Adam for 15 epochs with a batch size of 128 and a learning rate of 1e-3.
