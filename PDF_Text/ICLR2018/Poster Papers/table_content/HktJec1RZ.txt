Table 1: Translation results on the IWSLT 2014 German-English test set. MIXER Ranzato et al. (2015) uses aconvolutional encoder and simpler attention. LL (attention model with log likelihood) and BSO (beam searchoptimization) of Wiseman & Rush (2016), and LL, RF-C+LL, and AC+LL of Bahdanau et al. (2017) use aone-layer GRU encoder and decoder with attention. (RF-C+LL and AC+LL are different settings of actor-criticalgorithms combined With LL.) LL* stands for a well-tuned attention model With log likelihood With the sameword embedding size, and encoder and decoder size as NPMT.
Table 2: Examples of German-English translation outputs with their segmentations. We label the indexes ofthe words in the source sentence and we use those indexes to indicate where the output segment is emitted.
Table 3: Translation results on the IWSLT 2014 English-German test set.
Table 4: Examples of English-German translation outputs with their segmentations. The meanings of thesuperscript indexes and the “•” symbol are the same as those in Table 2.
Table 5: Translation results on the IWSLT 2015 English-Vietnamese tst2013 test set. The result of thesequence-to-sequence model with attention is obtained from an open source model provided by the authors.74	ConclusionWe proposed NPMT, a neural phrase-based machine translation system that models phrase structuresin the target language using SWAN. We also introduced a local reordering layer to mitigate the7https://github.com/tensorflow/nmt9Published as a conference paper at ICLR 2018source	1And 2I 3figured 4, 5this 6has 7to 8stop 9.
Table 6: Examples of English-Vietnamese translation outputs with their segmentations. The meanings of thesuperscript indexes and the “•” symbol are the same as those in Table 2.
Table 7: Analyze the effect of reordering layer window sizes in translation results on the IWSLT 2014 English-German test set.
Table 8: German-English phrase mapping results. We show the top 10 input, output phrase mappings in fivecategories (“One” stands for single word and “Many” stands for multiple words.). In the last column, Many →Many*, We remove the phrases With the “UNK” word as the “UNK” appears often.
Table 9: German-English longer phrase mapping results. We show the top 5 input, output phrase mappings fortWo categories: input and output phrases With three Words, and input and output phrases With four Words.
