Table 1: Order of magnitude input/output sizes and unigram recall for summarization datasets.
Table 2: Percentiles for different aspects of WikiSum dataset. Size is in number of words.
Table 3: Comparison of extractive method and corpus with L = 500, and the Transformer E-DmodelExtractor	Corpus	Test log-perplexity	ROUGE-Lcheating	combined	1.72975	59.3tf-idf	combined	2.46645	34.2tf-idf	citations-only	3.04299	22.6tf-idf	search-only	3.56593	2.8identity	combined	4.80215	4.05.3	Results and DiscussionThere are four main dimensions we vary in experiments in generating Wikipedia lead sections:1.	Extractive method: SumBasic, TextRank, tf-idf, identity, cheating extractor2.	Input corpus: citations, search results, combined3.	Abstractive model input length, L: We try values between 100 and 11000.
Table 4: Performance of best models of each model architecture using the combined corpus andtf-idf extractor.
Table 5: Linguistic quality human evaluation scores (scale 1-5, higher is better). A score signif- icantly different (according to the Welch Two Sample t-test, with p = 0.001) than the T-DMCA					model is denoted by *. Model	Focus	Grammar	Non- redundancy	Referential clarity	Structure and CoherenceT-DMCA (best)	4.5	4.6	4.2	4.5	4.2tf-idf -only	3.0*	3.6*	3.9	3.2*	2.7*seq2seq-attention	3.0*	3.4*	2.1*	3.4*	2.3*Table 6: Side-by-side for two models pair with large automatic metric gapsModel A	Model B	ROUGE-L A	ROUGE-L B	# Prefer B # Prefer AT-ED, L = 100	T-ED, L = 500	30.9	34.2	4.25T-ED, L = 500	T-DMCA-MoE-256, L = 7500	34.2	38.8	1.5method compared with our best abstractive model was the lack of structure and coherence in thesummaries.
Table 6: Side-by-side for two models pair with large automatic metric gapsModel A	Model B	ROUGE-L A	ROUGE-L B	# Prefer B # Prefer AT-ED, L = 100	T-ED, L = 500	30.9	34.2	4.25T-ED, L = 500	T-DMCA-MoE-256, L = 7500	34.2	38.8	1.5method compared with our best abstractive model was the lack of structure and coherence in thesummaries.
Table 7: Comparison of results with Sauper & Barzilay (2009). Note our results are reported forlead section, whereas Sauper & Barzilay report for articles.
