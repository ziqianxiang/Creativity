Table 1: Performance of the baseline detector (Hendrycks & Gimpel, 2016) using VGGNet. All val-ues are percentages and boldface values indicate relative the better results. For each in-distribution,we minimize the KL divergence term in (1) using training samples from an out-of-distributiondataset denoted by “seen”, where other “unseen” out-of-distributions were only used for testing.
Table 2: Classification test set accuracy of VGGNets on CIFAR-10 and SVHN datasets under vari-ous training losses.
Table 3: Expected calibration error (ECE) of VGGNets on CIFAR-10 and SVHN datasets undervarious training losses. The number of bins M is set to 20. All values are percentages and boldfacevalues indicate relative the better results.
Table 4: Performance of the baseline detector (Hendrycks & Gimpel, 2016) and ODIN detector(Liang et al., 2017) using AlexNet. All values are percentages and boldface values indicate rela-tive the better results. For each in-distribution, we minimize the KL divergence term in (1) usingtraining samples from an out-of-distribution dataset denoted by “seen”, where other “unseen” out-of-distributions were also used for testing.
Table 5: Performance of the baseline detector (Hendrycks & Gimpel, 2016) using VGGNets trainedby joint confidence loss with and without pull-away term (PT). All values are percentages and bold-face values indicate relative the better results.
Table 6: Performance of the baseline detector (Hendrycks & Gimpel, 2016) and ODIN detector(Liang et al., 2017) using VGGNet. All values are percentages and boldface values indicate relativethe better results.
