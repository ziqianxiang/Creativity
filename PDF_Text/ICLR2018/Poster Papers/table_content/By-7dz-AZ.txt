Table 1: Average model scores. ‘Inform.’ indicates (average) normalised root-mean-square error(NRMSE) in predicting z .
Table 2: (β-)VAE / InfoGAN architecture. Each network has 4 residual blocks (all but the firstand last rows). The input to each residual block is added to its output (with appropriate downsam-pling/upsampling to ensure that the dimensions match). Downsampling (J) is performed with meanpooling. ↑ indicates nearest-neighbour upsampling. When batch normalization (BN) is applied toconvolutional layers, per-channel normalization is used.
Table 3: Lasso regression results. (a) Disentanglement scores for each code variable. ‘W. Avg.’ ab-breviates weighted average. (b) Completeness scores for each generative factor. z0, . . . , z4 representazimuth, elevation, red, green and blue generative factors respectively. c) Test set NRMSE.
Table 4: Random forest regression results. Caption of Table 3 applies.
Table 5: Zeroshot performance. NRMSE in predicting unseen factor combinations.
