title,year,conference
 The vulnerability of learning to adversarial perturbation increases withintrinsic dimensionality,2017, In WIFS
 Adversarial examples are not easily detected: Bypassing tendetection methods,2017, arXiv preprint arXiv:1705
 Robust physical-world attacks on machine learning models,2017, arXivpreprint arXiv:1707
 Robustness of classifiers:from adversarial to random noise,2016, In NIPS
 Detecting adversarialsamples from artifacts,2017, arXiv preprint arXiv:1703
 Explaining and harnessing adversarialexamples,2014, arXiv preprint arXiv:1412
 Towards deep neural network architectures robust to adversarialexamples,2014, arXiv preprint arXiv:1412
 Local intrinsic dimensionality I: an extreme-value-theoretic foundation for simi-larity applications,2017, In SISAP
 Generalized expansion dimension,2012, InICDMW
 Finding nearest neighbors in growth-restricted metrics,2002, InSTOC
 Learning multiple layers of features from tiny images,2009, 2009
 Imagenet classification with deep convo-lutional neural networks,2012, In NIPS
 Handwritten digit recognition with a back-propagation net-work,1990, In Advances in neural information processing systems
 Scalable optimization of randomized operational decisions inadversarial classification settings,2015, In Artificial Intelligence and Statistics
 Adversarial examples detection in deep networks with convolutional filterstatistics,2016, arXiv preprint arXiv:1612
 Delving into transferable adversarial exam-ples and black-box attacks,2016, arXiv preprint arXiv:1611
 On detecting adversarialperturbations,2017, arXiv preprint arXiv:1702
 Readingdigits in natural images with unsupervised feature learning,2011, In NIPS workshop on deep learningand unsupervised feature learning
 Deep neural networks are easily fooled: High confi-dence predictions for unrecognizable images,2015, In CVPR
 clev-erhans v1,2016, 0
 Transferability in machine learning: fromphenomena to black-box attacks using adversarial samples,2016, arXiv preprint arXiv:1605
 Curtail: Charac-terizing and thwarting adversarial deep learning,2017, arXiv preprint arXiv:1709
 Accessorize to a crime:Real and stealthy attacks on state-of-the-art face recognition,2016, In Proceedings of the 2016 ACMSIGSAC Conference on Computer and Communications Security
 Intriguing properties of neural networks,2013, arXiv preprint arXiv:1312
 A boundary tilting persepective on the phenomenon of adversarialexamples,2016, arXiv preprint arXiv:1608
 The spaceof transferable adversarial examples,2017, arXiv preprint arXiv:1704
 Adversarial pertur-bations of deep neural networks,2016, Perturbations
 Feature squeezing: Detecting adversarial examples in deepneural networks,2017, arXiv preprint arXiv:1704
