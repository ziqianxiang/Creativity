title,year,conference
 On the generalization ability of on-linelearning algorithms,2004, IEEE Transactions on Information Theory
 Incorporating Nesterov MomentUm into Adam,2016, In Proceedings of 4th InternationalConference on Learning Representations
 Adam: A method for stochastic optimization,2015, In Proceedingsof 3rd International Conference on Learning Representations
 Imagenet classification with deep convo-lUtional neUral networks,2012, In Advances in Neural Information Processing Systems 25
 Adaptive boUnd optimization for online convexoptimization,2010, In Proceedings of the 23rd Annual Conference On Learning Theory
 RmsProp: Divide the gradient by a rUnning average of its recent mag-nitUde,2012, COURSERA: NeUral Networks for Machine Learning
 ADADELTA: An Adaptive Learning Rate Method,2012, CoRR
 Online convex programming and generalized infinitesimal gradient ascent,2003, InProceedings of the 20th International Conference on Machine Learning
