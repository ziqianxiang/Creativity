Table 1: Quantitative evaluation of various methods on the task of navigating using a single imageof goal in an unseen environment. Each column represents a different run of our system for adifferent initial/goal image pair. Our full GSP model takes longer to reach the goal on average givena successful run but reaches the goal successfully at a much higher rate.
Table 2: Quantitative evaluation of TurtleBot’s performance at following visual demonstrations intwo scenarios: maze and the loop. We report the % of landmarks reached by the agent across threeruns of two different demonstrations. Results show that our method outperforms the baselines. Notethat 3 more trials of the loop demonstration were tested under significantly different lighting condi-tions and neither model succeeded. Detailed results are available in the supplementary materials.
Table 3: Quantitative evaluation of our proposed GSP and the baseline models at following visualdemonstrations in VizDoom 3D Navigation. Medians and 95% confidence intervals are reported fordemonstration completion and efficiency over 50 seeds and 5 human paths per environment type.
Table 4: Quantitative evaluation of TurtleBot’s performance at following visual demonstrations intwo conditions: maze and the loop. The fraction denotes how many landmarks it reaches out of thetotal number of landmarks in the full demonstration. The bracketed number represents the numberof actions the agent took to reach its farthest landmark.
Table 5: Quantitative evaluation of our proposed GSP and the baseline models at following visualdemonstrations in VizDoom 3D Navigation. Means and standard errors are reported for demonstra-tion completion and efficiency over 50 seeds and 5 human paths per environment type.
