Figure 1: Baseline dilated convolutional network architecture (see description in app. B).
Figure 2: Best viewed in color. Dilated convolutional networks (left) and the mode trees underlying theirrespective tensor decompositions (right). (a) Baseline architecture - dilation 2l-1 in layer l. (b) Architectureobtained by swapping dilations of even and odd layers.
Figure 4: Best viewed in color. (a) Two mode trees T and T along With a possible choice of mixture nodes(same as in fig. 3(a)). (b) Sample of the resulting hybrid mode trees (def. 2).
Figure 5: Experimental results - increasing the number of interconnections between hidden layers of differentdilated convolutional networks improves accuracy, with no additional cost in computation or model capacity.
Figure 6: Mode tree T along with a specific index set I and the resulting tiling Î˜(I; T ) (def. 3).
Figure 7: Best viewed in color. Two mode trees T and T With a possible choice of mixture nodes (same asin fig. 3(a) and 4(a)), along with a particular formed hybrid tree H . An index set I and its complement Ic aretiled into more pieces by H than they are by T and T, leading the former to generate grid tensors with highermatricization ranks (theorem 1).
