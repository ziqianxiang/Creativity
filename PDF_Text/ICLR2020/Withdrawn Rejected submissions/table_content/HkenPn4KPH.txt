Table 1: Example images and dataset statistics. For few-shot learning experiments the classes aresplit into base, Val, and novel set. Image representations learned on base set are evaluated on thenovel set while Val set is used for cross-validation. These datasets vary in the number of classes butare orders of magnitude smaller than ImageNet dataset.
Table 2: Performance on few-shot transfer task. The mean accuracy (%) and the 95% confidenceinterval of 600 randomly chosen test experiments are reported for various combinations of lossfunctions. The top part shows the accuracy on 5-way 5-shot classification tasks, while the bottompart shows the same on 20-way 5-shot. Adding self-supervised losses to the ProtoNet loss improvesthe performance on all seven datasets on 5-way classification results. On 20-way classification, theimprovements are even larger. The last row indicates results with a randomly initialized network.
Table 3: Performance on few-shot transfer task with degraded inputs or less training data.
Table 4: Performance on few-shot transfer task using different meta-learners. Using jigsawpuzzle loss gives improvements across different meta-learners on most of the datasets. ProtoNetwith jigsaw loss performs the best on all five datasets.
Table 5: Performance on standard classification task. Per-image accuracy (%) on the test set arereported. Using self-supervision improves the accuracy of a ResNet18 network trained from scratchover the baseline of supervised training with cross-entropy (softmax) loss on all five datasets.
Table 6: Composition of the unlabeled datasets selected from a pool of images used in Figure 4c.
