Table 2: Error rate on Yelp-5.
Table 1: Error rates on CIFAR-10.
Table 3: Comparison between methods using different models where PyramidNet is used withShakeDrop regularization. Fully supervised Wide-ResNet-28-2 and PyramidNet+ShakeDrop havean error rate of 5.4 and 2.7 when trained on 50,000 examples without RandAugment. On CIFAR-10, with only 4,000 labeled examples, UDA matches the performance of the two fully supervisedmodels. On SVHN, UDA also matches the performance of our fully supervised model trained on73,257 examples without RandAugment, which has an error rate of 2.84.
Table 4: Error rates on text classification datasets. In the fully supervised settings, the pre-BERT SO-TAs include ULMFiT (Howard & Ruder, 2018) for Yelp-2 and Yelp-5, DPCNN (Johnson & Zhang,2017) for Amazon-2 and Amazon-5, Mixed VAT (Sachan et al., 2018) for IMDb and DBPedia. Allof our experiments use a sequence length of 512.
Table 5: Top-1 / top-5 accuracy on ImageNet with 10% and 100% of the labeled set. We use imagesize 224 and 331 for the 10% and 100% experiments respectively.
Table 6: Ablation study for Training Signal Annealing (TSA) on Yelp-5 and CIFAR-10. The shownnumbers are error rates.
Table 7: Error rate (%) for CIFAR-10.
Table 8: Error rate (%) for SVHN.
