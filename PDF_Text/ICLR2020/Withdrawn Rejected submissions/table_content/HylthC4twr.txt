Table 1: Average test accuracy on original train/val/test splits (50 times)	Cora	Citeseer Pubmed Reddit	PPI	2Circles BA-HighDGI GCN SGC	83.1 ± 0.2	72.1 ± 0.1	80.1 ± 0.2	94.5 ± 0.3	99.2 ± 0.1	85.2 ± 0.6	54.6 ± 1.8 80.0 ± 1.8	69.6 ± 1.1	79.3 ± 1.3	-	-	84.9 ± 0.8	58.9 ± 2.2 77.6 ± 2.2	65.6 ± 0.1	78.4 ± 1.1	94.9 ± 0.2	89.0 ± 0.1	53.5 ± 1.4	55.5 ± 1.3gfNN-low gfNN-high	82.3 ± 0.2	71.8 ± 0.1	79.2 ± 0.2	94.8 ± 0.2	89.3 ± 0.5	85.6 ± 0.8	55.4 ± 2.3 24.2 ± 1.9	22.5 ± 2.2	43.6 ± 1.3	10.5 ± 2.6	86.6 ± 0.1	48.3 ± 3.5	96.2 ± 1.08 DiscussionRecently, Kampffmeyer et al. (2019) observed that GCN models might have too strong Laplaciansmoothing effect (low-frequency in our terms) for zero-shot learning application. This is an exampleof an application where the frequency of data might be band-limited or higher than benchmarkgraph datasets. Some other possible scenario in a social network might include more complex andhigh-frequency nature that GNN models like GCN cannot learn well. One possible solution to thisscenario is to use both low- and high-pass filters like gfNN and select the model by validation data orlearn from both filters.
Table 2: Real-world benchmark datasets and synthetic datasets for vertex classificationDataset	Nodes	Edges	Features (X)	(μx ,σχ)	Classes	Train/Val/TestCora	2,708	5,278	1,433	(0.0007, 0.0071)	7	140/500/1,000Citeseer	3,327	4,732	3,703	(0.0003, 0.0029)	6	120/500/1,000Pubmed	19,717	44,338	500	(0.0019, 0.0087)	3	60/500/1,000Reddit	231,443	11,606,919	602	-	41	151,708/23,699/55,334PPI	56,944	818,716	50	-	121	44,906/6,514/5,524Two Circles	4,000	10,000	2	-	2	80/80/3,840BA-High	200	2000	50	(0,1)	2	10/10/180The Two Circle dataset is visually presented in Figure 7 (test accuracies are shown in the corner).
