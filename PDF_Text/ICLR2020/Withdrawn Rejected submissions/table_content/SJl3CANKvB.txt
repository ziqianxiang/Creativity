Table 1: Recall@k on Cub-200-2011 and Cars-196	Cub-200-2011						CarS-196					Recall@k(%)	1	2	4	8	16	32	1	2	4	8	16	32Clusetring(Oh Song et al. (2017))	48.2	61.4	71.8	81.9	-	-	58.1	70.6	80.3	87.8	-	-HDC(Oh Song et al. (2017))	53.6	65.7	77.0	85.6	91.5	95.5	73.7	83.2	89.5	93.8	96.7	98.4Margin(Wu et al. (2017))	63.6	74.4	83.1	90.0	94.2	-	79.6	86.5	91.9	95.1	97.3	-Smart Mining(Harwood et al. (2017))	49.8	62.3	74.1	83.3	-	-	64.7	76.2	84.2	90.2	-	-HDL(Ge (2018))	57.1	68.8	78.7	86.5	92.5	95.5	81.4	88.0	92.7	95.7	97.4	99.0ABIER(Opitz et al. (2018))	ɪr"	68.7	78.3	86.2	91.9	95.5	82.0	89.0	93.2	96.1	97.8	98.7ABE(Kim et al. (2018))	60.6	71.5	79.8	87.4	-	-	85.2	90.5	94.0	96.1	-	-HAP2S_E(Yu et al. (2018))	56.1	68.3	79.2	86.9	-	-	74.1	83.5	89.9	94.1	-	-MS(Wang et al. (2019))	65.7	77.0	86.3	91.3	94.8	97.0	84.1	90.4	94.0	96.5	98.0	98.9DRO-TopKM (Ours)	67.4	77.7	85.9	91.6	95.0	97.3	86.0	91.7	95.0	97.3	98.5	99.2DRO-TopKB(Ours)	68.1	78.4	86.0	91.4	95.1	97.6	85.4	91.0	94.2	96.5	98.0	99.0DRO-TopK-PNM (Ours)	67.3	77.6	85.7	91.2	95.0	97.7	86.1	91.7	95.1	97.1	98.4	99.1DRO-TopK-PNB(Ours)	67.6	77.9	86.0	91.8	95.2	97.7	86.2	91.7	95.8	97.4	98.6	99.3DRO-KLM (Ours)	67.7	78.0	86.1	91.8	95.6	97.8	86.4	91.9	95.4	97.5	98.7	99.3datasets and K is tuned from {160, 200, 240, 280} on Cub-200-2011 and Cars-196, and selectedfrom {640, 960, 1280, 1600, 1920} on In-Shop.
Table 2: Recover of MS loss and LS loss on Cub-200-2011 and Cars-196	Cub-200-2011						Cars-196					Recall@K(%)	1	2	4	8	16	32	1	2	4	8	16	32MS	55.6	67.7	77.4	86.3	92.1	95.8	73.2	81.5	87.6	92.6	-	-LS	56.8	67.9	77.5	85.6	91.2	95.2	69.7	79.3	86.2	91.1	-	-DRO-KL-G-γ = 1	56.4	68.3	78.9	86.3	91.7	95.8	70.5	79.8	86.6	91.6	94.9	97.1DRO-KL-G-γ = 0.1	56.8	68.7	79.0	86.6	92.1	95.9	72.5	81.9	88.1	92.3	95.4	97.3DRO-KL-G-γ = 0.01	57.0	69.4	79.9	87.0	92.3	95.9	73.1	82.2	88.8	93.4	96.2	98.0DRO-KL-G-γ = 0.001	56.7	68.5	79.0	87.3	92.6	96.0	75.0	83.4	89.5	93.7	96.6	98.3In Section 3.3, we theoretically show that LS loss and MS loss can be viewed as special cases ofour DRO framework. In this experiment, we aim to empirically demonstrate that our framework isgeneral enough and recovers LS loss. Specifically, we would show 1) when γ = 1, our frameworkperforms similarly to LS loss, as stated in Section 3.3, 2) our framework can be seen as a generalizedLS loss by treating γ as a hyper-parameter, and 3) our generalized LS loss outperforms MS loss, eventhough the performance of the ordinary LS loss is inferior to that of MS loss.
Table 3: ReCall@k on In-ShoPRecall@K	1	10	20	30	40	50FashionNet(Liu et al. (2016))	53.7	73.0	76.0	77.0	79.0	80.0HDC(Oh Song et al. (2017))	62.1	84.9	89.0	91.2	92.3	93.1HDL(Ge (2018))	80.9	94.3	95.8	97.2	97.4	97.8ABIER(Opitz et al. (2018))	83.1	95.1	96.9	97.5	97.8	98.0ABE(Yu et al. (2018))	87.3	96.7	97.9	98.2	98.5	98.7MS(Wang et al. (2019))	89.7	97.9	98.5	98.8	99.1	99.2DRO-TopKM (Ours)	91.0	98.1	98.7	99.0	99.1	99.2DRO-TopKB (Ours)	90.7	97.7	98.4	98.8	99.0	99.1DRO-TopK-PNM (Ours)	91.3	98.0	98.7	98.9	99.1	99.2DRO-TopK-PNB(Ours)	91.1	98.1	98.6	98.8	99.0	99.2DRO-KLM (Ours)	90.8	98.0	98.6	99.0	99.1	99.2Table 4: Recover of MS loss and LS loss on In-ShopRecall@K(%)	1	10		20	30	40	50MS	79.8	94.9	96.8	97.6	97.9	98.3LS	82.6	94.1	95.6	96.4	96.9	97.4DRO-KL-G-γ = 1	84.8	95.9	97.3	97.9	98.2	98.5DRO-KL-G-γ = 0.1	85.1	96.1	97.5	98.0	98.3	98.5DRO-KL-G-γ = 0.01	85.8	96.2	97.9	97.8	98.2	98.4
Table 4: Recover of MS loss and LS loss on In-ShopRecall@K(%)	1	10		20	30	40	50MS	79.8	94.9	96.8	97.6	97.9	98.3LS	82.6	94.1	95.6	96.4	96.9	97.4DRO-KL-G-γ = 1	84.8	95.9	97.3	97.9	98.2	98.5DRO-KL-G-γ = 0.1	85.1	96.1	97.5	98.0	98.3	98.5DRO-KL-G-γ = 0.01	85.8	96.2	97.9	97.8	98.2	98.4DRO-KL-G-γ = 0.001	85.7	96.1	97.4	97.9	98.2	98.54.2.2	Capacity to Handle Pair Imbalance.
