Table 1: Averaged testing classification error rate(%) of the sequential MNIST experiment.
Table 2: Classification error rate(%) of experiments on recurrent convolutional neural networks.
Table 3: Hyperparameters for the language modeling experiments. The batch size is 40 for theword level datasets and 128 for the character level datasets. The last four hyperparameters with * iscorresponding to the implementation of the Salesforce Language Model Toolkit and the details canbe find in salesforce (2019)12Under review as a conference paper at ICLR 2020Performance is evaluated using the perplexity (PPL) metric for the word level datasets and bits-per-character (BPC) metric for the character level datasets. The code of this experiment is adapted fromthe Salesforce Language Model Toolkit(salesforce (2019)).
Table 4: Classification error rate(%) of experiments on recurrent convolutional neural networks.
Table 5: Notationsnotation	objectzeros」ike(w)	Return a all-zero matrix whose size is the same as W% 一	Modulus operatorshape(w)	Return the size of matrix Ww.sum(0)	Return sum of the matrix W along axis 0. If w is a weight matrix of NN , this operation sums the weight that connect to the same input and returns the vector with the same size as input node size.
Table 6: Training Time of 1 epoch (seconds) in different experiments	PTB	Wikitext-2	PTB-c	enwik8	s-MNIST-28	s-MNIST-98	C10-RCNN96	C10-RCNN128	C10-RCNN160Path-SGD	53.9	90.2	79.8	1407	10.2	13.5	-	-	-SGD	31.4	66.0	61.5	1054	8.5	10.9	56.0	74.0	125.5G-SGD	33.9	-688	63.8	1103	92	115	60.9	798	1349Extra time cost	2.5	28	-23-	-49-	07	0.6	4.9	58	9.4time cost increase rate	8.0%	4.2%	3.7%	4.6%	8.2% 一	5.5% 一	8.7% 一	7.8%	7.5%B.4	Stack RNN and Convolutional LayerFor stack RNN, there are multiple layers of hidden nodes. Specifically, there are more than one W hand Wr. Note that the skeleton method is also held. Thus the Mask-Matrix-Constructor algorithmscan also be applied by generating mask matrix for all the weight matrix Wh according to the skeletonmethod.
Table 7: Averaged testing classification error rate(%) of the sequential MNIST experiment.
