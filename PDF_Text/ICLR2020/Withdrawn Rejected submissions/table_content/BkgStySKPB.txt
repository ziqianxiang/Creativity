Table 1: Top-1 classification accuracy on 1000 classes of ImageNet Deng et al. (2009) with single crop. Wecompare our CMC method with other unsupervised representation learning approaches by training 1000-waylogistic regression classifiers on top of the feature maps of each layer, as proposed by Zhang et al. (2016).
Table 2: Single crop top-1 classification accuracy on ImageNet. We evaluate CMC with ResNet-50, ResNet-101,or ResNet-50 x2 as encoder for each of the tWo vieWs (L and ab).
Table 3: Results on the task of predictingsemantic labels from L channel representa-tion which is learnt using the patch-basedcontrastive loss and all 4 views. We compareCMC with Random and Supervised baselines,which serve as lower and upper bounds re-spectively. Th core-view paradigm refers toFig. 3(a), and full-view Fig. 3(b).
Table 4: We compare predictive learningwith contrastive learning by evaluating thelearned encoder on unseen dataset and task.
Table 5: Classification accuracies on STL-10 by using a two layer MLP as classifier for evaluating therepresentations learned by a small AlexNet. For all methods we compare against, we include the numbersthat are reported in the DIM (Hjelm et al., 2019) paper, except for SplitBrain, which is our reimplementation.
Table 6: Test accuracy (%) on UCF-101 which evaluates task transferability and on HMDB-51 which evaluatestask and dataset transferability. Most methods either use single RGB view or additional optical flow view, whileVGAN explores sound as the second view. * indicates different network architecture.
Table 7: Performance on the task of using single view v to predict the semantic labels, where v can be L, ab,depth or surface normal. Our CMC framework improves the quality of unsupervised representations towardsthat of supervised ones, for all of views investigated. This uses the full-graph paradigm Fig. ??(b).
Table 8: The variant of AlexNet architecture used in our CMC for STL-10 (only half is presenthere due to splitting). X spatial resolution of layer, C number of channels in layer; K conv orpool kernel size; S computation stride; P padding; * channel size is dependent on the input source,e.g. 1 for L channel and 2 for ab channel.
Table 9: AlexNet architecture used in CMC for ImageNet (only half is present here due tosplitting). X spatial resolution of layer, C number of channels in layer; K conv or pool kernelsize; S computation stride; P padding; * channel size is dependent on the input source, e.g. 1 for Lchannel and 2 for ab channel.
Table 10: Encoder architecture used in our CMC for playing with different views on NYUDepth-V2. X spatial resolution of layer, C number of channels in layer; K conv or pool kernelsize; S computation stride; P padding; * channel size is dependent on the input source, e.g. 1 for L, 2for ab, 1 for depth, 3 for surface normal, and 1 for segmentation map.
