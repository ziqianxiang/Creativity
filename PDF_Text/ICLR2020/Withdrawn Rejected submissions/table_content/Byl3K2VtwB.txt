Table 1: Statistics of the datasetsDataset	Nodes	Edges	Features	ClassesCora (Sen et al., 2008)	2,708	5,429	1,433	7Citeseer (Sen et al., 2008)	3,327	4,732	3,703	6Pubmed (Namata et al., 2012)	19,717	44,338	500	3Wiki (Grover & Leskovec, 2016)	4,777	184,812	n/a	40bound of A then if H is a binary matrix and elements of A and A are i.i.d then given an ε ≥ 0,P(| L-L | ≤ ε) ≥ 1 —2k(eχτ~>( (nG )+eχτ~ι(—(——mε) )+eχτ~ι(———n_ε— )+eχ∙∩( — m_ε—) +Pu L | ≤ ε) ≥ 1 2k(eχp( i28k2(b-a)2 ) + exp( I28k2(b-a)2 ) + exp( 64k(b-a)2 ) + exp( 64k(b-a)2 ) +22eχp(-mk ) + 2exP(-n)).
Table 2: Node classification results.
Table 3: DMC vs. DGI on cluster qualityFigure 2: Effect of batch size5.2	Community detection evaluationSetup. Next, we aim to show the applicability of normcut loss to a graph-like setting, such aslearning word embeddings. Here, the nodes are words and the connection weight between twowords is measured by the following “kernel” function:k(wi, wj)log(#(wi, wj))ιog( log(#Wi)log(#Wj),0)where #wi is the number of times word wi appears in the corpus, while #(wi , wj ) is the numberof times the words appear together. The adjacency matrix obtained using the above function isthe PPMI matrix, a well-established concept in NLP (Levy & Goldberg, 2014). Following Yin& Shen (2018), we construct a word corpus of 10000 words that appear >100 times in the Text8corpus (Mahoney, 2011). Words are said to appear together if they are within a window of five.
Table 4: Test PrecisionTable 5: Top-5 words for the first five dimensions	Precision	Dim #1	Dim #2	Dim #3	Dim #4	Dim #5NNSC	35.85%	medieval	created	flight	full	internetSC	47%	earliest	features	pilot	job	networkOIWE	91.01%	scholars	dc adaptation batman	navy	fair offered calling	clientDMC	95.24%	renaissance classical		passenger aviation		server serversFigure 3: Embedding size vs. #communitiesFigure 4: Hierarchy of words/topics5.3	Effects of minibatch trainingSetup. We evaluate the effects of minibatch training on the classification accuracy on three citationnetworks by varying the batch size from 20 to 500.
Table 5: Top-5 words for the first five dimensions	Precision	Dim #1	Dim #2	Dim #3	Dim #4	Dim #5NNSC	35.85%	medieval	created	flight	full	internetSC	47%	earliest	features	pilot	job	networkOIWE	91.01%	scholars	dc adaptation batman	navy	fair offered calling	clientDMC	95.24%	renaissance classical		passenger aviation		server serversFigure 3: Embedding size vs. #communitiesFigure 4: Hierarchy of words/topics5.3	Effects of minibatch trainingSetup. We evaluate the effects of minibatch training on the classification accuracy on three citationnetworks by varying the batch size from 20 to 500.
