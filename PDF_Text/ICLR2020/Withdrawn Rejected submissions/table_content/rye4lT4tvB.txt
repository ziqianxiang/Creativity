Table 1: mIoU for feature level study. σ2 (di,j) is vari- ance of pixel dilation sampling.					Table 2: mIoU for pattern aggregation study. VGG-16 backbone is combined with FCN-8s and ResNet-101 is with Deeplab v3+.		conv3	conv4	conv5	σ (di,j)	MIOU			X-			1.96 X 10-4	63.9				X		1.84 × 10-4	64.7	Aggregation	VGG-16	ResNet- 1 0 1		X	4.01 × 10-6	66.5	Markov	-66.5-	77.2X	X		2.45 × 10-4	65.4	Gated	65.5	76.7	X	X	1.24 × 10-4	66.1	Recurrent	65.3	75.6X	X	X	1.93 × 10-4	65.9	Backbone	64.7	75.1alh=σ(Walhli-,j1+UlaYil,-j1)	(5)where σ(∙) is the sigmoid activation and ◦ means element-wise multiplication. In this way, layersare not strictly dependent following their hierarchical order and will impact dilation sampling in amore complicated way.
Table 3: mIoU of cases with availabledilation options change.
Table 4: mIoU for VOC 2012 validation set.
Table 5: mIoU for CityScape validation set.
Table 6: Accuracies for lage-scale image classification on ILSVRC 2012 and corresponding modelcomplexities. p# means model size and Ap# is the number of weights introduced by PAD-Nets;(△p#)/(p#) is the percentage of model size that PAD-Nets have increased.
Table 7: Top-1 Accuracy for Fine-Grained Visual Classification on different databases.
Table 8: PAD-Nets on semantic segmentation tasks. (Section 4.5)PAD-Nets	Architectures Description	ConfigurationsFCN8s/FCN32s + VGG-16	Conv-5 is modified to PAD layers. Dilation variables are learnt with 1, 2, and 4.	Follow FCN8s/FCN32s training scheme with no augmentation or image pre-processing or post-processing. FCN8s is trained in at once mode.
Table 9: PAD-Nets on large-scale image classification tasks. (Section 5.1)PAD-Nets	Architectures Description	ConfigurationsVGG-16	Only Conv-5 is incorporated with PAD units. The dilation variables are learnt based on 1, 2, and 4.	Follow Pytorch ImageNet training default settings with 128 batch size and 120 epochs.
Table 10: PAD-Nets on fine-grained image classification tasks. (Section 5.2)PAD-Nets	Architectures Description	ConfigurationsResNet-50	The last three convolution layers in Layer-2 block are modified with PAD units. The dilation variable are learnt based on 1,2, and 3.	The setting follows that of DLA reported in Yu et al. (2018) with two crop sizes, i.e., 224 and 448.
Table 11: PAD-FCN8s IoUs on VOC-2012 across all classes	background	aeroplane	bicycle	bird	boat	bottle	bus	car	cat	chair	cowPAD-FCN8s	0.914	0.833	0.388	0.751	0.627	0.740	0.802	0.744	0.805	0.252	0.805FCN8s	0.908	0.798	0.363	0.776	0.581	0.742	0.775	0.749	0.799	0.292	0.712	dining table	dog	horse	motorbike	person	potted plant	sheep	sofa	train	tv/monitor	mIoUPAD-FCN8s	0.474	0.724	0.729	0.783	0.791	0.510	0.729	0.370	0.773	0.600	0.665FCN8s	0.375	0.684	0.673	0.765	0.780	0.490	0.760	0.344	0.789	0.572	0.647B	More results on semantic segmentation and fine-grainedIMAGE CLASSIFICATIONMore quality results on semantic segmentation tasks are shown in Figure 7, Figure 8, and Figure9. More class IoUs are included in Table 11, Table 12, Table 13, and Table 14. For fine-grainedclassification tasks, detailed feature maps for fine-grained image classification are shown in Figure11.
Table 12: PAD-ResNet-101 IoUs on VOC-2012 across all classes	background	aeroplane	bicycle	bird	boat	bottle	bus	car	cat	chair	cowPAD-ResNet-101	0.932	0.838	0.393	0.848	0.622	0.756	0.908	0.848	0.918	0.373	0.874ResNet-101	0.922	0.770	0.388	0.853	0.626	0.698	0.913	0.836	0.886	0.225	0.835	dining table	dog	horse	motorbike	person	potted plant	sheep	sofa	train	tv/monitor	mIoUPAD-ResNet-101	0.584	0.879	0.851	0.805	0.833	0.554	0.852	0.534	0.835	0.648	0.772ResNet-101	0.568	0.862	0.791	0.810	0.815	0.452	0.764	0.461	0.824	0.691	0.75113Under review as a conference paper at ICLR 2020Table 13: PAD-DRN-54 IoUs on VOC-2012 across all classes	background	aeroplane	bicycle	bird	boat	bottle	bus	car	cat	chair	cowPAD-DRN-54-D	0.927	0.823	0.384	0.845	0.668	0.729	0.915	0.838	0.852	0.294	0.876DRN-54-D	0.921	0.799	0.345	0.846	0660	0.723	0.868	0.848	0.884	0.313	0.820	dining table	dog	horse	motorbike	person	potted plant	sheep	sofa	train	tv/monitor	mIoUPAD-DRN-54-D	0.568	0.839	0.836	0.814	0.813	0.491	0.805	0.434	0.781	0.693	0.772DRN-54-D	0.528	0.840	0.801	0.805	0.800	0.475	0.739	0.492	0.750	0.675	0.754Table 14: PAD-ResNet-101 IoUs on Cityscapes across all classes	road	sidewalk	building	wall	fence	pole	light	sign	vegetation	terrainPAD-ResNet-101	0.984	0.867	0.934	0.610	0.654	0.668	0.737	0.817	0.930	0.653ResNet-101	0.983	0.860	0.931	0.625	0.638	0.648	0.726	0.801	0.929	0.659
Table 13: PAD-DRN-54 IoUs on VOC-2012 across all classes	background	aeroplane	bicycle	bird	boat	bottle	bus	car	cat	chair	cowPAD-DRN-54-D	0.927	0.823	0.384	0.845	0.668	0.729	0.915	0.838	0.852	0.294	0.876DRN-54-D	0.921	0.799	0.345	0.846	0660	0.723	0.868	0.848	0.884	0.313	0.820	dining table	dog	horse	motorbike	person	potted plant	sheep	sofa	train	tv/monitor	mIoUPAD-DRN-54-D	0.568	0.839	0.836	0.814	0.813	0.491	0.805	0.434	0.781	0.693	0.772DRN-54-D	0.528	0.840	0.801	0.805	0.800	0.475	0.739	0.492	0.750	0.675	0.754Table 14: PAD-ResNet-101 IoUs on Cityscapes across all classes	road	sidewalk	building	wall	fence	pole	light	sign	vegetation	terrainPAD-ResNet-101	0.984	0.867	0.934	0.610	0.654	0.668	0.737	0.817	0.930	0.653ResNet-101	0.983	0.860	0.931	0.625	0.638	0.648	0.726	0.801	0.929	0.659	sky	person	rider	car	truck	bus	train	motorcycle	bicycle	mIoUPAD-ResNet-101	0.954	0.840	0.674	0.956	0.810	0.919	0.808	0.722	0.796	0.807ResNet-101	0.953	0.833	0.658	0.953	0.797	0.912	0.815	0.720	0.787	0.801Figure 7: Semantic segmentation results on Pascal VOC 2012.
Table 14: PAD-ResNet-101 IoUs on Cityscapes across all classes	road	sidewalk	building	wall	fence	pole	light	sign	vegetation	terrainPAD-ResNet-101	0.984	0.867	0.934	0.610	0.654	0.668	0.737	0.817	0.930	0.653ResNet-101	0.983	0.860	0.931	0.625	0.638	0.648	0.726	0.801	0.929	0.659	sky	person	rider	car	truck	bus	train	motorcycle	bicycle	mIoUPAD-ResNet-101	0.954	0.840	0.674	0.956	0.810	0.919	0.808	0.722	0.796	0.807ResNet-101	0.953	0.833	0.658	0.953	0.797	0.912	0.815	0.720	0.787	0.801Figure 7: Semantic segmentation results on Pascal VOC 2012.
