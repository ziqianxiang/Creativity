Table 1: Evaluated on MultiWOZ2.1, the proposed approach achieves better performance than TSCP (Lei et al.,2018), especially with higher performance gain in multi-domain dialogues. The best result in each metric ishighlighted in bold.
Table 2: Joint Accuracy metric on MultiWOZ2.1. Except for TSCP, the baseline results are as reported by Ericet al. (2019). Best results are highlighted in bold.
Table 3: We experiment with several model variants by controlling following changes: whether to includedialogue state in previous turn PrevBS as an input or not, length of dialogue history (in turns) as 1 (latest turnonly) or all possible dialogue turns, number of attention layers in slot-level module NdSst, domain-level moduleNdDst, and joint domain-slot module NdDsSt . The best result in each metric is highlighted in bold.
Table 4: Numbers of unique tokens in source and target sequences.
Table 5: Summary of MultiWOZ dataset (Budzianowski et al., 2018) by domainDomain	#dialogues			train	val	testRestaurant	3,817	438	437Hotel	3,387	416	394Attraction	2,718	401	396Train	3,117	484	495Taxi	1,655	207	195Police	245	0	0Hospital	287	0	0A.2 BaselinesWe describe a list of baseline models in DST setting and context-to-text generation setting.
Table 6: Summary of slots and DB details by domain in the MultiWOZ dataset (Budzianowski et al., 2018)Domain	Slots	#entities	DB attributesRestaurant	inf_area, inf_food, inf_name, inf_pricerange, 110	id, address, area, food, introduction, inf_bookday, inf_bookpeople, inf_booktime,	name, phone, postcode, pricerange, sig- req_address, req_area, req_food, req_phone,	nature, type req_postcodeHotel	injarea, inf_internet, injname, inf_parking, 33	id, address, area, internet, parking, sin- inf_pricerange, inf_stars, inf_type, inf_bookday,	gle, double, family, name, phone, post- inf_bookpeople, inf_bookstay, req_address,	code, pricerangeâ€™, takesbookings, stars, req_area, req_internet, req_parking, req_phone,	type req_postcode, req_stars, req_typeAttraction	injarea, inf_name, inf_type, req_address,	79	id, address, area, entrance, name, phone, req_area, req_phone, req_postcode, req_type	postcode, pricerange, openhours, typeTrain	inJarriveBy, inform_day, injdeparture,	2,828	trainID, arriveBy, day, departure, desti- inf_destination, inf_leaveAt, inf_bookpeople,	nation, duration, leaveAt, price req_duration, req_priceTaxi	inJarriveBy, injdeparture, inf_destination, -	- inf_leaveAt, req_phonePolice	injdepartment,	req_address, req_phone, -	- req_postcodeHospital	req_address, req_phone, req_postcode	-	-tion to obtain final vectors to predict individual state slots separately. The output vector is used tomeasure a score of a predefined candidate set for each slot.
Table 7: Additional experiment results on MultiWOZ2.1. Compared to the baseline TSCP (Lei et al., 2018),our model performs better in most of the metrics in each domain. For state tracking, the metrics are calculatedfor domain-specific slots of the corresponding domain at each dialogue turn. For task completion and responsegeneration, the metrics are computed for only single-domain dialogues with the corresponding domain in eachrow. The best result in each metric and domain is highlighted in bold.
Table 8: Additional experiment results of state tracking on MultiWOZ2.1. In each domain, the metrics arecalculated for domain-specific slots of the corresponding domain at each dialogue turn. The best result in eachdomain is highlighted in bold.
Table 9: Performance for context-to-text generation setting on MultiWOZ2.0. The baseline results are as reportedin the benchmark leaderboard.
Table 10: Complete results of an example multi-domain dialogue, including the input of past system responseSt-1 and current user utterance Ut, and the predicted dialogue belief state BSt and system response St. Thedialogue includes 11 turns in total and extends across 3 domains sequentially: restaurant, attraction, and taxi.
