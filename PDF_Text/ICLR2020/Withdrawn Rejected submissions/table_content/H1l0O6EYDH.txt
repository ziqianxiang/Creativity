Table 1: Performance result of block units in Figure 2 on CIFAR100 dataset. All the experimentedmodels are based on ShuffleNet-V2 with width hyper-parameter 1.1x which we customized to makethe number of output channels in Stage2, 3, 4 as 128, 256, 512, respectively for fair comparisonwith DWHT which requires 2‚Åø input channels.  We replaced all of 13 stride 1 basic blocks (i.e.  (a)block) in baseline model with (b), (c), (d) blocks, respectively. (c)-DWHT w/ ReLU denotes CTPClayer in (c) block is based on DWHT, while (d)-DCT w/o ReLU denotes CTPC layer in (d) block isbased on DCT.
Table 2: Performance result of hierarchically applying our optimal block on CIFAR100 dataset. Allthe models are based on MobileNet-V1 with width hyper-parameter 1x.  We replaced both stride 1,2 blocks in the baseline model with the optimal block that consist of [3     3 depthwise convolution -Batch Normalization - ReLU - CTPC - Batch Normalization] in series.
Table 3:  Quantitative comparison between the baseline model and our DCT/DWHT-based modelson WIDER FACE validation dataset.
Table 4: Quantitative comparison between the baseline model and our proposed DCT/DWHT-basedmodels on FDDB dataset. AP means the true positive rate at 1,000 false positives and all the modelswere evaluated with discontinuous criterion in FDDB dataset.
