Table 1: Testing result on homologous/non-homologous test setTest Set	NO Error	Loc Errors	Cls Errors	Loc and Cls ErrorsHomologous	96.44%	2.5%	1.24%	0.18%Non-homologous	96.26%	2.52%	1.44%	0.22%4.4 Translation Model ExperimentsWe regard the conversion of symbol sequences with location information into LaTeX sequencesas a translation process and solve this problem with the encoder-decoder model, which is of greatsignificance. As far as we know, we are the first to use the encoder-decoder model to solve the two-dimensional translation problem. As is shown in Section 4.2, we have 81214 different LaTeX mathequations, 71214 expressions for training, 5000 for validation and 5000 for test. In order to trainthe encoder-decoder model, we run our YOLOv3 model on the training dataset, validation datasetand test dataset, respectively and store the symbols’ position and classification information of everyimage. After filtering the wrong cases, we obtained 69405 training expressions, 4826 validationexpressions and 4822 test expressions.
Table 2:	Testing result of the encoder-decoder modelTest Set WER ExpRate ≤ 1%	≤ 2%Homologous	0.044	78.0%	83.1% 85.9%Non-homologous	0.045	77.9%	83.1% 85.7%decoder model is the position and classification information of symbols, not the image. Obviously,changes in image style has little influences on the encoder-decoder model.
Table 3:	Testing result of the homologous test datasetModel	WER	ExpRate	≤ 1%	≤ 2%Ours	0.048	74.3%	79.7%	82.8%Im2LaTex	0.054	73.37%	78.5%	80.9%Table 4:	Testing result of the non-homologous test datasetModel WER ExpRate ≤ 1%	≤ 2%Ours	0.050	74.1%	78.21%	81.5%Im2LaTex	0.1355	53.9%	60.9%	64.56%In Table 3, we can observe that our model achieved an ExpRate of 74.3%, while its WER was only0.048 for homologous test set, which is slightly better than Im2LaTex. However, Table 4 shows theresults of the non-homologous test dataset. The ExpRate of our model is 74.1%, 20.3 percentagepoints higher than Im2LaTex. The ≤ 1% error percentages ( 78.21%) and ≤ 2% error percent-ages ( 81.5%) of our model is also much higer than Im2LaTex. From these indicators, our systemoutperforms Im2LaTex for homologous test dataset, and is evidently better than Im2LaTex for non-homologous test dataset. So our model has better generalization, which is superior to Im2LaTex forrecognizing MEs with real backgrounds.
Table 4:	Testing result of the non-homologous test datasetModel WER ExpRate ≤ 1%	≤ 2%Ours	0.050	74.1%	78.21%	81.5%Im2LaTex	0.1355	53.9%	60.9%	64.56%In Table 3, we can observe that our model achieved an ExpRate of 74.3%, while its WER was only0.048 for homologous test set, which is slightly better than Im2LaTex. However, Table 4 shows theresults of the non-homologous test dataset. The ExpRate of our model is 74.1%, 20.3 percentagepoints higher than Im2LaTex. The ≤ 1% error percentages ( 78.21%) and ≤ 2% error percent-ages ( 81.5%) of our model is also much higer than Im2LaTex. From these indicators, our systemoutperforms Im2LaTex for homologous test dataset, and is evidently better than Im2LaTex for non-homologous test dataset. So our model has better generalization, which is superior to Im2LaTex forrecognizing MEs with real backgrounds.
