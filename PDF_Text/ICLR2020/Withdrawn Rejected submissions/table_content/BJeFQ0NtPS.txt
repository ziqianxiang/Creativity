Table 1: Mean Opinion Score (MOS) ratings with 95% confidence intervals for comparison.
Table 2: Attention error counts for text-to-spectrogram models on the 100-sentence test set. Oneor more mispronunciations, skips, and repeats count as a single mistake per utterance. The non-autoregressive ParaNet (17-layer decoder) with attention mask obtains the fewest attention errors intotal. For ablation study, we include the results for two additional ParaNet models. They have 6 and12 decoder layers and are denoted as ParaNet-6 and ParaNet-12, respectively.
Table 3: Mean Opinion Score (MOS) ratings with 95% confidence intervals for comparison.
Table 4: Hyperparameters of autoregressive seq2seq model and non-autoregressive seq2seq model inthe experiment.
