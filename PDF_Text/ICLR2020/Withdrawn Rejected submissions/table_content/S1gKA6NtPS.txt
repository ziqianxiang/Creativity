Table 1: Performance comparison of DSR and GP-based symbolic regression on 16 symbolic regressionbenchmarks. Bold values represent statistical significance (two-sample t-test, p < 0.05). Errors representstandard deviation (n = 100 for Nguyen benchmarks; n = 10 for Constant benchmarks).
Table 2: Benchmark symbolic regression problem specifications. U(a, b, n) denotes n random points uni-formly sampled between a and b for each input variable. Training and testing datasets use different randomseeds.
Table 3: DSR hyperparameters		Table 4: GP hyperparametersParameter	Value	Parameter	ValueBatch size	1,000	Population size	1,000Iterations	1,000	Generations	1,000Learning rate (α)	0.0003	Fitness function	NRMSEEntropy coefficient (λH)	0.08	Initialization method	FullComplexity coefficient (λC )	0	Selection type	TournamentMoving average coefficient (β)	0.5	Tournament size (k)	3Risk factor ()	0.1	Crossover probability	0.5 Mutation probability	0.1	Minimum subtree depth (dmin)	0		Maximum subtree depth (dmax)	2	12Under review as a conference paper at ICLR 2020For benchmarks with constants, constants are optimized using BFGS with an initial guess of 1.0 for eachconstant. We ensured that all benchmarks with constants do not get stuck in a poor local optimum whenoptimizing with BFGS and the candidate functional form is correct. Since floating point constants cannotbe recovered exactly, for benchmarks with constants we manually determined correctness of the functionalform by inspection. Since constant optimization is a computational bottleneck, we limited each expressionto three constants for both DSR and GP experiments.
