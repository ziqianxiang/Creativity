Table 1: Error rate on test set. “Ours” represent NODE models directly modified from ResNet18, trainedwith Heun-Euler solver, but tested with different solvers. “Adjoint” is the result when trained and tested withadjoint method, reported by (Gholami et al., 2019). We also report results from standard ResNet.
Table 2: Accuracy of adjoint method and directback-prop, for a GODE model with GCN as thederivative function.
Table 3: Results on node classification tasks. Wecompared various discrete-layer structures (markedwith DISC) and their corresponding GODE models(marked with ODE). We tested GODE model with dif-ferent ψ functions (“Lsig” represents linear.Sigmoid).
Table 4: Results on graph-classification tasks. Foreach base model structure, discerete-layer model ismarked with DISC; for corresponding GODE, wetested both free-form functions (“free”), and their in-vertible block form (“INV”). For each model, we use* (**) to mark GODE models that outperform corre-sponding discrete-layer baselines at a 5% (1%) signif-icance level under paired t-test.
Table 5: Accuracy of a free-form GCN-ODE on Cora and NODE18 on CIFAR10,varying with integration time.
Table 1: StatiSticS of datasetsDataset	Graphs	Nodes	Edges	Features	Classes	Label rateCora	1	2,708	5,278	1,433	7	0.052CiteSeer	1	3,327	4,552	3,703	6	0.036PubMEd	1	19,717	44,324	500	3	0.003MUTAG	188	17.93	19.79	7	2	0.8PROTEINS	1,113	39.06	72.82	3	2	0.8IMDB-BINARY	1,000	19.77	96.53	-	2	0.8REDDIT-BINARY	200	429.63	497.76	-	2	0.8B Details about invertible blocksTwo neural network blocks• / ♦ Forward / Inverse of a bijective functionFigure 1: Structure of bijective blocks. F and G can be any differentiable neural network whose output hasthe same shape as its input. Blue dot (Orange diamond) represents the forward (inverse) of a bijective function,corresponding to ψ (ψ-1) in Eq. 8 of the main paper. Left (right) figure represents the forward (inverse) as inEq. 8.
Table 2: Memory consumption of bijective blocks.
