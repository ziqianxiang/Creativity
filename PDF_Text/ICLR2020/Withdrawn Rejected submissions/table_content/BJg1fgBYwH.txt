Table 1: Network ComplexityModel	Params (M)	MACs (G)Baseline MobileNetV2	3.50	0.33Baseline ResNet101	44.55	7.87Baseline DenseNet121	7.98	2.90SAFE-MobileNetV2	3.57	0.36SAFE-ResNet101	44.62	7.90SAFE-DenseNet121	8.04	2.94propagation as discussed in section 3, we place several conventional CNN layers of smaller sizein parallel with the spiking convolution module. This is called the auxiliary CNN module. Theoutput feature map of the two parallel modules is maintained to have the same height and width, andconcatenated along the depth to be used as input tensor to the remaining CNN layers, referred to asthe main CNN module. Main CNN module is responsible for higher level feature detection as wellas the final classification. The main CNN module can be designed based on existing deep learningmodels. The concatenation of features from auxilary CNN and spikining convolutional module helpsintegrate global and local learning.
Table 2: Accuracy (%) results for CIFAR10 with AWGN noiseModel	Clean	40 dB	30 dB	25 dB	20 dB	15dB	12dBBaseline MobileNetV2	91.30	90.86	84.85	66.25	35.13	18.50	14.26Baseline ResNet101	93.57	89.74	86.39	78.32	55.47	26.33	15.53Baseline DenseNet121	93.00	92.87	89.84	82.59	60.42	27.10	16.88Noise trained MobileNetV2	90.54	90.64	90.16	86.36	62.22	25.37	16.51Noise trained ResNet101	92.41	92.51	92.26	90.92	77.81	35.97	19.85Noise trained DenseNet121	91.88	91.86	91.71	90.74	75.35	33.89	19.35MobileNetV2 with average filter	58.91	55.12	48.37	42.56	38.79	33.36	29.88ResNet101 with average filter	60.18	57.06	49.64	45.02	39.50	34.88	32.79DenseNet121 with average filter	59.58	58.86	51.00	46.89	42.05	35.06	34.09SAFE-MobileNetV2	91.33	91.25	90.01	90.68	87.88	64.95	39.22SAFE-ResNet101	93.59	93.43	92.13	92.11	90.47	70.85	43.25SAFE-DenseNet121	93.03	92.86	92.70	91.35	88.00	62.99	33.198Under review as a conference paper at ICLR 2020Table 3: ToP 1 Accuracy (%) results for ImageNet subset with noiseModel	Clean	25 dB	15dB	10dB	5 dBBaseline MobileNetV2	70.80	67.41	57.92	45.35	34.48Baseline ResNet101	71.02	67.81	64.04	46.27	35.47
Table 3: ToP 1 Accuracy (%) results for ImageNet subset with noiseModel	Clean	25 dB	15dB	10dB	5 dBBaseline MobileNetV2	70.80	67.41	57.92	45.35	34.48Baseline ResNet101	71.02	67.81	64.04	46.27	35.47Baseline DenseNet121	70.92	67.60	63.28	44.34	27.50Noise trained MobileNetV2	66.30	68.12	59.71	46.70	34.66Noise trained ResNet101	68.91	69.20	65.71	52.60	41.32Noise trained DenseNet121	69.13	70.51	66.47	52.76	36.32MobileNetV2 with average filter	67.44	66.91	61.69	51.69	40.43ResNet101 with average filter	68.18	68.25	65.14	53.09	41.50DenseNet121 with average filter	65.38	64.56	62.40	50.65	39.40SAFE-MobileNetV2	71.05	67.86	65.91	53.82	42.33SAFE-ResNet101	71.14	70.67	67.24	55.04	42.87SAFE-DenseNet121	70.81	69.44	65.47	54.30	40.84performance drop is observed under mild to no noise. This is expected as average filtering results insignificant loss of feature details for inPut images in the CIFAR-10 dataset.
Table 4: ToP 5 Accuracy (%) results for MobileNetV2on ImageNet subset with NoiseModel	Clean	10dB	5 dBBaseline	94.72	79.20	67.15Noise trained	92.43	81.63	68.36Average filtering	92.81	85.37	78.95SAFE-MobileNetV2	95.91	89.57	83.92training. The accuracy result is shown in Table 3. All networks achieve around 70% toP 1 accuracyon clean images. Noise training shows robustness imProvement over the baseline network but stillnegatively affects clean image accuracy. In this test the average filter shows less degradation underno noise condition than for the CIFAR10 test, due to higher resolution of inPut images. DensNet121shows more noise robustness than MobileNetV2 and ResNet101 when noise training is used, whilefor average filtering ResNet101 benefits the most. SAFE-DNN imPlementations of all three net-works exhibit same or better robustness over all noise levels. Clean image classification accuracyis also unaffected. ComParing toP 5 accuracy result for SAFE-MobileNetV2 and its baselines, asshown in Table 4, SAFE-MobileNetV2 is able to maintain above 80% accuracy even at 5 dB SNR,outPerforming all three baselines.
Table 5: Accuracy (%) results for CIFAR10 with different noise typesModel	Wald I	Wald II	Poisson I	Poisson II	S&P I	S&P IIBaseline MobileNetV2	83.81	48.41	63.88	37.70	68.86	32.37Baseline ResNet101	85.12	60.75	76.49	56.47	79.25	47.69Baseline DenseNet121	87.34	63.24	78.15	60.60	83.50	49.54Noise trained MobileNetV2	90.06	71.80	87.18	74.51	88.86	63.84Noise trained ResNet101	91.95	88.15	89.63	81.16	90.78	74.43Noise trained DenseNet121	91.48	84.42	89.44	78.90	89.93	72.24MobileNetV2 w/ average filter	53.12	36.70	54.40	35.84	51.35	31.29ResNet101 w/ average filter	54.06	38.03	56.75	38.59	52.19	34.25DenseNet121 w/ average filter	55.86	39.69	56.31	37.34	51.61	32.47SAFE-MobileNetV2	90.46	88.50	84.35	82.58	89.17	80.83SAFE-ResNet101	92.97	90.75	88.91	87.22	90.53	86.75SAFE-DenseNet121	92.83	89.52	87.67	85.75	90.28	85.38Table 6: Accuracy (%) results for ImageNet subset with different noise typesModel	Wald I	Wald II	Poisson I	Poisson II	S&P I	S&P IIBaseline MobileNetV2	68.56	58.99	65.16	51.08	66.53	46.81Noise trained MobileNetV2	69.07	62.12	67.31	60.22	67.99	53.86MobileNetV2 w/ average filter	66.05	61.46	64.52	59.91	62.07	45.50SAFE-MobileNetV2	70.19	64.37	66.74	63.15	67.10	58.91
Table 6: Accuracy (%) results for ImageNet subset with different noise typesModel	Wald I	Wald II	Poisson I	Poisson II	S&P I	S&P IIBaseline MobileNetV2	68.56	58.99	65.16	51.08	66.53	46.81Noise trained MobileNetV2	69.07	62.12	67.31	60.22	67.99	53.86MobileNetV2 w/ average filter	66.05	61.46	64.52	59.91	62.07	45.50SAFE-MobileNetV2	70.19	64.37	66.74	63.15	67.10	58.91(results not shown). As for ImageNet subset, networks based on MobileNetV2 are tested. Wald I is adistribution with μ = 5, scale = 0.3 and Wald II is a distribution with μ = 25, scale = 1; Poisson Ihas a distribution with peak of 255 and for Poisson II, 45; S&P I has 5% noisy pixels and S&P II has30%. As previously, noise-trained networks are trained with noisy images generated from Wald I,Poisson I and SP I. Similar to previous results, as shown in 6 SAFE-MobileNetV2 is more robust tothe different noise structures without ever-being trained on any noise structure.
Table 7: Accuracy (%) results for CIFAR10 with ad- versarial perturbation			Model	E = 3	E=8	E = 16Baseline MobileNetV2	83.50	67.59	47.93Baseline ResNet101	85.31	68.42	47.25Baseline DenseNet121	88.00	76.18	64.63SAFE-MobileNetV2	87.14	74.26	59.18SAFE-ResNet101	89.14	74.67	61.24SAFE-DenseNet121	90.13	82.86	76.54with different initialization are used as baseline against SAFE-DNN implementation of the deepnetwork. As shown in Table 7, SAFE-DNN also shows improved robustness to noise generated viaadversarial perturbations. However, we note that the results do not indicate robustness to white-boxattacks; and integration of SAFE-DNN with adversarial training approaches will be an interestingfuture work in this direction.
