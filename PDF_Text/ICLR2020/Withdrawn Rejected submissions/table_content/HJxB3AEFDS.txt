Table 1: Mock records of three patent-inventor name instances. Rows 1 and 2 are the same mockinventor, While row 3 is a different inventor.
Table 2: Performance of two example runs of our disambiguation algorithm (bottom rows), com-pared with other inventor name disambiguation studies evaluated on the IS or E&S labelled datasets.
Table 3: Performance of our disambiguation algorithm relative to other studies, regardless of evalu-ation dataset. All values in %.______________________________________________Method 便;l]	Splitting	Lumping	Recall	Precision	F1Li2014t	3.26	2.34			Ventura2015	2.31	1.64			Kim2016			98.48	99.60	99.04Morrison2017			92	98	95Yang2017			96.15	99.61	97.85Ours [0.03; 0.05]	1.24	0.58	98.76	99.41	99.09t Ventura et al. (2015) also use an “optoelectronics” (OE) labelled datasetto evaluate Li et al. (2014), obtaining lower errors on the full OE dataset(splitting: 2.49%, lumping: 0.39%), but higher errors on a random sample ofOE data (splitting: 10.54%, lumping: 1.21%).
Table 4: Comparison of alternate string-map layouts. Each row shows the highest F1 result obtainedfor that string-map layout.
Table 5: Hyperparameters that differ between the two network architectures. See (Krizhevsky et al.,2012) for more details on the network architecture.
