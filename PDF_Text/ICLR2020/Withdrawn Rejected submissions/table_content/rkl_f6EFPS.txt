Table 1: Correspondence between discrete and continuous quantities. When an regular (discrete)NN is a function mapping vectors to vectors, a continuous NN is an operator mapping functions tofunctionsthis means calculating a local Lipschitz coefficient K (43) connecting |yL+1 (W + U) -yL+1(W)| ≤K|U|. In the literature, there are known spectral bounds on the Lipschitz coefficient for the case ofinput perturbations. These bounds use the spectral norm of the matrix ∣∣ ∙ k2 and give a global result,valid for any input. This estimate is loose due to its exponential growth in the number of layers, as∣W ∣2 is rarely < 1. See Proposition 2 for the statement:Proposition 2 (K using spectral properties). kyL(χ2) — yL(χ1)k2 6 ∣∣χ2 — χ1k2 ∙ QL=1 ∣Wι∣2The proof can be found in (29) or in the supplementary material. It is also known that highperturbations under small input changes are attainable. Adversarial examples (5) are small changesto the input resulting in a high change in the output. This bound is equal to the one of (23), which istight in case if the network has the fewest neurons. In contrast, in Section 4, we derive our bound inthe limit n → ∞.
Table 2: Comparison of networks trained with increased dropout. Rank loss between ptrain andvarious metrics. Experiment shows crashing and correct networks, MAE or accuracy and test/traindatasets. Theoretical bounds include P212and T1.
Table 1: Correspondence between discrete and continuous quantitiesAdditional Proposition 3. Continuous networks with H = F are universal approximatorsProof. Based on the proof of [15]. By the property of discrete networks, they are universal approximators [15].
Table 2: Comparison of bigger convolutional networks when there are faults at every layer with p = 10-25295305315325335345355365375385395405417.4	Error superposition (testing AP7, additional)We test a random network with L = 4 on random input (see ErrorAdditivityRandom.ipynb). The error iscomputed on subsets of failing layers a, b. Then all pairs of disjoint subsets are considered, and the relative errorof ∆ estimation using linearity is computed as ∣∣∆a∪b — △a 一 ∆bk∕k∆a∪b∣∣. The results (see Figure 11) show thatthis relative error is only few percent both for mean and variance, with better results for the mean.
