Table 1: Individual Style Calibration: Style-consistency (×10-2, median over 5 seeds) of poli-cies evaluated with 4,000 Basketball and 500 Cheetah rollouts. Trained separately for each style,CTVAE-style policies outperform baselines for all styles in Cheetah and 4/5 styles in Basketball.
Table 2: Fine-grained Style-consistency: (×10-2, median over 5 seeds) Training on labeling func-tions with more classes yields increasingly fine-grained calibration of behavior. Although CTVAE-style degrades as the number of classes increases, it outperforms baselines for all styles.
Table 3: Multi Style-consistency: (10-2, median over 5 seeds) Simultaneously calibrated to multi-ple styles, CTVAE-style policies outperform baselines for all styles in Cheetah and in Basketball.
Table 4: KL-divergence and negative log-densityper timestep for TVAE models (lower is better).
Table 5: Dataset parameters for basketball and Cheetah environments.
Table 6: Hyperparameters for Algorithm 2. b is the number of batches to see all trajectories in thedataset once. We also use L2 regularization of 10-5 for training the dynamics model Mφ.
Table 7: Model parameters for basketball and Cheetah environments.
Table 8: [min, median, max] style-consistency (×10-2, 5 seeds) of policies evaluated with 4,000basketball rollouts each. CTVAE-style policies significantly outperform baselines in all experimentsand are calibrated at almost maximal style-consistency for 4/5 labeling functions. We note some rarefailure cases with our approach, which we leave as a direction for improvement for future work.
Table 9: [min, median, max] style-consistency (×10-2, 5 seeds) of policies evaluated with 500Cheetah rollouts each. CTVAE-style policies consistently outperform all baselines, but we note thatthere is still room for improvement (to reach 100% style-consistency).
Table 10: Mean and standard deviation style-consistency (×10-2, 5 seeds) of policies evaluatedwith 4,000 basketball rollouts each. CTVAE-style policies generally outperform baselines. Lowermean style-consistency (and large standard deviation) for CTVAE-style is often due to failure cases,as can be seen from the minimum style-consistency values we report in Table 8. Understanding thecauses of these failure cases and improving the algorithm’s stability are possible directions for futurework.
Table 11: Mean and standard deviation style-consistency (×10-2, 5 seeds) of policies evaluatedwith 500 Cheetah rollouts each. CTVAE-style policies consistently outperform all baselines, but wenote that there is still room for improvement (to reach 100% style-consistency).
Table 12: We report the median negative log-density per timestep (lower is better) and style-consistency (higher is better) of CTVAE-style policies for Cheetah (5 seeds). The first row cor-responds to experiments in Tables 1 and 9a, and the second row corresponds to the same experi-ments with 50% more training iterations. The KL-divergence in the two sets of experiments areroughly the same. Although imitation quality improves, style-consistency can sometimes degrade(e.g. SPEED, FRONT-FOOT HEIGHT), indicating a possible trade-off between imitation qualityand style-consistency.
Table 13: Comparing style-consistency (×10-2) between RNN and CTVAE policy models forDESTINATION in basketball. The style-consistency for 5 seeds are listed in increasing order. Ouralgorithm improves style-consistency for both policy models at the cost of a slight degradation inimitation quality. In general, CTVAE performs better than RNN in terms of both style-consistencyand imitation quality.
Table 14: Mean and standard deviation cross-entropy loss (Llabel , ×10-2) over 5 seeds of learnedlabel approximators Cψ* on test trajectories after nlabel training iterations for experiments in section6.1. Cψ* is only used during training; when computing style-consistency for our quantitative results,we use original labeling functions λ.
Table 15: Average mean-squared error of the dynamics model MW per timestep per dimension ontest trajectories after training for ndynamics iterations15Under review as a conference paper at ICLR 2020boundaries divide the court into 6 regions, each corresponding to a label class. The label indicatesthe target region of a trajectory’s final position (•). This policy achieves a style-consistency of0.93, as indicated in Table 8b. Note that the initial position () is the same as in Figures 2 and 3for comparison, but in general we sample an initial position from the prior p(y) to compute style-consistency.
