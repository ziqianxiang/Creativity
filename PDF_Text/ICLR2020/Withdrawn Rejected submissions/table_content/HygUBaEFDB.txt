Table 1: Performance and model complexity comparison on MNIST dataset.
Table 2: Validation of TRMTL for RNN on UFC11.
Table 3: Specification of network architecture ofTRMTL for the Omiglot-MNIST datasets.
Table 4: Performance comparison of STL, DMTRL and our TRMTL on Omniglot-MNIST datasets.
Table 5: Heterogeneous (left) and homogeneous (right) network architectures for Adience-CelebA datasets.
Table 6: Specification of network architecture and factorized TRRL representation on MNIST dataset.
Table 7: Performance comparison of STL, MRN, DMTRL and our TRMTL on MNIST dataset.
Table 8: Specification of network architecture and factorized TRRL representation on Omniglot dataset.
Table 9: Performance comparison of STL, MRN, DMTRL and our TRMTL on Omniglot dataset.
Table 10: Performance comparison of STL, MRN, DMTRL and our TRMTL on CIFAR-10 with unbalancedtraining samples, e.g., ‘5% vs 5% vs 5%’ means 5% of training samples are available for the respective taskA, task B and task A. TR-ranks R = 10 for TRMTL.
Table 12: Specification of network architecture and factorized TRRL representation on heterogenous inputswith distinct channels (RGB and grayscale image) for CIFAR-10.
Table 13: The results of heterogenous input dimensionality on CIFAR-10. Top: each task associates withRGB or grayscale image. Bottom: each task has input images of different spatial sizes.
Table 14: Specifications of heterogenous FC network architectures in the Office-Home experiment.
