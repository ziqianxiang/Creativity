Table 1: CIFAR10 results. Comparison of performance (classification accuracy) for Natural,Madry (Madry et al., 2018), Bilateral (Wang & Zhang, 2019), Feature-Scatter (Zhang &Wang, 2019) and the proposed Adv-Interp method under different attacks.
Table 2: Performance against stronger white-box attacks with increasing attack budgets. Themodels are trained with the attack budget =8, and are evaluated against attacks with larger budgets.
Table 3: Performance against stronger white-box attacks with increasing attack iterations. Themodels are trained with the attack budget =8.
Table 5: Ablation studies on different perturbation schemes for (a) image and (b) label.
Table 4: More evaluation results. Performance comparisons on (a) CIFAR100 and (b) SVHN.
Table 6: Black-box attack evaluations. Performance of the model trained with the Adv-Interpmethod under (a) gradient-based and (b) gradient-free black-box attacks.
Table 7: Categorization and analysis of different model training methods. X denotes the originalimage and y denotes the original label. δ is the perturbation added to the image X, constructed byaltering the prediction towards y0. E0y = Ey/(C — 1) where C is the total number of classes. Notethat different approaches can use different methods for generating δ.
Table 8: More results and comparisons with several recent methods on CIFAR10.
Table 9: More results against adaptive attacks on CIFAR10.
