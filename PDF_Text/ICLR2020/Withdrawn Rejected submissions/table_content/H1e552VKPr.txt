Table 1: Different datasets used in our experimentsthe components of Nr dimensional XrÎ¸ gives the same for each node. Finally, multiplying that- -1 1	K- 1With Dr 2 Ar Dr 2 produces the (normalized) importance of a node based on its own features andthe features of immediate neighbors (for one layer of intra-level attention). Hence, xr , which is a Kdimensional representation of the level graph Gr, is a sum of the features of the nodes weighted bythe respective normalized node importance. Please note, the impact from the first few level graphsbecomes noisy due to too many subsequent operations in a hierarchical pooling method like in Yinget al. (2018). But representing level graphs separately by the proposed intra-level attention maketheir impact more prominent.
Table 2: Classification accuracy (%) of different algorithms for node classification.
Table 3: Classification accuracy (%) of graph classification on multiple datasets.
Table 4: Classification accuracy (%) of different algorithms for node classification on the publicly availablenode splits into training, validation and test sets.
