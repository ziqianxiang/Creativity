Table 1: Exploiting NN-Mass for Model Compression on CIFAR-10 Dataset. All our experimentsare reported as mean ± standard deviation of three runs. DARTS results are reported from Liu et al.
Table 2: Details of Experiments for varying αij ’s and Average DensitiesExperiment TyPe	Number ofCells	Max. Long-Range Link Candidates (tc)	aij s	Depth	Width MultiplierImpact of aj's	1	200	Constant(1/N)	46	2		"^00	Ones (Traditional CNN)	^46	孱	1	"^00	Random Probabilities	46	2Impact of Average Density	3	[10,35,50] [20,45,75] [30,50,100] [40,60,120] [50,70,145]	Random Probabilities	31	2Impact of Average Density	3	[20,40,70] [30,50,100] [40,80,125] [50,105,150] [60,130,170]	Random Probabilities	40	2Impact of Average Density	3	[25,50,90] [35,80,125] [50,105,150] [70,130,170] [90,150,210]	Random Probabilities	49	2Impact of Average Density	3	[30,80,117] [50,110,150] [70,140,200] [90,175,250] [110,215,300]	Random Probabilities	64	2•	Comparison to Parameter Counting. Parameter counting (i.e., total number of train-able parameters in a model) has been a standard method to determine whether or not agiven model will achieve high accuracy. Towards this, we demonstrate that NN-Massis a significantly better metric than parameter counting for understanding generaliza-tion performance of various CNNs.
