Table 1: Regression performance comparison in terms of root mean squared error. The mean andstandard deviation are computed across 30 resamples. N is 1000 for SE1,2,3 and 6000 for RCP. Thevalues for LASSO and SRFF are borrowed from (Gregorova et al., 2018). DNN represents a deepneural network without feature selection.
Table 2: Performance comparison of survival analysis on METABRIC. We run the same experiment5 times with different train/test split and report the mean and the standard deviation on the testset. In (Katzman et al., 2018), it is reported that DeepSurv outperforms other existing survivalanalysis methods such as Random Survival Forest (RSF) (Ishwaran et al., 2008) and the original CoxProPotional HaZard ModeL________________________________________________________________	DeepSurv	RSF	Cox-Lasso	COX-HC	COX-STGC-index	0.612 (0.009)	0.626 (0.006)	0.580 (0.003)	0.636 (0.007)	0.633 (0.005)# FEATURES	221 (ALL)	221 (ALL)	44 (0)	8 (0.89)	2 (0)we use this data and focus on classifying two subpopulations of T-cells, namely Naive and regulatoryT-cells. We use the proposed method to select a subset of genes for which the network discriminatesbetween Naive and regulatory T-cells. We first filter out the genes that are lowly expressed in thecells, which leaves us with D = 2538 genes (features). The total number of cells in these two classesis N = 20742, of which we only use 10% of the data for training. We apply the proposed method fordifferent values of λ and report the number of selected features and classification accuracy on the testset. Here we compare our performance (STG and HC) to RF and LASSO. A least squares polynomialfit plot of the accuracy vs. number of selected features is presented in Fig. 3. The accuracy obtainedby a NN without feature selection is 91.09%, which is comparable to what we achieve with a smallfraction of the features. We have also evaluated the performance of the Hard-Concrete applied to alllayers (HC-Full), following the procedure in (LouiZos et al., 2017). Empirically we observed thatusing this type of regulariZation across all layers provides inferior capabilities in terms of feature
Table 3: List of the search range for the hyperparameters used in our expirements for XOR andTwo-MoonParam	Search range# dense layers	[I:3# hidden units	[10, 500]activation	[tanh, relu, sigmoid]LR	[1e-4, 1e-1]n-epoch (DFS, SG-LI-NN)	[50, 20000]α (SG-LI-NN)	[1e-3, 1]λ (SG-L1-NN)	[1e-7,1]λ (STG, DFS)	[1e-3, 1]λ (LASSO)	[0.01, 1]n-est (RF, XGBoost, Tree)	[5,100]n-boost-round (XGBooSt)	[1,100]Thresh (RF, XGBoost, Tree)	[0.01,0.5]max-depth (XGBoost)	[0.01,0.5]	C (SVC)		[1e-7,1]For the Phase Transition experiment, we use 0.1 as a learning rate. For all the experiments whenwe use Tree and RF, we use the default value for max-depth, so that nodes are expanded basedon the purity. For the XOR problem, the exact architectures used for the NN based methods
