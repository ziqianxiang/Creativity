Table 1: Comparison with state-of-the-art architectures on CIFAR-10 under the NASNET-likesearch space. * denotes model is trained with cutout. OS denotes one-shot approach. G denotesgradient-based approach. f indicates hard parameters constraint in search phase.
Table 2: Comparison with state-of-the-art architectures on ImageNet (mobile setting) underNASNET-like search space. f denotes direct search on ImageNet.
Table 3: Comparison with state-of-the-art architectures on ImageNet (200M-400M FLOPs) underShuffleNet-like search space. * denotes results reported using AutoAugment.
Table 4: Comparison of VAENAS and random search on NAS-Bench-101 dataset.
Table 5: The comparison of architectures searched with (w/) or without (w/o) VAENAS.
Table 6: NAS framework with different model depth on CIFAR-10.
