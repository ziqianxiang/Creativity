Table 1: (i) Performance of BERT-base vs Decomp-BERT-base, (ii) Performance drop, inferencespeedup and inference memory reduction of Decomp-BERT-base over BERT-base for 5 tasks.
Table 2: Performance, Inference Speed and Memory for different models on SQuAD.
Table 3: Inference latency (in seconds) on SQuAD datasets for BERT-base vs Decomp-BERT-base,as an average measured in batch mode. On the GPU and CPU we use a batch size 32 and on thephone (marked by *) we use a batch size of 1.
Table 4: Ablation analysis on SQuAD datasets for Decomp-BERT-base and Decomp-BERT-largemodels.
