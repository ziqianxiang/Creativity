Table 1:	Results of data poisoning defense on end-to-end Poison Frogs attackDefense	Poisons	Non poisons Attack success Class. accuracy (%)filtered	filtered (%) rate (%)k-NN (k=5000)	799/800	0.6	0.0	74.6L2 Norm outliers	395/800	1.0	50	74.61-class SVM	168/800	1.0	62.5	74.5Random filtering	84/800	10.0	87.5	74.5only consider successful attacks, so that the undefended attack success rate is 100%. As in the origi-nal paper (Shafahi et al., 2018), the network used is a modified Alexnet. The network is trained withthe poisons from a warm start over 10 epochs with a batch size of 128. We evaluate the performanceof the defenses described in Section 4 against collections of 50 poisons that successfully create atargeted misclassification, so that the undefended attack success rate is 100%. The results are shownin Table 1. Successful attacks must result in a targeted misclassification. The k-NN defense withk=5000 successfully identifies all but one poison across multiple attacks, while filtering just 0.6%of non-poison datapoints from the input data set. The k-NN defense reduces the attack success rateto 0%. Because classification accuracy surprisingly does not change significantly as k increases itis appropriate to set k as the class size of the training data, as shown in Figure 2. For k = 3 thepercentage of filtered non-poisons was 0.004%, while for k = 10000 it remained just 1.3%. Therelatively low filtering rate of nonpoisons for higher k may account for the low variation in test setclassification accuracy for different selections of k. The L2 defense also identifies roughly half of
Table 2:	Results of data poisoning defense on transfer learning of Convex Polytope AttackDefense	Num poisons Non poisons Attack success Class. accuracy (%)filtered	filtered (%) rate (%)k-NN (k=50)	510/510	4.3	0 .0	93.9L2 Norm outliers	509/510	9.1	1.0	93.41-class SVM	114/510	7.1	70.1	91.7Random filtering	47/510	10.0	66.8	91.3The attack success rates for each model architecture (undefended is 100%) are shown in Figure 3.
