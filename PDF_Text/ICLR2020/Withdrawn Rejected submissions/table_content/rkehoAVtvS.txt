Table 1: Information of the experimental data sets. The number of instances, features and classes arerecorded. The “avg.#CLs” column lists the average number of candidate labels in each PML set.
Table 2: Comparison results of in terms of Hamming loss, ranking loss, average precision, andmicro-averaging AUC. The best results are presented in bold font. The average number of candidatelabels is presented under the column “avg.#C.Ls”.
Table 3: Win/tie/loss counts of pairwise t-test (with p < 0.05 ) between PML-GAN and eachcomparison method over all dataset variants with different numbers of candidate labels.
Table 4: Comparison results of PML-GAN and its three ablation variants.
Table 5: The network architecture of PML-GAN. BN: Batch normalization; LReLU: Leaky rectifiedunit; Act.: Activation function; dim: Feature dimension of training samples x; class num: the numberof class labels.
Table 6: Comparison results for PML-GAN and the other methods in terms of two additional metrics:coverage and one error. The best results are in bold font.
Table 7: Comparison of PML-GAN with its ablation variants in terms of coverage and one error. Thebest results are in bold font.
Table 8: Comparison results for PML-GAN and PML-GAN0 in terms of six evaluation metrics. Thebest results are presented in bold font. The average number of candidate labels is presented undercolumn “avg.#C.Ls”.
Table 9: Win/tie/loss counts of pairwise t-test (with p < 0.05 ) about PML-GAN vs PML-GAN0 over all49 PML variant datasets with different numbers of candidate labels.
Table 10: Characteristics of the multi-label experimental datasets.
Table 11: Comparison of PML-GAN with the comparison methods. The best results are presented inbold font.
