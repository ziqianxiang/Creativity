Table 1: Accuracy obtained by training an standalone classifier, applying the API and the proposedwrapper for each domain	BB source acc.	BB target acc.	Non-reject. acc. (10/20/30%)	Class. quality (10/20/30%)	Reject. quality (10/20/30%)Apply Yelp BB to SST-2	89.18±0.08%	77.13±0.52%	81.38±0.72% 85.83±0.88% 90.08±0.94%	78.82±0.91% 79.66±1.15% 78.46±1.31%	4.66±0.63 4.33±0.44 3.69±0.31Apply SST-2 BB to Yelp	83.306±0.18%	82.106±0.88%	86,34±0.18% 89.44±0.38% 92.08±0.33%	83.27±0.88% 80.95±0.38% 76.77±0.46%	5.98±1.63 4.10±0.27 3.21±0.10Apply Electronics BB to Music	86.39±0.22%	90.38±0.13%	95.04±0.43% 96.45±0.35% 97.26±0.31%	90.67±0.88% 83.93±0.67% 75.77±0.54%	10.7±1.65 4.82±0.35 3.25±0.14Apply Music BB to Electronics	93.10±0.02%	83.06±0.0%	91.79±0.31% 94.90±0.85% 96.00±0.83%	90.27±0.54% 86.22±1.33% 79.91±0.98%	19.19±2.9 6.60±0.84 4.02±0.25Apply STL-10 to CIFAR10	53.53±0.12%	39.29±0.08%	42.53±0.04% 45.33±0.04% 47.78±0.05%	46.22±0.06% 52.18±0.06% 56.55±0.08%	2.56±0.05 2.62±0.02 2.25±0.01C Appendix CThis Appendix shows detailed results on the image case. Although the resulting quality obtainedfor the rejection mechanism in the case of images is not as large as in texts, when comparing to thepredictive entropy of the original classifier, we observe that the proposed measure is still excellent fordetecting out of sample images. The main difference between STL-10 and CIFAR10 is a variationon one of the classes. Where in STL-10 class 6 held monkeys, in CIFAR10 it corresponds to frogs.
