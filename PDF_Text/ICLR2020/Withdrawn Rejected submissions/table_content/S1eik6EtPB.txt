Table 1: Comparison of average and min-max (APGD) ensemble attack over four models on MNIST andCIFAR-10. Acc (%) represents the test accuracy of classifiers on adversarial examples. Here we set the iterationsof APGD as 50 for attack generation. The learning rates α, β and regularization factor γ are provided inAppendix C.2.
Table 2: Comparison of average and minmax optimization on universal perturbation over multiple inputexamples. The adversarial examples are generated by 20-step '∞-APGD With α = 1, β = 焉 and Y = 4.
Table 3: Comparison of average and min-max optimization on robust attack over multiple data transformationson CIFAR-10. Acc (%) represents the test accuracy of classifiers on adversarial examples (20-step '∞-APGD(e = 0.03) with α = 2, β =焉 and Y = 10) under different transformations.
Table 4: Adversarial training of MNIST models on single attacks ('∞ and '2) and multiple attacks (avg. andmin max). The perturbation magnitude e for '∞ and '2 attacks are 0.2 and 2.0, respectively. Top 2 test accuracyon each metric are highlighted. Complete table for varied is given in Table A8 (Appendix E).
Table A1: Neural network architectures used on the MNIST and CIFAR-10 dataset. Conv: convolutional layer,FC: fully connected layer, Globalpool: global average pooling layer.
Table A2: Clean test accuracy of DNN models on MNIST and CIFAR-10. We roughly derive the modelrobustness by attacking models separately using FGSM Goodfellow et al. (2014). The adversarial examples aregenerated by FGSM '∞ -attack (e = 0.2).
Table A3: Comparison of average and min-max (APGD) ensemble attack over four models on CIFAR-10. Acc(%) represents the test accuracy of classifiers on adversarial examples. The learning rates α, β and regularizationfactor Y are set as - '0 : α = 1,β =高,γ = 1, '1 : α = 1 ,β =焉,γ = 5, '2 : α = 1 ,β =焉,γ = 3;'∞ : α = 5, β =焉,γ = 6. The attack iteration for APGD is set as 50.
Table A4: Comparison of average, min-max (APGD) ensemble attack and some heuristic weighting schemesover four models on MNIST. Acc (%) represents the test accuracy of classifiers on adversarial examples.
Table A5: Comparison of average and min-max optimization on robust attack over multiple data transformationson CIFAR-10. Note that all data transformations are conducted stochastically with a probability of 0.8, exceptfor crop which randomly crops a central area from original image and re-size it into 32 × 32. The adversarialexamples are generated by 20-step '∞-APGD (e = 0.03) With α = 2, β =含 and Y = 10.
Table A6: Comparison of average and min-max optimization on robust attack over multiple data transformationson CIFAR-10. Here a neW rotation (rot) transformation is introduced, Where images are rotated 30 degreesclockWise. Note that all data transformations are conducted With a probability of 1.0. The adversarial examplesare generated by 20-step '∞ -APGD (e = 0.03) with α = 1, β = 含 and Y = 10.
Table A7: Adversarial training of MNIST models on single attacks ('∞ and '2), multiple attacks (avg. andmin max) and universal perturbation (uni). The perturbation magnitude e for '∞ and '2 attacks are 0.2 and 2.0respectively. USGD indicates universal adversarial training following Shafahi et al. (2018) ('∞ norm, e = 0.3)Top 2 test accuracy on each metric are highlighted.
Table A8: Adversarial training of MNIST models With single attacks ('∞ and '2) and multiple attacks (avg.
Table A9: Interpretability of domain weight w for universal perturbation to multiple inputs on MNIST (Digit0 to 4). Domain weight w for different images under `p-norm (p = 0, 1, 2, ∞) and two metrics measuringthe difficulty of attacking single image are recorded, where dist. ('2) denotes the the minimum distortion ofsuccessfully attacking images using C&W ('2) attack; 6ma ('∞) denotes the minimum perturbation magnitudefor '∞-PGD attack.
Table A10: Interpretability of domain weight w for universal perturbation to multiple inputs on MNIST (Digit5 to 9). Domain weight w for different images under `p-norm (p = 0, 1, 2, ∞) and two metrics measuringthe difficulty of attacking single image are recorded, where dist. ('2) denotes the the minimum distortion ofsuccessfully attacking images using C&W ('2) attack; 6ma ('∞) denotes the minimum perturbation magnitudefor '∞-PGD attack.
