Table 1: Results of showing where the ground-truth (GT) labels are in the prediction of learned adversarialexamples for different attack methods. The test is done in ImageNet-1000 val dataset using a pretrainedResNet-50 model (He et al., 2016). Please see Sec. 4 for detail of experimental settings.
Table 2: Results and comparisons under the ordered Top-k targeted attack protocol using randomly selectedand ordered 10 targets (GT exclusive) in ImageNet using ResNet-50. For Top-1 attacks, we also compare withthree state-of-the-art untargeted attack methods, FGSM (Goodfellow et al., 2015), PGD (Madry et al., 2018)and MIFGSM (Dong et al., 2018). 10 iterations are used for both PGD and MIFGSM.
Table 3: Results of ordered Top-5 targeted attacks with targets being selected based on (Top) label similarity,which uses 5 most-like labels and 5 least-like labels as targets respectively, and (Bottom) prediction score ofclean image, which uses 5 highest-score labels and 5-lowest score labels. In both cases, GT labels are exclusive.
Table 4: Results and comparisons using DenseNet-121 Huang et al. (2017) under the ordered Top-5 andTop-1 targeted attack protocol using randomly selected and ordered 5 targets (GT exclusive). For Top-1 at-tacks, we also compare with three state-of-the-art untargeted attack methods, FGSM (Goodfellow et al., 2015),PGD (Madry et al., 2018) and MIFGSM (Dong et al., 2018). 10 iterations are used for both PGD and MIFGSM.
