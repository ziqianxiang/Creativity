Table 1: Performance of the best models of each architecture for the Filtered Beer dataset.
Table 2: Performance of the best models of each architecture for the Full Beer dataset.
Table 3: Performance of the best models of each architecture for the Hotel dataset.
Table 4: Precision of selected words for each aspect. Percentage of words corresponds to the ratioof the number of highlighted words to the full review. All models are trained on Filtered Beer.
Table 5: Average Topic Coherence (NPMI) across different top-N words for each dataset. Eachaspect ai is considered as a topic and the masks (or attentions) are used to compute P(w|ai).
Table 6: Statistics of the multi-aspect review datasets. Full Beer and Hotel represent real-world beerand hotel reviews respectively. Filtered Beer contains a subset of beer reviews with assumptions,leading to a more straightforward and unrealistic dataset.
Table 7: Top ten words for each aspect from the Filtered Beer dataset, learned by various models.
Table 8: Top ten words for each aspect from the Full Beer dataset, learned by various models.
Table 9: Top ten words for each aspect from the Hotel dataset, learned by various models. Reddenotes intruders according to human annotators. Besides SAM, all methods find similar words formost aspects except the aspect Value, where MAM does not have an intruder.
