Table 1: Dataset Statistics	Cora	Citeseer	Pubmed	PPITask	Transductive	Transductive	Transductive	InductiveNodes	2,708 (1 graph)	3,327 (1 graph)	19,717 (1 graph)	56,944 (24 graphs)Edges	5,429	4,732	44,338	818,716Classes	7	6	3	121 (multilabel)Features	1,433	3,703	500	50Traning Nodes	140	120	60	44,906 (20 graphs)Validation Nodes	500	500	500	6,514 (2 graphs)Test Nodes	1,000	1,000	1,000	5,524 (2 graphs)Label Rate	0.052	0.036	0.003	0.789k-hop Path Attention. When P normalizes the output signals which have been rescaled and convo-luted multiple times by the nodes along the path, the propagation mechanism functions as the pathattention mechanism. The k-step path attention mechanism is expressed in our framework below,S = AQkAQk-1 …AQi, ~ ==	(14)S1After normalization ofP, the signal (PSHW)i of node i is fed into our node-wise adaptive encoderσi . The k-hop edge attention and path attention mechanisms are generalizations of Eq. 9.
Table 2: Summary of classification accuracy (transductive learning) (%).
Table 3: Summary of classification results interms of F1 (inductive learning) (%).
