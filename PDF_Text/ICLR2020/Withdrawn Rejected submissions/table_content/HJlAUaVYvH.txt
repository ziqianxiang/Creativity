Table 1:  Bounds on the error rate for VGG models trained on CIFAR-10 with the Lipschitzpenalty regulariser.  The bounds were computed with Proposition 2 at the 95% confidencelevel and the l₂ threat model.
Table 2:  Bounds on the error rate for VGG models trained on SVHN with the Lipschitzpenalty regulariser.  The bounds were computed with Proposition 2 at the 95% confidencelevel and the l₂ threat model.
Table  3:  Error  rates  (lower  is  better)  of  models  trained  with  different  regularisers  whenattacked with the projected gradient descent method of Madry et al. (2018).  The l₂ threatmodel and regularisers are used.  While our OVANet architecture does not improve empiricalrobustness, our LP training does benefit both model architectures.
Table 4:  Empirical error rates (lower is better) of models trained with different regulariserswhen attacked with the projected gradient descent method of Madry et al. (2018).  The lthreat model and regularisers are used.  While our OAVNet architecture does not improveempirical robustness, our LP training does benefit both model architectures.
Table 5:  Lipschitz constants for different architecture and regulariser combinations.
