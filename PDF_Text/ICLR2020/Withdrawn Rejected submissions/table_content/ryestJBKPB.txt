Table 1: Statistics of datasets used in the experiments. Please see Section 3 for the notations used.
Table 2: Results on real-world directed hypergraphs. We report 100× mean squared errors (loweris better) over 10 different train-test splits. Note that all the reported numbers need to be multipliedby 0.01 to get the actual numbers. Please see section 5 for more details.
Table 3: Accuracy on traditional graph-based SSL datasets. The experimental setting is the sameas in GCN KiPf & Welling (2017) and GAT Velickovic et al. (2018). We used 10% of the labelledvertices as validation data to tune the hyperparameter η.
Table 4: Ablation study of our proposed Soft-DHN. Please see section 5 for more details.
Table 5: List of hyperparameters used in the experiments. A set of values indicates that the corre-sponding hyperparameter is tuned from the set (on the validation split).
Table 6: Optimal hyperparameters on the validation set on Cora Co-authorship network.
