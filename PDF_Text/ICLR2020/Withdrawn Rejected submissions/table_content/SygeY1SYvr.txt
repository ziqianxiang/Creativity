Table 1:	Top: Centroid Networks vs. K-Means on raw and Protonet features. Bottom: Test clus-tering accuracies on Omniglot evaluation set, using the Constrained Clustering Network splits (Hsuet al., 2017) (much harder than Ravi splits). Numbers with a star* are those reported in (Hsu et al.,2019). We compared both using the Protonet Conv4 architecture and the architecture in (Hsu et al.,2017) (CCN), which has more filters. The differences between the two architectures are not sig-nificant. All our accuracy results are averaged over 1000 test episodes with a fixed model, and arereported with 95% confidence intervals.
Table 2:	Top: Few-shot clustering accuracies for Centroid Networks vs. K-Means on raw data andProtonet features.
Table 3: Using Centroid Networks to solve Omniglot and miniImageNet without using meta-testinglabels (unsupervised few-shot classification). We compare the unsupervised test accuracy of centroidnetworks with the supervised test accuracy of Protonets. Centroid Networks can solve Omniglot al-most perfectly (CSCC close to 100%), which suggests the class semantics are extremely consistent,while there is a small gap for miniImageNet (CSCC close to 80%), which suggests the class seman-tics are fairly consistent. Accuracy results are averaged over 1000 test episodes with a fixed model,and are reported with 95% confidence intervals.
Table 4: Using Centroid Networks to solve Meta-Dataset without using meta-testing labels (unsu-pervised few-shot classification) under the two originally proposed settings : training on ILSVRC,and training on all datasets except Traffic Sign and MSCOCO. We report supervised test accuracyfor Prototypical Networks (reproduced from the official implementation), unsupervised test accuracyfor Centroid Networks (ours), and approximate CSCCs (their ratio). All numbers are in percentages,all accuracies are averaged over 600 test episodes.
