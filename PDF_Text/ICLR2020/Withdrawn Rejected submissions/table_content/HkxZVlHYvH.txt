Table 1: Ergodic inference combines with pros of MCMC and VI and avoids their cons.
Table 4: Comparisons in terms of compuational efficiency and test log-likelihood in the training ofdeep generative models on the MNIST dataset. We implemented the deconvolutional decoder networkin Salimans et al. (2015) to test HVI. In Salimans et al. (2015), the test likelihood is estimated usingimportence-weighted samples from the encoder network. In our experiment, we use Hamiltonianannealled importance sampling and report the effective sample size (ESS).
Table 2: Estimation of -En [log ∏* (x)] and the sampling time on CPU: Each score (a/b) above refersto: a) -En [log∏*(x)] estimated by 100k samples; b) time in seconds to generate 100,000 samples.
Table 3: Left. The training time of MCMC parameter optimisation in seconds for 100 iterations forall candidate methods to produce the results in Figure 4. The training time of HEI is lower thanHVI because of the stop gradient trick mentioned in Section 3.2. We do not report the training timefor HAIS, because HAIS requires manual tuning of MCMC hyperparameters which is not directlycomparable to the gradient-based autotuning used by the other methods. Right. The training time inseconds per epoch for the experiments with deep generative models (DGM).
Table 5: The log likelihood on UCI datasets averaged over 20 splits.
