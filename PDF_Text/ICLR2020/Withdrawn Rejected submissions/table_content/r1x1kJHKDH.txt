Table 1: Classification results on CIFAR100, Indoor67, and Places205. We initialize the classification modelwith the representations φ(x) learned from unsupervised learning task. The model φ(x) comprises of a convlayer followed by two residual blocks (each having 2 conv layers). First column (called ‘Conv1’) corresponds toTop-1 classification accuracy with pre-trained model with the first conv layer frozen, second and third columnscorrespond to results with 3 conv layers and 5 conv layers frozen respectively. Details in Section 4.1.
Table 2: ImageNet classification results using ResNet18. We initialize weights from using the unsupervised task and fine-tune the last 2 residual blocks. Details in Section 4.1.				Table 3: Effect of maximum number of patches (N)(left) and number of hidden units (dp ) for patch appearance ZaPP (right) on classification accuracy. Details in Sec- tion 4.2.					Model	Top-1	Top-5		N CIFAR100		Indoor67 dp CIFAR100			Indoor67β-VAE	44.45	69.67		4	27.59	14.40	3	28.63	14.25PatchVAE	47.01	71.71		8	28.74	12.69	6	28.97	14.55β-VAE + Lw PatchVAE + Lw	47.28	71.78		16	28.94	14.33	9	28.21	14.55	47.87	72.49		32 64	27.78 29.00	13.28 12.76					83.79							Imagenet Supervised 61.37									Baselines. We use the β-VAE model (Section 3.1) as our primary baseline. In addition, we useweighted loss and discriminator loss resulting in the β-VAE-* family of baselines. We also compareagainst a BiGAN model from Donahue et al. (2016). We use similar backbone architectures forencoder/decoder (and discriminator if present) across all methods, and tried to keep the number ofparameters in different approaches comparable to the best of our ability. Exact architecture detailscan be found in Appendix 6.3.
Table 5: Effect of βvis : Too high or too low βviscan deteriorate the performance of learned repre-sentations on classification.
Table 4: Effect of zpvirsior: Increasing the prior onpatch visibility has adverse effect on classificationperformance.
Table 6: Encoder architecture for unsupervised learning task on CIFAR100 - All ‘convolutional’ layers arerepresented as (kernel_size × kernel_size, channels, stride, pad). BN stands for batch normalization layer andReLU for Rectified Linear Units.
Table 7: Encoder architecture for unsupervised learning task on Indoor67 and Places205 - All ‘convolutional’layers are represented as (kernel_size × kernel_size, channels, stride, pad). BN stands for batch normalizationlayer and ReLU for Rectified Linear Units. Note that PatchVAE and β-VAE architectures are slightly differentto account for sizes.
Table 8: Decoder architecture for unsupervised earning task on CIFAR100 - All ‘deconvolutional’ layers arerepresented as (kernel_size × kernel_size, channels, stride, pad). BN stands for batch normalization layer andReLU for Rectified Linear Units.
Table 9: Decoder architecture for unsupervised learning task on Indoor67 and Places205 - All ‘deconvolutional’layers are represented as (kernel_size × kernel_size, channels, stride, pad). BN stands for batch normalizationlayer and ReLU for Rectified Linear Units. Note that PatchVAE and β-VAE architectures are slightly differentto account for sizes.
Table 10: Architecture for supervised learning task - same for all baselines and our model. All convolutionallayers are represented as (kernel_size × kernel_size, channels, stride, pad). BN stands for batch bormalizationlayer and ReLU for Rectified Linear Units. All pooling operations are MaxPool and are represented by(kernel_size × kernel_size, stride, pad). Like Resnet-18, downsampling happens by convolutional layers thathave a stride of 2. In our model, downsampling happens during Conv1, Pool, and after Conv4-5.
