Table 1: Performance on CIFAR10 and MNIST datasets for 4 different types of CNNs with thethreshold, validation accuracy for full backpropagation (FB), validation accuracy for experimentaltechnique (PB) (PB) and the freezing ratio in parameters which is calculated as: (total gradients -non-zero gradients / total gradients) × 100Network	Dataset	Threshold	V. Accuracy (FB)	V. Accuracy (PB)	FrozenVGG19	CIFAR10	0.04	88.12%	87.70%	80.45%ResNet-110	CIFAR10	0.19	83.72%	82.83%	51.53%DenseNet-121	CIFAR10	0.45	88.20%	87.52%	69.33%LeNet-5	MNIST	0.50	99.25%	99.22%	92.36%Table 2: Average Performance over 3 runs on CIFAR10 and MNIST datasets for 4 different types ofCNNs with the threshold, validation accuracy for full backpropagation (FB), validation accuracy forour experimental technique (PB) and the freezing ratio in parameters which is calculated as: (totalgradients - non-zero gradients / total gradients) × 100resize all images to 256 × 256 pixels. We use a single layer LSTM with a hidden size of 512. Thebatch size is set 60. We use the Adam optimizer (Kingma & Ba, 2015) with an initial learning rate of5e-4 and anneal the learning rate by a factor of 0.8 once the BLEU-4 score shows no improvement for3 consecutive epochs. The word embedding and attention size is set to 512. We train for a maximumof 15 epochs with early stopping if the validation BLEU-4 score has not improved for 10 consecutiveepochs. When sampling, we use a beam size of 3. We use BLEU (Papineni et al., 2001) with up to4 grams (BLEU-1, BLEU-2, BLEU-3, BLEU-4) as our evaluation metric. We experiment on the
Table 2: Average Performance over 3 runs on CIFAR10 and MNIST datasets for 4 different types ofCNNs with the threshold, validation accuracy for full backpropagation (FB), validation accuracy forour experimental technique (PB) and the freezing ratio in parameters which is calculated as: (totalgradients - non-zero gradients / total gradients) × 100resize all images to 256 × 256 pixels. We use a single layer LSTM with a hidden size of 512. Thebatch size is set 60. We use the Adam optimizer (Kingma & Ba, 2015) with an initial learning rate of5e-4 and anneal the learning rate by a factor of 0.8 once the BLEU-4 score shows no improvement for3 consecutive epochs. The word embedding and attention size is set to 512. We train for a maximumof 15 epochs with early stopping if the validation BLEU-4 score has not improved for 10 consecutiveepochs. When sampling, we use a beam size of 3. We use BLEU (Papineni et al., 2001) with up to4 grams (BLEU-1, BLEU-2, BLEU-3, BLEU-4) as our evaluation metric. We experiment on thesoft attention variant of Xu et al. (2015). The best BLEU-4 score obtained when training with fullbackpropagation is 0.099. When applying our experimental technique (PB), using a threshold of 0.05,we obtain 61.81% redundant parameters which are frozen from the third epoch onwards. Under thissetting, we obtain a higher BLEU-4 score of 0.101 than the fully trained model. The freezing ratio iscalculated as: (total gradients - non-zero gradients / total gradients) × 100. Figure 4 shows somegenerated captions. For evaluation results on all BLEU scores, see Figure 5.
