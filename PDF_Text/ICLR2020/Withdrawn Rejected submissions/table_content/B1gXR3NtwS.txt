Table 1: Comparison with competing baselines in terms of the number of parameters and test errorrate. DBSN and its variants have 1.1 M parameters on CIFAR-100 due to a larger FC layer.
Table 2: Comparison of semantic segmentation performance on CamVid dataset. * indicates resultsfrom our implementation.
Table 3: Comparison of model calibration in terms of the Expected Calibration Error (ECE). Smalleris better.
Table 4: Comparison of the searched structure distributions based on the trained network weightsfrom DBSN and Random Î±.
Table 5: Comparison with competing baselines which deploy uncertainty on weights and adoptAdam-like VOGN (Khan et al., 2018) method for inference. (CIFAR-10)	Training time (hours)	Test error rate (%)	ECEDBSN	1.2	9.90	0.0070BNN-LS (with VOGN)	13.0	28.4	0.5391Fully Bayesian DBSN (with VOGN)	13.0	30.5	0.5169C	More Comparisons between DBSN and Competing Baselineswith Weight UncertaintyWe realized the BBB method used for modeling weight uncertainty in BNN-LS and Fully BayesianDBSN may be restrictive, resulting in such weakness. Therefore, we further implemented thesetwo baselines with a most-recently proposed mean-field natural-gradient variational inferencemethod, called Variational Online Gauss-Newton (VOGN) (Khan et al., 2018; Osawa et al., 2019).
