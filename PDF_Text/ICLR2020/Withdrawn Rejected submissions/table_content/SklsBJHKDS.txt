Table 1: Test accuracy on MNIST and CIFAR-10 With 50k bandit feedback training examples. BanditNet* isthe result from Joachims et al. (2018), while the BanditNet column is our implementation; we were unableto replicate the performance from prior Work (details in Appendix D). MINs outperform both BanditNet andBanditNet*, both with and without the inference procedure in Section 3.2. MINs w/o reweighting perform at parWith full MINs on MNIST, and slightly Worse on CIFAR 10, While still outperforming the baseline.
Table 2: Quantitative score-values for Youngest Face Opti-mization Task (larger the better)Task	MIN	MIN (best)≥ 15	-13.6	-12.2≥ 25	-26.2	-23.9Semantic image optimization. The goal in these tasks is to quan-tify the ability of MINs to optimize high-level properties that requiresemantic understanding of images. We consider MBO tasks on theIMDB-Wiki faces (Rothe et al., 2015; 2016) dataset, where the func-tion f(x) is the negative of the age of the person in the image. Hence,images with younger people have higher scores.
Table 3: Quantitative score valuesfor MNIST inpainting (contextual)Mask	MIN	Datasetmask A	223.57	149.0mask B	234.32	149.08Under review as a conference paper at ICLR 2020237.6, while the dataset average is 149.0. In the case where the context is the top half or quarter of theimage, MINs obtain average scores of 223.57 and 234.32, respectively, while the dataset average is149.0 for both tasks. We report these results in Table 3. We also conducted a contextual optimizationexperiment on faces from the Celeb-A dataset, with some example images shown in Figure 3. Thecontext corresponds to the choice for the attributes brown hair, black hair, bangs, or moustache. Theoptimization score is given by the sum of the attributes wavy hair, eyeglasses, smiling, and no beard.
Table 4: Active MBO on benchmark functions. The prior methods converge within 200 iterations. MINs requiremore iterations on some of the tasks, in which case we indicate the number of iterations in brackets. MINs reachsimilar final performance, and typically require 1-4× as much data as efficient GP-based algorithms.
Table 5: Protein design results, withmaximum fluorescence and the 50thpercentile out of 100 samples. Priormethod results are from Brookeset al. (2019). MINs perform com-parably to CbAS. MINs withoutreweighting (MIN-R) lead to moreconsistent sample quality (higher50%ile score), while MINs withreweighting can produce the highestscoring sample.
Table 6: Average quantitative perfor-mance for MNIST inpaintingMask	MIN	Datasetmask A	223.57	149.0maskB	234.32	149.0feedforward ReLU network with hidden units of size 256 each in this setting. For all experimentson CelebA and IMDB-Wiki faces, we used the VGAN (Peng et al., 2019) model and the associatedcodebase as our starting setup. For experiments on batch contextual bandits, we used a fully con-nected discriminator and generator for MNIST, and a convolutional generator and Resnet18-likediscriminator for CIFAR-10. The prediction in this setting is categorical - 1 of 10 labels needs tobe predicted, so instead of using reinforce or derivative free optimization to train the inverse map,we used the Gumbel-softmax Jang et al. (2016) trick with a temperature τ = 0.75, to be able to usestochastic gradient descent to train the model. For the protein flourescence maximization experiment,20Under review as a conference paper at ICLR 2020we used a 2-layer, 256-unit feed-forward gumbel-softmax inverse map and a 2-layer feed-forwarddiscriminator.
