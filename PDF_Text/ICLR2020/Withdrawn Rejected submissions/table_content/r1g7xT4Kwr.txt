Table 1: Avg. Reward and Avg. Success across the baseline models and our method applied to eachmethod. Note that whilst the performance difference between the two baselines is small, both ofour models outperform the baselines by a significant margin. Specifically, our PLEX LSTM variantshows a significant improvement over both baselines, achieving a higher result than the baselinePPO LSTM model (Savva et al., 2019) trained on more than double the number of environmentssteps.
