Table 1: Accuracy against various queue Sizes and random statesQueue Size	1	2	3	4	5	6	7	8	Mean-	62.79	65.04	61.96	63.42	63.62	62.25	62.98	63.43	63.19100	61.36	62.39	60.38	61.06	61.25	59.26	60.02	62.01	60.97200	61.84	62.47	61.13	62.24	62.18	61.02	60.94	61.91	61.72500	62.92	64.45	62.67	63.75	62.88	62.17	62.47	63.57	63.111000	64.96	66.16	63.40	65.25	66.06	64.20	64.24	65.62	64.992000	-	68.52	70.27	67.96	69.52	69.65	68.01	68.24	70.08	69.03The accuracy of CL-CNN is steadily increasing with queue size. Having a bigger memory to holdunknowns will help to make good decisions. With 10, 000 samples for growing in CIFAR10 ,increment of the queue size is stopped at 2, 000. When queue sizes are 1000, 2000, the accuracy isabove T-CNN accuracy.
Table 2: Accuracy without final queue of samples vs final accuracyQueue Size (λ)	Accuracy for samples (10000 - λ)	Delayed Feedback accuracy(10000)100 =	61.27	60.97200	6240	6172500	6491	63∏1000	68770	64992000 —	77.39	69.03The table 2 shows an interesting result of CL-CNN. The results are averaged over 8 random stateswhich are used to initialize network weights. The final queue contains the hardest examples for CL-CNN. For instance, if the queue size is 100, then 9900 samples are processed first. Finally, the lastcontent of the queue is processed. Infact, the samples which get high confidences will get a higherchance to leave the queue. These queues can be used to assist clustering the samples into harder andsimpler samples for the given model.
Table 3: Accuracy with color features vs accuracy without color featuresQueue Size	Accuracy with color features (%)	Accuracy without Color (%)100 二	62.73	60.97	=200	63:62	61:72500	65:56	63:111000	68:34	64:992000	-	73.26	69.03	—4.1.4	Batch update with Delayed FeedbackTable 4 shows the results with batch update. Adding batch update to the feedback with colordecreases the accuracy over CL-CNN with color feedback. But it ended up in a faster trainingtime(nearly 3 time faster for the batch size of 4). A batch of 4 is used to update. Sometimes getting4 samples which can meet the updating rule is not possible, in those scenarios model is updated witha smaller batch or even no update. Rather than a random feedback, color feedback with batch updateimproves a bit as shown in the table.
Table 4: Accuracy with color feedback and batch update vs accuracy of basic CL-CNNQueue Size	Accuracy with color and batch update (%)	Basic Delayed Feedback(%)100	:	61.92	60.97	=200	6260	61772500	63:98	63Tn1000	65:67	64:992000	-	69.35	—	69.03	—4.2	Decision Tree based ExperimentsThe framework is deployed in decision trees. Small changes are done to the framework. Instead ofmaintaining a queue, DTs are updated instantly. Unlike neural network, partial update to the modelfor a sample is not possible. Hence, for each new sample, the whole dataset is fitted. In addition, ifthe confidence values are higher, no update is done. The model is updated if the confidence value isin [0.5,].
