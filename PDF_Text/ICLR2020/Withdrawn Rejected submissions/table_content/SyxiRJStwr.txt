Table 1: Comparison of our method with the feedforward scale regression baseline and the oracle.
Table 2: Ablation of the number of iterations: entropy minimization saturates after 32 steps.
Table 3: Analysis of entropy minimization (compared to oracle and adversary optimization) andablation of the choice of parameters for optimization (score, scale, or both). The oracle/adversaryoptimizations minimize/maximize the cross-entropy of the output and truth to establish accuracybounds. The adversary results show that our method helps in spite of the risk of harm. The oracleresults show there are still better scales to be reached by further progress on dynamic inference.
