Table 1: Results (BLEU↑) on WMT'14 En什De translation using various decoding algorithms anddifferent settings of beam search width (b) and number of iterations (T) as a function of sentencelength (L). For each sentence we use 4 most likely sentence lengths. * denotes rescoring generatedhypotheses using autoregressive model instead of proposed model.
Table 2: Effect of the number of length candi-dates considered during decoding on BLEU, mea-sured on the validation set (newstest-2013) usingthe easy-first strategy.
Table 3: Constant-time machine translation on WMT’14 De→En with different settings of the budget(T) and number of tokens predicted each iteration (ot). * denotes rescoring generated hypothesesusing autoregressive model instead of proposed model.
Table 4: BLEU scores on WMT’14 En→De and De→En datasets showing performance of variousconstant-time machine translation approaches. Each block shows the performance of autoregressivemodel baseline with their proposed approach. AR denotes autoregressive model. Distill denotesdistillation. AR rescoring denotes rescoring of samples with autoregressive model. FT denotesfertility. NPD denotes noisy parallel decoding followed by rescoring with autoregressive model.
