Table 1: A summary of our student modelsâ€™ sizes compared to BERTBASE. #Params indicates thenumber of parameters in the student model, model size is measured in megabytes, and FLOPS ratiomeasures the relative ratio of floating point operations required for inference on the model.
Table 2: Masked language modeling task accuracy for the distilled student models and a fine-tune-from-scratch baseline. We observe consistently better performance for our proposed approaches.
Table 3: Results of the distilled models, the teacher model and baselines on the downstream languageunderstanding task test sets, obtained from the GLUE server, along with the size parameters andcompression ratios of the respective models compared to the teacher BERTBASE. MNLI-m andMNLI-mm refer to the genre-matched and genre-mismatched test sets for MNLI.
