Table 1: Dev accuracy (%) on the original SNLI dataset D and the datasets obtained through vari-ous representation-bias minimization. The -HypOnly baselines correspond to models trained on theinstances restricted to their hypotheses.
Table 2: Dev accuracy (%) on the original MNLI-matched and QNLI datasets and the datasetsobtained through ΦRoBERTa-representation-bias minimization. The -PartialInput baselines correspondto models trained on partial, incomplete input, namely the Hypotheses for MNLI instances and theAnswers for QNLI instances.
Table 3: KNN-distances by class, before and after applying (RoBERTa-filtered) AfLite to SNLI.
Table 4: SNLI accuracy (%) on three out-of-distribution evaluation tasks, comparing RoBERTa-large models pre-trained on the original SNLI data, and on AfLite-filtered data. On the HANSdataset, both models are evaluated on All, as well as on the non-entailment cases of the three syn-tactic heuristics (Lexical overlap, Subsequence, and Constituent). The NLI-Diagnostics dataset isbroken down into the full dataset (All), as well as the instances requiring logical reasoning (Logic)and the ones requiring world and commonsense knowledge (Knowledge). For Adversarial NLI, wefinetuned both models on the in-distribution training data for each round (Rd1, Rd2, and Rd3).
Table 5: Experimental results on ImageNet. We compare between three settings: the originaldataset’s train-test splits, using 20% of the training set but evaluating on the validation set, andusing the AfLite produced training and validation sets. AfLite produces a training dataset thatis also 20% of the training set size, making it a fair comparison in terms of dataset examples. Theresults show a significant drop in Top-1 and Top-5 accuracy: the Top-1 accuracy goes down byroughly 40 percentage points per model in this new training and evaluation setting.
