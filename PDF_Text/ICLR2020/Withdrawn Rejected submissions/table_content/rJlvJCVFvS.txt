Table 1:	Evaluating different supervision strate-gies with varying top K, using the VOC07 test-set, with ground truth relation labels as de-scribed in Section 3.2.
Table 2:	Recall comparison for the VisualGenome dataset with varying top K, where theground truth relation labels are human annotated.
Table 3: An evaluation of smooth L1 and L2 loss functions and variations of the focal loss factor r,on the VOC07 dataset. The results are reported as percentages (%) averaged over 3 runs.
Table 4: Object Detection Results. mAP@0.5: average precision over a bounding box overlapthreshold as IOU = 0.5. avg mAP: averaged mAP over multiple bounding box overlap thresholds.
Table 5: MIT67 Scene Categorization Results. The important entries are averages over 3 runs. Seethe text in Section 5.6 for a discussion. For details regarding Fs, Fc and F, see Section 4.4.
Table 6: Document categorization results for the 20 Newsgroups and Yahoo Answers datasets, withthe results averaged over 5 trials. For the Yahoo dataset, we train on sub-sampled training sets andreport results on the full test set.
Table 7: Detection results on the VOC07 dataset when varying supervision targets, where we showmaen accuracies over 3 runs.
Table 8: Document categorization results for the 20 Newsgroups dataset when varying the supervisiontarget, where we show mean accuracies over 5 runs.
Table 9: We compare center-mass values for the FAN-minicoco network between training and testing.
