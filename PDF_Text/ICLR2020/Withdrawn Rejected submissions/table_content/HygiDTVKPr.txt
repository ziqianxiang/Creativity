Table 1: Accuracy (correctly adjudicated items / total number of items) results on traditional crowd-sourcing datasets. The results of the first 4 methods are as reported in (Moreno et al., 2015).
Table 2: A summary of the variational distributions together with relevant expectations.
Table 3: Detailed evaluation results of the inferred mention pairs matched against expert annotations.
Table 4: The quality of the silver chains evaluated using standard coreference metrics against goldchains. The “#” column shows the maximum user workload where the “all” configuration uses thedataset as it is (does not alter the player workloads). CMPA is shorthand for CommunityMPA,MV for majority voting, while Stanford is the deterministic coreference system developed by Leeet al. (2011).
Table 5: Detailed evaluation results of a state of the art coreference system trained on silver chains.
Table 6: Detailed non referring scores (expletives + predicative NPs) obtained by a state of the artcoreference system trained on silver chains.
