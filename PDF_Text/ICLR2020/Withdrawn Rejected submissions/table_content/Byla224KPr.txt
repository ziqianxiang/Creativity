Table 1: Results of three post-processing methods including ours on our pretrained word vec-tors from three learning algorithms. In each cell, the three numbers refer to word vectors producedby “Skipgram / CBOW / GloVe”, and the dimension of them is 500. Bold indicates the best macro-averaged performance of post-processing methods. It shows that overall, our method is effective.
Table 2: Performance on word translation. The translation is done through k-NN with two dis-tances, in which one is the cosine similarity (noted as “NN” in the table), and the other one is theCross-domain Similarity Local Scaling (CSLS) (Lample et al., 2018). The Ledoit & Wolf’s methoddidn’t converge on unsupervised training so we excluded results from the method in the table.
Table 3: Performance of our post-processing method and the other two comparison partners onSemEval datasets. The task is to make good predictions of sentence vectors composed of averagingword vector. The word-level post-processing means that all methods are applied on word vectorsbefore averaging, and the sentence-level one means that all methods are applied on sentence vectors.
