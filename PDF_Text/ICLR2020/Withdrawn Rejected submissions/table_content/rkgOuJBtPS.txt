Table 1: Standard, robust, and attack accuracy on six GLUE tasks against ED1 perturbations. Forbaseline models, robust accuracy cannot be tractably computed, so we only compute attack accuracy,an upper bound on robust accuracy. Comparing these bounds, our agglomerative cluster encodingsoutperform the bast baseline, the typo corrector defense proposed by Pruthi et al. (2019) by 34.9points. Moreover, using TAREs we can compute the robust accuracy against the worst-case adversary,which we find outperforms the typo corrector by at least 32.7 points.
Table 2: Percentage of test examples with ∣Bα(x)∣ = 1 for each dataset.
Table 3: Results from internal permutation attacks. Internal permutation attacks bring the averageperformance for BERT across the six listed tasks from 86.2 to 15.7. Our CONNCOMP encodings,generated using the internal permutation attack surface, achieve a robust accuracy of 81.4, which isonly 4.8 points below standard accuracy.
