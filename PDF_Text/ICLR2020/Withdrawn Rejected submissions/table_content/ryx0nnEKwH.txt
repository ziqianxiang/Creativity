Table 1: Comparison of error rates (%) of BNSR, BN, BN with noisy mean and variance, BN withnoisy skewness on CIFAR-100. The training loss and error rate curves are in Fig. 2I BNSR	BN	Noise(μ, σ)	Noise(P)error ∣ 30.61	31.35	33.52	32.1Figure 2: Comparison of performance among (1) BNSR; (2) BN; (3) BN with noisy mean andvariance; (3) BN with noisy skewness on CIFAR-100. We show (a) the training loss; (b) the testingerror v.s. numbers of training epochs. The model is VGG-19.
Table 2: Comparison of error rates (%) of BNSR, BN, LN, IN on CIFAR-100. The training loss anderror rate curves are in Fig. 3I BNSR BN LN IN"error	23.49	25.51	39.78 2872~Figure 3: Comparison of performance among (1) Batch Normalization with Skewness Reduction(BNSR); (2) Batch Normalization (BN); (3) Layer Normalization (LN); (4) Instance Normalization(IN); on CIFAR-100. We show (a) the training loss; (b) the testing error v.s. numbers of trainingepochs. The model is ResNet-50.
Table 3: Comparison of error rates (%) of BN and BNSR on ImageNet dataset. The training lossand error rate curves are in Fig. 4I BNSR BNerror ∣ 38.32	39.54Figure 4: Comparison of performance between BNSR and BN on Tiny ImageNet dataset. We show(a) the training loss; (b) the testing error v.s. numbers of training epochs. The model is ResNet-50.
Table 4: Comparison of error rates (%) of BNSR under different percentage of usage on CIFAR-100.
