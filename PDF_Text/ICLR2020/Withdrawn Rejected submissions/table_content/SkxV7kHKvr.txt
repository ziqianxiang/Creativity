Table 1: The Statistics of Datasets4.2	Baselines and Experiment SettingsSince both pipelines of our proposed architecture work with graph convolution based on spectralgraph theory, we use recent works, such as ChebNet (Defferrard et al. (2016)) GCN (Kipf & Welling5Under review as a conference paper at ICLR 2020(2017)), and GWNN (Xu et al. (2019)), etc. These models maintain the same graph Lapalacian basestructure, unlike some other methods take partial graph structure, e.g. FastGCN (Chen et al. (2018))applies Monte Carlo importance sampling on edges. however, this kind of method only guaranteesthe convergence as the sample size goes to infinity.
Table 2: Results of Node ClassificationFig.4a) illustrate that when compared to the GCN, TwinGCN bearing two pipelines converges slowerbut achieves a higher accuracy as the number of epoch increases. This is because that we have twopipelines through mutual interaction. In Fig.4b), we observe that two loss curves of traditional GCNand TwinGCN have very similar decreasing trends. However, the loss curve of TwinGCN is slightlyabove GCN because the loss of TwinGCN is the summation of both primal and dual pipelines.
Table 3: Comparison resultsTable 3 shows the comparison results: the average test accuracy and the standard deviation fromthe model which has the best validation accuracy. The pipeline on the dual graph increases the6Under review as a conference paper at ICLR 20200.50ValIdatlon ACCUraCy CUrVe0 5 0 5 0 58 7 7 6 6 5■ ■■■■■Oooooo① 6ug-lod >UEDUU<0	50	100	150	200	250	300	350	400Epochs---- Val Accuracy (TwinGCN)Val Accuracy (GCN)Loss Function Curve1.6SQ 1"4
