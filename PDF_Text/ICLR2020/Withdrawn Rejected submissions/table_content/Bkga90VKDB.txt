Table 1: Machine translation accuracy in terms of BLEU for WMT En-Fr on newstest2014.
Table 2: Machine translation accuracy in terms of BLEU for WMT En-De on newstest2014.
Table 3: Machine translation accuracy in terms of BLEU for IWSLT Pt-En.
Table 4: Comparison of different methods for Funneling (64), CR refers to the compression rate.
Table 5: Comparison of different compression rates with bottleneck sizes of 64, 32 and 16 accord-ingly for IWSLT Pt-En.
Table 6: BLEU score for IWSLT Pt-En withcompression rate 7.93x.
Table 7: GroupFunneling (i.e. GroupReduce+ Funneling) on IWSLT Pt-En.
Table A.1: Parameters in the Transformer Base model (Vaswani et al. (2017)) based on a 50k dic-tionary size and tied input and output embedding.
Table A.2: Comparison of SVD with and without reconstruction loss on En-Fr translation.
Table A.3: Reconstruction losses for all language pairs.
Table A.4: BLEU score for Pt-En translation for different alpha values.
