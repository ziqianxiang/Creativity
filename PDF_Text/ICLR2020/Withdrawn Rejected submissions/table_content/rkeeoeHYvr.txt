Table 1: In the sentiment analysis task, we perform concatenative attack and scatter attack. Concatenativeadversary does not change existing context but instead appends the adversarial sentence to the paragraph, whilescatter attack scatters adversarial tokens over the whole passage. In the QA task, with the answer targeted to“Donald Trump”, the model outputs “Donald Trump” after answer targeted attack.
Table 2: Whitebox attack success rates on sentiment analysis. Targeted attack success rate is mea-sured by how many examples are successfully attacked to output the targeted label in average, whileuntargeted attack success rate calculates the percentage of examples attacked to output a label dif-ferent from the ground truth. Adv(∙) is short for our attack AdvCodec(∙) at different levels.
Table 3: Blackbox attack success rates on sentiment analysis. The transferability-based blackboxattack uses adversarial text generated from whitebox BERT model to attack blackbox SAM, andvice versa. TF is short for TextFooler.
Table 4: Whitebox attack results on QA in terms of exact match rates and F1 scores by the officialevaluation script. The lower EM and F1 scores mean the better attack success rate.
Table 5: Targeted Attack Results of whitebox attack onQA. Here, the targeted exact match rates and targeted F1Score measures how many model outputs match the tar-geted fake answers. Higher targeted EM and F1 meanhigher targeted attack success rate. UT is short for Uni-versal Trigger baseline.
Table 6: BlackBox attack results on QA in terms of exact match rates and F1 scores. Thetransferability-based blackbox attack uses adversarial text generated from whitebox models (an-notated as (w)) to attack different blakcbox models (annotated as (b)).
Table 7: Human evaluation on ad-versarial text quality aggregated bymajority vote.
Table 8: Human performance on Sentiment Analysis		Table 9: Human performance on QA	Method	Majority Acc	Method	Majority F1Origin	0.95	Origin	90.987AdvCodec(Word)	0.82	AdvCodec(Word)	82.897AdvCodec(Sent)	0.82	AdvCodec(Sent)	81.784To ensure that our generated adversarial text are compatible with the original paragraph, we askhuman participants to perform the sentiment classification and question answering task both onthe original dataset and adversarial dataset. Adversarial dataset on sentiment classification consistsof AdvCodec(Sent) concatenative adversarial examples and AdvCodec(Word) scatter attackexmaples. Adversarial dataset on QA consists of concatenative adversarial examples genereated byboth AdvCodec(Sent) and AdvCodec(Word). More specifically, we respectively prepare 100benign and adversarial data pairs for both QA and sentiment classification, and hand out them to505 Amazon Turks. Each turk is requested to answer at least 5 question and at most 15 questionsfor the QA task and judge the sentiment for at least 10 paragraphs and at most 20 paragraphs forthe sentiment classification task. We also perform a majority vote over Turk’s answers for the samequestion. The human evaluation results are displayed in Table 8 and Table 9, from which we seethat most of our concatenated adversarial text are compatible to the paragraph. While we can spota drop from the benign to adversarial datasets, we conduct an error analysis in QA and find theerror examples are noisy and not necessarily caused by our adversarial text. For adversarial datain the sentiment classification task, we notice that the generated tokens or appended sentences have
Table 10: Whitebox attack results on QA in terms of exact match rates and F1 scores by the officialevaluation script. The lower EM and F1 scores mean the better attack success rate. Adv(seq2seq)refers to AdvCodec, which uses seq2seq model as text autoencoder.
Table 11: Whitebox attack results on BERT-QA in terms of exact match rates and F1 scores by theofficial evaluation script. The lower EM and F1 scores mean the better attack success rate.
Table 12: Whitebox attack results on BERT-QA in terms of exact match rates and F1 scores by theofficial evaluation script. The lower EM and F1 scores mean the better attack success rate.
Table 13: Blackbox Attack Success Rate after					Table 14: Blackbox Attack Success Rate af-				inserting the whitebox generated adv sentence					ter inserting the whitebox generated adversarial				to different positions for BERT-classification.					sentence to different positions for BERT-QA.				Method		Back	Mid	Front	Method		Back	Mid	FrontAdv(Word)	target	0.739	0.678	0.820	Adv(Word)	EM	32.3	39.1	31.9	untarget	0.817	0.770	0.878		F1	36.4	43.4	36.3Adv(Sent)	target	0.220	0.174	0.217	Adv(Sent)	EM	47.0	51.3	42.4	untarget	0.531	0.504	0.532		F1	52.0	56.7	47.0B Model Settings & Human EvaluationB.1	Sentiment Classification ModelBERT. We use the 12-layer BERT-base model 1 with 768 hidden units, 12 self-attention headsand 110M parameters. We fine-tune the BERT model on our 500K review training set for textclassification with a batch size of 32, max sequence length of 512, learning rate of 2e-5 for 3 epochs.
Table 15:	Answer Targeted Concat Attack using AdvCodec(Sent) on QA task. The targetedanswer is Donald Trump.
Table 16:	Position Targeted Concat Attack using AdvCodec(Sent) on QA task.
Table 17:	Answer Targeted Concat Attack using AdvCodec(Word) on QA task. The targetedanswer is Donald Trump.
Table 18:	Position Targeted Concat Attack using AdvCodec(Sent) on QA task.
Table 19: Concat Attack using AdvCodec(Sent) on sentiment classification task.
Table 20:	Concat Attack using AdvCodec(Word) on sentiment classification task.
Table 21:	Scatter Attack using AdvCodec(Word) on sentiment classification task.
