Table 1: Test Accuracy (%) on SVHN. In red, SGD benefits from a hand-designed schedule for itslearning-rate. In black, adaptive methods, including ALI-G, have a single hyper-parameter for theirlearning-rate. SGDt refers to the performance reported by Zagoruyko & Komodakis (2016).
Table 2: Test Accuracy (%) on SNLI. In red, SGD benefits from a hand-designed schedule for itslearning-rate. In black, adaptive methods have a single hyper-parameter for their learning-rate. Inblue, ALI-Gâˆž does not have any hyper-parameter for its learning-rate. With an SVM loss, DFW andALI-G are procedurally identical algorithms - but in contrast to DFW, ALI-G can also employ theCE loss. Methods in the format X* re-use results from Berrada et al. (2019). SGDt is the resultfrom Conneau et al. (2017).
Table 3: Test Accuracy (%) on the CIFAR data sets. In red, SGD benefits from a hand-designedschedule for its learning-rate. In black, adaptive methods, including ALI-G, have a single hyper-Parameterfor their learning-rate. SGDt refers to the result from Zagoruyko & Komodakis (2016).
Table 4: Test Accuracy (%) on CIFAR including standard deviations. Each experiment was run threetimes.
