Table 1: MNIST and FashionMNIST modelarchitecture (33,000 parameters for k = 31).
Table 2: CIFAR10 convolutional model architec-ture (in total, 2,395,434 parameters).
Table 3: Accuracy of learning with privacy (average/best of 10 runs) compared to a non-privatebaseline of 75%. A CIFAR10 model is trained from a CIFAR100-transfer-learning initialization,with all-but-the-last layer frozen during training. The DP-SGD ε upper bounds at δ = 10-5 areε10 = 0.32, ε50 = 0.73, ε100 = 1.04, ε200 = 1.48, ε400 = 2.12 for the subscript-indicated epochs.
Table 4: CIFAR10 privacyand accuracy tradeoffs.
Table 5: Impact of batch size on trade-off between accuracy and privacy. The privacy budget is fixedto ε = 2.7 for all rows. A hyperparameter search is then conducted to find the best learning rate totrain the model with or without differential privacy on FashionMNIST.
Table 6: All convolutional architecture for CIFAR10 model with 2,334,730 parameters.
