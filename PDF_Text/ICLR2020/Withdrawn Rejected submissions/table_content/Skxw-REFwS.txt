Table 1: STAM NotationSymbol	Descriptionx	input vector.
Table 2: STAM HyperparametersSymbol	Default	DescriptionΛ	3	number of layers (index: l = 1... Λ)α	0.1	centroid learning rateβ	0.95	percentile for novelty detection distance thresholdγ	0.15	used in definition of class informative centroids∆	see below	STM capacityθ	30	number of updates for memory consolidationρi	see below	patch dimensionTable 3: MNIST/EMNIST ArchitectureLayer	Pi	∆ (incremental)	∆ (uniform)1	^^8-	400	-20002	13	400	20003	20	400	2000Table 4: SVHN ArchitectureLayer	Pi	∆ (incremental)	∆ (uniform)1	T0^	2000	100002	14	2000	100003	18	2000	10000B Image preprocessing
Table 3: MNIST/EMNIST ArchitectureLayer	Pi	∆ (incremental)	∆ (uniform)1	^^8-	400	-20002	13	400	20003	20	400	2000Table 4: SVHN ArchitectureLayer	Pi	∆ (incremental)	∆ (uniform)1	T0^	2000	100002	14	2000	100003	18	2000	10000B Image preprocessingGiven that each STAM operates on individual image patches, we perform patch normalization ratherthan image normalization. We chose a normalization operation that helps to identify similar patternsdespite variations in the brightness and contrast: every patch is transformed to zero-mean, unitvariance before clustering.At least for the datasets we consider in this paper, grayscale images resultin higher classification accuracy than color.
Table 4: SVHN ArchitectureLayer	Pi	∆ (incremental)	∆ (uniform)1	T0^	2000	100002	14	2000	100003	18	2000	10000B Image preprocessingGiven that each STAM operates on individual image patches, we perform patch normalization ratherthan image normalization. We chose a normalization operation that helps to identify similar patternsdespite variations in the brightness and contrast: every patch is transformed to zero-mean, unitvariance before clustering.At least for the datasets we consider in this paper, grayscale images resultin higher classification accuracy than color.
