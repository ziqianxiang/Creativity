Table 1: Note-wise test NLL on the MAESTRO and internal datasets, with event-based representa-tions of lengths L = 2048. We exclude the performance autoencoder baseline (no aggregation) as itmemorized the data (NLL = 0). Conditional models outperformed their unconditional counterparts.
Table 2: Note-wise test NLL on the MAESTRO and internal datasets with melody conditioning, withevent-based representations of lengths L = 2048. We note that sum worked best for MAESTRO,while concatenate outperformed all other baselines for the internal dataset.
Table 3: Average overlapping area (OA) similarity metrics comparing performance conditionedmodels with unconditional models. Unconditional and Melody-only baselines are from (Huanget al., 2019b). The metrics are described in detail in Section 4. The samples in this quantitativecomparison are used for the listener study shown in the left graph of Figure 4.
Table 4: Average overlapping area (OA) similarity metrics comparing models with different condi-tioning. Unconditional and Melody-only baselines are from (Huang et al., 2019b). The metrics aredescribed in detail in Section 4. The samples in this quantitative comparison are used for the listenerstudy shown in the right graph of Figure 4.
Table 5: Note-wise test NLL on the MAESTRO and internal piano performance datasets withmelody conditioning, with event-based representations of lengths L = 2048.
