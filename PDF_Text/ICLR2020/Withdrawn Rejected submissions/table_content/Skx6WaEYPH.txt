Table 1: Performance of post-averaging defending against different attacking methods ( = 8/255,and K = 15)._________________________________________________________________________________	Original Model			Defended by Post-Averaging					Top-1 Accuracy		Top-1 Accuracy		Defence	attack, defence	Dataset	Clean	Attacked	Clean	Attacked	Rate	#AdvFGSM, random(r=30)			0.0750	0.7734	0.7488	0.9426	3500PGD, random(r=30)	ImageNet	0.7750	0.0004	0.7732	0.7606	0.9639	3873DF, random(r=30)			0.0350	0.7730	0.7614	0.9639	3710C&W, random(r=30)			0.0090	0.7734	0.7548	0.9554	3830FGSM, random(r=6)			0.1816	0.9247	0.8022	0.8080	7552PGD, random(r=6)	CIFAR-10	0.9368	0.0000	0.9255	0.8841	0.9330	9368DF, random(r=6)			0.1968	0.9254	0.8626	0.8872	7413C&W, random(r=6)			0.0322	0.9257	0.8902	0.9367	90464.3	Experimental resultsTable 1 shows the performance of our defence approach against different attacking methods. In thistable, the samples for post-averaging are selected within an n-sphere of radius r as in eq.(8), withK = 15 different directions. Thus results in a total of 15 × 2 × 3 + 1 = 91 samples (including theinput) for each input image to be used in eq.(7). Moreover, all the adversarial samples generatedare restricted to be within the perturbation range = 8/255. We show the top-1 accuracy of theoriginal model and the defended model on both the Clean and the Attacked set respectively, as well
Table 2: Performance of post-averaging on ImageNet with different number of sampling directions(e = 8∕255 and r = 30).
