Table 1: MNLI (matched) dev set accuracy for different models.
Table 2: Transfer learning results for GLUE tasks. The source corpus is MNLI. Baseline accuracyis when Transfer BERT, Filler, and Role are all False, equivalent to no transfer. Fine-tuned accuracyis the best accuracy among all possible transfer options.
Table 3: HANS results for BERT and HUBERT (Transformer) models. Acc. indicates the averageof the results on each sub-task in HANS. Each model is fine-tuned on MNLI. ‘+’ indicates thatthe model is additionally fine-tuned on the SNLI corpus. ↑ indicates an increase and ] indicates adecrease in accuracy after the model is fine-tuned on SNLI.
Table 4: Details of the GLUE (excluding STS-B), SNLI and HANS corporaWe observed a lot of variance in the accuracy (±5%) for models trained on WNLI, MRPC, andCoLA. As mentioned in the GLUE webpage8, there are some issues with the dataset, which makesmany SOTA models perform worse than majority-voting. We found that MRPC results are highlydependent on the initial random seed and order of sentences in the shuffled training data whichis mainly caused by the small number of training samples (Table 4). CoLA is the only task inGLUE which examines grammatical correctness rather than sentiment, and thus it makes it harder tobenefit from the knowledge learned from other tasks. The train and test set are also constructed in anadversarial way which makes it very challenging. For example, the sentence “Bill pushed Harry offthe sofa for hours.” is labeled as incorrect in the train split but a very similar sentence “Bill pushedHarry off the sofa.” is labeled as correct in the test split. Hence, we only conduct our experimentson the remaining 5 datasets from GLUE.
Table 5: Transfer learning results for GLUE tasks. The source corpus is QQP. Baseline accuracy isfor when Transfer BERT, Filler, and Role are all False, which is equivalent to no transfer. Fine-tunedaccuracy is the best accuracy among all possible transfer options.
Table 6: Test set results for HUBERT (Transformer) and BERT. BERT accuracy indicates test resultson target corpus (without transfer) for bert-base-uncased which are directly taken from the GLUEleaderboard. Fine-tuned accuracy are the test results for best performing HUBERT (Transformer)model on target dev set after transfer (see Tables 2 and 5).
