Table 1: FCNN for bubble countingoperations	kernel	size	channelsconv	3×3	64×64	百conv	3×3	64×64	64max-pooling	3×3	32×32	64conv	3×3	32×32	128max-pooling	3×3	16×16	128conv	3×3	16×16	512max-pooling	3×3	8×8	512deconv	3×3	16×16	128deconv	3×3	32×32	64deconv	3×3	64×64	32conv (f (I))	3×3	64×64		1Figure 3: First layer output(yellow for higher values)The goal is to train the latent density map for localization:Θ = arg mιax Eq©(D|i)[log(p(c∣D))]	(3)In terms of training, equation 2 and 3 are identical. Following the notation of VAE (Burgess et al.,2018), we expose the hidden density map in 3 for further analysis.
Table 2: FCNN for crowd countingoperation	kernel	size	channelsRes-block	3×3	300 × 300	3^Res-block	3×3	300 × 300	64Res-block	3×3	300 × 300	128Res-block	3×3	300 × 300	128Res-block	3×3	300 × 300	128Res-block	3×3	300 × 300	64Res-block	3×3	300 × 300	32conv (f(I))	3×3	16×16		1_Figure 7: Residual BlockWe trained the network according to equation 2, where the ground-truth count within a 300×300patch is computed by adding up the head annotations. The counting error converges to around 0.85after 3×105 epochs. An example of the hidden density map is shown in Figure 6c. It shows thatthe CNN pays more attention to the human figures than the irrelevant backgrounds. But the networkdoes make some mistakes by counting parts of the booth, the tree, reflections, and the models ashuman beings, and for most of the bodies the detected features are along the their left sides. It canalso be noticed that for an individual person, the highlighted points concentrate on the upper body.
