Table 1: Descriptive statistics of the networks used in our experimental evaluation.
Table 2: Standard hyperparameter settings of the AE and MUSAE embeddings.
Table 3: Standard hyperparameter settings of the downstream logistic and elastic net regressionmodels that use the embeddings for classification, link prediction and regression.
Table 4:	Hyperparameter settings used for training the graph neural netWork baselines.
Table 5:	Node classification test performance evaluated by weighted, micro and macro F1 scorescalculated from 10 seeded train-test splits. We included standard errors of the scores and used 80%of nodes for training / 20% of nodes for testing. Red numbers denote the best performing nodeembedding method.
Table 6: Node classification test performance evaluated by weighted, micro and macro F1 scorescalculated from 10 seeded train-test splits. We included standard errors of the scores and used 80%of nodes for training / 20% of nodes for testing. Red numbers denote the best performing nodeembedding method and blue ones denote the best performing supervised graph neural network.
Table 7: Average test R2 values and standard errors on the Wikipedia traffic prediction tasks. Rednumbers denote the best results on each page-page network.
Table 8: Link prediction results - average AUC on the test set using attributed embeddings andlogistic regression. We created 100 seeded splits (80% training - 20% test). Standard errors ofAUC are included below. Red denotes the best performing embedding model considering bothneighbourhood based and attributed methods. We used 4 element-wise operators to create features.
Table 9: Link prediction results - average AUC on the test set using neighbourhood based embed-dings and logistic regression. We created 100 seeded splits (80% training - 20% test). Standarderrors of AUC are included below. Red denotes the best performing embedding model consider-ing both neighbourhood based and attributed methods. We used 4 element-wise operators to createfeatures.
