Table 2: Keyframe discovery for varied number ofpredicted keyframes. The data has approximately6 keyframes. Uninterpretable entries are omittedfor clarity: see the text for details.
Table 3: We compare different formulations for a surprise-based keyframe detection method: (1)detecting maxima of the KL divergence between prior and posterior in a stochastic prediction model,(2) detecting maxima in the lower bound on data likelihood log p (ELBO) of a stochastic predictionmodel, (3) the formulation proposed in Denton & Fergus (2018) that detects maxima of the varianceof a learned prior distribution.
Table 4: In addition to the F1 scores we report the minimal temporal distance to the next keyframeas an additional metric that is more graceful with respect to "close misses". Specifically, we reportthe distance to the next annotated keyframe averaged across predicted keyframes, min dtKruFe, and,inversely, the distance to the next predicted keyframe for each annotated keyframe, mindpKrFed. Forboth datasets the distance metrics support the F1 results: KeyIn discovers keyframes that are betteraligned with the annotated keyframes than the baselines.
Table 5: SSIM and PSNR scores on pushing and gridworld dataset. Higher is better.
Table 6: Keyframe SSIM and PSNR scores on pushing and gridworld dataset. Higher is better.
Table 7: F1 score and distance to closest annotated / predicted keyframe when trained and tested onsequences with additive Gaussian noise. KeyIn is able to reliably find keyframes on both datasetseven when trained and tested on noisy sequences. Even though the F1 score is lower on the Pushingdataset, the distances indicate that the discovered keyframes are well aligned with the annotatedkeyframes even under noise.
Table 8: Hyperparameters for the visual planning experiments.
