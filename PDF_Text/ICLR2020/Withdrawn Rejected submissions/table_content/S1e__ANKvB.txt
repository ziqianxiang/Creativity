Table 1: Input representation of atom nodesAtom FeatureDescriptionAtom typeAtom numberAcceptorDonorAromaticHybridizationNumber of HydrogensC, N, O, S, P, B, F, I, Sn, Cl, Br, Se, Si (one-hot)Numbers of protons (integer)Accepts electrons (binary)Donates electrons (binary)In an aromatic system (binary)sp, sp2, sp3 (one-hot or null)(integer)where U1 , U2 and b are trainable parameters.
Table 2: Comparison of top-n accuracies across all classesModel	top-n accuracy (%)				1		5	10Rule-based Expert System	^354	52.3	59.1	65.1LSTM+Attention	37.4	52.4	57.0	61.7Similarity	52.9	73.8	81.2	88.1Transformer (baseline)	ɪɪ	68.4	72.0	74.4GET-CT (our)	55.9	70.1	73.2	76.3GET-LG (our)	54.9	69.7	72.2	74.6GET-LT2 (our)	56.2	69.4	72.5	74.7GET-LT1 (our)	57.4	71.3*	74.8*	77.4*Table 3: Comparison of top-n accuracies across all classes without reaction typeModel	top-n accuracy (%) -1	3	5	10-Similarity	-373^^547^^633^^74TTransformer (baseline) GET-LT1 (our)	^T2.3^^575^^610^^65.7- 44.9 58.8 62.4 65.9Results show that our models outperform all of previous methods in top-1 accuracy, and ourbest model GET-LT1 achieves the new state-of-the-art among all Seq2Seq-based methods, i.e,7Under review as a conference paper at ICLR 2020LSTM+Attention, vanilla Transformer and models of GET. Compared with vanilla Transformer,
Table 3: Comparison of top-n accuracies across all classes without reaction typeModel	top-n accuracy (%) -1	3	5	10-Similarity	-373^^547^^633^^74TTransformer (baseline) GET-LT1 (our)	^T2.3^^575^^610^^65.7- 44.9 58.8 62.4 65.9Results show that our models outperform all of previous methods in top-1 accuracy, and ourbest model GET-LT1 achieves the new state-of-the-art among all Seq2Seq-based methods, i.e,7Under review as a conference paper at ICLR 2020LSTM+Attention, vanilla Transformer and models of GET. Compared with vanilla Transformer,GET-LT1 can improve the prediction accuracy by 3.1%, 2.9%, 2.8% and 3.0% in top-1, top-3, top-5and top-10 accuracy. Other variants also have varying degrees of performance improvement overvanilla Transformer. And our model can retain this comprehensive superiority after removing thereaction type, demonstrating that molecule structure information can help Transformer to predictmore accurate reactants. Besides, note that Similarity (Coley et al., 2017) is a template-based modelwhich predicts 100 candidates and just chooses the top-10 as the final result, while other template-free models, i.e., LSTM+Attention, Transformer and GET, are trained to accurately predict the top-1output and only generate 10 candidates using beam search. Therefore, it is not surprising that Simi-larity achieves very high accuracy. Nevertheless, even in this unfair situation, our models can surpassSimilarity up to 4.5% in top-1 accuracy.
Table 4: Comparison of the top-10 accuracy for each reaction classIvrCAnI				top-10 accuracy (%)								10	1	2	3	4	5	6	7	8	9	LSTM+Attention	57.5	74.6	46.1	27.8	80.0	62.8	67.8	69.1	47.3	56.5Transformer (baseline)	73.5	81.9	62.7	52.2	86.1	71.5	80.0	83.9	65.2	73.9GET-LT1 (our)	76.6	84.2	66.1	65.6	89.2	75.7	81.3	81.5	71.7	91.3Furthermore, the rate of producing grammatically invalid SMILES for different beam sizes areshown in Table 5 (with reaction type). As can be seen, after fusing molecule structure information,the model is more inclined to generate chemical-valid SMILES compared with vanilla Transformer,since the graphical representations, which directly capture the topological connection of atoms, areable to break the limitation of the SMILES sequence and can give the model additional guidance toproduce chemical-valid compound.
Table 5: The rate of producing grammatically invalid SMILES for different beam sizesModel	invalid SMILES, rate (%) when beam size k =				1	3	5	10LSTM+Attention	12.2	15.3	18.4	22.0Transformer (baseline)	3.5	14.3	20.3	30.2GET-LT1 (our)	2.2	13.4	19.5	29.36	Conclusion and Future WorkWe propose Graph Enhanced Transformer(GET), an effective framework that successfully combinesthe graphical and sequential representations of the molecule to improve the retrosynthesis predic-tion performance. Experiments indicate that our model outperforms state-of-the-art Seq2Seq-basedmethods on USPTO-50K dataset, and shows promising ability in reducing invalid SMILES rate.
