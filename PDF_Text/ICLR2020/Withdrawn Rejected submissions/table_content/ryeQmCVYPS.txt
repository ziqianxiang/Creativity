Table 1: The accuracy of standard and defective CNNs to classify randomly shuffled test images.
Table 2: Black-box defense performances against transfer-based attacks.
Table 3: Black-box defense performances against transfer-based attacks. Numbers in the middle meanthe success defense rates. Networks in the first row are the source models for generating adversarialexamples by PGD. 0.5-Bottom and 0.3-Bottom mean applying defective convolutional layers withkeep probability 0.5 and 0.3 to the bottom layers of the network whose name lies just above them.
Table 4: Ablation experiments of defective CNN. Numbers in the middle mean the success defenserates. p-Bottom and p-Top mean applying defective layers with keep probability p to bottomlayers and top layers respectively. p-BottomDC means making whole channels defective withkeep probability p. p-BottomSM means using the same defective mask in every channel withkeep probability p. p-Bottom×n means increasing channel number to n times at defective layers.
Table 5: Black-box defense performances against transfer-based attacks from ensemble models onthe CIFAR-10 dataset. Numbers in the middle mean the success defense rates. Networks in the firstrow indicate the source models which ensemble other four models except for the network itself. Thesource model generates adversarial examples by PGD. 0.5-Bottom and 0.3-Bottom mean applyingdefective convolutional layers with keep probability 0.5 and 0.3 to the bottom layers of the networkwhose name lies just above them. The source and target networks are initialized differently if theyshare the same architecture.
Table 6: Black-box defense performances against transfer-based attacks on the MNIST dataset.
Table 7: Black-box defense performances against decision-based attack (See Section A.4 for thecomplete setting). The larger value S(M) (defined in Equation (10)) has, the more robust the modelis. LS means label smoothing.
Table 8: Defense performances against white-box attacks. Numbers in the middle mean the successdefense rates. FGSM1, FGSM2, FGSM4 refer to FGSM with perturbation scale 1,2,4 respectively.
Table 9: Defense performances against two kinds of gray-box attacks for defective CNNs. Numbersmean the success defense rates. Networks in the first row are the source models for generatingadversarial examples by PGD, which runs for 20 steps with step size 1 and perturbation scale'∞ = 16. 0.5-Bottom and 0.3-Bottom in the left column represent the networks with the samestructure as the corresponding source networks but with different initialization. 0.5-BottomDIF and0.3-BottomDIF in the left column represent the networks with the same keep probabilities as thecorresponding source networks but with different sampling of defective neurons.
Table 10: Defense performances against gray-box attacks for standard CNNs. Numbers mean thesuccess defense rates. Networks in the first row are the source models for generating adversarialexamples by PGD, which runs for 20 steps with step size 1 and perturbation scale '∞ = 16. Thediagonal shows gray-box performances in the setting that the source and target networks share thesame structure but with different initializations.
Table 11: Extended experimental results of Section 4.3. Adversarial examples generated againstDenseNet-121. Numbers in the middle mean the success defense rates. The model trained on CIFAR-10 achieves 95.62% accuracy on test set. p-Bottom, p-Top, p-BottomDC, p-BottomSM, p-Bottom×nand p-BottomEN mean applying defective layers with keep probability p to bottom layers, applyingdefective layers with keep probability p to top layers, making whole channels defective with keepprobability p, using the same defective mask in every channel with keep probability p, increasingchannel number to n times at bottom layers and ensemble five models with different defective masksof the same keep probability p respectively.
Table 12: Extended experimental results of Section 4.3. Numbers in the middle mean the successdefense rates. Adversarial examples are generated against ResNet-18. The model trained on CIFAR-10 achieves 95.27% accuracy on test set. p-Bottom, p-Top, p-BottomDC, p-BottomSM, p-Bottom×nand p-BottomEN mean applying defective layers with keep probability p to bottom layers, applyingdefective layers with keep probability p to top layers, making whole channels defective with keepprobability p, using the same defective mask in every channel with keep probability p, increasingchannel number to n times at bottom layers and ensemble five models with different defective masksof the same keep probability p respectively.
Table 13: Extended experimental results of Section 4.3. Adversarial examples are generated againstResNet-50. Numbers in the middle mean the success defense rates. The model trained on CIFAR-10 achieves 95.69% accuracy on test set. p-Bottom, p-Top, p-BottomDC, p-BottomSM, p-Bottom×nand p-BottomEN mean applying defective layers with keep probability p to bottom layers, applyingdefective layers with keep probability p to top layers, making whole channels defective with keepprobability p, using the same defective mask in every channel with keep probability p, increasingchannel number to n times at bottom layers and ensemble five models with different defective masksof the same keep probability p respectively.
Table 14: Extended experimental results of Section 4.3. Numbers in the middle mean the successdefense rates. Adversarial examples are generated against SENet-18. The model trained on CIFAR-10 achieves 95.15% accuracy on test set. p-Bottom, p-Top, p-BottomDC, p-BottomSM, p-Bottom×nand p-BottomEN mean applying defective layers with keep probability p to bottom layers, applyingdefective layers with keep probability p to top layers, making whole channels defective with keepprobability p, using the same defective mask in every channel with keep probability p, increasingchannel number to n times at bottom layers and ensemble five models with different defective masksof the same keep probability p respectively.
Table 15: Extended experimental results of Section 4.3. Numbers in the middle mean the successdefense rates. Adversarial examples are generated against VGG-19. The model trained on CIFAR-10 achieves 94.04% accuracy on test set. p-Bottom, p-Top, p-BottomDC, p-BottomSM, p-Bottom×nand p-BottomEN mean applying defective layers with keep probability p to bottom layers, applyingdefective layers with keep probability p to top layers, making whole channels defective with keepprobability p, using the same defective mask in every channel with keep probability p, increasingchannel number to n times at bottom layers and ensemble five models with different defective masksof the same keep probability p respectively.
