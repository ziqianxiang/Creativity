Table 1: Test F1-Scores for Each SeedRun	Baseline	GAN-based Synthetic Data	ADASYN Autoencoder	GAN Discriminator Novelty Detection	GAN Autoencoder Novelty Detection0	0.79%	2.02%	0.52%	0.50%	1.27%1	1.77%	3.15%	0.30%	0.50%	1.14%2	1.28%	2.06%	0.50%	0.32%	1.26%3	1.29%	1.72%	0.49%	0.50%	1.00%4	0.68%	1.79%	0.52%	0.50%	1.17%Average	1.16%	2.15%	0.47%	0.46%	1.17%Standard Deviation	0.44%	0.58%	0.09%	0.08%	0.11%Comparing the results of each of the proposed methods against the baseline in Table 1, we observethat the only method that significantly improves classification accuracy is the GAN-based syntheticdata model with p-value = 0.01 based on the t-test. Surprisingly, using the ADASYN Autoencodergenerated synthetic data leads to a substantial decrease in the F1-score, suggesting that this syntheticdata technique does not capture the structure of the minority data. This suggests that interpolationin the autoencoder latent space is not sufficient, and the GAN component of the autoencoder isnecessary. We also note that the difference in the F1-score between the two novelty detection meth-ods is significant with p-value=2.8e-6 according to the t-test. We observe that the choice of outlierdetection is important for novelty detection.
Table 2: Differences Between Predictions for GAN Minority and Baseline Models	True Majority	True MinorityPredicted Majority	60^^	-1Predicted Minority	-60	1To explore how the models trained on the synthetic data improve on the baseline models, we examinethe difference between the confusion matrix of predictions on the test set for a model trained withand without the GAN-based synthetic data. In Table 2, we note that a number of false negatives andfalse positives in the baseline model are converted to true positives and true negatives, respectivelyin the model trained on the GAN-based synthetic data. That is, the improvement in classificationaccuracy of the model trained with the GAN-based synthetic data is due to a decrease in both falsenegatives and false positives.
Table 3: Test F1-ScoresData Imbalance	Baseline	GAN-based Synthetic Data	ADASYN Autoencoder	GAN Discriminator Novelty Detection	GAN Autoencoder Novelty Detection1%	7.80%	17.76%	0.00%	2.36%	1.86%5%	56.75%	52.85%	9.47%	9.63%	9.46%In Table 3, we compare the results of each of the proposed methods against the baseline. The onlymethod that significantly improves the F1-score is the model trained on the GAN-based syntheticdata. We also note that with 5% imbalance, the baseline model performance on the ensembles ishigh enough that the anomaly detection methods we consider do not improve performance. Thissuggests that these synthetic data generation techniques are only effective for highly imbalanceddatasets.
