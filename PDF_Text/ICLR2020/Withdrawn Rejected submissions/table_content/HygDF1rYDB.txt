Table 1: Notation used in the paper.
Table 2: Simulated Data I & II - Explanation performance compared to ground-truth. For Simulated DataII, We also show in the third column that the log-probabilities of our CoUnterfaCtUals are higher under the truedistribution.
Table 3: Real Data - Global Importance.
Table 4: Sanity Check Test Results for Simulated Data II. For all measures higher difference is better.
Table 5: General generator SettingSoftware used: Python 3.7.3 , Pytorch 1.0.1.post2GPU Info: Quadro 400CPU Info: Intel(R) Xeon(R) CPU E5-1620 v4 @ 3.50GHzThe counterfactual for observation i at time t can now be sampled by marginalizing over otherfeatures attime t. i.e, χit 〜 Px ,p(X|X0：t—i).
Table 6: List of clinical features for the risk predictor modelParameter Settings for mortality risk predictor model: The risk predictor model is a recurrentnetwork with GRU cells. All features are scaled to 0 mean, unit variance and the target is a probabilityscore ranging [0, 1]. The model achieves 0.7939(0.007) AUC on test set classification task. Detailedspecification of the model are presented in Table 7.
Table 7: Mortality risk predictor model features(a) Risk predictor MSE loss(b) Generator LossParameter Settings for conditional Generator: The recurrent network with specifications showin 8 learns a hidden latent vector ht representing the history. ht is then concatenated with x-i,t andfed into a non-linear 1-layer MLP to model the conditional distribution p(xi, t|X0:t-1).
Table 8: Training Settings for Feature Generators for MIMIC-III DataRisk scoreventvaso---------BICARBONATE---------LACTATE---------MAGNESIUM---------PHOSPHATE-----------SODIUM-----------HeartRateRespRatephenylephrinecolloid bolus—crystal Io id_bolu sBICARBONATEGLUCOSEMAGNESIUMSODIUMWBC
Table 9: Run-time results for simulated data and MIMIC experiment.
Table 10: Training Settings for Feature Generators for GHG DataParameter Settings for Black-Box: This black box regresses d = 15 tracer time signals to thetarget synthetic GHG time series for t = 327 time points. This model is trained using a 65%,15%,20%train, validation, test set respectively. All features are scaled to 0 mean unit variance and the target16Under review as a conference paper at ICLR 2020Figure 11: Left: Generator Loss for ghg data. Right: (Scaled) Regresser MSE lossis scaled time series is scaled in the range [-1, 1]. The regressor is an RNN model with theparameter settings given in Table 11. Figure 11 (a) shows the generator loss for all trained conditionalSetting	valueepochs	200Model	RNNbatch size	100Encoding size (m)	100Loss	MSERegressor Activation	LinearGradient Algorithm	Adam (learning rate = 0.001, βι = 0.9, β2 = 0.999, weight decay = 0)Table 11: Training Settings for Regressor for GHG Data(counterfactual) generators, while Figure 11 shows the training loss of black-box that was used topresent feature important results in Section 4.4.
Table 11: Training Settings for Regressor for GHG Data(counterfactual) generators, while Figure 11 shows the training loss of black-box that was used topresent feature important results in Section 4.4.
