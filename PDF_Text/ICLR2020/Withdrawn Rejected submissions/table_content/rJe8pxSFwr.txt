Table 1: Performance of AE schemes in presence of missing data for Fashion MNIST dataset:for a given convolutional AE architecture (see main text for details), a PCA and ConvAE mod-els trained on gap-free data with a 15-iteration projection-based interpolation (resp., DINEOF andConvAE), a zero-filling stratefy with the same ConvAE architecture (Zero-ConvAE) and the fixed-point and gradient-based versions of the proposed scheme. For each experiment, we evaluate fourmeasures: the reconstruction performance for the known image areas (R-score), the interpolationperformance for the missing data areas (I-score), the reconstruction performance of the trained AEwhen applied to gap-free images (AE-score), the classification score of a MLP classifier trained inthe trained latent space for training images involving missing data.
Table 2: Performance on SST dataset: We evaluate for each model interpolation, reconstructionand auto-encoding scores, resp. I-score, R-score and AE-score, in terms of percentage of explainedvariance resp. for the interpolation of missing data areas, the reconstruction of the whole imagewith missing data and the reconstruction of gap-free images. For each model, we evaluate thesescore for the training data (first row) and the test dataset (second row in brackets). We consider fourdifferent auto-encoder models, namely 20 and 80-dimensional PCAs and ConvAE1,2 models, andtwo GE-NN models, GE-NN1,2, combined with three interpolation strategies: the classic zero-fillingstrategy (Zero) and proposed iterative fixed-point (FP) and gradient-based (G) schemes, the figurein brackets denoting the number of iterations. For instance, FP(10)-GE-NN1 refers to GE-NN1with a 10-step fixed-point interpolation scheme. The PCAs are trained from gap-free data. We alsoconsider an Optimal Interpolation (OI) with a space-time Gaussian covariance with empirically-tuned parameters. We refer the reader to the main text for the detailed parameterization of theconsidered models.
Table 3: Interpolation performance for Lorenz-63 dynamics with different missing datarates: we compare the proposed neural-network aproach (FP(15)-GE-NN) to an ensemble KalmanSmoother (EnKS) assuming the dynamical model (12) is known, and a DINEOF scheme (21). Wereport interpolation results for a 75% missing data rate with uniform random sampling for threedifferent sampling time steps, dt = 0.01, dt = 0.02 and dt = 0.04. We report the mean square errorof the interpolation for the observed data (first row) and masked ones (second row).
