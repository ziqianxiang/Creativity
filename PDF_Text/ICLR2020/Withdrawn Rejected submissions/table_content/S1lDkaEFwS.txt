Table 1: Output randomization vs 3 black box attacks on 100 correctly classified ImageNet examplesmeasured by attack success rate (fraction of examples misclassified)Noise Variance	ZOO (18)	QL (19)	BAND (21)(undefended)	0.69	1.00	0.921.00e-4	0.03	0.73	0.581.00e-2	0.00	0.02	0.075.76e-2	0.00	0.01	0.067Under review as a conference paper at ICLR 2020Table 2: ZOO black box attack success rate vs three defensesDataset	Ex. Type	Distillation(10)	Mitigation(26)	OR (ours)MNIST	Targeted	1.00	-	0.00MNIST	Untargeted	0.99	-	0.01CIFAR10	Targeted	1.00	-	0.011CIFAR10	Untargeted	1.00	-	0.19ImageNet	Untargeted	-	0.76	0.0056	Related workIn this section, we discuss related gradient masking or obfuscated gradient defenses. We will focuson proactive defenses, which attempt to make a network robust, compared to reactive defenses, whichattempt to detect adversarial examples. (25) defined three ways to obfuscate gradients: shattered
Table 2: ZOO black box attack success rate vs three defensesDataset	Ex. Type	Distillation(10)	Mitigation(26)	OR (ours)MNIST	Targeted	1.00	-	0.00MNIST	Untargeted	0.99	-	0.01CIFAR10	Targeted	1.00	-	0.011CIFAR10	Untargeted	1.00	-	0.19ImageNet	Untargeted	-	0.76	0.0056	Related workIn this section, we discuss related gradient masking or obfuscated gradient defenses. We will focuson proactive defenses, which attempt to make a network robust, compared to reactive defenses, whichattempt to detect adversarial examples. (25) defined three ways to obfuscate gradients: shatteredgradients, exploding/vanishing gradients, and stochastic gradients.
