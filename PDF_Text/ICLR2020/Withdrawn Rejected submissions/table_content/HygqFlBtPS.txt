Table 1: Results on MNIST, and CIFAR10 with small networks, large networks, and different coefficients ofd(x,δ5, W,b), r(x,δo, W,b). All entries With positive λ or Y are using our regularizers. For all models notmarked as “Exact”, we have projected the input dimension of Wi:1 to 50, the same as Wong et al. (2018). For val-ues with *, larger e is used for training. e = 0.3, 2/255, 8/255 correspond to using e = 0.4, 2.2/255, 8.8/255for training respectively. For the methods: 1: (Dvijotham et al., 2018a); 2: (Xiao et al., 2018); 3: (Mirman et al.,2018); 4 (Gowal et al., 2018).
Table 2: Our results on the MNIST dataset, with CROWN-IBP. CI Orig are results copied from the paper, CIReImp are results of our implementation of CROWN-IBP, and CI Reg is with regularizer r.
Table 3: Ablation results on CIFAR10 with the small model, where = 2/255.
Table 4: Mean and standard deviation of the family of 10small models on MNIST with = 0.3. Baselineis CROWN-IBP with epoch=140 and lr_decay_SteP=20. Like in CROWN-IBR We run each model 5 times tocompute the mean and standard deviation. “Copied” are results from (Zhang et al., 2019b).
