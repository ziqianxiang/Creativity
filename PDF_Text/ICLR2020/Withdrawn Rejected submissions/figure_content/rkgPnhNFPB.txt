Figure 1: Deep learning representations of GAN-data are constructed by applying successive Lips-chitz operations to Gaussian vectors, therefore they are concentrated vectors by design, since Gaus-sian vectors are concentrated and thanks to the Lipschitz stability in Proposition 2.3.
Figure 2: Behavior of the largest singular value of a weight matrix in terms of the iterations ofa random walk (See proposition 3.1), without spectral normalization in (blue) and with spectralnormalization in (red). The (black) lines correspond to the theoretical bound yzσ2 + η2d1d0 fordifferent σjs. We took d° = di = 100 and η = 1/d0.
Figure 3: (Top) GAN generated images using the BigGAN model Brock et al. (2018). (Bottom)Real images selected from the Imagenet dataset Deng et al. (2009). We considered n = 1500 imagesfrom k = 3 classes which are Mushroom, Pizza and Hamburger.
Figure 4: (Top) Spectrum and leading eigenspace of the Gram matrix for CNN representations ofGAN generated images using the BigGAN model Brock et al. (2018). (Bottom) Spectrum andleading eigenspace of the Gram matrix for CNN representations of real images selected from theImagenet dataset Deng et al. (2009). Columns correspond to the three representation networks(Resnet50, VGG16 and Densenet201).
