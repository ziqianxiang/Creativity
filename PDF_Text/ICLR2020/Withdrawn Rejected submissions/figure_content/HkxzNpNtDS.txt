Figure 1: Overview of environment-agnostic multitask learning. See Section 3.1 for more details.
Figure 2: Selected tokens from the vocabulary for VLN (left) and NDH (right) tasks which gainedmore than 40 additional occurrences in the training dataset due to joint-training.
Figure 3: t-SNE visualization of trajectory encoder's output (1000 random paths across 11 differ-ent color-coded environments) for models trained with environment-aware objective (left) versusenvironment-agnostic objective (right).
Figure 4: Visualizing performance gap between seen and unseen environments for VLN and NDHtasks. For VLN, the plotted metric is agent’s success rate while for NDH, the metric is agent’sprogress.
