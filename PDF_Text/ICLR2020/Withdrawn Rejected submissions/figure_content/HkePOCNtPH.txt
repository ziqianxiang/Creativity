Figure 1: Highlighted pixels show convolution patterns for each tower, with the grey pixel being thecenter of each kernel.
Figure 2: Average normalized FreChet distance between the phrases of the distributionsAnother measure to visualize similarity between distributions is the t-distributed stochastic neigh-bourhood embedding (t-SNE) algorithm developed byMaaten & Hinton (2008). This algorithmgroups points that are similar in higher dimension closer together in low dimensions - making ituseful to visualize similarity between the tunes generated by both models along with the trainingdata. Here, we set the tunable parameter perplexity to 50. This increases the importance of globalsimilarity between vectors.
Figure 3: t-SNE visualization of the distributions of tunesOverall, these metrics show that music generated by our DCGAN is comparable to melodies gener-ated by RNNs on the same symbolic data. The use of dilations allows for our model to learn globaltune structure.
Figure 4: Distribution of notes5 ConclusionConverting sequential data into a format which implicitly encodes temporal information as spatialinformation is an effective way of generating samples of such data as whole pieces. Here, weexplored this approach for melody generation of fixed-length music forms, such as an Irish reel,using non-recurrent architecture for the discriminator CNN with towers and dilations, as well as aCNN for the GAN itself.
