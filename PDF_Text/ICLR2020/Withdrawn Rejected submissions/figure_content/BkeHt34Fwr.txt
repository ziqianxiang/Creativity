Figure 1: Schematic figure: Binary classification task, where nodes can be either black or white. Thelabel of nodes 1,4,6,9 (surrounded by dotted gray line) is already known. For each unlabeled node,the classifier prediction score is given by the grayscale between black and white. Local uncertaintytechniques would query node 21. However, knowing the label of this node would have a minimaleffect on other nodes. Regional uncertainty techniques would query the node with the most uncertainregion. In this case, those are nodes 5 and 14, since the first is surrounded by nodes with highlikelihood to both black and white (separates black and white), and the second is surrounded bynodes with high uncertainty. Standard centrality measures would query node 10, which is morecentral, ignoring the fact that this node is close to the two already known nodes (6,9), and thusprobably would not add much information. In contrast, the adaptive approach which seeks the ratiobetween APR and PR would favor node 14, since it is far from the influence of nodes with knownlabels, thus will append more new information, and still is very central.
Figure 2: Accuracy and Macro F1 as a function of training set fraction in 3 datasets for differentlearning methods. We tested for three reported datasets multiple precision estimates as a functionof the training set fraction. We have tested four algorithms: GXBoost, FFN, GCN and RF. Foreach algorithm, we tested three types of input, the neighbors class, topological features of the nodeand the combination of the two. The precision was computed for different training set fractions ina passive setup where the training set is pre-defined. One can clearly see that in all datasets andusing all measures, the GCN with the neighbors class as input produces the best accuracies (blackthick line).
Figure 3: Accuracy as a function of sampling fraction for different datasets and different local ALmethods. Results lower than the random sampling line (Thick gray line) represent AL algorithmsthat do not contribute to the accuracy. The two subplots surrounded by a box are the results with theBOW. We have tested Micro and Macro F1 as well as the loss, with similar results (data not shown).
Figure 4: Distance to randomly sampled nodes as a function of the fraction of sampled fraction.
