Figure 1: Illustration of our idea. S is the peer pre-diction function; our `peer is to “evaluate” a classi-fier’s prediction using a noisy reference.
Figure 2: Accuracy on test set during trainingA subset of the experiment results are shown in Table 1. A full table with all details can be foundin Appendix. Equalized Prior means that we pre-sample the dataset to guarantee p = 0.5. For thiscase We used 'peer without a (or rather α = 1 as in 'α-peer). For P = 0.5, We use validation dataset(using noisy labels) to tune α. Our method is competitive across all datasets and is even able tooutperform the surrogate loss method with access to the true error rates in a number of datasets, aswell as symmetric loss functions (which does not require the knowledge of noise rates when errorrates are symmetric) and the recently proposed information theoretical loss (Xu et al., 2019). Fig. 2shows that our method can prevent over-fitting when facing noisy labels.
Figure 3: Illustration of peer loss method.
Figure 4: Accuracy on test set during trainingloss method with access to the true error rates in most of them. C-SVM is also robust when errorrates are symmetric, and is competitive in 8 datasets.
