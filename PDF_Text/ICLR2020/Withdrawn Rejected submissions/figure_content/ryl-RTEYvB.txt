Figure 1: Cross sections of decision cells in the input space. To make these cross sections forLeNet’ models trained on the MNIST dataset, a test sample (black dot) and a two-dimensionalhyperplane ⊂ R784 passing through it are randomly chosen. Different colors indicate the differentclasses predicted by these models, transparency and contours are set by maximum of the softmaxvalues, and the circle around the test sample signifies distance to the closest decision boundary in theplane. (a) Decision cells are rugged without regularization. (b) Training with L2 regularization leadsto smoother decision cells, but does not necessarily ensure large cells. (c) Jacobian regularizationpushes boundaries outwards and embiggens decision cells.
Figure 2: Comparison of Approximate to Exact Jacobian Regularizer. The difference betweenthe exact method (cyan) and the random projection method with nproj = 1 (blue) and nproj = 3 (redorange) is negligible both in terms of accuracy (a) and the norm of the input-output Jacobian (b) onthe test set for LeNet’ models trained on MNIST with λJR = 0.01. Shading indicates the standarddeviation estimated over 5 distinct runs and dashed vertical lines signify the learning rate quenches.
Figure 3: Robustness against random and adversarial input perturbations. This key result il-lustrates that JaCobian regularization signifiCantly inCreases the robustness of a learned model withLeNet’ arChiteCture trained on the MNIST dataset. (a) Considering robustness under white noise per-turbations, JaCobian minimization is the most effeCtive regularizer. (b,C) JaCobian regularization aloneoutperforms an adversarial training defense (base models all inClude L2 and dropout regularization).
Figure S1:	Cross sections of decision cells in the input space for LeNet’ models trained on theMNIST dataset along random hyperplanes. Figure specifications are same as in Figure 1. (Left)No regularization. (Middle) L2 regularization with λWD = 0.0005 . (Right) Jacobian regularizationwith λJR = 0.01.
Figure S2:	Cross sections of decision cells in the input space for LeNet’ models trained on theMNIST dataset along adversarial hyperplanes. Namely, given a test sample (black dot), thehyperplane through it is spanned by two adversarial examples identified through FGSM, one for themodel trained with L2 regularization λWD = 0.0005 and dropout rate 0.5 but no defense (dark-greydot; left figure) and the other for the model with the same standard regularization methods plusJacobian regularization λJR = 0.01 and adversarial training (white-grey dot; right figure).
Figure S3:	Robustness against random and adversarial input perturbations for DDNet modelstrained on the CIFAR-10 dataset. Shades indicate standard deviations estimated over 5 distinctruns. (a) Comparison of regularization methods for robustness to white noise perturbations. (b,c)Comparison of different defense methods against adversarial attacks (all models here equipped withL2 and dropout regularization).
Figure S4:	Robustness against random and adversarial input perturbations for ResNet-18 mod-els trained on the CIFAR-10 dataset. Shades indicate standard deviations estimated over 5 distinctruns. (a) Comparison of regularization methods for robustness to white noise perturbations. (b,c)Comparison of different defense methods against adversarial attacks (all models here equipped withL2 regularization but not dropout: see Appendix D).
Figure S5:	Effects on test accuracy incurred by various modes of attacks. (a,d) LeNet’ onMNIST, (b,e) DDNet on CIFAR-10, and (c,f) ResNet-18 on CIFAR-10 trained (a,b,c) without defenseand (d,e,f) With defense - Jacobian regularization magnitude λJR = 0.01 and adversarial trainingwith εFGsM ∈ [0,0.01] - all also include L2 regularization λwD = 0.0005 and (except ReSNet-18)dropout rate 0.5.
Figure S6:	Dependence of robustness on the Jacobian regularization magnitude λJR. Accuracyunder corruption of input test data are evaluated for various models [base models all include L2(λWD = 0.0005) regularization and, except for ResNet-18, dropout (rate 0.5) regularization]. Shadesindicate standard deviations estimated over 5 distinct runs.
Figure S7:	Dependence of robustness on the Jacobian regularization magnitude λJR for Ima-geNet. Accuracy under corruption of input test data are evaluated for ResNet-18 trained on ImageNet[base models include L2 (λWD = 0.0001)] for a single run. For CW attack in (c), we used 10,000test examples (rather than 1,000 used for other figures) to compensate for the lack of multiple runs.
