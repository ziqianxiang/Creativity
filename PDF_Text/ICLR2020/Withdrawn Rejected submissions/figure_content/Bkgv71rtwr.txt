Figure 1: A comparison between (a) closed-setdomain adaptation, (b) existing methods for open-set domain adaptation, and (c) our open-set domainadaptation with category-agnostic clusters.
Figure 2: An overview of our SE-CC. Each labeled source image is fed into student model to train the classifierwith cross entropy. Each unlabeled target image xt is transformed into two perturbed samples, i.e., xtS and xtT ,before injected into student and teacher models separately. Conditional entropy is applied to xtS in studentpathway and self-ensembling loss is adopted to align the classification predictions between teacher and student.
Figure 3:Studentmodel Â»Framework of global mutual information estimation in our SE-CC.
Figure 4: Framework of local mutual information estimation in our SE-CC.
Figure 5: The t-SNE visualization of features learnt by (a) Source-only, (b) SE, and (c) SE-CC on VisDAdataset for open-set domain adaptation.
