Figure 1: Comparison between meta-learning (left) and localized meta-learning (right). In regularmeta-learning, the mean of prior wP is sampled from a global hyperposterior distribution Q =N(wQ, σw2 Idw). In the localized meta-learning, wP is produced by a prior predictor Φv(Dm).
Figure 2: A geometric view of Local Coordinate Coding. Given a set of anchor points, if data lieon a manifold, the empirical prior predictor Φv (S) can be locally approximated by a linear functionw.r.t. the coding. Given all bases, Φv (S) can be globally approximated.
Figure 3:	The average test accuracy of learning a new task for different number of training tasks(|C| = 64).
Figure 4:	(a) The impact of the number of bases |C | in LCC. (b) The divergence value (normalized)between the mean generated prior wP and the mean of learned posterior wQ .
