Figure 1: A good teacher may not be able to produce a good student. To maximize the effectivenessof distillation, you should early stop your epoch at a proper time.
Figure 2: Components of label noise in the largest five eigensapces of NTK are decreasing.
Figure 3: Comparison of error flow among MentorNet Jiang et al. (2017), Co-teaching Han et al.
Figure 4: Training on CIFAR10 with 40% noise injection.
Figure 5: Self-distillation always gains information.
