Figure 1: We propose a weakly-supervised approach for segmenting demonstrations into skill primitives, aka,sub-tasks. Our approach is end-to-end trainable, works directly from raw sensory data (e.g., images) and onlyrequires the knowledge of class of primitive sub-tasks performed during the demonstration to accomplish the endtask, without any need of segmentation or ordering of primitives. The key idea is to make per-time step predictioncorresponding to each sub-task and accumulate them to generate a trajectory-level predictions which are thentrained to match trajectory-level tags. Our segmentation model consists of an encoder followed by a recurrentLSTM model to capture time-series dependency. We use log-sum-exp to perform smooth accumulation oftime-step predictions into trajectory-level predictions.
Figure 2: We evaluate across four environments with different properties: (a) Discrete 2D Navigation as proofof concept. (b) Dial continuous control: Jaco robotic arm based manipulation with procedurally generateddemonstrations. (c) RoboSuite environment: Sawyer robot in simulation with human-collected demonstrations.
Figure 3: Figure shows qualitative visualization of the skills (sub-sampled) discovered by our approach onheld-out test set. (a) Dial Env: learned primitives using Jaco arm manipulation are shown. Skill # N correspondsto the arm dialing number N on touch pad. (b) RoboSuite Env: Three predicted primitives are shown where theprimitives are to pick and place an object into corresponding bin (top to bottom: cereal, milk, box) (c) MIMEEnv: Four discovered primitives are shown starting from top left clockwise: reach to object, wipe, stir insideobject, and pour out object.
