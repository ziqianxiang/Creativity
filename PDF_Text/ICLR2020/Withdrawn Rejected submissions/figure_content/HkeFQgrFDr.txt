Figure 1: GMM-UNIT working principle. The content is extracted from the input image (left, purple box),while the attribute (turquoise box) can be either sampled (top images) or extracted from a reference image(bottom images). Either way, the generator (blue box) is trained to output realistic images belonging to thedomain encoded in the attribute vector. This is possible thanks to the disentangled attribute-content latentrepresentation of GMM-UNIT and the generalisation properties associated to Gaussian mixture modeling.
Figure 2: Overview of the GMM-UNIT framework: a) Training phase to translate an image from domain Ato B. The generator uses the content of the input image (extracted by Ec) and the attribute of the target image(extracted by Ez) to train the network to fit the GMM. b) Testing with target attributes sampled from the GMMdistribution of the attributes of domain B; c) Testing with an attribute extracted from an image belonging to thetarget domain B . The style of this image is inspired from Zhu et al. (2017b).
Figure 3: Examples of edges â†’ shoes translation with the proposed GMM-UNiT.
Figure 4: Samples of domain translation of GMM-UNIT trained on Digits.
Figure 5: Facial expression synthesis results on the CelebA dataset with different attribute combinations. Eachrow represents a different output sampled from the model.
Figure 6: Examples of GMM-UNIT applied on the Style transfer task. The style is here extracted from a singlereference images provided by the user.
Figure 7: Generated images in previously unseen combinations of attributes.
Figure 8: Examples of domain interpolation given an input image.
Figure 9: Visual comparisons of state of the art methods on Edge o Shoes dataset. We note that BiCyCle-GAN, MUNIT and MSGAN are one-to-one domain translation models, while StarGAN* is a multi-domain(deterministiC) model. Finally DRIT++ and GMM-UNIT are multi-modal and multi-domain methods.
Figure 10: Visual comparisons of state of the art methods on the digits dataset. We note that StarGAN*is a multi-domain (deterministic) model, while DRIT++ and GMM-UNIT are multi-modal and multi-domainmethods.
Figure 11: Comparisons on CelebA dataset. BA: Black hair, BN: blondehair, BW: Brown hair, M: Male, FM:Female, Y: Young, O: Old.
Figure 12: An example of attribute intra-domain interpolation.
Figure 13: Visualization of the attribute vectors in a 2D space via t-SNE method. "S" refers to randomlysampling from GMM components (1: black hair, 2: blondehair, 3: brown hair) and "E" refers to extractingattribute vectors by the encoder EZ from the real data.
