Figure 1: The difference between (a) full backpropagation and (b) our proposed experimentaltechnique. In (b), weights which have nearly zero gradients are less likely to change throughout thetraining and are therefore kept frozen without being updated. These frozen weights are shown in red.
Figure 2: The histogram plot of gradients for (a) layer 3, (b) layer 7, (c) layer 10 and (d) layer13 of a VGG19 convolutional network. A large number of gradients have values very close to 0,indicating that a lot of weights in these layers have reached to a good value and are less likely tochange throughout the training.
Figure 3: The training loss (left) and validation accuracy (right) plots for (a,b) VGG19 trained onCIFAR10, (c,d) ResNet-110 trained on CIFAR10, (e,f) DenseNet-121 trained on CIFAR10 and (g,h)LeNet-5 trained on MNIST6Under review as a conference paper at ICLR 2020Network	Dataset	Threshold	V. Accuracy (FB)	V. Accuracy (PB)	FrozenVGG19	CIFAR10	0.04	88.12%	87.88%	79.68%ResNet-110	CIFAR10	0.19	83.72%	82.81%	49.85%DenseNet-121	CIFAR10	0.45	88.20%	87.63%	69.07%LeNet-5	MNIST	0.50	99.25%	99.22%	93.70%Table 1: Performance on CIFAR10 and MNIST datasets for 4 different types of CNNs with thethreshold, validation accuracy for full backpropagation (FB), validation accuracy for experimentaltechnique (PB) (PB) and the freezing ratio in parameters which is calculated as: (total gradients -non-zero gradients / total gradients) Ã— 100Network	Dataset	Threshold	V. Accuracy (FB)	V. Accuracy (PB)	FrozenVGG19	CIFAR10	0.04	88.12%	87.70%	80.45%ResNet-110	CIFAR10	0.19	83.72%	82.83%	51.53%DenseNet-121	CIFAR10	0.45	88.20%	87.52%	69.33%LeNet-5	MNIST	0.50	99.25%	99.22%	92.36%Table 2: Average Performance over 3 runs on CIFAR10 and MNIST datasets for 4 different types of
Figure 4: Results on training an image captioning model with visual attention mechanism (Xu et al.,2015) on the Flickr8k dataset using experimental technique (PB). The predicted word and attentionweights for each timestep are shown for 4 generated captions of different lengths7Under review as a conference paper at ICLR 2020Figure 5: BLEU-n scores (where n is the number of grams) reported on the the Flickr8k datasetfor image captioning with attention mechanism using both full backpropagation (FB) and ourexperimental technique (PB).
Figure 5: BLEU-n scores (where n is the number of grams) reported on the the Flickr8k datasetfor image captioning with attention mechanism using both full backpropagation (FB) and ourexperimental technique (PB).
