Figure 1: Top Row: Distillation performance using CNNs on MNIST while varying data set sizeand masking rate. (a) Test negative log likelihood of the teacher posterior predictive distribution. (b)Difference in test negative log likelihood between student and teacher posterior predictive distributionestimates. (c) Difference between teacher and student posterior entropy estimates on test data set.
Figure 2: NLL-Storage-Computation tradeoff while using CNNs on MNIST with masking rate29%. (a,b) Test negative log likelihood of posterior predictive distribution vs FLOPS found usingexhaustive search and group '1∕'2 with pruning. (c,d) Test negative log likelihood of posteriorpredictive distribution vs storage found using exhaustive search and group `1 /`2 with pruning.
Figure 3: Example MNIST data after masking with m = 14.
Figure 4: Distillation performance using Fully-Connected Networks on MNIST while varyingdata set size and masking rate. (a) Test negative log likelihood of the teacher posterior predictivedistribution. (b) Difference in test negative log likelihood between teacher and student posteriorpredictive distribution estimates. (c) Difference between teacher and student posterior entropyestimates on test data set.
Figure 5: Accuracy-Storage-Computation tradeoff while using CNNs on MNIST with masking rate29%. (a) Test accuracy using posterior predictive distribution vs FLOPS found using exhaustivesearch. (b) Test accuracy using posterior predictive distribution vs FLOPS found using group`1 /`2 with pruning. (c) Test accuracy using posterior predictive distribution vs storage found usingexhaustive search. (d) Test accuracy using posterior predictive distribution vs storage found usinggroup `1 /`2 with pruning. The optimal student model for this configuration is obtained with group`1 /`2 pruning. It has approximately 6.6× the number of parameters and 6.4× the FLOPS of the basestudent model.
Figure 6: Entropy Error-Storage-Computation tradeoff while using CNNs on MNIST with maskingrate 29%. (a) Test mean absolute error for posterior entropy vs FLOPS found using exhaustivesearch. (b) Test mean absolute error for posterior entropy Vs FLOPS found using group '1∕'2with pruning. (c) Test mean absolute error for posterior entropy vs storage found using exhaustivesearch. (d) Test mean absolute error for posterior entropy VS storage found using group '1∕'2 withpruning. The optimal student model for this configuration is obtained with group '1∕'2 pruning. Ithas approximately 1.8× the number of parameters and 4.3× the FLOPS of the base student model.
Figure 7: Accuracy-Storage-Computation tradeoff while using Fully-connected networks on MNISTwith masking rate 29%. (a) Test accuracy using posterior predictive distribution vs FLOPS foundusing exhaustive search. (b) Test accuracy using posterior predictive distribution vs FLOPS foundusing group '1∕'2 with pruning. (C) Test accuracy using posterior predictive distribution Vs storagefound using exhaustive search. (d) Test accuracy using posterior predictive distribution vs storagefound using group '1∕'2 with pruning. The optimal student model for this configuration is obtainedwith group '1∕'2 pruning. It has approximately 9.9× the number of parameters and 10× the FLOPSof the base student model.
Figure 8: NLL-Storage-Computation tradeoff while using Fully-connected networks on MNIST withmasking rate 29%. (a) Test negative log likelihood of posterior predictive distribution vs FLOPSfound using exhaustive search. (b) Test negative log likelihood of posterior predictive distribution vsFLOPS found using group '1 /'2 with pruning. (c) Test negative log likelihood of posterior predictivedistribution vs storage found using exhaustive search. (d) Test negative log likelihood of posteriorpredictive distribution vs storage found using group '1/'2 with pruning. The optimal student modelfor this configuration is obtained with group '1 /'2 pruning. It has approximately 9.9× the number ofparameters and 10× the FLOPS of the base student model.
Figure 9: Entropy Error-Storage-Computation tradeoff while using Fully-connected networks onMNIST with masking rate 29%. (a) Test mean absolute error for posterior entropy vs FLOPS foundusing exhaustive search. (b) Test mean absolute error for posterior entropy vs FLOPS found usinggroup `1 /`2 with pruning. (c) Test mean absolute error for posterior entropy vs storage found usingexhaustive search. (d) Test mean absolute error for posterior entropy vs storage found using group'1∕'2 with pruning. The optimal student model for this configuration is obtained with group '1∕'2pruning. It has approximately 4.2× the number of parameters and 4.2× the FLOPS of the basestudent model.
Figure 10: NLL-Storage-Computation tradeoff while using CNNs on CIFAR10 with training set sizeof 20,000 samples. (a) Test negative log likelihood of posterior predictive distribution vs FLOPSfound using exhaustive search. (b) Test negative log likelihood of posterior predictive distribution vsFLOPS found using group '1 /'2 with pruning. (c) Test negative log likelihood of posterior predictivedistribution vs storage found using exhaustive search. (d) Test negative log likelihood of posteriorpredictive distribution vs storage found using group '1/'2 with pruning. The optimal student modelfor this configuration is obtained with group '1 /'2 pruning. It has approximately 4.7× the number ofparameters and 5.2× the FLOPS of the base student model.
Figure 11: Accuracy-Storage-Computation tradeoff while using CNNs on CIFAR10 with sub-sampling training data to 20,000 samples. (a) Test accuracy using posterior predictive distribution vsFLOPS found using exhaustive search. (b) Test accuracy using posterior predictive distribution vsFLOPS found using group 'ι /'2 with pruning. (c) Test accuracy using posterior predictive distributionvs storage found using exhaustive search. (d) Test accuracy using posterior predictive distribution vsstorage found using group `1 /`2 with pruning. The optimal student model for this configuration isobtained with group '1 /'2 pruning. It has approximately 5.4× the number of parameters and 5.6×the FLOPS of the base student model.
Figure 12: Entropy Error-Storage-Computation tradeoff while using CNNs on CIFAR10 with sub-sampling training data to 20,000 samples. (a) Test mean absolute error for posterior entropy vsFLOPS found using exhaustive search. (b) Test mean absolute error for posterior entropy vs FLOPSfound using group '1∕'2 with pruning. (c) Test mean absolute error for posterior entropy Vs storagefound using exhaustive search. (d) Test mean absolute error for posterior entropy vs storage foundusing group '1∕'2 with pruning. The optimal student model for this configuration is obtained withgroup '1∕'2 pruning. It has approximately 1.6× the number of parameters and 2.8× the FLOPS ofthe base student model.
