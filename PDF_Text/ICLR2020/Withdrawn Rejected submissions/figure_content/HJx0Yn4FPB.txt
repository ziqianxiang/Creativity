Figure 1: Spatial attention map of ResNet-101 pretrained on ImageNet(RussakoVsky et al., 2015).(a)is original image and (b) is corresponding adVersarial image.For ResNet-101, which we use exclu-siVely in this paper, we grouped filters into stages as described in (He et al., 2015). These stages areconv2.x, conv3.x, conv4.x, conv5.x.
Figure 2: Schematic representation of ATLPA: a baseline model is adversarial trained so as, notonly to make similar the output labels, but to also have similar Tolerant Logits and spatial attentionmaps to those of original images and adversarial images.
Figure 3: Defense against gray-box and black-box attacks on 17 Flower CategoryDatabase.(a)(c) shows results against a gray-box PGD attacker with 10 to 200 attack itera-tions.(b)(d) shows results against a black-box PGD attacker with 10 to 200 attack iterations.Themaximum perturbation is ∈ {0.25, 0.5}. Our ATLPA(purple line) outperform the state-of-the-art in adversarial robustness against highly challenging gray-box and black-box PGD attacks.
Figure 4: Comparison of loss landscapes. Loss plots are generated by varying the input to themodels, starting from an original input image chosen from the testing set of 17 Flower CategoryDatabase. ATLPA(w/o ATT): ATLPA without Attentions.
Figure 5: Illustration of the effect of the attention mechanism of ATLPA. Using attention, however,changes the activation map significantly. ATLPA show obviously improved concentration. Withattention (the right-most column), we observed a large set of pixels that have high activation atimportant regions e.g. the whole petal. ATLPA w/o ATT: ATLPA without Attentions.
Figure 6: Illustration of the effect of the attention mechanism of ATLPA.Using attention, however,changes the activation map significantly. ATLPA show obviously improved concentration. Withattention (the right-most column), we observed a large set of pixels that have high activation atimportant regions e.g. front bumper of car .ATLPA w/o ATT: ATLPA without Attentions.
Figure 7: t-SNE visualization results on the final hidden features of different defense methods. Theinputs are adversarial images of 17 Flower Category Database and BMW-10 Database testingset.ATLPA(w/o ATT): ATLPA without Attention.
Figure 8: Comparison of loss landscapes. Loss plots are generated by varying the input to themodels, starting from an original input image chosen from the testing set of 17 Flower CategoryDatabase. The z axis represents the loss. If x is the original input, then we plot the loss varyingalong the space determined by two vectors: r1 = sign(5χ f (x)) and r2 〜 Rademacher(0.5).
