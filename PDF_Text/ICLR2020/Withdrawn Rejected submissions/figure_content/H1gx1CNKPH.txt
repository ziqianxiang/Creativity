Figure 1: KIF modules (orange) fetch relevant information from multi-modal external knowledgesources and incorporate it in standard neural architectures.
Figure 2: Human Evaluation. More than 50% indicates the KNN Model is preferred. Stars indicatestatistical significance at p < 0.05In Wizard of Wikipedia, there are two test sets: one set of seen topics, or topics that have been seenat training time with new test-time dialogues. The second set is unseen, or topics that have not beenencountered at all during training time. We evaluate on both of these subsets.
Figure 3:	Ablations on Wizard of Wikipedia. (a) KIF can scale to thousands of relevant sentences(blue) while the baseline model scales poorly (gray) (b) Gating can remove irrelevant information.
Figure 4:	Conversation between Human and KIF-Augmented Transformer on Wizard of Wikipedia.
Figure 5:	Examples of Top-2 Fetched Training Utterances and Fetched Knowledge when respondingto a human chat from the dataset using a trained Wizard of Wikipedia model. Examples are takenfrom validation.
Figure 6: (left) Human Evaluation on the Unseen Test set of Wizard of Wikipedia. More than50% indicates the KNN Model is preferred. Stars indicate statistical significance at p < 0.05(right) Variance of Human Evaluation Study on Wizard of Wikipedia. Analysis shows that multi-ple trials of the same experiments are relatively stable.
