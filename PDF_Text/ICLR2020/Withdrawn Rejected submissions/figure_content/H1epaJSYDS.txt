Figure 1: Anchor & Transform (ANT) is a general method to learn sparse representations of discreteobjects consisting of two steps: 1) Anchor: Learn embeddings A of a small set of anchor objectsA = {a1,…，a∣A∣},∣A∣ << ∣V∣ that are representative of all discrete objects (e.g. frequency andclustering based initialization methods). 2) Transform: Learn a sparse transformation T from theanchor embeddings to the full embedding matrix E. A and T are trained end-to-end for task specificrepresentation learning. ANT is scalable, flexible, end-to-end trainable, and allows the user to easilyincorporate domain knowledge about object interactions.
Figure 2: Initialization strategies for anchor objects combining ideas from frequency and k-means++clustering algorithms. Clustering initialization picks anchors to span the space of all objects.
Figure 3: Generalized nonlinear mixture of anchors Ai,…，AM and transformations Ti,…，TM,E = ∑M=ι SoftmaX(Tm)Am (softmax across rows of Tm). Different sparse transformations can belearned for different initializations of anchor embeddings.
Figure 4: Incorporating domain knowledge Via given relationship graphs (left) and extracting positiveand pairs (P) and negative pairs (N). Transformations between negative (unrelated) pairs are sparselypenalized while those between positive (related) pairs are not. The linear combination coefficients tuand tv of negative pairs are also discouraged from sharing similar entries.
