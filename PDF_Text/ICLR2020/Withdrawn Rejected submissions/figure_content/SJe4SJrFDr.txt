Figure 1: Concept: We consider a novel problem of distortion in latent features of a network in the presence ofadversarial perturbation, where the model observes different degrees of distortion for different features (brighterred indicates higher level of distortion). To solve this problem, our proposed method learns a bayesian pruningmask to suppress the higher distorted features in order to maximize itâ€™s robustness on adversarial perturbations.
Figure 2: a) Mean distortion (average perturbation in latent features across all layers) for various networks.
Figure 3: Comparison of clean and adversarial accu- Table 3: Comparison of clean and adversarial accuracyracy for adversarial examples generated from white- for adversarial examples generated from white-box andbox and black-box attack for different sparsity levels black-box attack to analyze the importance of individualfor Top VGG-16 on CiFAR10 Bottom VGG-16 on components for and Lenet-5 on MNiST and VGG-16 onCiFAR100.	CiFAR10 and CiFAR100 datasets.
Figure 4: Top: Visualization of the vulnerability of the latent-features with respect to the input pixels forvarious datasets. Bottom: Histogram of vulnerability of the features for the input layer for CIFAR-10 with thenumber of zeros shown in orange color.
Figure 5: Comparison of loss landscapes for various methods. We see that adversarial neural pruning behavessimilar to adversarial training and results in a much smooth and flattened loss surface compared to adversarialtraining. The z axis represents the loss projected along two random directions.
