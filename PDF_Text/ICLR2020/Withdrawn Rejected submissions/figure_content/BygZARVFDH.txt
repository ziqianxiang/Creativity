Figure 1: Illustration of logical composition operators over energy functions E1 and E2 (drawn as level sets).
Figure 2: Illustration of concept conjunction and negation. All the images are generated through the conjunctionand negation of energy functions. For example, images in the central part is the conjunction of male, black hair,and smiling energy function.
Figure 3: Combinations of different attributes on CelebA (a) and Mujoco scenes (b) via summation of energies.
Figure 4: (a) Examples of concept disjunction on joint attributes (represented by conjunction of energy) of notsmiling+female and smiling+male. EBMs are able to reliably support concept disjunction (generation of eitherone concept or the other) even when the concept itself is compound. (b) Examples of concept negation on theattributes of smiling female. When negating the female energy in combination with the smiling energy function,we are able to generate photos of males that are smiling.
Figure 5: Multi-object compositionality with EBMs.
Figure 6: Continual learning of concepts. A positionEBM is trained on cubes of one color. A shape EBM isthen trained on shapes of some fixed color. Finally, acolor EBM is trained on shapes of many colors. EBMscontinually learn to generate many shape colors at manypositions, despite position EBM only being trained oncubes of fixed color, and shape EBM being only trainedon shapes of a fixed color.
Figure 7: Illustration of generation of size/position concepts as a function of data percentage. By learninga composable representation of underlying concepts, EBMs are able to extrapolate better with less data, andexhibit both lower size and positional error.
Figure 8: Generated images of novel size and position combinations of EBM and holistic baseline model (right).
Figure 9: The influence of multiple observations on EBMs. Multiple images are generated under differentlighting conditions and objects. (a) The position prediction error decreases when the number of input imagesincreases independent of negative training steps used to train models. (b) Examples of generated images withvarying number of negative sampling steps. Large number of steps leads to more realistic images.
Figure 10: Inference with EBM trained on single cubesand tested on two cubes. In color is input image and ingrayscale is energy over object positions. The energiesfor images of two cubes correctly infer bimodality.
Figure 11: Generated images from the composition of an EBM trained on old, male, smiling and nonwavy hair.
Figure 12: Composition of ebmsWe also consider combining EBMs from different domains together in Figure 13. We combine aconditional EBM trained on the attribute smiling on CelebA with an EBM trained on Mujoco sceneson different different plane colors. EBMs are trained on separate datasets with separate architectures,but are still able to successfully generate meaningful combinations.
Figure 13: Generated images from EBMs trained on different domains. One EBM is conditioned on theattribute of smiling from the CelebA dataset, while the other EBM is conditioned on the color of the plane froma Mujoco Scenes dataset.
Figure 14: Comparison on samples generated from different sampling scenes on PixelCNN++ modelfrom (Salimans et al., 2017). We note that Langevin sampling, while not making realistic samples,generate higher likelihood samples than those from autoregressive sampling12Under review as a conference paper at ICLR 2020We considered Langevin based sampling on the pretrained CIFAR-10 unconditional PixelCNN++model (Salimans et al., 2017) in Figure 14. While both sampling schemes generate images withsimilar likelihoods (with Langevin sampling creating higher likelihood samples), we find imagesgenerated from Langevin sampling are significantly poorer than those generated from autoregressivesampling. We believe that when using MCMC sampling on generative models, it best to use EBMssince they are trained with MCMC inference, while other models are not trained in such a manner,and may have modes easily found through sampling that are not realistic as noted by (Nalisnick et al.,2018).
Figure 16: Generated unconditional CelebA images.
Figure 17: Energy histogram of model trained on CelebA smiling (left), CelebA attractive (middle) andpretrained CIFAR-10 model from (Du & Mordatch, 2019) (right). Are energy histograms are relatively similar.
