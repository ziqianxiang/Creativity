Figure 1: Features from the SVHN      MNIST scenario visualized using t-SNE. Circle and x markersrepresent the source and target domain features, respectively. In (a), features from DANN model arealigned but the fit is far from perfect, and the boundaries between classes are not clear. In contrast,our model in (b) produces clearly aligned and clustered features.
Figure 2: Overview of our method.  The feature generator G projects the input data into the featurespace.   The dashed line means weight sharing.   The embedded source features fˢ and the targetfeatures fᵗ are organized into a graph and then used together to evaluate cycle consistency throughlabel  propagation.   The  embedding  classifier  C  learns  from  the  source  ground-truth  labels.   Thediscriminator D determines whether features originated in the source or the target domain.
Figure 3:  Graphical interpretation of the effect of cycle loss in the SVHN    MNIST scenario.  (a)The model constructs a graph in the feature space, and the darkness of each line is proportional tosimilarity of the features.  (b) Features with high similarity, expressed as both direct and indirectconnections, cluster together by class to enforce cycle consistency.
Figure 4: Visualization of toy experiment. (Best viewed in color.) Blue and orange colors representlabels.  Circles with light color are source data and x markers with dark color are target data.  Theleft-most one depicts the initial data distribution. For the right six sub-figures, the top row refers toAssocDA and the bottom row refers to ours.  The second column illustrates the negative gradientsof    loss for target data that are close to the source with different labels. The third and fourth columnsare the updated data after gradient descent in the middle and at the end of the training.  The blacklines indicate the decision boundaries of logistic regression models trained with source labels. Oursaligns manifolds better than AssocDA and results in an accurate classifier for the target.
Figure 5: Visualization of learned features using t-SNE. Circles and x markers respectively indicatethe  source  and  target  features.   Colors  correspond  to labels.   In  all  cases,  the  features  from  twodomains form similar and tight clusters, which is the key objective of our method.
Figure 6: Illustration for Theorem 1. From the assumption, Tss is a block diagonal matrix of whichblock elements are T₁,T₂,     ,TC.  vj is all zero except nj elements in the middle of vj.  The njelements are all positive and their indices correspond to those of Tj in Tss.  In the proof, the lefteigenvector uj of Tj will be substituted to this part.
