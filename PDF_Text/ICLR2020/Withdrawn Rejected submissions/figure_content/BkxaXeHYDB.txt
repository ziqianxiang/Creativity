Figure 1: Contours around the minima of (a) ResNet18, (b) Newton-ResNet. Starting from a randompoint x0, ResNet needs more steps, i.e. more residual blocks, to reach the minimum.
Figure 2: Schematic of the (a) original, (b) our residual block for the tth layer. The path that includesC is referred to as the transformation path; while the other (with the identity transformation) isreferred to as the shortcut path. The symbol C denotes the operations in the transformation path,e.g. convolutions in He et al. (2016). The symbols N1, N2 are normalization layers, e.g. batchnormalization or 1 X 1 convolutions. The symbol * denotes an element-wise product.
Figure 3: The test accuracy of (a) ResNet18 and (b) the respective Newton-ResNet are plotted(CIFAR10 training). The two models perform similarly throughout the training, while ours has 46%less parameters. The width of the highlighted region denotes the standard deviation of each modelover 5 runs.
Figure 4: Baseline ResNetarchitectures (ResNet50 and ResNet101) and the Newton counterpart(Newton-ResNet50) on the ImageNet validation dataset. The proposed method produces consistentgains in the performance which are sustained throughout the training process.
Figure 5: Synthesized samples from GAN (sec. 4.5). It can be visually verified that both the SNGANand ‘Ours’ (with the proposed residual blocks) result in similar visual samples.
Figure 6: The test accuracy of (a) ResNet34 and (b) the respective Newton-ResNet are plotted(CIFAR10 training; sec. 4.3). The two models perform similarly throughout the training. The widthof the highlighted region denotes the standard deviation of each model over 5 runs.
Figure 7: The test accuracy of (a) ResNet34 and (b) the respective Newton-ResNet are plotted(CIFAR100 training; sec. 4.3). The two models perform similarly throughout the training. The widthof the highlighted region denotes the standard deviation of each model over 5 runs.
Figure 8: Four input mel-spectrograms; each image is used as input in the speech classificationexperiment in seC. 4.6. The label is the Corresponding word for eaCh image.
Figure 9: Training accuracy in the models without activation functions (further details in sec. 4.2).
