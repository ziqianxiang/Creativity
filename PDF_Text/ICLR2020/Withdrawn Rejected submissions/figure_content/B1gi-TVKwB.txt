Figure 1: Future predictions capturing information about the shape of the road ahead+ 1__ ____-≡---——田」(a) Lane centeredness	(b) Road angleFigure 2: (a) the lane centeredness position α is the distance from the center of the lane to the centerof the vehicle. (b) the road angle β is the angle between the direction of the vehicle and the directionof the road.
Figure 2: (a) the lane centeredness position α is the distance from the center of the lane to the centerof the vehicle. (b) the road angle β is the angle between the direction of the vehicle and the directionof the road.
Figure 3: Test scores (accumulated reward) during trainingIt could be argued that DDPG-Image may improve with more iterations; however this is likely notthe case. The reason is shown in Figure 4 where DDPG-Image consistently converges to a solutionthat oscillates between the extreme left and right steering actions very rapidly. This oscillation is soextreme that the agent is unable to achieve the target speed of 50 km/h; instead it travels at 40 km/hon average for all the test tracks. The performance gap also suggests that DDPG-ImageLowDim maybe relying more on the low dimensional lane information rather than the image.
Figure 4: Standard deviation of the change in action during trainingThe performance of the individual test tracks is given in the following Figure 5. The GVF-DPGapproach does not steer successfully on all test tracks: it fails immediately on wheel-2, part-waythrough on a-wheelway, and drives well on most of alpine-2. The DDPG-Image fails to completedirt-4, wheel-2, spring, and a-speedway. Finally, DDPG-ImageLowDim successfully completes allthe test tracks; however, the agent has a strong bias to the left side of the track. The GVF-DPG agentoften follows the classical controller relatively well except on the tracks where the agent fails. Thissuggests that using a predictive representation of lane centeredness α and road angle β achievescloser performance to a classical controller than an end-to-end learned approach. However, morework is needed to improve the generalization abilities of the approach.
Figure 5: The lane centeredness position on the (a) alpine-2, (b) evo-2-r, (c) dirt-4, (d) wheel-2, (e)spring, and (f) a-speedway tracks in TORCS.
Figure 6: Log-loss learning curves for the (a) Q-values of the DPG agents, (b) mean squared TD(temporal difference) errors of the GVF predictors, and (c) MSE of the behavior model estimatorThis work supports the predictive state representation hypothesis in Rafols et al. (2005) that deeppredictions can improve the generalization of RL to new road environments when using only im-ages as input. For future work, we hope to study how to learn the question for the predictive staterepresentation: τ , γ, and c. Moreover, because the behavior policy is unknown and estimated, ourresults suggest that collecting real-world human driving to train predictions off-policy without theneed for a simulator could be a viable approach to steering a vehicle from images. This is potentiallyadvantageous since the human driver can explore the road safely.
