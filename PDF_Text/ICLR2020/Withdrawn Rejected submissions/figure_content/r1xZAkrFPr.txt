Figure 1: Cartoon illustration of the hypothesis. x-axis in-dicates parameter values and y-axis plots the negative loss-L(θ, {xn, yn}nN=1) on train and validation data.
Figure 2: Results using SimpleCNN on CIFAR-10. Left plot: Cosine similarity between checkpointsto measure weight space alignment along optimization trajectory. Middle plot: The fraction of labelson which the predictions from different checkpoints disagree. Right plot: t-SNE plot of predictionsfrom checkpoints corresponding to 3 different randomly initialized trajectories (in different colors).
Figure 3: Results on CIFAR-10 using two different architectures. For each of these architectures, theleft subplot shows the cosine similarity between different solutions in weight space, and the rightsubplot shows the fraction of labels on which the predictions from different solutions disagree.
Figure 4:	Results using SimpleCNN on CIFAR-10: t-SNE plots of validation set predictions for eachtrajectory along with four different subspace generation methods (showed by squares), in addition to3 independently initialized and trained runs (different colors). As visible in the plot, the subspace-sampled functions stay in the prediction-space neighborhood of the run around which they wereconstructed, demonstrating that truly different functions are not sampled.
Figure 5:	Diversity versus accuracy plots for 3 models trained on CIFAR-10: SmallCNN, Medium-CNN and a ResNet20v1. The clear separation between the subspace sampling populations (for 4different subspace sampling methods) and the population of independently initialized and optimizedsolutions (red stars) is visible. The 2 limiting curves correspond to solution generated by perturbingthe reference solution’s predictions (bottom curve) and completely random predictions at a givenaccuracy (upper curve).
Figure 6: Results using MediumCNN on CIFAR-10: Radial loss landscape cut between the origin andtwo independent optima and the predictions of models on the same plane.
Figure 7: Left: Cartoon illustration showing linear connector (black) along with the optimizedconnector which lies on the manifold of low loss solutions. Right: The loss and accuracy in betweentwo independent optima on a linear path and an optimized path in the weight space.
Figure 8: Results using MediumCNN on CIFAR-10: Radial loss landscape cut between the origin andtwo independent optima along an optimize low-loss connector and predictions similarity along thesame planes.
Figure 9: Results on CIFAR-10 showing the complementary benefits of ensemble and subspacemethods, as well as the effect of ensemble size.
Figure 10: Results on CIFAR-10 using SimpleCNN: clean test and CIFAR-10-C corrupted test set.
Figure 11: Results using ResNet on ImageNet: clean test and ImageNet-C corrupted test set.
Figure S1: Loss landscape versus generalization: weights are typically initialized close to 0 andincrease radially through the course of training. Top row: we pick two optima from differenttrajectories as the axes, and plot loss surface. Looking at x and y axes, we observe that while a widerange of radii achieve low loss on training set, the range of optimal radius values is narrower onvalidation set. Bottom row: we average weights within each trajectory using WA and use them asaxes. A wider range of radius values generalize better along the WA directions, which confirms thefindings of Izmailov et al. (2018).
Figure S2:	The effect of random initializations and random training batches on the diversity ofpredictions.
Figure S3: Diversity versus accuracy plots for a ResNet20v1trained on CIFAR-100.
