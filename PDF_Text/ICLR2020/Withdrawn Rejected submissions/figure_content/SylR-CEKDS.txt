Figure 1: The Battleship task. Blue, red, and purple tiles are ships, dark gray tiles are water, and light gray tilesare hidden. The agent can see a partly revealed board, and should ask a question to seek information about thehidden board. Example questions and translated programs are shown on the right. We recommend viewing thefigures in color.
Figure 2: Neural program generation. Figure (a) shows the network architecture. The board is representedas a grid of one-shot vectors and is embedded with a convolutional neural network. The board embeddingand a sequence of symbols are inputted to a Transformer decoder (Vaswani et al., 2017) to generate outputvectors (details in section 4). PE means positional embeddings, and WE means word embeddings. (b) shows thederivation steps for program “(> (size Blue) 3)” using CFG. Non-terminals are shown as bold-faced,and terminals are shown in italic. The production rules used are shown next to each arrow.
Figure 3: Design of the tasks in experiment 1. The goal of task (a) is to find the color which has the least numberof visible tiles; the goal of task (b) to find the location and color of the missing tile; (c) is the compositionalitytask with 5 questions as known question types, and another one (in dotted box) as held out question type. Theformat of generated question is shown alongside the title of each task, where X, Y and Z are variables. Theaccuracy of supervised model for task (a) and (b) are given below each task.
Figure 4: Examples of model-generated questions. The natural language translations of the question programsare provided for interpretation. (a) shows three novel questions generated by the grammar enhanced model,(b) shows an example of how the model generates different type of questions by conditioning the input to thedecoder, (c) shows questions generated by our model as well as human annotators.
Figure 5:	Novel questions generated by the grammar enhanced model.
Figure 6:	Generated questions of different types by controlling the start condition.
Figure 7:	Comparisons of questions generated by our model with human questions.
Figure 8:	Example questions generated by the text-based model.
