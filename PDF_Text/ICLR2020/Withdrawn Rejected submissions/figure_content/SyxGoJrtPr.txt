Figure 1: Multi-dimensional performance comparison of four training methods using VGG-16network and CIFAR-10 dataset. All dimensions are separately normalized by the best-performancemethod. The average score of each method is 0.6718 for natural (standard training), 0.6900 forPGD-'∞ based adversarial training (Madry et al., 2018), 0.7107 for PGD-'∞ based TRADES (Zhanget al., 2019), and 0.8798 for SPROUT (ours). The exact numbers are reported in Table 6 in Appendix.
Figure 2: Robust accuracy under PGD-'∞ attack. SPROUT Signigicantly outperforms other methods.
Figure 3: Robust accuracy under C&W-'2 attackTransfer attack. We follow the criterion of evaluating transfer attacks as suggested by Athalye et al.
Figure 4: Loss landscape comparison of different training methods4.4 Invariance testIn addition to `p-norm bounded adversarial attacks, here we also evaluate model robustness againstdifferent kinds of input transformations using CIFAR-10 and Wide ResNet. Specifically, we change8Under review as a conference paper at ICLR 2020rotation (with 10 degree), brightness (increase the brightness factor to 1.5), contrast (increasethe contrast factor to 2) and make inputs into grayscale (average all RGB pixel values). Themodel accuracy under these invariance tests is summarized in Table 4. Results show that SPROUToutperforms adversarial training and TRADES. Interestingly, natural model attains the best accuracydespite the fact that it lacks adversarial robustness, suggesting a potential trade-off between accuracyin these invariance tests and `p-norm based adversarial robustness.
Figure 5: Robust accuracy with different combinations of the modules in SPROUT→- SPROUTGA—Mixup—DiricbIetGA+Mixup—Mixup+DirichletGA+Dirichlet-→- Uniform LS—GA+Mixup+LSPGD attacks with more iterations. To ensure the robustness of SPROUT is not an artifact ofrunning insufficient iterations in PGD attack (Athalye et al., 2018), in Figure 6a we show the robustaccuracy with the number of PGD-'∞ attack steps varying from 10 to 500 on VGG-16 and CIFAR-10.
Figure 6: Stability in PGD-'∞ attack and the effect of model initialization.
Figure 7: Effect of network width against PGD-'∞ attack on CIFAR-10 and ResNet.
Figure 8: Matrix plot of the product βs ∙ βt of the learned β parameter on CIFAR-10 and VGG-16.
Figure 9: Sensitivity of hyperparameters λ and a in SPROUT under PGD-'∞ attackA.5 PERFORMANCE ON CW-'∞ ATTACKTo further test the robustness on '∞ constraint, we replace the cross entropy loss with CW-'∞ loss(Carlini & Wagner, 2017) in PGD attack. Similar to the PGD-'∞ attack results in Figure 2, Figure 10shows that although SPROUT has slightly worse accuracy under small values, it attains much higherrobust accuracy when ≥ 0.03.
Figure 10: Robust accuracy under CW-'∞ attack.
