Figure 2: A comparison of training loss and training AUL as proxies for identifying mislabeledsamples. Top: Histograms of training sample loss over the course of training. The distributions forclean and mislabeled samples are very separable at the beginning of training, but become less sep-arable towards the end of training. Bottom: Histograms of training sample AUL. The distributionsfor clean and mislabeled samples remain separable even after the network has converged.
Figure 3: Left: Loss trajectories over epochs for a single clean sample and a single mislabeledexample (randomly selected). On average, the clean sample has a lower loss than the mislabeledexample. However, the loss decreases over time for both examples, and the trajectories are noisyand non-monotonic. Right: AUL trajectory for the same examples. Integrating loss over trainingtime reduces trajectory noise, making the samples’ different learning dynamics more separable.
Figure 4: Distribution of AUL (CIFAR10, 40% label noise) computed on ResNets and DenseNetsof different depth. The modes of the distribution are consistent across networks.
Figure 5: Pearson’s correlation of AUL and other metrics across various network architectures(RN=ResNet, DN=DenseNet) after 150 epochs. AUL produces a very consistent ranking of thetraining data. Training loss produces less consistent rankings. Furthermore, the loss on held-outdata points (from the test set) is also much less correlated across networks than AUL.
Figure 6: AUL distribution on CIFAR10 (ResNet-32) with varying amounts of mislabeled data. TheAUL distribution is bimodal, with the two modes corresponding to clean and mislabeled samples.
Figure 7: Identifying mislabeled data in noisy variants of CIFAR10 using AUL from trainedResNet-32 models. Left: predicted amount of noise in training set (uniform noise model, far left;pair flip noise model, middle left). Right: prediction/recall curves for identifying mislabeled data(uniform, middle right; pair flip, far right).
Figure 8: Distribution of loss (left) and AUL (right) over the course of network training. Shadedregion represents 1 standard deviation.
Figure 9: Identifying mislabeled data in noisy variants of CIFAR100 using AUL from trainedResNet-32 models. Left: predicted amount of noise in training set (uniform noise model, far left;pair flip noise model, middle left). Right: prediction/recall curves for identifying mislabeled data(uniform, middle right; pair flip, far right).
Figure 10: Additional images from the first 100 classes of ImageNet with large AUL when trainedon a DenseNet-121 model.
