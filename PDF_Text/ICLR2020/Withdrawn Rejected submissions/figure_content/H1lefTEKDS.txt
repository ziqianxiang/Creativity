Figure 1: A subset of all 18 performance curve figures of the bench-marked algorithms. All the algorithms arerun for 200k time-steps and with 4 random seeds. The remaining figures are in appendix C.
Figure 2: Performance curve for each algorithm trained for 1 million time-steps.
Figure  3:  The  relative  performancewith different planning horizon.
Figure 4:  The performance of HalfCheetah from our benchmark, and the HalfCheetah from thePETS paper Chua et al. (2018), which we refer to as "Modified". We also include the performanceof PETS-CEM and PETS-RS using different dynamics-propagation combination on the modifiedHalfCheetah from Chua et al. (2018).
Figure 5: Performance curve for MBRL algorithms.  There are still 3 more figures in a continuedFigure 6.
Figure 6: (Continued) Performance curve for MBRL algorithms.
Figure 7: The performance curve for algorithms with noise. We represent the noise standard deviationwith "O" and "A" respectively for the noise added to the observation and action space.
Figure 8:  (Continued) The performance curve for algorithms with noise.  We represent the noisestandard deviation with "O" and "A" respectively for the noise added to the observation and actionspace.
Figure 9: The performance grid using different planning horizon and depth.
Figure 10: The performance curve for different environment length and planning horizon in SLBO.
Figure 11: The performance of PETS-CEM on HalfCheetah using different network structures.
Figure 12: The performance curve for some of the tasks based on Roboschool or Pybullet Klimov &Schulman (2017); AMD (2014); Ellenberger (2018).
