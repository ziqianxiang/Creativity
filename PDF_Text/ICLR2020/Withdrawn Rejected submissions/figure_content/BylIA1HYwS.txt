Figure 1: We employ two data streams to train our framework. While pi and pj have the same style, pi andpk do not. (a) The reconstruction stream is trained using the language modeling loss LLM and the distillationloss LDIST. (b) The cross-style generation stream is trained using the style loss LSTYLE and the GAN lossLGAN. Note that we decompose each network into a feature extractor and an embedding layer.
Figure 2: (a) Style encoder Fs. (b) Text decoder Fg. We consider 4 different ways of injecting the style codez into Fg termed Model A, B, C, and D. Checkout main texts for more details.
Figure 3: Fluency and style scores achieved by the competing models on the 3-Style and 21-Styledatasets.
Figure 4: A typical example of the questionnaire for our A/B test on AMT for the fluency study.
