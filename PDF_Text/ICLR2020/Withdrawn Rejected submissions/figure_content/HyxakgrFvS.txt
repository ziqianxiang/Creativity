Figure 1:	The side-tuning framework vs the common alternatives fine-tuning and fixed features. Given apre-trained network that should be adapted to a new task, fine-tuning re-trains the pretrained network’s weightsand fixed feature extraction trains a readout function with no re-training of the pre-trained weights. In contrast,Side-tuning adapts the pre-trained network by training a lightweight conditioned “side” network that is fusedwith the (unchanged) pre-trained network using a simple additive process.
Figure 2:	Advantages of side-tuning vs. alternatives. Fixed features cannot adapt to new information, whilefine-tuning adapts too easily and forgets old information. Side-tuning is a simple method to address theselimitations.
Figure 3: Mechanics of side-tuning. (i) Side-tuning takes some core network (B) and adapts it to a new taskby (ii) adapting a side network. (iii) Shows the connectivity structure when using side-tuning along with alpha-blending. (iv) Existing adaptation methods turn out to be special cases of side-tuning. In particular: fine-tuning,feature extraction, and other approaches are side-tuning with a fixed curriculum on the blending parameter α.
Figure 4: Theoretical side-tuning learning curve.
Figure 5: Side-tuning does not forget in incremental learning. Qualitative results for incremental learningon Taskonomy with additive learning (side-tuning, top 3 rows) and constraint-based learning (EWC, bottom 3rows). Each row contains results for one task and columns show how predictions change over the course oftraining. Predictions from EWC quickly degrade over time, showing that EWC still catastrophically forgets.
Figure 6: Incremental Learning on Taskonomy and iCIFAR. The above curves show loss and error onincremental learning experiments for three tasks on Taskonomy (left) and iCIFAR dataset (right). The fact thatside-tuning losses are flat after training (as we go right) shows that it does not forget previously learned tasks.
Figure 7: Rigidity and average rank on Taskonomy and iCiFAR. From left: Side-tuning always learnsnew tasks easily; EWC becomes increasingly unable to learn new tasks as training progresses. Center: Thesame trend holds on iCIFAR, and the average rigidity is zero for side-tuning (and almost zero for PSP). Right:Side-tuning outperforms alternatives on both datasets, achieving a significantly better average rank on all tasks.
Figure 8: Side-tuning comparisons in other domains. Sidetuning matched the adaptability of fine-tuning on large datasets, While performing as Well or better than the best competing method in eachdomain: (a) In Taskonomy, performing either Normal Estimation or Object Classification using abase trained for Curvatures and either 100 or 4M images for transfer. Results using Obj. Cls. baseare similar and proVided in the appendix. (b) In SQuAD V2 question-ansWering, using BERT insteadof a conVolutional architecture. (c) In Habitat, learning to naVigate by imitating expert naVigationpolicies, using inputs based on either Curvature or Denoising. Finetuning does not perform as Wellin this domain. (d) Using RL (PPO) and direct interaction instead of superVised learning.
Figure 9: Analysis of learning mechanics. (a) Boosting: deeper network > many shallow learners. (b)Side-tuning outperformed alternatives on intermediate amounts of data. (c) Features/Side-tuning do more thanreduce gradient variance.
Figure 10: More qualitative results for side-tuning. These images were randomly selected from the val-idation set. Left-hand column is input, rightmost-column is ground truth. Images from left to right showpredictions as training progresses. Each block of 4 rows shows predictions on a different task (Reshading, 2DEdges. Surface Normals.)14Under review as a conference paper at ICLR 2020Elastic Weight Consolidation (EWC)Figure 11: More qualitative results for EWC. These images were randomly selected from the validation set.
Figure 11: More qualitative results for EWC. These images were randomly selected from the validation set.
Figure 12: More qualitative results for PSP. These images were randomly selected from the validation set.
Figure 13: More qualitative results for independent These images were randomly selected from the val-idation set. Left-hand column is input, rightmost-column is ground truth. Images from left to right showpredictions as training progresses. Each block of 4 rows shows predictions on a different task (Reshading, 2DEdges. Surface Normals.)17Under review as a conference paper at ICLR 2020A.3 Additional ExperimentsA.3.1 Network SizeTransfer Learning inMeth	so Norm	n Curvature (100/4M ims.)			als (MSE I )	Obj Cls (Acc ↑) j. s. (cc. ↑)<~1 . 1		ais (IEL OLj I)	Stand	需	0/0.010^^	^^24.8/63.3-Small	Bas0.	20/0.09	25.3/63.2Large	端	21/0.11	25.3/55.6(a)Transfer Learning in TaskonomyFrom Obj. Class. (100)Normals (MSE ψ)025
Figure 14:	Effect of network size. Modifying the network size from standard (large basae/smallside). Small bases generally have a small impact on performance. For hard tasks (e.g. classification),using a deeper side network can have a large positive effect.
Figure 15:	Reinforcement Learning) Side-tuning matches the performance of the best method when usingdenoising features as well.
Figure 16:	Imitation Learning Figure 17: Imitation Learning Figure 18: Imitation Learning(Denoising) SPL	(Curvature) SPL	(Curvature) RewardFigure 19: Additional Imitation Learning Data Study. We ablate over different quantities of experttrajectories. We observe that when data is scarce, features is a powerful choice whereas when datais plentiful, fine-tuning performs well. In both scenarios, side-tuning is able to perform as well asthe stronger approach.
Figure 19: Additional Imitation Learning Data Study. We ablate over different quantities of experttrajectories. We observe that when data is scarce, features is a powerful choice whereas when datais plentiful, fine-tuning performs well. In both scenarios, side-tuning is able to perform as well asthe stronger approach.
Figure 20: Average Accuracy in iCIFAR for All Methods. Note that the performance of Side-tune (A) iscomparable to that of PNN. Side-tuning (A) using multilayer perceptron (adapter) similar to what PNN uses.
Figure 21: Normalized Losses for all tasks in Taskonomy. We show the normalized loss values for allmethods for all tasks. PNN and Sidetune have comparable loss values.
Figure 22: Qualitative results for Reshading. Both PNN methods and Sidetune have similar qualitativeresults.
Figure 23: Qualitative results for 2D Edges. Both PNN methods and Sidetune have similar qualitativeresults.
Figure 24: Qualitative results for Surface Normals. Both PNN methods and Sidetune have similar qualita-tive results.
Figure 25: Average Accuracy for various Fusion methods in iCIFAR. Late fusion (the setting side-tuninguses) is better than or comparable to other fusion methods.
Figure 26: Qualitative results for Reshading for various Fusion methods. Various fusion methods havecomparable results.
Figure 27: Qualitative results for 2D Edges for various Fusion methods. Various fusion methods havecomparable results.
Figure 28: Qualitative results for Surface Normals for various Fusion methods. Late and distributedfusion perform similarly; better than early fusion.
Figure 29: Sidetuning can be used successfully even with black-box side information. When the baseinformation comes from a black-box process for which we have no other information, sidetuning can still beused (and performance improves vis-a-vis not using the inputs, and vs using inputs generated from a neuralnetwork). Existing lifelong learning approaches have no standard way to make use of this type of information.
