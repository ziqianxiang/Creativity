Figure 1: The workflow of our approach and comparison with existing AES models3.1	Sentence EmbeddingsWe use the same scheme as Liu et al. (2019) to obtain the embeddings at sentence level. It is proventhat Transformers, an attention mechanism that learns the contextual relations between words, caneffectively make use of the textual information. The model Bidirectional Encoder Representationsfrom Transformers (BERT) which is built on this this approach achieved state-of-the-art resultson various downstream tasks such as reading comprehension (Devlin et al., 2018). Therefore, wedirectly retrieve the word embeddings from pre-trained BERT model.
Figure 2: Architecture of Referee Network3.2.2	TrainingTo train RefNet, we firstly pair each essay with those with different scores within the same promptto form essay pairs. Pairing is not conducted across prompts because essays from different promptsare not really comparable due to disparate writing requirements and scoring scales. We do not pairthe essays with the same score because one essay can hardly be exactly as good as another: amongidentically scores essays, one can further distinguish one may be better than another. What’s more,the inconsistent scoring schemes make concept of equal quality even more vague. In the ASAPdataset, for instance, the scale can be as wide as 0-60 or as narrow as 0-3. As a result, two essayswith the same score in 0-3 scale may have drastically different scores in 0-60 scale. Therefore, itis foreseeable that requiring RefNet to categorize identically rated essays will frustrate the modelduring training and impair the performance. After pairing, RefNet is trained by minimizing the crossentropy between model output and true values.
Figure 3: Transfer Learningthis score notch is better than the input:1 niPi = 一 X R(ej, X)	⑶nij=1Two aspects are considered to form the voting criteria. First, according to the model, the test inputis inferior than pi percent of anchors with score label Ni . Intuitively, if we choose the anchors withhigher scores, the test essay will also be beaten. Therefore, depending on how large pi is, it willmore or less add to the likelihood that [Nmin , Ni ) contains the correct answer. In specific, votes ofvalue pi will be given to all the scores in [Nmin, Ni). Similarly, the test input is also superior than1 -pi percent of anchors with score label Ni. Thus, a vote with value 1 -pi is added to (Ni, Nmax].
Figure 4: The model accuracy for the essays pairs with different score difference. The score differ-ence here is relative to the scoring range of that prompt.
