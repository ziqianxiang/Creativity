Figure 1: (a) Convolutional layer operation and (b) computation of the filter Activation Magnitude.
Figure 2: AlexNet average accuracy for differ-ent pruning rations θobject classesFigure 3: Comparison of classification accuracybetween unpruned AlexNet and pruned usingNWP-M, LWP-33, NWP-66, LWP-66.
Figure 3: Comparison of classification accuracybetween unpruned AlexNet and pruned usingNWP-M, LWP-33, NWP-66, LWP-66.
Figure 4: The relative amount of filter pruned by layer and by pruning ratio (a) θ = 0.05, (b)θ=0.25,(c)θ=0.5In Figure 4 the Direct Pruning (DP) represents the number of filters removed by the semantic pruningmethod. The Residual Pruning (RP) represents the pruning resulting from the DP pruning. The RPpruning represents the filters that became inactive on average because their input becomes 0 onaverage after the DP pruning. Observe that similarly to the previous experiment, filters in 0th layerdo not get pruned at all. Similarly, filters in the 4th layer do not get pruned as well at low θ. Filtersfrom the 1st and 2nd layer is the one most pruned in DP while the filters of the 3rd layer are prunedas a consequence in RP. Additionally, notice that at 50% of pruning ration almost all filters fromthe 2nd layer are removed as a result of pruning. It is very interesting to see that even with higherpruning ratios, the 0th layer is not pruned at all and the 4th layer is pruned only at higher values ofθ. This means that the encoding provided by the first and last layer seems to be the most crucial andthe densest.
Figure 5: Examples of (a)-(d) object classes that improved for pruning ratio θ > 0, (e)-(h) that forcertain ratio θ > 0 have same accuracy of classification as when θ = 0 and (i)-(l) object classesfor which classification accuracy was always worse than when classifying when θ = 0. x-axis - θ,y-axis - accuracy.
Figure 6: Correlation of filters (a)-(c) left after pruning, (d)-(f) removed after pruning(e) jeep0.05 0.10 0.15 0.20 0.25 0.30 0.35 0∙M 0∙45Pruning ratio,。0,300.85ɑ. 0.80L∖O 0.75E 0.700.650.60Pruned Filter Correlatton for Class: lighter(f) lighter0.0	0.1	0.2	0,3	0.4	0.5	03Prunlnff ratlo,βNoivPntned Filter Correlation for Class： apron(a) non-pruned filter correlation(b) non-pruned filter correlation(c) PCA projection of activation magni-
Figure 7: Correlation of filters left after pruning (a), removed by pruning (b) and PCA mapping ofaccumulated response for class apronpuzzle is decreasing. It is possible to assume that, the effect of interference from unrelated filters isreducing, and as a result, improves the model accuracy, as shown in Figure 5h. The last exampleis provided for the class from the group, which was negatively affected by the pruning (Figure 5k).
