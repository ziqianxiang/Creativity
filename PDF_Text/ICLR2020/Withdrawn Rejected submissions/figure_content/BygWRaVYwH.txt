Figure 1: Comparison of meta-learned learning rates against fixed and multi-step annealed for train-ing DenseNet-BC(k=12) on CIFAR10. We observe convergence near state-of-the-art with bettersample complexity that using a hand-designed annealing schedule.
Figure 2: The learning rates during a training run of a VGG network with SGD as the inner optimizerfor 20-way 1-shot mini-imagenet classification. The colors show the parameter groups within themodel.
Figure 3: The learning rates during a training run of a VGG network with Adam as the inner opti-mizer for 20-way 1-shot mini-imagenet classification. The colors show the parameter groups withinthe model.
