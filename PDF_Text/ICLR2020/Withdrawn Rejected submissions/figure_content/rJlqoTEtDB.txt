Figure 1: Train and test accuracy for different models and datasets. The annotations indicate thebest overall test accuracy for each optimization method. The γ values in five experiments are0.8,0.8,0.8,0.7,0.8 for PoweredSGD and 0.8, 0.8, 0.8, 0.8, 0.7 for PoweredSGDM, respectively.
Figure 2: (a) Train accuracy comparison between SGD (learning rate = 0.1) and PoweredSGD(learning rate = 0.1, γ = 0.4) on the 13-layer fully-connected neural network. The arrows annotatethe accuracy values of both methods after 20 epochs. (b) The 1-norm of stochastic gradients of SGDand PoweredSGD in the first layer of the fully-connected neural network at every epoch.
Figure 3:	The amplification effects of Powerball function with different γ and different gradient sizes.
Figure 4:	We trained deep networks using PoweredSGD with different hyper-parameter settings.
Figure 5:	Effects of different γ on test accuracy. We show the best Top-1 accuracy on CIFAR-10dataset of ResNet-50 and DenseNet121 trained with PoweredSGD. Although the best choice of γdepends on learning rates, the selections can be quite robust considering the test accuracy.
Figure 6:	Effects of different γ on convergence. We show the best train loss on CIFAR-10 dataset ofResNet-50 trained with PoweredSGD. While the γ which achieves the best convergence performanceis closely related to the choice of learning rates, a Y chosen in the range of 0.4-0.6 Seem to providebetter robustness to change of learning rates.
Figure 7: Train loss and test accuracy for SGDR and PoweredSGDR. Learning rate schedules alsohelp accelerate training of PoweredSGD and improve the test performance.
Figure 8: Train and test accuracy for SGD, SGDM and PowerSGD. The annotations indicate the bestoverall test accuracy for each optimization method.
