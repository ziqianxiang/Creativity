Figure 1: Adaptation to test task Ts from the parameter initializations yielded by OC-MAML andMAMLB	Experiment DetailsFor MT-MNIST, we use the same 4-block convolutional architecture as used by Hsu et al. (2018)for their multi-class MNIST experiments. However, we exclude the batch normalization (Ioffe &Szegedy, 2015) layers, as we want to assess their effect in the OCC case, as discussed in Section 4.2.
Figure 2: Exemplary normal (left) and anomalous (right) samples belonging to different tasks fromthe STS-Sawtooth (a and b) and the STS-Sine (c and d) datasetsFigure 2 shows exemplary normal and anomalous samples from the STS-Sawtooth and STS-Sinedatasets. In order to increase the variance between the aforementioned synthetic signals underlyingthe different tasks, we randomly sample the frequency, i.e. the number of periods within the windowlength l , with which each waveform is generated, as well as the amplitude and the vertical position14Under review as a conference paper at ICLR 2020(see Figure 2). For sawtooth waveforms, we also randomly sample the width of the rising ramp asa proportion of the total cycle between 0% and 100%, for each task. Setting this value to 100% andto 0% produces sawtooth waveforms with rising and falling ramps, respectively. Setting it to 50%corresponds to triangle waveforms.
Figure 3: Exemplary anomalous samples from a finishing (left) and a roughing (right) operations,where the anomalous time-steps are depicted in red.
