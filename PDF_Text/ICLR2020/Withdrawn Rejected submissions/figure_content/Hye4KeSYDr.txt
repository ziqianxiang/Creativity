Figure 1: Different RobUStneSS-Sr (left) With varying ∣Sr | andRobUStneSS-Sr (right) with varying ∣Sr|. For Robustness-Sr(left), the higher the better; for Robustness-Sr (right), the lowerthe better. We omit points in the plot with value too high to fit inthe scale of y-axis.
Figure 2: Visualization onour proposed methods. Thetop features selected by Reg-Greedy are less noisy.
Figure 3: Visualization on top 20 percent relevantfeatures provided by existing explanations.
Figure 4: Visualization of targeted explanation. Ineach row, We highlight relevant regions explainingWhy the input is not predicted as the target class.
Figure 5: Comparisons between different targeted explanations against different targeted class onMNISTinteresting finding from the table is that while vanilla gradient has generally been viewed as a base-line method, it nonetheless performs competitively on the proposed criteria. To investigate deeperinto such observation, we shall visualize the explanations in the following subsection. For simplic-ity we will just apply Reg-Greedy with RObUStneSS-Sr criterion in the qualitative comparisons withprevious methods.
Figure 7: Explanations on a text classificationFigUre 6: ViSUaliZatiOn Of different explanations model where the predicted label for this sen-on ImageNet, where the predicted class for each tence is “sport”input is “fish”, “bird”, “dog”, and “sea lion”.	.
Figure 8: ComParisons_between our proposed methods under different criteria. From left to right:untargeted Robustness-Sr, targeted Robustness-Sr, untargeted Robustness-Sr, targeted Robustness-Sr .We omit points in the plot with value too high to fit in the scale of y-axis.
Figure 9: Comparisons between our proposed methods and existing explanations under different cri-teria. From left to right: untargeted Robustness-Sr, targeted Robustness-Sr, untargeted Robustness-Sr ,targeted Robustness-Sr. We omit points in the plot with value too high to fit in the scale ofy-axis.
Figure 10: Comparisons between our proposed methods Under_different criteria on ImageNet. Fromleft to right: untargeted Robustness-Sr, targeted Robustness-Sr, untargeted Robustness-Sr, targetedRobustness-Sr. We omit points in the plot with value too high to fit in the scale of y-axis.
Figure 11: Comparisons between our proposed methods under different criteria on ImageNet. Fromleft to right: untargeted Robustness-Sr, targeted Robustness-Sr, untargeted Robustness-Sr, targetedRobustness-Sr. We omit points in the plot with value too high to fit in the scale of y-axis.
Figure 12: Comparisons between explanations under different criteria on MNIST. Left figure:change in output logits as relevant features are inserted into the input. Right figure: change inoutput logits as relevant features are removed from the input.
Figure 13: Comparisons between different targeted explanations against different targeted class onMNIST.
Figure 14: Heatmap Visualization of different explanations on MNIST.
