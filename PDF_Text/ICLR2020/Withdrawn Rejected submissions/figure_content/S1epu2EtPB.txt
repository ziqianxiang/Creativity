Figure 1: Layout of the model used to generate the latent video representation z. The inputs are theencoded representations of the start and and frames E(xs) and E(xe), together with a noise vectoru.
Figure 2: Examples of videos generated with the proposed model. For each of the three datasets, thetop row represents the generated video sequences, the bottom row the original video from which thekey frames are sampled.
Figure 3: Output diversity illustrated by taking the average of 100 generated videos conditioned onthe same start and end frames.
Figure 4: Sample output from intermediate representations. Each row corresponds to connecting thefinal video generator to one of the last 8 latent representation generator layers, from layer 17 (top) to24 (bottom), the last of which is the actual output of the full model. Only the 14 in-between framesare shown.
