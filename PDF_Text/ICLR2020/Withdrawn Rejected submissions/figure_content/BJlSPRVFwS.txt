Figure 1: We plotted the train accuracy and generalization (test) loss and accuracy trajectories forthe methods. SGD runs a single process, whereas the asynchronous methods run 10 concurrentprocesses. In this set of experiments we have no momentum correction. The WIassm and WCassmdemonstrate better convergence per epoch compared to Passm. Note that, the single process executingSGD iterations has a better opportunity to use CUDA threads as there is no concurrent use of GPUsby multiple processes. The per epoch performance of Passm matches that of SGD inferring thatamount of subgradient updates are almost identical: in the former it is done collectively by all theconcurrent processes accessing disjoint set of tensors, whereas, in the latter it is done by a singleprocess using comparable amount of parallization.
Figure 2: Same setting as in Fig 1. We used a momentum = 0.9. It can be observed that withmomentum correction the convergence of Passm improves significantly. Mitliagkas et al. Mitliagkaset al. (2016) experimentally showed that the degree of asynchrony directly relates to momentum; ourexperiments show that the relative gain in terms of convergence per epoch by momentum correctionis better for Passm that exhibits more asynchrony compared to WCassm, which uses locks for writeconsistency.
Figure 3: This set of figures presents the train-loss trajectory against time (in minutes) whilecomparing asynchronous methods - running 5 and 10 concurrent processes - with sequential SGD.
Figure 4: Same setting as in the Fig 3, momentum = 0.9. We plotted test-accuracy in terms of Top1correct match % vs time (in minutes). In can be observed that Passm offers faster convergence perunit time in accuracy as well compared to the other two asynchronous methods.
