Figure 2: Train loss and test error (top-1) plots of three CNN architectures on CIFAR-10 dataset.
Figure 3: Top-1 and Top-5 test error for VGGNet and ResNeton ImageNet dataset.
Figure 4: Test perplexity for 2-layer and 3-layer LSTMmodel on Penn Treebank dataset.
Figure 5: Plot of max and min values across all coordinates of vbt against the iteration number forResNet model on CIFAR10 dataset.
Figure 6: Train loss and test error (top-1 error) of three CNN architectures on CIFAR-100. In allcases, Padam achieves the fastest training procedure among all methods and generalizes as well asSGD with momentum.
