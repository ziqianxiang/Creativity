Figure 1: Architecture of our proposed model RW-LISTA.
Figure 2: An example of input signal and output of the proposed reweighting block φ (after training).
Figure 3:	(a) Self-dependence introduced in the reweighting block, which corresponds to theelement-wise manner. (b) Local dependence introduced in the reweighting block, which is achievedby convolution (illustrated by a 1 × 3 convolution). (c) Global dependence introduced in thereweighting block, which is conducted by a fully connected layers.
Figure 4:	(a) Visualization of recovered signals by LISTA and RW-LSITA. (b) The results of dif-ferent reweighting blocks on synthetic CSS signals, where RwISTA and LISTA are considered forcomparison. (c) Visualization of the matrix of one learned reweighting FC layer.
Figure 5:	Comparisons of reweighted LISTAs with LISTAs at different SNR levels.
Figure 6:	Comparisons of RW-LISTA with state-of-the-art CSS solvers.
Figure 7:	Reconstructed 20 × 20 digit images on MNIST dataset using different recovery algorithmswith N = 400, M = 200 and SNR = 5 dB (Rows from up to down: original images, recoveredimages by RW-LISTA, LISTA, CluSS, EBSBL, MBCSLBP, and PCSBL)image pixels are zero. Extension of one-dimensional signal recovery to two-dimensional image re-covery is straightforward since the two-dimensional image can be transformed into one-dimensionalblock-sparse signal. In the experiment, We resize the images in MNIST into 20 × 20 and normal-ize the pixel value to [0, 1]. Then each image is rasterized into a 400-dimensional vector. We setN = 400, M = 200 and corrupt the observation with SNR = 5 dB. All the 60000 images in thetraining set have been used to train RW-LISTA.
