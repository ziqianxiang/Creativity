Figure 1: A DNT with four layers of NBs, each layer with five NBs. The input of each layer is aconcatenation of the input of the previous layer with its output. Moreover, the input x is multipliedelement-wise With a binary mask m (See section 3.3) before it is fed into the DNT.
Figure 2: (a) An example of a 7 × 7 checkerboard (XOR in the top left rectangle). (b) Mean accuracy(and standard error) of FCNs and GBDTs (XGBoost) over n × n checkerboard classification, n =2, . . . , 20. (c) A XOR-problem (2 × 2 checkerboard) with additional irrelevant features. (d) Low-and high-level features: XOR between checkerboards and additional binary feature.
Figure 3: Survival probability of male population taken from the Titanic dataset. On the left plot, wesee the survival vs age which exhibits multiple sharp transitions that resemble a 1D checkerboardbehavior. On the right plot, the example is extended to a 2D checkerboard, survival vs age and fare.
Figure 4: A DNF is implemented by concatenating the DNTs outputs and applying one fully-connected layer.
