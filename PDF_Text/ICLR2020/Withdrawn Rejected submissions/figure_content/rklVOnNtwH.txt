Figure 1: Comparison of existing and proposed methods. We visualized scatter plots of the outputsof the penultimate layer of a CNN that can estimate the uncertainties of latent features using theSVHN dataset (Netzer et al., 2011). We used only classes 0, 1, and 2 for the training data. Classes0, 1, 2, and OOD, indicated by red, yellow, blue, and black, respectively, were used for the vali-dation data. We plot the contour of the maximum output of the softmax layer of the model. Left:Because the image of “204” includes the digits “2” and “0,” the maximum value of the softmaxoutput decreases because the model does not know to which class the image belongs. Right: Thesizes of points in the scatter plots indicate the value of the combined uncertainties of features. Wecan classify the image of “204” as an in-distribution image according to the value of the combineduncertainties.
Figure 2: Network structure of UFEL when using DenseNet. Black arrow: Extracting the varianceof latent features using the reparameterization trick. Blue arrow: Combining these features.
Figure 3: Plot of ACC (x-axis) and AUROC (y-axis). The number on the plot indicates the numberof training epochs. We used CIFAR-10 (as in-distribution), TIM (as OOD), and the DenseNet-BCmodel. This graph shows that the AUROC of UFEL is less related to ACC than those of the baselineand ODIN.
Figure 4:	Plot of AUROC (y-axis) when changing the number of in-distribution dataset classes (x-axis). We used SVHN as in-distribution dataset, TIM, LSUN, and iSUN as OOD datasets, and theLeNet5 model. All plots were averaged over three runs and the error bar indicates one standarddeviation.
Figure 5:	Plot of AUROC (y-axis) when changing the OOD dataset (x-axis). We used CIFAR-10and CIFAR-100 as the in-distribution dataset. All plots are averaged over three runs and the errorbar indicates one standard deviation.
Figure 6: Visualization of original images.
Figure 7: CNN for feature combination.
