Figure 1: MobileNet v1 and v2 and EfficientNet models. Sparse models: blue, dense models:red. Sparse models include the cost of storing the location of non-zeros for sparse tensors as abitmask converted back into parameter count. That is every 32 values in the bitmask contributes one“parameter”.
Figure 2: Sparse 1x1 Convolution as SpMM. Left: Unstructured sparsity (or block size 1). Right:Output channel block size of 4et al., 2015). Park et al. (2016) was not able to accelerate 1 × 1 convolutions, Liu et al. (2015)did not attempt it. The latter also required generating a new set of kernels for each instance ofa model, which is often impractical for deployment. Due to the difficultly of accelerating sparsecomputation, channel pruning approaches have been preferred (Gordon et al., 2018; Dai et al., 2018;Luo et al., 2017; Louizos et al., 2018; Theis et al., 2018; He et al., 2018). These approaches pruneaway entire filters leaving the final model dense, and function more as an architecture search overchannel counts.
Figure 3: Visualization of the memory reads and writes of our algorithm. In step 1, we load 8 spatiallocations simultaneously for each of the non-zero weights in the first row of the weight matrix. Wemultiply each scalar weight by its corresponding row, accumulate the results, and in the end writethem out. Step 2 performs the same calculation for the next output channel. After steps 1 and 2, allvalues for these spatial locations are in the cache, so future loads in steps 3 and 4 will be fast, despitebeing random access.
Figure 4: FLOPs with increasing layer depth. All measurements taken on a Snapdragon (SD) 835.
Figure 5: FLOPs with increasing layer depth. Measurements taken on an Intel Xeon W-2135.
Figure 6: Effect of block size on top-1 accuracy. It only matters how many elements are in a block,the configuration is unimportant.
Figure 7: Effect of sparsity on top-1 accuracy. The sparser a model is, the fewer flops it requires toachieve a given Top-1 accuracy.
Figure 8: The x-axis corresponds to turning that layer and all following layers to block size 4, theprior layers are unstructured. The y-axis is the efficiency of making this change over an unstructuredmodel given as a ratio where the numerator is the speedup of changing the block(s) from unstructuredto block size 4 and the denominator is the decrease in top-1 accuracy that occurs by making thischange.
Figure 9: (left) EfficientNet scaling with block size. (right) EfficientNet scaling with sparsity.
