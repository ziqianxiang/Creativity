Figure 1: Binary classification on a toy dataset using a MAP estimate (a) and various Gaussianapproximations over the weights, sorted by their complexity of inverting the precision matrix. Theseapproximations are carried out only at the last layer of the network and d denotes the number ofhidden units at that layer. The shade of color represents the confidence of the prediction (darkershade means higher confidence). The decision boundary is in thick black. Even an arbitrary (i.e. non-Bayesian) isotropic (b) or diagonal (c) covariance makes the confidence bounded away from one.
Figure 2: An illustration of Proposition 2.3 for a linear classifier defined on R2 . The confidence ofthe marginalized prediction of a linear classifier is the highest in the direction of the lowest curvature,as described by Σ.
Figure 3: Binary (top) and multi-class (bottom) toy classification. The color represents either theconfidence (top) or entropy (bottom) of the prediction, with darker shade implies higher value.
Figure 4: The zoomed-out version of the MAP’s and Laplace’s confidence from Figure 1d, alongwith denominator of z.
