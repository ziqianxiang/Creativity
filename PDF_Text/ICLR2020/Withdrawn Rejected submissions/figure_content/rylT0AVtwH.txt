Figure 1: Overall architecture. The unimodal proposal network and multimodal proposal networkare employed by selection. Modalities are denoted by different colors. Unobserved modalities areshaded. (i.e. blue is observed while red/yellow are unobserved.) The selected variables are indicatedby the arrows. Standard normal prior is not plotted for simplicity. All components are trainedsimultaneously in an end-to-end manner.
Figure 2: Feature Imputations on UCI datasets. Missing ratios (x-axis) are 0.3, 0.5, 0.7. Categori-cal (top row) and numerical (bottom row) datasets are evaluated by PFC and NRMSE respectively(lower is better for both). We show mean and standard deviation over 3 independent runs.
Figure 4: Generation on MNIST+MNIST. Gen-erated Samples w/o conditional information. Asshown, the correspondence between modalities (pre-defined pairs) are preserved while stochastic multi-modal generation.
Figure 3: Imputation on MNIST+MNIST.
Figure 6: Generation on MNIST+MNIST. Generated Samples w/o conditional information. Asshown, the correspondence between modalities (pre-defined pairs) are preserved while generation.
Figure 7: Multiple independent sampling in selected latent space. The leftmost digits are observedimages in ground truth, and the right 8 digits are imputations of corresponding unobserved digits.
