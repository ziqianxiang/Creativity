Figure 1: Our solution to the alignment problem. A. A schematic demonstrating objects appearingand disappearing over time. B. An example of how an a shuffled list, S and aligning indices, I areconstructed from an unshuffled list U, also in the case where objects are C. dropped and D. added.
Figure 2: Schematic of the self-supervised AlignNet.
Figure 3: The Goal: Aligning a sequence of sets of entities. A. Given an input sequence of sets ofobjects (left), we would like to obtain a sequence of objects that are aligned over time (right). Thismeans that once a new object appears itis assigned a “sticky index” (Pylyshyn, 1989), correspondingto a slot index, any subsequent instances of that same object must be assigned to that same slot. B.
Figure 4: How many message passing stepsare needed? For each num^reCurrent_Stepswe trained five AlignNets and show the medianperformance with the standard deviations. TheAligner is trained with random numbers of objectsbeing added, dropped and slots left empty. Thetop five models all achieve 99.9% accuracy.
Figure 5: Episodic-sort-of-clevr question answering with the AlignNet and Relation NetworkThe episodic-sort-of-clevr question answering dataset consists of a sequence of observations of ob-jects within a scene, with objects appearing, disappearing and reappearing again across multiplescenes. Each object is represented symbolically and each scene is given a unique label. In this ex-ample, the episode contains two scenes, and each scene contains six objects, with four observationsper scene and two objects per observation. The AlignNet learns to write objects to an object-alignedmemory. This memory is then provided as input to a relation network, along with the question. Therelation network is trained to answer questions about the episode.
Figure 6: Varying the noise level and comparing to baselines for max「num ±o _drop = 2. Foreach noise_level We trained five AlignNets with max_num工o_drop = 2 and show the medianperformance with the standard deviations. The AlignNet achieves > 99% accuracy at all noiselevels and out-performs baselines.
Figure 7: Dropping up to five objects and comparing to baselines. For each m,a,XjnUmHoJIropwe trained five AlignNets and show the median performance with the standard deviations. We alsotake the median across five runs of the baseline models. The AlignNet achieves > 99.9% accuracywhen dropping up to five objects.
Figure 8: Adding up to five objects and comparing to baselines. For each max_num_to_add Wetrained five AlignNets and show the median performance with the standard deviations. We also takethe median across five runs of the baseline models. For each max_num_to_add at least one of thefive models achieves an accuracy > 99%.
Figure 9: Varying the noise level and comparing to baselines for max_num_to_add = 2. Foreach noiselevel We trained five AlignNets with max_num_to_add = 2 and show the medianperformance with the standard deviations. We also take the median across five runs of the baselinemodels. The AlignNet achieves > 99% accuracy at all noise levels, out-performing baselines.
Figure 10: Varying the noise level and comparing to baselines for max_num_to_add = 2 andmax jnum do .drop = 2. For each noiseJevel We trained five AlignNets and ShoW the medianperformance with the standard deviations. We also take the median across five runs of the baselinemodels. The best model at each noise level achieves > 99% accuracy at all noise levels, except atnoise」evel = 0.2, where the best model achieves 98.7% accuracy. All of our models out-performbaselines.
Figure 11: Visualisations of AlignNet results. These examples are not cherry picked. The Inputcolumn shows the list of objects, U, the Dropped column shows the list of objects, S, with entitiesdropped and the Add column shows the list of objects, S with additional entities not present in theInput. The Align column shows the aligned entities, slots that were empty in the Input may now beoccupied by new objects and entities that were in the Input but dropped are replaced by empty slots.
Figure 12: Comparing the number of message passing steps needed to obtain high test accuracywhen adding and dropping objects. For dropping, a single message passing step is sufficient.
Figure 13:	The AlignNet as a general framework with transformers at the core, rather than agraph network. We found that at least two layers of transformers were needed to achieve maximalperformance.
Figure 14: Accuracy with which sequences with different numbers of kept objects are aligned.
Figure 15: Visualisations of the aligned sequences over time. For each num_keep_slots in theinput sequence, we show how a train AlignNet, which we refer to as an Aligner, writes to mem-ory, M . We also show the resulting sequence of aligned objects. We render each symbolic objectrepresentation, in each slot as an image, to show all the objects in each slot.
