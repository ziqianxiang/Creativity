Figure 1: Adaptation-Imputation model: (a) training, (b) inference.
Figure 2: Missing patch size study7Under review as a conference paper at ICLR 2020comes very small (< 30%) or very large (> 65%). When the missing patch is too small mostof the information for predicting the target label is already available thus simple models performalready well; while when it becomes too big, too few information is available to guarantee efficientreconstructions from the non-missing patch.
Figure 3: ADV-MSE weighting on ads-kaggleter maximum performance but with high variance: performance ranges from 0.35 to 0.7 on the targetdomain. A small contribution from MSE (here λMSE = 0.005) stabilizes the results.
Figure 4: missing-features MNIST-MEvaluation The digits datasets are provided with a predefined train / test split. We reportaccuracy results on the target test set and use the source test set as validation set (Section D.2.1).
Figure 5: Base architecture for the ADV DANN modelD.1.2 ADSWe experiment with ADV models only. As input data is numeric and low dimensional, architecturesare simpler than in digits.
Figure 6: Features’ normalized distribution for each input dimension (features 1 to 12): (a) Sourcedomain (blue), (b) Target domain (red)20Under review as a conference paper at ICLR 2020(i)(j)Figure 7: Embeddings for MNIST → MNIST-M dataset on a batch, for source missing (acc 14.4%)(a) (b); ADV missing (acc 32.6%) (c) (d); ADV partial (acc 27.0%) (e) (f) ADV with imputation (acc56.3%); (g) (h) and ADV full (acc 74.2%) (i) (j). (a) (c) (e) (g) (i) represent the target (blue) andsource (red) clusters, (b) (d) (f) (h) (j) represent the classes on source and target instances.
Figure 7: Embeddings for MNIST → MNIST-M dataset on a batch, for source missing (acc 14.4%)(a) (b); ADV missing (acc 32.6%) (c) (d); ADV partial (acc 27.0%) (e) (f) ADV with imputation (acc56.3%); (g) (h) and ADV full (acc 74.2%) (i) (j). (a) (c) (e) (g) (i) represent the target (blue) andsource (red) clusters, (b) (d) (f) (h) (j) represent the classes on source and target instances.
Figure 8: Embeddings for MNIST → MNIST-M dataset on a batch, for source missing (acc 14.5%)(a) (b); OT missing (acc 18.8%) (c) (d); OT partial (acc 27.75%) (e) (f); OT with imputation (acc28.6%) (g) (h) and OT full (acc 45.9%) (i) (j). (a) (c) (e) (g) (i) represent the target (blue) and source(red) clusters, (b) (d) (f) (h) (j) represent the classes on source and target instances.
Figure 9: Embeddings for MNIST → USPS dataset on a batch, for source missing (acc 25.0%) (a)(b); OT missing (acc 58.0%) (c) (d); OT partial (acc 62.42%) (e) (f); OT with imputation (acc 65.2%)(g) (h) and OT full (acc 91.5%) (i) (j). (a) (c) (e) (g) (i) represent the target (blue) and source (red)clusters, (b) (d) (f) (h) (j) represent the classes on source and target instances.
