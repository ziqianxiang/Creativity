Figure 1: Horse Dataset: Example frames for each young Thoroughbred horse in the dataset. Ineach video the horse walks from left to right. The videos vary in horse color, the appearance ofsunlight and shadow, and relative horse size as well as background. This makes the data set idealfor tests in robustness and generalization. To illustrate the horse-10 task we arranged the horsesaccording to one split: the ten leftmost horses were used for train/test within-domain, and the restare the out-of-domain held out horses.
Figure 2: Transfer Learning boosts performance, especially on out-of-domain data. A: Illus-tration of the normalized error metric. B: Normalized Error vs. Network performance as rankedby the Top 1% accuracy on ImageNet (order by increasing ImageNet performance: MobileNetV2-0.35, MobileNetV2-0.5, MobileNetV2-0.75, MobileNetV2-1, ResNet-50, ResNet-101). The poseestimation performance is for 50% training set fraction. The faint lines indicate data for the threesplits. LEFT: Test data is in red, train is blue. RIGHT: additionally, pink is out-of-domain data;dashed lines indicate networks trained from scratch. Better ImageNet networks perform better onHorse-10; this relationship is even stronger for out-of-domain data. C: Example frames with humanannotated body parts vs. predicted body parts for MobileNetV2-0.35 and ResNet-50 architectureswith ImageNet pretraining on out-of-domain horses. D: Normalized Error vs. Training Set Frac-tion of Horse-10. For reference, 5% training data is ≈ 160 frames. Darker to light red shades aretest results for pretrained networks on within-domain data. Shades of pink show the test on out-of-domain data (order according to ImageNet performance: ResNet-101, ResNet-50, MobileNetV2-1,MobileNetV2-0.75, MobileNetV2-0.5, MobileNetV2-0.35). E: Same as C but for training fromscratch. F: Same as D but for training from scratch. All lines are averages of 3 splits (see Methods).
Figure 3: Fraction of correctly identified bodyparts improves with transfer learning A: Per-cent Correct Keypoint (PCK) vs. Training Set Fraction shows high performance for all pretrainednetworks on Horse-10. B: Same as A, but training from scratch. The performance drops strongly,especially for out-of-domain data C: Performance gain when using transfer learning. All lines areaverages of 3 splits, individual splits are shown as faint lines.
Figure 4: Up to a 3X gain with transfer learning on out-of-domain data. A: Transfer learninggain vs. architectures with 50% of the data used for training (comparing pretrained networks tofrom-scratch from Figure 2B). B: Same as in A, but for varying levels of input data (5 to 90%), lightto dark, respectively. All lines are averages of 3 splits.
Figure 5: Training randomly initialized networks longer cannot rescue out-of-domain per-formance. A: Normalized error vs. training iterations for ResNet 50 using 5% of the training data.
Figure 6: Summary of Findings: We present a new horse dataset for testing within and out-of-domain performance for pose estimation. We tested two classes of models, MobileNetV2s andResNets, which span a wide range of performance on ImageNet. We find that networks that performbetter on ImageNet are better for pose estimation. We also find that pretrained-ImageNet modelsstrongly improve out-of-domain robustness.
Figure 7: Example frames with human and pretrained network annotations. Here we showthe smallest networks, namely ResNet-50 and the ultra-lightweight MobileNetV2-0.35, trained for100, 000 iterations. Top Left set: example training images. Top Right: within domain test imageresults. Bottom: out-of-domain horses. Examples illustrate the challenges: varying coat colors,size changes, background, human legs, various postures, background horses, and partially occludedhorses while they walk in and out of the video frames.
Figure 8:	Transfer Learning boosts accuracy (PCK). A: Percent Correct Keypoint (PCK) vs.
Figure 9:	Test and training performance when training from scratch.) A: Normalized Errorvs. Training Set Fraction of Horse-10. 5% is ≈ 160 frames. Darker to light red shades aretest results for ResNet-101, ResNet-50, MobileNetV2-1, MobileNetV2-0.75, MobileNetV2-0.5,MobileNetV2-0.35. Darker to lighter blue is for training, same ordering as in test. B: Normal-ized Error vs. Network performance as ranked by the Top 1% accuracy on ImageNet, but hereon Horse-10; namely, MobileNetV2-0.35, MobileNetV2-0.5, MobileNetV2-.75, MobileNetV2-1,ResNet-50, ResNet-101. Test data is in red, train is blue. This data is for 50% training set fraction.
Figure 10: Speed Benchmarking for ResNets and MobileNetV2s: Inference speed for videos ofdifferent dimensions for all the architectures. A-C: FPS vs. batchsize, with video frame sizes asstated in the title. Three splits are shown for each network. MobileNetV2 gives a more than 2Xspeed improvement (over ResNet-50) for offline processing and about 40% for batchsize=1 on aTitan RTX GPU. On CPU we found even larger gains.
