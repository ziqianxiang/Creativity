Figure 1:  A sparse-reward task trainedby a YuMi robot in simulation and de-ployed to the real hardware.   The taskconsists of (1) opening a door, (2) press-ing  a button,  and (3) closing the door.
Figure 2:  This figure shows a comparison between the state distribution p(s) (dashed blue) and acorresponding novelty frontier distribution skewed from p(s) (red).
Figure 3:  Our method, Skew-Explore, aims to obtain uniform state visitation distribution estimatedfrom the history state set.  We start by sampling from our history state set, and weighting the statessuch that less-visited states are assigned with higher weights.  We then train a skewed distributionpskₑwₑd(s) using the weighted samples as the novelty frontier distribution. Next we sample referencepoints on the novelty frontier distribution and run our policy to explore around the points.
Figure  4:  The  PointMaze  environment  andthe DoorOpen environment.
Figure 5:  Results of how coverage and entropy changes over iterations in PointMaze (left) and theDoorOpen (right) environments.
Figure 6: Results of how coverage changes over iterations in the PointMaze environment.
Figure 7: (a) Relation between average extrinsic reward per iterations. (b) From up to down, left toright, this figure shows a sequence of the converged policy for the OpenPressClose task, which is along horizon task with a sparse reward given only at the end.
Figure 8: The change of coverage (left) and estimation of probability density (right) when adding anew point, in one-dimensional state space.  In the left image, the overall state coverage constructedby two black points is represented as the area of dark grey.  When a third point (red dot) is added,the overall state coverage increases and the amount of increase is the area of light grey. In the rightimage, the red curve shows the density distribution constructed by two black points.  When a newpoint (red dot) is added,  the density distribution changes to the dashed curve.  The state entropydecreases as the new point is in a region with high density.
Figure 9: This figure demonstrates the relationship between overall coverage and overlapping area.
Figure 10:  Five uniformly distributed points in PointMazeenvironment and the DoorOpen environment.
Figure 11: This figure show the relationship between convergence criteria and the number of itera-tions in PointMazz environment.
Figure 12: This figure shows the relationship between convergence criteria and the number of itera-tions in DoorOpen environment.
