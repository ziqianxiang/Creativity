Figure 1: Condition numbers of NTKs and their rate of convergence. Different colors representimages of different size. For example, in the yellow “12-6” , “12” represents the size of the datasetand “6” represents the dimension number (6 * 6 * 3 for FCNand (6,6,3) for CNN) (a) In the chaoticphase, κ(l) converges to 1 for all architectures. (b) We plot χl1κ(l), confirming κ explodes with rateχl1 /l in the ordered phase. In (c) and (d), the dashed lines representing the condition number κ(l)and solid lines the ratio between first and second eigenvalues. We see that, on the order-to-chaostransition, these two numbers converge to m++2 and dm+2 (horizontal lines) for FC/CNN-F andCNN-P respectively. In (e), we plot rates of convergence for CNN-P (solid) and CNN-F (dashed),confirming that pooling slows down the convergence of κ(l) by a factor of d. (f) Adding dropout tothe penultimate layer prevents κ(l) from divergence in the ordered phase. The legends indicate therate of the mask with ρ = 1 meaning keeping all activations. Horizontal lines are the limit of κ(l)computed in Equation 85 (here m = 20 for all curves.)definition of (alb) unchanged but define δa(lb) slightly differently to the above as δab = Pa - lq* totake into account the linear divergence at large depths. Taylor expanding to second order we find,Aa = - X2 1 + o(1)，现=-2lq*+ O(I)(23)Thus for large l, Θ(l) has the following formP(I) = lq* andPa) = 1 lq* + O(1). AS in the orderedphase, for large l it follows that Θ(l) essentially has two eigenspaces: one has dimension one andthe other has dimension (m - ) with》m)ax = (m +32)q* l + mO(1),	λ(eSt = 3q*l + O(1)	(24)
Figure 2: Maximal learning rate can be calculated via the λmax. y-axis: accuracy and x-axis:multiples of ηtheory. Each point on the solid (dashed) lines represents the best training (test) accuracythroughout training of one configuration. From blue to purple to red, (σω , σb) is moving from theorder phase to the chaotic phase. ρ = 1 is the theoretical prediction.
Figure 3: Top: training (left) and test accuracy of FCN using SGD. Bottom: test accuracy of CNN-P,CNN-F and the difference. In the blue strip, CNN-F significantly outperforms CNN-P, due to thefact that pooling increases the spectra gap by a factor of d.
