Figure 1: Demonstrations of the smoothing algorithm on two shapes from ModelNet40Suppose the underlying shape of the point cloud is a closed 2-manifold, in order to accommodateunevenly distributed points in point cloud data, we use a curvature-flow-based method, inspired by(Desbrun et al., 1999) and (Alexa et al., 2001). We first fit a local plane H = {x : hx, ni + D =0, x ∈ R3}, n ∈ R3, ||n|| = 1 for each point pi by minimizing the least-squares error:arg min	(hpj , ni + D)2	(5)n,D j∈N(pi)Under a special case we prove in Appendix A that the distance between pi and H can representthe local curvature. More generally, this distance is an approximation of the local curvature thatcan be computed efficiently. It is also possible to fit a quadratic surface so that the curvature canbe computed analytically, however such a fit would be both slower to compute and more prone tooverfitting, as we will show in the experiments.
Figure 2: A comparison between Taubin smoothing and our smoothing on 2-D point cloud. Left: A 2-Dellipse point cloud with 202 unevenly distributed points. Middle: Taubin smoothing. Right: Our smoothing. Inthe case of Taubin smoothing, highly concentrated areas are pushing points outward, resulting in an undesiredshape, while our algorithm is not influenced by point density.
Figure 3: Meshing a point cloud andthen applying Laplacian smoothing asin (Taubin, 1995). Corresponding pointclouds attached above.
Figure 4: Fitting quadratic surfaces to local neighbor-hoods and running mean-curvature-flow algorithm usingthe mean curvature calculated using the surfaces.
Figure 5: Example masks (best viewed in color). First four for PointConv, last four for DGCNN. Red indicateshigh mask value, blue low. Within each group of pictures from left to right: original shape, least amount ofpoints smoothed to drop the prediction confidence below 0.2×original confidence, least points inserted forrising the prediction above 0.8×original prediction confidence, 100% blurred. All the numbers below thepictures are of the format: percentage blurred [prediction confidence].
Figure 6: Auxillary graph for proof in Appendix A. From left to right: point pi and its actualneighbors (in blue), pi and its virtual neighbors (in red) and the fitted local plane H , enlarged graphof pi and three of its neighbors, pi with hi , which is pi ’s projection onto the fitted plane. hi is alsothe center of the ring formed by the virtual neighbors.
Figure 7: Deletion and insertion curves for all 40 classes in ModelNet40 for PointConv. Horizontalaxis is the deletion percentage (top 5%, 10%, etc.), and vertical axis is the predicted class score. Thered line is the deletion curve which blurs points from highest mask values, and the blue line is theinsertion curve (if read from right to left) which blurs points from lowest mask values.
Figure 7: Deletion and insertion curves for all 40 classes in ModelNet40 for PointConv. Horizontalaxis is the deletion percentage (top 5%, 10%, etc.), and vertical axis is the predicted class score. Thered line is the deletion curve which blurs points from highest mask values, and the blue line is theinsertion curve (if read from right to left) which blurs points from lowest mask values.
Figure 8: Deletion and insertion curves for all 40 classes in ModelNet40 for DGCNN. Horizontalaxis is the deletion percentage (top 5%, 10%, etc.), and vertical axis is the predicted class score. Thered line is the deletion curve which blurs points from highest mask values, and the blue line is theinsertion curve (if read from right to left) which blurs points from lowest mask values.
Figure 8: Deletion and insertion curves for all 40 classes in ModelNet40 for DGCNN. Horizontalaxis is the deletion percentage (top 5%, 10%, etc.), and vertical axis is the predicted class score. Thered line is the deletion curve which blurs points from highest mask values, and the blue line is theinsertion curve (if read from right to left) which blurs points from lowest mask values.
