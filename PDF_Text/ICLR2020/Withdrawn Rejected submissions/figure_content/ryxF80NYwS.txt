Figure 1: Encoding cluster labels. The col-ored points have fixed labels c1:n-1, formingK = 3 clusters. The four possible labels forthe circled point give four encoding vectorsGk , while the vector U encodes the 3 grayunlabeled points (Best seen in color).
Figure 2: Architecture of the Neural Clustering Process. The full model is composed by the deepnetworks h, g, u, f. Left: After assigning the cluster labels c1:n-1, each possible discrete value kfor cn gives a different symmetry-invariant encoding of x1:n into the vector Gk, using the functions hand g. The remaining, yet-unassigned points xn+1:N are encoded by u and summed into the vector U.
Figure 3:	Mixture of 2D Gaussians: Given the observations in the leftmost panel, we show samplesfrom the NCP posterior. Note that less-reasonable samples are assigned lower probability by the NCP.
Figure 4:	NCP trained on MNIST clusters. The top row shows 20 images from the MNIST testset. The five rows below show five samples of c1:20 from the NCP posterior. Note that each samplecaptures some ambiguity suggested by the form of particular digits.
Figure 5: Quantitative Evaluations. Upper left: Two 2D clusters of 50 points each (k = 0, 1) and aline over possible locations of a 101st last point. Upper right: Assuming the 2D model from (10),the posterior p(c101 |c1:100, x) can be computed exactly, and we compare it to the NCP estimate as afunction of the horizontal coordinate of x101, as this point moves over the gray line on the upper leftpanel. Geweke’s Tests. Lower left: The curves compare the exact mean (± one std.) of the numberof clusters K for different N’s from the CRP prior (with α = 0.7), with sampled estimates usingequation (11). Lower right: Similar comparison for the full histogram of K for N = 30 points.
Figure 7: Clustering multi-channel spike waveforms using NCP. Each row is an electrode channel.
Figure 8: Spike sorting on real data. 2000 spikes from real data were clustered by NCP (top-left)and vGMFM (top-mid). Each column shows the spikes assigned to one cluster (overlaying tracesand their average). Each row is one electrode channel. Top-right: t-SNE visualization of the spikeclusters. Bottom-left: Example pairs of matched RFs recovered by NCP (red boxes) and Kilosort(blue boxes). Blank indicates no matched counterpart. Bottom-right: Venn diagram of recovered RFs.
Figure 9: Spike sorting on hybrid data. Top: NCP, Kilo-sort, vGMFM recovered 13, 8, and 6 of the 20 injectedground-truth templates. Bottom: Peak-to-peak (PTP) sizeand firing rate of each injected template. (Smaller tem-plates with lower firing rates are more challenging.)Figure 10: Clustering ambiguous smallspikes. In both examples, multiple plausi-ble clustering results of small spikes wereproduced by sampling from the NCP pos-terior. (scale bar = 5× SD)Hybrid Data. We compared NCP against vGMFM and Kilosort on a hybrid recording with partialground truth as in Pachitariu et al. (2016). Spikes from 20 ground-truth templates were inserted into areal recording to test the spike sorting performance on realistic recordings with complex backgroundnoise and colliding spikes. As shown in Figure 9, NCP recovered 13 of the 20 injected ground-truthtemplates, outperforming both Kilosort and vGMFM, which recovered 8 and 6, respectively.
Figure 10: Clustering ambiguous smallspikes. In both examples, multiple plausi-ble clustering results of small spikes wereproduced by sampling from the NCP pos-terior. (scale bar = 5× SD)Hybrid Data. We compared NCP against vGMFM and Kilosort on a hybrid recording with partialground truth as in Pachitariu et al. (2016). Spikes from 20 ground-truth templates were inserted into areal recording to test the spike sorting performance on realistic recordings with complex backgroundnoise and colliding spikes. As shown in Figure 9, NCP recovered 13 of the 20 injected ground-truthtemplates, outperforming both Kilosort and vGMFM, which recovered 8 and 6, respectively.
Figure 11: Global permutation invariance. Training curves for the NCP model of 2D Gaussians inSection 2. Each minibatch was evaluated for 8 random permutations of the order of the points in thedataset. Above: Mean of the NLL over the permutations. Below: NLL standard deviation/NLL mean.
Figure 12: Synthetic data examples. Example of 500 synthetic spikes from 3 clusters.
Figure 13: Clustering synthetic data. The AMI scores for clustering 20 sets of 500, 1000, and 2000unseen synthetic spikes.
Figure 14: Spike sorting on real data. Receptive fields of 55 randomly selected pairs of unitsrecovered from Kilosort and NCP spike sorting. (Red boxes indicate units found by NCP; blueboxes by Kilosort.) Both approaches find the spikes with the biggest peak-to-peak (PTP) size. Forsmaller-PTP units often one sorting method finds a cell that the other sorter misses. NCP and KS finda comparable number of units with receptive fields here, with NCP finding a few more than KS; seetext for details.
Figure 15: Neural Particle Tracking. Left: Time trajectories of 5 2D particles. Note that particles can appearor disappear at arbitrary times. Middle and right: Two posterior samples. Note that since only one particle isobserved at each time, a particle not observed for some time leads to a possible ambiguity on the number ofparticles. (Best seen in color.)E Particle trackingInspired by the problem of electrode drift (Calabrese & Paninski, 2011; Pachitariu, 2019; Shan et al.,2017), let us consider now a generative model given byCt 〜p(ct∣cι,.. .,ct-1)	t = 1,...,T	(41)μk,t 〜p(μk,t∖μk,t-i)	k = 1...K t = 1,...,T	(42)Xt 〜p(xt∣μct,t)	t = 1,...,T	(43)In this model, a cluster corresponds to the points along the time trajectory of a particle, and (42)represents the time evolution of the cluster parameters. The cluster labels ct indicate which particle isobserved at time t, and note that particles can in principle appear or disappear at any time.
