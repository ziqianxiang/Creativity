Figure 1: (a) Top: illustration of our LaPlaCian pyramid based corruption construction strategy com-pared to traditional spatial corruption, where “LPS” indicates the Laplacian pyramid scale; Bottom:learned kernels when corruption is added in spatial domain (left) and gradient domain (right). (b) Vi-sualization of the discriminative capability on the MNIST test dataset, where samples are projectedto the 2D domain by using the t-SNE technique (Maaten & Hinton, 2008).
Figure 2: The illustration of the corruption with a LaPlaCian pyramid. A Gaussian pyramid isfirst constructed from the clean image, from which a Laplacian pyramid is built. After randomlyselecting a level (slice) from the Laplacian pyramid and adding random corruptions (e.g., noise), thefinal corrupted image is obtained by a reconstruction from the modified Laplacian pyramid.
Figure 3: Left: An illustration of the reconstruction performance on the MNIST dataset. The originalraw input images are randomly selected from the test set and are shown in the first row, whilethe second and last rows show the reconstructed results from conventional DAE and our LapDAE,respectively. DAE applied on Lap noise space and LapDAE on spatial noise space are also shownfor reference in the third and fourth rows. Right: Illustration on model convergence. The horizontalaxis shows the training iterations while vertical axis the training loss (in log scale).
Figure 4: Evaluation using the CIFAR-10 dataset. (a) The reconstruction result comparison, inwhich examples from each category are randomly selected for visualization. (b) The image retrievalresults by nearest neighbor. Given the query on the left, the top-5 (from left to right) retrieved resultsof DAE (middle) and LapDAE (right) are presented, in which red the ones indicate wrong category.
Figure 6: Additional results on illustration of the reconstruction performance using the MNISTdataset. The original raw input images are randomly selected from the test set and are shown in thefirst part, while the second and third parts show the reconstructed results from the conventional DAEand the proposed LapDAE, respectively.
Figure 7: Additional reconstruction results comparison using the CIFAR-10 dataset, in which ex-amples from each category in the test set are randomly selected for visualization. The original rawinput images are shown in the first part, while the second and third parts show the reconstructedresults from the conventional DAE and the proposed LapDAE, respectively.
Figure 8: Additional image retrieval results using the CIFAR-10 dataset by nearest neighbor. Giventhe query on the left, the top-5 (from left to right) retrieved results of DAE (middle) and LaPDAE(right) are presented, in which red marked ones indicate wrong category.
