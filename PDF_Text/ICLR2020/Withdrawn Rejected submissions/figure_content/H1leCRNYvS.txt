Figure 1: Left: Graphical model for a VAE for sampling N data points, where each sample x is con-ditioned on a latent code Z sampled from a prior, and data dimensions x₁, x₂, x₃ are conditionallyindependent given z. Middle: In the HBAE, the decoder distribution pθ(x z) is replaced by a deepEBM, where data dimensions can interact via undirected connections. Right: In the Set-HBAE, wefirst sample N set codes z, and we then sample M set elements by repeatedly generating from theEBM conditioned on the set latent code.
Figure 2:  Architectures for different models.  For each architecture, we use same colors to grouptogether modules that contribute cooperating terms to the adversarial loss formulation.  The HBAEcan be interpreted as a cGAN with a VAE encoder where all modules are learned jointly.
Figure 3: HBAE implementation. Left: Encoder. Middle: Conditional generator. Right: Conditionaldiscriminator, which takes as input ground truth x  or sample x¯.  The discriminator score is a dotproduct     of the intermediate representation and the latent code D(x|z) = h(x)T z.
Figure 4: Reconstructions and samples from HBAE. Left: input images from the test set (first row)and four stochastic reconstructions with different z′ (second through last rows). Right: unconditionalsamples (first row) and four stochastic samples with shared z and different z′.
Figure 5:  Markov chains starting from real examples from the test set (top row) and 6 recursiveconsecutive stochastic samples (second through last rows). We run two consecutive Markov chainsstaring from the same examples, corresponding to columns in the left and right plots.
Figure 6: Reconstructions of the ShapeNet (left figure) and VGGFace2 (right figure) daatasets witha Set-HBAE. For each block, the first row corresponds to an input set from the test split, and thesecond row shows one (stochastic) reconstruction of the set from the Set-HBAE.
Figure 7:  Uncurated unconditional generations from a Set-HBAE trained on ShapeNet (top) andVGGFace2  (bottom)  with  set  size  fixed  to  8.   Each  column  corresponds  to  a  sampled  set.   TheSet-HBAE generates sets that are coherent, and often with good visual quality.
Figure 8: VAE results on the Celeba Dataset. Top left: random samples of Celeba image; top right:reconstructions of a VAE; bottom: unconditional samples from a VAE.
Figure 9:  Unconditional GAN results on the Celeba Dataset.  Top left:  random samples of Celebaimage;  top  right:  reconstructions  of  a  GAN;  bottom:  unconditional  samples  from  a  GAN.  Thereconstructions are achieved by first training the unconditional GAN then train an additional encoderwith          the generator as decoder with l₁ loss.
