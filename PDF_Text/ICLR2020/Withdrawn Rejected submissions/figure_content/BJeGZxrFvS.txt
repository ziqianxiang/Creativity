Figure 1: Heatmap of Gradient Input saliency maps produced by various logits of a deep nettrained on MNIST. Red denotes pixels with positive values and Blue denotes negative values. Theinput image is of the number 3 , which is clearly visible in all maps. Note how maps computed usinglogits/labels ”7” and ” 5” assign red color (resp., blue color) to pixels that would have been expectedto be present (resp., absent) in those digits. The last figure shows the map produced using our CGImethod.
Figure 2: Histogram of Gradient Input scores for VGG-19 on Imagenet versus scores producedby mixture of two gaussians.
Figure 3:	Approximate completeness property of some saliency methods on VGG19, illustrated bynear-linear fit of (a) Gradient Input on ReLU nets with nonzero bias (b) DASP.
Figure 4:	Comparison of CGI saliency maps with Gradient Input saliency maps. Original imagesare shown on the left.
Figure 5: The first two figures depict layerwise and cascading randomization, respectively, for aVGG19 model trained on Imagenet for Gradient Input versus CGI. We find that in CGI, thesaliency map is almost blank when any weights are reinitialized. By contrast, we find that the origi-nal Gradient Input method displays the structure of the bird, no matter which layer is randomized.
Figure 6: Saliency map cascading randomization on MNIST for CDASP versus DASP. We noticethat DASP shows the structure of the digit even after randomization. CDASP eliminates the structureof the digit.
Figure 7: Second sanity check for Alexnet MNIST. On the middle image we find that using theoriginal gradient times input method results in an image where the original structure of the number3 is still visible. On the right hand side image we find that our modification removes the structure ofthe original input image, as we would expect for a model that had been fitted on randomized data.
Figure 8: Saliency map for layer-wise randomization of the learned weights. Diverging visualizationwhere we plot the positive importances in red and the negative importances in blue. We find thatwith CGI, the saliency map is almost blank when any layer is reinitialized. By contrast, we find thatGradient Input displays the structure of the bird, no matter which layer is randomized.
Figure 9: Saliency map cascading randomization LRP versus CLRP.
Figure 10: Saliency map for layer-wise randomization of the learned weights. Absolute value visu-alization where we plot the absolute value of the saliency map. We find that using CGI, the saliencymap is almost blank when any layer is reinitialized. By contrast, we find that Gradient Inputdisplays the structure of the bird, no matter which layer is randomized.
