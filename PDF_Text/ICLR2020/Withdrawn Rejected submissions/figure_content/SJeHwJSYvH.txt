Figure 1: Learning scenarios. Different distributional gaps may take place between training and test distri-butions. Our work is addressing the cross-bias generalisation problem. Background colours on the right threefigures indicate the decision boundaries of models trained on given training data.
Figure 2: Biased MNIST. We construct a synthetic datasetwith two types of biases - colour and texture - which highlycorrelate with the label during training. Upper row: colourbias. Lower row: colour and texture biases.
Figure 3: Qualitative results. Commonand uncommon images are shown accordingto class-texture relationship. Predictions ofResNet18 and REBI’S are shown as well.
Figure 4: Decision boundaries. Left to right: training data, baseline model, and our model.
Figure 5: Bias-target-wise accuracies. We show accuracies for each bias B = b and target Y = y pair inSingle-bias MNIST.
Figure 6: Impact of ρ. REBI’S is effective in de-biasing across different degree of bias in data.
Figure 7: Receptive fields of G. Biased and unbiased accuracies of REBI’S With F = LeNet and GBlindNet With varying receptive fields.
Figure 8: Texture-class correlation. We show samples from each texture cluster. For each cluster, we visualiseits top-3 correlated classes in rows.
Figure 9: More clustering samples. Extended version of Figure 8.
Figure 10: Data and model bias. Rows correspond to image labels and columns correspond to texture clusters.
Figure 11: Learning curve. De-biased ImageNet accuracies of vanilla ResNet50 and REBI’S trainedagainst BagNet50.
