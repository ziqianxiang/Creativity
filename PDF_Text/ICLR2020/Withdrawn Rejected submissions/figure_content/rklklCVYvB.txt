Figure 1: Comparing LSTM+T and LSTM+Time2Vec on several datasets.
Figure 2:	Comparing TLSTM1 and TLSTM3 on Last.FM and CiteULike in terms of Recall@10with and without Time2Vec.
Figure 3:	The models learned for our synthesized dataset before the final activation. The red dotsrepresent the points to be classified as 1.
Figure 4:	(a) Initial vs. (b) learned weights and frequencies for our synthesized dataset.
Figure 5:	An ablation study of several components in Time2Vec. (a) Comparing different activationfunctions for Time2Vec on Event-MNIST. Sigmoid and Tanh almost overlap. (b) Comparing fre-quencies fixed to equally-spaced values, frequencies fixed according to positional encoding (Vaswaniet al., 2017), and learned frequencies on Event-MNIST. (c) A histogram of the frequencies learned inTime2Vec for Event-MNIST. The x-axis represents frequency intervals and the y-axis represents thenumber of frequencies in that interval. (d) The performance of TLSTM3+Time2Vec on CiteULike interms of Recall@10 with and without the linear term.
Figure 6: Comparing LSTM+T and LSTM+Time2Vec on Event-MNIST.
Figure 7: Comparing LSTM+T and LSTM+Time2Vec on Event-MNIST and raw NjnDIGITS18.
Figure 9: Comparing LSTM+T and LSTM+Time2Vec on Last.FM.
Figure 8: Comparing LSTM+T and LSTM+Time2Vec on SOF.
Figure 10: Comparing LSTM+T and LSTM+Time2Vec on CiteULike.
Figure 11: TLSTM1’s performance on Last.FM with and without Time2Vec.
Figure 12: TLSTM1’s performance on CiteULike with and without Time2Vec.
Figure 14: TLSTM3’s performance on CiteULike with and without Time2Vec.
Figure 13: TLSTM3’s performance on Last.FM with and without Time2Vec.
