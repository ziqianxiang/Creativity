Figure 1: (a): Trajectory of a particle moving along a counter-clockwise route. The direction ofmotion is indicated by the arrow and the brightness, from lower to brighter intensity. (b) Groundtruth segmentation into “regimes”. Blue is moving straight, yellow is turning counter-clockwise, redis turning clockwise. (c) Segmentation learned by our SNLDS model. (d) Segmentation learned bybaseline SLDS model. Note that to model the nonlinear dynamics, the SLDS model needs to usemore segments.
Figure 2: Left: Illustration of the generative model. Dashed arrows indicate optional connections.
Figure 3: Segmentation on bouncing ball (left) and reacher task (right). From top to bottom:Row 1. ground truth of latent discrete states; Rows 2, 3, 4, 5, 6, 7. the posterior marginals, p(st =k|x1:T, z1:T), of SNLDS, SLDS, rSLDS, SVAE, KVAE, and Gumbel-Softmax SNLDS respectively,where lighter color represents higher probability. CompILE is not included because it representsa different model family that directly predicts the segment boundary without calculating posteriormarginals at each time step.
Figure 4: Comparing the relative negative log-likelihood (left) and the frame-wise F1 scores (right)on Dubins paths with 3 different annealing schedules. In the first run (green), the regularizationcoefficient and temperature start to decay at the very beginning of training. In the second run (red), thecross entropy regularization coefficients starts to decay at step 20, 000, while temperature annealingstarts at step 40, 000. In the third run (blue), the coefficient decay starts at step 50, 000, whiletemperature annealing starts at step 100, 000.
Figure 5: Left Column: SNLDS Segmentation on bouncing ball task with an RNN continuoustransition function. Top left: illustration of input sequence and reconstruction. Center Left (green):ground truth of the latent discrete states, corresponding to two directions of motion. Lower left (blue):the posterior marginal of p(st = k|x1:T, z1:T) of SNLDS at 100, 1000, 2000 and 10000 trainingsteps, where lighter color represents higher likelihood. Right Column: Training progress of relativenegative log-likelihood (Orange) and frame-wise F1 score (Blue) for SNLDS. Relative negativelog-likelihood is calculated as ln(nllk - min(nllk) + 1.), where nllk is negative log-likelihood. Thescale emphasizes that the loss still improves even late during training.
Figure 6: Illustration of the observations in reacher experiment. This is 2-D rendering of theobservational vector, but the inputs to the model are sequences of vectors, as in Kipf et al. (2019), notimages.
Figure 7: Image sequence reconstruction for Dubins path. The sequence is averaged with earlytimepoints scaled to low intensity, late timepoints unchanged to indicate direction.
