Figure 1: Experiment results on ResNet56 (He et al., 2016) trained on the CIFAR10 dataset. For thedetails of the experiments, refer to section 5. (a) The standard deviation of singular values of eachlayer of NNs with adversarial robustness (AR) strength 4, 16 (AR strength 8 is dropped for clarityof the plot). To emphasize, the x-axis is the layer index — overall 56 layers are involved. (b) Theprobability distribution of margins of NNs with AR strength 4, 8, 16. (c) The standard and adversarialaccuracy of NNs with AR 4, 8, 16.
Figure 2: (a) Illustration of the regularization effect of adversarial robustness. If a NN T is -adversarially robust, for a given example x (drawn as filled squares or circles) and points x0 in theyellow ball {x0 | ρ(x, x0) ≤ } around x, the predicted labels of x, x0 should be the same, and theloss variation is potentially bigger as x0 moves from the center to the edge, as shown as intenseryellow color at the edge of a ball. Collectively, the adversarial robustness of each example requiresan instance-space margin (IM) to exist for the decision boundary, shown as the shaded cyan margin.
Figure 3: Experiment results on CIFAR10/100, and Tiny-ImageNet. Net A, B are ResNet-56 andResNet-110 (He et al., 2016) respectively. The unit of x-axis is the adversarial robustness (AR)strength of NNs, c.f. the beginning of section 5. (a) Plots of loss gap (and error rate gap) betweentraining and test datasets v.s. AR strength. (b) Plots of losses (and error rates) on training and testdatasets v.s. AR strength.
Figure 4: Margin distributions of NNs with AR strength 4, 8, 16 on Training and Test sets ofCIFAR10/100.
Figure 5: (a)(b) are histograms of estimated probabilities and losses respectively of the test setsample of NNs trained AR strength 4, 8, 16. We plot a subplot of a narrower range inside the plotof the full range to show the histograms of examples that are around the middle values to show thechange induced by AR that induces more middle valued confidence predictions. (c)(d) are standarddeviations of singular values of weight matrices of NNs at each layer trained on CIFAR10/100 withAR strength 4, 16. The AR strength 8 is dropped for clarity.
Figure 6: The four plots from upper left to lower bottom (in each subfigure) are NNs with increasinglysmaller spectral complexity, where “Spectral Norm 1” means for each weight matrix of the NN,its spectral norm is at most 1. (a) Plots of training/test loss gap (and error gap) against adversarialrobustness strength. (b) Training/test losses and error rates against increased strength of adversarialrobustness.
Figure 7: Average maximal loss variation induced by adversarial examples in networks with increasingadversarial robustness. The experiments are carried on CIFAR10/100. represents the maximalperturbation can be applied on natural test examples to generate adversarial examples. It is measuredin the infinity norm. The larger the , the stronger the perturbation is. The error bars representstandard deviation.
Figure 8: Experiment results on CIFAR10/100. The network is ResNet-56 (He et al., 2016). The unitof x-axis is the adversarial robustness (AR) strength of NNs, c.f. the beginning of section 5. (a) Plotsof loss gap between training and test datasets v.s. AR strength. (b) Plots of error rates on training andtest datasets v.s. AR strength.
Figure 9: Margin distributions of NNs with AR strength 4, 8, 16 on Training and Test sets ofCIFAR10/100.
Figure 10: (a)(b) are histograms of estimated probabilities and losses respectively of the test setsample of NNs trained AR strength 4, 8, 16. We plot a subplot of a narrower range inside the plotof the full range to show the histograms of examples that are around the middle values to show thechange induced by AR that induces more middle valued confidence predictions. (c)(d) are standarddeviations of singular values of weight matrices of NNs at each layer trained on CIFAR10/100 withAR strength 4, 16. The AR strength 8 is dropped for clarity.
Figure 11: The plot of accuracy on adversarial examples v.s. adversarial defense strength built inNNs. The dotted line of which the intersections are marked by stars are adversarial accuracy in Madryet al. (2018) (CIFAR10), in Li et al. (2018) (Tiny ImageNet) under similar adversarial attack strength.
