Figure 1: An illustration of a hierarchy structure and the distribution relationship in a 2D spaceamong categories in such hierarchy. Multi-domain translation is shown in the horizontal direction(blue dashed arrow) while multimodal translation is indicated in the vertical direction (red dashedarrow). Since one child category is a special case of its parent, in the distribution space it is aconditional distribution of its parent, leading to the nested relationship between them.
Figure 2: Overview of the whole framework of the proposed method, which mainly consists of fivemodules: an encoder, a domain distributions modeling module, a decoder, a discriminator and a hi-erarchical classifier. Given images from different categories, the encoder extracts domain-irrelevantand domain-specific features respectively from the content and style branches. Then the decodertakes them as input to reconstruct the inputs supervised by the reconstruction losses. To realizethe multimodal and multi-domain translation, domain distributions are modeled in a common s-pace based on the semantic hierarchy structure and elaborately designed nested loss. Combiningthe domain-irrelevant features and sampled styles from any distribution, the decoder could translatethem to the target domain, guided by the adversarial loss and hierarchical classification loss.
Figure 3: Qualitative comparison on CelebA. The inputs are translated to their reversed value forgender and age attributes, and to black for hair color. StarGAN learns one-to-one mapping. MUNITand our HIT can generate multimodal results (3 outputs for each input are randomly sampled).
Figure 4:	Example results of HIT on ImageNet. For each input, 3 fixed styles are sampled fromlearned distribution of each category domain.
Figure 5:	Example results of HIT on ShapeNet. For each input, 3 fixed styles are sampled fromlearned distribution of each category domain.
Figure 6: Examples of hierarchical translation. For a target domain in a particular level, 5 styles aresampled from its distribution. With level becoming deeper, translations become more specific.
Figure 7: Translations using interpolations of sampled styles from different domain distributions (a)and style transfer between two real images (b).
Figure 8: Typical samples of hierarchical data on CelebA. Images within a purple rectangular boxare some instances of a leaf-level category. Categories within a green rectangular box belong toone common super-category. The super-categories within a red rectangular box share one commonancestor.
Figure 9:	Typical samples of hierarchical data on ImageNet. Images within a purple rectangularbox are some instances of a leaf-level category. Categories within a green rectangular box belong toone common super-category. The super-categories within a red rectangular box share one commonancestor.
Figure 10:	Typical samples of hierarchical data on ShapeNet. Images within a purple rectangularbox are some instances of a leaf-level category. Categories within a green rectangular box belong toone common super-category. The super-categories within a red rectangular box share one commonancestor.
Figure 11: The Inception Score (IS) of translated images in leaf-level on CelebA with differentdistribution margin m and fixed threshold α = 50.
Figure 12: The Inception Score (IS) of translated images in leaf-level on CelebA with differentnested threshold α and fixed distribution margin m = 2000.
