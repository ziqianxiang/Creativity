Figure 1: Visually distinguishing the concepts model debiasing and model trust (what we aim to do).
Figure 2: Landscape of the PreserveTask dataset describing the set of different possible tasks. Fivetasks could be performed on each image and each task has varying number of classes.
Figure 3: (a) A deep learning model learning features suited for multiple tasks, more than the in-tended shape classification task, (b) Existing approaches suppress other known tasks, such as sizeclassification by backpropagation of negative loss or gradient, (c) Proposed approach of suppressingall possible n-class classification task by using random class labels.
Figure 4: (Left) The accuracy matrix demonstrating the behavior of an ideal trusted DL model.
Figure 5: (Left) Trust scores obtained for various DL models. It can be observed that, of the fivemodels, the Inception-v1 and MobileNet has the least and highest trust score, respectively. (Right)Trust scores obtained after various suppression techniques for Inception-v1. It can be observed thatusing random labels for unknown tasks, we could improve the trustworthiness.
Figure 6: The performance matrix obtained after suppressing the known tasks in (a), (b) and theunknown tasks in (c), (d). Comparative results between a baseline negative loss function and theproposed GR layer based suppression is also shown. All results are computed for the Inception-v1model.
Figure 7: Comparison of color prediction performance with and without using the different tasksuppression mechanisms. It can be observed that using random labels reduces the performance ofcolor prediction irrespective of whether the preserved task was shape or size prediction.
Figure 8: (Left) Sample images from the colored MNIST dataset. (Right) TSNE plot of the featuredistribution of 392 images (class 0, foreground color: red and cyan) before and after suppressing thecolor prediction task.
Figure 9: Trust scores obtained for various DL models. It can be observed that, of the five models,the Inception-v1 and DenseNet has the least trust score while MobileNet has the highest.
Figure 10: The performance matrix heat-map detailing the shared task performance of Inception-v1model on the PreserveTask dataset.
Figure 11: The performance matrix heat-map detailing the shared task performance of DenseNetmodel on the PreserveTask dataset.
Figure 12: The performance matrix heat-map detailing the shared task performance of MobileNetmodel on the PreserveTask dataset.
Figure 13: The performance matrix heat-map detailing the shared task performance of VGG-16model on the PreserveTask dataset.
Figure 14: The performance matrix heat-map detailing the shared task performance of VGG-19model on the PreserveTask dataset.
Figure 15: Trust scores obtained after various suppression techniques. It can be observed that evenusing random labels for unknown tasks, we could improve the trustworthiness of the Inception-v1model on the PreserveTask dataset.
Figure 16: The performance matrix heat-map, after suppressing a known task using negative loss,detailing the shared task performance of Inception-v1 model on the PreserveTask dataset.
Figure 17: The performance matrix heat-map, after suppressing a known task using GR layer, de-tailing the shared task performance of Inception-v1 model on the PreserveTask dataset.
Figure 18: The performance matrix heat-map, after suppressing a unknown task using negative loss,detailing the shared task performance of Inception-v1 model on the PreserveTask dataset.
Figure 19: The performance matrix heat-map, after suppressing a unknown task using GR layer,detailing the shared task performance of Inception-v1 model on the PreserveTask dataset.
Figure 20: Trust scores obtained in the Diversity in Faces (DiF) dataset after various suppressiontechniques. It can be observed that even using random labels for unknown tasks, we could improvethe trustworthiness of the Inception-v1 model.
Figure 21: The performance matrix heat-map detailing the shared task performance of Inception-v1model on the Diversity in Faces (DiF) dataset.
Figure 22: The performance matrix heat-map obtained after suppressing the known tasks, detailingthe shared task performance of Inception-v1 model on the Diversity in Faces (DiF) dataset.
Figure 23: The performance matrix heat-map obtained after suppressing the unknown tasks, detail-ing the shared task performance of Inception-v1 model on the Diversity in Faces (DiF) dataset.
Figure 24: Trust scores obtained in the WIKI face dataset after various suppression techniques. It canbe observed that even using random labels for unknown tasks, we could improve the trustworthinessof the Inception-v1 model.
Figure 25: The performance matrix heat-map detailing the shared task performance of DenseNetmodel on the Wiki face dataset.
Figure 26: The performance matrix heat-map obtained after suppressing the known tasks, detailingthe shared task performance of DenseNet model on the Wiki face dataset.
Figure 27: The performance matrix heat-map obtained after suppressing the unknown tasks, detail-ing the shared task performance of DenseNet model on the Wiki face dataset.
