Figure 1: Illustration of the decomposi-tion of f = ψ ◦ φ.
Figure 2: LeNet5 characteristics after training on CIFAR10. Each color corresponds to a differentsetup of training, characterized by initialization strategy, mini batch size and learning rate. The setupsare ordered in ascending order by the mini batch size, with the largest corresponding to the brightestcolor of the displayed points.
Figure 3: LeNet5 configurations trained on CI-FAR10 with random reparameterizations. The cor-relation stays the same for the proposed measure,while it breaks for classic Hessian-based measure.
Figure 4: Robustness and flatness for LeNet5 con-figurations trained on CIFAR10. Results orderedby flatness, showing that robustness is bound byour flatness measure.
Figure 5: Layer-wise flatness measure calculated for MNIST trained fully-connected network. Fourplots correspond to four hidden layers of the network. For each of the layers a strong correlation withgeneralization error can be observed.
Figure 6: Neuron-wise flatness measure ρlσ calculated for each of the hidden layers for the fully-connected network trained on MNIST dataset. Each plot corresponds to a layer.
Figure 7: Neuron-wise flatness measure ρl calculated for each of the hidden layers for the fully-connected network trained on MNIST dataset. Each plot corresponds to a layer.
Figure 8: Network-wise flatness measures based on various neuron-wise and trace layer-wise mea-sures for the fully-connected network trained on MNIST dataset.
