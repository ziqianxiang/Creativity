Figure 1: ALE Space In-vadersIn this work, we first discuss current issues in the evaluation procedure of different DRL algorithmson ALE and their impact. We then propose an improved evaluation procedure, extending the rec-ommendations of Machado et al. (2018), named SABER : a Standardized Atari BEnchmark for1Under review as a conference paper at ICLR 2020Reinforcement learning. We suggest benchmarking on the world records human baseline and showthat RL algorithms are in fact far from solving most of the Atari games. As an illustration of SABER,current state-of-the-art DRL algorithm Rainbow (Hessel et al., 2018) is benchmarked. Finally, weintroduce and benchmark on SABER a new state-of-the-art agent: a distributable combination ofRainbow and Implicit Quantiles Network (IQN) (Dabney et al., 2018).
Figure 2: World records scores vs. the usual be-ginner human baseline (Mnih et al., 2015) (logscale).
Figure 3: Comparison of Rainbow and Rainbow-IQN on SABER: Median normalized scores withregards to training steps.
Figure 4: Comparison of Rainbow and Rainbow-IQN on SABER: classifying performance of agentsrelatively to the records baseline (at 200M training frames).
Figure 5: Median performance comparison for DQN, Rainbow and Rainbow-IQN with regards totraining frames. Evaluation time is set at 5 minutes to allow a comparison to DQN.
Figure 6: Median normalized scores with regards to training steps averaged over 5 seeds for bothRainbow and Rainbow-IQN. Only the 14 games on which 5 seeds have been conducted were usedfor this figure.
Figure 7: Agents performance comparison for the original Rainbow (Hessel et al., 2018) versusRainbow trained with (Machado et al., 2018) guidelines (30 minutes evaluation time to align withoriginal conditions)D.2 Rainbow-IQN: evaluation and comparisonInfluence of maximum episode length Figure 9 details the influence of evaluation time overthe performance range of the agents. As expected and discussed in the main article, evaluationtime has a strong impact on the normalized performance of the agents. In particular, no agentreaches superhuman performance before 30 minutes evaluation. More agents reach superhumanperformance when the evaluation time is not capped (in particular the ones that never stop playing,see next paragraph).
Figure 8: Performance comparison per game between the original Rainbow (Hessel et al., 2018)versus Rainbow trained with (Machado et al., 2018) guidelines (30 minutes evaluation time to alignwith original conditions)Agents performance classification for Rainbow depending on evaluation timeS-UMrt3H-Q JcuqEΠNFigure 9: Evolution of agents performance classification with evaluation time: Rainbow-IQN, 200Mtraining frames, evaluation time ranging from 5min to SABER conditionsI-r|R - r|(2)Note that we use the absolute value because in the game Skiing, the Rainbow agent is worse thanthe random agent. The details per game can be found in Figure 11. Note that games that are alreadysuperhuman in Rainbow are skipped, and that the Asteroids games, which is failing in Rainbow,becomes superhuman and is skipped in the figure for visualization purposes.
Figure 9: Evolution of agents performance classification with evaluation time: Rainbow-IQN, 200Mtraining frames, evaluation time ranging from 5min to SABER conditionsI-r|R - r|(2)Note that we use the absolute value because in the game Skiing, the Rainbow agent is worse thanthe random agent. The details per game can be found in Figure 11. Note that games that are alreadysuperhuman in Rainbow are skipped, and that the Asteroids games, which is failing in Rainbow,becomes superhuman and is skipped in the figure for visualization purposes.
Figure 10: Performance comparison per game between Rainbow and Rainbow-IQN on SABERconditions (200M training frames)% % %OooO O2 1 -oɔuɑʒlm O 七φdZaXXonyarslrevengeHIOLWO≤.deoJ3≡,baJ-VentUreUPInIdOWnBtankħam=FlIeJJ=Stennisaar_gUnnerSPaCeiinVadmSdar-SSk=Flg
Figure 11: Rainbow-IQN normalized with regards to a Rainbow baseline for each gameD.3 Stability of both Rainbow and Rainb ow-IQNThe 14 games on which we ran 5 trials for both Rainbow and Rainbow-IQN are: Asteroids, Cen-tipede, Demon Attack, Frostbite, Gravitar, Jamesbond, Krull, Kung Fu Master, Ms Pacman, PrivateEye, Seaquest, Up N Down, Yars Revenge and Zaxxon.
