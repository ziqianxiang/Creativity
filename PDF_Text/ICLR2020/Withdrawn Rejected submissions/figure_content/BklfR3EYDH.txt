Figure 1: Keyframing the future. Instead of predicting one frame after the other, we propose torepresent the sequence with the keyframes that depict the interesting moments of the sequence. Theremaining frames can be inpainted given the keyframes.
Figure 2: A probabilistic model for jointlykeyframing and inpainting a future sequence.
Figure 3: Soft keyframe loss in the relaxed formulation.
Figure 4: Sequences generated by KEYIN and a method with constant temporal keyframe offset(Jumpy) on Brownian Motion data. Generation is conditioned on the first five frames. The first halfof the sequence is shown. Movement direction changes are marked red in the ground truth sequenceand predicted keyframes are marked blue. We see that KEYIN can correctly reconstruct the motion asit selects an informative set of keyframes. The sequence generated by the Jumpy method does notreproduce the direction changes since they cannot be inferred from the selected keyframes.
Figure 5: Example generations by KEYIN on (top) Pushing and (bottom) Gridworld data. Thegeneration is conditioned on a single ground truth frame. Twelve of the 30 predicted frames areshown. We observe that for each transition between pushes and each action of the Gridworld agentour network predicts a keyframe either exactly at the timestep of the event or one timestep apart.
Figure 6: Distribution of trajectoriessampled from KeyIn. Each black linedenotes one of 100 trajectories of the ma-nipulated object. The obstacle is shownin blue and the initial position in pink.
Figure 7: Hierarchical planning on the Pushing dataset. Left: We use the model to produce keyframesthat represent the sequence between the current observation image and the goal. A low-level plannerbased on model predictive control produces the actions, at , executed to reach each keyframe, untilthe final goal is reached. Right: Planning performance on a Pushing task. The hierarchy discoveredby KeyIn outperforms comparable planning approaches.
Figure 8: Structure of the keyframe inference network. This diagram depicts the procedure to inferthe embedding of the n-th keyframe, κn, given the previously inferred keyframe embedding κn-1and the future images. The initial state of LSTMkey is produced by LSTMcond (not shown), whichtakes the embedding of past images as input. This ensures that the See the text for more details.
Figure 9: Qualitative keyframe discovery on the Structured Brownian Motion dataset for varyingnumber of predicted keyframes. Top: Ground truth sequence, keyframes with bold white frame.
Figure 10: A training sequence and two samples from our model on the Structured Brownian motiondataset. Each image shows an entire trajectory. Our model first samples the keyframes (shown inred), and then deterministically predicts the rest of the sequence. The image resolution was enhancedfor viewability.
Figure 11: Example keyframe detections on noisy sequences. Red frames mark annotated keyframes.
Figure 13: Sample planning task executions from the test set. From a start state depicted on the left,the robot arm successfully pushes the object into the goal position (semi-transparent object) guidedby the KEYIN subgoals. The right side of the figure shows intermediate frames of the executiontrajectories.
