Figure 1: Curves of estimated Q values in the toy environment at the starting point over the environ-ment steps.Each experiment is run four times.
Figure 2: A casual illustration of three Distributional Value Expansion(DVE) trajectories.
Figure 3: Average return over environment frames in MuJoCo and Roboschool environments. Eachexperiment is run four times.
Figure 4: Confidence ellipses of the distribution of estimated values Q versus the ground truth inHopper-v1. The points are extracted from environment steps of 1M, each includes statistics from10,000 points. The x-axis and y-axis represent the statistical cumulative discounted returns(groundtruth) and the predictive Q-values(both are normalized), respectively.
Figure 5: Examining the performance of RAVE variants and robustness of the learned policy. Eachexperiment is run four times. (a) Performance of RAVE with different Î±-CLB.(b) The falling rate ofvarious algorithms over the first 1M environment steps. Each point is evaluated on the outcome of1000 episodes.
Figure 6: An illustration of the rollout result with N = 4, Hmax = 3, P = 4. For each state of thetrajectory, there are 16 candidate targets.
