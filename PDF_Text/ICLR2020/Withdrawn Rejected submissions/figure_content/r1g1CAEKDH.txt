Figure 1: Schematics for channel synthesis from X to Y (a,b), and distributed simulation of (X, Y)(c,d). (a,c) and (b,d) correspond to the operational definition and the single-letter characterization ofeach problem, respectively. The local randomness U and V make the decoders stochastic.
Figure 2: A summary of the training objective for the Wyner VAE (15).
Figure 3: Schematics for selected sampling tasks. Double arrows denote deterministic mapping.
Figure 4:	Numerical evaluations for the MoG experiment. For each point of the plots, we trained 10different models and plotted average values with the shaded region that shows the standard deviation.
Figure 5:	Numerical evaluations of Wyner VAE for conditional generation of MNIST-MNIST add-1dataset. The plots were generated similarly as Fig. 4. See also Table 5 in the Appendix.
Figure 6:	Samples from Wyner VAE and the other models for MNIST-MNIST add-1 dataset. (a1-f1)Conditional sampling. (a2-f2) Conditional sampling with style control. For both tasks, the leftmostcolumn denotes the conditioning input to the models.
Figure 7: Samples from Wyner VAE for MNIST-SVHN dataset. (a,b) Conditional generation Withstyle control. (c,d) Joint stochastic reconstruction. (e,f) Joint generation with style control. λ = 0.1helps local latent variables capture style information, and the generated samples exhibit the effectcompared to λ = 0.
Figure 8: Conditional nll values of JVAE and VIB for MoG dataset. For each point of the plots, Wetrained 10 different models and plotted average values With the shaded region that shoWs the standarddeviation. (TWo largest and smallest outliers Were dropped for each point.)2All the scatter plots Were generated based on the Gaussian kernel density estimation.
Figure 9: Visualization of conditionally generated samples for MoG dataset. Each axis of the scatterplots corresponds to the first coordinate of Xi and Yi, respectively.2 The X data points were fromthe test data, and the Y data points were generated from the conditional models based on the testdata. One sample was generated for each data point.
Figure 10: Conditional generation.
Figure 11: Conditional generation with style control.
Figure 12: Joint generation.
Figure 13: Conditional generation.
Figure 16: Samples from Wyner VAE, JVAE, and CVAE for CelebA dataset. Multiple face imagesamples were conditionally sampled given an attribute vector listed at the leftmost column.
Figure 18: Sample images and their attribute vectors from CelebA dataset.
Figure 19: Conditional generation （attribute2face）.
Figure 20: Conditional generation with style control (attribute2face). Note that JVAE is not capableof style manipulation, and the results were simply generated from attribute2face generation and aregiven as a reference. Hence, the leftmost column is the sample image as in the conditional generationexperiment for JVAE.
