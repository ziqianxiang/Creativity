Figure 1: The combination of spans in the Eisner algorithm (a) and its second-order version (b). Forbrevity only one side is shown.
Figure 2: UAS of different encoder-decoder combinations relative dependency length5	Results and Analysis5.1	large training dataIt is widely believed that the more complex a model is, the more data it requires in parameter learn-ing. Considering the complexity brought by combining neural encoders and high-order decoders,we start our evaluations from large training datasets (more than 20000 sentences) from which we ex-pect all combinations will be effectively learned. Two treebanks meet the above require requirement:PTB and UD-Czech-CAC. In Table 2 we show the UAS results of running different encoder-decodercombinations on the two treebanks.
Figure 3: Standard deviation in UAS of four runs with small training data210□-2 .2-3-4-5-6∙∙⅛∙∙ LSTM-1+FO-⅛-LSTM-1+SO∙∙∙B∙∙ LSTM-2+FO1.51□0 0.5{	0nW -0.5<n
Figure 4: Average UAS relative to the combination of the non-neural encoder and the first-orderdecoder.
