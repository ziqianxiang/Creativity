Figure 1: (a) LayerNet architecture; (b) ACN with single neuron components. The input masksare shown by colored arrows to respective neurons, where f1 (red) has 2, f2 (orange) has 3 and fm(green) has 4 inputs. The output layer fout (blue) is an independent module which is not reused.
Figure 2: Plots of the model fit to the curve data. The first row shows the fit of the FC baseline,the second that of ACN. In the columns the respective number of model parameters as well as theachieved MSE on the test set are given above the plots. Since an arbitrary number of parameterscannot always be achieved with each model, the next nearest number with a competitive model wasselected, e.g. in the first column with 17 and 18 parameters respectively.
Figure 3: Plots of the model classification error on the test set for different numbers of parameters. Foreach tick on the x-axis the model with the best validation accuracy under the threshold for the numberof parameters is selected. In the titles next to the name of the dataset we indicate the dimension ofthe respective feature space. For some methods very small models could not be achieved so theyhave no points plotted on the left part of the plots (e.g. a fully connected network will not have lessparameters than a linear model with number_ofã€Œinputs X number_of.classes many parameters)up or even outperform it by a small margin, e.g. in case of the InternetAds dataset, however ACNremains competitive. TensorNet usually is at least a factor of two larger than the other models andtherefore is only shown in the last bin. The same applies for TP and BC on the optdigits, theorem andnomao/spambase datasets respectively.
