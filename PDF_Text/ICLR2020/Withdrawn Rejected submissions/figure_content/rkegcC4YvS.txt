Figure 1: Our hybrid model, a combination of a GAN prior and a Deep Decoder, has significantlyless representation error than the GAN Prior alone.
Figure 2: The model includes parameters α, β, θ, and z, which together comprise the imagerepresentation enforced by our Hybrid model. The final output information is a learned linearcombination of the two component images.
Figure 3: Reconstruction PSNRs versus measurement numbers for in-distribution test images for ourhybrid model, a Deep Decoder, and a GAN prior. The left panels zoom in to the low measurementregime of the right panels. Our hybrid model is able to yield higher PSNRs than both of its components,the Deep Decoder and a GAN, on in-distribution test images, in all but the lowest measurementregime. The effect is replicated both for the BEGAN (top row) and the DCGAN (bottom row).
Figure 4: Left: Samples of reconstructed images for m = 2500 measurements, a compression ratioof 0.051. The GAN prior has significant representation error, to the point where it appears to recoverthe face of the wrong person. The Deep Decoder has artifacts arising from too much smoothingof facial features. The hybrid model has sharply defined features, as does the GAN, without theunnecessary smoothness of the Deep Decoder by itself. Right: A comparison of output examples forthe Deep Decoder and hybrid models, along with the two components underlying the hybrid model.
Figure 5: Left: Performance of various image models on compressed sensing of images of birds,using a GAN prior trained to generate images of celebrity faces. Surprisingly, the hybrid model stillmarginally outperforms the Deep Decoder, as the GAN prior learns some general image statisticswhich are beneficial. Right: Coefficients of the GAN and Deep Decoder in the hybrid H . Darkercolors correspond to images out of the GAN prior training distribution. As one would expect, thecoefficient of the GAN prior is diminished when reconstructing images for which the GAN has notlearned relevant features.
Figure 6: Left: Reconstruction quality for images of celebrity faces, using GAN priors trained oncelebrity faces. There is a range of measurement regimes where the hybrid model outperforms theGAN as DIP model, which has significantly many more parameters. The GAN as DIP method usessignificantly more parameters in its image representation, since one must optimize over all weights ofa GAN. In the low measurement regime, this has no benefit in comparison to the underparametrizedhybrid model. Right: Reconstruction quality for images of birds, using GAN priors trained oncelebrity faces. In this case of out-of-distribution images, the range of measurements for which thehybrid model outperforms the GAN as DIP is is even more pronounced, demonstrating the versatilityof the hybrid method.
Figure 7: Parameter counts of image representations for image models used in our compressedsensing experiments. We report the maximum parameter count of the Deep Decoder and hybridmodels throughout our experiments, but the actual parameter count varies so that the Deep Decoderand hybrid models remain underparametrized with respect to the number of measurements. TheBEGAN models represent 128px images, with 49152 degrees of freedom. The DCGAN modelrepresents 64px images, with 12288 degrees of freedom.
