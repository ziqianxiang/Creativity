Figure 1: Our goal with Task-Optimal CCA is to compute a shared space that is also discriminative. We dothis by using NNs to compute an embedding for each view while simultaneously optimizing for correlationin the embedded space and a task-optimal objective. This setup is beneficial for three scenarios: 1) training aclassifier with the embedding from one view and testing with the embedding of the other view (ยง5.1), 2) whentwo views are available for training but only one at test time (ยง5.2), and 3) when both views are used for bothtraining and testing (ยง5.3). The embeddings for views Xi and X2 are represented by Ai and A2, respectively.
Figure 2: Deep CCA architectures: (a) DCCA maximizes the sum correlation in projection space by optimizingan equivalent loss, the trace norm objective (TNO) (Andrew et al., 2013); (b) SoftCCA relaxes the orthogonalityconstraints by regularizing with soft decorrelation (Decorr) and optimizes the `2 distance in the projectionspace (equivalent to sum correlation with activations normalized to unit variance) (Chang et al., 2018). OurTOCCA methods add a task loss and apply CCA orthogonality constraints by regularizing in two ways: (c)TOCCA-W uses whitening and (d) TOCCA-SD uses Decorr. The third method that we propose, TOCCA-ND,simply removes the Decorr components of TOCCA-SD.
Figure 3: Left: Sum correlation vs. cross-view classification accuracy (on MNIST) across different hyper-parameter settings on a training set size of 10,000 for DCCA (Andrew et al., 2013), SoftCCA (Chang et al.,2018), TOCCA-W, and TOCCA-SD. For unsupervised methods (DCCA and SoftCCA), large correlations donot necessarily imply good accuracy. Right: The effect of batch size on classification accuracy for each TOCCAmethod on MNIST (training set size of 10,000), and the effect of training set size on classification accuracy foreach method.OUr TOCCA variants out-performed all others across all training set sizes.
Figure 4: t-SNE plots for CCA methods on our variation of MNIST. Each method was used to computeprojections for the two views (left and right sides of the images) using 10,000 training examples. The plotsshow a visualization of the projection for the left view with each digit colored differently. TOCCA-SD andTOCCA-ND (not shown) produced similar results to TOCCA-W.
