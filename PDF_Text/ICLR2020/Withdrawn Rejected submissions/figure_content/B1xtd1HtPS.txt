Figure 1: Our network operates by processing local reference frames (LRF) on the object. InitialLRFs (b) are obtained by computing normal & tangent vectors on the point set in (a). (c) shows theLRFs randomly sampled from (a) and these are inputs to the first layer of our network. Subsequently,we obtain a multi-channel LRF that is a set of reference frames per pooling center (d). Holistically,our network aggregates the LRFs to arrive at rotation equivariant capsules.
Figure 2: Our quaternion equivariant (QE) network for processing local patches: Our input is a 3Dpoint set X on which we query local neighborhoods {xi} WithPrecomPUtedLRFS {qi}. Essentially,We learn the parameters of a fully connected network that continuously maps the canonicalized localpoint set to transformations ti, which are used to compute hypotheses (votes) from input poses. By aspecial dynamic routing procedure that uses the activations determined in a previous layer, we arriveat latent capsules that are composed of a set of orientations qi and new activations αi. Thanks tothe decoupling of local reference frames, αi is invariant and orientations qi are equivariant to inputrotations. All the operations and hence the entire QE-network are equivariant achieving a guaranteeddisentanglement of the rotation parameters. Hat symbol (q) refers to 'estimated'.
Figure 3: Our entire capsule architecture. We hierarchically send all the local patches to our Q-network as shown in Fig. 2. At each level the points are pooled in order to increase the receptivefield, gradually reducing the LRFS into a single capsule per class. We use classification and poseestimation (in the siamese case) as supervision cues to train the point-to-transform maps.
Figure 4: Shape alignment on the monitor (left) and toilet (right) objects via our Siamese equiv-ariant capsule architecture. The shapes are assigned to the the maximally activated class. Thecorresponding pose capsule provides the rotation estimate.
Figure 5: Our Siamese architecture used in the estimation of relative poses. We use a shared net-work to process two distinct point clouds (X, Y) to arrive at the latent representations (CX, αχ)and (CY, αγ) respectively. We then look for the highest activated capsules in both point sets andcompute the rotation from the corresponding capsules. Thanks to the rotations disentangled intocapsules, this final step simplifies to a relative quaternion calculation.
Figure 6: Additional intermediate results on car (first row) and chair (second row) objects. Thisfigure supplements Fig. 1 of the main paper.
Figure 7: Confusion matrix on ModelNet10 for classification.
Figure 8: Cumulative error histograms of rotation estimation on ModelNet10. Each row (< θ°) ofthis extended table shows the percentage of shapes that have rotation error less than θ. The colors ofthe bars correspond to the rows they reside in. The higher the errors are contained in the first bins(light blue) the better. Vice versa, the more the errors are clustered toward the 60° the worse theperformance of the method.
