Figure 1: Comparison of pretrain, compress and build up initialization schemes on CIFAR-10,CIFAR-100 and ImageNet. Results shown are mean and std over three trials of the top-1 valida-tion accuracy of an ensemble of ResNet-18 models. While compress does not perform well on smallsubsets of data, build up provides strong results on all subset sizes for all three tasks.
Figure 2: Comparing initialization schemes for ImageNet ResNet-18 training with variation ratios.
Figure 3: Analyzing the prediction consensus between different checkpoints during ImageNet train-ing. We observe very little, but consistent agreement in predictions between any consecutive pairof checkpoints. The overall agreement among the group of models decays rapidly. With 20 check-points, there is only consensus on around 90k samples for ResNet-18 and 50k samples for ResNet-10out of the 768k samples used for this evaluation.
