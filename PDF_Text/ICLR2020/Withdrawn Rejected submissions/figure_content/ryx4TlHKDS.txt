Figure 1: Learning dynamics of a singular mode of a single hidden layer network (d = 2). Thecontour lines visualize the manifolds of constant displacement levels qδ ≡ σ1σ2 - σ*. The op-timal solution σ∆ = 0 is shown in black. Tangent space of the manifolds defines the null-spaceof Hessian+. The vector field visualizes the displacement-normalized update [σι,σ2]∕∣σ∆∣, whoseamplitude is the normalized update speed: k<τk∕∣σ∆∣ H IIjk1-2/q. (A,B,C) SGD, NGD, √NGDshare the same update directions defined by the hyperbolic paths that conserve σ12 - σ22 (red lines),orthogonal to the null-space. But they exhibit different update speed: SGD exhibits vanishing speedproblem for small weights, while NGD has the opposite problem. In contrast, √NGD exhibits con-stant normalized speed. (D) NGD-d exhibits radially diverging vector field that conserves σ1∕σ2 .
Figure 2: Learning curves of input-output map and loss profile for various stiffness P levels: P =0 corresponds to NGD update, 1/2 ≤ P < 1 corresponds to VzNGD update, and 1 ≤ p < 2corresponds to SGD update for network depth ranging between 2 ≤ d < ∞. Top: Learning curvesof map singular modes(j(t)from eq (21). Dashed lines show the mode-strength of dataset σ*. Notethat large P increases the stiffness of dynamics, i.e. extreme changes of time-scale: between extremeslow and extreme fast. Half-max points (black circles) are shown to visualize the overall time-scaleof learning dynamics, which decreases with mode strength as σ-p. Bottom: Corresponding lossprofiles. Initial conditions:1(0)= 0 for P < 1, and 行⑼ = σ"100 for P ≥ 1. η= 1.
Figure 3: Curvature correction effect on generalization dynamics: (A) Singular mode strength ofinput-output correlation of training dataset. Dataset is generated from a rank-3 teacher networkwith added noise (SNR = 10). (B, C) Training and testing loss profiles of a 3-hidden-layer studentnetwork (See text). Note that all methods eventually converge to the identically overfitted solution(horizontal dashed-line). (D) Time-separated learning dynamics of across singular modes. To obtainthe individual mode components, we computed the network’s input-output correlation matrix, andprojected it to the singular vector basis of the data correlation matrix.
Figure 2: Training of a linear 3-layer network (D = 2).
