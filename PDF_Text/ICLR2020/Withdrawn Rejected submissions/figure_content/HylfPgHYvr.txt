Figure 1: Training of our occlusion resistant intuitive physics model. Our model takes asinput a video sequence containing segmentation masks of ob jects in individual frames (bottom).
Figure 2: Compositional RenderingNetwork.
Figure 3: 1: An overview of the scene. 2&3: Sample video frames (instance mask + depthfield) from our datasets (top) together with predictions obtained by our model (bottom).
Figure 4: The figure shows example predictions in five frames in a real scene containing 10frames. The small colored dots show the predicted positions of objects together with theestimated uncertainty shown by the colored “cloud”. The same colored dot is also shownin the (ground truth) center of each ob ject. The prediction is correct when the two dotscoincide. (see additional videos).
