Figure 1: Left: Generative model. According to the graphical model we obtain p(d, x, y, zd, zx , zy) =Pθ(x∣Zd, Zχ,Zy)pθd (Zd∣d)p(zχ)pθy (Zy ∣y)p(d)p(y). Right: Inference model. We propose to factorizethe variational posterior as qΦ& (Zd ∣x)qφx (zχ ∣x)qφy (zy |x). Dashed arrows represent the two auxiliaryclassifiers qωd (d∣Zd) and q□y (y∣Zy).
Figure 2: 2D embeddings of all three latent subspaces. In the top row embeddings are coloredaccording to their domain, in the bottom row they are colored according to their class. First column:zd encoded by qφd (zd |x). The top plot shows five distinct clusters, where each cluster correspondsto a single domain. In the bottom plot no clustering is visible. Second column: zx encoded byqφx (zx|x). We observe a correlation between the rotation angle of each MNIST digit and zx[0] inthe top plot. Upon visual inspection of the original inputs x, we find a correlation between the linethickness digit and zx[0] as well as a correlation between the digit width and zx[1] in the bottom plot.
Figure 3: Reconstructions of x using all three latent subspaces as well as reconstructions of x usingonly a single latent subspace at a time.
Figure 4: Samples from DIVA trained on Rotated MNIST.
Figure 5: Reconstructions. Left: First row is input, row 2 to 11 correspond to labels ’0’ to ’9’. Right:First row is input, row 2 to 6 correspond to domains 0, 15, 30, 45, 60.
Figure 6: 1000 two-dimensional embeddings Zd encoded by q$& (zd|x) for X from the test domainM 75。. The color of each point indicates the associated domain.
Figure 7: 1000 two-dimensional embeddings zy encoded by qφy (zy|X) for X from the test domainM75。. The color of each point indicates the associated class.
Figure 8: Left: Generative model. According to the graphical model we obtainp(x, Z) = pθ(x∣z)p(z).
