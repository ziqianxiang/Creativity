Figure 1: We study the task of prediction towards a given goal. When conditioning predictions on the goal,the distribution of possible trajectories reduces significantly (left vs. middle), making the modeling task easierand therefore allowing to scale prediction to much longer time horizons. Additionally, such goal-conditionedprediction enables more efficient, hierarchical prediction schemes (right).
Figure 2: Graphical models for state-space video generation. Left: video continuation. Right:the proposed goal-conditioned predictors (GCPs). b) a sequential goal-conditioned prediction.
Figure 3: Proposed latent variable models. Circles represent stochastic variables, shaded circlesrepresent variables observed at training and squares represent deterministic variables. Left: Sequentialprediction. Right: Hierarchical prediction.
Figure 4: Prior samples from GCP-tree on the four datasets: Human 3.6, pick&place, 3x3 Maze and10x10 Maze. Each sequence is subsampled to 9 frames.
Figure 5: Datasets used for our evaluation of goal-conditioned prediction. Left to right: Human3.6M (64×64px), pick&place dataset (64×64px)and Maze dataset (16×16px)third dataset, Maze, is collected in an environ-ment based on the Gym-Miniworld (Chevalier-Boisvert, 2018) simulator which consists of a number of sparsely connected rooms located on a grid.
Figure 6: Predictions on Human 3.6M. We see that the GCP models are able to faithfully capturethe human trajectory. The optical flow-based method (DVF) captures the background but fails togenerate complex motion needed for long-term goal-conditioned prediction. Causal InfoGan alsostruggles to capture the structure of these long sequences and produce implausible interpolations.
Figure 7: Runtime of GCP for dif-ferent sequence lengths on 10x10Maze (16 × 16px) with a batchsize of four. Experiments wereperformed on a standard NVIDIAP100 GPU.
Figure 9: Illustration of the agent successfully following plans generated by GCP-sequential modelthrough 5 rooms in succession. The agent’s position in the map is marked with the red diamond, thegoal is marked in green; time progresses from left to right; re-planning is performed every 5 steps.
Figure 8: Bottleneck discovery on pick&place.
Figure 10: Schematic visualization of the model architecture for GCP-Tree (first two layers depicted).
Figure 11: Prior samples from GCP-tree on the Human 3.6M dataset. Each row is a different priorsample conditioned on the same information.
Figure 12: Prior samples from GCP-tree on the 2D maze dataset. Each pair of rows shows twosamples given the same context.
