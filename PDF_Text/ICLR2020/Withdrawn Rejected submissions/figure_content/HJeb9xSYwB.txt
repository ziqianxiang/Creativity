Figure 1: The Voronoi diagram for a dense sample drawn from a low-dimensional distribution withtwo classes, one in red and one in black. The Voronoi cells, shown in green, vary in size dependingon how close a sample is to samples in the other class. The Voronoi edges that are adjacent totwo samples from two different classes are shown in solid green, and approach a decision boundarywhich is as far from the data distribution as possible.
Figure 2: To construct an adversarial example within a Voronoi cell, We repeatedly take steps inthe direction of the gradient of the loss, shown in blue. After each iteration we check if any of theVoronoi constraints are violated. We take the last iteration before a constraint is violated as ouradversarial example.
Figure 3: Adversarial training Voronoi constraints offers improved robustness in high codimension(10, 500) over standard adversarial training, on average.
Figure 4: Left: Adversarial training with Voronoi constraints on MNIST. Our model has NAUC 0.81and high classification accuracy after = 0.3. In particular, our model maintains 76.3% accuracyat = 0.4, compared to 2.6% accuracy for the Madry model. Right: On CIFAR-10, both modelsachieve NAUC of 0.29, but our model trades natural accuracy for robustness to larger perturbations.
Figure 5: The adversarial training of Madry et al. (2018) with = 0.4 (shown in green) produces amodel with significantly reduced robustness in the range [0, 0.3]. Increasing the number of epochsto 150, the resulting model (shown in red) does exhibit improved robustness in the range [0.3, 0.4],at the expense of some robustness in the range [0, 0.3] and still exhibits a sharp drop in accuracyafter 0.4. The purple model achieves NAUC of 0.76, while our model achieves NAUC 0.81.
