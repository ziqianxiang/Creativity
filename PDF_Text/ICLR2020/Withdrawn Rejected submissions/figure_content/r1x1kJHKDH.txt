Figure 1: (a) VAE Architecture. (b) Proposed PatChVAE Architecture: Our encoder network computes aset of feature maps f using Ï†(x). This is followed by 2 independent single layer networks - bottom networkgenerates part visibility parameters Qv. We combine QV with output of top network to generate part appearanceparameters Qa. We sample ZViS and ZaPP to construct Z as described in Section 3.2 which is input to the decodernetwork. We also visualize the corresponding priors for latents ZaPP and ZViS in the dashed gray boxes.
Figure 2: Concepts captured by parts: We visualize a few representative examples for several parts to qualitativelydemonstrate the visual concepts captured by parts. For each part, We crop image patches centered on the partlocation where it is predicted to be present. Selected patches are sorted by part visibility probability as score.
Figure 3: Masks used for weighted reconstruction loss Lw. First row contains images randomly samples fromMIT Indoor datatset. Second and third rows have the corresponding image laplacians and final reconstructionweight masks respectively. In the last row, we take the product of first and third row to highlight which parts ofimage are getting more attention while reconstruction.
