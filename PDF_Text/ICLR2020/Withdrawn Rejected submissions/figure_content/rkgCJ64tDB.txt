Figure 1: (a) A special case of ST -equivariant CNN with only (multiscale) spatial convolutions. The previousworks on ST -equivariant CNNs (Kanazawa et al., 2014; Marcos et al., 2018; Xu et al., 2014; Ghosh & Gupta,2019) are all variants of this architecture. (b) The general case of ST -equivariant CNN with joint convolutions(Theorem 1) where information transfers among different scales. See Remark 1 for more explanation.
Figure 2: Verification of ST -equivariance in Section 5.1. Given the original input x(0) and its rescaled versionDβ,vx(0), the four figures in each dashed rectangle are: x(l) [x(0)] (l-th layer feature of the original input),x(l) [Dβ,vx(0)] (l-th layer feature of the rescaled input), Tβ,v x(l) [x(0)] (rescaled l-th layer feature of the originalinput), and the difference (x(l) [Dβ,vx(0)] - Tβ,v x(l) [x(0)]) displayed in a (signal intensity) scale relative tothe maximum value of x(l) [Dβ,vx(0)]. It is clear that even after numerical discretization, ST -equivariance stillapproximately holds for ScDCFNet, i.e., x(l) [Dβ,vx(0)] - Tβ,v x(l) [x(0)] ≈ 0, but not for a regular CNN.
Figure 3: The numerical error in equivariance (i.e., the boundary “leakage” effect incurred by scale channeltruncation) as a function of network depth. Either (a) zero-padding or (b) replicate-padding is used for theconvolution in scale. The error is unavoidable as depth becomes larger, but it can be mitigated by (1) using jointconvolutional filters with a smaller support in scale (i.e., a smaller number of “taps” after discretization), and (2)using a replicate-padding instead of zero-padding. See Appendix B.1 for detailed explanation.
Figure 4: Reconstructing rescaled versions of the original test image by manipulating its image code Caccording to the group action (3). The first two images on the left are the original inputs; Decoder(C) denotesthe reconstruction using the (unchanged) image code C; Decoder(Dβ,v C) and Decoder(Tβ,vC) denote thereconstructions using the “rescaled” image codes Dβ,vC and Tβ,v C respectively according to (2) and (3).
