Figure 1: Sample generated images using CIFAR-10 (top row), and MNIST (bottom row) data-sets.Panels(a)-(e): Proposed MMD GAN with an automatic kernel selection via the particle SGD (Algorithm 1), Panels(b)-(f): MMD GAN Li et al. (2017) with an auto-encoder for dimensionality reduction in conjunction with amixed RBF Gaussian kernel whose bandwidths are manually tuned, Panels (c)-(g): MMD GAN in Li et al.
Figure 2: Visualization of data-points from the synthetic data-set PV = N(0, (1 + λ)Id×d) and PW =N(0, (1 - λ)Id×d) for d = 2. Panel (a): λ = 0.1, Panel (b): λ = 0.5, and Panel (c): λ = 0.9.
Figure 3: The evolution of the empirical measure μNτ(ξ) = N PN=I δ(ξ - ξkl) of the SGD particlesξm,… ,ξm ∈ IR2 at different iterations m. The empirical measure of random feature maps seemingly Con-verges to a Gaussian stationary measure corresponding to a Gaussian RBF kernel. Panel (a): m = 0, Panel (b):m = 300, Panel (c): m = 1000, and Panel (d): m = 2500.
Figure 4: The statistical power versus the threshold τ for the binary hypothesis testing via the unbiasedestimator of the kernel MMD. The parameters for this simulations are λ ∈ {0.1, 0.5, 0.9}, d = 100, n + m =100, p = 50. Panel (a): Trained kernel using the two-phase procedure with the particle SGD in equation 15 andan auto-encoder, Panel (b): Trained kernel with an auto-encoder and a fixed Gaussian kernel with the bandwidthσ = 1, Panel (c): Untrained kernel without an auto-encoder.
Figure 5: The MMD value during the two phase procedure for the kernel training. In the first phase, anauto-enCoder is trained (blue Curve). In the seCond phase, the kernel is trained using the embedded features (redcurve). Panel (a): λ = 0.9, Panel (b): λ = 0.5, Panel (c):X = 0.1 .
Figure 6: The sample generated images from CelebA (top row), and LSUN bedroom data-sets (bottom row).
