Figure 1: Convergence curve for projection length onto different components. (a) shows the curvewhen the target function have different component with the same scale. (b) shows the curve whenthe higner-order components have larger scale. Both illustrate that the lower-order components arelearned faster. Log-scale figures are shown in Appendix E.2.
Figure 2: Convergence curve for different components. (a) shows the curve of a trigonometricfunction. (b) shows the curve of a polynomial with even degrees. Both exhibits similar tendency ascombination of spherical harmonics.
Figure 3: Convergence curve for projection length onto vectors (determined by training data) andfunctions (estimated by test data). We can see that for low-order Gegenbauer polynomials, thenetwork learns the function while for the high-order Gegenbauer polynomial, the network overfitsthe training data.
Figure 4: Log-scale convergence curve for projection length onto different component. (a) showsthe curve when the target function have different component with the same scale. (b) shows thecurve when the higner-order components have larger scale. Both exhibit nearly linear convergenceespecially at late stage.
