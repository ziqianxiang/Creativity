Figure 1: Comparison of the learned attention across layers, datasets and attention variantsFigure 2: Visualization of the learned attentionof one node. Nodes are colored by labels andedges are colored by attention magnitude.
Figure 2: Visualization of the learned attentionof one node. Nodes are colored by labels andedges are colored by attention magnitude.
Figure 3: Attention learned by training on Coraand PPI with inductive and transductive settingsrespectively.
Figure 4: t-SNE visualization of ‘concat’ attention based features. From left to right, the features arefrom all layers, the first, and the second layer, respectively. See Appendix B.5 for more results.
Figure 5: Comparison of attention based sparsification against baseline random sparsification.
Figure 6: Sparsify graphs with one GAT and predict on sparsified graphs with another GNNsamples a proportion of edges over the entire graph(s) without replacement and we compare it againstthreshold sparsification.
Figure 7: t-SNE visualization of concat attention based features. From left to right, the features areseparately from all layers, the first layer and the second layer.
Figure 8: t-SNE visualization of dot product attention based features. From left to right, the featuresare separately from all layers, the first layer and the second layer.
Figure 9: t-SNE visualization of general attention based features. From left to right, the features areseparately from all layers, the first layer and the second layer.
