Figure 1: In this example, the three facts in the original graph (a) show that Turing received his PhDfrom Princeton and his undergraduate degree from King’s College Cambridge. Figures (b) and (c)show two methods of converting this ternary relation into three binary ones.
Figure 2: Visualization of HypE and HSimplE architectures. (a) function φ for HSimplE transformsentity embeddings by shifting them based on their position and combining them with the relationembedding. (b) function f (e, i) for HypE takes an entity embedding and the position the entityappears in the given tuple, and returns a vector. (c) function φ takes as input a tuple and outputs thescore of HypE for the tuple.
Figure 3: The above experiments show that HypE outperforms HSimplE when trained with fewerparameters, and when tested on samples that contain at least one entity in a position never encoun-tered during training. (a) MRR of HypE and HSimplE for different embedding dimensions. (b)Results of m-CP, HSimplE, and HypE on the missing positions test set.
Figure 4: An example of an embedding where ∣τ| = 5, δ = 4 and f3 is the third fact in Tp); this results in a vector of length ∣τ | where the Pth bit is set to 1 and all other bits set to 0. Finally,(()) sums the outcome of the resulting products to give us a score of 1.
