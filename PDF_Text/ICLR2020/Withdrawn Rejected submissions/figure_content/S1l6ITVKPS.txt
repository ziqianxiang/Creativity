Figure 1: The PrediNet architecture. WK and WS are shared across heads, whereas Wq 1 and Wq2are local to each head. See main text for more details.
Figure 2: Relations Game object sets and tasks. (a) Example objects from the training set and held-outtest sets. (b) There are five possible row / column patterns. In a multi-task setting, recognising eachrow pattern is a separate task. (C) Three examples tasks for the single-task setting. (d) An exampletarget task (left) and curriculum (right) for the multi-task setting. The curriculum task ids (right) foreach of the three examples (2, 4, and 3) correspond to the respective patterns in (b), and the task ineach case is to confirm whether or not the column of objects in the image conform to the designatedpattern. The aim of the target task (left) is to test whether the two rows of objects have the samepattern according to (b).
Figure 3: The four-stage experimental protocol for multi-task curriculum training. The same inputmodule (CNN) and output module (MLP) are used for the PrediNet and all baseline architectures;only the central module varies. Task identifiers are appended to the central module,s output vector.
Figure 4: Multi-task curriculum training. The target tasks are three column patterns (AAB, ABA, andABB) and the sole curriculum task is the 'between, relation.
Figure 5: Reusability of representations learned With a variety of target and pre-training tasks.
Figure 6: (a) Attention heat maps for the first four heads of a trained PrediNet. Left: trained on the‘same’ task. Right: trained on the ‘occurs’ task. (b) Principal component analysis. Left: PCA on theoutput of a selected head for a PrediNet trained on the ‘colour / shape’ task for pentominoes images(training set). Centre: The same PrediNet applied to hexominoes (held-out test set). Right: PCAapplied to a representative head of the MHA baseline with pentominoes (training set). (c) Ablationstudy. Accuracy for PrediNet and MHA on the ‘colour / shape’ task when random subsets of theheads are used at test time. PrediNet* only samples from heads that attend to the two objects.
Figure 7: PrediNet output in propositional form. (a) A small PrediNet (8 heads, 8 relations) trainedon the ‘between’ task is given an image. (b) Mean shift clustering is applied to the set of all attentionmasks computed by the heads. Each of the resulting 6 clusters is assigned a symbolic identifier. (c)Each relation is also given a symbolic identifier, and all 64 propositions computed by the PrediNet areenumerated in Prolog syntax, in accordance with Equation 1. (A subset is shown.) (d) The results canbe combined with further hand-written Prolog clauses. (Upper-case letters denote variables, whileconstants start with lower-case letters.) (e) Prolog queries can then be submitted. Here we are askingwhich relations r hold with a small value v between ob_2 and any other object x. (f) The query yieldsfour answers.
Figure S8:	Representative central module outputs for networks trained on the 'colour / shape, taskwhen projected onto the two largest principal components.
Figure S9:	Per-head PCA on the heads of a PrediNet and an MHA trained on the ‘colour / shape’task. For all networks, PCA was performed using the training data (pentominoes). In (a) and (c), thetraining data are projected onto the two largest PCs and in (b) the test data (hexominoes) was used.
