Figure 1: An illustration of the approach of this work. The Graph Neural Neural Network (GNN)(Battaglia et al., 2018) takes as input the graph of matches and then outputs a low rank embeddingof the adjacency matrix of the graph. The GNN operates on an embedding over the vertices of thegraph. In the figure, the GNN vertex embeddings are represented by different colors. The finalembedding is used to construct a pairwise similarity matrix, which we train to be a low dimensionalcycle-consistent representation of the graph adjacency matrix, thus pruning the erroneous matches.
Figure 2: (a) An illustration of the idea of the universe of features. Each feature in each imagecorresponds to a 3D point in the scene. We can construct cycle consistent embeddings of the featuresby mapping each one to the one-hot vector of its corresponding 3D point. While there can be manyfeatures, there are fewer 3D points and thus this corresponds to a low rank factorization of thecorrespondence matrix. Best viewed in color. (b) Visualization of the learned embeddings. On theleft we have the raw outputs, which are difficult to interpret. In the center, we rotated the featuresto best match the ground truth for a more interpretable visualization (see the end of Section 3.3).
Figure 3: (a) Errors are computed via absolute distance from the epipolar line, as expressed byEquation 6 via the epipolar constraint. The epipolar line is the line of projection of the feature inthe first image, projected into to the second. The distance to this line on the second image indicateshow likely that point is to correspond geometrically to the original feature. There can be falsepositives along the projected line, as shown by the square feature in the figure, but other pointswill be eliminated, such as the hexagonal feature. (b) Training curves with and without GeometricTraining loss, described in 8. The geometric training loss improves testing performance. Note howtraining with geometric consistency losses decreases the convergence time of the network. Bestviewed in color.
Figure 4: Plot of the losses of the baselines at different iteration numbers. The line shows the meanof the graph while the translucent coloring shows the 25th to 75th percentiles. The ROC AUC curvesremain fairly consistent while the L1 loss goes noticibly down after more iterations. Our methodcompares to 35-45 iterations of MatchALS, while only having 8 message passes. PGDDS performsbetter than us in L1 but we perform similarly in the ROC AUC metric. These results still hold evenwhen we change domains to the Graffiti dataset (see 4.2.1).
