Figure 1: The mutualexclusivity task used incognitive developmentresearch (Markman &Wachtel, 1988). Childrentend to associate thenovel word (“dax”) withthe novel object (right).
Figure 2: Evaluating mutual exclusivity in a feedforward (a) and seq2seq (b) neural network. (a) After trainingon a set of known objects, a novel label (“dax”) is presented as a one-hot input vector. The network maps thisvector to a one-hot output vector representing the predicted referent, through an intermediate embedding layerand an optional hidden layer (not shown). A representative output vector produced by a trained network isshown, placing almost all of the probability mass on known outputs. (b) A similar setup for mapping sequencesof labels to their referents. During the test phase a novel label “dax” is presented and the ME Score at thatoutput position is computed.
Figure 3: Evaluating mutual exclusivity on synthetic categorization tasks. ME Score (solid blue) and the cross-entropy loss (solid red) are plotted against the epochs of training. The configurations in the settings shownwere: (a) Results for a model with an embedding, hidden, and classification layers, (b) Results for a model withembedding and classification layers trained with a weight decay factor of 0.001, and (c) Results for a modelwith an embedding and classification layer trained with an entropy regularizer.
Figure 4: Ideal and untrained MEscores compared with the ME scores ofa few learned models.
Figure 5: Analysis of mutual exclusivity in machine translation datasets. The plots show the conditional proba-bility of encountering a new word in the target sentence, if a new word is present in the source sentence (y-axis;red line). Also plotted is the base rate of encountering a new target word (blue line). These quantities aremeasured as at different points during training (x-axis). Errors bars are standard deviations.
Figure 6: Analysis of mu-tual exclusivity in classificationdatasets. The plots show theprobability that a new input im-age belongs to an unseen classP (N |t), as a function of thenumber of images t seen so farduring training (blue), with itsstandard deviation. This mea-sure is contrasted with the MEscore of a neural network classi-fier trained through a similar runof the dataset (orange).
Figure 7: Results for the syn-thetic seq2seq task. The config-urations shown in the setting are(a) Results for a seq2seq GRUwithout attention (b) Results fora seq2seq GRU with attention.
