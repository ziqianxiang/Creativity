Figure 1: Top: Visualization of truth region (positive) of a triple according to Table 1. The residualvector , (a) becomes 0, (b) lies on the border of a sphere with radius γ1, (c) lies inside of a spherewith radius γ1, and (d) (h1,r1,t1) lies inside of a sphere with radius γ(h1,r1,t1) . Bottom: The his-togram of the scores of triples when TransE is trained on WordNet (WN18RR) using the losses ofEquation 2 (γ1 = 0), 2 (γ1 = 4), 4 (γ1 = 4) and 5 (γ = 6) respectively. Each of the bottom figuresis the approximation of the corresponding conditions (a) to (d).
Figure 2: Necessity condition for encoding symmetric relation: (a) when α < 1, the model cannotencode it. (b) when α = 1, the intersection of two hyperspheres is a point. u = 0 means embeddingvectors of all entities should be same. Therefore, symmetric cannot be encoded. (c) when α > 1,symmetric can be encoded as there are more than one point in the intersection of two hyperspheres.
Figure 3: The convergence of symmetric relation loss on FB15K2. The question is that how our model behaves under the loss 4 while we additionally disregardinjection of relation patterns. To this end, we considered TransComplEx4 which uses loss 4 but doesnot do any injection. Since the performances of RPTransComplEx4 and TransComplEx4 are veryclose, we conclude that the latter also learns the pattern over the existing triples quite efficiently. Thisis also confirmed by the convergence performance of them as shown in Figure 3 over the symmetricrelation.
Figure 4: The convergence of inverse relation loss on WN18The convergence of inverse, symmetric, implication and equivalence relation losses onFigure 5:FB15K14Under review as a conference paper at ICLR 2020figures show that the models trained by using the loss 4 can properly encode the relation patternseven without any injection mechanism. In other words, the TransComplEx4 model can properlyencode several relation patterns by only training on the triples (without using any additional relationpattern set to be injected). This shows the advantages of the models and the used losses.
Figure 5:FB15K14Under review as a conference paper at ICLR 2020figures show that the models trained by using the loss 4 can properly encode the relation patternseven without any injection mechanism. In other words, the TransComplEx4 model can properlyencode several relation patterns by only training on the triples (without using any additional relationpattern set to be injected). This shows the advantages of the models and the used losses.
Figure 6: Investigation of L6 with condition (c): The limitation is not valid, be-cause the triple (e2 , r, s2) can get an score to be considered as negative while triples((e1, r, s1), (e1,r, s2), (e2,r, s1)) are positive.
