Figure 1: Comparison of uniform label-flipping noise (Blue noise) and image search noise (Rednoise). From left to right, columns are true positives, blue noise, red noise (from text-to-imagesearch) and red noise (image-to-image search). The image-to-image search noise (the last column)only accounts for 28% of our data and fewer images are shown as a result.
Figure 2:	Vanilla training on synthetic (Blue) and real-world noise (Red) using Inception-ResNet.
Figure 3:	Comparison of generalization on noisy training data of Mini-ImageNet.
Figure 4: Fine-tuning using different ImageNet architectures.
Figure 5:	Peak accuracy of robust DNNs (trained from scratch) on Red and Blue Mini-ImageNet.
Figure 6:	Peak accuracy of robust DNNs (fine-tuned) on Red and Blue Mini-ImageNet.
Figure 7: Peak accuracy for different levels of added training noise.
Figure 8:	Peak accuracy of robust DNNs (trained from scratch) on Red and Blue Stanford Cars.
Figure 9:	Peak accuracy of robust DNNs (fine-tuned) on Red and Blue Stanford Cars.
Figure 10: The distribution of noisy and clean images in Mini-ImageNet and Stanford Cars. Grey,Blue and, Red bar represent images of clean labels, synthetic noisy labels and image-search noisylabels, respectively. Classes are ranked by the number of training examples. Better viewed in color.
Figure 11: Example training images in the WebVision dataset on three classes: ladybug, orange andjaguar. Note the ground-truth labels are not provided in WebVision and the images above may betrue or false positive. For comparison, Fig. 1 shows noisy training images in the proposed datasetwhich are all manually labeled.
Figure 12: Vanilla training on blue noise and red noise using Inception-ResNet. The first twocolumns are copied from Fig. 2 for comparison. The dark red curve in the third and fourth col-umn represents the noise of text-to-image search only and can be used to compare with the redcurve.
Figure 13:	Comparison of generalization on the noisy training data of Mini-ImageNet. The top rowis copied from Fig. 3 for comparison. The dark red curve in the bottom row represents the noise oftext-to-image search only.
Figure 14:	Fine-tuning using different ImageNet architectures. The top row is copied from Fig. 4for comparison. In the bottom row, the bars in dark red represent the noise of text-to-image searchonly. The results are comparable to the ones in Fig. 4 with slightly higher correlations (from 0.897and 0.875 to 0.915 and 0.920).
