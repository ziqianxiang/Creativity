Figure 1: Multi-object hierarchical attentive recurrent tracking (mohart). A glimpse is extracted for eachobject using a (fully differentiable) spatial attention mechanism. These glimpses are further processed witha CNN and fed into a relational reasoning module. A recurrent module which iterates over time steps allowsfor capturing of complex motion patterns. It also outputs spatial attention parameters and a feature vectorper object for the relational reasoning module. Dashed lines indicate temporal connections (from time stept to t + 1). The entire pipeline operates in parallel for the different objects, only the relational reasoningmodule allows for exchange of information between tracking states of each object. mohart is an extensionof hart (a single-object tracker), which features the same pipeline without the relational reasoning module.
Figure 2: The relational reasoning module in Mohart based on multi-headed self-attention. Here, weshow the computation of the interaction of the red object with all other objects. Object representations ft,mare computed using visual features, positional encoding and the hidden state from the recurrent module.
Figure 3: A scenario constructed to be impossible to solve without relational reasoning. Circles of thesame colour repel each other, circles of different colour attract each other. Crucially, each circle is randomlyassigned its identity in each time step. Hence, the algorithm can not infer the forces exerted on one objectwithout knowledge of the state of the other objects in the current time step. The forces in this scenarioscale with 1/âˆšr and the algorithm was trained to predict one time step into the future. HART (top) isindeed unable to predict the future location of the objects accurately. The achieved average IoU is 47%,which is only slightly higher than predicting the objects to have the same position in the next time stepas in the current one (34%). Using the relational reasoning module, MOHART (bottom) is able to makemeaningful predictions (76% IoU). The numbers in the bottom row indicate the self-attention weights fromthe perspective of the top left tracker (yellow number box). Interestingly, the attention scores have a strongcorrelation with the interaction strength (which scales with distance) without receiving supervision.
Figure 4 : Left: average IoU over sequence length for different implementations of relational reasoning onthe toy domain shown in fig. 3 (randomness = 1.0). Right: performance depending on how often agents arere-assigned identities randomly (sequence length 15). The higher the randomness, the less static the forcefield is and the more vital relational reasoning is. For randomness = 0.0, identities still have to be reassignedin some cases in order to prevent deadlocks, this leads to a performance loss for all models, which explainslower performance of self-attention for randomness = 0.0.
Figure 6: hart single object tracking applied four times in parallel and trained to predict the location ofeach circle three time steps into the future. Dashed lines indicate spatial attention, solid lines are predictedbounding boxes, faded circles show ground truth location at T + 3. Each circle exerts repulsive forces oneach other, where the force scales with 1/r, r being their distance.
Figure 7: Peeking into the future. Only the first two frames are shown to the tracking algorithm followedby three black frames. mohart learns to fall back on its internal motion model when no observation (i.e.
Figure 8: Tracking examples of both HART and MOHART. Coloured boxes are bounding boxes predictedby the model, arrows point at challenging aspects of the scenes. (A) & (C): Each person being trackedis temporarily occluded by a woman walking across the scene (blue arrows). mohart, which includes arelational reasoning module, handles this more robustly (compare red arrows).
Figure 9: Camera blackout experiment on a pedestrian street scene from the MOTChallenge dataset with-out ego-motion. Subsequent frames are displayed going from top left to bottom right. Shown are the inputsto the model (some of them being black frames, i.e. arrays of zeroes) and bounding boxes predicted byMOHART (coloured boxes). This scene is particularly challenging as occlusion and missing sensor inputcoincide (fourth row).
