Figure 1: Dirichlet distribution in 3 dimensions for different β values given a prediction of[0.25, 0.25, 0.50]This decomposition has a simple interpretation: While the output of the black-box classifier standsfor the mean, parameter β accounts for the spread of the distribution. The same or similar decompo-sition can be found in other works in a different context(Malinin & Gales, 2018)(Chen et al., 2018)4.
Figure 2: Model used to estimate the aleatoric uncertainty from the original black-box modelDense + reluDense + reluOriginal modelUncertainty WrapperBlack-box modelI DenSe + SOfPlUSDense + reluThis decoupling allows to effectively isolate the contribution of the black-box and the contributionthat remains to be computed, i.e. the value of parameter β. Figure 2 shows the integration ofthe wrapper (in light orange colour) with the black-box classifier (in light blue colour). Observethat the wrapper consists of two blocks: the Dirichlet reparameterization layer of the wrapper thatdecouples the influence of the black-box model from the rest (see the dashed line), and a deeplearning architecture which aims to compute the scalar value of β5.
Figure 3: Rejection performance metrics as proposed in (Condessa et al., 2015)nonrejected accuracy∣∕∩M~w~classification qualityμ∩jv∣ + ∣Λt∩π∣-Wl+ RI-rejection quality	.
Figure 4: Apply Yelp BB to SST-2Figure 5: Apply SST-2 BB to YelpFigure 8: Apply STL-10 BB to CIFAR10the predicted uncertainty focuses on intricate, ambiguous, or prone to error cases. We show resultsin NLP and computer vision domains with successful and encouraging results.
Figure 5: Apply SST-2 BB to YelpFigure 8: Apply STL-10 BB to CIFAR10the predicted uncertainty focuses on intricate, ambiguous, or prone to error cases. We show resultsin NLP and computer vision domains with successful and encouraging results.
Figure 8: Apply STL-10 BB to CIFAR10the predicted uncertainty focuses on intricate, ambiguous, or prone to error cases. We show resultsin NLP and computer vision domains with successful and encouraging results.
Figure 10: Distribution of the predicted entropies for two of the CIFAR10 classes.
Figure 11: Entropies for frogsIn figure 11 and 12, we can see the distributions of the images that belong to the frogs class andimages that belong to the trucks class. For the frogs class, we see that the values of uncertainty areconcentrated in the higher band of the diagram, whereas in the case of trucks, we find many withlower uncertainty. This detail shows that the metric assigns significant uncertainty to out-of-sampleclass points.
