Figure 1:	Experiments for verifying theory. Left: validation loss on DirectedSwimmer. Right:average return on NoisyCombinationLockPPO on DirectedSwimmer----baseline -一 1 expert ^—2 expert——4 expert----8 expert----16 expertFigure 2:	Experiments on policy Optimization with representation trained by imitation learning Left:average return on the DirectedSwimmer. Right: average return on the NoisyCombinationLock.
Figure 2:	Experiments on policy Optimization with representation trained by imitation learning Left:average return on the DirectedSwimmer. Right: average return on the NoisyCombinationLock.
Figure 3: The total rewards by different algorithms in DirectedSwimmer.
