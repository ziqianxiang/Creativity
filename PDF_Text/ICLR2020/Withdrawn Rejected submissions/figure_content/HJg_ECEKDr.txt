Figure 1:  (a) Generative Teaching Network (GTN) Method.  The numbers in the figure reflect theorder in which a GTN is executed. Noise is fed as an input to the Generator (1), which uses it to gen-erate new data (2). The learner is trained (e.g. using SGD or Adam) to perform well on the generateddata (3). The trained learner is then evaluated on the real training data in the outer-loop to computethe outer-loop meta-loss (4).  The gradients of the generator parameters are computed w.r.t. to themeta-loss to update the generator (5).  Both a learned curriculum and weight normalization sub-stantially improve GTN performance. (b) Weight normalization improves meta-gradient training ofGTNs, and makes the method much more robust to different hyperparameter settings. Each boxplotreports the final loss of 20 runs obtained during hyperparameter optimization with Bayesian Opti-mization (lower is better). (c) shows a comparison between GTNs with different types of curricula.
Figure 2:  Teaching MNIST with GTN-generated images.  (a) shows MNIST test set few-step ac-curacy across outer-loop iterations for different sources of inner-loop training data.  The inner-loopconsists of 32 SGD steps and the outer-loop optimizes MNIST validation accuracy.  Our method(GTN) outperforms the two controls (dataset distillation and samples from real data).  (b) shows,given final meta-training iteration, how iterations of inner-loop training compare between trainingdata sources (measured by MNIST training set accuracy).  (c) shows 100 random samples from thetrained GTN. Samples are usually recognizable as digits, but are not realistic (see Discussion). Eachcolumn contains samples from a different digit class, and each row is taken from different inner-loopiterations (evenly spaced from the 32 total iterations, with early iterations at the top).
Figure 3:  Teaching CIFAR10 with GTN-generated images.  (a) CIFAR10 training set performanceof the final learner (after 1,700 meta-optimization steps) across inner-loop learning iterations.  (b)Samples generated by GTN to teach CIFAR10 are unrecognizable, despite being effective for train-ing. Each column contains a different class, and each row is taken from the same inner-loop iteration(evenly spaced from all 128 iterations, early iterations at the top).  (c) Correlation between perfor-mance prediction using GTN-data vs. Real Data.  When considering the top half of architectures(as ranked by GTN evaluation), correlation between GTN evaluation and search evaluation is strong(0.5582 rank-correlation), suggesting that GTN-NAS has potential to uncover high performing ar-chitectures at a significantly lower cost. Architectures shown are uniformly sampled from the NASsearch space.  The top 10% of architectures according to the GTN evaluation (blue squares)– thoselikely to be selected by GTN-NAS–have high true asymptotic accuracy.
Figure 4: Comparison between a conditional generator and a generator that outputs an image/labelpair. We expected the latter “dark knowledge” approach to outperform the conditional generator, butthat does not seem to be the case. Because initialization and training of the dark knowledge variantwere more sensitive, we believe a more rigorous tuning of the process could lead to a different result.
Figure 5:  (a) The left figure shows that even though GTN was meta-trained to generate syntheticdata of batch size 128, sampling increasingly larger batches results in improved learner performance(the inner-loop optimization steps are fixed to 16).  (b) The right figure shows that increasing thenumber of inner-loop optimization steps (beyond the 16 steps used during meta-training) improveslearner performance. The performance gain with real data is larger in this setting. This improvementshows that GTNs do not overfit to a specific number of inner-loop optimization steps.
Figure 6: GTN samples w/o curriculum.
Figure 7: Performance of an ensemble of GTN learners vs. individual GTN learners. Ensembling aset of neural networks that each had different weight initializations, but were trained on data fromthe same GTN substantially improves performance.  This result provides more evidence that GTNsgenerate a healthy distribution of training data and are not somehow forcing the learners to all learna functionally equivalent solution.
Figure 8:  An A2C Agent control trains a single policy throughout all of training, while the GTNmethod starts with a new, randomly initialized network at each iteration and produces the plottedperformance after a single step of SGD. This plot is difficult to parse because of that difference:it compares the accumulated performance of A2C across all environment steps up to that point vs.
Figure 9:  Images generated by a basic GAN on MNIST before and after mode collapse.  Theleft image shows GAN-produced images early in GAN training and the right image shows GANsamples later in training after mode collapse has occurred due to training instabilities.
Figure 10:  Images generated by a GTN with an auxiliary GAN loss.  Combining GTNs withGANs produces far more realistic images than GTNs alone (which produced alien, unrecognizableimages, Figure 6). The combination also stabilizes GAN training, preventing mode collapse.
