Figure 1:	The Knossos MDP.
Figure 2:	Graph neural network3.1	SEARCHING THE SPACE OF REWRITES WITH A?We use the A? algorithm (Hart et al., 1968) both to train the compiler and to deploy it. A? maintainstwo priority queues. One queue (O) stores the frontier, i.e. states from which transitions have notbeen explored yet. The other one (C) stores the states visited so far and is used to avoid exploringthe same path twice. The states are explored in the order induced by the A? heuristic, which in ourcase corresponds to the learned value function V, obtained from previous iterations. In particular,node priority is set as follows:f (S) = f((es ,ts )) = V(S) + PH- ts-1 R(Si ,si+1).	â‘¶S--{Z-}	S---------{---------}s	c(s0)-c(s)Here, V(S) is the estimated future cost reduction obtained from state S within t remaining time-steps. The quantity c(S0) - c(S) corresponds to the cost reduction that has already been achieved bytime t, measured against the cost of the initial expression. Thus, f(S) is an estimate of the maximumpossible cost improvement from a trajectory passing through state S at time t.
Figure 3: Example of tricky optimisation task. Two expressions are similar but the optimal rewritestrategies are different.
Figure 5: Performance of Knossos on a set of arithmetic expressions. Horizontal axis shows epochs,vertical axis shows cost. Shaded area spans the 20% and 80% percentile over 10 repetitions.
Figure 4: General Matrix Mul-tiply (GEMM) program rewritesequence obtained by Knossos.
Figure 6: Performance of Knossos on basic linear algebra and convolutional network. Shaded areaindicates one standard deviation.
Figure 7: Comparison of wall time. Shaded area indicates one standard deviation.
Figure 8: Reverse mode of convolutional network rewrite sequence obtained by Knossos. The initialexpression was obtained from our rule-based ksc compiler and shown in the bottom left. The finalexpression was obtained after 32 rewriting steps and shown in the bottom right. The expression inthe bottom middle corresponds to the highest point in the cost sequence.
Figure 9: Comparison of A? search and Monte Carlo Tree Search.
Figure 10: List of expressions in training set for Linear Algebra Primitives.
Figure 11: Test expression for Linear Algebra Primitives (General Matrix Multiplication).
Figure 12:	List of expressions in train set for Convolutional Network.
Figure 13:	Test expression for Convolutional Network.
