Figure 1: Sensitivity s* of output fθ* (x) With respect to input dimensions Xi vs. the probability Pi(controlling correlation between input dimension i and target) for synthetic dataset A (Eq. 9). Leftplot shows θi (same as sensitivity) computed for a trained linear model. Right plot shows sensitivitycomputed for a trained MLP. IB regularization acts as a filter, suppressing the sensitivity of boththese models to weak correlation features (pi close to 0.5).
Figure 2: Sensitivity Si of output fθ* (x) with respect to input dimensions Xi vs. the probabilitypi (deciding the choice between feature with variance σ2 vs. 10σ2) for synthetic dataset B (Eq.
Figure 3: Performance on the distribution shifted test set of C-MNIST for various methods trained on C-MNIST training set.
Figure 4: Baseline methods severely overfit color features in the C-MNIST training set leading tonear 100% accuracy on C-MNIST validation set but close to chance performance on the distributionshifted C-MNIST test set.
Figure 5: Color MNIST training set (left) and out of distribution test set (right). Each class intraining set has two background colors and two foreground colors that are unique only to that class.
Figure 6: Random samples from MNIST (top), SVHN (middle) and MNIST-M (bottom) datasetsare shown to get a visual sense of the hardness of the out of distribution task.
Figure 7: Batch Normalization is unstable without AdaBN when using Entropy Penalty (experimenton C-MNIST dataset).
