Figure 1: Sample figure caption.
Figure 2: Test loss different training set sizesFinBERT outperforms ULMFit, and consequently all of the other methods in all metrics. In order tomeasure the performance of the models on different sizes of labeled training datasets, we ran LSTMclassifiers, ULMFit and FinBERT on 5 different configurations. The result can be seen on figure2, where the cross entropy losses on test set for each model are drawn. 100 training examples istoo low for all of the models. However, once the training size becomes 250, ULMFit and FinBERTstarts to successfully differentiate between labels, with an accuracy as high as 80% for FinBERT.
Figure 3: Validation loss trajectories with different training strategiesApplying all three of the strategies produce the best performance in terms of test loss and accuracy.
