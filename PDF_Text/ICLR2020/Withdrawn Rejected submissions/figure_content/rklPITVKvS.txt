Figure 1: Visualization of the gradient of DCGAN discriminator with respect to input images. Thefirst row shows samples from CelebA dataset. The second row and third row show gradients ofadversarially symmetrically trained discriminator and standard discriminator, respectively. We clipgradient to within ± 3 standard deviations of their mean and take the average absolute value of threechannels for easy visualization. We can see that adversarially trained discriminator can provide moreinformative gradient with less adversarial noise pattern, which can stabilize GAN training.
Figure 2: Schematic of proposed AS-GAN. Standard GAN training is illustrated as the first forwardpass and the first backward pass. In addition to standard GAN training procedure, we introduceadversarial training of discriminator on real samples, illustrated as the second forward pass and thesecond backward pass, which is equivalent to train discriminator with robust optimization.
Figure 3: (a) Best FID results under different settings of three independent runs (Lower is better).
Figure 4: Training curves of FID on CIAFR-10 (upper) and CelebA (lower) with DCGAN (left)and ResNet (right). Results show that the proposed method can accelerate convergence and achievebetter FID. Meanwhile, it can stabilize training with less sensitivity to network architecture andhyper-parameter setting.
Figure 6: (a) Confidence of discriminator on real data and adversarial samples of real data duringtraining. (b) Evolution of discriminator loss at different settings.
Figure 7: (a) Training curves of inception score with different methods. (b) Training curves of FIDwith different methods. With the increasing of iterations, our algorithm (ε = 1/255) convergesfaster and better than other models.
Figure 8: (a): 32 x 32 CIFAR-10 samples generated by AS-ResNet. (b): 64 x 64 CelebA samplesgenerated by AS-ResNet. We believe these samples are at least comparable to the best publishedresults so far.
Figure 9: (a): Interpolation results(a)on CIFAR-10. (b): Interpolation results fromAS-ResNet on CelebA.
Figure 10: (a): 64 x 64 results from AS-DCGAN on bedroom in LSUN. (b): 64 x 64 results fromunsupervised AS-DCGAN on ImageNet.
Figure 12: (a): Collapsed samples generated by standard GAN trained on CelebA. (b): Samplesgenerated by AS-ResNet trained on CelebA.
Figure 13: (a): Collapsed samples generated by standard GAN trained on CIFAR-10. (b): Samplesgenerated by AS-ResNet trained on CIFAR-10.
Figure 14: Benign samples (on odd rows) and adversarial samples of standard discriminator (oneven rows). Confidence is depicted at corner. Standard discriminator is extremely vulnerable toimperceptible perturbation. The pertubation level is 1/255.
Figure 15: Benign samples (on odd rows) and adversarial samples of discriminator adversariallytrained on real data (on even rows). Confidence is depicted at corner. After adversarial trainingon real samples, discriminator is more robust to adversarial perturbation. The pertubation level is1/255.
