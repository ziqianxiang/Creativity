Figure 1: Clean accuracy, maximum rate loWer bound RX ≤ I(Z; X) seen during training, androbustness to targeted PGD L2 and L∞ attacks on CEB, VIB, and Deterministic models trained onFashion MNIST. We can see that at any given value ofρ, the CEB models dominate the VIB modelson both accuracy and robustness, While having essentially identical maximum rates. None of thesemodels are adversarially trained.
Figure 2: CEB ρ vs. test set accuracy, and L2 and L∞ PGD adversarial attacks on CIFAR-10. Theattack parameters were selected to be about equally difficult for the adversarially-trained WRN 28×10model from Madry et al. (2017) (grey dashed and dotted lines). The deterministic baseline (Det.)only gets 8% accuracy on the L∞ attacks, but gets 66% on the L2 attack, substantially better thanthe 45.7% of the adversarially-trained model, which makes it clear that the adversarially-trainedmodel failed to generalize in any reasonable way to the L2 attack. The CEB models are alwayssubstantially more robust than Det., and many of them outperform Madry even on the L∞ attackthe Madry model was trained on, but for both attacks there is a clear general trend toward morerobustness as ρ decreases. Finally, the CEB and Det. models all reach about the same accuracy,ranging from 93.9% to 95.1%, with Det. at 94.4%. In comparison, Madry only gets 87.3%. Weemphasize that none of the CEB models is adversarially trained.
Figure 3: Untargeted adversarial attacks on small and large CIFAR-10 models showing both strongrobustness to PGD L2 and L∞ attacks, as well as excellent test accuracy of 97.5%. Left: Accuracyon untargeted L∞ attacks at different values of ε for all 10,000 test set examples. 28×10 and62 × 7 indicate the Wide ResNet size. CEBx indicates a CEB model trained at ρ = x. Madry isthe adversarially-trained model from Madry et al. (2017) (values provided by Aleksander Madry).
Figure 4:	Summary of the ImageNet- C experiments. In the main part of the figure (in blue),the average errors (lower is better) across corruption magnitude are shown for 33 different net-works for each of the labeled Common Corruptions (Hendrycks & Dietterich, 2019), ImageNet-A (Hendrycks et al., 2019), and targeted PGD attacks (Madry et al., 2017). The networks comein pairs, with the vertical lines denoting the baseline network’s performance and then in the cor-responding color the errors for each of 10 different CEB trained networks are shown with varyingρ = [1, 2, . . . , 10], arranged from 10 at the top to 1 at the bottom. The light blue lines denote abaseline ResNet-50 model trained without AutoAug. The blue lines show the same network(and baseline) but with AutoAug. The dark blue lines show ResNet-50 AutoAug networks thatwere made twice as wide. In this way we can separately see the effect of both data augmentationand enlarging the model, as well as the additive effect of CEB on each model. At the top in red areshown the same data for three summary statistics. clean denotes the clean errors of each of thenetworks. mCE denotes the AlexNet regularized average corruption errors. avg shows an equallyweighted average across all common corruptions. The dots denote the value for each CEB networkand each corruption at ρ*, the optimum P for the network as measured in terms of clean accuracy.
Figure 5:	Replication of Figure 4 but for ResNet- 1 52. The deeper model shows marked improve-ment across the board. Notice in particular the adversarial robustness to L∞ and L2 PGD attacks forthe CEB models over the deterministic baselines.
