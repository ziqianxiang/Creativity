Figure 1: Depicting two clusters (low-risk and high-risk; as shown by the true lifetime distributions) followingdifferent RMPPs, each with two subjects. T(u) is the true lifetime of subject u (may be unobserved due to rightcensoring or due to unobservability of termination signals). H(u) is her observed lifetime, the period betweenthe first and the last observed event. χ(u) is the time between the last observed event and tm, and Q(u) (tm) is thenumber of events of u after her joining and before tm .
Figure 2: (a) Feedforward neural network g(; W1) outputs the cluster assignments for a batch of users. Thecluster assignments along with the probability of termination is used to obtain lifetime distributions of eachcluster using Kaplan-Meier estimator. Finally, logarithm of Kuiper p-value upper bound is used as the divergenceloss ∆. (b) Lifetime distributions can have different shapes and can cross each other, violating proportionalhazards assumptions. (c) Divergence metric must account for the uncertainty in the distributions, otherwisedivergence maximization leads to imbalanced clusters. (d-e) Upper and lower bounds of the logarithm of Kuiperp-value when varying the Kuiper statistic D++D-.
Figure 3: (Friendster) Empirical lifetime distributions of clusters obtained from different methods for K=3(legend shows cluster sizes n1 , n2 , n3). Baseline methods (a-c) employ a two-stage clustering process anddo not guarantee clusters with maximally different lifetime distributions. (d) DeepCLife-MMD suffers fromsample anomalies (n2 = 0). (e) DeepCLife-KuiperUB obtains clusters with significantly different lifetimedistributions (best Logrank scores).
Figure 4: (MIMIC III) (a) Empirical lifetime distributions obtained by DeepCLife-KuiperUB for K = 2.
Figure 6: (Friendster) Empirical lifetime distributions of clusters obtained from different methods for K=3(legend shows cluster sizes n1 , n2 , n3).
Figure 7: (Friendster) Empirical lifetime distributions of clusters obtained from different methods for K=4(legend shows cluster sizes).
Figure 8: (Friendster) Empirical lifetime distributions of clusters obtained from different methods for K=5(legend shows cluster sizes).
Figure 9: (MIMIC III) Empirical lifetime distributions of clusters obtained from DeepCLife-KuiperUB withK=2 . . . 6 (legend shows cluster sizes).
Figure 10: (Friendster) Logrank scores (error bars denote standard errors) on a held-out validationset for the clusters obtained from DeepCLife-KuiperUB with different values of K. K = 4 seemsto give the best mean performance, while K = 5 is close behind; increasing K further drasticallyreduces the Logrank score.
Figure 11: (MIMIC III) Logrank scores (error bars denote standard errors) on a held-out validationset for the clusters obtained from DeepCLife-KuiperUB with different values of K . K = 6 givesthe best Logrank performance. However, Logrank scores for K = 2 to K = 5 do not increasesignificantly; suggesting K = 2 could be a good choice as well.
Figure 12: (Friendster) Clusters found by the proposed approach with K = 4 when maximizing theminimum divergence (left) vs maximizing the sum of divergences (right).
Figure 13: (Toy) True lifetime distributions of simulated clusters (with tm = 150).
