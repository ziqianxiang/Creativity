Figure 1: Efference copy diagram (Gwijde, 2018). A motor command, or efference, isissued by the CNS. A copy of the efference is made and is sent to an internal forwardmodel, which predicts the sensory result of the efference. The original efference is sent tothe motor system to act. The consequence of the action in the world is observed by thesensory system, and a reafference is created and sent to the CNS. The forward model isthen updated to minimize the discrepancy between predicted and actual reafference.
Figure 2: EfferenceNet architecture. The network takes as input the representation vectorφ(St) of the state St as determined by the feature map φ, as well as the one-hot encodedaction a. It outputs the estimated feature vector of the resulting state St+1 after action a isperformed.
Figure 3: Viewpoint matching task on unseen objects. Only the start and goal states are given.
Figure 4: The three-dimensional Laplacian Eigenmaps of a toy car with azimuth (top) or elevation(bottom) colored in. Euclidean distance is a good proxy for geodesic distance in this case.
Figure 5: Viewpoint matching task as before, based on a Laplacian Eigenmap representation. Thesearch algorithm can rely on an almost monotonously increasing similarity between prediction andtarget to guide its search.
Figure 6: Histograms of distance between goal and solution states along elevation (left) and azimuth(right) on test data. The distance between the start and goal viewpoints is equally distributed acrossall the trials, along both dimensions. The goal and the 180。flipped (azimuth) version of the goal areattractor states.
Figure 7: Aggregate heat maps of representation similarities on test data. The data iscollected as the state space is searched for a matching viewpoint. The pixels are arrangedaccording to their elevation and azimuth difference from the goal state. (a) We see cleargradients towards the two basins of attraction. The change is noticably less along theelevation due to less change at each step. (b) The agent can also alter the lighting ofthe scene, with qualitatively similar results. In this graphic we only measure the absolutevalue of the distance.
