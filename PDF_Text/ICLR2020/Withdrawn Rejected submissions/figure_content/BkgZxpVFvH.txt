Figure 1: The architecture of LSTOD consisting of (C1) ST-Conv blocks, (C2) TGCNN, (C3) VACN, and (C4) attention.
Figure 2: An example to show howstandard CNN fails to capture thenetwork structure of OD flows3.1	Spatial Adjacent Convolution NetworkBefore introducing the detailed architecture of VACN, we want to discuss why directly applyingstandard CNNs to the OD flow map Od,t may disregard the connections between neighboring ODflows in the graph space first. Figure 2 demonstrates that it fails to capture enough semantic infor-mation using the real-world example of ride demands. For the OD flow starting from v1 to v2 , asillustrated in the upper sub-figure, the most related OD flows should be those with either origin ordestination being v1 or v2 in the past few timestamps. A certain part of the travel requests from v1 tov2 can be matched with some historical finished trips from a third-party location to V1 by the samegroup of people, for example a trip from v3 to v1 . However, as the lower-left sub-figure illustrates,some of the OD flows covered by a single CNN filter (the green square) such as the four corners ofthe kernel window may be topologically far away from the target one in the graph.
Figure 3: Day-wise RMSE comparison between variedSTOD modelsFigure 4: RMSE on testing data with re-spect to ACN and standard CNN usingdifferent kernel sizes.
Figure 4: RMSE on testing data with re-spect to ACN and standard CNN usingdifferent kernel sizes.
Figure 5: Working mechanism of spatial adjacent convolution network (VACN) for a target OD flowfrom vi to vjC	Training DetailsBatch normalization is used in the VACN component. The batch size in our experiment was set to10, corresponding to 10 randomly sampled timestamps and all the 502 OD flows in each snapshot.
Figure 6: RMSE on testing data with respect to STOD with different p1 and p2 combinations.
