Figure 1: The partition of a networkwith neuronal sparsity into active (blue),inactive (grey) and interference (red)parts.
Figure 2: Middle: A network with neuronal sparsity. Left, right: the multi-head and single-head expansions.
Figure 3: Cartoon of sparsification hyper-parameter search. Each circular node corre-sponds to a model trained with a different pre-training hyperparameter. The green circles arethe models within m% of the best validationaccuracy. The dashed lines and green squaresdenote the trajectory and final end-point of thevalidation/sparsity of the model as the pruningthreshold Î¸ is increased. The model with thehighest sparsity is then chosen.
Figure 4: CIFAR-10 and split CIFAR-100 results on multi-head network. (a) Final validation accuracy after alltasks are trained. The red dashed bars on task 5 and 6 denote that the network ran out of capacity after trainingtask 4. At this point the performance of the network suffers as can be seen in comparison to other methods.(b)Percentage of the capacity of each layer used after the training of each task.
Figure 5: CIFAR-10 and split CIFAR-100 results on Wide single-head network. (a) Final test accuracy after alltasks are trained. The orange dashed bar on task 10 denotes that the network ran out of capacity after training task 9.
