Figure 1: We train predictive agents to explore a visually-rich 3D environment with an assortment of objects ofdifferent shapes, colors and sizes. As the agent navigates (trajectory shown in white on the top-down map), itcontains an auxiliary network that learns to simulate representations of future observations (labeled ‘SimulationNetwork’) say k steps into the future self-supervised by a loss on the agent’s future prediction against theground-truth egocentric observation at t ` k. Simultaneously, another decoder network is trained to extractanswers to a variety of questions about the environment, conditioned on the agent’s internal memory but withoutaffecting it (notice 'stop gradient' 一 gradients from the QA decoder are not backpropagated into the agent). Weuse this question-answering paradigm to decode and understand the internal representations that such agentsdevelop. Note that the top-down map is only shown for illustration purposes and not available to the agent.
Figure 2: Overview of our approach: at every timestep t, the agent receives an RGB observation xt as input,processes it using a convolutional neural network to produce zt , which is then processed by an LSTM to selectaction at. The agent is learning to explore - it receives a reward of 1.0 for navigating to each object in theenvironment. As it explores the environment, it builds up an internal representation ht , which receives pressurefrom an auxiliary predictive module to capture environment semantics so as to accurately predict consequencesof its actions multiple steps into the future. We experiment with a vanilla LSTM agent and two recent predictiveapproaches - action-conditional CPC (Guo et al., 2018) and SimCore (Gregor et al., 2019). The learnt internalrepresentations are then analyzed via a question-answering decoder whose gradients are not backpropagated tothe agent core. The QA decoder is an LSTM initialized with ht and receiving the question at every timestep.
Figure 3: L- Reward in an episode. R - Top-1 QA accuracy. Averaged over 3 seeds. Shaded region is 1 SD.
Figure 6: Answer accuracy over training for increasing QA decoder’s depths. Left subplot shows the results forthe SimCore agent and right subplot for the LSTM baseline. For SimCore, the QA accuracy increases with thedecoder depth, up to 12 layers. For the LSTM agent, QA accuracy is not better than chance regardless of thecapacity of the QA network.
Figure 7: QA accuracy over training for all questions and all models.
