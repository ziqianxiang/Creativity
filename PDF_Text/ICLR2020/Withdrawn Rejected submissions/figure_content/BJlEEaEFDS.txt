Figure 1: Comparison of mini-batch mean and variance at the start of the training with tracked mean andvariance which are used at inference for all the channels. Note the difference between both of these values.
Figure 2: Comparison of adversarial robustness of different normalizations for different Whitebox attackswith CIFAR100. Results are shown with 95% confidence interval computed over 5 random restarts. Batch-Norm w/o Tracking and RobustNorm have significantly higher adversarial robustness compared to othernorms. The results are even more clear when they are adversarially trained where RobustNorm’s robustnessis even more than BatchNorm w/o Tracking.
Figure 3: Comparison of evolution of validation loss and accuracy for CIFAR100 on Resnet20 with confi-dence intervals calculated with 5 random restarts. BatchNorm without tracking and RobustNorm have higheraccuracy and lower loss while RobustNorm being better than BatchNorm w/o tracking. For further details,please have a look at appendix B4.1	Resistance for different values of Adversarial PerturbnessTo further understand the performance of RobustNorm under adversarial conditions, we run an experimentwhere values are increased for the test set. We train networks with BatchNorm, BatchNorm w/o Trackingand RobustNorm with Natural as well as PGD-'∞ based adversarial training and tested them on differentvalues of . The results are shown in Figure 4. As increases, the robustness of neural network decreasesbut the robustness of neural network with RobustNorm is much higher than BatchNorm while also higherthan BatchNorm w/o tracking. To see the effect of an increase in adversarial noise on CIFAR100 dataset,see Figure 6 in the appendix.
Figure 4: Comparison of robust accuracy as e(adverSarial noise power) increases. Values are calculated forCIFAR10 with 3 random restarts and confidence interval of 95%. Robustness of RN is higher than bothBatchNorm and BatchNorm without tracking. While BatchNomr with and without tracking collapses withhigher epsilon BIM, RobustNorm,s accuracy is much higher. For same curves on CIFAR10, see appendixfor more details.
Figure 5: Effect of using very small inference time batch size on different norms. Part(a) shows results fornatural training while part(b) shows results for adversarial trained networks.
Figure 6: Figure shows effect of increase in adversarial noise e on three normalizatons for CIFAR100 dataset.
Figure 7: Comparison of BatchNorm with RobustNorm in terms of accuracy when tracking is used. Both ofthese norms have very similar clean accuracy despite RobustNorm being different in terms of ICS hypothesis.
Figure 8: Training and validation loss and accuracy evolution for adversarial training. Interestingly, Batch-Norm’s training loss decreases normally, its validation loss has lot more uncertainty and either remainingsame or start increasing. This way, BatchNorm is overfitting. A similar trend is also shown by RobustNormwhen tracking is used thought it vanishes when remove tracking and decrease in loss becomes normal andless uncertain.
Figure 9: Plots of loss landscape (Li et al., 2018a) of Resnet20 trained with different norms. Right columnshows Resnet20 trained on natural images while left column shows adversarially trained. Note that networkwithout tracking (9c, 9d, 9e, 9f) tends to have sharp minima.
Figure 10: Comparison of effect of hyperparameter P on clean accuracy for both adversarially trained andnaturally trained Resnet20 with RobustNorm with and without tracking.
Figure 11: Comparison of effect of hyperparameter P on clean accuracy.
