Figure 1: The distribution of weights in the first convolutional layer in discriminator (D) and the lastconvolutional layer in generator (G). (a) and (e) show original weight distributions in full precision,(b) and (f) use the Minmax-Q quantization, (c) and (g) use the Log-Q quantization, (d) and (h) use theTanh-Q quantization. The model here is DCGAN trained on CIFAR-10 dataset, and all quantizationschemes quantize full precision data to 2 bits.
Figure 2: The training curves of DCGAN using logarithmic minmax quantization in different bits.
Figure 3:	The distribution of weights in quantized DCGAN using 2-bit QGAN.
Figure 4:	The IS of quantized DCGANs in different bits using different methods on CIFAR-10.
Figure 5: The generated samples of various GAN models on CIFAR-10 dataset and DCGAN onCelebA dataset using QGAN. The kDjG denotes k-bit D and j -bit G.
