Figure 1: (a) General structure of an unfolded deep RNN (b) Detail of the gradient backpropagationin the two dimensional lattice.
Figure 2: Mean value of gradient magnitude with respect to the parameters for different RNN units.
Figure 3: Gradient magnitudes in pix-by-pix MNIST. (a) Mean gradient norm per layer at the startof training. (b) Evolution of gradient norm during 1st training epoch. (c) Loss during 1st epoch.
Figure 4: Results for pixel-by-pixel MNIST tasks.
Figure 5: Time series classification. (a,b) Crop classes. (c) Hand gestures (convolutional RNNs).
Figure 6: Mean gradient magnitude w.r.t. the parameters for LSTM with only forget gate, GRU,and the proposed STAR cell. top row: loss L(hTL) only on final prediction. bottom row: lossL(h1L . . . hTL) over all time steps.
Figure 7: Mean-normalised standard deviation of gradient magnitude for LSTM with only forgetgate, GRU, and the proposed STAR cell. top row: loss L(hTL) only on final prediction. bottom row:loss L(h1L . . . hTL) over all time steps.
