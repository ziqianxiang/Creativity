Under review as a conference paper at ICLR 2020
DP-LSSGD: An Optimization Method to Lift
the Utility in Privacy-Preserving ERM
Anonymous authors
Paper under double-blind review
Ab stract
Machine learning (ML) models trained by differentially private stochastic gradient
descent (DP-SGD) have much lower utility than the non-private ones. To mitigate
this degradation, we propose a DP Laplacian smoothing SGD (DP-LSSGD) to
train ML models with differential privacy (DP) guarantees. At the core of DP-
LSSGD is the Laplacian smoothing, which smooths out the Gaussian noise used
in the Gaussian mechanism. Under the same amount of noise used in the Gaus-
sian mechanism, DP-LSSGD attains the same DP guarantee, but in practice, DP-
LSSGD makes training both convex and nonconvex ML models more stable and
enables the trained models to generalize better. The proposed algorithm is sim-
ple to implement and the extra computational complexity and memory overhead
compared with DP-SGD are negligible. DP-LSSGD is applicable to train a large
variety of ML models, including DNNs.
1 Introduction
Many released machine learning (ML) models are trained on sensitive data that are often crowd-
sourced or contain private information (Yuen et al., 2011; Feng et al., 2017; Liu et al., 2017). With
overparameterization, deep neural nets (DNNs) can memorize the private training data, and it is pos-
sible to recover them and break the privacy by attacking the released models (Shokri et al., 2017).
For example, Fredrikson et al. demonstrated that a model-inversion attack can recover training im-
ages from a facial recognition system (Fredrikson et al., 2015). Protecting the private data is one of
the most critical tasks in ML.
Differential privacy (DP) (Dwork et al., 2006) is a theoretically rigorous tool for designing algo-
rithms on aggregated databases with a privacy guarantee. The idea is to add a certain amount of
noise to randomize the output of a given algorithm such that the attackers cannot distinguish outputs
of any two adjacent input datasets that differ in only one entry.
For repeated applications of additive noise based mechanisms, many tools have been invented to
analyze the DP guarantee for the model obtained at the final stage. These include the basic and
strong composition theorems and their refinements (Dwork et al., 2006; 2010; Kairouz et al., 2015),
the moments accountant (Abadi et al., 2016), etc. Beyond the original notion of DP, there are
also many other ways to define the privacy, e.g., local DP (Duchi et al., 2014), concentrated/zero-
concentrated DP (DWork & Rothblum, 2016; BUn & Steinke, 2016), and Renyi-DP (RDP) (Mironov,
2017).
Differentially private stochastic gradient descent (DP-SGD) reduces the utility of the trained models
severely compared With SGD. As shoWn in Figure 1, the training and validation losses of the logistic
regression on the MNIST dataset increase rapidly When the DP guarantee becomes stronger. The
convolutional neural net (CNN) 1 trained by DP-SGD has much loWer testing accuracy than the
non-private one on the MNIST. We Will discuss the detailed experimental settings in Section 4. A
natural question raised from such performance degradations is:
Can we improve DP-SGD, with negligible extra computational complexity and memory cost, such
that it can be used to train general ML models with improved utility?
1github.com/tensorflow/privacy/blob/master/tutorials/mnist_dpsgd_
tutorial.py
1
Under review as a conference paper at ICLR 2020
Iteration
Iteration
Figure 1: Training (left) and validation (middle) losses of the logistic regression on the MNIST
trained by DP-SGD with (, δ = 10-5)-DP guarantee. (right): testing accuracy of a simple CNN on
the MNIST trained by DP-SGD with (, δ = 10-5)-DP guarantee.
We answer the above question affirmatively by proposing differentially private Laplacian smoothing
SGD (DP-LSSGD) to improve the utility in privacy-preserving empirical risk minimization (ERM).
DP-LSSGD leverages the Laplacian smoothing (Osher et al., 2018) as a post-processing to smooth
the injected Gaussian noise in the differentially private SGD (DP-SGD) to improve the convergence
of DP-SGD in training ML models with DP guarantee.
1.1	Our Contributions
The main contributions of our work are highlighted as follows:
•	We propose DP-LSSGD and prove its privacy and utility guarantees for convex/nonconvex op-
timizations. We prove that under the same privacy budget, DP-LSSGD achieves better utility,
excluding a small term that is usually dominated by the other terms, than DP-SGD by a factor that
is much less than one for convex optimization.
•	We perform a large number of experiments logistic regression and CNN to verify the utility im-
provement by using DP-LSSGD. Numerical results show that DP-LSSGD remarkably reduces
training and validation losses and improves the generalization of the trained private models.
In Table 1, we compare the privacy and utility guarantees of DP-LSSGD and DP-SGD. For the
utility, the notation O(∙) hides the same constant and log factors for each bound. The constants d and
n denote the dimension of the model’s parameters and the number of training points, respectively.
The numbers γ and β are positive constants that are strictly less than one, and D0, Dσ, G are positive
constants, which will be defined in Section 3.
Table 1: Utility and Differential Privacy Guarantees.
Algorithm	DP	Assumption	Utility	Measurement	Reference
DP-SGD	(, δ)	convex	O √ √(Do+G2)d O 1 -(ɪn)	)	optimality gap	Bassily et al. (2014)
DP-SGD	(, δ)	nonconvex	O (√d∕(en))	`2 -norm of gradient	Zhang et al. (2017)
DP-LSSGD	(, δ)	convex	O √ √Y(Db +G2)d O ∖	(InF	optimality gap	This Work
DP-LSSGD	(, δ)	nonconvex	O (√W(en)) 1	`2 -norm of gradient	This Work
1 Measured in the norm induced by Aσ-1, we will discuss this in detail in Section 4.
1.2	Related Work
There is a massive volume of research over the past decade on designing algorithms for privacy-
preserving ML. Objective perturbation, output perturbation, and gradient perturbation are the three
major approaches to perform ERM with a DP guarantee. Chaudhuri & Monteleoni (2008); Chaud-
huri et al. (2011) considered both output and objective perturbations for privacy-preserving ERM,
and gave theoretical guarantees for both privacy and utility for logistic regression and SVM. Song
et al. (2013) numerically studied the effects of learning rate and batch size in DP-ERM. Wang et al.
(2016) studied stability, learnability and other properties of DP-ERM. Lee & Kifer (2018) proposed
an adaptive per-iteration privacy budget in concentrated DP gradient descent. Variance reduction
2
Under review as a conference paper at ICLR 2020
techniques, e.g., SVRG, have also been introduced to DP-ERM (Wang et al., 2017). The utility
bound of DP-SGD has also been analyzed for both convex and nonconvex smooth objectives (Bass-
ily et al., 2014; Zhang et al., 2017; Wang et al., 2019). Jayaraman et al. (2018) analyzed the excess
empirical risk of DP-ERM in a distributed setting. Besides ERM, many other ML models have been
made differentially private. These include: clustering (Su et al., 2015; Y. Wang & Singh, 2015;
Balcan et al., 2017), matrix completion (Jain et al., 2018), online learning (Jain et al., 2012), sparse
learning (Talwar et al., 2015; Wang & Gu, 2019), and topic modeling (Park et al., 2016). Gilbert
& McMillan (2017) exploited the ill-conditionedness of inverse problems to design algorithms to
release differentially private measurements of the physical system. Wang & Xu (2019) considered
sparse linear regression in the local DP models.
Shokri & Shmatikov (2015) proposed distributed selective SGD to train deep neural nets (DNNs)
with a DP guarantee in a distributed system, however, the obtained privacy guarantee was very
loose. Abadi et al. (2016) considered applying DP-SGD to train DNNs in a centralized setting.
They clipped the gradient `2 norm to bound the sensitivity and invented the moment accountant to
get better privacy loss estimation. Papernot et al. (2017) proposed Private Aggregation of Teacher
Ensembles/PATE based on the semi-supervised transfer learning to train DNNs, and this framework
improves both privacy and utility on top of the work by Abadi et al. (2016). Recently Papernot et al.
(2018) introduced new noisy aggregation mechanisms for teacher ensembles that enable a tighter
theoretical DP guarantee. The modified PATE is scalable to the large dataset and applicable to more
diversified ML tasks.
Laplacian smoothing (LS) can be regarded as a denoising technique that performs post-processing
on the Gaussian noise injected stochastic gradient. Denoising has been used in the DP earlier: Post-
processing can enforce consistency of contingency table releases (Barak et al., 2007) and leads to
accurate estimation of the degree distribution of private network (Hay et al., 2009). Nikolov et al.
(2013) showed that post-processing by projecting linear regression solutions, when the ground truth
solution is sparse, to a given 'ι-ball can remarkably reduce the estimation error. Bemstein et al.
(2017) used Expectation-Maximization to denoise a class of graphical models’ parameters. Balle &
Wang (2018) showed that in the output perturbation based differentially private algorithm design,
denoising dramatically improves the accuracy of the Gaussian mechanism in the high-dimensional
regime. To the best of our knowledge, we are the first to design a denoising technique on the
Gaussian noise injected gradient to improve the utility of the trained private ML models.
1.3	Notation
We use boldface upper-case letters A, B to denote matrices and boldface lower-case letters x, y
to denote vectors. For vectors x and y and positive definite matrix A, we use kxk2 and kxkA to
denote the '2-norm and the induced norm by A, respectively;hx, y〉denotes the inner product of X
and y; and λi(A) denotes the i-th largest eigenvalue of A. We denote the set of numbers from 1 to
n by [n]. N (0, Id×d) represents d-dimensional standard Gaussian.
1.4	Organization
This paper is organized in the following way: In Section 2, we introduce the DP-LSSGD algorithm.
In Section 3, we analyze the privacy and utility guarantees of DP-LSSGD for both convex and
nonconvex optimizations. We numerically verify the efficiency of DP-LSSGD in Section 4. We
conclude this work and point out some future directions in Section 5.
2 Problem Setup and Algorithm
2.1	Laplacian Smoothing Stochastic Gradient Descent (LSSGD)
In this paper, we consider empirical risk minimization problem as follows. Given a training set
S = {(x1, y1), . . . , (xn, yn)} drawn from some unknown but fixed distribution, we aim to find an
empirical risk minimizer that minimizes the empirical risk as follows,
1n
min F (w) := _£fi(w)，W ∈ Rd，
wn
(1)
i=1
3
Under review as a conference paper at ICLR 2020
where F (w) is the empirical risk (a.k.a., training loss), fi (w) = `(w; xi, yi) is the loss function of
a given ML model defined on the i-th training example (xi , yi), and w ∈ Rd is the model parameter
we want to learn. Empirical risk minimization serves as the mathematical foundation for training
many ML models that are mentioned above. The LSSGD (Osher et al., 2018) for solving (1) is given
by
wk+1= Wk-ηA-1 (1 X Vfik(Wk)),	(2)
ik∈Bk
where η is the learning rate, Vfik denotes the stochastic gradient of F evaluated from the pair of
input-output {xik, yik}, and Bk is a random subset of size b from [n]. Let Aσ = I - σL for σ ≥ 0
being a constant, where I ∈ Rd×d and L ∈ Rd×d are the identity and the discrete one-dimensional
Laplacian matrix with periodic boundary condition, respectively. Therefore,
	1 + 2σ	-σ	0	...	0	-σ	
	-σ	1 + 2σ	-σ . . .	0	0	
Aσ :=	0	-σ	1 + 2σ	. . .	0	0	⑶
	... -σ	... 0	...	... 0	...	... -σ	... 1 + 2σ	
When σ = 0, LSSGD reduces to SGD.
Note that Aσ is positive definite with condition number 1 + 4σ that is independent of Aσ's di-
mension, and LSSGD guarantees the same convergence rate as SGD in both convex and noncon-
vex optimization. Moreover, Laplacian smoothing (LS) can reduce the variance of SGD on-the-
fly, and lead to better generalization in training many ML models including DNNs (Osher et al.,
2018). For v ∈ Rd, let u := Aσ-1v, i.e., v = Aσu. Note Aσ is a convolution matrix, therefore,
V = AσU = U — σd * u, where d = [-2,1,0, ∙∙∙ , 0,1]T and * is the convolution operator. By the
fast Fourier transform (FFT), we have
A-Iv = u = ifft(fft(v)∕(1 - σ ∙ fft(d))),
where the division in the right hand side parentheses is performed in a coordinate wise way.
2.2	DP-LSSGD
DP ERM aims to learn a DP model, W, for the problem (1). A common approach is injecting
Gaussian noise into the stochastic gradient, and it resulting in the following DP-SGD
Wk+1= Wk - η (1 X Vfik (wk) + n) ,	(4)
ik∈Bk
where n is the injected Gaussian noise for DP guarantee. Note that the LS matrix Aσ-1 can remove
the noise in v. If we assume v is the initial signal, then Aσ-1v can be regarded as performing an
approximate diffusion step on the initial noisy signal which removes the noise from v. We will
provide a detailed argument for the diffusion process in the appendix. As numerical illustrations, we
consider the following two signals:
•	1D: vι = {sin(2iπ∕100)+0.lN(0,1)|i = 1, 2,…，100}.
•	2D: v2 = {sin(2iπ∕100) sin(2jπ∕100) + 0.2N(0, I2×2)∣i,j = 1, 2,…,100}.
We reshape v2 into 1D with row-major ordering and then perform LS. Figure 2 shows that LS can
remove noise efficiently. This noise removal property enables LSSGD to be more stable to the noise
injected stochastic gradient, therefore improves training DP models with gradient perturbations.
We propose the following DP-LSSGD for solving (1) with DP guarantee
Wk+1= Wk -IIA- (1 X Vfik (Wk) + n).	(5)
ik∈Bk
In this scheme, we first inject the noise n to the stochastic gradient Vfik (Wk), and then apply the
LS operator Aσ-1 to denoise the noisy stochastic gradient, Vfik (Wk) + n, on-the-fly. We assume
that each component function fi in (1) is G-Lipschitz. The DP-LSSGD for finite-sum optimization
is summarized in Algorithm 1. Compared with LSSGD, the main difference of DP-LSSGD lies in
injecting Gaussian noise into the stochastic gradient, before applying the Laplacian smoothing, to
guarantee the DP.
4
Under review as a conference paper at ICLR 2020
20
40
60
80
100
20	60	100
20
40
60
80
100
20	60	100
20
40
60
80
100
20	60	100
(a)	(b)	(c)	(d)
Figure 2: Illustration of LS (σ = 10 for v1 and σ = 100 for v2). (a): 1D signal sampled uniformly
from sin(x) for x ∈ [0, 2π]. (b), (c), (d): 2D original, noisy, and Laplacian Smoothed noisy signals
sampled uniformly from sin(x) sin(y) for (x, y) ∈ [0, 2π] × [0, 2π].
Algorithm 1 DP-LSSGD
Input: fi(w) is G-LiPschitz for i = 1, 2,…，n.
w0: initial guess ofw, (, δ): the privacy budget, η: the step size, T: the total number of iterations.
Output: (, δ)-differentially Private classifier wpriv.
for k = 0,1,…，T 一 1 do
wk+1 = wk 一 ηA-1 (1 Pik∈Bk Vfik (wk) + n), where n 〜N(0, ν2I) and V is defined in
Theorem 1, and Bk ⊂ [n].
return wT
3 Main Theory
In this section, we Present the Privacy and utility guarantees for DP-LSSGD. The technical Proofs
are Provided in the aPPendix.
Definition 1 ((, δ)-DP). (Dwork et al. (2006)) A randomized mechanism M : S N → R satisfies
(, δ)-DP if for any two adjacent datasets S, S0 ∈ SN differing by one element, and any output
subset O ⊆ R, it holds that
PM(S) ∈ O] ≤ ee ∙ P[M(S0) ∈ O] + δ.
Theorem 1 (Privacy Guarantee). Suppose that each component function fi is G-Lipschitz. Given
the total number of iterations T, for any δ > 0 and privacy budget e2 ≤ 5T log(1∕δ)b2∕n2, DP-
LSSGD, with injected Gaussian noise N(0, ν2 ) for each coordinate, satisfies (, δ)-DP with ν2 =
8TaG2/(n2e), where α = 2log(1∕δ)∕e + L
Remark 1. It is straightforward to show that the noise in Theorem 1 is in fact also tight to guarantee
the (e, δ)-DP for DP-SGD.
For convex ERM, DP-LSSGD guarantees the following utility in terms of the gaP between the
ergodic average of the points along the DP-LSSGD path and the optimal solution w*.
Theorem 2 (Utility Guarantee for convex oPtimization). Suppose F is convex and each component
function f is G -Lipschitz. Given any e2 ≤ 5T log(1∕δ)b2∕n2 and δ > 0, if we choose 以=1∕√T
and T = (Dσ + G2)n2e2∕(24dG2 log(1∕δ)), where Dσ = ∣∣w0 — w*∣∣A, and w* is the global
minimizer of F, the DP-LSSGD output W = PT—； ηk/ (PT=O ηi)wk satisfies thefollowing utility
E(F(w) - F(w*)) ≤ -Y" +G2)dIog(I.,
where Y = 1/dPd=I 1∕[1 + 2σ — 2σ cos(2πi∕d)].
Proposition 1. In Theorem 2, Y =(i-ω1d+√dσ+T, where ω = 2σ+1-σ4σ+1 < 1. That is, Y converge
to 0 almost exponentially as the dimension, d, increases.
Remark 2. In the above utility bound for convex optimization, for different σ (σ = 0 corresponds
to DP-SGD), the only difference lies in the term Y(Dσ + G2 ). The first part YDσ depends on
the gap between initialization w0 and the optimal solution w*. The second part YG2 decrease
monotonically as σ increases. σ should be selected to get an optimal trade-off between these two
parts. Based on our test on multi-class logistic regression for MNIST classification, σ 6= 0 always
outperforms the case when σ = 0.
5
Under review as a conference paper at ICLR 2020
For nonconvex ERM, DP-LSSGD has the following utility bound measured in gradient norm.
Theorem 3 (Utility Guarantee for nonconvex optimization). Suppose that F is nonconvex and
each component function f is G-Lipschitz and has L-Lipschitz continuous gradient. Given
any e2 ≤ 5Tlog(1∕δ)b2∕n2 and δ > 0, if we choose η = 1∕√T and T = (DF +
Lν2)n2e2∕(l2dLG2 log(1∕δ)), where DF = F(w0) — F(w*) with w* being the global minimum
of F, then the DP-LSSGD output W = PT-CI wk/T satisfies thefollowing utility
ll ，、3	GP6βdL(2DF + LG2)log(1∕δ)
EkVF(w)k2-ι ≤ 4	β() g( / ),
Aσ	n
where β = 1/dPd=I 1∕[1 + 2σ — 2σ cos(2πi∕d)]2.
Proposition 2. In Theorem 3, β =以2"1-^2：+2；^：-^^, where ω = 2σ+1-√σ+ and ξ =
—√+4σ. Therefore, β ∈ (0,1).
It is worth noting that if We use the '2-norm instead of the induced norm, We have the following
utility guarantee
EkVF (W)II2-1
EkVF(w)k2 ≤ λ . (A-A。≤ (1 +4σ)E∣VF(w)∣∣A-ι ≤ 4Z
G √6dL(2DF + LG2)log(1∕δ)
n
where Z = Jd Pd=I (1+2σ-21+C¾2∏i∕d))2 > L In the '2-norm, DP-LSSGD has a bigger Utility
upper bound than DP-SGD (set σ = 0 in ζ). However, this does not mean that DP-LSSGD has
worse performance. To see this point, let us consider the following simple nonconvex function
G + y2,
f(x,y) = [sin (2 (x2 + y2)),
for x2 + y2 ≤ 1
for x42 + y2 > 1.
(6)
For two points aι = (2,0) and a2 = (1, √3∕2), the distance to the local minima a* = (0,0) are 2
and √7∕2, while ∣∣Vf (a1)k2 = 1 and ∣∣Vf (a2)k2 = √13∕2. So a2 is closer to the local minima a*
than aι while its gradient has a larger '2 -norm.
4	Experiments
In this section, we verify the efficiency of DP-LSSGD in training multi-class logistic regression and
CNNS for MNIST and CIFAR10 classification. We use V J v∕ max (1, ∣∣v∣∣2∕C) (Abadi et al.,
2016) to clip the gradient '2-norms of the CNNs to C. The gradient clipping guarantee the Lipschitz
condition for the objective functions. We train all the models below with (, 10-5)-DP guarantee for
different . For Logistic regression we use the privacy budget given by Theorem 1, and for CNNs
we use the privacy budget in the Tensorflow privacy (Andrew & et al., 2019). We checked that these
two privacy budgets are consistent.
4.1	Logistic Regression for MNIST Classification
We ran 50 epochs of DP-LSSGD with learning rate scheduled as 1∕t with t being the index of the
iteration to train the '2-regularized (regularization constant 10-4) multi-class logistic regression. We
split the training data into 50K/10K with batch size 128 for cross-validation. We plot the evolution
of training and validation loss over iterations for privacy budgets (0.2, 10-5) and (0.1, 10-5) in
Figure 3. We see that the training loss curve of DP-SGD (σ = 0) is much higher and more oscillatory
(log-scale on the y-axis) than that of DP-LSSGD (σ = 1, 3). Also, the validation loss of the model
trained by DP-LSSGD decays faster and has a much smaller loss value than that of the model trained
by DP-SGD. Moreover, when the privacy guarantee gets stronger, the utility improvement by DP-
LSSGD becomes more significant.
Next, consider the testing accuracy of the multi-class logistic regression trained with (, 10-5)-
DP guarantee by DP-LSSGD includes σ = 0, i.e., DP-SGD. We list the test accuracy of logistic
regression trained in different settings in Table 2. These results reveal that DP-LSSGD with σ =
1, 2, 3 can improve the accuracy of the trained private model and also reduce the variance, especially
when the privacy guarantee is very strong, e.g., (0.1, 10-5).
6
Under review as a conference paper at ICLR 2020
Iteration
Iteration
Iteration
100 200 300 400
Iteration
Figure 3:	Training and validation losses of the multi-class logistic regression by DP-LSSGD. (a)
and (b): training and validation curves with (0.2, 10-5)-DP guarantee; (c) and (d): training and
validation curves with (0.1, 10-5)-DP guarantee. (Average over 5 runs)
Table 2: Testing accuracy of the multi-class logistic regression trained by DP-LSSGD
with (, δ = 10-5)-DP guarantee and different LS parameter σ. Unit: %. (5 runs)
	0.30	0.25	0.20	0.15	0.10
σ=0	81.74 ± 0.96	81.45 ± 1.59	78.92 ± 1.14	77.03 ± 0.69	73.49 ± 1.60
σ=1	84.21 ± 0.51	83.27 ± 0.35	81.56 ± 0.79	79.46 ± 1.33	76.29 ± 0.53
σ=2	84.23 ± 0.65	83.65 ± 0.76	82.15 ± 0.59	80.77 ± 1.26	76.31 ± 0.93
σ=3	85.11 ± 0.45	82.97 ± 0.48	82.22 ± 0.28	80.81 ± 1.03	77.13 ± 0.77
Figure 4:	Accuracy of the logistic regression on MNIST when different learning rates are used to
train the model. Left: (0.1, 10-5)-DP; Right: (0.2, 10-5)-DP.
4.1.1	The Effects of Step Size
We know that the step size in DP-SGD/DP-LSSGD may affect the accuracy of the trained private
models. We try different step size scheduling of the form {a/t|a = 0.5, 1.0, 1.5, 2.0, 2.5, 3.0},
where t is again the index of iteration, and all the other hyper-parameters are used the same as before.
Figure. 4 plots the test accuracy of the logistic regression model trained with different learning rate
scheduling and different privacy budget. We see that the private logistic regression model trained by
DP-LSSGD always outperforms DP-SGD.
4.2 CNN for MNIST and CIFAR 1 0 Classification
In this subsection, we consider training a small CNN 2 with DP-guarantee for MNIST classifica-
tion. We implement DP-LSSGD and DP-LSAdam (Kingma & Ba, 2014) (simply replace the noisy
gradient in DP-Adam in the Tensorflow privacy with the Laplacian smoothed surrogate) into the
Tensorflow privacy framework (Andrew & et al., 2019). We use the default learning rate 0.15 for
DP-(LS)SGD and 0.001 for DP-(LS)Adam and decay them by a factor of 10 at the 10K-th itera-
tion, norm clipping (1), batch size (256), and micro-batches (256). We vary the noise multiplier
(NM), and larger NM guarantees stronger DP. As shown in Figure 5, the privacy budget increases at
exactly the same speed (dashed red line) for four optimization algorithms. When the NM is large,
i.e., DP-guarantee is strong, DP-SGD performs very well in the initial period. However, after a
few epochs, the validation accuracy gets highly oscillatory and decays. DP-LSSGD can mitigate
the training instability issue of DP-SGD. DP-Adam outperforms DP-LSSGD, and DP-LSAdam can
further improve validation accuracy on top of DP-Adam.
2github.com/tensorflow/privacy/blob/master/tutorials/mnist_dpsgd
tutorial.py
7
Under review as a conference paper at ICLR 2020
Epoch
NM 2.0 (LS: σ = 0.2)
Epoch
NM 5.0 (LS: σ = 1.0)	NM 8.0 (LS: σ = 1.0)	NM 10.0 (LS: σ = 1.0)
Figure 5:	Performance comparison (validation accuracy) between different DP optimization algo-
rithms in training CNN for MNIST classification with a fixed δ = 10-5.
Next, we consider the effects of the LS constant (σ) and the learning rate in training the DP-CNN for
MNIST classification. We fixed the NM tobe 10, and run 60 epochs of DP-SGD and DP-LSSGD
with different σ and different learning rate. We show the comparison of DP-SGD with DP-LSSGD
with different σ in the left panel of Figure 6, and we see that as σ increases it becomes more stable
in training CNNs with DP-guarantee even though initially it becomes slightly slower. In the middle
panel of Figure 6, we plot the evolution of validation accuracy curves of the DP-CNN trained by
DP-SGD and DP-LSSGD with different learning rate, where the solid lines represent results for
DP-LSSGD and dashed lines for DP-SGD. DP-LSSGD outperforms DP-SGD in all learning rates
tested, and DP-LSSGD is much more stable than DP-SGD when a larger learning rate is used.
Finally, we go back to the accuracy degradation problem raised in Figure 1. As shown in Figure 3, LS
can efficiently reduce both training and validation losses in training multi-class logistic regression for
MNIST classification. Moreover, as shown in the right panel of Figure 6, DP-LSSGD can improve
the testing accuracy of the CNN used above significantly. In particular, DP-LSSGD improves the
testing accuracy of CNN by 3.2% and 5.0% for (0.4, 10-5) and (0.2, 10-5), respectively, on top of
DP-SGD. DP-LSAdam can further boost test accuracy. All the accuracies associated with any given
privacy budget in Figure 6 (right panel), are the optimal ones searched over the results obtained in
the above experiments with different learning rate, number of epochs, and NM.
Due to page limitation, we put the results of DP-CNN for CIFAR10 classification in the appendix.
Diff LS (σ)
Diff Learning Rate
vs. Accuracy
Figure 6:	Left & middle panels: Contrasting performance (validation acc) of DP-SGD and DP-
LSSGD with different σ and different learning rate. Right panel: vs. Testing accuracy of the
private models trained by different DP-optimization algorithms with a fixed δ = 10-5.
5 Conclusions
In this paper, we integrated Laplacian smoothing with DP-SGD for privacy-presrving ERM. The
resulting algorithm is simple to implement and the extra computational cost compared with the DP-
SGD is almost negligible. We show that DP-LSSGD can improve the utility of the trained private
ML models both numerically and theoretically. It is straightforward to combine LS with other
variance reduction technique, e.g., SVRG (Johoson & Zhang, 2013).
8
Under review as a conference paper at ICLR 2020
References
M. Abadi, A. Chu, I. Goodfellow, H. McMahan, I. Mironov, K. Talwar, and L. Zhang. Deep Learning
with Differential Privacy. In 23rd ACM Conference on Computer and Communications Security
(CCS 2016), 2016.
G. Andrew and et al. TensorFlow Privacy. https://github.com/tensorflow/privacy,
2019.
M. Balcan, T. Dick, Y. Liang, W. Mou, and H. Zhang. Differentially Private Clustering in High-
Dimensional Euclidean Spaces. In 34th International Conference on Machine Learning (ICML
2017), 2017.
B.	Balle and Y. Wang. Improving the Gaussian Mechanism for Differential Privacy: Analytical
Calibration and Optimal Denoising. In International Conference on Machine Learning, pp. 403-
412, 2018.
B.	Barak, K. Chaudhuri, C. Dwork, S. Kale, F. McSherry, and K. Talwar. Privacy, accuracy, and
consistency too: a holistic solution to contingency table release. In Proceedings of the twenty-sixth
ACM SIGMOD-SIGACT-SIGART symposium on Principles of database systems, pp. 273-282.
ACM, 2007.
R. Bassily, A. Smith, and A. Thakurta. Private Empirical Risk Minimization: Efficient Algorithms
and Tight Error Bounds. In 55th Annual IEEE Symposium on Foundations of Computer Science
(FOCS 2014), 2014.
G. Bernstein, R. McKenna, T. Sun, D. Sheldon, M. Hay, and G. Miklau. Differentially private
learning of undirected graphical models using collective graphical models. In Proceedings of the
34th International Conference on Machine Learning-Volume 70, pp. 478-487. JMLR. org, 2017.
M. Bun and T. Steinke. Concentrated Differential Privacy: Simplifications, Extensions, and Lower
Bounds. ArXiv:1605.02065, 2016.
K. Chaudhuri and C. Monteleoni. Privacy-Preserving Logistic Regression. In Advances in Neural
Information Processing Systems (NIPS 2008), 2008.
K. Chaudhuri, C. Monteleoni, and A. Sarwate. Differentially Private Empirical Risk Minimization.
Journal of Machine Learning Research, 12, 2011.
J. Duchi, M. Jordan, and M. Wainwright. Privacy Aware Learning. Journal of the Association for
Computing Machinery, 61(6), 2014.
C.	Dwork and G. Rothblum. Concentrated Diffentially Privacy. ArXiv:1603.01887, 2016.
C. Dwork, K. Kenthapadi, F. McSherry, I. Mironov, and M. Naor. Our data, ourselves: Privacy via
distributed noise generation. In Annual International Conference on the Theory and Applications
of Cryptographic Techniques, pp. 486-503. Springer, 2006.
C.	Dwork, G. Rothblum, and S. Vadhan. Boosting and Differential Privacy. In 51th Annual IEEE
Symposium on Foundations of Computer Science (FOCS 2010), 2010.
W. Feng, Z. Yan, H. Zhang, K. Zeng, Y. Xiao, and Y. T. Hou. A Survey on Security, Privacy and
Trust in Mobile Crowdsourcing. IEEE Internet of Things Journal, 2017.
M. Fredrikson, S. Jha, and T. Ristenpart. Model Inversion Attacks that Exploit Confidence In-
formation and Basic Countermeasures. In 22nd ACM SIGSAC Conference on Computer and
Communications Security (CCS 2015), 2015.
A. Gilbert and A. McMillan. Local Differential Privacy for Physical Sensor Data and Sparse Recov-
ery. arXiv:1706.05916, 2017.
M. Hay, C. Li, G. Miklau, and D. Jensen. Accurate estimation of the degree distribution of private
networks. In 2009 Ninth IEEE International Conference on Data Mining, pp. 169-178. IEEE,
2009.
9
Under review as a conference paper at ICLR 2020
P. Jain, P. Kothari, and A. Thakurta. Differentially Private Online Learning. In 25th Conference on
Learning Theory (COLT 2012), 2012.
P. Jain, O. Thakkar, and A. Thakurta. Differentially Private Matrix Completion. In 35th International
Conference on Machine Learning (ICML 2018), 2018.
B. Jayaraman, L. Wang, D. Evans, and Q. Gu. Distributed Learning without Distress: Privacy-
Preserving Empirical Risk Minimization. In Advances in Neural Information Processing Systems
(NIPS 2018), 2018.
R. Johoson and T. Zhang. Accelerating Stochastic Gradient Descent using Predictive Variance Re-
duction. In Advances in Neural Information Processing Systems, 2013.
P. Kairouz, S. Oh, and P. Viswanath. The Composition Theorem for Differential Privacy. In 32nd
International Conference on Machine Learning (ICML 2015), 2015.
D. Kingma and J. Ba. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980,
2014.
J. Lee and D. Kifer. Concentrated Differentially Private Gradient Descent with Adaptive per-
iteration Privacy Budget. ArXiv:1808.09501, 2018.
Y. Liu, K. Gadepalli, M. Norouzi, G. Dahl, T. Kohlberger, A. Boyko, S. Venugopalan, A. Timofeev,
P. Nelson, G. Corrado, and et al. Detecting Cancer Metastases on Gigapixel Pathology Images.
arXiv:1703.02442, 2017.
I.	Mironov. Renyi Differential Privacy. In Computer Security Foundations Symposium (CSF), 2017
IEEE 30th,pp. 263-275. IEEE, 2017.
A. Nikolov, K. Talwar, and L. Zhang. The geometry of differential privacy: the sparse and approx-
imate cases. In Proceedings of the forty-fifth annual ACM symposium on Theory of computing,
pp. 351-360. ACM, 2013.
S. Osher, B. Wang, P. Yin, X. Luo, M. Pham, and A. Lin. Laplacian Smoothing Gradient Descent.
ArXiv:1806.06317, 2018.
N. Papernot, M. Abadi, U. Erlingsson, I. Goodfellow, and K. Talwar. Semisupervised Knowledge
Transfer for Deep Learning from Private Training Data. In 5th International Conference on Learn-
ing Representation (ICLR 2017), 2017.
N. Papernot, S. Song, I. Mironov, A. Raghunathan, K. Talwar, and U. Erlingsson. Scalable Private
Learning with PATE. In International Conference on Learning Representations (ICLR 2018),
2018.
M. Park, J. Foulds, K. Chaudhuri, and M. Welling. Private Topic Modeling. arXiv:1609:04120,
2016.
R.	Shokri and V. Shmatikov. Privacy-Preserving Deep Learning. In 22nd ACM SIGSAC Conference
on Computer and Communications Security (CCS 2015), 2015.
R.	Shokri, M. Stronati, C. Song, and V. Shmatikov. Membership Inference Attacks Against Machine
Learning Models. Proceedings of the 2017 IEEE Symposium on Security and Privacy, 2017.
S.	Song, K. Chaudhuri, and A. Sarwate. Stochastic Gradient Descent with Differentially Private
Updates. In GlobalSIP Conference, 2013.
D. Su, J. Cao, N. Li, E. Bertino, and H. Jin. Differentially Private k-Means Clustering.
arXiv:1504.05998, 2015.
K.	Talwar, A. Thakurta, and L. Zhang. Nearly optimal private lasso. In Advances in Neural Infor-
mation Processing Systems, pp. 3025-3033, 2015.
10
Under review as a conference paper at ICLR 2020
D. Wang and J. Xu. On sparse linear regression in the local differential privacy model. In Kamalika
Chaudhuri and Ruslan Salakhutdinov (eds.), Proceedings of the 36th International Conference on
Machine Learning, volume 97 of Proceedings of Machine Learning Research, pp. 6628-6637,
Long Beach, California, USA, 09-15 JUn 2019. PMLR. URL http://proceedings.mlr.
press/v97/wang19m.html.
D. Wang, M. Ye, and J. Xu. Differentially Private Empirical Risk Minimization Revisited: Faster
and More General. In Advances in Neural Information Processing Systems (NIPS 2017), 2017.
D. Wang, C. Chen, and J. Xu. Differentially private empirical risk minimization with non-convex
loss functions. In International Conference on Machine Learning, pp. 6526-6535, 2019.
L.	Wang and Q. Gu. Differentially Private Iterative Gradient Hard Thresholding for Sparse Learning.
In Proceedings of the 28th International Joint Conference on Artificial Intelligence, 2019.
Y. Wang, J. Lei, and S. Fienberg. Learning with Differential Privacy: Stability, Learnability and the
Sufficiency and Necessity of ERM Principle. ArXiv:1502.06309, 2016.
Y. Wang, B. Balle, and S. Kasiviswanathan. Subsampled R\’enyi Differential Privacy and Analytical
Moments Accountant. arXiv preprint arXiv:1808.00087, 2018.
Y. Wang Y. Wang and A. Singh. Differentially Private Subspace Clustering. In Advances in Neural
Information Processing Systems (NIPS 2015), 2015.
M.	Yuen, I. King, and K. Leung. A Survey of Crowdsourcing Systems. In Proceedings of the IEEE
international conference on social computing (Socialcom 2011), 2011.
J.	Zhang, K. Zheng, W. Mou, and L. Wang. Efficient Private ERM for Smooth Objectives. In The
Twenty-Sixth International Joint Conference on Artificial Intelligence (IJCAI 2017), 2017.
11
Under review as a conference paper at ICLR 2020
A Proof of the Main Theorems
A. 1 Privacy Guarantee
To prove the privacy guarantee in Theorem 1, We first introduce the following '2-sensitivity.
Definition 2 ('2 -Sensitivity). For any given function f (∙), the '2 -sensitivity of f is defined by
∆(f) =	ma0x	kf(S)-f(S0)k2,
kS-S0k1=1
where kS - S0 k1 = 1 means the data sets S and S0 differ in only one entry.
We will adapt the concepts and techniques of Renyi DP (RDP) to prove the DP-guarantee of the
proposed DP-LSSGD.
Definition 3 (RDP). For α > 1 and ρ > 0, a randomized mechanism M : Sn → R satisfies
(α, ρ)-Renyi DP, i.e., (α, P)-RDP if for all adjacent datasets S, S0 ∈ Sn differing by one element,
we have
Da(M(S)IM(SO)) := α-ιlog E( MS) )α ≤ P,
where the expectation is taken over M(S0).
Lemma 1. (Wang et al., 2018) Given a function q : Sn → R, the Gaussian Mechanism M =
q(S) + n, where n 〜N(0,ν2I), satisfies (α, α∆2(q)∕(2ν2))-RDP. In addition, if we apply the
mechanism M to a subset of samples using uniform sampling without replacement, M satisfies
(α, τ2∆2(q)α∕ν2)-RDP when V2∕∆2(q) ≥ 1/1.25, with T denoting the subsample rate.
Lemma 2. (Mironov, 2017) If k randomized mechanisms Mi : Sn → R, for i ∈ [k], satisfy
(α, ρi)-RDP, then their composition (MI(S),..., Mk (S)) satisfies (α, Pk=I Pi)-RDP Moreover,
the input of the i-th mechanism can be based on outputs of the previous (i-1) mechanisms.
Lemma 3. Ifa randomized mechanism M : Sn → R satisfies (α, P)-RDP, then M satisfies (P +
log(1∕δ)∕(α — 1), δ)-DPfor all δ ∈ (0,1).
With the definition (Def. 3) and guarantees of RDP (Lemmas 1 and 2), and the connection between
RDP and (, δ)-DP (Lemma 3), we can prove the following DP-guarantee for DP-LSSGD.
Proof of Theorem 1. Let us denote the update of DP-SGD and DP-LSSGD at the k-th iteration start-
ing from any given points Wk and Wk, respectively, as
wk+1 = Wk — ηk (b X Vfik(wk) + n),	⑺
ik ∈Bk
and
Wk+ι= Wk — ηkA-1 (1 X Vfik(Wk) + n),	(8)
ik ∈Bk
where Bk is a mini batch that are drawn uniformly from [n], and |Bk| = b is the mini batch size.
We will show that with the aforementioned Gaussian noise N(0, ν2) for each coordinate of n,
the output of DP-SGD, W, after T iterations is (e, δ)-DP. Let US consider the mechanism Mk =
b Pik∈Bk Vfik (Wk) + n, and Mk = ⅞VF(Wk) + n with the query qk = b VF(Wk). We have
the '2-sensitivity of qk as ∆(qk) = IlVfik(Wk) 一 Vfil(Wk并2 ≤ 2G. According to Lemma 1, if
we add noise with variance
2 _ 4Tα(α — 1)G2
v	n2 log(1∕δ),
the mechanism Mk will satisfy (α, (n2∕b2)log(1∕δ)/(2(α — 1)T))-RDP. By post-processing
theorem, we immediately have that under the same noise, Mk = A-1(VF(Wk) + n) also
satisfies (α, (n2∕b2)log(1∕δ)/(2(α — 1)T))-RDP. According to Lemma 1, Mk will satisfy
12
Under review as a conference paper at ICLR 2020
(α,log(1∕δ)∕(α-1)T) -RDP provided that V2 ≥ 1∕1.25,because T = b/n. Let a = 2log(1∕δ)∕e+
1, We obtain that Mk satisfies (2log(1∕δ)∕e + 1, e∕(2T))-RDP as long as We have
V2	_ Tα(α - 1)b2 _ T(2log(1∕δ)+ c)2log(1∕δ)b2	1
∆(q)2	n2 log(1∕δ)	n2 log(1∕δ)e2	- 1.25.
Therefore, the folloWing condition suffices
2 < 5Tb2 log(1∕δ)
6 ≤	.	.
n2
Therefore, according to Lemma 2, We have wk satisfies 2 log(1∕δ)∕6 + 1, k6∕(2T) -RDP. Finally,
by Lemma 3, we have Wk satisfies (ke∕(2T) + e∕2, δ)-DP. Therefore, the output ofDP-SGD, W, is
(e,δ)-DP.	□
Remark 3. In the above proof, we used the following estimate of the `2 sensitivity
∆(qk) = kA-1Vfi(wk) - A-1VfiO(wk)k2∕n ≤ 2G∕n.
Indeed, let g = Vfi(Wk) — Vf(Wk) and d = A-1g, then according to Osher et al. (2018) we
have
kdk2 + 2σ	kD+dk d	2 2 + σ2	kLdk2 d —	kgk2
where d is the dimension of d, and				
--1	1	0.	..	0	0 一
0	-1	1.	..	0	0
D+ =	0	0	-1 .	..	0	0
... 1	... 0	...	. 0.	..	... ..	0	... -1
Moreover, ifwe assume the g is randomly sampled from a unit ball in a high dimensional space, then
a high probability estimation of the compression ratio of the `2 norm can be derived from Lemma. 5.
Numerical experiments show that kAσ-1Vfi(Wk) - Aσ-1 Vfi0 (Wk)k2 is much less than kVfi(Wk) -
Vfi0 (Wk)k2, so for the above noise, it can give much stronger privacy guarantee.
A.2 Utility Guarantee - Convex Optimization
To prove the utility guarantee for convex optimization, We first shoW that the LS operator compresses
the `2 norm of any given Gaussian random vector With a specific ratio in expectation.
Lemma 4. Let x ∈ Rd be the standard Gaussian random vector. Then
d1
Ekxk2-1 = V ；~~-—— ------,
Ab	1 + 2σ — 2σ cos(2∏i∕d)
where kxk2A-1 =. hx, Aσ-1xi is the square of the induced norm of x by the matrix Aσ-1.
Proof of Lemma 4. Let the eigenvalue decomposition of Aσ-1 be Aσ-1 = UΛUT , Where Λ is a
diagonal matrix with Aii = 1+2σ-2σC0s(2∏i∕d) We have
Ekxk2 -1 = E[Tr(x>UΛU>x)]
Aσ
d
= X Λii
i=1
d
X
i=1
1
1 + 2σ — 2σ cos(2πi∕d)
□
13
Under review as a conference paper at ICLR 2020
Proof of Theorem 2. Recall that we have the following update rule wk+1 = wk -
ηk Aσ1(^fik (Wk) + n), where ik are drawn uniformly from [n], and n 〜 N(0,ν2I). Observe
that
kwk+1 - w*kAσ = kwk -ηkA-I(Vfik(wk) + n) - w*kAσ
=kwk - w*kAσ + η2(kA-1 Vfik(wk)kAσ + kA-1nkAσ +2hA-1Vfik(wk), n〉)
—2ηk hVfik (wk) + n, wk — w*).
Taking expectation with respect to ik and n given wk, we have
Ekwk+1 - w*k2Aσ = Ekwk - w*k2Aσ - 2ηkEhVF (wk), wk - w*i + ηk2EkVfik(wk)k2Aσ-1 + ηk2Eknk2Aσ-1
≤ EkWk - w*kAσ - 2ηkE(F(wk) - F(w*)) + η2(G2 + γdν2),
where the second inequality is due to the convexity of F, and Lemma 4. It implies that
2ηkE(F(wk) - F(w*)) ≤ (EkWk - w*kAσ - E∣∣wk+1 - w*∣∣Aσ) + ηk(G2 + YdV2).
Now taking the full expectation and summing up over T iterations, we have
T-1	T-1
X 2ηkE(F(wk) - F(w*)) ≤ D, + X η2(G2 + γdν2),
k=0	k=0
where Dσ = ∣∣w0 - w*kAσ. Let Vk = ηk/(PT-01ηk), we have
£ VkE(F(wk) - F(w*)) ≤ Dσ + PTPKG2 + γdν2).
k=0	2	k=0 ηk
According to the definition of W and the convexity of F, we obtain
E(F(W) - F(w*)) ≤ Dσ + Pk=O 口(。2 + γdν2)
2 kT=-01 ηk
≤ Dσ + PT=O η2G2 + PT=CI η2	24YdTG2 log(1∕δ)
-2 Pk=0 ηk	2 PT=1 ηk	超	.
Let η = 1∕√T and T = (Dσ + G2)n2e2/(24γdG2 log(1∕δ)), we can obtain that
E(F(W) - F(w*)) ≤ 2Gp6Y(Dσ+G2)dIog(I包.
□
A.3 Utility Guarantee - Nonconvex Optimization
To prove the utility guarantee for nonconvex optimization, we need the following lemma, which
shows that the LS operator compresses the `2 norms of any given Gaussian random vector with a
specific ratio in expectation.
Lemma 5. Let x ∈ Rd be the standard Gaussian random vector. Then
d
EkAσ-1xk22 = X
i=1
1
(1 + 2σ — 2σ cos(2πi∕d))2
Proof of Lemma 5. Let the eigenvalue decomposition of Aσ-1 be Aσ-1 = UΛUT, where Λ is a
diagonal matrix With Aii = +σ-2σCos(2∏i∕n) We have
EkAσ-1xk22 = E[Tr(x>UΛU>UΛU>x)]
= E[Tr(x>UΛ2U>x)]
d
= X Λi2i
i=1
d
X
i=1
1
(1 + 2σ — 2σ cos(2πi∕d))2
β.
□
14
Under review as a conference paper at ICLR 2020
Proof of Theorem 3. Recall that we have the following update rule wt+1 = wk -
ηk Aσ1(^fik (Wk) + n), where ik are drawn uniformly from [n], and n 〜 N(0, V2I). Since F
is L-smooth, we have
F(wk+1) ≤ F(wk) + BF(wk), wk+1 - wki + LkWk+1 - wkk2
=F(Wka(wk), A-1 (Vfik (wk) + n)i
η2L
+ η2r (kA-1Vfik(wk)k2 + kA-1nk2 + 2hA-1Vfik(wk), A-1ni).
Taking expectation with respect to ik and n given wk, we have
EF(wk+1) ≤ EF(wk) - ηkEhVF(wk), A-IVfik(Wk)i + ηkL (EkA-IVfik (wk)k2 + EkA-Ink2)
≤ EF(wk) - ηk(1 - η2L)EkVF(wk)kA-ι + η2L(G2 + dβν2)
≤ EF(wk) - 4EkVF(wk)kA-ι + η2L(G2) dβν2),
2	Aσ	2
where the second inequality uses Lemma 5 and the last inequality is due to 1 一 ηkL/2 > 1/2. Now
taking the full expectation and summing up over T iterations, we have
T-1
EF(WT) ≤ F(w0) - X nEkVF(wk)k；-i
k=1
T-1
+X
k=1
η2L(G2 + dβν2)
2
If we choose fix step size, i.e., ηk = η, and rearranging the above inequality, and using F(w0) -
EF(wT) ≤ F(w0) - F(w*), we get
T-1
X EkVF(wk)k2Aσ-1
k=1
1
T
2
≤ ητ(F(w ) - F(w )) + ηL(G + dβν ),
which implies that
EkVF (W)IlA-ι
≤ 2Df
一ηT
+ ηL(G2 + dβν2 )
≤ 2DF + MG +24dβTG: log，10
ηT	n2 2
Let η = 1∕√T and T = (2DF + LG2)n2e2∕(24dLβG2 log(1∕δ)), where DF = F(w0) - F(w*),
we obtain
EkVF(W)kA-ι ≤ 4
G √6βdL(2DF + LG2)log(1∕δ)
n
□
B CALCULATIONS OF β AND γ
B.1 CALCULATION OF γ
To prove Proposition 1, we need the following two lemmas.
Lemma 6 (Residue Theorem). Let f(z) be a complex function defined on C, then the residue of f
around the pole z = c can be computed by the formula
1	dn-1
Res(f, C) = 7----ʌʃ lim ʒ-^-ɪ ((Z - c)nf (Z)).
(n - 1)! z→c dzz-1
where the order of the pole c is n. Moreover,
f(Z)dZ = 2πi X Res(f, ci),
ci
where {ci} be the set of pole(s) of f(Z) inside {Z||Z| < 1}.
(9)
(10)
15
Under review as a conference paper at ICLR 2020
The proof of Lemma 6 can be found in any complex analysis textbook.
Lemma 7. For 0 ≤ θ ≤ 2π, suppose
F(θ)
1
1 + 2σ(1 — cos(θ)),
has the discrete-time Fourier transform of series f[k]. Then, for integer k,
ɑ∣k∣
f [k] = √4σ+τ
where
2σ + 1 — √4σ + 1
α =--------------
2σ
Proof. By definition,
f [k] = ɪ 12∏ F(θ)eikθ dθ = ɪ 12∏-----------二——dθ.	(11)
f [ ]	2π J0	( )	2π J0	1 + 2σ(1-cos(θ))	()
We compute (11) by using Residue theorem. First, note that because F(θ) is real valued, f[k]
f[—k]; therefore, it suffices to compute (11)) for nonnegative k. Set z = eiθ. Observe that cos(θ)
0.5(z + 1/z) and dz = izdθ. Substituting in (11) and simplifying yields that
f
f[k]
—1
2πiσ
(z — α-)(z — α+)
dz,
(12)
where the integral is taken around the unit circle, and α± = 2σ+1±σ4σ+ are the roots of quadratic
—σz2 + (2σ + 1)z — σ. Note that α- lies within the unit circle; whereas, α+ lies outside of the
unit circle. Therefore, because k is nonnegative, α- is the only singularity of the integrand in (12)
within the unit circle. A straightforward application of the Residue Theorem, i.e., Lemma 6, yields
that
k
f[k]
—a
αk
σ(α- — α+ )
√4σ +1.
This completes the proof.
□
Proof of Proposition 1. First observe that we can re-write γ as
1 d-1	1
1 X__________1________
d j=0 1 + 2σ(1 — cos(警))
(13)
It remains to show that the above summation is equal to (i-α+√⅛σ+Γ. ThiS follows by lemmas 7 and
standard sampling results in Fourier analysis (i.e. sampling θ at points {2∏j∕d}d-1). Nevertheless,
we provide the details here for completeness: Observe that that the inverse discrete-time Fourier
transform of
d-1
is given by
g[k]={产
if k divides d,
otherwise.
Furthermore, let
F(θ)
1
1 + 2σ(1 — cos(θ)),
16
Under review as a conference paper at ICLR 2020
and use f [k] to denote its inverse discrete-time Fourier transform. Now,
1 d-1	1	1	2π
d jX 1 + 2σ(1 - cos( 2∏j)) = d /()()
j=
2π
=-ɪ DTFTT [F ∙ g][0]
2π
=-ɪ(DTFTT[F] * DTFTT[G])[0]
2π ∞
=~d £ f [-r]g[r]
r=-∞
2∏ ∞灯,川d
=方 E f[-'d]2∏
'=-∞
∞
= X f[-`d].
'=-∞
The proof is completed by substituting the result of lemma 7 in the above sum and simplifying. □
We list some typical values of γ in Table 1.
Table 3: The values ofγ corresponding to some σ and d.
	σ	1	2	3	4	5
d	= 1000	0.447	0.333	-0.277-	0.243	0.218
d=	10000	0.447	0.333	0.277	0.243	0.218
d=	100000	0.447	0.333	0.277	0.243	0.218
B.2 CALCULATION OF β
The proof of Proposition 2 is similar as the proof of Proposition 1. The only difference is that we
need to compute
1	2π
f [k] = 2∏ L
eikθ
------------------ddθ.
(1 + 2σ(1 - cos θ))
(14)
By Residue theorem, for k > 0 (note that f[-k] = f[k] ), we have
1	2π
f [k] = 2∏ /
1
eikθ
(1 + 2σ(1 - cos θ))
zk+1
2dθ
2πi	(z + σ(2z - z2- 1))2
dz
lim
z→α-
lim
z→α-
d
dz
d
dz
(z - α- )2
zk+1
(z + σ(2z - z2- 1))2
(k + 1)α,
4σ + 1
(zk+1	A
(σ2(z — α+ )2 )
k	2σαk+1
+ (4σ + 1)3/2，
where a- = 2σ+1-√4σ+1. Therefore, We have
2α2d+1 - ξα2d + 2ξdαd - 2α + ξ
σ2ξ3(1 — ad)2
We list some typical values of β in Table 2.
17
Under review as a conference paper at ICLR 2020
Table 4: The values of β corresponding to some σ and d.
	σ	1	2	3	4	5
d	= 1000	0.268	0.185	0.149	0.128	0.114
d=	10000	0.268	0.185	0.149	0.128	0.114
d=	100000	0.268	0.185	0.149	0.128	0.114
C Laplacian Smoothing and Diffusion Equation
Let u(x, t) be a function defined on the space-time domain [0, 1] × [0, +∞), suppose it satisfies the
following diffusion equation with the Neumann boundary condition
(察=⅛u, (x,t) ∈ [0, 1] × [0, +∞),
d⅛t) = τ = 0, t ∈ [0, +∞)	(15)
I u(x, 0) = f(x), X ∈ [0, 1]
If we apply the backward Euler in time and central finite difference in space to discretize the gov-
erning equation in (15), we get
v∆t - v0 = ∆tLv∆t,
where v0 is the discretization of f(x), and v∆t is the numerical solution of (15) at time ∆t. There-
fore, we have
v∆t= (I - ∆tL)-1v0,
which is the LS with σ = ∆t.
D CNN for CIFAR10 Classification
In this section, we will show that LS can also improve the utility of the DP-CNN trained by DP-SGD
and DP-Adam for CIFAR10 classification. We simply replace the CNN architecture used above
for MNIST classification with the benchmark architecture in the Tensorflow tutorial 3 for CIFAR10
classification. Also, we use the same set of parameters as that used for training DP-CNN for MNIST
classification except we fixed the noise multiplier to be 2.0 and clip the gradient `2 norm to 3. As
shown in Figure 7, LS can significantly improve the validation accuracy of the model trained by
DP-SGD and DP-Adam, and the DP guarantee for all these algorithms are the same (dashed line in
Figure 7).
Epoch
Figure 7: Performance comparison between different differentially private optimization algorithms
in training CNN for CIFAR10 classification with a fixed δ = 10-5.
3github.com/tensorflow/models/tree/master/tutorials/image/cifar10
18