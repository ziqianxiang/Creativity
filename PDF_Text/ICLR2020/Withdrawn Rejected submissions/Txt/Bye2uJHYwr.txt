Under review as a conference paper at ICLR 2020
Weighted Empirical Risk Minimization:
Transfer Learning based on Importance Sampling
Anonymous authors
Paper under double-blind review
Abstract
We consider statistical learning problems, when the distribution P0 of the training
observations Z10, . . . , Zn0 differs from the distribution P involved in the risk one
seeks to minimize (referred to as the test distribution) but is still defined on the same
measurable space as P and dominates it. In the unrealistic case where the likelihood
ratio Φ(z) = dP/dP0(z) is known, one may straightforwardly extends the Empirical
Risk Minimization (ERM) approach to this specific transfer learning setup using
the same idea as that behind Importance Sampling, by minimizing a weighted
version of the empirical risk functional computed from the ’biased’ training data Zi0
with weights Φ(Zi0). Although the importance function Φ(z) is generally unknown
in practice, we show that, in various situations frequently encountered in practice, it
takes a simple form and can be directly estimated from the Zi0 ’s and some auxiliary
information on the statistical population P. By means of linearization techniques,
we then prove that the generalization capacity of the approach aforementioned is
preserved when plugging the resulting estimates of the Φ(Z0)‘s into the weighted
empirical risk. Beyond these theoretical guarantees, numerical results provide
strong empirical evidence of the relevance of the approach promoted in this article.
1	Introduction
Prediction problems are of major importance in statistical learning. The main paradigm of predictive
learning is Empirical Risk Minimization (ERM in abbreviated form), see e.g. Devroye et al. (1996).
In the standard setup, Z is a random variable (r.v. in short) that takes its values in a feature space Z
with distribution P, Θ is a parameter space and ` : Θ × Z → R+ is a (measurable) loss function. The
risk is then defined by: ∀θ ∈ Θ,
RP(θ) = EP [`(θ, Z)],	(1)
and more generally for any measure Q on Z: RQ(θ) = Z `(θ, z)dQ(z). In most practical situations,
the distribution P involved in the definition of the risk is unknown and learning is based on the sole
observation of an independent and identically distributed (i.i.d.) sample Z1, . . . , Zn drawn from
P and the risk (1) must be replaced by an empirical counterpart (or a possibly smoothed/penalized
version of it), typically:
1n
bP (θ) = 一 2 '(Θ, Z) = Rb (θ),	(2)
i=1
where Pn = (1/n) in=1 δZi is the empirical measure of P and δz denotes the Dirac measure at any
point z. With the design of successful algorithms such as neural networks, support vector machines
or boosting methods to perform ERM, the practice of predictive learning has recently received a
significant attention and is now supported by a sound theory based on results in empirical process
theory. The performance of minimizers of (2) can be indeed studied by means of concentration
inequalities, quantifying the fluctuations of the maximal deviations suPθ∈θ |Rp(θ) - RP(θ)∣ under
various complexity assumptions for the functional class F = {'(θ, ∙): θ ∈ Θ} (e.g. VC dimension,
metric entropies, Rademacher averages), see Boucheron et al. (2013) for instance. Although, in the
Big Data era, the availability of massive digitized information to train predictive rules is an undeniable
opportunity for the widespread deployment of machine-learning solutions, the poor control of the
data acquisition process one is confronted with in many applications puts practicioners at risk of
jeopardizing the generalization ability of the rules produced by the algorithms implemented. Bias
1
Under review as a conference paper at ICLR 2020
selection issues in machine-learning are now the subject of much attention in the literature, see
Bolukbasi et al. (2016), Zhao et al. (2017), Burns et al. (2019), Liu et al. (2016) or Huang et al. (2007).
In the context of face analysis, a research area including a broad range of applications such as face
detection, face recognition or face attribute detection, machine learning algorithms trained with baised
training data, e.g. in terms of gender or ethnicity, raise concerns about fairness in machine learning.
Unfair algorithms may induce systemic undesired disadvantages for specific social groups, see Das
et al. (2018) for further details. Several examples of bias in deep learning based face recognition
systems are discussed in Nagpal et al. (2019).
Throughout the present article, we consider the case where the i.i.d. sample Z10, . . . , Zn0 available for
training is not drawn from P but from another distribution P0 , with respect to which P is absolutely
continuous, and the goal pursued is to set theoretical grounds for the application of ideas behind
Importance Sampling (IS in short) methodology to extend the ERM approach to this learning setup.
We highlight that the problem under study is a very particular case of Transfer Learning (see e.g. Pan
& Yang (2010), Ben-David et al. (2010) and Storkey (2009)), a research area currently receiving much
attention in the literature and encompassing general situations where the information/knowledge one
would like to transfer may take a form in the target space very different from that in the source space
(referred to as domain adaptation).
Weighted ERM (WERM). In this paper, we investigate conditions guaranteeing that values for the
parameter θ that nearly minimize (1) can be obtained through minimization of a weighted version of
the empirical risk based on the Zi0’s, namely
Rew,n(θ) = RPew,n (θ),	(3)
where Pw,n = (1/n) in=1 wiδZ0 and w = (w1, . . . , wn) ∈ Rn+ is a certain weight vector. Of course, ideal
weights W * are given by the likelihood function Φ(z) = (dP/ dP')(z): w； = Φ(Z0) for i ∈ {1, ..., n}.
In this case, the quantity (3) is obviously an unbiased estimate of the true risk (1):
EP0 hRPew*,n (θ)i = RP(θ),	(4)
and generalization bounds for the RP-risk excess of minimizers of Rew*,n can be directly established
by studying the concentration properties of the empirical process related to the Zi0 ’s and the class
of functions {Φ(∙)'(θ, ∙) : θ ∈ Θ} (see section 2 below). However, the importance function Φ is
unknown in general, just like distribution P. It is the major purpose of this article to show that, in
far from uncommon situations, the (ideal) weights wi* can be estimated from the Zi0s combined with
auxiliary information on the target population P. As shall be seen below, such favorable cases include
in particular classification problems where class probabilities in the test stage differ from those in the
training step, risk minimization in stratified populations (see Bekker & Davis (2018)), with strata
statistically represented in a different manner in the test and training populations, positive-unlabeled
learning (PU-learning, see e.g. du Plessis et al. (2014)). In each of these cases, we show that the
stochastic process obtained by plugging the weight estimates in the weighted empirical risk functional
(3) is much more complex than a simple empirical process (i.e. a collection of i.i.d. averages) but
can be however studied by means of linearization techniques, in the spirit of the ERM extensions
established in Clemengon et al. (2008) or Clemengon & Vayatis (20θ9). Learning rate bounds for
minimizers of the corresponding risk estimate are proved and, beyond these theoretical guarantees,
the performance of the weighted ERM approach is supported by convincing numerical results.
The article is structured as follows. In section 2, the ideal case where the importance function Φ
is known is preliminarily considered and a first basic example where the optimal weights can be
easily inferred and plugged into the risk without deteriorating the learning rate is discussed. The
main results of the paper are stated in section 3, which shows that the methodology promoted can
be applied to two important problems in practice, risk minimization in stratified populations and
PU-learning, with generalization guarantees. Illustrative numerical experiments are displayed in
section 4, while some concluding remarks are collected in section 5. Proofs and additional results are
deferred to the Supplementary Material.
2	Importance Sampling - Risk Minimization with Biased Data
Here and throughout, the indicator function of any event E is denoted by I{E}, the sup norm of any
bounded function h : Z → R by ||h∣∣∞. We place ourselves in the framework of statistical learning
2
Under review as a conference paper at ICLR 2020
based on biased training data previously introduced. As a first go, we consider the unrealistic situation
where the importance function Φ is known, insofar as we shall subsequently develop techniques
aiming at mimicking the minimization of the ideally weighted empirical risk
1n
RWW∙,n (θ) = - JʒW*'(θ, Z),	(5)
n i=1
namely the (unbiased) Importance Sampling estimator of (1) based on the instrumental data
Z 0, ..., Zn. The following result describes the performance of mmιmιzers θn of (5). Since the goal
of this paper is to promote the main ideas of the approach rather than to state results with the highest
level of generality due to space limitations, we assume throughout the article for simplicity that `
and Φ are both bounded functions. For σ1, . . . , σn independent Rademacher random variables
(i.e. symmetric {-1, 1}-valued r.v.’s), independent from the Zi0’s, we define the Rademacher average
associated to the class of function F as Rfn(F) := Eσ [suPθ∈θ n IP?=i σi'(θ, Z0)∣]. This quantity can
be bounded by metric entropy methods under appropriate complexity assumptions on the class F,
it is for instance of order Op(1/ √n) when F is a VC major class with finite VC dimension, see e.g.
Boucheron et al. (2005).
Lemma 1. With probability at least 1 - δ, we have: ∀n ≥ 1,
Rp(0*n) - minRp(θ) ≤ 4∣∣Φ∣∣∞E [Rn(F)] + 2∣∣Φ∣∣∞ sup	'(θ, Z)
θ∈Θ	(θ,z)∈Θ×Z
/2log(1∕δ)
n -n-
Of course, when p0 = p, we have Φ ≡ 1 and the bound stated above simply describes the performance
of standard empirical risk minimizers. The proof is based on the standard bound
Rp(eθ*n) - min Rp(θ) ≤ 2 sup ∣∣∣∣Rew*,n(θ) - E hRew*,n(θ)i∣∣∣∣,
θ∈Θ	θ∈Θ
combined with basic concentration results for empirical processes, see the Supplementary Material
for further details. Of course, the importance function Φ is generally unknown and must be estimated
in practice. As illustrated by the elementary example below (related to binary classification, in the
situation where the probability of occurence of a positive instance significantly differs in the training
and test stages), in certain statistical learning problems with biased training distribution, Φ takes a
simplistic form and can be easily estimated from the Zi0’s combined with auxiliary information on p.
Binary classification with varying class probabilities. The flagship problem in supervised learning
corresponds to the simplest situation, where Z = (X, Y), Y being a binary variable valued in {-1, +1}
say, and the r.v. X takes its values in a measurable space X and models some information hopefully
useful to predict Y. The parameter space Θ is a set G of measurable mappings (i.e. classifiers)
g : X → {-1, +1} and the loss function is given by `(g, (x, y)) = I{g(x) , y} for all g in G and any
(x, y) ∈ X × {-1, +1}. The distribution p of the random pair (X, Y) can be either described by X’s
marginal distribution μ(dx) and the posterior probability η(X) = P{Y = +1 | X = x} or else by the
triplet (p, F+, F-) where p = P{Y = +1} and Fσ (dx) is X’s conditional distribution given Y = σ1
with σ ∈ {-, +}. It is very common that the fraction of positive instances in the training dataset
is significantly lower than the rate p expected in the test stage, supposed to be known here (see
the Supplementary Material for the case where the rate p is only approximately known). We thus
consider the case where the distribution p0 of the training data (X10 , Y10), . . . , (Xn0 , Yn0) is described by
the triplet (p0, F+, F-) with p0 < p. The likelihood function takes the simple following form
Φ(χ,y) = I{y = +i}与 + I{y = -i} 1_p0 d=f φ(y),
p0	1 - p0
which reveals that it depends on the label y solely, and the ideally weighted empirical risk process is
eW*,n(g)=与 n X I{g(X0) = -1} + H n X I{g(X0) = +1}.	(6)
p n i:Yi0=1	1 -p n i:Yi0=-1
In general the theoretical rate p0 is unknown and one replaces (6) with
e铲,n (g) = -T X I{g (X0) = -I} + 1⅛p X I{g (Xi) = +i},	⑺
n+ i:Yi0=1	n- i:Yi0=-1
3
Under review as a conference paper at ICLR 2020
where n + = P日 I{Yi = +1} = n - n-, bb* = φ(Yi) and φ(y) = I[y = +1}np/n + + I{y = -1}n(1 - p)/n-.
The stochastic process above is not a standard empirical process but a collection of sums of two ratios
of basic averages. However, the following result provides a uniform control of the deviations between
the ideally weighted empirical risk and that obtained by plugging the empirical weights into the latter.
Lemma 2. Letε ∈ (0, 1/2). Suppose that pi ∈ (ε, 1 -ε). For any δ ∈ (0, 1), we have with probability
larger than 1 - δ:
SuPR铲,n (g) -RW ,n (g )1 ≤ W r0p,
g∈G	ε2	2n
as soon as n ≥ 2log(2∕δ)∕ε2.
See the APPendix for the technical Proof. Consequently, minimizing (7) nearly boils down to
minimizing (6). Combining Lemmas 2 and 1, we immediately get the generalization bound stated in
the result below.
C- --11- -YC	.ι ..1	1	.1	CT	C	C 1/^11 ι r .— ι	■	cm
Corollary 1. Suppose that the hypotheses OfLemma 2 arefufilled. Let gn be any mmιmιzer of Rb?,n
over class G. We have with probability at least 1 - δ:
RP@) - inf RP(g) ≤ 2max(p，1 - p) f2E[Rn(G)] + r^δ + W r0gp,
g∈G	ε	Vn	ε2 V	2n
as soon asn ≥ 2log(4∕δ)∕ε2; where Rin(G) = (1∕n)Eσ[suPg∈G | Pin=1 σiI{g(Xii) , Yii}|].
Hence, some side information (i.e. knowledge of Parameter p) has Permitted to weight the training
data in order to build an emPirical risk functional that aPProximates the target risk and to show that
minimization of this risk estimate yields Prediction rules with oPtimal (in the minimax sense) learning
rates. The PurPose of the subsequent analysis is to show that this remains true for more general
Problems. Observe in addition that the bound in Corollary 1 deteriorates as ε decays to zero: the
method used here is not intended to solve the few shot learning Problem, where almost no training
data with Positive labels is available (i.e. pi ≈ 0). As shall be seen in subsection 3.2, alternative
estimators of the imPortance function must be considered in this situation.
Remark 1. Although the quantity (7) can be viewed as a cost-sensitive version of the empirical
classification risk based on the (Xii, Yii)’s (see e.g. Bach et al. (2006)), we point out that the goal
pursued here is not to achieve an appropriate trade-off between type I and type II errors in the Pi
classification problem as in biometric applications for instance (i.e. optimization of the (F+, F-)-ROC
curve at a specific point) but to transfer knowledge gained in analyzing the biased data drawn from
Pi to the classification problem related to distribution P.
Related work. We Point out that the natural idea of using weights in ERM Problems that mimic those
induced by the imPortance function has already been used in Sugiyama et al. (2008) for covariate
shift adaptation Problems (i.e. suPervised situations, where the conditional distribution of the outPut
given the inPut information is the same in the training and test domains), when, in contrast to the
framework considered here, a test samPle is additionally available (a method for estimating directly
the imPortance function based on Kullback-Leibler divergence minimization is ProPosed, avoiding
estimation of the test density). ImPortance samPling estimators have been also considered in Garcke
& Vanck (2014) in the setuP of inductive transfer learning (the tasks between source and target are
different, regardless of the similarities between source and target domains), where the authors have
ProPosed two methods to aPProximate the imPortance function, among which one is again based on
minimizing the Kullback-Leibler divergence between the two distributions. In Cortes et al. (2008),
the samPle selection bias is assumed to be indePendent from the label, which is not true under our
stratum-shift assumPtion or for the PU learning Problem (see section 3). Lemma 1 assumes that the
exact imPortance function is known, as does Cortes et al. (2010). The next section introduces new
results for more realistic settings where it has to be learned from the data.
3 Weighted Empirical Risk Minimization - Generalization Guarantees
Through two imPortant and generic examPles, relevant for many aPPlications, we show that the
aPProach sketched above can be aPPlied to general situations, where aPProPriate auxiliary information
on the target distribution is available, with generalization guarantees.
4
Under review as a conference paper at ICLR 2020
3.1	Statistical Learning from Biased Data in a Stratified Population
A natural extension of the simplistic problem considered in section 2 is multiclass classification in a
stratified population. The random labels Y and Y0 are supposed to take their values in {1, . . . , J} say,
with J ≥ 1, and each labeled observation (X, Y) belongs to a certain random stratum S in {1, . . . , K}
with K ≥ 1. Again, the distribution P of a random element Z = (X, Y, S ) may be described by the
parameters {(pj,k, Fj,k) : 1 ≤ j ≤ J, 1 ≤ k ≤ K} where Fj,k is the conditional distribution of X given
(Y S) = (j, k) and pj,k = P(x,y,s)~P{Y = j, S = k}. Then, We have
JK
dP(x, y, s) = ΣΣI{y = j, s = k}pj,kdFj,k(x),
and considering a distribution P0 With Fj,k ≡ F0j,k but possibly different class-stratum probabilities
p0j,k , the likelihood function becomes
JK
dpo (X, y, S) = XX Pk IU =j, S =k }d=f φ(y, S).
A more general frameWork can actually encompass this specific setup by defining ’meta-strata’ in
{1, . . . , J} × {1, . . . , K}. Strata may often correspond to categorical input features in practice. The
formalism introduced beloW is more general and includes the example considered in the preceding
section, Where strata are defined by labels.
Learning from biased stratified data. Consider a general mixture model, Where distributions P
and P0 are stratified over K ≥ 1 strata. Namely, Z = (x, S) and Z0 = (x0, S0) With auxiliary random
variables S and S0 (the strata) valued in {1, . . . , K}. We place ourselves in a Stratum-Shift context,
assuming that the conditional distribution of x given S = k is the same as that of x0 given S0 = k,
denoted by Fk(dx), for any k ∈ {1, . . . , K}. HoWever, stratum probabilities pk = P(S = k) and
p0k = P(S0 = k) may possibly be different. In this setup, the likelihood function depends only on the
strata and can be expressed in a very simple form, as folloWs:
ddP(X,S) = X I{S =k}P d=f φ(S).
dP	k=1	pk
In this case, the ideally Weighted empirical risk Writes
1n	K
RWn(θ) = 一 Y'(θ, Zi) Y I{Si = k}pk.
n i=1	k=1	pk
If the strata probabilities pk’s for the test distribution are knoWn, an empirical counterpart of the ideal
empirical risk above is obtained by simply plugging estimates of the p0k ’s computed from the training
data:
nK
Rw*,n(θ) = ∑'(θ,Zi) ∑ I{Si = k}pk,	(8)
i=1	k=1	nk
With nk = Pn=ι I{Si = k}, b* = b(Si) and b(S) = P晨 I{S = k}npknk.
A bound for the excess of risk is given in Theorem 1, that can be vieWed as a generalization of
Corollary 1.
Theorem 1.	Let ε ∈ (0,1/2) and aSSume that Pk ∈ (ε, 1 一 ε) for k = 1,..., K. Let θn be any mιnιmιzer
of Rb?,n as defined in (8) over class Θ. We have with probability at least 1 一 δ:
RP(e;) - inf RP(θ) ≤ 2max^ [2E[Rn 内 + L	+ 4L r≡,
θ∈θ	ε	Nn	ε2 Y	2n
∖
as soon as n ≥ 2log(4K/ð)/e2; where Rn(F) = (1/n)Eσ[suPθ∈θ IPn=1 σi'(θ,Z0)|], and the loss is
bounded by L = sup(θ,z)∈Θ×Z `(θ, z).
Just like in Corollary 1, the bound in Theorem 1 exPlodes When ε vanishes, Which corresPonds
to the situation Where a stratum k ∈ {1, . . . , K} is very Poorly rePresented in the training data, i.e.
When pik << pk . Again, as highlighted by the exPeriments carried out, reWeighting the losses in a
frequentist (ERM) aPProach guarantees good generalization ProPerties in a sPecific setuP only, Where
the training information, though biased, is sufficiently informative.
5
Under review as a conference paper at ICLR 2020
3.2 Positive-Unlabeled Learning
Relaxing the stratum-shift assumption made in the previous subsection, the importance function
becomes more complex and writes:
dP
Φ(ɪ, S) = dp0f (羽 S) = 2j I{S = k}
pk dFk
p0k dFk0
where Fk and Fk0 are respectively the conditional distributions of X given S = k and of X0 given
S0 = k. The Positive-Unlabeled (PU) learning problem, which has recently been the subject of much
attention (see e.g. du Plessis et al. (2014), Du Plessis et al. (2015), Kiryo et al. (2017)), provides a
typical example of this situation. Re-using the notations introduced in section 2, in the PU problem,
the testing and training distributions P andP0 are respectively described by the triplets (p, F+, F-)
and (q, F+, F), where F = pF+ + (1 - p)F- is the marginal distribution of X. Hence, the objective
pursued is to solve a binary classification task, based on the sole observation of a training sample
pooling data with positive labels and unlabeled data, q denoting the theoretical fraction of positive
data among the dataset. As noticed in du Plessis et al. (2014) (see also Du Plessis et al. (2015), Kiryo
et al. (2017)), the likelihood/importance function can be expressed in a simple manner, as follows:
∀(x,y) ∈X×{-1, +1}, Φ(x,y) = pI{y = +1} + -ɪI{y = -1} - / dF+ (x)I{y = -1}.	(9)
q	1 - q	1 - q dF
Based on an i.i.d. sample (X10, Y10), . . . , (Xn0, Yn0) drawn from P0 combined with the knowledge
of p (which can also be estimated from PU data, see e.g. Du Plessis & Sugiyama (2014)) and
using thatF- = (1/(1 - p))(F - pF+), one may obtain estimators of q, F+ andF by computing
n0+/n = (1/n)Pin=1I{Yi0= +1}, Fb+ = (1/n0+)Pin=1I{Yi0= +1}δXi0 andFb= (1/n0-)Pin=1I{Yi0= -1}δXi0.
However, plugging these quantities into (9) do not permit to get a statistical version of the importance
function, insofar as the probability measures F+ andF are mutually singular with probability one, as
soon asF+ is continuous. Of course, as proposed in du Plessis et al. (2014), one may use statistical
methods (e.g. kernel smoothing) to build distribution estimators, that ensures absolute continuity
but are subject to the curse of dimensionality. However, WERM can still be applied in this case, by
observing that: ∀g ∈ G,
2p	1
Rp(g) = -P + EP — I{g(x，) = -1,『=+1} + τ—I{g(X) = +1, 7 = -1} ,	(10)
q	1-q
which leads to the weighted empirical risk
2p X I{g(χ0 = -1} + 京 X I{g(Xi) = +1}.	(11)
n+ i:Yi0=+1	n- i:Yi0=-1
Minimization of (11) yields rules egn whose generalization ability regarding the binary problem related
to (P, F+, F-) can be guaranteed, as shown by the following result, the form of the weighted empirical
risk in this case being quite similar to (7).
Theorem 2.	Let ε ∈ (0, 1/2). SuPPoSe that q ∈ (ε, 1 - ε). Let egn be any minimizer of the weighted
emPirical riSk (11) over claSS G. We have with Probability at leaSt 1 - δ:
RP初)-inf Rp(g) ≤ 也3 f2E[Rn (G)] + 产巫 + 丁 ro萼,
g ∈G	ε	Nn	ε2	V 2 n
\
as soon asn ≥ 2log(4∕δ)∕ε2; Where RRn(G) = (1/n)Eσ[supg∈g | Pn=1 σiI{g(Xi) , Y0}∣].
Remark 2. Let η(x) = P{Y = +1 | X = x} denote the PoSterior Probability and recall that
(dF+ ∕dF-)(x) = ((1 - P)∕ P)(η( x)∕(1 - η(x)). ObServing that
Φ(x, y) = pI{y = +1} + 1 - η(x) I{y = -1},	(12)
q	1-q
in the caSe when an eStimate bη(x) of η(x) iS available, one can Perform WERM uSing the emPirical
weight function
b(χ, y) = npp I{y = +1} + 1η(x)- I{y = -1}.	(13)
n0+	1 - n0+ ∕n
A bound that deScribeS how thiS aPProach generalizeS, dePending on the accuracy of eStimate bη, can
be eaSily eStabliShed, for more detailS refer to Theorem 3 in the SuPPlementary Material, where it iS
alSo diScuSSed how to exPloit Such formulaS in order to deSign incremental WERM ProcedureS.
6
Under review as a conference paper at ICLR 2020
4 Numerical Experiments
This section illustrates the impact of reweighting by the likelihood ratio on classification performances,
as a special case of the general strategy presented in Section 2. A first simple illustration on known
probability distributions highlights the impact of the shapes of the distributions on the importance of
reweighting. This example illustrates in the infinite-sample case that separable or almost separable
data do not require reweighting, in contrast to noisy data. Since the distribution shapes are unknown
for real data, we infer that reweighting will have variable effectiveness, depending on the dataset. This
illustration is deferred to the Appendix, as well as an experiment on reweighting for classification of
MNIST dataset where bias is introduced in the distribution of the classes. We detail here a second
experiment that uses the structure of ImageNet to illustrate reweighting with a stratified population and
strata distribution bias or strata bias. The code of the experiments can be found at https://drive.
google.com/drive/folders/1-tWJ4n4WyXuTza8dLPngyHSVprKUZFVJ?usp=sharing.
We focus on the learning from biased stratified data setting introduced in Section 3.1 by leveraging
the ImageNet Large Scale Visual Recognition Challenge (ILSVRC); a well-known benchmark for
the image classification task, see Russakovsky et al. (2014) for more details.
The challenge consists in learning a classifier from 1.3 million training images spread out over 1,000
classes. Performance is evaluated using the validation dataset of 50,000 images of ILSVRC as our
test dataset. ImageNet is an image database organized according to the WordNet hierarchy, which
groups nouns in sets of related words called synsets. In that context, images are examples of very
precise nouns, e.g. flamingo, which are contained in a larger synset, e.g. bird.
The impact of reweighting in presence of strata bias is illustrated on the ILSVRC classification
problem with broad significance synsets for strata. To do this, we encode the data using deep neural
networks. Specifically our encoding is the flattened output of the last convolutional layer of the
network ResNet50 introduced in He et al. (2015). It was trained for classification on the training
dataset of ILSVRC. The encodings X1, . . . ,Xn belong to a 2,048-dimensional space.
A total of 33 strata are derived from a list of high-level categories provided by ImageNet1. The
construction of the strata is postponed to the Appendix. By default, strata probabilities pk and p0k
for 1 ≤ k ≤ K are equivalent between training and testing datasets, meaning that reweighting by
Φ would have little to no effect. Since our testing data is the validation data of ILSVRC, we have
around 25 times more training than testing data. Introducing a strata bias parameter 0 ≤ γ ≤ 1, we
set the strata train probabilities such that Pfk = γ1-bK/2c/kpk before renormalization and remove train
instances so that the train set has the right distribution over strata; see the Appendix for more details
on the generation of strata bias. When γ is close to one, there is little to no strata bias. In contrast,
when γ approaches 0, strata bias is extreme.
0.25-
Train
Test
0.20-
1 015-
o.ιo-
0.05-
0.00
1J⅛
⅛ τ ITTJiT i⅛
Strata
Comparison of pk’s and p0k’s.
Model	Reweighting	miss rate	top-5 error
	Unif. Φb = 1	0.344	0.130
Linear	e	O Strata Φ	0.329	0.120
	… 飞 Class Φ	0.328	0.119
	No bias	0.297	0.102
	Unif. Φb = 1	0.371	0.143
MLP	Strata Φ	0.364	0.138
	〜 二 Class Φ	0.363	0.138
	No bias	0.316	0.111
Table of results.
Figure 1:	Results for the strata reweighting experiment with ImageNet.
1http://www.image-net.org/about-stats
7
Under review as a conference paper at ICLR 2020
Dynamics for the SCE.
Dynamics for the miss rate.
Dynamics for the top-5 error.
Figure 2:	Dynamics for the linear model for the strata reweighting experiment with ImageNet.
Dynamics for the SCE.
0.15- 一 class
----------No bias
o.ιo ∖
0	10000	20000
0
10000	20000
Dynamics for the miss rate.
Dynamics for the top-5 error.
Figure 3:	Dynamics for the MLP model for the strata reweighting experiment with ImageNet.
The models used are a linear model and a multilayer perceptron (MLP) with one hidden layer;
more details are given in the Appendix. We report better performance when reweighting using the
strata information, compared to the case where the strata information is ignored, see fig. 1. For
comparison, we added two reference experiments: one which reweights the train instances by the
class probabilities, which we do not know in a stratified population experiment, and one with more
data and no strata bias because it uses all of the ILSVRC train data. The dominance of the linear
model over the MLP can be justified by the much higher number of parameters to estimate for the
MLP.
5 Conclusion
In this paper, we have considered specific transfer learning problems, where the distribution of the
test data P differs from that of the training data, P0 , and is absolutely continuous with respect to the
latter. This setup encompasses many situations in practice, where the data acquisition process is not
perfectly controlled. In this situation, a simple change of measure shows that the target risk may
be viewed as the expectation of a weighted version of the basic empirical risk, with ideal weights
given by the importance function Φ = dP/dP0 , unknown in practice. Throughout this article, we have
shown that, in statistical learning problems corresponding to a wide variety of practical applications,
these ideal weights can be replaced by statistical versions based solely on the training data combined
with very simple information about the target distribution. The generalisation capacity of rules learnt
from biased training data by minimization of the weighted empirical risk has been established, with
learning bounds. These theoretical results are also illustrated with several numerical experiments.
8
Under review as a conference paper at ICLR 2020
References
Francis Bach, David Heckerman, and Eric Horvitz. Considering cost asymmetry in learning classifiers,
2006.
Jessa Bekker and Jesse Davis. Beyond the selected completely at random assumption for learning
from positive and unlabeled data. CoRR, abs/1809.03207, 2018. URL http://arxiv.org/abs/
1809.03207.
Shai Ben-David, John Blitzer, Koby Crammer, Alex Kulesza, Fernando Pereira, and Jennifer Wort-
man Vaughan. A theory of learning from different domains. Machine Learning, 79(1), 2010.
Tolga Bolukbasi, Kai-Wei Chang, James Zou, Venkatesh Saligrama, and Adam Kalai. Man is to
computer programmer as woman is to homemaker? debiasing word embeddings. In NIPS, pp.
4349-4357, 2016.
StePhane Boucheron, Olivier Bousquet, and Gwbor Lugosi. Theory of classification : a survey of
some recent advances. ESAIM: Probability and Statistics, 9:323-375, 2005.
StePhane Boucheron, Gdbor Lugosi, and Pascal Massart. Concentration Inequalities: A NonasymP-
totic Theory of Independence. OUP Oxford, 2013.
Kaylee Burns, Lisa Anne Hendricks, Kate Saenko, Trevor Darrell, and Anna Rohrbach. Women also
snowboard: Overcoming bias in caPtioning models. 2019.
FrangOiS Chollet et al. Keras. https://keras.io, 2015.
Stephan CIemengOn and Nicolas Vayatis. Empirical performance maximization based on linear rank
statistics. In NIPS, volume 3559 of Lecture Notes in ComPuter Science, PP. 1-15. SPringer, 2009.
Stephan Clemengon and Nicolas Vayatis. Tree-Based Ranking Methods. IEEE Trans. on Inf. Theory,
5(9):4136-4156, 2009.
Stephan Clemengon, Gwbor Lugosi, and Nicolas Vayatis. Ranking and Empirical Minimization of
U-Statistics. The Annals of Statistics, 36(2):844-874, 2008.
Corinna Cortes, Mehryar Mohri, Michael Riley, and Afshin Rostamizadeh. Sample selection bias
correction theory. In International conference on algorithmic learning theory, pp. 38-53. Springer,
2008.
Corinna Cortes, Yishay Mansour, and Mehryar Mohri. Learning bounds for importance weighting.
In Advances in neural information Processing systems, pp. 442-450, 2010.
Abhijit Das, Antitza Dantcheva, and Francois Bremond. Mitigating bias in gender, age and ethnicity
classification: a multi-task convolution neural network approach. In Proceedings of the EuroPean
Conference on ComPuter Vision (ECCV), pp. 0-0, 2018.
Luc Devroye, Ldszl6 Gyorfi, and Gdbor Lugosi. A Probabilistic Theory of Pattern Recognition.
Springer, 1996.
Marthinus Christoffel Du Plessis and Masashi Sugiyama. Class prior estimation from positive and
unlabeled data. IEICE TRANSACTIONS on Information and Systems, 97(5):1358-1362, 2014.
Marthinus Christoffel du Plessis, Gang Niu, and Masashi Sugiyama. Analysis of learning from
positive and unlabeled data. In NIPS, pp. 703-711, 2014.
Marthinus Christoffel Du Plessis, Gang Niu, and Masashi Sugiyama. Convex formulation for learning
from positive and unlabeled data. In ICML, ICML’15, pp. 1386-1394. JMLR.org, 2015. URL
http://dl.acm.org/citation.cfm?id=3045118.3045266.
Jochen Garcke and Thomas Vanck. Importance weighted inductive transfer learning for regression.
In ECML PKDD, pp. 466-481. Springer, 2014.
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image
recognition. CoRR, abs/1512.03385, 2015. URL http://arxiv.org/abs/1512.03385.
9
Under review as a conference paper at ICLR 2020
Jiayuan Huang, Arthur Gretton, Karsten M Borgwardt, Bernhard Scholkopf, and Alexander J. Smola.
Correcting sample selection bias by unlabeled data. In NIPS, pp. 601-608, 2007.
Ryuichi Kiryo, Gang Niu, Marthinus Christoffel du Plessis, and Masashi Sugiyama. Positive-
unlabeled learning with non-negative risk estimator. In NIPS, pp. 1674-1684, 2017.
Zhen Liu, Jun-an Yang, Hui Liu, and Wei Wang. Transfer learning by sample selection bias correction
and its application in communication specific emitter identification. JCM, 11:417-427, 2016.
Shruti Nagpal, Maneet Singh, Richa Singh, Mayank Vatsa, and Nalini Ratha. Deep learning for face
recognition: Pride or prejudiced? arXiv preprint arXiv:1904.01219, 2019.
Sinno Jialin Pan and Qiang Yang. A survey on transfer learning. IEEE Transactions on Knowledge and
Data Engineering, 22(10):1345-1359, Oct 2010. ISSN 1041-4347. doi: 10.1109/TKDE.2009.191.
Sebastian Ruder. An overview of gradient descent optimization algorithms. CoRR, abs/1609.04747,
2016. URL http://arxiv.org/abs/1609.04747.
Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng
Huang, Andrej Karpathy, Aditya Khosla, Michael S. Bernstein, Alexander C. Berg, and Fei-
Fei Li. Imagenet large scale visual recognition challenge. CoRR, abs/1409.0575, 2014. URL
http://arxiv.org/abs/1409.0575.
Amos Storkey. When training and test sets are different: characterizing learning transfer. Dataset
shift in machine learning, pp. 3-28, 2009.
Masashi Sugiyama, Shinichi Nakajima, Hisashi Kashima, Paul von Buenau, and Motoaki Kawanabe.
Direct importance estimation with model selection and its application to covariate shift adaptation.
In NIPS, pp. 1433-1440, 2008.
Jieyu Zhao, Tianlu Wang, Mark Yatskar, Vicente Ordonez, and Kai-Wei Chang. Men also like
shopping: Reducing gender bias amplification using corpus-level constraints. In EMNLP, 2017.
Appendix - Technical Proofs
Here we detail the proofs of the results stated in the article and discuss their connection with related
work.
Proof of Lemma 1
Let δ ∈ (0, 1). Applying the classic maximal deviation bound stated in Theorem 3.2 of Boucheron
et al. (2005) to the bounded class K = {z ∈ Z 7→ Φ(z)l(θ, z) : θ ∈ Θ}, we obtain that, with
probability at least 1 - δ:
sup Ie优,n(θ) - EhR优,n(θ)]l ≤ 2E [Rn(K)] + IΦII∞ sup	l'(θ, N)1
θ∈Θ	(θ,z)∈Θ×Z
/2log(1∕δ)
n -n-
In addition, by virtue of the contraction principle, we have R'n(K) ≤ ∣∣Φ∣∣∞R'n(F) almost-surely. The
desired result can be thus deduced from the bound above combined with the classic bound
Rp(Θn) - min Rp(θ) ≤ 2 sup IR优 n(θ) - E [麓[(θ)]∣.
θ∈Θ	θ∈Θ
Proof of Lemma 2
Apply twice the Taylor expansion
1	1 x - a (x - a)2
x a	a2	xa2
10
Under review as a conference paper at ICLR 2020
so as to get
1	1 n +/n - P0 (n +/n - P')2
		-		-	;;	+ 	τ-,
n +/ n-----------------------------------p P-p02-p02 n +/ n
1	1	n-/n - 1 + p0 (n-/n - 1 + P')2
	 - 	-	Z— +------------Z------
n0- /n-----------------------------------------------1 - p0-(1 - p0)2	(1 - p0)2 n0- /n
This yields the decomposition
R病,n (g) -R城,n(g )
--pp2(n _p‘)n X 期 (x0)
-1, Yi = +1]
—
(⅛⅛ BT + P
! n X 电 (冲=+1,Y=-1]+EP(Pnlf n X 咽 (4=-1,Y=+1]
+(I-P警；2；n ∑ 酩(χp)=+1, y；=-1].
We deduce that
校b∙,n(g)-Rj(g)| ≤n+/% p 1 (1 +1 n +/n-pi(忐+ r⅛))-
By virtue of Hoeffding inequality, we obtain that, for any δ ∈ (0,1), we have with probability larger
than 1 - δ:	_______
In +/n-p'∣≤ E
so that, in particular, min{n +/n, 1 - n +/n] ≥ ε - ,log(2@/(2n). This yields the desired result.
Proof of Corollary 1
Observe first that | | Φ 11 ∞ ≤ max(p, 1 - P)/% and
RP(gn) -	inf RP(g)	≤ 2 sup	∣ eb*,n (g)	- R城,n (g) 1 + 2 sup1 R便,n (g) -	RP(g) 1.
g∈G	g ∈G	1	Ig∈G 1	1
The result then directly follows from the application of Lemmas 1-2 combined with the union bound.
Proof of Theorem 1
Observe first that ∣∣Φ∣∣∞ ≤ maxk Pk/ε and
Rp(或)-inf Rp(θ) ≤ 2 sup ∣ eb*, ∕θ) - e便,n (θ) ∣+ 2 sup ∣ RW便,n (θ) - Rp(θ) ∣.
θ∈θ	θ∈Θ 1	1 θ∈Θ 1	1
The result then directly follows from the application of Lemmas 1-3 combined with the union bound.
Lemma 3. Let ε ∈ (0, 1/2). Suppose that p k ∈ (ε, 1 - ε) fork ∈ {1, ..., K}. For any δ ∈ (0,1), we
have with probability larger than 1 - δ:
∣ ~ ,、u z I 2L ∕log(2K/δ)
sup ] eeb*,n (θ) - Rw*,n (θ) ∣ ≤ ʌ/ ʒ-,
θ∈Θ 1	1 ε V	2 n
as soon as n ≥ 2 log(2K/δ)/ε2, where L = SUPGZ)∈θ×z '(θ, Z).
proof.
Apply the Taylor expansion
1	1 X - a	(X - a)2
ɪ a	a2	xa2
11
Under review as a conference paper at ICLR 2020
so as to get for all k ∈ {1, . . . , K}
1	1	nk/n-p Pk	(nk/n- pk )2
	=----------	+	-
n0k/n--------------------------------p0k	p0k2-p0k2n0k/n
This yields the decomposition
Rwb∙,n(θ) - RW∙,n(θ)
1n
We deduce that
Rb∙,n(θ) - R优,n(θ)
n i=1
- p0k |
+ Pk(nk/n - Pk)2
P k2 nkn
—
—
—
—
By virtue of Hoeffding inequality, we obtain that, for any k ∈ {1, . . . , K} and δ ∈ (0, 1), we have with
probability larger than 1 - δ:
nk/n - Pk∣≤ E
so that, by a union bound, maxk{nk/n} ≥ ε - {log(2K∕δ)∕(2n). This yields the desired result.
Proof of Theorem 2
Observe first that ∣∣Φ∣∣∞ ≤ max(2P, 1)∕e and
Rpp(gn) - inf Rpp(g) ≤ 2 SUP ∣eb*,n(g) - Ra,n(g)∣ + 2 SUP ∣R便,n(g) - RP(g)∣,
g∈G	g∈G	g∈G
with weighted empirical risk R便,n (g) defined in (11). The result then 出rectly follows from the
aPPlication of Lemmas 1-4 combined with the union bound.
Lemma 4. Let ε ∈ (0, 1/2). SuPPose that q ∈ (ε, 1 - ε). For any δ ∈ (0, 1), we have with Probability
larger than 1 - δ:
sup R",n (g)-RW ,n (g )∣≤ 丁 严远,
g∈G	ε2	2n
as soon as n ≥ 2log(2∕δ)∕ε2.
proof. Apply twice the Taylor expansion
1	1 x-a (x -a)2
x a a2	xa2 ,
so as to get
1	1 n0+ ∕n - q (n0+∕n - q)2
		=	- - -τ	 + 	--,
n0+ ∕n-------------------------------q q2-q2n0+ ∕n
1	1	n0-∕n - 1 + q	(n0- ∕n - 1 + q)2
—:  = ------------------------Z  + --------Z------
n-/n	1 - q (1 - q)2	(1 - q)2n-/n
This yields the decomposition
eb*,n(g) - Rw*,n(g) = -qp	一 Q^ n^ X Hg(Xi) = -1, Yi = +1}
—
斤% (n- - 1 + q!1 X I{g(X0) = +1, Yi = -1} + 丝丝21 X I{g(X0) = -1, Yi = +1}
(1 - q)2 n	n i=1	i	i	q2ni+ ∕n	n i=1	i	i
+
(1-/n- 21 + 1 )21 X I{g (X0)
(1 - q)2 n0- ∕n n i=1	i
=+1, Yi0 = -1}.
12
Under review as a conference paper at ICLR 2020
We deduce that
IR6,n(g) - ew',n(g)1 ≤ n +/n2 ql (2p + 1 + n+/n - q|(n+pn + T-⅛M!!.
By virtue of Hoeffding inequality, we obtain that, for any δ ∈ (0, 1), we have with probability larger
than 1 - δ:
n +/n - q∣≤ E，
so that, in particular, min{n +/n, 1 - n +/n} ≥ ε - {log(2∕δ)∕(2n). This yields the desired result.
Alternative approach for Positive-Unlabeled Learning


Theorem 3. Let b； = b(Xi, Y0) for all i ∈ {1,..., n} with b defined in (13). Suppose that the
—
hypotheses of Lemma 5 are fulfilled. Let ^gn be any minimizer of Rb*,n over class G. We have with
probability at least 1 - δ:
RP(en)-inf Rp(g) ≤ 2max(p,1- P) ∣E[RRn(G)] + JIoQ/δ]+ 42 J^g4/^ +4supbb(ɪ)-η(x)|,
g∈G	ε	Vn	ε2 V	2n	x∈χ
as soon as n ≥ 2log(4/6)/£2.
proof. Observe first that ∣∣Φ∣∣∞ ≤ maxk pk/ε and
Rp(en) - inf RP(θ) ≤ 2 SUP 1R病,n(θ) - Rw；,n同 + 2 SUP ew；,n(θ) - (RPo
θ∈Θ	θ∈Θ	θ∈Θ
The result then directly follows from the aPPlication of Lemmas 1-5 combined with the union bound.
Lemma 5. Let weights wb； be defined as in Theorem 3. Let ε ∈ (0, 1/2). Suppose that q ∈ (ε, 1 - ε).
For any δ ∈ (0, 1), we have with probability larger than 1 - δ:
suPIIRwb；,n(g) -Rw；,n(g)
g∈G
≤ W Jlog；2/" + 2 sup b(x) - η(x)|,
ε	2n	x∈X
as soon as n ≥ 2log(2/6)/*2.
proof.
Apply twice the Taylor expansion
1	1 x - a	(x - a)2
x a	a2	xa2 ,
so as to get
1	1 n0+ /n - q (n0+ /n - q)2
		=	- - -τ	 + 	---,
n0+ /n-------------------------q	q2-q2n0+ /n
1	1	n0-/n - 1 + q (n0- /n - 1 + q)2
		=		-	Z	 + 	Z-.
n-/n-------------------------------------1 - q-(1 - q)2-(1 - q)2n-/n
This yields the decomposition
e病,n (g) - Rw；, n (g) =- q (~n+ 一 q) n XI{ g(Xi) = -1, Yi = +1}
-(i⅛(=τ+q! nX (1-b( Xi))I松 (Xi)=+1,Y=-1}+p⅞n⅛q)2 nX 典 (Xi)=-1,Y=+1}
+(n*;/*X (1-b( Xi))I故 (Xi)=+1,Y=-1}+(τ⅛X (η( Xi)-b( Xi))I故 (Xi)=+1,Y=-1}.
13
Under review as a conference paper at ICLR 2020
We deduce that
Rb∙,n(g) - Rw∙,n(g)1 ≤	In+/n	q1(1 +	In +/n	- ql	(-1-	+ -j-10-γ-1) +	n-/n	SUP b(ɪ) -	η(x)|.
ε2	+ n0+/n 1 - n0+/n	1 - q	x∈X
By virtUe of Hoeffding ineqUality, we obtain that, for any δ ∈ (0, 1), we have with Probability larger
than 1 - δ:
n+/ n - q ∣≤ rogF，
so that, in particular, min{n +/n, 1 - n +/n} ≥ ε - ,log(2∕δ)∕(2n). Moreover, still under this event,
n-/n ≤ 2(1 - q) if n ≥ log(2/6)/(2£2). This yields the desired result.
Appendix - Extension to Iterative WERM
As highlighted in Remark 2, the importance function can be expressed as a function of the ideal
decision function in certain situations: Eq. (12) involves the regression function η(x), that defines
the optimal (Bayes) classifier g*(X) = 2I{η(x) ≥ 1/2} - 1. This simple observation paves the way
for a possible incremental application of the WERM approach: in the case where the solution of
the WERM problem considered outputs an estimate of the optimal decision function, it can be next
re-used for defining and solving a novel WERM problem. Whereas binary classification based on
PU data only aims at recovering a single level set of the posterior probability η(x), it is not the case
of a more ambitious statistical learning problem, referred to as bipartite ranking, for which such an
incremental version of WERM can be described.
Bipartite ranking based on PU data. In bipartite ranking, the statistical challenge consists of
ranking all the instances x ∈ X through a scoring function s : X → R in the same order as the
likelihood ratio Ψ(X) = (dF+ /dF-)(X), or, equivalently, as the regression function η(x) = P{Y =
+1 I X = x}, x ∈ X: the higher the score s(X), the more likely one should observe Y = +1. Let
S = {s : X → R measurable} denotes the set of all scoring functions on the input space X. A classical
way of measuring "how much stochastically larger" a distribution G on R than another one, H say,
consists in drawing the "probability-probability plot":
t∈R7→ (1 -H(t), 1 - G(t)),
with the convention that possible jumps are connected by line segments (in order to guarantee the
continuity of the curve). Equipped with this convention, this boils down to plot the graph of the
mapping
ROCh,G : α ∈ (0,1) → ROCh,g = 1 -0。H-1(1 - α),
where Γ-1(u) = inf{t ∈ R : Γ(t) ≥ u} denotes the pseudo-inverse of any cumulative distribution
function Γ(t) on R. The closer to the left upper corner of the unit square [0, 1]2, the larger the
distribution G is compared to H in a stochastic sense. This approach is known as ROC analysis. The
gold standard for evaluating the ranking performance of a scoring function s is thus the ROC curve:
ROCs d=ef ROCFs,-,Fs,+,
where Fs,+ and Fs,- denote the conditional distributions of s(X) given Y = +1 and given Y = -1
respectively, i.e. the images of class distributions F+ and F- by the mapping s(x). Indeed, it follows
from a standard Neyman-Pearson argument that the ROC curve ROC* of strictly increasing transforms
of η(x) is optimal with respect to this criterion in the sense that:
∀α∈ (0, 1), ROCs(α) ≤ ROC*(α),
for any scoring function S. We set S* = {T ◦ η : T : (0,1) :→ R}. A summary quantity of this
functional criterion that is widely used in practice is the Area Under the ROC Curve (AUC in short),
given by:
AUC(s)
Z1
α=0
ROCs (α) dα,
for s ∈ S. Beyond its scalar nature, an attractive property of this criterion lies in the fact that it can be
interpreted in a probabilistic manner, insofar as we have the relation: ∀s ∈ S,
AUC(s) = P {s(X) < s(X，) ∣ (Y Yz) = (-1, +1)} + 2P {S(X) = S(X，) I (Y, Yz) = (-1, +1)}.
14
Under review as a conference paper at ICLR 2020
Denoting by (Xi, Yi), i ∈ {1, 2}, independent copies of the pair (X, Y) and placing ourselves in the
situation where S(X)'s distribution is continuous, as observed in ClemengOn et al. (2008), we have
AUC(s) = 1 - LP(s)∕(2P(1 - P)), where
LP(s) d=ef P {(s(X1) - s(X2))(Y1 -Y2))<0},
is the ranking risk, the theoretical rate of discording pairs namely, that can be viewed as a pairwise
classification risk. Hence, bipartite ranking can be formulated as the problem of learning a scoring
function s that minimizes the ranking risk
dP	dP
Lp(S) = EP柩P0 dP (X0, y0) dP (X2, y0) × I {(S(X0) - S(X2))(K- Y0)) < 0}.
CtrJ	CtrJ
Now, using Eq. (12) and the fact that η = PΨ∕(1 - P + PΨ), We have:
dp(χ, y) =	Φ(χ,y)	= pI{y =	+1}+ 1]	η(X)I{y = -1}	= PI{y	= +1}+ ∩—诉1~p+ 甲(CI{y = -1}.
dP0	q	1	- q	q	(1 - q)(1 - P + PΨ(X))
Therefore, it has been shown in Clemengon & Vayatis (2009) (see Corollary 5 therein) that for any S*
in S*,
dF+ (X) = dF,+(S*(X)) almost-surely.
dF -	dFS *,-
For any S candidate, setting ΨS (x) = dFS,+ ∕dFS,-(S(x)), one can define
Φ S (X, y) = P I{y = +1} +-------1--p-----------1{ y = -1}.
q	(1 - q)(1 - P + PΨS(S(X)))'	'
From this formula, it is the easy to see how an incremental use of the WERM could be implemented.
•	Start from an initial guess S for the optimal scoring functions (e.g. solve the empirical
ranking risk minimization problem ignoring the bias issue)
•	Estimate ΦS from the (Xi0, Yi0)’s and the knowledge of P, observing that one is not confronted
with the curse of dimensionality in this case
•	Solve the Weighted Empirical Ranking Risk Minimization problem using the weight function
ΦS(X1, y1)ΦS(X2, y2),
which produces a new scoring function S and iterate.
Investigating the performance of such an incremental procedure will be the subject of future research.
Appendix - Inaccurate Prior Information about the Test Distribution
As noticed in section 2, it may happen that the rate of positive instances in the target population is
approximately known only. Suppose that our guess for P is eP such that |P - eP| ≤ ζ, with ζ ∈ (0, 1).
Denote by P the distribution over X × {-1, +1} under which X is drawn from ePF+ + (1 - eP)F- and
such that P(xy卜Α{Y = 1 | X = x} = P(x,γ卜P{Y = 1 | X = x} = η(x).
By a change of measure we have,
Pe(Y，g(X))	=	Pp(Y，g(X))	+	EP	[ dP (X,	Y)-1)I{Y ,	g(X)},
< • < 11	. 1	1 .1	1 • . 1'	1' .ι 1	∙ r∙	• 1 r∙	ι >Λ ι 7ζ
which allows to bound the difference of the classification risks ofg under P and P:
∣- ---
dP
∣Re(g) -Rp(g)∣ ≤ EP dP(x, y) - 1
2|eP - P| ≤ 2ζ.
Appendix - Additional Numerical Experiments
In this Appendix, more details about the experiments carried out are provided.
15
Under review as a conference paper at ICLR 2020
Importance of reweighting for simple distributions
Introduce a random pair (X, Y) in [0, 1] × {-1, +1} where X | Y = +1 has for probability density
function (pdf) f+(x) = (1 + α)xα, α > 0 and X | Y = -1 has for pdf f-(x) = (1 + β)(1 - x)β,β > 0. As
in Section 2, the train and test datasets have different class probabilities p0 and p for Y = +1. The
loss ` is defined as `(θ, z) = I{(x - θ)y ≥ 0} where θ > 0 is a learnt parameter.
The true risk can be explicitely calculated. For θ > 0, we have
RP(θ) = pθ1+α + (1 - p)(1 -θ)1+β,
and the optimal threshold θp can be found by derivating the risk Rp(θ). The derivative is zero when θ
satisfies
p(1 + α)θα = (1 - p)(1 + β)(1 - θ)β.	(14)
Solving eq. (14) is straightforward for well-chosen values of α, β, which are detailed in fig. 4. The
excess error E(p0, p) = RP(θp,) - RP(θp) for the diagonal entries of fig. 4 are plotted in fig. 5, in the
infinite sample case.
	(α,β)		
	(0, 0)	(1/2,1/2)	(1,1)	(2, 2)
印	r∩ i] [0, 1]	(I- P)2	1 _	√-p
θp		P 2+(1- p )2	ɪ p	√p + vɪ-p
a = 0,β = 0
Figure 4: Optimal parameters θ* for different values of α,β.
a = 1, β = 1
ι.o
a = 0,β = 0
0.8
0.6
d
0.4
0.2
0.00 0.25 0.50 0.75 1.00
P'
0.0
0.2
0.4
0.6
0.8
1.0
a = 0.5,6 =0.5
a=l,β = l
o
ι.o
0.0	------
0.00 0.25 0.50 0.75 1.00
P'
0.8
0.6
0.4
0.2
0.0	-------
0.00 0.25 0.50 0.75 1.00
P'
0
8
6
4
0
2
0
0.0
0.00 0.25 0.50 0.75 1.00
P'
0
8
0
6
0
4
0
2
o
Figure 5:	Pdf’s and values of the excess risk E(p0,p) for different values of α,β.
The results of fig. 5 show that the optimum for the train distribution is significantly different from the
optimum for the test distribution for the excess risk when the problem involves Bayes noise.
Generalities on real data experiments
Strategy to induce bias in balanced datasets In the two real data experiments described in the
part concerning the MNIST experiment in the Appendix and in Section 4, the same strategy is used
to induce class distribution bias or strata bias. Since both experiments involve a small test dataset, it
16
Under review as a conference paper at ICLR 2020
is kept intact, while we discard elements of the train dataset to induce bias between the train and test
datasets. The bias is parameterized by a single parameter γ, such that when γ is close to one, there is
little strata or class bias, while when γ approaches 0, bias is extreme.
The bias we induce is inspired by a power law, which is often used to model unequal distributions.
Each value of a modality, i.e. a possible value of the stratum or class of an instance, is given by one of
the values of the power law at random. Formally, the target train distribution {p0k}kK=1 over a modality
S ∈ {1, . . . , K}, is defined for all 1 ≤ k ≤ K as
b K/2」
---7ΓΓ-
P 0 =	Y "σ( Pk
Pk κ	_LK/2J	,
ΣK=1Y σ(k) Pk
where σ is a random permutation in {1, . . . , K}.
To generate a train dataset with modality distribution {P0k}kK=1, we sample instances from the original
train data set D° = {(Xi, Yi, S；)}3, where Yi is the class, Si is the modality. For MNIST experiment,
Si0 = Yi0, while for Section 4, the value Si0 is the stratum of the instance i. The output of the train
dataset is noted Dn , see Algorithm 1 for the detailed algorithm of the train dataset generation.
Algorithm 1 Biased training dataset generation
Data: DDn = {(X Y" S；)}?」{PPk}晨
Result: Dn
D JG # Initialize the result index set.
for k = 1, . . . , K do
I Ik J {i | 1 ≤ i ≤ n, Si = k}	# Count the candidates for each modality.
end
msamp J min(#I1 , . . . , #IK)
while msamP > 0 do
m1 , . . . , mK J M(msamp , P1 , . . . , PK)	# M is the multinomial law.
for k = 1, . . . , K do
I Dk J RandSet(mk, Ik)	# RandSet(n, X) is a random subset ofn elements ofX.
I Ik J Ik \ Dk
end
msamp J min (#I1 , . . . , #IK )
DJD∪ SK Dk
end
Dn J {(Xii, Yii, S ii) | i∈D}
Return Dn
Models Both MNIST and ImageNet experiments compare two models: a linear model and a
multilayer perceptron (MLP) with one hidden layer. Given a classification problem of input x of
dimension d with K classes, precisely with d = 784, K = 10 for MNIST and d = 2048, K = 1000
for ImageNet data, a linear model simply learns the weights matrix W ∈ Rd×K and the bias vector
b ∈ RK and outputs logits l = W>x + b. On the other hand, the MLP has a hidden layer of
dimension h = L(d + K)/2J and learns the weights matrices W1 ∈ Rd,h, W2 ∈ {h, K} and bias vectors
b1 ∈ Rh, b2 ∈ RK and outputs logits l = W2>h(W1>x + b1) + b2 where h is the ReLU function, i.e.
h : x 7→ max(x, 0). The number of parameters for each dataset and each model is summarized in
table 1.
The weight decay or l2 penalization for the linear model and MLP model are written, respectively
P = 2 IWk and P = ∣ k W1k + ɪ k W1k.
Cost function The cost function is the Softmax Cross-Entropy (SCE), which is the most used
classification loss in deep learning. Specifically, given logits l = (l1, . . . , lK) ∈ RK, the softmax
function is γ : Rk → [0, 1]K with γ = (γ1, . . . ,γK) and for all k ∈ {1, . . . , K},
exp(lk)
γk: l →	----------
PKj=0 exp(lj)
17
Under review as a conference paper at ICLR 2020
Database	Model	
	Linear	MLP
MNIST	7,850	315,625
ImageNet	2,049,000	4,647,676
Table 1: Number of parameters for each model.
Experiment	MNIST - Section 5	ImageNet - Section 4
Net weights std init σ0	0.01	0.01
Weight decay λ Unif	0.01	0.002
Weight decay λ Strata	X	0.003
Weight decay λ Class	0.01	0.003
Weight decay λ Sym data	X	0.001
Learning rate η	0.01	0.001
Momentum γ	0.9	0.9
Batch size B	1,000	1,000
MLP hidden layer size h	397	1,524
Figure 6:	Parameters of the MNIST and ImageNet experiments - Section 5 and Section 4.
Given an instance with logits l and ground truth class value y, the expression of the softmax cross-
entropy c(l, y) is
K
c(l, y) =	I{y = k} log (γk(l)) .
k=1
The loss that is reweighted depending on the cases as described in Section 3 is this quantity c(l, y).
The loss on the test set is never reweighted, since the test set is the target distribution. The weights
and bias of the model that yield the logits are tuned using backpropagation on this loss averaged on
random batches of B elements of the training data summed with the regularization term λ ∙ P where λ
is a hyperparameter that controls the strength of the regularization.
Preprocessing, optimization, parameters The images of ILSVRC were encoded using the im-
plementation of ResNet50 provided by the library keras2, see Chollet et al. (2015), by taking the
flattened output of the last convolutional layer.
Optimization is performed using a momentum batch gradient descent algorithm, which updates the
parameters θt at timestep t with an update vector vt by performing the following operations:
Vt = γ Vt-1 + nV C (θt-ι),
θt = θt-1 - vt,
where η is the learning rate and γ is the momentum, as explained in Ruder (2016).
The parameters of the learning processes are summarized in fig. 6. The weight decay pa-
rameters λ were cross-validated by trying values on a logarithmic scale, e.g. for ImageNet
{10-4, 10-3, 10-2, 10-1, 1} and then trying more fine-grained values between the two best results,
e.g. for ImageNet 10-3 was best and 10-2 was second best so we tried {0.002, 0.003, 0.004, 0.005}.
The standard deviation initialization of the weights was chosen by trial-and-error to avoid overflows.
The learning rate was fixed after trying different values to have fast convergence while keeping good
convergence properties.
Stratified information for ImageNet In this section, we detail the data preprocessing necessary
to assign strata to the ILSVRC data. These were constructed using a list of 27 high-level categories
found on the ImageNet website3 copied in Figure 7. Each ILSVRC image has a ground truth low
2https://keras.io/applications/
3 http://www.image-net.org/about-stats
18
Under review as a conference paper at ICLR 2020
categories	# synset	# images per synset	Total # images
amphibian	94	591	56K
animal	3822	732	2799K
appliance	51	1164	59K
bird	856	949	812K
covering	946	819	774K
device	2385	675	1610K
fabric	262	690	181K
fish	566	494	280K
flower	462	735	339K
food	1495	670	1001K
fruit	309	607	188K
fungus	303	453	137K
furniture	187	1043	195K
geological formation	151	838	127K
invertebrate	728	573	417K
mammal	1138	821	934K
musical instrument	157	891	140K
plant	1666	600	999K
reptile	268	707	190K
sport	166	1207	200K
structure	1239	763	946K
tool	316	551	174K
tree	993	568	564K
utensil	86	912	78K
vegetable	176	764	135K
vehicle	481	778	374K
person	2035	468	952K
Figure 7:	Original categories used to construct the strata for the experiment of Section 4.
19
Under review as a conference paper at ICLR 2020
level synset, either from in the name of the training instance, or in the validation textfile for the
validation dataset, that is provided by the ImageNet website. The ImageNet API 4 provides the
hierarchy of synsets in the form of is-a relationships, e.g. a flamingo is a bird. Using this information,
for each synset in the validation and training database, we gathered all of its ancestors in the hierarchy
that were in the table fig. 7. Most of the synsets had only one ancestor, which then accounts for
one stratum. Some of the synsets had no ancestors, or even several ancestors in the table, which
accounts in for extra strata, either a no-category stratum or a strata composed of the union of several
ancestors. The final distribution of the dataset over the created strata is summarized by Figure 8.
Observe the presence of a no_strata stratum and of unions of two high-level synsets strata, e.g.
n00015388_n01905661. A definition provided by the API of each of the synsets involved in the strata
strata
Figure 8: Distribution of the ImageNet train dataset over the created strata which definitions are given
in fig. 9 .
is given in fig. 9.
Classes bias experiment for MNIST
The impact of the bias correction in the multi-class supervised learning setting described in Section 2
is illustrated on a widely used dataset for studying classification tasks: the MNIST dataset.
The MNIST dataset is composed of images X ∈ Rd of digits and labels being the value of the digits.
In our experiment, we learn to predict the value of the digit so we have K = 10 classes corresponding
to digits between 0 and 9. The dataset contains 60, 000 images for training and 10, 000 images for
testing, all equally distributed within the classes. There is therefore no class bias between train and
test samples in the original dataset.
Bias between classes is induced using the power law strategy described above. We deal with the
classification task associated to (X, Y) with a linear model or a MLP with one hidden layer that
optimizes the softmax cross-entropy (SCE) using momentum gradient descent. We compare the
uniform weighting of each instance in the train set (corresponding to the case where there is no
reweighting described in eq. (2)) with the reweighting of each instance using the proportion of
each label Y for the train and test datasets as described in eq. (7). Precisions about the model
and parameters are given in paragraph dealing with Preprocessing, optimization, parameters in the
Appendix.
The optimization dynamics are summarized in fig. 10. We report the median over 100 runs of these
values for the test set and a fixed random sample of the train set. For the test set, we represent 95%
confidence-intervals in a lighter tone. The x-axis corresponds to the number of iterations of the
learning process.
4http://image-net.org/download-API
20
Under review as a conference paper at ICLR 2020
Strata name		Definition	
n00015388	n01861778	animal, animate being, beast (. . . )	mammal, mammalian
no strata			
n03183080		device	
n03122748		covering	
n04524313		vehicle	
n00015388	n01905661	animal, animate being, beast (. . . )	invertebrate
n00015388	n01503061	animal, animate being, beast (. . . )	bird
n04341686		structure, construction	
n00015388	n01661091	animal, animate being, beast (. . . )	reptile, reptilian
n03183080	n03800933	device	musical instrument, instrument
n03405725		furniture, piece of furniture, (. . . )	
n13134947		fruit	
n00015388	n02512053	animal, animate being, beast (. . . )	fish
n07707451		vegetable, veggie, veg	
n04451818		tool	
n02729837		appliance	
n09287968		geological formation, formation	
n04285146		sports equipment	
n00015388	n01627424	animal, animate being, beast (. . . )	amphibian
n07566340		foodstuff, food product	
n12992868		fungus	
n04516672		utensil	
n03309808		fabric, cloth, material, textile	
n00015388		animal, animate being, beast (. . . )	
n00017222	n11669921	plant, flora, plant life	flower
n02729837	n03183080	appliance	device
n03183080	n04451818	device	tool
n03122748	n03183080	covering	device
n04285146	n04524313	sports equipment	vehicle
n04341686	n04524313	structure, construction	vehicle
n07566340	n07707451	foodstuff, food product	vegetable, veggie, veg
n03183080	n04524313	device	vehicle
Figure 9: Definitions of the strata created for the experiments in Section 4, which frequencies are
given in fig. 8.
21
Under review as a conference paper at ICLR 2020
Comparison of pk’s and p0k’s.
MLP model: cost.
Figure 10: Dynamics for the class reweighting experiment with MNIST.
sal s--ς
Linear model: miss rate.
MLP model: miss rate.
For the uniform weights, we see that the misclassification rate is pretty low for the train set, but poor
for the test set. By reweighting the instances, we see that we favor low error over the test set, which
gives a miss probability reduced by half.
22