Under review as a conference paper at ICLR 2020
Wildly Unsupervised Domain Adaptation and
Its Powerful and Efficient Solution
Anonymous authors
Paper under double-blind review
Ab stract
In unsupervised domain adaptation (UDA), classifiers for the target domain (TD) are
trained with clean labeled data from the source domain (SD) and unlabeled data from TD.
However, in the wild, it is hard to acquire a large amount of perfectly clean labeled data in
SD given limited budget. Hence, we consider a new, more realistic and more challenging
problem setting, where classifiers have to be trained with noisy labeled data from SD and
unlabeled data from TD—we name it wildly UDA (WUDA). We show that WUDA ruins
all UDA methods if taking no care of label noise in SD, and to this end, we propose a
Butterfly framework, a powerful and efficient solution to WUDA. Butterfly maintains four
models (e.g., deep networks) simultaneously, where two take care of all adaptations (i.e.,
noisy-to-clean, labeled-to-unlabeled, and SD-to-TD-distributional) and then the other two
can focus on classification in TD. As a consequence, Butterfly possesses all the conceptually
necessary components for solving WUDA. Experiments demonstrate that under WUDA,
Butterfly significantly outperforms existing baseline methods.
1 Introduction
Domain adaptation (DA) aims to learn a discriminative classifier in the presence of a shift between training
data in source domain and test data in target domain (Ben-David et al., 2010; Ganin and Lempitsky, 2015;
Xiao and Guo, 2015; Zhang et al., 2015; 2013). Currently, DA can be divided into three categories: supervised
DA (Tzeng et al., 2015), semi-supervised DA (Guo and Xiao, 2012) and unsupervised DA (UDA) (Saito et al.,
2017). When the number of labeled data is few in target domain, supervised DA is also known as few-shot
DA (Motiian et al., 2017). Since unlabeled data in target domain can be easily obtained, UDA exhibits the
greatest potential in the real world (Ganin and Lempitsky, 2015; Ganin et al., 2016; Gong et al., 2012; 2016;
Long et al., 2015; Saito et al., 2017; 2018).
UDA methods train with clean labeled data in source domain (i.e., clean source data) and unlabeled data
in target domain (i.e., unlabeled target data) to obtain classifiers for the target domain (TD), which mainly
consist of three orthogonal techniques: integral probability metrics (IPM) (Ghifary et al., 2017; Gong et al.,
2016; Gretton et al., 2012; Lee and Raginsky, 2018; Long et al., 2015), adversarial training (Ganin et al.,
2016; Gong et al., 2018; Hoffman et al., 2018; Li et al., 2018; Saito et al., 2018; Tzeng et al., 2017) and
pseudo labeling (Saito et al., 2017). Compared to IPM- and adversarial-training-based methods, the pseudo-
labeling-based method (i.e., asymmetric tri-training domain adaptation (ATDA) (Saito et al., 2017)) can
construct a high-quality target-specific representation, providing a better classification performance.
However, in the wild, the data volume of source domain tends to be large. To avoid the expensive labeling
cost, labeled data in source domain normally come from amateur annotators or the Internet (Lee et al., 2018;
Schroff et al., 2011; Tommasi and Tuytelaars, 2014). This brings us a new, more realistic and more challenging
problem, wildy unsupervised domain adaptation (abbreviated as WUDA, Figure 1). This adaptation aims to
1
Under review as a conference paper at ICLR 2020
The blue line denotes that UDA transfers knowledge from
clean source data (Ps) to unlabeled target data (Pxt). How-
ever, perfectly clean data is hard to acquire. This brings wildly
unsupervised domain adaptation (WUDA), namely transfer-
ring knowledge from noisy source data (Ps) to unlabeled target
data (Pxt). Note that label corruption process (black dash line)
is unknown in practice. To handle WUDA, a compromise so-
lution is a two-step approach (green line), which sequentially
combines label-noise algorithms (Ps → Ps , label correction)
and existing UDA (Ps → Pxt ). This paper proposes a ro-
bust one-step approach called Butterfly (red line, Pes → Pxt
directly), which eliminates noise effects from PS.
Figure 1:	Wildly unsupervised domain adaptation (WUDA).
transfer knowledge from noisy labeled data in source domain (Ps, i.e., noisy source data) to unlabeled target
data (Pxt). Unfortunately, existing UDA methods share an implicit assumption that there are no noisy source
data. Namely, these methods focus on transferring knowledge from clean source data (Ps) to unlabeled target
data (Pxt ). Therefore, these methods cannot well handle the WUDA.
To validate this fact, we empirically reveal the deficiency of existing UDA methods (Figure 2). To improve
these methods, a straightforward solution is a two-step approach. In Figure 1, we can first use label-noise
algorithms to train a model on noisy source data, then leverage this trained model to assign pseudo labels
for noisy source data. Via UDA methods, we can transfer knowledge from pseudo-labeled source data (Ps)
to unlabeled target data (Pxt). Nonetheless, pseudo-labeled source data are still noisy, and such two-step
approach may not eliminate noise effects.
To circumvent the issue of two-step approach, we present a robust one-step approach called Butterfly. In
high level, Butterfly directly transfers knowledge from Ps to Pxt, and uses the transferred knowledge to
construct target-specific representations. In low level, Butterfly maintains four networks dividing two branches
(Figure 3): Two networks in Branch-I are jointly trained on noisy source data and pseudo-labeled target data
(data in mixture domain (MD)); while two networks in Branch-II are trained on pseudo-labeled target data.
The reason why Butterfly can be robust takes root in the dual-checking principle (DCP): Butterfly checks
high-correctness data out, from not only the data in MD but also the pseudo-labeled target data. After cross-
propagating these high-correctness data, Butterfly can obtain high-quality domain-invariant representations
(DIR) and target-specific representations (TSR) simultaneously in an iterative manner. If we only check
data in MD (i.e., single checking), the error existed in pseudo-labeled target data will accumulate, leading to
low-quality DIR and TSR.
We conduct experiments on simulated WUDA tasks, including 4 MNIST-to-SYND tasks, 4 SYND-to-MNIST
tasks and 24 human-sentiment tasks. Besides, we conduct experiments on 3 real-world WUDA tasks.
Empirical results demonstrate that Butterfly can robustly transfer knowledge from noisy source data to
unlabeled target data. Meanwhile, Butterfly performs much better than existing UDA methods when source
domain (SD) suffers the extreme (e.g., 45%) noise.
2 Wildly Unsupervised Domain Adaptation
In this section, we first define a new, more realistic and more challenging setting called wildly unsupervised
domain adaptation (WUDA), and explain the nature of WUDA. Then, we empirically show that representative
UDA methods cannot handle WUDA well, which motivates us to propose Butterfly (see Section 3).
Definition 1 (Wildly Unsupervised Domain Adaptation). Let Xt be a multivariate random variable defined
on the space X with respective a probability density pxt, (Xs, Ys) be a multivariate random variable defined
2
Under review as a conference paper at ICLR 2020
(a) Symmetry-flip noise: S→M (left), M→S (right)	(b) Pair-flip noise: S→M (left), M→S (right)
Figure 2:	WUDA ruins representative UDA methods. Representative UDA methods includes deep adaptation
networks (DAN, a IPM based method (Long et al., 2015)), domain-adversarial neural network (DANN, a
adversarial training based method (Ganin et al., 2016)), asymmetric tri-training domain adaptation (ATDA, a
pseudo-label based method (Saito et al., 2017)) and transferable curriculum learning (TCL, a robust UDA
method (Shu et al., 2019)). B-Net is our proposed WUDA method. We report target-domain accuracy of all
methods when the noise rate of source domain changes (a) from 5% to 70% (symmetry-flip noise) and (b)
from 5% to 45% (pair-flip noise). Clearly, when the noise rate of source domain increases, target-domain
accuracy of representative UDA methods drops quickly while that of B-Net keeps stable consistently.
on the space XX C with respective a probability density PS, where C = {1,..., K}. Let Pxs be the marginal
probability density of PS. Given i.i.d. data D S = {(xsi ,ysi)}n= 1 and Dt = {xti }n= 1 drawn from PS and
Pxt, in wildly unsupervised domain adaptation, we aim to train with DS and Dt to accurately annotate data
drawn from Pxt, where Pxs 6= Pxt.
Remark 1. In Definition 1, DPS is noisy source data, Dt is unlabeled target data, and PPS and Pxt are two
probability measures corresponding to densities PPS (xS , yPS) and Pxt (xt).
Nature of WUDA. Specifically, there are five distributions involved in WUDA setting: 1) a marginal
distribution on source data, i.e., Pxs in Definition 1; 2) a marginal distribution on target data, i.e., Pxt in
Definition 1; 3) an incorrect conditional distribution of label given xS, q(yS|xS); 4) a correct conditional
distribution of label given xS, P(yS|xS) and 5) a correct conditional distribution of label given xt, P(yt|xt).
Based on Definition 1 and Appendix A.2, noisy source data DS are drawn from PPS(xS, yS) = Pxs (xS)((1 -
ρ)p(ys ∣xs) + ρq(ys∣xs)), where P IS the noise rate in source data. Namely, source data Ds are mixture of
correct source data from Pxs (xS)P(yS|xS) and incorrect data from Pxs (xS)q(yS|xS). Target data Dt are drawn
from Pxt . In WUDA setting, we aim to train a classifier with DP s and Dt. This classifier is expected to
accurately annotate data fromPxt, i.e., to accurately simulate distribution 5).
WUDA ruins representative UDA methods. We take a simple example to illustrate why WUDA ruins
representative UDA methods. We corrupt source data using symmetry flipping (Patrini et al., 2017) and pair
flipping (Han et al., 2018) (Appendix B). Namely, the corrupted source data (Ds in Definition 1) are drawn
from PS whose density is PS (XS ,Vs) = Pxs (XS )((1 — P)P(ys ∣Xs) + ρq (ys ∣Xs)). We draw the target data Dt
from Pxt whose density is Pxt. To instantiate source and target data, we leverage MNIST and SYND (Figure 6
in Appendix C), respectively.
Thus, we first construct two WUDA tasks with symmetry-flip noise: corrupted SYND→MNIST (S→M) and
corrupted MNIST →SYND (M→S). In Figure 2 (a), we report target-domain accuracy of representative UDA
methods, when the noise rate ρ of SD changes from 5% to 70%. Itis clear that target-domain accuracy of these
representative UDA methods drops quickly when ρ increases. This means that WUDA ruins representative
UDA methods. Then, we construct another two WUDA tasks with pair-flip noise. In Figure 2 (b), we report
target-domain accuracy, when the noise rate ρ of SD changes from 5% to 45%. Again, WUDA still ruins
representative UDA methods. Note that pair-flip noise is much harder than symmetry-flip noise, and its noise
rate cannot be over 50% in practice (Han et al., 2018).
3
Under review as a conference paper at ICLR 2020
DIR
I I Noisy source data 口 Pseudo-Iabeled target data
F1
F2
Ft1
Ft2
Figure 3: Butterfly Framework. Two networks (F1 and F2) in Branch-I are jointly trained on noisy source
data and pseudo-labeled target data (mixture domain). Two networks in Branch-II (Ft1 and Ft2) are trained
on pseudo-labeled target data. By using dual-checking principle, Butterfly checks high-correctness data out
from both mixture and pseudo-labeled target data. After cross-propagating checked data, Butterfly can obtain
high-quality domain-invariant representations (DIR) and target-specific representations (TSR) simultaneously
in an iterative manner. Note that the interaction between DIR and TSR happens via the shared CNN. Besides,
in the first training epoch, since we do not have any pseudo-labeled target data, we need to use noisy source
data as the pseudo-labeled target data, which follows Saito et al. (2017).
However, the proposed Butterfly network (abbreviated as B-Net, Figure 3) performs robustly when ρ increases
(blue lines in Figure 2). In following sections, we will introduce Butterfly framework, and explain why
Butterfly achieves better target-domain accuracy consistently.
3	B utterfly: Towards robust one-step approach
To realize a robust WUDA approach, we propose a Butterfly framework (a one-step approach, Algorithm 1),
which trains four networks dividing into two branches (Figure 3). By using DCP, Branch-I checks which data
is correct in MD; while Branch-II checks which pseudo-labeled target data is correct. To ensure these checked
data highly-correct, we apply the small-loss trick based on memorization effects of deep learning (Arpit et al.,
2017). After cross-propagating these checked data (Bengio, 2014), Butterfly can obtain high-quality DIR and
TSR simultaneously in an iterative manner.
Loss function in Butterfly. Four networks trained by Butterfly share the same loss function but with
different inputs.
1n
L(O,u; F,D) = ^n--Eui'(F(χi),yi),
i=1uii=1
(1)
where n is the batch size, and F represents a network (e.g., F1,F2,Ft1 and Ft2). D = {(xi, yi)}n=ι is a
mini-batch for training a network, where {xi, yi}n=ι could be data in MD or TD (Figure 3), and θ represents
parameters of F and U = [uι,…，un]τ is an n-by-1 vector whose elements equal 0 or 1. '(∙, ∙) is the
cross-entropy loss. For two networks in Branch-I, following Saito et al. (2017), we also add a regularizer
l°Tιιθf2i∣ in their loss functions, where θfiι and θf 21 are weights of the first fully-connect layer of Fi and
F2 . With this regularizer, F1 and F2 will learn from different features.
Nature of the loss L. In loss function L, we have n instances: (xi, yi), where i = 1,2,...,n. For the
ith instance, we will compute its cross-entropy loss (i.e., '(F(χi),yi)), and we will denote this instance
as “selected” if ui = 1. Thus, the nature of L is actually the average value of cross-entropy loss of these
4
Under review as a conference paper at ICLR 2020
“selected” instances. Note that, we need to set a constrain to prevent Pin=1 ui = 0 in L, which means that we
need to select at least one instance to compute L.
Training procedure of Butterfly. For two networks in each branch, they will first check high-correctness
data out and then cross update their parameters using these data.
Based on loss function defined in Eq. (1), entire training procedures of Butterfly are shown in Algorithm 1.
First, We initialize training data for two branches (D) for Branch-I and DDl for Branch-II), four networks
(F1, F2, Ft1 and Ft2) and the number of pseudo labels (line 2). In the first epoch (T = 1), following Saito
et al. (2017), Dl is the same with DDS (i.e., We use noisy source data as pseudo-labeled target data) since We
cannot annotate pseudo labels for target data when T = 1. After mini-batch D is fetched from D (line 4),
F1 and F2 check high-correctness data out and update their parameters (lines 5) using Algorithm 2. Using
similar procedures, Ft1 and Ft2 also update their parameters using Algorithm 2 (lines 6-7).
In each epoch, after Nmax mini-batch updating, we randomly select nlt unlabeled target data and assign them
pseudo labels using F1 and F2 (lines 8). Following Saito et al. (2017), the Labeling function in Algorithm 1
(line 8) assigns pseudo labels for unlabeled target data, when predictions of F1 and F2 agree and at least
one of them is confident about their predictions (probability above 0.9 or 0.95). Using this function, we can
obtain the pseudo-labeled target data D)l for training Branch-II in the next epoch. Then, we merge Dl and
D)s to be D) for training Branch-I in the next epoch (line 9). Finally, we update n1, R(T) and Rt(T) in lines
10-11 according to Saito et al. (2017) and Han et al. (2018). Note that R(T) is a piecewise-defined linear
function. Namely, when T ≥ Tk, R(T) = 1 - τ; when T ≤ Tk, R(T) = 1 - T/Tk × τ.
In Algorithm 1, we use τ to represent the noise rate (i.e., the ratio of data with incorrect labels) in MD and use
τt to represent the noise rate in TD. However, in WUDA, we cannot obtain the ground-truth τ and τt . Thus,
we regard τ and τt as hyper-parameters. Note that τ and τt are robustly set to 0.4 and 0.05 in experiments.
Checking process in Butterfly. In Algorithm 2, we first obtain four inputs: 1) networks F1 and F2, and 2)
a mini-batch D, and 3) learning rate η and 4) remember rate α (line 1). Then, we will obtain the best u1 by
solving a minimization problem (line 2). L represents the loss function defined in Eq. (1). θ1 represents the
parameters of the network F1 . Similarly we will obtain the best u2 (line 3). θ2 represents the parameters of
the network F2 . Next, θ1 and θ2 are updated using gradient descent, where the gradients are computed using
a given optimizer (lines 4-5). Finally, we substitute the updated θ1 into F1 and the updated θ2 into F2 and
output F1 and F2 (line 6).
Solution to minimization problems in Algorithm 2. In line 2 or 3 in Algorithm 2, we need to solve a
minimization problem: minu，：iu，>a|D| L(θ, u0; F, D) and return the best u0 as U (uι in line 2 and u in
line 3). In this paragraph, we will show how to quickly solve this problem using a sorting algorithm. Recall
the nature of the loss L, we know L is the average value of cross-entropy losses of “selected” instances, and
1u0 is the number of these “selected” instances. Thus this minimization problem is equivalent to “given a
fixed F (F1 or F2) and n instances in D, how to select at least k instances such that L is minimized”, where
k = dα∣D∣e. To solve this problem, we first use a sorting algorithm (top_k function in TensorFlow) to sort
these n instances according to their cross-entropy losses '(Fι(χJ, yj. Then, we select k instance with the
smallest cross-entropy losses. Finally, let ui of these k instances be 1 and ui of the other instances be 0, and
we can get the best u = [u1, . . . , un]. The average value of cross-entropy losses of these k instances is the
minimized value of L(θ, u0; F, D) under the constrain 1u0 > α∣D∣.
4	B utterfly vs. Two-step Approach
This section analyzes why Butterfly is better than two-step approach using theoretical results in Appendix D.
Practitioner may safely skip it. Following Ben-David et al. (2010), we derive an upper bound of target-domain
risk for WUDA. Compared to existing UDA bounds, the WUDA bound has two extra terms (see Eq. (6)): ∆s
(noise effect from source data), and ∆t (noise effects from pseudo labels of target data). We will use ∆s and
∆t to show why Butterfly (a one-step approach) can eliminate noise effects while two-step methods cannot.
5
Under review as a conference paper at ICLR 2020
Algorithm 1 Butterfly Framework: quadruple training for WUDA problem
1:	Input Ds, Dt, learning rate η, fixed T, fixed τt, epoch Tk and Tmax, iteration Nmax, # of pseudo-labeled target data
ninit , max of ninit nt
,max;
2:	Initial Fι, F2, Ftι, F⅛, Dl = D§, D = D§, nt =电九加
for T = 1, 2, . . . , Tmax do
3:	Shuffle training set D;	// Noisy dataset
for N = 1, . . . , Nmax do
4:	Fetch mini-batch D from D;
5:	Update BranCh-I: F1,F2 = CheCking(F1 ,F2 ,D,η, R(T));	// Check data in MD using Algorithm 2
l
6:	Fetch mini-batch Dt from Dtl ;
7:	Update Branch-II: Ftι, Ft2 = CheCking(Ft 1, Ft2,Dt, η, Rt(T));	// Check data in TD using Algorithm 2
end
8:	Obtain Dl =Labelling(F1, F2,Dt,nt);
.	-_	~	~	~ 7
9:	Obtain D = DS ∪ DIt;
// Label Dt, following Saito et al. (2017)
// Update MD
10: Update nt = min{T∕20 * nt,ntmax}
11: Update R(T) = 1 一 min{Tτ, τ}, Rt(T) = 1 一 min{Tτt,τt};
end
12: Output Ft1 and Ft2
	
Algorithm 2 CheCking(F1, F2, D, η, α)	
1:	Input networks F1 , F2 , mini-batch D, learning rate η, remember rate α; 2:	Obtain uι = argminui：iui>a|D| L(θι, ul； Fι,D); 3:	Obtain u2 = argminu2：iu2>a|D| L(θ2, u2； F2,D); 4:	Update θι = θι 一 ηVL(θι, u2; Fι,D); 5:	Update θ2 = θ2 一 ηVU(θ2, ui； F2,D); 6:	Output F1 and F2	// Check high-correctness data // Check high-correctness data // Update θ1 // Update θ2
Two-step approach (a compromise solution). To reduce noise effects, a straightforward solution is two-
step approach. In the first step, we can train a classifier with noisy source data using Co-teaching (Han et al.,
2018) and use this classifier to annotate pseudo labels for source data. In the second step, we use ATDA
(Saito et al., 2017) to train a target-domain classifier with pseudo-label-source data and target data.
However, two-step approach may not reduce noise effects ∆s (i.e., not alleviating noise effects from source
data). In two-step approach, after using Co-teaching, ∆s will become pseudo-label-source effects ∆0s (see
Eq. (7)). The first part of ∆0s may be less than that of ∆s due to Co-teaching, but the second term of ∆0s may
be higher than that of ∆s since Co-teaching does not consider to minimize it. Thus, it is hard to say whether
∆0s < ∆s. This means that, the two-step approach may not really reduce noise effects ∆s. Besides, two-step
approach does not take care of eliminating ∆t explicitly. Based on above analysis, we can find that a two-step
approach cannot eliminate ∆s and ∆t .
One-step approach (Butterfly). To eliminate noise effects ∆ = ∆s + ∆t , Butterfly aims to select correct
data simultaneously from noisy source data and pseudo-labeled target data (see Section 3). Let ρs01 be the
probability that incorrect data is selected from noisy source data, and ρt01 be the probability that incorrect data
is selected from pseudo-labeled target data. Theorem 3 shows that ∆ → 0 if ρs01 → 0 and ρt01 → 0. Since
Butterfly can select correct data with a high probability (i.e., ρs01 → 0 and ρt01 → 0), noise effects will be
eliminated (∆ → 0).
6
Under review as a conference paper at ICLR 2020
(a) S20	(b) S45	(c) P20	(d) P45
Figure 4: Target-domain accuracy vs. number of epochs on four SYND→MNIST WUDA tasks.
5	Experiments
Simulated WUDA tasks. We verify the effectiveness of our approach on three benchmark datasets (vision
and text), including MNIST, SYN-DIGITS (SYND) and human-sentiment analysis (i.e., Amazon products
reviews on book, dvd, electronics and kitchen). They are used to construct 14 basic tasks: MNIST →SYND
(M→S), SYND→MNIST (S→M), book→dvd (B→D), book→electronics (B→E), . . . , and kitchen → elec-
tronics (K→E). These tasks are often used for evaluation of UDA methods (Ganin et al., 2016; Saito et al.,
2017; 2018). Since all source datasets are clean, we corrupt source data using symmetry flipping (Patrini et al.,
2017) and pair flipping (Han et al., 2018) (Appendix B) with noise rate ρ chosen from {0.2, 0.45}. So, for
each basic task, we have four kinds of noisy source data: Pair-45% (P45), Pair-20% (P20), Symmetry-45%
(S45), Symmetry-20% (S20). Namely, we evaluate the performance of each method using 32 simulated
WUDA tasks: 8 digit tasks and 24 human-sentiment tasks. Note that the human-sentiment task is a binary
classification problem, so pair flipping is equal to symmetry flipping. Thus, we only have 24 human-sentiment
tasks. Results on human-sentiment tasks are reported in Appendix E.
Real-world WUDA tasks. We also verify the efficacy of our approach on “cross-dataset benchmark”
including Bing, Caltech256, Imagenet and SUN (Tommasi and Tuytelaars, 2014). In this benchmark, Bing,
Caltech256, Imagenet and SUN contain common 40 classes. Since Bing dataset was formed by collecting
images retrieved by Bing image search, it contains rich noisy data, with presence of multiple objects in the
same image and caricaturization (Tommasi and Tuytelaars, 2014). We use Bing as noisy source data, and
Caltech256, Imagenet and SUN as unlabeled target data, which can form three real-world WUDA tasks.
Besides, we also test our method on two common UDA tasks ( MNIST →SVHN and SVHN→MNIST) to help
compare with other UDA-based papers in literature.
Baselines. We realize Butterfly using four networks (abbreviated as B-Net) and compare B-Net with
following baselines: 1) ATDA: representative pseudo label based UDA method (Saito et al., 2017); 2)
deep adaptation networks (DAN): representative IPM based UDA method (Long et al., 2015); 3) DANN:
representative adversiral training based UDA method (Ganin et al., 2016); 4) TCL: an existing robust UDA
method; 5) Co teaching+ATDA (Co+ATDA): a two-step method (see Section 4); 6) Co teaching+TCL
(Co+TCL): a two-step method. Implementation details are demonstrated in Appendix F.
Results on simulated WUDA (including 8 tasks). Table 1 reports the accuracy on the unlabled target data
(i.e., target-domain accuracy) in 8 tasks. As can be seen, average target-domain accuracy of B-Net is higher
than those of all baselines. On S20 case (the easiest case), most methods work well. ATDA has a satisfactory
performance although it does not consider the noise effects explicitly. Then, when facing harder cases (i.e.,
P20 and P45), ATDA fails to transfer useful knowledge from noisy source data to unlabeled target data. When
facing the hardest cases (i.e., M→S with P45 and S45), DANN has higher accuracy than DAN and ATDA
have. However, when facing the easiest cases (i.e., S→M with P20 and S20), the performance of DANN is
worse than that of DAN and ATDA. Although two-step method Co+ATDA (or Co+TCL) outperforms ATDA
(or TCL) in all 8 tasks, it cannot beat one-step method: B-Net in terms of average target-domain accuracy.
This result is an evidence for the claim in Section 4. In the task S→M with P20, Co+ATDA outperforms all
methods (slightly higher than B-Net), since pseudo-labeled source data are almost correct.
7
Under review as a conference paper at ICLR 2020
6-5-4-
0.0.S
>U2DUU< U SlUOPJe PEI-
而.54.3
>U2DUU< uraEOPJ ① p(ŋ.L
6 5 4 3 2
0.0.0.0.0.
>U2DUU< U-eluopJ8p(o-L
Epoch T	Epoch T	Epoch T	Epoch T
(a) S20	(b) S45	(c) P20	(d) P45
Figure 5: Target-domain accuracy vs. number of epochs on four MNIST→SYND WUDA tasks.
Table 1: Target-domain accuracy on 8 digit WUDA tasks (SYNDrMNIST). Bold value represents the highest
accuracy in each row.
Tasks	Type	DAN	DANN	ATDA	TCL	Co+TCL	Co+ATDA	B-Net
	P20	90.17%	79.06%	55.95%	80.81%	88.56%	95.37%	95.29%
	P45	67.00%	55.34%	53.66%	55.97%	73.27%	75.43%	90.21%
S→M	S20	90.74%	75.19%	89.87%	80.23%	85.88%	95.22%	95.88%
	S45	89.31%	65.87%	87.53%	68.54%	75.69%	92.03%	94.97%
	P20	40.82%	58.78%	33.74%	58.88%	59.08%	58.02%	60.36%
	P45	28.41%	43.70%	19.50%	45.31%	47.15%	46.80%	56.62%
M→S	S20	30.62%	53.52%	49.80%	56.74%	56.91%	56.64%	57.05%
	S45	28.21%	43.76%	17.20%	49.91%	51.22%	54.29%	56.18%
Average		58.16%	58.01%	50.91%	62.05%	67.22%	71.73%	75.82%
Figures 4 and 5 show the target-domain accuracy vs. number of epochs among ATDA, Co+ATDA and
B-Net. Besides, we show the accuracy of ATDA trained with clean source data (ATDA-TCS) as a reference
point. When accuracy of one method is close to that of ATDA-TCS (red dash line), this method successfully
eliminates noise effects. From our observations, it is clear that B-Net is very close to ATDA-TCS in 7 out of
8 tasks (except for S→M task with P45, Figure 4-(d)), which is an evidence that Butterfly can eliminate noise
effects. Since P45 case is the hardest one, it is reasonable that B-Net cannot perfectly eliminate noise effects.
An interesting phenomenon is that, B-Net outperforms ATDA-TCS in 2 M→S tasks (Figure 5-(a), (c)). This
means that B-Net transfers more useful knowledge (from noisy source data to unlabeled target data) even
than ATDA-TCS (from clean source data to unlabeled target data).
Results on real-world WUDA (including 3 tasks). Table 2 reports the target-domain accuracy for 3 tasks.
B-Net enjoys the best performance on all tasks. It should be noted that, in both Bing→Caltech256 and
Bing→ImageNet tasks, ATDA is slightly worse than B-Net. However, in Bing→SUN task, ATDA is much
worse than B-Net. The reason is that the DIR between Bing and SUN are more affected by noisy source
data. This phenomenon is also observed when comparing DANN and TCL. Compared to Co+ATDA, ATDA
is slightly better than Co+ATDA. This abnormal phenomenon can be explained using ∆ (see Section 4),
after using Co-teaching to assign pseudo labels for noisy source data, the second term in ∆s may increase,
which results in that ∆ increases, i.e., noise effects actually increase. This phenomenon is an evidence that a
two-step method may not really reduce noise effects.
Results on two UDA tasks. Table 3 reports the target-domain accuracy for 2 common UDA tasks. The
target-domain accuracy of DAN, DANN and ATDA are results reported by Saito et al. (2017). Although
the target-domain accuracy of B-Net is not always higher than that of ATDA, B-Net still has satisfactory
performance on UDA problem. Note that, since B-Net is a WUDA method, it is reasonable that B-Net is not
the state-of-the-art UDA method.
Ablation study. Finally, we conduct thorough experiments to show the contribution of individual compo-
nents in B-Net. We report average target-domain accuracy on 32 simulated WUDA tasks (8 digit and 24
8
Under review as a conference paper at ICLR 2020
Table 2: Target-domain accuracy on 3 real-world WUDA tasks. The source domain is the Bing dataset that
contains noisy information from the Internet. Bold value represents the highest accuracy in each row.
Target	DAN	DANN	ATDA	TCL	Co+TCL	Co+ATDA	B-Net
Caltech256	77.83%	78.00%	80.84%	79.35%	79.27%	79.89%	81.71%
Imagenet	70.29%	72.16%	74.89%	72.53%	72.33%	74.73%	75.00%
SUN	24.56%	26.80%	26.26%	28.80%	29.15%	26.31%	30.54%
Average	57.56%	58.99%	60.66%	60.23%	60.25%	60.31%	62.42%
Table 3: Target-domain accuracy on 2 UDA tasks. Bold value represents the highest accuracy in each row.
Tasks	DAN	DANN	ATDA	B-Net
MNIST→SVHN	-	35.70%	52.80%	52.64%
SVHN→MNIST	71.10%	71.10%	85.00%	85.82%
Table 4: Results of ablation study. Average target-domain accuracy on 8 simulated digit WUDA tasks (Digit),
24 simulated human-sentiment WUDA tasks (Sentiment) and 3 real-world WUDA tasks (Real-world). Bold
value represents the highest accuracy in each row.
Datasets	B w/o C	DCP-D	DCP-M	B-Net-S	B-Net-T	B-Net-ST	B-Net-M	B-Net
Digit	74.52%	59.19%	70.85%	71.93%	52.00%	72.27%	73.89%	75.82%
Sentiment	63.57%	61.37%	63.39%	61.49%	61.12%	61.73%	62.21%	63.77%
Real-world	62.27%	59.82%	62.34%	61.91%	60.87%	62.24%	62.17%	62.42%
human-sentiment WUDA tasks) and 3 real-world WUDA tasks. We consider following baselines: 1) B w/o
C: train B-Net by Algorithm 1, WithoUt adding ∣θTπθf 211 into the loss function of B-Net. 2) DCP-D: realize
DCP via Decoupling (MaIaCh and Shalev-Shwartz, 2017) to check data in MD and TD. 3) DCP-M: realize
DCP via MentorNet (Jiang et al., 2018) to check data in MD and TD. 4) B-Net-S: train B-Net where the
check is turned on for Source data in MD. 5) B-Net-T: train B-Net where the check is turned on for Target
data in TD. 6) B-Net-ST: train B-Net where the checks are turned on for Source data in MD and Target data
in TD. 7) B-Net-M: train B-Net where the check is turned on for all data in MD. Note that in the full B-Net,
the checks are turned on for all data in MD and Target data in TD.
Comparing B-Net with B w/o C reveals whether the constraint ∣θTπθf 211 takes effects. Comparing B-Net
with DCP-D and DCP-M shows whether realizing DCP via Co-teaching is the optimal way. Comparing
B-Net with B-Net-S, B-Net-T, B-Net-ST and B-Net-M reveals whether DCP is necessary. Table 4 reports
average target-domain accuracy of above baselines and B-Net. As can be seen, 1) B-Net benefits from adding
the constraint to the loss function L; 2) realizing DCP by Co-teaching is better than using Decoupling or
MentorNet; and 3) DCP is necessary since accuracy of B-Net is higher than those of B-Net-S, B-Net-T,
B-Net-ST and B-Net-M.
6	Conclusions
This paper opens a new problem called wildly unsupervised domain adaptation (WUDA). However, existing
UDA methods cannot handle WUDA well. To address this problem, we propose a robust one-step approach
called Butterfly. Butterfly maintains four deep networks simultaneously: Two take care of all adaptations;
while the other two can focus on classification in target domain. We compare Butterfly with existing UDA
methods on 32 simulated and 3 real-world WUDA tasks. Empirical results demonstrate that Butterfly can
robustly transfer knowledge from noisy source data to unlabeled target data. In future, we will extend our
Butterfly framework to address open-set UDA when source domain contains noisy data.
9
Under review as a conference paper at ICLR 2020
References
D. Arpit, S. Jastrzebski, N. Ballas, D. Krueger, E. Bengio, M. Kanwal, T. Maharaj, A. Fischer, A. Courville,
and Y. Bengio. A closer look at memorization in deep networks. In ICML, 2017.
S. Ben-David, J. Blitzer, K. Crammer, A. Kulesza, F. Pereira, and J. W. Vaughan. A theory of learning from
different domains. MLJ, 79(1-2):151-175, 2010.
Y. Bengio. Evolving culture versus local minima. In Growing Adaptive Machines, pages 109-138. 2014.
A.	Bergamo and L. Torresani. Exploiting weakly-labeled web images to improve object classification: a
domain adaptation approach. In NeurIPS, pages 181-189, 2010.
J. Deng, W. Dong, R. Socher, L. Li, K. Li, and F. Li. Imagenet: A large-scale hierarchical image database. In
CVPR, pages 248-255, 2009.
Y. Ganin and V. S. Lempitsky. Unsupervised domain adaptation by backpropagation. In ICML, pages
1180-1189, 2015.
Y. Ganin, E. Ustinova, H. Ajakan, P. Germain, H. Larochelle, F. Laviolette, M. Marchand, and V. S. Lempitsky.
Domain-adversarial training of neural networks. JMLR, 17:59:1-59:35, 2016.
M. Ghifary, D. Balduzzi, W. B. Kleijn, and M. Zhang. Scatter component analysis : A unified framework
for domain adaptation and domain generalization. TPAMI, 39(7):1414-1430, 2017. doi: 10.1109/TPAMI.
2016.2599532.
B.	Gong, Y. Shi, F. Sha, and K. Grauman. Geodesic flow kernel for unsupervised domain adaptation. In
CVPR, pages 2066-2073, 2012.
M. Gong, K. Zhang, T. Liu, D. Tao, and C. Glymour. Domain adaptation with conditional transferable
components. In ICML, pages 2839-2848, 2016.
M. Gong, K. Zhang, B. Huang, C. Glymour, D. Tao, and K. Batmanghelich. Causal generative domain
adaptation networks. CoRR, abs/1804.04333, 2018.
A.	Gretton, K. M. Borgwardt, M.J. Rasch, B. Scholkopf, and A. J. Smola. A kernel two-sample test. JMLR,
13:723-773, 2012.
G. Griffin, A. Holub, and P. Perona. Caltech-256 object category dataset. Technical report, California Institute
of Technology, 2007.
Y. Guo and M. Xiao. Cross language text classification via subspace co-regularized multi-view learning. In
ICML, 2012.
B.	Han, Q. Yao, X. Yu, G. Niu, M. Xu, W. Hu, I. W. Tsang, and M. Sugiyama. Co-teaching: Robust training
of deep neural networks with extremely noisy labels. In NeurIPS, pages 8527-8537, 2018.
J. Hoffman, E. Tzeng, T. Park, J. Zhu, P. Isola, K. Saenko, A. A. Efros, and T. Darrell. Cycada: Cycle-
consistent adversarial domain adaptation. In ICML, pages 1994-2003, 2018.
L. Jiang, Z. Zhou, T. Leung, L. Li, and F. Li. Mentornet: Learning data-driven curriculum for very deep
neural networks on corrupted labels. In ICML, pages 2309-2318, 2018.
J.	Lee and M. Raginsky. Minimax statistical learning with wasserstein distances. In NeurIPS, pages
2692-2701, 2018.
10
Under review as a conference paper at ICLR 2020
K.	Lee, X. He, L. Zhang, and L. Yang. Cleannet: Transfer learning for scalable image classifier training with
label noise. In CVPR, pages 5447-5456, 2018.
Y. Li, X. Tian, M. Gong, Y. Liu, T. Liu, K. Zhang, and D. Tao. Deep domain generalization via conditional
invariant adversarial networks. In ECCV, pages 647-663, 2018.
T. Liu and D. Tao. Classification with noisy labels by importance reweighting. TPAMI, 38(3):447-461, 2016.
M. Long, Y. Cao, J. Wang, and M. I. Jordan. Learning transferable features with deep adaptation networks.
In ICML, pages 97-105, 2015.
E.	Malach and S. Shalev-Shwartz. Decoupling "when to update" from "how to update". In NeurIPS, pages
961-971, 2017.
S.	Motiian, Q. Jones, S. M. Iranmanesh, and G. Doretto. Few-shot adversarial domain adaptation. In NeurIPS,
pages 6673-6683, 2017.
Giorgio Patrini, Alessandro Rozza, Aditya Krishna Menon, Richard Nock, and Lizhen Qu. Making deep
neural networks robust to label noise: A loss correction approach. In CVPR, pages 2233-2241, 2017.
K. Saito, Y. Ushiku, and T. Harada. Asymmetric tri-training for unsupervised domain adaptation. In ICML,
pages 2988-2997, 2017.
K. Saito, K. Watanabe, Y. Ushiku, and T. Harada. Maximum classifier discrepancy for unsupervised domain
adaptation. In CVPR, pages 3723-3732, 2018.
F.	Schroff, A. Criminisi, and A. Zisserman. Harvesting image databases from the web. TPAMI, 33(4):754-766,
2011.
Y. Shu, Z. Cao, M. Long, and J. Wang. Transferable curriculum for weakly-supervised domain adaptation. In
AAAI, 2019.
T. Tommasi and T. Tuytelaars. A testbed for cross-dataset analysis. In ECCV TASK-CV Workshops, pages
18-31, 2014.
E. Tzeng, J. Hoffman, T. Darrell, and K. Saenko. Simultaneous deep transfer across domains and tasks. In
ICCV, pages 4068-4076, 2015.
E. Tzeng, J. Hoffman, K. Saenko, and T. Darrell. Adversarial discriminative domain adaptation. In CVPR,
pages 2962-2971, 2017.
J.	Xiao, J. Hays, K. A. Ehinger, A. Oliva, and A. Torralba. SUN database: Large-scale scene recognition
from abbey to zoo. In CVPR, pages 3485-3492, 2010.
M. Xiao and Y. Guo. Feature space independent semi-supervised domain adaptation via kernel matching.
TPAMI, 37(1):54-66, 2015.
T. Xiao, T. Xia, Y. Yang, C. Huang, and X. Wang. Learning from massive noisy labeled data for image
classification. In CVPR, pages 2691-2699, 2015.
K. Zhang, B. Scholkopf, K. Muandet, and Z. Wang. Domain adaptation under target and conditional shift. In
ICML, pages 819-827, 2013.
K.	Zhang, M. Gong, and B. Scholkopf. Multi-source domain adaptation: A causal view. In AAAI, pages
3150-3157, 2015.
11
Under review as a conference paper at ICLR 2020
A Review of generation of noisy labels
This section presents a review on two label-noise generation processes.
A.1 Transition matrix
We assume that there is a clean multivariate random variable (Xs, Ys) defined on X × Y with a probability
density ps(xs, ys), where Y = {1, ..., K} is a label set with K labels. However, samples of (Xs, Ys) cannot
be directly obtained and we only can observe noisy source data from the multivariate random variable
(Xs, Ys) defined on XXY with a probability density ps(χs, ys). Ps(Xs,y$) is generated by a transition
probability Pr(Ys = j|Ys = i), i.e., the flip rate from a clean label i to a noisy label j. When we generate
ps(χs,ys) using Q, we often assume that PKS = Ips(χs,ys) = PKS = Ips(χs,ys), i.e., the class conditional
noise (Liu and Tao, 2016). All these transition probabilities are summarized into a transition matrix Q, where
. ,_______________ .
Qij = Pr(Y = j ∣Ys = i).
The transition matrix Q is easily estimated in certain situations (Liu and Tao, 2016). However, in more
complex situations, such as clothing1M dataset (Xiao et al., 2015), noisy source data is directly generated by
selecting data from a pool, which mixes correct data (data with correct labels) and incorrect data (data with
incorrect labels). Namely, how the correct label i is corrupted to j (i 6= j ) is unclear.
A.2 Sample selection
Formally, there is a multivariate random variable (Xs, Ys, Vs) defined on X × Y × V with a probability density
ppso(xs, ys, vs), where V = {0, 1} and Vs = 1 means “correct” and Vs = 0 means “incorrect”. Nonetheless,
samples from (Xs, Ys, Vs) cannot be obtained and we can only observe (Xs, Ys) from a distribution with the
following density.
1
Ps(Xs,yS) = EPXS ,Ys∣Vs (Xs,ys|Vs)PV (Vs),
vS=0
(2)
where PpVoS (Vs) = RX PyKS=1Ppso(Xs, ys , Vs )dXs . The density in Eq. (2) means that we lost the information
from Vs. If We uniformly select samples drawn from Ps(Xs,ys), the noise rate of these samples is PVo (0). It is
clear that the multivariate random variable (Xs, Ys|Vs = 1) is the clean multivariate random variable (Xs, Ys)
defined in Appendix A.1. Then, qs(Xs, ys) is used to describe the density of incorrect multivariate random
variable (Xs,K∣K = 0). Using Ps(χs,ys) and qs(xs,ys), Ps(Xs,ys) can be expressed by the following
equation.
Ps(Xs,ys) = (I — P)Ps(Xs,ys) + Pqs (Xs,ys),	(3)
where ρ = PpVo (0). Here, we do not assume PyK=1Ps(Xs, ys) = PyK =1 qs(Xs, ys). To reduce noise effects
from incorrect data, scholars aim to recover the information of Vs, i.e., to select correct data from data drawn
fromPs(Xs,ys) (Han et al., 2018; Jiang et al., 2018; Malach and Shalev-Shwartz, 2017).
12
Under review as a conference paper at ICLR 2020


ɪ
2
2
O
Λ
ɪ
Z
0
3

3
3
3
5
(a) MNIST
W盘］
5 16d”底 9
7生
(b) SYND




4
石
6
ɪ
ɪ
6



7

&

5
1
%
Figure 6: Visualization of MNIST and SYND.
B TRANSITION MATRIX Q
Precise definitions of Symmetry flipping and Pair flipping are presented below, where ρ is the noise rate and
K is the number of labels.
		1-ρ K-1	P K-1 1-P	... P K-1	P K-1 ...	P 1 K-1 P K-1	
Symmetry flipping:	Q=	. . .		. . .		. . .	
		P K-1 .K-1	... P K-1	P K-1 ...	1-P P K-1	P K-1 1-P	
		「1 - P 0	P 1-P	0 P	...	0 _ 0	
Pair flipping:	Q=	. . . 0 P	0	. . . ...	. . . 1-P 01	. . . P -P	.
Following Han et al. (2018); Jiang et al. (2018), we can corrupt clean-label datasets manually using the noise
transition matrix Q .
C	Datasets visualization
Figure 6 shows datasets: MNIST and SYND. Figure 7 shows datasets: Bing, Caltech256, Imagenet and SUN
(taking “horse” as the common class).
13
Under review as a conference paper at ICLR 2020
(a) Bing provided by Bergamo and Torresani (2010)
(b) Caltech256 provided by Griffin et al. (2007)
(c) ImageNet provided by Deng et al. (2009)
(d) SUN provided by Xiao et al. (2010)
Figure 7: Visualization of Bing, Caltech256, ImageNet and SUN (taking “horse” as the common class).
D Theoretical analysis
This section presents some interesting theoretical findings related to WUDA problem. We use following
notations in this section: 1) a space X ⊂ Rd and Y = {1, 2,…,K} as a label set; 2) PS(XS, ys), PS(XS, ys)
and qs(xs, ys) represent densities of noisy, correct and incorrect multivariate random variables (m.r.v.) defined
on XXY, respectively1, and Pxs(XS), Pxs(Xs) and qxs(xs) are their marginal densities; and 3) Pxt (Xt) repre-
sents density of m.r.v. Xt defined on X; and 4) We use '(h(X), h0(x)) to represent loss function between two
1 1 11 ∙	n	1 L∖	K ∕7∖ E	Γ /) / 7 / ∖~∖1 Ie ∕7∖ E	「"7 / ∖	∖7 ,
labelling functions; and 5) we use Rs(h) = Eps(xs,ys)['(h(XS),ys)] and Rs(h) = Eps(xs,ys)['(h(XS),ys)] to
represent expected risks on the noisy and correct m.r.v.; and 6) we use Rs (h, h ) = EpxS(xs)['(h(XS), h (xs))],
Rs(h, h0) = Epxs(xs)['(h(XS),h0(XS))] and Rt(h, h0) = Epxt(xt)仅(h(Xt),h0(Xt))] to represent expected
1There are two common ways to express the density of noisy m.r.v. (see Appendix A). One way is to use a mixture of
densities of correct and incorrect m.r.v..
14
Under review as a conference paper at ICLR 2020
discrepancy between two labelling functions h, h0 under different marginal densities; 7) the ground-truth and
1	1 1	1∙ C , ∙	l' , 1	, 1	∙	F ,FK "∕∖	f3∕∖
pseudo labeling function of the target domain are denoted by ft(xt) and ft(xt).
D.1 WUDA ruins UDA methods
Theoretically, we analyze why existing UDA methods cannot well transfer useful knowledge from noisy
source data Ds to unlabelled target data Dt directly. We first present a theorem to show relations between
_ ，-、 . ~ ，-、
Rs(h) and Rs(h).
Theorem 1.	For any labelling function h : X → Y, if Ps(Xs,y§) is generated by a transition matrix Q as
demonstrated in Appendix A.1, we have
Rs(h) = Rs(h)+ Epxs(Xs)[ητ(xs)(Q - I)'(h(xs))],	(4)
where '(h(xs)) = ['(h(xs), 1),...,'(h(xs),K)]T and η(xs) = [pγs∣χs (1|xs),…，pγs∣χs (K∣xs)]T. If
Ps(xs,ys) is generated by sample selection as described in inAppendixA.2, we have
Rs(h) = (I-P)Rs(h) + PEqxs (xs)[ηT(Xs)'(h(Xs))],	⑸
where ηq (xs) = [qYs|Xs(1|xs), ..., qYs|Xs(K|xs)]T.
Remark 2. In Eq.(5), EqxS (xs) [ηT(xs)'(h(xs))] represents the expected risk on the incorrect m.r.v.. To en-
sure to obtain useful knowledge from Ps, we need to avoid Rs(h) ≈ EqxS (Xs) 吗(xs)'(h(xs))]. Specifically,
we assume: there is a constant 0 < Ms < ∞ such that EqxS(xs)[ηT(xs)'(h(xs))] ≤ Rs(h) + Ms.
Theorem 1 shows that the expected risk Rs(h) only equals Rs(h) when two cases happen: 1) Q = I and
P = 0 and 2) some special combinations (e.g., special pXs, qXs, Q, η and `) to make the second term in Eq. (4)
equal zero or to make the second term in Eq. (5) equal PRs(h). Case 1) means that data in source domain
is clean, which is not real in the wild. Case 2) almost never happens, since it is hard to find such special
combinations when pXs , qXs , Q and η are unknown. Thus, Rs (h) has an essential difference with Rs (h).
Then, following proof skills in Ben-David et al. (2010), we derive the upper bound of Rt (h) as follows.
Theorem 2.	For any labelling function h : X → Y, we have
Rt(h,ft) ≤	Rs(h)	+
|—{^}
(i)	risk on noisy data
..~. ~ ~..
∖Rt(hft)- Rs(h,ft)∖
|---------{---------}
(ii)	discrepancy between distributions
..~. ..
+ ∖Rs(h,ft) - Rs(h)∖
|---------{--------}
(iii)	domain dissimilarity
.~ . . .. . ~ ~. . ~..
+ IRs(h) - Rs(h)∖ + ∖Rs(h,ft) - Rs(hft)∖ +
|-----------------------{------------------------}
(iv) noise effects from source ∆s
∖Rt(h,ft) - Rt(h,ft)| .
|------------{-------------}
(v) noise effects from target ∆t
(6)
TB	TCE	,1	∙	ClT	11 C-	,1	,	, ZA
Remark 3. To ensure that we can gain useful knowledge from ft(Xt), we assume: there is a constant 0 <
--	.	一	…，一 ，、 7 ， 、、、 一 ，一 ?、	- - 一 一	…，一 ，、 7 ， 、、、 一 ，一 ~ 、	--
Mt < ∞ such that Eqxs (χ)['(h(χ)ft(χ))] ≤ Rs(h,ft) + Mt and Eqxt(X) ['(h(x)ft(χ))] ≤ Rt(hft) + Mt,
whereqXt(X) = pXt (X)1A (X)/PXt (A) andA = {X : ft(X) 6= ft(X)}.
It is clear that the upper bound of Rt(h, ft), shown in Eq. (6), has 5 components. However, existing UDA
methods only focus on minimizing (i) + (ii) (Ganin et al., 2016; Ghifary et al., 2017; Long et al., 2015) or
(i) + (ii) + (iii) (Saito et al., 2017), which ignores terms (iv) and (v) (i.e., ∆ = ∆s + ∆t). Thus, in theory,
existing UDA methods cannot handle wildly unsupervised domain adaptation well.
D.2 Two-step approach is a compromise solution
To reduce noise effects, a straightforward solution is two-step approach. In the first step, we can train a
classifier with noisy source data using Co-teaching (Han et al., 2018) and use this classifier to annotate pseudo
15
Under review as a conference paper at ICLR 2020
labels for source data. In the second step, we use ATDA (Saito et al., 2017) to train a target-domain classifier
with pseudo-label-source and target data.
Nonetheless, the pseudo-labeled source data is still noisy. Let labels of noisy source data y be replaced with
pseudo labels yS after pre-processing. Noise effects ∆ will become pseudo-label effects ∆p as follows.
∆p = ∣RS(h)- Rs(h)∣ + ∣RS(h,ft) - Rs(h,ft)∣ +∆t,	⑺
'---------------------{z---------------------}
pseudo-label-source effects ∆0s
where R0s(h) and Rs0 (h, ft) correspond to Rs(h) and Rs(h, ft) in ∆s. It is clear that the difference between
∆p and ∆ is ∆0s - ∆s. The first term in ∆0s may be less than that in ∆s due to Co-teaching, but the second
term in ∆0s may be higher than that in ∆s since Co-teaching does not consider to minimize it. Thus, it is hard
to say whether ∆0s < ∆s (i.e., ∆p < ∆). This means that two-step approach may not really reduce noise
effects.
D.3 Why does Butterfly can eliminate noise effect
To eliminate noise effects ∆, we aim to select correct data simultaneously from noisy source data and
pseudo-labeled target data. In theory, we prove that noise effects will be eliminated if we can select correct
data with a high probability. Let ρs01 represent the probability that incorrect data is selected from noisy source
data, and ρt01 represent the probability that incorrect data is selected from pseudo-labeled target data. Theorem
3 shows that ∆ → 0 if ρ0s1 → 0 and ρt01 → 0 and presents a new upper bound of Rt(h, ft).
Theorem 3.	Given two m.r.v. (Xs, Ys, Us) defined on X × Y × V and (Xt, Ut) defined on X × V, under
the assumptions in Remarks 2 and 3, ∀e ∈ (0,1), there are δs and δt, if Ep0 3)['(h(xt), ft(xt))] ≤
Rt(h, ft) + ρs01Mt, ρs01 < δs and ρt01 < δt, for any labeling function h, we will have
.~.. ~ . . ~.. . ~.. . ..
|RPpo(h,ft,us) - Rs(h,ft)∖ + |RPpo(h,us)- Rs(h)∖ < 2e.	(8)
Moreover, if ρs01 ≤ δs and ρt01 ≤ δt, we will have
Rt(h,ft) ≤
Rp) (h,us)	+
'-----{z----}
(i) risk on noisy data
∖RRPo(h, ft, Ut)- Rp(h, ft, up)∖ + ∖Rs(h, ft) - Rs(h)∖
'------------------V-----------------------}	'----------V--------------}
(ii) discrepancy between distributions	(iii) domain dissimilarity
+
2e
|{z}
2e
(iv)	noise effects from source ∆s
|{z}
(v)	noise effects from target ∆t
(9)
+
Where Pxt (X)	= Pxt (X)IB (x)∕pxt (B), Rp (h,us)	=	(1 - Pus )-1Epso (xs,ys,Us)[us'(h(Xs),yp)],
R (h,ft,ut)	=	(1 - Put)TEPto(xt,ut)[ut'(h(Xt),ft(χt))], RPo(h,ft,us)	=	(1 - Pus)T
Po
Epso (xs,ys,us) [υs'(h(xs), ft(xs))], Ppso (xs ,ys,us) IS the density of (Xs, Ys, Us), Pt (xt, Ut) IS the density of
(Xt,Ut), Pus = Rx PK=I Ps(xs,ys, 0)dxs < LPut= RxPtP(xt, 0)dxt < 1, B = X/A and V = {0,1}.
Remark 4. In Appendix H.3.1, we give precise definitions of Ps01 and Pt01 and demonstrate the meaning of
EPxjxt)['(h(Xt),ft(xt))] ≤ Rt(h,ft) + P01Mt (Remark 5).
Data drawn from the distribution of (Xs, Ys, Us) can be regarded as a pool that mixes the selected (Us = 1)
and unselected (Us = 0) noisy source data. Data drawn from the distribution of (Xt, Ut) can be regarded
as a pool that mixes the selected (Ut = 1) and unselected (Ut = 0) pseudo-labeled target data. Theorem 3
shows that if selected data have a high probability to be correct ones (P0s1 → 0 and Pt01 → 0), then ∆s and ∆t
approach 0, meaning that noise effects are eliminated. This motivates us to find a reliable way to select correct
data from noisy source data and pseudo-labeled target data and build up a one-step approach for WUDA.
16
Under review as a conference paper at ICLR 2020
Why Butterfly? Guided by Theorem 3, a robust approach should check high-correctness data out (meaning
ρs01 → 0 and ρt01 → 0). This checking process will make (iv) and (v), 2 + 2, become 0. Then, we can
po	po
obtain gradients of Rpso(h, us), Rs(h, ft, us) and Rtpo(h, ft, ut) w.r.t. parameters of h and use these gradients
to minimize them, which minimizes (i) and (ii) as (i) + (ii) ≤ RRSo(h, US) + RRs (h, ft, US) + RRpO(h, ft, Ut).
Note that (iii) cannot be directly minimized since we cannot pinpoint clean source data. However, following
Saito et al. (2017), we can indirectly minimize (iii) via minimizing Rpo(h, US) + RSo(h, ft, Us), as (iii) ≤
Rs(h, ft) + Rs(h) ≤ RS (h, US) + RS (h, ft,Us) + 2e, where the last inequality follows Eq. (8). This means
that a robust approach guided by Theorem 3 can minimize all terms in the right side of inequality in Eq. (9).
To realize this robust approach, we propose a Butterfly framework (Algorithm 1), which trains four networks
dividing into two branches (Figure 3). By using dual-checking principle, Branch-I checks which data is
correct in the mixture domain; while Branch-II checks which pseudo-labeled target data is correct. To
ensure these checked data highly-correct, we apply the small-loss trick based on memorization effects of
deep learning Arpit et al. (2017). After cross-propagating these checked data Bengio (2014), Butterfly can
obtain high-quality DIR and TSR simultaneously in an iterative manner. Theoretically, Branch-I minimizes
(i) + (ii) + (iii) + (iv); while Branch-II minimizes (ii) + (v). This means that Butterfly can minimize all
terms in the right side of inequality in Eq. (9). Note that empirical estimators of Rpo(h, US), RRpo(h, ft, Ut)
po
and RSpo(h, ft, US) (in Theorem 3) can be expressed using the loss function of Butterfly (see Eq. (1)).
Relations to Co-teaching. As Butterfly is related to Co-teaching, we discuss their major differences here.
Although Co-teaching (Han et al., 2018) applies the small-loss trick and the cross-update technique to train
deep networks against noisy data, it can only deal with one-domain problem instead cross-domain problem.
Besides, we argue that Butterfly is not a simple mixtrue of Co-teaching and ATDA for two reasons.
First, network structure of Butterfly is different with that of ATDA and Co-teaching: Butterfly maintains four
networks; while ATDA maintains three and Co-teaching maintains two. We cannot simply combine ADTA
and Co-teaching to derive Butterfly. Second, we have justified that the sequential mixture of Co-teaching
and ATDA (i.e., two-step method) cannot eliminate noise effects caused by noisy source data (see Section 4).
Specifically, two-step methods only take care of part of noise effects but Butterfly takes care of the whole
noise effects. Thus, Butterfly is the first method to eliminate noise effects rather than alleviate it.
Relations to TCL. Recently, transferable curriculum learning (TCL) is a robust UDA method to handle
noise Shu et al. (2019). TCL uses small-loss trick to train the domain-adversarial neural network (DANN)
Ganin et al. (2016). However, TCL can only minimize (i) + (ii) + (iv), while Butterfly can minimize all
terms in the right side of Eq. (9).
E Results on human-sentiment WUDA tasks
Tables 5 and 6 report the target-domain accuracy of each method for 24 human-sentiment WUDA tasks. For
these tasks, B-Net has the highest average accuracy. It should be noted that two-step method does not always
perform better than existing UDA methods, such as for 20%-noise situation. The main reason is Co-teaching
performs poorly when pinpointing clean source data from noisy source data. Another observation is that
noise effects is not eliminated like classification results on digit WUDA tasks. The main reason is that these
datasets provide fixed features and we cannot extract better features in the training process. However, in digit
WUDA tasks, we can gradually obtain better features for each domain and finally eliminate noise effects.
17
Under review as a conference paper at ICLR 2020
Table 5: Target-domain accuracy on 12 human-sentiment WUDA tasks with the 20% noise rate. Bold values
mean the highest values in each row.
Tasks	DAN	DANN	ATDA	TCL	Co+TCL	Co+ATDA	B-Net
B→D	68.28%	68.08%	70.31%	71.40%	67.81%	66.70%	71.84%
B→E	63.78%	63.53%	72.79%	65.08%	60.54%	68.89%	75.92%
B→K	65.48%	64.63%	71.79%	66.80%	61.23%	66.51%	76.32%
D→B	64.63%	64.52%	70.25%	67.33%	65.22%	68.04%	70.56%
D→E	65.33%	65.16%	69.99%	66.74%	64.55%	67.32%	73.73%
D→K	65.68%	66.28%	74.53%	68.82%	67.98%	72.20%	77.97%
E→B	60.41%	60.15%	63.89%	63.13%	61.18%	61.08%	62.22%
E→D	62.35%	61.67%	62.30%	62.93%	60.81%	59.77%	63.53%
E→K	72.05%	71.51%	74.00%	75.36%	72.65%	70.85%	78.96%
K→B	59.94%	59.40%	63.53%	62.77%	60.71%	61.22%	63.36%
K→D	61.46%	61.51%	64.66%	64.16%	64.15%	64.94%	66.98%
K→E	70.60%	72.23%	74.75%	74.14%	68.95%	69.69%	76.96%
Average	65.00%	64.89%	69.40%	67.39%	64.65%	66.43%	71.53%
Table 6: Target-domain accuracy on 12 human-sentiment WUDA tasks with the 45% noise rate. Bold values
mean the highest values in each row.
Tasks	DAN	DANN	ATDA	TCL	Co+TCL	Co+ATDA	B-Net
B→D	52.43%	52.98%	53.56%	54.44%	53.21%	54.32%	56.59%
B→E	52.17%	53.50%	55.14%	54.14%	53.98%	57.34%	55.74%
B→K	52.89%	51.84%	51.14%	53.32%	51.77%	53.28%	57.00%
D→B	53.11%	53.04%	54.48%	53.27%	54.85%	55.95%	55.15%
D→E	51.30%	53.04%	54.21%	53.77%	55.63%	56.08%	58.91%
D→K	52.15%	53.17%	57.99%	52.45%	58.10%	59.94%	66.20%
E→B	51.38%	51.08%	52.54%	52.14%	54.88%	53.30%	54.93%
E→D	52.83%	51.24%	49.02%	52.57%	50.03%	49.62%	52.88%
E→K	54.21%	53.58%	51.66%	55.04%	56.15%	52.10%	56.12%
K→B	50.44%	51.77%	51.96%	51.50%	53.81%	52.59%	51.39%
K→D	52.20%	51.45%	52.86%	53.19%	55.69%	54.52%	53.53%
K→E	54.72%	53.33%	52.11%	53.46%	51.26%	52.62%	53.71%
Average	52.49%	52.50%	53.65%	53.27%	54.11%	54.31%	56.01%
F Experimental settings
F.1 Network structure and optimizer
We implement all methods on Python 3.6 with a NIVIDIA P100 GPU. We use MomentumSGD for opti-
mization in digit and real-world tasks, and set the momentum as 0.9. We use Adagrad for optimization in
human-sentiment tasks because of sparsity of review data (Saito et al., 2017). F1, F2, Ft1 and Ft2 are 6-layer
CNN (3 convolutional layers and 3 fully-connected layers) for digit tasks; and are 3-layer neural networks
(3 fully-connected layers) for human-sentiment tasks; and are 4-layer neural networks (4 fully-connected
layers) for real-world tasks. The ReLU active function is used as avtivation function of these networks.
Besides, dropout and batch normalization are also used. The network topology is shown in Figures 8, 9 and
10. As deep networks are highly nonconvex, even with the same network and optimization method, different
initializations can lead to different local optimal. Thus, following Malach and Shalev-Shwartz (2017), we
also take four networks with the same architecture but different initializations as four classifiers.
18
Under review as a conference paper at ICLR 2020
Figure 8: The architecture of B-Net for digit WUDA tasks SYND - MNIST. We added BN layer in the last
convolution layer in CNN and FC layers in F1 and F2. We also used dropout in the last convolution layer in
CNN and FC layers in F1, F2, Ft1 and Ft2 (dropout probability is set to 0.5).
FC 50
units
ReLU
DIR
F1
DIR
FC 2 units
Softmax
FC 50
units
ReLU
Branch-I
F2
TSR
FC 50
units
ReLU
TSR
Figure 9: The architecture of B-Net for human-sentiment WUDA tasks. We added BN layer in the first FC
layers in F1 and F2. We also used dropout in the first FC layers in F1, F2, Ft1 and Ft2 (dropout probability is
set to 0.5).
19
Under review as a conference paper at ICLR 2020
DIR
Branch-I
DIR
TSR
TSR
Figure 10: The architecture of B-Net for real-world WUDA tasks. We added BN layer in the first FC layers in
F1, F2, Ft1 and Ft2. We also used dropout in the first FC layers in F1, F2, Ft1 and Ft2 (dropout probability
is set to 0.5).
F.2 Experimental setup
For all 35 WUDA tasks and 2 UDA tasks, Tk is set to 5, Tmax is set to 30. Learning rate is set to 0.01 for
simulated tasks and 0.05 for real-world WUDA tasks and UDA tasks, γt is set to 0.05 for simulated tasks and
0.02 for real-world WUDA tasks and UDA tasks. Confidence level of labelling function in line 8 of Algorithm
1 is set to 0.95 for 8 digit tasks and 2 UDA tasks, and 0.9 for 24 human-sentiment tasks and 0.8 for real-world
WUDA tasks. γ is set to 0.4 for digit tasks, 0.1 for human-sentiment tasks, 0.2 for real-world WUDA tasks
and 0.1 for UDA tasks. nlt,max is set to 15, 000 for digit tasks and UDA tasks, 500 for human-sentiment
tasks and 4000 for real-world WUDA tasks. Nmax is set to 1000 for digit tasks and UDA tasks, and 200 for
human-sentiment and real-world tasks. Batch size is set to 128 for digit, real-world WUDA tasks and UDA
tasks, and 24 for human-sentiment tasks. Penalty parameter is set to 0.01 for digit, real-world WUDA tasks
and UDA tasks, and 0.001 for human-sentiment tasks.
To fairly compare all methods, they have the same network structure. Namely, ATDA, DAN, DANN, TCL and
B-Net adopt the same network structure for each dataset. Note that DANN and TCL use the same structure
for their discriminate networks. All experiments are repeated ten times and we report the average accuracy
value and standard deviation (STD) of accuracy values of ten experiments.
F.3 Links to datasets
Digit datasets (MNIST and SYN Digit (SYND)) can be downloaded from official code of ATDA. The link is
https://github.com/ksaito-ut/atda.
Sentiment datasets (Amazon products reviews) can be downloaded from the official code of marginal-
ized Stacked Denoising Autoencoder (mSDA). The link is https://www.cse.wustl.edu/~mchen/
code/mSDA.tar.
Real-world datasets (BCIS) can be downloaded from the website of the project “A Testbed for Cross-Dataset
Analysis”: https://sites.google.com/site/crossdataset/home/files ("setup DENSE
decaf7", 1.3GB, decaf7 features).
20
Under review as a conference paper at ICLR 2020
G Running time
Table 7 shows the average running time of each method on the task SYND→MNIST. Although B-Net trains
four networks, its running time is still comparable to most baselines.
Table 7: Running time for each method on the task SYND→MNIST (minutes).
Methods	DAN	DANN	ATDA	TCL	Co+ATDA	B-Net
Time	17.17	9.02	17.17	14.04	18.28	20.55
H Proofs
This section provides proofs of theorems demonstrated in the supplementary.
H.1 Proof of Theorem 1
Proof. We will fist prove Eq. (4) (Case 1) and then prove Eq. (5) (Case 2).
Case 1. According to definition of Rs(h), we have
二，、、 一 …，一，
Rs(h) = Eps(Xs,ys)['(Nxs),yS)]
X
X
X
ZX
K
E '(h(xs),ys)ps(xs,ys)dxs
ys=ι
K
E '(h(xs), yS)PYsIXs (ys|xS)Pxs (xs)dxs
ys=ι
ητ(xs)'(h(xs))pxs (xs)dxs,
(10)
where '(h(xs)) = ['(h(xs), 1),...,'(h(xs),K)[T and η(xs) = [Pγs∣χs (1|xs),..., tPγs∖χs (Klxs)]T. AC-
cording to definition of the transition matrix Q, we know that
ητ (xs) = ητ (xs)Q,
(11)
where η(xs) = [pγs∣χs (1|xs),…，Pγs∣χs (K∣xs)]τ. Substituting Eq. (11) into Eq. (10), we have
RRs(h) = / ητ(xs)Q'(h(xs))Pxs (xs)dxs
X
=/ ητ(xs)I'(h(xs))pxs (xs)dxs + / ητ(xs)(Q - I)'(h(xs))pxs (xs)dxs
=Rs(h)+ Epxs (xs)[ητ (xs)(Q — I )'(h(xs))].
Hence, Case 1 is proved.
21
Under review as a conference paper at ICLR 2020
Case 2. According to definition of Rs (h) and Eq. (3), we have
二，-、	一	…，-，	、…、r
Rs(h) = EPs(xs,ys ) ['(h(Xs),yS)]
K
=/ £ '(h(χs),ys)ρs(χs,ys)dxs
JX ys = ι
K
' E '(h(xs),ys)((1 - P)Ps(Xs,ys) + Pqs(Xs,ys))dxs
X ys=1
KK
(1 - P) /	'(h(xs),ys)ps(xs,ys)dxs + P £'(h(xs),ys)qs(xs,ys)dxs
X ys=1	X ys=1
K
(1 - p)Rs(h) + P / E '(h(xs),ys)qγs∣χs (ys∣xs)qχs (xs)dxs.
X ys=1
(12)
Letηq(Xs) = [qYs|Xs(1|Xs), ...,qYs|Xs(K|Xs)]T, we have
Rs(h) = (1 - P)Rs(h) + PEqxs(χs)[ηT(xs)'(h(xs))].
Hence, Case 2 is proved.
□
H.2 Proof of Theorem 2
Proof. For any labelling function h, we have
Rt(h,ft) = Rt(h,ft) + Rs(h) - Rs(h) + Rs(h,ft) - Rs(h,ft)
=Rs(h) + Rt(h, ft) - Rs(h,ft) + Rs(h, ft) - Rs(h) + Rs(h) - Rs(h)
+ Rs(h,ft)- Rs(h,ft).	(13)
Since we do not know ft, we substitute following equations into Eq. (13),
Rt(h,ft) = Rt(h,ft) + Rt(h, ft) - Rt(h,ft),
~ . . . . ~ ~ . ~ . . ~ ~ .
Rs(h, ft) = Rs(h,ft) + Rs(h, ft) - Rs(h,ft),
Rs(h, ft) = Rs(h,ft) + Rs(h, ft) - Rs(h,ft).
Then, we have
. . ~ ~ , ~ . ~ . ~ . .
Rt(h,ft) = Rs(h) + Rt(h,ft) - Rs(h,ft) + Rs(h,ft) - Rs(h)
. . ~ ~ . ~ . ~ . . . ~ .
+ Rs(h) - Rs(h) + Rs(h,ft) - Rs(h, ft) + Rt(h,ft) - Rt(h, ft)
~ . . 〜、 ~ 〜、. . . 〜、 ..
≤ Rs(h) + |Rt(h,ft) - Rs(h,ft)| + ∣Rs(h,ft) - Rs(h)∣
.~ . . . . . ~ 〜、 . 〜、. . . . . ~ .
+ ∣Rs(h)- Rs(h)∣ + ∣Rs(h,ft)- Rs(h,ft)∖ + ∣Rt(h,ft) - Rt(h,ft)∖.
Hence, this theorem is proved.	口
H.3 Proof of Theorem 3
H.3.1 Preliminary
Before stating the proof, we first present a random variable below.
22
Under review as a conference paper at ICLR 2020
Let (Xt, Vt) be a m.r.v. defined on X × V with respective a density ptpo(xt, vt), where V = {0, 1}. Vt can
be regarded as perfect-selection random variables. Namely, Vt = 1 means ft (xt) = ft (xt) and Vt = 0
means ft(xt) = ft(xt). Let PVo (Vt) be the marginal density of ppo(χt,vt). Itis clear that, higher value of
po	po
ppVo (Vt = 1) means that ft is more like ft. In following, we use 1 - ρvt to represent ppVo (Vt = 1).
Then, we will show 1) relation between (Xs, Ys, Vs) and (Xs, Ys, Us), 2) relation between (Xt, Vt) and
(Xt, Ut) and definitions of ρs01 and ρt01. Based on (Xt, Vt) and (Xs, Ys, Vs) defined in Appendix A.2, the
densities of (Xs, Ys, Us) and (Xt, Ut) can be expressed as follows.
PXs ,Ys∣Us (Xs,ys Ii) =POipXs,Ys IVs (Xs,ys|0)+ p1ipXs,Ys∖Vs IXsjys II)，
PXtIUt (XtIi) = P0iPχt I Vt (xt|0) + PIipXtIVt (Xtl1),
where ρjsi = Pr(Vs = jIUs = i) represents the probability of the event: Vs = j given Us = i, ρtji = Pr(Vt =
jIUt = i) represents the probability of the event: Vt = j given Ut = i (i, j = 0, 1). Since Ps(Xs, ys) =
PXs ,Ys IVs (Xs , ys I1), qs (Xs , ys ) = PXs ,Ys IVs (Xs , ys I0), PXt IVt (Xt I0) = Pxt (Xt )1A (Xt)/Pxt (A) = qxt (Xt)
andpXt∣v (Xt|1) = Pxt (Xt)IB (Xt)IPxt(B) = Pxt (Xt) (A = {x : ft(X) = ft(X)}, B = X/A), we have
PXs,κ∣us (Xs,ysIi) = PIiqs(Xs,ys) + PIips(Xs,ys),	(14)
pXt∣ut (XtIi) = ρ0iqxt (Xt) + PtIiPxt(Xt)∙	(15)
Next, We give a lemma to show relation between Rpo(h,us) and Rs (h).
Lemma 1. Given the multivariate random variable (Xs,Ys, Us) With the probability Po(Xs,ys, Us) and
Eq. (14), we have
IRS (h,us) - Rs(h)I ≤ Poi max{Eqs(xs,ys)['(h(Xs),ys)],Rs(h)}.	(16)
Proof. According to definition of Rpo(h, Us) in Theorem 3, we have
iK
RSo(h,Us) = (I-Pus)T	XX
us'(h(Xs), ys)Ppo(Xs, ys,us)dXs
X us=0 ys=i
K
= (I-Pus)T / £'(h(Xs),ys)PXs,Ys|Us(Xs,y∕I)PUs(I)dXs
X ys=i
K
(=)(I-Pus)T(I-Pus) /	'(h(Xs),ys)(Poiqs(Xs,ys) + PSIps(Xs,ys))dXs
X ys=i
=PSIEqs("s,ls)['(h^s), ys)] + PIIRs(h),
where (a) is based on the definition of Pus and Eq. (14). Thus, we have
.~ 一. . .. . , ., . . ..
IRSo(h,υs) - Rs(h)I = IP0ιEqs(xs,ys)['(h(Xs),ys)] - (1 -4)Rs(h)I
≤ P01 max{Eqs(xs,ys)['(h(Xs), ys)], Rs(h)}.
This lemma is proved.
□
Similar with Lemma 1, we can obtain
IRPo(h,ft,ut)- Rs(h,ft)I≤ P01 max{Eqχs(xs)['(h(Xs),ft(Xs))],Rs(h,ft)}∙	(17)
Then, we give another lemma to show relation between Rpo (h, ft,us) and Rt(h,ft).
23
Under review as a conference paper at ICLR 2020
Lemma 2. Given the multivariate random variable (Xt, Ut) with the probability Po (xt, Ut) and Eq. (15), if
EpxJxt) ['(h(xt),ft(xt))] ≤ Rt(h,ft) + P01 Mt, then we have
IRRpo(h,ft, Ut) - Rt(h,ft) ≤ p0i max{Eqxt(χt)['(h(xt),ft(xt))], Rt(h,ft)} + ρl1Pθ1Mt.	(18)
po
Proof. According to definition of Rt (h, ft, ut) in Theorem 3, we have
1
R (h,ft,ut) = (1 — Put)T / Eut'(h(xt), ft(xt))P (xt,ut)dxt
X ut=0
(I-Put)TL '(h(Xt),ft(Xt))PX
= (1 - ρut)-1 (1 - ρut)
X
'(h(Xs),ft (Xt))(P0ιqxt (Xt) + ρi⅛Xt∣ Vt(XtII)) dxt
f
=P01Eqxt(xt)['(h(Xt),ft(Xt))] + PtIIl '(h(Xt),ft(Xt))PXt∣vt (XtM = 1)dXt
X
=P01Eqxt(xt)['(h(Xt),ft(Xt))] + P11 / '(h(Xt),ft(Xt))PXtIVt (XtM = 1)dXt
X
=P01Eqxt (xt)['(h(Xt), ft (Xt))] + P11 L '(h(Xt), ft (Xt))Pxt (Xt)dXt
=PθιEqxt(xt)['(h(Xt),ft(Xt))]+ P11Epxt (xt)['(h(Xt),ft(Xt))],
(19)
1 / ∖ ∙ 1	1 ,1 1 r~ ∙ 1 ∙	IL / ι λ∖ ι / 7 ∖ ∙ 1	1 .λ 1 r> ∙ .∙ CTz∖	∖
where (a) is based on the definition of Pus and Eq. (14) and (b) is based on the definition ofVt (ft(Xt) = ft(Xt)
when Vt = 1). Since EpxJxt)['(h(Xt),ft(Xt))] ≤ Rt(h,ft) + P0ιMt,wehave
Rpo(h, f ut) ≤ POiEqxt(xt)['(h(Xt),ft(Xt))]+ P1ι(Rt(h, ft) + P0ιMt).	(20)
Thus, we have
IRp S,ft,ut) - Rt(Aft)I = lPoιEqxt(xt)['(h(Xt),ft(Xt))]+ PiiEpxt (xt)['(h(Xt),ft(Xt))]
-	Rt(h, ft)I
≤∣P01Eqxt(xt)['(h(Xt),ft(Xt))]+ P1ι(Rt(h,ft)+ POiMt)
-	Rt(h, ft)I
=IpOi(Eqxt(xt)['(h(Xt),ft(Xt))] - Rt(h,ft))+ PliPOiMtI
≤ ρ0i max{Eqxt(xt)['(h(Xt), ft(Xt))],R(h,ft)} + ρiiP0iMt.
This lemma is proved.	口
Remark 5. In Lemma 2, the assumption Ep；∕xt)['(h(X.), ft(Xt))] ≤ Rt(h, ft) + ρ0iMt means that the
expect risk restricted in B (i.e., Ep； ⑶)['(h(Xt), ft(Xt))]) Can represent the true risk Rt(h, ft) when ρ0i is
small, where B = {X : ft(X) = ft(X)}. In Butterfly, it is equivalent to that pseudo labels provided by noisy
source data are more useful if we can select more correct data from noisy source data. If this assumption fails,
we cannot gain useful knowledge from ft even when we can perfectly select correct data from pseudo-labeled
target data (PtOi = 0).
24
Under review as a conference paper at ICLR 2020
Inequalities (16), (17) and (18)	show that	if	we can avoid to annotate incorrect data	as	“correct”
(P01 = 0 and ρ0ι = 0), we have	Rp (h, us)	=	Rs(h'), Rs (h, ft,ut) = Rs(h, ft) and Rp	(h,	ft,ut)=
c∕7"∖∙λT ,11	a ι t	IC ι -rm	I^n∕7∕∖ ∖ T τm	I^n∕7∕ ∖3∕ ∖ ∖ T ι
Rt(h,ft). Nonetheless, ρ0ι and ρ0ι never equal 0,and Eqs(Xs,ys)['(h(x),y)], Eqxs(Xs)['(h(xs), ft(xs))] and
EqxJxt) ['(h(xt), ft(xt))] may equal +∞ for some h. In next section, we prove that, under the assumption
in Remarks 2 and3, Rp (h, us) → Rs(h), Rs (h, ft,ut) → RS(h, ft) and Rp (h, ft,ut) → Rt(h,ft) if
ρs01 → 0 and ρt01 → 0. Moreover, we give a new upper bound of Rt(h, ft).
H.3.2 Proof of Theorem 3
Now, we prove Theorem 3 as follows.
.	.	-	-	..~1Λ∩ ，一	、	~1Λ∩ ，一 ≈	、 一 ，- U、、	一， ~1Λ∩ ，一 二	、
Proof. We first prove upper bounds of |RS (h, US)-RS (h)|, |RS (h, ft, Ut)-RS (h, ft)| and |Rp (h, ft, Ut)-
Rt(h, ft)| under assumptions in Theorem 3.
Based on Lemma 1, we have
.~_____ . .. . , ., . . ..
∣RSo(h,Us) - Rs(h)∣ = ∣ρ0ιEqs(xs,ys)['(h(χs),ys)] - (1 - p1i)Rs(h)∣
≤ ∣P0ι(Rs(h) + Ms) - P0ιRs(h)∖
= ρS01 MS .
Similar, we have
∖RSo(h,ft,ut) - Rs(h,ft)∖ ≤ P0ιMt,
∖Rpo(h, ft, ut) - Rt(h,ft)∖ ≤ P01Mt + ρ1ιP0ιMt.
Since MS and Mt are positive constants, it is clear that Rpo(h, us) → RS (h), Rp°(h, ft,ut) → RS (h, ft)
and Rp (h,ft,ut) → Rt(h,ft) when ρ0ι → 0 and ρ0ι → 0.
Specifically, ∀ ∈	(0, 1), let δt	=	/Mt and δS	=	/ max{MS, ρt11Mt}.	When ρS01	< δS and ρt01	<	δt, we
have
.~____________________________.. . .. . ~_______________ ~ . . ~..
∖Rpo(h,US) - RS(h)∖ + ∖Rpo(h,ft,ut) - RS(h,ft)∖ < 2e
.~cc	~	.	..
∖Rpo(h,ft,ut)- Rt(h,ft)∖ < 2e.
Hence, we prove the Eq. (8). In following, we give a new upper bound of Rt(h, ft). Call back to Theorem
2, we replace 1) R§(h) with Rp (h,%),2) R§(h, ft) With Rp (h, ft, ut),3) R§(h, ft) with Rp (h,ft,ut).
Then, we have
Rt(h,ft) ≤ RSo(h,US) + ∖Rpo(h,ft,ut) - RSo(h,ft,ut))∖ + ∖Rs(% ft) - RS(h)∖
.~_____ . . . ~_____________ ~ . ~ . . . ~一 . ~ ..
+ ∖Rpo(h,US) - R,(h)∖ + ∖RSo(h,ft,ut)- RS(h,ft)∖ + ∖Rt(h,ft) - R°(h, ft,u)∖.
Let ρS01 ≤ δS and ρt01 ≤ δt, we have
Rt(h,ft) ≤	RSo(h,%)	+
S----{z----}
(i) risk on noisy data
∖Rpo(h, ft, ut) - RSo(h, ft, Us)∖ + ∖RS(h, ft) - R,(h)∖
S------------------{-----------------} S-----------------{z-------}
(ii) discrepancy between distributions (iii) domain dissimilarity
+ (iv)noiseeffeSct{2szef}romsource∆s + (v)noiseeffeSc{2tszef}romtarget∆t
Hence, we prove this theorem.
□
25