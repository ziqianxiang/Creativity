Under review as a conference paper at ICLR 2020
A Unified framework for randomized
SMOOTHING BASED CERTIFIED DEFENSES
Anonymous authors
Paper under double-blind review
Ab stract
Randomized smoothing, which was recently proved to be a certified defen-
sive technique, has received considerable attention due to its scalability to large
datasets and neural networks. However, several important questions still remain
unanswered in the existing frameworks, such as (i) whether Gaussian mechanism
is an optimal choice for certifying '2 -normed robustness, and (ii) whether random-
ized smoothing can certify '∞-normed robustness (on high-dimensional datasets
like ImageNet). To answer these questions, we introduce a unified and self-
contained framework to study randomized smoothing-based certified defenses,
where we mainly focus on the two most popular norms in adversarial machine
learning, i.e., '2 and '∞ norm. We answer the above two questions by first demon-
strating that Gaussian mechanism and Exponential mechanism are the (near) op-
timal options to certify the '2 and '∞-normed robustness. We further show that
the largest '∞ radius certified by randomized smoothing is upper bounded by
O(1/√d), where d is the dimensionality of the data. This theoretical finding sug-
gests that certifying '∞ -normed robustness by randomized smoothing may not be
scalable to high-dimensional data. The veracity of our framework and analysis is
verified by extensive evaluations on CIFAR10 and ImageNet.
1	Introduction
The past decade has witnessed tremendous success of deep learning in handling various learning
tasks like image classification (Krizhevsky et al., 2012), natural language processing (Cho et al.,
2014), and game playing (Silver et al., 2016). Nevertheless, a major unresolved issue of deep learn-
ing is its vulnerability to adversarial samples that are almost indistinguishable from natural samples
to humans but can mislead deep neural networks (DNNs) to make wrong predictions with high
confidence (Szegedy et al., 2013; Goodfellow et al., 2014). This phenomenon, referred to as adver-
sarial attack, is considered to be one of the biggest threats to the deployment of many deep learning
systems. Thus, a great deal of effort has been devoted to developing defensive techniques for it.
However, the majority of the existing defenses are of heuristic nature (i.e., without any theoretical
guarantees), implying that they may be ineffective against stronger attacks. Recent works (He et al.,
2017; Athalye et al., 2018; Uesato et al., 2018) have confirmed this concern, and showed that most of
those heuristic defenses actually fail to defend stronger adaptive attacks. This forces us to shift our
attentions to certifiable defenses as they can classify all the samples in a predefined neighborhood
of the natural samples with a theoretically-guaranteed error bound. Among all existing certifiable
defensive techniques, randomized smoothing emerges as the most popular one due to its scalability
to large datasets and arbitrary networks. Remarkably, using the Gaussian mechanism for random-
ized smoothing, Cohen et al. (2019) successfully certify 49% accuracy on the original ImageNet
dataset under adversarial perturbations with '2 norm less than 0.5. Despite these successes, there
are still several unanswered questions regarding randomized smoothing based certified defenses.
One of such questions is, why should Gaussian noise be used for randomized smoothing to certify
'2 -normed robustness, and is Gaussian mechanism the best option? Another important question is
regarding the generalizability of this method to other norms, especially the '∞ norm. If randomized
smoothing can be used to certify '∞-normed robustness, what mechanism is the optimal choice?
To shed light on the above questions, we propose in this paper a unified and self-contained frame-
work for randomized smoothing-based certified defenses. We look at the problem from a differential
privacy’s point of view and present two types of robustness in this framework. One is motivated by
1
Under review as a conference paper at ICLR 2020
Mechanism	'2-normed D∞ Robustness DMR Robustness		D∞ Robustness	'∞-normed DMR Robustness
Gaussian	unable to certify	near optimal	unable to certify	near optimal
		r scales in O(1)		r scales in O(1∕√dlogd)
Exponential	not optimal	not optimal	optimal r scales in O(1 /d)	not optimal
Table 1: Summary of our framework
-differential privacy (-DP), which uses ∞-divergence to measure the distance between the prob-
abilities of predictions on randomized natural samples and randomized adversarial samples and is
therefore called D∞ robustness. The other is inspired by -zero concentrated differential privacy
(E-ZCDP) that uses the Maximal Relative Renyi (MR) divergence as the probability distance mea-
surement and is called DMR robustness. For both of them, we focus on certifying robustness in
either '2 or '∞ norm by randomized smoothing. Specifically, our contributions are five-fold:
1.	We propose a unified and self-contained framework for certifying D∞ and/or DMR robust-
ness in '2 and '∞ norms by randomized smoothing.
2.	In our framework, we demonstrate that the Gaussian mechanism is a near optimal choice
for certifying DMR robustness in '2 norm, and the robust radius is O(1).
3.	We also prove that an exponential mechanism is the optimal choice for certifying D∞
robustness in '∞ norm, but the robust radius is only O(1/d), making it unscalable to high-
dimensional data.
4.	We show that the Gaussian mechanism is also a near optimal choice for certifying DMR ro-
bustness in '∞ norm, but the robust radius is O (1 / √d log d), making it also hardly scalable
to high-dimensional data.
5.	The largest robust '∞ radius that can be certified by randomized smoothing to achieve
DMR robustness is upper bounded by O(1/√d).
Table 1 summarizes the (near) optimal mechanisms of our framework for certifying the '2 and '∞-
normed robustness.
2	Related Work
There are three main approaches for certified defenses. The first approach formulates the task of
adversarial verification as an optimization problem and solves it by relaxations (Dvijotham et al.,
2018; Raghunathan et al., 2018; Wong & Kolter, 2018). The second approach uses different tech-
niques, such as interval analysis and abstract interpretations, to maintain an outer approximation of
the output at each layer through the network. (Mirman et al., 2018; Wang et al., 2018; Gowal et al.,
2018). The third approach uses randomized smoothing to certify robustness, and is gaining popular-
ity recently due to its strong scalability (Lecuyer et al., 2018; Li et al., 2018; Cohen et al., 2019) to
large datasets and arbitrary networks. For this approach, Lecuyer et al. (2018) showed that random-
ized smoothing can certify the '2 and '1-normed robustness by using inequalities from differential
privacy. Li et al. (2018) achieved a stronger guarantee on the '2 -normed robustness using tools from
information theory. Cohen et al. (2019) further obtained a tight guarantee on the '2-normed robust-
ness using Gaussian noise. A remaining issue in all of these works is that they did not give answers
to questions like why Gaussian noise is used to certify the '2-normed robustness and what is the
best mechanism to certify the '∞-normed robustness. To answer these questions, we present in this
paper a new general framework to study randomized smoothing based certified defenses.
3	Robustness Motivated by Differential Privacy
In this section, we introduce our framework. Let x be a data sample and y ∈ Y be its label, where Y
is the label set. We denote by f (∙) a deterministic classifier with prediction f (x) for any data sample
x. If there exists an x0 in a small lp ball centered at x and with f(x0) 6= f (x), x0 is viewed as an
adversarial sample.
2
Under review as a conference paper at ICLR 2020
Definition 1 (Randomized Classifier (Cohen et al., 2019)). Given an input x, the prediction of a
randomized classifier g(∙) is defined as
argmax P (g(x) = c).
c∈Y
Specifically, for a randomized smoothing classifier g(x) = f(x + Z), where Z is a random vector
and f (∙) is a deterministic classifier, the prediction of X is the class of C whose region S，{x ∈
Rd, f (X) = c} has the largest probability measure in the distribution of X + Z (X 〜p(x + Z)).
Before introducing our framework, we first recall the definition of robustness for a deterministic
classifier in (Diochnos et al., 2018).
Definition 2 (Robustness (Diochnos et al., 2018)). For a given classifier f, a sample X and some
norm ∣∣ ∙ ∣∣. f is (r, k ∙ ∣∣)-(error-region) robust on the sample X if
∀X0 ∈ B(X, r), f(X) = f(X0),	(1)
where B(x, r) is the ball centered at X and with norm ∣∣ ∙ ∣∣ and radius r.
Note that in Definition 2, the classifier is assumed to be deterministic. To generalize the concept
of robustness to randomized classifiers (see Definition 1), we define a relaxed version of the (error-
region) robustness. Since g(X) is a random value, instead of using equality, we measure the dif-
ference between g(X) and g(X0) by a certain divergence. This leads us to the following definition,
which is a basic concept in our framework that will be used throughout the paper.
Definition 3 (Relaxed Robustness). For a given (randomized) classifier g(∙), a Sample X and some
norm ∣∣ ∙ ∣∣, the classifier g is (r, D, ∣ ∙ ∣∣, e)-(error-region) robust on X if
∀X0 ∈ B(X, r), max{D(g(X), g(X0)), D(g(X0), g(X))} ≤ .	(2)
where D is some divergence metric between two probability distributions. The max function is used
to ensure that the measurement is symmetric.
Compared with Definition 2, there are two additional terms in Definition 3: represents the “dis-
tance” or difference between the distributions of g(X) and g(X0). When is small, we expect that
the distributions of predictions on X and X0, i.e., g(X) and g(X0), are almost the same, which is
just a generalization of the equality in Definition 2. D is some divergence measurement between
two probability distributions. In this paper, we use two types of divergence, ∞-Divergence and
Maximal Relative Renyi Divergence, to measure the distance between two probability distributions.
Correspondingly, we have two types of robustness called D∞ and DMR robustness.
Definition 4 (∞-Divergence). The ∞-Divergence D∞ of distributions P and Q is defined as
D∞(P ∣Q)=	sup log P(W,
x∈supp(Q)	Q(X)
where supp(Q) is the support of the distribution Q.
Definition 5 (Maximal Relative Renyi Divergence). The Maximal Relative Renyi Divergence
DMR(P∣Q) of distributions P and Q is defined as
D Dap∖	Da(P IQ
DMR(P∣∣Q) = max、--------------,
α∈(1,∞)	α
where Da(PIlQ) is the Renyi divergence between P and Q, which is defined as
Da(P ∣Q) = jlog Ex 〜q(笔尸.
α - 1	Q(X)
Definition 6 (D∞ Robustness). A randomized smoothing mechanism A(∙) (including classifiers) is
a (r, D∞,∣∙ Il, e)-robust mechanism if
∀X0 ∈ B(X, r), max{D∞ (A(X), A(X0)), D(A(X0), A(X))} ≤ ,	(3)
where ∣∣ ∙ ∣ is the norm ofthe ball B(x, r). Ifa randomized smoothing classifier g(∙) satisfies Eq. (3),
it is a (r, D∞, ∣ ∙ ∣∣, e)-robust classifier or it certifies D∞ Robustness.
3
Under review as a conference paper at ICLR 2020
D∞ Robustness is motivated by the notion of -differential privacy (-DP) (Dwork et al., 2006).
To achieve -DP for a randomized algorithm, we can use several mechanisms such as Laplacian
mechanism or Exponential mechanism (see (Dwork et al., 2014) for details). However, it is known
that adding Gaussian noise often does not lead to -DP, but rather (, δ)-DP (Dwork et al., 2014)
which has an additional parameter δ and thus is harder to be incorporated in our framework. To
alleivate this issue, We employ Maximal Relative Renyi Divergence as the the probability distance
measurement to define another type of robustness, namely DMR robustness.
Definition 7 (DMR Robustness). A randomized smoothing mechanism A(∙) is a (r, DMR, k ∙ ∣∣, e)-
robust mechanism if
∀x0 ∈ B(x, r), max{DMR(A(x), A(x0)), DMR(A(x0), A(x))} ≤ .	(4)
Ifa randomized smoothing classifier g(∙) satisfies Eq. (4), it is a (r, Dmr, ∣ ∙ ∣∣, C)-robust classifier
or it certifies DM R Robustness.
DM R Robustness is inspired by the notion of zero-Concentrated Differential Privacy (zCDP) (Bun
& Steinke, 2016), Whose connection to DP is shoWn in the folloWing theorem.
Theorem 8 ((Bun & Steinke, 2016)). Let P and Q be two probability distributions satisfying the
conditions of D∞(P∣∣Q) ≤ E and D∞(Q∣P) ≤ 匕 Then, DMR(P∣∣Q) ≤ 1 c2.
Theorem 8	indicates that DMR-robustness is a relaxed version of D∞-robustness.
Remark (Connections betWeen D∞ & DMR Robustness and Standard Definitions). Although D∞
& DM R Robustness are seemingly new concepts defined in this paper, they actually have several
connections with the existing frameworks Lecuyer et al. (2018) and Cohen et al. (2019). Specifically,
as long as D∞ robustness is certified, the expected output stability bound in Lecuyer et al. (2018)
will be guaranteed with δ0 = 0. And if DM R robustness is certified, the expected output stability
,	,	.	—	—	，一2、
bound in Lecuyer et al. (2018) will be guaranteed with c0 = (C + 1)√e and δ = exp(-c4),
according to Theorem 10. Besides, the “scale” of the robust radius certified by our framework is
similar the “scale” of the robust radius in Cohen et al. (2019), according to Corollary 11.
Theorem 9	(Postprocessing Property). Let g(x) = f (A(X)) be a randomized classifier, where f (∙)
is any deterministic function (classifier). g(∙) is (r, D, ∣ ∙ ∣∣, e)-robust if A(∙) is (r, D, ∣ ∙ ∣∣, e)-robust
(where D includes D∞ and DMR).
The above theorem is derived from the post-processing properties of DP and zCDP. A detailed
proof (explanation) is given in Appendix B. This property allows us to concentrate only on
the randomized smoothing mechanism A without needing to consider the specific form of the
deterministic function (classifier) f (∙). Next, we consider the cases of certifying D∞ or DMR
robustness using '2 and '∞-norm.
3.1 CERTIFYING `2 -NORMED ROBUSTNESS
The following theorem shows that randomized smoothing by the Gaussian mechanism is
(r,DMR, ∣∣∙ ∣∣,e)-robust.
Theorem 10. Let f be any classifier and g(x) = f (x+z) be its corresponding randomized classifier
for samples X ∈ Rd, where Z 〜N(0,σ2Id). Then, g(∙) is (r, Dmr, ∣ ∙ ∣∣2, 2σ2)-robust on any X.
2
Moreover, let c denote 2σ2. Then, for any λ > 0 and any measurable set S = 0, thefollowing holds
with probability at least 1 — exp(一 λ22),
log f∏⅛¾ ≤ λ + √	(5)
P (g(X0) ∈ S)
That is, when λ = c√c, log p(g(χ)∈Sl) ≤ (C + 1)√E with probability 1 — exp(-4). In practice,
c = 3 is enough to achieve a high probability.
Corollary 11. Adding Gaussian noise Z ∈ N(0, σ2Id) can defend any x0 ∈ B(x, r = √2eσ) that
2
satisfies the condition of DMR(g(x)∣g(x )) ≤ c with probability at least 1 — exp(-c4). Further-
more, √c can be calculated (bounded) by (logPa — logpb)∕2(1 + c) or (logPɑ∕(1 — pa))/2(1 + c)
(binary case), where Pa and Pb are respectively the probabilities of the randomized classifier g(∙)
returning the most probable class Ca and the runner-up class Cb on input X.
4
Under review as a conference paper at ICLR 2020
Detailed proofs for Theorem 10, Corollary 11, and all the following theorems are provided in
Appendix B. From Theorem 9, we can see that for classifiers like g(x) = f(x + z), we only need
to prove that the randomized mechanism A(X) = X + z(z 〜N(0, σ2Id)) is (r, DMR, k ∙ ∣∣2,	)-
robust. Also, the connection between E and pa, Pb can be derived for all E or √ (in the certified radii)
as in Corollary 11. Note that a similar theorem has also been proved by Cohen et al. (2019). But there
are some major differences between our framework and theirs (Cohen et al., 2019). Specifically, our
framework certifies the robustness with a probability of failure, and the certified radius r depends on
c that controls the probability of failure. A smaller c yields a larger r compared to those in Cohen
et al. (2019), and vice versa. Moreover, in our framework, we show that the Gaussian mechanism is
a near optimal option, by providing a lower bound below for all possible noises that can certify the
`2 -normed DM R robustness.
Next, we consider the following unanswered question (i.e., the first question). Since there are infinite
ways of sampling z, a natural problem is to determine whether Gaussian mechanism is the optimal
option to certify the `2 -normed DMR robustness. To answer this question, we first give a lower
bound on the magnitude of the noise z added in the randomized smoothing mechanism A(X) = X+z
to ensure that A(x), as well as f (A(X)), is (r, Dmr, ∣ ∙ ∣∣2, e)-robust. If the magnitude of Gaussian
noise is close to the lower bound, then Gaussian mechanism is considered as “near optimal”.
Theorem 12 (Lower Bound of the Noise). For any E ≤ O⑴,if there is a (2r, Dmr, ∣ ∙ ∣∣2, j)-
robust randomized smoothing mechanism A(X) = X + Z : [0, √ ]d → [0, √ ]d such that for all
X ∈ [0, √rd]d,
E[∣z∣∞] = EA∣A(X) - X∣∞ ≤ α,
for some α ≤ O(1), then it must be true that α ≥ Ω(√). In another word, Ω(√) is the lower
bound of the expected '∞ norm ofthe random noise.
Theorem 12 indicates that the expected '∞ norm of the added random noise should be at least
Ω(√rj) to guarantee (r, DMR, ∣ ∙ ∣∣2, E)-robustness. For Gaussian mechanism, the expected '∞ norm
is O(σ√log d) ((Orabona & Pal, 2015)), which is O(√√log d) according to Corollary 11. This
means that Gaussian mechanism is near optimal (i.e., up to an O(√log d) factor) here. Equivalently,
if We fix the magnitude of the expected '∞-norm of the added noise as a, the largest radius r that can
be certified by any (r, Dmr, k ∙ ∣∣2, e)-robust randomized smoothing mechanisms is upper bounded
by O(α√E), which is also close to the robust radius guaranteed by Gaussian mechanism (up to an
O(√log d) factor).
3.2 Certifying '∞-normed Robustness
Previous work on the randomized smoothing-based certified defenses (Cohen et al., 2019; Li et al.,
2018) mainly uses Gaussian noise to certify the '2-normed robustness. Thus, another natural ques-
tion (i.e., the second question) is to determine whether randomized smoothing can use some mech-
anism to certify the '∞-normed robustness. In this section, We consider this question using our
general framework.
Before extending our result to the '∞-normed case, We first recall the '2-normed case and inves-
kzk2
tigate the form of the density function of Gaussian noise: p(z) 8 exp(-1^22). Based on this,
we conjecture that, to certify '∞-normed robustness, we can sample the noise using an exponential
mechanism:
P(z) X exp(一∣z∣∞).	(6)
σ
We show in the following theorem that randomized smoothing by (6) certifies (r, Dmr, ∣∣∙ ∣∣∞, ∙)-
robustness, which could be considered as an extension of the '2-normed case. Moreover, we can
prove that it is (r, D∞, ∣ ∙ ∣∣∞, ∙)-robust. However, the certified radius r is O(1∕d), which implies
that it is unscalable to high-dimensional data.
Theorem 13. Let f be any classifier and g(X) = f (X+z) be its corresponding randomized classifier
for sample X ∈ Rd, where the noise Z 〜p(z) in (6). Then, g(∙) is (r, Dmr, Il ∙ ∣∣∞, 2^2)-robust.
Moreover it is (r, D∞, ∣ ∙ ∣∣∞, σσ)-robust.
5
Under review as a conference paper at ICLR 2020
Remark 14. Due to the high dimensionality of samples in real world applications, directly sampling
Z 〜p(z) by the Markov Chain Monte Carlo (MCMC) algorithm requires a large number ofrandom-
walks that can incur high computational cost. To alleviate this issue, we adopt an efficient sampling
method from (Steinke & Ullman, 2015) that first samples R from Gamma(d+1, σ) and then samples
z from [-R, R]d uniformly. The complexity of this sampling algorithm is only O(d).
Comparing Theorems 10 and 13, we can see that randomized smoothing via (6) can certify a region
that has (almost) the same radius as that of Gaussian distribution in the '2-normed case, due to
similarity in their density functions and the robustness guarantees. In the following theorem we
show that the magnitude of the noise added by (6) is much larger than that of Gaussian distribution
in the `2 -normed case.
Theorem 15.	For the distribution that can guarantee Theorem 13, the following theorem holds
Ez[kzk∞] = dσ.	(7)
Note that compared with the Gaussian noise added in Theorem 10 which satisfies the condition of
Ez[kzk∞] = O(σ√logd), the expected '∞-norm of the distribution in (6) is proportional to the
dimensionality d of the data, which is quite large. This means that for any image data, at least one
pixel will be perturbed by the magnitude of dσ, which will completely ruin the accuracy of the
classification network. However, if we want the noise to have a magnitude of O(1), σ needs to be
O(1/d), and so does the robust radius.
Theorem 15 is a somewhat negative result for randomized smoothing using distribution (6) to cer-
tify the '∞-normed robustness. Thus, an immediate question is whether exponential mechanism is
the right choice to certify the '∞-normed robustness. The following theorem shows that for any
(r, D∞, k ∙ ∣∣∞, r)-robust randomized smoothing mechanism, the expected '∞-norm of the added
noise is lower bounded by Ω(dσ). Thus, combining the following theorem with Theorem 15, We can
conclude that the exponential mechanism is actually an optimal choice to certify D∞ robustness.
Theorem 16.	Forany (2r, D∞, ∣ ∙ ∣∣∞, 2)-robust mechanism A(X) = X + Z : [0, r]d → [0, r]d such
that
E[∣Z∣∞] = EA∣A(X) - X∣∞ ≤ α,∀X ∈ [0, r]d,
it must be true that a ≥ Ω(rd).
From Theorem 16 we can see that, for any (∙, D∞, ∣ ∙ ∣∣∞, 2)-robust randomized smoothing mech-
anism, if we fix the expectation of the '∞-norm of the added noise in the exponential mechanism
as α, the largest '∞ radius that can be certified is upper bounded by O(αe∕d). Compared with the
'2-normed case in Theorem 11, we can see that there is an additional factor of O(1∕d), which makes
it unscalable to high-dimensional data. Equivalently, if we want the same radius to be certified as in
the Theorem 10, the expected '∞-norm of the added noise needs to be at least Ω( rd), which will be
too large for any image data.
The less than ideal lower bound in Theorem 16 is for D∞-robustness. Since DMR-robustness is
more relaxed than D∞-robustness, a natural question is thus to determine whether the lower bound
can be improved by switching to DMR-robustness. Unfortunately, the following theorem shows that
a similar phenomenon still holds for DMR-robustness.
Theorem 17.	For any (2r, Dmr, ∣ ∙ ∣∣∞, 2)-robust mechanism A(X) = X + Z : [0,r]d → [0,r]d
such that
E[∣z∣∞] = EAIIA(X)- X∣∣∞ ≤ α,∀x ∈ [0,r]d,
it must be true that a ≥ Ω(r√d).
From Theorems 17 and 15 we can see that in the definition of (2r, Dmr, ∣∙ ∣∣∞)-robustness, adding
noise according to (6) is not near optimal. The following theorem shows that in this case, Gaussian
mechanism is actually a near optimal choice.
Theorem 18.	Let r,e > 0 be some fixed number and A(X) = X + Z with Z 〜 N(0, dr2). Then,
A(∙) is (r, Dmr, ∣∣∙ ∣∣∞, e)-robust. E[∣z∣∞] = EAkA(X) — x∣∞ is upper bounded by O( r√√∣g d).
From Theorem 17 and 18, we can conclude that for all randomized smoothing mechanisms that
are (∙, 0, DMR, ∣ ∙ ∣∣∞, ∣)-robust, if the expected '∞-norm of the added noise is fixed to be α, the
6
Under review as a conference paper at ICLR 2020
-----train σ = 0.25
train σ = 0.50
----- train σ= 1.00
----train σ= 0.25
train σ= 0.50
—train Cr= 1.00
Figure 1: Certifying DMR robustness in `2 norm on CIFAR-10: vary the Gaussian noise used in the
training process and fix the σ of the Gaussian mechanism as σ = 0.5. c = 1 (left) and c = 3 (right)
largest radius that can be certified is upper bounded by O (r√Fα), and the largest radius that can be
certified by GaUSSian mechanism is OQNdlog d) (and σ is Ω(√∣0=)). If α and e are both set
to be O(1), the largest radius that can be certified using Gaussian mechanism to achieve DMR-
robustness is greater than the largest radius that can be certified to achieve D∞ -robustness by at
least a factor of O(<d/ log d). This is reasonable since the definition of DMR-robustness is more
relaxed. Obviously, there is some trade-off between the rigorousness of the notion of robustness
and the largest certified robust radius, i.e., when the robustness is relaxed, the largest certified radius
increases. We will investigate this trade-off more in the future research.
4	Experiments
4.1	Datasets and Models
The performance of our framework is verified on two widely-used datasets, i.e., CIFAR10 and Im-
ageNet*. Following Cohen et al. (2019), We use a 110-layer residual network and the classical
ResNet-50 as the base models for CIFAR10 and ImageNet respectively. Note that it may be difficult
for the models to classify noisy images without seeing any noisy samples in the training stage. Thus,
we train all the models by adding appropriate Gaussian noise on the training images. The certified
accuracy for radius R is defined as the fraction of the test set whose certified radii are larger than R
L The value of e in all our derived certified radii can be calculated by Pa (or PQ and Pb) as shown
in the proof of Corollary 11. It is also worth noting that we do not compare our results with (Cohen
et al., 2019) in the experiments because our framework and (Cohen et al., 2019) endow robustness
with different definitions. Moreover, our work does not aim at improving the tightness of the guar-
antee on the '2 -normed robustness but aims at presenting a general and self-contained framework
to study some remaining issues, such as the optimality of the Gaussian mechanism, and the specific
mechanisms to certify the '∞ -normed robustness.
4.2	Empirical Results
Certifying the '2-normed Robustness To certify the '2-normed Robustness, as we explained
in previous section, Gaussian mechanism is a near optimal option. Thus, we mainly evaluate the
performance of Gaussian mechanism in our framework. We first fix the value of σ in Gaussian
mechanism and show the certified accuracy of the classifiers trained by varied Gaussian noises in
Figure 1. As shown in Figure 1, using σ = 0.50 Gaussian noise to train the classifier is a good
setting here. So in Figure 2, we evaluate the Gaussian mechanism with different σ values on the
classifier trained by σ = 0.50 Gaussian noise. Overall, on CIFAR-10, our framework can certify
approximately 20% accuracy under '2 = 1.0 perturbation+. We also show the results on ImageNet
by Figures 4 and 5 in Appendix C.
* Pixel value range is [0.0,1.0]
tFor more details, please refer to (Cohen et al., 2019)
iOn CIFAR-10, '2 = 1.0 perturbation allows 4/255 perturbation on every pixel
7
Under review as a conference paper at ICLR 2020
Figure 2: Certifying DM R robustness in `2 norm on CIFAR-10: vary the σ in the Gaussian mecha-
nism and fix σ of the training noise as σ = 0.50. c = 1 (left) and c = 3 (right)
Figure 3: Certifying D∞ robustness and DMR robustness in '∞ norm on CIFAR-10: vary the σ in
the Exponential mechanism (left) vary the σ in the Gaussian mechanism (right). The classifier is
trained with σ = 0.50 Gaussian noise.
Certifying the '∞-normed Robustness To certify the '∞-normed robustness, We evaluate the
performance of the Exponential mechanism in the definition of D∞-robustness and the Gaussian
mechanism in the definition of DMR-robustness. As shown in Figure 3, the '∞ radii that can be
certified by Gaussian mechanism are about 10 〜 20 times (i.e., O(ʌ/d/ logd) with d = 3072
as shown in our theories) larger than the '∞ radii certified by the exponential mechanism. On
ImageNet, as shown in Figure 6 in Appendix C, the robust radii are less than 1/255 (due to scaling
in O(1∕d) or O(1∕√dlog d)), indicating that certifying the '∞-normed robustness by randomized
smoothing may not be applicable to high-dimensional data.
5	Conclusion
In this paper, we present a general framework for certifying two types of robustness (D∞ and DMR-
robustness) in the '2 and '∞ norms by randomized smoothing. Under our framework, we first give
the answers to the remaining questions in the previous studies on randomized smoothing-based
certifiable defenses, i.e., the optimality of Gaussian mechanism and the possibility to certify the
'∞-normed robustness. Specifically, we demonstrate that (i) Gaussian mechanism is a near optimal
option to certify DMR-robustness in `2 norm by giving a lower bound on all DM R -robust mecha-
nisms, with certified radii scaling in O(1); (ii) an exponential mechanism is the optimal choice for
certifying D∞-robustness in '∞ norm, with certified radii scaling in O(1∕d); (iii) Gaussian mech-
anism is a near optimal option to certify DMR-robustness in '∞ norm, with certified radii scaling
in OQNdlog d); (iv) the largest '∞ radius that can be certified by randomized smoothing in our
framework is upper bounded by O(1∕ʌ/d), indicating that randomized smoothing may not be scal-
able to high-dimensional data in terms of certifying the '∞-normed robustness.
8
Under review as a conference paper at ICLR 2020
References
Anish Athalye, Nicholas Carlini, and David Wagner. Obfuscated gradients give a false sense of
security: Circumventing defenses to adversarial examples. arXiv preprint arXiv:1802.00420,
2018.
Mark Bun and Thomas Steinke. Concentrated differential privacy: Simplifications, extensions, and
lower bounds. In Theory OfCryptography Conference, pp. 635-658. Springer, 2016.
Mark Bun, Jonathan Ullman, and Salil Vadhan. Fingerprinting codes and the price of approximate
differential privacy. SIAM Journal on Computing, 47(5):1888-1938, 2018.
KyUnghyUn Cho, Bart Van Merrienboer, Caglar Gulcehre, Dzmitry Bahdanau, Fethi Bougares, Hol-
ger Schwenk, and Yoshua Bengio. Learning phrase representations using rnn encoder-decoder
for statistical machine translation. arXiv preprint arXiv:1406.1078, 2014.
Jeremy M Cohen, Elan Rosenfeld, and J Zico Kolter. Certified adversarial robustness via randomized
smoothing. arXiv preprint arXiv:1902.02918, 2019.
Dimitrios Diochnos, Saeed Mahloujifar, and Mohammad Mahmoody. Adversarial risk and robust-
ness: General definitions and implications for the uniform distribution. In Advances in Neural
Information Processing Systems, pp. 10359-10368, 2018.
Krishnamurthy Dvijotham, Robert Stanforth, Sven Gowal, Timothy A Mann, and Pushmeet Kohli.
A dual approach to scalable verification of deep networks. In UAI, pp. 550-559, 2018.
Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam Smith. Calibrating noise to sensitivity
in private data analysis. In Theory of cryptography conference, pp. 265-284. Springer, 2006.
Cynthia Dwork, Aaron Roth, et al. The algorithmic foundations of differential privacy. Foundations
and TrendsR in Theoretical Computer Science, 9(3-4):211-407, 2014.
Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversarial
examples. arXiv preprint arXiv:1412.6572, 2014.
Sven Gowal, Krishnamurthy Dvijotham, Robert Stanforth, Rudy Bunel, Chongli Qin, Jonathan Ue-
sato, Timothy Mann, and Pushmeet Kohli. On the effectiveness of interval bound propagation for
training verifiably robust models. arXiv preprint arXiv:1810.12715, 2018.
Moritz Hardt and Kunal Talwar. On the geometry of differential privacy. In Proceedings of the
forty-second ACM symposium on Theory of computing, pp. 705-714. ACM, 2010.
Warren He, James Wei, Xinyun Chen, Nicholas Carlini, and Dawn Song. Adversarial example
defense: Ensembles of weak defenses are not strong. In 11th USENIX Workshop on Offensive
Technologies (WOOT 17), 2017.
Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classification with deep convo-
lutional neural networks. In Advances in neural information processing systems, pp. 1097-1105,
2012.
Mathias Lecuyer, Vaggelis Atlidakis, Roxana Geambasu, Daniel Hsu, and Suman Jana. Certified
robustness to adversarial examples with differential privacy. arXiv preprint arXiv:1802.03471,
2018.
Bai Li, Changyou Chen, Wenlin Wang, and Lawrence Carin. Second-order adversarial attack and
certifiable robustness. arXiv preprint arXiv:1809.03113, 2018.
Matthew Mirman, Timon Gehr, and Martin Vechev. Differentiable abstract interpretation for prov-
ably robust neural networks. In International Conference on Machine Learning, pp. 3575-3583,
2018.
Francesco Orabona and David PaL Optimal non-aSymPtotic lower bound on the minimax regret of
learning with expert advice. arXiv preprint arXiv:1511.02176, 2015.
9
Under review as a conference paper at ICLR 2020
Aditi Raghunathan, Jacob Steinhardt, and Percy Liang. Certified defenses against adversarial exam-
ples. arXiv preprint arXiv:1801.09344, 2018.
David Silver, Aja Huang, Chris J Maddison, Arthur Guez, Laurent Sifre, George Van Den Driessche,
Julian Schrittwieser, Ioannis Antonoglou, Veda Panneershelvam, Marc Lanctot, et al. Mastering
the game of go with deep neural networks and tree search. nature, 529(7587):484-489, 2016.
Thomas Steinke and Jonathan Ullman. Between pure and approximate differential privacy. arXiv
preprint arXiv:1501.06095, 2015.
Thomas Steinke and Jonathan Ullman. Between pure and approximate differential privacy. Journal
of Privacy and Confidentiality, 7(2), 2016.
Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian Goodfellow,
and Rob Fergus. Intriguing properties of neural networks. arXiv preprint arXiv:1312.6199, 2013.
Jonathan Uesato, Brendan ODonoghue, Pushmeet Kohli, and Aaron Oord. Adversarial risk and the
dangers of evaluating against weak attacks. In International Conference on Machine Learning,
pp. 5032-5041,2018.
Roman Vershynin. High-dimensional probability: An introduction with applications in data science,
volume 47. Cambridge University Press, 2018.
Shiqi Wang, Kexin Pei, Justin Whitehouse, Junfeng Yang, and Suman Jana. Efficient formal safety
analysis of neural networks. In Advances in Neural Information Processing Systems, pp. 6367-
6377, 2018.
Eric Wong and Zico Kolter. Provable defenses against adversarial examples via the convex outer
adversarial polytope. In International Conference on Machine Learning, pp. 5283-5292, 2018.
10
Under review as a conference paper at ICLR 2020
A Differential Privacy Background
In this section, we briefly introduce the concepts of differential privacy used in this paper.
Definition 19 (Differential Privacy (DP) (Dwork et al., 2006)). Given a data universe X, we say
that two datasets D, D0 ⊆ X are neighbors if they differ by only one entry, which is denoted by
D 〜D0. A randomized algorithm A is E-differentially private (DP) if for all neighboring datasets
D, D0 the following holds
D∞(A(D)kA(D0)) ≤E.
Intuitively, DP ensures that an adversary cannot infer whether or not a participant (data sample) is
participating in dataset D due to the fact that the distribution of A(D) is almost the same as that of
A(D0), which means that DP-mechanisms are robust to 1-sample change. Now consider the case
where D is some 1-size dataset (i.e., one data sample). Then, DP ensures that the distribution of
A(D) and A(D0) are almost the same, where D0 is just any other data sample. Inspired by notion
of DP, we define D∞ robustness in Definition 6.
Definition 20 (Zero-Concentrated Differential Privacy (zCDP)). A randomized mechanism A is
called E-ZCDP iffor all D 〜D0
max{DMR(A(D)kA(D0)), DMR(A(D0)kA(D))} ≤ E.	(8)
zCDP is a relaxed version of DP according to Theorem 8. Motivated by zCDP, we define DMR
robustness in Definition 7.
B Omitted Proofs
Proof of Theorem 9. This theorem can be easily proved by the following lemma,
Lemma 21 ((Bun & Steinke, 2016)). Let P and Q be two distributions on Ω and let f : Ω → Θ be
a deterministic function. Let f(P) and f(Q) denote the distributions on Θ induced by applying f
to P and Q respectively. Then we have
Dα(f(P)kf(Q)) ≤ Dα(PkQ).
Similar post-processing property also holds when α = ∞ (DWork et al., 2006). Therefore, if A(∙)
satisfies Definition 6 or 7, then f (A(∙)) will satisfy Definition 6 or 7 for any deterministic function
(classifier) f (∙).	口
Proof of Theorem 10. By Theorem 9, we only need to show that the randomized smoothing mecha-
nism A(X) = X + Z is (r, Dmr, k ∙ ∣∣2)-robust, which can be proved by the following lemma.
Lemma 22 ((Bun & Steinke, 2016)). Let x, x0 ∈ Rd, and α ∈ [1, ∞). Then
Da(N(X,σ2Id)kN(x0,σ2Id)) = αkx Jx0k2.
2σ2
2
Thusfor all x0 ∈ B(x, r), we have DMR(A(x)∣A(x0)) ≤ 字.
Next we prove (5). To prove this inequality, we first define the loss random variable.
Definition 23 ((Bun & Steinke, 2016)). Let Y and Y0 be random variables on Ω. We define the loss
random variable between Y and Y0, denoted by Z = Loss(Y kY 0), as follows: Define a function
F : Ω → R by F(y) = log P[Y=y]]. Then Z is distributed according to F(Y).
By this we can write Z = Loss(g(X)∣g(X0)) and rewrite DMR(g(X)∣g(X0)) as
2
∀α ∈ (1, ∞], E[e(aT)Z] ≤ e(aT)2σ2a.
This implies that Z is sub-Gaussian. By using the tail-bound of sub-Gaussian (Vershynin, 2018), we
have
λ2
P[Z>λ + e] ≤ exp(-晨),	(9)
where 枭=e.	口
11
Under review as a conference paper at ICLR 2020
ProofofCorollary 11. Since we fix E = 3,the certified radius is r = √2eσ. Now We prove the
upper bound of √ for a classifier g(∙). Given Theorem 10, we should have
P (g(x) = Ca)
P (g(x0) = Ca)
≤ (C + I)√E,
and
P (g(x0) = Cb)
P(g(x) = Cb)
≤ (C + I)√e,
since X is also in B(x0, r). Then we have log p(g(X0)=Ca) ≥ log P(g(X)=Ca] - 2(c + 1)√E. According
to Definition 1, as long as log P(g(χ0)=Ca) > 0, g(∙) can correctly classify χ0. Thus, as long as
log P(g(X)=Ca) - 2(c +1)√e > 0 (i.e., √ < (logPa Togpb)∕2(1+ c)), g(∙) classifies x0 as c&. □
Proofof Theorem 12. Let {χι, X2, ∙∙∙ , X2d} = {0, √}d. For each Xi, we use the same adversarial
example χ0 = 0 to derive the lower bound. Since A is (2r, Dmr, k ∙ ∣∣2, j)-robust, we have for all
Xi, Xj, i, j ∈ [2d],
max{DMR(A(xi)kA(xj)), DMR(A(Xj)kA(Xi))} ≤ 2 ∙ ∣ = e.
That is A is E-ZCDP on the dataset X = {0, -√2 }d. Next we will prove the lower bound for all
E-zCDP mechanisms.
We first consider the case where r = √d, and then generalize it to any r. Before that we will first
prove the lower bound of one-way marginal (i.e., mean estimation) under E-zCDP. For an n-size
dataset X ∈ Rn×d, the one-way marginal is just h(D) = 1 Pn=I Xi, where Xi is the i-th row of
X. Specifically, when n = 1, one-way marginal is just the data point itself. We show the following
theorem,
Theorem 24. If there exists an E-zCDP mechanism A : {0, 1}d 7→ [0, 1]d such that for all x ∈
{0, 1}d
EkA(x) - xk∞ ≤ α,
(10)
then 1 ≥ Ω(√*
Proof of Theorem 24. To prove this theorem, our idea is to first use the connection between E-zCDP
and (E, δ)-DP.
Lemma 25 (Prop.1.3 in Bun & Steinke (2016)). If A is E-ZCDP then it is (E + 2 JE log 1, δ)-
differentially private.
Bun et al. (2018) first give the optimal rate of one-way marginal estimation which is improved by
Steinke & Ullman (2016).
Lemma 26 (Theorem 1.1 in Steinke & Ullman (2016)). For every E ≤ O(1), every 2-ωS) ≤ δ ≤
nι+Ω(i) and every α ≤ 110, if A : ({0,1}d)n → [0,1]d is (e, δ) -DP and E[∣A(D) - h(D)∣∞] ≤ α,
then
n ≥ Ω(
d log δ
Eα .
(11)
Setting n = 1, E
E + 2、Elog ɪ in Lemma 26, we can see that if E[∣A(x) - x∣∞] ≤ α then
1 ≥ Ω( —VZdlog 1 ∙) ≥ Ω(-√=), where the last inequality is due to the fact that -VZlog § 1
一	k(e+2√e log 1 )a‘ -	"√a2j"	Y J	e+2√e log ⅛
Ω(；).
j
≥
□
12
Under review as a conference paper at ICLR 2020
Now We Come back to the proof for any r. If A : {0,力}d → [0,}]d is e-zCDP, where
EAkA(Xi) - xik∞ ≤ α, then we have EAk √√d A(Xi) - √√d xik∞ ≤ √d α. Thus, √d A is an C-
ZCDP mechanism on {0,1}d → [0,1]d. By Theorem 24 with α = √dα ≤ O(1), we have
1
r
≥ °(~√=^2 )，
Cα2
i.e., α ≥ Ω
(12)
□
ProofofTheorem 13. We will first prove that Α(x) = X + Z is (r, D∞, k ∙ ∣∣∞, σ)-robust. Then
2
by Theorems 8 and 9, we can easily show that g(∙) is (r, Dmr, k ∙ k∞,旨)-robust. Consider
X, X0 , kX0 - Xk∞ ≤ r. Then, for any y we have
P(Iy — χ) = eχp(-ky-tχk∞)
P(y - χ0) exp(- ky-χ0k∞ )
≤ exp( ky -x0k∞ -ky -xk∞ ) ≤ exp(M-⅛) ≤ eχp(r).
σ	σσ
Thus, for any subset S we have
log A(X) ∈ S = log JSP(Z-X)dZ ≤ r.
A(x0) ∈ S	Rsp(z —X0)dz	σ
□
ProofofTheorem 15. Define the distribution D on [0, ∞) to be Z 〜D, meaning Z = ∣∣z∣∞ for
Z 〜p(z), where P(Z) is in (6). The probability density function of D is given by
Pd(z) H ZdTeXP( — Z),
σ
which is obtained by integrating the probability density function (6) over the infinity ball of radius
Z with surface area d2dZd-1 H Zd-1. PD is the Gamma distribution with shape d and mean σ, and
thus E[z] = dσ.	□
Proofof Theorem 16. Let X = {x1,x2, ∙ ∙ ∙ ,x2d} = {0, r}d be the set of samples. Since A is
(2r, k •…k∞)-robustand ∣∣Xi — Xj ∣∣∞ ≤ 2r, we know that
max{D∞(A(xi)kA(xj)),D∞(A(xj)kA(xi))} ≤C.
Thus, A : Rd 7→ Rd is C-DP on X. Similar to the proof for Theorem 12, we can reduce our problem
to studying the lower bound of one-way marginal for 1-size data problem in the C-DP model. Now
we first consider the case ofr = 1. We have the following lemma which is given by Hardt & Talwar
(2010).
Lemma 27 (Theorem 1.1 in (Hardt & Talwar, 2010)). If there exists an C-DP mechanism A :
{0, 1}d 7→ [0, 1]d satisfying the following inequality for all x ∈ {0, 1}d
EkA(x) — xk∞ ≤ α,	(13)
then 1 ≥ Ω(京).
Now we consider any C-DP mechanism A : {0, r}d 7→ [0, r]d. If
E[kA(x) — xk∞] ≤ α,
then E[k ɪA(x) —	ɪx∣∣∞]	≤ α.	That is, ɪA(x)	: {0,1}d	→ [0,1]d.	Thus, by lemma 26 we can see
that 1 ≥ Ω(dr).	r	r	r	□
Proof of Theorem 17. The proof is almost the same as that of Theorem 12. Assume that we have a
set of data points X = {xι, x2 •…，x2d} = {0, r}d. A will also be C-ZCDP on X as in the proof of
Theorem 12. Thus, if
E[kA(x) — xk∞] ≤ α,
13
Under review as a conference paper at ICLR 2020
then
E[k r A(X)- rxk∞ ] ≤ rɑ.
This means that 1 A(x) : {0,1}d → [0,1]d is E-ZCDP. Thus, by Theorem 24 We must have
1 ≥ 1 dɑ2).
□
Proof of Theorem 18. The proof is almost the same as that of Theorem 10. By Lemma 22, we have
Da(N(X, dr2)kN(χ0, dr2)) = Okx-Xi ≤ αdekx- x0k∞ ≤ αe.
Therefore, A(X) = X + Z with Z 〜N(0, dr2) is (r, Dmr, k ∙ ∣∣∞, e)-robust. Theboundof E[∣∣zk∞]
can be easily proved by substituting σ in O(σ√log d)((Orabona & Pal, 2015)) with ʌ/ ¾2.	□
14
Under review as a conference paper at ICLR 2020
C More Experimental Results (ImageNet)
C.1 CERTIFYING `2 ROBUSTNESS
Figure 4: Certifying DMR robustness in `2 norm on ImageNet: vary the the Gaussian noise in the
training process and fix the σ of the Gaussian mechanism as σ = 0.5. c = 1 (left) and c = 3 (right).
Figure 5: Certifying DMR robustness in `2 norm on ImageNet: vary the σ in the Gaussian mecha-
nism and fix the σ of the training noise as σ = 0.5. c = 1 (left) and c = 3 (right). There is no green
line because the accuracy is 0 when adding σ = 1.0 Gaussian noise to the images.
C.2 Certifying '∞ Robustness
Exponetial mechanism (D00):九 radius (le-5)
Figure 6: Certifying D∞ robustness and DMR robustness in '∞ norm by the Exponential mech-
anism and the Gaussian mechanism on imageNet: vary the σ in the exponential mechanism (left)
vary the σ in the Gaussian mechanism (right). The classifier is trained with σ = 0.50 Gaussian
noise. As we can see, the certified radius is smaller than 1/255.
15