Under review as a conference paper at ICLR 2020
SOFTLOC: ROBUST TEMPORAL LOCALIZATION
under Label Misalignment
Anonymous authors
Paper under double-blind review
Abstract
This work addresses the long-standing problem of robust event localization in the
presence of temporally misaligned labels in the training data. We propose a novel
versatile loss function that generalizes a number of training regimes from standard
fully-supervised cross-entropy to count-based weakly-supervised learning. Unlike
classical models which are constrained to strictly fit the annotations during training,
our soft localization learning approach relaxes the reliance on the exact position of
labels instead. Training with this new loss function exhibits strong robustness to
temporal misalignment of labels, thus alleviating the burden of precise annotation
of temporal sequences. We demonstrate state-of-the-art performance against stan-
dard benchmarks in a number of challenging experiments and further show that
robustness to label noise is not achieved at the expense of raw performance.
1 Introduction
The surge of deep neural networks (LeCun et al., 2015;
Schmidhuber, 2015) has accentuated the evergrowing need
for large corpora of data (Banko & Brill, 2001; Halevy et al.,
2009). The main bottleneck for the efficient creation of
datasets remains the annotation process. Over the years, while
new labeling paradigms have emerged to alleviate this issue
(e.g., crowdsourcing (Deng et al., 2009) or external informa-
tion sources (Abu-El-Haija et al., 2016)), these methods have
also highlighted, and emphasized, the prevalence of label
noise. Deep neural networks are unfortunately not immune
to these perturbations as their intrinsic ability to memorize
and learn label noise (Zhang et al., 2017) can be the cause
of training robustness issues and poor generalization perfor-
mance. In this context, the development of models robust to
label noise is essential.
This work tackles the problem of precise temporal localiza-
tion of events (i.e., determining when and which events occur)
in sequential data (e.g. time series, video or audio sequences)
despite only having access to poorly aligned annotations for
training (see Figure 1). This task is characterized by the dis-
crepency between the precision required of the predictions
during inference and the noisiness of the training labels. In-
deed, while models are trained on inaccurate data, they are
evaluated on their ability to predict event occurences as pre-
cisely as possible with respect to the ground-truth. In such
Figure 1: Temporal localization un-
der label misalignment. Models are
trained with noisy labels that differ
from the actual ground-truth, while
the final inference objective is the pre-
cise localization of events.
a setting, effective models have to infer event locations more accurately than the labels they relied
on for training. This requirement is particularly challenging for most classical approaches that
are designed to learn localization by strictly mimicking the provided annotations. Indeed, as the
training labels themselves do not accurately reflect the event location, focusing on replicating these
unreliable patterns is incompatible with the overall objective of learning the actual ground-truth.
These challenges highlight the need for more relaxed learning approaches that are less dependent on
the exact location of labels for training.
1
Under review as a conference paper at ICLR 2020
The presence of temporal noise in localization tasks is ubiquitous given the continuous nature of the
perturbation, in contrast to classification noise where only a fraction of the samples are misclassified.
Temporal labeling is further characterized by an inevitable trade-off between annotation precision
and time investment. For instance, while a coarse manual transcription of a minute of complex
piano music might be achieved within a moderate time frame, a millisecond precision requirement
— a common assumption for deep learning models — significantly increases the annotation burden.
In this respect, models alleviating the need for costly annotations are key for a wide and efficient
deployment of deep learning models in temporal localization applications.
This work introduces a novel model-agnostic loss function that relaxes the reliance of the learning
process on the exact temporal location of the annotations. This softer learning approach inherently
makes the model more robust to temporally misaligned labels.
Contributions This work: a) proposes a novel loss function for robust temporal localization under
label misalignment, b) presents a succinct analysis of the loss’ properties, c) evaluates the robustness
of state-of-the-art localization models to label misalignment, and d) demonstrates the effectiveness of
the proposed approach in various experiments.
2	Problem Formulation
The main assumption of this work is the instantaneous nature (i.e., lasting only one time-step in
discrete time settings) of the events of interest. (Durations can nevertheless be modelled in such a
framework by labeling the beginning and end of each event class as two separate channels.) Thus,
for each sample, the ground-truth TG := {(tm, cm) | m ≤ M} consists of M event occurrences each
defined by its exact timestamp (tm ∈ R≥0) and its class (cm ∈ [1, ..., d], with d event classes). In this
work, temporal label misalignment is then modelled by adding perturbations to the ground-truth
timestamps:
__r 。 ，	~.	- 一	iirl. 一	...
T ：= {(tm + em, Cm) | m ≤ M}, Where em 〜E.	(1)
Although commonly defined as a normal distribution N (0, σi2) (see experiments in Section 5.1 and
5.2), the noise distribution E can also represent a Wider range of perturbations (see experiments in
Sections 5.2 and 5.3). The training dataset D ：= {(Xi, TiL) ： 0 < i ≤ N} is comprised of N pairs with
model input (Xi) and misaligned labels (TiL). The aim of this Work is the folloWing:
Objective Estimate the true event occurrence times TG Ofan unseen input sequence X using
only the noisy data D for training.
From a practical standpoint, although not necessary for the use of our loss, time is generally dis-
cretized. In such a discrete setting, each predictor Xi of the training data D ：= {(Xi, Yi) ： 0 < i ≤ N}
is an observable temporal sequence of length Ti (i.e., Xi = (xi(t))tT=i 1 ∈ IRTi×λ) such as a DNN-
learned representation, a spectrogram or any other λ-dimensional time-series. The label sequence
Yi = (yi(t))tT=i 1 ∈ {0, 1}Ti×d is then the discrete equivalent of TL. (Note that this last statement
assumes that only one event per class can occur at each time-step; in cases where this assumption is
violated, the use of smaller temporal granularity solves this issue.)
3	Related Works
Temporal Localization Under Label Misalignment The literature on temporal noise robustness
is limited despite the critical relevance of this issue. First, Yadati et al. (2018) propose solutions
combining noisy and expert labels; however, unlike our approach, these methods require a sizable
clean subset of annotations. Second, while Adams & Marlin (2017) achieve increased robustness
by augmenting simple classifiers with an explicit probabilistic model of the noise structures, the
effectiveness of the approach on more complex temporal models (e.g., LSTM) still needs to be
demonstrated. Finally, Lea et al. (2017) perform robust temporal action segmentation by introducing
an encoder-decoder architecture. However, the coarse temporal encoding comes at the expense of
finer-grained temporal information, which is essential for the precise localization of short events (e.g.,
drum hits). In this paper, rather than a new architecture, we propose a novel and flexible loss function
2
Under review as a conference paper at ICLR 2020
Figure 2: Inherent drawbacks of the classical trick of smoothing the labels only. Issue 2: ambiguous
predictions of event locations require the use of additional heuristics. Issue 3: close events cannot
be easily disentangled. Issue 4: the need to estimate the left-tail of label distributions compels the
model to detect events before their actual occurrence, which might lead to overfitting.
— agnostic to the underlying network — which allows the robust training of temporal localization
networks even in the presence of extensive label misalignment.
Classical Heuristic Our approach is closely linked to the more classical trick of label smoothing
or target smearing (e.g., applying a σ2-GauSSian filter Φσ2 to the labels) which has been considered to
increase robustness to temporal misalignment of annotations (Schluter & Bock, 2014; Hawthorne
et al., 2017). This slight modification of the input data converts the original point prediction problem
into a distribution prediction problem. Indeed, the smoothing of the labels transforms the point
labels into distributions. The algorithm is then trained to predict these distributions, which eventually
have to be transformed back to point predictions using hand-crafted peak picking heuristics (see
Figure 3 (left)). This methodology is also very common in 2D image keypoint detection applications
which deal with spatial uncertainty, e.g. human pose estimation (Tompson et al., 2014; 2015) or
facial landmark detection (Merget et al., 2018). However, despite its intuitive nature, this traditional
solution presents several inherent drawbacks (see Figure 2): (Issue 1) Even in a noise-free setting,
by transforming the impulse-like target into a distribution, the optimal model predictions (with
respect to the training loss) differs from the actual goal of the pipeline (i.e., precise localization
indicated by the original event label). (Issue 2) As the model learns by mimicking the smoothed
target throughout the learning phase, the predictions themselves will be spread out over several
time-steps. Hence, additional tailored heuristics, such as peak picking (Bock et al., 2013) or complex
thresholding, are required to achieve precise temporal localization. (Issue 3) Even advanced
peak picking approaches struggle to disentangle close events. For instance, a unique maximum
might emergence in the middle of two events, thus significantly disturbing the timeliness of the final
predictions. (Issue 4) Having the label mass dispersed temporally both before and after the event
occurrences is problematic not only for causal models (i.e., models that make predictions at time t
only with data up to time t - 1) but also for one-sided recurrent networks and fully convolutional
architectures with limited receptive fields. Indeed, all these models have to estimate the left tail of the
label distribution before even seeing the event occur. This requirement compels the model to find some
structure before the actual event occurrence, leading to poor generalization performance. Although
bidirectional networks do not suffer from it, this issue limits the range of possible architectures. The
presence of strong label misalignment further worsens these four issues as increased noise commonly
warrants increased smoothing, dispersing the label (and consequently prediction) mass even more.
Overall, experimental evidence (e.g. Section 5.1.1) shows that the accumulation of these issues
proves to be very detrimental to the noise robustness of these classical approaches.
In contrast, this work presents a novel paradigm for dealing with temporal label uncertainty. The main
idea consists in directly inferring point predictions rather than resorting to distributions or heatmaps
by fully integrating the modelling of the noise into the loss function. Such a direct approach allows
for an end-to-end learning of localization without the need for additional hand-crafted components.
In addition, the systematic and standalone loss function proposed in this regard (Section 4.2) not only
solves all the above-mentioned issues but also scales well to extensive label misalignment.
Weakly-Supervised Learning Some weakly-supervised models leverage weaker annotations to
infer more fine-grained concepts. In such frameworks, noisy labels are implicitly bypassed by the
use of higher-level labels — which are more invariant to perturbations. For instance, some works
achieve object detection (Fergus et al., 2003; Bilen & Vedaldi, 2016) or temporal localization (Kumar
3
Under review as a conference paper at ICLR 2020
Classical approach
OUrS (end-to-end)
/V∖r ι°ss ^√∖∕‰j I /V∖z: SoftLoc
smoothing [
Peak-picking
Labels
Predictions
smoothing [	↑ smoothing
I 'I ¼ 叫「I
Labels
Data
Predictions
Figure 3: Modelling novelty. By smoothing both the labels and predictions, the model directly
infers point predictions rather than distributions. Among other things, this modification allows for
end-to-end learning of localization and alleviates the need for peak-picking. (left) Classical approach
of smoothing the labels only. (right) Our novel end-to-end approach and its S oftLoc loss function.
& Raj, 2016; Wang et al., 2017) using only class-level annotations. However, finer-grained labels,
even noisy ones, often contain some additional information that is essential for optimal performance.
4	SOFTLOC MODEL
4.1	Soft Localization Learning Loss
The general principle of relaxing the localization learning is intuitive and potentially powerful if
carefully implemented. However, by smoothing the label only, classical approaches transform the
original point prediction problem into a distribution prediction problem which eventually causes
issues (see Section 3). Many of the drawbacks arising from the asymmetric nature of the one-sided
smoothing can however be alleviated by filtering not only the labels (i.e., 42 * Yi(∙)), but also the
predictions (i.e., 42 * Yi(∙)) with a unique softness parameter Si. The comparison of these two
smoothed processes yields a relaxed loss function for the soft learning of the location that deals on
its own with the temporal uncertainty of the labels. Indeed, in such a setting, the model is given
input sequences of point-like events and directly infers point predictions without having to resort to
distributions or heatmaps (see Figure 3 (right)); it is only the loss function that views these point
labels and predictions as smoothed processes. In discrete time settings, the loss can be written as
LSLL (θ) = X L(ΦS2 * yi,θ(•), ΦS2 * yi(∙)), with ΦS2 a Si2-Gaussian filter,	(2)
where L (∙, ∙) can be any measure of distance. The learning is characterized as soft since the loss is
not strictly constraining in terms of precision or mass concentration. Indeed, the mass of each event
can be both scattered over numerous time-steps and slightly shifted temporally without any abrupt
increase in loss. Thus, the model’s reliance on exact label locations is relaxed.
Measure L In noise-free settings, the average stepwise cross-entropy is a common choice of loss
function for state-of-the-art models (Lea et al., 2017; Wu et al., 2018; Hawthorne et al., 2019). While a
potentially unbounded penalization of false predictions might be ideal when training on clean datasets,
such behavior can be highly detrimental when labels are subject to temporal misalignment. Therefore,
for all experiments in Section 5, L is set to the (bounded) average local mean-squared error.
Properties Symmetrically smoothing both the labels and predictions solves several of the issues
highlighted in the previous section (see Figure 4). First, in a noise-free setting, the optimal predictions
with respect to LSLL are the original annotations themselves. (Solves 1). Second, since the predictions
are also smoothed over time, each trigger adds detection mass not only after, but also before the
prediction time. Therefore, the model is not required the estimate the left-tail of the label distribution
before the actual event occurrence (Solves 4). The prediction mass for a particular event is not
necessarily dispersed over time anymore. For instance, in noise-free settings, the point-like targets
themselves are the solution to the optimization problem. However, LSLL does not strictly constrain
the mass of each event to be contained in a single time-step (Partially Solves 2 & 3).
4
Under review as a conference paper at ICLR 2020
Figure 4: The different issues arising from only smoothing the labels are solved by our approach.
Solves 2: the predictions are unambiguous as the model infers point predictions that are converged
towards well-defined points in time. Solves 3: no disentanglement is required as the model di-
rectly infers point predictions instead of distributions. Solves 4: point predictions span symmetric
distributions through smoothing, thus solving the left-tail estimation issue.
4.2	SOFTLOC LOSS
The potential dispersion of the prediction mass and its direct consequences on localization perfor-
mance still need to be addressed. To that end, we propose to leverage the properties of the weakly-
supervised model defined in (Schroeter et al., 2019), which achieves precise temporal localization
using only occurrence counts for training. Aside from exhibiting strong localization performance, the
loss introduced in that work possesses an implicit mass convergence property, which concentrates the
scattered prediction mass toward well-defined single points in time:
LMC (θ) =-X log (X Y yi,θ(I) Y(I- yi,θCj))),	⑶
i	A∈F l∈A	j∈Ac
where F is the set of all subsets of {1, 2, ..., Ti} of size Pk yi(k).
Full S oftLoc Model Incorporating this mass convergence loss as a regularizer to our soft localiza-
tion learning loss LSLL allows the model to directly achieve precise impulse-like localization, without
weakening its noise robustness properties. Thus, this eliminates prediction ambiguity, as only a single
point prediction is outputted per event occurrence (Solves 2 & 3). Overall, when trained with the
S oftLoc loss,
LSOftLOC (θ) = (1 - ατ)LSll(θ) + ατLMC(θ),	(4)
the model simultaneously softly learns to mimic the localization annotation, while converging the
scatter mass tOward impulse-like predictiOns. In this equatiOn, ατ regulates the predOminance Of the
mass cOnvergence against the sOft learning (fOr training iteratiOn τ ). FrOm a practical standpOint,
starting with a mOderate ατ allOws an initial relaxed lOcalizatiOn learning, befOre perfOrming strOnger
mass cOnvergence (see SectiOn 5 fOr the specific settings used in this paper).
End-to-end Learning of Localization One Of the key factOrs Of the predOminance Of the deep
learning mOdels Over classical Ones relies On their ability tO sOlve prOblems in an end-tO-end fash-
iOn (COllObert et al., 2011; Krizhevsky et al., 2012), withOut the need tO resOrt tO partial OptimizatiOn
Or hand-crafted heuristics. In cOntrast tO mOre classical apprOach (see SectiOn 3), Our prOpOsed methOd
is an end-tO-end sOlutiOn tO the prOblem Of tempOral lOcalizatiOn in the presence Of misaligned labels
(see Issue 2). This sOlutiOn eliminates the need fOr hand-crafted cOmpOnents (e.g. peak picking) and
is expected tO better serve the task at hand.
Continuous Setting While all experiments in SectiOn 5 and mOst state-Of-the-art tempOral lOcal-
izatiOn mOdels perfOrm a discretizatiOn Of time, the lOss definitiOn can easily be adapted tO suit
cOntinuOus-time framewOrks.
4.3	Generalization of Past Works
Our versatile S OftLOc mOdel is a generalizatiOn Of several past wOrks. Indeed, depending On the
sOftness parameter SM , the mOdel encOmpasses a wide range Of training regimes frOm classical
fully-supervised tO cOunt-based weakly-supervised.
5
Under review as a conference paper at ICLR 2020
Softness → 0 By tending SM toward zero, the model becomes similar to a count-aware localization
RNN with soft localization learning loss. For instance, setting L (∙) = - log(1 -H) yields
JimCLSLL (θ) = -Elog (1 - ∣yi,θ(t) -yi(t)∣)
M→0
i,t
yi(t)∈{0,1-X yi(t)log (yi,θ(t)) + (1 - yi(t)) log (1 - yifi(t)),
i,t
(5)
which corresponds to the sum of all stepwise cross-entropies. By further setting ατ = 0 (i.e., dis-
carding any count-awareness), our loss function becomes identical to the ones found in numerous
temporal detection works (e.g., drum detection (Wu et al., 2018), piano onset detection (Hawthorne
et al., 2017), and video action segmentation (Lea et al., 2017)).
Softness → ∞ Setting SM → ∞ causes the gradient of LSLL (θ) to vanish, discarding any prior
information of localization, thus making the training weakly-supervised (Schroeter et al., 2019):
Iim LSoftLoc (θ) = ατ ∙ LMc(θ) <x LMc(θ).	⑹
SM →∞
4.4	Dealing with Uncertainties
The introduced softness parameter can be leveraged to deal with different kinds of uncertainties. First,
in contrast to the traditional approach of aggregating the annotations of multiple individuals (thus
trading off dataset richness for noise reduction), our model can be trained on all conflicting individual
sequences, since it can cope with noisy annotations. Second, an annotator specific softness Sa2 can
further be implemented to model their respective reliability. Finally, an extract specific softness can
be incorporated to capture the noise or annotation complexity of certain more challenging sequences.
Experiments conducted in the section below show that the performance is robust to variations in
the softness parameter. Indeed, this hyperparameter only acts as a coarse indicator of temporal
uncertainty and thus does not need to strictly match the underlying noise distribution.
5	Experiments
In this section, we demonstrate the effectiveness and flexibility of our approach in a broad range of
challenging experiments (music event detection, times series detection, video action segmentation). ,
Experiment and implementation details can be found on the paper’s website1.
5.1	Music Experiments
5.1.1	Piano Onset Experiment
Piano transcription and more specifically piano onset detection is a difficult problem as it requires
precise and simultaneous detection of hits from 88 different polyphonic channels.
Dataset This experiment is based on the MAPS database (Emiya et al., 2010). The dataset creation
protocol strictly follows the one from Hawthorne et al. (2017). (Only onsets are considered for the
comparison.) To evaluate the robustness, the training labels are artificially perturbed according to a
normal distribution ∈m 〜N(0, σ2), while the test labels are kept intact for unbiased evaluation.
Benchmarks Three different benchmarks are considered. First, the state-of-the-art model (on clean
data) proposed by Hawthorne et al. (2017) is highly representative of models aiming for optimal
performance with little regard for annotation noise (Hawthorne). Second, a smoothed version of
the first benchmark with extended onset length (i.e., over 96ms) illustrates the common practice
used to achieve robustness (Hawthorne (smoothed)). Finally, as the first benchmark performs local
classification using standard cross-entropy, the soft bootstrapping loss proposed by Reed et al. (2014)
is leveraged instead for increased robustness (Bootstrap (soft)).
1Anonymous link: https://github.com/SoftLocICLR/submission
6
Under review as a conference paper at ICLR 2020
Architecture, Training and Evaluation Our network is comprised of six convolutional layers
(representation learning) followed by a 128-unit LSTM (temporal dependencies learning) and two
fully-connected layers (prediction mapping). The network is trained using mel-spectrograms (Stevens
et al., 1937) and their first derivatives stacked together as model input, while data augmentation in the
form of sample rate variations is applied for increased robustness and performance. The loss (Equa-
tion 4) with softness SM = 100ms is optimized using the Adam algorithm (Kingma & Ba, 2015). The
models are evaluated on the noise-free test set using F1-scores computed with the standard mir_eval
library (Raffel et al.) and a 50ms tolerance (Hawthorne et al., 2017). (0丁 = max(min(τ-005,.9),.2).)
Results As depicted in Figure 5, our pro-
posed SoftLoc approach displays strong ro-
bustness against label misalignment; in con-
trast to all benchmarks, the performance ap-
pears almost invariant to the noise level. (See
Appendix A.1 for discussion on the model’s
performance for σ > 200ms.) At σ = 150ms,
only 26% of training labels lie within the
50ms tolerance. In this context, the score
achieved by our SoftLoc model (i.e.,〜75%)
is unattainable for classical approaches, which
do not take label uncertainty into account
and attempt to strictly fit the noisy annota-
tions. While standard tricks, such as label
smoothing, slightly improve noise robustness
(e.g., Hawthorne (smoothed)), their effective-
ness is limited in contrast to our proposed ap-
proach. Finally, the parameters used through-
out this experiment are fixed. However, as our
loss is a strict generalization of the standard
cross-entropy loss used by Hawthorne et al.
(2017), the small performance gap for small
noise levels can be reduced by setting ατ = 1,
SM→ 0ms and L (∙) = - log(1 - ∣∙∣).
Ours (SoftLoc)
Hawthorne (smoothed)
Bootslrap (soft)
Noise σ [ms]
Figure 5: F1 piano onset detection performance of
our approach (softness SM= 100ms) and the bench-
mark models as a function of label noise levels.
Ablation Study To assess the usefulness of the different components of LSoftLoc, we repeat the
above experiments keeping only individual parts of the loss function. Table 1 reveals that LSLL is
the main driver of performance in noise-free settings, while LMC ensures stability under increased
label misalignment. (A simple threshold-based peak-picking algorithm was implemented to infer
localization from the dispersed mass produced by LSLL .) Overall, while each loss individually
produces reasonable predictions, only the combined LSoftLoc yields both competitive scores in
noise-free settings and strong robustness to temporal misalignment.
5.1.2	Drum Detection Experiment
The softness SM is a defining model hyperparameter. In this section, 210 independent runs for the same
drum detection experiment are conducted with varying noise and softness levels in order to highlight
the correlation between this key parameter, label noise and the final localization performance.
Dataset The experiment is based on the D-DTD Eval Random drum detection task (IDMT-SMT-
Drums dataset (Dittmar & Gartner, 2014)) performed by WU et al. (2018). The goal is the correct
Table 1: Ablation Study. Piano onset detection performance of our model trained with loss functions
LSoftLoc (SM= 100ms), LSLL and LMC respectively in various noise level settings.
Loss	σ = 0ms	50ms	100ms	150ms	200ms
LSLL (ατ = 0)	76.06	76.00	75.10	66.88	46.91
LMC (ατ = 1)	71.59	73.04	68.69	70.33	67.26
LSOFTLOC	—76^88 -	一 7^34 ~	~5566~	一~ι48 —	~7688
7
Under review as a conference paper at ICLR 2020
Figure 6: Drum detection performance with respect to model softness and label noise. F1-scores are
Gaussian Nadaraya-Watson estimates based on 210 runs (white dots) sampled uniformly at random.
temporal localization of three different classes of drum hits — hi-hats (HH), kick drums (KD), and
snare drums (SD) — within a 50ms tolerance window. Normally distributed errors ∈m 〜N(0, σ2)
are artificially introduced on all training and validation labels, while the test labels are kept intact for
unbiased inference. The noise level σ for each run is uniformly sampled from the range [0ms, 100ms].
Architecture, Training and Evaluation The network is similar to the one in Section 5.1.1, except
for the number of filters and nodes. The model softness SM for each run is uniformly sampled from
[0ms, 150ms]. Training and evaluation are carried out in the same way as in the piano experiment in
Section 5.1.1. (Learning rate: 10-4, batch size: 32, iterations: 1.5 × 105, sample length: 1.5s).
Results The results of the 210 runs are displayed in Figure 6. A Gaussian Nadaraya-Watson kernel
regression (Nadaraya, 1964; Watson, 1964) is used to interpolate the F1-score, offering a detailed
view of the model’s response to varying label noise levels. This figure not only confirms the model’s
high robustness to label misalignments, but also reveals that these results are very robust to changes in
the softness level. Indeed, a wide range of softnesses yield optimal performance, as long as sM ≥ σ.
Obviously, extreme softness levels (e.g. SM2 → ∞) would however induce a partial or even total loss of
the information conveyed by the localization prior, resulting in a decrease in performance (see Table
2). Robustness considerations aside, our SoftLoc model displays an outstanding overall performance
with F1 -scores over 95% across all noise levels; the model — even when trained on extremely noisy
labels (e.g., σ = 100ms) — outperforms several standard benchmarks Wu et al. (2018) which were
trained on noise-free training samples (σ = 0ms).
Noise-free Comparison In clean settings (i.e., σ = 0ms) , the benchmark models have a clear
advantage as they correctly assume noise-free labels. Despite this, our SoftLoc model achieves state-
of-the-art performance on three different metrics (KD, HH, precision) demonstrating that robustness
does not come at the expense of raw localization performance (see Table 2).
5.2	Time Series Detection
The timely detection of events in healthcare time series is a crucial challenge to improve medical
decision making. The task tackled in this section consists in the precise temporal detection of smoking
episodes using wearable sensors features based on the puffMarker dataset (Saleheen et al., 2015).
Once again, in order to conduct the robustness analysis, the original annotations are artificially
misaligned. However, as each time-step in this dataset represents a full respiration cycle, the
noise distributions must be applied in a discrete fashion: namely, rounded normal distribution (i.e.,
Ei 〜[N(0, σ2)]) or binary constant length shifting of labels (δ steps either to the left or the right
with equal probability), denoted B(-δ, δ). This task is particularly challenging as detections have to
be perfectly aligned with the ground-truth to be considered correct.
Model and Benchmark As the focus is set on robustness rather than raw performance, the model
architecture is kept extremely simple: a 14-node fully connected layer followed by a 14-unit LSTM
8
Under review as a conference paper at ICLR 2020
Table 2: Noise-free Drum Detection. Comparison of our S oftLoc model (SM= 100ms) and state-of-
the-art models evaluated in Wu et al. (2018) on the clean D-DTD Eval Random task (σ = 0ms). The
F1 -scores per instrument (KD/SD/HH), the average precision, recall, and overall F1 are displayed.
Method	KD	SD	HH	Pre	Rec	F1
RNN	97.2	92.9	97.3	；95.7	96.9	9 95.8
tanhB	95.4	93.1	97.3	I 93.9	97.1	I 95.3
ReLUts	86.6	93.9	97.7	1 92.7	95.0	1 92.7
lstmpB	98.4	96.7	97.4	；97.7	97.6	；97.5
GRUTS	91.4	93.2	96.2	I 91.8	97.2	I 93.6
sM → ∞	96.0	90.4	97.1	；95.1	93.9	；94.5
SM = 100ms	98.6	95.7	97.8	I 98.3	97.2	I 97.4
and a final fully connected layer with softmax activation. Both the standard cross-entropy (CE)
and our LSoftLoc loss function are evaluated. The LR-M model proposed by Adams & Marlin
(2017), which was developed to achieve strong robustness to temporal misalignment of labels on this
particular dataset, is also considered as benchmark.
Results The results, produced using ten 6-fold (leave-one-patient-out) cross-validation. are sum-
marized in Table 3. Not only does training with the proposed LSoftLoc loss function yield a strong
improvement in robustness when compared to the standard cross-entropy, but our simple recurrent
model also significantly outperforms the robust LR-M model on all metrics. In addition, our approach
displays low standard deviations, which underlines the consistency and robustness of the learning.
These observations hold for both noise distributions (N and B); hence, the normal smoothing filters
do not require the underlying noise to be normally distributed in order for the model to be effective.
Further testing with skew normal distribution of noise confirm these results even in non-symmetric
settings.
5.3	Video Action Segmentation
Video action segmentation — a dense classification problem where each time-step has to be mapped
to one action class — differs substantially from music event localization or time series detection
problems, where scattered events from multiple classes have to be precisely localized. Nonetheless,
the properties of the SoftLoc loss can still be leveraged on such a task; in this context, while the
role of LSLL is unchanged, LMC acts as a count-based regularizer, rather than a means for mass
convergence.
Experiments Several video segmentation experiments from Lea et al. (2017) are replicated using
either the standard cross-entropy (original loss), LSLL or LSoftLoc as training loss for the ED-
TCN model. As the ED-TCN model already exhibits strong robustness properties against label
misalignment Lea et al. (2017), these experiments will allow to measure the additional marginal gain
in performance and robustness when replacing the standard cross-entropy with our the proposed
LSoftLoc loss function. To assess robustness, each label sequence in the training set is either delayed
or advanced by a fixed constant δ. (SM = 7s).
Table 3: Smoking Puff Detection. Comparison of LR-M (Adams & Marlin, 2017) and the deep model
trained with CE or LSoftLoc with respect to misalignment distributions bN (0, σ2)e and B(-δ, δ).
Reported metrics are mean and standard deviation of ten 6-fold cross-validated F1-scores.
		σ,δ = 0	1	2	3	4
N	LR-M	93.0 (3.2)	80.6	(8.6)	65.9	(17.4)	64.0	(15.6)	55.0	(19.7) CE	92.6 (2.9)	55.3	(16.2)	36.0	(15.6)	28.9	(17.0)	25.8	(16.2) LSOFTLOC	93.1 (2.5)	90.6	(3.4)	87.8	(4.1)	83.6	(5.2)	79.0	(6.9)
B	LR-M	—	65.5 (14.5)	54.9	(20.4)	44.1	(19.7)	51.8	(19.8) CE	—	41.7 (15.3)	28.3	(14.5)	26.6	(15.3)	22.8	(15.1) LSOFTLOC	—	90.8 (3.3)	87.0	(4.7)	81.7	(7.2)	72.4	(10.1)
9
Under review as a conference paper at ICLR 2020
Table 4: Video Action Segmentation. Comparison of various training losses (CE, LSLL and LSoftLoc)
with respect to different label misalignment levels for the ED-TCN model on 50 Salads (mid). Metrics
are mean and standard deviation F1@10 (Lea et al., 2017) of ten 5-fold cross-validations.
Loss	δ = 0s	5s	10s	15s	20s
CE	66.7 (1.6)	59.7 (1.2)	43.4 (0.9)	33.6 (1.1)	26.7 (0.8)
Lsll	66.7 (1.0)	60.6 (0.9)	47.5 (1.2)	36.1 (0.8)	28.0 (1.2)
LSOFTLOC	67.2 (0.8)	61.5 (1.3)	48.0(1.0)	38.0 (1.9)	29.5 (1.1)
Results As summarized in Table 4 and Table 5 (in Appendix B.2), replacing the standard cross-
entropy loss with LSoftLoc does not only significantly increase the robustness of the ED-TCN model
— which was already shown to be robust to label misalignment (Lea et al., 2017) — but also achieves
competitive performance in noise-free settings. Further experiments with different softness parameters
(see Figure 10 in Appendix B.1) reveal that increasing the model softness SM as the underlying noise
levels increase produces optimal performance. For instance, in noisy settings, greater performance
can be achieved (up to 25% overperformance) by simply choosing a large enough softness. Overall,
the SoftLoc loss function displays strong results on a very different task (i.e., temporal segmentation
as opposed to temporal localization), highlighting once again its versatility of application.
6	Conclusion
In this work, we have shown how relaxing annotation requirements (i.e., weakening the model’s
reliance on the exact location of events) not only has the practical benefit of alleviating annotation
efforts but, more importantly, leads to a model that is robust to temporal noise without compromising
performance on clean training data. This contrasts with traditional approaches which attempt to
strictly mimic the annotations, leading to poor predictions when training with noisy labels. We have
demonstrated these claims on a number of classical challenging tasks, in which our SoftLoc loss
exhibits state-of-the-art performance.
The proposed loss function is agnostic to the underlying network and hence can be used as a loss
replacement in almost any recurrent architecture. The versatility of the model can find applications in
a wide array of tasks, even beyond temporal localization.
References
Sami Abu-El-Haija, Nisarg Kothari, Joonseok Lee, Paul Natsev, George Toderici, Balakrishnan
Varadarajan, and Sudheendra Vijayanarasimhan. YouTube-8m: A large-scale video classification
benchmark. arXiv preprint arXiv:1609.08675, 2016.
Roy Adams and Ben Marlin. Learning Time Series Detection Models from Temporally Imprecise
Labels. In Proceedings of the International Conference on Artificial Intelligence and Statistics,
volume 54, pp. 157-165. PMLR, 2017.
Michele Banko and Eric Brill. Scaling to very very large corpora for natural language disambiguation.
In Proceedings of the Annual Meeting of the Association for Computational Linguistics, pp. 26-33.
Association for Computational Linguistics, 2001.
Hakan Bilen and Andrea Vedaldi. Weakly supervised deep detection networks. In Proceedings of
Conference on Computer Vision and Pattern Recognition (CVPR), pp. 2846-2854. IEEE, 2016.
Sebastian Bock, Jan Schluter, and Gerhard Widmer. Enhanced peak picking for onset detection with
recurrent neural networks. In Proceedings of the 6th International Workshop on Machine Learning
and Music (MML), pp. 15-18, 2013.
Ronan Collobert, Jason Weston, Leon Bottou, Michael Karlen, Koray Kavukcuoglu, and Pavel Kuksa.
Natural language processing (almost) from scratch. Journal of Machine Learning Research, 12
(Aug):2493-2537, 2011.
10
Under review as a conference paper at ICLR 2020
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. ImageNet: A large-scale
hierarchical image database. In Proceedings of Conference on Computer Vision and Pattern
Recognition (CVPR),pp. 248-255. IEEE, 2009.
Christian Dittmar and Daniel Gartner. Real-time transcription and separation of drum recordings
based on NMF decomposition. In Proceedings of International Conference on Digital Audio
Effects (DAFx), 2014.
Valentin Emiya, Roland Badeau, and Bertrand David. Multipitch estimation of piano sounds using
a new probabilistic spectral smoothness principle. IEEE Transactions on Audio, Speech, and
Language Processing, 18(6):1643-1654, 2010.
Robert Fergus, Pietro Perona, and Andrew Zisserman. Object class recognition by unsupervised scale-
invariant learning. In Proceedings of Conference on Computer Vision and Pattern Recognition
(CVPR), pp. 264-271. IEEE, 2003.
Alon Halevy, Peter Norvig, and Fernando Pereira. The unreasonable effectiveness of data. IEEE
Intelligent Systems, (2):8-12, 2009.
Curtis Hawthorne, Erich Elsen, Jialin Song, Adam Roberts, Ian Simon, Colin Raffel, Jesse Engel,
Sageev Oore, and Douglas Eck. Onsets and frames: Dual-objective piano transcription. arXiv
preprint arXiv:1710.11153, 2017.
Curtis Hawthorne, Andrew Stasyuk, Adam Roberts, Ian Simon, Anna Huang, Sander Dieleman, Erich
Elsen, Jesse Engel, and Douglas Eck. Enabling factorized piano music modeling and generation
with the maestro dataset. In Proceedings of International Conference on Learning Representations
(ICLR), 2019.
Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In Proceedings of
International Conference on Learning Representations (ICLR), 2015.
Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classification with deep con-
volutional neural networks. In Advances in Neural Information Processing Systems (NIPS), pp.
1097-1105, 2012.
Anurag Kumar and Bhiksha Raj. Audio event detection using weakly labeled data. In Proceedings of
International Conference on Multimedia, pp. 1038-1047. ACM, 2016.
Colin Lea, Michael D Flynn, Rene Vidal, Austin Reiter, and Gregory D Hager. Temporal convolutional
networks for action segmentation and detection. In Proceedings of Conference on Computer Vision
and Pattern Recognition (CVPR), pp. 156-165. IEEE, 2017.
Yann LeCun, Yoshua Bengio, and Geoffrey Hinton. Deep learning. Nature, 521(7553):436, 2015.
Daniel Merget, Matthias Rock, and Gerhard Rigoll. Robust facial landmark detection via a fully-
convolutional local-global context network. In Proceedings of Conference on Computer Vision
and Pattern Recognition (CVPR), pp. 781-790, 2018.
Elizbar A Nadaraya. On estimating regression. Theory of Probability & Its Applications, 9(1):
141-142, 1964.
Colin Raffel, Brian McFee, Eric J Humphrey, Justin Salamon, Oriol Nieto, Dawen Liang, and
Daniel PW Ellis. mir_eval: A transparent implementation of common MIR metrics.
Scott Reed, Honglak Lee, Dragomir Anguelov, Christian Szegedy, Dumitru Erhan, and Andrew
Rabinovich. Training deep neural networks on noisy labels with bootstrapping. arXiv preprint
arXiv:1412.6596, 2014.
Nazir Saleheen, Amin Ahsan Ali, Syed Monowar Hossain, Hillol Sarker, Soujanya Chatterjee,
Benjamin Marlin, Emre Ertin, Mustafa Al’Absi, and Santosh Kumar. puffmarker: a multi-sensor
approach for pinpointing the timing of first lapse in smoking cessation. In Proceedings of the
2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing, pp. 999-1010.
ACM, 2015.
11
Under review as a conference paper at ICLR 2020
Jan Schluter and Sebastian Bock. Improved musical onset detection with convolutional neural
networks. In Proceedings of International Conference on Acoustics, Speech and Signal Processing
(ICASSP),pp. 6979-6983. IEEE, 2014.
Jurgen Schmidhuber. Deep learning in neural networks: An overview. Neural Networks, 61:85-117,
2015.
Julien Schroeter, Kirill Sidorov, and David Marshall. Weakly-supervised temporal localization via
occurrence count learning. In Proceedings of International Conference on Machine Learning
(ICML), pp. 5649-5659, 2019.
Stanley Smith Stevens, John Volkmann, and Edwin B Newman. A scale for the measurement of the
psychological magnitude pitch. The Journal of the Acoustical Society of America, 8(3):185-190,
1937.
Jonathan Tompson, Ross Goroshin, Arjun Jain, Yann LeCun, and Christoph Bregler. Efficient object
localization using convolutional networks. In Proceedings of Conference on Computer Vision and
Pattern Recognition (CVPR), pp. 648-656, 2015.
Jonathan J Tompson, Arjun Jain, Yann LeCun, and Christoph Bregler. Joint training ofa convolutional
network and a graphical model for human pose estimation. In Advances in Neural Information
Processing Systems (NIPS), pp. 1799-1807, 2014.
Limin Wang, Yuanjun Xiong, Dahua Lin, and Luc Van Gool. Untrimmednets for weakly supervised
action recognition and detection. In Proceedings of Conference on Computer Vision and Pattern
Recognition (CVPR), pp. 4325-4334. IEEE, 2017.
Geoffrey S Watson. Smooth regression analysis. Sankhya: The Indian Journal ofStatistics, Series A,
pp. 359-372, 1964.
Chih-Wei Wu, Christian Dittmar, Carl Southall, Richard Vogl, Gerhard Widmer, Jason Hockman,
Meinard Muller, and Alexander Lerch. A review of automatic drum transcription. IEEE/ACM
Transactions on Audio, Speech and Language Processing (TASLP), 26(9):1457-1483, 2018.
Karthik Yadati, Martha Larson, Cynthia CS Liem, and Alan Hanjalic. Detecting socially significant
music events using temporally noisy labels. IEEE Transactions on Multimedia, 20(9):2526-2540,
2018.
Chiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht, and Oriol Vinyals. Understanding
deep learning requires rethinking generalization. In Proceedings of International Conference on
Learning Representations (ICLR), 2017.
12
Under review as a conference paper at ICLR 2020
A Piano Onset Detection
A.1 Extreme Noise Settings
Figure 1 (in the main text) depicts the strong invari-
ance of our SoftLoc model to label misalignment on
a broad array of noise levels (i.e., up to σ = 200ms).
In this section, we evaluate the model’s performance
on an even wider range in order to fully assess its
behavior in extreme settings. To that end additional
piano onset detection experiments, with noise levels
up to σ = 1000ms, were conducted following the
protocol described in Section 5.1. The results are
displayed in Figure 7.
Overall, this figure confirms the remarkable robust-
ness of our SoftLoc model to label misalignment.
While the absolute performance unsurprisingly de-
creases as the training data becomes less accurate,
the detection capability of the model in noisy settings
outshines any classical approach (see Figure 1 in the
main text). Finally, these results could further be
improved by increasing the model softness SM (see
Section 5.2).
Figure 7: F1 piano onset detection perfor-
mance of the SoftLoc model (SM = 100ms) as
a function of label misalignment.
(a) Noise-free training data (σ = 0ms)
(b) Noisy training data (σ = 50ms)
(c) Very noisy training data (σ = 100ms)
(d) Extremely noisy training data (σ = 200ms)
Figure 8: Out-of-sample predictions of our SoftLoc model trained on data subject to various
levels of noise, ranging from (a) the noise-free case σ = 0ms to (d) the extremely noisy
σ = 200ms. (Schubert-Piano Sonata inA minor, D 784, Opus 143, 3. Mov)
13
Under review as a conference paper at ICLR 2020
A.2 Further Illustrations
Timeliness of SoftLoc predictions Figure 8 illustrates how consistently precise and well-centered
(i.e., neither too late nor early) the predictions are regardless of the noise setting. Indeed, there is
almost no difference in prediction centering when comparing the results for σ = 0ms or σ = 200ms.
Noisy Labels and Ground-Truth Discrepancy To further illustrate the complexity of the localiza-
tion task when annotations are subject to misalignment, we consider the training labels as predictions
and then compare them to the clean ground-truth. Figure 9 displays an example of the quality of
the training labels. Obviously, in the noise-free setting (i.e., σ = 0ms), the localization is spotless
as the training labels and the ground-truths are identical. However, as the noise level increases,
the proportion of labels that stay within the 50ms tolerance window decreases significantly. More
precisely, the performance (i.e., F1-score) of the labels themselves is 68.2%, 39.8% and 23.7% for σ
equal to 50ms, 100ms and 200ms respectively.
(a) Noise-free labels (σ = 0ms)
(b) Noisy labels (σ = 50ms)
(c) Very noisy labels (σ = 100ms)
(d) Extremely noisy labels (σ = 200ms)
Figure 9: In-sample performance of the noisy training labels themselves (as predictions)
When compared to the clean ground-truth. (Liszt - Hungarian Rhapsody No. 10)
14
Under review as a conference paper at ICLR 2020
B Video Action S egmentation
B.1	Impact of the Softness Parameter
As depicted in Figure 10, training with the S oftLoc loss function instead of the standard cross-entropy
yields improved performance (up to 25%) in all noise settings almost regardless of the softness
SM . The only exception occurs when selecting a softness level that is too wide while training with
noise-free (δ = 0) labels. As also observed in Section 5.1.2, the model achieves optimal performance
when the softness level SM is slightly larger than noise level δ. However, although the efficiency of
the approach is bound to decrease when the disparity between selected softness and noise level is
becoming too large, a performance close to the optimal one can be achieve with a wide range of
softnesses SM.
-%】əɔuBuUOj-Bdφ>aBφB
Figure 10: Video Action Segmentation. Relative performance of the ED-TCN model trained with
LSoftLoc — relative to CE — with respect to the softness level SM for various noise levels δ.
15
Under review as a conference paper at ICLR 2020
B.2	Additional Results
Table 5: Video Action Segmentation. Performance comparison of different training losses (cross-
entropy, LSLL and LSoftLoc) for the ED-TCN model on various datasets and measures. Metrics are
mean and standard deviation F1@10 or F1@50 (Lea et al., 2017) of ten 5-fold cross-validation.
50 Salads (mid)
Loss	δ = 0s	5s	10s	15s	20s
O CE	51.8 (0.7)	38.5 (1.1)	19.7 (0.7)	10.7 (0.8)	6.9 (1.0)
LSLL	50.7 (0.5)	38.8 (1.4)	22.3 (1.1)	12.3 (0.8)	7.8 (0.9)
LSOFTLOC	49.8 (0.9)	39.5 (1.2)	23.4 (1.4)	13.7 (0.9)	7.5 (0.8)
50 Salads (eval)
Loss	δ = 0s	5s	10s	15s	20s
o CE	74.9 (0.8)	72.7 (0.9)	59.6 (1.2)	48.1 (1.0)	41.8 (0.6)
LSLL	75.4 (0.6)	73.0 (0.9)	61.9 (0.8)	49.2 (0.9)	41.8 (1.2)
LSOFTLOC	75.5 (1.2)	73.7 (1.3)	62.7 (1.5)	50.4 (0.8)	43.8 (1.7)
g CE	63.2 (0.7)	52.7 (1.5)	34.4 (0.8)	21.9 (1.4)	15.3 (1.0)
LSLL	63.4 (1.0)	55.3 (1.1)	35.1 (1.0)	22.8 (1.2)	15.7 (1.2)
LSOFTLOC	63.5 (1.1)	55.7 (0.9)	36.8 (1.1)	23.6 (0.9)	16.2 (1.3)
GTEA DATASET
Loss	δ = 0s	5s	10s	15s	20s
o CE	74.7 (1.2)	64.3 (0.9)	37.1 (1.9)	27.6 (1.4)	23.8 (1.6)
LSLL	74.1 (1.3)	64.3 (2.4)	41.3 (2.0)	28.5 (1.4)	22.8 (1.7)
LSOFTLOC	73.4 (1.2)	65.2 (1.2)	43.8 (2.7)	28.5 (1.6)	22.5 (0.8)
g CE	59.3 (1.8)	33.0 (1.9)	12.0 (1.0)	8.1 (0.9)	7.8 (1.2)
LSLL	54.5 (1.5)	33.7 (2.7)	14.3 (1.0)	8.0 (0.8)	5.9 (1.0)
LSOFTLOC	52.0 (1.2)	34.8 (1.2)	15.4 (1.3)	8.4 (1.4)	5.1 (0.5)
16