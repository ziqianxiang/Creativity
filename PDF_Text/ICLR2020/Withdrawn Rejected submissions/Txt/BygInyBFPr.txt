Under review as a conference paper at ICLR 2020
Exploring the Pareto-Optimality between
Quality and Diversity in Text Generation
Anonymous authors
Paper under double-blind review
Ab stract
Quality and diversity are two essential aspects for performance evaluation of text
generation models. Quality indicates how likely the generated samples are to be
real samples, and diversity indicates how much differences there are between gen-
erated samples. Though quality and diversity metrics have been widely used for
evaluation, it is still not clear what the relationship is between them. In this pa-
per, we give theoretical analysis of a multi-objective programming problem where
quality and diversity are both expected to be maximized. We prove that there ex-
ists a family of Pareto-optimal solutions, giving an explanation of the widely ob-
served tradeoff behavior between quality and diversity in practice. We also give
the structure of such solutions, and show that a linear combination of quality and
diversity is sufficient to measure the divergence between the generated distribu-
tion and the real distribution. Further, we derive an efficient algorithm to reach
the Pareto-optimal solutions in practice, enabling a controllable quality-diversity
tradeoff.
1 Introduction
Text generation is an essential task for many NLP applications, such as machine writing (Zhang
et al., 2017), machine translation (Bahdanau et al., 2014), image captioning (Rennie et al., 2017)
and dialogue system (Li et al., 2017). Recently, lots of neural generation models have been proposed
and gained increasing attentions (Yu et al., 2017; Fedus et al., 2018; Chen et al., 2018). However,
it is still an open problem which metrics are suitable to evaluate the performance of text generation
models. Among the metrics used in practice, generation quality and diversity are two most widely
considered aspects. High generation quality requires the model to generate realistic samples, i.e.
generated samples are free of grammatical or logical errors. While high generation diversity requires
the model to generate diverse samples, i.e. generated samples are less likely to be duplicate and
contain diverse unique patterns.
This work is motivated by three questions about quality and diversity:
Q1: What is the relationship between quality and diversity? Besides being evaluation metrics,
high generation quality and diversity have also been critical requirements in many applica-
tions (Li et al., 2015; Xu et al., 2018; Zhang et al., 2018b). However, many researches find
that quality and diversity show a tradeoff behavior among well-trained models (Lu et al.,
2018; Gao et al., 2019; Hashimoto et al., 2019). Though in accordance with intuition, such
observations stay empirical and lack of theoretical support.
Q2: Is there any gap between quality-diversity evaluation and the divergence objective? The
original objective of training a text generation model is to approximate the probability
distribution of real text data, which is equivalent to minimizing a divergence between model
distribution and the real distribution (Mikolov et al., 2010). Since divergence would be
intractable if the text probabilities are not modeled explicitly, some researchers opt to use
quality and diversity metrics instead as a remedy (Fedus et al., 2018; Chen et al., 2018).
However, it is not clear whether it is sufficient to approximate divergence by integration of
quality and diversity.
Q3: How to achieve optimal solutions in practice when quality and diversity are both required
to be maximized? Quality or diversity may be focused more than another in some applica-
1
Under review as a conference paper at ICLR 2020
tions. Though researchers have proposed different methods to tackle different application
scenarios (Zhang et al., 2018a; Li et al., 2015; Zhang et al., 2018b), it is still an open
problem how to maximize one aspect while keeping another above some threshold, i.e.
achieving a Pareto-optimal solution.
In this paper, we try to answer the above three question under the unconditional text generation
setting. We first give a general definition of quality and diversity, and then study a Multi-Objective
Programming(MOP) problem which maximizes quality and diversity simultaneously. Answers are
given by performing theoretical analysis over this MOP problem:
A1: Quality and diversity truly act as a tradeoff. We prove there exists a family of Pareto-
optimal solutions for the MOP problem, which constitutes the Pareto-frontier. For each
Pareto-optimal solution Q, there exists another Pareto-optimal solution Q0, such that either
quality or diversity of Q0 is higher than Q. This indicates that a quality-diversity tradeoff
exists among all these optimal solutions, and non-optimal solutions have the potential to be
improved over both metrics.
A2: Quality and diversity can be combined to be a divergence. We prove that a linear com-
bination of some paired quality and diversity constitutes a divergence metric between the
generated distribution and the real distribution, including some widely recognized quality
and diversity metrics as special cases.
A3: Optimal solutions over both quality and diversity can be achieved by our proposed QDTC
method. We prove that the optimal solutions of the MOP problem can be obtained by
optimizing a designed objective function, and propose a QDTC algorithm which can be
implemented efficiently like the widely used maximum likelihood estimation method. Ex-
periments show that this algorithm achieves controllable quality and diversity tradeoff on
both synthetic data and real MSCOCO dataset.
2	Related Work
To evaluate the performance of text generation models, many evaluation metrics are designed for
different purposes. Early neural text generation models use Perplexity(PPL) to show how much
a language model fit the training data (Mikolov et al., 2010), and this metric is still adopted in
recent works (Zhang et al., 2018a; Fedus et al., 2018). PPL is correspondent to the Kullback-
Leibler(KL) divergence, thus is a metric showing the difference between model distribution and the
real distribution. However, Chen et al. (1998) show that PPL does not seem to correlate well with
the task performance in real applications. Moreover, PPL cannot be calculated if text probabilities
are not explicitly given. Therefore, the quality and diversity of generated text are further considered
as complementary metrics.
For quality metrics, the evaluation is closely related to the ground truth distribution. Yu et al. (2017)
propose to use Negative Log-Likelihood where the real distribution is known in advance, which
measures the average log-probability of generated samples over the real distribution. If the real
distribution is not explicitly given, BLEU (Papineni et al., 2002) and ROUGE (Lin & Och, 2004)
are usually applied, which measure the n-gram overlap between generated samples and a set of
reference ground truth samples. For diversity metrics, the evaluation is performed within the model
itself. Li et al. (2015) proposed Distinct-n as diversity metric, which calculates the ratio of unique
n-grams in generated samples. Zhu et al. (2018) proposed another metric called Self-BLEU, which
is similar to BLEU score but use generated samples as reference set. In this work, we assume the real
distribution P and the model distribution Q are explicitly given. To perform theoretical analysis, we
propose a general form of quality and diversity, which is in accordance with above proposed metrics.
Although the tradeoff behavior between quality and diversity has not been well studied theoretically,
there have been some works trying to control such tradeoff. The temperature-based method is the
most widely used one (Hashimoto et al., 2019; Fan et al., 2018; Lau et al., 2017). By dividing the
probability vector by a temperature factor t before softmax operation, one can achieve higher quality
with smaller t and higher diversity with larger t during the decoding stage. Another method to
control the tradeoff during training is proposed by Li et al. (2019). With different hyper-parameters
in the objective function, the trained model can get higher quality at the expense of lower diversity.
2
Under review as a conference paper at ICLR 2020
Whether these methods can achieve optimal solutions under quality and diversity is still not clear,
and the conclusions will be discussed in this paper.
3	Definition of Quality and Diversity
Currently there is no unified definition for quality and diversity in text generation, which poses great
challenges for further theoretical studies. In fact, it is not easy to define a general form of quality and
diversity due to various understandings of these two aspects. In this paper, we try to give a general
form of quality and diversity in a mathematical view, though it may not be comprehensive enough
to cover all possible understandings.
3.1	A general form of quality and diversity
Text data is usually discrete, so we make the following notations. Assume the vocabulary size is |V |,
and the maximum length is L, then the distribution of text data can be described by a categorical dis-
tribution with size N = |V |L . We denote the real distribution and the generated model distribution
as P(x) = (P1,P2,…，Pn) and Q(X) = (Q1,Q2,…，QN), respectively.
In general, the Quality of a text generation model measures how likely the generated text are to be
realistic text in human’s view. Since the value of real probability P(x) can be viewed as reflecting
the realistic degree ofa text x, the expectation of some function over P(x) could be used to quantify
quality. For example, in Yu et al. (2017) and Nie et al. (2018), the Log-Likelihood(LL) is used as the
quality metric, where LL(Q; P) = Ex〜Q log P(x). Following this idea, We propose a general form
of quality, i.e., U(Q; P) = Ex〜q∕u,[P(x)], where fu[P(x)] is a function over P(x).
Similarly, the Diversity of a text generation model measures how much difference there are among
those generated texts. From the viewpoint of information, Shannon-Entropy(SE) of Q(x) can be
used as a natural diversity metric, where SE(Q) = -Ex〜Q log Q(χ). From another understanding
view, a text x should be less likely to be generated again if the diversity is high. This idea has
been adopted in biology to evaluate the diversity of biocoenosis, named as the Simpson’s Diversity
Index(SDI), where SDI(Q) = 1 — Ex〜qQ(x). Summarizing these two different understandings,
we obtain a general form of diversity, i.e. V(Q) = -Ex〜Qfv [Q(χ)].
To this end, we propose a general form of quality and diversity metrics as follows:
NN
U(Q) = U(Q;P) = Ex〜Qfu[P(χ)] = XQi ∙ f (Pi),	V(Q) = -Ex〜Qfv[Q(χ)] = Xg(Qi),
i=1	i=1
where fu(x) is denoted as f (x) and - fvxx) is denoted as g(χ).
3.2	The Rationality of quality and diversity
To guarantee U and V are rational quality and diversity metrics, we need to discuss about the con-
ditions of f and g. Without loss of generality, we first assume that f is differentiable and g is twice
differentiable. Further, the following requirements are necessary for rational quality and diversity:
1.	Generating more samples with higher real probability yields higher overall quality;
2.	Distributing the probability more equally yields higher overall diversity.
Mathematically, these two requirements can be formalized as the following two properties:
1.IfPi > Pj,thenforQ0 = (Q1,...,Qi+,...,Qj-,...),U(Q0) > U(Q)forany ∈ (0,Qj).
2.IfQi ≥ Qj,thenforQ0 = (Q1,...,Qi+,...,Qj-,...),V(Q0) < V(Q)forany ∈ (0,Qj).
Then we can obtain the conditions of f and g by the following theorem:
Theorem 1. The following conditions are both sufficient and necessary to satisfy the properties 1-2:
For any x1, x2 s.t. x1 > x2 > 0 and x1 + x2 ≤ 1, we have f(x1) > f(x2) and g0(x1) < g0(x2).
According to Theorem 1, it is necessary for f(x) to be strictly monotonically increasing and g(x) to
be strictly concave for X ∈ (0, ɪ). For simplicity, we only consider the cases where such properties
3
Under review as a conference paper at ICLR 2020
hold for x ∈ (0, 1), thus get a sufficient condition: i.e. f(x) is strictly monotonically increasing for
x ∈ (0, 1), and g(x) is strictly concave for x ∈ (0, 1).
Under this condition, we can see that a model with highest quality will distribute all its density to
text with highest real probability, and a model with highest diversity will be uniform, which are
consistent with human understandings.
We list some speical cases under this condition, which will be used as examples in the following
analysis. For quality metrics, we use Log-Likelihood(LL) with f(x) = log x and Coverage-Rate(CR)
with f(x) = x. For diversity metrics, we use Shannon-Entropy(SE) with g(x) = -x logx and
Negative Repeat-Rate(NRR) with g(x) = -x2.
4	The Pareto-Optimality
4.1	The MOP Problem
To explore the relationship between quality and diversity, we consider the following Multi-Objective
Programming(MOP):
max(U(Q),V(Q))
Q
N
s	.t.	Qi = 1
i=1
∀i, -Qi ≤ 0
The goal is to maximize both quality and diversity, while keeping Q a legal distribution. The optimal
solutions of a MOP problem are called Pareto-optima, which means no other solution can beat them
consistently over all objectives.
We give definitions of the terminologies of Pareto-optimality below:
Definition 1. For two distributions Q and Q0, if one of the following conditions are satisfied, we say
that Q is dominated by Q0.
1.	U(Q0) > U(Q) and V (Q0) ≥ V (Q);
2.	U(Q0) ≥ U(Q) and V (Q0) > V (Q).
A solution Q is called a Pareto-optimum if it is not dominated by any Q0. The set containing all the
Pareto-optima is called the Pareto-frontier.
Intuitively, a Pareto-optimum is a solution that there is no distribution can achieve both higher quality
and higher diversity than it. And all the Pareto-optima constitutes the Pareto-frontier. The Pareto-
frontier may collapse into one solution which leads to a global optimum, e.g. if P is uniform, the
unique optimal solution would be Q* = P. However it is often the case where the objectives in
MOP problem cannot reach their optima consistently, thus there exists a family of optimal solutions.
To verify the tradeoff behavior between quality and diversity, we need to prove the existence of such
a family of optimal solutions, thus the structure of the Pareto-frontier under a non-uniform P is what
we care about.
4.2 The Pareto-frontier
We try to show what the Pareto-optima look like by giving the following theorems:
Lemma 1. If Q is a Pareto-optimum, the following conditions are satisfied: if Pi > Pj, then
Qi ≥ Qj;ifPi =Pj,thenQi =Qj.
Theorem 2.	For a distribution Q, if P is not uniform, then:
(1)	The following condition is both sufficient and necessary for Q to be a Pareto-optimum: there
exist real value w ≤ 0 and b that for any i = 1, . . . , N, there is
Qi = g0-1[w ∙ f (Pi) + b],	⑴
4
Under review as a conference paper at ICLR 2020
where
Log Likelihood
①α①>le6①N
Coverage Rate
Figure 1: Illustration of the Pareto-frontier on a random toy categorical distribution with size 20.
Left: The LL-SE case. Right: The CR-NRR case.
^-ι(x) = g g0-1(X) ifχ < g0(O),
g	0	ifx ≥ g0(0),
(2)	b is correspondent to w, i.e. b is fixed once w is fixed. If f(x) < 0 for all x ∈ [0, 1], then
b is strictly monotonically increasing w.r.t. w. If f(x) > 0 for all x ∈ [0, 1], then b is strictly
monotonically decreasing w.r.t. w.
(3)	If we denote a Pareto-optimum Q as Q(w), then for any w1 < w2: if w1 , w2 ∈ [B, 0],
there is	Q(w1)	6=	Q(w2)	and U (Q(w1)) > U (Q(w2)),	V	(Q(w1))	< V	(Q(w2));	if w1,	w2	∈
(一∞,B], there is Q(wι) = Q(w2)； where B =f(P(M)-Tf(P二),and Pmi = maxi Pi, Pm^ =
maxPi 6=Pm Pi, M = #{i|Pi = Pm1 }, # denotes the size of a set.
Lemma 1 shows that the optimal distribution is order-preserving, and Theorem 2 further gives the
structure of Pareto-optima. Since different ws lead to different distributions, we can change w from
0 to B and get a family of optimal solutions with different quality and diversity. As such, for a
non-uniform P, the Pareto-frontier is a family of distributions.
Now we can see that, ifwe want to maximize quality and diversity at the same time, these two metric
acts as a tradeoff. Since all distributions in the Pareto-frontier are Pareto-optima, trying to improve
one metric for an optimum will lead to another optimum at most, thus inevitably causing another
metric to drop.
We show the result of Theorem 2 here on the special cases used in Section 3.2. We pair LL with SE,
and CR with NRR. For the LL-SE metrics, the Pareto-optima can be written as
Pβ	N
Qi = P, Z = EPe, β ≥ 0,
Z
i=1
we have w = -β, and b = 1 + log Z. This is exactly the case used in Li et al. (2019). For the
CR-NRR metrics, the Pareto-optimum can be written as
Qi = max(P + γ, 0), Z = X max(Pi + γ, 0), Y > - max Pi,
Zi
i=1
We have W = - IZ, and b = - 2Zγ. An illustration of the Pareto-frontier on a toy dataset is shown in
Figure 1.
4.3	Relationship with Divergence
Besides quality and diversity, the direct difference between model distribution Q and real P is also
considered in practice, which is usually evaluated by Divergence metrics such as the Kullback-
Leibler divergence. Since calculation of divergence is usually intractable, quality and diversity are
5
Under review as a conference paper at ICLR 2020
often used together as a remedy. However, itis still not clear whether combining quality and diversity
is sufficient for divergence evaluation.
We show that a linear combination of quality and diversity constitute a divergence metric if function
f and g are carefully chosen. Define a weighted sum of quality and diversity as W (Q) = αU (Q) +
(1 - α)V (Q), α ∈ [0, 1), then D(P ||Q) = W(P) - W(Q) would become a divergence metric as
long as Q = P is a Pareto-optimum, as shown in the following Theorem:
Theorem 3.	The following condition is both sufficient and necessary for Q = P to be in the Pareto-
frontier for any P: there exist w0 ≤ 0 and b0 that
g(x)
w0
f (x)dx + b0x.
(2)
If the above condition is satisfied, then Q = P corresponds to a Pareto-optimum with w = w0
and b = b0, and it is the only distribution that maximize W(Q) = αU (Q) + (1 - α)V (Q) with
α = Ww-1, and D(P||Q) = W(P) 一 W(Q) becomes a divergence metric.
We find that if quality and diversity metrics are carefully chosen, namely g is the integral of a affine
transformation of f, we can get a divergence metric by a linear combination of these two metrics.
Since such condition is also necessary, the real distribution is unlikely to be a Pareto-optima if we use
casually chosen metrics. This means, there would be one distribution achieving both higher quality
and higher diversity than the ground truth, which is implausible. Illustration of such phenomenon
with mismatched metrics is shown in Appendix A.7. Therefore, if the condition in Theorem 3 is
not satisfied, it would be unlikely to measure the divergence using a combination of quality and
diversity.
The special cases listed in Section 3.2 would satisfy the condition in Theorem 3 if LL is paired with
SE and CR with NRR. For the LL-SE metrics, D(P||Q) = 11 PN=I Qi ∙ log Qi, which is exactly
the Reverse KL divergence if the constant 1 is ignored. For the CR-NRR metrics, D(P||Q)=
1 PN=I(Qi 一 Pi)2, which measures the sum of squared difference among all probabilities.
5 Optimization of the MOP Problem
Though the original goal is to recover real distribution for text generation models, higher quality
or higher diversity may become the primary requirement in real applications. As a result, it is
meaningful to achieve other Pareto-optima besides recovering the real distribution, leading to a
controllable quality-diversity tradeoff.
One widely used method for quality-diversity tradeoff control is introducing a temperature factor
to the decoding stage of neural decoders. However, such temperature-based method violates the
order-preserving requirements in Lemma 1, thus cannot achieve general Pareto-optima due to the
sequential nature of text(see Appendix A.8 for explanation). In fact, it is non-trivial to achieve
general Pareto-optima through such post-editing methods, i.e. train a model with Q = P and then
modify the decoding strategy.
As a result, we seek methods which can get the Pareto-optimal model immediately after training. In
real applications, the real probability P(x) is never explicitly given, thus a unified objective such as
W(Q) in Section 3.2 is not feasible for training a model. So we will give a method to achieve the
Pareto-optima without knowing P.
5.1	Training Objective
Borrowing the idea from the DDR methodLi et al. (2019), we also use a modified training objective
while keeping the algorithm similar to the widely used maximum likelihood estimation method. For
a Pareto-optimum Q satisfying Qi = g0-1[w ∙ f (Pi) + b], the corresponding training objective is
max Ex〜P h[Q(x)],
Q
h(x) =	-----Cc、八 dx,	c > 0
f f-1[-]
(3)
6
Under review as a conference paper at ICLR 2020
Since fT has no definition outside of [f(0),f(1)], We use f-1 as an expansion, and the value
outside of [f (0), f (1)] can be defined arbitrarily as long as f-1 is monotonically increasing and
strictly positive. Theorem 4 gives the condition when such f-1 can be constructed and guarantees
that We can get a Pareto-optimum by solving the above problem. In the folloWing discussions, We
further assume that f and g satisfy the conditions in Theorem 3 in order to get reasonable quality-
diversity metrics.
Theorem 4.	There exists f-i to make h concave, if and only if limχ→0+ f (x) = -∞. If h(x)
is concave w.r.t x ∈ (0, 1), then with a objective defined as Equation 3, the optimal solution is a
Pareto-optimum defined as Equation 1.
The parameter w and b in the expression of Pareto-optima provides a smooth way to control the
quality-diversity tradeoff according to Theorem 2. Therefore, we can achieve higher quality or
diversity by tuning w or b accordingly in Equation 3.
Since we do not know the value of both w and b for most of the time, such training objective cannot
be applied directly to general cases. However, there are some cases which is still tractable. We
observed that there is a free parameter c in the expression of h(x). Since changing c does not
change the solution, so if w or b could be separated from h(x) and constitute a factor, we can get a
feasible objective using another parameter. For example, if h(x, w, b, C) = hι(x, W) ∙ h2(w, b) ∙ c,
we can set c = h2-1(w, b) so that h(x, w, b, c) = h1(x, w). In this way, b can be neglected and we
only need to care about w. According to Theorem 5, if f is the logarithmic function or the power
function, then b or w can be neglected respectively.
Theorem 5.	If f-i = f T , then the following condition is both sufficient and necessary for
h(x,w,b,c) to be decomposed as h(x,w,b,c) = hι(x,w) ∙ h2(w,b) ∙ c: there exist constant a
and d such that f (x) = a ∙ log X + d.
Also, the following condition is both sufficient and necessary for h(x, w, b, c) to be decomposed as
h(x, w, b, C) = h3(x, b) ∙ h4 (w, b) ∙ c: there exist constant a and d such that f (x) = d ∙ Xa.
Theorem 5 provides a necessary condition for h to be used in practice, but we still need f to be
monotonically increasing and h to be concave for a sufficient condition. Since an affine transfor-
mation of f is equivalent to f in terms of optimal solutions, we only consider the non-trivial cases
in Theorem 5, including f(X) = logX and f(X) = Xa. To simplify the conclusion, we assume
g0 (X) = -f (X) which means w0 = -1 and b0 = 0 in Theorem 3.
For the case of logarithmic function f (x) = log x, we have h0(x) = Xw1 ∙ eW ∙ c. And for the case
of power function f (x) = Xa where a > 0, we have h0(x) = (Xa + b)-1 ∙ (-w)1 ∙ c. This case
does not satisfy the concavity condition, thus should be discarded. However, the continuity holds
for f (x) = -Xa where a < 0, we have h0(∕) = (Xa — b)- 1 ∙ (—w)1 ∙ c.
As such, we can select an appropriate c to diminish the factor w or b. Thus in practice we can use
h0(X) = X W,
or
h0(X) = (Xa — b)- 1, a < 0.
The derivative is sufficient for the gradient calculation, so it is not necessary to know the exact form
of h(X).
5.2 Algorithm
We show how to do the optimization using the expression of h0 . For a model Qθ parameterized by
θ, denote the loss function as
L = -Ex〜P h[Qθ(x)].
The gradient w.r.t θ at current value θ = θ0 would be
▽&L|6=60 = -Ex〜P h [Qθ(X)] , ▽&Qθ (x) |θ=θo
=-Ex〜P h0[Qθ(X)] ∙ Qθ(x) ∙ Vθ logQθ(x)∣θ=θο
=-VθEx〜P h0[Qθ0(x)] ∙Qθo(x) ∙ logQθ(x)∣θ=Θo.
7
Under review as a conference paper at ICLR 2020
Algorithm 1 The Quality-Diversity Tradeoff Control Algorithm
Input: Dataset D = {xi}iN=1, batch size M, learning rate α, model Qθ, function h0.
1:	Initialize Qθ with random weights.
2:	Pre-train Qθ with Maximum Likelihood Estimation. (optional)
3:	repeat
4:	Sample M examples {xi }iM=1 from D.
5:	θo 一 θ.
6:	Calculate T(xi) for each i using Equation 4.
7:	θ  θ + α ∙VθMj pi=1 T(Xi) ∙ log qθ(Xi)
8:	until convergence
Table 1: A summary of the two QDTC methods used in our experiments.
Method	f(X)	g(X)	h0 (x)	U(Q)	V(Q)
QDTC-logarithm	log X	-XlogX	ɪ X W	PiN=- Qi log Pi	- Pi=- Qi log Qi
QDTC-reciprocal	x	log X	--b X		__PN	Q -L=I Pi	PiN=- log Qi
Let
T(X) = h0[Qθ0 (X)] ∙ Qθ0 (X),	⑷
then
VθL∣θ=θο = -VθEχ〜P T(x) ∙ logQθ(x)∣θ=Θo.	(5)
Now the model can be optimized using Equation 5. We summarized this Quality-Diversity Tradeoff
Control(QDTC) algorithm as Algorithm 1:
Note that when We use h0(X) = Xw1 and constrain W in (一∞, -1), QDTC method would be equiv-
alent to the Differentiated Distribution Recovery(DDR) method used by Li et al. (2019), thus DDR
is a special case of our QDTC.
6	Experiments
In this section, we evaluate our proposed QDTC method on synthetic data as well as MSCOCO
Image Caption dataset(Chen et al., 2015), compared with the temperature-based method.
For the temperature-based method, we pre-train the model with Maximum Likelihood Estima-
tion(MLE), and then tune the temperature t for different output during decoding.
For our QDTC method, we use two pairs of metrics: the logarithm ones where f(X) = log X, g(X) =
-X log x; and the reciprocal ones where f (x) = 一 ɪ, g(X) = log x. We summarize the details of
these two cases in Table 1. Although QDTC can be used without any pre-training, we find it would
converge faster and more stably if we pre-train the model with MLE. As a result, we also use MLE
pre-training for QDTC in all of our experiments.
6.1	Experiments on Synthetic Data
In the synthetic data, the real probability P is explicitly given, so we can evaluate how close a
generated model Q is to the Pareto-frontier.
Specifically, we define a sequential data space with vocabulary size 10 and length 3. Thus the
total number of feasible texts is N = 103. The synthetic data are generated using a randomly
initialized oracle model, whose parameters are known in advance. In our experiments, this model
contains an embedding layer with dimension 32, an LSTM layer with 32 hidden nodes, and a fully-
connected(FC) output layer with 10 hidden nodes.
The text generation model share the same structure with the oracle model, but use learned param-
eters. To guarantee the consistency between training and test, we do not construct a dataset D in
advance. Instead, we sample data from the oracle model directly whenever data are needed. The
8
Under review as a conference paper at ICLR 2020
Diversity(Iogarithm)
Figure 2: Evaluation of quality and diversity on synthetic data. Vertical dashed lines show the
boundary of maximum diversity. Left: The original metrics. Right: The quality discrepancy under
the same diversity level compared with the Pareto-frontier.
×~× QDTC-reciprocal
•~∙ Tp-based
Diversity(reciprocal)
quality and diversity of the trained model are computed by the corresponding metrics in the loga-
rithm case and the reciprocal case as shown in Table 1.
As we can see from the results shown in Figure 2, all methods show smooth curves from upper left
to lower right under the evaluation of quality and diversity, indicating a tradeoff relation between
the two metrics. The curves of our QDTC methods closely fit their corresponding ground truth
curve, which means Pareto-optima are well obtained. The curve of temperature-based method gets
close with ground truth at two points: the middle point where t = 1 and the leftmost point where
t → ∞. This makes sense because temperature-based method can achieve Q = P with t = 1 and
Q becomes uniform when t tends to +∞. However at other points, the discrepancies grow much
larger, indicating a failure to achieve other Pareto-optima.
6.2	Experiments on MSCOCO Dataset
To show the effectiveness of QDTC on real text data, we run experiments on the MSCOCO Image
Caption dataset. Our empirical settings are exactly the same as Guo et al. (2017), including the
preprocessing and the data separation. Specifically, only the captions are used as text data, and
sentences which contain words with frequency lower than 10 are removed. 80,000 unique sentences
are sampled as training set, and another 5,000 unique sentences are used as test set. The final
vocabulary size is 4,840 and maximum text length is 32.
The architectures of the text generation models are similar as that on synthetic data. The embedding
dimension and number of LSTM hidden nodes are set to 128, and the number of FC hidden nodes
is 4,840.
Since the ground truth distribution P is unknown under this setting, the calculations of our general
defined quality and diversity metrics may become intractable. Fortunately, the CR-NRR metrics can
be approximated by sampling due to the linearity of f :
NN
CR(Q; P) = X	Qi	∙	Pi	=	Ex〜P Q(x),	NRR(Q)	= — XQ2 =	-Ex〜Q	Q(x).
9
Under review as a conference paper at ICLR 2020
Figure 3: Evaluation of quality and diversity on MSCOCO dataset. We apply 7 hyper-parameters
for each method, their corresponding values from left to right are: [1.3, 1.2, 1.1, 1.0, 0.9, 0.8, 0.7]
for t in temperature-based method; [-0.85, -0.9, -0.95, -1.0, -1.1, -1.2, -1.3] for w in QDTC-
logarithm; [1e9, 1e8, 1e7, 0, -1e6, -2e6, -5e6] for b in QDTC-reciprocal.
Therefore, the expectation over Q in NRR can be directly taken on generated samples, while the
expectation over P in CR can be calculated by sampling from the test set.
Besides using CR and NRR as metrics, we also evaluate our results by the widely used quality and
diversity metrics in application, i.e. BLEU-n (Papineni et al., 2002) and Distinct-n (Li et al., 2015).
BLEU-n measures the degree of n-gram overlap between generated text and a reference text set,
i.e. the test set. Distinct-n calculates the ratio of unique n-grams over all n-grams in generated text.
Here we set n = 3. The experimental results are shown in Figure 3.
From the results, we can see that with the change ofw or b, our QDTC methods show smooth control
of the quality-diversity tradeoff under CR-NRR and even BLEU-Distinct metrics. Therefore, QDTC
can be applied in some real applications where quality or diversity is preferred while keeping another
metric above a threshold. QDTC methods do not show consistent superiority over temperature-
based method in the figure, this is because the metrics used in the real data are different from the
corresponding theoretical metrics in QDTC. Nevertheless, QDTC performs better than temperature-
based method in many cases.
7	Conclusion and Discussion
In this paper, we mainly focus on the theoretical study of quality and diversity in text generation.
We give a general definition of quality and diversity, and then study the MOP problem where quality
and diversity are both required to be maximized. Three main conclusions are obtained by our study:
Firstly, quality and diversity show a clear tradeoff relation in theory. Therefore, we suggest using
both metrics for evaluation in real application instead of focusing only one metric, to get a compre-
hensive understanding of a specific text generation model.
Secondly, a linear combination of some paired quality and diversity is equivalent to a divergence.
This theoretical result indicates that quality and diversity metrics should be carefully chosen in
practice, to avoid the mistake that ground-truth distribution is non-optimal.
Thirdly, an algorithm named QDTC is proposed to efficiently optimize both quality and diversity.
Experimental results show that QDTC achieves good approximation of the Pareto-optima on both
synthetic data and real MSCOCO data. In applications where one metric is favored more than
another, a good model should be able to achieve the required Pareto-optimal solution. We can see
that our proposed QDTC gives a feasible example of how to achieve a controllable quality-diversity
tradeoff in this direction.
In the future, we would like to study the relationship between quality and diversity under the con-
ditional text generation settings. It is also anticipated to extend the conclusions to continuous data
generation settings, such as image or video generation.
10
Under review as a conference paper at ICLR 2020
References
Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. Neural machine translation by jointly
learning to align and translate. arXiv preprint arXiv:1409.0473, 2014.
Liqun Chen, Shuyang Dai, Chenyang Tao, Haichao Zhang, Zhe Gan, Dinghan Shen, Yizhe Zhang,
Guoyin Wang, Ruiyi Zhang, and Lawrence Carin. Adversarial text generation via feature-mover’s
distance. In Advances in Neural Information Processing Systems, pp. 4666-4677, 2018.
Stanley F Chen, Douglas Beeferman, and Ronald Rosenfeld. Evaluation metrics for language model-
s. In DARPA Broadcast News Transcription and Understanding Workshop, pp. 275-280. Citeseer,
1998.
Xinlei Chen, Hao Fang, TsUng-Yi Lin, Ramakrishna Vedantam, Saurabh Gupta, Piotr Dollar, and
C Lawrence Zitnick. Microsoft coco captions: Data collection and evaluation server. arXiv
preprint arXiv:1504.00325, 2015.
Angela Fan, Mike Lewis, and Yann Dauphin. Hierarchical neural story generation. arXiv preprint
arXiv:1805.04833, 2018.
William Fedus, Ian Goodfellow, and Andrew M Dai. Maskgan: Better text generation via filling in
the ,. arXivpreprint arXiv:180L 07736, 2018.
Xiang Gao, Sungjin Lee, Yizhe Zhang, Chris Brockett, Michel Galley, Jianfeng Gao, and Bill Dolan.
Jointly optimizing diversity and relevance in neural response generation. arXiv preprint arX-
iv:1902.11205, 2019.
Jiaxian Guo, Sidi Lu, Han Cai, Weinan Zhang, Yong Yu, and Jun Wang. Long text generation via
adversarial training with leaked information. arXiv preprint arXiv:1709.08624, 2017.
Tatsunori B Hashimoto, Hugh Zhang, and Percy Liang. Unifying human and statistical evaluation
for natural language generation. arXiv preprint arXiv:1904.02792, 2019.
Jey Han Lau, Timothy Baldwin, and Trevor Cohn. Topically driven neural language model. arXiv
preprint arXiv:1704.08012, 2017.
Jianing Li, Yanyan Lan, Jiafeng Guo, Jun Xu, and Xueqi Cheng. Differentiated distribution recovery
for neural text generation. In AAAI, 2019.
Jiwei Li, Michel Galley, Chris Brockett, Jianfeng Gao, and Bill Dolan. A diversity-promoting
objective function for neural conversation models. arXiv preprint arXiv:1510.03055, 2015.
JiWei Li, Will Monroe, Tianlin Shi, Sebastien Jean, Alan Ritter, and Dan Jurafsky. Adversarial
learning for neural dialogue generation. arXiv preprint arXiv:1701.06547, 2017.
Chin-YeW Lin and FJ Och. Looking for a feW good metrics: Rouge and its evaluation. In Ntcir
Workshop, 2004.
Sidi Lu, Yaoming Zhu, Weinan Zhang, Jun Wang, and Yong Yu. Neural text generation: Past,
present and beyond. arXiv preprint arXiv:1803.07133, 2018.
Tomas Mikolov, Martin Karafiat, LUkas Burget, Jan Cernocky, and Sanjeev Khudanpur. Recurrent
neural netWork based language model. In Eleventh Annual Conference of the International Speech
Communication Association, 2010.
Weili Nie, Nina Narodytska, and Ankit Patel. Relgan: Relational generative adversarial netWorks
for text generation. 2018.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. Bleu: a method for automatic
evaluation of machine translation. In Proceedings of the 40th annual meeting on association for
computational linguistics, pp. 311-318. Association for Computational Linguistics, 2002.
Steven J Rennie, Etienne Marcheret, Youssef Mroueh, Jarret Ross, and Vaibhava Goel. Self-critical
sequence training for image captioning. In CVPR, volume 1, pp. 3, 2017.
11
Under review as a conference paper at ICLR 2020
Jingjing Xu, Xuancheng Ren, Junyang Lin, and Xu Sun. Diversity-promoting gan: A cross-entropy
based generative adversarial network for diversified text generation. In Proceedings of the 2018
Conference on Empirical Methods in Natural Language Processing,pp. 3940-3949, 2018.
Lantao Yu, Weinan Zhang, Jun Wang, and Yong Yu. Seqgan: Sequence generative adversarial nets
with policy gradient. In AAAI, pp. 2852-2858, 2017.
Hainan Zhang, Yanyan Lan, Jiafeng Guo, Jun Xu, and Xueqi Cheng. Reinforcing coherence for
sequence to sequence model in dialogue generation. In IJCAI, pp. 4567-4573, 2018a.
Hainan Zhang, Yanyan Lan, Jiafeng Guo, Jun Xu, and Xueqi Cheng. Tailored sequence to sequence
models to different conversation scenarios. In Proceedings of the 56th Annual Meeting of the
Association for Computational Linguistics (Volume 1: Long Papers), pp. 1479-1488, 2018b.
Jiyuan Zhang, Yang Feng, Dong Wang, Yang Wang, Andrew Abel, Shiyue Zhang, and Andi
Zhang. Flexible and creative chinese poetry generation using neural memory. arXiv preprint
arXiv:1705.03773, 2017.
Yaoming Zhu, Sidi Lu, Lei Zheng, Jiaxian Guo, Weinan Zhang, Jun Wang, and Yong Yu. Texygen:
A benchmarking platform for text generation models. In The 41st International ACM SIGIR
Conference on Research & Development in Information Retrieval, pp. 1097-1100. ACM, 2018.
A Appendix
A.1 Preliminaries
Before starting the proofs, we first introduce some preliminaries on the constrained convex opti-
mization problem. Assume f (x), ci (x), and hj (x) are continuous differentiable function define on
Rn , consider the constrained convex optimization problem defined as follows:
min
x∈Rn
s.t.
f(x)
Ci(X) ≤ 0, i = 1, 2,…，k
hj (X)=0, j = 1, 2,…，l
(6)
The optimal solutions for above problem are given by, as shown in the following theorem:
Theorem 6. Assume f(X) and ci(X) are convex, hj (X) are affine, and ci are strictly feasible (there
exists one X satisfying ci (X) < 0 for all i). Define the Lagrange function as:
kl
L(X, α, β) = f(X) +	αici(X) +	βjhj (X),
i=1	j=1
(7)
where α ≥ 0. Then the the following conditions are both sufficient and necessary for X to be a
solution in problem 6.
VχL(x* ,α*,β*) =0
VaL(x* ,α*,β*) = 0
Ve L(x* ,α*,β*) = 0
α*Ci(x*) = 0, i = 1, 2,…，k	(8)
Ci(x*) ≤ 0, i = 1, 2,…，k
α* ≥ 0, i = 1, 2, ∙∙∙ ,k
hj(x*) = 0, j = 1, 2,…，k
The conditions in Equation 8 are called the Karush-Kuhn-Tucker(KKT) conditions.
12
Under review as a conference paper at ICLR 2020
A.2 Proof of Theorem 1
For property 1, from U(Q0) - U(Q) = f(Pi) - f(Pj) = [f (Pi) - f(Pj)] > 0, we get f(Pi) >
f (Pj ). We then get the conclusion by setting x1 = Pi and x2 = Pj .
For property 2, V (Q0) - V (Q) = [g(Qi + ) + g(Qj - )] - [g(Qi) +g(Qj)] < 0 is true for any
Qi > Qj. Denote C = Qi + Qj and r(x) = g(x) + g(C - x), then we have V (Q0) - V (Q) =
r(Qi +) - r(Qi) < 0 for any Qi, . Since 0 < Qi < Qi + < 1, we need r0 (x) < 0 for x ∈ (0, 1).
Then, since r0 (x) = g0 (x) - g0(C - x) < 0 is true for any 0 < C - x < x < 1. Set x1 = C - x
and x2 = x and we get g0(x1) < g0(x2) for any x1 > x2 > 0 and x1 + x2 = Qi + Qj ≤ 1.
A.3 Proof of Lemma 1
If Pi > Pj , assume Qi < Qj , we can construct Q0 where Q0k = Qk for all k 6= i, j and Q0i =
Qj,Q0j = Qi. As such, V (Q0) = V(Q)butU(Q0)-U(Q) = (Qj-Qi)[f(Pi)-f(Pj)] > 0. This
means Q is dominated by Q0, which conflicts with the fact that Q is a Pareto-optimum. So Qi ≥ Qj .
If Pi = Pj , assume Qi 6= Qj , and we can further assume Qi > Qj . Again we construct Q0
where Qk = Qk for all k = i,j and Qi = Qj = Qi+Qj. Surely We have U(Q0) = U(Q), and
V (Q0)-V (Q) = 2g( Qi+Qj )-g(Qi)-g(Qj). Since g is strictly concave, we have V (Q0)-V (Q) >
0, which means Q is dominated by Q0 . This causes confliction, so Qi = Qj .
A.4 Lemma 2 and its proof
This lemma is used to support the proof of Theorem 2 and Theorem 3.
Lemma 2. Assume α ∈ [0, 1) and W (Q) = αU (Q) + (1 - α)V (Q), then the distribution Q that
maximize W(Q) satisfies Qi = g0-1[w ∙ f (Pi) + b], and W = θ-ɪ∙
Define the optimization problem as follows:
min -α ∙ U(Q) - (1 - α)V(Q)
Q
N
s.t. 1 -XQi = 0
i=1
∀i, -Qi ≤ 0
Again we first check that the prerequisites in KKT are all satisfied. -U (Q) is linear and -V (Q) is
convex w.r.t. Q0; 1 - PiN=1 Qi is affine w.r.t. Q0; since all Qi can be positive, so the inequalities are
all strictly feasible.
The Lagrange function is:
N	N	NN
L(Qi, λ, ξi) =-αXQif(Pi) -(1-α)Xg(Qi)+λ(1-XQi)-XξiQ0i, ξ≥0
i=1	i=1	i=1	i=1
Apply KKT and we get the following conditions for a optimal solution:
∀i,∂L
∂ Qi
-αf (Pi) - (1 - α)g0 (Qi) - λ - ξi = 0,
∀i, -ξiQi = 0
For Qi 6= 0, there is ξi = 0, so
Qi=g0-1[ 匕f (Pi)+
占];
for Qi = 0, there is ξi > 0, so
α
O-If (Pi) +
λ
α-1
> g0(0).
13
Under review as a conference paper at ICLR 2020
Denote W = ɑ-⅛ and b = α--i and combine the two cases together, We get:
Qi = g0-1 [W ∙ f (Pi)+ b],	W ≤ 0,
The above derivation is both sufficient and necessary, so we finished the proof.
A.5 Proof of Theorem 2
We give the proofs for three conclusions individually.
A.5.1 CONCLUSION 1
Here we only consider the case with U(Q) 6= maxQ U (Q), and the case where U (Q) =
maxQ U(Q) will be incorporated into conclusion 3. We try to find a distribution Q0 with the highest
diversity while quality is not lower than Q. Define a convex optimization problem as follows:
min -V (Q0)
s.t. U(Q) - U(Q0) ≤ 0
N
1-XQ0i=0
i=1
∀i, -Q0i ≤ 0
For Q to be a Pareto-optimum, it’s both sufficient and necessary for Q to be a solution of above
problem. Thus we try to solve this problem next.
We first check that the prerequisites in KKT are all satisfied. -V (Q0) is convex w.r.t. Q0; 1 -
PiN=1 Q0i is affine w.r.t. Q0; U(Q) - U(Q0) and -Q0i are convex(linear) w.r.t Q0; since all Q0i can be
positive and U(Q) 6= maxQ U (Q), so the inequalities are all strictly feasible.
The Lagrange function is:
N	NN	N
L(Qi, λ, η, ξi) =-Xg(Q0i)+λ(1-XQ0i)+ηX(Qi-Q0i)f(Pi)-XξiQ0i,	η,ξ≥0
Apply KKT and we get the following conditions for a optimal solution:
∂L
∀i, ∂Q0^ = -g (Qi) - λ - ηf (Pi) - ξi = 0,
η[U(Q) - U(Q0)] =0,
∀i, -ξiQ0i =0
Since we need Q to be a solution, so
∀i, -g0(Qi)-λ-ηf(Pi)-ξi=0,
∀i, -ξiQi = 0
For Qi 6= 0, there is ξi = 0, so Qi = g0-1[-ηf(Pi) - λ]; for Qi = 0, there is ξi > 0, so
-ηf (Pi) - λ > g0(0). Denote W = -η and b = -λ and combine the two cases together, we get:
Qi = g0-1 [W ∙ f (Pi)+ b],	W ≤ 0,
where
g"'(X) = {
g0-1(x)
0
if x < g0(0),
if x ≥ g0(0).
The above derivations are both sufficient and necessary, thus we finish the proof.
14
Under review as a conference paper at ICLR 2020
A.5.2 CONCLUSION 2
For the second conclusion, we separate the proof into two parts: (1) b is correspondent to w; (2) the
monotonicity of b w.r.t. w.
(1)	The sum of all Qi should be 1. Denote
N
T (w,b) = X g0-1[w ∙f (Pi) + b].
i=1
Since g0(x) is strictly monotonically decreasing, so T(w, b) is monotonically non-increasing w.r.t.
b. If T(w, b) > 0, there would be a term which is strictly monotonically decreasing w.r.t. b, under
which condition T(w, b) is strictly monotonically decreasing w.r.t. b. Also, T(w, b) is continuous
w.r.t. b since g0-1 is continuous. When
b = g0(0) - W ∙ f (maxPi),
i
there is
w ∙ f (Pi) + b ≥ w ∙ f (maxPi) + b = g(0),
i
so T(w, b) = 0; when
b = g,(-1) — w ∙ f (minPi),
Ni
w ∙ f (Pi) + b ≤ w ∙ f (minPi) + b = g'(-1),
iN
so T(w, b) ≥ 1. From above analysis, the value ofT can reach 0 orbe greater than 1. So combining
the monotonicity of T, there exists and only one b that satisfies T(w, b) = 1, leading to a rational
distribution.
(2)	Define T(w, b) = PN=I g0-1[w ∙ f (Pi) + b(w)] as above. Since T(w, b) represents the total
probability of a distribution, so there should be T(w, b) ≡ 1, thus 瞿 =0.
dT = X	f(Pi) + b0(w)
dw	J g00{g0-1[w ∙ f (Pi) + b(w)]} ,
i∈S
where S = {i∣w ∙ f (Pi) + b(w) < go(0)}. By the condition 第=0,we get
b0 (w)
P _______________f (Pi)________
乙i∈s g00{g0-1[w∙f(Pi)+b(w)]}
—
Σ
1
i∈S g00{g0-1[w∙f(Pi)+b(w)]}
Since g00(x) < 0, so if f(x) < 0 for all x ∈ [0, 1], we can get b0 (w) > 0, thus b is strictly
monotonically increasing w.r.t. w. Similarly, if f(x) > 0 for all x ∈ [0, 1], we can get b0(w) < 0,
thus b is strictly monotonically decreasing w.r.t. w.
A.5.3 CONCLUSION 3
For the third conclusion, we also separate the proof into two parts: (1) the uniqueness of Q(w); (2)
the monotonicity of U and V w.r.t. w.
(1) Since P is not uniform, so we can denote B, Pm1, Pm2 as they are in the theorem. According
to Lemma 1, since Pm1 is the largest one, so the corresponding Qm1 is also the largest one, which
means
Qmi = g0-1[w ∙ f (Pmι )+ b] > O.
Thus we get
W ∙ f (Pmi) + b < g0(O).
At the same time, because we can get Qi = Qm1 if Pi = Pm1 , so we can sum up all the largest Qi
and get
N
M ∙ Qmi ≤ X Qi = 1,
i=1
15
Under review as a conference paper at ICLR 2020
we can get
W ∙ f (PmI) + b ≥ g0( M).
(9)
Consider the case where W ≥ B, we first prove that W ∙ f (Pm2) + b ≤ go(0). Assume
W ∙ f(Pm2 )+ b>gθ(0),	(10)
then Qm2 = 0, and there is Qi = 0 for any i satisfying Pi ≤ Pm2 . As a result, there should be
Qi = M for all i satisfying Pi = Pmi, which means
W ∙ f(Pmι)+ b = g0( MM).
(11)
Subtract Equation 11 by Equation 10, we get
W ∙ [f (「mi)- f(Pm2 )] <g0( MO-d(O),
so
w<T≡⅛ = B
This contradict with the fact that W ≥ B. Thus We have W ∙ f (Pm吆) + b ≤ g0(O).
Combining the above conclusions, for any W1, W2 ∈ [B, 0], assume Q(W1) = Q(W2), then
W1∙ f (Pmi ) + bl = W2 ∙ f (Pmi ) + bz,
W1∙ f(Pm2 ) + bl = W2 ∙ f (Pm2 ) + b?.
As Pmi 6= Pm2, so W1 = W2, causing contradiction. Thus we have Q(W1) 6= Q(W2).
For any W ≤ B, assume
W ∙ f (Pm2) + b < g0(O).
By subtracting Equation 9 and Equation 12, we get
(12)
so
W ∙ [f (Pmi)- f(Pm2 )] >g0(⅛) - g0(O),
W>
g0( M)- g0 (O)	= B
f (Pmi)- f(Pm2 )=.
This causes contradiction, so the above assumption does not hold. Thus We have W ∙ f (Pm?) + b ≥
g0(O), which means Qm? = 0. Borrowing the proof above, We know that Qi =吉 for all i satisfying
Pi = Pmi . This is a trivial Pareto-optimal case where U(Q) = maxQ U (Q). Now we know
the distribution Q is fixed and does not change as W changes, so for any Wl, W2 ≤ B, there is
Q(Wl) = Q(W2).
(2) For the expression ofQi, since f and g0 are both continuous and monotonic, so it is easy to know
that Qi is continuous w.r.t. W, then U (Q(W)) and V (Q(W)) are both continuous w.r.t. W. We just
need to prove the monotonicity.
Assume B ≤ Wl < W2 ≤ 0, the goal is to prove that U (Q(Wl)) > U(Q(W2)) and V (Q(Wl)) <
V(Q(w2)). According to Lemma 2, Wi and w? have their corresponding αι = Ww-1 and a? =
Ww-1, and αι > α2. Since Q(w) is the optimal solution for problem aU(Q) + (1 - α)V(Q), and
Q(W1) is different with Q(W?), so the following inequalities hold:
α1U(Q(W1)) + (1 - α1)V(Q(W1)) > α1U(Q(W?)) + (1 - α1)V(Q(W?)),
α?U(Q(wi)) + (1 - α2)V(Q(wi)) < a?U(Q(w2)) + (1 - a?)V(Q(w?)).
Subtracting the first equation by the second one, we get
(αι - α2)[(U(Q(wi)) - U(Q(w2))) - (V(Q(wi)) - V(Q(w2)))] > 0.
As α1 > α?, so
U(Q(W1)) - U(Q(W?)) > V (Q(W1)) - V (Q(W?)).
Because Q(W1) and Q(W?) are both Pareto-optima, there quality and diversity should satis-
fy one of the following: U(Q(W1)) > U(Q(W?)), V(Q(W1)) < V(Q(W?)) or U(Q(W1)) <
U (Q(W?)), V(Q(W1)) > V(Q(W?)). With the derived restriction U(Q(W1)) - U(Q(W?)) >
V(Q(W1)) - V(Q(W?)), we know the first one holds, that is U(Q(W1)) > U(Q(W?)) and
V(Q(W1)) < V(Q(W?)).
16
Under review as a conference paper at ICLR 2020
Log Likelihood
Figure 4: Illustration of the Pareto-frontier on a random toy categorical distribution with size 20.
The diversity metrics are swaped, thus are mismatched. Left: Pair LL with NRR. Right: Pair CR
with SE. Note that there is always a gap between the star and the curve, indicating that the real
distribution lies on neither of the two Pareto-frontiers.
——Pareto-frontier	∖
2∙4 r ∙ ∙ ∙ Random distribtuions	∖	∣
*** Real distribution	`
2.3 I------1-------1------1-------1-------1------1-------1-------1
0.035	0.040 0.045	0.050 0.055	0.060 0.065	0.070 0.075
Coverage Rate
A.6 Proof of Theorem 3
The requirement that Q = P in the Pareto-frontier is equivalent to the following condition: for any
P , there exist w0 ≤ 0 and b0 that for any i, there is
Pi = ^-1 [wo ∙ f (Pi) + bo].
This means, for any Pi > 0, there is wo ∙ f (Pi) + bo = g(Pi). Since f and gf are both continuous,
so
wo ∙ f (0) + bo - g0(0) = lim wo ∙ f (Pi) + bo - g0(Pi) = 0.
Pi→o
We can see wo ∙ f (Pi) + bo = g，(Pi) is also true for Pi = 0. By solving this differential equation,
we get
g(x) = wo	f (x)dx + box.
Here bo can be any value because Pi = g0-1 [wo ∙ f (Pi) + bo] always lead to a plausible distribution
P. Under this condition, we know that Q = P is the only distribution that maximize W (Q) =
αU(Q) + (1 - α)V(Q) where α = Ww-1 according to Lemma 2. With the above conclusions, it is
easy to check that D(P ||Q) = W(P) - W(Q) ≥ 0andD(P||Q) = 0ifandonlyifQ = P,thus
D(P ||Q) is a divergence metric.
A.7 Illustration of Pareto -frontier with Mismatched Metrics
We show in Figure 4 that the point Q = P is under the Pareto-frontier curve when quality and
diversity metrics are not matched, i.e. the condition in Theorem 3 is not satisfied. We use the same
toy dataset as in Figure 1, but pair LL with NRR and CR with SE.
A.8 Insufficiency of Temperature-based Method
Temperature-based method for quality-diversity tradeoff is implemented through dividing the prob-
ability vector a by a temperature factor t before the softmax operation:
1	|V|
Q(x; t) = Softmax(a/t) = — (ea1 /t,…，ea|v|/t),	Z = Eeai/t.
i=1
When the temperature is high (t → ∞), the distribution would be near uniform; and when the
temperature is low (t → 0), the distribution would be sharp and assign Q(x) → 1 for x with largest
P(x), and Q(x) → 0 for other x. However in text generation, this is applied for the conditional
probability of each token given its prefix, i.e. P(xi|x1:i-1), and is intractable to apply on the global
probability P(x1:L).
17
Under review as a conference paper at ICLR 2020
We give an example showing that this method violates the requirements in Lemma 1, thus cannot
be used to achieve general Pareto-optima. To be concrete, if the post-edited model distribution is Q,
we construct a simple case that Qi > Qj while Pi < Pj for some i, j .
Assume the text length is 2, and the vocabulary is {a, b, c}. Then the real probability ofa text sample
X = (χ1,χ2) would be P (x) = P (xi) ∙ P (χ2∣χ1). We assume P (xi) = (0.5,0.5,0.0), P (χ2∣χ1 =
a) = (0.4, 0.3, 0.3), P(x2 |x1 = b) = (0.5, 0.5, 0.0), then we have P (aa) = 0.2 < P (ba) = 0.25.
However when the temperature t approaches 0, there would be Q(x1) = (0.5, 0.5, 0.0), Q(x2|x1 =
a) = (1.0, 0.0, 0.0), Q(x2 |x1 = b) = (0.5, 0.5, 0.0), so that Q(aa) = 0.5 > Q(ba) = 0.25.
This clearly violates the order-preserving nature of a Pareto-optimum, thus we can never get the full
Pareto-frontier using the temperature-based method, no matter what f and g are.
A.9 Proof of Theorem 4
We discuss the condition of f as conclusion 1 and the optimal solutions of the objective as conclusion
2.
A.9.1 CONCLUSION 1
Since g0(x) is continuous and strictly monotonically decreasing w.r.t. X and w < 0, g (R-b is
continuous and strictly monotonically increasing w.r.t. x. By changing the value of W and b, g(2-b
can reach any finite real value. To make h concave, we need ^-1	to be monotonically decreasing
f (x)
w.r.t. x ∈ (-∞, ∞).
We know that f is strictly monotonically increasing for x ∈ (0, 1), so f(0) = limx→0+ f(x) is
either a finite value or -∞.
Consider the case where f(0) is a finite value z. The domain of definition off-1 would be (z, f (1)),
and f T(Z) = 0. Since f-1 in an expansion of f-1, f-1 shares the same value in (z, f (1)), so
f-1(z) = 0. This will lead to limx→z+ ʃ-ɪ-y = +∞. Thus ʃ-ɪ-j is unable to be monotonically
decreasing near x = z .
Then we consider the case where f(0) = -∞. The domain of definition of f-1 would be
(-∞, f (1)], and f-1(x) > 0 for any x ∈ (-∞, f (1)]. If f(1) = +∞, then we construc-
t f-1(χ) = fT(X), so that f-1(χ) is strictly positive and monotonically increasing. As such,
^-1 would be monotonically decreasing. If f ⑴ is a finite value, which means f-1 (f (1)) = 1,
f (x)
it is easy to define the value of f-1(χ) in X ∈ (f (1), +∞) to guarantee f-1(χ) is monotonically
increasing and strictly positive. As such, ʌɪ would also be monotonically decreasing and strictly
f-1(x)
positive.
Based on above analysis, we can conclude that it is both sufficient and necessary for
limx→0+ f(X) = -∞.
A.9.2 CONCLUSION 2
This problem is a convex optimization problem:
N
min - XPi∙h(Qi)
i=1
N
s.t. 1 -XQi =0
i=1
∀i, -Qi ≤ 0
The Lagrange function is:
N	NN
L(Q, λ, ξi) = -XPih(Qi)+λ(1-XQi)-XξiQi, ξ≥0.
i=1	i=1	i=1
18
Under review as a conference paper at ICLR 2020
We then check if Qi = g0-1[w ∙ f (Pi) + b] is a solution of this problem. Since h0(x) =  gc(x)-b ,
f [ W ]
so
∂L
∂Qi
—
c • Pi
----------:----Λ —
f-1 [ g0(Qi)-b ]
We show that this requirement is satisfied with Qi = g0-1[w • f (Pi) + b], λ = -c: if Qi > 0, then
g0 (Qi) = w • f(Pi) + b,
in Which case ξi = 0, and
∂L
∂Qi
cPP - λ - ξi = 0.
If Qi = 0, then
w • f(Pi) + b ≥ g0(0),
so
Pi
0 ≤ --i-- ≤ 1
≤ f-1[T] ≤ .
We can set
f-1[⅛] + C ≥ 0,
so that
∂L
∂Qi	.
The above derivations are both sufficient and necessary, so Qi = g0-1[w ∙ f (Pi) + b] is the unique
optimal solution.
A.10 Proof of Theorem 5
We discuss the logarithm function case as conclusion 1 and the power function case as conclusion
2.
A.10.1 CONCLUSION 1
For sufficiency, When f (x) = a log X + d, there is f T(X) = exp{x-d}, so
h0(x, w, b, c)
exp{ 3 - b+wd }
wa wa
exp{-Mx，-*” }. exp{m}. c.
wa
wa
By setting hι(x,w) = R exp{- g (XW-Wd}dx and h2(w, b) = exp{Wba}, we get h(x,w,b,c)
h0(X, W, b, c)dX = h1 (X, W) • h2 (W, b) • c.
For necessity, pick any X1, X2 ∈ (0, 1), and construct a function:
H (x,w,b)= h(xi，w，b，c)	f-1
h0(X2, w, b, c)	f-1 [
g0(x2 )-b
g0 (XI )-b ].
W 」
If the decomposition can be found, this Will require H(X, w, b) to exclude b in its expression, so
there should be
Denote A(X, w, b) = f-1 [g
∂H(X, w, b)
∂b
(X)-b
W
1
∂H(X, w, b)
—∂b—=0.
]. Then we have
A(x2, w, b)2
• {-
A(X1 , w, b)
+	A(x2,w, b)
Wf 0[A(X2, W, b)]	Wf 0[A(xι,w, b)]
—
—
c
FRW-I
c
w
]
} = 0.
19
Under review as a conference paper at ICLR 2020
This lead to
A(xι, w, b) ∙ f 0[A(xι, w, b)] = A(x2, w, b) ∙ f 0[A(x2, w, b)].
This holds for any x1 , x2, so both the left and right side should be a constant. Denote this constant
as a, then
A(x, w, b) ∙ f 0[A(x, w, b)] = a.
For simplicity, denote A(x, w, b) as t, then
t ∙ f0(t) = a.
We get f(x) = alogx + d by solving this differentiable equation, where a, d can be any constant.
A.10.2 CONCLUSION 2
For sufficiency, when f (x) = d ∙ xa, there is f T(X) = ((X) 1, so
h(x,w,b,c = f-1[ g"b ]
c
∣-g0(χ)-b-∣ 1
[-Wd~] α
=[g0(x) — b]- 1 ∙ (wd) 1 ∙ c.
By setting hι(x,b) = R[g0(x) — b]- 1 dx and h2(w,b) = (wd) 1, We get h(x, w, b, c)
/ h0(x, w, b, c)dx = hi (x, b) ∙ h2 (w, b) ∙ c.
For necessity, we again pick any x1 , x2 ∈ (0, 1), and construct the function:
g0(x2 )-b
H (x,w,b)= hl：1Whc= f±
h0(x2, w, b, c)	f-1 [
]
w
g0 (xι )-b ].
W 」
If the decomposition can be found, this will require H(x, w, b) to exclude w in its expression, so
there should be
∂H(x, w, b)
-∂w- = 0.
Again denote A(x, w, b) = f T [g (W)-b]. Then we have
∂H(x,w, b) =	1	{-A(xι,w,b)[g0(x2) — b] + A(x2,w, b)[g0(xι) — b])= 0
∂b	A(x2,w,b)2	w2f0[A(x2, w, b)]	w2f 0[A(xι, w, b)]
This lead to
w
w
A(xι,w,b) ∙ f0[A(xι,w,b)] ∙
g0(x1) - b
=A(x2,w,b) ∙ f0[A(x2,w,b)] ∙
g0(x2) - b.
This holds for any x1 , x2, so both the left and right side should be a constant. Denote this constant
as a, then
A(x, w, b) ∙ f 0[A(x, w, b)] ∙
w
-7~x----= a.
g0(x) — b
For simplicity, denote A(x, w, b) as t, then g (W-b = f (t), and
t ∙ f 0(t) ∙ —ɪ- = a.
f ( ) f(t)
We get f (x) = d ∙ Xa by solving this differentiable equation, where a, d can be any constant.
20