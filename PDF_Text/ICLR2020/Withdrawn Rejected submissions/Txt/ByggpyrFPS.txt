Under review as a conference paper at ICLR 2020
Bayesian Variational Autoencoders for
Unsupervised Out-of-Distribution Detection
Anonymous authors
Paper under double-blind review
Ab stract
Despite their successes, deep neural networks still make unreliable predictions
when faced with test data drawn from a distribution different to that of the train-
ing data, constituting a major problem for AI safety. While this motivated a recent
surge in interest in developing methods to detect such out-of-distribution (OoD)
inputs, a robust solution is still lacking. We propose a new probabilistic, unsu-
pervised approach to this problem based on a Bayesian variational autoencoder
model, which estimates a full posterior distribution over the decoder parameters
using stochastic gradient Markov chain Monte Carlo, instead of fitting a point es-
timate. We describe how information-theoretic measures based on this posterior
can then be used to detect OoD data both in input space as well as in the model’s
latent space. The effectiveness of our approach is empirically demonstrated.
1	Introduction
Outlier detection in input space. While deep neural networks (DNNs) have successfully tackled
complex real-world problems in various domains including vision, speech and language (Schmid-
huber, 2015; LeCun et al., 2015; Goodfellow et al., 2016), they still face significant limitations that
make them unfit for safety-critical applications (Amodei et al., 2016). One well-known shortcoming
of DNNs is that when faced with test data points coming from a different distribution than the data
the network was exposed to during training, the DNN will not only output wrong predictions, but it
will do so with high confidence. The lack of robustness of DNNs to such out-of-distribution (OoD)
inputs (or outliers/anomalies) was recently addressed by the development of various methods to
detect OoD inputs. Most existing OoD detection approaches are task-specific in that they consider
a certain prediction task (typically classification) and use the corresponding output labels for the
supervised training of a deep discriminative model to produce the desired target output as well as
some confidence score (Hendrycks & Gimpel, 2016; Hendrycks et al., 2018; Liang et al., 2017).
Alternatively, task-agnostic OoD detection methods solely use the input data for the unsupervised
training of a deep generative model (DGM). One simple and seemingly sensible approach to detect
a potential OoD input x* is to train a likelihood-based DGM (e.g. a vAe, auto-regressive DGM, or
flow-based DGM) by (approximately) maximizing the likelihood p(D∣θ) of the model parameters θ
under the training data D, and to then estimate the probability p(x*∣θ) that x* was generated by the
model θ (Bishop, 1994): If p(x*∣θ) is large, then x* must be in-distribution, and OoD otherwise.
However, recent works have shown that this likelihood-based approach does not work in general, as
deep generative models sometimes assign higher probability to OoD data than to in-distribution data
(Nalisnick et al., 2018; Choi & Jang, 2018). Motivated by this finding, recent works have tried to
develop more effective scores by correcting the likelihood estimate (Choi & Jang, 2018; Ren et al.,
2019; Nalisnick et al., 2019). However, while these approaches improve upon the likelihood score,
we argue that OoD detection scores which are fundamentally based on the likelihood values are not
robust, as the likelihood estimates produced by commonly used DGMs are not reliable for OoD data,
similar to how deep discriminative models produce unreliable output predictions on OoD data.
Outlier detection in latent space. In a distinct line of research, recent works have tackled the
challenge of efficiently optimizing a complex black-box function f : X → R, f(x) = y defined
over high-dimensional, richly structured input domains X (e.g. graphs, images or text). Given
examples D = {(xi, yi)}iN=1, these methods jointly train a VAE on inputs x and a predictive model
g : Z → R, g(z) = y mapping from latent codes z to targets y, to then perform the optimization
1
Under review as a conference paper at ICLR 2020
w.r.t. y in the low-dimensional, continuous latent space Z instead of in input space X (Gomez-
Bombarelli et al., 2018). While these approaches have achieved state-of-the-art results in important
domains including automatic chemical design and automatic machine learning (Gomez-Bombarelli
et al., 2018; Luo et al., 2018; Lu et al., 2018), their practical effectiveness is limited by their ability to
handle the following trade-off: They need to find inputs x that both have a high target value y and are
sufficiently novel (i.e., not too close to inputs in the training data D), while at the same time ensuring
that the optimization w.r.t. y does not progress into regions of the latent space Z too far away from
the training data, which might yield latent points z that decode to semantically meaningless and/or
syntactically invalid inputs X (Kusner et al., 2017; Griffiths & Hernandez-Lobato, 2017; Brookes
et al., 2019; Mahmood & Hernandez-Lobato, 2019; Alperstein et al., 2019). We observe that the
required ability to quantify the semantic/syntactic distance of latent codes z to the training data
directly corresponds to the ability to detect outliers in latent space Z.
Our approach. In this work, we propose a principled, unsupervised, probabilistic method to si-
multaneously tackle the challenge of detecting outliers x* in input space X (without directly relying
on likelihood estimates) as well as outliers z* in latent space Z. To this end, we take an information-
theoretic perspective on OoD detection, and propose to use the (expected) informativeness of an in-
put x* / latent z* as a proxy for whether x* / z* is OoD or not. To quantify this informativeness, we
take inspiration from information-theoretic active learning (MacKay, 1992) and leverage probabilis-
tic inference techniques to maintain a posterior distribution over the parameters ofa deep generative
model, in particular of a variational autoencoder (VAE) (Kingma & Welling, 2013; Rezende et al.,
2014). This results in a Bayesian VAE (BVAE) model, where instead of fitting a point estimate of
the decoder parameters via maximum likelihood, we estimate their posterior distribution using sam-
ples generated via stochastic gradient Markov chain Monte Carlo (MCMC). The informativeness
of an unobserved input x* / latent z* is then quantified by measuring the (expected) change in the
posterior over model parameters after having observed x* / z*. In summary, our contributions are
as follows: (a) We propose a Bayesian VAE model which uses state-of-the-art Bayesian inference
techniques to estimate a posterior distribution over the decoder parameters (Section 3.2). (b) We
describe how this model can be used to detect outliers both in input space (Section 3.3) as well as
in the model’s latent space (Section 3.4) using information-theoretic metrics. (c) We empirically
demonstrate that our approach outperforms state-of-the-art outlier detection methods (Section 5).
2	Background
2.1	Variational Autoencoders
Consider a latent-variable modelp(x, z∣θ) with marginal likelihoodp(x∣θ) = Jp(x, z∣θ)dz, where
x are observed variables, z are local latent variables (i.e., individually tied to some x), and θ are
global latent variables (i.e., shared among all x).1 For clarity, we will mostly refer to z simply as la-
tent variables (i.e., without the prefix local), and to θ as model/decoder parameters. We assume that
p(x, z∣θ) = p(x∣z, θ)p(z), i.e., the joint density p(x, z∣θ) factorizes into a prior distribution p(z)
on the local latent variables z and a parameterized likelihood p(x|z, θ) of the observed variables x
given z. We furthermore assume the Z to be continuous, such that computing p(x∣θ) in generally
intractable. Such a model is called a variational autoencoder (VAE) (Kingma & Welling, 2013;
Rezende et al., 2014) if θ are the parameters of a deep neural network, and the corresponding in-
tractable posterior distribution p(z|x, θ) over the latent variables z is approximated using amortized
variational inference via another deep neural network q(z|x, φ) parameterized by φ (typically called
the encoder, inference network or recognition network). Given some dataset D = {xi}iN=1 of N
input vectors xi ∈ X drawn i.i.d. from some underlying data distribution p* (x), the parameters θ
and φ of a VAE are then learned by maximizing the evidence lower bound (ELBO) Lθ,φ, which is a
lower bound to the marginal log-likelihood logp(x∣θ), i.e.,
Lθ,φ(x) = Eq(z∣χ,Φ)[logp(x∣z,θ)] - DκL(q(z∣x,Φ)kp(z)) ≤ logp(x∣θ)	(1)
for some input x ∈ D. By independence, Lθ,φ(D) = Px∈D Lθ,φ(x). Since maximizing the ELBO
approximately maximizes logp(D∣θ), this training procedure can be viewed as approximate max-
1 Note that most literature on VAEs includes the parameters θ as a subscript, e.g., pθ (x, z), assuming a fixed
point estimate Θmle of θ, i.e., pθmle (x, Z) = p(x, z∣θ = Θmle). We instead use the notation p(x, z∣θ) to make
explicit that we assume θ to be a random variable governed by some distribution (to be detailed in Section 3).
2
Under review as a conference paper at ICLR 2020
imum likelihood estimation (MLE). In practice, Lθ,φ(x) in Eq. (1) is maximized by mini-batch
stochastic gradient-based optimization using low-variance, unbiased, stochastic Monte Carlo esti-
mators of VLθ,φ obtained via the reparametrization trick. Finally, one can approximate the prob-
ability p(x∣θ, φ) of a data point X under the generative model via importance sampling w.r.t. the
variational posterior q(z|x, φ), i.e.,
/	—	∣"p(x∣z, θ)p(z)[	1 S p(x∣Zk,θ)p(zk)
p(xlθ, φ) = Eq(ZlχM [ q(z∣x,φ) J ' K∑^ q(Zk ∣x,φ)	, zk 〜q(zlx,φ) .	⑵
Note that the likelihood p(x∣θ, φ) in Eq. (2) is conditioned on both θ and φ, to make explicit the
dependence on the parameters φ of the proposal distribution q(z|x, φ).
2.2	Bayesian Learning in Neural Networks via Stochastic Gradient MCMC
To generate samples θ 〜p(θ∣D) of parameters θ of a deep neural network, one can use state-of-
the-art stochastic gradient Markov chain Monte Carlo methods such as stochastic gradient Hamil-
tonian Monte Carlo (SGHMC). Hamiltonian Monte Carlo (HMC) (Duane et al., 1987; Betancourt,
2017) is a method for generating samples θ 〜p(θ∣D) in a Metropolis-Hastings framework that
efficiently explores the state space. In particular, consider the posterior distribution p(θ∣D) a
exp(-U(θ, D)) with potential energy function U(θ, D) = 一 logp(D,θ) = 一 log(p(D∣θ)p(θ))=
一 Px∈d logp(x∣θ) - logp(θ) induced by the prior p(θ) and marginal log-likelihood logp(x∣θ).
HMC generates samples θ 〜p(θ∣D) by simulating Hamiltonian dynamics, which involves evaluat-
ing the gradient VθU(θ) of U. However, direct computation of this gradient requires examination
of the entire dataset D (due to the summation of the log-likelihood over all x ∈ D), which might
become prohibitively costly for large datasets. To tackle this issue, Chen et al. (2014) recently
proposed a scalable HMC variant called stochastic gradient Hamiltonian Monte Carlo (SGHMC),
which considers a noisy, unbiased estimate of the gradient computed from a minibatch M of points
sampled uniformly at random from D (i.e., akin to minibatch-based optimization algorithms such as
variants of stochastic gradient descent), i.e.,
VθU(θ, D) ` VθU(θ,M) = - ∣M∣ Px∈m Vθ logp(x∣θ) - Vθ logp(θ).	⑶
3	Bayesian Variational Autoencoders for OoD Detection
3.1	Motivation and Intuition
We take the following information-theoretic perspective on OoD detection. Consider an active learn-
ing scenario, where we have computed an estimate of our model parameters θ based on some ob-
servations D, and want to add an unobserved input x* to the training set D to improve our estimate
of θ as much as possible. To this end, in information-theoretic active learning (MacKay, 1992), it
is observed that every potential input x* contains a certain amount of information about the values
of the model parameters. In other words, every data point x* helps us to some extent in updating
our model parameters to find the optimal ones which capture the true underlying data-generating
process. Now, we argue that inputs which are uninformative about the model parameters are likely
similar to the data points already in the training set D, i.e., they are likely in-distribution inputs.
In contrast, inputs which are very informative about the model parameters are likely different from
everything we have seen so far in the training data D, i.e., they are likely OoD inputs. We thus
propose to use the informativeness of a datum x* as a proxy for whether x* is OoD or not. To
quantify this informativeness, information-theoretic active learning approaches leverage probabilis-
tic inference techniques to maintain a posterior distribution p(θ∣D) over model parameters θ given
data D (i.e., instead of fitting a point estimate of θ via maximum likelihood estimation). Given this
posterior p(θ∣D), the informativeness of an unobserved datum x* is then quantified by measuring
the (expected) change in the posterior after having observed x*, i.e., the change required to update
p(θ∣D) to the posterior p(θ∣D ∪ {x*}). We follow this approach and propose to use a Bayesian VAE
(BVAE) model, where instead of fitting a point estimate of the parameters via maximum likelihood,
we estimate their posterior distribution using samples generated via stochastic gradient MCMC.
3
Under review as a conference paper at ICLR 2020
3.2	THE BAYESIAN VAE (BVAE)
In contrast to an ordinary VAE, where we fit the generative model parameters θ via (approximate)
MLE, i.e., θMLE = arg maxθ L(D)θ,φ, to obtain the likelihood p(x|z, θMLE), we place a prior p(θ)
over θ and estimate its full posterior distribution p(θ∣D) 8 p(D∣θ)p(θ), to induce the generator like-
lihood p(x∣z, D) = Rp(x∣z, θ)p(θ∣D)dθ = Ep(θ∣D)[p(x∣z, θ)]. ThiS induces the marginal likelihood
p(x∣D) = Ep(z)[p(x|z, D)] = RRp(x∣z,θ)p(θ∣D)p(z)dθdz = Ep(θ∣D) [p(x∣θ)]	(4)
which marginalizes over both the local latent variables z and the global latent variables θ. The
generative process defined in Eq. (4) first draws a latent vector Z 〜p(z) from its prior and a decoder
parameterization θ 〜p(θ∣D) from its posterior, and then generates X 〜p(x∣z, θ) by passing both
through the likelihood. Training this model now involves performing Bayesian inference over both
Z and θ, resulting in the posterior p(z∣x, D) over Z and the posterior p(θ∣D) H p(D∣θ)p(θ) over
θ . Since both posteriors are intractable for the model we consider, we will now discuss how to
approximate inference over z and θ, respectively.
3.2.1	INFERENCE OVER THE LATENT VARIABLES z
To estimate the posterior p(z|x, D) over z, we follow an ordinary VAE and resort to amortized
variational inference via a recognition network q(z|x, φ) with variational parameters φ, using the
ELBO Lθ,φ(x) ≤ logp(x∣θ) in Eq. (1). We learn the encoder parameters φ via approximate MLE,
using a low-variance, unbiased Monte Carlo estimator of the stochastic gradient VφLθ,φ(x), i.e.,
VφLθ,φ(x) ` L P= Vφ log[p(x∣zι,θ)] - VφDκL(q(z∣x, φ)kp(z)),	Zl 〜q(z∣x, φ)	(5)
where the posterior samples zl 〜q(z∣x, φ) are generated using the reparametrization trick.
3.2.2	INFERENCE OVER THE MODEL PARAMETERS θ
To generate posterior samples θ 〜p(θ∣D) of decoder parameters (e.g. as required to approximate
the gradient VφLφ(x) in Eq. (5)), we propose to use SGHMC (cf. Section 2). However, the gra-
dient of the energy function VθU(θ, M) in Eq. (3) used for simulating the Hamiltonian dynamics
requires us to evaluate the log-likelihood logp(x∣θ), which is intractable in a VAE and thus also
in our model. To alleviate this issue, we approximate the log-likelihood appearing in VθU(θ, M)
by the ELBO Lθ,φ(x) of an ordinary VAE in Eq. (1). Given a set Θ = {θm}mM=1 of posterior
samples θm 〜p(θ∣D), We can more intuitively think of working with a finite mixture/ensemble of
decoders/generative models p(x∣z, D) = Ep(θ∣D) [p(x∣z, θ)] ` 吉 Pθ∈θ p(x∣z, θ) (cf. Eq. (4)).
3.2.3	INFERENCE OVER THE VARIATIONAL PARAMETERS φ
Recall that the goal of amortized variational inference is to learn how to do posterior inference,
by finding the optimal parameters φMLE = arg maxφ L(D)θ,φ (cf. Eq. (1)) of an inference net-
work i : X → Ψ : iφ(x) = ψ mapping inputs x to parameters ψ of the variational posterior
qψ (z) = q(z|x, φ) over z. However, one fundamental shortcoming of fitting an inference network
via MLE is that the model q(z|x, φMLE) will not generalize to OoD inputs, but instead produce con-
fidently wrong posterior inferences for OoD inputs. To alleviate this issue, we refrain from fitting
a point estimate φMLE, and instead consider a Bayesian treatment of the variational parameters φ
(i.e., in addition to the Bayesian treatment of the decoder parameters θ discussed earlier). While this
might seem strange conceptually, it allows us to quantify our epistemic uncertainty in the amortized
inference of z, intuitively increasing the flexibility of the recognition network. We thus also place a
prior p(φ) over φ and infer the posterior p(φ∣D) h p(D∣φ)p(φ), yielding the amortized posterior
q(z∣x, D) = R q(z∣x, φ)p(φ∣D)dφ = Ep(φ∣D) [q(z∣x, φ)]′吉 PM=I q(z∣x, φj), φj 〜p(φ∣D) . (6)
We also use SGHMC to generate the posterior samples φj 〜p(φ∣D), again approximating the log-
likelihood logp(x∣φ, D) in VφU(φ, M) (cf. Eq. (3)) by the ELbO Lθ,φ(x) in Eq. (1). Given a set
Φ = {φj}M=ι of posterior samples φj 〜p(φ∣D), we can again more intuitively think of Eq. (6) as
defining a finite mixture/ensemble of inference networks q(z|x, D) ' -MM Pφ∈Φ q(Z|x, φ).
4
Under review as a conference paper at ICLR 2020
Inference over θ revisited. When doing inference over both φ and θ, we need to slightly adapt the
SGHMC sampling procedure for the decoder parameters θ 〜p(θ∣D) described in Section 3.2.2. In
particular, instead of using the ELBO Lθ,φ(x) ofan ordinary VAE in Eq. (1) (which is based on the
recognition network q(z|x, φ) and thus depends on both θ and φ), we now need to use the ELBO
Lθ (X) = Eq(z∣x,D)[log p(x∣z,θ)]- DκL(q(z∣x, D)kp(z)) ≤ log p(x∣θ, D)	(7)
which depends on θ only, as itis based on the encoder mixture q(z|x, D) in Eq. (6) and thus integrates
the variational parameters φ over their posterior p(φ∣D). We then obtain an approximation to the
stochastic gradient VθU(θ, M) in Eq. (3) by using a Monte Carlo approximation of the gradient
VθLθ (x) of the ELBO in Eq. (7), i.e.,
NBLf)(x) = Eq(z∣x,D)[Vθ logp(x∣z, θ)] ` L PL=1 Vθ logp(x∣zι,θ),	Zl 〜q(z∣x, D) .	(8)
The Zl 〜q(z∣x, D) are sampled from the encoder mixture in Eq. (6) by first sampling the index of
the mixture component uniformly at random, i.e., j 〜U [1, M] (due to the mixture weights all being
1/M), and then sampling the latent vector ZI from the j-th mixture component, i.e., ZI 〜q(z∣x, φj).
3.3 Detecting Outliers in Input Space
Training a BVAE (see Appendix B for pseudocode) yields the sets Φ = {φj}jM=1 and Θ = {θm}mM=1
of posterior samples φj 〜 p(φ∣D) and θm 〜 p(θ∣D) of encoder and decoder parameters, respec-
tively. Given these samples, we follow ideas from information-theoretic active learning (MacKay,
1992) (cf. Section 1) and aim to detect if a certain test input x* is OoD based on its informativeness
about the model parameters θ, as measured by the change in the posterior distribution over θ after
having observed x* . In particular, assume that given some data D and prior p(θ), we have inferred
the posterior p(θ∣D) = RpD||f)p(f)df = PpDDf)p(θ) over θ. In a sequential Bayesian setting, the
posterior p(θ∣D) then serves as the new prior, which, given a new observation x*, is updated to
the posterior oθΘ∣D ∪{x*})	=	—P(X_|f)p(f|D)—	=	P(X_If) (θθ∣D)	ie by multinlvins? n(Θ∣D)	bv
IhePOSteriOr P(OID ∪ {x })	=	Rp(χ*∣f)p(f∣D)dθ	=	p(χ*∣D)p(°|D),	i∙e∙, by multiplying P(OID)	by
the normalized likelihood p(X* |D). The intuition now is as follows: If x* is very different from the
previous observations in D, then the updated posterior P(θID ∪ {x*}) will likely be different from
P(θID), to capture the atypicality of x*. In contrast, if x* is very similar to the observations in D,
then the posterior P(θID ∪ {x*}) will also be similar to the previous one P(θID). Thus, to detect
whether x* is OoD or not, we aim to quantify the change from P(θID) to P(θID ∪ {x*}), which is
captured by the factor p(χ* ||D). Since in our case, the posterior p(θ∣D) is represented by the finite set
of samples Θ, we find ourselves in a sequential Monte Carlo (or particle filtering) setting, such that
for a given parameter/particle θ and input x*, the normalized likelihood P(X*∣D)) can be written as
P(X*lθ) =)	P(X*lθ)	〜	P(X*lθ)	= Mw With W =	P(X*lθ)
p(x*|D)	/6他)旧①*怛)]—吉 pf∈θP(x*∣θ)	θ,	θ Pf∈θP(X*lθ)
(9)
where wf ∈ [0, 1] and f∈Θ wf = 1. The scalar wf defined in Eq. (9) can be interpreted as the
probability that x* was generated from the particle θ, thus measuring how well x* is explained by
the model θ (and thus how useful θ is for describing the updatedposteriorP(θID∪{x*})), relative to
the other particles. More formally, the values [wf]f∈Θ correspond to the importance weights of the
samples/particles θ ∈ Θ drawn from the proposal distribution P(θID) (i.e., the previous posterior)
for an importance sampling-based Monte Carlo approximation of an expectation w.r.t. the target
distribution P(θID ∪ {x*}) (i.e., the updated posterior after having observed x*), i.e.,
(9)
Ep(θ∣D∪{x*})[f (θ)] ' Ep(θ∣D) [Mwf f(θ)]'焉 Pθ∈θ Mwf f(θ) = Pθ∈θ Wf f(θ)	(10)
for some function f : Θ → R. To measure the change in distribution fromP(θID) to P(θID ∪ {x*}),
we can then use the weights [wf]f∈Θ to compute the effective sample size (ESS)
ESSθ(x*) = L 1	2 (=) (pf∈θP(X[θ)] , suchthat ESSθ(x*) ∈ [1,M] .	(11)
f∈Θ wf2	f∈Θ P(x*Iθ)2
The ESS(x*) is a widely used measure for the efficiency of the estimator in Eq. (10), and measures
how many i.i.d. samples drawn from the target posteriorP(θID∪ {x*}) are equivalent to the M sam-
ples θ ∈ Θ drawn from the proposal posterior P(θID) and weighted according to wf. It intuitively
5
Under review as a conference paper at ICLR 2020
quantifies the degree of agreement between the particles θ ∈ Θ as to how probable the input x* is,
inducing the following decision rule: IfESS(X*) is large, then [wθ]θ∈θ is close to the uniform dis-
tribution [M]θ∈θ (for which ESS(x*) = M), meaning that all particles θ ∈ Θ explain x* equally
well and are in agreement as to how probable x* is. Thus, x* likely is an in-distribution input.
Conversely, if ESS(x*) is small, then [wθ]θ∈Θ contains a few large weights (i.e., corresponding to
particles that by chance happen to explain the datum well), with all other weights being very small,
where in the extreme case, [wθ]θ∈Θ = [0, . . . , 0, 1, 0, . . . , 0] (for which ESS(x*) = 1). This means
that the particles do not agree as to how probable x* is, so that x* likely is an OoD input.
Finally, we discuss how to compute the likelihood p(x∣θ) of the BVAE given an input X required
to compute the weight wθ in Eq. (9). We consider two approaches based on importance sampling,
with different proposal distributions for sampling the latent codes zk depending on the assumed
relationship between the samples Θ of decoder parameters and the samples Φ of encoder parameters:
1.	Firstly, one may treat the samples in Θ and Φ as being coupled as (θm, φm) ∈ {(θm, φm)}mM=1,
where each pair (θm , φm) effectively defines a separate VAE. This is motivated by the fact that
in practice, we for simplicity do indeed take samples of full VAEs, by simultaneously sampling
fromp(θ∣D) andp(φ∣D), as outlined in Algorithm 1 in Appendix B. Since such a coupled sample
(θm , φm ) defines a VAE, the likelihood can then simply be computed as in a regular VAE, i.e.,
p(x∣θm) = p(x∣θm, φm) as defined in Eq.(2), using the proposal distribution q(z∣x, φm).
2.	Secondly, one may decouple the samples in Θ and Φ and treat them as being independent of each
other. In particular, for a given decoder sample θm, instead of using the corresponding sample
φm as the encoder, we may view the encoder as the mixture q(z|x, D) ' mM Pφ∈Φ q(Zk|x, φ)in
Eq. (6) defined by all samples in Φ. The likelihood is then estimated as p(x∣θ) = p(x∣θ, D) with
θ ∣θ Dx	E	Ip(Xlz,θ)p(Z)]⑹1 XX	P(XIZk,θ)p(Zk)	D . D
p(	xlθ, D) = Eq(Zlx,D)[ q(z∣x, D) J ' K k=1 焉 Pφ∈φ q(zk Ix,φ), Zk ~q(z|x'D) (12)
where the proposal distribution now is the mixture q(Z|x, D) instead of q(Z|x, φ). Since
q(Z|x, D) marginalizes over encoder parameters φ, the likelihood in Eq. (12) only depends on θ.
3.4 Detecting Outliers in Latent Space
Detecting outliers in latent space involves identifying latent vectors Z* which are very different from
the latent vectors corresponding to the training inputs D, and which will thus yield unpredictable
results when passed through the decoder to produce p(x|Z*, θ). To discriminate if a given latent
vector Z* is an outlier or not, we follow the same approach as in Section 3.3 and quantify the
informativeness of z* on the model parameters θ by measuring the change in the posterior p(θ∣D).
However, quantifying this change in posterior by e.g. computing the ESS metric in Eq. (11) requires
evaluating the likelihood p(x* ∣θ) of the input x* corresponding to the latent code z*, which is
not available to us. We thus alternatively quantify the expected change in the posterior p(θ∣D) by
computing the expected ESS, by averaging over the likelihood mixturep(x∣z*, D) (cf. Section 3.2),
thus effectively taking into account all possible inputs x* corresponding to z*, i.e.,
ESSθ(z*) = Ep(χ∣z*,D) [ESSθ(x)] (') ɪ X (pθ∈θp(xn∣z*,θ)2 ,	Xn 〜p(x∣z*, D) (13)
N n=1	θ∈Θ p(xn∣z*, θ)2
where the inputs xn are sampled from the decoder mixture p(x∣z*, D) by first sampling the index
of the mixture component uniformly at random, i.e., m 〜U [1, M] (due to the mixture weights
all being 1/M), and then sampling Xn from the m-th mixture component, i.e., Xn 〜p(x∣z*,θm).
In contrast to computing the ESS in Eq. (11) for outlier detection in input space, where we had
to estimate the likelihoods via importance sampling using the (mixture of) inference network(s),
computing the likelihoods p(xn∣z*, θ) in Eq. (13) simply involves passing the given latent code z*
through the decoders parameterized by θ ∈ Θ. In fact, the encoding part of the model is not required
for outlier detection in latent space. If we are only interested in outlier detection in latent space, we
thus do not face any of the issues arising from the recognition network making wrong inferences for
OoD inputs, and as a result do not require a Bayesian treatment of the encoder parameters φ.
6
Under review as a conference paper at ICLR 2020
4	Related Work
Supervised/Discriminative outlier detection methods Most existing OoD detection approaches
are task-specific and designed for the context of a certain prediction task. As described in Section 1,
these approaches train a deep discriminative model in a supervised fashion using the given labels.
To detect outliers w.r.t. the target task, many approaches then rely on a confidence score to decide
on the reliability of the prediction, which is either produced by modifying the model and/or training
procedure, or computed/extracted post-hoc from the model and/or predictions (DeVries & Taylor,
2018; An & Cho, 2015; Solch et al., 2016; Ahmed & Courville, 2019; Sricharan & Srivastava,
2018; Hendrycks & Gimpel, 2016; Hendrycks et al., 2018; Liang et al., 2017; Shafaei et al., 2018).
Alternatively, one can use predictive uncertainty estimates for OoD detection (Malinin & Gales,
2018; Gal & Ghahramani, 2016; Lakshminarayanan et al., 2017; Osawa et al., 2019; Ovadia et al.,
2019). One drawback of such task-specific approaches is that discriminatively trained models by
design discard all input features which are not informative about the specific prediction task, such
that information which is relevant for OoD detection might be lost.
Unsupervised/Generative outlier detection methods In contrast, task-agnostic OoD detection
methods solely use the input data for the unsupervised training of a deep generative model, which
makes them more general, as they do not require the availability of labels for some prediction task.
Moreover, these approaches capture the entire input data distribution via the generative model, which
might be beneficial for OoD detection (it was shown that despite not exploiting label information,
unsupervised approaches often work better in practice (Ren et al., 2019)). Perhaps closest to our
approach is the recent work by Choi & Jang (2018), which use an ensemble (Lakshminarayanan
et al., 2017) of independently trained likelihood-based generative models (i.e., with random pa-
rameter initializations and random data shuffling) to approximate the Watanabe-Akaike Information
Criterion (Watanabe, 2010) Ep(θ∣D)[logp(x*∣θ)] - Varp(θ∣D)[logp(x*∣θ)]. The WAIC provides an
asymptotically correct estimate between the training and test set expectations (assuming a fixed un-
derlying data distribution) and can be viewed as a corrected log-likelihood score which penalizes
points x with a large variance in log-likelihoods. Their approach has two shortcomings as com-
pared to ours: Firstly, while we use stochastic gradient MCMC on a single model to obtain M
approximate posterior samples, they train M independent models to form an ensemble, which (a) is
not a principled way of doing approximate Bayesian inference (although connections can be made
(Mandt et al., 2017) under certain conditions), and (b) is M times more computationally expen-
sive in practice. Secondly, independent of the quality of the posterior approximation, their score
is not expected to work well, since it still relies on the suboptimal log-likelihood estimates (as we
will demonstrate in the experiments). Another recent unsupervised approach is the likelihood ra-
tio method by Ren et al. (2019), which corrects the likelihood logp(x*∣θ) for confounding general
population level background statistics captured by a background model p(x*∣θ0), resulting in the
score log p(x*∣θ) - log p(x*∣θo). The background model p(x*∣θo) is in practice trained by perturb-
ing the data D with noise to corrupt its semantic structure, i.e., by sampling input dimensions i.i.d.
from a Bernoulli distribution with rate μ ∈ [0.1,0.2] and replacing their values by uniform noise,
e.g. Xi 〜U{0,..., 255} for images. Finally, Nalisnick et al. (2019) proposed to use the score
I log p(x*∣θ) - N Pχ∈D log p(x∣θ) I to account for the typicality of the input x*.
5	Experiments
We now present some experimental results showing the competitiveness of our approach.
5.1	Out-of-distribution detection in input space
BVAE details. We implemented the proposed BVAE model in PyTorch (see Appendix B for
pseudocode), using the robust, scale adapted SGHMC variant proposed by Springenberg et al.
(2016)2. We follow Chen et al. (2014); Springenberg et al. (2016) and use Gaussian priors over
θ and φ, i.e., p(θ) = N(0, λθ-1) and p(φ) = N (0, λφ-1). We also place Gamma hyperpriors
over the precision parameters λθ and λφ, i.e., p(λθ) = Γ(αθ, βθ) and p(λφ) = Γ(αφ, βφ), with
2We use their implementation of the SGHMC sampler as a PyTorch Optimizer (https://
github.com/automl/pybnn), thus serving as a drop-in replacement for an optimizer such as SGD.
7
Under review as a conference paper at ICLR 2020
αθ = βθ = αφ = βφ = 1, and resample λθ and λφ after every training epoch (i.e., after an entire
pass over D). We also follow the previous work and use a step size of 10-3 and momentum decay of
0.05 for SGHMC. We discard samples within a burn-in phase of B = 1 epoch, and store a sample
(of both encoder and decoder parameters) after every D = 1 epoch. We only keep the 10 most recent
samples to represent the posterior. In addition to the BVAE described in Section 3.2 which uses the
two ELBOs Lθ,φ in Eq. (1) and Lθ in Eq. (7) to train/sample from φ and θ, respectively (denoted by
BVAE), we also report results on the following variants: a BVAE that uses the ordinary VAE ELBO
in Eq. (1) for both φ and θ (B^VAE; see Appendix C for pseudocode) and a VAE where only θ is
integrated out and φ is estimated via maximum likelihood (BVAEθ). We furthermore consider both
alternative ways of estimating the log-likelihoods for computing the ESS (cf. Section 3.3), i.e., the
case where log-likelihoods are computed using samples Φ of encoders and Θ of decoders that are
treated as independent (ESS), and the case where the log-likelihoods are computed using coupled
samples {(φj, θj)}jM=1 (ESSθφ).
Experimental setup. We use two benchmarks: (a) FashionMNIST (in-distribution) vs. MNIST
(OoD) (Hendrycks et al., 2018; Nalisnick et al., 2018; Ren et al., 2019; Zenati et al., 2018; Akcay
et al., 2018), and (b) eight classes of FashionMNIST (in-distribution) vs. the remaining two classes
(OoD), using five different splits {(0, 1), (2, 3), (4, 5), (6, 7), (8, 9)} of held-out classes (Ahmed &
Courville, 2019). We compare against the log-likelihood (LL) as well as three state-of-the-art meth-
ods for unsupervised OoD detection (all described in Section 4): (1) The generative ensemble based
method by Choi & Jang (2018) composed of five independently trained models (WAIC), (2) the
likelihood ratio method by Ren et al.(2019) (LLR), using Bernoulli rates μ = 0.2 for the Fashion-
MNIST vs. MNIST experiment (Ren et al., 2019), and μ = 0.15 for the other experiment, and (3)
the test for typicality by Nalisnick et al. (2019) (TT). All methods use VAEs for the log-likelihood
estimation.3 They are evaluated by randomly selecting 5000 in-distribution and OoD inputs from
held-out test sets and computing the following threshold independent metrics (Hendrycks & Gimpel,
2016; Liang et al., 2017; Hendrycks et al., 2018; Alemi et al., 2018; Ren et al., 2019): (i) The area
under the ROC curve (AUROC↑), (ii) the area under the precision-recall curve (AUPRC↑), and (iii)
the false-positive rate at 80% true-positive rate (FPR80J).
Results. Table 1 shows that our approaches generally perform better on the considered bench-
marks. Coupling the encoder and decoder samples appears beneficial, which might be due to the
fact that we actually take the samples in couples after every epoch. Being Bayesian about the en-
coder parameters φ also seems to help. Fig. 2 show the precision-recall and ROC curves used to
compute the metrics, for the FashionMNIST vs. MNIST experiment (see Appendix E for the curves
for the other experiment). Fig. 1 shows histograms of the log-likelihoods (left) and of the BVAE-ESS
scores (right) on FashionMNIST in-distribution (blue) vs. MNIST OoD (orange) test data. While the
log-likelihoods strongly overlap, the ESS scores more clearly separate in-distribution data (closer to
ESS = 10 on the r.h.s.) from OoD data (closer to ESS = 1 on the l.h.s.).
5.2	Out-of-distribution detection in latent space
While input space OoD detection is a well-studied problem, OoD detection in latent space was
only recently identified as an important open problem (GOmez-BOmbarelli et al., 2018; Griffiths &
Hernandez-Lobato, 2017; Mahmood & Hernandez-Lobato, 2019; Alperstein et al., 2019) (see also
Section 1). Thus, there is a lack of suitable experimental benchmarks, making a quantitative evalua-
tion challenging. A major issue in designing toy benchmarks based on commonly-used datasets such
as MNIST or FashionMNIST (i.e., as typically used for assessing input space OoD detection) is that
it is not clear how to obtain ground truth labels for which latent points are OoD and which are not,
as We require OoD labels for all possible latent vectors Z ∈ Rd, notjust for those corresponding to
inputs x* from some training or test set. As a first step to facilitate a systematic empirical evaluation
of latent space OoD detection techniques, We propose the folloWing experimental protocol.
We use the BVAE variant Where only θ is integrated out and φ is estimated via maximum likelihood
(denoted by BVAEθ in Section 5.1, using the same prior and hyperprior as described there). We
3The architecture of the deconvolutional VAE We use and the training protocol folloWs previous Work (Nal-
isnick et al., 2018; Choi & Jang, 2018; Ren et al., 2019). We use the Adam optimizer (Kingma & Ba, 2014)
With learning rate 10-3 for all maximum likelihood fits of parameters.
8
Under review as a conference paper at ICLR 2020
Table 1: AUROC↑, AUPRC↑, and FPR80J scores (where higher ↑ or lower ] is better) of the
baselines (top) and our methods (bottom). For the experiment on FashionMNIST with with held-out
classes, We report the mean scores over all five class splits.
	FashionMNIST Vs MNIST			FashionMNIST (held-out)		
	AUROC↑	AUPRC↑	FPR801	AUROC↑	AUPRC↑	FPR80；
LL	0.557	0.564	0.703	0.565	0.577	0.683
WAIC	0.541	0.548	0.798	0.446	0.464	0.827
LLR	0.617	0.613	0.638	0.560	0.569	0.698
TT	0.482	0.502	0.833	0.482	0.496	0.806
BVAE-ESS	0.842	0.830	0.245	0.660	0.650	0.577
BVAE-ESSθφ	0.871	0.855	0.190	0.697	0.681	0.534
—■			 BVAE-ESS	0.897	0.893	0.149	0.672	0.659	0.562
B^VAE-ESSθφ	0.921	0.907	0.082	0.683	0.668	0.558
BVAEθ-ESS	0.904	0.891	0.117	0.693	0.680	0.540
Figure 1: Histograms of LL (left) and B^VAE-ESSθφ (right) on FashionMNIST (in-distribution) and
MNIST (out-of-distribution). The ESS score separates the data more clearly than the LL score.
Figure 2: (Left) Precision-recall curves (treating OoD data as the upper class) and (right) ROC
curves of all methods on the FashionMNIST vs. MNIST benchmark.
train this BVAE model on some dataset (we will use FashionMNIST here), and then sample N =
10000 latent test vectors Z from the Gaussian N(0, b ∙ Id) where b ∈ R+, following Mahmood &
Hernandez-Lobato (2019) (We use b = 10000). Since there does not exist a ground truth label for
whether a given latent point Z is OoD or not, we instead compute some OoD proxy score (to be
detailed below) for each of the N latent test vectors and then simply define the N/2 latents with the
lowest scores to be in-distribution, and the N/2 latents with the highest scores to be OoD.
9
Under review as a conference paper at ICLR 2020
For this OoD score, we propose to train an ensemble of J convolutional neural network clas-
sifiers with parameters W = {wj}jJ=1 on FashionMNIST (Lakshminarayanan et al., 2017).
We then approximate the mutual information score4 5 proposed by Houlsby et al. (2011), i.e.,
I(w,y∣x*,D) = H(p(y∣x*,D)) - Ep(w∣D)[H(p(y∣x*,w))], where Ep(w∣D)[H(p(y∣x*,w))] `
J Pw∈W H(p(y∣x*, W)) is the average entropy of the predictive class distribution of the clas-
sifier with parameters w, and H(p(y∣x*, D)) ` H (1 Pw∈wp(y∣x*, W)) is the entropy of the
mixture J Pw∈wp(y∣x*, w) of categorical distributions p(y∣x*, w) (which is again categorical
with averaged probits). Note that this score requires a test input x*. Since in our setting, we
only know the latent code z* corresponding to x*, we instead use the expected mutual informa-
tion under the mixture decoding distribution p(x|z*, D) defined by the decoder ensemble Θ, i.e.,
Ep(x∣z* ,D) [I(w,y∣x, D)] ′ N PN=1 I(w, y∣Xn, D) where Xn 〜p(x∣z*, D). In practice, we use an
ensemble of J = 5 classifiers and N = 32 input samples for the expectation.
We compare the expected ESS (see Section 3.4, with N = 32) against two baselines: (a) The
distance of z* ∈ Rd to the spherical annulus of radius √d — 1, since that is where most probability
mass lies under our prior N(0, Id) (Annulus) (Alperstein et al., 2019). (b) the log-probability of
z* under the training data distribution in latent space q(z)= 告 Px∈D q(z∣x, φ), i.e., a uniform
mixture of N Gaussians in our case (qz)5 (Mahmood & Hernandez-Lobato, 2019). Fig. 3 shows
that our proposed method significantly outperforms the two baselines on this benchmark task.
Figure 3: (Left) Precision-recall curves (treating OoD data as the upper class) and (right) ROC
curves of all methods on the FashionMNIST based latent space OoD detection benchmark.
6 Conclusion
We proposed a new approach to unsupervised out-of-distribution detection in input space as well
as in latent space, using information-theoretic metrics based on the approximated posterior over the
parameters of a variational autoencoder. For future work, we are keen to explore extensions of our
approach to (i) state-of-the-art VAE architectures (e.g., using more sophisticated posteriors (Rezende
& Mohamed, 2015), priors (Tomczak & Welling, 2017; Papamakarios et al., 2017; Bauer & Mnih,
2019), decoders, etc., which is all complementary); (ii) use alternative lower bounds to the marginal
log-likelihood, such as the importance weighted lower bound used in an IWAE (Burda et al., 2015),
or combinations of the VAE and IWAE lower bounds, as proposed in (Rainforth et al., 2018); (iii)
alternative approximate inference techniques for estimating the posterior distribution over model
parameters; (iv) other likelihood-based deep generative models (e.g., flow-based and auto-regressive
deep generative models); (v) exploit label information (e.g., by using a hybrid model combining our
BVAE with a predictive model, to enable semi-supervised OoD detection).
4This score is closely related to the disagreement score Pw∈w DKL(p(y∣x*, w)∣∣p(y∣x*, D)) proposed
by Lakshminarayanan et al. (2017) for ensemble-based OoD detection, which could be used alternatively.
5For efficiency, we only consider the 100 nearest neighbors (found by a 100-NN model) of a latent test point
z* for computing this log-probability (Mahmood & Hernandez-Lobato, 2019).
10
Under review as a conference paper at ICLR 2020
References
Faruk Ahmed and Aaron Courville. Detecting semantic anomalies. arXiv preprint
arXiv:1908.04388, 2019.
Samet Akcay, Amir Atapour-Abarghouei, and Toby P Breckon. Ganomaly: Semi-supervised
anomaly detection via adversarial training. In Asian Conference on Computer Vision, pp. 622-
637. Springer, 2018.
Alexander A Alemi, Ian Fischer, and Joshua V Dillon. Uncertainty in the variational information
bottleneck. arXiv preprint arXiv:1807.00906, 2018.
Zaccary Alperstein, Artem Cherkasov, and Jason Tyler Rolfe. All smiles variational autoencoder.
arXiv preprint arXiv:1905.13343, 2019.
Dario Amodei, Chris Olah, Jacob Steinhardt, Paul Christiano, John Schulman, and Dan Mane. Con-
crete problems in ai safety. arXiv preprint arXiv:1606.06565, 2016.
Jinwon An and Sungzoon Cho. Variational autoencoder based anomaly detection using reconstruc-
tion probability. Special Lecture on IE, 2(1), 2015.
Matthias Bauer and Andriy Mnih. Resampled priors for variational autoencoders. In The 22nd
International Conference on Artificial Intelligence and Statistics, pp. 66-75, 2019.
Michael Betancourt. A conceptual introduction to hamiltonian monte carlo. arXiv preprint
arXiv:1701.02434, 2017.
Christopher M Bishop. Novelty detection and neural network validation. IEE Proceedings-Vision,
Image and Signal processing, 141(4):217-222, 1994.
David H Brookes, Hahnbeom Park, and Jennifer Listgarten. Conditioning by adaptive sampling for
robust design. arXiv preprint arXiv:1901.10060, 2019.
Yuri Burda, Roger Grosse, and Ruslan Salakhutdinov. Importance weighted autoencoders. arXiv
preprint arXiv:1509.00519, 2015.
Tianqi Chen, Emily Fox, and Carlos Guestrin. Stochastic gradient hamiltonian monte carlo. In
International conference on machine learning, pp. 1683-1691, 2014.
Hyunsun Choi and Eric Jang. Generative ensembles for robust anomaly detection. arXiv preprint
arXiv:1810.01392, 2018.
Terrance DeVries and Graham W Taylor. Learning confidence for out-of-distribution detection in
neural networks. arXiv preprint arXiv:1802.04865, 2018.
Simon Duane, Anthony D Kennedy, Brian J Pendleton, and Duncan Roweth. Hybrid monte carlo.
Physics letters B, 195(2):216-222, 1987.
Yarin Gal and Zoubin Ghahramani. Dropout as a bayesian approximation: Representing model
uncertainty in deep learning. In international conference on machine learning, pp. 1050-1059,
2016.
Rafael Gomez-Bombarelli, Jennifer N Wei, David Duvenaud, Jose Miguel Hernandez-Lobato,
Benjamin Sanchez-Lengeling, Dennis Sheberla, Jorge Aguilera-Iparraguirre, Timothy D Hirzel,
Ryan P Adams, and Alan Aspuru-Guzik. Automatic chemical design using a data-driven contin-
uous representation of molecules. ACS central science, 4(2):268-276, 2018.
Ian Goodfellow, Yoshua Bengio, Aaron Courville, and Yoshua Bengio. Deep learning, volume 1.
MIT Press, 2016.
Ryan-Rhys Griffiths and Jose Miguel Hernandez-Lobato. Constrained bayesian optimization for
automatic chemical design. arXiv preprint arXiv:1709.05501, 2017.
Dan Hendrycks and Kevin Gimpel. A baseline for detecting misclassified and out-of-distribution
examples in neural networks. arXiv preprint arXiv:1610.02136, 2016.
11
Under review as a conference paper at ICLR 2020
Dan Hendrycks, Mantas Mazeika, and Thomas G Dietterich. Deep anomaly detection with outlier
exposure. arXiv preprint arXiv:1812.04606, 2018.
Neil Houlsby, Ferenc Huszar, ZoUbin Ghahramani, and Mate Lengyel. Bayesian active learning for
classification and preference learning. arXiv preprint arXiv:1112.5745, 2011.
Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint
arXiv:1412.6980, 2014.
Diederik P Kingma and Max Welling. Auto-encoding variational bayes. arXiv preprint
arXiv:1312.6114, 2013.
Matt J Kusner, Brooks Paige, and Jose Miguel Hernandez-Lobato. Grammar variational autoen-
coder. In Proceedings of the 34th International Conference on Machine Learning-Volume 70, pp.
1945-1954. JMLR. org, 2017.
Balaji Lakshminarayanan, Alexander Pritzel, and Charles Blundell. Simple and scalable predictive
uncertainty estimation using deep ensembles. In Advances in Neural Information Processing
Systems, pp. 6402-6413, 2017.
Yann LeCun, Yoshua Bengio, and Geoffrey Hinton. Deep learning. nature, 521(7553):436, 2015.
Shiyu Liang, Yixuan Li, and R Srikant. Enhancing the reliability of out-of-distribution image detec-
tion in neural networks. arXiv preprint arXiv:1706.02690, 2017.
Xiaoyu Lu, Javier Gonzalez, Zhenwen Dai, and Neil Lawrence. Structured variationally auto-
encoded optimization. In International Conference on Machine Learning, pp. 3273-3281, 2018.
Renqian Luo, Fei Tian, Tao Qin, Enhong Chen, and Tie-Yan Liu. Neural architecture optimization.
In Advances in Neural Information Processing Systems, pp. 7827-7838, 2018.
David JC MacKay. Information-based objective functions for active data selection. Neural compu-
tation, 4(4):590-604, 1992.
Omar Mahmood and JoSe Miguel Hernandez-Lobato. A cold approach to generating optimal sam-
ples. arXiv preprint arXiv:1905.09885, 2019.
Andrey Malinin and Mark Gales. Predictive uncertainty estimation via prior networks. In Advances
in Neural Information Processing Systems, pp. 7047-7058, 2018.
Stephan Mandt, Matthew D Hoffman, and David M Blei. Stochastic gradient descent as approximate
bayesian inference. The Journal of Machine Learning Research, 18(1):4873-4907, 2017.
Eric Nalisnick, Akihiro Matsukawa, Yee Whye Teh, Dilan Gorur, and Balaji Lakshminarayanan. Do
deep generative models know what they don’t know? arXiv preprint arXiv:1810.09136, 2018.
Eric Nalisnick, Akihiro Matsukawa, Yee Whye Teh, and Balaji Lakshminarayanan. Detecting
out-of-distribution inputs to deep generative models using a test for typicality. arXiv preprint
arXiv:1906.02994, 2019.
Kazuki Osawa, Siddharth Swaroop, Anirudh Jain, Runa Eschenhagen, Richard E Turner, Rio
Yokota, and Mohammad Emtiyaz Khan. Practical deep learning with bayesian principles. arXiv
preprint arXiv:1906.02506, 2019.
Yaniv Ovadia, Emily Fertig, Jie Ren, Zachary Nado, D Sculley, Sebastian Nowozin, Joshua V Dil-
lon, Balaji Lakshminarayanan, and Jasper Snoek. Can you trust your model’s uncertainty? eval-
uating predictive uncertainty under dataset shift. arXiv preprint arXiv:1906.02530, 2019.
George Papamakarios, Theo Pavlakou, and Iain Murray. Masked autoregressive flow for density
estimation. In Advances in Neural Information Processing Systems, pp. 2338-2347, 2017.
Tom Rainforth, Adam R Kosiorek, Tuan Anh Le, Chris J Maddison, Maximilian Igl, Frank Wood,
and Yee Whye Teh. Tighter variational bounds are not necessarily better. arXiv preprint
arXiv:1802.04537, 2018.
12
Under review as a conference paper at ICLR 2020
Jie Ren, Peter J Liu, Emily Fertig, Jasper Snoek, Ryan Poplin, Mark A DePristo, Joshua V Dillon,
and Balaji Lakshminarayanan. Likelihood ratios for out-of-distribution detection. arXiv preprint
arXiv:1906.02845, 2019.
Danilo Jimenez Rezende and Shakir Mohamed. Variational inference with normalizing flows. arXiv
preprint arXiv:1505.05770, 2015.
Danilo Jimenez Rezende, Shakir Mohamed, and Daan Wierstra. Stochastic backpropagation and
approximate inference in deep generative models. arXiv preprint arXiv:1401.4082, 2014.
Jurgen Schmidhuber. Deep learning in neural networks: An overview. Neural networks, 61:85-117,
2015.
Alireza Shafaei, Mark Schmidt, and James J Little. Does your model know the digit 6 is not a cat?
a less biased evaluation of” outlier” detectors. arXiv preprint arXiv:1809.04729, 2018.
Maximilian Solch, Justin Bayer, Marvin Ludersdorfer, and Patrick van der Smagt. Varia-
tional inference for on-line anomaly detection in high-dimensional time series. arXiv preprint
arXiv:1602.07109, 2016.
Jost Tobias Springenberg, Aaron Klein, Stefan Falkner, and Frank Hutter. Bayesian optimization
with robust bayesian neural networks. In Advances in Neural Information Processing Systems,
pp. 4134-4142, 2016.
Kumar Sricharan and Ashok Srivastava. Building robust classifiers through generation of confident
out of distribution examples. arXiv preprint arXiv:1812.00239, 2018.
Jakub M Tomczak and Max Welling. Vae with a vampprior. arXiv preprint arXiv:1705.07120, 2017.
Sumio Watanabe. Asymptotic equivalence of bayes cross validation and widely applicable infor-
mation criterion in singular learning theory. Journal of Machine Learning Research, 11(Dec):
3571-3594, 2010.
Houssam Zenati, Chuan Sheng Foo, Bruno Lecouat, Gaurav Manek, and Vijay Ramaseshan Chan-
drasekhar. Efficient gan-based anomaly detection. arXiv preprint arXiv:1802.06222, 2018.
13
Under review as a conference paper at ICLR 2020
A SVHN vs. CIFAR 1 0 results for OoD detection in input space
We performed additional experiments on OoD detection in input space on the higher-dimensional
SVHN (in-distribution) vs. CIFAR10 (OoD) benchmark6 (Hendrycks et al., 2018; Nalisnick et al.,
2019; Choi & Jang, 2018), following the same experimental protocol as described in Section 5.1.
Looking at Table 2 and Fig. 5, we arrive at the same conclusion as with the benchmarks considered
in Section 5.1 in that our approaches appear to significantly outperform the baselines we compare
against. While the variants BVAE-ESS and BVAE-ESSθφ are not as strong as the other BVAE-ESS
variants on this benchmark (as compared to the benchmarks considered in Section 3.3), they still
outperform the other baselines. The histograms in Fig. 4 again show that the BVAE-ESS scores
(right) more clearly separate in-distribution data from OoD data than the log-likelihood scores (left).
Table 2: AUROC↑, AUPRC↑, and FPR80J scores (where higher ↑ or lower ] is better) of the
baselines (top) and our methods (bottom) on the SVHN vs. CIFAR10 benchmark.
	AUROC↑	AUPRC↑	FPR80J
LL	0.574	0.575	0.634
WAIC	0.293	0.380	0.912
LLR	0.570	0.570	0.638
TT	0.395	0.428	0.859
BVAE-ESS	0.667	0.656	0.564
BVAE-ESSθφ	0.669	0.647	0.562
BVAE-ESS	0.828	0.817	0.281
B^VAE-ESSθφ	0.814	0.799	0.310
BVAEθ-ESS	0.807	0.793	0.331
Figure 4: Histograms of LL (left) and BVAE-ESS (right) on SVHN (in-distribution) and CIFAR10
(out-of-distribution). The ESS score separates the data more clearly than the LL score.
B Pseudocode of BVAE training procedure
Algorithm 1 shows the overall Bayesian VAE (BVAE) training procedure, which produces sets
Φ = {φB, φB+D, φB+2D, . . . , φT} and Θ = {θB, θB+D, θB+2D, . . . , θT} ofM = (T -B)/D+ 1
sequentially generated posterior samples φt 〜 p(φ∣D) and θt 〜 p(θ∣D) that do not fall into the
Markov chain’s burn-in phase of B epochs and are D epochs apart from each other (to avoid corre-
lation). Note that Algorithm 1 can in practice be conveniently implemented by exploiting automatic
differentiation tools commonly employed by modern deep learning frameworks.
6Interestingly, following the implementation details provided in Nalisnick et al. (2019), we were not quite
able to reproduce their results. In particular, our experiments yielded better calibrated log-likelihood scores for
the benchmark CIFAR10 (in-distribution) vs. SVHN (OoD) than theirs (i.e., our VAE model assigned lower
likelihood to most of the SVHN OoD data than to the CIFAR10 in-distribution data, as desired); this phe-
nomenon requires further investigation. For this reason, we instead chose the opposite benchmark, i.e., SVHN
(in-distribution) vs. CIFAR10 (OoD), for which the likelihood scores largely overlap, as shown in Fig. 4 (left).
14
Under review as a conference paper at ICLR 2020
Figure 5: (Left) Precision-recall curves (treating OoD data as the upper class) and (right) ROC
curves of all methods on the SVHN vs. CIFAR10 benchmark.
Algorithm 1 Bayesian VAE Training
Input: Dataset D, generative model p(x, z, θ), inference model q(z|x, φ), burn-in length B, sam-
ple distance D, mini-batch size |M|
Initialize φo, θo and Φ = 0, Θ = 0
Define number of mini-batches per epoch Nb =0
for t = 1, . . . , T do
Set φ0 = φt-1, θ0 = θt-1
for b = 1, . . . , Nb do
Sample minibatch M 〜D
Set Θ* = {θb-ι} if t ≤ B else Θ* = Θ
Set Φ* = {φb-ι} if t ≤ B else Φ* = Φ
Compute VφU(φb-ι, Θ*, M), update φb-ι → φb Via SGHMC
Compute VθU(θb-ι, Φ*,M), update θb-ι → θb Via SGHMC
end for
Set φt = φNb , θt = θNb
if t ≥ B and (t - B ) mod D = 0 then
Add Φ = Φ ∪ {φt} and Θ = Θ ∪ {θt}
end if
end for
Output: Posterior samples Φ and Θ
X—7	τV / 7	zʌ T∖ ΛT∖	1 X—7	TT / ∕λ	ɪ	T∖ ΛT \	♦	,♦	,,1	,1 J	1 ∙	. ∙ l-ɪ	/C、
VφU(φb-ι, Θ*, M) and VθU(θb-ι, Φ*, M) are approximations to the stochastic gradient in Eq. (3)
required for the SGHMC updates, defined as
VφU(φ, M) ≈ VφU(φb-ι, Θ*, M)
|M| X vΦLΦb-ι(X)- vφ log P(Bb-I)
x∈M
(14)
—
with ELBO gradient VφLφ^ [(x) as in Eq. (5), and
VθU(θ,M) ≈VθU(θb-ι, Φ*,M)
|M| X NθLthtab-ι (X)- vθ logp(θb-1)
x∈M
(15)
—
with ELBO gradient VθL^b_ɪ (x) as in Eq.(8).
C Pseudocode of alternative BVAE training procedure
Algorithm 2 shows pseudocode of an alternatiVe Bayesian VAE (BVAE) training procedure, which
essentially is identical to the training ofan ordinary VAE, but using the SGHMC sampler instead of
15
Under review as a conference paper at ICLR 2020
a stochastic gradient optimizer. The posterior samples Θ and Φ are thus not used during training (as
in Algorithm 1), but only for test time prediction.
Algorithm 2 Alternative Bayesian VAE Training
Input: Dataset D, generative model P(x, Z, θ), inference model q(ZIx, φ), burn-in length B, sam-
ple distance D, mini-batch size IMI
Initialize φo, θo and Φ = 0, Θ = 0
Define number of mini-batches per epoch Nb =备
for t = 1, . . . , T do
Set φo = φt-ι, θo = θt-ι
for b = 1, . . . , Nb do
Sample minibatch M 〜D
~ , 0	ʌ
O
Compute VφU(φb-1, θb-1, M), update φb-1 → φb via SGHMC
ʌ , ʌ ʌ
O
O
Compute VθU(φb-ι, θb-ι, M), update θb-ι → θb Via SGHMC
end for
ʌ
ʌ
Set φt = φNb , θt = θNb
if t ≥ B and (t - B ) mod D = 0 then
Add Φ = Φ ∪ {φt } and Θ = Θ ∪ {θt}
end if
end for
Output: Posterior samples Φ and Θ
We have
U(φb-1,θb-1, M)
|D| X
两XiM
-1,φb-1 (x) - logp(φb-ι) - logp(θb-ι)
(16)
—
ʌ
O
with the standard VAE ELBO as in Eq. (1), i.e.,
O
ʌ
-1,φb-1 (X) = Eq(ζ∣x,φb-1)[logP(Xlz,θb-l)] — DKLg(Z|x, φb-1 )kP(Z)).
(17)
D Numerically stable implementation of the ESS score
For numerical stability, we in practice always work with log-probabilities (since raw probabilities
may get arbitrarily close to and thus be rounded to zero). I.e., instead of directly computing p(x∣θ)
in Eq. (12) based on the probabilities p(x∣z, θ), p(z) and q(z∣x, φ), we compute logp(x∣θ) based on
the respective log-probabilities log p(x|z, θ), log p(z) and log q(z|x, φ) as follows:
1K
logp(x∣θ) ` log I KE
k=1
=log (K X
k=1
P(XIZk ,θ)p(Zk )
M pφ∈φ q(Zk|x, φ)
exp log
logmeanexpz log
p(x∣Zk ,θ)p(Zk) ʌʌ
志 Pφ∈Φ q(Zk Ix,φ) JJ
P(xIZk, θ)P(Zk)
logmeanexpz log
焉 pφ∈φ q(zk|x, φ) J
exp(log(P(X|Zk, θ)P(Zk)))
logmeanexpz log
exp(log(MM Pφ∈Φ exp(logp(zk∣x, φ))))
exp(logp(x∣zk,θ)+logP(Zk)) ʌ
exp(logmeanexpφ(log Pzk |x, φ)))
= logmeanexpzk logP(xIZk, θ) + log P(Zk) - logmeanexpφ(logP(ZkIx,φ))
where Zk 〜 q(Z∣x, D), where the last equality uses log Ixp(θ) = log(exp(a — b)) = a 一 b, and
where logmeanexp is a variant of the commonly used numerically stable logsumexp function which
computes the mean instead of the sum.
16
Under review as a conference paper at ICLR 2020
We thus obtain the vector P = [pθ]θ∈θ = [logp(x∣Θ)]θ∈θ of log-likelihoods, which We can then use
to compute the vector w = [wθ]θ∈Θ of weights wθ in Eq. (9) by passing p through the numerically
stable softmax function, i.e.,
p(x∣θ)	_	exp(pθ)	_	exp(pθ -p*)	_<	*∖
pθ∈θP(Xm) 一 pθ∈θ eχp(Pθ厂 pθ∈θ eχp(Pθ -p*) —	p p θ
(18)
wherep* = max(p) = max{logp(x∣θ)∣θ ∈ Θ} is the largest log-likelihood value across all θ ∈ Θ.
E Precision-ROC and PR Curves for FashionMNIST (held-out
classes) benchmark
UO-S-OaJd
Precision-Recall curves
0.0	0.2
0.4	0.6
Recall
UMOK 3Λ≈-sod Brui
ROC curves
——LL(AUROC=O.51)
「LH(AUROC=O.50)
——TT(A∪ROC=0.41)
——VVAIC(AUROC=O.30)
—BVAE-ESS (A∪ROC=0.63)
——BVAE-ESSJ (AUROC=0.66)
(A∪ROC=0.66)
—(AUROC=0.68)
BVAEe-ESS (AUROC=0.66)
0.4	0.6
False Positive Rate
0.8	1.0
0.8	1.0
Uo-S-UaJd
Figure 6: (Left) Precision-recall curves and (right) ROC curves of all methods on the FashionMNIST
(held-out classes) benchmark with classes 0 and 1 held-out.
Precision-Recall curves
——LL (AU PRC=0.57)
——LLR (A∪PRC=0.57)
——TT(A∪PRC=0.51)
——WAIC (AUPRC=0.48)
——BVAE-ESS (AUPRC=O.SB)
——BVAE-ESSl(AUPRC=O.64)
——雨EESS(AUPRC=O.61)
—(AUPRC=0.63)
BVAEe-ESS (AUPRC=0.64)
0.0	0.2
0.4	0.6	0.8
Recall
ROC curves
se⅞j 9Λ≈-sod BnU
0.2	0.4	0.6	0.8	1.0
False Positive Rate
—LL(AUROC=0.59)
「LIΛ (AUROC=0.58)
—TT(AUROC=O.48)
—WAIC (AUROC=0.48)
—BVAE-ESS (A∪ROC=0.60)
——BVAE-ES印(AURoC=O.66)
丽EESS (AUROC=0.64)
——SKIEeS% (A∪ROC=0.65)
BVAEe-ESS (AUROC=O.66)
Figure 7:	(Left) Precision-recall curves and (right) ROC curves of all methods on the FashionMNIST
(held-out classes) benchmark with classes 2 and 3 held-out.
17
Under review as a conference paper at ICLR 2020
Precision-Recall curves
0.8
1.0
0.4	0.6
Recall
——U. (AUPRC=0.49)
—LLR (AUPRC=0.49)
——TT (AUPRC=0.46)
——WAlC (A∪PRC=0.43)
——BVAE-ESS (AUPRC=0.68)
——BVAE-ESS^ (A∪PRC=0.71)
^iZS-ESS (AUPRC=0.65)
——≤VMKeSSJ (AUPRC=0∙70)
BVAEe-ESS (AUPRC=0.69)
ROC curves
UMOK 3Λ≈-sod BfUJ.
D.B
False Positive Rate
Figure 8:	(Left) Precision-recall curves and (right) ROC curves of all methods on the FashionMNIST
(held-out classes) benchmark with classes 4 and 5 held-out.
Precision-Recall curves
Uo-S-UaJd
ROC curves
D.B
False Positive Rate
UMOK 3Λ≈-sod BfUJ.
——TT(A∪PRC=0.51)
——WAIC (AUPRC=O.Sl)
——BVAE-ESS (A∪PRC=0.53)
——BVAE-ES*(AUPRC=O.59)
——前5EESS(AUPRC=O.56)
—tfi¾KESS∣ (AUPRC=0.53)
BVAE8-ESS (AUPRC=O.56)
Figure 9:	(Left) Precision-recall curves and (right) ROC curves of all methods on the FashionMNIST
(held-out classes) benchmark with classes 6 and 7 held-out.
Precision-Recall curves
0.4
0.2-
0.0
---LLtAUPRC=0.7。)
—LLR (AUPRC=0.69)
——EAUPRC=O.60)
——WAIC (AUPRC=O.SO)
—BVAE-ESS (AUPRC=O.BS)
——BVAE-ES* (A∪PRC=0.87)
——Meess(AUPRC=ORI)
——^L¾7-ESS∣ (AUPRC=0.84)
BVAEe-ESS (AUPRC=0.89)
0.0	0.2
0.4	0.6	0.8	1.0
ROC curves
0.8
1.0
False Positive Rate
—LL(AUROC=0.72)
——LLR (A∪ROC=0.71)
—TT(A∪ROC=0.53)
—WAIC (AUROC=O.50)
——BVAE-ESS (AUROC=0.84)
—BVAE-ESy(AUROC=O.86)
SWSess (AUROC=O.83)
—tf0E⅛S印(AUROC=O.83)
BVAE8-ESS (AUROC=0.89)
Recall
Figure 10:	(Left) Precision-recall curves and (right) ROC curves of all methods on the FashionM-
NIST (held-out classes) benchmark with classes 8 and 9 held-out.
18