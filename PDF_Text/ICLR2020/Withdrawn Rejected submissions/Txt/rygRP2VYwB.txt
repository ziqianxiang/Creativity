Under review as a conference paper at ICLR 2020
Stochastically Controlled	Compositional
Gradient for Composition Problems
Anonymous authors
Paper under double-blind review
Ab stract
We consider composition problems of the form n Pin=1 Fi(ɪ P；=i Gj(x)).
Composition optimization arises in many important machine learning applica-
tions: reinforcement learning, variance-aware learning, nonlinear embedding, and
many others. Both gradient descent and stochastic gradient descent are straight-
forward solution, but both require to compute n P；=i Gj (x) in each single it-
eration, which is inefficient-especially when n is large. Therefore, with the aim
of significantly reducing the query complexity of such problems, we designed a
stochastically controlled compositional gradient algorithm that incorporates two
kinds of variance reduction techniques, and works in both strongly convex and
non-convex settings. The strategy is also accompanied by a mini-batch version
of the proposed method that improves query complexity with respect to the size
of the mini-batch. Comprehensive experiments demonstrate the superiority of the
proposed method over existing methods.
1	Introduction
In this paper, we study the following composition minimization problem,
XmRN (f (x) =f F(G(X)) =f 1 XX Fi (nX Gj (X)))，	(LI)
where f : RN → R is differentiable and possibly non-convex, each Fi: RM → R is a smooth
function, each Gi: RN → RM is a mapping function, both the numbers of Fi’s and Gj ’s are
assumed to be n for simplicity We call G(x):= n P；=i Gj(x) the inner function, and F(w):=
§ pn=1 Fi(W) the outer function. Many machine learning problems can be cast as composition
problems that include two finite-sum structures: reinforcement learning (Sutton et al., 1998; Wang
et al., 2017; Liu et al., 2016), variance-averse learning (Lian et al., 2017), and nonlinear embedding
(Hinton & Roweis, 2003; Dikmen et al., 2015). In particular,
•	(reinforcement learning) The S × S system of Bellman equations Wang et al. (2017)
can be written as minx∈RS kE[B]x - E[b]k2, where E[B] = I - γPπ, γ ∈ (0, 1) is a
discount factor, Pπ is the transition probability under policy π, and E[b] is the expected
state transition reward. This is one of key problems in reinforcement learning for evaluating
the value of a policy π.
•	(risk-averse learning) The risk-averse learning Lian et al. (2017) aims to maximize the
expected return while control the variance (or risk) in the meantime:
minx - Ea [h(x; a)] + λVara [h(x; a)],
where h(x; a) is the loss function including a random variable a, λ > 0 is a regularization
parameter.
•	(nonlinear embedding) Stochastic nonlinear embedding Hinton & Roweis (2003) aims
to map a group of points from a high dimensional space to a low dimensional space by
minimizing the KL divergence. It is a non-convex composition optimization
minx X KL(p∙∣t k q.∣t) := XXPi∣t log pit,	QZ
where pi|t and qi|t are the conditional probabilities w.r.p. {zi}in=1 and {xi}in=1,
1
Under review as a conference paper at ICLR 2020
_	d(Zt,Zi)	c., _	d(Xt,Xi)
pilt — Pj=t d(zt,zj), qilt — Pj=t d(xt,xj),
where d(∙, ∙) is the dissimilar distance function between two samples.
To solve the composition optimization including the finite-sum structure in (1.1), two most straight-
forward approaches are the gradient descent (GD) and the stochastic gradient descent (SGD). How-
ever, it is extremely expensive to scan all the inner functions (for both SGD and GD) as well as all
the outer functions (for GD) in each iteration. However, note that, unlike solving common stochastic
optimization problems, randomly sampling one inner function and one outer function does not give
an unbiased estimate for the true gradient; that is, Ei〜[n],j〜冈[(∂Gj(X))TdFi(G(x))] = Vf (x),
where G(x)is the estimation of G(x). The key to solving this composition objective is how to es-
timate the value of G(xk) and its Jacobian with high accuracy using only a few samples in each
iteration.
Recently, many stochastic optimization methods solving the composition problem have been devel-
oped, such as the stochastic gradient based method and the variance-reduction based method. For
example, stochastic compositional gradient descent (SCGD) (Wang et al., 2017; Liu et al., 2016)
estimates the inner function G(x) by using an iterative weighted average of the past values of G(x),
and then performs the stochastic quasi-gradient iteration. The advantage of this method is that con-
vergence rate does not depend on n; however, it queries more samples to the desired point. Another
set of approaches is based on variance reduction - for instance, compositional stochastic variance
reduction gradient (Compositional-SVRG) (Lian et al., 2017) estimates the inner function G(x) and
the gradient of function f(x) by using the variance reduction technique; however, the derived linear
convergence rate is related to n. Motivated by a few recent works (Lei & Jordan, 2017; Lei et al.,
2017; Allen-Zhu, 2017) that focus on the stochastically controlled gradient, we were inspired to look
for a way to improve the query complexity and reduce the dependence on n to solve the composition
optimization in (1.1).
Hence, this paper presents a novel and more efficient method named stochastically controlled com-
positional gradient (SCCG) for solving composition problems involving a two-finite-sum structure.
The result is improved query complexity over existing approaches. Further, all results in this paper
can be easily extended to cases where the number of Fi and the number of Gj are different. The
main contributions of this article are summarized below.
•	We provide a stochastically controlled function to estimate the inner function G(x). In-
spired by stochastically controlled stochastic gradient (SCSG) (Lei & Jordan, 2017) that
estimates the gradient, G(X) can also be estimated by using a snapshot X§, in which G(Xs)
is not computed directly, but is estimated through a random subset from [n]. This is the
first time that a stochastically controlled function has been incorporated into the process
of estimating the inner function. We have also analyzed how the size of the subset might
influence the query complexity for both strongly convex and non-convex functions.
•	We provide a stochastically controlled compositional gradient to estimate the Vf (X). How-
ever, there are two potential situations that could be encountered in the estimation process
that can impede convergence. First, the expectation of the gradient is no longer an un-
biased estimation; and, second, the gradient of f (Xs) at the snapshot is formed by two
random subsets, which are used for the functions Fi and Gj respectively. Moreover, the
biased gradient bring more difficulty in proving the convergence, which are greatly differ-
ent from those encountered in (Lei & Jordan, 2017; Lian et al., 2017; Lei et al., 2017). To
address these scenarios, we have identified a bound on the size of the subsets that are used
to estimate the gradient. The details of the analysis can be referred to Section 3.1 and 3.2.
•	A mini-batch version of the proposed algorithm is also provided for both strongly convex
and non-convex functions. The corresponding query complexities are improved according
to the size of the mini-batch. More information can be referred to Section 3.3.
1.1	Results
Following the classical benchmark for a general problem, the composition algorithm is also to find
a point X satisfying f (x) 一 f (x*) ≤ E for a convex function, where x* is the optimal point in the
strongly convex function, and kVf (X)k2 ≤ for a non-convex function, respectively. The elegance
2
Under review as a conference paper at ICLR 2020
Algorithm	Strongly Convex	Non-convex
SCGD (Wang et al., 2017)	O(1/e3/2)	OWɔ
Acc-SCGD (Wang et al., 2017)	O(1/e5/4)	O(1/e7/2)
ASC-PG(LiUetaL,2016)	一	O(1/e5/4)	O(1/e9/4)
SC-SVRG (Liu et al., 2017b)	O Xn + Lf/〃4)log(1/e),	O(n4/5/e)
mini-batch VRSC-PG (Huo et al., 2018)	O Kn + 乙〃〃3) log(l/j	O(n2/3/e)
mini-batch C-SAGA (Yuan et al., 2019)	O Iln + Lf/〃3j log(l/e)j	O(n2/3/e)
SCCG	O ((min {n,表} + L2min {n, μ⅛}}og (I∕e))	O(min{+,嗒})
mini-batch SCCG (b= 1,min {n, ɪ} 3)	O ((min {n,表} + Lmin {n, *}}og (I∕e))	O(min{泰,啜})
Table 1: Comparison of the query complexity with different algorithms. Note: μ and Lf are defined
in the Preliminary Section. b is the size of the mini-batch.
of a composition algorithm is evaluated based on its query complexity, defined as the number of
queries in a given sampling oracle that are needed to compute the gradient. Here, we give the query
complexities of the composition problem in Table 1, which offers an insightful comparison to other
algorithms.
Strongly convex function The query complexity for the strongly convex function is
O((min{n, 1∕(eμ2)} + Lf /μ2min{n, 1∕μ2}) log(1∕e)). The result is the general form for the
strongly convex composition and is equal to or better than the query complexity in (Lian et al.,
2017) and (Liu et al., 2017a).
Non-convex function The query complexity is O(min{1/9/5, n4/5/}), which is better than the
result in (Liu et al., 2016) and comparable to the result in (Liu et al., 2017b).
Mini-batch 1 For the mini-batch version, the query complexity can be improved to some extent, that
is O((min{n, 1∕(eμ2)} + Lf /(bμ2)min{n, 1∕μ2}) log(1∕e)). and O(min{1∕c9∕5, n4/5/^}/。1/5)
for strongly convex and non-convex functions, respectively, which are better than mini-batch vari-
ance reduced stochastic compositional proximal gradient method (VRSC-PG) (Huo et al., 2018) and
mini-batch Composite SAGA (C-SAGA)(YUan et al., 2019) when b=1 /μ and min {n, 1 /e}2/3 for
strongly convex and non-convex functions, respectively.
1.2	Related work
As the amount of data we have at our disposal grows, stochastic optimization has become a pop-
ular technique in the realm of machine and deep learning, particularly for optimizing finite-sum
functions. The typical algorithms for solving such problems include stochastic gradient descent
(Ghadimi & Lan, 2016), SVRG (Johnson & Zhang, 2013; Reddi et al., 2016), stochastic dual co-
ordinate ascent (SDCA) (Shalev-Shwartz & Zhang, 2014; 2013) and the accelerated Nesterov’s
method (Nesterov, 2013), accelerated randomized proximal coordinate (APCG) (Lin et al., 2014;
2015) and Katyusha method (Allen-Zhu, 2017). The standard procedure for optimizing a problem
with a finite-sum structure is to randomly select one or a block of components to estimate the gra-
dient. However, knowing that the estimated gradient usually has a large variance, the gradient of
the function is estimated from a snapshot to appropriately reduce the variance - in other words, the
procedure includes a variance reduction mechanism.
Composition optimization problems can also be solved with the above algorithms, but the two-
finite-sum structures in composition problems mean that when the gradient of the inner function is
estimated directly, the query complexity can substantially increase. Recently, Wang et al. (2017)
proposed a method based on first-order SCGD to overcome this issue where the variable and the
inner function are updated alternately in two steps. The method has a query complexity of O(-7/2 )
for a general function and O(-5/4) for a strongly convex function. Liu et al. (2016) employed Nes-
1 b denotes the size of the mini-batch, can be obtained through the η ≤ 1 from Theorem 1 and Theorem 2.
3
Under review as a conference paper at ICLR 2020
terov’s method to accelerate the composition problem, reaching O(-5/4) and O(-9/4) for strongly
convex and non-convex functions, respectively. Ghadimi et al. (2018) proposed a nested averaged
stochastic approximation method to find an approximate stationary point within the problem, result-
ing in a sample complexity of O(1/2). However, these methods estimate the inner function using
an iterative weighted average of the past function.
The other stream of solutions focuses on variance reduction technology. For instance, Lian et al.
(2017) initially applied the SVRG-based method to estimate the inner function G(x) and the gradi-
ent of the function f (x), which yields a linear convergence rate. Subsequently, Liu et al. (2017a) and
Devraj & Chen (2019) applied a dual-based method to composition problem, which also yields a lin-
ear convergence rate. Devraj & Chen (2019) also applied the stochastic variance reduced primal-dual
algorithms to composition problem. Yu & Huang (2017) turned to an ADMM-based Boyd (2011)
method and provided an analysis of convex functions that do not rely on Lipschitz smoothness.
Moreover, Liu et al. (2017b) went a step further and considered non-convex functions, analyzing the
query complexity with both inner and outer functions of different sizes. Lin et al. (2018) considered
non-smooth convex composition functions, offering an incremental first-order oracle complexity
analysis. Zhang & Xiao (2019) and Huo et al. (2018) also provided an randomized incremental
gradient method for the composition problem including regularization.
Many recent articles have discussed variance reduction methods that estimate the gradient from a
random subset rather than through direct computation. Lei & Jordan (2017), for example, proposed
an SCSG method for a convex finite-sum function. They then applied it to a non-convex problem
in (Lei et al., 2017) by using less than a single pass to compute the gradient at the snapshot point.
Furthermore, Allen-Zhu (2017) proposed the Natasha1.5 algorithm, in which the gradient for each
epoch is based on a random subset. Moreover, the objective function has the regularization term.
Liu et al. (2018) applied an SCSG based method to the zeroth-order optimization problems with the
finite-sum function. Recently, Yuan et al. (2019) applied the stochastic recursive gradient descent
method to the composition problem.
The rest of paper is organized as follows: in Section 2, we give preliminaries used for analyzing
the proposed algorithm. Section 3 presents the SCSG-based method for the strongly convex and
non-convex composition problem and the corresponding mini-batch version. In Section 4, we give
the experimental results. We conclude our paper in Section 5.
2	Preliminaries
Throughout this paper, We use the Euclidean norm denoted by』∙ ∣∣. We use i ∈ [n] to denote that
i is generated from [n] = {1, 2,…，n}. We denote by (∂G(x))TVF(G(X)) the full gradient of the
function f, ∂G(x) the Jacobian of G, and (∂Gj(X))TVFi(G(X)) as the stochastic gradient of the
function f, Where i and j are randomly and independently selected from [n]. We use A = |A| to
denote the number of elements in the set A, and define GA(X)= 十 Pι≤j≤A G∕j](x). We use
E to denote the expectation, that is E∕[v] = + Pι≤i≤A v∕[i]. Note that all the variables such as
subsets A and B, elements i and j are independently selected from [n], in particular, the element
in A and B are independent. So We use E in instead of Ei , Ej ,EA and EB except When explicitly
stated otherWise. Recall definitions on Lipschitz function, smooth function and strongly convex.
Definition 1. For function p on X, ∀X, y ∈ X, A function p is a Bp-Lipschitz, that is
∣p(X) - p(y)∣ ≤ Bp ∣X - y∣; A function p is a Lp-smooth, that is ∣Vp(X) - Vp(y)∣ ≤
LpkX - y∣∣； AfUnctionP isa μ-strongly convex, that isP (y) ≥ P (x) + hp (x), y —x)+μ∕2∣x — y∣2.
Through our discussions, We make the folloWing assumptions,
Assumption 1. Let BG, LF and Lf be positive scalars, 2
•	Gj is BG-Lipschitz, j ∈ [n], that is ∣Gj (X) — Gj (y)∣ ≤ BG ∣X — y∣.
•	Fi is LF -smooth, i ∈ [n], that is ∣VFi(X) — VFi (y)∣ ≤ LF ∣X — y∣.
2In the strongly convex composition problem, the upper bounded Jacobian does not imply that the gradient
of f (x) is upper bounded since We do not require the gradient of Fi is upper bounded. Moreover, in the
experimental section, We Will shoW that the Jacobian of G(x) is bounded.
4
Under review as a conference paper at ICLR 2020
•	For function Fi(G(X)) ,there exists a constant Lf satisfying ∣∣(∂Gj (x))TVFi(G(x)) 一
(dGj(y))TvFi(G(y))k ≤ Lf kχ 一 yk,∀i,j ∈ [n]∙
•	We assume that i and j are independently and randomly selected from [n], z ∈ RM , x ∈
RN, then E[(∂Gj (x))TVFi (z)] = (∂G(x))TVF(z).
Furthermore, we define H1 and H2 are the upper bounds on the variance of G(x) and
(∂G(x))TVF(y), respectively, that is,
n	nn
1 P ∣G(x) - Gi(x)k2 ≤ Hi, n⅛ PP ∖∖(∂G(x))TVF(y) - (∂G∙(X))TVFi(y)∣∣2 ≤ H
i=1	j=1i=1
In the paper, we denote by Xsk the k-th inner iteration at s-th epoch. But in each epoch analysis, we
drop the superscript S and denote by Xk for xk. We let x* be the optimal solution of the convex
f (x). Throughout the convergence analysis, We use O(∙) notation to avoid many constants, such as
BG, LF, and Lf, that are irrelevant with the convergence rate.
3	Stochastically Controlled Compositional Gradient
In this section, We present the variance-reduction based method for the composition problem, Which
can be used for both the strongly convex function and non-convex function. Before describing the
proposed algorithm, We recall the original SVRG (Johnson & Zhang, 2013). The general process
of SVRG Works as folloWs. The update process is divided into S epochs, and each of the epoch
consists of K iterations. At the beginning of each epoch, SVRG defines a snapshot vector Xs, and
then compute the full gradient Vf (Xs). In the inner iteration of the current epoch, SVRG defines
the estimated gradient by randomly selecting ik from [n] at the k-th iteration,
(∂G(Xk))TVFik(G(Xk))- (∂G(Xs))TVFik(G(Xs)) + Vf(Xs).	(3.1)
HoWever, for the composition problem, there are also variance-reduction based methods in (Lian
et al., 2017; Liu et al., 2017a;b). The difference With SVRG is that there is another estimated
function for G(X), Which also has the finite-sum structure. These methods define the estimated
function as
Gk = GA(Xk) - Ga (Xs) + G(Xs),	(3.2)
Where A is the mini-batch formed by randomly sampling from [n]. Whereas, as the number of the
inner function Gj and the outer function Fi increase, it is not reasonable to compute the full gradient
of f(X) and the full function G(X) directly for each epoch.
Extending from the SCSG (Lei et al., 2017; Lei & Jordan, 2017) and Natasha1.5 (Allen-Zhu, 2017),
We present a neW algorithm SCCG for the composition problem as shoWn in Algorithm 1. 3 We
introduce tWo subsets D1 and D2, Which are independent With each other and randomly selected
from [n], respectively. We define D = D1∪D2 as aneW variable, Which is important in analyzing the
convergence. Firstly, D1 is used for estimating the inner function. Based on the variance reduction
technique, the estimated inner function at k-th iteration of s-th epoch is
Gk = GA(Xk) - Ga (Xs) + Gdi (Xs),	(3.3)
Where the subset of A is the same as in (3.2). Note that A and D are independent With each other.
The difference With (3.2) is that the third term in (3.3) is computed under the subset D1 rather than
[n]. Throughout the paper, We assume that |A| ≤ |D1|. Secondly, D2 is used to estimate the outer
function F. The key distinguish With (Lei et al., 2017; Lei & Jordan, 2017; Allen-Zhu, 2017) is
the biased full gradient of f (Xs). We define this estimated full gradient of f (XS) for each epoch as
VfD(XS) = (∂Gdi (XS))TVFD2(Gdi (Xs)). Though Ea,d[V/d(x§)] = Vf(XS), we could still
estimate the gradient of the f(Xk) by
Vfk = (∂Gjk(Xk))TVFik(Gk) - (∂Gjk(XS))TVFik(Gdi (Xs)) + VfD(XS),	(3.4)
3The parameters’ setting can be referred to Theorem 1 and Theorem 2 for the strongly convex and non-
convex function, respectively.
5
Under review as a conference paper at ICLR 2020
Algorithm 1 Stochastically Controlled Compositional Gradient (SCCG) for the strongly convex or
non-convex composition problem
Require: K, S, η , Xo and D = Di ∪D2, where Di and D2 are mini-batches.
for S = 0,1,2,…，S 一 1 do
Sample from [n] for D times to form mini-batch Di
Sample from [n] for D times to form mini-batch D2
VfD (Xs) = (∂Gdi (Xs))TVFD2 (Gdi (Xs))
xo = Xs
for k = 0,1, 2,…，K — 1 do
Sample from [n] to form mini-batch A
Gk = GA(Xk) - GA(Xs) + GDI (Xs)
Uniformly and randomly pick ik and jk from [n]
Compute the estimated gradient Vfk from (3.4)
Xk+i = Xk 一 ηVfk
end for
Update Xs+i = XK, or Xs+i = Xr, r is randomly selected from [K - 1]
end for
Output: Xk is uniformly and randomly chosen from S ∈ {0,…，S - 1} and k ∈ {0,.., K - 1}.
where ik and jk are randomly selected from [n] at the k-th iteration for functions F and G, respec-
tively. Furthermore, Eij,jkA,D [Vfk] 6= Vf(Xk) as well. This gives us more discussion about the
upper bound with respect to the estimated function and the gradient under the new random subset D
(more details can be referred to appendix).
3.1 SCCG for the strongly convex case
In this subsection, we analyze the query complexity for the strongly convex composition problem
and show that our result is better or comparable to the previous methods. Furthermore, we discuss
the query complexity under different value with respect to n, μ and E
Theorem 1. InAlgorithm 1,for the μ-strongly convex problem, suppose Assumption 1 holds, let the
SteP size is η ≤ μ∕(135Lf), the subset size of A is A = min{n, 128BG LF/μ2}, the subset size of
Di and D2 are both D = min {n, 5(16BG LF Hi + 4氏)/(4cμ2)}, the number of the inner iter-
ation is K ≥ 540Lf/μ2, the number ofouter iteration is S ≥ 1∕(log(1∕ρ))log(2E∣∣Xo — X* *k2∕e).
Then, the query complexity is (D + KA) S = O
((min {n,壶} + L2 min {n, μ2})log(I∕e)).
As can be seen from the above result, Theorem 1 presents the general query complexity under
different parameters ( the details of parameters’ setting can be referred to the Appendix.). Comparing
n with corresponding parameters, we analyze the query complexity separately. We remove the
parameters such as BG, LF, Hi and H2, and analyze the size with the order of 1∕μ2. We consider
three internals of n while the min value of the function in the above query complexity will take
different results:
• 1∕μ2 ≤ 1/(e〃2) ≤ n. When n is large enough such that we can obtain the query complex-
ity is O((1∕(eμ2) + Lf ∕μ4) log(1∕e)). This result avoids the situation that computing the
full gradient of f(X) and the full function G(X) for the large-scale number of n. What’s
more, this result is better than Compositional-SVRG (Lian et al., 2017; Liu et al., 2017a).
• 1∕μ2 ≤ n ≤ 1∕(eμ2). When n is smaller than 1∕(eμ2), the query complexity becomes
θ((n + Lf ∕μ4) log(1∕e)), which is the same as Compositional-SVRG (Lian et al., 2017).
However, We need to compute the full gradient of Vf (Xs) as in (3.1). The estimation of
inner function G(X) is the same as in (Lian et al., 2017).
• n ≤ 1∕μ2 ≤ 1∕(eμ2). When n is the smallest one, the query complexity becomes
O((n + Lfn∕μ2)log(1∕e)). The result has a similar form to SVRG (Johnson & Zhang,
2013). This also gives us an intuition that the inner function should be computed directly
rather than estimated if n is small.
6
Under review as a conference paper at ICLR 2020
3.2	SCCG for the Nonconvex Case
In the previous subsection, we showed convex SCCG converges to the optimal point with improved
query complexity. A natural question is whether the proposed algorithm can improve the perfor-
mance of the non-convex problem. We provide an affirmative answer. In this subsection, we present
the query complexity for the non-convex composition problem in term of stationarity gap ||Vf (x)||2.
Theorem 2. In Algorithm 1, for non-convex function, suppose Assumption 1 holds, let the step size
is η = min{1/n2/5, 2/5}, the size of the subset D1 and D2 are D = min {n, O(1/)}, the size
of subset A is A = min {n, O (1∕η)} ,the number of inner iteration is K ≤ O (l∕η3∕2), the total
number ofiteration is T = O (1/ (En)), in order to obtain E[∣∣Vf (Xk)II2] ≤ G the query complexity
is O (min {l∕e9/4 5, n4/5/e}).
From the above result, we analyze the query complexity of the non-convex problem separately:
1) when n ≥ 1∕e, our query complexity becomes O(1∕e9/5), which is independent on n. This
is better than the query complexity of the accelerated method in (Liu et al., 2016), in which the
query complexity does not depend on n as well. 2) when n ≤ 1∕E, the query complexity becomes
O(n4∕5∕c), which is consistent with the result of (LiU et al., 2017b) in solving the problem (1.1).
3.3	Mini-batch version of SCCG
In this subsection, we present the mini-batch version of the proposed method in Algorithm 2 (in
appendix) and obtain the corresponding query complexities for both the strongly convex and the
non-convex functions, which provably benefit from mini-batching. As the process of the proof is
similar to that of Theorem 1 and Theorem 2, and the difference with Algorithm 1 is the computation
of the gradient of f(x) (the corresponding proof of bound is in appendix), we could directly present
the corresponding results for both the strongly convex and the non-convex problems.
Corollary 1. In Algorithm 2, for the μ-strongly convex problem, SUPPOSeASSUmPtion1 holds, let the
StePSize n ≤ bμ∕(135Lf), the number ofthe inner iteration is K ≥ 540Lf ∕eμ2), in order to obtain
Ekxs-X*k2
≤ E, the query comPlexity is O
((min {n, ^⅛} + L2 min {n, μ⅛}) log(I∕e)).
Corollary 2. In Algorithm 2, for the non-convex Problem, suPPose AssumPtion 1 holds, let the steP
size n = b3∕5 min{1∕n2∕5, E2∕5}, the number of the inner iteration is K ≤ O b1∕2∕(n3∕2) , in
order to obtain E[∣Vf (xk)∣2] ≤ e, the query complexity is (1∕b1∕5)O (min {1∕e9/5, n"5∕c}).
From the above-given query complexity results for the strongly convex and non-convex problems,
we can see that both of their step size n and the number of inner iteration K are larger than the
corresponding ones in the non-mini-batch version. These two key parameters lead to the improved
query complexity for both strongly convex and non-convex functions.
4	Experiments
In this section, we evaluate the performance of our proposed algorithm on the strongly convex and
non-convex functions, respectively.
SCCG for strongly convex function4 To verify the effectiveness of the algorithm, we use the
mean-variance optimization in portfolio management5:
n
minx∈Rd — n Pn=I hri,xi+n Pn=Khri,xi — nP hri, xi)2,
i=1
where ri ∈ RN , i ∈ [n] is the reward vector, and x ∈ RN is the invested quantity. In the experi-
mental setting, We set n=3000, ∣A∣≈ n2/3, |D1| = 2400, 2600,2800, which are denoted as SCCG
(2400), SCCG (2600) and SCCG (2800). The reward vectors are generated on Gaussian distribution
4Our aim is to compare our general variance-reduce based method with the stochastic composition gradient
method, and also to verify the proposed algorithm, thus we do not include SVRG-based method.
5This formulation is just used to verify our proposed algorithm. In appendix, we show the bounded Jacobian.
7
Under review as a conference paper at ICLR 2020
10-20
1	2	3	4	5	6	7	8
Number of queries	ɪɪio6
10-3
0
1	2	3	4	5	6	7	8
Number of queries	ɪɪio6
10-2o	1
2	3	4	5	6	7	8
Number of queries	xιo6
Figure 1:	Strongly convex: Comparison of the gap between the function value and the optimal value
among SCGD, ASC-PG and SCCG methods. Dataset (from left to right): condition numbers of the
covariance matrix are set κcov =10, 30 and 50, respectively.
K
10-4
10-4
10-4
-U,pfgβiN
6 6，
∙∙∙
-Up0 -O iN
6 6 7
∙∙∙
-Up0 -O iN
Figure 2:	Non-convex: Comparison of the norm of the gradient between SCGD, ASC-PG and
SCCG; Dataset (from left to right): mnist, olivettifaces and coil20.
with the condition number of its covariance matrix denoted by κcov. Furthermore, we consider three
conditions numbers, κcov=10, 30 and 50. We compare our algorithm with the stochastic gradient
based methods SCGD and accelerated stochastic method ASC-PG. Figure 1 shows the performance
of the gap between the value function and optimal value, we observe that our algorithm is better than
stochastic gradient methods, SCGD and ASC-PG.
SCCG for non-convex function For the non-convex function, we apply the proposed SCCG method
to the nonlinear embedding problem in (1.2). We consider the distance of low-dimension space
between xi and xj as 1/(1 + kxi - xj k2), i,j ∈ [n]. Then, the problem can be formulated as the
problem in (1.1), in which the details can be referred to the appendix. We consider three datasets:
mnist, Olivetti faces and COIL-20 including different sample sizes and dimensions, 1000× 784,
400 × 4096 and 1440× 16384. Our experiment is to verify our proposed algorithm, thus we set
D1 = D2 in default and choose three different sizes of sample set D1, which are smaller than n. For
example, for the case of mnist, we choose |D1 | = 400, 600, 800, which are denoted as SCCG (400),
SCCG (600) and SCCG (800). Furthermore, We also set ∣A∣≈ n2/3, where n is the total number of
samples. Figure 2 shows the norm of the gradient, and Figure 3 (in appendix) shows the objection
value. We compare our algorithm with the stochastic gradient based method (SCGD and ASC-PG),
and observe that our proposed algorithm is better than SCGD and ASC-PG on both the norm of
the gradient and objective function. Additional experiments on reinforcement learning are given in
appendix.
5 Conclusion
In this paper, we propose the variance reduction based method for the strongly convex and non-
convex composition problems. We apply the stochastically controlled stochastic gradient to estimate
inner function G(x) and the gradient of f(x). The query complexity of our proposed algorithm is
better than or equal to the current methods on both strongly convex and non-convex functions.
Furthermore, we also present the corresponding mini-batch version of the proposed method, in
which the query complexities are improved as well. Experimental results also confirm that our
algorithm achieves better query complexity in a real-world problem.
8
Under review as a conference paper at ICLR 2020
References
Zeyuan Allen-Zhu. Natasha 2: Faster Non-Convex Optimization Than SGD.	ArXiv,
abs/1708.08694, 2017.
Zeyuan Allen-Zhu. Katyusha: The first direct acceleration of stochastic gradient methods. In Sym-
posium on Theory of Computing, 2017.
Stephen Boyd. Alternating direction method of multipliers. In Talk at NIPS Workshop on Optimiza-
tion and Machine Learning, 2011.
Adithya M Devraj and Jianshu Chen. Stochastic variance reduced primal dual algorithms for empir-
ical composition optimization. arXiv preprint arXiv:1907.09150, 2019.
Onur Dikmen, Zhirong Yang, and Erkki Oja. Learning the information divergence. IEEE transac-
tions on pattern analysis and machine intelligence, 37(7):1442-1454, 2015.
Saeed Ghadimi and Guanghui Lan. Accelerated gradient methods for nonconvex nonlinear and
stochastic programming. Mathematical Programming, 156(1-2):59-99, 2016.
Saeed Ghadimi, Andrzej RUszczynski, and Mengdi Wang. A single time-scale stochastic approxi-
mation method for nested stochastic optimization. arXiv preprint arXiv:1812.01094, 2018.
Geoffrey E Hinton and Sam T Roweis. Stochastic neighbor embedding. In Neural Information
Processing Systems, pp. 857-864, 2003.
ZhoUyUan HUo, Bin GU, Ji LiU, and Heng HUang. Accelerated method for stochastic composition
optimization with nonsmooth regUlarization. In Thirty-Second AAAI Conference on Artificial
Intelligence, 2018.
Rie Johnson and Tong Zhang. Accelerating stochastic gradient descent Using predictive variance
redUction. In Neural Information Processing Systems, pp. 315-323, 2013.
LihUa Lei and Michael Jordan. Less than a single pass: Stochastically controlled stochastic gradient.
In Artificial Intelligence and Statistics, pp. 148-156, 2017.
LihUa Lei, Cheng JU, Jianbo Chen, and Michael I Jordan. Non-convex finite-sUm optimization via
scsg methods. In Neural Information Processing Systems, pp. 2348-2358, 2017.
XiangrU Lian, Mengdi Wang, and Ji LiU. Finite-sUm composition optimization via variance redUced
gradient descent. In Artificial Intelligence and Statistics, 2017.
Qihang Lin, Zhaosong LU, and Lin Xiao. An accelerated proximal coordinate gradient method. In
Neural Information Processing Systems, pp. 3059-3067, 2014.
Qihang Lin, Zhaosong LU, and Lin Xiao. An accelerated randomized proximal coordinate gra-
dient method and its application to regUlarized empirical risk minimization. SIAM Journal on
Optimization, pp. 2244-2273, 2015.
Tianyi Lin, ChenyoU Fan, Mengdi Wang, and Michael I Jordan. Improved oracle complexity for
stochastic compositional variance redUced gradient. arXiv preprint arXiv:1806.00458, 2018.
Ji LiU, Mengdi Wang, and Ethan Fang. Accelerating stochastic composition optimization. In Neural
Information Processing Systems, pp. 1714-1722, 2016.
LiU LiU, Ji LiU, and Dacheng Tao. DUality-free methods for stochastic composition optimization.
arXiv preprint arXiv:1710.09554, 2017a.
LiU LiU, Ji LiU, and Dacheng Tao. Variance redUced methods for non-convex composition optimiza-
tion. arXiv preprint arXiv:1711.04416, 2017b.
LiU LiU, Minhao Cheng, Cho-JUi Hsieh, and Dacheng Tao. Stochastic zeroth-order optimization via
variance redUction method. arXiv preprint arXiv:1805.11811, 2018.
YUrii Nesterov. Introductory lectures on convex optimization: A basic course, volUme 87. Springer
Science & BUsiness Media, 2013.
9
Under review as a conference paper at ICLR 2020
Sashank J Reddi, Ahmed Hefny, Suvrit Sra, Barnabas Poczos, and Alex Smola. Stochastic variance
reduction for nonconvex optimization. In International Conference on Machine Learning, pp.
314-323,2016.
Shai Shalev-Shwartz and Tong Zhang. Stochastic dual coordinate ascent methods for regularized
loss minimization. Journal of Machine Learning Research, 14(Feb):567-599, 2013.
Shai Shalev-Shwartz and Tong Zhang. Accelerated proximal stochastic dual coordinate ascent for
regularized loss minimization. In International Conference on Machine Learning, pp. 64-72,
2014.
Richard S Sutton, Andrew G Barto, et al. Reinforcement learning: An introduction. MIT press,
1998.
Mengdi Wang, Ethan X Fang, and Han Liu. Stochastic compositional gradient descent: algorithms
for minimizing compositions of expected-value functions. Mathematical Programming, 161(1-2):
419-449, 2017.
Lin Xiao and Tong Zhang. A proximal stochastic gradient method with progressive variance reduc-
tion. SIAM Journal on Optimization, 24(4):2057-2075, 2014.
Yue Yu and Longbo Huang. Fast stochastic variance reduced admm for stochastic composition
optimization. In International Joint Conferences on Artificial Intelligence, 2017.
Huizhuo Yuan, Xiangru Lian, Chris Junchi Li, and Liu Ji. Efficient non-convex stochastic compo-
sitional optimization algorithm via stochastic recursive gradient descent. In Neural Information
Processing Systems, 2019.
Junyu Zhang and Lin Xiao. A composite randomized incremental gradient method. In International
Conference on Machine Learning, pp. 7454-7462, 2019.
10
Under review as a conference paper at ICLR 2020
A	Technical Tool
For the subset A ⊆ [n], we present the following lemma that the variance of a random variable
decreases by a factor |A| if we choose |A| independent elements from [n] and average them. The
proof process is trivial However, it is an important tool for analyzing the query complexity under the
different sizes of the subsets.
Lemma 1. If v1, ..., vn ∈ Rd satisfy Pin=1 vi = ~0, and A is a non-empty, uniform random subset of
[n] and A = |A|, that is elements in A are uniformly selected from [n] without replacement, then
n
EAll 1 Pb∈AVb∣∣2≤ I(A<n) 1P l∣Vi∣l2.
i=1
Furthermore, if elements in A are independently selected from [n] with replacement,, then
n
EAll A Pb∈AVbll2 = An P l∣Vill2.
i=1
Proof. Based on the Pin=1 vi = ~0, and permutation and combination,
For the case that A is a non-empty, uniformly random subset of [n], we have
EAHXb∈A Vbll2 =EA hXb∈A kvbk2i + C⅛ X *Vi, C⅛1) X Vj +
n i∈[n]	i6=j
=AI Xn=Jvik2+Ai⅛ XJVW=j VjE
=AI Xn=Jvik2+A(A - 1) Xi∈[n] hVi, -Vii
=A(n甘 1 Xn>ik2
≤AI (A<n) 1 Xi=Ikvik2,
where CAn refer to the number of the combination of n things taken A at a time without repetition.
Thus, we have
Ea| AXb∈A Vbll2 = A2EAllXb∈A Vbll2 ≤ — 1 X kVik2
i=1
For the case that the element in A is randomly and independently selected from [n], we have
EAlllXb∈A Vblll2 =EA hXb∈A kVbk2i + 2EA hX1≤b<A DVb, Xb<k≤A VkEi
=Bn Xnvik2 + 2EA hXi≤b<A DE [V] , Xb<k≤A VkEi
=AI Xn=Jvik2+a (A - ɪ) kE [v]k2	⑶I)
=AI Xn=Jvik2.
□
Based on Lemma 1, we can obtain the inequality with two-variables D1 and D2, which are used for
the gradient of f (x).
11
Under review as a conference paper at ICLR 2020
Lemma 2. If wι,...,wn ∈ RM×N and vι,...,vn ∈ RM satisfy (1 Pi∈[n] Wi)T(1 Pj∈[n]Vj)=
WTv, and D = [Di, D2] is a non-empty, uniform random subset consist of Di and D2, which are
independently and uniformly selected from [n], D = |D1| = |D2 |, then
ED ∣DΓ1D∣ (Xdl∈Dl wdi)T (Xd2∈D2 vd2) - Wv
=ED D (XMd2]∈D ((WdI )Tvd2 - WTv))
I (D2 < n2) 1 G H τ —t —∣∣2
≤ —D— n Σ H(Wi) Vj-W vII.
i,j=i
B B ound analysis of SCCG for the composition problem
B.1 Bounds analysis of the estimated function and the gradient
Here, We mainly give different kinds of bounds for the proposed algorithm, such as Ear k Gk -
G(Xk)k2, EDkEA,ik,jJVfk] — Vf(xk)k2 and Ei%,%,a,d∣∣Vfk - Vf(Xk)k2. Thesebounds will be
used to analyze the convergence rate and query complexity. These bounds are all based on Assump-
tion 1. Parameters such as BG, BF, LG, LF and Lf in the bound are all from these Assumptions.
We do not define the exact value of parameters such as h, A and D, which have a great influence on
the convergence but will be clearly defined in the query analysis. Our proposed bounds are similar
to that of (Lian et al., 2017; Liu et al., 2017a;b), but, the difference lies on that there is an extra
subset D, which shows an interesting phenomenon. That is when the subset D is equal to [n], the
corresponding bounds are the same as in (Lian et al., 2017; Liu et al., 2017a;b). However, it is the
independent subset D that gives more general query complexity result for the problem (1.1). The
following bounds are all used for the composition problem for both convex and non-convex prob-
lems based on the Lemma 1 and Lemma 2. For simplicity, we drop the superscript ik, jk, A and D
for the expectation with E in the proof.
Lemma 3. Suppose Assumption 1 holds, for G^k defined in (3.3) with D = |Di ∣ and A = ∣A∣, we
have
Ea,DikGk - G(xk)k2 ≤ 4I(A<n) BGEkXk - Xsk2 + 6I (D‹ n) Hi.
AD
_	一一 一 一一..	一公，.一 一.	一
Proof. By the definition of Gk in (3.3), we have
EIlG k - G(Xk )k2 =EIlGk - GDI (Xk ) + GDI (Xk ) - G(Xk)112
≤2EkGk - GDI (Xk)Il 2 + 2EIlGDI (Xk ) - G(Xk )k2
≤ 4 I (Ajn) BG EkXk - Xsk2 +6 I (Dj n) Hi,
AD
where 1 follows from ∣∣ai + a2∣∣2 ≤ 2a2i + 2a22; 2 is based on Lemma 1 and the following
inequality: Through adding and subtracting the term G(Xk) 一 G(Xs), we have
EkGk - GDi(Xk)k2
=EkGA(Xk) - Ga(Xs) + Gdi (Xs) - Gdi(Xk)k2
=EkGA(Xk) - Ga(Xs) - (G(Xk) - G(Xs)) + (G(Xk) - G(XS)) + Gdi(XS)- Gdi(Xk)k2
≤1	2	2
≤2EkGA(Xk) - GA(XS)-(G(Xk ) - G(XS))) k + 2EkGDI (XS)- GDI (Xk ) - (G(XS)- G(Xk))∣∣
≤2 ——A )EikGi(XS)- Gi(Xk)『+ 2EkGDI (XS)- G(XS)『+ 2Ek-GDI (Xk) + G(Xk)『
≤ 2 I(A：n) BG EkXk- Xsk2 +4 I (Dj n) Hi,
AD
12
Under review as a conference paper at ICLR 2020
where 1 follows from ||a + b||2 ≤ 2a2 +2b2; 2 is based on Lemma 1; 3 follows from the bounded
function of G and the upper bound of variance of G. Note that A and xk are independent; and D
and Xs are independent.	□
Lemma 4. Suppose Assumption 1 holds, for Gk defined in (3.3) and Vfk defined in (3.4) with
D = [D1,D2] andD = |D1| = |D2|, we have
ED kEA,ik,jk [Vfk ] -Vf (Xk )k2 ≤4BG LF(4 I (Ajn)) EkXk- χs∣2
+ 32B2 L2 I(D <n) H 4I(D2 < n2) H
+ 32BGLF------H-----H1 + 4---772---H2.
D	D2
Proof. Through adding and subtracting the terms of
(∂G(xk))tVF(G(xk)), (∂Gdi (Xs))TVFDI (G(Xs)), (∂G(Xs))TVF(G(Xs)),
we have
EDkEA,ik,jk [Vfk] - Vf(Xk)k2
=EikdG(Xk ))tVF (G^ k) - (∂G(Xs ))tVF (Gdi (Xs)) + VfD (Xs) - Vf(Xk )∣∣2
≤4E∣∣(∂G(Xk))tVF(Gk) - (∂G(Xk))tVF(G(Xk))∣∣2
+ 4E∣∣(∂G(Xs))τVF(G(Xs)) - (∂G(Xs))τVF(Gdi(Xs))∣∣2
+ 4E∣∣VfD(Xs) - (∂Gdi(Xs))TVFD2(G(Xs))∣∣2
+ 4E∣∣(∂Gdi(Xs))τVFD2(G(Xs)) - (∂G(Xs))τVF(G(Xs))∣∣2
≤4BGLFE∣∣Gk - G(Xk)∣∣2 + 4BGLFEkG(Xs)- Gdi(Xs)∣2 + 4BGLFEkG(Xs)- G^(Xs)∣2 + 4I(D2D< n2)%
≤ 4BG LF(4 I(A< n)) EkXk - Xsk2 +32BG LF I(Dj n) Hi +4 I(D2'肾 H,
A	D	D2
where 1 follows from ||a1 + a2 + a3 + a4 ||2 ≤ 4a21 + 4a22 + 4a23 + 4a42 ; 2 is based on the
bounded Jacobian of G and the smoothness of F in Assumption 1, and the upper bound of variance
in Lemma 2. 3 is based on Lemma 3 and the upper bound of variance of G(X). Note that A and Xk
are independent; and D and Xs are independent.	□
Lemma 5. Suppose Assumption 1 holds, for Gk defined in (3.3) and Vfk defined in (3.4) with
D= [D1,D2] andD = |D1| = |D2|, we have
Eik,jk,A,DIVfk-Vf (Xk )k2
≤40BG LF I(DD
2
n
<
2
(D
I(
H2
+5BGLF ( B⅛⅛
-
k
X
Ek
2
D
4
+
A
Proof. Through adding and subtracting the term of (∂Gj(Xk))TVFi(G(Xk)),
(∂Gj(Xs))τVFi(G(Xs)), (∂G(Xs))τVF(G(Xs)), (dG^ (Xs))TVFDI(G(Xs)) (Note that, D
and Xs are independent), We have
EkVfk-Vf(Xk )k2
=E∣∣(∂Gj(Xk))TVFi(Gk) - (∂Gj(Xs))TVFi(GDI(Xs)) + VfD(Xs) - Vf(Xk)∣∣2
≤1	2
≤5E∣∣(∂Gj(Xk))TVFi(G(Xk)) - (∂Gj(Xs))TVFi(G(Xs))-(Vf(Xk) - (∂G(Xs))τVF(G(Xs)))∣∣
13
Under review as a conference paper at ICLR 2020
+ 5E∣∣(∂Gj(Xk))TVFi(Gk) - (∂Gj(Xk))TVFi(G(Xk))『
+ 5E∣∣ (∂Gj(Xs))TVFi(G(Xs))- (∂Gj(Xs))TVFi(GDI (Xs)) ∣∣2
+ 5E∣∣VfD(Xs) - (∂Gdi(Xs))TVFD2(G(Xs))∣∣2
+ 5E∣∣(∂Gdi(Xs))TVFD2(G(Xs))-(∂G(Xs))TVF(G(Xs))∣∣2
≤5Lf EkXk - Xsk2 + 5BGLFE∣∣Gk - G(Xk)∣∣2 + 5BGLFEkG(Xs)- Gd、(Xs)∣∣2
+ 5BGLFEkG(Xs) - Gdi(Xs)k2 + 5I(D" n2)H
D2
≤5BGLF (Bf + 4I(A<n)! EkXk- Xsk2 + 40BGLFI(DD< n) H + 5I(DD< n H2
where 1 follows from ||a1 + a2 + a3 + a4 + a5||2 ≤ 5a12 + 5a22 + 5a32 + 5a42 + 5a52; 2 is based
on E[kX - E[X]k2] = E[X2 - kE[X]k2] ≤ E[X2], the smoothness of Fi, the bounded Jacobian of
G(X) and the smoothness of F in Assumption 1, and the upper bound of the variance. 3 is based
on Lemma 3.	□
As can be seen from the above results directly, when A and D increase, the upper bounds are close
to the bounds in (Lian et al., 2017; Liu et al., 2017a;b). Though there are extra terms with respect to
A and D, they give us another direction for analyzing the convergence rate and query complexity.
The convergence rate not only depends on the convergence sequence, but also the terms including
the event function I. Thus, we can obtain the lower bound range of A and D that is related to .
Furthermore, this lemma can be applied to analyze the convergence rate and query complexity of
the convex and non-convex composition problem.
C Proof of SCCG method for composition problem
C.1 Proof of SCCG method for Strongly convex composition problem
In this section, we analyze the proposed algorithm for the strongly convex composition problem. We
first present the convergence of the proposed algorithm and then give the query complexity. Though
the proof is similar to that of (Lian et al., 2017) and (Xiao & Zhang, 2014), we present a more
clear and simple process as there is an extra term derived from the subset D. In order to ensure the
convergence of the proposed algorithm, we obtain the desired parameters’ setting, such as A, D, K,
η and h. Based on the setting, we can obtain the corresponding query complexity, which is better
than or equal to the SVRG-based method in (Lian et al., 2017) and (Liu et al., 2017a). This is in fact
that the event function I has an influence on the size of A and D.
C.1.1 Convergence analysis
Based on the strong convex and smoothness of the function of f (X), we provide the convergence
sequence, in which the parameters are not defined. But the sequences motivate us to consider the
parameters, setting such that lead to the desired convergence rate. Note that, D and Xs are indepen-
dent.
Theorem 3. Suppose Assumption 1 holds, in Algorithm 1, let h > 0, η > 0, A = |A|, D = |D1| =
∣D21, K is the number ofthe inner iteration, x* is the optimal point, we have
EkXS - x*k2 ≤ PSEkXo - χ*k2 + 空FS,
ρ1 1 - ρ
where P = (K^ + P2)∕ρ1, P2 and ρ3 defined (V, V1 are defined in (C.4) and(C.5).)
Pi = (2μ — h — 4V｝一(12Lf + 10V) η) η,	(C.1)
14
Under review as a conference paper at ICLR 2020
P2 =2(2Vh ÷5 (Lf + V) η) η,
1 4τr 2
P3 =τη三匕 ÷ 2η2V1.
h 5
(C.2)
(C.3)
Proof. By the update of Xk in Algorithm 1, we have
E∣∣xk+ι - χ"∣2
=EkXk - x* k2 - 2ηE"fk,Xk - x*〉÷ η2E∣∣ V川2
=EkXk- x*k2 - 2ηE"∕(xk) ÷ 旧人,[v『k] - Vf(Xk ),Xk - x*i ÷ η2E ∣ ∣ V,fk∣∣
=EkXk - x* k2 - 2ηE"f (xk), Xk - x*〉- 2ηE(EA,i,j [v/k] - Vf(Xk), Xk - x*〉
÷ η2E ∣ ∣ Vfk ÷ Vf (Xk) -Vf (xk) ∣ ∣ 2
≤ EkXk - X* k2 - 2ημEkxk - x*k2 ÷ η1 E 悔,切 ∣Vfk ] - Vf (Xk) ∣ ∣ 2 ÷ hηE∣∣Xk - x*『
÷ 2η2 (EkVf(Xk )k2 ÷ E ∣ ∣ Vfk- Vf(Xk) ∣ ∣)
=EkXk- x*k2 - (2ημ - hη)E∣∣Xk - x*『÷ η1 旧胆从切 ∣Vfk] - Vf(Xk) ∣ ∣
÷2η2 (EkVf(Xk) -Vf(x*)k2 ÷ E∣ ∣ Vfk-Vf(Xk) ∣ ∣)
≤Ekxk - x*k2 - (2ημ - hη)E∣∣Xk - x*k2 ÷ η1(4V∣∣Xk - Xsk2 ÷ V2)
÷ 2η2(LfE||xk — x*『÷ 5 (Lf ÷ V) ∣∣Xk — Xs『÷ V.)
=EkXk - x*k2 -(2〃 - h - 4V1 - (12Lf ÷ 10V) η) ηE∣∣xk - x*∣2
÷2 0V1÷5 (Lf ÷ V) η) ηEkXs - x*『÷ ɪηV2 ÷2η2V1,
where
V =BGLF(4I(A；n)) ,	(C.4)
Vi =40BGLF I(Dj n) H1 ÷ 51(D2J n2) H2,	(C.5)
D	D2
V2 =32BGLFI(Dj n) Hi ÷ 41(D2J n2) H2 = 4Vi,	(C.6)
D	D2	5
① is based on ||ai ÷ α2∣∣2 ≤ 2α2 ÷ 2α2 and (ɑi, α2i ≤ h∣∣ɑι∣∣2 ÷ ɪ∣∣α2∣∣2, h > 0;② is based on
strongly-convex of f in Assumption 1, and Lemma 4, 5.
Summing UP from k = 0 to k = K - 1, we have
K-i
EkXK - x*k2 ≤ EkXO - x*k2 - Pi X E∣∣Xk 一 x*k2 ÷ Kρ2E ∣∣Xs 一 x*k ÷ Kρ3,
k=0
where
pi = 0μ — h — 4V ɪ — (12Lf ÷ 10V) η) η,
P2 =2 (2Vh ÷ 5 (Lf ÷ V) η) η,
15
Under review as a conference paper at ICLR 2020
12
P3 =T ηV2 + 2η2V1.
h
For xo = Xs, by arranging, We have
ρ1E∣∣Xs+1 - χ*k2 ≤-1 E∣∣χo - x*k2 + ρ2E∣∣Xs - x*『+ ρ3 - ɪEIlxK - x*『
KK
≤ (K + P) Ekxs - x*『+ ρ3.
We assume that ρ1 > 0 in (C.1), then We can obtain
S
EkxS - x*k2 ≤PSEkxo- x*k2 + — XPs
ρ1 s=0
≤PSEkxo - x*k2 + — 1-ρS-,	(C.7)
P1 1 - P
where P =(KK + ρ2)∕ρ1, ρ2 and ρ3 defined in (C.2) and (C.3), the last inequality is based on the
formula of geometric progression.	□
Thus, if xs converges to the optimal point x*, we need to ensure that ρ < 1 and the second term
P3(1- PS)∕(P1(1- P)) is less than ∕2. Actually, ifD = n, the second term is equal to zero, which
will be similar to the convergence results in (Lian et al., 2017) and (Liu et al., 2017a).
Proof of Theorem 1
Proof. In order to keep the proposed algorithm converge, we consider the parameters’ setting, we
first ensure that P1 > 0 in (C.1), and then define
P = (~F7 + ρ2"ρ1,	(C.8)
K
that require P < 1, where P2 defined in (C.2). Thus, the convergence sequence is
PS	P1
EkxS - x*k2 ≤ PSEkxO- x*k2 + - VPs ≤ PSEkxo - x*k2 + -;—.
P1 s=o	P1 1- P
We ensure ρ3 ɪ--^ ≤ ɪe, where P3 defined in (C.3), that we can derive the size of the D. In the
following we analyze the parameters’ setting such that satisfying the above requirement.
1. In order to ensure P1 > 0 in (C.1), we consider the parameter h, η and A,
(a)
(b)
h = μ, consider pi in (C.1), we should require that h ≤ μ, however, V in (C.4) has the
relationship with A and D. In order to keep A small enough, we set the upper bound
of h. Thus, we set h = μ.
A = min {n, 128B&LFμ20
Thus, we have
, based on the setting of h, we require that V∕h <
μ
16.
V = BGLF(4I(A<n)) ≤ 8BGLFI(A<n) ≤ ⅛μ2.
For V defined in (C.4), ifA < n, we have
A ≥ 128BGLFμ2,
otherwise, A = n satisfy the requirement. Thus, we have A
min {n, 128BGLFμ2}.
≤ 44 μn ≤
≤ 12Lf +10 Lf ≤
the definition in
(c)
η ≤ 5∣μτ, back to the target of ρι > 0, we require that η ≤ 5∣μ2
3 μ = μ-41V	=	2μ-h—4 hV	t th t ≤ L b
12Lf +10μ2 = 12Lf + 10V = 2Lf + 10(Lf +V), note that 〃 ≤ Lf by
preliminaries.
16
Under review as a conference paper at ICLR 2020
2.	In order to ensure ρ < 1 in (C.8), we first consider ρ1 and ρ2 in (C.1) and (C.2). By the
setting of h = μ and V < μ2∕16, We have,
ρι ≥ (μ - 2Lfη - (4μ + 10 (L
ρ2 ≤4 μη 116μ2 + 10 (Lf + 116μ2
+ 116μ)η))η ≥
η2 ≤ ɑ μ +10 1L
We require that P = KP^ + ρ2 < 1, and analyze the two terms separately,
(a)	In order to p2 < ɪ, that is
ρ2 <(4μ + 885Lfη)η < 1
ρ1 < (4μ -崂Lfn) η < 2.
Weget n ≤ i3μLf.
(b)	In order to K^ < 2, that is
IIV	1
Kρl	2Kρ2 —2K (1 μ +10 (Lf + 16μ2) n) n
1	1	1
1k (1 μ + 885Lfn) n ≤ 2K (4μn) < 2.
Thus, we have K ≥ 540 Lf.
,	μ2
3.	Consider the term PSE∣∣x0 - χ*∣∣2 + ρ34-ρ, we analyze them separately,
(a)	In order to ensure P3 4-ρ ≤ 4 e, that is
P3_______1_________ =	P3	≤	P3	≤	P3	≤	2ρ3	≤ 1 ^
P1 1 -	(K4-	+	p2)	ρ1 - KK -	ρ2	—	ρ1	- KK - 2P1	—	2 ρ1	- KK _ ρ1 _ 2
Based on the bound of P4 in (C.9), the definition of V4 in (C.5) and the step size n
mentioned above, we have
i. For V
μ nV2 + 2n2V4	4 V2 + 2nV4	4 μ V4 + 2nV4	(5μ + 2n)V4
ρι	3 μ - 404 Lfn	3 μ - 484 Lfn	4μ - 404 Lf n ―
thus, we have
Vl ≤ 5 eμ2
(3 - 4°4i⅛)
5 + 135
eμ2 ≤
ɪ + 2 —μ^
5μ + 4 135μ2
4μ - 484
5μ +2 13μLf
e ≤ 3 μ -崂 Lfn e
一(577 + 2ni
ii. If D <
wise D
n,
0,
we can obtain D ≥ 4^2(20BGLFHi +5H2),
the above inequality is correct. Thus, we obtain
other-
D=
≤
≤
min
(b)	In order to ensure PS E∣Xo - χ*∣2 ≤ 4 e, we need the number of the outer iterations
S ≥——1——
—lOg(I/P)
1 2E∣Xo - x*k2
log-----------
17
Under review as a conference paper at ICLR 2020
All in all, we consider the query complexity based on above parameters’ setting. For each outer
iteration, there will be (D + KA) queries. Thus, the query complexity is
(D + KA) S = O
log (1/)
□
C.2 Proof of SCCG method for Non-convex composition problem
C.2. 1 Related bounds
Lemma 6. Suppose Assumption 1 hold, in Algorithm 1, we can obtain the following new sequence
with respect to f (XGand ||xk 一 Xs∣∣2 ,let h > 0,η> 0, A = |A| and D = ∣Dι∣ = ∣D21, we have
E[f(xk+ι)] + Ck+1E∣∣Xk+1 - Xsk2 ≤ E[f(Xk)] + CkEIlxk - Xs∣∣2 — UkIVf(Xk)k2 + Jk,
where
W =BG LF(4 I(A产+4 当户)， Ck =ck+ι (1 + (h + 4hW) n + 10 (Lf + W) n2)	(C.11)
+2Wn+5(Lf2 +W)Lfn2,	(C.12)
Uk = ( (2 一 hck+l) n 一 (Lf + 2ck+1) n2),	(C.13)
W _20B2 L2 I(D <n) H 51(D2 < n2) H W1 =20BglF	h H1 + 5	R2	H2, D	D2	(C.14)
Jk = (2 + hck + 1 ) 5WIn + (Lf + 2ck+1) Win2.	(C.15)
Proof. Consider the upper bound of f (χk+ι) and ∣∣Xk+ι — Xs ∣2, respectively,
• Base on the smoothness off in Assumption 1 and take expectation with respective to ik, jk,
we have
Ei,j [f (Xk+1)]
≤E[f(Xk)] 一ηE(Vf(Xk), Vfki + Lη2E∣∣v.fk∣∣2
=E [f (Xk)] 一 ηEhVf (Xk), Vfk- Vf(Xk) + Vf(Xk) + Lf η2E∣ vfk∣∣2
=E [f (Xk)] 一 ηEhVf (Xk), Vf(Xk)i 一 ηhVf (Xk), E [Vfk] - Vf (Xk)i + L2fη2E∣∣Vfk - Vf(Xk) + Vf(Xk)∣∣2
≤E [f (Xk)] 一 ηE∣Vf (Xk)k2 + 1 ηE∣Vf(Xk)k2 + 2〃旧网切[Vfki - Vf(Xk)∣∣2
+ Lfη2 (2EkVf(Xk)k2 + 2E∣∣Vfk - Vf(Xk)∣∣2)
=E[f(Xk)] 一 1 ηE∣Vf(Xk)k2 + 2ηE∣∣EA,i,j [Vfki - Vf(Xk)∣∣2 + Lfη2 (EkVf(Xk)k2 + E∣∣Vfk - Vf(Xk)『；
=E [f (Xk)] 一 (1 η - Lfnr EkVf(Xk)k2 + 2ηE∣∣EA,i,j [Vfk] -Vf(Xk)∣∣2 + Lfn2E∣∣Vfk-Vf(Xk)∣∣2,
where the last inequality is based on ||a1 + a2 ||2 ≤ 2a21 + 2a22.
18
Under review as a conference paper at ICLR 2020
• Base on the update of Xk in Algorithm 1 and take expectation with respective to ik, jk, we
have,
Ei.jkxk+1 - xs k
=EkXk - Xsk2 - 2ηE"fk,Xk - Xs〉+ η2E ∣ ∣ VfkII
=EkXk - XS
=EkXk - XS
k2
k2
-2ηE”fk - Vf (xk) + Vf (xk), Xk - XS〉] + η2E∣ Vk ∣∣2
-2ηEhVf(xk),Xk - Xs〉] - 2η<E [V『k] -Vf(Xk),Xk 一 Xs〉]
2
+ η2E∣∣V.fk -Vf (xk) + Vf (xkM
≤EE - XSk2 + hη∣∣Vf(xk)『+ hη∣ ∣ E [vfk] - Vf(Xk)『+ |ηE∣∣Xk - Xs『
+ η2 (⅛Vf(xk)k2 + 2E∣ ∣ Vfk - Vf (xk) ∣ ∣[
〜
=(1 + 2η) EkXk - Xsk2 + (hη + 2η2) EkVf(Xk)『+ hηE∣∣E ∣Vfk] - Vf(Xk) ∣ ∣ 2 + 2η2E ∣ ∣ Vfk - Vf(Xk) ∣ ∣2,
where the inequality is based on 2(α1, b* ≤l∕hkα1k2+h∣∣α2k2, ∀h > 0, and ||ai+a21|2 ≤
2a2 + 202∙
Combine above equalities and Lemma 4, 5, we form a Lyapunov function,
E[f (xk+i)] + Ck+1E∣∣Xk+1 - Xsk2
=E[f(xk)] - (2η - Lfη2) ∣∣Vf(xk)k2 + 1η∣∣E 忖川-Vf(Xk)∣∣2 + Lfη2∣∣Vf - Vf(Xk)∣∣2
+ Ck+1 ((1 + hη) EkXk - Xsk2 + (hη + 2η2) ∣∣Vf (xk)『+ hη ∣ ∣ E ∣Vf ] - Vf(Xk) ∣ ∣ 2 + 2η2∣∣Vf - Vf(Xk)∣∣2
=E[f (xk)] + Ck+ι (1 + 2η) EkXk - Xsk2 -
Ck+ιh) η -(Lf + 2ck+ι) η2 ) ∣∣Vf(xk)∣∣2
+ (Lfη2 + 2η2Ck+1) ∣∣ Vfk- Vf(Xk )|| + Q η + hηck+1) ∣∣E [Vfk] - Vf(Xk )∣∣
≤E[f (xk)] + CkEkXk- Xsk2 - UkkVf(Xk)∣∣2 + Jk,
where
Uk
hck+1 η - (Lf + 2ck+1) η2 ；
W1 =40BGLFI(DD< n) H1 + 5
4
W2 =-Wi；
5
I(D2 < n2)
D2
H2；
Jk = ( 2 + hck + 1 ) W2η + (Lf + 2ck + 1) w1η2;
W =BG L2f 4
ck =ck+1	1 +
I (A<n)λ
Γ
(I + 4hWj η + 10 (Lf + W) η2) + 2Wη + 5(Lf + W )Lf η2.
□
Based on the above inequality with respect to the sequence E[f (Xk)] + CkEkXk - Xs k2 and Algo-
rithm 1, we can obtain the convergence form in which the parameters are not clear defined.
19
Under review as a conference paper at ICLR 2020
Theorem 4. In Algorithm 1, suppose Assumption 1 holds, we can obtain the following new sequence
with respect to f (Xk) and ||xk 一 Xs||2. K is the number ofinner iterations, S is the number ofinner
iterations, we have
u°E[kVf(Xk)k2] ≤ f(x0)J-f (x*) + Jo,
KS
where Xk is the output point, Jo and u° are defined in (C.15) and(C.13).
Proof. Based on the update for ck in (C.12), we can see that ck > ck+1. As ck is a decreasing
sequence, we have uo < uk and Jk < Jo . Then, we get
uoE[kVf (χk)k2] ≤ E[f(χk)] + CkE[∣∣Xk — Xsk2] - (E[f (χk+ι)] + Ck+1E[∣∣Xk+1 - Xsk2]) + Jo.
Sum from k = 0 to k = K - 1, we can get
1 K-1
K ∑uE[kVf(Xfc)k2] ≤
k=o
E[f (Xo)] —(E[f (xk )]+ CK E[∣∣xk - Xsk2])
K
+ Jo
≤
E[f(Xo)] — E[f(Xκ)]
K
+ Jo .
Since Xo = Xs, let Xs+ι = XK, We obtain,
K x uoE[kVf(Xfc)k2] ≤ Ef(Xs)I -KEf(Xs+1)] + J。.
k=o
Summing the outer iteration from s = 0 to S — , We have
S-1	K -1
uoE[kVf (Xk )k2]= 1 x K χuoE[kVf(Xsk)k2] +Jo
s=o k=o
≤ E[f(Xo)] — E[f(Xs)]
上 T f f (Xo) — f(X*)q T
+ JO ≤ —KS- + J
KS
where Xk indicates the s-th outer iteration at k-th inner iteration, and Xk is uniformly and randomly
chosen from S = {0,…,S — 1} and k={0,.., K - 1}.	白
C.2.2 Convergence analysis
Base on Algorithm 1, the analysis of convergence is based on the smoothness off(X) and the
update of X under the Lyapunov function to form the convergence sequence. Theorem 1 shows that
our proposed algorithm can converge to the stationary point.
The convergence proof is similar to that of (Liu et al., 2017b; Reddi et al., 2016), however, our
algorithm considers the inexact computation of the gradient at the beginning of each epoch. Thus,
we derive the different parameters’ setting. In particular, the number of the subset D and A depend
on the min function. Intuitively, we can compute the gradient and inner function based on the subset
rather on the whole sample. Moreover, considering the convergence results, we can see that the step
size η has the relationship with many parameters, such as the subset A, inner iteration K and the
total iteration T .
Proof of Theorem 2
Proof. In order to have E[kVf (Xk)k2] ≤ e, that is
E[kVf(Xk)k2] ≤ LfOSK(χ*)) + Jo/uo ≤ f + f ≤ e,
we consider the corresponding parameters’ setting:
20
Under review as a conference paper at ICLR 2020
1.	For the first term, consider ck defined in (C.12) define ck = ck+1Y + U, for k = K, we
have
CK = G) Q + 占)- 占,
where
Y =1+ (2 + 4hW)η + 10 (BG LF + W) η2,
U =2Wη + 5(Lf2 + W)Lfη2 > 0.
By setting cK → 0, we obtain
_ UYK U _ U (YK - 1)
c0 = Y - 1 - Y - 1 = -Y - 1-.
Then, putting the Y and U into the above equation. We have
c0
2Wη + 5(Lf + W )Lf η2
(2 + 4hW) η + 10 (Lf + W) η2
2W + 5(Lf2 + W)Lfη
(h2 + 4hW) + 10 (Lf + W)
C, (C.16)
η
where C = YK - 1. Because c0 has the influence on the parameters such as K, C and u0,
we analyze them separately,
(a)	For K and C, based on the character of function (1 + *)	→ e,6 as t1, t2 → +∞
and t1t2 < 1, and the function is also the increasing function with an upper bound of
e, we require
K < 1/( (2 + 4hW)η + 10 (Lf + W) η2
(C.17)
thus, we have C < e - 1.
(b)	For u0 defined in (C.13), in order to keep uk > 0, we need to keep c0h < 1/4. If
coh < 1/4, there exits a constant U such that uo = uη. In order to satisfy c°h < 1/4,
combine with (C.16) and C < e - 1, that is
h ≤	2W + 5(Lf + W )Lf η	h ( _n ≤ 1
°3 一(h2 + 4hW) + 10 (Lf + W) η ɛ — 4,
i.	By setting h =	713-, there exist W > 0, based on above inequality, We have
5 Lfη
W ≤	16Lf η + 50Lf.5 " < WLf η
9.6 + 34L3f η - 50 Lf3 ηη
Thus, combine With the definition ofW in (C.11), We require that
W = BG LF(41(AF)) ≤ 8BG LF I(A < n) ≤ WLf η = O (Lf η).
If A < n, We require A ≥ O BG4 L2F /(Lf3 η) . Thus, We have A =
min {n, O (1∕η)}.
ii.	Based on the setting ofh and W, combing With (C.17), We have
1
K<10
+ 5√Lfn WLf η) η+ 10 (Lf+ WLfη M
1
(10 JLf η + 5 JLf η) η + 10 (Lf + η) η2
6Here the ’e’ is the Euler number, approximate to 2.718.
O Gl⅛
21
Under review as a conference paper at ICLR 2020
2.	For the second term about J0, as u0 = w1η, we require
0T- =4 (W + hco ) W2 + (Lf + 2co) Win
un u ∖2 j
≤ 1 WI (3 + Lfn +1 n√n)
u5	2
≤u (20BGLFHI + 5H2)(5 + Lfn + n√n) —~D~~≤ ≤ 23
Then, if D < n, we require that
D ≥ 福(20BGLFHi + 5H2)(5 + 2Lfη + coη√η) = O (ɪ).
Thus, we set D = min {n, O(1/)}.
3. Based on the first term
2Lf(f(x0)-f(x*))
ηe	.
Lf(f(x0)-f(x*))
ηSK
≤ 1 e, the total number of iteration is T = SK
Thus, based on the above parameters, setting, We can ensure that E[kVf (Xk)Il2] ≤ e.
Based on the parameters’ setting, that is D = min {n, O(1/)}, A = min {n, O (1/n)}, K ≤
O (l∕n3/2), and T = O (1/ (eŋ)), we have,
O (T (D + KA)
where the optimal n = min 1/n2/5, 2/5 .
□
D Proof for the Mini-batch of the SCCG to the composition
PROBLEM
We provide the Mini-batch version of SCCG:
The following lemma is distinguish with Lemma 5 in which the estimated gradient γ is obtained
through b times repeat.
Lemma 7. Suppose Assumption 1 holds, for Gk defined in (3.3) and Λ defined in Algorithm 2 with
D = [Di, D2] and D = |Di| = |D2|, we have
Eikjk,A,D kΛ - Vf(Xk )k2 ≤5BG LF (^BLL2 + 4 I (A<n) + 4 I (Djn)) Ekxk- Xs∣2
+ 20BG LF I⅛ Hi +5 I¾8 H2,
Proof. Through adding and subtracting the term of b P (∂Gj(xk))TVFi(G(Xk)),
(i,j )∈Ib
b P (∂Gi(Xs))TVFi(G(Xs)), and (∂G(Xs))TVF(G(Xs)),	(∂Gd∖ (Xs))TTVFDI (G(Xs)),
(i,j)∈Ib
we have
EkΛ - Vf (Xk)k2
22
Under review as a conference paper at ICLR 2020
Algorithm 2 Mini-batch version of SCCG
Require: K, S, η (learning rate), Xo and D = [Di, D2]
for S = 0,1,2,…，S 一 1 do
Sample from [n] for D times to form mini-batch D1
Sample from [n] for D times to form mini-batch D2
PfD (Xs) = (∂Gdi (Xs))TVF⅛2 (Gdi (Xs))
xo = Xs
for k = 0,1, 2,…，K — 1 do
Sample from [n] to form mini-batch A
G k = GA(Xk) — Ga(Xs) + Gdi (Xs)
Λo = 0
for t=1,...,b do
Uniformly and randomly pick ik and jk from [n]
Compute the estimated gradient Vfk from (3.4)
Λt+1 = Λt + Vfk
end for
Λ = Λb∕b
Xk+1 = Xk — ηΛ
end for
Update Xs+i = XK, or Xs+i = Xr, r is randomly selected from [K - 1]
end for
Output: Xk is uniformly and randomly chosen from S ∈ {0,…，S — 1} and k ∈ {0,.., K — 1}.
2
≤5E b X (∂Gj(Xk))TVFi(G(Xk)) — (∂Gj(Xs))TVFi(G(Xs))- (Vf(xQ - (∂G(Xs))TVF(G(Xs)))
(i,j)∈Ib
+ 5E
+ 5E
2
：X (∂Gj (xk ))TVFi(Gk) — (∂Gj (xk))TVFi(G(Xk))
(i,j)∈Ib
2
；X (∂Gj(Xs))TVFi(G(Xs))-(∂Gj(Xs))TVFi(GDI(Xs))
(i,j)∈Ib
+ 5EIVfD (Xs) — (∂Gdi (Xs))TVFD2(G(Xs))『
+ 5E∣∣(∂Gdi (Xs))TVFD2(G(Xs))-(∂G(Xs))TVF (G(Xs))∣∣2
≤5∙LfE∣∣Xk — Xsk2 + 5BGLFE∣∣Gk — G(xk)∣∣2 + 5BGLFEkG(Xs)- Gdi(Xs)∣∣2
+ 5BGLFEkG(Xs) — Gdi(Xs)k2 + 5I(D" n2)H
D2
≤5BG LF (bBLL2 +4 I(A<n)! EkXk- Xsk2 +40BG LF I(DD< n) H + 5 I(DD< n H2
where 1 follows from ||ai + a2 + a3 + a4 + a5 ||2 ≤ 5a2i + 5a22 + 5a23 + 5a42 + 5a52, and 2 is
based on E[kX — E[X]k2] = E[X2 — kE[X]k2] ≤ E[X2] and Lemma 1, the smoothness of Fi,
the bounded Jacobian of G(X) and the smoothness of F in Assumption 1, and the upper bound of
variance in Lemma 2.③ is based on Lemma 3.	□
Proof of Corollary 2
23
Under review as a conference paper at ICLR 2020
Proof. Based on the parameters, setting, that is D = min {n, O(1∕e)}, A = min {n, O (b∕η)},
K ≤ O (b1/2/n3/2), and T = O (1/ (eη)), We have,
where the optimal η
O (K (D + KA)
E Experiment
E.1 risk-averse learning
To verify the effectiveness of the algorithm, We use the mean-variance optimization in portfolio
management7:
nn	n
min- X g,x + nX(hri,xi- n Xhri，Xi)2，
i=1	i=1	i=1
Where ri ∈ RN ， i ∈ [n] is the reWard vector, and x ∈ RN is the invested quantity. The objec-
tive function can be transformed as the composition of tWo finite-sum functions in (1.1) With the
folloWing forms:
Gj(X) =[x, hrj, χi]T, y = ； Xj=IGj(X) = [yι,y2]T,
Fi (y) = - hri， y1 i + (hri， y1 i - y2 )2 ， j， i ∈ [n].
Where y1 ∈ RM and y2 ∈ R.
Note that the function Gj (X) = [X， hrj ， Xi], and the corresponding Jacobian is [I， e]>, Where I ∈
RN ×N is a unit matrix, and e ∈ RN ×1 is all-ones vector. It is straightforWard to prove that the
norm of the Jacobian is bounded, i.e. Gj (X) is BG-Lipschitz. We choose such example of the
composition problem to verify the efficiency of the proposed algorithms, because it has been Widely
used in related researches (Lian et al., 2017; Wang et al., 2017; Lin et al., 2018). The source code
package Will be released as soon as possible to ensure the reproducibility.
E.2 Non-linear embedding
For the non-convex function, We apply the proposed SCCG method to the nonlinear embed-
ding problem in (1.2). We consider the distance of loW-dimension space betWeen Xi and Xj as
1/(1 + kXi - Xj k2), i， j ∈ [n]. Then, the problem can be formulated as the problem in (1.1). In
particular,
1n	1n 1n
n Xi=I Fi ⑹=n Xi=I Fi (n Xj=IGj (X))，
Where
1n
y = n Xj=IGj(X);
Gj(X)
n	ɪ	n
1 + ∣∣X1 - Xjk2	，	，1 + IlXn - Xjk2
T
;
Xn2
k=ιPkIi(Ilyi - y Il +log(yn+k)),i,j ∈ [n].
7This formulation is just used to verify our proposed algorithm.
24
Under review as a conference paper at ICLR 2020
Figure 3:	Non-convex: Comparison of the objective function between SCGD, ASC-PG and SCCG;
Dataset (from left to right): mnist, olivettifaces and coil20.
Note that, consider the function g (x) = 1+-2, its gradient is Vg (x) =1二？. For different value
1+x	(1+x )
of x, we can see that
|x| ≥ 1 ⇒(1 + x2)2 ≥ x;
|x| < 1 ⇒(1 + x2)2 ≥ 1 > x.
Thus, we obtain |Vg (x)| ≤ 2, which is upper bounded. Based on this results, we can obtain that the
norm of Jacobian is also bounded. Moreover, in practice, wo do not compute the Jacobian directly
as the dimension is large. The matrix of Jacobian is sparse due to the random subset, which greatly
save much space.
We consider three datasets: mnist, Olivetti faces and COIL-20 with different sample sizes and di-
mensions, 1000× 784, 400 × 4096 and 1440× 16384. Our experiment is to verify our proposed
algorithm, thus, we set D1 = D2 in default and choose three different sizes of sample set D1, which
are smaller than n. For example, for the case of mnist, we choose |D1| = 400, 600, 800, which
are denoted as SCCG (400), SCCG (600) and SCCG (800). Furthermore, we also set ∣A∣≈ n2/3,
where n is the total number of samples. Figure 2(in the main paper) shows the norm of the gradient,
and Figure 3 shows the function value. We compare our algorithm with stochastic gradient based
method (SCGD and ASC-PG) and observe that our proposed algorithm is better than SCGD and
ASC-PG on both the norm of the gradient and objective function.
E.3 Reinforcement learning
We consider the policy value evaluation in reinforcement learning. Let the policy of interest be π,
total states be S, and the value function of state be V π at state s1,
V π (s1) = Eπ {Rs1,s2 + γV π (s2) |s2} , s1, s2 ∈ [S],
where Rs1,s2 is the reward of moving from state s1 to s2, and the expectation is taking over state s2
conditioned on state si. We assume Vπ(S) ≈ΦTw* for some w* ∈ Rd, where Φ is the linear map
of the feature used to approximate the value of the state. Then, the problem can be formulated as the
Bellman residual minimization problem, that is
S /	S
mWnX (hφi,wi - XPinj (Ri,j + Y hφj, Wi)
where γ is a discount factor, rij is the random reward of transition from i to state j . Our proposed
algorithm can be applied to the above problem, which can be formulated as the composition problem
by taking
gj (w) =ShΦ1, wi , ..., hΦ2, wi , P1π,j (R1,j +γ hΦj,wi) , ..., PSπ,j (RS,j +γ hΦj, wi)T;
S
g(w) =Xgi (w) = y =	yy21 ;
j=1
fi (y) =Sky1,i - y2,ik2.
25
Under review as a conference paper at ICLR 2020
Vv5
en-e> e>=80
0
0	1
2	3	4	5	6
Number of queries	κ ιo7
en-e> e>=8"0
0.5	1	1.5	2	2.5	3	3.5
Number of queries	x108
Figure 4:	Reinforcement Learning application: Comparison of the objectively values between
SCGD, ASC-PG and SCCG (including three different values of ∣Dι∣= 0.95 * n, 0.9 * n, 0.8n);
Dataset (from left to right): n=500,1000, and 1500.
10-1
∙∙
-upτ-O UJ-ON
0	1	2	3	4	5	6
Number of queries
x107
∙u
-upτ-O UJ-ON
0	0.5	1	1.5	2	2.5	3	3.5
Number of queries	x108
-upτ-O UJ-ON
0	0.5	1	1.5	2	2.5	3	3.5	4	4.5	5
Number of queries	χio8
Figure 5:	Reinforcement Learning application: Comparison of the norm of gradient between SCGD,
ASC-PG and SCCG (including three different values of |D1|= 0.95 * n, 0.9*n, 0.8n); Dataset (from
left to right): n=500,1000, and 1500.
In the experiments, parameters Pπ, Φ and R are randomly selected. We implement on three data
with the size of n = 500, 1000, 1500. And we set |D1 | = 0.95 * n, 0.9 * n, 0.8n, respectively
for different value of n. We set b = ∣A∣≈ n2/3 based on our theory analysis. Figure 4 and 5
show the experimental results, which demonstrate that our proposed method is better than the non-
variance reduction based methods SCGD and ASC-PG on both the objective value and the norm of
the gradient.
26