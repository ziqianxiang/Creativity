Under review as a conference paper at ICLR 2020
Artificial Design: Modeling Artificial Super
Intelligence with Extended General Relativ-
ity and Universal Darwinism via Geometriza-
tion for Universal Design Automation
(Far from the Madding Crowd: How to Be
Shallow to Avoid Got Lost in Deep Forest?)
Anonymous authors
Paper under double-blind review
Ab stract
Let us share the joy of our unprecedented discovery with you: Physical Geometry
and Biological Geometry are the outcome of the physical laws and biological laws
respectively, and Artificial Super Intelligence (ASI) has to be a combination of
both design and learning instead of learning alone, with that we propose Artificial
Design, a bio-physical inspired mathematical model for Hierarchical Multi-Agent
Multi-Environment Model-agnostic Policy-agnostic Deep Reinforcement Learn-
ing (HMMMPDRL) based ASI by reusing and extending General Relativity and
Universal Darwinism with Geometrization. With Artificial Design we solve Deep
Reinforcement Learning blackbox puzzle in AI and ASI. By treating HMMM-
PDRL as multiverse regardless the mutual exclusiveness between Multi-Agent
and Multi-Environment, we reuse General Relativity’s 4-Dimensional Pseudo-
Riemannian Manifold based SpaceTime Model for Reinforcement Learning part
of HMMMPDRL, we also make a T-symmetry extension to General Relativity, re-
place N-Dimensional space with N-Dimensional GeneSpace, and formulate a N-
Dimensional Riemannian Manifold based GeneSpace Model for Deep Learning
part of HMMMPDRL, whereas Deep Learning architecture is adopted to approx-
imate very complex state-action space composed environments in HMMMPDRL.
By modeling ASI with Artificial Design rigorously in this way, we claim that intel-
ligence, whether natural, artificial, or super-artificial like ASI, is just the geometry
effect of N-Dimensional GeneSpace caused by Geometrization, and that paves the
way in achieving ASI through Universal Design Automation of Artificial Design
in theory. Of course, our Multiversal endeavor won’t stop from there, endorse us
to artificially co-accelerate human civilization in every possible way you might
imagine.
Index terms— Artificial Design, Artificial Super Intelligence, General Relativity, Universal Darwin-
ism, Geometrization, Gene, Manifold, Tensor, SpaceTime, GeneSpace, Deep Reinforcement Learn-
ing, Universal Approximation, Geometry Effect, Universal Design Automation, Universal Paradox
1	Introduction
Sage Laozi, in his book titled Tao Te Ching wrote in 6th century BC ago, with its ink on bamboo
version of the Warring States Era and unearthed in 1993, along with its ink on silk version of 2nd
century BC and unearthed in 1973 as both illustrated, said: Tao begets One, One begets Two, Two
begets Three, Three begets Everything. That is how the universe began, and here One refers to Taiji
as illustrated. It of course makes sense philosophically given the fact of such claim were made 2,500
years ago. Around the similar time frame when Laozi was alive, Greek Philosopher Pythagoras be-
lieved in multiverse (musica universalis) governed by mathematical equations, and metempsychosis
(transmigration of souls) holding that soul is immortal as cycling among different bodies, unfortu-
1
Under review as a conference paper at ICLR 2020
Figure 2: Tao Te Ching Ink on Bamboo
nately no excavation evidence so far yet. Anyway all make sense philosophically. Most recently,
German Philosopher Hegel said: What is rational is actual and what is actual is rational, which also
makes sense philosophically. So far so good, so where are we now?
Software is eating the world, yet AI is increasingly eating software and software-defined ev-
erything. The latest AI research now can generate and synthesize algorithms (hence software)
right from requirements as opposed to from just algorithms to software as before. What does it
mean to us as a software developer when 500,000 lines of source code via programming gets
replaced by 500 lines of TensorFlow 17 (even much less if in Keras) code via learning? Please
note, Apollo 11 mission controller’s source code has only 130,000 lines of assembly code, while
modern autopilot has millions of line of source code, and Tesla’s Autopilot has 400,000,000
lines of source code. Even with the capability of processing PB-scale big data pipeline in real-
time, and EB-scale big data lake in batch-mode, all powered by elastic public/private/hybrid cloud
computing/edge-computing in bare metal/Virtual Machine/Container through Infrastructure-as-
a-Service (IaaS)/Platform-as-a-Service (PaaS)/Software-as-a-Service (SaaS) leveraging Software-
Defined-Compute (SDC), Software-Defined-Network (SDN), Software-Defined-Storage (SDS).
Such mighty low cost high performance cloud computing equipped with millions of CPU/GPU
cores spanning multiple data centers in different data centers of same/different availability zone(s)
is making traditional HPC quickly obsolete nowadays, furthermore the upcoming 5G makes both
cloud computing/edge computing and edge-computing/edge computing seamless coordination in
real-time possible, please note in theory 5G has only 1ms delay, way below human’s 100ms re-
sponse time. Meanwhile Software Process, especially development, testing, delivery, deployment,
operation, has been significantly advanced due to the mature of Continuous Integration, Continu-
ous Delivery/Deployment (CI/CD), that yields multiple stable releases a day as de facto industry
standard as opposed to monthly/quarterly/yearly release in old non-elastic data center computing
days. The same true technically agile methodology can also applied to AI model training and serv-
ing seamlessly as well. Last but not the least, most recently an AI-chip startup in Silicon Valley
released a Wafer-Scale Chip with its die size bigger than an iPad, integrating 12 trillion transistors
with 40K AI cores, 18G on-chip memory, 9PB/s memory bandwidth, 100PB/s fabric bandwidth, in
TSMC 16nm process in attempting to overcome the downside of distributed processing brought by
SDC, SDN and SDS. With such paradigm shift in both hardware and software, now we are able to
Figure 3: Tao Te Ching Ink on Silk
2
Under review as a conference paper at ICLR 2020
model Deep Learning Neural Networks (DNN) 5 with billions of connections, millions of parame-
ters, hundreds of layers for real-life applications. However, even with such significant progress in
both software and hardware, the matter of fact is the degree of intelligence demonstrated by AI still
falls far behind of human intelligence in most cases.
General Relativity 1 and Darwinism 2 are cornerstones of universe and life respectively. General Rel-
ativity generalizes Special Relativity and refines Newton’s Law of Universal Gravitation, providing a
unified description of gravity as a geometric effect of Space and Time, or Spatial-Termporal (Space-
Time). The curvature of SpaceTime models gravity, and is directly related to the energy and mo-
mentum of whatever matter and radiation are present. The relationship is specified by the Einstein
Filed Equations. Darwinism is a theory of biological evolution developed by Darwin and others,
claiming that all species of organisms arise and develop through the natural selection of small, in-
herited variations that increase the individual’s ability to compete, survive, and reproduce. However,
when Darwinism was developed, there was no concept of gene yet. Neo-Darwinism6, also called the
Modern Evolutionary Synthesis, just like synthesis in Electronic Design Automation (EDA), gen-
erally denotes the integration of Charles Darwin’s theory of evolution by natural selection, Gregor
Mendel’s theory of genetics as the basis for biological inheritance, and mathematical population
genetics. Furthermore Universal Darwinism, a variety of approaches that extend Darwinism and
Neo-Darwinism beyond its original domain of biological evolution on Earth, was formulated in
a generalized version to apply to explain evolution in a wide variety of other domains, including
physics, psychology, economics, culture, medicine, computer science.
Among universe, multiverse, genes, brains, economies, games, blockchains, AI and ASI, even fluid
dynamics, one thing in common is their non-linearity as complex dynamical systems. Since the
claims on the similarity between man/brain and machine/computer made by those visionaries like
Turing, von Neumann, Wiener, Schrodinger, Shannon, McCarthy, and Minsky, followed by the dis-
covery of DNA structure by Watson and Crick 12, AI has been experiencing several boom and bust.
However even with the recent progress on Deep Learning, Reinforcement Learning 4, Meta Learning
(AutoML and AutoDL), Learning to Learn, Transfer Learning, Never-end Learning, in mimicking
they way how human and other living system learning by interacting with environment, and the
way how human’s and other living system’s brain operating based on ANN in the form of DNN,
implemented in both software and hardware, as well as the most recent encouraging results on AI’s
application on gaming , such as model-free/model-based board games, card games, and video games
with perfect/imperfect information such as Go (AlphaGo 13, AlphaZero 14), StarCraft (AlphaStar),
DeepStack, No-Limit Poker (Libratus)15, ATARI, Dota2, a clear sign of ascending from AI to ASI,
is definitely emerging, which might lead to a new kind of Grand Unification in the context of intelli-
gence. Actually the latest endeavor is Yang-Mills-Higgs Equations, which attempts to tackle Grand
Unification in physics by unifying gravitational theory such as General Relativity with Quantum
Electrodynamics, the electroweak theory, the standard model of particle physics, as Higgs field is
a theory of interactions of spin zero particles, and General Relativity is for spin two particles and
a symmetric rank-2 Tensor, the metric Tensor. Despite of impressive success achieved by the state-
of-the-art of Deep Reinforcement Learning 8 via various heuristics, there are a lot of cases where
it does not work at all or does not work well with current practice in real-life 19, for example, in
non-stationary partially observable dynamic safety-critical environment where exploration/training
and exploitation/serving cannot be separated in real-time. We believe that the root cause of such
weakness actually lies in not only the failure of establishing a consistent mathematical foundation
for ASI, but also the fiasco of understanding the nature and sources of intelligence in ASI from
bio-physical perspective.
EDA aims to fully automate/synthesize the whole production process ranging from specification,
design, manufacture, and even operation of semiconductor chips and its composed printed circuit
boards and electronic systems, in other words, EDA is all about synthesis, from Algorithm-level,
Hardware-system-level/Software-system-level, RTL/Source code-level, Gate-level/Assembly-level,
to Layout-level/Executable-level. Technically ASI through Artificial Design can be implemented in
either Life Synthesis or Robot Synthesis. Life Synthesis means living system, can be specified and
transformed step by step from gene to, protein, organelle, cell, tissue, organ, till body. While Life
Synthesis is still far away, biosynthesis such as gene synthesis and protein synthesis do work. Robot
Synthesis means intelligent robot, regardless of size and shape, can self-reproduce or self-replicate,
self-organize, and self-improve itself. Robot Synthesis is the more viable way as opposed to Life
Synthesis if we can leverage how the way the mature EDA industry works on synthesizing trillions
3
Under review as a conference paper at ICLR 2020
of transistors on a single System-On-a-Chip (SoC) possible nowadays. Similar to EDA for SoC, ASI
can be realized by Universal Design Automation of Artificial Design.
2	Complex System as AI and Vice Verse
Universes, multiverse, genes, brains, social network, economies, and blockchains among other sys-
tems are all complex systems for sure, but how complex are they? Complexity has different inter-
pretations in different contexts, such as system complexity, network complexity, and computational
complexity, etc. The key difference between complex system and complex network is, originally the
former focuses more on the external property, while the latter focuses more on the internal property.
However nowadays their difference has vanished.
Original complex network research focused on random graphs such as Erdos-Renyi model before
the rising of World Wide Web and the Internet. It arose with the discovery of small-world model,
followed by scale-free, power law model. Artificial Neural Networks, molecular networks including
gene regulatory networks for computational neurogentic modeling, protein-protein interaction net-
works in molecular kinetics, cell signaling networks with neural networks as its subset, metabolic
networks, food networks in ecosystems, and blockchains, are all complex networks and nonlinear
dynamical systems. The function of a dynamical system may be deterministic or stochastic depend-
ing on whether the mapping between an initial state and a final state is deterministic or stochastic.
A dynamical system’s time and state space can be either discrete and modeled by difference equa-
tions traditionally, or continuous and modeled by differential equations traditionally, with exam-
ples like Navier-Stokes Equations in fluid dynamics, the Lotka-Volterra Equations in ecology, and
Michaelis-Menten Equations in enzyme kinetics. A nonlinear system is a system in which the change
of the output is not proportional to the change of the input. Nonlinear dynamical systems, describing
changes in variables over time, may appear chaotic, unpredictable, or counter-intuitive, contrasting
with much simpler linear systems. A lot on nonlinear dynamical systems exhibit extreme sensitivity
to small perturbations in initial conditions, e.g., Lorenz system, can produce a phenomenon known
as chaos demonstrating butterfly effect. Actually chaos is temporal fractal, and fractal is spatial
chaos, both of them stem from dynamical systems. Initially chaos was recognized as in the three-
body problem in celestial mechanics. For a dynamical system to display chaotic behavior, it must be
either nonlinear with three or more dimensions or infinite-Dimensional if linear. The biggest chal-
lenge for complex heterogeneous networks right now is the combinatorial explosion due to the size,
non-linearity, and heterogeneous nature, and traditional models and related algorithms do not help
in tackling such challenges.
Universes, as complex systems, is all of space, time, matter, and energy, the latter can be either
inorganism or organism, which forms the basis of life. So far General Relativity is the de facto
physical law in governing universe, as both Newtonian Theory and Special Relativity only work
with linear systems representing flat space or flat SpaceTime, while universe is actually nonlinear
representing curved SpaceTime.
Multiverse is a hypothetical group of multiple universes, and it can be hierarchical. Together, these
universes comprise everything that exists: the entirety of space, time, matter, energy, and the phys-
ical laws and constants that describe them. The different universes within the multiverse are called
parallel universes. Multiverse has been hypothesized in cosmology, physics, astronomy among other
domains. The physics community has debated the various multiverse theories over time, and is di-
vided about whether any other universes exist outside of our own, however that does not prevent us
from adopting the concept of multiverse in modeling Hierarchical Multi-Agent Multi-Environment
Model-agnostic Policy-agnostic Deep Reinforcement Learning based ASI.
Genes are DNA sequences that encode biological instructions for the synthesis of proteins, are com-
plex systems. The total amount of DNA in a cell is referred to as genome. There are approximately
60 trillion cells in human being. At any moment, human genome, which consists of 6.4 billion letters
encoded in A (Adenine), C (Cytosine), G (Guanine), and T (Thymine), is being decoded to produce
20 possible amino acids for protein synthesis. Human genome contains the ensemble of the genetic
heredity, and the instructions for both construction and operation. Through heredity, variations be-
tween individuals can accumulate and cause species to evolve by natural selection, so-called Natural
evolution as opposed to Accelerated Spontaneous Artificial Genetic Evolution, namely Artificial
4
Under review as a conference paper at ICLR 2020
：：：畸㈱掇蹦翳龄舞：：：
…Gugcaucugacuccugaggagaag
τmvm
--VHL~T~P~E~E~K-
DNA
(transcription
.RNA
(translation)
protein
Figure 4:	Central Dogma Simplified
Design. The phenomena of mirror neutron was hard to explain, quantum entanglement that can be
used for teleportation might be one of the possible of explanations. Despite of that, gene is still
a much better explanation at biological level. As of today, the roles of most functional sequences
in human genome still remain not completely decoded, hence unknown. There are three types of
RNA, namely messenger RNA or mRNA, ribosomal or rRNA, and transfer RNA or tRNA, they
serve different roles in inter-playing with both DNA and protein during gene expression. The way
it roughly works through gene regulatory network is called Central Dogma. The transmission of
genes to organism’s offspring is the basis of the heredity of phenotypic traits. These genes make up
different DNA sequences called genotypes. Genotypes combined with ecology-based environmental
and evolution-based developmental factors determine what the phenotypes will be. Gene regulatory
network is a collection of molecular regulators, which can be DNA, RNA, protein and complexes of
these, that interact with each other and with other substances in the cell to govern the gene expres-
sion levels of mRNA and proteins. Again we still not sure how exactly it works. DNA Computing is
a branch of computing which uses DNA, biochemistry, and molecular biology hardware, instead of
the traditional silicon-based microelectronics technologies. Latest research on DNA Computing can
perform reversible DNA Computing bringing it one step closer to the silicon-based microelectron-
ics technology, which is called molectronics. DNA computing is very suited as a medium for data
processing. According to different calculations a DNA-computer with one liter of fluid containing
six grams of DNA could potentially have a memory capacity of 3072EB. The theoretical maximum
data transfer speed would also be enormous due to the massive parallelism of the calculations far be-
yond today’s most powerful computers can reach. DAN computing, just like Quantum Computing,
which uses quantum-mechanical phenomena such as superposition and entanglement too perform
computation, is still in its infancy.
Human brain, as a complex system, has a cellular structure, it is composed primarily of two broad
classes of cells: neurons and neuroglia. Neurons as opposed to neuroglia, are usually considered the
most important cells in the brain. The property that makes neurons unique is their ability to send
signals to specific target cells over long distances. Brain, specifically cerebral cortex, used to be
regarded as the sole source of intelligence, it has 16 billion neurons in contrast to cerebellum’s 69
billion neurons. These neurons are connected to each other in a complex, recurrent fashion. It is still
far away to completely understand how human brain exactly functions in demonstrating intelligence
through brain science at present. So far ANN vaguely inspired by the biological neural networks in
brain has been successfully adopted in AI with known limitations. However current brain-inspired
AI take neither evolution nor development into consideration, and for brain itself, it does not distin-
guish the role of different parts of brain inter-plays. Today, ANN-based Deep Learning in modeling
complex nonlinear relationships between inputs and outputs is widely adopted in AI. Deep Learning
uses a lot of techniques on artificial neural networks in the form of Deep Neural Networks (DNN)
such as Feedforward Neural Networks (FNN), Convolutional Neural Networks (CNN) for image
recognition, Recurrent Neural Networks (RNN) for speech recognition and Natural Language Pro-
cessing (NLP), auto-encoder and Long Short-Term Memory (LSTM) for machine translation, which
can have billions of nodes and billions of parameters in a ultra-high-dimensional feature space, in
either manual or fully automatic neural network design way and optimization techniques such as
stochastic gradient descent with back propagation and automatic differentiation for inference, in
attempt to converge quickly instead of being stuck at saddle points in non-convex Manifold in a
heuristic way.
Social network as online society as a complex systems is a social structure made up of a set of
social actors (such as individuals or organizations), sets of dyadic ties, and other social interactions
between actors. The social network perspective provides a set of methods for analyzing the structure
of whole social entities as well as a variety of theories explaining the patterns observed in these
structures. Nowadays with major social networks worldwide are producing social data in PB-scale
individually, and in EB-scale combined everyday.
5
Under review as a conference paper at ICLR 2020
Economy being defined as a social domain that emphasizes the practices, discourses, and material
expressions associated with the production, use, and management of resources, is also a nonlinear
dynamical system. The widely adopted Arrow-Debreu model, which suggests that under certain
economic assumptions such as convex preferences, perfect competition , and demand independence
, there must be a set of prices such that aggregate supplies will equal aggregate demands for every
commodity in the economy. The assumption of convexity precluded many applications before the
proof of the existence of economic equilibrium when some consumer preferences need not be convex
. A convexified economy has general equilibrium that are closely approximated by quasi-equilibrium
of the original non-equilibrium economy based on the Shapley-Folkman theorem. Of course, Nash
Equilibrium, part of Game Theory, also plays significant role in tackling real economical challenges,
and yet not quite fruitful.
The frenzy on Bitcoin, as a complex system, has been lasting for a while, while experiencing
boom and bust, it is surging again most recently. The foundation of bitcoin along with other crypt-
currencies is blockchain. Blockchain is a peer-to-peer decentralized, distributed and public digital
ledger, that is used to record transactions across many computers, so that the record cannot be altered
retroactively without the alteration of all subsequent blocks and the collusion of the network. This
allows the participants to verify and audit transactions inexpensively. A blockchain database is man-
aged autonomously using a peer-to-peer self-organizing network and a distributed time-stamping
server. They are authenticated by mass collaboration powered by collective self-interests. Hence
blockchain network is a system both complex and self-organizing, and it serves the technical foun-
dation of Decentralized Autonomous Organization (DAO). Blockchain makes it possible for any
organization to adopt DAO in conducting business without the need of a trusted authority or broker,
that is called Trustless Trust. Blockchain can be either public or private.
3 Gene and Environment as Source of Intelligence
There is no strict definition of intelligence so far yet. Typically intelligence can be defined as the
ability of learning, as well as instinct such as spatial and temporal reasoning capability. Our way of
interpreting intelligence is a brute-force way, we claim that intelligence is opposite to brute-force.
Leverage of intelligence is called exploitation, and accumulation of intelligence is called exploration.
Exploration typically replies on search, which is environment-dependent and resource-constraint ,
hence may or may not succeed. Intelligence is most often studied in humans but has also been
observed in other living systems. Intelligence in machines, whether in software or hardware, or
combined, is called AI, and ASI means machines’ cognizance supersedes that of human.
Any living system who has genes, regardless with or without brain, possesses certain degree of
intelligence. A lot of research on AI claims its inspiration comes from human brain, the fact is most
of them are only related to visual cortex in cerebral instead. As opposed to cerebral, cerebellum
modulates the outputs of other brain systems, whether motor related or thought related, to make
them certain and precise. Removal of the cerebellum does not prevent a living system from doing
anything in particular, but it makes actions hesitant and clumsy. Such kind of precision is not built-
in, but learned by trial and error. Only 10% of the brain’s total volume consists of the cerebellum
and yet 50% of all neurons are held within its structure. For human being, the cerebellum plays an
important role in motor control, and it may also be involved in some cognitive functions such as
attention and language as well as for emotion regulation. The human cerebellum does not initiate
movement, but contributes to coordination, precision, and accurate timing: it receives input from
sensory systems of the spinal cord and from other parts of the brain, and integrates these inputs to
fine-tune motor activity. Hence as opposed to just cerebral, both cerebral and cerebellum contribute
to intelligence, partially due to brain. Furthermore, current research on AI, ASI and ASI ignores
intelligent living systems’ brain-body seamless coordination almost completely.
Is human intelligence as well as other natural intelligence inborn by design via gene or developed
through environment by learning? The answer is both, and that also applies to all living systems. Ac-
cording to one of latest research on human brain, human hippocampal neurogenesis drops sharply
in children at age 13 to undetectable levels in adults, that explains exactly why children older than
13 cannot easily adapt to new languages. Here we divide intelligence into intrinsic Agent Intelli-
gence/Computing Intelligence/Planning Intelligence/Exploitation Intelligence, and extrinsic Envi-
ronment Intelligence/Learning Intelligence/Trial and Error Intelligence/Exploration Intelligence.
6
Under review as a conference paper at ICLR 2020
CDNA
Crna 工：
protein
Figure 5:	Alternative View of Central Dogma
For example, epistemology is the branch of philosophy concerned with the theory of knowledge. On-
tology in philosophy means the combination of subject and object, hence we can divide epistemol-
ogy into intrinsic epistemology and extrinsic epistemology, as well as ontology into intrinsic ontol-
ogy and extrinsic ontology. Both Intrinsic Epistemology and Intrinsic Ontology are pre-determined
by gene as soul, and both Extrinsic Epistemology and Extrinsic Ontology are acquired after living
system’s birth by learning from environment. Being intrinsic means via heredity, and both evolution-
dependent and development-independent, and being extrinsic means both environment-dependent
and development-dependent. Actually in information theory, Shannon entropy 21 measures the num-
ber of internal arrangements of a system that result in the same outward appearance, and it rises
because , a system evolves toward states that have many internal arrangements or statistical reasons.
Surprisingly Shannon also had a less well-known PhD. thesis on genetics 18 that might blow your
mind.
Creativity is the generation of novelty as a result of inspiration. Like intelligence, creativity is deter-
mined by gene, development, and environment. Creativity can also be divided into intrinsic creativity
and extrinsic creativity.
Intelligence cannot work without the help of memory. For any learning used in AI and ASI, all
need memory. Memory, whether physical or virtual, plays pivotal role in AI, both from software
perspective and hardware perspective. There is radical difference between GPU memory architecture
and CPU’s memory architecture, in terms of clock frequency, memory bandwidth, and controller
complexity among others. In AI and ASI, memory is modeled by both short-term memory and long-
term memory, we believe cache-memory should be served as intermediate layer between short-term
memory and long-term memory, just like the function of cache in computer architecture. Soul is
the mental abilities of living system, traditionally it is regarded as a unscientific concept. According
to Aristotle, there are three kinds of soul: the vegetative soul, the sensitive soul, and the rational
soul, and human beings possess all of three souls together. Georg Wilhelm Friedrich Hegel once
said, the heart is everywhere. While it sounds ridiculous, actually those sages’ views inspired us
in linking soul with gene, which is also ubiquitous. Instinct is the inherent inclination of a living
system towards a particular complex behavior, such as Fixed Action Pattern (FAP). Any behavior is
instinctive if it is performed without learning to be experienced, and is therefore based upon gene
through heredity.
In computer science, gene is well-known for its conceptional adoption in genetic algorithm (GA),
which is a meta-heuristic inspired by the process of natural selection that belongs to the larger class
of evolutionary algorithms (EA) for evolution simulation of natural evolution strategies. However it
does not leverage too much potential of the role of gene. Schrodinger regarded gene as hereditary
code-script in his book 16, just like software in a computer. Contrary to Darwin, Schrodinger also
claimed that mutation instead of variation, is the driver of natural selection. Francis Crick, once co-
authored a paper claiming gene as ultimate parasite, selfish and immortal. Actually gene is not only
the source of intelligence, but also the source of consciousness, and existence of consciousness is
the key difference between AI and ASI. The alternative view of Central Dogma is illustrated below.
There is no strict definition of consciousness so far. Roughly consciousness can be defined as the
change of state in being aware of both self and environment. Similarly self-Consciousness can be
defined as the change of state in being aware of self. No state change, no consciousness and self-
Consciousness. Both consciousness and self-Consciousness have not been major research topics
since the inception of AI3, partly because they are too hard to tackle, partly because it is located
at where both science and philosophy can hardly reach. Any living system, whether animal such
as human being or plant, possesses Consciousness and self-Consciousness, because all of them are
being defined by genes. consciousness can be demonstrated anywhere in such living system as a
peer-to-peer based distributed system besides brain if there is one.
Tononi proposed Integrated Information Theory (IIT) in attempt to explain what consciousness is,
and why it might be associated with certain physical systems. His theory predicts whether that sys-
7
Under review as a conference paper at ICLR 2020
Figure 6: Feedforward Control and Feedback Control
tem is conscious, to what degree it is conscious, and what particular experience it is having. Accord-
ing to IIT, a system’s consciousness is determined by its causal properties like cause-effect generated
by the relationships among different states the system demonstrates, and is therefore an intrinsic, fun-
damental property of any physical system. In contrast to IIT, we interpret and model consciousness
with environment in consideration by Cybernetics pioneered by Weiner 11 via feed-forward mecha-
nism and feedback (both positive and negative) mechanisms, from engineering perspective instead
of philosophical perspective. Cybernetics is a interdisciplinary approach for exploring regulatory
systems, their structures, constraints, and possibilities. Wiener defined cybernetics as, the scientific
study of control and communication in the animal and the machine. The word cybernetics coincides
with Cogito ergo sum in Latin by Rene Descartes, which means I think, therefore I am. Schrodinger
had a similar vision, he attempted to check whether one’s body functions as a pure mechanism ac-
cording to Laws of Nature; and one takes full responsibility for it by controlling so-called the motion
of the atoms according to Laws of Nature as consciousness is everywhere, not just in brain.
Here we divide artificial consciousness into deterministic consciousness and stochastic conscious-
ness. The advantage of modeling consciousness with Cybernetics facilitates the computation of
consciousness by leveraging both algorithm-based symbolic computing, and learning-based neu-
ral computing such as Deep Learning, which has shown to be very powerful and promising in ex-
tracting pertinent features especially for complex nonlinear dynamical systems, where conventional
techniques are unable to tackle. Contrary to linear systems that classical physics governs, complex
systems like living systems have to rely on correlation-based learning approach if causality-based
approach does not work well alone.
Inspired by the works of Gibbs, both Schrodinger and Prigogine attempted to unify living system and
physical system via thermodynamics, Prigogine claimed that any system’s, whether living system
or physical system , self-organization relies on its recursive self-improvement, butterfly effect can
happen under certain circumstances via feed-forward mechanism. The most recent emerging Dar-
winian Dynamics claims that, the evolution of order, or the value of entropy, in both living systems
and physical systems obeys the same fundamental principle.
von Neumann defined artificial life in the following way when he proposed Universal Constructor,
a self-reproducing machine in a cellular automata 9 , firstly it can reproduce itself, and secondly it
can simulate the Turing Machine, unfortunately Turing Machine has its modeling limitation as we
mentioned before. While Quantum Darwinism 20 aspires to explain the emergence of the classical
world from quantum world as the superposition, entanglement, and environment as witness, due to
a process of Darwinian natural selection induced by the environment interacting with the quantum
system, where the many possible quantum states are selected against in favor of a possible pointer
state, from living system-inspired AI’s and ASI’s point of view, the long-standing foe of Quantum
Electrodynamics, General Relativity is more suitable to be combined with Universal Darwinism
in Macro-world. Accelerated Spontaneous Artificial Genetic Evolution is achievable through the
self-improvement capability of ASI, just like directed evolution through either recombinant DNA or
polymerase chain reaction (PCR) in an artificially or unusually naturally changing environment, that
paves the way for Artificial Design of ASI.
8
Under review as a conference paper at ICLR 2020
4 Model ASI by Extending General Relativity and Universal
Darwinism
Since human intelligence as well as other natural intelligence is inborn by design via gene and devel-
oped through environment by learning, hence ASI should also be inborn by design via Multi-Agent
and developed through Multi-Environment by learning, that is why we model ASI with Hierarchical
Multi-Agent Multi-Environment Model-agnostic Policy-agnostic Deep Reinforcement Learning by
adopting the concept of Multiverse.
In the current practice of AI, both Reinforcement Learning and Deep Learning play significant
roles. Today Deep Learning has been applied to fields including computer vision, speech recogni-
tion, natural language processing, audio recognition, social network filtering, machine translation,
bioinformatics, drug design, medical image analysis, material inspection and gaming producing re-
sults comparable to and in some cases superior to human experts. Despite of such success, how
Deep Learning exactly works remains unknown as a blackbox, Various efforts have been attempted
to understand how Deep Learning works mathematically, one significant of them is the Universal
Approximation Theorem. The theorem states that simple neural networks such as FNN can repre-
sent a wide variety of continuous functions approximately when given appropriate parameters and
proper activity function; however, it does not explain why those neural networks can demonstrate
learnability and hence intelligence mathematically.
Reinforcement Learning enables an agent to self-navigate an environment using rewards. The envi-
ronment is typically formulated as a Markov Decision Process (MDP) or Multi-Armed Bandits, for
the former Bootstrapping through Dynamic Programming technique is used. The main difference
between the classical Dynamic Programming methods and Reinforcement Learning algorithms is
that the latter do not assume knowledge of an exact mathematical model of the MDP, and they tar-
get large MDPs through function approximation by leveraging Deep Learning where exact methods
become infeasible. The exploration vs. exploitation trade-off in Reinforcement Learning has been
most thoroughly studied through the single-state Multi-Armed Bandit problem and finite state space
MDPs. Reinforcement Learning requires clever exploration mechanisms. Randomly selecting ac-
tions, without reference to an estimated probability distribution, shows poor performance. The case
of (small) finite Markov Decision Processes is relatively well understood. However, due to the lack
of algorithms that scale well with the number of states (or scale to state space exploration problem),
simple exploration methods are the most practical. One way to tackle such challenge is adopting
greedy algorithms. While whether exact/optimal or approximate/greedy, all of those algorithms have
their pros and cons, how to model them along as other undiscovered counter-parts mathematically
in a unified way remains a challenge.
Deep Reinforcement Learning as illustrated uses Deep Learning and Reinforcement Learning prin-
ciples in order to create efficient algorithms that can be applied on both games and real-life appli-
cations. Instead of using actual state-value pairs, which is often too large in environments where
the State-Action/Spatial-Temporal space (SpaceTime) for Q-learning to converge in short time, by
using Deep Learning architecture such as DNN in approximating the action-value function such as
Q-function with Reinforcement Learning algorithms such as Q-learning, actor critic or etc, a pow-
erful Deep Reinforcement Learning model can be created that is capable to scale to problems with
very large state-action spaces that were previously unsolvable. While Reinforcement Learning itself
can be explained mathematically, Deep Reinforcement Learning is not due to the blackbox nature
of Deep Learning used for function approximation.
A Hierarchical Multi-Agent Multi-Environment system (Self-Organized System) is a complex hier-
archical system composed of multiple interacting intelligent agents interacting with multiple envi-
ronments. Hierarchical Multi-Agent Multi-Environment systems can solve problems that are diffi-
cult or impossible for an individual agent or a monolithic system to solve. Intelligence in hierarchy
including strategy, tactics and reactive control may include methodical, functional, procedural ap-
proaches, algorithmic search. General Relativity, provides a unified description of gravity as a geo-
metric property of space and time (SpaceTime), by generalizing Special Relativity and Newtonian
Theory. It leads to spectacular predictions as black holes, gravitational waves, and the big bang in
early universe. In General Relativity, space and time are not modeled as separate entities, instead
they are modeled as 4-Dimensional SpaceTime, three spatial dimensions and one time dimension,
and gravity is viewed as a consequence of the curved geometry of such 4-Dimensional SpaceTime.
9
Under review as a conference paper at ICLR 2020
Figure 7: Deep Reinforcement Learning
O
Figure 8: Projection of a Calabi-Yau Manifold
The curvature of SpaceTime is directly related to the energy and momentum. Differential Operators,
Lie Groups that provide a natural framework for analyzing the continuous symmetries of differen-
tial equations, and Metric Manifolds (Manifolds with Tensor Fields), as special Abelian Groups,
are three mathematical foundations of General Relativity; whereas for Quantum Mechanics, they
are Differential Operators, and Hilbert Spaces, which are special Banach Spaces, and special Metric
Spaces, and special Topological Spaces. Einstein Field Equation, a system of Nonlinear Partial Dif-
ferential Equations, as the core of General Relativity, describes the relation between the geometry of
a 4-Dimensional, Pseudo-Riemannian Manifold in SpaceTime topology, and the energy-momentum
contained in that SpaceTime. Being nonlinear in nature, it is very difficult to solve, except sev-
eral known exact solutions under restricted conditions, such as the Schwarzschild Solution, the
Reissner-Nordstrom Solution, the Kerr Solution, most of those solutions are approximations relying
on computing-based numerical methods such as perturbation or function approximation adopting
Deep Learning based approach. Among them one solution is the Expansion of Universe.
A Pseudo-Riemannian Manifold is a generalization ofa Riemannian Manifold in which the require-
ment of positive-definiteness is relaxed, the metric Tensor need not be positive-definite, but only
need be a non-degenerate bi-linear form. Einstein Manifold is a Riemannian or Pseudo-Riemannian
Manifold whose Ricci Tensor is proportional to the metric, which is a solution of the vacuum Ein-
stein Field Equations with cosmological constant. A projection of a Calabi-Yau Manifold yielding
applications in theoretical physics, particularly in Superstring Theory, is a special Kahler Manifold ,
who is further a Riemannian Manifold. The Riemann curvature Tensor is given in terms of the Levi-
Civita connection V by the following formula: R(u, V)W = NuNvw - VvVuw - V[u,v]w, where
[u,v] is the Lie bracket of vector fields in Lie algebra. For each pair of tangent vectors u, v, R(u, v)
is a linear transformation of the tangent space of the Manifold. It is linear in u and v, and so defines
a Tensor. For metric g on Manifold M, the tangent vectors at each point in the Manifold M can be
classed into three different types, timelike if g(X, X) < 0 null or lightlike if g(X, X) = 0 spacelike
ifg(X,X)>0
The Einstein Field Equation can be used in modeling the Reinforcement Learning part of Hierarchi-
cal Multi-Agent Multi-Environment Model-agnostic Policy-agnostic Deep Reinforcement Learning
based ASI, and it is listed as follows:
G
G μν + Λgμν = 8π C4 Tμν
Gμν ≡ Rμν - 2 Rgμν
(1)
(2)
In the above equations, μ,ν = 1,2, 3,4 in 4-Dimensional PseUdo-Riemannian Manifold of SPace-
Time Model SO(1,3), which adopts SpaceTime Algebra (also as Clifford Algebra) Cl1,3 (R) , it is
built uP from an orthogonal basis of one time-like vector γ0, and three sPace-like vectors, γ1, γ2, γ3
,with the multiplication rule YμYν + YVYμ = 2ημν , where η*ν is the MinkoWski Metric with sig-
nature (- + + +). Thus, γ2 =+1, γ2 = γ2 = γ3 = -1 Otherwise γμYν = -YVγμ, Einstein Tensor
Gμν is symmetric, hence Gμν = Gνμ
10
Under review as a conference paper at ICLR 2020
Furthermore in the above equations, R*“ is the Ricci curvature Tensor, g*“ is the metric Tensor, R
the scalar curvature. Tμν is the Energy-Momentum (also as stress-energy) Tensor, Λ is the Cosmo-
logical Constant explaining the existence of Dark Energy related to the Expansion of Universe, G
the Newton,s Gravitational Constant, C the Speed of Light, and 8∏ CG4 the proportionality constant.
In the above Einstein Equation for the Reinforcement Learning part of Hierarchical Multi-Agent
Multi-Environment Model-agnostic Policy-agnostic Deep Reinforcement Learning based ASI, it
states that SpaceTime (True/Quasi-Spatial Action-Temporal State Space), tells Reinforcement
Learning of ASI how to demonstrate Agent Intelligence/Computing Intelligence/Planning Intelli-
gence/Exploitation Intelligence, and Reinforcement Learning of ASI tells SpaceTime how to curve.
Hence Agent Intelligence/Computing Intelligence/Planning Intelligence/Exploitation Intelligence is
just the geometry effect of 4-Dimensional SpaceTime caused by Geometrization, in other words,
Agent Intelligence/Computing Intelligence/Planning Intelligence/Exploitation Intelligence is mod-
eled as curvature of 4-Dimensional SpaceTime.
When a system behaves no difference when time is reversed, it is said to show T-symmetry. The
second law of thermodynamics explains the phenomenon of irreversibility of any isolated system
with its entropy keeping on increasing in nature. However since intelligence originally only belongs
to living systems, also is part of life, whether artificial life or real life, and life is an open system
which can demonstrate reversibility that can operate continuously at non-equilibrium. Hence we can
make a T-Symmetry extension for intelligence. Based on CPT (Charge, Parity, Time) symmetry,
which is one of the most fundamental symmetry in physics. Such extension leverages Riemannian
Manifold’s curvature symmetry, as part of space symmetries, which Pseudo-Riemannian Manifold
lacks, because it is curvature collineation that preserves the Riemann Tensor.
gμν (X)
g11(x)
g21(x)
g31(x)
g41(x)
g12(x)
g22(x)
g32(x)
g42(x)
g13(x)
g23(x)
g33(x)
g43(x)
g14(x)
g24(x)
g34(x)
g44(x)
(3)
gαβ(x)
g11(x)
g21(x)
g31(x)
g12(x)	g13(x)...	g1N (x)
g22(x)	g23(x)...	g2N (x)
g32(x)	g33(x)...	g3N (x)
(4)
g(N1 (x)	gN1 (x)	gN3(x)...	gNN (x)
The Extended Einstein Field Equation on Manifold (MN, g) in modeling the Deep Learning part of
Hierarchical Multi-Agent Multi-Environment Model-agnostic Policy-agnostic Deep Reinforcement
Learning based ASI is formulated as follows:
Gαβ + Λgαβ
8∏C4 Tae
Gae ≡ Rae - 2 Rgae
(5)
(6)
Where α, β = 1,2, ..., N in N-Dimensional T-symmetry Extended Riemannian Manifold of GeneS-
pace Model by replacing physical space with GeneSpace as source of intelligence. The model adopts
Clifford algebra C l1,N (R) , it is built up from an orthogonal basis of N GeneSpace-like vector, N
can be as big as infinite in terms of GeneSpace dimensionality. γ1 , γ2, γ3, , γN , with the multipli-
cation rule γaγe + γaγe = 2ηae where ηae is the Riemannian metric with signature (+ + + ... +).
with γaγe = γeγα
In the above Extended Einstein Equation for the Deep Learning part of Hierarchical Multi-
Agent Multi-Environment Model-agnostic Policy-agnostic Deep Reinforcement Learning based
ASI, it states that GeneSpace, tells Deep Learning of ASI how to demonstrate Environment In-
telligence/Learning Intelligence/Trial and Error Intelligence/Exploration Intelligence, and Deep
Learning of ASI tells GeneSpace how to curve. Hence Environment Intelligence/Learning In-
telligence/Trial and Error Intelligence/Exploration Intelligence is just the geometry effect of
11
Under review as a conference paper at ICLR 2020
N-Dimensional GeneSpace caused by Geometrization, in other words, Environment Intelli-
gence/Learning Intelligence/Trial and Error Intelligence/Exploration Intelligence is modeled as cur-
vature of N-Dimensional GeneSpace.
Even though our Extended General Relativity does not reduce the computational complexity of ASI,
as the Extended Einstein Field Equations are still higher-order nonlinear partial differential equa-
tions, and whether continuous optimization, or differential geometry, or differential equations, are
functionally equivalent in solving nonlinear problems algorithmically, geometrically, algebraically
respectively. Actually there is a chicken-and-egg paradox here: one way of solving both the Ex-
tended Einstein Field Equations is through function approximation adopting Deep Learning based
approach, and Deep Learning can be formulated in the Extended Einstein Field Equations them-
selves, we call it a typical Problem/Solution Paradox, or more universally as Universal Paradox,
actually all paradoxes can be classified as Universal Paradox, where solutions rely on problems, and
vice verse. Anyway our extension not only lays a consistent mathematical foundation and makes
solution space visible and transparent for ASI, but also paves the way for our ongoing work on
complexity reduction for ASI.
Complexity reduction in computation and learning, whether discrete or continuous, deterministic or
stochastic, online or off-line, exact or approximate with/without tight (upper and/or lower) bounds
to optimal solution, remains big challenges for AI and ASI. Optimization can be classified as dif-
ferent ways: Discrete optimization (such as integer programming and Combinatorial Optimization)
vs. Continuous Optimization; Gradient-based (First Order as opposed to Second Order Optimiza-
tion) vs. Constrained Optimization; Convex Optimization vs. Non-Convex Optimization. All prob-
lems can be classified as P, NP, NP-complete, and NP-hard. There are very few optimal/exact yet
greedy algorithms which can take the advantage of special structures such as matroid in geomet-
ric space (independent sets) with the following properties: heredity and augmentation/exchange,
whereas all of the remaining, such as non-convex optimization 7 for geodesics in high-dimensional
nonlinear Manifold frequently encountered in Deep Learning, have to resort to various heuristics for
approximation with or without bounded complexity. In the meantime, in the era of AI and ASI, as
correlation dominating causality, the challenges of NP-complete and NP-hard have been mitigated
due to the inherent difference between Computing Complexity and Learning Complexity is increas-
ing. Nevertheless, there is no free lunch in computational complexity reduction, all are trade-off
among (running ) time and space (memory and disk). In the mean time, technology advance such
as all-memory computing, quantum computing also does not change the nature of computational
complexity. However, fortunately achieving ASI does not require 100% computational tractability:
for hard problems, you just need a viable solution instead of the best solution.
5	Discussion
New scientific theory and new technological practice are two pillars of any industrial revolution. It
is hard to deny that while the latter has to be accepted by the majority in the market from the begin-
ning, the former seems always is being embraced by the minority in the academia since its inception.
The matter of fact is only dictatorship instead of Democracy works in this world, while revolution-
ary theory always gets more resistance than evolutionary theory because politics exists everywhere
and human nature tends to follow the intuition instead of the counter-intuition. Since the renais-
sance, causality-based Reductionism, such as Precipice Reductionism in physics and Step-by-Step
Reductionism in biology, instead of correlation-based Anti-Reductionism, has been in dominance,
and quite successful. However, when it comes to fundamental problems beyond basic science and
technology, such as the origin of universe and life, the nature of intelligence and consciousness,
and how brain and genes work among, just to name a few, Reductionism experiences difficulty in
offering decent answers.
Now in modern physics, one of biggest challenges is the incompatibility of General Relativity and
Quantum Electrodynamics, part of the Grand Unification challenge. If we don’t quantize General
Relativity, then we run into contradictions with Quantum Electrodynamics. The easiest one to un-
derstand is the infinite universe problem: Observations indicate that the universe is probably infinite,
even though the observed universe is finite. Quantum Electrodynamics tells us the universe must
be finite, and General Relativity tells us it can be infinite. Resolving such incompatibility is very
important as Multi-Agent in Hierarchical Multi-Agent Multi-Environment Model-agnostic Policy-
12
Under review as a conference paper at ICLR 2020
agnostic Deep Reinforcement Learning based ASI, has different interpretations in General Relativity
and Quantum Electrodynamics, which can be a huddle.
In Abiogenesis, part of the roots of Artificial Design, one of the most fundamental questions is the
chicken-and-egg paradox for DNA and protein, or the DNA/Protein Paradox, the origin of life puz-
zle, the dilemma of causality, it belongs to Problem/Solution Paradox, and is just another kind of
Universal Paradox. While there are different answers for that, such as proximate causation, ultimate
causation, and reciprocal causation, or even RNA first, however, nothing is convincing. Our answer
to this DNA-and-Protein paradox is that, both DNA and protein were created by someone who de-
pends on our faith, just like matter and curved-SpaceTime (field), life and intelligence, were created
simultaneously, just like our formulation of Artificial Design model of Hierarchical Multi-Agent
Multi-Environment Model-agnostic Policy-agnostic Deep Reinforcement Learning based ASI for
Artificial Design. In other words, initial conditions for any complex system in conventional think-
ing, whether living or physical, does not work any more. Simply put, Artificial Design, which states
that that intelligence, whether natural, artificial, or super-artificial like ASI, is just a combination
of the geometry effect of both 4-Dimensional SpaceTime and N-Dimensional GeneSpace caused by
Geometrization, just like both General Relativity and Universal Darwinism, is also counter-intuitive.
6	Appendix
Here we list a few existing works we never know till finalizing this paper at the last minute as follows,
we are glad there are already a few existing interesting works aside from pioneering works done by
both Einstein and Darwin, yet none of them offers a global universal mathematical foundation for
bio-physical inspired ASI associated with both General Relativity and Universal Darwinism in our
humble opinion, use your own judgment please. By the way, the following list may not be complete,
we are sure it can be expanded as we continue in working on this challenging yet exciting frontier.
The problem is being in industry, we do not possesses the luxury in conducting extensive if not
exhaustive literature search (let alone reading), especially given its interdisciplinary nature, so please
bear with us. In case your important work has not included yet, please let us know at your earliest
convenience.
•	Hornik on Universal Approximation Theorem 22
•	Rashevsky on Geometrization of Biology 23
•	Palais on Geometrization of Physics 24
•	Btyson on Intelligence by Design 25
•	Campbell on Bayesian methods and Universal Darwinism 26
•	Pellionisz and Llinas on Geometrization of Brain Function through Tensor Network The-
27
ory 27
•	Lawrence on Manifold Learning for Dimension Reduction 28
References
[1]	Einstein, A. (1920). Relativity: The Special and the General Theory: Popular Exposition,
Methuen & Co. Ltd.
[2]	Darwin, Charles (1860). On the Origin of Species by Means of Natural Selection, or the Preser-
vation of Favoured Races in the Struggle for Life (6th ed.), London: John Murray.
[3]	McCarthy, J.; Minsky, M.; Rochester; N., Shannon; C.E., A Proposal for the Dartmouth Summer
Research Project on Artificial Intelligence, August, 1955.
[4]	Sutton, Richard S.; Bartto, Andrew G.. Reinforcement Learning: An Introduction, Second Edi-
tion, MIT Press, Cambridge, MA, 2018.
[5]	Bengio, Yoshua; LeCun, Yann; Hinton, Geoffrey (2015). Deep Learning. Nature. 521 (7553):
pp. 436-444.
13
Under review as a conference paper at ICLR 2020
[6]	Gould, Stephen Jay (2011). Challenges to Neo-Darwinism and Their Meaning for a Revised
View of Human consciousness. In McMurrin, Sterling M. (ed.). The Tanner Lectures on Human
Values. 6. Salt Lake City, UT; Cambridge, UK: University of Utah Press; Cambridge University
Press. ISBN 978-0-521-17647-7.
[7]	Anandkumar, A. Recent Advances and Challenges in Non-Convex Optimization, ICML 2016.
[8]	Francois-Lavet, Vincent; Henderson, Peter; Islam, Riashat; Bellemare, Marc G.; Pineau, Joelle
(2018). An Introduction to Deep Reinforcement Learning. Foundations and Trends in Machine
Learning. 11 (34):pp. 219-354.
[9]	von Neumann, J. (1966). Theory of Self-Reproducing Automata, Edited & Completed by Burks,
A. W., University of Illinois Press.
[10]	Dulac-Arnold G. et al. Challenges of Real-World Reinforcement Learning,
https://arxiv.org/abs/1904.12901v1.
[11]	Weiner, N. (1948). Cybernetics: Or Control and Communication in the Animal and the Ma-
chine, MIT Press.
[12]	Watson, J. D.; Crick, F. H. (1953). Molecular Structure of Nucleic Acids; A structure for de-
oxyribose nucleic acid, Nature. 171 (4356): pp. 737-738.
[13]	Silver, D. et al. (2016). Mastering the Game ofGo with Deep Neural Network and Tree Search,
Nature. 529 (7587): pp. 484-489.
[14]	Silver, D. et al. (2017). Mastering the Game of Go without Human Knowledge, Nature. 550
(7676): pp. 354-359.
[15]	Brown N.; Sandholm T. (2017). Safe and Nested Subgame Solving for Imperfect-information
Games, Neural Information Processing Systems (NIPS).
[16]	Schrodinger, E. (1944). What Is life? The Physical Aspect of the Living Cell, Cambridge Uni-
versity Press.
[17]	Abadi, M. et al. TensorFlow: A system for Large-scale Machine Learning, OSDI 2016.
[18]	Shannon, C. (1940). Algebra for Theoretical Genetics. MIT PhD dissertation.
[19]	Dulac-Arnold G. et al. Challenges of Real-World Reinforcement Learning,
https://arxiv.org/abs/1904.12901v1.
[20]	Zurek, W. H. (2003). Quantum Darwinism and Envariance. arXiv:quant-ph/0308163.
[21]	Shannon, C.; Weaver, W. (1949). The Mathematical Theory of Communication. The University
of Illinois Press.
[22]	Hornik, Kurt (1991). Approximation Capabilities of Multilayer Feedforward Networks. Neural
Networks. 4(2), pp. 251-257. doi:10.1016/0893-6080(91)90009-T.
[23]	Rashevsky, N (1956). The Geometrization of Biology. Bulletin of Mathematical Biophysics.
18: pp. 31-54. doi:10.1007/bf02477842.
[24]	Palais, Richard (1981). The Geometrization of Physics. Lecture Notes in Mathematics: pp. 1-
107.
[25]	Btyson, Joanna Joy (2001). Intelligence by Design : Principles of Modularity and Coordination
for Engineering Complex Adaptive Agents. MIT PhD Thesis
[26]	Campbell, John (2009). Bayesian Methods and Universal Darwinism. AIP Conf. Proc. 1193,
40, doi:10.1063/1.3275642. pp. 40-47.
[27]	Pellionisz, A., Llinas, R. (1980). Tensorial Approach To The Geometry of Brain Func-
tion: Cerebellar Coordination Via A Metric Tensor. Neuroscience. 5 (7): pp. 11251136.
doi:10.1016/0306-4522(80)90191-8. PMID 6967569.
[28]	Lawrence, Neil D (2012). A Unifying Probabilistic Perspective for Spectral Dimensional-
ity Reduction: Insights and New Models. Journal of Machine Learning Research. 13 (May):
pp. 1609-1638.
14