Under review as a conference paper at ICLR 2019
Project and Forget: Solving large-scale met-
RIC CONSTRAINED PROBLEMS
Anonymous authors
Paper under double-blind review
Ab stract
Given a set of distances amongst points, determining what metric representation
is most “consistent” with the input distances or the metric that best captures the
relevant geometric features of the data is a key step in many machine learning
algorithms. In this paper, we focus on metric constrained problems, a class of
optimization problems with metric constraints. In particular, we identify three
types of metric constrained problems: metric nearness (Brickell et al. (2008)),
weighted correlation clustering on general graphs (Bansal et al. (2004)), and metric
learning (Bellet et al. (2013); Davis et al. (2007)). Because of the large number
of constraints in these problems, however, these and other researchers have been
forced to restrict either the kinds of metrics learned or the size of the problem that
can be solved.
We provide an algorithm, Project and Forget, that uses Bregman projections
with cutting planes, to solve metric constrained problems with many (possibly
exponentially) inequality constraints. We also prove that our algorithm converges
to the global optimal solution. Additionally, we show that the optimality error
(L2 distance of the current iterate to the optimal) asymptotically decays at an
exponential rate. We show that using our method we can solve large problem
instances of three types of metric constrained problems, out-performing all state of
the art methods with respect to CPU times and problem sizes.
1	Introduction
Given a set of distances amongst data points, many machine learning algorithms are considerably
“easier” once these distances adhere to a metric. Furthermore, learning what metric is most “consistent”
with the input distances or the metric that best captures the relevant geometric features of the data
(e.g., the correlation structure in the data) is a key step in efficient, approximation algorithms for
classification, clustering, regression, feature selection, etc. Indyk (1999) provides a list of other
computational problems such as nearest neighbor search, (approximate) proximity problems, facility
location, and a variety of graph problems for which we have efficient approximation algorithms in a
general metric space. Given the importance of metric representations of data sets, we focus on metric
constrained problems, a class of optimization problems with metric constraints; i.e., optimization
of a convex function subject to metric constraints, such as the triangle inequality, on all the output
variables.
In particular, we identify three types of metric constrained problems: metric nearness (Brickell et al.
(2008)), weighted correlation clustering on general graphs (Bansal et al. (2004)), and metric learning
(Bellet et al. (2013); Davis et al. (2007)). Briefly, the metric nearness problem seeks the closest metric
to a given set of distances, the goal of correlation clustering is to partition nodes in a graph according
to their similarity, and metric learning finds a metric on a dataset that is consistent with (dis)similarity
information about the data points.
All of these problems can be modeled as constrained convex optimization problems with a large
number of constraints. Unfortunately, because of the large number of constraints, using standard
optimization techniques, researchers have been forced to restrict either the kinds of metrics learned or
the size of the problem that can be solved.
Many of the existing methods for metric constrained problems suffer from some sort of significant
drawback that hampers performance or restricts the instance size. Gradient based algorithms such as
1
Under review as a conference paper at ICLR 2019
projected gradient descent (e.g., Beck & Teboulle (2009); Nesterov (1983)) or Riemannian gradient
descent require a projection onto the space of all metrics, which in general, is an intractable problem.
One modification of this approach is to subsample the constraints and then project onto the sampled
set (See Nedic (2011); Polyak (2001); Wang & Bertsekas (2013); Wang et al. (2015)). For metric
constrained problems, however, we have many more constraints than data points, so the condition
numbers of the problems are quite high and these algorithms tend to require a large number of
iterations.
Another standard approach is to consider the Lagrangian and maintain a KKT type optimality
condition. These methods run into two different kinds of problems. First, computing the gradient
becomes an intractable problem for methods that maintain the KKT condition by using Newton’s
method. Examples of such methods include the interior point method and the barrier method. One fix
could be to subsample the constraints and only compute those gradients, but this approach runs into
the same drawbacks as before. The other option is to incrementally update the Lagrangian, looking at
one constraint at a time. These methods, such as Bauschke & Lewis (2000); Iusem (1991); Iusem &
De Pierro (1990), traditionally require us to cycle through all the constraints which is not feasible
with metric constraints.
One final approach is to use cutting planes. The performance of this method is very heavily dependent
on the cut selection process (see Dey & Molinaro (2018); Poirrier & Yu (2019) for deep discussions
about the cut selection process). The discovery of Gomory cuts and other subsequent work such as
branch and bound, has led to the viability of the cutting plane method for solving mixed integer linear
programs. This success has, however, not transferred to other problems. In general, if the cuts are not
selected appropriately, the algorithm could potentially take an exponential number of iterations; i.e.,
add an exponential number of constraints. Thus, to use this method, we must show for each problem
that the specific cutting plane selection method results in a feasible algorithm (see Chandrasekaran
et al. (2012) for an example).
In this paper, we provide an algorithm, Project and Forget, that uses Bregman projections with
cutting planes, to solve metric constrained problems with many (possibly exponentially) inequality
constraints. In fact, the algorithm is a general purpose one that can solve large constrained convex
optimization problems, not only those arising from metric constraints. We also develop a stochastic
version of our algorithm. This version is a similar adaptation of the Bregman method, as Nedic
(2011); Polyak (2001); Wang & Bertsekas (2013); Wang et al. (2015) are adaptations of the projected
gradient method. This version of our algorithm can be used to solve problems where each data point
(or pair, triple of data points) form a constraint. The major contributions of our paper is as follows:
1.	Using a specific instantiation of the Project and Forget algorithm, we solve the
weighted correlation clustering problem on a graph with over 130, 000 nodes. To solve this
problem with previous methods, we would need to solve a linear program with over 1015
constraints. Furthermore, we demonstrate our algorithms superiority by outperforming the
current state of the art in terms of CPU times.
2.	We use our algorithm to develop a new algorithm that solves the metric nearness problem.
We show that our algorithm outperforms the current state of the art with respect to CPU
time and can be used to solve the problem for non-complete graphs.
3.	We use the the stochastic version of our algorithm to develop a new algorithm to solve
the information theoretic machine learning problem. We compare this against the standard
method and show that in general we require fewer projections to solve the problem. Using
our algorithm we can also solve the full version of the convex program presented in Davis
et al. (2007) instead of a heuristic approximation. Thus, demonstrating that we can solve
larger instances of the problem.
4.	Finally, we prove that our algorithm converges to the global optimal solution. Additionally,
we show that the optimality error (L2 distance of the current iterate to the optimal) asymp-
totically decays at an exponential rate. We also show that because of the Forget step,
when the algorithm terminates, the set of constraints that remain remembered are exactly
the active constraints. Thus, our algorithm also finds the set of active constraints.
We present the necessary background material and problem formulations in Section 2. In Section 3,
we provide a general form of the Project and Forget algorithm and detail its theoretical analysis.
We instantiate our algorithm to solve three types of metric constrained problems in Section 4 and
2
Under review as a conference paper at ICLR 2019
highlight the empirical performance. Complete proofs and discussion may be found in the sections in
the Appendix.
2	Preliminaries
2.1	Metric constrained problems, general formulation
Metric polytope. To set the stage for our optimization problems, we define the set over which we
optimize first. Let METn ⊂ R(n2) be the space of all metrics on n points. Given a graph G the metric
polytope MET(G) is the projection of METn onto the coordinates given by the edges of G (i.e., we
consider distances only between pairs of points that are adjacent in G).
It can be easily seen that for any x ∈ R(n2), we have that x ∈ METn(G) if and only if ∀e ∈
G, x(e) ≥ 0 and for every cycle C in G and ∀e ∈ C, we have that x(e) ≤ P(I∈cf∣=ex(e).
Therefore, METn(G) can be described as the intersection of exponentially many half-spaces.
Metric constrained problems. Now that we have the set over which we want to optimize, we give a
general formulation for metric constrained optimization problems: given a strictly convex function f,
a graph G, and a finite family of half-space H = {Hi} such that Hi = {x : hai, xi ≤ bi}, we seek
the unique point x* ∈ Ti Hi ∩ MET(G) =: C that minimizes f. That is, if We set A to be the matrix
whose rows are ai and b be the vector whose coordinates are bi we seek
minimize f(x)
subject to Ax ≤ b	(2.1)
x∈ MET (G).
The constraints encoded in the matrix A let us impose additional constraints beyond that of a metric.
In this paper, A is used only for correlation clustering.
2.2	Specific metric constrained problems
Metric nearness. Following Brickell et al. (2008), the metric nearness problem is: given a point
x ∈ R(n2), find the closest (in some `p norm) point x* ∈ METn to x. This problem is a form of
metric learning; see Brickell et al. (2008) for an application to clustering and see Gilbert & Sonthalia
(2018) for an application to unsupervised metric learning. I
Weighted correlation clustering on graphs. Bansal et al. (2004) introduced correlation clustering.
In this problem, we are given a graph G = (V, E) (not necessarily complete) in which each edge e
has two non-negative numbers w+ (e) and w- (e) that indicate the level of similarity and dissimilarity
between its nodes. The goal of correlation clustering is to partition the nodes into clusters so as to
minimize some objective function. The most common objective is	w+(e)xe + w-(e)(1 - xe ),
e∈E
where xe ∈ {0, 1} indicates whether the end points of the edge e belong to different cluster. In
general, this variant of the problem is NP-hard and many different algorithms have been developed to
solve the problem. The best approximation results (with approximation ratios O(log n) in general,
and O(1) for specific cases), however, are obtained by rounding the solution to the following relaxed
linear problem
minimize Pe∈E w+ (e)xe + w- (e)(1 - xe )
subject to xij ≤ xik + xkj i, j, k = 1, ..., n	(2.2)
xij ∈ [0, 1] i,j = 1, ..., n.
See Charikar et al. (2005); Emanuel & Fiat (2003) for details. Many special cases, such as when the
weights are ±1 and G = Kn, can be solved with faster algorithms (e.g., Ailon et al. (2005)).
Metric learning. The final metric constrained problem we consider is metric learning. There are
many different versions of this problem (see Bellet et al. (2013); SUdreZ D^az et al. (2018) for two
different surveys on the topic) but all of the instantiations have a similar formulation: given a data set
X and possibly some additional information, learn an appropriate metric on X . Many of the existing
methods seek a linear map L such that the learned metric is given by
de (χ,y) = J(χ - y)TC(X - y)
3
Under review as a conference paper at ICLR 2019
where C = LTL. Our general purpose algorithm can directly learn the appropriate metric without
resorting to the above specific form, however, this generalization requires more focus than we can
give it in this paper. Instead, we focus on a specific instantiation (that also differs from the above),
specifically information theoretic metric learning (ITML), as in Davis et al. (2007). In ITML, we
consider LTL as the covariance matrix of a Gaussian distribution p(x; C) and we are given two sets
S, D which represent the set of similar and dissimilar points. The problem we solve is:
minimize KL p(x; C)kp(x; I)
subject to dA (xi , xj ) ≤ u	(i, j) ∈ S	(2.3)
dA(xi, xj) ≥ l.	(i, j) ∈ D
2.3	Bregman Projections
All of the above problems can be couched in general terms and, in the Appendix 6, we give such a
general formulation. We seek to optimize a rich class of convex functions f, known as Bregman
functions, denoted B(S), with useful properties for algorithmic and convergence analysis, subject
to metric constraints. More details about Bregman functions and the general setting in which our
algorithm works can be found in the Appendix sec:generalProblem . We do, however, detail Bregman
projections, a key step in our specific algorithms in this section.
Definition 1. Given a convex function f (x) : S → R whose gradient is defined on all of S, we
define its generalized Bregman distance Df : S × S → R as follows: Df (x, y) = f (x) - f (y) -
hVf (y),χ - y.
Definition 2. Given a strictly convex function f, a closed convex set C, and a point y, the projection
of y onto C with respect to Df is a point x* ∈ dom(f) such that
x* = arg min Df (x,y).
x∈C ∩dom(f)
3	Algorithms and analysis
In this section, we present our algorithm that we will use to solve metric constrained problems and
state its convergence behavior. The detailed proofs can all be found in the Appendix 8.
3.1	The Algorithm
Our method is an iterative one and is presented in Algorithm 1. Each iteration consists of three phases.
In the first phase, we obtain1 a list of violated metric constraints L. If we have additional constraints
represented in A, A is a list corresponding to these hyperplanes. In the second phase, we merge L(ν),
the list of constraints we have been keeping tracking of up to the νth iteration, with L and project
onto each of the constraints in the list L(ν) ∪ L ∪ A iteratively. Finally, in the third phase, we forget
some constraints.
The project and forget steps for algorithm are presented in Algorithm 2. Let us step through the code
to understand intuitively its behavior. Let Hi = {x : hai, xi ≤ bi} be a constraint and x the current
iterate. The first step is to calculate x* and θ. Here x* is the projection of x onto the boundary of Hi
and θ is a “measure” of how far x is from x*. However, θ can be any real number and so we examine
two cases: θ positive or negative.
It can be easily seen that θ is negative if and only if the constraint is violated. In this case, we have
c = θ because (as we will see in proof) the algorithm always maintains zi ≥ 0. Then on line 5, we
compute the projection of X onto Hi. Finally, since We corrected X for this constraint, We add ∣θ∣ to
zi . Since each time we correct for Hi , we add to zi , we see that zi stores the total corrections made
for Hi .
On the other hand, if θ is positive, this constraint is satisfied. In this case, if We also have that zi is
positive; i.e., We have corrected for Hi before, then We have over compensated for this constraint and,
1In the general formulation of the algorithm in the Appendix 6, this list is obtained by querying a separation
oracle With one of tWo properties. See the Appendix for a detailed discussion.
4
Under review as a conference paper at ICLR 2019
Algorithm 1 General Algorithm.
1:	function F(f, A)
2:	L(O) = 0, z(0) = 0. Initialize x(0) so that Vf (x(0)) = 0.
3:	while Not Converged do
4:	L = METRIC VIOLATIONS(xν)
5:	L(ν+1) = L(V) ∪ L ∪A
6:	x(ν+1) = PrCject(X(V), L(V+1))
7:	L(ν+1) = Forget(L(V+1))
return x
8:
9:	function METRIC VIOLATIONS(d)
10:	L = 0
11:	Let d(i, j ) be the weight of shortest path between nodes i and j or ∞ if none exists.
12:	for Edge e = (i, j) ∈ E do
13:	if w(i, j ) > d(i, j ) then
14:	Let P be the shortest path between i and j
15:	Add C = P ∪ {(i, j)} to L
return L
thus, we must undo some of the corrections. If c = zi , then we undo all of the corrections and zi is
set to 0. Otherwise, if c = θ we only undo part of the correction.
The forget step is relatively easy: given a constraint Hi , we check if zi = 0. If zi = 0, then this
means we have not done any net corrections for this constraint and we can forget about it; i.e., delete
it from L(V).
Algorithm 2 Project and Forget algorithms.
1:	function PROJECT(x, z, L)
2:	for Hi = {y : hai, yi = bi} ∈ L do
3:	Find x*,θ by solving Vf (x*) 一 Vf (x) = θai and x* ∈ Hi
4:	ci = min (zi , θ)
5:	x — such that Vf (xn+1) — Vf (x) = Ciai
6:	Zi J Zi - Ci
return x, z
7:	function FORGET(x, Z, L)
8:	for Hi = {x : hai, xi = bi} ∈ L do
9:	if Zi == 0 then Forget Hi
return L
In general, calculating the Bregman projection (line 3) cannot be done exactly. See Dhillon & Tropp
(2007) for a general method to perform the calculation on line 3 and for an analytic formula for when
f is a quadratic function.
3.2	Convergence Analysis
Now that we have specified the algorithm, we establish a few crucial theoretical properties. The
first is that our algorithm is guaranteed to converge to the global optimum. In fact, we also show
that asymptotically, our error decreases at an exponential rate. These main theoretical results can be
summarized by the following theorem.
Theorem 1. If f ∈ B(S), Hi are strongly zone consistent with respect to f2, and ∃ x0 ∈ S such that
Vf(x0) = 0, then
1.	Then any sequence xn produced by Algorithm 1 converges to the optimal solution of problem
2.1.
2This is a technical condition and is discussed in Appendix 6. In the case of our problems this is true.
5
Under review as a conference paper at ICLR 2019
2.	If x* is the optimal solution, f is twice differentiable at x*, and the Hessian H := Hf (x*)
is positive semidefinite, then there exists ρ ∈ (0, 1) such that
lim
ν→∞
kx* - Xν+1kH
l∣χ* - XVIIh
≤ρ
(3.1)
where lyl2H = yT Hy.
Proof. The proof of this theorem has been moved to the supplementary material section. □
The proof of Theorem 1 also establishes another important theoretical property.
Proposition 1. If ai is an inactive constraint, then there exists a N, such that for all n ≥ N, we have
that zin = 0. That is, after some finite time, we never project onto inactive constraints ever again.
Corollary 1. Under the assumptions for part (2) of Theorem 1, we have that the sequence zn → z*
also converges.
These properties are important as they permit the following interpretation of our algorithm. The
algorithm spends the initial few iterations identifying the active constraints from amongst a large
number of constraints. The algorithm then spends the remainder of the iterations finding the optimal
solution with respect to these constraints. This ability to find the set of active constraints is of the
main advantages of our algorithm.
3.3 Stochastic Variant
In some problems, we do not optimize over the whole of MET(G) but a subset, as is the case in
ITML. In such problems, we have constraints defined using subsets of the data points and as we may
have many data points, we may have considerably more constraints than we want to examine. For
this reason, we present a stochastic version of our algorithm that can be used in these cases. Instead
of calling Metric Violation to get a list of metric violated constraints, we randomly sample from
our constraints. In this version, at each iteration, we choose a random set of constraint and project
onto these constraints and the ones we remember from before, and then forget some constraints. The
advantage this has over similar stochastic methods such Wang et al. (2015) is that as we sample
constraints, the list L(ν) keeps track of the important constraints that we have seen so far. In this case,
we have the following convergence result.
Theorem 2. If f ∈ B(S), Hi are strongly zone consistent with respect to f, and ∃ x0 ∈ S such
that Vf (x0) = 0, then with probability 1 any sequence Xn produced by the stochastic algorithm
converges to the optimal solution of problem 2.1. Furthermore, if x* is the optimal solution, f is
twice differentiable at x*, and the Hessian H := Hf(x*) is positive semidefinite, then there exists
ρ ∈ (0, 1) such that with probability 1,
lim
ν→∞
∣X* - Xν+1∣H
∣∣χ* 一 XV ∣∣h
≤ ρ.
4 Experiments
To demonstrate the effectiveness of our method in solving metric constrained problems, we solve
large instances of each of the problem. More details3 about each of the experiments can be found in
the Appendix 9.
4.1	Weighted correlation clustering on general graphs
4.1.1	Dense graphs
As the LP formulation for correlation clustering in Equation 2.2 has O(n3) constraints, solving the
LP for large n becomes infeasible quickly, in terms of both memory and time. Veldt et al. (2019)
3All implementations and experiments can be found at https://www.dropbox.com/sh/
lq5nnhi4je2lh89/AABUUW7k5z3lXTSm8x1hhN1Da?dl=0.
6
Under review as a conference paper at ICLR 2019
showed that for instances with n ≈ 4000, standard solvers such as Gurobi ran out of memory on
a 100 GB machine. On the other hand, Veldt et al. (2019) develop a method using which they can
feasibly solve the problem for n ≈ 11000. To solve the problem, they transformation problem 2.2
into problem 4.1 for some an appropriately defined d, W, W. For general Y, the solution to problem
4.1 approximates the optimal solution to 2.2. However, for large enough γ it has been shown that the
two problems are equivalent.
minimize WT |x — d| + Y |x — d|T W |x — d|
subject to x ∈ MET(Kn)
(4.1)
This is the version of the LP that we solve with our algorithm. We solve this for four graphs from the
Stanford sparse network repository Leskovec & Krevl (2014). Following Veldt et al. (2019), we use
the method from Wang et al. (2013) to convert these graphs into instances of weighted correlation
clustering on a complete graph. We compare our method against Ruggles et al. (2019), a parallel
version of Veldt et al. (2019), in terms of running time, quality of the solutions, and memory usage.
We see from Table 1 that our algorithm takes less time to get a better approximation ratio, but requires
more memory per iteration. Our algorithm requires more memory because the initial few iterations
find a large number of constraints. Later, in the forget step, the algorithm forgets these constraints
until the number of constraints stabilizes at a reasonable level. Hence, our initial memory usage is
much larger than our later memory usage.
Table 1: Comparison with Ruggles et al. (2019). We set γ = 1 and ran until the maximum violation
of a metric constraint was smaller than 0.01. We used a parallel version of the algorithm METRIC
Violation as our oracle. All of the computations were done on a machine with 16 physical cores
and 13 GB of RAM per core. More details about the experiment can be found in the supplementary
material section.
Graph			Time (s)	Opt Ratio		Avg. mem. / iter. (GiB)	
	n	Ours	Ruggles et al.	Ours	Ruggles et al.	Ours	Ruggles et al.
CAGrQc	4158	2098	5577	1.33	1.38	4.4	1.3
Power	4941	1393	6082	1.33	1.37	5.9	2
CAHepTh	8638	9660	35021	1.33	1.36	24	8
CAHepPh	11204	71071	135568	1.33	1.46	27.5	15
To see how the number of constraints found by the oracle evolves, we plot the number of constraints
found by the oracle and the number of constraints after the forget step for the CA-HepTh graph.
This plot can be seen in Figure 1. Figure 1 also shows us, as expected, the exponential decay of the
maximum violation of a metric constraint.
Figure 1: Left: The number of constraints is on the y axis (log scale) and the number of iterations on
the x axis. Right: Plot for the maximum violation of a metric constraint (log scale) versus iterations.
7
Under review as a conference paper at ICLR 2019
4.1.2	Sparse graphs
For much real-world data, the graph G is larger than our previous experiments but it is also sparse.
As stated, the problem (2.2) requires O(n3) constraints and O(n2) variables. However, in practice,
there are very few active constraints, as seen in Table 2. Proposition 2 tells us that if we optimize over
MET(G) instead of METn, then the quality of the solution is not degraded. With this generalization
to MET(G), the number of variables is greatly reduced but the number of constraints is increased.
Our algorithmic approach, however, can handle this increase in the number of constraints. Thus, we
can solve the weighted correlation clustering problem for general graphs G.
Proposition 2. Let π be the Projectionfrom METn to MET(G). Thenfor any optimal solution x* to
the following problem
minimize	e∈E w+ (e)xe + w-(e)(1 - xe)
subject to x ∈ MET(G)	(4.2)
xij ∈ [0, 1], i,j = 1, ..., n
we have thatfor all X ∈ π-1(x*), X is an optimal solution to 2.2.
Table 2: Results for our algorithm on larger graphs. We ran our experiment on a machine with 48
physical cores and 13 GB of RAM per core, but we only used 32 threads for the computations.
Graph	n	# Constraints	Time	Opt Ratio	# Active Constraints	Iters.
Slashdot	82140	5.54 × 1014	46.7 hours	1.78	384227	145
Epinions	131,828	2.29 × 1015	121.2 hours	1.77	579926	193
Since the weighting of the edges does not affect the size of the linear program that needs to be solved,
we tested our algorithm on signed graphs to get an estimate of the running time for the algorithm.
We took two graphs from Leskovec & Krevl (2014). These graphs are much bigger instances than
our previous experiments and have 82140 nodes and 131,828 nodes, respectively. Even if we use
the parallel version of Veldt et al. (2019), based on the average time it took for a single iteration for
the CA-HepPh graph, it would take an estimated two days for a single iteration for a graph with
n ≈ 80, 000. Since most graphs require at least 100 iterations, Veldt et al. (2019); Ruggles et al.
(2019) cannot be used to solve problems of this magnitude. Other methods of solving the LP are also
not feasible as they run out of memory on much smaller instances.
As we can see from Table 2 these instances have over 500 trillion constraints, but the number of active
constraints is only a tiny fraction of the number of active constraints. Thus, using our approach we
can solve the weighted correlation clustering problem on much larger graphs than ever before and this
is possible because the graphs are sparse. That is, our oracle finds violated cycle inequalities relatively
quickly and, since we forget inactive constraints, we project onto only a relatively small number of
constraints. Thus, each iteration is done relatively quickly. In this experiment, each iteration took 500
to 3000 seconds.
4.2	Metric nearness
To do a head to head comparison against the algorithm presented in Brickell et al. (2008), we
generated two types of random weighted complete graphs. For type one graphs, for each edge e we
set w(e) = 1 with probability 0.8 and and w(e) = 0 with probability 0.2. For type two graphs, we
let w(e)〜N(0,1). For both types of graphs, We ran both algorithms until the distance between the
current iterate and its optimal decrease only solution (see Brickell et al. (2008)) was smaller than one.
The computations were done on a machine with four physical cores with 13 GB of memory per core.
We can see from Figure 2 that as n grows, our algorithm outperforms the algorithm from Brickell
et al. (2008). We also see that our algorithm has less variability in its running time. Additionally,
since we forget constraints, we are interested in the number of active constraints for these problems.
From our experiments, we see that for type one graphs, our algorithm consistently returns n2/2
constraints, and for type two graphs, consistently returns n2 constraints.
In general, Brickell et al. (2008)’s algorithm works for G = Kn only. For real-world data, we
may not have full information about the interactions between data points; such relations may be
8
Under review as a conference paper at ICLR 2019
Figure 2: The red line is the mean running time over 5 samples for the algorithm from Brickell et al.
(2008). The blue line is the running mean time for our algorithm. On the left we have the running
times for type one graphs and on the right we have the running times for type two graphs.
sparse. Therefore, we do not restrict ourselves to finding the closest point in METn when seeking a
metric. Instead, we want to find the closest point in MET(G) where G is the graph representing the
interactions for which we have information. As seen in Section 4.1.2 we can solve the problem when
G is sparse.
4.3	Metric learning
For the final problem, we solve a variant of the metric learning problem, ITML. To do a head to head
comparison against Davis et al. (2007), we implemented their algorithm in Julia. As the algorithm
from Davis et al. (2007) doesn’t solve the complete linear program, only an approximation, we
compare our algorithms on the quality of the solution.
For each data set, we uniformly at random choose 80% of the data points to be the training set and the
remaining to be the test set. We then let the similar pairs S be pairs that had the same label and the
dissimilar pairs D be all of the other pairs. For the algorithm from Davis et al. (2007), as suggested
in the paper, we randomly sampled 20c2 constraints, where c is the number of different classes and
ran the algorithm so that it performed about 106 projections.
Because the algorithm from Davis et al. (2007) is also based on Bregman projections, to do a fair head
to head comparison, we limit our selves to the same number of projections and, on each iteration,
randomly sampled 2 × 105 constraints, 105 from S and 105 from D. We then ran the algorithm for
10 iterations. Note when sampling constraints we allowed repetition. That is, if a constraint was
sampled k times during an iteration, we projected onto it k times.
Table 3: Table comparing the testing accuracy of Project and Forget and ITML. Here the
accuracy for ITML is the average over 100 trials.
Algorithm	Banana	Ionsphere	Coil2000	Letter	Penbased	Spambase	Texture
Ourt	0.88679	0.90000	0.93842	0.90250	0.97408	0.93587	0.99909
ITML	0.88816	0.86985	0.93842	0.92852	0.99039	0.90713	0.98390
The accuracy reported in Table 3 is based on one run of our algorithm since we have a theoretical
guarantee that we converge to the optimal solution. However, since there is a great amount of
variability in the constraints selected for the algorithm from Davis et al. (2007), we ran their algorithm
100 times and report the mean accuracy. As it can be seen from the table, in half cases our algorithm
has better test accuracy as we solve the complete linear program.
These results are interesting as both methods are guaranteed theoretically to converge to their optimal
solution; the difference in accuracy is due to the difference in the set of constraints being considered.
We conclude that in the cases ITML does better on average, it indicates that subsampling the set of
constraints, rather than using all of constraints, leads to lower generalization error. To verify that
this difference in performance highlighted a difference in problems and not in convergence of the
9
Under review as a conference paper at ICLR 2019
different algorithms, we ran PROJECT AND FORGET for 105 iterations, where we sample 2 × 103
constraints per iteration and did not see any significant improvement in the accuracy.
5	Future Work
In conclusion we see that our algorithm Project and Forget can be used to solve not only large
scale versions of three metric constrained problems but also opens many avenues for future work.
The first direction is motivated by ITML. As we see in Table 3, sometimes it is better to select only a
small subset of the constraints rather than computing with all of them. It is an interesting question
whether we can determine what inherent properties of the data set result in this phenomenon. If we
can answer this, we can reduce the number of constraints by several orders of magnitude.
Another avenue of work that this algorithm opens is in learning better, more general metrics. Many
existing metric learning algorithms learn a linear transform of Euclidean space and then use this
transformed space to obtain a more relevant metric. Using our technique, however, we can directly
learn a Euclidean metric that optimizes the objective function which we could then embed into
Euclidean space using multidimensional scaling or some other embedding technique. We are also no
longer restricted to Euclidean metrics, but can learn hyperbolic and tree metrics as well, getting better
metric representations of our data. With these techniques, we would gain a better understanding the
space a data set lies in and a better, usable metric representation.
10
Under review as a conference paper at ICLR 2019
References
Nir Ailon, Moses Charikar, and Alantha Newman. Aggregating inconsistent information: ranking
and clustering. In STOC’05: Proceedings of the 37th Annual ACM Symposium on Theory of
Computing,pp. 684-693. ACM, New York, 2005. doi: 10.1145/1060590.1060692.
David Avis, Patrick Hayden, and Mark M. Wilde. Leggett-Garg inequalities and the geometry of the
cut polytope. Phys. Rev. A (3), 82(3):030102, 4, 2010. ISSN 1050-2947. doi: 10.1103/PhysRevA.
82.030102.
Egon Balas and William Pulleyblank. The perfectly matchable subgraph polytope of a bipartite graph.
In Proceedings of the symposium on the matching problem: theory, algorithms, and applications
(Gaithersburg, Md., 1981), volume 13, pp. 495-516, 1983. doi: 10.1002/net.3230130405.
Nikhil Bansal, Avrim Blum, and Shuchi Chawla. Correlation clustering. Mach. Learn., 56(1-3):
89-113, 2004. ISSN 0885-6125. doi: 10.1023/B:MACH.0000033116.57574.95.
Francisco Barahona. On cuts and matchings in planar graphs. Math. Programming, 60(1, Ser. A):
53-68, 1993. ISSN 0025-5610. doi: 10.1007/BF01580600.
Francisco Barahona and Ali Ridha Mahjoub. Compositions of graphs and polyhedra. I. Balanced
induced subgraphs and acyclic subgraphs. SIAM J. Discrete Math., 7(3):344-358, 1994. ISSN
0895-4801. doi: 10.1137/S0895480190182666.
Heinz H. Bauschke and Jonathan M. Borwein. Legendre functions and the method of random
Bregman projections. J. Convex Anal., 4(1):27-67, 1997. ISSN 0944-6532.
Heinz H. Bauschke and Adrian S. Lewis. Dykstra’s algorithm with Bregman projections: a
convergence proof. Optimization, 48(4):409-427, 2000. ISSN 0233-1934. doi: 10.1080/
02331930008844513.
Amir Beck and Marc Teboulle. A fast iterative shrinkage-thresholding algorithm for linear inverse
problems. SIAM J. Imaging Sci., 2(1):183-202, 2009. ISSN 1936-4954. doi: 10.1137/080716542.
Aurelien BelleL Amaury Habrard, and Marc Sebban. A survey on metric learning for feature vectors
and structured data. ArXiv, abs/1306.6709, 2013.
Justin Brickell, Inderjit S. Dhillon, Suvrit Sra, and Joel A. Tropp. The metric nearness problem.
SIAM J. Matrix Anal. Appl., 30(1):375-396, 2008. ISSN 0895-4798. doi: 10.1137/060653391.
Yair Censor and Stavros Zenios. Parallel optimization: Theory, algorithms, and applications. Oxford
University Press, 01 1997. ISBN ISBN-13: 978-0195100624.
Karthekeyan Chandrasekaran, Ldszl6 A. V6gh, and Santosh Vempala. The cutting plane method
is polynomial for perfect matchings. In 2012 IEEE 53rd Annual Symposium on Foundations of
Computer Science—FOCS 2012, pp. 571-580. IEEE Computer Soc., Los Alamitos, CA, 2012.
Moses Charikar, Venkatesan Guruswami, and Anthony Wirth. Clustering with qualitative information.
J. Comput. System Sci., 71(3):360-383, 2005. ISSN 0022-0000. doi: 10.1016/j.jcss.2004.10.012.
Jason V. Davis, Brian Kulis, Prateek Jain, Suvrit Sra, and Inderjit S. Dhillon. Information-theoretic
metric learning. In Proceedings of the 24th International Conference on Machine Learning, ICML
’07, pp. 209-216, New York, NY, USA, 2007. ACM. ISBN 978-1-59593-793-3.
Santanu S. Dey and Marco Molinaro. Theoretical challenges towards cutting-plane selection. Math.
Program., 170(1, Ser. B):237-266, 2018. ISSN 0025-5610. doi: 10.1007/s10107-018-1302-4.
Michel Deza and Monique Laurent. Applications of cut polyhedra. I, II. J. Comput. Appl. Math., 55
(2):191-216, 217-247, 1994. ISSN 0377-0427. doi: 10.1016/0377-0427(94)90020-5.
Inderjit S. Dhillon and Joel A. Tropp. Matrix nearness problems with Bregman divergences. SIAM J.
Matrix Anal. Appl., 29(4):1120-1146, 2007. ISSN 0895-4798. doi: 10.1137/060649021.
Tommy Elfving. An algorithm for maximum entropy image reconstruction from noisy data. Math.
Comput. Modelling, 12(6):729-745, 1989. ISSN 0895-7177. doi: 10.1016/0895-7177(89)90358-0.
11
Under review as a conference paper at ICLR 2019
Dotan Emanuel and Amos Fiat. Correlation clustering—minimizing disagreements on arbitrary
weighted graphs. In Algorithms—ESA 2003, volume 2832 of Lecture Notes in Comput. Sci., pp.
208-220. Springer, Berlin, 2003. doi:10.1007/978-3-540-39658-1_21.
Rong-En Fan, Pai-Hsuen Chen, and Chih-Jen Lin. Working set selection using second order infor-
mation for training support vector machines. J. Mach. Learn. Res., 6:1889-1918, 2005. ISSN
1532-4435.
Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, Xiang-Rui Wang, and Chih-Jen Lin. Liblinear: A
library for large linear classification. Journal of Machine Learning Research, 9:1871-1874, 2008.
Samuel Fiorini, Serge Massar, Sebastian Pokutta, Hans Raj Tiwary, and Ronald de Wolf. Linear
vs. semidefinite extended formulations: exponential separation and strong lower bounds. In
STOC’12—Proceedings of the 2012 ACM Symposium on Theory of Computing, pp. 95-106. ACM,
New York, 2012. doi: 10.1145/2213977.2213988.
A.	C. Gilbert and L. Jain. If it ain’t broke, don’t fix it: Sparse metric repair. In 2017 55th Annual
Allerton Conference on Communication, Control, and Computing (Allerton), pp. 612-619, Oct
2017. doi: 10.1109/ALLERTON.2017.8262793.
Anna C. Gilbert and Rishi Sonthalia. Unsupervised metric learning in presence of missing data.
2018 56th Annual Allerton Conference on Communication, Control, and Computing (Allerton), pp.
313-321, 2018.
W. Glunt, T. L. Hayden, S. Hong, and J. Wells. An alternating projection algorithm for computing
the nearest Euclidean distance matrix. SIAM J. Matrix Anal. Appl., 11(4):589-600, 1990a. ISSN
0895-4798. doi: 10.1137/0611042.
W. Glunt, T. L. Hayden, S. Hong, and J. Wells. An alternating projection algorithm for computing the
nearest euclidean distance matrix. SIAM Journal on Matrix Analysis and Applications, 11:589-12,
October 1990b.
M. Grotschel, L. Lovasz, and A. Schrijver. The ellipsoid method and its consequences in combinatorial
optimization. Combinatorica, 1(2):169-197, 1981. ISSN 0209-9683. doi: 10.1007/BF02579273.
Piotr Indyk. Sublinear time algorithms for metric space problems. In Annual ACM Symposium on
Theory of Computing (Atlanta, GA, 1999), pp. 428-432. ACM, New York, 1999. doi: 10.1145/
301250.301366.
Alfredo N. Iusem. On dual convergence and the rate of primal convergence of Bregman’s convex
programming method. SIAM J. Optim., 1(3):401-423, 1991. ISSN 1052-6234. doi: 10.1137/
0801025.
Alfredo N. Iusem and Alvaro R. De Pierro. On the convergence properties of Hildreth’s quadratic
programming algorithm. Math. Programming, 47(1, (Ser. A)):37-51, 1990. ISSN 0025-5610. doi:
10.1007/BF01580851.
Ariel Jaimovich, Gal Elidan, Hanah Margalit, and Nir Friedman. Towards an integrated protein-
protein interaction network: A relational markov network approach. Journal of computational
biology : a journal of computational molecular cell biology, 13 2:145-64, 2006.
Thorsten Joachims, Thomas Finley, and Chun-Nam John Yu. Cutting-plane training of structural
svms. Machine Learning, 77:27-59, 2009.
Monique Laurent. A connection between positive semidefinite and Euclidean distance matrix
completion problems. Linear Algebra Appl., 273:9-22, 1998. ISSN 0024-3795. doi: 10.1016/
S0024-3795(98)90126-4.
Jure Leskovec and Andrej Krevl. SNAP Datasets: Stanford large network dataset collection, June
2014.
Bo Lin, Anthea Monod, and Ruriko Yoshida. Tropical foundations for probability and statistics on
phylogenetic tree space. arXiv e-prints, 2018.
12
Under review as a conference paper at ICLR 2019
Angelia NediC. Random algorithms for convex minimization problems. Math. Program., 129(2, Ser.
B):225-253, 2011. ISSN 0025-5610. doi: 10.1007∕s10107-011-0468-9.
Yu. E. Nesterov. A method for solving the convex programming problem with convergence rate
O(1∕k2). Dokl. Akad. Nauk SSSR, 269(3):543-547, 1983. ISSN 0002-3264.
Xinghao Pan, Dimitris S. Papailiopoulos, Samet Oymak, Benjamin Recht, Kannan Ramchandran,
and Michael I. Jordan. Parallel correlation clustering on big graphs. In NIPS, 2015.
Divya Pandove, Shivani Goel, and Rinkle Rani. Correlation clustering methodologies and their
fundamental results. Expert Systems, 2018.
Laurent Poirrier and James Yu. On the depth of cutting planes. arXiv e-prints, art. arXiv:1903.05304,
Mar 2019.
B.	T. Polyak. Random algorithms for solving convex inequalities. In Inherently parallel algorithms
in feasibility and optimization and their applications (Haifa, 2000), volume 8 of Stud. Comput.
Math., pp. 409-422. North-Holland, Amsterdam, 2001. doi: 10.1016/S1570-579X(01)80024-0.
Thomas Rothvoss. The matching polytope has exponential extension complexity. In STOC’14—
Proceedings of the 2014 ACM Symposium on Theory of Computing, pp. 263-272. ACM, New
York, 2014.
Cameron Ruggles, Nate Veldt, and David F. Gleich. A Parallel Projection Method for Metric
Constrained Optimization. arXiv e-prints, art. arXiv:1901.10084, Jan 2019.
Frederic Sala, Chris De Sa, Albert Gu, and Christopher Re. Representation tradeoffs for hyperbolic
embeddings. Proceedings of the 35th International Conference on Machine Learning, pp. 4460-
4469, July 2018.
I. J. Schoenberg. Metric spaces and positive definite functions. Trans. Amer. Math. Soc., 44(3):
522-536, 1938. ISSN 0002-9947. doi: 10.2307/1989894.
David Sontag and Tommi S. Jaakkola. New outer bounds on the marginal polytope. In J. C. Platt,
D. Koller, Y. Singer, and S. T. Roweis (eds.), Advances in Neural Information Processing Systems
20, pp. 1393-1400. Curran Associates, Inc., 2008.
David Sontag, Talya Meltzer, Amir Globerson, Tommi Jaakkola, and Yair Weiss. Tightening lp
relaxations for map using message passing. In Proceedings of the Twenty-Fourth Conference on
Uncertainty in Artificial Intelligence, UAI’08, pp. 503-510, Arlington, Virginia, United States,
2008. AUAI Press. ISBN 0-9749039-4-9.
David Sontag, Do Kook Choe, and Yitao Li. Efficiently searching for frustrated cycles in map
inference. In Proceedings of the Twenty-Eighth Conference Annual Conference on Uncertainty in
Artificial Intelligence (UAI-12), pp. 795-804, Corvallis, Oregon, 2012. AUAI Press.
David A Sontag and Tommi S. Jaakkola. On iteratively constraining the marginal polytope for
approximate inference and map. Semantic Scholar, 2007.
Juan Luis Suarez Diaz, Salvador Garcia, and Francisco Herrera. A tutorial on distance metric learning:
Mathematical foundations, algorithms and software. arxiv eprint, 12 2018.
Yichuan Tang. Deep learning using support vector machines. ICML 2013 Challenges in Representa-
tion Learning, abs/1306.0239, 2013.
Nate Veldt, David Gleich, Anthony Wirth, and James Saunderson. Metric-constrained optimization
for graph clustering algorithms. SIAM Journal on Mathematics of Data Science, 1:333-355, 01
2019. doi: 10.1137/18M1217152.
Mengdi Wang and Dimitri P. Bertsekas. Incremental constraint projection-proximal methods for
nonsmooth convex optimization. http://www.mit.edu/ dimitrib/, 2013.
Mengdi Wang, Yichen Chen, Jialin Liu, and Yuantao Gu. Random multi-constraint projection:
Stochastic gradient methods for convex optimization with many constraints. ArXiv, abs/1511.03760,
2015.
13
Under review as a conference paper at ICLR 2019
Yubo Wang, Linli Xu, Yucheng Chen, and Hao Wang. A scalable approach for general correlation
clustering. In ADMA, 2013.
Chen Yanover, Talya Meltzer, and Yair Weiss. Linear programming relaxations and belief
propagation—an empirical study. J. Mach. Learn. Res.,7:1887-1907, 2006. ISSN 1532-4435.
14
Under review as a conference paper at ICLR 2019
6 Convex programming
As we mentioned in main body of the paper, there is a much more general formulation of the metric
constrained optimization problems and a correspondingly general variant of the algorithm. We present
that setting below and detail the convergence results in the following section.
Given a strictly convex function f, and a finite family of half-space H = {Hi} such that Hi = {x :
(a%, Xi ≤ bi}, We want to find the unique point x* ∈ Ti Hi =: C that minimizes f. That is, if We set
A to be the matrix whose rows are ai and b be the vector whose coordinates are bi we seek
minimize f(x)
subject to Ax ≤ b
(6.1)
We refer to each Hi as a constraint set and C as the feasible region. We shall assume that C is not
empty, i.e., there is at least one feasible point. In general, We can represent any half-space by a linear
inequality.
In general, since A is an extremely large matrix, computing A or Writing A doWn is not computation-
ally feasible for many large instances of the problem. Therefore, We access the constraint sets only
through an oracle that has one of the tWo folloWing separation properties.
Property 1. Q is a deterministic separation oracle for a family of half-spaces H, if there exists a
positive, non-decreasing, continuous function φ, with φ(0) = 0, such that on input x ∈ Rd, Q either
certifies x ∈ C or returns a list L ⊂ H such that
max dist(x, C) ≥ φ(dist(x, C)).
C∈L
Property 2. Q is a random separation oracle for a family of half-spaces H, if there exists some
distribution D and a lower bound τ > 0, such that on input x ∈ Rd, Q returns a list L ⊂ H such
that
〜 -~ -
∀H ∈ H, PrD [H ∈ L] ≥ τ.
For the random oracle, We do not need it to decide Whether x ∈ C, so this oralce can be used to solve
optimization problems over polytopes for Which deciding membership is NP-hard.
In addition our method Works for a rich class of functions knoWn as Bregman functions.
Definition 3. Afunction f : Λ → R is called a Bregman function if there exists a non-empty convex
set S such that S ⊂ Λ and the following hold:
(i)	f (x) is continuous, strictly convex on S, and has continuous partial derivatives in S.
(ii)	For every α ∈ R, the partial level SetS Lf (y,α) := {x ∈ S : Df(x,y) ≤ α} and
Lf (x, α) := {y ∈ S : Df(x, y) ≤ α} are boundedfor all X ∈ S,y ∈ S.
(iii)	Ifyn ∈ S and lim yn = y*, then lim Df (y*, yn) = 0.
n→∞	n→∞
(iv)	If yn	∈	S, Xn ∈	S,	lim	Df(Xn,yn)	= 0,	yn	→	y*, and Xn is bounded, then Xn →	y*.
n→∞
We denote the family of Bregman functions by B(S). We refer to S as the zone of the function and we
take the closure of the S to be the domain of f.
Definition 4. We say that a hyperplane Hi is strongly zone consistent with a respect to a Bregman
function f and its zone S, if for all y ∈ S and for all hyperplanes H, parallel to Hi that lie in
between y and Hi, the Bregman projection of y onto H lies in S instead ofin S.
Next, We briefly discuss under What assumptions can We solve solve our optimization problem and
What these assumptions mean.
Assumption 1. f(X) is a Bregman function.
This class of function includes many natural objective functions, including f(X) = - Pin=1 Xi log(Xi)
with zone S = R+ (here f is defined on the boundary of S by taking the limit) and f (x) = P ∣∣Xkp
for p ∈ (1, ∞). The `p norms for p = 1, ∞ are not Bregman functions but can be made Bregman
functions by adding a quadratic term. That is, f(X) = cTX is a not Bregman function, but cT X+XT QX
for any positive definite Q is a Bregman function.
15
Under review as a conference paper at ICLR 2019
Additionally, strongly convex functions and Legendre functions are related to Bregman functions, but
neither class implies the other. See Bauschke & Lewis (2000) for an example and a more in-depth
discussion.
Assumption 2. All hyperplanes in H are strongly zone consistent with respect to f (x).
This assumption is used to guarantee that when we do a projection the point we project onto lies within
our domain. This is not too restrictive. For example, all hyperplanes are strongly zone consistent
with respect to the objective functions f(x) = 0.5kxk2 and f(x) = - Pi xi log(xi).
Assumption 3. C is non-empty.
This is needed to make sure that the algorithm converges.
7 The general algorithms
To set the stage for subsequent discussions, we present the general structure of all of our algorithms.
They are all iterative and, in general, are run until some convergence criterion has been met. The
convergence criterion depends largely on the specific application for which the algorithm is tailored.
For this reason, we postpone the discussion of the convergence criterion until the applications section.
Each iteration consists of three phases, as shown in algorithm 3. In the first phase, we query our oracle
Q to obtain a list of constraints L. In the second phase, we merge L(ν), the list of constraints we have
been keeping tracking of up to the νth iteration, with L and project onto each of the constraints in the
list L(ν) ∪ L iteratively. Finally, in the third phase, we forget some constraints.
Algorithm 3 General Algorithm.
1 2 3 4 5 6 7	: function F(Q, f) L(O) = 0, z(0) = 0. Initialize x(0) so that Vf (x(0)) = 0. :	while Not Converged do :	L= Q(xν) L(ν+1) = L(V) ∪ L	〜 x(ν+1) = PrCjeCt(X(V),L(ν+1)) L(ν+1) = FOrget(L(V+1)) return x
7.1 Project and Forget algorithms
The project and forget steps for algorithm are presented in Algorithm 4. Let us step through the code
to understand the behavior of the algorithm. Let Hi = {x : hai, xi ≤ bi be our constraint and x our
current iterate. The first thing We do is calculate x* and θ. Here x* is the projection of X onto the
boundary of Hi and θ is a “measure” ofhow far X is from x*. However, θ can be any real number.
Let us discuss separately the cases θ positive and negative beloW.
It can be easily seen Censor & Zenios (1997) that θ is negative if and only if the constraint is violated.
In this case, c = θ. This is because (as we will see in proof) we will always maintain that zi ≥ 0.
Then on line 5, we just compute the projection of x onto Hi . Finally, since we corrected x for this
constraint, we add ∣θ∣ to z%. Since each time we correct for Hi, we add to zi, we see that Zi stores
how the total corrections made for Hi .
On the other hand, if θ is positive, this means that this constraint is satisfied. In this case, if we also
have that zi is positive, i.e., we have corrected for Hi before, then we have over compensated for this
constraint. Hence we must do undo some of the corrections. Thus, if c = zi then we undo all of the
corrections and zi is now 0. Otherwise if c = θ we only undo part of the correction.
The FORGET step is relatively easy, given a constraint Hi we just need to check if zi = 0. If zi = 0,
then this means we have not done any net corrections for this constraint. Thus, we can forget about it;
i.e., delete it from L(ν).
16
Under review as a conference paper at ICLR 2019
Algorithm 4 Project and Forget algorithms.
1:	function PROJECT(x, z, L)
2:	for Hi = {y : hai, yi = bi} ∈ L do
3:	Find χ*,θ by solving Vf (x*) - Nf(X) = θai and x* ∈ Hi
4:	ci = min (zi , θ)
5:	x — such that Vf (xn+1) — Vf (x) = Ciai
6:	Zi J Zi — Ci
return x, z
7:	function FORGET(x, Z, L)
8:	for Hi = {x : hai, xi = bi} ∈ L do
9:	if Zi == 0 then Forget Hi
return L
In general, calculating the Bregman projection (line 3) cannot be done exactly. See Dhillon & Tropp
(2007) for a general method to perform the calculation on line 3 and for an analytic formula for when
f is a quadratic function.
7.2 Convergence Analysis
Now that we have specified our algorithm, we need to establish a few crucial theoretical properties.
The first is that under assumptions 1,2,3 our algorithm is guaranteed to converge to the global
optimum solution. In fact, we also show that asymptotically, our error decreases at an exponential
rate. These main theoretical results can be summarized by the following theorem.
Theorem 3. If f ∈ B(S), Hi are strongly zone consistent with respect to f, and ∃ x0 ∈ S such that
Vf(x0) = 0, then
1. If the oracle Q satisfies property 1 (property 2), then any sequence xn produced by the
above algorithm converges (with probability 1) to the optimal solution of problem 6.1.
2. If x* is the optimal solution, f is twice differentiable at x*, and the Hessian H := Hf(x*)
is positive semidefinite, then there exists ρ ∈ (0, 1) such that
lim kx* — xν+ιkH ≤ P
ν→∞ kx* — xνkH
(7.1)
where ky k* 1 2H = yT Hy. In the case when we have an oracle that satisfies property 2, the
limit in 7.1 holds with probability 1.
Proof. The proof of this theorem has been moved to the supplementary material section. □
The proof of Theorem 3 also establishes another important theoretical property.
Proposition 3. If ai is an inactive constraint, then (with probability 1) Ziν = 0 for the tail of the
sequence.
Corollary 2. Under the assumptions for part (2) of Theorem 3, we have that the sequence Zn → Z*
also converges.
These properties are important as they permit the following interpretation of our algorithm. The
algorithm spends the initial few iterations identifying the active constraints from amongst a large
number of constraints. The algorithm then spends the remainder of the iterations finding the optimal
solution with respect to these constraints. This ability to find the set of active constraints is one of the
main advantages of our algorithm.
7.3 The Metric Constrained Versions
First we can easily see that function Metric Violation in Algorithm 1 is an oracle that satisfies
Property 1
17
Under review as a conference paper at ICLR 2019
Proposition 4. Function METRIC VIOLATION in Algorithm 1 is an Θ(n2 log(n) + n|E |) oracle
that has Property 1
Proof. The first step in METRIC VIOLATION is to calculate the shortest distance between all pairs of
nodes. This can be done using Dijkstra’s algorithm in Θ(n2 log(n) + n|E|) time. Then if the shortest
path between any adjacent pair of vertices is not the edge connecting them, then the algorithm has
found a violated cycle inequality. Note that if no such path exists, then all cycle inequalities have
been satisfied. Hence our point is within the metric polytope. Thus, we have an oracle that separates
the polytope. However, we want an oracle that satisfies property 1.
Given a point x and a hyperplane HC,e, defined by some cycle C and an edge e, the deficit of this
constraint is given by the following formula.
d(C, e) = x(e) — ^X x(e)
e∈c,e=e
If this quantity is positive, then x violates this constraint. In this case, the distance from x to this
constraint is d(C,∣e). While the above oracle does not find the cycle C and edge e that maximize this
distance, it does find the cycle C and edge e that maximize d(C, e). Since |C| ∈ [1, n], if we let
φ(x) = x/n, We see that oracle satisfies property 1.	□
Similarly we can see that uniformly randomly sampling constraints is an oracle that satisfies Property
2. Thus We can see that both algorithms presented in the main text are special cases of the above
algorithm.
7.4 Truly Stochastic Variant
NoW Algorithm 4 can be used With an oracle that satisfies property 2. HoWever, this is not a completely
stochastic algorithm. We still have to keep track of the constraints that We have seen and carefully
pick Which constraints to forget. Nevertheless, We can modify our forget step to forget all constraints
and obtain a truly stochastic version of the algorithm. In this version, at each iteration, We choose a
random set of constraint and project onto these constraints only, independently of What constraints
Were used in previous iterations. We cannot, hoWever, forget the values of the dual variables. In this
case, We have the folloWing convergence result.
Theorem 4. If f ∈ B(S), Hi are strongly zone consistent with respect to f, and ∃ x0 ∈ S such
that Vf (x0) = 0, then with probability 1 any Sequence Xn produced by the above truly Stochastic
algorithm converges to the optimal solution ofproblem 6.1. Furthermore, if x* is the optimal solution,
f is twice differentiable at x*, and the Hessian H := Hf (x*) is positive semidefinite, then there
exists ρ ∈ (0, 1) such that with probability 1,
lim inf
ν→∞
kx*— xν+1kH
∣∣χ* — XV ∣∣h
≤ ρ.
This version of our algorithm is very similar to the algorithms presented NediC (2011); Wang et al.
(2015). The major difference being that We do not need to a gradient descent step. Instead We
maintain the KKT conditions, by keeping track of the dual variables and doing dual corrections.
HoWever, in practice using 4 With the random oracle tends to produce better results. This is because
by not forgetting the active constraints that We have seen, instead of hoping that We sample them, We
speed up convergence significantly.
8 Convergence Results
In this section, We present the proofs of Theorems 3 and 4. Because the proof of Theorem 3 is quite
technical and involves tWo different types of separation oracles, We split it into several parts. In
Subsections 8.1 and 8.2, We prove the first part of Theorem 3 for separation oracles With property 1
and 2, respectively. In Subsection 8.3, We prove the second part of Theorem 3 (also subdividing this
proof into several cases). Finally, in Subsection 8.4 We prove Theorem 4, noting only the changes
necessary from the proof of Theorem 3.
18
Under review as a conference paper at ICLR 2019
8.1	Proof of part 1 of Theorem 3 for oracles that satisfy property 1
We remind the reader of the notation established in Section 2. The vector of variables over which we
optimize is x, f is the objective function, Hi = {y : hy, aii = bi} are the hyperplanes that lie on the
boundaries of the half-space constraints, L is the Lagrangian, z is the dual variable, A is the matrix
with rows given by ai, and b is the vector with rows bi .
Next, we clarify the indexing of the variables. Algorithm 3 has three steps per iteration and during
the PROJECT step there are multiple projections. When we want to refer to a variable after the νth
iteration, it will have a superscript with a ν. When we refer to a variable after the n(i, k)th projection,
we use the superscript n(i, k). Finally, before the nth projection, i(n) will represent the index of the
hyperplane onto which we project.
Finally, let R be the maximum number of constraints that our oracle Q returns. This is clearly upper
bounded by the total number of constraints, which we have assumed is finite. We are now ready to
prove the first part of Theorem 3.
Theorem 3. (Part 1) If f ∈ B(S), Hi are strongly zone consistent with respect to f, ∃ x0 ∈ S, such
that Vf (x0) = 0, and the oracle Q satisfies property 1, then any sequence Xn produced by Algorithm
3 converges to optimal solution of problem 6.1.
Proof. The proof of this theorem is an adaptation of the proof of convergence for the traditional
Bregman method that is presented in Censor & Zenios (1997) whose proof entails the following four
steps. The main difference between Censor and Zenios’ proof and ours is that of the last two steps.
We present the entire proof, however, for completeness. To that end, we show that
Step 1. the KKT condition, Vf (x) = Vf(x0) - ATz, is always maintained,
Step 2. the sequence xn is bounded and it has at least one accumulation point,
Step 3. any accumulation point of xn is feasible (i.e., is in C), and
Step 4. any accumulation point is the optimal solution.
Step 1. The KKT condition, Vf (x) = Vf(x0) - ATz, is always maintained.
We show by induction that for all n, Vf(xn) = -ATzn. In the base case, z = 0, thus, Vf(x0) =
0 = -ATz0. Assume the result holds for iteration n, then
Vf(xn+1) = Vf(xn) + cnai(n) = -ATzn + ATcnei(n) = -AT(zn - cnei(n)) = -ATzn+1
We know that cn ≤ zin(n) ; therefore, we maintain zn+1 ≥ 0 as well.
Step 2. The sequence xn is bounded and has an accumulation point.
To show that xn is a bounded, we first show that L(xn, zn) n is a monotonically increasing sequence
bounded from above. This observation results from the following string of equalities:
L(xn+1, zn+1) -L(xn,zn) =	f(xn+1) - f(xn)	+	hzn+1, Axn+1 -bi	- hzn, Axn - bi
=	f(xn+1) - f(xn)	+	hATzn+1, xn+1i	-	hAT zn, xni - hzn+1	-zn,bi
= f(xn+1) - f(xn) - hVf(xn+1), xn+1i + hVf(xn), xni + hcnei(n), bi
= f(xn+1) - f(xn) - hVf(xn) + cnai(n), xn+1i + hVf(xn), xni + cnbi(n)
= f(xn+1) - f(xn) - hVf(xn), xn+1 - xni - hcnai(n), xn+1i + cnbi(n)
=Df(xn+1,xn)+cn(bi(n)-hai(n),xn+1i)
'-------{z----} '----------{z---------}
(1)	(2)
Next, we show that both terms (1) and (2) are non-negative. We know that Df is always non-negative
so we only need to consider term (2). There are two cases: (i) if cn = θn, then xn+1 ∈ Hi(n) and
19
Under review as a conference paper at ICLR 2019
bi(n) - hai(n), xn+1i = 0. On the other hand, (ii) if cn = zin(n), then bi(n) - hai(n), xn+1 i ≥ 0
and cn ≥ 0. We can conclude that the difference between successive terms of L(xn, zn) is always
non-negative and, hence, it is an increasing sequence.
To bound the sequence, let y be a feasible point (i.e., Ay ≤ b). (Note that this is the only place we
use the assumption that the feasible set is not empty.) Then
Df (y, Xn) = f (y) - f (xn) -hVf (xn), y -Xni
=f(y)-f(xn)+hzn,Ay-Axni
≤f(y)-f(Xn)+hzn,b-AXni.
Rearranging terms in the inequality, we obtain a bound on the sequence L(Xnzn) from above:
L(Xn,zn)=f(Xn)+hzn,AXn-bi≤f(y)-Df(y,Xn)≤f(y).
Since the sequence (L(Xn, zn))n∈N is increasing and bounded, it is a convergent sequence and the
difference between successive terms of the sequence goes to 0. Therefore,
lim Df(Xn+1,Xn) = 0.
n→∞
From the previous inequality we also have that
Df(y, Xn) ≤ f (y) - L(xn,zn) ≤ f (y) - L(x0, z0) =: α.
Using part (ii) of the definition of a Bregman function, we see that L2f (y, α) is bounded and since
(Xn)n∈N ∈ Lf2 (y, α), Xn is a bounded sequence with an accumulation point.
Step 3. Any accumulation point x* of Xn is feasible (i.e., is in C).
This is the only step in which We use the fact that our oracle satisfies property 1. Let x* be some
accumulation point for Xn and assume for the sake of contradiction that AX* 6≤ b. Let A, b be the
maximal set of constraints that X* does satisfy; i.e.,
≈ , ~
Ax* ≤ b.
Let (Xnk ) be a subsequence such that Xnk → X* and H be a constraint that X* violates. Define as
:= φ(d(X*, H)) > 0.	(8.1)
Because Xn is bounded, Xnk is a convergent subsequence Xnk → X*, and Df (Xn+1, Xn) → 0, by
equation 6.48 from Censor & Zenios (1997) we see that for any t,
Xnk+t → X*.
In particular, the proposition holds for all t ≤ 2|A| + 2=: T.
Let us consider an augmented subsequence Xnk, Xnk+1, . . . , Xnk+T, i.e., add in extra terms. Note
that if nk+1 - nk → ∞, then this augmented sequence is not the entire sequence. We want to show
that infinitely many of the terms in our augmented sequence satisfy a constraint not in A. Should this
hold, then because we have only finitely many constraints, there exists at least one single constraint
a that is not in A, such that infinitely many terms of the augmented sequence all satisfy the single
constraint a. Finally, because our augmented sequence converges to x* and we are only looking at
closed constraints, we must have that X* also satisfies the constraint aa. Thus, we would arrive at a
contradiction of the maximality of A and x* would have to be in the feasible region.
To see that infinitely many of the terms in our augmented sequence satisfy a constraint not in Aa,
let νk be the iteration in which the nkth projection takes place. Note that we can assume without
loss of generality that in any iteration, we project onto any constraint at most once. If this were not
the case and we projected onto constraints more often, we would simply change the value of T to
reflect this larger number of projections. Therefore, we have two possibilities for which iteration the
nk + |Aa| + 1st projection takes place and we consider each case below.
Case 1:	The nk + |Aa| + 1st projection, infinitely often, takes places in νkth iteration. Since we
project onto each constraint at most once, one of the projections between the nk and nk + |Aa| + 1st
20
Under review as a conference paper at ICLR 2019
projection must be onto a hyperplane defined by a constraint not represented in A and amongst the
人
terms xnk, χnk+1,..., Xnk+lAl+1, We must have a term that satisfies a constraint not in A infinitely
often.
Case 2:	The n + | A| + 1st projection, infinitely often, takes place in Vk + 1st iteration or later.
If this projection happens in νk + 1st iteration, consider the iteration in Which We do the nk + Tth
projection. If this projection also takes place in the νk + 1st iteration, then We have done at least
|A| + 1 projections in the Vk + 1st iteration. Hence, amongst χnk+lAl + 1,..., χnk+T, we must have
a term that satisfies a constraint not in A.
If the nk + |A| + 1st or the n + Tth projection happens in the Vk + 2nd iteration or later, then
between the nk th and the nk + Tth projection, we must have projected onto all constraints returned
by oracle in the Vk + 1st iteration. Therefore, we must have projected onto some hyperplane defined
by a (for some constraint C) such that
dnk ：= d(xνk+1,C) ≥ φ(d(xνk+1,c)).
EI	. 1	∙ .	i'Γ∙ ♦ .1	IlC-Cl	1 ∙	17 ±	1 . 1 .'/'ll	± ll∕C,l
Then there exists a sufficiently small δ > 0, depending on A, b, x*, such that if ∣∣y - x*k ≤ δ, then
Ay ≤ b +21,
where 1 is vector of all ones.
Since our augmented sequence converges to x*, we know that there exists a K, such that for all
k ≥ K and t ≤ T, kxnk+t - x*∣ < δ. That is, for all k ≥ K and t ≤ T,
Axnk+t ≤ b + ∣1.	(8.2)
Note xνk+1 is within our augmented sequence so if ^ is infinitely often in A, by equation 8.2, we
have that infinitely often
-≥ dnk.
2 —
Finally, because the augmented sequence converges to x*,
-=φ(d(x*, H)) ≤ φ(d(x*,C)) = lim φ(d(xνk+1, C)) ≤ lim dnk ≤ -.
k→∞	k→∞	2
The first inequality follows from the fact that φ is non-decreasing. Therefore, ^ is not in A infinitely
often and amongst xnk , xnk+1, . . . , xnk+T, we must have a term that satisfies a constraint not in
A infinitely often. Thus, there is a constraint a not in A that is satisfied by infinitely terms of our
augmented sequence and we have a contradiction.
Step 4. Optimality of accumulation point.
Because we have established the feasibility of all accumulation points, we show next that any
accumulation point xnk → x* is optimal.
First, we show that there exists an N, such that for any k ≥ N, and for any ai such that
hai,x*i < bi,
we have zink = 0. To do so, we assume for the sake of contradiction that for some ai, our sequence zink
is infinitely often not 0. The algorithm then projects onto this constraint infinitely often. Therefore,
the point xnk lies on the hyperplane defined by ai , bi infinitely often. Thus, the limit point x* must
lie on this hyperplane as well and we have a contradiction.
Now we know that for any constraint ai, we either have that hai, x*i = bi or we have that zink = 0
for the tail of the sequence. Thus, for sufficiently large k,
hznk,Axnk - bi = hAT znk,xnk - x*i = (-▽/(Xnk ),xnk - x*i = Df(x*,xnk) - f (x*) + f(xnk).
Next, by part (iii) of the definition of a Bregman function,
lim Df(X*,Xnk) =0.
k→∞
21
Under review as a conference paper at ICLR 2019
Finally,
lim L(Xk ,zk) = lim f (Xnk) + (znk, Axnk — b)= f(x*).
k→∞	k→∞
We also know that L(Xk,zk) ≤ f (y) for any feasible y. Thus, f (x*) ≤ f (y). Hence x* is an
optimal solution. Now since f is strictly convex, this optimal point is unique. Therefore, we have
that (xn)n∈N has only one accumulation point and χn → x*.	□
An important fact consequence of this proof is the following proposition:
Proposition 3. If ai is an inactive constraint, then there exists a N, such that for all n ≥ N, we have
that zin = 0. That is, after some finite time, we never project onto inactive constraints ever again.
8.2	Proof of part 1 of Theorem 3 for oracles that satisfy property 2
In this subsection, we prove part 1 of Theorem 3 for oracles that satisfy property 2. We make note of
the key ideas in this proof as they are useful in the proof of the truly stochastic variant. To be precise,
we prove:
Theorem 1. (Part 1) If f ∈ B(S), Hi are strongly zone consistent with respect to f, ∃ x0 ∈ S, such
that Vf (x0) = 0, and the oracle Q satisfies property 2, then with probability 1, any Sequence xn
produced by Algorithm 3 converges to optimal solution of problem 6.1.
Proof. Assume that we have an oracle that satisfies property 2. A careful reading of the previous
proof shows that if we switch out an oracle with property 1 for an oracle with property 2, then we only
need to adjust step 3 of our proof. The crucial part of that step was showing that for our augmented
sequence, we had infinitely many terms that satisfied a constraint not in A. We make the following
adjustments to our analysis.
Let νk be the iteration in which the nkth projection takes place. In the previous proof, we used the
property of the oracle only when the nk +Tth projection took place in the νk + 2nd iteration or a later
iteration. In this case, the augmented sequence encompasses all of the νk + 1st iteration infinitely
often.
Let us choose a constraint ^ that is not satisfied by x*. Because the oracle satisfies property 2, for
each iteration Vk + 1, our oracle returns ^ with probability at least τ > 0. By the Borel Cantelli
Lemma, we know that during the selected iterations, the constraint ^ is, with probability one, returned
infinitely often by our oracle. Thus, our augmented sequence satisfies this constraint with probability
1 and x* lies in the feasible region with probability 1.	□
A direct consequence of this proof is the proof of the probabilistic version of Proposition 3.
Proposition 3. With probability 1, we project onto inactive constraints a finite number of times.
8.3	Proof of part 2 of Theorem 3
The discussions in Iusem & De Pierro (1990); Iusem (1991) almost directly apply to that for our
algorithm. For completeness, we present it along with the necessary modifications. As with the
traditional Bregman algorithm, we first present the case when f(x) is quadratic. That is,
f (x) = r + ST ∙ X + gxTHx
where H is a positive definite matrix. In this case, it is easy to see that
Df (x, y) = kx - yk2H := (x - y)TH(x - y).
22
Under review as a conference paper at ICLR 2019
8.3.1	Proof of part 2 of Theorem 3—Quadratic Case
In this section, we will prove the following variation of Theorem 3.
Theorem 3. If f is a strictly convex quadratic function, Hi are strongly zone consistent with respect
to f, x0 = H-1s ∈ S, and the oracle Q satisfies either property 1 or2, then there exists ρ ∈ (0, 1)
such that
kx*-Xν+1kH
ν→∞ I∣x* - XV∣∣H
≤ρ
(8.3)
where IyI2H = yT Hy. In the case when we have an oracle that satisfies property 2, the limit in 8.3
holds with probability 1.
We establish some notation ahead of our lemmas. Let I be the set of all active constraints. That is, if
x* is the optimal solution then
I = {i : hai,x*i = bi}.
Let S be the set of all x that satisfy these constraints (namely S = {x : ∀i ∈ I, hai, xi = bi}). Let
Hx be the hyperplane, such that Hx represents the constraint in I that is furthest from x. Define
d(x, Hx)
μ = inf —————.
x6∈S d(x, S)
By IUsem & De Pierro (1990), We know that μ > 0. Let U be the set of all optimal dual variables z;
i.e., U = {z : Vf (x*) = -ATz} and let IV = {i : zν+1 = 0}.
Next, we present a few preliminary lemmas. These lemmas exist in some form or another in Iusem
(1991); Iusem & De Pierro (1990) and we present them suitably modified for our purpose. These
lemmas require the following set of assumptions about an iteration ν:
1.	∀i 6∈ I, ziV = 0;
2.	for all i 6∈ I, we do not project onto this constraint in the νth iteration; and,
3.	there exists z ∈ U, such that for all i 6∈ IV , zi = 0.
Lemma 1. Let x* be the optimal solution for an instance of problem 6.1. For any sequence xn → x*
such that xn , zn maintain the KKT conditions, there exists an M, such that for all ν ≥ M, there
exists a z ∈ U, such that for all i 6∈ IV, we have that zi = 0.
Proof. Let VV = {z : ∀i 6∈ IV, zi = 0}. Then assume, for the sake of contradiction, that the result is
false. That is, there is a sequence Vk such that VVk ∩ U = "• Then Since there finitely many different
IV (hence finitely many VV), we have that one of these must occur infinitely often. Thus, by taking an
appropriate subsequence, we assume, without loss of generality, that IVk are all equal. Let V = VVk
and obtain V ∩ U = 0.
Since V is a closed subspace, U is a closed set, and V ∩ U = 0, we must have that d(V, U) > 0. But
zVk+1 ∈ V and so
d(zVk+C, U) ≥ d(V,U) > 0.
Since xV → x* and we maintain the KKT conditions, we have that for any z ∈ U,
ATzV = -Vf(xV) → -Vf(x*) = ATz.
Thus d(zν, U) → 0 which is a contradiction.	□
Lemma 2. For any sequence xn → x* , if for a given ν, we have that the sequence satisfies
assumptions (1) and (2), then
K
IxV+1 - x*I2Q ≤ IxV - x*I2Q - X Ixn+1 - xnI2Q
n=k
where k and K are the indices of the first and last projection that take place in the νth iteration.
Proof. This Lemma is simply a statement about Bregman projections and so its proof requires no
modification.	□
23
Under review as a conference paper at ICLR 2019
Before we proceed, we introduce additional notation. Let AIν , biν be the submatrix of A, b with rows
from Iν and
Sν = {x : AIνk x = bIνk }.
Lemma 3. For any sequence such that Xn → x*, iffor a given V, we have that it satisfies assumptions
(1), (2), and (3), then we have that ∣∣xν+1 一 x*∣∣q = d(xν+1,Sν).
Proof. Consider the constrained problem
xm∈iSn ∣xν+1 一 x∣2Q	(8.4)
Then sufficient conditions for a pair (x, zIν) to be optimal for this problem are
AIνx = bIν and x = xν+1 一 Q-1AIT zIν
By Proposition 3, we see that since x* is solution to problem 6.1, we have that AIν x* = bIν. Then
by assumptions and the manner in which we do projections, we have that there exists z ∈ U , such
that for all i 6∈ Iν , zi = 0 and
x* = xν+1 一 Q-1AT (zν+1 一 z)
Then since ziν+1 = 0 for all i 6∈ Iν, we have that
x* = xν+1 一 Q-1AITν (zIνν+1 一 zIν)
Thus, x* is the optimal solution to 8.4.	口
Next for x 6∈ Sν, let Hxν be the hyperplane of that is furthest from x and define
μν
inf
x6∈Sν
d(x,HX)
d(x, Sν )
Now we are ready to prove the following theorem.
Theorem 5. Let x* is the optimal solution to problem 6.1. Then given ν that satisfies assumptions
(1), (2), and (3), we have that
kχν+1 -χ*kQ ≤ L+μkχν - χ*kQ
where Lis the number of projections that happened in νth iteration.
Proof. By Lemma 3, for any such ν we have that xν+1 6∈ Sν (or we have converged already).
Suppose constraint j ∈ IV defines the hyperplane HVV+ι. Then by Lemma 3 and definitions of μν ,μ
we have the following inequality.
∣xV+1 -x*∣ = d(xV+1,SV)
≤ -1 d(xν+1,HVν+ι)
μν
≤ 1d(χν+1,HXν+ι)
μ
Now since IV = {i : ziV+1 6= 0}, we know that during the νth iteration we must have projected onto
HxVν+1 . Note that this is the only place in the proof where we need the fact that we remember old
constraints. Let us say that this happens during the rth projection of the νth iteration.
Note by assumption, we satisfy the assumptions of Lemma 2. Let yr , yV+1 be the projections of
xr , xV+1 onto HxVν+1 . Then we see that
24
Under review as a conference paper at ICLR 2019
d(xν+1,Hxνν+1)2= kyν+1 -xν+1k2Q
≤ kyr - xν+1k2Q
≤ kyr - xr+1kQ + XL kxi - xi+1kQ
i=r+1
[yν+1 by def is the closest point]
[Triangle inequality]
-xi+1kQ!
xi+1kQ!
≤ L	kxi - xi+1k2Q
[ Cauchy Schwarz]
≤ L (kχν-χ*kQ -kχν+1-χ*kQ)
[Lemma 2]
Thus, we get that
μ2kxν+1x*k2 ≤ d(xν+1 ,HXVν+ι )2 ≤ L (IlxV - x*∣∣2 -∣∣xν+1 - x*∣IQ)
Rearranging, we get that
kxν+1-x*kQ ≤ τ+Lμkxν-x*kQ.
□
As a corollary to the above theorem, we have that algorithm 1 converges linearly.
Theorem 3. If f is a strictly convex quadratic function, Hi are strongly zone consistent with respect
to f, x0 = H-1s ∈ S, and the oracle Q satisfies either property 1 or2, then there exists ρ ∈ (0, 1)
such that
kx*-xν+1kH
ν→∞ kx* - xν∣∣h
≤ρ
(8.3)
where IyI2H = yT Hy. In the case when we have an oracle that satisfies property 2, the limit in 8.3
holds with probability 1.
Proof. Using Proposition 3, Lemma 1, and that we have finitely many constraints, we see that if ν is
large enough, the assumptions for Theorem 5 are satisfied. Taking the limit gives us the needed result.
In the case when we have an oracle that satisfies property 2, consider the product space of all possible
sequences of hyperplanes returned by our oracle. In this product space, we see that with probability
1, we generate a sequence of hyperplanes, such that algorithm 1 converges. For any such sequence
of hyperplanes, we have that 8.3 holds. Thus, the limit in 8.3 holds with probability 1 for random
separation oracles.	□
8.3.2 Proof of part 2 of Theorem 3—General
The rate of convergence for the general Bregman method was established in Iusem (1991). To show
this, let f be the 2nd degree Taylor polynomial of f centered at the optimal solution x*.
f(χ) = f(x*) + Vf (x*)τ ∙ x + 2xτ ∙ v2f (x*) ∙ x
For notational convenience, let H be the Hessian of f at x* . Then we can see that if replace f with f
in 6.1 then the optimal solution does not change. Thus, if had access to f and could use this function
to do our projections, then from the quadratic case we have our result.
25
Under review as a conference paper at ICLR 2019
Thus, to get the general result, if XV is our standard iterate and XV is the iterate produced by using f
instead of f, then Iusem (1991) shows that kXV - XV ∣∣ is o(∣∣χν - x*∣∣h). Specifically, We can extract
the following theorem from Iusem (1991).
Theorem 6. Iusem (1991) Let x* is the optimal solution for problem 6.1 and Xn is the sequence
produced by using the same sequence of hyperplanes but with f instead of f. Given a sequence Xn
produced by Bregman projections, such that Xn → X*, and for large enough ν we satisfy assumptions
(1), (2), and (3), then ∣∣xv — XV∣∣ is o(∣xv — x* ∣h)
Using this we can get the general result as follows
∣xv+1 - X*∣H ≤ ∣xv+1 -xv+1∣h + ∣xv+1 -X*∣H
≤ ∣∣xv+1 - Xv+1∣h + PkXV - x*∣h	[Quadratic case convergence]
≤ ∣xv+1 - xv+1∣h + PkXV - XVkH + PkXV - X*∣H
Then diving by ∣XV+1 - X* ∣H, and using Theorem 6 to take the limit, we get that there exists
P ∈ (0, 1) such that
lim
V→∞
∣x* - xv+1∣h
∣∣x* - xv∣∣h
≤P
(8.3)
As with the quadratic case, we see that is an oracle satisfies property 2, then 8.3 holds with probability
1. Thus, we have proved Theorem 3 in its complete generality.
8.4 Proof of Theorem 4
In this section we prove Theorem 4 in essentially the same manner as we did for Theorem 3 and so
we outline only what changes are necessary.
Theorem 4. If f ∈ B(S), the hyperplanes Hi are strongly zone consistent with respect to f, and
∃ X0 ∈ S such that Vf (x0) = 0, then with probability 1 any sequence Xn produced by the algorithm
converges to the optimal solution of problem 6.1. Furthermore, ifX* is the optimal solution, f is
twice differentiable at X*, and the Hessian H := Hf(X*) is positive semidefinite, then there exists
P ∈ (0, 1) such that with probability 1,
lim inf
V→∞
∣x* - xv+1∣h
∣∣x* - xv∣∣h
≤ P.
To prove Theorem 4, we need to analyze only what goes wrong if the algorithm “forgets” all of
the old constraints. First, consider the proof in the case that we converge to the optimal solution.
Then, steps 1,2, and 3 are completely unaffected by forgetting old constraints. The only step that is
affected is step 4. In a previous proof, we argued that if for some inactive constraint ai, zi is non-zero
infinitely often, then we projected onto this constraint infinitely often. In our present setting, we
cannot conclude this directly as ziV > 0 does not imply that we remember ai on the νth iteration.
However, due to property 2, we know that Q returns ai with probability at least τ . Thus, again using
the Borel Cantelli Lemmas, we see that we have ai infinitely often and this iteration converges to the
optimal.
To prove the second part of the theorem, we recall from Theorem 6 that we only need to analyze
the case when f is a quadratic function. Indeed, the only place where we used the fact that we
remembered old constraints was in the proof of Theorem 5 in which we needed to remember old
constraints to guarantee that during the νth iteration we project onto the constraint ai that is furthest
from XV among those constraints for which ziV+1 > 0. We cannot guarantee that this happens always
but we can guarantee that it happens infinitely often.
Therefore, the conclusion of Theorem 5 holds infinitely often instead of for the tail of the sequence
and we replace the limit with a limit infimum to obtain the desired result.
26
Under review as a conference paper at ICLR 2019
9 Application Details
All code, data, and outputs from the experiments can be found at https://www.dropbox.com/
sh/lq5nnhi4je2lh89/AABUUW7k5z3lXTSm8x1hhN1Da?dl=0. All code was written in
Julia 1.1.0 and run on Google Cloud Compute instances.
9.1	Metric Nearness
Convergence Criterion.
One variant of the metric nearness problem is the decrease only variant, in which we are not allowed
to increase the distances and must only decrease them. This problem can solved in O(n3) time by
calculating the all pairs shortest path metric Gilbert & Jain (2017). Given Xn as input, let xn be the
optimal decrease only metric. We ran these experiments UntiIkXn - χn∣∣2 ≤ 1.
Implementations.
We implemented the algorithm from Brickell et al. (2008). We made a small modification that
improves the running time. In Brickell et al. (2008), it is recommended that we store the dual variable
z as a sparse vector. However, as we do not want the overhead of handling sparse vectors, we store z
as a dense vector.
Algorithm 1 was implemented with two modifications. As we can see from algorithm ??, when
the oracle finds violated constraints, it looks at each edge in G and then decides whether there is a
violated inequality with that edge. It is cleaner in theory to find all such violated constraints at once
and then do the project and forget steps. It is, however, much more efficient in practice to do the
project and forget steps for a single constraint as we find it. This approach also helps cut down on
memory usage.
The second modification is that once our oracle returns a list of constraints (note we have already
projected onto these once), we project onto our whole list of constraints again. Thus, for the
constraints returned by the oracle, we project onto these constraints twice per iteration. Note this
does not affect any of the convergence results for the algorithm. The pseudocode for this modification
can be seen in Algorithm 5.
Algorithm 5 Pseudocode for the implementation for Metric Nearness.	
1	L0 = 0, z0 = 0. Initialize x0 so that Vf (x0) = 0.
2	: while Not Converged do
3	:	Let d(i, j) be the weight of shortest path between nodes i and j or ∞ if none exists.
4	:	L=0
5	:	for Edge e = i(, j) ∈ E do
6	:	if w(i, j) > d(i, j) then
7	:	Let P be the shortest path between i and j .
8	:	LetC = P ∪ {(i,j)}.
9	:	Project onto C and update x, z .
10	:	if zC ! = 0 then
11	:	Add C to L.
12	~	,	-1 Lν+1 = LV ∪ L
13	xν+1,zν+1 = Project(xν ,zν, Lν+1)
14	Lν+1 = Forget(Lν+1)
	return x
Additional Test Case.
We also tested our algorithm on an additional type of random weighted complete graph. Let uij be
sampled from the uniform distribution on [0, 1] and vij from a standard normal, then the weight for
an edge e = ij is given by
Wij = ∖1000 ∙ uij ∙ vij]
In this case, we got the following running times.
27
Under review as a conference paper at ICLR 2019
Figure 3: The red line is the mean running time for the algorithm from Brickell et al. (2008). The
blue line is the running mean time for our algorithm. All computations were done on a machine with
4 physical cores, each with 13 GB of RAM.
9.2	Correlation Clustering
Transforming the LP. The formulation of the LP that we solve is as follows:
minimize WT f + 1 f T ∙ W ∙ f
subject to x ∈ MET(G)	(9.1)
fij = |xij - dij |,	(i, j) ∈ E.
The transformation 2.2 into 9.1 has two parts. The first part is the transformation done in Veldt
et al. (2019) to obtain the formulation presented in 4.1. To do this transformation We define W(e)=
∣w+ (e) - w-(e) |. Then W is a diagonal matrix whose entries are given by W. Finally, we define d
as folloWs
1 W-1 (e) > W+ (e)
0 otherwise
The second step of the transformation, is the relaxation from x ∈ METn to x ∈ MET(G). The proof
for the second is now presented.
Proposition 2. Let f(x) be a function whose values only depends on the values xij fore = (i, j) ∈ G
and consider the following constrained optimization problem.
minimize	f(x)
subject to x ∈ MET(Kn)
(9.2)
Let π be the projection from METn to MET(G) and let f (π(x)) = f(x). Then for any optimal
solution x* to thefollowing problem
■ ■ ■	X/ ∖
minimize	f (x)
subject to x ∈ MET(G)
(4.2)
we have thatfor all X ∈ π-1(x*), X is an optimal solution to 9.2.
Proof. Here, we see that if X is the minimizer of 4.2 and x* the minimizer of 9.2 then
〜〜 .
f(x*) = f(∏(χ*)) ≥ f(x) = f(∏-1(x))
□
Calculating the Approximation Ratio.
Let X be the optimal solution to4.1, then if we let R
X is an
1+ Y
1 + R
xt Wx ,	,
----tft, by Veldt et al. (2019), we have that
2γwT x
approximation to the optimal solution of 2.2. This is the formula we used to calculate
the approximation ratios reported in Tables 1 and 2. For our experiments we used γ = 1.
28
Under review as a conference paper at ICLR 2019
Convergence Criterion.
We ran the experiment until the maximum violation of a metric inequality was at most 0.01. However,
the two algorithms, Ruggles et al. (2019) and ours, have different metric constraints. Specifically
Ruggles et al. (2019) only uses all constraints that come from 3 cycles, whereas we use all cycle
constraints. Theoretically both sets of constraints define the same polytope, but practically there is a
difference. Thus, in practice our algorithm was run to a slightly greater level of convergence than the
one from Ruggles et al. (2019).
Implementations.
For the case when G = Kn , in addition to the modifications that were done for metric nearness
experiment, we made two more modifications. First, we did the project and forget step one
additional time per iteration. Second, we parallelized the oracle by running Dykstra’s algorithm in
parallel. The pseudocode for this version of algorithm 1 can be seen in Algorithm 6.
Algorithm 6 Pseudocode for the implementation for CC for the dense case.
1:	L0 = 0, z0 = 0. Initialize x0 so that Vf (x0) = 0.
2:	La is the list of additional constraints. za0 = 0 (dual for additional constraints)
3:	while Not Converged do
4:	Let d(i, j ) be the weight of shortest path between nodes i and j or ∞ if none exists. This is
found using a parallel algorithm.
5:	L = 0
6:	for Edge e = i(, j) ∈ E do
7:	if w(i, j ) > d(i, j ) then
8:	Let C = P ∪ {(i, j)}. Where P be the shortest path between i and j.
9:	Project onto C and update x, z .
10:	if zC ! = 0 then Add C to L.
11:	LV — LV ∪ L
12:	for i = 1, 2 do
13:	xν,zν — Project(XV, ZV, LV)
14:	LV — Forget(LV)
15:	xV,zV J PrCject(XV, Za, La)
16:	xV+1 = xV,LV+1 = LV, zV+1 = zV, zaV+1 = zaV,
return X
For the sparse version, we made only two modifications: we used the parallel version of the oracle,
and during each iteration, we did the project and forget step 75 times.
Note that for both experiments, the additional constraints that were introduced due to the transforma-
tion were all projected onto once per iteration and never forgotten. The pseudocode for this version
can be seen in Algorithm 7.
We used the implementation provided by the authors of Veldt et al. (2019) to run the experiments for
their algorithm.
9.3	Information Theoretic Metric Learning
The hyper-parameters were set as follows: γ = 1, u = 1, l = 10. The pseudocode for our algorithm
can be seen in Algorithm 8. The classification was done using the k nearest neighbor classifier.
29
Under review as a conference paper at ICLR 2019
Algorithm 7 Pseudocode for the implementation for CC for the sparse case.
1 2 3 4	L0 = 0, z0 = 0. Initialize x0 so that Vf (x0) = 0. : La is the list of additional constraints. za0 = 0 (dual for additional constraints) : while Not Converged do :	Let d(i, j ) be the weight of shortest path between nodes i and j or ∞ if none exists. This is found using a parallel algorithm.
5 6 7 8 9 10 11 12 13 14 15	:	L=0 :	for Edge e = i(, j) ∈ E do :	if w(i, j) > d(i, j) then :	Let C = P ∪ {(i, j)}. Where P be the shortest path between i and j. :	Add C to L. LV — LV ∪ L :	fori = 1, . . . ,75 do xν,zν — Project(XV ,zν ,Lν) LV — Forget(LV) xν,zV J Project(XV, ZV, La) :	xV+1 = xV , LV+1 = LV, zV+1 = zV, zaV+1 = zaV, return X
Algorithm 8 Pseudocode for the Project and Forget algorithm for ITML.
1	function PFITML(X, C, γ, u,l, S, D)
2	:	λ0 = 0, Ξij = u for (i, j) ∈ S and Ξij = l for (i, j) ∈ D. Initialize C = I.
3	:	while Not Converged do
4	:	Randomly sample (i, j) from S
5	:	Do projection for this constraint
6	:	Randomly sample (i, j) from D
7	:	Do projection for this constraint
	return C
8	: function PROJECTION(X, i, j, S, D, u, l, Ξ, λ, C)
9	:	p = distC(Xi,Xj)
10	:	δ = 1 if (i, j) ∈ Sandδ = -1 if(i,j) ∈ D
11	α = min (λij , 2 (P - Ξγj))
12	β = i-δap
13	Ξ.. = Y _Sij_ Iij	Y γ+δαΞ j
14	:	λij = λij - α
15	:	C = C + βC(Xi - Xj)(Xi - Xjj)TCT
30