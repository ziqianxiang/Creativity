Under review as a conference paper at ICLR 2020
Learning Flat Latent Manifolds with VAEs
Anonymous authors
Paper under double-blind review
Ab stract
Latent-variable models represent observed data by mapping a prior distribution over
some latent space to an observed space. Often, the prior distribution is specified by
the user to be very simple, effectively shifting the burden of a learning algorithm to
the estimation of a highly non-linear likelihood function. This poses a problem for
the calculation of a popular distance function—the geodesic between data points in
the latent space—as this is often solved iteratively via numerical methods. These
are less effective if the problem at hand is not well captured by first or second-
order approximations. In this work, we propose less complex likelihood functions
by allowing complex distributions and explicitly penalising the curvature of the
decoder. This results in geodesics which are approximated well by the Euclidean
distance in latent space, decreasing the runtime by a factor of 1,000 with little
loss in accuracy. Additionally, we apply our method to a state-of-the-art tracking
algorithm using real world image data, showing that our unsupervised method
performs similar to supervised learning methods.
1	Introduction
Latent-variable models (LVMs) are a viable tool in data analysis: a set of observations is explained
by a simpler set of latent variables in conjunction with a map from the latent space to the space
of observation. Methods from this family (e.g., principal component analysis (Wold et al., 1987),
non-negative matrix factorisation (Lee & Seung, 2001), generalised discriminant analysis (Baudat
& Anouar, 2000), etc.) are standard tools, serving either as feature extractors for subsequent data
processing pipelines, density estimators or dimensionality reducers for visualisation.
Despite the maturity of the field, research has far from halted. While kernel methods (KernelPCA
(SchOlkoPf et al., 1997), KemelNMF (Li & Ding, 2006), etc.) have been used to improve the
applicability of LVMs to data inhibiting non-linear phenomena, neural formulations such as the
variational autoencoder (VAE) (Kingma & Welling, 2014; Rezende et al., 2014) or the generative
adversarial network (GAN) (Goodfellow et al., 2014) have become popular recently, especially due
to their enormous success on modelling natural images. Here, a simple prior distribution (such as a
multivariate standard normal or a uniform distribution) is mapped to the space of observations by
means of a powerful deep neural network. A learning algorithm then finds weights for that neural
network such that the data distribution is approximated well. In case of GANs, this is a minimax
game, while the evidence lower bound is maximised in the case of VAEs.
If the data distribution is relatively complicated and the prior is relatively simple, the map from the
latent to the observable space, the decoder, has to be sufficiently complex. In fact, it has to mimic the
inverse CDF in parts. This results in highly non-linear neural networks. As an example, the separation
of two modes in the probability landscape has to be implemented by a flat CDF, which in turn requires
an infinitely steep inverse CDF. Not only does this often pose difficulties for gradient-based learning.
It also hinders the calculation of geodesics, the shortest paths from one point to another, as measured
by the rate of change in the decoder along the path in latent space. Geodesics are often solved
numerically, i.e. through a gradient-based optimisation of first or second order. In a cartography
scenario, it is crucial to project the three-dimensional earth onto a two-dimensional map. When
applying VAEs, the problem is summarised to map from a two-dimensional Euclidean latent space
(the map) to the three-dimensional observation space (the earth surface). If, by construction, the
decoder exhibits regions of high curvature, the stage is especially bad for such methods.
We aim to improve the state of geodesics in deep latent-variable models with respect to runtime and
use the geodesic as a distance metric. We expect that short (approximate) geodesics under the learned
1
Under review as a conference paper at ICLR 2020
model indicate similarity of data points in question. If we assume that a simple prior and a simple
decoder are insufficient to represent complex data distributions and a complex decoder is detrimental
to the calculation of geodesics, we need the prior to be sufficiently complex to allow the decoder to
be sufficiently simple. Our solution is the use of a powerful hierarchical prior representation in the
context of VAEs and the simple penalisation of the curvature of the decoder. We name this approach
flat manifold variational autoencoder since the Riemannian manifold of the decoder is isometric
to Euclidean space. We show empirically that the resulting model features geodesics which are
approximated very well by the Euclidean distance. This effectively removes the need for numerical
optimisation, reducing the calculation of an approximate geodesic to that of a simple Euclidean
distance calculation in latent space. This is accompanied by a speedup of several orders of magnitude,
rendering the method practical for applications in real-time scenarios.
2	Variational Autoencoders with Riemannian Manifold
Regularisation
2.1	Background on VAEs with Hierarchical Priors
Latent-variable models (LVMs) are defined as
p(x) =	p(x|z) p(z) dz,
(1)
where z ∈ RNz represents latent variables and x ∈ RNx the observable data. The integral in Eq. (1)
is usually intractable but it can be approximated by maximising the evidence lower bound (ELBO)
(Kingma & Welling, 2014; Rezende et al., 2014):
EpD(X) [logPθ(x)] ≥ EpD(XJEqφ(z∣x)[logPθ(x|z)] - KL (qφ(z∣x)k p(z))],
(2)
where PD(x) = N PN=1 δ(x - Xi) represents the empirical distribution of the data D. The distribu-
tion parameters of the approximate posterior q© (z∣x) and the likelihood pθ (x∣z) are represented by
neural networks. The prior p(z) is usually defined as the standard normal distribution. This model is
commonly referred to the variational autoencoder (VAE).
However, a standard normal prior often leads to an over-regularisation of the approximate posterior,
which results in a less informative learned latent representation of the data (Tomczak & Welling, 2018;
Klushyn et al., 2019). To enable the model to learn an informative latent representation, Klushyn
et al. (2019) propose to use a flexible hierarchical prior pθ(z) = ∕pθ(z∣Z) p(Z)dZ, where p(ζ) is the
standard normal distribution. Based on the insight that the optimal prior is the aggregated posterior
(Tomczak & Welling, 2018), the above integral is approximated by an importance-weighted (IW)
bound (Burda et al., 2015) using samples from q©(z∣x). This leads to a model with two stochastic
layers and the following upper bound on the Kullback-Leibler (KL) term:
EpD(χ) KL (qφ(z∣x)∣∣ p(z)) ≤ F(φ, Θ, Φ)
≡ EpD (x)
Eqφ(z∣x) lθg qφ (ZIX)- EZLK ~qφ(Z∣z) [ lθg K X POqzW)'"]，
(3)
where K is the number of importance samples. Since it has been shown that high ELBO values do
not necessarily correlate with informative latent representations (Alemi et al., 2018; Higgins et al.,
2017)——which is also the case for hierarchical models (S0nderby et al., 2016)——different optimisation
approaches have been introduced (Bowman et al., 2016; S0nderby et al., 2016). Klushyn et al. (2019)
follow the line of argument in (Rezende & Viola, 2018) and reformulate the resulting ELBO as the
Lagrangian of a constrained optimisation problem:
Lvhp(Θ, Φ, Θ, Φ; λ) ≡F (φ, Θ, Φ) + λ( EpD(X)Eqφ(z∣χ) [Cθ (x,z)] - κ2),	(4)
with the optimisation objective F(φ, Θ, Φ), the inequality constraint EpD3)Eqφ(z∣x) [Cθ(x, z)] ≤
κ2, and the Lagrange multiplier λ. Cθ (x, z) is defined as the reconstruction-error-related term in
-logpθ(x|z). Thus, we obtain the following optimisation problem:
min min max min LVHP (θ, φ, Θ, Φ; λ) s.t. λ ≥ 0.
Θ,Φ θ λ φ
(5)
2
Under review as a conference paper at ICLR 2020
Building on that, the authors propose an optimisation algorithm—including a λ-update scheme—
to achieve a tight lower bound on the log likelihood. This approach is referred to as variational
hierarchical prior VHP-VAE.
2.2	Background on Riemannian Geometry for VAEs
A manifold M is a space which is differentiable and locally Euclidean. Given M , a Riemannian
manifold is (M, G), where G ∈ RNz ×Nz is the Riemannian metric tensor. At each point z ∈ M in
the latent space, the corresponding metric tensor G defines an inner product in the tangent space
z0 ∈ TzM :
hz0, z0iz ≡ z0T G(z) z0.
(6)
Chen et al. (2018a); Arvanitidis et al. (2018) define the latent space of a VAE as a Riemannian
manifold, which allows for computing the observation space distance based on distances in the
latent space. Given a smooth trajectory γ : [0, 1] → RNz in the Riemannian (latent) space and the
corresponding Nx-dimensional Euclidean (observation) space, the Riemaninan distance of the curve
can be written as
L(Y) = / 。⑴ dt,	φ(t) ≡ q<γ0⑴,γ0⑴〉Mt) = ,γ0⑴TG(Y(U)Y'⑴,	⑺
where G depends on γ, φ(t) denotes the Riemannian velocity and γ0(t) represents the time-derivative
of the trajectory. In the VAE models, Y is transformed by a continuous function f(Y(t)) (decoder) to
x, and the metric tensor is defined as G = JTJ, where J is the Jacobian of the decoder. The geodesic
is obtained by minimising L(Y).
The magnification factor (MF(Z) ≡ ʌ/det G(z)) (Bishop et al., 1997) shows the sensitivity of the
likelihood functions. When projecting from the Riemannian (latent) to the Euclidean (observation)
space, the MF can be considered a scaling coefficient.
2.3	Flat Manifold VAE
In this work, we aim to compute geodesics directly in the latent space by measuring the Euclidean
distance between encoded data points. For this purpose, the metric tensor, which describes our latent
space, needs to be G 8 1—hence a Euclidean metric. This simplifies the computation of geodesics
(Eq. (7)) to
L(Y) = Z1
0
φ(t)dt H ∣∣z(1) — z(0)k∙
(8)
We refer to a manifold M with this property as flat manifold (Lee, 2006). As a consequence, our
model must be capable of learning such flat manifold latent spaces, which typically requires complex
latent representations of the data (see experiments in Sec. 4). Therefore, we propose the following
approach: (i) to enable our model to learn complex latent representations, we introduce a flexible
prior, which is learned by the model (empirical Bayes); and (ii) we penalise the curvature of the
decoder such that G H 1.
For this purpose, we extend the VHP-VAE introduced in Sec. 2.1 by a Jacobian-regularisation term.
Defining the regularisation term as part of the constraint is in line with the constrained optimisation
setting. The resulting objective function is
L = F (Φ, Θ, Φ) + λ( EpD (x) Eqφ(z∣χ) [Cθ (x, z) + βJ(z)T J(z) — c21∣∣] — κ2),	(9)
where β is a hyper-parameter determining the influence of the regularisation. c2 is defined to be
the mean over the batch samples and diagonal elements of JTJ, which we view as a normalisation
process. Additionally, we use a stochastic approximation (first order Taylor expansion) of the Jacobian
(Rifai et al., 2011b) to improve the computational efficiency:
J(Z) = σi→0 σ EpD(χ)Eqφ(z∣χ)[f (Z + E)- f (Z)],	(10)
3
Under review as a conference paper at ICLR 2020
where E 〜N(0, σ2I). This approximation method allows for a faster computation of the gradient
and avoids the second-derivative problem of piece-wise linear layers (Chen et al., 2018a) during
optimisation.
However, the regularisation term in Eq. (9) only effects the decoder function in regions where data is
available. To overcome this issue, we propose to use mixup, a data-augmentation method (Zhang
et al., 2018), which was introduced in the context of supervised learning. We extend this method to
the VAE framework (unsupervised learning) by applying it to encoded data in the latent space. Our
aim is to augment data by interpolating between two encoded data points zi and zj :
gaug(zi,zj) = (1 - α) zi + αzj,	(11)
with Xi, Xj 〜PD(x), Zi 〜qφ(z∣Xi), Zj 〜qφ(z∣Xj), and a 〜U(一α0, 1 + α0). In contrast to
(Zhang et al., 2018), where α ∈ [0, 1] limits the data augmentation to only convex combinations,
we define α0 > 0 to take into account the outer edge of the data manifold. We obtain the objective
function of our flat manifold VAE (FMVAE) by combining mixup (Eq. (11)) with Eq. (9):
LVHP-FMVAE = LVHP + λ β Exa,Xj~pD(x) Eza~qφ(z∣Xi),Zj~qφ(z∣Xj) ||| G(gaug (Zi, Zj)) 一 C 1||].
(12)
By using augmented data when minimising kG 一 c21k, we regularise G to be a scaled identity
matrix for the entire latent space enclosed by our data manifold. Hence, our VAE learns a scaled
Euclidean latent space, where c is the scale factor. Therefore, the function f (Z) (decoder) is—up to
the scale factor c—isometry/distance-preserving since Dx(f(Zi), f(Zj)) ≈ cDz(Zi, Zj), where D
refers to the distance between two data points in the observation and latent space, respectively.
The decoder of the proposed approach satisfies the Lipschitz continuity condition. Given the Lipschitz
continuity condition Dx(f(Zi), f(Zj)) ≤ a Dz(Zi, Zj), where a is the Lipschitz constant, we consider
the decoder function, and hence the latent space as smooth if ∃ c ≤ a.
3	Related Work
Latent space of VAEs. In general, the latent space of VAEs is considered to be Euclidean (e.g.
Kingma et al., 2016; Higgins et al., 2017), but they are not constrained to be Euclidean. This can be
problematic if a precise metric is required in the latent space. Some recent works (Mathieu et al.,
2019; Grattarola et al., 2018) adapted the latent space to be non-Euclidean to match the data structure.
We solve the problem from another perspective by enforcing the latent space to be Euclidean.
Jacobian and Hessian regularisation. In (Rifai et al., 2011a), the authors propose to regularise the
Jacobian and Hessian of the encoder. However, the encoders of VAEs are already regularised by the
KL term. Furthermore, it is more difficult augment data in the observation space than in the latent
space for data augmentation. Encoder regularisation enables the model to perform better in case
of, e.g., object recognition from the latent space. By contrast, decoder regularisation enables the
model to do tasks such as generating motions based on the latent space. In (Hadjeres et al., 2017), the
Jacobian of the decoder was regularised to be as small as possible/zero. By contrast, we regularise
the Jacobian to be constand, and hence the Hessian to be zero leading to a correct metric in the latent
space. Nie & Patel (2019) regularised the Jacobian with respect to the weights of both the encoder
and decoder for GANs. In terms of supervised learning, Jakubovitz & Giryes (2018) regularised the
Jacobian to improve the robustness for classification.
Metric learning. Various metric learning approaches for both deep supervised and unsupervised
models were proposed. For instance, deep metric learning (Hoffer & Ailon, 2015) used a triplet
network for supervised learning. Karaletsos et al. (2016) introduced an unsupervised metric learning
method, where a VAE is combined with triplets. However, a human oracle is still required. By
contrast, our approach is completely based on unsupervised learning, using the tangent space of the
decoder as a distance metric. Our proposed method is similar to the metric learning methods such as
Large Margin Nearest Neighbor (Weinberger & Saul, 2009), which pulls target neighbours together
and pushes imposters away, but our approach is an unsupervised method.
Constraints in latent space. Constraints on time (e.g. Wang et al., 2007; Chen et al., 2016; 2015)
allow to obtain similar distance metrics in the latent space. However, our method can be used for
general datasets without sequential data. Additionally, constraints on time cannot guarantee that
4
Under review as a conference paper at ICLR 2020
the metric is correct in between of different time steps. By contrast, in case of sequential data, our
method can be used to obtain a correct metric through data augmentation.
Data augmentation. In regions without training data, the latent space is trained arbitrarily. Our
method is able to augment data in the latent space, so that we can smoothly interpolate between
two points even in case the data in between is missing in the training dataset using mixup. Various
follow-up studies of mixup were developed, such as (Verma et al., 2018; Beckham et al., 2019).
GANs which generates fake data in the latent space are a similar approach as our approach.
Geodesic. There have been some recent studies on geodesics for generative models using both
stochastic methods (e.g. Tosi et al., 2014; Arvanitidis et al., 2018; Hauberg, 2018; Chen et al.,
2018b) and deterministic approaches (e.g., Chen et al., 2018a; 2019). The main difference is that the
stochastic methods work for the regions without data, because the RBF layer generates high MF for
those—however, it is less general. The uncertainty does not emerge from a principled way (such as
in a Bayesian model) but is instead driven by certain assumptions. The deterministic method requires
other strategies to guarantee that the geodesic is within the data manifold. In our proposed method,
we regularise the latent space to have a similar metric, so that we do not need to consider low density
regions. In previous work, methods were introduced for computing/finding the geodesic in the latent
space. However, it is a novel approach to use the geodesic/Riemannian distance for influencing the
latent representation. Tenenbaum et al. (2000) projected the latent space to a new latent space where
the geodesic is equivalent to the Euclidean interpolation. However, the two separate processes—VAEs
and projection—probably cannot allow the model to find the latent features autonomously.
4	Experiments
We test our method on artificial pendulum images, human motion, the MNIST and the MOT16
datasets. We measure the performance in terms of equidistances, interpolation smoothness and
geodesics. Additionally, our method is applied to a real-world environment—a tracking system from
the context of autonomous driving. Consequently, the tracking and re-identification capabilities are
evaluated.
Riemannian metric tensor has many intrinsic properties of a manifold and measures local angles,
length, surface area and volumes (Bronstein et al., 2017). Therefore, the models are quantified using
the Riemannian metric tensor—condition numbers and MFs. The condition number which shows
the ratio of the most elongated to the least elongated direction is defined as k(G) = Smax(G), where
S is an eigenvalue of G. Since we cannot directly compare the MFs of different models, the MFs
are normalised through dividing by their mean. Accordingly, we can measure how the MFs spread
out from their mean. The model is more invariant with respect to the metric tensor if the condition
number is smaller and the normalised MF is closer to one.
4.1	Pendulum image dataset
-Mue UO4≈O,J
O O - O
Ooo
一ə-eɔsm0= ,JOceJ u04e-'≡ω,eE
0 5 0 5
- - - -
3 3 4 4
- -
(b) Latent representation of VHP-VAE.
-0
-20	0	20	-O
Zι
(a) Latent representation of VHP-FMVAE.
-MUe uo-≈2
Ooo
Ooo
3 2 1
一-e。SMO= ,JOceJ UOAeu≡uMeuj
Figure 1:	Equidistance in the latent space of the pendulum dataset. The black curves are points of
equal distance to a center. The distance is computed using (7).
5
Under review as a conference paper at ICLR 2020
Ooooo
5 0 5 0 5
2 2 11
,J9qEnu uo-pu∞
50505050
. . . . . . . .
44332211
M-≥ pə--ee,jou
6000
5 5000
q
40 4000
U
O 3000
：三
W
§ 2000
u
1000
252015w
人≡p"---e∪J.JOU
/ /
於
methods
methods
methods
35
30
methods
(a) Pendulum.	(b) MNIST.
Figure 2:	Boxplot of the condition number and the normalised MF for pendulum and MNIST datasets.
The pendulum and MNIST have 10,000 and 1,000 samples generated in from the latent space,
respectively.
The pendulum dataset (Klushyn et al., 2019; Chen et al., 2018a) consists of 16 × 16-pixel images
generated by a pendulum simulator. We generated 15 ∙ 103 images with joint angle in the ranges of
[0, 360) degrees. Additionally, we added 0.05 Gaussian noise to each pixel to avoid overfitting.
Fig. 1 shows the equidistance plots for five different encoded data points. VHP-FMVAE smoothens
the MF, while VHP-VAE has large area of high MF in the middle. Without regularisation, the
contour of the equidistances are significant different from high MF areas to low MF areas. Fig. 2a
shows that the condition number of the VHP-FMVAE is smaller than that of the VAE-VHP in terms
of the Riemannian tensor. Additionally, the normalised MF of the VHP-FMVAE is closer to one.
In order to avoid bias visualisation in Fig. 1, 3 and 7, we reset the range of the MF for plot-
ting while not changing the MF values. In Fig. 1a, Fig. 3a and 7, the upper range is set to be
max(MFMmean(MKmaan(MFIeata)). MFi and mf? refer to the MF of VHP-FMVAE with/without
Jacobian normalisation/mixup and VAE-VHP, respectively. MF(data) and MF(grid_area) are the
MF of the training data and the MF of the grid area, respectively.
4.2	Human motion
To evaluate our approach, CMU human motion dataset (http://mocap.cs.cmu.edu) is used.
Walking (subject 35), jogging (subject 35), balancing (subject 49), punching (subject 143) and
kicking (subject 74) are selected for the experiment. After data pre-processing, the input data is a
50-dimensional vector of the joint angles. The dataset is unbalanced—walking dataset size is larger
than that of jogging.
Table 1: The length ratio of Euclidean interpolation to geodesic. The Riemannian distance and the
distance in the latent space are computed. We randomly sample 100 pairs of points and interpolate
between each pair. The mean and the standard deviation of the ratios are listed below.
DATASET	METHOD	Riemannian	LATENT
Human	VHP-FMVAE	1.02 ± 0.06	0.93 ± 0.03
	VHP-VAE	1.23 ± 0.20	0.82 ± 0.10
MNIST	VHP-FMVAE	1.01 ± 0.08	0.92 ± 0.05
	VHP-VAE	1.13 ±0.22	0.70 ± 0.31
Equidistance. We randomly select a point from each class as the centre of the equidistance. As
shown in Fig. 3, the proposed method has more similar equidistance at different locations in the latent
space, while in the model without regularisation, the equidistance contour is distorted in the high MF
6
Under review as a conference paper at ICLR 2020
equidistance	----- geodesic
Euclidean interpolation ∙ walking
balancing
jogging
punching
kicking
⑶ Latent representation of VHP-FMVAE.
(b) Latent representation of VAE-VHP.
Figure 3: Equidistance in the latent space of the human motion dataset. (a) Jogging is a large-range
movement compared with walking, so that jogging is reasonably distributed on a larger area in the
latent space than that of walking. (b) In contrast, without regularisation, walking is larger than
the jogging in the latent space. For FMVAE, the Euclidean interpolatioins are much closer to the
geodesics.
yoo
q
40 400
⊂
O 300
IbOo
O
100
108 6 4
lxw pəs--bbOU
joint index
Figure 5: Smoothness of the human dataset. The
mean and standard deviation are shown. The
smaller the value is, the smoother the model is.
(a) Condition number. (b) Normalised MF.
Figure 4: Boxplot of the condition number and
the normalised MF of human motion dataset.
(a)	Linear interpolation of VHP-FMVAE.
髀坨料翻瞥顿函物幅布江馆
Zw国航雅MWWf卿将抄#
熠WW期嬲≡就施旃咂楸SS
≡≡≡≡wħwhħħħħ
0］鬻则晒炯朗机内W画秣窈领
(b)	Linear interpolation of VHP-VAE.
4 1
Figure 6:	Generated movements of the human motion dataset. The abrupt motions are marked by
blue boxes.
area. The latent space of VHP-FMVAE reflects the true distribution of the data (see more details in
Fig. 3). Moreover, we compute the Riemannian tensors for 3,000 samples randomly generated from
the latent space. In different locations of a latent space, the Riemannian tensors of VHP-FMVAE is
more invariant than that of VAE-VHP (see Fig. 4).
7
Under review as a conference paper at ICLR 2020
(a) Latent representation of VHP-FMVAE with-
out mixup. In the area which has training data,
the equidistance contour is smooth. However, in
the area of data missing, e.g., between two move-
ments, the MF is high and the equidistances are
distorted.
-7 -6 -5 -4 -3 -2
magnification factor [log scale]
(b) Latent representation of VHP-FMVAE without the Jaco-
bian normalisation. Although it does not have extreme sharp
equidistance contour, the equidistance is still scaled in various
locations of the latent space. Additionally, the distribution of
walking in the latent space is still larger than that of jogging.
Figure 7:	Influence of the data augmentation and the Jacobian normalisation. The movements are
coloured the same as Fig. 3.
Smoothness. We randomly sample 100 pair points and linearly interpolate between each pair. The
second derivative of each trajectory is defined as the smoothness factor. Fig. 5 illustrates that VHP-
FMVAE significantly outperforms the latent space of VAE-VHP in terms of the smoothness. Fig. 6
shows five examples of the interpolated trajectories.
Geodesic. We compare the proposed method with the graph-based geodesic approach (Chen et al.,
2019) which approximates the geodesic using a graph in a generative model. The graph-based
approach is much faster than previous geodesic search method such as (Chen et al., 2018a). The graph
of the baseline has 14,400 nodes which are sampled in the latent space using uniform distribution.
Each node has 12 neighbours. The regularisation of singular value decomposition (SVD) (Chen et al.,
2018a) is 0.001 for VAE-VHP while itis adapted to VHP-FMVAE based the mean value of the square
of the singular.
Table 1 shows the ratios from Euclidean interpolations to geodesics. If the ratio of the distance is
close to one, the Euclidean interpolation is able to approximate the geodesic. Table 1 demonstrates
that the Euclidean interpolation of VHP-FMVAE is more close to geodesic, compared with VAE-VHP.
Additionally, the proposed method is 1,000 times faster than the graph-based method in terms of
searching for the geodesics. Fig. 3 depicts five examples of the geodesics.
Influence of the data augmentation and the Jacobian normalisation. Fig. 7a shows the influence
of the data augmentation. The samples of the regularisation term are the same as LVHP. Fig. 7b
illustrates the influence of the Jacobian normalisation. We removed the normalisation, and conse-
quently the regularisation term is kG(gaug(zi, zj))k. The c21 term in the regularisation is necessary;
otherwise it only has dissimilarity constraints, but cannot reduce the distance for points with high
similarities. For instance, the walking is not squeezed in the latent space (see Fig. 4). By contrast,
regularising the Jacobian to be constant elongates the distance in the latent space with high MF areas
while squeezing the distance with low MF areas.
4.3 MNIST
A fixed binarised version of the MNIST digit dataset (Larochelle & Murray, 2011) is used to evaluate
our approach. The dataset consists of 50,000 training and 10,000 test images of handwritten digits
(zero to nine) with 28 × 28 pixels in size.
The equidistances of VHP-FMVAE are more invariant and smoother than that of VAE-VHP (see
Fig. 8 and Fig. 4). Similar as the human motion dataset, the geodesic of our method is more similar
to Euclidean interpolation, compared with VAE-VHP, which indicates that the latent space of the
VHP-FMVAE is able to approximate geodesic (see Table 1).
8
Under review as a conference paper at ICLR 2020
(a) Latent representation of VHP-FMVAE.
(b) Latent representation of VHP-VAE.
Figure 8:	Equidistance in the latent space of MNIST dataset. (b) The data ranges on z1 and z2 of the
VHP-VAE are [-106.21, 369.38] and [-365.64, 164.08], respectively. For better visualisation, we crop
out the less dense areas.
4.4 Tracking
We evaluate our approach on the MOT16 object-tracking database (Milan et al., 2016), which is a
large-scale person re-identification dataset, containing both static and dynamic scenes from diverse
cameras.
Table 2: Comparisons between different descriptors for the purposes of object tracking and re-
identification (Ristani et al., 2016). The bold and the red numbers denote the best results among all
methods and among non-supervised methods, respectively.
Method	Type	IDF1↑	IDP↑	IDR↑	RECALL↑	PRECISION↑	FAR；	MT↑
VHP-FMVAE-SORT β = 300 (OURS)	UNSUPERVISED	63.7	77.0	54.3	65.0	92.3	1.12	158
VHP-FMVAE-SORT β = 3000 (OURS)	UNSUPERVISED	64.2	77.6	54.8	65.1	92.3	1.13	162
VHP-VAE-SORT	UNSUPERVISED	60.5	72.3	52.1	65.8	91.4	1.28	170
SORT	N.A.	57.0	67.4	49.4	66.4	90.6	1.44	158
DEEPSORT	SUPERVISED	64.7	76.9	55.8	66.7	91.9	1.22	180
Method	Pw	ML；	FP；	FN；	IDS；	FM；	MOTA ↑	MOTP ↑	MOTAL↑
VHP-FMVAE-SORT β = 300 (OURS)	269	90	5950	38592	616	1143	59.1	81.8	59.7
VHP-FMVAE-SORT β = 3000 (OURS)	265	90	6026	38515	598	1163	59.1	81.8	59.7
VHP-VAE-SORT	266	81	6820	37739	693	1264	59.0	81.6	59.6
SORT	275	84	7643	37071	1486	1515	58.2	81.9	59.5
DEEPSORT	250	87	6506	36747	585	1165	60.3	81.6	60.8
We compare with two baselines: SORT (Bewley et al., 2016) and DeepSORT (Wojke et al., 2017).
SORT is a simple online and realtime tracking method, which uses bounding box intersection-over-
union (IOU) for associating detections between frames and Kalman filters for the track predictions. It
relies on good two-dimensional bounding box detections from a separate detector, and suffers from
ID switching when tracks overlap in the image. DeepSORT extends the original SORT algorithm
to integrate appearance information based on a deep appearance descriptor, which helps with re-
identification in the case of such overlaps or missed detections. The deep appearance descriptor is
trained using a supervised cosine metric learning approach (Wojke & Bewley, 2018). The candidate
object locations of the pre-generated detections for both SORT, DeepSORT and our method are taken
from (Yu et al., 2016). Further details regarding the implementation can be found in App. A.3.
9
Under review as a conference paper at ICLR 2020
(b) DeepSORT.
Figure 9: Example identity switches between overlapping tracks. For vanilla SORT, track 3260
gets occluded and when subsequently visible, it gets assigned a new ID 3421. For deeSORT and
VHP-VAE-SORT, the occluding track gets assigned the same ID as the track it occludes (42/61), and
subsequently keeps this (erroneous) track. For VHP-FMVAE-SORT, the track 42 gets occluded, but
is re-identified correctly when again visible.
(d) VHP-FMVAE-SORT with β = 3000.
We use the following metrics for evaluation. ↑ indicates that the higher the score is, the better the
performance is. On the contrary, ] indicates that the lower the score is, the better the performance is.
・	IDFι(↑): ID Fi Score
. IDP(↑): ID Precision
・	IDR(↑): ID Recall
•	FARQ): False Alarm Ratio
•	MT(↑): Mostly Tracked Trajectory
•	PT(1): Partially Tracked Trajectory
•	ML(1): Mostly Lost Trajectory
•	FP(1): False Positives
•	FN(1): False Negatives
•	IDs。)： Number of times an ID switches to a
different previously tracked object
•	FM(1): Fragmentations
•	MOTA(↑): Multi-object tracking accuracy
•	MOTP(↑): Multi-object tracking precision
•	MOTAL(↑): Log tracking accuracy
Table 2 shows that the performance of the proposed method is better than that of the model without
Jacobian regularisation, and even close to the the performance of supervised learning. All methods
depend on the same underlying detector for object candidates, and identical Kalmann filter parameters.
Compared to baseline SORT which does not utilise any appearance information, DeepSORT has 2.54
times, VHP-VAE-SORT has 2.14 times, VHP-FMVAE-SORT (β = 300) has 2.41 times and VHP-
FMVAE-SORT (β = 3000) has 2.48 times fewer ID switches. Whilst the supervised DeepSORT
descriptor has the least, using unsupervised VAEs with flat decoders has only 2.2% more switches,
without the need for labels. Furthermore, by ensuring a quasi-Euclidean latent space, one can query
nearest-neighbours efficiently via data-structures such as kDTrees. Fig. 9 shows an example of the
results. In other examples of the videos, the VHP-FMVAE-SORT works similar as the deepSORT.
Videos of the results can be downloaded at: http://tiny.cc/0s71cz
5	Conclusion
In this paper, we have proposed a novel approach, which we call flat manifold variational autoencoder.
We have shown that—using this method—geodesics can be computed directly in the latent space
by measuring the Euclidean distance between encoded data points. This is realised by combining a
powerful empirical Bayes prior with a Jacobian-regularisation method that constrains the learned
latent space to be Euclidean. Consequently, geodesic can be approximated 1,000 times faster
than comparable state-of-the-art methods. Furthermore, using the approximated geodesic as a
distance function, we have evaluated our approach on the MOT16 object-tracking database showing
comparable performance as in case of supervised learning.
10
Under review as a conference paper at ICLR 2020
References
Alexander A Alemi, Ben Poole, Ian Fischer, Joshua V Dillon, Rif A Saurous, and Kevin Murphy.
Fixing a broken ELBO. ICML, 2018.
Georgios Arvanitidis, Lars Kai Hansen, and S0ren Hauberg. Latent space oddity: on the curvature of
deep generative models. In ICLR, 2018.
Gaston Baudat and Fatiha Anouar. Generalized discriminant analysis using a kernel approach. Neural
computation,12(10):2385-2404, 2000.
Christopher Beckham, Sina Honari, Alex M Lamb, Vikas Verma, Farnoosh Ghadiri, R Devon Hjelm,
Yoshua Bengio, and Christopher Pal. On adversarial mixup resynthesis. NeurIPS, 2019.
Alex Bewley, Zongyuan Ge, Lionel Ott, Fabio Ramos, and Ben Upcroft. Simple online and realtime
tracking. In 2016 IEEE International Conference on Image Processing (ICIP), pp. 3464-3468.
IEEE, 2016.
Christopher M Bishop, Markus Svens’ en, and Christopher KI Williams. Magnification factors for
the SOM and GTM algorithms. In Proceedings Workshop on Self-Organizing Maps, 1997.
Samuel R. Bowman, Luke Vilnis, Oriol Vinyals, Andrew Dai, Rafal Jozefowicz, and Samy Bengio.
Generating sentences from a continuous space. CoNLL, 2016.
Michael M Bronstein, Joan Bruna, Yann LeCun, Arthur Szlam, and Pierre Vandergheynst. Geometric
deep learning: going beyond Euclidean data. IEEE Signal Processing Magazine, 34(4):18-42,
2017.
Yuri Burda, Roger B. Grosse, and Ruslan Salakhutdinov. Importance weighted autoencoders. CoRR,
abs/1509.00519, 2015.
Nutan Chen, Justin Bayer, Sebastian Urban, and Patrick Van Der Smagt. Efficient movement
representation by embedding dynamic movement primitives in deep autoencoders. In 2015 IEEE-
RAS 15th International Conference on Humanoid Robots (Humanoids), pp. 434-440. IEEE, 2015.
Nutan Chen, Maximilian Karl, and Patrick van der Smagt. Dynamic movement primitives in
latent space of time-dependent variational autoencoders. In 2016 IEEE-RAS 16th International
Conference on Humanoid Robots (Humanoids), pp. 629-636, 2016.
Nutan Chen, Alexej Klushyn, Richard Kurle, Xueyan Jiang, Justin Bayer, and Patrick van der Smagt.
Metrics for deep generative models. In AISTATS, pp. 1540-1550, 2018a.
Nutan Chen, Alexej Klushyn, Alexandros Paraschos, Djalel Benbouzid, and Patrick van der Smagt.
Active learning based on data uncertainty and model sensitivity. IEEE/RSJ IROS, 2018b.
Nutan Chen, Francesco Ferroni, Alexej Klushyn, Alexandros Paraschos, Justin Bayer, and Patrick
van der Smagt. Fast approximate geodesics for deep generative models. In ICANN, 2019.
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair,
Aaron Courville, and Yoshua Bengio. Generative adversarial nets. In NIPS, pp. 2672-2680, 2014.
Daniele Grattarola, Daniele Zambon, Cesare Alippi, and Lorenzo Livi. Learning graph embed-
dings on constant-curvature manifolds for change detection in graph streams. arXiv preprint
arXiv:1805.06299, 2018.
Gaetan Hadjeres, Frank Nielsen, and FrangoiS Pachet. GLSR-VAE: geodesic latent space regulariza-
tion for variational autoencoder architectures. In 2017 IEEE Symposium Series on Computational
Intelligence (SSCI), pp. 1-7, 2017.
S0ren Hauberg. Only bayes should learn a manifold (on the estimation of differential geometric
structure from data). arXiv, 2018.
Irina Higgins, Loic Matthey, Arka Pal, Christopher Burgess, Xavier Glorot, Matthew Botvinick,
Shakir Mohamed, and Alexander Lerchner. Beta-VAE: Learning basic visual concepts with a
constrained variational framework. ICLR, 2017.
11
Under review as a conference paper at ICLR 2020
Elad Hoffer and Nir Ailon. Deep metric learning using triplet network. In International Workshop on
Similarity-Based Pattern Recognition, pp. 84-92. Springer, 2015.
Daniel Jakubovitz and Raja Giryes. Improving DNN robustness to adversarial attacks using Jacobian
regularization. In Proceedings of the European Conference on Computer Vision (ECCV), pp.
514-529, 2018.
Theofanis Karaletsos, Serge Belongie, and Gunnar Ratsch. Bayesian representation learning with
oracle constraints. ICLR, 2016.
Diederik P. Kingma and Max Welling. Auto-encoding variational Bayes. ICLR, 2014.
Diederik P. Kingma, Tim Salimans, Rafal Jozefowicz, Xi Chen, Ilya Sutskever, and Max Welling.
Improving Variational Inference with Inverse Autoregressive Flow. NIPS, 2016.
Alexej Klushyn, Nutan Chen, Richard Kurle, Botond Cseke, and Patrick van der Smagt. Learning
hierarchical priors in VAEs. NeurIPS, 2019.
Hugo Larochelle and Iain Murray. The neural autoregressive distribution estimator. In International
Conference on Artificial Intelligence and Statistics, pp. 29-37, 2011.
Daniel D Lee and H Sebastian Seung. Algorithms for non-negative matrix factorization. In Advances
in neural information processing systems, pp. 556-562, 2001.
John M Lee. Riemannian manifolds: an introduction to curvature, volume 176. Springer Science &
Business Media, 2006.
Tao Li and Chris Ding. The relationships among various nonnegative matrix factorization methods
for clustering. In International Conference on Data Mining, pp. 362-371. IEEE, 2006.
Emile Mathieu, Charline Le Lan, Chris J Maddison, Ryota Tomioka, and Yee Whye Teh. Hierarchical
representations with Poincar\’e variational auto-encoders. arXiv preprint arXiv:1901.06033, 2019.
Anton Milan, Laura LeaI-TaiXaIan Reid, Stefan Roth, and Konrad Schindler. Mot16: A benchmark
for multi-object tracking. arXiv preprint arXiv:1603.00831, 2016.
Weili Nie and Ankit Patel. Towards a better understanding and regularization of GAN training
dynamics. In UAI, 2019.
Danilo Jimenez Rezende and Fabio Viola. Taming VAEs. arXiv preprint arXiv:1810.00597, 2018.
Danilo Jimenez Rezende, Shakir Mohamed, and Daan Wierstra. Stochastic backpropagation and
approXimate inference in deep generative models. In ICML, volume 32, pp. 1278-1286, 2014.
Salah Rifai, Yann N Dauphin, Pascal Vincent, Yoshua Bengio, and Xavier Muller. The manifold
tangent classifier. In Advances in Neural Information Processing Systems, pp. 2294-2302, 2011a.
Salah Rifai, Gregoire Mesnil, Pascal Vincent, Xavier Muller, Yoshua Bengio, Yann Dauphin, and
Xavier Glorot. Higher order contractive auto-encoder. In ECML-PKDD, pp. 645-660. Springer,
2011b.
Ergys Ristani, Francesco Solera, Roger S. Zou, Rita Cucchiara, and Carlo Tomasi. Performance
measures and a data set for multi-target, multi-camera tracking. CoRR, abs/1609.01775, 2016.
Bernhard Scholkopf, Alexander Smola, and Klaus-Robert Muller. Kernel principal component
analysis. In International conference on artificial neural networks, pp. 583-588. Springer, 1997.
Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for large-scale image
recognition. ICLR, 2015.
Casper Kaae S0nderby, Tapani Raiko, Lars Maal0e, S0ren Kaae S0nderby, and Ole Winther. Ladder
variational autoencoders. NIPS, 2016.
Joshua B Tenenbaum, Vin De Silva, and John C Langford. A global geometric framework for
nonlinear dimensionality reduction. science, 290(5500):2319-2323, 2000.
12
Under review as a conference paper at ICLR 2020
Jakub M. Tomczak and Max Welling. VAE with a vampprior. In International Conference on
Artificial Intelligence and Statistics,pp. 1214-1223, 2018.
Alessandra Tosi, S0ren Hauberg, Alfredo Vellido, and Neil D. Lawrence. Metrics for probabilistic
geometries. In UAI, pp. 800-808, 2014.
Vikas Verma, Alex Lamb, Christopher Beckham, Amir Najafi, Ioannis Mitliagkas, Aaron Courville,
David Lopez-Paz, and Yoshua Bengio. Manifold mixup: Better representations by interpolating
hidden states. ICML, 2018.
Jack M Wang, David J Fleet, and Aaron Hertzmann. Gaussian process dynamical models for human
motion. IEEE transactions on pattern analysis and machine intelligence, 30(2):283-298, 2007.
Kilian Q Weinberger and Lawrence K Saul. Distance metric learning for large margin nearest
neighbor classification. Journal of Machine Learning Research, 10(Feb):207-244, 2009.
Nicolai Wojke and Alex Bewley. Deep cosine metric learning for person re-identification. In IEEE
Winter Conference on Applications of Computer Vision (WACV), pp. 748-756, 2018.
Nicolai Wojke, Alex Bewley, and Dietrich Paulus. Simple online and realtime tracking with a deep
association metric. In IEEE International Conference on Image Processing, pp. 3645-3649, 2017.
Svante Wold, Kim Esbensen, and Paul Geladi. Principal component analysis. Chemometrics and
intelligent laboratory systems, 2(1-3):37-52, 1987.
Fengwei Yu, Wenbo Li, Quanquan Li, Yu Liu, Xiaohua Shi, and Junjie Yan. POI: multiple object
tracking with high performance detection and appearance feature. CoRR, abs/1610.06136, 2016.
Hongyi Zhang, Moustapha Cisse, Yann N. Dauphin, and David Lopez-Paz. mixup: Beyond empirical
risk minimization. International Conference on Learning Representations, 2018.
13
Under review as a conference paper at ICLR 2020
A Appendix
A.1 Vector Field
(a) VHP-FMVAE.
(b) VHP-VAE.
Figure 10: Vector field of the human motion dataset. The vector field is a vector of L2 norm over
the output of Jacobian. The figures are corresponding to Fig. 3. The vector field of VHP-FMVAE is
more regular than that of VAE-VHP.
A.2 Model Architectures
Table 3: Model architectures. FC refers to fully-connected layers. Conv2D and Conv2DT denote
tow-D convolution layer and transposed two-D convolution layer, respectively. See the definition of
ν in (Klushyn et al., 2019).
Dataset	Optimiser	Architecture
Pendulum	Adam 1e-4	INPUT	16×16×1 Latents	2 qφ(z∣x)	FC 256,	256.	RELU activation. pθ (x|z)	FC 256,	256.	RELU ACTIVATION.	GAUSSIAN. qφ(Z∣z)	FC 256,	256,	RELU activation. Pθ(z∣Z)	FC 256,	256,	RELU activation. oTHERS	κ= 0.025, ν= 1, K= 16,β = 1000.
CMU Human	Adam 1e-4	Input	50 Latents	2 qφ(z∣x)	FC	256, 256,	256, 256. RELU activation. pθ (x|z)	FC	256, 256,	256, 256. RELU ACTivATioN. GAUSSiAN. qφ(Z∣z)	FC	256, 256,	256, 256, ReLU activation. Pθ(z∣Z)	FC	256, 256,	256, 256, RELU ACTIVATION. oTHERS	κ= 0.03, ν= 1, K= 32, β = 8000.
MNIST	Adam 1e-4	INPUT	28×28×1 Latents	2 qφ(z∣x)	FC 256,	256, 256,	256. ReLU	activation. pθ (x|z)	FC 256,	256, 256,	256. RELU	ACTivATioN. BERNoULLi. qφ(Z∣z)	FC 256,	256, 256,	256. ReLU	activation. Pθ(z∣Z)	FC 256,	256, 256,	256. ReLU	activation. oTHERS	κ = 0.245 , ν = 1, K = 16, β = 8000.
MOT16	Adam 3e-5	iNPUT	64×64×3 Latents	128 qφ(z∣x)	VGG16 (Simonyan & Zisserman, 2015) Pθ(x|z)	Conv2DT+Conv2D 256, 128, 64, 32, 16. ReLU activation. Gaussian. qφ(Z∣z)	FC 512, 512. ReLU activation. Pθ(z∣Z)	FC 512, 512. ReLU activation. oTHERs	κ = 0.8 , ν = 1, K = 8, β = 300 or 3000.
14
Under review as a conference paper at ICLR 2020
A.3 IMPLEMENTATION OF VHP-FMVAE-SORT
We evaluate the performance of our model by replacing the appearance descriptor from DeepSORT
with the latent space embedding from the various auto-encoders used, using the same size of 128.
The hyperparameters used were held constant: the minimum detection confidence of 0.3, NMS max
overlap of 0.7, max cosine distance 0.2, max appearance budget 100. We tested a VHP-FMVAE, and
our regularised VHP-FMVAE with β = 300 and β = 3000.
15