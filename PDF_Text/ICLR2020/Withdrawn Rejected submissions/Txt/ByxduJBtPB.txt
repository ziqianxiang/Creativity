Under review as a conference paper at ICLR 2020
When Covariate-shifted Data Augmentation
Increases Test Error And How to Fix It
Anonymous authors
Paper under double-blind review
Ab stract
We study covariate-shifted data augmentation where the augmented targets are
drawn from the true predictive distribution but the inputs are shifted. Empirically,
some forms of data augmentation such as adversarial training improve robustness,
but increase test error. We provide precise conditions under which data augmentation
can increase test error for minimum norm interpolation estimators in linear regres-
sion. As a fix, we propose X-regularization which uses unlabeled data to regularize
the parameters towards the non-augmented estimate. We prove that augmentation
with X-regularization never increases test error in linear regression. Empirically,
X-regularization consistently improves both robustness and standard test error
across different adversarial training algorithms and perturbations on Cifar- 1 0.
1 Introduction
Adversarial training improves the robustness of neural networks to perturbations, commonly referred to
as adversarial examples (Goodfellow et al., 2015; Szegedy et al., 2014; Biggio et al., 2013). However,
adversarial training also causes an undesirable increase in the error on the unperturbed images (test
error). How do we obtain both robust and accurate networks? At the core, adversarial training is a
form of data augmentation where we augment the training set with worst-case perturbations of each
training image within a ball defined by the attack model. In this work, we study the general question
of how to train classifiers on augmented training data without causing an increase in test error, while
simultaneously preserving the benefits of augmentation such as robustness.
First, We analyze Why some forms of data augmentation such as with adversarial '∞ perturbations
increase error. Previous works (Tsipras et al., 2019; Zhang et al., 2019; Fawzi et al., 2018; Nakkiran,
2019) provide simple constructions to explain the increase in test error With adversarial perturbations,
but rely on assumptions, such as incorrect labeling of the adversarial perturbations or insufficient
complexity of the hypothesis class, that We do not expect to hold in practice. We seek a simple
theoretical setup that can shed light on Why augmentation, even With label-preserving perturbations
in a Well-specified setting, causes an increase in test error. On the surface, it seems like We have only
added information about the label distribution, so Why does the test error increase?
In this Work, We theoretically study minimum norm interpolation in Well-specified linear regression,
and shoW that data augmentation With label-preserving perturbations can increase the test error
in some regimes, even When the targets are noiseless. For example, Figure 1(a) illustrates a
function interpolation problem via cubic splines Which exemplifies this phenomenon. Without data
augmentation, the estimated predictor (dashed blue) is a line that captures the global structure and
obtains loW error. Data augmentation With local perturbations (crosses) encourages the predictor to
fit the local structure of the high density points but compromises the global structure on the tail (solid
orange) (Figure 1(b)). We shoW that this tension betWeen local and global fit stems from the estimator
having the Wrong inductive bias. In particular, the minimum norm estimator minimizes a generic
parameter norm While the test error is measured by a possibly different norm on the parameter error
vector Which depends on the data distribution (Section 4.1). Further, one might expect augmentation
to be most helpful in loW data settings. We shoW that in linear regression, this is also exactly the
regime Where augmentation can be most harmful. On real datasets, We similarly observe that data
augmentation can be more detrimental With a smaller original training set (Section 5).
Motivated by our analysis of interpolation in linear regression, We propose aneW estimator for data
augmentation based on X-regularization (Section 6). X-regularization encourages the data augmented
1
Under review as a conference paper at ICLR 2020
4
2
O
0	2	4
Figure 1: We consider perfectly fitting training points using cubic splines while minimizing
smoothness of the function. (Left) depicts the true function f? and the mass Pxy on each point
(x,y) size of the circles) (Middle) With a small number of standard training samples (circles) from
the distribution depicted in (a), augmentating the dataset with local perturbations (crosses) causes
the augmented estimator to have larger error than the standard estimator due to being maximally
smooth while also fitting the augmented local perturbations. (Right) Our proposed X-regularization
regularizes the model predictions towards the predictions of a standard model (trained without
perturbations) on unlabeled data, allowing for fitting both the local and global structure.
interpolant to stay close to the original interpolant while fitting the extra augmented points. We
prove that X-regularization eliminates the increase in test error upon data augmentation in the case
of noiseless linear regression. See Figure 1(c) for its effect on the spline interpolation problem.
X-regularization naturally extends to more general losses and complex models and is closely related to
self-training (Scudder, 1965), the classical semisupervised learning algorithm. For the particular setting
of robustness, X-regularization applied to adversarial training takes the form of robust self-training
(RST) that was recently proposed in (Carmon et al., 2019; Najafi et al., 2019; Uesato et al., 2019). The
previous works view RST as a way to beat the sample complexity barrier of robustness. By showing that
RST is an instantiation of X-regularization, we motivate RST as an appropriate data dependent regular-
izer that improves both standard accuracy and robustness. We evaluate the effect of RST on standard and
robust accuracy with different adversarial training losses and perturbations on Cifar- 1 0 in Section 6.3.
With '∞ perturbations, We find that RST improves standard accuracy by 4-6% while maintaining or
even improving the robustness achieved by the vanilla adversarial training counterpart. With random
and adversarial rotations, RST improves standard accuracy by 〜1% and robust accuracy by 1-3%. Our
experiments suggest that RST, and more broadly using unlabeled data with X-regularization, is a promis-
ing approach to mitigate the undesirable drop in standard accuracy when training robust networks.
2 Related Work
The detrimental effect of data augmentation has been previously studied in the context of a “tradeoff”
between accuracy and robustness.
Understanding the tradeoff. In an attempt to explain the tradeoff between robustness and
accuracy, Tsipras et al. (2019); Zhang et al. (2019); Fawzi et al. (2018); Nakkiran (2019) provide simple
constructions that showcase an inherent tension between these objectives even in the limit of infinite
data. These constructions rely on either non-label-preserving perturbations or insufficient model
complexity to express a robust and accurate classifier. However, in practice, we typically augment
with “imperceptible” perturbations that do not change the label, and we assume large neural networks
used in practice to be expressive enough to contain a robust and accurate classifier. We address both
these insufficiencies by studying covariate-shifted data augmentation where the extra data is labeled
according to the same predictive distribution as the original data, and well-specified linear regression.
Mitigating the tradeoff. Existing proposals to mitigate the observed increase in standard error
caused by adversarial augmentations are based on finding better architectures via Neural Architecture
Search (Cubuk et al., 2017) or changing the neural net training algorithm (Lamb et al., 2019). While
these methods have shown some success, they are restricted to neural networks. We complement this
line of work by studying this tradeoff more generally and also provide some theoretical justification.
2
Under review as a conference paper at ICLR 2020
3 Setup
3.1	Covariate-shifted data augmentation.
Let Pχy denote the underlying distribution of (x,y) pairs, Px its marginal on Rd, and Py(∙ | x) the
conditional distribution of the targets given inputs.
We refer to the training data from the underlying distribution Pxy by standard training data. Formally,
we have n pairs (xi,yi)〜Pxy forming the measurement matrix Xstd = [χ1,χ2,…Xn]> ∈ Rn×d and
target vector ystd = [y1,y2,...yn]> ∈Rn.
Analogously , we consider augmenting the training set with “extra” training points denoted by
XeXt = [X1,X2,…Xm]> ∈ Rm×d with associated targets yext = [y1,y2, ...ym]> ∈ Rm. We focus on
covariate-shifted data augmentations which includes most forms of data augmentations used in practice
.Here, the targets yext are drawn from the same underlying predictive distribution Py(∙ | x) as the
standard data, while the extra inputs Xext could be arbitrary.
Examples. Typically , the “extra” training points are constructed as follows: Xi = T(xi), y% = y%,
where T is some label-preserving transformation thereby enforcing that the extra targets are as if
sampled from Py(∙ | x). Example transformations include translations, horizontal flips, small rotations,
small '∞ perturbations in vision, and replacing words with their synonyms in NLp However, our
treatment of data augmentation in this work is more general where Xext is not necessarily obtained
via transformations of Xstd. Empirically, our main focus is on mitigating the increase in test error
upon adversarial training. Most popular forms of adversarial training are instances of covariate-shifted
data augmentation . Consider projected gradient adversarial training (PG-AT) (Madry et al., 2018)
which confers robustness to adversarial examples (Szegedy et al., 2014) but also causes an increase
in standard test error. PG-AT can be viewed as a form of iterative data augmentation that falls in our
framework above. Formally, let B(x) be the set of perturbations ofx that we would like to be robust
against. We assume that the label is constant over B(x). The transformation at step t of the training
for data point Xi is Tt(Xi) = argmax '(θt,xi,yi), where θt are the model parameters at time step t.
x∈B(xi)
The worst-case (max loss) perturbation is approximated via the projected gradient method.
3.2	Minimum norm interpolation in well-specified linear regression
Consider a regression task where the targets y ∈ R are drawn from the conditional distribution
Py(∙ | x)= N (x>θ?, σ), for some vector θ? ∈ Rd. Our goal is to learn a linear predictor fθ (x)= x>θ .
In this work, we focus on interpolating estimators, which draws motivation from modern machine
learning models that achieve near zero training loss (on both standard and extra augmented points).
Interpolating estimators for linear models are analyzed in many recent works (Ma et al., 2018; Belkin
et al., 2018; Hastie et al., 2019; Liang & Rakhlin, 2018; Bartlett et al., 2019). We present our results
for interpolating linear regression estimators with minimum Euclidean norm, but our analysis directly
applies to more general Mahalanobis norms via suitable rotations. See Appendix A. Given inputs
X ∈ Rn×d and corresponding targets Y ∈Rn as training data, we define the following minimum norm
interpolation estimator as
θ = argmjnnkθ∣∣2 :Xθ = Y∣.	(1)
In particular , we compare the following estimators : (i) the standard estimator θstd which has [Xstd,ystd]
as training data and (ii) the data augmented estimator θaug with X = [Xstd;Xext],Y = [ystd;yext] as
training data:
θstd = argmin{∣∣θ∣∣2 :Xstdθ = ystd} and θa∏g =argmin∣kθk2 :XStdθ = ystd,Xextθ = yext}.⑵
4 Bias and Variance of Minimum Norm Interpolants
We evaluate the two estimators described in Equation 2 using the error on a random sample xtest drawn
from Px . Let Σ be the covariance of Px . We focus on the error conditioned on Xstd , Xext , which
3
Under review as a conference paper at ICLR 2020
decomposes into a bias and variance term as follows
Re)=旧陞黑®-。*))2]=E[(θ-θ*)>∑(θ-θ?)]
=(E[θ] -θ*)>Σ(E[θ] -θ*)+tr(Cov(θ)Σ),	(3)
x---------{-----------} X---{-----}
Bias B(θ)	Variance V(θ)
where the expectation is taken over the randomness in xtest and targets ystd , yext conditioned on
Xstd , Xext . In this section, we treat Xstd , Xext as fixed quantities. However, since Xstd consists of
samples from Px, the number of samples dictates some structure on Xstd. We touch upon this aspect
in Section ?? where we study how the effect of augmentation varies with the number of samples in
the original training set, both theoretically and empirically.
4.1	Bias of Minimum Norm Interpolants
For minimum norm interpolant with X,Y as training data, the bias term B(θ) can be expressed as
follows. On expectation (over targets Y ), any interpolating estimator recovers θ? in the column space
of X, but is unconstrained in Null(X > X). The minimum norm interpolant sets the component in
Null(X > X) to zero. Formally,
E[θ] = (X>X户X>Xθ? =⇒ B(θ) = θ*>∏X∑∏Xθ?,
where ∏X =(I — (X>X户(X>X)) is the projection matrix onto NUll(X>X).
We now compare the bias of the standard and data augmented estimators (defined in Equation 2). It
is convenient to define ∑std = XstdXStd and ∑aug = XstdXStd + X>tXext∙ Let Π⊥i = I — ∑*d∑std and
Π⊥ug = I -∑lug∑aug be the projection matrices onto Null(∑std) and Null(∑aug) respectively. Then,
B(θstd) = θ*>∏⊥d∑∏⊥dθ? and B(θaug) = θ*>∏⊥1gΣΠ⊥1gθ*.	(4)
Remark 1. Note that the bias in parameter error is ∣∣E[θ] — θ*∣∣2 = ∣∣∏Xθ*∣∣2. Since
Null(Σaug) ⊆ Null(ΣStd), we have ∣∣Π⊥igθ*∣2 ≤ ∣∣Π⊥dθ*∣∣2, and data augmentation always re-
duces the bias in parameter error. However, the bias in test error upon augmentation B(θaug) could
be larger or smaller than B(θstd).
4.1.1	SIMPLE LINEAR PROBLEM IN R3 WHERE ADDING DATA INCREASES BIAS
The following example illUstrates how the interaction between the colUmn spaces of standard inpUts Xstd,
extra inpUts Xext and the Underlying trUe parameter θ? coUld caUse data aUgmentation to increase bias.
For simplicity, we choose Σ = diag([λ1, λ2, λ3]) with λ2 λ1, Xstd = e3 and additional data
Xext = e1 +e2 where e1,e2,e3 denote the standard bases in R3. For brevity in notation, we denote
E[θstd] by θstdand E[仄ug] by θaug.
Recall that by virtue of being minimum norm interpolants, (θstd — θ?) ∈ Null(∑std) = R2 and
(θaug — θ?) ∈ Null(∑aug) = {ρ(eι 一 e2 : P ∈ R}. Figure 2 depicts these parameter errors for different
choices of θ? .
Bias under different settings of θ?. Plugging these terms into the bias expression in Equation (4) yields
Batd) =。?口1 + θ? 2λ2	and B(θaug) = (1∕4)(θ? —。?)兄 + (1/4)(。?一θ?)^.
Since in our construction of Σ we have λ2 λ1, the bias expression is dominated by the coefficient
on λ2, which is the projection of the parameter error on e2 (red lines in Figure 2). Depending on θ?,
B(θaug) could be larger or smaller than B(θstd). In particular,
(i)	when θ1? θ2? as in Fig. 2 (a), augmenting with Xext can increase bias B(θaug) B(θstd). Even
though the augmented estimator has lower parameter error overall (∣θaug 一 θ? k 2 ≤ k θstd — θ? k 2),the
increase in parameter error along e2 dominates the effect on the bias because λ2 λ1.
(ii)	when θ2? θ1? as in Fig. 2 (b), the same Xext causes B(θaug) to be smaller than B(θstd). Here
the augmented estimator has smaller parameter error along e2 and hence decreasing bias despite an
increase along e1.
4
Under review as a conference paper at ICLR 2020
Figure 2: Illustration of the 3-D example described in Sec. 4.1.1. In (a), (b) We depict the errors
θaug 一 θ (green solid) and θstd 一 θ (blue solid) projected onto Null(∑std) that is spanned by
eigenvectors eι and e2 of Σ with λ?》λι. Red lines depict the projection of parameter errors on
e2 which determines the bias. In (a) θ?》θ? and bias increases upon augmentation. In (b) θ?》θ?
and bias decreases upon augmentation. (c), (d)The space of safe augmentation directions (orange)
that don’t increase bias for a given θ? are cone-shaped, where the cone width depends on the alignment
ofθ? with eigenvectors of Σ and the skew in eigenvalues of Σ.
(C) Σ = diag([1,4])
(d) Σ = diag([1,25])
In summary, the minimum norm interpolant treats all unobserved dimensions in the null space
“equally”. In contrast, the bias is dominated by the components of the parameter error along the top
eigenvectors of Σ. This mismatch could lead to settings where decreasing the null space of the training
points via augmentation increases the error along top eigenvectors of Σ. We formalize this intuition
and present a general characterization below.
4.1.2	General characterizations
We now study the biases of the standard and augmented estimators in general. Recall that Πs⊥td and Πa⊥ug
are the projection matrices onto Null(Σstd) and Null(Σaug) respectively, where Σstd = Xs>tdXstd and
Σaug=Xs>tdXstd+Xe>xtXext. Since Null(Σaug) ⊆Null(Σstd), we can decompose Πs⊥tdθ? into orthogonal
components v = Πa⊥ugθ? and w = Πs⊥tdΠaugθ? . Substituting this decomposition into Equation 4, we
get the following exact characterization for when data augmentation increases bias.
Theorem 1. The augmented estimator θaug has larger bias i.e., B(θaug) > B (θstd) if and only if
v> Σv < —2w> Σv,	(5)
where v = Πs⊥tdΠaugθ? and w = Πa⊥ugθ?.
The proof of Theorem 1 is in Appendix B.1. We see that condition (5) depends on θ? which is typically
unknown. Hence, we cannot determine apriori ifa particular form of augmentation would be “safe”
and not increase error (like random translations in Cifar- 1 0) or harmful (like random rotations in
Cifar- 1 0). However, we can make the following statements about when data augmentation is safe
(for any θ?) in some restricted settings.
1.	When Σ = I, the condition (5) is always met (since w ⊥ v) and hence data augmentation
is always safe and never increases bias for any θ? . This suggests that data augmentation
increases bias when there is a mismatch between the norm being minimized during
interpolation and the norm of the parameter error that determines test error.
2.	When Xext spans the entire nullspace of Σstd such that Σaug is invertible, w=0 for all θ? and
data augmentation never increases bias.
3.	In the simple case where Xext is rank-one, data augmentation is safe for all θ? if and only
if Πs⊥tdXext is an eigenvector of Σ. See Appendix B.4 for a proof.
Finally, we illustrate the safe augmentation directions Xext in the nullspace of Σstd for the simple 3-D
problem discussed above for two different choices of Σ and a fixed θ? (Figure 2 (c), (d)). The safe aug-
mentations lie in cones around the eigenvectors of Σ while the width and alignment of the cones depends
on the alignment between θ? and the eigenvectors of Σ. As the eigenvalues of Σ become more skewed,
5
Under review as a conference paper at ICLR 2020
Figure 3: Top 4 eigenvectors of Σ in the splines problem, representing wave functions in the input
space. The eigenvalues corresponding to “global” eigenvectors which vary less over the domain are
larger, making errors in global dimensions costly in terms of test error.
the space of safe augmentations shrinks. We present a dual perspective on Theorem 1 in Appendix B
which characterizes the effect of augmentation on the bias in terms of properties of the true parameter θ?.
Local vs. global structure. Finally, we tie our analysis back to the spline staircase problem from
Figure 1. The inputs can be appropriately rotated so that the cubic spline interpolant is the minimum
Euclidean norm interpolant (as in Equations 2). Under this rotation, the different eigenvectors of
Null(Σstd) measure either the fitin the “local” high frequency components or “global” low frequency
components (See Figure 3). Any augmentation that encourages fitting local components inNull(Σstd)
could lead to a worse fit of the global structure, leading to increased test error (See Figure 3). This
is suggestive of a similar trade-off phenomenon in practice where adversarial training (with say '∞
perturbations) encourages neural networks to fit the high-frequency components of the signal while
compromising on the overall global structure causing an increase in test error.
4.2	Variance of Minimum Norm Interpolants
The main focus of this work is on the effect of data augmentation on the bias of minimum norm
interpolants. For completeness, we present some conditions under which the data augmentation
increases or decreases variance. For a more complete treatment, please refer to Appendix C. Let
Xstd ,ystd be the standard training data, with extra points Xext ,yext and let Πs⊥td denote the projection
matrix onto Null(Xs>tdXstd ).
Theorem 2. For the minimum norm interpolants defined in Equation 2, the following hold.
1.	When Πs⊥tdXext = 0 such that the extra points lie in the column space of original standard
training data, V (θaug) ≤V (θstd).
2.	When Xext ⊥ Xstd, such that the extra points lie entirely in Null(Xs>tdXstd), we have
V(θaug) ≥ V(θStd)∙
In general, when Xext ∈ Null(Xs>tdXstd), we see that both the bias and variance of minimum norm
interpolants could increase upon data augmentation, shedding some light on why data augmentation
sometimes increases standard error in practice.
5	Effect of size of the original training set
In this section, we study how the effect of data augmentation varies as we vary the size of the original
standard training set. We first briefly study this in the setting of minimum norm interpolation in linear
regression. We then empirically evaluate the effect of adversarial training as we vary the number of
original training samples in Cifar- 1 0 and observe that the empirical trends mirror the trends dictated
by our analysis in linear regression.
5.1	Minimum norm interpolation—small and large data regimes.
Without loss of generality, we assume that Σ, the population covariance ofPx is invertible since the
test error only depends on columnspace ofΣ.
Large data regime. In the large data regime where the number of standard training points n → ∞, the
empirical covariance of the original training points Σstd = Xs>tdXstd ≈ nΣ is invertible with Πs⊥td = 0.
Both θstd and θa∏g are unbiased (from Equation 4). From Theorem 2, variance of θa∏g is never larger than
6
Under review as a conference paper at ICLR 2020
匕 0.75
S
r7 0.50
,s
<0.25
ιij
⅛0.00
S> 6 4 2c
(s(BSE3sFsnvr3-SaL
IO2	IO3	3
Number Of labeled samples	NUmberOflabeledSamPIeS
(a)	Spline Staircase
(b)	CIFAR- 1 0 (AT)
(％二 ESH击ttωl 二 6ng」」山ttωl
Number of labeled samples
at, ε = ς∣5
X-Reg, ε —京
at∙ e = ⅛
X-Reg, ε —圭
(c) CIFAR- 1 0 (AT)
Figure 4: Effect of data augmentation on test error as we vary the number of training samples. We plot
the difference in errors of the augmented estimator and standard estimator. In both the spline staircase
simulations and data augmentation with adversarial '∞ perturbations via adversarial training (AT)
on Cifar- 1 0, we find that as we increase the number of samples, the increase in test error decreases.
that of θstd. Putting together, the test error never increases upon augmentation in the large sample regime
matching the common intuition that more data from the correct target distribution should never hurt.
Small data regime. In the small data regime, where nis much smaller than d, the empirical covariance
Σstd could be far from invertible. As we increase the number of samples, the null space Null(Σstd)
shrinks. Our analysis in Section 4 shows that for a fixed θ?, the magnitude of possible increase in both
bias and variance decreases as Πs⊥tdXext decreases (See Appendix E) for details). This suggests that as
the size of Xstd increases, the increase in test error due to augmentation decreases. We run simulations of
the spline staircase example from Figure 1 and find that this trend holds (Figure 4(a); see Appendix D).
5.2	Empirical observations on the effect of sample size.
Do the trends in linear regression also hold for classification with more complex models and real
world datasets? For our empirical study, we focus on adversarial training (Madry et al., 2018),
iterative data augmentations with adversarial '∞ perturbations of different magnitudes e. We train
a WideResNet-40-2 (Zagoruyko & Komodakis, 2016) on Cifar- 1 0 training set subsampled by
varying amounts. We plot the difference in the test errors of the augmented and standard estimators as a
function of training set size in Figure 4. We find that augmentation is less detrimental to test error with
increase in sample size (Figure 4(b)), matching the trends predicted by our analysis of linear regression.
Extrapolating the plot, we see that there should be no tradeoff between robustness and accuracy in
the infinite data limit—contradicting the toy examples studied in (Tsipras et al., 2019; Zhang et al.,
2019; Nakkiran, 2019) which we discussed in Section 2.
6	Mitigating the increase in bias upon augmentation
To this point, the paper focuses on understanding why data augmentation could increase test error by
analysing the setting of minimum norm interpolation in linear regression. However, data augmentation
(e.g., via adversarial perturbations) often comes with desirable benefits such as robustness of estimators.
In this section, we leverage our understanding from linear regression to design a new estimator for
interpolating augmented data that mitigates the increase in test error while preserving the benefits.
To this end, we introduce X-regularization, and prove that X-regularization eliminates the increase
in bias upon augmentation for noiseless linear regression (Section 6.1. In Section 6.2, we show that
this estimator naturally generalizes to arbitrary losses and complex models and is closely connected
to the classical semi-supervised self-training algorithm (Scudder, 1965). We empirically evaluate
the performance of this general X-regularization on adversarial training in Section 6.3. In a nutshell,
X-regularization causes a smaller increase in standard error while maintaining or simultaneously
improving the robustness of neural networks trained on Cifar- 1 0.
7
Under review as a conference paper at ICLR 2020
6.1	X-regularization for linear regression
Our development considers a stylized setting of interpolation in linear regression with noiseless
observations from a linear model, y = x>θ?, where the dimension is (much) larger than the number
of observations. Let θint-std interpolate the initial data, satisfying Xstdθint-std = ystd . We use θint-std to
construct anew data augmented estimator θx-aug that interpolates both the standard data and augmented
extra data while satisfying R(θx-aug) ≤ R(θint-std).
Given Σ and an initial interpolant θint-std, we propose the X-regularized data augmentation estimator
θx-aug ∈ argmin (θ - θint-std) Σ(θ - θint-std) : Xstdθ = ystd, Xextθ = yext .
(6)
El ▼ T	1 • 1	. 久	.•	/'	11	JlFl •>∙>,/ PT-	\ 1
The X-regularized estimator θx-aug optimizes for small error on the labeled data (Xstd, ystd) and
(Xext,yext) while keeping the predictions of θx-aug close to those of θint-std over unlabeled inputs drawn
from Px . To motivate our estimator, recall our discussion on the effect of data augmentation on the bias
(test error in noiseless case) of minimum norm interpolants in Section 4.1. By fitting extra dimensions
of Xext, the data augmented estimator could have a larger parameter error than θint-std in important
directions of Σ, and consequently higher test error (Figure 2). A natural strategy to mitigate this
increase, then, is to fit Xext while staying close to θint-std weighted by Σ, which leads to the estimator
defined in Equation 6. This intuition can be formalized to prove that the X-regularized interpolant
θx-aug never has higher test error than θint-std.
Theorem 3. Assume the noiseless linear model y = x> θ?. Let θint-std be an arbitrary interpolant of
the standard data, i.e. Xstdθint-std = ystd. Let θx-aug be the X-regularized interpolant (6). Then
R(θx-aug ) ≤ R(θint-std).
See Appendix ?? for proof. To provide some graphical intuition for the result, consider the spline
interpolant θstd Fig. 1 illustrates where Xext consists of local perturbations. The X-regularized estimator
matches the standard interpolant θstd on points outside the training set, thereby capturing global
structure while simultaneously fitting local structure on the training set via Xext.
Note that our discussion on the effect of sample sizes in Section 5 suggests that a larger labeled standard
training set would mitigate the drop in standard error due to augmentation. However, our development
of X-regularization suggests that we only need unlabeled data, which is much cheaper to obtain in
practice. Unlabeled data is often used to improve standard test error in the semi-supervised learning
paradigm. Here, we motivate the use of unlabeled data to mitigate the possible increase in test error
from data augmentation.
6.2	Robust self-training as X-regularization for robustness
To motivate using X-regularization for general models and losses, note that the expression of the
objective function for the X-regularized estimator in (6) can be rewritten in a more general form:
(θ — θint-std)>∑(θ — θint-std)= EPx [(x>θ-x>θint-std)2]= Ep* ['sq(fθ(x),fθgtd (x))],
where 'sq is the squared loss between the predictions of the model fθ (x) with the predictions
(pseudo-labels) ofa given interpolant fθint-std (x). A generalized version of X-regularization replaces
'sq with some general loss' that include classification losses such as the logistic loss. Written this way,
X-regularization regularizes the predictions ofan augmented estimator towards the predictions of the
standard interpolant, similarly to the classical semi-supervised self-training algorithm (Scudder, 1965).
The main motivation of our work is to fix the the drop in standard test performance from augmentation
strategies that seek to enforce robustness by adding label-preserving transformations of existing inputs.
With augmentations take the form of some label-preserving transformations T, itis natural to consider
transformations of both the labeled and unlabeled data as the set of “extra” points, that constitute Xext.
Generalizing the linear regression estimator of Equation 6 to use arbitrary losses and transformation
8
Under review as a conference paper at ICLR 2020
Method	Robust TestAcc.	Standard TestAcc.
Standard Training	0.8%	95.2%
Standard Self-Training	0.3%	96.4%
PG-AT (Madry et al., 2018)	45.8%	87.3%
RST + PG-AT	58.5%	91.8%
TRADES (Zhang etal.,2019)	55.4%	84.0%
RST + TRADES (Carmon et al., 2019)	63.1%	89.7%
Interpolated AT (Lamb et al., 2019)1	45.1%	93.6%
Neural Arch. Search (Cubuk et al., 2017)	50.1%	93.2%
Table 1: Performance of X-regularization instantiated as robust self-training (RST) applied to different
perturbations and adversarial training algorithms. (Left) CIFAR- 1 0 standard test accuracy and robust
test accuracy against '∞ perturbations of size e = 8/255. All methods use e = 8/255 while training.
Robust accuracies are against a PG based attack with 20 steps. (Right) CIFAR- 1 0 standard test
accuracy and robust test accuracy against a grid attack of rotations up to 30 degrees and translations up
to 〜10% of the image size, following (Engstrom et al., 2019). All adversarial and random methods use
rotations and translations with these same parameters during training. For both tables, all shaded rows
make use of 500K unlabeled images from 80M Tiny Images sourced in (Carmon et al., 2019). RST
improves both the standard and robust accuracy over the vanilla counterparts for different algorithms
(AT and TRADES) as well as different perturbations ('∞ and rotation/translations).
Method	Robust Test Acc.	Standard TestAcc.
Standard Training	0.2%	94.6%
Worst-of-10	73.9%	95.0%
RST + Worst-of-10	75.1%	95.8%
Random	67.7%	95.1%
RST + Random	70.9%	95.8%
Worst-of-10	69.2%	91.3%
(Engstrom et al., 2019)2 Random (Yang et al., 2019)3	58.3%	91.8%
based augmentations, we get,
θx-aug ：=argmin| N T	X	'(fθ (x),y)+β "fθ(T (x)),y)
θ	(x,y)∈[Xstd,ystd]
m
+λm-1X'(fθ (Xi),fθstd (Xi))+β'(fθ (T (Xi)),f^std (Xi)).	⑺
i=1
We note that the general X-regularized estimator above is the Robust Self-Training (RST) algorithm
proposed and studied recently by Carmon et al. (2019), when applied to arbitrary transformations.
Variants of RST were also studied in (Najafi et al., 2019; Uesato et al., 2019). By deriving RST via X-
regularization, we provide some theoretical justification for why RST would improve standard accuracy.
6.3	Empirical evaluation of X-regularization as RST
For our empirical investigation, we evaluate the effect of X-regularization on the commonly
observed tradeoff between robustness and standard accuracy when augmenting the training set with
transformations. We recall that X-regularization when applied to transformation based augmentations
leads to Robust Self Training. Therefore, we refer to X-regularization and RST synonymously through
this section. We instantiate the robust self-training estimator defined in Equation 7 on both PG-AT
and TRADES; exact loss functions appear in Appendix F.2. All of our experiments are on Cifar- 1 0,
and RST estimators use 500K unlabeled images sourced from Tiny Images in (Carmon et al., 2019)
in addition to the labeled training set.
In our first experiment, we use the same settings as our experiments on effect of sample size
in Cifar- 1 0 in Section 5. We compare the error of RST+PG-AT and standard training in Figure 4.
We find that RST+PG-AT has lower standard test error than the standard training, while simultaneously
fitting the training data robustly and achieving higher robustness (see Appendix G.2.1). We also see
the maximum gains from RST+PG-AT are in the small data regime where adversarial training has
the most affect on standard error.
In our next experiment, we compare with other methods in the literature. We train a larger WRN-28-
10 model with the entire labeled Cifar- 1 0 training set and 500K unlabeled images. Table 1(left)
summarizes the results. While there is a still a drop in accuracy compared to standard training, RST has
higher standard accuracy than the vanilla counterparts without sacrificing robustness, in both PG-AT
and TRADES. The gains are comparable to gains from other measures to improve the tradeoff between
9
Under review as a conference paper at ICLR 2020
robustness and accuracy such as Interpolated Adversarial Training and Neural Architecture Search. RST
could be integrated with the above training algorithms to see further gains; we leave this to future work.
Finally, we test the effect of RST on a different family of perturbations. We consider adversarial (worst
of 10) and random augmentations using simultaneous rotations and translations of the input image.
Table 1(right) presents the results. While the augmented estimators marginally improve standard
accuracy for these perturbations, applying RST increases both robust and standard accuracies beyond
that of the augmented estimator in both cases. This shows that RST is beneficial even when data
augmentation does not decrease standard test error.
7	Discussion
Semi-supervised setting. General X-regularization leverages unlabeled data to mitigate the possible
harmful effect of data augmentation. The traditional setup of semi-supervised learning involves
only one objective: improve the standard accuracy on the underlying population. We revisit the
semi-supervised setting with a different focus. For several applications, standard supervised deep
learning provides highly accurate classifiers, but they are surprisingly brittle. Attempts to improve
robustness typically lower accuracy. Training robust and accurate classifiers remains an open challenge,
and semi-supervised learning is emerging as a promising approach. Recent work (Carmon et al.,
2019; Najafi et al., 2019; Uesato et al., 2019) has studied the benefits of semi-supervised learning in
improving robustness. In our work, we bolster this line of work by demonstrating that semi-supervised
learning can simultaneously improve the accuracy, while maintaining robustness.
Self-training. In this work, we study X-regularization which is closely related to self-training, perhaps
the oldest semi-supervised learning algorithm (Scudder, 1965). In the traditional setting of improving
standard accuracy, self-training has shown some success, but other approaches perform significantly bet-
ter; see survey (Oliver et al., 2018). However, in the regime where we care about both robustness and ac-
curacy, we see that self-training based approaches such as X-regularization offer significant benefits. We
provide a detailed comparison of X-regularization to other semi-supervised learning algorithms in Ap-
pendix H. Variants of self-training are also gaining prominence in the related but different setting of unsu-
pervised domain adaptation. Here, the unlabeled data is from the “target” distribution, while the labeled
data is from a different “source” distribution and the goal is to perform well on the target distribution.
Interpolation in linear regression. Analysis of the interpolation regime has recently gained promi-
nence with the observation that neural networks obtain zero training error. Previous works (Hastie et al.,
2019; Bartlett et al., 2019; Belkin et al., 2019) study the performance of minimum norm interpolants in
overparameterized linear regression in an attempt to explain the generalization properties of neural net-
works that are not explained by the classical perspective on interpolation and overfitting. In our work, we
show that the same overparameterized setting also sheds light on the empirical observation that data aug-
mentation sometimes helps and sometimes harms test performance. In contrast, in the classical under-
parameterized regime, data augmentation never harms test performance as common statistical intuition
would suggest. Studying interpolation in the overparameterized regime even in simple settings such as
linear regression thus seems to be valuable in understanding the properties of neural networks in practice.
Conclusion. We studied adversarial training through the lens of data augmentation with the goal of
training robust and accurate classifiers. We analyzed general data augmentation in a stylized setting
and proved that unlabeled data can eliminate possible increase in test error. This motivated a general
estimator based on self-training combined with adversarial training that shows promise in improving
both the accuracy and robustness of neural networks in practice. While using unlabeled data via simple
self-training has shown to improve both accuracy and robustness, how to best utilize unlabeled data
in this context is an open question. Further, can we obtain highly robust and accurate networks by
simply using a large amount of unlabeled data, or do we need further innovations in neural network
architectures and training?
References
P. L. Bartlett, P. M. Long, G. Lugosi, and A. Tsigler. Benign overfitting in linear regression. arXiv, 2019.
M. Belkin, S. Ma, and S. Mandal. To understand deep learning we need to understand kernel learning.
In International Conference on Machine Learning (ICML), 2018.
10
Under review as a conference paper at ICLR 2020
M. Belkin, D. Hsu, and J. Xu. Two models of double descent for weak features. arXiv, 2019.
B. Biggio, I. Corona, D. Maiorca, B. Nelson, N. Srndic, P. Laskov, G. Giacmto, and F. Roli. Evasion
attacks against machine learning at test time. In Joint European conference on machine learning
and knowledge discovery in databases,pp. 387-402,2013.
Y. Carmon, A. Raghunathan, L. Schmidt, P. Liang, and J. C. Duchi. Unlabeled data improves
adversarial robustness. In Advances in Neural Information Processing Systems (NeurIPS), 2019.
E. D. Cubuk, B. Zoph, S. S. Schoenholz, and Q. V. Le. Intriguing properties of adversarial examples.
arXiv preprint arXiv:1711.02846, 2017.
S. Diamond and S. Boyd. CVXPY: A Python-embedded modeling language for convex optimization.
Journal of Machine Learning Research (JMLR), 17(83):1-5, 2016.
L. Engstrom, B. Tran, D. Tsipras, L. Schmidt, and A. Madry. Exploring the landscape of spatial
robustness. In International Conference on Machine Learning (ICML), pp. 1802-1811, 2019.
A. Fawzi, O. Fawzi, and P. Frossard. Analysis of classifiers robustness to adversarial perturbations.
Machine Learning, 107(3):481-508, 2018.
J. Friedman, T. Hastie, and R. Tibshirani. The elements of statistical learning, volume 1. Springer
series in statistics New York, NY, USA: Springer series in statistics New York, NY, USA:, 2001.
I. J. Goodfellow, J. Shlens, and C. Szegedy. Explaining and harnessing adversarial examples. In
International Conference on Learning Representations (ICLR), 2015.
T. Hastie, A. Montanari, S. Rosset, and R. J. Tibshirani. Surprises in high-dimensional ridgeless least
squares interpolation. arXiv preprint arXiv:1903.08560, 2019.
P. Kovanic. On the pseudoinverse of a sum of symmetric matrices with applications to estimation.
Kybernetika, 15, 1979.
A. Krizhevsky, I. Sutskever, and G. E. Hinton. Imagenet classification with deep convolutional neural
networks. In Advances in Neural Information Processing Systems (NeurIPS), pp. 1097-1105, 2012.
S.	Laine and T. Aila. Temporal ensembling for semi-supervised learning. In International Conference
on Learning Representations (ICLR), 2017.
A. Lamb, V. Verma, J. Kannala, and Y. Bengio. Interpolated adversarial training: Achieving robust
neural networks without sacrificing too much accuracy. arXiv, 2019.
T.	Liang and A. Rakhlin. Just interpolate: Kernel” ridgeless” regression can generalize. arXiv preprint
arXiv:1808.00387, 2018.
S.	Ma, R. Bassily, and M. Belkin. The power of interpolation: Understanding the effectiveness of
SGD in modern over-parametrized learning. In International Conference on Machine Learning
(ICML), 2018.
A. Madry, A. Makelov, L. Schmidt, D. Tsipras, and A. Vladu. Towards deep learning models resistant
to adversarial attacks. In International Conference on Learning Representations (ICLR), 2018.
T.	Miyato, S. Maeda, S. Ishii, and M. Koyama. Virtual adversarial training: a regularization method
for supervised and semi-supervised learning. IEEE transactions on pattern analysis and machine
intelligence, 2018.
A. Najafi, S. Maeda, M. Koyama, and T. Miyato. Robustness to adversarial perturbations in learning
from incomplete data. arXiv preprint arXiv:1905.13021, 2019.
P. Nakkiran. Adversarial robustness may be at odds with simplicity. arXiv preprint arXiv:1901.00532,
2019.
A. Oliver, A. Odena, C. A. Raffel, E. D. Cubuk, and I. Goodfellow. Realistic evaluation of deep
semi-supervised learning algorithms. In Advances in Neural Information Processing Systems
(NeurIPS), pp. 3235-3246, 2018.
11
Under review as a conference paper at ICLR 2020
M. Sajjadi, M. Javanmardi, and T. Tasdizen. Regularization with stochastic transformations and
perturbations for deep semi-supervised learning. In Advances in Neural Information Processing
SyStemS(NeurIPS) ,pp.1163-1171,2016.
H. Scudder. Probability of error of some adaptive pattern-recognition machines. IEEE Transactions
on Information Theory, 11(3):363-371, 1965.
C. Szegedy, W. Zaremba, I. Sutskever, J. Bruna, D. Erhan, I. Goodfellow, and R. Fergus. Intriguing prop-
erties of neural networks. In International Conference on Learning RepreSentationS (ICLR), 2014.
D. Tsipras, S. Santurkar, L. Engstrom, A. Turner, and A. Madry. Robustness may be at odds with
accuracy. In International Conference on Learning RepreSentationS (ICLR), 2019.
J. Uesato, J. Alayrac, P. Huang, R. Stanforth, A. Fawzi, and P. Kohli. Are labels required for improving
adversarial robustness? arXiv preprint arXiv:1905.13725, 2019.
Q. Xie, Z. Dai, E. Hovy, M. Luong, and Q. V. Le. Unsupervised data augmentation. arXiv preprint
arXiv:1904.12848, 2019.
L. Yaeger, R. Lyon, and B. Webb. Effective training of a neural network character classifier for word
recognition. In AdvanceS in Neural Information ProceSSing SyStemS (NeurIPS), pp. 807-813, 1996.
F. Yang, Z. Wang, and C. Heinze-Deml. Invariance-inducing regularization using worst-case transfor-
mations suffices to boost accuracy and spatial robustness. arXiv preprint arXiv:1906.11235, 2019.
S. Zagoruyko and N. Komodakis. Wide residual networks. In BritiSh Machine ViSion Conference, 2016.
H. Zhang, Y. Yu, J. Jiao, E. P. Xing, L. E. Ghaoui, and M. I. Jordan. Theoretically principled trade-off
between robustness and accuracy. In International Conference on Machine Learning (ICML), 2019.
A Transformations to handle arb itrary matrix norms
Consider a more general minimum norm estimator of the following form. Given inputs X and
corresponding targets Y as training data, we study the interpolation estimator,
θ = argmin {θ>Mθ: Xθ = Y },
(8)
where M is a positive definite (PD) matrix that incorporates prior knowledge about the true model.
For simplicitly, we present our results in terms of the `2 norm (ridgeless regression) as defined in
Equation 8. However, all our results hold for arbitrary M -norms via appropriate rotations. Given
an arbitrary PD matrix M, the rotated covariates X J M-1/2X and rotated parameters θ J M 1/2θ
maintain Y=Xθ+σN(0,I) and the M-norm of parameters simplifies to kθk2.
B Bias of minimum norm interpolants
B.1	Proof of Theorem 1
Inequality (5) follows from
= C∏⊥ugθ?)>∑π⊥1gθ?-C∏⊥d θ?)>∑π⊥d θ?
=w>Σw-(w+v)>Σ(w+v)
-2w>Σv-v>Σv	(9)
by decomposition of Π⊥dθ? = V+W where V = Π⊥d∏ugθ? and W = ∏s⊥d∏⊥1gθ?. We also want to note
that the bias difference does scale with kθ? k2 .
12
Under review as a conference paper at ICLR 2020
B.2	Bias increase requires complex true estimators
A dual perspective on Theorem 1 leads the following proposition that characterizes the properties
of the true function θ? that leads to harmful augmentations.
Proposition 1. For a given Xstd,Xext,Σ, a bias increase ofB(θaug) -B(θstd) =c> 0 via augmentation
with Xext is possible only ifθ? is sufficiently more complex than θstd in the `2 norm, i.e.
kθ*k2-kθStd k2>γc	(10)
for some scalar γ > 0 that depends on Xstd,Xext,Σ.
B.2.1	Proof of inequality (10)
The proof of inequality (10) is based on the following two lemmas that are also useful for
characterization purposes in Corollary 1.
Lemma 1. Ifa PSD matrix Σ has non-equal eigenvalues, one can find two unit vectors w,v for which
the following holds
w>v = 0	and	w>Σv 6= 0	(11)
Hence, there exists a combination of original and augmentation dataset Xstd , Xext such that
condition (11) holds for two directions v ∈ Col(Πs⊥tdΠaug) andw ∈ Col(Πs⊥tdΠa⊥ug) = Col(Πa⊥ug).
Note that neither w nor v can be eigenvectors of Σ in order for both conditions in equation (11) to
hold. Given a population covariance, fixed original and augmentation data for which condition (11)
holds, we can now explicitly construct θ? for which augmentation hurts bias.
Lemma 2. Assume Σ, Xstd, Xext are fixed. Then condition (11) holds for two directions v ∈
Col (Π ⊥d Π aug) and W ∈ Col (Π ⊥d Π ⊥g) iffthere exists a θ? such that B (θ aug) — B (θ std) ≥ C forsome c> 0.
T-T , 1	,1 Λ	cc-i- 1	, , 7 r 11 ∙ 1	1	1 ∙ , 1	11 λ 11 9 11 λ 11 9
Furthermore, the '2 norm of θ needs to satisfy thefollowιng lower bounds with ci := ∣∣θ aug k2 -∣∣θstd∣∣2
c2
kθ k — kθaug Il ≥ β1c1 +β2 —
c1
c2
kθ k — kθ std k ≥ (β1 + I)CI +β2—	(12)
c1
where βi are constants that depend on Xstd,Xext,Σ.
Inequality (10) follows directly from the second statement of Lemma 2 by minimizing the bound (12)
with respect to ci which is a free parameter to be chosen during construction of θ? (see proof of
Lemma (2). The minimum is attained for ci = 2y∕(βι + I)(β2c2). We hence conclude that θ? needs
to be sufficiently more complex than a good standard solution, i.e. k θ? k 2 — k θstd k 2 >γc where γ> 0
is a constant that depends on the Xstd,Xext.
B.3	Proof of Technical Lemmas
In this section we prove the technical lemmas that are used to prove Theorem 1.
B.3.1	Proof of Lemma 2
Any vector Πs⊥tdθ ∈ Null(Σstd) can be decomposed into orthogonal components Πs⊥tdθ =
Πs⊥tdΠa⊥ug θ + Πs⊥tdΠaug θ. Using the minimum-norm property, we can then always decompose the
(rotated) augmented estimator θaug ∈ Col(Π⊥1g) = Col(Π⊥d∏⊥1g) and true parameter θ? by
θaug = θstd + E Zivi
vi ∈ext
θ? = θaug + X ξjwj,
wj ∈rest
13
Under review as a conference paper at ICLR 2020
where we define “ext” as the set of basis vectors which span Col(Πs⊥tdΠaug) and respectively “rest” for
Null(Σaug). Requiring the bias increase to be some constant c> 0 can be rewritten using identity (9)
as follows
_ , O 、	_ , O 、
B(θaug)-B (。Std)=C
^ ⇒ ()： Zivi)Tς(〉： Zivi)+c = -2(	X ξjwj )Σ(	X ζivi)
vi ∈ext	vi ∈ext	wj ∈rest	vi ∈ext
^⇒(X Zivi)>夕(X Zivi)+c=-2	X	&<刈>夕3	(13)
vi ∈ext	vi ∈ext	wj ∈rest,vi ∈ext
The left hand side of equation (13) is always positive, hence it is necessary for this equality to hold
with any c> 0, that there exists at least one pair i,j such that wj>Σvi 6=0 and one direction of the iff
statement is proved.
For the other direction, we show that if there exist v ∈ Col(Πs⊥tdΠaug) and w ∈ Col(Πs⊥tdΠa⊥ug) for
which condition (11) holds (wlog we assume that the w>Σv < 0) we can construct a θ? for which the
inequality (5) in Theorem 1 holds as follows:
Itis then necessary by our assumption that ξj Zi wj> Σvi > 0 for at least some i,j. We can then set Zi > 0
such that kθaug -θstdk2 = kZk2 =c1 >0, i.e. that the augmented estimator is not equal to the standard
estimator (else obviously there can be no difference in bias and equality (13) cannot be satisfied for
any desired bias increase c>0).
The choice of ξ minimizing kθ? - θaug k2 = Pj ξj2 that also satisfies equation (13) is an appropri-
ately scaled vector in the direction of x = W>ΣV Z where we define W := [w1, ... , w|rest|] and
V := [v1,...,v|ext|]. Defining c0 =Z>V >ΣV Z for convenience and then setting
ξ=-20⅛X	(14)
which is well-defined since x 6= 0, yields a θ? such that augmentation hurts. It is thus necessary for
B (θaug)-B(θstd) = c that
χξ2 =	(C0+C)2	= (Z>V >∑VZ+c)2
ξ-==j = 4∣∣ W > ΣVZ ∣∣2 = 4Z > V > ΣWW > ΣVZ
≥	(Z>V >∑VZ)2	+	C2
≥ 4Z> V> ΣWW> ΣVZ + 4Z> V> ΣWW> ΣVZ
≥ ci λmm(v >∑v) +	c2
≥ 4 λmaχ(W>∑V)+4cιλmaχ(W>ΣV).
By assuming existence of i,j such that ξj Zi wj> Σvi 6=0, we are guaranteed that λ2max(W> ΣV) > 0.
Note due to construction We have ∣ θ? 12 = ∣∣θstd ∣∣2 + PiZi2 + Pjξj and plugging in the choice of ξj
in equation (14) we have
kθ*k2 . kθ k2 ≥」+ $in(V >”)L	C2	ɪ
k ∣2 k std∣2≥1 [ 4λmaχ(w>∑v)]+4λmaχ(w>∑v)c1.
Setting β = [1+ 4：?;((V>⅞V)] , β2 = 4*aX(W > ςv) yields the result.
B.3.2 Proof of Lemma 1
Let λ1,...,λm be the m non-zero eigenvalues of Σ and ui be the corresponding eigenvectors. Then
choose v to be any combination of the eigenvectors v = U β Where U = [u1,...,um] Where at least βi,βj 6=
14
Under review as a conference paper at ICLR 2020
0 for λi 6= λj. We next construct w = Uαby choosing α as follows such that the inequality in (11) holds:
=βj
αi=W+β
_ -β
αj=W+β
and αk =0 for k 6=i,j. Then we have that α>β=0 and hence w>v=0. Simultaneously
w>Σv = λiβiαi+λjβjαj
=(λi-λj) ββ+β2=0
which concludes the proof of the first statement.
We now prove the second statement by constructing Σstd = Xs>tdXstd , Σext = Xe>xtXext using w, v .
We can then obtain Xstd , Xext using any standard decomposition method to obtain Xstd , Xext. We
construct Σstd , Σext using w, v. Without loss of generality, we can make them simultaneously
diagonalizable. We construct a set of eigenvectors that is the same for both matrices paired with
different eigenvalues. Let the shared eigenvectors include w, v . Then if we set the corresponding
eigenvalues λw(Σext) = 0,λv(Σext) >0 and λw(Σstd) = 0,λv(Σstd) =0, then λw(Σaug) =0 such that
w ∈Col(Πs⊥tdΠa⊥ug) and v ∈ Col(Πs⊥tdΠaug). This shows the second statement. With this, we can design
a θ? for which augmentation hurts as in Lemma 2.
B.4 Characterization Corollary 1
A simpler case to analyze is when we only augment with one extra data point. The following corollary
characterizes which single augmentation directions lead to higher prediction error for the augmented
estimator.
Corollary 1. The following characterizations hold for augmentation directions that do not cause
the bias of the augmented estimator to be higher than the original estimator.
(a)
(in terms of ratios of inner products) For a given θ?, data augmentation does not increase
the bias of the augmented estimator for a single augmentation direction xext if
XLπ⊥dςπ⊥dxext	2 (π⊥dXext)> ςπ⊥dθ?
—―>τrl —-------2
Xext πstd Xext
XL π ⊥dθ?
≤0
(15)
(b)	(in terms of eigenvectors) Data augmentation does not increase bias for any θ? if πs⊥tdXext
is an eigenvector of Σ. However if one augments in the direction ofa mixture of eigenvectors
ofΣ with different eigenvalues, there exists θ? such that augmentation hurts.
(c)	(depending on well-conditioning of Σ) If ：max^) ≤ 2 and Π⊥dθ? is an eigenvector of Σ, then
no augmentations Xext increase bias.
The form in Equation (15) compares ratios of inner products of πs⊥tdXext and πs⊥tdθ? in two spaces: the
one in the numerator is weighted by Σ whereas the denominator is the standard inner product. Thus,
if Σ scales and rotates rather inhomogeneously, then augmenting with Xext may hurt bias. Here again,
if Σ = γI for γ > 0, then the condition must hold.
B.4.1	Proof of Corollary 1 (a)
Note that for a single augmentation point Xext = Xe>xt, the orthogonal decomposition of πs⊥tdθ? into
Col(∏⊥ug) and Col(Π⊥d∏ug) is defined by V = ∏⊥χX1tθ? ∏⊥dXext and W = ∏⊥dθ? - V respectively.
Plugging back into into identity (9) then yields the fos llowing condition for safe augmentations:
2(v-∏⊥dθ*)>∑v-v>∑v ≤ 0	(16)
v>∑v — 2(∏⊥dθ*)>∑v ≤ 0
0 ∏⊥dXext> ∑∏⊥dXext ≤ 2(∏⊥d θ?)> ∑∏⊥d Xext ∙ ”^^2
∏s⊥tdXext>θ?
15
Under review as a conference paper at ICLR 2020
Rearranging the terms yields inequality (15).
Safe augmentation directions for specific choices ofθ? and Σ are illustrated in Figure 2.
B.4.2	Proof of Corollary 1 (b)
Assume that Πs⊥tdxext is an eigevector of Σ with eigenvalue λ>0. We have
x
e>xt Πs⊥td ΣΠs⊥td xext
e>xtΠs⊥tdxext
2(∏⊥dXext)>∑∏⊥dθ?
xLπ⊥dθ?
-λ<0
x
for any θ?. Hence by Corollary 1 (a), the bias doesn’t increase by augmenting with eigenvectors of
Σ for any θ? .
When the single augmentation direction v is not an eigenvector of Σ, by Lemma 1 one can find w such
that w>Σv 6= 0. The proof in Lemma 1 gives an explicit construction for w such that condition (11)
holds and the result then follows directly by Lemma 2.
B.4.3	Proof of Corollary 1 (c)
Suppose ΣΠs⊥tdθ? = λΠs⊥tdθ? for some λmin(Σ) ≤ λ≤ λmax(Σ). Then starting with the expression (15),
x
e>xtΠs⊥tdΣΠs⊥tdxext
>tπ⊥d Xext
2(Π⊥dXext)>ΣΠ⊥dθ?
Xextn⊥dθ?
Xextn⊥~夕^^^&
XextnStdXeXt
-2λ
x
≤ λmax(Σ) -2λ < 0
by applying ：max(ji) ≤ 2. ThUS when Π⊥dθ? is an eigenvector of Σ, there are no augmentations Xext
that increaSe the biaS.
C Variance of minimum norm interpolants
In thiS Section, we conSider the caSe where the noiSe iS non-zero, and compute the varianceS of the two
eStimatorS of intereSt: the Standard eStimator θStd and data augmented eStimator θaug. The following the-
orem provideS a general characterization of the relation between variance of the Standard eStimator and
variance of the augmented eStimator. Theorem 2 iS a corollary of thiS general reSult that we preSent firSt.
Theorem 4 (Variance). The difference in the variances ofa standard and augmented estimator can
be expressed as follows:
1
σ2
-tr
、---------{----------Z J
T1 : Variance increase
(∑∑!td X >，(i+Xext ∑!td X >, )-1χ4 Md),
—一一	J
(17)
{1^^^^^^^^^^≡
T2 : Variance reduction
where Xext d=f ∏⊥dXext, is the component of Xext in the null space of Σstd.
>Λ ∕'	τ-> IlC	/C' .1	. . 1 T 7- / A∖ ， /C / A I PT- PT- ∖ ŋʌ 1 ■	.1	♦	♦	∙	1
Proof. Recall from (3) that the V (θ) = tr(Cov(θ | XStd Xext)Σ). For the minimum norm interpolation
eStimatorS θStd and θaug in Equation 2, we have the following expreSSionS for the varianceS of the
eStimatorS.
V (dstd)=G2trQ!td，)，
V(θaug)=σ2tr (以里夕)，
where ΣStd =XS>tdXStd and Σaug =XS>tdXStd+Xe>xtXext. Note that Since ΣStd,Σaug are unnormalized, the
quantities ∑[d and Σ^g decay with n with the variances V(θstd) ,V(θaug) also decay with n as expected.
Λ .	「才	才
In order to compare V(θstd) and V(θaug), We need to compare ∑!td and ∑aug. Iorder to do this, We
leverage the result from Kovanic (1979) on the pseudo-inverse of the sum of two symmetric matrices:
(Σstd + XextXext) * = ^td - KdXext(I + Xext ^tdX>t)	1 Xext ^td + Xext(Xext) >,
where recall that Xext is the component of Xext in the null space of ∑std. Multiplying each term by
Σ and using linearity of trace, We get the required expression.	□
16
Under review as a conference paper at ICLR 2020
Proof of Theorem 2. Theorem 2 follows directly from the general result above (Theorem 4). Note
that the terms T1 and T2 are traces of PSD matrices and hence non-negative, and capture the magnitude
of variance increase and variance reduction respectively. From Theorem 4, we see that (i) if Xext is
entirely in the span of Σstd making Xext = 0, T1 =0 making V (θaug) ≤ V (θstd) (ii) On the other extreme,
才，
if Xext is entirely m the null space With ∑StdXeχt = 0, T2 =0 and hence V (θaug) ≥ V (θstd).
D	Details for spline staircase
We describe the data distribution, augmentations, and model details for the spline experiment in
Figure 4 and toy scenario in Figure 1. Finally, We shoW that We can construct a simplified family of
spline problems Where the ratio betWeen test errors of the augmented and standard estimators increases
unboundedly as the number of stairs.
D.1 True model
We consider a finite input domain
T ={0,,1,1+,...,s-1,s-1+}	(18)
for some integer s corresponding to the total number of “stairs” in the staircase problem. Let
Tine ⊂T = {0,1,…，s -1}. We define the underlying function f ?: R → R as f ? (t )= [t]. This function
takes a staircase shape, and is linear When restricted to Tline.
Sampling training data Xstd We describe the data distribution in terms of the one-dimensional input
t, and by the one-to-one correspondence With spline basis features x=X(t), this also defines the distri-
bution of spline features x ∈ X. Letw ∈ ∆s define a distribution over Tline Where ∆s is the probability
simplex of dimension s. We define the data distribution With the folloWing generative process for one
sample t. First, sample a point i from Tline according to the categorical distribution described by w,
such that i 〜CategoriCal(w). Second, sample t by perturbing i with probability δ such that
t= i	W.p. 1 -δ
i +	w.p. δ.
The sampled t is in Tline with probability 1 - δ and Tlicne with probability δ, where we choose δ to be small.
Sampling augmented points Xext For each element ti in the training set, we augment with
Ti = [Uu.^arB(ti)], an input chosen uniformly at random from Bg = {[t∕, [tiC +e}. Recall that in our
work, we consider data augmentation where the targets associated with the augmented points are from
the ground truth oracle. Notice that by definition, f ?(&)=f ?(ti) for all i∈ B(ti), and thus we can
set the augmented targets to be yi = y%. This is similar to random data augmentation in images (Yaeger
et al., 1996; Krizhevsky et al., 2012), where inputs are perturbed in a way that preserves the label.
D.2 Spline model
We parameterize the spline predictors as fθ(t) = θ>X(t) where X : R → Rd is the cubic B-spline
feature mapping (Friedman et al., 2001) and the norm offθ(t) can be expressed as θ>Mθ for a matrix
M that penalizes a large second derivative norm where [M]ij = Xi00 (u)Xj00 (u)u. . Notice that the
splines problem is a linear regression problem from Rd to R in the feature domain X(t), allowing
direct application of Theorem 1. As a linear regression problem, we define the finite domain as
X = {X(t): t ∈ T} containing 2s elements in Rd. There is a one-to-one correspondence between t and
X (t), such that X-1 is well-defined. We define the features that correspond to inputs in Tline as Xline =
{x :X-1(x) ∈Tline}. Using this feature mapping, there exists a θ? such that fθ? (t) =f?(t) fort ∈T.
Our hypothesis class is the family of cubic B-splines as defined in (Friedman et al., 2001). Cubic
B-splines are piecewise cubic functions, where the endpoints of each cubic function are called the knots.
In our example, we fix the knots to be [0,,1,...,s- 1,s- 1+], which places a knot on every point in
T. This ensures that the function class contains an interpolating function on allt ∈T, i.e. for some θ?,
fθ*(t)=θ*>x (t)=f ? (t)=btc.
17
Under review as a conference paper at ICLR 2020
2 10
(P4s ' 6n4) UO_」34_」。ωπ-m
On the line
Perturbations

0123456789
Augmentation point (t)
(b) Augment with x = Φ(3.5)
(c) Augment with x = Φ(4.5)
(a)
Figure 5: Visualization of the effect of single augmentation points in the noiseless spline problem
given an initial dataset XStd = {Φ(t): t ∈ {0,1,2,3,4}}. The standard estimator defined by XStd is linear.
(a) Plot of the difference term in Corollary 1 (a), is positive when augmenting a single point causes
higher test error. Augmenting with points on Xline does not affect the bias, but augmenting with any
element of {X (t): t ∈{2.5,3.5,4.5}} hurts the bias of the augmented estimator dramatically. (b), (c)
Augmenting withX(3.5) or X(4.5) hurts the bias by changing the direction of extrapolation.
Global (q3)
∏igX ⑸
Local (q2s)
(a) Nullspace projections onto local vs. global
Figure 6: Nullspace projections onto global direction q3 and local direction q2s in Null(Σ) via Πlg,
representing global and local eigenvectors respectively. The local perturbation ΠlgΦ(1.5) has both
local and global components, creating a high-error component in the global direction.
We solve the minimum norm problem
θstd = argmin{θ>Mθ: Xstdθ = ystd}
θ
(19)
for the standard estimator and the corresponding augmented problem to obtain the augmented estimator.
D.3 Evaluating Corollary 1 (a) for splines
We now illustrate the characterization for the effect of augmentation with different single points in
Theorem 1 (a) on the splines problem. We assume the domain to T as defined in equation 18 with s= 10
and our training data to be Xstd = {X(t) :t ∈ {0,1,2,3,4}}. Let local perturbations be spline features
for t ∈/ Tline where t =t+ is away from some t ∈ {0,1,2,3,4} from the training set. We examine
all possible single augmentation points in Figure 5 (a) and plot the calculated predictive test error
difference as defined in equation (16). Figure 5 shows that augmenting with an additional point from
{X(t): t ∈Tine} does not affect the bias, but adding any perturbation point in {X (t): t ∈{2.5,3.5,4.5}}
where t ∈/ Tline increases the error significantly by changing the direction in which the estimator
extrapolates. Particularly, local augmentations near the boundary of the original dataset hurt the most
while other augmentations do not significantly affect the bias of the augmented estimator.
18
Under review as a conference paper at ICLR 2020
D.3.1 Local and global structure in the spline staircase
In the spline staircase, the local perturbations can be thought ofas fitting high frequency noise in the
function space, where fitting them causes a global change in the function.
To see this, we transform the problem to minimum `2 norm linear interpolation using features
XM (t) = X (t)M -1/2 so that the results from Section 4.1.2 apply directly. Let Σ be the population
covariance of XM for a uniform distribution over the discrete domain consisting of s stairs and
their perturbations (Figure 1). Let Q = [qi]i2=s 1 be the eigenvectors of Σ in decreasing order of their
corresponding eigenvalues. The visualization in Figure 3 shows that qi are wave functions in the
original input space; the “frequency” of the wave increases as i increases.
Suppose the original training set consists of two points, Xstd = [XM (0),XM (1)]>. We study the effect
of augmenting point xext in terms of qi above. First, we find that the first two eigenvectors corresponding
to linear functions satisfy Πs⊥tdq1 =Πs⊥tdq2 =0. Intuitively, this is because the standard estimator is linear.
For ease of visualization, we consider the 2D space in Null(Σ) spanned by Πs⊥tdq3 (global direction,
low frequency) and Πs⊥tdq2s (local direction, high frequency). The matrix Πlg = [Πs⊥tdq3 , Πs⊥tdq2s]>
projects onto this space. Note that the same results hold when projecting onto all Πs⊥tdqi in Null(Σ).
In terms of the simple 3-D example in Section 4.1.1, the global direction corresponds to the costly direc-
tion with large eigenvalue, as changes in global structure heavily affect the predictive test error. Figure 6
plots the projections Πlg θ? and ΠlgXext for different Xext. When θ? has high frequency variations
and is complex, Πlgθ? = (θ? -θstd) is aligned with the local dimension. For xext immediately local to
training points, the projection Πlgxext (orange vector in Figure 6) has both local and global components.
Augmenting these local perturbations introduces error in the global component. For other xext farther
from training points, Πlgxext (blue vector in Figure 6) is almost entirely global and perpendicular to
θ? - θstd, leaving bias unchanged. Thus, augmenting data close to original data cause estimators to
fit local components at the cost of the costly global component which changes overall structure of
the predictor like in Figure 1(middle). The choice of inductive bias in the M-norm being minimized
results in eigenvectors of Σ that correspond to local and global components, dictating this tradeoff.
D.4 Data augmentation can be quite painful for splines
We construct a family of spline problems such that as the number the augmented estimator has much
higher error than the standard estimator. We assume that our predictors are from the full family of
cubic splines.
Sampling distribution
We define a modified domain with continuous intervals T = ∪ts=-01 [t,t+]. Considering only s which
is a multiple of 2, we sample the original data set as described in Section D.1 with the following
probability mass w:
w(t) =
11-γ
t < s/2,t ∈ Tline
t ≥ s∕2,t ∈ Tline.
(20)
for γ ∈ [0, 1). We define a probability distribution PT on T for a random variable T by setting
T = Z+S(Z) where Z 〜CategoriCal(w) and the Z-dependent perturbation S(Z) is defined as
Uniform([z,z+])	w.p. δ
S(Z) ~V	1 父
z,	w.p. 1-δ.
(21)
We obtain the training dataset XStd = {X(tι),...,X(tn)} by sampling t 〜PT.
Augmenting with an interval
Consider a modified augmented estimator for the splines problem, where for each point ti we
augment with the entire interval [btic,btic +] with ∈ [0,1∕2) and the estimator is enforced to output
fθ(χ)= yi = [ti C for all X intheinterval [[切，[川+6].Additionally, suppose that the ratio s/n = O(1)
between the number of stairs s and the number of samples n is constant.
In this simplified setting, we can show that the test error of the augmented estimator grows while the
test error of the standard estimator decays to 0.
19
Under review as a conference paper at ICLR 2020
Theorem 5. Let the setting be defined as above. Then with the choice of δ = Iog(S )-)g(s T) and
Y = c/s for a constant C ∈ [0,1) ,the ratio between test errors is lower bounded as
_ , O 、
R(θaug )
R(θstd)
= Ω(s2)
(22)
1 ∙ 1	. ∙	.	r - . 1	C/ % ∖ . C
which goes to infinity as s→∞. Furthermore, R(θstd) →0 as s →∞.
Proof. We first lower bound the test error of the augmented estimator. Define E1 as the event that only
the lower half of the stairs is sampled, i.e. {t : t < s/2}, which occurs with probability (1 -γ)n. Let
t? = maxi btic be the largest “stair” value seen in the training set. Note that the min-norm augmented
estimator will extrapolate with zero derivative for t ≥ maxi btic. This is because on the interval
[t?,t? + ], the augmented estimator is forced to have zero derivative, and the solution minimizing
the second derivative of the prediction continues with zero derivative for all t ≥ t? . In the event E1 ,
t? ≤ s/2 -1, where t* = s/2 -1 achieves the lowest error in this event. As a result, on the points in
the second half of the staircase, i.e. t = {t ∈T: t> 2 -1}, the augmented estimator incurs large error:
s
R(θaug IEI) ≥ X (t-(S/2-I))2 ∙ s/2
t=s/2
s/2
=Xt2 ∙ Sγ2= 6(s2+2s + 1).
Therefore the expected risk of the augmented estimator is bounded by
R(θaug) ≥R(θaug ∣Eι)P(E1) = γ(s2 + 2s + 1)(1-γ)n
≥ 1Y (1-γn)(s2 +2s + 1)
6
c c2
=Ω(------(s2 + 2s+1)) =Ω(s)
s
where in the first line, we note that the error on each interval is the same and the probability of each
intervalis (1-δ)s/2 +eI ∙ sY2 =力.
Next we upper bound the test error of the standard estimator. Define E2 tobe the event where all points
are sampled from Tline, which occurs with probability (1 - δ)n. In this case, the standard estimator
is linear and fits the points on Tline with zero error, while incurring error for all points not in Tline. Note
that the probability density of sampling a point not in Tine is either ∣ ∙ I-Y or ∣ ∙力,which we upper
bound as ∣ ∙方.
s-1
R(θstd | E2 ) = X-而 u u2du =------7XO(se3)
t=1 s/2 0	s/2
=O(δ)
Therefore for event E2, the expected error is bounded as
,ʌ , . , .
R(^std ∣E2)P(E2) = O(δ)(1-δ)n
= O(δ)e-δn
s7-1
=O(δ ∙)
= O(δ) = O(log(s7)-log(s7-1) ) = O(1/S)
s
since log(s7) -log(s7 - 1) ≤ 1 fors ≥ 2. For the complementary event E2c, note that cubic spline predic-
tors can grow only as O(t3), with error O(t6). Therefore the expected error for case E2c is bounded as
R(θstd IEc)P(Ec) ≤ O(t6)(1-e-δn)
1
=O(t6)O( s7 ) = O(1/s)
20
Under review as a conference paper at ICLR 2020
Putting the parts together yields
,ʌ , ʌ , ʌ 一 ,
R(θstd) = R(θstd | E2)P(E2)+R(θstd | Ec)P(Ec)
≤ O(1∕s)+O(1∕s) = O(1∕s).
ThUS overall, R(θstd) = O(1∕s) and combining the bounds yields the result.	□
E Effect of sample size on error increase via augmentation
In this section, we discuss what our analysis of the effect of augmentation on the error of mininum inter-
polants says about the trends with respect to varying sample sizes of the standard training set (Xstd,ystd).
Trends in variance. We refer the reader to the precise expression for the difference in variance
provided in Theorem 4. Let us consider a case where data augmentation causes an increase in variance.
For simplicity, Xext ⊥ Xstd, across all sample sizes in the small sample regime. For a fixed Xext, we
see that the magnitude of variance increase is governed by Πs⊥tdXext which decreases as we get more
standard training points.
Trends in bias. Recall the expressions for B(θstd) and B(θaug) from Equation 4. Using the same
notation as that of Theorem 5, we have the following expression for the amount of bias increase. Let
v = Πs⊥tdΠaugθ? andv=Πa⊥ugθ?. We have,
_ , O 、	_ , O	-Γ —	~Γ —
B(°aUg)-B(°Std) = -V ςv-2w ςv,	(23)
where w>Σv is a negative quantity when data augmentation causes an increase in bias. Recall that
we are in the small sample regime where Σstd is not invertible for a range of sample sizes. Suppose
we augment with Xext such that Xext ∈ Null(Σstd) in this regime of interest. In this case, we can write
v = Πs⊥tdΠa⊥ugθ? = u>θ?. For a fixed problem setting θ?, we see that v is fixed. Let us now look at
w=Πa⊥ugθ?. Recall that Πa⊥ug is the projection matrix onto Σstd+Xe>xtXext. Fora fixed Xext, as the null
space of Σstd shrinks with more training points, w decreases. Note that the magnitude of increase in
bias decreases as w decreases (for a fixed v). This suggests that the effect of augmentation on bias
should decrease as we get more samples, in the small data regime.
Our heuristic calculations in some settings of Xext in minimum norm interpolation in linear regression
suggest that the overall increase in test error should decrease as we increase the sample size of
the original training set. Empirically, we find similar trends when performing adversarial data
augmentations with varying training set sizes.
F	X-regularization
F.1 X-regularization for linear regression
In this section, we prove Theorem 3, which we reproduce here.
Theorem 3. Assume the noiseless linear model y= x> θ?. Let θint-std be an arbitrary interpolant of
the standard data, i.e. Xstdθint-std = ystd. Let θx-aug be the X-regularized interpolant (6). Then
R(θx-aug ) ≤ RGnt-Std).
Proof. Let {ui} be an orthonormal basis of the kernel Null(Σstd + Xe>xtXext) and {vi} be an
orthonormal basis for Null(Σstd) \ span({ui}). Let U and V be the linear operators defined by
Uw = PiUiwi and Vw = Piviwi ,respectively, noting that U > V = 0. Defining Π⊥d := (I - ∑]d∑std)
tobe the projection onto the null space of Xstd, we see that there are unique vectors ρ,α such that
θ? = (I-Π⊥d)θ? + Uρ+Vα.	(24a)
As θint-std interpolates the standard data, we also have
θint-std = (I-Πs⊥td)θ?+ Uw+Vz,	(24b)
21
Under review as a conference paper at ICLR 2020
as XstdUw=XstdV z=0, and finally,
θχ-aug = (I — ∏⊥d)θ? + Uρ + Vλ
where we note the common ρ between Eqs. (24a) and (24c).
(24c)
Using the representations (24) we may provide an alternative formulation for the augmented
estimator (6), using this to prove the theorem. Indeed, writing θint-std -θx-aug = U(w-ρ)+V(z-λ),
we immediately have that the estimator has the form (24c), with the choice
λ = argmin{(U (W -ρ) + V (Z-λ))>Σ(U (W — ρ)+V (Z — λ))}.
λ
The optimality conditions for this quadratic imply that
V>ΣV(λ-Z)=V>ΣU(W-ρ).	(25)
Now, recall that the predictive test error of a vector θ is R(θ) = (θ - θ*)>Σ(θ -θ?) = ∣∣θ -θ*k∑,using
Mahalanobis norm notation. In particular, a few quadratic expansions yield
R(θint-std) -R(θx-aug)
= ∣U(W-ρ)+V(Z-α)∣2Σ-∣V(λ-α)∣2Σ
= ∣U(W-ρ)+VZ∣2Σ+∣Vα∣2Σ-2(U(W-ρ)+VZ)>ΣVα-∣Vλ∣2Σ-∣Vα∣2Σ+2(Vλ)>ΣVα
(=i) ∣U(W-ρ)+V Z∣2Σ-2(V λ)>ΣV α-∣V λ∣2Σ+2(V λ)>V α
= ∣U(W-ρ)+VZ∣2Σ -∣Vλ∣2Σ,	(26)
where step (i) used that (U(W-ρ))>ΣV= (V(λ-Z))>ΣV from the optimality conditions (25).
Finally, we consider the rightmost term in equality (26). Again using the optimality conditions (25),
we have
∣Vλk∑ = λ>V>£1/2£1/2(U(W-ρ) + Vz) ≤ ∣Vλk∑kU(W-ρ) + Vzk∑
by Cauchy-Schwarz. Revisiting equality (26), we obtain
RGnt-Std)-R(©x-aug) = IlU(W -P)+VzkΣ - I b
∣V λ∣Σ
≥∣U (W - ρ)+Vz∣2 -kVλk∑kU(W - p+Vzk∑ =0,
ς	∣∣Vλ∣∑
as desired.	□
F.2 X-regularization for data augmentations that promote robustness
The main motivation of our work is to provide a method to perform data augmentation such that the
benefits such as robustness are preserved, without seeing the undesirable drop in standard accuracy.
The general X-regularized estimator (Equation 7) holds for any form of augmentation. We now write
out the exact loss functions when we apply X-regularization to two forms of adversarial training:
Projected Gradient Adversarial Training of (Madry et al., 2018) and TRADES (Zhang et al., 2019).
Throughout, we assume the same notation as that used in the definition of the general estimator.
XStd,ystd denote the standard training set and we have access to m unlabeled points Xi,i = 1,...m.
F.2.1 Projected Gradient Adversarial Training
Note that the unlabeled data can be perturbed to obtain more extra data, because of the special structure
of the extra points added: every training point generates a perturbed extra training point. This leads
to the following natural generalization, where we obtain adversarial perturbations from the unlabeled
data, and label them with the pseudo-label generated from the standard trained model. As the distance
measure, we use the same loss that is used for classification. Put together, we have
θx-aug ：=argminj N T	X	'(fθ (x),y)+β'(fθ (XadV ),y)
(x,y)∈[Xstd ,ystd]
m
+λm-1X'(fθ (Xi),f^std (Xi))+β'(fθ (XadVi),f^std (Xi)) ,	(27)
i=1
22
Under review as a conference paper at ICLR 2020
In practice, Xadv is found by performing a few steps of projected gradient method on '(fθ (χ),y), and
similarly Xadv by performing a few steps of projected gradient method on '(fθ (X) ,f^d(X)).
F.2.2 TRADES
TRADES was a modification of the projected gradient adversarial training algorithm of (Madry et al.,
2018). Here, the loss function is modified in the following way, instead of operating on the label
directly, the robustness term operates on the normalized logits, which can be thought ofas probabilities
of different labels. Using their modified loss and applying X-regularization leads to the following.
θx-aug ：=argmin|NT	X	'(fθ(x),y)+β KL(pθ(Xadv)∣∣Pθ(x))
θ	(x,y)∈[Xstd,ystd]
m
+λm-1X'(fθ(Xi),f^std(Xiy)+β KL(pθ(Xadvi)I∣p^std(Xi)) },	(28)
i=1
where KL(pθ(X),pθ(Xadv) is the KL divergence between the probability over class labels assigned
to X and Xadv.
G Experimental Details
G.1 Spline simulations
For spline simulations in Figure 1 and Figure 4, we implement the optimization of the standard and
robust objectives using the basis described in (Friedman et al., 2001). The penalty matrix M computes
second-order finite differences of the parameters θ. We solve the min-norm objective directly using
CVXPY (Diamond & Boyd, 2016). Each point in Figure 4(a) represents the average test error over 25
trials of randomly sampled training datasets between 22 and 1000 samples. Shaded regions represent
1 standard deviation.
G.2 X-regularization as robust self-training
In the adversarial training setting where augmentations are generated through transformations of
existing data, it is natural to instantiate X-regularization as robust self-training, as discussed in
Section F. We evaluate the performance of X-regularization applied to '∞ adversarial perturbations,
adversarial rotations, and random rotations.
G.2. 1 Subsampling Cifar- 1 0
We augment with '∞ adversarial perturbations of various sizes. In each epoch, We findthe augmented ex-
amples via Projected Gradient Ascent on the multiclass logistic loss (cross-entropy loss) of the incorrect
class. Training the augmented estimator in this setup uses essentially the adversarial training procedure
of (Madry et al., 2018), with equal weight on both the ”clean” and adversarial examples during training.
We instantiate the general X-regularization estimator as robust self-training defined in (27). We
compare the test error of the augmented estimator with an estimator trained using RST. We apply RST
to adversarial training algorithms in Cifar- 1 0 using 500k unlabeled examples sourced from Tiny
Images, as in (Carmon et al., 2019).
We use Wide ResNet 40-2 models (Zagoruyko & Komodakis, 2016) while varying the number of
samples in CIFAR- 1 0. We sub-sample CIFAR-10 by factors of {1,2,5,8,10,20,40} in Figure 4(a) and
{1,2,5,8,10} in Figure 4(b). For sub-sample factors 1 to 20, we report results averaged from 2 trials
for each model. For sub-sample factors greater than 20, we average over 5 trials. All models are trained
for 200 epochs with respect to the size of the labeled training dataset and all achieve almost 100%
standard and robust training accuracy.
We evaluate the robustness of models to the strong PGD-attack with 40 steps and 5 restarts. In
Figure 4(b), we used a simple heuristic to set the regularization strength λ in Equation (27) to be
λ = min(0.9,γ)∕(1 - min(0.9,γ)) where Y ∈ [0,1] is the fraction of the original CIFAR-10 dataset
23
Under review as a conference paper at ICLR 2020
(％)pgJO七 山 qo⅛H6w,XHOXJ 山 qo⅛∣
(a) Robust error, Cifar- 1 0
Number of labeled samples
(b) Relative standard error, Cifar- 1 0
(％)(ss ⅛D≤bω ①>=-①ɑ
Figure 7: (a) Difference in robust test error between our X-regularized adversarial training model
and the vanilla adversarial training (AT) model for Cifar- 1 0. X-regularization (instantiated as RST)
keeps the robust accuracy within 2% of the AT model for small subsamples and even improves over
the AT model for larger subsamples of CIFAR-10. (b) Relative difference in standard error between
augmented estimators (our X-regularized model and the AT model) and the standard estimator on
Cifar- 1 0. We achieve up to 20% better standard error than the standard model for small subsamples.
Standard AT RST+AT
Standard Test Acc	94.63%	94.15%	95.47%
Robust Test Acc (= 1/255)	-	85.59%	87.20%
Table 2:	Accuracies for the standard, vanilla adversarial training (AT), and AT with X-regularization
(RST) for = 1/255 on the full CIFAR- 1 0 dataset. Accuracies are averaged over two trials. The robust
test accuracy of the standard model is near 0%.
Standard AT X-reg
Standard Test Acc	94.63%	92.69% 94.86%
Robust Test Acc ( = 2/255)	-	77.87%	80.46%
Table 3:	Accuracies for the standard, vanilla adversarial training (AT), and AT with X-regularization
(X-reg) for = 2/255 on the full CIFAR- 1 0 dataset. Accuracies are averaged over two trials. The
robust test accuracy of the standard model is near 0%.
sampled. Intuitively, we give more weight to the unlabeled data when the original dataset is larger,
meaning that the standard estimator produces more accurate pseudo-labels. We fix β=5.
Figure 7 shows that the robust accuracy of the RST model stays within 2% of the robust model (trained
using PGD adversarial training) for all subsamples, and even improves upon the robust model on the
full dataset (Tables 2,3).
Note that we cannot directly compare the empirical performance of RST+adversarial training on
Cifar- 1 0 with other methods to obtain robust models that are modifications of vanilla adversarial
training. We use a smaller model due to computational constraints enforced by adversarial training.
Since the model is small, we could only fit adversarially augmented examples with small = 2/255,
while existing baselines use = 8/255. Note that even for = 2/255, adversarial data augmentation
leads to an increase in error. We show that RST can fix this. While ensuring models are robust is an
important goal in itself, in this work, we view adversarial training through the lens of covariate-shifted
data augmentation and study how to use augmented data without increasing test error. We show
that X-regularization based methods like RST preserve the other benefits of some kinds of data
augmentation like increased robustness to adversarial examples.
G.2.2 '∞ ADVERSARIAL PERTURBATIONS
In Table 1, we evaluate X-regularization as robust self-training applied to PGD and TRADES
adversarial training. The models are trained on the full Cifar- 1 0 dataset, and models which use
24
Under review as a conference paper at ICLR 2020
unlabeled data (self-training and X-reg) also use 500k unlabeled examples from Tiny Images. All
models except the Interpolated AT and Neural Architecture Search model use the same base model
WideResNet 28-10. To evaluate robust accuracy, we use a strong PGD-attack with 40 steps and 5
restarts against '∞ perturbations of size 8/255. For X-regularization models, We set λ = 9 and β = 5 in
Equation (27) and Equation (28), following the heuristic λ = min(0.9,γ)∕(1-min(0.9,γ)) for Y =1.
We train for 200 epochs such that 100% training standard accuracy is attained.
G.2.3 Adversarial and random rotation/translations
In Table 1 (right), we instantiate X-regularization as robust self-training for adversarial and random
rotation/translations, using these transformations as xadv in Equation (27). The attack model is a grid of
rotations of up to 30 degrees and translations of up to 〜10% of the image size. The grid consists of31
linearly spaced rotations and 5 linearly spaced translations in both dimensions. The Worst-of-10 model
samples 10 uniformly random transformations of each input and augment with the one where the model
performs the worst (causes an incorrect prediction, ifit exists). The Random model samples 1 random
transformation as the augmented input. All models (besides cited models) use the WRN-40-2 architec-
ture and are trained for 200 epochs. We use the same hyperparameters λ,β as in G.2.2 for Equation (27).
H Comparison to s tandard self-training algorithms
The main objective of X-regularization is to allow to perform data augmentation without sacrificing
standard accuracy. This is done by smoothing an augmented estimator to provide labels close to a
standard non-augmented estimator on the unlabeled data. This is closely related to but different two
broad kinds of semi-supervised learning.
1.	Self-training (pseudo-labeling): Classical self-training does not deal with data augmentation
or robustness. We view X-regularization as a a generalization of self-training in the context
of data augmentations. Here the pseudolabels are generated by a standard non-augmented
estimator that is not trained on the labeled augmented points. In contrast, standard
self-training would just use all labeled data to generate pseudo-labels. However, since some
augmentations cause a drop in standard accuracy, and hence this would generate worse
pseudo-labels than the X-regularized version.
2.	Consistency based regularization: Another popular semi-supervised learning strategy is
based on enforcing consistency in a model’s predictions across various perturbations of
the unlabeled data (Miyato et al., 2018; Xie et al., 2019; Sajjadi et al., 2016; Laine & Aila,
2017)). X-regularization is similar in spirit, but has an additional crucial component. We
generate pseudo-labels first by performing standard training, and rather than enforcing simply
consistency across perturbations, we enforce that the unlabeled data and perturbations are
matched with the pseudo-labels generated.
25