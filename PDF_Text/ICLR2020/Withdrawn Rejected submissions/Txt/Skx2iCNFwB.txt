Under review as a conference paper at ICLR 2020
Stabilizing	Neural ODE Networks with
Stochasticity
Anonymous authors
Paper under double-blind review
Ab stract
Neural Ordinary Differential Equation (Neural ODE) has been proposed as a
continuous approximation to the ResNet architecture. Some commonly used
regularization mechanisms in discrete neural networks (e.g. dropout, Gaussian
noise) are missing in current Neural ODE networks. In this paper, we propose a
new continuous neural network framework called Neural Stochastic Differential
Equation (Neural SDE) network, which naturally incorporates various commonly
used regularization mechanisms based on random noise injection. Our framework
can model various types of noise injection frequently used in discrete networks
for regularization purpose, such as dropout and additive/multiplicative noise in
each block. We provide theoretical analysis explaining the improved robustness of
Neural SDE models against input perturbations. Furthermore, we demonstrate that
the Neural SDE network can achieve better generalization than the Neural ODE
and is more resistant to adversarial and non-adversarial input perturbations.
1 Introduction
Residual neural networks (ResNet) (He et al., 2016) are composed of multiple residual blocks
transforming the hidden states according to:
hn+1 = hn + f(hn; wn),
(1)
where hn is the input to the n-th layer and f(hn; wn) is a non-linear function parameterized by wn.
Recently, a continuous approximation to the ResNet architecture has been proposed (Chen et al.,
2018), where the evolution of the hidden state ht can be described as a dynamic system obeying the
equation:
ht = hs +	f(hτ, τ; w) dτ,
s
(2)
where f(hτ, τ; w) is the continuous form of the nonlinear function f(hn; wn); hs and ht are hidden
states at two different time s 6= t. A standard ODE solver can be used to solve all the hidden states
and final states (output from the neural network), starting from an initial state (input to the neural
network). The continuous neural network described in (2) exhibits several advantages over its discrete
counterpart described in (1), in terms of parameter efficiency, memory efficiency, explicit control of
the numerical error of final output, etc.
One missing component in the current Neural ODE network is the various regularization mech-
anisms commonly employed in discrete neural networks. These regularization techniques have
been demonstrated to be crucial in reducing generalization errors, and in improving the robustness
of neural networks to adversarial attacks. Many of these regularization techniques are based on
stochastic noise injection. For instance, dropout (Srivastava et al., 2014) is widely adopted to prevent
overfitting; injecting Gaussian random noise during the forward propagation is effective in improving
generalization (Bishop, 1995; An, 1996) as well as robustness to adversarial attacks (Liu et al., 2018;
Lecuyer et al., 2018). However, these regularization methods in discrete neural networks are not
directly applicable to Neural ODE network, because Neural ODE network is a deterministic system.
Our work attempts to incorporate the above-mentioned stochastic noise injection based regularization
mechanisms to the current Neural ODE network, to improve the generalization ability and the
robustness of the network. We propose a new continuous neural network framework called Neural
1
Under review as a conference paper at ICLR 2020
Stochastic Differential Equation (Neural SDE) network, which models stochastic noise injection
by stochastic differential equations (SDE). In this new framework, we can employ existing techniques
from the stability theory of SDE to study the robustness of neural networks. Our results provide
theoretical insights to understanding why introducing stochasticity during neural network training
and testing leads to improved robustness against adversarial attacks. Furthermore, we demonstrate
that, by incorporating the noise injection regularization mechanism to the continuous neural network,
we can reduce overfitting and achieve lower generalization error. For instance, on the CIFAR-10
dataset, we observe that the new Neural SDE can improve the test accuracy of the Neural ODE from
81.63% to 84.55%, with other factors unchanged. Our contributions can be summarized as follows:
•	We propose a new Stochastic Differential Equation (SDE) framework to incorporate randomness
in continuous neural networks. The proposed random noise injection can be used as a drop-in
component in any continuous neural networks. Our Neural SDE framework can model various
types of noises widely used for regularization purpose in discrete networks, such as dropout
(Bernoulli type) and Gaussian noise.
•	We carry out a theoretical analysis of the stability conditions of the Neural SDE network, to prove
that the randomness introduced in the Neural SDE network can stabilize the dynamical system,
which helps improve the robustness and generalization ability of the neural network.
•	We verify by numerical experiments that stochastic noise injection in the SDE network can
successfully regularize the continuous neural network models, and the proposed Neural SDE
network achieves better robustness and improves generalization performance.
Notations: Throughout this paper, we use h ∈ Rn to denote the hidden states in a neural network,
where h0 = x is the input (also called initial condition) and y is the label. The residual block with
parameters w ∈ Rd can be written as a nonlinear transform f(hτ , τ ; w). We assume the integration
is always taken from 0 to T. Bt ∈ Rm is m-dimensional Brownian motion. G(hτ, τ; v) ∈ Rn×m is
the diffusion matrix parameterized by v. Unless stated explicitly, We use ∣∣∙∣∣ to represent '2-norm
for vector and Frobenius norm for matrix.
2	Related work
Our Work is inspired by the success of the recent Neural ODE netWork, and We seek to improve
the generalization and robustness of Neural ODE, by adding regularization mechanisms crucial
to the success of discrete netWorks. Regularization mechanisms such as dropout cannot be easily
incorporated in the Neural ODE due to its deterministic nature.
Neural ODE The basic idea of Neural ODE is discussed in the previous section, here We briefly
revieW relevant literature. The idea of formulating ResNet as a dynamic system Was discussed in (E,
2017). A frameWork Was proposed to link existing deep architectures With discretized numerical
ODE solvers (Lu et al., 2018), and Was shoWn to be parameter efficient. These netWorks adopt
layer-wise architecture - each layer is parameterized by different independent weights. The Neural
ODE model (Chen et al., 2018) computes hidden states in a different Way: it directly models the
dynamics of hidden states by an ODE solver, with the dynamics parameterized by a shared model.
A memory efficient approach to compute the gradients by adjoint methods was developed, making
it possible to train large, multi-scale generative networks (Ardizzone et al., 2018; Grathwohl et al.,
2018). Our work can be regarded as an extension of this framework, with the purpose of incorporating
a variety of noise-injection based regularization mechanisms. Stochastic differential equation in the
context of neural network has been studied before, focusing either on understanding how dropout
shapes the loss landscape (Sun et al., 2018), or on using stochastic differential equation as a universal
function approximation tool to learn the solution of high dimensional PDEs (Raissi, 2018). Instead,
our work tries to explain why adding random noise boosts the stability of deep neural networks, and
demonstrates the improved generalization and robustness.
Noisy Neural Networks Adding random noise to different layers is a technique commonly em-
ployed in training neural networks. Dropout (Srivastava et al., 2014) randomly disables some neurons
to avoid overfitting, which can be viewed as multiplying hidden states with Bernoulli random vari-
ables. Stochastic depth neural network (Huang et al., 2016) randomly drops some residual blocks
of residual neural network during training time. Another successful regularization for ResNet is
Shake-Shake regularization (Gastaldi, 2017), which sets a binary random variable to randomly switch
between two residual blocks during training. More recently, dropblock (Ghiasi et al., 2018) was
designed specifically for convolutional layers: unlike dropout, it drops some continuous regions
rather than sparse points to hidden states. All of the above regularization techniques are proposed
2
Under review as a conference paper at ICLR 2020
to improve generalization performance. One common characteristic of them is that they fix the
network during testing time. There is another line of research that focuses on improving robustness to
perturbations/adversarial attacks by noise injection. Among them, random self-ensemble (Liu et al.,
2018; Lecuyer et al., 2018) adds Gaussian noise to hidden states during both training and testing
time. In training time, it works as a regularizer to prevent overfitting; in testing time, the random
noise is also helpful, which will be explained in this paper. Very recently, there are several concurrent
works on Neural SDE (Jia & Benson, 2019; Tzen & Raginsky, 2019; Wang et al., 2019). However
compared with Jia & Benson (2019) and Tzen & Raginsky (2019), our paper addresses a very
different problem, i.e. the robustness of deep random neural network. And while Wang et al. (2019)
deals with adversarial robustness (which is also in our scope, but we extend it to non-adversarial
robustness), their method is still based on adversarial training. In contrast, we are interested in the
robustness rooted in the randomness of training and testing.
3	Neural Stochastic Differential Equation
In this section, we first introduce our proposed Neural
SDE to improve the robustness of Neural ODE. Informally
speaking, Neural SDE can be viewed as using random-
ness as a drop-in augmentation for Neural ODE, and it
can include some widely used randomization layers such
as dropout and Gaussian noise layer (Liu et al., 2018).
However, solving Neural SDE is non-trivial, we derive the
gradients of loss over model weights. Finally we theoret-
ically analyze the stability conditions of Neural SDE.
Before delving into the multi-dimensional SDE, let’s first
look at a 1-d toy example to see how SDE can solve the
instability issue of ODE. Suppose we have a simple SDE,
dxt = xt dt + σxt dBt with Bt be the standard Brownian
motion. We provide a numerical simulation in Figure 1
for xt with different σ.
When we set σ = 0, SDE becomes ODE dxt = xt dt
and xt = c0et where c0 is an integration constant. If
c0 6= 0 we can see that xt → ±∞. Furthermore, a
small perturbation in xt will be amplified through t. This
clearly shows instability of ODE. On the other hand, if
We instead make σ > √2 (the system is SDE), We have
Xt = co exp ((1 — σ2∕2)t + σBt) a→ 0.
Figure 1: Toy example. By compar-
ing the simulations under σ = 0 and
σ = 2.8, We see adding noise to the sys-
tem can be an effective Way to control
xt. Average over multiple runs is used to
cancel out the volatility during the early
stage. It is noteWorthy that here We em-
ploy the multiplicative noise, Where the
deviation term scales proportional to xt .
hτ = h0 + I /(ħt, t; w)dt + I G(ht, t; v)dWt
o	o
Xo	ho	hr
Figure 2: Our model architecture (more details can be found in appendix). The initial value of SDE
is the output of a convolutional layer, and the value at time T is passed to a linear classifier after
average pooling.
The toy example in Figure 1 reveals that the behavior of solution paths can change significantly after
adding a stochastic term. This example is inspiring because We can control the impact of perturbations
on the output by adding a stochastic term to neural netWorks.
Figure 2 shoWs a sample Neural SDE model architecture, and it is the one used in the experiment. It
consists of three parts, the first part is a single convolution block, folloWed by a Neural SDE netWork
(We Will explain the detail of Neural SDE in Section 3.1) and lastly the linear classifier. We put
most of the trainable parameters into the second part (Neural SDE), Whereas the first/third parts are
3
Under review as a conference paper at ICLR 2020
mainly for increasing/reducing the dimension as desired. Recall that both Neural ODE and SDE are
dimension preserving.
3.1	Modeling randomness in neural networks
In the Neural ODE system (2), a slightly perturbed input state will be amplified in deep layers (as
shown in Figure 1) which makes the system unstable to input perturbation and prone to overfitting.
Randomness is an important component in discrete networks (e.g., dropout for regularization) to tackle
this issue, however to our knowledge, there is no existing work concerning adding randomness in the
continuous neural networks for regularization purpose. And it is non-trivial to encode randomness in
continuous neural networks, such as Neural ODE, as we need to consider how to add randomness so
that to guarantee the robustness, and how to solve the continuous system efficiently. To solve these
challenges, motivated by (Lu et al., 2018; Sun et al., 2018), we propose to add a single diffusion
term into Neural ODE as:
dht = f(ht,t;w)dt+ G(ht, t; v) dBt,
(3)
where Bt is the standard BroWnian motion (0ksendal, 2003), which is a continuous time stochastic
process such that Bt+s - Bs follows Gaussian with mean 0 and variance t; G(ht , t; v) is a transfor-
mation parameterized by v. This formula is quite general, and can include many existing randomness
injection models with residual connections under different forms of G(ht, t; v). As examples, we
briefly list some of them below.
Gaussian noise injection: Consider a simple example in (25) when G(ht, t; v) is a diagonal
matrix, and we can model both additive and multiplicative noise as
additive: dht = f (ht , t; w) dt + Σ(t) dBt
multiplicative: dht = f (ht , t; w) dt + Σ(ht , t) dBt ,
(4)
where Σ(t) is a diagonal matrix and its diagonal elements control the variance of the noise added to
hidden states. This can be viewed as a continuous approximation of noise injection techniques in
discrete neural network. For example, the discrete version of the additive noise can be written as
hn+1 =	hn	+	f (hn；	Wn)	+ ∑nZn,	With	∑n	=	(Jnl,	Zn	i%	N(0,	1),	(5)
which injects Gaussian noise after each residual block. It has been shown that injecting small Gaussian
noise can be viewed as a regularization in neural networks (Bishop, 1995; An, 1996). Furthermore,
(Liu et al., 2018; Lecuyer et al., 2018) recently showed that adding a slightly larger noise in one
or all residual blocks can improve the adversarial robustness of neural networks. We will provide
the stability analysis of (25) in Section 3.3, which provides a theoretical explanation towards the
robustness of Neural SDE.
Dropout: Our framework can also model the dropout layer which randomly disables some neurons
in the residual blocks. Let us see how to unify dropout under our Neural SDE framework. First we
notice that in the discrete case
hn+1 =	hn	+	f (hn；	Wn)	G) Yn	= h + f (hn； Wn) + f (hn； Wn)	G)	( Yn	—	I),	(6)
pp
where Yn i% B(1,p) and G indicates the Hadamard product. Note that We divide Yn by P in (6) to
maintain the same expectation. Furthermore, we have
Yn — I
p
S ∙ rɪi( Yn - I)≈ J
Uz,…N"	⑺
The boxed part above is approximated by standard normal distribution (by matching the first and
second order moment). The final SDE with dropout can be obtained by combining (6) with (7)
dht = f(ht, t; W) dt + ^-pf- f(ht, t； W) G dBt∙
(8)
Others: Lu et al. (2018) includes some other stochastic layers that can be formulated under Neural
SDE framework, including shake-shake regularization (Gastaldi, 2017) and stochastic depth (Huang
et al., 2016). Both of them are used as regularization techniques that work very similar to dropout.
4
Under review as a conference paper at ICLR 2020
10-2
101
Iol
O O 一
Ilo
(.ɔ①S)①luuunH
102	103
Network depth t
JojJe uo-sz'sBɔsɪɑ
102	103	104
Network depth t
Figure 3: Left: we compare the propagation time between Neural ODE, ODE with adjoint, and
SDE. We can see that the running time increases proportionally with network depth and there is
no significant overhead in neural SDE. Right: We compute the error of SDE solver caused by
discretization in EUler schemes, measured by the relative error in ht, i.e. ε = khTh-hTk and
hτ is the ground-truth (computed with a very fine grid), hT is computed with coarse grid ∆t ∈
[1.0 X 10-4,1.0 X 10-1] (note that network depth t = T/∆T).
3.2	Propagation though SDE Solvers
The overall implementation of training neural network containing SDE solver is similar to Neural
ODE (Chen et al., 2018) and it is stated in Algorithm 1. We can see from the algorithm that for forward
propagation we apply some standard SDE solvers such as Euler-Maruyama (Kloeden & Platen, 2013),
Milstein (Milshtein, 1975) or higher order Runge-Kutta method, but for backward propagation we
can simply rely on the automatic gradient. In practice, we find that the most straightforward autograd
Algorithm 1 Forward and backward propagation of Neural SDE
1:	procedure Training-process	. Do forward & backward propagation
2:	Given initial state h0, integral range [0, T].
3:	hτ = SDE-Solvef(ht,t; w), G(ht,t; v), [0,T]).	. Call a black-box SDE solver
4:	Calculate loss L = '(hτ).
5:	Calculate gradient ∂∂W and ∂V With autograd.
6:	Update network parameters w and v .
method works efficiently in our experiments, see Figure 3(left). Furthermore, we find that the
discretization error is small enough to perform classification task even for larger grid size in SDE
solver (Line 3 in Algorithm 1) as shown in Figure 3(right). More details can be found in Appendix C.
Note that instead of using automatic gradient computation, we can also calculates the gradients by
adjoint method, which first transforms the SDE system in (25) into a deterministic PDE through
Feynman-Kac formula (Cattiaux & Mesnager, 2002). Due to the space limit we defer it to appendix E.
Since a simple implementation with auto-differentiation is already achieving competitive run time
and approximation with Neural ODE as shown in Figure 3, we will use that for the experiments
throughout this paper.
3.3	Robustness of Neural SDE
in this section, we theoretically analyze the stability of Neural SDE, showing that the randomness term
can indeed improve the robustness of the model against small input perturbation. This also explains
why noise injection can improve the robustness in discrete networks, which has been observed in
literature (Liu et al., 2018; Lecuyer et al., 2018). First we need to show the existence and uniqueness
of solution to (25), we pose following assumptions on drift f and diffusion G.
Assumption 1.f and G are at most linear, i.e. kf (x, t)k + kG(x, t)k ≤ c1(1 + kxk) for c1 > 0,
∀x ∈ Rn and t ∈ R+ .
Assumption 2.f and G are c2-Lipschitz: kf (x, t) -f(y, t)k + kG(x, t) - G(y, t)k ≤ c2 kx - yk
for c2 > 0, ∀x, y ∈ Rn and t ∈ R+.
5
Under review as a conference paper at ICLR 2020
Based on the above assumptions, We can show that the SDE (25) has a unique solution (0ksendal,
2003). We remark that assumption on f is quite natural and is also enforced on the original Neural
ODE model (Chen et al., 2018); as to diffusion matrix G, we have seen that for dropout, Gaussian
noise injection and other random models, both assumptions are automatically satisfied as long as f
possesses the same regularities.
We analyze the dynamics of perturbation. Our analysis applies not only to the Neural SDE model
but also to Neural ODE model, by setting the diffusion term G to zero. First of all, we consider
initializing our Neural SDE (25) at two slightly different values h0 and he0 = h0 + ε0 , where ε0 is
the perturbation for h0 with kε0k ≤ δ. So, under the new perturbed initialization he0, the hidden state
at time t follows the same SDE in (25),
dhte = f(hte, t; w) dt + G(hte, t; v) dB0t,	with he0 = h0 + ε0,	(9)
where B0t is Brownian motions for the SDE associated with initialization he0 . Then it is natural to
analyze how the perturbation εt = hte - ht evolves in the long run. Subtracting (25) from (9)
dεt = f (hte, t; w) - f (ht, t; w) dt + G(hte,t;v) - G(ht, t; v) dBt	(10)
= f∆(εt, t; w) dt + G∆(εt, t; v) dBt.
Here we made an implicit assumption that the Brownian motions Bt and B0t have the same sample
path for both initialization h0 and he0, i.e. Bt = B0t w.p.1. In other words, we focus on the difference
of two random processes ht and hte driven by the same underlying Brownian motion. So it is valid to
subtract the diffusion terms.
An important property of (10) is that it admits a trivial solution εt ≡ 0, ∀t ∈ R+ and w ∈ Rd . We
show that both the drift (f) and diffusion (G) are zero under this solution:
f∆(0, t; w) = f(ht + 0, t; w) - f(ht, t; w) = 0,
G∆(0, t; v) = G(ht + 0, t; w) - G(ht, t; w) = 0.
(11)
The implication of zero solution is clear: for a neural network, if we do not perturb the input data,
then the output will never change. However, the solution εt = 0 can be highly unstable, in the sense
that for an arbitrarily small perturbation ε0 6= 0 at initialization, the change of output εT can be
arbitrarily bad. On the other hand, as shown below, by choosing the diffusion term G properly, we
can always control εt within a small range.
In general, we cannot get the closed form solution to a multidimensional SDE but we can still
analyze the asymptotic stability through the dynamics f and G. This is an extension of Lyapunov
stability theory to a stochastic system. First we define the notion of stability in the stochastic case.
Let (Ω, F, P) be a complete probability space with filtration {Ft}t≥o and Bt be an m-dimensional
Brownian motion defined in the probability space, we consider the SDE in (10) with initial value ε0
dεt =f∆(εt,t)dt+G∆(εt,t)dBt,	(12)
For simplicity we dropped the dependency on parameters w and v . We further assume f∆ :
Rn × R+ 7→ Rn and G∆ : Rn × R+ 7→ Rn×m are both Borel measurable. We can show that
if assumptions (1) and (2) hold for f and G, then they hold for f∆ and G∆ as well (see Lemma
A.2 in Appendix), and we know the SDE (12) allows a unique solution εt. We have the following
Lynapunov stability results from (Mao, 2007).
Definition 3.1 (Lyapunov stability of SDE). The solution εt = 0 of (12):
A.	is stochastically stable if for any α ∈ (0,1) and r > 0, there exists a δ = δ(α,r) > 0 such that
Pr{kεt k < r for all t ≥ 0} ≥ 1 - α whenever kε0k ≤ δ. Moreover, iffor any α ∈ (0, 1), there
exists a δ = δ(α) > 0 such that Pr{limt→∞ kεtk = 0} ≥ 1 - α whenever kε0k ≤ δ, it is said to
be stochastically asymptotically stable;
B.	is almost SUreIy exponentially stable if lim sup1 log ∣∣εt ∣∣ < 0 a.s.1 for all ε0 ∈ Rn.
t→∞
Note that for part A in Definition 3.1, it is hard to quantify how well the stability is and how fast
the solution reaches equilibrium. In addition, under assumptions (1, 2), we have a straightforward
1“a.s.” is the abbreviation for “almost surely”.
6
Under review as a conference paper at ICLR 2020
result Pr{εt 6= 0 for all t ≥ 0} = 1 whenever ε0 6= 0 as shown in Appendix (see Lemma A.3).
That is, almost all the sample paths starting from a non-zero initialization can never reach zero due
to Brownian motion. On the contrary, the almost sure exponentially stability result implies that
almost all the sample paths of the solution will be close to zero exponentially fast. One important
result regarding to stability of this system is Mao (2007), deferred to Theorem A.1 in Appendix. We
now consider a special case, when the noise is multiplicative G(ht,t) = σ ∙ ht and m = 1. The
corresponding SDE of perturbation εt = hte - ht has the following form
dεt = f∆(εt,t; w)dt + σ ∙ εt dBt.	(13)
Note that for the deterministic case of (13) by setting σ ≡ 0, the solution may not be stable in certain
cases (see Figure 1). Whereas for general cases when σ > 0, following corollary claims that by
setting σ properly, we will achieve an (almost surely) exponentially stable system.
Corollary 3.0.1. For (13), if f(ht, t; w) is L-Lipschtiz continuous w.r.t. ht, then (13) has a unique
solution with the property limsup 1 log ∣∣εtk ≤ —(σ2 一 L) almost surely for any ε° ∈ Rn. In
t→∞
particular, if σ2 > 2L, the solution εt = 0 is almost surely exponentially stable.
4	Experimental Results
In this section we show the effectiveness of our Neural SDE framework in terms of generalization,
non-adversarial robustness and adversarial robustness. We use the SDE model architecture illustrated
in Figure 2 during the experiment. Throughout our experiments, we set f (∙) to be a neural network
with several convolution blocks. As to G(∙) we have the following choices:
•	Neural ODE, this can be done by dropping the diffusion term G(ht, t; v) = 0.
•	Additive noise, when the diffusion term is independent of ht, here we simply set it to be diagonal
G(ht, t; v) = σtI.
•	Multiplicative noise, when the diffusion term is proportional to ht, or G(ht, t; w) = σtht.
•	Dropout noise, when the diffusion term is proportional to the drift term f(ht, t; w), i.e.
G(ht, t; v) = σt diag{f (ht, t; w)}.
Note the last three are our proposed Neural SDE with different types of randomness as explained
in Section 3.1. For more experimental details, such as neural network architecture of f (∙) and the
solver for Neural SDE, please refer to Appendix B. Note that we use the same architecture for both
ODE and SDE, so the comparisons are fair.
4.1	Generalization Performance
In the first experiment, we show small noise helps generalization. However, note that our noise
injection is different from randomness layer in the discrete case, for instance, dropout layer adds
Bernoulli noise at training time but not testing time; whereas our Neural SDE model keeps randomness
at testing time and takes the average prediction of multiple forward propagations.
As for datasets, we choose CIFAR-10, STL-10 and Tiny-ImageNet2 to include various sizes and
number of classes. The experimental results are shown in Table 1. We see that for all datasets, Neural
SDE consistently outperforms ODE, and the reason is that adding moderate noise to the models at
training time can act as a regularizer and thus improves testing accuracy. Based upon that, if we
further keep testing time noise and ensemble the outputs, we will obtain even better results.
Table 1: Evaluating the model generalization under different choices of diffusion matrix G(ht, t; v)
introduced above. For the last three noise types, we search a suitable parameter σt for each so that
the diffusion matrix G properly regularizes the model. TTN means testing time noise. Model size is
counted by #Parameters.
Data	Model size	Accuracy@1 — w/o TTN				Accuracy@1 — w/ TTN			
		ODE	Additive	Multiplicative	Dropout	ODE	Additive	Multiplicative	Dropout
CIFAR-10	115K	81.63	83.65	83.26	83.60	-	83.89	83.76	84.55
STL-10	2.44 M	58.03	61.23	60.54	61.26	—	62.11	62.58	62.13
Tiny-ImageNet	2.49 M	45.19	45.25	46.94	47.04	—	45.39	46.65	47.81
2Downloaded from https://tiny-imagenet.herokuapp.com/
7
Under review as a conference paper at ICLR 2020
4.2	Improved non-adversarial robustness
In this experiment, we aim at evaluating the robustness of models under non-adversarial corruptions
following the idea of (Hendrycks & Dietterich, 2019). The corrupted datasets contain tens of defects
in photography including motion blur, Gaussian noise, fog etc. For each noise type, we run Neural
ODE and Neural SDE with dropout noise, and gather the testing accuracy. The final results are
reported by mean accuracy (mAcc) in Table 2 by changing the level of corruption. Both models are
trained on completely clean data, which means the corrupted images are not visible to them during
the training stage, nor could they augment the training set with the same types of corruptions. From
the table, we can see that Neural SDE performs better than Neural ODE in 8 out of 10 cases. For the
rest two, both ODE and SDE are performing very close. This shows that our proposed Neural SDE
can improve the robustness of Neural ODE under non-adversarial corrupted data.
Table 2: Testing accuracy results under different levels of non-adversarial perturbations.
Data	Noise type	mild corrupt — Accuracy → severe corrupt				
		Level 1	Level 2	Level 3 ]	Level 4	Level 5
	oDE	75.89	70.59	66.52	60.91	53.02
CIFAR10-G	Dropout	77.02	71.58	67.21	61.61	53.81
	Dropout+TTN	79.07	73.98	69.74	64.19	55.99
	oDE	23.01	19.18	15.20	12.20	9.88
TinyImageNet-Ct	Dropout	22.85	18.94	14.64	11.54	9.09
	Dropout+TTN	23.84	19.89	15.28	12.08	9.44
t Downloaded from https://github.com/hendrycks/robustness
4.3	Improved adversarial robustness
Figure 4: Comparing the robustness against '2-norm constrained adversarial perturbations, on CIFAR-
10 (left), sTL-10 (middle) and Tiny-ImageNet (right) data. We evaluate testing accuracy with three
models, namely Neural oDE, Neural sDE with multiplicative noise and dropout noise.
Next, we consider the performance of Neural sDE models under adversarial perturbation. Clearly,
this scenario is strictly harder than the previous case: by design, the adversarial perturbations
are guaranteed to be the worst case within a small neighborhood (ignoring the suboptimality of
optimization algorithms) crafted through constrained loss maximization procedure, so it represents
the worst case performance. In our experiment, We adopt multi-step '∞-PGD attack (Madry et al.,
2017), although other strong white-box attacks such as C&W (Carlini & Wagner, 2017) are also
suitable. The experimental results are shown in Figure 4. As we can see Neural sDE with either
multiplicative noise or dropout noise are more resistant to adversarial attack than Neural oDE, and
dropout noise outperforms multiplicative noise.
4.4	Visualizing the perturbations of hidden states
In this experiment, we take a look at the perturbation
εt = hte - ht at any time t. Recall the 1-d toy example
in Figure 1, we observe that the perturbation at time t
can be well suppressed by adding a strong diffusion term,
which is also confirmed by theorem. However, it is still
questionable whether the same phenomenon also exists in
deep neural network since we cannot add very large noise
to the network during training or testing time. If the noise
is too large, it will also remove all useful features. Thus it
becomes important to make sure that this will not happen
to our models. To this end, we first sample an input x
from CIFAR-10 and gather all the hidden states ht at time
Figure 5: Comparing the perturbations
of hidden states, εt , on both oDE and
sDE (we choose dropout-style noise).
t = [0, ∆t, 2∆t, . . . , N ∆t]. Then we perform regular PGD attack (Madry et al., 2017) to find the
8
Under review as a conference paper at ICLR 2020
perturbation δx such that xadv = x + δx is an adversarial image, and feed the new data xadv into
network again so we get hte at the same time stamps as ht . Finally we plot the error εt = hte - ht
w.r.t. time t (also called “network depth”), shown in Figure 5. We can observe that by adding a
diffusion term (dropout-style noise), the error accumulates much slower than the ordinary Neural
ODE model.
5	Conclusion
To conclude, we introduce the Neural SDE model which can stabilize the prediction of Neural ODE
by injecting stochastic noise. Our model can achieve better generalization and improve the robustness
to both adversarial and non-adversarial noises.
References
Guozhong An. The effects of adding noise during backpropagation training on a generalization
performance. Neural computation, 8(3):643-674, 1996.
Lynton Ardizzone, Jakob Kruse, Sebastian Wirkert, Daniel Rahner, Eric W Pellegrini, Ralf S Klessen,
Lena Maier-Hein, Carsten Rother, and Ullrich KOthe. Analyzing inverse problems with invertible
neural networks. arXiv preprint arXiv:1808.04730, 2018.
Chris M Bishop. Training with noise is equivalent to tikhonov regularization. Neural computation, 7
(1):108-116, 1995.
Nicholas Carlini and David Wagner. Towards evaluating the robustness of neural networks. In 2017
IEEE Symposium on Security and Privacy (SP), pp. 39-57. IEEE, 2017.
Patrick Cattiaux and Laurent Mesnager. Hypoelliptic non-homogeneous diffusions. Probability
Theory and Related Fields, 123(4):453-483, 2002.
Tian Qi Chen, Yulia Rubanova, Jesse Bettencourt, and David K Duvenaud. Neural ordinary dif-
ferential equations. In Advances in Neural Information Processing Systems, pp. 6572-6583,
2018.
Weinan E. A proposal on machine learning via dynamical systems. Communications in Mathematics
and Statistics, 5(1):1-11, 2017.
Xavier Gastaldi. Shake-shake regularization. arXiv preprint arXiv:1705.07485, 2017.
Golnaz Ghiasi, Tsung-Yi Lin, and Quoc V Le. Dropblock: A regularization method for convolutional
networks. In Advances in Neural Information Processing Systems, pp. 10727-10737, 2018.
Will Grathwohl, Ricky TQ Chen, Jesse Betterncourt, Ilya Sutskever, and David Duvenaud. Ffjord:
Free-form continuous dynamics for scalable reversible generative models. arXiv preprint
arXiv:1810.01367, 2018.
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image
recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition,
pp. 770-778, 2016.
Dan Hendrycks and Thomas Dietterich. Benchmarking neural network robustness to common
corruptions and perturbations. arXiv preprint arXiv:1903.12261, 2019.
Gao Huang, Yu Sun, Zhuang Liu, Daniel Sedra, and Kilian Q Weinberger. Deep networks with
stochastic depth. In European conference on computer vision, pp. 646-661. Springer, 2016.
Junteng Jia and Austin R. Benson. Neural jump stochastic differential equations, 2019.
Peter E Kloeden and Eckhard Platen. Numerical solution of stochastic differential equations, vol-
ume 23. Springer Science & Business Media, 2013.
9
Under review as a conference paper at ICLR 2020
Mathias Lecuyer, Vaggelis Atlidakis, Roxana Geambasu, Daniel Hsu, and Suman Jana. Certified
robustness to adversarial examples with differential privacy. arXiv preprint arXiv:1802.03471,
2018.
Xuanqing Liu, Minhao Cheng, Huan Zhang, and Cho-Jui Hsieh. Towards robust neural networks via
random self-ensemble. In Proceedings of the European Conference on Computer Vision (ECCV),
pp. 369-385, 2018.
Yiping Lu, Aoxiao Zhong, Quanzheng Li, and Bin Dong. Beyond finite layer neural networks:
Bridging deep architectures and numerical differential equations. In International Conference on
Machine Learning, pp. 3282-3291, 2018.
Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and Adrian Vladu.
Towards deep learning models resistant to adversarial attacks. arXiv preprint arXiv:1706.06083,
2017.
Xuerong Mao. Stochastic differential equations and applications. Elsevier, 2007.
GN Milshtein. Approximate integration of stochastic differential equations. Theory of Probability &
Its Applications, 19(3):557-562, 1975.
Bemt 0ksendal. Stochastic differential equations. In Stochastic differential equations, pp. 65-84.
Springer, 2003.
Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary DeVito,
Zeming Lin, Alban Desmaison, Luca Antiga, and Adam Lerer. Automatic differentiation in
pytorch. 2017.
Maziar Raissi. Forward-backward stochastic neural networks: Deep learning of high-dimensional
partial differential equations. arXiv preprint arXiv:1804.07010, 2018.
Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov.
Dropout: a simple way to prevent neural networks from overfitting. The Journal of Machine
Learning Research, 15(1):1929-1958, 2014.
Qi Sun, Yunzhe Tao, and Qiang Du. Stochastic training of residual networks: a differential equation
viewpoint. arXiv preprint arXiv:1812.00174, 2018.
Belinda Tzen and Maxim Raginsky. Neural stochastic differential equations: Deep latent gaussian
models in the diffusion limit, 2019.
Bao Wang, Binjie Yuan, Zuoqiang Shi, and Stanley J Osher. Enresnet: Resnet ensemble via the
feynman-kac formalism. In Neural Information Processing Systems, 2019.
Bolei Zhou, Aditya Khosla, Agata Lapedriza, Aude Oliva, and Antonio Torralba. Learning deep
features for discriminative localization. In Proceedings of the IEEE conference on computer vision
and pattern recognition, pp. 2921-2929, 2016.
10
Under review as a conference paper at ICLR 2020
We include the omitted proofs, experiment details and performance analysis here.
Appendix A	Omitted Theorems and Proofs
Theorem A.1. (MAO, 2007) If there exists a non-negative real valued function V (ε, t) defined on
Rn × R+ that has continuous partial derivatives
1/(户八.dV(ε,t) v∕f 八.dV(ε,t) v (户八.d2V(ε,t)
VIet) =	,V2(Gt) = ^^,V1Jet) = ~^ε∂ε>^
and constants p > 0, c1 > 0, c2 ∈ R, c3 ≥ 0 such that the following inequalities hold:
1.	c1kεkp≤V(ε,t)
2.	LV(ε,t) = V2(ε,t) + V1(ε,t)f∆(ε,t) + 2Tr[G∆(ε,t)Vι,ι(ε,t)G∆(ε,t)] ≤ c2V(ε,t)
3.	kV1(ε,t)G∆(ε,t)k2 ≥ c3V2(ε,t)
for all ε 6= 0 and t > 0. Then for all ε0 ∈ Rn,
limsup1log ∣∣εtk ≤ -c3 - 2c2 a.s.	(14)
t→∞ t	2p
In particular, if c3 ≥ 2c2, the solution εt ≡ 0 is almost surely exponentially stable.
We present the proofs of theorems on stability of SDE. The proofs are adapted from (Mao, 2007). We
start with two crucial lemmas.
Lemma A.2. If f, G satisfy Assumption (2), then f∆, G∆ satisfy Assumption (1,2).
Proof. By Assumption (2) on f, G, We can obtain that for any ε,卷 ∈ Rn,t ≥ 0
∣f∆(ε,t)∣ +∣G∆(ε,t)∣ ≤ c2∣ε∣ ≤ c2(1 + ∣ε∣),
kf∆(ε,t) - f∆(ε,t)k + ∣G∆(ε,t) - G∆(ε,t)k ≤ c2∣ε - ε∣.
This guarantees the uniqueness of the solution of (12).	□
Lemma A.3. For (12), whenever ε0 6= 0, Pr{εt 6= 0for all t ≥ 0} = 1.
Proof. We prove it by contradiction. Let τ = inf{t ≥ 0 : εt = 0}. Then if it is not true, there exists
some ε0 6= 0 such that Pr{τ < ∞} > 0. Therefore, We can find sufficiently large constant T > 0
and θ > 1 such that Pr(A) := Pr{τ < T and ∣ε∕ ≤ θ 一 1, ∀ 0 ≤ t ≤ T} > 0. By Assumption 2 on
f and G, there exists a positive constant Kθ such that
∣f∆(ε,t)∣ +∣G∆(ε,t)∣ ≤Kθ∣ε∣, for all ∣ε∣ ≤θand0 ≤t ≤T.	(15)
Let V(ε, t) = ∣∣-1. Then, for any 0 ≤ ∣ε∣ ≤ θ and 0 ≤ t ≤ T, We have
LV (ε,t) = -∣εk-3ε>f∆(ε,t) + ∣ {-∣εk-3kG∆(ε, t)∣2 + 3∣εk-5kετG∆ (ε,t)∣2}
≤ ∣ε∣-2∣f∆(ε,t)∣ +∣ε∣-3∣G∆(ε,t)∣2
≤Kθ∣ε∣-1+Kθ2∣ε∣-1=Kθ(1+Kθ)V(ε,t),	(16)
Where the first inequality comes from Cauchy-SchWartz and the last one comes from (15). For any
δ ∈ (0, ∣ε0∣), We define the stopping time τδ := inf{t ≥ 0 : ∣εt∣ ∈/ (δ, θ)}. Let νδ = min{τδ, T}.
By Ito's formula, E e-Kθ(I+Kθ)νδ V(ενδ, νδ)
- Kθ(1 + Kθ)V(εs, s) + LV(εs, s) ds ≤ ∣ε0∣-1. (17)
Since τδ ≤ T and ∣ετδ ∣ = δ for any ω ∈ A, then (17) implies
Ee-Kθ(1+Kθ)Tδ-11A = δ-1e-Kθ(1+Kθ)T Pr(A) ≤ ∣ε0∣-1.	(18)
Thus, Pr(A) ≤ δkεok-1eκθ(1+Kθ)T. Letting δ → 0, we obtain Pr(A) = 0, which leads to a
contradiction.	□
νδ
V(ε0, 0) +E	e-Kθ(1+Kθ)s
0
11
Under review as a conference paper at ICLR 2020
Proof of Theorem A.1
We then prove Theorem A.1. Clearly, (14) holds for ε0 = 0 since εt ≡ 0. For any ε0 6= 0, we have
Et = 0 for all t ≥ 0 almost surely by Lemma A.3. Thus, by applying ItO's formula and condition (2),
we can show that for t ≥ 0,
log V(εt, t) ≤ log V(εo, O)+c2t+M⑴-W Z11(	△( s,)i ds. (19)
2 0 V (εs, s)
where M(t) = Rt VI(EsV()G∆(εs,s) dBs is a continuous martingale with initial value M(0) = 0. By
the exponential martingale inequality, for any arbitrary α ∈ (0,1) and n = 1,2, ∙∙∙ ,we have
Pr ʃ sup [M(t) - α Zt 1V1 (εsVs)G△(:S，S)I2 ds] > 2 logn} ≤	∙	(20)
0≤t≤n	2 0	V2(εs, s)	α	n2
Applying Borel-Cantelli lemma, we can get that for almost all ω ∈ Ω, there exists an integer
n0 = n0(ω) such that ifn ≥ n0,
M(t) ≤ 2 log n + α Zt 1V1 (εsIs)G4(:4)12 ds, ∀ 0 ≤ t ≤ n.	(21)
α	2 0	V2(εs, s)
Combining (19), (21) and condition (3), we can obtain that
log V(εt,t) ≤ log V(：0,0) - 1[(1 - α)c3 - 2c2]t + 2 log n.	(22)
2α
for all 0 ≤ t ≤ n and n ≥ no almost surely. Therefore, for almost all ω ∈ Ω, if n 一 1 ≤ t ≤ n and
n ≥ n0, we have
t log V(εt,t) ≤ -1[(1 - α)c3 - 2c2] +
log V(εo, 0) + 2 log n
n-1
which consequently implies
lim sup1log V(：t,t) ≤ -1[(1 - α)c3 - 2c2]) a.s.
t→∞ t	2
(23)
(24)
With condition (1) and arbitrary choice of α ∈ (0, 1), we can obtain (14).
Proof of Corollary 3.0.1
We apply Theorem A.1 to establish the theories on stability of (13). Note that f(ht, t; w) is L-
Lipschitz continuous w.r.t ht and G(ht, t; v) = σht, m = 1. Then, (13) has a unique solution, with
f∆ and G∆ satisfying Assumptions (1,2)
kf∆(εt,t)k + kG∆ (εt, t)k ≤ max{L,σ}kεtk ≤ max{L, σ}(1 + kεtk),
kf∆(εt,t) - f∆(Et,t)k + kG∆(εt,t) - G∆(Et,t)k ≤ max{L,σ}∣∣εt -司|.
To apply Theorem A.1, let V(ε, t) = kεk2. Then,
LV(ε, t) = 2ε>f∆(ε,t) + σ2 kεk2 ≤ (2L + σ2)kεk2 = (2L + σ2)V(ε, t),
kV1(ε,t)G∆(ε,t)k2 =4σ2V(ε,t)2.
Let c1 = 1, p = 2, c2 = 2L + σ2, c3 = 4σ2. By Theorem A.1, we finished the proof.
Appendix B	Experiment settings
We have experimented several numerical solver for stochastic differential equations, and finally
decided to adopt the most straightforward Euler scheme. Although higher order solvers would also
work, we find low order solver is fast and precise enough. We follow the idea in Neural ODE (Chen
et al., 2018) and divide the whole classifier into three parts, the first part is to increase the number of
channels to a suitable value (which can also be regarded as feature extraction for neural SDE); the
following part the the ODE/SDE solver, note that the shape of intermediate states are not changed
throughout. The last layer is for classification.
The overview of our model architecture is described in Figure 2. Here we list some key hyper-
parameters for each model in Table 3. We can see that the architectures are roughly the same, except
that for Tiny-ImageNet, our model is significantly larger due to that fact that this data is significantly
harder to train on.
12
Under review as a conference paper at ICLR 2020
Dataset
First block
SDE block
Last block
MNIST	Conv2d(1, 64, 3, 1) × 1	GroUpNorm(32, 64) Conv2d(64, 64, 3, 1, 1) ReLU	× 3	GroUpNorm(32,64) ReLU GAP Linear(64, 10)	× 1
CIFAR-10	Conv2d(3, 64, 3, 1) × 1	GroUpNorm(32, 64) Conv2d(64, 64, 3, 1, 1) ReLU	× 3	GroUpNorm(32,64) ReLU GAP Linear(64, 10)	× 1
Tiny-ImageNet	'Conv2d(3,64,3,1,1) 一 GroupNorm(32, 64) ReLU Conv2d(64,128,4,2,1) GroUpNorm(32,128) ReLU	× 1	GroUpNorm(32, 256) Conv2d(256, 256, 3, 1, 1) ReLU	×3	GroUpNorm(32,256) ReLU GAP Linear(256, 200)	× 1
	Conv2d(128, 256, 4, 2, 1)					
Table 3: Model hyper-parameters. We follow the parameter convention in PyTorch (Paszke et al.,
2017). “GAP” means global average pooling Zhou et al. (2016).
Appendix C	Some empirical analysis
We provide some extra experiments to examine the discretization error due to Euler scheme. Different
from traditional weak and strong convergence analysis of SDE solver, here we only need to care
about the error in mean values, i.e. ∣∣EXt - EXtk, since in our case only the results will be first be
averaged before linear classifier and the accuracy of classification should not be affected as long as
the mean values are precise enough. To verify that, we run our neural SDE model under different
discretization step, specifically ∆t = {1.0 × 10-1, 5.0 × 10-2, 1.0 × 10-2, 5.0 × 10-3, 1.0 ×
10-3, 5.0 × 10-4, 1.0 × 10-4} and because we cannot solve the equation in closed form, we choose
the result by ∆t = 1.0 × 10-5 as the ground truth. For each step size, we solve the SDE 1000
times independently and average the resulting image embedding vectors. The discritization error
is measured by the relative error in the sense of Euclidean norm: ka - bk2 /kbk2 . The results are
shown in Figure 6. We can observe that although finer step size leads to smaller discretization error,
even a coarse step ∆t = 0.1 with relative error 〜2-4 can hardly change the prediction results.
2-4 -
2-5-
2--
2-7 -
2-8-
2-9 -
101	102	103	104
Network depth t
Uo=忑Zl∙s∙I°Sla
Figure 6: Discretization error under different step size in SDE solver.
Appendix D Running time comparison: Neural SDE, Neural ODE,
and Neural ODE-adjoint
See Figure 7.
13
Under review as a conference paper at ICLR 2020
Iol
O O -
Ilo
(•0①S)①IUHUIUUnH
102	103	104
Network depth t
Figure 7: Running time comparison (forward propagation) between Neural SDE, Neural ODE and
Neural ODE - adjoint. The curves are largely overlapped, meaning all methods have running time
proportional to network depth.
Appendix E	transform stochastic ordinary differential equation
to deterministic partial differential equation, and its
GRADIENT COMPUTATION THROUGH THE ADJOINT STATE
METHOD
The d-dimensional stochastic differential equation (SDE) discussed in section 3.1 is as follows:
dht = f(ht,t;w)dt+G(ht,t)dBt,	(25)
Note that w are the parameters of our neural network. Our new loss function for the stochastic
neural network is the expectation of the original loss function (e.g. softmax) L acting on the end time
state hT (counterpart to the last layer of discrete neural network), conditioned on initial state h0 , or
intermediate state ht. Let’s denote this expectation as u(ht, t)
u(ht,t)=E(L(hT)|ht).
(26)
Under smoothness assumptions on f (∙) and G(∙) in equation (25), from Feynman-Kac formula
(Cattiaux & Mesnager, 2002), u(ht, t) satisfies:
d∂u + W=IfiEt; W) ∂dui + Nd^MGlij ∂h∂h- = 0	(27)
with the boundary condition (final condition):
u(h, T ) = L(hT )	(28)
Our objective is to find W that minimize
J(h0, W) = E(L(hT)|h0; W) = u(h0, 0;W)	(29)
with u(h, t; W) satisfies the PDE system specified in equation(27).
This optimization problem can be solve with the adjoint state method, with the forward state solved
from the PDE and boundary condition defined in equation(27). It can be derived that the adjoint state
a(h,t) and the gradient ∂dJ can be solved by the following equations:
The adjoint state satisfies the following system:
∂a ∂	1	∂2
∂t + 2=1 ∂hi[fi(h,t; w)a] - 2*i，j=1 ∂hi∂hj[[GG ]ija]=0	(30)
with the boundary condition (initial condition):
a(h, 0) = δ(h0)	(31)
14
Under review as a conference paper at ICLR 2020
δ(h0) is the Dirac delta function which concentrates at h0 .
The gradient can be written as:
∂J ∂f ∂u i
∂w	ha ∂w ∂h h,t
h∙, ∙ih,t denotes integration over both h and t.
(32)
Equation(27) and equation(30) are actually the Kolmogorov backward equation and Kolmogorov for-
ward equation respectively, which are well-known equations in the mathematical finance community.
While the Kolmogorov backward equation describes the evolution of the expectation of loss with
time, the Kolmogorov forward equation describes the evoluation of a probability distribution.
15