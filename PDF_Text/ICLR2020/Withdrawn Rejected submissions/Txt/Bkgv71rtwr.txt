Under review as a conference paper at ICLR 2020
Open-Set Domain Adaptation with
Category-Agnostic Clusters
Anonymous authors
Paper under double-blind review
Ab stract
Unsupervised domain adaptation has received significant attention in recent years.
Most of existing works tackle the closed-set scenario, assuming that the source and
target domains share the exactly same categories. In practice, nevertheless, a target
domain often contains samples of classes unseen in source domain (i.e., unknown
class). The extension of domain adaptation from closed-set to such open-set sit-
uation is not trivial since the target samples in unknown class are not expected
to align with the source. In this paper, we address this problem by augmenting
the state-of-the-art domain adaptation technique, Self-Ensembling, with category-
agnostic clusters in target domain. Specifically, we present Self-Ensembling with
Category-agnostic Clusters (SE-CC) — a novel architecture that steers domain
adaptation with the additional guidance of category-agnostic clusters that are spe-
cific to target domain. These clustering information provides domain-specific vi-
sual cues, facilitating the generalization of Self-Ensembling for both closed-set
and open-set scenarios. Technically, clustering is firstly performed over all the
unlabeled target samples to obtain the category-agnostic clusters, which reveal the
underlying data space structure peculiar to target domain. A clustering branch is
capitalized on to ensure that the learnt representation preserves such underlying
structure by matching the estimated assignment distribution over clusters to the in-
herent cluster distribution for each target sample. Furthermore, SE-CC enhances
the learnt representation with mutual information maximization. Extensive exper-
iments are conducted on Office and VisDA datasets for both open-set and closed-
set domain adaptation, and superior results are reported when comparing to the
state-of-the-art approaches.
1 Introduction
Convolutional Neural Networks (CNNs) have
driven vision technologies to reach new state-of-
the-arts. The achievements, nevertheless, are on
the assumption that large quantities of annotated
data are accessible for model training. The assump-
tion becomes impractical when cost-expensive and
labor-intensive manual labeling is required. An al-
ternative is to recycle off-the-shelf learnt knowl-
edge/models in source domain for new domain(s).
Unfortunately, the performance often drops signif-
icantly on a new domain, a phenomenon known as
“domain shift.” One feasible way to alleviate this
problem is to capitalize on unsupervised domain
adaptation, which leverages labeled source samples
Figure 1: A comparison between (a) closed-set
domain adaptation, (b) existing methods for open-
set domain adaptation, and (c) our open-set domain
adaptation with category-agnostic clusters.
and unlabeled target samples to generalize a target model. One of the most critical limitations is that
most existing models simply align data distributions between source and target domains. As a con-
sequence, these models are only applicable in closed-set scenario (Figure 1(a)) under the unrealistic
assumption that both domains should share exactly the same set of categories. This adversely hin-
ders the generalization of these models in open-set scenario to distinguish target samples of unknown
class (unseen in source domain) from the target samples of known classes (seen in source domain).
1
Under review as a conference paper at ICLR 2020
The difficulty of open-set domain adaptation mainly originates from two aspects: 1) how to dis-
tinguish the unknown target samples from known ones while classifying the known target samples
correctly? 2) how to learn a hybrid network for both closed-set and open-set domain adaptation?
One straightforward way (Figure 1(b)) to alleviate the first issue is by employing an additional binary
classifier for assigning known/unknown label to each target sample Panareda Busto & Gall (2017).
All the unknown target samples are further taken as outlier and will be discarded during the adap-
tation from source to target. As the unknown target samples are holistically grouped as one generic
class, the inherent data structure is not fully exploited. In the case when the distribution of these tar-
get samples is diverse or the semantic labels between known and unknown classes are ambiguous,
the performance of binary classification is suboptimal. Instead, we novelly perform clustering over
all unlabeled target samples to explicitly model the diverse semantics of both known and unknown
classes in target domain, as depicted in Figure 1(c). All target samples are firstly decomposed into
clusters, and the learnt clusters, though category-agnostic, convey the discriminative knowledge of
unknown and known classes specific to target domain. As such, by further steering domain adapta-
tion with category-agnostic clusters, the learnt representations are expected to be domain-invariant
for known classes, and discriminative for unknown and known classes in target domain. To address
the second issue, we remould Self-Ensembling French et al. (2018) with an additional clustering
branch to estimate the assignment distribution over all clusters for each target sample, which in turn
refines the learnt representations to preserve inherent structure of target domain.
To this end, we present a new Self-Ensembling with Category-agnostic Clusters (SE-CC), as shown
in Figure 2. Specifically, clustering is firstly implemented to decompose all the target samples into a
set of category-agnostic clusters. The underlying structure of each target sample is thus formulated
as its inherent cluster distribution over all clusters, which is initially obtained by utilizing a softmax
over the cosine similarities between this sample and each cluster centroid. With this, an additional
clustering branch is integrated into student model of Self-Ensembling to predict the cluster assign-
ment distribution of each target sample. For each target sample, the KL-divergence is exploited to
model the mismatch between its estimated cluster assignment distribution and the inherent cluster
distribution. By minimizing the KL-divergence, the learnt feature is enforced to preserve the un-
derlying data structure in target domain. Moreover, we uniquely maximize the mutual information
among the input intermediate feature map, the output classification distribution and cluster assign-
ment distribution of target sample in student to further enhance the learnt feature representation. The
whole SE-CC framework is jointly optimized.
2	Related Work
Unsupervised Domain Adaptation. One common solution for unsupervised domain adaptation
in closed-set scenario is to learn transferrable feature in CNNs by minimizing domain discrepancy
through Maximum Mean Discrepancy (MMD) Gretton et al. (2012). Tzeng et al. (2014) is one of
early works that integrates MMD into CNNs to learn domain invariant representation. Long et al.
(2016) additionally incorporates a residual transfer module into the MMD-based adaptation of clas-
sifiers. Inspired by Goodfellow et al. (2014), another direction of unsupervised domain adaptation
is to encourage domain confusion across different domains via a domain discriminator, which is de-
vised to predict the domain (source/target) of each input sample. In particular, a domain confusion
loss Tzeng et al. (2015) in domain discriminator is devised to enforce the learnt representation to
be domain invariant. Ganin & Lempitsky (2015) formulates domain confusion as a task of binary
classification and utilizes a gradient reversal algorithm to optimize domain discriminator.
Open-Set Domain Adaptation. The task of open-set domain adaptation goes beyond the tradi-
tional domain adaptation to tackle a realistic open-set scenario, in which the target domain in-
cludes numerous samples from completely new and unknown classes not present in source domain.
Panareda Busto & Gall (2017) is one of the early attempts to tackle the realistic open-set scenario.
Busto et al. additionally exploit the assignments of target samples as know/unknown classes when
learning the mapping of known classes from source to target domain. Later on, Saito et al. (2018b)
utilizes adversarial training to learn feature representations that could separate the target samples of
unknown class from the known target samples. Furthermore, Baktashmotlagh et al. (2019) factor-
izes the source and target data into the shared and private subspace. The shared subspace models
the target and source samples from known classes, while the target samples from unknown class are
modeled with a private subspace, tailored to the target domain.
2
Under review as a conference paper at ICLR 2020

Student model
Source Image
Cluster 1
Cluster
Assignment
CIUster assignment
distribution
Target Image
Teacher model
N-1
Figure 2: An overview of our SE-CC. Each labeled source image is fed into student model to train the classifier
with cross entropy. Each unlabeled target image xt is transformed into two perturbed samples, i.e., xtS and xtT ,
before injected into student and teacher models separately. Conditional entropy is applied to xtS in student
pathway and self-ensembling loss is adopted to align the classification predictions between teacher and student.
To further exploit the underlying data structure of target domain, we perform clustering to decompose the
whole unlabeled target samples into a set of category-agnostic clusters (top right), which will be incorporated
into Self-Ensembling to facilitate both closed-set and open-set scenarios. Specifically, an additional clustering
branch is integrated into student to infer the assignment distribution over all clusters for each target sample
xtS . By aligning the estimated cluster assignment distribution to the inherent cluster distribution learnt from
original clusters via minimizing their KL-divergence, the feature representation is enforced to preserve the
underlying data structure in target domain. Furthermore, the feature representation of student is enhanced by
maximizing the mutual information among its feature map, classification and cluster assignment distributions
(bottom right). The maximization is conducted at both global and local levels as detailed in Appendix A.
Summary. In summary, similar in spirit as previous methods Baktashmotlagh et al. (2019);
Panareda Busto & Gall (2017), SE-CC utilizes unlabeled target samples for learning task-specific
classifiers in the open-set scenario. Different from these approaches, SE-CC leverages category-
agnostic clusters for representation learning. The learnt feature is driven to preserve the target data
structure during domain adaption. The structure preservation enables effective alignment of sample
distributions within known and unknown classes, and discrimination of samples between known and
unknown classes. As a by-product, the preservation, which is represented as a cluster probability
distribution, is exploited to further enhance representation learning. This is achieved through maxi-
mizing the mutual information among input feature, its cluster and class probability distributions. To
the best of our knowledge, there is no study yet to fully explore the advantages of category-agnostic
clusters for open-set domain adaptation.
Clustering
branch
Class 1
Class 2
⅛ a
Self-ensembling
Category-agnostic Clusters
Γ IiistRr K
Cluster 4
Cluster 6
KL-divergence
Inherent CIUSter
distribution
Real
Fake
Global/Local Mutual
Information Discriminator
Global/Local Mutual
Information Discrimin
Mutual Information
Maximization
3	Approach: Self-Ensembling with Category-agnostic Clusters
In this paper, we remold Self-Ensembling to suit both closed-set and open-set scenarios by in-
tegrating category-agnostic clusters into domain adaptation procedure. An overview of our Self-
Ensembling with Category-agnostic Clusters (SE-CC) model is depicted in Figure 2.
3.1	Notation
In open-set domain adaptation, we are given the labeled samples Xs = {(xs, ys)} in source domain
and the unlabeled samples Xt = {xt } in target domain belonging to N classes, where ys is the
class label of sample xs. The set of N classes is denoted as C, which consists of N - 1 known
classes shared between two domains and an additional unknown class that aggregates all samples of
unlabeled classes. The goal of open-set domain adaptation is to learn the domain-invariant repre-
sentations and classifiers for recognizing the N - 1 known classes in target domain and meanwhile
distinguishing the unknown target samples from known ones.
3.2	Self-Ensembling in Closed-Set Adaptation
We first briefly recall the method of Self-Ensembling French et al. (2018). Self-Ensembling mainly
builds upon the Mean Teacher Tarvainen & Valpola (2017) for semi-supervised learning, which
3
Under review as a conference paper at ICLR 2020
consists of a student model and a teacher model with the same network architecture. The main idea
behind Self-Ensembling is to encourage consistent classification predictions between teacher and
student under small perturbations of the input image. In other words, despite of different augmen-
tations imposed on a target sample, both teacher and student models should predict similar classifi-
cation probability distribution over all classes. Specifically, given two perturbed target samples xtS
and xtT augmented from an unlabeled sample xt, the self-ensembling loss penalizes the difference
between the classification predictions of student and teacher:
LSE(xt) = ||PcSls(xtS)-PcTls(xtT)||22,	(1)
where PcSls(xtS) ∈ RN and PcTls(xtT ) ∈ RN denote the predicted classification distribution over N
classes via the classification branch in student and teacher. During training, the student is trained
using gradient descent, while the weights of the teacher are directly updated as the exponential
moving average of the student weights. Inspired by Shu et al. (2018), we additionally adopt the
unsupervised conditional entropy loss to train the classification branch in student, aiming to drive
the decision boundaries of the classifier far away from high-density regions in target domain.
Accordingly, the overall training loss of our Self-Ensembling is composed of supervised cross en-
tropy loss (LCSE) on source data, unsupervised self-ensembling loss (LSE) and conditional entropy
loss (LCDE) of unlabeled target data, balanced with two tradeoff parameters (λ1 and λ2):
L = X	LCSE (xs , ys) + X (λ1LSE(xt) + λ2LCDE (xt)).	(2)
(xs,ys)∈S	xt∈T
3.3	SE-CC for Open-Set Adaptation
Open-set is more difficult than closed-set domain adaptation because it is required to classify not
only inliers but also outliers into N - 1 known and one unknown classes. The most typical way
is by learning a binary classifier to recognize each target sample as known/unkown class. Never-
theless, such recipe oversimplifies the problem by assuming that all unknown samples belong to
one class, while leaving the inherent data distribution among them unexploited. The robustness of
this approach is questionable when the unknown samples span across multiple unknown classes and
may not be properly grouped as one generic class. To alleviate this issue, we perform clustering
to explicitly model the diverse semantics in target domain as the distilled category-agnostic clus-
ters, which are further integrated into Self-Ensembling to guide domain adaptation. Specifically,
we design an additional clustering branch in student of Self-Ensembling to align its estimated clus-
ter assignment distribution with the inherent cluster distribution among category-agnostic clusters.
Hence, the learnt feature representations are enforced to be domain-invariant for known classes and
meanwhile more discriminative for unknown and known classes in target domain.
Category-agnostic Clusters. Clustering is an essential data analysis technique for grouping unla-
beled data in unsupervised machine learning Jain et al. (1999). Here we utilize k-means MacQueen
et al. (1967), the most popular clustering method, to decompose all unlabeled target samples Xt into
a set of K clusters {Ck}kK=1, where Ck represents the set of target samples from the k-th cluster.
Accordingly, the obtained clusters {Ck}kK=1, though category-agnostic, is still able to reveal the un-
derlying structure tailored to target domain, where the target samples with similar semantics stay
closer with local discrimination. In our implementations, we directly represent each target sample
Xt as the output feature (Xt) of CNNs pre-trained on ImageNet Russakovsky et al. (2015) for ClUs-
tering. We also tried to refresh the clusters according to learnt features periodically (e.g., every 5
training epoches), but that did not make a major difference.
We encode the underlying structure of each target sample xt as the joint relations between this
sample and all category-agnostic clusters, i.e., the inherent cluster distribution over all clusters.
SPecifically, for each target sample xt, we measure its inherent cluster distribution PClu(Xt) ∈ RK
through a softmax over the cosine similarities between this sample and each cluster centroid. The
k-th element represents the cosine similarity between Xt and the centroid μk of k-th cluster:
P kiu(xt)
eP∙cos(χt,μk)
Σk0 ep∙cθs
(xt,Hk0)
μk = ∣C1k∣	X xt,
xt∈Ck
(3)
where Cos (∙) is cosine similarity function and P is the temperature parameter of softmax for scaling.
The centroid of each cluster μk is defined as the average of all samples belonging to that cluster.
4
Under review as a conference paper at ICLR 2020
Clustering Branch. An additional branch in student, named as clustering branch, is especially
designed to predict the distribution over all category-agnostic clusters for cluster assignment of each
target sample xtS . Concretely, we denote the feature of target sample xtS along student pathway as
xtS ∈ RM . Hence, depending on the input feature xtS , clustering branch infers its cluster assignment
distribution Pclu (xtS) ∈ RK over all K clusters via a modified softmax layer Liu et al. (2017):
Pcklu (xtS) =
ep∙cos(χS Wk)
Σk0 ep∙cos
(xtS,Wk0)
(4)
where Pcklu(xtS) is the k-th element in Pclu representing the probability of assigning target sample
xtS into the k-th cluster. Wk is the k-th row of the parameter matrix W ∈ RK ×M in the modified
softmax layer, which denotes the cluster assignment parameter matrix for the k-th cluster.
KL-divergence Loss. The clustering branch is trained with the supervision from the inherent cluster
distribution of each target sample. To measure the mismatch between the estimated cluster assign-
ment distribution and the inherent cluster distribution, a KL-divergence loss is defined as
LKL = P KL(Pclu(Xt)||Pclu(XS)) = P Pk Fkiu(xt) log(Pklu(XS)) I	⑸
By minimizing the KL-divergence loss, the learnt representation is enforced to preserve the under-
lying data structure of target domain, pursuing to be more discriminative for both unknown and
known classes. Moreover, we incorporate the inter-cluster relationship into the KL-divergence loss
as a constraint to preserve the inherent relations among the cluster assignment parameter matrices.
The spirit behind follows the philosophy that the cluster assignment parameter matrices of two se-
mantically similar clusters should be similar. Hence, the KL-divergence loss with the constraint of
inter-cluster relationships is formulated as
LKL = P KL (Pclu(Xt)||Pclu(XS)) s.t. cos(Wk, Wk0 ) = cos(μk ,Mk, ),1 ≤ k,k0 ≤ K. (6)
xt∈T
The KL-divergence loss in Eq.(6) is further relaxed as:
LKL = P KL(P clu(xt)∣∣Pclu(xS))+ P	| cos (Wk, Wk0)-cos(μk,μko)|.	(7)
xt∈T	1≤k,k0 ≤K
3.4	Mutual Information Maximization in Student
Given the input feature ofa target sample, the student in our SE-CC produces both classification and
cluster assignment distributions via the two parallel branches in a multi-task paradigm. To further
strengthen the learnt target feature in an unsupervised manner, we leverage Mutual Information
Maximization (MIM) Hjelm et al. (2019) in student to maximize the mutual information among the
input feature and the two output distributions. The rationale behind follows the philosophy that the
global/local mutual information between input feature and output high-level features can be used
to tune the feature’s suitability for downstream tasks. As a result, we design a MIM module in
student to simultaneously estimate and maximize the local and global mutual information among
input feature map, the output classification distribution, and cluster assignment distribution.
Global Mutual Information. Technically, let xtS ∈ RH×H×D0 be the output feature map of the last
convolutional layer in student model for the input target sample xtS (H: the size of height and width;
D0: the number of channels). We encode this feature map into a global feature vector G(xtS) ∈ RD1
via a convolutional layer (kernel size: 3 × 3; stride size: 1; filter number: D1) plus an average pool-
ing layer. Next, we concatenate the global feature vector G(xtS) with the conditioning classification
distribution PcSls (xtS) and cluster assignment distribution Pclu (xtS). The concatenated feature will
be fed into the global Mutual information discriminator for discriminating whether the input global
feature vector is aligned with the given classification and cluster assignment distributions. Here
the global Mutual information discriminator is implemented with three stacked fully-connected net-
work plus nonlinear activation. The final output score of global Mutual information discriminator is
Vg ([G(xtS), PcSls (xtS), Pclu(xtS)]), which represents the probability of discriminating the real input
feature with matched classification and cluster assignment distributions. As such, the global Mutual
Information is estimated via Jensen-Shannon MI estimator Nowozin et al. (2016):
LgSD = P -M-Vg([G(xS), PSls(XS), PClu(XS)]))
xt∈T	(8)
— P W(Vg ([G(XS), PCIs(XS), PClu(XS )])),
xt∈T ,xt = xt '	,
5
Under review as a conference paper at ICLR 2020
where 夕(∙)is SoftplUs function and G(XS) denotes the global feature of a different target image XS.
Local Mutual Information. In addition, we exploit the local Mutual Information among the lo-
cal input feature at every spatial location, and the output classification and cluster assignment
distributions. In particular, we spatially replicate the two distributions PcSls(xtS) and Pclu(xtS)
to construct H × H × N and H × H × K feature maps respectively, and then concatenate
them with the input feature map xtS along the channel dimension. The concatenated feature map
L(xtS, PcSls(xtS), Pclu(xtS)) ∈ RH×H×(D0+N+K) will be fed into the local Mutual information dis-
criminator for discriminating whether each input local feature is matched with the given classifica-
tion and cluster assignment distributions. The local Mutual information discriminator is constructed
with three stacked convolutional layer (kernel size: 1 × 1) plus nonlinear activation. Hence the final
output score map of local Mutual information discriminator is Vl(L(xtS, PcSls (xtS), Pclu(xtS))) ∈
RH×H. The i-th element Vli(L(xtS, PcSls (xtS), Pclu(xtS))) in score map denotes the probability of
discriminating the real input local feature at the i-th spatial location with matched classification and
cluster assignment distributions. As such, the local Mutual Information is estimated as:
H2
LJSD = P - H12 P X-Vti(L(Xt, PSls(XS), PClu(XS))))
xt∈T	i=12	(9)
- P	H12 P r(vli(L(xS,PSls(XS),PClu(XS)))).
^t∈T ,xt=xt	i=1 、	/
Accordingly, the final objective for MIM module is measured as the combination of local and global
Mutual Information estimations, balanced with tradeoff parameter α:
LMIM = αLgJSD + LlJSD.	(10)
Appendix A conceptually depicts the process of both local and global mutual information estimation.
3.5	Training
The overall training objective of our SE-CC integrates the cross entropy loss on source data, unsu-
pervised self-ensembling loss, conditional entropy loss, KL-divergence loss of clustering branch in
Eq.(7), and the local & global Mutual Information estimation in Eq.(10) on target data:
L =	LCSE (xs, ys) +	(λ1LSE(xt) + λ2LCDE(xt)) + λ3LKL - λ4LMIM,
(xs,ys)∈S	xt∈T
(11)
where λ3 and λ4 are tradeoff parameters.
4	Experiments
We empirically verify the merit of our SE-CC by conducting experiments on Office Saenko et al.
(2010) and VisDA Peng et al. (2018) datasets for both open-set and closed-set domain adaptation.
Office is the standard benchmark for domain adaptation, which contains 4,110 images from 31
categories. They are collected from three domains: Amazon (A), DSLR (D), and Webcam (W). Six
directions of transfer among them are evaluated for both open-set and closed-set adaptation. For
open-set adaptation, as in Panareda Busto & Gall (2017), we firstly take 10 classes as the known
classes shared between source and target domains. In alphabetical order, the classes with labels 11-
20 are taken as the unknown classes in source, and the ones with labels 21-31 are unknown classes
in target. Two metrics OS and OS*, are adopted for evaluation (OS: the accuracy on all known &
unknown target samples; OS*: the accuracy on the target samples of the 10 known classes). We
adopt AlexNet Krizhevsky et al. (2012) pre-trained on ImageNet Russakovsky et al. (2015) as the
basic CNNs architecture for clustering and adaptation. For closed-set adaptation, we follow Long
et al. (2017) and report accuracy on target domain over all 31 classes. The basic architecture of
CNNs for clustering and adaptation is ResNet50 He et al. (2016) pre-trained on ImageNet.
VisDA is a large-scale dataset for the challenging synthetic-real image transfer, consisting of 280k
images from three domains. The synthetic images generated from 3D CAD models are taken as the
training domain. The validation domain contains real images from COCO Lin et al. (2014) and the
testing domain includes video frames in YTBB Real et al. (2017). Given the fact that the ground
truth of testing set are not publicly available, the synthetic images in training domain are taken as
source and the COCO images in validation domain are taken as target for evaluation. In particular,
6
Under review as a conference paper at ICLR 2020
Table 1: Performance comparison with the state of arts on Office for open-set domain adaptation. ♦ indicates
a different open-set setting without unknown source examples.
Method	A → D		A → W		D → A		D → W		W → A		W→D		Avg	
	OS	OS*	OS	OS*	OS	OS*	OS	OS*	OS	OS*	OS	OS*	OS	OS*
Source-only	^67T^	67.0	~46Γ	63.8	^6L9^	60.7	^906^	92.3	-60^	^597^	96.7	98.7	^35^	73.7
RTN Long et al. (2016)	76.6	74.7	73.0	70.8	57.2	53.8	89.0	88.1	62.4	60.2	98.8	98.3	76.2	74.3
ReVGrad Ganin & Lempitsky (2015)	78.3	77.3	75.9	73.8	57.6	54.1	89.8	88.9	64.0	61.8	98.7	98.0	77.4	75.7
AODA♦ Saito et al. (2018b)	76.6	76.4	74.9	74.3	62.5	62.3	94.4	94.6	81.4	81.2	96.8	96.9	81.1	80.9
ATI-λ Panareda Busto & Gall (2017)	79.8	79.2	77.6	76.5	71.3	70.0	93.5	93.2	76.7	76.5	98.3	99.2	82.9	82.4
FRODA Baktashmotlagh et al. (2019)	88.0	-	78.7	-	76.5	-	98.0	-	73.7	-	94.6	-	84.9	-
-SE-CC♦	80.6	84.0	82.4	84.2	83.2	90.3	92.9	96.6	82.7	85.9	96.8	99.1	86.4	90.0
SE-CC	85.3	84.5	85.1	84.3	87.9	89.5	97.7	97.8	86.8	87.5	99.4	99.6	90.4	90.5
Table 2: Performance comparison with the state of arts on VisDA for open-set domain adaptation (Known-to-
Unknown Ratio = 1:10). ♦ indicates a different open-set setting without unknown source examples. t indicates
the results are referred from the official leaderboard ViSDA (2018) (ViSda-SE and ViSda_AODA).
Method	aero bike bus car horse knife mbike person plant skbrd train truck unk	Knwn	Mean	Overall
Source-only	53.8 54.2 50.3 48.7 72.7 5.3~82.0~27.0 49.6 43.4 78.0 5.1 44.2	^69^	47.3	44.8
RevGrad Ganin & Lempitsky (2015)	33.0 57.3 44.1 33.9 72.1 46.9 82.2	26.8 36.8 50.4 89.4 9.8 47.8	48.6	48.5	47.8
RTN Long et al. (2016)	49.2 72.6 66.5 39.5 80.8 18.8 73.8	56.8 47.4 45.2 74.0 4.5 48.7	52.4	52.1	49.0
SEt French et al. (2018)	94.2 74.1 86.1 68.1 91.0 26.1 95.2	46.0 85.0 40.4 79.2 11.0 51.0	66.4	65.2	52.7
AODAQt Saito et al. (2018b)	80.2 63.1 59.1 63.1 83.2 12.1 89.1	5.0	61.0 14.0 79.2 0.0 69.0	50.8	52.2	67.6
ATI-λ Panareda Busto & Gall (2017)	85.7 74.9 60.3 49.9 80.0 19.3 88.8	40.8 54.0 59.2 66.4 18.2 59.5	58.1	58.2	59.3
SE-CCq	82.1 80.7 59.7 50.0 80.6 36.7 83.1^^56.2 56.6 21.9 57.7 4.0 70.6	55.8	56.9	69.2
SE-CC	94.2 79.0 83.4 70.7 91.0 43.5 89.3	73.3 69.4 58.8 79.4 12.8 71.6	70.4	70.5	71.6
for open-set adaptation, we follow the open-set setting in Peng et al. (2018) and take the 12 classes as
the known classes for source & target domains, the 33 background classes as the unknown classes in
source, and the other 69 COCO categories as the unknown classes in target. The known-to-unknown
ratio of samples in target domain is strictly set as 1:10. Three metrics, i.e., Knwn, Mean, and OVerall,
are adopted for eValuation. Here Knwn denotes the accuracy aVeraged oVer all known classes, Mean
is the accuracy aVeraged oVer all known & unknown classes, and OVerall is the accuracy oVer all
target samples. For closed-set adaptation, we report the accuracy of all the 12 classes for adaptation,
as in the closed-set setting of Peng et al. (2018). We utilize ResNet152 as the backbone of CNNs for
clustering and adaptation in both closed-set and open-set scenarios.
4.1	Performance Comparison
Open-Set Domain Adaptation on Office. The performances of different models on Office for
open-set adaptation are shown in Table 1. It is worth noting that AODA adopts a different open-set
setting where unknown source samples are absent. For fair comparison with AODA, we additionally
include a variant of our SE-CC (dubbed as SE-CC♦) which learns classifier without unknown source
samples. Specifically, the classifier in SE-CC♦ is naturally able to recognize only the N-1 known
classes and the target samples will be recognized as unknown if the predicted probability is lower
than the threshold for any class as performed in open set SVM Jain et al. (2014).
OVerall, the results across two metrics consistently indicate that our SE-CC obtains better perfor-
mances against other state-of-the-art closed-set adaptation models (RTN and ReVGrad) and open-set
adaptation methods (AODA, ATI-λ, and FRODA) on most transfer directions. Please also note that
our SE-CC improVes the classification accuracy eVidently on the harder transfers, e.g., D → A and
W → A, where the two domains are substantially different. The results generally highlight the
key adVantage of exploiting underlying target data structure implicit in category-agnostic clusters
for open-set domain adaptation. Such design makes the learnt feature representation to be domain-
inVariant for known classes while discriminatiVe enough to segregate target samples from known
and unknown classes. Specifically, by aligning the data distributions between source and target do-
mains, RTN and ReVGrad exhibit better performance than Source-only that trains classifier only on
source data while leaVing unlabeled target data unexploited. By rejecting unknown target samples as
outliers and aligning data distributions only for inliers, the open-set adaptation techniques (AODA,
ATI-λ, and FRODA) outperform RTN and ReVGrad. This confirms the effectiVeness of exclud-
ing unknown target samples from the known target samples during domain adaptation in open-set
scenario. NeVertheless, AODA, ATI-λ, and FRODA are still inferior to our SE-CC which steers
the domain adaptation by injecting the distribution of category-agnostic clusters as a constraint for
feature learning and alignment.
7
Under review as a conference paper at ICLR 2020
Table 3: Performance comparison With the state of arts on Office dataset for closed-set domain adaptation.
Method	A → D	A → W	D → A	D→W	W → A	W → D	AVg
RTN Long et al. (2016)	77.5	84.5	66.2	96.8	64.8	99.4	816
RevGrad Ganin & Lempitsky (2015)	79.7	82.0	68.2	96.9	67.4	99.1	82.2
JAN Long et al. (2017)	85.1	86.0	69.2	96.7	70.7	99.7	84.6
SimNet Pinheiro (2018)	85.3	88.6	73.4	98.2	71.8	99.7	86.2
GTA Sankaranarayanan et al. (2018)	87.7	89.5	72.8	97.9	71.4	99.8	86.5
iCAN Zhang et al. (2018)	90.1	92.5	72.1	98.8	69.9	100	87.2
SE-CC	91.6	90.8	74.2	99.0	73.2	100	88T
Table 4: Performance comparison with the state of arts on VisDA dataset for closed-set domain adaptation.
Method	aero	bike	bus	car	horse	knife	mbike	person	plant	skbrd	train	truck	Mean
Source-only	~67Γ^	51.4	50.8	64.5	83.4	13.0	89.9	34.4	78.8	47.0	88.1	2.0	55.9
RevGrad Ganin & Lempitsky (2015)	81.9	77.7	82.8	44.3	81.2	29.5	65.1	28.6	51.9	54.6	82.8	7.8	57.4
RTN Long et al. (2016)	89.1	56.4	72.4	69.7	77.9	49.5	87.7	13.0	88.1	77.4	86.7	7.2	64.6
MCD Saito et al. (2018a)	87.0	60.9	83.7	64.0	88.9	79.6	84.7	76.9	88.6	40.3	83.0	25.8	71.9
SimNet Pinheiro (2018)	94.3	82.3	73.5	47.2	87.9	49.2	75.1	79.7	85.3	68.5	81.1	50.3	72.9
SE French et al. (2018)	96.2	87.8	84.4	66.5	96.1	96.1	90.5	81.5	95.3	91.5	87.5	51.6	85.4
SE-CC	~969~	86.5	83.0	79.9	96.3	97.4	90.5	83.4	94.2	94.1	88.2	56.0	87.2
Open-Set Domain Adaptation on VisDA. The performance comparison on VisDA for open-set
adaptation is summarized in Table 2. Our SE-CC performs consistently better than other methods
across all the three metrics. In particular, the Mean accuracy averaged over 12 knoWn classes plus
one unknoWn class of our SE-CC can achieve 70.5%, making the absolute improvement over the best
closed-set adaptation method (SE) and open-set adaptation approach (ATI-λ) by 5.3% and 12.3%,
respectively. Similar to the observations on Office for open-set adaptation, the open-set adaptation
approaches (AODA and ATI-λ) exhibit better performance than RTN and RevGrad, by additionally
separating unknoWn target samples from knoWn target samples for open-set adaptation. Note that
although the closed-set technique SE achieves higher Mean per-category accuracy than the open-set
techniques (AODA and ATI-λ), the Overall accuracy over all target samples of SE are still Worse
than open-set techniques. This is because SE aligns unknoWn samples across different domains
and thus fails to recognize unknoWn target samples. Furthermore, by integrating category-agnostic
clusters into SE and steering domain adaptation to preserve the underlying target data structure of
both knoWn and unknoWn classes, SE-CC boosts the performances in terms of all metrics.
Closed-Set Domain Adaptation on Office and VisDA. To further verify the generality of our pro-
posed SE-CC, We additionally conduct experiments for domain adaptation in closed-set scenario.
Tables 3 and 4 shoW the performance comparisons on Office and VisDA datasets for closed-set
domain adaptation. Similar to the observations for open-set domain adaptation task on these tWo
datasets, our SE-CC achieves better performances than other state-of-the-art closed-set adaptation
techniques. The results basically demonstrate the advantage of exploiting the underlying data struc-
ture in target domain via category-agnostic clusters, for domain adaptation, even on closed-set sce-
nario Without any diverse and ambiguous unknoWn samples.
Ablation Study. Here We investigate hoW each Table 5: Performance contribution of each design		
design in our SE-CC influences the overall per- (i.e., Conditional Entropy (CE), KL-divergence		
formance. Conditional Entropy (CE) incorporates Loss (KL), and Mutual Information Maximization		
an unsupervised conditional entropy loss into SE (MIM)) in SE-CC on VisDA for open-set transfer.		
to drive the classifier’s decision boundaries aWay	Method	CE KL MIM	Knwn Mean Overall
from high-density target data regions in student SE		66.4 65.2^^527-
model. KL-divergence Loss (KL) aligns the esti- +CE	X	67.3 66.3	55.8
mated cluster assignment distribution to the inher- +KL	X X	69.3 69.3 69.1
ent cluster distribution for each target sample, tar- SE-CC	XXX	70.4 70.5 7L^~
geting for refining feature to preserve the underlying structure of target domain. Mutual Information
Maximization (MIM) further enhances the feature’s suitability for doWnstream tasks by maximiz-
ing the mutual information among the input feature, the output classification and cluster assignment
distributions. Table 5 details the performance improvements on VisDA by considering different de-
signs and their contributions for open-set domain adaptation in our SE-CC. CE is a general Way to
enhance classifier for target domain irrespective of any domain adaptation architectures. In our case,
CE improves the Mean accuracy from 65.2% to 66.3%, Which demonstrates that CE is an effective
choice. KL and MIM are tWo specific designs in our SE-CC and the performance gain of each is
3.0% and 1.2% in Mean metric. In other Words, our SE-CC leads to a large performance boost of
4.2% in total in terms of Mean metric. The results verify the idea of exploiting underlying target
data structure and mutual information maximization for open-set adaptation.
8
Under review as a conference paper at ICLR 2020
5	Conclusion
We have presented Self-Ensembling with Category-agnostic Clusters (SE-CC), which exploits the
category-agnostic clusters in target domain for domain adaptation in both open-set and closed-set
scenarios. Particularly, we study the problem from the viewpoint of how to separate unknown target
samples from known ones and how to learn a hybrid network that nicely integrates category-agnostic
clusters into Self-Ensembling. We initially perform clustering to decompose all target samples into
a set of category-agnostic clusters. Next, an additional clustering branch is integrated into student
model to align the estimated cluster assignment distribution to the inherent cluster distribution im-
plicit in category-agnostic clusters. That enforces the learnt feature to preserve the underlying data
structure in target domain. Moreover, the mutual information among the input feature, the outputs
of classification and clustering branches is exploited to further enhance the learnt feature. Experi-
ments conducted on Office and VisDA for both open-set and closed-set adaptation tasks verify our
proposal. Performance improvements are observed when comparing to state-of-the-art techniques.
References
Mahsa Baktashmotlagh, Masoud Faraki, Tom Drummond, and Mathieu Salzmann. Learning factor-
ized representations for open-set domain adaptation. In ICLR, 2019.
Geoffrey French, Michal Mackiewicz, and Mark Fisher. Self-ensembling for domain adaptation. In
ICLR, 2018.
Yaroslav Ganin and Victor Lempitsky. Unsupervised domain adaptation by backpropagation. In
ICML, 2015.
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair,
Aaron Courville, and Yoshua Bengio. Generative adversarial nets. In NIPS, 2014.
Arthur Gretton, Karsten M Borgwardt, Malte J Rasch, Bernhard Scholkopf, and Alexander Smola.
A kernel two-sample test. Journal of Machine Learning Research, 2012.
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recog-
nition. In CVPR, 2016.
R Devon Hjelm, Alex Fedorov, Samuel Lavoie-Marchildon, Karan Grewal, Adam Trischler, and
Yoshua Bengio. Learning deep representations by mutual information estimation and maximiza-
tion. In ICLR, 2019.
Anil K Jain, M Narasimha Murty, and Patrick J Flynn. Data clustering: a review. ACM computing
surveys, 1999.
Lalit P Jain, Walter J Scheirer, and Terrance E Boult. Multi-class open set recognition using proba-
bility of inclusion. In ECCV, 2014.
Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classification with deep convo-
lutional neural networks. In NIPS, 2012.
Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr
Dollar, and C Lawrence Zitnick. Microsoft COCO: Common objects in context. In ECCV,, 2014.
Weiyang Liu, Yandong Wen, Zhiding Yu, Ming Li, Bhiksha Raj, and Le Song. Sphereface: Deep
hypersphere embedding for face recognition. In CVPR, 2017.
Mingsheng Long, Han Zhu, Jianmin Wang, and Michael I Jordan. Unsupervised domain adaptation
with residual transfer networks. In NIPS, 2016.
Mingsheng Long, Jianmin Wang, and Michael I Jordan. Deep transfer learning with joint adaptation
networks. In ICML, 2017.
Laurens Van Der Maaten and Geoffrey Hinton. Visualizing data using t-SNE. JMLR, 2008.
9
Under review as a conference paper at ICLR 2020
James MacQueen et al. Some methods for classification and analysis of multivariate observations.
In Proceedings of the fifth Berkeley symposium on mathematical statistics and probability, 1967.
Sebastian Nowozin, Botond Cseke, and Ryota Tomioka. f-gan: Training generative neural samplers
using variational divergence minimization. In NIPS, 2016.
Pau Panareda Busto and Juergen Gall. Open set domain adaptation. In ICCV, 2017.
Xingchao Peng, Ben Usman, Kuniaki Saito, Neela Kaushik, Judy Hoffman, and Kate Saenko.
Syn2real: A new benchmark forsynthetic-to-real visual domain adaptation. arXiv preprint
arXiv:1806.09755, 2018.
Pedro O Pinheiro. Unsupervised domain adaptation with similarity learning. In CVPR, 2018.
Esteban Real, Jonathon Shlens, Stefano Mazzocchi, Xin Pan, and Vincent Vanhoucke. Youtube-
boundingboxes: A large high-precision human-annotated data set for object detection in video. In
CVPR, 2017.
Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng
Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, Alexander C. Berg, and Li Fei-Fei.
ImageNet Large Scale Visual Recognition Challenge. IJCV, 2015.
Kate Saenko, Brian Kulis, Mario Fritz, and Trevor Darrell. Adapting visual category models to new
domains. In ECCV, 2010.
Kuniaki Saito, Kohei Watanabe, Yoshitaka Ushiku, and Tatsuya Harada. Maximum classifier dis-
crepancy for unsupervised domain adaptation. In CVPR, 2018a.
Kuniaki Saito, Shohei Yamamoto, Yoshitaka Ushiku, and Tatsuya Harada. Open set domain adap-
tation by backpropagation. In ECCV, 2018b.
Swami Sankaranarayanan, Yogesh Balaji, Carlos D Castillo, and Rama Chellappa. Generate to
adapt: Aligning domains using generative adversarial networks. In CVPR, 2018.
Rui Shu, Hung H Bui, Hirokazu Narui, and Stefano Ermon. A dirt-t approach to unsupervised
domain adaptation. In ICLR, 2018.
Antti Tarvainen and Harri Valpola. Mean teachers are better role models: Weight-averaged consis-
tency targets improve semi-supervised deep learning results. In NIPS, 2017.
Eric Tzeng, Judy Hoffman, Ning Zhang, Kate Saenko, and Trevor Darrell. Deep domain confusion:
Maximizing for domain invariance. arXiv preprint arXiv:1412.3474, 2014.
Eric Tzeng, Judy Hoffman, Trevor Darrell, and Kate Saenko. Simultaneous deep transfer across
domains and tasks. In ICCV, 2015.
VisDA, 2018. URL https://competitions.codalab.org/competitions/19113#
results.
Weichen Zhang, Wanli Ouyang, Wen Li, and Dong Xu. Collaborative and adversarial network for
unsupervised domain adaptation. In CVPR, 2018.
10
Under review as a conference paper at ICLR 2020
A	Global/Local Mutual Information Maximization
In this section, we illustrate the detailed frameworks for global and local mutual information esti-
mation in Figure 3 and Figure 4, resPectively.
Student
model
--------►
Student
model A
T
--------Fak Fake
%([G(潭),P5(婢),P"t,(婢)])
%([G(xf),P氏公),P*(婢)])
--------43 Real
Global Mutual
Information
Discriminator
Figure 3:
Student
model »
Framework of global mutual information estimation in our SE-CC.
Figure 4: Framework of local mutual information estimation in our SE-CC.

B	Implementation Details
The implementation of our SE-CC is mainly developed with PyTorch and the network weights are
optimized with SGD. We set the learning rate and mini-batch size as 0.001 and 56 for all exper-
iments. The maximum training iteration is set as 300 and 25 epochs on Office and VisDA, re-
spectively. The dimension D1 of global feature for global Mutual Information estimation is set as
128/1,024 in the backbone of AlexNet/ResNet.
Table 6: HyPerParameters for each task.
Task		K	λ1	λ2	λ3		λ4	α
Open-set domain adaptation (Office)		10	0.1	1	0.001	1
OPen-set domain adaPtation (VisDA)	500	10	0.1	1	0.01	5
Closed-set domain adaptation (Office)	35	10	0.01	0.1	0.0001	1
Closed-set domain adaptation (VisDA)	500	10	0.01	1	0.01	5
Table 6 details the settings of cluster number K, the tradeoff parameters λ1, λ2, λ3, λ4 in Eq.(11)
and α in Eq.(10) on two datasets for oPen-set and closed-set adaPtation tasks. In Particular, the
number of clusters (K) is determined using GaP statistics method. λ1 = 10 is fixed based on
French et al. (2018) for all the exPeriments, and the other four Parameters are tuned as in Hjelm
et al. (2019); Shu et al. (2018). We restrict the hyPer-Parameter search for each transfer in range of
λ2 = {10-2,10-1,1},λ3 = {10-2,10-1,1},λ4 = {10-4,10-3,10-2},andα = {1, 5, 10}.
11
Under review as a conference paper at ICLR 2020
C Experimental Analysis
Evaluation of Clustering Branch. To study how the design of loss function in clustering branch
affects the performance, we compare the use of KL-divergence in our proposed SE-CC with L1 and
L2 distance. The results in Table 7(a) verify that KL-divergence is a better measure of mismatch
between the classification and cluster assignment distributions than L1 and L2 distance, which yield
inferior performance.
Evaluation of Mutual Information Maximization. Next, we evaluate different variants of MIM
module in our SE-CC by estimating mutual information between input feature and different out-
puts, as shown in Table 7(b). CLS, CLU and CLS+CLU estimates the local and global mutual
information between input feature and the output of classification branch, the output of clustering
branch, and the combined output of two branches, respectively. Compared to our SE-CC without
MIM module (Knwn: 69.3%, Mean: 69.3%, and Overall: 69.1%), CLS and CLU slightly improves
the performances by additionally exploiting the mutual information between input feature and the
output of each branch. Furthermore, CLS+CLU obtains a larger performance boost, when combin-
ing the outputs from both branches for mutual information estimation. The results demonstrate the
merit of exploiting the mutual information among the input feature and the combined outputs of two
downstream tasks (i.e., classification and cluster assignment) in our MIM module.
Table 7: Evaluation of (a) clustering branch with different loss functions (i.e., L1: L1 distance, L2: L2 dis-
tance, and KL: KL-divergence) to measure the mismatch between two distributions and (b) mutual information
estimated over input feature and different outputs (i.e., CLS: output of classification branch, CLU: output of
clustering branch, and CLS+CLU: combined output of classification and clustering branches) on VisDA dataset
for open-set domain adaptation.
(a)				(b)			
Method	KnWn	Mean	Overall	Method	Knwn	Mean	Overall
L1	-68.6^^	68.7	70.1	CLS	69.3	69.4	69.4
L2	68.3	68.4	70.1	CLU	70.0	70.1	70.8
KL	70.4	70.5	71.6	CLS+CLU	70.4	70.5	71.6
Feature Visualization. We visualize the features learnt by Source-only, SE, and SE-CC with t-
SNE Maaten & Hinton (2008) on VisDA for open-set adaptation in Figure 5(a)-(c). Compared to
Source-only without domain adaptation, SE brings the two distributions of source and target closer,
leading to domain-invariant representation. However, in SE, all target samples including unknown
samples are enforced to match source samples, making it difficult to recognize unknown target
samples with ambiguous semantics. Through the preservation of underlying target data structure for
both known and unknown classes by SE-CC, the unknown target samples are separated from known
target samples, and meanwhile the known samples in two domains are indistinguishable.
kno known in source - unknown in source - known in target - unknown in target
(a) Source-only
(c) SE-CC
Figure 5: The t-SNE visualization of features learnt by (a) Source-only, (b) SE, and (c) SE-CC on VisDA
dataset for open-set domain adaptation.
12