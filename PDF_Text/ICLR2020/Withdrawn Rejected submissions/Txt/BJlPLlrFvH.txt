Under review as a conference paper at ICLR 2020
Variable Complexity in the Univariate and
Multivariate Structural Causal Model
Anonymous authors
Paper under double-blind review
Ab stract
We provide a critical view of the univariate Structural Causal Model. We show
that by comparing the individual complexities of univariate cause and effect, in
the StrUctural Causal ModeL one can identify the cause and the effect, without
considering their interaction at all. The entropy of each Variable is ineffective in
measuringIhe complexity, and We ProPoSe We suggest to capture it the complex-
ity by the reconstruction error of an autoencoder that operates on the list of Serted
SamPleS the percentiles of the distribution. Comparing the reconstruction errors
of the two autoencoders, one for each variable, is shown to perform well on the
accepted benchmarks of the field. Hence, the decision as to which of the two is
the cause and which is the effect may not be based on causality but on complexity.
In the multivariate case, where one can ensure that the complexities of the cause
and effect are balanced, we propose a new adversarial training method that mimics
the disentangled structure of the causal model. We extend the results of Zhang &
Hyvrinen (2010) to the multidimensional case, showing that such modeling is
only likely in the direction of causality. Furthermore, the learned model is shown
theoretically to perform the separation to the causal component and to the residual
(noise) component. Our multidimensional method obtains a significantly higher
accuracy than the literature methods.
1	Introduction
A long standing debate in the causality literature, is whether causality can be inferred without in-
tervention (Pearl, 2009; Spirtes et al., 2000). The Structural Causal Model (SCM) (Spirtes et al.,
2000) is a simple causative model for which many results demonstrate the possibility of such infer-
ence (Stegle et al., 2010; Bloebaum et al., 2018; Goudet et al., 2018; Lopez-Paz et al., 2017; 2015).
In this model, the effect (Y ) is a function of the cause (X) and some independent random noise (E).
In this work, we take a critical perspective of the univariate SCM. We demonstrate empirically that
for the 1D univariate case, which is the dominant case in the existing literature, the SCM model
leads to an effect that has a lower complexity than the cause. Therefore, one can identify the cause
and the effect by measuring their individual complexities, with no need to make the inference based
on both variables simultaneously. Thus, the decision as to which of the two is the cause and which
is the effect may not be based on causality but on complexity.
Since We are dealing with unordered 1D univariate random variables, the complexity measure has to
be based on the probability distribution function. As we show empirically, comparing the entropies
of the distribution two random variables is ineffective for inferring the causal direction. We, there-
fore, consider the quantiles, i.e, fixed sized vectors that are obtained as sub-sequences of the sorted
sampled values of the variable.
We consider suitable complexity scores for these vectors. In our analysis, we show that the recon-
struction error ofan autoencoder ofa multivariate random variable is a valid complexity measure. In
addition, we link the reconstruction error based complexity, in the case of variational autoencoders,
to the differential entropy of the input random variable. Hence, by computing the reconstruction
errors of trained autoencoders on these vectors we estimate the entropies of the quantile vectors of
X and Y .
1
Under review as a conference paper at ICLR 2020
The challenges of measuring causality independently of complexity in the 1D case lead us to con-
sider the multidimensional case, where the complexity can be controlled by, e.g., manipulating the
dimension of the noise signal in the SCM model. Note that unlike GoUdet et al. (2018), We consider
pairs of multivariate vectors and not many univariate variables in a graph structure. We demonstrate
that for the multidimensional case, any method that is based on comparing the complexity of the
individual random variables X and Y fails to infer causality of random variables. Furthermore, We
extend the result of Zhang & Hyvrinen (2010) to the multidimensional case and prove that an SCM
is unlikely to hold in both directions X → Y and Y → X for reasonable conditions.
Based on our observations, We propose aneW causality inference method for multidimensional cause
and effect. The algorithm learns three networks in a way that mimics the parts of the SCM model.
The noise part is unknoWn and is replaced by a function that is constrained to be independent of the
cause, as captured by an adversarial loss. However, we show analytically and empirically that even
without the explicit constraint, in several cases, such an independence emerges.
Our empirical results support our analysis and demonstrate that in the 1D univariate case, assigning
cause and effect based on complexity is competitive with the state of the art methods. In the mul-
tidimensional case, we show that the proposed method outperforms existing and new extensions of
the literature methods to the multidimensional case.
1.1	Problem Setup
We investigate the problem of causal inference from observational data. A non-linear structural
causal model (SCM for short) is a generative process of the following form:
X ~ PX
E ~ PE	(1)
Y 一 g(f(X),E)
The functions g : Rdf +de → Rn and f : Rn → Rdf are fixed and unknown. In general, g and f are
non-linear. Here, X is the input random variable and E is the environment random variable that is
independent of X . We say that X causes Y if they satisfy a generative process such as Eq. 1.
We present methods for inferring whether X causes Y (denoted by X → Y) or Y causes X, or
neither. The algorithm is provided with i.i.d samples {(xi, yi)}mLι 〜PmY (the distribution of m
i.i.d samples from the joint distribution PX,Y) from the generative process of Eq. 1. In general, by
(cf. Prop 4.8, (Peters et al., 2017)), for any joint distribution PX,Y of two random variables X
and Y, there is an SCM, Y = g(f(X), E), where E is a noise variable, such that, X E and h is
some (measurable) function. Therefore, in general, deciding whether X causes Y or vice versa is
ill-posed when only provided with samples from the joint distribution. However, Zhang & Hyvrinen
(2010) showed for the one dimensional case (i.e., X, Y ∈ R) that under reasonable conditions, a
representation Y = g(f(X) +E) holds only in one direction. In Sec. 3.2 we extend this theorem and
show that a representation Y = g(f (X), E) holds only in one direction when g and f are assumed
to be neural networks and X, Y are multidimensional (we call such SCMs neural SCMs).
Throughout the paper, we denote by PU [u] := P[U ≤ u] the cumulative distribution function of a
uni/multi-variate real valued random variable U andP is a standard Lebesgue measure. Additionally,
we denote by PU(U) = duPU [u] the probability density function of U (if exists, i.e., PU [u] is
absolutely continuous). We denote by Eu~u [f (u)] or by EpU [f (u)] the expected value of f (U) for
u that is distributed by PU [u], depending on the context. The identity matrix of dimension n × n
is denoted by In. We recall a few notations from information theory (Shannon, 1948; Cover &
Thomas, 2006). The entropy of a random variable U, is defined as h(U) := -EpU [log(pU (U))],
where U is the domain of U. The mutual information between two random variables U and V
is denoted by I (U; V ):= Ep(u,v Jlog (PpUVpVv)) ]- Sometimes, we will denote Ip(U; V), to
specify the PDF, p, of the variables (U, V).
1.2	Related Work
In causal inference, the algorithm is provided with a dataset of matched samples (x, y) of two
random variables X and Y and decides whether X causes Y or vice versa. The early wisdom
2
Under review as a conference paper at ICLR 2020
in this area asserted that this asymmetry of the data generating process (i.e., that Y is computed
from X and not vice versa) is not apparent from looking at PX,Y alone. That is, in general, provided
with samples from the joint distribution PX,Y of two variables X, Y does tell us whether it has been
induced by an SCM from X to Y or from Y to X .
In publications such as (Pearl, 2009; Spirtes et al., 2000) it is argued that in order to decide whether
X causes Y or vice versa, one needs to observe the influence of interventions on the environment
parameter. To avoid employing interventions, most publications assume prior knowledge on the
generating process and/or independence between the cause and the mechanism.
Various methods for causal inference under the SCM model have been suggested. Many of
these methods are based on independence testing, where the algorithm models the data as Y =
g(f (X), E) (and vice versa) and decides upon the side that provides a better fitting in terms of map-
ping accuracy and independence between f(X) and E = r(X, Y ). The LiNGAM (Shimizu et al.,
2006) algorithm assumes that the SCM takes the form Y = βX + E, where X E and β ∈ R and
E is non-Gaussian. The algorithm learns β, such that, X and Y - βX are independent by applying
independent component analysis (ICA for short). The Direct-LiNGAM (Shimizu et al., 2011) ex-
tends this method and replaces the mutual information minimization with a non-parametric kernel
based loss (Bach & Jordan, 2003). However, the computation of this loss is of order Θ(m2) in the
the worst case (m is the number of samples).
The ANM approach (Hoyer et al., 2009) extends LiNGAM’s modeling and assumes that Y =
f (X ) + E, where X E . In their modeling they employ a Gaussian process for the learned mech-
anism between the two random variable. The function f is trained to map between X and Y (and
vice versa) and the method then tests whether, X and f(X) - Y are independent. The independence
test is based on kernels (Gretton et al., 2005).
A different extension of LiNGAM is the PNL algorithm by Zhang & Hyvrinen (2010). This algo-
rithm learns a mapping between X and Y (and vice versa) of the form Y = g(f (X) + E), where
f (X ) and E are restricted to be independent. To do so, PNL trains two neural networks f and g to
minimize the mutual information between f(X) and E = g-1(Y ) - f(X). The main disadvantage
of this methods is the reliance on the minimization of the mutual information. It is often hard to
measure and optimize the mutual information directly, especially in higher dimensions. In many
cases, it requires having an explicit modeling of the density functions, because of the computation
of expected log-probability within the formulation of the entropy measure.
In our method, we take a similar approach to the above methods. However, our independence
constraint is non-parametric and is applied on the observations rather on an explicit modeling of
the density functions. In addition, we do not assume restrictive structural assumptions and treat
the generic case where the effect is of the form Y = g(f (X), E). In addition, our method is
computationally efficient.
Several other methods take different approaches. For example, the Information Geometric Causal
Inference algorithm (IGCI) (Daniusis et al., 2012) approach determines the causal relationship in a
deterministic setting Y = f (X) under an independence assumption between the cause X and the
mechanism f, Cov(log f0(x),pX) = 0.
The Conditional Distribution Similarity Statistic (CDS) (Fonollosa, 2016) measures the standard
deviation of the values of Y (resp. X) after binning in the X (resp. Y ) direction. The lower the
standard deivation, the more likely the pair to be X → Y . The CURE algorithm (Sgouritsa et al.,
2015) compares between X → Y and Y → X directions in the following manner: is given as
follows: if we can estimate pX|Y based on samples from pY more accurately than pY |X based on
samples from pX, then X → Y is inferred.
The BivariateFit method learns a Gaussian process regressor in both directions and decides upon the
side that had the lowest error. The RECI method (Bloebaum et al., 2018) trains a regression model in
both directions, and returns the side that produced a lower MSE loss. The utilized regression models
were: a logistic function, polynomial functions, support vector regression and neural networks. The
CGNN algorithm (Goudet et al., 2018) uses the Maximum Mean Discrepancy (MMD) distance
between the distribution produced by modeling Y as an effect ofX, (X, g(X, E)) (and vice versa),
and the ground truth distribution. The algorithm compares the two distances and returns the direction
that led to a smaller distance. The Gaussian Process Inference model (GPI) (Stegle et al., 2010)
3
Under review as a conference paper at ICLR 2020
builds two generative models, one for X → Y and one for Y → X. The distribution of the candidate
cause variable is modelled as a Gaussian mixture model, and the mechanism f is a Gaussian process.
The causal direction is determined from the generative model that best fits the data.
Finally, it is worth mentioning that several other methods, such as (Heinze-Deml et al., 2017; Zhang
et al., 2011) assume a different type of SCM, where the algorithm is provided with separate datasets
that correspond to different environments, i.e., sampled i.i.d from PX,Y |E, where the value of E
is fixed for all samples in the dataset. In these publications, a different independence condition is
assumed: Y is independent of E given X. This assumption typically fails in our setting. In our
paper, we focus on a vanilla SCM, where the algorithm is only provided with observational samples
ofX and Y = g(f (X), E) (i.i.d samples). The samples are not divided into subsets that are invariant
w.r.t E.
2	The Univariate Case
In this section, we intend to show that the univariate case is a bit simplistic. For this purpose, we
start by describing a method for identifying the cause and the effect, which considers each of the
two variables independently without considering the mapping between them. The method is based
on the statistics of the quantiles of each of the two distributions. In Sec. 2.2, we show that the
reconstruction error of an autoencoder is directly linked to the differential entropy of the distribution
it models.
2.1	A Method for Inferring Directionality
We hypothesize that due to the information PrOCessing inequality, the entropy of the CaUse h(X) in
the SCM model is higher than the entropy h(Y) of the effect. However, estimating the entropy of
each random Variable from its SamPleS does not PreSent a COnSiStent difference between the entropies
h(X)and h(Y).
OUr method,therefore,The proposed method computes an alternative a complexity score for X and,
independently, for Y. It then compares the scores and decides that the cause is the random variable
that has the larger score among them.
Our scoring function has a few stages. As a first step, it converts the random variable at hand
(say, X) into a multivariate random variable. This is done by sorting the samples of the random
variable, and then cutting the obtained list into fixed sized vectors of length k. We discard the
largest measurements in the case where the number of samples is not a multiple of k. We denote the
random variable obtained this way by U .
At the second stage, the method trains an autoencoder A : Rk → Rk on these quantile vectors.
Formally, A is trained to minimize the following objective:
Lrecon(A) ：= Eu〜U ['(A(u),u)]	(2)
where `(a, b) is some loss function. In our implementation, we employ the L2-loss function, defined
as `(a, b) = ka - bk22. Finally, the method uses the value ofLrecon(A), which we refer to as the AEQ
score, as a proxy for the complexity ofX (smaller loss means lower complexity). It decides that X
or Y is the cause, based on which side provides a higher AEQ.
2.2	Reconstruction Error as an Estimator of the Entropy
Next, we would like to provide better understanding of the AEQ method. Since we use the re-
construction error as a measure of complexity, we next link it to entropy, which is an acceptable
complexity measure. This will explain that the AEQ method estimates and compares the entropies
of the percentiles of X and Y . This does not imply that the AEQ method compares between the
entropies of X and Y .
The analysis This is done in the context of a learned variational autoencoder (VAE) (Kingma &
Welling, 2014), with a fixed latent space dimension.
We are given a real-valued vector-random-variable U (not necessarily quantiles) with a PDF pU(u).
We recall the setting of VAEs and the analysis of Zhao et al. (2017). The VAE model employs
4
Under review as a conference paper at ICLR 2020
a d dimensional latent variable Z 〜N(0, Id), and considers the family of the distribution pθ(u|z)
parameterized by θ ∈ Θ. The objective of this framework is to select θ that maximizes the likelihood
of the samples of U within pθ (u|z) ∙ P(Z),
Eu〜U [logPθ (u)] = Eu〜U
7
Rd
Pθ(u|z) ∙ P(Z) dz
(3)
where P(Z) = exp(-∣∣zk2∕2) ∙ (2π)-k∕2 is the PDF of Z and pθ(u) = pθ(u|z) ∙ p(z). Intypical
situations, We select pθ to be the PDF of a normal distribution N (fθ (z), σ2 ∙ In), where fθ (Z) ∈ F
is a learned neural network and σ12 is a variance hyperparameter of the framework. We denote by
P = {pθ (u∣z)∣z ∈ Rd, θ ∈ Θ} the class of density functions over X.
To optimize this objective, it is required to evaluate Pθ-1 (u), which involves the computation of a
high dimensional integral. Even though this integral can be approximated by sampling, this is a
costy process that has to be done for every sample u. To solve this problem, we have a second
distribution that is responsible to model the latent codes Z that are most probable given u. This PDF
is denoted by qΦ(z∣u) and corresponds to a normal distribution N(gφ(u), σ2 ∙ Id). Here, gφ(u) is a
neural network with parameters φ ∈ Φ.
Suppose we are given a fixed inference distribution qφ(Z∣u), which maps (probabilistically) inputs
U to features z. We denote by qφ(u, Z) := PU(u) ∙ qφ(Z∣u) the joint distribution of U and z, the
marginal q®(Z):= Ju qφ(u, Z)du and the posterior qφ(u∣Z) = qφ(Z∣u) ∙ PU(U)Iqφ(Z).
The optimization criterion is redefined as follows, where for each Z we use a member of a class of
distributions, P, to fit a different qφ(u∣Z) rather than the entire PU.
L =Eqφ(u,z) [logPθ (u|z)]	(4)
The following lemma links the reconstruction loss and the entropy (all proofs are in the appendix)
Lemma 1. In the setting of Sec. 2.2. Let θ* be the global optimum of Eq. 4 for a sufficiently large
F. Assume that P is sufficiently large, such that:
∀z ∈ Z, φ ∈ Φ : qφ(u∣Z) ∈ P	(5)
Then,
h(U) = 5^^2 ∙ Eu~U [Ee~N(0,Id) [∣∣fθ* (gφ(U) + σ2 ∙ Id ∙ E)- u∣∣2]]
2σ1	(6)
+ 2EgU [kgφ(u)k2] + d " 12- "2)) + 2log(2∏σ2)
2
Therefore, from this lemma, we observe that if gφ is learned, such that, the expected norm of the
encodings of u, Eu〜U [∣∣gφ(u)∣∣2] is bounded, then, the differential entropy h(U) is proportional
reconstruction error of the learned autoencoder. In particular, for two random variables U1 and U2 ,
their entropies can be compared, by considering the reconstruction error of their autoencoders with
the same hyperparameters (latent space dimension d, σ12, σ22, etc’).
3	The Multivariate Case
For the univariate case, one can consider the complexity of the X and Y variables of the SCM model
and infer directionality. We propose the AEQ complexity for this case, since more conventional
complexities are ill-defined for unordered 1D data or, in the case of entropy, found to be ineffective.
In the multivariate case, one can consider the complexity of the random variables in various ways.
We focus on the family of complexity measures C(X) that satisfy the assumption that when X and
Y are independent
C(X, Y) ≥ max(C(X), C(Y)).	(7)
Sample complexity measures that satisfy this condition are the Shannon Entropy and the Kol-
mogorov Complexity. Lem. 3 in Appendix. B.2 shows that the complexity that is based on au-
toencoder modeling is also in this family.
The next result shows that for any complexity measure C in this family, one cannot infer direction-
ality in the multivariate SCM based on C.
5
Under review as a conference paper at ICLR 2020
Lemma 2. Let C be a complexity measure of multivariate random variables (i.e, non-negative and
,∙ C L r ∖ rni	,»	, ■ I , r	ι	■ ι ι / λλ π ，7、	ι /	π ，7、	ι . ι .
satisfies Eq. 7). Then, there are triplets of random variables (X, E, Y ) and (X, E, Y ), such that,
Y = g(X, E), Y = g (X, E), C(X) < C(Y) and C(X) > C(Y). Therefore, C cannot serve as a
score for causal inference.
3.1	A Method for Causal Inference
The causality inference algorithm trains neural networks G, F, R and D. The success of fitting these
networks serves as the score for the causality test.
The function F models the function f, G models g and R(Y) aims to model the environment
parameter E . In general, our method aims at solving the following objective:
m
min Lerr(G, F, R) =	—	X kG(F(G	R(bi))	- bik2	小
G,F,R	m	i=1	(8)
s.t: A R(B)
where A is either X or Y and B is the other option, and ai = xi , bi = yi or ai = yi , bi = xi
accordingly. To decide whether X → Y or vice versa, we train a different triplet G, F, R for each
direction and see if we can minimize the translation error subject to independence. We decide upon
a specified direction if the loss can be minimized subject to independence. In general, searching
within the space of functions that satisfy A R(B) is an intractable problem. However, we can
replace it with a loss term that is minimized when A R(B).
Independence loss We would like R(B) to capture the information encoded in E. Therefore,
restrict R(B) and A to be independent in each other. We propose an adversarial loss for this purpose,
which is a modified version of a loss proposed by Brakel & Bengio (2017) and later analyzed by
(Press et al., 2019).
This loss measures the discrepancy between the joint distribution PA,R(B) and the product of the
marginal distributions PA × PR(B) . Let dF (dR) be the dimension of F’s output (R). To measure
the discrepancy, we make use of a discriminator D : Rn+dR → [0, 1] from a class C that maximizes
the following term:
1m	1
LD(D； R) = m ɪ2 `(D 3, R(bi)), 1) + m
i=1
m
X '(D(ai,R(bi)), 0)
i=1
(9)
where D is a discriminator network, and l(p, q) = -(q log(p) + (1 - q) log(1 - p)) is the binary
cross entropy loss for P ∈ [0,1] and q ∈ {0,1}. In addition, {(ai, bi)}m=ι are i.i.d samples from
PA X PB .To create such samples, We can simply generate samples from ai 〜PA and b 〜PB
independently and then arbitrarily match them into couples (ai, bi).
To restrict that R(B) and A are independent, We train R to fool the discriminator D and to convince
it that the tWo sets of samples are from the same distribution,
1m	1
LindeP(R; D)= m ɪ2 '(D(Oi, R(bi)), 1) + 三
i=1
m
X '(D(ai ,R(bi)), 1)
i=1
(10)
Full objective The full objective of our method is then translated into the folloWing program:
min Lerr(G, F, R) + λι ∙Li∏dep(R; D)
G,F,R	(11)
min LD (D; R)
Where λ1 is some positive constant. The discriminator D minimizes the loss LD (D; R) concur-
rently With the other netWorks. We denote by creal the percentage of samples (ai, bi) that the dis-
CnminatOr classifies as 1 and by Cfake the percentage of samples (^i, bi) that are classified as 0.
We note that When creal + cfake ≈ 1, the discriminator is unable to discriminate betWeen the tWo
distributions, i.e., it is Wrong in classifying half of the samples.
Our method decides ifX causes Y or vice versa by comparing the score Lerr(G, F, R). A loWer error
means a better fit. The full description of the architecture employed for the encoders, generator and
discriminator is given in Appendix. A.
6
Under review as a conference paper at ICLR 2020
3.2 Analysis
In this section, we analyze the proposed method. In Thm. 1, we show that if X and Y admit a SCM
in one direction, then it admits a SCM in the opposite direction only if the involved functions satisfy
a specific partial differential equation.
Theorem 1 (Identifiability of neural SCMs). Let PX,Y admit a neural SCM from X to Y as in Eq. 1,
such that pX, and the activation functions of f and g are three-times differentiable. Then it admits
a neural SCM from Y to X only ifpX, f, g satisfy Eq. 34 in the Appendix.
This result generalizes the one-dimensional case presented in (Zhang & Hyvrinen, 2010), where a
one-dimensional version of this differential equation is shown to hold in the analog case.
In the following theorem, we show that minimizing the proposed losses is sufficient to recover the
different components, i.e., F(X) 8 f (X) and R(Y) 8 E, where A α B means that A = f (B) for
some invertible function f .
Theorem 2 (Uniqueness of Representation). Let PX,Y admit a nonlinear model from X to Y as in
Eq. 1, i.e., Y = g(f (X), E) for some random variable E X. Assume that f and g are invertible.
Let G, F and R be functions, such that, Lerr ：= E(x,y)〜(x,y)[∣∣G(F(x), R(y)) - yk2] = 0 and G
and F are invertiblefUnctions and XdLR(Y). Then, F(X) H f(X) and R(Y) H E.
Here, LerT ：= E(x,y)〜(x,y)[∣∣G(F(x),R(y)) — y∣∣2] is the mapping error proposed in Eq. 8. In
addition, the assumption X R(Y) is sufficed by the independence loss. In Lem. 6 in Appendix. B.3
we extend this lemma to the case where the mapping loss is not necessarily zero and get rid of the
assumption that G is invertible. In this case, instead of showing that R(Y) H E, we provide an upper
bound on the reconstruction of E out of R(Y) (and vice versa) that improves as Lerr decreases.
We note that when the entropy of R(Y) is smaller than the entropy of E, then, the independence
X R(Y) follows, even without the discriminator. Typically, when R has a limited capacity (i.e.,
small number of layers or output dimension), then, the entropy of R(Y) is limited as well.
Theorem 3 (Emergence of independent representations). Let PX,Y admits a nonlinear model
from X to Y as in Eq. 1, i.e., Y = g(f (X), E) for some random variable E X. As-
sume that X and Y are discrete random variables. Let G, F and R be functions, such that,
Lerr := E(x,y)〜(x,y )[kG(F (x), R(y)) 一 y∣∣2] = 0 and G is an invertible function. Assume that
h(R(Y)) ≤ h(E) and that g is invertible. Then, we have: F(X) R(Y), F(X) H f(X) and
R(Y) H E.
To conclude this section, by Thm. 1, under reasonable assumptions, ifX and Y admit a multivariate
SCM in direction X → Y, then, there is no such representation in the other direction. By Thm. 2,
by training our method in both directions, one is able to capture the causal model in the correct
direction. This is something that is impossible to do in the other direction by Thm. 1. By Thm. 3,
we show that in cases where h(R(Y)) ≤ h(E), the independence between F(X) and R(Y) emerges
implicitly. This is the typical case, when R’s capacity is limited.
4 Experiments
This section is divided into two parts. The first, is devoted to showing that causal inference in
the one-dimensional case highly depends on the complexities of the distributions of X and Y. In
the second part of this section, we show that our multivariate causal inference method outperforms
existing baselines. Most of the baseline implementations were taken from the Causality Discovery
Toolbox of Kalainathan & Goudet (2019). The experiments with PNL (Zhang & Hyvrinen, 2010),
LiNGAM (Shimizu et al., 2006) and GPI (Stegle et al., 2010) are based on their original matlab
code.
4.1	One-Dimensional Data
We compared the autoencoder method on several well-known one dimensional cause-effect pairs
datasets. Each dataset consists of a list of pairs of real valued random variables (X, Y) with their
direction 1 or 0 depending on X → Y or Y → X (resp.). For each pair, we have a dataset of
samples {(xi, yi)}im=1.
7
Under review as a conference paper at ICLR 2020
Five cause-effect inference datasets, covering a wide range of associations, are used. CE-
Net (Goudet et al., 2018) contains 300 artificial cause-effect pairs generated using random distribu-
tions as causes, and neural networks as causal mechanisms. CE-Gauss contains 300 artificial cause-
effect pairs as generated by Mooij et al. (2016), using random mixtures of Gaussians as causes, and
Gaussian process priors as causal mechanisms. CE-Multi (Goudet et al., 2018) contains 300 artifi-
cial cause-effect pairs built with random linear and polynomial causal mechanisms. In this dataset,
simulated additive or multiplicative noise is applied before or after the causal mechanism.
The real-world datasets include the diabetes dataset by Frank & Asuncion (2010), where causality
is from Insulin → Glucose. Glucose curves and Insulin dose were analysed for 69 patients, each
serves as a separate dataset. To match the literature protocols, the pairs are taken in an orderless
manner, ignoring the time series aspect of the problem. Finally, the Tubingen cause-effect pairs
dataset by Mooij et al. (2016) is employed. This dataset is a collection of 100 heterogeneous, hand-
collected, real-world cause-effect samples.
The autoencoder employed in our method is a fully-connected 5-layered neural network with 3 layers
for the encoder and 2 layers for the decoder. The hyperparameters of this algorithm are the sizes of
each layer, the activation function and the input dimension, i.e., length of sorted cuts (denoted by
k in Sec. 2). Throughout the experiments, we noticed that the hyperparameter that has the highest
influence is the input dimension. For all datasets results are stable in the range of 200 ≤ k ≤ 300,
and we therefore use k = 250 throughout the experiments. For all dataset we employed the ReLU
activation function, except the Tubingen dataset, where the sigmoid activation function produced
better results (results are also reasonable with ReLU, but not state of the art).
In addition to our method, we also employ the entropy of each individual variable as a complexity
method. This is done by binning the values of the variables into 50 bins. Other numbers of bins
produce similar results.
Tab. 1 presents the mean AUC for each literature benchmark. As can be seen, the AEQ complexity
measure produces reasonable results in comparison to the state of the art methods, indicating that
the 1D SCM model can be overcome by comparing per-variable scores. On the popular Tubingen
dataset, the One-Sided AEQ computation outperforms all literature methods.
Tab. 2 presents accuracy rates for various methods on the Tubingen dataset, where such results are
often reported in the literature. As can be seen, our simple method outperforms almost all other
methods, including methods that employ supervised learning of the cause-effect relation.
4.2	Multivariate Data
We compared our method on several synthetic datasets. Each dataset consists ofa list of pairs of real
multivariate random variables (X, Y ) with their direction 1 or 0, depending on X → Y or Y → X
(resp.). For each pair, we have a dataset of samples {(xi, yi)}im=1.
We employ five datasets, covering multiple associations. Each dataset contains 300 artificial cause-
effect pairs. The cause random variable is of the form X = h(z), where h is some function and
Z 〜N(0,σ2 ∙ In). The effect is of the form Y = g(u(X,E)), where E 〜N(0,σ2 ∙ In) is
independent of X, u is a fixed function that combined the cause X and the noise term E and g is the
causal mechanism. For each dataset, the functions h and g are taken from the same family of causal
mechanisms H. Each pair of random variables is specified by randomly selected functions h and g.
MCE-Poly is generated element-wise polynomials composed on linear transformations as mech-
anisms and u(X, E) = X + E. MCE-Net pairs are generated using neural networks as causal
mechanisms and u is the concatenation operator. The mechanism in MCE-SigMix consists of linear
transformation followed by element wise application of qa,b,c(x) := ab(X + c)/1 + |b ∙ (x + c)|,
where a, b, C are random real valued numbers, which are sampled for each pair and x = x + e, where
e is the environment random variable. In this case, u(X, E) = X + E.
In order to create each one of the synthetic datasets we took the standard synthetic data generators of
Kalainathan & Goudet (2019) and extended them to produce multivariate causal pairs. We noticed
that a-priori, the produced datasets are imbalanced in a way that the reconstruction error of a standard
autoencoder on each random variable can be employed as a score that predicts the cause variable
with a high accuracy. Therefore, in order to create balanced datasets, we varied the amount of noise
8
Under review as a conference paper at ICLR 2020
Table 1: Mean AUC rates of various baselines on different one dimensional cause-effect pairs
datasets. Our simple AEQ algorithm achieves competitive results on most datasets.
Dataset
Method	CE-Net	CE-Gauss	CE-Multi	Tubingen	Diabetes
BivariateFit	77.6	36.3	55.4	58.4	0.0
LiNGAM (Shimizu et al., 2006)	43.7	66.5	59.3	39.7	100.0
CDS (Fonollosa, 2016)	89.5	84.3	37.2	59.8	12.0
IGCI (Daniusis et al., 2012)	57.2	33.2	80.7	62.2	100.0
ANM (Hoyer et al., 2009)	85.1	88.9	35.5	53.7	22.2
PNL (Zhang & Hyvrinen, 2010)	75.5	83.0	49.0	68.1	28.1
GPI (Stegle et al., 2010)	88.4	89.1	65.8	66.4	92.9
RECI (Bloebaum et al., 2018)	60.0	64.2	85.3	62.6	95.4
CGNN (Goudet et al., 2018)	89.6	82.9	96.6	79.8	34.1
Entropy as a complexity measure	49.6	49.7	50.8	54.5	53.4
Our AEQ comparison	62.5	71.0	96.0	82.8	95.0
Table 2: Accuracy rates of various baselines on the CE-Tub dataset. Our simple algorithm AEQ
achieves almost SOTA accuracy.
Method	Supervised	Acc
LiNGAM (ShimizU et al., 2006)	-	44.3%
BivariateFit	-	44.9%
Entropy as a complexity measure	-	52.5%
IGCI (Daniusis et al., 2012)	-	62.6%
CDS (Fonollosa, 2016)	-	65.5%
ANM (Hoyer et al., 2009)	-	59.5%
CURE (Sgouritsa et al., 2015)	-	60.0%a
GPI (Stegle et al., 2010)	-	62.6%
PNL (Zhang & Hyvrinen, 2010)	-	66.2%
CGNN (Goudet et al., 2018)	-	74.4%
RECI (Bloebaum et al., 2018)	-	77.5%
SLOPE (Marx & Vreeken, 2017)	-	81.0%
Our AEQ comparison	-	80.0%
Jarfo (Fonollosa, 2016)	+	59.5%
RCC (Lopez-Paz et al., 2015)	+	75.0%b
NCC (Lopez-Paz et al., 2017)	+	79.0%
aThe accuracy of CURE is reported on version 0.8 of the dataset in (Sgouritsa et al., 2015) as 75%. In Bloe-
baum et al. (2018) they reran this algorithm and achieved an accuracy rate around 60%.
bThe accuracy scores reported in (Lopez-Paz et al., 2015) are for version 0.8 of the dataset, in (Lopez-Paz
et al., 2017) they reran RCC (Lopez-Paz et al., 2015) on version 1.0 of the dataset.
dimensions and their intensity until the autoencoder reconstruction error of both X and Y became
similar. Note that for these multivariate variables, we do not use quantiles and use the variables
themsevles. As the AutoEncoder reconstruction results in Tab. 3 show, in the MCE-SigMix dataset
balancing was only partly successful.
In Tab. 3 we also compare our method to BivariateFit and ANM (Hoyer et al., 2009) algorithms
on these datasets and present favorable performance. The other literature methods are designed
for the univariate case and therefore, we were unable to extend them. The only baseline methods
that are extendable to multi dimensions are PNL (Zhang & Hyvrinen, 2010), CGNN (Goudet et al.,
2018) and RECI (BloebaUm et al., 2018). However, their runtime becomes too long. SPeCfiCally,
However, RECI’s runtime is of order O(n3), where n is the input dimension.
9
Under review as a conference paper at ICLR 2020
Table 3: Mean AUC rates of various baselines on different multidimensional dimensional cause-
effect pairs datasets. The datasets are designed and balanced, such that an autoencoder method
would fail. Our method achieves SOTA results.
Method	MCE-Poly	MCE-Net	MCE-SigMix	MOUS-MEG
BivariateFit	54.7	48.4	48.2	44.2
ANM (Hoyer et al., 2009)	52.2	51.1	46.4	52.4
PNL (Zhang & Hyvrinen, 2010)	76.4	54.7	16.8	56.3
CGNN (Goudet et al., 2018)	47.8	67.8	58.8	40.9
AE reconstruction	57.2	42.4	22.3	41.2
Our method	95.3	70.0	98.5	87.6
In addition to the synthetic dataset, we also employ the MOUS-MEG real world dataset, provided
to us by the authors of (Anonymous, 2020). This dataset is part of Mother Of Unification Studies
(MOUS) dataset (Schoffelen et al., 2019). This dataset contains magneto-encephalography (MEG)
recordings of 102 healthy dutch-speaking subjects performing a reading task (9 of them were ex-
cluded due to corrupted data). Each subject was asked to read 120 sentences in Dutch, both in the
right order and randomly mixed order, which adds up to a total of over 1000 words. Each word
was presented on the computer screen for 351ms on average and was separated from the next word
by 3-4 seconds. Each time step consists of 301 MEG readings of the magnetometers, attached to
different parts of the head. For more information see (Schoffelen et al., 2019). For each pair (X, Y ),
X is the interval [-1.5s, -0.5s] relative to the word onset concatenated with the word embedding
(using the spaCy python module with Dutch language model), this presents the subject in his “rest”
state (i.e. the cause). Y is the interval [0, 1.0s] relative to the word onset, which presents the subject
in his “active” state (i.e. the effect). The results, also given in Tab. 3 show a clear advantage over
the literature methods.
To validate the soundness of the dataset, we ran made a few experiments on variations of the dataset
and report the results in Tab. 4. As can be seen, a dataset where the cause consists of the word
embedding and the effect consists of the subject’s “active” state is highly imbalanced. This is rea-
sonable since the word embedding and the MEG readings are encoded differently and are of different
dimensions. In addition, when the cause is selected to be the “rest” state and the effect is the “active”
state, the various algorithms are unable to infer which side is the cause and which one is the effect
since the word is missing.
Emergence of independence To check the importance of our adversarial loss in identifying the
direction of causality and capturing the implicit independent representation f (X) and E, we applied
our method without training R against the discriminator. Therefore, in this case, the discriminator
only serves as a test whether X and R(Y ) are independent or not. Recall that our analysis shows
that the discriminator is not necessary under reasonable conditions. As can be seen in Tab. 5, the
adversarial loss improves the results when there is no implicit emergence of independence, however,
in cases where there is emergence of independence, the results are similar. This is Verfied in Tab. 5,
Which ShoWs Similar Performance With and WithoUt the discriminator.
As mentioned in Sec. 3.1, the distance between creal + cfake to 1 indicates the amount of dependence
betWeen X and R(Y ). We denote by Ind C the mean values of |creal + cfake - 1| over all pairs
of random variables, epochs and samples When training our method in the causal direction. The
same mean score When training in the anti-causal direction is denoted Ind E. As is evident from
Tab. 5, the independence is similar betWeen the tWo directions, emphasizing the importance of the
reconstruction error in the score.
We noticed that the values of Ind C and Ind E are smaller for the full method. HoWever, in MCE-Poly
and MCE-SigMix they are still very small, and therefore, there is implicit emergence of indepen-
dence betWeen X and R(Y ), even Without explicitly training R(Y ) to be independent of X. This
can explain the fact that the drop in the AUC is significant but not drastic.
10
Under review as a conference paper at ICLR 2020
Table 4: Results of various methods on different variations of the MOUS-MEG dataset.
Method	Dataset Rest, Word → Active Rest → Active Word → Active
BivariateFit ANM (Hoyer et al., 2009) AE reconstruction Our method	44.2	58.1	0.0 52.4	49.3	0.0 41.2	51.7	98.6 87.6	44.4	0.0
Table 5: Emergence of independence. Ind C (Ind E) is the mean of |creal + cfake - 1| over all pairs
of random variables, epochs and samples, when training the method from X to Y (vice versa). w/o
backprop means without backpropagating gradients from D to R.
Full method	w/o backprop
Dataset	AUC	Ind C	IndE	AUC	Ind C	Ind E
MCE-Poly	95.3	0.06	0.05	95.1	0.10	0.10
MCE-Net	70.0	0.16	0.20	65.1	0.55	0.55
MCE-SigMix	98.5	0.05	0.06	98.8	0.16	0.20
MOUS-MEG	87.6	0.61	0.61	80.7	0.74	0.75
5 Summary
We identify an inbalance in the complexities of cause and effect in the UnidimensionaI SCM model
and suggest a method to exploit it. Since the method does not consider the interactions between the
variables, its success in predicting cause and effect indicates an inherent bias in the unidimensional
datasets. Turning our attention to the multivariate case, where the complexity can be actively bal-
anced, we propose a new method in which the learned networks models the underlying SCM model
itself. Since the noise term E is unknown, we replace it by a function of Y that is enforced to be
independent of X. We also show that under reasonable conditions, the independence emerges even
without explicitly enforcing it.
References
Anonymous. Measuring causal influence with back-to-back regression: the linear case. In
Submitted to International Conference on Learning Representations, 2020. URL https:
//openreview.net/forum?id=B1lKDlHtwS. under review.
Francis R. Bach and Michael I. Jordan. Kernel independent component analysis. J. Mach. Learn.
Res., 3:1-48, MarCh 2003.ISSN 1532-4435. doi: 10.1162/153244303768966085. URL https:
//doi.org/10.1162/153244303768966085.
Patrick Bloebaum, Dominik Janzing, Takashi Washio, Shohei Shimizu, and Bernhard Schoelkopf.
Cause-effect inference by comparing regression errors. In Amos Storkey and Fernando Perez-
Cruz (eds.), Proceedings of the Twenty-First International Conference on Artificial Intelligence
and Statistics, volume 84 of Proceedings of Machine Learning Research, pp. 900-909, Playa
Blanca, Lanzarote, Canary Islands, 09-11 Apr 2018. PMLR.
Philemon Brakel and Y Bengio. Learning independent features with adversarial nets for non-linear
ica. 2017.
Thomas M. Cover and Joy A. Thomas. Elements of Information Theory (Wiley Series in Telecom-
munications and Signal Processing). Wiley-Interscience, New York, NY, USA, 2006. ISBN
0471241954.
Povilas Daniusis, Dominik Janzing, Joris M. Mooij, Jakob Zscheischler, Bastian Steudel, Kun
Zhang, and Bernhard Scholkopf. Inferring deterministic causal relations. CoRR, 2012.
11
Under review as a conference paper at ICLR 2020
M. Feder and N. Merhav. Relations between entropy and error probability. IEEE Transactions on
Information Theory, 40(1):259-266, Jan 1994.
Jose A. R. Fonollosa. Conditional distribution variability measures for causality detection. ArXiv,
abs/1601.06680, 2016.
A. Frank and A. Asuncion. UCI machine learning repository, 2010. http://archive.ics.uci.edu/ml.
Olivier Goudet, Diviyan Kalainathan, Philippe Caillou, David Lopez-Paz, Isabelle Guyon, and
MicheIe Sebag. Learning functional causal models with generative neural networks. In Ex-
plainable and Interpretable Models in Computer Vision and Machine Learning, Springer Series
on Challenges in Machine Learning. Springer International Publishing, 2018.
Arthur Gretton, RalfHerbrich, Alexander Smola, Olivier Bousquet, and Bernhard Scholkopf. Kernel
methods for measuring independence. J. Mach. Learn. Res., 6:2075-2129, December 2005. ISSN
1532-4435. URL http://dl.acm.org/citation.cfm?id=1046920.1194914.
Christina Heinze-Deml, Jonas Peters, and Nicolai Meinshausen. Invariant causal prediction for
nonlinear models. Journal of Causal Inference, 6, 2017.
Patrik O. Hoyer, Dominik Janzing, Joris M Mooij, Jonas Peters, and Bernhard Scholkopf. Nonlin-
ear causal discovery with additive noise models. In D. Koller, D. Schuurmans, Y. Bengio, and
L. Bottou (eds.), Advances in Neural Information Processing Systems 21, pp. 689-696. Curran
Associates, Inc., 2009.
Diviyan Kalainathan and Olivier Goudet. Causal discovery toolbox: Uncover causal relationships
in python, 2019.
Diederik P. Kingma and Max Welling. Auto-encoding variational bayes. In 2nd International
Conference on Learning Representations, ICLR 2014, Banff, AB, Canada, April 14-16, 2014,
Conference Track Proceedings, 2014.
D. Lopez-Paz, R. Nishihara, S. Chintala, B. Scholkopf, andL. Bottou. Discovering causal signals in
images. In Proceedings IEEE Conference on Computer Vision and Pattern Recognition (CVPR)
2017, pp. 58-66, Piscataway, NJ, USA, July 2017. IEEE.
David Lopez-Paz, Krikamol Muandet, Bernhard Schlkopf, and Iliya Tolstikhin. Towards a learning
theory of cause-effect inference. In Francis Bach and David Blei (eds.), Proceedings of the 32nd
International Conference on Machine Learning, volume 37 of Proceedings of Machine Learning
Research, pp. 1452-1461, Lille, France, 07-09 Jul 2015. PMLR.
A. Marx and J. Vreeken. Telling cause from effect using mdl-based local and global regression. In
2017 IEEE International Conference on Data Mining (ICDM), pp. 307-316, Nov 2017.
Joris M. Mooij, Jonas Peters, Dominik Janzing, Jakob Zscheischler, and Bernhard Scholkopf. Dis-
tinguishing cause from effect using observational data: Methods and benchmarks. Journal of
Machine Learning Research, 17(32):1-102, 2016.
Judea Pearl. Causality: Models, Reasoning and Inference. Cambridge University Press, New York,
NY, USA, 2nd edition, 2009. ISBN 052189560X, 9780521895606.
J. Peters, D. Janzing, and B. Scholkopf. Elements of Causal Inference - Foundations and Learning
Algorithms. Adaptive Computation and Machine Learning Series. The MIT Press, Cambridge,
MA, USA, 2017.
Ori Press, Tomer Galanti, Sagie Benaim, and Lior Wolf. Emerging disentanglement in auto-encoder
based unsupervised image content transfer. In International Conference on Learning Representa-
tions, 2019.
Jan-Mathijs Schoffelen, Robert Oostenveld, Nietzsche HL Lam, Julia Udden, Annika Hulten, and
Peter Hagoort. A 204-subject multimodal neuroimaging dataset to study language processing.
Scientific data, 6(1):17, 2019.
12
Under review as a conference paper at ICLR 2020
Eleni Sgouritsa, Dominik Janzing, Philipp Hennig, and Bernhard Schlkopf. Inference of Cause and
Effect with Unsupervised Inverse Regression. In Guy Lebanon and S. V. N. Vishwanathan (eds.),
Proceedings of the Eighteenth International Conference on Artificial Intelligence and Statistics,
volume 38 of Proceedings of Machine Learning Research, pp. 847-855, San Diego, California,
USA, 09-12 May 2015. PMLR.
Claude Elwood Shannon. A mathematical theory of communication. The Bell System Technical
Journal, 27(3):379-423, 7 1948. doi: 10.1002/j.1538-7305.1948.tb01338.x. URL https://
ieeexplore.ieee.org/document/6773024/.
Shohei Shimizu, Patrik O. Hoyer, Aapo Hyvarinen, and Antti Kerminen. A linear non-gaussian
acyclic model for causal discovery. J. Mach. Learn. Res., 7:2003-2030, December 2006. ISSN
1532-4435.
Shohei Shimizu, Takanori Inazumi, Yasuhiro Sogawa, Aapo Hyvarinen, Yoshinobu Kawahara,
Takashi Washio, Patrik O. Hoyer, and Kenneth Bollen. Directlingam: A direct method for learn-
ing a linear non-gaussian structural equation model. J. Mach. Learn. Res., 12:1225-1248, July
2011. ISSN 1532-4435. URL http://dl.acm.org/citation.cfm?id=1953048.
2021040.
John R. Silvester. Determinants of block matrices. The Mathematical Gazette, pp. 2000, 1999.
P. Spirtes, C. Glymour, and R. Scheines. Causation, Prediction, and Search. MIT press, 2nd edition,
2000.
Oliver Stegle, Dominik Janzing, Kun Zhang, Joris M Mooij, and Bernhard Scholkopf. Probabilistic
latent variable models for distinguishing between cause and effect. In J. D. Lafferty, C. K. I.
Williams, J. Shawe-Taylor, R. S. Zemel, and A. Culotta (eds.), Advances in Neural Information
Processing Systems 23, pp. 1687-1695. Curran Associates, Inc., 2010.
Kun Zhang and Aapo Hyvrinen. Distinguishing causes from effects using nonlinear acyclic causal
models. In Isabelle Guyon, Dominik Janzing, and Bernhard Schlkopf (eds.), Proceedings of
Workshop on Causality: Objectives and Assessment at NIPS 2008, volume 6 of Proceedings of
Machine Learning Research, pp. 157-164, Whistler, Canada, 12 Dec 2010. PMLR.
Kun Zhang, Jonas Peters, Dominik Janzing, and Bernhard Scholkopf. Kernel-based conditional
independence test and application in causal discovery. In Proceedings of the Twenty-Seventh
Conference on Uncertainty in Artificial Intelligence, UAI’11, pp. 804-813, Arlington, Virginia,
United States, 2011. AUAI Press. ISBN 978-0-9749039-7-2. URL http://dl.acm.org/
citation.cfm?id=3020548.3020641.
Shengjia Zhao, Jiaming Song, and Stefano Ermon. Towards deeper understanding of variational
autoencoding models. ArXiv, abs/1702.08658, 2017.
13
Under review as a conference paper at ICLR 2020
A	Architecture
The function G, F, R and D in the multivariate method in Sec. 3 are fully connected neural networks
and their architectures are as follows: F is a 2-layered network with dimensions 100 → 60 → 50,
R is a 3-layered network with dimensions 100 → 50 → 50 → 20, G is a 2-layers neural network
with dimensions 50 + 20 → 80 → 100 (the input has 50 dimensions for F (X) and 20 for R(Y )).
The discriminator is a 3-layers network with dimensions 100 + 20 → 60 → 50 → 2 (the input is X
and R(Y )). The activation function in all networks is the sigmoid function except the discriminator
that applies the leaky ReLU activation. For all networks, the activation is not applied at the output
layer.
B Analysis
B.1	Terminology and Notations
We recall some relevant notations and terminology. The identity matrix of dimension n is denoted
by In. For a vector X = (xi,..., Xn) ∈ Rn We denote ∣∣χk2 := VzPn=I X the Euclidean norm of
x. For a differentiable function f : Rm → Rn and x ∈ Rm , we denote by
J(f(X)) :
(12)
∈[n],j∈[m]
the Jacobian matrix of f in X. For a tWice differentiable function f : Rm → R, We denote by
H(f(X)) :
∂ 2f
∂Zi∂Zj
(13)
,j∈[m]
the Hessian matrix of f in X. Additionally, for a tWice differentiable function f : Rm → Rn ,
f(X) = (f1(X), . . . ,fn(X)), We denote the Hessian of f by H(f(X)) := (H(f1(X)), . . . ,H(fn(X))).
For a scalar function f : Rm → R instead of using the Jacobian notation, the gradient notation Will
be employed, V(f (x)) := J(f (x)).
B.2	Autoencoder as a Complexity Measure
Let F = {Hd}d∞=1 be a family of classes of autoencoders A : Rd → Rd. Assume that the family
F is closed to fixations, i.e., for any autoencoder A ∈ Hd1+d2 and any fixed vector y* ∈ Rd2
(x* ∈ Rd1), we have: A(x,y*)i：di ∈ HdI(A(X*屈)电+1论 ∈ Hd2). Here, Vij = (vi,...,vj). We
consider that this is the typical situation When considering neural netWorks With biases.
Let X be a random variable. Let X be a multivariate random variable dimension d. We define the
autoencoding complexity of X as follows:
C(X； F) := min Ex〜X ['(A*(x),x)]	(14)
A*∈Hd
Lemma 3. Let {Hd}d∞=1 be a family of classes of autoencoders that is closed to fixations. The
function C(X; F) is a complexity measure according to Sec. 3.
Proof. First, since `(a, b) ≥ 0 for all a, b ∈ Rk, this function is non-negative. Next, we would like
to show that Cα(X, Y) ≥ max(C(X),C(Y)). Let A* be the minimizer of Ex〜X ['(A*(x), x)]
within Hd1+d2. We consider that there is a vector y*, such that,
E(x,y)〜(x,y)['(A(χ, y), (χ, y))] ≥Ey〜YEx〜X ['(A(χ, y), (χ,y))]
≥Ex〜X ['(A(x,y*), (x,y*))]	(15)
≥ Ex〜X ['(A(x,y*)i：di,x)]
We note that A(x, y*)1:d1 ∈ Hd1 . Therefore,
E(x,y)〜(X,Y) ['(A(x,y), (x,y))] ≥ Amindl Ex〜X ['(A*(x),x)] = C(X； F)	(16)
By similar considerations, C(X, Y; F).	□
14
Under review as a conference paper at ICLR 2020
B.3	Proofs for the Results
In this section We provide the proofs of the main results in the paper.
Lemma 1. In the setting of Sec. 2.2. Let θ* be the global optimum of Eq. 4 for a sufficiently large
F. Assume that P is sufficiently large, such that:
Then,
∀z ∈ Z, φ ∈ Φ : qφ(u∣z) ∈ P
h(U) =2σ2 ∙ Eu 〜U [Ee 〜N (0,Id) [kfθ* (gφ (U) + σ2 ∙ Id ∙ E)- uk2]]
(5)
+ 2Eu〜U [kgφ(U)k2] +
d ∙ (σ2 - 1 - log(σ2))
+2log(2πσ2)
(6)
2
Proof. This is a corollary of the analysis of Zhao et al. (2017). By their analysis, We have:
h(U) = Iqφ (z; U) - Eqφ [log pθ* (U|z)]
(17)
Since We selected pθ* (u|z) to be the PDF of a normal distribution N(fθ* (z), σ2 ∙ In'), We have:
log Pθ*(u∣z)
kfθ*(Z) - uk2 - n log(2∏σ2)
2σ1	2
(18)
—
Therefore, since Z distributed by qφ(z∣u) can be represented as z|u 〜gφ(u) + σ2 ∙ Id ∙ e, where
E 〜N(0,Id),
1n
-Eqφ(u,z) [logpθ* (u|z)] =2σ2 ∙ Eqφ(u,z) [kfθ* (Z) - uk] + 彳 log(2πσ1 )
1n
= 2σ2 ∙ Eu〜U [Eqφ(z∣u) [kfθ* (Z)- uk] ] + 2 log(2πσl )
= 2σ2 ∙ Eu〜U [Ee〜N(0,Id) [kfθ* (gφ(u) + σ2 ∙ Id ∙ E) - uk2]]
+2log(2πσ2)
In addition, We have:
Iqφ (z; u) = Eu〜U[DκL(qφ(z∣u)kp(z))]
=Eu〜U[Dkl(N(gφ(u),σ2 ∙ Id)IlN(0,Id))]
=Eu〜U 1 (d ∙ σ2 + kgφ(u)k2 + dlog(σ2))
(19)
(20)
d ∙ (σ2- 1- log(σ2))
2
Therefore, We obtained the desired equation.
+ 2Eu [kgΦ(U)k2]
□
Lemma 2. Let C be a complexity measure of multivariate random variables (i.e, non-negative and
,∙c L r ∖ rni	,»	, ■ I ,	「	1	- 7 1	/ ΛΛ π ，7、	7 / 命 π ，7、	ι . ι .
satisfies Eq. 7). Then, there are triplets of random variables (X, E, Y) and (X, E, Y), such that,
ʌ
ʌ
Y = g(X, E), Y = g (X, E), C(X) < C(Y) and C(X) > C(Y). Therefore, C cannot serve as a
score for causal inference.
Proof. Let X be a random variable and E X, such that, Y = g(X, E). Assume that C(X) <
C(Y ). Then, let X0 be a random variable independent of X, such that, C(X0) > C(Y ). Then, We
have: C(X, X0) > C(Y) and We have: Y = g0 (X, X0, E), for g0(a, b, c) = g(a, c).
□
The folloWing lemma is an extension of Thm. 1 in (Zhang & Hyvrinen, 2010) to real valued random
variables of dimension > 1.
15
Under review as a conference paper at ICLR 2020
(21)
(22)
(23)
Lemma 4. Assume that (X, Y ) can be described by both:
Y = g1(f1(X) + E1), s.t: X E1 and g1 is invertible
and
X = g2(f2(Y ) + E2), s.t: Y E2 and g2 is invertible
Assume that g1 and g2 are invertible and let:
Ti ：= g-1(Y) and hi ：= f2 ◦ gι
T2 := g2-1(X) and h2 := f1 ◦g2
Assume that the involved densities pT2, pE1 and nonlinear functions fi, gi and f2, g2 are third order
differentiable. We then have the following equations for all (X, Y) satisfying:
H(η1(t2)) ∙ J(h1(t1)) — H(η2(e1)) ∙ J(h2(t2))
+ H(η2(ei)) ∙ J(h2(t2)) ∙ J(h1(t1)) ∙ J(h2(t2))	(24)
-V(η2(e1)) ∙ H(h2(t2)) ∙ J(h1(t1)) =0
whereηi(t2) := log pT2 (t2) andη2(ei) := logpE1(ei).
Proof. The proof is an extension of the proof of Thm. 1 in (Zhang & Hyvrinen, 2010). We define:
Ti := gi-i(Y) and hi := f2 ◦ gi
T2 := g2-i(X) and h2 := fi ◦g2
(25)
Since g2 is invertible, the independence between X and Ei is equivalent to the independence be-
tween T2 and Ei . Similarly, the independence between Y and E2 is equivalent to the independence
between Ti and E2. Consider the transformation F : (E2, Ti) 7→ (Ei, T2):
Ei =Ti -fi(X) =Ti -fi(g2(T2))
T2 =f2(Y)+E2 =f2(gi(Ti))+E2
The Jacobian matrix of this transformation is given by:
(26)
T ♦一 T< PYQC 九 N ——	—J(h2 (t2))	I I - J(h2(t2)) ∙J(hi(ti))]
J := J(F (e2 , ti )) =	I	J(h1(t1))
(27)
Since I commutes with any matrix, by Thm. 3 in (Silvester, 1999), we have:
I det(J(F(E2,T1)))∣ = det(-J(h2(T2)) ∙ J(h1(T1)) - I ∙ (I - J(h2(T2)) ∙ J(h1(T1)))) = 1
(28)
Therefore, we have:	pτ?(t2)	∙	pEι(ei)	=	PT1,E2(t1,e2)∕∣ det J|	=	pτ1,E2(t1,e2).	Hence,
log(pT1,E2 (ti, e2)) = ηi(t2) + η2(ei) and we have:
dIog(PT产(I,e2)) = Vη1(t2) -Vη2(e1) ∙ J(h2(t2))	(29)
Therefore,
"log(PT1,E2 (ti2" =H(η1(t2)) ∙ J(h1(t1)) — H(η2(e1)) ∙ (I — J(h2(t2)) ∙ J(h1(t1))) ∙ J(h2(t2))
∂e2 ∂ti
-V(η2(e1)) ∙ H(h2(t2)) ∙ J(h1(t1))
=H(η1(t2)) ∙ J(h1(t1)) — H(η2(e1)) ∙ J(h2(t2))
+ H(η2(e1)) ∙ J(h2(t2)) ∙ J(h1(t1)) ∙ J(h2(t2))
-V(η2(e1)) ∙ H(h2(t2)) ∙ J(hi(ti))
(30)
The independence between Ti and E2 implies that for every possible (ti, e2), we have:
d2 log PTi ,E2 (t1,e2)	Ll
∂e2∂t1	= 0.	LJ
16
Under review as a conference paper at ICLR 2020
Lemma 5 (Reduction to post-linear models). Let f(x) = σ1(Wd . . . σ1(W1x)) and g(u, v) =
σ2(Uk . . . σ2(U1(u, v))) be two neural networks. Then, if Y = g(f(X), E) for some E X, we
can represent Y = g(f (X) + N) for some N Il X.
Proof. Let f(x) = σ1(Wd . . . σ1(W1x)) and g(u, v) = σ2(Uk . . . σ2(U1(u, v))) be two neural
networks. Here, (u, v) is the concatenation of the vectors u and v. We consider that Uk(f(X), E) =
UIf(X) + U2E. We define a noise variable N := U2E and have: XJLN. In addition, let f(x):=
U1f(χ) andg(z) := σ2(Uk ...σ2(U2σ2(z))). Weconsiderthat: Y = g(f(X) + N) as desired. □
Theorem 1 (Identifiability of neural SCMs). Let PX,Y admit a neural SCM from X to Y as in Eq. 1,
such that pX, and the activation functions of f and g are three-times differentiable. Then it admits
a neural SCM from Y to X only ifpX, f, g satisfy Eq. 34 in the Appendix.
Proof. Let fi(z) = σ1(Wi,d . . . σ1(Wi,1z)) and gi(u,v) = σ2(Ui,k . . . σ2(Ui,1(u, v))) (where i
1, 2) be pairs of neural networks, such that, σ1 and σ2 are three-times differentiable. Assume that:
Y=g(f(X),E1)andX=g(f(Y),E2)
for some E1 X and E2 Y. By Lem. 5, we can represent
,ʌ ,
Y = ^1(f1(X) + N1),
where Ni = U2,1Eι, fι = U1,1fι(X) and g1(z) = σ2(U1,k ... σ2(U1,2σ2(z)))
and also,
,ʌ ,
X = g2(f2(Y) + N2),
where N = U2,1E2, f2 = U1,ιf2(X) and g2(z) = σ2(U2,k ...σ2(U2,2σ2(z)))
(31)
(32)
(33)
From the proof of Lem. 5, it is evident that the constructed gi, fi and ^1,f2 are three-times differ-
entiable whenever σi and σ2 are. Therefore, by Thm. 1, the following differential equation holds:
H(ηi(t2)) ∙ J(h1(t1)) - H(η2(ni)) ∙ J(h2(t2))
+ H(η2(n1)) ∙ J(h2(t2)) ∙ J(h1(t1)) ∙ J(h2(t2))	(34)
-V(η2(n1)) ∙ H(h2(t2)) ∙J(hι(tι)) = 0
where
T1 := ^-1(Y) and hi := ff ◦ gi	符,
T2 := ^-1(X) and h2 := fi ◦ ^2
and ηι(t2) := log»(t2) and η2(n1) := logPn (ni).	□
Theorem 2 (Uniqueness of Representation). Let PX,Y admit a nonlinear model from X to Y as in
Eq. 1, i.e., Y = g(f (X), E) for some random variable E X. Assume that f and g are invertible.
Let G, F and R be functions, such that, Lerr := E(x,y)〜(x,y)[∣∣G(F(x), R(y)) — yk2] = 0 and G
and F are invertiblefUnctions and X U R(Y). Then, F (X) H f (X) and R(Y) H E.
Proof. Since F and f are invertible, one can represent: F(X) = F(f-i(f(X))) and f(X) =
f(F-i(F(X))). Similarly, since G and g are invertible, we also have: (F(X), R(Y)) H
(f(X), E).	Since (F(X), R(Y))	H	(f(X),	E)	and	F(X)	H	f(X),	we have:	R(Y)	=
Q(F (X), E). However, R(Y) F(X) and therefore, we can represent R(Y) = P (E) and vice
versa.	□
Theorem 3 (Emergence of independent representations). Let PX,Y admits a nonlinear model
from X to Y as in Eq. 1, i.e., Y = g(f (X), E) for some random variable E X. As-
sume that X and Y are discrete random variables. Let G, F and R be functions, such that,
LerT := E(x,y)〜(x,y )[kG(F (x), R(y)) 一 y∣∣2] = 0 and G is an invertible function. Assume that
h(R(Y)) ≤ h(E) and that g is invertible. Then, we have: F(X) R(Y), F(X) H f(X) and
R(Y) H E.
17
Under review as a conference paper at ICLR 2020
Proof. Since g and f are invertible, we have: h(Y ) = h(f (X)) + h(E) ≤ h(X) + h(E). In
addition, we have: h(R(Y )) ≤ h(E). Therefore, since G is invertible, h(Y ) = h(F (X), R(Y )) ≤
h(F(X)) + h(R(Y)) ≤ h(X) + h(E) = h(Y). Hence, F(X) and R(Y) are independent. □
In the following three lemmas we extend Thms. 2 and 3.
Lemma 6. Let PX,Y admit a nonlinear model from X to Y as in Eq. 1, i.e., Y = g(f (X), E),
for some random variable E X. Assume that f and g are invertible. Assume that X and Y are
discrete and Y is over a set Y, such that, ∀y1 6= y2 ∈ Y, we have, ky1 - y2 k2 > ∆ > 0. Let G,
F and R be functions, such that, Lerr ：= E(x,y)〜(x,y ) [∣∣y — G(F (x), R(y))k2] < ∆∕2 and F is
invertible. Then, F(X) (X f (X) and I(R(Y); E) ≥(1 - 气)∙ h(E) - Lβjf.
Proof. First, since both F and f are invertible, F(X) 8 f (X). By the proof of Lem. 10 in (Press
et al., 2019), there is a function r, such that:
P(x,y)〜(X,Y)[r(F(X),R(y)) = y] ≥ (1-Lrr) ≥ 0.5
(36)
Since g is invertible, there is a function u(Y) = E. In particular,
P(x,y)〜(X,Y)[u(r(F(X),R(y))) = u(y)] ≥ (1 - Lrr) ≥ 0.5
(37)
Therefore, by Lem. 6 in (Press et al., 2019), we have:
I (F (X), R(Y )； E) ≥ (l - P) . h(© - h O - Lerr
(38)
By the analysis in the proof of Lem. 10 in (Press et al., 2019), we derive that:
I(F(X),R(Y); E) ≥(1 -L∆rr) ∙ h(E)-qLr
(39)
Finally, since F(X) is a function of X which is independent of E, we obtain the desired inequality:
I(R(Y )； E) ≥(1 —δf) ∙ h(E) - V ^eF
(40)
□
We mention that in Lem. 6, the function R(Y) can hold all of the information present in Y. There-
fore, in order to suffice that R(Y) holds only the information present in E, one can restrict that
h(R(Y)) ≤ h(E) + as will be shown in the next lemma. We note that under the conditions of
Lem. 6, h(R(Y)) ≤ h(E) + 1 is equivalent to I(F(X); R(Y)) ≤ 2 for 1, 2 that are functions of
each other.
Lemma 7. In the setting of Lem. 6. Assume that h(R(Y)) ≤ h(E) + , for some constant > 0.
Then, I(F(X); R(Y)) ≤ LgL ∙ h(Y) + ʌ L∆r + 邑 In addition, there arefunCtions ri, r?, such that,
P[r1(R(Y)) = E] ≤ 1 - 2-Lerr∙h(E)Zg-VLerrZg	(41)
and
P[r2(E) = R(Y)] ≤ 1 - 2-Lebh(E)∕g-√L≈r∕g-e	(42)
Proof. By Lem. 10 in Press et al. (2019), we have:
h(F(X),R(Y)) ≥ h(F(X),R(Y); Y) ≥
• h(Y) -
(43)
18
Under review as a conference paper at ICLR 2020
In addition, by the data processing inequality and the assumption h(R(Y )) ≤ h(E) +
I(F(X);R(Y)) ≤h(F(X))+h(R(Y))-h(F(X),R(Y))
≤h(X)+h(Y)+-
• h(Y) —
≤ h(Y) +-
• h(Y) -
≤L∆≡ • h(Y) + √Lf + e
Finally, by Feder & Merhav (1994), there is a function r1, such that,
P[r1 (R(Y)) 6= E] ≤ 1 - 2I(R(Y);E)-h(E)
≤ 1 - 2-Lerr∙h(E)/δ-√Lerr/δ
In addition, there is a function r2, such that,
P[r2(E) 6= R(Y)] ≤ 1 - 2I(R(Y );E)-h(R(Y ))
≤ 1 - 2I(R(Y );E)-h(E)-
≤ 1 - 2-Lerr∙h(E)/δ-√Lerr/ʌ-6
as desired.
, we have:
(44)
(45)
(46)
□
19