Under review as a conference paper at ICLR 2020
CPGAN: Toward s a Better Global Landscape
of GANs
Anonymous authors
Paper under double-blind review
Ab stract
GANs have been very popular in data generation and unsupervised learning, but
our understanding of GAN training is still very limited. One major reason is that
GANs are often formulated as non-convex-concave min-max optimization. As a
result, most recent studies focused on the analysis in the local region around the
equilibrium. In this work, we perform a global analysis of GANs from two per-
spectives: the global landscape of the outer-optimization problem and the global
behavior of the gradient descent dynamics. We find that the original GAN has ex-
ponentially many bad strict local minima which are perceived as mode-collapse,
and the training dynamics (with linear discriminators) cannot escape mode col-
lapse. To address these issues, we propose a simple modification to the original
GAN, by coupling the generated samples and the true samples. We prove that
the new formulation has no bad basins, and its training dynamics (with linear
discriminators) has a Lyapunov function that leads to global convergence. Our ex-
periments on standard datasets show that this simple loss outperforms the original
GAN and WGAN-GP.
1	Introduction
Generative Adversarial Networks (GANs) (Goodfellow et al., 2014) have been one of the most
popular methods for generating data. The original GAN minimizes the loss φ(pg , pdata) =
maxD hD (pg, pdata), where hD is a binary classification loss that depends on the discriminator
D. To justify the loss, Goodfellow et al. (2014) prove two theoretical results: first, for a given pg,
the outer function φ(pg, pdata) is the Jenson-Shannon (JS) distance (minus a constant); second, the
outer function is convex inpg, so a gradient descent method onpg converges to the global minimum.
In order to further understand the training behavior of GANs, there has been a surge of interest
in min-max optimization or games. One major challenge is the question about which problems
to analyze. The first candidates are the two-person matrix game minψ maxθ ψTAθ or general
convex-concave problems. But the GAN formulation is not a convex-concave problem. As stated
by Daskalakis & Panageas (2018), our knowledge of min-max optimization in non convex-concave
settings is “very limited.” Therefore, existing results often only analyze local stability or local con-
vergence (Daskalakis et al., 2017; Daskalakis & Panageas, 2018; Azizian et al., 2019; Gidel et al.,
2018; Mazumdaretal., 2019; Yazici etal., 2018; Jinetal., 2019; Sanjabi etal., 2018). Local analysis
can tell us the behavior of the algorithms near the desired point, but how do we know that the algo-
rithm will arrive there and not at some highly sub-optimal points? Answering this question requires
a global landscape analysis or a study of global training dynamics.
There are some attempts on a global analysis of GANs. Mescheder et al. (2018) and Feizi et al.
(2017) analyzed the simplest setting: the true data distribution is a single point and a single Gaussian
distribution respectively. In these cases, the training dynamics of some GANs can converge to the
globally optimal solution. Thus at least in the simplest single-mode setting, there is evidence that
the global landscape of (some) GANs is compelling. However, it remains unclear whether those
GANs have similarly nice properties in the multi-modal setting. Again, the difficulty here is that the
practical GAN formulation is not convex-concave, even for simple discriminators/generators. These
works and other related ones are reviewed in more detail in Appendix B.
Our contributions. In this work, we make a step towards understanding the global behavior of
GAN training, under multi-modal settings. We focus on analyzing GANs for learning a multi-point
1
Under review as a conference paper at ICLR 2020
distribution. This is a finite-sample version of the problem analyzed by Goodfellow et al. (2014),
and a multi-mode extension of the Dirac-GAN problem analyzed by Mescheder et al. (2018). We
approach the problem from two perspectives. First, we consider the min-max optimization problem
and analyze the landscape of the outer problem assuming powerful discriminators. This perspective
was used by Goodfellow et al. (2014). In contrast, as optimization variables we use the samples
Y instead of the probability density pg . Second, we consider the training dynamics of the game
formulation assuming linear discriminators. Our contributions are summarized as follows.
•	For the original GAN, we prove that the outer-minimization problem has exponentially
many sub-optimal strict local minima. Each strict local minima corresponds to a mode-
collapse situation.
•	For both the original GAN and WGAN-GP, we prove that with linear discriminators, the
training dynamics cannot escape from mode-collapse.
•	We propose a new GAN formulation called CP-GAN (CoupleGAN) that enjoys nice global
properties. From the first perspective, we prove that the outer-minimization problem of CP-
GAN has no bad strict local minima, improving upon the original GAN. From the second
perspective, we prove that with linear discriminators, the training dynamics of CP-GAN
can escape from mode-collapse; in addition, it has a global Lyapunov function that permits
to prove global convergence.
•	Our simulation results show that the new GAN performs better than WGAN-GP and the
original GAN in standard datasets, in terms of FID scores. Our modification to the loss
function has some similarity with the Wasserstein distance (coupling data points), but it
turns out it works better than WGAN-GP on all datasets we tested. We remark that CP-
GAN is orthogonal to other techniques such as spectral normalization Miyato et al. (2018),
thus we only compare with vanilla methods such as WGAN-GP.
Finally, we remark that CP-GAN is just one example of GAN problems with nice global properties,
and we hope our analysis can shed light on the design of other tractable GAN formulations.
Outline. The rest of the paper is structured as follows. We present the CP-GAN loss in Section 2,
and discuss our analysis framework in Section 3. In Section 4, we analyze the outer-optimization
problem of JS-GAN and the training dynamics of JS-GAN and W-GAN. In Section 5, we analyze
the outer-optimization problem and the training dynamics of CP-GAN. We evaluate its performance
on synthetic and standard datasets in Section 6. All proofs are in the Appendix.
2	New Loss: CP-GAN
In this section, we first review the formulation of GANs briefly. Next, we present the new formula-
tion of CP-GAN. The theoretical advantage of the new formulation will be discussed later.
2.1	Generative Adversarial Networks
We first review the formulation of the original GAN proposed by Goodfellow et al. (2014). Given
samples from a true data distribution pdata , we want to generate a new distribution pg to mimic
pdata. To judge how far away the generated distribution pg is from pdata, a discriminator (a.k.a.
critic) computes a loss value that measures their gap. This discriminator D addresses a binary
classification problem, which should yield 1 for the true data point and 0 for the generated data
point. The goal of the generator is to generate pg to fool the discriminator so that the loss value is
minimized. Formally, the problem for a GAN is given by
minmaχ Eχ~pdata,y~pg Iog(D(X)) +lOg(I - D(y)).	(I)
pg	D
A common choice for the discriminator is D(U) = i+exp；_f(u)), where f is a function. Given this
choice, the formulation given in Eq. (1) becomes
mgnmaχ Ex~pdata,y~pg lθg 彳而京)j + lθg	.
2
Under review as a conference paper at ICLR 2020
We will use a generator Gθ(z) parameterized by θ to produce samples from a distribution pg, where
z is drawn from a given distribution pz . This yields the following program:
min max Ex~Pdata,z~Pzlog 1 + eχp(-f(χ)) + log 1+eχp(f (G(Z))).
(2)
To resolve the vanishing gradient issue, Goodfellow et al. (2014) proposed to use a game formulation
(often referred to as non-saturating GAN):
mαχEχ~Pdata,z~Pz log ι + eχp(-f (χ)) + log ι+eχp(f (G(Z)))，	Ga)
miηEX~Pdata,Z~Pzlog(I + eχP(-f (G(Z)))).	Gb)
2.2	Coupling GAN
As mentioned before, the program is given in Eq. (3) has shortcomings, which we propose to address
via the following formulation:
minmaχEx~Pdata,z~Pz [log1+eχp(fθ(G：(Z))- fθ(x)) ].	(4a)
Similar to the - log D trick used in the original GAN training (a.k.a. non-saturating GAN), in prac-
tice we always use the non-saturating version for training:
D problem : minEχ~pdata,z~pz [log(1 + eχp(fθ(Gψ(Z)) - fθ(x)))],	(5a)
Gproblem : minEχ-pdata,z-pz[log(1 + eχp(fθ(X)- fθ(G：(Z))))].	(5b)
ψ	aa z
Here fθ is a deep net parameterized by θ, and G： is a generator net parameterized by ψ.
How to interpret the new loss? Our original intuition is to use “personalized criterion”. In JS-
GAN, the discriminator wants to solve a binary classification problem by finding a single decision
boundary that separates true data and generated data. For instance, if true data are x1 = 1 and
x2 = 2, and generated data are y1 = 0.5 and y2 = 0.5, then the boundary is drawn at, say, 0.8. Then
the discriminator only has the motivation to approach x2 = 1, since this would cross the bar of the
current discriminator. An analogy is that if the requirement for the students is “get 60 points”, then
they will try to get 60 points and then rest (surely, there will be follow-up raise, but the raise cannot
be too fast, since most students cannot catch). This causes x2 to be missed by the generator, since
it is “too good to learn”. In contrast, in CP-GAN, the discriminator provides two boundaries at 0.8
and 1.5, and y1 will try to cross 0.8 to approach x1 = 1, and y2 will try to cross 1.5 to approach
x2 = 2. Thus it can better learn the true distribution. An analogy is that if the requirements are
set differently for different students, like one “60 point” and one “90 point”, then they will learn to
achieve the two goals. Thus CP-GAN is adopting “personalized criterion” for the generated data.
3	Multi-DiracGAN: Multi-Mode Generation
Mescheder (2018) quoted Rahimi: “simple experiments, simple theorems are the building blocks
that help us understand more complicated systems.” Then they defined a simple model called Dirac-
GAN, which uses a linear discriminator and a powerful generator to recover a single-point distribu-
tion. We define a much more general model than the DiracGAN. We refer it as Multi-DiracGAN.
Definition 3.1 The Multi-DiracGAN consists ofa generator distribution Y = (y1, . . . , yn) ∈ Rd×n
and a discriminator f (x). The true data distribution is given by a n-point distribution X =
(x1, . . . , xn) ∈ Rd×n, where xi ’s are distinct.
One motivation of the Multi-DiracGAN is to consider an “empirical” version of the problem. Yet
another motivation is the construction of a simple model of multi-mode distributions: for instance,
when n = 2, we have a two-point distribution which is the simplest two-mode distribution. We
are not aware of an existing global analysis that can be applied to this simple 2-point model. See
Appendix A for more discussions.
3
Under review as a conference paper at ICLR 2020
When analyzing an optimization formulation, it is natural to proceed in the following steps: (1)
Sanity check, i.e., study whether the globally optimal solutions are desired; (2) Landscape analysis,
i.e., check whether there are undesirable local minima; (3) Convergence analysis, i.e., check whether
the proposed algorithm converges to a local minimum or stationary point. We will first perform a
sanity check and landscape analysis (for powerful discriminators), and then study the dynamics (for
linear discriminators).
4	Analysis of Some Existing GANs
4.1	JS-GAN has Exponentially Many Bad Basins
We analyze the landscape of JS-GAN under the Multi-DiracGAN model with powerful discrimina-
tors, the formulation of which can be written as:
miRnn φJS (Y, X) , maxLJS(f;Y),	(6)
where LJS(f； Y) = T Pn=IlOg(1 + exp(-f (xi)) - ɪ Pn=IlOg(1 + exp(f (yi))).
The range of φJS(Y, X) is [-2 log 2, 0] because LJS (f; Y) ≤ 0 and φJS(Y, X) ≥ L(0; Y) =
-2 lOg 2, where L(0; Y) represents the value achieved at f = 0.
To build intuition, we first present a result for the case of n = 2 points.
Claim 4.1 Suppose n	2 and x1 6= x2 ∈ Rd . Then (-2log2 ≈ -1.3862,	if {x1,x2} = {y1,y2}
φJS(Y,X)=	J - log2 ≈ -0.6931,	if l{X1,X2} ∩ {yi,y2H = 1, I log 2 一 1.5log 3 ≈ -0.9548, if y1 = y? ∈ {x1,x2}, I。	if ∣{x1,x2} ∩ {y1,y2}∣ = 0.
The global minimum is -2 lOg 2, which is achieved iff the generated data points {y1, y2} coincide
with the true data points {x1, x2 }.
As a corollary of the above claim, the outer optimization objective of the original GAN has a bad
strict local-min when two points overlap (a mode-collapse).
Corollary 4.1 Suppose n = 2 and xι = x2 ∈ Rd. Then Y = (x1,x1) is a sub-optimal strict local
minimum of the function g(Y) = φJS(Y, X).
We illustrate the landscape ofφJS(Y, X) in Figure 1a for the special case that d = 1, x1 = 0, x2 = 1.
In this case, Y = (y1, y2) = (0, 1) is the global minimum of φJS(Y, X) with optimal value
-2 lOg 2 ≈ -1.3862, and Y = (0, 0) is a strict local minimum of φJS(Y, X) with value approx-
imately -0.9548. An intuitive way to understand the landscape and Corollary 4.1 is given as fol-
lows. Consider a point (y1, y2) moving from (0, 1) to (-0.1, -0.1), going through four points:
(y1, y2) = (0, 1), (0, 0.5), (0, 0), and finally (-0.1, -0.1). The four points correspond to the four
cases above, thus giving values -1.3862, -0.6931, -0.9548, 0. The four values are not monotone,
indicating that there is a strict local minimum at -0.9538.
For general n, the landscape can be characterized in a similar fashion. The following result states
that the original GAN objective has exponentially many strict bad local minima.
Proposition 1 Suppose x1, x2 , . . . , xn ∈ Rd are distinct. Consider the problem in Eq. (6).
(i)	The global minimal value is -2 lOg 2, which is achieved iff the generated data points coincide
with the true data points, i.e., {y1, . . . , yn } = {x1, . . . , xn }.
(ii)	If yi ∈ {x1, . . . , xn }, i = 1, 2, . . . , n and yi = yj for some i 6= j, then Y is a sub-optimal strict
local minimum. Therefore, φjs(∙, X) has (nn 一 n!) sub-optimal strict local minima.
The landscape analysis is a high-level analysis that provides some preliminary insight into the train-
ing process. But there are two gaps compared to the true training process: (1) in practice, we always
4
Under review as a conference paper at ICLR 2020
Figure 1: Graphical illustration of the landscape of GAN outer optimization problem minY φ(Y, X).
It is not a rigorous figure for two reasons: (1) there are only four possible function values, thus the
function is a piece-wise linear function, but we use smooth curves to connect them to make the figure
easier to understand. (2) the landscape should be two-dimensional, but we only pick illustrative
points and and illustrate them in 1D space.
use different objectives for D and G (the - log D trick) to resolve the gradient vanishing issue;
(2) the D problem is addressed via a few gradient steps only. We suspect that the major insight
conveyed in the landscape analysis can still carry over to the training dynamics for the following
reasons: (1) the objectives for D and G are still closely related thus the “landscape” is still similar
(this can be proved rigorously by considering a bi-level optimization problem, which we skip here);
(2) inexactly optimizing D can smooth the landscape, so that the flat regions in φJS(∙,X) becomes
smooth (this may be why having a discontinuous outer-function is not too big an issue of JS-GAN).
However, we suspect that this smoothing effect cannot easily eliminate some deep basins, especially
when there are exponentially many. A complete analysis of this effect is beyond the scope of this
paper, and we will just show some evidence by analyzing the training dynamics of JS-GAN with
linear discriminators.
4.2	Training Dynamics of JS-GAN
We consider the non-saturating version of the formulation in Eq. (6), which is also the finite-sample
version of Eq. (3). We assume a linear discriminator f(u) = wTu + b, where w ∈ Rd, b ∈ R.
min
θ=(w,b)∈Rd ×R
LGDAN(Y ; θ)
n
log(1 + exp(-wT xi - b)) + log(1 + exp(wT yi + b)),
i=1
n
Y =(y1,.m..,yinn)∈Rd×n LGGAN(Y; θ), Xi=1 log(1 + exp(-wT yi - b)).
Consider the dynamics corresponding to the simultaneous gradient descent (GD) 1:
dw	二 - dLDAN	n _ ^X	Xi 1+ 1 + ewT χi+b i=1	y	(7a)
dt	一 --∂w 一		1 + e-wTyi-b ,	
db	二 - dLDAN	n1 =X -- 1+	ewT xi+b i=1	1	(7b)
dt	一	∂b~ 一		1 + e-wTyi-b ,	
dyi =	二 -dLGAN _	w		(7c)
dt	dy	1 + ewTyi+b .		
The common method to deal with such complicated dynamics is local linearization. This permits to
analyze the local behavior of the dynamics (see, e.g., Mescheder et al. (2018)). A global analysis of
the dynamics often requires a proper Lyapunov function that is non-increasing along the trajectories.
But the design of Lyapunov functions is often challenging.
1Other papers, such as Mescheder (2018) analyzed both simultaneous GD and alternating GD. For simplic-
ity, we only analyze simultaneous GD in this paper.
5
Under review as a conference paper at ICLR 2020
Even if one does not find such a function, one may wonder whether this is due to the lack of tech-
nical tools, or due to some intrinsic barriers. Motivated by the landscape result in Proposition 1, we
wish to analyze the mode-collapse patterns, i.e., the pattern occurring when some points overlap. In-
terestingly, we find that collapsed modes cannot be recovered under JS-GAN dynamics, as formally
stated in the following claim:
Claim 4.2 Starting from any initial point (θ(0), Y (0)), the trajectory (θ(t), Y (t)) defined in
Eq. (20) satisfies kyi(t) - yj (t)k ≤ kyi(0) - yj (0)k, ∀t.
This claim predicts that starting from yι(0) = y2(0)=…=yn, (0) (all points fall into one mode),
prevents these points from separating. It is interesting to more rigorously characterize bad global
behavior of JS-GAN dynamics, either for a linear or a neural-net discriminator (e.g., whether mode-
collapse patterns create bad attractors or limit cycles). Anyhow, the above claim makes it very hard,
if not impossible, to prove the global convergence of JS-GAN dynamics for multi-mode problems.
4.3	Discussions of WGAN and its variants
One may wonder whether W-GAN or its variants can provide a solution to the above issues. We
briefly discuss the difficulties in a global analysis of WGAN and its variants.
For W-GAN with Lipschitz constrain on f, itis not hard to prove that the outer-optimization problem
has a nice landscape. However, it is hard to impose the Lipschitz condition in practice; in addition,
gradient dynamics with constraints are difficult to analyze 2 *.
A practical solution to resolve the Lipschitz constraint issue is to add a gradient penalty,
which recovers WGAN-GP Gulrajani et al. (2017). However, the outer-optimization problem
minγ maxf Pi f(xi) - Pi f (y, - λ Pi(∣∣Vuf (u) ∣u=yi k - 1)2 may have a complicated land-
scape due to the extra regularization term.
We further show that the dynamics of WGAN-GP with linear discriminators have a similar issue to
JS-GAN. The details are provided in Appendix.
Claim 4.3 Starting from any initial point (w(0), Y (0)), the trajectory (w(t), Y (t)) defined by
WGAN-GP dynamics satisfies kyi(t) - yj (t)k = kyi(0) - yj (0)k, ∀t.
To avoid additional issues due to constraints, we remain interested in the logistic function used in
the JS-GAN formulation. We hope that a small modification to the JS-GAN directly addresses its
issues. We will now show that CP-GAN does achieve this goal.
5	Analysis of CP-GAN
In this section, we analyze the proposed new CP-GAN formulation and show that it has an advantage
over the original GAN framework. We highlight again a major difference of our analysis compared
to earlier works: we focus on global analysis while most existing results focus on local analysis.
5.1	CP-GAN HAS NO BAD BASIN
Following the aforementioned steps, the finite-sample version of CP-GAN reads
1n	1
mγnφCP(γ,X), Where φCP(γ,X) , SuP n ∑logι+eχp(f (yi) - f (χi)))，	⑻
resulting in a range φCP(Y, X) ∈ [- log 2, 0]. For simplicity, we define gCP (Y) = φCP(Y, X) as
the data X are fixed throughout the paper.
Proposition 2 Suppose x1, x2, . . . , xn ∈ Rd are distinct. The global minimal value of gCP (Y) is
- log 2, which is achieved iff {x1, . . . , xn} = {y1, . . . , yn}. Furthermore, for any Y, there is a
continuous path from Y to a global minimum along which the value of gCP (Y) is non-increasing.
2Mescheder (2018) analyzed W-GAN dynamics, but only consider the local region around 0, thus its anal-
ysis essentially ignores the Lipschitz constraint.
6
Under review as a conference paper at ICLR 2020
To understand this result, consider the special case n = 2 and x1 6= x2 ∈ Rd . In this case, we have
(-log2 ≈ -0.6931,	if {x1,x2} = {y1,y2}
Φcp(Y,X) = < -2 log2 ≈ -0.3466, if |{i : Xi = yi}| = 1
10	otherwise.
We illustrate the landscape of gCP (Y) in Figure 1b for the special case that n = 2, d = 1, x1 =
0, x2 = 1. In this case, (y1, y2) = (0, 1) and (y1, y2) = (1, 0) are two global minima of gCP (Y)
with optimal value - log 2 ≈ -0.6931. Similar to the previous subsection, there is an intuitive
way to understand the landscape: Consider a point (y1, y2) moving from (0, 1) to (-0.1, -0.1),
going through four points: (y1, y2) = (0, 1), then (0, 0.5), then (0, 0), and finally (-0.1, -0.1).
The four points correspond to four values -0.6931, -0.3466, -0.3466, 0. The four values are non-
decreasing, indicating that there is a monotone path connecting the mode-collapsed pattern (0, 0)
and a global-min (0, 1). This is different from the landscape of the JS-GAN loss, where any path
between the two points has to cross some barrier.
Comparing Proposition 2 and Proposition 1, we observe the landscape of CP-GAN to be better
than that of the original GAN formulation. How does that help training? Intuitively, the original
GAN landscape has many basins of attraction. When starting a random initial point, a descent
algorithm might fall into one of the bad basins, causing mode collapse. For CP-GAN, the only
basin of attraction is the global minimum, thus the algorithm is more likely to converge to the global
minimum.
5.2 Training Dynamics of CP-GAN
Next, we consider the training dynamics of CP-GAN and reveal nice global properties. Consider the
game variant of the GAN formulation in Eq. (8), i.e., the finite-sample version of Eq. (5). Further,
we assume the linear discriminator f (u) = wTu, where w ∈ Rd:
min
θ=w∈Rd
n
LCDP(Y; θ) , X log(1 + exp(wT (yi - xi))),
i=1
min
Y=(y1,...,yn)∈Rd×n
n
LCGP (Y; θ) , X log(1 + exp(wT (xi - yi))).
i=1
(9)
Consider the dynamics corresponding to the simultaneous gradient descent for CP-GAN:
dw = dt	∂LCDP 		：	= ∂w	n _	Xi - yi ʌ/ 1 + ewT(χi-y), i=1	(10a)
dyi =	∂LCGP	w	(10b)
dt	=			= ∂y	1 + ewT(yi-χi).	
Define δi = y% — Xi,∀i. Define function βj(t) = 2∣∣δi(t) — δj(t)∣∣2,∀ i,j.
Claim 5.1 Along the trajectory defined by Eq. (10), we have ∣(δi(t) - δj (t)∣ ≤ ∣(δi(0) -
δj (0)∣, ∀i, j.
This claim looks similar to the result for the JS-GAN dynamics given in Claim 4.2. However, there is
an important difference. For the original GAN, the gaps between generated samples are shrinking,
while for CP-GAN, the gaps between the errors are shrinking. Thus CP-GAN is a more natural
choice from this perspective.
This claim only shows the difference of the two GAN formulations, and we will show that CP-GAN
has the extra benefit that it has a natural potential function. Consider the function
1	1n
V = 2 ιιw∣2 + 2 52∣xi- yi∣2.
Obviously, V = 0 iff w = 0 and xi = yi , ∀i. According to the following result, V is non-increasing
along the trajectory of CP-GAN training.
7
Under review as a conference paper at ICLR 2020
Model	MNIST	CIFAR10	STL10	CelebA	LSUN
ɪɪ	IS	FID	IS	FID	IS	FID	IS	FID	IS	FID
NSGAN	1.98±0.01 7.73	5.62±0.09 53.42	5.88±0.06 82.81	2.46±0.01 21.68	2.77±0.03 41.15
WGAN-GP	2.00±0.01 7.05	6.52±0.08 40.31	7.34±0.11 65.23	2.65±0.01 17.18	2.80±0.01 34.02
CPGAN	2.05±0.02 5.08	6.72±0.06 36.66	7.56±0.21 57.07	2.73±0.02 15.45	2.82±0.02 30.41
Table 1: Inception score (IS) (higher is better) and Frechet Inception distance (FID) (lower is better)
for non-saturating GAN, WGAN-GP and our proposed CPGAN on MNIST, CIFAR10, STL10,
CelebA and LSUN.
Claim 5.2 Along the trajectory ofthe dynamics defined in Eq. (10), we have dVt) ≤ 0.
Thus V is a Lyapunov function for the CP-GAN dynamics. As mentioned earlier Mescheder (2018)
showed that V is a Lyapunov function for the JS-GAN dynamics (non-saturating version) given
in Eq. (20) if n = 1 and x1 = 0. However, when we check the case x1 6= 0, we found it is no
longer a Lyapunov function. This means that the JS-GAN formulation is not “translation-invariant”
in the sense that shifting xi and yi together leads to different dynamics. A simple fix to make it
shift-invariant is to a couple Y and X together.
With the Lyapunov function, we have the global convergence to the set θ such that
hVθ V(θ), h(θ)i = 0, where h is the right-hand side of Eq. (10). With a bit more effort, We can
show the global convergence of CP-GAN dynamics.
Proposition 3 (global convergence of CP-GAN dynamics) Starting from any initial point θ(0), con-
sider the trajectory defined by the CP-GAN dynamics θ(t).
(1)	For general d, limt→∞ θ(t) ∈ E, where E , {(w, y) : wT (yi - xi) = 0, ∀i}.
(2)	When d = 1, starting from any initial point θ(0), limt→∞ θ(t) ∈ M, where M = {(w, y) : w =
0, Pi xi = Pi yi}.
The set of stationary points include some undesired points. The next result shows that the Jacobian
at these undesired points has a positive real part, thus they are not stable. Simulations also show that
small perturbation can escape these undesired points.
Claim 5.3 When d = 1, for the training dynamics given in Eq. (10), at any point other than the
desired solution (y1, . . . , yn) = (x1, . . . , xn) in the set of stationary solutions, the Jacobian has an
eigenvalue with positive real part.
Now we have a clear understanding of the global behavior of the training dynamics of CP-GAN. The
most important fact is that the energy function V is a Lyapunov function. There may be other loss
functions that have a Lyapunov function, at least in the simple setting, and we leave that exploration
to future work.
6	Experiments
In this section, we present empirical results comparing different GAN loss functions. We aim to
show the qualitative and quantitative improvements achieved by using the proposed loss.
6.1	Synthetic Datasets
We first demonstrate our results on 2-dimensional synthetic data. Specifically, the 2-dimensional
data x = (x1, x2) is drawn from a mixture of 5 or 25 equally weighted Gaussians each with a
variance of 0.002, the means of which are spaced equally on the unit circle. See the blue points in
columns (a) and (d) of figure 2 for an illustration. Our generated samples are shown as the red points
in (a) and (c) in figure 2 and we can see our generators can catch every mode. The generator and the
discriminator loss are shown in (b), (c), (e) and (f).
8
Under review as a conference paper at ICLR 2020
(b)	(c)	(d)	(e)
(a)
1 U ” “
Bo- SSC8Z3&
E-LBEEK ≡3b
(f)
IlwaHon
Figure 2: (a) True(blue) and generated(red) Samples (b) loss for the generator (c) loss for the dis-
criminator from 5-Gaussian synthetic data. (d) True(blue) and generated(red) Samples (e) loss for
the generator (f) loss for the discriminator from 25-Gaussian synthetic data.
6.2	Image Generation
In this section, we present results on the task of image generation. We train and evaluate CPGAN
on four datasets: (1) MNIST (LeCun et al., 1998) (32×32); (2) CIFAR-10 (Krizhevsky, 2009)
(32×32); (3) STL-10 (Adam Coates, 2011) (48×48); (4) CelebA (Liu et al., 2015) (64×64); and
(5) LSUN Bedrooms (Yu et al., 2015) (64×64). We use three ResNet Blocks structure for MNIST
generator, and the DCGAN structure for CIFAR-10, STL-10, CelebA and LSUN. The input size for
the generator is 128-dimension.
In all our experiments we train the generator and discriminator in an alternating fashion. The batch
size is set to 64. We trained the generator and the discriminator each 30k batch iterations on the
MNIST dataset and 100k iterations on the CIFAR-10, STL-10, CelebA and LSUN datasets. We
tuned the learning rate for each model to achieve their best performance. Some generated samples
are shown in Appendix H.
We use inception scores (IS) (Salimans et al., 2016) and Frechet Inception distance (FID) (HeUsel
et al., 2017) to assess the quality of the generated images. We used 50k generated images for IS
and 10k true images and 10k generated images for FID metric calculation. We provide the results
in Table 1. We observe the proposed loss to perform better than other losses in terms of Inception
Score and FID, on all data sets.
7	Conclusion
The analysis of the population version of GANs is difficult. In this work, we analyzed an empirical
version of a few GAN formulations, i.e., assuming the true data distribution is the empirical dis-
tribution consists of n points. In this formulation, the samples are moving during the optimization
process, which is what is happening in practical training. This analysis can also mimics an n-mode
distribution; in fact, it captures the macro-learning part of the learning process. We show that using
this perspective, the JS-GAN formulation has exponentially many bad basins, and they correspond
to mode collapse. We also show that a new formulation CP-GAN does not have bad basins. Fur-
ther, we analyzed the training dynamics for the log-linear discriminators, and showed that there is
a global Lyapunov function for CP-GAN. Simulation on CELEBA, CIFAR10, etc. shows that the
new loss improves FID scores compared to WGAN-GP. This is achieved by only changing two lines
of code in Pytorch, which we think is quite remarkable.
9
Under review as a conference paper at ICLR 2020
References
Andrew Y. Ng Adam Coates, Honglak Lee. An analysis of single layer networks in unsupervised
feature learning. AISTATS, 2011.
Martin Arjovsky and Leon Bottou. Towards principled methods for training generative adversarial
networks. In NIPS 2016 Workshop on Adversarial Training. In review for ICLR, volume 2016,
2017.
Sanjeev Arora, Rong Ge, Yingyu Liang, Tengyu Ma, and Yi Zhang. Generalization and equilibrium
in generative adversarial nets (GANs). In Proceedings of the 34th International Conference on
Machine Learning,pp. 224-232, 2017.
Walss Azizian, Ioannis Mitliagkas, Simon LacoSte-Julien, and Gauthier GideL A tight and uni-
fied analysis of extragradient for a whole spectrum of differentiable games. arXiv preprint
arXiv:1906.05945, 2019.
Cyril Cohen and Damien Rouhling. A formal proof in coq of lasalle’s invariance principle. In
International Conference on Interactive Theorem Proving, pp. 148-163. Springer, 2017.
Constantinos Daskalakis and Ioannis Panageas. The limit points of (optimistic) gradient descent in
min-max optimization. In Advances in Neural Information Processing Systems, pp. 9236-9246,
2018.
Constantinos Daskalakis, Andrew Ilyas, Vasilis Syrgkanis, and Haoyang Zeng. Training gans with
optimism. arXiv preprint arXiv:1711.00141, 2017.
Soheil Feizi, Farzan Farnia, Tony Ginart, and David Tse. Understanding gans: the lqg setting. arXiv
preprint arXiv:1710.10793, 2017.
Gauthier Gidel, Reyhane Askari Hemmat, Mohammad Pezeshki, Remi Lepriol, Gabriel Huang, Si-
mon Lacoste-Julien, and Ioannis Mitliagkas. Negative momentum for improved game dynamics.
arXiv preprint arXiv:1807.04740, 2018.
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair,
Aaron Courville, and Yoshua Bengio. Generative adversarial nets. In Advances in neural infor-
mation processing systems, pp. 2672-2680, 2014.
Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Dumoulin, and Aaron Courville. Im-
proved training of wasserstein gans. arXiv preprint arXiv:1704.00028, 2017.
Wassim M Haddad and VijaySekhar Chellaboina. Nonlinear dynamical systems and control: a
Lyapunov-based approach. Princeton university press, 2011.
Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter.
Gans trained by a two time-scale update rule converge to a local nash equilibrium. In Advances
in Neural Information Processing Systems, pp. 6629-6640, 2017.
Chi Jin, Praneeth Netrapalli, and Michael I Jordan. Minmax optimization: Stable limit points of
gradient descent ascent are locally optimal. arXiv preprint arXiv:1902.00618, 2019.
Alex Krizhevsky. Learning multiple layers of features from tiny images. 2009.
Yann LeCun, Corinna Cortes, and Christopher JC Burges. The mnist database of handwritten digits,
1998.
Yann LeCun, Sumit Chopra, Raia Hadsell, M Ranzato, and F Huang. A tutorial on energy-based
learning. Predicting structured data, 1(0), 2006.
Jerry Li, Aleksander Madry, John Peebles, and Ludwig Schmidt. Towards understanding the dy-
namics of generative adversarial networks. arXiv preprint arXiv:1706.09884, 2017.
Zinan Lin, Ashish Khetan, Giulia Fanti, and Sewoong Oh. Pacgan: The power of two samples
in generative adversarial networks. In Advances in Neural Information Processing Systems, pp.
1498-1507, 2018.
10
Under review as a conference paper at ICLR 2020
Ziwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou Tang. Deep learning face attributes in the wild.
In Proceedings of International Conference on Computer Vision (ICCV), 2015.
Eric V Mazumdar, Michael I Jordan, and S Shankar Sastry. On finding local nash equilibria (and
only local nash equilibria) in zero-sum games. arXiv preprint arXiv:1901.00838, 2019.
Lars Mescheder. On the convergence properties of gan training. arXiv preprint arXiv:1801.04406,
1:16, 2018.
Lars Mescheder, Andreas Geiger, and Sebastian Nowozin. Which training methods for gans do
actually converge? arXiv preprint arXiv:1801.04406, 2018.
Luke Metz, Ben Poole, David Pfau, and Jascha Sohl-Dickstein. Unrolled generative adversarial
networks. arXiv preprint arXiv:1611.02163, 2016.
Takeru Miyato, Toshiki Kataoka, Masanori Koyama, and Yuichi Yoshida. Spectral normalization
for generative adversarial networks. arXiv preprint arXiv:1802.05957, 2018.
Ruslan Salakhutdinov and Geoffrey Hinton. Deep boltzmann machines. In Artificial intelligence
and statistics,pp. 448-455, 2009.
Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, Xi Chen, and
Xi Chen. Improved techniques for training gans. In D. D. Lee, M. Sugiyama, U. V. Luxburg,
I. Guyon, and R. Garnett (eds.), Advances in Neural Information Processing Systems 29, pp.
2234-2242. Curran Associates, Inc., 2016. URL http://papers.nips.cc/paper/
6125-improved-techniques-for-training-gans.pdf.
Maziar Sanjabi, Jimmy Ba, Meisam Razaviyayn, and Jason D Lee. On the convergence and ro-
bustness of training gans with regularized optimal transport. In Advances in Neural Information
Processing Systems, pp. 7091-7101, 2018.
Yasin Yazici, ChUan-Sheng Foo, Stefan Winkler, Kim-HUi Yap, Georgios Piliouras, and Vi-
jay Chandrasekhar. The unusual effectiveness of averaging in gan training. arXiv preprint
arXiv:1806.04498, 2018.
Fisher YU, Ari Seff, Yinda Zhang, ShUran Song, Thomas FUnkhoUser, and Jianxiong Xiao. LsUn:
ConstrUction of a large-scale image dataset Using deep learning with hUmans in the loop. arXiv
preprint arXiv:1506.03365, 2015.
A	Empirical Vers ion: Effect of Macro-learning
The motivation of analyzing the empirical version is two-fold. First, it is a common practice in
machine learning to separately analyze the popUlation version and the empirical version. Second,
as we mentioned, “the n-point distribUtion is an estimation of the n-mode distribUtion”, and we
elaborate below.
GANs are implicit generative models, as opposed to the explicit models like energy based models
(LeCUn et al. (2006)) and restricted boltzman machine (SalakhUtdinov & Hinton (2009)). In the
implicit models, there is no explicit parameterization of the probabality density. The benefit of
implicit models is that it is easier to train and sample from. DUring the training of GANs, when the
parameters of the mapping (i.e. generator) change, it is the generated samples that are moving, not
that an explicit probability density is moving. These two views are illUstrated in FigUre 3.
Next, we will explain that the two views are both related and orthogonal.
First, there is a connection between the two views. As shown in FigUre 4, we can smooth the
empirical distribUtion (blUe color) which is discrete to be a continUoUs distribUtion (yellow color).
DUring the algorithms, the samples are actUally moving, bUt that also corresponds to the moving of
the Underlying continUoUs probability density. ThUs it is reasonable to assUme pg is moving, as an
approximation to the real pictUre that the samples are moving.
Second, we think these two views are orthogonal, and correspond to “macro-learning” and “micro-
learning” respectively, when learning a mUlti-mode distribUtion. Consider learning a two-mode
11
Under review as a conference paper at ICLR 2020
(a) Population version: probability density changes (b) Empirical version: samples move
Figure 3: Population version and empirical version. Population version: the probability densities
are changing. Empirical version: the samples are moving.
Figure 4: Illustration of the learning process of the single mode. The generated samples are moving,
which correspond to the adjustment of the probability densities. They represent two views on the
learning process.
distribution pdata, and we start from an initial two-mode distribution pg . There are two differences
between pg and pdata : first, the locations of the two modes are different; second, the distribution
within each mode is different. To learn the distribution, we want to eliminate both differences: first,
move the two modes of pg to roughly overlap with the two modes of pdata which we call “macro
learning”; second, adjust the distributions of each mode to match those of pdata , which we call
“micro learning”. This is illustrated in Figure 5 and Figure 6.
Therefore, we have explained the two reasons of analyzing the empirical version (the n-point distri-
bution). First, it is the practically used version. Second, it captures the “macro-learning” behavior
of learning a multi-mode distribution.
Finally, the two types of learning are related to the two types of mode collapse mentioned in Lin
et al. (2018): “entire modes from the input data are never generated, or the generator only creates
images within a subset of a particular mode.” Failure of macro-learning can cause missing modes in
the generated distributions, which corresponds to the first type of mode collapse. Failure of micro-
learning can cause a sub-mode of a mode to be missed, which also corresponds to the second type
of mode collapse. See more discussions of related works on mode collapse in Appendix B.
A. 1 Generalization
One may wonder whether fitting the n data points can cause memorization and thus may not gen-
eralize. We explain from two perspectives: first, the existing theory on generalization of GANs;
second, intuition why this does not overfit.
First, there exists generalization bounds for GANs. Suppose the true distribution is pdata and the
generated distribution is pg . Further, suppose we sample n points x0i s from pg and sample n points
from Pg, and use μ and V to represent the two empirical distributions (discrete distributions with
equal probability). Arora et al. (2017) proved that for a large class of GAN problems (including
JS-GAN using neural-net discriminator and generators), only polynomial samples are needed to
achieve a small generalization error. As a result of the generalization bound, Arora et al. (2017)
12
Under review as a conference paper at ICLR 2020
Figure 5: Illustration of the process of learning a multi-mode distribution. Will decompose this
process into two parts in the next figure.
(a) Macro-learning
(b) Micro-learning
Figure 6: Illustration of learning a multi-mode distribution. We decompose the process as the macro-
learning and the micro-learning. The macro-learning refers to the moving of the whole mode towards
the underlying mode. The micro-learning refers to the adjustment of the distribution within each
mode. If macro-learning fails, then an entire mode is missed in the generated distributions, which
corresponds to mode collapse. Note that even for the single-mode, the learning process can be
decomposed into the macro learning and the micro learning.
stated that if the GAN successfully minimized the empirical distance (i.e. the distance between μ
and ν), then the population distance (the distance between the two distributions pdata and pg) is also
small. Therefore, there is a generalization guarantee under suitable conditions. Of course, there is
much space in improving the generalization bound of Arora et al. (2017), and that is an orthogonal
line of research. Our goal of this paper is mainly to study how to “successfully minimized the
empirical distance” (i.e. fit the n-point distribution μ). Technically speaking, the form of Arora
et al. (2017) does not cover CP-GAN, but the proof can be easily extended to CP-GAN.
Second, we provide some intuition why fitting the points may not cause overfitting. Consider a
simple case of learning a two-mode distribution in Figure 7. During training, we learned a generator
that maps the latent samples zi’s to xi’s, thus fit the empirical distribution. Ifwe sample anew latent
sample zi, then the generator will map zj to anew point xj in the underlying data distribution. Thus
fitting the empirical distribution can still leads to generating new data points.
Figure 7: Learning a two-mode distribution. During training, we learned a generator that maps the
latent samples zi’s to xi’s, thus fit the data. If we sample a new zi, then it will be mapped to a new
point in the underlying data distribution.
13
Under review as a conference paper at ICLR 2020
B	Related Works
Single-mode analysis. Two papers Feizi et al. (2017) Mescheder et al. (2018) provided global
analysis of GANs for the single-mode case. Feizi et al. (2017) analyzed the case that the true
distribution pdata is a single Gaussian distribution. It considers the population version, i.e., there is a
continuous latent distribution of pz . For a new formulation called quadratic GAN and using a linear
generator and a quadratic discriminator, this paper proved the global convergence of alternating
GDA. The min-max problem they consider is a bi-linear function forD and a bi-linear function for G
(not a typical a bi-linear game which is linear in either variable, but bi-linear in either variable). They
found an interesting Lyapunov function for the min-max problem, leading to the global convergence.
The major difference with our papers is that they considered the single-mode case, while we consider
the multi-mode case. There are a few other differences: (a) They consider the population version,
and we consider the empirical version. (b) They consider the quadratic discriminator (since to learn a
Gaussian, the disciminator needs to be constrained), and we analyze both the powerful discriminator
case and the linear discriminator.
To extend to the multi-mode case such as multi-Gaussian, as we discussed earlier, there is a macro-
learning effect and micro-learning effect. Our work on n-point distributions captures the macro-
learning effect, and Feizi et al. (2017) captures the micro-learning effect for Gaussian data. In the
future, it would be quite interesting to combine the analysis of Feizi et al. (2017) and our analysis to
the multi-Gaussian case.
Mescheder et al. (2018) considered the case that the true distribution pdata is a single point 0. Even
for this case, GDA for all min-max formulations of GANs does not converge locally. However,
it proved that for the non-saturating version of JS-GAN, GDA converges to the desired solution
0. Interestingly, we found that their proof cannot be directly generalized to the case that pdata is
a single non-zero point. Thus even for the single non-zero point setting, it is natural to use our
CP-GAN formulation to prove global convergence.
Mode collapse. Mode collapse is one of the major challenges for GANs, and received a lot of atten-
tion. Roughly speaking, it means that some “modes” of the true data distributions are not generated.
The cause of mode collapse is not well understood, and there are a few high-level hypotheses, such
as improper loss function Arjovsky & Bottou (2017); Arora et al. (2017) and weak discriminators
Metz et al. (2016); Salimans et al. (2016); Arora et al. (2017); Li et al. (2017). Interestingly, CP-
GAN both changes the loss function and improves the discriminator.
A number of empirical solutions have been proposed, including unrolled GAN Metz et al. (2016)
and minibatch discrimination Salimans et al. (2016). A recent work Lin et al. (2018) proposed
a theoretically motivated method PacGAN, which we elaborate below. The key observation is
the following: two pairs of distributions with the same total variation distance do not exhibit
the same degree of mode collapse. For instance, consider Q = U[0, 1], P1 = U [0.2, 1] and
P2 = 0.6U [0, 0.5] + 1.4U ([0.5, 1]), where U[a, b] is the uniform distribution on [a, b]. Then
TV (Q, P1) = TV (Q, P2), but P1 has mode collapse while P2 does not. They proposed to pack the
samples, i.e., consider the distance of the product distribution Pm and Qm. The main theoretical
result that “TV (Pm, Qm) is a better loss to penalize strong mode collapse than TV (P, Q)”. Based
on this result, they extracted the key idea of “packing” to apply it to any GAN.
Our paper is different from Lin et al. (2018) in the following aspects. First, they did not provide
theoretical analysis for a specific GAN; in contrast, we prove theoretical results of specific JS-GAN
and CP-GAN formulations. Second, we provided an explanation for “why mode collapse happens”,
by linking mode collapse to a fundamental optimization subject “bad basin”. Third, their focus is to
mitigate “bad basin”, and our starting point is to analyze the global landscape, and the link to mode
collapse is a natural byproduct of the analysis.
C Proofs in Section 4.1
C.1 Proof of Claim 4.1
We will compute values of φJS(Y, X) for all Y .
14
Under review as a conference paper at ICLR 2020
Denote D(U) = i+exp；_f(u))∈ [0,1]. Since f can be any continuous function, D can be any
continuous function with range (0, 1).
φJS(Y, X) = sup
f
= sup
D
Consider four cases.
1 XX log__1___+ 1 XX log_1__
n i=1 g 1 + exp(-f (Xi)) n g 1 + exp(f (yi)}
nn
—Xlog(D(xi)) + - Xlog(1 - D(yi)).
n i=1	n i=1
Case 1:	Both generated points overlap with the true data points, and are distinct, i.e., y1 = x1, y2 =
x2 or y2 = x1 , y2 = x2 . Then the objective is
SUp -log(D(xι)) +-log(1 - D(xι)) +-log(D(x2)) +-log(1 - D(x2)).
D2	2	2	2
The optimal value is -2log2, which is achieved when D(χι) = D(χ2) = 2. The corresponding
function values of f are f(x1) = f(x2) = 0. The values of f on other points do not matter.
Case 2:	Exactly one of the generated points overlaps with the true data points. Without loss of
generality, we can check the case y1 = x1, y2 ∈/ {x1, x2}. The problem becomes
SUp -log(D(xι)) +-log(D(x2)) +-log(1 - D(xι)) +-log(1 - D(y2)).
D2	2	2	2
The optimal value - log 2 ≈ -0.6931 is achieved when D(x1) = 1/2, D(x2) = 1 and D(y2) = 0.
The corresponding function values of f are f(x1) = - log 2, f(x2) = ∞ and f(y2) = -∞.
Case 3:	Both generated points overlap with the true data points, and are the same. Without loss of
generality, check the case y1 = y2 = x1.
sup -Iog(D(xι))+ log(1 - D(xι)) + -log(D(x2)).
D2	2
The optimal value 2 log 1 +log 2 ≈ -0.9548 is achieved when D(χι) = 1/3 and D(χ2) = 0. The
corresponding function values of f are f(x1) = - log 2, f(x2) = ∞.
Case 4:	Both generated points are different from the true data points. y1, y2 ∈/ {x1, x2}. It becomes
separable over the four points
sup 1 log(D(xι))	+ 1 log(D(x2))	+ 1	log(1 - D(yι))	+ 1log(1	- D(y2)).
D2	2	2	2
Each term can achieve its maximum log 1 = 0. Thus the optimal value 0 is achieved when D(x1) =
D(x2) = 1 and D(y1) = D(y2) = 0. The corresponding function values of f are f(x1) = -∞,
f(x2) = ∞ .
C.2 Proof of Corollary 4.1
We re-state the corollary below.
Corollary C.1 Suppose Y = (y1,y2) satisfies yjι = y2 = xι, then it is a sub-optimal Strict local
minimum of the problem.
Proof: Suppose is the minimal non-zero distance between two points ofx1, x2, y1, y2. Consider a
small perturbation of Y as Y = (yι + e`jg2 + ⑦)，where 匕| < e. We want to verify that
φ(Y, X) > φ(Y,X) ≈ -0.9548.	(11)
There are two possibilities.
Possibility 1: 1 = 0 or 2 = 0. WLOG, assume 1 = 0, then we must have 2 > 0. Then we
still have yι = yι = xi. Since the perturbation amount is small enough, We have y2 ∈ {χι, X2}.
According to Case 2 above, we have
φ(Y,X) = - log2 ≈ -0.6931 > -0.9548.
15
Under review as a conference paper at ICLR 2020
Possibility 2: 1 > 0, 2 > 0. Since the perturbation amount 1 and 2 are small enough, we have
y1 ∈/ {x1, x2}, y2 ∈/ {x1, x2}. According to Case 4 above, we have
φ(Y,X) = 0 > -0.9548.
Combining both cases, we have proved (12).
Q.E.D.
C.3 Proof of Proposition 1
Denote D(U) = i+exp；_f(u))∈ [0,1]. Since f can be any continuous function, D can be any
continuous function with range (0, 1).
1n	1
(My,X ) = sup n i=1 logι + eχp(-f (Xi))
1n
+ n Xlog
1
1 + exp(f(yi))
nn
sup — X log(D(xi)) + — X log(1 -
Dn	n
i=1	i=1
D(yi)).
Denote F(D； Y) = n Pn=I log(D(xi)) + n Pn=I log(1 - D(yi)) Since D(U) ∈ (0,1) for any
u, then F(D; Y) ≤ 0. When D(u) → 2,∀u, We have F(D; Y) → -2log2, thus φjs(Y, X)=
SuPD F(D; Y) ≥ -2log2. Thus the range of φjs(∙, ∙) is [-2log2,0].
Now we compute the value of Φjs(∙, X) for each Y. For any i, denote Mi to be set of indices of yj
such that yj equals xi, and mi to be the size of the set Mi, i.e.,
Mi = {j : yj = xi }, mi = |Mi |, i = 1, 2, . . . , n.
Denote Ω = {1, 2,..., n}∖(Mι ∪ M2 …∪ Mn). Then we have
Φjs(y,x) =1SuP (X[iog(D(χi)) + X iog(i - D(yj))] + X iog(i - D(yj))
n D ∖i=1	j∈Mi	j∈Ω
=ISUP ( X[log(D(xi)) + mi log(1 - D(Xi))] + X log(1 - D(yj)))
D D ∖i=1	j∈Ω	/
n
=1X
n
i=1
SuP[log(ti) + mi log(1 - ti)] +0
ti∈R
n
(ii) 1	1	mi
=n ∑[log L + mi log L]
i=1
1n
一Emi log mi - (mi + 1)log(mi + 1)].
i=1
Here (i) is because D(yj), j ∈ Ω are independent of D(Xi)'s and thus can be any values; in this
step, the optimal D(yj) = 1, ∀j ∈ Ω. (ii) is because for any positive number m, supt∈R∣log(t) +
m PNI log(1 -1)] = log m+τ + m log m+τ.
When mi = 1, i = 1, 2, . . . , n, i.e., yi = Xi, ∀i, the function φJS(Y, X) achieves value -2 log 2.
Thus Y = (X1 , X2 , . . . , Xn ) is a global minimum.
Next, we show that if Y satisfies that if mi + m2 + •…+ mu = n then Y is a strict local-min.
Denote δ as the minimal distance between two points of X1 , X2, . . . , Xn , i.e.,
δ = min kXk -Xlk.
k6=l
Consider a small perturbation of Y as Y = (yi, y2,..., yn) = (yi + e1,y2 + S,..., yn + en), where
kj k < δ, ∀j and Pj kj k2 > 0. We want to verify that
Φjs(Y,X) >Φjs(Y,X).	(12)
16
Under review as a conference paper at ICLR 2020
Denote
mi = l{j : Iyj = xi}|, i = 1, 2, . . . , n.
According to the assumption mi + m2 +---+ mn = n, We have yj ∈ {xι,..., xn}, ∀j. Consider
an arbitrary j, and suppose yj = xi. Together with ∣∣yj - yjk = |匕|| < δ = mink=ι ∣∣xk - xιk,
we have yj∙ ∈ ({xi, χ2,..., Xn}∖{χi}). In other words, the only possible point in {xi,..., Xn} that
can coincide with yj- is Xi, and this happens only when Ej = 0. As a result, we have
mi ≤ mi,	, i = 1, 2,.. ., n.
Together with the fact that t logt - (t + 1) log(t + 1) is a strictly decreasing function in t ∈ [0, ∞),
we have
1n
Φjs(Y,X) = 一 ɪ^[mɪilogmi - (mi + i)log(m⅛ +1)]
i=i
1n
≥ — £[mi log mi - (mi + 1)log(mi + 1)] = φjs (Y, X).
n i=i
The equality is achieved iff mi = m^ ∀i, which holds iff Ej = 0, ∀j. Since we have assumed
Pjkejk2 > O, the equality does not hold, thus φ(Y, X) > φ(Y, X). Therefore, we have proved
that Y is a strict local minimum.
Finally, if Y satisfies thatmi + m2 + •…+ mn = n and mk ≥ 2 for some k, then Φjs(Y, X) >
-2 log 2. Thus Y is a sub-optimal strict local minimum. Q.E.D.
D Technical Details of Section 4.2 and 4.3
D.1 Proof of Claim 4.2
Define a function αij (t) =
daij (t)
dt
2 kyi(t)-yj (t)k2,∀ i,j.
Q )T d(yi - yj)
yj) -dt-
—
1 + ewτ yi+b
—
1
1 + ewT yj +b
(wT yi - wTyj)
1 + ewτ yi+b
—
w
1
≤ 0.
In the last step, we used the fact that (ai - a2) (1+e07 - ɪ+^) ≤ O for any ai, a2 ∈ R. Note
that in the above computation, we skip the time index t. Therefore αij (t) is non-increasing along
the trajectory, which implies kyi(t) - yj(t)k ≤ kyi(0) - yj(0)k,∀t.
D.2 Proof of Claim 4.3
WGAN-GP with linear discriminators can be expressed as
nn
min LDWGAN-GP(Y; θ) , -XwTxi +XwTyi + λ(kwk - 1)2.
w∈Rd	-
i=i	i=i
min
Y=(y1,...,yn)∈Rd×n
n
LGWGAN-GP (Y ; θ) , -	wTyi .
i=i
Consider the dynamics corresponding to the simultaneous gradient descent for WGAN-GP:
dw = dt	∂LD	n 二					 = X(Xi - yi) - 2λw + 2w∕∣w∣,	(13a) ∂w i=i
dyi = dt	∂LG ∂LWGAN-GP 二	λ	= -w.	(13b) ∂yi
17
Under review as a conference paper at ICLR 2020
Define a functionαij⑴=1 l∣yi(t) -yj(t)k2,∀ i,j.
Thus lyi(t) - yj (t)l will be a constant for all t.
E Technical Details of Section E.5
E.1 Proof of Claim 5.1
Define a function αj(t) = 2 k(yi(t) — Xi) — (yj(t) — Xj)∣∣2,∀ i,j. Denote δi(t) = yi(t) — Xi.
dαij ⑴=(δ
dt =( δ
1 + ewT (yi-xi)
δ )T d⅛也=(δi
1
—
1 + ewT δi	1 + ewT δj
—
w
—
1
≤ 0.
The equality holds iff wT δi = wTδj, i.e., wT (δi — δj ) = 0.
E.2 Proof of Claim 5.2
Let ui = wT (yi — Xi), i = 1, . . . , n, we have
dV =WT dw + X(yi-Xi)T 华
dt dt 乙	dt
i
n
WT X1 ：wT (yl-y.) + X(yi — Xi)T
1+ew (xi -yi)
i=1	i
1 + ewT (yi-χi)
X WT (Xi — y) + X WT (yi - Xi)
1+ 1 + ewτ (xi-yi)	1+ 1 + ewτ (yi-Xi)
i=1	i=1
n
X
i=1
-Ui
1 + e-ui
n
+X
i=1
Ui
1 + eui
nn
XX
i=1 i=1
Ui(1 — eui)
1 + eui
≤ 0,
(14a)
(14b)
(14c)
(14d)
(14e)
w
In the last step we used the fact that U(1 — eu) ≤ 0, ∀U ∈ R. Note that in the above computation,
we skip the time index t.
E.3 Proof of Proposition 3
We restate the proposition below.
Proposition 4 (restate; global convergence of CPGAN dynamics) When d = 1, starting from any
initial point θ(0), the trajectory defined by the CPGAN dynamics θ(t) will satisfy limt→∞ θ(t) ∈ M,
where M = {(W, y) : W = 0, Pi Xi = Pi yi}.
18
Under review as a conference paper at ICLR 2020
We will use Lasalle’s invariance principle (see, e.g. (Haddad & Chellaboina, 2011, Theorem 3.3) or
(Cohen & Rouhling, 2017, Theorem 1)) to prove this result.
Definition (invariance set). A set A is said to be invariant with respect to a differential equation
dU = h(u(t)) if every solution to this equation starting in A remains in A.
Lemma 1 (Lasalle's invariance principle) Consider a dynamical System defined by 暮=h(u(t)),
where h is a vector mapping. Assume h has continuous first partial derivatives and h(0) = 0. Let K
be an invariant compact set. Suppose there is a scalar function V which has continuous first partial
derivatives in K and is such that V(P) = hVV(p), h(p)i ≤ 0,∀p ∈ K. Let E be the set of all
points p ∈ K such that V(p) = 0. Let M be the largest invariant set in E. Then for every solution
t starting in K, u(t) → M as t → ∞.
Our goal is to show that starting from any initial point θ(0) = (w(0), y(0)), the dynamics defined
by (10), denoted as θ(t) = (w(t), y(t)) will converge to the set
M = {(w, y) : w = 0,Xxi=Xyi}.	(15)
ii
Define
K = {θ : kθk2 ≤kθ(0)k2}
Since V ≤ 0, we have ∣∣θ(t)∣∣2 ≤ ∣∣θ(0)k2, thus θ(t) ∈ K, ∀t. Thus K is an invariant compact set.
According to Claim 5.2, the set of points p such that V(p) = 0 is
E , {(w,y) : wT (yi - xi) = 0, ∀i}.
According to the LaSalle’s invariance principle, the algorithm will converge to the largest invariance
subset of E.Without knowing which set it is, we can already obtain the result that the algorithm
converges to the set E. This proves the first part of the result. The analysis so far works for any d.
Next, we will use the condition d = 1. We show that when M defined in (15) is the largest invariant
set in E. Assume the contrary, that there is a set MQM ⊆ E such that M is an invariant set. Then
starting from any point θ(0) ∈ E\M, We have θ(t) ∈ M.
Since d = 1, then set E becomes
E = {(w, y) ∈ R1×(n+1) : w(yi - xi) = 0, ∀i}.
Let E1 = {(w, y) : w = 0} and E2 = {(w, y) : yi = xi, ∀i}, then E = E1 ∪ E2. The set M is still
M = {(w, y) : w = 0,	xi =	yi}.
ii
Since θ(0) ∈ E but not in M, and E2 ⊆ M, then we have θ(0) ∈ E1 and θ(0) ∈/ E2. This implies
w(0) = 0 and Pi(χi(0) — yi(0))2 = 0. According to the fact that V(P) = 0,∀p ∈ E and θ(t) ∈ E,
we have that
V(θ(t)) = V(θ(0)) =	(xi(0) - yi(0))2 + w(0)2 ,δ.	(16)
i
Since the path θ(t) ∈ M ⊆ E for all t, we have θ(t) ∈ E1 or E2. Suppose J = {t ∈ R : θ(t) ∈ E2},
then for s ∈ J we have V(θ(s)) = w(s)2 + 0 = w(s)2. By (16), we have
w(s)2 = δ, ∀s.
For t ∈/ J, we have θ(t) ∈ E1 and thus w(t) = 0. Thus w(t) = 0, ∀t ∈/ J and w(t) = δ, ∀s ∈ J. As
w(t) is continuous for t and w(0) = 0, we must have J = 0. This means w(t) = 0 for all t.
Recall the dynamics defined by 10 for the case d = 1 is
dw = dt	∂LCDP =	：	= ∂w	n _	Xi - yi ʌ-" 1 + ew(χi-yi). i=1	(17a)
dyi =	∂LCGP	w	(17b)
dt	=			= ∂y	1 + gw(yi-χi).	
19
Under review as a conference paper at ICLR 2020
Along the path θ(t) ∈ E, we have w(t)(yi (t) - xi(t)) = 0, ∀t, thus
dyi(t)
dt
0
1 + e0
∀i,
which implies yi(t) = yi(0),∀i. This further implies dwd(t) = PJxi(t) - yi(t)] = P∕χi(0)-
yi(0)] , δ0. Since θ(0) ∈ E but not in M, thus we must have Pi xi(0) 6= Pi yi(0), implying
δo = 0. Thus dwdtt) = δo = 0, which contradicts w(t) = 0, ∀t. This contradiction implies that the
original assumption that there is a set MGM ⊆ E such that M is an invariant set does not hold.
Thus the largest invariant subset of E must be a subset of M .
Finally, if θ(0) ∈ M, then the gradients are zero, thus θ(t) ∈ M, ∀t, which implies that M itself is
a invariant set. Thus M is indeed the largest invariant set of E.
E.4 Proof of Claim 5.3
We restate the claim below.
Claim E.1 When d= 1, for the training dynamics of (10), at any point other than the desired solu-
tion (y1, . . . , yn) = (x1, . . . , xn) in the set of stationary solutions, the Jacobian has an eigenvalue
with positive real part 3 * *.
When d = 1, the dynamical system is given by
dw	∂LCDP dt	∂w dyi	∂LCGP 	=			二 dt	∂yi	n xi - yi 二〉 		7	√.	(18a) 1 + ew(xi -yi) i=1 二-——W——?	(18b) 1 + ew(yi-xi)
We can write it as
, ..
θ = h(θ) = (h0(θ), ... , hn(O)),
where h is the right hand side of the i-th equation. The Jacobian J = Vh satisfies the following:
∂h0 J11 = ∂W =	XX (Xi - yi)2 1 + ew(yi-xi), i=1
∂h0 J1,i+1 =西= ∂hi %1,1= ∂W = ∂hi Ji+1,i+1 ==匹	1	ew(yi-xi) -1 + ew(Xi-yi) + W(Xi- yi)(l + ew(yi-Xi))2，∀i = 1，…，n， 1	ew(yi-xi) 1 + ew(yi-χi) + w(yi	Xi) (ι + ew(yi-xi))2， W2ew(yi-xi) = (1 + ew(yi-xi))2
0, ifi,j ≥ 2andi 6=j.
When evaluated at θ = (0, y1, . . . , yn), we have
丁 _ ∖-'' (Xi - Ui)2
11	= Z-/	2	,
i=1	2
J1,i+1 = - 2, ∀i = 1,...,n,
Ji+1,1 = 2,
Ji+1,j+1 = 0,	i, j ≥ 1.
3The stability of typical equilibria of smooth ODEs is determined by the sign of real part of eigenvalues of
the Jacobian matrix. It is unstable if at least one eigenvalue has positive real part. See, e.g., Mescheder (2018)
for the discussions.
20
Under review as a conference paper at ICLR 2020
Figure 8: Graphical illustration of LaSalle’s invariance principle. Figure from Cohen & Rouhling
(2017). Starting from K, the dynamics will finally converge to the set M .
It is easy to verify that J only has two non-zero eigenvalues
λ1,2 = 2 J11 ±√2 √-1.
Therefore, when xi = yi , ∀xi , the eigenvalues of the Jacobian have zero real part. When some xi 6=
yi, then the two eigenvalues of the Jacobian have a positive real part, meaning that this stationary
point is not stable. This proves the result: in the set of stationary solutions M = {(w, y) : w =
0, Pi xi = Pi yi}, any point other than the desired solution (y1, . . . , yn) is not stable.
E.5 Analysis of CP-GAN Dynamics for Convex Case
Next, we consider the training dynamics of a generalized CP-GAN for a convex discriminator.
In (9), we used a log-linear discriminator D(u) = log(1 + e-w u) (although we called it a “lin-
ear discriminator” previously for simplicity). In this subsection, we show that the same analysis
can be extended to a “convex-linear” discriminator. The empirical version with the convex-linear
discriminator is presented below; it is an extension of (9).
min
θ=w∈Rd
n
LCDP(Y; θ) , X φ(wT (yi -xi)),
i=1
min
Y=(y1,...,yn)∈Rd×n
n
LCGP(Y; θ) , X φ(wT (xi -yi)).
i=1
Consider the dynamics corresponding to the simultaneous gradient descent for CP-GAN:
dw = dt	∂LD	n 二--C— = E(Xi - yi)φ (w (yi - Xi)),	(19a) ∂w i=1
dyi —= dt	二-dLcp = wφ0(wT(Xi - yi))	(19b) ∂yi
We still consider the function	V = 2kwk2 + 1X Ilxi - yik2. i=1
According to the following result, V is non-increasing along the trajectory of CP-GAN training with
convex discriminators, thus it is still a global Lyapunov function for the dynamics (19).
Claim E.2 Suppose φ is a convex function. Along the trajectory of the dynamics defined in Eq. (19),
we have dV(t) ≤ 0.
21
Under review as a conference paper at ICLR 2020
Proof of Claim E.2: Let ui = wT (yi - xi), i = 1, . . . , n, we have
dV =WT dw + X …)T 暮	(20a)
dt dt	dt
i
n
=wT	(xi	- yi)φ0(wT(yi	- xi))	+	(yi	-	xi)T wφ0(wT (xi	-	yi))	(20b)
i=1	i
nn
=	wT (xi - yi)φ0(wT (yi - xi)) +	wT (yi - xi)φ0(wT(xi - yi))	(20c)
i=1	i=1
nn
= X(-ui)φ0(ui) + Xuiφ0(-ui)	(20d)
i=1	i=1
n
= X ui[φ0(-ui) - φ0(ui)] ≤ 0,	(20e)
i=1
In the last step we used the fact that u(φ0(-u) - φ0(u)) ≤ 0, ∀u ∈ R due to the convexity of φ.
Note that in the above computation, we skip the time index t.
Thus V is a Lyapunov function for the CP-GAN dynamics with convex discriminators. □
It is not hard to extend the convergence results to this case, and we skip the details.
F PROOF OF PROPOSITION 2 FOR n = 2
Without loss of generality, we can consider two points x1 = 0, x2 = 1. The problem becomes
CP	1	1	1	1
g (Y) =泮 2log EfkTo + 2 log EfIFfo,
where F is the set of continuous functions with domain Rd. We compute all values of gCP (Y) as
follows.
Case 1:	The two generated points are the same as the true data points, i.e., {x1, x2} = {y1, y2}. If
y1 = 0, y2 = 1, then
gcP(Y) = ∣[log1∕2 + log1∕2] = - log2 ≈ -0.6937.
Ify1 = 1, y2 = 0, then
CP	1	1	1	1
g( ∖ f∈F∣2 g1+exp(f(0)- f⑴)+2 g1 + exp(f⑴-f (0))_
111	1
=SUp X logm----由 + X logm---厂不
t∈R 2	1 + exp(t)	2	1 + exp(-t)
= - log 2.
Case 2:	Exactly one of the generated points coincides with the corresponding true data point, i.e.,
|{i : yi = xi}| = 1. Without loss of generality, we can check the case y1 = 0, y2 6= 1. Then
gCP(Y) ≥ SUp 1 2 log ----771n^~TTTnV
f∈F 2	1 + exp(f (0) -f(0))
+ 2log
1
1 + exp(f ⑴-f (y2))
1
=-1log2 + sup 1 log
2	t∈R 2
=-∣log2 ≈ -0.3466.
1 + exp(t)
The value is achieved when f(1) -f(y2) → -∞ (or more precisely, there is a sequence of functions
such that the difference f(1) - f(y2) goes to minus infinity).
22
Under review as a conference paper at ICLR 2020
Case 3: Both generated points are different from the true data points, i.e., |{i : yi = xi}| = 1. Then
gCP(Y) ≥ SUp 1 log t———rrL~~hʒr
f∈F 2	1 + exp(f (0) - f(y1))
+ 2log
1
1 + exp(f(1) - f(y2))
sup log
t1∈R,t2∈R 2	1 + exp(t1)
+2log
1
1 +exρ(t2)
0.
The value is achieved when f(1) - f(y2) → -∞ and f(0) - f(y2) → -∞.
According to the above results, the only global minima are {y1, y2} = {x1, x2}. In addition, from
any Y, it is easy to verify that there is a non-decreasing path from Y to a global minimum.
G PROOF OF PROPOSITION 2 FOR GENERAL n
Recall the function
1n	1
g(Y ) = sup n i=1 l0g1+eχp(f 3-f (Xi)))
1n
-呼-£log(1+exp(f(y，)- f(xi)))).
fn
Proposition 5 (restatement of Proposition 2 ) Suppose x1, x2, . . . , xn ∈ Rd are distinct. The global
minimal value of gCP (Y) is - log 2, which is achieved iff {x1, . . . , xn} = {y1, . . . , yn}. Further-
more, the function g(Y) has no sub-optimal basin.
The key of the proof is to compute the values of g(Y) for any Y. Roughly speaking, the value g(Y)
can be computed by the following process:
(1)	We can build a graph with vertices representing distinct values in x0is, yi0s and draw directed
edges from xi to yi. This graph can be decomposed into cycles and trees.
(2)	Each vertex in a cycle contributes - n log2 to the value g(Y).
(3)	Each vertex in a tree contributes 0 to the value g(Y).
Putting these ideas together, the value g(Y) equals -1 log2 times the number of vertices in the
cycles.
The outline of this section is as follows. In the first subsection, as a warm-up example, we prove that
if {y1, y2, . . . , yn } = {x1, . . . , xn }, then Y is a global minimum of g(Y). In the second subsection,
as another warm-up example, we prove that if there exists some yi ∈/ {x1, . . . , xn }, then it is not a
global minimum. In the third subsection, we prove Proposition 2, in three steps. The proofs of some
technical lemmas will be provided in the remaining subsections.
G.1 Warm-up example 1: All generated points match the true points
Prove that if {y1, y2, . . . , yn } = {x1, . . . , xn }, then Y is a global minimum of g(Y).
Suppose yi = xσ(i), then (σ(1), σ(2), . . . , σ(n)) is a permutation of (1, 2, . . . , n). We view σ as
a mapping from {1, 2, . . . , n} to {1, 2, . . . , n}. Pick an arbitrary i, then in the infinite sequence
i, σ(i), σ(σ(i)), σ(3) (i), . . . there exists at least two numbers that are the same. Suppose σ(k0) (i) =
σ(k0+T) (i) for some k0, T, then since σ is a one-to-one mapping we have i = σ(T) (i). Then we
obtain a cycle C = (i, σ(i), σ(2) (i), . . . , σ(T -1) (i)).
We can divide {1, 2, . . . , n} into the collection of finitely many cycles C1, C2, . . . , CK. Each cycle
Ck = (ck(1), ck(2), . . . , ck(mk)) satisfies ck(j + 1) = σ(ck(j)), j = 1, 2, . . . ,mk where ck(mk +
23
Under review as a conference paper at ICLR 2020
1) is defined as ck(1). Now we calculate the value of g(Y ).
1n
g(Y) = sup -	log
fn
i=1
1 + exp(f(yi) - f(xi)))
1
1
=一 inf —ΣΣlog (1 + exp(f(yi) 一 f(xi))))
k=1 i∈Ck
K mk
=-in f 1∑∑log (1 + exp(f (Xck(j+1)) — f (xck(jɔ))))
f n k=1 j=1
K	mk
=) 一 n X inf X log (ι+eχpf (Xck(j+1))- f (Xckj)))))
k=1	j=1
1K
——X inf
n t1,t2,...,tmk ∈R
k=1	k
mk-1
log (1 + exp(tj+1 一 tj)) + log (1 + exp(t1 一 tmk))
j=1
1K
(=) -^ £mk log(1 + exp(0))
n k=1
= 一 log 2.
Here (i) is because {1, 2, . . . , n} is the combination of C1, . . . , CK and i ∈ Ck means that i = ck(j)
for some j. (ii) is because Ck’s are disjoint and f can be any continuous function; more specifically,
the values of f at Xi’s for i in two different cycles are independent, i.e., the choice of {f(Xi) : i ∈
Ck1 } is independent of the choice of {f(Xi) : i ∈ Ck2} if k1 6= k2, thus we can take the infimum
over each cycle (i.e. put “inf” inside the sum over k). (iii) is because Pjm=-11 log(1 + exp(tj+1 一
tj)) + log (1 + exp(t1 一 tm)) is a convex function of t1, t2, . . . , tm and the minimum is achieved
at t1 = t2 = . . . tm = 0.
G.2 Warm-up example 2: new point generated
Suppose yj ∈ {X1, . . . , Xn}, ∀j, and there exist some Xi0 that is not equal to any yj. In this part,
we compute the value g(Y) and show that Y is not a global minimum. The computation for this
example will illustrate how a “free” variable reduces the objective value g(Y) by at least 一* log 2.
Later in the general proof, we will see that any vertex not in a cycle will reduce the objective value
by exactly 一 n log2.
Consider the term log(1 + exp(f (yi0) 一 f (Xi0))). Since Xi0 does not appear in any other term in
Pi log(1 + exp(f(yi) 一 f (Xi))), the choice of f(Xi0) is free. Therefore, no matter what values of
f(X1), . . . , f(Xi0-1), f(Xi0+1), . . . ,f(Xn ) andf(y1), . . . ,f(yn ) are, we can always pick f (Xi0) so
that f (yio) ― f(xio) → -∞, making the term log(1+exp(f 3。) ― f(χi°))) → 0.
1n
g(Y) = -"f — £log(i + exp(f(yi) - fE))))
f n i=1
=一 "f1 X log(1+exp(f (yi) 一 f (Xi)))) + O
fn
i6=i0
≥ 一1X log(i +1)
n
i6=i0
=一 n_1 log 2.
n
G.3 Formal proof of Proposition 2
This proof is divided into three steps. In Step 1, we compute the value of g(Y) if all yi ∈
{X1, . . . , Xn }. This is the major step of the whole proof. In Step 2, we compute the value of g(Y)
24
Under review as a conference paper at ICLR 2020
for any Y . In Step 3, we show that if Y is not a global minimum, then there is a non-decreasing
continuous path from Y to a global minimum.
G.3.1 STEP 1: COMPUTE g(Y) THAT ALL yi ∈ {x1, . . . , xn}
Assume
yi ∈ {x1, . . . ,xn},∀i.	(21)
We build a directed graph G = (V, A) as follows. The set of vertices V = {1, 2, . . . , n} represents
x1 , x2 , . . . , xn . We draw a directed edge (i, j) ∈ A if yi = xj ; in this case, there is a term log(1 +
exp(f (xj) - f(xi))) in the expression of g(Y ). Note that in this directed graph, it is possible to
have a self-loop (i, i), which corresponds to the case yi = xi. Because of the assumption (21), we
can simply express
1n
g(Y)=-呼-£log(1 + exp(f(yi) - f(xi))))
f n i=1
=-inf n X log(1 +exp(f (Xj) - f (Xi)))).
f n (i,j)∈A
Each yi correspond to a unique Xj, thus the outdegree of i, denoted as outdegree(i), must be exactly
1; in other words, for each i there is exactly one directed edge going out from i. The indegree of
each i, denoted as indegree(i), can be any number in {0, 1, . . . ,n}.
To proceed, we need a few definitions from standard graph theory.
Definition G.1 (walk, path and cycle) In a directed graph G, a directed walk (or more simply,
walk) W = (v0, e1, v1, e2, . . . , vm-1, em, vm) is a sequence of vertices and edges such that vi ∈ V
for every i ∈ {0, 1, . . . , m} and ei is a directed edge from vi-1 to vi for every i ∈ {1, . . . , m}.
The set of vertices in W is denoted as V (W), and the set of edged in W is denoted as A(W). If
v0, v1, . . . , vm are distinct we call it a directed path (or path), and we say the length of the path is
m. If v0, v1, . . . , vm-1 are distinct and vm = v0, we call it a directed cycle (or cycle).
Note that we always say v has a path to itself v (with length 0), no matter whether there is an edge
between v to itself or not. This is because the degenerate walk W = (v) satisfies the conditions of
the above definition.
Definition G.2 (tree) A directed tree is a directed graph T = (V, A) with a designated node r ∈ V,
the root, such that there is exactly one path from v to r for each node v ∈ V and there is no edge
from the root r to itself. The depth of a node in a tree is the length of the path from the node to
the root (define the depth of the root to be 0). A subtree of a directed graph G is a subgraph T of
G = (V, A) which is a directed tree. The set of vertices in T is denoted as V (T), and the set of
edged in T is denoted as A(T ).
We prove a lemma that states that the graph can be decomposed into the union of cycles and trees.
A graphical illustration is given in Figure 10.
Lemma 2 Suppose G = (V, A) is a directed graph and outdegree(v) = 1, ∀v ∈ V. Then we have
the following:
(a)	There exist cycles C1, C2, . . . , CK and subtrees T1, T2, . . . , TM such that each edge v ∈ A
appears either in exactly one of the cycles or in exactly one of the subtrees.
(b)	The root of each subtree um is a vertex of a certain cycle Ck where 1 ≤ k ≤
K. In addition, each vertex of the graph appears in exactly one of the following sets:
V(C1),...,V(CK),V(T1)\{u1},...,V(TM)\{uM},
(c)	There is at least one cycle in the graph;
25
Under review as a conference paper at ICLR 2020
Figure 9: The first figure is a connected component of a graph. It contains 10 vertices and 10 directed
edges. It can be decomposed into a cycle and two subtrees. The cycle consists of vertices 1, 2, 3, 4.
The first subtree consists of edge (10, 4) and vertices 10, 4, and the second subtree consists of edges
(8, 7), (9, 7), (7, 5), (6, 5), (5, 1). The second figure is another connected component of the same
graph as the first figure. It has one cycle being a self-loop, and two trees attached to it. The third
figure is an example of Lemma 3. There is one vertice 9 with outdegree 0, which corresponds to
y6 and y7 since both 6 and 7 are connected to it. The fact that the two edges have the same head 9
implies that y6 = y7.
(c) Example for Lemma 3
With this lemma, we are ready to compute the value g(Y ). According to Lemma 2, we have
n
- ng(Y) = infXlog(1 + exp(f(yi) - f(xi))))
f i=1
KM
=叩 X X log(1+exp(f(yi) - f(xi))))+ X X	log(1+exp(f(yi) - fE))))
f	k=1 i∈V (Ck)	m=1 i∈V (Tm)\{um}
K
≥ , X X log(1+exp(f(yi) - f(xi))))，gcyc.
f	k=1 i∈V (Ck)
(23)
We then compute gcyc . Since Ck is a cycle, we have Xk , {xi : i ∈ Ck } = {yi : i ∈ Ck }. Since
the cycles Ck's are disjoint, We have Xk ∩ Xi = 0, ∀k = l, meaning that the values f (xi), f (yi) for
i in one cycle Ck are independent of the values corresponding to a different cycle Cl. Then the sum
in the expression of gcyc can be decomposed according to different cycles.
K
gcyc =呼 X X log (1 + exp(f (yi) — f (xi))))
f k=1 i∈V (Ck)
K
= Xinff X log (1 +exp(f(yi) - f(xi))))
k=1 f i∈V (Ck)
Similar to Step 1, We can shoW that the infimum for each cycle is achieved When the values f(xi) =
f(xj), ∀i, j ∈ V (Ck). A more detailed proof is given as folloWs. Pick an arbitrary k, and suppose
all the edges of Ck are (v1, v2), (v2, v3), . . . , (vr-1, vr), (vr, v1), Where r = |V (Ck)| is the number
26
Under review as a conference paper at ICLR 2020
of vertices in the cycle Ck. Denote vr+1 = v1. Then
inf X log (1 +exp(f(yi) - f (xi))))
f i∈V (Ck)
r
=i *nf X log (1+exp(f (χVj + ι ) - f (Xvj))))
f j=1	(24)
r-1
= inf	log (1 + exp(tj+1 - tj))) +log(1 + exp(t1 - tr)))
t1 ,t2,...,tr ∈R
j=1
=r log 2 = |V (Ck)| log 2.
The infimum is achieved when f (xvj =…=f (Xvr), or equivalently, f(Xi) = f(Xj), ∀ij ∈
V (Ck ). Therefore,
K
gcyc = log2X |V(Ck)|.	(25)
k=1
According to (23) and (25), we have
K
-ng(Y) ≥ X |V(Ck)I log2.	(26)
k=1
Next, we prove that for any > 0, there exists a continuous function f such that
K
-ng(Y) < X|V(Ck)|log2+.	(27)
k=1
Let N be a large positive number such that
n log (1 + exp(-N))) < .	(28)
Pick a continuous function f as follows.
f(Xi) = (0N, dh i∈ SSkKM=1VV(CTk),	(29)
[N ∙ depth(i), i ∈ Um=I V(Tm).
Note that the root um of a tree Tm is also in a certain cycle Ck, thus the value f (Xum ) is defined
twice in (29), but in both definitions its value is 0, thus the definition is valid. For any i ∈ V(Ck),
suppose yi = Xj, then both i,j ∈ V(Ck) which implies f(yi) -f(Xi) = f(Xj) -f(Xi) = 0. For any
i ∈ V(Tm)\{um}, suppose yi = Xj, then by the definition of the graph (i,j) is a directed edge of
the tree Tm, which means that depth(i) = depth(j)+1. Thus f(yi) -f(Xi) = f(Xj) -f(Xi) = -N.
In summary, for the choice of f in (29), we have
f(yi) - f(Xi) =	0-,N,
i ∈ SkK=1 V (Ck),
i ∈ SmM=1 V (Tm).
(30)
27
Under review as a conference paper at ICLR 2020
For the choice of f in (29), we have
-nF(Y;f)
n
= X log (1 + exp(f(yi) - f(xi))))
i=1
-K	M	'
= X X log(1 + exp(f (yi) - f (xi)))) + X X log(1 + exp(f (yi) - f (xi))))
k=1 i∈V (Ck)	m=1 i∈V (Tm)\{um}
-K	M	-
(IO) X X iog(ι + eχp(0)))+ X X log(1 + exp(-N)))
k=1 i∈V (Ck)	m=1 i∈V (Tm)\{um}
KM
=X|V(Ck)|log2+X(|V(Tm)| -1)log(1+exp(-N)))
k=1	k=1
K
≤X |V(Ck)| log2 +nlog(1 + exp(-N)))
k=1
(28)	K
<	|V (Ck )| log 2 + .
k=1
This proves (27).
Combining (26) and (27), we have -ng(Y ) = PkK=1 |V (Ck)| log 2, or equivalently,
1K
g(Y ) = 1 X
n
k=1
|V(Ck)|log2.
G.3.2 STEP 2: COMPUTE g(Y) FOR ANY Y
In the general case, not all yi’s lie in the set {x1, . . . , xn}. Denote the set
H = {i : yi ∈ {x1, . . . , xn}}, Hc = {j : yj ∈/ {x1, . . . , xn}}.
Since yj’s in Hc may be the same, we define the set of such distinct values of yj’s as
Yout = {y ∈ Rd : y = yj , for some j ∈ Hc}.
Let nout = |Yout|, then there are total n + nout distinct values in x1, . . . , xn, y1, . . . , yn. Without loss
of generality, assume y1, . . . , ynout are distinct (this is because the value of g(Y) does not change if
we re-index xi’s and yi’s as long as the subscripts of xi, yi change together), then
Yout = {y1 , . . . , yn
out .
We build a directed graph G = (V, A) as follows. The set of vertices V = {1, 2, . . . , n, n +
1, . . . , n + nout} represents x1, x2, . . . , xn and y1, . . . , ynout . For i, j ≤ n, we draw a directed edge
(i, j) ∈ A if yi = xj; in this case, there is a term log(1 + exp(f (xj) - f(xi))) in the expression
of g(Y). For 1 ≤ i ≤ n and 1 ≤ j ≤ nout, we draw a directed edge (i, n + j) ∈ A if yi = yj; in
this case, there is a term log(1 + exp(f (yj) - f (xi))) in the expression of g(Y). Note that in this
directed graph, it is possible to have a self-loop (i, i), which corresponds to the case yi = xi.
This graph has the following property: for each 1 ≤ i ≤ n, the outdegree is exactly 1; for each
n ≤ j ≤ n + nout, the outdegree of j is 0. Moreover, each vertex representing some yi has an
incoming degree at least 1 (since otherwise this vertex will not be created); note that an vertex
representing xi may have incoming degree 0. We present a lemma which is an extension of the
Lemma 2. The proof is given in Appendix G.5.
Lemma 3 Suppose G = (V, A) is a directed graph and outdegree(v) ≤ 1, ∀v ∈ V. Then we have
the following:
28
Under review as a conference paper at ICLR 2020
(a)	There exist cycles C1, C2, . . . , CK and subtrees T1, T2, . . . , TM such that each edge v ∈ A
appears either in exactly one of the cycles or in exactly one of the subtrees.
(b)	Denote the root of subtree Tm as um, m = 1, . . . , M. Then um is either a vertex of a certain
cycle Ck where 1 ≤ k ≤ K, or a vertex with outdegree 0.
(c)	Suppose u1 , . . . , uM0 are in a certain cycle, and uM0+1, . . . , uM have outdegree
0.	Then each vertex of the graph appears in exactly one of the following sets:
V(C1),...,V(CK),V(T1)\{u1},...,V(TM0)\{uM0},V(TM0+1),...,V(TM).
Note that (b) is different from Lemma 2, because under the assumption of that lemma that each
vertex has an outgoing edge, the root of a tree cannot have outdegree 0.
The computation of g(Y ) is quite similar to the previous case. We will highlight a few small differ-
ences. We still have
- ng(Y)
n
= inff X ξ(f (yi) - f (xi))
f i=1
KM
=ff X X ξ(f(yi)-f(χi))+ X X	ξ(f(yi)- f(xi)
k=1 i∈V (Ck )	m=1 i∈V (Tm )\{um }
K
≥ inf X X Iog(I + eχp(f(Ui)- f(Xi))))
k=1 i∈V (Ck)
△〜
,gcyc .
(31)
Same as before, we have gcyc = PkK=1 |V (Ck)| log 2. Once we fix the values of f(xi) to be a
constant for i in cycles (which makes the first sum achieves the value PkK=1 |V (Ck)| log 2), we can
always pick the values of f on the vertices j in the trees so that f(yj ) - f(xj) → ∞. Therefore, we
have
K
-ng(Y ) = gcyc = X |V (Ck)| log 2.
k=1
G.3.3 Step 3: Finding a non-decreasing path to a global minimum
Finally, we prove that for any Y , there is a non-decreasing continuous path from Y to one global
minimum Y*. In other words, there is a continuous function η : [0,1] → Rd×n such that η(0)=
Y, η(1) = Y * and g(η(t)) is a non-decreasing function with respect to t ∈ [0,1]. In this proof, We
will just describe the path in words, and skip the rigorous definition of the continuous function η,
since it should be clear from the context how to define η.
The following claim shows that we can increase the value of Y incrementally; see the proof in
Appendix G.6
Claim G.1 For an arbitrary Y that is not a global minimum, there exists another Y and a non-
1
decreasing continuous path from Y to Y such that g(Y) 一 g(Y) ≥ n log 2.
For any Y that is not a global minimum, we apply Claim G.1 for finitely many times (no more than
n times), then we will arrive at one global minimum Y*. We connect all non-decreasing continuous
paths, and get a non-decreasing continuous path from Y to Y*. This finishes the proof of Proposition
2.
G.4 Proof of Lemma 2
We first prove a few observations. We will slightly extend the definition of “walk” to allow a walk
with infinite length.
29
Under review as a conference paper at ICLR 2020
Observation 1: Suppose in a directed graph G = (V, A), any vertex has outdegree exactly 1.
Starting from any vertex v0 ∈ V (G), there is a unique walk with infinite length
W(v0) , (v0,e1,v1,e2,v2, . . . ,vi,ei,vi+1,ei+1, . . . ),
where ei is an edge in A(G) with tail vi-1 and head vi.
Proof of Observation 1: At each vertex vi, there is a unique outgoing edge ei = (vi, vi+1) which
uniquely defines the next vertex vi+ι. Continue the process, We have proved Observation 1. □
Observation 2: Suppose in a directed graph G = (V, A), any vertex has outdegree exactly 1.
Suppose the unique Walk starting from v0 is W(v0) , (v0, e1, v1, e2, v2, . . . , vi, ei, vi+1, ei+1, . . . ),
then the Walk can be decomposed into tWo parts
W1(v0) = (v0,e1,v1,e2,v2, . . . ,vi0-1,ei1,vi0),
W2(v0) = (vi0,ei0+1,vi0+1,ei0+2,vi0+2, . . . ),
Where W1(v0) is a directed path from v0 to vi0 (i.e. the vertices v0, v1, . . . , vi0 are distinct), and
W2 (v0) is the repetition of a certain cycle (i.e. there exists T such that vi+T = vi, for any i ≥ i0).
This decomposition is unique.
Proof of Observation 2: Since there are only finitely many vertices in the graph, then some vertices
must appear at least tWice in W (v0). Among all such vertices, suppose u is the one that appears
the earliest in the Walk W(v0), and the first tWo appearances are vi0 = u and vi1 = u and i0 < i1.
Denote T = i1 - i0 . Since there is a unique edge going out from any vertex, thus vi0+1 must
be the same as vi1+1 = vi0+1+T. Continue the process, We have vi = vi+T for any i ≥ i0.
Thus starting from u = vi0, the Walk W2(v0) Will be repetitions of the cycle consisting of vertices
vi0 , vi0+1, . . . , vi1-1, and We denote this cycle as Ck0.
If the vertices before vi1 are not distinct, then there are at least tWo vertices vj = vl Where 0 ≤ j <
l ≤ i0. This contradicts the definition of i0. Therefore, W1(v0) is a directed path from v0 to vi0. □
In Observation 2, for any v0 ∈ V , the “transition point” vi0 in the infinite Walk W (v0) is unique.
We define the “first-touch-vertex” of v0 to be vi0 . The first-touch-vertex u = vi0 has the folloWing
properties: (i) u ∈ Ck for some k; (ii) there exists a path from v to u; (iii) any paths from v to
any vertex in the cycle Ck other than u must pass u. In other Words, if an ant starts from v0 and
craWls along the edges, the first vertex in a cycle that it touches is u. Since any v0 corresponds to a
unique W (v0), its first-touch-vertex must exist and unique. Note that if u is in some cycle, then its
first-touch-point is u itself.
As a corollary of Observation 2, there is at least one cycle in the graph. Suppose all cycles of G
are C1 , C2 , . . . , CK. Because the outdegree of each vertex is 1, these cycles must be disjoint, i.e.,
V(Ci) ∩ V(Cj) = 0 and A(Ci) ∩ A(Cj) = 0, forany i = j.
Define R to be the set of vertices of C1, . . . , Cm With indegree at least tWo, i.e.,
R , {v : v ∈ Ck for some k, and indegree(v) ≥ 2}.
Suppose the elements of R are u1, . . . , uM. We denote the set of vertices in the cycles as
K
匕=U V (Ci) ∪∙∙∙∪ V(CK).	(32)
k=1
We describe the intuition behind the partitioning of G. Based on Observation 2, starting from any
vertex outside of Vc there is a unique path that reaches Vc . Combining all vertices that reach the
cycles atum (denoted as Vm), and the paths from these vertices to um, We obtain a directed subgraph
Tm, Which is connected With Vc only via the vertex um . The subgraphs Tm ’s are disjoint from each
other since they are connected With Vc via different vertices. In addition, each vertex outside of Vc
lies in exactly one of the subgraph Tm. Thus, We can partition the Whole graph into the union of the
cycles C1 , . . . , CK and the subgraphs T1 , . . . , TM .
30
Under review as a conference paper at ICLR 2020
Next, we provide more formal definitions and proofs. For any m ∈ {1, 2, . . . , M}, define
Vm = {v ∈ V(G) : Um is the first-touch-vertex of v},	(33a)
Vm = Vm\{Umh	(33b)
Am = {e ∈ A(G) : the tail of e is in Vm},	(33c)
Tm = (Vm,Am) isaSUbgraPhofG.	(33d)
We first show that V1, V2, . . . , VM and V(C1), . . . , V(CK) form a partition of the edge set of G,
i.e.,
V(G) = [K V(Ck) [	[M Vm ,	(34a)
k=1	m=1
Vm ∩ Vc = 0, ∀m,s,.	(34b)
Vm ∩ V(Ck)= 0, ∀m,k.	(34c)
V(Ck)∩V(Cl) =0, ∀k 6=l,	(34d)
For any vertex v ∈/ SkK=1 V(Ck) , its first-touch-vertex w must be different from v (otherwise v
would be in a certain cycle). Since w is in a cycle, denoted as Ck0, there is a directed edge with head
w; in addition, since w is a first-touch-vertex ofv ∈/ Ck0, then there must be another edge with head
w. Thus the indegree of w is at least 2, which means w ∈ R. Thus w = Um for some m, which
imPlies v ∈ Vm. Since any v ∈/ SkK=1 V(Ck) must belong to Vm for some m, we have Proved
(34a).
Since each vertex v has a unique first-touch-vertex, thus a vertex cannot lie in two different sets Vm
and Vs, which Proves (34b). Assume (34c) does not hold, i.e., there exists some v ∈ V(Ck) ∩ Vm
for some k, m. Since the first-touch-vertex of v is v itself, according to (33a) we have v = Um; but
according to (33b) v = Um ∈/ Vm, a contradiction. Thus (34c) holds. (34d) is obvious.
Next, we show that the edge sets of T1, . . . , Tm and C1, . . . , CK form a Partition of the edge set of
G, i.e.,
A(G) =	[K A(Ck) [	[M A(Tm) ,	(35a)
k=1	m=1
A(Tm)∩A(Ts) =0,	∀m,s,.	(35b)
A(Tm)∩A(Ck) =0,	∀m, k.	(35c)
A(Ck)∩A(Cl) =0,	∀k 6=l,	(35d)
These relation can be Proved easily by (34) and the definitions (33c) and (33d). For any edge
e1 ∈ A(G)\ SkK=1 A(Ck) , we want to show that e1 lies in at least one Tm. SuPPose e1 = (v0, v1)
where v0, v1 ∈ V (G). Since e1 is not in a cycle, v0 ∈/ Vc, thus by (34a) we have v0 ∈ Vm for a
certain m, which further imPlies e1 ∈ Am = A(Tm) by the the definitions (33c) and (33d). Thus
we Proved (35a). Any edge e in A(Tm) has a tail U ∈ V(Tm), thus according to (34b) we know
U ∈/ Vs, ∀s 6= m. By the definition (33c), we have e ∈/ Am = A(Tm), which Proves (35b). Similarly,
any edge e in A(Ck) has a tail U ∈ V(Ck), thus according to (34c) we know U ∈/ Vm, ∀m, thus
we have e ∈/ Am = A(Tm), which Proves (35c). The last one (35d) holds because the cycles are
disjoint.
Finally, we Prove that for any m ∈ {1, 2, . . . , M}, Tm is a subtree of G with the root Um. For any
vertex v0 in the subgraPh Tm, consider the walk W (v0). Any Path starting from v0 must be Part
of W(v0). Starting from v0 there is only one Path from v0 to Um which is W1(v0), according to
Observation 2. Therefore, by the definition of directed tree, Tm is a directed tree with the root Um.
G.5 Proof of Lemma 3
We utilize the result of Lemma 2 to Prove Lemma 3. More sPecifically, we will reduce to the case
of Lemma 2.
31
Under review as a conference paper at ICLR 2020
We build anew graph as follows. Denote the set of vertices in G that have outdegree 0 as D0. For any
vertice in D0, we add an edge from D0 to itself (a self-loop), and obtain a new graph G = (V, A).
Now each vertice in G has outdegree exactly 1.
Each self-loop is a length-1 cycle, thus by adding edges to vertices in D0 we have created |D0 |
length-1 cycles, denoted as CK+1, . . . , CK+|D0|. Suppose all other cycles are C1, C2, . . . , CK.
According to Lemma 1, there exist cycles C1, C2, . . . , CK, CK+1, . . . , CK+|D0| and subtrees
T1,T2,..., TM such that: (a) Each edge V ∈ A appears either in exactly one of the cycles or in
exactly one of the subtrees. (b) The root of each subtree um is a vertex of a certain cycle Ck where
1 ≤ k ≤ K + |D0|. In addition, each vertex of the graph appears in exactly one of the following
sets: V(C1),...,V(CK),V(T1)\{u1},...,V(TM)\{uM},
Now we remove the edges added to vertices in D0 and restore the original graph. Then we have
removed the cycles CK+1, . . . , CK+|D0| and do not change other cycles and subtrees. We do change
the relations between the trees and the cycles: previously, the root of each tree is a vertex in a certain
cycle; now, since some cycles are removed, the roots of some trees will be a vertex with outdegree
0. Suppose these trees are TM0+1, TM0+2, . . . , TM.
After removing the edges added to vertices in D0, C1, C2, . . . , CK and subtrees T1, T2, . . . , TM sat-
isfy the following: (a) Each edge v ∈ A appears either in exactly one of the cycles or in exactly one
of the subtrees. (b) Denote the root of subtree Tm as um, m = 1, . . . , M. Then um is either a vertex
ofa certain cycle Ck where 1 ≤ k ≤ K, or a vertex with outdegree 0. (c) Each vertex of the graph ap-
pears in exactly one of the following sets: V (C1), . . . , V (CK), V (T1)\{u1}, . . . , V (TM0)\{uM0},
V (TM0+1), . . . , V (TM).
G.6 Proof of Claim G.1
We first prove the case for d ≥ 2. Suppose the corresponding graph for Y is G, and G is decomposed
into the union of cycles C1, . . . , CK and trees T1, . . . , Tm. We perform the following operation: pick
an arbitrary tree Tm with the root um . We claim that there must be an edge e with the head um . If
um > n (i.e. um represents some yi), then there must be an incoming edge to um, thus the claim
holds. If um ≤ n (i.e. um represents some xi), then um must have an outgoing edge, and this edge
must be in a cycle (otherwise um cannot be the root). Thus um is chosen to be in a tree Tm must
because um is a head of an edge.
Suppose v is the tail of the edge e. Now we remove the edge e = (v, um) and create a new
edge e0 = (v, v). The new edge corresponds to yv = xv. The old edge (v, um) corresponds to
yv = xum (and a term ξ(f (xum) - f (xv))) if um ≤ n or yv = yum-n ∈/ {x1, . . . ,xn} (and a
term ξ(f(yum-n) - f (xv))) if um > n. This change corresponds to the change of yv: we change
yv = Xum (if Um ≤ n) or yv = yUm-n (if Um > n) to yv = Xv . Let yi = yi for any i = v.
Previously v is in a tree Tm, now v is the head ofa new tree, and also part of the new cycle CK+1 =
(v, e0, v). In this new graph, the number of vertices in cycles increases by 1, thus the value of g
increases by - 1 log 2, i.e., g(Y) - g(Y) = 1 log 2.
Since d ≥ 2, we can find a path in Rd from a point to another point without passing any of the points
in {xι,..., Xn}. In the continuous process of moving yv to yv, the function values will not change
except at the end that yv = Xv. Thus there is a non-increasing path from Y to Y, in the sense that
along this path the function values of g does not decrease.
The illustration of this proof is given as below.
32
Under review as a conference paper at ICLR 2020
(a) Original graph
(b) Modified graph, with improved function value
Figure 10: Illustration of the proof of Claim G.1. For the figure on the left, we pick an arbitrary tree
with the head being vertex 9, which corresponds to y6 = y7. We change y7 to y7 = χ7 to obtain the
figure on the right. Since one more cycle is created, the function value increases by -1 log2.
For the case d = 1, the above proof does not work. The reason is that the path from yv to Iyv may
touch other points in {x1, . . . , xn} and thus may change the value of g. We only need to make a
small modification: we move yv in R until it touches a certain xi that corresponds to a vertex in the
tree Tm, at which point a cycle is created, and the function value increases by at least 1 log 2. This
path is a non-decreasing path, thus the claim is also proved.
H Generated S amples in S imulation
Here we show some samples of generated data in the appendix.
33
Under review as a conference paper at ICLR 2020
(c)
(d)
(e)
Figure 11: Generated (a)MNIST (b) CIFAR-10 (c) CelebA (d) LSUN samples by CPGAN.
34