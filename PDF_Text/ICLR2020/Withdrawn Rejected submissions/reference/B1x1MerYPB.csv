title,year,conference
 Unsupervised neural machinetranslation,2018, In Proceedings of ICLR
 An effective approach to unsupervised machinetranslation,2019, In Proceedings of ACL
 The mathe-matics of statistical machine translation: Parameter estimation,1993, Computational Linguistics
 Semi-supervised learning for neural machine translation,2016, In Proceedings of ACL
 Transformer-xl: Attentive language models beyond a fixed-length context,2019, In Proceedingsof ACL
 RePUrposing decoder-transformer language modelsfor abstractive summarization,2019, ArXiv
 Unified langUage model pre-training for natUral langUage Understandingand generation,2019, CoRR
 Understanding back-translation atscale,2018, In Proceedings of EMNLP
 On Using monolingUal corpora in neUral ma-chine translation,2015, CoRR
 Document context neural machine translation with memorynetworks,2018, In Proceedings of ACL
 Sequence-level knowledge distillation,2016, In Proceedings ofEMNLP
 Adam: A method for stochastic optimization,2015, In Proceedingsof ICLR
 Cache-based document-level neuralmachine translation,2017, CoRR
 Cross-lingual language model pretraining,2019,	CoRR
 Unsupervisedmachine translation using monolingual corpora only,2018, In Proceedings of ICLR
 Learned in translation:Contextualized word vectors,2017, In Proceedings of NeurIPS
 Regularizing and optimizing LSTMlanguage models,2018, In Proceedings of ICLR
 An analysis of neural language modelingat multiple scales,2018, CoRR
 Facebook fair’sWMT19 news translation task submission,2019, In Proceedings of WMT
 Deep contextualized word representations,2018, In Proceedings of NAACL
 A call for clarity in reporting BLEU scores,2018, In Proceedings of WMT
 Improving language under-standing by generative pre-training,2018, 2018
 Languagemodels are unsupervised multitask learners,2019, OpenAI Blog
 Improving neural machine translation modelswith monolingual data,2016, In Proceedings of ACL
 Neural machine translation of rare words withsubword units,2016, In Proceedings of ACL
 The Mathematical Theory of Communication,1949, Universityof Illinois Press
 A study oftranslation edit rate with targeted human annotation,2006, In Proceedings of AMTA
 MASS: masked sequence to sequencepre-training for language generation,2019, In Proceedings of ICML
 Baidu neuralmachine translation systems for wmt19,2019, In Proceedings of WMT
 Context-aware neural machine trans-lation learns anaphora resolution,2018, In Proceedings of ACL
 Learning to remember translation historyWith a continuous cache,2018, TACL
 Attention is all you need,2017, In Proceedings of NeurIPS
 Exploiting cross-sentence context for neuralmachine translation,2017, In Proceedings of EMNLP
 Document-level neural machine translation with hierarchical attention networks,2018, In Proceedings of EMNLP
 Microsoft research asia’s systems for wmt19,2019, In Proceedings of WMT
 Xlnet: Generalized autoregressive pretraining for language understanding,2019, CoRR
 Simple and effective noisy channel modeling for neuralmachine translation,2019, In Proceedings of EMNLP
 The neural noisychannel,2017, In Proceedings of ICLR
 Defending against neural fake news,2019, arXiv preprint arXiv:1905
 Improving the transformer translation model with document-level context,2018, In Proceedingsof EMNLP
 Encoder-agnostic adaptation for conditional language generation,2019, CoRR
