title,year,conference
 State-of-the-art in artificial neural network applications:A survey,2018, Heliyon
 Natural gradient works efficiently in learning,0899, NeUral Comput
 Classification in the presence of label noise: a survey,2013, IEEEtransactions on neural networks and learning systems
 Co-teaching: Robust training of deep neural networks with extremely noisy labels,2018, InAdVanceS in neural information PrOceSSing systems
 Understanding generalization of deep neural networks trainedwith noisy labels,2019, arXiv PrePrint arXiv:1905
 Adam: A method for stochastic optimization,2014, CoRR
 Openimages: A public dataset for large-scale multi-label andmulti-class image classification,2016, DataSet available from https:ã€ƒgithub
 StatiStical Physics,2013, Number v
 Gradient descent with early stopping is prov-ably robust to label noise for overparameterized neural networks,2019, arXiv PrePrint arXiv:1903
 Learning word vectors for sentiment analysis,2011, In PrOceedingS of the 49th AnnUal Meetingof the ASSOciatiOn for Computational LingUiStics: HUman LangUage Technologies
 Early stopping without avalidation set,2017, arXiv PrePrint arXiv:1703
 Sgd on neural networks learns functions of increasing complexity,2019, arXiv PrePrintarXiv:1905
 Makingdeep neural networks robust to label noise: A loss correction approach,2017, In PrOCeedingS of theIEEE COnferenCe on COmPUter ViSiOn and Pattern Recognition
 Glove: Global vectors for wordrepresentation,2014, In PrOCeedingS of the 2014 COnference on empirical methods in natural IangUageprocessing (EMNLP)
 Understandingdeep learning requires rethinking generalization,2017, 2017
 Deep gamblers: Learning to abstain with portfolio theory,2019, arXiv PrePrintarXiv:1907
