title,year,conference
 Obfuscated gradients give a false sense ofsecurity: Circumventing defenses to adversarial examples,2018, arXiv preprint arXiv:1802
 Unrestricted adversarial examples,2018, arXiv preprint arXiv:1809
 Thermometer encoding: One hot wayto resist adversarial examples,2018, In International Conference on Learning Representations
 Towards evaluating the robustness of neural networks,2017, In 2017IEEE Symposium on Security and Privacy (SP)
 Certified adversarial robustness via randomizedsmoothing,2019, arXiv preprint arXiv:1902
 Adual approach to scalable verification of deep networks,2018, In UAI
 The algorithmic foundations of differential privacy,2014, Foundationsand TrendsR in Theoretical Computer Science
 Spectrum estimation for large dimensional covariance matrices usingrandom matrix theory,2008, The Annals of Statistics
 Characterizing adversarial subspaces using localintrinsic dimensionality,2018, arXiv preprint arXiv:1801
 Distillation as adefense to adversarial perturbations against deep neural networks,2016, In 2016 IEEE Symposium onSecurity and Privacy (SP)
 Certified defenses against adversarialexamples,2018, In International Conference on Learning Representations
 Intriguing properties of neural networks,2014, In International Conference on LearningRepresentations
 Provable defenses against adversarial examples via the convex outeradversarial polytope,2017, arXiv preprint arXiv:1711
 Spatially transformedadversarial examples,2018, arXiv preprint arXiv:1801
