title,year,conference
 Online learning in mdps with side information,2014, arXivpreprint arXiv:1406
 Regret Bounds for the Adaptive Control of LinearQuadratic Systems,2011, Technical report
 Regret bounds for model-free linearquadratic control,2018, arXiv preprint arXiv:1804
 Learning linear-quadratic regulators efficientlywith only âˆšT regret,2019, arXiv preprint arXiv:1902
 Policy certificates: Towards accountablereinforcement learning,2018, arXiv preprint arXiv:1811
 On the sample com-plexity of the linear quadratic regulator,2017, arXiv preprint arXiv:1710
	Re-gret bounds for robust adaptive control of the linear quadratic regulator,2018, InS
 Transfer learning for related reinforcement learning tasks viaimage-to-image translation,2018, arXiv preprint arXiv:1806
 Contextual markov decision processes,2015, arXivpreprint arXiv:1502
 Transfer learning across patient varia-tions with hidden parameter markov decision processes,2016, arXiv preprint arXiv:1612
 Reward predictive representations gener-alize across tasks in reinforcement learning,2019, BioRxiv
 Optimal input signals for parameter estimation in dynamic systems-survey and newresults,1974, IEEE Transactions on Automatic Control
 Contextual markov decision processes using generalized linearmodels,2019, arXiv preprint arXiv:1903
 Markov decision processes with con-tinuous side information,2018, In Algorithmic Learning Theory
 Markov Decision Processes,2014,: Discrete Stochastic Dynamic Programming
 Extra: Transfer-guidedexploration,2019, arXiv preprint arXiv:1906
 Sample-efficient reinforcement learning through transfer andarchitectural priors,2018, arXiv preprint arXiv:1801
 Least-squares temporal difference learning for the linear quadraticregUlator,2017, arXiv preprint arXiv:1712
 Learning andplanning with a semantic model,2018, arXiv preprint arXiv:1809
