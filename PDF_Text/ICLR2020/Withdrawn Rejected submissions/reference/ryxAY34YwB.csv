title,year,conference
 Bert: Pre-training of deepbidirectional transformers for language understanding,2018, arXiv preprint arXiv:1810
 Unified language model pre-training for natural language understandingand generation,2019, arXiv preprint arXiv:1905
 Learning-based single-document summa-rization with compression and anaphoricity constraints,2016, arXiv preprint arXiv:1603
 Countering the effects of leadbias in news summarization via multi-stage training and auxiliary losses,2019, EMNLP
 Importance of copying mechanism for news headline generation,2019, arXiv preprintarXiv:1904
 Teaching machines to read and comprehend,2015, Advances in neuralinformation processing Systems
 Earlier isnt always better: Sub-aspect analysis on corpus and system biases in summarization,2019, EMNLP
 Sentencepiece: A simple and language independent subwordtokenizer and detokenizer for neural text processing,2018, arXiv preprint arXiv:1808
 Deep recurrent generative decoder for abstractivetext summarization,2017, arXiv preprint arXiv:1708
 Actor-critic based training framework for abstractive summa-rization,2018, arXiv preprint arXiv:1803
 Rouge: A package for automatic evaluation of summaries,2004, Text SummarizationBranches Out
 On the variance of the adaptive learning rate and beyond,2019, arXiv preprint arXiv:1908
 Text summarization with pretrained encoders,2019, EMNLP
 Learned in translation:Contextualized word vectors,2017, In Advances in Neural Information Processing Systems
 Passage re-ranking with bert,2019, arXiv preprintarXiv:1901
 A deep reinforced model for abstractivesummarization,2017, arXiv preprint arXiv:1705
 Deep contextualized word representations,2018, arXiv preprint arXiv:1802
 Improving language under-standing by generative pre-training,2018, 2018
 A neural attention model for abstractivesentence summarization,2015, arXiv preprint arXiv:1509
 A neural attention model for abstractivesentence summarization,2015, arXiv preprint arXiv:1509
 The new york times annotated corpus,2008, Linguistic Data Consortium
 Get to the point: Summarization with pointer-generator networks,2017, arXiv preprint arXiv:1704
 Attention is all you need,2017, pp
 Bottlesum: Unsupervised and self-supervised sentence summarization using the information bottleneck principle,2019, arXiv preprintarXiv:1909
 Improving abstractive document sum-marization with salient information modeling,2019, Proceedings of the 57th Annual Meeting of theAssociation for Computational Linguistics
