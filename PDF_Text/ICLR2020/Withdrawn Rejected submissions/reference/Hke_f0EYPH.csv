title,year,conference
 Tensorflow: A system for large-scalemachine learning,2016, 2016
 Synthesizing robust adversarial examples,2017, arXiv preprintarXiv:1707
 Obfuscated gradients give a false sense ofsecurity: Circumventing defenses to adversarial examples,2018, ICML
 Rademacher and gaussian complexities: Risk bounds andstructural results,2002, JMLR
 Cnn-cert: An efficientframework for certifying robustness of convolutional neural networks,2019, In AAAI
 Towards evaluating the robustness of neural networks,2017, In IEEESymposium on Security and Privacy (SP)
 Provably minimally-distorted adversarialexamples,2017, arXiv preprint arXiv:1709
 Ead: elastic-net attacks todeep neural networks via adversarial examples,2018, AAAI
 Provable robustness of relu networksvia maximization of linear regions,2019, In AISTATS
 Training verified learners with learned verifiers,2018, arXivpreprint arXiv:1805
 Adual approach to scalable verification of deep networks,2018, UAI
 Ai2: Safety androbustness certification of neural networks with abstract interpretation,2018, In IEEE Symposium onSecurity and Privacy (SP)
 Explaining and harnessing adversarialexamples,2015, ICLR
 On the effectiveness ofinterval bound propagation for training verifiably robust models,2018, arXiv preprint arXiv:1810
 Formal guarantees on the robustness of a classifieragainst adversarial manipulation,2017, In NIPS
 Reluplex: An efficientsmt solver for verifying deep neural networks,2017, In International Conference on Computer AidedVerification
 Provable defenses against adversarial examples via the convex outeradversarial polytope,2018, ICML
 Differentiable abstract interpretation for provablyrobust neural networks,2018, In International Conference on Machine Learning
 Norm-based capacity control in neuralnetworks,2015, JMLR
 Certified defenses against adversarialexamples,2018, ICLR
 A Convex RelaxationBarrier to Tight Robustness Verification of Neural Networks,2019, arXiv preprint arXiv:1902
 Fast andeffective robustness certification,2018, In NeurIPS
 An abstractdomain for certifying neural networks,2019, In POPL
 Certifiable distributional robustness withprincipled adversarial training,2018, ICLR
 Man vs,2012, computer: Benchmarking machinelearning algorithms for traffic sign recognition
 One pixel attack for fooling deep neuralnetworks,2019, IEEE Transactions on Evolutionary Computation
 Intriguing properties of neural networks,2013, arXiv preprint arXiv:1312
 Verifying neural networks with mixed integer programming,2019, InICLR
 Adversarial training and robustness for multiple perturbations,2019, arXivpreprint arXiv:1904
 Efficient formal safetyanalysis of neural networks,2018, In NeurIPS
 Scaling provable adversarialdefenses,2018, arXiv preprint arXiv:1805
 Training for fasteradversarial robustness verification via inducing relu stability,2019, In ICLR
 Efficient neural networkrobustness certification with general activation functions,2018, In NIPS
	`0 Norm Threat Model2,2020,	Model EnsembleI
