title,year,conference
 SMOTE:synthetic minority over-sampling technique,2011, CoRR
 Stochastic dual coordinate ascent with adaptive prob-abilities,2015, In Proceedings of The 32nd International Conference on Machine Learning
 Adaptive subgradient methods for online learning andstochastic optimization,1532, J
 On large-batch training for deep learning: Generalization gap and sharp minima,2016, CoRR
 ADAM: A method for stochastic optimization,2014, CoRR
 On the convergence of ADAM and beyond,2018, InInternational Conference on Learning Representations
 Adaptive variance reducing for stochas-tic gradient descent,2016, In Proceedings of the 32nd International Joint Conference on ArtificialIntelligence
 Training region-based object detectorswith online hard example mining,2016, CoRR
 Safe adaptive importance sampling,2017, CoRR
 Lecture 6,2012,5â€”RMSProp: Divide the gradient by a running average of itsrecent magnitude
 ADADELTA: an adaptive learning rate method,2012, CoRR
