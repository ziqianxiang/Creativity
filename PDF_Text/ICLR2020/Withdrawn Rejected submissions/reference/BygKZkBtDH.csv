title,year,conference
 Neural machine translation by jointlylearning to align and translate,2015, In Proc
 In Proc,2017, of IJCNLP
 Learning phrase representations using RNN encoder-decoderfor statistical machine translation,2014, In Proc
 Recurrent stacking of layers for compact neural machine translationmodels,2019, In Proc
 BERT: Pre-training of deepbidirectional Transformers for language understanding,2019, In Proc
 Exploiting deep represen-tations for neural machine translation,2018, In Proc
 Ensemble distillation for neural ma-chine translation,2017, CoRR
 Deep learning withlimited numerical precision,2015, In Proc
 Sequence-level knowledge distillation,2016, In Proc
 Fixed point quantization of deepconvolutional networks,2016, In Proc
 BLEU: A method for automaticevaluation of machine translation,2002, In Proc
 A call for clarity in reporting BLEU scores,2018, In Proc
 Compression of neural machinetranslation models via pruning,1029, In Proc
 On the importance of initial-ization and momentum in deep learning,2013, In Proc
 Attention is all you need,2017, In Proc
 Multi-layer repre-sentation fusion for neural machine translation,2018, In Proc
 Tied Transformers: Neural machinetranslation with shared encoder and decoder,2019, In Proc
 Accelerating neural Transformer via an average attentionnetwork,2018, In Proc
