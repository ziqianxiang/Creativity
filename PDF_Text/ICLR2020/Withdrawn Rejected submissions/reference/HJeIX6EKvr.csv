title,year,conference
 Fine-grained analysis of op-timization and generalization for overparameterized two-layer neural networks,2019,  In InternationalConference on Machine Learning (ICML)
  A closer look at memorization in deep networks,2017,  In International Conferenceon      Machine Learning (ICML)
 Unlabeled dataimproves adversarial robustness,2019, arXiv:1905
 An analysis of single-layer networks in unsupervisedfeature learning,2011, In Conference on Artificial Intelligence and Statistics (AISTATS)
  Imagenet:  A large-scalehierarchical image database,2009, In Conference on Computer Vision and Pattern Recognition (CVPR)
   Gradient descent finds globalminima of deep neural networks,2019,   In International Conference on Machine Learning (ICML)
  Gradient descent provably optimizesover-parameterized neural networks,2018,  In International Conference on Learning Representations(ICLR)
 Shake-shake regularization,2017, arXiv:1705
 Who said what: Modelingindividual labelers improves classification,2018, In Conference on Artificial Intelligence (AAAI)
  Deep pyramidal residual networks,2017,  In Conferenceon Computer Vision and Pattern Recognition (CVPR)
 Deep residual learning for image recog-nition,2016, In Conference on Computer Vision and Pattern Recognition (CVPR)
  Densely connectedconvolutional networks,2017,   In Conference on Computer Vision and Pattern Recognition (CVPR)
 Learning deep networks from noisy labels withdropout regularization,2016, In International Conference on Data Mining (ICDM)
     Temporal  ensembling  for  semi-supervised  learning,2016,     arXiv:1610
   Gradient descent with early stopping isprovably robust to label noise for overparameterized neural networks,2019, arXiv:1903
 Progressive neural architecture search,2018, In EuropeanConference on Computer Vision (ECCV)
 Dimensionality-driven learning with noisy labels,2018, In InternationalConference on Machine Learning (ICML)
  Deep learning is robust to massivelabel noise,2017, arXiv:1705
  Learning with bad training data via iterative trimmed loss mini-mization,2019, In International Conference on Machine Learning (ICML)
  Very deep convolutional networks for large-scale imagerecognition,2015, In International Conference on Learning Representations (ICLR)
    Better  generalization  with  on-the-fly  dataset  denoising,2018,     Sep  2018
  Limited gradient descent: Learning with noisy labels,2018,  arXiv:1811
  Joint optimization frame-work for learning with noisy labels,2018,  In Conference on Computer Vision and Pattern Recognition(CVPR)
  80 million tiny images:  A large data set for nonpara-metric object and scene recognition,2008,   In IEEE Transactions on Pattern Analysis and MachineIntelligence (TPAMI)
  Generalized cross entropy loss for training deep neural networkswith noisy labels,2018, In Advances in Neural Information Processing Systems (NIPS)
