title,year,conference
 On pixel-wise explanations for non-linear classifier decisions by layer-wiserelevance propagation,2015, PloS one
 Decision-based adversarial attacks: Reliableattacks against black-box machine learning models,2017, arXiv preprint arXiv:1712
 Towards evaluating the robustness of neural networks,2017, In 2017IEEE Symposium on Security and Privacy (SP)
 Ex-plaining image classifiers by counterfactual generation,2018, In ICLR 2019
 Robust decision trees against ad-versarial examples,2019, In ICML
 Query-efficient hard-label black-box attack: An optimization-based approach,2018, arXiv preprintarXiv:1807
 Real time image saliency for black box classifiers,2017, In NIPS
 Explanations based on the missing: Towards contrastive explanationswith pertinent negatives,2018, In Advances in Neural Information Processing Systems
 Interpretable explanations of black boxes by meaningful pertur-bation,2017, 2017 IEEE International Conference on Computer Vision (ICCV)
 Ai2: Safety and robustness certification of neural networks with abstract interpreta-tion,2018, In 2018 IEEE Symposium on Security and Privacy (SP)
 Explaining and harnessing adversarialexamples,2014, arXiv preprint arXiv:1412
 Counterfactual visualexplanations,2019, In International Conference on Machine Learning
 Reluplex: Anefficient smt solver for verifying deep neural networks,2017, In International Conference on ComputerAided Verification
 Understanding black-box predictions via influence functions,2017, InInternational Conference on Machine Learning
 Understanding neural networks through representationerasure,2016, CoRR
 A unified approach to interpreting model predictions,2017, In Advancesin Neural Information Processing Systems
 Visual explanation by interpretation: Improvingvisual feedback capabilities of deep neural networks,2019, In International Conference on LearningRepresentations
 Rise: Randomized input sampling for explanation ofblack-box models,2018, arXiv preprint arXiv:1806
 Model agnostic supervised local explana-tions,2018, In Advances in Neural Information Processing Systems
 Why should i trust you?: Explaining thepredictions of any classifier,2016, In Proceedings of the 22ndACM SIGKDD International Conferenceon Knowledge Discovery and Data Mining
 A convex relaxationbarrier to tight robust verification of neural networks,2019, arXiv preprint arXiv:1902
 Evaluating the visualization of what a deep neural network has learned,2016, IEEE transactionson neural networks and learning systems
 Learning important features throughpropagating activation differences,2017, International Conference on Machine Learning
 Axiomatic attribution for deep networks,2017, InInternational Conference on Machine Learning
 Efficient formal safetyanalysis of neural networks,2018, In Advances in Neural Information Processing Systems
 Towards fast computation of certified robustness for relu networks,2018, InInternational Conference on Machine Learning
 Provable defenses against adversarial examples via the convex outeradversarial polytope,2018, In International Conference on Machine Learning
 Structured adversarial attack: Towards general implementation and betterinterpretability,2018, arXiv preprint arXiv:1808
 Visualizing and understanding convolutional networks,2014, InEuropean conference on computer vision
 Efficient neural net-work robustness certification with general activation functions,2018, In Advances in neural informationprocessing systems
 Recurjac: An efficient recursive algorithm forbounding jacobian matrix of neural networks and its applications,2019, In Proceedings of the AAAIConference on Artificial Intelligence
 Men also likeshopping: Reducing gender bias amplification using corpus-level constraints,2017, In Proceedings ofthe 2017 Conference on Empirical Methods in Natural Language Processing
