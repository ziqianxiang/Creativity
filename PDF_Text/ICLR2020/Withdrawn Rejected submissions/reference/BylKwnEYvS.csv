title,year,conference
 Collaborative filtering via concept decomposition on the netflix dataset,2008, In ECAI
 On the optimization of deep networks: Implicit acceleration byoverparameterization,2018, arXiv preprint arXiv:1802
 Training a 3-node neural network is np-complete,1989, In Advances in neuralinformation processing systems
 Testing Models of Cognition at Scale,2018, PhD thesis
 Exact matrix completion via convex optimization,2009, Foundations ofComputational mathematics
 The loss surfaces of multi-layer networks,2015, In Artificial Intelligence and Statistics
 Support-vector networks,1995, Machine learning
 Asymptotic analysis of the stochastic blockmodel for modular networks and its algorithmic applications,2011, Physical Review E
 Some results on convex bodies and banach spaces,1961, 1961
 Randomized nonnegative matrix factor-ization,2018, Pattern Recognition Letters
 A deep non-negative matrix factorization neural network,2017, 2017
 Escaping from saddle pointsâ€”online stochastic gradient fortensor decomposition,2015, In Conference on Learning Theory
 The why and how of nonnegative matrix factorization,2014, Regularization
 Concentration of the spectral measure for large matrices,2000, ElectronicCommunications in Probability
 The movielens datasets: History and context,2016, Acm transactions oninteractive intelligent systems (tiis)
 Deep residual learning for image recognition,2016, In Proceedingsof the IEEE conference on computer vision and pattern recognition
 Probability inequalities for sums of bounded random variables,1994, In The CollectedWorks of Wassily Hoeffding
 Stochastic blockmodels: First steps,1983, Social networks
 On large-batch trainingfor deep learning: Generalization gap and sharp minima,2016, arXiv preprint arXiv:1609
 Mixture-of-tastes models for representing users with diverse interests,2017, arXiv preprintarXiv:1711
 The concentration of measure phenomenon,2001, Number 89
 Algorithms for non-negative matrix factorization,2001, In Advances in neuralinformation processing systems
 Optimizing star-convex functions,2016, In 2016 IEEE 57th Annual Symposiumon Foundations of Computer Science (FOCS)
 Fast bregman divergence nmf using taylor expansion and coordi-nate descent,2012, In Proceedings of the 18th ACM SIGKDD international conference on Knowledgediscovery and data mining
 Convergence analysis of two-layer neural networks with relu activation,2017, InAdvances in Neural Information Processing Systems
 Depth creates no bad local minima,2017, arXiv preprint arXiv:1702
 An efficient non-negative matrix-factorization-based approachto collaborative filtering for recommender systems,2014, IEEE Transactions on Industrial Informatics
 Human-level control through deep reinforcementlearning,2015, Nature
 Automated phase mapping with agilefd and its application to lightabsorber discovery in the v-mn-nb oxide system,2016, ACS combinatorial science
 Non-negative matrix factorisation of large mass spec-trometry datasets,2017, Chemometrics and Intelligent Laboratory Systems
 User-friendly tail bounds for sums of random matrices,2012, Foundations of computationalmathematics
 Introduction to the non-asymptotic analysis of random matrices,2010, arXiv preprintarXiv:1011
 Learning from incomplete ratings using non-negativematrix factorization,2006, In Proceedings of the 2006 SIAM international conference on data mining
 Large-scale parallel collaborative filtering forthe netflix prize,2008, In International conference on algorithmic applications in management
 Sgd converges to global minimum in deeplearning via star-convex path,2019, arXiv preprint arXiv:1901
 Data augmentationconsists of randomized cropping with 4-padding and randomized horizontal flipping,2016, The learningrate is decreased by a factor of 10 after epochs p150
