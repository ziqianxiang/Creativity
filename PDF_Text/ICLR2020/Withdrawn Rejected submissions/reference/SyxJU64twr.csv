title,year,conference
 Surprise-based intrinsic motivation for deep reinforcementlearning,2017, arXiv preprint arXiv:1703
 Openai gym,2016, arXiv preprint arXiv:1606
 Exploration by random networkdistillation,2018, arXiv preprint arXiv:1810
 Deep reinforcementlearning in a handful of trials using probabilistic dynamics models,2018, In Advances in NeuralInformation Processing Systems
 GEP-PG: Decoupling exploration andexploitation in deep reinforcement learning algorithms,2018, arXiv preprint arXiv:1802
 Curiosity-driven reinforcement learning with homeostaticregulation,2018, arXiv preprint arXiv:1801
 Benchmarking deepreinforcement learning for continuous control,2016, In International Conference on Machine Learning
 Distributional multivariate policy evaluation and explorationwith the bellman gan,2018, arXiv preprint arXiv:1808
 Soft actor-critic: Off-policy maxi-mum entropy deep reinforcement learning with a stochastic actor,2018, arXiv preprint arXiv:1801
 VIME:Variational information maximizing exploration,2016, In Advances in Neural Information ProcessingSystems
 EMI:exploration with mutual information,2018, CoRR
 Adam: A method for stochastic optimization,2014, arXiv preprintarXiv:1412
 Model-ensembletrust-region policy optimization,2018, arXiv preprint arXiv:1802
 Human-levelcontrol through deep reinforcement learning,2015, Nature
 Neural network dy-namics for model-based deep reinforcement learning with model-free fine-tuning,2017, arXiv preprintarXiv:1708
 Self-imitation learning,2018, arXiv preprintarXiv:1806
 Curiosity-driven exploration byself-supervised prediction,2017, In International Conference on Machine Learning (ICML)
 Episodic curiosity through reachability,2018, arXiv preprint arXiv:1810
 Trust regionpolicy optimization,2015, In International Conference on Machine Learning
 High-dimensionalcontinuous control using generalized advantage estimation,2015, arXiv preprint arXiv:1506
 Proximal policyoptimization algorithms,2017, arXiv preprint arXiv:1707
 Exploration conscious reinforcement learningrevisited,2018, arXiv preprint arXiv:1812
 Model-based active exploration,2018, CoRR
 Action branching architectures for deep rein-forcement learning,2018, In AAAI
 Deep reinforcement learning with double q-learning,2016, In AAAI
 On learning intrinsic rewards for policy gradientmethods,2018, In Advances in Neural Information Processing Systems
 The size of the used replay buffer for all these three methods is 1,2018,1M
 One is to generateintrinsic reward explicitly and to train the agent with the total reward which is the sum of theextrinsic reward and the adequately scaled intrinsic reward,2018, The other is indirect methods which donot explicitly generate intrinsic reward
	Explicit Intrinsic Reward GenerationAndrychowicz et al,2018, (2017) suggested a new intrinsic reward for sparse and binary extrinsic rewardenvironments
