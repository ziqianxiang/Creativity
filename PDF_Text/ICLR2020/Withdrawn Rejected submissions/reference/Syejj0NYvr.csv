title,year,conference
 Obfuscated gradients give a false sense of se-curity: Circumventing defenses to adversarial examples,2018, In International Conference on Machinelearning
 There are many con-sistent explanations of unlabeled data: Why you should average,2019, In International Conference onLearning Representations
 Wild patterns: Ten years after the rise of adversarial machinelearning,2017, CoRR
 Decision-based adversarial attacks: Reliableattacks against black-box machine learning models,2018, In International Conference on LearningRepresentations
 Towards evaluating the robustness of neural networks,2017, In IEEESymposium on Security and Privacy
 Audio adversarial examples: Targeted attacks on speech-to-text,2018, In IEEE Symposium on Security and Privacy Workshops
 On evaluating adversarialrobustness,2019, CoRR
 Essentially no barriersin neural network energy landscape,2018, In International Conference on Machine Learning
 Learning perceptually-aligned representations via adversarial robustness,2019, CoRR
 Adversarial examples are anatural consequence of test error in noise,2019, CoRR
 Explaining and harnessing adversarialexamples,2015, In International Conference on Learning Representations
 Excessive invariancecauses adversarial vulnerability,2019, In International Conference on Learning Representations
 Learning multiple layers of features from tiny images,2009, Technical report
 Imagenet classification with deep convo-lutional neural networks,2012, In Advances in Neural Information Processing Systems
 Adversarial machine learning at scale,2017, InInternational Conference on Learning Representations
 Interpolated adversarial training:Achieving robust neural networks without sacrificing too much accuracy,2019, CoRR
 Defense against adversarial attacksusing high-level representation guided denoiser,2018, In IEEE Conference on Computer Vision andPattern Recognition
 Towards robust neural networksvia random self-ensemble,2018, In European Conference on Computer Vision
 Adversarial Neural Pruning,2019, CoRR
 MagNet: a two-pronged defense against adversarial examples,2017, InACM SIGSAC Conference on Computer and Communications Security
 On detecting adversarialperturbations,2017, In International Conference on Learning Representations
 Deepfool: a simple andaccurate method to fool deep neural networks,2016, In IEEE Conference on Computer Vision andPattern Recognition
 Universaladversarial perturbations,2017, In Computer Vision and Pattern Recognition
 Simple black-box adversarial perturbationsfor deep networks,2017, CoRR
 Readingdigits in natural images with unsupervised feature learning,2011, In NIPS Workshop on Deep Learningand Unsupervised Feature Learning
 Unifying adversarial training algorithmswith data gradient regularization,2017, Neural Comput
 Improving adversarial robustness viapromoting ensemble diversity,2019, In International Conference on Machine Learning
 Deflectingadversarial attacks with pixel deflection,2018, In IEEE Conference on Computer Vision and PatternRecognition
 Defense-GAN: Protecting classifiersagainst adversarial attacks using generative models,2018, In International Conference on LearningRepresentations
 Pixeldefend:Leveraging generative models to understand and defend against adversarial examples,2017, CoRR
 Multivariate stochastic approximation using a simultaneous perturbation gradientapproximation,1992, IEEE Transactions on Automatic Control
 Disentangling adversarial robustness and general-ization,2019, In IEEE Conference on Computer Vision and Pattern Recognition
 One pixel attack for fooling deepneural networks,2017, CoRR
 Intriguing properties of neural networks,2014, In International Conference onLearning Representations
 Re-thinking the inception architecture for computer vision,2016, In IEEE Conference on Computer Visionand Pattern Recognition
 A boundary tilting persepective on the phenomenon of adver-sarial examples,2016, CoRR
 Thespace of transferable adversarial examples,2017, CoRR
 Graph interpolating activation improves both natural and robustaccuracies in data-efficient deep learning,2019, CoRR
 Adversarial defense via data dependent activation function and total variation mini-mization,2018, CoRR
 Deep neural netswith interpolating function as output activation,2018, In Advances in Neural Information ProcessingSystems
 Resnets ensemble via the feynman-kac formalism to improve natural and robust accuracies,2019, In Advances in Neural InformationProcessing Systems
 Bilateral adversarial training: Towards fast training of more robustmodels against adversarial attacks,2019, In International Conference on Computer Vision
 Generating ad-versarial examples with adversarial networks,2018, In International Joint Conference on ArtificialIntelligence
 Mitigating adversarialeffects through randomization,2018, In International Conference on Learning Representations
 Deep defense: Training DNNs with improvedadversarial robustness,2018, In Advances in Neural Information Processing Systems
 Wide residual networks,2016, In British Machine VisionConference
 Defense against adversarial attacks using feature scattering-basedadversarial training,2019, CoRR
 mixup: Beyond empiricalrisk minimization,2018, In International Conference on Learning Representations
