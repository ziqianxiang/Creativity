title,year,conference
 Pseudo-recursal: Solvingthe catastrophic forgetting problem in deep neural networks,2018, arXiv preprint arXiv:1802
 Large-scale machine learning with stochastic gradient descent,2010, In Proceedings ofCOMPSTATâ€™2010
 Model compression,2006, InProceedings of the 12th ACM SIGKDD international conference on Knowledge discovery anddata mining
 Super-samples from kernel herding,2012, arXiv preprintarXiv:1203
 Imagenet: A large-scalehierarchical image database,2009, In 2009 IEEE conference on computer vision and patternrecognition
 Catastrophic forgetting in connectionist networks,1999, Trends in cognitive sciences
 Overcoming catastrophic interference using conceptor-aidedbackpropagation,2018, 2018
 Distilling the knowledge in a neural network,2015, arXivpreprint arXiv:1503
 Overcomingcatastrophic forgetting by incremental moment matching,2017, In Advances in neural informationprocessing systems
 Learning without forgetting,2018, IEEE transactions on pattern analysisand machine intelligence
 Gradient episodic memory for continual learning,2017, In Advances in NeuralInformation Processing Systems
 Connectionist models of recognition memory: constraints imposed by learning andforgetting functions,1990, Psychological review
 icarl:Incremental classifier and representation learning,2017, In Proceedings of the IEEE Conference onComputer Vision and Pattern Recognition
 Continual learning with deep generativereplay,2017, In Advances in Neural Information Processing Systems
 Prototypical networks for few-shot learning,2017, InAdvances in Neural Information Processing Systems
 Lifelong robot learning,1995, Robotics and autonomous systems
 Generative replay with feedback connections as a generalstrategy for continual learning,2018, arXiv preprint arXiv:1809
 Few-shot self reminder to overcome catastrophicforgetting,2018, arXiv preprint arXiv:1812
