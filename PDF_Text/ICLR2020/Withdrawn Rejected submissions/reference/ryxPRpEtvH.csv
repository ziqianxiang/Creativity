title,year,conference
 The description length of deep learning models,2018, In Advances inNeural Information Processing Systems
 Weight uncertainty inneural network,2015, In International Conference on Machine Learning
 Stochastic gradient hamiltonian monte carlo,2014, InInternational conference on machine learning
 Dropout as a bayesian approximation: Representing modeluncertainty in deep learning,2016, In international conference on machine learning
 A theoretically grounded application of dropout in recurrentneural networks,2016, In Advances in neural information processing systems
 Concrete dropout,2017, In Advances in Neural InformationProcessing Systems
 Shake-shake regularization,2017, arXiv preprint arXiv:1705
 Bias-reduced uncertainty estimation for deep neuralclassifiers,2019, International Conference on Learning Representations
 Dropblock: A regularization method for convolutionalnetworks,2018, In Advances in Neural Information Processing Systems
 Meta-learning for stochastic gradientmcmc,2019, International Conference on Learning Representations
 Practical variational inference for neural networks,2011, In Advances in neural informationprocessing systems
 Deep residual learning for imagerecognition,2016, In Proceedings of the IEEE conference on computer vision and pattern recognition
 Identity mappings in deep residualnetworks,2016, In European conference on computer vision
 Deep networks withstochastic depth,2016, In European conference on computer vision
 Adaptive ensemble prediction for deep neural networks based on confidence level,2019, InThe 22nd International Conference on Artificial Intelligence and Statistics
 Variational dropout and the local reparameterizationtrick,2015, In Advances in Neural Information Processing Systems
 Learning multiple layers of features from tiny images,2009, Technical report
 Calibrated structured prediction,2015, In Advances in NeuralInformation Processing Systems
 Measures of diversity in classifier ensembles andtheir relationship with the ensemble accuracy,2003, Machine learning
 Simple and scalable predictiveuncertainty estimation using deep ensembles,2017, In Advances in Neural Information ProcessingSystems
 Fractalnet: Ultra-deep neural networkswithout residuals,2017, International Conference on Learning Representations
 A complete recipe for stochastic gradient mcmc,2015, InAdvances in Neural Information Processing Systems
 Asimple baseline for bayesian uncertainty in deep learning,2019, arXiv preprint arXiv:1902
 Readingdigits in natural images with unsupervised feature learning,2011, 2011
 Swapout: Learning an ensemble of deep architec-tures,2016, In Advances in neural information processing systems
 Efficient objectlocalization using convolutional networks,2015, In Proceedings of the IEEE Conference on ComputerVision and Pattern Recognition
 Residual networks behave like ensembles ofrelatively shallow networks,2016, In Advances in neural information processing systems
 Regularization of neuralnetworks using dropconnect,2013, In International conference on machine learning
