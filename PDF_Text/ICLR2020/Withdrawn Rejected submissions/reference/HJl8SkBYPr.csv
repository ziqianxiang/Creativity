title,year,conference
  There are many con-sistent explanations of unlabeled data:  Why you should average,2019,   International Conference onLearning Representations
  Curriculum learning,2009,  InProceedings of the 26th annual international conference on machine learning
      Mixmatch:    A   holistic   approach   to   semi-supervised   learning,2019,      arXiv   preprintarXiv:1905
 Improving generalization with active learning,1994, Machinelearning
  Agnostic active learningwithout constraints,2019, In International Conference on Machine Learning
   Activelearning with disagreement graphs,2019, In International Conference on Machine Learning
  Hierarchical sampling for active learning,2008,  In Proceedings of the25th international conference on Machine learning
  A general agnostic active learning algo-rithm,2008, In Advances in neural information processing systems
  Active and semi-supervised learning inasr: Benefits on the acoustic and language models,2019, arXiv preprint arXiv:1903
  Active and semi-supervised learning inASR: benefits on the acoustic and language models,2019, arXiv:1903
   A  convex  optimizationframework for active learning,2013, In Proceedings of the IEEE International Conference on ComputerVision
 Selecting influential examples: Active learn-ing with expected model output changes,2014, In European Conference on Computer Vision
  Deep Learning,2016,  MIT Press
   Active instance sampling via matrix partition,2010,   In Advances in Neural InformationProcessing Systems
  Multi-class active learning for imageclassification,2009, In 2009 IEEE Conference on Computer Vision and Pattern Recognition
  Learning active learning from data,2017,  InAdvances in Neural Information Processing Systems
   Temporal ensembling for semi-supervised learning,2017,   InternationalConference on Learning Representations
  Simple and scalable predictiveuncertainty  estimation  using  deep  ensembles,2017,   In  Advances  in  Neural  Information  ProcessingSystems
  Training confidence-calibrated classifiersfor detecting out-of-distribution samples,2018, Neural Information Processing Systems
  Heterogeneous uncertainty sampling for supervised learning,1994,  InMachine learning proceedings 1994
 A sequential algorithm for training text classifiers,1994, In SIGIR94
  Hierarchical subqueryevaluation for active learning on a graph,2014,  In Proceedings of the IEEE conference on computervision and pattern recognition
  Employing em and pool-based active learningfor text classification,1998, In Proc
  Realis-tic evaluation of deep semi-supervised learning algorithms,2018,  In Advances in Neural InformationProcessing Systems
 Margin-based active learning for structured output spaces,2006, In EuropeanConference on Machine Learning
 Toward optimal active learning through monte carlo estima-tion of error reduction,2001, ICML
   Active learning for convolutional neural networks:  A core-setapproach,2018, International Conference on Learning Representations
   Multiple-instance active learning,2008,   In Advances inneural information processing systems
  Query by committee,1992,  In Proceedingsof the fifth annual workshop on Computational learning theory
   Unsupervised dataaugmentation for consistency training,2019, arXiv preprint arXiv:1904
  Learning loss for active learning,2019,  In Proceedings of the IEEEConference on Computer Vision and Pattern Recognition
  Learning loss for active learning,2019,  In 2019 IEEE Conference onComputer Vision and Pattern Recognition
 Improving the robustness of deepneural networks via stability training,2016,  In Proceedings of the ieee conference on computer visionand pattern recognition
     Combining  active  learning  and  semi-supervised learning using gaussian fields and harmonic functions,2003, In ICML 2003 workshop on thecontinuum from labeled to unlabeled data in machine learning and data mining
