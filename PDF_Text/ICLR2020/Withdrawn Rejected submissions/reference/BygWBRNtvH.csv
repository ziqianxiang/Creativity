title,year,conference
 Obfuscated gradients give a false sense ofsecurity: Circumventing defenses to adversarial examples,2018, In International Conference on MachineLearning (ICML)
 Synthesizing robust adversarialexamples,2018, In International Conference on Machine Learning (ICML)
 Decision-based adversarial attacks: Reliableattacks against black-box machine learning models,2018, In International Conference on LearningRepresentations (ICLR)
 Adversarial vision challenge,2018, arXiv preprintarXiv:1808
 Adversarial examples are not easily detected: Bypassing tendetection methods,2017, In ACM Workshop on Artificial Intelligence and Security
 Towards evaluating the robustness of neural networks,2017, In IEEESymposium on Security and Privacy
 On evaluating adversarial robustness,2019, arXiv preprintarXiv:1902
 Query-efficienthard-label black-box attack: An optimization-based approach,2019, In International Conference onLearning Representations (ICLR)
 Parsevalnetworks: Improving robustness to adversarial examples,2017, In International Conference on MachineLearning (ICML)
 Certified adversarial robustness via randomizedsmoothing,2019, In International Conference on Machine Learning (ICML)
 Stochastic activation pruning for robust adversarial defense,2018, InInternational Conference on Learning Representations (ICLR)
 Boostingadversarial attacks with momentum,2018, In Proceedings of the IEEE Conference on Computer Visionand Pattern Recognition (CVPR)
 Efficientdecision-based black-box adversarial attacks on face recognition,2019, In Proceedings of the IEEEConference on Computer Vision and Pattern Recognition (CVPR)
 A study of the effect of jpgcompression on adversarial images,2016, arXiv preprint arXiv:1608
 Exploringthe landscape of spatial robustness,2019, In International Conference on Machine Learning (ICML)
 Explaining and harnessing adversarialexamples,2015, In International Conference on Learning Representations (ICLR)
 Speech recognition with deep recurrentneural networks,2013, In IEEE International Conference on Acoustics
 Countering adversarialimages using input transformations,2018, In International Conference on Learning Representations(ICLR)
 Deep residual learning for imagerecognition,2016, In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition(CVPR)
 Decision boundary analysis of adversarial examples,2018, InInternational Conference on Learning Representations (ICLR)
 Formal guarantees on the robustness of a classifieragainst adversarial manipulation,2017, In Advances in Neural Information Processing Systems (NeurIPS)
 Black-box adversarial attacks withlimited queries and information,2018, In International Conference on Machine Learning (ICML)
 Adversarial logit pairing,2018, arXiv preprintarXiv:1803
 Adam: A method for stochastic optimization,2015, In InternationalConference on Learning Representations (ICLR)
 Imagenet classification with deep con-volutional neural networks,2012, In Advances in Neural Information Processing Systems (NeurIPS)
 Adversarial examples in the physical world,2017, InInternational Conference on Learning Representations (ICLR) Workshops
 Adversarial attacks and defences competition,2018, arXivpreprint arXiv:1804
 Defense againstadversarial attacks using high-level representation guided denoiser,2018, In Proceedings of the IEEEConference on Computer Vision and Pattern Recognition (CVPR)
 Deepsec:A uniform platform for security analysis of deep learning model,2019, In IEEE Symposium on Securityand Privacy
 Towards robust neural networks viarandom self-ensemble,2018, In Proceedings of the European Conference on Computer Vision (ECCV)
 Adv-bnn: Improved adversarial defensethrough robust bayesian neural network,2019, In International Conference on Learning Representations(ICLR)
 Deepfool: a simple andaccurate method to fool deep neural networks,2016, In Proceedings of the IEEE Conference on ComputerVision and Pattern Recognition (CVPR)
 Adversarialrobustness toolbox v0,2018, 4
 Improving adversarial robustness viapromoting ensemble diversity,2019, In International Conference on Machine Learning (ICML)
 Technical report on thecleverhans v2,2016, 1
 Distillation as adefense to adversarial perturbations against deep neural networks,2016, In IEEE Symposium on Securityand Privacy
 Certified defenses against adversarialexamples,2018, In International Conference on Learning Representations (ICLR)
 Semidefinite relaxations for certifyingrobustness to adversarial examples,2018, In Advances in Neural Information Processing Systems(NeurIPS)
 Foolbox v0,2017, 8
 Defense-gan: Protecting classifiersagainst adversarial attacks using generative models,2018, In International Conference on LearningRepresentations (ICLR)
 Certifying some distributional robustness withprincipled adversarial training,2018, In International Conference on Learning Representations (ICLR)
 Pixeldefend: Lever-aging generative models to understand and defend against adversarial examples,2018, In InternationalConference on Learning Representations (ICLR)
 Constructing unrestricted adversarial ex-amples with generative models,2018, In Advances in Neural Information Processing Systems (NeurIPS)
 Intriguing properties of neural networks,2014, In International Conference on LearningRepresentations (ICLR)
 Rethinking theinception architecture for computer vision,2016, In Proceedings of the IEEE Conference on ComputerVision and Pattern Recognition (CVPR)
 Ensemble ad-versarial training: Attacks and defenses,2018, In International Conference on Learning Representations(ICLR)
 Provable defenses against adversarial examples via the convex outeradversarial polytope,2018, In International Conference on Machine Learning (ICML)
 Scaling provable adversarialdefenses,2018, In Advances in Neural Information Processing Systems (NeurIPS)
 Spatially transformedadversarial examples,2018, In International Conference on Learning Representations (ICLR)
 Training for fasteradversarial robustness verification via inducing relu stability,2019, In International Conference onLearning Representations (ICLR)
 Mitigating adversarial effectsthrough randomization,2018, In International Conference on Learning Representations (ICLR)
 Feature denoisingfor improving adversarial robustness,2019, In Proceedings of the IEEE Conference on Computer Visionand Pattern Recognition (CVPR)
 Feature squeezing: Detecting adversarial examples indeep neural networks,2018, In Proceedings of the Network and Distributed System Security Symposium(NDSS)
 Deep defense: Training dnns with improvedadversarial robustness,2018, In Advances in Neural Information Processing Systems (NeurIPS)
