title,year,conference
 Maximum a posteriori policy optimisation,2018, In ICLR
 An actor-critic algorithm for sequence prediction,2017, In ICLR
 Scheduled sampling for sequence predictionWithreCurrentneuralnetWorks,2015, In NeurIPS
 Using expectation-maximization for reinforcement learning,1997, NeuralComputation
 Cold-start reinforcement learning With softmax policy gradient,2017, In Advances inNeural Information Processing Systems
 English GigaWord,2003, Linguistic Data Consortium
 Reinforcement learning With deep energy-based policies,2017, In ICML
 Layer-Wise coordinationbetWeen encoder and decoder for neural machine translation,2018, In NeurIPS
 Generative adversarial imitation learning,2016, In NeurIPS
 Automated text summarization and the summarist system,1998, In Proceedings ofa workshop on held at Baltimore
 Sequence tutor: Conservative fine-tuning of sequence generation models With KL-control,2017, InICML
 Deep visual-semantic alignments for generating image descriptions,2015, In CVPR
 Alpha-divergencebridges maximum likelihood and reinforcement learning in neural sequence generation,2018, 2018
 SEARNN: Training RNNsWith global-local losses,2018, In ICLR
 Reinforcement learning and control as probabilistic inference: Tutorial and revieW,2018, arXivpreprint arXiv:1805
 Effective approaches to attention-based neuralmachine translation,2015, In EMNLP
 Softmax q-distribution esti-mation for structured prediction: A theoretical interpretation for raml,2017, arXiv preprint arXiv:1705
 Policy shaping and generalized updateequations for semantic parsing from denotations,2018, In EMNLP
 Human-level control through deepreinforcement learning,2015, Nature
 Bleu: a method for automatic evaluation ofmachine translation,2002, In Proceedings of the 40th annual meeting on association for computational linguistics
 Relative entropy policy search,1607, In AAAI
 Sequence level training withrecurrent neural networks,2016, In ICLR
 Self-critical sequencetraining for image captioning,2017, In CVPR
 Efficient reductions for imitation learning,2010, In AISTATS
 A neural attention model for abstractive sentencesummarization,2015, In EMNLP
 Trust region policy opti-mization,2015, In ICML
 Proximal policy optimizationalgorithms,2017, arXiv preprint arXiv:1707
 Posterior attention models for sequence to sequence learning,2019, In ICLR
 Sequence to sequence learning with neural networks,2014, InAdvances in neural information processing systems
 Policy gradient methods forreinforcement learning with function approximation,2000, In Advances in neural information processing systems
 Distral: Robust multitask reinforcement learning,2017, In NeurIPS
 Attention is all you need,2017, In NeurIPS
 Show and tell: A neural image captiongenerator,2015, In CVPR
 Sequence-to-sequence learning as beam-search optimization,2016, InEMNLP
 Imitation learn-ing from imperfect demonstration,2019, In ICML
 Data noising assmoothing in neural network language models,2017, In ICLR
 Reinforcement and imitation learning for diverse visuomotorskills,2018, In RSS
 Modeling purposeful adaptive behavior with the principle of maximum causal entropy,2010, InPhD Thesis
