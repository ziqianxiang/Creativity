title,year,conference
 Obfuscated gradients give a false sense ofsecurity: Circumventing defenses to adversarial examples,2018, arXiv preprint arXiv:1802
 Learning phrase representations using rnn encoder-decoderfor statistical machine translation,2014, arXiv preprint arXiv:1406
 Certified adversarial robustness via randomizedsmoothing,2019, arXiv preprint arXiv:1902
 Adversarial risk and robust-ness: General definitions and implications for the uniform distribution,2018, In Advances in NeuralInformation Processing Systems
 Calibrating noise to sensitivityin private data analysis,2006, In Theory of cryptography conference
 The algorithmic foundations of differential privacy,2014, Foundationsand TrendsR in Theoretical Computer Science
 Explaining and harnessing adversarialexamples,2014, arXiv preprint arXiv:1412
 On the effectiveness of interval bound propagation fortraining verifiably robust models,2018, arXiv preprint arXiv:1810
 Imagenet classification with deep convo-lutional neural networks,2012, In Advances in neural information processing systems
 Certifiedrobustness to adversarial examples with differential privacy,2018, arXiv preprint arXiv:1802
 Second-order adversarial attack andcertifiable robustness,2018, arXiv preprint arXiv:1809
 Differentiable abstract interpretation for prov-ably robust neural networks,2018, In International Conference on Machine Learning
 Certified defenses against adversarial exam-ples,2018, arXiv preprint arXiv:1801
 Masteringthe game of go with deep neural networks and tree search,2016, nature
 Intriguing properties of neural networks,2013, arXiv preprint arXiv:1312
 Efficient formal safetyanalysis of neural networks,2018, In Advances in Neural Information Processing Systems
 Provable defenses against adversarial examples via the convex outeradversarial polytope,2018, In International Conference on Machine Learning
