title,year,conference
 Obfuscated gradients give a false sense of security: Circum-venting defenses to adversarial examples,2018, ICML
 Deep convolutional networks do not classifybased on global object shape,2018, PLoS computational biology
 A computational approach to edge detection,1986, In IEEE Transactions on Pattern Analysisand Machine Intelligence
 Towards evaluating the robustness of neural networks,2017, In 2017 IEEESymposium on Security and Privacy
 On evaluating adversarial robustness,2019, arXiv preprint arXiv:1902
 Targeted backdoor attacks on deep learning systemsusing data poisoning,2017, arXiv preprint arXiv:1712
 Targeted backdoor attacks on deep learning systemsusing data poisoning,2017, arXiv preprint arXiv:1712
 On the sensitivity of adversarial robustnessto input data distributions,2019, In ICLR
 Deep Learning,2016, MIT Press
 Generative adversarial nets,2014, In NIPS
 Explaining and harnessing adversarial examples,2014, arXivpreprint arXiv:1412
 Badnets: Identifying vulnerabilities in the machine learningmodel supply chain,2017, arXiv preprint arXiv:1708
 Deep residual learning for image recognition,2016, In CVPR
 Benchmarking neural network robustness to common corruptionsand perturbations,2019, In ICLR
 Image-to-image translation with conditional adversarialnetworks,2017, In CVPR
 Measuring the tendency of cnns to learn surface statistical regularities,2017, arXivpreprint arXiv:1711
 Measuring the tendency of cnns to learn surface statistical regularities,2017, arXivpreprint arXiv:1711
 The importance of shape in early lexical learning,1988, Cognitivedevelopment
 Data poisoning attacks on factorization-based col-laborative filtering,2016, In NIPS
 Defense against adversarial attacks usinghigh-level representation guided denoiser,2018, In CVPR
 Fine-pruning: Defending against backdooring attacks on deepneural networks,2018, arXiv preprint arXiv:1805
 Deep learning face attributes in the wild,2015, In ICCV
 Towards deep learning modelsresistant to adversarial attacks,2018, In ICLR
 Defense-gan: Protecting classifiers against adversar-ial attacks using generative models,2018, In IClR
 Pixeldefend: Leveraging generativemodels to understand and defend against adversarial examples,2018, In ICLR
 Intriguingproperties of neural networks,2013, arXiv preprint arXiv:1312
 Shieldnets: Defending against adversarial attacksusing probabilistic adversarial robustness,2019, In CVPR
 Spectral signatures in backdoor attacks,2018, In NIPS
 Learning robust representations by projecting super-ficial statistics out,2019, In ICLR
 High-resolution imagesynthesis and semantic manipulation with conditional gans,2018, In CVPR
 Fashion-mnist: a novel image dataset for benchmarking machinelearning algorithms,2017, arXiv preprint arXiv:1708
 Holistically-nested edge detection,2015, In ICCV
 Deep feature flow for video recognition,2017, In CVPR
