title,year,conference
 Expert gate: Lifelong learning with anetwork of experts,2017, In CVPR
 Episodicmemory in lifelong language learning,2019, arXiv preprint arXiv:1906
 Learning factored representations in a deepmixture of experts,2013, arXiv preprint arXiv:1312
 Neural architecture search: A survey,2018, arXivpreprint arXiv:1808
 The cascade-correlation learning architecture,1990, In Advancesin neural information processing systems
 Pathnet: Evolution channels gradient descent in super neuralnetworks,2017, arXiv preprint arXiv:1701
 An empirical investi-gation of catastrophic forgetting in gradient-based neural networks,2013, arXiv preprint arXiv:1312
 Classes for fast maximum entropy training,2001, In Acoustics
 Unbounded cache model for onlinelanguage modeling with open vocabulary,2017, In Advances in Neural Information Processing Systems
 Generating sequences with recurrent neural networks,2013, arXiv preprint arXiv:1308
 Neural turing machines,2014, arXiv preprintarXiv:1410
 Learning hierarchical informa-tion flow with recurrent neural modules,2017, In Advances in Neural Information Processing Systems
 Products of experts,1999, In 1999 Ninth International Conference on Artificial NeuralNetworks ICANN 99
 Distilling the knowledge in a neural network,2015, arXivpreprint arXiv:1503
 Back-propagation algorithm which varies thenumber of hidden units,1991, Neural Networks
 Adaptive mixtures oflocal experts,1991, Neural computation
 Inferring algorithmic patterns with stack-augmented recurrentnets,2015, In Advances in neural information processing systems
 Learning to create and reuse words in open-vocabulary neural language modeling,2017, arXiv preprint arXiv:1704
 Adam: A method for stochastic optimization,2014, arXiv preprintarXiv:1412
 Europarl: A parallel corpus for statistical machine translation,2005, In MT summit
 Overcomingcatastrophic forgetting by incremental moment matching,2017, In Advances in Neural InformationProcessing Systems
 Learning without forgetting,2018, IEEE Transactions on Pattern Analysisand Machine Intelligence
 Gradient episodic memory for continual learning,2017, InAdvances in Neural Information Processing Systems
 Why there are complementarylearning systems in the hippocampus and neocortex: insights from the successes and failures ofconnectionist models of learning and memory,1995, Psychological review
 Pointer sentinel mixturemodels,2016, arXiv preprint arXiv:1609
 Recurrentneural network based language model,2010, In Eleventh annual conference of the international speechcommunication association
 Continuous multilinguality with language vectors,2016, arXiv preprintarXiv:1612
 Connectionist models of recognition memory: constraints imposed by learning andforgetting functions,1990, Psychological review
 Learning multiple visual domains withresidual adapters,2017, In Advances in Neural Information Processing Systems
 Progressive neural networks,2016, arXiv preprintarXiv:1606
 Overcoming catastrophicforgetting with hard attention to the task,2018, arXiv preprint arXiv:1801
 Outrageously large neural networks: The sparsely-gated mixture-of-experts layer,2017, arXivpreprint arXiv:1701
 Compete to compute,2013, In Advances in neural information processing systems
 Designing neural networksthrough neuroevolution,2019, Nature Machine Intelligence
 End-to-end memory networks,2015, In Advancesin neural information processing systems
 Generating text with recurrent neuralnetworks,2011, In Proceedings of ICML 2011
 Deep mixture of experts via shallow embedding,2018, arXiv preprint arXiv:1806
 Breaking the softmaxbottleneck: A high-rank rnn language model,2017, arXiv preprint arXiv:1711
 Aligning books and movies: Towards story-like visual explanations by watchingmovies and reading books,2015, In Proceedings of the IEEE international conference on computervision
