title,year,conference
 Neural machine translation by jointlylearning to align and translate,2015, In International Conference on Learning Representations
 Conditional computation inneural networks for faster models,2015, arXiv preprint arXiv:1511
 Learning long-term dependencies with gradientdescent is difficult,1994, IEEE Transactions on Neural Networks
 Estimating or propagating gradients throughstochastic neurons for conditional computation,2013, arXiv preprint arXiv:1308
 Skip rnn:Learning to skip state updates in recurrent neural networks,2018, In International Conference onLearning Representations
 Recurrent neuralnetworks for multivariate time series with missing values,2018, Scientific reports
 A survey of model compression and accelerationfor deep neural networks,2017, arXiv preprint arXiv:1710
 Learning phrase representations using rnn encoder-decoder forstatistical machine translation,2014, In Empirical Methods in Natural Language Processing
 Finding structure in time,1990, Cognitive science
 Generating sequences with recurrent neural networks,2013, In arXiv preprintarXiv:1308
 Recurrent world models facilitate policy evolution,2018, In Advancesin Neural Information Processing Systems
 Deep residual learning for imagerecognition,2016, In Computer vision and pattern recognition
 Recurrent orthogonal networks and long-memorytasks,2016, 2016
 Long short-term memory,1997, Neural Computation
 Variable computation inrecurrent neural networks,2017, In International Conference on Learning Representations
 Adam: A method for stochastic optimization,2014, arXiv preprintarXiv:1412
 A clockwork rnn,2014, InInternational Conference on Machine Learning
 Zoneout: Regularizing rnns byrandomly preserving hidden activations,2017, In International Conference on Learning Representations
 Phased lstm: Accelerating recurrent networktraining for long or event-based sequences,2016, In Advances in Neural Information Processing Systems
 Self-delimiting neural networks,2012, arXivpreprint arXiv:1210
 Outrageously large neural networks: The sparsely-gated mixture-of-experts layer,2017, arXivpreprint arXiv:1701
 Ordered neurons: Incorpo-rating tree structures into recurrent neural networks,2019, In International Conference on LearningRepresentations
 Highway networks,2015, In Advancesin Neural Information Processing Systems
 Recurrent residual learning for sequence classification,2016, In Empiricalmethods in natural language processing
 Simple statistical gradient-following algorithms for connectionist reinforcementlearning,1992, Machine learning
 Recurrenthighway networks,2017, In International Conference on Machine Learning
