title,year,conference
 Character-level languagemodeling with deeper self-attention,2019, In Proceedings of the 33rd AAAI Conference on ArtificialIntelligence
 Adaptive input representations for neural language modeling,2019, InICLR
 Neural machine translation by jointlylearning to align and translate,2015, In ICLR
 Quick training of probabilistic neural nets by impor-tance sampling,2003, In AISTATS
 Generating long sequences with sparsetransformers,2019, arXiv preprint arXiv:1904
 Transformer-xl: Attentive language models beyond a fixed-length context,2019, arXivpreprint arXiv:1901
 Language modeling with gatedconvolutional networks,2017, In ICML
 Efficient softmax approximationfor gpus,2017, In ICML
 Improving neural language models with acontinuous cache,2017, In ICLR
 Neural turing machines,2014, arXiv preprintarXiv:1410
 Deep residual learning for imagerecognition,2016, In Proceedings of the IEEE conference on computer vision and pattern recognition
 Long short-term memory,1997, Neural computation
 Tying word vectors and word classifiers: Aloss framework for language modeling,2017, In ICLR
 Hierarchical mixtures of experts and the em algorithm,1994, Neuralcomputation
 Exploring thelimits of language modeling,2016, arXiv preprint arXiv:1602
 Layer normalization,2016, arXiv preprintarXiv:1607
 Pointer sentinel mixturemodels,2017, In ICLR
 An analysis of neural language modelingat multiple scales,2018, arXiv preprint arXiv:1803
 Recurrentneural network based language model,2010, In Eleventh annual conference of the international speechcommunication association
 Key-value memory networks for directly reading documents,2016, In EMNLP
 Hierarchical probabilistic neural network language model,2005, InAISTATS
 On the difficulty of training recurrent neuralnetworks,2013, In ICML
 Using the output embedding to improve language models,2017, In EACL (2)
 Fast parametric learning withactivation memorization,2018, In ICML
 Neural machine translation of rare words withsubword units,2016, In ACL (1)
 Adaptive attentionspan in transformers,2019, In ACL
 Attention is all you need,2017, In NIPS
 Pointer networks,2015, In NIPS
 Recurrent neural network regularization,2014, arXivpreprint arXiv:1409
 Recurrenthighway networks,2017, In ICML
