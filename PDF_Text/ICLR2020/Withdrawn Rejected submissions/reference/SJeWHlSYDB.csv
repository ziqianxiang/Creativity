title,year,conference
 Wasserstein gan,2017, arXiv preprint arXiv:1701
 Invertible residual networks,2018, arXiv preprintarXiv:1811
 Some general divergence measures for probability distributions,1588, Acta MathematicaHungarica
 Manypaths to equilibrium: Gans do not need to decrease a divergence at every step,2017, arXiv preprintarXiv:1710
 Fano’s inequality for random variables,2018, arXiv
 Improved training of Wasser-stein gans,2017, In Advances in Neural Information Processing Systems
 Gans trained by a twotime-scale update rule converge to a local nash equilibrium,2017, In Advances in Neural InformationProcessing Systems
 Fast and robust fixed-point algorithms for independent component analysis,1045, IEEETransactions on Neural Networks
 Batch normalization: Accelerating deep network training by reducinginternal covariate shift,2015, arXiv preprint arXiv:1502
 Adam: A method for stochastic optimization,2014, arXiv preprint arXiv:1412
 Auto-Encoding Variational Bayes,2013, arXiv:1312
 On convergence and stability of gans,2017, arXiv preprintarXiv:1705
 Mmd gan: Towards deeper understanding ofmoment matching network,2017, In Advances in Neural Information Processing Systems
 On divergences and informations in statistics and information theory,2006, IEEETransactions on Information Theory
 Deep Learning Face Attributes in the Wild,2015, In Proceedings ofInternational Conference on Computer Vision (ICCV)
 Are gans created equal? a large-scalestudy,2018, In Advances in neural information processing systems
 Spectral normalization for generative adversarialnetworks,2018, arXiv preprint arXiv:1802
 Learning in implicit generative models,2016, arXiv preprint
 Fast exact multiplication by the hessian,1994, Neural computation
 Computational optimal transport,2019, Foundations and Trends® in MachineLearning
 Variational inference with normalizing flows,2015, arXiv preprintarXiv:1505
 Fast curvature matrix-vector products for second-order gradient descent,2002, Neuralcomputation
 Amortised map inference for imagesuper-resolution,2016, arXiv preprint arXiv:1610
 Wasserstein auto-encoders,2017, arXiv preprintarXiv:1711
 A maximum-likelihood interpretation for slow feature analysis,2007, Neuralcomputation
 Note on the consistency of the maximum likelihood estimate,1949, The Annals of MathematicalStatistics
 Bayesian independent component analysis: Variational methods andnon-negative decompositions,1051, Digital Signal Processing
 Variational f-divergence minimization,2018, arXivpreprint arXiv:1907
