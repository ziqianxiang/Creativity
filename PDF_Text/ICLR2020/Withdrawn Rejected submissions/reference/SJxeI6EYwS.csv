title,year,conference
 Deep variational informationbottleneck,2017, In ICLR
 Obfuscated gradients give a false sense ofsecurity: Circumventing defenses to adversarial examples,2018, In ICML
 Training with noise is equivalent to tikhonov regularization,1995, Neural Computation
 Weight uncertainty inneural networks,2015, In ICML
 Towards evaluating the robustness of neural networks,2017, InIEEESSP
 Compressing neural networks using the variationalinformation bottleneck,2018, In ICML
 Learning embeddings into entropicwasserstein spaces,2019, In ICLR
 DropoUt as a Bayesian approximation: Representing modelUncertainty in deep learning,2016, In ICML
 Training deep neUral-networks Using a noise adaptationlayer,2017, In ICLR
 Explaining and harnessing adversarialexamples,2015, In ICLR
 Practical variational inference for neUral networks,2011, In NIPS
 Deep residUal learning for imagerecognition,2016, In CVPR
 Using trUsted data to traindeep networks on labels corrUpted by severe noise,2018, In NIPS
 Mentornet: Learning data-driven cUrricUlUm for very deep neUral networks on corrUpted labels,2018, In ICML
 Adam: A method for stochastic optimization,2015, In ICLR
 AUto-encoding variational bayes,2014, In ICLR
 Variational dropout and the local reparameterizationtrick,2015, In NIPS
 Cleannet: Transfer learning for scalableimage classifier training with label noise,2017, In ICCV
 Towards robust neural networks viarandom self-ensemble,2018, In ECCV
 Adv-bnn: Improved adversarial defensethrough robust bayesian neural network,2019, In ICLR
 Learningefficient convolutional networks through network slimming,2017, In ICCV
 Bayesian compression for deep learning,2017, InNIPS
 Learning sparse neural networks throughl_0 regularization,2018, In ICLR
 Variational dropout sparsifies deep neuralnetworks,2017, In ICML
 Adding gradient noise improves learning for very deep networks,2015, CoRR
 Structured bayesianpruning via log-normal multiplicative noise,2017, In NIPS
 Regularizing deep neuralnetworks by noise: Its interpretation and optimization,2017, In NIPS
 Makingdeep neural networks robust to label noise: A loss correction approach,2017, In CVPR
 Sampling-free epistemic uncertainty estimation using approximated variance propagation,2019, In ICCV
 Training deep neural networks on noisy labels with bootstrapping,2015, In ICLR Workshop
 A scalable laplace approximation for neuralnetworks,2018, In ICLR
 Very deep convolutional networks for large-scale imagerecognition,2015, In ICLR
 Generalized dropout,2016, CoRR
 Trainingconvolutional networks with noisy labels,2015, In ICLR
 The information bottleneck method,1999, InAllerton
 Natural-parameter networks: A class of probabilisticneural networks,2016, In NIPS
 Learning structured sparsity indeep neural networks,2016, In NIPS
 Mitigating adversarialeffects through randomization,2018, In ICLR
 Bayesian adversarial learning,2018, In NIPS
 Adversarial noise layer: Regularize neuralnetwork by adding noise,2018, CoRR
 Scalable personre-identification: A benchmark,2015, In ICCV
 The experiments arerun on the label noise robust learning task with network comprising two FC layers,2020, For the network12Under review as a conference paper at ICLR 2020with one SL
