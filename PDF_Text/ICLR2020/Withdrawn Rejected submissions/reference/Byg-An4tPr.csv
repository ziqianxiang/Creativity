title,year,conference
 Deep learning with differential privacy,2016, arXiv:1607
 On the protection of private information in machine learningsystems: Two recent approches,2017, In 2017 IEEE 30th Computer Security Foundations Symposium(CSF)
 Robustness to adversarial examples through an ensemble ofspecialists,2017, CoRR
 Improving the Gaussian mechanism for differential privacy: Ana-lytical calibration and optimal denoising,2018, In Jennifer Dy and Andreas Krause (eds
 Towards evaluating the robustness of neural networks,2017, In 2017 IEEESymposium on Security and Privacy (SP)
 Parse-val networks: Improving robustness to adversarial examples,2017, In Doina Precup and Yee WhyeTeh (eds
 Certified adversarial robustness via randomizedsmoothing,2019, In Kamalika Chaudhuri and Ruslan Salakhutdinov (eds
 Discovering adversarialexamples with momentum,2017, CoRR
 Calibrating noise to sensitivity in private dataanalysis,2006, Theory of Cryptography
 The algorithmic foundations of differential privacy,1551, Found
 Model inversion attacks that exploit con-fidence information and basic countermeasures,2015, In Proceedings of the 22Nd ACM SIGSACConference on Computer and Communications Security
 Deepmask: Masking DNN models for robustness againstadversarial samples,2017, CoRR
 Explaining and harnessing adversarialexamples,2014, CoRR
 Towards deep neural network architectures robust to adversarialexamples,2014, CoRR
 Deep residual learning for image recog-nition,2015, CoRR
 Long short-term memory,1997, Neural Computation
 Block-ing transferability of adversarial examPles in black-box learning systems,2017, arXiv preprintarXiv:1703
 Mitigating fooling with comPetitive overcomPlete outPut layer neuralnetworks,2017, In 2017 International Joint Conference on Neural Networks (IJCNN)
 Provable defenses against adversarial examPles via the convex outeradversarial PolytoPe,2017, CoRR
 Learning multiPle layers of features from tiny images,2009, 2009
 Adversarial machine learning at scale,2016, CoRR
 Gradient-based learning aPPlied to document recog-nition,1998, Proceedings of the IEEE
 Certifiedrobustness to adversarial examPles with differential Privacy,2018, In arXiv:1802
 Second-order adversarial attackand certifiable robustness,2018, CoRR
 Margin maximization for robust classification using deeP learning,2017, In2017 International Joint Conference on Neural Networks (IJCNN)
 On detecting adversar-ial Perturbations,2017, In Proceedings of 5th International Conference on Learning Representations(ICLR)
 The limitations of deePlearning in adversarial settings,2016, In 2016 IEEE European Symposium on Security and Privacy
 Distillation as a defense to adversarialperturbations against deep neural networks,2016, In 2016 IEEE Symposium on Security and Privacy(SP)
 Extending defensive distillation,2017, arXiv preprintarXiv:1705
 Scalable private learning with pate,2018, arXiv preprint arXiv:1802
 Het-erogeneous gaussian mechanism: Preserving differential privacy in deep learning with provablerobustness,2019, In Proceedings of the 28th International Joint Conference on Λrtificial Intelligence(IJCA119)
 Certified defenses against adversarial exam-ples,2018, CoRR
 Privacy-preserving deep learning,2015, In CCS’15
 Ensembleadversarial training: Attacks and defenses,2017, arXiv preprint arXiv:1705
 Learning adversary-resistant deep neural networks,2016, CoRR
 Feature squeezing: Detecting adversarial examples in deepneural networks,2017, CoRR
 Differentially private model publishing for deeplearning,2019, In 2019 IEEE Symposium on Security and Privacy (SP)
 Functional mechanism:regression analysis under differential privacy,2012, PVLDB
 Accelerating very deep convolutionalnetworks for classification and detection,2015, CoRR
