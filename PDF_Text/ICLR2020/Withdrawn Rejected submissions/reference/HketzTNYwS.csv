title,year,conference
 Layer normalization,2016, CoRR
 The fifth pascal recognizingtextual entailment challenge,2009, In TAC
 A unified architecture for natural language processing: Deepneural networks with multitask learning,2008, In Proceedings of the 25th international conference onMachine learning
 Xnli: Evaluating cross-lingual sentence representations,2018, arXivpreprint arXiv:1809
 Bert: Pre-training of deepbidirectional transformers for language understanding,2018, arXiv preprint arXiv:1810
 Triviaqa: A large scale distantlysupervised challenge dataset for reading comprehension,2017, arXiv preprint arXiv:1705
 Zero-shot relation extraction viareading comprehension,2017, arXiv preprint arXiv:1706
 Multi-task deep neural networksfor natural language understanding,2019, arXiv preprint arXiv:1901
 Roberta: A robustly optimized bert pretrainingapproach,2019, arXiv preprint arXiv:1907
 Learned in translation:Contextualized word vectors,2017, In Advances in Neural Information Processing Systems
 Deep contextualized word representations,2018, arXiv preprint arXiv:1802
 Sentence encoders on stilts: Supplementarytraining on intermediate labeled-data tasks,2018, arXiv preprint arXiv:1811
 Attention is all you need,2017, In I
 Glue:A multi-task benchmark and analysis platform for natural language understanding,2018, arXiv preprintarXiv:1804
 A broad-coverage challenge corpus forsentence understanding through inference,2017, arXiv preprint arXiv:1704
