title,year,conference
 Pooled contextualized embeddings for namedentity recognition,2019, In Proceedings of the 2019 Conference of the North American Chapter of theAssociation for Computational Linguistics: Human Language Technologies
 Multimodal word distributions,2017, In Proceedings of the55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)
 Do deep nets really need to be deep? In Z,2014, Ghahramani
 The problem with bias: fromallocative to representational harms in machine learning,2017, Special Interest Group for Computing
 A neural probabilisticlanguage model,1532, J
 Enriching word vectorswith subword information,2017, Transactions of the Association for Computational Linguistics
 Man is to computer programmer as woman is to homemaker? debiasingword embeddings,2016, In D
 SPARSE: Structured prediction usingargument-relative structured encoding,2019, In Proceedings of the Third Workshop on StructuredPrediction for NLP
 Semantics derived automatically from lan-guage corpora contain human-like biases,0036, Science
 An analysis of deep neural networkmodels for practical applications,2016, CoRR
 A unified architecture for natural language processing: Deepneural networks with multitask learning,2008, In Proceedings of the 25th International Conferenceon Machine Learning
 Morphological word-embeddings,2015, In Proceedings of the 2015Conference of the North American Chapter of the Association for Computational Linguistics:Human Language Technologies
 Word embeddings quantify 100years of gender and ethnic stereotypes,0027, Proceedings of the National Academy of Sciences
 Variational pretraining for semi-supervised text classification,2019, In Proceedings of the 57th Annual Meeting of the Association forComputational Linguistics
 Optimal brain damage,1990, In D
 MUSE: Modularizing unsupervised sense embeddings,2017, InProceedings of the 2017 Conference on Empirical Methods in Natural Language Processing
 Improving distributional similarity with lessons learnedfrom word embeddings,2015, Transactions of the Association for Computational Linguistics
 Evaluating the energy efficiency of deepconvolutional neural networks on cpus and gpus,2016, In 2016 IEEE International Conferences onBig Data and Cloud Computing (BDCloud)
 Roberta: A robustly optimized BERT pretrainingapproach,2019, CoRR
 Learned in translation:Contextualized word vectors,2017, In Advances in Neural Information Processing Systems
 Contextual correlates of semantic similarity,1991, Language andcognitive processes
 All-but-the-top: Simple and effective postprocessing for wordrepresentations,2018, In International Conference on Learning Representations
 Fair is better than sensational: Man is todoctor as woman is to doctor,2019, arXiv preprint arXiv:1905
 Neural random projections for language modelling,2018, CoRR
 Automatic differentiation inpytorch,2017, 2017
 Glove: Global vectors for word rep-resentation,2014, In Proceedings of the 2014 Conference on Empirical Methods in Natural LanguageProcessing (EMNLP) 
 Association for Computational Linguistics,1174, doi:10
 Towardsa seamless integration of word senses into downstream NLP applications,2017, In Proceedings of the55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)
 Improving language under-standing by generative pre-training,2018, 2018
 Languagemodels are unsupervised multitask learners,2019, 2019
 Contextual correlates of synonymy,0001, Commun
 Neural Transfer Learning for Natural Language Processing,2019, PhD thesis
 Green AI,2019, CoRR
 Retrofitting contextualized word embed-dings with paraphrases,2019, In Proceedings of the 2019 Conference on Empirical Methods in NaturalLanguage Processing
 A sub-character architecture for Korean language processing,1075, In Proceedingsof the 2017 Conference on Empirical Methods in Natural Language Processing
 Distilling task-specific knowledge from BERT into simple neural networks,2019, CoRR
 Xlnet: Generalized autoregressive pretraining for language understanding,2019, arXiv preprintarXiv:1906
 Men also likeshopping: Reducing gender bias amplification using corpus-level constraints,2017, In Proceedings ofthe 2017 Conference on Empirical Methods in Natural Language Processing
 Learning gender-neutral wordembeddings,2018, In Proceedings of the 2018 Conference on Empirical Methods in Natural LanguageProcessing
