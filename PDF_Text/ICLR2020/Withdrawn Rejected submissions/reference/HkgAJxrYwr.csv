title,year,conference
 Practical secure aggregation for privacy-preserving machine learning,2017, In Proceedings of the 2017 ACM SIGSAC Conference on Computerand Communications Security
 Distributed statistical machine learning in adversarial settings:Byzantine gradient descent,2017, POMACS
 Byzantine-robust distributedlearning: Towards optimal statistical rates,2018, In ICML
 Mitigating sybils in federated learningpoisoning,2018, arXiv preprint arXiv:1808
 Machine learning with adversaries: Byzantinetolerant gradient descent,2017, In Advances in Neural Information Processing Systems
 Robust regression using repeated medians,1982, Biometrika
 Gradient-based learning applied todocument recognition,1998, Proceedings of the IEEE
 Ups and downs: Modeling the visual evolution of fashion trendswith one-class collaborative filtering,2016, 2016
 Beyondinferring class representatives: User-level privacy leakage from federated learning,2018, arXiv preprintarXiv:1812
 Logan: Membershipinference attacks against generative models,2019, Proceedings on Privacy Enhancing Technologies
 Deep models under the GAN: in-formation leakage from collaborative deep learning,2017, In Proceedings of the 2017 ACM SIGSACConference on Computer and Communications Security
 Exploiting unintendedfeature leakage in collaborative learning,2019, In IEEE Symposium on Security and Privacy
 How tobackdoor federated learning,2018, arXiv preprint arXiv:1807
 Distributed robust learning,2014, CoRR
 Byzantine stochastic gradient descent,2018, In Advances inNeural Information Processing Systems
 Differentially private federated learning: A clientlevel perspective,2017, arXiv preprint arXiv:1712
 Ahybrid approach to privacy-preserving federated learning,2018, arXiv preprint arXiv:1812
 Differentially private learning with adaptiveclipping,2019, arXiv preprint arXiv:1905
 Automatic differentiation inpytorch,2017, 2017
 Bag of tricks for efficienttext classification,2016, arXiv preprint arXiv:1607
 Badnets: Evaluating backdooringattacks on deep neural networks,2019, IEEEAccess
 Adam: A method for stochastic optimization,2014, arXiv preprintarXiv:1412
