title,year,conference
 Con-crete problems in ai safety,2016, arXiv preprint arXiv:1606
 Understanding deep neuralnetworks with rectified linear units,2018, In ICLR
 Weight uncertainty inneural networks,2015, In ICML
 Uncertainty in deep learning,2016, University of Cambridge
 Dropout as a bayesian approximation: Representing modeluncertainty in deep learning,2016, In ICML
 On calibration of modern neuralnetworks,2017, In ICML
 Deep residual learning for image recog-nition,2016, In CVPR
 Identity mappings in deep residualnetworks,2016, In ECCV
 Why relu networks yield high-confidence predictions far away from the training data and how to mitigate the problem,2019, In CVPR
 A baseline for detecting misclassified and out-of-distributionexamples in neural networks,2017, In ICLR
 Densely connectedconvolutional networks,2017, In CVPR
 Simple and scalable predictiveuncertainty estimation using deep ensembles,2017, In NIPS
 Enhancing the reliability of out-of-distribution imagedetection in neural networks,2018, In ICLR
 Adv-BNN: Improved adversarial defensethrough robust bayesian neural network,2019, In ICLR
 Multiplicative normalizing flows for variational Bayesian neuralnetworks,2017, In ICML
 The evidence framework applied to classification networks,1992, Neural computation
 Deep neural networks are easily fooled: High confi-dence predictions for unrecognizable images,2015, In CVPR
 A scalable laplace approximation for neuralnetworks,2018, In ICLR
