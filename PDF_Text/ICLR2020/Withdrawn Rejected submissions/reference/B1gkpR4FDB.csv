title,year,conference
 On-line learning rate adaptation with hypergradient descent,2018, In Proceedings of the Sixth InternationalConference on Learning Representations (ICLR)
 Online algorithms and stochastic approximations,2012, In David Saad (ed
 Stochastic Processes,2013, Lecture notes
 ImageNet: A Large-Scale HierarchicalImage Database,2009, In CVPR09
 Batch means and spectral variance estimators in markov chainmonte carlo,2010, The Annals of Statistics
 Understanding the role momentum instochastic gradient methods,2019, In Advances in Neural Information Processing Systems
 Deep Learning,2016, MIT Press
 A stochastic analog of the conjugate gradient method,1972, Cybernetics
 Deep residual networks for image recog-nition,2016, In Proceedgins of the 29th IEEE Conference on Computer Vision and Pattern Recognition(CVPR)
 Increased rates of convergence through learning rate adaption,1988, Neural Networks
 Accelerat-ing stochastic gradient descent for least squares regression,2018, In Conference On Learning Theory
 Accelerated stochastic approximation,1958, Annals of Mathematical Statistics
 Adam: A method for stochastic optimization,2014, arXiv preprintarXiv:1412
 Testing Statistical Hypotheses,2005, Springer
 Tuning-freestep-size adaption,2012, In Proceedings of the IEEE International Conference on Acoustics
 Adaptive step adjustment for a stochastic optimization algo-rithm,1983, Zh
 Numerical Optimization,2006, Springer
 Comparison of the rates of convergence of one-step and multi-step optimizationalgorithms in the presence of noise,1977, Engineering Cybernetics
 Stochastic approximation method with gradient averag-ing for unconstrained problems,1983, IEEE Transactions on Automatic Control
 Stochastic approximation algorithm with gradient aver-aging and on-line stepsize rUles,1984, In J
 A method of aggregate stochastic subgradients withon-line stepsize rules for convex stochastic programming problems,1986, Mathematical ProgrammingStudy
 Minimizing finite sums with the stochasticaverage gradient,2017, Mathematical Programming
 Local gain adaptation in stochastic gradient descent,1999, In Proceedings ofNineth International Conference on Artificial Neural Networks (ICANN)
 On the importance of initial-ization and momentum in deep learning,2013, In Sanjoy Dasgupta and David McAllester (eds
 The marginalvalue of adaptive gradient methods in machine learning,2017, In Advances in Neural InformationProcessing Systems
 Fluctuation-dissipation relations for stochastic gradient descent,2018, arXiv preprintarXiv:1810
