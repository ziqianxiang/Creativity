title,year,conference
 Sanity checks forsaliency maps,2018, NeurIPS
 Towards robust interpretability with self-explainingneural networks,2018, NeurIPS
 Towards better understand-ing of gradient-based attribution methods for deep neural networks,2018, ICLR
 On pixel-wise explanations for non-linear classifier decisions by layer-wiserelevance propagation,2015, PLoS
 Imagenet: A large-scalehierarchical image database,2009, In CVPR
 A rotation and atranslation suffice: Fooling cnns with simple transformations,2017, CoRR
 Equalizing gender biases in neural machine translationwith word embeddings techniques,2019, arXiv preprint arXiv:1901
 Interpretable explanations of black boxes by meaningful perturba-tion,2017, CoRR
 Ex-plaining explanations: An overview of interpretability of machine learning,2019, arXiv:1806
 Explaining and harnessing adversarialexamples,2014, arXiv preprint arXiv:1412
 Evaluating feature importanceestimates,2018, CoRR
 Addressing bias in machine learning algorithms:A pilot study on emotion recognition for intelligent systems,2017, In IEEE Workshop on AdvancedRobotics and Its Social Impacts (ARSO)
 Neural machine translation in linear time,2016, CoRR
 Learning how to explain neural networks: Patternnet and patternat-tribution,2017, arXiv:1705
 Gradient-based learning appliedto document recognition,1998, Proceedings ofthe IEEE
 The mythos of model interpretability,2016, CoRR
 An introduction to informationretrieval,2009, Cambridge University Press
 A survey of evaluation methods and measures forinterpretable machine learning,2018, arxXiv:1811
 Learning deconvolution network for seman-tic segmentation,2015, arXiv:1505
 Automatic differentiation inpytorch,2017, 2017
 ”why should I trust you?”: Explainingthe predictions of any classifier,2016, In SIGKDD
 Anchors: High-precision model-agnosticexplanations,2018, AAAI
 Right for the right rasons: Trainingdifferentiable models by constraining their explanations,2017, arXiv:1703
 Grad-cam: Why did you say that? visual explanations from deep networks viagradient-based localization,2016, CoRR
 Learning important features throughpropagating activation differences,2017, ICML
 Masteringthe game of go with deep neural networks and tree search,2016, nature
 Smoothgrad:Removing noise by adding noise,2017, arXiv preprint arXiv:1706
 Striving forsimplicity: The all convolutional net,2015, arXiv:1412
 Axiomatic attribution for deep networks,2017, CoRR
 Intriguing properties of neural networks,2013, arXiv preprint arXiv:1312
 Re-thinking the inception architecture for computer vision,2015, CoRR
 On the euclidean distance of images,2005, IEEE Transactionson Pattern Analysis and Machine Intelligence
 Explainability scenarios: Towards scenario-based xai design,2019, IUI
 Bim: Towards quantitative evaluation of interpretability methodswith ground truth,2019, arXiv preprint arXiv:1907
 shapedtw: shape dynamic time warping,2016, arXiv:1606
 Improving semantic segmentation via video propagation and label relaxation,2018, CoRR
