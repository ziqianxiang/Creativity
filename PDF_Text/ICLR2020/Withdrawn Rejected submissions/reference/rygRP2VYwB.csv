title,year,conference
 Natasha 2: Faster Non-Convex Optimization Than SGD,2017,	ArXiv
 Stochastic variance reduced primal dual algorithms for empir-ical composition optimization,2019, arXiv preprint arXiv:1907
 Accelerated gradient methods for nonconvex nonlinear andstochastic programming,2016, Mathematical Programming
 A single time-scale stochastic approxi-mation method for nested stochastic optimization,2018, arXiv preprint arXiv:1812
 Stochastic neighbor embedding,2003, In Neural InformationProcessing Systems
 Accelerating stochastic gradient descent Using predictive varianceredUction,2013, In Neural Information Processing Systems
 Non-convex finite-sUm optimization viascsg methods,2017, In Neural Information Processing Systems
 An accelerated proximal coordinate gradient method,2014, InNeural Information Processing Systems
 Improved oracle complexity forstochastic compositional variance redUced gradient,2018, arXiv preprint arXiv:1806
 Accelerating stochastic composition optimization,2016, In NeuralInformation Processing Systems
 Variance redUced methods for non-convex composition optimiza-tion,2017, arXiv preprint arXiv:1711
 Stochastic zeroth-order optimization viavariance redUction method,2018, arXiv preprint arXiv:1805
 Accelerated proximal stochastic dual coordinate ascent forregularized loss minimization,2014, In International Conference on Machine Learning
 Reinforcement learning: An introduction,1998, MIT press
 Stochastic compositional gradient descent: algorithmsfor minimizing compositions of expected-value functions,2017, Mathematical Programming
 Fast stochastic variance reduced admm for stochastic compositionoptimization,2017, In International Joint Conferences on Artificial Intelligence
 Efficient non-convex stochastic compo-sitional optimization algorithm via stochastic recursive gradient descent,2019, In Neural InformationProcessing Systems
 A composite randomized incremental gradient method,2019, In InternationalConference on Machine Learning
③ is based on Lemma 3,2020,	□Proof of Corollary 223Under review as a conference paper at ICLR 2020Proof
