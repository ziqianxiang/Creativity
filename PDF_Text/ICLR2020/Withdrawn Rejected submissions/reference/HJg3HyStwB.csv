title,year,conference
   Obfuscated gradients give a false sense ofsecurity: Circumventing defenses to adversarial examples,2018, In ICML
 Learning to attack: Adversarial transformation networks,2018, In AAAI
 Towards evaluating the robustness of neural networks,2017, In 2017IEEE Symposium on Security and Privacy (SP)
 Transformation properties of learned visual representations,2015, ICLR
 Boost-ing adversarial attacks with momentum,2018, In CVPR
  Robustness of rotation-equivariant net-works to adversarial perturbations,2018, arXiv preprint arXiv:1802
  Generative adversarial nets,2014,  In NeurIPS
  Explaining and harnessing adversarialexamples,2014, ICLR
 Deep residual learning for image recog-nition,2016, In CVPR
   Spatial  transformer  networks,2015,   InNeurIPS
  Adam:  A method for stochastic optimization,2014,  arXiv preprintarXiv:1412
  Adversarial machine learning at scale,2016,  ICLR
 The MNIST database of handwritten digits,1998, 1998
  Gradient-based learning appliedto document recognition,1998, Proceedings of the IEEE
 Understanding image representations by measuring their equivari-ance and equivalence,2015, In CVPR
   Improved network robustness with adversary critic,2018,   InNeurIPS
  DeepFool: A simple andaccurate method to fool deep neural networks,2016, In CVPR
  Deep neural networks are easily fooled: High confi-dence predictions for unrecognizable images,2015, In CVPR
  Conditional image synthesis with auxil-iary classifier GANs,2017, In ICML
  Technical report on the cleverhans v2,2018,1
   Defense-GAN:  Protecting  classifiersagainst adversarial attacks using generative models,2018, ICLR
   Constructing unrestricted adversarialexamples with generative models,2018, In NeurIPS
 Ensemble adversarial training: Attacks and defenses,2018, ICLR
  Generating adver-sarial examples with adversarial networks,2018, In IJCAI
  Spatially trans-formed adversarial examples,2018, ICLR
