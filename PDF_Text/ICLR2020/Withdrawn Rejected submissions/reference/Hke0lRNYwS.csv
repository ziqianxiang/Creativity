title,year,conference
 Regularized auto-encoders estimate local statistics,2012, CoRR
 Modeling brain function: The world of attractor neural networks,1992, Cambridge UniversityPress
 Associative content-addressable networks with exponentially many robuststable states,2017, arXiv preprint arXiv:1704
 Density estimation using Real NVP,2016, arXiv preprintarXiv:1605
 Implicit generation and generalization in energy-based models,2019, arXiv preprintarXiv:1903
 Boltzmann machine,2007, Scholarpedia
 Gradient flow in recurrent nets: The difficulty of learninglong-term dependencies,2001, In J
 Neurons with graded response have collective computational properties like those oftwo-state neurons,1984, Proceedings of the National Academy of Sciences
 Evidence that recurrent circuits arecritical to the ventral streamâ€™s execution of core object recognition behavior,1546, Nature neuroscience
 Deeply-recursive convolutional network for image super-resolution,2016, In Computer Vision and Pattern Recognition
 Auto-encoding variational Bayes,2013, arXiv preprint arXiv:1312
 Dense associative memory for pattern recognition,2016, In Advances inNeural Information Processing Systems
 Fast and accurate image super-resolutionwith deep Laplacian pyramid networks,2018, IEEE Transactions on Pattern Analysis and MachineIntelligence
 Human-Level Concept Learning throughProbabilistic Program Induction,0036, Science
 State-reification networks: Improving generalization by modeling the distribution ofhidden representations,2019, In K
 Convolutional deep belief networks for scalableunsupervised learning of hierarchical representations,2009, In Proceedings of the 26th InternationalConference on Machine Learning
 Learning deep parsimonious representations,2016, InD
 Reviving andimproving recurrent back-propagation,2018, In J
 A database of human segmented natural imagesand its application to evaluating segmentation algorithms and measuring ecological statistics,2001, InProceedings of the International Conference on Computer Vision (ICCV)
 An interactive activation model of context effects in letterperception: I,1981, an account of basic findings
 Attractor networks,2009, In P
 Task-driven convolutional recurrent models of the visual system,2018, In Advances in Neural InformationProcessing Systems
 An image synthesizer,1985, In Proceedings of the 12th Annual Conference on ComputerGraphics and Interactive Techniques
 Generalization of back-propagation to recurrent neural networks,1987, Physical ReviewLetters
 Deep boltzmann machines,2009, In Artificial intelligence and statistics
 A neural basis for inference in perceptual ambiguity,0027, Proceedings ofthe National Academy of Sciences
 The sentence wrap-up dogma,2018, Cognition
 Learning to predict by the methods of temporal differences,1988, Machine Learning
 Image super-resolution via deep recursive residual network,2017, 2017 IEEEConference on Computer Vision and Pattern Recognition (CVPR)
 Recurrent computations for visual pattern completion,2018, Proceedings of the NationalAcademy of Sciences
 Extracting and composing robust featureswith denoising autoencoders,2008, In Proceedings of the 25th International Conference on MachineLearning
 Exponential family harmoniums with anapplication to information retrieval,2005, In L
 The Kanerva machine: A generative distributedmemory,2018, In International Conference on Learning Representations
 Image super-resolution via sparse representation,2010, IEEEtransactions on image processing
 Localist attractor networks,2001, Neural Computation
 On single image scale-up using sparse-representations,2010, InProceedings of the International conference on curves and surfaces
