title,year,conference
 Grad-cam++: Generalized gradient-based visual explanations for deep convolutional networks,2018, In IEEEWinter Conference on Applications of Computer Vision (WACV)
 Infogan:Interpretable representation learning by information maximizing generative adversarial nets,2016, InAdvances in Neural Information Processing Systems (NeurIPS)
 Real time image saliency for black box classifiers,2017, In Advances inNeural Information Processing Systems (NeurIPS)
 Techniques for interpretable machine learning,2018, arXivpreprint arXiv:1808
 Visualizing higher-layerfeatures of a deep network,2009, University of Montreal
 Understanding deep networks via extremal per-turbations and smooth masks,2019, In Proceedings of the IEEE International Conference on ComputerVision (ICCV)
 Lstm:A search space odyssey,2016, IEEE transactions on neural networks and learning systems (TNNLS)
 DeeP residual learning for image recog-nition,2016, In Proceedings of the IEEE conference on Computer Vision and Pattern Recognition(CVPR)
 Batch normalization: Accelerating deep network training by re-ducing internal covariate shift,2015, In Proceedings of the IEEE International Conference on MachineLearning (ICML)
 Recurrentneural network based language model,2010, In The annual conference of the international speechcommunication association
 Methods for interpreting and un-derstanding deep neural networks,2018, Digital Signal Processing
 Rectified linear units improve restricted boltzmann machines,2010, InProceedings of the International Conference on Machine Learning (ICML)
 Very deep convolutional networks for large-scale imagerecognition,2014, arXiv preprint arXiv:1409
 Deep inside convolutional networks:Visualising image classification models and saliency maps,2014, International Conference on LearningRepresentations (ICLR) Workshop
 Smoothgrad:removing noise by adding noise,2017, ICML workshop
 Striving forsimplicity: The all convolutional net,2014, International Conference on Learning Representations(ICLR) Workshop
 Instance normalization: The missing in-gredient for fast stylization,2016, arXiv preprint arXiv:1607
 The corresponding probability density function is displayedin Fig,1996,7(a)
 According to the probability density transformation Forbes et al,2020, (2011)
