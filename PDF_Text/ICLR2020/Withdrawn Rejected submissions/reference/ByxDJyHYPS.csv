title,year,conference
 Bert: Pre-training of deepbidirectional transformers for language understanding,2018, NAACL
 Gated-attention readers for text comprehension,2016, ACL
 Allennlp: A deep semantic natural languageprocessing platform,2017, 2017
 Cut to the chase: Acontext zoom-in network for reading comprehension,2018, Association for Computational Linguistics
 Attention is not explanation,2019, NAACL
 Semi-supervised classification with graph convolutional net-works,2017, ICLR
 Ask me anything: Dynamic memory networks fornatural language processing,2016, In International Conference on Machine Learning
 Exploiting explicit paths for multi-hop readingcomprehension,2018, arXiv preprint arXiv:1811
 RACE: Large-scale ReAdingComprehension Dataset From Examinations,2017, arXiv preprint arXiv:1704
 RoBERTa: A Robustly Optimized BERT Pre-training Approach,2019, arXiv preprint arXiv:1907
 Compositional questions do not necessitate multi-hop reasoning,2019, In ACL
 Multi-hop read-ing comprehension through question decomposition and rescoring,2019, In Proceedings of the57th Conference of the Association for Computational Linguistics
 Dy-namically fused graph network for multi-hop reasoning,2019, In Proceedings of the 57thConference of the Association for Computational Linguistics
 MCTest: A Challenge Dataset forthe Open-Domain Machine Comprehension of Text,2013, In EMNLP
 Bidirectional attentionflow for machine comprehension,2017, ICLR
 Reasonet: Learning to stop readingin machine comprehension,2017, In Proceedings of the 23rd ACM SIGKDD International Conferenceon Knowledge Discovery and Data Mining
 Explor-ing Graph-structured Passage Representation for Multi-hop Reading Comprehension with GraphNeural Networks,2018, arXiv preprint arXiv:1809
 End-to-end memory networks,2015, In Advancesin neural information processing systems
 Multi-hop read-ing comprehension across multiple documents by reasoning over heterogeneous graphs,2019, arXivpreprint arXiv:1905
 Pointer networks,2015, In Advances in NeuralInformation Processing Systems
 Evidencesentence extraction for machine reading comprehension,2019, arXiv preprint arXiv:1902
