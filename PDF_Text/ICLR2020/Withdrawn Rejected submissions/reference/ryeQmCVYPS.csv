title,year,conference
 Deep convolutionalnetworks do not classify based on global object shape,2018, PLoS computational biology
 Evasion attacks against machine learning at test time,2013, In Joint Europeanconference on machine learning and knowledge discovery in databases
 Decision-based adversarial attacks: Reliableattacks against black-box machine learning models,2017, arXiv preprint arXiv:1712
 Thermometer encoding: One hotway to resist adversarial examples,2018, 2018
 Towards evaluating the robustness of neural networks,2016, CoRR
 Deformableconvolutional networks,2017, In Proceedings of the IEEE international conference on computer vision
 Boostingadversarial attacks with momentum,2017, arXiv preprint arXiv:1710
 Adversarial examples are a naturalconsequence of test error in noise,2019, arXiv preprint arXiv:1901
 Dropblock: A regularization method for convolutionalnetworks,2018, In Advances in Neural Information Processing Systems
 Explaining and harnessing adversarialexamples,2015, In International Conference on Learning Representations
 Deep residual learning for imagerecognition,2016, In Proceedings of the IEEE conference on computer vision and pattern recognition
 Dropping pixels for adversarial robust-ness,2019, arXiv preprint arXiv:1905
 Squeeze-and-excitation networks,2017, CoRR
 Squeeze-and-excitation networks,2017, arXiv preprint arXiv:1709
 Densely connectedconvolutional networks,2017, In CVPR
 Adversarial machine learning at scale,2016, arXivpreprint arXiv:1611
 Gradient-based learning applied todocument recognition,1998, Proceedings of the IEEE
 Deep learning,2015, nature
 Defenseagainst adversarial attacks using high-level representation guided denoiser,2017, arXiv preprintarXiv:1712
 Analyzing the noise robustness ofdeep neural networks,2018, arXiv preprint arXiv:1810
 Delving into transferable adversarial examplesand black-box attacks,2016, arXiv preprint arXiv:1611
 Inceptionism: Going deeper into neuralnetworks,2015, 2015
 Towards the science ofsecurity and privacy in machine learning,2016, arXiv preprint arXiv:1611
 Transferability in machine learning:from phenomena to black-box attacks using adversarial samples,2016, CoRR
 Foolbox: A python toolbox to benchmarkthe robustness of machine learning models,2017, arXiv preprint arXiv:1707
 Faster r-cnn: Towards real-time objectdetection with region proposal networks,2015, In Advances in neural information processing systems
 Defense-gan: Protecting classifiers againstadversarial attacks using generative models,2018, arXiv preprint arXiv:1805
 Very deep convolutional networks for large-scale imagerecognition,2014, arXiv preprint arXiv:1409
 Pixeldefend:Leveraging generative models to understand and defend against adversarial examples,2017, arXivpreprint arXiv:1710
 Adversarial defense by stratifiedconvolutional sparse coding,2018, arXiv preprint arXiv:1812
 Intriguing properties of neural networks,2013, CoRR
 Rethinkingthe inception architecture for computer vision,2016, In Proceedings of the IEEE conference on computervision and pattern recognition
 Efficient objectlocalization using convolutional networks,2015, In Proceedings of the IEEE Conference on ComputerVision and Pattern Recognition
 Wide residual networks,2016, arXiv preprint arXiv:1605
 Visualizing and understanding convolutional networks,2014, InEuropean conference on computer vision
 Decision-based attack performs based on the predictionof the model,2017, It needs less information from the model and has the potential to perform betteragainst adversarial defenses based on gradient masking
