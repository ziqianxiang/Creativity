title,year,conference
 Towards robust interpretability with self-explainingneural networks,2018, In arXiv:1806
 Evaluating recurrent neuralnetwork explanations,2019, In arXiv:1904
 Understanding deep features with computer-generated im-agery,2015, In ICCV
 Network dissection:Quantifying interpretability of deep visual representations,2017, In CVPR
 Interpretable deep mod-els for icu outcome prediction,2016, In American Medical Informatics Association (AMIA) AnnualSymposium
 L-shapley and c-shapley:Efficient model interpretation for structured data,2018, In arXiv:1808
 Infogan:Interpretable representation learning by information maximizing generative adversarial nets,2016, InNIPS
 Retain: an interpretable predictive model for healthcare using reverse time attentionmechansim,2017, In arXiv:1608
 An integrative 3c evaluation framework for explainableartificial intelligence,2019, In The annual Americas Conference on Information Systems (AMCIS)
 Net2vec: Quantifying and explaining how concepts are encoded byfilters in deep neural networks,2018, In CVPR
 Interpretable explanations of black boxes by meaningful pertur-bation,2017, In arXiv:1704
 Distilling a neural network into a soft decision tree,2017, InarXiv:1711
 Interpretation of neural networks is fragile,2019, InAAAI
 Deep residual learning for image recog-nition,2016, In CVPR
 β-vae: learning basic visual concepts with a con-strained variational framework,2017, In ICLR
 Harnessing deep neuralnetworks with logic rules,2016, In arXiv:1603
 Learning how to explain neural networks: Patternnet and patternat-tribution,2018, In ICLR
 Understanding black-box predictions via influence functions,2017, InICML
 Learning multiple layers of features from tiny images,2009, In ComputerScience Department
 Imagenet classification with deep convo-lutional neural networks,2012, In NIPS
 Identifying unknown unknownsin the open world: Representations and policies for guided exploration,2017, In AAAI
 Gradient-based learning applied todocument recognition,1998, In Proceedings of the IEEE
 Learning deep parsimoniousrepresentations,2016, In NIPS
 A unified approach to interpreting model predictions,2017, In NIPS
 Understanding deep image representations by invertingthem,2015, In CVPR
 “why should i trust you?” explaining thepredictions of any classifier,2016, In KDD
 Grad-cam: Visual explanations from deep networks via gradient-based local-ization,2017, In ICCV
 A value for n-person games,1953, In Contributions to the Theory of Games
 Not just a black box:Learning important features through propagating activation differences,2016, In arXiv:1605
 Neural activation constellations: Unsupervised part model discov-ery with convolutional networks,2015, In ICCV
 Very deep convolutional networks for large-scale imagerecognition,2015, In ICLR
 Deep inside convolutional networks:Visualising image classification models and saliency maps,2013, In arXiv:1312
 Striving forsimplicity: The all convolutional net,2014, In arXiv:1412
 Teaching composition-ality to cnns,2017, In CVPR
 Intriguing properties of neural networks,2014, In arXiv:1312
 Transparent model distillation,2018, InarXiv:1801
 Explainable neuralnetworks based on additive index models,2018, In arXiv:1806
 Evaluating explainersvia perturbation,2019, In arXiv:1906
 Beyond sparsity: Tree regularization of deep models for interpretability,2017, In NIPS TIMLWorkshop
 Interpretable r-cnn,2017, InarXiv:1711
 Bim: Towards quantitative evaluation of interpretability methodswith ground truth,2019, In arXiv:1907
 Understanding neuralnetworks through deep visualization,2015, In ICML Deep Learning Workshop
 Visualizing and understanding convolutional networks,2014, InECCV
 Unsupervised learningof neural networks to explain neural networks,2018, In arXiv:1805
 Object detectorsemerge in deep scene cnns,2015, In ICRL
 Learning deepfeatures for discriminative localization,2016, In CVPR
1 and Section 3,2009,2
