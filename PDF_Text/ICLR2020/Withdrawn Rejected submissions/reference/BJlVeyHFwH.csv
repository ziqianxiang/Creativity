title,year,conference
 Analyzing inverse problems with invertibleneural networks,2019, International Conference on Learning Representations
 Numerical methods for evolutionary differential equations,2008, Computational Scienceand Engineering
 Analysis of Invariance and Robust-ness via Invertibility of ReLU-Networks,2018, arXiv preprint arXiv:1806
 Decision-based adversarial attacks: Reliableattacks against black-box machine learning models,2018, In International Conference on LearningRepresentations
 Neural ordinarydifferential equations,2018, Advances in Neural Information Processing Systems
 Residual flows forinvertible generative modeling,2019, Advances in Neural Information Processing Systems
 Discovering hidden factorsof variation in deep networks,2014, arXiv preprint arXiv:1412
 Reducing overfit-ting in deep networks by decorrelating representations,2015, arXiv preprint arXiv:1511
 Com-parison of maximum likelihood and GAN-based training of real NVPs,2017, arXiv preprintarXiv:1705
 NICE: Non-linear independent componentsestimation,2014, arXiv preprint arXiv:1410
 Large scale adversarial representation learning,2019, arXiv preprintarXiv:1907
 Neural spline flows,2019, InAdvances in Neural Information Processing Systems
 Geometric measure theory,1969, Grundlehren der mathematischen Wissenschaften
 The reversible residual network:Backpropagation without storing activations,2017, In Advances in Neural Information ProcessingSystems
 Regularisation of neural networksby enforcing Lipschitz continuity,2018, arXiv preprint arXiv:1804
 FFJORD:Free-form continuous dynamics for scalable reversible generative models,2019, International Conferenceon Learning Representations
 Deep learning withlimited numerical precision,2015, In International Conference on Machine Learning
 Emerging convolutions for generativenormalizing flows,2019, International Conference on Machine Learning
 Excessive invariancecauses adversarial vulnerability,2019, International Conference on Learning Representations
 Sum-of-squares polynomial flow,2019, In InternationalConference on Machine Learning
 Adam: A method for stochastic optimization,2015, In InternationalConference on Learning Representations
 Glow: Generative flow with invertible 1x1 convolutions,2018, InAdvances in Neural Information Processing Systems
 Generalizing Hamiltonian MonteCarlo with neural networks,2017, arXiv preprint arXiv:1711
 Deep learning face attributes in the wild,2015, InInternational Conference on Computer Vision
 Gradient-based hyperparameter optimizationthrough reversible learning,2015, In International Conference on Machine Learning
 Understanding deep image representations by invertingthem,2014, Conference on Computer Vision and Pattern Recognition
 Spectral normalization forgenerative adversarial networks,2018, In International Conference on Learning Representations
 Masked autoregressive flow for densityestimation,2017, In Advances in Neural Information Processing Systems
 Variational inference with normalizing flows,2015, In InternationalConference on Machine Learning
 A-NICE-MC: Adversarial training for MCMC,2017, InAdvances in Neural Information Processing Systems
 MintNet: Building invertible neural networks withmasked convolutions,2019, Advances in Neural Information Processing Systems
 Intriguing properties of neural networks,2013, arXiv preprint arXiv:1312
 Lipschitz regularity of deep neural networks: Analysis andefficient estimation,2018, In Advances in Neural Information Processing Systems
 Wide residual networks,2016, arXiv preprint arXiv:1605
