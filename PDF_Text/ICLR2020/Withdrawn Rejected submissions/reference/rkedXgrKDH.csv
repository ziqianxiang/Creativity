title,year,conference
 Net-trim: Convex pruning of deepneural networks with performance guarantee,2017, In Advances in Neural Information ProcessingSystems
 Understanding the difficulty of training deep feedforward neuralnetworks,2010, In Proceedings of the thirteenth international conference on artificial intelligence andstatistics
 On characterizing the capacity of neural networks usingalgebraic topology,2018, arXiv preprint arXiv:1802
 Complexity of linear regions in deep networks,2019, In InternationalConference on Machine Learning
 Multilayer feedforward networks are uni-versal approximators,1989, Neural networks
 A provably convergent schemefor compressive sensing under random generative priors,2018, arXiv preprint arXiv:1812
 Binarizedneural networks,2016, In Advances in neural information processing systems
 Trainingquantized nets: A deeper understanding,2017, In Advances in Neural Information Processing Systems
 Bayesian compression for deep learning,2017, InAdvances in Neural Information Processing Systems
 Multi-layer generalizedlinear estimation,2017, In 2017 IEEE International Symposium on Information Theory (ISIT)
 Expo-nential expressivity in deep neural networks through transient chaos,2016, In Advances in NeuralInformation Processing Systems 29
 Training and inference with integers in deepneural networks,2018, In International Conference on Learning Representations
