title,year,conference
 Discrete cosine transform,1974, IEEE transactionson Computers
 Wasserstein gan,2017, arXiv preprintarXiv:1701
 Obfuscated gradients give a false sense of se-curity: Circumventing defenses to adversarial examples,2018, In Proceedings of the 35th InternationalConference on Machine Learning
 Thermometer encoding: One hotway to resist adversarial examples,2018, In International Conference on Learning Representations
 Towards evaluating the robustness of neural networks,2017, 2017IEEE Symposium on Security and Privacy (SP)
 Stochastic activation pruning for robustadversarial defense,2018, In International Conference on Learning Representations
 Explaining and harnessing adversarialexamples,2014, arXiv preprint arXiv:1412
 Countering adversarialimages using input transformations,2018, In International Conference on Learning Representations
 Deep residual learning for image recog-nition,2016, In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)
 Parametric noise injection: Trainable randomnessto improve deep neural network robustness against adversarial attack,2019, In Proceedings of the IEEEConference on Computer Vision and Pattern Recognition
 Comdefend: An efficient imagecompression model to defend adversarial examples,2019, CoRR
 Perceptual losses for real-time style transfer andsuper-resolution,2016, In European conference on computer vision
 Adversarial machine learning at scale,2016, arXivpreprint arXiv:1611
 Magnet: a two-pronged defense against adversarial examples,2017, InProceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security
 Cascade adversarial machine learning reg-ularized with a unified embedding,2018, In International Conference on Learning Representations
 Readingdigits in natural images with unsupervised feature learning,2011, 2011
 On the effectiveness of defensive distillation,2016, arXiv preprintarXiv:1607
 The limitations of deep learning in adversarial settings,2016, pp
 Distillation as adefense to adversarial perturbations against deep neural networks,2016, In 2016 IEEE Symposium onSecurity and Privacy (SP)
 Practical black-box attacks against machine learning,2017, In Proceedings of the 2017 ACMon Asia Conference on Computer and Communications Security
 Defense-gan: Protecting classifiers againstadversarial attacks using generative models,2018, arXiv preprint arXiv:1805
 Adversarial defense by strati-fied convolutional sparse coding,2019, CVPR
 Intriguing properties of neural networks,2013, arXiv preprint arXiv:1312
 The jpeg still picture compression standard,1992, IEEE transactions on consumerelectronics
 A direct approach to robust deep learning using adversar-ial networks,2019, In International Conference on Learning Representations
 11 adversarial perturbations of deep neural networks,2016, Perturbations
 Generating adver-sarial examples with adversarial networks,2018, arXiv preprint arXiv:1801
 Mitigating adversarialeffects through randomization,2018, In International Conference on Learning Representations
 Feature denoisingfor improving adversarial robustness,2018, arXiv preprint arXiv:1812
 Feature squeezing: Detecting adversarial examples in deepneural networks,2017, arXiv preprint arXiv:1704
