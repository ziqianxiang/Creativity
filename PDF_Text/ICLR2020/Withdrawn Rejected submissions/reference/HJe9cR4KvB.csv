title,year,conference
  Multinomial adversarial networks for multi-domain text classifica-tion,2018, arXiv preprint arXiv:1802
  Semi-supervised se-quence modeling with cross-view training,2018, arXiv preprint arXiv:1809
   Maximum likelihood from incomplete data viathe em algorithm,1977,  JOURNAL OF THE ROYAL STATISTICAL SOCIETY
  Bert:  Pre-training of deepbidirectional transformers for language understanding,2018, arXiv preprint arXiv:1810
   Joint cross-domain classification andsubspace learning for unsupervised adaptation,2015, Pattern Recognition Letters
    Who  said  what:Modeling  individual  labelers  improves  classification,2017,    CoRR
   Conditional random fields:  Probabilistic models for segmenting and labeling se-quence data,2001, In ICML
  Semi-supervised training using adversarial multi-task learning forspoken language understanding,2018,  In 2018 IEEE International Conference on Acoustics
   Heterogeneoussupervision for relation extraction:  A representation learning approach,2017,   In Proceedings of the2017 Conference on Empirical Methods in Natural Language Processing
  Efficient Contextualized Repre-sentation: Language Model Pruning for Sequence Labeling,2018, In EMNLP
  End-to-end sequence labeling via bi-directional lstm-cnns-crf,2016,  InProceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume1:  Long Papers)
 End-to-end sequence labeling via bi-directional lstm-cnns-crf,2016, arXivpreprint arXiv:1603
  Unsupervised domain adaptation with imbalanced cross-domain data,2015,  InProceedings of the IEEE International Conference on Computer Vision
 Multi-task domain adaptation for sequence tagging,2016, arXiv preprintarXiv:1608
  Massively multilingual transfer for ner,2019,  In Proceedingsof the 57th Conference of the Association for Computational Linguistics
   A maximum entropy model for part-of-speech tagging,1996,   In Conference onEmpirical Methods in Natural Language Processing
 Deep learning from crowds,2018, In AAAI
    Sequence  labeling  with  multipleannotators,1573,   Machine  Learning
   Strong baselines for neural semi-supervised learning underdomain shift,2018, arXiv preprint arXiv:1804
 SQUARE: A Benchmark for Research on Computing CrowdConsensus,2013,   In  Proceedings  of  the  1st  AAAI  Conference  on  Human  Computation  (HCOMP)
   Cheap and fastâ€”but is itgood?:   Evaluating  non-expert  annotations  for  natural  language  tasks,2008,   In  Proceedings  of  theConference  on  Empirical  Methods  in  Natural  Language  Processing
 Attention is all you need,2017, In Advances in neural informationprocessing systems
  Transfer learning for sequence taggingwith hierarchical recurrent networks,2017, arXiv preprint arXiv:1703
