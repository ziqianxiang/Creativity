title,year,conference
 Deepmind lab,2016, arXiv:1612
 Openai gym,2016, arXiv:1606
 Particle filter-based policy gradient inpomdps,2009, In NeurIPS
 A survey of convergence results on particle filtering methods forpractitioners,2005, IEEE TSP
 Generative adversarial nets,2014, In NeurIPS
 Improvedtraining of wasserstein gans,2017, In NeurIPS
 Soft actor-critic: Off-policymaximum entropy deep reinforcement learning with a stochastic actor,2015, In ICML
 Deep variationalreinforcement learning for pomdps,2018, arXiv preprint arXiv:1806
 Differentiable particle filters: End-to-endlearning with algorithmic priors,2018, In RSS
 Planning and acting in partiallyobservable stochastic domains,1998, Artificial intelligence
 Optimal control as a graphical model inferenceproblem,2012, Machine learning
 Qmdp-net: Deep learning for planning under partialobservability,2017, In NeurIPS
 Integrating algorithmic planning and deep learning forpartially observable navigation,2018, arXiv preprint arXiv:1807
 Particle filter networks: End-to-end probabilisticlocalization from visual observations,2018, arXiv preprint arXiv:1805
 Variational policy search via trajectory optimization,2013, In NeurIPS
 Learning policies for partiallyobservable environments: Scaling up,1995, In ICML
 Spectral normalization forgenerative adversarial networks,2018, In ICLR
 The cross-entropy method for policy search indecentralizedpomdps,2008, Informatica
 Graph-based cross entropy method for solving multi-robot decentralizedpomdps,2016, In ICRA
 Probabilisticplanning with sequential monte carlo methods,2018, In ICLR
 Belief space planningassuming maximum likelihood observations,2010, In RSS
 An approximate inference approach totemporal optimization in optimal control,2010, In NeurIPS
 An online and approximate solver forpomdps with continuous action space,2015, In ICRA
 Reinforcement learning via recurrentconvolutional neural networks,2016, In ICPR
 Monte-carlo planning in large pomdps,2010, In NeurIPS
 Value iteration networks,2016, InNeurIPS
 Robot trajectory optimization using approximate inference,2009, In ICML
 Probabilistic inference for solving discrete and continuous statemarkov decision processes,2006, In ICML
 On improving deep reinforcement learningfor pomdps,2018, arXiv preprint arXiv:1804
 Modeling Purposeful Adaptive Behavior with the Principle of Maximum CausalEntropy,2010, PhD thesis
