title,year,conference
 Thermometer encoding: One hotway to resist adversarial examples,2018, In International Conference on Learning Representations
 Towards evaluating the robustness of neural networks,2017, In2017 IEEE Symposium on Security and Privacy
 Stochastic activation pruning for robustadversarial defense,2018, In International Conference on Learning Representations
 Adversarial vulnerability for any classifier,2018, InAdvances in Neural Information Processing Systems
 Explaining and harnessing adversarialexamples,2015, In 3rd International Conference on Learning Representations
 Benchmarking neural network robustness to common cor-ruptions and perturbations,2019, In International Conference on Learning Representations
 Interpolated adversarial training:Achieving robust neural networks without sacrificing accuracy,2019, CoRR
 The curse of concentrationin robust learning: Evasion and poisoning attacks from concentration of measure,2019, In Proceedingsof the AAAI Conference on Artificial Intelligence
 Deepfool: A simple andaccurate method to fool deep neural networks,2016, In 2016 IEEE Conference on Computer Vision andPattern Recognition
 Defense-GAN: Protecting classifiersagainst adversarial attacks using generative models,2018, In International Conference on LearningRepresentations
 Intriguing properties of neural networks,2014, In International Conference onLearning Representations
 Wasserstein adversarial examples via projectedSinkhorn iterations,2019, In Kamalika Chaudhuri and Ruslan Salakhutdinov (eds
 Spatially trans-formed adversarial examples,2018, In International Conference on Learning Representations
 Feature denoisingfor improving adversarial robustness,2019, In The IEEE Conference on Computer Vision and PatternRecognition (CVPR)
