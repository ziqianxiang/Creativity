title,year,conference
 A survey of machine learning for bigcode andnaturalness,0360, ACM ComPut Surv
 Learning to represent programs with graphs,2018, InInternational Conference on Learning RePresentations
 Context2name: A deep learning-based approach to infer naturalvariable names from usage contexts,2018, CoRR
 Enriching word vectors with subword informa-tion,2017, Transactions of the Association for Computational Linguistics
 BERT: pre-training of deep bidirectional trans-formers for language understanding,2018, CoRR
 Automatic software repair: A survey,1939, IEEE Transactions on SoftwareEngineering
 Automated software vulnerability detection with machine learning,2018, CoRR
 Defects4j: A database of existing faults to enable controlled testingstudies for java programs,2014, In Proceedings of the 2014 International Symposium on Software Testing and Analysis
 How Often Do Single-Statement Bugs Occur? The ManySStuBs4JDataset,2019, arXiv preprint arXiv:1905
 Roberta: A robustly optimized BERT pretraining approach,2019, CoRR
 Distributed representa-tions of words and phrases and their compositionality,2013, In C
 Automatic software repair: A bibliography,2018, ACM Comput
 Efficient non-parametric estimationof multiple embeddings per word in vector space,2014, In Proceedings of the 2014 Conference on Empirical Methodsin Natural Language Processing (EMNLP)
 Glove: Global vectors for word representation,2014, InProceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)
 Word representations: A simple and general method for semi-supervised learning,2010, In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics
 Neural program repair by jointlylearning to localize and repair,2019, In International Conference on Learning Representations
 Sorting and transformingprogram repair ingredients via deep learning code similarities,2019, pp
 Charagram: Embedding words and sentences viacharacter n-grams,2016, In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing
 XLNet:Generalized autoregressive pretraining for language understanding,2019, CoRR
 Learning torepresent edits,2018, CoRR
