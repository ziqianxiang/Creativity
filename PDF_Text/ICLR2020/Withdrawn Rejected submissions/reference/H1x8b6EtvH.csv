title,year,conference
  Double Viterbi: Weight encoding for high com-pression  ratio  and  fast  on-chip  reconstruction  for  deep  neural  network,2019,   In  International  Conference  onLearning Representations (ICLR)
   GroupReduce:  Block-wise low-rank ap-proximation for neural language model shrinking,2018,  In Advances in Neural Information Processing Systems
  Deep Learning,2016,  MIT Press
  Dynamic network surgery for efficient DNNs,2016,  In Advances inNeural Information Processing Systems
  EIE:efficient inference engine on compressed deep neural network,2016,   In Proceedings of the 43rd InternationalSymposium on Computer Architecture
 Deep residual learning for image recognition,2016, 2016IEEE Conference on Computer Vision and Pattern Recognition (CVPR)
  Channel pruning for accelerating very deep neural networks,2017,  In TheIEEE International Conference on Computer Vision (ICCV)
   Imagenet  classification  with  deep  convolutionalneural networks,2012,  In F
  Optimal brain damage,1990,  In Advances in Neural InformationProcessing Systems
  Rethinking the value of networkpruning,2019, In International Conference on Learning Representations (ICLR)
  The penn treebank: Annotating predicate argument structure,1994,  In Proceedingsof the Workshop on Human Language Technology
   Variational dropout sparsifies deep neural net-works,2017, In International Conference on Machine Learning (ICML)
  Learning structured sparsity in deep neuralnetworks,2016, In Advances in Neural Information Processing Systems
   Al-ternating multi-bit quantization for recurrent neural networks,2018,   In International Conference on LearningRepresentations (ICLR)
  Scalpel:Customizing  DNN  pruning  to  the  underlying  hardware  parallelism,2017,   In  Proceedings  of  the  44th  AnnualInternational Symposium on Computer Architecture
  Binary matrix factorization with applica-tions,2007, In IEEE International Conference on Data Mining
