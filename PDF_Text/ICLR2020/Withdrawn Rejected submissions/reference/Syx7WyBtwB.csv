title,year,conference
 Slic superpixels compared to state-of-the-art superpixel methods,2012, IEEE transactionson pattern analysis and machine intelligence
 ToWards better understanding ofgradient-based attribution methods for deep neural netWorks,2018, In 6th International Conference onLearning Representations (ICLR 2018)
 On pixel-Wise explanations for non-linear classifier decisions by layer-Wiserelevance propagation,2015, PloS one
 Man isto computer programmer as woman is to homemaker? debiasing word embeddings,2016, In Advancesin neural information processing Systems
 Womenalso snowboard: Overcoming bias in captioning models,2018, arXiv preprint arXiv:1803
 Real time image saliency for black box classifiers,2017, arXiv preprintarXiv:1705
 Learning ex-plainable models using attribution priors,2019, arXiv preprint arXiv:1906
 Interpretable explanations of black boxes by meaningful pertur-bation,2017, arXiv preprint arXiv:1704
 Word embeddings quantify 100years of gender and ethnic stereotypes,0027, Proceedings of the National Academy of Sciences
 Attention is not explanation,2019, arXiv preprint arXiv:1902
 Repair: Removing representation bias by dataset resampling,2019, arXivpreprint arXiv:1904
 A unified approach to interpreting model predictions,2017, In Advancesin Neural Information Processing Systems
 Embedding human knowledge in deep neuralnetwork via attention map,2019, arXiv preprint arXiv:1905
 Automatic rule extraction from long short term memorynetworks,2017, arXiv preprint arXiv:1702
 Beyond word importance: Contextual decompositionto extract interactions from lstms,2018, arXiv preprint arXiv:1801
 A theoretical explanation for perplexing behaviors ofbackpropagation-based visualizations,2018, arXiv preprint arXiv:1805
 Why should i trust you?: Explaining thepredictions of any classifier,2016, In Proceedings of the 22nd ACM SIGKDD International Conferenceon Knowledge Discovery and Data Mining
 Aggregating explainability methods for neural networks stabi-lizes explanations,2019, arXiv preprint arXiv:1903
 Right for the right reasons: Train-ing differentiable models by constraining their explanations,2017, arXiv preprint arXiv:1703
 Grad-cam: Visual explanations from deep networks via gradient-based local-ization,2017, In Proceedings of the IEEE International Conference on Computer Vision
 Not just a blackbox: Learning important features through propagating activation differences,2016, arXiv preprintarXiv:1605
 Very deep convolutional networks for large-scale imagerecognition,2014, arXiv preprint arXiv:1409
 Hierarchical interpretations for neural networkpredictions,2018, arXiv preprint arXiv:1806
 Striving forsimplicity: The all convolutional net,2014, arXiv preprint arXiv:1412
 Axiomatic attribution for deep networks,2017, ICML
 Learning robust representations byprojecting superficial statistics out,2019, arXiv preprint arXiv:1903
 Interpreting adversarially trained convolutional neural net-works,2019, arXiv preprint arXiv:1905
 Visualizing deep neural networkdecisions: Prediction difference analysis,2017, arXiv preprint arXiv:1702
