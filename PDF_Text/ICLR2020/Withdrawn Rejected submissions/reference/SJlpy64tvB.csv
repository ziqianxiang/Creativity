title,year,conference
 Obfuscated gradients give a false sense ofsecurity: Circumventing defenses to adversarial examples,2018, arXiv preprint arXiv:1802
 Decision-based adversarial attacks: Reliableattacks against black-box machine learning models,2017, arXiv preprint arXiv:1712
 Thermometer encoding: One hotway to resist adversarial examples,2018, 2018
 Adversarial examples are not easily detected: Bypassing tendetection methods,2017, In Proceedings of the 10th ACM Workshop on Artificial Intelligence andSecurity
 Towards evaluating the robustness of neural networks,2017, InSecurity and Privacy (SP)
 Riemannianwalk for incremental learning: Understanding forgetting and intransigence,2018, In Proceedings of theEuropean Conference on Computer Vision (ECCV)
 Efficientlifelong learning with a-gem,2018, arXiv preprint arXiv:1812
 Zoo: Zeroth order opti-mization based black-box attacks to deep neural networks without training substitute models,2017, InProceedings of the 10th ACM Workshop on Artificial Intelligence and Security
 Episodicmemory in lifelong language learning,2019, arXiv preprint arXiv:1906
 Stochastic activation pruning for robust adversarial de-fense,2018, arXiv preprint arXiv:1803
 Arotation and a translation suffice: Fooling cnns with simple transformations,2017, arXiv preprintarXiv:1712
 Catastrophic forgetting in connectionist networks,1999, Trends in cognitive sciences
 Explaining and harnessing adversarialexamples,2014, arXiv preprint arXiv:1412
 Countering adversarialimages using input transformations,2018, In International Conference on Learning Representations
 Black-box adversarial attacks withlimited queries and information,2018, arXiv preprint arXiv:1804
 Overcom-ing catastrophic forgetting in neural networks,2017, Proceedings of the national academy of sciences
 Learning multiple layers of features from tiny images,2009, Technical report
 Nattack: Learning the distri-butions of adversarial examples for an improved black-box attack on deep neural networks,2019, arXivpreprint arXiv:1905
 Defense againstadversarial attacks using high-level representation guided denoiser,2018, In Proceedings of the IEEEConference on Computer Vision and Pattern Recognition
 Towards robust neural networksvia random self-ensemble,2018, In European Conference on Computer Vision
 Gradient episodic memory for continual learning,2017, In Advances in NeuralInformation Processing Systems
 Cascade adversarial machine learning reg-ularized with a unified embedding,2018, In International Conference on Learning Representations
 Practical black-box attacks against machine learning,2017, In Proceedings of the 2017 ACMon Asia Conference on Computer and Communications Security
 Deflectingadversarial attacks with pixel deflection,2018, In Proceedings of the IEEE Conference on ComputerVision and Pattern Recognition
 Progressive neural networks,2016, arXiv preprintarXiv:1606
 Evolution strategies as a scalable alterna-tive to reinforcement learning,2017, arXiv preprint arXiv:1703
 Intriguing properties of neural networks,2013, arXiv preprint arXiv:1312
 Lifelong robot learning,1995, Robotics and autonomous systems
 A direct approach to robust deep learning using adversar-ial networks,2019, In International Conference on Learning Representations
 Mitigating adversarialeffects through randomization,2018, In International Conference on Learning Representations
