title,year,conference
  A note on the inception score,2018,  arXiv preprint arXiv:1801
 Deep rewiring: Trainingvery sparse deep networks,2017, arXiv preprint arXiv:1711
  Accurate and conservative estimates of mrflog-likelihood using reverse annealing,2015,  In Artificial Intelligence and Statistics
   Adaptive noise schedule for denoising autoencoder,2014,   InInternational conference on neural information processing
  Residual flows forinvertible generative modeling,2019, arXiv preprint arXiv:1906
  Generative ensembles for robust anomaly detection,2018,  arXiv preprintarXiv:1810
  NICE: non-linear independent components es-timation,2015,  In 3rd International Conference on Learning Representations
 Implicit generation and generalization in energy-based models,2019, arXivpreprint arXiv:1903
  Scheduled denoising autoencoders,2015,  In 3rd InternationalConference on Learning Representations
 Deep residual learning for image recog-nition,2016, In Proceedings of the IEEE conference on computer vision and pattern recognition
   Identity mappings in deep residualnetworks,2016, In European conference on computer vision
 Products of experts,1999, 1999
   Training products of experts by minimizing contrastive divergence,2002,   Neuralcomputation
  Efficient coding of natural images with a population of noisylinear-nonlinear neurons,2011, In Advances in neural information processing systems
 Glow: Generative flow with invertible 1x1 convolutions,2018, InAdvances in Neural Information Processing Systems
 Maximum entropy generatorsfor energy-based models,2019, arXiv preprint arXiv:1901
  A tutorial on energy-basedlearning,2006, Predicting structured data
 Spectral normalization forgenerative adversarial networks,2018,  In 6th International Conference on Learning Representations
 Annealed importance sampling,2001, Statistics and computing
 Mcmc using hamiltonian dynamics,2011, Handbook of markov chain monte carlo
 On the anatomy of mcmc-based maximum likelihood learning of energy-based models,2019,  arXiv preprint arXiv:1903
  Autoregressive quantile networks for generativemodeling,2018,   In Proceedings of the 35th International Conference on Machine Learning
  Nonlinear dimensionality reduction by locally linear embed-ding,2000, science
   On the quantitative analysis of deep belief networks,2008,   InProceedings of the 25th international conference on Machine learning
   Neural empirical bayes,2019,   arXiv preprint arXiv:1903
  Deep energy estimatornetworks,2018, arXiv preprint arXiv:1805
   A  global  geometric  framework  fornonlinear dimensionality reduction,2000, science
  Training restricted boltzmann machines using approximations to the likelihoodgradient,2008, In Proceedings of the 25th international conference on Machine learning
 Scale mixtures of gaussians and the statistics of naturalimages,2000, In Advances in neural information processing systems
   Convolutional  adaptive  denoising  autoencoders  for  hierarchicalfeature extraction,2018, Frontiers of Computer Science
