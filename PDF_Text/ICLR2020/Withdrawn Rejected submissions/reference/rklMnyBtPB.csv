title,year,conference
 Obfuscated gradients give a false sense ofsecurity: Circumventing defenses to adversarial examples,2018, In Proceedings of the 35th InternationalConference on Machine Learning
 Synthesizing robust adversarialexamples,2018, In Jennifer Dy and Andreas Krause (eds
 DeciSion-baSed adverSarial attackS: ReliableattackS againSt black-box machine learning modelS,2017, arXiv preprint arXiv:1712
 Towards evaluating the robustness of neural networks,2017, InSecurity and Privacy (SP)
 Provable robustness against all adversarial lp-perturbations forpâ‰¥1,2019, CoRR
 Boostingadversarial attacks with momentum,2018, In The IEEE Conference on Computer Vision and PatternRecognition (CVPR)
 Efficient projections ontothe l1-ball for learning in high dimensions,2008, In Proceedings of the 25th International Conferenceon Machine Learning
 Evaluating and understanding the robustness ofadversarial logit pairing,2018, arXiv preprint arXiv:1807
 Explaining and harnessing adversarialexamples,2015, In International Conference on Learning Representations
 On the effectiveness ofinterval bound propagation for training verifiably robust models,2018, CoRR
 Identity mappings in deep residualnetworks,2016, In European conference on computer vision
 Adversarial logit pairing,2018, CoRR
 Reluplex: An efficientsmt solver for verifying deep neural networks,2017, arXiv preprint arXiv:1702
 No need to worry about adversarialexamples in object detection in autonomous vehicles,2017, arXiv preprint arXiv:1707
 Differentiable abstract interpretation for provablyrobust neural networks,2018, In International Conference on Machine Learning (ICML)
 Deepfool: a simple andaccurate method to fool deep neural networks,2016, In Proceedings of the IEEE conference on computervision and pattern recognition
 Distillation as adefense to adversarial perturbations against deep neural networks,2016, In Security and Privacy (SP)
 Practical black-box attacks against machine learning,2017, In Proceedings of the 2017 ACM onAsia Conference on Computer and Communications Security
 Certified defenses against adversarialexamples,2018, In International Conference on Learning Representations
 Semidefinite relaxations for cer-tifying robustness to adversarial examples,2018, In S
 Foolbox: A python toolbox to benchmarkthe robustness of machine learning models,2017, arXiv preprint arXiv:1707
 Decoupling direction and norm for efficient gradient-based L2 adversarial attacks anddefenses,2018, CoRR
 Intriguing properties of neural networks,2014, In International Conference on LearningRepresentations
 Evaluating robustness of neural networks with mixedinteger programming,2019, In International Conference on Learning Representations
 Adversarial training and robustness for multiple perturbations,2019, arXivpreprint arXiv:1904
 Provable defenses against adversarial examples via the convex outeradversarial polytope,2018, In International Conference on Machine Learning
 Scaling provable adversarialdefenses,2018, In S
