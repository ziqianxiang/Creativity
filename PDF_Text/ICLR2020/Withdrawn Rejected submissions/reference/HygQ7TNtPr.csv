title,year,conference
 Proxquant: Quantized neural networks via proximaloperators,2018, arXiv preprint arXiv:1810
 Estimating or propagating gradientsthrough stochastic neurons for conditional computation,2013, arXiv preprint arXiv:1308
 Deep learning with low precisionby half-wave gaussian quantization,2017, In Proceedings of the IEEE Conference on Computer Visionand Pattern Recognition
 Pact: Parameterized clipping activation for quantized neuralnetworks,2018, arXiv preprint arXiv:1805
 Imagenet: A large-scale hi-erarchical image database,2009, In 2009 IEEE conference on computer vision and pattern recognition
 Releq: an automatic reinforcement learning approach for deepquantization of neural networks,2018, arXiv preprint arXiv:1811
 Learned step size quantization,2019, arXiv preprint arXiv:1902
 Delving deep into rectifiers: Surpassinghuman-level performance on imagenet classification,2015, In Proceedings of the IEEE internationalconference on computer vision
 Identity mappings in deep residualnetworks,2016, In European conference on computer vision
 Quantization and training of neural networks forefficient integer-arithmetic-only inference,2018, In Proceedings of the IEEE Conference on ComputerVision and Pattern Recognition
 Trained uniform quantizationfor accurate and efficient neural network inference on fixed-point hardware,2019, arXiv preprintarXiv:1903
 Quantizing deep convolutional networks for efficient inference: Awhitepaper,2018, arXiv preprint arXiv:1806
 Continuous control with deep reinforcement learning,2015, arXivpreprint arXiv:1509
 Learn-ing efficient convolutional networks through network slimming,2017, In Proceedings of the IEEEInternational Conference on Computer Vision
 Sgdr: Stochastic gradient descent with warm restarts,2016, arXivpreprint arXiv:1608
 Autoqb: Automl for network quantization andbinarization on mobile devices,2019, arXiv preprint arXiv:1902
 Rethinking generalization requires revisitingold ideas: statistical mechanics approaches and complex learning behavior,2017, arXiv preprintarXiv:1710
 Ternary neural networks with fine-grained quantization,2017, arXiv preprintarXiv:1705
 Apprentice: Using knowledge distillation techniques to improvelow-precision network accuracy,2017, arXiv preprint arXiv:1711
 Wrpn: wide reduced-precisionnetworks,2017, arXiv preprint arXiv:1709
 Speechrecognition using deep neural networks: A systematic review,2019, IEEE Access
 Xnor-net: Imagenetclassification using binary convolutional neural networks,2016, In European Conference on ComputerVision
 Deep informationpropagation,2016, arXiv preprint arXiv:1611
 Statistical mechanics of learn-ing from examples,1992, Physical review A
 Aquantization-friendly separable convolution for mobilenets,2018, In 2018 1st Workshop on EnergyEfficient Machine Learning and Cognitive Computing for Embedded Applications (EMC2)
 Very deep convolutional networks for large-scale imagerecognition,2014, arXiv preprint arXiv:1409
 Differentiable quantization of deep neuralnetworks,2019, arXiv preprint arXiv:1905
 Stochastic processes in physics and chemistry,1992, Elsevier
 Haq: Hardware-aware automated quan-tization with mixed precision,2019, In Proceedings of the IEEE Conference on Computer Vision andPattern Recognition
 Mixedprecision quantization of convnets via differentiable neural architecture search,2018, arXiv preprintarXiv:1812
 Alternating multi-bit quantization for recurrent neural networks,2018, arXiv preprintarXiv:1802
 Mean field residual networks: On the edge of chaos,2017, In Advancesin neural information processing systems
 Amean field theory of batch normalization,2019, arXiv preprint arXiv:1902
 Lq-nets: Learned quantization forhighly accurate and compact deep neural networks,2018, In Proceedings of the European Conferenceon Computer Vision (ECCV)
 Fixup initialization: Residual learning withoutnormalization,2019, arXiv preprint arXiv:1901
 Dorefa-net: Train-ing low bitwidth convolutional neural networks with low bitwidth gradients,2016, arXiv preprintarXiv:1606
 Trained ternary quantization,2016, arXivpreprint arXiv:1612
