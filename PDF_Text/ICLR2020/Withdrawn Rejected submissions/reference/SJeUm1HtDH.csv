title,year,conference
 Learning to pokeby poking: Experiential learning of intuitive physics,2016, NIPS
 Objects that sound,2017, CoRR
 Benchmarking in manipulation research: The ycb object and model set and benchmarkingprotocols,2015, arXiv preprint arXiv:1502
 Multitask learning,1997, Machine learning
 Learning audiofeedback for estimating amount and flow of granular material,2018, In Aude Billard
 A planning framework for non-prehensile manipula-tion under clutter and uncertainty,2012, Autonomous Robots
 Deep visual foresight for planning robot motion,2017, In 2017 IEEEInternational Conference on Robotics and Automation (ICRA)
 Learning to fly by crashing,2017,	CoRR
 Learning latent dynamics for planning from pixels,2018, arXiv preprint arXiv:1811
 Model-based planning with discrete andcontinuous actions,2017, arXiv preprint arXiv:1705
 Category-specific object re-construction from a single image,2015, In Computer Vision and Pattern Regognition (CVPR)
 A unified approach for motion and force control of robot manipulators: TheOPerational space formulation,1987, IEEE J
 Imagenet classification with deep convo-lutional neural networks,2012, In NIPS
 End-to-end training of deep visuo-motor policies,2016, JMLR
 Learning hand-eye coordinationfor robotic grasping with deep learning and large-scale data collection,2016, ISER
 Learning to grasp withoutseeing,2018, CoRR
 A mathematical introduction to robotic manipulation,2017, CRC press
 Visually indicated sounds,2015, CoRR
 Learning to push by grasping: Using multiple tasks for effectivelearning,2016, arXiv preprint arXiv:1609
 The curious robot:Learning visual representations via physical interactions,2016, ECCV
 Multiple paired forward and inverse models for motorcontrol,1998, Neural networks
 Learning to track: Online multi-object tracking bydecision making,2015, In International Conference on Computer Vision (ICCV)
 Environment probing interaction policies,2019, ICLR
