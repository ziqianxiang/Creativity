title,year,conference
 Infinite mixture prototypesfor few-shot learning,2019, arXiv preprint arXiv:1902
 How Children Learn the Meanings of Words,2000, MIT Press
 On the propertiesof neUral machine translation: Encoder-decoder approaches,2014, In Eighth Workshop on Syntax
 Lost in machine translation: A method to redUce mean-ing loss,2019, arXiv preprint arXiv:1902
 From the lexicon to expectations aboUt kinds: a role for asso-ciative learning,2005, Psychological Review
 Imagenet: A large-scale hi-erarchical image database,2009, In 2009 IEEE conference on computer vision and pattern recognition
 Learning indUctive biases with simple neUral networks,2018, InProceedings of the 40th Annual Conference of the Cognitive Science Society (CogSci)
 Combined spokenlangUage translation,2014, In Proc
 Deep convolUtionalnetworks do not classify based on global object shape,2018, PLoS Computational Biology
 Batch Normalization: Accelerating Deep Network Training byRedUcing Internal Covariate Shift,2015, arXiv preprint
 An associative model of adaptive inferencefor learning word-referent mappings,2012, Psychonomic Bulletin and Review
 Adam: A method for stochastic gradient descent,2015, InInternational Conference on Learning Representations (ICLR)
 Compositional generalization throUgh meta seqUence-to-seqUence learning,2019, arXivpreprint
 Generalization withoUt Systematicity: On the CompositionalSkills of SeqUence-to-SeqUence RecUrrent Networks,2018, In International Conference on MachineLearning (ICML)
 HUman-level concept learningthroUgh probabilistic program indUction,2015, Science
 BUildingmachines that learn and think like people,2017, Behavioral and Brain Sciences
 HUman few-shot learning of compositional in-strUctions,2019, In Proceedings of the 41st Annual Conference of the Cognitive Science Society
 The importance of shape in early lexicallearning,1988, Cognitive Development
 Deep learning,2015, Nature
 Achieving open vocabulary neural machine trans-lation with hybrid word-character models,2016, In ACL
 Effective Approaches to Attention-based Neural Machine Translation,2015, In Empirical Methods in Natural Language Processing(EMNLP)
 Rethinking Eliminative Connectionism,1998, Cognitive Psychology
 The Algebraic Mind: Integrating Connectionism and Cognitive Science,2003, MIT Press
 Categorization and Naming in Children,1989, MIT Press
 Childrenâ€™s use of mutual exclusivity to constrain themeanings of words,0010, Cognitive Psychology
 Word learning emerges from the inter-action of online referent selection and slow associative learning,2012, Psychological review
 Meta-Learning with Memory-Augmented Neural Networks,2016, In International Conference on MachineLearning (ICML)
 Infants rapidly learn word-referent mappings via cross-situational statis-tics,2008, Cognition
 Prototypical networks for few-shot learning,2017, InAdvances in Neural Information Processing Systems
 Sequence to Sequence Learning with Neural Net-works,2014, In Advances in Neural Information Processing Systems (NIPS)
