title,year,conference
 Extremely large minibatch SGD: training resnet-50 on imagenet in 15 minutes,2017, CoRR
 Structured pruning of deep convolutional neuralnetworks,2015, CoRR
 Compressingneural networks with the hashing trick,2015, CoRR
 Understanding the difficulty of training deep feedforward neuralnetworks,2010,  In Yee Whye Teh and Mike Titterington (eds
  Second order derivatives for network pruning:  Optimal brainsurgeon,1993,  In S
 Delving deep into rectifiers: Surpassinghuman-level performance on imagenet classification,2015, CoRR
 Deep residual learning for image recog-nition,2015, CoRR
  Orthogonal rnns and long-memory tasks,2016,  CoRR
 MobileNets: Efficient Convolutional Neural Networks forMobile Vision Applications,0004, 2017
  Closnets: Batchless dnn training with on-chip apriori sparse neural topologies,2018, 2018
   Population  based  training  of  neural  networks,2017,   CoRR
  Optimal brain damage,1990,  In D
 Sparse convolu-tional neural networks,2015,  In Proceedings of the IEEE Conference on Computer Vision and PatternRecognition
 Revisiting small batch training for deep neural networks,2018, CoRR
 Online object represen-tations with contrastive learning,2019, CoRR
 Deep expander networks: Efficient deepnetworks from graph theory,2017, CoRR
  Radix-net:  Structured sparse matrices for deep neural net-works,2019, CoRR
  Exact solutions to the nonlinear dynamics oflearning in deep linear neural networks,2013, 12 2013
  Collective dynamics of ’small-world’ networks,1476,  Nature
  Learning structured sparsity indeep neural networks,2016, CoRR
4 and 6,2019,5
