title,year,conference
 On the emergence of invariance and disentangling in deeprepresentations,2017, arXiv preprint arXiv:1706
 Deep speech 2: End-to-end speech recognition in english and mandarin,2016, In International Conference on MachineLearning
 Mirror descent and nonlinear projected subgradient methods forconvex optimization,2003, Operations Research Letters
 A generalization theory of gradient descent for learning over-parameterized deep relu networks,2019, arXiv preprint arXiv:1902
 Gradient descent finds globalminima of deep neural networks,2018, arXiv preprint arXiv:1811
 The robustness of the p-norm algorithms,2003, Machine Learning
 Speech recognition with deep recur-rent neural networks,2013, In 2013 IEEE international conference on acoustics
 General convergence results for lineardiscriminant updates,2001, Machine Learning
 Characterizing implicit bias interms of optimization geometry,2018, In International Conference on Machine Learning
 Implicit bias of gradient descenton linear convolutional networks,2018, arXiv preprint arXiv:1806
 Hoo optimality criteria for LMS and backprop-agation,1994, In Advances in Neural Information Processing Systems 6
 Exponentiated gradient versus gradient descent for linearpredictors,1997, Information and Computation
 Imagenet classification with deep convo-lutional neural networks,2012, In Advances in Neural Information Processing Systems
 Gradient-based learning applied todocument recognition,1998, Proceedings of the IEEE
 Deep learning,2015, Nature
 Gradient descent onlyconverges to minimizers,2016, In Conference on Learning Theory
 Learning overparameterized neural networks via stochastic gradientdescent on structured data,2018, In Advances in Neural Information Processing Systems
 On the implicit bias of dropout,2018, In InternationalConference on Machine Learning
 Human-levelcontrol through deep reinforcement learning,2015, Nature
 Problem complexity and method efficiency inoptimization,1983, 1983
 Geometry of opti-mization and implicit regularization in deep learning,2017, arXiv preprint arXiv:1705
 Overparameterized nonlinear learning: Gradient descenttakes the shortest path? In Proceedings of the 36th International Conference on Machine Learn-ing,2019, PMLR
 Opening the black box of deep neural networks via informa-tion,2017, arXiv preprint arXiv:1703
 Masteringthe game of go with deep neural networks and tree search,2016, Nature
 Theoretical insights into the optimiza-tion landscape of over-parameterized shallow neural networks,2017, arXiv preprint arXiv:1707
 The im-plicit bias of gradient descent on separable data,2017, arXiv preprint arXiv:1710
 The marginalvalue of adaptive gradient methods in machine learning,2017, In Advances in Neural InformationProcessing Systems
 Understandingdeep learning requires rethinking generalization,2016, arXiv preprint arXiv:1611
