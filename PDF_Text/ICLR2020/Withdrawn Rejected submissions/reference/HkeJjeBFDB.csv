title,year,conference
 The effects of adding noise during backpropagation training on a generalizationperformance,1996, Neural computation
 Weight uncertainty inneural networks,2015, arXiv preprint arXiv:1505
 Towards evaluating the robustness of neural networks,2017, In 2017IEEE Symposium on Security and Privacy (SP)
 Certified adversarial robustness via randomizedsmoothing,2019, arXiv preprint arXiv:1902
 Cinic-10 is not imagenetor cifar-10,2018, arXiv preprint arXiv:1810
 Imagenet: A large-scale hi-erarchical image database,2009, In 2009 IEEE conference on computer vision and pattern recognition
 On thesensitivity of adversarial robustness to input data distributions,2019, arXiv preprint arXiv:1902
 Neuroplasticity: changes in grey matter induced by training,2004, Nature
 Noise in the nervous system,2008, Nature reviewsneuroscience
 Dropout as a bayesian approximation: Representing model uncertaintyin deep learning,2015, arxiv
 Explaining and harnessing adversarialexamples,2014, arXiv preprint arXiv:1412
 Practical variational inference for neural networks,2011, In Advances in neural informationprocessing systems
 Using videos to evaluateimage model robustness,2019, arXiv preprint arXiv:1904
 Dropout distillation for efficiently estimating modelconfidence,2018, arXiv preprint arXiv:1809
 Deep self-learning from noisy labels,2019, arXiv preprintarXiv:1908
 Deep residual learning for image recognition,2015, computer visionand pattern recognition (cvpr)
 Benchmarking neural network robustness to common cor-ruptions and perturbations,2019, arXiv preprint arXiv:1903
 Natural adversarialexamples,2019, arXiv preprint arXiv:1907
 Distilling the knowledge in a neural network,2015, arXivpreprint arXiv:1503
 Understanding generalization of deep neural networks trainedwith noisy labels,2019, arXiv preprint arXiv:1905
 A neural network framework forcognitive bias,2018, Frontiers in psychology
 Imagenet classification with deep convo-Iutional neural networks,2012, In Advances in neural information processing systems
 Certifiedrobustness to adversarial examples with differential privacy,2018, arXiv preprint arXiv:1802
 Enhancing the reliability of out-of-distribution image detec-tion in neural networks,2017, arXiv preprint arXiv:1706
 Towards robust neural networks viarandom self-ensemble,2018, In Proceedings of the European Conference on Computer Vision (ECCV)
 A unifying view on dataset shift in classification,2012, Pattern Recognition
 Regularizingneural networks by penalizing confident output distributions,2017, arXiv preprint arXiv:1701
 Theoretical evidence for adversarial robustness through randomization:the case of the exponential family,2019, arXiv preprint arXiv:1902
 Parametric noise injection: Trainable ran-domness to improve deep neural network robustness against adversarial attack,2018, arXiv preprintarXiv:1811
 Trial-to-trial vari-ability in the responses of neurons carries information about stimulus location in the rat whiskerthalamus,2011, ProceedingsoftheNationalAcademyofSciences
 A recurrent network that performs a context-sensitive predictiontask,1996, In Proceedings of the 18th annual conference of the cognitive science society
 Intriguing properties of neural networks,2013, arXiv preprint arXiv:1312
 Rethink-ing the inception architecture for computer vision,2016, In Proceedings of the IEEE conference oncomputer vision and pattern recognition
 Similarity-preserving knowledge distillation,2019, arXiv preprintarXiv:1907
 Regularization of neuralnetworks using dropconnect,2013, In International conference on machine learning
 Symmetric crossentropy for robust learning with noisy labels,2019, arXiv preprint arXiv:1908
 Mitigating adversarialeffects through randomization,2017, arXiv preprint arXiv:1711
 Paying more attention to attention: Improving the perfor-mance of convolutional neural networks via attention transfer,2016, arXiv preprint arXiv:1612
 Wide residual networks,2016, arXiv preprintarXiv:1605
