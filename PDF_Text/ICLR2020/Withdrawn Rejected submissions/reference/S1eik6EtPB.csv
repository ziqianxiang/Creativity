title,year,conference
 Robust neural networks using randomized adversarial training,2019, arXivpreprint arXiv:1903
 Synthesizing robust adversarial examples,2018, InJennifer Dy and Andreas Krause (eds
 Synthesizing robust adversarial examples,2018, ICML
 Obfuscated gradients give a false sense ofsecurity: Circumventing defenses to adversarial examples,2018, arXiv preprint arXiv:1802
 Convex optimization,2004, Cambridge university press
 Towards evaluating the robustness of neural networks,2017, InSecurity and Privacy (SP)
 Audio adversarial examples: Targeted attacks on speech-to-text,2018, In IEEE Symposium on Security and Privacy Workshops
 EAD: elastic-net attacks todeep neural networks via adversarial examples,2018, AAAI
 Provable robustness against all adversarial lp-perturbations forp â‰¥ 1,2019, arXiv preprint arXiv:1905
 Explaining and harnessing adversarialexamples,2015, 2015 ICLR
 Explaining and harnessing adversarialexamples,2014, arXiv preprint arXiv:1412
 Deep residual learning for imagerecognition,2016, In Proceedings of the IEEE conference on computer vision and pattern recognition
 Adversarial attackson neural network policies,2017, In ICLR (Workshop)
 Adversarial examples for evaluating reading comprehension systems,2017, InEMNLP
 Testing robustness againstunforeseen adversaries,2019, arXiv preprint arXiv:1908
 Linear convergence of gradient and proximal-gradient methods under the PoIyak-IojaSieWiCz condition,2016, In Joint European Conference onMachine Learning and Knowledge Discovery in Databases
 Improving adversarial robustness of ensembles Withdiversity training,2019, arXiv preprint arXiv:1901
 Gradient-based learning applied to documentrecognition,0018, Proceedings of the IEEE
 Delving into transferable adversarial examplesand black-box attacks,2017, In ICLR
 Block alternating optimization for non-convex min-max problems:Algorithms and applications in signal processing and communications,2018, 2018
 Block alternating optimization for non-convexmin-max problems: algorithms and applications in signal processing and communications,2019, InProceedings of IEEE International Conference on Acoustics
 Magnet: a tWo-pronged defense against adversarial examples,2017, InProceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security
 Universaladversarial perturbations against semantic image segmentation,2017, In ICCV
 Deepfool: a simple andaccurate method to fool deep neural netWorks,2016, In Proceedings of 2016 IEEE Conference onComputer Vision and Pattern Recognition (CVPR)
 Universaladversarial perturbations,2017, In IEEE Conference on Computer Vision and Pattern Recognition(CVPR)
 Improving adversarial robustness viapromoting ensemble diversity,2019, arXiv preprint arXiv:1901
 Distillation as adefense to adversarial perturbations against deep neural networks,2016, In Security and Privacy (SP)
 Practical black-box attacks against machine learning,2017, In Proceedings of the 2017 ACM onAsia Conference on Computer and Communications Security
 Non-convex min-max optimization: Provable algorithmsand applications in machine learning,2018, arXiv preprint arXiv:1810
 Very deep convolutional networks for large-scale imagerecognition,2015, In ICLR
 Striving forsimplicity: The all convolutional net,2015, In ICLR (Workshop)
 Intriguing properties of neural networks,2013, arXiv preprint arXiv:1312
 Going deeper with convolutions,2015, InCVPR
 Ensemble adversarialtraining: Attacks and defenses,2018, 2018 ICLR
 Adversarial training and robustness for multiple perturbations,2019, arXivpreprint arXiv:1904
 The space oftransferable adversarial examples,2017, arXiv preprint arXiv:1704
 Mitigating adversarial effectsthrough randomization,2017, arXiv preprint arXiv:1711
 Structured adversarial attack: Towards general implementation and betterinterpretability,2019, In International Conference on Learning Representations
 Feature squeezing: Detecting adversarial examples in deepneural networks,2018, In NDSS
 Wide residual networks,2016, In BMVC
