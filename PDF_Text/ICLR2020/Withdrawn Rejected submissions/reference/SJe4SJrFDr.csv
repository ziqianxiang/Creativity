title,year,conference
 Obfuscated gradients give a false sense ofsecurity: Circumventing defenses to adversarial examples,2018, CoRR
 Segnet: A deep convolutional encoder-decoder architecture for image segmentation,2015, IEEE Transactions on Pattern Analysis and MachineIntelligence
 End to end learning for self-driving cars,2016, CoRR
 Thermometer encoding: One hot wayto resist adversarial examples,2018, In International Conference on Learning Representations
 Towards evaluating the robustness of neural networks,2016, CoRR
 Memory bounded deep convolutional networks,2014, CoRR
 Compressing neural networks using the variational informationbottleneck,2018, CoRR
 Arcface: Additive angular margin loss for deep facerecognition,2018, CoRR
 Stochastic activation pruning for robustadversarial defense,2018, In International Conference on Learning Representations
 Evaluating and understanding the robustness ofadversarial logit pairing,2018, arXiv preprint arXiv:1807
 Deepmask: Masking DNN models for robustness againstadversarial samples,2017, CoRR
 Sparse dnns with improved adversarialrobustness,2018, CoRR
 Delving deep into rectifiers: Surpassinghuman-level performance on imagenet classification,2015, CoRR
 Mask r-cnn,2017, 2017 IEEEInternational Conference on Computer Vision (ICCV)
 Using pre-training can improve model robustnessand uncertainty,2019, In International Conference on Machine Learning
 Bridging adversarial robustness and gradientinterpretability,2019, CoRR
 Adam: A method for stochastic optimization,2015, CoRR
 Variational dropout and the local repa-rameterization trick,2015, In C
 Adversarial machine learning at scale,2016, CoRR
 Scaling machinelearning as a service,2017, In Claire Hardgrove
 Adv-BNN: Improved adversarial defensethrough robust bayesian neural network,2019, In International Conference on Learning Representations
 Stick-breaking variational autoencoders,2016, arXiv preprintarXiv:1605
 Structured bayesianpruning via log-normal multiplicative noise,2017, In NIPS
 Distillation as adefense to adversarial perturbations against deep neural networks,2015, CoRR
 Distillation asa defense to adversarial perturbations against deep neural networks,2015, 2016 IEEE Symposium onSecurity and Privacy (SP)
 Practical black-box attacks against deep learning systems using adversarialexamples,2016, CoRR
 Chexnet: Radiologist-level pneumonia detection on chest x-rays with deep learning,2017, ArXiv
 Adver-sarially robust generalization requires more data,2018, In S
 Mastering the game of go withdeep neural networks and tree search,2016, Nature
 Mastering the game ofgo without human knowledge,2017, Nature
 Very deep convolutional networks for large-scale imagerecognition,2015, CoRR
 Intriguing properties of neural networks,2013, CoRR
 Ro-bustness may be at odds with accuracy,2019, In International Conference on Learning Representations
	Learning struc-tured sparsity in deep neural networks,2016, In D
 Provable defenses against adversarial examples via the convex outeradversarial polytope,2018, In ICML
 Mitigating adversarial effectsthrough randomization,2018, In International Conference on Learning Representations
 Feature squeezing: Detecting adversarial examples indeep neural networks,2017, CoRR
 Feature squeezing: Detecting adversarial examples indeep neural networks,2017, CoRR
