Table 1: Results on Permuted- and Split-MNIST. Baseline results are taken from Nguyen et al. (2017). Forthe experiments conducted in this work we show the mean and standard deviation over 10 random repetitions.
Table 2: Results on sequential Omniglot. Baseline results are taken from Schwarz et al. (2018). Shown aremean and standard deviation over 5 random task permutations. Note that methods ‘Single model per Task’ and‘Progressive Nets’ are not directly comparable due to unrealistic assumptions, but serve as an upper bound on theperformance for the remaining continual learning methods.
Table 3: Task boundary detection evaluatedas a binary classification task (Positive labelscorresponds to task switches).
Table 4: Hyperparameters for the experiments on Split MNIST. Optimal values (in bold) were chosen on thevalidation set. Test set results were obtained by training on the union of training&validation set using thosevalues.
Table 5: Hyperparameters for the experiments on Permuted MNIST. Optimal values (in bold) were chosen onthe validation set. Test set results were obtained by training on the union of training&validation set using thosevalues.
Table 6: Hyperparameters for the experiments on Omniglot. Optimal values (in bold) were chosen on thevalidation set. Test set results were obtained by training on the union of training&validation set using thosevalues.
Table 7: Results on sequential Omniglot using a MLP.
