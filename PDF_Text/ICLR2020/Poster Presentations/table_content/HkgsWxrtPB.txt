Table 1: (Playground) The subtask graphs in D1 have the same graph structure as training set, but the graphwas unseen. The subtask graphs in D2, D3, and D4 have (unseen) larger graph structures. (Mining) The subtaskgraphs in Eval are unseen during training.
Table 2: The range from which the subtask reward of serve subtask was sampled, in the AI2-THOR environment.
Table 3: Summary of hyper-parameters used for MSGI-Meta, RL2, and HRL agents.
Table 4: The range of hyper-parameters we searched over. We did beam-search to find the best parameter withthe priority of η, λ, β, βent, (dflat, dgru), LR-decay.
