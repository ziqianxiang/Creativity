Table 1: MNIST, CIFAR10 and tiny-ImageNet untargeted attack comparison: Meta attacker attains compara-ble success rate and L2 distortion as baselines, and significantly reduces query numbers.
Table 2: MNIST, CIFAR10 and tiny-ImageNet targeted attack comparison: Meta attack significantly outper-forms other black-box methods in query numbers.
Table 3: Cosine similarity between estimated gradients and white-box gradients.
Table 4: MNIST untargeted attaCk Comparison.
Table 5: MNIST targeted attaCk Comparison.
Table 6: Structure of meta attacker. Conv: convolutional layer, Convt: de-convolutional layer.
Table 7:	NeUraI network architecture Used on MNIST.
Table 8:	Accuracy of each target model on each datasetDataSet ∣ MNIST ∣ CIFAR10 ∣ tiny-ImageNetModel I MNIST Model ∣ Resnet18 ∣ VGG19 ∣ Resnet34Accuracy ∣	0.9911	∣	0.9501	∣ 0.6481 ∣	0.69726.5 Adversarial Examples Generated by Our Method13Published as a conference paper at ICLR 2020Target class0123456789C7l23q56 39 9©12345 6 C* 夕 O/燧IN 3q53。3 9Ols3q54 qs 9◎ 1G 3 q 5 4 r* S 9。\2>4569，O/⅞J>l23q56 Γ*s 30∖23q56。夕 0/43123 q 6 6 o<s>qCl23q56。夕彳Figure 4: Adversarial examples generated by our method on MNIST. The groundtruth images are
