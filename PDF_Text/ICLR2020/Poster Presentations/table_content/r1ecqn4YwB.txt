Table 1: Performance on the M4, M3, tourism test sets, aggregated over each dataset. Evaluationmetrics are specified for each dataset; lower values are better. The number of time series in eachdataset is provided in brackets.
Table 2: Composition of the M4 dataset: the number of time series based on their sampling frequencyand type.
Table 3: Composition of the M3 dataset: the number of time series based on their sampling frequencyand type.
Table 4: Composition of the tourism dataset: the number of time series based on their samplingfrequency.
Table 5: smape on the validation set, generic ar-chitecture. smape for varying number of stacks,each having one residual block.
Table 6: smape on the validation set, inter-pretable architecture. Ablation of the synergyof the layers with different basis functions andmulti-block stack gain.
Table 7: Performance on the M4 test set, smape. Lower values are better. The results are obtained onthe ensemble of 18 generic models.
Table 8: Performance on the M4 test set, smape. Lower values are better. The results are obtained onthe ensemble of 18 interpretable models.
Table 9: Performance on the M4 test set, owa. Lower values are better. The results are obtained onthe ensemble of 18 generic models.
Table 10: Performance on the M4 test set, owa. Lower values are better. The results are obtained onthe ensemble of 18 interpretable models.
Table 11: Performance on the M4 test set, sMAPE. Lower values are better. Red - second best.
Table 12: Performance on the M4 test set, OWA and M4 rank. Lower values are better. Red - secondbest.
Table 13: Performance decomposition on non-overlapping subsets of the M4 test set and comparisonwith the Smyl model results.
Table 14: Performance on the M3 test set, Average smape, aggregate over all forecast horizons(Yearly: 1-6, Quarterly: 1-8, Monthly: 1-18, Other: 1-8, Average: 1-18). Lower values are better.
Table 15: Performance on the tourism test set, Average mape, aggregate over all forecast horizons(Yearly: 1-4, QUarterly: 1-8, Monthly: 1-24, Average: 1-24). Lower values are better. Red - secondbest.
Table 16: ND Performance on the electricity and traffic test sets.
Table 17: ND Performance of DeepAR, Deep State Space, and N-BEATS models on M4-Hourly andtourism datasets	M4 (Hourly)	tourism (Monthly)	tourism (Quarterly)DeepAR	0.09	0.107	0.11DeepState	0.044	0.138	0.098N-BEATS-G (ours)	0.023	0.097	0.080N-BEATS-I (ours)	0.027	0.103	0.079N-BEATS-I+G (ours)	0.025	0.099	0.07725Published as a conference paper at ICLR 2020Table 18: Settings of hyperparameters across subsets of M4, M3, tourism datasets.
Table 18: Settings of hyperparameters across subsets of M4, M3, tourism datasets.
Table 19: Detailed traces of signals depicted in row 1 of Fig. 5, corresponding to the time seriesYearly: id Y3974.
Table 20: Detailed traces of signals depicted in row 2 of Fig. 5, corresponding to the time seriesQuarterly: id Q11588.
Table 21: Detailed traces of signals depicted in row 3 of Fig. 5, corresponding to the time seriesMonthly: id M19006.
Table 22: Detailed traces of signals depicted in row 4 of Fig. 5, corresponding to the time seriesWeekly: id W246.
Table 23: Detailed traces of signals depicted in row 5 of Fig. 5, corresponding to the time seriesDaily: id D404.
Table 24: Detailed traces of signals depicted in row 6 of Fig. 5, corresponding to the time seriesHourly: id H344.
