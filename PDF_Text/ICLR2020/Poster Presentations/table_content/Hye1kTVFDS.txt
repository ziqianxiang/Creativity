Table 1: Running Expensive Model BasedPlannerthe output of the planner. We find that most of thetimes agent access the privileged information (outputof model based planner) near the junctions as shown in Table 1.
Table 2: Generalization of the agent to larger grids in RoomNXSY envs and FindObj envs. Successof an agent is measured by the fraction of episodes where the agent was able to navigate to the goalin 500 steps. Results are averaged over 500 examples, and 5 different random seeds.
Table 3: Goal Driven Navigation - Percentage oftime steps on which each method acsess the goal in-formation when the agent is near the junction point(or branching points in the maze. We show that theproposed method learns to access the privilegedinput (in this case, the goal) only when necessary.
Table 4: Multiagent communication: The VBB performs better, as compared to the baselines. Inthe baseline scenario, all of the agents communicate with all the other agents all the time. Averagedover 5 random seeds.
Table 5: The VBB performs better, as compared to the baselines. The VBB transmits a similarnumber of bits, while accessing privileged information a fraction of the time (in brackets % of timesaccess to privileged information). Using REINFORCE to learn the parameter of the Bernoulli, doesnot perform as well as the proposed method.
Table 6:	Classification error results (Mnih et al., 2014). Averaged over 3 random seeds.
Table 7:	Shared parameters for benchmark tasksK Architectural DetailsFor our work, we made sure to keep the architecture detail as similar to the baseline as possible.
