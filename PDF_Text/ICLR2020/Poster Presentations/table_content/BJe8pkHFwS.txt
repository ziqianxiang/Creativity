Table 1: Dataset statistics (“m” stands for multi-class classification, and “s” for single-class.)Dataset	Nodes	Edges	Degree	Feature	Classes	Train / Val / TestPPI	14,755	225,270	^^15^^	50	121 (m)	0.66 / 0.12 / 0.22Flickr	89,250	899,756	10	500	7 (s)	0.50 / 0.25 / 0.25Reddit	232,965	11,606,919	50	602	41 (s)	0.66 / 0.10 / 0.24Yelp	716,847	6,977,410	10	300	100 (m)	0.75 / 0.10 / 0.15Amazon	1,598,960	132,169,734	83	200	107 (m)	0.85 / 0.05 / 0.10PPI (large version)	56,944	818,716	~~14^^	50	121 (m)	0.79 / 0.11 / 0.10We open source GraphSAINTr We compare with six baselines: 1. vanilla GCN (KiPf & Welling,2016), 2. GraphSAGE (Hamilton et al., 2017), 3. FastGCN (Chen et al., 2018b), 4. S-GCN (Chenet al., 2018a), 5. AS-GCN (Huang et al., 2018), and 6. ClusterGCN (Chiang et al., 2019). Allbaselines are executed with their officially released code (see Appendix C.3 for downloadable URLsand commit numbers). Baselines and GraphSAINT are all implemented in Tensorflow with Python3.
Table 2: Comparison of test set F1-micro score with state-of-the-art methodsMethod	PPI	Flickr	Reddit	Yelp	AmazonGCN	0.515±0.006	0.492±0.003	0.933±0.000	0.378±0.001	0.281±0.005GraphSAGE	0.637±0.006	0.501±0.013	0.953±0.001	0.634±0.006	0.758±0.002FastGCN	0.513±0.032	0.504±0.001	0.924±0.001	0.265±0.053	0.174±0.021S-GCN	0.963±0.010	0.482±0.003	0.964±0.001	0.640±0.002	AS-GCN	0.687±0.012	0.504±0.002	0.958±0.001		ClusterGCN	0.875±0.004	0.481±0.005	0.954±0.001	0.609±0.005	0.759±0.008GraphSAINT-Node	0.960±0.001	0.507±0.001	0.962±0.001	0.641±0.000	0.782±0.004GraphSAINT-Edge	0.981±0.007	0.510±0.002	0.966±0.001	0.653±0.003	0.807±0.001GraphSAINT-RW	0.981±0.004	0.511±0.001	0.966±0.001	0.653±0.003	0.815±0.001GraphSAINT-MRW	0.980±0.006	0.510±0.001	0.964±0.000	0.652±0.001	0.809±0.001Table 3: Additional comparison with ClusterGCN (test set F1-micro score)	PPI (large version)	Reddit 2 X 512	5 X 2048	2 X 128	4 X 128ClusterGCN GraphSAINT	0.903±0.002 0.994±0.000 0.954±0.001	0.966±0.001 0.941±0.003	0.995±0.000 0.966±0.001	0.970±0.001^Open sourced code: https://github.com/GraphSAINT/GraphSAINT^The codes throw runtime error on the large datasets (Yelp or Amazon).
Table 3: Additional comparison with ClusterGCN (test set F1-micro score)	PPI (large version)	Reddit 2 X 512	5 X 2048	2 X 128	4 X 128ClusterGCN GraphSAINT	0.903±0.002 0.994±0.000 0.954±0.001	0.966±0.001 0.941±0.003	0.995±0.000 0.966±0.001	0.970±0.001^Open sourced code: https://github.com/GraphSAINT/GraphSAINT^The codes throw runtime error on the large datasets (Yelp or Amazon).
Table 4: URLs and commit number to run baseline codesBaseline	URL	CommitVanilla GCN	github.com/williamleif/GraphSAGE	a0fdefGraphSAGE	github.com/williamleif/GraphSAGE	a0fdefFastGCN	github.com/matenure/FastGCN	b8e6e6S-GCN	github.com/thu-ml/stochastic_gcn	da7b78AS-GCN	github.com/huangwb/AS-GCN	5436ecClusterGCN	github.com/google- research/google- research/tree/master/cluster_gcn	99021eTable 5: Training configuration of GraphSAINT for Table 2Sampler	Dataset	Training		Sampling					Learning rate	Dropout	Node budget	Edge budget	Roots	Walk length	PPI	0.01	0.0	6000	—	—	—Node	Flickr	0.01	0.2	8000	—	—	—	Reddit	0.01	0.1	8000	—	—	—	Yelp	0.01	0.1	5000	—	—	—	Amazon	0.01	0.1	4500	—	—	—	PPI	0.01	0.1	—	4000	—	—Edge	Flickr	0.01	0.2	—	6000	—	—	Reddit	0.01	0.1	—	6000	—	—	Yelp	0.01	0.1	—	2500	—	—
Table 5: Training configuration of GraphSAINT for Table 2Sampler	Dataset	Training		Sampling					Learning rate	Dropout	Node budget	Edge budget	Roots	Walk length	PPI	0.01	0.0	6000	—	—	—Node	Flickr	0.01	0.2	8000	—	—	—	Reddit	0.01	0.1	8000	—	—	—	Yelp	0.01	0.1	5000	—	—	—	Amazon	0.01	0.1	4500	—	—	—	PPI	0.01	0.1	—	4000	—	—Edge	Flickr	0.01	0.2	—	6000	—	—	Reddit	0.01	0.1	—	6000	—	—	Yelp	0.01	0.1	—	2500	—	—	Amazon	0.01	0.1	—	2000	—	—	PPI	0.01	0.1	—	—	3000	2RW	Flickr	0.01	0.2	—	—	6000	2	Reddit	0.01	0.1	—	—	2000	4	Yelp	0.01	0.1	—	—	1250	2	Amazon	0.01	0.1	—	—	1500	2	PPI	0.01	0.1	8000	—	2500	—MRW	Flickr	0.01	0.2	12000	—	3000	—
Table 6: Training configuration of GraphSAINT for Table 3Arch.	Sampler	Dataset	Training			Sampling				Learning rate	Dropout	Node budget	Edge budget Roots	Walk length2 × 512	MRW	PPI (large)	0.01	0.1	1500	—	300	—5 × 2048	RW	PPI (large)	0.01	0.1	—	—	3000	22 × 128	Edge	Reddit	0.01	0.1	—	6000	—	—4× 128	Edge	Reddit	0.01	0.2	—	11000	—	—Table 7: Training configuration of GraphSAINT for Figure 4 (Reddit)	2-layer GAT-SAINT	4-layer GAT-SAINT	2-layer JK-SAINT	4-layer JK-SAINTHidden dimension	128	128	128	128Attention K	8	8	—	—Aggregation L	—	—	Concat.	Concat.
Table 7: Training configuration of GraphSAINT for Figure 4 (Reddit)	2-layer GAT-SAINT	4-layer GAT-SAINT	2-layer JK-SAINT	4-layer JK-SAINTHidden dimension	128	128	128	128Attention K	8	8	—	—Aggregation L	—	—	Concat.	Concat.
Table 8: Per epoch training time breakdown for AS-GCNDataset	Sampling time (sec)	Forward / Backward propagation time (sec)PPI	1.1	0.2Flickr	5.3	1.1Reddit	20.7	3.5Cost of clustering of ClusterGCN ClUsterGCN uses the highly optimized METIS SoftWare计 toperform clustering. Table 9 summarizes the time to obtain the clusters for the five graphs. On thelarge and dense Amazon graph, the cost of clustering increase dramatically. The pre-processingtime of ClusterGCN on Amazon is more than 4× of the total training time. On the other hand, thesampling cost of GraphSAINT does not increase significantly for large graphs (see Figure 7).
Table 9: Clustering time of ClusterGCN	PPI	Flickr	Reddit	Yelp	AmazonTime (sec)	2.2	11.6	40.0	106.7	2254.2Taking into account the pre-processing time, sampling time and training time altogether, We sum-marize the total convergence time of GraphSAINT and ClusterGCN in Table 10 (corresponding toTable 2 configuration). On graphs that are large and dense (e.g., Amazon), GraphSAINT achievessignificantly faster convergence. Note that both the sampling of GraphSAINT and clustering ofClusterGCN can be performed offline.
Table 10: Comparison of total convergence time (pre-processing + sampling + training, unit: second)	PPI	Flickr	Reddit	Yelp	AmazonGraphSAINT-Edge	91.0	7.0	16.6	273.9	401.0GraphSAINT-RW	103.6	7.5	17.2	310.1	425.6ClusterGCN	163.2	12.9	55.3	256.0	2804.8D.3 Effect of Batch SizeTable 11 shoWs the change of test set accuracy With batch sizes. For each roW of Table 11, We fix thebatch size, tune the other hyperparameters according to Appendix C.3, and report the highest test setaccuracy achieved. For GraphSAGE, S-GCN and AS-GCN, their default batch sizes (512,1000 and512, respectively) lead to the highest accuracy on all datasets. For FastGCN, increasing the defaultbatch size (from 400 to 4000) leads to noticeable accuracy improvement. For ClusterGCN, differentdatasets correspond to different optimal batch sizes. Note that the accuracy in Section 5.1 is alreadytuned by identifying the optimal batch size on a per graph basis.
Table 11: Test set F1-micro for the baselines under various batch sizesMethod	Batch size	PPI	Flickr	Reddit	Yelp	Amazon	256	0.600	0.474	0.934	0.563	0.428GraphSAGE	512*	0.637	0.501	0.953	0.634	0.758	1024	0.610	0.482	0.935	0.632	0.705	2048	0.625	0.374	0.936	0.563	0.447	400*	0.513	0.504	0.924	0.265	0.174FastGCN	2000	0.561	0.506	0.934	0.255	0.196	4000	0.564	0.507	0.934	0.260	0.195	500	0.519	0.462	—1		^^—	1000*	0.963	0.482	0.964	0.640	S-GCN	2000	0.646	0.482	0.949	0.614	」	4000	0.804	0.482	0.949	0.594		8000	0.694	0.481	0.950	0.613	,	256	0.682	0.504	0.950		—AS-GCN	512*	0.687	0.504	0.958	,	二	1024	0.687	0.502	0.951			2048	0.670	0.502	0.952	,	二	500	0.875	0.481	0.942	0.604	0.752	1000	0.831	0.478	0.947	0.602	0.756
