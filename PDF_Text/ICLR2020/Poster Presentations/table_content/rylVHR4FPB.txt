Table 1: Comparison of performance of BQNs against the baseline E-QNN. Each E-QNN is anensemble of 10 networks, which are trained individually and but make predictions jointly. We reportboth NLL (which accounts for prediction uncertainty) and 0-1 test error (which doesn’t account forprediction uncertainty). All the numbers are averages over 10 runs with different seeds, the standarddeviation are exhibited following the ± sign.
Table 2: Deterministic model compression through direct training of QNN (Courbariaux et al.,2016) v.s. MAP estimation in our proposed BQN. All the numbers are averages over 10 runs withdifferent seeds, the standard deviation are exhibited following the ± sign.
Table 3: Bayesian Model compression through direct training of Ensemble-QNN vs a Monte-Carlosampling on our proposed BQN. Each ensemble consists of 5 quantized neural networks, and forfair comparison we use 5 samples for Monte-Carlo evaluation. All the numbers are averages over10 runs with different seeds, the standard deviation are exhibited following the ± sign.
Table 4: Performance of different networks in terms of RMSE. The numbers for BQN are averagesover 10 runs with different seeds, the standard deviation are exhibited following the ± sign. Theresults for PBP, EBP are from Ghosh et al. (2016), and the one for NPN is from (Wang et al., 2016).
