Table 1: Experiment In : Out domainsTarget		OOD	CIFAR-10	SVHN	LSUN	TinyImageNetTinyImageNet	SVHN	CIFAR-10	CIFAR-100LSUN	SVHN	CIFAR-10	CIFAR-100CelebA	SVHN	CIFAR-10	CIFAR-100loss against the corresponding target network on each dataset.
Table 2: OOD detection results (TNR at 95% TPR) on CIFAR-10, TinyImageNet, LSUN, and CelebAdatasets. See Table 1 for OODs used in each case.
Table 3: Classification performance of fine-tuned classifier over the activation map trained bySVD-RND, RND, and randomly initialized weights. SVD-RND consistently outperforms RND.
Table 4: Performance of uniform SVD-RND and optimized SVD-RNDTarget: CIFAR-10, OOD: SVHN/LSUN/TinyImageNet. Target: TinyImageNet (TIMG), OOD: SVHN/CIFAR-10/CIFAR-100Dataset/btrain	AUROC	TNR(95% TPR)	Detection accuracy	AUPR in	AUPR outCIFAR-10/3 (uniform)	0.967/0.961/0.961	0.944/0.827/0.836	0.962/0.904/0.904	0.843/0.966/0.962	0.989/0.949/0.953CIFAR-10/4 (uniform)	0.964/0.987/0.988	0.941/0.954/0.959	0.958/0.957/0.961	0.848/0.989/0.989	0.987/0.983/0.985CIFAR-10/1 (optimized)	0.981/0.985/0.982	0.969/0.956/0.952	0.980/0.955/0.953	0.903/0.987/0.983	0.993/0.975/0.976TIMG/3 (uniform)	0.993/0.831/0.814	0.999/0.745/0.701	0.989/0.855/0.832	0.991/0.741/0.725	0.995/0.878/0.864TIMG/4 (uniform)	0.984/0.939/0.923	0.954/0.880/0.842	0.976/0.927/0.908	0.982/0.915/0.894	0.989/0.938/0.928TIMG/2 (optimized)	0.983/0.969/0.960	0.991/0.926/0.911	0.980/0.963/0.953	0.978/0.965/0.951	0.989/0.958/0.9535.1	Representation learning in SVD-RNDWhile SVD-RND outperforms RND on every In : Out domains in Section 4, we provide furtherevidence that SVD-RND learns superior target distribution representation compared to RND. For theevidence, we fine-tune a classifier over the fixed activation map of SVD-RND and RND. We set theactivation map as the output of the first 15 or 27 layers of RND and SVD-RND predictor networktrained in CIFAR-10 datasets. For the fine-tuning, we either appended three residual blocks and alinear output layer with softmax activation (denoted as 7-layer in Table 3) or a linear layer (denotedas linear in Table 3). Then, we fine-tune the appended network for the CIFAR-10 classification task.
Table 5: OOD detection performance of SVD-ROT-RND and SVD-VER-RNDMethod	Target: CelebA, OOD: SVHN/CIFAR-10/CIFAR-100				AUPR out	AUROC	TNR(95 % TPR)	Detection accuracy	AUPR in	SVD-ROT-RND	0.997/0.996/0.996	0.999/0.993/0.994	0.996/0.991/0.991	0.998/0.998/0.998	0.993/0.986/0.988SVD-VER-RND	0.999/0.993/0.994	0.999/0.982/0.982	0.998/0.982/0.981	0.999/0.997/0.997	0.998/0.984/0.986SVD-RND	0.999/0.963/0.964	0.999/0.897/0.897	0.998/0.928/0.928	0.999/0.981/0.981	0.998/0.941/0.943ROT-RND	0.974/0.979/0.982	0.950/0.937/0.945	0.964/0.952/0.956	0.950/0.989/0.991	0.981/0.964/0.969VER-RND	0.964/0.961/0.964	0.930/0.887/0.897	0.952/0.923/0.926	0.934/0.979/0.980	0.975/0.941/0.9465.3 Further improvement of SVD-RNDWhile SVD-RND achieves reasonable OOD detection performance, combining SVD-RND with otherbaseline algorithms may further enhance the performance. For example, as shown in Table 2, trainingagainst rotated data benefits OOD detection in CelebA dataset. Therefore, we combine SVD-RNDand geometric transform-based methods to further improve SVD-RND. We treat both blurred dataand geometrically transformed data as OOD and train the predictor network to discriminate theoriginal data from the OOD. We combine rotation and vertical translation with SVD-RND and denotethem as SVD-ROT-RND and SVD-VER-RND, respectively.
Table 6: OOD detection results on CIFAR-10, TinyImageNet, LSUN, and CelebA datasetsTarget: CIFAR-10, OOD: SVHN/LSUN/TinyImageNetMethod	AUROC	TNR(95% TPR)	Detection accuracy	AUPR in	AUPR outSVD-RND (proposed)	0.981/0.985/0.982	0.969/0.956/0.952	0.980/0.955/0.953	0.903/0.987/0.983	0.993/0.975/0.976DCT-RND (proposed)	0.944/0.948/0.925	0.899/0.797/0.748	0.940/0.883/0.861	0.769/0.945/0.909	0.981/0.946/0.930GB-RND (proposed)	0.624/0.952/0.923	0.474/0.803/0.739	0.722/0.887/0.858	0.311/0.950/0.908	0.860/0.952/0.928RND	0.211/0.941/0.923	0.008/0.762/0.736	0.500/0.873/0.857	0.180/0.937/0.908	0.560/0.943/0.931GPND	0.230/0.941/0.895	0.050/0.767/0.665	0.513/0.876/0.828	0.190/0.936/0.872	0.605/0.941/0.905Flip	0.490/0.616/0.607	0.057/0.091/0.081	0.534/0.601/0.599	0.281/0.663/0.656	0.707/0.564/0.553Rotate	0.853/0.777/0.824	0.235/0.246/0.308	0.826/0.714/0.755	0.735/0.806/0.840	0.911/0.719/0.773Vertical Translation	0.276/0.924/0.896	0.105/0.649/0.648	0.540/0.849/0.823	0.193/0.923/0.881	0.654/0.919/0.899Horizontal Translation	0.279/0.917/0.890	0.070/0.675/0.630	0.523/0.844/0.818	0.193/0.915/0.874	0.637/0.905/0.889Vertical Shear	0.331/0.937/0.909	0.077/0.744/0.684	0.520/0.869/0.839	0.205/0.936/0.896	0.663/0.927/0.905Horizontal Shear	0.503/0.929/0.902	0.227/0.720/0.672	0.590/0.860/0.834	0.261/0.925/0.886	0.781/0.928/0.908Contrast	0.659/0.859/0.829	0.468/0.000/0.002	0.725/0.815/0.785	0.331/0.885/0.842	0.859/0.746/0.721Invert	0.611/0.911/0.900	0.473/0.614/0.622	0.712/0.849/0.841	0.303/0.919/0.897	0.848/0.871/0.870Typicality Test	0.411/0.929/0.905	0.008/0.734/0.691	0.501/0.861/0.841	0.258/0.917/0.880	0.632/0.933/0.916Target: TinyImageNet, OOD: SVHN/CIFAR-10/CIFAR-100Method	AUROC	TNR(95% TPR)	Detection accuracy	AUPR in	AUPR outSVD-RND (proposed)	0.983/0.969/0.960	0.99170.926/0.911	0.980/0.963/0.953	0.978/0.965/0.951	0.989/0.958/0.953
Table 7: Test uncertainty of RND on OOD CIFAR-10 data generated by adding orthogonal noise tothe CIFAR-10 dataData	Original	Blurred	ɑ “ 5	α “ 10	α “ 15	α “ 20Average UnCertainty(X lθ´5)	5.631	5.190	5.648	5.795	6.051	6.437Finally, for typicality test, we estimated the average test loss of the RND for 50000 training examples.
