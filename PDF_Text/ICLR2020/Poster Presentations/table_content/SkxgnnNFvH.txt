Table 1: Datasets used in this PaPer.
Table 2: Validation performance on ConvAI2 after fine-tuning a Bi-encoder pre-trained with BERT,averaged over 5 runs. The batch size is the number of training negatives + 1 as we use the otherelements of the batch as negatives during training.
Table 3: Validation performance (R@1/20) on ConvAI2 using pre-trained weights of BERT-basewith different parameters fine-tuned. Average over 5 runs (Bi-encoders) or 3 runs (Cross-encoders).
Table 4: Test performance of Bi-, Poly- and Cross-encoders on our selected tasks.
Table 5: Average time in milliseconds to predict the next dialogue utterance from C possible candi-dates on ConvAI2. * are inferred.
Table 6: Training time in hours.
Table 7: Bi-encoder results on the ConvAI2 valid set for different choices of function red(âˆ™).
Table 8: Validation and test performance of Poly-encoder variants, with weights initialized from(Devlin et al., 2019). Scores are shown for ConvAI2 and DSTC 7 Track 1. Bold numbers indicatethe highest performing variant within that number of codes.
Table 9: Average time in milliseconds to predict the next dialogue utterance from N possible candi-dates. * are inferred.
Table 10: Validation and test performances of Bi-, Poly- and Cross-encoders. Scores are shown forConvAI2, DSTC7 Track 1 and Ubuntu v2, and the previous state-of-the-art models in the literature.
