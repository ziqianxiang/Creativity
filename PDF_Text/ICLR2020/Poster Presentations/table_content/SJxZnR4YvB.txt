Table 1: Summary of baseline approaches and our resultsT steps can be simulated by a single-agent bandit algorithm running for MT time steps, the regret ofany protocol is lower bounded by the optimal regret of a single-agent algorithm running for MT timesteps. Therefore, we consider O( MKT) regret for multi-armed bandits and O(d MT) regret forlinear bandits to be near-optimal.
