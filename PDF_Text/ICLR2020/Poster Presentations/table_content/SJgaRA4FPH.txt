Table 1: ML modeler tasks typically accomplished via data inspection. In Section 2.1 we observe thatselection criteria can be applied programmatically to train generative models able to address these tasks.
Table 2: Top 10 generated OOV words by joint characterprobability (computed using Equation 1), with and withoutthe bug. Number accompanying is joint probability. Themodel is trained with case-insensitive tokenization.
Table 3: Privacy parameters for different scenarios. N is size of user subpopulation that meets selectioncriteria (not overall population size). Simulations are with overall population of 3,400, and realistic scenariosare with overall population of 2,000,000. All experiments use clip parameter S of 0.1 and 1,000 rounds.
Table 4: Number of users and sentences in the Stack Overflow dataset.
Table 5: Privacy hyperparameters for DP RNN experiments.
Table 6: Overall OOV rate observed (during training) in different word-LM experiment settings.
Table 7: Sample phrases generated from word-LMs when 0%, 1%, 10%, and 100% of sentences affected.
Table 8: Top 20 char-LM-generated OOV words by joint character probability, for 0% (without bug), 1%,10%, and 100% of examples affected by bug. Value alongside is joint probability (computed via Equation 1).
Table 9: DP federated GAN experimental hyperparameters.
Table 10: User accuracy percentiles (without bug).
Table 11: Subpopulation sizes for simulations in Section 6. Total population size is 3,400 user devices.
Table 12: Subpopulation sizes for filter ‘by example’ simulations, when excluding a user’s participation insubpopulation if containing < 5 examples of classification result. Total population size is 3,400 users.
Table 13: Privacy parameters for different filter ‘by example’ (T2) scenarios. N is size of user subpopulationthat meets selection criteria (not overall population size). Simulations are with overall population of 3,400,and realistic scenarios are with overall population of 2,000,000. All experiments use clip parameter S of 0.1and 1,000 rounds.
