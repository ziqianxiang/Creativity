Table 1: The search space size of network quantization. QBN âˆˆ [0, 32], where 0 means the com-Ponent is pruned. niayer is the layer number of the network.
Table 2: The comparison OfDRL-based techniques for quantization and pruning.
Table 3: Network Quantization by AutoQ (A-QBN: the average QBN of activations; W-QBN: theaverage QBN of weights; LAT: inference latency).
