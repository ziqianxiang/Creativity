Table S1:	γ-Net architecture for contour detection in BSDS natural images. For comparison, theBDCN, which is the state of the art on BSDS, contains ≈16.3M parameters. When training on anNVIDIA GeForce RTX, this γ-Nettakes 1.8 seconds per image, whereas the BDCN takes 0.1 secondsper image. “Down” refers to down-sampling layers; “up” refers to up-sampling layers, and “readout”maps model activities into per-pixel decisions. Kernels are described as kernel-height × kernel-width/ stride size. All convolutional layers except for the Readout use non-linearities. All non-linearitiesin this network are linear rectifications. Model predictions come from the fGRU hidden state forconv-2-down, which are resized to match the input image resolution and passed to the linear per-pixelreadout.
Table S2:	γ-Netarchitecture for cell membrane detection in SEM images. A 2D version of theU-Net of Lee et al. (2017), which is the state of the art on SNEMI3D, contains ≈600K parameters.
Table S3:	SEM image volumes used in membrane prediction. SNEMI3D images and annotationsare publicly available (Kasthuri et al., 2015), whereas the Ding dataset is a volume from (Ding et al.,2016) that we annotated.
