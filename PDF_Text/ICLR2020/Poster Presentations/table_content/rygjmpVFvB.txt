Table 1: Comparison of the semi-supervised learning in our DSGAN and the state-of-the-art methods.
Table 2: Training times of our method and badGAN. We only report the training time on MNIST, onWhich the authors of badGAN applied PixelCNN++. The experiments run on a NVIDIA 1080 Ti.
Table 3: Comparison of our method (VAE+DSGAN) and the state-of-the-art methods: VAE Kingma& Welling (2014a), AND Abati et al. (2019), DSVDD Ruff et al. (2018), and OCGAN Perera et al.
Table 4: Semi-supervised learning results on MNIST with and without the use of sampling tricks.
Table 5: Hyperparameters in semi-supervised learning.
Table 6: Network architectures for semi-supervised learning on MNIST. (GN: Gaussian noise)Generator G	Discriminator D	Classifier CInput: z ∈ R100 from unif(0, 1)	Input: 250 dimension feature	Input: 28 × 28 gray image100 × 500 FC layer with BN Softplus 500 × 500 FC layer with BN Softplus 500 × 784 FC layer with WN Sigmoid	250 × 400 FC layer ReLU 400 × 200 FC layer ReLU 200 × 100 FC layer ReLU 100 × 1 FC layer	GN, std = 0.3 784 × 1000 FC layer with WN ,ReLU GN, std = 0.5 1000 × 500 FC layer with WN, ReLU GN, std = 0.5 500 × 250 FC layer with WN, ReLU GN, std = 0.5 250 × 250 FC layer with WN, ReLU GN, std = 0.5 250 × 250 FC layer with WN, ReLU		250 × 10 FC layer with WNFurthermore, the training procedure alternates between k steps of optimizing D and one step ofoptimizing G. We find that k in Algorithm 1 is a key role in the problem of mode collapse fordifferent applications. For semi-supervised learning, we set k = 1 for all datasets.
Table 7: The architectures of generator and discriminator for semi-supervised learning on SVHN andCIFAR-10. N was set to 128 and 192 for SVHN and CIFAR-10, respectively.
Table 8: The architecture of classifiers for semi-supervised learning on SVHN and CIFAR-10. (GN:Gaussian noise; lReLU(leak rate): LeakyReLU(leak rate))Classifier C for SVHN	Classifier C for CIFAR-10	Input: 32 × 32 RGB image	Input: 32 × 32 RGB imageGN, std = 0.05Dropout2d, dropping rate = 0.153 × 3 conv. 64 stride = 1 with WN, lReLU(0.2)3 × 3 conv. 64 stride = 1 with WN, lReLU(0.2)3 × 3 conv. 64 stride = 2 with WN, lReLU(0.2)Dropout2d, dropping rate = 0.53 ×	3 conv.	128 stride	=	1	with WN,	lReLU(0.2)3 ×	3 conv.	128 stride	=	1	with WN,	lReLU(0.2)3 ×	3 conv.	128 stride	=	2	with WN,	lReLU(0.2)Dropout2d, dropping rate = 0.53 ×	3 conv.	128 stride	=	1	with WN,	lReLU(0.2)1 ×	1 conv.	128 stride	=	1	with WN,	lReLU(0.2)1 ×	1 conv.	128 stride	=	1	with WN,	lReLU(0.2)Global average PoolingGN, std = 0.05Dropout2d, dropping rate = 0.2
Table 9: The architectures of generator and discriminator in DSGAN for novelty detection.
Table 10: The architectures of VAE for novelty detection.
Table 11: Ablation study of different α values for DSGAN in semi-supervised learning, where theresult for MNIST is represented in terms of number of errors and the percentage of errors was usedfor other datasets.
Table 12: FIDs of GAN and DSGAN on CelebA. Smaller FID means that the generated distributionis closer to the distribution of images with glasses.
