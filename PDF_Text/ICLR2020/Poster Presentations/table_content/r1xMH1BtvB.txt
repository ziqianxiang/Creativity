Table 1: Comparison of small models on the GLUE dev set. BERT-Small/Base are our implemen-tation and use the same hyperparameters as ELECTRA-Small/Base. Infer FLOPs assumes singlelength-128 input. Training times should be taken with a grain of salt as they are for different hard-ware and with sometimes un-optimized code. ELECTRA performs well even when trained on asingle GPU, scoring 5 GLUE points higher than a comparable BERT model and even outscoring themuch larger GPT model.
Table 2: Comparison of large models on the GLUE dev set. ELECTRA and RoBERTa are shownfor different numbers of pre-training steps, indicated by the numbers after the dashes. ELECTRAperforms comparably to XLNet and RoBERTa when using less than 1/4 of their pre-training computeand outperforms them when given a similar amount of pre-training compute. BERT dev results arefrom Clark et al. (2019).
Table 3: GLUE test-set results for large models. Models in this table incorporate additional trickssuch as ensembling to improve scores (see Appendix B for details). Some models do not haveQNLI scores because they treat QNLI as a ranking task, which has recently been disallowed by theGLUE benchmark. To compare against these models, we report the average score excluding QNLI(Avg.*) in addition to the GLUE leaderboard score (Score). “ELECTRA” and “RoBERTa” refer tothe fully-trained ELECTRA-1.75M and RoBERTa-500K models.
Table 4: Results on the SQuAD for non-ensemble models.
Table 5: Compute-efficiency experiments (see text for details).
Table 6: Pre-train hyperparameters. We also train an ELECTRA-Large model for 1.75M steps (otherhyperparameters are identical).
Table 7: Fine-tune hyperparameters•	For WNLI, we follow the trick described in Liu et al. (2019) where we extract candidateantecedents for the pronoun using rules and train a model to score the correct antecedenthighly. However, different from Liu et al. (2019), the scoring function is not based on MLMprobabilities. Instead, we fine-tune ELECTRA’s discriminator so it assigns high scores tothe tokens of the correct antecedent when the correct antecedent replaces the pronoun. Forexample, if the Winograd schema is “the trophy could not fit in the suitcase because it wastoo big,” we train the discriminator so it gives a high score to “trophy” in “the trophy couldnot fit in the suitcase because the trophy was too big” but a low score to “suitcase” in “thetrophy could not fit in the suitcase because the suitcase was too big.”•	For each task we ensemble the best 10 of 30 models fine-tuned with different random seedsbut initialized from the same pre-trained checkpoint.
Table 8: Results for models on the GLUE test set. Only models with single-task finetuning (noensembling, task-specific tricks, etc.) are shown.
