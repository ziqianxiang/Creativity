Table 1: Experiments on synthetic datasets. Under standard benchmark settings, AE-OT achievesbest performances over an average of 10 independent experiment results in terms of modes captured,probability of high quality samples and reverse KL divergence. The mean values and standarddeviations of the experiment results are reported here.
Table 2: Quantitative comparison with FID	Adversarial				Non-Adversarial		Reference	Dataset	NS GAN	LSGAN	WGAN	BEGAN	VAE	GLANN	AE	OursMNIST	6.8±0.5	7.8±0.6	6.7±0.4	13.1±1.0	23.8±0.6	8.6±0.1	5.5	6.2±0.2Fansion	26.5±1.6	30.7±2.2	21.5±1.6	22.9±0.9	58.7±1.2	13.0±0.1	4.7	10.1±0.3CIFAR-10	58.5±1.9	87.1 ±47.5	55.2±2.3	71.4±1.6	65.4±0.2	46.5±0.2	28.2	38.3±0.5CelebA	55.0±3.3	53.9±2.8	41.3±2.0	38.9±0.9	85.7±3.8	46.3±0.1	67.5	68.4± 0.5state-of-the-art generative models. Theoretically, the FID scores of our proposed generative modelsshould be close to that of the pre-trained autoencoders, and this is also validated in our experiments.
Table 3: EnCoder architecture for StaCk MNISTlayer	number of outputs	kernel size	stride	BN	activationInput X 〜Pdata	28*28*3				Convolution	14*14*16	5*5	2		LeakyReLUConvolution	7*7*32	5*5	2	Yes	LeakyReLUConvolution	4*4*64	5*5	2	Yes	LeakyReLUConvolution	2*2*128	5*5	2	Yes	LeakyReLUFully connected	100				architecture same as the consistent generator architectures in GANs, and encoder having mirroredarchitecture.
Table 4: Decoder architecture for Stack MNISTlayer	number of outputs	kernel size	stride	BN	activationInput Z 〜PIatent	100				Fully connected	2*2*128			Yes	ReLUTransposed Convolution	4*4*64	5*5	2	Yes	ReLUTransposed Convolution	7*7*32	5*5	2	Yes	ReLUTransposed Convolution	14*14*16	5*5	2	Yes	ReLUTransposed Convolution	28*28*3	5*5	2		TanhTable 5: Experiments on stacked MNIST. Results have shown that our method achieves best resultsin termS of mode captured and reverSe KL divergence. (*) In WGAN, PacWGAN and AE-OTexperiments, number of feature maps in each network layer is a quarter of those in other experiments.
Table 5: Experiments on stacked MNIST. Results have shown that our method achieves best resultsin termS of mode captured and reverSe KL divergence. (*) In WGAN, PacWGAN and AE-OTexperiments, number of feature maps in each network layer is a quarter of those in other experiments.
Table 6: Probability of identical images in a batch of 1024 generated images from DCGAN, PacGAN2and AE-OT. Results have shown that our method achives best result in terms of collision probabilityon CelebA dataset._______________________________________________________________Discriminator size (Decoder size)	Probability of collision			DCGAN	PaCDCGAN2	AE-OT273K	1	0.33	04×273K	0.42	0	016×273K	0.86	0	025×273K	0.65	0.17	0Table 7: Encoder architecture in CelebA experimentlayer	number of outputs	kernel size	stride	BN	activationInput X 〜Pdata	64*64*3				Convolution	32*32*dim_f	4*4	2		LeakyReLUConvolution	16*16*dim_f*2	4*4	2	Yes	LeakyReLUConvolution	8*8*dim_f*4	4*4	2	Yes	LeakyReLUConvolution	4*4*dim_f*8	4*4	2	Yes	LeakyReLUConvolution	100	4*4	1		Table 8: Decoder architecture in CelebA experimentlayer	number of outputs	kernel size	stride	BN	activationInput Z 〜Platent	"Ig0				
Table 7: Encoder architecture in CelebA experimentlayer	number of outputs	kernel size	stride	BN	activationInput X 〜Pdata	64*64*3				Convolution	32*32*dim_f	4*4	2		LeakyReLUConvolution	16*16*dim_f*2	4*4	2	Yes	LeakyReLUConvolution	8*8*dim_f*4	4*4	2	Yes	LeakyReLUConvolution	4*4*dim_f*8	4*4	2	Yes	LeakyReLUConvolution	100	4*4	1		Table 8: Decoder architecture in CelebA experimentlayer	number of outputs	kernel size	stride	BN	activationInput Z 〜Platent	"Ig0				Transposed Convolution	4*4*dim_f*8				Transposed Convolution	8*8*dim_f*4	4*4	2	Yes	ReLUTransposed Convolution	16*16*dim_f*2	4*4	2	Yes	ReLUTransposed Convolution	32*32*dim_f	4*4	2	Yes	ReLUTransposed Convolution	64*64*3	4*4	2		Tanh17Published as a conference paper at ICLR 2020Figure 7: The generated human faces with the architecture originated from DCGAN Radford et al.
Table 8: Decoder architecture in CelebA experimentlayer	number of outputs	kernel size	stride	BN	activationInput Z 〜Platent	"Ig0				Transposed Convolution	4*4*dim_f*8				Transposed Convolution	8*8*dim_f*4	4*4	2	Yes	ReLUTransposed Convolution	16*16*dim_f*2	4*4	2	Yes	ReLUTransposed Convolution	32*32*dim_f	4*4	2	Yes	ReLUTransposed Convolution	64*64*3	4*4	2		Tanh17Published as a conference paper at ICLR 2020Figure 7: The generated human faces with the architecture originated from DCGAN Radford et al.
