title,year,conference
 Scalable methods for 8-bit training ofneural networks,2018, In Advances in Neural Information Processing Systems
 Mixed precision training of convolutional neural networks using integer operations,2018, arXivpreprint arXiv:1802
 Imagenet: A large-scale hi-erarchical image database,2009, In 2009 IEEE conference on computer vision and pattern recognition
 A survey on methods and theories of quantized neural networks,2018,	CoRR
 Deep learning withlimited numerical precision,2015, In International Conference on Machine Learning
 The movielens datasets: History and context,2016, Acmtransactions on interactive intelligent systems (tiis)
 Identity mappings in deep residualnetworks,2016, In European conference on computer vision
 Rethinking floating point for deep learning,2018, CoRR
 A study of bfloat16 for deep learning training,2019, arXiv preprint arXiv:1905
 Adam: A method for stochastic optimization,2014, arXiv preprintarXiv:1412
 Flexpoint: An adaptive numerical format forefficient training of deep neural networks,2017, In Advances in neural information processing systems
 Imagenet classification with deep convo-Iutional neural networks,2012, In Advances in neural information processing Systems
 Gradient-based learning appliedto document recognition,1998, Proceedings of the IEEE
 Stanford neural machine translation systems forspoken language domain,2015, In International Workshop on Spoken Language Translation
 An introduction to different rounding algorithms,2006, Programmable Logic DesignLine
 Mixed precision train-ing with 8-bit floating point,2019, arXiv preprint arXiv:1905
 Mixedprecision training,2018, In International Conference on Learning Representations
 Bleu: A method for automaticevaluation of machine translation,2002, In Proceedings of the 40th Annual Meeting on Association forComputational Linguistics
 Attention is all you need,2017, In Advances in neural informationprocessing systems
 Tensor2tensor for neural machine translation,2018,	CoRR
 Train-ing deep neural networks with 8-bit floating point numbers,2018, In Advances in neural informationprocessing systems
 Training and inference with integers in deepneural networks,2018, arXiv preprint arXiv:1802
 Dorefa-net: Train-ing low bitwidth convolutional neural networks with low bitwidth gradients,2016, arXiv preprintarXiv:1606
