title,year,conference
 Auxiliary image regularizationfor deep cnns with noisy labels,2015, arXiv preprint arXiv:1511
 Classification in the presence of label noise: a survey,2013, IEEEtransactions on neural networks and learning Systems
 Shake-shake regularization,2017, arXiv preprint arXiv:1705
 Training deep neural-networks using a noise adaptationlayer,2016, 2016
 Co-teaching: Robust training of deep neural networks with extremely noisy labels,2018, InNeurIPS
 Deep bilevel learning,2018, In ECCV
 MentorNet: Learning Data-Driven Curriculum for Very Deep Neural Networks on Corrupted Labels,1712, arXiv:1712
 Temporal ensembling for semi-supervised learning,2016, arXiv preprintarXiv:1610
 Sgdr: Stochastic gradient descent with warm restarts,2016, arXivpreprint arXiv:1608
 Smooth neighbors on teacher graphsfor semi-supervised learning,2018, In Proceedings of the IEEE Conference on Computer Vision andPattern Recognition
 Dimensionality-driven learning with noisy labels,2018, arXivpreprint arXiv:1806
 Anomaly detection withmultiple-hypotheses predictions,2019, In Kamalika Chaudhuri and Ruslan Salakhutdinov (eds
 DeepUsps: Deep robUst UnsUpervised saliency predic-tion via self-sUpervision,2019, In Advances in Neural Information Processing Systems
 AUtomatic differentiation inpytorch,2017, 2017
 Training deep neUral networks on noisy labels with bootstrapping,2014, arXiv preprintarXiv:1412
 Deep learning is robUst to massivelabel noise,2017, arXiv preprint arXiv:1705
 On the importance ofinitialization and momentUm in deep learning,2013, ICML (3)
 Joint optimization frame-work for learning with noisy labels,2018, In Proceedings of the IEEE Conference on Computer Visionand Pattern Recognition
 Mean teachers are better role models: Weight-averaged consis-tency targets improve semi-sUpervised deep learning resUlts,2017, In Advances in neural informationprocessing systems
 Combating label noise in deep learning Using abstention,2019, arXiv preprint arXiv:1905
 Symmetric cross en-tropy for robUst learning with noisy labels,2019, In Proceedings of the IEEE International Conferenceon Computer Vision
 Aggregated residual trans-formations for deep neUral networks,2017, In Proceedings of the IEEE Conference on Computer Visionand Pattern Recognition
 Generalized cross entropy loss for training deep neural netWorksWith noisy labels,2018, In Advances in Neural Information Processing Systems
