title,year,conference
 Deep learning with differential privacy,2016, In Proceedings of the 2016 ACM SIGSACConference on Computer and Communications Security
 Stronger generalization bounds for deepnets via a compression approach,2018, In Jennifer G
 Reconciling modern machine-learningpractice and the classical bias-variance trade-off,0027, Proceedings of the National Academy ofSciences
 Stability and generalization,1532, J
 CircUit-based intrinsic methods to detect overfitting,2019, CoRR
 Theloss sUrfaces of mUltilayer networks,2015, In GUy Lebanon and S
 Sharp minima can generalize fordeep nets,2017, CoRR
 Stiffness: A new perspective ongeneralization in neural networks,2019, CoRR
 Flat minima,1997, Neural COmPut
 On large-batch training for deeP learning: Generalization gaP and sharP minima,2016, CoRR
 What size neural network gives oPtimalgeneralization? convergence ProPerties of backProPagation,1996, Technical rePort
 Bad global minima exist andSGD can reach them,2019, CoRR
 Uniform convergence may be unable to exPlain general-ization in deeP learning,2019, In Hanna M
 SGD on neural networks learns functions of increasing comPlexity,2019, CoRR
 Towardsunderstanding the role of over-Parametrization in generalization of neural networks,2018, CoRR
 On the sPectral bias of neural networks,2019, In Kamalika Chaudhuriand Ruslan Salakhutdinov (eds
 DeeP learning is robust to massivelabel noise,2017, CoRR
 TheimPact of neural network overParameterization on gradient confusion and stochastic gradientdescent,2019, CoRR
 In S,2018, Bengio
 Understandingdeep learning requires rethinking generalization,2017, In Proceedings of the International Conferenceon Learning Representations ICLR
 The global optimizationgeometry of shallow linear neural networks,2018, CoRR
