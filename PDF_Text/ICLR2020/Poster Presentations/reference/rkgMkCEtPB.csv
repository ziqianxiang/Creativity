title,year,conference
 Few-shot text classification withdistributional signatures,2019, arXiv preprint arXiv:1908
 Meta-learning with differen-tiable closed-form solvers,2018, arXiv preprint arXiv:1805
 A closer lookat few-shot classification,2019, arXiv preprint arXiv:1904
 Meta-learning and universality: Deep representations and gradientdescent can approximate any learning algorithm,2017, arXiv preprint arXiv:1710
 Probabilistic model-agnostic meta-learning,2018, InAdvances in Neural Information Processing Systems
 Meta-Learning probabilistic inference for prediction,2018, arXiv preprint arXiv:1805
 Recasting gradient-based meta-learning as hierarchical bayes,2018, arXiv preprint arXiv:1801
 Meta-learning priors for efficient onlinebayesian regression,2018, arXiv preprint arXiv:1807
 Unsupervised learning via meta-learning,2018, arXiv preprintarXiv:1810
 Meta-learning representations for continual learning,2019, arXivpreprint arXiv:1905
 Siamese neural networks for one-shotimage recognition,2015, In ICML Deep Learning Workshop
 Similarity of neuralnetwork representations revisited,2019, arXiv preprint arXiv:1905
 Meta-learning withdifferentiable convex optimization,2019, In Proceedings of the IEEE Conference on Computer Visionand Pattern Recognition
 Gradient-based meta-learning with learned layerwise metric andsubspace,2018, arXiv preprint arXiv:1801
 Insights on representational similarity in neuralnetworks with canonical correlation,2018, arXiv preprint arXiv:1806
 Reptile: A scalable metalearning algorithm,2018, arXiv preprintarXiv:1803
 SVCCA: Singular vectorcanonical correlation analysis for deep learning dynamics and interpretability,2017, In Advances inNeural Information Processing Systems
 Transfusion: Understandingtransfer learning with applications to medical imaging,2019, arXiv preprint arXiv:1902
 Optimization as a model for few-shot learning,2016, 2016
 Meta-learning with latent embedding optimization,2018, arXiv preprintarXiv:1807
 Meta-learning with memory-augmented neural networks,2016, In International Conference on MachineLearning
 Prototypical networks for few-shot learning,2017, InAdvances in Neural Information Processing Systems
 Meta-Dataset: A datasetof datasets for learning to learn from few examples,2019, arXiv preprint arXiv:1903
 Matching Networks for oneshot learning,2016, In Advances in neural information processing systems
 To whatextent do different neural networks learn the same representation: A Neuron Activation SubspaceMatch Approach,2018, In NeurIPS 2018
 Fastcontext adaptation via meta-learning,2018, arXiv preprint arXiv:1810
7x as fast as MAML,2020, This leads to a significant overalltraining speedup
