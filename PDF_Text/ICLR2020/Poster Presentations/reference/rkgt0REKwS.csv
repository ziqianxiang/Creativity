title,year,conference
 A closer lookat memorization in deep networks,2017, In ICML
 Curriculum learning,2009, InICML
 Training deep neural-networks using a noise adaptationlayer,2017, In ICLR
 Co-teaching: Robust training of deep neural networks with extremely noisy labels,2018, InAdvances in Neural Information Processing Systems
 Mentornet: Learning data-driven curriculum for very deep neural networks on corrupted labels,2018, 2018
 Learning from noisy singly-labeleddata,2018, ICLR
 Self-paced learning for latent variablemodels,2010, In Advances in Neural Information Processing Systems
 Robust inference viagenerative classifiers for handling noisy labels,2019, In International Conference on Machine Learning
 Virtual adversarial training for semi-supervisedtext classification,2016, In ICLR
 L1 and l2 regularization for multiclass hinge loss models,2011, InSymposium on Machine Learning in Speech and Language Processing
 Makingdeep neural networks robust to label noise: A loss correction approach,2017, In Proceedings of theIEEE Conference on Computer Vision and Pattern Recognition 
 Trainingconvolutional networks with noisy labels,2014, arXiv preprint arXiv:1406
 Joint optimization frame-work for learning with noisy labels,2018, In Proceedings of the IEEE Conference on Computer Visionand Pattern Recognition
 Learning with symmetric labelnoise: The importance of being unhinged,2015, In Advances in Neural Information Processing Systems
 Understandingdeep learning requires rethinking generalization,2017, ICLR
 Generalized cross entropy loss for training deep neural networkswith noisy labels,2018, In Advances in neural information processing systems
