title,year,conference
 Stochastic learning,2003, In Summer School on Machine Learning
 Bagging predictors,1996, Machine Learning
 Massive exploration of neuralmachine translation architectures,2017, CoRR
 Model compression,2006, In KDD
 Efficientlifelong learning with A-GEM,2018, ArXiv
 The comparison and evaluation of forecasters,1983, 1983
 ImageNet: A large-scalehierarchical image database,2009, In CVPR 2009
 Ensemble methods in machine learning,2000, In Multiple Classifier Systems
 Analyzing the role of model uncertainty for electronic healthrecords,2019, arXiv preprint arXiv:1906
 Deep ensembles: A loss landscape perspec-tive,2019, ArXiv
 Catastrophic forgetting in connectionist networks,1999, Trends in Cognitive Sciences
 Dropout as a Bayesian Approximation: Representing ModelUncertainty in Deep Learning,2015, In ICML
 Escaping from saddle pointsâ€”online stochasticgradient for tensor decomposition,2015, In Conference on Learning Theory
 Deep learning,2015, Nature
 On calibration of modern neuralnetworks,2017, In ICML
 Evaluating scalable Bayesian deeplearning methods for robust computer vision,2019, ArXiv
 Deep residual learning for imagerecognition,2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)
 Benchmarking neural network robustness to commoncorruptions and perturbations,2019, In International Conference on Learning Representations
 Bayesian learning for neural networks,1995, 1995
 Deep networks withstochastic depth,2016, In ECCV
 Batch Normalization: Accelerating deep network training byreducing internal covariate shift,2015, In ICML
 Deep learning without poor local minima,2016, In Advances in neural informationprocessing Systems
 Adam: A method for stochastic optimization,2014, arXiv preprintarXiv:1412
 Overcoming catastrophicforgetting in neural networks,2016, Proceedings of the National Academy of Sciences of the UnitedStates of America
 Learning multiple layers of features from tiny images,2009, 2009
 Temporal ensembling for semi-supervised learning,2017, CoRR
 Simple and scalable predictiveuncertainty estimation using deep ensembles,2017, In NIPS
 Gradient episodic memory for continuum learning,2017, InNIPS
 SGDR: Stochastic gradient descent with restarts,2016, CoRR
 Catastrophic interference in connectionist networks: The sequential learningproblem,1989, 1989
 K for theprice of 1: Parameter-efficient multi-task and transfer learning,2018, ArXiv
 FiLM: Visualreasoning with a general conditioning layer,2017, In AAAI
 When networks disagree: Ensemble methods for hybridneural networks,1992, 1992
 iCaRL:Incremental classifier and representation learning,2016, 2017 IEEE Conference on Computer Vision andPattern Recognition (CVPR)
 Deep Bayesian bandits showdown,2018, 2018
 Experiencereplay for continual learning,2018, ArXiv
 FitNets: Hints for thin deep nets,2015, CoRR
 Progressive neural networks,2016, ArXiv
 No more pesky learning rate guessing games,2015, CoRR
 Highway networks,2015, CoRR
 Lifelong learning algorithms,1998, In Learning to Learn
 Attention is all yoU need,2017, In NIPS
 An emPiricalanalysis of droPoUt in Piecewise linear networks,2014, CoRR
 Horizontal and vertical ensemble with deeP rePresentationfor classification,2013, CoRR
 Lifelong learning with dynamicallyexPandable networks,2017, ArXiv
 Incremental self-imProvement for life-time mUlti-agentreinforcement learning,1996, 1996
 Eachconsists of a training set of size 50K and a test set of size 10K,2015, They are natural images with32x32 pixels
 WMT16 English-German dataset consists of roughly 4,2017,5Msentence pairs
