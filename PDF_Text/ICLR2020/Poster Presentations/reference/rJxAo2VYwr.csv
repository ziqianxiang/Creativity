title,year,conference
 Towards evaluating the robustness of neural networks,2017, InIEEE Symposium on Security and Privacy
 Improving black-box adversarialattacks with a transfer-based prior,2019, CoRR
 Imagenet: A large-scalehierarchical image database,2009, In CVPR
 Boost-ing adversarial attacks with momentum,2018, In CVPR
 Analyzing and improving representa-tions with the soft nearest neighbor loss,2019, In ICML
 Explaining and harnessing adversarialexamples,2015, In ICLR
 Deep residual learning for image recog-nition,2016, In CVPR
 Densely connectedconvolutional networks,2017, In CVPR
 Feature space perturbations yield moretransferable adversarial examples,2019, In CVPR
 Adversarial machine learning at scale,2017, InICLR
 Adversarial attacks anddefences competition,2018, arXiv
 Defensive quantization: When efficiency meets robustness,2019, InICLR
 Delving into transferable adversarial exam-ples and black-box attacks,2017, In ICLR
 In ICLR,2018, OpenReview
 Deepfool: A simple andaccurate method to fool deep neural networks,2016, In CVPR
 Simple black-box adversarial attacks on deepneural networks,2017, In CVPR Workshops
 Transferability in machine learning:from phenomena to black-box attacks using adversarial samples,2016, arXiv
 Adversarial manipulation of deeprepresentations,2016, In ICLR
 Very deep convolutional networks for large-scale imagerecognition,2015, In ICLR
 Smooth-grad: removing noise by adding noise,2017, arXiv
 One pixel attack for fooling deepneural networks,2017, arXiv
 Intriguing properties of neural networks,2014, In ICLR
 Thespace of transferable adversarial examples,2017, arXiv
 Ensemble adversarial training: Attacks and defenses,2018, In ICLR
 Feature denoisingfor improving adversarial robustness,2019, In CVPR
 Visualizing and understanding convolutional networks,2014, InECCV (1)
