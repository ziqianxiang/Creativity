title,year,conference
 Un-certainty estimation via stochastic batch normalization,2019, In International Symposium on NeuralNetworks
 Bayesian dark knowl-edge,2015, In Advances in Neural Information Processing Systems
 Weight uncertainty inneural networks,2015, arXiv preprint arXiv:1505
 Sample-efficient reinforcement learning with stochastic ensemble value expansion,2018, In Advances in NeuralInformation Processing Systems
 Deep reinforcement learn-ing in a handful of trials using probabilistic dynamics models,2018, In Advances in Neural InformationProcessing Systems
 Accelerating montecarlo bayesian inference via approximating predictive uncertainty over simplex,2019, arXiv preprintarXiv:1905
 Uncertainty in deep learning,2016, PhD thesis
 Dropout as a bayesian approximation: Representing modeluncertainty in deep learning,2016, In international conference on machine learning
 Evaluating scalable bayesian deeplearning methods for robust computer vision,2019, arXiv preprint arXiv:1906
 Distilling the knowledge in a neural network,2015, arXivpreprint arXiv:1503
 Batch normalization: Accelerating deep network training byreducing internal covariate shift,2015, arXiv preprint arXiv:1502
 Variational dropout and the local reparameteri-Zation trick,2015, In Advances in Neural Information Processing Systems
 Verified uncertainty calibration,2019, In Advances inNeural Information Processing Systems
 Simple and scalable predictiveuncertainty estimation using deep ensembles,2017, In Advances in Neural Information ProcessingSystems
 Asimple baseline for bayesian uncertainty in deep learning,2019, arXiv preprint arXiv:1902
 Predictive uncertainty estimation via prior networks,2018, In Advancesin Neural Information Processing Systems
 Optimizing neural networks with kronecker-factored approximatecurvature,2015, In International conference on machine learning
 Inhibited Softmax for uncertainty estima-tion in neural networks,2018, arXiv preprint arXiv:1810
 Measuringcalibration in deep learning,2019, 2019
 Automatic differentiation inPyTorch,2017, In NIPS Autodiff Workshop
 Evaluating predictive uncertainty challenge,2005, In Machine Learning ChallengesWorkshop
 A scalable laplace approximation for neuralnetworks,2018, 2018
 Very deep convolutional networks for large-scale imagerecognition,2014, arXiv preprint arXiv:1409
 HoWto train deep variational autoencoders and probabilistic ladder networks,2016, In 33rd InternationalConference on Machine Learning (ICML 2016)
 Intriguing properties of neural netWorks,2013, arXiv preprint arXiv:1312
 Going deeper With convolutions,2015, InProceedings of the IEEE conference on computer vision and pattern recognition
 Bayesian uncertainty estimation for batch nor-malized deep netWorks,2018, In International Conference on Machine Learning (ICML)
 Neural netWork ensembles andvariational inference revisited,2018, In 1st Symposium on Advances in Approximate Bayesian Inference
 Hydra: Preservingensemble diversity for model distillation,2020, arXiv preprint arXiv:2001
 Soft Weight-sharing for neural netWork compres-sion,2017, arXiv preprint arXiv:1702
 Evaluating model calibration in classification,2019, arXiv preprintarXiv:1902
 Adversar-ial distillation of bayesian neural netWork posteriors,2018, In International Conference on MachineLearning
 Fast dropout training,2013, In international conference on machinelearning
 Wide residual networks,2016, arXiv preprintarXiv:1605
 mixup: Beyond empiricalrisk minimization,2017, arXiv preprint arXiv:1710
 Cyclicalstochastic gradient mcmc for bayesian deep learning,2019, arXiv preprint arXiv:1902
