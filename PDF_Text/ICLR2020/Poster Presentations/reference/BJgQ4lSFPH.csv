title,year,conference
 The fifth pascal recognizingtextual entailment challenge,2009, In TAC
 A large annotatedcorpus for learning natural language inference,2015, arXiv preprint arXiv:1508
 Neural sentence ordering,2016, arXiv preprintarXiv:1607
 Bert: Pre-training of deepbidirectional transformers for language understanding,2018, arXiv preprint arXiv:1810
 Finding structure in time,1990, Cognitive science
 A comparison ofneural models for word ordering,2017, arXiv preprint arXiv:1708
 Long short-term memory,1997, Neural computation
 SPanbert:ImProving Pre-training by rePresenting and Predicting sPans,2019, arXiv preprint arXiv:1907
 The winograd schema challenge,2012, InThirteenth International Conference on the Principles of Knowledge Representation and Reasoning
 Multi-task deeP neural networks fornatural language understanding,2019, arXiv preprint arXiv:1901
 RoBERTa: A robustly oPtimized BERT PretrainingaPProach,2019, arXiv preprint arXiv:1907
 Learned in translation:Contextualized word vectors,2017, In Advances in Neural Information Processing Systems
 Recurrentneural network based language model,2010, In Eleventh annual conference of the international speechcommunication association
 Deep contextualized word representations,2018, arXiv preprint arXiv:1802
 Sentence encoders on stilts: Supplementarytraining on intermediate labeled-data tasks,2018, arXiv preprint arXiv:1811
 Building applied natural language generation systems,1997, NaturalLanguage Engineering
 Word ordering without syntax,2016, arXivpreprint arXiv:1604
 Attention is all you need,2017, In Advances in neural informationprocessing systems
 Glue:A multi-task benchmark and analysis platform for natural language understanding,2018, arXiv preprintarXiv:1804
 A broad-coverage challenge corpus forsentence understanding through inference,2017, arXiv preprint arXiv:1704
 Xlnet: Generalized autoregressive pretraining for language understanding,2019, arXiv preprintarXiv:1906
 Qanet: Combining local convolution with global self-attention for readingcomprehension,2018, arXiv preprint arXiv:1804
 Aligning books and movies: Towards story-like visual explanations by watchingmovies and reading books,2015, In Proceedings of the IEEE international conference on computervision
