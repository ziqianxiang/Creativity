title,year,conference
 Obfuscated gradients give a false senseof security: Circumventing defenses to adversarial examples,2018, In International Conference onMachine Learning
 Evasion attacks against machine learning at test time,2013, In Joint Europeanconference on machine learning and knowledge discovery in databases
 Adversarial examples are not easily detected: Bypassing tendetection methods,2017, In Proceedings of the 10th ACM Workshop on Artificial Intelligence andSecurity
 Towards evaluating the robustness of neural networks,2017, In 2017IEEE Symposium on Security and Privacy (SP)
 ImageNet: A large-scalehierarchical image database,2009, In IEEE Conference on Computer Vision and Pattern Recognition
 Detecting adversarialsamples from artifacts,2017, arXiv preprint arXiv:1703
 Motivating therules of the game for adversarial example research,2018, arXiv preprint arXiv:1807
 Adversarial spheres,2018, In International Conference on Learning Representations
 Adversarial and clean data are not twins,2017, arXivpreprint arXiv:1704
 Explaining and harnessing adversarialexamples,2014, In International Conference on Learning Representations
 Evaluation methodology for attacks against confidencethresholding models,2018, 2018
 Early methods for detecting adversarial images,2016, In InternationalConference on Learning Representations
 Matrix capsules with em routing,2018, InInternational Conference on Learning Representations
 Are odds really odd? bypassingstatistical detection of adversarial examples,2019, arXiv preprint arXiv:1907
 Adam: A method for stochastic optimization,2014, In InternationalConference on Learning Representations
 Learning multiple layers of features from tiny images,2009, Technical report
 Adversarial examples in the physical world,2016, InInternational Conference on Learning Representations
 Adversarial attacks and defences competition,2018, arXivpreprint arXiv:1804
 Gradient-based learning applied todocument recognition,1998, Proceedings of the IEEE
 Adversarial examples detection in deep networks with convolutional filterstatistics,2017, In Proceedings of the IEEE International Conference on Computer Vision
 On detecting adversarialperturbations,2017, In International Conference on Learning Representations
 On the vulnerability of capsulenetworks to adversarial attacks,2019, arXiv preprint arXiv:1906
 Mnist-c: A robustness benchmark for computer vision,2019, In ICML2019 Workshop on Uncertainty and Robustness in Deep Learning
 Readingdigits in natural images with unsupervised feature learning,2011, In NIPS workshop on deep learningand unsupervised feature learning
 Deepcaps: Going deeper with capsule networks,2019, In Proceedingsofthe IEEE Conference on Computer Vision and Pattern Recognition
 The odds are odd: A statistical test for detectingadversarial examples,2019, In International Conference on Machine Learning
 Robust perception throughanalysis by synthesis,2018, arXiv preprint arXiv:1805
 Pixeldefend: Lever-aging generative models to understand and defend against adversarial examples,2017, In InternationalConference on Learning Representations
 Intriguing properties of neural networks,2013, In International Conference on LearningRepresentations
 A note on the evaluation of generativemodels,2015, In International Conference on Learning Representations
 Fashion-mnist: a novel image dataset for benchmarkingmachine learning algorithms,2017, arXiv preprint arXiv:1708
 Sun database:Large-scale scene recognition from abbey to zoo,2010, In 2010 IEEE Computer Society Conference onComputer Vision and Pattern Recognition
 The unreasonableeffectiveness of deep features as a perceptual metric,2018, In Proceedings of the IEEE Conference onComputer Vision and Pattern Recognition
