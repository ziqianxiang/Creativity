title,year,conference
 Generating more interesting responses inneural conversation models with distributional constraints,2018, In Proceedings of the 2018 Conferenceon Empirical Methods in Natural Language Processing
 A stable and effective learningstrategy for trainable greedy decoding,2018, arXiv preprint arXiv:1804
 Style transformer: Unpaired text styletransfer without disentangled latent representation,2019, arXiv preprint arXiv:1905
 Transformer-xl: Attentive language models beyond a fixed-length context,2019, arXivpreprint arXiv:1901
 Bert: Pre-training of deepbidirectional transformers for language understanding,2019, In Proceedings of the 2019 Conference ofthe North American Chapter of the Association for Computational Linguistics: Human LanguageTechnologies
 Hierarchical neural story generation,2018, arXiv preprintarXiv:1805
 Hafez: an interactive poetrygeneration system,2017, In Proceedings of ACL 2017
 Learning to translate in real-timewith neural machine translation,2016, arXiv preprint arXiv:1610
 Trainable greedy decoding for neural machinetranslation,2017, arXiv preprint arXiv:1702
 Learningto write with cooperative discriminators,2018, CoRR
 The curious case of neural text degener-ation,2019, arXiv preprint arXiv:1904
 Controllable textgeneration,2017, CoRR
 Categorical reparameterization with gumbel-softmax,2016, 2016
 CTRL- A Conditional Transformer Language Model for Controllable Generation,2019, arXiv preprintarXiv:1909
 Con-trolling output length in neural encoder-decoders,2016, In Proceedings of the 2016 Conference onEmpirical Methods in Natural Language Processing
 Multiple-attribute text rewriting,2019, In International Conference on LearningRepresentations
 Learning word vectors for sentiment analysis,2011, In Proceedings of the 49th Annual Meetingof the Association for Computational Linguistics: Human Language Technologies
 Foundations of statisticalnatural language processing,1999, MIT press
 Facebook fairâ€™swmt19 news translation task submission,2019, arXiv preprint arXiv:1907
 Deep neural networks are easily fooled: High con-fidence predictions for unrecognizable images,2015, The IEEE Conference on Computer Vision andPattern Recognition (CVPR)
 Languagemodels are unsupervised multitask learners,2019, OpenAI Blog
 Exponential convergence of langevin distributions andtheir discrete approximations,1996, Bernoulli
 Style transfer from non-paralleltext by cross-alignment,2017, CoRR
 Recursive deep models for semantic compositionality over a sentimenttreebank,2013, In Proceedings of the 2013 Conference on Empirical Methods in Natural LanguageProcessing
 Intriguing properties of neural networks,2013, CoRR
 Universal adversarialtriggers for nlp,2019, arXiv preprint arXiv:1908
 Simple statistical gradient-following algorithms for connectionist reinforcementlearning,1992, Machine learning
 Plan-and-write: Towards better automatic storytelling,2019, In Proceedings of the AAAI Conference on ArtificialIntelligence
 Simple and effective noisy channelmodeling for neural machine translation,2019, arXiv preprint arXiv:1908
 The neural noisychannel,2016, arXiv preprint arXiv:1611
 Putting machine translation in context with the noisy channel model,2019, arXiv preprintarXiv:1910
 Fine-tuning language models from human preferences,2019, arXivpreprint arXiv:1909
8 billion over its role in thedeath of an Ohio teenager,2012, The lawsuit says a company that sells guns to military and policeofficials failed a security test in 2012
