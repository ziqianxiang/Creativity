title,year,conference
 Deep learning with differential privacy,2016, In CCS
 Synthetic and natural noise both break neural machine trans-lation,2018, In ICLR
 The secret sharer:Evaluating and testing unintended memorization in neural networks,2019, In USENIX
 Copycat cnn: Stealing knoWledge by persuading confession With random non-labeled data,2018, In IJCNN
 The algorithmic foundations of differential privacy,2014, Foundationsand TrendsÂ® in Theoretical Computer Science
 Hotflip: White-box adversarial examplesfor text classification,2018, In ACL
 SWitchboard: Telephone speech corpusfor research and development,1992, In ICASSP
 Membership inference attacks on sequence-to-sequence models,2019, arXiv preprint arXiv:1904
 High-fidelity extraction of neural netWork models,2019, arXiv preprint arXiv:1909
 Simple and scalable predictiveuncertainty estimation using deep ensembles,2017, In NIPS
 FeW sample knoWledge distillation forefficient netWork compression,2018, arXiv preprint arXiv:1812
 Adversarial learning,2005, In KDD
 Right for the Wrong reasons: Diagnosing syntacticheuristics in natural language inference,2019, In ACL
 Pointer sentinel mixturemodels,2017, In ICLR
 Zero-shot knowledge transfer via adversarial belief matching,2019, InNeurIPS
 Machine Learning with Membership Privacyusing Adversarial Regularization,2018, In CCS
 Zero-shot knowledge distillation in deep networks,2019, arXiv preprintarXiv:1905
 Knockoff nets: Stealing functionality ofblack-box models,2019, In CVPR
 Prediction poisoning: Utility-constraineddefenses against model stealing attacks,2019, arXiv preprint arXiv:1906
 Aframework for the extraction of deep neural networks by leveraging public data,2019, arXiv preprintarXiv:1905
 Practical black-box attacks against machine learning,2017, In AsiaCCS
 Glove: Global vectors for wordrepresentation,2014, In EMNLP
 Recursive deep models for semantic compositionality over a sentimenttreebank,2013, In EMNLP
 Auditing data provenance in text-generation models,2019, InKDD
 Dawn: Dynamic adversarialwatermarking of neural networks,2019, arXiv preprint arXiv:1906
 Stealing machinelearning models via prediction apis,2016, In USENIX
 Attention is all you need,2017, In NIPS
 Universal adversarialtriggers for nlp,2019, In EMNLP
 Automatically evading classifiers,2016, In NDSS
 Learning and evalu-ating general linguistic intelligence,2019, arXiv preprint arXiv:1901
 Qanet: Combining local convolution with global self-attention for readingcomprehension,2018, In ICLR
 Understandingdeep learning requires rethinking generalization,2017, In ICLR
