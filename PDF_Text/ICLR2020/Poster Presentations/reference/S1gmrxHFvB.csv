title,year,conference
 Randaugment: Practical automateddata augmentation with a reduced search space,2019, arXiv preprint arXiv:1909
 AutoAugment:Learning augmentation policies from data,2018, CVPR
 ImageNet: A large-scalehierarchical image database,2009, CVPR
 Improved regularization of convolutional neural networkswith Cutout,2017, arXiv preprint arXiv:1708
 Evaluating and understanding the robustness ofadversarial logit pairing,2018, arXiv preprint
 Generalisation in humans and deep neural networks,2018, NeurIPS
 Motivatingthe rules of the game for adversarial example research,2018, CoRR
 On calibration of modern neuralnetworks,2017, ICML
 Mixup as locally linear out-of-manifold regulariza-tion,2019, In AAAI
 Deep residual learning for imagerecognition,2015, CVPR
 Benchmarking neural network robustness to commoncorruptions and perturbations,2019, ICLR
 A baseline for detecting misclassified and out-of-distributionexamples in neural networks,2017, ICLR
 Using pre-training can improve model robustnessand uncertainty,2019, In ICML
 Deep anomaly detection with outlierexposure,2019, ICLR
 Densely connectedconvolutional networks,2017, In CVPR
 Testing robustness againstunforeseen adversaries,2019, arXiv preprint
 Adversarial logit pairing,2018, NeurIPS
 Learning multiple layers of features from tiny images,2009, 2009
 ImageNet classification with deep convolu-tional neural networks,2012, NeurIPS
 Simple and scalable predictiveuncertainty estimation using deep ensembles,2017, In NeurIPS
 Detecting and correcting for labelshift with black box predictors,2018, ArXiv
 Improv-ing robustness without sacrificing accuracy with patch Gaussian augmentation,2019, arXiv preprintarXiv:1906
 SGDR: stochastic gradient descent with warm restarts,2016, ICLR
 Posterior calibration and exploratory analysis for naturallanguage processing models,2015, EMNLP
 Adversarialtraining can hurt generalization,2019, arXiv preprint arXiv:1906
 Weight normalization: A simple reparameterization to acceleratetraining of deep neural networks,2016, NeurIPS
 Striving forsimplicity: The all convolutional net,2014, CoRR
 Unbiased look at dataset bias,2011, CVPR
 Unsupervised dataaugmentation,2019, arXiv preprint arXiv:1904
 Aggregated residualtransformations for deep neural networks,2016, CVPR
 Wide residual networks,2016, In BMVC
 mixup: Beyond empiricalrisk minimization,2017, ICLR
 Making convolutional networks shift-invariant again,2019, In ICML
 Improving the robustness of deepneural networks via stability training,2016, CVPR
 Random erasing data augmenta-tion,2017, arXiv preprint arXiv:1708
