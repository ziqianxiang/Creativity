title,year,conference
 Obfuscated gradients give a false sense ofsecurity: Circumventing defenses to adversarial examples,2018, In ICML
 Hilbert-based generativedefense for adversarial examples,2019, In ICCV
 On evaluating adversarial robustness,2019, arXiv preprintarXiv:1902
 Unlabeled dataimproves adversarial robustness,2019, arXiv preprint arXiv:1905
 Deepdriving: Learning affordance fordirect perception in autonomous driving,2015, In CVPR
 Certified adversarial robustness via randomizedsmoothing,2019, arXiv preprint arXiv:1902
 Compression to the rescue: Defending from adversarial attacksacross modalities,2018, In KDD
 Bert: Pre-training of deepbidirectional transformers for language understanding,2018, arXiv preprint arXiv:1810
 On thesensitivity of adversarial robustness to input data distributions,2019, ICLR
 Detecting adversarialsamples from artifacts,2017, arXiv preprint arXiv:1703
 Adversarial attacks on medical machine learning,2019, Science
 Explaining and harnessing adversarialexamples,2015, In ICLR
 Towards deep neural network architectures robust to adversarialexamples,2014, arXiv preprint arXiv:1412
 Countering adversarialimages using input transformations,2018, In ICLR
 Deep residual learning for imagerecognition,2016, In CVPR
 Black-box adversarialattacks on video recognition models,2019, In ACM MM
 Adversarial logit pairing,2018, arXiv preprintarXiv:1803
 Gradient-based learning applied todocument recognition,1998, Proceedings of the IEEE
 A simple unified framework for detectingout-of-distribution samples and adversarial attacks,2018, In NeurIPS
 Defense againstadversarial attacks using high-level representation guided denoiser,2018, In CVPR
 Security analysis and en-hancement of model compressed deep learning systems under adversarial attacks,2018, arXiv preprintarXiv:1802
 Characterizing adversarial subspaces using localintrinsic dimensionality,2018, In ICLR
 Understandingadversarial attacks on deep learning based medical image analysis systems,2019, arXiv preprintarXiv:1907
 Robustness to adversarialperturbations in learning from incomplete data,2019, arXiv preprint arXiv:1905
 Adversarial robustness may be at odds with simplicity,2019, arXiv preprintarXiv:1901
 Practical black-box attacks against machine learning,2017, In Asia CCS
 Defend deep neural networksagainst adversarial examples via fixed anddynamic quantized activation functions,2018, arXiv preprintarXiv:1807
 Improving the adversarial robustness and interpretabilityof deep neural networks by regularizing their input gradients,2018, In AAAI
 Provably robust deep learning via adversarially trained smoothed classifiers,2019, arXivpreprint arXiv:1906
 Defense-GAN: Protecting classifiersagainst adversarial attacks using generative models,2018, In ICLR
 Adver-sarially robust generalization requires more data,2018, In NeurIPS
 Intriguing properties of neural networks,2013, arXiv preprint arXiv:1312
 80 million tiny images: A large data set fornonparametric object and scene recognition,2008, IEEE Transactions on Pattern Analysis and MachineIntelligence
 Ensemble adversarial training: Attacks and defenses,2018, In ICLR
 Residual convolutional ctc networksfor automatic speech recognition,2017, arXiv preprint arXiv:1702
 On theconvergence and robustness of adversarial training,2019, In ICML
 Skip connections matter:On the transferability of adversarial examples generated with resnets,2020, In ICLR
 Feature squeezing: Detecting adversarial examples in deepneural networks,2017, arXiv preprint arXiv:1704
 Wide residual networks,2016, arXiv preprint arXiv:1605
 Dirichlet latent variable hierarchical recurrent encoder-decoderin dialogue generation,2019, In EMNLP
 Adversariallyrobust generalization just requires more unlabeled data,2019, arXiv preprint arXiv:1906
 Improving the robustness of deepneural networks via stability training,2016, In CVPR
