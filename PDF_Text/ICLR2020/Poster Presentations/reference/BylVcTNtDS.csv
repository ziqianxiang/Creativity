title,year,conference
 Towards open set deep networks,2016, In Proceedings of the IEEEconference on computer vision and pattern recognition
 Adversarial examples are not easily detected: Bypassing tendetection methods,2017, In Proceedings of the 10th ACM Workshop on Artificial Intelligence andSecurity
 Towards evaluating the robustness of neural networks,2017, In 2017IEEE Symposium on Security and Privacy (SP)
 Attention to scale: Scale-aware semantic image segmentation,2016, In Proceedings of the IEEE conference on computer visionand pattern recognition
 Zoo: Zeroth order opti-mization based black-box attacks to deep neural networks without training substitute models,2017, InProceedings of the 10th ACM Workshop on Artificial Intelligence and Security
 Targeted backdoor attacks on deeplearning systems using data poisoning,2017, arXiv preprint arXiv:1712
 Adversarial examples that fool both human and computervision,2018, arXiv preprint arXiv:1802
 Toward open-set face recog-nition,2017, In Proceedings of the IEEE Conference on Computer Vision and Pattern RecognitionWorkshops
 Block-ing transferability of adversarial examples in black-box learning systems,2017, arXiv preprintarXiv:1703
 Transfer learning from speaker verification tomultispeaker text-to-speech synthesis,2018, In Advances in Neural Information Processing Systems
 Backdoor embedding inconvolutional neural network models via invisible perturbation,2018, arXiv preprint arXiv:1808
 Trojaning attack on neural networks,2017, Proc
 Towards poisoning of deep learning algorithms with back-gradientoptimization,2017, In Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security
 Deep neural networks are easily fooled: High confi-dence predictions for unrecognizable images,2015, In Proceedings of the IEEE conference on computervision and pattern recognition
 Practical black-box attacks against machine learning,2017, In Proceedings of the 2017 ACMon Asia conference on computer and communications security
 Deep face recognition,2015, In BMVC
 Deep learning for encrypted traffic classification: An overview,2019, IEEEcommunications magazine
 Security of deep learning methodologies: Challenges and opportuni-ties,2019, arXiv preprint arXiv:1912
 Accessorize to a crime:Real and stealthy attacks on state-of-the-art face recognition,2016, In Proceedings of the 2016 ACMSIGSAC Conference on Computer and Communications Security
 Intriguing properties of neural networks,2013, arXiv preprint arXiv:1312
