title,year,conference
 Constrained policy optimization,2017, InProceedings of International Conference on Machine Learning
 Projections for approximate policyiteration algorithms,2019, In Proceedings of International Conference on Machine Learning
 Lyapunov-based safe policy optimization for continuous control,2019, arXiv preprintarXiv:1901
 Benchmarking deepreinforcement learning for continuous control,2016, In Proceedings of International Conference onMachine Learning
 Reinforcement learning fromimperfect demonstrations,2018, arXiv preprint arXiv:1802
 Approximately optimal approximate reinforcement learning,2002, InProceedings OfInternational Conference on Machine Learning
 Playing atari with deep reinforcement learning,2013, arXiv preprintarXiv:1312
 Learning complex dexterous manipulation with deep reinforcementlearning and demonstrations,2017, arXiv preprint arXiv:1709
 A reduction of imitation learning and StrUc-tured prediction to no-regret online learning,2011, In Proceedings of International Conference onArtificial Intelligence and Statistics
 Trust regionpolicy optimization,2015, In Proceedings of International Conference on Machine Learning
 High-dimensional continuous control using generalized advantage estimation,2015, arXiv preprintarXiv:1506
 Mastering the game of gowithout human knowledge,2017, Nature
 Benchmarks for reinforcement learning inmixed-autonomy traffic,2018, In Proceedings of Conference on Robot Learning
 By the theorem in Achiam et al,2020, (2017) and Lemma S
 The dash linein the cost constraint plot is the cost constraint threshold h,2020, PCPO with KL divergence projection isthe only one that can satisfy the constraint with the highest reward
