title,year,conference
 Generating Long Sequences withSparse Transformers,2019, arXiv preprint arXiv:1904
 Cognitive Graph for Multi-HopReading Comprehension at Scale,2019, In Proceedings of the 57th Annual Meeting of the Associationfor Computational Linguistics
 Entity Linking in Queries: Efficiencyvs,2017,Effectiveness
 Semi-supervised Classification with Graph Convolutional Net-works,2017, In International Conference on Learning Representations
 Generating Wikipedia by Summarizing Long Sequences,2018, In International Conferenceon Learning Representations
 RoBERTa: A Robustly Optimized BERT Pre-training Approach,2019, arXiv preprint arXiv:1907
 Kernel Graph Attention Network for Fact Veri-fication,2019, arXiv preprint arXiv:1910
 Compositional Questions Do Not Necessitate Multi-hop Reasoning,2019, In Proceedings ofthe 57th Annual Meeting of the Association for Computational Linguistics
 Multi-hop Reading Com-prehension through Question Decomposition and Rescoring,2019, In Proceedings of the 57th AnnualMeeting of the Association for Computational Linguistics
 Revealing the Importance of Semantic Retrieval forMachine Reading at Scale,2019, In Proceedings of the 2019 Conference on Empirical Methods inNatural Language Processing and the 9th International Joint Conference on Natural LanguageProcessing
 Passage Re-ranking with BERT,2019, arXiv preprintarXiv:1901
 Modeling Relational Data with Graph Convolutional Networks,2017, arXiv preprintarXiv:1703
 Graph Attention Networks,2018, In International Conference on Learning Representations
 Deep Graph Library: Towards Efficient and Scalable DeepLearning on Graphs,2019, In ICLR Workshop on Representation Learning on Graphs and Manifolds
