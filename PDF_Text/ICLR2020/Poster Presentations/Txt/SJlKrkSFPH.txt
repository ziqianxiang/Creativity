Published as a conference paper at ICLR 2020
A Framework for Robustness Certification of
Smoothed Classifiers using f-Divergences
Krishnamurthy(Dj) Dvijothamt Jamie Hayes中 Borja Ballet J. Zico Kolterac
ChongliQint AndrasGyorgyt KaiXiaobt* SvenGoWalt PushmeetKohlit
tDeepMind, London, UK ^ University College London, UK
a Carnegie Mellon University, USA b Massachusetts Institute of Technology, USA
c Bosch Center for AI, USA
{dvij, bballe, chongliqin, agyorgy, sgowal, pushmeet}@google.com
{zkolter}@cs.cmu.edu {j.hayes}@ucl.ac.uk {kaix}@mit.edu
Ab stract
Formal verification techniques that compute provable guarantees on properties
of machine learning models, like robustness to norm-bounded adversarial pertur-
bations, have yielded impressive results. Although most techniques developed
so far require knowledge of the architecture of the machine learning model and
remain hard to scale to complex prediction pipelines, the method of randomized
smoothing has been shown to overcome many of these obstacles. By requiring
only black-box access to the underlying model, randomized smoothing scales to
large architectures and is agnostic to the internals of the network. However, past
work on randomized smoothing has focused on restricted classes of smoothing
measures or perturbations (like Gaussian or discrete) and has only been able to
prove robustness with respect to simple norm bounds. In this paper we introduce a
general framework for proving robustness properties of smoothed machine learning
models in the black-box setting. Specifically, we extend randomized smoothing
procedures to handle arbitrary smoothing measures and prove robustness of the
smoothed classifier by using f -divergences. Our methodology improves upon the
state of the art in terms of computation time or certified robustness on several image
classification tasks and an audio classification task, with respect to several classes
of adversarial perturbations.
1	Introduction
Predictors obtained from machine learning algorithms have been shown to be vulnerable to making
errors when the inputs are perturbed by carefully chosen small but imperceptible amounts (Szegedy
et al., 2014; Biggio et al., 2013). This has motivated significant amount of research in improving
adversarial robustness of a machine learning model (see, e.g. Goodfellow et al., 2015; Madry et al.,
2018). While significant advances have been made, it has been shown that models that were estimated
to be robust have later been broken by stronger attacks (Athalye et al., 2018; Uesato et al., 2018).
This has led to the need for methods that offer provable guarantees that the predictor cannot be forced
to misclassify an example by any attack algorithm restricted to produce perturbations within a certain
set (for example, within an `p norm ball). While progress has been made leading to methods that are
able to compute provable guarantees for several image and text classification tasks (Wong & Kolter,
2018; Wong et al., 2018; Raghunathan et al., 2018; Dvijotham et al., 2018; Katz et al., 2017; Huang
et al., 2019; Jia et al., 2019), these methods require extensive knowledge of the architecture of the
predictor and are not easy to extend to new models or architectures, requiring specialized algorithms
for each new class of models. Furthermore, the computational complexity of these methods grows
significantly with input dimension and model size.
To deal with these obstacles, recent work has proposed the randomized smoothing strategy for
verifying the robustness of classifiers. Specifically, Lecuyer et al. (2019) and Cohen et al. (2019)
*Work done during an internship at DeePMind.
1
Published as a conference paper at ICLR 2020
have shown that robustness properties can be more easily verified for the smoothed version of a base
classifier h producing labels in some set Y :
hs(x) = arg max P [h(X) = y] ,
y∈Y X~μ(X)
(1)
where the labels returned by the smoothed classifier hs are obtained by taking a “majority vote” over
the predictions of the original classifier h on random inputs drawn from a probability distribution
μ(x), called the smoothing measure. LecUyer et al. (2019) showed that verifying the robustness
of this smoothed classifier is significantly simpler than verifying the original classifier h and only
requires estimating the distribution of outputs of the classifier under random perturbations of the
input, but does not require access to the internals of the classifier h. We refer to this as black-box
verification.
In this work, we develop a general framework for black-box verification that recovers prior work as
special cases, and improves upon previous results in various ways.
Contributions Our contributions are summarized as follows:
1.	We formulate the general problem of black-box verification via a generalized randomized
smoothing procedure, which extends existing approaches to allow for arbitrary smoothing
measures. Specifically, we show that robustness certificates for smoothed classifiers can be
obtained by solving a small convex optimization problem when allowed adversarial perturbations
can be characterized via divergence-based bounds on the smoothing measure.
2.	We prove that our certificates generalize previous results obtained in related work (Lecuyer
et al., 2019; Cohen et al., 2019; Li et al., 2019), and vastly extend the class of perturbations and
smoothing measures that can be used while still allowing certifiable guarantees.
3.	We introduce the notion of full-information and information-limited settings, and show that the
information-limited setting that has been the main focus of prior work leads to weaker certificates
for smoothed probabilistic classifiers, and can be improved by using additional information (the
distribution of label scores under randomized smoothing).
4.	We evaluate our framework experimentally on image and classification tasks, obtaining ro-
bustness certificates that improve upon other black-box methods either in terms of certificate
tightness or computation time on robustness to `0, `1 or `2 perturbations on MNIST, CIFAR-10
and ImageNet. `2 perturbations result from worst-case realizations of white noise that is common
in many image, speech and video processing. `0 perturbations can model missing data (missing
pixels in an image, or samples in a time-domain audio signal) while `1 perturbations can be
used to model convex combinations of discrete perturbations in text classification (Jia et al.,
2019). We also obtain the first, to the best of our knowledge, certifiably robust model for an
audio classification task, Librispeech (Panayotov et al., 2015), with variable-length inputs.
2	Black-box verification for smoothed classifiers
Consider a binary classifier h : X → {±1} given to us as a black box, so we can only access the
inputs and outputs of h but not its internals. We are interested in investigating the robustness of
the smoothed classifier hs (defined in Eq. 1) against adversarial perturbations of size at most with
respect to a given norm ∣∣∙k. To determine whether a norm-bounded adversarial attack on a fixed
input x ∈ X with hs(x) = +1 could be successful, we can solve the optimization problem
min
∣∣x0-xk≤e X0〜μ(x0)
[h(X0) = +1] ,
(2)
P
and check whether the minimum value can be smaller than 2. This is a non-convex optimization
problem for which we may not even be able to compute gradients since we only have black-box access
to h. While techniques have been developed to address this problem, obtaining provable guarantees
on whether these algorithms actually find the worst-case adversarial perturbation is difficult since we
do not know anything about the nature of h.
Motivated by this difficulty, we take a different approach: Rather than studying the adversarial attack
in the input space X, we study it in the space of probability measures over inputs, denoted by P(X).
2
Published as a conference paper at ICLR 2020
Formally, this amounts to rewriting Eq. 2 as
min	P [h(X0) = +1] .	(3)
ν∈{μ(x0)"∣x0-xk≤e} X0〜VL
This is an infinite dimensional optimization problem over the space of probability measures ν ∈ P(X)
subject to the constraint V ∈ D = {μ(x0) : ∣∣x0 - x∣∣ ≤ e}. While this set is still intractable to
deal with, we can consider relaxations of this set defined by divergence constraints between ν and
P = μ(χ), i.e., D ⊆ {ν : D(V∣∣ρ) ≤ ED} where D denotes some divergence between probability
distributions. We will show in Section 3 that for several commonly used divergences (in fact, for any
f -divergence; cf. Ali & Silvey, 1966), the relaxed problem can be solved efficiently.
2.1	A general framework for robustness certification
To formulate the general verification problem, consider a specification φ : X → Z ⊆ R: a generic
function over the input space (that typically is a function of the classifier output) that we want to verify
has certain properties. Unless otherwise specified, we will assume that X ⊆ Rd (we work in a d
dimensional input space). Our framework also involves a reference measure ρ (in the above example
We would take P = μ(χ)) and a collection of perturbed distributions D (in the above example We
would take D = Dχ,e = {μ(x0) : ∣x0 - Xk ≤ e}).
Verifying that a given specification φ is robustly certified is equivalent to checking whether the
optimal value of the optimization problem
OPT(φ, P, D) := min E [φ(X)] ,	(4)
ν∈D X〜V
is non-negative. Solving problems of this form is the key workhorse of our general framework for
black-box certification of adversarial robustness for smoothed classifiers.
Using these ingredients we introduce two closely related certification problems: information-limited
robust certification and full-information robust certification. In the former case, we assume that we
are given only given access to PX〜ρ[φ(X) = +1], PX〜ν[φ(X) = +1]. In the latter case, we are
given full-access to specification φ. The definitions are below.
Definition 2.1 (Information-limited robust certification). Given reference distribution P ∈ P(X),
probabilities θa , θb that satisfy θa, θb ≥ 0, θa + θb ≤ 1 and collection of perturbed distributions
D ⊂ P(X) containing P, define the class of specifications S as
S = ∣φ: X→{-1,0,+1} s.t. XP [φ(X) = +1] ≥ θa,XP [φ(X) = -1] ≤ θb∣
We say that S is information-limited robustly certified at P with respect to D if the following condition
holds: EX 〜ν[φ(X)] ≥ 0 for all V ∈D,φ ∈ S.
Note since we don,t have access to φ, we need to prove that EX〜V [Φ(X)] ≥ 0 ∀ν ∈ D is satisfied
for all specifications in set S. Although the information-limited case may seem challenging because
we need to provide guarantees that hold simultaneously over a whole class of specifications, it turns
out that, for perturbation sets D specified by an f -divergence bound, this certification task can be
solved efficiently using convex optimization.
Definition 2.2 (Full-information robust certification). Given a reference distribution P ∈ P(X), a
specification φ : X → Z ⊆ R and a collection of perturbed distributions D ⊂ P(X) containing P,
we say that φ is full-information robustly certified at P with respect to D if the following condition
holds: EX〜V [Φ(X)] ≥ 0 for all V ∈ D.
Most often we are dealing with the case where we have full access to the specification φ, thus we
should be able to certify using full-information robust certification. However, prior works, Cohen
et al. (2019) and Lecuyer et al. (2019), have only provided solutions to certify with respect to the
information-limited case where we cannot use all of the information about φ. The framework we
develop is a more general method that can be used in both information-limited and full-information
scenarios. We will demonstrate that our framework recovers certificates provided by Cohen et al.
(2019), Li et al. (2019) and dominates Lecuyer et al. (2019) in the information-limited setting
(see section 5). Further, it can utilize full-information about the specification φ to provide tighter
certificates for smoothed probabilistic classifiers (see section 6).
3
Published as a conference paper at ICLR 2020
2.1.1	Robustness specification for smoothed hard classifiers
We first note that the definitions above are sufficient to capture the standard usage of randomized
smoothing as it has been used in past work (e.g. Lecuyer et al., 2019; Cohen et al., 2019) to verify
the robustness of smoothed multi-class classifiers. Specifically, consider smoothing a classifier
h : X → Y with a finite set of labels Y using a smoothing measure μ : X → P(X). The resulting
randomly smoothed classifier hs is defined in Eq. 1. Our goal is to certify that the prediction hs (x) is
robust to perturbations of size at most measured by distance function1 d : X × X 7→ R+ , i.e.,
hs(x0) = hs(x) ∀x0 such that d(x, x0) ≤	.	(5)
To PoSe this question within our framework, We choose the reference distribution P = μ(x), the
set of perturbed distributions Dx,e = {μ(x0) : d(x, x0) ≤ e}, and the following specifications. Let
c = hs(x). For every c0 ∈ Y \ {c}, we define the sPecification φc,c0 : X 7→ {-1, 0, +1} as follows:
+1 if h(x) = c ,
φc,c0 (x) =	-1 if h(x) = c0 ,
I 0 otherwise .
Then, Eq. 5 holds if and only if every φc,c,, C = c, is robustly certified at μ(x) with respect to Dx
(see Appendix A.1).
2.2	Constraint sets from f-divergences
Dealing with the set Dx, directly is difficult due to its possibly non-convex geometry. In this section,
we discuss specific relaxations of this set, i.e., choices for sets D such that Dx, ⊆ D that are easier
to optimize over. In particular, we focus on a general family of constraint sets defined in terms of
f -divergences. These divergences satisfy a number of useful properties and include many well-known
instances (e.g. relative entropy, total variation); see Appendix A.2 for details.
Definition 2.3. (f -divergence constraint set). Given ρ, ν ∈ P(X), their f -divergence is defined as
Df(V kp)=χHf(VS )1,
where f : R+ 7→ R is a convex function with f (1) = 0. Given a reference distribution ρ, an
f -divergence Df and a bound f ≥ 0, we define thef-divergence constraint set to be:
Df = {ν ∈P (X )： Df(V kρ) ≤ f }.
Technically, this definition depends on the Radon-Nikodym derivative of V with respect to ρ, but we
ignore measure-theoretic issues in this paper for simplicity of exposition. For continuous distributions,
V and ρ should be treated as densities, and for discrete distributions as probability mass functions.
Relaxations usingf-divergence This construction immediately allows us to obtain relaxations of
Dx,. For example, by choosingf(u) = u log(u), we have the KL-divergence. Using KL-divergence
yields the following relaxation between norm-based and divergence-based constraint sets for Gaussian
smoothing measures, i.e. μ(x) = N(x, σ2I):
Dx,e = {μ(x0) ： kX - x0k2 ≤ e} ⊆ {〃 ： KL(V∣∣μ(x)) ≤ g/(2σ2)}.
Tighter relaxations can be constructed by combining mul-
tiple divergence-based constraints. In particular, suppose
F is a collection of convex functions each defining an
f -divergence, and assume each f ∈ F has a bound f
associated with it. Then we can define the constraint set
containing perturbed distributions where all the bounds
hold simultaneously (Fig. 1):
DF ：= \ Df = {ν ： ∀ f ∈ F Df(V∣ρ) ≤ f}.
f∈F
------------------------------------- Figure 1: Intersecting f-divergence con-
d is an arbitrary +stance function (not necessarily a metric egtrOints to obtain better relaxations DF (de-
picted by the orange region) of Dx, .
4
Published as a conference paper at ICLR 2020
In this paper, we work with the following divergences:
(I)Renyi: Ra(VkP) = log(1 + Df(VkP))∕(α - 1) where
f(x) = Xa — 1 (for α ≥ 1), and Ra(PkV) = log(1 — Df(V ∣∣ρ))∕(α-1) with f (x) = 1-xa (for 0 ≤
α ≤ 1). The limit α → ∞ yields the infinite order Renyi divergence R∞(ν∣ρ) = SuPx(V(x)∕ρ(x)).
(2)	KL(V kP) = Df (VkP) with f(x) = x log(x).
(3)	Hockey-Stick: DHS,β (V kP) = Df (VkP) with f(x) = max(x - β, 0) - max(1 - β, 0).
It turns out that the Renyi and KL divergences are computationally attractive for a broad class of
smoothing measures, while the Hockey-Stick divergences are theoretically attractive as they lead to
optimal certificates in the information-limited setting. However, Hockey-Stick divergences are harder
to estimate in general, so we only use them for Gaussian smoothing measures.
2.3 Computing f-divergence bounds
In general, our framework can be used with any family of smoothing measures and any family of
f divergences such that an upper bound on maxν∈Dx, Df (VkP) can be estimated efficiently. We
describe how f -divergence bounds can be obtained for several classes of smoothing measures:
Product measures Product measures are of the form μ(x)=卷d=ιNi(χi) where X = Qd=ι Xi
and μi is a smoothing measure on Xi. We note that the discrete smoothing measure used in (Lee
et al., 2019), the Gaussian measure used in (Cohen et al., 2019) and the Laplacian measure used
in (Li et al., 2019) are all of this form. For such measures, one can construct bounds on Renyi-
divergences subject to any `p norm constraint using a Lagrangian relaxation of the optimization
problem maxx0Rx-x0kp≤e Ra(μ(χ0)∣∣μ(χ)) (see Appendix A.3 for details).
Norm-based smoothing measures Appendix A.9.1 also shows how we can obtain bounds on the
infinite-order Renyi divergence R∞, as well as on several classes of f -divergences, for norm-based
smoothing measures of the form μ(x)[X ] b exp(-∣X - x∣).
3 Our certification procedures
We now show how to reduce the problems of full-information and information-limited robust black-
box certification to simple convex optimization problems for general constraint sets D defined in
terms of f -divergences. This allows us, by extension, to solve the problem for related divergences
like Renyi divergences. The following two theorems provide the main foundation for the verification
procedures in the paper.
Theorem 1 (Verifying full-information robust certification). Let DF be the constraint set defined by
F = {f1, . . . , fM} and fi = i. Define fλ(u) = PiM=1 λifi(u) and denote its convex conjugate2
by fλ. The specification φ is robustly certified at P with respect to DF (cf. Definition 2.2) if and only
if the optimal value of the following convex optimization problem is non-negative:
M
.maχ,	K - X Xq- YE [fλ(κ- φ(χ))].
λι,...,λM ≥0,κ	A_X	X~ρ
i=1
(6)
The proof of Theorem 1, given in Appendix A.4, uses standard duality results to show that the dual
of the verification optimization problem has the desired form. We note that the special case where
M = 1 reduces to Proposition 1 of Duchi & Namkoong (2018), although the result is used in a
completely different context in that work.
To build a practical certification algorithm from Theorem 1, we must do two things: 1) compute
the optimal values of λ and κ; and 2) estimate the expectation in Eq. 6. Since the estimation of
the expectation cannot be done in closed form (due to the black-box nature of φ), we must rely on
sampling. In step 1 of Algorithm 1, we use N samples taken independently from P to estimate the
expectation and solve the “sampled” optimization problem using an off-the-shelf solver (Diamond
2For any function f : R+ → R, its convex conjugate is defined as f * (U) = maxv≥0 (Uv — f (Vy).
5
Published as a conference paper at ICLR 2020
Algorithm 1 Full information certification (see appendix A.9 for details of subroutines)
Inputs: Query access to specification φ : X → [a, b], sampling access to reference distribution ρ,
divergences f and bounds g, sample sizes N, N, confidence level Z.
1:	κ*,λ* - ESTIMATEOPT(ρ,φ, N, {fi}Mι, {q}M=ι).
2:	Eub — UPPERCONFIDENCEBOUND(ρ, φ, N, {fi}M=1, {ei}M1, a, b, λ*,κ*,Z).
3:	If κ* - P= λ*ei - Eub ≥ 0 return CERTIFIED else return NOT CERTIFIED.
& Boyd, 2016). This gives us κ*, λ*, the estimated optimal values of K and λ, respectively. Then
we take these values and compute a high-confidence lower bound on the objective function of Eq. 6,
which is then used to verify robustness. In particular, in step 2, we compute a high-confidence upper
bound Eub on the expectation term in the objective such that Eub ≥ EX〜ρ[fλ(κ* - φ(X))] with
probability at least ζ; this computation involves taking N independent samples from ρ and finding a
confidence interval around the resulting empirical estimate of the expectation (for details, see Eq. 25
in Appendix A.9.1). Plugging in this estimate back into Eq. 6 gives the desired high-confidence lower
bound in step 3. Details of both subroutines EstimateOpt and UpperConfidenceBound used
in Algorithm 1 are given in Algorithm 3 in Appendix A.9.2.
Our next theorem concerns the specialization of this verification procedure to the information-limited
setting.
Theorem 2 (Verifying information-limited robust certification). Let DF be as in Theorem 1, and
S and θa, θb be as in Definition 2.1. The class of specifications S is information-limited robustly
certified at ρ with respect to DF (cf. Definition 2.1) if and only if the optimal value of the following
convex optimization problem is non-negative:
min
ζa,ζb,ζc≥0
Subject to
ζa - ζb
ζa + ζb + ζc = 1 ,	Dfi (ζkθ) ≤ i i = 1, . . . , M ,
(7)
where θ = (θa, θb, 1 - θa - θb) and ζ = (ζa, ζb, ζc) are interpreted as probability distributions.
The proof of Theorem 2 is presented in Appendix A.5. It is based on the fact that in the information-
limited setting, it is possible to directly compute the expectation in Eq. 6, and in fact this expectation
only depends on φ via the probabilities θa and θb .
Theorem 2 naturally leads to a certification algorithm, presented in Algorithm 2. It simply uses
the same procedure as Cohen et al. (2019, Section 3.2) to compute a high-confidence lower bound
θa on the probability of the correct class under randomized smoothing and then solves the convex
optimization problem Eq. 7. Again, we can use an off-the-shelf solver CVXPY (Diamond & Boyd,
2016) in step 2 for the general M > 1 case, but closed-form solutions are also available for M = 1;
these are given in Table 4 in Appendix A.6.
Algorithm 2 Information-limited certification
Inputs: Query access to classifier h, correct label y, sampling access to reference distribution ρ,
divergences f and bounds ei, sample sizes N, N, confidence level Z.
1:	SampleX1,... ,XN 〜P and test3 whether y = argmaXyo∈γPX〜ρ[h(X) = y0].
2:	Sample X1,..., XN 〜P and compute4 a bound PX 〜ρ[h(X) = y0] ≥ θɑ with confidence Z.
3:	Obtain o* by solving Eq. 7 with θ0 — θɑ and θb - 1 - %.
4:	If o* ≥ 0 return CERTIFIED else return NOT CERTIFIED.
4 Theoretical analysis of certification methods
We now present theoretical results characterizing our certification methods and show the following:
3Using the algorithm from Hung & Fithian (2019).
4Using the algorithm from Clopper & Pearson (1934).
6
Published as a conference paper at ICLR 2020
1.	For smoothed probabilistic classifiers, the full-information certificate dominates the information-
limited one.
2.	In the information-limited setting, if we define the f -divergence relaxation DF using Hockey-
Stick divergences with specific parameters, then the computed certificate is provably tight.
4.1 Advantage of full-information certification
Consider a soft binary classifier H : X → [0, 1] that outputs the probability of label +1 and consider
a point X ∈ X with H(x) > 1/2. Wedefinethe specification φ(x) = H(x) - 1. Then, the smoothed
classifier Hs(X) = EX〜*(x)[H(X)] predicts label +1 for all χ0 with ∣∣χ0 - x|| ≤ E if and only if φ is
full-information robustly certified at μ(x) with respect to Dχ,e = {μ(x0) : ∣x0 - Xk ≤ e}. Note that
the optimization in Theorem 1 depends on the full distribution of φ(X) ∈ [-1/2,1/2], X 〜μ(x).
On the other hand, to certify this robustness in the information-limited setting is equivalent to taking
the specification φ(X) = 1[H(X) > 1/2] (the indicator function of the event H(X) > 1/2), in which
case the only information available is θa = Hs(X) = EX〜*(x)[H(X)].
To compare the two approaches, consider the objective of Eq. 6 with a single f -divergence constraint
Df(νkρ) ≤ E. Then, we have
R-M-XjB(X)[fλ(κ-CKX))] = ""-X%) fλ(K-H(X) + 2)]
=κ-λe-xJ!(x)fλ((κ+2-I)H(X)+ (K+1 )(1 -H(X)))]
≥κ - λe - xjE(x)fλ (K- 2)H (x )+fλ(κ+2 )(1- H(X))_
=K - λ - θafλ (K - 2) - (I - θa )fλ (K + 2),
where the third line follows from Jensen’s inequality. The proof of Theorem 2 shows that maximizing
the final expression above with respect to K, λ is equivalent to the dual of the information-limited
certification problem Eq. 7. Thus, the information-limited setting computes a weaker certificate than
the full-information setting for soft classifiers:
Corollary 3. The optimization problem of Eq. 6 with the specification φ defined above has an
optimal value that is greater than or equal to that of the optimization problem defined in Eq. 7.
4.2 Tight relaxations for Information-limited robust certification
Ideally, we would like to certify robustness of specifications with respect to sets of the form Dx, =
{μ(χ0) : d(χ, x0) ≤ e}. The following result shows that the gap between the ideal Dχ,e and the
tractable constraint sets DF can be closed in the context of information-limited robust certification
provided that we can measure hockey-stick divergences of every non-negative order β ≥ 0. The
proof is given in Appendix A.7.
Theorem 4. Let θa, θb, ρ, D, S be as in Definition 2.1. Define Eβ = maxν∈D DHS,β(νkρ) for all
β ≥ 0 and let βa, βb be chosen as follows:
βa, β = argmax 1 -	βa(1	-	θa)	-	βbθb	- (Eea + [1 -仇]十)-(Eeb	+ [1 -仇]十)∙⑻
βa≥βb≥0
Define the constraint set
DHS = {ν ∈ P(X): DHs；比(V Il P) ≤ Eea }∩{ν ∈ P(X): DHs；曜(V Il P) ≤ EeJ ∙
Then, S is information-limited robustly certified at ρ with respect to D if and only if S is information-
limited robustly certified at P with respect to DHS. Thus, the optimal information-limited certificate
in this case can be obtained by applying theorem 2 to DHS .
5 Connections with prior work
Table 1 summarizes the differences between our work and prior work in terms of the set of smoothing
measures admitted, the offline computation cost of the certification procedure (which needs to
7
Published as a conference paper at ICLR 2020
be performed once for every possible perturbation size and choice of smoothing measure), the
perturbations considered, whether they can use information beyond θa , θb to improve the certificates
and whether they compute optimal certificates for a given smoothing measure in the information-
limited setting.
	μ(x)	Computation		Use additional information?	Optimal
COhenetaL(2019)	Gaussian	O(1)		X	-Yes-
-Lee etal. (2019)-	Finite Support*	O(d3)		Only decision trees	-Yes-
-Li etal. (2019)	Gaussian Laplacian	O1	'1	X	-No-
LeCUyer etal.(2019)	Arbitrary	O1	All'p	X	-No-
Our work	Arbitrary	。⑴	All'p	Arbitrary classifiers	YeS
Table 1: Comparison between black-box verification methods. * Technically, Lee et al. (2019) can handle
smoothing measures such that the likelihood ratios take a finite set of values, but most practical instances of this
correspond to finite-support distributions.
Cohen et al. (2019) study the problem of verifying hard classifiers smoothed by Gaussian noise, and
derive optimal certificates with respect to `2 perturbations of the input. Their results can be recovered
as a special case of our framework when applied to sets defined via constraints on hockey-stick
divergences. Theorem 4 shows that the optimal certificate in the information-limited setting can be
computed by applying theorem 2 to a constraint set with two hockey-stick divergences.
For the Gaussian measure μ(x) = N(x,σ2l), the HS divergence Dhs*(μ(x)kμ(x0)) can be
computed in closed form and is purely a function of the `2 distance kx - x0 k2 . This enables us to
efficienctly compute the βa,βb in theorem 4. Thus, We obtain the following result (see Appendix
A.7.2 for a proof):
Corollary 5. Let P = N(x, σ2I), Dχ,e = {N(x0, σ2I) : kX — x0k2 ≤ e} and 1 ≥ θα ≥ θb ≥ 0.
Let DHS be defined as in theorem 4. Then, applying theorem 2 to the constraint set DHS gives the
following condition for robust certification:
Ψg (ψ-1(θa) — :) +Ψg (ψ-1(1 — θb) — σ) ≥ 1 ,	(9)
where Ψg is the CDF of a standard normal random variable N(0, 1). With straightforward algebra
(worked out in appendix A.7.2) , this can be shown to be equivalent to
Ψ-1(θa) - Ψ-1(θb) ≥ 生,
σ
which is the certificate from Theorem 1 of Cohen et al. (2019).
Lee et al. (2019) derive optimal certificates in the information-limited setting under the assumption
that the likelihood ratio between measures P(XX) (where V = μ(χ0), P = μ(χ)) can only take values
from a finite set. This is a restrictive assumption that prevents the authors from accommodating natural
smoothing measures like Gaussian or Laplacian measures. Further, the complexity of computing the
certificates in their framework is significant: O(d3) computation (where d is the input dimension)
is needed to certify smoothness to `0 perturbations. The authors also derive tighter certificates for
the special case of certain classes of decision trees by exploiting the tree structure. In contrast, our
framework can derive tighter certificates in the full-information setting for arbitrary classifiers.
Li et al. (2019) use properties OfRenyi divergences to derive robustness certificates for classifiers
smoothed by Gaussian (resp. Laplacian) noise under `2 (resp. `1 ) perturbations. Their results can
be obtained as special cases of ours; in particular, the Renyi divergence certificates in Table 4 (in
Appendix A.6) recover the results of Lemma 1 of Li et al. (2019), but the latter are only applicable
for Gaussian and Laplacian smoothing measures.
Lecuyer et al. (2019) introduce the notion of pixel differential privacy (pixelDP) and show that
smoothing measures μ satisfying pixelDP with respect to a certain type of perturbations lead to
adversarially robust classifiers. We can show that pixelDP can be viewed as a special instance of our
8
Published as a conference paper at ICLR 2020
certification framework with two specific hockey-stick divergences, and that the certificates derived
from the pixelDP are provably dominated by the certificates from our framework (Theorem 1) with
the same choice of divergences (see Corollary 7 in Appendix A.7.3).
6 Experiments
6.1	Full-Information improves upon Information-limited certification
To compare full-information certificates with limited-
information certificates, we trained a ResNet-152 model
on ImageNet with data augmentation by adding noise
via sampling from a zero-mean Gaussian with variance
0.5 for each coordinate; during certification we sample
from the same distribution to estimate lower bounds on
the probability of the top predicted class. For the full-
information certificate, we use two hockey-stick diver-
gences for the certificate and tune the parameters β to
obtain the highest value in the optimization problem in
step 2 of Algorithm 1. For the infromation-limited certifi-
cate, our approach reduces to that of (Cohen et al., 2019)
and we follow the same certification procedure. We use
N = 1000, N = 1000000, Z = .99 for both certification
procedures.
Figure 2 shows the difference between the two certificates.
The certificate provided by the full-information method
is always stronger than the one given by the information-
limited method. The difference is often substantial - for
one of the test samples, the full-information setting can
certify robustness to `2 perturbations of radius = 9.42
in the full-information case while the limited-information
certificate can only be provided for perturbation radius
= 2.69.
6.2	Scalability and Tightness
In this section we consider `0 perturbations for both Ima-
geNet and Binary MNIST (that is, we consider the number
of pixels that can be perturbed without changing the pre-
diction). To test for scalability and tightness trade-offs of
our framework, we compare our methodology to that of
Figure 2: Information-limited vs full-
information certificates for ImageNet for `2
perturbations. The dashed line represents
equal certificates and every point below the
dashed line has a stronger certificate from
the full information verification setting. We
run the comparison on 50 randomly selected
examples from the validation set. Each blue
dot in Figure 2 corresponds to one test point,
with its x coordinate representing the radius
for full information certificate (from Algo-
rithm 1) and y coordinate the information-
limited certificate (which is equivalent to the
certification procedure of Cohen et al., 2019).
The running time of the full-information cer-
tification procedure is .2s per example (ex-
cluding the sampling cost) while the limited-
information certification takes .002s per ex-
ample. Both procedures incur the same sam-
pling cost as they use the same number of
samples.
Lee et al. (2019), as their work obtains the optimal bound for `0 . We computed certificates for a
single model for each classification task; for Binary MNIST we used the same model and training
procedure as Lee et al. (2019) and for ImageNet, we used the model released in the Github code
accompanying the paper of Lee et al. (2019). We use the discrete smoothing measure (appendix A.10)
with parameter p = 0.8 for Binary MNIST certification, and p = 0.2 for ImageNet certification.
In our experiments we ran the certification procedures on all test examples from the Binary MNIST
dataset, while for ImageNet, following prior work (Lee et al., 2019; Cohen et al., 2019), on every
100th example from validation set. The proportion of the examples for which accuracy can be
certified are reported in Table 2 for various values of . Comparing with the optimal certificates
obtained by the certification method of Lee et al. (2019), the table shows that our bounds remains
tight for Binary MNIST up until = 3, and we do so with 130 times speed-up. For ImageNet, our
bounds differ only about 7-15% in terms of accuracy, and we obtain this with approximately 20
million times speed-up.
9
Published as a conference paper at ICLR 2020
Dataset	Certificate	Smoothing	Computation			Certified Accuracy				
		Value	Time							
				=1	=2	=3	W = 4	W=5	W=6	W=7
Binary MNIST	Lee et al. (2019)	0.8	3.68s	0.919	0.767	0.530	0.513	0.348	0.194	0.095
	Ours		0.028s	0.919	0.767	0.530	0.296	0.162	0.080	0.015
ImageNet	Lee et al. (2019)	0.2	4 days	0.488	0.418	0.310	0.250	0.244	0.234	0.224
	Ours		0.028s	0.362	0.262	0.224	0.186	0.136	0	0
Table 2: Proportion of the examples With verified '0-robustness for different accuracy (e) parameters.
6.3	Certification for Audio Classification: Librispeech
Audio classification systems have been shoWn to be susceptible to adversarial attacks (Qin et al.,
2019). HoWever, building audio classifiers that are provably robust to adversarial attacks has been
hard due to the complexity of audio processing architectures. We take a step toWards provably robust
audio classifiers by shoWing that our approach can certify robustness of a classifier trained for speaker
recognition on a state-of-the-art model for this task. We focus on `0 perturbations that zero out a
fraction of the audio sample, as they correspond to missing data in an audio signal. Missing data can
occur due to errors in recording audio or packets dropped While transmitting an audio signal over a
netWork and is a common issue (Turner, 2010; Smaragdis et al., 2009).
In principle, the method of Lee et al. (2019) is applicable to compute robustness certificates, but at
an impractically large computational cost, since the computation needs to be repeated Whenever an
input of a neW length (for Which a certificate has not previously been computed) arrives. Concretely,
this constitutes an O(d3) computation for the length d ranging from 38 to 522,320 (the set of audio
sequence lengths observed in the Librispeech test dataset (Panayotov et al., 2015)).
The results are shoWn in Table 3. To the best of our knoWledge, these are the first results shoWing
certified robustness of an audio classifier. We believe this is a significant advance toWards certification
of classifiers in audio and classifiers operating on variable-length inputs more generally.
Dataset	Certificate	Smoothing Value	Computation Time	Certified Accuracy							
				W=0	W=1	W=2	W=3	W = 4	W=5	W=6	W=7
		0.5		0.511	0.225	0.091	0.091	0.091	0.091	0.091	0
Librispeech	Ours	0.7	0.028s	0.885	0.634	0.405	0.405	0.405	0.405	0	0
		0.9		0.872	0.772	0.711	0.711	0.711	0	0	0
Table 3: `0 robustness results for Librispeech (Panayotov et al., 2015). From the Librispeech dataset, We
created a corpus of sentence utterances from ten different speakers. The classification task is, given an audio
sample, to predict Whom is speaking. The test set consisted of 30 audio samples for each of the ten speakers.
We use a DeepSpeaker architecture (Li et al., 2017), trained With the Adam optimizer (β1 = 0.9, β2 = 0.5) for
50,000 steps With a learning rate of 0.0001. The architecture is the same as that of Li et al. (2017), except for
changing the number of neurons in the final layer for speaker identification With ten classes. Three models Were
trained With smoothing values of p = 0.5, p = 0.7, and p = 0.9, respectively, and We used the same values
for certification. Certification was performed using N = 1000, N = 1000000, Z = .99 using M = 1 Renyi
divergence, With α tuned to obtain the best certificate. The proportion of samples With certified robustness for
different accuracy values are reported, computed on 300 test set samples.
7 Conclusion
We have introduced a general framework for black-box verification using f -divergence constraints.
The framework improves upon state-of-the-art results on both image classification and audio tasks
by a significant margin in terms of robustness certificates or computation time. We believe that our
framework can potentially enable scalable computation of robustness verification for more complex
predictors and structured perturbations that can be modeled using f-divergence constraints.
References
Syed Mumtaz Ali and Samuel D Silvey. A general class of coefficients of divergence of one
distribution from another. Journal of the Royal Statistical Society: Series B (Methodological), 28
10
Published as a conference paper at ICLR 2020
(1):131-142,1966.
Anish Athalye, Nicholas Carlini, and David Wagner. Obfuscated gradients give a false sense of
security: Circumventing defenses to adversarial examples. In International Conference on Machine
Learning, 2018.
Jean-Yves Audibert, Remi Munos, and Csaba Szepesvari. Exploration-exploitation tradeoff using
variance estimates in multi-armed bandits. Theoretical Computer Science, 410(19):1876-1902,
2009.
Borja Balle and Yu-Xiang Wang. Improving the gaussian mechanism for differential privacy:
Analytical calibration and optimal denoising. In International Conference on Machine Learning,
pp. 403-412, 2018.
Gilles Barthe and Federico Olmedo. Beyond differential privacy: Composition theorems and relational
logic for f-divergences between probabilistic programs. In International Colloquium on Automata,
Languages, and Programming, pp. 49-60. Springer, 2013.
Battista Biggio, Igino Corona, Davide Maiorca, Blaine Nelson, Nedim Srndic, Pavel Laskov, Giorgio
Giacinto, and Fabio Roli. Evasion attacks against machine learning at test time. In Joint European
conference on machine learning and knowledge discovery in databases, pp. 387-402. Springer,
2013.
Sebastian Bubeck.	Orf523 (advanced optimization):	Introduction.
https://blogs.princeton.edu/imabandit/2013/02/05/orf523-advanced-optimization-introduction/,
2013.
Charles J Clopper and Egon S Pearson. The use of confidence or fiducial limits illustrated in the case
of the binomial. Biometrika, 26(4):404-413, 1934.
Jeremy M Cohen, Elan Rosenfeld, and J Zico Kolter. Certified adversarial robustness via randomized
smoothing. arXiv preprint arXiv:1902.02918, 2019.
Imre Csiszar, Paul C Shields, et al. Information theory and statistics: A tutorial. Foundations and
TrendsR in Communications and Information Theory, 1(4):417-528, 2004.
Steven Diamond and Stephen Boyd. Cvxpy: A python-embedded modeling language for convex
optimization. The Journal of Machine Learning Research, 17(1):2909-2913, 2016.
John Duchi and Hongseok Namkoong. Learning models with uniform performance via distributionally
robust optimization. arXiv preprint arXiv:1810.08750, 2018.
Krishnamuthy Dvijotham, Robert Stanforth, Sven Gowal, Timothy Mann, and Pushmeet Kohli.
Towards scalable verification of neural networks: A dual approach. In Conference on Uncertainty
in Artificial Intelligence, 2018.
Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversarial
examples. In International Conference on Machine Learning, 2015.
Po-Sen Huang, Robert Stanforth, Johannes Welbl, Chris Dyer, Dani Yogatama, Sven Gowal, Krishna-
murthy Dvijotham, and Pushmeet Kohli. Achieving verified robustness to symbol substitutions via
interval bound propagation. arXiv preprint arXiv:1909.01492, 2019.
Kenneth Hung and William Fithian. Rank verification for exponential families. The Annals of
Statistics, 47(2):758-782, 2019.
Robin Jia, Aditi Raghunathan, Kerem Goksel, and Percy Liang. Certified robustness to adversarial
word substitutions. arXiv preprint arXiv:1909.00986, 2019.
Guy Katz, Clark Barrett, David L Dill, Kyle Julian, and Mykel J Kochenderfer. Reluplex: An efficient
smt solver for verifying deep neural networks. In International Conference on Computer Aided
Verification, pp. 97-117. Springer, 2017.
11
Published as a conference paper at ICLR 2020
Mathias Lecuyer, Vaggelis Atlidakis, Roxana Geambasu, Daniel Hsu, and Suman Jana. Certified
robustness to adversarial examples with differential privacy. In 2019 IEEE Symposium on Security
and Privacy (SP),pp. 656-672. IEEE, 2019.
Guang-He Lee, Yang Yuan, Shiyu Chang, and Tommi S Jaakkola. A stratified approach to robustness
for randomly smoothed classifiers. arXiv preprint arXiv:1906.04948, 2019.
Bai Li, Changyou Chen, Wenlin Wang, and Lawrence Carin. Certified adversarial robustness with
additive noises. In Advances in Neural Information Processing Systems, 2019.
Chao Li, Xiaokong Ma, Bing Jiang, Xiangang Li, Xuewei Zhang, Xiao Liu, Ying Cao, Ajay Kannan,
and Zhenyao Zhu. Deep speaker: an end-to-end neural speaker embedding system. arXiv preprint
arXiv:1705.02304, 2017.
Friedrich Liese and Igor Vajda. On divergences and informations in statistics and information theory.
IEEE Transactions on Information Theory, 52(10):4394-4412, 2006.
Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and Adrian Vladu.
Towards deep learning models resistant to adversarial attacks. In International Conference on
Learning Representations, 2018.
V. Panayotov, G. Chen, D. Povey, and S. Khudanpur. Librispeech: An asr corpus based on public
domain audio books. In 2015 IEEE International Conference on Acoustics, Speech and Signal
Processing (ICASSP), pp. 5206-5210, April 2015. doi: 10.1109/ICASSP.2015.7178964.
Yao Qin, Nicholas Carlini, Ian Goodfellow, Garrison Cottrell, and Colin Raffel. Imperceptible,
robust, and targeted adversarial examples for automatic speech recognition. arXiv preprint
arXiv:1903.10346, 2019.
Aditi Raghunathan, Jacob Steinhardt, and Percy Liang. Certified defenses against adversarial
examples. In International Conference on Learning Representations, 2018. URL https://
openreview.net/forum?id=Bys4ob-Rb.
Paris Smaragdis, Bhiksha Raj, and Madhusudana Shashanka. Missing data imputation for spectral
audio signals. In 2009 IEEE International Workshop on Machine Learning for Signal Processing,
pp. 1-6. IEEE, 2009.
Thomas Steinke and Jonathan Ullman. Between pure and approximate differential privacy. Journal
of Privacy and Confidentiality, 7(2), 2016.
Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian Goodfellow,
and Rob Fergus. Intriguing properties of neural networks. In International Conference on Learning
Representations, 2014.
Richard E Turner. Statistical models for natural sounds. PhD thesis, UCL (University College
London), 2010.
Jonathan Uesato, Brendan O’Donoghue, Aaron van den Oord, and Pushmeet Kohli. Adversarial
risk and the dangers of evaluating against weak attacks. In International Conference on Machine
Learning, 2018.
Eric Wong and J Zico Kolter. Provable defenses against adversarial examples via the convex outer
adversarial polytope. International Conference on Machine Learning, 2018.
Eric Wong, Frank Schmidt, Jan Hendrik Metzen, and J Zico Kolter. Scaling provable adversarial
defenses. In Advances in Neural Information Processing Systems, pp. 8400-8409, 2018.
12
Published as a conference paper at ICLR 2020
A Appendix
A. 1 Adversarial specification for smoothed classifiers
Note that for any ν ∈ Dx, we have
XEyφc,c0 (X)] = χΑν[h(X) = c]- χPlν[h(X) = c0].
Therefore, EX〜V[φce (X)]	≥	0 for all C ∈ Y \ {c} is equivalent to c ∈
argmaxy∈γ PX〜ν[h(X) = y]. For V = μ(x0), this means that hs(x0) = c (assuming the argmax is
unique). In other words, EX〜V [ΦcC (X)] ≥ 0 for all C ∈ Y \ {c} and all μ(x0) ∈ Dχ,e if and only if
hs(x0) = c for all x0 such that d(x, x0) ≤ , proving the required robustness certificate.
A.1.1 Robustness specification for smoothed soft classifiers
Consider a soft classifier H : X → P(Y) that for each input x returns a probability distribution H(x)
over the set of potential labels Y (e.g. H might represent the outputs of the soft-max layer of a neural
network). As in the case of hard classifiers, our methodology can be used to provide robustness
guarantees for smoothed soft classifiers obtained by applying a smoothing measure μ(x) to the input.
In this case, the smoothed classifier is again a soft classifier given by Hs(X) = EX〜*(x)[H(X)].
Let x be a fixed input point and write p = Hs(x) ∈ P(Y) to denote the distribution over labels.
A number of robustness properties about the soft classifier Hs at x can be phrased in terms of
Definition 2.2. For example, let Y = {1,..., K} and suppose that pi ≥ p ≥ •… ≥ PK so
that {1, . . . , k} are the top k labels at x. Then we can verify that the set of top k labels will not
change when moving the input from x to x0 with kx - x0 k ≤ by defining the specifications
φi,j(z) = H(z)i - H(z)j for i ∈ [1, k] and j ∈ [k + 1, K], and showing that all of these φi,j are
robustly certified at μ(χ) with respect to the set Dχ,e defined above. The case k = 1 corresponds to
robustness of the standard classification rule outputting the label with the largest score.
Another example is robustness of classifiers which are allowed to abstain. For example, suppose we
[♦II 1	1	1	∙ i' T	Γ∙ TT 1	1	.1	111	∙ .1	.1	1	.1
build a hard classifier h out of Hs which returns the label with the maximum score as long as the
gap between this score and the score of any other label is at least γ ; otherwise it produces no output.
Then we can certify that h will not abstain and return the label c = arg maxy∈Y py at any point close
to x by showing that every φc0 (z) = H(z)c - H(z)c，- γ, C = c, is robustly certified at μ(x) with
respect to Dx,.
A.2 Background on f-divergences
A number of well-known properties about f -divergences are used throughout the paper, both explicitly
and implicitly. Here we review such properties for the readers’ convenience. Proofs and further
details can be found in, e.g., (Csiszar et al., 2004; Liese & Vajda, 2006).
Recall that the f -divergences can be defined for any convex function f : R+ → R such that f(1) = 0.
We note that this requirement holds without loss of generality as the map x 7→ f(x) - f(1) is convex
whenever f is convex. Any f -divergence Df satisfies the following:
1.	Df(νkρ)≥0.
2.	Df (ρkρ) = 0, and Df (ν kρ) = 0 implies ν = ρ whenever f is strictly convex at 1.
3.	Df(F*(ν)kF*(ρ)) ≤ Df(V∣∣ρ) for any function F, where F*(ρ) is the push-forward of ρ.
4.	Df(V∣∣ρ) = Df(PkV) where f(u) = uf (U) is again convex with f(1) = 0.
A.3 B ounding Renyi divergences
We being with the optimization problem
max Ra (μ(x0)kμ(x))
x0	(10)
subject to ∣x - x0 ∣p ≤
13
Published as a conference paper at ICLR 2020
Since we have Rα(μ(x0)kμ(x)) = Ei Rα(μi(xi)kμi(xi)). The constraint can be rewritten as
X|xi-x0i|P ≤p
i
Forming the Lagrangian relaxation, we obtain
Im ax. TRa(〃i(Xi)k〃i(Xi)) + γ Σ2lxi - xi|p - €p	∙
x0:|Xi-xi∣≤e/γ/	∖i^	)
where the constraint |X0i - Xi | ≤ is implied by kX0 - Xkp ≤ . We can maximize separately over
each X0i to obtain
—TEp + Σ2 max	Ra(μi(Xi)Ilμi(χi)) + γ∣χi - Xi|p .
i x0i∈[xi-,xi+]
By weak duality, for anyγ ≥ 0, this is an upper bound on Eq. 10. We can minimize this bound over
≥ 0 to obtain the tightest bound.
The minimization over X0i for each i can be solved in closed-form or via as simple 1-dimensional
minimization problem for most smoothing measures.
A.4 Proof of theorem 1
For simplicity of exposition (and to avoid measure theoretic issues), we focus on the case where ν, ρ
have well defined densities ν(X), ρ(X) such that ρ(X) > 0 whenever ν(X) > 0.
We begin by rewriting the optimization problem in terms of the likelihood ratio r(X) = P(XX): We
have
XEJφ(x)] = X耳ρ[r(χ)φ(χ)] ,	Dfi(PkV) = XEyfiEX))] ,	XEyr(X)] = 1 ,
where the first two equalities follow directly by plugging in ν(X) = ρ(X)r(X) and the third is
obtained using the fact that ν is a probability measure. Using these relations, the optimization over ν
can be rewritten as
min E [r(X)φ(X)]
r≥0 X〜P
subject to JEρ[fi(r(X))] ≤ ei,	JEρ[r(X)] = 1 ,
(11)
where r ≥ 0 denotes that r(X) ≥ 0 ∀X ∈ X . The optimization over r is a convex optimization
problem and can be solved using Lagrangian duality as follows - we first dualize the constraints on r
to obtain
m≥nXEJ(X)φ(X)] + Eλi(XEyfi(r(X))] - e) + κ(1 - XEjr(X)]
min E	r(X)φ(X) +	λifi(r(X)) - κr(X) +κ -	λiE
r≥0 X〜P	z—*,	z—*,
ii
κ -	λiEi - E
〜	X〜P
i
max κr - rφ(X) -	λifi (r)
r≥0
i
κ - ∑λiei - XEEP
i
max r(κ - φ(X)) - fλ(r)
κ - y~^λiei - E [fλ(κ - φ(X))]
i	XEP
By strong duality, it holds that maximizing the final expression with respect to λ ≥ 0, κ achieves
the optimal value in Eq. 11. Thus, if the optimal value is smaller than 0, the specification is not
robustly certified and if it is larger than 0, the specification is robustly certified. Finally, since we are
14
Published as a conference paper at ICLR 2020
ultimately interested in proving that the objective is non-negative, we can restrict ourselves to λ ≥ 0
such that Pi λi = 1 (since if the optimal λ added up to something larger, we could simply rescale
the values to add up to 1 and multiply κ by the same scaling factor without changing the sign of the
objective function).
This concludes the proof of correctness of the certificate Eq. 6.
A.5 Proof of theorem 2
For the next result, we observe that when φ is ternary valued, the optimization over κ, λ above can be
written as
maχ K - V2 λiei - θafλ (K - I)- θbfλ(κ + I)- θcfλ (K),
κ,λ≥0
i
where θ = Pχ~ρ[Φ(X) = +1], θ = Pχ~ρ[Φ(X) = -1],θc = PX~ρ[Φ(X) = 0].
Writing out the expression for f *, We obtain
max min K - Xλii	- θa	(K	-	1)γa	- Xλifi(γa)	-	θb	(K + 1)γb	- Xλifi(γb)
- θc Kγc - X λifi(γa)
= min max K(1 - θaγa	-	θbγb	- θcγc) +	λi	θyfi (γy)	- i	+ θaγa	-	θbγb	,
γ≥0 λ≥0,κ
,	i	y∈{a,b,c}
where the second inequality follows from strong duality. The inner maximization is unbounded unless
γyθy = 1 ,	θyfi (γy) ≤ i .
y∈{a,b,c}	y∈{a,b,c}
One thing to note is that, we can rewrite these constraints in terms of ζ = θ γ, i.e. ζy = θyγy
for y ∈ {a, b, c}. These constraints ensure that ζ is a probability distribution over {+1, 0, -1} and
furthermore
θyfi(γy) = Dfi(ζkθ) .
y∈{a,b,c}
Thus, the second constraint above is equivalent to Dfi (ζkθ) ≤ i. Writing the optimization problem
in terms of ζ, we obtain
min
ζa,ζb,ζc≥0
ζa - ζb
subject to Dfi (ζkθ) ≤ i i = 1, . . . , M ,
ζa + ζb + ζc = 1 .
A.6 Closed-form certificates for the information-limited setting
In this section we present closed-form certificates for the information-limited setting which can be
derived from Theorem 2 for M = 1. The results are summarized in Table 4. In the next subsections
we present the derivation of the certificates for Hockey-Stick and Renyi divergences. The certificates
for the KL and infinite Renyi divergence can be derived by taking limits of the Renyi certificate (as
α → 1, ∞ respectively).
A.6.1 Calculation of certificate for hockey-stick divergence
The function f(u) = max(u - β, 0) - max(1 - β, 0) is a convex function with f(1) = 0. Then, we
have
fλ(u) = max (Uv — λmax(v — β, 0)) + λ max(1 — β, 0)
v≥0
max(βu, 0) + λ max(1 — β, 0) if u ≤ λ ,
∞	if u > λ .
15
Published as a conference paper at ICLR 2020
Divergence constraint	f(U)		Certificate
KL divergence KL(VkP) ≤ EKL		U log(u)	EKL ≤ -lθg(1 - (√θ∑ - √b)2)
Renyi divergences (α ≥ 0) Rα (V kρ) ≤ ER,α	sign(α — 1)(ua — 1)	ER,α ≤ - log(1 - θa - θb + 2η) θ θ (1-α)+θ (1-α) ʌ ( 1-α ) η = ( a	+	)	
Infinite Renyi divergence R∞(νkρ) ≤ ER,∞	C		—	eR,∞ ≤ - log(1 - (θa - θb))
HOCkey-StiCk divergences (β ≥ 0) DHS,β(VkP) ≤ EHS,β		[u - β]+ - [1 - β] +	EHS,β ≤ [产亿一气厂"11] +
Table 4: Certificates for various f -divergences for the information-limited setting. Note that the Renyi
divergences are not proper f-divergences, but are defined as Ra(V∣∣ρ) = α⅛ι log(1 + Df(Vkρ)).
The infinite Renyi divergence, defined as SuPx log(ν(x)∕ρ(x)), is obtained by taking the limit
α → ∞. All certificates depend on the gap between θa and θb. Notation: [u]+ = max(u, 0).
The certificate given by Eq. 6 in Theorem 1 for this divergence in the case of a smoothed hard
classifier takes the form
max
κ∈R,λ≥0
(K - -E [fλ(K - φ(X))])
∖	X〜P	)
λ ≥ 0
where the specification takes the values
φ(X)
w.p. θa ,
w.p. θb ,
w.p. 1-	θa-	θb .
Plugging in the expression for f * the objective function above takes the form
K — B (θa[κ — 1]+ + θb[κ + 1]+ + (1 — θa — θb)[κ] + ) — λ(C + maχ(1 — B, O)) ,
where we use the notation [u]+ = max(u, 0) and assumed the constraints K ≤ λ-	1 since the
objective is-∞ otherwise. If B ≤ 1, the objective is increasing monotonically in K, so the optimal
value is to set K to its upper bound λ- 1. Plugging this in, the possible values of the derivative with
respect to λ are
(β(1 - θb) - E if 0 ≤ λ < 1 ,
Bθa-	if1 < λ < 2 ,
Ii	if λ > 2 .
Thus, if E ≤ Bθa, the maximum is attained at 2, if Bθa ≤ E ≤ B(1 - θb), the maximum is attained at
1, else the maximum is attained at 0, leading to the certificate:
-1
B(1-θb)-E-1
B(1 + (θa - θb)) - 2E - 1
ifE≥B(1-θb) ,
ifBθa ≤E≤B(1-θb) ,
ifE≤Bθa .
Thus, the certificate is non-negative only if
E ≤ max
β(1 + (θa - θb))- 1
2
The case B ≥ 1 can be worked out similarly, leading to
< maxf β(-1 + (θa - θb)) + 1
≤ mιax
一1	2
,0
The two cases can be combined as
E ≤ max
β(θa - θb) -Ie - 1|
2
,0
16
Published as a conference paper at ICLR 2020
A.6.2 Calculation of certificate for RENYI divergence
We consider the cases α ≥ 1 and α ≤ 1 separately.
Case 1 (α ≥ 1) if α ≥ 1, the function f(u) = (uα - 1) is a convex function with f(1) = 0. Then,
we have
λ	if u ≤ 0
fλ(u) = maxUv — λ(vα — 1) = <	/	、 ɑ
λ '	v≥0	k /	[λ + λ(α - 1)(λuα) α-1	if u ≥ 0
α
=λ + λ(α- 1)( * °)) m .
λα
Suppose We have a bound on the Renyi divergence Ra(VkP) ≤ e. Then We know Df(VkP) ≤
exp((α - 1)e) - 1. Let β = a--1 and
B = θa(max(0, κ - 1))β + θb(max(0, κ + 1))β + (1 - θa - θb)(max(0, κ))β .
Then the certificate Eq. 6 simplifies to (after some algebra)
max K — λ exp((α — 1)e) — Bλ1-β(° - 0 .
λ≥0,κ	αβ
Setting the derivative With respect to λ to 0 and solving for λ, We obtain
λ = U —B— )(1)
α exp((α - 1))
and the optimal certificate reduces to
max κ — B1 exp (—
κβ
For this number to be positive, we need that κ ≥ 0 and
κ
—≥ eχp -5
B β	∖β
The LHS above evaluates to
_ 1
(θa max(0,1 - Y)β + θb max(0,1 + γ)β + 1 一 θa 一 θb) β
where Y = 1 ≥ °. Maximizing this expression with respect to Y, we obtain
θ--1一 θ--1
Y = θa-1 +。厂1 ,
so that the certificate reduces to
2βθaθb(θ-τ + θ--1)(-α-τ )+1 — θa — θb)( β) ≥ exp G
Taking logarithms noW gives the result.
∖-λ + λ 1-α(1 — α)(-U)(- 1-α)	if u ≤ 0 ,
∞	otherwise .
Case 2 (0 ≤ α ≤ 1) When 0 ≤ α ≤ 1, the function f(u) = (1 — uα ) is a convex function with
f(1) = 0. Then, we have
fλ(u) = max Uv — λ(1 — v-)
v≥0
Further, a bound Rα(VkP) ≤ — implies
Df (V kP) ≤ 1 — exp((α — 1)—) .
17
Published as a conference paper at ICLR 2020
Then the certificate from Eq. 6 reduces to
max κ + λ exp((α -
κ,λ≥0
__α	__α
—κ)~1-α + θb(-1 — κ)~1-α
with the constraint κ ≤ -1 (otherwise the certificate is -∞). Setting the derivative with respect to λ
to 0 and solving for λ, we obtain
eχp(S - 1)e(1-α))
λ =-------------------
αω
where
ω
αα
(θa(1 — Kr 1-α + θb(-1 — Kr1-α
Plugging this back into the certificate and setting β = ι-α, We obtain
eχp (— β
K + ——
ω
For this number to be positive, We require that
-i- ≥ eχp(三
一κω	∖p
The LHS of the above expression evaluates to
(θa (1 + γ)(-β) + θb(1 — Y)(-β) + 1 — θa — θb) (m
where Y = 一 1. Maximizing this expression over Y ∈ [0,1], we obtain the final certificate to be
1 — θa — θb + 2
1	、 (ɪ)∖ (-β)	/
%)(aI ≥ exP(彳
Taking logarithms, We obtain
≤ —log 1 — θa — θb + 2
θa-α+θb-α∖(1-α)
2
A.7 Information-limited robust certification and tight relaxations
A.7.1 Proof of theorem 4
At a high level, the proof shows that, in the information-limited case, to achieve robust certification
under an arbitrary set of constraints D it suffices to know the “envelope” of D with respect to all
hockey-stick divergences of order p ≥ 0, i.e. the function p 7→ maχν∈D DHS,β(νkρ) captures all
the necessary information to provide information-limited robust certification with respect to D.
We start by considering the following optimization problem:
min	E [Ψ(X)]
Ψ : XT{-1,0,+ 1},ν∈D X〜V
subject to E [1[Ψ(X) = +1]] ≥ θa ,
X〜P」、，
E [1[Ψ(X) = —1]] ≤ θb .
X〜P
(12)
In the information-limited setting, this problem attains the minimum expected value over φ ∈ S .
Here 1[φ(X) = 1] denotes the indicator function.
18
Published as a conference paper at ICLR 2020
It will be convenient to write this in a slightly different form: Rather than looking at the outputs of Ψ
as the +1, 0, -1, we look at them as vectors in R3:
Z=(001!,001!,001!)
and define
1
a=	-101
a+
a- =	001
Then, we can write the optimization problem Eq. 12 equivalently as
min E aTΨ(X)
Ψ i XTZ,ν∈D X〜VL	」
subject to E a+TΨ(X) ≥ θa ,
X〜PL '	j
E a-TΨ(X) ≤ θb .
X〜PL	' j
(13)
We first consider the minimization over Ψ for a fixed value of ν . We begin by observing that since the
objective is linear, the optimization over Ψ can be replaced with the optimization over the convex hull
of the set of Ψ that satisfy the constraints (Bubeck, 2013). Since each input x ∈ X can be mapped
independently of the rest, the convex hull is simply the cross product of the convex hull at every x, to
obtain the constraint set
Ψ : X 7→ P(Z) such that E aT+Ψ(X) ≥ θa, E aT-Ψ(X) ≤ θb
X 〜PL	X〜PL
Therefore, the optimization problem reduces to
min E aTΨ(X)
Ψ i X→P(Z) X〜VL	，」
subject to E a+TΨ(X) ≥ θa ,
X〜PL '	j
E a-TΨ(X) ≤ θb .
X〜P
(14)
This is a convex optimization problem in Ψ. Denote
MX )=VX
Considering the dual of this optimization problem with respect to the optimization variable Ψ, we
obtain
min E	aTΨ(X)r(X) -λa	E	a+TΨ(X)	-θa	+λb	E	a-TΨ(X)	-θb
Ψ X-pl	j	∖ X-pl ，	j )	∖ X〜P」	j
min λaθa - λbθb + E
min λaθa - λbθb + E
Ψ
X〜P
Ψ
X〜P
(r(X)a - λaa+ + λba-)>Ψ(X)
「( T(X) - λa∖τ	]
0	Ψ(X) .
-r(X) + λb
Since we can choose Ψ(x) independently for each x ∈ X, we can minimize each term in the
expectation independently to obtain
r(x) - λa T
min	0 Ψ(x) = min(r(x) - λa, 0, -r(x) + λb) .
Ψ(x)∈P(Z) r(x) +λb
This implies that the Lagrangian evaluates to
λaθa - λbθb + E [min(r(X) - λa, 0, r(X) + λb)] .
X〜P
We now consider two cases:
19
Published as a conference paper at ICLR 2020
Case 1 (λa ≥ λb ≥ 0) In this case, we can see that
min(r(X) - λa,0, -r(X) + λb) = min(r(X) - λa,0) + min(-r(X) + λb,0)
= r(X) - λa - max(r(X) - λa, 0) - max(r(X) - λb, 0) .
Then, the Lagrangian reduces to
λaθa - λbθb + E [r(X) - λa] - E [max(r(X) - λa, 0)] - E [max(r(X) - λb, 0)]
= 1 - λa(1 - θa) - λbθb - (DHS,λa (νkρ) + max(1 - λa, 0)) - (DHS,λb (ν kρ) + max(1 - λb, 0))
Case 2 (λb ≥ λa ≥ 0) In this case, we can see that
min(r(X) - λa,0, -r(X) + λb) = min(r(X) - λa, -r(X) + λb)
r(X) - λa + 2min(θ, λa+^b - r(X)
r(X) - λa - 2 max r(X) -
λa + λb
,0
2
Then, the Lagrangian reduces to
λaθa - λbθb + E [r(X) - λa] - 2 E
max (r(X) — 'a ； Xb, 0
1 - λa (1 - θa) - λbθb - 2 (DHS λa + λb (VkP) + max (1------ɪ~~, 0
We know that 1 - θa ≥ θb and λb ≥ λa. If λb > λa, by choosing λ0a = λa + κ and λ0b = λb - κ for
some small κ > 0, we know that the the sum of the first three terms would reduce while the final
term would remain unchanged. Thus, at the the optimum in this case, we can assume λa = λb and
we obtain
1 - λa(1 - θa) - λaθb - 2(DHS,λa (ν kρ) + max(1 - λa, 0))
Final analysis of the Lagrangian Combining the two cases we can write the dual problem as
max 1 - λa(1 - θa) - λbθb - (DHS,λa (ν kρ) + max(1 - λa, 0))
λa≥λb≥0
- (DHS,λb(νkρ) + max(1 - λb,0)) .
(15)
By strong duality, the optimal value of the above problem precisely matches the optimal value of
Eq. 14 (and hence Eq. 12). Thus, information limited robust certification with respect to D holds if
and only if Eq. 15 has a non-negative optimal value for each ν ∈ D. Since we have that
mν∈aDxDHS,λa(νkρ)=λa ,	mν∈aDxDHS,λb(νkρ)=λb ,
information-limited robust certification holds if and only if the optimal value of
max 1 - λa(1 - θa) - λbθb - (λa + max(1 - λa, 0)) - (λb + max(1 - λb, 0))	(16)
λa≥λb≥0	a
is non-negative. Further, since the optimal value only depended on the value of DHS,β(νkρ) for
β ≥ 0, it is equivalent to information-limited robust certification with respect to DHS.
The above argument also shows that in this case, information-limited robust certification with respect
to D is equivalent to requiring that the following convex optimization problem has a non-negative
optimal value:
max 1 - λa(1 -	θa)	- λbθb	-	(∈λa	+ [1 - λa] + ) -	(eλb	+	[1	-	λb] + ) ∙	(17)
λa≥λb≥0
Let λa, λ^ be the optimal values attained. Since this certificate depends only on the value of two
Hockey-stick divergences at λa, λ^, it must coincide with the application of theorem 2 to the constraint
set DHS defined by constraints on these hockey-stick divergences (as we know that 2 computes the
optimal certificate for any constraint set defined only by a set of f-divergences). This observation
completes the proof.
20
Published as a conference paper at ICLR 2020
A.7.2 Gaussian smoothing measures
Theorem 4 gives us the optimal limited-information certificate problem provided that we can compute
,,max∕ DHs,β(μ(χ0)kμ(χ))
x0 :d(x,x0 )≤e
for each β ≥ 0. In particular, when μ is a Gaussian measure μ(x) = N(x, σ21), We can leverage the
following result from Balle & Wang (2018).
Lemma 6. Let Ψg be the CDF of a standard normal random variable N(0, 1). For any β ≥ 0 and
x ∈ Rd we have
“：1*的 DHS，e (μ(xO)kμ(X))=ψg 层
log(β)σ
- βΨg
2σ
log(β)σλ
2e )
- [1 - β]+
—
—

—
Applying Eq. 17 to the expression in Lemma 6 proves Corollary 5.
Proof of Corollary 5. With the notation from Theorem 4 we have, for β ≥ 0,
log(β)σ、
2e )
— βΨg (-2σ - log；：") - max(1 - β, 0).
Plugging this expression into Eq. 17 allows us to verify information-limited robust certification of
N(x0,σ2I) with respect to Dχ,e = {N(x0,σ2I) : kX - /1卜 ≤ e} by solving
max 1 - λa(1 - θa) - λbθb
λa≥λb≥0
—
—
(工-log(λa)σ)
log(λa)σ))
(工-log(λb)σ)
log(λb)σ
-2^~
Eq. 9 then follows from setting the derivatives of this expression to 0 with respect to λa , λb and
imposing the condition that the optimal solution is non-negative.	口
To check that Corollary 5 is equivalent to the optimal certification in (Cohen et al., 2019, Theorem
1) we first recall that, in our notation, their result can be stated as: the class of specifications
S in Definition 2.1 is information-limited robustly certified at ρ = N X, σ2I with respect to
Dχ,e = {N(x0,σ21) : kX - x0k2 ≤ e} if and only if
—≤ ψ-1(θa) - ψ-1(θb) .	(18)
The equivalence between Eq. 9 and Eq. 18 now follows from the identity 1 - Ψg (θ) = Ψg (-θ) and
the monotonicity of Ψg :
ψg (ψ-1(θa)- σ) + ψg (ψ-1(1 - θb)- σ) ≥1
0 ψg (ψ-ι(θa) - σ)≥ 1 - Ψg (ψ-ι(i-θb) - σ)
O ψg (ψ--1(θa) - I)≥ ψg (σ - ψ-1(1-θb))
^⇒ ψ-1(θa)- σσ ≥ σσ- ψ-1(1 - %)
O ψ-1(θa)+Ψ-1(1-θb) ≥ 至
σ
O Ψ-1(θa) - Ψ-1(θb) ≥ 主.
σ
21
Published as a conference paper at ICLR 2020
A.7.3 Relation to PixelDP
Pixel differential privacy (pixelDP) was introduced in Lecuyer et al. (2019) using the same similarity
measure between distributions used in differential privacy: a distribution-valued function G : Rd →
P(Z) satisfies (ε, τ)-pixelDP with respect to `p perturbations if for any kx - x0kp ≤ 1 it holds that
DDP,eε(G(x)kG(x0)) ≤ τ, where
DDP,eε(G(x)kG(x0))=sup	P	[X∈E]-eε P	[X0∈E]	(19)
E ∖X 〜G(X)	X0 〜G(x0)	)
and the supremum is over all (measurable) subsets E of Z. In particular, Lecuyer et al. show that
using a smoothing measure μ satisfying PixelDP with respect to 'p leads to adversarially robust
classifiers against `p perturbations.
To show that their result fits as a particular instance of our framework, take P = μ(x) and fix ε ≥ 0
and T ∈ [0,1]. Due to the symmetry of the constraint kx - x0kp ≤ 1, if μ satisfies (ε,τ )-pixelDP with
respect to 'p perturbations, then we have the relaxation condition {μ(χ0) : ∣Ix - χ0kp ≤ 1} ⊆ Dε^,
where
Dε,τ = {ν : DDP,eε (ν kρ) ≤ τ and DDP,eε (ρkν) ≤ τ} .	(20)
Now we recall that Barthe & Olmedo (2013) noticed that DDP,eε is equivalent to the hockey-stick
divergence DHS,β of order β = eε . Thus, since f -divergences are closed under reversal (property
4 in Appendix A.2), we see that the constraint set Dε,τ can be directly written in the form DF (cf.
Section 2.2).
The main result in Lecuyer et al. (2019) is a limited-information black-box certification method for
smoothed classifiers. The resulting certificate for, which provides certification with respect to Dε,τ,
is given by
T ≤ θa-e2εθb
eε + 1
(21)
For comparison, the certificate we obtain for the relaxation {ν : DDP,eε (νkρ) ≤ T} of Dε,τ (HS
certificate in Table 4) already improves on the certificate by Lecuyer et al. whenever θa - θb ≥
(β - 1)(1 - θa - θb), which, e.g., always holds in the binary classification case. Furthermore, since
Theorem 2 provides optimal certificates for D, we have the following result.
Corollary 7. The optimal certificates for the constraint set D (cf. Eq. 20) obtained from Theorem 2
are stronger than those obtained from Eq. 21.
A.8 Efficient sampling and f-divergence computation for norm-based
SMOOTHING MEASURES
Lemma 8. The smoothing measure μ : X → P(X) with density μ(x)[z] H exp(-∣z - Xk) satisfies
max R∞(μ(x + δ)∣μ(x)) ≤ E .
kδk≤
if ∣x∣ is any norm. Further, if f is convex function with f (1) = 0 such that f (1) is convex and
monotonically increasing in u, then
max Df (μ(x + δ)Hμ(X)) ≤ max V EGJf(exp(-kX - δk + IIXk))] .	(22)
kδk≤e	kδk=eX 〜μ⑼
Proof. By the triangle inequality, we have
μ(X )[z] —	II II	∙√∣n V aγτ√llτ ∙√ll∖
( w 1 — exp(kz - Xk - kz - X k) ≤ eχp(kx - X k)
μ(x)[z]
so that
R∞(μ(X0)kμ(X)) ≤∣∣x - X0k ∙
Similarly, for f that satisfy the conditions of the theorem, it can be shown that Df (μ(X0)kμ(X)) is
convex in x0 so that its maximum over the convex SetkXO - Xk ≤ E is attained on the boundary. □
22
Published as a conference paper at ICLR 2020
For several norms, the optimization problem in Eq. 22 can be solved in closed form. These include
'ι,'2, '∞ norms and the matrix spectral norm and nuclear norm (the final two are relevant when X is
a space of matrices). The results are documented in Table 5. Thus, every f -divergence that meets the
conditions of Lemma 8 can be estimated efficiently for these norms. In particular, the divergences
that are induced by the functions f (u-α) for any monotonic convex function f and α ≥ 0 satisfy
this constraint. This gives us a very flexible class of f -divergences that can be efficiently estimated
for these norm-based smoothing measures.
Constraint on δ	Bound on Eq. 22	Sampling from X 〜 μ(0)
∣δ ∣1 ≤	E	[f(exp(∣∣X -Ee0k1-kX∣∣1))] X 〜μι(0)		Xi 〜Lap(0,1) iid
∣δ ∣2 ≤	E	[f (CXP(IX - ee0k2 - kXk2))] X 〜μ2(0)	X = Ru R 〜Γ(d, 1) U 〜U(∂B2)	
∣δ ∣∞ ≤	E Jf(exp(∣X -e1∣∣∞ -∣X∣∞))] X 〜μ∞(0)	X = Ru R 〜Γ(d +1,1) U ∈ U(B∞)	
∣δ ∣nuc ≤	Ew [f(exp(UU [[s]]VT Y [[e0]]∣Lc-ksk1))] S 〜μι(0) U,V 〜U (O)	X = U [[s]]V t S 〜μι, U,V 〜U(O)
∣δ ∣? ≤	E	[f(exp(∣∣U [[s]]VT - e [[e0]]∣∣?-|同匕))] S 〜μ∞(x)	? U,V 〜U (O)	X = U [[s]]V t S 〜μ∞, U,V 〜U(O)
Table 5: Bounds on f -divergences: e0 is the vector with 1 in the first coordinate and zeros in all other
coordinates and 1 is the vector with all coordinates equal to 1. μp refers to the smoothing measure
induced by the `p norm, U(S) refers to the uniform measure over the set S, O is the set of orthogonal
matrices and Bp = {kzkp ≤ 1} is the unit ball in the `p norm.
Efficient sampling The only other requirement for obtaining a certificate computationally is to be
able to sample from μ(χ) to estimate θ0, θb. Since μ(χ) is log-concave, there are general purpose
polynomial time algorithms for sampling from this measure. However, for most norms, more efficient
methods exist, as outlined below.
The random variable X 〜μ(χ) can be obtained as X = X + Z with Z 〜μ(0). Thus, to sample
from μ(x) for any X it is enough to be able to sample from μ(0). For |卜||「this reduces to sampling
from a Laplace distribution which can be done easily. For ∣∣∙∣∣∞, (Steinke & Ullman, 2016) give
the following efficient sampling procedure: first sample r from a Gamma distribution with shape
d + 1 and mean d + 1, i.e, r 〜Γ(d + 1,1), and then sample each Z%, i ∈ [d], uniformly from [-r, r].
Theorem 9 gives a short proof of correctness for this procedure. Theorem 10 also has a similar result
for the case of ∣∣∙k2 and Table 5 lists the sampling procedures for several norms.
Theorem 9.	The random variable Z ∈ Rd obtained by first sampling R 〜Γ(d + 1,1) and then
sampling each Z七, i ∈ [d], uniformly from [-R, R] has density α e-kzk∞.
Proof. We first compute the normalization constant for a density of the form α e-kzk∞ as follows:
Z e-kzk∞dz = Z ∞ Z 1[∣z∣∞
Rd	0	Rd
∞
e-tdt =	2ddtd-1e-tdt = d!2d .
0
Next we show the density of Z satisfies pZ(z) = e-kzk∞ /(d!2d) by noting that conditioned on
R = r we have pZ|R=r(z) = 1[∣z∣∞ ≤ r]/(2r)d because of the uniform sampling used in each
23
Published as a conference paper at ICLR 2020
coordinate, and integrating over R sampled from a Gamma distribution with shape d + 1 and mean
d + 1 yields
PZ(Z)=广pz∣R=r(z)pR(r)dr =广 1[kzk∞≤ r] Tdr = ɪ 广 e-dr =二
PZ( )	J0	PZIR=r(	)pR( )	J0	(2r)d	d!	d!2d	∕∣z∣∞	d!2d
□
Theorem 10.	The random variable Z ∈ Rd obtained by first sampling Z0 〜N(0, I) and R 〜
Γp(d, 1) and then taking Z = R1系 has density b e-kzkk2. Here Γp (d, a) denotes the generalized
Gamma distribution of order P > 0 with shape d and scale a.
Proof. First note that W = 口禹 〜 U(B2); i.e. it is uniform on the '2 ball of radius 1. Therefore,
RW is uniform on the `2 ball of radius R and the conditional density of Z given R is given by
,jɔ , z ^√ʌ —	l["z"2 r]F("∕2)	^⅛iτιpp	R lɔoo HpτiQitx^ g ∙n Z/p、(*v	d--1 -- Tp	We	oet
pZ∣R=r (Z) =	-2∏d∕2rd-ι----.	Since	R has density pR(r)	Z	r e ,	we	get
∞
PZ (Z) =
0
PZ|R=r(Z)PR(r)dr
Z
∞
0
1[∣∣z∣∣2=r]Γ(d∕2)
2∏d∕2γd-1
rd1erp dr
Z e-kzk2p
□
A.9 Algorithm for full-information certification
In this section we describe the subroutines used in Algorithm 1. First we describe a generic procedure
to provide high-probability confidence intervals for estimating expectations, then we give a detailed
description of the subroutines.
A.9.1 High-confidence estimates of expected values
Let Z1 , . . . , ZN be independent, identically distributed random variables with range R and mean m.
Let the empirical mean be Z= N PN=I Zi and the empirical variance be σ2 = N PN=I(Zi 一 Z)2.
Applying Bernstein’s inequality to the sum and the sum of the squares of these random variables, we
get the empirical Bernstein bound (Audibert et al., 2009), which states that with probability at least
1 一 Z,
/ 2σ2 log(3∕Z)	3Rlog(3∕Z)
IZ - m| ≤ V -N- + —t-.	(23)
The main benefit of the above inequality is that as long as the variance of the sample Zι,..., ZN is
small, the convergence rate becomes essentially O(1∕N) instead of the standard O(1∕√N). Also,
since Eq. 23 only contains empirical quantities apart from the range R, it can be used to obtain
computable bounds for the expectation μ: with probability at least 1 一 Z,
Z 一 r 2σ2 log(3∕Z) 一 3Rlog(3∕Z) ≤ m ≤ Z+ r 2σ2 log(3∕Z) ∣ 3Rlog(3∕Z) .	(24)
A.9.2 Subroutines for Algorithm 1
The bound in Eq. 24 can be applied to approximate the expectation in Eq. 6 with high probability for
given values of λ and κ. More specifically, if the function fλ(κ 一 φ(∙)) is bounded with range R,
then taking N samples Xι,...,XN independently from ρ, and defining Zi = f； (K 一 φ(Xi)), and
Z and σ2 as above, Eq. 24 implies that with probability at least 1 一 Z,
E fλ(κ — φ(Xi))] ≤ z + J2。21?3/Z) +
X 〜P	V N
3R 1og(3∕Z)
N
(25)
24
Published as a conference paper at ICLR 2020
Plugging in this bound to Eq. 6 gives a high-probability lower bound for the function to be maximized
for any given λ and κ.
Details of the above procedures are given in Algorithm 3. We use an off-the-shelf convex optimization
solver (Diamond & Boyd, 2016) in the ESTIMETEOPT subroutine.
Algorithm 3 Subroutines for Algorithm 1
function ESTIMATEOPT(ρ, φ, N, {fi}, {i })
Sample X 1,..., XN 〜P and obtain κ* and λ* by solving Eq. 6 with EX〜ρ[fλ(κ - φ(X))]
replaced by N PN=1 fλ (K - φ(Xi)) and the additional constraints f；* (κ-a) < ∞, f；* (κ-b) <
∞.
return κ*, λ*.
end function
function UPPERCONFIDENCEBOUND(ρ, φ, N, {fi}M=1, {g}M=1, a, b, λ, κ, ζ)
Sample X 1,..., X N 〜P and compute Zi — f； (κ - φ(X i)) for i = 1,..., N.
__ 7∖T	.ʃ
Set Z 一 PiN Z .
Set σ - F-Z)2.
Set R = maxx∈(a,b) f； (κ - x) - minx∈(a,b) f； (κ - x).
Set	____________
∕2σ2 log(3∕Z)	3Rlog(3∕Z)
Eub J Z + V —N— + —N—.
return Eub .
end function
A.10 `0 SMOOTHING MEASURE
We can also handle discrete perturbations in our framework. A natural case to consider is `0
perturbations. In this case, we assume that X = Ad where
A = {1, .. .,K}
is a discrete set. Then, we can choose
d	1[zi6=xi]
μ(x)[z] = ∏p1[zi=x4Kq-1)	(26)
i=1
where p + q = 1, p ≥ q ≥ 0, and p denotes the probability that the measure retains the value of x
and Kq-i denotes a uniform probability of switching it to a different value. In this case, it can be
shown that for every α > 0 that
八。g(p( (K⅛p 尸 + K-1 ( V 尸 + "叫
Ra(〃(x0)k〃(X))= kχ - χ0k0 -----------------------；-------------------
α- 1
\ /
so that we can derive a certificate with respect to '0 perturbations using any set of Renyi divergences
(or combinations of theses).
This can be extended to structured discrete perturbations by introducing coupling terms between the
perturbations:
d
μ(x)[z] Y Yp1[zi=xi]
i=1
1[zi 6=xi]
exp
d-1
η1[zi = xi ]1[zi+1
xi+1]
This would correlate perturbations between adjacent features (which for example may be useful to
model correlated perturbations for time series data). Since this can be viewed as a Markov Chain,
Renyi divergences between μ(x), μ(x0) are still easy to compute.
25
Published as a conference paper at ICLR 2020
A.11 COMPARISON WITH LECUYER ET AL. (2019) ON `1 PERTURBATIONS
Here we compare our certificates to Lecuyer et al. (2019) on the MNIST, CIFAR-10 and ImageNet
datasets. The smoothing distribution is as described in A.8; a zero mean Laplacian distribution with
smoothing value defined by the scale of the distribution. We first describe the hyperparameters used
in training and certification for each of the datasets. For all datasets, images were normalized into a
[0,1] range.
MNIST hyperparameters: We trained a standard three layer CNN ReLU classifier for 50,000
steps with a batch size of 128 and a learning rate of 0.001. The smoothing value during training
was set to 1.0. For certification We use N = 1K, N = 10M, Z = .99, and sweep over a range of
smoothing values between 0.5 and 1.5 and report the best certificate found. Certified accuracy is
reported on 1,000 MNIST test set images.
CIFAR-10 hyperparameters: We trained a Wide ResNet classifier for 50,000 training steps with
a batch size of 32 and a learning rate of 0.001. The smoothing value during training was set to 0.2.
For certification we use N = 1K, N = 1M, Z = .99, and sweep over a range of smoothing values
between 0.1 and 0.5 and report the best certificate found. Certified accuracy is reported on 1,000
CIFAR-10 test set images.
ImageNet hyperparameters: We trained a ResNet-152 classifier for 1 million training steps with
a batch size of 16 and an initial learning rate of 0.1 that is decayed by a factor of ten every 25,000
steps. The smoothing value during training was set to 0.1. For certification we use N = 1K, N =
100K, Z = .99, and sweep over a range of smoothing values between 0.05 and 0.25 and report the
best certificate found. Certified accuracy is reported on 500 ImageNet validation set images.
Table 6: `1 comparison with Lecuyer et al. (2019) on MNIST.
Certificate
Lecuyer et al. (2019)
Ours
Certified Accuracy
e = 1 e = 2 e = 3 e = 4 e = 5 e = 6 e = 7
0.772	0.548	0.424	0.061	0	0	0
0.860	0.716	0.584	0.447	0.325	0.201	0.017
(a)	CIFAR-10: `1 robustness
(b)	ImageNet: `1 robustness
Figure 3: Certified accuracy under `1 perturbations on CIFAR-10 and ImageNet.
Results for MNIST can be seen in Table 6, CIFAR-10 and ImageNet results are shown in Figure 3.
We significantly outperform Lecuyer et al. (2019) on all three datasets.
26