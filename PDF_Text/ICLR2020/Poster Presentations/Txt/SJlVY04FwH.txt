Published as a conference paper at ICLR 2020
Convergence of Gradient Methods on Bilin-
ear Zero-Sum Games
Guojun Zhang & Yaoliang Yu
Department of Computer Science
University of Waterloo
Vector Institute
{guojun.zhang,yaoliang.yu}@uwaterloo.ca
Ab stract
Min-max formulations have attracted great attention in the ML community due to
the rise of deep generative models and adversarial methods, while understanding
the dynamics of gradient algorithms for solving such formulations has remained
a grand challenge. As a first step, we restrict to bilinear zero-sum games and
give a systematic analysis of popular gradient updates, for both simultaneous and
alternating versions. We provide exact conditions for their convergence and find
the optimal parameter setup and convergence rates. In particular, our results offer
formal evidence that alternating updates converge “better” than simultaneous ones.
1	Introduction
Min-max optimization has received significant attention recently due to the popularity of generative
adversarial networks (GANs) (Goodfellow et al., 2014), adversarial training (Madry et al., 2018) and
reinforcement learning (Du et al., 2017; Dai et al., 2018), just to name some examples. Formally,
given a bivariate function f (x, y), We aim to find a saddle point (x*, y*) such that
f (x*, y) ≤ f (x*, y*) ≤ f (x,y),∀x ∈ Rn, ∀y ∈ Rn.	(1.1)
Since the beginning of game theory, various algorithms have been proposed for finding saddle points
(ArroW et al., 1958; Dem’yanov & Pevnyi, 1972; Gol’shtein, 1972; Korpelevich, 1976; Rockafellar,
1976; Bruck, 1977; Lions, 1978; Nemirovski & Yudin, 1983; Freund & Schapire, 1999). Due to its
recent resurgence in ML, neW algorithms specifically designed for training GANs Were proposed
(Daskalakis et al., 2018; Kingma & Ba, 2015; Gidel et al., 2019b; Mescheder et al., 2017). HoWever,
due to the inherent non-convexity in deep learning formulations, our current understanding of the
convergence behaviour of neW and classic gradient algorithms is still quite limited, and existing
analysis mostly focused on bilinear games or strongly-convex-strongly-concave games (Tseng, 1995;
Daskalakis et al., 2018; Gidel et al., 2019b; Liang & Stokes, 2019; Mokhtari et al., 2019b). Non-
zero-sum bilinear games, on the other hand, are knoWn to be PPAD-complete (Chen et al., 2009) (for
finding approximate Nash equilibria, see e.g. Deligkas et al. (2017)).
In this Work, We study bilinear zero-sum games as a first step toWards understanding general min-max
optimization, although our results apply to some simple GAN settings (Gidel et al., 2019a). It is
Well-knoWn that certain gradient algorithms converge linearly on bilinear zero-sum games (Liang
& Stokes, 2019; Mokhtari et al., 2019b; Rockafellar, 1976; Korpelevich, 1976). These iterative
algorithms usually come with two versions: Jacobi style updates or Gauss-Seidel (GS) style. In
a Jacobi style, We update the tWo sets of parameters (i.e., x and y) simultaneously Whereas in a
GS style we update them alternatingly (i.e., one after the other). Thus, Jacobi style updates are
naturally amenable to parallelization while GS style updates have to be sequential, although the latter
is usually found to converge faster (and more stable). In numerical linear algebra, the celebrated
Stein-Rosenberg theorem (Stein & Rosenberg, 1948) formally proves that in solving certain linear
systems, GS updates converge strictly faster than their Jacobi counterparts, and often with a larger set
of convergent instances. However, this result does not readily apply to bilinear zero-sum games.
Our main goal here is to answer the following questions about solving bilinear zero-sum games:
•	When exactly does a gradient-type algorithm converge?
1
Published as a conference paper at ICLR 2020
Table 1: Comparisons between Jacobi and Gauss-Seidel updates. The second and third columns show
when exactly an algorithm converges, with Jacobi or GS updates. The last column shows whether the
convergence region of Jacobi updates is contained in the GS convergence region.
Algorithm	Jacobi	Gauss-Seidel	Contained?
GD	diverges	limit cycle	N/A
EG	Theorem 3.2	Theorem 3.2	if βι + β2 + α < 2∕σ2
OGD	Theorem 3.3	Theorem 3.3	yes
momentum	does not converge	Theorem 3.4	yes
Table 2: Optimal convergence rates. In the second column, β* denotes a specific parameter that
depends on σ1 and σn (see equation 4.2). In the third column, the linear rates are for large κ. The
optimal parameters for both Jacobi and Gauss-Seidel EG algorithms are the same. α denotes the step
size (α1 = α2 = α), and β1 and β2 are hyper-parameters for EG and OGD, as given in §2.
Algorithm	α	β1	β2	Rate exponent	Comment
EG	〜0	2/。2+σn)	β1	〜1 - 2∕κ2	Jacobi and Gauss-Seidel
Jacobi OGD	2βι	β*	β1	〜1 — 1∕(6κ2)	β1 = β2 = α∕2
GS OGD	√2∕σι	√2σ"σ2+嘘)	0	〜1 — 1∕κ2	β1 and β2 can interchange
•	What is the optimal convergence rate by tuning the step size or other parameters?
•	Can we prove something similar to the Stein-Rosenberg theorem for Jacobi and GS updates?
Contributions We summarize our main results from §3 and §4 in Table 1 and 2 respectively, with
supporting experiments given in §5. We use σ1 and σn to denote the largest and the smallest singular
values of matrix E (see equation 2.1), and K := σι∕σn denotes the condition number. The algorithms
will be introduced in §2. Note that we generalize gradient-type algorithms but retain the same names.
Table 1 shows that in most cases that we study, whenever Jacobi updates converge, the corresponding
GS updates converge as well (usually with a faster rate), but the converse is not true (§3). This
extends the well-known Stein-Rosenberg theorem to bilinear games. Furthermore, Table 2 tells us
that by generalizing existing gradient algorithms, we can obtain faster convergence rates.
2	Preliminaries
In the study of GAN training, bilinear games are often regarded as an important simple example
for theoretically analyzing and understanding new algorithms and techniques (e.g. Daskalakis et al.,
2018; Gidel et al., 2019a;b; Liang & Stokes, 2019). It captures the difficulty in GAN training and can
represent some simple GAN formulations (Arjovsky et al., 2017; Daskalakis et al., 2018; Gidel et al.,
2019a; Mescheder et al., 2018). Mathematically, bilinear zero-sum games can be formulated as the
following min-max problem:
minx∈Rn maxy∈Rn x>Ey + b>x + c>y.	(2.1)
The set of all saddle points (see definition in eq. (1.1)) is:
{(x, y) | Ey + b = 0, E>x + c = 0}.	(2.2)
Throughout, for simplicity we assume E to be invertible, whereas the seemingly general case with
non-invertible E is treated in Appendix G. The linear terms are not essential in our analysis and
we take b = c = 0 throughout the paper1. In this case, the only saddle point is (0, 0). For bilinear
games, it is well-known that simultaneous gradient descent ascent does not converge (Nemirovski
& Yudin, 1983) and other gradient-based algorithms tailored for min-max optimization have been
proposed (Korpelevich, 1976; Daskalakis et al., 2018; Gidel et al., 2019a; Mescheder et al., 2017).
These iterative algorithms all belong to the class of general linear dynamical systems (LDS, a.k.a.
1If they are not zero, one can translate x and y to cancel the linear terms, see e.g. Gidel et al. (2019b).
2
Published as a conference paper at ICLR 2020
matrix iterative processes). Using state augmentation z(t) := (x(t), y(t)) we define a general k-step
LDS as follows:
z(t) = Pik=1 Aiz(t-i) +d,
(2.3)
where the matrices Ai and vector d depend on the gradient algorithm (examples can be found in
Appendix C.1). Define the characteristic polynomial, with A0 = -I:
p(λ) := det(Pik=0 Aiλk-i).
(2.4)
The following well-known result decides when such a k-step LDS converges for any initialization:
Theorem 2.1 (e.g. Gohberg et al. (1982)). The LDS in eq. (2.3) converges for any initialization
(z(0),..., z(kT)) iff the spectral radius r := max{∣λ∣ : p(λ) = 0} < 1, in which case {z(t)}
converges linearly with an (asymptotic) exponent r.
Therefore, understanding the bilinear game dynamics reduces to spectral analysis. The (sufficient and
necessary) convergence condition reduces to that all roots of p(λ) lie in the (open) unit disk, which
can be conveniently analyzed through the celebrated Schur’s theorem (Schur, 1917):
Theorem 2.2 (Schur (1917)). The roots ofa real polynomial p(λ) = a0λn + aιλn-1 + •一+ an are
within the (open) unit disk of the complex plane iff ∀k ∈ {1, 2, . . . , n}, det(Pk Pk> - Qk>Qk) > 0,
where Pk , Qk are k × k matrices defined as: [Pk]i,j = ai-j 1i≥j, [Qk]i,j = an-i+j 1i≤j.
In the theorem above, we denoted 1S as the indicator function of the event S, i.e. 1S = 1 if S
holds and 1S = 0 otherwise. For a nice summary of related stability tests, see Mansour (2011). We
therefore define Schur stable polynomials to be those polynomials whose roots all lie within the
(open) unit disk of the complex plane. Schur’s theorem has the following corollary (proof included in
Appendix B.2 for the sake of completeness):
Corollary 2.1 (e.g. Mansour (2011)). A real quadratic polynomial λ2 + aλ + b is Schur stable
iffb < 1, |a| < 1 + b; A real cubic polynomial λ3 + aλ2 + bλ + c is Schur stable iff |c| < 1,
|a+ c| < 1 + b, b - ac < 1 - c2; A real quartic polynomial λ4 + aλ3 + bλ2 + cλ + d is Schur stable
iff |c - ad| < 1 - d2, |a + c| < b + d + 1, and b < (1 + d) + (c - ad)(a - c)/(d - 1)2.
Let us formally define Jacobi and GS updates: Jacobi updates take the form
x(t) = T1(x(t-1), y(t-1), . . . , x(t-k), y(t-k)), y(t) = T2(x(t-1), y(t-1), . . . , x(t-k), y(t-k)),
while GaUss-Seidel updates replace x(t-i) with the more recent x(t-i+1) in operator T2, where
T1 , T2 : Rnk × Rnk → Rn can be any update functions. For LDS updates in eq. (2.3) we find a nice
relation between the characteristic polynomials of Jacobi and GS updates in Theorem 2.3 (proof in
Appendix B.1), which turns out to greatly simplify our subsequent analyses:
Theorem 2.3 (Jacobi vs. Gauss-Seidel). Let p(λ, Y) = det(Pk=0(γLi + Ui)λk-i), where Ai =
Li + Ui and Li is strictly lower block triangular. Then, the characteristic polynomial of Jacobi
updates is p(λ, 1) while that of Gauss-Seidel updates isp(λ,λ).
Compared to the Jacobi update, in some sense the Gauss-Seidel update amounts to shifting the
strictly lower block triangular matrices Li one step to the left, as p(λ, λ) can be rewritten as
det Pik=0(Li+1 + Ui)λk-i , with Lk+1 := 0. This observation will significantly simplify our
comparison between Jacobi and Gauss-Seidel updates.
Next, we define some popular gradient algorithms for finding saddle points in the min-max problem
min max f(x, y).
xy
(2.5)
We present the algorithms for a general (bivariate) function f although our main results will specialize
f to the bilinear case in eq. (2.1). Note that we introduced more “step sizes” for our refined analysis,
as we find that the enlarged parameter space often contains choices for faster linear convergence (see
§4). We only define the Jacobi updates, while the GS counterparts can be easily inferred. We always
use α1 and α2 to define step sizes (or learning rates) which are positive.
3
Published as a conference paper at ICLR 2020
Gradient descent (GD) The generalized GD update has the following form:
X(HI)= X⑶-αι Vxf (x(t), y(t)),	y(t+1) = y(t) + αZyf (x(t), y(t)).	(2.6)
When α1 = α2, the convergence of averaged iterates (a.k.a. Cesari convergence) for convex-concave
games is analyzed in (BrUck,1977; NemiroVski & YUdin,1978; Nedic & Ozdaglar, 2009). Recent
progress on interpreting GD with dynamical systems can be seen in, e.g., Mertikopoulos et al. (2018);
Bailey et al. (2019); Bailey & PilioUras (2018).
Extra-gradient (EG) We stUdy a generalized Version of EG, defined as follows:
X(t+1/2) = X(t) - γ1Vxf(X(t), y(t)), y(t+1/2) = y(t) + γ2Vyf(X(t), y(t));	(2.7)
x(t+1) = X㈤-αιVχf (x(t+1/2), y(t+1/2)), y(t+1) = y㈤ + αNy f (x(t+1/2), y(t+1/2)). (2.8)
EG was first proposed in KorpeleVich (1976) with the restriction α1 = α2 = γ1 = γ2, Under which
linear conVergence was proVed for bilinear games. ConVergence of EG on conVex-concaVe games
was analyzed in NemiroVski (2004); Monteiro & SVaiter (2010), and MertikopoUlos et al. (2019)
proVides conVergence gUarantees for specific non-conVex-non-concaVe problems. For bilinear games,
a slightly more generalized Version was proposed in Liang & Stokes (2019) where α1 = α2, γ1 = γ2,
with linear conVergence proVed. For later conVenience we define β1 = α2γ1 and β2 = α1γ2.
Optimistic gradient descent (OGD) We stUdy a generalized Version of OGD, defined as follows:
X(t+1) = X(t) - α1Vxf(X(t), y(t)) + β1Vxf(X(t-1), y(t-1)),	(2.9)
y(t+1) = y(t) + α2Vyf(X(t), y(t)) - β2Vyf(X(t-1), y(t-1)).	(2.10)
The original Version of OGD was giVen in PopoV (1980) with α1 = α2 = 2β1 = 2β2 and rediscoVered
in the GAN literatUre (Daskalakis et al., 2018). Its linear conVergence for bilinear games was proVed
in Liang & Stokes (2019). A slightly more generalized Version with α1 = α2 and β1 = β2 was
analyzed in Peng et al. (2019); Mokhtari et al. (2019b), again with linear conVergence proVed. The
stochastic case was analyzed in Hsieh et al. (2019).
Momentum method Generalized heaVy ball method was analyzed in Gidel et al. (2019b):
X(t+1) = X(t) - α1Vxf(X(t), y(t)) + β1(X(t) -X(t-1)),	(2.11)
y(t+1) =y(t)+α2Vyf(X(t),y(t))+β2(y(t) - y(t-1)).	(2.12)
This is a modification of Polyak’s heaVy ball (HB) (Polyak, 1964), which also motiVated NesteroV’s
accelerated gradient algorithm (NAG) (NesteroV, 1983). Note that for both X-Update and the y-Update,
we add a scale mUltiple of the sUccessiVe difference (e.g. proxy of the momentUm). For this algorithm
oUr resUlt below improVes those obtained in Gidel et al. (2019b), as will be discUssed in §3.
EG and OGD as approximations of proximal point algorithm It has been obserVed recently in
Mokhtari et al. (2019b) that for conVex-concaVe games, EG (α1 = α2 = γ1 = γ2 = η) and OGD
(αι∕2 = α2∕2 = βι = β2 = η) can be treated as approximations of the proximal point algorithm
(Martinet, 1970; Rockafellar, 1976) when η is small. With this resUlt, one can show that EG and OGD
conVerge to saddle points sUblinearly for smooth conVex-concaVe games (Mokhtari et al., 2019a).
We giVe a brief introdUction of the proximal point algorithm in Appendix A (inclUding a linear
conVergence resUlt for the slightly generalized Version).
The aboVe algorithms, when specialized to a bilinear fUnction f (see eq. (2.1)), can be rewritten as a
1-step or 2-step LDS (see. eq. (2.3)). See Appendix C.1 for details.
3	Exact conditions
With tools from §2, we formUlate necessary and sUfficient conditions Under which a gradient-based
algorithm conVerges for bilinear games. We sometimes Use “J” as a shorthand for Jacobi style Updates
and “GS” for Gauss-Seidel style updates. For each algorithm, We first write down the characteristic
polynomials (see deriVation in Appendix C.1) for both Jacobi and GS Updates, and present the exact
conditions for conVergence. Specifically, we show that in many cases the GS conVergence regions
strictly include the Jacobi conVergence regions. The proofs for Theorem 3.1, 3.2, 3.3 and 3.4 can be
found in Appendix C.2, C.3, C.4, and C.5, respectiVely.
4
Published as a conference paper at ICLR 2020
GD The characteristic equations can be computed as:
J: (λ- 1)2 +α1α2σ2 = 0, GS: (λ- 1)2 + α1α2σ2λ = 0.	(3.1)
Scaling symmetry From section 3 We obtain a scaling symmetry (α1,ɑ2) → (tα1,α2∕t), with
t > 0. With this symmetry we can always fix α1 = α2 = α. This symmetry also holds for
EG and momentum. For OGD, the scaling symmetry is slightly different with (α1, β1, α2, β2) →
(tαι, tβ1,α2∕t, β2∕t), but we can still use this symmetry to fix αι = α2 = α.
Theorem 3.1	(GD). Jacobi GD and Gauss-Seidel GD do not converge. However, Gauss-SeideI GD
can have a limit cycle while Jacobi GD always diverges.
In the constrained case, Mertikopoulos et al. (2018) and Bailey & Piliouras (2018) show that FTRL, a
more generalized algorithm of GD, does not converge for polymatrix games. When α1 = α2, the
result of Gauss-Seidel GD has been shown in Bailey et al. (2019).
EG The characteristic equations can be computed as:
J:	(λ	- 1)2 + (β1 +	β2 )σ2 (λ - 1) +	(α1α2σ2	+	β1β2σ4)	=	0,	(3.2)
GS: (λ - 1)2 + (α1α2 + β1 + β2 )σ2 (λ - 1) + (α1α2σ2 + β1β2σ4) = 0.	(3.3)
Theorem 3.2	(EG). For generalized EG with α1 = α2 = α and γi = βi∕α, Jacobi and Gauss-Seidel
updates achieve linear convergence iff for any singular value σ of E, we have:
J : ∣βισ2 + β2σ2 — 2| < 1 + (1 — βισ2)(1 — β2σ2) + α2σ2,
(1 - β1σ2 )(1 - β2σ2) + α2σ2 < 1,	(3.4)
GS ： ∣(βι + β2 + α2)σ2 — 2| < 1 + (1 — βισ2)(1 — β2σ2),
(1 - β1σ2)(1 - β2σ2) < 1.	(3.5)
If β1 + β2 + α2 < 2∕σ12, the convergence region of GS updates strictly include that of Jacobi updates.
OGD The characteristic equations can be computed as:
J:	λ2(λ - 1)2 + (λα1 -β1)(λα2 -β2)σ2 = 0,	(3.6)
GS:	λ2(λ - 1)2 + (λα1 -β1)(λα2 - β2)λσ2 = 0.	(3.7)
Theorem 3.3	(OGD). For generalized OGD with α1 = α2 = α, Jacobi and Gauss-Seidel updates
achieve linear convergence iff for any singular value σ of E, we have:
J:
GS :
ʃ Iβ1β2σ21 < 1, (α — βι)(α — β2) > 0, 4 + (α + βι)(α + β2)σ2 > 0,
tα2 (β2σ2 + 1) (β2σ2 + 1) < (β1β2σ2 + 1)(2α(β1 + β2) + 8182(8182σ2 - 3));
(α - β1 )(α - β2 ) > 0, (α + β1 )(α + β2 )σ2 < 4,
(α81σ2 + 1)(α82σ2 + 1) > (1 + 8182σ2)2.
(3.8)
(3.9)
The convergence region of GS updates strictly include that of Jacobi updates.
Momentum The characteristic equations can be computed as:
J: (λ- 1)2(λ -81)(λ-82) + α1α2σ2λ2 = 0,	(3.10)
GS: (λ - 1)2(λ -81)(λ - 82) + α1α2σ2λ3 = 0.	(3.11)
Theorem 3.4	(momentum). For the generalized momentum method with α1 = α2 = α, the Jacobi
updates never converge, while the GS updates converge iff for any singular value σ of E, we have:
|8182| < 1,| -α2σ2 +81+82 +2| <8182 +3, 4(81 + 1)(82 +1) > α2σ2,
α2σ28182 < (1 - 8182)(28182 - 81 - 82).	(3.12)
This condition implies that at least one of 81 , 82 is negative.
5
Published as a conference paper at ICLR 2020
Prior to our work, only sufficient conditions for linear convergence were given for the usual EG and
OGD; see §2 above. For the momentum method, our result improves upon Gidel et al. (2019b) where
they only considered specific cases of parameters. For example, they only considered β1 = β2 ≥
-1/16 for Jacobi momentum (but with explicit rate of divergence), and β1 = -1/2, β2 = 0 for GS
momentum (with convergence rate). Our Theorem 3.4 gives a more complete picture and formally
justifies the necessity of negative momentum.
In the theorems above, we used the term “convergence region” to denote a subset of the parameter
space (with parameters α, β or γ) where the algorithm converges. Our result shares similarity with
the celebrated Stein-Rosenberg theorem (Stein & Rosenberg, 1948), which only applies to solving
linear systems with non-negative matrices (if one were to apply it to our case, the matrix S in eq. (F.1)
in Appendix F needs to have non-zero diagonal entries, which is not possible). In this sense, our
results extend the Stein-Rosenberg theorem to cover nontrivial bilinear games.
4 Optimal exponents of linear convergence
In this section we study the optimal convergence rates of EG and OGD. We define the exponent of
linear convergence as r = limt→∞ ||z(t) ||/||z(t-1) || which is the same as the spectral radius. For
ease of presentation we fix αι = α2 = α > 0 (using scaling symmetry) and we use r* to denote
the optimal exponent of linear convergence (achieved by tuning the parameters α, β, γ). Our results
show that by generalizing gradient algorithms one can obtain better convergence rates.
Theorem 4.1	(EG optimal). Both Jacobi and GS EG achieve the optimal exponent of linear conver-
gence r* = (κ2 一 1)∕(κ2 + 1) at α → 0 and βι = β2 = 2∕(σ2 + σ%). As K → ∞, r* → 1 一 2∕κ2.
Note that we defined βi = γi α in Section 2. In other words, we are taking very large extra-gradient
steps (γi → ∞) and very small gradient steps (α → 0).
Theorem 4.2	(OGD optimal). For Jacobi OGD with β1 = β2 = β, to achieve the optimal exponent
of linear convergence, we must have α ≤ 2β. For the original OGD with α = 2β, the optimal
exponent of linear convergence r* satisfies
r2 = ɪ +------1/(σ2 - σn)(5σ2 一 σ* + ∖∕(σ2 — σ1)(9σ2 — σ[)), at	(4.1)
T	，,	，,	，,	in//'
1	/3 4	2	2 3/2P9 2 U I 6 2 2	4
1	3σ1 一 (σ1 一 σn )	9σ1 一 σn + 6σ1 σn 一 σn
β = 4√2V	σ4σn	.	(4.2)
If κ → ∞, r* 〜1 — 1∕(6κ2). For GS OGD with β2 = 0, the optimal exponent of convergence is
r* = (K(κ2 — 1)∕(κ2 + 1),, at a = √2∕σι and βι = √2σι∕(σ2 + σ%). If K → ∞, r* 〜1 — 1∕κ2.
Remark The original OGD (Popov, 1980; Daskalakis et al., 2018) with α = 2β may not always be
optimal. For example, take one-dimensional bilinear game and σ = 1, and denote the spectral radius
given α, β as r(α, β). If we fix α = 1∕2, by numerically solving section 3 we have
r(1∕2, 1∕4) ≈ 0.966, r(1∕2, 1∕3) ≈ 0.956,	(4.3)
i.e, α = 1∕2, β = 1∕3 is a better choice than α = 2β = 1∕2.
Numerical method We provide a numerical method for finding the optimal exponent of linear
convergence, by realizing that the unit disk in Theorem 2.2 is not special. Let us call a polynomial to
be r-Schur stable if all of its roots lie within an (open) disk of radius r in the complex plane. We can
scale the polynomial with the following lemma:
Lemma 4.1. A polynomial p(λ) is r-Schur stable iff p(rλ) is Schur stable.
With the lemma above, one can rescale the Schur conditions and find the convergence region where
the exponent of linear convergence is at most r (r < 1). A simple binary search would allow one to
find a better and better convergence region. See details in Appendix D.3.
6
Published as a conference paper at ICLR 2020
Figure 1: Left: linear convergence of optimal EG, Jacobi OGD, GaUss-Seidel OGD in a bilinear
game with the log distance; Middle: comparison among Adam, SGD and EG in learning the mean of
a Gaussian with WGAN with the squared distance; Right: Comparison between EG with (α = 0.02,
γ = 2.0) and without scaling (α = γ = 0.2). We use the squared distance.
Figure 2: Heat maps of the spectral radii of different algorithms. We take σ = 1 for convenience. The
horizontal axis is α and the vertical axis is β. Top row: Jacobi updates; Bottom row: Gauss-Seidel
updates. Columns (left to right): EG; OGD; momentum. If the spectral radius is strictly less than one,
it means that our algorithm converges. In each column, the Jacobi convergence region is contained in
the GS convergence region (for EG we need an additional assumption, see Theorem 3.2).
5	Experiments
Bilinear game We run experiments on a simple bilinear game and choose the optimal parameters
as suggested in Theorem 4.1 and 4.2. The results are shown in the left panel of Figure 1, which
confirms the predicted linear rates.
Density plots We show the density plots (heat maps) of the spectral radii in Figure 2. We make
plots for EG, OGD and momentum with both Jacobi and GS updates. These plots are made when
β1 = β2 = β and they agree with our theorems in §3.
Wasserstein GAN As in Daskalakis et al. (2018), we consider a WGAN (Arjovsky et al., 2017)
that learns the mean of a Gaussian:
minφ max© f (φ, θ) := Ex〜N(v,σ2i)[s(θ>x)] - Ez〜N(0,σ2i)[s(θ>(z + Φ))],	(5.1)
where s(x) is the sigmoid function. It can be shown that near the saddle point (θ*, φ*) = (0, V) the
min-max optimization can be treated as a bilinear game (Appendix E.1). With GS updates, we find
that Adam diverges, SGD goes around a limit cycle, and EG converges, as shown in the middle panel
of Figure 1. We can see that Adam does not behave well even in this simple task of learning a single
two-dimensional Gaussian with GAN.
Our next experiment shows that generalized algorithms may have an advantage over traditional ones.
Inspired by Theorem 4.1, we compare the convergence of two EGs with the same parameter β = αγ,
and find that with scaling, EG has better convergence, as shown in the right panel of Figure 1. Finally,
7
Published as a conference paper at ICLR 2020
Figure 3: Jacobi vs. GS updates. y-axis: Squared distance ∣∣φ - v||2. x-axis: Number of epochs.
Left: EG with γ = 0.2, α = 0.02; Middle: OGD with α = 0.2, β1 = 0.1, β2 = 0; Right:
Momentum with α = 0.08, β = -0.1. We plot only a few epochs for Jacobi if it does not converge.
Figure 4: Test samples from the generator network trained with stochastic GD (step size α = 0.01).
Top row: Jacobi updates; Bottom row: Gauss-Seidel updates. Columns: epoch 0,10, 15, 20.
we compare Jacobi updates with GS updates. In Figure 3, we can see that GS updates converge even
if the corresponding Jacobi updates do not.
Mixtures of Gaussians (GMMs) Our last experiment is on learning GMMs with a vanilla GAN
(Goodfellow et al., 2014) that does not directly fall into our analysis. We choose a 3-hidden layer
ReLU network for both the generator and the discriminator, and each hidden layer has 256 units. We
find that for GD and OGD, Jacobi style updates converge more slowly than GS updates, and whenever
Jacobi updates converge, the corresponding GS updates converges as well. These comparisons can be
found in Figure 4 and 5, which implies the possibility of extending our results to non-bilinear games.
Interestingly, we observe that even Jacobi GD converges on this example. We provide additional
comparison between the Jacobi and GS updates of Adam (Kingma & Ba, 2015) in Appendix E.2.
Figure 5: Test samples from the generator network trained with stochastic OGD (α = 2β = 0.02).
Top row: Jacobi updates; Bottom row: Gauss-Seidel updates. Columns: epoch 0, 10, 60, 100.
8
Published as a conference paper at ICLR 2020
6	Conclusions
In this work we focus on the convergence behaviour of gradient-based algorithms for solving bilinear
games. By drawing a connection to discrete linear dynamical systems (§2) and using Schur’s
theorem, we provide necessary and sufficient conditions for a variety of gradient algorithms, for both
simultaneous (Jacobi) and alternating (GaUss-Seidel) updates. Our results show that GaUss-Seidel
updates converge more easily than Jacobi updates. Furthermore, we find the optimal exponents of
linear convergence for EG and OGD, and provide a numerical method for searching that exponent. We
performed a number of experiments to validate our theoretical findings and suggest further analysis.
There are many future directions to explore. For example, our preliminary experiments on GANs
suggest that similar (local) results might be obtained for more general games. Indeed, the local
convergence behaviour of min-max nonlinear optimization can be studied through analyzing the
spectrum of the Jacobian matrix of the update operator (see, e.g., Nagarajan & Kolter (2017); Gidel
et al. (2019b)). We believe our framework that draws the connection to linear discrete dynamic
systems and Schur’s theorem is a powerful machinery that can be applied in such problems and
beyond. It would be interesting to generalize our results to the constrained case (even for bilinear
games), as studied in Daskalakis & Panageas (2019); Carmon et al. (2019). Extending our results to
account for stochastic noise (as empirically tested in our experiments) is another interesting direction,
with results in Gidel et al. (2019a); Hsieh et al. (2019).
Acknowledgements
We would like to thank Argyrios Deligkas, Sarath Pattathil and Georgios Piliouras for pointing
out several related references. GZ is supported by David R. Cheriton Scholarship. We gratefully
acknowledge funding support from NSERC and the Waterloo-Huawei Joint Innovation Lab.
References
M. Arjovsky, S. Chintala, and L. Bottou. Wasserstein generative adversarial networks. In International
Conference on Machine Learning, 2017.
K. J. Arrow, L. Hurwicz, and H. Uzawa. Studies in linear and non-linear programming. Stanford
University Press, 1958.
J. P. Bailey and G. Piliouras. Multiplicative weights update in zero-sum games. In Proceedings of the
2018 ACM Conference on Economics and Computation, pp. 321-338. ACM, 2018.
J. P. Bailey, G. Gidel, and G. Piliouras. Finite regret and cycles with fixed step-size via alternating
gradient descent-ascent. arXiv preprint arXiv:1907.04392, 2019.
R.	E. Bruck. On the weak convergence of an ergodic iteration for the solution of variational
inequalities for monotone operators in Hilbert space. Journal of Mathematical Analysis and
Applications, 61(1):159-164, 1977.
Y. Carmon, Y. Jin, A. Sidford, and K. Tian. Variance reduction for matrix games. In Advances in
Neural Information Processing Systems, pp. 11377-11388, 2019.
X. Chen, X. Deng, and S.-H. Teng. Settling the complexity of computing two-player Nash equilibria.
Journal of the ACM, 56(3):14, 2009.
S.	S. Cheng and S. S. Chiou. Exact stability regions for quartic polynomials. Bulletin of the Brazilian
Mathematical Society, 38(1):21-38, 2007.
B.	Dai, A. Shaw, L. Li, L. Xiao, N. He, Z. Liu, J. Chen, and L. Song. Sbeed: Convergent reinforcement
learning with nonlinear function approximation. In International Conference on Machine Learning,
pp. 1125-1134, 2018.
C.	Daskalakis and I. Panageas. Last-iterate convergence: Zero-sum games and constrained min-max
optimization. In Innovations in Theoretical Computer Science, 2019.
9
Published as a conference paper at ICLR 2020
C. Daskalakis, A. Ilyas, V. Syrgkanis, and H. Zeng. Training GANs with optimism. In International
Conference on Learning Representations, 2018.
A. Deligkas, J. Fearnley, R. Savani, and P. Spirakis. Computing approximate Nash equilibria in
polymatrix games. AIgorithmica,77(2):487-514, 2017.
V. F. Dem’yanov and A. B. Pevnyi. Numerical methods for finding saddle points. USSR Computa-
tional Mathematics and Mathematical Physics, 12(5):11-52, 1972.
S. S. Du, J. Chen, L. Li, L. Xiao, and D. Zhou. Stochastic variance reduction methods for policy
evaluation. In International Conference on Machine Learning, pp. 1049-1058, 2017.
Y. Freund and R. E. Schapire. Adaptive game playing using multiplicative weights. Games and
Economic Behavior, 29(1-2):79-103, 1999.
G. Gidel, H. Berard, G. Vignoud, P. Vincent, and S. Lacoste-Julien. A variational inequality perspec-
tive on generative adversarial networks. In International Conference on Learning Representations,
2019a.
G. Gidel, R. A. Hemmat, M. Pezeshki, G. Huang, R. Lepriol, S. Lacoste-Julien, and I. Mitliagkas.
Negative momentum for improved game dynamics. In AISTATS, 2019b.
I. Gohberg, P. Lancaster, and L. Rodman. Matrix polynomials. Academic Press, 1982.
E. G. Gol’shtein. A generalized gradient method for finding saddlepoints. Ekonomika i matematich-
eskie metody, 8(4):569-579, 1972.
I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, and
Y. Bengio. Generative adversarial nets. In Advances in Neural Information Processing Systems, pp.
2672-2680, 2014.
Y.-G. Hsieh, F. Iutzeler, J. Malick, and P. Mertikopoulos. On the convergence of single-call stochastic
extra-gradient methods. In Advances in Neural Information Processing Systems, pp. 6936-6946,
2019.
D. P. Kingma and J. Ba. Adam: A method for stochastic optimization. In International Conference
on Learning Representations, 2015.
G. M. Korpelevich. The extragradient method for finding saddle points and other problems. Matecon,
12:747-756, 1976.
T. Liang and J. Stokes. Interaction matters: A note on non-asymptotic local convergence of generative
adversarial networks. In AISTATS, 2019.
P L. Lions. Une m6thode iterative de resolution d'une inequation VariatiOnnelle. Israel Journal of
Mathematics, 31(2):204-208, 1978.
A.	Madry, A. Makelov, L. Schmidt, D. Tsipras, and A. Vladu. Towards deep learning models resistant
to adversarial attacks. In International Conference on Learning Representations, 2018.
M. Mansour. Discrete-time and sampled-data stability tests. In Williams S. Levine (ed.), The Control
Handbook: Control System Fundamentals. CRC press, 2nd edition, 2011.
B.	Martinet. Regularisation d’inequations variationnelles par approximations successives. ESAIM:
Mathematical Modelling and Numerical Analysis: Modelisation Mathematique et Analyse
Numerique ,4(R3):154-158, 1970.
P. Mertikopoulos, C. Papadimitriou, and G. Piliouras. Cycles in adversarial regularized learning.
In Proceedings of the Twenty-Ninth Annual ACM-SIAM Symposium on Discrete Algorithms, pp.
2703-2717. SIAM, 2018.
P. Mertikopoulos, B. Lecouat, H. Zenati, C.-S. Foo, V. Chandrasekhar, and G. Piliouras. Optimistic
mirror descent in saddle-point problems: Going the extra (gradient) mile. In International
Conference on Learning Representations, 2019.
10
Published as a conference paper at ICLR 2020
L. Mescheder, S. Nowozin, and A. Geiger. The numerics of GANs. In Advances in Neural Information
Processing Systems,pp. 1825-1835, 2017.
L. Mescheder, A. Geiger, and S. Nowozin. Which training methods for GANs do actually converge?
In International Conference on Machine Learning, 2018.
A. Mokhtari, A. Ozdaglar, and S. Pattathil. Proximal point approximations achieving a convergence
rate of O(1/k) for smooth convex-concave saddle point problems: Optimistic gradient and extra-
gradient methods. arXiv preprint arXiv:1906.01115, 2019a.
A. Mokhtari, A. Ozdaglar, and S. Pattathil. A unified analysis of extra-gradient and optimistic gradient
methods for saddle point problems: Proximal point approach. arXiv preprint arXiv:1901.08511,
2019b.
R. D. C. Monteiro and B. F. Svaiter. On the complexity of the hybrid proximal extragradient method
for the iterates and the ergodic mean. SIAM Journal on Optimization, 20(6):2755-2787, 2010.
V. Nagarajan and J. Z. Kolter. Gradient descent GAN optimization is locally stable. In Advances in
Neural Information Processing Systems, pp. 5585-5595, 2017.
A. NediC and A. Ozdaglar. Subgradient methods for saddle-point problems. Journal ofoptimization
theory and applications, 142(1):205-228, 2009.
A. Nemirovski. Prox-method with rate of convergence O(1/t) for variational inequalities with
lipschitz continuous monotone operators and smooth convex-concave saddle point problems. SIAM
Journal on Optimization, 15(1):229-251, 2004.
A.	S. Nemirovski and D. B. Yudin. CeS派O convergence of the gradient method of approximating
saddle points of convex-concave functions. Doklady Akademii Nauk, 239:1056-1059, 1978.
A. S. Nemirovski and D. B. Yudin. Problem complexity and method efficiency in optimization. Wiley,
1983.
Y. Nesterov. A method for unconstrained convex minimization problem with the rate of convergence
O(1/k2). Doklady Akademii Nauk, 269:543-547, 1983.
W. Peng, Y. Dai, H. Zhang, and L. Cheng. Training GANs with centripetal acceleration. arXiv
preprint arXiv:1902.08949, 2019.
B.	T. Polyak. Some methods of speeding up the convergence of iteration methods. USSR Computa-
tional Mathematics and Mathematical Physics, 4(5):1-17, 1964.
L. D. Popov. A modification of the Arrow-Hurwicz method for search of saddle points. Mathematical
Notes, 28(5):845-848, 1980.
R. T. Rockafellar. Monotone operators and the proximal point algorithm. SIAM journal on control
and optimization, 14(5):877-898, 1976.
Y. Saad. Iterative methods for sparse linear systems. SIAM, 2nd edition, 2003.
I. Schur. Uber Potenzreihen, die im Innern des Einheitskreises beschrankt sind. Journalfur die reine
und angewandte Mathematik, 147:205-232, 1917.
P. Stein and R. L. Rosenberg. On the solution of linear simultaneous equations by iteration. Journal
of the London Mathematical Society, 1(2):111-118, 1948.
P. Tseng. On linear convergence of iterative methods for the variational inequality problem. Journal
of Computational and Applied Mathematics, 60(1-2):237-252, 1995.
11
Published as a conference paper at ICLR 2020
A Proximal point (PP) algorithm
PP was originally proposed by Martinet (1970) with α1 = α2 and then carefully studied by Rockafel-
lar (1976). The linear convergence for bilinear games was also proved in the same reference. Note
that We do not consider GaUss-Seidel PP since We do not get a meaningful solution after a shift of
steps2.
X(HI) = Xm- αιVχf (x(t+1), y(t+1)), y(t+1) = y(t) + aVyf (χ(t+1), y(t+1)),	(A.1)
Where x(t+1) and y(t+1) are given implicitly by solving the equations above. For bilinear games, one
can derive that:
-1
z(t+1) = I	α1E	z(t)
z	=	-α2E> I	z
(A.2)
We can compute the exact form of the inverse matrix, but perhaps an easier Way is just to compute
the spectrum of the original matrix (the same as Jacobi GD except that We flip the signs of αi) and
perform λ → 1∕λ. Using the fact that the eigenvalues of a matrix are reciprocals of the eigenvalues
of its inverse, the characteristic equation is:
(1∕λ — 1)2 + α1α2σ2 = 0.	(A.3)
With the scaling symmetry (αι,ɑ2) → (tɑι, α2∕t), We can take αι = α2 = α > 0. With the
notations in Corollary 2.1, We have a = -2∕(1 + α2σ2) and b = 1∕(1 + α2σ2), and it is easy
to check |a| < 1 + b and b < 1 are alWays satisfied, Which means linear convergence is alWays
guaranteed. Hence, We have the folloWing theorem:
Theorem A.1. For bilinear games, the proximal point algorithm always converges linearly.
Although the proximal point algorithm behaves Well, it is rarely used in practice since it is an implicit
method, i.e., one needs to solve (X(t+1), y(t+1)) from equation A.1.
B Proofs in Section 2
B.1 Proof of Theorem 2.3
In this section We apply Theorem 2.1 to prove Theorem 2.3, an interesting connection betWeen Jacobi
and Gauss-Seidel updates:
Theorem 2.3 (Jacobi vs. Gauss-Seidel). Letp(λ, Y) = det(Pk=0(γLi + Ui)λk-i), where Ai =
Li + Ui and Li is strictly lower block triangular. Then, the characteristic polynomial of Jacobi
updates is p(λ, 1) while that of Gauss-Seidel updates isp(λ,λ).
Let us first consider the block linear iterative process in the sense of Jacobi (i.e., all blocks are updated
simultaneously):
z(t)
z(t1
k
XAi
i=1
l-1
X XAi,jzj(t-i)
zb(t-i)
i=1
j=1
b
+ X Ai,j zj(t-i)
j=l
+ d,	(B.1)
k
Where Ai,j is the j-th column block of Ai. For each matrix Ai, We decompose it into the sum
Ai = Li + Ui ,	(B.2)
Where Li is the strictly loWer block triangular part and Ui is the upper (including diagonal) block
triangular part. Theorem 2.1 indicates that the convergence behaviour of equation B.1 is governed by
the largest modulus of the roots of the characteristic polynomial:
det -λkI+XAiλk-i	= det -λkI + X(Li + Ui)λk-i .	(B.3)
2If one uses inverse operators this is in principle doable.
12
Published as a conference paper at ICLR 2020
Alternatively, We can also consider the updates in the sense of Gauss-Seidel (i.e., blocks are updated
sequentially):
k	l-1	b
ZF= X X Aij Zjl+1)+ X Aij Zjl)	+ di,	l = 1,...,b.	(B.4)
i=1 j =1	j =l	l
We can reWrite the Gauss-Seidel update elegantly3 as:
k
(I - L1)Z(t) = X(Li+1 + Ui)Z(t-i) + d,	(B.5)
i=1
i.e.,
k
Z(t) = X(I - L1)-1(Li+1 + Ui)Z(t-i) + (I - L1)-1d,	(B.6)
Where Lk+1 := 0. Applying Theorem 2.1 again We knoW the convergence behaviour of the Gauss-
Seidel update is governed by the largest modulus of roots of the characteristic polynomial:
det -λkI + Xk (I - L1)-1(Li+1 + Ui)λk-i	(B.7)
=det (I-L1)-1-λkI+λkL1+Xk (Li+1 + Ui)λk-i	(B.8)
=det(I - LI)T ∙ det ^X(λLi + Ui)λk-i)	(B.9)
Note that A0 = -I and the factor det(I - L1)-1 can be discarded since multiplying a characteristic
polynomial by a non-zero constant factor does not change its roots.
B.2 Proof of Corollary 2.1
Corollary 2.1 (e.g. Mansour (2011)). A real quadratic polynomial λ2 + aλ + b is Schur stable
iff b < 1, |a| < 1 + b; A real cubic polynomial λ3 + aλ2 + bλ + c is Schur stable iff |c| < 1,
|a + c| < 1 + b, b - ac < 1 - c2; A real quartic polynomial λ4 + aλ3 + bλ2 + cλ + d is Schur stable
iff |c - ad| < 1 - d , |a + c| < b + d + 1, and b < (1 + d) + (c - ad)(a - c)/(d - 1) .
Proof. It suffices to prove the result for quartic polynomials. We Write doWn the matrices:
P1 = [1], Q1 = [d],
P2 =	1 a 1	0 1 0	, Q2 = 0	d 0	c d d	, c
P3 =	a	1	0 ,Q3	=	0	d
	b	a	1		0	0
	-1	0	0	0-			-d
	a	1	00			0
P4 =	b	a	1 0 , Q4		=	0
	c	b	a0			0
(B.10)
(B.11)
b		
c	,	(B.12)
d		
c	b	a-	
d	cb	
0	dc	.	(B.13)
0	0d	
We require det(PkPk> - Qk>Qk) =: δk > 0, for k = 1, 2, 3, 4. If k = 1, We have 1 - d2 > 0,
namely, |d| < 1. δ2 > 0 reduces to (c - ad)2 < (1 - d2)2 and thus |c - ad| < 1 - d2 due to the
first condition. δ4 > 0 simplifies to:
-((a + c)2 - (b + d + 1)2)((b - d - 1)(d - 1)2 - (a - c)(c - ad))2 < 0,	(B.14)
3This is Well-knoWn When k = 1, see e.g. Saad (2003).
13
Published as a conference paper at ICLR 2020
which yields |a + c| < |b + d +	1|. Finally, δ3 >	0 reduces to:
((b - d - 1)(d - 1)2 - (a -	c)(c - ad))((d2	- 1)(b + d + 1)	+ (c -	ad)(a +	c)) > 0.	(B.15)
Denote p(λ) := λ4 + aλ3 + bλ2 + cλ + d, we must have p(1) > 0 and p(-1) > 0, as otherwise
there is a real root λo with ∣λo∣ ≥ 1. Hence We obtain b + d +1 > |a + c| > 0. Also, from
|c - ad| < 1 - d2, we know that:
|c - αd∣∙∣α + c| < |b + d +1∣(1 - d2) = (b + d + 1)(1 - d2).	(B.16)
So, the second factor in B.15 is negative and the positivity of the first factor reduces to:
b< (1 + d)+(C— Fa-C).	(B.17)
(d-1)2
To obtain the Schur condition for cubic polynomials, we take d = 0, and the quartic Schur condition
becomes:
|c| < 1, |a + c| < b + 1, b - ac < 1 - c2.	(B.18)
To obtain the Schur condition for quadratic polynomials, we take c = 0 in the above and write:
b < 1, |a| < 1+b.	(B.19)
The proof is now complete.	□
C	Proofs in Section 3
Some of the following proofs in Appendix C.4 and C.5 rely on Mathematica code (mostly with
the built-in function Reduce) but in principle the code can be verified manually using cylindrical
algebraic decomposition.4
C.1 Derivation of characteristic polynomials
In this appendix, we derive the exact forms of LDSs (eq. (2.3)) and the characteristic polynomials for
all gradient-based methods introduced in §2, with eq. (2.4). The following lemma is well-known and
easy to verify using Schur’s complement:
Lemma C.1. Given M ∈ R2n×2n, A ∈ Rn×n and
AB
M = CA DB .	(C.1)
If C and D commute, then det M = det(AD - BC).
Gradient descent From equation 2.6 the update equation of Jacobi GD can be derived as:
z(t+1)
I
α2E>
-α1E	(t)
Iz
(C.2)
and with Lemma C.1, we compute the characteristic polynomial as in eq. (2.4):
det (-λα-E1)>I (λα-1E1)I = det[(λ - 1)2I+α1α2EE>],	(C.3)
With spectral decomposition we obtain equation 3.1. Taking α2 → λα2 and with Theorem 2.3 we
obtain the corresponding GS updates. Therefore, the characteristic polynomials for GD are:
J: (λ- 1)2 + α1α2σ2 = 0, GS: (λ - 1)2 + α1α2σ2λ = 0.	(C.4)
4See the online Mathematica documentation.
14
Published as a conference paper at ICLR 2020
Extra-gradient From eq. (2.7) and eq. (2.8), the update of Jacobi EG is:
(t+1)	I - β2 EE>	-α1E	(t)
z =	α2E>	I - β1E>E z
the characteristic polynomial is:
d	(λ - 1)I + β2EE>	α1E
det -α2E>	(λ- 1)I + β1E>E .
(C.5)
(C.6)
Since We assumed α? > 0, We can left multiply the second row by β2E/α2 and add it to the first
row. Hence, we obtain:
dt Γ(λ - 1)I αιE + (λ - l)β2E∕α2 + β1β2EE>E/a
det -α2E>	(λ - 1)I+β1E>E	.
With Lemma C.1 the equation above becomes:
det[(λ - 1)2I + (β1 + β2)E>E(λ - 1) + (α1α2E>E + β1β2E>EE>E)],
(C.7)
(C.8)
Which simplifies to equation 3.2 With spectral decomposition. Note that to obtain the GS polynomial,
We simply take α2 → λα2 in the Jacobi polynomial as shoWn in Theorem 2.3. For the ease of reading
We copy the characteristic equations for generalized EG:
J: (λ - 1)2 + (β1 + β2 )σ2 (λ - 1) + (α1α2σ2 + β1β2σ4) = 0,	(C.9)
GS: (λ - 1)2 + (α1α2 + β1 + β2 )σ2 (λ - 1) + (α1α2σ2 + β1β2σ4) = 0.	(C.10)
Optimistic gradient descent We can compute the LDS for OGD With eq. (2.9) and eq. (2.10):
z(t+2) = I	-α1E	z(t+1)	+	0	β1E z(t)
z =	α2E> I	z	+	-β2E>	0 z
(C.11)
With eq. (2.4), the characteristic polynomial for Jacobi OGD is
det
(λ2 - λ)I
(-λα2 +β2)E>
(λα1 - β1 )E
(λ2 - λ)I
(C.12)
Taking the determinant and With Lemma C.1 We obtain equation 3.6. The characteristic polynomial
for GS updates in equation 3.7 can be subsequently derived With Theorem 2.3, by taking (α2 , β2 ) →
(λα2 , λβ2 ). For the ease of reading We copy the characteristic polynomials from the main text as:
J: λ2(λ - 1)2 + (λα1 -β1)(λα2 -β2)σ2 = 0,	(C.13)
GS: λ2(λ - 1)2 + (λα1 - β1)(λα2 -β2)λσ2 = 0.	(C.14)
Momentum method With eq. (2.11) and eq. (2.12), the LDS for the momentum method is:
z(t+2)	(1 + β1)I	-α1E	z(t+1) + -β1I	0	z(t)
z = α2E>	(1 +β2)I z +	0	-β2I z
From eq. (2.4), the characteristic polynomial for Jacobi momentum is
(λ2 - λ(1 + β1 ) + β1 )I	λα1 E
det	-λα2E>	(λ2 -λ(1+β2)+β2)I
(C.15)
(C.16)
Taking the determinant and With Lemma C.1 We obtain equation 3.10, While equation 3.11 can be
derived With Theorem 2.3, by taking α2 → λα2 . For the ease of reading We copy the characteristic
polynomials from the main text as:
J: (λ - 1)2(λ - β1)(λ - β2) + α1α2σ2λ2 = 0,	(C.17)
GS: (λ- 1)2(λ - β1)(λ - β2) + α1α2σ2λ3 = 0.	(C.18)
C.2 Proof of Theorem 3.1: Schur conditions of GD
Theorem 3.1	(GD). Jacobi GD and Gauss-Seidel GD do not converge. However, Gauss-SeideI GD
can have a limit cycle while Jacobi GD always diverges.
Proof. With the notations in Corollary 2.1, for Jacobi GD, b = 1 + α2σ2 > 1. For Gauss-Seidel GD,
b = 1. The Schur conditions are violated.	□
15
Published as a conference paper at ICLR 2020
C.3 Proof of Theorem 3.2: Schur conditions of EG
Theorem 3.2	(EG). For generalized EG with αι = α2 = α and Yi = βi∕α, Jacobi and Gauss-Seidel
updates achieve linear convergence iff for any singular value σ of E, we have:
J : ∣βισ2 + β2σ2 — 2| < 1 + (1 — βισ2)(1 — β2σ2) + α2σ2,
(1 - β1σ2 )(1 - β2σ2) + α2σ2 < 1,	(3.4)
GS ： ∣(βι + β2 + α2)σ2 — 2| < 1 + (1 — βισ2)(1 — β2σ2),
(1 - β1σ2)(1 - β2σ2) < 1.	(3.5)
If β1 + β2 + α2 < 2∕σ12, the convergence region of GS updates strictly include that of Jacobi updates.
Both characteristic polynomials can be written as a quadratic polynomial λ2 + aλ + b, where:
J: a = (β1 + β2)σ2 - 2, b = (1 - β1σ2 )(1 - β2σ2 ) + α2σ2 ,	(C.19)
GS: a = (β1 +β2 +α2)σ2 - 2, b = (1 - β1σ2)(1 - β2σ2).	(C.20)
Compared to Jacobi EG, the only difference between GaUss-Seidel and Jacobi updates is that the
α2σ2 in b is now in a, which agrees with Theorem 2.3. Using Corollary 2.1, we can derive the Schur
conditions equation 3.4 and equation 3.5.
More can be said ifβ1 +β2 is small. For instance, if β1 + β2 + α2 < 2∕σ12, then equation 3.4 implies
equation 3.5. In this case, the first conditions of equation 3.4 and equation 3.5 are equivalent, while
the second condition of equation 3.4 strictly implies that of equation 3.5. Hence, the Schur region of
Gauss-Seidel updates includes that of Jacobi updates. The same holds true if βι + β2 < 342.
More precisely, to show that the GS convergence region strictly contains that of the Jacobi convergence
region, simply take β1 = β2 = β . The Schur condition for Jacobi EG and Gauss-Seidel EG are
separately:
J: α2σ2 + (βσ2 - 1)2 < 1,	(C.21)
GS: 0 < βσ2 < 2 and ∣ασ∣ < 2 - βσ2.	(C.22)
It can be shown that ifβ = α2∕3 and α → 0, equation C.21 is always violated whereas equation C.22
is always satisfied.
Conversely, we give an example when Jacobi EG converges while GS EG does not. Let β1σ2 =
β2σ2 ≡ 2, then Jacobi EG converges iff α2σ2 < 3 while GS EG converges iff α2σ2 < 4.
C.4 Proof of Theorem 3.3: Schur conditions of OGD
In this subsection, we fill in the details of the proof of Theorem 3.3, by first deriving the Schur
conditions of OGD, and then studying the relation between Jacobi OGD and GS OGD.
Theorem 3.3 (OGD). For generalized OGD with α1 = α2 = α, Jacobi and Gauss-Seidel updates
achieve linear convergence iff for any singular value σ of E, we have:
J:
GS :
(∣β1β2σ21 < 1, (α — βι)(α — β2) > 0, 4 + (α + βι)(α + β2)σ2 > 0,
lα2 (β2σ2 + 1) (β2σ2 + 1) < (βιβ2σ2 + 1)(2α(βι + β2) + 8182(8182σ2 - 3));
((α - β1 )(α - β2 ) > 0, (α + β1 )(α + β2 )σ2 < 4,
(α81σ2 + 1)(α82σ2 + 1) > (1 + 8182σ2)2.
(3.8)
(3.9)
The convergence region of GS updates strictly include that of Jacobi updates.
The Jacobi characteristic polynomial is now quartic in the form λ4 + aλ3 + bλ2 + cλ + d, with
a = -2, b = α2σ2 + 1, c = -α(81 + 82)σ2, d = 8182σ2 .	(C.23)
Comparably, the GS polynomial equation 3.7 can be reduced to a cubic one λ3 + aλ2 + bλ + c with
a = -2 + α2σ2, b = -α(81 + 82)σ2 + 1, c = 8182σ2 .	(C.24)
First we derive the Schur conditions equation 3.8 and equation 3.9. Note that other than Corollary
2.1,	an equivalent Schur condition can be read from Cheng & Chiou (2007, Theorem 1) as:
16
Published as a conference paper at ICLR 2020
Theorem C.1 (Cheng & Chiou (2007)). A real quartic polynomial λ4 + aλ3 + bλ2 + cλ + d is
Schur stable iff:
|d| < 1, |a| < d + 3, |a + c| < b + d + 1,
(1 -	d)2b +	c2 -	a(1	+ d)c - (1 + d)(1 -	d)2	+ a2d	<	0.	(C.25)
With equation C.23 and Theorem C.1, it is straightforward to derive equation 3.8. With equation C.24
and Corollary 2.1, we can derive equation 3.9 without much effort.
Now, let us study the relation between the convergence region of Jacobi OGD and GS OGD, as
given in equation 3.8 and equation 3.9. Namely, we want to prove the last sentence of Theorem 3.3.
The outline of our proof is as follows. We first show that each region of (α, β1, β2) described in
equation 3.8 (the Jacobi region) is contained in the region described in equation 3.9 (the GS region).
Since we are only studying one singular value, we slightly abuse the notations and rewrite βiσ as
βi (i = 1, 2) and ασ as α. From equation 3.6 and equation 3.7, β1 and β2 can switch. WLOG, we
assume β1 ≥ β2 . There are four cases to consider:
•	β1 ≥ β2 > 0. The third Jacobi condition in equation 3.8 now is redundant, and we have
α > β1 or α < β2 for both methods. Solving the quadratic feasibility condition for α gives:
0 <β2 < 1,β2 ≤ βι <β⅛^4+5β2 ,βι <α<u + Vf京,(C.26)
2(1 + β2 )	t
where u = (β1β2 + 1)(β1 +β2), v = β1β2(β1β2 + 1)(β1β2 - 3), t= (β12 + 1)(β22 + 1).
On the other hand, assume α > β1 , the first and third GS conditions are automatic. Solving
the second gives:
0 < β2 < 1, β2 ≤ β1 <
2
,β1 < α < - 2(β1 +β2) + 2 P (β - β2)2 + 16.
(C.27)
Define f(β2) ：= -β2 + √8 + β22/2 and g(β2) ：= (β2 + √4 + 5β2)∕(2(1 + β2)), and
one can show that
f(β2) ≥ g(β2).	(C.28)
Furthermore, it can also be shown that given 0 < β2 < 1 and β2 ≤ β1 < g(β2), we have
(u + Pu2 + 4v)∕t < -(βι + β2)∕2 + (1∕2)P(βι - β2)2 + 16.	(C.29)
•	βι ≥ β2 = 0. The Schur condition for Jacobi and Gauss-Seidel updates reduces to:
Jacobi: 0 < β1 < 1, β1 < α <
2βι
1 + β2 ,
GS: 0 <βι < √2, βι < α < -β1 + j16 + β2 .
(C.30)
(C.31)
One can show that given βι ∈ (0,1), We have 2βι∕(1 + β2) < (-βι + ,16 + β1 )/2.
•	β1 ≥ 0 > β2 . Reducing the first, second and fourth conditions of equation 3.8 yields:
β2 < 0, 0 < β1 <
β2 + ʌ/4 + 5β2
2(1 + β2)
, β1 < α <
u + u2 + tv
t
(C.32)
This region contains the Jacobi region. It can be similarly proved that even within this larger
region, GS Schur condition equation 3.9 is always satisfied.
•	β2 ≤ βι < 0. We have u < 0, tv < 0 and thus α < (u + √u2 + tv)∕t < 0. This
contradicts our assumption that α > 0.
Combining the four cases above, we know that the Jacobi region is contained in the GS region.
To show the strict inclusion, take β1 = β2 = α∕5 and α → 0. One can show that as long as α is
small enough, all the Jacobi regions do not contain this point, each of which is described with a
17
Published as a conference paper at ICLR 2020
singular value in equation 3.8. However, all the GS regions described in equation 3.9 contain this
point.
The proof above is still missing some details. We provide the proofs of equation C.26, equation C.28,
equation C.29 and equation C.32 in the sub-sub-sections below, with the help of Mathematica,
although one can also verify these claims manually. Moreover, a one line proof of the inclusion can
be given with Mathematica code, as shown in Section C.4.5.
C.4. 1 Proof of equation C.26
The fourth condition of equation 3.8 can be rewritten as:
α2t - 2uα - v < 0,	(C.33)
where u = (β1β2 + 1)(β1 + β2), v = β1β2(β1β2 + 1)(β1β2 -3), t = (β12 + 1)(β22 + 1). The
discriminant is 4(u2 + tv) = (1 - β1β2)2(1 + β1β2)(β12 + β22 + β12β22 - β1β2) ≥ 0. Since if
β1β2 < 0,
β1 + β2 + β1β2 - β1β2 = β1 + β2 + β1β2(β1β2 - 1) > 0,
Ifβ1β2 ≥0,
β1 + β2 + β1 β2 - β1 β2 = (β1 - β2 ) + β1 β2 (1 + β1 β2 ) ≥ 0,
where We used ∣β1β2∣ < 1 in both cases. So, equation C.33 becomes:
U-√U2+v <α<u + √2+tv.	(C.34)
Combining with α > β1 or α < β2 obtained from the second condition, we have:
U-√U2+v <α<β2 or βι < α < U + √"+v.	(C.35)
The first case is not possible, with the following code:
u = (b1 b2 + 1) (b1 + b2); v = b1 b2 (b1 b2 + 1) (b1 b2 - 3);
t = (b1^2 + 1) (b2^2	+ 1);
Reduce[b2 t > u - Sqrt[u^2 + t v] && b1 >= b2 > 0
&& Abs[b1 b2] < 1],
and we have:
False.
Therefore, the only possible case is βι < α < (u + √u2 + tv)/t. Where the feasibility region can
be solved with:
Reduce[b1 t < u + Sqrt[u^2+t v]&&b1>=b2>0&&Abs[b1 b2] < 1].
What we get is:
0<b2<1 &&
b2<=b1<b2∕(2 (1+b2^2))+1∕2 Sqrt[(4+5 b2^2)∕(1+b2^2)^2].
Therefore, we have proved equation C.26.
C.4.2 Proof of equation C.28
With
Reduce[-(b2∕2) + Sqrt[8 + b2^2]∕2 >=
(b2 + Sqrt[4 + 5 b2^2])∕(2 (1 + b2^2)) && 0 < b2 < 1],
we can remove the first constraint and get:
0 < b2 < 1.
18
Published as a conference paper at ICLR 2020
C.4.3 Proof of equation C.29
Given
Reduce[-1/2 (b1 + b2) + 1/2 Sqrt[(b1 - b2)^2 + 16] >
(u + Sqrt[u^2 + t v])/t &&
0 < b2 < 1 &&
b2 <= bl < (b2 + Sqrt[4 + 5 b2^2])∕(2 (1 + b2^2)), {b2, b1}],
we can remove the first constraint and get:
0 < b2 < 1 &&
b2 <= b1 < b2∕(2 (1 + b2^2)) +
1∕2 Sqrt[(4 + 5 b2^2)∕(1 + b2^2)^2].
C.4.4 Proof of equation C.32
The second Jacobi condition simplifies to α > β1 and the fourth simplifies to equation C.34.
Combining with the first Jacobi condition:
Reduce[Abs[b1 b2] < 1 &&
a > b1 && (u - Sqrt[u^2 + t v])∕t < a < (u + Sqrt[u^2 + t v])∕t
&& b1 >= 0 && b2 < 0, {b2, b1, a} ] ∕∕ Simplify,
we have:
b2 < 0 && b1 > 0 &&
b2∕(1 + b2^2) + Sqrt[(4 + 5 b2^2)∕(1 + b2^2)^2] > 2 b1 &&
b1 < a < (b1 + b2 + b1^2 b2 + b1 b2^2)∕((1 + b1^2) (1 + b2^2)) +
Sqrt[((-1 + b1 b2)^2 (b1^2 + b2^2 + b1 b2 (-1 + b2^2) +
b1^3 (b2 + b2^3)))∕((1 + b1^2)^2 (1 + b2^2)^2)].
This can be further simplified to achieve equation C.32.
C.4.5 One line proof
In fact, there is another very simple proof:
Reduce[ForAll[{b1, b2, a}, (a - b1) (a - b2) > 0
&& (a + b1) (a + b2) > -4 && Abs[b1 b2] < 1 &&
a^2 (b1^2	+ 1) (b2^2 +	1) <	(b1	b2	+ 1)	(2	a	(b1 + b2) +
b1	b2 (b1	b2 - 3)),	(a	-	b1)	(a	- b2) >	0 &&
(a	+ b1)	(a + b2) <	4
&&	(a b1	+ 1) (a b2	+ 1)	> (1	+	b1	b2)^2],	{b2, b1, a}]
True.
However, this proof does not tell us much information about the range of our variables.
C.5 proof of Theorem 3.4: Schur conditions of momentum
Theorem 3.4 (momentum). For the generalized momentum method with α1 = α2 = α, the Jacobi
updates never converge, while the GS updates converge iff for any singular value σ of E, we have:
Iβ1β21 < 1, | — α2σ2 + βι + β2 + 2| < βιβ2 + 3, 4(βι + I)(β2 + 1) > α2σ2,
α2σ2β1β2 < (1 -β1β2)(2β1β2 -β1 -β2).	(3.12)
This condition implies that at least one of β1 , β2 is negative.
C.5. 1 Schur conditions of Jacobi and GS updates
Jacobi condition We first rename ασ as al and β1, β2 as b1, b2. With Theorem C.1:
19
Published as a conference paper at ICLR 2020
{Abs[d] < 1, Abs[a] < d + 3,
a + b + c + d + 1 > 0, -a + b - c + d + 1 >
0, (1 - d)^2 b - (c - a d) (a - c) - (1 + d) (1 - d)^2 <
0} /. {a -> -2 - b1 - b2, b -> al^2 + 1 + 2 (b1 + b2) + b1 b2,
c -> -b1 - b2 - 2 b1 b2, d -> b1 b2} // FullSimplify.
We obtain:
{Abs[b1 b2] < 1, Abs[2 + b1 + b2] < 3 + b1 b2, al^2 > 0,
al^2 + 4 (1 + b1) (1 + b2) > 0, al^2 (-1 + b1 b2)^2 < 0}.
The last condition is never satisfied and thus Jacobi momentum never converges.
Gauss-Seidel condition With Theorem C.1, We compute:
{Abs[d] < 1, Abs[a] < d + 3,
a + b + c + d + 1 > 0, -a + b - c + d + 1 >
0,
0}
(1 - d)^2 b + c^2 - a
/. {a -> al^2 - 2 - b1
(1 + d) c - (1
- b2, b -> 1 +
c -> -b1 - b2
2 b1 b2, d -> b1 b2} // FullSimplify.
+ d) (1 - d)^2 + a^2 d <
2 (b1 + b2) + b1 b2,
The result is:
{Abs[b1 b2]
4 (1 + b1)
al^2 (b1 +
< 1, Abs[2 - al^2
(1 + b2) > al^2,
b2 + (-2 + al^2 -
+ b1 + b2]
< 3 + b1 b2, al^2 > 0,
b1) b1 b2 + b1
(-1 + 2 b1) b2^2) < 0},
Which can be further simplified to equation 3.12.
C.5.2 Negative momentum
With Theorem 3.4, We can actually shoW that in general at least one of β1 and β2 must be negative.
There are three cases to consider, and in each case We simplify equation 3.12:
1.	β1 β2 = 0. WLOG, let β2 = 0, and We obtain
-1 < β1 < 0 and α2σ2 < 4(1 + β1).	(C.36)
2.	β1 β2 > 0. We have
-1 < β1 < 0, -1 < β2 < 0,α2σ2 < 4(1 + β1)(1 + β2).	(C.37)
3.	β1β2 < 0. WLOG, We assume β1 ≥ β2. We obtain:
-1 < β2 < 0, 0 < Bl < min — - 7Γ7Γ, I - 1 /j. |] .	(C.38)
3β2	1 + 2β2
The constraints for α are α > 0 and:
max ! (I-βlβ2)(2β1zβ2 -βl-βG , 01< ɑ2σ2 < 4(1 + βι)(1 + β2).	(C.39)
β1 β2
These conditions can be further simplified by analyzing all singular values. They only depend on σ1
and σn, the largest and the smallest singular values. NoW, let us derive equation C.37, equation C.38
and equation C.39 more carefully. Note that We use a for ασ.
C.5.3 Proof of equation C.37
Reduce[Abs[b1 b2]
4 (b1 + 1) (b2 + 1)
a^2 b1 b2 < (1 - b1
a > 0, {b2, b1, a}]
< 1 && Abs[-a^2 + b1 + b2 + 2] < b1 b2 + 3 &&
> a^2 &&
b2) (2 b1 b2 - b1 - b2) && b1 b2 > 0 &&
-1 < b2
< 0 && -1 < b1 < 0 && 0 < a
< Sqrt[4 + 4 b1 + 4 b2 + 4 b1 b2]
20
Published as a conference paper at ICLR 2020
C.5.4 Proof of equations C.38 and C.39
Reduce[Abs[b1 b2] < 1 && Abs[-a^2 + b1 + b2 + 2] < b1 b2 + 3 &&
4 (b1 + 1) (b2 + 1) > a^2 &&
a^2 b1 b2 < (1 - b1 b2) (2 b1 b2 - b1 - b2) && b1 b2 < 0 &&
b1 >= b2 && a > 0, {b2, b1, a}]
(-1 < b2 <= -(1/3) && ((0 < b1 <= b2/(-1 + 2 b2) &&
0 < a < Sqrt[4 + 4 b1 + 4 b2 + 4 b1 b2]) || (b2/(-1 + 2 b2) <
b1 < -(1/(3 b2)) &&
Sqrt[(-b1 - b2 + 2 bl b2 + b1^2 b2 + bl b2^2 - 2 b1^2 b2^2)∕(
b1 b2)] < a < Sqrt[4 + 4 b1 + 4 b2 + 4 b1 b2]))) || (-(1/3) <
b2 < 0 && ((0 < b1 <= b2∕(-1 + 2 b2) &&
0 < a < Sqrt[4 + 4 b1 + 4 b2 + 4 b1 b2]) || (b2∕(-1 + 2 b2) <
b1 < -(b2∕(1 + 2 b2)) &&
Sqrt[(-b1 - b2 + 2 b1 b2 + b1^2 b2 + b1 b2^2 - 2 b1^2 b2^2)∕(
b1 b2)] < a < Sqrt[4 + 4 b1 + 4 b2 + 4 b1 b2])))
Some further simplication yields equation C.38 and equation C.39.
D	Proofs in Section 4
For bilinear games and gradient-based methods, a Schur condition defines the region of convergence
in the parameter space, as we have seen in Section 3. However, it is unknown which setting of
parameters has the best convergence rate in a Schur stable region. We explore this problem now. Due
to Theorem 3.1, we do not need to study GD. The remaining cases are EG, OGD and GS momentum
(Jacobi momentum does not converge due to Theorem 3.4). Analytically (Section D.1 and D.2),
we study the optimal linear rates for EG and special cases of generalized OGD (Jacobi OGD with
βι = β2 and Gauss-Seidel OGD with β2 = 0). The special cases include the original form of OGD.
We also provide details for the numerical method described at the end of Section 4.
The optimal spectral radius is obtained by solving another min-max optimization problem:
min max r(θ, σ),	(D.1)
θ σ∈Sv(E)
where θ denotes the collection of all hyper-parameters, and r(θ, σ) is defined as the spectral radius
function that relies on the choice of parameters and the singular value σ. We also use Sv(E) to
denote the set of singular values of E .
In general, the function r(θ, σ) is non-convex and thus difficult to analyze. However, in the special
case of quadratic characteristic polynomials, it is possible to solve equation D.1. This is how we will
analyze EG and special cases of OGD, as r(θ, σ) can be expressed using root functions of quadratic
polynomials. For cubic and quartic polynomials, it is in principle also doable as we have analytic
formulas for the roots. However, these formulas are extremely complicated and difficult to optimize
and we leave it for future work. For EG and OGD, we will show that the optimal linear rates depend
only on the conditional number κ := σ1 /σn .
For simplicity, we always fix α1 = α2 = α > 0 using the scaling symmetry studied in Section 3.
D.1 Proof of Theorem 4.1: Optimal convergence rate of EG
Theorem 4.1	(EG optimal). Both Jacobi and GS EG achieve the optimal exponent of linear conver-
gence r* = (κ2 一 1)∕(κ2 + 1) at α → 0 and βι = β2 = 2∕(σ2 + σ%). As K → ∞, r* → 1 一 2∕κ2.
D.1.1 Jacobi EG
For Jacobi updates, if β1 = β2 = β, by solving the roots of equation 3.2, the min-max problem is:
min max pα2σ2 + (1 — βσ2)2.	(D.2)
α,β σ∈Sv(E)
21
Published as a conference paper at ICLR 2020
If σι = σn = σ, We can simply take α → 0 and β = 1∕σ2 to obtain a super-linear convergence rate.
Otherwise, let us assume σ1 > σn . We obtain a lower bound by taking α → 0 and equation D.2
reduces to:
min max |1 - βσ2 |.
β σ∈Sv(E)
(D.3)
The optimal solution is given at 1 - βσ, = βσ( - 1, yielding β = 2∕(σ2 + σ]). The optimal radius
is thus (σ2 - σn)∕(σ2 + σ∖) since the lower bound equation D.3 can be achieved by taking ɑ → 0.
From general β1, β2, it can be verified that the optimal radius is achieved at β1 = β2 and the problem
reduces to the previous case. The optimization problem is:
min max r (α, β1 , β2 , σ),	(D.4)
α,β1,β2 σ∈Sv(E)
where
r(α, β1, β2, σ)
(vz(1 - βισ2)(1 - β2σ2) + α2σ2
111 - 1 (β1 + β2)σ2∣ + 1 p/(β1 - β2)2σ4 - 4α2σ2
4α2 > (β1 - β2)2σ2,
4α2 ≤ (β1 - β2)2σ2.
In the first case, a lower bound is obtained at α2 = (βι - β2)2σ2∕4 and thus the objective only
depends on β1 + β2. In the second case, the lower bound is obtained at α → 0 and β1 → β2 .
Therefore, the function is optimized at β1 = β2 and α → 0.
Our analysis above does not mean that α → 0 and β1 = β2 = 2∕(σ12 + σn2 ) is the only optimal
choice. For example, when σ1 = σn = 1, we can take β1 = 1 + α and β2 = 1 - α to obtain a
super-linear convergence rate.
D.1.2 Gauss-Seidel EG
For Gauss-Seidel updates and βι = β2 = β, we do the following optimization:
min max
α,β σ∈Sv(E)
r(α, β, σ),
(D.5)
where by solving equation 3.3:
r(αβσ)J1-βσ2	________________________
(O- σ2 — (1 — βσ2) + / α2σ2(α2 σ2 — 4(1 — βσ2))/2
α2σ2 < 4(1 - βσ2),
α2σ2 ≥ 4(1 - βσ2).
r(σ, β, σ2) is quasi-convex in σ2, so we just need to minimize over α, β at both end points. Hence,
equation D.5 reduces to:
min max{r(α, β, σ1), r(α, β, σn)}.
α,β
By arguing over three cases: ɑ2 +4β < 4∕σ2, ɑ2 + 4β > 4∕σ∕ and 4∕σ2 ≤ α2 +4β ≤ 4∕σ,, we
find that the minimum (κ2 - 1)∕(κ2 + 1) can be achieved at α → 0 and β = 2∕(σ2 + σ2), the same
as Jacobi EG. This is because α → 0 decouples x and y and it does not matter whether the update is
Jacobi or GS.
For general β1, β2, it can be verified that the optimal radius is achieved at β1 = β2 . We do the
following transformation: βi → ξi - α2∕2, so that the characteristic polynomial becomes:
(λ- 1)2+(ξ1+ξ2)σ2(λ-1)+α2σ2+(ξ1-α2∕2)(ξ2 - α2∕2)σ4 =0.	(D.6)
Denote ξ1 + ξ2 = φ, and (ξ1 - α2∕2)(ξ2 - α2∕2) = ν, we have:
λ2 - (2 - σ2φ)λ + 1 - σ2φ + σ4v + σ2α2 = 0.	(D.7)
The discriminant is ∆ := σ2 (σ2 (φ2 - 4ν) - 4α2 ). We discuss two cases:
1.	φ2 - 4ν < 0. We are minimizing:
min ∖∕1 + (α2 - φ)σ2 + σ4ν ∨ /1 + (α2 - φ)σ, + σ,V,
,u,v
with a∨ b := max{a, b} a shorthand. A minimizer is at α → 0 and ν → φ2∕4 (since
φ2 < 4ν), where β1 = β2 = 2∕(σ12 + σn2 ) and α → 0.
22
Published as a conference paper at ICLR 2020
2.	φ2 - 4ν ≥ 0. A lower bound is:
min |1 - φσ2∕2∣ ∨ |1 -。-：/2|,
u
which is obtained iff 4α2 〜(φ2 - 4ν)t for all σ2. This is only possible if α → 0 and
φ2 → 4ν, which yields βι = β2 = 2∕(σ2 + σ^).
From what has been discussed, the optimal radius is (κ2 - 1)∕(κ2 + 1) which can be achieved at
β = β2 = 2/(。2 + σn2 ) and α → 0. Again, this might not be the only choice. For instance, take
σ1 = σn2 = 1, from equation 3.3, a super-linear convergence rate can be achieved at β1 = 1 and
β2 = 1 - α2 .
D.2 Proof of Theorem 4.2: Optimal convergence rate of OGD
Theorem 4.2	(OGD optimal). For Jacobi OGD with β1 = β2 = β, to achieve the optimal linear
rate, we must have α ≤ 2β. For the original OGD with α = 2β, the optimal linear rate r* satisfies
J — 1 -U 1	4 2 (n∙2 n-2	5rr 2 n-2	ι q ΓΓ2 Z2WnZ2	∑2	D8,
r* = 2 + 4√2σ2	V (σ1	- σn)(5σ1	- σn	+ V (σ1	- σn)(9σ1	- σn)),	(D∙8)
at
β = 4√2 产
—
2 C2、3/2, ∕9∑2	2^ _l 6rτ2zτ2 zτ4
(σ1 - σn) / ^√9σ1 - σn +6σ1 σn - σn
σ4σn
(D.9)
If K → ∞, r* 〜1 — 1∕(6κ2). For GauSS-Seidel OGD with β2 = 0, the optimal linear rate is
r* =(K(κ2 - 1)∕(κ2 + 1),, at a = √2∕σ1 and β1 = √2σ1∕(σ2 + σ%). If K → ∞, r* 〜1 — 1∕κ2.
For OGD, the characteristic polynomials equation 3.6 and equation 3.7 are quartic and cubic separately,
and thus optimizing the spectral radii for generalized OGD is difficult. However, we can study two
special cases: for Jacobi OGD, we take β1 = β2; for Gauss-Seidel OGD, we take β2 = 0. In both
cases, the spectral radius functions can be obtained by solving quadratic polynomials.
D.2.1 Jacobi OGD
We assume β1 = β2 = β in this subsection. The characteristic polynomial for Jacobi OGD
equation 3.6 can be written as:
λ2(λ- 1)2 + (λα - β)2σ2 =0.	(D.10)
Factorizing it gives two equations which are conjugate to each other:
λ(λ- 1)±i(λα-β)σ =0.	(D.11)
The roots of one equation are the conjugates of the other equation. WLOG, we solve λ(λ - 1) +
i(λα - β)σ = 0 which gives (1∕2)(u ± v), where
U = 1 — iασ, V = p1 — α2σ2 — 2i(α — 2β)σ.	(D.12)
Denote ∆1 = 1 - α2σ2 and ∆2 = 2(α - 2β)σ. If α ≥ 2β, v can be expressed as:
1
V = √2
H,δ2 + δ2 + ∆1 - i Wδ2 + δ2 -△1) =: √2(a - ib),
(D.13)
therefore, the spectral radius r(α, β, σ) satisfies:
r(α, β, σ)2 = 4 ((1 + a∕√2)2 + (ασ + b∕√2)2) = 4(1 + α2σ2 + J∆2 + ∆2 + √2(bσα + a)),
(D.14)
and the minimum is achieved at α = 2β . From now on, we assume α ≤ 2β, and thus V = a + ib.
We write:
r(α, β, σ)2 = 1 max{ ((1 + a∕√2)2 + (ασ - b∕√¾2) , ((1 - a∕√2)2 + (ασ + b∕√2)2)},
= 4(1 + α2σ2 + J∆ + ∆2 + √2∣bσα - a|).
(4 (1 + α2σ2	+	P∆2 + ∆2	— √2(bσα —	a))	0 < ασ ≤	1,
1 1 (1 + α2σ2	+	P△[ + ∆2	+ √2(bσα —	a))	ασ > 1.
(D.15)
23
Published as a conference paper at ICLR 2020
This is a non-convex and non-differentiable function, which is extremely difficult to optimize.
At α = 2β, in this case, a = pl - 4β2σ2sign(1 一 4β2σ2) and b = p4β2σ2 — 1sign(4β2σ2 一 1).
The sign function sign(x) is defined to be 1 if x > 0 and 0 otherwise. The function we are optimizing
is a quasi-convex function:
r(β, σ)2
1( (1 + pi- 4β2σ2)
[2β2σ2 + βσ√4β2σ2 - 1
4β2σ2 ≤ 1,
4β2σ2 > 1.
(D.16)
We are maximizing over σ and minimizing over β. There are three cases:
•	4β2σ12 ≤ 1. At 4β2σ12 = 1, the optimal radius is:
r2 = 2 1 +
•	4β2σn2 ≥ 1. At 4β2σn2 = 1, the optimal radius satisfies:
r
2
*
κ2 κ
T+2 Z
-1.
•	4β2σn2 ≤ 1 and 4β2σ12 ≥ 1. The optimal β is achieved at:
2 (1 + √1 - 4户时)=2β2σ2 + βσ1,4β2σ2 - 1.
The solution is unique since the left is decreasing and the right is increasing. The optimal β
is:
1	3 Qrr4	2	C2、3/2, ∕9Σ2	2/2 ∣ 6rr2zτ2	zτ4
_	1	/	3σι	- (σ1 - σn) / V9σ1	-	σn	十 6σ1	σn	-	σn
β* = 4√2v	σ4σn
(D.17)
The optimal radius satisfies:
r2 = 1 + 4√⅛2 M -σn)(5σ2 -σn + q(σ -σn)(9σ2 -σn).。⑻
This is the optimal solution among the three cases. If σn2 /σ12 is small enough we have
r2 ~ 1 - 1∕(3κ2).
D.2.2 GAUSS-SEIDEL OGD
In this subsection, We study Gauss-Seidel OGD and fix β2 = 0. The characteristic polynomial
equation 3.7 now reduces to a quadratic polynomial:
λ2 + (α2σ2 - 2)λ + 1 - αβ1 σ2 = 0.
For convenience, We reparametrize β1 → β∕α. So, the quadratic polynomial becomes:
λ2 + (α2σ2 -2)λ+1 -βσ2 =0.
We are doing a min-max optimization minα,β maxσ r(α, β, σ), Where r(α, β, σ) is:
( β )_ √ √1 - βσ2	______________________ α4σ2 < 4(α2	- β)
，°i, ，σ 2∣ 2 ∣α2σ2 — 2|	+ 2 √ɑ4σ4	— 4(α2	— β)σ2	α4σ2 ≥ 4(α2	— β).
There are three cases to consider:
(D.19)
•	α4σ12 ≤ 4(α2 - β). We are minimizing 1 - βσn2 over α and β. Optimizing over β1 gives
β = α2 -α4σ12∕4. Then We minimize over α and obtain α2 = 2∕σ12. The optimal β = 1∕σ12
and the optimal radius is，1 - 1∕κ2.
24
Published as a conference paper at ICLR 2020
•	α4σn2 > 4(α2 - β). Fixing α, the optimal β = α2 - α4 σn2 /4, and we are solving
mαnmaχ∣2 ia2σ2 - 2| + 1 ɑ2qσ2(σ2 - σn), 2 iα2σn — 2|}.
We need to discuss three cases: α2σn > 2, α2σ2 < 2 and 2∕σ12 < α2 < 2∕σ.. In the first
case, the optimal radius is
κ2 — 1 + κp(κ2 — 1).
In the second case, α2 → 2∕σ2 and the optimal radius is，1 — 1∕κ2. In the third case, the
optimal radius is also，1 — 1∕κ2 minimized at α2 → 2∕σ2.
• α4σ12 > 4(α2 — β) and α4σn2 < 4(α2 — β). In this case, we have α2σ12 < 4. Otherwise,
r(α, β, σ1) > 1. We are minimizing over:
max{P1 - βσ1, 1 ∣ɑ2σ2 — 2| + 2 Ja4σ4 — 4α2σ2 + 4βσ2}.
The minimum over a is achieved at α2σ2 = 2, and β = 2∕(σ2 + σ∖),this gives α = √2∕σ1
and βι = √2σ1∕(σ2 + σ^). The optimal radius is r* = p(κ2 — 1)∕(κ2 + 1).
Out of the three cases, the optimal radius is obtained in the third case, where r 〜1 — 1∕κ2. This is
better than Jacobi OGD, but still worse than the optimal EG.
D.3 Numerical method
We first prove Lemma 4.1:
Lemma 4.1. A polynomial p(λ) is r-Schur stable iff p(rλ) is Schur stable.
Proof. Denotep(λ) = Qn=1(λ — λi). We havep(rλ) H Qn=1(λ — λi∕r), and:
∀i ∈ [n], ∣λi∣ < r ^⇒ ∀i ∈ [n], ∣λi∕r∣ < 1.	(D.20)
□
With Lemma 4.1 and Corollary 2.1, we have the following corollary:
Corollary D.1. A real quadratic polynomial λ2 + aλ + b is r-Schur stable iff b < r2, |a| < r + b∕r;
A real cubic polynomial λ3 + aλ2 + bλ + c is r-Schur stable iff |c| < r3, |ar2 + c| < r3 + br,
br4 — acr2 < r6 — c2; A real quartic polynomial λ4 + aλ3 + bλ2 + cλ + d is r-Schur stable iff
|cr5 — adr3| < r8 — d2, |ar2 + c| < br + d∕r + r3, and
b<r2 + dr-2 + J (Cr2 — ad),：：-C).
(d — r4)2
Proof. In Corollary 2.1, rescale the coefficients according to Lemma 4.1.	□
We can use the corollaries above to find the regions where r-Schur stability is possible, i.e., a linear
rate of exponent r. A simple algorithm might be to start from r0 = 1, find the region S0. Then
recursively take rt+1 = srt and find the Schur stable region St+1 inside St . If the region is empty
then stop the search and return St. s can be taken to be, say, 0.99. Formally, this algorithm can be
described as follows in Algorithm 1:
r0 = 1, t = 0, s = 0.99;
Find the r0-Schur region S0;
while St is not empty do
rt+1 = srt ;
Find the rt+1-Schur region St+1;
t=t+1;
end
Algorithm 1: Numerical method for finding the optimal convergence rate
In this algorithm, Corollary D.1 can be applied to obtain any r-Schur region.
25
Published as a conference paper at ICLR 2020
Figure 6: Test samples generated from the generator network trained with stochastic Adam. Top row:
Jacobi updates; Bottom row: GaUss-Seidel updates. Columns (left to right): epoch 0, 5, 10, 20.
E S upplementary material for Sections 5 and 6
We provide supplementary material for Sections 5 and 6. We first prove that when learning the
mean of a Gaussian, WGAN is locally a bilinear game in Appendix E.1. For mixtures of Gaussians,
we provide supplementary experiments about Adam in Appendix E.2. This result implies that in
some cases, Jacobi updates are better than GS updates. We further verify this claim in Appendix E.3
by showing an example of OGD on bilinear games. Optimizing the spectral radius given a certain
singular value is possible numerically, as in Appendix E.4.
E.1 Wasserstein GAN
Inspired by Daskalakis et al. (2018), we consider the following WGAN (Arjovsky et al., 2017):
f(Φ, θ) = min max Ex 〜N (v,σ2i) [s(θ>x)] — Ez 〜N (。工 I)[s(θ>(z + Φ))],	(E.1)
φθ
with s(x) := 1/(1 + e-x) the sigmoid function. We study the local behavior near the saddle point
(v, 0), which depends on the Hessian:
θ θ
2φ2θ
VV
φφ
2φ2θ
VV
-Eφ[s00(θ>z)θθ>]	-Eφ[s00(θ>z)θz> + s0(θ>z)I]
(Vφθ)>	Ev[s00(θ>x)xx>] - Eφ[s00(θ>z)zz>]
with Ev a shorthand for Ex〜N(v,σ2i) and Eφ for Ez〜N(ψ,^2∑). At the saddle point, the Hessian is
simplified as:
=
θθ
2φ2θ
VV
φφ
2φ2θ
VV
4
I/0
-
4
0I/
-
=
I
0(0)0
0
Therefore, this WGAN is locally a bilinear game.
E.2 Mixtures of Gaussians with Adam
Given the same parameter settings as in Section 5, we train the vanilla GAN using Adam, with the
step size α = 0.0002, and β1 = 0.9, β2 = 0.999. As shown in Figure 6, Jacobi updates converge
faster than the corresponding GS updates.
26
Published as a conference paper at ICLR 2020
Figure 7: Contour plot of spectral radius equal to 0.8. The red curve is for the Jacobi polynomial and
the blue curve is for the GS polynomial. The GS region is larger but for some parameter settings,
Jacobi OGD achieves a faster convergence rate.
E.3 Jacobi updates may converge faster than GS updates
Take α = 0.9625, β1 = β2 = β = 0.5722, and σ = 1, the Jacobi and GS OGD radii are separately
0.790283 and 0.816572 (by solving equation 3.6 and equation 3.7), which means that Jacobi OGD
has better performance for this setting of parameters. A more intuitive picture is given as Figure 7,
where we take β1 = β2 = β .
E.4 Single singular value
We minimize r(θ, σ) for a given singular value numerically. WLOG, we take σ = 1, since we can
rescale parameters to obtain other values of σ . We implement grid search for all the parameters within
the range [-2, 2] and step size 0.05. For the step size α, we take it to be positive. We use {a, b, s} as
a shorthand for {a, a + s, a + 2s, . . . , b}.
•	We first numerically solve the characteristic polynomial for Jacobi OGD equation 3.6, fixing
α1 = α2 = α with scaling symmetry. With α ∈ {0, 2, 0.05}, βi ∈ {-2, 2, 0.05}, the best
parameter setting is α = 0.7, β1 = 0.1 and β2 = 0.6. β1 and β2 can be switched. The
optimal radius is 0.6.
•	We also numerically solve the characteristic polynomial for Gauss-Seidel OGD equation 3.7,
fixing α1 = α2 = α with scaling symmetry. With α ∈ {0, 2, 0.05}, βi ∈ {-2, 2, 0.05},
the best parameter setting is α = 1.4, βι = 0.7 and β2 = 0. βι and β2 can be switched.
The optimal rate is 1∕(5√2). This rate can be further improved to be zero where α = √2,
βι = 1/√2 and β2 = 0.
•	Finally, we numerically solve the polynomial for Gauss-Seidel momentum equation 3.11,
with the same grid. The optimal parameter choice is α = 1.8, β1 = -0.1 and β2 = -0.05.
β1 and β2 can be switched. The optimal rate is 0.5.
F Splitting Method
In this appendix, we interpret the gradient-based algorithms (except PP) we have studied in this paper
as splitting methods (Saad, 2003), for both Jacobi and Gauss-Seidel updates. By doing this, one can
understand our algorithms better in the context of numerical linear algebra and compare our results in
Section 3 with the Stein-Rosenberg theorem.
27
Published as a conference paper at ICLR 2020
F.1 Jacobi updates
From equation 2.2, finding a saddle point is equivalent to solving:
-b
-E>
: d.
(F.1)
0
E
0
x
y
c
Now, we try to understand the Jacobi algorithms using splitting method. For GD and EG, the method
splits S into M - N and solve
zt+1 = M-1Nzt + M-1d.	(F.2)
For GD, we can obtain that: M=	α1-1i 0 0	α2-1i	,N=	α1-1i	-E E>	α2-1i	.	(F.3)
For EG, we need to compute an inverse:				
M-1 =	αE1 I> -β1IE , N =M-S.	(F.4)
β2E	α2I
Given det(α1α2I + β1β2EE>) 6= 0, the inverse always exists.
The splitting method can also work for second-step methods, such as OGD and momentum. We split
S = M -N - P and solve:
	zt+1 = M-1Nzt + M-1Pzt-1 + M	—1d.	(F.5)
For OGD, we have:			
	「 I	aιE	^∣		
一 I	0	a1 —βι	a1 —βι	「	0	βιE 1	
M = a1-β1 ∩ 0	I	, N =	T	, P =	0 T	aι-βτ β2 E>	.	(F.6)
	a2-β2	a2E >	I	————	0 aɔ 一 βo a2— 2	
	a2 —β2	a2-β2		
For the momentum method, we can write:
	α-1I	0 -		'Mβι I	-E		-βι I	0	
M=	0 a-1I	,N=	a1 E>	1 + β2 I a2	,P=	a1 0	-a21	.	(F.7)
F.2 GAUSS-SEIDEL UPDATES
Now, we try to understand the GS algorithms using splitting method. For GD and EG, the method
splits S into M - N and solve
	zt+1	= M—	1Nzt + M—1d.			(F.8)
For GD, we can obtain that:						
M=	α-1I -E>	0 a—1I	,N=	a—1I 0	-E a-1I	.	(F.9)
For EG, we need to compute an inverse:						
M-1 = (β2+αα11Iα2)E> α2(I--ββ11EE>E) , N =M -S.	(F.10)
The splitting method can also work for second-step methods, such as OGD and momentum. We split
S = M -N - P and solve:
zt+1 = M-1Nzt + M-1Pzt-1 + M-1d.
(F.11)
For OGD, we obtain:
M
∣- I
α1-β1
α2E>
------ττ~
α2-β2
0
I
ɑ2-β2 -
I
α1-β1
β2E>
α2 -β2
α1 E
α1 -β1
I
α2-β2
「0 βιE	^∣
0	α1-β1
00
(F.12)
N
For the momentum method, we can write:
M
α1-1I
-E>
0
α2-1I
,1+β11	-E 一
α1
0	1+β21
α2
P = [- a? i
=0
-β21
α2
(F.13)
N
0
28
Published as a conference paper at ICLR 2020
G	Singular bilinear games
In this paper we considered the bilinear game when E is a non-singular square matrix for simplicity.
Now let us study the general case where E ∈ Rm×n . As stated in Section 2, saddle points exist iff
b ∈ R(E), c ∈ R(E>).	(G.1)
Assume b = Eb0, c = E>c0. One can shift the origin of x and y: x → x - b0, y → y - c0, such
that the linear terms cancel out. Therefore, the min-max optimization problem becomes:
min max x> Ey.	(G.2)
x∈Rm y∈Rn
The set of saddle points is:
{(x, y)|y ∈N(E), X ∈N(E>)}.	(G.3)
For all the first-order algorithms we study in this paper, x(t) ∈ x(0) +R(E) and y(t) ∈ y(0) +R(E>).
Since for any matrix X ∈ Rp×q, R(X)㊉ N(X>) = Rp, if the algorithm converges to a saddle
point, then this saddle point is uniquely defined by the initialization:
X* = P⊥x⑼，y* = P⊥> y⑼,	(G.4)
where
PX := I - XtX,	(G.5)
is the orthogonal projection operator onto the null space of X, and Xt denotes the Moore-Penrose
pseudoinverse. Therefore, the convergence to the saddle point is described by the distances of X(t)
and y(t) to the null spaces N(E>) andN(E). We consider the following measure:
∆t2 = ||EtEy(t)||2 + ||EEtX(t)||2,	(G.6)
as the Euclidean distance of z(t) = (X(t), y(t)) to the space of saddle points N(E>) × N(E).
Consider the singular value decomposition of E:
E= U Σ0r 00 V>,	(G.7)
with Σr ∈ Rr×r diagonal and non-singular. Define:
v(t) = V >y(t), u(t) = U>X(t),	(G.8)
and equation G.6 becomes:
∆t2 = ||vr(t)||2 + ||u(rt)||2,	(G.9)
with vr denoting the sub-vector with the first r elements of v. Hence, the convergence of the bilinear
game with a singular matrix E reduces to the convergence of the bilinear game with a non-singular
matrix Σr, and all our previous analysis still holds.
29