Published as a conference paper at ICLR 2020
An Inductive Bias for Distances: Neural Nets
that Respect the Triangle Inequality
Silviu Pitis*, Harris Chan*, Kiarash Jamali, Jimmy Ba
University of Toronto, Vector Institute
{spitis, hchan}@cs.toronto.edu
Ab stract
Distances are pervasive in machine learning. They serve as similarity measures,
loss functions, and learning targets; it is said that a good distance measure solves
a task. When defining distances, the triangle inequality has proven to be a useful
constraint, both theoretically—to prove convergence and optimality guarantees—
and empirically—as an inductive bias. Deep metric learning architectures that
respect the triangle inequality rely, almost exclusively, on Euclidean distance in the
latent space. Though effective, this fails to model two broad classes of subadditive
distances, common in graphs and reinforcement learning: asymmetric metrics, and
metrics that cannot be embedded into Euclidean space. To address these problems,
we introduce novel architectures that are guaranteed to satisfy the triangle inequality.
We prove our architectures universally approximate norm-induced metrics on Rn ,
and present a similar result for modified Input Convex Neural Networks. We show
that our architectures outperform existing metric approaches when modeling graph
distances and have a better inductive bias than non-metric approaches when training
data is limited in the multi-goal reinforcement learning setting.1
1	Introduction
Many machine learning tasks involve a distance measure over the input domain. A good measure
can make a once hard task easy, even trivial. In many cases—including graph distances, certain
clustering algorithms, and general value functions in reinforcement learning (RL)—it is either known
that distances satisfy the triangle inequality, or required for purposes of theoretical guarantees; e.g.,
speed and loss guarantees in k-nearest neighbors and clustering (Cover and Hart, 1967; Indyk, 1999;
Davidson and Ravi, 2009), or optimality guarantees for A* search (Russell and Norvig, 2016). This
also makes the triangle inequality a potentially useful inductive bias for learning distances. For these
reasons, numerous papers have studied different ways to learn distances that satisfy the triangle
inequality (Xing et al., 2003; Yang and Jin, 2006; Brickell et al., 2008; Kulis et al., 2013).
The usual approach to enforcing the triangle inequality in deep metric learning (Yi et al., 2014;
Hoffer and Ailon, 2015; Wang et al., 2018) is to use a Siamese network (Bromley et al., 1994) that
computes a Euclidean distance in the latent space. Specifically, the Siamese network models distance
dX : X × X → R+ on domain X by learning embedding φ : X → Rn and computing dX (x, y) as
kφ(x) - φ(y)k2. Successful applications include collaborative filtering (Hsieh et al., 2017), few-shot
learning (Snell et al., 2017), and multi-goal reinforcement learning (Schaul et al., 2015). The use of
Euclidean distance, however, has at least two downsides. First, the Euclidean architecture cannot
represent asymmetric metrics, which arise naturally in directed graphs and reinforcement learning.
Second, it is well known that for some metric spaces (X, dX), including large classes of symmetric
graphs (e.g., constant-degree expanders and k-regular graphs), there is no embedding φ : X → Rn
that can model dχ precisely using ∣∣ ∙ ∣∣2 (Indyk et al., 2017). A classic example is shown in Figure 1.
In part due to these issues, some have considered non-architectural constraints. He et al. (2016)
impose a triangle inequality constraint in RL via an online, algorithmic penalty. Implementing such a
penalty can be expensive, and does not provide any guarantees. An approach that does guarantee
1Code available at https://github.com/spitis/deepnorms
1
Published as a conference paper at ICLR 2020
Norm	MSE
Euclidean, Rn,∀n	0.057
Deep Norm, R2	0.000
Wide Norm, R2	0.000
Mahalanobis
Fig. 1： The nodes in the graph (left) cannot be embedded into any Rn so that edge distances are
represented by the Euclidean metric: points φ(A) and φ(D) must lie at the midpoint of the segment
from φ(B) to φ(C)—but then φ(A) and φ(D) coincide, which is incorrect. Our models fit the data
in R2 (middle). The visualization (right) shows learned norm balls in red and embeddings in blue.
satisfaction of triangle inequality is to fix any violations after learning, as done by Brickell et al.
(2008). But this does not scale to large problems or provide an inductive bias during learning.
Is it possible to impose the triangle inequality architecturally, without the downsides of Euclidean
distance?
In response to this question, we present the following contributions: (1) three novel neural network
architectures, Deep Norms, Wide Norms and Neural Metrics, which model symmetric and asymmetric
norms and metrics, (2) universal approximation theorems for Deep Norms and Wide Norms and
modified Input Convex Neural Networks (Amos et al., 2017), and (3) empirical evaluations of our
models on several tasks: modeling norms, metric nearness, modeling shortest path lengths, and
learning a general value function (Sutton et al., 2011). Our models are guaranteed to satisfy the
triangle inequality, straightforward to implement, and may be used in place of the usual Euclidean
metric should one seek to model asymmetry or increase expressiveness.
2	Modeling Norms
2.1	Preliminaries
Our goal is to construct expressive models of metrics and quasi-metrics on domain X . A metric is a
function d : X × X → R+ satisfying, ∀x, y, z ∈ X :
M1 (Non-negativity). d(x, y) ≥ 0.	M3 (Subadditivity). d(x,	z)	≤ d(x, y)	+ d(y,	z).
M2 (Definiteness). d(x, y) = 0 ^⇒	X = y. M4 (Symmetry). d(x, y)	=	d(y, x).
Since we care mostly about the triangle inequality (M3), we relax other axioms and define a quasi-
metric as a function that is M1 and M3, but not necessarily M2 or M4. Given weighted graph
G = (V, E) with non-negative weights, shortest path lengths define a quasi-metric between vertices.
When X is a vector space (we assume over R), many common metrics, e.g., Euclidean and Manhattan
distances, are induced by a norm. A norm is a function k ∙ k : X → R satisfying, ∀x, y ∈ X, α ∈ R+:
N1 (Pos. def.). kxk > 0, unless x = 0.	N3	(Subadditivity). kx + yk ≤ kxk + kyk .
N2 (Pos. homo.). α∣∣xk = ∣∣αxk ,for a ≥ 0. N4 (Symmetry). kxk = ∣∣ - x∣∣.
An asymmetric norm is N1-N3, but not necessarily N4. An (asymmetric) semi-norm is non-
negative, N2 and N3 (and N4), but not necessarily N1. We will use the fact that any asymmetric
semi-norm ∣∣ ∙ ∣∣ induces a quasi-metric using the rule, d(χ,y) = ||x 一 y∣, and first construct
models of asymmetric semi-norms. Any induced quasi-metric d is translation invariant—d(x, y) =
d(x + z, y + Z)—and positive homogeneous—d(αx, αy) = αd(x, y) for ɑ ≥ 0. If ∣∙∣ is symmetric
(N4), so is d (M4). If ∣∙ ∣∣ is N1, d is M2. Metrics that are not translation invariant (e.g., Bi et al.
(2015)) or positive homogeneous (e.g., our Neural Metrics in Section 3) cannot be induced by a norm.
A convex function f : X → R is a function satisfying C1: ∀x,y ∈ X, α ∈ [0,1]: f(ax+(1-a)y) ≤
αf(x) + (1 一 α)f (y). The commonly used ReLU activation, relu(x) = max(0, x), is convex.
2.2	Deep Norms
It is easy to see that any N2 and N3 function is convex—thus, all asymmetric semi-norms are convex.
This motivates modeling norms as constrained convex functions, using the following proposition.
Proposition 1. All positive homogeneous convex functions are subadditive; i.e., C1 ∧ N2 ⇒ N3.
2
Published as a conference paper at ICLR 2020
The proof is straightforward (PUt α = 1 in C1 and apply
N2 to the left side). To use Proposition 1, we begin with the
InpUt Convex NeUral Network (ICNN) (Amos et al., 2017)
architectUre, which satisfies C1, and fUrther constrain it to
be non-negative and satisfy N2. The resUlting Deep Norm
architectUre is gUaranteed to be an asymmetric semi-norm. A
k-layer Deep Norm is defined as:
IlxII = hk,	with	hi = gi(Wi+hi-i + Uix)	(1)	.
for i = 1...k, where x is the input, h0 = 0, W+ = 0, the activationfUgnCtioneeP NNormervecCiiecnurN 2
(element-wise), gk is non-negative, W++ is a non-negative matrix, and Ui is an unconstrained matrix.
As compared to the original ICNN architecture, we have omitted the bias terms from Equation 1,
have constrained the gi to preserve positive homogeneity while also allowing them to be any function
that preserves element-wise convexity (this is essential to our universal approximation results), and
have required gk to be non-negative. It is easy to verify that the set of valid element-wise gi is
{gαβ (x) = α relu(x) + βx | α, β ≥ 0}. This includes ReLUs and leaky ReLUs. But we do not
restrict ourselves to element-wise activations. Inspired by GroupSort (Anil et al., 2018), we use
activations that depend on multiple inputs (and preserve element-wise C1 and N2). In particular, we
use the pairwise MaxReLU:
maxrelu(x, y) = [max(x, y), α relu(x) + β relu(y)], where α, β ≥ 0	(2)
Deep Norms are N2 and N3. Using the following propositions, we may also impose N1 and N4.
Proposition 2. If k ∙ | is an asymmetric semi-norm, then ∣∣x∣ = ||x| + ∣∣ 一x| is a semi-norm.
Proposition 3. If ∣∣ ∙ ∣∣a is an (asymmetric) semi-norm, ∣ ∙ ∣∣b is a norm (e.g., ∣ ∙ ∣∣b = ∣∣ ∙ ∣∣2), and
λ > 0, then ∣x∣a+λb = ∣x∣a + λ∣x∣b is an (asymmetric) norm.
2.3	Wide Norms
In addition to Deep Norms, we propose the following alternative method for constructing norms: a
Wide Norm is any combination of (asymmetric) (semi-) norms that preserves N1-N4. It is easy to
verify that both (1) non-negative sums and (2) max are valid combinations (indeed, these properties
were also used to construct Deep Norms), and so the vector-wise MaxMean combination is valid:
maxmean(x1, x2, . . . , xn) = α max(x1, x2, . . . , xn) + (1 - α) mean(x1, x2, . . . , xn).
Although the family of Wide Norms is broad, for computational reasons to be discussed in Subsection
3.5, we focus our attention on the Wide Mahalanobis norm. References to “Wide Norms” in the rest
of this paper refer to Wide Mahalanobis norms. The Mahalanobis norm of x ∈ Rn , parameterized
by W ∈ Rm×n, is defined as IlxkW = ∣∣ Wx∣2. It is easily verifiedthat ∣ ∙ ∣∣w is a proper norm when
W is a non-singular (square) matrix, and a semi-norm when W is singular or m < n.
A k-component Mixture of Mahalanobis norm (hereafter Wide Norm, or Wide Norm with k Eu-
clidean components) is defined as the maxmean of k Mahalanobis norms:
∣x∣ = maxmeani (∣Wix∣2) where Wi ∈ Rmi×n with mi ≤ n.	(3)
Wide Norms are symmetric by default, and must be asymmetrized to obtain asymmetric (semi-)
norms. We use the below property (Bauer et al., 1961) and propositions (proofs in Appendix A).
N5. Il ∙ ∣ is monotonic in the positive orthant if 0 ≤ x ≤ y (element-wise) implies ∣∣x∣ ≤ ∣∣y∣∣∙
Proposition 4. If ∣∣ ∙ ∣∣ is an N5 (semi-) norm on R2n, then ||x| = ∣∣relu(x :: 一x)∣, where :: denotes
concatenation, is an asymmetric (semi-) norm on Rn.
Proposition 5. The Mahalanobis norm with W = DU, with D diagonal and U non-negative, is N5.
2.4	Universal Approximation of Convex Functions and Norms
How expressive are Deep Norms and Wide Norms? Although it was empirically shown that ICNNs
have “substantial representation power” (Amos et al., 2017), the only prior work characterizing the
approximation power of ICNNs uses a narrow network with infinite depth, which does not reflect
typical usage (Chen et al., 2018). One of our key contributions is a series of universal approximation
results for ICNNs (with MaxReLU activations), Deep Norms and Wide Norms that use a more
practical infinite width construction. The next lemma is central to our results.
3
Published as a conference paper at ICLR 2020
Lemma 1 (Semilattice Stone-Weierstrass (from below)). Let C be a set of continuous functions
defined on compact subset K of Rn, L be a closed subset of C, and f ∈ C. If (1) for every x ∈ K,
there exists gx ∈ L such that gx ≤ f and gx (x) = f (x), and (2) L is closed under max (i.e.,
a, b ∈ L ⇒ max(a, b) ∈ L), then ∃h ∈ L with f = h on K.
Intuitively, Lemma 1 and its proof (Appendix A) say we can approximate continuous f arbitrarily
well with a family L of functions that is closed under maximums if we can “wrap” f from below using
functions gx ∈ L with gx ≤ f . Our Universal Approximation (UA) results are now straightforward.
Theorem 1 (UA for MICNNs). The family M of Max Input Convex Neural Networks (MICNNs) that
uses pairwise max-pooling (or MaxReLU) activations is dense in the family C of convex functions.
Proof. For f ∈ C , x ∈ Rn , let gx ∈ M be a linear function whose hyperplane in the graph of f is
tangent to f at x. Then gx satisfies condition (1) of Lemma 1 (because f is convex). The use of
pairwise max activations allows one to construct max(h1, h2) ∈ M for any two h1, h2 ∈ M by
using log2 (n) max-pooling layers, satisfying condition (2) of Lemma 1. Thus f is in the closure of
M, and the result follows.	□
This result applies when MaxReLUs are used, since we can set α, β = 0. Using MaxReLU (rather
than max) guarantees that MICNNs can imitate regular ICNNs with at most double the parameters.
Theorem 2 (UA for Deep Norms and Wide Norms). The families D of Deep Norms (using MaxReLU)
and W of Wide Norms (using MaxMean) are dense in the family N of asymmetric semi-norms.
Proof (sketch). The proof is almost identical to that of Theorem 1, except that here D and W contain
all linear functions whose graph is tangent to any f ∈ N since f is N2. This is easy to see for
functions defined on R2. See Appendix A for more details.	□
2.5	Modeling Norms in 2D
Having shown that Deep Norms and Wide Norms universally approximate norms, we now show that
they can successfully learn to approximate random norms on R2 when trained using gradient descent.
To generate data, we use the below fact, proved in Appendix A.
Proposition 6. The set of all asymmetric norms on Rn is in one-to-one correspondence with the set
of all bounded and open convex sets (“unit balls”) containing the origin.
We use Proposition 6 by generating a random point set, computing its convex hull, and using the hull
as the unit ball of the generated norm, k∙∣∣. We then train different models to approximate k ∙ k using
|D| ∈ {16,128} training samples of form ((xη, yη), η), where ∣∣(x, y)k = 1 and η 〜U(0.85,1.15).
The models are trained to minimize the mean squared error (MSE) between the predicted (scalar)
norm value and the ground truth norm value. See Appendix C.1 for details.
Figure 3 illustrates the learned 2D norm balls of a random symmetric (top) and asymmetric (bottom)
norm, for three architectures: Deep Norm, Wide Norm, and an unconstrained, fully connected neural
network (MLP). The blue contours in Figure 3 are the ground truth norm balls for values {0.5, 1, 1.5},
and black contours the norm balls of the learned approximations. With the small dataset, the MLP
(a) Small Dataset (k = 16)
•4.0
-3.5
-2.5
-2.0
1.5
1.0
•as
(b) Large Dataset (k = 128)
aa
Fig. 3: Visualization of learned 2D norms (top) and asymmetric norms (bottom). Blue contours are
the ground truth norm balls for values {0.5, 1, 1.5}, and black contours the learned approximations.
4
Published as a conference paper at ICLR 2020
	N1 (M1-2)	N2 (Homo.)	N3 (M3)	N4 (M4)	UA	Notes
Euclidean	✓	✓	✓	✓	X	
MLP	X	X	X	X	✓	
Deep Norm	*	✓	✓	*	✓	
Wide Norm	*	✓	✓	*	✓	works for large minibatches (§§3.5)
Neural Metric	*	*	✓	*	✓	based on Deep Norm or Wide Norm
Table 1: Norm (metric) properties of different architectures. As compared to Euclidean architectures,
ours are universal asymmetric semi-norm approximators (UA) and can use propositions to optionally
satisfy (*) N1 and N4. Neural metrics relax the unnecessary homogeneity constraint on metrics.
overfits to the training data and generalizes poorly, while Deep Norm and Wide Norm generalize
almost perfectly. With the large dataset, we observe that Deep Norms and Wide Norms generalize to
larger and smaller norm balls (due to being N2), whereas the MLP is unable to generalize to the 0.5
norm ball (indeed, MLP-1 (0.5) = 0). While the symmetric Wide Norm fits well, the results suggest
that the asymmetrized Wide Norm is not as effective as the naturally asymmetric Deep Norm. See
Appendix C for additional details and visualizations.
3	Modeling Metrics
Having constructed models of asymmetric semi-norms on Rn , we now use them to induce quasi-
metrics on a domain X. As the geometry of X’s raw feature space will not, in general, be amenable
to a favorable metric (indeed, the raw features need not be in Rn), we assume the Siamese network
approach and learn an embedding function, φ : X → Rn. A Deep Norm or Wide Norm ∣∣ ∙ ∣∣θ, with
parameters θ, is defined on Rn and the metric over X is induced as dφ,θ(x, y) = kφ(y) - φ(x)kθ.
We could also define k ∙ ∣∣θ using an unconstrained neural network (MLP), but this would not be
guaranteed to satisfy the norm axioms and induce a quasi-metric.
To illustrate this approach, we revisit Figure 1. To get the results shown, we represent the four nodes
as one hot vectors and embed them into R2 using φ(x) = Wx, W ∈ R2×4. We then define the
norm on R2 as either a Mahalanobis norm, a Deep Norm, or a Wide Norm. Training the norm and φ
together, end-to-end with gradient descent, produces the Figure 1 results.
The choices are summarized in Table 1. While Deep Norm and Wide Norm have similar properties,
the depth of the former suggests that they can learn efficient, hierarchical representations (as do deep
neural networks); however, Wide Norms have a computational advantage when computing pairwise
distances for large minibatches, which we explore in Subsection 3.5. Since inducing metrics with
Deep Norms or Wide Norms produces a potentially unnecessary homogeneity constraint (due to N2),
the next Subsection considers Neural metrics, which offer an approach to relaxing this constraint.
3.1	Neural Metrics
Instead of inducing a metric with a norm, we could define a metric directly as a non-negative weighted
sum of different metrics. E.g., as we did for Wide Norms, we can define a Wide Metric as the mean
of k deep Euclidean metrics. If all components of a Wide Metric are norm-induced, however, it can be
induced directly by a single Wide Norm with k components, by setting φ(x) to be the concatenation
of the φi(x), and using each Wj to select the indices corresponding to φj. It follows that for a family
of Wide Metrics to be more expressive than the family of norm-induced metrics, it must include
components that are either not translation invariant or not positive homogeneous. We consider the
latter, and use the propositions below to modify our norm-induced metrics (proofs in Appendix A).
Proposition 7 (Metric-preserving concave functions). If d : X × X → R+ is (quasi-) metric,
f : R+ → R+, f-1(0) = {0}, and f is concave (i.e., -f is convex), then f ◦ d is (quasi-) metric.
Proposition 8 (Max preserves metrics). If d1 and d2 are (quasi-) metric, so too is max(d1, d2).
To use Proposition 7, we note that each unit in the final layer of a Deep Norm defines a metric
(assuming gk-1 is non-negative, as it is when using ReLU or MaxReLU activations), as does
5
Published as a conference paper at ICLR 2020
each component of a Wide Norm. Thus, by applying metric-preserving functions fi to these
metrics, and then combining them using a MaxMean, mean or max, we obtain a valid metric, which
we name a Neural Metric. Our k-component fi are parameterized by wi, bi ∈ Rk as follows:
fi (x) = minj {wij x + bij }, where wij ≥ 0, bij ≥ 0, b0 = 0.
The advantage of Neural Metrics over plain Deep Norms and Wide Norms is that one can better
model certain metrics, such as d(x, y) = min(1, kx - yk). This type of metric might be induced by
shortest path lengths in a fully connected graph with some maximum edge weight (for example, a
navigation problem with a teleportation device that takes some constant time to operate).
3.2	Application: Metric Nearness
We now apply our models to the metric nearness
problem (Sra et al., 2005; Brickell et al., 2008). In
this problem, we are given a matrix of pairwise non-
metric distances between (finite) n objects, and it is
desired to minimally repair the data to satisfy metric
properties (the triangle inequality, M3, in particu-
lar). Formally, given data matrix D ∈ Rn×n , we
seek metric solution X ∈ Rn×n that minimizes the
“distortion” JMN = kX - Dk2 /kDk2 (normalized
	J(S) JMN	#M	JMN	#-M)3	
TF	2.01e-2	7.7e3	1.30e-1	3.8e2
Eucl	9.12e-2	0	2.02e-1	0
WN	2.44e-2	0	1.86e-1	0
DN	2.00e-2	0	7.29e-2	0
Table 2: Metric nearness for sym. (S) and
asym. (A) matrices in R200×200 (10 seeds).
distance) to the original metric. Sra et al. (2005) proved this loss function attains its unique global
minimum in the set of size n discrete metrics and proposed an O(n3) triangle fixing (“TF”) algorithm
for the symmetric case, which iteratively fixes M3 violations and is guaranteed to converge to the
global minimum. Table 2 shows that for n = 200, our models (Deep Norm (DN) and Wide Norm
(WN) based Neural Metrics) achieve results comparable to that found by 400 iterations of TF in
the symmetric case. We note that TF, which approaches the solution through the space of all n × n
matrices, produces a non-metric approximation, so that the number of M3 violations (#「M3)is
greater than 0; this said, it is possible to fix these violations by adding a small constant to all entries of
the matrix, which does not appreciably increase the loss JMN . To test our models in the asymmetric
case, we modified the TF algorithm; although our modified TF found a solution , our DN model
performed significantly better. See Appendix D for complete experimental details.
Although triangle fixing is effective for small n, there is no obvious way to scale it to large datasets
or to metric approximations of non-metric distance functions defined on a continuous domain. Using
our models in these settings is natural, as we demonstrate in the next subsection.
3.3	Application: Modeling Graph Distances
In the previous subsection we sought to “fix” a noisy, but small and fully observable metric; we now
test the generalization ability of our models using large (n > 100K) metrics. We do this on the task
of modeling shortest path lengths in a weighted graph G = (V, E). So long as edge weights are
positive and the graph is connected, shortest path lengths are discrete quasi-metrics (n = |V |), and
provide an ideal domain for a comparison to the standard Euclidean approach.
Our experiments are structured as a supervised learning task, with inputs x, y ∈ V and targets d(x, y).
The targets for a random subset of 150K pairs (of the O(|V |2) total pairs) were computed beforehand
	|V|	|E|	max(d)	σd	Sym?
to	278K	611K	145.7	24.5	÷÷
3d	125K	375K	86.7	13.2	÷÷
taxi	391K	752K	111.2	13.4	÷÷
push	390K	1498K	113.1	14.3	→
3dr	123K	368K	86.5	13.1	→
3dd	125K	375K	97.8	13.4	→
(a) Graph statistics
Table 4: Graph experiments. (a) Statistics for different graphs. (b) Test MSE after 1000 epochs at
training size |D| = 50000 (3 seeds). The best metric (and overall result if different) is bolded.
	Eucl.	WN	DNI	DNN	MLP
to	12.5	6.6	6.7	6.7	12.3
3d	31.2	17.3	15.4	12.9	20.6
taxi	14.4	10.6	11.8	11.4	5.8
push	22.2	14.0	14.7	13.5	11.3
3dr	22.0	17.5	21.8	18.3	25.5
3dd	211.8	177.1	199.5	157.7	252.7
(b) Final test MSE @ |D| = 50000
6
Published as a conference paper at ICLR 2020
4-Room Asym Value SE WIdeNorm Asym
Maze Asvm Value	SE WIdeNorm Asvm
Fig. 4: GVF environments. Left: The 4-Room (top) and Maze (bottom) environments, with walls
(green), empty cells (red), and agent (blue). The next column shows example ground truth values,
where state s0 denotes agent at top left cell. Upper triangular regions indicate the value of V (s0, s)
while lower indicate V (s, s0). Center: Squared Error (SE) heatmap between the learned and ground
truth value for WideNorm and MLP architecture. Right: Success weighted by Path Length (SPL)
metric heatmap. Higher is better. See Section 3.4 for detail and Appendix F for more visualizations.
using A* search and normalized to have mean 50. 10K were used as a test set, and the remainder
was subsampled to form training sets of size |D| ∈ {1K, 2K, 5K, 10K, 20K, 50K}. Nodes were
represented using noisy landmark embeddings (see Appendix E). We compare Wide Norms, Deep
Norms (ICNN style, with ReLU activations, DNI), and Deep Norm based Neural Metrics (with
MaxReLU and concave activations, DNN) to the standard Siamese-style Bromley et al. (1994) deep
Euclidean metric and MLPs in six graphs, three symmetric and three not, summarized in Table 3a and
described in Appendix E. Though MLPs do not induce proper metrics, they are expressive function
approximators and serve as a relevant reference point. The results (shown for |D| = 50K in Table
3b and expanded upon in Appendix E) show that our models tend to outperform the basic Siamese
(Euclidean/Mahalanobis) network, and oftentimes the MLP reference point as well.
3.4	Application: Learning General Value Functions
In this section, we evaluate our models on the task of learning a Universal Value Function Approxima-
tor (UVFA) in goal-oriented reinforcement learning (Sutton et al., 2011; Schaul et al., 2015). Figure
4 (left) illustrates the two 11x11 grid world environments, 4-Room and Maze, in which we conduct
our experiments. Each environment has a symmetric version, where the reward is constant (-1), and
an asymmetric version with state-action dependent reward. We create a training set of transitions
(s, s0 , g, r, d) for the state, next state, goal, reward, and done flag, and the UVFA Vθ (s, g) is trained
to minimize the temporal difference error via bootstrapped updates with no discounting. We tested
several architectures at different training set sizes, which leaves out a portion of transitions such that
only a fraction of states or goals were present during training. See Appendix F.1 for details.
—j— euclidean -ɪ- mlp
icnn -于-deepnorm asym -f-- widenorm asym deepnorm sym widenorm sym
Fig. 5: GVF results. Generalization as measured by SPL metric (higher is better) on held out (s, g)
pairs as function of fraction of goals seen during training. Results averaged over 3 seeds and error bar
indicates standard deviation. For fraction = 1 we evaluate on entire data.
7
Published as a conference paper at ICLR 2020
Figure 5 summarizes the final generalization performance (on held out (s, g) pairs) for each archi-
tecture after training for 1000 epochs. Performance is given in terms of the SPL metric (Anderson
et al., 2018), which measures the success rate of reaching the goal weighted by the ratio of agent
versus optimal path cost. We observe that when given only partial training data, Deep Norm and
Wide Norm consistently outperform both MLPs and ICNNs at each sparsity level. As expected, the
Euclidean metric could not solve the asymmetric environments. Qualitatively, we plot a heatmap
of the squared difference (SE) between the learned and ground truth value function in Figure 4
(center), and observed that our proposed architectures have mostly lower SE than the MLP and ICNN
architectures. Figure 4 (right) illustrates that WideNorm architecture is able to reach more cells (with
almost optimal trajectory) in the environment when using a greedy policy with respect to the learned
value function. Additional visualizations and results are in Appendix F.2.
3.5	Computational Considerations
	32	128	512	2048
Euclidean	0.18	0.27	0.45	1.06
WN 3x600	1.59	1.57	1.75	2.36
WN 64x64	15.7	13.4	17.7	26.3
DN 2x400	0.97	5.73	76.9	293
DN 3x600	1.50	11.4	174	OOM
Several deep metric learning algorithms, such as semi-
hard triplet mining Schroff et al. (2015), involve
computing a pairwise distance matrix for large mini-
batches. For example, Schroff et al. use mini-batches
of size 1800. Computing this matrix for Euclidean
distances can be done efficiently by taking advantage
of the identity kx - yk22 = kxk22 + kyk22 - 2xTy (see
Section 4 of Oh Song et al. (2016) for details). This
same identity can be applied to each component of
a Wide Norm. There is no obvious way, however, to
compute pairwise Deep Norms more efficiently than the naive O(n2) approach. To quantify, we
recorded the pairwise distance computation time for our implementations (Table 6). Thus, although
our previous experiments often found that Deep Norms performed slightly better (see, e.g., Figure 3
and Tables 2 and 3b), these results suggest that only Wide Norms are practical for large mini-batches.
Fig. 6: Mean computation time (ms) for
different mini-batch sizes (250 trials).
4	Discussion and Other Related Work
Deep Norms, Wide Norms, and Neural Metrics all respect the triangle inequality while universally
approximating finite-dimensional asymmetric semi-norms. This allows them to represent metrics
that the deep Euclidean Siamese architecture cannot, no matter how deep its embedding function is
(see Figure 1). Our models thus provide a more expressive, non-Euclidean alternative for learning
distances that satisfy the triangle inequality. As noted in the Introduction, this may useful for
providing running time and error rate guarantees in clustering (Davidson and Ravi, 2009) and as an
inductive bias to improve generalization performance (Figure 5; Hsieh et al. (2017)).
A line of theoretical work, surveyed by Indyk et al. (2017), characterizes the representational
capacity of Euclidean space (and, more generally, `p space) by examining the asymptotic “distortion”
of embedding n-point metric spaces into Euclidean space. Here the distortion of an embedding
φ : X → X0 of metric space (X, dX) into metric space (X0, dX0) is at most c ≥ 1 if there exists
r > 0 such that for all x,y ∈ X, r ∙ dχ(x, y) ≤ dχ0(φ(x), φ(y)) ≤ Cr ∙ dχ(x, y). The pioneering
work of Bourgain (1985) bounds worst case distortion by O(log n), and Linial et al. (1995) shows
that this bound is tight (i.e., Θ(log n)) for graph distances in n-point constant-degree expanders.
This applies regardless of the dimensionality of the embedding space, and is true for all `p with
1 ≤ p < ∞. Future work might investigate the asymptotic distortion of our proposed architectures.
On account of the above limitations, others have also proposed non-Euclidean alternatives to learning
and representing metrics. To improve expressivity, some have proposed non-parametric algorithms
that learn distances directly. For instance, Biswas and Jacobs (2015) propose to frame clustering as
a metric nearness problem and applying a quadratic programming algorithm; see also Gilbert and
Jain (2017) and Veldt et al. (2018). Others learn parametric distances, as we do. Bi et al. (2015)
parameterize and learn Cayley-Klein metrics, which are not translation-invariant. Yang and Jin
(2006) and Nielsen et al. (2016) propose metrics that are similar to our Wide Norm, in that they use
non-negative sums of several components (binary codes and Cayley-Klein metrics). As for symmetry,
several papers have used asymmetric measures such as KL divergence (Vilnis and McCallum, 2014;
8
Published as a conference paper at ICLR 2020
Vendrov et al., 2015; Chen et al., 2016; Ou et al., 2016). To our knowledge, we are the first to propose
a parametric measure that is both asymmetric and satisfies the triangle inequality.
Another common approach in deep “metric” learning is to forgo the triangle inequality altogether and
use non-metric similarity measures such as cosine similarity (Bromley et al., 1994; Yi et al., 2014).
This can be sensible, as proper metrics are not always required. In image recognition, for example, the
triangle inequality is questionable: why should d(CAT, WOLF) ≤ d(CAT, DOG) + d(DOG, WOLF)?
In this case, Scheirer et al. (2014) find that non-metric similarities often perform better, concluding
that “good recognition is non-metric”. Thus, one should apply our models with care, in settings
where the triangle inequality is thought to be a useful inductive bias (e.g., Hsieh et al. (2017)). Such
applications we are excited about include learning search heuristics (Russell and Norvig, 2016) and
scaling our UVFA models to more complex reinforcement learning problems (Plappert et al., 2018).
5	Conclusion
This paper proposed three novel architectures for modeling asymmetric semi-norms and metrics.
They can be used instead of the usual Euclidean metric to increase expressiveness while respecting
the triangle inequality. We showed that our models outperform Euclidean metrics when used with a
Siamese-style deep metric learning architecture to (1) solve the metric nearness problem, (2) model
shortest path lengths, and (3) learn general value functions in small reinforcement learning domains.
Future work should explore larger scale applications such as facial recognition (Schroff et al., 2015),
collaborative metric learning (Hsieh et al., 2017) and continuous control (Plappert et al., 2018).
Acknowledgments
We thank Cem Anil, James Lucas, Mitchell Stern, Michael Zhang and the anonymous reviewers for
helpful discussions. Harris Chan was supported by an NSERC CGS-M award. Resources used in
preparing this research were provided, in part, by the Province of Ontario, the Government of Canada
through CIFAR, and companies sponsoring the Vector Institute (www.vectorinstitute.ai/
#partners).
References
Brandon Amos, Lei Xu, and J. Zico Kolter. Input convex neural networks. In Doina Precup and
Yee Whye Teh, editors, Proceedings of the 34th International Conference on Machine Learning,
volume 7θ of Proceedings ofMachine Learning Research, pages 146-155, International Convention
Centre, Sydney, Australia, 06-11 Aug 2017. PMLR. URL http://proceedings.mlr.
press/v70/amos17b.html.
Peter Anderson, Angel Chang, Devendra Singh Chaplot, Alexey Dosovitskiy, Saurabh Gupta, Vladlen
Koltun, Jana Kosecka, Jitendra Malik, Roozbeh Mottaghi, Manolis Savva, et al. On evaluation of
embodied navigation agents. arXiv preprint arXiv:1807.06757, 2018.
Cem Anil, James Lucas, and Roger Grosse. Sorting out lipschitz function approximation. arXiv
preprint arXiv:1811.05381, 2018.
F. L. Bauer, J. Stoer, and C. Witzgall. Absolute and monotonic norms. Numerische Mathematik, 3(1):
257-264, Dec 1961. ISSN 0945-3245. doi: 10.1007/BF01386026. URL https://doi.org/
10.1007/BF01386026.
Yanhong Bi, Bin Fan, and Fuchao Wu. Beyond mahalanobis metric: cayley-klein metric learning.
In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages
2339-2347, 2015.
Arijit Biswas and David W Jacobs. An efficient algorithm for learning distances that obey the triangle
inequality. In BMVC, pages 10-1, 2015.
Jean Bourgain. On lipschitz embedding of finite metric spaces in hilbert space. Israel Journal of
Mathematics, 52(1-2):46-52, 1985.
9
Published as a conference paper at ICLR 2020
Justin Brickell, Inderjit S Dhillon, Suvrit Sra, and Joel A Tropp. The metric nearness problem. SIAM
Journal on Matrix AnaIysis andApplications, 30(1):375-396, 2008.
Jane Bromley, Isabelle Guyon, Yann LeCun, Eduard Sackinger, and Roopak Shah. Signature
verification using a" siamese" time delay neural network. In Advances in neural information
processing systems, pages 737-744, 1994.
Ying-Cong Chen, Wei-Shi Zheng, Jian-Huang Lai, and Pong C Yuen. An asymmetric distance
model for cross-view feature mapping in person reidentification. IEEE transactions on circuits
and systems for video technology, 27(8):1661-1675, 2016.
Yize Chen, Yuanyuan Shi, and Baosen Zhang. Optimal control via neural networks: A convex
approach. arXiv preprint arXiv:1805.11835, 2018.
Thomas Cover and Peter Hart. Nearest neighbor pattern classification. IEEE transactions on
information theory, 13(1):21-27, 1967.
Ian Davidson and Sekharipuram S Ravi. Using instance-level constraints in agglomerative hierarchical
clustering: theoretical and empirical results. Data mining and knowledge discovery, 18(2):257-282,
2009.
JozefDobos. Metric preserving functions. StroffekKosice, 1998.
A. C. Gilbert and L. Jain. If it ain’t broke, don’t fix it: Sparse metric repair. arXiv e-prints, October
2017.
Aditya Grover and Jure Leskovec. node2vec: Scalable feature learning for networks. In Proceedings
of the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining,
pages 855-864. ACM, 2016.
Frank S He, Yang Liu, Alexander G Schwing, and Jian Peng. Learning to play in a day: Faster deep
reinforcement learning by optimality tightening. arXiv preprint arXiv:1611.01606, 2016.
Elad Hoffer and Nir Ailon. Deep metric learning using triplet network. In Aasa Feragen, Marcello
Pelillo, and Marco Loog, editors, Similarity-Based Pattern Recognition, pages 84-92, Cham, 2015.
Springer International Publishing.
Cheng-Kang Hsieh, Longqi Yang, Yin Cui, Tsung-Yi Lin, Serge Belongie, and Deborah Estrin.
Collaborative metric learning. In Proceedings of the 26th International Conference on World Wide
Web, pages 193-201. International World Wide Web Conferences Steering Committee, 2017.
Piotr Indyk. Sublinear time algorithms for metric space problems. In Proceedings of the Thirty-
first Annual ACM Symposium on Theory of Computing, STOC ’99, pages 428-434, New York,
NY, USA, 1999. ACM. ISBN 1-58113-067-8. doi: 10.1145/301250.301366. URL http:
//doi.acm.org/10.1145/301250.301366.
Piotr Indyk, Jir0ι Matousek, and Anastasios Sidiropoulos. 8: Low-distortion embeddings of finite
metric spaces. In Handbook of discrete and computational geometry, pages 211-231. Chapman
and Hall/CRC, 2017.
Eric Jones, Travis Oliphant, Pearu Peterson, et al. SciPy: Open source scientific tools for Python,
2001. URL http://www.scipy.org/. [Online; accessed <today>].
Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint
arXiv:1412.6980, 2014.
Brian Kulis et al. Metric learning: A survey. Foundations and TrendsR in Machine Learning, 5(4):
287-364, 2013.
Nathan Linial, Eran London, and Yuri Rabinovich. The geometry of graphs and some of its algorithmic
applications. Combinatorica, 15(2):215-245, 1995.
Frank Nielsen, Boris Muzellec, and Richard Nock. Classification with mixtures of curved mahalanobis
metrics. In Image Processing (ICIP), 2016 IEEE International Conference on, pages 241-245.
IEEE, 2016.
10
Published as a conference paper at ICLR 2020
Hyun Oh Song, Yu Xiang, Stefanie Jegelka, and Silvio Savarese. Deep metric learning via lifted
structured feature embedding. In Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition, pages 4004-4012, 2016.
Mingdong Ou, Peng Cui, Jian Pei, Ziwei Zhang, and Wenwu Zhu. Asymmetric transitivity preserv-
ing graph embedding. In Proceedings of the 22nd ACM SIGKDD international conference on
Knowledge discovery and data mining, pages 1105-1114. ACM, 2016.
Matthias Plappert, Marcin Andrychowicz, Alex Ray, Bob McGrew, Bowen Baker, Glenn Powell,
Jonas Schneider, Josh Tobin, Maciek Chociej, Peter Welinder, et al. Multi-goal reinforcement learn-
ing: Challenging robotics environments and request for research. arXiv preprint arXiv:1802.09464,
2018.
Stuart J Russell and Peter Norvig. Artificial intelligence: a modern approach. Malaysia; Pearson
Education Limited„ 2016.
Tom Schaul, Daniel Horgan, Karol Gregor, and David Silver. Universal value function approximators.
In International Conference on Machine Learning, pages 1312-1320, 2015.
Walter J Scheirer, Michael J Wilber, Michael Eckmann, and Terrance E Boult. Good recognition is
non-metric. Pattern Recognition, 47(8):2721-2731, 2014.
Florian Schroff, Dmitry Kalenichenko, and James Philbin. Facenet: A unified embedding for face
recognition and clustering. In Proceedings of the IEEE conference on computer vision and pattern
recognition, pages 815-823, 2015.
Jake Snell, Kevin Swersky, and Richard Zemel. Prototypical networks for few-shot learning. In
Advances in Neural Information Processing Systems, pages 4077-4087, 2017.
Suvrit Sra, Joel Tropp, and Inderjit S Dhillon. Triangle fixing algorithms for the metric nearness
problem. In Advances in Neural Information Processing Systems, pages 361-368, 2005.
Richard S Sutton, Joseph Modayil, Michael Delp, Thomas Degris, Patrick M Pilarski, Adam White,
and Doina Precup. Horde: A scalable real-time architecture for learning knowledge from unsuper-
vised sensorimotor interaction. In The 10th International Conference on Autonomous Agents and
Multiagent Systems-Volume 2, pages 761-768. International Foundation for Autonomous Agents
and Multiagent Systems, 2011.
N. Veldt, D. Gleich, A. Wirth, and J. Saunderson. A Projection Method for Metric-Constrained
Optimization. arXiv e-prints, June 2018.
Ivan Vendrov, Ryan Kiros, Sanja Fidler, and Raquel Urtasun. Order-embeddings of images and
language. arXiv preprint arXiv:1511.06361, 2015.
Luke Vilnis and Andrew McCallum. Word representations via gaussian embedding. arXiv preprint
arXiv:1412.6623, 2014.
Qi Wang, Jia Wan, and Yuan Yuan. Deep metric learning for crowdedness regression. IEEE
Transactions on Circuits and Systems for Video Technology, 28(10):2633-2643, 2018.
Eric P Xing, Michael I Jordan, Stuart J Russell, and Andrew Y Ng. Distance metric learning with
application to clustering with side-information. In Advances in neural information processing
systems, pages 521-528, 2003.
Liu Yang and Rong Jin. Distance metric learning: A comprehensive survey. Michigan State Universiy,
2(2):4, 2006.
Dong Yi, Zhen Lei, Shengcai Liao, and Stan Z Li. Deep metric learning for person re-identification.
In Pattern Recognition (ICPR), 2014 22nd International Conference on, pages 34-39. IEEE, 2014.
11
Published as a conference paper at ICLR 2020
A	Proofs
In this Appendix, we restate each proposition from the main text and provide a short proof.
Proposition 1. All positive homogeneous convex functions are subadditive; i.e., C1 ∧ N2 ⇒ N3.
Proof. Putting α = 0.5 in the definition of C1 gives f(0.5x + 0.5y) ≤ 0.5f (x) + 0.5f (y). Applying
N2 on the left and multiplying by 2 gives f (X + y) ≤ f (x) + f (y) as desired.	□
Proposition 2. If k ∙ | is an asymmetric semi-norm, then ∣∣xk = ||x| + ∣∣ 一x| is a semi-norm.
Proof. ∣∣χ∣ = ||x| + ∣∣ -x| = ∣∣ -χ∣,so N4 is satisfied. N2-N3 and non-negativity are similarly
trivial.	□
Proposition 3. If ∣∣ ∙ ∣∣a is an (asymmetric) semi-norm, ∣ ∙ ∣∣b is a norm (e.g., ∣ ∙ ∣∣b = ∣∣ ∙ ∣∣2), and
λ > 0, then ∣x∣a+λb = ∣x∣a + λ∣x∣b is an (asymmetric) norm.
Proof. This follows from the positive definiteness of λ∣x∣b and the easily verified fact that non-
negative weighted sums of semi-norms are semi-norms.	□
Proposition 4. If ∣∣ ∙ ∣∣ is an N5 (semi-) norm on R2n, then ||x| = ∣∣relu(x :: 一x)∣, where :: denotes
concatenation, is an asymmetric (semi-) norm on Rn.
Proof. N1 and N2 are easily verified. To see that ∣∣ ∙ | is not necessarily symmetric, choose ∣∣ ∙ ∣∣ to be
a Mahalanobis norm parameterized by a diagonal W with Wii = i (but NB that if ∣∙∣ is invariant to
element-wise permutations, as are the Lp norms, ∣ ∙ | will be symmetric). For N3, we have:
∣∣X∣ + I∣y∣ = Ilrelu(X :: -x)∣∣ + Ilrelu(y :: -y)∣∣
≥ ∣relu(x :: -x) + relu(y :: -y)∣
≥ ∣relu(X + y :: -(X+y))∣
=l∣χ + y|.
The first inequality holds because ∣∙∣ is N3. The second holds because ∣∙∣ is N5, and we have either
element-wise equality (when Sign(Xi) and sign(yi) agree) or domination (when they don't). □
Proposition 5. The Mahalanobis norm with W = DU, with D diagonal and U non-negative, is N5.
Proof. Let ∣ ∙ ∣∣ be ∣∣ ∙ ∣∣2, and 0 ≤ X ≤ y = X + e. We have:
∣WX∣∣Wy∣ ≥ |(WX)T(Wy)|
= XWTW(X + )
=XWTWX+XUTDTDU
≥ ∣WX∣2.
The first inequality is Cauchy-Schwarz. The second holds as all elements of X, UTDTDU, and are
non-negative.	□
Lemma 1 (Semilattice Stone-Weierstrass (from below)). Let C be a set of continuous functions
defined on compact subset K of Rn, L be a closed subset of C, and f ∈ C. If (1) for every X ∈ K,
there exists gx ∈ L such that gx ≤ f and gx (X) = f (X), and (2) L is closed under max (i.e.,
a, b ∈ L ⇒ max(a, b) ∈ L), then ∃h ∈ L with f = h on K.
Proof. Fix > 0 and consider the sets Ux = {y | y ∈ K, f(y) -	< gx (y)}, for all X ∈ K.
The Ux form an open cover of K, so there is a finite subcover {Ux1 , Ux2, . . . , Uxn}. Let g =
max(gxι ,gχ2,..., gχn) ∈ L. We have f 一 E ≤ g ≤ f, and the result follows since L is closed. □
Theorem 1 (UA for MICNNs). The family M of Max Input Convex Neural Networks (MICNNs) that
uses pairwise max-pooling (or MaxReLU) activations is dense in the family C of convex functions.
12
Published as a conference paper at ICLR 2020
Proof. For f ∈ C , x ∈ Rn , let gx ∈ M be a linear function whose hyperplane in the graph of f is
tangent to f at x. Then gx satisfies condition (1) of Lemma 1 (because f is convex). The use of
pairwise max activations allows one to construct max(h1, h2) ∈ M for any two h1, h2 ∈ M by
using log2 (n) max-pooling layers, satisfying condition (2) of Lemma 1. Thus f is in the closure of
M, and the result follows.	□
Theorem 2 (UA for Deep Norms and Wide Norms). The families D of Deep Norms (using MaxReLU)
and W of Wide Norms (using MaxMean) are dense in the family N of asymmetric semi-norms.
Proof. The proof is almost identical to that of Theorem 1. The only subtlety is that D and W do not
contain all linear functions in Rn ; they do, however, contain all linear functions whose hyperplane is
tangent to any f ∈ N, since f is N2. This is easy to see for functions defined on R2 . To generalize
the intuition to Rn, consider the ray Rx = {(αx :: αkxk) | α ≥ 0} ⊂ Rn+1 defined for each x ∈ Rn.
By N2, this ray is a subset of the graph g ⊂ Rn+1 of f . Furthermore, any hyperplane tangent to one
point on this ray is tangent to the entire ray and contains all points on the ray, since the ray is linear
from the origin—therefore the hyperplane contains the origin. But any hyperplane tangent to g at x is
tangent to a point (x) on the ray Rx , and so contains the origin. Since D and W contain all linear
functions containing the origin, it follows that they contain all linear functions whose graph is tangent
to f, in satisfaction of condition (1) of Lemma 1 (because f is convex). For Deep Norms, the use of
pairwise max activations allows one to construct a global max operation, as in the proof of Theorem
1, satisfying condition (2) of Lemma 1. Wide Norms using MaxMean have direct access to a global
max, and so satisfy condition (2) of Lemma 1. It follows that f is in the closures of D and W.	□
Proposition 6. The set of all asymmetric norms on Rn is in one-to-one correspondence with the set
of all bounded and open convex sets (“unit balls”) containing the origin.
Proof. Given asymmetric norm ∣∣ ∙ k on Rn, its unit ball Bi := {x ∣kx∣∣ < 1} is convex since,
∀x, y ∈ B1, λ ∈ [0, 1], we have k(1 - λ)x + λyk ≤ (1 - λ)kxk + λkyk ≤ 1 (using N3 & N2).
Conversely, given open and bounded convex set Bi containing the origin, let ∣∣χ∣ = inf{a > 0 | X ∈
B1 }. N1 and N2 are straightforward and N3 follows by noting that for x, y ∈ Rn , α, β > 0, such
that X, y ∈ Bi, we have 0⅛χ + α+^y =帮 ∈ Bi, so that inf{γ > 0 | x+y ∈ Bi} ≤ inf{α >
0 | X ∈ Bi} + inf{β> 0 | β ∈ Bi}.	□
Proposition 7 (Metric-preserving concave functions). If d : X × X → R+ is (quasi-) metric,
f : R+ → R+, f-i(0) = {0}, and f is concave (i.e., -f is convex), then f ◦ d is (quasi-) metric.
Proof. This proposition is proven for metrics by Dobos (1998) (Chapter 1, Theorem 3). The extension
to quasi-metrics is immediate, as the proof does not require symmetry.	□
Proposition 8 (Max preserves metrics). Ifdi and d2 are (quasi-) metric, so too is max(di, d2).
Proof. M1 and M2 are trivial. For M3, let d = max(di, d2). Given some x, y, z, we have both
di(x, y)+di (y, z) ≥ di (x, z) and d2(x, y)+d2 (y, z) ≥ d2 (x, z), so that d(x, y)+d(y, z) ≥ di(x, z)
and d(x, y) + d(y, z) ≥ d2(x, z) . Therefore, d(x, y) + d(y, z) ≥ max(di (x, z), d2(x, z)) = d(x, z).
Because if an element is larger than two other elements, it is also larger than their max.	□
Erratum dated July 6, 2020 The originally published version of our paper did not cite the prior
universal approximation result for ICNNs by Chen et al. (2018), which we were not aware of at the
time. The text of Subsection 2.4 has been revised to reflect this prior work.
B	Implementation Details
Except where otherwise noted, these implementation details are common throughout our experiments.
Our Deep Norm implementation constrains each Wi for i < k to be non-negative by clipping the
parameter matrix after each gradient update. For Wk, we use either a simple mean or MaxMean (see
Subsection 2.3). We set Uk = 0. We use either ReLU or MaxReLU for our activations gi, as noted.
13
Published as a conference paper at ICLR 2020
Since the output layer is always scalar (size 1), we refer to Deep Norms in terms of their hidden
layers only. Thus, a Deep Norm with k = 3 layers of sizes (400, 400, 1) is a “2x400” Deep Norm.
Our Wide Norm implementation avoids parameterizing the αi in Equation 3 by absorbing them into
the weight matrices, so that kXk = 1 PikUixk2, where Ui = αikWi. Our asymmetric Wide Norm
constrains matrix U of Proposition 5 by clipping negative values and does not use matrix D (i.e., we
set D = I).
Neither our Deep Norm nor Wide Norm implementations impose positive definiteness. This simplifies
our architectures, does not sacrifice representational power, and allows them to be used on pseudo-
metric problems (where d(x, y) = 0 is possible for distinct x, y ∈ X).
Neural Metrics involve only a very small modification to Deep Norms and Wide Norms: before
applying the mean or MaxMean global activation to obtain the final output, we apply an element-wise
concave activation function, as described in Subsection 3.1.
C 2d Norms Additional Details
Dataset generation To generate data, we use Proposition 6 by generating a random point set,
computing its convex hull, and using the hull as the unit ball of the generated norm, k ∙ ∣∣. Having
obtained the unit ball for a random norm, we sample a set of N = 500 unit vectors in R2 (according
to L2) in random directions, then scale the vectors until they intersect the convex hull: {x}N .
We use these vectors for testing data, defined as Dtest = {(x(1) , 1), ..., (x(N) , 1)}. For training
data, we sample a size |D| = {16, 128} subset of these vectors and multiply them by random
perturbations e(i) 〜U(0.85,1.15) to get {x ∣x(i) = x(i)e(i)}k. The training data is then defined as
Dtrain = {(x ⑴,£%,..., (X(Rnk)) }.
Models We compare 4 model types on 4 types of norms. The models are (1) Mahalanobis, (2) Deep
Norms of depth ∈ {2, 3, 4, 5} and layer size ∈ {10, 50, 250}, (3) Wide Norms of width ∈ {2, 10, 50}
and number of components ∈ {2, 10, 50}, and (4) unconstrained, fully connected neural networks
with ReLU activations of depth ∈ {2, 3, 4, 5} and layer size ∈ {10, 50, 250} (MLPs). Although MLPs
do not generally satisfy N1-N4, we are interested in how they generalize without the architectural
inductive bias.
Norms The norms we experiment on are random (1) symmetric and (2) asymmetric norms, con-
structed as above, and (3) square (L∞), and (4) diamond (L1) norms.
Training The models, parameterized by θ, are trained to minimize the mean squared error
(MSE) between the predicted (scalar) norm value ∣∣X(i)k and the label norm value e(i): L(θ)=
MM PM(kx(i) ∣∣θ - €(i))2, where M = 16 is the batch size. We use Adam Optimizer Kingma and Ba
(2014), with learning rate 1e-3, and train for a maximum of 5000 epochs.
Results Tables 5-7 show the test MSE for the best configurations for each target norm and training
data size. Deep Norms performed orders of magnitude better than Mahalanobis and Wide Norms on
the random symmetric and asymmetric norms, but Wide Norms performed better on the square and
diamond norms. The MLP performed worse than our models, except on the asymmetric norm with
small training data.
Figure 3 illustrates the learned norm balls for random symmetric and asymmetric norms, when trained
with small (k = 16) and large (k = 128) data sizes. Appendix C includes additional visualizations.
From the red contours, we observe that Deep Norms and Wide Norms generalize to larger and smaller
norm balls (due to being N2), whereas the MLP is unable to generalize to the 0.5 norm ball.
C.1 Additional Details on Norm Generation
To generate point sets in R2, we generated c ∈ [3, 10] clusters, each with ni ∈ [5, 50] random points.
The points for each cluster were sampled from a truncated normal distribution with μi 〜U(-0.5,0.5)
and σ(i) ~ U(0.2,0.6), truncated to 2 standard deviations. For symmetric sets, we considered only
14
Published as a conference paper at ICLR 2020
	Maha	DN	WN	MLP
sym				
16	3.4×10-3	1.5×10-5	6.7×10-5	1.5×10-3
128	3.2×10-3	7.8×10-7	1.0×10-6	1.2×10-5
asym				
16	1.7×10-1	4.1×10-4	4.9×10-3	1.6×10-3
128	1.7×10-1	2.5×10-5	4.5×10-3	3.0×10-5
square				
16	1.7×10-2	3.0×10-5	2.4×10-9	7.7×10-3
128	1.1×10-2	2.1×10-6	9.3×10-9	7.8×10-6
diamond				
16	1.2×10-2	6.5×10-4	4.6×10-8	2.2×10-3
128	1.1×10-2	4.5×10-7	2.3×10-10	7.8×10-6
Table 5: MSE on 2d norm test set (target norm value = 1) for the best configuration of each type
(allowing for early stopping), for each data size (16 and 128) and target norm.
	Maha	DN	WN	MLP
sym				
16	1.4×10-2	6.0×10-5	2.7×10-4	3.8×10-2
128	1.3×10-2	3.1×10-6	4.0×10-6	2.3×10-2
asym				
16	6.7×10-1	1.6×10-2	2.0×10-2	2.0×10-1
128	6.7×10-1	2.0×10-4	1.8×10-2	2.8×10-2
square				
16	6.8×10-2	1.2×10-4	9.6×10-9	2.7×10-1
128	4.4×10-2	8.3×10-6	3.7×10-8	6.1×10-3
diamond				
16	4.6×10-2	2.6×10-3	1.9×10-7	4.1×10-1
128	4.4×10-2	1.8×10-6	9.3×10-10	7.4×10-2
Table 6: MSE on 2d norm test set (target norm value = 2) for the best configuration of each type
(allowing for early stopping), for each data size (16 and 128) and target norm.
Maha	DN	WN	MLP
sym
16 128	8.5×10-4 8.1×10-4	3.7×10-6 2.0×10-7	1.7×10-5 2.5×10-7	4.5×10-2 1.2×10-2
asym				
16	4.2×10-2	1.0×10-4	1.2×10-3	7.9×10-2
128	4.2×10-2	6.2×10-6	1.1×10-3	7.6×10-2
square				
16	4.3×10-3	7.5×10-6	6.0×10-10	7.5×10-2
128	2.7×10-3	5.2×10-7	2.3×10-9	1.0×10-2
diamond				
16	2.9×10-3	1.6×10-4	1.2×10-8	1.0×10-1
128	2.8×10-3	1.1×10-7	5.8×10-11	2.5×10-2
Table 7: MSE on 2d norm test set (target norm value = 0.5) for the best configuration of each type
(allowing for early stopping), for each data size (16 and 128) and target norm.
15
Published as a conference paper at ICLR 2020
those points with positive x-coordinates and also included their reflection about the origin. To ensure
that the origin was inside the resulting convex hull, we normalized the points to have mean zero
before computing the hull. The convex hull was generated by using the SciPy library Jones et al.
(2001) ConvexHull implementation.
C.2 Additional Visualizations
Figure 8 and Figure 7 further visualizes the training data and the Mahalanobis architecture in addition
to the MLP, Deep Norm, and Wide Norm architectures, for the random symmetric, asymmetric,
square (L∞) and the diamond (L1) unit ball shape.
Training Data Mahalanobis Deep Norm Wide Norm	MLP
1.5
1.0
0.5
0.0
-0.5
-1.0
-1.5
⅛∞0-
□
4.0
3.5
3.0
2.5
2.0
1.5
1.0
0.5
0.Q
D.□
DeeP Norm
Wide Norm
Q
1.5
1.0
0.5
0.0
-0.5
-1.0
-1.5
E.2.司
Training Data Mahalanobis
(a) Small Dataset (k = 16)
1.000
(b) Large Dataset (k = 128)
Fig. 7: Visualization of the 2d unit circles learned by several architectures (see Section 2.5) for a
square and diamond shape convex hull, corresponding to L∞ and L1 norm unit circle, respectively.
The first column shows the training data points (in green), while the red line to the convex hull
illustrates the portion of the convex hull which is covered by the training vector. Blue contours
represent ground truth norm balls, and red contours learned norm balls, in each case for norm values
{0.5, 1, 2}.

16
Published as a conference paper at ICLR 2020
(b) Large Dataset (k = 128)
Fig. 8: Visualization of the 2d unit circles learned by several architectures (see Section 2.5) for
a symmetric and asymmetric shape convex hull, corresponding to L∞ and L1 norm unit circle,
respectively. The first column shows the training data points (in green), while the red line to the
convex hull illustrates the portion of the convex hull which is covered by the training vector. Blue
contours represent ground truth norm balls, and red contours learned norm balls, in each case for
norm values {0.5, 1, 2}.
17
Published as a conference paper at ICLR 2020
D Metric Nearnes s Additional Details
Dataset creation For the symmetric metric nearness dataset, we generated the data as was found in
Sra et al. (2005): a random matrix in R200×200 was generated with values drawn from the uniform
distribution ranging between 0 and 5. This matrix was added to its transpose to make it symmetric.
Random uniform noise was added to each entry between 0 and 1, then the diagonal was removed.
For the asymmetric case, a more complex dataset creation strategy was employed due to the fact that
a random asymmetric matrix generated as above was too difficult a task for triangle fixing. Instead,
we generated a random directed lattice graph with random weights generated from the exponential
function applied to a random uniform sample between -1 and 1. The distances were calculated using
Dijkstra's A* algorithm. Then, again, random uniform noise between 0 and 4 was added to the output,
multiples of 10 removed to make the scale comparable to before, and the diagonals removed. The
reason for the extra noise was due to the fact that the data matrix was already much closer to a metric.
Architectures used For the symmetric metric nearness experiment, the Deep Norm based Neural
Metric architecture used two layers of 512 neurons (we found that larger layer sizes learned much
faster), with a 512-dimensional embedding function, MaxReLU activations, 5-unit concave activation
functions, and a MaxMean global pooling layer. The Wide Norm based Neural Metric consisted
of 128 Mahalanobis components of size 48, with a 512-dimensional embedding function, 5-unit
concave activation functions, and MaxMean global pooling. The deep Euclidean architecture used a
1024-dimensional embedding function. For the asymmetric case, the architectures were the same
except that we used the asymmetric equivalents for Deep Norm and Wide Norm.
Training Regime The triangle fixing algorithm was allowed to go up to 400 iterations or conver-
gence. For the symmetric case we reimplemented Sra et al. (2005) in Python using their C++ code as
a template. For the asymmetric version, we used the same code but we removed their symmetrization
step. For the training of all networks, we did 1500 epochs in total split up in to 500 epoch chunks
were the learning rate decreased from 1e-3 to 3e-4 to 1e-4 at the end, using a batch size of 1000.
We used the Adam optimizer Kingma and Ba (2014) with default hyperparameters. Results were
averaged over 10 seeds.
Fig. 9: Learning curves on symmetric metric nearness.
E Graph Experiments Additional Details
Symmetric graph descriptions The first symmetric graph, to, consists of a symmetrized road
network extracted from openStreetMap (OSM, www.openstreetmap.org). The second, 3d, represents
navigation in a 50x50x50 cubic 3d gridworld, where the agent can move one step at a time in 6
directions, and movement wraps around the sides of the cube. The third, taxi, represents a 25x25
2d taxi environment, where the agent can move in four directions and there is a passenger that the
agent can pick up and drop. Unlike in 3d, there is no wraparound in taxi. Weights for edges in to
correspond to the OSM distances, whereas weights for edges in 3d and taxi are randomly sampled
from {0.01, 0.02, . . . , 1.00} (but final distances are normalized so that the mean distance is 50).
18
Published as a conference paper at ICLR 2020
Asymmetric graph descriptions The first, push, is a 25x25 2d pusher environment, where the
agent can move in four directions, and there is a box that the agent can push by moving into it. If the
box is pushed into a wall, it switches places with the agent. The second, 3dd, is a directed version
of 3d, where all paths in three of the six movement directions have been pruned (the same three
directions for all nodes). The third, 3dr, is a randomly pruned version of 3d, where three random
movement directions were pruned at each node, and any inaccessible portions of the resulting graph
were pruned.
Dataset generation Our experiments are structured as a supervised learning task, with inputs
x, y ∈ V and targets d(x, y). The targets for a random subset of 150K pairs (of the O(|V |2)
total pairs) were computed beforehand using A* search and normalized to have mean 50. 10K
were used as a test set, and the remainder was subsampled to form training sets of size |D| ∈
{1K, 2K, 5K, 10K, 20K, 50K}. Nodes were represented using noisy landmark embeddings. A subset
of 32 landmark nodes was randomly chosen, and the distances to and from all other nodes in the
graph were computed using Dijkstra’s algorithm to form 32 base landmark features for symmetric
graphs and 32 base landmark features for asymmetric graphs. These base landmark features were
then normalized to have mean 0 and standard deviation 1, and noise sampled from N (0, 0.2) was
added. To add additional noise through distractor features, 96 normally distributed features were
concatenated with the noisy landmark features to obtain node embeddings with 128 dimensions for
symmetric graphs and 160 dimensions for asymmetric graphs. We also tested node2vec embeddings
Grover and Leskovec (2016), but found that our noisy landmark approach was both faster to run and
produced results that were an order of magnitude better for all algorithms.
Architectures We compare a 128-dimensional Mahalanobis metric (equivalent to a deep Euclidean
metric with an additional layer), a Wide Norm based Neural Metric (32 components of 32 units, with
5-unit concave activations, and MaxMean global pooling), a plain Deep Norm (3 layers of 128 units,
ICNN style with ReLU activations, no concave activations, and average pooling, DNI), and a Deep
Norm based Neural Metric (3 layers of 128 units, with MaxReLU and 5-unit concave activations,
and MaxMean pooling, DNN), and an MLP (3 layers of 128 units). We train each algorithm with 4
different embedding functions φ, each a fully connected, feed-forward neural network with ReLU
activations. The depths of tested φ ranged from 0 to 3 layers, all with 128 units. No regularization
was used besides the size/depth of the layers.
Training Training was done end-to-end with Adam Optimizer Kingma and Ba (2014), using an
initial learning rate of 1e-3 and a batch size of 256. Networks were each trained for 1000 total epochs,
and the learning rate was divided by 5 every 250 epochs.
Results The complete results/learning curves are displayed in Figures 10 and 11 below.
F	General Value Functions Additional Details
F.1 Experimental Details
4-Room and Maze environment description The fully observable grid environment has a state
and goal representation of a binary tensor with dimensions 11 × 11 × 3. Each cell in the 2D grid
is represented by a 1-hot vector with 3 dimensions, indicating whether the cell is (1) empty, (2)
wall, (3) agent. The agent can move up to 4 cardinal directions (North, South, East, West). If a
wall is present in the direction then the agent cannot take that move. The 4-Room environment
and Maze environment has a total of 4556 and 2450 training (s, g) pairs, respectively. For each
environment, the agent has access to a neighbour function N(s) which returns a list of possible next
states, corresponding to the empty cells adjacent to the current agent location. This is equivalent to
having environment transition model p(s0|s, a) over all the actions.
Transition reward and episode termination For symmetric environments, every transition has a
reward of -1, i.e., R(s, s0) = -1. Note that reward is not a function of the goal, but the termination is.
For asymmetric environments, we add a noise μ 〜U(0, -5) to the base -1 reward for a transition
if the direction of movement is west (left) or south (down). The done flag is set to 1 when the
neighbouring state equals to the goal, i.e. D(s, s0, g) = [s0 = g].
19
Published as a conference paper at ICLR 2020
Choosing Training-Test Split Dataset Given the full training data set of (s, g) pairs, we use 2
types of splitting into train and test datasets: (1) goal, and (2) state. We denote the training fraction
η =∈ [0, 1] as the fraction of the total data points used for the training set. For goal splitting, we pick
a subset of goals {g*} ⊆ g with ∣{g*}∣ ≈ (1 - η)∣{g}∣, and remove all (s, g) pairs where g ∈ g*,
from the training set. These goals were chosen to be the percentage of empty cells from the bottom
of the grid, when numbering the empty cells from left to right, and top-down (i.e. reading order of
words in a page). This corresponds to approximately a fraction of the bottom rows of goals. In this
case, the training set observes all possible states, and hence also all the transition rewards. We are
interested in whether it can generalize to new unseen goals. For state splitting, we perform a similar
procedure but instead with a subset of states which are removed, with the states corresponding to the
agent being at the bottom rows of the grid. While all the goals are included in the training dataset, in
the state splitting, some states and transition rewards are unknown to the agent, hence much more
difficult to generalize.
Architecture The architectures used for the experiments consist of a shared feature extractor φ for
the state s and goal g, followed by a function fθ on the difference of the features:
V (s, g; φ, θ) = fθ(φ(g) - φ(s))	(4)
The feature extractor φ is composed of 2 convolutional layers with 3 × 3 kernel size, and 32 and
62 filters with ReLU activations and a stride of 1. We then flatten the feature maps and follow by
2 fully connected layers of hidden size 128 and 64, with ReLU activation on the first layer only.
The variants of fθ are summarized in table 8. Euclidean simply computes the L2 norm between the
feature embeddings: kφ(g) - φ(s)k2:
Table 8: Value Function Architectures
fθ	# Hiddens	#	Layers	Act. Func.	Concave Units Pool Func.
	/Component Size	/Components		
MLP	64	3	ReLU	--
ICNN	64	3	ReLU	--
DeepNorm	64	3	MaxReLU	5	Mean
WideNorm	64	32	-	5	Mean
Training The objective function for training the models is the Temporal Difference (TD) Error
L(φ, θ):
L(φ,θ) = E(s,g)~D [(V(S,g; φ,θ) - y)2],
=(r(s, s0, g) + maXs'∈N(S) V(s0, g； Φ, θ) if s0 = g
y	r(S, S0, g),	otherwise
(5)
(6)
Where N(S) refers to the set of next states of S after applying different actions at that state. Note that
we did not apply a discount factor on the value of the next state (i.e. the discount factor γ = 1). We
make use of target networks φ, θ when computing the target y. The target networks are updated once
every epoch of training, via exponential moving average (Polyak Averaging) with the main networks
(φ, θ):
θ(n+1) = α(9(n) + (1 - α)θ(n),
(7)
where, α = 0.95 is the update fraction. We use Adam Kingma and Ba (2014) with learning rate
0.0001, batch size 128, for 1000 epoch. We evaluate SPL metric every 200 epoch.
20
Published as a conference paper at ICLR 2020
Evaluation Metrics We evaluate the learned value functions on several metrics: MSE, Policy
Success, and SPL Anderson et al. (2018). The MSE was calculated on on the ground truth value
of the held out test set V (s, g). For policy success and SPL, we select N = 100 random (s, g)
pairs in the test set, initialize the agent at s, and follow a greedy policy to visit the neighbour
s0 = arg max0s r(s, s0) + V (s0) for up to T = 121 timesteps (11 × 11). If the agent reaches the
desired goal within the episode i then the binary success indicator Si = 1 and the episode terminates,
and 0 otherwise. Let li be the ground truth V (s, g) optimal episode cumulative reward (i.e. path
cost), and pi the cumulative reward in the episode by the agent’s trajectory. We then define the Policy
Success rate and SPL as:
1N	1N	l
Success = N X Si，SPL= N X Si maχ(pi,ii)	⑻
F.2 Additional Evaluations and Visualizations
We visualize additional heatmaps for (1) learned value function (Figure 15), (2) Squared Error
(SE) between the ground truth value and the learned value (Figure 16), and (3) SPL metric for
individual (s0, s) and (s, s0) pairs (Figure 17). These results are for agents trained with training
fraction η = 0.75.
In comparing the performance versus training fraction, we also plot the final performance after 1000
epoch of training: (1) training set SPL versus training fraction (Figure 13a), (2) Train (Figure 14a)
and test (Figure 14b) mean squared error (MSE) with the groundtruth values. We note that while
our Deep Norm and Wide Norm appears to have higher MSE than the baselines, in practice when
utilizing the value function with greedy policy, our architectures were able to achieve better success
than the baseline architectures.
21
Published as a conference paper at ICLR 2020
(山 Sw) eqrow
IDI = 10000 IDI = 20000 IDI = 50000
40302010一
GSw)NAA
Ooooo
4 3 2 1
(山SiΛl) nN，Ncl
(a) Learning curves for to
GJSW) eqraw
(山SW) NM (WSW) WN—Nd
O O O O „
4 3 2 1
(山 Sw)Cnw
∣D∣
=2000
=5000
10000
<				-tr -te ^
		min final	te 27 te 29
[DI
∣D∣
			-tr -te
v-				
		min	te 23
		final	te 23
7			-tr
Γ			-te
I		min te 28	
	—	final te 41	
	.				
	——tr -
	——te
生	min te 26
	
500	1000
				tr —te .
v—		
		min te 25 final te 25
min te
final te
min te 13
final te 21
500	1000
500	1000
500	1000
(b) Learning curves for 3d
IDI = 5000
IDI= 10000
Ooooooooo-
4 3 2 1 4 3 2 1
Gs≡pɪ:ew GSw) NM
		
		
		
		
	
	
	
	
				tr —te
		min te 38	
		final te 47	
IDI = 20000
IDI= 50000

			tr	
		—te	
			
C		min te 22 final te 23	
			
			
			
				tr —te
			min te 10
			final te 11
		
		
		
		
		
		
OOooooooOC
4 3 2 1 4 3 2 1
(山Sw) WN—N0 (山SW)Cnw
32
32
te3232
		
		
		
		
(c) Learning curves for taxi
Fig. 10: Symmetric graph learning curves.
22
Published as a conference paper at ICLR 2020
Ooooooooooooooo
4 3 2 1 4 3 2 1 4 3 2 1
(山 SIAI) eqrow (山 SW) NAA (WSW) nN，Na
O
Oo
min te 35
final te 52
	min	
	final	1
		
final te 23
			- tr ——te
		min te 22
		final te 22
			tr
		—te
		
1		
		
40302010C
GSw)CnIΛ∣

min te 35
final te 41
√-*⅜		 w -
(tr
te
∖	min te 25
∖	final te 35
500	1000
		
		-	tr -
/		——te
L		min te 23 final te 36
500	1000
500	1000 0
			tr
		—te-
C		min te 15 final te 25
500	, 1000
D
Oo
O
IDI = 2000
(a) Learning curves for 3dr
IDI = 5000
IDI = 10000
IDI = 20000
O O O O Λ
4 3 2 1
UJsn) eu(ow
			tr
		—te
		min te 252
		final te 261
		J —	tr te
		min te 237	
		nal te 254	
			tr —te
		min te 227
		inal te 240
		一	tr te
		min te 222	
	final te 230		
			tr	
		—te	
		min te 219	
		inal te 223	
∣D∣≡ 50000
Oooooooooo
4 3 2 1 4 3 2 1
(WSIAI) NM (山SW) WN，N。
40302010C
(山 SIAI)Cn 工
		tr
	—te
	min te 224 final te 231
		tr
	——te
	min te 219
	inalte 225
			tr
		——te
		min te 214
	final te 214	
			tr
		—te
		min te 205 inal te 205
		tr ——te
	
	min te 193
	inal te 193
			tr
		——te
		min te 177 inalte 177
		tr ——te	
	Lj	min te 222 inalte 317

Gsw)roxzew (山 SW) NM
			
			
			
		
		
		
OOooooooOC
4 3 2 1 4 3 2 1
(山Sw) WN—N0 (山SW)Cnw
		
		
		
final te 241
		I —	-tr -te
		min te 221	
	final te 223		
final te 201
min te 158
final te 158
min te 135
inalte 253
min te 46
final te 48
(b) Learning curves for 3dd
IDI= 2000
IDI = 5000
			tr
		—te
		min te 31
		final te 31
		
			te
		min te 39
		final ⅞e 39
				tr
			—te
		min te 32	
V		final te 39	
		
		min te 20 final te 22
—te
min te 18
final te 18
			tr —te
		
		mln te 14
已		final te 14
		——tr 	te
		
		min te 22
U		final ⅞e 22
final te 11
(c) Learning curves for push
Fig. 11: Asymmetric graph learning curves.
23
Published as a conference paper at ICLR 2020
4-Room Asym Reward
Fig. 12: GVF environments. Left: The 4-Room and Maze environments, with walls (green),
empty cells (red), and agent (blue). Center: Rewards in asymmetric environments. Symmetric
versions have reward -1 everywhere. Right: Example ground truth value, where state s0 denotes
agent at top left cell. Upper triangular regions indicate the value of V (s0, s) while lower indicate
V (s, s0).
24
Published as a conference paper at ICLR 2020
4-Room (Asym)	4-Room (Sym)	Maze (Asym)	Maze (Sym)
Test SPL	Test SPL	ɪ	Train SPL	Train SPL
euclidean	—ɪ- mlp --I— icnn -⅛- deepnorm asym -⅛- widenorm asym deepnorm sym widenorm sym
(a) Train Set SPL versus fraction of training set.
euclidean mlp —I—■ icnn -十一deepnorm asym widenorm asym deepnorm sym widenorm sym
(b) Test Set SPL versus fraction of training set.
Fig. 13: Additional performance on the train/test SPL metric vs training fraction for the four
environment variants (higher is better).
25
Published as a conference paper at ICLR 2020
4-Room (Asym)
打 0.10
∑
c
'ra
匚 0.05
0.00
Training Frac (goal)
山 s≡U'5:
Training Frac (state)
0.100-
0.075-
0.050-
0.025
0.000
0.25	0.50	0.75	1.00
Training Frac (state)
Training Frac (state)
euclidean	—ɪ- mlp -I— icnn -⅛- deepnorm asym -⅛- widenorm asym deepnorm sym widenorm sym
(a)	Train Set MSE versus fraction of training set.
4-Room (Asym)
4-Room (Sym)
Maze (Asym)
Maze (Sym)
山 SWtt31
Training Frac (goal)
Training Frac (goal)
Training Frac (state)
Training Frac (state)
0.75	1.00
Training Frac (state)
--------1--------；
0.25	0.50	0.75	1.00
Training Frac (state)
0.50
—j— euclidean -ɪ- mlp
icnn -于-deepnorm asym -f-- widenorm asym deepnorm sym widenorm sym
(b)	Test Set MSE versus fraction of training set.
Fig. 14: Additional performance on the train/test MSE metric vs training fraction for the four
environment variants (lower is better).
26
Published as a conference paper at ICLR 2020


Vah
Groundtruth
value Euclidean
VaUp M p
value DeenNorm ⅛ym Value WldeNorm ASyE
value WldeNorm Sym
ValiiP Ml P
ValllO ICNN
DeepNorm .
value WldeNorm Sym
(a)	4-Room Asymmetric environment
Value DeenNorm Svm
Value DeepNorm Sym
Value WIdeNorm Asym
Value WIdeNorm Asym
VaIUe WldeNorm SVE
Value WIdeNorm Sym

Sr Cxs -
(b)	4-Room Symmetric environment
value Groundtruth
Value Euclidean
Value MLP
Value ICNN
Value DeepNorm Asym
Value DeepNorm Sym
Value WIdeNorm Asym
Value WIdeNorm Sym
Value Grcundtruth
Value Euclidean
Value MLP
Value ICNN
Value OeepNorm Asym
Value DeepNorm Sym
Value WldeNorm Asym
Value WIdeNorm Sym
(c)	Maze Asymmetric environment
(d)	Maze Symmetric environment
Fig. 15: Learned Value Function for the four environments with Train Fraction = 0.75.
27
Published as a conference paper at ICLR 2020
-K6 ⅞S9χ UXSVEOOUd
SE MLP
value GroundtriJth
CeISqMX gΛSV E8tfl4
V=Iig Λroι ιn<4tτι rt∙h
-3» srcwEooa—4
£AU Sr Cxs EOOK4
value Groundtruth
-3v ⅞h gxsv SNnX
Value Groundtnjth
sH ⅜hgxsv SNnX
Value Groundtnjth
-3» Sr WS «N£
V=Iig Λroι ιn<⅛n ιt∙h
SE Euclidean
CB l∕qUU
CC rααr⅜klc∙m Acir m
CC ΓΛaαr⅜klcrm Cvfm
CC U/IHoMrtrm "c，E

(a) 4-Room Asymmetric environment
SE Euclidean
SE MLP
SE ICNN
SE DeepNorm Asym	SE DeepNorm Sym
SE WIdeNorm Asym
-500
-400
-300
-200
-100
-0
CP UUlrioMnrm Cvm
用和FIFIFIE
R111÷⅞TI⅜ITE
(b) 4-Room Symmetric environment
SE DeepNorm Asym
SE DeepNorm Sym
SE WIdeNorm Asym
SE Euclidean
SE EUCudean
SE MLP
SE MLP
SE ICNN

SE WIdeNorm Sym
B
CP PriflMaan
1
SE DeepNorm Asym
SE PeePNornI SynI
因同
(c) Maze Asymmetric environment
SEMLP
CF CNN
SE DeepNorm Asym
sF IlAAnNnrm Svm
SE WIdeNorm Asym
sF WIrwNnrm AVVE
SE WIdeNorm Sym
≡
SE WIdeNorm Sym
≡
g-io.0
75
5.0
25
100
ΓI-4∞
3∞
200
100
-1500
-1000
-5∞
-0
-80
-eo
-40
-20
-0
SE WIdeNorm Sym
(d) Maze Symmetric environment
Fig. 16: Squared Error (SE) compared to the ground truth value function for the four environments
with Train Fraction = 0.75.
28
Published as a conference paper at ICLR 2020
SPLWideNorm Asym
SPL WideNorm Asym
SPL DeepNorm Sym
SPL DeePNorm Sym

SPL DeepNorm Asym
SPL DeepNorm Asym
SPL Euclidean
SPL Euclidean
∙,13s~8F-EASY E00tt4
-80 -EASY E00tt4
(a)	4-Room Asymmetric environment
-SS ⅛F -E>» Eootflvs3s GF-UJΛS EMUS
SPL Euclidean
SPL Euclidean
SPL DeepNorm Asym
SPL DeepNorm Asym
SPL DeepNorm Sym
SPL DeepNorm Sym
SPL WideNorm Asym
SPL WideNorm Asym
SPL WideNorm Sym
-0∙β
-0.6
0.4
-0.2
SPL WideNorm Sym
-o.e
-0.6
0.4
-0.2
1.0
0.0
1.0
-0.0
(b)	4-Room Symmetric environment
SPL Eudidean
-SS ⅛F -IUAsV VNOE
SPL MLP
SPL ICNN
SPL DeepNorm Asym
SPL DeepNorm Sym
SPL WideNorm Asym
SPL Euclidean
s3s ⅜F-E‰W< HOE
SPL MLP
SPL ICNN
SPL DeepNorm Asym
SPL DeePNorm Sym
SPL WideNorm Asym
(c)	Maze Asymmetric environment
-SS ⅜F-E›n VNOX
s3s ⅜F-E›n VNOX
SPL DeePNOrm ASym
SPL DeepNorm Sym
SPL WideNorm Asym
SPLWideNorm Sym
0.6
0.4
0.2
0.0
SPL DeepNorm Asym	SPL DeepNorm Sym SPL WideNorm Asym
(d)	Maze Symmetric environment
Fig. 17: Success weighted by Path Length (SPL) metric the four environments with Train Fraction =
0.75.
29