Published as a conference paper at ICLR 2020
Relational State-Space Model
for Stochastic Multi-Object Systems
Fan Yangt, Ling Chen*t, Fan Zhout, Yusong Gao^, Wei Cao^
tCollege of Computer Science and Technology, Zhejiang University, Hangzhou, China
^ Alibaba Group, Hangzhou, China
{fanyang01,lingchen,fanzhou}@zju.edu.cn
{jianchuan.gys,mingsong.cw}@alibaba-inc.com
Ab stract
Real-world dynamical systems often consist of multiple stochastic subsystems that
interact with each other. Modeling and forecasting the behavior of such dynamics
are generally not easy, due to the inherent hardness in understanding the com-
plicated interactions and evolutions of their constituents. This paper introduces
the relational state-space model (R-SSM), a sequential hierarchical latent variable
model that makes use of graph neural networks (GNNs) to simulate the joint state
transitions of multiple correlated objects. By letting GNNs cooperate with SSM,
R-SSM provides a flexible way to incorporate relational information into the mod-
eling of multi-object dynamics. We further suggest augmenting the model with
normalizing flows instantiated for vertex-indexed random variables and propose
two auxiliary contrastive objectives to facilitate the learning. The utility of R-SSM
is empirically evaluated on synthetic and real time series datasets.
1	Introduction
Many real-world dynamical systems can be decomposed into smaller interacting subsystems if we
take a fine-grained view. For example, the trajectories of coupled particles are co-determined by per-
particle physical properties (e.g., mass and velocity) and their physical interactions (e.g., gravity);
traffic flow can be viewed as the coevolution of a large number of vehicle dynamics. Models that
are able to better capture the complex behavior of such multi-object systems are of wide interest to
various communities, e.g., physics, ecology, biology, geoscience, and finance.
State-space models (SSMs) are a wide class of sequential latent variable models (LVMs) that serve
as workhorses for the analysis of dynamical systems and sequence data. Although SSMs are tra-
ditionally designed under the guidance of domain-specific knowledge or tractability consideration,
recently introduced deep SSMs (Fraccaro, 2018) use neural networks (NNs) to parameterize flex-
ible state transitions and emissions, achieving much higher expressivity. To develop deep SSMs
for multi-object systems, graph neural networks (GNNs) emerge to be a promising choice, as they
have been shown to be fundamental NN building blocks that can impose relational inductive bias
explicitly and model complex interactions effectively (Battaglia et al., 2018).
Recent works that advocate GNNs for modeling multi-object dynamics mostly make use of GNNs
in an autoregressive (AR) fashion. AR models based on recurrent (G)NNs can be viewed as special
instantiations of SSMs in which the state transitions are restricted to being deterministic (Fraccaro,
2018, Section 4.2). Despite their simplicity, it has been pointed out that their modeling capability is
bottlenecked by the deterministic state transitions (Chung et al., 2015; Fraccaro et al., 2016) and the
oversimplified observation distributions (Yang et al., 2018).
In this study, we make the following contributions: (i) We propose the relational state-space model
(R-SSM), a novel hierarchical deep SSM that simulates the stochastic state transitions of interacting
objects with GNNs, extending GNN-based dynamics modeling to challenging stochastic multi-ob-
ject systems. (ii) We suggest using the graph normalizing flow (GNF) to construct expressive joint
* Corresponding author.
1
Published as a conference paper at ICLR 2020
state distributions for R-SSM, further enhancing its ability to capture the joint evolutions of corre-
lated stochastic subsystems. (iii) We develop structured posterior approximation to learn R-SSM
using variational inference and introduce two auxiliary training objectives to facilitate the learning.
Our experiments on synthetic and real-world time series datasets show that R-SSM achieves com-
petitive test likelihood and good prediction performance in comparison to GNN-based AR models
and other sequential LVMs. The remainder of this paper is organized as follows: Section 2 briefly
reviews neccesary preliminaries. Section 3 introduces R-SSM formally and presents the methods
to learn R-SSM from observations. Related work is summarized in Section 4 and experimental
evaluation is presented in Section 5. We conclude the paper in Section 6.
2	Preliminaries
In this work, an attributed directed graph is given by a 4-tuple: G = (V, E, V, E), where V = [N] :=
{1, . . . , N} is the set of vertices, E ⊆ [N] × [N] is the set of edges, V ∈ RN×dv is a matrix of static
vertex attributes, and E ∈ RN ×N ×de is a sparse tensor storing the static edge attributes. The set of
direct predecessors of vertex i is notated as Ni- = {p|(p, i) ∈ E}. We use the notation xi to refer to
the i-th row of matrix X and write xij to indicate the (i, j)-th entry of tensor X (if the corresponding
matrix or tensor appears in the context). For sequences, we write x≤t = x1:t := (x1, . . . , xt) and
switch to xt(i) for referring to the i-th row of matrix Xt .
2.1	Graph Neural Networks
GNNs are a class of neural networks developed to process graph-structured data and support rela-
tional reasoning. Here we focus on vertex-centric GNNs that iteratively update the vertex repre-
sentations of a graph G while being equivariant (Maron et al., 2019) under vertex relabeling. Let
H ∈ RN×d be a matrix of vertex representations, in which the i-th row hi ∈ Rd is the vectorized
representation attached to vertex i. Conditioning on the static graph structure and attributes given
by G, a GNN just takes the vertex representations H along with some graph-level context g ∈ Rdg
as input and returns new vertex representations H0 ∈ RN×d0 as output, i.e., H0 = GNN(G, g, H).
When updating the representation of vertex i from hi to h0i , a GNN takes the representations of
other nearby vertices into consideration. Popular GNN variants achieve this through a multi-round
message passing paradigm, in which the vertices repeatedly send messages to their neighbors, ag-
gregate the messeages they received, and update their own representations accordingly. Formally,
the operations performed by a basic block of a message-passing GNN are defined as follows:
∀(j, i) ∈	E	:	Mj→i	=	MESSAGE (g, vj, vi, eji, hj, hi)	(1)
∀i ∈	V	:	Ai	=	AGGREGATE {Mp→i}p∈Ni-	(2)
∀i ∈	V	:	h0i	=	COMBINE(g,vi,hi,Ai)	(3)
Throughout this work, we	implement Equations	(1)	and (2) by adopting a multi-head attention mech-
anism similar to Vaswani et al. (2017) and Velikovi et al. (2018). For Equation (3), we use either a
RNN cell or a residual block (He et al., 2016), depending on whether the inputs to GNN are RNN
states or not. We write such a block as H0 = MHA(G, g, H) and give its detailed implementation
in the Appendix. A GNN simply stacks L separately-parameterized MHA blocks and iteratively
computes H =: H(0), . . . , H(L) =: H0, in which H(l) = MHA(G, g, H(l-1)) for l = 1, . . . , L. We
write this construction as H0 = GNN(G, g, H) and treat it as a black box to avoid notational clutter.
2.2	State-Space Models
State-space models are widely applied to analyze dynamical systems whose true states are not
directly observable. Formally, an SSM assumes the dynamical system follows a latent state pro-
cess {zt}t≥1, which possibly depends on exogenous inputs {ut}t≥1. Parameterized by some
(unknown) static parameter θ, the latent state process is characterized by an initial density
zι 〜 ∏θ(∙∣uι) and a transition density Zt+1 〜 fθ (∙∣z≤t, U≤t+1). Moreover, at each time
step, some noisy measurements of the latent state are observed through an observation density:
2
Published as a conference paper at ICLR 2020
Figure 1: Graphical structures of R-SSM. Diamonds represent deterministic states and circles repre-
sent random variables. To be concise, the dependencies on the graph G and exogenous inputs U1:T
are not shown. (b) is the result of collapsing all deterministic states in (a) and writing Zt = (ztg , Zt).
In (c), solid lines represent the computation shared with the generative model and dashed lines rep-
resent additional computation for inference.
Xt 〜gθ (∙∣z≤t, U≤t) . The joint density of xi：t and zi：T factors as: p(xi：T, zi：T|ui：T)=
∏θ (zi| Ui) Q T=2 fθ (z t∣ z <t, U ≤t) Q T=I gθ (x t∣ z ≤t, U ≤t).
The superior expressiveness of SSMs can be seen from the fact that the marginal predictive dis-
tribution P(xt∣X<t, U≤t) = JP(xt, Z≤t∖X<t, U≤t) dz≤t can be far more complex than unimodal
distributions and their finite mixtures that are common in AR models. Recently developed deep
SSMs use RNNs to compress z≤t (and U≤t) into fixed-size vectors to achieve tractability. As shown
in next section, R-SSM can be viewed as enabling multiple individual deep SSMs to communicate.
2.3	Normalizing Flows
Normalizing flows (Rezende & Mohamed, 2015) are invertible transformations that have the capabil-
ity to transform a simple probability density into a complex one (or vice versa). Given two domains
X ⊆ RD and Y ⊆ RD, letf : X → Y be an invertible mapping with inverse f-1. Applying f to
a random variable z ∈ X with density p(z), by the change of variables rule, the resulting random
variable z0 = f(z) ∈ Y will have a density:
0	∂f-1
P(z0) = P(Z) det --——I = P(Z) det
∂z0
∂f
∂ Z
-1
A series of invertible mappings with cheap-to-evaluate determinants can be chained together to
achieve complex transformations while retaining efficient density calculation. This provides a pow-
erful way to construct expressive distributions.
3	Relational State-Space Model
Suppose there is a dynamical system that consists of multiple interacting objects, and observing this
system at a specific time is accomplished by acquiring measurements from every individual object
simultaneously. We further assume these objects are homogeneous, i.e., they share the same mea-
surement model, and leave systems whose constituents are nonhomogeneous for future work. To
generatively model a time-ordered series of observations collected from this system, the straightfor-
ward approach that builds an individual SSM for each object is usually unsatisfactory, as it simply
assumes the state of each object evolves independently and ignores the interactions between objects.
To break such an independence assumption, our main idea is to let multiple individual SSMs interact
through GNNs, which are expected to capture the joint state transitions of correlated objects well.
3
Published as a conference paper at ICLR 2020
3.1	Generative model
Given the observations for a multi-object dynamical system, our model further assumes its inter-
action structure is known as prior knowledge. The interaction structure is provided as a directed
graph, in which each object corresponds to a vertex, and a directed edge indicates that the state of
its head is likely to be affected by its tail. In situations where such graph structure is not available, a
complete graph can be specified. However, to model dynamical systems comprising a large number
of objects, it is often beneficial to explicitly specify sparse graph structures, because they impose
stronger relational inductive bias and help save the computational cost.
A relational state-space model assumes a set of correlated dynamical subsystems evolve jointly under
the coordination of graph neural networks. Formally, given a graph G = (V, E, V, E), in which an
edge (i, j) ∈ E indicates that the state of vertex j may be affected by vertex i. Let ut(i) ∈ Rdu
and x(ti) ∈ Rdx be the input and observation for vertex i at time step t, respectively. For T steps,
we introduce a set of unobserved random variables {z(1i:)T}iN=1, in which zt(i) ∈ Rdz represents the
latent state of vertex i at time step t. Furthermore, we introduce a global latent variable ztg ∈ Rdg
for each time step to represent the global state shared by all vertices. Conditioning on the graph and
exogenous inputs, an R-SSM factorizes the joint density of observations and latent states as follows:
T
Y fθ ({z 弋)} N=1, Z "俄 it} L，Z <t, G,{u 罢} 3)
t=1
TN
YYgθ (xt(i)Zt(i),Zg≤t, {Z(<i)t}iN=1,G, {u(≤i)t}iN=1) (4)
t=1 i=1
For notational simplicity, we switch to the matrix notation Zt = Zt(1), Zt(2), . . . , Zt(N) from now
on. The joint transition density fθ is further factorized as a product of global transition density
fθg and local transition density fθ?, i.e., fθ (Zt, Ztg|. . .) = fθg (Ztg|. . .) fθ? (Zt|Ztg, . . .) . To instan-
tiate these conditional distributions, a GNN accompanied by RNN cells is adopted to recurrently
compress the past dependencies at each time step into fixed-size context vectors. Specifically, the
observations are assumed to be generated from following process:
ht() = RNNV (ht-1, [zt-1, Ut()]), hg = READOUTθ(G, Ht)
h g = RNN g (h g-1，[z g-1，h g ])，Z g 〜fθ (' Ihg)
Ht = GNNg(G, zg,Ht), Zt 〜fg(∙∣Ht)
Xt i 〜gθ(∙ ∣zti), h (i), z g, h g)
for i = 1,..., N and t = 1,…，T, where h0i) = h 0 and z0i) = Zd. Here hg, zg, hŋ and Zd are
learnable initial states. The READOUT function aggregates the context vectors of all vertices into a
global context vector in a permutation-invariant manner. The global transition density fθg is specified
to be a diagonal Gaussian distribution whose mean and variance are parameterized by the output of
a multilayer perceptron (MLP), and the local transition density fθ? will be discussed later. The local
observation distribution gθ can be freely selected in line with the data, and in our experiments it is
either a Gaussian distribution or a mixture of logistic distributions parameterized by MLPs.
The graphical structure of two consecutive steps of the generating process is illustrated in Figure 1a.
An intuitive way to think about this generative model is to note that the N + 1 latent state processes
interact through the GNN, which enables the new state of a vertex to depend on not only its own
state trajectory but also the state trajectories of other vertices and the entire graph.
3.2	Learning and inference
As illustrated in Figure 1b, writing Zt = (ztg , Zt) and suppressing the dependencies on the graph
G and exogenous inputs U1:T , an R-SSM can be interpreted as an ordinary SSM in which the
entire graph evolves as a whole, i.e., the joint density of latent states and observations factors as:
4
Published as a conference paper at ICLR 2020
P (Xi： τ, Z i： τ) = Q T=1 pθ (Zt∣Z<t) Pθ (X t∣Zt). Given observations Xi： t , we are interested in learn-
ing unknown parameters θ and inferring unobserved states Z1:T. For the learning task we wish to
maximize the marginal likelihood pθ(Xi：t) = J pθ(Xi：t, Zi：t) dZi：t, but in our case the integral
is intractable. We adopt a recently developed variational inference (VI) approach called variational
sequential Monte Carlo (VSMC) (Maddison et al., 2017; Naesseth et al., 2018; Le et al., 2018),
which maximizes a variational lower bound on the log marginal likelihood instead and learns the
proposal distributions for the inference task simultaneously.
Given a sequence of proposal distributions {qφ (Zt|Z<t, X≤t)}tT=i parameterized by φ, running the
sequential Monte Carlo (SMC) algorithm with K particles yields an unbiased marginal likelihood
estimator pθφ,κ(Xi：T) = QtT=i i/K PkK=i wtk , where wtk is the unnormalized importance weight
of particle k at time t. The variational lower bound is obtained by applying the Jensen’s inequality:
L铲C(θ, Φ) ：= E [logPθ,φ,κ(Xi：t)] ≤ logE [Pθ,φ,κ(Xi：T)] = logPθ(Xi：t)	⑸
Assuming the proposal distributions are reparameterizable (Kingma & Welling, 2014), we use the
biased gradient estimator VLSMC(θ, φ) ≈ E[V log ιpθ,φ,κ (Xi：t)] to maximize LSMc.
Proposal design. We make the proposal for Zt depend on the information up to time t and
share some parameters with the generative model. We also choose to factorize qφ (Zt|. . .) =
rφg (ztg|. . .) rφ? (Zt|ztg, . . .) . The proposal distributions for all time steps are structured as follows:
b (i) = RNN φ (bt-i ,[xti), Uti)]), b g = READOUT φ,i( G, B t)
Bt = GNNφ (G, bg, Bt), bg = READOUTφ,2(G, Bt)
Zg 〜τφ( ∙∣hg, bg), Zt 〜rφ(∙∣Ht, Bt)
for i = 1, . . . , N and t = 1, . . . , T, where htg and Hi：T are computed using the relevant parts of the
generative model. rφg is specified to be a diagonal Gaussian parameterized by an MLP, and rφ? will be
discussed soon. Here Bt can be interpreted as a belief state (Gregor et al., 2019), which summarizes
past observations X≤t (and inputs U≤t) deterministically. The graphical structure of this proposal
design is shown in Figure 1c, and the detailed VSMC implementation using this proposal is given
in Appendix A.4.
3.3	Graph Normalizing Flow
The local transition density fθ? Zt ∣ . . . and the local proposal density rφ? (Zt|. . .) may be param-
eterized in several ways. One simple and efficient starting point is (block-)diagonal Gaussian dis-
tribution: fθ? (Zt∣ ∙∙∙) = QN=IN(z(i)|...), which assumes that the object states are conditionally
independent, i.e., the joint state distribution is completely factorized over objects. We believe that
such an independence assumption is an oversimplification for situations where the joint state evolu-
tion is multimodal and highly correlated. One possible way to introduce inter-object dependencies
is modeling joint state distributions as Markov random fields (MRFs) (Naesseth et al., 2019), but
this will significantly complicate the learning.
Here we introduce the Graph Normalizing Flow (GNF) 1, which adapts Glow (Kingma & Dhariwal,
2018) to graph settings and enables us to build expressive joint distributions for correlated random
variables indexed by graph nodes. As described earlier, the key ingredient for a flow is a series
invertible mappings that are iteratively applied to the samples of a base distribution. Now we are
interested in the case where the samples are vertex states Zt, and thus the invertible mappings
should be further constrained to be equivariant under vertex relabeling. This rules out popular
autoregressive flows, e.g., IAF (Kingma et al., 2016) and MAF (Papamakarios et al., 2017).
Our GNF is built upon the coupling layer introduced in Dinh et al. (2017), which provides a flexible
framework to construct efficient invertible mappings. A GNF coupling layer splits the input Z ∈
RN×D into two parts, Za ∈ RN×d and Zb ∈ RN×(D-d). The output Z0 ∈ RN×D is formed as:
Z a = Z a , Z b = Z b Θ exp (S (Z a )) + t (Z a ) , Z 0 = [Z Za, Z b ],
1GNF has been independently developed by Liu et al. (2019) for different purpose.
5
Published as a conference paper at ICLR 2020
where Θ denotes the element-wise product, and the functions S (∙) and t (∙) are specified to be GNNs
to enforce the equivariance property. A GNF combines a coupling layer with a trainable element-
wise affine layer and an invertible 1 × 1 convolution layer (Hoogeboom et al., 2019), organizing them
as: Input → Affine → Coupling → Conv1×1 → Output. A visual illustration of this architecture is
provided in Appendix A.5.
In order to obtain more expressive prior and variational posterior approximation, the local transition
density and local proposal density can be constructed by stacking multiple GNFs on top of diagonal
Gaussian distributions parameterized by MLPs. With the message passing inside the coupling layers,
GNFs can transform independent noise into correlated noise and thus increase model expressivity.
The 1 × 1 convolution layers free us from manually permuting the dimensions, and the element-wise
affine layers enable us to tune their initial weights to stablize training.
3.4	Auxiliary contrastive prediction tasks
In our initial experiments, we found that learning R-SSM suffered from the posterior collpase
phenomenon, which is a well known problem in the training of variational autoencoders (VAEs).
It means that the variational posterior approximation q®(Zt∣Z<t, X≤) degenerate into the prior
fθ(Zt∣Z<t) in the early stage of optimization, making the training dynamics get stuck in undesir-
able local optima. Besides, we also encountered a more subtle problem inherent in likelihood-based
training of deep sequential models. That is, for relatively smooth observations, the learned model
tended to only capture short-term local correlations but not the interaction effects and long-term
transition dynamics.
Motivated by recent advances in unsupervised representation learning based on mutual information
maximization, in particular the Contrastive Predictive Coding (CPC) approach (Oord et al., 2018),
we alleviate these problems by forcing the latent states to perform two auxiliary contrastive predic-
tion tasks. At each time step t, the future observations of each vertex i are summarized into a vector
using a backward RNN: c(ti) = RNNψ(x(>i)t). Then we define two auxiliary CPC objectives:
La1ux
X1Xlog	λψ,ι(Ii),c))
t=1 白	Pc∈Ωt,i λΨ, 1(zF ,c)
T-1 N	λ (flii)「(i八
X Xlog Pc∈Ω2¾⅛
E
where zt ) = [zg, zti)], h(i) = MLPψ(Pj=i ∧ j∈N- h(j)), and ωt,i is a set that contains c(ti) and
some negative samples. The expectation is over negative samples and the latent states sampled from
the filtering distributions. The positive score functions λψ,1 and λψ,2 are specified to be simple
log-bilinear models.
Intuitively, La1ux encourages the latent states to encode useful information that helps distinguish the
future summaries from negative samples. La2ux encourages the deterministic states to reflect the
interaction effects, as it contrastingly predicts the future summary of vertex i based on the states of
i’s neighbors only. The negative samples are selected from the future summaries of other vertices
within the minibatch. The final objective to maximize is L = L4 SKMC + β1La1ux + β2La2ux, in which
β1 ≥ 0 and β2 ≥ 0 are tunable hyperparameters. The procedure to estimate this objective is
described in Appendix A.4.
4 Related Work
GNN-based dynamics modeling. GNNs (Scarselli et al., 2009; Duvenaud et al., 2015; Li et al.,
2016; Defferrard et al., 2016; Gilmer et al., 2017; Hamilton et al., 2017; Velikovi et al., 2018; Xu
et al., 2019; Maron et al., 2019) provide a promising framework to learn on graph-structured data and
impose relational inductive bias in learning models. We refer the reader to Battaglia et al. (2018)
for a recent review. GNNs (or neural message passing modules) are the core components of re-
cently developed neural physics simulators (Battaglia et al., 2016; Watters et al., 2017; Chang et al.,
2017; Janner et al., 2019; Sanchez-Gonzalez et al., 2018; Mrowca et al., 2018; Li et al., 2019) and
spatiotemporal or multi-agent dynamics models (Alahi et al., 2016; Hoshen, 2017; Li et al., 2018;
Zhang et al., 2018; Tacchetti et al., 2019; Chen et al., 2020). In these works, GNNs usually act au-
toregressively or be integrated into the sequence-to-sequence (seq2seq) framework (Sutskever et al.,
6
Published as a conference paper at ICLR 2020
2014). Besides, recently they have been combined with generative adversarial networks (Goodfel-
low et al., 2014) and normalizing flows for multi-agent forecasting (Gupta et al., 2018; Kosaraju
et al., 2019; Rhinehart et al., 2019). R-SSM differs from all these works by introducing structured
latent variables to represent the uncertainty on state transition and estimation.
GNNs in sequential LVMs. A few recent works have combined GNNs with a sequential latent
variable model, including R-NEM (van Steenkiste et al., 2018), NRI (Kipf et al., 2018), SQAIR
(Kosiorek et al., 2018), VGRNN (Hajiramezanali et al., 2019), MFP (Tang & Salakhutdinov, 2019),
and Graph VRNN (Sun et al., 2019; Yeh et al., 2019). The latent variables in R-NEM and NRI
are discrete and represent membership relations and types of edges, respectively. In contrast, the
latent variables in our model are continuous and represent the states of objects. SQAIR is also a
deep SSM for multi-object dynamics, but the GNN is only used in its inference network. VGRNN
is focused on modeling the topological evolution of dynamical graphs. MFP employs a conditional
VAE architecture, in which the per-agent discrete latent variables are shared by all time steps. The
work most relevant to ours is Graph VRNN, in which the hidden states of per-agent VRNNs interact
through GNNs. Our work mainly differs from it by introducing a global latent state process to make
the model hierarchical and exploring the use of normalizing flows as well as the auxiliary contrastive
objectives. More subtle differences are discussed in Section 5.2.
Deep LVMs for sequential data. There has been growing interest in developing latent variable
models for sequential data with neural networks as their building blocks, among which the works
most relevant to ours are stochastic RNNs and deep SSMs. Many works have proposed incorporating
stochastic latent variables into vanilla RNNs to equip them with the ability to express more complex
data distributions (Bayer & Osendorfer, 2014; Chung et al., 2015; Fraccaro et al., 2016; Goyal
et al., 2017; Ke et al., 2019) or, from another perspective, developing deep SSMs by parameterizing
flexible transition and emission distributions using neural networks (Krishnan et al., 2017; Fraccaro
et al., 2017; Buesing et al., 2018; Zheng et al., 2017; Hafner et al., 2019). Approximate inference
and parameter estimation methods for nonlinear SSMs have been extensively studied in the literature
(Doucet & Johansen, 2009; Andrieu et al., 2010; Kantas et al., 2015; Gu et al., 2015; Karl et al., 2016;
Marino et al., 2018; Gregor et al., 2019; Hirt & Dellaportas, 2019). We choose VSMC (Maddison
et al., 2017; Naesseth et al., 2018; Le et al., 2018) as it combines the powers of VI and SMC. The
posterior collapse problem is commonly addressed by KL annealing, which does not work with
VSMC. The idea of using auxiliary costs to train deep SSMs has been explored in Z-forcing (Goyal
et al., 2017; Ke et al., 2019), which predicts the future summaries directly rather than contrastingly.
As a result, the backward RNN in Z-forcing may degenerate easily.
5	Experiments
We implement R-SSM using the TensorFlow Probability library (Dillon et al., 2017). The experi-
ments are organized as follows: In Section 5.1, we sample a toy dataset from a simple stochastic
multi-object model and validate that R-SSM can fit it well while AR models and non-relational
models may struggle. In Section 5.2, R-SSM is compared with state-of-the-art sequential LVMs
for multi-agent modeling on a basketball gameplay dataset, and the effectiveness of GNF is tested
through ablation studies. Finally, in Section 5.3, the prediction performance of R-SSM is compared
with strong GNN-based seq2seq baselines on a road traffic dataset. Due to the space constraint, the
detailed model architecture and hyperparameter settings for each dataset are given in the Appendix.
Below, all values reported with error bars are averaged over 3 or 5 runs.
5.1	Synthetic toy dataset
First we construct a simple toy dataset to illustrate the capability of R-SSM. Each example in this
dataset is generated by the following procedure:
G ~ SBM(N, K,po,pι), Vi ~ Normal(0, I), Z(i) ~ Normal(0, 1)
≡(i) = η> V i + α IP j∈Niz-ι/lNil + α 2 Zt-1	⑹
zti) 〜Normal(cos((Z(i)), σ2,	x(i) 〜Normal(tanh(εz(i)),q%)
7
Published as a conference paper at ICLR 2020
Table 2: Test log-likelihood and rollout quality comparisons on the basketball gameplay dataset
(offensive players only).
Model	SMC L1000	ELBO	Speed	Distance	OOB
VRNN	—	2360	0.89	43.78	33.78
MI-VRNN			2362	0.79	38.92	15.52
R-SSM	2459.8 ±.3	2372.3 ±.8	0.83 ±.01	40.75 ±.15	1.84 ±.16
+La2ux	2463.3 ±.4	2380.2 ±.6	0.82 ±.01	40.36 ±.23	2.17 ±.09
+GNF (4)	2483.2 ±.3	2381.6 ±.4	0.80 ±.00	39.37 ±.35	2.06 ±.15
+GNF (8)	2501.6 ±.2	2382.1 ±.4	0.79 ±.00	39.14 ±.29	2.12 ±.10
Ground Truth					0.77	37.78	2.21
for i = 1, . . . , N and t = 1, . . . , T . Here SBM is short for the symmetric stochastic block model,
in which each vertex i belongs to exact one of the K communities, and two vertices i and j are
connected with probability p0 if they are in the same community, p1 otherwise. A vertex-specific
covariate vector vi ∈ Rdv is attached to each vertex i, and by Equation (6), the state of each vertex
i can be affected by its neighbors Ni. Choosing the parameters dv = 4, N = 36, K = 3, p0 = 1/3,
p1 = 1/18, T = 80, α1 = 5.0, α2 = -1.5, η = [-1.5, 0.4, 2.0, -0.9]>, σx = σz = 0.05, and
ε = 2.5, we generate 10K examples for training, validation, and test, respectively. A typical example
is visualized in the Appendix.
Despite the simple generating process, the resulting dataset is highly challenging for common mod-
els to fit. To show this, we compare R-SSM with several baselines, including (a) VAR: Fitting a
first-order vector autoregression model for each example; (b) VRNN: A variational RNN (Chung
et al., 2015) shared by all examples; (c) GNN-AR: A variant of the recurrent decoder of NRI (Kipf
et al., 2018), which is exactly a GNN-based AR model when given the ground-truth graph. VAR
and VRNN are given access to the observations {x(1i:)T }iN=1 only, while GNN-AR and R-SSM are
additionally given access to the graph structure (V, E) (but not the vertex covariates). GNF is not
used in R-SSM because the true joint transition distribution is factorized over vertices.
For each model, we calculate three metrics:
(1) LL: Average log-likelihood (or its lower
bound) of test examples; (2) MSE: Average
mean squared one-step prediction error given
the first 75 time steps of each test example;
(3)	CP: Average coverage probability of a
90% one-step prediction interval. For non-
analytic models, point predictions and pre-
diction intervals are computed using 1000
Monte Carlo samples. The results are re-
ported in Table 1.
The generating process involves latent fac-
tors and nonlinearities, so VAR performs
Table 1: Test log-likelihood and prediction perfor-
mance comparisons on the synthetic toy dataset.
Model	LL	MSE	CP
VAR	-366	0.679 ± .000	0.750 ±.000
VRNN	≥-2641	0.501 ±.003	0.931 ±.002
GNN-AR	-94	0.286 ±.002	0.806 ±.004
R-SSM	≥2583	0.029 ± .00i	0.883 ±.002
+La2ux	≥2647	0.024 ±.001	0.897 ±.001
poorly as expected. VRNN largely underfits the data and struggles to generalize, which may be
caused by the different topologies under the examples. In contrast, GNN-AR and R-SSM gener-
alize well as expected, while R-SSM achieves much higher test log-likelihood and produces good
one-step probabilistic predictions. This toy case illustrates the generalization ability of GNNs and
suggests the importance of latent variables for capturing the uncertainty in stochastic multi-object
systems. We also observed that without La1ux the training dynamics easily get stuck in posterior
collapse at the very early stage, and adding La2ux help improve the test likelihood.
5.2	Basketball gameplay
In basketball gameplay, the trajectories of players and the ball are highly correlated and demonstrate
rich, dynamic interations. Here we compare R-SSM with a state-of-the-art hierarchical sequential
LVM for multi-agent trajectories (Zhan et al., 2019), in which the per-agent VRNNs are coordinated
8
Published as a conference paper at ICLR 2020
Table 3: Test log-likelihood comparison on
the basketball gameplay dataset (offensive
players plus the ball).
Model	LL	USMC L1000
Yeh et al. (2019)		
GRNN	2264		
VRNN	>2750	—
GVRNN	>2832		
R-SSM+La2ux	>2761 ± 1	2805 ±0
+GNF (8)	>2783 ±1	2826 ±0
Table 4: Forecast MAE comparison on the METR-
LA dataset. h is the number of steps predicted into
the future. The Xt-h baseline outputs Xt-h to
predict Xt .
Model	h = 3	h=6	h=12
Xt-h	3.97	4.99	6.65
DCRNN	2.77	3.15	3.60
GaAN	2.71	3.12	3.64
R-SSM	2.67 ±.00	3.14 ±.01	3.72 ±.02
CP	0.896 ±.001	0.891 ±.001	0.883 ±.002
by a global "macro intent" model. We note it as MI-VRNN. The dataset2 includes 107,146 training
examples and 13,845 test examples, each of which contains the 2D trajectories of ten players and the
ball recorded at 6Hz for 50 time steps. Following their settings, we use the trajectories of offensive
team only and preprocess the data in exactly the same way to make the results directly comparable.
The complete graph of players is used as the input to R-SSM.
Several ablation studies are performed to verify the utility of the proposed ideas. In Table 3, we
report test likelihood bounds and the rollout quality evaluated with three heuristic statistics: average
speed (feet/step), average distance traveled (feet), and the percentage of out-of-bound (OOB) time
steps. The VRNN baseline developed by Zhan et al. (2019) is also included for comparison. Note
that the VSMC bound LS1M00C0 is a tighter log-likelihood approximation than the ELBO (which is
equivalent to LS1MC). The rollout statistics of R-SSMs are calculated from 150K 50-step rollouts
with 10 burn-in steps. Several selected rollouts are visualized in the Appendix.
As illustrated in Table 2, all R-SSMs outperform the baselines in terms of average test log-likelihood.
Again, we observed that adding La1ux is necessary for training R-SSM successfully on this dataset.
Training with the proposed auxiliary loss La2ux and adding GNFs do improve the results. R-SSM with
8 GNFs (4 in prior, 4 in proposal) achieves higher likelihood than R-SSM with 4 GNFs, indicating
that increasing the expressivity of joint state distributions helps fit the data better. As for the rollout
quality, the OOB rate of the rollouts sampled from our model matches the ground-truth significantly
better, while the other two statistics are comparable to the MI-VRNN baseline.
In Table 3, we also provide preliminary results for the setting that additionally includes the tra-
jectory of the ball. This enables us to compare with the results reported by Yeh et al. (2019) for
Graph VRNN (GVRNN). The complete graph of ball and players served as input to R-SSM is an-
notated with two node types (player or ball) and three edge types (player-to-ball, ball-to-player or
player-to-player). R-SSM achieves competitive test likelihood, and adding GNFs helps improve the
performance. We point out that several noticeable design choices of GVRNN may help it outperform
R-SSM: (i) GVRNN uses a GNN-based observation model, while R-SSM uses a simple factorized
observation model. (ii) GVRNN encodes X1:t-1 into Ht and thus enables the prior of Zt to depend
on past observations, which is not the case in R-SSM. (iii) GVRNN uses several implementation
tricks, e.g., predicting the changes in observations only (Xt = Xt-1 + ∆Xt) and passing raw ob-
servations as additional input to GNNs. We would like to investigate the effect of these interesting
differences in future work.
5.3	Road traffic
Traffic speed forecasting on road networks is an important but challenging task, as the traffic dy-
namics exhibit complex spatiotemporal interactions. In this subsection, we demonstrate that R-SSM
is comparable to the state-of-the-art GNN-based seq2seq baselines on a real-world traffic dataset.
The METR-LA dataset (Li et al., 2018) contains 4 months of 1D traffic speed measurements that
were recorded via 207 sensors and aggregated into 5 minutes windows. For this dataset, all con-
ditional inputs G = (V, E, V, E) and U1:T are provided to R-SSM, in which E is constructed by
connecting two sensors if their road network distance is below a threshold, V stores the geographic
2Data Source: STATS,copyright 2019.
9
Published as a conference paper at ICLR 2020
positions and learnable embeddings of sensors, E stores the road network distances of edges, and
U1:T provides the time information (hour-of-day and day-of-week). We impute the missing values
for training and exclude them from evaluation. GNF is not used because of GPU memory limitation.
Following the settings in Li et al. (2018), we train our model on small time windows spanning 2
hours and use a 7:1:2 split for training, validation, and test.
The comparison of mean absolute forecast errors (MAE) is reported in Table 4. The three forecast
horizons correspond to 15, 30, and 60 minutes. We give point predictions by taking the element-
wise median of 2K Monte Carlo forecasts. Compared with DCRNN (Li et al., 2018) and GaAN
(Zhang et al., 2018), R-SSM delivers comparable short-term forecasts but slightly worse long-term
forecasts.
We argue that the results are admissible because: (i) By using MAE loss and scheduled sampling,
the DCRNN and GaAN baselines are trained on the multi-step objective that they are later evaluated
on, making them hard to beat. (ii) Some stochastic systems are inherently unpredictable beyond a
few steps due to the process noise, e.g., the toy model in Section 5.1. In such case, multi-step MAE
may not be a reasonable metric, and probabistic forecasts may be prefered. The average coverage
probabilities (CP) of 90% prediction intervals reported in Table 4 indicate that R-SSM provides
good uncertainty estimates. (iii) Improving the multi-step prediction ability of deep SSMs is still an
open problem with a few recent attempts (Ke et al., 2019; Hafner et al., 2019). We would like to
explore it in future work.
6 Conclusions
In this work, we present a deep hierarchical state-space model in which the state transitions of
correlated objects are coordinated by graph neural networks. To effectively learn the model from
observation data, we develop a structured posterior approximation and propose two auxiliary con-
trastive prediction tasks to help the learning. We further introduce the graph normalizing flow to
enhance the expressiveness of the joint transition density and the posterior approximation. The ex-
periments show that our model can outperform or match the state-of-the-arts on several time series
modeling tasks. Directions for future work include testing the model on high-dimensional observa-
tions, extending the model to directly learn from visual data, and including discrete latent variables
in the model.
Acknowledgments
This work was supported by the National Key Research and Development Program of China (No.
2018YFB0505000) and the Alibaba-Zhejiang University Joint Institute of Frontier Technologies.
Fan Yang would like to thank Qingchen Yu for her helpful feedback on early drafts of this paper.
References
Alexandre Alahi, Kratarth Goel, Vignesh Ramanathan, Alexandre Robicquet, Li Fei-Fei, and Silvio
Savarese. Social lstm: Human trajectory prediction in crowded spaces. In Proceedings of the
IEEE Conference on Computer Vision and Pattern Recognition, 2016.
Christophe Andrieu, Arnaud Doucet, and Roman Holenstein. Particle markov chain monte carlo
methods. Journal of the Royal Statistical Society: Series B (Statistical Methodology),72(3):269-
342, 2010.
Peter Battaglia, Razvan Pascanu, Matthew Lai, Danilo Jimenez Rezende, and koray kavukcuoglu.
Interaction networks for learning about objects, relations and physics. In Advances in Neural
Information Processing Systems 29. 2016.
Peter W Battaglia, Jessica B Hamrick, Victor Bapst, Alvaro Sanchez-Gonzalez, Vinicius Zambaldi,
Mateusz Malinowski, Andrea Tacchetti, David Raposo, Adam Santoro, Ryan Faulkner, et al. Re-
lational inductive biases, deep learning, and graph networks. arXiv preprint arXiv:1806.01261,
2018.
Justin Bayer and Christian Osendorfer. Learning stochastic recurrent networks. arXiv preprint
arXiv:1411.7610, 2014.
10
Published as a conference paper at ICLR 2020
Lars Buesing, Theophane Weber, Sebastien Racaniere, SM Eslami, Danilo Rezende, David P Re-
ichert, Fabio Viola, Frederic Besse, Karol Gregor, Demis Hassabis, et al. Learning and querying
fast generative models for reinforcement learning. arXiv preprint arXiv:1802.03006, 2018.
Michael Chang, Tomer Ullman, Antonio Torralba, and Joshua Tenenbaum. A compositional object-
based approach to learning physical dynamics. In International Conference on Learning Repre-
sentations. 2017.
Weiqi Chen, Ling Chen, Yu Xie, Wei Cao, Yusong Gao, and Xiaojie Feng. Multi-range attentive
bicomponent graph convolutional network for traffic forecasting. In AAAI Conference on Artificial
Intelligence, 2020.
Junyoung Chung, Kyle Kastner, Laurent Dinh, Kratarth Goel, Aaron C Courville, and Yoshua Ben-
gio. A recurrent latent variable model for sequential data. In Advances in Neural Information
Processing Systems 28, 2015.
Michael Defferrard, Xavier Bresson, and Pierre Vandergheynst. Convolutional neural networks
on graphs with fast localized spectral filtering. In Advances in Neural Information Processing
Systems 29. 2016.
Joshua V Dillon, Ian Langmore, Dustin Tran, Eugene Brevdo, Srinivas Vasudevan, Dave Moore,
Brian Patton, Alex Alemi, Matt Hoffman, and Rif A Saurous. Tensorflow distributions. arXiv
preprint arXiv:1711.10604, 2017.
Laurent Dinh, Jascha Sohl-Dickstein, and Samy Bengio. Density estimation using real nvp. In
International Conference on Learning Representations, 2017.
Arnaud Doucet and Adam M Johansen. A tutorial on particle filtering and smoothing: Fifteen years
later. Handbook of Nonlinear Filtering, 2009.
David K Duvenaud, Dougal Maclaurin, Jorge Iparraguirre, Rafael Bombarell, Timothy Hirzel, Alan
Aspuru-Guzik, and Ryan P Adams. Convolutional networks on graphs for learning molecular
fingerprints. In Advances in Neural Information Processing Systems 28. 2015.
Marco Fraccaro. Deep Latent Variable Models for Sequential Data. PhD thesis, 2018.
Marco Fraccaro, S0ren Kaae S0 nderby, Ulrich Paquet, and Ole Winther. Sequential neural models
with stochastic layers. In Advances in Neural Information Processing Systems 29, 2016.
Marco Fraccaro, Simon Kamronn, Ulrich Paquet, and Ole Winther. A disentangled recognition
and nonlinear dynamics model for unsupervised learning. In Advances in Neural Information
Processing Systems 30, 2017.
Justin Gilmer, Samuel S. Schoenholz, Patrick F. Riley, Oriol Vinyals, and George E. Dahl. Neu-
ral message passing for quantum chemistry. In Proceedings of the International Conference on
Machine Learning, 2017.
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair,
Aaron Courville, and Yoshua Bengio. Generative adversarial nets. In Advances in Neural Infor-
mation Processing Systems 27. 2014.
Anirudhand Goyal, Alessandro Sordoni, Marc-Alexandre C6t6, Nan Rosemary Ke, and Yoshua
Bengio. Z-forcing: Training stochastic recurrent networks. In Advances in Neural Information
Processing Systems 30, 2017.
Karol Gregor, George Papamakarios, Frederic Besse, Lars Buesing, and Theophane Weber. Tempo-
ral difference variational auto-encoder. In International Conference on Learning Representations,
2019.
Shixiang (Shane) Gu, Zoubin Ghahramani, and Richard E Turner. Neural adaptive sequential monte
carlo. In Advances in Neural Information Processing Systems 28. 2015.
Agrim Gupta, Justin Johnson, Li Fei-Fei, Silvio Savarese, and Alexandre Alahi. Social gan: So-
cially acceptable trajectories with generative adversarial networks. In Proceedings of the IEEE
Conference on Computer Vision and Pattern Recognition, 2018.
11
Published as a conference paper at ICLR 2020
Danijar Hafner, Timothy Lillicrap, Ian Fischer, Ruben Villegas, David Ha, Honglak Lee, and James
Davidson. Learning latent dynamics for planning from pixels. In Proceedings of the International
Conference on Machine Learning, 2019.
Ehsan Hajiramezanali, Arman Hasanzadeh, Nick Duffield, Krishna R Narayanan, Mingyuan Zhou,
and Xiaoning Qian. Variational graph recurrent neural networks. In Advances in Neural Informa-
tion Processing Systems 32. 2019.
Will Hamilton, Zhitao Ying, and Jure Leskovec. Inductive representation learning on large graphs.
In Advances in Neural Information Processing Systems 30. 2017.
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recog-
nition. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,
2016.
Marcel Hirt and Petros Dellaportas. Scalable bayesian learning for state space models using varia-
tional inference with smc samplers. In Proceedings of the International Conference on Artificial
Intelligence and Statistics, 2019.
Emiel Hoogeboom, Rianne van den Berg, and Max Welling. Emerging convolutions for generative
normalizing flows. In Proceedings of the International Conference on Machine Learning, 2019.
Yedid Hoshen. Vain: Attentional multi-agent predictive modeling. In Advances in Neural Informa-
tion Processing Systems 30. 2017.
Michael Janner, Sergey Levine, William T. Freeman, Joshua B. Tenenbaum, Chelsea Finn, and
Jiajun Wu. Reasoning about physical interactions with object-centric models. In International
Conference on Learning Representations, 2019.
Nikolas Kantas, Arnaud Doucet, Sumeetpal S Singh, Jan Maciejowski, Nicolas Chopin, et al. On
particle methods for parameter estimation in state-space models. Statistical Science, 30(3):328-
351, 2015.
Maximilian Karl, Maximilian Soelch, Justin Bayer, and Patrick van der Smagt. Deep variational
bayes filters: Unsupervised learning of state space models from raw data. In International Con-
ference on Learning Representations. 2016.
Nan Rosemary Ke, Amanpreet Singh, Ahmed Touati, Anirudh Goyal, Yoshua Bengio, Devi Parikh,
and Dhruv Batra. Modeling the long term future in model-based reinforcement learning. In
International Conference on Learning Representations, 2019.
Diederik P Kingma and Max Welling. Auto-encoding variational bayes. In International Conference
on Learning Representations. 2014.
Durk P Kingma and Prafulla Dhariwal. Glow: Generative flow with invertible 1x1 convolutions. In
Advances in Neural Information Processing Systems 31. 2018.
Durk P Kingma, Tim Salimans, Rafal Jozefowicz, Xi Chen, Ilya Sutskever, and Max Welling. Im-
proved variational inference with inverse autoregressive flow. In Advances in Neural Information
Processing Systems 29. 2016.
Thomas Kipf, Ethan Fetaya, Kuan-Chieh Wang, Max Welling, and Richard Zemel. Neural relational
inference for interacting systems. In Proceedings of the International Conference on Machine
Learning, 2018.
Vineet Kosaraju, Amir Sadeghian, Roberto Mardn-Martin, Ian Reid, S. Hamid Rezatofighi, and
Silvio Savarese. Social-bigat: Multimodal trajectory forecasting using bicycle-gan and graph
attention networks. In Advances in Neural Information Processing Systems 32. 2019.
Adam Kosiorek, Hyunjik Kim, Yee Whye Teh, and Ingmar Posner. Sequential attend, infer, repeat:
Generative modelling of moving objects. In Advances in Neural Information Processing Systems
31. 2018.
12
Published as a conference paper at ICLR 2020
Rahul G Krishnan, Uri Shalit, and David Sontag. Structured inference networks for nonlinear state
space models. In AAAI Conference on Artificial Intelligence, 2017.
Tuan Anh Le, Maximilian Igl, Tom Rainforth, Tom Jin, and Frank Wood. Auto-encoding sequential
monte carlo. In International Conference on Learning Representations, 2018.
Yaguang Li, Rose Yu, Cyrus Shahabi, and Yan Liu. Diffusion convolutional recurrent neural net-
work: Data-driven traffic forecasting. In International Conference on Learning Representations,
2018.
Yujia Li, Daniel Tarlow, Marc Brockschmidt, and Richard Zemel. Gated graph sequence neural
networks. International Conference on Learning Representations, 2016.
Yunzhu Li, Jiajun Wu, Russ Tedrake, Joshua B. Tenenbaum, and Antonio Torralba. Learning par-
ticle dynamics for manipulating rigid bodies, deformable objects, and fluids. In International
Conference on Learning Representations, 2019.
Jenny Liu, Aviral Kumar, Jimmy Ba, Jamie Kiros, and Kevin Swersky. Graph normalizing flows. In
Advances in Neural Information Processing Systems 32. 2019.
Chris J Maddison, John Lawson, George Tucker, Nicolas Heess, Mohammad Norouzi, Andriy Mnih,
Arnaud Doucet, and Yee Teh. Filtering variational objectives. In Advances in Neural Information
Processing Systems 30. 2017.
Joseph Marino, Milan Cvitkovic, and Yisong Yue. A general method for amortizing variational
filtering. In Advances in Neural Information Processing Systems 31. 2018.
Haggai Maron, Heli Ben-Hamu, Nadav Shamir, and Yaron Lipman. Invariant and equivariant graph
networks. In International Conference on Learning Representations, 2019.
Damian Mrowca, Chengxu Zhuang, Elias Wang, Nick Haber, Li F Fei-Fei, Josh Tenenbaum, and
Daniel L Yamins. Flexible neural representation for physics prediction. In Advances in Neural
Information Processing Systems 31. 2018.
C. A. Naesseth, F. Lindsten, and T. B. Schon. High-dimensional filtering using nested sequential
monte carlo. IEEE Transactions on Signal Processing, 67(16):4177-4188, 2019.
Christian Naesseth, Scott Linderman, Rajesh Ranganath, and David Blei. Variational sequential
monte carlo. In Proceedings of the International Conference on Artificial Intelligence and Statis-
tics, 2018.
Aaron van den Oord, Yazhe Li, and Oriol Vinyals. Representation learning with contrastive predic-
tive coding. arXiv preprint arXiv:1807.03748, 2018.
George Papamakarios, Theo Pavlakou, and Iain Murray. Masked autoregressive flow for density
estimation. In Advances in Neural Information Processing Systems 30. 2017.
Danilo Rezende and Shakir Mohamed. Variational inference with normalizing flows. In Proceedings
of the International Conference on Machine Learning, 2015.
Nicholas Rhinehart, Rowan McAllister, Kris Kitani, and Sergey Levine. Precog: Prediction condi-
tioned on goals in visual multi-agent settings. In The IEEE International Conference on Computer
Vision, 2019.
Alvaro Sanchez-Gonzalez, Nicolas Heess, Jost Tobias Springenberg, Josh Merel, Martin Riedmiller,
Raia Hadsell, and Peter Battaglia. Graph networks as learnable physics engines for inference and
control. In Proceedings of the International Conference on Machine Learning, 2018.
Franco Scarselli, Marco Gori, Ah Chung Tsoi, Markus Hagenbuchner, and Gabriele Monfardini.
The graph neural network model. IEEE Transactions on Neural Networks, 20(1):61-80, 2009.
Chen Sun, Per Karlsson, Jiajun Wu, Joshua B Tenenbaum, and Kevin Murphy. Stochastic prediction
of multi-agent interactions from partial observations. In International Conference on Learning
Representations, 2019.
13
Published as a conference paper at ICLR 2020
Ilya Sutskever, Oriol Vinyals, and Quoc V Le. Sequence to sequence learning with neural networks.
In Advances in Neural Information Processing Systems 27. 2014.
Andrea Tacchetti, H. Francis Song, Pedro A. M. Mediano, Vinicius Zambaldi, Jdnos Kramdr, Neil C.
Rabinowitz, Thore Graepel, Matthew Botvinick, and Peter W. Battaglia. Relational forward mod-
els for multi-agent learning. In International Conference on Learning Representations, 2019.
Yichuan Charlie Tang and Ruslan Salakhutdinov. Multiple futures prediction. In Advances in Neural
Information Processing Systems 32. 2019.
Sjoerd van Steenkiste, Michael Chang, Klaus Greff, and Jurgen Schmidhuber. Relational neural
expectation maximization: Unsupervised discovery of objects and their interactions. In Interna-
tional Conference on Learning Representations, 2018.
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez,
E ukasz Kaiser, and Illia Polosukhin. Attention is all you need. In Advances in Neural Infor-
mation Processing Systems 30. 2017.
Petar Velikovi, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lid, and Yoshua Ben-
gio. Graph attention networks. In International Conference on Learning Representations, 2018.
Nicholas Watters, Daniel Zoran, Theophane Weber, Peter Battaglia, Razvan Pascanu, and Andrea
Tacchetti. Visual interaction networks: Learning a physics simulator from video. In Advances in
Neural Information Processing Systems 30. 2017.
Keyulu Xu, Weihua Hu, Jure Leskovec, and Stefanie Jegelka. How powerful are graph neural
networks? In International Conference on Learning Representations, 2019.
Zhilin Yang, Zihang Dai, Ruslan Salakhutdinov, and William W. Cohen. Breaking the softmax
bottleneck: a high-rank RNN language model. In International Conference on Learning Repre-
sentations, 2018.
Raymond A. Yeh, Alexander G. Schwing, Jonathan Huang, and Kevin Murphy. Diverse generation
for multi-agent sports games. In Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition, 2019.
Eric Zhan, Stephan Zheng, Yisong Yue, Long Sha, and Patrick Lucey. Generating multi-agent
trajectories using programmatic weak supervision. In International Conference on Learning Rep-
resentations, 2019.
Jiani Zhang, Xingjian Shi, Junyuan Xie, Hao Ma, Irwin King, and Dit-Yan Yeung. Gaan: Gated
attention networks for learning on large and spatiotemporal graphs. In Conference on Uncertainty
in Artificial Intelligence, 2018.
Xun Zheng, Manzil Zaheer, Amr Ahmed, Yuan Wang, Eric P Xing, and Alexander J Smola. State
space lstm models with particle mcmc inference. arXiv preprint arXiv:1711.11179, 2017.
14
Published as a conference paper at ICLR 2020
A	Appendix
A. 1 MHA implementation
Each attention head k ∈ [K] is separately parameterized and operates as follows. For ∀(j, i) ∈ E,
it produces a message vector βjk→i together with an unnormalized scalar weight ωjk→i . Then for
∀i ∈ V, it aggregates all messages sent to i in a permutation-invariant manner:
{ap→i }p∈N- = softmax ({ωp→i }p∈N- ) , ai = Pp∈N- αp→iβp→i .
Putting all K heads together, it turns out that Mj→i = {(ωjk→i , βjk→i)}kK=1 and Ai = {aik}kK=1.
Specifically, each attention head is parameterized in a query-key-value style:
∀i ∈ V :	Vi = MLPV (Vi) ∈ Rdv , hi = [hi, Vi, g]
∙-v	∙-v	∙-v
Q = H W Q , A = H W A , C = H W C
βj→i = C j ,	ωj→i = q J aj / Pdq + MLPe(eji ) ∈ R
for d= d + dv + dg, WQ ∈ Rd×dq, WA ∈ Rd×dq, and WC ∈ Rd×dc.
A.2 Model details
In this work, the READOUT function is implemented by passing the concatenation of the outputs
of a mean aggregator and an element-wise max aggregator through a gated activation unit. The
transition densities in the generative model are specified to be:
fθ(Zg∣ht) = Normal(-∖μ3θ (ht),ςθ(ht)) ,	⑺
N
fθ(Zt∣Ht) = ∏Normal (Zti)∣μ? (h(i)) , ∑? ”))，	(8)
i=1
where μg and Σg (similarly μ and Σ?) are 3-layer MLPs that share their first layer. Σg and Σ?
output diagonal covariance matrices using the softplus activation. The proposal densities rφθ and rφ?
are specified in a similar way. Then GNFs can be stacked on top of fθ? and rφ? to make them more
expressive.
A.3 Experiments
We use the Adam optimizer with an initial learning rate of 0.001 and a gradient clipping of 1.0
for all experiments. The learning rate was annealed according to a linear cosine decay. We set
β1 = β2 = 1.0 for the auxiliary losses in all experiments.
Synthetic toy dataset. A typical example in the dataset is visualized in Figure 2. The architectures
of the models are specified as follows.
(a)	VRNN: Using 128-dimensional latent variables and a two-layer, 512-unit GRU.
(b)	GNN-AR: Using a two-layer GNN and an one-layer, 128-unit GRU shared by all nodes.
(c)	R-SSM: We let dg = dz = 8. All RNNs are specified to be two-layer, 32-unit LSTMs. All
MLPs use 64 hidden units. The generative model and the proposal both use a 4-head MHA
layer. 4 SMC samples and a batch size of 16 are used in training.
Basketball player movement. We let dg = dz = 32. All RNNs are specified to be two-layer, 64-
unit LSTMs and all MLPs use 256 hidden units. The generative model uses one 8-head MHA layer
and the proposal uses two 8-head MHA layers. Each GNF uses an additional MHA layer shared by
the functions S (∙) and t (∙ ).4 SMC samples and a batch size of 64 are used in training. Eight selected
rollouts from the trained model are visualized in Figure 3.
Road traffic. We let dg = dz = 8. A 32-dimensional embedding for each sensor is jointly learned
as a part of the vertex attribute. All RNNs are specified to be two-layer, 32-unit LSTMs and all
MLPs use 64 hidden units. The generative model and the proposal both use two 8-head MHA layers.
3 SMC samples and a batch size of 16 are used in training.
15
Published as a conference paper at ICLR 2020
rwπww [ww⅜w≡ rwττvnπ^
≡wwwm mZWWmIpfWrVWM≡ι≡≡
M⅜M⅛W k∕uw⅛≡ U√dUJ⅛κ l⅜WWW
WWoBJ⅛≡wt ⅛w≡o h≡≡≡⅝
A⅛MΠWV^ ⅛xΛ4JMM HWWWn uvwʌ^ɪ
ɪɪiu ⅛m⅛l^v nrrwɪ mMa≡≡
l⅜JUJ≡M UUmMllll LauMIILkWWWWM
rwrwrThM≡≡w [≡mm≡ kwnwu
IWTrnrɪ pnr^τArrIMM⅛4∕yj ⅛M⅛<g
Figure 2:	An example from the toy dataset (N = 36, T = 80).
Figure 3:	Selected rollouts from the trained model. Black dots represent the starting points.
16
Published as a conference paper at ICLR 2020
A.4 Training
We optimize the VSMC bound estimated by the following SMC algorithm:
Algorithm 1 Estimate the VSMC bound LSMC
Input: graph G, observations X1:T, exogenous inputs U1:T
Require: generative model {f, f? gθ }, proposal {rφ, rφ }, number of particles K
for k = 1 . . . K do
Simulate Zg卡〜rφ(∙∣G, Xi, Ui)
Simulate Zi,k 〜rφ(∙∣zg足 G, Xi, Ui)
S f k - fθ (z 1 ,k) fθ(ZI,k * 1 zg,k，G UI)QN=ι gθ(x1" 1z1：k>z1,k,…)
Set 吗=	rg(zi-k\：:?)r?(zi：k\：:^
end for
Initialize LSMC = log PK=I Wk∕κ
for t = 2 . . . T do
{zg<t,k, Z<t,k}kK=i = RESAMPLE({zg<t,k, Z<t,k, wtk-i}kK=i)
for k = 1 . . . K do
Simulate Zg 卜〜rφ(∙∣z< 卜,Z‹t,k, G, X≤t, U≤t)
Simulate Z；k 〜rφ(∙∣z§…,Z</,G, X≤t, U≤)
fθ(Zzt,k\…)fθ(Zt,k\Z≤t,k,Z<t,k,…) QN=I gθ(Xt)\z(,k,Z≤t,k,Z<t,k,…)
rg(z g,k∖---) rφ(Z t,k\---)
Set wtk
Set zg≤t,k = (zg<t,k, ztg,k), Z≤t,k = (Z<t,k, Zt,k)
end for
Update LSMC = LSMC + log PK=i WtlK
end for
Output: LSMC
In our model, dependencies on zg<t,k and Z<t,k are provided through the compact RNN states htg,k
and Ht,k. When GNFs are used in fθ? and rφ?, density calculation and backpropagation are automat-
ically handled by the TensorFlow Probability library.
To estimate the auxiliary objectives Laiux and La2ux, we reuse the resampled unweighted particles
{{zig:t,k, Zi:t,k}kK=i}tT=-ii generated by Algorithm 1 to form Monte Carlo estimations for them:
LTx = χiX⅛ιθgPMi(λti：：)), L2ux = χiXKlogpλ2(h(ti)
t =i i =i	∑c ∈ Ω t,i λψ,i(Z t,k, c)	t =i i =i	∑c ∈ Ω t,i λψ, 2(h t,k, C)
wherez (k = [z g,k, z ((Ii], h h(ik =MLP ψ(P j=i ∧ j∈N- h (jk),and ω t,i 协阳山凯丽血现 Ci and
some negative samples selected from the future summaries of other vertices within the minibatch.
17
Published as a conference paper at ICLR 2020
A.5 Graph Normalizing Flow
Za ∈ m×d
3h
Zb ∈ ^N×(D-d)
element-wise
multiplication
element-wise
addition
ZiOy + β
element-wise
affine layer
Z ∈ rn×d
invertible
conv1x1 layer
W ∈ 脓D×D
r^1-rB)LC)6-QE

Figure 4:	Visual illustration of a GNF. Multiple GNFs can be stacked together to achieve more
expressive transformation.
The element-wise affine layer is proposed by Kingma & Dhariwal (2018) for normalizing the activa-
tions. Its parameters Y ∈ RD and β ∈ RD are initialized such that the per-channel activations have
roughly zero mean and unit variance at the beginning of training. The invertible linear transforma-
tion W ∈ RD × D is parameterized using a QR decomposition (Hoogeboom et al., 2019).
18