Published as a conference paper at ICLR 2020
Weakly Supervised Clustering by Exploiting
Unique Class Count
Mustafa Umit Oner1,2, Hwee Kuan Lee1,2,3,4 & Wing-Kin Sung1,5
1School of Computing, National University of Singapore, Singapore 117417, 2A*STAR
Bioinformatics Institute, Singapore 138671, 3Image and Pervasive Access Lab (IPAL),
CNRS UMI 2955, Singapore 138632, 4Singapore Eye Research Institute, Singapore
169856, 5A*STAR Genome Institute of Singapore, Singapore 138672
{umitoner,ksung}@comp.nus.edu.sg, {leehk}@bii.a-star.edu.sg
Ab stract
A weakly supervised learning based clustering framework is proposed in this pa-
per. As the core of this framework, we introduce a novel multiple instance learning
task based on abag level label called unique class count (ucc), which is the number
of unique classes among all instances inside the bag. In this task, no annotations
on individual instances inside the bag are needed during training of the models.
We mathematically prove that with a perfect ucc classifier, perfect clustering of
individual instances inside the bags is possible even when no annotations on indi-
vidual instances are given during training. We have constructed a neural network
based ucc classifier and experimentally shown that the clustering performance of
our framework with our weakly supervised ucc classifier is comparable to that of
fully supervised learning models where labels for all instances are known. Fur-
thermore, we have tested the applicability of our framework to a real world task
of semantic segmentation of breast cancer metastases in histological lymph node
sections and shown that the performance of our weakly supervised framework is
comparable to the performance of a fully supervised Unet model.
1	Introduction
In machine learning, there are two main learning tasks on two ends of scale bar: unsupervised
learning and supervised learning. Generally, performance of supervised models is better than that
of unsupervised models since the mapping between data and associated labels is provided explicitly
in supervised learning. This performance advantage of supervised learning requires a lot of labelled
data, which is expensive. Any other learning tasks reside in between these two tasks, so are their
performances. Weakly supervised learning is an example of such tasks. There are three types of
supervision in weakly supervised learning: incomplete, inexact and inaccurate supervision. Multiple
instance learning (MIL) is a special type of weakly supervised learning and a typical example of
inexact supervision (Zhou, 2017). In MIL, data consists of bags of instances and their corresponding
bag level labels. Although the labels are somehow related to instances inside the bags, the instances
are not explicitly labeled. In traditional MIL, given the bags and corresponding bag level labels,
task is to learn the mapping between bags and labels while the goal is to predict labels of unseen
bags (Dietterich et al., 1997; Foulds & Frank, 2010).
In this paper, we explore the feasibility of finding out labels of individual instances inside the bags
only given the bag level labels, i.e. there is no individual instance level labels. One important
application of this task is semantic segmentation of breast cancer metastases in histological lymph
node sections, which is a crucial step in staging of breast cancer (Brierley et al., 2016). In this
task, each pathology image of a lymph node section is a bag and each pixel inside that image is an
instance. Then, given the bag level label that whether the image contains metastases or not, the task
is to label each pixel as either metastases or normal. This task can be achieved by asking experts
to exhaustively annotate each metastases region in each image. However, this exhaustive annotation
process is tedious, time consuming and more importantly not a part of clinical workflow.
1
Published as a conference paper at ICLR 2020
Output is predicted ucc label.
UCC model tries to minimize loss
between truth ucc labels and
Input is a bag containing n instances
ofk di∩erent classes of objects, i.e. a
bag with ucc-k. Individual instance
labels are unknown.
predicted ucc labels during training.
Given bags and
corresponding bag level ucc
labels, UCC model Ieams to
predict ucc of unseen bags.
Trained UCC model is used as a feature extractor and
unsupervised clustering is performed on extracted
features of individual instances inside the bag.
Figure 1: Weakly supervised clustering framework. Our framework (green dashed line) consists of
the U CC model (magenta dashed line) and the unsupervised instance clustering branch.
In many complex systems, such as in many types of cancers, measurements can only be obtained
at coarse level (bag level), but information at fine level (individual instance level) is of paramount
importance. To achieve this, we propose a weakly supervised learning based clustering framework.
Given a dataset consisting of instances with unknown labels, our ultimate objective is to cluster the
instances in this dataset. To achieve this objective, we introduce a novel MIL task based on a new
kind of bag level label called unique class count (ucc), which is the number of unique classes or the
number of clusters among all the instances inside the bag. We organize the dataset into non-empty
bags, where each bag is a subset of individual instances from this dataset. Each bag is associated
with a bag level ucc label. Then, our MIL task is to learn mapping between the bags and their
associated bag level ucc labels and then to predict the ucc labels of unseen bags. We mathematically
show that a ucc classifier trained on this task can be used to perform unsupervised clustering on
individual instances in the dataset. Intuitively, for a ucc classifier to count the number of unique
classes in a bag, it has to first learn discriminant features for underlying classes. Then, it can group
the features obtained from the bag and count the number of groups, so the number of unique classes.
Our weakly supervised clustering framework is illustrated in Figure 1. It consists of a neural net-
work based ucc classifier, which is called as Unique Class Count (UCC) model, and an unsuper-
vised clustering branch. The UCC model accepts any bag of instances as input and uses ucc labels
for supervised training. Then, the trained UCC model is used as a feature extractor and unsuper-
vised clustering is performed on the extracted features of individual instances inside the bags in the
clustering branch. One application of our framework is the semantic segmentation of breast can-
cer metastases in lymph node sections (see Figure 4). The problem can be formulated as follows.
The input is a set of images. Each image (bag) has a label of ucc1 (image is fully normal or fully
metastases) or ucc2 (image is a mixture of normal and metastases). Our aim is to segment the pixels
(instances) in the image into normal and metastases. A UCC model can be trained to predict ucc
labels of individual images in a fully supervised manner; and the trained model can be used to ex-
tract features of pixels (intances) inside the images (bags). Then, semantic segmentation masks can
be obtained by unsupervised clustering of the pixels (each is represented by the extracted features)
into two clusters (metastases or normal). Note that ucc does not directly provide an exact label for
each individual instance. Therefore, our framework is a weakly supervised clustering framework.
Finally, we have constructed ucc classifiers and experimentally shown that clustering performance
of our framework with our ucc classifiers is better than the performance of unsupervised models
and comparable to performance of fully supervised learning models. We have also tested the per-
formance of our model on the real world task of semantic segmentation of breast cancer metastases
in lymph node sections. We have compared the performance of our model with the performance
of popular medical image segmentation architecture of Unet (Ronneberger et al., 2015) and shown
that our weakly supervised model approximates the performance of fully supervised Unet model1.
Hence, there are three main contributions of this paper:
1.	We have defined unique class count as a bag level label in MIL setup and mathematically
proved that a perfect ucc classifier, in principle, can be used to perfectly cluster the indi-
vidual instances inside the bags.
1 Code and trained models: http://bit.ly/uniqueclasscount
2
Published as a conference paper at ICLR 2020
2.	We have constructed a neural network based ucc classifier by incorporating kernel density
estimation (KDE) (Parzen, 1962) as a layer into our model architecture, which provided us
with end-to-end training capability.
3.	We have experimentally shown that clustering performance of our framework is better than
the performance of unsupervised models and comparable to performance of fully super-
vised learning models.
The rest of the paper is organized such that related work is in Section 2, details of our weakly
supervised clustering framework are in Section 3, results of the experiments on MNIST, CIFAR10
and CIFAR100 datasets are in Section 4, results of the experiments in semantic segmentation of
breast cancer metastases are in Section 5, and Section 6 concludes the paper.
2	Related Work
This work is partly related to MIL which was first introduced in (Dietterich et al., 1997) for drug
activity prediction. Different types of MIL were derived with different assumptions (Gartner et al.,
2002; Zhang & Goldman, 2002; Chen et al., 2006; Foulds, 2008; Zhang & Zhou, 2009; Zhou et al.,
2009), which are reviewed in detail in (Foulds & Frank, 2010), and they were used for many different
applications such as, image annotation/categorization/retrieval (Chen & Wang, 2004; Zhang et al.,
2002; Tang et al., 2010), text categorization (Andrews et al., 2003; Settles et al., 2008), spam detec-
tion (Jorgensen et al., 2008), medical diagnosis (Dundar et al., 2007), face/object detection (Zhang
et al., 2006; Felzenszwalb et al., 2010) and object tracking (Babenko et al., 2011).
In MIL, different types of pooling layers are used to combine extracted features of instances inside
the bags, such as max-pooling and log-sum-exp pooling (Ramon & De Raedt, 2000; Zhou & Zhang,
2002; Wu et al., 2015; Wang et al., 2018). On the other hand, our UCC model uses KDE layer in
order to estimate the distribution of extracted features. The advantage of KDE over pooling layers
is that it embeds the instance level features into distribution space rather than summarizing them.
There are also methods modeling cardinality and set distributions (Liu et al., 2015; Brukhim &
Globerson, 2018; Kipf et al., 2018). However, cardinality of a set and ucc are completely different
from each other. It is also important to state that ucc is obviously different from object/crowd count-
ing (Idrees et al., 2013; Arteta et al., 2014; Zhang et al., 2015; 2016) since the task in object/crowd
counting is to count the instances of the same type of object or people.
Lastly, we compare clustering accuracies of our models with clustering accuracies of unsupervised
baseline models: K-means (Wang et al., 2015) and Spectral Clustering (Zelnik-Manor & Perona,
2005); state of the art unsupervised models: JULE (Yang et al., 2016), GMVAE (Dilokthanakul
et al., 2016), DAC (Chang et al., 2017), DEPICT (Ghasedi Dizaji et al., 2017) and DEC (Xie et al.,
2016); and state of the art semi-supervised models: AAE (Makhzani et al., 2015), CatGAN (Sprin-
genberg, 2015), LN (Rasmus et al., 2015) and ADGM (Maal0e et al., 2016).
3	Weakly Supervised Clustering Framework
In this section, we state our machine learning objective and formally define our novel MIL task,
which is the core of our weakly supervised clustering framework. Finally, we explain details of the
two main components of our framework, namely UCC model and unsupervised clustering branch.
Objective: Let X = {χ1,χ2,…，Xn} be a dataset such that each instance Xi ∈ X belongs
to a class, but its label is unknown. In this paper, we assume that total number of classes K is
known. Hence, each instance xi is endowed with an underlying, but unkown, label L(xi) = li ∈
{1,2,…，K}. Further assume that for each class k ∈ {1, 2,…K}, there exist at least one element
xi ∈ X such that L(xi) = li = k. Our eventual objective is to derive a predicted class label li for
each instance xi that tends towards underlying truth class li, i.e. li → L(xi) = li .
3.1	A NOVEL MIL TASK
In this novel MIL task, unique class count is used as an inexact, weak, bag level label and is defined
in Definition 1. Assume that We are given subsets σζ ⊂ X, Z = 1,2,…，N and unique class counts
3
Published as a conference paper at ICLR 2020
ησζ∀σζ. Hence, MIL dataset is D = {(σι,ησj, ∙∙∙ , (σN,ησN)}. Then, our MIL task is to learn
the mapping between the bags and their associated bag level ucc labels while the goal is to predict
the ucc labels of unseen bags.
Definition 1 Given a subset σζ ⊂ X, unique class count, ησζ, is defined as the number of unique
classes that all instances in the subset σζ belong to, i.e. %4=∣{L(xi)∣Xi ∈ q&}|. Recall that each
instance belongs to an underlying unknown class.
Given a dataset D, our eventual objective is to assign a label to each instance xi ∈ X such that
assigned labels and underlying unknown classes are consistent. To achieve this eventual objective,
a deep learning model is designed such that the following intermediate objectives can be achieved
while it is being trained on our MIL task:
1.	Unique class count: Given an unseen set σζ, the deep learning model, which is trained on
D, can predict its unique class count ησζ correctly.
2.	Labels on sets: Let σζpure and σξpure be two disjoint pure sets (Definition 2) such that
while all instances in σζpure belong to one underlying class, all instances in σξpure belong
to another class. Given σζpure and σξpure, the deep learning model should enable us to
develop an unsupervised learning model to label instances in σζpure and σξpure as belonging
to different classes. Note that the underlying classes for instances in the sets are unknown.
3.	Labels on instances: Given individual instances xi ∈ X, the deep learning model should
enable us to assign a label to each individual instance xi such that all instances with dif-
ferent/same underlying unknown classes are assigned different/same labels. This is the
eventual unsupervised learning objective.
Definition 2 A set σ is called a pure set if its unique class count equals one. All pure sets is denoted
by the symbol σpure in this paper.
3.2	Unique Class Count Model
In order to achieve the stated objectives, we have designed a deep learning based Unique Class Count
(UCC) model. Our UCC model consists of three neural network modules (θfeature, θdrn, θdecoder) and
can be trained end-to-end. The first module θfeature extracts features from individual instances; then
distributions of features are constructed from extracted features. The second module θdrn is used to
predict ucc label from these distributions. The last module θdecoder is used to construct an autoencoder
together with θfeature soas to improve the extracted features by ensuring that extracted features contain
semantic information for reconstruction.
Formally, for Xi ∈ σζ, i = {1,2, ∙∙∙ , ∣σζ |}, feature extractor module θfeature extracts J features
{fσ,i, fσ,i,…，fJ,i} = θfeatUre(Xi) for each instance Xi ∈ σζ. As a short hand, We write the operator
θfeature as operating element wise on the set to generate a feature matrix θfeature(σζ) = fσζ with matrix
elements fσj,i ∈ R, representing the jth feature of the ith instance. After obtaining features for all
instances in σζ, a kernel density estimation (KDE) module is used to accumulate feature distribu-
tions hσζ = (h34(v), haζ (v),…,hjc (v)). Then, hσζ is used as input to distribution regression
module θdra to predict the Ucc label,脑《=θdrn(hσζ) as a softmax vector (心,宿《,… 愁4).Con-
currently, decoder module θdecoder in autoencoder branch is used to reconstruct the input images from
the extracted features in an unsupervised fashion, Xi = θdecoder(θfeature(xi)). Hence, UCC model,
main modules of which are illustrated in Figure 2(a), optimizes two losses concurrently: ‘ucc loss’
and ‘autoencoder loss’. While ‘ucc loss’ is cross-entropy loss, ‘autoencoder loss’ is mean square
error loss. Loss for one bag is given in Equation 1.
α
K
X ηkζ log ηki
k=1
+ (1 - α)
autoencoder loss
where α ∈ [0, 1]
(1)
'-----------V-----------}
ucc loss
4
Published as a conference paper at ICLR 2020
Figure 2: Weakly supervised clustering framework. (a) UCC model: θfeature extracts J features,
shown in colored nodes. KDE module obtains feature distribution for each feature. Then, θdrn pre-
diets the ucc label 诅∙ Concurrently, decoder module θde∞der in autoencoder branch reconstructs the
input images from the extracted features. (b) Unsupervised clustering: Trained feature extractor,
fture, is USed to extract the features of all instances in X and unsupervised clustering is performed
on extracted features. Note that li is clustering label of xi ∈ X.
3.2.1	Kernel Density Estimation Module
In UCC model, input is a set σς and output is corresponding UCC label 诅,which does not de-
pend on permutation of the instances in σζ. KDE module provides UCC model with permutation-
invariant property. Moreover, KDE module uses the Gaussian kernel and it is differentiable, so our
model can be trained end-to-end (Appendix A). KDE module also enables our theoretical analysis
thanks to its decomposability property (Appendix B). Lastly, KDE module estimates the probability
distribution of extracted features and enables θdrn to fully utilize the information in the shape of the
distribution rather than looking at point estimates of distribution obtained by other types of pooling
layers (Ramon & De Raedt, 2000; Zhou & Zhang, 2002; Wang et al., 2018) (Appendix C.6).
3.2.2	Properties of Unique Class Count Model
This section mathematically proves that the UCC model guarantees, in principle, to achieve the
stated intermediate objectives in Section 3.1. Proof of propositions are given in Appendix B.
ProPosition 1 Let σζ, σξ be disjoint subsets of X with predicted unique class COUntS %《 =力。,=L
Ifthe predicted unique class count of。” = σζ ∪ σξ is ησν = 2, then hσ< = hσξ.
Definition 3 A perfect unique class count classifier takes in any set σ and output the correct pre-
dicted unique class count ησ = ησ.
ProPosition 2 Given a perfect unique class count classifier. The dataset X can be perfectly clus-
tered into K subsets σpure, ξ = 1, 2,…,K, such that X = Uξ=ι σpure and σpure = {x,∣Xi ∈
X, L(xi) = ξ}.
ProPosition 3 Given a perfect unique class count classifier. Decompose the dataset X into K
subsets σξure, ξ = 1,…K, such that σξure = {x/x, ∈ X, L(Xi) = ξ}. Then, h.re = hσpure for
ξ 6= ζ.	ξ	ζ
Suppose we have a perfect ucc classifier. For any two pure sets σζpure and σξpure, which consist of
instances of two different underlying classes, ucc labels must be predicted correctly by the perfect
ucc classifier. Hence, the conditions of Proposition 1 are satisfied, so we have hσpure 6= hσpure.
Therefore, we can, in principle, perform an unsupervised clustering on the distributions of the sets
without knowing the underlying truth classes of the instances. Hence, the perfect ucc classifier en-
ables us to achieve our intermediate objective of “Labels on sets”. Furthermore, given a perfect
ucc classifier, Proposition 2 states that by performing predictions of ucc labels alone, without any
5
Published as a conference paper at ICLR 2020
knowledge of underlying truth classes for instances, one can in principle perform perfect cluster-
ing for individual instances. Hence, a perfect ucc classifier enables us to achieve our intermediate
objective of “Labels on instances”.
3.3	Unsupervised Instance Clustering
In order to achieve our ultimate objective of developing an unsupervised learning model for cluster-
ing all the instances in dataset X, we add this unsupervised clustering branch into our framework.
Theoreticallly, we have shown in Proposition 3 that given a perfect ucc classifier, distributions of
pure subsets of instances coming from different underlying classes are different.
In practice, it may not be always possible (probably most of the times) to train a perfect ucc classifier,
so we try to approximate it. First of all, we train our ucc classifier on our novel MIL task and save
our trained model (feature, ⅛rn, decoder). Then, We use trained feature extractor feature to obtain feature
matrix fχ = &eatUre(X). Finally, extracted features are clustered in an unsupervised fashion, by using
simple k-means and spectral clustering methods. Figure 2(b) illustrates the unsupervised clustering
process in our framework. A good feature extractor HfeatUre is of paramount importance in this task.
Relatively poor HfeatUre may result in a poor unsupervised clustering performance in practice even if
we have a strong θHdrn. To obtain a strong θHfeature, we employ an autoencoder branch, so as to achieve
high clustering performance in our unsupervised instance clustering task. The autoencoder branch
ensures that features extracted by θHfeature contain semantic information for reconstruction.
4	Experiments on MNIST and CIFAR Datasets
This section analyzes the performances of our UCC models and fully supervised models in terms
of our eventual objective of unsupervised instance clustering on MNIST (10 clusters) (LeCun et al.,
1998), CIFAR10 (10 clusters) and CIFAR100 (20 clusters) datasets (Krizhevsky & Hinton, 2009).
4.1	Model Architectures and Datasets
To analyze different characteristics of our framework, different kinds of unique class count models
were trained during our experiments: UCC, UCC2+, UCCα=1 and UCCα2+=1. These unique class
count models took sets of instances as inputs and were trained on ucc labels. While UCC and
U C C 2+ models had autoencoder branch in their architecture and they were optimized jointly over
both autoencoder loss and ucc loss, UCCα=1 and UCCα2+=1 models did not have autoencoder branch
in their architecture and they were optimized over ucc loss only (i.e. α = 1 in Equation 1). The aim
of training unique class count models with and without autoencoder branch was to show the effect
of autoencoder branch in the robustness of clustering performance with respect to ucc classification
performance. UCC and UCCα=1 models were trained on bags with labels of ucc1 to ucc4. On
the other hand, UCC2+ and UCCα2+=1 models were trained on bags with labels ucc2 to ucc4. Our
models were trained on ucc labels up to ucc4 instead of ucc10 (ucc20 in CIFAR100) since the
performance was almost the same for both cases and training with ucc1 to ucc4 was much faster
(Appendix C.2). Please note that for perfect clustering of instances inside the bags, it is enough to
have a perfect ucc classifier that can perfectly discriminate ucc1 and ucc2 bags from Proposition 2.
The aim of traininig U CC2+ and U CCα2+=1 models was to experimentally check whether these
models can perform as good as UCC and UCCα=1 models even if there is no pure subsets during
training. In addition to our unique class count models, for benchmarking purposes, we also trained
fully supervised models, F ullySupervised, and unsupervised autoencoder models, Autoencoder.
F ullySupervised models took individual instances as inputs and used instance level ground truths
as labels during training. On the other hand, Autoencoder models were trained in an unsupervised
manner by optimizing autoencoder loss (i.e. α = 0 in Equation 1). It is important to note that all
models for a dataset shared the same architecture for feature extractor module and all the modules in
our models are fine tuned for optimum performance and training time as explained in Appendix C.1.
We trained and tested our models on MNIST, CIFAR10 and CIFAR100 datasets. We have Xmnist,tr,
Xmnist,val and Xmnist,test for MNIST; Xcifar10,tr, Xcifar10,val and Xcifar10,test for CIFAR10; and
Xcif ar100,tr, Xcifar100,val and Xcif ar100,test for CIFAR100. Note that tr, val and test subscripts
stand for ‘training’, ‘validation’ and ‘test’ sets, respectively. All the results presented in this paper
were obtained on hold-out test sets Xmnist,test, Xcif ar10,test and Xcif ar100,test . F ullySupervised
6
Published as a conference paper at ICLR 2020
Table 1: Minimum inter-class JS divergence values, ucc classification accuracy values and clustering
accuracy values of our models (first part), baseline and state of the art unsupervised models (second
part) and state of the art semi-supervised models (third part) on different test datasets. The best
clustering accuracy values for each kind of models (weakly supervised (our models), unsupervised,
semi-supervised) are highlighted in bold. (‘x’: not applicable, ‘-’: missing’)
	min. JS divergence			ucc acc.			clustering acc.		
	mnist	cifar10	cifar100	mnist	cifar10	cifar100	mnist	cifar10	cifar100
UCC	0.222	0.097	0.004	TW	0.972	0.824	≡τ	0.781	0.338
UCC 2+	0.251	0.005	0.002	TW	0.936	0.814	0.98T	0.545	0.278
UCCa=I	0.221	0.127	0.003	ɪw	0.982	0.855	^098Γ	0.774	0.317
UCCa=I	一	0.023	0.002	0.003	0.996	0.920	0.837	0.881	0.521	0.284
AUtoencoder	0.101	0.004	0.002	X	X	X	0.930-	0.241	0.167
FullySupervised	0.283	0.065	0.019	X	X	X	0.988-	0.833	0.563
JULE (Yang et al., 2016)							0.964-	0.272	0.137
GMVAE (DilokthanakUl et al., 2016)	一							0.885"	-	-
DAC (Chang et al.,	2017)*						0.978"	0.522	0.238
DEC (Xie etal., 2016)*							0.843-	0.301	0.185
DEPICT (GhaSedi Dizaji et al., 2017)*	一							0.965"	-	-
Spectral (Zelnik-Manor & Perona, 2005)							0.696-	0.247	0.136
K-means (Wang et al., 2015)							0.572-	0.229	0.130
ADGM (Maal0e et al., 2016)	二							TW	-	-
Ladder Networks (Rasmus et al., 2015)							0.989"	0.796	-
AAE (Makhzani et al., 2015)							■098T	-	-
CatGAN (SPringenberg, 2015)	一							0.98T	0.804	-
* Models do not separate training and testing data, i.e. their results are not on hold-out test sets.
models took individual instances as inputs and were trained on instance level ground truths. Unique
class count models took sets of instances as inputs, which were sampled from the power sets
2Xmnist,tr, 2Xcif ar10,tr and 2Xcifar100,tr, and were trained on ucc labels (Appendix C.2). While all
the models were trained in a supervised setup, either on ucc labels or instance level ground truths,
all of them were used to extract features for unsupervised clustering of individual instances.
4.2	Unique Class Count Prediction
Preceeding sections showed, in theory, that a perfect ucc classifier can perform ‘weakly’ super-
vised clustering perfectly. We evaluate ucc prediction accuracy of our unique class count models
in accordance with our first intermediate objective that unique class count models should predict
ucc labels of unseen subsets correctly. We randomly sampled subsets for each ucc label from the
power sets of test sets and predicted the ucc labels by using trained models. Then, we calculated the
ucc prediction accuracies by using predicted and truth ucc labels, which are summarized in Table 1
(Appendix C.3). We observed that as the task becomes harder (from MNIST to CIFAR100), it also
becomes harder to approximate the perfect ucc classifier. Moreover, UCC and UCCα=1 models,
in general, have higher scores than their counterpart models of UCC2+ and UCCα2+=1, which is ex-
pected since the ucc prediction task becomes easier at the absence of pure sets and models reach to
early stopping condition (Appendix C.1) more easily. This is also supported by annother interesting,
yet reasonable, observation that UCC2+ models have higher ucc accuracies than UCCα2+=1 models
thanks to the autoencoder branch which makes UCC2+ harder to reach to early stopping condition.
4.3	Labels on Sets
Jensen-Shannon (JS) divergence (Lin, 1991) value between feature distributions of two pure sets
consisting of instances of two different underlying classes is defined as inter-class JS divergence in
this paper and used for comparison on ‘Labels on sets’ objective of assigning labels to pure sets.
Higher values of inter-class JS divergence are desired since it means that feature distributions of
7
Published as a conference paper at ICLR 2020
K-means
Spectral
0.5	0.6	0.7	0.8	0.9	1.0
ucc accuracy
5 0 5 0 5
3 3 2 2 1
SO.O.0.。
XJBJnUUB 6u∙c⅛snu
0.4	0.5	0.6	0.7	0.8
ucc accuracy
Figure 3:	Clustering accuracy vs ucc accuracy plots of UCC and UCCα=1 models together with
k-means and spectral clustering accuracy baselines on MNIST, CIFAR10 and CIFAR100 datasets.
pure sets of underlying classes are far apart from each other. The features of all the instances in a
particular class are extracted by using a trained model and feature distributions associated to that
class obtained by performing kernel density estimation on these extracted features. Then, for each
pair of classes, inter-class JS divergence values are calculated (Appendix C.4). For a particular
model, which is used in feature extraction, the minimum of these pairwise inter-class JS divergence
values is used as a metric in the comparison of models. We have observed that as the task gets
more challenging and the number of clusters increases, there is a drop in minimum inter-class JS
divergence values, which is summarized in Table 1.
4.4 Labels on Instances
For our eventual objective of ‘Labels on instances’, we have used ‘clustering accuracy’ as a compar-
ison metric, which is calculated similar to Ghasedi Dizaji et al. (2017). By using our trained models,
we extracted features of individual instances of all classes in test sets. Then, we performed unsuper-
vised clustering over these features by using k-means and spectral clustering. We used number of
classes in ground truth as number of clusters (MNIST: 10, CIFAR10: 10, CIFAR100: 20 clusters)
during clustering and gave the best clustering accuracy for each model in Table 1 (Appendix C.5).
In Table 1, we compare clustering accuracies of our models together with baseline and state of the
art models in the literature: baseline unsupervised (K-means (Wang et al., 2015), Spectral Clus-
tering (Zelnik-Manor & Perona, 2005)); state of the art unsupervised (JULE (Yang et al., 2016),
GMVAE (Dilokthanakul et al., 2016), DAC (Chang et al., 2017), DEPICT (Ghasedi Dizaji et al.,
2017), DEC (Xie et al., 2016)) and state of the art semi-supervised (AAE (Makhzani et al., 2015),
CatGAN (SPringenberg, 2015), LN (Rasmus et al., 2015), ADGM (Maal0e et al., 2016)). Clustering
performance of our unique class count models is better than the performance of unsupervised models
in all datasets and comParable to Performance of fully suPervised learning models in MNIST and CI-
FAR10 datasets. The Performance gaP gets larger in CIFAR100 dataset as the task becomes harder.
Although semi-suPervised methods use some Part of the dataset with ‘exact’ labels during training,
our models Perform on Par with AAE and CatGAN models and comParable to LN and ADGM
models on MNIST dataset. ADGM and LN even reach to the Performance of the F ullySupervised
model since they exPloit training with ‘exact’ labeled data. On CIFAR10 dataset, LN and CatGAN
models are slightly better than our unique class count models; however, they use 10% of instances
with ‘exact’ labels, which is not a small Portion.
In general, our UCC and UCCα=1 models have similar Performance, and they are better than their
counterPart models of UCC2+ and U C Cα2+=1 due to the absence of Pure sets during training. How-
ever, in the real world tasks, the absence of Pure sets heavily dePends on the nature of the Problem.
In our task of semantic segmentation of breast cancer metastases in histological lymPh node sec-
tions, for examPle, there are many Pure sets. Furthermore, we observed that there is a Performance
gaP between UCC2+ and UCCα2+=1 models: UCC2+ models Perform better than UCCα2+=1 models
thanks to the autoencoder branch. The effect of autoencoder branch is also aPParent in Figure 3,
which shows clustering accuracy vs ucc accuracy curves for different datasets. For MNIST dataset,
while UCC model gives clustering accuracy values ProPortional to ucc accuracy, UCCα=1 model
cannot reach to high clustering accuracy values until it reaches to high ucc accuracies. The reason
is that autoencoder branch in UCC helPs θfeature module to extract better features during the initial
Phases of the training Process, where the ucc classification accuracy is low. ComPared to other
8
Published as a conference paper at ICLR 2020
① 6PUJ- XSeIλ∣ XSBIAl
IndU- £mj_ P ①一。-P ①D:
Puno」。
〃ccl (normal)
XSBIAl XSelλ∣
P ①一。一 P ①D:P ①一。一 P ①d:
SailfI SUB ① E
UCC2 (boundary) IICC2 (boundary)
Figure 4:	Example images from hold-out test dataset with corresponding ucc
ground truth
masks and predicted masks by U CCsegment, Unet and K-means clustering models.
datasets, this effect is more significant in MNIST dataset since itself is clusterable. Although au-
toencoder branch helps in CIFAR10 and CIFAR100 datasets as well, improvements in clustering
accuracy coming from autoencoder branch seems to be limited, so two models UCC and UCCα=1
follow nearly the same trend in the plots. The reason is that CIFAR10 and CIFAR100 datasets are
more complex than MNIST dataset, so autoencoder is not powerful enough to contribute to extract
discrimant features, which is also confirmed by the limited improvements of Autoencoder models
over baseline performance in these datasets.
5 Semantic Segmentation of Breast Cancer Metastases
Semantic segmentation of breast cancer metastases in histological lymph node sections is a cru-
cial step in staging of breast cancer, which is the major determinant of the treatment and progno-
sis (Brierley et al., 2016). Given the images of lymph node sections, the task is to detect and locate,
i.e. semantically segment out, metastases regions in the images. We have formulated this task in
our novel MIL framework such that each image is treated as a bag and corresponding ucc label is
obtained based on whether the image is from fully normal or metastases region, which is labeled
by ucc1, or from boundary region (i.e. image with both normal and metastases regions), which is
labeled by ucc2. We have shown that this segmentation task can be achieved by using our weakly
supervised clustering framework without knowing the ground truth metastases region masks of im-
ages, which require experts to exhaustively annotate each metastases region in each image. This
annotation process is tedious, time consuming and more importantly not a part of clinical workflow.
We have used 512 × 512 image crops from publicly available CAMELYON dataset (Litjens et al.,
2018) and constructed our bags by using 32 × 32 patches over these images. We trained our unique
class count model U C Csegment on ucc labels. Then, we used the trained model as a feature ex-
tractor and conducted unsupervised clustering over the patches of the images in the hold-out test
dataset to obtain semantic segmentation masks. For benchmarking purposes, we have also trained a
fully supervised Unet model (Ronneberger et al., 2015), which is a well-known biomedical image
segmentation architecture, by using the ground truth masks and predicted the segmentation maps in
9
Published as a conference paper at ICLR 2020
Table 2: Semantic segmentation performance statistics of U CCsegment, Unet and K-means clus-
tering methods on hold-out test dataset.
TPR	FPR	TNR	FNR	PA
UCCsegment(WeaklysUPervised)	0.818	0.149	0.851	0.182	0.863
Unet (fullysupervised)	0.860	0.126	0.874	0.140	0.889^
K-means (unsupervised baseline)	0.370	0.271	0.729	0.630	0.512
the test set. The aim of this comparison Was to shoW that at the absence of ground truth masks, our
model can approximate the performance of a fully supervised model. Moreover, We have obtained
semantic segmentation maps in the test dataset by using k-means clustering as a baseline study. Ex-
ample images from test dataset With corresponding ground truth masks, ucc labels and predicted
masks by different models are shoWn in Figure 4. (Please see Appendix D.1 for more details.)
Furthermore, We have calculated pixel level gross statistics of TPR (True Positive Rate), FPR (False
Positive Rate), TNR (True Negative Rate), FNR (False Negative Rate) and PA (Pixel Accuracy)
over the images of hold-out test dataset and declared the mean values in Table 2 (Appendix D.2).
When We look at the performance of unsupervised baseline method of K-means clustering, it is
obvious that semantic segmentation of metastases regions in lymph node sections is not an easy
task. Baseline method achieves a very loW TPR value of 0.370 and almost random score of 0.512
in PA. On the other hand, both our Weakly supervised model U C Csegment and fully supervised
model Unet outperform the baseline method. When We compare our model U C Csegment With
Unet model, We see that both models behave similarly. They have reasonably high TPR and TNR
scores, and loW FPR and FNR scores. Moreover, they have loWer FPR values than FNR values,
Which is more favorable than vice-versa since pathologists opt to use immunohistochemistry (IHC)
to confirm negative cases (Bejnordi et al., 2017). HoWever, there is a performance gap betWeen
tWo models, Which is mainly due to the fact that Unet model is a fully supervised model and it is
trained on ground truth masks, Which requires exhaustive annotations by experts. On the contrary,
U C Csegment model is trained on ucc labels and approximates to the performance of the Unet
model. ucc label is obtained based on Whether the image is metastatic, non-metastatic or mixture,
Which is much cheaper and easier to obtain compared to exhaustive mask annotations. Another
factor affecting the performance of U C Cseg ment model is that ucc1 labels can sometimes be noisy.
It is possible to have some small portion of normal cells in cancer regions and vice-versa due to the
nature of the cancer. HoWever, our U C Csegment is robust to this noise and gives reasonably good
results, Which approximates the performance of Unet model.
6 Conclusion
In this paper, We proposed a Weakly supervised learning based clustering frameWork and introduce
a novel MIL task as the core of this frameWork. We defined ucc as a bag level label in MIL setup
and mathematically proved that a perfect ucc classifier can be used to perfectly cluster individual
instances inside the bags. We designed a neural netWork based ucc classifer and experimentally
shoWed that clustering performance of our frameWork With our ucc classifiers are better than the
performance of unsupervised models and comparable to performance of fully supervised learning
models. Finally, We shoWed that our Weakly supervised unique class count model, U C Csegment, can
be used for semantic segmentation of breast cancer metastases in histological lymph node sections.
We compared the performance of our model U C Csegment With the performance of a Unet model
and shoWed that our Weakly supervised model approximates the performance of fully supervised
Unet model. In the future, We Want to check the performance of our U C Csegment model With other
medical image datasets and use it to discover neW morphological patterns in cancer that had been
overlooked in traditional pathology WorkfloW.
Acknowledgements
This Work is supported by the Biomedical Research Council of the Agency for Science, Technology,
and Research, Singapore and the National University of Singapore, Singapore.
10
Published as a conference paper at ICLR 2020
References
Stuart Andrews, Ioannis Tsochantaridis, and Thomas Hofmann. Support vector machines for
multiple-instance learning. In Advances in neural information processing systems, pp. 577-584,
2003.
Carlos Arteta, Victor Lempitsky, J Alison Noble, and Andrew Zisserman. Interactive object count-
ing. In European conference on computer vision, pp. 504-518. Springer, 2014.
Boris Babenko, Ming-Hsuan Yang, and Serge Belongie. Robust object tracking with online multiple
instance learning. IEEE transactions on pattern analysis and machine intelligence, 33(8):1619-
1632, 2011.
Babak Ehteshami Bejnordi, Mitko Veta, Paul Johannes Van Diest, Bram Van Ginneken, Nico
Karssemeijer, Geert Litjens, Jeroen AWM Van Der Laak, Meyke Hermsen, Quirine F Manson,
Maschenka Balkenhol, et al. Diagnostic assessment of deep learning algorithms for detection of
lymph node metastases in women with breast cancer. Jama, 318(22):2199-2210, 2017.
James D Brierley, Mary K Gospodarowicz, and Christian Wittekind. TNM classification of malig-
nant tumours. John Wiley & Sons, 2016.
Nataly Brukhim and Amir Globerson. Predict and constrain: Modeling cardinality in deep structured
prediction. In International Conference on Machine Learning, pp. 658-666, 2018.
Jianlong Chang, Lingfeng Wang, Gaofeng Meng, Shiming Xiang, and Chunhong Pan. Deep adap-
tive image clustering. In Proceedings of the IEEE International Conference on Computer Vision,
pp. 5879-5887, 2017.
Yixin Chen and James Z Wang. Image categorization by learning and reasoning with regions.
Journal of Machine Learning Research, 5(Aug):913-939, 2004.
Yixin Chen, Jinbo Bi, and James Ze Wang. Miles: Multiple-instance learning via embedded instance
selection. IEEE Transactions on Pattern Analysis and Machine Intelligence, 28(12):1931-1947,
2006.
Thomas G Dietterich, Richard H Lathrop, and Tomas Lozano-Perez. Solving the multiple instance
problem with axis-parallel rectangles. Artificial intelligence, 89(1-2):31-71, 1997.
Nat Dilokthanakul, Pedro AM Mediano, Marta Garnelo, Matthew CH Lee, Hugh Salimbeni, Kai
Arulkumaran, and Murray Shanahan. Deep unsupervised clustering with gaussian mixture varia-
tional autoencoders. arXiv preprint arXiv:1611.02648, 2016.
Murat Dundar, Balaji Krishnapuram, RB Rao, and Glenn M Fung. Multiple instance learning for
computer aided diagnosis. In Advances in neural information processing systems, pp. 425-432,
2007.
Pedro F Felzenszwalb, Ross B Girshick, David McAllester, and Deva Ramanan. Object detection
with discriminatively trained part-based models. IEEE transactions on pattern analysis and ma-
chine intelligence, 32(9):1627-1645, 2010.
James Foulds and Eibe Frank. A review of multi-instance learning assumptions. The Knowledge
Engineering Review, 25(1):1-25, 2010.
James Richard Foulds. Learning instance weights in multi-instance learning. PhD thesis, The
University of Waikato, 2008.
Thomas Gartner, Peter A Flach, Adam Kowalczyk, and Alexander J Smola. Multi-instance kernels.
In ICML, volume 2, pp. 7, 2002.
Kamran Ghasedi Dizaji, Amirhossein Herandi, Cheng Deng, Weidong Cai, and Heng Huang. Deep
clustering via joint convolutional autoencoder embedding and relative entropy minimization. In
Proceedings of the IEEE International Conference on Computer Vision, pp. 5736-5745, 2017.
11
Published as a conference paper at ICLR 2020
Haroon Idrees, Imran Saleemi, Cody Seibert, and Mubarak Shah. Multi-source multi-scale counting
in extremely dense crowd images. In Proceedings of the IEEE conference on computer vision and
pattern recognition, pp. 2547-2554, 2013.
Zach Jorgensen, Yan Zhou, and Meador Inge. A multiple instance learning strategy for combating
good word attacks on spam filters. Journal of Machine Learning Research, 9(Jun):1115-1146,
2008.
Andreas Kipf, Thomas Kipf, Bernhard Radke, Viktor Leis, Peter Boncz, and Alfons Kem-
per. Learned cardinalities: Estimating correlated joins with deep learning. arXiv preprint
arXiv:1809.00677, 2018.
Alex Krizhevsky and Geoffrey Hinton. Learning multiple layers of features from tiny images. Tech-
nical report, Citeseer, 2009.
Yann LeCun, Leon Bottou, Yoshua Bengio, Patrick Haffner, et al. Gradient-based learning applied
to document recognition. Proceedings of the IEEE, 86(11):2278-2324, 1998.
Jianhua Lin. Divergence measures based on the shannon entropy. IEEE Transactions on Information
theory, 37(1):145-151, 1991.
Geert Litjens, Peter Bandi, Babak Ehteshami Bejnordi, Oscar Geessink, Maschenka Balkenhol,
Peter Bult, Altuna Halilovic, Meyke Hermsen, Rob van de Loo, Rob Vogels, et al. 1399 h&e-
stained sentinel lymph node sections of breast cancer patients: the camelyon dataset. GigaScience,
7(6):giy065, 2018.
Henry Liu, Mingbin Xu, Ziting Yu, Vincent Corvinelli, and Calisto Zuzarte. Cardinality estimation
using neural networks. In Proceedings of the 25th Annual International Conference on Computer
Science and Software Engineering, pp. 53-59. IBM Corp., 2015.
Lars Maal0e, Casper Kaae S0nderby, S0ren Kaae S0nderby, and Ole Winther. Auxiliary deep gen-
erative models. arXiv preprint arXiv:1602.05473, 2016.
Alireza Makhzani, Jonathon Shlens, Navdeep Jaitly, Ian Goodfellow, and Brendan Frey. Adversarial
autoencoders. arXiv preprint arXiv:1511.05644, 2015.
Emanuel Parzen. On estimation of a probability density function and mode. The annals of mathe-
matical statistics, 33(3):1065-1076, 1962.
Jan Ramon and Luc De Raedt. Multi instance neural networks. 2000.
Antti Rasmus, Mathias Berglund, Mikko Honkala, Harri Valpola, and Tapani Raiko. Semi-
supervised learning with ladder networks. In Advances in neural information processing systems,
pp. 3546-3554, 2015.
Olaf Ronneberger, Philipp Fischer, and Thomas Brox. U-net: Convolutional networks for biomedi-
cal image segmentation. In International Conference on Medical image computing and computer-
assisted intervention, pp. 234-241. Springer, 2015.
Burr Settles, Mark Craven, and Soumya Ray. Multiple-instance active learning. In Advances in
neural information processing systems, pp. 1289-1296, 2008.
Jost Tobias Springenberg. Unsupervised and semi-supervised learning with categorical generative
adversarial networks. arXiv preprint arXiv:1511.06390, 2015.
Jinhui Tang, Haojie Li, Guo-Jun Qi, and Tat-Seng Chua. Image annotation by graph-based inference
with integrated multiple/single instance representations. IEEE Transactions on Multimedia, 12(2):
131-141, 2010.
Jianfeng Wang, Jingdong Wang, Jingkuan Song, Xin-Shun Xu, Heng Tao Shen, and Shipeng Li.
Optimized cartesian k-means. IEEE Transactions on Knowledge and Data Engineering, 27(1):
180-192, 2015.
Xinggang Wang, Yongluan Yan, Peng Tang, Xiang Bai, and Wenyu Liu. Revisiting multiple instance
neural networks. Pattern Recognition, 74:15-24, 2018.
12
Published as a conference paper at ICLR 2020
Jiajun Wu, Yinan Yu, Chang Huang, and Kai Yu. Deep multiple instance learning for image clas-
sification and auto-annotation. In Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition, pp. 3460-3469, 2015.
Junyuan Xie, Ross Girshick, and Ali Farhadi. Unsupervised deep embedding for clustering analysis.
In International conference on machine learning, pp. 478-487, 2016.
Jianwei Yang, Devi Parikh, and Dhruv Batra. Joint unsupervised learning of deep representations
and image clusters. In Proceedings of the IEEE Conference on Computer Vision and Pattern
Recognition, pp. 5147-5156, 2016.
Sergey Zagoruyko and Nikos Komodakis. Wide residual networks. arXiv preprint
arXiv:1605.07146, 2016.
Lihi Zelnik-Manor and Pietro Perona. Self-tuning spectral clustering. In Advances in neural infor-
mation processing systems, pp. 1601-1608, 2005.
Cha Zhang, John C Platt, and Paul A Viola. Multiple instance boosting for object detection. In
Advances in neural information processing systems, pp. 1417-1424, 2006.
Cong Zhang, Hongsheng Li, Xiaogang Wang, and Xiaokang Yang. Cross-scene crowd counting via
deep convolutional neural networks. In Proceedings of the IEEE conference on computer vision
and pattern recognition, pp. 833-841, 2015.
Min-Ling Zhang and Zhi-Hua Zhou. Multi-instance clustering with applications to multi-instance
prediction. Applied Intelligence, 31(1):47-68, 2009.
Qi Zhang and Sally A Goldman. Em-dd: An improved multiple-instance learning technique. In
Advances in neural information processing systems, pp. 1073-1080, 2002.
Qi Zhang, Sally A Goldman, Wei Yu, and Jason E Fritts. Content-based image retrieval using
multiple-instance learning. In ICML, volume 1, pp. 2. Citeseer, 2002.
Yingying Zhang, Desen Zhou, Siqin Chen, Shenghua Gao, and Yi Ma. Single-image crowd count-
ing via multi-column convolutional neural network. In Proceedings of the IEEE conference on
computer vision and pattern recognition, pp. 589-597, 2016.
Zhi-Hua Zhou. A brief introduction to weakly supervised learning. National Science Review, 5(1):
44-53, 2017.
Zhi-Hua Zhou and Min-Ling Zhang. Neural networks for multi-instance learning. In Proceedings of
the International Conference on Intelligent Information Technology, Beijing, China, pp. 455-459,
2002.
Zhi-Hua Zhou, Yu-Yin Sun, and Yu-Feng Li. Multi-instance learning by treating instances as non-
iid samples. In Proceedings of the 26th annual international conference on machine learning, pp.
1249-1256. ACM, 2009.
13
Published as a conference paper at ICLR 2020
A	Kernel Density Estimation
Kernel density estimation is a statistical method to estimate underlying unknown probability dis-
tribution in data (Parzen, 1962). It works based on fitting kernels at sample points of an unknown
distribution and adding them up to construct the estimated probability distribution. Kernel density
estimation process is illustrated in Figure 5.
Figure 5: KDE module - the Gaussian kernel (κ(v - fσj,i)) for each extracted feature for a sample is
illustrated with colored curves and previously accumulated kernels are shown in gray. Estimated fea-
ture distributions, which are obtained by employing Equation 2, are sampled at some pre-determined
intervals and passed to θdrn.
A. 1 KDE module is differentiable
The distribution of the feature hjσ (v) is obtained by applying kernel density estimation on the
extracted features fσj,i as in Equation 2. In order to be able to train our unique class count model
end-to-end, we need to show that KDE module is differentiable, so that we can pass the gradients
from θdrn to θfeature during back-propagation. Derivative of hjσ (v) with respect to input of KDE
14
Published as a conference paper at ICLR 2020
module, fσj,ζi , can be obtained as in Equation 3.
AhjZ(V = _1_ (V - f力 e-212(v-fσζi)
∂fj	| σZ | σ2 √2πσ2
(2)
(3)
After showing that KDE module is differentiable, we can show the weight update process for θfeature
module in our model. Feature extractor module θfeature is shared by both autoencoder branch and ucc
branch in our model. During back-propagation phase of the end-to-end training process, the weight
updates of θfeature comprise the gradients coming from both branches (Equation 5). Gradients coming
from autoencoder branch follow the traditional neural network back-propagation flow through the
convolutional and fully connected layers. Different than that, gradients coming from ucc branch
(Equation 6) also back-propagate through the custom KDE layer according to Equation 3.
(4)
Loss = α Lossucc + (1 - α) Lossae where α ∈ [0, 1]
|	{Z	}	l^^^}
ucc	autoencoder
loss	loss
∂ Loss	_	∂LθSSucc	+ (1	
		= ∂ θfeature	∂θfeature		∂ ∂LθSSae ∂θfeature
|~{{}	I - - J		1_ - - J
	~^^^^{^^^^^		~^^^{^^^^
gradients	gradients		gradients
for	from		from
θfeature	ucc branch		autoencoder branch
∂LθSSucc __ ∂LθSSucc
∂θfeature =	dhj4
∂hσζ
f
''~{z}
back-propagation
through
KDE layer
∂fσζ
X ∂-
feature
(5)
(6)
B	Proofs of Propositions
Before proceeding to the formal proofs, it is helpful to emphasize the decomposability property of
kernel density estimation here.
For any set, σζ, one could partition it into a set of M disjoint subsets σζ = σ1 ∪ σ2 ∪∙∙∙∪ σM where
σλ ∩σψ = 0 for λ = ψ. It is trivial to show that distribution hjζ (v) is simply a linear combination of
distributions h" (v), λ = 1, 2, ∙∙∙ ,M (Equation 7). As a direct consequence, one could decompose
any set into its pure subsets. This is an important decomposition which will be used in the proofs of
propositions later.
, 幺 ，	lσ0 I
hjζ(v) = ɪ^wj]hj](v),∀j where w0( =而
(7)
Now, we can proceed to formally state our propositions.
Definition 1 Given a subset σζ ⊂ X, unique class count, ησζ, is defined as the number of unique
classes that all instances in the subset σζ belong to, i.e. %4=∣{L(xi)∣Xi ∈ q&}∣. Recall that each
instance belongs to an underlying unknown class.
Definition 2 A set σ is called a pure set if its unique class count equals one. All pure sets are
denoted by the symbol σpure in this paper.
15
Published as a conference paper at ICLR 2020
Proposition B. 1 For any set σζ ⊂ X, the unique class count ησζ of σζ does not depend on the
number of instances in σζ belonging to a certain class.
Proof: This conclusion is obvious from the definition of unique class count in Definition 1.	■
Proposition B. 2 θdrn is non-linear.
Proof: We give a proof by contradiction using Proposition B.1. Suppose θdrn is linear, then
θdrn(hσν) = θdrn(wζhσζ + wξhσξ)	(8)
= wζ θdrn (hσζ) + wξθdrn(hσξ)
= wζ ησζ + Wξ ησξ = ησν
Hence, θdrn is linear only when Equation 8 holds. However, by Proposition B.1, (θfeature, θdrn) should
count correctly regardless of the proportion of the size of the sets ∣σζ | and ∣σξ |. Hence, Equation 8
cannot hold true and θdra by contradiction cannot be linear.	■
Proposition B. 3 Let σζ, σξ be disjoint subsets of X with predicted unique class counts 诅 and
ησξ, respectively. Let %ν be the predicted unique class count of q» = σζ ∪ σξ. If h^ = hσξ, then
ησν = ησζ = ησξ.
Proof: The distribution of set σν can be decomposed into distribution of subsets,
hσν = wζ hσζ + wξ hσξ where wζ + wξ = 1	(9)
hσζ = hσξ =⇒ hσν = hσζ	(10)
Hence, %丫 =	=	.	■
Proposition 1 Let σζ, σξ be disjoint subsets of X with predicted unique class counts %« = %ξ = 1.
Ifthe predicted unique class count of σν = σζ ∪ σξ is ησν = 2, then hσζ = hσξ.
Proof: Proof of this proposition follows immediately from the contra-positive of Proposition B.3. ■
Definition 3 A perfect unique class count classifier takes in any set σ and output the correct pre-
dicted unique class count % = ησ.
Proposition 2 Given a perfect unique class count classifier. The dataset X can be perfectly clus-
tered into K subsets σξu'e, ξ = 1, 2,…,K, such that X = Sξ=1 σξpure and σ1pure = {x∕xi ∈
X, L(xi) = ξ}.
Proof: First note that this proposition holds because the “perfect unique class count classifier” is a
very strong condition. Decompose X into subsets with single instance and then apply the unique
class count on each subset, by definition, unique class counts of all subsets are one. Randomly pair
up the subsets and merge them if their union still yield unique class count of one. Recursively apply
merging on this condition until no subsets can be merged.	■
Proposition 3 Given a perfect unique class count classifier. Decompose the dataset X into K
subsets σξpure, ξ = 1, ∙∙∙ K, such that σξure = {x∕xi ∈ X, L(Xi) = ξ}. Then,八色…=hσpure for
ξ 6= ζ.	ξ	ζ
Proof: Since in Proposition 1, the subsets are arbitrary, it holds for any two subsets with unique
class count of one. By pairing up all combinations, one arrives at this proposition. Note that for a
perfect unique class count classifier, η = η.	■
C Details on Experiments with MNIST and CIFAR Datasets
C.1 Details of Model Architectures
Feature extractor module θfeature has convolutional blocks similar to the wide residual blocks
in Zagoruyko & Komodakis (2016). However, the parameters of architectures, number of con-
volutional and fully connected layers, number of filters in convolutional layers, number of nodes in
16
Published as a conference paper at ICLR 2020
fully-connected layers, number of bins and σ value in KDE module, were decided based on models’
performance and training times. While increasing number of convolutional layers or filters were not
improving performance of the models substantialy, they were putting a heavy computation burden.
For determining the architecture of θdrn, we checked the performances of different number of fully
connected layers. As the number of layers increased, the ucc classification performance of the mod-
els increased. However, we want θfeature to be powerful, so we stopped to increase number of layers
as soon as we got good results. For KDE module, we have tried parameters of 11 bins, 21 bins,
σ = 0.1 and σ = 0.01. Best results were obtained with 11 bins and σ = 0.1. Similarly, we have
tested different number of features at the output of θfeature module and we decided to use 10 features
for MNIST and CIFAR10 datasets and 16 features for CIFAR100 dataset based on the clustering
performance and computation burden.
During training, loss value of validation sets was observed as early stopping criteria. Training of the
models was stopped if the validation loss didn’t drop for some certain amount of training iterations.
For the final set of hyperparameters and details of architectures, please see the code for our experi-
ments: http://bit.ly/uniqueclasscount
C.2 Details of Datasets
We trained and tested our models on MNIST, CIFAR10 and CIFAR100 datasets. While MNIST and
CIFAR10 datasets have 10 classes, CIFAR100 dataset has 20 classes. For MNIST, we randomly
splitted 10,000 images from training set as validation set, so we had 50,000, 10,000 and 10,000
images in our training Xmnist,tr, validation Xmnist,val and test sets Xmnist,test, respectively. In CI-
FAR10 dataset, there are 50,000 and 10,000 images with equal number of instances from each class
in training and testing sets, respectively. Similar to MNIST dataset, we randomly splitted 10,000
images from the training set as validation set. Hence, we had 40,000, 10,000 and 10,000 images in
our training Xcifar10,tr, validation Xcifar10,val and testing Xcifar10,test sets for CIFAR10, respec-
tively. In CIFAR100 dataset, there are 50,000 and 10,000 images with equal number of instances
from each class in training and testing sets, respectively. Similar to other datasets, we randomly
splitted 10,000 images from the training set as validation set. Hence, we had 40,000, 10,000 and
10,000 images in our training Xcif ar100,tr, validation Xcif ar100,val and testing Xcifar100,test sets
for CIFAR10, respectively.
F ullySupervised models took individual instances as inputs and were trained on instance level
ground truths. Xmnist,tr, Xcifar10,tr and Xcifar100,tr were used for training of F ullySupervised
models. Unique class count models took sets of instances as inputs and were trained on ucc labels.
Inputs to unique class count models were sampled from the power sets of MNIST, CIFAR10 and
CIFAR100 datasets, i.e. 2Xmnist,tr, 2Xcifar10,tr and 2Xcifar100,tr. For MNIST and CIFAR10 datasets,
the subsets (bags) with 32 instances and for CIFAR100 dataset, the subsets (bags) with 128 instances
are used in our experiments. While UCC and UCCα=1 models are trained on ucc1 to ucc4 labels,
U CC2+ and U C Cα2+=1 models are trained on ucc2 to ucc4 labels.
Our models were trained on ucc labels up to ucc4 instead of ucc10 (ucc20 in CIFAR100) since the
performance was almost the same for both cases in our experiment with MNIST dataset, results of
which are shown in Table 3. On the other hand, training with ucc1 to ucc4 was much faster than
ucc1 to ucc10 because as the ucc label gets larger, the number of instances in a bag is required to be
larger in order to represent each class and number of elements in powerset also grows exponentially.
Please note that for perfect clustering of instances, it is enough to have a perfect ucc classifier that
can discriminate ucc1 and ucc2 from Proposition 2.
All the results presented in this paper were obtained on hold-out test sets Xmnist,test, Xcifar10,test
and Xcifar100,test.
17
Published as a conference paper at ICLR 2020
Table 3: Clustering accuracy comparison of training unique class count models with ucc labels of
ucc1 to ucc4 and ucc1 to ucc10 on MNIST dataset.
	clustering accuracy	
	ucc1 to ucc4 ucc1 to ucc10	
UCC	0.984	0.983
UCC2+	0.984	0.982
C.3 CONFUSION MATRICES FOR ucc PREDICTIONS
We randomly sampled subsets for each ucc label from the power sets of test sets and predicted the
ucc labels by using trained models. Then, we calculated the ucc prediction accuracies by using
predicted and truth ucc labels, which are summarized in Table 1. Here, we show confusion matrices
of our UCC and UCC2+ models on MNIST, CIFAR10 and CIFAR100 datasets as examples in
Figure 6, 7 and 8, respectively.
(a) UCC
(b) UCC2+
Figure 6: Confusion matrices of our UCC and UCC2+ models for ucc prediction on MNIST.
υccl
0.993
0.007 0.000
0.005
0.061
UCC2 -
0.000
0.972
0.023
υcc3 -
0.000
0.001
0.938
0.2
υcc4 -
0.000
0.000	0.013
0.987
IZE
UUU
u	υ	u
n	n	n
Predicted label
(a) UCC
Figure 7: Confusion matrices of our
Predicted label
(b) UCC2+
U C C and U C C 2+ models for ucc prediction on
CIFAR10.
I3q£ ωsH
18
Published as a conference paper at ICLR 2020
0.881
0.037	0.046	0.036
0.817
0.105
0.032
0.743
0.009 0.078
0.913
0.020
0.001
0.000
0.059
0.224
(a) UCC
(b) UCC2+
Figure 8:	Confusion matrices of our UCC and UCC2+ models for ucc prediction on CIFAR100.
C.4 Feature Distributions and Inter-class JS Divergence Matrices
The features of all the instances in a particular class are extracted by using a trained model and
feature distributions associated to that class obtained by performing kernel density estimation on
these extracted features. Then, for each pair of classes, inter-class JS divergence values are calcu-
lated. We show inter-class JS divergence matrices for our F ullySupervised and UCC models on
MNIST test dataset in Figure 9. We also show the underlying distributions for F ullySupervised
and UCC models in Figure 10 and 11, respectively.
1
2
6
7
8
Djs("∣∣2)
0.000
0.570
0.563
D”(刊 IQ)
0.570 0.563 0.566
0.469 0.466 0.457 0.478
0.373
0.459
0.000
0.377
0.562
0.661
0.473
0.650
0.464
0.557
0.643
ι.o
1.0
0.377
0.000
0.551
0.469
0.657 0.645
0.457
0.535
0.459
0.566 0.562 0.551
0.000
0.647
0.449 0.470
0.283
0.536
0.454
0.469
0.661
0.469
0.647
0.000
0.559
0.37010.739
0.455
0.359
0.6
0.000
0.608
0.395 0.476
0.576 0.530 0.399
0.532 0.437
0.503
0.608
0.000
0.504 0.496
0.549 0.559 0.538
0.467 0.487
0.555
0.8
0.395
0.504
0.000
0.376
0.508 0.469 0.360 0.365
0.281
0.364
0.476 0.496 0.376
0.000
0.485
0.412 0.405 0.458
0.339
0.477
0.6
4-
0.576 0.549 0.508 0.485
0.000
0.489
0.434 0.404
0.332 0.287
0.466 0.473
0.657
0.449
0.559
0.000
0.535 0.557
0.447
0.362
0.530 0.559
0.469 0.412
0.489
0.000
0.407 0.457
0.324
0.444
0.4
0.4
0.457
0.650 0.645
0.470
0.370
0.535
0.000
0.565
0.448
0.542
0.399
0.538
0.360 0.405 0.434 0.407
0.000
0.435
0.281
0.403
0.478 0.464 0.457 0.283
0.557 0.565
0.000
0.454
0.367
Q 5 32
0.467
0.365 0.458 0.404 0.457 0.435
0.000
0.347 0.366
0.2
0.2
0.373
0.557 0.535 0.536
0.455 0.447 0.448 0.454
0.000
0.613
0.437 0.487
0.281 0.339 0.332 0.324 0.281 0.347
0.000
0.222
0.459
0.643
0.459 0.454
0.359 0362
0.542
0.367
0.613
0.000
0.503 0.555
0.364
0.477
0.287
0.444 0.403 0.366
0.222
0.000
0
2
5
6
7
8
9
7
0
2
3
4	5
Q
6
8
9
0.0
1
2
3
4	5
Q
6
7
8
9
(a) F ullySupervised
0.0
(b) UCC
Figure 9:	Inter-class JS divergence matrix calculated over the distributions of features extracted by
our F ullySupervised and UCC models on MNIST test dataset.
19
PUbliShed as a ConferenCe PaPersICLR 2020

Figure 10: Distributions of extracted features by our FullySupervised model on MNIST test dataset. Each column corresponds to a feature learned by model and
each row corresponds to an underlying class in the test dataset.
PUbHShed as a COnferenCe PaPer at ICLR 2020
Q4 03 0.2 QL 0.0				∖			Q4 Q3 &2 QL 0.0		-X1	/				0.4 Q3 &2 QL 0.0	/	C					0.4 Q3 &2 QL 0.0					/	\	0.4 Q3 &2 Ql Qo					0.4 0.3 Q2 0.1 QO	/	C	V					0.4 0.3 Q2 0.1 QO					Γ	\	0.4 0.3 0.2 0.1 0.0			/	Λ	J		0.4 0.3 0.2 0.1 QO	/	A	\	—			0.4 0.3 0.2 0.1 QO					八	\
o.a Q3 0.2 QL	ɪ ɪ-：	-		Γ~ P a	-Γ^ ΛJ	-Γ^ Hl	~Γ^ 1 I	0.4 Q3 Q.2 GL	ɪ ɪ-：	-1-	-T F	-		1- CO Ci	~Γ^ 1 I	0.4 Q3 Q.2 GL	≡	s	§		m a		0.4 0.3 0.2 GL	ɪ 1-：		T-	—Γ^ F	-1	Γ^ IO m Ci O		- < I	Qa Q3 Q2 0.1	l^γ^ 1-：	-Γ^	-1	1	1	J— Pg 8 O CiCiOI		0.4 0.3 Q.2 0.1	≡	S	3		m O			0.4 Q3 Q2 0.1	H		T-	-1- -T	-Γ^ 'Λ.	-Γ^ Il	-1- - 5		ɪ --	-Γ^	-	— U		Γ^ m 0	- 5		lt^ --	-Γ^	-V -r	- -	I m 0	- 5		ɪ --	-i	Γ P Ci	-V 'Λ.	-r^ Ill	-TJ O
			:							/	L	:							:																			Z										0.4 0.3 Q2 0.1					Z		Od Q3 Q2 0.1					:		Od Q3 Q2 0.1	/		:			
																																																																				
	Λ		S	S	S	二		Λ	-Γ^	§		S	二			3	S			二			3	S		44 Q	二		Λ	3	3 S ≡ S				3	3		S				g	:二	m		3	二			3			S	二		S	3	二		骂	二		S		S			二
0.4 03 0.2 QL QO							0.4 Q3 QZ QL 0.0							0.4 Q3 QZ QL 0.0							0.4 Q3 QZ QL 0.0							0.4 Q3 Q2 QL QO					0.4 Q3 Q2 0.1 GO								0.4 Q3 Q2 0.1 GO							0.4 Q3 Q2 0.1 QO							0.4 0.3 0.2 Ql QO							0.4 0.3 0.2 Ql QO						
0.4 03 0.2 QL	K		S	-l	S		0.4 Q3 QZ QL	二	S			S		0.4 Q3 QZ QL	二	3	S		S		0.4 Q3 QZ QL	二	3	S				0.4 Q3 Q2 0.1	二	3	3 S S 3		Q4 Q3 0.2 0.1	§	3	m		S	二；		Q4 Q3 0.2 0.1			m		S	二		§	W			S			S	S	3	⅛	Z	二		S		S		3	
	/										L							/	Λ	\											/				二	/		\:					/	、				0.4 0.3 Q2 0.1					:	\	0.4 Q3 0.2 0.1							0.4 Q3 0.2 0.1			:		V	
																																																																				
	S		V 0	-Γ^	g	二		S	S			0 O	二		S	S	S		M Q	二		S	S	S	9 M S Q		二		S	S	中 9 8 O CCC-J			§	S	二		M Q	二				r^ e		£	S	二		§	S		喳 C	0 0	二		S	S	二		to O	二		S		∙⅛ O	£	S	二
Q4 03 0.2 QL				F	;		Q4 Q3 0.2 QL				L	\		Q4 Q3 0.2 QL					—		Q4 Q3 0.2 QL				J			0.4 Q3 &2 Ql					0.4 0.3 Q2 0.1								0.4 0.3 Q2 0.1		二	一				0.4 0.3 Q2 0.1	/	一					0.4 0.3 0.2 0.1					二	V	0.4 0.3 0.2 0.1				rxX		
																																																																				
	S		P a	S	S			S	S	§		«0			S	S	S		«			S	S	S	9 8 O Ci				S	S	≡ S 3 3			≡	S			0 O				≡		3	S	S	二		≡	S			« Ci	二		≡	S	≡		« Ci	二		≡		P Ci	S	3	
o.a 03 0.2 QL	/	∖					0.4 03 Q2 QL							0.4 03 Q2 QL			/				0.4 03 Q2 QL				/	C	\	0.4 &3 Q2 Gl	/	ɜ		、		0.4 Q3 Q2 0.1		W	/	、	V			0.4 Q3 Q2 0.1				√--	/		\	0.4 Q3 Q.2 0.1		√		\			Od 0.3 Q2 0.1		彳	/		、		Od 0.3 Q2 0.1		/				
,I '							Qo							Qo							QO																																															
			S	S	S	二		Λ	S	§		0 Q			Λ	3						Λ	3	S	22		二			3		9 8 0			3	3							:二			3	二		S	3				二			3	二		骂	二				3			二
0.4 03 0.2 QL 0.0			/				0.4 Q3 QZ QL QO							0.4 Q3 QZ QL QO					z∖		0.4 Q3 QZ QL QO							0.4 Q3 Q2 QL QO					0.4 Q3 Q2 0.1 GO		y						0.4 Q3 Q2 0.1 GO							0.4 Q3 Q2 0.1 QO	/						0.4 0.3 0.2 Ql QO							0.4 0.3 0.2 Ql QO						
21
Figure 11: Distributions of extracted features by our UCC model on MNIST test dataset. Each column corresponds to a feature learned by model and each row
corresponds to an underlying class in the test dataset.
Published as a conference paper at ICLR 2020
C.5 K-means and Spectral Clustering Accuracies of Our Models
We performed unsupervised clustering by using k-means and spectral clustering and gave the best
clustering accuracy for each model on each dataset in Table 1 in the main text. Here, we present all
the clustering accuracies for our models in Table 4.
Table 4: Clustering accuracy values of our models with K-means and Spectral clustering methods
on different test datasets. Best value for each model in each dataset is highlighted in bold.
MNIST	CIFAR10	CIFAR100
	K-means	Spectral	K-means	Spectral	K-means	Spectral
UCC	0.979	0.984	-^0.781	0.680	0.338	0.261
UCC2+	0.977	0.984	^^0.545	0.502	0.278	0.225
UCCa=1	0.981	0.984	-^0.774	0.635	0.317	0.249
UCCa2+=1	0.881	0.832	^^0.521	0.463	0.284	0.237
Autoencoder	0.930	0.832	^^0.241	0.230	0.167	0.140
F ullySupervised	0.988	0.106	0.833	0.464	0.563	0.328
C.6 UCC Models with Averaging Layer and KDE Layer
KDE layer is chosen as MIL pooling layer in UCC model because of its four main properties,
first three of which are essential for the proper operation of proposed framework and validity of the
propositions in the paper:
1.	KDE layer is permutation-invariant, i.e. the output of KDE layer does not depend on the
permutation of its inputs, which is important for the stability of θdrn module.
2.	KDE layer is differentiable, so UCC model can be trained end-to-end.
3.	KDE layer has decomposability property which enables our theoretical analysis (Ap-
pendix B).
4.	KDE layer enables θdrn to fully utilize the information in the shape of the distribution rather
than looking at point estimates of distribution.
Averaging layer (Wang et al., 2018) as an MIL pooling layer, which also has the first three properties,
can be an alternative to KDE layer in UCC model. We have conducted additional experiments
by replacing KDE layer with ’averaging layer’ and compare the clustering accuracy values of the
models with averaging layer and the models with KDE layer in Table 5.
Table 5: Clustering accuracy values of the models with averaging layer and the models with KDE
layer.
clustering acc.
mnist_Cifar10
UCC (KDE Iayer)	0.984 0.78F=
UCC (Averaging layer)	0.987 0.638
UCCa=I (KDE Iayer)	0981 ^^0.774
UCCa=I (Averaging Iayer) 0.943 0.508-
22
Published as a conference paper at ICLR 2020
D Details on Semantic Segmentation Task
D. 1 Details of Model and Dataset
Our model U C Csegment has the same architecture with the UCC model in CIFAR10 dataset, but
this time we have used 16 features. We have also constructed the Unet model with the same blocks
used in U C Csegment model in order to ensure a fair comparison. The details of the models can be
seen in our code: http://bit.ly/uniqueclasscount
We have used 512 × 512 image crops from publicly available CAMELYON dataset (Litjens et al.,
2018). CAMELYON dataset is a public Whole Slide Image (WSI) dataset of histological lymph
node sections. It also provides the exhaustive annotations for metastases regions inside the slides
which enables us to train fully supervised models for benchmarking of our weakly supervised unique
class count model.
We randomly crop 512×512 images over the WSIs of CAMELYON dataset and associate a ucc label
to each image based on whether it is fully metastases/normal (ucc1) or mixture (ucc2). We assigned
ucc labels based on provided ground truths since they are readily available. However, please note
that in case no annotations provided, obtaining ucc labels is much cheaper and easier compared to
tedious and time consuming exhaustive metastases region annotations. We assigned ucc1 label to an
image if the metastases region in the corresponding ground truth mask is either less than 20% (i.e.
normal) or more than 80% (i.e metastases). On the other hand, we assigned ucc2 label to an image
if the metastases region in the corresponding ground truth mask is more than 30% and less than 70%
(i.e. mixture). Actually, this labeling scheme imitates the noise that would have been introduced
if ucc labeling had been done directly by the user instead of using ground truth masks. Beyond
that, ucc1 labels in this task can naturally be noisy since it is possible to have some small portion of
normal cells in cancer regions and vice-versa due to the nature of the cancer. In this way, we have
constructed our segmentation dataset consisting of training, validation and testing sets. The images
in training and validation sets are cropped randomly over the WSIs in training set of CAMELYON
dataset and the images in testing set are cropped randomly over the test set of CAMELYON dataset.
Then, the bags in our MIL dataset to train U C Csegment model are constructed by using 32 × 32
patches over these images. Each bag contains 32 instances, where each instance is a 32 × 32 patch.
The details of our segmentation dataset are shown in Table 6.
We have provided the segmentation dataset under “./data/camelyon/” folder inside our code folder.
If you want to use this dataset for benchmarking purposes please cite our paper (referenced later)
together with the original CAMELYON dataset paper of Litjens et al. (2018).
Table 6: Details of our segmentation dataset: number of WSIs used to crop the images in each set,
number of images in each set and corresponding label distributions in each set
	ucc1			ucc2	# of images	# of WSIs
	normal	metastases	total	mixture		
Training	461	322	^783^^	310	1093	159
Validation	278	245	^323^^	211	734	106
Testing	282	668	~950~	228	1178	126
We have given confusion matrix for ucc predictions of our U C Csegment model in Figure 12. For
Unet model, we have shown loss curves of traininig and validation sets during training in Figure 13.
23
Published as a conference paper at ICLR 2020
uccl	ucc2
Predicted Label
Figure 12: Confusion matrix of our U C Csegment model for ucc predictions on our segmentation
dataset.
iteration
Figure 13: Training and validation loss curves during training of our Unet model. We have used the
best model weights, which were saved at iteration 58000, during training. Models starts to overfit
after iteration 60000 and early stopping terminates the training.
D.2 Definitions of Evealution Metrics
In this section, we have defined our pixel level evaluation metrics used for performance comparison
of our weakly supervised U C Csegment model, fully supervised Unet model and unsupervised base-
line K - means model. Table 7 shows the structure of pixel level confusion matrix together with
basic statistical terms. Then, our pixel level evaluation metrics TPR (True Positive Rate), FPR (False
Positive Rate), TNR (True Negative Rate), FNR (False Negative Rate) and PA (Pixel Accuracy) are
defined in Equation 11, 12, 13, 14 and 15, respectively.
Table 7: Structure of pixel level confusion matrix together with basic statistical terms
Predicted
Positive (P)
Negative (N)
Ground	Truth
Positive (P)	Negative (N)
True Positive (TP)	False PositiVe (FP)
False Negative (FN)	TrUe Negative (TN)
TPR
TP
TP + FN
(11)
24
Published as a conference paper at ICLR 2020
FPR =	FP	(12)
	二 FP + TN	
TNR =	TN	(13)
	二 TN + FP	
FNR =	FN	(14)
	二 FN + TP	
PA
TP + TN
TP + FP + TN + FN
(15)
25