Figure 1: Overview of our CN-DPM model. Each expert k (blue boxes) contains a discriminativecomponent for modeling p(y|x; φkD) and a generative component for modeling p(x; φkG), jointlyrepresenting p(x, y; φk). We also keep the assigned data count Nk per expert. (a) During training,each sample (x, y) coming in a sequence is evaluated by every expert to calculate the responsibilityρk of each expert. IfρK+1 is high enough, i.e., none of the existing experts is responsible, the data isstored into short-term memory (STM). Otherwise, it is learned by the corresponding expert. WhenSTM is full, a new expert is created from the data in STM. (b) Since CN-DPM is a generative model,we first compute the joint distribution p(x, y) for a given x, from which it is trivial to infer p(y|x).
Figure 2: SPlit-CIFAR10 (0.2 EPoch).
Figure 3: SPlit-CIFAR100.
Figure 4: An example of the expert pruning in the Split-MNIST scenario.
Figure 5: Scenario configuration ofFuzzy Split-MNISTLabel: O Label： O Label： 1 Label: O Label: O Label： 1 Label: 1 Label: O Label: O Label： OLabel: 1 Label： O Label： 1 Label: 3 Label: 2 Label: 2 Label: 2 Label: 3 Label: 2 Label： 3Label: 5 Label： 5 Label： 5 Label: 4 Label: 5 Label： 4 Label: 5 Label: 4 Label： 4 Label： 6Label: 7 Label： 7 Label： 7 Label: 7 Label: 6 Label： 6 Label: 6 Label: 6 Label： 8 Label： 8Label： 9 Label： 8 Label： 8 Label： 8 Label： 8 Label： 9 Label： 9 Label： 8 Label： 8 Label： 8Figure 6: Examples of generation samples by CN-DPM trained on Split-MNIST.
Figure 6: Examples of generation samples by CN-DPM trained on Split-MNIST.
Figure 7: The effects of concentration pa-rameter α.
Figure 8: Full training graphs.
Figure 9: Accuracy for each task in Split-CIFAR10.
Figure 10: Accuracy for each task in Split-CIFAR100.
