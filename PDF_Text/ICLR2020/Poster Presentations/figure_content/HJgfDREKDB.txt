Figure 1: Top: Overview of HOF. The encoder network gφ encodes the geometry of the objectpictured in each input image directly into the parameters of the mapping function fθ, which producesa reconstruction as a transformation of a canonical object (here, the unit sphere). Bottom: Wevisualize the transformation fθ by showing various subsets of the inputs X and their correspondingmapped locations in red and green, respectively. In each frame, light gray shows the rest of X anddark gray shows the rest of the reconstructed object.
Figure 2: From left to right: Input RGB image, ground truth point cloud, reconstruction fromFoldingNet (Yang et al., 2018), reconstruction from DeepSDF (Park et al., 2019), and our method.
Figure 3: Runtime analysis comparing HOF with DeepSDF and FoldingNet architectures. HOF-1and HOF-3 are HOF with 1 and 3 hidden layers, respectively. Computing environment details aregiven in Section B.2.
Figure 4: Top Left. An example of inter-class interpolation between two objects by functioncomposition. We show the ground truth objects OA and OB, a single evaluation of their respectivedecoding functions (giving fA(X) and fB(X)), as well as the possible permutations of compositions,which makes up the leaf nodes in each tree. In fB(fA(X)), we see the wings straighten but remainnarrow. In fA(fB (X)), we observe the wings broaden, but they remain angled. Top Right. Anexample of inter-class interpolation, mixing a table and a rifle. We observe what might be interpretedas a gun with legs in fB(fA(X)) and a table with a single coherent stock in fA (fB (X)).
Figure 5: Slices of the sphere where the input points are sampled from and their projections in thepredicted point set. Slices of the input sphere are colored red; the locations where this subset of theinputs are mapped are green. Above: minimizing the Chamfer distance only. Below: MinimizingChamfer distance with regularization (Equation 6). In both cases, the mapping is smooth, but onlywith regularization is the mapping close to the intuitive projection mapping.
Figure 6: Collision-free path generation. The paths are color-coded as Blue: baseline showing L1distance, Green: baseline going around a bounding box around the object, Yellow: with GT voxelsas obstacles, Magenta: with EPCG voxels, Cyan: with HOF voxels. The rightmost figure shows allpaths together viewed from three different view points. Best viewed in color.
Figure 7: Inter-class interpolation between two objects using function composition and parameterinterpolation. We see that the composition-based interpolation preserves some geometric featuressuch as chair legs, car roof, and airplane wings. Direct interpolation of the network parameters failsto meaningfully capture features from the parent objects. We use k = 4, and (fB ◦ fB ◦ fA ◦ fA)(X)for the interpolations with composition.
Figure 8: 2D illustration of the baseline path generation methods. The dotted path in blue is producedby Shortest L1 and the dashed path in green is by SABB. In our experiments, we use the rectilinearshortest path as the output of Shortest L1.
