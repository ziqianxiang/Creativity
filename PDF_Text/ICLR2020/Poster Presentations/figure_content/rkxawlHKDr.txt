Figure 1: Illustration of our method. The input image I is encoded using network E and decodedback by the decoder D to provide a 2D displacement field J. The vertices of the polygon at time t-1are updated by the displacement values specified by J, creating the polygon of the next time step.
Figure 2: Illustration of the (a) encoder and(b) decoder blocks.
Figure 3: Illustration of the initial contourgeneration process.
Figure 4: Qualitative results of DARNet (Cheng et al., 2019) and our method. Columns (a)-(c)show results from the Vaihingen dataset (Rottensteiner et al.), and (d)-(f) show results from the Binghuts (Marcos et al., 2018) dataset. (b) and (e) - DARNet (Cheng et al., 2019), (c) and (f) - Ours.
Figure 5: Qualitative results on the mammographic and cardiac datasets. Top - INBreast (Moreiraet al., 2012), Middle - DDSM-BCRP (Heath et al., 1998), Bottom - SCD (Radau et al., 2009). Blue- Initial contour. Yellow - Final contour. Green - GT Mask.
Figure 6: Sample results from the Cityscapes dataset.
Figure 7: Varying number of vertices. Yellow - Our method. Green - DARNet (Cheng et al., 2019)100INBreast----Ours Fl-ScoreOurs mloU2	3# of Iterations95Figure 8: Top - different number of vertices, and Bottom - different number of iterations. Resultsfor DARNet (Cheng et al., 2019) are available for the buildings datasets.
Figure 8: Top - different number of vertices, and Bottom - different number of iterations. Resultsfor DARNet (Cheng et al., 2019) are available for the buildings datasets.
