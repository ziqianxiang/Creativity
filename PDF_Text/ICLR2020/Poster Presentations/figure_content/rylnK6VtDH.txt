Figure 1: (Left) Venn diagrams of multiplicative interactions with respect to other model classescommonly used in ML. (Right) Comparison of various orders of multiplicative interactions and theirrelation to other perspectives.
Figure 2: Number of parameters needed for a regular, single layer MLP (blue line) to represent thefunction up to 0.1 MSE over the domain of a standard d-dimensional Gaussian compared to thesame quantity for a multiplicative model (green line). Ïƒ denotes sigmoid. Dotted lines representpruned models where all weights below absolute value of 0.001 were dropped. Note that for MLPall parameters are actually used, while for MI module some of these functions (summation and dotproduct) can be compactly represented with pruning.
Figure 3: Averaged learning curves for different models while varying the number of tasks in the toymultitask regression domain. Shaded regions represent standard error of mean estimation.
Figure 4: (a) A t-SNE plot of the generated weights from an M layer. (b) Human normalisedperformance (capped at 100) when using task ID as context to an M layer. (c) Using a learnt contextinstead.
Figure 5: Results on Neural Processes and language modelling on WikiText-103.
