Figure 1: (best in color) SGC’s performance (dashed lines) with increasing graph convolutions (K)on Cora dataset (train/val/test split is 3%/10%/87%). For each K, we train SGC in 500 epochs,save the model with the best validation accuracy, and report all measures based on the saved model.
Figure 2: Illustration of PairNorm, comprising centering and rescaling steps.
Figure 3: (best in color) Performance comparison ofthe original (dashed) vs. PairNorm-enhanced (solid)GCN and GAT models with increasing layers on Cora.
Figure 4: (best in color) Comparison of ‘vanilla, vs. PAIRNORM-enhanced SGC, GCN, and GATperformance on Cora for p = 1. Green diamond symbols depict the layer at which validationaccuracy peaks. PairNorm boosts overall performance by enabling more robust deep GNNs.
Figure 5: Comparison of ‘vanilla’ vs. PairNorm-enhanced SGC, corresponding to Figure 1, fordatasets (from top to bottom) Citeseer, Pubmed, and CoauthorCS. PAIRNORM provides im-proved robustness to performance decay due to oversmoothing with increasing number of layers.
Figure 6: Comparison of ‘vanilla’ (dashed) vs. PairNorm-enhanced (solid) GCN (left) and GAT(right) models, corresponding to Figure 3, for datasets (from top to bottom) Citeseer, Pubmed, andCoauthorCS. PAIRNORM provides improved robustness against performance decay with increasingnumber of layers.
Figure 7: Comparison of ‘vanilla’ (dashed) vs. PairNorm-enhanced (solid) (from left to right)SGC, GCN, and GAT model performance under SSNC-MV for p = 1, corresponding to Figure 4,for datasets (from top to bottom) Citeseer, Pubmed, and CoauthorCS. Green diamond symbolsdepict the layer at which validation accuracy peaks. PairNorm boosts overall performance byenabling more robust deep GNNs.
Figure 8: Supplementary results to Table 2 for GCN on (from top to bottom) Cora, Citeseer,Pubmed, and CoauthorCS.
Figure 9: Supplementary results to Table 3 for GAT on (from top to bottom) Cora, Citeseer,Pubmed, and CoauthorCS.
Figure 10: Measuring average distance (squared and not-squared) between representations at eachlayer for SGC, SGC with PairNorm, and SGC with PairNorm-SI. The setting is the same withFigure 1 and they share the same performance.
Figure 11: Measuring distribution of distances between representations at each layer for SGC, SGCwith PairNorm, and SGC with PairNorm-SI. Supplementary results for Figure 10.
Figure 12: Measuring average distance (squared and not-squared) between representations at eachlayer for GCN, GCN with PAIRNORM, and GCN with PAIRNORM-SI. We trained three 12-layerGCNs with #hidden=128 and dropout=0.6 in 1000 epochs. Respective test set accuracies are31.09%, 77.77%, 75.09%. Note that the scale of distances is not comparable across models, sincethey have learnable parameters that scale these distances differently.
Figure 13: Measuring distribution of distances between representations at each layer for GCN, GCNwith PairNorm, and GCN with PairNorm-SI. Supplementary results for Figure 12.
