Figure 1: The proposed architecture for hierarchical graph representation learning using the pro-posed memory layer. The query network projects the initial node features into a latent query spaceand each memory layer jointly coarsens the input queries and transforms them into a new queryspace.
Figure 2: Visualization of the learned clusters of two molecule instances from (a) ESOL and (b)Lipophilicity datasets. The visualizations show that the learned clusters correspond to known chem-ical groups. Note that a node without label represents a carbon atom. For more visualizations anddiscussion see section A.5to guarantee invariance to permutations improves the performance. For example, it increases theaccuracy on the DD dataset from 82.24% to 84.40%.
Figure 3: Validation (a) R2 score, and (b) RMSE achieved by MemGNN model on ESOL with GATand e-GAT based query networks.
Figure 4: Figures (b) and (d) show computed clusters without using unsupervised clustering loss,whereas Figures (a) and (c) show the clusters learned using the unsupervised clustering loss. Thevisualizations suggest that the unsupervised loss helps the model in learning distinct and meaningfulclusters.
Figure 5: Clusters learned by a MeMGNN for ESOL and LIPO dataset. Chemical groups like OH(hydroxyl group), CCl3, COOH (carboxyl group), CO (ketone group) as well as benzene rings havebeen recognized during the learning procedure. These chemical groups are highly active and have agreat impact on the solubility of molecules.
