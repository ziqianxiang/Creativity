Figure 1: Sample motor programs that emerge by discovering the space of motor programs from a diverse setof robot demonstration data in an unsupervised manner. These motor programs facilitate understanding thecommonalities across various demonstrations, and accelerate learning for downstream tasks.
Figure 2: An overview of our approach. Our abstraction network takes in an observed demonstration τobs andpredict a sequence of latent variables {z}. These {z} are each decoded into their corresponding motor programsvia the motor program network. We finally recompose these motor programs into the recomposed trajectory.
Figure 3: Visualization of the embedding of the latent representation of motor programs learned by our model(depicted on the left are the start configurations of each motor program, displayed at the corresponding positionin the embedded space), and a set of sample primitives unrolled in time (depicted on the right). Each rowcorresponds to one primitive, annotated with semantic labels of what this motor primitive resembles.
Figure 4: Depiction of execution of the learned primitives on real world Baxter robot. Each row is a singleprimitive, while columns show progress of the primitive over time. Row 1 depicts a left handed reachingprimitive, while row 2 shows a right handed returning primitive. More visualizations provided in supplementarymaterial, and videos are provided in the webpage.
Figure 5: Visualization of consistent segmentations. Each row represents a different instance ofa “Drop Objects”task from the MIME Dataset, while each column represents a time-step in the demonstration. White framesrepresent predicted segmentation points, while colored boxes represent ground truth semantic annotations. Redboxes are reaching primitives, blue boxes are grasping, orange boxes are placing, and green boxes are returningprimitives. We see our model predicts 4 motor programs - reaching, grasping, placing the object a small distanceaway, and returning. This is consistent with the true semantic annotations of these demonstrations, and theoverall sequence of primitives expected of the “Drop Box” task.
Figure 6: RL training curves with and without motor programs. Solid lines denote mean success rate, whileshaded region denotes ±1 standard deviation across 10 random seeds.
Figure 7: Depiction of execution of additional learned primitives on real world Baxter robot. As in Fig. 4, eachrow is a single primitive, while columns show progress of the primitive over time. Row 1 depicts a left handedreturning primitive, row 2 depicts a right handed pushing primitive, row 3 depicts a left handed pushing primitive(in a different configuration to the left handed one), and finally row 4 depicts a right handed twisting primitive.
