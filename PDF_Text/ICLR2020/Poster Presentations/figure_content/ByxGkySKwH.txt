Figure 1: Illustration on toy dataset: We show the color-coded confidence in the prediction (yellowindicates high confidence maxy p(y|x) ≈ 1, whereas dark purple regions indicate low confidencemaxy p(y|x) ≈ 0.5) for a normal neural network (left) and our CCU neural network (right). Thedecision boundary is shown in white which is similar for both models. Our CCU-model retainshigh-confidence predictions in regions close to the training data, whereas far away from the trainingthe CCU-model outputs close to uniform confidence. In contrast the normal neural network isover-confident everywhere except very close to the decision boundary.
Figure 2: Adversarial Noise: We maximize the confidence of the OOD methods using PGD in theball around a uniform noise sample (seed images, left) on which CCU is guaranteed by Corollary 3.1to yield less than 1.1 M maximal confidence. For each OOD method We report the image with thehighest confidence. Maha and MCD use scores where lower is more confident (indicated by *). If wedo not find a sample that has higher confidence/lower score than the median of the in-distribution,we highlight this in boldface. All other OOD methods fail on some dataset, see Table 1 for aquantitative version. ODIN at high temperatures always returns low confidence, so a value of 0.1 isnot informative.
Figure 3: Histograms of bounds: Certified radius in transformed space for different datasets.
