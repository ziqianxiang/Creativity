Figure 1: Overview of our model extraction setup for question answering.2An attacker first queriesa victim BERT model, and then uses its predicted answers to fine-tune their own BERT model. Thisprocess works even when passages and questions are random sequences of words as shown here.
Figure 2: Average dev F1 for extracted SQuAD models after selecting different subsets of data froma large pool of wiki and random data. Subsets are selected based on the agreement between theoutputs of different runs of the original SQuAD model. Notice the large difference between thehighest agreement (blue) and the lowest agreement (green), especially at small dataset sizes.
Figure 3: Histogram of average F1 agreement between five different runs of BERT question answer-ing models trained on the original SQuAD dataset. Notice the higher agreement on points in thewiki dataset compared to random.
