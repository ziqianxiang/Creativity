Figure 1: A schematic illustration of EBMM. The energy function is modelled by a neural network.
Figure 2: Visualization of gradient descent iterations during retrieval of Omniglot characters (largestmodel). Four random images are shown from the batch of 64.
Figure 3: Distortion (reconstruction error) vs rate (memory size) analysis on batches of 64 images.
Figure 4: Visualization of gradient descent iterations during retrieval of CIFAR images. The lastcolumn contains reconstructions from Memory networks (both models use 10k memory).
Figure 5: ImageNet results.
Figure 6: Energy distributions of different classes of patterns under an Omniglot model. Memoriesare the patterns written into memory, non-memories are other randomly sampled images and distortedmemories are the written patterns distorted as during the retrieval. CIFAR images were produced bybinarizing the original RGB images and serve as out-of-distribution samples.
Figure 7: Reconstruction error on Omniglot. Dynamic Kanerva Machine is compared to EBMM withconvolutional memory. 15% salt and pepper noise is used.
Figure 8: An example of a retrieval of a single batch by Dynamic Kanerva Machine. A model with12K memory was used. Top: salt and pepper noise, bottom: 16 × 16 block noise. First line: originalpatterns, middle line: distorted queries, bottom line: retrieved patterns.
Figure 9: Generalization to different noise intensity on Omniglot. Each line represents a modeltrained with a certain noise level. All models use 16K memory.
Figure 11: Effect of including the ∣∣VχE(x) ||2 term in the writing loss (3) on Omniglot.
