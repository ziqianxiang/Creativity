Figure 1: Overall idea of the proposed meta-sampling frame-work. The task is denoted with T. The two components andspecific inputs will be described in details.
Figure 2: Roll-out architecture of the proposed NIAF as ameta sampler, consisting of a generator G and an autore-gressive conditional model T(∙;ψ). The meta samples arethen fed to a task network C(∙; W) to encode uncertaintyinto specific tasks such as classification. Please see detaileddescriptions in the text.
Figure 3: Convergence of meta-sampling different Gaussian mixture models. SGLD-m and SVGD-mare SGLD and SVGD with the same initialization as DAMS. Other samplers are initialized randomly.
Figure 4: Adaptation efficiency in terms of testing accuracy on CIFAR10 (left) and MNIST (right).
Figure 5: Sample efficiency evaluation with 5%, 20%, 30% of training data on CIFAR10. (see text).
Figure 6: Testing accuracy (left, CIFAR10), uncertainty adaptation evaluation in terms of negativelog-likelihood (middle, CIFAR10) and entropy of out-of-distribution prediction (right) on notMNIST.
Figure 7: Learning curves of 5-way 1-shot classification.
Figure 9: Densities of three Gaussian mixtures.
Figure 13: Meta sampling Bayesian regression for two test tasks (topand bottom). Each row plots posteriors after meta training (left), metatesting (middle, 0.8K (top) and 0.9K (bottom) iterations) and re-training(right, 0.8K (top) and 0.9K (bottom) iterations).
Figure 10: Comparison among different samplers on adapting to Mixture of 4-Gaussian. Top toBottom row: DAMS, SGLD-m, SVGD-m, SVGD, SGLD and NNSGHMC19Published as a conference paper at ICLR 2020Figure 11: Comparison among different samplers on adapting to Mixture of 20-Gaussian. Top toBottom row: DAMS, SVGD, SGLD and NNSGHMC(t, y) are {(0, 0), (2/5, 0), (4/5, 0)}. For the first setting, meta testing consists ofdata {(0, 0), (3/5, 0), (6/5, 0)}. For the second setting, meta testing consists of data{(0, 0), (4/5, 0), (8/5, 0)}. Meta training data corresponds to a posterior with two modes off ∈ {0.0, 5/4}. For the first setting, the test data corresponds to a posterior with threemodes f ∈ {0.0, 5/6, 5/3}. For the second setting, the test data corresponds to four modesf ∈ {0.0, 5/8, 5/4, 15/8}. We compare our DAMS with the result of re-training from scratchwith the test data. Empirical distribution with samples and kernel density estimation are plotted inFigure 13. The first setting takes about 3.4K iterations to find the three modes in the posterior withre-training, while it takes about 0.8K iterations with meta adaptation. For the second setting, it takesmore than 3.6K iterations to find the four modes with training from scratch, while it is about 0.9Kiterations with meta adaptation. For both test tasks, the sampler with re-training miss at least onemode compared with the meta sampler adaptation with the same number of iterations. We can seethat DAMS can adapt the training posterior to the test posterior much faster than re-training fromscratch due to effective uncertainty adaption, obtaining more than 3X speedups.
Figure 11: Comparison among different samplers on adapting to Mixture of 20-Gaussian. Top toBottom row: DAMS, SVGD, SGLD and NNSGHMC(t, y) are {(0, 0), (2/5, 0), (4/5, 0)}. For the first setting, meta testing consists ofdata {(0, 0), (3/5, 0), (6/5, 0)}. For the second setting, meta testing consists of data{(0, 0), (4/5, 0), (8/5, 0)}. Meta training data corresponds to a posterior with two modes off ∈ {0.0, 5/4}. For the first setting, the test data corresponds to a posterior with threemodes f ∈ {0.0, 5/6, 5/3}. For the second setting, the test data corresponds to four modesf ∈ {0.0, 5/8, 5/4, 15/8}. We compare our DAMS with the result of re-training from scratchwith the test data. Empirical distribution with samples and kernel density estimation are plotted inFigure 13. The first setting takes about 3.4K iterations to find the three modes in the posterior withre-training, while it takes about 0.8K iterations with meta adaptation. For the second setting, it takesmore than 3.6K iterations to find the four modes with training from scratch, while it is about 0.9Kiterations with meta adaptation. For both test tasks, the sampler with re-training miss at least onemode compared with the meta sampler adaptation with the same number of iterations. We can seethat DAMS can adapt the training posterior to the test posterior much faster than re-training fromscratch due to effective uncertainty adaption, obtaining more than 3X speedups.
Figure 12: Comparison among different samplers on adapting to Mixture of 6-Gaussian. Top toBottom row: DAMS, SVGD, SGLD and NNSGHMCD.4 Uncertainty evaluation via entropy of out-of-sample predictiveDISTRIBUTIONSWe show the predictive uncertainty of DAMS compared to SGHMC and NNSGHMC by exploringthe posterior of neural parameters, we estimate the uncertainty for out-of-distribution data samplesLakshminarayanan et al. (2017). We train different algorithms on the MNIST dataset, and estimate theentropy of the predictive distribution on the notMNIST dataset Bulatov (2011). We follow Louizos& Welling (2017a) and use the empirical CDF of entropy to evaluate the uncertainty. Since theprobability of observing a high confidence prediction is low, curves that are nearer to the bottom rightof the figure estimates uncertainty better. The predictive distribution of the trained model is expectedto be uniform over the notMNIST digits as the samples from the dataset are from unseen classes. TheBNN is a CNN with 16 and 50 filters whose kernel sizes are 5 and 5 for the two convolutional layers,respectively. The hidden units of the fully connected layer is 300. The uncertainty evaluation resultsare shown in the right plot of Figure 6.
