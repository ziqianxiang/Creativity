Figure 1: (a) Throughout (iterations per second) in inference procedure using different Normaliza-tion methods. The implementation details can be seen in appendix B.2. (b)ImageNet classificationvalidation error vs. batch sizes.
Figure 2: Plot of batch statistics from layer1.0.bn1 in ResNet-50 during training. The formulation ofthese batch statistics (μB, σB, gB, Ψb) have been shown in Section 3.1. Blue line represents the smallbatch statistic (|B| = 2) to compute, while orange line represents the regular batch statistics(|B| =32). The x-axis represents the iterations, while the y-axis represents the l2 norm of these statistics ineach figures. Notice the mean of g and Ψ is close to zero, hence l2 norm of gB and ΨB essentiallyrepresent their standard deviation.
Figure 3: Plot of batch statistics from layer1.0.bn1 in ResNet-50 with a modified structure duringtraining. The formulation of these batch statistics ( χ2B, ΨB) is shown in section 4.2, 3.1 respectively.
Figure 4: Plot of batch statistics from layer1.0.bn1 in ResNet-50 with MABN. The formulation ofthese batch statistics ( χ2B, ΨB) is shown in section 4.2, 3.1 respectively. Blue line represents theSMA batch statistic(2+30), while orange line represents the regular batch statistics(32). We use themoving average batch statistics to update the network parameters.
