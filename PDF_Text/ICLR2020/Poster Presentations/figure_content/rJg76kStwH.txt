Figure 1: Overview of our method for combining MLN and GNN using the variational EM framework.
Figure 2: Bottom: A knowledgebase as a factor graph. {A, C, D}are entities, and F (Friend) andS (Smoke) are predicates. Top:Markov Logic Network (MLN)with formula f(c,c0) := -S(C) V—F(c, c0) V S(c0). Shaded circlescorrespond to latent variables.
Figure 3: Bottom: A knowledgebase with 0-1-0-1 loop. Top: MLN.
Figure 4: Left / Right: Inference time on UW-CSE / Kinship respectively. N/A indicates the method is infeasible.
Figure 5: Example 1. Top: Knowledge base. Bottom: MLNUnlike the example shown in main text, where A and B have OPPOSITE relation with E, Fig. 5shows a very simple example where A and B have exactly the same structure which makes A and Bindistinguishable and isomorphic. However, since (A,E) and (B,E) are not isomorphic, it can be easilyseen that L(A, E) has different posterior from L(B, E).
Figure 6: The same example as in Fig. 3. Top: Knowledge base. Bottom: MLNFig. 6 shows an example which is the same as in Fig. 3. However, in this example, it is alreadyrevealed in the knowledge base that (A, E) and (B, E) have different local structures as they areconnected by different observations. That is, (A, [F(A, E) = 1] , E) and (B, [F(B, E) = 0] , E) can bedistinguished by GNN.
Figure 7: Example 2. Top: Knowledge base. Bottom: MLNIn Fig. 7, (A, E) and (C, H) have the same local structure, so that the tuple (A, [F(A, E) = 1] , E) and(C, [F(C, H) = 1] , H) can NOT be distingushed by GNN. However, we can make use of subgraph(A, E, B, F) to define a formula, and then the resulting MLN gives different posterior to L(A, E) andL(C, H), as can be seen from the figure. Note that this construction of MLN is the same as theconstruction steps stated in the proof in Sec. E.
Figure 8: An example of the factor graphfor the logic formula -Husband (X,Y) ∨-Mother(Y,Z) ∨ Daughter(Z,X).
