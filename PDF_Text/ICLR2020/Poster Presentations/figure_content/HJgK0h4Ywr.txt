Figure 1: Differences in probabilistic assumption of MIG and Robust MIG.
Figure 2: The informativeness and the total information of some FactorVAE and β-VAE models. Foreach hyperparameter, we report the mean and the standard error of 4 different runs.
Figure 3: I(zi,z6=i),WSEPINandSEPIN@3 of some FactorVAE and β-VAE models.
Figure 4:	Visualization of the representations learned by representative FactorVAE, VAE, and β-VAEmodels with separability (I (zi , z6=i)) and informativeness (I (zi , x)) scores. Representations aresorted by their separability scores.
Figure 5:	(a) and (b): Unnormalized JEMMIG and RMIG scores of several FactorVAE and β-VAEmodels. (c): Correlation between JEMMIG and RMIG.
Figure 6:	Comparison between JEMMIG/RMIG and the metrics in (Eastwood & Williams, 2018).
Figure 7: “disentanglement”, “completeness” and “informativeness” (error) scores of several Factor-VAE and β-VAE models.
Figure 8: (a): Comparison between JEMMIG and “modularity” (#bins=100). (b) and (c): “modularity”scores of several FactorVAE and β-VAE models. The original version computes I(zi,yk) usingEq(zi∣χ)[zi] while the correct version compute I(zi, yk) using q(zi∣x).
Figure 9: Normalized informativeness scores (bins=100) of all latent variables sorted in descendingorder.
Figure 10: Visualization of the top informative representations. Scores are unnormalized.
Figure 11: Normalized MISJED scores of all latent pairs sorted by their informativeness.
Figure 12: Top 5 representations that are most correlated with some ground truth factors. For eachrepresentation, we show its mutual information with the ground truth factor.
Figure 13: Normalized JEMMIG and RMIG scores for all attributes in the CelebA dataset. We sortedthe JEMMIG and RMIG scores of the FactorVAE in ascending and descending orders, respectively.
Figure 14: Normalized informativeness scores (bins=100) of all latent variables sorted in descendingorder.
Figure 15: Normalized MISJED scores (bins=100) of all latent pairs sorted by their informativeness.
Figure 16: Top 3 representations sorted by their mutual information with different ground truthfactors.
Figure 17:	Dependences OfRMIG (normalized), JEMMIG (normalized) and 志 PK=-01 H(zi*,yk)on the number of bins. The dataset is dSprite.
Figure 18:	Dependences of JEMMIG and WSEPIN on the number of samples. All models have 10latent variables. The dataset is dSprites.
Figure 19:	Dependences of various quantitative measures on the number of latents. All measures arecomputed via sampling. The model used in this experiment is β-VAE with β = 10.
Figure 20: Correlation matrix of representations learned by FactorVAE, β-VAE and AAE.
Figure 21: Illustration of representations learned by AAE and FactorVAE. A big red circle representsthe total amount of information that x contains orH(x) which is limited by the amount of training data.
Figure 22: Distribution of Eq(Zi∣χ(n)) [zi] over all x(n)〜PD(x) of a particular representation Zi fordifferent AAE models.
Figure 23: (a): Our mutual information matrix I(zi, yk), (b): The mutual information matrixI(zi, yk) in (Ridgeway & Mozer, 2018), (c): The importance matrix Rik in (Eastwood & Williams,2018). In (a) and (b), the columns corresponding to the following ground truth factors: “shape”,“scale”, “rotation”, “x-position”, “y-position”. In (c), the column for “shape” is excluded because themetrics in (Eastwood & Williams, 2018) do not support categorical factors. Values corresponding todisentangled representations are highlighted in red. Defective values are highlighted in green. Themodel is FactorVAE with TC=20.
Figure 24: Correlation between the sampling (#samples=10000) and quantized (value range=[-4, 4],#bins=100) estimations of JEMMIG/RMIG. In the subplot (a), the red line is y = x - log(bin width)while in the subplot (b), the red line is y = x. Blues denotes FactorVAE models and oranges denotesβ-VAE models. The dataset is dSprites.
Figure 25: Left: Correlation between our RMIG (#bins=100) and the original MIG (Chen et al., 2018)(#samples=10000). Right: Correlation between our RMIG (#bins=100) and the implementation ofMIG in (Locatello et al., 2019) (#bins=100). Experiments are conducted on the dSprites dataset.
Figure 26: Random traversal on the latent space of FactorVAE. We can easily see the visual resem-blance among image regions corresponding the same number.
Figure 27:	Top 10 representations sorted by the variance of the distribution of Eq(z |x(n)) [zi] over allx(n) .
Figure 28:	Top 10 representations sorted by informativeness scores. We can clearly see the consistencyof representations across different runs.
