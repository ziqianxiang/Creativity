Figure 1: The need for semi-supervised anomaly detection: The training data (shown in (a)) consistsof (mostly normal) unlabeled data (gray) as well as a few labeled normal samples (blue) and labeledanomalies (orange). Figures (b)-(f) show the decision boundaries of the various learning paradigmsat testing time along with novel anomalies that occur (bottom left in each plot). Our semi-supervisedAD approach takes advantage of all training data: unlabeled samples, labeled normal samples, aswell as labeled anomalies. This strikes a balance between one-class learning and classification.
Figure 2: Results of scenario (i), where we increase the ratio of labeled anomalies γl in the trainingset. We report avg. AUC with st. dev. over 90 experiments at various ratios γl . A “?” indicates astatistically significant (α = 0.05) difference between the 1st and 2nd best method.
Figure 3: Results of scenario (ii), where we pollute the unlabeled part of the training set with (un-known) anomalies. We report avg. AUC with st. dev. over 90 experiments at various ratios γp . A“?” indicates a statistically significant (α = 0.05) difference between the 1st and 2nd best method.
Figure 4: Results of scenario (iii), where we increase the number of anomaly classes kl included inthe labeled training data. We report avg. AUC with st. dev. over 100 experiments for various kl. A“?” indicates a statistically significant (α = 0.05) difference between the 1st and 2nd best method.
Figure 5: Deep SAD sensitivity analysis w.r.t. η.
Figure 6: Sensitivity analysis w.r.t. the network representation dimensionality d for our Deep SADmethod and the closest competitor hybrid SSAD. We report avg. AUC with st. dev. over 90 experi-ments for various values of d.
Figure 7:	AUC scatterplots of best (1st) vs. second best (2nd) performing methods in experimentalscenario (i) on CIFAR-10, where we increase the ratio of labeled anomalies γl in the training set.
Figure 8:	AUC scatterplots of best (1st) vs. second best (2nd) performing methods in experimentalscenario (ii) on CIFAR-10, where we pollute the unlabeled part of the training set with (unknown)anomalies at various ratios γp .
Figure 9: AUC scatterplotsscenario (iii) on CIFAR-10labeled training data.
