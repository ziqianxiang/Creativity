Figure 1:	Label precision (%) of Self-training and three LECs on CIFAR-10 with random labelnoise. We plot the average as a solid line and the standard deviation as a shadow around the line.
Figure 2:	Label precision (%) of small-loss examples of the current network (in green) andthe intersection of small-loss examples of the current and preceding networks (in red) duringrunning LTEC on CIFAR-10 with random label noise. We report the precision from epoch 11 whenthe filtering process starts.
Figure 3: Test accuracy (%) of different algorithms on MNIST/CIFAR with random label noise.
Figure 4: Label precision (%) of different algorithms on MNIST/CIFAR with random label noise.
Figure 5: Recall (%) of LTEC and LTEC-full on CIFAR-10 with random label noise. We plot theaverage as a solid line and the standard deviation as a shadow around the line.
Figure A1: Corruption matrices of CIFAR-10 with random label noise and semantic noise.
Figure A2: Clean examples (top) and noisy examples (bottom) randomly sampled from CIFAR-10 with 20% semantic noise. We observe that noisy examples contain atypical features and aresemantically mislabeled.
Figure A3: Recall (%) of LTECs with varying M on CIFAR-10 with random label noise.
