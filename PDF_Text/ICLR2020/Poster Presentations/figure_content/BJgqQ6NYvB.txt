Figure 1: The multi-resolution branching search space for FasterSeg, where we aim to optimize multiplebranches with different output resolutions. These outputs are progressively aggregated together in the headmodule. Each cell is individually searchable and may have two inputs and two outputs, both of differentdownsampling rates (s). Inside each cell, we enable searching for expansion ratios within a single superkernel.
Figure 2: Our multi-resolution search spacecovers existing manual designs for real-timesegmentation (unused cells omitted). Top: IC-Net (Zhao et al., 2018). Bottom: BiSeNet (Yuet al., 2018a)We follow the convention to increase the number of channels at each time of resolution downsam-pling. To enlarge the model capacity without incurring much latency, we first downsample the inputimage to 8 original scale with our stem module, and then set our searchable downsample ratess ∈ {8, 16, 32}. Figure 2 shows that our multi-resolution search space is able to cover existinghuman-designed networks for real-time segmentation. See Appendix B for branch selection details.
Figure 3: Correlation between networklatency and its estimation via our la-tency lookup table (linear coefficient:0.993). Red line indicates “y = x”.
Figure 4: Comparing mIoU (%) and latency (ms) between supernets. The search is conducted on the Cityscapestraining set and mIoU is measured on the validation set.
Figure 5: Our co-searching framework,which optimizes two architectures dur-ing search (left orange) and distills froma complex teacher to a light student dur-ing training from scratch (right green).
Figure 6: FasterSeg network discovered by our NAS framework.
Figure 7: Visualization on Cityscapes validation set. Columns from left to right correspond to original images,ground truths, and results of "O, s∣χ = 8,b = 1", "O, s∣χ = 8,b = 2”, "T T pruned T”, FasterSeg (seeTable 3 for annotation details). Best viewed in color.
