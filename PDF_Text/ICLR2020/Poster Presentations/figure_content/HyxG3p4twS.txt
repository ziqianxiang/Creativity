Figure 1: A generic end-to-end trainable model of photo acquisition and dissemination: camera ISPis modeled by a neural imaging pipeline (NIP); manipulation detection is performed by a forensicanalysis network (FAN); the channel may use either JPEG or a trainable deep compression network(DCN). Potentially trainable elements are shown in yellow.
Figure 2: Architecture of our deep compression network: an auto-encoder with 3 sub-samplingstages and residual units in between. (Empty arrows: no activation; filled arrows: leaky ReLU.)dard JPEG compression, and we extended it to support trainable codecs. We show a generic versionof the updated model in Fig. 1 with highlighted potentially trainable elements. In this study, wefixed the camera model, and jointly optimize the FAN and a deep compression network (DCN). Wedescribe the design of our DCN codec, and its pre-training protocol below.
Figure 3:	Entropy estimation error for a Laplacian distribution with varying scale and for the latentspace of 128 × 128 px images. The t-Student kernel is significantly more accurate - especially forwide distributions overflowing the codebook range.
Figure 4:	Example images from the considered clic, kodak and raw test sets (512×512 px).
Figure 5: Rate-distortion trade-offs on the clic, kodak and raw test sets. (See Fig. A.5 for MS-SSIM).
Figure 7: Subtle photo manipulation: (left) 128×128 px native patch; (rest) various post-processing.
Figure 8: The rate-distortion-accuracy trade-off (raw test Set) reveals significant improvements inmanipulation detection accuracy while maintaining similar rate-distortion performance.
Figure 9: Visualization of frequency attenuation/amplification patterns in the FFT domain for thefine-tuned DCN codec (low-quality, 16-C model).
Figure 10: Compression results for various versions of the low-quality DCN: (1st column) originalimage; (2nd) pre-trained model; (3rd-6th) fine-tuned models with decreasing λc .
