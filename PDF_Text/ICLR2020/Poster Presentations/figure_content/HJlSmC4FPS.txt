Figure 1: First-order analysis of the residual of a denoising convolutional neural network as a functionof noise level. The plots show the norms of the residual and the net bias averaged over 100 20 × 20natural-image patches for networks trained over different training ranges. The range of noises usedfor training is highlighted in blue. (a) When the network is trained over the full range of noise levels(σ ∈ [0, 100]) the net bias is small, growing slightly as the noise increases. (b-c) When the network istrained over the a smaller range (σ ∈ [0, 55] and σ ∈ [0, 30]), the net bias grows explosively for noiselevels beyond the training range. This coincides with a dramatic drop in performance, reflected in thedifference between the magnitudes of the residual and the true noise. The CNN used for this exampleis DnCNN (Zhang et al., 2017); using alternative architectures yields similar results as shown inFigure 8.
Figure 2: Denoising of an example natural image by a CNN and its bias-free counterpart (BF-CNN),both trained over noise levels in the range σ ∈ [0, 10] (image intensities are in the range [0, 255]).
Figure 3: Comparison of the performance of a CNN and a BF-CNN with the same architecture forthe experimental design described in Section 5. The performance is quantified by the PSNR of thedenoised image as a function of the input PSNR. Both networks are trained over a fixed ranges ofnoise levels indicated by a blue background. In all cases, the performance of BF-CNN generalizesrobustly beyond the training range, while that of the CNN degrades significantly. The CNN used forthis example is DnCNN (Zhang et al., 2017); using alternative architectures yields similar results (seeFigures 11 and 12).
Figure 4: Visualization of the linear weighting functions (rows of Ay in equation 4) of a BF-CNN forthree example pixels of an input image, and three levels of noise. The images in the three rightmostcolumns show the weighting functions used to compute each of the indicated pixels (red squares).
Figure 5: Analysis of the SVD of the Jacobian of a BF-CNN for ten natural images, corruptedby noise of standard deviation σ = 50. (a) Singular value distributions. For all images, a largeproportion of the values are near zero, indicating (approximately) a projection onto a subspace (thesignal subspace). (b) Histogram of dot products (cosine of angle) between the left and right singularvectors that lie within the signal subspaces. (c) Effective dimensionality of the signal subspaces(computed as sum of squared singular values) as a function of noise level. For comparison, thetotal dimensionality of the space is 1600 (40 × 40 pixels). Average dimensionality (red curve) fallsapproximately as the inverse of σ (dashed curve). The CNN used for this example is DnCNN (Zhanget al., 2017); using alternative architectures yields similar results (see Figure 17).
Figure 6: Visualization of left singular vectors of the Jacobian of a BF-CNN, evaluated on twodifferent images (top and bottom rows), corrupted by noise with standard deviation σ = 50. The leftcolumn shows original (clean) images. The next three columns show singular vectors correspondingto non-negligible singular values. The vectors capture features from the clean image. The last threecolumns on the right show singular vectors corresponding to singular values that are almost equal tozero. These vectors are noisy and unstructured. The CNN used for this example is DnCNN (Zhanget al., 2017); using alternative architectures yields similar results (see Figure 16).
Figure 7: Signal subspace properties. Left: Signal subspace, computed from Jacobian of a BF-CNNevaluated at a particular noise level, contains the clean image. Specifically, the fraction of squared `2norm preserved by projection onto the subspace is nearly one as σ grows from 10 to 100 (relative tothe image pixels, which lie in the range [0, 255]). Results are averaged over 50 example clean images.
Figure 8: First-order analysis of the residual of Recurrent-CNN (Section A.2), UNet (Section A.3)and DenseNet (Section A.4) as a function of noise level. The plots show the magnitudes of theresidual and the net bias averaged over 68 images in Set68 test set of Berkeley Segmentation Dataset(Martin et al., 2001) for networks trained over different training ranges. The range of noises usedfor training is highlighted in gray. (left) When the network is trained over the full range of noiselevels (σ ∈ [0, 100]) the net bias is small, growing slightly as the noise increases. (middle and right)When the network is trained over the a smaller range (σ ∈ [0, 55] and σ ∈ [0, 30]), the net bias growsexplosively for noise levels outside the training range. This coincides with the dramatic drop inperformance due to overfitting, reflected in the difference between the residual and the true noise.
Figure 9: Visualization of the decomposition of output of DnCNN trained for noise range [0, 55] intolinear part and net bias. The noise level σ = 70 (highlighted by *) is outside the training range. Overthe training range, the net bias is small, and the linear part is responsible for most of the denoisingeffort. However, when the network is evaluated out of the training range, the contribution of the biasincreases dramatically, which coincides with a significant drop in denoising performance.
Figure 10: Visualization of the decomposition of output of Recurrent-CNN (Section A.2, UNet(Section A.3) and DenseNet (Section A.4) trained for noise range [0, 55] into linear part and net bias.
Figure 11: Comparisons of architectures with (red curves) and without (blue curves) a net bias forthe experimental design described in Section 5. The performance is quantified by the PSNR ofthe denoised image as a function of the input PSNR of the noisy image. All the architectures withbias perform poorly out of their training range, whereas the bias-free versions all achieve excellentgeneralization across noise levels. (a) Deep Convolutional Neural Network, DnCNN (Zhang et al.,2017). (b) Recurrent architecture inspired by DURR (Zhang et al., 2018a). (c) Multiscale architectureinspired by the UNet (Ronneberger et al., 2015). (d) Architecture with multiple skip connectionsinspired by the DenseNet (Huang et al., 2017).
Figure 12: Comparisons of architectures with (red curves) and without (blue curves) a net biasfor the experimental design described in Section 5. The performance is quantified by the SSIM ofthe denoised image as a function of the input SSIM of the noisy image. All the architectures withbias perform poorly out of their training range, whereas the bias-free versions all achieve excellentgeneralization across noise levels. (a) Deep Convolutional Neural Network, DnCNN (Zhang et al.,2017). (b) Recurrent architecture inspired by DURR (Zhang et al., 2018a). (c) Multiscale architectureinspired by the UNet (Ronneberger et al., 2015). (d) Architecture with multiple skip connectionsinspired by the DenseNet (Huang et al., 2017).
Figure 13: Visualization of the linear weighting functions (rows of Ay) of Bias-Free Recurrent-CNN(top 2 rows) (Section A.2), Bias-Free UNet (next 2 rows) (Section A.3) and Bias-Free DenseNet(bottom 2 rows) (Section A.4) for three example pixels of a noisy input image (left). The nextimage is the denoised output. The three images on the right show the linear weighting functionscorresponding to each of the indicated pixels (red squares). All weighting functions sum to one, andthus compute a local average (although some weights are negative, indicated in red). Their shapesvary substantially, and are adapted to the underlying image content. Each row corresponds to a noisyinput with increasing σ and the filters adapt by averaging over a larger region.
Figure 14: Visualization of the linear weighting functions (rows of Ay) of a BF-DnCNN for threeexample pixels of a noisy input image (left). The next image is the denoised output. The threeimages on the right show the linear weighting functions corresponding to each of the indicated pixels(red squares). All weighting functions sum to one, and thus compute a local average (althoughsome weights are negative, indicated in red). Their shapes vary substantially, and are adapted to theunderlying image content. Each row corresponds to a noisy input with increasing σ and the filtersadapt by averaging over a larger region.
Figure 15: Visualization of the linear weighting functions (rows of Ay) of Bias-Free Recurrent-CNN(top 2 rows) (Section A.2), Bias-Free UNet (next 2 rows) (Section A.3) and Bias-Free DenseNet(bottom 2 rows) (Section A.4) for three example pixels of a noisy input image (left). The nextimage is the denoised output. The three images on the right show the linear weighting functionscorresponding to each of the indicated pixels (red squares). All weighting functions sum to one, andthus compute a local average (although some weights are negative, indicated in red). Their shapesvary substantially, and are adapted to the underlying image content. Each row corresponds to a noisyinput with increasing σ and the filters adapt by averaging over a larger region.
Figure 16: Visualization of left singular vectors of the Jacobian of a BF Recurrent CNN (top 2rows), BF UNet (next 2 rows) and BF DenseNet (bottom 2 rows) evaluated on three different images,corrupted by noise with standard deviation σ = 25. The left column shows original (clean) images.
Figure 17: Analysis of the SVD of the Jacobian of BF-CNN for ten natural images, corrupted bynoise of standard deviation σ = 50. For all images, a large proportion of the singular values are nearzero, indicating (approximately) a projection onto a subspace (the signal subspace). (a) Recurrentarchitecture inspired by DURR (Zhang et al., 2018a). (b) Multiscale architecture inspired by theUNet (Ronneberger et al., 2015). (c) Architecture with multiple skip connections inspired by theDenseNet (Huang et al., 2017).
Figure 18: Comparison of the performance of a CNN and a BF-CNN with the same architecture forthe experimental design described in Section 5. The networks are trained using i.i.d. Gaussian noisebut evaluated on noise drawn i.i.d. from a uniform distribution with mean 0. The performance isquantified by the PSNR of the denoised image as a function of the input PSNR of the noisy image. Allthe architectures with bias perform poorly out of their training range, whereas the bias-free versionsall achieve excellent generalization across noise levels, i.e. they are able to generalize across the twodifferent noise distributions. The CNN used for this example is DnCNN (Zhang et al., 2017); usingalternative architectures yields similar results (see Figures 19).
Figure 19: Comparisons of architectures with (red curves) and without (blue curves) a net bias forthe experimental design described in Section 5. The networks are trained using i.i.d. Gaussian noisebut evaluated on noise drawn i.i.d. from a uniform distribution with mean 0. The performance isquantified by the PSNR of the denoised image as a function of the input PSNR of the noisy image. Allthe architectures with bias perform poorly out of their training range, whereas the bias-free versionsall achieve excellent generalization across noise levels, i.e. they are able to generalize across thetwo different noise distributions. (a) Deep Convolutional Neural Network, DnCNN (Zhang et al.,2017). (b) Recurrent architecture inspired by DURR (Zhang et al., 2018a). (c) Multiscale architectureinspired by the UNet (Ronneberger et al., 2015). (d) Architecture with multiple skip connectionsinspired by the DenseNet (Huang et al., 2017).
Figure 20: Comparison of the performance of DnCNN and a corresponding BF-CNN for imagerestoration. Training is carried out on data corrupted with Gaussian noise σnoise ∈ [0, 55] and Gaussianblur σblur ∈ [0, 4]. Performance is measured on test data for inside and outside the training ranges.
