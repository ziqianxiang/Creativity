Figure 1: On top, two predictors(green) were trained to fit two randomly-generated priors (red). On the bottom, weobtain uncertainties from the differencebetween predictors and priors. Dots cor-respond to training points xi .
Figure 2: Architecture of the random prior networks f and predictor networks hXf . The predictornetworks hXf typically share the same architectural core, but have additional layers relative to theprior networks. Both the green and red parts of the predictor networks are trained.
Figure 3: Distribution of uncertainty estimates for various algorithms. Top row shows seen data,bottom row shows unseen data from CIFAR-10. For random priors (RP), uncertainties are ^. Forother algorithms, they are 1 - max(p*), where pμ is the averaged output of models in ensemble(Lakshminarayanan et al., 2017).
Figure 4: Calibration curves showing the relationship between uncertainty (horizontal axis) andaccuracy (vertical axis) for B = 1, 5, 10 on CIFAR-10.
Figure 5: The relationship between uncertainty (horizontal axis) and accuracy (vertical axis) forB =1, 5, 10 on a subset of75 samples from CIFAR-10. In well-calibrated models, accuracy increases asuncertainty declines.
Figure 6: Distribution of uncertainty estimates for various algorithms. Top row shows seen data,bottom row shows unseen data from CIFAR-10, where we trained on a sample of 75 images fromthe training set. For random priors (RP), uncertainties are σ2. For other algorithms, they are 1 -max(pμ), where pμ is the averaged output of models in ensemble (Lakshminarayanan et al., 2017).
Figure 7: Robustnessof OOD perfromanceto initialization scale.
Figure 8: Distribution of uncertainty estimates for various algorithms. Top row shows seen data,bottom row shows unseen data from CIFAR-100. For random priors (RP), uncertainties are σ2. Forother algorithms, they are 1 - max(p*), where pμ is the averaged output of models in ensemble(Lakshminarayanan et al., 2017).
Figure 9: The relationship between uncertainty (horizontal axis) and accuracy (vertical axis) for B =1, 5, 10 on samples from CIFAR-100. In well-calibrated models, accuracy increases as uncertaintydeclines.
