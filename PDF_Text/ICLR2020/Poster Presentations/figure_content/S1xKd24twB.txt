Figure 1: Average reward on 100 episodes after training.
Figure 2: Image-based Atari. Smoothed with a rolling window of 100 episodes. Standard erroron three random seeds. X-axis represents amount of interaction with the environment (not expertdemonstrations).
Figure 3: SQIL: best per-formance on 10 consecutivetraining episodes. BC, GAIL:results from Dhariwal et al.
Figure 4: Best success rate on 100 consecutive episodes dur-ing training. Standard error on five random seeds. Perfor-mance bolded if at least within one standard error of expert.
Figure 5:	Image-based Car Racing. Average reward on 100 episodes after training. Standard erroron three random seeds.
Figure 6:	Image-based Atari. Smoothed with a rolling window of 100 episodes. Standard erroron three random seeds. X-axis represents amount of interaction with the environment (not expertdemonstrations).
Figure 7: Low-dimensional Lunar Lander. Best success rate on 100 consecutive episodes duringtraining. Standard error on five random seeds. Performance bolded if at least within one standarderror of expert.
Figure 8: Standard error over two random seeds. No smoothing across training steps.
