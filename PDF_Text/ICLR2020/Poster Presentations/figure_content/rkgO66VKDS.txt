Figure 1: Computation of a low precision convolution or fully connected layer, as envisioned here.
Figure 2: Given s = 1, QN = 0, QP = 3, A) quantizer output and B) gradients of the quantizeroutput with respect to step size, s, for LSQ, or a related parameter controlling the width of thequantized domain (equal to s(QP + QN)) for QIL (Jung et al., 2018) and PACT (Choi et al., 2018b).
Figure 3: Accuracy vs. model size for the networks considered here show some 2-bit networksprovide the highest accuracy at a given model size. Full precision model sizes are inset for reference.
Figure 4: Relative parameter update magnitudes given different step size gradient scales. A gradientscale of 1âˆ•nwQP better balances relative step size and weight gradient magnitudes (right vs. left).
