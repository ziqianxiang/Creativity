Figure 1: Accuracy of IMP when rewinding tovarious iterations of the early phase for ResNet-20 sub-networks as a function of sparsity level.
Figure 2: Rough timeline of the early phase of training for ResNet-20 on CIFAR-10.
Figure 4: Performance of an IMP-derived sub-network of ResNet-20 on CIFAR-10 initialized to thesigns at iteration 0 or k and the magnitudes at iteration 0 or k. Left: k = 500. Right: k = 2000.
Figure 3: Basic telemetry about the state of ResNet-20 during the first 4000 iterations (10 epochs).
Figure 5: Performance of an IMP-derived ResNet-20 sub-network on CIFAR-10 initialized with theweights at iteration k permuted within various structural elements. Left: k = 500. Right: k = 2000.
Figure 6: The effect of training an IMP-derived sub-network of ResNet-20 on CIFAR-10 initializedwith the weights at iteration k as shuffled within various structural elements where shuffling onlyoccurs between weights with the same sign. Left: k = 500. Right: k = 2000.
Figure 7: The effect of training an IMP-derived sub-network of ResNet-20 on CIFAR-10 initializedwith the weights at iteration k and Gaussian noise of nσ, where σ is the standard deviation of theinitialization distribution for each layer. Left: k = 500. Right: k = 2000.
Figure 8: The effective standard deviation of various perturbations as a function of mean evaluationaccuracy (across 5 seeds) at sparsity 26.2%. The mean of each perturbation was approximately 0.
Figure 9: The effect of pre-training ResNet-20 on CIFAR-10 with random labels, self-supervisedrotation, 4x blurring, and 4x blurring and self-supervised rotation.
Figure 10: The effect of pretraining sparse sub-networks of Resnet-20 (rewound to iteration 500)with 40 epochs of self-supervised rotation before training on CIFAR-10.
Figure A1: Rough timeline of the early phase of training for ResNet-18 on CIFAR-10, includingresults from previous papers.
Figure A2: The effect of IMP rewinding iteration on the accuracy of sub-networks at various levelsof sparsity. Accompanies Figure 1.
Figure A3: Basic telemetry about the state of all networks in Table A1 during the first 4000 iterationsof training. Accompanies Figure 3.
Figure A5: The effect of training an IMP-derived sub-network initialized with the weights at itera-tion k as shuffled within various structural elements. Accompanies Figure 5.
Figure A6: The effect of training an IMP-derived sub-network initialized with the weights at iter-ation k as shuffled within various structural elements where shuffling only occurs between weightswith the same sign. Accompanies Figure 6.
Figure A7: The effect of training an IMP-derived sub-network initialized with the weights at itera-tion k and Gaussian noise of nσ, where σ is the standard deviation of the initialization distributionfor each layer. Accompanies Figure 7.
Figure A8: The effective standard deviation of each of the perturbations studied in Section 5 as afunction of mean evaluation accuracy (across five seeds). Accompanies Figure 8.
Figure A9: The effect of pre-training CIFAR-10 with random labels. Accompanies Figure 9.
