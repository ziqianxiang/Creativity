Figure 2: (a) IMD distances between language pairs for unaligned Wikipedia word embeddings and(b) distances from the simple English Wikipedia visualized for IMD, FID, and KID. We consider 16languages: Polish, Russian, Greek, Hungarian, Turkish, Arabic, Hebrew, English, Simple English,Swedish, German, Spanish, Dutch, Portugese, Vietnamese, and Waray-Waray.
Figure 3: Comparison of IMD and PIP loss onword embeddings of different dimension. IMDdetects subtle changes in the dimensionality.
Figure 4: (left) IMD score across convolutional layers of the VGG-16 network on CIFAR-10 andCIFAR-100 datasets; (right) training progression in terms of accuracy (dotted) and IMD (solid) onCIFAR-10 and CIFAR-100 datasets for VGG-16 and ResNet-20, with respect to VGG-16.
Figure 5: FID, KID and IMD on theCIFAR-10 dataset with Gaussian blur.
Figure 6: Plotting the normalized heattrace allows interpretation of medium- andglobal-scale structure of datasets. Bestviewed in color.
Figure 7: Stability and scalability experiment: (left) stability of FID, KID and IMD wrt. sample sizeon CIFAR-10 and CIFAR-100 dataset; (right) scalability of FID, KID and IMD wrt. sample size onsynthetic datasets.
Figure 8: Errors (solid) and errorbounds (dotted) for the approximation ofmatrix exponential action with varyingtemperature t.
Figure 9:	Trace estimation errors (solid) and error bounds (dotted) for: (left) the number of Lanczossteps m with fixed number of random vectors nv = 100; (right) the number of random vectors nvin Hutchinson estimator with fixed number of Lanczos steps m = 10. Lines correspond to varyingtemperatures t.
Figure 10:	Bad GAN producesWe provide an additional experiment clearly showing the case samples inside the torus holewhere IMD is superior to its main competitors, FID and KID. (red). FID and KID cannot detectWe train two vanilla GANs on the points of a 3D torus. The bad such behaviour.
Figure 11: FID and KID are not able to capture language affinity from unaligned word2vecembeddings.
Figure 12: Variance of the trace estimate.
Figure 13: CIFAR-10 graph colored withtrue class labels.
Figure 14: MNIST samples (left: WGAN, right: WGAN-GP).â…œt AiA*n naFigure 16: CIFAR-10 samples (left: WGAN, right: WGAN-GP)Figure 15: FashionMNIST samples (left: WGAN, right: WGAN-GP)Figure 17: CelebA samples (left: WGAN, right: WGAN-GP)17Published as a conference paper at ICLR 2020MNIST WGANCOnvGenerator((latent_to_features): Sequential((0): Linear(in_features=100, out_features=512, bias=True)(1): ReLU())(features_to_image): Sequential((0): ConvTranspose2d(128, 64, kernel_size=(4, 4),stride=(2, 2), padding=(1, 1))(1): ReLU()(2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)(3): ConvTranspose2d(64, 32, kernel_size=(4, 4),stride=(2, 2), padding=(1, 1))
Figure 16: CIFAR-10 samples (left: WGAN, right: WGAN-GP)Figure 15: FashionMNIST samples (left: WGAN, right: WGAN-GP)Figure 17: CelebA samples (left: WGAN, right: WGAN-GP)17Published as a conference paper at ICLR 2020MNIST WGANCOnvGenerator((latent_to_features): Sequential((0): Linear(in_features=100, out_features=512, bias=True)(1): ReLU())(features_to_image): Sequential((0): ConvTranspose2d(128, 64, kernel_size=(4, 4),stride=(2, 2), padding=(1, 1))(1): ReLU()(2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)(3): ConvTranspose2d(64, 32, kernel_size=(4, 4),stride=(2, 2), padding=(1, 1))(4): ReLU()(5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)
Figure 15: FashionMNIST samples (left: WGAN, right: WGAN-GP)Figure 17: CelebA samples (left: WGAN, right: WGAN-GP)17Published as a conference paper at ICLR 2020MNIST WGANCOnvGenerator((latent_to_features): Sequential((0): Linear(in_features=100, out_features=512, bias=True)(1): ReLU())(features_to_image): Sequential((0): ConvTranspose2d(128, 64, kernel_size=(4, 4),stride=(2, 2), padding=(1, 1))(1): ReLU()(2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)(3): ConvTranspose2d(64, 32, kernel_size=(4, 4),stride=(2, 2), padding=(1, 1))(4): ReLU()(5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)(6): ConvTranspose2d(32, 16, kernel_size=(4, 4),
Figure 17: CelebA samples (left: WGAN, right: WGAN-GP)17Published as a conference paper at ICLR 2020MNIST WGANCOnvGenerator((latent_to_features): Sequential((0): Linear(in_features=100, out_features=512, bias=True)(1): ReLU())(features_to_image): Sequential((0): ConvTranspose2d(128, 64, kernel_size=(4, 4),stride=(2, 2), padding=(1, 1))(1): ReLU()(2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)(3): ConvTranspose2d(64, 32, kernel_size=(4, 4),stride=(2, 2), padding=(1, 1))(4): ReLU()(5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)(6): ConvTranspose2d(32, 16, kernel_size=(4, 4),stride=(2, 2), padding=(1, 1))
