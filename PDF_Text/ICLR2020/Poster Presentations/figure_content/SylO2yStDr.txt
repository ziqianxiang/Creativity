Figure 1: LayerDrop (right) randomly drops layers at training time. At test time, this allows forsub-network selection to any desired depth as the network has been trained to be robust to pruning.
Figure 2:	Performance as a function of Pruning on various generation tasks (test set), compared totraining smaller models from scratch and pruning a Transformer baseline trained without LayerDrop.
Figure 3:	(left) Performance as a function of Pruning on MNLI and SST2 compared to BERTand RoBERTa trained from scratch and DistilBERT. Pruning one network trained with LayerDrop(blue) outperforms alternatives that require a new network for each point. (right) Performancewhen Training on More Data shows even stronger results on MNLI and SST2 for pruned models.
Figure 4: (left) Impact of Various Structured Dropouts on Wikitext-103 Valid. Dropping Lay-ers is straightforward and has strong performance. (right) Comparison of Pruning Strategies onWikitext-103 Valid. Marginal gains can be achieved, but dropping every other layer is hard to beat.
Figure 5: Relative Importance of Specific Layers.
Figure 6: Effect of Train LayerDrop onInference-time Pruning. (Wikitext-103Valid) Training with larger LayerDrop isbeneficial for significant pruning.
Figure 7: Effect of LayerDrop on TrainingTimePercentage of pruned layers94.093.593.092.592.091.591.090.5-O Train drop rate=0.1 O Train drop rate=0.2 -O- Train drop rate=0.5Figure 8: Effect of Train LayerDrop on Inference-time Pruning on MNLI, SST2, and QNLIBERT: Relationship between LayerDrop at Training Time and Pruning at Inference TimeSimilar to the analysis on Language Modeling, we find that training with larger quantities of Layer-Drop allows for more aggressive pruning at inference time on various natural language generationtasks. However, as these tasks involve a finetuning step on the downstream tasks after pre-training,the effect is less straightforward. Results are shown in Figure 8.
Figure 8: Effect of Train LayerDrop on Inference-time Pruning on MNLI, SST2, and QNLIBERT: Relationship between LayerDrop at Training Time and Pruning at Inference TimeSimilar to the analysis on Language Modeling, we find that training with larger quantities of Layer-Drop allows for more aggressive pruning at inference time on various natural language generationtasks. However, as these tasks involve a finetuning step on the downstream tasks after pre-training,the effect is less straightforward. Results are shown in Figure 8.
