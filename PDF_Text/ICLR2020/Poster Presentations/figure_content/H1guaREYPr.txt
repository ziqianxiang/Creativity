Figure 1: Overview of the proposed inference and generation stages.
Figure 2: The illustration of generated face images from interpolated speech conditions. Note thatthe first column consists of the ground truth image of the speakers3.
Figure 3: The illustration of generated face images from interpolated speech condition vectors whilefixing z . Note that the images on the very left and right sides of each row are the ground truth faceimages of the speakers.
Figure 4: The illustration of generated face images from interpolated random vectors while fixingc. Note that the images on the very left side of each row are the ground truth face images of thespeakers.
Figure 5: The scatter plots of CD(c1, c2) and CD(fe1, fe2).
Figure 7: The structure of the speech encoder. O, K, S indicate the number of output channels, sizeof the kernel and stride, respectively14Published as a conference paper at ICLR 2020fFigure 8: The structure of the discriminator network. The blue colored blocks indicate the networkstructure of the face encoder F which is transferred to the discriminator network at the generationstage. The numbers on each block denote the output channel. The GSP denotes a global sum poolingalong the spatial dimension.
Figure 8: The structure of the discriminator network. The blue colored blocks indicate the networkstructure of the face encoder F which is transferred to the discriminator network at the generationstage. The numbers on each block denote the output channel. The GSP denotes a global sum poolingalong the spatial dimension.
Figure 9: The structure of the generator network. The numbers on each block denote the outputchannel.
Figure 10: The uncurated generated face images of 19 speakers from the test set of the AVSpeech.
Figure 11: The uncurated generated face images of 19 speakers from the test set of the AVSpeech.
Figure 12: The generated face images when skipping the inference training stage. The very leftcolumn is composed of the ground truth face images of speakers.
