Figure 1: Illustration of formulating the synchronization policy problem asan RL problem.
Figure 2: Performance comparison of RLP w.r.t. existing policies. (a) Average results on all testingcases. (b) Results on DNN models with 0 and 3 hidden layers. (c) Results on clusters with differentnumber of stragglers.
Figure 3: Evaluation on the generalization ability of RLP on unseen cases. (a) Results on clusterswith different number of workers. (b) Results on new DNN model and new dataset. (c) Results oncombination of clusters with different number of workers, new DNN model and new dataset.
Figure 4: Visualization of the training process of SGD under different synchronization policies.
