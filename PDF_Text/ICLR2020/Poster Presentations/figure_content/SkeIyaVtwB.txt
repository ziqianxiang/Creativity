Figure 1:	The distance between the red state andall other states, measured via the second eigen-vector (left) and Euclidean distance (right). Thesecond eigenvector captures the connectivity ofthe graph, so distances reflect path lengths in thegraph; the pair of nodes with the maximum andminimum values are the farthest apart. Figure isadapted from Jinnai et al. (2019b), Figure 2.
Figure 2:	Comparison between options gener-ated by deep covering options (left) and coveringoptions (right). Blue regions represent statesin the initiation set and shaded regions statesin the termination set. Generated options haveinitiation and termination sets consisting of asingle state, making them impractical in largestate-spaces.
Figure 3: PerformanCe of online option disCovery agents, averaged over 5 runs. The shaded areashows the standard deviation. In PointFall (Figure 3b), the agent must push the movable bloCk into aChasm to make a bridge that allows it to reaCh the goal. In PointMaZe (Figure 3C), the agent mustfirst move away from the goal (in terms of L2 distanCe) to suCCessfully reaCh it, sinCe the Corridor isU-shaped. The green arrow shows suCCessful trajeCtories. In PointPush (Figure 3d) a greedy agentwould move forward and push the movable bloCk into the path to reaCh the goal. To reaCh the goal, itmust push a movable bloCk to the right to Clear the path towards the goal.
Figure 4: Options generated by offline option discovery. (a, c, e, f) States visited by a random walkwithout and with options. (b, d) Trajectories obtained by the generated options. Shadowed regions inthe figures approximately show the (x, y) coordinate of the termination set when the velocity is 0.
