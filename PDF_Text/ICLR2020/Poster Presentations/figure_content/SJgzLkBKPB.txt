Figure 1: Saliency maps generated by existing approachesfunction and policy vector between the original and perturbed state. They achieve promising resultson agents trained to play Atari games. Iyer et al. (2018) compute saliency maps using a difference inthe action-value (Q(s, a)) between the original and perturbed state.
Figure 2: Comparing saliency of RL agents trained to play Breakout(a) SARFA (b) Greydanus et al. (2018)	(c) SARFA (d) Greydanus et al. (2018)Figure 3: Comparing saliency of RL agents trained to play Atari Pong3.1 Illustrative ExamplesIn this section, we provide examples of generated saliency maps to highlight the qualitative differencesbetween SARFA that is action-focused and existing approaches that are not.
Figure 3: Comparing saliency of RL agents trained to play Atari Pong3.1 Illustrative ExamplesIn this section, we provide examples of generated saliency maps to highlight the qualitative differencesbetween SARFA that is action-focused and existing approaches that are not.
Figure 4: Comparing saliency of RL agents trained to play Space Invaders(c) Iyer et al. (2018)	(d) Greydanus et al. (2018)Figure 5:	Comparing saliency maps generated by different approaches for the MiniGo agent3.2	Human Studies: ChessTo show that SARFA generates saliency maps that provide useful information to humans, we conducthuman studies on problem-solving for chess puzzles. We show forty chess players (ELO 1600-2000)fifteen chess puzzles from https://www.chess.com (average difficulty ELO 1800). For each puzzle,we show either the puzzle without a saliency map, or the puzzle with a saliency map generated bySARFA, Greydanus et al. (2018), or Iyer et al. (2018). The player is then asked to solve the puzzle.
Figure 5:	Comparing saliency maps generated by different approaches for the MiniGo agent3.2	Human Studies: ChessTo show that SARFA generates saliency maps that provide useful information to humans, we conducthuman studies on problem-solving for chess puzzles. We show forty chess players (ELO 1600-2000)fifteen chess puzzles from https://www.chess.com (average difficulty ELO 1800). For each puzzle,we show either the puzzle without a saliency map, or the puzzle with a saliency map generated bySARFA, Greydanus et al. (2018), or Iyer et al. (2018). The player is then asked to solve the puzzle.
Figure 6:	ROC curves comparing approaches on the chess saliency dataset(Greydanus et al., 2018; Iyer et al., 2018). Each approach generates a list of squares and a score thatindicates how salient the piece on the square is for a particular move. We scale the scores between 0and 1 to generate ROC curves. Figure 6a shows the results. SARFA generates saliency maps thatare better than existing approaches at identifying chess pieces that humans deem relevant in certainpositions.
Figure 7:	Saliency maps generated by SARFA that demonstrate common tactical motifs in chess3.5 Robustness to PerturbationsWe are also interested in evaluating the robustness of the generated saliency maps: is the saliencydifferent if non-salient changes are made to the state? To evaluate the robustness of SARFA, weperform two irrelevant perturbations to the positions in the chess saliency dataset. First, we pick arandom piece amongst the ones labeled non-salient by human experts in a particular position, andremove it from the board. We repeat this for each puzzle in the dataset to generate a new perturbedsaliency dataset. Second, we remove a random piece amongst ones labeled non-salient by SARFA foreach puzzle, creating another perturbed saliency dataset. In order to evaluate the effect of non-salientperturbations on our generated saliency maps, we compute the AUC values for the generated saliencymaps, as above, for these perturbed datasets. Since we remove non-salient pieces, we expect thesaliency maps and subsequently AUC value to be similar to the value on the original dataset. For boththese perturbations, we get an AUC value of 0.92, same as the value on the non-perturbed dataset,confirming the robustness of our saliency maps to these non-relevant perturbations.
Figure 8:	Saliency Maps generated by SARFA for the top 3 moves in a chess positionA	Experimental DetailsFor experiments on chess, we use the Stockfish 10 agent: https://stockfishchess.org/. Stockfishworks using a heuristic-based measure for each state along with Alpha-Beta Pruning to search overthe state-space.
Figure 9:	Saliency maps generated by different approaches for the LeelaZero Deep ReinforcementLearning Agenthighlight several pieces that are not relevant to the move being explained. On the other hand, thesaliency maps generated by SARFA highlight the pieces relevant to the move.
