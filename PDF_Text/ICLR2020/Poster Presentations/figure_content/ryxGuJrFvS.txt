Figure 1: Representative training and test examples for the datasets we consider. The correlationbetween the label y and the spurious attribute a at training time does not hold at test time.
Figure 2: Training (light) and validation (dark) accuracy for CelebA throughout training. With de-fault hyperparameters and training to convergence, ERM and DRO models achieve perfect trainingaccuracy across groups, but generalize badly on the worst-case group (red line in the left panels).
Figure 3: Training (light) and validation (dark) accuracies for each group over time, for differentadjustments C. When C = 0, the generalization gap for waterbirds on land (green line) is large,dragging down worst-group accuracy. At C = 2, which has the best worst-group validation accu-racy, the accuracies are balanced. At C = 4, we overcompensate for group sizes, so smaller groups(e.g., waterbirds on land) do better at the expense of larger groups (e.g., landbirds on land).
Figure 4: Toy example illustrating that DRO and importance weighting are not equivalent. The DROsolution is θ*, while any importance weighting would result in solutions at θι or θ2.
