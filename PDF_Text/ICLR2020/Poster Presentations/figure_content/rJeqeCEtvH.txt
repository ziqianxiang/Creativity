Figure 1: Schematic showing how we parameterize the conditional likelihood p(x|y, zu, zs). Left:A block of 1-D convolutions and RNNs originally introduced by Wang et al. (2017) and describedin detail in the appendix. Right: Schematic of the sequence-to-sequence network that outputs themeans of our auto-regressive distribution. At each decoder time step, the network outputs the meansfor the next two spectrogram frames.
Figure 2: Left: The graphical model showing the conditional independence assumptions betweeneach of the stochastic variables. Centre: The structure of the variational distribution used to approx-imate the posterior for fully unsupervised data points and Right: supervised points.
Figure 3: The circumplex model of emotion. Each possible emotion is represented in a 2 dimen-sional plane consisting of an arousal dimension and valence dimension. This figure is borrowedfrom Munoz-de Escalona & Canas (2017).
Figure 4: Objective evaluation metrics as a function of supervision fraction. 100% supervisioncorresponds to 45 hours of supervised training data and 0% supervision corresponds to base tacotron.
Figure 5: Mean opinion score (MOS) evaluation template. For each utterance, the human ratersassign a 1-5 score of the perceived naturalness, with 1 being “Bad” and 5 being “Excellent”.
Figure 6: A/B evaluation affect control evaluation template. The emotion label (Happy in the figure)varies depending on the task.
Figure 7: Objective controllability of speaking rate and F0 variation evaluation metrics presented atmultiple supervision levels, on LibriTTS (Zen et al., 2019) datasets. 100% supervision correspondsto 62 hours of supervised data.
