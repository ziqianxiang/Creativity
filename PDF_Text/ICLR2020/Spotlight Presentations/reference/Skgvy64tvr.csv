title,year,conference
 On the convergence rate of training recurrent neuralnetworks,2019, In NeurIPS
 A convergence theory for deep learning via over-parameterization,2019, In ICML
 Synthesizing robust adversarialexamples,2017, arXiv preprint arXiv:1707
 Obfuscated gradients give a false sense ofsecurity: Circumventing defenses to adversarial examples,2018, In Proceedings of the 35th InternationalConference on Machine Learning
 The security of machinelearning,2010, Machine Learning
 Decision-based adversarial attacks: Reliableattacks against black-box machine learning models,2017, arXiv preprint arXiv:1712
 Thermometer encoding: One hotway to resist adversarial examples,2018, 2018
 Towards evaluating the robustness of neural networks,2017, In 2017IEEE Symposium on Security and Privacy (SP)
 Boundary attack++: Query-efficient decision-based adversarialattack,2019, arXiv preprint arXiv:1904
 Certified adversarial robustness via randomizedsmoothing,2019, arXiv preprint arXiv:1902
 Introduction toalgorithms,2009, MIT press
 Imagenet: A large-scalehierarchical image database,2009, In 2009 IEEE conference on computer vision and pattern recognition
 Stochastic activation pruning for robustadversarial defense,2018, In International Conference on Learning Representations
 Boostingadversarial attacks with momentum,2018, In Proceedings of the IEEE Conference on Computer Visionand Pattern Recognition
 Neuronal circuits of the neocortex,2004, Annu
 Gradient descent provably optimizesover-parameterized neural networks,2018, arXiv preprint arXiv:1810
 Explaining and harnessing adversarialexamples,2014, arXiv preprint arXiv:1412
 Countering adversarialimages using input transformations,2018, In International Conference on Learning Representations
 Deep residual learning for imagerecognition,2016, In Proceedings of the IEEE conference on computer vision and pattern recognition
 Benchmarking neural network robustness to commoncorruptions and perturbations,2019, In International Conference on Learning Representations
 Densely connectedconvolutional networks,2017, In Proceedings of the IEEE conference on computer vision and patternrecognition
 Adversarial machine learning at scale,2016, arXivpreprint arXiv:1611
 Learning overparameterized neural networks via stochastic gradientdescent on structured data,2018, In Advances in Neural Information Processing Systems
 Defensive quantization: When efficiency meets robustness,2019, InInternational Conference on Learning Representations
 Characterizing adversarial subspaces using localintrinsic dimensionality,2018, In International Conference on Learning Representations
 Neural computation with winner-take-all as the only nonlinear operation,2000, InAdvances in neural information processing systems
 On the k-winners-take-all network,1989, In Advancesin neural information processing Systems
 Deepfool: a simple andaccurate method to fool deep neural networks,2016, In Proceedings of the IEEE conference on computervision and pattern recognition
 Simple black-box adversarial perturbations fordeep networks,2016, arXiv preprint arXiv:1612
 Practical black-box attacks against machine learning,2017, In Proceedings of the 2017 ACM onAsia conference on computer and communications security
 Foolbox: A python toolbox to benchmarkthe robustness of machine learning models,2017, arXiv preprint arXiv:1707
 Improving the adversarial robustness and interpretabilityof deep neural networks by regularizing their input gradients,2017, CoRR
 Defense-GAN: Protecting classifiersagainst adversarial attacks using generative models,2018, In International Conference on LearningRepresentations
 Accessorize to a crime:Real and stealthy attacks on state-of-the-art face recognition,2016, In Proceedings of the 2016 ACMSIGSAC Conference on Computer and Communications Security
 Very deep convolutional networks for large-scale imagerecognition,2014, arXiv preprint arXiv:1409
 Compete to compute,2013, In Advances in Neural Information Processing Systems 26
 Understandinglocally competitive networks,2014, arXiv preprint arXiv:1410
 Is robustnessthe cost of accuracy? - a comprehensive study on the robustness of 18 deep image classificationmodels,2018, In Vittorio Ferrari
 One pixel attack for fooling deep neuralnetworks,2019, IEEE Transactions on Evolutionary Computation
 Intriguing properties of neural networks,2014, In International Conference on LearningRepresentations
 Fooling automated surveillance cameras:adversarial patches to attack person detection,2019, arXiv preprint arXiv:1904
 Ensemble adversarial training: Attacks and defenses,2017, arXiv preprint arXiv:1705
 Mitigating adversarial effectsthrough randomization,2018, In International Conference on Learning Representations
 Feature denoising forimproving adversarial robustness,2018, arXiv preprint arXiv:1812
 Wide residual networks,2016, arXiv preprint arXiv:1605
 Improving the robustness of deepneural networks via stability training,2016, In The IEEE Conference on Computer Vision and PatternRecognition (CVPR)
