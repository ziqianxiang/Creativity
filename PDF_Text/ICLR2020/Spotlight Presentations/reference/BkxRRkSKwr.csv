title,year,conference
 Towards better understanding ofgradient-based attribution methods for deep neural networks,2017, arXiv preprint arXiv:1711
 Visualizing the effects of predictor variables in black box supervised learningmodels,2016, arXiv preprint arXiv:1612
 Neural machine translation by jointlylearning to align and translate,2015, In 3rd International Conference on Learning Representations
 Explaining image clas-sifiers by counterfactual generation,2019, In International Conference on Learning Representations
 Learning to explain: Aninformation-theoretic perspective on model interpretation,2018, In ICML
 Bert: Pre-training of deepbidirectional transformers for language understanding,2018, arXiv preprint arXiv:1810
 A survey of methods for explaining black box models,2018, ACM computing surveys(CSUR)
 Interpretation of prediction models using the input gradient,2016, arXiv preprintarXiv:1611
 Long short-term memory,1997, Neural computation
 Discovering additive structure in black box functions,2004, In Proceedings of the tenthACM SIGKDD international conference on Knowledge discovery and data mining
 Representation of linguistic form and functionin recurrent neural networks,2017, Computational Linguistics
 Rationalizing neural predictions,2016, In EMNLP
 Understanding neural networks through representationerasure,2016, arXiv preprint arXiv:1612
 Towards explainable NLP: A generative explanationframework for text classification,2019, In Proceedings of the 57th Conference of the Association forComputational Linguistics
 Roberta: A robustly optimized bert pretrainingapproach,2019, arXiv preprint arXiv:1907
 A unified approach to interpreting model predictions,2017, In Advancesin Neural Information Processing Systems
 A survey of evaluation methods and measures forinterpretable machine learning,2018, arXiv preprint arXiv:1811
 Beyond word importance: Contextual decompositionto extract interactions from lstms,2018, In ICLR
 Glove: Global vectors for wordrepresentation,2014, In Proceedings of the 2014 conference on empirical methods in natural languageprocessing (EMNLP)
 Deep contextualized word representations,2018, arXiv preprint arXiv:1802
 Evaluating neural network explanation methodsusing hybrid documents and morphological agreement,2018, arXiv preprint arXiv:1801
 ”why should I trust you?”: Explaining thepredictions of any classifier,2016, In Proceedings of the 22nd ACM SIGKDD International Conferenceon Knowledge Discovery and Data Mining
 A value for n-person games,1953, Contributions to the Theory of Games
 Deep inside convolutional networks: Vi-sualising image classification models and saliency maps,2013, arXiv preprint arXiv:1312
 Hierarchical interpretations for neural networkpredictions,2019, In ICLR
 Detecting statistical interactionswith additive groves of trees,2008, In Proceedings of the 25th international conference on Machinelearning
 Can i trust you more? model-agnostichierarchical explanations,2018, ArXiv
 Attention is all you need,2017, In Advances in neural informationprocessing systems
 Character-level convolutional networks for text clas-sification,2015, In Advances in neural information processing systems
 Position-aware attention and supervised data improve slot filling,2017, In Proceedings of the 2017 Conferenceon Empirical Methods in Natural Language Processing (EMNLP 2017)
 The feature importanceranking measure,2009, In Joint European Conference on Machine Learning and Knowledge Discoveryin Databases
 Visualizing deep neural networkdecisions: Prediction difference analysis,2017, In ICLR
