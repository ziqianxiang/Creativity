title,year,conference
 Tubespam: Comment spam filteringon youtube,2015, In 2015 IEEE 14th International Conference on Machine Learning and Applications(ICMLA)
 Contributions to the study ofsms spam filtering: new collection and results,2011, In Proceedings of the 11th ACM symposium onDocument engineering
 Fastus: A finite-state processor for information extraction from real-world text,1993, In IJCAI
 Combining labeled and unlabeled data with co-training,1998, In COLT
 Trading convexity for scalability,2006, In ICML 2006
 Gate: A framework and graphical development environment for robust nlptools and applications,2002, In Proc
 Bert: Pre-training of deepbidirectional transformers for language understanding,2018, arXiv preprint arXiv:1810
 DL2: Training and querying neural networks with logic,2019, In Proceedings of the 36thInternational Conference on Machine Learning
 Generating accurate rule sets without global optimization,1998, In J
 Training deep neural-networks using a noise adaptationlayer,2016, 2016
 Co-teaching: Robust training of deep neural networks with extremely noisy labels,2018, InAdvances in Neural Information Processing Systems 31 
 Harnessing deep neuralnetworks with logic rules,2016, In Proceedings of the 54th Annual Meeting of the Association forComputational Linguistics (Volume 1: Long Papers)
 Adventure: Adversarial train-ing for textual entailment with knowledge-guided examples,2018, In Proceedings of the 56th AnnualMeeting of the Association for Computational Linguistics (Volume 1: Long Papers)
 Learning from noisy singly-labeleddata,2018, In International Conference on Learning Representations
 Query understand-ing enhanced by hierarchical parsing structures,2013, In 2013 IEEE Workshop on Automatic SpeechRecognition and Understanding
 Adversarial data programming: Using gans to relaxthe bottleneck of curated labeled data,2018, In 2018 IEEE Conference on Computer Vision and PatternRecognition
 Deep contextualized word representations,2018, arXiv preprint arXiv:1802
 Learning with bad training data via iterative trimmed loss mini-mization,2019, In Proceedings of the 36th International Conference on Machine Learning
 Revisiting unreasonable ef-fectiveness of data in deep learning era,2017, In IEEE International Conference on Computer Vision
 Joint optimization frame-work for learning with noisy labels,2018, In Proceedings of the IEEE Conference on Computer Visionand Pattern Recognition
 The language of generalization,2019, PsychologicalReview
 Learningfrom noisy large-scale datasets with minimal supervision,2017, In Proceedings of the IEEE Conferenceon Computer Vision and Pattern Recognition
 A semantic lossfunction for deep learning with symbolic knowledge,2018, In Proceedings of the 35th InternationalConference on Machine Learning
 Generalized cross entropy loss for training deep neural networkswith noisy labels,2018, In Advances in Neural Information Processing Systems 31
