title,year,conference
 Exploration by random networkdistillation,2019, In International Conference on Learning Representations
 Convergence of value aggregation for imitation learning,2018, arXivpreprint arXiv:1801
 Search-based structured prediction,2009, CoRR
 Explicit explore-exploit algorithms in continuous state spaces,2019, InH
 Model-predictive policy learning with un-certainty regularization for driving in dense traffic,2019, In International Conference on LearningRePresentations
 Rainbow: Combiningimprovements in deep reinforcement learning,2018, In AAAI
 Generative adversarial imitation learning,2016, In D
 Continuous control with deep reinforcement learning,2016, CoRR
 Learning self-correctable policies and value functionsfrom demonstrations with negative sampling,2019, CoRR
 Ensembledagger: Abayesian approach to safe imitation learning,2018, ArXiv
 Human-level control through deep rein-forcement learning,0028, Nature
 Asynchronous methods for deep reinforcementlearning,2016, In Maria Florina Balcan and Kilian Q
 Over-coming exploration in reinforcement learning with demonstrations,2017, 2018 IEEE InternationalConference on Robotics and Automation (ICRA)
 Deep exploration viabootstrapped DQN,2016, CoRR
 SQIL: imitation learning via regularizedbehavioral cloning,2019, CoRR
 Efficient reductions for imitation learning,2010, In Yee Whye Tehand Mike Titterington (eds
 Reinforcement and imitation learning via interactive no-regretlearning,2014, arXiv preprint arXiv:1406
 A reduction of imitation learning and struc-tured prediction to no-regret online learning,2011, In Geoffrey Gordon
 Sample efficient imitation learning forcontinuous control,2019, In International Conference on Learning Representations
 Proximal policyoptimization algorithms,2017, CoRR
 Model-based active exploration,2018, CoRR
 Random expert distilla-tion: Imitation learning via expert policy support estimation,2019, In Proceedings of InternationalConference on Machine Learning
 Nοn-mοnοtοnic sequential textgeneration,2019, CoRR
