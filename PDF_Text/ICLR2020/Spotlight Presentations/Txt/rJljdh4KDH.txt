Published as a conference paper at ICLR 2020
Multi-Scale Representation Learning for Spa-
tial Feature Distributions using Grid Cells
Gengchen Mai1, KrzysztofJanowicz1, Bo Yan2, Rui Zhu1, Ling Cai1 & Ni Lao3
1STKO Lab, University of California, Santa Barbara, CA, USA, 93106
{gengchen_mai,janowicz,ruizhu,lingcai}@ucsb.edu
2LinkedIn Corporation, Mountain View, CA, USA, 94043
boyan1@linkedin.com
3SayMosaic Inc., Palo Alto, CA, USA, 94303
ni.lao@mosaix.ai
Ab stract
Unsupervised text encoding models have recently fueled substantial progress in
Natural Language Processing (NLP). The key idea is to use neural networks to
convert words in texts to vector space representations (embeddings) based on word
positions in a sentence and their contexts, which are suitable for end-to-end training
of downstream tasks. We see a strikingly similar situation in spatial analysis,
which focuses on incorporating both absolute positions and spatial contexts of
geographic objects such as Points of Interest (POIs) into models. A general-purpose
representation model for space is valuable for a multitude of tasks. However, no
such general model exists to date beyond simply applying discretization or feed-
forward nets to coordinates, and little effort has been put into jointly modeling
distributions with vastly different characteristics, which commonly emerges from
GIS data. Meanwhile, Nobel Prize-winning Neuroscience research shows that
grid cells in mammals provide a multi-scale periodic representation that functions
as a metric for location encoding and is critical for recognizing places and for
path-integration. Therefore, we propose a representation learning model called
Space2Vec to encode the absolute positions and spatial relationships of places.
We conduct experiments on two real-world geographic data for two different
tasks: 1) predicting types of POIs given their positions and context, 2) image
classification leveraging their geo-locations. Results show that because of its multi-
scale representations, Space2Vec outperforms well-established ML approaches
such as RBF kernels, multi-layer feed-forward nets, and tile embedding approaches
for location modeling and image classification tasks. Detailed analysis shows
that all baselines can at most well handle distribution at one scale but show poor
performances in other scales. In contrast, Space2Vec ’s multi-scale representation
can handle distributions at different scales. 1
1 Introduction
Unsupervised text encoding models such as Word2Vec (Mikolov et al., 2013), Glove (Pennington
et al., 2014), ELMo (Peters et al., 2018), and BERT (Devlin et al., 2018) have been effectively utilized
in many Natural Language Processing (NLP) tasks. At their core they train models which encode
words into vector space representations based on their positions in the text and their context. A
similar situation can be encountered in the field of Geographic Information Science (GIScience). For
example, spatial interpolation aims at predicting an attribute value, e.g., elevation, at an unsampled
location based on the known attribute values of nearby samples. Geographic information has become
an important component to many tasks such as fine-grained image classification (Mac Aodha et al.,
2019), point cloud classification and semantic segmentation (Qi et al., 2017), reasoning about Point
of Interest (POI) type similarity (Yan et al., 2017), land cover classification (Kussul et al., 2017), and
geographic question answering (Mai et al., 2019b). Developing a general model for vector space
representation of any point in space would pave the way for many future applications.
1Link to project repository: https://github.com/gengchenmai/space2vec
1
Published as a conference paper at ICLR 2020
(a) Women’s Cloth (b) Education
(c) Ripley’s K
(d) Renormalized Ripley’s K
Figure 1: The challenge of joint modeling distributions with very different characteristics. (a)(b) The POI
locations (red dots) in Las Vegas and Space2Vec predicted conditional likelihood of Women’s Clothing (with
a clustered distribution) and Education (with an even distribution). The dark area in (b) indicates that the
downtown area has more POIs of other types than education. (c) Ripley’s K curves of POI types for which
Space2Vec has the largest and smallest improvement over wrap (Mac Aodha et al., 2019). Each curve represents
the number of POIs of a certain type inside certain radios centered at every POI of that type; (d) Ripley’s K
curves renormalized by POI densities and shown in log-scale. To efficiently achieve multi-scale representation
Space2Vec concatenates the grid cell encoding of 64 scales (with wave lengths ranging from 50 meters to 40k
meters) as the first layer of a deep model, and trains with POI data in an unsupervised fashion.
However, existing models often utilize specific methods to deal with geographic information and
often disregards geographic coordinates. For example, Place2Vec (Yan et al., 2017) converts the
coordinates of POIs into spatially collocated POI pairs within certain distance bins, and does not
preserve information about the (cardinal) direction between points. Li et al. (2017) propose DCRNN
for traffic forecasting in which the traffic sensor network is converted to a distance weighted graph
which necessarily forfeits information about the spatial layout of sensors. There is, however, no
general representation model beyond simply applying discretization (Berg et al., 2014; Tang et al.,
2015) or feed-forward nets (Chu et al., 2019; Mac Aodha et al., 2019) to coordinates.
A key challenge in developing a general-purpose representation model for space is how to deal with
mixtures of distributions with very different characteristics (see an example in Figure 1), which
often emerges in spatial datasets (McKenzie et al., 2015). For example, there are POI types with
clustered distributions such as women’s clothing, while there are other POI types with regular
distributions such as education. These feature distributions co-exist in the same space, and yet we
want a single representation to accommodate all of them in a task such as location-aware image
classification (Mac Aodha et al., 2019). Ripley’s K is a spatial analysis method used to describe point
patterns over a given area of interest. Figure 1c shows the K plot of several POI types in Las Vegas.
One can see that as the radius grows the numbers of POIs increase at different rates for different POI
types. In order to see the relative change of density at different scales, we renormalize the curves
by each POI type’s density and show it in log scale in Figure 1d. One can see two distinct POI type
groups with different distribution patterns with clustered and even distributions. If we want to model
the distribution of these POIs by discretizing the study area into tiles, we have to use small grid sizes
for women’s clothing while using larger grid sizes for educations because smaller grid sizes lead to
over- parameterization of the model and overfitting. In order to jointly describe these distributions
and their patterns, we need an encoding method which supports multi-scale representations.
Nobel Prize winning Neuroscience research (Abbott & Callaway, 2014) has demonstrated that grid
cells in mammals provide a multi-scale periodic representation that functions as a metric for location
encoding, which is critical for integrating self-motion. Moreover, Blair et al. (2007) show that the
multi-scale periodic representation of grid cells can be simulated by summing three cosine grating
functions oriented 60。apart, which may be regarded as a simple Fourier model of the hexagonal
lattice. This research inspired us to encode locations with multi-scale periodic representations. Our
assumption is that decomposed geographic coordinates helps machine learning models, such as deep
neural nets, and multi-scale representations deal with the inefficiency of intrinsically single-scale
methods such as RFB kernels or discretization (tile embeddings). To validate this intuition, we
propose an encoder-decoder framework to encode the distribution of point-features2 in space and
2In GIS and spatial analysis, ‘features’ are representations of real-world entities. A tree can, for instance, be
modeled by a point-feature, while a street would be represented as a line string feature.
2
Published as a conference paper at ICLR 2020
train such a model in an unsupervised manner. This idea of using sinusoid functions with different
frequencies to encode positions is similar to the position encoding proposed in the Transformer
model (Vaswani et al., 2017). However, the position encoding model of Transformer deals with
a discrete 1D space - the positions of words in a sentence - while our model works on higher
dimensional continuous spaces such as the surface of earth.
In summary, the contributions of our work are as follows:
1.	We propose an encoder-decoder encoding framework called Space2Vec using sinusoid
functions with different frequencies to model absolute positions and spatial contexts. We
also propose a multi-head attention mechanism based on context points. To the best of our
knowledge, this is the first attention model that explicitly considers the spatial relationships
between the query point and context points.
2.	We conduct experiments on two real world geographic data for two different tasks: 1)
predicting types of POIs given their positions and context, 2) image classification leveraging
their geo-locations. Space2Vec outperforms well-established encoding methods such as
RBF kernels, multi-layer feed-forward nets, and tile embedding approaches for location
modeling and image classification.
3.	To understand the advantages of Space2Vec we visualize the firing patterns (response maps)
of location models’ encoding layer neurons and show how they handle spatial structures at
different scales by integrating multi-scale representations. Furthermore the firing patterns
for the spatial context models neurons give insight into how the grid-like cells capture the
decreasing distance effect with multi-scale representations.
2	Problem Formulation
Distributed representation of point-features in space can be formulated as follows. Given a set
of points P “ tpi u, i.e., Points of Interests (POIs), in L-D space (L “ 2, 3) define a function
fP,θpxq : RL → Rd (L ! d), which is parameterized by θ and maps any coordinate X in space to a
vector representation of d dimension. Each point (e.g., a restaurant) pi “ pxi , viq is associated with
a location Xi and attributes vi (i.e., POI features such as type, name, capacity, etc.). The function
fP,θpXq encodes the probability distribution of point features over space and can give a representation
of any point in the space. Attributes (e.g. place types such as Museum) and coordinate of point can
be seen as analogies to words and word positions in commonly used word embedding models.
3	Related Work
There has been theoretical research on neural network based path integration/spatial localization
models and their relationships with grid cells. Both Cueva & Wei (2018) and Banino et al. (2018)
showed that grid-like spatial response patterns emerge in trained networks for navigation tasks which
demonstrate that grid cells are critical for vector-based navigation. Moreover, Gao et al. (2019)
propose a representational model for grid cells in navigation tasks which has good quality such as
magnified local isometry. All these research is focusing on understanding the relationship between
the grid-like spatial response patterns and navigation tasks from a theoretical perspective. In contrast,
our goal focuses on utilizing these theoretical results on real world data in geoinformatics.
Radial Basis Function (RBF) kernel is a well-established approach to generating learning friendly
representation from points in space for machine learning algorithms such as SVM classification (Bau-
dat & Anouar, 2001) and regression (Bierens, 1994). However, the representation is example based
- i.e., the resultant model uses the positions of training examples as the centers of Gaussian kernel
functions (Maz’ya & Schmidt, 1996). In comparison, the grid cell based location encoding relies on
sine and cosine functions, and the resultant model is inductive and does not store training examples.
Recently the computer vision community shows increasing interests in incorporating geographic
information (e.g. coordinate encoding) into neural network architectures for multiple tasks such
as image classification (Tang et al., 2015) and fine grained recognition (Berg et al., 2014; Chu
et al., 2019; Mac Aodha et al., 2019). Both Berg et al. (2014) and Tang et al. (2015) proposed
to discretize the study area into regular grids. To model the geographical prior distribution of the
image categories, the grid id is used for GPS encoding instead of the raw coordinates. However,
choosing the correct discretization is challenging (Openshaw, 1984; Fotheringham & Wong, 1991),
3
Published as a conference paper at ICLR 2020
and incorrect choices can significantly affect the final performance (Moat et al., 2018; Lechner et al.,
2012). In addition, discretization does not scale well in terms of memory use. To overcome these
difficulties, both Chu et al. (2019) and Mac Aodha et al. (2019) advocated the idea of inductive
location encoders which directly encode coordinates into a location embedding. However, both of
them directly feed the coordinates into a feed-forward neural network (Chu et al., 2019) or residual
blocks (Mac Aodha et al., 2019) without any feature decomposition strategy. Our experiments
show that this direct encoding approach is insufficient to capture the spatial feature distribution and
Space2Vec significantly outperforms them by integrating spatial representations of different scales.
4	Method
We solve distributed representation of point-features in space (defined in Section 2) with an encoder-
decoder architecture:
1.	Given a point pi “ pxi, viq a point space encoder Encpxq pq encodes location xi into a
location embedding erxis P Rdpxq and a point feature encoder Encpvq pq encodes its feature
into a feature embedding ervis P Rdpvq . e “ rerxis; erviss P Rd is the full representation
of point pi P P, where d “ dpxq ` dpvq. r; s represents vector concatenation. In contrast,
geographic entities not in P within the studied space can be represented by their location
embedding erxj s since its vi is unknown.
2.	We developed two types of decoders which can be used independently or jointly. A location
decoder Decs pq reconstructs point feature embedding ervis given location embedding
erxis, and a spatial context decoder Decc pq reconstructs the feature embedding ervis
of point pi based on the space and feature embeddings tei1, ..., eij, ..., einu of nearest
neighboring points tpi1, ..., pij, ...,pinu, where n is a hyper-parameter.
4.1	Encoder
Point Feature Encoder Each point pi “ pxi , viq in a point set P is often associated with features
such as the air pollution station data associate with some air quality measures, a set of POIs with
POI types and names, a set of points from survey and mapping with elevation values, a set of points
from geological survey with mineral content measure, and so on. The point feature encoder Encpvq pq
encodes such features vi into a feature embedding ervis P Rdpvq . The implementation of Encpvq pq
depends on the nature of these features. For example, if each point represents a POI with multiple
POI types (as in this study), the feature embedding ervis can simply be the mean of each POI types’
embeddings eMS “ — XhH“1 t?q, where t?q indicates the hth POI type embedding of a POI Pi
H
with H POI types. We apply L2 normalization to the POI type embedding matrix.
Point Space Encoder A part of the novelty of this paper is from the point space encoder Encpxq pq.
We first introduce Theorem 1 which provide an analytical solution φpxq as the base of encoding any
location x P R2 in 2D space to a distributed representation:
Theorem 1. Let Ψpxq “ peixaj,xy, j “ 1, 2, 3qT P C3 where eiθ “ cos θ ` i sin θ is the Euler
notation of complex values; xaj, xy is the inner product of aj and x. a1, a2, a3 P R2 are 2D vectors
such that the angle between ak and a? is 2π/3, @j, }aj} “ 2ʌ/ɑ. Let C P C3*3 be a random complex
matrix such as C*C “ I. Then φ(x) “ Cψ(x), M(∆x) “ Cdiag(Ψ(∆x))C* satisfies
φpx ` ∆xq “ M p∆xqφpxq	(1)
and
xφ(x ` ∆xq, φ(xqy “ d(1 ´ α}∆x}2q	(2)
where d “ 3 is the dimension of φ(xq and ∆x is a small displacement from x.
The proof of Theorem 1 can be seen in Gao et al. (2019). φ(xq “ CΨ(xq P C3 amounts to a
6-dimension real value vector and each dimension shows a hexagon firing pattern which models the
grid cell behavior. Because of the periodicity of sin(q and cos(q, this single scale representation φ(xq
does not form a global codebook of 2D positions, i.e. there can be x ‰ y, but φ(xq “ φ(yq.
Inspired by Theorem 1 and the multi-scale periodic representation of grid cells in mammals (Ab-
bott & Callaway, 2014) we set up our point space encoder erxs “ Encpthxqeory(xq to use sine
4
Published as a conference paper at ICLR 2020
and cosine functions of different frequencies to encode positions in space. Given any point x in
the studied 2D space, the space encoder Enctphxqeorypxq “ NNpP E ptq pxqq where PEptq pxq “
rPE0tq(x);…;PEstqpx);…;PES´ ι(x)S is a concatenation of multi-scale representations of dpxq “
6S dimensions. Here S is the total number of grid scales and S “ 0,1, 2,…，S — 1. NNpq represents
fully connected ReLU layers. Let aι = [1,0]T, a2 = [—1/2, ?3/2ST, a3 “ [—1/2, —?3{2]T P R2
be three unit vectors and the angle between any of them is 2π{3. λmin , λmax are the minimum and
maximum grid scale and g “ λmaχ. At each scale s, PEstqpXq = [PEstq (x); PE(P2 (x); PEs,3 (Xqs
is a concatenation of three components, where
P Espt,jq pXq “ [cosp
〈X, aj〉
λmin ∙ gs/(ST)
q; sinp
〈x, aj〉
λmin ∙ gs/(ST)
qs@j“1,2,3;
(3)
NNpq and PEptq pXq are analogies of C and ΨpXq in Theorem 1.
Similarly we can define another space encoder EncpgxrqidpXq “ NNpP Epgq pXqq inspired by
the position encoding model of Transformer (Vaswani et al., 2017), where P EpgqpXq “
[PE0gq(x);…；PEsg)px);…；PEpg)IpXqs is still a concatenation of its multi-scale representations,
while P EspgqpXq “ [P Espg,1q pXq; PEsp,g2qpXqs handles each component l of X separately:
xrls	xrls
4 ɔ n	PESgl)(Xq “ rcθsp λmin …)；SmpEL W “ 1, 2
4.2	Decoder
(4)
Two types of decoders are designed for two major types of GIS problems: location modeling and
spatial context modeling (See Section 5.1).
Location Decoder Decs pq directly reconstructs point feature embedding e[vis given its space
embedding e[xis. We use one layer feed-forward neural network NNdecpq
e[vis1 “ Decs pxi; θdecs q “ NNdecpe[xisq	(5)
For training we use inner product to compare the reconstructed feature embedding e[vis1 against the
real feature embeddings of e[vis and other negative points (see training detail in Sec 4.3).
Spatial Context Decoder Deccpq reconstructs the feature embedding e[vis of the center
point pi based on the space and feature embeddings tei1, ..., eij, ..., einu of n nearby points
tpi1, ..., pij, ..., pinu. Note that the feed-in order of context points should not affect the predic-
tion results, which can be achieved by permutation invariant neural network architectures (Zaheer
et al., 2017) like PointNet (Qi et al., 2017).
1Kn
e[vis1 “ Decc pxi, tei1, ..., eij, ..., einu; θdecc q “ gp K∑∑∙αijk e[vij sq	(6)
K k“1j“1
Here g is an activation function such as sigmoid. ajk “ Wnexpxpj：)卜)is the attention of Pi with its
jth neighbor through the kth attention head, and	o
σijk “ LeakyReLU pakT [e[visinit; e[vij s; e[xi — xij ssq	(7)
where ak P R2dpvq 'dpx is the attention parameter in the kth attention head. The multi-head attention
mechanism is inspired by Graph Attention Network (Velickovic et al., 2018) and Mai et al. (2019a).
To represent the spatial relationship (distance and direction) between each context point pij “
pxij , vijq and the center point pi “ pxi, viq, we use the space encoder Encpx) pq to encode the
displacement between them ∆xij “ xi — xij . Note that we are modeling the spatial interactions
between the center point and n context points simultaneously.
In Eq. 7, e[visinit indicates the initial guess of the feature embedding e[vis of point pi which is com-
puted by using another multi-head attention layer as Eq. 6 where the weight ɑj “ Wnexpxpσq ).
Here, σi1jk is computed as Eq. 8 where the query embedding e[vis is excluded.
σi1jk “ LeakyReLU pa1kT [e[vij s; e[xi — xij ssq	(8)
5
Published as a conference paper at ICLR 2020
4.3	Unsupervised Training
The unsupervised learning task can simply be maximizing the log likelihood of observing the true
point pi at position xi among all the points in P
LP (θ) “一 £ log P (Pi∣Pii,…,Pij,…,Pin) “一 £ log 7 exppervis ervi?]八	(9)
piPP	piPP	poPP exppervosTervis1q
Here only the feature embedding of Pi is used (without location embedding) to prevent revealing the
identities of the point candidates, and θ “ rθenc ; θdecs
Negative sampling by Mikolov et al. (2013) can be used to improve the efficiency of training
LP (θq = 一 £ ´ log σ(ervi]Tervi]1) + 3 £ log σ(-ervο]Tervr)	(IO)
piPP	|Ni| poPNi
Here Ni J P is a set of sampled negative points for Pi (Pi R Ni) and σ(x) “ 1{(1 ' e~x).
5	Experiment
In this section we compare Space2Vec with commonly used position encoding methods, and analyze
them both quantitatively and qualitatively.
Baselines Our baselines include 1) direct directly applying feed-forward nets (Chu et al., 2019);
2) tile discretization (Berg et al., 2014; Adams et al., 2015; Tang et al., 2015); 3) wraP feed-forward
nets with coordinate wrapping (Mac Aodha et al., 2019); and 4) rbf Radial Basis Function (RBF)
kernels (Baudat & Anouar, 2001; Bierens, 1994). See Appendix A.1 for details of the baselines.
5.1	POI Type Classification Tasks
Dataset and Tasks To test the proposed model, we conduct experiments on geographic datasets
with POI position and type information. We utilize the open-source dataset published by Yelp
Data Challenge and select all POIs within the Las Vegas downtown area3. There are 21,830 POIs
with 1,191 different POI types in this dataset. Note that each POI may be associated with one
or more types, and we do not use any other meta-data such as business names, reviews for this
study. We project geographic coordinates into projection coordinates using the NAD83/Conus Albers
projection coordinate system4. The POIs are split into training, validation, and test dataset with ratios
80%:10%:10%. We create two tasks setups which represent different types of modeling need in
Geographic Information Science:
•	Location Modeling predicts the feature information associated with a POI based on its
location xi represented by the location decoder Decs (). This represents a large number of
location prediction problems such as image fine grained recognition with geographic prior
(Chu et al., 2019), and species potential distribution prediction (Zuo et al., 2008).
•	Spatial Context Modeling predicts the feature information associated with a POI based
on its context tei1, ..., eij, ..., einu represented by the spatial context decoder Decc (). This
represents a collections of spatial context prediction problem such as spatial context based
facade image classification (Yan et al., 2018), and all spatial interpolation problems.
We use POI prediction metrics to evaluate these models. Given the real point feature embedding
ervis and N negative feature embeddings Ni “ tervis´u, we compare the predicted ervis1 with
them by cosine distance. The cosine scores are used to rank ervis and N negative samples. The
negative feature embeddings are the feature embeddings of points Pj randomly sampled from P and
Pi ‰ Pj . We evaluate each model using Negative Log-Likelihood (NLL), Mean Reciprocal Rank
(MRR) and HIT@5 (the chance of the true POI being ranked to top 5. We train and test each model
10 times to estimate standard deviations. See Appendix A.2 for hyper-parameter selection details.
5.1.1	Location Modeling Evaluation
We first study location modeling with the location decoder Decs () in Section 4.2. We use a negative
sample size of N “ 100. Table 1 shows the average metrics of different models with their best hyper-
3The geographic range is(35.989438, 36.270897) for latitude and (-115.047977,-115.3290609) for longitude.
4https://epsg.io/5070-1252
6
Published as a conference paper at ICLR 2020
(a) direct (b) tile (C) wrap (d) rbf (σ=1k) (e) λmin=1k ⑴ λmin =500 (g) λmin =50
Figure 2: Embedding clustering of (a) direct; (b) tile with the best cell size c “ 500; (c) wrap (h “ 3, o “
512); (d) rbf with the best σ (1k) and 200 anChor points (red) and (e)(f)(h) theory models with different λmin,
but fixed λmax “ 40k and S “ 64. All models use 1 hidden ReLU layers of 512 neurons exCept wrap.
Table 1: The evaluation results of different loCation models on the validation and test dataset.
	Train NLL	NLL	Validation MRR	HIT@5	Testing	
					MRR	HIT@5
random		-	0.052 (0.002)	4.8 (0.5)	0.051 (0.002)	5.0 (0.5)
direct	1.285	1.332	0.089 (0.001)	10.6 (0.2)	0.090 (0.001)	11.3 (0.2)
tile (c=500)	1.118	1.261	0.123 (0.001)	16.8 (0.2)	0.120 (0.001)	17.1 (0.3)
wrap(h=3,o=512)	1.222	1.288	0.112 (0.001)	14.6 (0.1)	0.119(0.001)	15.8 (0.2)
rbf (σ =1k)	1.209	1.279	0.115 (0.001)	15.2 (0.2)	0.123 (0.001)	16.8 (0.3)
grid (λmin=50)	1.156	1.258	0.128 (0.001)	18.1 (0.3)	0.139 (0.001)	20.0 (0.2)
hexa (λmin=50)	1.230	1.297	0.107 (0.001)	14.0 (0.2)	0.105 (0.001)	14.5 (0.2)
theorydiag (λmin=50)	1.277	1.324	0.094 (0.001)	12.3 (0.3)	0.094 (0.002)	11.2 (0.3)
theory (λmin=1k)	1.207	1.281	0.123 (0.002)	16.3 (0.5)	0.121 (0.001)	16.2 (0.1)
theory (λmin =500)	1.188	1.269	0.132 (0.001)	17.6 (0.3)	0.129 (0.001)	17.7 (0.2)
theory (λmin=50)	1.098	1.249	0.137 (0.002)	19.4 (0.1)	0.144 (0.001)	20.0 (0.2)
parameter setting on the validation set. We Can see that direct and theorydiag are less Competitive,
only beating the random selection baseline. Other methods With single scale representations -
including tile, wrap, and rbf - perform better. The best results come from various version of the
grid cell models, Which are capable of dealing With multi-scale representations.
In order to understand the reason for the superiority of grid cell models We provide qualitative analysis
of their representations. We apply hierarchical clustering to the location embeddings produced by
studied models using cosine distance as the distance metric (See Fig. 2). We can see that When
restricted to large grid sizes (λmin “ 1k), theory has similar representation (Fig. 2d, 2e, and Fig. 4d,
4e) and performance compared to rbf (σ “ 1k). HoWever it is able to significantly outperform rbf
(σ “ 1k) (and tile and wrap) When small grid sizes (λmin “ 500, 50) are available. The relative
improvements over rbf (σ “ 1k) are -0.2%, +0.6%, +2.1% MRR for λmin=1k, 500, 50 respectively.
5.1.2	Multi-Scale Analysis of Location Modeling
In order to shoW hoW our multi-scale location representation model Will affect the prediction of POI
types With different distribution patterns, We classify all 1,191 POI types into three groups based on
radius r, Which is derived from each POI types’ renormalized Ripley’s K curve (See Figure 1d for
examples). It indicates the x axis value of the intersection betWeen the curve and the line of y “ 3.0.
A loWer r indicates a more clustered distribution patterns. These three groups are listed beloW:
1.	Clustered (r ≤ 100m): POI types with clustered distribution patterns;
2.	Middle (100m V r V 200m): POI types with less extreme scales;
3.	Even (r > 200m): POI types with even distribution patterns.
Table 2 shows the performance (M RR) of direct, tile, wrap, rbf, and our theory model on the test
dataset of the location modeling task with respect to these three different POI distribution groups.
The numbers in pq indicate the MRR difference betweeb a baseline and theory. # POI refers to total
number of POI belong to each group5. We can see that 1) The two neural net approaches (direct and
wrap) have no scale related parameter and are not performing ideally across all scales, with direct
5The reason why the sum of#POI of these three groups does not equal to the total number of POI is because
one POI can have multiple types and they may belonging to different groups.
7
Published as a conference paper at ICLR 2020
Table 2: Comparing performances in different POI groups. We classify all 1,191 POI types into three
groups based on the radius r of their root types, where their renormalized Ripley’s K curve (See
Figure 1d) reach 3.0: 1) Clustered (r ≤ 100m): POI types with clustered distribution patterns; 2)
Middle (100m V r V 200m): POI types with unclear distribution patterns; 3) Even (r2200m):
POI types with even distribution patterns. The MRR of wrap and theory on those three groups are
shown. The numbers in pq indicate the difference between the MRR of a baseline model and the
MRR of theory with respect to a specific group. #POI refers to the total number of POIs belonging
to each group. Root Types indicates the root categories of those POI types belong to each group.
POI Groups	Clustered (r ≤ 100m)	Middle (100m V r V 200m)	Even (r > 200m)
direct	0.080 (-0.047)	0.108 (-0.030)	0.084 (-0.047)
wrap	0.106 (-0.021)	0.126 (-0.012)	0.122 (-0.009)
tile	0.108(-0.019)	0.135 (-0.003)	0.111 (-0.020)
rbf	0.112(-0.015)	0.136 (-0.002)	0.119(-0.012)
theory	0.127 (-)	0.138(-)	0.131(-)
# POI	16,016	7,443	3,915
Root Types	Restaurants; Shopping; Food; Nightlife; Automotive; Active Life; Arts & Entertainment; Financial Services	Beauty & Spas; Health & Medical; Local Services; Hotels & Travel; Professional Services; Public Services & Government	Home Services; Event Planning & Services; Pets; Education
performs worse because of its simple single layer network. 2) The two approaches with built-in scale
parameter (tile and rbf) have to trade off the performance of different scales. Their best parameter
settings lead to close performances to that of Space2Vec at the middle scale, while performing poorly
in both clustered and regular groups. These observation clearly shows that all baselines can at most
well handle distribution at one scale but show poor performances in other scales. In contrast,
Space2Vec’s multi-scale representation can handle distributions at different scales.
5.1.3	S patial Context Modeling Evaluation
Next, we evaluate the spatial context decoder Deccpq in Sec. 4.2. We use the same evaluation set
up as location modeling. The context points are obtained by querying the n-th nearest points using
PostGIS (n “ 10). As for validation and test datasets, we make sure the center points are all unknown
during the training phase. Table 3 shows the evaluation results of different models for spatial context
modeling. The baseline approaches (direct, tile, wrap, rbf) generally perform poorly in context
modeling. We designed specialized version of these approaches (polar, polar_tile, scaled_rbf)
with polar coordinates, which lead to significantly improvements. Note that these are models proposed
by us specialized for context modeling and therefore are less general than the grid cell approaches.
Table 3: The evaluation results of different spatial context models on the validation and test dataset.
All encoders contains a 1 hidden layer FFN. All grid cell encoders set λmin=10, λmax=10k.
Space2V ec	Train NLL	NLL	Validation MRR	HIT@5	Testing	
					MRR	HIT@5
none	1.163	1.297	0.159 (0.002)	22.4 (0.5)	0.167 (0.006)	23.4 (0.7)
direct	1.151	1.282	0.170 (0.002)	24.6 (0.4)	0.175 (0.003)	24.7 (0.5)
polar	1.157	1.283	0.176 (0.004)	25.4 (0.4)	0.178 (0.006)	24.9 (0.1)
tile pc “ 50q	1.163	1.298	0.173 (0.004)	24.0 (0.6)	0.173 (0.001)	23.4 (0.1)
polar_tilepS “ 64q	1.161	1.282	0.173 (0.003)	25.0 (0.1)	0.177 (0.001)	24.5 (0.3)
wrap (h=2,o=512)	1.167	1.291	0.159 (0.001)	23.0 (0.1)	0.170 (0.001)	23.9 (0.2)
rbf pσ “ 50q	1.160	1.281	0.179 (0.002)	25.2 (0.6)	0.172 (0.001)	25.0 (0.1)
scaled_rbf (σ=40,β=0.1)	1.150	1.272	0.177 (0.002)	25.7 (0.1)	0.181 (0.001)	25.3 (0.1)
grid(λmin=10)	1.172	1.285	0.178 (0.004)	24.9 (0.5)	0.181 (0.001)	25.1 (0.3)
hexa (λmin =10)	1.156	1.289	0.173 (0.002)	24.0 (0.2)	0.183 (0.002)	25.3 (0.2)
theorydiag pλmin “ 10q	1.156	1.287	0.168 (0.001)	24.1 (0.4)	0.174 (0.005)	24.9 (0.1)
theory(λmin=200)	1.168	1.295	0.159 (0.001)	23.1 (0.2)	0.170 (0.001)	23.2 (0.2)
theory(λmin=50)	1.157	1.275	0.171 (0.001)	24.2 (0.3)	0.173 (0.001)	24.8 (0.4)
theory(λmin=10)	1.158	1.280	0.177 (0.003)	25.2 (0.3)	0.185 (0.002)	25.7 (0.3)
8
Published as a conference paper at ICLR 2020
(a) direct
(b) polar
(f) theory
(c) wrap	(d) polar_tile	(e) scaled_rbf
(g) direct
(i) wrap
(j) polar_tile
(k) SCaled_rbf	(l) theory
Figure 3: Embedding clustering in the original space of (a) direct; (b) polar; (c) wrap, h=2,o=512;
(d) polar_tile, S = 64, (e) scaled_rbf, σ = 40, β=0.1; and (f) theory, λmin “ 10, λmax “ 10k,
S “ 64. (g)(h)(i)(j)(k)(l) are the clustering results of the same models in the polar-distance space
using log(k ∆xj k 'iq. All models use 1 hidden ReLU (except Wrap) layers of 512 neurons. Most
models except wrap can capture a shift when distance is around e5 ´ 1 « 150 meters.
Nevertheless the grid cell approaches are able to perform better than the specialized approaches on
the test dataset while have competitive performance on validation dataset. See Appendix ?? for the
visualization of context models. Actually the gains are small for all baseline approaches also. The
reason is that we expect location encoding to be less important when context information is accessible.
Similarly as discussed in (Gao et al., 2019), it is when there is a lack of visual clues that the grid cells
of animals are the most helpful for their navigation.
Figure 6 shows the location embedding clustering results in both Cartesian and polar coordinate
systems. We can see that direct (Fig. 3a, 3g) only captures the distance information when the context
POI is very close (log(∣∣ ∆xj k +1) ≤ 5) while in the farther spatial context it purely models the
direction information. polar (Fig. 3b, 3h) has the similar behaviors but captures the distance infor-
mation in a more fine-grained manner. wrap (Fig. 3c, 3i) mainly focuses on differentiating relative
positions in farther spatial context cont which might explain its lower performance6 . polar_tile (Fig.
3d) mostly responds to distance information. Interestingly, scaled_rbf and theory have similar
representations in the polar coordinate system (Fig. 3k, 3l) and similar performance (Table 3). While
scaled_rbf captures the gradually decreased distance effect with a scaled kernel size which becomes
larger in farther distance, theory achieves this by integrating representations of different scales.
5.2 Fine-Grained Image Classification Tasks
To demonstrate the generalizability of Space2Vec for space representation we utilized the proposed
point space encoder Encpxq () model in a well-known computer vision task: fine-grained image
classification. As we discussed in Section 3, many studies (Berg et al., 2014; Chu et al., 2019;
Mac Aodha et al., 2019) have shown that geographic prior information - where (and when) the image
is taken - is very important additional information for the fine-grained image classification task and
can substantially improve the model performance. For example, the appearance information is usually
not sufficient to differentiate two visually similar species. In this case, the geographic prior becomes
much more important because these two species may have very different spatial prior distributions
such as the example of European Toads and Spiny Toads in Figure 1 of Mac Aodha et al. (2019).
We adopt the task setup of Mac Aodha et al. (2019). During training we have a set of tuples D “
t(Ii, xi, yi,pi) | i “ 1, ..., Nu where Ii indicates an image, yi P t1, 2, ..., Cu is the corresponding
class label (species category), xi “ rlongitudei , latitudeis is the geographic coordinates where
the image was taken, and pi is the id of the photographer who took this image. At training time, a
location encoder is trained to capture the spatial prior information P(y | x). At inference time, pi
information is not available and the final image classification prediction is calculated based on the
6Note that wrap is original proposed by Mac Aodha et al. (2019) for location modelling, not spatial context
modelling. This results indicates wrap is not good at this task.
9
Published as a conference paper at ICLR 2020
Table 4: Fine-grained image classification results on two datasets: BirdSnap: and NABirds:. The
classification accuracy is calculated by combining image classification predictions P py | Iq with
different spatial priors Ppy | xq. The grid and theory model use 1 hidden ReLU layers of 512
neurons. The evaluation results of the baseline models are from Table 1 of Mac Aodha et al. (2019).
	BirdSnap：	NABirds：
No Prior (i.e. uniform)	70.07	76.08
Nearest Neighbor (num)	77.76	"^9.99
Nearest Neighbor (spatial)	77.98	80.79
Adaptive Kernel (Berg et al., 2014)	78.65	81.11
tile (Tang et al., 2015) (location only)	77.19	79.58
wrap (Mac Aodha et al., 2019) (location only)	78.65	81.15
rbf (σ=1k)	78.56	81.13
grid (λmin=0.0001, λmax=360, S = 64)	79.44	81.28
theory (λmin=0.0001, λmaχ=360, S = 64)	79.35	81.59
combination of two models: 1) the trained location encoder which captures the spatial priors P py | xq
and 2) the pretrained image classification model, InceptionV3 network (Szegedy et al., 2016), which
captures P py | Iq. Bayesian theory has been used to derive the joint distribution P py | I, xq. See
Mac Aodha et al. (2019) for detail explanation as well as the loss function. Note that while Space2Vec
outperforms specialized density estimation methods such as Adaptive Kernel (Berg et al., 2014), it
would be interesting to explore early fusion Space2Vec ’s representations with the image module.
We use two versions of our point space encoder Encpxq pq model (grid, theory) as the location
encoder to capture the spatial prior information Ppy | xq. The evaluation results of our models as well
as multiple baselines are shown in Table 4. We can see that both grid, theory outperform previous
models as well as that of Mac Aodha et al. (2019) on two fine-grained image classification
datasets with significant sizes: BirdSnap:, NABirds:. theory shows superiority over grid on
NABirds: while fail to outperform grid on BirdSnap:. Note that we only pick baseline models
which capture spatial-only prior and drop models which additionally consider time information.
Both grid and theory use 1 hidden ReLU layers of 512 neurons for NNpq and they have the same
hyperparameters: λmin=0.0001, λmax=360, S = 64. Like Mac Aodha et al. (2019), the location
embedding size dpxq is 1024 and we train the location encoder for 30 epochs. Our implementation is
based on the original code7 of Mac Aodha et al. (2019) for both model training and evaluation phase.
6 Conclusion
We introduced an encoder-decoder framework as a general-purpose representation model for space
inspired by biological grid cells’ multi-scale periodic representations. The model is an inductive
learning model and can be trained in an unsupervised manner. We conduct two experiments on POI
type prediction based on 1) POI locations and 2) nearby POIs. The evaluation results demonstrate the
effectiveness of our model. Our analysis reveals that it is the ability to integrate representations of
different scales that makes the grid cell models outperform other baselines on these two tasks. In the
future, we hope to incorporate the presented framework to more complex GIS tasks such as social
network analysis, and sea surface temperature prediction.
Acknowledgments
The presented work is partially funded by the NSF award 1936677 C-Accel Pilot - Track A1 (Open
Knowledge Network): Spatially-Explicit Models, Methods, And Services For Open Knowledge
Networks, Esri Inc., and Microsoft AI for Earth Grant: Deep Species Spatio-temporal Distribution
Modeling for Biodiversity Hotspot Prediction. We thank Dr. Ruiqi Gao for discussions about grid
cells, Dr. Wenyun Zuo for discussion about species potential distribution prediction and Dr. Yingjie
Hu for his suggestions about the introduction section.
7https://github.com/macaodha/geo_prior/
10
Published as a conference paper at ICLR 2020
References
Alison Abbott and Ewen Callaway. Nobel prize for decoding brain’s sense of place. Nature News,
514(7521):153, 2014.
Benjamin Adams, Grant McKenzie, and Mark Gahegan. Frankenplace: interactive thematic mapping
for ad hoc exploratory search. In Proceedings of the 24th international conference on world wide
web, pp. 12-22. International World Wide Web Conferences Steering Committee, 2015.
Andrea Banino, Caswell Barry, Benigno Uria, Charles Blundell, Timothy Lillicrap, Piotr Mirowski,
Alexander Pritzel, Martin J Chadwick, Thomas Degris, Joseph Modayil, et al. Vector-based
navigation using grid-like representations in artificial agents. Nature, 557(7705):429, 2018.
G Baudat and F Anouar. Kernel-based methods and function approximation. volume 2, pp. 1244 -
1249 vol.2, 02 2001. ISBN 0-7803-7044-9. doi: 10.1109/IJCNN.2001.939539.
Thomas Berg, Jiongxin Liu, Seung Woo Lee, Michelle L Alexander, David W Jacobs, and Peter N
Belhumeur. Birdsnap: Large-scale fine-grained visual categorization of birds. In Proceedings of
the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2011-2018, 2014.
Herman J. Bierens. The nadaraya-watson kernel regression function estimator. Topics in Advanced
Econometrics, 16:212-247, 1994.
Hugh T Blair, Adam C Welday, and Kechen Zhang. Scale-invariant memory representations emerge
from moire interference between grid fields that produce theta oscillations: a computational model.
Journal of Neuroscience, 27(12):3211-3229, 2007.
Grace Chu, Brian Potetz, Weijun Wang, Andrew Howard, Yang Song, Fernando Brucher, Thomas
Leung, and Hartwig Adam. Geo-aware networks for fine grained recognition. arXiv preprint
arXiv:1906.01737, 2019.
Christopher J Cueva and Xue-Xin Wei. Emergence of grid-like representations by training recurrent
neural networks to perform spatial localization. arXiv preprint arXiv:1803.07770, 2018.
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert: Pre-training of deep
bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805, 2018.
A Stewart Fotheringham and David WS Wong. The modifiable areal unit problem in multivariate
statistical analysis. Environment and planning A, 23(7):1025-1044, 1991.
Ruiqi Gao, Jianwen Xie, Song-Chun Zhu, and Ying Nian Wu. Learning grid cells as vector represen-
tation of self-position coupled with matrix representation of self-motion. In Proceedings of ICLR
2019, 2019.
Nataliia Kussul, Mykola Lavreniuk, Sergii Skakun, and Andrii Shelestov. Deep learning classification
of land cover and crop types using remote sensing data. IEEE Geoscience and Remote Sensing
Letters, 14(5):778-782, 2017.
Alex M Lechner, William T Langford, Simon D Jones, Sarah A Bekessy, and Ascelin Gordon. Inves-
tigating species-environment relationships at multiple scales: Differentiating between intrinsic
scale and the modifiable areal unit problem. Ecological Complexity, 11:91-102, 2012.
Yaguang Li, Rose Yu, Cyrus Shahabi, and Yan Liu. Diffusion convolutional recurrent neural network:
Data-driven traffic forecasting. arXiv preprint arXiv:1707.01926, 2017.
Oisin Mac Aodha, Elijah Cole, and Pietro Perona. Presence-only geographical priors for fine-grained
image classification. arXiv preprint arXiv:1906.05272, 2019.
Gengchen Mai, Krzysztof Janowicz, Bo Yan, Rui Zhu, Ling Cai, and Ni Lao. Contextual graph
attention for answering logical queries over incomplete knowledge graphs. In Proceedings of the
10th International Conference on Knowledge Capture, pp. 171-178, 2019a.
Gengchen Mai, Bo Yan, Krzysztof Janowicz, and Rui Zhu. Relaxing unanswerable geographic
questions using a spatially explicit knowledge graph embedding model. In AGILE: The 22nd
Annual International Conference on Geographic Information Science, pp. 21-39. Springer, 2019b.
11
Published as a conference paper at ICLR 2020
V Maz’ya and G Schmidt. On approximate approximations using gaussian kernels. IMA Journal of
Numerical Analysis,16:13-29, 01 1996.
Grant McKenzie, Krzysztof Janowicz, Song Gao, Jiue-An Yang, and Yingjie Hu. Poi pulse: A
multi-granular, semantic signature-based information observatory for the interactive visualization
of big geosocial data. Cartographica: The International Journal for Geographic Information and
Geovisualization, 50(2):71-85, 2015.
Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean. Distributed representations
of words and phrases and their compositionality. In Advances in neural information processing
systems, pp. 3111-3119, 2013.
Justin Moat, Steven P Bachman, Richard Field, and Doreen S Boyd. Refining area of occupancy to
address the modifiable areal unit problem in ecology and conservation. Conservation biology, 32
(6):1278-1289, 2018.
Stan Openshaw. The modifiable areal unit problem. Concepts and techniques in modern geography,
1984.
Jeffrey Pennington, Richard Socher, and Christopher Manning. Glove: Global vectors for word
representation. In Proceedings of the 2014 conference on empirical methods in natural language
processing (EMNLP), pp. 1532-1543, 2014.
Matthew E Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee, and
Luke Zettlemoyer. Deep contextualized word representations. arXiv preprint arXiv:1802.05365,
2018.
Charles R Qi, Hao Su, Kaichun Mo, and Leonidas J Guibas. Pointnet: Deep learning on point sets for
3d classification and segmentation. In Proceedings of the IEEE Conference on Computer Vision
and Pattern Recognition, pp. 652-660, 2017.
Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jon Shlens, and Zbigniew Wojna. Rethinking
the inception architecture for computer vision. In Proceedings of the IEEE conference on computer
vision and pattern recognition, pp. 2818-2826, 2016.
Kevin Tang, Manohar Paluri, Li Fei-Fei, Rob Fergus, and Lubomir Bourdev. Improving image
classification with location context. In Proceedings of the IEEE international conference on
computer vision, pp. 1008-1016, 2015.
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez,匕Ukasz
Kaiser, and Illia Polosukhin. Attention is all you need. In Advances in Neural Information
Processing Systems, pp. 5998-6008, 2017.
Petar Velickovic, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, and Yoshua
Bengio. Graph attention networks. In ICLR 2018, 2018.
Bo Yan, Krzysztof Janowicz, Gengchen Mai, and Song Gao. From itdl to place2vec: Reasoning about
place type similarity and relatedness by learning embeddings from augmented spatial contexts. In
Proceedings of the 25th ACM SIGSPATIAL International Conference on Advances in Geographic
Information Systems, pp. 35. ACM, 2017.
Bo Yan, Krzysztof Janowicz, Gengchen Mai, and Rui Zhu. xnet+ sc: Classifying places based
on images by incorporating spatial contexts. In 10th International Conference on Geographic
Information Science (GIScience 2018). Schloss Dagstuhl-Leibniz-Zentrum fuer Informatik, 2018.
Manzil Zaheer, Satwik Kottur, Siamak Ravanbakhsh, Barnabas Poczos, Ruslan R Salakhutdinov,
and Alexander J Smola. Deep sets. In Advances in neural information processing systems, pp.
3391-3401, 2017.
Wenyun Zuo, Ni Lao, Yuying Geng, and Keping Ma. Geosvm: an efficient and effective tool to
predict species’ potential distributions. Journal of Plant Ecology, 1(2):143-145, 2008.
12
Published as a conference paper at ICLR 2020
A	Appendix
A.1	Baselines
To help understand the mechanism of distributed space representation we compare multiple ways of
encoding spatial information. Different models use different point space encoder Encpxq pq to encode
either location xi (for location modeling loc) or the displacement between the center point and one
context point ∆xij “ xi ´ xij (for spatial context modeling cont)8.
•	random shuffles the order of the correct POI and N negative samples randomly as the
predicted ranking. This shows the lower bound of each metrics.
•	direct directly encode location xi (or ∆xij for cont) into a location embedding erxis (or
er∆xij s) using a feed-forward neural networks (FFNs)9, denoted as Encpdxirqect pxq without
decomposing coordinates into a multi-scale periodic representation. This is essentially the
GPS encoding method used by Chu et al. (2019). Note that Chu et al. (2019) is not open
sourced and we end up implementing the model architecture ourselves.
•	tile divides the study area Aloc (for loc) or the range of spatial context defined by λmax ,
Acont, (for cont) into grids with equal grid sizes c. Each grid has an embedding to be used
as the encoding for every location xi or displacement ∆xij fall into this grid. This is a
common practice by many previous work when dealing with coordinate data (Berg et al.,
2014; Adams et al., 2015; Tang et al., 2015).
•	wrap is a location encoder model recently introduced by Mac Aodha et al. (2019). It
first normalizes x (or ∆x) into the range r´1, 1s and uses a coordinate wrap mechanism
rsinpπxrls q; cospπxrls qs to convert each dimension of x into 2 numbers. This is then passed
through an initial fully connected layer, followed by a series of h residual blocks, each
consisting of two fully connected layers (o hidden neurons) with a dropout layer in between.
We adopt the official code of Mac Aodha et al. (2019)10 11 for this implementation.
•	rbf randomly samples M points from the training dataset as RBF anchor points
{xamnchor, m “ 1...M} (or samples M ∆xamnchor from Acont for cont) 11, and use gaus-
anchor 2	anchor 2
Sian kernels exp ' ´ k-i——m——k-) (or exp ' ´ k——ij-------产--------k-) for Cont)
2σ2	2σ2
on each anchor points, where σ is the kernel size. Each point pi has a M -dimension RBF
feature vector which is fed into a FNN to obtain the spatial embedding. This is a strong
baseline for representing floating number features in machine learning models.
•	grid as described in Section 4.1 inspired by the position encoding in Transformer (Vaswani
et al., 2017).
•	hexa Same as grid but use sinpθq, sinpθ ` 2π{3q, and sinpθ ` 4π{3q in P Espg,lq pxq.
•	theory as described in Section 4.1, uses the theoretical models (Gao et al., 2019) as the first
layerofEnctphxqeorypxq orEnctphxqeoryp∆xijq.
•	theorydiag further constrains NNpq as a block diagonal matrix, with each scale as a block.
We also have the following baselines which are specific to the spatial context modeling task.
•	none the decoder Decc pq does not consider the spatial relationship between the center point
and context points but only the co-locate patterns such as Place2Vec (Yan et al., 2017). That
means we drop the er∆xij s from the attention mechanism in Equ. 7 and 8.
•	polar first converts the displacement ∆xij into polar coordinates pr, θq centered at the
center point where r “ log(∣∣ ∆xj ∣∣ +1). Then it uses [r, θ] as the input for a FFN to
obtain the spatial relationship embedding in Equ. 7. We find out that it has a significant
performance improvement over the variation with r =∣ ∆xj ∣.
8We will use meter as the unit of λmin , λmax , σ, c.
9we first normalizes x (or ∆x) into the range r´1, 1s
10http://www.vision.caltech.edu/~macaodha/projects/geopriors/
11these anchor points are fixed in both loc and cont.
13
Published as a conference paper at ICLR 2020
•	polar_tile is a modified version of tile but the grids are extracted from polar coordinates
(r, θ) centered at the center point where r “ log(∣ ∆xij k +1). Instead of using grid size
c, we use the number of grids along θ (or r) axis, F , as the only hyperparameter. Similarly,
We find that r “ logpk ∆xij k +1) outperform r “k ∆xij k significantly.
scaled_rbf is a modified version of rbf for cont whose kernel size is proportional to
the distance between the current anchor point and the origin, k ∆xamnchor k. That is
exp ´
k ∆χj ´ ∆xmrhor k2
2σ2 ,,
σscaled
. Here σscaled “ σ + β k ∆xamnchor k where σ is the
basic kernel size and β is kernel rescale factor, a constant. We developed this mechanism
to help RFB to deal with relations at different scale, and we observe that it produces
significantly better result than vanilla RBFs.
A.2 Hyper-Parameter Selection
We perform grid search for all methods based on their performance on the validation sets.
Location Modeling The hyper-parameters of theory models are based on grid search with
dpvq “ p32, 64, 128, 256), dpxq “ p32, 64, 128, 256), S “ p4, 8, 16, 32, 64, 128), and λmin “
p1, 5, 10, 50, 100, 200, 500, 1k) while λmax “ 40k is decided based on the total size of the study
area. We find out the best performances of different grid cell based models are obtained when
dpvq “ 64, dpxq “ 64, S “ 64, and λmin “ 50. In terms of tile, the hyper-parameters are se-
lected from c “ p10, 50, 100, 200, 500, 1000) while c “ 500 gives us the best performance.As
for rbf, we do grid search on the hyper-parameters: M “ p10, 50, 100, 200, 400, 800) and
σ “ p102, 103, 104, 105, 106, 107). The best performance of rbf is obtain when M “ 200 and
σ “ 103. As for wrap, grid search is performed on: h “ p1, 2, 3, 4) and o “ p64, 128, 256, 512)
while h “ 3 and o “ 512 gives us the best result. All models use FFNs in their Encpxqp) except
wrap. The number of layers f and the number of hidden state neurons u of the FFN are selected from
f “ p1, 2, 3) and u “ p128, 256, 512). We find out f “ 1 and u “ 512 give the best performance
for direct, tile, rbf, and theory. So we use them for every model for a fair comparison.
Spatial Context Modeling Grid search is used for hyperparameter tuning and the best performance
of different grid cell models is obtain when dpvq “ 64, dpxq “ 64, S “ 64, and λmin “ 10. We set
λmax “ 10k based on the maximum displacement between context points and center points to make
the location encoding unique. As for multiple baseline models, grid search is used again to obtain the
best model. The best model hyperparameters are shown in () besides the model names in Table 3.
Note that both rbf and scaled_rbf achieve the best performance with M “ 100.
Figure 4: The firing pattern for the first 8 neurons (out of 64) given different encoders in location modeling.
14
Published as a conference paper at ICLR 2020
A.4 Embedding clustering of RBF and theory models
(a) λmin=200
(b) λmin=100
(c) λmin=50
(d) λmin = 10
(e) λmin=200
(f) λmin=100
0	1	2	3	4	5	6
f6-
-5 5-
(g) λmin =50
(h) λmin=10
Figure 5: Embedding clustering in the original space of (a)(b)(c)(d) theory with different λmin , but the
same λmax “ 10k and S “ 64. (e)(f)(g)(h) are the embedding clustering results of the same models in the
polar-distance space. All models use 1 hidden ReLU layers of 512 neurons.
(e) β=0.0	(f) β=0.1	(g) β=0.2	(h) β=0.3
Figure 6: Embedding clustering of RBF models with different kernel rescalar factor β (a)(b)(c)(d) in the original
space; (e)(f)(g)(h) in the polar-distance space. Here β=0.0 indicates the original RBF model. All models use
σ=10m as the basic kernel size and 1 hidden ReLU layers of 512 neurons.
15