Table 1: Robustness comparison of different models. We report their mean classification accuracies(%) and standard deviations (mean ± std) on perturbed images from the MNIST, the SVHN, andthe ImgNet10 datasets. Two types of perturbations are used-zero-mean Gaussian noise and FGSMadversarial attack. The results show that ODENets are much more robust in comparison to CNNmodels.
Table 2: Robustness comparison of different models. We report their mean classification accuracies(%) and standard deviations (mean ± std) on perturbed images from the MNIST, the SVHN, andthe ImgNet10 datsets. Three types of perturbations are used-zero-mean Gaussian noise, FGSMadversarial attack, and PGD adversarial attack. The results show that ODENets are more robustcompared to CNN models.
Table 3: Classification accuracy (mean ± Std in %) on perturbed images from MNIST, SVHN andImgNet10. To evaluate the robustness of classifiers, We use three types of perturbations, namelyzero-mean Gaussian noise with standard deviation σ, FGSM attack and PGD attack. From theresults, the proposed TisODE effectively improve the robustness of the vanilla neural ODE.
Table 4: Classification accuracy (mean ± std in %) on perturbed images from MNIST and SVHN.
Table 5: The architectures of the ODENets on different datasets.
Table 6: The corresponding indexes to each class in the original ImageNet datasetClass	Indexing-dog-	n02090721,^^n02091032,^^n02088094bird	n01532829,	n01558993,	n01534433car	n02814533,	n03930630,	n03100240fish	n01484850,	n01491361,	n01494475monkey	n02483708,	n02484975,	n02486261turtle	n01664065,	n01665541,	n01667114lizard	n01677366,	n01682714,	n01685808bridge	n03933933,	n04366367,	n04311004cow	n02403003,	n02408429,	n02410509crab	n01980166,	n01978455,	n019812767.3	GRONWALL'S INEQUALITYWe formally state the Gronwall's Inequality here, following the version in (Howard, 1998).
Table 7: Classification accuracy (%) on perturbed images from MNIST. To evaluate the robustnessof classifiers, We use three types of perturbations, namely zero-mean Gaussian noise with standarddeviation σ, FGSM attack and PGD attack.
Table 8: Classification accuracy (%) on perturbed images from CIFAR10. To evaluate the robustnessof classifiers, we use two types of perturbations, namely zero-mean Gaussian noise with standarddeviation σ and FGSM attack.
Table 9: The architecture of the ODENet on CIFAR10.
