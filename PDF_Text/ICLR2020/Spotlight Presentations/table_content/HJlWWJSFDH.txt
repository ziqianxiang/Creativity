Table 1: Test ROC-AUC (%) performance on molecular prediction benchmarks using differentpre-training strategies with GIN. The rightmost column averages the mean of test performanceacross the 8 datasets. The best result for each dataset and comparable results (i.e., results within onestandard deviation from the best result) are bolded. The shaded cells indicate negative transfer, i.e.,ROC-AUC of a pre-trained model is worse than that of a non-pre-trained model. Notice that node- aswell as graph-level pretraining are essential for good performance.
Table 2: Test ROC-AUC (%) performance of different GNN architectures with and withoutpre-training. Without pre-training, the less expressive GNNs give slightly better performancethan the most expressive GIN because of their smaller model complexity in a low data regime.
Table 3: 10-fold cross validation accuracy (%) on classic graph classification benchmarks usingdifferent pre-training strategies with GIN. All the previous results are excerpted from Xu et al.
Table 4: Test ROC-AUC (%) performance on molecular prediction benchmarks with differentGNN architectures. The rightmost column averages the mean of test performance across the 8datasets. For pre-training, we applied Context Prediction + graph-level supervised pre-training.
