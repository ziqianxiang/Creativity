Figure 1: “Are both dots on the same object?”(a) Bottom-up grouping. Our visual system cansegregate an object from its background with rapid, bottom-up mechanisms, when the object isdissimilar to its background. In this case, the object is said to “pop-out” from its background, makingit trivial to judge whether the two dots are on the same object surface or not. (b) Non-bottom-upprocesses. Perceptual grouping mechanisms help segment a visual scene. (b, Top) The elements of abehaviorally relevant perceptual object, such as a path formed by tracks in the snow, are transitivelygrouped together according to low-level “Gestalt” principles. This allows the observer to trace apath from one end to the other. (b, Bottom) Alternatively, observers may rely on prior knowledge orsemantic cues to segment an object from a cluttered background. (c) Synthetic grouping tasks. (c,Top) The Pathfinder challenge (reproduced with permission from Linsley et al. (2018b) and inspiredby Houtkamp & Roelfsema 2010) involves answering a simple question: "Are the two dots connectedby a path?" This task can be easily solved with Gestalt grouping strategies. (c, Bottom) Here, weintroduce a novel “cluttered ABC” (cABC) challenge, inspired by Vecera & Farah (1997). The cABCchallenge asks the same question on visual stimuli for which Gestalt strategies are ineffective. Instead,cABC taps into object-based strategies for perceptual grouping.
Figure 2: An overview of the two synthetic visual reasoning challenges used: the “Pathfinder”(top two rows) and the “cluttered ABC” (cABC, bottom two rows). On both tasks, a modelmust judge whether the two white markers fall on the same or different paths/letters. For both, weparametrically controlled task difficulty by adjusting intra-class image variability in the image dataset.
Figure 3: We define a convolutional RNN model that can learn feedforward (gray), horizontal(green), and/or top-down (red) connections to disentangle the contributions of each type ofconnections for perceptual grouping. (a) A conceptual diagram of the TD+H-CNN architecture,depicting three layers of activity and feedforward, horizontal, and top-down connections. (b) Adeep learning diagram of the TD+H-CNN, unraveled over processing timesteps. Bottom-up totop-down passes of the input image allow recurrent horizontal (green fGRUs) and top-down (redfGRU) interactions between units to evolve. This allows the model to implement complex groupingstrategies, like transitively linking target features together or selecting whole objects from clutter.
Figure 4: Pathfinder and cABC challenges disentangle the relative contributions of horizontalvs. top-down connections for perceptual grouping. (a) Accuracies of human and neural networkmodels on three levels of the Pathfinder and cABC challenges. While human participants and theTD+H-CNN model are able to solve all difficulties of each challenge, Pathfinder strains the TD-CNNand cABC strains the H-CNN. (b) We visualized the computations learned by our networks usingimages containing single markers (See Appendix B for details.) We found that H-CNN and TD-CNNlearn distinct strategies to solve Pathfinder and cABC challenges, respectively. The H-CNN solvesPathfinder by iteratively grouping segments of a target path while suppressing background clutter.
Figure 5: Pathfinder and cABC challenges are efficiently solved by visual strategies that dependon feedback - not feedforward - processing. (a) Performance of feedforward models on eachdifficulty of the two challenges. Deeper ResNet models solved Pathfinder, whereas the ResNet-18 andU-Net solved cABC, indicating a trade-off between capacity vs. parameter efficiency for feedforwardstrategies to Pathfinder vs. cABC, respectively (failures to generalize reflect overfitting). (b) Thenumber of parameters of each model (plotted as a multiple of the number of parameters in theH-CNN) plotted against model performance on the hard dataset of each challenge. The H+TD-CNNsolves both challenges with an order-of-magnitude fewer parameters than reference ResNet andU-Net models. (c) Correlations between human and leading model decisions on the hard datasetof each challenge. The TD+H-CNN and its successful lesioned variants were significantly morecorrelated with humans than successful feedforward reference models. Significance comparisonswith the worst feedforward reference model omitted due to space constraints. P-values are derivedfrom bootstrapped comparisons of model performance (Edgington, 1964). Error bars depict SEM; *:P <0.05; **: P <0.01.
Figure S1: Visual depiction of the CABC image generation algorithm. (Top row) Generationprocedure of individual letter images. Two independently sampled letter categories are renderedin a randomly sampled (but same) font. Each letter image undergoes three linear transformations 一scale, rotation and shear - as well as two steps of nonlinear transformations - warp and pixelation.
Figure S2:	Two example letter images undergoing geometric warping. A “warp template” for eachimage is sampled by randomly overlaying 10 Gaussian images. Each pixel in a letter image istranslated by a displacement proportional to the gradient of its warp template in the correspondinglocation.
Figure S3:	Two control cABC challenges. In luminance control, two letters are rendered in different,randomly sampled pixel intensity values. In positional control, two letters are always rendered withouttouching or overlapping each other.
Figure S4:	Segmentation version of the two challenges. Here, a model is tasked with producing asoutput an image which contains only the object which is marked in the input image.
Figure S5:	Performance on two cABC-control challenges. Top-down feedback is critical whenlocal grouping cues are unavailable. We verify this by constructing two controlled versions of thecABC challenge, where local Gestalt grouping cues are provided in the form of spatial segregationbetween two letters (a), or in the form of luminance segregation (b). In both cases, the architecturesthat lack top-down feedback mechanism can solve the challenge at all levels of difficulties.
Figure S6:	fGRUs outperform GRUs and LSTMs on Pathfinder and cABC. Our recurrent hier-archical architectures performed better on Pathfinder and cABC challenges when they used fGRUsinstead of either LSTMs (Hochreiter & Schmidhuber, 1997) or GRUs (Cho et al., 2014a).
Figure S7: Recurrence improves fGRU model performance on Pathfinder and cABC. Each ofour recurrent models performed better when given 8-timesteps of recurrent processing instead of 1timestep.
Figure S8: A comparison of different Parameterizations of H+TD-CNN and ResNet-18 modelson Pathfinder and cABC. (a) We compared the original H+TD-CNN to a deeper version (5 insteadof 3 convolutional blocks between its low- and high-level fGRU modules). This deeper H+TD-CNNperformed similarly to the original version. We also tested whether widening the ResNet-18 couldrescue its performance on Pathfinder. Indeed, the wider ResNet-18 (matched in number of parametersto ResNet-50) performed far better on Pathfinder than the original version, but was still far worse onthe task than a normal ResNet-50. (b) Performance of each of these models is plotted as a function oftheir total free parameters. Variants of the TD+H-CNN are far more parameter efficient at solvingPathfinder and CABC than variants of ResNet-18. Ellipses group variants of each model class.
Figure S9: Our recurrent convolutional architectures. Feedforward or bottom-up connections(gray) pass information from lower-order to higher-order layers; horizontal connections (green) passinformation between units in the same layer separated by spatial location and/or channels; top-downconnections (red) pass information from higher-order to lower-order layers. We use “feedback” as anumbrella term for both top-down and horizontal connections as these can only be implemented in amodel with recurrent activity that supports incremental updates to model units.
