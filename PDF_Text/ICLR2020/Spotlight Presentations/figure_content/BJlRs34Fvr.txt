Figure 1: Left: Illustration of the last 3 skip connections (green lines) and residual modules (blackboxes) of a ImageNet-trained ResNet-18. Right: The success rate (in the form of “white-box/black-box”) of adversarial attacks crafted using gradients flowing through either a skip connection (goingupwards) or a residual module (going leftwards) at each junction point (circle). Three examplebackpropagation paths are highlighted in different colors, with the green path skipping over the lasttwo residual modules having the best attack success rate while the red path through all 3 residualmodules having the worst attack success rate. The attacks are crafted by BIM on 5000 ImageNetvalidation images under maximum L∞ perturbation = 16 (pixel values are in [0, 255]). Theblack-box success rate is tested against a VGG19 target model.
Figure 2: The attack success rates of black-box attacks crafted by different attack methods on 8source models against 3 unsecured target models: VGG19 (left), SE154 (middle) and IncV3 (right).
Figure 3: Parameter tuning: the success rates of black-box attacks crafted by 10-step SGM withvarying decay parameter γ ∈ [0.1, 1.0]. The solid and dash curves represent results on ResNet andDenseNet source models respectively.
Figure 4: White-box success rate for FGSM versus SGM. In (b) and (c), each color corresponds toone model, with FGSM is represented by solid curve and SGM is represented by dashed curve.
Figure 5: Visualization of 6 clean images and their corresponding adversarial examples. The cleanimages are shown in the top row, adversarial images crafted on ResNet-152 are shown in the middlerow, while those crafted on DenseNet-201 are shown in the bottom row. All adversarial images arecrafted using our proposed SGM (10-step) under maximum perturbation = 16.
Figure 6: “Transferability” of decay parameter: the success rates of black-box attacks crafted by10-step SGM with varying decay parameter γ ∈ [0.1, 1.0]. The curves represent results againstdifferent target models respectively.
