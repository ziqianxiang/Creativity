Figure 1: We trained latent variable models for posterior inference, which requires minimizing logprobability under the model. Training with IWAE leads to optimizing for the bias while leaving thetrue model in an unstable state, whereas training with SUMO—though noisy—leads to convergence.
Figure 2: Training with reverse KL requires min-imizing log p(X). SUMO estimates are unbiasedand trains well, but minimizing the lower boundIWAE with small k leads to estimates of -∞.
Figure 3: Latent variable policies allow faster exploration than autoregressive policy models, whilebeing more expressive than an independent policy. SUMO works well with entropy regularization,whereas IWAE is unstable and converges to similar performance as the non-latent variable model.
Figure 4: A comparison of SUMO estimations with different distributions and IWAE estimations oftest negative log-likelihood on a trained model with IWAE1 objective on MNIST. The expected costis K + 5 for each evaluation. The results are averaged over 100 runs (mean in bold and std shaded).
Figure 5: Empricial validation of the convergence rate of the norms of ∆ and ∆g.
Figure 6: Test negative log-likelihood against the gradient clipping norm and clipping percentage,when training with SUMO (k=15).
