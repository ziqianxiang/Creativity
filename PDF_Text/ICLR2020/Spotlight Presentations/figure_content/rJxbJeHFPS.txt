Figure 1:	Overview of reasoning tasks with increasingly complex structure. Each task categoryshows an example task on which we perform experiments in Section 4. Algorithmic alignmentsuggests that (a) Deep Sets and GNNs, but not MLP, can sample efficiently learn summary statistics,(b) GNNs, but not Deep Sets, can learn relational argmax, (c) GNNs can learn dynamic programming,an algorithmic paradigm that we show to unify many reasoning tasks, (d) GNNs cannot learn subsetsum (NP-hard), but NES, a network we design based on exhaustive search, can generalize. Our theoryagrees with empirical results (Fig. 3).
Figure 2:	Our framework suggests that better algorithmic alignment improves generalization.
Figure 3: Test accuracies on reasoning tasks with increasingly complex structure. Fig. 1 showsan overview of the tasks. GNNk is GNN with k iterations. (a) Summary statistics. All models exceptMLP generalize. (b) Relational argmax. Deep Sets fail. (c) Dynamic programming. Only GNNs withsufficient iterations generalize. (d) An NP-hard problem. Even GNNs fail, but NES generalizes.
Figure 4: Test accuracy vs. training set size for models trained on sub-sampled training sets andevaluated on the same test set of monster trainer (DP task). Test accuracies increase faster when aneural network aligns well with an algorithmic solution of the task. For example, the test accuracyof GNN4 increases by 23% when the number of training samples increases from 40, 000 to 80, 000,which is much higher than that of Deep Sets (0.2%).
