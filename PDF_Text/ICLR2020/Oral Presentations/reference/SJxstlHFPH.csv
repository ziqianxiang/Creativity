title,year,conference
 Neural query language: A knowledge basequery language for tensorflow,2019, arXiv preprint arXiv:1905
 Bert: Pre-training of deepbidirectional transformers for language understanding,2019, NAACL
 Neuralmodels for reasoning over multiple mentions using coreference,2018, In North American Associationfor Computational Linguistics (NAACL)
 Cognitive graph for multi-hopreading comprehension at scale,2019, In Association for Computational Linguistics (ACL)
 Billion-scale similarity search with gpus,2017, arXivpreprint arXiv:1702
 Exploiting explicit paths for multi-hop readingcomprehension,2019, In Association for Computational Linguistics (ACL)
 Key-value memory networks for directly reading documents,2016, arXiv preprintarXiv:1606
 Distant supervision forrelation extraction with an incomplete knowledge base,2013, In Proceedings of the 2013 Conference ofthe North American Chapter of the Association for Computational Linguistics: Human LanguageTechnologies
 Sling: A framework for frame semanticparsing,2017, arXiv preprint arXiv:1710
 Green ai,2019, arXiv preprintarXiv:1907
 Bidirectional attentionflow for machine comprehension,2016, arXiv preprint arXiv:1611
 Energy and policy considerations for deeplearning in nlp,2019, arXiv preprint arXiv:1906
 What do you learn fromcontext? probing for sentence structure in contextualized word representations,2019, In InternationalConference on Learning Representations
 Attention is all you need,2017, In Advances in neural informationprocessing systems
 Wikidata: a free collaborative knowledge base,2014, 2014
 Dynami-cally fused graph network for multi-hop reasoning,2019, In Association for Computational Linguistics(ACL)
 Leveraging knowledge bases in lstms for improving machine read-ing,2017, 2017
 Embedding entities andrelations for learning and inference in knowledge bases,2014, arXiv preprint arXiv:1412
