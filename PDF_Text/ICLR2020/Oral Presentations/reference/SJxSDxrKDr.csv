title,year,conference
 Obfuscated gradients give a false sense of se-curity: Circumventing defenses to adversarial examples,2018, In Proceedings of the 35th InternationalConference on Machine Learning
 Certi-fying geometric robustness of neural networks,2019, In Advances in Neural Information ProcessingSystems
 Evasion attacks against machine learning at test time,2013, In JointEuropean conference on machine learning and knowledge discovery in databases
 Certified adversarial robustness via randomizedsmoothing,2019, In Proceedings of the 36th International Conference on Machine Learning
 Training verified learners with learned ver-ifiers,2018, arXiv preprint arXiv:1805
 ExPlaining and harnessing adversarialexamPles,2015, In International Conference on Learning Representations
 On the effectiveness of interval bound ProPagation fortraining verifiably robust models,2018, arXiv preprint arXiv:1810
 Formal guarantees on the robustness of a classifieragainst adversarial maniPulation,2017, In Advances in Neural Information Processing Systems
 ReluPlex: Anefficient smt solver for verifying deeP neural networks,2017, In International Conference on ComputerAided Verification
 Adam: A method for stochastic oPtimization,2014, arXiv preprintarXiv:1412
 Differentiable abstract interpretation for prov-ably robust neural networks,2018, In International Conference on Machine Learning
 A provable defense for deep residualnetworks,2019, arXiv preprint arXiv:1903
 Towards verifying robustness of neuralnetworks against semantic perturbations,2019, arXiv preprint arXiv:1912
 Automatic differentiation inpytorch,2017, 2017
 Verification of non-linearspecifications for neural networks,2019, In International Conference on Learning Representations
 Certified defenses against adversarial exam-ples,2018, In International Conference on Learning Representations
 Provably robust deep learning via adversarially trained smoothed classifiers,2019, arXivpreprint arXiv:1906
 A convex relaxationbarrier to tight robust verification of neural networks,2019, arXiv preprint arXiv:1902
 Fast andeffective robustness certification,2018, In Advances in Neural Information Processing Systems
 Beyond the single neuronconvex barrier for neural network certification,2019, In Advances in Neural Information ProcessingSystems
 Boosting robustness certifica-tion of neural networks,2019, In International Conference on Learning Representations
 An abstract domain for certi-fying neural networks,2019, Proceedings of the ACM on Programming Languages
 Intriguing properties of neural networks,2013, arXiv preprint arXiv:1312
 Evaluating robustness of neural networks with mixedinteger programming,2019, In International Conference on Learning Representations
 Towards fast computation of certified robustness for ReLU networks,2018, InProceedings of the 35th International Conference on Machine Learning
 Scaling provable adversarialdefenses,2018, In Advances in Neural Information Processing Systems 31
 Training forfaster adversarial robustness verification via inducing reLU stability,2019, In International Conferenceon Learning Representations
 Feature denoisingfor improving adversarial robustness,2019, In Proceedings of the IEEE Conference on Computer Visionand Pattern Recognition
 Reproducibility issue,2019, 2019
 Correctness verification of neural networks,2019, arXiv preprintarXiv:1906
 Efficient neural net-work robustness certification with general activation functions,2018, In Advances in neural informationprocessing systems
 Towards sta-ble and efficient training of verifiably robust neural networks,2019, arXiv preprint arXiv:1906
 Towards stable and efficient training of verifiably robust neural networks,2020, InInternational Conference on Learning Representations
