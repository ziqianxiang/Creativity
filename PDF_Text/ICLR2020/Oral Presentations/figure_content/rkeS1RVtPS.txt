Figure 1: Illustration of the proposed cyclical stepsizeschedule (red) and the traditional decreasing stepsizeschedule (blue) for SG-MCMC algorithms.
Figure 3: Results of cSG-MCMC with DNNs on the CIFAR-100 dataset. (a) MDS visualization inweight space: cSG-MCMC show larger distance than traditional schedules. (b) Testing errors (%)on the path of two samples: cSG-MCMC shows more varied performance. (c) Testing errors (%) asa function of the number of cycles M : cSGLD yields consistently lower errors.
Figure 2: Sampling from a mixture of 25 Gaus-sians shown in (a) for the parallel setting. Witha budget of 50k Ã— 4 = 200k samples, traditionalSGLD in (b) has only disCovered 4 of the 25modes, while our CSGLD in (C) has fully exploredthe distribution.
Figure 4: Empirical CDF for the entropy ofthe predictive distribution on notMNIST dataset.
Figure 5: Sampling from a mixture of25 Gaussians in the non-parallel setting. With a budget of 50Ksamples, traditional SGLD has only discovered one of the 25 modes, while our proposed cSGLDhas explored significantly more of the distribution.
Figure 6: NLL and error (%) as a function of temeprature on CIFAR-10 using cSGLD. The bestperformance of both NLL and error is achieved at T = 0.1.
Figure 7: NLL and error (%) as a function of temeprature on CIFAR-100 using cSGLD. The bestperformance of both NLL and error is achieved at T = 0.01.
