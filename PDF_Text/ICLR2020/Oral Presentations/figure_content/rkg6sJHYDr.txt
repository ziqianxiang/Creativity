Figure 1: Population-based intrinsically motivated goal exploration process with incremental learn-ing of a goal space (IMGEP-OGL algorithm) used to explore a continuous GOL model.
Figure 2: Example patterns produced in the continuous GOL system (Lenia). Illustration of thedynamical morphing from an initial CPPN image to an animal (a). The automated discovery (b) isable to find similar complex animals as a human-expert manual search (c) by Chan (2019).
Figure 3: (a) Although random explorations reach the highest diversity in the analytic parameterspace, (b) IMGEPs reach a higher diversity in the analytic behavior space (except when using ran-dom representations). (c) IMGEPs with a learned goal space discovered a larger diversity of animalscompared to a hand-defined goal space. (d) Learned goal spaces are as efficient as a hand-definedspace for finding diverse non-animals. Overall, IMGEPs with unsupervised learning of goal featuresare efficient to discover a diversity of diverse patterns. Depicted is the average diversity (n = 10)with the standard deviation as shaded area (for some not visible because it is too small). The finaldiversity is significantly different (Welchs t-test, p < 0.01) for algorithms between the braces plottedon the right of each figure. See Figs. 6 to 10 for a qualitative visual illustration of these results.
Figure 4: (a) Hand-defined and (b) learned goal spaces have major differences shown here by a t-SNE visualization. The different number and size of clusters of animals or non-animals can explainthe differences in their resulting diversity between the algorithms (Fig. 3).
Figure 5: Proportion of patterns for each class and algorithm. Each dot besides the boxplot showsthe proportion of found patterns for each repetition (n = 10). The box ranges from the upper tothe lower quartile. The whiskers represent the upper and lower fence. The mean is indicated by thedashed line and the median by the solid line.
Figure 6: Randomly selected examples of patterns discovered by the random exploration algorithmduring a single exploration with 5000 iterations.
Figure 7: Randomly selected examples of patterns discovered by the IMGEP-RGS algorithm duringa single exploration with 5000 iterations.
Figure 8: Randomly selected examples of patterns discovered by the IMGEP-HGS algorithm duringa single exploration with 5000 iterations.
Figure 9: Randomly selected examples of patterns discovered by the IMGEP-PGL algorithm duringa single exploration with 5000 iterations.
Figure 10: Randomly selected examples of patterns discovered by the IMGEP-OGL algorithm dur-ing a single exploration with 5000 iterations.
Figure 11: PCA and t-SNE visualization of the goal spaces for the IMGEP variants show that HGShas more area (PCA) and clusters (t-SNE) for non-animals compared to learned goal spaces (PGLand OGL) and vice versa for animals. t-SNE shows that the hand-defined goal space (HGS) andlearned goal spaces (PGL and OGL) structure and cluster more the discovered patterns compared torandom goal space (RGS).
Figure 13: CPPNs are recurrent neural networks. Their input is a bias of 1, the X and y coordinateof a grid cell and its center distance d. Their output is the activity value of the grid cell.
Figure 14: CPPNs can generate complex patterns via their random initialization and successivemutations. Each row shows generated patterns by one CPPN and its mutations.
Figure 15: Averaged learning curves (n = 10) of the β-VAEs for the IMGEP-PGL and OGLexperiments.
Figure 16: Examples of patterns (left) and their reconstruction (right) by β-VAE networks usedfor the IMGEP-PGL (a) and OGL (b). The patterns are sampled from their validation dataset. Forthe PGL (a) the dataset is composed of animal patterns (row 1) from Chan (2019) and randomlygenerated CPPN patterns (row 2). For the OGL (b) it is composed of animal patterns (row 1) andnon-animal patterns (row 2).
Figure 17: Illustration of the diversity measure in a two-dimensional space. Ranges for the dimen-sions are [-5, 5] and [0, 0.3]. The number bins per dimension is 7 resulting in 72 = 49 discretizedareas. The diversity is the number of areas (here 12) in which points exist (grey areas).
Figure 18: Examples of patterns (left) and their reconstruction (right) by the β-VAE used for theanalytic parameter (a) and behavior space (b). The patterns are sampled from the validation dataset.
Figure 19: Influence of the number of bins per dimensions on the diversity measure. Depicted is theaverage diversity (n = 10) with the standard deviation as shaded area.
