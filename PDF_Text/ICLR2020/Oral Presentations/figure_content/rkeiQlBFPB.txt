Figure 1: Schematics of WarpGrad. WarpGrad preconditioning is embedded in task-learners f by in-terleaving warp-layers (ω(1), ω(2)) between each task-learner’s layers (h(1), h(2)). WarpGrad achievepreconditioning by modulating layer activations in the forward pass and gradients in the backwardpass by backpropagating through warp-layers (Dω), which implicitly preconditions gradients bysome matrix (P). Warp-parameters (φ) are meta-learned over the joint search space induced by taskadaptation (Eθ [J (φ)]) to form a geometry that facilitates task learning.
Figure 2: Gradient-based meta-learning. Colours denote different tasks (τ), dashed lines denotebackpropagation through the adaptation process, and solid black lines denote optimiser parameter(φ) gradients w.r.t. one step of task parameter (θ) adaptation. Left: A meta-learned initialisationcompresses trajectory information into a single initial point (θ0). Middle: MAML-based optimisersinteract with adaptation trajectories at every step and backpropagate through each interaction. Right:WarpGrad is trajectory agnostic. Task adaptation defines an empirical distribution p(τ, θ) over whichWarpGrad learns a geometry for adaptation by optimising for steepest descent directions.
Figure 3: Left: synthetic experiment illustrating how WarpGrad warps gradients (see Appendix D forfull details). Each task f 〜p(f) defines a distinct loss surface (W, bottom row). Gradient descent(black) on these surfaces struggles to find a minimum. WarpGrad meta-learns a warp ω to producebetter update directions (magenta; Section 2.4). In doing so, WarpGrad learns a meta-geometry Pwhere standard gradient descent is well behaved (top row). Right: gradient descent in P is equivalentto first-order Riemannian descent in W under a meta-learned Riemann metric (Section 2.3).
Figure 4: Left: Omniglot test accuracies on held-out tasks after meta-training on a varying numberof tasks. Shading represents standard deviation across 10 independent runs. We compare Warp-Leap, Leap, and Reptile, multi-headed finetuning, as well as SGD and KFAC which used randominitialisation but with 4x larger batch size and 10x larger learning rate. Right: On a RL mazenavigation task, mean cumulative return is shown. Shading represents inter-quartile ranges across 10independent runs.^Simple modulation and ^retroactive modulation are used (Miconi et al., 2019).
Figure 5: Continual learning experiment. Average log-loss over 100 randomly sampled tasks, eachcomprised of 5 sub-tasks. Left: learned sequentially as seen during meta-training. Right: learned inrandom order [sub-task 1, 3, 4, 2, 0].
Figure 6: Illustration of possible WarpGrad architectures. Orange represents task layers and bluerepresents warp-layers.㊉ denotes residual connections and Θ any form of gating mechanism. Wecan obtain warped architectures by interleaving task- and warp-layers (a, c) or by designating somelayers in standard architectures as task-adaptable and some as warp-layers (b, d).
Figure 7: Example trajectories on three task loss surfaces. We start Gradient Descent (black)and WarpGrad (magenta) from the same initialisation; while SGD struggles with the curvature,the WarpGrad optimiser has learned a warp such that gradient descent in the representation space(top) leads to rapid convergence in model parameter space (bottom).
Figure 8: Omniglot results. Top: test accuracies on held-out tasks after meta-training on a varyingnumber of tasks. Bottom: AUC under accuracy curve on held-out tasks after meta-training on avarying number of tasks. Shading represents standard deviation across 10 independent runs. Wecompare between Warp-Leap, Leap, and Reptile, multi-headed finetuning, as well as SGD and KFACwhich used random initialisation but with a 10x larger learning rate.
Figure 9: Ablation study. Left: Comparison of mean activation value E[h(x)] across layers, pre- andpost-warping. Right: Shatten-1 norm of Cov(h(x), h(x)) - I, pre- and post-norm. Statistics aregathered on held-out test set and averaged over tasks and adaptation steps.
Figure 10: Multi-shot tieredImageNet results. Top: mean learning curves (test classification accuracy)on held-out meta-test tasks. Bottom: mean test classification performance on held-out meta-test tasksduring meta-training. Training from scratch omitted as it is not meta-trained.
Figure 11: Mean cumulative return for maze navigation task, for 200000 training steps. Shadingrepresents inter-quartile ranges across 10 independent runs. ^ Simple modulation and ^retroactivemodulation, respectively (Miconi et al., 2019).
Figure 12: Continual learning regression experiment. Average log-loss over 100 randomly sampledtasks. Each task contains 5 sub-tasks learned (a) sequentially as seen during meta-training or (b) inrandom order [sub-task 1, 3, 4, 2, 0]. We train on each sub-task for 20 steps, for a total of K = 100task adaptation steps.
