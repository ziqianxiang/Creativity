Figure 1: Mainnet Activations before the Start of Training on MNIST.
Figure 2: Evolution of Hypernet Output Layer Activations during Training on MNIST. Xavier initresults in unstable mainnet weights throughout training, while hyperfan-in and hyperfan-out initresult in mainnet weights that stabilize quickly.
Figure 3: Loss and Test Accuracy Plots on MNIST.
Figure 4: Continual Learning Loss on a Sequence of Regression Tasks.
Figure 5: Loss and Test Accuracy Plots on CIFAR-10.
Figure 6: Loss and Test Accuracy Plots on ImageNet.
Figure 7: Evolution of Mainnet Activations during Training on MNIST.
Figure 8: Mainnet Activations at the End of Training on MNIST.
Figure 9:	Mainnet Gradients before the Start of Training on MNIST.
Figure 10:	Evolution of Mainnet Gradients during Training on MNIST.
Figure 11:	Mainnet Gradients at the End of Training on MNIST.
Figure 12:	Hypernet Output Layer Activations before the Start of Training on MNIST.
Figure 13: Hypernet Output Layer Activations at the End of Training on MNIST.
Figure 14: Hypernet Output Layer Gradients before the Start of Training on MNIST.
Figure 15: Evolution of Hypernet Output Layer Gradients during Training on MNIST.
Figure 16: Hypernet Output Layer Gradients at the End of Training on MNIST.
Figure 17:	Loss and Test Accuracy Plots on MNIST.
Figure 18:	Mainnet Activations before the Start of Training on MNIST.
Figure 19:	Evolution of Mainnet Activations during Training on MNIST.
Figure 20:	Mainnet Activations at the End of Training on MNIST.
Figure 21:	Mainnet Gradients before the Start of Training on MNIST.
Figure 22:	Evolution of Mainnet Gradients during Training on MNIST.
Figure 23: Mainnet Gradients at the End of Training on MNIST.
Figure 24:	Hypernet Output Layer Activations before the Start of Training on MNIST.
Figure 25:	Evolution of Hypernet Output Layer Activations during Training on MNIST.
Figure 26:	Hypernet Output Layer Activations at the End of Training on MNIST.
Figure 27:	Hypernet Output Layer Gradients before the Start of Training on MNIST.
Figure 28:	Evolution of Hypernet Output Layer Gradients during Training on MNIST.
Figure 29: Hypernet Output Layer Gradients at the End of Training on MNIST.
