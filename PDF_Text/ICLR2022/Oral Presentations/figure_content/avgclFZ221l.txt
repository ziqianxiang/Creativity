Figure 1: Example that illustrates a few important concepts. (a) Training data shows how Equations (2) to (4)define the training distribution P pXtr, Y trq. Task: Given an image of a rod (shown in brown), we wish topredict the orientation of the rod, i.e., whether the rod is upright or flat (Y :“ hpUrotq). In this example, wehave D “ {rot} (image rotations 0o and 90°) and D “ {trans} (horizontal translations of —5, 0, '5 units) asany horizontal translation does not affect the orientation of the rod. (b) The test data (only a single exampleshown) suffers an OOD shift through a different distribution over P pUtransq, where non-zero translations canhappen before the second rotation. (c) Here we illustrate why an invariance that is good for traditional dataaugmentation, such as counting the brown pixels in the green shaded area, would fail in test if, say, a `5 unitshorizontal translation happens before a rotation. (d) Here we illustrate why counterfactual language is neededto define how the input data would change in the presence of changes to Utrans. Using counterfactuals, it isfinally clear that the invariant representation must be able to also consider the number of brown pixels inside thehorizontal purple and green bands (among other horizontal bands).
Figure 2: (a) (i) True causal DAG; (ii) causal DAG of counterfactual invariant representation; (iii) Causal modelsearch. (b) Partial order over invariant representations (arrows indicate higher invariance). (c) An example figurewhere training data has a single example per equivalence class in X{ „1 (green rectangles). Then, we haveCOMPpFt1u , Dq “ COMPpFH , Dq even though Ft1u is more invariant (simpler) than FH.
