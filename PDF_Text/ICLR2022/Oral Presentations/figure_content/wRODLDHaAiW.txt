Figure 1: Fast and robust learning iniLQR-VAE. Example run of iLQR-VAE on asynthetic dataset generated by an autonomouslinear dynamical. iLQR-VAE with an adap-tive prior over control inputs (red) initiallyuses large inputs to fit the observations, butgradually pushes those inputs back into initialconditions as it acquires the ground truth au-tonomous dynamics. In contrast, iLQR-VAEwith a rigid input prior imposing autonomousdynamics gets stuck in plateaus and learnsconsiderably more slowly (black; see text fordetails). For each setting, insets show thethree inferred inputs for a given test trial (top;posterior mean u|o, rescaled by the maxi-mum input in the sequence), and the poste-rior predictions for the first two correspond-ing outputs (0i|o; black dots: ground truth;blue: posterior mean with 95% c.i.). We alsocompare learning curves with LFADS (yellow
Figure 2: Learning nonlinear autonomous dynamics. (A) Evolution of the negative ELBO dur-ing training of an iLQR-VAE model with a nonlinear RNN and a Gaussian likelihood (n = 20,m = 5, no = 3). The inputs inferred by iLQR are originally strong (blue, before learning), butare progressively pushed to initial conditions (red, after learning) as the autonomous dynamics ofthe Lorenz attractor are approximated with increasing accuracy. (B) Four example test trajectories(columns), conditioning on the noisy data within the first half (green shading), and predicting in thesecond half. (C) Single long autonomous trajectory after training (setting ut>0 = 0), starting froma random initial condition and running the dynamics for 10000 steps. The model displays the but-terfly topology characteristic of the Lorenz system, and completes multiple cycles without deviatingfrom the attractor, suggesting that the ground-truth dynamics have been learned.
Figure 3: Inferring sparse inputs to a linear system. (A) Top: example observations (blackdots) and inferred posterior mean (blue line). Bottom: true and inferred inputs. iLQR-VAE is ableto infer the timing and magnitude of the inputs almost perfectly, despite being trained on only asingle timeseries of 1000 time steps. Note that iLQR-VAE fails to infer one of the smallest inputs,whose effect on the observations is largely masked by observation noise. (B) Comparison of the true(black) and learned (blue) eigenvalue spectra. This shows that iLQR-VAE recovers the ground-truthdynamical system up to a similarity transformation.
Figure 4: iLQR-VAE can be used to decode kinematics from neural data, and learns dynamicsrelying strongly on preparatory inputs. (A) 50 example hand trajectories (top) from the monkeyreaching ‘Maze’ dataset, corresponding single-trial firing rate timecourse (middle; one example neu-ron), and inferred input (bottom; one example input dimension). (B) Mean (thick) and single-‘trial’(thin) firing rates of two example neurons during reaches of various directions (colours), alignedto target onset. Note that three single-‘trial’ firing rates are shown for only three of the 8 reachdirections for which averages are shown. Interestingly, single ‘trial’ activities evolve tightly aroundtheir trial averages, and resembles the firing rate responses shown in A (middle). (C) Example spikeraster (top) and hand kinematics (bottom) for a 4 second-long chunk of test data in the continuousmonkey reaching task. vx and vy refer to hand x- and y-velocities respectively. (D) Overall magni-tude of the inferred inputs kut k (blue), average population spiking activity (red), and hand velocitykyt k (black), each z-scored, averaged across movement episodes, and aligned to target onset (top)or movement onset (bottom).
Figure S1: Illustration of the model iLQR-VAE is trained to model a set of noisy observations(here, spike trains). During each training iteration, iLQR is used to infer the input u (green), givenobservations and the current parameters of the generator. Intuitively, the optimal inputs are ones thatproduce latent trajectories in the RNN that are most compatible with the data, without overfitting.
Figure S2: Illustration of the learningcurves for 5 different runs of the “forced au-tonomous” iLQR-VAE model. The modelconsistently gets stuck in plateaus during theoptimization, leading to a sloWer convergencethan their “free” counterparts (see Figure 1).
Figure S3: (A) Top: example Duffing trajectories (100 time steps, dt = 0.03) starting from randominitial conditions. Bottom: negative ELBO during the course of training. (B) Top: spike rastercorresponding to an example test sample. Middle: first two principal components of the posteriormean over firing rates (red), given the spiking data shown at the top. For comparison, the ground-truth PCs in the first half of the trial (before the perturbation) are shown as black dots, with theirhypothetical unperturbed continuation shown as a dashed line. The second half of the ground-truthPCs (after the perturbation) are shown in gray. Bottom: norm of the inferred input.
Figure S4: Details of the sparse input inference in LFADS and iLQR-VAE. (A) Top: exampleobservations (black dots) and inferred posterior mean (blue line). Bottom: true and inferred inputs.
Figure S5: Comparison of the Student (pink) and Gaussian (green) prior for learning a linear dy-namical system driven by autoregressive inputs (AR) or sparse inputs. (A) Fit of the observationsusing the Gaussian (top) and Student (bottom) priors. Both allow to fit the observations highly ac-curately. (B) Inferred input norm for both priors. The temporal structure of the signal is very similarin both cases, as the Student prior essentially becomes Gaussian for large values of ν. (C) Evolutionof the loss for both choices of prior. The loss curves are closely aligned, and both models convergeto a similar ELBO value. (D) Fit of the observations using the Gaussian (top) and Student (bottom)priors. Both models allow to fit the observations, but the Student prior allows to obtain smoothertrajectories. (E) Inferred input norm for both priors. The Student prior is close to 0 at all times,except when it requires a sharp input to explain the data. On the other hand, the Gaussian priorrequires a large variance to be able to fit sparse inputs, leading to non-zero inferred inputs at all timepoints. (F) Evolution of the loss for both prior choices. The loss curve for the Student prior is lowerthan the Gaussian one throughout training, and converges to a higher ELBO value.
Figure S6: Projection of the neural activity of 200 movementsin the subspace defined by the top tWo jPCA axes. jPCAfinds the subspace capturing most rotations in the data, Whilespanning the same space as the top 2 principal components.
Figure S7: Comparisonof the firing rates inferredby bGPFA and iLQR-VAEon the first 100ms of thecontinuous reaching taskdata, for three differentneurons. bGPFA learnssmoother trajectories. Onthe other hand, fittingiLQR-VAE with a Gaussianprior with no temporalstructure allows to capturemore variance in the firingrates, which in turn leadsto a better decoding of thekinematics.
Figure S8: Ground truth hand velocity(red) and decoded kinematics using iLQR-VAE (blue) and bGPFA (dotted black). A lin-ear decoder was trained on 9 minutes of dataand then evaluated on the first minute of therecording (shown here). bGPFA struggles tocapture the biggest peaks in the velocity, con-sistent with the smoother firing rates and thelower R2.
Figure S9: Comparison of the posterior mean of a Kalman smoother and LQR. We ran bothLQR and a Kalman smoother on noisy observations generated by a latent system (see text for de-tails). (A) The Kalman smoother (blue) and LQR (dotted red) both inferred the same posterior meanfor the latent trajectories, matching the true latents (black) almost perfectly. The posterior uncer-tainty is shown for both cases on half of the data. The iLQR-VAE uncertainty was obtained byoptimizing the variance of the recognition model for 200 iterations, and then drawing 1000 samplesfrom the recognition model. (B) We compared learning the parameters of the posterior distributionusing iLQR v.s direct minimization of the NLL. On unseen data, both were able to converge to asolution close to the smoothed output trajectory. Note that we stopped the optimization after 8000iterations. (C) Learning curves of the direct optimization and iLQR-VAE on the same 168 trainingtrials. Note that we used Adam with the same learning rate of 0.02 in both cases, in order to directlycompare the effect of the gradient steps. Both x and y axes use a logarithmic scale.
