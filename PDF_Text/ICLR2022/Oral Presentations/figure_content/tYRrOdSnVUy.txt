Figure 1: A visualization of the generalization bound trained with different approaches. Theleft figure shows Supervised Learning in the source domain, which can derive a wide generalizationarea. When Target-Specified NTL is applied (middle), the target domain is removed from the gen-eralization area. As for Source-Only NTL (right), the generalization area is significantly reduced.
Figure 2: The data of STL10 attached without/with the patch.
Figure 3: Performance OfaFAR10, STL10, VisDAas source or target domain for Supervised Learning,Target-Specified NTL and Source-Only NTL.
Figure 6: The change of mutual informationI(z; n) at every training round, and it is ob-served by the domain discriminator.
Figure 5: PDF-s of distribution PZ|0 and PZ|1. Theblue curve is the PDF of PZ|0, and the green one isthe PDF of PZ|1. The orange curve is the PDF ofPZ |0 with a smaller variance (best view in color).
Figure 7: Augmentation results of USPS generated by the generative adversarial augmentationframework.
Figure 8: Augmentation of SVHN generated by the generative adversarial augmentation framework.
Figure 9: Augmentation results of MNIST-M generated by the generative adversarial augmentationframework.
Figure 10: Augmentation results of SYN-D generated by the generative adversarial augmentationframework.
Figure 11: Augmentation results of CIFAR10 generated by the generative adversarial augmentationframework.
Figure 12: Augmentation results of STL10 generated by the generative adversarial augmentationframework.
