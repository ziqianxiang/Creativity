Table 2: Comparison with copyingbaselines. We report MSE×10-3 onprediction of keypoints + coefficients.
Table 1: Comparison with the state-of-the-art models inphysics-inspired machine learning of video signals, report-ing reconstruction error (PSNR and introduced L-PSNR).
Table 3: Impact of having additional Orientation/shape co-efficients (✓) compared to the keypoint-only solution (X),for different numbers of keypoints: equal to number of ob-jects (=N), 2N and 4N.
Table 5: Learning the filter bank H from scratchhas a mild negative effect on the reconstructiontask. We report the PSNR on static reconstruc-tion performance without the dynamic model.
Table 4: Impact of the dynamic CoDy encoder(✓) against the baseline operating in the keypoint+ coefficient space (X). We report MSE× 10-3on prediction of keypoints + coefficients (4 pts).
Table 6: (a) Sanity check of the identifiability constraint in BlocktowerCF, which results in betterestimation of cube masses. The corrected accuracy only considers those cubes for which changesin masses are consequential for the trajectory D. (b) MSE between ground truth 3D positions andpredicted positions after 1 second, depending on the sampling rate of the trajectory.
Table 7: PSNR (dB) on the task of reconstructingthe target from the source (both randomly sam-pled from Filtered-CoPhy), using 5 coefficientsper keypoint. We vary the number of keypoints inour model. Here N is the maximum number ofthe objects in the scene.
Table 8: Impact of the number of keypoints and the presence of additional appearance coefficientin the de-rendering module for pure image reconstruction (no dynamic model). We report PSNR(dB) and MSE on the image gradient. N is the maximum number of the objects in the scene.
Table 9: PSNR (dB) on the task of reconstructing target from the source (both randomly sampledfrom Filtered-CoPhy), using 5 coefficients per keypoint. We vary the number of keypoints in bothour model and the Transporter. Note that Transporter uses target features to reconstruct the image,hence it is not comparable with our model.
Table 10: Architectural details of the de-rendering module.
Table 11: MOT metrics for different methods. While not comparable, we report the CoPhyNetperformance as a soft upper bound. Our method and UV-CDN use one keypoint per object.
