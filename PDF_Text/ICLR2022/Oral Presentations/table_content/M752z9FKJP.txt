Table 1: Test accuracy (% ± sd over 3 runs) for audio classification in the single (one model pertask) and multi-task (one model for all tasks) settings.
Table 2: Learned strides (% ± sd over 3 runs) of the first layer for the single and multi-task models.
Table 3: Accuracies (% ± sd over 3 runs) on CIFAR10 and CIFAR100. First column representsstrides at each shortcut block, (2, 2, 2) being the configuration of (He et al., 2016a). For reference,the state-of-the-art on CIFAR10 (CIFAR100) is (Dosovitskiy et al., 2020) ((Foret et al., 2020)) withan accuracy of 99.5% (96.1%).
Table 4: Top-1 and top-5 accuracies (% ± sd over 3 runs) on Imagenet, (1, 2, 2, 2) being the config-uration of (He et al., 2016a). For reference, state-of-the-art on Imagenet is (Dai et al., 2021) with atop-1 accuracy of 90.88%.
Table A.1: Datasets used for audio classification. Default train/test splits are always adopted.
Table A.2: Per-step time and peak memory usage of Spectral Pooling and DiffStride relative tostrided convolutions, on a V100 GPU. During training, a “step” is the forward and backward passfor a single batch, while in inference it only involves a forward pass.
Table A.3: Accuracies (% ± sd over 3 runs) for CIFAR10 for each downsampling method with theDenseNet-BC architecture. First column represents strides at each transition block, (2, 2) being theconfiguration of (Huang et al., 2017).
Table A.4: Accuracies (% ± sd over 3 runs) for CIFAR100 for each downsampling method with theDenseNet-BC architecture. First column represents strides at each transition block, (2, 2) being theconfiguration of (Huang et al., 2017).
Table A.5: Accuracies (% ± sd over 3 runs) for CIFAR10 for each downsampling method withthe EfficientNet-B0 architecture. First column represents strides at each strided convolution, with(1, 2, 2, 2, 1, 2, 1) being the configuration of (Tan & Le, 2019).
Table A.6: Accuracies (% ± sd over 3 runs) for CIFAR100 for each downsampling method withthe EfficientNet-B0 architecture. First column represents strides at each strided convolution, with(1, 2, 2, 2, 1, 2, 1) being the configuration of (Tan & Le, 2019).
Table A.7: Test accuracy (% ± sd over 3 runs) for audio classification in the multi-task (one modelfor all tasks) with DiffStride, when learning a single stride value (Shared stride) per layer, or adifferent one for each dimension (Different strides).
