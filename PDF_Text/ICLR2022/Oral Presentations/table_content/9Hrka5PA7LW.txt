Table 1: Accuracy and forgetting of the learnt representations on Split CIFAR-10, Split CIFAR-100 and SplitTiny-ImageNet on Resnet-18 architecture with KNN classifier (Wu et al., 2018). All the values are measured bycomputing mean and standard deviation across three trials. The best and second-best results are highlighted inbold and Underline respectively.
Table 2: Comparison of accuracy on out of distribution datasets using a KNN classifier (Wu et al., 2018) on pre-trained SCL and UCL representations. We consider MNIST (LeCun, 1998), Fashion-MNIST (FMNIST) (Xiaoet al., 2017), SVHN (Netzer et al., 2011) as out of distribution for Split CIFAR-100 and Split CIFAR-10. All thevalues are measured by computing mean and standard deviation across three trials. The best and second-bestresults are highlighted in bold and Underline respectively.
Table 3:	`2 distance between UCL parameters aftercompletion of training.
Table 4:	`2 distance between SCL paraneters aftercompletion of training.
Table A.5: Hyperparameter configurations for all the datasets on ResNet-18 architecture.
