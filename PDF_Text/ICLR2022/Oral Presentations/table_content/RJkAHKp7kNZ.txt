Table 1: Aggregate cube grasping out-of-distribution generalization performance across the three experimentvariants computed from taking the three highest success rates achieved in each run of each DAgger or DrQagent. The hand-centric perspective leads to the best aggregate success rate for both algorithms, with its 95%confidence intervals of the interquartile mean (IQM) not overlapping those of the third-person perspective.
Table 2: Aggregate sponge grasping out-of-distribution generalization performance across thethree sets of distribution shifts.
Table 3: Aggregate out-of-distribution generalization performance across all six Meta-World tasks computedfrom taking the three highest success rates achieved in each run of each DrQ-v2 agent. Using both perspectiveswith a VIB on the third-person perspective’s representation results in the best aggregate success rate. The lastthree agents are ablations of the above and are presented and discussed in Appendix C.4.
Table 4: Variants of the cube grasping environment with distribution shifts used for the DAgger and DrQexperiments. All task variants include initial object position and initial end-effector position randomizationthat is consistent across train and test. Table textures are from the describable textures dataset (DTD) (Cimpoiet al., 2014).
Table 5: The default hyperparameters used for DAgger in the cube grasping environment.
Table 6: The default hyperparameters used for DrQ in the cube grasping environment.
Table 7: The default hyperparameters used for DAC in the cube grasping environment.
Table 8: Out-of-distribution generalization performance comparisons between a behavior cloning (BC) policyusing a hand-centric visual perspective and a BC policy using a third-person perspective. The distribution shiftsinclude unseen table heights (where zshift indicates the change from the base table height used during training,in meters), unseen distractor objects, and unseen table textures. Compared to the third-person perspective, thehand-centric perspective leads to better out-of-generalization distribution performance across all three distribu-tion shifts. In-distribution results are provided to give an idea of a performance ceiling. Each success rate iscomputed over 20 evaluation episodes.
Table 9: The distributions of the initial object positions used in the six Meta-World environments. At trainingtime, we use the “narrow” initial object positions. At test time, we use the set difference between the “narrow”and “wide” initial object positions, i.e. we repeatedly resample from “wide” until none of the objects in theenvironment lie in the “narrow” distribution. As a result, the train- and test-time distributions are disjoint. Therange of positions for each object is given as a pair of coordinates: (xlow, ylow, zlow) and (xhigh, yhigh, zhigh).
Table 10: The hyperparameters used for DrQ-v2 in the Meta-World tasks. The lower half of the table presentsthe hyperparameters that are specific to the regularization methods and ablation agents.
