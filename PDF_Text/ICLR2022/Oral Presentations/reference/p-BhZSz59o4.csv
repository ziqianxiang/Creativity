title,year,conference
 Self-labelling via simultaneous clusteringand representation learning,2020, In International Conference on Learning Representations (ICLR)
 Learning representations by maximiz-ing mutual information across views,2019, In Advances in Neural Information Processing Systems
 UniLMv2: Pseudo-masked language modelsfor unified language model pre-training,2020, In Proceedings of the 37th International Conferenceon Machine Learning
 Deep clustering for unsuper-vised learning of visual features,2018, In Proceedings of the European Conference on Computer Vision(ECCV)
 Emerging properties in self-supervised vision transformers,2021, arXiv preprintarXiv:2104
 A simple framework forcontrastive learning of visual representations,2020, preprint arXiv:2002
 Exploring simple siamese representation learning,2020, preprintarXiv:2011
 Improved baselines with momentumcontrastive learning,2020, preprint arXiv:2003
 An empirical study of training self-supervised visiontransformers,2021, ArXiv
 BERT: pre-training of deepbidirectional transformers for language understanding,2019, In Proceedings of the 2019 Conference ofthe North American Chapter of the Association for Computational Linguistics: Human LanguageTechnologies
 An imageis worth 16x16 words: Transformers for image recognition at scale,2020, preprint arXiv:2010
 Bootstrap your own latent:A new approach to self-supervised learning,2020, In NeurIPS
 Momentum contrast forunsupervised visual representation learning,2020, In CVPR
 Learning deep representations by mutual information estimationand maximization,2019, In International Conference on Learning Representations
 Deep networks withstochastic depth,2016, In Bastian Leibe
 Categorical reparameterization with gumbel-softmax,2017, In 5thInternational Conference on Learning Representations
 Span-BERT: Improving pre-training by representing and predicting spans,2020, Transactions of the As-sociation for Computational Linguistics
 Auto-Encoding Variational Bayes,2014, In 2nd InternationalConference on Learning Representations
 Unsupervised representation learning by predicting imagerotations,2018, In International Conference on Learning Representations (ICLR)
 Learning multiple layers of features from tiny images,2009, Masterâ€™s thesis
 Prototypical contrastive learning of unsu-pervised representations,2021, In International Conference on Learning Representations
 Microsoft coco: Common objects in context,2014, In Europeanconference on computer vision
 Efficient trainingof visual transformers with small datasets,2021, In Thirty-Fifth Conference on Neural InformationProcessing Systems
 Swin Transformer: Hierarchical vision transformer using shifted windows,2021, arXiv preprintarXiv:2103
 Decoupled weight decay regularization,2019, In International Confer-ence on Learning Representations
 The Concrete Distribution: A Continuous Re-laxation of Discrete Random Variables,2017, In International Conference on Learning Representations
 Unsupervised learning of visual representations by solving jigsawpuzzles,2016, In European conference on computer vision
 Representation learning with contrastive predictivecoding,2018, preprint arXiv:1807
 Intermediate-task transfer learningwith pretrained language models: When and why does it work? In Proceedings of the 58thAnnual Meeting of the Association for Computational Linguistics,2020, Association for ComputationalLinguistics
 Exploring the limits of transfer learning with a unified text-to-text transformer,2020, J
 Zero-shot text-to-image generation,2021, ArXiv
 Generating diverse high-fidelity images withVQ-VAE-2,2019, In Advances in Neural Information Processing Systems
 Imagenetlarge scale visual recognition challenge,2015, IJCV
 Neural machine translation of rare words withsubword units,2016, In Proceedings of the 54th Annual Meeting of the Association for ComputationalLinguistics (Volume 1: Long Papers)
 Training data-effiCient image transformers & distillation through attention,2020, preprintarXiv:2012
 Goingdeeper with image transformers,2021, arXiv preprint arXiv:2103
 Selfie: Self-supervised pretraining for imageembedding,2019, arXiv preprint arXiv:1906
 Neural discrete representation learn-ing,2017, In Proceedings of the 31st International Conference on Neural Information ProcessingSystems
 Attention is all you need,2017, In Isabelle Guyon
 Unsupervised feature learning vianon-parametric instance discrimination,2018, In CVPR
 Unified perceptual parsing forscene understanding,2018, In ECCV
 Self-supervisedlearning with swin transformers,2021, arXiv preprint arXiv:2105
 Colorful image colorization,2016, In ECCV
 Rethinking semantic segmentationfrom a sequence-to-sequence perspective with transformers,2020, CoRR
