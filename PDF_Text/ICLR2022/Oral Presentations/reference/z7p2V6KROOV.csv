title,year,conference
 Persistent anti-muslim bias in large languagemodels,2021, arXiv preprint arXiv:2101
 Wildlife insights: Aplatform to maximize the potential of camera trap and other passive sensor wildlife data for theplanet,2020, Environmental Conservation
 Deep learning for segmentation of brain tUmors:Impact of cross-institUtional training and testing,2018, Med Phys
 Big self-supervisedmodels advance medical image classification,2021, arXiv preprint arXiv:2101
 Recognition in terra incognita,2018, In European Con-ference on Computer Vision (ECCV)
 Efficient pipeline for camera trap image review,2019, arXivpreprint arXiv:1907
 A theory of learning from different domains,2010, Machine Learning
 Ethical considerations when using geospatialtechnologies for evidence generation,2018, Innocenti Discussion Paper
 Adamatch:A unified approach to semi-supervised learning and domain adaptation,2021, arXiv preprintarXiv:2106
 Pubchem: integrated plat-form of small molecules and biological activities,2008, In Annual reports in computational chemistry
 Man isto computer programmer as woman is to homemaker? Debiasing word embeddings,2016, In Advancesin Neural Information Processing Systems (NeurIPS)
 Nuancedmetrics for measuring unintended bias with real data for text classification,2019, In World Wide Web(WWW)
 Language models are few-shot learners,2020, arXiv preprintarXiv:2005
 Terra-ref data processing infrastruc-ture,9781, In Proceedings of the Practice and Experience on Advanced Research Computing
 Semantics derived automatically fromlanguage corpora contain human-like biases,2017, Science
 Un-supervised learning of visual features by contrasting cluster assignments,2020, In Advances in NeuralInformation Processing Systems (NeurIPS)
 LEGAL-BERT:¡±preparing the muppets for court¡±,2020, In Empirical Methods in NaturalLanguage Processing (EMNLP)
 A simple framework forcontrastive learning of visual representations,2020, In International Conference on Machine Learning(ICML)
 A simple framework forcontrastive learning of visual representations,2020, In International conference on machine learning
 Self supervised contrastive learning for digital histopathol-ogy,2020, arXiv preprint arXiv:2011
 Tydi qa: A benchmark for information-seeking question answering intypologically diverse languages,2020, arXiv preprint arXiv:2003
 Cross-lingual language model pretraining,2019, In Advances inNeural Information Processing Systems (NeurIPS)
 Xnli: Evaluating cross-lingual sentence representations,2018, InEmpirical Methods in Natural Language Processing (EMNLP)
 The cityscapes dataset for semantic urbanscene understanding,2016, In Proceedings of the IEEE conference on computer vision and patternrecognition
 Randaugment: Practical automateddata augmentation with a reduced search space,2020, In Computer Vision and Pattern Recognition(CVPR)
 Self-supervision closes the gap between weak and strong supervision in histology,2020, arXiv preprintarXiv:2012
 BERT: Pre-training of deepbidirectional transformers for language understanding,2019, In Association for Computational Linguis-tics (ACL)
 Improved regularization of convolutional neural networkswith cutout,2017, arXiv preprint arXiv:1708
 Onrobustness and transferability of convolutional neural networks,2020, arXiv preprint arXiv:2007
 Adaptive methodsfor real-world domain generalization,2021, In Computer Vision and Pattern Recognition (CVPR)
 Word embeddings quantify 100years of gender and ethnic stereotypes,2018, Science
 Real-toxicityprompts: Evaluating neural toxic degeneration in language models,2020, arXiv preprintarXiv:2009
 Shortcut learning in deep neural networks,2020, NatureMachine Intelligence
 UnsUpervised representation learning bypredicting image rotations,2018, In International Conference on Learning Representations (ICLR)
 Deep sparse rectifier neUral networks,2011, InArtificial Intelligence and Statistics (AISTATS)
 Entropy regUlarization,2005, In Semi-Supervised Learning
 Domain-specific langUage model pretraining for biomedicalnatUral langUage processing,2020, arXiv preprint arXiv:2007
 In search of lost domain generalization,2020, arXiv preprintarXiv:2007
 Don¡¯t stop pretraining: adapt langUage models to domains and tasks,2020, arXivpreprint arXiv:2004
 Realm: Retrieval-augmented language model pre-training,2020, In icml
 Deep residual learning for image recog-nition,2016, In Computer Vision and Pattern Recognition (CVPR)
 Momentum contrast for un-supervised visual representation learning,2020, In Computer Vision and Pattern Recognition (CVPR)
 Distilling the knowledge in a neural network,2015, InNIPS Deep Learning and Representation Learning Workshop
 Cycada: Cycle consistent adversarial domain adaptation,2018, In InternationalConference on Machine Learning (ICML)
 Open Graph Benchmark: Datasets for machine learning on graphs,2020, In Ad-vances in Neural Information Processing Systems (NeurIPS)
 Strategies for pre-training graph neural networks,2020, In International Conference onLearning Representations (ICLR)
 Densely connectedconvolutional networks,2017, In Proceedings of the IEEE Conference on Computer Vision and PatternRecognition
 A database for handwritten text recognition research,1994, IEEE Transactions onpattern analysis and machine intelligence
 Semi-supervised deep kernel learning: Regres-sion with unlabeled data by minimizing predictive variance,2018, In Advances in Neural InformationProcessing Systems (NeurIPS)
 Transfer learning library,2020, https://github
 Selective question answering under domain shift,2020, InAssociation for Computational Linguistics (ACL)
 Half a percent of labels isenough: Efficient animal detection in uav imagery using deep cnns and active learning,2019, IEEETransactions on Geoscience and Remote Sensing
 WILDS: Abenchmark of in-the-wild distribution shifts,2021, In International Conference on Machine Learning(ICML)
 Machine learning methods for histopathological imageanalysis,2018, Computational and structural biotechnology journal
 Self-path: Self-supervision for classification of pathology images with limitedannotations,2021, IEEE Transactions on Medical Imaging
 Gradient-based learning applied todocument recognition,1998, Proceedings of the IEEE
 Pseudo-label: The simple and efficient semi-supervised learning method for deepneural networks,2013, In ICML Workshop on Challenges in Representation Learning
 Predicting what you already know helps:Provable self-supervised learning,2020, arXiv preprint arXiv:2008
 Biobert: a pre-trained biomedical language representation model for biomedical textmining,2020, Bioinformatics
 Semi-supervised learningfor imbalanced sentiment classification,2011, In International Joint Conference on Artificial Intelli-gence (IJCAI)
 Learning transferable features withdeep adaptation networks,2015, In International conference on machine learning
 Deep transfer learning with jointadaptation networks,2017, In International conference on machine learning
 Conditional adversarialdomain adaptation,2018, In Advances in Neural Information Processing Systems (NeurIPS)
 Domain adaptation with multiplesources,2009, In Advances in Neural Information Processing Systems (NeurIPS) 
 The effect of natural distributionshift on question answering models,2020, arXiv preprint arXiv:2004
 Accuracy on the line: on the strong correlationbetween out-of-distribution and in-distribution generalization,2021, In International Conference onMachine Learning (ICML)
 Surprisingly simple semi-supervised do-main adaptation with pretraining and consistency,2021, arXiv preprint arXiv:2101
 Stereoset: Measuring stereotypical bias in pretrainedlanguage models,2020, arXiv preprint arXiv:2004
 Participatory re-search for low-resourced machine translation: A case study in African languages,2020, In Findings ofEmpirical Methods in Natural Language Processing (Findings of EMNLP)
 Readingdigits in natural images with unsupervised feature learning,2011, In NIPS Workshop on Deep Learningand Unsupervised Feature Learning
 Justifying recommendations using distantly-labeled re-views and fine-grained aspects,2019, In Empirical Methods in Natural Language Processing (EMNLP)
 A deep active learning system for species identification and counting in camera trapimages,2021, Methods in Ecology and Evolution
 Distributionally robust lan-guage modeling,2019, In Empirical Methods in Natural Language Processing (EMNLP)
 Focus on the positives: Self-supervised learning for biodiversity monitoring,2021, arXiv preprint arXiv:2108
 Moment matchingfor multi-source domain adaptation,2019, In International Conference on Computer Vision (ICCV)
 Learning transferable visual models from natural language supervision,2021, In Interna-tional Conference on Machine Learning (ICML)
 Learning transferable visualmodels from natural language supervision,2021, arXiv preprint arXiv:2103
 Self-supervised pretraining improves self-supervised pretraining,2021, arXiv
 Adversarial domain adapta-tion for classification of prostate histopathology whole-slide images,2018, In International Conferenceon Medical Image Computing and Computer-Assisted Intervention
 Faster R-CNN: Towards real-timeobject detection with region proposal networks,2015, IEEE Transactions on Pattern Analysis andMachine Intelligence (PAMI)
 Playing for data: Ground truthfrom computer games,2016, In European conference on computer vision
 The gbif integrated publishing toolkit: facilitatingthe efficient publishing of biodiversity data on the internet,2014, PloS one
 Model-based domain generalization,2021, arXivpreprint arXiv:2102
 Extended-connectivity fingerprints,2010, Journal of Chemical Infor-mation and Modeling
 Self-supervised graph transformer on large-scale molecular data,2020, arXiv preprintarXiv:2007
 ImageNet large scale visualrecognition challenge,2015, International Journal of Computer Vision
 Adapting visual category models to newdomains,2010, In European conference on computer vision
 Distributionally robustneural networks for group shifts: On the importance of regularization for worst-case generaliza-tion,2020, In International Conference on Learning Representations (ICLR)
 Asymmetric tri-training for unsuperviseddomain adaptation,2017, In International Conference on Machine Learning (ICML)
 Maximum classifier dis-crepancy for unsupervised domain adaptation,2018, In Proceedings of the IEEE conference on com-Puter vision and pattern recognition
 Teacher-student chain for efficient semi-supervised histology image classification,2020, arXiv preprintarXiv:2003
 Fixmatch: Simplifying semi-supervised learningwith consistency and confidence,2020, arXiv
 Image representations learned with unsupervised pre-trainingcontain human-like biases,2021, In ACM Conference on Fairness
 The semi-supervised inaturalist-aves challenge at fgvc7 work-shop,2021, arXiv preprint arXiv:2103
 Deep coral: Correlation alignment for deep domain adaptation,2016, InEuropean Conference on Computer Vision (ECCV)
 Return of frustratingly easy domain adaptation,2016, InAssociation for the Advancement of Artificial Intelligence (AAAI)
 Infograph: Unsupervised and semi-supervised graph-level representation learning via mutual information maximization,2020, In Interna-tional Conference on Learning Representations (ICLR)
 Assessing social and intersectional biases in contextualized wordrepresentations,2019, arXiv preprint arXiv:1911
 Measuring robustness to natural distribution shifts in image classification,2020, arXiv preprintarXiv:2007
 Quantifying the effects of data augmentation and stain color normaliza-tion in convolutional neural networks for computational pathology,2019, Medical Image Analysis
 Conditional contrastive learning: Removing undesirable information in self-supervised representations,2021, arXiv preprint arXiv:2106
 An empirical study on robustness to spuriouscorrelations using pre-trained language models,2020, Transactions of the Association for Computa-tional Linguistics (TACL)
 Deephashing network for unsupervised domain adaptation,2017, In Computer Vision and Pattern Recogni-tion (CVPR)
 Towards domain-agnosticcontrastive learning,2021, In International Conference on Machine Learning (ICML)
 Mitosiscounting in breast cancer: Object-level interobserver agreement and comparison to an automaticmethod,2016, PloS one
 Extracting andcomposing robust features with denoising autoencoders,2008, In International Conference on MachineLearning (ICML)
 Cross-domaincontrastive learning for unsupervised domain adaptation,2021, arXiv
 Why do pretrained language models help in down-stream tasks? an analysis of head and prompt tuning,2021, arXiv preprint arXiv:2106
 Individualtree-crown detection in rgb imagery using semi-supervised deep learning neural networks,2019, RemoteSensing
 A generaldeep learning model for bird detection in high resolution airborne imagery,2021, bioRxiv
 The cancer genome atlas pan-cancer analysis project,2013, Nature genetics
 Moleculenet: a benchmark for molecular machine learn-ing,2018, Chemical science
 Transfer learning fromdeep features for remote sensing and poverty mapping,2016, In Association for the Advancement ofArtificial Intelligence (AAAI)
 Self-training with noisy studentimproves imagenet classification,2020, arXiv
 Self-supervised learningof graph neural networks: A unified review,2021, arXiv preprint arXiv:2102
 Larger norm more transferable: An adap-tive feature norm approach for unsupervised domain adaptation,2019, In International Conference onComputer Vision (ICCV)
 Using publicly available satellite imagery and deep learning tounderstand economic well-being in africa,2020, Nature Communications
 Semi-supervised modelsare strong unsupervised domain adaptation learners,2021, arXiv preprint arXiv:2106
 From whole slide imaging to microscopy: Deep microscopyadaptation network for histopathology cancer image classification,2019, In International Conferenceon Medical Image Computing and Computer-Assisted Intervention
 Bridging theory and algorithm fordomain adaptation,2019, In International Conference on Machine Learning (ICML)
 Adversarial multiple source domain adaptation,2018, Advances in neural information processingsystems
