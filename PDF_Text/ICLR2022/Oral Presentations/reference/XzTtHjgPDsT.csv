title,year,conference
 Equilateral triangles: A challenge for connectionist vision,2009, 2009
 Neural module networks,2016, InProceedings ofthe IEEE Conference on Computer Vision and Pattern Recognition
 A cognitive theory of consciousness,1993, Cambridge University Press
 In the theatre of consciousness,1997, global workspace theory
 Neural machine translation by jointlylearning to align and translate,2014, arXiv preprint arXiv:1409
 Dota 2 with large scaledeep reinforcement learning,2019, arXiv preprint arXiv:1912
 A framework for the cooperation of learning algorithms,1991, InAdvances in neural information processing systems
 Vehicles: Experiments in synthetic psychology,1986, MIT press
 Intelligence without representation,1991, Artificial intelligence
 Language models arefew-shot learners,2020, arXiv preprint arXiv:2005
 Memory transformer,2020, arXiv preprint arXiv:2006
 Generating long sequences with sparsetransformers,2019, arXiv preprint arXiv:1904
 Transformer-xl: Attentive language models beyond a fixed-length context,2019, arXiv preprintarXiv:1901
 Experimental and theoretical approaches to consciousprocessing,2011, Neuron
 A neuronal model of a globalworkspace in effortful cognitive tasks,1998, Proceedings of the national Academy of Sciences
 Animage is worth 16x16 words: Transformers for image recognition at scale,2020, arXiv preprintarXiv:2010
 Pathnet: Evolution channels gradient descent in suPer neuralnetworks,2017, arXiv preprint arXiv:1701
 The modularity of mind,1983, MIT Press
 CATER: A diagnostic dataset for comPositional actions andtemPoral reasoning,2019, CoRR
 Recurrent independent mechanisms,2019, arXiv preprint arXiv:1909
 Object files and schemata: Factorizing declarative andprocedural knowledge in dynamical systems,2020, arXiv preprint arXiv:2006
 Neural turing machines,2014, CoRR
 Adaptive mixtures oflocal experts,1991, Neural computation
 Sparse attentive backtracking: Temporalcredit assignment through reminding,2018, In Advances in neural information processing systems
 Adam: A method for stochastic optimization,2014, arXiv preprintarXiv:1412
 Set trans-former: A framework for attention-based permutation-invariant neural networks,2019, In InternationalConference on Machine Learning
 Metaattention networks: Meta-learning attention to modulate information between recurrent independentmechanisms,2021, In International Conference on Learning Representations
 Society of mind,1988, Simon and Schuster
 Learning to combine top-down and bottom-up signals inrecurrent neural networks with attention over modules,2020, In International Conference on MachineLearning
 Learning to combine top-down and bottom-up signals inrecurrent neural networks with attention over modules,2020, In International Conference on MachineLearning
 Image transformer,2018, In International Conference on Machine Learning
 Languagemodels are unsupervised multitask learners,2019, OpenAI blog
 Compressivetransformers for long-range sequence modelling,2019, arXiv preprint arXiv:1911
 Neural programmer-interpreters,2015, arXiv preprint arXiv:1511
 Routing networks: Adaptive selection ofnon-linear functions for multi-task learning,2017, arXiv preprint arXiv:1711
 Routing networks and thechallenges of modular and compositional computation,2019, arXiv preprint arXiv:1904
 A simple neural network module for relational reasoning,2017, InAdvances in neural information processing systems
 Relational recurrent neuralnetworks,2018, In Advances in Neural Information Processing Systems
 Embodiment and the inner life: Cognition and Consciousness in the Space ofPossible Minds,2010, Oxford University Press
 The brainâ€™s connective core and its role in animal cognition,2012, PhilosophicalTransactions of the Royal Society B: Biological Sciences
 Outrageously large neural networks: The sparsely-gated mixture-of-experts layer,2017, arXivpreprint arXiv:1701
 Relational neuralexpectation maximization: Unsupervised discovery of objects and their interactions,2018, arXiv preprintarXiv:1802
 Attention is all you need,2017, In Advances in neural informationprocessing systems
 Grandmaster level instarcraft ii using multi-agent reinforcement learning,2019, Nature
