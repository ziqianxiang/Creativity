Published as a conference paper at ICLR 2022
Multimeasurement Generative Models
Saeed Saremi1, 2& Rupesh Kumar Srivastava1
1NNAISENSE Inc.
2Redwood Center, UC Berkeley
{saeed,rupesh}@nnaisense.com
Ab stract
We formally map the problem of sampling from an unknown distribution with
a density in Rd to the problem of learning and sampling a smoother density in
RMd obtained by convolution with a fixed factorial kernel: the new density is
referred to as M-density and the kernel as multimeasurement noise model (MNM).
The M-density in RMd is smoother than the original density in Rd, easier to
learn and sample from, yet for large M the two problems are mathematically
equivalent since clean data can be estimated exactly given a multimeasurement
noisy observation using the Bayes estimator. To formulate the problem, we derive
the Bayes estimator for Poisson and Gaussian MNMs in closed form in terms of the
unnormalized M-density. This leads to a simple least-squares objective for learning
parametric energy and score functions. We present various parametrization schemes
of interest including one in which studying Gaussian M-densities directly leads to
multidenoising autoencoders—this is the first theoretical connection made between
denoising autoencoders and empirical Bayes in the literature. Samples in Rd are
obtained by walk-jump sampling (Saremi & Hyvarinen, 2019) via underdamped
Langevin MCMC (walk) to sample from M-density and the multimeasurement
Bayes estimation (jump). We study permutation invariant Gaussian M-densities on
MNIST, CIFAR-10, and FFHQ-256 datasets, and demonstrate the effectiveness of
this framework for realizing fast-mixing stable Markov chains in high dimensions.
1 Introduction
Consider a collection of i.i.d. samples {xi}in=1, assumed to have been drawn from an unknown
distribution with density pX in Rd . An important problem in probabilistic modeling is the task of
drawing independent samples from pX , which has numerous potential applications. This problem is
typically approached in two phases: approximating pX, and drawing samples from the approximated
density. In unnormalized models the first phase is approached by learning the energy function fX
associated with the Gibbs distribution PX H exp(-fχ), and for the second phase one must resort to
Markov chain Monte Carlo methods, such as Langevin MCMC, which are typically very slow to mix
in high dimensions. MCMC sampling is considered an “art” and we do not have black box samplers
that converge fast and are stable for complex (natural) distributions. The source of the problem is
mainly attributed to the fact that the energy functions of interest are typically highly nonconvex.
A broad sketch of our solution to this problem is to model a smoother density in an M-fold expanded
space. The new density denoted by p(y), called M-density, is defined in RMd, where the boldfaced
y is a shorthand for (y1 , . . . , yM). M-density is smoother in the sense that its marginals pm(ym)
are obtained by the convolution pm (ym) = pm(ym|x)p(x)dx with a smoothing kernelpm(ym|x)
which for most of the paper we take to be the isotropic Gaussian:
Ym =X+N(0,σm2 Id).
Although we bypass learning p(x), the new formalism allows for generating samples from p(x) since
X can be estimated exactly given Y = y (for large M). To give a physical picture, our approach
here is based on “taking apart” the complex manifold where the random variable X is concentrated in
Rd and mapping it to a smoother manifold in RMd where Y = (Y1 , . . . , YM) is now concentrated.
Smoothing a density with a kernel is a technique in nonparametric density estimation that goes back
to Parzen (1962). In kernel density estimation, the estimator of p(x) is obtained by convolving the
1
Published as a conference paper at ICLR 2022
empirical measure with a kernel. In that methodology, the kernel bandwidth (σ, for Gaussian kernels)
is adjusted to estimate p(x) in Rd given a collection of independent samples {xi}in=1. This estimator,
like most nonparametric estimators, suffers from a severe curse of dimensionality (Wainwright, 2019).
But what if the kernel bandwidth is fixed: how much easier is the problem of estimating p(y)?
This question is answered in (Goldfeld et al., 2020), where they obtained the rate of convergence
eO(d)n-1/2 (measured using various distances) in remarkable contrast to the well-known n-1/d
rate for estimating p(x). This nonparametric estimation result is not directly relevant here, but it
formalizes the intuition that learning p(y) = p(y|x)p(x)dx is a lot simpler than learning p(x).
With this motivation, we start with an introduction to the problem of learning unnormalized p(y),
based on independent samples from p(x). This problem was formulated by Vincent (2011) using score
matching (Hyvarinen, 2005). It was approached recently with the more fundamental methodology
of empirical Bayes (Saremi & Hyvarinen, 2019). The idea is to use the Bayes estimator of X given
Y = y, the study of which is at the root of the empirical Bayes approach to statistics (Robbins, 1956),
in a least-squares objective. This machinery builds on the fact that the estimator xb(y) = E[X|Y = y]
can be expressed in closed form in terms of unnormalized p(y) (Sec. 3.1). For Gaussian kernels,
the learning objective arrived at in (Saremi & Hyvarinen, 2019) is identical (up to a multiplicative
constant) to the denoising score matching formulation (Vincent, 2011), but with new insights rooted
in empirical Bayes which is the statistical framework for denoising.
The main problem with the empirical Bayes methodology is that p(x|y) remains unknown and cannot
be sampled from. The estimator xb(y) = E[X|Y = y] can be computed, but the concentration of
the posterior p(x|y) around the mean is not in our control. Our solution to this problem starts with
an observation that is very intuitive from a Bayesian perspective: one can sharpen the posterior by
simply taking more independent noisy measurements. This scheme is formalized by replacing p(y|x)
with the factorial kernel p(y|x):
M
p(y|x) =	pm(ym|x), where y = (y1, . . . ,yM),
m=1
(1)
which we name multimeasurement noise model (MNM). Now, the object of interest is a different
density which we call M-density obtained by convolving p(x) with the factorial kernel:
p(y) =
p(y|x)p(x)dx.
(2)
This formally maps the original problem of drawing samples from p(x) to drawing samples from
p(y) for any fixed noise level since the estimator of X given Y = y is asymptotically exact. We
quantify this for Gaussian MNMs using the plug-in estimator (the empirical mean of measurements).
Smooth & Symmetric! Consider Gaussian MNMS with equal noise level σ in the regime of large
σ, large M such that σ,d∕M is “small”.1 In that regime, the complex manifold associated with
the data distribution is mapped to a very smooth symmetric manifold in a much higher dimensional
space. The original manifold can be reconstructed via a single step by computing xb(y). Due to equal
noise levels, the manifold associated with M-density is symmetric under the permutation group:
p(y1, . . . ,yM) = p(yπ(1), . . . , yπ(M)),	(3)
where π is a permutation of indices (Fig. 1). Although we develop a general methodology for studying
M-densities, in the later part of the paper we focus on permutation invariant Gaussian M-densities.
The paper is organized as follows. In Sec. 2, we derive Bayes estimators for Poisson and Gaussian
MNMs. In Sec. 3, we present the least-squares objective for learning Gaussian M-densities. We also
give a weaker formulation of the learning objective based on score matching. Sec. 4 is devoted to the
important topic of parametrization, where we introduce multidenoising autoencoder (MDAE) in
which we formally connect M-densities to the DAE literature. DAEs have never been studied for
factorial kernels and the emergence of MDAE as a generative model should be of wide interest. In
addition, we introduce metaencoder formulated in an unnormalized latent variable model, which is
mainly left as a side contribution. In Sec. 5, we present the sampling algorithm used in the paper.
In Sec. 6, we present our experiments on MNIST, CIFAR-10, and FFHQ-256 datasets which were
focused on permutation invariant M-densities. The experiments are mainly of qualitative nature
demonstrating the effectiveness of this method in generating fast mixing and very long Markov chains
in high dimensions. Related works are discussed in Sec. 7, and we finish with concluding remarks.
1The regime σ,d/M y 1 is obtained in our analysis of the highly suboptimal plug-in estimator (Sec. 2.3).
2
Published as a conference paper at ICLR 2022
(b) p(y)
Figure 1: (M-density) (a) A mixture of Gaussian in 1d. (b,c,d) The M-density (M = 2, σ1 = σ2), the
corresponding log-density and score function are visualized (based on calculations in Appendix A).
(d) ▽ logp(y)
Notation. The subscripts are dropped from densities and energy functions when it is clear from
their arguments: p(y) = pY (y), p(y|x) = pY|X=x(y), f(y) = fY(y), etc. Bold fonts are reserved
for multimeasurement random variables: Y = (Y1, . . . , YM). The following are shorthand notations:
[M] = {1,...,M} and Nm = Nym. Throughout, V is the gradient with respect to inputs (in RMd),
not parameters. The following convention is used regarding parametric functions: fθ(∙) = f (∙; θ).
Different parametrization schemes come with a different set of parameters, the collection of which
we denote by θ. For all the datasets used in the paper, X takes values in the hypercube [0, 1]d.
2 Formalism: Multimeasurement Bayes Estimators
This work is based on generalizing the empirical Bayes methodology to MNMs. It is well known that
the least-squares estimator of X given Y = y (for any noise model) is the Bayes estimator:
xb(y)
xp(y|x)p(x)dx
p(y|x)p(x)dx
(4)
Next we study this estimator a` la Robbins (1956) for Poisson (the Poisson kernel was the first example
studied in 1956) and Gaussian MNMs. In both cases the estimator xb(y) is derived to be a functional
of the joint density p(y). In addition, xb(y) is invariant to scaling p(y) by a constant, therefore one
can ignore the partition function in this estimation problem. This is the main appeal of this formalism.
Analytical results for Poisson MNMs are included to demonstrate the generality of the new formalism,
but we will not pursue it as a generative model in our experiments for technical reasons due to the
challenges regarding sampling discrete distributions in high dimensions (see Remark 7).
2.1	Poisson MNM
Let X be a random variable taking values in R+ . The Poisson MNM is defined by:
M xyl
p(y∣x) = e-Mx ɪɪ —p yι ∈ N.
l=1 yl !
The numerator in r.h.s. of Eq. 4 is computed next. The measurement index m below is an arbitrary
index in [M] used for absorbing x such that xp(y|x) has the same functional form as p(y|x):
x(ym +1)	xyl
J xp(y∣x)p(x)dx = J e-Mx(ym + 1)(y +1y	打p(x)dx = (ym + 1)p(y + 1m),
where 1m is defined as a vector whose component l is δml . Using Eq. 4, it immediately follows
b(y) = (ym + 1)p(y + Im), m ∈ [M].	(5)
p(y)
We emphasize that the dependency of xb(y) on the noise channel (measurement index) m that appears
on the right hand side of the expression above is only an artifact of the calculation (we observe this
again for Gaussian MNMs). The result above holds for any measurement index m ∈ [M], therefore
(ym + 1)p(y + 1m) = (ym0 + 1)p(y + 1m0) for all m, m0 ∈ [M].
3
Published as a conference paper at ICLR 2022
Example. We can derive the estimator xb(y) analytically for p(x) = e-x. We first derive p(y):2
p(y) = (PQl4! (M +1)T-Pl yl,
lyl!
where the sums/products are over the measurement indices l ∈ [M]. Using Eq. 5, it follows
X(V) = S +1)p(y + 1m) =(“ +1) Pl yl + 1	1	= Pl yl + 1
x(y) = (ym + 1) p(y)	=(ym + 1) ym + 1 M + 1 = M +1
As expected one arrives at the same result by computing Eq. 5 for any measurement index m.
2.2	Gaussian MNM
Let X be a random variable in Rd . The Gaussian MNM is defined by:
M
p(y|x) =	pm(ym|x), where pm(ym|x) = N(ym; x, σm2 Id).	(6)
m=1
It follows (as in the Poisson MNM, m in the equation below is an arbitrary index in [M]):
σmVmp(y|X) = (X - ym)p(y|x).
We multiply both sides of the above expression by P(X) and integrate over x. The derivative NmL
(with respect to ym) and the integration over X commute, and using Eq. 4 it follows
σm2 Nmp(y) = Xb(y)p(y) - ymp(y),
which we simplify by dividing both sides by p(y):
Xb(y) = ym + σm2 Nm log p(y), m ∈ [M].	(7)
This expression is the generalization of the known result due to Miyasawa (1961). As in the Poisson
MNM, the result above holds for any m ∈ [M], therefore:
ym + σm2 Nm log p(y) = ym0 + σm2 0 Nm0 log p(y) for all m, m0 ∈ [M].	(8)
Example. We also studied the M-density for Gaussian MNMs analytically. The calculations are
insightful and give more intuitions on the new formalism. We refer to Appendix A for the results.
Remark 1 (Xb(θm) (y) notation). For parametric M-densities, Eq. 8 is in general an approximation.
We use the superscript m to emphasize that there are M ways to compute the parametric estimator:
Xb(θm)(y) = ym + σm2 Nm logpθ (y)
Remark 2 (σ 0 M notation). Gaussian MNMs with the constant noise level σ are denoted by σ 0 M.
For σ 0 M models, the M-density p(y) (resp. the score function V logp(y)) is invariant (resp.
equivariant) with respect to the permutation group π : [M] → [M]. See Fig. 1 for an illustration.
2.3	Concentration of the plug-in estimator
The plug-in estimator of X is the empirical mean of the multiple noisy measurements we denote by
Xbmean(y) = M-1 Pm ym. This estimator is highly suboptimal but its analysis in high dimensions
for Gaussian MNMs is useful. Due to the concentration of measure phenomenon (Tao, 2012) we have
∣∣X - bmean(y)∣∣2 ≈ 0eff√d,	(9)
where σeff (“eff” is for effective) is given by
σeff = M (X*!1/2 .	(10)
The calculation is straightforward since ym = X + εm,, where εm,〜N(0,。也Id). It follows:
X - Xbmean(y) = -M-1 Pm εm which has the same law as N(0, σe2ffId). This calculation shows
that the estimator of X in Rd concentrates at the true value at a worst-case rate O(，d/M) (consider
replacing the sum in Eq. 10 by Mσm2 ax). This analysis is very conservative, as it ignores the
correlations between the components of y in RM d (within and across noise channels), and one
expects a (much) tighter concentration for the optimal estimator. In the next section, we present an
algorithm to learn the multimeasurement Bayes estimator based on independent samples from p(X).
2The derivation is straightforward using R∞ e-αxxβdx = α-1-ββ! for α > 0,β ∈ N.
4
Published as a conference paper at ICLR 2022
3	Learning Gaussian M-densities
3.1	Neural Empirical Bayes
In this section, we focus on learning Gaussian M-densities using the empirical Bayes formalism. We
closely follow the approach taken by Saremi & Hyvarinen (2θl9) and extend it to M-densities. The
power of empirical Bayes lies in the fact that it is formulated in the absence of any clean data. This
is reflected by the fact that xb(y) is expressed in terms of p(y) which can in principle be estimated
without observing samples from p(x) (Robbins, 1956); we generalized that to factorial kernels in
Sec. 2. What if we start with independent samples {xi}in=1 from p(x) and our goal is to learn p(y)?
A key insight in neural empirical Bayes was that the empirical Bayes machinery can be turned on
its head in the form of a Gedankenexperiment (Saremi & Hyvarinen, 2019): we can draw samples
(indexed by j) from the factorial kernel yij 〜p(y |xi) and feed the noisy data to the empirical Bayes
“experimenter” (the word used in 1956). The experimenter’s task (our task!) is to estimate X, but
since we observe X = xi, the squared `2 norm xi - xbθ (yij)22 serves as a signal to learn p(y), and
also xb(y) for unseen noisy data (as a reminder the Bayes estimator is the least-squares estimator).
Next, we present the least-squares objective to learn p(y) 8 e-f(y for Gaussian M-densities. It
is important to note that xb(y) is expressed in terms of unnormalized p(y), without which we must
estimate the partition function (or its gradient) during learning. Here, we can choose any expressive
family of functions to parametrize xb(y) which is key to the success of this framework. Using our
formalism (Sec. 2.2), the Bayes estimator takes the following parametric form (see Remark 1):
x(m) (y) = ym - σmNm fθ(y), m ∈ [M].	(11)
There are therefore M least-squares learning objectives
L(m)(θ) = E(x,y)L(m)(x, y; θ), where L(m)(x, y; θ) = x - xb(θm)(y)22	(12)
that in principle need to be minimized simultaneously, since as a corollary of Eq. 8 we have:
L(m)(x, y; θ*) ≈ L(m0)(x, y; θ*) for all m,m0 ∈ [M], X ∈ Rd, y ∈ RMd.	(13)
The balance between the M losses can be enforced during learning by using a softmax-weighted
sum of them in the learning objective, effectively weighing the higher losses more in each update.
However, in our parametrization schemes, coming up, simply taking the mean of the M losses as the
learning objective proved to be sufficient for a balanced learning across all the noise channels:
1M
L(θ) = M ∑L(m)(θ).	(14)
m=1
The above learning objective is the one we use in the remainder of the paper.
3.2	Denoising Score Matching
One can also study M-densities using score matching with the following objective (Hyvarinen, 2005):
J(θ) = Ey - Nyfθ(y) - Ny log p(y)22.	(15)
In Appendix B, we show that the score matching learning objective is equal (up to an additive
constant independent of θ) to the following multimeasurement denoising score matching (MDSM)
objective:
M
J(θ) = X Jm(θ), where Jm(θ) = E(χ,y)∣∣ - Nmfθ(y) + ym-x∣∣2 .	(16)
m=1	σm
This is a simple extension of the result by Vincent (2011) to Gaussian MNMs. The MDSM objective
and the empirical Bayes' (Eq. 14) are identical (up to a multiplicative constant) for σ 0 M models.
Remark 3. Compared to neural empirical Bayes (NEB), denoising score matching (DSM) takes a
very different approach regarding learning M-densities. DSM starts with score matching (Eq. 15).
NEB starts with deriving the Bayes estimator of X given Y = y for a known kernel p(y|x) (Eq. 7).
NEB is a stronger formulation in the sense that two goals are achieved at once: learning M-density
and learning xb(y). What remains unknown in DSM is the latter, and knowing the estimator is key
here. Without it, we cannot draw a formal equivalence between pX and pY (see Sec. 1). We return to
this discussion at the end of the paper from a different angle with regards to denoising autoencoders.
5
Published as a conference paper at ICLR 2022
4	Parametrization S chemes
We present three parametrization schemes for modeling Gaussian M-densities. Due to our interest in
σ 0 M models We switch to a lighter notation. Here, the learning objective (Eq. 14) takes the form
12
L(θ) = M E(x,y)〜p(y∣x)p(x)∣∣x 0 M — N + σ2Vfθ(y)∣∣2,	(17)
where x 0 M denotes (x, . . . , x) repeated M times. Parametrization schemes fall under two general
groups: multimeasurement energy model (MEM) and multimeasurement score model (MSM). In what
follows, MDAE is an instance of MSM, MEM2 & MUVB are (closely related) instances of MEM.
4.1	MDAE (multidenoising autoencoder)
The rigorous approach to learning Gaussian M-densities is to parametrize the energy function f .
In that parametrization, Vfθ is computed with automatic differentiation and used in the objective
(Eq. 17). That is a computational burden, but it comes with a major advantage as the learned score
function is guaranteed to be a gradient field. The direct parametrization of Vf is problematic due to
this requirement analyzed by (Saremi, 2019); see also (Salimans & Ho, 2021) for a recent discussion.
Putting that debate aside, in MDAE we parametrize the score function explicitly gθ : RMd → RMd .
Then, gθ replaces -Vfθ in Eq. 17. In particular, we consider the following reparametrization:
gθ(y) := (vθ(y) — y)∕σ2,	(18)
simply motivated by the fact we would like to cancel y in Eq. 17, otherwise the loss starts at very
high values at the initialization. This is especially so in the regime of large σ , M, and d. It follows:
L(θ) = MT E(χ,y)〜p(y∣χ)p(χ) IIx 0 M - V(y)俏.	(19)
This is very intriguing and it is worth taking a moment to examine the result: modeling M-densities
is now formally mapped to denoising multimeasurement noisy data explicitly. It is a DAE loss with a
multimeasurement twist. Crucially, due to our empirical Bayes formulation, the MDAE output νθ (y)
becomes a parametrization of the Bayes estimator(s) (combine Eq. 18 and Eq. 11):
xb(m)(y; θ) = νm(y; θ).	(20)
This makes a strong theoretical connection between our generalization of empirical Bayes to factorial
kernels and a new learning paradigm under multidenoising autoencoders, valid for any noise level σ .
4.2	MEM2 (mem with a quadratic form with an optional metaencoder)
Can we write down an energy function associated with the score function in Eq. 18? The answer is
no, since gθ is not a gradient field in general, but we can try the following (θ = (η, ζ)):
12
fθ(y) := 2σ2I∣y — Vn(y)I∣2 + hζ(y,Vn(N)).	QI)
Ignoring hζ for now, by calculating -Vfθ we do get both terms in Eq. 18, plus other terms. The
function hζ which we call metaencoder is optional here. Intuitively, it captures the “higher order
interactions” between N and V, beyond the quadratic term (see below for another motivation). The
metaencoder is implicitly parametrized by η (via Vn), while having its own set of parameters ζ.
4.3 MUVB (multimeasurement unnormalized variational bayes)
The expression above (Eq. 21) is a simplification of an unnormalized latent variable model that one
can set up, where we take the variational free energy to be the energy function. This builds on recent
studies towards bringing together empirical Bayes and variational Bayes (Saremi, 2020a;b). We
outline the big picture here and refer to Appendix C for details. Latent variable models operate on
the principle of maximum likelihood, where one is obliged to have normalized models. Since our
model is unnormalized we consider setting up a latent variable model with unnormalized conditional
density. Essentially both terms in Eq. 21 arise by considering (z is the vector of latent variables)
P(n,Z)(y|z) Y exP (— 2σ2ky — Vn(z)∣∖2 — hζ(y Vn(Z))) ,	(22)
named metalikelihood which further underscores the fact that it is unnormalized. The full expression
for the energy function also involves the posterior qφ(z∣y). As a remark, note that what is shared
between all three parametrization schemes is V, although vastly different in how xb(N) is computed.
6
Published as a conference paper at ICLR 2022
5 Sampling Algorithm
Our sampling algorithm is an adaptation of walk-jump sampling (WJS) (Saremi & Hyvarinen, 2019).
We run an MCMC algorithm to sample M-density by generating a Markov chain of multimeasurement
noisy samples. This is the walk phase of WJS schematized by the dashed arrows in Fig. 2. At arbitrary
discrete time k, clean samples are generated by simply computing xb(yk) (θ is dropped for a clean
notation). This is the jump phase of WJS schematized by the solid arrow in Fig. 2. What is appealing
about multimeasurement generative models is the fact that for large M, p(x|yk) is highly concentrated
around its mean xb(yk), therefore this scheme is an exact sampling scheme—this was in fact our
original motivation to study M-densities. For sampling the M-density (the walk phase), we consider
Langevin MCMC algorithms that are based on discretizing the underdamped Langevin diffusion:
dvt = -YVtdt - uVf (yt)dt + (y∕2γu)dBt,
dyt = vtdt.
(23)
Here γ is the friction, u the inverse mass, and Bt the standard Brownian motion in RMd . Discretizing
the Langevin diffusion and their analysis are challenging problems due to the non-smooth nature of
the Brownian motion (MorterS & Peres, 2010). There has been a significant progress being made
however in devising and analyzing Langevin MCMC algorithms, e.g. Cheng et al. (2018) introduced
an algorithm with a mixing time that scales as O (ʌ/d) in a notable contrast to the best known O(d)
for MCMC algorithms based on overdamped Langevin diffusion. The dimension dependence of the
mixing time is of great interest here since we expand the dimension M-fold. To give an idea regarding
the dimension, for the 4 0 8 model on FFHQ-256, Md ≈ 106. We implemented (Cheng et al., 2018,
Algorithm 1) in this paper which to our knowledge is its first use for generative modeling. In addition,
we used a Langevin MCMC algorithm due to Sachs et al. (2017), also used by Arbel et al. (2020).
Note, in addition to γ and u, Langevin MCMC requires δ, the step size used for discretizing Eq. 23.
Figure 2: (WJS schematic) In this schematic, the Langevin walk
is denoted by the dashed arrow. The jump is denoted by the solid
arrow which is deterministic. The jumps in WJS are asynchronous
(Remark 5). In presenting long chains in the paper we show jumps
at various frequencies denoted by ∆k (Remark 6). We use the
same MCMC parameters for all noise channels due to permutation
symmetry in σ 0 M models. See Appendix D for more details.
Figure 3: (WJS chains on FFHQ-256) The chains are shown skipping ∆k = 10 steps (no warmup).
We used Algorithm 1 with δ = 2, γ = 1/2, u = 1. Transitions are best viewed electronically.
7
Published as a conference paper at ICLR 2022
Figure 4: (4 0 8 gallery) Samples from our FFHQ-256, MDAE, 4 0 8 model.
6	Experimental Results
For all models with the MDAE and MEM2 parametrizations, we used U2-Net (Qin et al., 2020)
network architecture, a recent variant of UNet (Ronneberger et al., 2015), with a few simple changes
(see Appendix E). For the MUVB parametrization for MNIST (evaluated in Sec. G.3), we used
Residual networks for the encoder, decoder and metaencoder. Despite the inherent complexity of the
task of learning high-dimensional energy models, it is notable that our framework results in a single
least-squares objective function, which we optimized using Adam (Kingma & Ba, 2014) without
additional learning rate schedules. Additional details of the experimental setup are in Appendix E.
Arguably, the ultimate test for an energy model is whether one can generate realistic samples from it
with a single fast mixing MCMC chain that explores all modes of the distribution indefinitely, starting
from random noise. We informally refer to them as lifelong Markov chains. To give a physical
picture, a gas of molecules that has come in contact with a thermal reservoir does not stop mid air after
thermalizing—arriving at its “first sample”—it continues generating samples from the Boltzmann
distribution as long as the physical system exists. To meet this challenge, the energy landscape must
not have any pathologies that cause the sampling chain to break or get stuck in certain modes. In
addition, we need fast mixing (Langevin) MCMC algorithms, a very active area of research by itself.
To put this goal in context, in recent energy models for high-dimensional data (Xie et al., 2016; 2018;
Nijkamp et al., 2019; Du & Mordatch, 2019; Zhao et al., 2020; Du et al., 2020; Xie et al., 2021),
sampling using MCMC quickly breaks or collapses to a mode and chains longer than a few hundred
steps were not reported. Thus, evaluation in prior work relies on samples from independent MCMC
chains, in addition by using heuristics like “replay buffer” (Du & Mordatch, 2019). In this work, we
report FID scores obtained by single MCMC chains, the first result of its kind, which we consider as
a benchmark for future works on long run MCMC chains (see Table 4 for numerical comparisons).
For MNIST, we obtain fast-mixing chains for over 1 M steps using MDAE and MUVB. On CIFAR-
10 and FFHQ-256, we obtain stable chains up to 1 M and 10 K steps, respectively, using MDAE.
The results are remarkable since energy models—that learn a single energy/score function—have
never been scaled to 256×256 resolution images. The closest results are by Nijkamp et al. (2019)
and Du et al. (2020) on CelebA (128 X128)—in particular, our results in Figs. 3, 4 can be compared
to (Nijkamp et al., 2019, Figs. 1, 2). For CIFAR-10, we report the FID score of 43.95 for 1 0 8
model, which we note is achieved by a single MCMC chain (Fig. 13); the closest result on FID score
obtained for long run MCMC is 78.12 by Nijkamp et al. (2022) which is not on single chains, but on
several parallel chains (in that paper the “long run” chains are 2K steps vs. 1 M steps in this work).
Our detailed experimental results are organized in appendices as follows. Appendix F is devoted
to an introduction to Langevin MCMC with demonstrations using our FFHQ-256 4 0 8 model.
Appendix G is devoted to MNIST experiments. At first we compare 1/4 0 1 and 1 0 16 (Sec. G.1).
These models are statistically identical regarding the plug-in estimators (Eq. 10) and they arrive at
similar training losses, but very different as generative models. This sheds light on the question
why we considered such high noise levels in designing experiments (Fig. 5). We then present the
effect of increasing M for a fixed σ, the issue of time complexity, and mixing time vs. image quality
trade-off (Sec. G.2). The discussions in Sec. G.1 and Sec. G.2 are closely related. We then compare
MDAE and MUVB for 1 0 4 with the message that MDAE generates sharper samples while MUVB
has better mixing properties (Sec. G.3). We then present one example of a lifelong Markov chain
(Sec. G.4). Our MDAE model struggles on the CIFAR-10 challenge due to optimization problems.
The results and further discussion are presented in Appendix H. Finally, in Appendix I we show
chains obtained for FFHQ-256, including the ones that some of the images in Fig. 4 were taken from.
8
Published as a conference paper at ICLR 2022
Figure 5: (single-step multidenoising) A clean data (x), a sample from MNM (y) for the 4 0 4 model
(Fig. 3a), the outputs of MDAE (ν), and xbmean(y) are visualized from left to right. The outputs νθ(y)
correspond to the Bayes estimator(s) which as expected from theory (Eq. 8) are indistinguishable.
7	Related Work
Despite being a fundamental framework for denoising, empirical Bayes has been surprisingly absent
in the DAE/DSM literature. Raphan & Simoncelli (2011) first mentioned the connection between
empirical Bayes and score matching, but this work is practically unknown in the literature; for much
of its development, DSM was all tied to DAEs (Vincent, 2011; Alain & Bengio, 2014); see (Bengio
et al., 2013) for an extensive survey. Abstracting DSM away from DAE is due to Saremi et al.
(2018) where they directly parametrized the energy function. In this work, we closed the circle, from
empirical Bayes to DAEs. One can indeed use the MDAE objective and learn a generative model:
a highly generalized DAE naturally arise from empirical Bayes. The important subtlety here is, as
we remarked in Sec. 3.2, we can only arrive at this connection starting from our generalization of
empirical Bayes, not the other way around. Of course, this core multimeasurement aspect of our
approach, without which we do not have a generative model, does not exist in the DAE literature.3
To address the problem of choosing a noise level in DSM (Saremi et al., 2018), Song & Ermon (2019)
studied it with multiple noise levels by summing up the losses using a weighing scheme. See (Li et al.,
2019; Chen et al., 2020; Song & Ermon, 2020; Kadkhodaie & Simoncelli, 2020; Jolicoeur-Martineau
et al., 2020) in that direction. The learning objectives in these models are based on heuristics in how
different noise levels are weighted. Denoising diffusion models (Ho et al., 2020; Song et al., 2020;
Gao et al., 2020) follow the same philosophy while being theoretically sound. Sampling in these
models are based on annealing or reversing a diffusion process. Our philosophy here is fundamentally
different. Even “noise levels” have very different meaning here, associated with the M noise channels
of the factorial kernel. All noise levels (which we took to be equal in later parts, a meaningless choice
in other methods) are encapsulated in a single energy/score function. Using Langevin MCMC we
only sample highly noisy data y. Clean data in Rd is generated via a single step by computing xb(y).
8	Conclusion
We approached the problem of generative modeling by mapping a complex density in Rd to a
smoother “dual” density, named M-density, in RMd . Permutation invariance is a design choice
which we found particularly appealing. Using factorial kernels for density estimation and generative
modeling have never been explored before and this work should open up many new avenues. We
believe the topic of parametrization will play an especially important role in future developments.
There is a unity in the parametrization schemes we proposed and studied in the paper, but much
remains to be explored in understanding and extending the relationship between MEMs and MSMs.
Our MDAE parametrization scheme (an instance of MSM) is especially appealing for its simplicity
and connections to the past literature. DAEs have a very rich history in the field of representation
learning. But research on them as generative models stopped around 2015. Our hypothesis is that
one must use very large noise to make them work as generative models for complex datasets in high
dimensions. Our permutation invariant multimeasurement approach is an elegant solution since it
allows for that choice at the cost of computation (large M), with only one parameter left to tune: σ !
Crucially, the probabilistic interpretation is ingrained here, given by the algebraic relations between
the MDAE output V(y), the Bayes estimator b(y), and the score function V logp(y).
3 There are similarities between Eq. 5 in (Alain & Bengio, 2014) and Eq. 18 here. However, one is on barely
noisy data (σ → 0) in Rd, the other on multimeasurements in RMd for any (high) noise level σ. There, they
arrived at Eq. 5 (with some effort) starting from a DAE objective. Here, we start with Eq. 18 (it defines the score
function) and arrive at MDAE objective (Eq. 19), in one line of algebra.
9
Published as a conference paper at ICLR 2022
Acknowledgement
We would like to thank AaPo Hyvarinen, Francis Bach, and Faustino Gomez for their valuable
comments on the manuscript, and Vojtech Micka for help in running experiments.
Ethical Considerations
By their very nature, generative models assign a high (imPlicit or exPlicit) likelihood to Points
in their training set. When samPles are generated from a trained generative model, it is quite
Possible that some samPles are very similar or identical to certain data Points in the training set.
This is imPortant to keeP in mind when the data used to train a generative model is confidential
or contains Personally identifiable information such as Pictures of faces in the FFHQ-256 dataset
(Karras et al., 2019). Care should be taken to abide by license terms and ethical PrinciPles when using
samPles from generative models. For FFHQ-256 in Particular, Please see terms of use at https:
//github.com/NVlabs/ffhq-dataset/blob/master/README.md. Additionally, we
recommend considering the in-dePth discussion on this subject by Prabhu & Birhane (2020) before
dePloying aPPlications based on generative models.
Reproducibility Statement
All imPortant details of the exPerimental setuP are Provided in APPendix E. Our code is Publicly
available at https://github.com/nnaisense/mems.
References
Guillaume Alain and Yoshua Bengio. What regularized auto-encoders learn from the data-generating
distribution. The Journal ofMachine Learning Research,15(1):3563-3593, 2014.
Philip W Anderson. More is different. Science, 177(4047):393-396, 1972.
ChristoPhe Andrieu, Nando De Freitas, Arnaud Doucet, and Michael I Jordan. An introduction to
MCMC for machine learning. Machine learning, 50(1-2):5-43, 2003.
Michael Arbel, Liang Zhou, and Arthur Gretton. Generalized energy based models. arXiv preprint
arXiv:2003.05033, 2020.
Yoshua Bengio, Aaron Courville, and Pascal Vincent. Representation learning: A review and new
perspectives. IEEE Transactions on Pattern Analysis and Machine Intelligence, 35(8):1798-1828,
2013.
Nanxin Chen, Yu Zhang, Heiga Zen, Ron J Weiss, Mohammad Norouzi, and William Chan. Wavegrad:
Estimating gradients for waveform generation. arXiv preprint arXiv:2009.00713, 2020.
Xiang Cheng, Niladri S Chatterji, Peter L Bartlett, and Michael I Jordan. Underdamped Langevin
MCMC: A non-asymptotic analysis. In Conference on Learning Theory, pp. 300-323. PMLR,
2018.
Rewon Child. Very deep VAEs generalize autoregressive models and can outperform them on images.
arXiv preprint arXiv:2011.10650, 2020.
Yilun Du and Igor Mordatch. Implicit generation and generalization in energy-based models. arXiv
preprint arXiv:1903.08689, 2019.
Yilun Du, Shuang Li, Joshua Tenenbaum, and Igor Mordatch. Improved contrastive divergence
training of energy based models. arXiv preprint arXiv:2012.01316, 2020.
Stefan Elfwing, Eiji Uchibe, and Kenji Doya. Sigmoid-weighted linear units for neural network
function approximation in reinforcement learning. arXiv preprint arXiv:1702.03118, 2017.
William Falcon et al. Pytorch Lightning. URL https://github.com/PyTorchLightning.
Ruiqi Gao, Yang Song, Ben Poole, Ying Nian Wu, and Diederik P Kingma. Learning energy-based
models by diffusion recovery likelihood. arXiv preprint arXiv:2012.08125, 2020.
10
Published as a conference paper at ICLR 2022
Ziv Goldfeld, Kristjan Greenewald, Jonathan Niles-Weed, and Yury Polyanskiy. Convergence of
smoothed empirical measures with applications to entropy estimation. IEEE Transactions on
Information Theory, 66(7):4368-4391, 2020.
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image
recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition,
pp. 770-778, 2016.
Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter.
GANs trained by a two time-scale update rule converge to a local nash equilibrium. Advances in
neural information processing systems, 30, 2017.
Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion probabilistic models. arXiv preprint
arXiv:2006.11239, 2020.
AaPo Hyvarinen. Estimation of non-normalized statistical models by score matching. Journal of
Machine Learning Research, 6(Apr):695-709, 2005.
Alexia Jolicoeur-Martineau, Remi Piche-Taillefer, Remi Tachet des Combes, and Ioannis Mitliagkas.
Adversarial score matching and imProved samPling for image generation. arXiv preprint
arXiv:2009.05475, 2020.
Michael I Jordan, Zoubin Ghahramani, Tommi S Jaakkola, and Lawrence K Saul. An introduction to
variational methods for graPhical models. Machine learning, 37(2):183-233, 1999.
Zahra Kadkhodaie and Eero P Simoncelli. Solving linear inverse Problems using the Prior imPlicit in
a denoiser. arXiv preprint arXiv:2007.13640, 2020.
Tero Karras, Samuli Laine, and Timo Aila. A style-based generator architecture for generative
adversarial networks. In Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition, PP. 4401-4410, 2019.
Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic oPtimization. arXiv preprint
arXiv:1412.6980, 2014.
Diederik P Kingma and Max Welling. Auto-encoding variational Bayes. arXiv preprint
arXiv:1312.6114, 2013.
Alex Krizhevsky. Learning multiPle layers of features from tiny images. Master’s thesis, University
of Toronto, 2009.
Yann LeCun, Leon Bottou, YoShUa Bengio, and Patrick Haffner. Gradient-based learning applied to
document recognition. Proceedings of the IEEE, 86(11):2278-2324, 1998.
Zengyi Li, Yubei Chen, and Friedrich T Sommer. Learning energy-based models in high-dimensional
spaces with multi-scale denoising score matching. arXiv preprint arXiv:1910.07762, 2019.
Min Lin, Qiang Chen, and Shuicheng Yan. Network in network. arXiv preprint arXiv:1312.4400,
2013.
Koichi Miyasawa. An empirical Bayes estimator of the mean of a normal population. Bulletin of the
International Statistical Institute, 38(4):181-188, 1961.
Takeru Miyato, Toshiki Kataoka, Masanori Koyama, and Yuichi Yoshida. Spectral normalization for
generative adversarial networks. arXiv preprint arXiv:1802.05957, 2018.
Peter Morters and Yuval Peres. Brownian motion, volume 30. Cambridge University Press, 2010.
Erik Nijkamp, Mitch Hill, Song-Chun Zhu, and Ying Nian Wu. Learning non-convergent non-
persistent short-run MCMC toward energy-based model. arXiv preprint arXiv:1904.09770, 2019.
Erik Nijkamp, Ruiqi Gao, Pavel Sountsov, Srinivas Vasudevan, Bo Pang, Song-Chun Zhu, and
Ying Nian Wu. MCMC should mix: Learning energy-based model with flow-based backbone. In
International Conference on Learning Representations, 2022.
11
Published as a conference paper at ICLR 2022
Emanuel Parzen. On estimation of a probability density function and mode. The annals of mathemat-
ical statistics, 33(3):1065-1076,1962.
Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary DeVito,
Zeming Lin, Alban Desmaison, Luca Antiga, and Adam Lerer. Automatic differentiation in
PyTorch. 2017.
Vinay Uday Prabhu and Abeba Birhane. Large image datasets: A pyrrhic win for computer vision?
arXiv preprint arXiv:2006.16923, 2020.
Xuebin Qin, Zichen Zhang, Chenyang Huang, Masood Dehghan, Osmar Zaiane, and Martin Jagersand.
U2-Net: Going deeper with nested U-structure for salient object detection. volume 106, pp. 107404,
2020.
Prajit Ramachandran, Barret Zoph, and Quoc V Le. Swish: a self-gated activation function. arXiv
preprint arXiv:1710.05941, 7, 2017.
Martin Raphan and Eero P Simoncelli. Least squares estimation without priors or supervision. Neural
Computation, 23(2):374-420, 2011.
Herbert Robbins. An empirical Bayes approach to statistics. In Proc. Third Berkeley Symp., volume 1,
pp. 157-163, 1956.
Olaf Ronneberger, Philipp Fischer, and Thomas Brox. U-Net: Convolutional networks for biomedical
image segmentation. In International Conference on Medical image computing and computer-
assisted intervention, pp. 234-241. Springer, 2015.
Matthias Sachs, Benedict Leimkuhler, and Vincent Danos. Langevin dynamics with variable coeffi-
cients and nonconservative forces: from stationary states to numerical methods. Entropy, 19(12):
647, 2017.
Tim Salimans and Jonathan Ho. Should EBMs model the energy or the score? In Energy Based
Models Workshop-ICLR 2021, 2021.
Saeed Saremi. On approximating Vf with neural networks. arXiv preprint arXiv:1910.12744, 2019.
Saeed Saremi. Learning and inference in imaginary noise models. arXiv preprint arXiv:2005.09047,
2020a.
Saeed Saremi. Unnormalized variational Bayes. arXiv preprint arXiv:2007.15130, 2020b.
Saeed Saremi and Aapo Hyvarinen. Neural empirical Bayes. Journal ofMachine Learning Research,
20(181):1-23, 2019.
Saeed Saremi, Arash Mehrjou, Bernhard Scholkopf, and Aapo Hyvarinen. Deep energy estimator
networks. arXiv preprint arXiv:1805.08306, 2018.
Yang Song and Stefano Ermon. Generative modeling by estimating gradients of the data distribution.
arXiv preprint arXiv:1907.05600, 2019.
Yang Song and Stefano Ermon. Improved techniques for training score-based generative models.
arXiv preprint arXiv:2006.09011, 2020.
Yang Song, Jascha Sohl-Dickstein, Diederik P Kingma, Abhishek Kumar, Stefano Ermon, and Ben
Poole. Score-based generative modeling through stochastic differential equations. arXiv preprint
arXiv:2011.13456, 2020.
Rupesh Kumar Srivastava, Klaus Greff, and JUrgen Schmidhuber. Training very deep networks.
In Proceedings of the 28th International Conference on Neural Information Processing Systems-
Volume 2, pp. 2377-2385, 2015.
Terence Tao. Topics in random matrix theory. American Mathematical Society, 2012.
Pascal Vincent. A connection between score matching and denoising autoencoders. Neural Computa-
tion, 23(7):1661-1674, 2011.
12
Published as a conference paper at ICLR 2022
Martin J Wainwright. High-dimensional statistics: A non-asymptotic viewpoint, volume 48. Cam-
bridge University Press, 2019.
Norbert Wiener. Extrapolation, interpolation, and smoothing of stationary time series: with engi-
neering applications, volume 8. MIT press Cambridge, MA, 1964.
Jianwen Xie, Yang Lu, Song-Chun Zhu, and Yingnian Wu. A theory of generative convnet. In
International Conference on Machine Learning,pp. 2635-2644. PMLR, 2016.
Jianwen Xie, Yang Lu, Ruiqi Gao, Song-Chun Zhu, and Ying Nian Wu. Cooperative training of
descriptor and generator networks. IEEE transactions on pattern analysis and machine intelligence,
42(1):27-45, 2018.
Jianwen Xie, Zilong Zheng, and Ping Li. Learning energy-based model with variational auto-encoder
as amortized sampler. In The Thirty-Fifth AAAI Conference on Artificial Intelligence (AAAI),
volume 2, 2021.
Yang Zhao, Jianwen Xie, and Ping Li. Learning energy-based generative models via coarse-to-fine
expanding and sampling. In International Conference on Learning Representations, 2020.
13
Published as a conference paper at ICLR 2022
A Gaussian M-densities
We study the Bayes estimator for Gaussian MNMs analytically for X = N(μ, σ2Id), where μ ∈ Rd.
As in the example for Poisson MNM in the paper, the first step is to derive an expression for the joint
density
p(y) =	pm(ym|x)p(x)dx.
m
(24)
We start with M = 2. Next we perform the integral above:
log p(y1, y2 )
Ily1俏。2+度+帆俏(苏+由+ |仅俏⑸+度
2(σισ2 + σ2σ0 + σ0σ2)
+ 2hyι, y2iσ0 + 2hμ, y2iσ2 + 2hμ, yιiσ2
2(σ2σ2 + σ2 σ2 + σ0σ2)
- logZ(σ0,σ1,σ2),
(25)
where Z is the partition function:
Z(σ0,σ1,σ2) = ((2∏)2(σ0σ1σ2)2(σ-2 + σ-2 + σ-2))d/2 .
The multimeasurement Bayes estimator of X is computed next via Eq. 7:
〜	、	μσ2σ2 + yισ2σ2 + y2σ0σ2
x(y1 ,y2) = FRW不厂.
(26)
As a sanity check, xb(y) is the same whether Eq. 7 is computed using m = 1 or m = 2. Another
sanity check is the limit σ1 → 0, which we recover xb(y1, y2) = y1 = x. The linear relation (linear
in y for μ = 0) observed in Eq. 26 is a generalization of the well known results for M = 1, known
as Wiener filter (Wiener, 1964).
A visualization of this result for a mixture of Gaussian is given in Fig. 1. Next we state the results for
general M, and after that we derive the expression for the Bayes estimator xb(y).
It is convenient to define the following notations:
M	MM
∑m := ∏ σ2m ∙ ZM, where ZM := ɪɪ σ2πi ∙ E σrn2,
m=0	m=0	m=0
M
y :=〉: yM\m, where yM\m := ym
m=0
ɪɪ σ2, and y := μ.
l∈[M ]\m
With these notations, the expression for the M-density is given by:
logp(y) = - X ⅛F + ∣l - dlog ((2∏)m PZM).
m=0 2σm2	2ΣM
(27)
We can now derive xb(y) using Eq. 7. Given the expression above, the algebra is straightforward:
b(y) = ym + σmVm logp(y)
=ym - ym + σm (2ςm )-1 Vm ∣∣y ∣∣2
=(2 Y σ2 ∙ Zm )-12σm, ∣	∏ σ2) y
l=0	∖l∈[M ]\m	)
=y/ZM
(28)
Note that the final expression is the same by carrying the algebra for any measurement index m.
14
Published as a conference paper at ICLR 2022
B M-DENSITY SCORE MATCHING ≡ MULTIMEASUREMENT DSM
Here We provide the score matching formalism (Hyvarinen, 2005) on M-densities and We arrive at
a multimeasurement denoising score matching (MDSM) learning objective. The derivation closely
folloWs (Vincent, 2011) using our notation. In What folloWs equalities are modulo additive constants
(not functions of parameters θ) Which We denote by the color gray:
J(θ) = EyII-Vyfθ (y) - Vy log p(y)∣∣2
=EyIIVy fθ (y)∣∣2 +2 ∙ EyhVyfxy), Vy log P(y)i+Ey∣∣vy log P(y)∣∣2
= Ey∣∣Vyfθ(y)∣∣22 +2	p(y)hVyfθ(y), Vy logp(y)idy
= Ey∣∣Vyfθ(y)∣∣22 +2	hVyfθ(y), Vyp(y)idy
= Ey∣∣Vyfθ(y)∣∣22 + 2	hVyfθ(y), Vyp(y|x)ip(x)dxdy
= Ey∣∣Vyfθ(y)∣∣22 + 2	hVyfθ(y), p(y|x)-1Vyp(y|x)ip(y|x)p(x)dxdy
=EyIIVyfθ(y)∣∣2 +2 ∙ E(χ,y)"yfθ9, Vy logP(y⑶)
=E(x,y) II VyfXy) ∣∣2 + 2 ∙ E(x,y) hVyfθ⑺,Vy logP(y Ix)i -E(x,y) ∣∣ Vy logP(y Ix) ∣∣2
=E(χ,y)∣∣ - Vyfθ(y) - Vy logP(y|x升2
(29)
The M-density score matching learning objective is given by the first identity above and the last
equality is the MDSM objective:
J(θ) = E(x,y)∣∣ -Vyfθ(y) - Vy log p(yIx)∣∣22	(30)
For Gaussian MNMs, the MDSM learning objective simplifies to:
M
J(θ) = X Jm(θ), where Jm = E(χ,y) ∣∣ - Vm^fθ(y) + ym-x ∣∣2 .	(31)
m=1	σm
C MUVB: an unnormalized latent variable model
In this section We give a formulation of the energy function parametrization scheme Which is named
multimeasurement unnormalized variational Bayes (MUVB). Conceptually, MUVB is motivated
by the goal of connecting empirical Bayes’ denoising frameWork With variational Bayes’ inference
machinery. There seem to be fundamental challenges here since one model is based on least-
squares estimation, the other based on the principle of maximum likelihood. In What folloWs, this
“fundamental conflict” takes the shape of latent variable model that is unnormalized. There have been
recent sudies along these lines (Saremi, 2020a;b) that We expand on; in particular We introduce the
novel metaencoder. At a high level, the idea here is to set up a latent variable model for M-densities
and use the variational free energy as the energy function. We refer to (Jordan et al., 1999) for an
introduction to variational methods. In what follows, We use the lighter notation for σ 0 M models
(Remark 2) that We also used in Sec. 4.
In its simplest form, the latent variable model for M-densities is set up by the following choices:
•	The prior over latent variables which we take to be Gaussian
p(z) = N(z; 0, Idz ).
•	The approximate posterior over latent variables qφ(zIy) which is taken to be the factorized
Gaussian, a standard choice in the literature.
•	For the conditional densitypη(yIz) we can consider the following
pη(yIz) = N(y; νη(z), σ2IMd),
15
Published as a conference paper at ICLR 2022
which may seem as a especially “natural” choice since samples from the M-density are
obtained by adding multimeasurement noise to clean samples.
In the variational autoencoder parlance, φ are the encoder’s parameters, η the decoder’s parameters,
and ν = (ν1, . . . , νM) the decoder’s outputs. With this setup, the variational free energy is easily
derived which we take to be the energy function as follows (θ = (φ, η)):
12
fθ (y) = 2σ2 Eqφ(z∣y)∣∣y - 1 11 * * Vn(Z)I∣2 + KL(qφ (Hy)kp(Z)),
where the KL divergence is derived in closed form, and the expectation is computed by sampling
z 〜qφ(z∣y) via the reparametrization trick (Kingma & Welling, 2013).
In this machinery, in the inference step we are forced to have normalized (and tractable) posteriors
since We must take samples from qφ(z∣y). What about the conditional density p(y∣z)? If We were to
formalize a VAE for modeling M-densities we had to have a normalized conditional density p(y|Z)
since that frameWork is based on the principle of maximum likelihood. What is intriguing about our
setup is that since our goal is to learn the unnormalized p(y), We can consider conditional densities
p(y|Z ) that are unnormalized. An intuitive choice is the folloWing that We name metalikelihood:
P(n,Z)(y|z) X eχp (-2σ2l∣y - Vn(Z)Il2 - hζ(y, Vn(Z))).
NoW, the energy function takes the folloWing form (θ = (φ, η, ζ)):
fθ(y) = Eqφ(z∣y) I∣y — Vn(z)ll2+ hζ(y,Vn(Z)) + KL(q。(Hy)kp(Z)).	(32)
This is the final form of MUVB energy function. We refer to hζ by metaencoder. Its input is
(y, ν (Z ; η)) (note that Z itself is a function of y via inference), and one can simply use any encoder
architecture to parametrize it. In our implementation, We used the standard VAE pipeline and We
reused the encoder architecture to parametrize the metaencoder.
D Two Walk-Jump Sampling Algorithms
In this section We provide the Walk-jump sampling (WJS) algorithm based on different discretizations
of underdamped Langevin diffusion (Eq. 23). The first is due to Sachs et al. (2017) Which has also
been used by Arbel et al. (2020) for generative modeling. The second is based on a recent algorithm
analyzed by Cheng et al. (2018) Which We implemented and give the detailed algorithm here. In
addition, We extended their calculation to general friction (they set γ = 2 in the paper) and provide
an extension of the (Cheng et al., 2018, Lemma 11) for completeness (the proof closely folloWs the
calculation in the reference). In both cases we provide the algorithm for σ 0 M models.
D. 1 Walk-Jump Sampling Algorithm I
Algorithm 1: Walk-jump sampling (Saremi & Hyvarinen, 2019) using the discretization of
Langevin diffusion by Sachs et al. (2017). The for loop corresponds to the dashed arrows (walk)
in Fig. 2 and line 14 (〈•)is computed over the measurement indices m) to the solid arrow (jump).
1: Input δ (step size), U (inverse mass), Y (friction), K (steps taken)
2: Input Learned energy function f (y) or score function g(y) ≈ V logp(y)
3: Ouput XK
4: Yo 〜Unif([0,1]Md)
5: Vo - 0
6: for k = [0, . . . , K) do
7：	γk+ι - γk + δV k/2
8:	Ψk+1 J -Vyf(Yk+ι) or Ψk+1 J g(Yk+ι)
9:	Vk+1 J Vk + uδΨk+ι∕2
10:	Bk+1 〜N(0,IMd)
11:	Vk + 1 J exp(-Yδ)vk+1 + uδψk + 1/2 + PpU (1 - exp(-2Yδ))Bk + 1
12:	Yk+1 J Yk+1 + δVk+1∕2
13: end for
14: XbK J hYK,m - σ2Vmf(YK)i or XbK J hYK,m+σ2gm(YK)i
16
Published as a conference paper at ICLR 2022
D.2 Walk-Jump Sampling Algorithm II
Before stating the algorithm, we extend the calculation in Cheng et al. (2018, Lemma 11) to general
friction, which we used in our implementation of their Langevin MCMC algorithm. The algorithm is
stated following the proof of the lemma which closely follows Cheng et al. (2018).
The starting point is solving the diffusion Eq. 23. With the initial condition (y0 , v0), the solution
(yt , vt ) to the discrete underdamped Langevin diffusion is (t is considered small here)
vt = voe-γt - U (JOt e-Y(t—S)Vf (yo)ds) + P2YULt e-γ(t-s)dBs,
yt = y0 +	vsds,
0
(33)
These equations above are then used in the proof of the following lemma.
Lemma 1. Conditioned on (y0 , v0), the solution of underdamped Langevin diffusion (Eq. 23)
integrated up to time t is a Gaussian with conditional means
E[vt] = voe-γt - γ-1u(1 - e-γt)Vf (yo)
E[yt] = yo + Y-1(1 — e-γt)vo - YTu (t - γ-1(1 - e-γt)) Vf (y0),
(34)
and with conditional covariances
E[(yt - E[yt])(yt - E[yt])>] = YTU(2t - 4γ-1 (1 - e-γt) + YT(1 - e-2γt)) ∙小
E[(vt - E[vt])(vt - E[vt])>] = u(1 - e-2γt) ∙ 5	(35)
E[(yt - E[yt])(vt - E[vt])>] = YTU(I - 2e-γt + e-2γt) ∙ Imd.
Proof. Computation of conditional means is straightforward as the Brownian motion has zero means:
E[vt] = v0e-γt - Y-1u(1 - e-γt)Vf(y0)
E[yt] = yo + YT(I- e-γt)vo - YTU (t - YT(I- e-γt)) Vf (yo),
All the conditional covariances only involve the Brownian motion terms. We start with the simplest:
E[(vt - E[vt])(vt - E[vt])>] = 2YuE
2YU
Z0te-γ(t-s)d
(t e-2γ J)ds) ∙ IMd
t
e-γ(t-s
(36)
=u(1 - e-2γt) ∙ IMd
From Eq. 33, the Brownian motion term for yt is given by
e-γ(t-s
γrdr dBs
2Y-1
-γ(t-s) dBs.
The conditional covariance for yt follows similar to Eq. 36:
E[(yt - E[yt])(yt - E[yt])>] = 2Y-1u
e-γ(t-叫2 dS∖ ∙ IMd
(37)
=YTU (2t - 4y-1(1 - e-γt) + Y-1(1 - e-2γt)) ∙ IMd
Finally the conditional covariance between yt and vt is given by
E[(yt - E[yt])(vt - E[vt])>] = 2UE
2U
e-γ(t-s)) e-γ(t-s)ds ∙ IMd
1 - e-γ(t-s) dB
t e-γ(t-s)dBs)
Y-1u(1 - 2e-γt + e-2γt) ∙ IMd
□
17
Published as a conference paper at ICLR 2022
Algorithm 2: Walk-Jump Sampling (WJS) using the discretization of Langevin diffusion from
Lemma 1. Below, we provide the Cholesky decomposition of the conditional covariance matrix.
1:
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
Input δ (step size), u (inverse mass), γ (friction), K (steps taken)
Input Learned energy function f(y) or score function g(y) ≈ V log p(y)
Ouput XK
Yο 〜Unif([0,1]Md)
Vο - 0
for k = [0, . . . , K) do
ψk《-----Vyf (Yk) or ψk - g(Yk)
Vk+1 J Vke-γδ + YTu(1 - e-γδ)Ψk
Yk+1 J Yk + Y-1(1 - e-γδ)Vk + YTu (δ - γ-1(1 - e-γδ)) Ψk
Bk+1 〜 N (0, I2Md)
Yk+1
Vk+1
end for
^
XK — hYK,
一(vk+l) + LBk+1	// see Eq. 38
^,m ― O? Vmf(YK )i or XK《-hYK,m + σ? gm(Y K )i
The Cholesky decomposition Σ = LL> for the conditional covariance in Lemma 1 is given by:
where
L = ( gyy ∙ IMd
∑-y2∑yv ∙ IMd
(∑vvTv∕Σyy)1/2 ∙ IMdJ ,
Σyy = YTU (2δ- 4γ-1(1 - e-γδ)+ YT(I-e-2γδ))
Σvv = u(1 - e-2γδ)
Σyv = Y-1u(1 - 2e-γδ + e-2γδ)
(38)
(39)
(40)
(41)
Algorithm 1 vs. Algorithm 2 The two algorithms presented in this section have very different
properties in our high dimensional experiments. In general we found Algorithm 1 (A1) to behave
similarly to overdamped version (see Appendix F for some illustrations) albeit with much faster
mixing. We found friction Y to play a very different role in comparing the two algorithms, also
apparent in comparing the mathematical expressions in both algorithms: in A1, the friction only
appears in the form exp(-Yδ); it is more complex in A2. Similar discrepancy is found regarding u.
Remark 4 (Initialization scheme). The initialization Y0 〜 Unif([0, 1]Md) used in the algorithms is
the conventional choice, but for very large σ we found it effective to initialize the chain by further
adding the Gaussian noise in RMd :
Y0 = 0 + ε0, where 0 〜 Unif([0, 1]Md), ε0 〜 N (0, σ2Id)
Otherwise, with large step sizes δ = O(σ) the chains starting with the uniform distribution could
break early on. We found this scheme reliable, and it is well motivated since M-density p(y) is
obtained by convolving p(x) with the Gaussian MNM. With this initialization one starts “relatively
close” to the M-density manifold and this is more pronounced for larger σ. However, this initialization
scheme is based on heuristics (as is the conventional one).
Remark 5 (The jump in WJS is asynchronous). The jump in WJS is asynchronous (Fig. 2) and it can
also be taken inside the for loop in the algorithms provided without affecting the Langevin chain.
Remark 6 (The ∆k notation). In running long chains we set K to be large, and we report the jumps
(taken inside the for loops in the algorithms provided) with a certain fixed frequency denoted by ∆k.
Remark 7 (WJS for Poisson M-densities). WJS is a general sampling algorithm, schematized in
Fig. 2. However, for Poisson MNMs it will involve sampling a discrete distribution in NMd which
we do not know how to do efficiently in high dimensions (note that Langevin MCMC cannot be
used since the score function is not well defined for discrete distributions). We can use Metropolis-
Hastings algorithm and its popular variant Gibbs sampling but these algorithms are very slow in
high dimensions since at each iteration of the sampling algorithm in principle only 1 dimension out
of Md shall be updated, so in the general case the mixing time is at best of O(M d); one can use
“blocking” techniques but they are problem dependent and typically complex (Andrieu et al., 2003).
18
Published as a conference paper at ICLR 2022
E Experimental Setup
Datasets Our experiments were conducted on the MNIST (LeCun et al., 1998), CIFAR-10
(Krizhevsky, 2009) and FFHQ-256 (Karras et al., 2019; pre-processed version by Child, 2020)
datasets. The CIFAR-10 and FFHQ-256 training sets were augmented with random horizontal flips
during training.
Network Architectures For all experiments with the MDAE and MEM2 parametrization, the
U2Net network architecture (Qin et al., 2020) was chosen since it is a recent and effective variant
of the UNet (Ronneberger et al., 2015) that has been successfully applied to various pixel-level
prediction problems. However, we have not experimented with alternatives. Minor adjustments were
made to the U2Net from the original paper: we removed all normalization layers, and switched the
activation function to x → X ∙ sigmoid(x) (Elfwing et al., 2017; Ramachandran et al., 2017). To
approximately control the variance of inputs to the network in each dimension, even if the noise level
σ is large, the noisy input values were divided by a scaling factor √0.2252 + σ2. We also adjusted
the number of “stages” in the network, stage heights and layer widths (see Table 1 for details), in
order to fit reasonable batch sizes on available GPU hardware and keep experiment durations limited
to a few days (see Table 2).
For experiments with the MUVB parametrization (the MNIST model in Sec. G.3), we used Residual
convolutional networks utilizing a bottleneck block design with skip connections and average pooling
layers (Lin et al., 2013; Srivastava et al., 2015; He et al., 2016). The architecture of the encoder and
metaencoder were kept the same, while the decoder used the encoder architecture in reverse, with the
pooling layers substituted with nearest neighbour upsampling. See Table 3 for a detailed description
of the encoder architecture.
Remark 8. Strictly speaking, for σ 0 M models the energy function is permutation invariant and y
should be treated as {y1, . . . , yM}, a set consisting of M Euclidean vectors. This is however difficult
to enforce while keeping the model expressive. We note that in our model the permutation symmetry
is a “fragile symmetry” which one can easily break by making σm just slightly different from each
other. Therefore, we designed the architecture to be used for the general setting of σm different from
each other, and in experiments we just set them to be equal.
Training All models were trained using the Adam (Kingma & Ba, 2014) optimizer with the default
setting of β1 = 0.9, β2 = 0.999 and = 10-8. Table 2 lists the main hyperparameters used and
hardware requirements for training MDAE models for each dataset. The resulting training curves are
shown in Fig. 6, showing the stability of the optimization with a relatively simple setup.
Software All models were implemented in the CPython (v3.8) library PyTorch v1.9.0 (Paszke et al.,
2017) using the PyTorch Lightning framework v1.4.6 (Falcon et al.).
Table 1: U2Net architecture used for MDAE and MEM2 parametrizations for all datasets. All layer
widths (number of channels) were expanded by a width factor for CIFAR-10 and FFHQ-256.
Stage	Height	In channels	Mid channels	Out channels	Side
Encoder 1	6	3 or 1	64	64	
Encoder 2	5	64	128	128	
Encoder 3	4	128	128	256	
Encoder 4	3	256	256	512	
Encoder 5	3	512	256	512	512
Decoder 4	3	1024	128	256	256
Decoder 3	3	512	128	128	128
Decoder 2	5	256	128	64	64
Decoder 1	6	128	64	64	64
19
Published as a conference paper at ICLR 2022
(a) MNIST 1 ③ 16
(b) CIFAR-10 1 ③ 8	(c) FFHQ-256 4 ③ 8
Figure 6: MDAE training plots demonstrate that optimization is stable for all datasets. Loss values
on the y-axis in these plots represent the value of our objective function (Eq. 14).
Table 2: Main hyperparameters and computational resources used for training MDAE models.
	MNIST 1 ⑥ 16	CIFAR-10 1 ⑥ 8	FFHQ-256 4 ⑥ 8
Width factor	1	2	2
Learning rate	0.00002	0.00002	0.00002
Total batch size	128	256	16
GPUs	1×GTX Titan X	4×GTX Titan X	4×V100
Run Time	≈2.3 days (1000 epochs)	≈2 days (1000 epochs)	≈2.75 days (250 epochs)
Table 3: MUVB Encoder architecture for MNIST. Each row indicates a sequence of transforma-
tions in the first column, and the spatial resolution of the resulting output in the second column.
Block{N}×{D} denotes a sequence of D blocks, each consisting of four convolutional layers with a
skip connection using a “bottleneck" design: the layers have widths [N, 0.25 * N, 0.25 * N, N] and
kernel sizes [1, 3, 3, 1], except when the input resolution becomes smaller than 3, in which case all
the kernel sizes are 1.
Module	Output resolution
Input	28×28
Block128×2	28×28
AveragePool	14×14
Block256×2	14×14
AveragePool	7×7
Block512×2	7×7
AveragePool	4×4
Block1024×2	4×4
AveragePool	2×2
Block1024×2	2×2
AveragePool	1×1
Block1024×1	1×1
20
Published as a conference paper at ICLR 2022
F Langevin MCMC Laboratory
In this section, we give a light tutorial on Langevin MCMC used in the walk phase of WJS. Perhaps
the most interesting result enabled by multimeasurement generative models is that Langevin MCMC
in high dimensions becomes stable enough for us to examine and dissect the performance of various
Langevin MCMC variants in practice.
The reader might ask why we used underdamped Langevin MCMC versus its well-known overdamped
version. The reason is the recent theoretical developments discussed in Sec. 5 that show much faster
dimension dependence for the convergence (mixing time), O(VZd) vs. O(d), for underdamped
Langevin MCMC. To give an idea regarding the dimension, for the 4 0 8 model on FFHQ-256,
Md ≈ 106. Our trained model for 4 0 8 is used throughout this section. In addition, the MCMC is
initialized with the fixed random seed throughout this section.
F.1 Overdamped Langevin MCMC
We start with overdamped Langevin MCMC which is simpler and give us some intuitions on the
behavior of Langevin MCMC in general. The algorithm is based on the following stochastic iterations
(setting inverse mass u = 1):
δ2
yk+ι — Yk - —Vf (yk) + δ ∙ εk, where εk 〜N (0, I Md).	(42)
2	l{z}
l^Az^	(B
Comparing above with Eq. 7, it is intuitive to consider setting δ = O(σ). We start with δ = σ: in
this case Ak pulls noisy data to clean manifold (note the important extra factor of 1/2 however)
and Bk term corresponds to adding multimeasurement noise sampled from N(0, σ2IMd). The
overall effect is that one starts “walking” on the manifold of the M-density. And if that is the
case, the jumps computed by xb(yk) should give samples close to the manifold of the (clean) data
distribution—samples from p(x). We start with that experiment by setting δ = σ. Note that in
walk-jump sampling we sample the M-density in RMd generating highly noisy data for σ = 4; we
only show clean (jump) samples in Rd. This is shown next by skipping every 30 steps, i.e. ∆k = 30:
Our intuition was partly correct in that the sampler manages to “capture modes” but the step size is
clearly too high. Now consider δ = σ∕2 and ∆k = 100:
Continuing the chain, now shown for ∆k = 1000, we arrive at
Theoretically, to converge to the true distribution (associated with the M-density) the step size should
be small, where “small” is dictated by how “close” one wishes to be to the true distribution, e.g.
see (Cheng et al., 2018, Theorem 1). As we see above, even for δ = 2 the sampler does not converge
after 1000 steps, but a fixed δ = σ∕2 appears to be too high for this model. By continuing with the
chain with the step size δ = σ∕2 one starts to gradually move away from the manifold as shown next:
21
Published as a conference paper at ICLR 2022
F.2 Underdamped Langevin MCMC
In this section we focus on underdamped Langevin MCMC. The algorithms are based on discretizing
underdamped Langevin diffusion (Eq. 23). In this paper, we considered two such discretization
schemes, by Sachs et al. (2017) that we used in Algorithm 1, and the one due to Cheng et al. (2018)
that we implemented and used in Algorithm 2. The first algorithm is not analyzed but it is very easy
to show that in the limit γ → ∞ it will be reduced to the overdamped Langevin MCMC we just
discussed. Second algorithm is more complex in how friction γ and inverse mass u behave. For
comparison, we present results obtained by both algorithms, showing Algorithm 1 first. As in the
previous section, we start with δ = σ ; we set γ = 1 (u = 1 unless stated otherwise) with ∆k = 30:
As in the previous section δ = σ is too high for FFHQ-256, 4 0 8 model. (However, note the relative
stability of Algorithm 2, for this random seed.) Next, we consider δ = σ∕2,γ = 1, shown with
∆k = 100:
Note the remarkable contrast between the results above and the corresponding figure (for ∆k = 100)
in the previous section. We continue the chain with the same ∆k = 100:
Both algorithms start to diverge for this choice of parameters (δ = σ∕2, γ = 1). To add more stability
we can consider increasing the “mass” (lowering u). In (Cheng et al., 2018), u is replaced with 1∕L,
where L is the Lipschitz constant of the score function. By lowering u, we are telling the algorithm
that the score function is less smooth and MCMC uses more conservative updates. This can also be
seen in the equations in both algorithms, where the step size δ is multiplied by u in several places.
However, note this effect is more subtle than just simply scaling δ, especially so for Algorithm 2 as
can be seen by inspection. Next, we consider u = 1∕2. This will affect the mixing time and the chains
are now shown with ∆k = 1000 (instead of ∆k = 100 earlier):
This experiment concludes this section. We come back to more FFHQ-256 chains in Appendix I.
22
Published as a conference paper at ICLR 2022
G MNIST
G. 1 More is Different
There is a notion of congruence which arise in our analysis in Sec. 2.3 which we denote by “=”: two
different models, σ 0 M and σ0 0 M0 , “agree with each other” in terms of the plug-in estimator
σ 0 M = σ0 0 M0 if -‰ = σ=.
M	√M7
However these models are vastly different, one is in RMd, the other in RM0d. And if σ σ0 we
expect that σ 0 M model to have better properties as a generative model. This is clear in the regime
(σ0	1, M0 = 1). In that regime, almost no learning occurs: at test time MCMC either gets stuck
in a mode for a long time (the best case scenario) or simply breaks down. We refer to (Saremi &
Hyvarinen, 2019) for a geometric intuition on why large noise is essential in these models regarding
the walk-jump sampling. We should point out that this is a general phenomenon in all denoising
objectives (Alain & Bengio, 2014; Song & Ermon, 2020). In a nutshell, when noise is small the
Langevin sampler finds it difficult to navigate in high dimensions and the forces of the Brownian
motion eventually takes it to a part of space unknown to our model and MCMC breaks down (the
first experiment below). If we are “lucky” we can find the manifold initially (the second experiment
below) and MCMC may remain stable for a while but a model with σ > σ0 will have better mixing
properties. We should highlight that in the analysis of Cheng et al. (2018) the mixing time scales
as κ2 where κ is the condition number (see Sec. 1.4.1) proportional to the Lipschitz constant; this
quantifies the intuition that MCMC on smoother densities (smaller Lipschitz constant) mixes faster.
To validate these intuitions we consider comparing 1 0 16 and 1/4 0 1. In addition to statistically
identical plug-in estimators, these models also arrive at similar training losses with the same training
schedules (1.03 for 1 0 16 and 1.19 for 1/4 0 1). We start with 1/4 0 1. Below we show WJS using
Algorithm 2 with the setting (δ = 1/8, Y = 1∕2, U = 1) (the setting δ = σ∕2, Y = 1∕2,u = 1 is a
simple choice we used in testing all our σ 0 M models). Here, MCMC breaks down shortly after the
last step shown here (this chain is shown with ∆k = 30, in the remainder ∆k = 500):
---------- m⅛⅞≡ΛJUUu‹if-------------------- dɪw
Algorithm 1 is more stable here and we arrive at the following chain (total of 105 steps):
O OOG C
O O。工 I
Ui O G λα ɪ
y O q Fo
OoqSC
Oo 3 EaU
OoDc6o
Q。oδo
00G6 D
Go。50
ooo¾-s
0 0198 1
Oo。“3
ob 白4Q
0 0046
060 Cro
q-3 O Os
QG Qoo
qG。。。
〃 e qc>。
Oouoo
OOQ0D
OOQOO
Oouoo
O 06 O O
02 Oo
Ou d。。
O D≈oo O
O。力O O
70 9CO
5cb 3 0
PiOQ 5 0
E>0 ∖cp<9
Ool \。
Avouoo
OOJOO
Oo。OU
00。O \
¾ D C O (
Now, for 1 0 16 model, using Algorithm 2 with parameters (δ = 1/2, γ = 1/2, u = 1), we arrive at:
乙 O 0 OUooao
CKq q b，crooo
i v ? 1 ∙⅛ cι λ ʒ ⅛
5531 i6Q∖qq
Qo /b —1
W 5 Qll 7
Q∖P9∕%S
s9 ¥ 3 8
C/ Λπ Ul ¢- δ
5 4∖se¾
∖ U * S 8
q q bs6>
ZJIM ∩z Λ5 δ
+ q 43h
λ7 Cl or ¾ H
彳 q 9 3 q
3 q Γ*-6 q
Sq ^TZO Qv
/to al CT。b
K 3 q O Q
3 q4o。
5¼∙3 Q M
a 5 331a
3 Q?w Cr
yLΛo & K
5 u∖ Λv 6 OJ
8 Ui 5 ∖
3 q q¾g
q κp3 C
斗 ∖ q1>6
d夕q习4
Aπlr∖ 气
HH O Q∙⅛q
5 0 0 3'
And using Algorithm 1 with the same parameters (and initial seed) we arrive at:
5 Q Y lf ∖ ∖
7 nr「q
∖ ∖ ∖ 3›35
、马 § w 5 q
q ? S，0。
IQGQQL3"QQ Ifi V 3 3
⅛ ∖ ∖ ∖ ∖ ∖ I ) I I ∖ ∖ I
4qnu7yy37quqq
/eoeɔQ 2乙〃 ∕7∕0O
V O ∖ er O
G 2 I『O
g/、do
5λ√ ∖ Ao
3 4 ∖ n O
3^∖mq
∖ ∖ ∖ q q 夕 u u q n
OOOO。Ooq q tχ ∖
I ∖ ∖ ] 5 i ∖ ∖ ∖ ∖ ∖
qqgq∖∖Jib? Q
Oqqqqqqqq55
(Note the stark differences in terms of mixing between Algorithms 1 and 2 for this model.)
In summary, more is different: quantitative differences become qualitative ones (Anderson, 1972)
and this is highlighted here for “congruent" σ 0 M models that differ in terms of the noise level.
If computation is not an issue, one should always consider models with larger σ but this remains a
conjecture here in its limiting case (as σ and M grow unbounded, while σ∕√M remains “small”).
23
Published as a conference paper at ICLR 2022
G.2 INCREASING M: TIME COMPLEXITY, SAMPLE QUALITY, AND MIXING TIME TRADE-OFFS
Here we extend the ablation study in the previous section by studying σ 0 M models with a fixed
σ where we increase M. In the previous section we studied two models where xb(y) has the same
statistical properties as measured by the loss (and the plug-in estimator), and we validated the
hypothesis that MCMC sampling has better mixing properties for the smoother M-density (with
larger σ). Now, the question is what if we keep σ fixed and increase M?
As we motivated in Sec. 1, by increasing M the posterior p(x|y) concentrates on the mean xb(y),
thus increasing the sample quality in WJS. However there are trade-offs: (i) The first is the issue
of time complexity which is an open problem here. In our architecture, the M measurements are
passed through a convolutional layer and after that models with different M have approximately the
same time complexity. The problem is this may not be an ideal architecture. Presumably, one should
increase the network capacity when increasing M (for the same σ) but by how much we do not know
(this clearly depends on how complex pX is). Here we ignore this issue and we assume that our
architecture has enough capacity for the largest M = 16 considered. (ii) The second trade-off is as
we increase M, the price we pay for higher sample quality is that we will have longer mixing times,
both in terms of generating the first sample, and more importantly in the mixing between modes. This
trade-off is intuitive since p(y1, . . . , yM) becomes more complex for larger M (for fixed σ). Below
we compare WJS chains (as before, without warmup) for σ = 1 and M = 1, 2, 4, 16:
于8 422 S
26手24NZq
aGfg “N2 S
2G F&“ NN Q
aGFOyZZ Q
aQFeyzz 9
2GDO。9 22.<Γ
328。夕22 q
3V30∂。夕 ZZ Q
3L®。夕 22 Q
36sθ夕 22 Q
36 33 夕22 Q
3“722 α
多久0 &夕22 Q
57 份 g 9 22Q
57 qs72 2 q
5 7 q，7?ZQ
37QSv->zq
57QSσ>-xq
37JS7qxq
573s7raq
y7¾y7，N 4
5 7sy7L N 4
5 力3F7Lα4
5 73 牙7Lα4
5 13y7L 1 4
513y7rct4
313Fc-∕a4
513*qJsnsa
sq3yq 5 22
5gsF4*⅛πβ2
5 gS*qfbπs2
5旷5F大企m2
695V4蹲32
5t>5fgGq2
6 96f2。g2
5 9 51片4gz
SabgJqZN
6a6∕8422
SaGf8 qNZ
(3G(5(50660000000000
Q6,rdz5q
046,F2Γ35q
046(F635Cr
0464p335q
066<p635q
0∙6^635q
046 户$11Pq
046 手SIlPq
O∖S6F6c-⅛sc~
0VS6 尸或350~
0/6 Q身 σ-
0XS6 尸£134
0X36 尸zr<34
0∖36 FZ3 3。
0×36 1
0∖36<^/ 737
CC66z<∕37
Og6^z<> 3 β-
c46^z53's-
C4 6右/5?>吁
d√J6∕sfo1
2 6 6z5 ro q
& >o 6z5 a q
0££/5 3斗
0 6 Z ʃ ɔɔ
0 6 6，5 3 4
G 6 3/5 3 4
0 6 4，533
0 6 *,r3 3-3
O 6 ∙ d B
0 6 4 C 3 2
0，4<r^35
064FyM¾
0 6 4 Γ ʃ 3 ¾
06,f3Γ23
066γ∕33
066 FV> 3 a
06,∕,6 区3
066-ru*δ
Q66.rs35
。白万万万万万万万万万万万万万万万万万万万万?5多万存万万万万万万万
后万万万与弓9斤斤斤5555$于夕夕夕夕夕55$$ SSS号SSMf广5■f
夕夕夕夕，SSS55SS55S5SSS5SSSS55S，京//****2
宅宅宅宅宅RWWRWB宕宕qWWWRWR宝宝二宝宝WR宅飞宅WWW名名言WR
WR宕宕宕WW宕宕WW宕宕宕宕宕小君飞宕宕WWWWWR宕宕RRWRRWR名/若W
WRWWRWRW若宕宕R宕WWWSW宕 WWWWRR宕宕RR WSWS55555
55555556)55555t55SSB5555555555555555555555
5555555555555555555555555555555555555555
DIPbb
z>7)bb
z>∙oLb
D,btob
z>bcob
z>*t>co b
DiOCOb
ðtobb
D<07>b
z>jocob
Bjocob
Blocob
o,o<ob
3τ><ob
Knb
ð^^ob
Z50,bb
JQQbb
bz>,bb
bτj<3b
BQbb
U0 6b
2Jτ)<□b
5τ>0b
S∙D<□b
υ∙z>τib
SQtpb
5∙D<3 b
S0 0b
与DFb
4Dpb
S0tpb
fτ)<0b
巧Qpb
SDPb
WHb
号DQb
与DPb
芳 D0b
萼D0b
OODO
OODO
OODO
OoDo
OODO
Oooo
DDOO
DGDO
OODo
Oooo
DDDO
ODGo
Oooo
Oooo
DDDO
Oooo
Oooo
Oooo
Oooo
Oooo
OODO
Oooo
OoOO
Oo O0
OODO
OooO
ħ- O O O
O O O
GooO
b D O O
Kv O O O
Gooe
b O O O
hv nu -O O
⅛ b O O
GDCb
b O OD
Rv b O O
Kv nV O
b D G O
Figure 7: (mixing time vs. image quality trade-off) WJS chains for 1 0 M models are presented in
“real time” (∆k = 1) starting from noise (320 steps in total), for M = 1, 2, 4, 16 in order from top
pannel to the bottom one. We used Algorithm 2 (δ = 1/2, γ = 1/2, u = 1) with the same initial seed.
Note that, at the cost of sample quality, all classes are visited in 1 0 1 in the short chain presented.
24
Published as a conference paper at ICLR 2022
G.3 MUVB vs. MDAE
Below we make a one to one comparison between MUVB and MDAE for the 1 0 4 setting we trained
on MNIST. In both cases we ran a single chain for 1 million+ steps. For sampling M-density we used
the Langevin MCMC algorithm by Sachs et al. (2017) with parameters (δ = 1, γ = 1/4, u = 1) (see
Appendix D). This is an “aggressive” choice of parameters for Langevin MCMC, designed for fast
mixing, yet the chains do not break up to 1M+ steps (we stopped them due to computational reasons).
Below we show the two chains at discrete time resolution of 5 steps (the first sample, top left corner,
is obtained after only 5 steps). This comparison visually demonstrates that MUVB has better mixing
and MDAE better sample quality. All digit classes are visited in MUVB in a variety of styles in 4000
steps shown here. MDAE chain is cleaner but the classes {0, 1, 5, 6} are visited scarcely.
x3354u47qF22Nx3z5 0y3
*0 33 4 αq 廿 7q^a⅛aN3z6,√∙3
f334q4q7qoorlΛr<^326 O F3
/53 49qqr∖qΓ3a1N323 0fz3
,6349:TqOq,Γ⅛JxN325JL 3
8 3 3dg4u,q,rtaz432y□%3
&93&444 2q7riallJ32¥6>% q
&93■夕 4τ7σ-,πialJ32q。阜 9
才W3ft亍 4u 7 + F223Λ32 +C?Q3
2S3 3 夕 44 7yx21a<λ32 ð-ufe9
8¾3s 夕“ q 3o<l 324。67
*63S 4 4u7l<f13aa3z4o(p7
8B3594q7J321=a3zqoG,q
8B35 夕“，7∕3Λπif⅛ - 33 40υq
80035tK447I 6 2ɔ,3a3s4ou9
*3ms 夕 43-7 — 822122354 OQ Z.
3835 9 TH71E22Γix3sqobA-
3^349447 —才2 2pg3oτΓ6Q 5
3 6o335qH>∕32a2πs354∂-9 4
8 3345qq 7//22 3 G35qou4
S ʒs 6 S UlM Γ'∕32 3nη!533qcb Y
83 S Ssw 7/32。NΛ63q0b q
g∂rASSH4 7，ga。CCa d COqOQ 4
0o}33644'7∕9c¼2qJJΓ0qoQ 什
¢03336TN-7，+ 3aJ2∕3qoB W
83S36447/432 ;a/3qo6W
83¾38H4-7∕qp2 NaoSqbNy
OOoO⅜d6 Zr47∕q42 Γxa63aucpq
g*3J,Gq "7∕qc⅛2π51o3QO69
gco3JGq4-7∕qJ∖3αo5QG^夕
8G0 36^qql∕qszJa43qq6夕
gnvB36 qu r"/q^3，003q。。÷
OOam36 q q7/ q.πsd>2ao5q0*3g
8g¾3Gqγ-7∕q<⅛3∕ao3ςro49
Oo 8 S 3 G M Ur Γ∙d q 夕分「<<037。45
OOg33G4J-Γ-∕q√>aJao39Q6g
go¾33G4 3"l/HΛa7aD39e6r
9?033644『/。夕^41。39。£›r
£833644 1/。Paja23τoa L
gx336quA∕qpJB24 350。歹
Figure 8: MUVB, 1 0 4 model on MNIST, ∆k = 5 steps.
8337√449-7yp∕4 30o3 3'Oogg
83fc∖7^4%√7:SFf 43003 3 9gg
83374 4+ “ 7%∕ / 03g33y33
CO33∙79 44√7≠g / UOo33283
8337 9≠4 47≠Ntr吁 3D03390oΓ
e33734q√7 什？<Γ13g33pg ,
e∙33 7q44y7^^∕9}83m 夕 gΓ
8>337q4+√^*f-gs9*38339
3337q4q√7-÷8g<'-5g339pg
e>337q4q/7+8V 夕 3g33g 夕，
Θ337q44∕L⅛8Γ7qg33egF
S337q44/Z 1rco∕7qg33g∕Γ
S337q44∕z-qag73933gg*
s337q44^A-4κg7l>y33ggF
8>33 7q4u^z*-4aF 73>%93RgF
ε>3J 7 9 4 4- √- Γ*-qoo? 73R33>g0f
0337q44 4 4=rg073q3,bg∕s
853 7q44yf*-qgoo7BC*∙3¾g∕g
8>537q44/ 4q3g73 nr ʒ ʒ co ʃ σo
a53><J~44 / Γ*-4gg73rz3⅛8∕g
5532944≠c*-18r73qg2>8∕g
B33 夕 94½*918F7rr*7g,b8^g
CO 33 夕 <''4y^918r7π-*7s¾Jfc彳？
邑一33 夕 14 4,418iF7彳 783Jg 9
CO33夕 7m4∕41bF74 723Fr9
e>3 3 , 4√413eF74σgag<Γ9
6337 7K444 73p7q7g38zg
3, Ur 小√qc-3 夕7“ 7238,8
e>;377H + 4qr-cτ∖z∕θ-cxo03ggg
e>s3夕 7μ彳√∙c-73,Γ0∖v,g33ga
βs3夕 7q 1¥M，/¥夕 g3qwg
6S3夕7u+9∙1c''τlΓx√9 groqgg
363夕 7U4√C-C-孑不，“7 83q8夕
383 夕744tA5-C-?，夕"9 Doroxgg
583 夕7“4-4-q7 久 F0y283Xgg
583 夕 7√44q Γ-2F8q9g34g9
5003,7“ 4 qq Γ-apδoq9g3*g?
与CQ37Γ*44qq :V-IFFqg833gR
683 7 Γ-√44q Γ-3pgqr7 83BX Y
083κ>>7‹∕4qvr-gf4rqMPO33gg
Figure 9: MDAE, 1 0 4 model on MNIST, ∆k = 5 steps.
25
Published as a conference paper at ICLR 2022
G.4 Lifelong Markov Chain
We demonstrate the WJS chain with 1 million+ steps obtained in MDAE (10 4) in its entirety (viewed
left to right, top to bottom). We informally refer to these long chains that never break as lifelong
Markov chains. The chain is reported here in its “entirety” to demonstrate the fact that it does not get
stuck in a mode and remains stable through the end (we stopped it due to computational reasons).
AO02r"夕∕FO∕Ng g2r&bU夕^q5-夕于5Γ60s‰九 L乙 ¥7J2 X-Co /3£335a y/
S2372GN33Hg，/64 43y3 工 IP5^∕3390NFr⅝A*74s?&?N3qg2323。乙。s/qg
3,gz 2 g /9 Γ⅛0LF8∕2op∕48933Ays38 + 93z 5422 sg2-Og 9乙3¾x.∕P∕OJ,∂3AN3
ooz<^337∕40 SU8M8I978%∕∕2 VJ^52gs33“2。K ggg∕Λo3√产 A/N⅞c3 0∕j5q2 2N
7yzsN∕M4 2≠43r3<QMA7t2sz6n,6 004∕2g4 r55*Nr/^8r£78Ay53o3s/g> 久
3775Γw√riry3s¾√3∕∕oczoo QN 92 S3PO73Z53 夕69J2os3∕4gzM4∕,87 FZJPJ/
32 L<4o82ra07IDλ, A 0□C2 2S 歹75∕4s<ΛFsy4 7 zx，z¥002 1 + 5 乙√y9o23F7
3<p5z2,of3.l∩<√ogʃOM,,0 66*∙z-2^d93yN∙‰3^2Gy9^∕37F38004qrmy"rl354
18义？2，*』33。330344,7广^3久6;>广3>32匕22-2乙031S"/夕 qz78≤-<>yz003∖a3∕4Λ
Xknr-2r¾Fu∕3a,y33Λ33∕6A5zro -33g2-。/2-3」3∙⅛∕SN≠3r∕3oΓ001g¾y//O
7g6r4Jf 夕//Zgr 6oqe2 2r0Γv},o7A+g24Q(bz33M,NΛg3∕3g∕23∕f354g0
72sr32-∙RyΓ32Aqri 夕夕夕 g√JzJ,5∕∕s7 夕g^g40g232-l^4^rb3wz7 3H7^gb2?
Oobosg三子少 F = ∕357z4r3∕G57∕7q3p3<7x57Jd 乙7 7s∙7∕"3∕00003∖3Z7,67
36<fx3y∕gz7ΛSOQg4,Λ4>3SΓi 夕ɪ,F夕<Γy√<og,3^/WZg 工/Fz5ez38Λ2zugr4 乙 Ny
O38C4 7 SggPS 乙 3g 4431 3 9 JN ΓKA2VIW2-ONΓ03Z y/C<5,6，S5grz6γ*3≠∕s」//
3g∕ΛN 73 9Λ40o 〉 e3%;73332^8gaoo√2 o□3,gb∕0 /og∖D√x^N d £C)9g38^√
6O7GA7OfoM 夕 M2 rg3732^gτBrz92 8z^o>α/*4q∕2 4o975*VT-L crsΛqλo 2 尸 43彳。
g892*ΛO3∕2-7i-rrc∕ fJ‰Λss∕5gg^57^oyAkNΛOri/4g∕∖n34ag32x.487Γ∖3<p∕d
$1GaXO2OHΓ3 5 乙 丁。327？637 9 RZ333o∕? VJ2rofzsoo^33√2-X7AgFywLGSF4
s>』Λr3>yc gE7%9τ5∕NZ y832^3, SR3」30s∙OF7 75√Γ<-3F∙÷AX7 1g3d ‰ 3472 ‰
S 3 7//乙 Z 夕/ CbfS72 歹夕( 2 y 3H2gγz∕8ΓY2J右牙 08〃 IQO0∕3^6>∕N7o9gAOL5q62-z
35^53 7sl∙<r77LFgz∖sg2.干 S3 夕3斤彳 Sy4乙 ›b^A。7LS-M 夕 3gu√4 3 0Bg20r2-√s32-
IP0 7J~3Gr4 S 7ZLg0ΛgJ尸r5-3g3∂e<ΓHF52∕<z+货/工 3oqb03 8 5“久 Cogg 工x22yΛ79
s〃，$ SC 又 2s422^J4CΛ73y33∕M^z33∙‰"‰o SdS309oooocr'≤rA2o4*gd3z-2 ri ?又力
,0,，，。久2_53CX√42 4 33y孑 03Fvg√5Sd 3/0*432^35 乙 7 8 1 gs5^πx54 乙G785
rdg"3σBCI OgY "9 5夕3200¥夕3743 25-,U002夕545~夕4:009^¥^36〃48{\6>J2_/>12
3A¾3so3olb 夕÷ggΓ×N3,7EOc><*∙y3?夕 g6A ZF ,Fz7z521052-3<19a3a"γ"x8ψcn2
Lq7s392.-9c5√mo733∕s24∕Ir321ΛL5½0g7goz32^sggA94s9"?■〃 52y24G∂
6。7。302¥。GZ 3。400~ 342^0 2 卜22324之。Γg3eΓ'b*'≤3 夕 5fJ// SO 9 73733。CPr
so/4n44∖¾z./00/41 乙z3axo 72.DQga37226?MrO332Sf⅜4cxsg∕o34g33 9z.yΛ，ʃ
god√∕^0□BxJFC5gx83l>≡30β7 3PA,3(≤)Z>NO4∕S /xzr7r50OQ∕2oΛS，Fg3o 工 £3
/02-732。CZ 8/乙 blng5/32./3gy£Q3s% h〃〃J，oar?vl35*G43x0 7r\4s340N48
∕0d 2 9 Z。。Zg 乂 SFgog500√,，zsκ^7乙 S72 O45=,oaOo Aol4fo∙12 2 OOO∕,OJ2Z40 夕√
(oOJl-?^。。Z33夕，rozg厅4 斤 G Oqfo7r√sri 7Qz5323aΓ5‰qgNKO304s/Gb〃f0“
gor2-%«2o/N33，q?6?2 S4 J 5gz∕g 0L"¼3li(xA。Az33β?( O300X.I72 SX 厂工
s“£ J 夕 N52*γo∕23gg∕6 J 2 2 夕 39 夕l∕7√36l S3 / sx-+d)N2.23 乙 7e3J*x 32 2VI∕ZΓ
S，,Γ25xgN "√N∕7N gcNΓS2。000 夕 2Λ√g55 工 3vxgs74gq2J3lo2-FFr4-Nαgr√g
OOe，。夕JgT4o2Dylg 乙。g330 7<FO33F2SXrr夕J77sr⅛∖8q2r≤3z3AWT Λ 7 3∕gy
ʃɔ-，，F3FK3o2ou/xG0orn 广 3^3stod^*y325400SJ6y2∖3QF33^√s3UrΛAFy
5ZOOO 3-2,V6O2 乙；T322。工。7 3c,4a√3s4a∕o 夕叶72 6 0∕52xSerWSrl6S2 53N
Figure 10: MDAE, 1 0 4 model on MNIST, ∆k = 500 steps, 1 million+ steps in total.
26
Published as a conference paper at ICLR 2022
H CIFAR-10: single-chain FID evaluation & some failure modes
The main “fear” in parametrizing the score function directly in MSM, which MDAE is an instance of,
is we are not guaranteed to learn a conservative score function (see Sec. 4.1). More importantly, we do
not have a control over how the learned model is failing in that regard. These fears were realized in our
CIFAR experiments on the 10 8 model presented below. The main results use Algorithm 2. Algorithm
1 simply fails for the Langevin MCMC parameters we experimented with below (for completeness
we present a short chain at the bottom panel). In 2D toy experiments the non-conservative score
functions were quantified in (Saremi et al., 2018, Fig. 1h), but this quantification is difficult in high
dimensions. However, what is intriguing about the experiments here is that the “non-conservative
nature” of the score function is manifested—this is merely a conjecture—in the cyclic mode visits
apparent in the Markov chain.
∙.×!7∖∙⅛sx∖7+ .国，n
V/-FT 备 * ⅛ ,。0 J / :《X
诺rτwu.，电 <⅛' ’•骼Λ
年XXQ赤
Γhκ√
士?*
Q qy:/ Zw*
Figure 11: Top panels use Algorithm 2 at two different checkpoints. The bottom panel uses Algorithm
1. MCMC parameters are (δ = 0.1, γ = 2, u = 10) for the top and bottom panel, and u = 20 for the
middle panel. In all cases ∆k = 500 (≈ 2 × 105 steps). The FID scores are respectively 91 & 79.

27
Published as a conference paper at ICLR 2022
We encountered the same problem using spectral normalization (Miyato et al., 2018): the chain
below was obtained using Algorithm 2 with the setting (δ = 1/2, γ = 1/2, u = 1) where we got the
FID score of 99. We ran the chain for 1 M steps; the first 600 K steps are visualized below:
Figure 12: WJS chain for MDAE 1 0 8, trained with spectral normalization, ∆k = 500.
28
Published as a conference paper at ICLR 2022
We also experimented with training MDAE using SGD optimizer. Using Algorithm 1 with the setting
(δ = 0.7, γ = 1, u = 1) the MCMC chain was stable for 1 M steps where we stopped the chain. We
picked 50 K images at equal interval of ∆k = 20 from the chain resulting in an FID of 43.95:
Figure 13: The first 13 K steps of a WJS chain with 1M steps for MDAE 1 0 8 on CIFAR-10 with
∆k = 10. We obtained the FID score of 43.95 by selecting 50K samples skipping ∆k = 20 steps.

29
Published as a conference paper at ICLR 2022
We finish this section with a discussion on numerical comparisons on the sample quality between our
MDAE 1 0 8 model and other recent MCMC-based methods, summarized in Table 4:
•	The table excludes denoising diffusion models since the MCMC chain in such models are
“conditional” in the sense that sampling is via reversing a diffusion process based on a
sequence of conditional distributions which is learned during training (see the discussion in
Sec. 7). By comparison, in all the papers in the table below there is only one energy/score
function that is being learned.
•	The use of the term “long chain” below is based on the current status of the field, chains
of order 1,000 steps: the MCMC chains used for generation and reporting FID scores in
most prior works has been “short”, of order 50 to 100 steps by comparison which we have
indicated in a column in the table. The FID scores in those papers were obtained by 50K
short-run parallel chains.
•	Our work is unique in this literature in that for the first time we report competitive FID
scores obtained from a single MCMC chain. As we emphasized in Sec. 6 the quest for
generating very long “life long” chains with good sample quality and mixing properties, as
measured by the FID score (Heusel et al., 2017), is a scientific challenge and we believe
it is an ultimate test to demonstrate that one has found a good approximation to the true
energy/score function. We should point out that the only competitive paper here in obtaining
FID scores with long MCMC chains is by Nijkamp et al. (2022) where the “long chains”
have been limited to 2,000 steps and the FID obtained is much worse (78.12) than what we
obtained (43.95) with our 1 0 8 model from a single MCMC chain of 1,000,000 steps (see
Fig. 13).
Table 4: FID results for unconditional MCMC-based sample generation on CIFAR-10
	FID	long chain	single chain	MCMC steps
Xie et al. (2018)	35.25	X	X	N/A
Nijkamp et al. (2019)	23.02	X	X	100
Du & Mordatch (2019)	40.58	X	X	60
Zhao et al. (2020)	16.71	X	X	60
Xie et al. (2021)	36.20	X	X	50
Nijkamp et al. (2022)	78.12	✓	X	2,000
MDAE, 1 ⑥ 8 (our work)	43.95	✓	✓	1,000,000
I FFHQ-256
In this section, we provide several WJS chains for our MDAE 4 0 8 model on FFHQ-256 dataset. We
refer to Algorithm 1 by A1 and Algorithm 2 by A2, and MCMC parameters are listed as (δ, γ, u).
A1; (2, 1, 1); ∆k = 300
A2; (2, 1, 1); ∆k = 200
30
Published as a conference paper at ICLR 2022
A2; (1/10, 1, 10); ∆k = 500
A2; (4, 1/2, 1/4); ∆k = 150
A1; (2, 1/2, 1); ∆k = 100
A1; (2, 1/2, 1); ∆k = 20
31