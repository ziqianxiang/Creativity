Published as a conference paper at ICLR 2022
Frequency-aware SGD for Efficient Embed-
ding Learning with Provable B enefits
Yan Li *
ISyE, Georgia Tech
yli939@gatech.edu
Dhruv Choudhary
Meta
choudharydhruv@fb.com
Xiaohan Wei
Meta
ubimeteor@fb.com
Baichuan Yuan
Meta
bcyuan@fb.com
Bhargav Bhushanam
Meta
bbhushanam@fb.com
Tuo Zhao
ISyE, Georgia Tech
tourzhao@gatech.edu
Guanghui Lan
ISyE, Georgia Tech
george.lan@isye.gatech.edu
Ab stract
Embedding learning has found widespread applications in recommendation sys-
tems and natural language modeling, among other domains. To learn quality em-
beddings efficiently, adaptive learning rate algorithms have demonstrated supe-
rior empirical performance over SGD, largely accredited to their token-dependent
learning rate. However, the underlying mechanism for the efficiency of token-
dependent learning rate remains underexplored. We show that incorporating fre-
quency information of tokens in the embedding learning problems leads to prov-
ably efficient algorithms, and demonstrate that common adaptive algorithms im-
plicitly exploit the frequency information to a large extent. Specifically, we pro-
pose (Counter-based) Frequency-aware Stochastic Gradient Descent, which ap-
plies a frequency-dependent learning rate for each token, and exhibits provable
speed-up compared to SGD when the token distribution is imbalanced. Empir-
ically, we show the proposed algorithms are able to improve or match adaptive
algorithms on benchmark recommendation tasks and a large-scale industrial rec-
ommendation system, closing the performance gap between SGD and adaptive al-
gorithms, while using significantly lower memory. Our results are the first to show
token-dependent learning rate provably improves convergence for non-convex em-
bedding learning problems.
1	Introduction
Embedding learning describes a problem of learning dense real-valued vector representation for cat-
egorical data, often referred to as token (Pennington et al., 2014; Mikolov et al., 2013a;b). Good
quality embeddings can capture rich semantic information of tokens, and thus serve as the corner-
stone for downstream applications (Santos et al., 2020). Due to their significant impact on model
performance and large memory footprint (21.8% of total parameters for BERT (Devlin et al., 2018),
95% for industrial recommenders in Section 4), how to learn quality embedding vectors efficiently
forms an important problem in applications, including recommendation systems and natural lan-
guage processing.
Empirically, adaptive algorithms (Duchi et al., 2011; Kingma & Ba, 2014; Reddi et al., 2019) have
witnessed significant successes, yielding state of the art performance in both industrial-scale recom-
mendation systems and natural language model (Guo et al., 2017; Zhou et al., 2018b; Devlin et al.,
2018; Liu et al., 2019). Stochastic gradient descent (SGD), on the other hand, has struggled to keep
up, often yielding much slower convergence and low quality models (Liu et al., 2020; Zhang et al.,
2019) (see also Figure 2). The sharp contrast on the efficiency of adaptive algorithms and SGD is
particularly distinctive, as SGD is the typical choice of optimization algorithms in the other domains
of machine learning, such as vision/image related tasks (He et al., 2016; Goyal et al., 2017).
* Work done during an internship at Meta.
1
Published as a conference paper at ICLR 2022
The common belief behind the empirical edge of adaptive learning rate algorithms over SGD is
that the former ones exploit sparsity of high dimensional feature. Specifically, a feature in a typical
embedding learning problem comes in the form of one/multi-hot encoding of tokens (e.g. wordpiece
in NLP and user/item in recommendation systems), which leads to a sparse stochastic gradient that
has only non-zero values for tokens within the mini-batch. In addition, token distributions of real
world data are often highly imbalanced and satisfy the power-law property (Piantadosi, 2014; Celma,
2010; Clauset et al., 2009), and infrequent tokens are widely believed to be more informative to
model learning. Thus adaptive algorithms can pick up information from the infrequent tokens more
efficiently, as they can schedule a higher learning rate for the infrequent tokens (Duchi et al., 2011).
Despite the appealing intuition, there is a significant theory-practice gap on the empirical superiority
of adaptive learning rate algorithms over SGD, and no developed theories can explicitly justify the
previous intuition. Better dimensional dependence of adaptive algorithms has only been shown
in the convex setting (Duchi et al., 2011), which hardly generalizes to even the simplest practical
models in embedding learning problems (e.g., Factorization Machine, Rendle (2010)), whose loss
landscape is non-convex. For non-convex settings, most theoretical efforts have been devoted to
analyzing adaptive learning rate algorithms for general non-convex objectives, which yield subpar
convergence rate compared to standard SGD (Ward et al., 2018; Defossez et al., 2020; Chen et al.,
2018; Zhou et al., 2018a). In fact, the standard SGD has been recently shown to be minimax optimal
for non-convex problems (Drori & Shamir, 2020; Arjevani et al., 2019), and thus not improvable in
general. Moreover, since adaptive algorithms are only implicitly exploiting frequency information,
and if the intuition indeed holds true, one might naturally wonder whether we can instead develop
an adaptive learning rate schedule that explicitly depends on frequency information. Motivated by
our previous discussions, we raise and aim to address the following questions
Questions
Can we design a frequency-dependent adaptive learning rate schedule? Can we show prov-
able benefits over SGD?
Our contributions. We answer the previous question by showing that token frequency information
can be leveraged to design provably efficient algorithms for embedding learning. Specifically,
• We propose Frequency-aware Stochastic Gradient Descent (FA-SGD), a simple modification
to standard SGD, which applies a token-dependent learning rate that inversely proportional to
the frequency of the token. We also propose a variant, named Counter-based Frequency-aware
Stochastic Gradient Descent (CF-SGD), which is able to estimate frequency in an online fashion,
much similar to Adagrad (Duchi et al., 2011) and Adam (Kingma & Ba, 2014).
• Theoretically, we show that both FA-SGD and CF-SGD outperform standard SGD for embedding
learning problems. Specifically, they are able to significantly improve convergence for learning
infrequent tokens, while maintaining convergence speed for frequent tokens. To the best of our
knowledge, our proposed algorithms are the first to show provable speed-up over standard SGD for
non-convex embedding learning problems. This is in sharp contrast with other popular adaptive
learning rate algorithms, whose empirical performance can not be explained by existing theories.
• Empirically, we conduct extensive experiments on benchmark datasets and a large-scale industrial
recommendation system. We show that FA/CF-SGD is able to significantly improve over SGD,
and improves/matches popular adaptive learning rate algorithms. We also observe the second-
order moment maintained by Adagrad and Adam highly correlates with the frequency information,
demonstrating intimate connections between adaptive algorithms and the proposed FA/CF-SGD.
1.1 Related Literature
Adaptive algorithms for non-convex problems. There has been a fruitful line of research on an-
alyzing the convergence of adaptive learning rate algorithms in non-convex setting. These results
aim to match the convergence rate of standard SGD given by O(1∕√T) (Ghadimi & Lan, 2013),
however often with additional factor of log T (Ward et al., 2018; DefOSSez et al., 2020; Chen et al.,
2018; Reddi et al., 2018), or with worse dimension dependence (Zhou et al., 2018a) for smooth
problem (assumed by almost all prior works). Moreover, all existing works aim to analyze the con-
vergence for general non-convex problems, ignoring unique data features in embedding learning
problems, where adaptive algorithms are most successful. We explicitly take account into the spar-
2
Published as a conference paper at ICLR 2022
Algorithm 1 Frequency-aware Stochastic Gradient Descent
Input: Total iteration number T , token frequency {pk}k∈X, and learning rate schedule
{ηkt}k∈X,t∈[T] specified by (7).
Initialize: Θ0 ∈ RN×d, sample T 〜Unif([T]),
for t = 0, . . . τ do
(I)	SamPle (it,jt) 〜D, caicuiate gtt = Vθit'(θit,θjt； yit,jJ, gjt = vθj-t'(θit,θjt； yit,jt)
(2)	Update parameters
θitt+1 =θitt-ηittgitt, θit+1 = θit, ∀i∈U,i 6=it
end for
Output: Θτ
θjtt+1 =θjtt-ηjttgjtt, θjt+1=θjt, ∀j∈V,j 6=jt
sity of stochastic gradient, and token distribution imbalancedness into the design and analysis of our
proposed algorithms, which are the keys to better convergence properties.
Adaptive algorithms and SGD. To the best of our knowledge, the study on understanding why
adaptive learning rate algorithms outperform SGD is very limited. Zhang et al. (2019) argue that
BERT pretraining (Devlin et al., 2018) has heavy-tailed noise, implying unbounded variance and
possible non-convergence of SGD. Normalized gradient clipping method is proposed therein and
converges for a family of heavy-tailed noise distributions. Our results focus on a different direction
by showing that imbalanced token distribution is an important factor that can be leveraged to design
more efficient algorithms for embedding learning problems. Our result also does not rely on the
noise to be heavy-tailed for the convergence benefits of the proposed FA/CF-SGD to take effect.
Notations: For a Vector/matrix, We use ∣∣∙∣∣ to denotes its '2-norm/FrobeniUs norm. We use ∣∣∙k2 to
denote the spectral norm of a matrix.
2	Problem Setup
We consider an embedding learning problem Which aims to learn user and item embeddings through
their interactions. We denote U as the set of users, and V as the set of items, and let X = U ∪ V
denote the union, referred to as tokens throughout the rest of the paper. We assume |X | = N, i.e.,
the total number of user and item is N. For the ease of presentation, We alWays use letter i to index
user set U, letter j to index item set V , and letter k to index the union setX. The embedding learning
problem can be abstracted into the folloWing stochastic optimization problem:
min f(Θ) = E(i,j)〜D ['(仇电 yij)] = X D(i,j)'(θi,θj； yij).	(1)
Θ∈RN×d	i∈U,j∈V
Here (i, j) denotes the user-item pair sampled from the unknoWn interaction distribution D, θi,
θj ∈ Rd (the i,j-throW ofΘ) denotes their embedding Vectors respectiVely, and the loss `(θi, θj; yij)
denotes the prediction loss for their interaction yij ∈ {-1, +1} (e.g., logistic loss). We further let
pi= X D(i, j), ∀i∈ U; pj =XD(i,j), ∀j ∈V,	(2)
j∈V	i∈U
denote the marginal distribution oVer U and V .
Remark 2.1. Our analysis also alloWs treatment of additional netWork structure (With parame-
ters denoted by W) that takes nonlinear transformation of embedding Vectors, e.g.,f(Θ, W) =
E(i,j)〜D'(θi, θj, W； yij). We omit their explicit treatment for presentation simplicity. In addition,
although We mainly discuss in the context of recommendation, our analysis and results only relies
on sparsity of stochastic gradient and the imbalancedness of token distributions, Which alloW one to
extend our results to other embedding learning problems (e.g., language model pretraining).
The full algorithmic descriptions of our proposed Frequency-aWare Stochastic Gradient Descent
(FA-SGD) algorithm are presented in Algorithm 1. Note that randomly outputting a historical iter-
ate is commonly adopted in literature for shoWing conVergence of stochastic gradient descent type
algorithms for non-conVex problems (Ghadimi & Lan, 2013). In practice, We can simply use the last
iterate ΘT as the output solution. In addition, Section 3.3 presents CF-SGD (Algorithm 2), Which
does not need the token distribution as the input and can estimate it in an online fashion.
3
Published as a conference paper at ICLR 2022
At iteration t, FA-SGD samples (it,jt)〜D, and ob-
tain the sparse stochastic gradient gt defined in (3).
Note that only the it-th and jt -th row ofgt are non-zero.
One can readily verify that 旧@,九)〜D [gt] = ▽㊀f(Θt).
Going forward, We will denote Vfk as the k-th row of
gradient Vf (Θt), and g1t as the k-th row of stochastic
gradient gt . Note that we have
.	0>
Vθit 'Rt ,θjt ； "it,"
gt =	.
.
Vθjt '(一 ,θjt; yit,jt)>
0>
(3)
Ejt gitt |it = i = Vfit/pi, Eit gjtt |jt = j = Vfjt/pj.	(4)
We further denote δtk = Afk 一 gfk for all k ∈ X. Then by definition E [δtt |it = i] = 0 and
E δjt |jt = j = 0 for all i ∈ U, j ∈ V . We pose the following assumptions on the its variance.
Assumption 1 (Bounded conditional variance). We assume that the variance of δit is bounded. That
is, there exists {σk2}k∈X, such that
E [kδitk2 |it	= i] ≤	σ2,	E [kδjtk2	|jt	=	j]	≤	σ2,	VI ∈ U,j ∈ V.	(5)
Assumption 1 allows us to provide a finer characterization on the variance of stochastic gradient
compared to typical variance assumption in literature. To illustrate, recall that standard assumption
in the stochastic optimization literature assumes Var(gt) = E kVΘft 一 gtk2 ≤ σ2 for some uni-
versal constant σ > 0. Consider an extreme setting, where we have exact gradient for the sampled
user-item pair, i.e., gi = + Vfkt and gjt = + Vfjt, then we have σk = 0 for all k ∈ X. In
contrast, the variance of gt is still non-zero. In general setting, we can bound the variance as shown
in the following proposition. Note that the variance lower bound arises naturally form the extreme
sparsity of the stochastic gradient.
Proposition 2.1. Given Assumption 1, we have
X(1/Pk - 1) ∣∣Vfk∣∣2 ≤ Var(gt) ≤ X Pkσ2 + X(1/Pk - 1) ∣IVfk『.	(6)
k∈X	k∈X	k∈X
Assumption 2 (Smoothness of prediction loss). We assume `(u, v; y) is symmetric w.r.t. u and v for
any y ∈ { —1, +1}, and there exists L > 0 such that ∣∣ VUu'(∙, ∙; ∙)∣[ ≤ L, ∣∣ V"'(∙, ∙; ∙)∣∣2 ≤ L.
The assumption on the symmetry of ` is readily satisfied by almost all neural network architecture.
In essence, this assumption only requires that the parameterization of embedding vector is token
agnostic. On the other hand, the spectral upper bound on the Hessian matrix is a standard assumption
in optimization literature.
3 Theoretical Results
We first present the convergence results of FA-SGD and standard SGD for embedding learning
problem formulated in (1), and discuss the advantage that FA-SGD offers when the token distribution
{pk }k∈X is highly imbalanced. We further propose a variant, named CF-SGD, which can estimate
frequency information in an online fashion and still provably enjoys the benefits of FA-SGD.
3.1	Convergence of FA-SGD and standard SGD
Theorem 3.1	(FA-SGD). With Assumption 1 and 2, take learning rate policy to be
ηkk = min{1∕(4L),α∕ PTpk 卜
(7)
where T denotes the total number of iterations, and α
have
J(f(Θ0)-f*) /(LPι∈χpισ2)ie
E kVfkτk2
,√pk√P1∈X ∕iσ2(f(Θ0)-f*)L
+	√T
∀k ∈ X.
(8)
4
Published as a conference paper at ICLR 2022
Remark 3.1 (Connection with Stochastic Block Coordinate Descent). Our FA-SGD shares some
similarities with Stochastic Block Coordinate Descent (SBCD) (Nesterov, 2012; Dang & Lan, 2015;
Richtarik & Takac, 2014) applied to problem (1), in the sense that each iteration We sample certain
blocks of variables (θit , θjt in our case), and only update the sampled blocks by following its stochas-
tic gradient. Different from SBCD, the stochastic gradient of the block variable git in the FA-SGD
is biased, as shoWn in (4). Note that With unbiased stochastic gradient, SBCD method typically con-
verges sloWer than standard SGD by a factor that can be as large as number of blocks. As a concrete
example, When the token distribution is uniform, SBCD converges sloWer than standard SGD by a
factor of |X |, hence sloWer than FA-SGD by a factor of |X | from Corollary 3.1 developed later.
Recall that from Proposition 2.1, the variance of stochastic gradient is heavily influenced by the
population gradient ▽㊀f (Θ), and can be huge whenever the population gradient is, presumably
in the early phase of training. This relationship is also supported by empirical findings in Zhang
et al. (2019) (Figure 2a), where the authors show that for BERT pretraining, the noise distribution
in stochastic gradient gt is highly non-stationary, which has large variance in the beginning of the
training and smaller variance at the end of training. Since existing analysis of SGD in literature
assumes a constant variance bound for the stochastic gradient, our observation in Proposition 2.1
requires an alternative analysis of SGD for problem (1).
To obtain the convergence rate of standard SGD in the presence of iterate-dependent variance (6),
our key insight is to tailor the convergence analysis to the sparsity of the stochastic gradient for
problem (1). We show the convergence of standard SGD as the following.
Theorem 3.2	(Standard SGD). With Assumption 1 and 2, take learning rate policy to be ηkt
min{4L，√T}
, where T denotes the total number of iterations, and α
,/ f(θ0)-f* 燧 have
V L P1∈X p2σ2' We have
EkVfTk2 = O (L(f(θT)-f*) + √Pl∈Xp2σ√f(θ0)-f*)L) , ∀k ∈ X.	(9)
Note that both FA-SGD and standard SGD attain a rate of O(1/√T). Compared to existing rates of
standard SGD (Ghadimi & Lan, 2013), we do not require constant variance bound on stochastic gra-
dient, as we have discussed above. Compared to existing rates of adaptive learning rate algorithms
(Zhou et al., 2018a; Chen et al., 2018), both rates obtained here exhibits dimension-free property.
We emphasize here that due to the dimension-free nature of the bounds for both SGD and FA-SGD,
We do not claim the proposed FA-SGD has better dependence on dimension' Which is the main moti-
vation of adaptive algorithms (Duchi et al., 2011; Kingma & Ba, 2014; Reddi et al., 2019). Instead,
the major difference on the convergence of FA-SGD (8) and that of standard SGD (9) is that the for-
mer one is token-dependent. Specifically, for FA-SGD, each token k ∈ X has its own convergence
characterization, while all the tokens have the same convergence characterization in the standard
SGD. We first make a simple observation stating the equivalence of FA-SGD and standard SGD,
when the token distribution {pk }k∈X is uniform.
Corollary 3.1 (Uniform Distribution). Suppose the user distribution {pi}i∈U and item distribution
{pj }j∈V is the uniform distribution. Then FA-SGD and standard SGD is equivalent to each other'
in terms of both algorithmic execution and convergence rate.
3.2	When does FA-SGD outperform standard SGD?
We show FA-SGD shines when the token distribution {pk}k∈X, defined in (2), is highly imbalanced.
Before we present detailed discussions, we make an important remark that highly imbalanced token
distributions are ubiquitous in social systems, presented in the form poWer-laW. Examples of such
distributions include the degree of individuals in the social network (Muchnik et al., 2013); the
frequency of words in natural language (Zipf, 2016); citations for academic papers (Brzezinski,
2015); number of links on the internet (Albert et al., 1999). For more discussions on power-law
distributions in social and natural systems, we refer readers to Kumamoto & Kamihigashi (2018).
In Figure 1c, 1d we plot the user and item counting distribution of Movielens-1M dataset. One could
clearly see that the user and item distributions are highly imbalanced, with a small percentages of
users/items taking up the majority of rating records. We defer details on the skewness of token
distributions for Criteo dataset to Appendix C.
5
Published as a conference paper at ICLR 2022
(a) Exponential Tail
zɔɑðnbaɪ'ɪ'
O-
0	2000	4000	6000
User ID Rank
(C) User counts
ItemID Rank
(d) Item counts
Figure 1: Token distribution with an exponential and polynomial tail, and the user/item counting
distributions for Movielens-1M dataset.
To illustrate the comparative advantage of FA-SGD when the token distribution {pk }k∈X is highly
skewed. We consider two classes of distribution families with different tail properties, one with
exponential tail, and one with polynomial tail.
Corollary 3.2 (Exponential Tail). LetU = {in}|nU=|1, V = {jm}|mV=| 1, where in denote the user with
n-th largest frequency, and jm denote the item with the m-th largest frequency. Suppose
Pin (X exp(-τn), Pjm (X exp(-τm), ∀n ∈ [|U|], m ∈ [|V|]	(10)
for some τ > 0. Define UT as the set of users whose frequencies are within e-factor from the highest
frequency: UT = {in : n ≤ 1}, and VT similarly as VT = {jm : m ≤ 1}. We refer to UT as the
top users, and VT as the top items.
Then given |U |, |V | ≥ 1 ,the proposed FA-SGD, compared to standard SGD:
(1)	Obtains the same rate of convergence, for the top users UT and top items VT;
(2)	ElI▽/T Il CanconvergefaSterbyafactorof Ω {exp(τ(n — |UT|))} for in ∈ U \ UT ;
(3)	E Il Vfτ^ ∣∣2 can ConvergefaSter by afactor of Ω {exp (T(m — |VT|))} for jm ∈ V \ VT.
We remark that |U|, |V| ≥ 1 is a very mild condition, as it only requires that the most infrequent
user/item should have its frequency smaller than the most frequent user/item by at least a factor of
e. i.e., the non-top user/item set U \ UT, V \ VT is nonempty, This is readily satisfied by the token
distributions in recommendation systems and natural language modeling (Celma, 2010; Zipf, 2016),
where the lowest frequency is at least orders of magnitude smaller than the highest frequency. The
factor of e in defining UT, VT can also be readily replaced by any constant larger than 1.
From Corollary 3.2, we can see that FA-SGD improves significantly over standard SGD for user/item
distribution with exponential tail. Specifically, FA-SGD achieves the same convergence rate of top
users/items compared to SGD, meanwhile it significantly improves the convergence of the non-top
users/items. Moreover, the strength of such an improvement increases exponentially as we move
towards the tail users/items.
Corollary 3.3 (Polynomial Tail). Let U = {in}|nU=|1, V = {jm}|mV=| 1, where in denote the user with
n-th largest frequency, and jm denote the item with the m-th largest frequency. Suppose
Pin X n-ν, Pjm X m-ν, ∀n ∈ [|U |], m ∈ [|V |]	(11)
for some ν ≥ 2. Define UT as the set of users whose frequencies are within 2-factor from the highest
frequency: UT = {in : n-ν ≥ 1/16}, and VT similarly as VT = {jm : m-ν ≥ 1/16}. We refer to
UT as the top users, and VT as the top items.
Thengiven |U|, |V | ≥ 161 ",the FA-SGD, compared to standard SGD:
(1)	Obtains the same rate of convergence, for the top users UT and top items VT;
(2)	E Il Vfτι ∣∣2 can convergefaster by afactor of ω{ (∣un^) ∣ for each in ∈ U \ UT;
(3)	E ∣∣ ▽/TJ12 can converge faster by afactor of ω{ (Pm^) ∣ for each jm ∈ V \ VT.
We remark that polynomial tail (37) is also the prototypical example of the power law distribution
class for modeling social behaviors (Kumamoto & Kamihigashi, 2018). The constant 2 in the condi-
tion ν ≥ 2 can be replaced by any constant strictly larger than 1, with slight changes to the constant
factor in the statements of the corollary.
From Corollary 3.3, we can see that FA-SGD improves significantly over standard SGD for user/item
distribution with polynomial tail. Specifically, FA-SGD achieves the same convergence rate of top
6
Published as a conference paper at ICLR 2022
Algorithm 2 Counter-based Frequency-aware Stochastic Gradient Descent
Input: Total iteration number T .
Initialize: Θ0 ∈ RN×d, counter sample T 〜Unif({T∕2,...,T}).
for t = 0, . . . τ do
(I)	Sample (it,jt) 〜D, CalcUlate gtt = Vθit'(θit,θjt； yit,jt), gjt = vθjt'(θit,θjt; yit,jt)
(2)	Compute counter-based learning rate ηbit cti , ηbjt ctj specified by (12)
(3)	Update parameters
θitt+1=θitt-ηbittgitt, θit+1 = θit, ∀i∈U,i 6=it
θjtt+1 =θjtt-ηbjttgjtt, θjt+1=θjt, ∀j∈V,j 6=jt
(4)	Update counters
ctit+1 = citt	+ 1,	cit+1	=	cit,	∀i ∈ U, i 6= it
ctj+t 1 = ctjt	+ 1,	ctj+1	=	ctj,	∀j ∈ V,j 6=jt
end for
Output: Θτ
users/items compared to SGD, meanwhile it significantly improves the convergence of the non-top
users/items. Moreover, the strength of such an improvement increases in polynomial order as we
move towards the tail users/items.
3.3 Online Estimation of Frequency Information
In certain application scenarios, the token distribution {pk}k∈X can be unknown in advance of
learning. To apply FA-SGD, one needs to employ a preprocessing step in order to estimate the token
distribution to a high accuracy, and then run the algorithm with estimated token distribution. Such a
preprocessing step often requires additional human efforts and data. To remove such an undesirable
preprocessing step, below we present an online variant of FA-SGD, which uses the counter of tokens
collected during training to estimate the token distribution dynamically. We show that the proposed
Counter-based Frequency-aware Stochastic Gradient Descent (CF-SGD) is able to retain the benefits
of FA-SGD despite unknown token distribution.
Theorem 3.3 (CoUnter-basedFA-SGD). In addition to Assumption 1 and 2, suppose ∣∣Vf (∙)k ≤ G.
Take counter-based learning rate policy in Algorithm 2 to be
ηbkt (ctk) = min	1/(4L), 1/	T pbtk	,	pbtk	=	ctk/t,	∀k∈X,t∈	[T],	(12)
where T denotes the total number of iterations, α
f * + Pk∈χ Pkσ2∕L, we have
JMf/ (L P1∈X pισ2) and Mf = f(θ0) -
EkVfTk2 = O (LMf + √pk√Pl∈x唯LS)-f*) + √pk(P√Xpl，2)),Vk ∈ X. (13)
for T ≥ max {min,∈x pl,GTOg(Mpk1∕2L+α∕√pk1}.
We believe the assumption on gradient bound ∣∣Vf (∙)∣ ≤ G is not strictly necessary and can be re-
moved with more refined analysis. Nevertheless, the reqUirement on T only logarithmically depends
on the gradient bound G. In addition, we highlight that the convergence characterization in Theorem
3.3 is still token-dependent. Specifically, we can show that despite not knowing token distribution
beforehand, CF-SGD can gain the same advantages that FA-SGD enjoys over SGD.
Corollary 3.4 (Exponential Tail). Suppose we have the same set of conditions given in Corollary
3.2, and σ/, L (f (Θ0) - f *) ≤ 1. Define UT as the set of users whose frequencies are within e -
factor from the highest frequency: UT = {in : n ≤ 1}, and VT similarly as Vt = {jm : m ≤ 1}.
We refer to UT as the top users, and VT as the top items.
Then given |U |, ∣V | ≥ ɪ, the proposed CF-SGD, compared to standard SGD:
(1)	Obtains the same rate of convergence, for the top users UT and top items VT;
(2)	EhVfT Il can convergefaster by afactor of Ω {exp(τ(n — |UT|))} for in ∈ U \ UT ;
7
Published as a conference paper at ICLR 2022
(3)	E Il Vfj^ ∣∣2 Can converge faster by afactor of Ω {exp (T (m — |VT |))} for jm ∈ V \ Vt .
Corollary 3.5 (Polynomial Tail). Suppose we have the same set of conditions given in Corollary
3.3, and σ/d L (f (Θ0) - f *) ≤ 1. Define UT as the set of users whose frequencies are within
2-factor from the highest frequency: UT = {in : n-ν ≥ 1/16}, and VT similarly as VT = {jm :
m-ν ≥ 1/16}. We refer to UT as the top users, and VT as the top items.
Then given |U|, |V| ≥ 161/v, theFA-SGD, compared to Standard SGD:
(1)	Obtains the same rate of convergence, for the top users UT and top items VT;
(2)	E∣∣Vfτ∣∣2 can convergefaster by afactor of ω{ (∣un^) ∣ for each in ∈ U \ UT;
(3)	E∣∣VfjJ∣2 can converge faster by afactor of ω{ (Pm^) ∣ for each jm ∈ V \ VT.
The proofs of Corollary 3.4 and 3.5 follow similar lines as in the proofs of Corollary 3.2 and 3.3,
which we defer to Appendix D
4	Experiments
We conduct extensive experiments to verify the effectiveness of our proposed algorithms and our
developed theories, on both publicly available benchmark recommendation datasets, and a large-
scale industrial recommendation system. Additional experiments on learning Word2Vec embed-
dings (Mikolov et al., 2013a) are presented in Appendix B, demonstrating the general applicability
of the FA/CF-SGD. We list key elements of our experiment setup for benchmark datasets below.
•	Datasets: MovieLens-1M (GroupLens, 2003) and Criteo 1TB Click Logs dataset (Criteo, 2014).
•	Models: Factorization Machine (FM) (Rendle, 2010), and DeepFM (Guo et al., 2017).
•	Metric: Training loss (cross-entropy loss), and test AUC (Area Under the ROC Curve).
•	Baseline algorithms: SGD, Adam (Kingma & Ba, 2014), Adagrad (Duchi et al., 2011). Note that
Adam and Adagrad are widely popular in training recommendation systems and language models.
We also empirically verify that the token distributions for both Movielens-1M (Figure 1) and Criteo
(Appendix C) dataset are highly imbalanced, with most of the token distributions having a clear
polynomially or exponentially decaying tail.
Since CF-SGD does not require frequency information, which is a huge practical benefit compared
to FA-SGD, in our experiments we mainly evaluate our proposed CF-SGD against the baseline
algorithms. To ensure a fair comparison, for each dataset and model type, we carefully tune the
learning rate of each algorithm for best performance. We apply early stopping and stop training
whenever the validation AUC do not increase for 2 consecutive epochs, which is widely adopted in
practice (Takacs et al., 2009; Dacrema et al., 2021).
5000 10000 15000 20000	0	5000 10000 15000 20000	0	2500 5000 7500 10000	0	2500 5000 7500 IOOQO
Iteration	Iteration	Iteration	ItBration
(a) Training loss	(b) Validation AUC	(c) Training loss	(d) Validation AUC
Figure 2: Movielens-1M dataset with FM and DeepFM model. CF-SGD significantly outperforms
standard SGD, and is highly competitive against Adam, Adagrad.
Movielens-1M: We can observe from Figure 2 that for FM and DeepFM model: (1) SGD yields the
slowest convergence in training loss and AUC. (2) The proposed CF-SGD yields significantly faster
convergence than SGD for training loss. In addition, CF-SGD converges even faster than the adap-
tive learning algorithms in the early stage of training; (3) All the algorithms eventually reaches peak
AUC around 81.0%, while CF-SGD attains the peak AUC much faster than baseline algorithms.
These empirical observations help us confirm the effectiveness of the proposed CF-SGD algorithm.
We further make an empirical observation that draws a close connection between adaptive algorithms
and CF-SGD. We plot the second-order gradient moment maintained by Adagrad and Adam against
the estimated frequency maintained by CF-SGD. Surprisingly, the second-order gradient moment
quickly develops a close-to linear relationship with the frequency information accumulated by CF-
SGD (Figure 3a,3b) . This observation suggests that Adagrad and Adam are exploiting frequency
information implicitly to a large extent.
8
Published as a conference paper at ICLR 2022
Criteo: We observe qualitative behavior of CF-SGD similar to Movielens-1M dataset, as can be
seen in Figure 3c,3d, 4a,4b.
0∙0∙
FM
0.9
0.6
0	2500 5000 7500 10000 12500
Iteration
(a) Correlation
Q0∙aeIeJJ03
0.9
0.8
0.7
0.6
0.5
0.4
Adam
---Adagrad
0	1	2	3	4	5
Iteration	le5
(c) Training loss
0	1	2	3	4	5
Iteration	le5
(d) Validation AUC
2500 5000 7500 10000
Iteration
(b) Correlation
Figure 3: (a-b) Second-order gradient moment correlates linearly with
CF-SGD; (c-d) Comparisons on Criteo dataset with FM model.
frequency maintained by
LoSS
DeePFM
0	1	2	3	4	5^
Iteration	le5
(a) Training loss
DeePFM	.	Industrial Recommender Sys.
O 1	2	3	4	5^
Itsration	1
(b) Validation AUC
0.785
0.800
5 O
9 9
7 7
Kz 6闫君占
0.0	0.5	1.0	1.5	2.0	2.5
Iteration IelO
(c) Train NE Curve
Industrial Recommender Sys.
(d) Train NE Diff %
Figure 4: (a-b) Comparisons on Criteo dataset with DeepFM model; (c-d) Comparisons on a
industrial-scale recommendation dataset with an ultra-large recommender model.
Alg	NE	Diff%
Adagrad	078643	-0.0-
CF-SGD	078628	-0.02
Table 1: Eval NE Diff %
Industrial Recommendation System: We train an ultra-large
industrial recommendation model with the proposed CF-SGD.
The training data contains 10 days of user-item interaction
records, with 〜2.5 billion examples per day (25 billion exam-
ples in total). We use around 800 features, with 〜100 million
average number of tokens per feature. We compare CF-SGD with Adagrad, which has been carefully
tuned in production usage. For both algorithms, we use a batch size of 64k and do one-pass training.
Different from benchmark academic datasets, we use Normalized Entropy (NE) as the evaluating
metric (He et al., 2014) (smaller is better), which is the cross-entropy loss normalized by the entropy
of background click through rate. Note that due to numerous iterations of the production model,
any relative improvement 〜 0.02% is considered to be significant. In Figure 4c, 4d We compare
the training NE curve CF-SGD and Adagrad, we can see that CF-SGD shows faster convergence
than Adagrad (see NE difference % in Figure 4d). From Table 1 we can observe that CF-SGD also
improves over Adagrad during the serving phase.
Memory Efficiency: On top of the above empirical evidences showing that CF-SGD learns fast 一
faster than standard SGD, and comparable (if not better) to adaptive algorithms, we further highlight
that CF-SGD learns cheap. Specifically, adaptive algorithms require additional memory to store
history information for each parameter. For an embedding table of size N × d (N tokens, d being
embedding dimension), the memory needed is at least 3N × d for Adam (first/second-order gradient
moment), and 2N × d for Adagrad (second-order gradient moment). In sharp contrast, CF-SGD
only requires N additional memory, for storing the estimated frequency. Since the choice of typical
embedding dimension d exceeds 64 (Yin & Shen, 2018), adaptive algorithms require memory at least
twice the size of the embedding table, while CF-SGD requires negligible memory overhead. Note
the industrial recommendation model in our experiments has a size over multiple terabytes, with
above 95% of consumed by embedding tables. Doubling the memory footprint by using standard
Adam/Adagrad is infeasible in terms of both engineering and environmental concern.
5 Conclusion
We propose (Counter-based) Frequency-aware SGD for embedding learning problems, which adopts
frequency-dependent learning rate schedule for each token. We demonstrate provable benefits that
FA/CF-SGD enjoy over standard SGD for imbalanced token distributions, with extensive exper-
iments supporting our theoretical findings. Our empirical findings also suggest that adaptive al-
gorithms can implicitly exploit frequency information and hence share close connections with the
proposed algorithms, this connection might be helpful in the direct analysis of adaptive algorithms
for embedding learning problems, which we leave as a future direction.
9
Published as a conference paper at ICLR 2022
Acknowledgements
We deeply appreciate Aaron Defazio and Michael Rabbat for their valuable feedbacks and insightful
discussions. We are also grateful to Yuxi Hu for his help on production model experiments.
References
Reka Albert, HaWoong Jeong, and Albert-Laszlo Barabasi. Diameter of the world-wide web. nature,
401(6749):130-131,1999.
Yossi Arjevani, Yair Carmon, John C Duchi, Dylan J Foster, Nathan Srebro, and Blake Woodworth.
Lower bounds for non-convex stochastic optimization. arXiv preprint arXiv:1912.02365, 2019.
Michal Brzezinski. Power laws in citation distributions: evidence from scopus. Scientometrics, 103
(1):213-228, 2015.
(Oscar Celma. The long tail in recommender systems. In Music Recommendation and Discovery,
pp. 87-107. Springer, 2010.
Xiangyi Chen, Sijia Liu, Ruoyu Sun, and Mingyi Hong. On the convergence ofa class of adam-type
algorithms for non-convex optimization. arXiv preprint arXiv:1808.02941, 2018.
Aaron Clauset, Cosma Rohilla Shalizi, and Mark EJ Newman. Power-law distributions in empirical
data. SIAM review, 51(4):661-703, 2009.
Criteo. Criteo 1TB Click Logs dataset. https://ailab.criteo.com/ressources/, 2014.
Maurizio Ferrari Dacrema, Simone Boglio, Paolo Cremonesi, and Dietmar Jannach. A troubling
analysis of reproducibility and progress in recommender systems research. ACM Transactions on
Information Systems (TOIS), 39(2):1-49, 2021.
Cong D Dang and Guanghui Lan. Stochastic block mirror descent methods for nonsmooth and
stochastic optimization. SIAM Journal on Optimization, 25(2):856-881, 2015.
Alexandre Defossez, Leon Bottou, Francis Bach, and Nicolas Usunier. A simple convergence proof
of adam and adagrad. arXiv preprint arXiv:2003.02395, 2020.
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert: Pre-training of deep
bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805, 2018.
Yoel Drori and Ohad Shamir. The complexity of finding stationary points with stochastic gradient
descent. In International Conference on Machine Learning, pp. 2658-2667. PMLR, 2020.
John Duchi, Elad Hazan, and Yoram Singer. Adaptive subgradient methods for online learning and
stochastic optimization. Journal of machine learning research, 12(7), 2011.
Saeed Ghadimi and Guanghui Lan. Stochastic first-and zeroth-order methods for nonconvex stochas-
tic programming. SIAM Journal on Optimization, 23(4):2341-2368, 2013.
Priya Goyal, Piotr Dollar, Ross Girshick, Pieter Noordhuis, Lukasz Wesolowski, Aapo Kyrola, An-
drew Tulloch, Yangqing Jia, and Kaiming He. Accurate, large minibatch sgd: Training imagenet
in 1 hour. arXiv preprint arXiv:1706.02677, 2017.
GroupLens. Movielens-1M. https://grouplens.org/datasets/movielens/1m/,
2003.
Huifeng Guo, Ruiming Tang, Yunming Ye, Zhenguo Li, and Xiuqiang He. Deepfm: a factorization-
machine based neural network for ctr prediction. arXiv preprint arXiv:1703.04247, 2017.
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recog-
nition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pp.
770-778, 2016.
10
Published as a conference paper at ICLR 2022
Xinran He, Junfeng Pan, Ou Jin, Tianbing Xu, Bo Liu, Tao Xu, Yanxin Shi, Antoine Atallah, Ralf
Herbrich, Stuart Bowers, et al. Practical lessons from predicting clicks on ads at facebook. In
Proceedings of the Eighth International Workshop on Data Mining for Online Advertising, pp.
1-9, 2014.
Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint
arXiv:1412.6980, 2014.
Shin-Ichiro Kumamoto and Takashi Kamihigashi. Power laws in stochastic processes for social
phenomena: An introductory review. Frontiers in Physics, 6:20, 2018.
Liyuan Liu, Xiaodong Liu, Jianfeng Gao, Weizhu Chen, and Jiawei Han. Understanding the diffi-
culty of training transformers. arXiv preprint arXiv:2004.08249, 2020.
Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike
Lewis, Luke Zettlemoyer, and Veselin Stoyanov. Roberta: A robustly optimized bert pretraining
approach. arXiv preprint arXiv:1907.11692, 2019.
Stephen Merity, Caiming Xiong, James Bradbury, and Richard Socher. Pointer sentinel mixture
models. arXiv preprint arXiv:1609.07843, 2016.
Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. Efficient estimation of word represen-
tations in vector space. arXiv preprint arXiv:1301.3781, 2013a.
Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean. Distributed representa-
tions of words and phrases and their compositionality. In Advances in neural information pro-
cessing systems, pp. 3111-3119, 2013b.
LeV Muchnik, Sen Pei, Lucas C Parra, Saulo DS Reis, Jose S Andrade Jr, Shlomo Havlin, and
Hernan A Makse. Origins of power-law degree distribution in the heterogeneity of human activity
in social networks. Scientific reports, 3(1):1-8, 2013.
Yu Nesterov. Efficiency of coordinate descent methods on huge-scale optimization problems. SIAM
Journal on Optimization, 22(2):341-362, 2012.
Jeffrey Pennington, Richard Socher, and Christopher Manning. GloVe: Global vectors for word
representation. In Proceedings of the 2014 Conference on Empirical Methods in Natural Lan-
guage Processing (EMNLP), pp. 1532-1543, Doha, Qatar, October 2014. Association for Com-
putational Linguistics. doi: 10.3115/v1/D14-1162. URL https://aclanthology.org/
D14-1162.
Steven T Piantadosi. Zipf?s word frequency law in natural language: A critical review and future
directions. Psychonomic bulletin & review, 21(5):1112-1130, 2014.
S Reddi, Manzil Zaheer, Devendra Sachan, Satyen Kale, and Sanjiv Kumar. Adaptive methods for
nonconvex optimization. In Proceeding of 32nd Conference on Neural Information Processing
Systems (NIPS 2018), 2018.
Sashank J Reddi, Satyen Kale, and Sanjiv Kumar. On the convergence of adam and beyond. arXiv
preprint arXiv:1904.09237, 2019.
Steffen Rendle. Factorization machines. In 2010 IEEE International conference on data mining, pp.
995-1000. IEEE, 2010.
Peter Richtarik and Martin Takac. Iteration complexity of randomized block-coordinate descent
methods for minimizing a composite function. Mathematical Programming, 144(1):1-38, 2014.
Joaquim Santos, Bernardo Consoli, and Renata Vieira. Word embedding evaluation in downstream
tasks and semantic analogies. In Proceedings of the 12th Language Resources and Evaluation
Conference, pp. 4828-4834, Marseille, France, May 2020. European Language Resources Asso-
ciation. ISBN 979-10-95546-34-4. URL https://aclanthology.org/2020.lrec-1.
594.
11
Published as a conference paper at ICLR 2022
Gabor Takacs, Istvan Pilaszy, Bottyan Nemeth, and Domonkos Tikk. Scalable collaborative filtering
approaches for large recommender systems. The Journal ofMachine Learning Research, 10:623-
656, 2009.
Rachel Ward, Xiaoxia Wu, and Leon Bottou. Adagrad stepsizes: Sharp convergence over nonconvex
landscapes, from any initialization. arXiv preprint arXiv:1806.01811, 2, 2018.
Zi Yin and Yuanyuan Shen. On the dimensionality of word embedding. arXiv preprint
arXiv:1812.04224, 2018.
Jingzhao Zhang, Sai Praneeth Karimireddy, Andreas Veit, Seungyeon Kim, Sashank J Reddi, Sanjiv
Kumar, and Suvrit Sra. Why are adaptive methods good for attention models? arXiv preprint
arXiv:1912.03194, 2019.
Dongruo Zhou, Jinghui Chen, Yuan Cao, Yiqi Tang, Ziyan Yang, and Quanquan Gu. On
the convergence of adaptive gradient methods for nonconvex optimization. arXiv preprint
arXiv:1808.05671, 2018a.
Guorui Zhou, Xiaoqiang Zhu, Chenru Song, Ying Fan, Han Zhu, Xiao Ma, Yanghui Yan, Junqi Jin,
Han Li, and Kun Gai. Deep interest network for click-through rate prediction. In Proceedings of
the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, pp.
1059-1068, 2018b.
George Kingsley Zipf. Human behavior and the principle of least effort: An introduction to human
ecology. Ravenio Books, 2016.
12
Published as a conference paper at ICLR 2022
A Experiment Details
A. 1 Datasets and Preprocessing
•	Movielens-1M: Movielens-1M contains 1,000,209 anonymous ratings of approximately 3,900
movies made by 6,040 MovieLens users. Each ratings is an integer ranging from 1 to 5. We use
only user id and movie id to make prediction. We treat samples with rating less or equal to 3 as
negative examples, and samples with rating greater than 3 as positive examples.
•	Criteo: The dataset consists of a portion of Criteo’s traffic over a period of 7 days. Each sample
corresponds to an ad served by Criteo. The label is either 0 (indicating ad being clicked) or 1
(indicating ad being ignored). The dataset consists of 13 features (integer values) and 26 categor-
ical features. There is 45840617 total examples. For the integer valued features, we apply the log
transformation (log(x) whenever x > 2), and convert into categorical features, as suggested by
the winner of Criteo Competition 1.
For both Movielens-1M and Criteo dataset, we random split into training set, validation set and test
set, taking up 80%, 10%, and 10% of the total samples respectively.
Implementation: We build upon torchfm2, which contains implementation of various popular rec-
ommendation models.
A.2 Model Architecture
For all FM models, we use 64 as the embedding size. For all DeepFM models, we use 16 as the
embedding size, and use (16, 16) as the widths of the hidden layers.
A.3 Hyperparameters
For Movielens-IM dataset, the learning rate of different algorithms are list in Table 2.
Model Type	SGD	CF-SGD	Adagrad	Adam
-FM	Tel	Te0	-^e-2	^Te-3
DeePFM	1e-2	2e0	4e-2	2e-3
Table 2: Learning rates for Movielens-1M dataset.
For Criteo dataset, the Iearning rate of different algorithms arelist in Table 3.
Model Type	SGD	CF-SGD	Adagrad	Adam
^FM	Te-2	Te-1	Te-2	^Te-3
DeePFM	1e-2	1e-2	1e-2	1e-3
Table 3: Learning rates for Criteo dataset.
All the algorithms use 1024 as the batch size during training.
B Additional Experiments on Word2Vec Embedding Learning
We demonstrate the effectiveness of the proposed FA/CF-SGD for embedding learning problems in
natural language modeling. Specifically, we conduct experiments for learning Word2Vec embed-
dings proposed in Mikolov et al. (2013a). Two learning models are considered:
(1)	Continuous Bag-of-Words (CBOW): CBOW aims to predict each word (which we refer to as
the center word), given its neighboring words. The training task is defined by taking each word
in the corpus as the center word, and minimize the total prediction loss.
(2)	Skip-Gram: Skip-Gram aims to predict each context word, given a center word. The training
task is defined by taking each word in the corpus as the center word, and minimize the total
prediction loss.
Dataset and Preprocessing. We use WikiText-2 dataset (Merity et al., 2016), which contains 36k
text lines and 2M tokens in the training dataset. We remove extremely rare tokens with less than
1https://www.kaggle.com/c/criteo-display-ad-challenge/discussion/10555
2https://github.com/rixwew/pytorch-fm
13
Published as a conference paper at ICLR 2022
50 occurrences in the training dataset. Note that removing extremely rare tokens was also proposed
in the original Word2Vec paper Mikolov et al. (2013a), where only the top 1 million most frequent
tokens are selected.
Experiment details and results. We choose the embedding dimension to be 300 as suggested value
in Mikolov et al. (2013a). Note that for each word w, Word2Vec represents itby a pair of embedding
vectors (uw , vw ), which we refer to as the center embedding and context embedding, respectively.
Specifically, uw is used when w serves as the center word, and vw is used when w serves as the
context word. This makes the proposed FA/CF-SGD perfectly applicable for learning Word2Vec
embeddings, by simply setting U as the set of center embedding vectors, and V as the set of context
embedding vectors.
We compare CF-SGD with standard SGD, and Adam. Following the suggestion from Mikolov et al.
(2013a), we deCrease the learning rate linearly as epoCh inCreases. We use an initial stepsize of 1.0
for both CF-SGD and SGD, and the stepsize of 0.025 for Adam. We iterate over the training dataset
for 20 epoChs, with a batCh size of 96. Note the original Word2VeC was trained with only 3 epoChs,
albeit on a much larger corpus. The results are reported in Figure 5.
WWOJrafl3εH
Figure 5: Comparison between CF-SGD, SGD, and Adam for learning Word2Vec embeddings on
WikiText-2 dataset.
One can clearly see that for both CBOW and Skip-Gram models, CF-SGD is able to significantly
improve over standard SGD. For Skip-Gram model, we observe that CF-SGD even yields compa-
rable performance to Adam. For CBOW model, CF-SGD is able fill in the huge performance gap
between Adam and SGD, and yields similar testing performance compared to Adam. Note that we
do not extensively tune the initial stepsize of CF-SGD, and the linearly-decaying stepsize annealing
rule was proposed in Mikolov et al. (2013a) for speeding-up SGD, which we believe might not the
optimal choice for CF-SGD. We believe further improvements can be made by searching for the best
initial learning rate and proper stepsize annealing rule for CF-SGD.
8 7 6 5
SSoq BULULejl
SGD
---Adam
---CF-SGD
0	2000	4000	6000
Iteration
(C) Training loss
8
7-
6-
5-
O 5 IO 15
Epoch
(d) Testing loss
14
Published as a conference paper at ICLR 2022
C Real World Token Distributions
We plot token distributions for the first 28 features (after preprocessing) of the benchmark recom-
mendation dataset Criteo. Note that the semantic information of features for the Criteo dataset is
xou∙,nM⅞l u∂j,Ql
0.0
0	10	20	30	40	50
TokenRank
(a)	Feature 0
80
0 00 0	20	40	60
Token Rank
(m) Feature 12
Toten Raak
(q) Feature 18
1000 2000 3000 4000 5000
Token Rank
(u) Feature 23
xou,,nbalH US3pi-
0.00
xou,,nbalH US3pi-
xou,,nbalH u∂3{oi-
0	20	40	60	80	100
Token Rank
(b)	Feature 1
10	20	30
Token Rank
(d) Feature 3
0.00
XOuenb⅛⅞ι u∞pi-
0.0
0∙0∙0∙0∙
XOUanbdJH ua}IO
0	25	50	75	100
Token Rank
(f)	Feature 5
0	2	4	6
ToIæn Rank
(j) Feature 9
500	1000	1500
Token Rank
(n) Feature 13
o.oooj->
2500 5000 7500 10000 12500
Token Rank
(r) Feature 19
0.00
uaoii
0.0
xou,,nbalH u∂3{oi-
0	20	40	60
Token Rank
(g)	Feature 6
80
20	40	60
Token Rank
(h)	Feature 7
0	10	20	30
ToIæn Rank
(k)	Feature 10
0.12-
0.10-
0.08
0.06
0.02-
0.00 .
0	200	400
Token Rank
(o) Feature 14
0.6
m°∙5
10.4
£0-3-
i°∙2-
o.ι-
o.o-
0	10	20	30	40
Token Rank
(l)	Feature 11
u∞pi-
0	100	200	300
Token Rank
(p) Feature 17
0	200	400	600
ToIæn Rank
(s) Feature 20
0	12
Token Rank
(t) Feature 21
0.030
025
富 0.020∙
I 0.015
■I o.oιo
0.005
0.000 -
I 1000	2000
TokenRank
(v) Feature 25
3000
.0075
0	5	10	15	20	25
ToIæn Rank
(W) Feature 26
0.0150-
0.0050
0.0025
0.0000
^.0.0125-
g 0.0100
2500 5000 75。。10000
Token Rank
(x) Feature 27

XaUenbaIH US3pi-
2 0 8 6
8

15
Published as a conference paper at ICLR 2022
D	Analysis
Throughout our analysis, we use ξt = (it, jt) to denote the random user/item ids sampled from the
unknown distribution D. We use ξ[t] = {ξs }ts-=10 to denote the random samples collected up to the
beginning of the t-th iteration, and use ξ and ξ[T] interchangeably when the context is clear. Finally,
we use Ft = σ(ξ[t]) to denote the σ-algebra generated by the random variables ξ[t].
Proofof Proposition 2.1. Let VfU ∈ R|Ul×d denote the submatrix that contains gradient of users
embeddings, and VfV ∈ R|Vl×d for the gradient of item embeddings. Similarly, let gU ∈
RIU l×d, gV ∈ RlVl×d denote the stochastic gradient of user and item embeddings, respectively.
Eit,jJgU-VfU『=Eit EjtIiJVft-git∣∣2 + X	IlVfiII2
i6=it,i∈U
=EiJ(I-J)2llVftIl2+EjtIitINII2 + X IlVfitIl2
pit	i6=it ,i∈U
=X PiEjt Iit=i llδitll2 + X Pi(i -92 Il VfiII2 + X PiX Il Vfit0 Il2
i∈U	i∈U	pi	i∈U i0 6=i
=X PiEjt∣it=i IIδitII2 + X Pi(I-小2 Il VfilI2+ X(I- Pi)IIVfitII2.
i∈U	i∈U	Pi	i∈U
Similarly, we can show
Eit,jt IIgV	- VfVII2	= XPjEit∣jt=j llδjtll2	+ XPj(I- J)2	IIVf；II2 + X(1	-Pj)	IlVfjtIl2.
j∈V	j∈V	Pj	j∈V
Note that kgt 一 Vft『=∣∣gU - VfU ∣∣2 + kgV 一 VfV ∣∣2, from which We conclude the proof. □
Proposition D.1. Given Assumption 2, let δi , δj ∈ Rd, and Θ0 satisfy θi0 = θi + δi , δj0 = θj + δj,
we have
f (Θ0) ≤ f(Θ) + hVθif,δii + <Vθjf, j + L kδik2 + L kδjk2,
where Lk = 2L°k for all k ∈ X.
Proof. Apply second-order Taylor expansion, we have
f(Θ0) = f(Θ) + hVθif, δii + <Vθjf, j + 2(δ>,δ>) (Jey F) (δi, δj)
where
方=V2iθif (Θ) = X D(i,j)VUu'(θi,θj; yij),
j∈V
E = V2i θjf(θ) = D(i,j )Vuv '(θi,θj; yij-),
F = V2j θj f (θ) = X D(i,j )VVv '(θi,θj∙; yij) = X D(i,j)VUu'(e,θj; yij),
i∈U	i∈U
for some θ as convex combination of θ and θ0, and the last equality uses the fact that `(u; v) is
symmetric w.r.t U and v. NOWgiventheaSSUmPtiOnthat ∣∣VUu'(∙, ∙; ∙) / ≤l,∣∣vUv'(∙, ∙； ∙)∣2 ≤ L,
16
Published as a conference paper at ICLR 2022
we have
f (Θ0) = f (Θ) + (Vθif, δi i + <Vθjf, j + δ> He δi + δ> Fδj + 2δ> Eeδj
≤ f(Θ) + hVθif,δii + <Vθjf,δj> + 2 (X D(i,j0) kδik2 + X Dmj) kδjk2
j0∈V	u0∈U
+ D(i, j) kδik2 + D(i, j) kδjk2
=f(Θ)+hVθif,δii+Vθjf,δj+ XLD(i,j0)kδik2+ XLD(i0,j)kδjk2
j0∈V	u0∈U
=f(θ)+hv%f,δi i+<Vθjf,j+L kδik2+L kδj k2,
where in the first inequality We use δ>Eδj ≤ L |闷||阳| ≤ LL(∣∣δ∕∣2 + ∣∣δj∣∣2), and in the last
equality we use the definition that Lk = 2Lpk for all k ∈ X.
□
Before we specify the concrete learning rate, we have the following generic convergence character-
ization.
Proposition D.2. Given learning rate {ηkt }k∈X,t∈[T], we have the following holds for Algorithm 1.
EX X (ηk - L^) Wfkll2 ≤ f(θ0) - f + 2X XPk Lk (ηt )2σ2.
=0 k∈X	pk	=0 k∈X
Proof. From Proposition D.1, we have
f(Θt+1) ≤f(Θt)+Vfitt,θitt+1
—
屹〉+ 0—) + L llθt+1 - θtt ll2 + j llθj+1 - θjt ll2
f (θt)-	ntt	(Vfitt,gtt〉-脸(Vfjt,gjt〉+	^2it * Ugtt/ + j n2t	llgjt『	(14)
Conditioned on past history F, we have
Eitjt [nit(f")] = Eit Ejtiit W,〈 Vfitt,gt)] = E
i∈U
Pft l≡f
Pini
pi
XnitllVfitll2. (15)
i∈U
Similarly, we have
(16)
On the other hand, we have
2
EitjJLit (ηtj2∣∣gttl∣2]
E	Lit (ntt )2	-1 Vfitt	+ δt1
pi
≤ 2跖Ejt∣it	Lit (ηit )2
ll Vfitt ll2
+llδittll2
≤ 2EitLit (ηtt )2
ll Vfitt ll2
2∑ PiLi(ηt)2
i∈U
P2t
∣Vfitk2
P2
+ σi2t
+ σi2
(17)
t
t
17
Published as a conference paper at ICLR 2022
where the first inequality uses ka + bk2 ≤ 2 kak2 + 2 kbk2 , the second inequality uses (5), and the
final equality uses the definition of Li in Proposition D.1. Following similar arguments, We also
have
Eit,jt hLit,jt(ηjt)2∣成，≤ 2XPjLj(ηj)2 (ɪf L + σ2).	(18)
Plug in (15) (16) (17) (18) back into (14), we obtain
Eitjt f (θt+1)IFt] ≤ f (θt) - X (ηt - L^) IlVftI∣2 - X (ηj- Lj) ∣∣Vft∣∣2
i∈U	pi	j∈V	pj
+ 2 (XPiLimt)2σi2 + XPjLj(ηj)2σ2 J
i∈U	j∈U
=f(θt)- XQk- L(η)) IlVfkII2 + 2 XPkLk(ηk)2σ2.
k∈X	Pk	k∈X
Equivalently, we have
X (ηk - L^) IIVfkII2 ≤ f(Θt) - Eitjt [f(Θt+1)∣Ft] +2 X PkLk(ηk)2σ2.	(19)
k∈X	Pk	k∈X
Sum up (19) from t = 0 to T and take total expectation, we have
EX X (ηk - Lk≡1) IIVfkII2 ≤ f(θ0) - f* + 2X XPk Lk (ηk )2σ2.
t=0 k∈X	Pk	t=0 k∈X
□
Proof of Theorem 3.1. Given Proposition D.2, suppose we use constant stepsize, i.e., ηkt = ηk for
all t ∈ [T], and sample T 〜Unif([T]), then for any k ∈ X,
EX (ηk-『)IIVfkII2 ≤ f(Θ0) - f* + 2X XPk Lk(ηk )2σ2,
t=0	Pk	t=0 k∈X
which implies that for any k ∈ X ,
E kVfkτ k2 ≤
f (Θ0); f *	+2 Pι∈χ PlLl (ηi )2σ2
T (ηk - Lpk)2)	TnkTlkFr
For a given α > 0, we choose {ηkt } as the following
min { 41L, √⅛ },
Combined with Proposition D.1, we have nk - Lkpj) = nk - 2L(nk)2 ≥ η2k, and hence
E kVfkτ k2 ≤
2 (f(Θ0)- f*) J 4Pι∈χPlLι(nι)2σ2
Tnk	nk
We can bound the first term by
O
T
18
Published as a conference paper at ICLR 2022
In addition, since
XPiLισ2(ηO2 ≤ Xp2Lσ2六=LPl∈χpισ202
l∈X	l∈X	pl
thus we can bound the second term by
PlEXpιLι(ηι)2σ2 ≤ L PlEX pισ2α2 max QL √PkT 1
ηk T T	I , α ∫
=O J L2a2 PlEX plσ2	L√pkPlEX plσ20
=[ T	+	√T
Thus we have
EkVfT k2 = O {LfθT二fI
La PlEX Plσl , L√pk PlEX Plσ2α
+	T	+	√T
(20)
By choosing α
J f∈f2 ,wehave
√pk f(Θ0) - f*)	L√Pk PlEX Plσ2a	J √pk IPlEX plσl2(f(θ/- f*)L
α√τ	+	√T	= ɪ	√T
L202 PlEX Plσl2 = L (f (Θ0) - f *)
(21)
(22)
Thus combining (20) (21) (22), we have
EkVfkτk2=O
√Pk√PlEXPlσ2(f (Θ0) - f *)L
+	√T
∀k ∈ X.
T
□
Proof of Theorem 3.2. Given Proposition D.2, suppose we use token-agnostic constant stepsize, i.e.,
ηk = η for all t ∈ [T], k ∈ X, and sample T 〜Unif([T]), then for any k ∈ X,
E X (η -守)WfkU2≤ f(θ0)-f *+2 X XPk Lk (η)2σ2,
t=0	Pk	t=0 kEX
which implies that for any k ∈ X ,
E kVfkτ k2 ≤
f (Θ0): f *	PlEX PlLlg))σl
TFIkFJ	(η -之)
For a given α > 0, we choose {ηt } as the following
Combined with Proposition D.1, We have η 一 Lkpn) = η 一 2L(η)2 ≥ 2, and hence
E kVfkτ k2 ≤
2 (f(Θ0)- f *) + 4PlEXPlLl(ηl)2σ2
Tη +
η
19
Published as a conference paper at ICLR 2022
We can bound the first term by
In addition, since
XPιLισ2(ηO2 ≤ Xp2Lσ2 J = L 0严。2
l∈X	l∈X
thus we can bound the second term by
η
Pι∈x p2 Llml)2。2
La pl∈x p2σ2 + L pl∈xp2σ2α
T	+	√T
Thus we have
EkVfT k2
∕L(f(Θ0)-f *)	(f (Θ0)- f *)	La Pl∈χ p2σ2	L Pl∈χ p2σl2a ɪ
ɪ T +	a√T	+	T	+	√T	∫.
(23)
By choosing a
√L∑θ°f2 ,wehave
(f(Θ0)-f *) + L Pl∈χ p2σl2a = O/ JPl∈x PMXf (®O)- I)L
a√T	√T	ɪ	√T
La Pl∈χ p2σ2 = L (f(Θ0)- f *)
(24)
(25)
Thus combining (23) (24) (25), we have
E kVfkτk2
,Pl∈χP2σ2(f (Θ0)- f*)L
+	√T
∀k ∈ X.
O
T
□
ProofofTheorem 3.3. We define b = P：=。1 {it = i} /t, Pj = P：=。1 {jt = j} /t, and b =
min 2L, √⅛= for all t ∈ [T],i ∈ U,j ∈ V, k ∈ X. In addition, We define the frequency-
dependent learning rates ηk = min {2L, √!ɑ- }.
Note that (19) still holds. Sum up (19) from t = 0 to T and take total expectation, we have
Eξ X X (b - Lk(bk)-) Il Vfkll2 ≤ f(Θ0)- f * + 2Eξ X X PkLk(bk)2σ2.
t=。 k∈X	pk	t=。 k∈X
(26)
In contrast to FA-SGD and standard SGD, here the stepsize ηbkt ∈ Ft is also a random variable. We
first proceed to upper bound the right hand side of (26).
20
Published as a conference paper at ICLR 2022
For each k ∈ X, denote Tk = F, where c > 0 is any absolute constant. Note that We have for any
pk
t ≥ Tk,
P (|pk - Pk | ≥ P) ≤ P (lp⅛ - Pk | ≥ Pk) ≤ eχp (-Pk (tp- Pk)) ≤ eχp(-tPk).	(27)
Moreover, we have
IPk - Pk | ≤ P ⇒ lbk - ηk | ≤ αoηk,	(28)
where a° = max {1 - ‘2/3, √2 - 1} < 1. Note that for any T > Tk,
TTk	T
XPkLkσ2Eξ [(bk)2] = XPkLkσ2Eξ [(殖)2] + X PkLkσ[Eξ [(殖)2],
t=0	t=0	t=Tk +1
To bound the first term, note that from definition of ηk, we have ηk ≤ L, hence
Tk	_	Tk	_
XPkLkσ2Eξ [(b)2] ≤ XPkLkσk
t=0	t=0
(L ) = Tk PkLk σ2
(Li)= CLk σ2
To bound the second term, note that from (27), for anyt≥ Tk with probability at least 1 - δkt (here
δk = exp(-tPk)), we have that ∣ηk - Qtk | ≤ α0ηk. Denote Hk = {ω : ∣ηk - ηjk | ≤ α0ηk}, we have
Eξ (bk )2= Eξ (b )2 IHk + Eξ (b )21(HD
≤(i+αo )2(ηk )2Eξ Hk+ +
≤ (1 + α0)2(ηkt )2 + δkt
Hence for any t ≥ Tk ,
T	T	T	2
X PkLkσ2Eξ [(bk)2] ≤ X(1 + ɑo)2PkLkσk(nk)2 + X δkPkLkσk (L)
t=Tk +1	t=0	t=Tk +1
Thus we obtain
工「」「…C = "1 '2
EPkLkσ2Eξ [(b)2] ≤ cLkθ2 (L) +
t=0	L
£(1 + αo)2Pk Lk σk (nk)2 + E δk PkLk σ2
≤ cLkσk (L) +
≤ CLkOk (L) +
t=0
T
X(I+ αo)2Pk Lk σk (nk )2 +
t=0
T
t=Tk+1
exp(-c)Pk	2
1 - exp(-Pk)LkOk
L )2
^X(I + α0)2PkLkσ2 (ηk )2 + α1 exp(-C)LkOik
t=0
L )2
k
T
T
L
where the last inequality uses the fact that PT=Tk+ι δk ≤ PZTk δk = ⅞¾⅛ = ι-χ⅞-Pk)
and α1 = SUpp∈(0,1) 1-exP(-p).
Hence by denoting T0 = maxk∈X Tk, we have that for any k ∈ X, andt≥ T0,
T
EξX ηbkt -
t=0
Lk (bk)2)
Pk
I∣vfk∣l2 ≤ f(Θ0) -f* + 2{
E cLkθk
k∈X
^{z
(A)
+ 52∑(1 + αo)2PkLkO2(ηk)2 + αι exp(-c)Lkθ2
t=0 k∈X
^Z
(B)
|
}	(C)
T
}
(29)
21
Published as a conference paper at ICLR 2022
Note that term (B) in (29) can be bounded following exactly the same step as in the proof of Theorem
3.1, for which we have
2
T XPιLισ2Sl)2 ≤ T XPιLσι T- = L Xpισ2α2.
l∈X	l∈X	pl l∈X
Hence for any constant c > 0 (we can readily choose c = 1), we have
Eξ X (bbk - Lk®) WfkII2 = f (Θ0) - f * + 2卜 X Lkσ2 (L
t=0	k∈X
'--------{z-----
(A0)
+ (1 + α0 )2 L X pk σk2 α2 +
k∈X
'-----------------------------------}
{z^
(B0)
X a1 exp(-C)Lkσ2 (1)
k∈X
'-----------------------}
{z^
(C0)
By the definition of ηk, We also have % - Lk(Pb) ≥ 等,then
T
Eξ X	ηbkt -
t=0
Tɪ) IWkII2 ≥ Eξ Xηt IWkII2.
pk	t=0
Hence We obtain
Tt
Eξ X ηk iiVfk『
≤ f (Θ0) - f * + 2 CELkσ2
k∈X
X--------
(A0)
+ (1 + αo)2L E Pkσkα2 + £ αι exp(-c)Lkσ2
k∈X	k∈X
---------------} '-----
(B0)
(30)
^{^―
(C0)
or equivalently,
Eξ X ɪ lVfk ι∣2 ≤2 (f 3)-f*) +4 + 4 + 4
ξ	Tt k	Tt	Tt	Tt	Tt
t=0	t=0 ηk	t=0 ηk	t=0 ηk	t=0 ηk	t=0 ηk
(31)
Let T0 denote a positive integer to be determined later, recall that from (27), for any t ≥ T0, With
t	t	tt	t
probability at least 1 - δk (here δk = exp(-tpk)), We have ∣ηk 一 nkI ≤ α0ηk hold. Denote
Bk = {w : ∣ηk - bk I ≤ αoηk}, then We have that for any k ∈ X,
Tt	Tt
Eξ X pTb½ Il Vfk Il2 ≥ Eξ X pTb½ IlVfkII2
t=0	t=0 ηk	t Te	t=0 ηk
T
≥ Eξ X
t=Te0
bbk
PT=o ηk
IlVfkIl2 IBk
Y
≥ (1-αo) X pTηk-^Eξ∣∣vfk∣∣2 IBk
t=Te0	t=0 ηk
≥ (1 - αo) X -Tηk-^ {Eξ ||Vfk『-ekG2O
t=Te0	t=0 ηkt
，	,，一 二, T
=(I -α0TT - °)X T-⅛ {Eξ IlVfkI2 - ekG2O
t=Te0	0	0
≥ (——0T——°) {EτEξ kVfTk2 - eT0G2O ,
(32)
22
Published as a conference paper at ICLR 2022
where the fourth inequality uses the assumption that ∣∣Vfk∣∣2 ≤ G2, and the last equality follows
from the definition that T 〜Unif {T0,...,T}. Finally, choose T0 = T/2, combine (31) and (32),
we obtain
EEiNfT 俨—O J2 (f(Ο0)-f *)+	4(AO)	4(B0)	4(C0)	严炉
ETEξ kvfk k — OI —=T—t— + E~~t + E~~t + E~~t + δk G
t=0 ηk	t=0 ηk t=0 ηk	t=0 ηk
Combine with the definition of (A’), (B’), (C’) in (30), and the definition of δkT0, we obtain
ETEξ∣VfkT∣2=O[f-*+ KXLkkσ(1 )2 + (I+ α0)2Jk∈XPpkσα2 + eCG
T	tT=0 ηkt	tT=0 ηkt	k
=O[ JfT + L PPX E2 + exp(-Tpk/2)C2 1
t=0 ηk	t=0 ηk
=OJ Mf	+ L Pk∈X Pkσ2α2 ]
—l∑t=0 ηk	J=0 ηk	。
where the last inequality holds whenever T ≥ Tb0 and Tb0 is large enough so that exp(-Tb0 pk/2)G2 ≤
PMf t ≤ —M—, and the second equality follows from the definition of Mf = f(Θ0) 一 f* +
/=0 nk_ _ PT=ο ηk
Jk∈x Lkσ2 (L)2 = f(Θ0) ― f* + Jk∈χ Pkσ2/L. Finally, following similar lines as in the proof
of Theorem 3.1, by choosing α
Mf
L pι∈x Piσ2
we obtain that for T ≥ max
T0 , Tb0 ,

Eξ kvfτ ∣2 = O { LMf + 内 j√Tp 心Mf
Jl LMf √k √∑ι∈χ Pισ2L (f (Θ0) ― f *) + (Jι∈χ pισ2)2 1
=OI 丁 +	√T
八]LMf ι √pk √∑1∈X pισ2L (f (θ0) - f *) √ √Pk (J1∈X pισ2)
=OI 丁 +	√T	+	√T
∀k ∈ X,
where the last inequality uses simple fact √a + b ≤ √α + ʌ/b whenever a,b > 0. It remains to
estimate the order of T0, we need exp(-T0Pk/2)C2 ≤
taking Tb0
2 log G-log(Mf (1∕2L+α∕√Pk))
Pk
Mf
PT0o ηk
, this can be readily satisfied by
□
Improvement of CF-SGD over SGD. Now under the the assumption that σl2 = σ2 for all l ∈ X,
compared with the rate of convergence of standard SGD in (9), the improvement of Counter-based
Frequency-aware SGD is governed by the ratio γc defined by
Yc := √∑√√⅛ (1+ pLdf*)),
which is only a constant factor away from the the improvement ratio γf of vanilla frequency-aware
SGD over standard SGD, given by
√pk
f - √∑ιeχ P2 .
Hence both Corollary 3.2 and 3.3 hold for Counter-based Frequency-aware SGD after properly
adjusting the constant factor in the statement.	□
23
Published as a conference paper at ICLR 2022
Proof of Corollary 3.1. By trivial verification.
□
Corollary D.1 (Corollary 3.2, restated). Let U = {in}|nU=|1, V = {jm}|mV=| 1, where in denote the
user with n-th largest frequency, and jm denote the item with the m-th largest frequency. Suppose
Pin H exp(-τn), Pjm H exp(-τm), ∀n ∈ [|U|], m ∈ [|V|].
for some τ > 0. Then there exists βU, βV > 0 such that for any user in ∈ U, we have
Pin P1∈X P"2
Pι∈x P2σ2
βU(τ) exp (-τ n) ≤
1 +exp(-τ)
1 - exp(-τ )
exp (-τ n) .
Similarly, for any item jm ∈ V, we have
Pjm P1∈X pισ2
P1∈X P2σ2
βV (τ) exp {-τ m} ≤
1 +exp(-τ)
1 - exp(-τ )
exp {-τ m} .
(33)
(34)
(35)
In addition, there exists an absolute constant C > 0, such that for WhenVer |U |, |V | ≥ 1, we have
βU(τ), βV (τ) ≤ C, and thus
PinP∈X"尸 ≤ C exp (-τn) ； Ppm≤ C exp {-τm} , ∀in ∈ U, Vjm ∈ V. (36)
l∈X Pl2σl2	l∈X Pl2σl2
Proof. Define MU = 1yeXP(-TUI), and MV = 1--XpP(-TVI), from (33) We have Pin
MU exp(-τ n), Pjm = MV exp(-τ m). In addition, we denote
MU,V
Pl2 =	Pi2+	Pj2 =MU2
l∈X	i∈U	j∈V
1 — exp(-2τ |U|)
1 — exp(-2τ)
+ M2 1 - exp(-2τIU|)
+ V 1 - exp(-2τ)
(1 + exp(-τ∣U∣)) (1 - exp(-τ)) + (1 + exp(-τ∣V∣)) (1 - exp(一τ))
(1 - exp(-τ|U|)) (1 + exp(-τ))	(1 - exp(-τ|V|)) (1 + exp(-τ))
Thus We obtain,
Pin Pι∈x Pισ2
Pι∈x P2σ2
2Pi	2MU
力------2 =	exp(-τn) = βu exp(-τn),
l∈X Pl2	MU,V
∀in ∈ U
PjPTPX 渭1=p⅛⅛=MMV exp(-Tm)=βV exp(-τm),
∀jm ∈ V,
From the definition of βU = MMU, βV = MV, combined with the fact that Mu,v ≥ 2 ：-；；；(二；),
and MU, MV ≤ 1, we obtain the inequality in (34) and (35). Finally, whenever ∣U∣, ∣V∣ ≥ 1, we
have βU ≤ 1--XXP⅛ 1+exp(-τ) ≤ 1-e-1 and similarly Bv ≤ 1⅛. Let C = i-e-1, we
obtain (36).
□
Corollary D.2 (Corollary 3.3, restated). Let U = {in}InU=I1, V = {jm}ImV=I 1, where in denote the
user with n-th largest frequency, and jm denote the item with the m-th largest frequency. Suppose
Pin H n-ν, Pjm H m-ν, ∀n ∈ [|U |], m ∈ [|V |].	(37)
for some ν ≥ 2. Define UT as the set of users whose frequencies are within 2-factor from the highest
frequency: UT = {in : n-ν ≥ 1/2}, and VT similarly as VT = {jm : m-ν ≥ 1/2}. We refer to
UT as the top users, and VT as the top items. Then there exists an absolute constant C > 0, such
that
Pin P1∈X PE
Pι∈x P2σ2
≤ Ct PjPP：P2Pr ≤Cm-V
∀in ∈ U, ∀jm ∈ V.
24
Published as a conference paper at ICLR 2022
Proof. We have Pin = MUn-ν, where MU =「口1 -V. Similarly, we have Pjm = MVm-ν,
Tn=I n V
-VWT--. Hence
∑m=ι mν
where MV
Pin Pι∈x pισ2 =	2pin =_________2Mun-ν_________
∑ι∈χ p2σl 一	Pι∈χ PP -	MU	Pn=I	3+ MV	Pm=I	m-2ν
We have
|U |	|U |
X n-ν = 1 + X n-ν
n=1	2
r∣u |+1	ι
≥1+/ n-"=1+口
[21-ν - (∣u | + i)1-ν],
|U |
X
n=T
n-ν
1+∕
|U | + i
n-ν
1 + — [1 - (∣U∣ + 1)1-"],
V——1
<
1U|	I
Xn-2" > 1 + 2ν-7 [21-2" - (∣U∣ + 1)1-2"],
n=1
which implies
MU <
MV <
V — 1
21-" - (∣U∣ + 1)1-" + U - 1
V — 1
21-" - (∣V∣ + 1)1-" + V - 1
V — 1
U > (∣U∣ + 1)1-" + V
V-1
U > (∣V∣ + 1)1-" + V
Thus
Pin PI∈Χ Plσ2
Pι∈x P2σ2
rt-"_________2(2"-1)______
≤________________________________n	(21-ν _(|u | + 1)1-v +"-1)("-1)______________________
―2	2 2	2	2 2
((W+1)1-V+") (21-2"-(∣U∣ + 1)1-2" + 2v - 1)+ ((|V|"1-V +") (21-2"-(∣V∣ + 1)1-2" + 2v - 1)
Note that
21-2" - (∣U∣ + 1)1-2" + 2v - 1 > 2v - 1, 21-2" - (∣V∣ + 1)1-2" + 2v - 1 > 2v - 1,
1111
(∣U∣ + 1)1-" + V > 1 + V, (∣V∣ + 1)1-" + V > 1 + V,
1	,1	1	,1
21-" - (∣U∣ + 1)1-" + V - 1 < V - 1, 21-" - (∣V∣ + 1)1-" + V - 1 < V - 1'
Then we conclude with
Pin Pι∈x Pισ2 < (2v - 1)
∑ι∈x P2σ2	— (V- I)
(1 + ν)2
(ν - 1)(2v - 1)
n-"
≤ 16n-",
where the last inequality follows from the fact that V ≥ 2. Similarly we can show that
Pjm PI∈X PC2
∑ι∈x P2σ2
≤ 16m-".
Take C = 16, we obtain the desired result.
□
25