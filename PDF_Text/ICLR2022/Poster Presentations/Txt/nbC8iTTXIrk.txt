Published as a conference paper at ICLR 2022
Optimization Inspired Multi-Branch Equilib-
rium Models
Mingjie Li1, Yisen WangI,2, Xingyu Xie1, Zhouchen Lin1,2,3 *
1	Key Lab. of Machine Perception (MoE), School of Artificial Intelligence, Peking University
2	Institute for Artificial Intelligence, Peking University
3	Pazhou Lab, Guangzhou, 510330, China.
Abstract
Works have shown the strong connections between some implicit models and
optimization problems. However, explorations on such relationships are lim-
ited. Most works pay attention to some common mathematical properties,
such as sparsity. In this work, we propose a new type of implicit model
inspired by the designing of the systems’ hidden objective functions, called
the Multi-branch Optimization induced Equilibrium networks (MOptEqs).
The model architecture is designed based on modelling the hidden objective
function for the multi-resolution recognition task. Furthermore, we also pro-
pose a new strategy inspired by our understandings of the hidden objective
function. In this manner, the proposed model can better utilize the hierar-
chical patterns for recognition tasks and retain the abilities for interpreting
the whole structure as trying to obtain the minima of the problem’s goal.
Comparing with the state-of-the-art models, our MOptEqs not only enjoys
better explainability but are also superior to MDEQ with less parameter
consumption and better performance on practical tasks. Furthermore, we
also implement various experiments to demonstrate the effectiveness of our
new methods and explore the applicability of the model’s hidden objective
function.
1 Introduction
Whereas Deep Neural Networks (DNNs) have achieved great success in many real-world
tasks such as computer vision and neural language process, the limited interpretability of
DNNs greatly hinders their further development.
However, many traditional machine learning methods, e.g.,matrix recovery (Zhang et al.,
2018b; 2015; Liu & Li, 2016), subspace clustering (You et al., 2016), image deblurring (Liu
et al., 2014) and so on, can be interpreted into minimizing the following objective functions:
min f (Z) + g(E), s.t. X = AZ + BE.
Z,E
where A ∈ Rm×d 1, B ∈ Rm×d2, X ∈ Rm×n, and f(∙) and g(∙) are convex functions designed
by the modelling of their properties. For this count, the interpretability of such methods is
much better than DNNs. Furthermore, these methods can also enjoy state-of-the-art and
robust performance on these tasks. We call such interpretability these methods enjoy as
"mathematical interpretability", i.e., whether the whole network structure can be summa-
rized as a compact mathematical model that can be mathematically analyzed.
Except for these methods, the Optimization Induced Equilibrium Networks (OptEqs) pro-
posed by Xie et al. (2021) recover its whole system to an optimization problem. The forward
propagation for OptEqs tries to solve Eqn (1) to get output y, z* ∈ Rd for input x ∈ Rdin .
We call the front part of Eqn (1) as OptEqs’ equilibrium equation, which is the central part
for equilibrium models. And its forward procedure can be regarded as solving the hidden
objective functions shown as Eqn(2),
* Corresponding author
1
Published as a conference paper at ICLR 2022
Z* = σ(Wz* + Ug(x) + b), y = WCZ*,	(1)
min G (z； g (x)) = min [J f (W T T z) - DU g (x) + b, W T T Z + 11∣ W T T z ∣∣2 - 11Iz ∣∣2 . (2)
W, U, Wc are learnable weights, g is the convolution layers projecting input x from real-
world domain to feature space like other neural architectures, and f is the outputs’ penalty.
Although OptEqs’ interpretability is satisfying, it still remains some weaknesses worth ex-
ploring. First, although OptEqs performs better than some implicit models, these models
only consider a single view (or resolution) of the input in their implicit parts. We call these
models single-view implicit models in the following. However, nearly all the state-of-the-art
pattern recognition systems (Lee et al., 2009b; Wang et al., 2019a; Huang et al., 2017; He
et al., 2016; Burt & Adelson, 1987) benefit from the multi-layer or multi-resolution feature
extractors in domains like computer vision and audio processing. Secondly, limited new
modules are proposed in their work, which mainly consider the math properties of features
like sparsity, but whether these properties can benefit image recognition tasks is unexplored.
Besides OptEqs, MDEQ (Bai et al., 2020) constructs its equilibrium equation Z* = F(z*; x)
and block F with the inspiration of explicit models especially HRNet Wang et al. (2019a).
Then they solve the equilibrium equation by the accelerated algorithm for output z* . Al-
though it shows the state-of-the-art performance with efficient memory cost as other implicit
models, such strategies will make the mo del lose "interpretability" since the MDEQ is a black
box because its output is solved in an implicit way (root-finding method), which makes anal-
ysis on its features of intermediate layers almost impossible. Furthermore, its complicated
structure also hinders its analysis from mathematical systems. More efficient blocks with
good interpretability still needs exploring.
Motivated by the limitations of the above models, we would like to design a multi-scale DEQ
structure with state-of-the-art performance and preserve mathematical interpretability from
the inspiration of OptEqs and multi-scale models. Our contributions are listed below:
•	We propose a multi-branch implicit model, called Multi-branch OptEqs (MOptEqs),
which efficiently utilizes different scales inputs with better performance and smaller
model size. Furthermore, it still retains its connection to an optimization problem.
•	We propose some properties modelled as new terms for the model’s hidden objective
function from our analysis on the relationships between branches and their hierarchi-
cal dependencies. With new problem’s formulation, we obtain the fusion module in
our MOptEqs, called Hierarchical Heritage and Diversity Module (HH&D Module).
•	Apart from the new module design, we also propose the Perturbation Enhanced
strategy (PE) for our MOptEqs from our analysis on the model’s hidden objective
function. The new strategy cannot only enhance the performance of our MOptEqs,
but also improve the robustness of our models.
1.1	Related Works
Implicit Models. Nearly all modern deep learning approaches use explicit models, which
provide an explicit computation graph for the forward propagation. In contrast, the compu-
tation graphs for implicit models are "flexible" or can be assumed as having "infinite" depth.
For example, Neural ODEs (Chen et al., 2018; Massaroli et al., 2020) encode their neural
architectures by a differential system with learnable parameters. Then the implicit ODE
solvers they used is equivalent to a continuous ResNet taking infinitesimal steps. Further-
more, the training process of Neural ODEs can be depicted as finding a differential system of
a certain type (like heat equations) by updating its learnable parameters which demonstrate
that Neural ODE also enjoy interpretability to a certain extent.
Moreover, DEQ (Bai et al., 2019; Winston & Kolter, 2020) is another class of implicit models.
The central part of DEQ is the designation of the equilibrium equations z* = F(z*; x) and
block F. Its forward procedure is trying to solve the equilibrium equations with input x to
2
Published as a conference paper at ICLR 2022
get the equilibrium state Z* as output by accelerated algorithms. Since the Z* is fixed given
F and x, its inference can be regarded as forwarding an explicit network stacked by the same
block F for infinite times. For example, DEQ chooses their F by one set of Conv+ReLU
while MDEQ constructs an HRNet-like block as theirs. However, no evidence shows that the
best block constructions in explicit models can perform the best in the DEQ scheme. The
construction of DEQ blocks or equilibrium equations is an open question worth exploring.
Furthermore, most DEQ blocks do not have any mathematical insights (like the diffusion
process in Neural ODE) and perform totally a black box with limited interpretability.
Since implicit models usually adopt accelerated root-finding algorithms for their forward
outputs and backward gradients, they enjoy the advantages of constant and more efficient
memory costs compared with DNNs. Due to the above advantages, the design of implicit
models draws much attention these days (Ghaoui et al., 2019; Gould et al., 2019). Apart from
the models illustrated above, many kinds of other implicit models are proposed, including
differentiable physics engines (Qiao et al., 2020; de Avila Belbute-Peres et al., 2018), logical
structure learning (Wang et al., 2019b) and implicit neural blocks (Li et al., 2020).
Model Interpretaiblity. Many researchers nowadays are trying to make their proposed
method more interpretable. Although there are many kinds of approaches to achieve this
goal, we marginally divide them into two parts: "Empirical" and "Mathematical" inter-
pretability. Many works, such as (Zhang et al., 2018a; Zhang & Zhu, 2018; Bau et al., 2018),
attempt to empirically disassemble the black box by characterizing some statistical or struc-
tural information like the outputs and gradients of neural networks’ middle layers. However,
these works cannot be directly implemented on DEQ models since implicit ones do not have
explicit depths like DNNs, which makes analyzing such models by dissecting each layer’s
behavior almost impossible. Apart from that, researchers (Djolonga & Krause, 2017; Amos
& Kolter, 2017; Xie et al., 2019; Chan et al., 2020) also managed to understand the neural
architecture by linking it to a mathematical problem. In this way, researchers can analyze
the black box by its corresponding mathematical problem. Furthermore, new components
can be proposed due to the analysis of these problems. Our model aims to design a new
DEQ architecture with proper mathematical interpretability. Compared with former works,
our model can perform better on the classification tasks with novel components.
2 Multi-Branch Optimized Induced Equilirium Models
2.1	The proposed architecture for the Multi-Branch OptEqs
Inspired by OptEqs, we first design an objective function for our tasks to solve and then
use its first-order stationary conditions as MOptEqs’ equilibrium equation. The base of
our function is formed by summarizing several objective functions of different scales defined
for OptEqs (Details are stated in Appendix A.1). However, such a model can not obtain
satisfying results since these branches are independent. For this count, we need to design
some terms describing the dependencies of each branch in the hidden objective function, as
shown in the following paragraphs. Then we can obtain the equilibrium equations for our
MOptEqs and our MOptEqs’ block F by analyzing the first-order stationary condition of
our designed optimization problem.
Hierarchical Heritage Modeling. State-of-the-art explicit models for image tasks are ex-
plicitly structured into sequential stages and process different resolutions hierarchically (He
et al., 2016; Shelhamer et al., 2017; Lee et al., 2009a), which implies that features should
be extracted hierarchically. In other words, the posterior branches should inherit from their
prior ones, which we call such property hierarchical heritage. In our work, we are going
to formulate such correlation of neighbouring branches in the hidden objective function by
adding the following inner-product term into its origin:
H(zi, zj) = zi> Pi:j zj	(3)
where Zi ∈ Rdi , Zj ∈ Rdj , Pi:j ∈ Rsi ×sj denotes the Average Downsample (its transpose can
be regarded as a weighted nearest upsample) or Identity matrix suited to the shape of Zi
and Zj (i < j or j = 1, i = L). This term estimates the summation for similarity of i-th and
j-th branchs channels with the same channel index (corresponding channels).
3
Published as a conference paper at ICLR 2022
When zi and zj are similar, the inner product will be large. Otherwise, the result will become
small, which implies that the relationship of corresponding channels is weak. In this way,
we can ensure the similarity of corresponding channels of the near branches. Except for
the relations between different branches’ corresponding channels, the relationships between
dis-corresponding channels are explored in the following section.
Diversity Modeling. In addition to the hierarchical relations for corresponding channels,
works (Pang et al., 2019; Amada et al., 2021) have shown enhancing the diversities between
branches can also improve the model’s improvements. Therefore, we also consider making
different branches extract various features to improve the representation abilities. To achieve
such a goal, we add a diversity term in the objective function Eqn (4) for i < j,
CC
D(zi, zj) = X X |vec-1(zi)(k1)>vec-1(Pi:jzj)(k2)|,	(4)
k1=1 k2=1
k2 6=k1
where vec-1 is the inverse vectorization operator converting the vectorized feature zi ∈
Rdi×1 to a matrix in RT ×C with C channels and Vec-- 1(zi)(k) ∈ Rdi ×1 denotes the k-
th channel of i-th branch in practice. Since we have already considered the relationships
between the corresponding channels in the hierarchical term, we only tries to estimate the
diversities of dis-corresponding channels of the i-th and j-th branches in this term. As the
diversity term goes small, the diversities between the branches become stronger.
The architecture of MOptEqs and its hidden problem. With the two terms we
proposed, we can reformulate the hidden objective for our problem as follows:
min G(z1, ..., zL; g(x)) = min
z1,...,zL	z1,...,zL
X 1>f(Wi-1>zi) - Uig(x) +bi,Wi-1>z
i=1
+ 2(λD(zi, Zi+ι) + IlWTTZiIl2 一 H(zi, Zi +ι))
(5)
L
g(x) is the input feature for the raw input x, λ > 0 is a hyperparameter and zi ∈ Rdi ×1 are
the final outputs of MOptEqs. We can choose f to constrain zi on our demand and will
influence model’s activation function. If we choose f (x) = I{x ≥ 0} to ensure the outputs
to be positive, then the activation function is ReLU. We set D(zL, zL+1) = D(zL, z1) and
H(zL, zL+1) = H(zL, z1) when i = L to complete the loop. The two terms we added tries to
make the corresponding channels of different branches correlated by maximizing the H term
and enhancing the diversities of different branches by minimizing D term. We note that H
and D are not conflict since they are handling different pairs of channels for branches.
As the following proposition shows, we finally get the equilibrium equations (Eqn (6)) for
our MOptEqs by calculating the first-order stationary conditions VZ宅 G = 0 for problem G.
Proposition 1 The proposed multi-branch structure induced by Eqn (5) can be depicted as
solving the equilibrium points e* :
[z>*,…，z>*]> ∈ RPL=1 di for the following equations:
----------- —-I-	----—√-⅛	√-⅛
e = W Te (W h (Z) + U g (x) + b)
W1
where W =	.	,U = [UT,…，UT]T, e =[bT,…，bT]T.
WL
(6)
And h(Z) = [h 1(z1,zl, z2)>,.., h(Zi, Zi-1, Zi+ι)>, ∙∙, hL(ZL,zL- 1,z1)>]>
fined as the mapping from Rdi × Rdi+1 × Rdi-1 to Rdi ,
and each hi is de-
h(zi , Zi— 1, Zi +1) =2 (Pi：i +1Zi +1 + Pi— 1:izi—1)
一 2vec(vecT(Pi：i +1Zi+1)SignMi：i +1 一 diag(Mi：i +1)])
—2vec(vec- 1(P3：izi- 1)sign[M3：「diag(Mi-1：i)]),
Mi：i+1 =vec—1(Pi：i+1Zi+1)Tvec—1(Zi),
Mi—1：i =vec—1(Zi)Tvec—1(PiT—1：iZi—1).
4
Published as a conference paper at ICLR 2022
HHD	Zq
Module
Wlff(WIZl + Uιg(x) +bl) —►
HHD	z%
Module
Wlσ(W2z2 + U2g(x) + b2)
W^σ(W3z3 + U3g(x) + b3) —►
(b) HH&D′s structure.
Figure 1: The structure of the MOPtEqs and HH&D Module. Dotted lines in the figure
denotes the upsampling, downsampling or identity operators to suit the size of each branch,
0 denotes multiplication operator,㊉ denotes addition operator, RD operator processes a
matrix by removing its diagonal, SIGN operator convert each element of a matrix to its
sign and the di = CHiWi with C is the channel number and Hi, Wi are the height and
width of the feature map.
(a) MOPtEqs' structure.
MHOHDie 二 叩监小灯如丹姐 一
The equilibrium points for the above formula are also the first-order stationary points for the
optimization problem Eqn(5).
The proof of the proposition is listed in Appendix A.3. In this manner, We obtain the
proposed architecture MOptEqs, its forward propagation is equivalent to find the equilibrium
points of Eqn(6), and such process can also be regarded as solving the stationary points of
the optimization problem (5). The whole structure is also shown in Figure 1 (a) and we
also draw figures to illustrate the practical process of hi (HH&D) on its right (Figure 1 (b)).
We also evaluate the effectiveness of such modelling in Section. 3.2’s experiments.
2.2	The proposed Perturbation Enhanced Strategy for MOptEqs
Researches (Kong et al., 2020; Xie et al., 2020; Tang et al., 2021) have discovered that small
perturbations can enhance the generalization abilities and varieties of branches for neural
architectures. Most efficient works use adversarial perturbations based on gradients (Xie
& Yuille, 2020) for such a trick. However, such a strategy will slow the training process
since they need at least one more back-propagation in each training step for perturbations,
which is time-consuming. Unlike these methods, we can acquire more computation efficient
perturbations because our models can be formulated as minimizing an objective function
we designed. Then we can replace the maximum problem (details in Appendix A.2) for
adversarial perturbation with maximizing our architecture’s hidden objective function G,
since we assume MOptEq’s performance will go worse if G(z; g(x)) changes a lot at g(x)’s
neighborhoods since the forward propagation of MOptEqs is minimization G(z; g(x)).
Assumption 1 For a well trained OptEqs with its objective function denoted as G(z; g(x))
and a natural sample x which can be correctly classified. If an input perturbation kδk∞ ≤
can cause one of the fol lowing changes:
∣G(Zz0； g(X)- ^)-G(Z*； g(x))| ≥ L13
IIz'0' - z*∣∣2 ≥ L2e.
with L1 , L2 > 1, it may lead the OptEqs to the wrong results with high probability.
For the second part of the assumption, it’s common sense and widely used in the analysis
of adversarial robustness (Zhang et al., 2021; Li et al., 2020). With the above assumption,
we can generate the perturbations by maximizing the objective function G(z; g(x)) for our
MOptEqs. Since our MOptEqs can be regarded as a kind of "implicit" ensembling that
parallels several equilibrium models, we decide to inject the perturbations acquired for the
prior branch to the posterior one, like boosting to enhance the performance.
5
Published as a conference paper at ICLR 2022
Then the hidden objective function of MOptEqs with G(z; g(x)) is shown as follows,
min G(z1, ...,zL; g(x)) = min
z1,...,zL	z1,...,zL
X 1>f(Wi-1>zi)- Ui(g(x) -δi-1)+bi,Wi-1>z
i=1
L
+ 1 (λD(Zi,zi +ι) + IlWTTZik2-H(Zi,zi +ι))j ,
s.t.	δi	= argmax 1>f(Wi-1>zi) - DUi(g(x)	- δi)	+ bi,Wi-1>ziE	for i ∈	[1, L].
kδik∞≤
where δ0 = 0. And the problem becomes a bilevel optimization problem. The solution to the
lower-level problem is δi = sign(Ui>Wi-1>zi). Since the perturbation can be obtained by
feeding the output of the activation layer σ(Wz + Ug(x) + b) to the transposed convolution
layer with weight Ui , we call it reconstructed perturbation. Compared with the adversarial
perturbations based on gradients, our perturbations can be acquired directly by matrix-
vector multiplication instead of iteratively built by gradients. Thus, such a process does not
require much computation cost. Following the above steps, we obtain a harmful perturbed
direction for the prior branches and then added them to their posterior branches. We note
that our perturbation is added to the input feature g(x) instead of the raw input.
Proposition 2 For a natural sample x and a well trained OptEqs
Z * = W T σ (WZ * + U g (x) + b)
with its hidden objective function denoted as G(z; g(x)), for g0(x) = g(x) - δ and δ =
sign(UiTWi-1TZi), which obeys the constraint kδk∞ ≤ . Z0* and Z* are defined as fol lows:
zz0 = argmin G(z; g(x)),
z
z" = argmin G(z; g(x)).
z
If the Il Wk 2)k Uk 2 ≤ 1 and N ∣∣ UT W-1TZ* k ι》g where N is the element number of g(x),
then
max nG(z0*; g(x) - δ) - G(z*; g(x)), √Ne∣z0* - Z*∣2} ≥ 2 {e∣UTWTTZ*∣ι - Ne2}.
The proposition demonstrates if we choose the perturbed direction to be esign(UTW-1TZ),
at least one of the changes for the G or Z* will be around eIUTW-1TZ* I1 and implies each
branch may perform bad on the perturbed data according to our assumptions. With the
experiments in Section.3.2, we can conclude that our reconstructed perturbation is useful
and our assumption is reasonable. Like boosting strategy, we can feed the perturbed data
for the prior branch to its posterior branch to enhance the performance; we call such method
as the Perturbation Enhanced strategy (PE). Following experiments also show that PE
can indeed enhance the performance of our MOptEqs.
2.3 Model Optimization and Forward Convergence
Forward Propagation and Implicit Differentiation. Like other equilibrium models,
the forward propagation procedure is solving the given equilibrium functions Eqn 7. For this
count, our model also enjoys the constant memory cost advantages as other DEQs. In our
work, run root-finding algorithms to solve the roots Z* = [z 1,…ZL] of the following problem
to reach the equilibrium states, which is the same as MDEQ (shown in Appendix A.5):
▽ WG(zι,…,ZL; g(x)) = 0.	(7)
As for the backward propagation, we also adopt the implicit differentiation method widely
used in (Bai et al., 2020; 2019; Chen et al., 2018). Instead of tracing the gradients during the
forward propagation, the implicit differentiation method directly backpropagates through
the equilibrium state using the Jacobian of Tθ = ▽ ZG + Z at Z*. For a given loss l = L(Z*, y)
(where y is the target) and the gradients can be written as
∂l ∂l ,τ T LLI ∂Tθ	知
硝=苔(I- JT IZ)西.	⑻
6
Published as a conference paper at ICLR 2022
Model	Model Size	Accuracy	Model	Model Size	Accuracy
Neural ODEs	172K	53.7%	ResNet-18	10M	92.9 ± 0.2%
Aug. Neural ODEs	172K	60.6%	MonDEQ	1M	89.7%
Single-tire MonDEQ	854K	82.5%	MDEQ	2.53M	92.6 ± 0.2%
Deep OptEqs1	199K	87.4%	MDEQ	10M	93.8 ± 0.3%
Parallel-OptEqs	193K	87.4%	MOptEqs	0.48M	92.9 ± 0.2%
POptEqs(sum)	193K	88.4%	MOptEqs	1.9M	94.0 ± 0.1%
POptEqs(conv)	276K	88.9%	MOptEqs	8.1M	94.6%
MOptEqs (w/o PE) MOptEqs	193K 193K	89.1% 89.5%	(b) Comparison of the models with		
			multiple-scales. MonDEQ here is the		
(a) Comparison of the models with single-scales			multi-tired monotone DEQ.		
Table 1: Evaluation on CIFAR-10 for different models. "Parallel-OptEqs"(POptEqs) means
our model is built without utilizing HH&D fusion (Stated in Appendix A.1), which is formed
by paralleling several OptEqs with the method stated in the brackets for fusion. "w/o PE"
means MOptEqs is trained without our PE strategy.
And the calculation of ∂∂Z- (I — J3 Iz*) —1 is equivalent to solve root m for the following
equation:
m(I - JTθ1 z*) + ∂Z- = 0∙	⑼
As for the root-finding algorithm, we can use Broyden method (Broyden, 1965), Anderson
Method (Anderson, 1965; Bai et al., 2021) or other root-finding methods to solve Eqn(7) for
the equilibrium state and Eqn(9) for the backward gradient.
Forward Convergence. Like other implicit models, we make some constraints on param-
eters in order to make the whole MOptEqs TΘ(z; x) (z here is {zi}L=ι) be a contractive
mapping. For the MOptEqs without considering HH&D (Eqn 10), the models can easily
converge with kWi k2 ≤ ζ < 1. But since we use the HH&D module, we need to choose
proper λ to ensure the convergence, around or less than will be appropriate. We also
conduct experiments to verify the convergence in Appendix A.7.
3 Experimental Results
In this section, we conduct experiments for the image classification tasks on CIFAR-
10,CIFAR-100 Krizhevsky et al. (2009) and ImageNette implemented on the Py-
Torch (Paszke et al., 2017) platform to demonstrate the effectiveness of our model. Details
are listed in Appendix A.6.
3.1	Comparison of Prior Implicit Models
In this part, we decide to verify the superiority of MOptEqs in two aspects. First, we
build the single-scale MOptEqs and compare the empirical results with other single-scale
implicit models. And then we compare the experimental results with prior implicit models
that utilize the multi-scale inputs like MDEQs, the state-of-the-art implicit model with
multi-resolution.
Implicit Models with Single View. In this part, we compare our MOptEqs with other
single-view implicit models with comparable model sizes. Like OptEqs who uses three
blocks for their experiment, we first construct our small MOptEqs with three branches
whose outputs share the same size and the channel number C = 32. Results in Table.1
(a) demonstrates that our MOptEqs structure can even enhance the performance for recog-
nition tasks under the single-view cases. Compared to the multi-branch model without
fusion (POptEqs), our MOptEqs’ HH&D can efficiently utilize the relationships between
different branches and lead the model to better performance. Our superiority also holds
compared with former multi branches fusion methods: "sum" (non-parametric module) and
"conv" (parametric module). Meanwhile, we can also conclude the effectiveness of our per-
turbation enhanced strategy from the table since its performance is the best.
7
Published as a conference paper at ICLR 2022
Model	Model Size	Accuracy	Model	Model Size	Accuracy
MDEQ	2.6M 11M	70.8 ± 0.2% 72.4 ± 0.2%	MDEQ	2.5M 10M	90.5 ± 0.2% 91.3 ± 0.3%
MOptEqs	1.9M	73.4 ± 0.2%	MOptEqs	1.9M	92.1 ± 0.2%
MOptEqs	8.1M	74.7%	MOptEqs	10M	92.4%
(a) Evaluation on CIFAR-100 for models.			(b) Evaluation on Imagenette for models.		
Table 2: Evaluation on CIFAR-100 and ImageNette for MDEQ and MOptEqs.
Implicit Models with Multiple Scales. Moreover, we conduct experiments compared
with other models which handling multi-scale inputs. Like MDEQ, we construct our
MOptEqs with four branches with resolution size equals to 32,16,8,4. Other details can
be found in Appendix A.6. From Table.1 (b) and as shown in Table.2 (a), one can see that
our MOptEqs not only outperforms the widely used explicit model ResNet-18 (He et al.,
2016), but also shows better performance compared with MDEQ with fewer parameters on
CIFAR, which is one of the best models. The empirical results for the multi-scale models
further verify the superiority of MOptEqs and its strategy.
Apart from experiments on small images, we also conduct experiments on ImageNette, which
is a subset of 10 classes from ImageNet. Compared with MDEQ, our MOptEqs consistently
perform better shown in Table.2 (b). Nevertheless, as one can see from the results, the
difference between MDEQ and our model becomes much bigger in the CIFAR-100 and
Imagenette with the same training hyper-parameters. Such a phenomenon demonstrates
that the performance of our model is much more stable than MDEQ. Apart from these
experiments, we also conducted ablation studies for our models in the following section.
3.2 The comprehensive understanding of MOptEqs
Figure 2:	Visualization of the channels correlations for the MOptEqs and POptEqs.
Visualization of the impact for the HH&D module. In this section, we try to estimate
the effect of our HH&D module. We finish experiments in this part using three-branch
MOptEqs with 16 channels for each branch to make the visualization more clear.
We tries to verify our HH&D module’s effect in two aspects. First, we plot scatter figures for
the values of
£L=1 Ej∈N(i) D(zi，Zj )
L (C 2-C)
(denoted as Average D) and Pi=1 Pj∈LCi) H(ZZiZZ) (denoted
as Average H) for 100 randomly chosen samples (N (i) denotes neighboring branch of the
i-th branch). Since the hidden optimization problem is to maximizing H while minimizing
D, we find that our MOptEqs (Figure 2(a)) can induce the output features to reach such
goal compared with POptEqs (MOptEqs without HH&D) (Figure 2(b)).
Furthermore, we also plot heatmaps of the first two branches’ correlation score
(|vec-1(z2)vec-1(z1)>| ∈ R16×16) for a randomly chosen sample shown in Figure 2(c)(d).
One can see that MOptEqs’ heatmap (Figure 2(c)) is more likely to be a diagonal matrix
while heatmap Figure 2(d) for POptEqs looks random. The heatmap shows that our HH&D
can induce the model to perform as our demand, which means corresponding channels for ad-
jacent branches can be more correlated, while the dis-corresponding channels are unrelated
due to our architecture design. The visualizations and former results on different datasets
verify the effectiveness of our modelling and our HH&D modules’ design.
8
Published as a conference paper at ICLR 2022
7
(c)
(a)	(b)
Figure 3:	(a) Test accuracy changes with respect to the perturbation size for different
perturbed directions. (b) Test Accuracy for small MOptEqs (w. and w/o. PE) under PGD
attack with different inner iterations. (c) Plot of the accuracies for the small MOptEqs
without HH&D trained by the extended loss with respect to various γ.
Evaluation of the reconstructed perturbation. We compare our perturbation with
randomly generated ones in a one-branch well-trained MOptEqs to validate its effectiveness.
We first feed a natural sample x to the model and acquire output z for x and generate our
reconstructed perturbation using such output and then feed it to the model. Furthermore,
we add the perturbations generated by Binomial distribution (P(δi = ) = P(δi = -) = 0.5)
and Uniform distribution U [-, ] to input features g(x) for comparison. The result of each
distribution is averaged for five trials. Figure 3(a) shows our perturbation generated by
maximizing G is much more effective, which validates the effectiveness of our reconstructed
perturbations and the rationality of our assumptions and analysis in Section.2.2.
Robustness of our MOptEqs trained by PE strategy. In addition to improving the
generalization abilities for models as shown in Sec.3.1, perturbations with proper size may
also enhance the robustness of our MOptEqs, shown in Figure 3(b). We conduct experiments
on small MOptEqs (the same setting as Sec.3.1’s single-view model). Our perturbation
enhanced strategy goes stronger as increases. The figure shows that accuracy for the
model trained naturally drops quicker than trained by PE strategy. Overall, trained with
appropriate reconstructed perturbation can partly improve the robustness of our MOptEqs.
MOptEqs vs. adding Regularizers in training loss. Apart from our HH&D modules,
adding D and H to the training loss is one of the most popular methods for obtaining outputs
with certain properties. In order to demonstrate the superiority of our module empirically,
we conduct experiments for our MOptEqs trained by cross-entropy and POptEqs (MOptEqs
(w/o. HH&D)) trained by the cross-entropy loss adding γ PiL=1 (H(zi, zi+1) - λD(zi, zi+1))
as regularizers (we call it augmented loss). Then we drew its test accuracy for different γ
trained by the augmented loss (λ is the same as ours) shown in Figure 3(c).
With proper γ, POptEqs trained by additional loss can perform better than γ = 0. Such
phenomenon demonstrates the effectiveness of our HH&D Modelling. Furthermore, the
figure demonstrates the superiority of our model since the traditional method is consistently
worse than ours. We left some other explorations for our model in the Appendix.
4 Conclusion
We introduce the multi-branch optimization induced equilibrium models (MOptEqs), a new
extension of OptEqs that can utilize multiscale information for recognition tasks and retain
its ability to recover to an optimization problem whose solution is equivalent to the equilib-
rium states of our model. The model architecture is designed based on modelling the hidden
objective function for the multi-resolution recognition task. Furthermore, we also propose
a new strategy inspired by our understandings of the hidden optimization problem. The
empirical results show the advantages of our proposed methods. The success of our HH&D
module and PE strategy demonstrates the deep link between the optimization problem and
neural architecture and may motivate further explorations.
9
Published as a conference paper at ICLR 2022
Acknowledgments
Yisen Wang is partially supported by the National Natural Science Foundation of China
under Grant 62006153, Project 2020BD006 supported by PKU-Baidu Fund, and Open Re-
search Projects of Zhejiang Lab (No. 2022RC0AB05).
Zhouchen Lin is supported by the NSF China (No. 61731018), NSFC Tianyuan Fund for
Mathematics (No. 12026606), Project 2020BD006 supported by PKU-Baidu Fund, and
Qualcomm.
References
Takuma Amada, Kazuya Kakizaki, Toshinori Araki, Seng Pei Liew, Joseph Keshet, and
Jun Furukawa. Adversarial robustness for face recognition: How to introduce ensemble
diversity among feature extractors? 2021.
Brandon Amos and J Zico Kolter. Optnet: Differentiable optimization as a layer in neural
networks. In International Conference on Machine Learning, pp. 136-145. PMLR, 2017.
Donald G. M. Anderson. Iterative procedures for nonlinear integral equations. Journal of the
ACM, 12(4):547-560, 1965. doi: 10.1145/321296.321305. URL http://dblp.uni-trier.
de/db/journals/jacm/jacm12.html#Anderson65.
Shaojie Bai, J. Zico Kolter, and Vladlen Koltun. Deep equilibrium models. In Hanna M.
Wallach, Hugo Larochelle, Alina Beygelzimer, Florence d,Alche-Buc, Emily B. Fox, and
Roman Garnett (eds.), Advances in Neural Information Processing Systems 32: Annual
Conference on Neural Information Processing Systems 2019, NeurIPS 2019, December
8-14, 2019, Vancouver, BC, Canada, pp. 688-699, 2019.
Shaojie Bai, Vladlen Koltun, and J. Zico Kolter. Multiscale deep equilibrium models. In
Hugo Larochelle, Marc’Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-
Tien Lin (eds.), Advances in Neural Information Processing Systems 33: Annual Con-
ference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12,
2020, virtual, 2020.
Shaojie Bai, Vladlen Koltun, and J. Zico Kolter. Stabilizing equilibrium models by jaco-
bian regularization. CoRR, abs/2106.14342, 2021. URL https://arxiv.org/abs/2106.
14342.
David Bau, Jun-Yan Zhu, Hendrik Strobelt, Bolei Zhou, Joshua B. Tenenbaum, William T.
Freeman, and Antonio Torralba. GAN dissection: Visualizing and understanding genera-
tive adversarial networks. CoRR, abs/1811.10597, 2018. URL http://arxiv.org/abs/
1811.10597.
Charles G Broyden. A class of methods for solving nonlinear simultaneous equations. Math-
ematics of computation, 19(92):577-593, 1965.
Peter J Burt and Edward H Adelson. The laplacian pyramid as a compact image code. In
Readings in computer vision, pp. 671-679. Elsevier, 1987.
Kwan Ho Ryan Chan, Yaodong Yu, Chong You, Haozhi Qi, John Wright, and Yi Ma. Deep
networks from the principle of rate reduction. arXiv preprint arXiv:2010.14765, 2020.
Tian Qi Chen, Yulia Rubanova, Jesse Bettencourt, and David Duvenaud. Neural ordinary
differential equations. In Samy Bengio, Hanna M. Wallach, Hugo Larochelle, Kristen Grau-
man, Nicold Cesa-Bianchi, and Roman Garnett (eds.), Advances in Neural Information
Processing Systems 31: Annual Conference on Neural Information Processing Systems
2018, NeurIPS 2018, December 3-8, 2018, Montreal, Canada, pp. 6572-6583, 2018.
Filipe de Avila Belbute-Peres, Kevin Smith, Kelsey Allen, Josh Tenenbaum, and J Zico
Kolter. End-to-end differentiable physics for learning and control. Advances in neural
information processing systems, 31:7178-7189, 2018.
10
Published as a conference paper at ICLR 2022
Josip Djolonga and Andreas Krause. Differentiable learning of submodular models. Advances
in Neural Information Processing Systems, 30:1013-1023, 2017.
Zhengyang Geng, Meng-Hao Guo, Hongxu Chen, Xia Li, Ke Wei, and Zhouchen Lin. Is
attention better than matrix decomposition? In International Conference on Learning
Representations, 2021.
Laurent El Ghaoui, Fangda Gu, Bertrand Travacca, and Armin Askari. Implicit deep learn-
ing. CoRR, abs/1908.06315, 2019.
Stephen Gould, Richard Hartley, and Dylan Campbell. Deep declarative networks: A new
hope. CoRR, abs/1909.04866, 2019.
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image
recognition. In 2016 IEEE Conference on Computer Vision and Pattern Recognition,
CVPR 2016, Las Vegas, NV, USA, June 27-30, 2016, pp. 770-778. IEEE Computer
Society, 2016. doi: 10.1109/CVPR.2016.90.
Gao Huang, Zhuang Liu, Laurens van der Maaten, and Kilian Q. Weinberger. Densely
connected convolutional networks. In 2017 IEEE Conference on Computer Vision and
Pattern Recognition, CVPR 2017, Honolulu, HI, USA, July 21-26, 2017, pp. 2261-2269.
IEEE Computer Society, 2017. doi: 10.1109/CVPR.2017.243.
Kezhi Kong, Guohao Li, Mucong Ding, Zuxuan Wu, Chen Zhu, Bernard Ghanem, Gavin
Taylor, and Tom Goldstein. Flag: Adversarial data augmentation for graph neural net-
works. arXiv preprint arXiv:2010.09891, 2020.
Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny
images. 2009.
Honglak Lee, Roger Grosse, Rajesh Ranganath, and Andrew Y Ng. Convolutional deep belief
networks for scalable unsupervised learning of hierarchical representations. In Proceedings
of the 26th annual international conference on machine learning, pp. 609-616, 2009a.
Honglak Lee, Roger B. Grosse, Rajesh Ranganath, and Andrew Y. Ng. Convolutional deep
belief networks for scalable unsupervised learning of hierarchical representations. In An-
drea Pohoreckyj Danyluk, Leon Bottou, and Michael L. Littman (eds.), Proceedings of the
26th Annual International Conference on Machine Learning, ICML 2009, Montreal, Que-
bec, Canada, June 14-18, 2009, volume 382 of ACM International Conference Proceeding
Series, pp. 609-616. ACM, 2009b. doi: 10.1145/1553374.1553453.
Jia Li, Cong Fang, and Zhouchen Lin. Lifted proximal operator machines. In Proceedings
of the AAAI Conference on Artificial Intel ligence, volume 33, pp. 4181-4188, 2019.
Mingjie Li, Lingshen He, and Zhouchen Lin. Implicit euler skip connections: Enhancing
adversarial robustness via numerical stability. In Proceedings of the 37th International
Conference on Machine Learning, ICML 2020, 13-18 July 2020, Virtual Event, volume
119 of Proceedings of Machine Learning Research, pp. 5874-5883. PMLR, 2020.
Guangcan Liu and Ping Li. Low-rank matrix completion in the presence of high coherence.
IEEE Transactions on Signal Processing, 64(21):5623-5633, 2016.
Guangcan Liu, Shiyu Chang, and Yi Ma. Blind image deblurring using spectral properties of
convolution operators. IEEE Transactions on image processing, 23(12):5047-5056, 2014.
Stefano Massaroli, Michael Poli, Jinkyoo Park, Atsushi Yamashita, and Hajime Asama.
Dissecting neural odes. In Hugo Larochelle, Marc’Aurelio Ranzato, Raia Hadsell, Maria-
Florina Balcan, and Hsuan-Tien Lin (eds.), Advances in Neural Information Process-
ing Systems 33: Annual Conference on Neural Information Processing Systems 2020,
NeurIPS 2020, December 6-12, 2020, virtual, 2020.
Michael C Mozer. A focused back-propagation algorithm for temporal pattern recognition.
Complex systems, 3(4):349-381, 1989.
11
Published as a conference paper at ICLR 2022
Tianyu Pang, Kun Xu, Chao Du, Ning Chen, and Jun Zhu. Improving adversarial robustness
via promoting ensemble diversity. In Kamalika Chaudhuri and Ruslan Salakhutdinov
(eds.), Proceedings of the 36th International Conference on Machine Learning, ICML
2019, 9-15 June 2019, Long Beach, California, USA, volume 97 of Proceedings of Machine
Learning Research, pp. 4970-4979. PmLr, 2019.
Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary
DeVito, Zeming Lin, Alban Desmaison, Luca Antiga, and Adam Lerer. Automatic differ-
entiation in pytorch. In NIPS-W, 2017.
Yi-Ling Qiao, Junbang Liang, Vladlen Koltun, and Ming Lin. Scalable differentiable physics
for learning and control. In International Conference on Machine Learning, pp. 7847-7856.
PMLR, 2020.
Evan Shelhamer, Jonathan Long, and Trevor Darrell. Fully convolutional networks for
semantic segmentation. IEEE Trans. Pattern Anal. Mach. Intel l., 39(4):640-651, 2017.
doi: 10.1109/TPAMI.2016.2572683.
Shiyu Tang, Ruihao Gong, Yan Wang, Aishan Liu, Jiakai Wang, Xinyun Chen, Fengwei Yu,
Xianglong Liu, Dawn Song, Alan Yuille, et al. Robustart: Benchmarking robustness on
architecture design and training techniques. arXiv preprint arXiv:2109.05211, 2021.
Jingdong Wang, Ke Sun, Tianheng Cheng, Borui Jiang, Chaorui Deng, Yang Zhao, Dong
Liu, Yadong Mu, Mingkui Tan, Xinggang Wang, Wenyu Liu, and Bin Xiao. Deep high-
resolution representation learning for visual recognition. CoRR, abs/1908.07919, 2019a.
Po-Wei Wang, Priya Donti, Bryan Wilder, and Zico Kolter. Satnet: Bridging deep learning
and logical reasoning using a differentiable satisfiability solver. In International Confer-
ence on Machine Learning, pp. 6545-6554. PMLR, 2019b.
Ezra Winston and J. Zico Kolter. Monotone operator equilibrium networks. In Hugo
Larochelle, Marc’Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien
Lin (eds.), Advances in Neural Information Processing Systems 33: Annual Conference
on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020,
virtual, 2020.
Cihang Xie and Alan L. Yuille. Intriguing properties of adversarial training at scale. In
8th International Conference on Learning Representations, ICLR 2020, Addis Ababa,
Ethiopia, April 26-30, 2020. OpenReview.net, 2020.
Cihang Xie, Mingxing Tan, Boqing Gong, Jiang Wang, Alan L Yuille, and Quoc V Le. Adver-
sarial examples improve image recognition. In Proceedings of the IEEE/CVF Conference
on Computer Vision and Pattern Recognition, pp. 819-828, 2020.
Xingyu Xie, Jianlong Wu, Guangcan Liu, Zhisheng Zhong, and Zhouchen Lin. Differen-
tiable linearized admm. In International Conference on Machine Learning, pp. 6902-6911.
PMLR, 2019.
Xingyu Xie, Jianlong Wu, Guangcan Liu, Zhisheng Zhong, and Zhouchen Lin. Optimization
induced deep equilibrium networks. arXiv preprint arXiv:2105.13228, 2021.
Chong You, Daniel Robinson, and Rene Vidal. Scalable sparse subspace clustering by
orthogonal matching pursuit. In Proceedings of the IEEE conference on computer vision
and pattern recognition, pp. 3918-3927, 2016.
Bohang Zhang, Tianle Cai, Zhou Lu, Di He, and Liwei Wang. Towards certifying l infinity)
robustness using neural networks with l infinity-dist neurons. CoRR, abs/2102.05363,
2021.
Hongyang Zhang, Zhouchen Lin, Chao Zhang, and Edward Y Chang. Exact recoverability
of robust pca via outlier pursuit with tight recovery bounds. In Twenty-Ninth AAAI
Conference on Artificial Intel ligence, 2015.
12
Published as a conference paper at ICLR 2022
Quanshi Zhang and Song-Chun Zhu. Visual interpretability for deep learning: a survey.
arXiv preprint arXiv:1802.00614, 2018.
Quanshi Zhang, Ying Nian Wu, and Song-Chun Zhu. Interpretable convolutional neu-
ral networks. In 2018 IEEE Conference on Computer Vision and Pattern Recogni-
tion, CVPR 2018, Salt Lake City, UT, USA, June 18-22, 2018, pp. 8827-8836. Com-
puter Vision Foundation / IEEE Computer Society, 2018a. doi: 10.1109/CVPR.
2018.00920. URL http://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_
Interpretable_Convolutional_Neural_CVPR_2018_paper.html.
Xiao Zhang, Lingxiao Wang, Yaodong Yu, and Quanquan Gu. A primal-dual analysis of
global optimality in nonconvex low-rank matrix recovery. In International conference on
machine learning, pp. 5862-5871. PMLR, 2018b.
13
Published as a conference paper at ICLR 2022
A Appendix
A.1 Paralleling Multi-Branch OptEqs
Experiments show that even a simple one-layer OptEqs module enjoys impressive generaliza-
tion abilities. If we view a simple one-layer OptEqs module as a powerful feature generator,
we can use an "ensemble" scheme on the DEQs by paralleling several DEQ modules. Then we
get the multi-branch implicit structure (formulated as Eqn 10), which is capable of utilizing
samples of multi-resolution but also retains the capability of recovering to an optimization
problem.
z 1 = Wlb (Wιz1 + U1 g (x) + bl),
......	(10)
z L = W >b (W L z L + U Lg (x) + b L ),
where Z * denotes the equilibrium outputs of i-th branch, We call this structure Parallel-
OptEqs (POptEqs). Like (Xie et al., 2021) stated for OptEqs, the POptEqs can also be
depicted as solving the following problem (Eqn 11) if Wi is invertible and σ(∙) is activation
function,
L
min G(z1, ..., zL; g(x)) = min	1>f(Wi-1>zi) - Uig(x) + bi, Wi-1>z
z1,...,zL	z1,...,zL
i=1	(11)
+ 2IlW-1 >Zikk - 1 kzik2 ,
where g(x) is the input feature with raw input x, zi ∈ Rdi ×1 and f added for the activation
function. For example f is the positive orthant f(x) = I{x ≥ 0} if we use ReLU activation,
since (I + ∂f)-1 is the ReLU activation function, other activation functions can be found
in Li et al. (2019).The calculation of the above structure (Eqn 10) is equivalent to solving
the stationary points VZiG = 0.
A.2 Adversarial Perturbations.
Adversarial perturbations aim to cheat well-trained neural networks with small or unnotice-
able changes on natural images. The adversarial perturbations can be obtained by solving
the following maximum problem for input xnat and label y:
max L(fN N (xnat + δ); y),
δ∈C
where C is the feasible set of δ in case the change is too large and usually chosen to be
an l-infinite ball. Due to the neural network is a non-convex function for δ, obtaining the
perturbation is not easy. The most popular method is the PGD-k method which solves the
above problem by implementing the projected gradient method by k times. Although the
performance of such a method is satisfactory in most cases, it makes the whole training
procedure k + 1 times slower than the origin. In our work, we replace the above objective
function with our model’s hidden objective function. Since the hidden optimization prob-
lem is convex with respect to the perturbation, we can get the perturbation much easier.
Moreover, such perturbation can also enhance the generalization abilities, as shown in the
experiments.
A.3 Proofs for Proposition.1
In this section, we are going to prove that the equilibrium equation Eqn 1 is also the first
order stationary points for the optimization problem 5.
14
Published as a conference paper at ICLR 2022
Proof 1 The equilibrium equations Eqn 1 in the proposition can be separated into different
branches as follows:
Z1 = Wlrb (W1 h 1 (z1, ZL, Z2)+ U1 g(x) + b1),
Zi = WJσ (Wihi(zi,Zi Zi+ι) + Uig(x) + b),	(12)
ZL = WLσ (WLhL (zL, ZL-1, Z1) + ULg(x) + bL),
where hi : Rdi × Rdi +1 × Rdi-1 T Rdi can be defined as:
hi (z i, z i— 1, z i +1) =2(P i ：i +1Z i +1 + P T-1: i z i—1)
—2VeC(VeC- 1(Pi：i+凤+1)Sign [Mi：i+1 - diag(Mi：i +1)])	(13)
—2 vec(vec-1 (p 3：iz-I)Sign [M 3： i- diag(M i-1： i)]),
where
M i ： i+1 = vec - 1(P i ： i+1Z i+1)r vec - 1(z i).
First, we need to prove that
1 L
h(zi, zi-1, zi +1) = - 2 Vzi ɪ2[λD(zi, zi+1) — H(zi, Zi+1)]
i=1
(14)
The derivatives for the right term can be divided as the derivatives for H and D:
LL
Vzi	H(z k, zk +1) = VZi EZ r P k ： k +1Z k +1
k=1	k=1
=VZi (zr Pi：i +1Zi +1 + Zr- 1Pi-1：iZi )
= Pi：i+1zi+1 + Pi-1：izi-1
which is the first term of hi. Then we are going to calculate the derivatives for D:
L	Lc c
Vzi	D(Z k, z k +1) = V z iΣΣ Σ I Vec - 1(z k)(kI) T vec - 1(P k ： k+1Z k +1)(k 2) ∣
k =1	k = 1 k ι = 1 k 2 = k 1
(c c
X X Ivec- 1(zi)(k 1)TVeCT(Pi：i+1Zi+1)(k2)∣
k1=1 k26=k1
cc
+ XX Ivec- 1(zi-1)(k 1)TVeCT(Pi-1：iZi)(k2)∣ I
k1=1 k26=k1
一	/ C C
=vec VVeCT(Zi) IX X IVeCT(Zi)(kI)TVeCT(Pi：i+1Zi +1)(k2)∣
∖k 1=1k 2 = k 1
+ X X Ivec- 1(zi-1)(k1)TVeCT(Pi-1：iZi)(k2)∣ H
k1=1 k26=k1
with the fol lowing equation holds for the sampling matrix Pi-1：i and sampling is done for
each channel independently:
vec - 1(z i-1)(k 1)T vec - 1(P i-1：讯)(k 2) = vec - 1(P T-1： i z -1)( k 1)T vec - 1(z i)(k 2)
15
Published as a conference paper at ICLR 2022
The equation can be formulated as:
1 L
NZi 2 ED(Zk
“k = 1
(c c
X X IVeCT(Zi)(k 1)TVeCT(Pi” +ιzi +ι)(k2)∣
k ι = 1k 2= k ι
+ XX IVeCT(P - izi_ι)(ki)TVeCT(Zi)(k2) ∣ ∣1
k1=1 k26=k1
Since
c
Rvec-i(zi) E E IVeCT(Zi)(kI)TVeCT(Pi：i +ιzi +ι)(k2)i
k1=1 k26=k1
R VeC - i(z ° W (X X IVeCT(Zi)(k1) T VeCT(Pi ： i +ιz i +1)(k 2) i ) ,..., V VeC-I(Z。)(C)(∙∙∙)
k1=1 k26=k1
L
X Sign(VeC- 1(zi)(I)TVeC- 1(Pi：i+ιzi +i)(k2))VeC- 1(Pi：i +ιzi+i)(k2),
k26=1
L
X Sign(VeC-1 (Zi产)TVeC- 1(Pi：i十用十。(k2))VeC- 1(Pi：i +1 Zi +1)(k2)
k 2 = C	_
=VeC - 1(P i ： i +1Z i +1 )sign[VeC - 1(P i ： i 十闻十。T VeC - 1(z i) — diag(VeC - 1(P i ： i 十凤+1) t VeC - 1(z i))]
=VeC - 1(P i ： i +1Z i +1 )sign[M i ： i +1 — diag(M i ： i+1)],
In the same manner, we can get,
cc
vVeC-i(zi) X X IVeCT(Pt- 1：iZi-1)(k1)TVeCT(Zi)(k2)i
k1=1 k26=k1
=VeC-1(P - 1： i z i- 1)sign[M-1： i — diag(M -1： i)]
Taking all the terms together, we’ve proved the correctness of Eqn 14. Then we can proved
the relationships between Eqn 12 and the first-order stationary points for Eqn 5. Take Zi for
an example:
L1
0 = VZiE ITf(W-1TZi) — (Uig(x) + bi, W-1Tz)+ - (XD(Zi&+1) + ∣∣W-1TZ∕∣2 — H(&, &+1))
i=1 L	-
0 = W- 1(I + ∂f )(W-1Tzi) — W- 1(Uig(x) + bi) — h(zi, Z-, Zi+1)
Then we can get the equilibrium equation:
Zi = Wτσ(Wihi(zi, zi-1, zi +1) + Uig(x) + bi),
the proof is the same for all i. In this manner, we proved the relations between the structure
and the optimization problems. The proof for the proposition is complete.
A.4 Proofs for Proposition.2
Proof 2 From the preliminaries above, the difference between G(z!^; g(x) — δ) and
G(z*; g(x)) with δ = eSIGN(UTW-1TZ*) is as fol lows:
G(z0*; g(x) — δ) — G(z*; g(x)) = G(z0*; g(x)) — G(z*; g(x)) +〈esign(UTW-1TZ*), UTW-1TZ0*)
Since z* is the minimizer of G at g(x), the above function can be converted as fol lows:
G(z0*; g(x) — δ) — G(z*; g(x)) ≥〈esign(UTW-1TZ*), UTW-1TZ0*)
=e∣∣UTW-1Tz*∣∣1 —〈esign(UTW-1TZ*), UTW-1T(z* — Z0*)》
16
Published as a conference paper at ICLR 2022
From the structure of OptEqs, we can get:
eSIGN(UT WTTZ*)τUT WTT (Z* - Z'*)
≤e∣∣U>WTT(z* - Z,*)∣∣1
≤√NekUTWTT(z* - z/*)k2
≤√NekUTe(WZ* + Ug(x) + b) - σ(WZ,* + U(g(X)- S) + b)) k2
≤√Nekσ(WZ* + Ug(x) + b) - σ(WZ,* + U(g(x) - δ) + b) ∣∣2
≤√Nek Wz* + Ug(x) + b - WZ/* - U(g(x) - S) - b||2
≤√Nβ∣ W(z* - z/*) + USk2
≤√Ne∣ W(z* - z/*)k2 + √N(^∣∣USk2
≤√Nβ∣z/* - z*k2 + Ne2
The inequality is acquired because of the Lipshitzness of common activation function (ReLU
and Leacky ReLU) and the bounds on weight matrices. With the above results, we can get:
G(z/*； g(x) - S) - G(z*; g(x)) ≥ ekUTWTTZ*∣i -√Ne∣∣z'* - Z*k2 - Ne2
Then we can obtain the proposition:
max nG(zZ; g(x) - S) - G(z*; g(x)), √Ne∣∣z/* - Z*k2} ≥ 1 {e∣∣UTWTTZ*∣i - Ne2}
The proofs are similar when considering the HH&D modules.
A.5 Forward Process of our MOptEqs’ implicit part.
The forward propagation is illustrated as follows:
Algorithm 1: Forward Process of our MOptEqs’ implicit part.
Require: Input x, initial points {zi}iL=1 , perturbation size e, S0 = 0, maximum
perturbation size e.
Ensure: Equilibrium points{zi }iL=1
Calculate the input feature g(x).
The calculation of VZG(Z; g(x)) = 0 is the same as finding the equilibrium points
Tθ = V z G + Z = Z
.
Use Broyden (Broyden, 1965) or Anderson Method (Anderson, 1965) or others to find
roots of the following equation like MDEQ:
Tθ (Z; g (x)) = Z
return Z = {Z*}L=ι
And the calculation of Tθ is shown as follows:
17
Published as a conference paper at ICLR 2022
Algorithm 2: The Calculation of Tθ = VZG + Z at (Z,g(x)).
Require: Input feature g(x), initial points {zi}iL=1 , perturbation size , δ0 = 0, maximum
perturbation size .
Ensure: Output Tθ = VZG(Z; g(x)) + Z
for i ∈ RANGE(1, L) do
kι, k2 - neighbor of i in L-loop
Calculate Zpi by hi (Shown in Figure 1 (b)):
Z Pi《-hi (Zi, z i— 1, Zi +1)
if Use PE Method then
yi J σ (WiZPi + Ui (g(X)- δi-1)+ bi)
δi J eSIGN(UJy)
else
yi J σ(WiZPi + Uig(x) + bi)
end if
Zi J Wi>yi
end for
return {Z↑}L=ι
A.6 Experiments details of MOptEqs for the experiments Classification.
A.6.1 CIFAR-10
For classification tasks of single-view models, we set the channel number of each branch to
32, λ = 0.01 and perturbation size = 0.1 for the small MOptEqs with three branches for the
single-view comparison as OptEqs. The batch size is set to be 128 for all the experiments.
As for the multi-scale models’ comparison, we use four branches with each branch take
inputs with resolutions equals 32, 16, 8, 4 like MDEQ, the output channel number for each
branch is 256 for MOptEqs with 1.9M learnable parameters. At the same time, we set
the channel number to be 128 for MOptEqs with 0.48M learnable parameters. And we set
λ = 0.001 and perturbation size = 0.1 for the experiments.
We use the widely used SGD algorithm for training procedure. We set weight decay to be
0.001 and the initial learning rate start from 0.1 and decay by 0.1 at 100, 150, 175-th epoch
with 200 epochs in total like others. We use the standard data augmentation for all the
experiments.
Our implementation for small MDEQ only changes the channel number of MDEQ’s 10M
model to obtain the comparable size with our model, without changing the training settings
and its hyper-parameters.
A.6.2 CIFAR-100
Except for CIFAR-10, we also finish the experiments on CIFAR-100 classification2 to fur-
ther verify our model’s effectiveness. The model we used is the same as the models used
in the multi-scale comparison, only changing the output from 10 to 100 for classification.
MDEQ with 11M parameter is the same model as (Bai et al., 2020) proposed for CIFAR-10
experiment with only changing the output from 10 to 100 for CIFAR-100. Moreover, the
hyper-parameter setting is also the same as (Bai et al., 2020) proposed in the paper.
We use the widely used SGD algorithm for training procedure. We set weight decay to be
0.001 and the initial learning rate start from 0.1 and decay by 0.1 at 100, 150, 175-th epoch
with 200 epochs in total like others. We use the standard data augmentation for all the
experiments.
2https://www.cs.toronto.edu/ kriz/cifar.html
18
Published as a conference paper at ICLR 2022
(a)	Plot of small MOptEqs’ convergence
with respect to different λ.
(b)	Plot of multi-scale
MOptEqs’ (λ = 0.001) convergence.
Figure 4: The convergent iterations’ of our
MOptEqs (λ = 0.001) forward propagation. Relative error is defined as
forward root-finding procedure used for our
kTj+1 -Tj k2
-kTjk2-
A.6.3 ImageNette
Besides the classification for images with small size, we also conduct the experiments on the
Imagenette3 , which is a subset of 10 classes from ImageNet4 with 9469 training photos and
its test set consists of 3925 images. Furthermore, we use the full-size version of Imagenette5
further to verify the superiority of our models on large-scale images. The model architecture
for our MOptEqs and MDEQ (for comparison) is the same as the ones used in the multi-
scale models’ comparison for CIFAR-10 except adding two downsampling layers in the head
of models to downsample the input size from 256 to 64. As for the hyper-parameters, we
only change the weight decay to be 5e - 5, batch size to be 32 and extend the whole training
epochs to 200 with 100-th, 150-th, 175-th for the learning rate decay for all the models. All
the hyper-parameters for both MOptEqs and MDEQs are hardly changed during all the
datasets.
A.7 Convergence validation for our MOptEqs.
As shown in Figure 4(a), the Anderson method can quickly find the equilibrium points
for our small MOptEq used for single-view comparison. From the figure, one can see that
MOptEqs with proper λ (around or smaller than *,around 0.03 in this circumstance) can
ensure the whole mappings be contractive. But too large λ will make the mo del hard to
converge or even fail.
Apart from plotting the convergent iterations’ of our forward root-finding procedure for the
small MOptEqs (shown in Figure 4 (a)), we also draw figures to show the convergence of the
forward propagation for our multi-scale MOptEqs (λ = 0.001) used in the imagenette and
CIFAR experiments as Figure 4 (b) shown. We use the pre-trained model on Imagenette
whose prediction accuracy is reported in the above sections. One can see that our multi-scale
MOptEqs can also quickly converge to the equilibrium points as we expected.
A.8 Ablation Studies on the impact of D and H part
In this section, we analyzed the influence of our D and H term for a single-branch MOptEq
model trained without PE method shown in Table. 3. We set λ = 0.02 for the experiment.
From the table, one can see that the contribution of the H term is slightly higher than
the diversity term. But considering both two terms can significantly improve the results
comparing with MOptEqs without considering these two terms.
3https://github.com/fastai/imagenette/
4https://www.image-net.org/
5https://s3.amazonaws.com/fast-ai-imageclas/imagenette2.tgz
19
Published as a conference paper at ICLR 2022
Model	Natural Accuracy
MOptEqs	89.1%
-D	88.6%
-H	88.4%
- D, H	87.4%
Table 3: Evaluation on MOptEqs trained with and without considering D and H part.
A.9 Experiments on the ImageNet
Except CIFAR and Imagenette, we also conducted experiments on ImageNet with 13M
parameters shown as below:
Model	Model Size	Natural Accuracy
ResNet	13M	70.3%
HR-Net	13M	72.3%
MOptEqs	13M	72.5%
Table 4: Evaluation on MOptEqs on ImageNet.
From the results, one can see that our model can achieve the satisfying performance on
ImageNet compared with the state-of-the-art models.
A.10 PE method and robustness
From the above experiments, one can see that the PE method may also improve the ro-
bustness of our MOptEqs. In this section, we conduct experiments to see whether the PE
methods can further enhance the robustness of MOptEqs when we use adversarial training
methods on these models. We finish comparisons of PGD-3 training for the single-view
MOptEq with or without PE, and the result is shown as follows: From the table, we can
Model	Natural Accuracy	PGD-20 Accuracy(e =蔡)
PGD-3 w/o PE	78.60%	37.18%
PGD-3 w. PE	78.40%	38.05%
Table 5: Evaluation on MOptEqs trained by PGD-3 with and without PE method.
conclude that our PE method can improve the robustness of our MOptEqs model trained
by the adversarial training method. Such advantages also demonstrate the superiority of
our models’ mathematical interpretability since the PE method is acquired based on the
model’s hidden optimization problem.
A.11 Other Training methods: Fixed Point method and One-step gradients
A.11.1 Methods
Since our model is not so complicated, we can use the fixed point method for L iteration for
the forward propagation. While for the back propagation, we can use BPTT (Mozer, 1989)
and (Geng et al., 2021) proposed method, which only backward the final forward iterations
using the chain rule:
∂L	∂L ∂TΘL
-- -------Z---——
∂ (■)	∂ TL ∂( ∙)
where θ ∈ Θ are the learnable parameters for the implicit models, TΘL denotes the output z
for the L-th fixed-point iteration. Since the back-propagation of such a strategy is similar
20
Published as a conference paper at ICLR 2022
to backwards only a single layer of DNN module without the calculation of root-finding
algorithm for the Jacobian in the implicit differentiation, the computational cost is much
less than the implicit method. However, the gradient approximated by such a method is
not accurate and may cause the performance drop. However, as we illustrated below, such
a method can be regarded as a trade-off if the computational resources of training are not
enough.
A.11.2 Empirical Results and Computational Efficiency of One-stpe
Gradient
We take the ImageNette dataset as an example, the training memory cost, forward time,
and test accuracy are shown as follows (each batch contains 32 images and is finished on 2
x GTX 1080Ti for 200 epochs):
Model	Memory/Batch	Infer Time/Batch	Total Time	Accuracy
MDEQ	8GB	1.06s	9h	91.42%
MOptEq(one step)	3GB	0.26s	3h	91.21%
Table 6: The comparison of the computational cost of MDEQ and our MOptEqs (trained
by one-step gradient).
The results shows that the one-step gradient methods can save a lot computation resources
while with slightly drop on the performance.
21