Published as a conference paper at ICLR 2022
Efficient and Differentiable Conformal Pre-
diction with General Function Classes
Yu Bai
Salesforce Research
yu.bai@salesforce.com
Song Mei
UC Berkeley
songmei@berkeley.edu
Huan Wang & Yingbo Zhou & Caiming Xiong
Salesforce Research
{huan.wang, yingbo.zhou, cxiong}@salesforce.com
Ab stract
Quantifying the data uncertainty in learning tasks is often done by learning a pre-
diction interval or prediction set of the label given the input. Two commonly
desired properties for learned prediction sets are valid coverage and good effi-
ciency (such as low length or low cardinality). Conformal prediction is a power-
ful technique for learning prediction sets with valid coverage, yet by default its
conformalization step only learns a single parameter, and does not optimize the
efficiency over more expressive function classes.
In this paper, we propose a generalization of conformal prediction to multiple
learnable parameters, by considering the constrained empirical risk minimization
(ERM) problem of finding the most efficient prediction set subject to valid em-
pirical coverage. This meta-algorithm generalizes existing conformal prediction
algorithms, and we show that it achieves approximate valid population coverage
and near-optimal efficiency within class, whenever the function class in the con-
formalization step is low-capacity in a certain sense. Next, this ERM problem
is challenging to optimize as it involves a non-differentiable coverage constraint.
We develop a gradient-based algorithm for it by approximating the original con-
strained ERM using differentiable surrogate losses and Lagrangians. Experiments
show that our algorithm is able to learn valid prediction sets and improve the
efficiency significantly over existing approaches in several applications such as
prediction intervals with improved length, minimum-volume prediction sets for
multi-output regression, and label prediction sets for image classification.
1 Introduction
Modern machine learning models can yield highly accurate predictions in many applications. As
these predictions are often used in critical decision making, itis increasingly important to accompany
them with an uncertainty quantification of how much the true label may deviate from the prediction.
A common approach to quantifying the uncertainty in the data is to learn a prediction set—a set-
valued analogue of usual (point) predictions—which outputs a subset of candidate labels instead of
a single predicted label. For example, this could be a prediction interval for regression, or a discrete
label set for multi-class classification. A common requirement for learned prediction sets is that it
should achieve valid coverage, i.e. the set should cover the true label with high probability (such as
90%) on a new test example (Lawless & Fredette, 2005). In addition to coverage, the prediction set
is often desired to have a good efficiency, such as a low length or small cardinality (Lei et al., 2018;
Sadinle et al., 2019), in order for it to be informative. Note that coverage and efficiency typically
come as a trade-off, as it is in general more likely to achieve a better coverage using a larger set.
This paper is concerned with the problem of finding the most efficient prediction set with valid
coverage. Our approach builds on conformal prediction (Vovk et al., 2005), a powerful framework
for generating prediction sets from (trained) base predictors with finite-sample coverage guarantees.
Code available at https://github.com/allenbai01/cp-gen.
1
Published as a conference paper at ICLR 2022
Figure 1: Comparison of vanilla conformal prediction and our CP-Gen for learning a prediction interval with
90% nominal coverage on a real-world regression task. Left: The function class {Ct} is the prediction intervals
used by Conformalized Quantile Regression. Right: {Cθ,t} is a larger class of intervals used by our conformal
quantile finetuning procedure with the same base predictor; here the additional trainable parameter θ is the last
linear layer within the quantile neural network (cf. Section 5.1 and Appendix E.3 for more details).
0.5	Len(QftS))	Len(Cft), a%))	1.5
Length
Conformal prediction has been used for learning prediction sets in a variety of tasks in regres-
sion (Lei & Wasserman, 2014; Lei et al., 2018; Romano et al., 2019), classification (Cauchois et al.,
2020b; Romano et al., 2020; Angelopoulos et al., 2020), structured prediction (Bates et al., 2021),
and so on. However, the conformalization step in conformal prediction by default does not offer the
flexibility for optimizing additional efficiency metrics, as the efficiency is already determined by the
associated score function and the target coverage level. As a concrete example, the Conformalized
Quantile Regression algorithm learns a single width adjustment parameter that turns a two-sided
quantile predictor into a prediction interval of valid coverage (Romano et al., 2019); however, it
does not offer a way of further optimizing its length (cf. Figure 1 Left).
For certain efficiency metrics and prediction tasks, several approaches have been proposed, for ex-
ample by designing a better score function (Angelopoulos et al., 2020), using base predictors of a
specific form (Izbicki et al., 2019; 2020; Sadinle et al., 2019), or selecting a best training hyperpa-
rameter (Yang & Kuchibhotla, 2021). However, optimizing the efficiency for more general tasks
or efficiency metrics still largely requires “manual” efforts by the researcher, as it (1) often relies
on specific domain knowledge about the task at hand; (2) is often done in conjunction with confor-
mal prediction in multiple rounds of trial-and-error; (3) is often done by reasoning about high-level
properties of the efficiency loss and coverage constraints (e.g. what makes the length short), but not
by directly optimizing the efficiency-coverage trade-off in a data-dependent way. To the best of our
knowledge, there is a lack of a more principled and unified approach for optimizing any efficiency
metric subject to valid coverage over any class of prediction sets.
In this paper, we cast the above task as a constrained empirical risk minimization (ERM) problem
of optimizing the efficiency subject to the coverage constraint, over any general function class of
prediction sets with potentially multiple learnable parameters. This is motivated by a simple obser-
vation that vanilla conformal prediction is already equivalent to solving such a constrained ERM
with one learnable parameter (Section 2.1). Overall, our algorithm can be viewed as an automatic
and data-dependent approach for optimizing the efficiency simulatneously with conformal predic-
tion. Our contributions are summarized as follows.
•	We propose CP-Gen (Conformal Prediction with General Function Class), a generalization of
conformal prediction to learning multiple parameters. CP-Gen selects within an arbitrary class
of prediction sets by solving the constrained ERM problem of best efficiency subject to valid
empirical coverage (Section 3.1), and is a systematic extension of existing algorithms.
•	We show theoretically that CP-Gen achieves approximately valid coverage and near-optimal ef-
ficiency within class, whenever the class is low-capacity with respect to both the coverage and
the efficiency loss (Section 3.2, with concrete examples in Appendix C). We also provide a prac-
tical variant CP-Gen-Recal using data splitting and reconformalization, which achieves exact
coverage, as well as good efficiency under additional assumptions (Section 3.3).
•	To address the issue that CP-Gen and CP-Gen-Recal involve a non-differentiable coverage
constraint, we develop a differentiable approximation using surrogate losses and Lagrangians
(Section 4). This allows us to solve the constrained ERM problem over higher-dimensional con-
tinuous parameter spaces via gradient-based optimization, and is more flexible than existing al-
gorithms that require discretization and brute-force search.
2
Published as a conference paper at ICLR 2022
•	We empirically demonstrate that CP-Gen-Recal with our gradient-based implementation can
learn prediction sets with valid coverage and significantly improved efficiency on three real-data
tasks: prediction intervals for regression with improved length, minimum-volume prediction sets
for multi-output regression, and label prediction sets for ImageNet (Section 5 & Appendix F).
We illustrate our main insight via the coverage-vs-efficiency trade-off plots in Figure 1: While
vanilla conformal prediction only learns a single parameter (within its conformalization step) by a
simple thresholding rule over a coverage-efficiency curve, our CP-Gen is able to further improve
the efficiency by thresholding a region formed by a larger function class.
1.1 Related work
Learning prediction sets via conformal prediction The framework of conformal prediction for
learning prediction sets is originated in the early works of (Vovk et al., 1999; 2005; Shafer & Vovk,
2008). The main advantage of conformal prediction is that it yields (marginal) coverage guarantees
regardless of the data distribution (i.e. distribution-free). More recently, conformal prediction has
been applied to a variety of uncertainty quantification tasks, such as prediction intervals for regres-
sion (Papadopoulos, 2008; Vovk, 2012; 2015; Lei & Wasserman, 2014; Vovk et al., 2018; Lei et al.,
2018; Romano et al., 2019; Izbicki et al., 2019; Guan, 2019; Gupta et al., 2019; Kivaranovic et al.,
2020; Barber et al., 2021; Foygel Barber et al., 2021), label prediction sets for classification problems
(Lei et al., 2013; Sadinle et al., 2019; Romano et al., 2020; Cauchois et al., 2020b;a; Angelopoulos
et al., 2020), and prediction sets for structured output (Bates et al., 2021).
Optimizing efficiency in addition to valid coverage The problem of finding a prediction set with
(approximate) valid coverage and small size has been considered, e.g. in Pearce et al. (2018); Chen
et al. (2021) for regression and Park et al. (2019) for classification; however, these approaches do not
use conformal prediction. Yang & Kuchibhotla (2021) propose to minimize the length of the confor-
mal interval over either a finite class or a linear aggregation of base predictors, and provides coverage
and efficiency guarantees. All above works formulate this task as a risk minimization problem, yet
are restricted to considering either finite classes or specific efficiency loss functions. Our work is
inspired by (Yang & Kuchibhotla, 2021) and generalizes the above works by allowing any function
class and efficiency loss, along with providing a differentiable approximate implementation.
The problem of optimizing the efficiency can also be done by utilizing structures of the particular
efficiency loss to choose a specific base predictor and an associated prediction set (Lei & Wasserman,
2014; Sadinle et al., 2019; Izbicki et al., 2019; 2020). By contrast, our approach does not require
either the efficiency loss or the base predictor to possess any structure, and is thus complementary.
Other algorithms and theory An alternative line of work constructs prediction intervals / predic-
tion sets by aggregating the prediction over multiple base predictors through Bayesian neural net-
work (Mackay, 1992; Gal & Ghahramani, 2016; Kendall & Gal, 2017; Malinin & Gales, 2018; Mad-
dox et al., 2019) or ensemble methods (Lakshminarayanan et al., 2016; Ovadia et al., 2019; Huang
et al., 2017; Malinin et al., 2019). However, these methods do not typically come with (frequentist)
coverage guarantees. The recent work of Hoff (2021) studies ways of enhancing Bayes-optimal pre-
diction with frequentist coverage. Prediction intervals can also be obtained by parameter estimation
using a parametric model for the data (Cox, 1975; Bjornstad, 1990; Beran, 1990; Barndorff-Nielsen
& Cox, 1996; Hall et al., 1999; Lawless & Fredette, 2005); see (Tian et al., 2020) for a review. How-
ever, the coverage of such prediction intervals relies heavily on the parametric model being correct
(well-specified), and can even fail in certain high-dimensional regimes where the model is indeed
correct (Bai et al., 2021).
2 Preliminaries
Uncertainty quantification via prediction sets We consider standard learning problems in which
we observe a dataset D of examples (xi , yi) ∈ X × Y from some data distribution, and wish to
predict the label y from the input x. A prediction set is a set-valued function C : X → 2Y where
C(x) is a subset of Y. Two prevalent examples are regression (Y = R) in which we can choose
C(x) ⊂ R as a prediction interval, and (multi-class) classification (Y = [L] := {1, . . . , L}) in
which we can choose C(x) ⊂ [L] as a (discrete) label prediction set.
3
Published as a conference paper at ICLR 2022
Coverage and efficiency The (marginal) coverage probability (henceforth coverage) of a predic-
tion set C is defined as
Coverage(C) := P(Y ∈ C(X))
where (X, Y ) is a test example from the same data distribution. We also define the (mis)-coverage
loss Lcoverage(C) := 1 - Coverage(C) = P(Y ∈/ C(X)). A learned prediction set is often desired
to achieve valid coverage in the sense that Coverage(C) ≥ 1 - α for some α ∈ (0, 1). Here 1 - α
is a pre-determined target coverage level; typical choices are e.g. 1 - α ∈ {90%, 95%}, which
corresponds to picking α ∈ {0.1, 0.05}.
In addition to valid coverage, it is often desired that the prediction set has a good efficiency (such as
small size). This is motivated by the fact that valid coverage can be achieved trivially if we do not
care about the size, e.g. by always outputting C = Y, which is not informative. Throughout this
paper We will use 'eff to denote the particular efficiency loss We care about, where 'eff (C; (x, y))
measures the efficiency loss of C on an example (x, y), such as the length (Lebesgue measure) of
prediction intervals, or the size (cardinality) of label prediction sets.
Nested set framework We adopt the nested set framework of (Gupta et al., 2019) for convenience
for our presentation and analysis. A family {Ct}t∈T⊂R is said to be a (family of) nested sets if
t ≤ t0 implies that Ct(x) ⊂ Ct0 (x) for all x ∈ X. Throughout this paper out notation Ct or
Cθ,t are assumed to be nested sets with respect to t. We assume that our efficiency loss `eff is
non-decreasing w.r.t. its (set-valued) argument, i.e. 'eff (C; (χ,y)) ≤ 'eff (C0; (x, y)) if C ⊆ C0.
Therefore, for nested sets the loss t 7→ `eff (Ct; (x, y)) is non-decreasing in t. As the coverage loss
L(Ct) = P(Y ∈/ Ct (X)) (and its empirical version) is instead non-increasing in t, the efficiency
loss and the coverage loss always comes as a trade-off.
2.1 Conformal prediction
Conformal prediction (Vovk et al., 2005; Lei & Wasserman, 2014) is a powerful technique for learn-
ing prediction sets with coverage guarantees. The core of conformal prediction is its conformaliza-
tion step, which turns any base prediction function (or training algorithm) into a prediction set.
We here briefly review conformal prediction using the vanilla (split) conformal regression method
of (Lei et al., 2018), and refer the readers to (Angelopoulos & Bates, 2021) for more examples.
Given any base predictor f : X → R (potentially learned on a training dataset Dtrain), conformal
prediction outputs a prediction interval
Ctb(x) := f (x) -bt,f(x) + bt,	(1)
where bt ∈ R≥0 is chosen as the (1 - α)-quantile1 of |y - f (x)| on a calibration dataset Dcal with
size ncal := |Dcal| using the following conformalization step:
tb= d(1 - α)ncale -th largest of {|yi - f (xi)|}in=ca1l.	(2)
The main guarantee for the learned interval Cbt is that it achieves a (1 - α) coverage guarantee of
the form PDcal,(X,Y)(Y ∈ Cbt(X)) ≥ 1 - α (Lei et al., 2018, Theorem 2.2). The proof relies on the
exchangeability between the scores {|yi - f(xi)|}in=ca1l and |Y - f(X)|, which allows this guarantee
to hold in a distribution-free fashion (i.e. for any data distribution).
Conformal prediction as a constrained ERM with one parameter We start by a simple re-
interpretation that the conformalization step (2) is equivalent to solving a constrained empirical risk
minimization (ERM) problem with a single learnable parameter t (cf. Appendix A for the proof).
Proposition 1 (Conformal regression as a constrained ERM with one learnable parameter). The
， 个 一 TΓħ 1 r 1 ∙	∕c∖ ∙ ,T	1	,,7 r ιι ♦	，	∙ I τ->τ-> λ æ 1 ι
parameter t ∈ R defined in (2) is the solution to the following constrained ERM problem
1
minimize Leff (Ct):=—— 〉	'eff (Ct； (xi,yi)) = 2t
t≥0	ncal
cal i∈Dcal	3
(3)
1
SubjeCt to Lcoverage(Ct) :=	1	1 {yi ∈ Ct(Xi)} ≤ α∙
ncal i∈Dcal
1Technically (2) requires the d(1 - α)(nrecal + 1)e-th largest element to guarantee valid coverage (Vovk
et al., 2005); here we choose the close d(1 - α)nrecale-th largest to allow the following insight.
4
Published as a conference paper at ICLR 2022
Algorithm 1 Conformal Prediction with General Function Class (CP-Gen)
Input: Class of prediction sets C = {Cθ,t}θ∈Θ,t∈T ; target miscoverage level α ∈ (0, 1); ε0 ≥ 0.
Efficiency loss `eff ; Calibration dataset Dcal with size ncal .
1: Solve the following constrained ERM problem on dataset Dcal (with relaxation parameter ε0 ):
1
(θ,t) - arg min Leff (Cθ,t)∙=—— 5	'eff (Cθ,t(xi),yi)
θ∈Θ,t∈T	ncal i∈Dcal
1
subject to Lcoverage (Cθ,t) ：= ------ 1{ 1 {yi ∈ Cθ,t (Xi)} ≤ α + ε0.
ncal i∈Dcal
(5)
Output: Prediction set Cθb,bt .
Above, 'eff (C; (x, y)) = length(C(X)) is the length ofthe interval C(X).
Though simple, this re-interpretation suggests a limitation to the conformalization step (2) as well as
its analogue in other existing conformal methods: It only learns a single parameter t, and thus cannot
further optimize the efficiency due to the coverage-efficiency trade-off (cf. Figure 1). However, the
form of the constrained ERM problem (3) suggests that it can be readily extended to more general
function classes with more than one learnable parameters, which is the focus of this work.
3 Conformal prediction with general function classes
3.1	Algorithm
Our algorithm, Conformal Prediction with General Function Classes (CP-Gen; full description in
Algorithm 1), is an extension of the constrained ERM problem (3) into the case of general function
classes with multiple learnable parameters. CP-Gen takes in a function class of prediction sets
C := {Cθ,t(X) : θ ∈ Θ,t ∈ T ⊂ R},	(4)
where (as mentioned) we assume that {Cθ,t}t∈T is a nested set for each θ ∈ Θ. The parameter set Θ
as well as the form of Cθ,t in (4) can be arbitrary, depending on applications and the available base
predictors at hand. Given C, our algorithm then solves the constrained ERM problem (5) of finding
the smallest interval among C subject to valid coverage on dataset Dcal .
Compared with vanilla conformal prediction, Algorithm 1 allows more general tasks with an ar-
bitrary function class and efficiency loss; for example, this encompasses several recent algorithms
such as finite hyperparameter selection and linear aggregation (Yang & Kuchibhotla, 2021; Chen
et al., 2021). We remark that (5) includes an additional relaxation parameter ε0 ≥ 0 for the coverage
constraint. This is for analysis (for Proposition 2(b) & 7(b)) only; our implementation uses ε0 = 0.
3.2	Theory
An important theoretical question about CP-Gen is whether it achieves coverage and efficiency
guarantees on the population (test data). This section showcases that, by standard generalization
arguments, CP-Gen achieves approximate validity and near-optimal efficiency whenever function
class is low-capacity in a certain sense. We remark that our experiments use the modified algo-
rithm CP-Gen-Recal (Section 3.3) which involves a reconformalization step. Here we focus on
CP-Gen as we believe its theory could be more informative.
Let L{eff,coverage}(Cθ,t) := E['{eff,coverage}(Cθ,t； (X, Y))] denote the PoPUlation coverage and ef-
ficiency lossesfor any (θ, t). We define the following uniform concentration quantities:
εeff := supθ∈Θ,t∈T Leff (Cθ,t) - Leff (Cθ,t)
εcoverage := supθ∈Θ,t∈T
coverage
(Cθ,t ) - Lc
overage (Cθ,t )
(6)
(7)
^
L
5
Published as a conference paper at ICLR 2022
Algorithm 2 Conformal Prediction with General Fn. Class and Recalibration (CP-Gen-Recal)
Input: Class of prediction sets C = {Cθ,t}θ∈Θ,t∈T ; target miscoverage level α ∈ (0, 1); ε0 ≥ 0.
Efficiency loss `eff ; Calibration datasets Dcal, Drecal with size ncal, nrecal .
1:	Run Algorithm 1 on dataset Dcal (with relaxation parameter ε0) to obtain (θ, t).
2:	Keep θ, and reconformalize t ∈ T on the recalibration dataset Drecal :
brecai — inf {t ∈ T : yi ∈ °b,t(xi) for at least d(1 — α)(nrecai + 1)] examples (XiJyi) ∈ Drecaι}.
Output: Prediction set Cθb bt	.
θ,trecal
The following proposition connects the generalization of CP-Gen to the above uniform concentra-
tion quantities by standard arguments (see Appendix B for the proof. We remark that the proof relies
on Dcal being i.i.d., which is slightly stronger than exchangeability assumption commonly assumed
in the conformal prediction literature.)
Proposition 2 (Generalization of CP-Gen). The prediction set Cθb,bt learned by Algorithm 1 satisfies
(a)
i.e.
(b)
i.e.
(Approximately valid population coverage) We have
Lcoverage(Cθb,bt ) ≤ α + ε0 +
εcoverage,
the population coverage of Cθb,bt is at least 1 一 α 一 (ε0 + εcoverage).
(Near-optimal efficiency) Suppose ε0 ≥ εcoverage, then we further have
Leff (Cθb bt) ≤	inf	Leff (Cθ,t) + 2εeff,
e θ,t	(θ,t)∈Θ×T	e ,	e
Lcoverage (Cθ,t)≤α
Cθb,bt achieves 2εeff -near-optimal efficiency against any prediction set within C with at least
(1 - α) population coverage.
Examples of good generalization Proposition 2 shows that CP-Gen acheives approximate cov-
erage and near-optimal efficiency if the concentration terms εeff and effcoverage are small. In
Appendix C, we bound these on two example function classes: Finite Class (Proposition 4) and
VC/Rademacher Class (Proposition 5). Both classes admit bounds of the form {εeff , effcoverage } ≤
,Comp(C)∕ncai with high probability via standard concentration arguments, where Comp(C) is a
certain complexity measure of C. Combined with Proposition 2, our CP-Gen algorithm with these
classes achieve an 1 一 α 一 vzComp(C)∕ncai approximate coverage guarantee and ∙∖∕Comp(C)∕ncai
near-optimal efficiency guarantee. In particular, our Proposition 4 recovers the coverage guarantee
for the finite-class selection algorithm of (Yang & Kuchibhotla, 2021, Theorem 1) though our effi-
ciency guarantee is more general.
We remark that both examples above contain important applications. The finite class contains e.g.
optimizing over a K-dimensional hyperparameter to use via grid search, with e.g. (1∕δ)K confi-
dence sets and thus Comp(C) = O(log((1∕δ)K)) = O(K log(1∕δ)). The VC/Rademacher class
contains the important special case of linear classes with K base predictors (we defer the formal
statement and proof to Appendix C.3). Also, these examples are not necessarily exhaustive. Our
take-away is rather that we may expect CP-Gen to generalize well (and thus achieves good coverage
and efficiency) more broadly in practice, for instance whenever it learns K ncal parameters.
3.3 Algorithm with valid coverage via reconformalization
Although CP-Gen enjoys theoretical bounds on the coverage and efficiency, a notable drawback is
that it does not guarantee exactly valid (at least) 1 - α coverage like usual conformal prediction, and
its approximate coverage bound depends on the uniform concentration quantity εcoverage that is not
computable from the observed data without structural assumptions on the function class C .
To remedy this, we incorporate a simple reconformalization technique on another recalibration
dataset Drecal (e.g. a further data split), which guarantees valid finite-sample coverage by exchange-
ability. We call this algorithm CP-Gen-Recal and provide the full description in Algorithm 2.
6
Published as a conference paper at ICLR 2022
We remark that this reconformalization technique for obtaining guaranteed 1 - α coverage is widely
used in the conformal prediction literature, e.g. (Angelopoulos et al., 2020). However, to the best of
our knowledge, there is no known analysis for our CP-Gen-Recal algorithm for general function
classes, for which we provide a result below (formal statement and proof can be found in Proposi-
tion 7 & Appendix D). The proof of the coverage bound is standard as in the conformal prediction
literature, while the proof of the efficiency bound builds upon the result for CP-Gen (Proposi-
tion 2(b)) and handles additional concentration terms from the reconformalization step.
Proposition 3 (Coverage and efficiency guarantee for CP-Gen-Recal; Informal version).
The prediction set Cθb,bt	learned by Algorithm 2 achieves (1 - α) finite-sample coverage:
PDrecal,(X,Y) (Y ∈ Cθb,btrecal) ≥ 1 - α. Further, it achieves O(εeff +
εcoverage + 1∕√nrecal)仅。)
optimal efficiency under additional regularity assumptions.
4 Differentiable optimization
Our (meta) algorithms CP-Gen and CP-Gen-Recal involve solving the constrained ERM prob-
lem (5). One feasible case is when Θ is finite and small, in which we enumerate all possible θ ∈ Θ
and find the optimal t for each θ efficiently using quantile computation. However, this optimization
is significantly more challenging when the underlying parameter set Θ is continuous and we wish
to jointly optimize over (θ, t): The coverage loss Lcoverage(Cθ,t) is non-differentiable and its “gra-
dient” is zero almost everywhere as it uses the zero-one loss. This makes the coverage constraint
challenging to deal with and not amenable to any gradient-based algorithm.
To address this non-differentiability, we develop a gradient-based practical implementation by ap-
proximating the coverage constraint. We first rewrite each individual coverage loss into the form
1 {y ∈ Cθ,t(x)} = 1 {sθ,t(χ,y) < 0} = 'oι(sθ,t(χ,y)).
where '01(z) := 1 {z < 0} is the zero-one loss. (Such arewriting is possible in most cases by taking
sθ,t as a suitable “score-like” function; see Appendix E for instantiations in our experiments.) Then,
inspired by the theory of surrogate losses (Bartlett et al., 2006), We approximate '01 (z) by the hinge
loss `hinge(z) = [1 - z]+ which is (almost everywhere) differentiable with a non-trivial gradient.
We find the hinge loss to perform better empirically than alternatives such as the logistic loss.
To deal with the (modified) constraint, we turn it into an exact penalty term with penalty parameter
λ ≥ 0, and use a standard primal-dual formulation (Bertsekas, 1997) to obtain an unconstrained
min-max optimization problem on the Lagrangian:
min max Lbeff (Cθ,t) + λ Lbhinge (Cθ,t) - α ,
θ,t λ≥0	+
(8)
Where Lhinge(Cθ,t)：=急 Pn=1l 'hinge(sθ,t(xi, yi)) is the empirical hinge loss on the calibration
dataset Dcal. Our final practical implementation of (5) solves the problem (8) by Stochastic Gradient
Descent-Ascent (with respect to (θ, t) and λ) to yield an approximate solution (θ, t). We remark
that in our experiments where we use the reconformalized version CP-Gen-Recal, we only keep
^
^
the θ obtained from (8) and perform additional reconformalization to compute trecal to guarantee
coverage.
We also emphasize that the approximation in (8) makes the problem differentiable at the cost of
deviating from the true constrained ERM problem (5) and thus potentially may sacrifice in terms of
the efficiency. However, our experiments in Section 5 show that such an implementation can still
improve the efficiency over existing approaches in practice, despite the approximation.
5	Experiments
We empirically test our CP-Gen-Recal algorithm (using the practical implementation (8)) on
three representative real-data tasks. The concrete construction of {Cθ,t} will be described within
each application. Throughout this section we choose 1 - α = 90% as the nominal coverage level,
and use the CP-Gen-Recal algorithm to guarantee coverage in expectation. We provide ablations
with α ∈ {80%, 95%} in Appendix G.1 and G.2 and the CP-Gen algorithm in Appendix G.3.
Several additional ablations and analyses can be found in Appendix H.
7
Published as a conference paper at ICLR 2022
Table 1: Results for conformal quantile finetuning on real-data regression tasks at level 1 - α = 90%. For
each method we report the (test) coverage, length, and pinball loss of the corresponding base quantile predictor.
All results are averaged over 8 random seeds.
Dataset	CQR			QR + CP-Gen-Recal (ours)		
	Coverage(%)	Length	test Lpinball	Coverage(%)	Length	test Lpinball
MEPS」9	89.98	1.167	0.112	90.09	0.890	0.131
MEPS _20	89.72	1.165	0.117	89.99	0.830	0.141
MEPS _21	89.81	1.145	0.107	90.22	0.962	0.129
Facebook」	90.12	0.555	0.052	90.34	0.384	0.090
FaCebook_2	90.13	0.491	0.044	90.02	0.364	0.092
kin8nm	90.03	1.214	0.076	89.31	1.173	0.078
naval	89.70	3.095	0.164	89.71	3.077	0.166
bio	90.26	2.271	0.130	90.20	2.164	0.148
blog ,data	90.19	0.605	0.058	90.01	0.496	0.107
Nominal (1 - α)	90.00	-	-	90.00	-	-
5.1	Improved prediction intervals via conformal quantile finetuning
Setup We consider regression tasks in which we use quantile regression (pinball loss) to train a
base quantile predictor F (x) = [flo(x), fhi(x)] = θ0>Φ(x) on Dtrain (with learning rate decay
by monitoring validation loss on Dcal). Here Φb : X → Rdh is the learned representation function,
θb0 ∈ Rdh ×2 is the last linear layer (dh denotes the last hidden dimension), and fblo , fbhi are the learned
{lower, upper} quantile functions (see Appendix E.1 for more details on the training procedure).
Given F , we learn a baseline prediction interval of the form [flo (x) - t, fhi (x) + t] on Drecal via
Conformalized Quantile Regression (CQR) (Romano et al., 2019).
We then attempt to improve the length over CQR by conformal quantile finetuning: Fix the repre-
sentation function Φ and finetune the linear layer θ using our CP-Gen-Recal algorithm, so that
Cθ,t (x) = [θl>oΦb(x) -t, θh>iΦb(x) +t] (where θ = [θlo, θhi]). We learn a new θ on Dcal via (8) (where
`eff is chosen as the length), and then compute trecal on Drecal as in Algorithm 2.
We perform the above on 9 real-world regression datasets with a 3-layer MLP with width dh = 64,
similar as (Romano et al., 2019; Feldman et al., 2021). Additional details about the setup can
be found in Appendix E.1. We also test various tweaks of the CQR baseline (results provided in
Appendix H.2).
Results Table 1 compares the (test) coverage and length between CQR and the finetuned linear
layer via our CP-Gen-Recal. While both CQR and CP-Gen-Recal achieves valid 90% cover-
age, CP-Gen-Recal can systematically improve the length over CQR on all tasks. Table 1 also
>
reports the pinball loss for both the base θ0Φ(x) as well as the fine-tuned θ>Φ(x) on the test set
Dtest . Intriguingly, our conformal finetuning made the pinball loss worse while managing to im-
prove the length. This suggests the unique advantage of our constrained ERM objective, as it rules
out the simple explanation that the length improvement is just because of a lower test loss. We
remark that while CP-Gen-Recal improves the length over CQR, it comes at a cost in terms of
worse conditional coverage (analysis presented in Appendix H.1).
5.2	Minimum-volume prediction sets for multi-output regression
Setup This task aims to learn a box-shaped prediction set for multi-output regression with a small
volume. Our learning task is regression with output dimension dout > 1. We first learn a based
predictor fb : Rd → Rdout by minimizing the MSE loss on Dtrain . We then learn a box-shaped
prediction set of the form Cu(x) = Qid=ou1t [fbi(x) - ubi, fbi(x) + ubi] by one of the following methods:
•	(Coord-wise): Each ubi is obtained by vanilla conformalization (2) over the i-th output co-
ordinate on Dcal ∪ Drecal . To guarantee 1 - α coverage, each coordinate is conformalized at
level 1 - α∕d°ut, motivated by the union bound.
8
Published as a conference paper at ICLR 2022
Table 2: Results for multi-output regression on next-state prediction tasks, at level 1 - α = 90%. For each
method we report the (test) coverage and volume of its learned box-shaped prediction set. The reported volume
is the “halfened” version Qid=ou1t ui . All results are averaged over 8 random seeds.
	Coord-wise	Coord-wise-Recal	CP-Gen-Recal (ours)
Dataset	Coverage(%)	Volume	Coverage(%)	Volume	Coverage(%)	Volume
Cartpole	94.28	1.20 × 10-5	90.17	5.10 X 10-6	90.12	2.30 X 10-6
Half-Cheetah	93.90	1.10 × 10-5	90.06	1.23 × 10-6	90.02	9.07 X 10-7
Ant	93.56	3.37 × 10-3	89.99	1.70 X 10-4	90.02	8.25 X 10-5
Walker	94.42	2.59 × 10-5	90.01	7.33 X 10-7	89.94	3.47 X 10-7
Swimmer	95.62	2.80 × 10-5	89.90	2.22 X 10-6	90.13	1.46 X 10-7
Hopper	92.87	2.81 × 10-9	90.02	1.01 X 10-9	89.92	8.25 X 10-10
Humanoid	94.75	4.28 × 10-4	89.95	8.53 X 10-8	89.94	4.95 X 10-8
Nominal (1 - α)	90.00	-	90.00	-	90.00	-
•	(Coord-wise-Recal): Perform the above on Dcal to learn ubi, and reconformalize an addi-
tional t ≥ 0 on Drecal to reshape the prediction set proportionally:
Cub,t(x) = Qid=ou1t [fbi (x) - tubi, fbi(x) + tubi].
(9)
•	(CP-Gen-Recal, ours): Optimize the volume directly over all u ∈ Rdout using (8) on Dcal,
where 'eff (Cu； (x, y)) = QdoUIt (2ui) is chosen as the volume loss. We then reconformalize
an additional t ≥ 0 on Drecal to reshape the prediction set same as in (9). Note that this
reconformalization step is equivalent to Algorithm 2 with the re-parametrization ub 7→ (θ, t)
d1
where θ ∈ Rd>o0ut-1 denotes the ratio between ubi, and t ∈ R>0 denotes a common scale.
Our datasets are a collection of next-state prediction tasks with multi-dimensional continuous states
in offline reinforcement learning (RL), constructed similarly as D4RL (Fu et al., 2020) with some
differences. Additional details about the dataset and experimental setup are in Appendix E.2. We
also test an additional Max-score-Conformal baseline (which uses vanilla conformal predic-
tion with score function ky-f(x)k∞, equivalent to a hypercube-shaped predictor) in Appendix H.3,
which we find also performs worse than our CP-Gen-Recal.
Results Table 2 reports the (test) coverage and volume of the above three methods.
The Coord-wise method achieves valid coverage but is quite conservative (over-covers),
which is as expected as the union bound is worst-case in nature and the coordinate-wise
conformalization does not utilize the potential correlation between the output coordinates.
Coord-wise-Recal achieves approximately 90% coverage with a much smaller volume. Our
CP-Gen-Recal also achieves valid 90% coverage but a further lower volume across all tasks.
This suggests that optimizing the volume over all possible u ∈ Rdout data-dependently using our
CP-Gen-Recal is indeed more flexible than pre-determined conformalization schemes such as
Coord-wise.
Additional experiment: label prediction sets for ImageNet We show that CP-Gen-Recal can
learn label prediction sets for ImageNet with valid coverage and improved size over existing ap-
proaches, by finding an optimized set of ensemble weights over multiple base neural networks (Ta-
ble 5). The full setup and results are presented in Appendix F.
6	Conclusion
This paper proposes Conformal Prediction with General Function Class, a conformal prediction
algorithm that optimizes the efficiency metric subject to valid coverage over a general function
class of prediction sets. We provide theoretical guarantees for its coverage and efficiency in certain
situations, and develop a gradient-based practical implementation which performs well empirically
on several large-scale tasks. We believe our work opens up many directions for future work, such as
stronger theoretical guarantees via more structured function classes, further improving the gradient-
based approximate implementation, or experiments on other uncertainty quantification tasks.
9
Published as a conference paper at ICLR 2022
Acknowledgment
We thank Silvio Savarese for the suggestion on the multi-output regression task, and Yuping Luo
for the help with preparing the offline reinforcement learning dataset. We thank the anonymous
reviewers for their valuable feedback.
References
Physicochemical properties of protein tertiary structure data set. https://archive.
ics.uci.edu/ml/datasets/Physicochemical+Properties+of+Protein+
Tertiary+Structure. Accessed: January, 2019.
Blogfeedback data set.	https://archive.ics.uci.edu/ml/datasets/
BlogFeedback. Accessed: January, 2019.
Facebook comment volume data set. https://archive.ics.uci.edu/ml/datasets/
Facebook+Comment+Volume+Dataset. Accessed: January, 2019.
Kinematics of an 8 link robot arm. http://ftp.cs.toronto.edu/pub/neuron/delve/
data/tarfiles/kin-family/. Accessed: May, 2021.
Medical expenditure panel survey, panel 19. https://meps.ahrq.gov/mepsweb/data_
stats/download_data_files_detail.jsp?cboPufNumber=HC-181, a. Ac-
cessed: January, 2019.
Medical expenditure panel survey, panel 20. https://meps.ahrq.gov/mepsweb/data_
stats/download_data_files_detail.jsp?cboPufNumber=HC-181, b. Ac-
cessed: January, 2019.
Medical expenditure panel survey, panel 21. https://meps.ahrq.gov/mepsweb/data_
stats/download_data_files_detail.jsp?cboPufNumber=HC-192, c. Ac-
cessed: January, 2019.
Condition based maintenance of naval propulsion plants data set. http://archive.ics.uci.
edu/ml/datasets/Condition+Based+Maintenance+of+Naval+Propulsion+
Plants. Accessed: May, 2021.
Anastasios Angelopoulos, Stephen Bates, Jitendra Malik, and Michael I Jordan. Uncertainty sets
for image classifiers using conformal prediction. arXiv preprint arXiv:2009.14193, 2020.
Anastasios N Angelopoulos and Stephen Bates. A gentle introduction to conformal prediction and
distribution-free uncertainty quantification. arXiv preprint arXiv:2107.07511, 2021.
Yu Bai, Song Mei, Huan Wang, and Caiming Xiong. Understanding the under-coverage bias in
uncertainty estimation. arXiv preprint arXiv:2106.05515, 2021.
Rina Foygel Barber, Emmanuel J Candes, Aaditya Ramdas, and Ryan J Tibshirani. Predictive
inference with the jackknife+. TheAnnals of Statistics, 49(1):486-507, 2021.
Ole E Barndorff-Nielsen and David R Cox. Prediction and asymptotics. Bernoulli, pp. 319-340,
1996.
Peter L Bartlett, Michael I Jordan, and Jon D McAuliffe. Convexity, classification, and risk bounds.
Journal of the American Statistical Association, 101(473):138-156, 2006.
Stephen Bates, Anastasios Angelopoulos, Lihua Lei, Jitendra Malik, and Michael I Jordan.
Distribution-free, risk-controlling prediction sets. arXiv preprint arXiv:2101.02703, 2021.
Rudolf Beran. Calibrating prediction regions. Journal of the American Statistical Association, 85
(411):715-723, 1990.
Dimitri P Bertsekas. Nonlinear programming. Journal of the Operational Research Society, 48(3):
334-334, 1997.
10
Published as a conference paper at ICLR 2022
Jan F Bjornstad. Predictive likelihood: A review. Statistical Science, pp. 242-254,1990.
Greg Brockman, Vicki Cheung, Ludwig Pettersson, Jonas Schneider, John Schulman, Jie Tang, and
Wojciech Zaremba. Openai gym, 2016.
Maxime Cauchois, Suyash Gupta, Alnur Ali, and John C Duchi. Robust validation: Confident
predictions even when distributions shift. arXiv preprint arXiv:2008.04267, 2020a.
Maxime Cauchois, Suyash Gupta, and John Duchi. Knowing what you know: valid confidence sets
in multiclass and multilabel prediction. arXiv preprint arXiv:2004.10181, 2020b.
Haoxian Chen, Ziyi Huang, Henry Lam, Huajie Qian, and Haofeng Zhang. Learning prediction
intervals for regression: Generalization and calibration. In International Conference on Artificial
Intelligence and Statistics, pp. 820-828. PMLR, 2021.
DR Cox. Prediction intervals and empirical bayes confidence intervals. Journal of Applied Proba-
bility, 12(S1):47-55, 1975.
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: A large-scale hi-
erarchical image database. In 2009 IEEE conference on computer vision and pattern recognition,
pp. 248-255. Ieee, 2009.
Shai Feldman, Stephen Bates, and Yaniv Romano. Improving conditional coverage via orthogonal
quantile regression. arXiv preprint arXiv:2106.00394, 2021.
Rina Foygel Barber, Emmanuel J Candes, Aaditya Ramdas, and Ryan J Tibshirani. The limits of
distribution-free conditional predictive inference. Information and Inference: A Journal of the
IMA, 10(2):455-482, 2021.
Justin Fu, Aviral Kumar, Ofir Nachum, George Tucker, and Sergey Levine. D4rl: Datasets for deep
data-driven reinforcement learning, 2020.
Yarin Gal and Zoubin Ghahramani. Dropout as a bayesian approximation: Representing model
uncertainty in deep learning. In international conference on machine learning, pp. 1050-1059.
PMLR, 2016.
Leying Guan. Conformal prediction with localization. arXiv preprint arXiv:1908.08558, 2019.
Chirag Gupta, Arun K Kuchibhotla, and Aaditya K Ramdas. Nested conformal prediction and
quantile out-of-bag ensemble methods. arXiv preprint arXiv:1910.10562, 2019.
Peter Hall, Liang Peng, and Nader Tajvidi. On prediction intervals based on predictive likelihood or
bootstrap methods. Biometrika, 86(4):871-880, 1999.
Peter Hoff. Bayes-optimal prediction with frequentist coverage control. arXiv preprint
arXiv:2105.14045, 2021.
Gao Huang, Yixuan Li, Geoff Pleiss, Zhuang Liu, John E Hopcroft, and Kilian Q Weinberger.
Snapshot ensembles: Train 1, get m for free. arXiv preprint arXiv:1704.00109, 2017.
Rafael Izbicki, Gilson T Shimizu, and Rafael B Stern. Flexible distribution-free conditional predic-
tive bands using density estimators. arXiv preprint arXiv:1910.05575, 2019.
Rafael Izbicki, Gilson Shimizu, and Rafael B Stern. Cd-split and hpd-split: efficient conformal
regions in high dimensions. arXiv preprint arXiv:2007.12778, 2020.
Alex Kendall and Yarin Gal. What uncertainties do we need in bayesian deep learning for computer
vision? arXiv preprint arXiv:1703.04977, 2017.
Danijel Kivaranovic, Kory D Johnson, and Hannes Leeb. Adaptive, distribution-free prediction
intervals for deep networks. In International Conference on Artificial Intelligence and Statistics,
pp. 4346-4356. PMLR, 2020.
Balaji Lakshminarayanan, Alexander Pritzel, and Charles Blundell. Simple and scalable predictive
uncertainty estimation using deep ensembles. arXiv preprint arXiv:1612.01474, 2016.
11
Published as a conference paper at ICLR 2022
JF Lawless and Marc Fredette. Frequentist prediction intervals and predictive distributions.
Biometrika, 92(3):529-542, 2005.
Jing Lei and Larry Wasserman. Distribution-free prediction bands for non-parametric regression.
Journal of the Royal Statistical Society: Series B: Statistical Methodology, pp. 71-96, 2014.
Jing Lei, James Robins, and Larry Wasserman. Distribution-free prediction sets. Journal of the
American Statistical Association, 108(501):278-287, 2013.
Jing Lei, Max G’Sell, Alessandro Rinaldo, Ryan J Tibshirani, and Larry Wasserman. Distribution-
free predictive inference for regression. Journal of the American Statistical Association, 113
(523):1094-1111, 2018.
David John Cameron Mackay. Bayesian methods for adaptive models. PhD thesis, California
Institute of Technology, 1992.
Wesley J Maddox, Pavel Izmailov, Timur Garipov, Dmitry P Vetrov, and Andrew Gordon Wilson.
A simple baseline for bayesian uncertainty in deep learning. Advances in Neural Information
Processing Systems, 32:13153-13164, 2019.
Andrey Malinin and Mark Gales. Predictive uncertainty estimation via prior networks. arXiv
preprint arXiv:1802.10501, 2018.
Andrey Malinin, Bruno Mlodozeniec, and Mark Gales. Ensemble distribution distillation. arXiv
preprint arXiv:1905.00076, 2019.
Pascal Massart. The tight constant in the dvoretzky-kiefer-wolfowitz inequality. The annals of
Probability, pp. 1269-1283, 1990.
Yaniv Ovadia, Emily Fertig, Jie Ren, Zachary Nado, David Sculley, Sebastian Nowozin, Joshua
Dillon, Balaji Lakshminarayanan, and Jasper Snoek. Can you trust your model’s uncertainty?
evaluating predictive uncertainty under dataset shift. In Advances in Neural Information Process-
ing Systems, pp. 13991-14002, 2019.
Harris Papadopoulos. Inductive conformal prediction: Theory and application to neural networks.
In Tools in artificial intelligence. Citeseer, 2008.
Sangdon Park, Osbert Bastani, Nikolai Matni, and Insup Lee. Pac confidence sets for deep neural
networks via calibrated prediction. arXiv preprint arXiv:2001.00106, 2019.
Tim Pearce, Alexandra Brintrup, Mohamed Zaki, and Andy Neely. High-quality prediction inter-
vals for deep learning: A distribution-free, ensembled approach. In International Conference on
Machine Learning, pp. 4075-4084. PMLR, 2018.
Benjamin Recht, Rebecca Roelofs, Ludwig Schmidt, and Vaishaal Shankar. Do imagenet classifiers
generalize to imagenet? In International Conference on Machine Learning, pp. 5389-5400.
PMLR, 2019.
Yaniv Romano, Evan Patterson, and Emmanuel J Candes. Conformalized quantile regression. arXiv
preprint arXiv:1905.03222, 2019.
Yaniv Romano, Matteo Sesia, and Emmanuel J Candes. Classification with valid and adaptive
coverage. arXiv preprint arXiv:2006.02544, 2020.
Mauricio Sadinle, Jing Lei, and Larry Wasserman. Least ambiguous set-valued classifiers with
bounded error levels. Journal of the American Statistical Association, 114(525):223-234, 2019.
Glenn Shafer and Vladimir Vovk. A tutorial on conformal prediction. Journal of Machine Learning
Research, 9(3), 2008.
Qinglong Tian, Daniel J Nordman, and William Q Meeker. Methods to compute prediction intervals:
A review and new results. arXiv preprint arXiv:2011.03065, 2020.
Aad Van Der Vaart and Jon A Wellner. A note on bounds for vc dimensions. Institute of Mathemat-
ical Statistics collections, 5:103, 2009.
12
Published as a conference paper at ICLR 2022
Roman Vershynin. High-dimensional probability: An introduction with applications in data science,
volume 47. Cambridge university press, 2018.
Vladimir Vovk. Conditional validity of inductive conformal predictors. In Asian conference on
machine learning,pp. 475-490. PMLR, 2012.
Vladimir Vovk. Cross-conformal predictors. Annals of Mathematics and Artificial Intelligence, 74
(1):9-28, 2015.
Vladimir Vovk, Alexander Gammerman, and Glenn Shafer. Algorithmic learning in a random world.
Springer Science & Business Media, 2005.
Vladimir Vovk, Ilia Nouretdinov, Valery Manokhin, and Alexander Gammerman. Cross-conformal
predictive distributions. In Conformal and Probabilistic Prediction and Applications, pp. 37-51.
PMLR, 2018.
Volodya Vovk, Alexander Gammerman, and Craig Saunders. Machine-learning applications of al-
gorithmic randomness. 1999.
Yachong Yang and Arun Kumar Kuchibhotla. Finite-sample efficient conformal prediction. arXiv
preprint arXiv:2104.13871, 2021.
A Proof of Proposition 1
Recall that Ct(X) = [f (x) - t, f(x) + t] satisfies 'eff (Ct；(x, y)) = length(Ct(X)) = 2t for any
(x, y). Also, we have
1 {y ∈ Ct(χ)} = 1 {y ∈ [f (χ) -1, f(χ) +1]} = 1 {|y - f(χ)l > t},
or equivalently 1 {y ∈ Ct(X)} = 1 {|y - f (X)| ≤ t}. Therefore, problem (3) is equivalent to
minimize t
t≥0
1 ncal
subject to 1 - Lcoverage(Ct) := ---------- V2 1 {版-f (Xi)I ≤ t} ≥ 1 - α∙
ncal i=1
By definition of quantiles, this problem is solved at
tb= d(1 - α)ncale -th largest element of {Iyi - f (Xi)I}in=ca1l,
which is the desired result.
□
B Proof of Proposition 2
(a)
(b)
As Cθb,bt solves problem (5), it satisfies the constraint Lcoverage(Cθb,bt) ≤ α + ε0. Therefore,
Lcoverage (Cθb,tb)
bb
Lcoverage (Cθb bt ) +Lcoverage (Cθb bt ) - Lcoverage (Cθb bt )
X---,«}
{z'∖∣f^^^
≤α+ε0
≤ α + ε0 + sup	Lcoverage (Cθ,t) - Lb
coverage(Cθ,t )
(θ,t)∈Θ×T
α + ε0 + εcoverage .
Suppose εcoverage ≤ ε0. Taking any (θ, t) ∈ Θ × T such that Lcoverage(Cθ,t) ≤ α, we have
b
Lcoverage (Cθ,t ) ≤ Lcoverage (Cθ,t ) + εcoverage ≤ α + εcoverage ≤ α + ε0 .
This shows that (θ, t) lies within the constraint set of problem (5). Thus as (θb, bt) further minimizes
the loss Leff within the constraint set, we have Leff (Cθb,bt) ≤ Leff (Cθ,t). This shows that
Leff (Cθb,bt) - Leff (Cθ,t)
13
Published as a conference paper at ICLR 2022
≤ Leff (Cθbbt) - Leff (Cθ,t) +2	sup	Leff (Cθ,t) - Leff (Cθ,t)
、_______--{____________/	(θ,t)∈Θ×T 1
≤0
≤ 2εeff .
As the above holds simultaneously for all (θ, t) ∈ Θ × T with at most α coverage loss, taking the
sup over the left-hand side yields
Leff(Cθb,bt) -	(θ,t)i∈nΘf ×T	Leff (Cθ,t) ≤ 2εeff.
Lcoverage (Cθ,t )≤α
□
C Examples of good generalization for CP-Gen
We provide two concrete examples where the concentration terms εeff and εcoverage are small with
high probability, in which case Proposition 2 guarantees that CP-Gen learns an prediction set with
approximate validity and near-optimal efficiency.
Assumption A (Bounded and Lipschitz efficiency loss). The loss function `eff satisfies
A1 (Bounded loss). ∣'eff (Cθ,t; (x, y))| ≤ M for all (θ,t ∈ Θ XT and all (x, y) ∈ X ×Y.
A2 (t-Lipschitzness). t 7→ `eff (Cθ,t; (x, y)) is LT -Lipschitz for all (θ, x, y) ∈ Θ × X × Y.
Assumption B (Bounded T). The parameter space T ⊂ R is bounded: supt∈T ∣t∣ ≤ BT.
C.1 Finite class
Proposition 4 (Finite class). Suppose Θ is a finite set (NΘ := ∣Θ∣ < ∞), and suppose Assump-
tions A1, A2, B hold. Then, we have with probability at least 1 - δ that
εcoverage ≤ C√log(Nθ∕δ)∕ncai and εeff ≤ C ∙
[m Plog(Nθ∕δ) + LT BT i / √ncai,
where C > 0 is an absolute constant.
Proof. We first bound εcoverage . Fix any θ ∈ Θ, define
tθ(x,y) := inf {t ∈ T : Cθ,t (x) 3 y}
(10)
to be the smallest possible t ∈ T such that the Cθ,t (x) contains y. Observe that, as {Cθ,t (x)}t∈T
are nested sets, the coverage event can be rewritten as 1 {y ∈ Cθ,t(x)} = 1 {t ≥ tθ (x, y)} for any
(x, y). Therefore, we have
sup Lb
t∈T
coverage
(Cθ,t ) - Lc
overage (Cθ,t )
ncal
SuPl 一 X 1 {y ∈ Cθ,t(xi)} - P(Y ∈ Cθ,t(X))
t∈T ncal i=1
l	ncal	l
sup l----- X 1 {yi ∈ Cθ,t(Xi)} - P(Y ∈ Cθ,t(X))
t∈T l ncal i=1	l
ll 1 ncal
supl ——£1 {tθ(χ,y) ≤ t} — P(x,y)(tθ(X,Y) ≤ t)
t∈T l ncal i=1
sup lllFbθ(t) - Fθ(t)lll,
where we have defined Fθ : R → [0, 1] as the CDF of the random variable tθ (X, Y) and similarly
Fbθ as the empirical CDF of the same random variable over the finite dataset Dcal. Applying the
Dvoretzky-Kiefer-Wolfowitz (DKW) inequality (Massart, 1990, Corollary 1) yields that
sup
t∈T
lFθ ⑻-Fθ (t)l≤ J⅞g
14
Published as a conference paper at ICLR 2022
with probability at least 1 - δ. Now, taking the union bound with respect to θ ∈ Θ (where for each
θ We plug in tail probability δ∕2Nθ) We get that with probability at least 1 - δ∕2,
εcoverage
sup sup Lcoverage (Cθ,t) -
Lcoverage(Cθ,t)
θ∈Θ t∈T
supsup ∣Fθ(t) - Fθ(t)∣ ≤ ʌlogφ^ ≤ Cl∕lOgNa.
θ∈Θ t∈T	2ncal	ncal
(11)
for some absolute constant C > 0.
We next bound εeff. Fix any θ ∈ Θ. We have by standard symmetrization argument that
E sup
t∈T
(Cθ,t) - Leff (Cθ,t)
ncal
E"∣^ X 'eff 9- E['eff …，Y 川
I 1 ncal
≤ 2E(xi,yi),εi sup 1------- ɪ^ɛi'eff (Cθ,t; (xi,yi))
t∈T I ncal i=1
ncal
1 X εi ∙ t
i=1
(ii)	I 1 ncal	II
≤ 2LT ∙ BT ∙ Eεi 11 tt- E εi
i=1 I
(i)
≤ 2Lt ∙ Eεi sup
t∈T ∣ ncal
ncal
I#
2LT ∙ Eεi I —
ncal
ncal
E^i ∙ sup ∣t∣
i=1
t∈T
(iii)		
≤ 2LT ∙ BT/ √ncal.
i
Above, (i) used the Lipschitzness Assumption A2 and the Rademacher contraction inequality (Ver-
shynin, 2018, Exercise 6.7.7); (ii) used Assumption B, and (iii) used Eεi [∣ n1γ Pn=? εj] ≤
Eεi
Pncal
i=1 εi
2
1/2	.id
=1∕√ncai. (Above ε 七 Unif({±1}) are Rademacher variables.)
Next, as each loss |'©任(Cθ,t; (x, y))| ≤ M by Assumption A1, the random variable
sup ILeff (Cθ,t) - Leff (Cθ,t)
t∈T
satisfies the M/ncal finite-difference property. Therefore by McDiarmid’s Inequality, We have With
probability at least 1 - δ that
sup ∣∣Lbeff (Cθ,t) - Leff (Cθ,t)∣∣
≤ E [sup I Leff (Cθ,t) — Leff (0θ,t)∣] + S M 21-
t∈T	2ncal
LT BT + M Plog(1∕δ)
≤C	√nca	.
Finally, by union bound over θ ∈ Θ (Where We plug in δ∕2NΘ as tail probability into the above),
We have With probability at least 1 - δ∕2 that
εeff = sup sup ∣Leff (Cθ,t) - Leff (Cθ,t)
θ∈Θ t∈T
l LτBt + MPIOg(N㊀⑷
≤ C ---------,	-------.
(12)
(11)	together With (12) is the desired result.
□
15
Published as a conference paper at ICLR 2022
C.2 VC/Rademacher class
Next, for any class C, let VC(C) := VC({(x, y) 7→ 1 {y ∈/ Cθ,t (x)} : θ ∈ Θ, t ∈ T}) denote its VC
dimension with respect to the coverage loss.
Proposition 5 (VC/Rademacher class). We have for some absolute constant C > 0 that
(a)	Suppose VC(C) = K + 1 < ∞ ,then with probability at least 1 一 δ∕2,
εcoverage ≤C VZ(K +1+log(1∕δ))∕ncai.
(b)	Suppose Assumption A1 holds. Then we have with probability at least 1 — δ∕2 that
εeff ≤ ChRnffal (C) + PM2 log(1∕δ)∕ncai],
where RnffaI(C) := E(Xi9)圣卜uP(θ,t)∈θ×τ 岛 Pn=1l εi'eff(Cθ,t; (xi,yi))∣] is the Rademacher
complexity ofthe class C with respect to 'eff (above εi 吧 Unif({±1})).
Proof. (a) By assumption, the class of Boolean functions {(x, y) 7→ 1 {y ∈∕ Cθ,t(x)}}(θ,t)∈Θ×T
has VC dimension K + 1 < ∞. Therefore by the standard Rademacher complexity bound for VC
classes (Vershynin, 2018, Theorem 8.3.23) and McDiarmid’s Inequality, we have with probability at
least 1 一 δ∕2 that
∣	1 ncal
εcoverage = Sup | 一 V 1 {% ∈ Cθ,t(x>yi}- P(Y ∈ Cθ,t(X))
(θ,t)∈Θ×T ∣ ncal i=1
≤C
10g≡ ≤ CJ
2ncal
K+1+log(1∕δ)
ncal
(b)	We have by standard symmetrization argument that (below ε% ~ Unif({±1}) denote
Rademacher variables)
E Sup
θ∈Θ,t∈T
E[εeff] = E sup	∣∣∣Lbeff (Cθ,t) 一 Leff (Cθ,t)∣∣∣
θ∈Θ,t∈T
ncal	∣
----^X 'eff (Cθ,t; (xi, yi)) - E['eff (Cθ,t; (X, Y))]
ncal i=1	∣
∣∣ 1 ncal	∣∣
≤ 2E(xi,yi ),εi	Sup	|----- V2εi'eff (Cθ,t, (Xi,9% ))	= 2Rn (C ).
θ∈Θ,t∈T ∣ ncal i=1	∣
Further by Assumption A1, the quantity εeff satisfies M∕ncal bounded-difference, so applying Mc-
Diarmid’s Inequality gives that with probability at least 1 一 δ∕2,
εeff ≤ E[εeff] + yiM≡ ≤ C "Rnffai (C) + ^^^
□
C.3 Case study: Linear class
In this section, we study prediction intervals with a specific linear structure and show that it satisfies
the conditions of the VC/Rademacher class of Proposition 5.
Concretely, suppose we have a regression task (Y = R), and the prediction interval Cθ,t (x) takes a
linear form
Cθ,t (x) = [θ> Φlo (x) 一 tσ(x), θ>Φhi(x) + tσ(x)],	(13)
16
Published as a conference paper at ICLR 2022
where θ ∈ Θ ⊂ RK, Φhi, Φlo : X → RK are feature maps such that Φlo(x)i ≤ Φhi(x)i for all
i ∈ [K], σ : X → R>0.
For intuitions, we can think of Φ{hi,lo} as pretrained representation functions and σ as an (optional)
pretrained function for modeling the variability of y |x. Note that this encompasses linear ensem-
bling of several existing methods, such as vanilla conformal regression (Lei et al., 2018) by taking
Φhi = Φlo = Φ where each Φi : X → R is a base predictor, as well as Conformalized Quantile Re-
gression (Romano et al., 2019) where each (Φlo,i, Φhi,i) is a pair of learned lower and upper quantile
functions.
Our goal is to find an optimal linear function of this representation that yields the shortest prediction
interval (with fixed width) subject to valid coverage.
We assume that both the features and the parameters are bounded:
Assumption C (Bounded features and parameters). We have supθ∈Θ kθk ≤ BΘ, supx∈X kΦ(x)k ≤
BΦ, supx∈X σ(x) ≤ Bσ, and supt∈T |t| ≤ BT.
The following result shows that Proposition 5 is applicable on the linear class.
Corollary 6 (Coverage and length guarantees for linear class). For the (K + 1)-dimensional linear
class (13), suppose Assumption C holds, and we take the efficiency loss to be the length of the
interval: 'eff (C; (x, y)) := length(C(X)). Then, we have with probability at least 1 一 δ (over the
calibration dataset Dcal) that
εcoverage ≤ C S K +1+log(DiI, and εeff ≤ C [BθBφ + BT Bσ ] ∙ Sbg⑴ ^ ,
ncal	ncal
where C > 0 is an absolute constant.
Proof. We verify the conditions of Proposition 5. First, we have
1 {y ∈ Cθ,t(x)} = 1 {max {y — θ>Φhi(x),θ>Φio(x) — y} > tσ(x)}.
The set within the indicator above is the union of two sets (x, y) : y 一 θ> Φhi (x) 一 tσ(x) > 0
and {(x, y) : θ> Φlo (x) — y — tσ(x) > 0}. Note that each family of sets (over (θ, t) ∈ RK × R are
linear halfspaces with feature dimension K + 2), and thus has VC-dimension ≤ K + 2. Applying
the VC dimension bound for unions of sets (Van Der Vaart & Wellner, 2009, Theorem 1.1), we get
VC(C) ≤ C0(K + 2 + K + 2) ≤ C(K + 1) for some absolute constant C > 0. Therefore the
condition of Proposition 5(a) holds from which we obtain the desired bound for εcoverage .
To bound εeff, we first note that for any (x, y) ∈ X × R,
∣'eff(Cθ,t; (x,y))∣ = Ilength(Cθ,t(x))∣
= θ>(Φhi(x) — Φlo(x)) + 2tσ(x) ≤ kθk kΦhi(x) — Φlo(x)k + 2tσ(x)
≤ 2BΘBΦ + 2BT Bσ =: M,
and thus the boundedness assumption (Assumption A1) holds with M defined above. Next, we have
the following bound on the Rademacher complexity
ncal
Rnffl (C)= E SUp I——X εi(θ>(Φhi(xi) — Φio (Xi)) + 2tσ(xi))
cal	(θ,t)∈Θ×Tncal i=1
≤ E sup I ∖ θ, -- ^X εi(φhi (Xi)- φlo(Xi))) ।
θ∈Θ I ncal i=1	I
+ E sup
t∈T
1	ncal
2t ∙ —	εiσ(χi)
ncal i=1
≤ sup ∣∣θ∣∣∙ E
θ∈Θ
ncal
εi(Φhi(xi) — Φlo(xi))
i=1
2 1/2
+ 2sup |t| ∙ E	— Xεiσ(xi)
t∈T	ncal i=1
1/2
≤ BΘ ∙ e ------ kφhi(xl) - φlo(xl)∣∣2
ncal
+ 2Bt ∙ E
ɪσ2(xι)
ncal
1/2
17
Published as a conference paper at ICLR 2022
BΘ BΦ + BT Bσ
≤ C	√ncaι-.
Applying Proposition 5(b), We get εeff ≤ C ∙ [BθBφ + BTBσ] ∙ y4og(T∕δ)∕nCai With probability
□
at least 1 - δ. This is the desired bound for εeff .
D Theoretical guarantee for CP-Gen-Recal
In this section We state and prove the formal theoretical guarantee for the CP-Gen-Recal algo-
rithm (Algorithm 2).
Define the score tθ(X,Y) := inf {t ∈ T : Y ∈ Cθ,t(X)} and let Fθ(t) := P(Y ∈ Cθ,t(X)) =
P(tθ(X, Y ) ≤ t) denote its CDF.
Assumption D (LoWer bounded density for score function). For any θ ∈ Θ, tθ (X, Y ) has a positive
density fθ (t) = Fθ0 (t) > 0 on t ∈ T. Further, let tθ,1-α := inf {t ∈ T : Fθ (t) ≥ 1 - α} denote its
(1 一 α) quantile, then there exists some constants c0 ,δ0 > 0 such that
i	inf	x fθθ ⑴ ≥ C0.
t∈[tθ,1-α-δ0,tθ,1-α+δ0]
Proposition 7 (Valid coverage and near-optimal efficiency for reconformalized algorithm). The
following holds for Algorithm 2:
(a)	(Valid coverage) For any possible θ ∈ Θ learned in Line 1 and the resulting trecal, we have
EDrecal [LCOVe” (/,亍…)≤。，/^ PDZ(X,Y) (Y ∈	(X)) ≥ 1-。.
(b)	(Efficiency) Suppose Assumptions A2 and D hold, max {εcoverage + 1∕ncai, 2 PlOg(1 ∕δ) ∕nτecai}
c0δo (recall the definition of εcoverage in (7)), and εcoverage ≤ ε0. Thenfor δ ≤ 0.5, we have with
probability at least 1 一 δ that
≤
Leff (Cb,brecaJ '	(©,tm^xT	Leff (Cθ,J + 2εeff + CLT ∙
Lcoverage (Cθ,t )≤α
l 1	/log(10
εcoverage +	+
ncai	nrecai
Proof. (a) As the learned parameter θ (and thus the family of nested sets Cθb,t) is independent of the
recalibration dataset Drecai, We have that the scores tθb(x, y) on dataset Drecai and a neW test point
/ -χr τ r∖	ι	ι ι	∕? Et f -i zzɔ ,	, ι AcYC C	∙ , ∙ t ∖	ι	r
(X, Y) are exchangeable given any θ. Therefore by (Gupta et al., 2019, Proposition 1), We have for
any θ ∈ Θ that
PDrecal,(X,Y) Y ∈ Cθb,btrecal
or equivalently EDrecal Lcoverage(Cθb,tbrecal ) ≤ α.
≥ 1 一 α,
(b)	For any θ ∈ Θ, define the score function tθ (x, y) the same as in (10), and similarly define the
CDF Fθ (t) := P(tθ (X, Y) ≤ t) and its empirical counterpart Fbθcai(t) and Fbθrecai (t) as the finite-
sample version on dataset Dcai and Drecai respectively.
We first analyze t. By the same derivation as in (11), We have
sup Fbθbcai(t) 一 Fθb(t) ≤ sup	Fbθcai(t) 一 Fθ (t) = εcoverage.
t∈T θ	(θ,t)∈Θ×T
As (θb, bt) solves the constrained ERM (5) and by the assumption that `eff (Cθ,t; (x, y)) is monotone
in t, We have that bt is the minimal value of t ∈ T such that Fbbcai (t) ≥ 1 一 α. Therefore, (as
|Dcai| = ncai and {tθ (xi, yi)}i∈D are almost surely distinct by Assumption D,) We have
1 一 α ≤ Fbθbcai(tb) ≤ 1 一 α + 1∕ncai.
18
Published as a conference paper at ICLR 2022
This shows that
—
coverage + 1/ncal,
Where We recall that tθb,1-α is the (1 - α) (population) quantile of tθb(X, Y ). Note that Fθ0 (t) =
fθ(t) ≥ Co on t ∈ [tb,ι-α - δo,tb,ι-α + δo] by Assumption D. Further, Egverage + 1∕&ai ≤ Coδ0.
Therefore, by monotonicity of Fθ, We must have tb ∈ [tθb,1-α - δ0, tθb,1-α + δ0], and thus
∣∣t - tθb,1-α ∣∣ ≤ (εcoverage + 1∕ncai)∕Co∙
(14)
^
^
We next analyze btrecal . As the dataset Drecal is independent of θ, we can apply the DKW Inequal-
ity (Massart, 1990, Corollary 1) to obtain that
sup
t∈T
log(1∕δ)
2nrecal
with probability at least 1 - δ. Using a similar argument as above, we get (for δ ≤ 0.5)
Fθb(tbrecal) - Fθb(tθb,1
Iog(I© +	1	≤ 2 kog(1∕δ)
2nrecal	nrecal	nrecal
As 2,log(1∕δ)∕nrecai ≤ c0δo, We can apply the similar argument as above to deduce that
— tb,ι-α∣ ≤ 2plθg(1∕δ)∕nrecai∕c0.
(15)
Combining (14) and (15) and using the Lipschitzness of the efficiency loss (Assumption A2), we get
Leff (Cθb,btrecal) -Leff(Cθb,tb)
≤ LT ∙ ∣trecal - b| ≤ LT ∙
-tθb,1-α∣∣ + ∣∣tθb,1-α - tb∣∣
≤ CLT ∙
εcoverage + ncal +
log(10 I /
-^	"c0.
nrecal
Finally, as We assumed εcoverage ≤ ε0, the condition of Proposition 2(b) holds, so We have
Leff (Cθb bt) ≤	inf	Leff (Cθ,t) + 2εeff.
e θ,t	(θ,t)∈Θ×T	e ,	e
Lcoverage (Cθ,t)≤α
Summing the preceding tWo bounds, We get
Leff (Cb,breca) '	×T	Leff (4") + 2染6 + CLT -
Lcoverage (Cθ,t )≤α
Which is the desired result.
εcoverage + ncal +
3 ∕co.
nrecal
□
E	Additional experimental details
E.1 Conformal quantile finetuning
Datasets Our choice of the datasets folloWs (Feldman et al., 2021). We provide information about
these datasets in Table 3.
All datasets are standardized so that inputs and labels have mean 0 and standard deviation 1, and
split into (train, cal, recal, test) With size 70%, 10%, 10%, 10% (varying With the random seed).
19
Published as a conference paper at ICLR 2022
Table 3: Information about the regression datasets. Here (n, d) denotes the (sample size, feature dim).
Dataset	n	d
MEPS_19 (mep, a)	15785	139
MEPS_20 (mep, b)	17541	139
MEPS_21(m叩，c)	15656	139
Facebook_1 (fac)	40948	53
FaCebook_2 (fac)	81311	53
kin8nm (kin)	8192	8
naval (nav)	11934	17
bio (bio)	45730	9
blog_data (blo)	52397	280
Base predictor and optimization Our network architecture is a 3-layer MLP with width 64 and
output dimension 2 (for the lower and upper quantile). We use momentum SGD with initial learning
rate 10-3 and momentum 0.9, batch-size 1024, and run the optimization for a max of 10000 epochs.
A 10x learning rate decay is performed if the validation loss on Dcal has not decreased in 10 epochs,
and we stop the learning whenever the learning rate decay happens for 3 times. The loss function
used in training F =[力。，fhi] is the summed pinball loss of level ɑ∕2 for 力。and 1 - α∕2 for fhi,
following (Romano et al., 2019):
'(F; (xi,yi)) = 'α/Lll(Ko(Xi)- y。+ 'p—b/2i仇i(Xi)- y)
where for any β ∈ (0,1), '；由匕ɑ]1 is the pinball loss at level β:
")={(- -∖)t	if t < O.
Optimization details for CP-Gen-Recal For the conformal quantile finetuning procedure with
our CP-Gen-Recal, we rewrite the miscoverage loss for the quantile-based prediction interval as
1 {y ∈/ Cθ,t(X)} = 1 nt - max nθl>o Φb (X) - y,y - θh>iΦb(X)o < 0o .
(In practice our θ also includes a trainable bias same as the original top linear layer; here we abuse
notation slightly to allow easier presentation.) We approximate the right-hand side above with the
hinge loss to obtain the formulation (8). To solve that optimization problem, we use SGD on (θ, t)
with learning rate 0.01 and (ascent on) λ with learning rate 0.1. The batch-size here is 256 and the
number of episodes is 1000. To ensure t > 0 we use a log parametrization for t. Finally, trecal is
computed by the reconformalization step in Algorithm 2 on Drecal .
E.2 Multi-output regression
Datasets We generate offline datasets consisting of (state, action, next_state) pairs within RL tasks
within the OpenAI Gym (Brockman et al., 2016). For each task, the data is generated by executing a
medium-performing behavior policy that is extracted from standard RL training runs. All tasks are
continuous state and continuous action. Table 4 summarizes the state and action dimension, along
with the reward of the policies used for generating the data. All datasets contain 200K examples.
All datasets are standardized so that inputs and labels have mean 0 and standard deviation 1, and
split into (train, cal, recal, test) with size 70%, 10%, 10%, 10% (varying with the random seed).
Base predictor and optimization Our network architecture is a 3-layer MLP with width 64, input
dimension din = dS + dA, and output dimension dout = dS . We use momentum SGD with initial
learning rate 10-3, momentum 0.9, and batch-size 512. We run the optimization for 1000 epochs
with a 10x learning rate decay at epoch 500. The loss function for training the network is the
standard MSE loss.
Optimization details for CP-Gen-Recal For the conformal quantile finetuning procedure with
our CP-Gen-Recal, we rewrite the miscoverage loss for the box-shaped prediction set as
(dout
y ∈/	[fbi(X) - ui, fbi(X) + ui]
i=1
1 - max |yi - fbi(X)|/ui < 0 .
1≤i≤dout
20
Published as a conference paper at ICLR 2022
Table 4: Information about the next-state prediction datasets. Here (dS , dA) denotes the (state, action) dimen-
sion of the corresponding RL task. Datasets with a (slim) note only extract a subset of the full state (so that dS
is less than the full state dimension). We also report the mean reward of the behavior policies.
RL Task	ds	dA	mean reward
Cartpole	4	1	107
Half-Cheetah	17	6	8015
Ant (slim)	27	8	4645
Walker	17	6	3170
Swimmer	8	2	51
Hopper	11	3	2066
Humanoid (slim)	45	17	1357
where we recall u ∈ Rdout is the learnable parameter within the initial optimization stage of
CP-Gen-Recal as discussed in Section 5.2. We approximate the right-hand side above with the
hinge loss to obtain the formulation (8). To solve that optimization problem, we use SGD on (θ, t)
with learning rate 0.01 and (ascent on) λ with learning rate 0.01. The batch-size here is 1024 and
the number of episodes is 1000. To ensure u > 0 we use a log parametrization for u.
For the reconformalization step, we keep the (relative) ratios of the ub obtained above (as the θ), and
then reconformalize an additional trecal > 0 on Drecal via the proportional reshaping of (9).
E.3 Details for Figure 1
Figure 1 is obtained on one run of our conformal quantile finetuning experiment on the MEPS_19
dataset, and illustrates the coverage-efficiency tradeoff. Both figures there compute the coverage
and length on the (unseen) test set Dtest , for better illustration. Figure 1 Left plots the family
[flo(x) - t, fhi(x) + t] used by Conformalized Quantile Regression. Figure 1 Right plots the family
Cθ,t(x) = [θl>oΦb(x)-t,θh>iΦb(x)].
The specific function class of θ shown in the thinner lines is a finite set of linear interpolations
of the original θ0 obtained in QR and the new θ obtained by conformal quantile finetuning, with
combination weights within {-0.3, -0.2, . . . , 1.0}. The shaded region is then obtained by filling in
the area.
F Results for label prediction sets on ImageNet
Here we present the ImageNet label prediction set experiment abbreviated in Section 5.
Dataset and model We take K = 9 large-scale pretrained neural networks on the ImageNet train-
ing set (Deng et al., 2009). Our models are {ResNeXt101, ResNet152, ResNet101, DenseNet161,
ResNet18, ResNet50, VGG16, Inception, ShuffleNet}, similar as in (Angelopoulos et al., 2020).
We then consider task of constructing label prediction sets with valid coverage and small cardinal-
ity. We train and test out conformal procedures on the following two datasets, neither seen by the
pretrained models:
(1)	ImageNet-Val: The original validation set of ImageNet with 50000 images. We randomly
split (varying with seed) this into |Dcal| = 10000, |Drecal| = 10000, and |Dtest| = 30000.
(2)	ImageNet-V2 (Recht et al., 2019): A new validation set following the roughly the same
collection routines of the original images in ImageNet, however believed to have a mild dis-
tribution shift and thus slightly harder for classifiers pretrained on ImageNet. This dataset
contains 10000 images, which we randomly split (varying with seed) into |Dcal| = 4000,
|Drecal| = 1000, and |Dtest| = 5000.
Methods for learning prediction sets Our constructions of the prediction sets are based on the
Least Ambiguous Set-Valued Classifier (LAC) method of (Sadinle et al., 2019), which turns any base
21
Published as a conference paper at ICLR 2022
Table 5: Results for ImageNet Prediction Sets with Conformal Ensembling. For each method we report
the (test) coverage and set size. Each entry reports the (mean, std) over 8 random seeds.
Best conformalized single model Conformalized uniform ensemble Ensemble via CP-Gen-Recal (ours)
Dataset	Coverage(%)	Size	Coverage(%)	Size	Coverage(%)	Size
ImageNet-Val	90.10 ± 0.29	1.70 ± 0.03	90.13 ± 0.21	1.62 ± 0.02	90.11 ± 0.33	1.51 ± 0.03
ImageNetV2	90.01 ± 0.71	5.00 ± 0.24	89.93 ± 0.71	4.66 ± 0.22	90.18 ± 0.85	4.39 ± 0.44
predictor P wherep(∙∣χ) denotes the predicted distribution of the L = 1000 labels into a prediction
set Ct(x) via
Ct(x) = {y ∈ [L] : p(y|x) > t},
where t is found by conformal prediction.
We consider learning a valid prediction set with smaller set size by finding an optimized ensem-
ble weight of the K base predictors using our CP-Gen-Recal algorithm. This means we learn
prediction sets of the form
Cθ,t(χ) = {y ∈ [L]： pθ(y|x)：= XθkPk(y|x) > t},
where {pk}k∈[K] are the base predictors.
Our CP-Gen-Recal algorithm (and its practical implementation (8)) would solve a primal-dual
optimization problem with the efficiency loss and hinge approximate coverage constraint to optimize
(θ, t). However, here the efficiency loss we care about (the cardinality) is non-differentiable. We
make a further approximation by considering the Lqq norm with q = 0.5 as the surrogate efficiency
loss:
L
`eff(θ, t; (xi, yi)) ：=	[Pθ (y0 |xi) - t]q+,
y0=1
with the intuition that the q → 0 limit is exactly the cardinality of Cθ,t(xi). Our final optimization
problem is then
1 ncal L	1 ncal
θ∈m* int>0 ιmaχ—Σ E 位(y0E)- t]+ +λ-Σ`hinge(pθ(yi∣χi) -1).
θ∈∆K,t>0 λ>0 ncal	0	ncal
i=1 y0=1	i=1
We solve this by SGD on (θ, t) and (ascent on) λ, with the softmax parameterization for θ ( θ ∈ ∆K
as an ensemble weight is a probability distribution) and log parametrization for t > 0. The learning
rate is 10-2 for (θ, t) and 10-4 for λ. We perform this optimization for 500 epochs over Dcal with
batch-size 256 for ImageNet-Val and 64 for ImageNet-V2.
θbj
After we obtain the iterates
(where j denotes the epoch count), we perform a further iterate
selection of first re-computing the t(θj) by conformalizing on Dcal, and then choosing the iterate j
with the best average set size also on Dcal , before feeding it into the reconformalization step with
Drecal . As the Drecal is only used in the reconformalization step, such as method still guarantees
valid coverage like the original Algorithm 2.
We compare our above algorithm against two baselines: conformalizing each individual model and
reporting the best one, or Conformalizing the uniform ensemble (which uses weights θunif = * 1κ).
For these two baselines, for fairness of comparison, we allow them to use the whole Dcal ∪ Drecal
as the calibration set, as their construction (apart from pre-training) is not data-dependent.
Results Table 5 shows that our algorithm is able to learn label prediction sets with valid coverage
and improved set sizes over the baselines. This demonstrates the advantage of our method even in
applications where the efficiency loss (here set size) is non-differentiable and needs to be further
approximated to allow gradient-based algorithms.
22
Published as a conference paper at ICLR 2022
G Ablation studies
G. 1 Conformal quantile finetuning
We report ablation results for the conformal quantile finetuning problem with nominal coverage
level 1 - α ∈ {80%, 95%}, and otherwise exactly the same setup as Section 5.1. The conclusions
are qualitatively the same as the 90% version presented in Table 1.
Table 6: Results for conformal quantile finetuning on real-data regression tasks at level 1 - α = 80%. For
each method we report the (test) coverage, length, and pinball loss of the corresponding base quantile predictor.
All results are averaged over 8 random seeds.
Dataset	CQR			QR + CP-Gen-Recal (ours)		
	Coverage(%)	Length	test Lpinball	Coverage(%)	Length	test Lpinball
MEPS」9	80.42	0.702	0.154	80.45	0.514	0.190
MEPS _20	80.44	0.707	0.161	80.48	0.466	0.200
MEPS _21	79.91	0.696	0.151	79.85	0.618	0.192
Facebook_1	80.38	0.348	0.072	80.01	0.198	0.137
FaCebook_2	79.96	0.329	0.063	79.80	0.189	0.138
kin8nm	79.59	0.865	0.119	78.69	0.832	0.125
naval	79.91	2.777	0.311	79.76	2.721	0.311
bio	80.07	1.791	0.222	80.54	1.674	0.248
blog_data	80.64	0.399	0.082	80.10	0.272	0.158
Nominal (1 - α)	80.00	-	-	80.00	-	-
Table 7: Results for conformal quantile finetuning on real-data regression tasks at level 1 - α = 95%. For
each method we report the (test) coverage, length, and pinball loss of the corresponding base quantile predictor.
All results are averaged over 8 random seeds.
Dataset	CQR			QR + CP-Gen-Recal (ours)		
	Coverage(%)	Length	test Lpinball	Coverage(%)	Length	test Lpinball
MEPS _19	94.60	1.674	0.078	95.10	1.292	0.091
MEPS _20	94.72	1.650	0.081	94.78	1.261	0.097
MEPS _21	94.64	1.633	0.071	94.99	1.351	0.086
Facebook_1	94.96	0.797	0.036	95.04	0.601	0.061
FaCebook_2	95.17	0.700	0.031	94.98	0.560	0.060
kin8nm	95.15	1.602	0.047	94.95	1.557	0.048
naval	94.87	3.308	0.084	94.83	3.265	0.088
bio	95.17	2.698	0.073	95.22	2.587	0.084
blog ,data	95.07	0.862	0.040	95.09	0.744	0.068
Nominal (1 - α)	95.00	-	-	95.00	-	-
G.2 Multi- output regression
We report ablation results for the multi-output regression problem with nominal coverage level
1 - α ∈ {80%, 95%}, and otherwise exactly the same setup as Section 5.2. The conclusions are
qualitatively the same as the 90% version presented in Table 2, except for one dataset at level 95%.
G.3 Comparison of CP-Gen and CP-Gen-Recal
We compare the performance of CP-Gen and CP-Gen-Recal on the multi-output regression tasks
using the same setup as Section 5.2. Recall that the vanilla CP-Gen optimizes both (θb, bt) on Dcal
(we additionally reconformalize t on the same Dcal to address the potential bias in t brought by the
approximate optimization (8)), whereas our main CP-Gen-Recal algorithm optimizes θ on Dcal
1	Cr 个	T-A
and reconformalizes trecal on Drecal .
Table 10 reports the results. Observe that, except for the volume on one dataset (Humanoid), there is
no significant difference in both the coverage and the volume for the two methods. For practice we
recommend CP-Gen-Recal whenever the exact coverage guarantee is important, yet this result
23
Published as a conference paper at ICLR 2022
Table 8: Results for multi-output regression on next-state prediction tasks, at level 1 - α = 80%. For each
method we report the (test) coverage and volume of its learned box-shaped prediction set. The reported volume
is the “halfened” version Qid=ou1t ui . All results are averaged over 8 random seeds.
Dataset	Coord-wise		Coord-wise-Recal		CP-Gen-Recal (ours)	
	Coverage(%)	Volume	Coverage(%)	Volume	Coverage(%)	Volume
Cartpole	87.82	1.74 × 10-6	80.08	7.83 × 10-7	80.09	7.45 × 10-7
Half-Cheetah	88.28	4.26 × 10-7	79.96	2.42 × 10-8	80.04	1.37 × 10-8
Ant	87.77	1.97 × 10-5	80.12	3.97 × 10-7	80.06	1.75 × 10-7
Walker	90.25	5.88 × 10-7	80.28	3.13 × 10-9	80.28	1.45 × 10-9
Swimmer	91.49	1.33 × 10-6	79.99	6.18 × 10-8	79.97	4.32 × 10-9
Hopper	86.47	3.25 × 10-10	79.87	7.40 × 10-11	79.97	4.41 × 10-11
Humanoid	90.84	2.86 × 10-7	80.05	9.47 × 10-13	80.02	2.41 × 10-13
Nominal (1 - α)	80.00	-	80.00	-	80.00	-
Table 9: Results for multi-output regression on next-state prediction tasks, at level 1 - α = 95%. For each
method we report the (test) coverage and volume of its learned box-shaped prediction set. The reported volume
is the “halfened” version Qid=ou1t ui . All results are averaged over 8 random seeds.
	Coord-wise				Coord-wise-Recal				CP-Gen-Recal		(ours)	
Dataset	Coverage(%)	Volume			Coverage(%)	Volume			Coverage(%)	Volume		
Cartpole	97.21	1.07	×	10-4	95.10	4.60	×	10-5	95.12	8.61	×	10-6
Half-Cheetah	96.80	2.37	×	10-4	95.03	4.03	×	10-5	95.01	3.29	×	10-5
Ant	96.65	5.30	×	10-1	95.02	4.87	×	10-2	95.09	2.39	×	10-2
Walker	97.01	8.08	×	10-4	94.94	6.21	×	10-5	94.99	4.27	×	10-5
Swimmer	97.74	3.44	×	10-4	94.95	3.77	×	10-5	95.01	5.34	×	10-6
Hopper	96.27	1.76	×	10-8	94.96	8.23	×	10-9	94.96	1.19	×	10-8
Humanoid	97.22	3.58	×	10-1	94.99	7.69	×	10-4	94.91	7.49	×	10-4
Nominal (1 - α)	95.00		-		95.00		-		95.00		-	
shows that—perhaps originating from the fact that here ncal = 20000 is large—the coverage (gen-
eralization error) of CP-Gen is also nearly valid, which may be better than what our Proposition 2
suggests.
Table 10: Comparison of CP-Gen and CP-Gen-Recal on the multi-output regression tasks. The reported
volume is the “halfened” version Qid=ou1t ui .
Dataset	CP-Gen-Recal		CP-Gen	
	Coverage(%)	Volume	Coverage(%)	Volume
Cartpole	90.12	2.30 X 10-6	90.09	2.30 X 10-6
Half-Cheetah	90.02	9.07 × 10-7	89.96	8.83 X 10-7
Ant	90.02	8.25 X 10-5	89.98	8.21 X 10-5
Walker	89.94	3.47 X 10-7	89.91	3.30 X 10-7
Swimmer	90.13	1.46 X 10-7	89.96	1.29 X 10-7
Hopper	89.92	8.25 X 10-10	89.92	8.23 X 10-10
Humanoid	89.94	4.95 X 10-8	90.05	7.08 X 10-8
Nominal	90.00	-	90.00	-
24
Published as a conference paper at ICLR 2022
H Additional experiments and analyses
H.1 Conditional coverage of CP-Gen-Recal
We analyze the improved length prediction intervals learned by CP-Gen-Recal (Section 5.1) by
evaluating its conditional coverage metrics and comparing with the baseline CQR method.
As conditional coverage is hard to reliably estimate from finite data, we consider two proxy metrics
proposed in (Feldman et al., 2021) that measure the independence between length and indicator of
coverage:
The correlation coefficient (Corr) between the following two random variables: the interval size
L = length(C(X)) and the indicator of coverage V
1 Y∈
Cb(X)
. A (population) corre-
lation of0 is a necessary (but not sufficient) condition of perfect conditional coverage (Feldman
et al., 2021). Here we measure the absolute correlation, which is smaller the better.
• HSIC: A more sophisticated correlation metric between L and V that takes into account nonlin-
ear correlation structures. A (population) HSIC of 0 is a necessary and sufficient condition of
the independence between L and V . We estimate HSIC on the finite test data using the method
in (Feldman et al., 2021).
Table 11 reports the results. Observe that while our CP-Gen-Recal improves the length, it
achieves worse (higher) Correlation/HSIC than the baseline CQR, which is expected as length and
conditional coverage often come as a trade-off.
Table 11: Conditional coverage results for conformal quantile finetuning on real-data regression tasks at
level 1 - α = 90%. For each method we report the (absolute) correlation coefficient as well as the HSIC metric
between length and indicator of coverage. All results are averaged over 8 random seeds.
Dataset	CQR			QR +	CP-Gen-Recal (ours)	
	Corr(1)	HSICa)	Length(I)	Corr(1)	HSICa)	Lengtha)
MEPS_19	0.022	3.03 × 10-5	1.167	0.049	1.77 × 10-4	0.890
MEPS _20	0.032	3.63 × 10-5	1.165	0.113	2.66 × 10-4	0.830
MEPS_21	0.029	4.72 × 10-5	1.145	0.068	2.20 × 10-4	0.962
Facebook. 1	0.029	1.27 × 10-5	0.555	0.175	7.34 × 10-4	0.384
FaCebook_2	0.024	1.16 × 10-5	0.491	0.116	2.68 × 10-4	0.364
kin8nm	0.031	4.85 × 10-5	1.214	0.084	9.32 × 10-5	1.173
naval	0.091	1.05 × 10-5	3.095	0.064	2.16 × 10-5	3.077
bio	0.026	4.15 × 10-5	2.271	0.041	1.09 × 10-4	2.164
blog ,data	0.013	4.60 × 10-5	0.605	0.141	5.75 × 10-4	0.496
H.2 Alternative tweaks for CQR baseline
Here we test two additional tweaked versions of the CQR baseline in the prediction interval experi-
ment of Section 5.1:
•	CQR-Dtrain ∪ Dcal : Use dataset Dtrain ∪ Dcal for training the base quantile regressor, then
conformalize on Drecal .
•	CQR-PinballFt: Train the base quantile regressor on Dtrain, and finetune the last linear
layer on Dcal using the pinball loss (same as training), and conformalize on Drecal.
Optimization details about these two methods are described in Section H.2.1.
Result Table 12 reports the results for these two tweaked baselines, in comparison with our orig-
inal baseline CQR as well as our proposed QR + CP-Gen-Recal. Observe that using more train-
ing data (CQR-Dtrain ∪ Dcal) improves the length slightly on some datasets but not all. In con-
trast, CQR-PinballFt is unable to improve either the pinball loss or the length over the base
CQR(observe that CQR-PinballFt uses the same set of training data as CQR-Dtrain ∪ Dcal but
uses a less expressive model in the finetuning stage). Overall, on almost all datasets (except for
kin8nm), our CP-Gen-Recal still achieves the best length.
25
Published as a conference paper at ICLR 2022
Table 12: Results for conformal quantile finetuning on real-data regression tasks at level 1-α = 90%. Here
we compare our CP-Gen-Recal method with tweaked versions of the baseline CQR method. All results
are averaged over the same 8 random seeds as in Table 1. All (average) coverages are within (90 ± 0.5)% and
omitted here.
Dataset	CQR-Dtrain		CQR-Dtrain ∪ Dcal		CQR-PinballFt		QR + CP-Gen-Recal (ours)	
	Length	test Lpinball	Length	test LPinball	Length	test LPinball	Length	test LPinball
MEPS-19	1.167	0.112	1.171	0.111	1.192	0.112	0.890	0.131
MEPS _20	1.165	0.117	1.179	0.114	1.190	0.117	0.830	0.141
MEPS_21	1.145	0.107	1.150	0.106	1.249	0.107	0.962	0.129
Facebook. 1	0.555	0.052	0.549	0.051	0.578	0.052	0.384	0.090
FaCebook_2	0.491	0.044	0.472	0.042	0.523	0.044	0.364	0.092
kin8nm	1.214	0.076	1.165	0.072	1.232	0.075	1.173	0.078
naval	3.095	0.164	3.089	0.164	3.096	0.164	3.077	0.166
bio	2.271	0.130	2.240	0.128	2.271	0.130	2.164	0.148
blog_data	0.605	0.058	0.551	0.056	0.660	0.058	0.496	0.107
H.2.1 Optimization details
CQR-Dtrain ∪ Dcal : Our original CQR baseline used Dcal for monitoring validation loss and au-
tomatically determining the early stopping (cf. Section E.1), and Drecal for conformalization. To
optimize on Dtrain ∪ Dcal, we do not use automatic learning rate decay and early stopping, but in-
stead manually picked the number of epochs and corresponding learning rate decay schedule that is
close to average runs of the CQR method on each dataset. This choice ensures that our new baseline
still gets to use see the exact same amount of data for conformalizing (Drecal) and testing (Dtest),
and has a optimization setup as close as possible the original CQR baseline.
More concretely, We optimize for 800 epochs for {MEPS_19, MEPS_20, MEPS_21}, 1500 epochs
for {Facebook」, FacebookN, blog-data}, 6000 epochs for kin8nm, 350 epochs for naval, and 2500
epochs for bio. For all datasets, the learning rate decays by 10x tWice, at 90% and 95% of the total
epochs.
CQR-PinballFt: We finetuned on Dcal With 1000 epochs and batch size 256. The learning rate
Was chosen Within {10-2, 10-3} and the results are not too different for these tWo choices (length
difference is Within 0.010 for these tWo choices, and there is no overall Winner). We presented the
results With learning rate 10-3.
H.3 Additional Max-score-Conformal baseline for multi-output regression
We test one additional baseline method for the multi-output regression experiment in Section 5.2:
• Max-score-Conformal: Here We consider the hypercube-shaped predictor
dout
Ct(x) = Y[fbi(x) - t,fi(x) + t],	(16)
i=1
and use conformal prediction on Dcal ∪ Drecal to compute a conformalized t and the final
prediction set Ctb(x). In other Words, We perform standard conformal prediction With score
C J II	G/ ∖ II
function ky - f (x)k∞.
We remark that both the Coord-wise-Recal and the Max-score-Conformal baseline
methods are special instances of CP-Gen-RecalWith some fixed θ0: In our parametrization,
u = (θ, t), θ determines the shape (i.e. relative ratios betWeen the u0is) Whereas t determines the
size. Therefore, Max-score-Conformal can be thought ofas choosing θ0 to be the all-ones ra-
tio (i.e. hypercube-shaped), Whereas Coord-wise-Recalcan be thought of as choosing θ0 from
a coordinate-Wise one dimensional conformal prediction.
Result Table 13 reports the result for Max-score-Conformal. Compared With the exist-
ing baseline Coord-wise-Recal, Max-score-Conformal achieves better volume on the
Cartpole dataset but Worse volume on almost all other datasets (except for SWimmer Where their
26
Published as a conference paper at ICLR 2022
volumes are similar). Further, note that Max-score-Conformal achieves significantly higher
volumes for certain datsets (Ant, Humanoid). Our inspection shows that this due to the fact that
there are a certain number of hard-to-predict state dimensions (and many other easy-to-predict
state dimensions) for these two datasets. Therefore, Coord-wise-Recal which builds on
Coord-wise adapts to this structure and uses only a high length on these dimensions only, whereas
the Max-score-Conformal method pays this max conformal score on all dimensions to yield
an unnecessarily high volume.
We remark that our CP-Gen-Recal still performs significantly better than both baselines.
Table 13: Results for multi-output regression on next-state prediction tasks, at level 1 - α = 90%. The
setting is the same as in Table 2 (with the same 8 random seeds), and here we compare additionally with the
Max-score-Conformal baseline method described in (16).
Dataset	Coord-wise-Recal		Max-score-Conformal		CP-Gen-Recal (ours)	
	Coverage(%)	Volume	Coverage(%)	Volume	Coverage(%)	Volume
Cartpole	90.17	5.10 × 10-6	90.10	3.07 × 10-6	90.12	2.30 × 10-6
Half-Cheetah	90.06	1.23 × 10-6	89.96	1.72 × 10-4	90.02	9.07 × 10-7
Ant	89.99	1.70 × 10-4	90.06	3.46 × 102	90.02	8.25 × 10-5
Walker	90.01	7.33 × 10-7	90.02	1.03 × 10-2	89.94	3.47 × 10-7
Swimmer	89.90	2.22 × 10-6	90.08	2.21 × 10-6	90.13	1.46 × 10-7
Hopper	90.02	1.01 × 10-9	89.96	1.29 × 10-8	89.92	8.25 × 10-10
Humanoid	89.95	8.53 × 10-8	89.98	2.48 × 107	89.94	4.95 × 10-8
Nominal (1 - α)	90.00	-	90.00	-	90.00	-
H.4	100 random seeds and standard deviation
Here we repeat the experiments in Section 5.1 & 5.2 with 100 random seeds and the exact same se-
tups. We report the mean and standard deviations in Table 14 for the prediction intervals experiment
(Section 5.1), Table 15 for the mean and Table 16 for the standard deviation for the multi-output
regression experiment (Section 5.2).
Table 14: Results for conformal quantile finetuning on real-data regression tasks at level 1 - α = 90%. For
each method we report the (test) coverage, length, and pinball loss of the corresponding base quantile predictor.
All results are averaged over 100 random seeds.
Dataset	CQR			QR + CP-Gen-Recal (ours)		
	Coverage(%)	Length	test Lpinball	Coverage(%)	Length	test Lpinball
MEPS_19	89.92 ±1.16	1.147 ±0.057	0.107 ±0.013	89.95 ±0.012	0.895 ± 0.126	0.130 ±0.015
MEPS_20	89.90 ±0.98	1.164 ±0.054	0.109 ±0.012	89.97 ±0.011	0.872 ± 0.113	0.131 ±0.015
MEPS_21	90.00 ±0.94	1.162 ±0.056	0.104 ±0.011	90.08 ±0.011	0.910 ± 0.133	0.126 ±0.013
Facebook」	90.12 ±0.71	0.540 ±0.040	0.050 ±0.007	90.07 ±0.007	0.382 ± 0.051	0.089 ±0.009
Facebook_2	90.04 ±0.50	0.497 ±0.028	0.044 ±0.005	90.06 ±0.005	0.389 ± 0.075	0.091 ±0.007
kin8nm	90.34 ±1.37	1.238 ±0.067	0.076 ±0.004	90.31 ±0.013	1.216 ± 0.068	0.080 ±0.004
naval	89.99 ±1.13	3.101 ±0.015	0.164 ±0.001	89.95 ±0.011	3.095 ± 0.028	0.167 ±0.001
bio	90.00 ±0.69	2.261 ±0.033	0.130 ±0.002	89.97 ±0.005	2.154 ± 0.031	0.148 ±0.003
blog,data	89.99 ±0.60	0.593 ±0.033	0.058 ±0.005	89.95 ±0.007	0.460 ± 0.075	0.104 ±0.006
Nominal (1 - α	90.00	-	-	90.00	-	-
27
Published as a conference paper at ICLR 2022
Table 15: Results for multi-output regression (mean) on next-state prediction tasks, at level 1 - α = 90%.
For each method we report the (test) coverage and volume of its learned box-shaped prediction set. The reported
volume is the “halfened” version Qid=ou1t ui. All results are averaged over 100 random seeds.
	Coord-wise		Coord-wise-Recal		CP-Gen-Recal (ours)	
Dataset	Coverage(%)	Volume	Coverage(%)	Volume	Coverage(%)	Volume
Cartpole	94.30	1.14 × 10-5	90.02	4.80 × 10-6	90.03	2.05 × 10-6
Half-Cheetah	93.84	1.05 × 10-5	90.00	1.22 × 10-6	90.02	9.01 × 10-7
Ant	93.53	3.26 × 10-3	89.94	1.75 × 10-4	89.98	9.22 × 10-5
Walker	94.52	2.82 × 10-5	89.99	7.48 × 10-7	90.00	3.74 × 10-7
Swimmer	95.65	2.82 × 10-5	90.02	2.18 × 10-6	90.01	1.24 × 10-7
Hopper	92.95	2.53 × 10-9	89.98	8.86 × 10-10	89.99	7.04 × 10-10
Humanoid	94.87	7.43 × 10-4	90.06	1.69 × 10-7	90.03	8.95 × 10-8
Nominal (1 - α)	90.00	-	90.00	-	90.00	-
Table 16: Results for multi-output regression (standard deviation) on next-state prediction tasks, at level
1 - α = 90%. For each method we report the (test) coverage and volume of its learned box-shaped prediction
set. The reported volume is the “halfened” version Qid=ou1t ui. All standard deviations are computed over 100
random seeds.
Coord-wise	Coord-wise-Recal	CP-Gen-Recal (ours)
Dataset	Coverage(%)	Volume	Coverage(%)	Volume	Coverage(%)	Volume
Cartpole	0.35	3.57 × 10-6	0.31	1.33 × 10-6	0.27	4.46 × 10-7
Half-Cheetah	0.25	2.46 × 10-6	0.32	2.75 × 10-7	0.31	2.10 × 10-7
Ant	0.27	1.50 × 10-3	0.29	8.06 × 10-5	0.29	4.15 × 10-5
Walker	0.24	8.81 × 10-6	0.30	2.18 × 10-7	0.29	1.12 × 10-7
Swimmer	0.24	6.47 × 10-6	0.29	5.83 × 10-7	0.33	3.36 × 10-8
Hopper	0.29	6.83 × 10-10	0.29	2.26 × 10-10	0.33	1.97 × 10-10
Humanoid	0.23	1.22 × 10-3	0.30	2.71 × 10-7	0.29	1.47 × 10-7
28