Published as a conference paper at ICLR 2022
Self-Supervised Inference in State-Space Mod-
ELS
David Ruhe	Patrick Forre
AI4Science, AMLab, Anton Pannekoek Institute AI4Science, AMLab
University of Amsterdam, The Netherlands	University of Amsterdam, The Netherlands
d.ruhe@uva.nl	p.d.forre@uva.nl
Ab stract
We perform approximate inference in state-space models with nonlinear state tran-
sitions. Without parameterizing a generative model, we apply Bayesian update
formulas using a local linearity approximation parameterized by neural networks.
This comes accompanied by a maximum likelihood objective that requires no su-
pervision via uncorrupt observations or ground truth latent states. The optimiza-
tion backpropagates through a recursion similar to the classical Kalman filter and
smoother. Additionally, using an approximate conditional independence, we can
perform smoothing without having to parameterize a separate model. In scien-
tific applications, domain knowledge can give a linear approximation of the latent
transition maps, which we can easily incorporate into our model. Usage of such
domain knowledge is reflected in excellent results (despite our model’s simplic-
ity) on the chaotic Lorenz system compared to fully supervised and variational
inference methods. Finally, we show competitive results on an audio denoising
experiment.
1 Introduction
Many sequential processes in industry and research involve noisy measurements that describe la-
tent dynamics. A state-space model is a type of graphical model that effectively represents such
noise-afflicted data (Bishop, 2006). The joint distribution is assumed to factorize according to a di-
rected graph that encodes the dependency between variables using conditional probabilities. One is
usually interested in performing inference, meaning to obtain reasonable estimates of the posterior
distribution of the latent states or uncorrupt measurements. Approaches involving sampling (Neal
et al., 2011), variational inference (Kingma & Welling, 2013), or belief propagation (Koller & Fried-
man, 2009) have been proposed before. Assuming a hidden Markov process (Koller & Friedman,
2009), the celebrated Kalman filter and smoother (Kalman, 1960; Rauch et al., 1965) are classical
approaches to solving the posterior inference problem. However, the Markov assumption, together
with linear Gaussian transition and emission probabilities, limit their flexibility. We present filtering
and smoothing methods that are related to the classical Kalman filter updates but are augmented with
flexible function estimators without using a constrained graphical model. By noting that the filtering
and smoothing recursions can be back-propagated through, these estimators can be trained with a
principled maximum-likelihood objective reminiscent of the noise2noise objective (Lehtinen
et al., 2018; Laine et al., 2019). By using a locally linear transition distribution, the posterior distri-
bution remains tractable despite the use of non-linear function estimators. Further, we show how a
linearized smoothing procedure can be applied directly to the filtering distributions, discarding the
need to train a separate model for smoothing.
To verify what is claimed, we perform three experiments. (1) A linear dynamics filtering experi-
ment, where we show how our models approximate the optimal solution with sufficient data. We
also report that including expert knowledge can yield better estimates of latent states. (2) A more
challenging chaotic Lorenz smoothing experiment that shows how our models perform on par with
recently proposed supervised models. (3) An audio denoising experiment that uses real-world noise
showing practical applicability of the methods.
Our contributions can be summarized as follows.
1
Published as a conference paper at ICLR 2022
Noisy measurements
Extended Kalman Smoother	Recurrent Smoother (Ours)
Recursive Smoother (Ours)
Ground Truth
Figure 1: Best viewed on screen. Qualitative results of our work. To the noisy measurements (1st
from left), we apply an extended Kalman smoother (2nd). From the noisy measurements, we learn
a recurrent model that does slightly better (3rd). Our recursive model combines expert knowledge
with inference (4th), yielding the best result. Ground truth provided for comparison (5th).
1.	We show that the posterior inference distribution of a state-space model is tractable while
parameter estimation is performed by neural networks. This means that we can apply the
classical recursive Bayesian updates, akin to the Kalman filter and smoother, with mild
assumptions on the generative process.
2.	Our proposed method is optimized using maximum likelihood in a self-supervised manner.
That is, ground truth values of states and measurements are not assumed to be available for
training. Still, despite our model’s simplicity, our experiments show that it performs better
or on par with several baselines.
3.	We show that the model can be combined with prior knowledge about the transition and
emission probabilities, allowing for better applicability in low data regimes and incentiviz-
ing the model to provide more interpretable estimates of the latent states.
4.	A linearized smoothing approach is presented that does not require explicit additional pa-
rameterization and learning of the smoothing distribution.
2	Related Work
Becker et al. (2019) provide a detailed discussion of recent related work, which we build on here and
in table 1. An early method that extends the earlier introduced Kalman filter by allowing nonlinear
transitions and emissions is the Extended Kalman filter (Ljung, 1979). It is limited due to the naive
approach to locally linearize the transition and emission distributions. Furthermore, the transition
and emission mechanisms are usually assumed to be known, or estimated with Expectation Maxi-
mization (Moon, 1996). More flexible methods that combine deep learning with variational infer-
ence include Black Box Variational Inference (Archer et al., 2015), Structured Inference Networks
(Krishnan et al., 2017), Kalman Variational Autoencoder (Fraccaro et al., 2017), Deep Variational
Bayes Filters (Karl et al., 2017), Variational Sequential Monte Carlo (Naesseth et al., 2018) and Dis-
entangled Sequential Autoencoder (Yingzhen & Mandt, 2018). However, the lower-bound objective
makes the approach less scalable and accurate (see also Becker et al. (2019). Furthermore, all of
the above methods explicitly assume a graphical model, imposing a strong but potentially harmful
inductive bias. The BackpropKF (Haarnoja et al., 2016) and Recurrent Kalman Network (Becker
et al., 2019) move away from variational inference and borrow Bayesian filtering techniques from
the Kalman filter. We follow this direction but do not require supervision through ground truth latent
states or uncorrupt emissions. Satorras et al. (2019) combine Kalman filters through message pass-
ing with graph neural networks to perform hybrid inference. We perform some of their experiments
by also incorporating expert knowledge. However, contrary to their approach, we do not need su-
pervision. Finally, concurrently to this work, Revach et al. (2021) develop KalmanNet. It proposes
similar techniques but evaluates them in a supervised manner. The authors, however, do suggest
that an unsupervised approach can also be feasible. Additionally, we more explicitly state what gen-
erative assumptions are required, then target the posterior distribution of interest, and develop the
model and objective function from there. Moreover, the current paper includes linearized smoothing
(section 6), parameterized smoothing (appendix A), and the recurrent model (appendix C). We also
denote theoretical guarantees under the noise2noise objective.
2
Published as a conference paper at ICLR 2022
scalable state est. uncertainty noise dir. opt. self-sup.
Ljung(1979)	X /× X	X X ×	×
HoChreiteret. al. (1997)	X	X	X / ×	X	X	×
Cho et al. (2014)	X	X	X/×	X	X	×
WahlStrometaL (2015)	X	X	X/ ×	×	X	×
Watter et al. (2015)	X	×	X	X	×	X
ArCher et al. (2015)
KriShnan et al. (2017)
FraCCaro et al. (2017)
Karl et al. (2017)
NaeSSeth et al. (2018)
Yingzhen et al. (2018)
X /×	×	X
X×	X
X /×	×	X
X×	X
X×	X
X×	X
X×	X
X×	X
X×	X
X×	X
X×	X
××	X
RangaPurametaL (2018) X/ × X (1D)	X
Doerr et al. (2018)	× X	X
×X	X
XX	X
SatorraS et al. (2019)
Haarnoja et al. (2016)
BeCker et al. (2019)
XX	×
XX	X
XX	X
XX	×
XX	×
XX	×
Ours
X /×	X	X X X X
Figure 2: State-spaCe model with deeper la-
tent struCture.
Table 1: We ComPare whether algorithmS are SCal-
able, State eStimation Can be Performed, modelS Pro-
vide unCertainty eStimateS, noiSy or miSSing data
Can be handled, oPtimization iS Performed direCtly
and if supervision is required. “X/x” means that it
dePendS on the Parameterization.
3	Generative Model Assumptions
In this seCtion, we expliCitly state the model’s generative proCess assumptions. First, we assume
that we Can measure (at least) one run of (noise-affliCted) sequential data y0:K := (y0, . . . , yK),
where eaCh yk ∈ RM, k = 0, . . . , K. We abbreviate: yl:k := (yl, . . . , yk) and y<k := y0:k-1
and y≤k := y0:k and y-k := (y0:k-1, yk+1:K). We then assume that y0:K is the result of some
possibly non-linear probabilistiC latent dynamiCs, i.e., ofa distribution p(x0:K), whose variables are
given by x0:K := (x0, . . . , xK) with xk ∈ RN. EaCh yk is assumed to be drawn from some shared
noisy emission probability p(yk | xk). The joint probability is then assumed to faCtorize as:
K
p(y0:K, x0:K) = p(x0:K)	p(yk | xk).	(1)
k=0
Further impliCit assumptions about the generative model are imposed via inferenCe model ChoiCes
(see seCtion 7). Note that this faCtorization enCodes several Conditional independenCes like
yk ⊥⊥ (y-k , x-k) | xk .	(2)
TypiCal models that follow these assumptions are linear dynamiCal systems, hidden Markov models,
but also nonlinear state-spaCe models with higher-order Markov Chains in latent spaCe like presented
in fig. 2.
In Contrast to other approaChes (e.g., Krishnan et al. (2015); Johnson et al. (2016); Krishnan et al.
(2017)) where one tries to model the latent dynamiCs with transition probabilities p(xk | xk-1) and
possibly non-linear emission probabilities p(yk | xk), we go the other way around. We assume that
all the non-linear dynamiCs are Captured inside the latent distribution p(x0:K), where at this point
we make no further assumption about its faCtorization, and the emission probabilities are (well-
approximated with) a linear Gaussian noise model:
p(yk | xk) = N (yk | Hxk,R) ,	(3)
where the matrix H represents the measurement deviCe and R is the CovarianCe matrix of the in-
dependent additive noise. We make a brief argument why this assumption is not too restriCtive.
First, if one is interested in denoising Corrupted measurements, any nonlinear emission Can be Cap-
tured direCtly inside the latent states xk . To see this, let zk ∈ RN-M denote non-emitted state
variables. We then put xk := [yk zk]>, where yk is Computed by applying the nonlinear emis-
sion to zk . We thus inClude the measurements in the modeled latent state xk . Then we Can put
H := IM 0M×(N-M). SeCond, teChniques proposed by Laine et al. (2019) allow for non-
Gaussian noise models, relaxing the need for assumption eq. (3). Third, we Can loCally linearize the
3
Published as a conference paper at ICLR 2022
emission (Ljung, 1979). Finally, industrial or academic applications include cases where emissions
are (sparse) Gaussian measurements and the challenging nonlinear dynamics occur in latent space.
Examples can be found in MRI imaging (Lustig et al., 2007) and radio astronomy (Thompson et al.,
2017).
4 Parameterization
In this section, we show how we parameterize the inference model. A lot of the paper’s work relies
on established Bayesian filtering machinery. However, for completeness, we like to prove how all
the update steps remain valid while using neural networks for function estimation.
Given our noisy measurements y0:K = (y0 , . . . , yK) we want to find good estimates for the latent
states x0:K = (x0, . . . , xK), which generated y0:K. For this, we want to infer the marginal condi-
tional distributions p(xk | y≤k) or p(xk | y<k) (for forecasting), for an online inference approach
(filtering); and p(xk | y0:K) or p(xk | y-k), for a full inference approach (smoothing). In the
main body of the paper, we only consider filtering. Smoothing can be performed similarly, which is
detailed in the supplementary material (appendix A).
We start with the following advantageous parameterization:
P(Xk I χk-ι,y<k) = N (Xk I Fk∣<k χk-ι + e^k∣<k,Qk∣<k),	(4)
where F⅛∣<k ：= F⅛∣<k (y<k), e⅛∣<k := e⅛∣<k(y<k) and Qk∣<k := Qk∣<k(y<k) are parameterized
with neural networks. Next, we have available
P(Xk-I | y≤(k-1)) = N (χk-ι | χ(k-i)∣≤(k-i),Rk-i)∣≤(k-i)),
(5)
i.e., the previous time-step’s conditional marginal distribution of interest. For k = 1, this is some
initialization. Otherwise, it is the result of the procedure we are currently describing. We use this
distribution to evaluate the marginalization
P(Xk I y<k) = P(Xk I Xk-1, y<k) P(Xk-1 I y<k) dXk-1
=N (Xk | xk∣<k, Pk | <k ),
(6)
with
xk∣<k (y<k ) = Fk|<k xk-1∣≤k-1 + ek∣<k,
>
Pk∣<k (y<k ) = Fk∣<k Pk-1∣≤k-1 Fk∣<k + Qk|<k ∙
(7)
Note that the distributions under the integral eq. (6) are jointly Gaussian only because of the param-
eterization eq. (4). Hence, we can evaluate the integral analytically.
Finally, to obtain the conditional P(Xk I y≤k) = P(Xk I yk, y<k) we use Bayes’ rule:
/ I	、	p(yk	I	Xk,	y<k)	∙ p(χk I y<k) eq.⑵	p(yk	I	Xk)	,	∣	、
P(XkIyk，y<k) =-------------PB^----------------- = PB^ ∙P(Xk Iy<k).⑻
Equation (3) and the result eq. (6) allow us to also get an analytic expression for
P(Xk I y≤k) = N (Xk I Xk∣≤k, Pk∣≤k)	(9)
with the following abbreviations:
χ^k∣≤k(y≤k) ：= Xk|<k + Kklyk- HXk|<k), Pk∣≤k(y≤k) ：= Pk∣<k - Kk HPkVk. (IO)
We introduce the Kalman gain matrix similar to the classical formulas:
Kk := Pk∣<k H> (HPkI<k H> + R)-1.	(11)
Note that taking the matrix inverse at this place in eq. (11) is more efficient than in the standard
Gaussian formulas (for reference presented in appendix B) if M ≤ N , which holds for our experi-
ments.
4
Published as a conference paper at ICLR 2022
Figure 3: Our recursive model visualized. Data-Point yk is fed, together with hidden state h→,
into a GRU unit. The new hidden state h→+ι is decoded into multiplicative component Fk+ι and
additive component ek+ι. Using these, the previous posterior mean Xk∣≤k is transformed into the
prior estimate for time-step k + 1 Xk+ι≤k. y^+ι is used to obtain posterior mean Xk+ι∣≤(k+i).
This completes the recursion: we can use eq. (9) for a new time-step k + 1 by plugging it back
into eq. (6). We have shown how estimating a local linear transition using neural networks in eq. (4)
ensures that all the recursive update steps from the Kalman filter analytically hold without specifying
and estimating a generative model.
We note that we could also have parameterized
p(χk | y<k) = N (Xk | Xk∣<k(y<k), Pk∣<k(y<k))	(12)
with Xk∣<k(y<k) and Pk∣<k(y<k) directly estimated by a neural network. This has the advantage
that we do not rely on a local linear transition model. However, it also means that we are esti-
mating xk without any form of temporal regularization. Additionally, it is harder to incorporate
prior knowledge about the transitions maps into such a model. Nonetheless, we detail this param-
eterization further in the supplementary material (appendix C) and include its performance in our
experiments in section 8.
To conclude the section, we like to discuss some of the limitations of the approach. 1. The Gaus-
sianity assumption of eq. (4) ensures but also restricts eq. (8) and eq. (9) to these forms. That is,
we make a direct assumption about the form of the posterior p(xk | y≤k). Defending our case,
we like to point out that methods such as variational inference (Krishnan et al., 2017) or posterior
regularization (Ganchev et al., 2010) also make assumptions (e.g., mean-field Gaussian) about the
posterior. 2. Since we did not explicitly specify a factorization of p(x0:K), we cannot ensure that
the distributions we obtain from the above procedure form a posterior to the ground truth generative
process. This does not mean, however, that we cannot perform accurate inference. Arguably, not
making explicit assumptions about the generative process is preferred to making wrong assumptions
and using those for modeling, which can be the case for variational auto-encoders. 3. The local
linearity assumption is justifiable if the length between time-steps is sufficiently small. However,
note that the model is more flexible than directly parameterizing eq. (12) (see appendix C) since it
reduces to that case by putting Fk := 0 for all k.
5 Fitting
We have shown in the previous section how parameterization of a local linear transition model
leads to recursive estimation of p(xk | y<k) and p(xk | y≤k) for all k using classical Bayesian
filtering formulas. The inference is only effective if the estimates Fk∣<k, ek∣<k and Qk∣<k from
eq. (4) are accurate. We can use the parameterization p(xk | y<k) of eq. (6), the emission model
p(yk | xk) = N(yk | H xk, R) from eq. (3), and the factorization from eq. (1) to see that an
analytic form of the log-likelihood of the data emerges:
p(yk | y<k)
p(yk | xk) p(xk | y<k) dxk
N (yk I HXk∣<k(y<k),HPk∣<k(y<k) H> + R),
(13)
5
Published as a conference paper at ICLR 2022
K
log p(yo：K) = X log N (y® | H Xk∣<k (y<k), HPk∣<k (y<k) H > + R .	(14)
k=0
If we put yk∣<k := H xk|<® (y<k) and Mk|<k := HP%<k(y<k) H 1 + R, then the maximum-
likelihood objective leads to the following loss function, which we can minimize using gradient
descent methods w.r.t. all model parameters:
K
L ：= X (y,y<<k - yk)> M-<k(y®i<k - yk) + logdet M用<®].	(15)
k=0
Note that each term in the sum above represents a one-step-ahead self-supervised error term. We
thus minimize the prediction residuals 0k∣<k(y<k) - yk in a norm that is inversely scaled with
the above covariance matrix, plus a regularizing determinant term, which prevents the covariance
matrix from diverging. The arisen loss function is similar to the noise2noise (Lehtinen et al.,
2018; Krull et al., 2019; Batson & Royer, 2019; Laine et al., 2019) objective from computer vision
literature, combined with a locally linear transition model like Becker et al. (2019). We show in
appendix D that this objective will yield correct results (meaning estimating the ground-truth xk) if
the noise is independent with E[yk | Hxk] = Hxk. A similar procedure in the causality literature
is given by ScholkoPf et al. (2016). An algorithmic presentation of performing inference and fitting
is presented in appendix E.
Note that after fitting the parameters to the data, eq. (6) can directly be used to do one-step ahead
forecasting. Forecasting an arbitrary number of time steps is possible by plugging the new value
Xκ+ι∣κ via yκ+ι := H Xκ+ι∣κ back into the recurrent model, and so on. This is not a generative
model but merely a convenience that we deemed worth mentioning.
6 Linearized Smoothing
So far, we have only discussed how to perform filtering. Recall that for smoothing, we are instead
interested in the quantity p(xk | y0:K). A smoothing strategy highly similar to the methods de-
scribed earlier can be obtained by explicitly parameterizing such a model, which we detail in the
supplementary material. Here, we introduce a linearized smoothing procedure. The essential advan-
tage is that no additional model has to be trained, which can be costly. Several algorithms stemming
from the Kalman filter literature can be applied, such as the RTS smoother (Rauch et al., 1965) and
the two-filter smoother (Kitagawa, 1994). To enable this, we need to assume that the conditional
mutual information I (xk-1; yk:K | xk, y0:k-1) is small for all k = 1, . . . , K. In other words, we
assume that we approximately have the following conditional independences:
xk-1 ⊥⊥ yk:K | (xk, y0:k-1).	(16)
To explain the motivation for this requirement, consider the model in fig. 2. If the states of y0:k-1
and xk are known, then the additional information that yk:K has about the latent variable xk-1
would need to be passed along the unblocked deeper paths like yk+ι J Xk+ι J ek+ι J ek J
xk-1. Then the assumption of small I(xk-1; yk:K | xk, y0:k-1) can be interpreted as that the
deeper paths transport less information than the lower direct paths. If we consider all edges to the
xk’s as linear and the edges to the ek’s as non-linear maps, the above could be interpreted as an
information-theoretic version of expressing that the non-linear correction terms are small compared
to the linear parts in the functional relations between the variables.
We will now show that under the earlier assumptions and eq. (16) we get a Gaussian approximation:
p(xk | yo：K) ≈ N (Xk | Zk, Gk). We will do backward induction with ZK := Xκ∣≤κ and
GK := PK∣≤κ. To propagate this to previous time steps k - 1 we use the chain rule:
p(xk-1
| y0:K) =	p(xk-1
| xk, y0:K) p(xk | y0:K) dxk,
(17)
where the second term is known by backward induction and for the first term we make use of the
approximate conditional independence from eq. (16) to get
p(xk-1 | xk , y0:K ) = p(xk-1 | yk:K , xk , y0:k-1 )	≈	p(xk-1 | xk , y0:k-1 ).	(18)
6
Published as a conference paper at ICLR 2022
The latter was shown to be Gaussian in section 4:
P(χk-1, Xk | yo：k-i)= N	[xχ- 1] 1 Fxk∣≤k-1
PIk-1∣≤k-1
Fk|<k Pk -1∣≤k-1
^	. .	^ T
Pk-1∣≤k-1 Fk∣<k
Pk|<k
(19)
By use of the usual formulas for Gaussians and the reverse KaIman gain matrix Jk-1∣k We arrive at
the following update formulas, k = K,..., 1, with ZK
xκ∣≤κ an
一 J	ʌ
d Gk := PK
≤K:
>	-1
jk-1∣k := Pk-1∣≤k-1 Fk∣<k Pk|<k，
>
Gk-I ：= Pk-1∣≤k-1 + Jk-1|k (Pk∣≤k - Pk|<k ) Jk-1∣k ,
zk-1 := xk-1∣≤k-1 + Jk-1∣k (Zk - xk∣≤k)
As such, we can perform inference for all k = 0, . . . , K with p(xk | y0:K) ≈ N
Algorithmically, the above is presented in appendix E.
(xk | Zk,
(20)
(21)
(22)
7 Recurrent Neural Network
Before going into the experiments section, we briefly explain how we specifically estimate the
functions Fk∣<k(y<k), ek∣<k(y<k) and Qk∣<k(y<k) that parameterize the transition probability
p(xk | y<k, xk-1) (eq. (4)). The choice of the model here implicitly makes further assumptions
about the generative model. Ifwe consider neural networks, the temporal nature of the data suggests
recurrent neural networks (Graves et al., 2013), convolutional neural networks (Kalchbrenner et al.,
2014), or transformer architectures (Vaswani et al., 2017). Additionally, if the data is image-based,
one might further make use of convolutions. For our experiments, we use a Gated Recurrent Unit
(GRU) network (Cho et al., 2014), that recursively encodes hidden representations. Therefore, we
put
Qk|<k ：= LkLk ,
■ ʌ -1
Fk
ek ：= f(h→ ),
L k
hk→ := GRU(yk→-1,hk→-1),	(23)
where L k is a Cholesky factor and f is a multi-layer perceptron decoder.
8 Experiments
We perform three experiments, as motivated in section 1. Technical details on the setup of the ex-
periments can be found in the supplementary material (appendix F). We refer to the model detailed
in section 4 as the recursive filter, as it uses the Bayesian update recursion. For smoothing exper-
iments, we use recursive smoother. The model obtained by parameterizing p(xk | y<k) directly
(eq. (12)) is referred to as the recurrent filter or recurrent smoother, as it only employs recurrent
neural networks (and no Bayesian recursion) to estimate said density directly.
8.1	Linear Dynamics
In the linear Gaussian case, it is known that the Kalman filter will give the optimal solution. Thus,
we can get a lower bound on the test loss. In this toy experiment, we simulate particle tracking under
linear dynamics and noisy measurements of the location. We use Newtonian physics equations as
prior knowledge. We generate trajectories T = {x0:K, y0:K} with xk ∈ R6 and yk ∈ R2 according
to the differential equations:
0
x = Ax = 0
0
1
-c
-τc
0p
1v
0a
(24)
We obtain sparse, noisy measurements yk = Hxk + r with r 〜N(0, R). H is a selection matrix
that returns a two-dimensional position vector. We run this experiment in a filtering setting, i.e.,
7
Published as a conference paper at ICLR 2022
Figure 4: Considers the linear dynam-
ics experiment (section 8.1). The mean
squared error on the test set (lower is
better) as a function of the number of
examples.
Figure 5: Considers the Lorenz experiment (sec-
tion 8.2). The mean squared error on the test set (lower
is better) as a function of the number of examples used
for training.
we only use past observations. We compare against (1) the raw, noisy measurements which inher-
ently deviate from the clean measurements, (2) the Kalman filter solution where we optimized the
transition covariance matrix using clean data (hence supervised), (3) the optimal solution, which
is a Kalman filter with ground truth parameters performing exact inference. To estimate the tran-
sition maps for the Kalman filter, We use the standard Taylor series of eA(t UP to the first order.
Additionally, we use this expert knowledge as an inductive bias for the recursive filter’s transition
maps.
In fig. 4 We depict the test mean squared error (MSE, loWer is better) as a function of the number
of training samples. Given enough data, the self-supervised models approximate the optimal solu-
tion arbitrarily Well. Our recursive model significantly outperforms both the Kalman filter and the
inference model in the loW-data regime by using incorporated expert knoWledge. Additionally, We
report that the recursive model’s distance to the ground truth latent states is much closer to the opti-
mal solution than both the inference model and Kalman filter. Specifically, We report average mean
squared errors of 0.685 for the inference model, 0.241 for the Kalman filter, 0.161 for the recursive
model compared to 0.135 for the optimal Kalman filter. Finally, it is Worth noting that the recursive
model has much less variance as a function of its initialization.
8.2	Lorenz Equations
We simulate a Lorenz system according to
-σ
X = Ax = P — xι
x2
σ
—1
0
0
x1
x2
x3
(25)
We have H = I, x ∈ R3 and y ∈ R3 . The Lorenz equations model atmospheric convection and
form a classic example of chaos. Therefore, performing inference is much more complex than in
the linear case. This time, We perform smoothing (see appendix A) and compare against (1) the
raW measurements, (2) a supervised Extended Kalman smoother (Ljung, 1979), (3) the variational
inference approach of Krishnan et al. (2017), (4) the supervised recursive model of Satorras et al.
(2019). Our models include a recurrent smoother, a recursive smoother, and the recursive filter
With linearized smoothing (section 6). Transition maps for the Extended Kalman smoother and the
recursive models are obtained by taking a second-order Taylor series of eA(t. For the supervised
extended Kalman filter, We again optimize its covariance estimate using ground truth data.
In fig. 5 We plot the test mean squared error (MSE, loWer is better) as a function of the number of
examples available for training. It is clear that our methods approach the ground truth states With
8
Published as a conference paper at ICLR 2022
	Whitenoise	Doing the dishes	Dude miaowing	Exercise Bike	Pink noise	Running tap	Combined
Kalman Filter (Supervised)	0.225	0.230	0.232	0.237	0.235	0.230	0.227
Noise2Noise (Lehtinen et al., 2018)	0.327	0.399	0.448	0.430	0.440	0.383	0.526
SIN (Krishnan et al., 2017)	0.297	0.373	0.352	0.348	0.377	0.342	0.343
Recurrent Filter (Ours)	0.102	0.207	0.213	0.200	0.234	0.175	0.181
Recursive Filter (Ours)	0.107	0.206	0.213	0.198	0.232	0.166	0.175
Recursive Filter + RTS Smoother (Ours)	0.100	0.204	0.215	0.197	0.231	0.166	0.176
RKN (Becker et al., 2019, Supervised)	0.121	0.127	0.109	0.105	0.085	0.121	0.125
Table 2: Considers the audio denoising experiment (section 8.3). Test mean squared error (MSE,
lower is better) per model and noise subset. Blue numbers indicate second-best performing models.
more data. This is in contrast to the Extended Kalman smoother, which barely outperforms the noisy
measurements. We also see that the recursive models significantly outperform the recurrent model
in the low-data regime. The recursive filter with linearized smoothing performs comparably to the
other models and even better in low-data regimes. We hypothesize that this is because the required
assumption for the linearized smoother holds (section 6) and regularizes the model. The variational
method of Krishnan et al. (2017) performs poorly in low-data regimes. Most notably, the supervised
method of Satorras et al. (2019) outperforms our models only slightly.
8.3	Audio Denoising
Next, we test the model on non-fabricated data with less ideal noise characteristics. Specifically,
we use the SpeechCommands spoken audio dataset (Warden, 2018). Performing inference on
spoken audio is challenging, as it arguably requires understanding natural language. To this end,
recent progress on synthesizing raw audio has been made (Lakhotia et al., 2021). However, this
requires scaling to much larger and more sophisticated neural networks than presented here, which
we deem out the current work’s scope. Therefore, we take a subset of the entire dataset, using audio
from the classes “tree”, “six”, “eight”, “yes”, and “cat”. We overlay these clean audio sequences
{x(01:K) , . . . , x(0N:K) } with various noise classes that the dataset provides. That is, for every noise class
C we obtain a set of noisy sequences {y0(1:K) , . . . , y0(N:K)}C. We also consider a “combined” class in
which we sample from the union of the noise sets. The task is to denoise the audio without having
access to clean data. We evaluate the models on non-silent parts of the audio, as performance on
those sections is the most interesting. Notably, none of these noise classes is Gaussian distributed.
We show the mean squared error on the test set of all models per noise class in table 2. Our models
outperform the Kalman filter, Noise2Noise (Lehtinen et al., 2018), and SIN (Krishnan et al., 2017)
unsupervised baselines. We suspect that the relatively poor performance of SIN is due to its genera-
tive Markov assumption, regularizing the model too strongly. The poor performance of Noise2Noise
is due to the fact that it does not use the current measurement yk to infer xk . Like before, note that
the Kalman filter is “supervised” as we optimized its covariance matrix using clean data. The super-
vised RKN (Becker et al., 2019) outperforms our models on most noise classes, but notably not on
white noise. Most of these noise classes have temporal structure, making them predictable from past
data. This is confirmed by observing these mean squared error values over the course of training.
Initially, the values were better than reported in table 2, but the model increasingly fits the noise
over time. Thus, although two of the main assumptions about the model (independent Gaussian
noise) are violated, we still can denoise effectively. Since the RKN’s targets are denoised (hence
“supervised”), it does not have this problem. In practice, obtaining clean data can be challenging.
9	Conclusion
We presented an advantageous parameterization of an inference procedure for nonlinear state-space
models with potentially higher-order latent Markov chains. The inference distribution is split into
linear and nonlinear parts, allowing for a recursion akin to the Kalman filter and smoother algo-
rithms. Optimization is performed directly using a maximum-likelihood objective that backpropa-
gates through these recursions. Smoothing can be performed similarly, but we additionally proposed
linearized smoothing that can directly be applied to the filtering distributions. Our model is simple
and builds on established methods from signal processing. Despite this, results showed that it can
perform better or on par with fully supervised or variational inference methods.
9
Published as a conference paper at ICLR 2022
10	Ethics S tatement
The paper presents a simple method to perform inference using noisy sequential data. Applications
can be found throughout society, e.g., tracking particles, denoising images or audio, or estimating
system states. While many such examples are for good, there are applications with ethically debat-
able motivations. Among these could be tracking humans or denoising purposefully corrupted data
(e.g., to hide one’s identity).
11	Reproducibility S tatement
We are in the process of releasing code for the current work. For clarity and reproducibility, the
presented methods are available as algorithms in the supplementary material. Furthermore, we made
explicit wherever we needed to make an approximation or an assumption.
References
Evan Archer, Il Memming Park, Lars Buesing, John Cunningham, and Liam Paninski. Black box
variational inference for state space models. arXiv preprint arXiv:1511.07367, 2015.
Philipp Bader, Sergio Blanes, and Fernando Casas. Computing the matrix exponential with an
optimized taylor polynomial approximation. Mathematics, 7(12):1174, 2019.
Joshua Batson and Loic Royer. Noise2self: Blind denoising by self-supervision. In ICML, 2019.
Philipp Becker, Harit Pandya, Gregor H. W. Gebhardt, Cheng Zhao, C. James Taylor, and Gerhard
Neumann. Recurrent kalman networks: Factorized inference in high-dimensional deep feature
spaces. In ICML, 2019.
Christopher M Bishop. Pattern recognition. Machine learning, 128(9), 2006.
Kyunghyun Cho, Bart Van Merrieinboer, Caglar Gulcehre, Dzmitry Bahdanau, Fethi Bougares, Hol-
ger Schwenk, and Yoshua Bengio. Learning phrase representations using rnn encoder-decoder
for statistical machine translation. arXiv preprint arXiv:1406.1078, 2014.
Andreas Doerr, Christian Daniel, Martin Schiegg, Nguyen-Tuong Duy, Stefan Schaal, Marc Tous-
saint, and Trimpe Sebastian. Probabilistic recurrent state-space models. In International Confer-
ence on Machine Learning, pp. 1280-1289. PMLR, 2018.
Marco Fraccaro, Simon Kamronn, Ulrich Paquet, and Ole Winther. A disentangled recognition and
nonlinear dynamics model for unsupervised learning. arXiv preprint arXiv:1710.05741, 2017.
KUzman Ganchev, Joao Graca, Jennifer Gillenwater, and Ben Taskar. Posterior regularization for
structured latent variable models. The Journal of Machine Learning Research, 11:2001-2049,
2010.
Christian Gourieroux, Alain Monfort, and Alain Trognon. Pseudo maximum likelihood methods:
Theory. Econometrica: journal of the Econometric Society, pp. 681-700, 1984.
Alex Graves, Abdel-rahman Mohamed, and Geoffrey Hinton. Speech recognition with deep recur-
rent neural networks. In 2013 IEEE international conference on acoustics, speech and signal
processing, pp. 6645-6649. Ieee, 2013.
Tuomas Haarnoja, Anurag Ajay, Sergey Levine, and Pieter Abbeel. Backprop KF: learning discrim-
inative deterministic state estimators. In NeurIPS, 2016.
Matthew J. Johnson, David Duvenaud, Alexander B. Wiltschko, Ryan P. Adams, and Sandeep R.
Datta. Composing graphical models with neural networks for structured representations and fast
inference. In NeurIPS, 2016.
Nal Kalchbrenner, Edward Grefenstette, and Phil Blunsom. A convolutional neural network for
modelling sentences. arXiv preprint arXiv:1404.2188, 2014.
10
Published as a conference paper at ICLR 2022
Rudolph Emil Kalman. A new approach to linear filtering and prediction problems. 1960.
Maximilian Karl, Maximilian Soelch, Justin Bayer, and Patrick van der Smagt. Deep variational
bayes filters: Unsupervised learning of state space models from raw data. In ICLR, 2017.
Diederik P Kingma and Max Welling. Auto-encoding variational bayes. arXiv preprint
arXiv:1312.6114, 2013.
Genshiro Kitagawa. The two-filter formula for smoothing and an implementation of the gaussian-
sum smoother. Annals ofthe Institute OfStatistical Mathematics, 46(4):605-623,1994.
Daphne Koller and Nir Friedman. Probabilistic graphical models: principles and techniques. MIT
press, 2009.
Rahul G Krishnan, Uri Shalit, and David Sontag. Deep kalman filters. arXiv preprint
arXiv:1511.05121, 2015.
Rahul G. Krishnan, Uri Shalit, and David A. Sontag. Structured inference networks for nonlinear
state space models. In AAAI, pp. 2101-2109. AAAI Press, 2017.
Alexander Krull, Tim-Oliver Buchholz, and Florian Jug. Noise2void - learning denoising from
single noisy images. In CVPR, 2019.
Samuli Laine, Tero Karras, Jaakko Lehtinen, and Timo Aila. High-quality self-supervised deep
image denoising. In NeurIPS, 2019.
Kushal Lakhotia, Evgeny Kharitonov, Wei-Ning Hsu, Yossi Adi, Adam Polyak, Benjamin Bolte,
Tu-Anh Nguyen, Jade Copet, Alexei Baevski, Adelrahman Mohamed, et al. Generative spoken
language modeling from raw audio. arXiv preprint arXiv:2102.01192, 2021.
Jaakko Lehtinen, Jacob Munkberg, Jon Hasselgren, Samuli Laine, Tero Karras, Miika Aittala, and
Timo Aila. Noise2noise: Learning image restoration without clean data. In ICML, 2018.
Lennart Ljung. Asymptotic behavior of the extended kalman filter as a parameter estimator for linear
systems. IEEE Transactions on Automatic Control, 24(1):36-50, 1979.
Michael Lustig, David Donoho, and John M Pauly. Sparse mri: The application of compressed
sensing for rapid mr imaging. Magnetic Resonance in Medicine: An Official Journal of the
International Society for Magnetic Resonance in Medicine, 58(6):1182-1195, 2007.
Todd K Moon. The expectation-maximization algorithm. IEEE Signal processing magazine, 13(6):
47-60, 1996.
Christian Naesseth, Scott Linderman, Rajesh Ranganath, and David Blei. Variational sequential
monte carlo. In International conference on artificial intelligence and statistics, pp. 968-977.
PMLR, 2018.
Radford M Neal et al. Mcmc using hamiltonian dynamics. Handbook of markov chain monte carlo,
2(11):2, 2011.
Syama Sundar Rangapuram, Matthias W Seeger, Jan Gasthaus, Lorenzo Stella, Yuyang Wang, and
Tim Januschowski. Deep state space models for time series forecasting. Advances in neural
information processing systems, 31:7785-7794, 2018.
Herbert E Rauch, F Tung, and Charlotte T Striebel. Maximum likelihood estimates of linear dynamic
systems. AIAA journal, 3(8):1445-1450, 1965.
Guy Revach, Nir Shlezinger, Xiaoyong Ni, Adria Lopez Escoriza, Ruud JG van Sloun, and Yonina C
Eldar. Kalmannet: Neural network aided kalman filtering for partially known dynamics. arXiv
preprint arXiv:2107.10043, 2021.
Victor Garcia Satorras, Max Welling, and Zeynep Akata. Combining generative and discriminative
models for hybrid inference. In NeurIPS, 2019.
11
Published as a conference paper at ICLR 2022
Bemhard Scholkopf, David W Hogg, DUn Wang, Daniel Foreman-Mackey, Dominik Janzing, Carl-
Johann Simon-Gabriel, and Jonas Peters. Modeling confounding by half-sibling regression. Pro-
Ceedings of the National Academy of Sciences ,113(27):7391-7398, 2016.
Richard A Thompson, James M Moran, and George W Swenson Jr. Interferometry and synthesis in
radio astronomy. Springer NatUre, 2017.
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez,
Eukasz Kaiser, and Illia Polosukhin. Attention is all you need. In Advances in neural information
processing systems, pp. 5998-6008, 2017.
Niklas Wahlstrom, Thomas B Schon, and Marc Peter Deisenroth. From pixels to torques: Policy
learning with deep dynamical models. arXiv preprint arXiv:1502.02251, 2015.
Pete Warden. Speech commands: A dataset for limited-vocabulary speech recognition. arXiv
preprint arXiv:1804.03209, 2018.
Manuel Watter, Jost Tobias Springenberg, Joschka Boedecker, and Martin Riedmiller. Embed to
control: A locally linear latent dynamics model for control from raw images. arXiv preprint
arXiv:1506.07365, 2015.
Li Yingzhen and Stephan Mandt. Disentangled sequential autoencoder. In International Conference
on Machine Learning, pp. 5670-5679. PMLR, 2018.
A Parameterized Smoothing
In the main body of the paper, we showed how to parameterize the model for recursive estimation of
p(xk | y≤k), k = 0, . . . , K. Additionally, we provided a linearized smoothing procedure that yields
p(xk | y1:K). The disadvantage clearly is the linearization. Here, we show how we can recursively
estimate p(xk | y1:K) in a similar sense to the filtering setting.
First, we put
P(Xk | xk-1, y-k ) = N (Xk | Fk|—k xk-1 + ek|—k, Qk|—k) ,	(26)
1	*	/	∖	1 ʌ	/	∖	1	X~∖	/	∖	.	∙ 1	1	.	1.1.
where Fk∣-k(y-k) and ek — (y-k) and Qk∣-k(y-k) are two-sided recurrent neural network out-
puts similar to section 7. We compute the distribution of interest as follows:
p(	I	„	、	p(yk	|	Xk)P(Xk | y—k)	sr`
P(Xk	|	y0K)=	P(yk | y-k)—	(27)
X	Plyk	|	Xk) /P(Xk, Xk-1	|	y-k)dXk-1	(28)
=	P(yk	|	Xk) P(Xk | Xk—1,	y—k)P(Xk—1 | y—k)dXk—1	(29)
xk-1⊥⊥yk |y-k
P(yk | Xk)
P(Xk | Xk—1, y—k)P(Xk—1
| y0:K)dXk—1
(30)
where we make the approximation to compute eq. (27) efficiently and recursively. It is justified if
I(Xk—1; yk | y—k) < for small . That is, the additional information that yk conveys about Xk—1
is marginal if we have all other data. Let
P(Xk-I | y0:K ) := N (Xk-1 | Xk -1|0:K, Pk-1|0:K)	(31)
be previous time-step’s posterior. Then put
/ I	∖ a r/ I τ^π	. ʌ	人 ∖	∕cc∖
P(Xk | Xk-1, y-k ) := N (X | Fk | -k Xk-1 +ek∣-k, Qk|-k ).	(32)
where we left out the arguments for the following quantities estimated by an RNN.
Fk|-k(y-k)	→ GRU(h→	)
ek∣-k(y-k)	:= f(h→, h")	h^ := GRU(h-, yk-1)	(33)
[Qk∣-k (y-k )J	LM	LGRU(hk+1, yk+1)j
12
Published as a conference paper at ICLR 2022
Applying the integral in eq. (30) We get
/P(Xk | xk-i, y-k)p(χk-ι | yo：K)dχk-ι = N (Xk | x^k∖-k, Pk∣-,	(34)
Where We put
q. .一 ^, q	I ,⅞ ,	^	.一 ^ ,	^	^ T I A .
xk∖-k ∙ = Fk∖-kxk-1|0:K + ek∖-k	Pk∖-k ∙ = Fk∖-kPk-1 ∖0:KFk∖-k + Qk∖-k	(35)
A data likelihood can be computed as folloWs
p(yk | y-k)
/p(yk | χk)p(χk | y-k)dχk
/Pi)/
p(χk-ι, Xk | y-k)dχkXk-i
/i)/
p(Xk | Xk-i, y-k)p(Xk-i
| y-k)dχkXk-ι
χk-ι⊥⊥yk ∖y-k
]p(yk∖χk)/
p(Xk | Xk-i, y-k)p(Xk-i
| yo：K)dxkXk-1
Where We made the same approximation eq. (30) as before. It evaluates to
/p(yk | Xk)p(χk | y-k)dχk = N (yk | yk∖-k, Mk∖-k
With
yk∖-k ∙= HX^k|-k
Afk∖-k := H]^k∣-kHτ + R
(36)
(37)
(38)
(39)
(40)
(41)
For fitting to the data we now would use a maximum-pseudo-likelihood (Gourieroux et al., 1984)
approach by maximizing:
KK
X log p(yk | y-k) = X log N (yk | HXk∖-k (y-k), HPk∖-k (y-k) HT + R) ,	(42)
k=0	k=0
leading to minimizing the following self-supervised loss function:
K
L := X [(yk∖-k - yk)t 曲--k (yk∖-k - y) +log det 曲图一],	(43)
k=0
1	ʌ	τ τ ʌ	/	∖ ι τt ʌɪ	τ τ -r∖	/	∖ ττ^Γ
where yk∖-k ：= HXk∖-k(y-k) and Mk∖-k ：= HPk∖-k(y-k) H 1 + R.
B	Gaussian Conditioning Formulas
Since many of the calculations used in this work are based on the Gaussian conditioning formulas,
we provide them here. if
p(x) = N(x | μ, P),	(44)
p(y | X) = N(y | HX + b, R),	(45)
then
p(y) = N(y | Hμ + b, R + HPHt),	(46)
p(X | y)= N (X | Σ [H tR-1 (y - b) + P-1μ] , ∑),	(47)
with
Σ = (P-1 + H tR-1H )-1.	(48)
13
Published as a conference paper at ICLR 2022
C DIRECT PARAMETERIZATION OF p(x | y<k)
We show here how to directly parameterize p(x | y<k) and p(x | y-k). This parameterization is
referred to as the recurrent model in our experiments. The procedure is rather straightforward. For
filtering, we putp(xk | y<k)= N (Xk | Xk∣-k(y<k), P5k∣<k(y<k)). We model:
xk∣<k := ek ,	Pk∣<k := LkLk ,	Lek := f(hk→),	(49)
where Lk is a cholesky factor and f is a multi-layer perceptron. The argument hk→ is recursively
given by
hk→ := GRU(yk-1,hk→-1),	(50)
where we employ a Gated Recurrent Unit (GRU) network (Cho et al., 2014). Note that this param-
eterization is equivalent to the model described in the main paper with Fk := 0.
For smoothing,P(Xk | y-k) = N (Xk | Xk∣-k(y-k),Pk|-k(y-k))∙
Xk∣-k := ek,	Pk∣-k := LkL>,	Lk := f(h→, hD,	(51)
where Lk is a cholesky factor and f is a multi-layer perceptron.
h→ := GRU(yk-ι, h→-ι),	h" :=GRU(yk+i, ht+ι).	(52)
Once P(X | y<k) (filtering) or P(X | y-k) (smoothing) is obtained, all the procedures for inference
and optimization described in the main paper and appendix A remain the same.
D Bias-Variance-Noise Decomposition of the Self-Supervised
Generalization Error
Any estimate Xk = Xk (y-k) for Xk that is not dependent on yk Will give Us a bias-variance-
noise decomposition of the generalization error. Note that this setting covers both the filtering and
smoothing case. Define “optimal model" y1 := E [yk | y-k], then under the specified generative
model (section 3) we have
E [l∣yk - ykk2 | y-ki = E [∣∣yk -讥 + y - ykk2 | y-ki	(53)
=E hkyk - ykk2 I y-k] + Var [yk | y-k] + 2E [颔-y∕⅛)> (yk - yk | y-ki (54)
=kyk - yk∣∣2 + Var [yk I y-k] + 2(yk - yk)> E[(yk - y) I y-k]	(55)
X--------{z------}
0
Var [yk I y-k] = E [∣∣yk - HXk - nk∣∣2 I y-k]	(56)
=E h∣yk - HXkI∣2 I y-ki + E [l∣nkI∣2 I y-k] +2Eh(HXk- yk)> n I y-ki	(57)
'-----------V------------}
0
Xk,y=⊥⊥nk E h∣yk - HXk∣2 I y-ki + tr(R)	(58)
Thus,
E h∣yk - ykI∣21 y-k] = kyk - yk∣2 + E h∣yk - HXk 1121 y-k] +tr(R)	(59)
Note that yk = E [HXk I y-k] = HE [Xk I y-k]. Then, define our model ryk := HXk. The
reducible part of the error becomes
kyk - yk∣2 = ∣H(E[Xk I y-k] - Xk)k2	(60)
14
Published as a conference paper at ICLR 2022
For this reason, the model output Xk approaches the optimal model under minimization of the Self-
supervised error (perturbed by H).
Additionally, the model τ^k approaches HXk (the uncorrupted measurement) under this criterion.
E [kyk - yk∣∣2] = E [kyk - HXk + HXk - y ∣∣2]
(61)
E [∣yk - HXkk2] + E [k
E [∣y⅛- HXkk2i + E h∣
HXk -
HXk
yk∣∣2] + 2E [(j^k — HXk)> (HXk — yk)]
yk k2i+2 EKyk-HXk )]> ElHx上
(62)
(63)
z
0
E Uyk - HXkk2] +tr(R) + EUIHx：.- ykk]2,
(64)
z
0
If We then take τ^k := HXk then the reducible part of the error approximates the true Xk (perturbed
byH).
E [kyk - HXkk2] = E [kH (Xk - Xk)k2]
(65)
15
Published as a conference paper at ICLR 2022
E Algorithms
Algorithm 1: Recursive Filter (Inference)
input : Data (time-series) y0：K = (y。，...，yκ), emission matrices H and R, parameters φ.
output:
1.
2.
3.
4.
For training: Loss value LK and its gradient VψLκ.
For inference: xk∣≤k and Pk∣ ≤k for k in 0,..., K. Inference is done via:
p(xk I y≤k) = N (xk I xk∣ ≤k, Pk∣≤k)∙
i - -t ∙	∙	1	.ι ∙	/	τ-↑	-r∖	ʌ	ι -r∖	i` 7 ∙ r∖	T7
For linearized smoothing (section 6): Fk∣<k, Pk∣ <k, xk ∣ ≤k and Pk∣≤k, for k in 0,..., K.
For forecasting: xκ+ι ∣ <(k+i) and Pκ+ι ∣<(k+i). Forecasting is done via:
p(xκ+1 * 1 y0:K) = N (xκ+1 1 xK+1 ∣<(K+1), PK+1 ∣<(K+1)).
ho ：= 0
L-1 := 0
ŋ .一 /S_
P0∣<0 ：= Q0
X0∣<0 ：= e0
for k in 0,...,K do
Bk∣<k ：= (HPk∣<k HT + R)T
yk∣<k ：= Hxk∣<k
T
Lk ：= Lk-I + (yk — yk∣<k) Bk∣<k (yk — yk∣<k) - IOgdet 8k∣<k
Tr. .一 ^	IJT ^
Kk ： = Pk∣<k H Bk∣<k
ŋ .一 ŋ	τr. τj ŋ
Pk ∣ ≤k ： = Pk∣ <k	Kk H Pk∣ <k
xk∣ ≤k ：= xk ∣ <k + Kk (yk - yk ∣ <k)
hk+ι ：= GRUφ(hk, yk)
ek+1∣<(k+1)
Fk + 1∣<(k + 1)
Lk+1∣<(k+1)J
:=fφ(hk+ι)
>	>	τ>
Qk + 1∣<(k+1)	：=	Lk + 1∣<(k + 1)	Lk+1∣<(k + 1)
^	^	^	^ T	∕^
Pk + 1∣<(k+1)	：=	Fk + 1∣<(k+1)	Pk∣≤k Fk+1∣<(k + 1)	+	Qk + 1∣<(k+1)
q	.	♦一	r . .	.	q . . I q
xk + 1∣<(k+1)	：=	Fk + 1∣<(k+1)	xk∣≤k + ek+1∣<(k+1)
end
For the training case We use backpropagation through the above loop to compute VφLχ.
Algorithm 2: Recursive Filter (Training)
input : Data (time-series) y0：K = (y0,..., yκ),, emission matrices H and R, initialized
parameters φ0, number of training rounds I.
output: Model parameters φ* for inference at test-time.
for i in 0,...,I do
Obtain LK) and VφLK) from algorithm 1.
Run preferred optimizer step to update parameters φ with VφLKK (and LKK).
end
16
Published as a conference paper at ICLR 2022
Algorithm 3: Parameterized Recursive Smoother (Inference)
input : Data (time-series) y0：K = (y0,..., yκ), emission matrices H and R, initialized
parameters φ0
output:
1.	Loss value LK and its gradient w.r.t. all model parameters Vφ(Lk) for training.
2.	For all k in 0,...,K: Xk∣0:K, Pk∣0:K. These can be used for inference through
P(Xk | y0:K) = N (Xk∣0:K, Pk10:K).
h→ := 0
hκ+ι := 0
L-I := 0
A	A
P0∣-0 ：= Q0
X0∣-0 ：= <≡0
for k in 0,...,K do
Bk∣-k ：= (HPk∣-k HT + R)T
ryk∣-k ：= HXk∣-k
-1 + (yk - yk∣-k)T Bk∣-k (yk - yk∣-k) - IOgdet Bk∣-k
(k k k
：= ：= ：= ：=
∣-k HTBk∣-k
介 rʃ ŋ
∣-k - Kk H Pk∣-k
+ Kk (yk - yk∣-k)
h→+1 ：= GRUφ(h→, yk
h屋ι ：= GRUφ(h葭,yk+ι
ek+1∣-(k+1)
Fk + 1∣-(k + 1)
LLk+1∣-(k+1)J
fφ(h→+1, ht⅛1)
+ 1∣-(k+1) ：= Lk + 1∣-(k + 1)
LT 「、
Lk+1∣-(k + 1)
^	.	.一	^	^	^ T	I	∕^
pk + 1∣-(k+1) ：=	Fk + 1∣-(k+1)	pk∣0:K	Fk+1∣-(k+1) +	Qk+1∣-(k + 1)
q	.	♦一	r	. .	.	q . I <
xk + 1∣-(k+1) ：=	Fk + 1∣-(k+1)	xk∣0:K	+ ek⅛1∣-(k⅛1)
end
For training case We also use backpropagation through the above loop to compute V⅛Lχ
Algorithm 4: Parameterized Recursive Smoother (Training)
input : Data (time-series) y0：K = (y。，...，yκ), emission matrices H and R, initialized
parameters φ0, number of training rounds I
output: Model parameters φ* for inference at test-time.
for i in 1,...,I do
Obtain VφLK) from algorithm 3.
Run preferred optimizer step.
end
17
Published as a conference paper at ICLR 2022
Algorithm 5: Linearized Smoother
♦	，	X T 1	Γ∙ *	ŋ	-r∖	ʌ	Γ∙	117	Γ∖	T7 1 .	1 Γ∙	.1
input : Values of: Fk∖<k, Pk∖<k, Pk∖<k, Xk∖≤k for all k = 0,...,K, obtained from the
recursive filter algorithm.
output: Linearly smoothed distributions P(Xk | yo：K) = N (Xk | Zk, Gk) for all
k = 0,..., K.
ZK := xk∖<k
Zv____7⅛
GK := pk∖<k
for k = K,..., 1 do
>	.D -	rτ	6-1
Jk-1∖k := pk-1∖<k-1 Fk∖<k Pk\<k
τ
Gk-1 := pk-1∖<k-1 + Jk-1∖k ( Pk∖<k - Pk∖<k ) Jk-1∖k
Zk-1 := xk-1∖<k-1 + Jk-1∖k (Zk - xk∖<k)
end
Algorithm 6： Recurrent Smoother (Training)
input : Training data (time-series) y0：K = (yo,..., yκ), emission function N(HXk, R),
initialized parameters φ0, number of training iterations n.
output: Optimized parameters φ*
for iin1ton do
ho := 0
hK+1 := 0
L(i):= 0
for kin0to K do
h→ := GRUφ(h→1, yk-1)
h := GRUφ(h-1, yk+1)
[Lk'-k卜=∕φ(hΓ, hr)
[Lk∖-k
τ
pk∖-k := Lk∖-kLk∖-k
yk∖-k := HX^k\-k
Bk∖-k := (HPk∖-kHT + R)T
Lki := Lki-I + (yk - yk∖-Qτ Bk∖-k (yk - yk∖-k ) - IOgdet B k∖-k
end
Compute %LK) and apply SGD step with respect to all model parameters, which amounts
to backpropagation through the above calculations.
end
For the filter variant, the steps that involve the backward direction (—) are left out.
18
Published as a conference paper at ICLR 2022
Algorithm 7: Recurrent Smoother (Inference)
input : Test data y0：K = (yo,∙∙∙, yκ), trained parameters φ*, emission function N(Hx, R).
output: Inferred posteriors P(Xk | yo：K) = N(Xk | Xk®K, A|o：K) for all k
ho := 0
hK+1 := 0
for kin0to K do
h→ =GRUφ(h→-ι, yk-ι)
ht =GRUφ(ht-ι, yk+ι)
[Lk1-k 卜=∕φ(hΓ, hr)
|_Lk|-k
D_	^	^ T
Pk∣-k := Lk∣-kLk∣-k
Kk := Pk∣-kHT (HPk∣-kHT + R)T
Xk∣0:K := Xk∣-k + Kk(yk - HXk∣-k)
^	^	^r.	^
Pk10:K . = Pk∣-k	KkHPk∣-k
end
For the filter variant, the steps that involve the backward direction (—) are left out.
19
Published as a conference paper at ICLR 2022
F Experiments: Details
F.1 Linear Dynamics
As specified in the main paper, the dynamics are according to
0
X = Ax = 0
0
1
-c
-τc
0p
1v
0a
(66)
Since these are linear transitions, we can calculate any transition directly using x(t + ∆t)
eA∆t x(t).
F:
eA	0
0 eA
Q:
(67)
■一
Q
0
0
Q
We used c = 0.06, τ = 0.17, ∆t := 1 and covariance
Q = 0.12 ∙
■
003
010
1-30 O
(68)
The matrix exponential is computed using Bader et al. (2019). The parameters for the emission
distribution:
H:
100000
000100
R :=0.52 ∙
10
01
(69)
We simulate a K := 131, 072 trajectory for training, K := 16, 384 trajectory for validation and
K := 32, 768 for testing. The F that is used in the (non-optimal) Kalman filter and recursive model
is computed as follows:
1
eAAt ≈ F = X(∆tAn)∕n!
(70)
F.2 Lorenz Equations
We simulate a Lorenz system according to
-σ
X = Ax = P — xι
x2
σ
—1
0
x1
x2
x3
(71)
We integrate the system using dt = 0.00001 and sample it uniformly at ∆t = 0.05. We use ρ = 28,
σ = 10, β = 8∕3. The transition in ∆t arbitrary time-steps is linearly approximated by a Taylor
expansion and used in the Kalman smoother and recursive models.
2
eA|x"t ≈ Fk := X(∆tA∣χk)n/n!	(72)
n=0
We simulate K := 131, 072 steps for training, K := 32, 768 for testing and K := 16, 384 for
validation. We have H := I and thus X ∈ R3 and y ∈ R3. We use R := 0.52I.
G Parameterized Smoothing: Alternative Posterior Evaluation
We would like to point out that the distribution p(Xk | y0:K) can be obtained without making
assumption eq. (30), which we stretch out here. Initial experiments showed that using these calcu-
lations the model did not converge as smoothly as when using the ones stated before. However, it
could be of interest to further investigate. Returning to the posterior of interest
p(Xk | y0:K)
p(Xk | Xk-1, y0:K) p(Xk-1
| y0:K) dXk-1
Z p®p(" Xk) Q P(Xk 1 xk-1, y-k)p(xk-1
p(yk | Xk-1 , y-k )
| y0:K) dXk-1.
(73)
(74)
20
Published as a conference paper at ICLR 2022
We have
p(xk-ι | yo:K) = N (Xk-I | Xk-1∣0:K(yo:K), F,k-ι∖o:κ(y0:K))	(75)
as the previous time-step,s posterior.
P (Xk 1 xk-1, y-k ) = N (Xk 1 Fk∖-k xk-1 + ek∣-k, Qk∣-k)	(76)
where Fk∖-k(y-k), ek∖-k(y-k) and Qk∖-k(y-k) are estimated by a neural network. Combining
this with noise model eq. (3) we get:
p(χk | Xk-ι, yo：K)
xk 1 Fk∖-k xk-1 + ek∖-k + Kk (yk - H (Fk∖-k xk-1 + ek∖-k)), Qk∖-k - Kk H Q k ∖-k
(77)
=N (Xk | (I - Kn H) (Fk∖-k Xk-1 + ^k∖-k) + Kk yk,(I - Kn H) Qk∖-k) ,	(78)
where we directly applied the Woodbury matrix identity to obtain Kalman gain matrix
Kk ：= Qk∖ -k HT (HQk∖ -k HT + R)T	(79)
Then, applying the integral we get:
p (Xk | yo：K) = N (Xk | Xk ∖ o：K, Pk∖ 0：K) ,	(80)
with:
Pk ∖ 0:K =	(I -	Kn H)	Fk ∖ -k Pk-I ∖ 0:K F>-k	(I -	Kn	H )T	+(I -	Kn	H) Q k ∖ -k,	(81)
and
Xk ∖ 0:K = Fk∖ -kXk-I ∖ 0:K + ek∖ -k + Kk (yk - H (Fk∖-kXk-1 ∖ 0:K + ek∖-k))	(82)
=(I - Kn H) (Fk ∖ -k Xk-1 ∖ 0:K + 6k ∖ -k) + Kk yk .	(83)
21