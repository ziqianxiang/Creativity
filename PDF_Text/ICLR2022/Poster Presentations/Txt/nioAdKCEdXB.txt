Published as a conference paper at ICLR 2022
Likelihood Training of Schrodinger Bridge
using Forward-Backward SDEs Theory
Tianrong Chen*, Guan-Horng Liu*, Evangelos A. Theodorou
Georgia institute of Technology, USA
{tianrong.chen, ghliu, evangelos.theodorou}@gatech.edu
Ab stract
Schrodinger Bridge (SB) is an entropy-regularized optimal transport problem that
has received increasing attention in deep generative modeling for its mathematical
flexibility compared to the Scored-based Generative Model (SGM). However, it
remains unclear whether the optimization principle of SB relates to the modern
training of deep generative models, which often rely on constructing log-likelihood
objectives.This raises questions on the suitability of SB models as a principled alter-
native for generative applications. in this work, we present a novel computational
framework for likelihood training of SB models grounded on Forward-Backward
Stochastic Differential Equations Theory - a mathematical methodology appeared
in stochastic optimal control that transforms the optimality condition of SB into
a set of SDEs. Crucially, these SDEs can be used to construct the likelihood
objectives for SB that, surprisingly, generalizes the ones for SGM as special cases.
This leads to a new optimization principle that inherits the same SB optimality
yet without losing applications of modern generative training techniques, and we
show that the resulting training algorithm achieves comparable results on generat-
ing realistic images on MNiST, CelebA, and CiFAR10. our code is available at
https://github.com/ghliu/SB-FBSDE.
1 Introduction
Score-based Generative Model (SGM; Song et al. (2020)) is an emerg-
ing generative model class that has achieved remarkable results in
synthesizing high-fidelity data (Song & Ermon, 2020; Kong et al.,
2020a;b). Like many deep generative models, SGM seeks to find
nonlinear functions that transform simple distributions (typically Gaus-
sian) into complex, often intractable, data distributions. In SGM, this
is done by first diffusing data to noise through a stochastic differential
equation (SDE); then learning to reverse this diffusion process by
regressing a network to the score function (i.e. the gradient of the
log probability density) at each time step (Hyvarinen & Dayan, 2005).
This reversed process thereby defines the generation (see Fig. 1).
Despite its empirical successes, SGM admits few limitations. First, the
diffusion process has to obey a simple form (e.g. linear or degenerate
drift) in order to compute the analytic score function for the regression
purpose. Secondly, the diffusion process needs to run to sufficiently
large time steps so that the end distribution is approximate Gaussian
(Kong & Ping, 2021). For these reasons, SGM often takes a notoriously
Data-to-noise (diffusion) SDE
NoiSe-to-data (generation) SDE
SGM	SB
Given	Learned
Learned	Learned
Figure 1: Both Score-based
Generative Model (SGM)
and Schrodinger Bridge
(SB) transform between two
distributions. While SGM
requires pre-specifying the
data-to-noise diffusion, SB
instead learns the process.
long time in generating data (Jolicoeur-Martineau et al., 2021), thereby limiting their practical usages
compared to e.g. GANs or flow-based models (Ping et al., 2020; Karras et al., 2020b).
in the attempt to lift these restrictions, a line of recent works inspired by Schrodinger Bridge (SB;
Schrodinger (1932)) has been proposed (De Bortoli et al., 2021; Wang et al., 2021; Vargas et al., 2021).
SB - as an entropy-regularized optimal transport problem - seeks two optimal policies that transform
back-and-forth between two arbitrary distributions in a finite horizon. The similarity between the
* Equal contribution. Order determined by coin flip. See Author Contributions section.
1
Published as a conference paper at ICLR 2022
two problems (i.e. both involve transforming distributions) is evident, and the additional flexibility
from SB is also attractive. To enable SB-inspired generative training, however, previous works
require either ad-hoc multi-stage optimization or retreat to traditional SB algorithms, e.g. Iterative
Proportional Fitting (IPF; Kullback (1968)). The underlying relation between the optimization
principle of SB and modern generative training, in particular SGM, remains relatively unexplored,
despite their intimately related problem formulations. More importantly, with the recent connection
between SGM and log-likelihood computation (Song et al., 2021), it is crucial to explore whether
there exists an alternative way of training SB that better respects, or perhaps generalizes, modern
training of SGM, so as to solidify the suitability of SB as a principled generative model.
In this work, we present a fundamental connection between solving SB and training SGM. The
difficulty arises immediately as one notices that the optimality condition of SB and the likelihood
objective of SGM are represented by merely two distinct mathematical objects. While the former
is characterized by two coupled partial differential equations (PDEs) (Leonard, 2013), the latter
integrates over a notably complex SDE that resembles neither its diffusion nor reversed process (Song
et al., 2021). Nevertheless, inspired by the recent advance on understanding deep learning through the
optimal control perspective (Li & Hao, 2018; Liu et al., 2021a;b), we show that Forward-Backward
SDEs - a mathematical methodology appearing in stochastic optimal control for solving nonlinear
PDEs (Han et al., 2018) - paves an elegant way to connect the two objectives. The implication of our
findings is nontrivial: It yields an exact log-likelihood expression of SB that precisely generalizes
the one of SGM (Song et al., 2021) to fully nonlinear diffusion, thereby providing novel theoretical
connections between the two model classes. Algorithmically, our framework suggests rich training
procedures that resemble the joint optimization for diffusion flow-based models (Zhang & Chen,
2021) or more traditional IPF approaches (Kullback, 1968; De Bortoli et al., 2021). This allows one
to marry the best of both worlds by improving the SB training with e.g. a SGM-inspired Langevin
corrector (Song & Ermon, 2019). The resulting method, SB-FBSDE, generates encouraging images
on MNIST, CelebA, and CIFAR10 and outperforms prior optimal transport models by a large margin.
Our method differs from the concurrent SB methods (De Bortoli et al., 2021; Vargas et al., 2021) in
various aspects. First, while both prior methods rely on solving SB with mean-matching regression,
our SB-FBSDE instead utilizes a divergence-based objectives (see §3.2). Secondly, neither of the
prior methods focuses on log-likelihood training, which is the key finding in SB-FBSDE to bridge
connections to SGM and adopt modern training improvements. Indeed, due to the difference in the
underlying SDE classes,1 their connections to SGM can only be made after time discretization by
carefully choosing each step size (De Bortoli et al., 2021). In contrast, our theoretical connection is
derived readily in continuous-time; hence unaffected by the choice of numerical discretization.
In summary, we present the following contributions.
•	We present a novel computational framework, grounded on Forward-Backward SDEs theory,
for computing the log-likelihood objectives of Schrodinger Bridge (SB) and solidifying their
theoretical connections to Score-based Generative Model (SGM).
•	Our framework suggests a new training principle that retains the mathematical flexibility from SB
while enjoying advanced techniques from the modern generative training of SGM.
•	We show that the resulting method - named SB-FBSDE - outperforms previous optimal transport-
inspired baselines on synthesizing high-fidelity images and is comparable to other existing models.
Notation. We denote ptSDE (Xt) as the marginal density driven by some SDE process X(t) ≡ Xt
until the time step t ∈ [0, T]. The time direction is aligned throughout this article such that p0 and pT
respectively correspond to the data and prior distributions. The gradient, divergence, and Hessian of
a function f(x), where X ∈ Rn, will be denoted as Vχf ∈ Rn, Rx ∙ f ∈ R, and VXf ∈ Rn×n.
2 Preliminaries
2.1	Score-based Generative Model (SGM)
Given a data point X0 ∈ Rn sampled from an unknown data distribution pdata, SGM first progressively
diffuses the data towards random noise with the following forward SDE:
dXt = f (t, Xt)dt + g(t)dWt, Xo 〜Pdata,	(1)
1 We adopt the recent advance in SB theory (Caluya & Halder, 2021) that extends classical SB models (used
in prior works) to the exact SDE class appearing in SGM. See Appendices A and C for more details.
2
Published as a conference paper at ICLR 2022
where f (∙,t) : Rn → Rn, g(t) ∈ R, and Wt ∈ Rn are the drift, diffusion, and standard Wiener
process. Typically, g(∙) is some monotonically increasing function such that for sufficiently large
time steps, we have p(T1) ≈ pprior resemble some prior distribution (e.g. Gaussian) at the terminal
horizon T. Reversing (1) yields another SDE2 that traverses backward in time (Anderson, 1982):
dXt = [f - g2 Vx logpt1)(Xt)]dt + g dWt, XT 〜pT),	(2)
where PtI) corresponds to the marginal density of SDE (1) at time t, and Vx logPtI) is known as
the score function. These two stochastic processes are equivalent in the sense that their marginal
densities are equal to each other throughout t ∈ [0, T]; in other words, P(t1) ≡ P(t2).
When the drift f is of simple structure, for instance linear (Ho et al., 2020) or simply degenerate (Song
& Ermon, 2019), the conditional score function Vx logP(t1)(Xt|X0 = x0) ≡ Vx log Pt|x0 admits an
analytic solution at any time t. Hence, SGM proposes to train a parameterized score network s(t, x; θ)
by regressing its outputs to the ground-truth values, i.e. E[λ(t)ks(t, Xt; θ) - Vx log Pt|x0 k2], where
the expectation is taken over the SDE (1). In practice, λ(t) is some hand-designed weighting function
that largely affects the performance. Recent works (Song et al., 2021; Huang et al., 2021) have shown
that the log-likelihood of SGM, despite being complex, can be lower-bounded as follows:
2g2kstk2 + Vx ∙ (g2st- f) dt, (3)
k2 - 2kgVxlogPt∣x0 k2-Vx ∙ f dt,
where st ≡ s(t, x; θ) and the expectation is taken over the SDE (1) given a data point X0 = x0. This
objective (3) suggests a principled choice of λ(t) := g(t)2. After training, SGM simply substitutes
the score function with the learned score network s(t, x; θ) to generate data fromPprior,
dXt = [f - g2 s(t, Xt; θ)]dt + g dWt,	XT 〜Pprior.	(4)
It is important to notice that Pprior needs not equal P(T1) in practice, and the approximation is close only
through a careful design of (1). Notably, designing the diffusion g(t) can be particularly problematic
as it affects both the approximation P(T1) ≈ Pprior and the training via the weighting λ(t); hence can
lead to unstable training (Nichol & Dhariwal, 2021). In contrast, Schrodinger Bridge considers a
more flexible framework for designing the forward diffusion that requires minimal manipulation.
logP0SGM(x0) ≥LSGM(x0; θ) = E[logPT(XT)] - E
0
E [log PT (XT)] - Z
0
E 2g2kst -VxlogPt∣x0
2.2	SCHRODINGER BRIDGE (SB)
Following the dynamic expression of SB (Pavon & Wakolbinger, 1991; Dai Pra, 1991), consider
min	DKL(Q || P),	(5)
Q∈P (pdata,pprior)
where Q ∈ P(Pdata, Pprior) belongs to a set of path measure with Pdata and Pprior as its marginal
densities at t = 0 and T. On the other hand, P denotes a reference measure, which we will set to the
path measure of (1) for later convenience. The optimality condition to (5) is characterized by two
PDEs that are coupled through their boundary conditions. We summarize the related result below.
Theorem 1 (SB optimality; Chen et al. (2021); Pavon & Wakolbinger (1991); Caluya & Halder
(2021)). Let Ψ(t, x) and Ψ(t, x) be the solutions to the following PDEs:
∂Ψ = -VxΨTf-1 Tr(g2VxΨ)	,	、	,	、
U	=	-Vx ∙ (Ψ f )+2w VxΨ) s： ψ(Mψ(0, ∙) =Pdata，ψ(T, ∙)ψ (T,	∙)	=PPrior	⑹
Then, the	solution to the optimization (5) can be expressed by the path measure	of	the	following
forward (7a), or equivalently backward (7b), SDE:
dXt = [f + g2 Vx log Ψ(t, Xt)]dt + g dWt, X0 〜 Pdata,	(7a)
dXt = [f - g2 Vx log Ψb (t, Xt)]dt + g dWt, XT 〜 Pprior,	(7b)
where Vx log Ψ(t, Xt) and Vx log Ψ(t, Xt) are the optimal forward and backward drifts for SB.
2Hereafter, we will sometimes drop f ≡ f(t, Xt) and g ≡ g(t) for brevity.
3
Published as a conference paper at ICLR 2022
Score-based Generative Model (SGM)
dXt=[f ：
Data
dX力=[f -^2Vxlog^dt + gdW/
Control-affine SDEs
Stochastic Optimal
Control Perspective
Log-likelihood
Ob Objective (3)
]ldt + gdWf
No Noise
FBSDEs Theory
(Theorem 3 & 4)
Schrodinger Bridge (SB)
I dX% = [/+i∕vjogψjd/ + gdWt
Data x0	No Noise
----dX% = [ʃ -⅛2 VxIog Φ] dt + gdWt
PDEsOptimOl) PDEs Optimality (6)
Figure 2: Schematic diagram of the our stochastic optimal control interpretation, and how it connects
the objective of SGM (3) and optimality of SB (6) through Forward-Backward SDEs theory.
Similar to the forward/backward processes in SGM, the stochastic processes of SB in (7a) and (7b)
are also equivalent in the sense that ∀t ∈ [0, T], p；7a) ≡ p；7b) ≡ PSB. In fact, its marginal density
obeys a factorization principle: PSB(Xt) = Ψ(t, Xt)Ψ(t, Xt).
To construct the generative pipeline from (7b), one requires solving the PDEs in (6) to obtain Ψ.
Unfortunately, these PDEs are hard to solve even for low-dimensional systems (Renardy & Rogers,
2006); let alone for generative applications. Indeed, previous works either have to replace the
original Schrodinger Bridge (Pdata 二 PPriOr) With multiple stages, Pdata 二 PmiddIe 二 Pprior, so that
each segment admits an analytic solution (Wang et al., 2021), or consider the following half-bridge
(Pdata J Pprior vs. Pdata → Pprior) optimization (De Bortoli et al., 2021; Vargas et al., 2021),
Q(1) := arg min DKL(Q || Q(0)), Q(0) := arg min DKL(Q || Q(1))
Q∈P (∙,Pprior )	q∈p(Pdata ,∙)
which can be solved with IPF algorithm (Kullback, 1968) starting from Q(0) := P. In the following
section, we will present a scalable computational framework for solving the optimality PDEs in
(6) and show that it paves an elegant way connecting the optimality principle of SB (6) to the
parameterized log-likelihood of SGM (3).
3 Approach
We motivate our approach starting from some control-theoretic observation (see Fig. 2). Notice that
both SGM and SB consist of forward and backward SDEs with similar structures. From the stochastic
control perspective, these SDEs belong to the class of control-affine SDEs with additive noise:
dXt =A(t,Xt)dt+B(t,Xt)u(t,Xt)dt+C(t)dWt.	(8)
It is clear that the control-affine SDE (8) includes all SDEs (1,2,4,7) appearing in §2 by considering
(A, B, C) := (f, I, g) and different interpretations of the control variables u(t, Xt). This implies
that the optimization processes of both SGM and SB can be aligned through the lens of stochastic
optimal control (SOC). Indeed, both problems can be interpreted as seeking some time-varying
control policy, either the score function Vx logPt∣x0 in SGM or Vx log Ψ in SB, that minimizes
some objectives, (3) vs. (5), while subjected to some control-affine SDEs, (1,2) vs. (7). In what
follows, we will show that a specific mathematical methodology in nonlinear SOC literature - called
Forward-Backward SDES theory (FBSDEs; see Ma et al. (1999)) - links the optimality condition of
SB (6) to the log-likelihood objectives of SGM (3). All proofs are left to Appendix B.
3.1 Forward-Backward SDEs (FBSDEs) Representation for SB
The theory of FBSDEs establishes an innate connection between different classes of PDEs and
forward-backward SDEs. Below we introduce the following connection related to our problem.
Lemma 2 (Nonlinear Feynman-Kac;3 Exarchos & Theodorou (2018)). ConSider the coupled SDES
dXt=f(t,Xt)dt+G(t,Xt)dWt,	X0=x0	(9a)
[dYt = -h(t, Xt, Yt, Zt)dt + Z(t, Xt)tdWt,	YT =夕(XT)	(9b)
3Lemma 2 can be viewed as the nonlinear extension of the celebrated Feynman-Kac formula (Karatzas &
Shreve, 2012), which characterizes the connection between linear PDEs and forward SDEs.
4
Published as a conference paper at ICLR 2022
where thefunCtions f, G, h, and 夕 satisfy proper regularity conditions4 so that there exists a pair of
unique strong solutions satisfying (9). Now, consider the following second-order parabolic PDE and
suppose v(t, x) ≡ v is once continuously differentiable in t and twice in x, i.e. v ∈ C1,2,
∂v 1
∂t + 2 Tr(VXv GGT) + Vχvτf + h(t, x, v, GT Jv) = 0, v(T, x)=2(x),	(10)
then the solution to (9) coincides with the solution to (10) along paths generated by the forward SDE
(9a) almost surely, i.e., the following stochastic representation (known as the nonlinear Feynman-Kac
relation) is valid:
v(t, Xt) = Yt	and	G(t, Xt)TVxv(t, Xt) = Zt.	(11)
Lemma 2 states that solutions to a certain class of nonlinear (via the function h in (10)) PDEs can be
represented by solutions to a set of forward-backward SDEs (9) through the transformation (11), and
this relation can be extended to the viscosity case (Pardoux & Peng (1992); see also Appendix B).
Note that Yt is the solution to the backward SDE (9b) whose randomness is driven by the forward
SDE (9a). Indeed, it is clear from (11) that Yt (hence also Zt) is a time-varying function of Xt.
Since the v appearing in the nonlinear Feynman-Kac relation (11) takes the random vector Xt as
its argument, v(t, Xt ) shall also be understood as a random variable. Finally, it is known that the
original (deterministic) PDE solution v(t, x) can be recovered by taking conditional expectation, i.e.
v(t, X) = EXt〜(9a)[Yt∣Xt = x] and G(t, X)TVxv(t, X) = EXt〜(9a)[ZtXt = x].	(12)
Since it is often computationally favorable to solve SDEs rather than PDEs, Lemma 2 has been
widely used as a scalable method for solving high-dimensional PDEs (Han et al., 2018; Pereira et al.,
2019). Take SOC applications for instance, their PDE optimality condition can be characterized
by (11) under proper conditions, with the optimal control given in the form of Zt . Hence, one can
adopt Lemma 2 to solve the underlying FBSDEs, rather than the original PDE optimality, for the
optimal control. Despite seemingly attractive, whether these principles can be extended to SB, whose
optimality conditions are given by two coupled PDEs in (6), remains unclear. Below we derive a
similar FBSDEs representation for SB.
Theorem 3 (FBSDEs to SB optimality (6)). Consider the following set of coupled SDEs,
dXt = (f + gZt)dt + gdWt	(13a)
< dYt = 1 ZTZtdt + ZTdWt	(13b)
1
dYt =(JZTZt + Vx ∙ (gZt - f) + ZTZt/ dt + ZTdWt	(13c)
where f and g satisfy the same regularity conditions in Lemma 2 (see Footnote 4), and the boundary
conditions are given by X(0) = x0 and YT + YbT = logpprior(XT). Suppose Ψ, Ψb ∈ C1,2, then
the nonlinear Feynman-Kac relations between the FBSDEs (13) and PDEs (6) are given by
Yt≡Y(t,Xt)=logΨ(t,Xt),	Zt ≡ Z(t, Xt) = gVx log Ψ(t, Xt),
(14)
Ybt≡Yb(t,Xt) =logΨb(t,Xt),	Zbt≡Zb(t,Xt) = gVx log Ψb (t, Xt).
L ,τ	/■< τ -Cr ∖ ι .ι r 11	■ t ,.
Furthermore, (Yt, Yt) obey the following relation:
Yt + Ybt = logptSB(Xt).
The FBSDEs for SB (13) share a similar forward-backward structure as in (9), where (13a) and
(13b,13c) respectively represent the forward and backward SDEs. One can verify that the forward
SDE (13a) coincides with the optimal forward SDE (7a) with the substitution Zt = gVx log Ψ.
^
In other words, these FBSDEs provide a local representation of log Ψ and log Ψ evaluated on the
optimal path governed
by (7a). Since Zt and Zbt
can be understood as the forward/backward policies,
in a similar spirit of policy-based methods (Pereira et al., 2020; Schulman et al., 2015), that guide the
SDE processes of SB, they sufficiently characterize the SB model. Hence, our next step is to derive a
proper training objective to optimize these policies.
4 Yong & ZhoU (1999); Kobylanski (2000) require f, G, h, and g to be continuous, f and G to be uniformly
Lipschitz in x, and h to satisfy quadratic growth condition in z.
5
Published as a conference paper at ICLR 2022
3.2	Log-likelihood Computation of SB
Theorem 3 has an important implication: It suggests that given a path sampled from the forward
SDE (13a), the solutions to the backward SDEs (13b,13c) at t = 0 provide an unbiased estimation of
the log-likelihood of the data point x0, i.e. E Y0 + Yb0|X0 = x0 = log pS0B (x0) = log pdata (x0),
where Xt is sampled from (13a). We now state our main result, which makes this observation formal:
Theorem 4 (Log-likelihood of SB model). Given the solution satisfying the FBSDE system in (13),
the log-likelihood of the SB model (Zt, Zt), at a data point x0, can be expressed as
logp0SB(x0) = E [log pT
(XT)]-ZT
0
2l∣ztk2+2kZt - "x logPSB + Ztk2
―2IIgVxlogPSB - Zt∣∣2-Vχ ∙f dt
(15)
E
E[logPT(XT)] -Z TE
0
2IIZtk2+2IIZtk2 + Vx YgZt - f) + ZTZt dt, (16)
where the expectation is taken over the forward SDE (13a) with the initial condition X0 = x0.
Similar to (3), Theorem 4 suggests a parameterized lower bound to the log-likelihoods, i.e.
logPS0B(x0) ≥ LSB(x0; θ, φ) where LSB(x0; θ, φ) shares the same expression in (16) except that
Zt ≈ Z(t, x; θ) and Zt ≈ Z(t, x; φ) are approximated with some parameterized models (e.g.
DNNs). Note that Vx log PtSB is intractable in practice for any nontrivial (Zt, Zb t). Hence, we use the
divergence-based objective in (16) as our training objective of both policies.
Connection to score-based models. Recall Fig. 2 and compare the parameterized log-likelihoods of
SB (16) to SGM (3); one can verify that LSB collapses to LSGM when (Zt, Zt) := (0, g st). From
the SB perspective, this occurs only when P(T1) = Pprior. Since no effort is required in the forward
process to reach Pprior, the optimal forward control Zt, by definition, degenerates; thereby making
the backward control Zb t collapses to the score function. However, in any case when P(T1) 6= Pprior,
for instance when the diffusion SDEs are improperly designed, the forward policy Zt steers the
diffusion process back to Pprior, while its backward counterpart Zb t compensates the reversed process
accordingly. From this view, SB alleviates the problematic design in SGM by enlarging the class of
diffusion processes to accept nonlinear drifts and providing an optimization principle on learning
these processes. Moreover, Theorem 4 generalizes the log-likelihood training from SGM to SB.
Connection to flow-based models. Interestingly, the log-likelihood computation in Theorem 4,
where we use a path {Xt }t∈[0,T] sampled from a data point X0 to parameterize its log-likelihood,
resembles modern training of (deterministic) flow-based models (Grathwohl et al., 2018), which have
recently been shown to admit a close relation to SGM (Song et al., 2020; Gong & Li, 2021). The
connection is built on the concept of probability flow - which suggests that the marginal density of an
SDE can be evaluated through an ordinary differential equation (ODE). Below, we provide a similar
flow representation for SB, further strengthening their connection to modern generative models.
Corollary 5 (Probability flow for SB). The following ODE characterizes the probability flow of the
optimal processes of SB (7) in the sense that ∀t, P(t17) ≡ P(t7) ≡ PtSB.
1
dXt = f + gZ(t, Xt)- 2g (Z(t, Xt)+ Z(t, Xt)) dt	(17)
One can verify (see Remark 10 in §B) that computing the log-likelihood of this ODE model (17)
using flow-based training techniques indeed recovers the training objective of SB derived in (16).
3.3	Practical Implementation
In this section, we detail the implementation of our FBSDE-inspired SB model, named SB-FBSDE.
Training process. We treat the log-likelihood in (16) as our training objective, where the divergence
can be can be estimated efficiently following Hutchinson (1989). This immediately distinguishes
SB-FBSDE from prior SB models (De Bortoli et al., 2021; Vargas et al., 2021), which instead rely on
6
Published as a conference paper at ICLR 2022
Algorithm 1 Likelihood training of SB-FBSDE
Input: boundary distributions pdata and pprior,
parameterized policies Z(∙, ∙; θ) and Z(∙, ∙; φ)
repeat
if memory resource is affordable then
run Algorithm 2.
else
run Algorithm 3.
end if
until converges
Algorithm 2 Joint (diffusion flow-based) training
for k = 1 to K do
Sample Xt∈[o,t] from (13a) where xo 〜 Pdata
(computational graph retained).
Compute LSB(x0; θ, φ) with (16).
Update (θ, φ) with Vθ,φLSB(xo； θ, φ).
end for
Algorithm 3 Alternate (IPF-based) training
Input: Caching frequency M
for k = 1 to K do
if k%M == 0 then
Sample Xt∈[o,τ] from (13a) where xo 〜Pdata
(computational graph discarded).
end if
Compute LSB(xo； φ) with (18).
Update φ with gradient VφLSB (xo； φ).
end for
for k = 1 to K do
if k%M == 0 then
Sample Xt∈[o,τ] from (7b) where XT 〜PPriOr
(computational graph discarded).
end if
Compute LSB (xT； θ) with (19).
Update θ with gradient Vθ LSB (xT； θ).
end for
LSB(X0； O) = -	EXt〜(7a)
0
LSB(XT； θ) = 一 Z EXt〜(7b)
0
regression-based objectives.5 For low-dimensional datasets, we simply perform joint optimization,
max Lsb (xo ； θ, Φ),to train the parameterized policies Z(∙, ∙; θ) and Z (∙, ∙; φ). For higher-dimensional
(e.g. image) datasets, however, it can be prohibitively expensive to keep the entire computational
graph. In these cases, we follow De Bortoli et al. (2021) by caching the sampled trajectories in a reply
buffer and refreshing them in a lower frequency basis (around 1500 iterations). Although this implies
that the gradient path w.r.t. θ will be discarded, we can leverage the symmetric structure of SB and
re-derive the log-likelihood for the sampled noise, i.e. LSB (xT ), based on the backward trajectories
sampled from (7b). We leave the derivation to Theorem 11 in §B due to space constraint. This results
in an alternate training between the following two objectives after dropping all unrelated terms,
1 kZ(t,Xt;φ)k2 + gVx ∙ Z(t,Xt;φ) + ZTZ(t,Xt；φ) dt, (18)
2kZ(t, Xt； θ)k2 + gVx ∙ Z(t, Xt; θ)+ ZTZ(t, Xt; θ) dt. (19)
Our training process is summarized in Alg. 1. While the joint training scheme in Alg. 2 resembles
recent diffusion flow-based models (Zhang & Chen, 2021), the alternate training in Alg. 3 relates to
the classical IPF (De Bortoli et al., 2021), despite differing in the underlying objectives. Empirically,
the joint training scheme can converge faster yet at the cost of introducing memory complexity. We
highlight these flexible training procedures arising from the unified viewpoint provided in Theorem 4.
Hereafter, we refer to each cycle, i.e. 2K training steps, in Alg. 3 as a training stage of SB-FBSDE.
Generative process. While the generative processes for SB can be performed as simply as propagat-
ing (7b) given the trained policy Z(∙, ∙; φ), it has been constantly observed that adopting Langevin
sampling to the generative process greatly improves performance (Song et al., 2020). This procedure,
often referred to as the Langevin corrector, requires knowing the score function Vx log pt . For SB,
we can estimate its value by recalling (see §2.2) that Zt + Zbt = gVx log ptSB. This results in the
following predictor-corrector sampling procedure (see Alg. 4 in Appendix D for more details).
Predict step: Xt . Xt + g Zt∆t + Pg∆t 'e	(20)
Correct step: Xt — Xt + ~g^(Zt + Zt) + √2σJe	(21)
where e 〜N(0, I) and σt is the pre-specified noise scales (see (59) in Appendix D).
Limitations & efficiency. The main computational burden of our method comes from the computation
of the divergence and maintaining two distinct networks. Despite it typically increases the memory by
2〜2.5 times compared to SGM, we empirically observe that the divergence-based training converges
much faster per iteration than standard regression. As a result, SB-FBSDE admits comparable training
time (+6.8% in our CIFAR10 experiment) compared to SGM, yet with a substantially fewer sampling
time (-80%) due to adopting nonlinear SDEs.
5In fact, their regression targets may be recovered from (15) under proper transformation; see Appendix C.
7
Published as a conference paper at ICLR 2022
4 Experiments
(b) Checkerboard
(a) GMM
T=0.00
T= 0.33
T=0∙66
T=1.00
Figure 3: Validation of our SB-FBSDE model on two synthetic toy datasets that represent continuous
and discontinuous distributions. Upper: Generation (Pdata — Pprior) process with the backward vector
field Z (∙, •; φ). Bottom: Diffusion (Pdata → PPriOr) process with the forward vector field Z(∙, ∙; θ).
C)	I	4	2	2	7	/	J q
∕3753f7∕1
q	夕	了	3	I	¥	∖	7 z
3	/	5	m	/	G	夕	IZ
2 18317/2
7	7	2	4	1	71"
ʃ	/	9	/	/	4	S	J ʒ
二 y∕37∕ 八 $
Figure 4:	Uncurated samples from our SB-FBSDE models trained on MNIST (left), resized CelebA
(middle) and CIFAR10 (right). More images can be found in Appendix E.
Setups. We testify SB-FBSDE on two toy datasets and three image datasets, i.e. MNIST, CelebA,6
and CIFAR10. Pprior is set to a zero-mean Gaussian whose variance varies for each task and can
be computed according to Song & Ermon (2020). We parameterize Z(∙, ∙; θ) and Z(∙, ∙; φ) with
residual-based networks for toy datasets and consider Unet (Ronneberger et al., 2015) and NCSN++
(Song et al., 2020) respectively for MNIST/CelebA and CIFAR10. All networks adopt position
encoding and are trained with AdamW (Loshchilov & Hutter, 2017) on a TITAN RTX. We adopt
VE-SDE (i.e. f := 0; see Song et al. (2020)) as our SDE backbone, which implies that in order
to achieve reasonable performance, SB must learn a proper data-to-noise diffusion process. On
all datasets, we set the horizon T =1.0 and solve the SDEs via the Euler-Maruyama method. The
interval [0, T] is discretized into 200 steps for CIFAR10 and 100 steps for all other datasets, which
are much fewer than the ones in SGM (≥1000 steps). Other details are left in Appendix D.
Toy datasets. We first validate our joint optimization (i.e. Alg 2) on generating a mixture of Gaussian
and checkerboard (adopted from Grathwohl et al. (2018)) as the representatives of continuous and
discontinuous distributions. Figure 3 shows how the learned policies, i.e. Z(∙, ∙; θ) and Z(∙, ∙; φ),
construct the vector fields that progressively transport samples back-and-forth between Pprior and Pdata.
The vector fields can be highly nonlinear and dissimilar to each other. This resembles neither SGMs,
whose forward vector field must obey linear structure, nor flow-based models, whose vector fields are
simply with opposite directions. We highlight this as a distinct feature arising from SB models.
Image datasets. Next, we validate our alternate training (i.e. Alg 3) on high-dimensional image
generation. The generated images for MNIST, CelebA, and CIFAR10 are presented in Fig. 4, which
clearly suggest that our SB-FBSDE is able to synthesize high-fidelity images. More uncurated
images can be founded in Appendix E. Regarding the quantitative evaluation, Table 1 summarizes
the negative log-likelihood (NLL; measured in bits/dim) and the FreChet Inception Distance score
(FID; Heusel et al. (2017)) on CIFAR10. For our SB-FBSDE, we compute the NLL on the test set
using Corollary 5, in a similar vein to SGMs and flow-based models, and report the FID over 50k
6We follow a similar setup of prior SB models (De Bortoli et al., 2021) and resize the image size to 32.
8
Published as a conference paper at ICLR 2022
Table 1: CIFAR10 evaluation using negative log-likelihood (NLL; bits/dim) on the test set and sample
quality (FID score) w.r.t. the training set. Our SB-FBSDE outperforms other optimal transport
baselines by a large margin and is comparable to existing generative models.
Model Class	Method	NLL 1	FID 1
	SB-FBSDE (ours)	2.96	3.01
Optimal Transport	DOT (Tanaka, 2019)	-	15.78
	Multi-stage SB (Wang et al., 2021)	-	12.32
	DGflow (Ansari et al., 2020)	-	9.63
	SDE (deep, sub-VP; Song et al. (2020))	2.99	2.92
	ScoreFlow (Song et al., 2021)	2.74	5.7
SGMs	VDM (Kingma et al., 2021)	2.49	4.00
	LSGM(Vahdat et al., 2021)	3.43	2.10
MNIST
Figure 6: Ablation analysis where we show that adding
Langevin corrector to SB-FBSDE uniformly improves
the FID scores on both CelebA and CIFAR10 training.
Linear drift (f= αtxt)
Degenerate drift (f= 0)
SB-FBSDE Train Stage
Figure 5:	Validation of our SB-FBSDE on
learning forward diffusions that are closer
(in KL sense) to pprior compared to SGM.
samples w.r.t the training set. Notably, our SB-FBSDE achieves 2.98 bits/dim and 3.18 FID score on
CIFAR10, which is comparable to the top existing methods from other model classes (e.g. SGMs)
and outperforms prior Optimal Transport (OT) methods (Wang et al., 2021; Tanaka, 2019) by a large
margin in terms of the sample quality. More importantly, it enables log-likelihood computations that
are otherwise infeasible in prior OT methods. We note that the quantitative comparisons on MNIST
and CelebA are omitted as the scores on these two datasets are not widely reported and different
pre-processing (e.g. resizing of CelebA) can lead to values that are not directly comparable.
Validity of SB forward diffusion. Our theoretical analysis in §3.2 suggests that the forward policy
Z(∙, ∙; θ) ≡ Zθ plays an essential role in governing samples towards pprior. Here, We validate this
conjecture by computing the KL divergence between the terminal distribution induced by Zθ, i.e.
p(T13a), and the designated prior pprior. We refer readers to Appendix D for the actual computation.
Figure 5 reports these values over MNIST training. For both degenerate (f := 0) and linear
(f := αtXt) base drifts, our SB-FBSDE generates terminal distributions that are much closer to pprior.
Note that the values of SGM remain unchanged throughout training since SGM relies on pre-specified
diffusion. This is in contrast to our SB-FBSDE whose forward policy Zθ gradually shortens the KL
gap to pprior, thereby providing a better forward diffusion for training the backward policy.
Effect of Langevin corrector. In practice, we observe that the Langevin corrector greatly affects the
generative performance. As shown in Fig. 6, including these corrector steps uniformly improves the
sample quality (FID) on both CelebA and CIFAR10 throughout training. Since the SDEs are often
solved via the Euler-Maruyama method, their propagation can be subjected to discretization errors
accumulated over time. These Langevin steps thereby help re-distributing the samples at each time
step t towards the desired density ptSB. We emphasize this improvement as the benefit gained from
applying modern generative training techniques based on the solid connection between SB and SGM.
5 Conclusion
In this work, we present a novel computational framework, grounded on Forward-Backward SDEs
theory, for computing the log-likelihood of Schrodinger Bridge (SB) - a recently emerging model
that adopts entropy-regularized optimal transport for generative modeling. Our findings provide
new theoretical insights by generalizing previous theoretical results for Score-based Generative
Model, and facilitate applications of modern generative training for SB. We validate our method on
various image generative tasks, e.g. MNIST, CelebA, and CIFAR10, showing encouraging results in
synthesizing high-fidelity samples while retaining the rigorous mathematical framework.
9
Published as a conference paper at ICLR 2022
Acknowledgments
The authors would like to thank Ioannis Exarchos and Oswin So for their generous involvement and
helpful supports during the rebuttal. The authors would also like to thank Marcus A Pereira and
Ethan N Evans for their participation and kind discussion in the early stage of project exploration.
Author Contributions
The original idea of solving the PDE optimality of SB with FBSDEs theory was initiated by Tianrong.
Later, Guan derived the main theories (i.e. Theorem 3, 4, 11, and Corollary 5) presented in Section 3.1,
3.2 and Appendix B with few helps from Tianrong. Tianrong designed the practical algorithms (e.g.
stage-wise optimization and Langevin-corrector) in Section 3.3 and conducted most experiments with
few helps from Guan. Guan wrote the main paper except for Section 4, which were written by both
Tianrong and Guan. Both Guan and Tianrong contributed to code development.
Reproducibility S tatement
Our training algorithms are detailed in Alg. 1, 2, and 3, with the training objectives given in the
same section (see (16, 18, 19)). Other implementation details (e.g. data pre-processing) are left in
Appendix D. This shall provide sufficient information for readers of interests to reproduce our results.
As we strongly believe in the merit of open sourcing, we intend to release our implementation upon
publication. On the theoretical side, all proofs are left to Appendix B due to space constraint. We
provide the assumptions in the same section.
References
Brian DO Anderson. Reverse-time diffusion equation models. Stochastic Processes and their
Applications ,12(3):313-326,1982.
Abdul Fatir Ansari, Ming Liang Ang, and Harold Soh. Refining deep generative models via discrimi-
nator gradient flow. arXiv preprint arXiv:2012.00780, 2020.
Kenneth Caluya and Abhishek Halder. Wasserstein proximal algorithms for the SchrOdinger bridge
problem: Density control with nonlinear drift. IEEE Transactions on Automatic Control, 2021.
Jianfei Chen, Cheng Lu, Biqi Chenli, Jun Zhu, and Tian Tian. Vflow: More expressive generative
flows with variational data augmentation. In International Conference on Machine Learning, pp.
1660-1669. PMLR, 2020.
Tian Qi Chen, Yulia Rubanova, Jesse Bettencourt, and David K Duvenaud. Neural ordinary dif-
ferential equations. In Advances in Neural Information Processing Systems, pp. 6572-6583,
2018.
Yongxin Chen, Tryphon T Georgiou, and Michele Pavon. Stochastic control liaisons: Richard
sinkhorn meets gaspard monge on a schrOdinger bridge. SIAM Review, 63(2):249-313, 2021.
Rewon Child. Very deep vaes generalize autoregressive models and can outperform them on images.
arXiv preprint arXiv:2011.10650, 2020.
Julian D Cole. On a quasi-linear parabolic equation occurring in aerodynamics. Quarterly of applied
mathematics, 9(3):225-236, 1951.
Paolo Dai Pra. A stochastic control approach to reciprocal diffusion processes. Applied mathematics
and Optimization, 23(1):313-329, 1991.
Valentin De Bortoli, James Thornton, Jeremy Heng, and Arnaud Doucet. Diffusion schrOdinger
bridge with applications to score-based generative modeling. arXiv preprint arXiv:2106.01357,
2021.
10
Published as a conference paper at ICLR 2022
Ioannis Exarchos and Evangelos A Theodorou. Stochastic optimal control via forward and backward
stochastic differential equations and importance sampling. Automatica, 87:159-165, 2018.
Wenbo Gong and Yingzhen Li. Interpreting diffusion score matching using normalizing flow. arXiv
preprint arXiv:2107.10072, 2021.
Xinyu Gong, Shiyu Chang, Yifan Jiang, and Zhangyang Wang. Autogan: Neural architecture search
for generative adversarial networks. In Proceedings of the IEEE/CVF International Conference on
Computer Vision, pp. 3224-3234, 2019.
Alex A Gorodetsky, Sertac Karaman, and Youssef M Marzouk. Efficient high-dimensional stochastic
optimal motion control using tensor-train decomposition. In Robotics: Science and Systems, 2015.
Will Grathwohl, Ricky TQ Chen, Jesse Betterncourt, Ilya Sutskever, and David Duvenaud. Ffjord:
Free-form continuous dynamics for scalable reversible generative models. arXiv preprint
arXiv:1810.01367, 2018.
Jiequn Han, Arnulf Jentzen, and E Weinan. Solving high-dimensional partial differential equations
using deep learning. Proceedings of the National Academy of Sciences, 115(34):8505-8510, 2018.
Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter. Gans
trained by a two time-scale update rule converge to a local nash equilibrium. Advances in neural
information processing systems, 30, 2017.
Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion probabilistic models. arXiv preprint
arXiv:2006.11239, 2020.
Eberhard Hopf. The partial differential equation ut+ uux= μxx. Communications on Pure andApplied
mathematics, 3(3):201-230, 1950.
Chin-Wei Huang, Laurent Dinh, and Aaron Courville. Augmented normalizing flows: Bridging the
gap between generative flows and latent variable models. arXiv preprint arXiv:2002.07101, 2020.
Chin-Wei Huang, Jae Hyun Lim, and Aaron Courville. A variational perspective on diffusion-based
generative models and score matching. arXiv preprint arXiv:2106.02808, 2021.
Michael F Hutchinson. A stochastic estimator of the trace of the influence matrix for laplacian
smoothing splines. Communications in Statistics-Simulation and Computation, 18(3):1059-1076,
1989.
Aapo Hyvarinen and Peter Dayan. Estimation of non-normalized statistical models by score matching.
Journal of Machine Learning Research, 6(4), 2005.
Kiyosi It6.On stochastic differential equations, volume 4. American Mathematical Soc., 1951.
Alexia Jolicoeur-Martineau, Ke Li, Remi PichC-Taillefer, Tal Kachman, and Ioannis Mitliagkas.
Gotta go fast when generating data with score-based models. arXiv preprint arXiv:2105.14080,
2021.
Ioannis Karatzas and Steven Shreve. Brownian motion and stochastic calculus, volume 113. Springer
Science & Business Media, 2012.
Tero Karras, Miika Aittala, Janne Hellsten, Samuli Laine, Jaakko Lehtinen, and Timo Aila. Training
generative adversarial networks with limited data. arXiv preprint arXiv:2006.06676, 2020a.
Tero Karras, Samuli Laine, Miika Aittala, Janne Hellsten, Jaakko Lehtinen, and Timo Aila. Analyzing
and improving the image quality of stylegan. In Proceedings of the IEEE/CVF Conference on
Computer Vision and Pattern Recognition, pp. 8110-8119, 2020b.
Diederik P Kingma, Tim Salimans, Ben Poole, and Jonathan Ho. Variational diffusion models. arXiv
preprint arXiv:2107.00630, 2021.
Magdalena Kobylanski. Backward stochastic differential equations and partial differential equations
with quadratic growth. Annals of probability, pp. 558-602, 2000.
11
Published as a conference paper at ICLR 2022
Jungil Kong, Jaehyeon Kim, and Jaekyoung Bae. Hifi-gan: Generative adversarial networks for
efficient and high fidelity speech synthesis. arXiv preprint arXiv:2010.05646, 2020a.
Zhifeng Kong and Wei Ping. On fast sampling of diffusion probabilistic models. arXiv preprint
arXiv:2106.00132, 2021.
Zhifeng Kong, Wei Ping, Jiaji Huang, Kexin Zhao, and Bryan Catanzaro. Diffwave: A versatile
diffusion model for audio synthesis. arXiv preprint arXiv:2009.09761, 2020b.
Solomon Kullback. Probability densities with given marginals. The Annals of Mathematical Statistics,
39(4):1236-1243,1968.
Christian Leonard. A survey of the Schrodinger problem and some of its connections with optimal
transport. arXiv preprint arXiv:1308.0215, 2013.
Qianxiao Li and Shuji Hao. An optimal control approach to deep learning and applications to
discrete-weight neural networks. arXiv preprint arXiv:1803.01299, 2018.
Guan-Horng Liu, Tianrong Chen, and Evangelos A Theodorou. Ddpnopt: Differential dynamic
programming neural optimizer. In International Conference on Learning Representations, 2021a.
Guan-Horng Liu, Tianrong Chen, and Evangelos A Theodorou. Dynamic game theoretic neural
optimizer. In International Conference on Machine Learning, 2021b.
Ilya Loshchilov and Frank Hutter. Decoupled weight decay regularization. arXiv preprint
arXiv:1711.05101, 2017.
Jin Ma, J-M Morel, and Jiongmin Yong. Forward-backward stochastic differential equations and
their applications. Number 1702. Springer Science & Business Media, 1999.
Lars Maal0e, Marco Fraccaro, Valentin Lievin, and Ole Winther. Biva: A very deep hierarchy of
latent variables for generative modeling. arXiv preprint arXiv:1902.02102, 2019.
Dimitra Maoutsa, Sebastian Reich, and Manfred Opper. Interacting particle solutions of fokker-
planck equations through gradient-log-density estimation. Entropy, 22(8):802, 2020.
Balint Negyesi, Kristoffer Andersson, and Cornelis W Oosterlee. The one step malliavin scheme:
new discretization of bsdes implemented with deep learning regressions. arXiv preprint
arXiv:2110.05421, 2021.
Alex Nichol and Prafulla Dhariwal. Improved denoising diffusion probabilistic models. arXiv
preprint arXiv:2102.09672, 2021.
Etienne Pardoux and Shige Peng. Backward stochastic differential equations and quasilinear parabolic
partial differential equations. In Stochastic partial differential equations and their applications, pp.
200-217. Springer, 1992.
Jeeseung Park and Younggeun Kim. Styleformer: Transformer based generative adversarial networks
with style vector. arXiv preprint arXiv:2106.07023, 2021.
Michele Pavon and Anton Wakolbinger. On free energy, stochastic control, and schrodinger processes.
In Modeling, Estimation and Control of Systems with Uncertainty, pp. 334-348. Springer, 1991.
Marcus Pereira, Ziyi Wang, Ioannis Exarchos, and Evangelos A Theodorou. Neural network
architectures for stochastic control using the nonlinear feynman-kac lemma. arXiv preprint
arXiv:1902.03986, 2019.
Marcus Pereira, Ziyi Wang, Tianrong Chen, Emily Reed, and Evangelos Theodorou. Feynman-kac
neural network architectures for stochastic control using second-order fbsde theory. In Learning
for Dynamics and Control, pp. 728-738. PMLR, 2020.
Wei Ping, Kainan Peng, Kexin Zhao, and Zhao Song. Waveflow: A compact flow-based model for
raw audio. In International Conference on Machine Learning, pp. 7706-7716. PMLR, 2020.
12
Published as a conference paper at ICLR 2022
Prajit Ramachandran, Barret Zoph, and Quoc V Le. Searching for activation functions. arXiv preprint
arXiv:1710.05941, 2017.
Michael Renardy and Robert C Rogers. An introduction to partial differential equations, volume 13.
Springer Science & Business Media, 2006.
Olaf Ronneberger, Philipp Fischer, and Thomas Brox. U-net: Convolutional networks for biomedical
image segmentation. In International Conference on Medical image computing and computer-
assisted intervention, pp. 234-241. Springer, 2015.
Erwin Schrodinger. Surla theorie relativiste de l,electron et ^interpretation de la mecanique quantique.
In AnnaIes de l,institut Henri Poincare, volume 2, pp. 269-310, 1932.
John Schulman, Sergey Levine, Pieter Abbeel, Michael Jordan, and Philipp Moritz. Trust region
policy optimization. In International conference on machine learning, pp. 1889-1897, 2015.
Yang Song and Stefano Ermon. Generative modeling by estimating gradients of the data distribution.
arXiv preprint arXiv:1907.05600, 2019.
Yang Song and Stefano Ermon. Improved techniques for training score-based generative models.
arXiv preprint arXiv:2006.09011, 2020.
Yang Song, Jascha Sohl-Dickstein, Diederik P Kingma, Abhishek Kumar, Stefano Ermon, and Ben
Poole. Score-based generative modeling through stochastic differential equations. arXiv preprint
arXiv:2011.13456, 2020.
Yang Song, Conor Durkan, Iain Murray, and Stefano Ermon. Maximum likelihood training of
score-based diffusion models. arXiv e-prints, pp. arXiv-2101, 2021.
Akinori Tanaka. Discriminator optimal transport. arXiv preprint arXiv:1910.06832, 2019.
Arash Vahdat and Jan Kautz. Nvae: A deep hierarchical variational autoencoder. arXiv preprint
arXiv:2007.03898, 2020.
Arash Vahdat, Karsten Kreis, and Jan Kautz. Score-based generative modeling in latent space. arXiv
preprint arXiv:2106.05931, 2021.
Francisco Vargas, Pierre Thodoroff, Neil D Lawrence, and Austen Lamacraft. Solving schrodinger
bridges via maximum likelihood. arXiv preprint arXiv:2106.02081, 2021.
Gefei Wang, Yuling Jiao, Qian Xu, Yang Wang, and Can Yang. Deep generative learning via
schrodinger bridge. arXiv preprint arXiv:2106.10410, 2021.
Jiongmin Yong and Xun Yu Zhou. Stochastic controls: Hamiltonian systems and HJB equations,
volume 43. Springer Science & Business Media, 1999.
Qinsheng Zhang and Yongxin Chen. Diffusion normalizing flow. arXiv preprint arXiv:2110.07579,
2021.
13
Published as a conference paper at ICLR 2022
A Introduction of SCHRGDINGER Bridge
In this subsection, We provide a brief review for Schrodinger Bridge (SB) and some reasonings for
Theorem 1. The SB problem, at its classical form, considers the following optimization (Dai Pra,
1991; Pavon & Wakolbinger, 1991),
T1
min E	xku(t, Xt)k2
u∈U 0	2
∫ dXt = u(t, Xt)dt + H dWt
[Xo 〜po(X),	XT 〜PT(X)
(22)
where U := {u : [0, T] × Rn 7→ Rn|hu, ui < ∞}. The optimization (22) characterizes a standard
stochastic optimal control (SOC) programming with energy (i.e. 1 ∣∣uk2) minimization except with
an additional terminal boundary condition. The optimality conditions to (22) are given by
∂ψ
∂t
∂p*
∂t
-2l∣Vχψk2 - e δψ,
Nx ∙ (p*Vχψ) + e ∆p*,
(23a)
(23b)
where ψ(t, x) ∈ C1,2 is known as the value function in SOC literature and p* (t, x) ∈ C1,2 is the
associated optimal marginal density. ∆ denotes the Laplace operator. Equations (23a) and (23b) are
respectively the Kolmogorov’s backward and forward PDEs, also known as Hamilton-Jacobi-Bellman
and Fokker-Planck equations. The SB system can be obtained by applying the Hopf-Cole (Hopf,
・ 一〜-- .一一~	.	一 公、	一
1950; Cole, 1951) transformation (ψ,p*) → (Ψ, Ψ),
d d∂Ψ = -e δψ
[碧=e ∆Ψ
∂t
_ , . O , .	_ , 一 . O , 一 .
s.t. Ψ(0, ∙)Ψ(0, ∙) = P0, Ψ(T, ∙)Ψ(T, ∙) = PT.
(24)
In this work, we consider a recent generalization of (22) and (24) to an SDE class with nonlinear
drift, affine control, and time-varying diffusion. We synthesize their results below.
Theorem 6 (SB optimality; Caluya & Halder (2021)). Consider the following optimization
minE
u
ZOT 2ku(t, Xt)k2
[dXt = [f (t, Xt) + g(t) u(t, Xt)]dt + √2Tg(t) dWt
Sst I Xo 〜po(X),	XT 〜PT(X)
(25)
where g(t) is uniformly lower-bounded and f(t, Xt) satisfies Lipschitz conditions with at most linear
growth in x. Then, the Hopf-Cole transformation to (25) becomes
(∂Ψ = -VχΨTf-e Tr(g2VxΨ)
(碧=-Vx ∙ (Ψf)+e Tr(g2VxΨ) ,
(26)
∙.1 .1	7	1	T .∙	、含 /C ∖	√Γ=∕E ∖ √T√ ∕ΓΠ \
With the same boundary conditions Ψ(0, ∙)Ψ(0, ∙) = po, Ψ(T, ∙)Ψ(T, ∙)
to (25) is thereby given by
PT. The optimal control
u*(t, Xt) = 2eg(t)Vx logΨ(t, Xt).
(27)
Proof. See Section III and Theorem 2 inf Caluya & Halder (2021).
Theorem 6 is particularly attractive to us since its SDE corresponds exactly to the one appearing in
score-based generative models. one can recover Theorem 1 by
(i) Following Pavon & Wakolbinger (1991), we know that the objective in (25) is equivalent to
DKL(Q || P) by an application of Girsanov’s Theorem.
□
14
Published as a conference paper at ICLR 2022
(ii)	Equation (26) is exactly (6) with e = 2. Furthermore, substituting the optimal control (27) to
the stochastic process in (25) yields the optimal forward SDE in (7a).
(iii)	Finally, reversing the SDE (7a) from forward to backward following Anderson (1982),
dXt = [f + g2 Vx logΨ(t, Xt)- g2 Vx logPSB]dt + g dWt,	(28)
and recalling the factorization principle, logPSB(∙) = logΨ(t, ∙)+logΨ(t, ∙), from Equation
(4.15) in Chen et al. (2021) yield the optimal backward SDE in (7b).
B Proofs and Remarks in Section 3
In this section, we provide proofs for all of our theorems. We following the same notation by denoting
PtSDE (Xt) as the marginal density driven by some SDE process X(t) ≡ Xt until the time step
t ∈ [0, T]. Gradient and Hessian of a function f (x), where x ∈ Rn, will respectively be denoted
as Vx f ∈ Rn and V2xf ∈ Rn×n. Divergence and Laplace operators will respectively be denoted
as V∙ and ∆. Note that ∆ = V ∙ V. For notational brevity, we will only keep the subscript X for
multivariate functions. Finally, Tr(A) denotes the trace of a square matrix A.
We first restate the celebrated Itδ lemma, which is known as the extension of the chain rule of ordinary
calculus to the stochastic setting. It relies on the fact that dWt2 and dt are of the same scale and
keeps the expansion up to O(dt).
Lemma 7 (It6 formula; It6 (1951)). Let V ∈ C1,2 and let Xt be the stochastic process satisfying
dXt = f(t,Xt)dt+G(t,Xt)dWt.
Then, the stochastic process v(t, Xt) is also an Ito process satisfying
dv(t, Xt)=)Xtdt + ∣Vχv(t, Xt)Tf + 1 Tr [GTVXv(t, Xt)G] dt
+ Vxv(t,Xt)TG(t,Xt)dWt.
(29)
Next, the following lemma will be useful in proving Theorem 3.
Lemma 8. The following equality holds at any point x ∈ Rn such that P(x) 6= 0.
P(X) Tr (V2p(x)) = ∣∣Vlogp(x)k2 + ∆logP(X)
Proof.
Tr (V2p(x)) = ∆p(x) = V ∙ Vp(x)
=V ∙ (p(x)VlogP(X))
= VP(X)TV log P(X) + P(X)∆ log P(X)
= P(X)V logP(X)TV log P(X) + P(X)∆ log P(X)
=P(X)(IlV log P(X)Il2 + ∆log P(X))
□
Assumptions Before stating our proofs, we provide the assumptions used throughout the paper.
These assumptions are adopted from stochastic analysis for SGM (Song et al., 2021; Yong & Zhou,
1999; Anderson, 1982), SB (Caluya & Halder, 2021), and FBSDE (Exarchos & Theodorou, 2018;
Gorodetsky et al., 2015).
(i)	Pprior , Pdata ∈ C2 with finite second-order moment.
(ii)	f and g are continuous functions, and |g(t)|2 > 0 is uniformly lower-bounded w.r.t. t.
......... 一一	,	」	、一、	，、一	、	、一、 个， 、一，	八	.
(iii)	∀t ∈ [0,T], we have f(t, X), Vx logPt(X), Vx log Ψ(t, X), Vx log Ψb (t, X), Z(t, X; θ), and
Z(t, X; φ) Lipschitz and at most linear growth w.r.t. X.
15
Published as a conference paper at ICLR 2022
(iv)	Ψ, Ψ ∈ C 1,2. h, and 夕 are continuous functions. h satisfies quadratic growth w.r.t. X
uniformly in t.
(v)	∃k > 0 : ptSB (x) = O(exp-kxk2k) as x → ∞.
Assumptions (i) (ii) (iii) are standard conditions in stochastic analysis to ensure the existence-
uniqueness of the SDEs; hence also appear in SGM analysis (Song et al., 2021). Assumption (iv)
allows applications of Ito formula and properly defines the backward SDE in FBSDE theory. Finally,
assumption (v) assures the exponential limiting behavior when performing integration by parts.
Now, let us begin the proofs of Theorem 3, 4, and Corollary 5.
Theorem 3 (FBSDEs to SB optimality (6)). Consider the following set of coupled SDEs,
dXt = (f+gZt)dt+gdWt
dYt = 2 ZTZtdt + ZTdWt
1
dYt =(2 Z TZ t + Vx ∙ (gZ t - f) + Z TZt) dt + Z T dWt
(30a)
(30b)
(30c)
where f and g satisfy the same regularity conditions in Lemma 2 (see Footnote 4), and the boundary
conditions are given by X(0) = x0 and YT + Yb T = logpprior(XT). Suppose Ψ, Ψb ∈ C1,2, then
nonlinear Feynman-Kac relations between the FBSDEs (13) and PDEs (6) are given by
Yt≡Y(t,Xt)=logΨ(t,Xt),	Zt ≡ Z(t, Xt) = gVx log Ψ(t, Xt),
^ ^, ^. ^ ^, ^. .
Yb t ≡Yb (t,Xt) =logΨb (t, Xt),	Zbt ≡Zb (t,Xt) =gVxlogΨb (t,Xt).
(31)
L ,τ	/■< τ -Cr ∖ ι .ι r 11	■ t ,.
Furthermore, (Yt, Yt) obey the following relation:
Yt + Yb t = logptSB(Xt).
Proof. Similar to how the original nonlinear Feynman-Kac (i.e. Lemma 2) can be carried out by
an application of Ito lemma (Ma et al., 1999). We can apply Ito lemma 7 to the stochastic process
log Ψ(t, Xt) w.r.t. the optimal forward SDE (7a).
dlogΨ= dl∂g」dt + l-Vχ logΨT(f + g2Vχ logΨ) + 2g2 Tr [VX logΨ] dt + [gVχ logΨT] dWt.
(32)
From the PDE dynamics (6), we know that
¾ψ = Ψ∙ (-Vx^f -球…ψ))
=-Vx logΨTf - 2g2 Tr(：VxΨ).
The first term in the RHS can be readily canceled out with the related f -term in (32). The second
term can also be canceled out using the fact that Vx logΨ = ψ VXΨ 一 击 VχΨVχΨT. Hence, We
are left with
dlogΨ = kgVχ logΨk2 - 1 g2 Tr ]ψ2VχΨVχΨTUdt + gVχlogΨTdWt
=1 kgVx logΨk2dt + gVx logΨTdWt.	(33)
Likewise, applying Ito lemma to log Ψ(t, Xt), where Xt follows the SDE in (7a),
b
d logΨ = ~∂fψ dt + Vx logΨ t( + g2Vχ logΨ) + 1 g2 Tr [vX logψ] dt + [gVχlogΨ Ti dWt,
(34)
16
Published as a conference paper at ICLR 2022
b
but now noticing that the dynamics of d~∂gψ become
竽=⅛ Zx ∙(ψ f )+1-(g2vχψ))
=-Vx logΨTf -Vx ∙ f + 1 g2 TrdVxΨ).
2Ψ
Only the first term in the RHS will be canceled out in (34). Hence, we are left with
dlogΨ = -Vx ∙ f +1 g2 Tr iVxΨ dt
+ g2 Vx log Ψ T Vx log Ψ + 2 g2 Tr ∣Vx logΨ] dt + gVx log Ψ TdWt.
(35)
Notice that the trace terms above can be simplified to
∣Tr[i VxΨ + Vx logΨ
Tr ψVxΨ — 1 kVxlogΨk2
2IIVx logΨk2 + ∆x logΨ,
where the last equality follows by Lemma 8. Substituting this result back to (35), we get
dlogΨ =	—Vx ∙ f + 1 ∣∣gVx logΨk2 + g2∆xlogΨ +	g2VxlogΨTVx	logΨ	dt + gVx	logΨTdWt
=Vx ∙ (g2 Vx log Ψ—f) + 2 IgVx logΨk2 +	g2Vx logΨTVx	logΨ	dt + gVx	log ΨTdWt
(36)
Finally, by rewriting (33) and (36) with the nonlinear Feynman-Kac in (31) yields
dXt = (f + gZt)dt + gdWt
dYt = 2 ZTZtdt + ZT dWt
1
dYt =(2ZTZt + Vx ∙(gZt — f) + ZTZt)dt + ZTdWt
This concludes the proof.	□
Remark 9 (Viscosity solutions). These FBSDE results can be extended to viscosity solutions in the
case when the classical solution does not exist (Pardoux & Peng, 1992). For the completeness, one
shall understand them in the sense of v(t, x) = lim→∞ v(t, x) uniformly in (t, x) over a compact
set. Here ve(t, x) is the classical solution to (10) with (fe, Ge, he, φe) converge uniformly toward
(f, G, h,夕)over the compact set. We refer readers of interests to Exarchos & Theodorou (2018);
Negyesi et al. (2021), and their references therein.
Theorem 4 (Log-likelihood for SB models). Given the solution satisfying the FBSDE system in (13),
the log-likelihood of the SB model (Zt, Zt), at a data point x0, can be expressed as
T1	1
LSB(X0) = E[logPT(XT)] - J E 2IIZtIl +2IlZt — gVxlogpt + ZtIl
—2IlgVxIOgPSB - Zt∣∣2 —Vx ∙f dt
E [log pT (XT)] — Z E
0
2IIZtIl2+2IIZt∣∣2 + Vx YgZt — f) + ZTZt	dt,
(38)
(39)
where the expectation is taken over the forward SDE (13a) with the initial condition X0 = x0.
17
Published as a conference paper at ICLR 2022
Proof.
LSB(x0)
=E hY0+Yb0|X0 =x0i
=E
YT -
dt + Yb T -
((JkZtk2 + V∙(gZt-f) + ZTZt
dtX0 = x0
=E hYT +YbT|X0 =x0i -Z T
E 2IIZtk2 + 2IlZtk2 + VYgZt - f) + ZTZtlXO = xo	dt
=E[log pT (XT)] -
I0TE	2kZtk2
+ 2kZtk2 + v ∙ (gZt - f) + ZTZt dt,
(40)
which recovers (39). Finally, notice that with integration by part, we have
EXt〜PtB [-gZTVx logPSB],
(41)
where we adopt common practice and assume the limiting behavior of ptSB; in other words, ∃k > 0 :
ptSB(x) = O(exp-kxk2k) as x → ∞. With (41), we can rewrite the related parts in (40) as
E 2kZtk2 + gV∙ Zt + ZTZt
=E 2kZtk2 - ZT(gVlogPSB) + ZTZt
=E 1 kZt - gVlogPSB + Ztk2 - 2kgVlogPSB - Ztk2 .	(42)
Hence, We also recover (38).	□
Corollary 5 (Probability flow for SB). The following ODE characterizes the probability flow of the
optimal processes of SB (7) in the sense that ∀t, P(t17) ≡ P(t7) ≡ PtSB.
1
dXt =	f +	gZ(t,	Xt)	- 2g	(Z(t,	Xt)+ Z(t,	Xt))	dt	(43)
Proof. The probability ODE floW (Song et al., 2020; Maoutsa et al., 2020) suggests that the equivalent
ODE model for the SDE (1) is given by
dXt = f - 1 g2Vχ logPtI) dt.
We can adopt this result to the SDES of SB (7a) by considering f — f + gZt and PtI) - pSB. This
yields
dXt = f + gZt - 2g2VχlogpSb dt.	(44)
Applying the the factorization principle (Chen et al., 2021) With g log PtSB = Zt + Zbt concludes the
proof.	□
18
Published as a conference paper at ICLR 2022
Remark 10 (Connection between SB-FBSDE and flow-based models). To demonstrate how applying
flow-based training techniques to the probability ODE flow of SB (43) recovers the same log-
likelihood objective in (39), recall that given an ODE dXt = F(t, Xt)dt with Xo = xo 〜pdata,
flow-based models compute the change in log-density using the instantaneous change of variables
formula (Chen et al., 2018):
∂ log p(Xt)
∂t
-Vχ ∙ F,
which implies that the log-likelihood of xo can be computed as
logp(Xτ) = logp(xo) - Z Vχ ∙ F dt.
o
Now, consider the probability ODE flow of SB in (44),
11
FSB := f + gZt - 2g(Zt + Zt) = f + 2g(Zt- Zt).
(45)
Substituting this vector field FSB to (45) yields
logPT(Xt) = logPo(xo) - / Vx ∙ (f + 2g(Zt - Zt))dt
⇒ E [logPo(xo)] = E [logpτ(XT)] + / E 卜X ∙ (f + 2g(Zt -
dt
= E[logpT(XT)] -Z T
o
=E [logPT(XT)] — 广
o
E Vx ∙ (gZt - f) - 1 gVx ∙ (Zt + Zt) dt
E Vx ∙(gZt- f) +
(=) E [logpt(Xt)] - ZT
o
1
E Vx ∙(gZt - f ) + 2(Zt + Zt)2 dt,
(46)
where (*) is due to integration by parts (recall (41)) and (**) again uses the factorization principle
Zt + Zb t = gVx log PtSB. One can verify that (46) indeed recovers (39).
Theorem 11 (FBSDE computation for LSB (xT) in SB models). With the same regularity conditions
in Theorem 3, the following FBSDEs also satisfy the nonlinear Feynman-Kac relations in (31).
dXt	= ff - gZt) dt + gdWt	(47a)
< dYt	= - (2ZTZt + Vx ∙ (gZt	+ f)	+ ZTZ J dt	+ ZTdWt	(47b)
^	1 ^-ι-^	^-ι-
dYt = - -ZTZtdt + ZTdWt	(47c)
2
Given a backward trajectory Sampledfrom (47a), where XT = XT and XT 〜PpriOr,the log-likelihood
of xT is given by logPprior(xT) = E YT + Yb T|XT = xT := LSB(xT). In particular,
LSB(XT) = E[logPT(Xo)] - Z
o
E 2kZtk2+2IIZtk2 + VX ∙ (gZt + f) + ZTZt dt,	(48)
Proof. Due to the symmetric structure of SB, we can consider a new time coordinate
s,T -t.
Under this transformation, the base reference P appearing in (5) is equivalent to
dXs = -f(s, Xs)ds + g dWs.
The corresponding PDE optimality becomes
∂Φ = VxΦTf -1 Tr(g2V2 Φ)	ʌ	ʌ
Ids = Vx ∙ (φ f)+ 1 3g2VXφ)	sɪ φ(0,∙)φ (0, ∙)= Pprior，φ(T,∙)φ (T,∙)=pdata,	(49)
^
^
^
19
Published as a conference paper at ICLR 2022
and the optimal forward/backward policies are given by
dXs = [-f + g2 Vx log Φ(s, Xs)]ds + g dWs, Xo 〜Pprior,	(50a)
__	-	.	C __ -	^ ,	_、、_	____ ______ .
dXs = [-f — g Vx log Φ(s, Xs)]ds + g dWs, XT 〜pdata.	(50b)
By comparing (50) with (7), one can notice that the new SB system (Φ, Φ)s corresponds to the
original system (Ψ, Ψ)t via
Φ(s, Xs) =Ψb(T — t, XT-t)	and	Φb(s,Xs) =Ψ(T —t,XT-t).	(51)
Equation (51) shall be understood as the forward policy in t-coordinate system corresponds to the
backward policy in s-coordinate system, and vise versa. Following similar derivations in the proof
of Theorem 3, We can apply Ito lemma to expend the stochastic processes d log Φ and d log Φ w.r.t.
(50a). This yields the following FBSDE system.
dXs = (gZ0s —f)ds+gdWs	(52a)
dYS = 2 kZSk2ds + Zs TdWs	(52b)
dY0 = (2kZSk2 + Vx ∙ (gZs + f) + ZsTZs) ds + ZsTdWs	(52c)
Similar to (51), (Ys0, Ybs0, Z0s, Zb0s) relate to the original FBSDE system (30) by
(Ys0,Ybs0,Z0s,Zb0s)=(YbT0-t,YT0-t,Zb0T-t,Z0T-t).	(53)
Changing the coordinate from s to t and applying (53) readily yield (47). Finally, the expression in
(48) can be carried out similar to (40):
LSB (xT)
=E hYT +YbT|XT = xTi
=E Yo - /T (2kZtk2) dt + Yo - /τ gkZtk2 + V∙ (gZt + f) + ZTZJ dt∣Xτ = XT
2kZtk2 + 2IIZtk2 + V YgZt + f) + ZTZt∣XT = XT dt
2 kZtk2 + V∙ (gZt + f)+ ZTZ t dt.	(54)
We conclude the proof.	□
=E Yo+Ybo|XT =X
E
T
/ E 2kZtk2
=E[logpo(Xo)] -
C Comparison with prior SB works
Our method is closely related to tWo concurrent SB models (De Bortoli et al., 2021; Vargas et al.,
2021), yet differs in various aspects. BeloW We enumerate some of the differences.
Training loss. Both concurrent methods rely on solving SB mean-matching regression betWeen
the current drift and (estimated) optimal drift. This is in contrast to our SB-FBSDE, Which instead
utilizes a divergence-based objective (16). HoWever, the regression objectives are in fact captured by
Theorem 4. To see that, recall the forWard and backWard transition models considered in De Bortoli
et al. (2021),
Xk+1 〜N(Fk(Xk), 2γk+ιI), and Xk 〜N(Bk+ι(Xk+ι), 2γk+ιI),
Where Fk(X) := X + γk+1fk(X) and Bk+1 (X) := X + γk+1bk+1 (X) are solved alternately via
Bk + 1 J argmin E [kBk + i(Xk+I)-(Xk+1 + Fk (Xk ) - Fk (Xk+1))k2]	(55a)
Bk+1
Fk J arg min E kFk(Xk+1) - (Xk + Bk+1(Xk) - Bk+1(Xk))k2 .	(55b)
Fk
20
Published as a conference paper at ICLR 2022
In what follows, we focus mainly on the connection between (55a) and Theorem 4, yet similar
analysis can be applied to (55b). Now, expanding (55a) with the definition of (Bk+1 , Fk)
kBk+1 (Xk+1) - (Xk+1 + Fk(Xk) - Fk(Xk+1)k2
=k(Xk+1 + γk+1 bk+1 (Xk+1)) - (Xk+1 + Xk + γk+1fk(Xk) - Xk+1 - γk+1fk(Xk+1))k2
=kγk+1fk(Xk+1) + γk+1bk+1(Xk+1) - (Xk + γk+1fk(Xk) - Xk+1)k2,
’__'._	-{，一	-{，_
(56)
不
（2）
which resembles the term ∣∣Zt + Zt - gVχ logPSBk2 in (15). While ② indeed corresponds to our
backward policy Z(k+1, Xk+1) after time discretization, 1 slightly differs from Z(k+1, Xk+1)
in how time is integrated, γk+1f (k, Xk+1) vs. Z(k+1, Xk+1). On the other hand, 3 may be seen
as an approximation of gVx log ptSB, which, crucially, is not utilized in SB-FBSDE training. Since
Vx log ptSB is often intractable (nor does SB-FBSDE try to approximate it), SB-FBSDE instead uses
the divergence-based objective (16), which does not appear in their practical training.
SDE model class. It is important to recognize that both concurrent methods are rooted in the classical
SB formulation with the following SDE model,
dXt = f(t, Xt)dt + p2γ dWt,
which, crucially, differs from the SDE concerned by both our SB-FBSDE and SGM,
dXt = f(t, Xt)dt + g(t)dWt,	(57)
in that the diffusion g(t) is a time-varying function. This implies that the connection between classical
SB models and SGM can only be made in discrete-time after choosing proper step sizes. For instance,
De Bortoli et al. (2021) considers the Euler-Maruyama discretization (see their §C.3),
Xk+1 = Xk + Yk+ιf(k, Xk) + P2Yk+T e,	(58)
where e 〜N(0, I). In order for (58) to match the discretization of (57), where g(t) is often
a monotonically increasing function, the step sizes {γk}kN=1 must also increase monotonically.
However, since Vx log ptSB is approximated in De Bortoli et al. (2021) using the states from two
consecutive steps (see (55)), this may also affect the accuracy of the regression targets.
In contrast, our SB-FBSDE is grounded on the recent SB theory (Caluya & Halder, 2021), which
considers the same SDE model as in (57). As such, connection between SB-FBSDE and SGM is
made directly in continuous-time (and can be extended to discrete-time flawlessly); hence unaffected
by the choice of numerical discretization or step sizes.
Model parametrization. While Vargas et al. (2021) utilizes non-parametric models, e.g. Gaussian
processes (hence are not directly comparable), both De Bortoli et al. (2021) and SB-FBSDE use
DNNs to approximate the SB policies.
Training algorithm and convergence. Both concurrent methods rely on solving SB with IPF
algorithm, which performs alternate training between the forward/backward policies. While SB-
FBSDE can also be trained with IPF (see Alg. 3), we stress that it is also possible to train both policies
jointly whenever the computational budget permits. Interestingly, this joint optimization - which
is not presented in concurrent methods - resembles the training scheme of the recently-proposed
diffusion flow-based model (Zhang & Chen, 2021). We highlight these flexible training procedures
arising from the unified viewpoint provided in Theorem 4. Finally, with the close relation between
Alg. 3 and IPF (despite with different objectives and SDE model classes), convergence analysis from
classical IPF can be applied with few efforts. We leave it as a promising future work.
Corrector Sampling. While both De Bortoli et al. (2021) and SB-FBSDE implement corrector
sampling, they corresponds to different quantities. Specifically, our SB-FBSDE relies on the same
predictor-corrector scheme proposed in SGM (see Sec 4.2 in Song et al. (2020)), where the “corrector”
part is made with a Langevin sampling using the desired optimal density “V log pt”. In SB, this term
corresponds exactly to adding the outputs of our networks "Z + Z". This computation differs from the
corrector sampling appearing in De Bortoli et al. (2021), which relies on single network (i.e. either
Z or Z). Crucially, this implies that the two methods is approaching different target distributions;
hence leading to different training results. Notably, it has been reported in De Bortoli et al. (2021)
that corrector sampling only gives negligible improvement (see §J.2 in De Bortoli et al. (2021)), yet
in our case we observe major quantitative improvement (up to 4 FID).
21
Published as a conference paper at ICLR 2022
D Experiment Details
Table 1 with other models.
Table 2: CIFAR10 evaluation.
Model Class	Method	NLL 1	FID 1
	SB-FBSDE (ours)	2.96	3.01
Optimal Transport	DOT (Tanaka, 2019)	-	15.78
	Multi-stage SB (Wang et al., 2021)	-	12.32
	DGflow (Ansari et al., 2020)	-	9.63
	SDE (deep, SUb-VP; Song et al. (2020))	2.99	2.92
SGMs	ScoreFlow (Song et al., 2021)	2.74	5.7
	VDM (Kingma et al., 2021)	2.49	4.00
	LSGM(Vahdat et al., 2021)	3.43	2.10
	VDVAE (Child, 2020)	2.87	-
VAEs	NVAE (Vahdat & KaUtz, 2020)	2.91	23.49
	BIVA (Maal0e etal., 2019)	3.08	-
	FFJORD (GrathWohl et al., 2018)	3.40	-
Flows	VFlow (Chen et al., 2020)	2.98	-
	ANF (HUang et al., 2020)	3.05	-
	AutoGAN (Gong et al., 2019)	-	12.42
GANs	StyleGAN2-ADA (Karras et al., 2020a)	-	2.92
	LeCAM (Park & Kim, 2021)	-	2.47
Figure 7: Training Hyper-parameters
Dataset	learning rate	time steps	batch size	variance of pprior
Toy	2e-4	100	400	1.0
Mnist	2e-4	100	200	1.0
CelebA	2e-4	100	200	900.0
CIFAR10	1e-5	200	64	2500.0
Figure 8: Network Architectures
Dataset	Zt (∙, ∙; θ) and # of parameters	Zt (∙, ∙; φ) and # of parameters
Toy	FC-ResNet (0.76M)	FC-ResNet (0.76M)
Mnist	reduced Unet (1.95M)	reduced Unet (1.95M)
CelebA	Unet (39.63M)	Unet (39.63M)
CIFAR10	NCSN++ (62.69M)	Unet (39.63M)
Training. We use Exponential Moving Average (EMA) with the decay rate of 0.99. Table 7 details
the hyper-parameters used for each dataset. As mentioned in De Bortoli et al. (2021), the alternate
training scheme may substantially accelerate the convergence under proper initialization. Specifically,
when Zt is initialized with degenerate outputs (e.g. by zeroing out its
last layer), training Zbt at the
first K steps can be made in a similar SGM fashion since ptSB now admits analytical expression. As
f .ι	-∣∙	,	/TC YC∖	♦	∕r-r	∖ ι	ι	, ∙	∙ ι ,
for the proceeding stages, we resume to use (18, 19) since (Zt, Zt) no longer have trivial outputs.
Data pre-processing. MNIST is padded from 28×28 to 32×32 to prevent degenerate feature maps
through Unet. CelebA is resized to 3×32×32 to accelerate training. Both CelebA and CIFAR10 are
augmented with random horizontal flips to enhance the diversity.
22
Published as a conference paper at ICLR 2022
Figure 9: Network architecture for toy datasets.
Sampling. The sampling procedure is
summarized in Alg. 4. Given some
pre-defined signal-to-noise ratio r (we
set r =0.05 for all experiments), the
Langevin noise scale σt,i at each time
step t and each corrector step i is com-
puted by
2r2g2kik2
σt.i =	K	^,
k(z(t, Xt,i) + Z (t, Xt,i))k2
(59)
Network architectures. Table 8 summa-
rizes the network architecture used for
each dataset. For toy datasets, we param-
Algorithm 4 Generative Process of SB-FBSDE
Input: pprior, PohCieS Z(∙, ∙; θ) and Z(∙, ∙; φ)
Sample XT 〜pp∏or.
for t = T to ∆t do
Sample e 〜N(0, I).
Predict Xt,ι - Xt + g Zt∆t + √g∆t'e.
for i = 1 to N do
Sample q 〜N(0, I).
Compute Vx logPtBi ≈ [Z(t, Xt,i)+b(t, Xt,i)]∕g.
Compute σt,i with (59).
Correct Xt,i+ι — Xt,i + σt,iVχ logPSi + √2σti'&.
end for
Propagate Xt-∆t — Xt,N.
end for
return X0
eterize Z(∙, ∙; θ) and Z(∙, ∙; φ) With the
architectures shown in Fig. 9. Specifically, FCBlock represents a fully connected layer followed by
a sWish nonlinear activation (Ramachandran et al., 2017). As for MNIST, We consider a smaller
version of Unet (Ho et al., 2020) by reducing the numbers of residual block, attention heads, and
channels respectively to 1, 2, and 32. Unet and NCSN++ respectively correspond to the architectures
appeared in Ho et al. (2020) and Song et al. (2020).
Remarks on Table 1. We note that the values of our SB-FBSDE reported in Table 1 are computed
without the Langevin corrector due to the computational constraint. For all other experiments, We
adopt the Langevin corrector as it generally improves the performance (see Fig. 6). This implies
that our results on CIFAR10, despite already being encouraging, may be further improved With the
Langevin corrector.
Remarks on Fig. 5. To estimating KL(pT, pprior), We first compute the pixel-Wise first and second
moments given the generated samples XT at the end of the forWard diffusion. After fitting a diagonal
Gaussian to {XT}, We can apply the analytic formula for computing the KL divergence betWeen tWo
multivariate Gaussians.
Remarks on Fig. 6. To accelerate the sampling process With the Langevin corrector, for this
experiment We consider a reduced Unet (see Table 8) for CelebA. The FID scores on both datasets
are computed With 10k samples. We stress, hoWever, that the performance improvement using the
Langevin corrector remains consistent across other (larger) architectures and if one increases the FID
samples.
E	Additional Experiments
Comparison to De Bortoli et al. (2021) under same setup. To demonstrate the superior perfor-
mance of our model, We conduct experiments With the exact same setup implemented in De Bortoli
et al. (2021). Specifically, We adopt the same netWork architecture (reduced U-net), image pre-
processing (center-cropping 140 pixel and resizing to 32 × 32), step sizes (N =50), and horizon (0.5
second) for fair comparison. Comparing our Fig. 10b to De Bortoli et al. (2021) (see their Fig. 6),
it is clear that images generated by our model have higher diversity (e.g. color skin, facing angle,
background, etc) and better visual quality. We conjecture that our performance difference may come
from (i) the (in)sensitivity to numerical discretization betWeen our divergence objectives and their
mean-matching regression, and (ii) the foundational differences in hoW diffusion coefficients are
designed.
23
Published as a conference paper at ICLR 2022
(a) Ground Truth
■删 Hba
⅛1⅜ yr∙1∙ 9'归㈤


(b) SB-FBSDE Generated Image
W*KMUHa9
，■明・岛事■闺
■ •■•7•洞电
»d 4图0@新・

Figure 10: Comparison between images generated by ground truth and SB-FBSDE on reduced
CelebA. Our SB-FBSDE is trained under the same data pre-processing, network architecture and
stepsizes implemented in De Bortoli et al. (2021).
(c) SGM/50k + SB/f/5k + SB/b/5k
Figure 11: Qualitative results at the different stages of training. (a) Results after 50k training iterations
using SGM’s regression loss. (b) Refine the results of Fig. 11a by training the backward policy using
(18) with 5k iterations. (c) Refine the results of Fig. 11a with a full SB-FBSDE stage using (18,19).
SGM regression training + SB divergence-based training. Table 3 reports the FID (using 10k
samples, without corrector steps) at different stages of CIFAR10 training. We first train the backward
policy with SGM’s regression loss for a sufficient long iterations (50k) until the FID roughly converges.
Then, we switch to our alternate training (Alg. 3) using the divergence-based objectives. Crucially,
24
Published as a conference paper at ICLR 2022
Table 3: SGM regression training + SB divergence-based training. We denote “SGM/50k” as “training
50k steps using SGM loss”, and “SB/{f,b}/5k” as “training forward/backward policy with 5k steps
using our divergence loss”, and etc.
	initialization	SGM/10k	SGM/20k	SGM/50k	SGM/50k + SB/b/5k	SGM/50k + SB/f/5k + SB/b/5k
FID	448	41.37	35.47	33.68	13.35	11.85
with only 5k iterations of our divergence-based training, we drop the FID dramatically down to
13.35 from 33.68. With a full stage of training (last column), the FID decreases even lower to 11.85.
The qualitative results are provided in Fig. 11. Comparing Fig. 11a (corresponds to “SGM/50k” in
Table 3) and Fig. 11b (corresponds to “SGM/50k + SB/b/5k” in Table 3), it can be seen that the
visible flaw and noise have been substantially improved.
Additional Figures
3 2 入，SQ 4
c7sg,Γ-l
7√-" 3 G I 7
2 a t. /f >(
a q 3 Fy 6 3
6 7 了9 5 2 c√
/ *√7 夕 CPy I Λ/
〃 / q √> 3 2 7
Q 3 / 3 3 午
97夕÷R >
6φ∙74 2 4
5 Xw 7 3 79
Oc / 7 / 4 3
Jl ʒ /。0© 5
5 r Z
0 3 6 Vr 73
a 3 3 7，J
6/72/3
2 2 ? '3 7 7
3^β∙∕21n
3 1 7 q Jx
S 夕，g 5 /
4 ½< / Ar 3 JI
/77/73
/3371?
9 / →¾ J O/
/, Y 7 *57*^才
夕-27?5^
ς> 5 3∕f⅛‹
7 G> > hr- 7 d V
ə √M ʌs /V 5 J y
7 n d 乡> 0 /
,$ /，。7 7，
∖13%737
5 / 3 7 8
，5 g 4 / 7 Ir
? I ɔ L 7
;3 /。/
7 > 夕 3 3 4 3
3 /9 0 3 1><?
?/，2 ' / 5
7∕Qrsv/
1 7 / I a/ 5
3 7√7 3z)7
3 7 夕 7 / / J
7 J J 3 9 3 /
夕 I Γ 7 S 3 Z
VL- 59 Q 7 /
Figure 12: Uncurated samples generated by our SB-FBSDE on MNIST.
25
Published as a conference paper at ICLR 2022
Figure 13: Uncurated samples generated by our SB-FBSDE on resized CelebA.
26
Published as a conference paper at ICLR 2022

/网露窑卫 a⅛⅛EK ⅛≡

■ £⅛-工NHHM3Bci3举 M
SHΛQ3SQHα^□F^SMΠ -
A⅝ IHaR - SRK . 5■一
Is ・■ ■⅞JπΞ3liBB/凝。KB济H
RKUBES^^^ Fa∙⅛sFB⅛□
≡HR 阖巧 Hesiis∙2 r 交E鲍髭≡≡
sss^^s > l rfiii
US 偏曲/Π1<∙0E2>.6□&*>■■ M出
«0即 J占，#O= ecmhaiEH
a≡a^ ħq≡π⅞ ? ⅛≤-1
二口K1DR，函」Gklt≡aEfe轮 NBIɪ
EJE⅛4山SE召生 m AaΞr∙∙EB
HHkAΞ≡∙雪qi0h9BRXRTl或工，
_壬庭 Bh 幽 YΞ般nB0mκ<rEa为卡≡∙τ
一一a WaF9&M社 ⅛n^⅞Rr^⅜
一 ■品∙eRκp.一 SaB嘴∙DEQbs
3七N也掘段E黔0⅛Ξεal□物福嚏国Q J
即E・。餐加1l⅛狗fta』[3srH，L -
,『◎慈点四ŋa,∙c39aEMS3
Figure 14: Uncurated samples generated by our SB-FBSDE on CIFAR10.
27