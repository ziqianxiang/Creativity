Published as a conference paper at ICLR 2022
Omni-Scale CNNs: a simple and effective ker-
nel size configuration for time series classifi-
CATION
Wensi Tang1, Guodong Long1, Lu Liu1,2,Tianyi Zhou3,4, Michael Blumenstein1, Jing Jiang1
1Australian Artificial Intelligence Institute, University of Technology Sydney,2 Google
3University of Washington, Seattle, 4University of Maryland, College Park
{wensi.tang, lu.liu-10}@student.uts.edu.au,
{guodong.long, michael.blumenstein, jing.jiang}@uts.edu.au, tianyizh@uw.edu
Ab stract
The Receptive Field (RF) size has been one of the most important factors for One
Dimensional Convolutional Neural Networks (1D-CNNs) on time series classi-
fication tasks. Large efforts have been taken to choose the appropriate size be-
cause it has a huge influence on the performance and differs significantly for each
dataset. In this paper, we propose an Omni-Scale block (OS-block) for 1D-CNNs,
where the kernel sizes are decided by a simple and universal rule. Particularly,
it is a set of kernel sizes that can efficiently cover the best RF size across differ-
ent datasets via consisting of multiple prime numbers according to the length of
the time series. The experiment result shows that models with the OS-block can
achieve a similar performance as models with the searched optimal RF size and
due to the strong optimal RF size capture ability, simple 1D-CNN models with
OS-block achieves the state-of-the-art performance on four time series bench-
marks, including both univariate and multivariate data from multiple domains.
Comprehensive analysis and discussions shed light on why the OS-block can cap-
ture optimal RF sizes across different datasets. Code available here 1
1	Introduction
One of the most challenging problems for Time Series Classification (TSC) tasks is how to tell
models in what time scales 2 to extract features. Time series (TS) data is a series of data points
ordered by time or other meaningful sequences such as frequency. Due to the variety of information
sources (e.g., medical sensors, economic indicators, and logs) and record settings (e.g., sampling
rate, record length, and bandwidth), TS data is naturally composed of various types of signals on
various time scales (Hills et al., 2014; Schafer, 2015; DaU et al., 2018). Thus, in What time scales
can a model “see” from the TS input data has been a key for the performance ofTS classification.
Traditional machine learning methods have taken huge efforts to capture important time scales, and
the computational resource consumption increase exponentially With the length of TS increase. For
example, for shapelet methods (Hills et al., 2014; Lines et al., 2012), Whose discriminatory feature
is obtained via finding sub-sequences from TS that can be representative of class membership, the
time scale capture Work is finding the proper sub-sequences length. To obtain the proper length,
even for a dataset With length 512, (Hills et al., 2014) has to try 71 different sub-sequence lengths.
For other methods, such as (Berndt & Clifford, 1994; Schafer, 2015; Lucas et al., 2019), despite
the time scale capture might be called by different names such as finding Warping size or WindoW
length. They all need searching Works to identify those important time scales. More recent deep
learning based methods also shoWed that they had to pay alot of attention to this time scale problem.
MCNN (Cui et al., 2016) searches the kernel size to find the best RF ofa 1D-CNN for every dataset.
Tapnet (Zhang et al., 2020) additionally considers the dilation steps. Chen & Shi (2021) also take
1https://github.com/Wensi-Tang/OS-CNN.
2It has different names for different methods. Generally, it refers to the length of the time series sub-
sequence for feature extraction.
1
Published as a conference paper at ICLR 2022
5 0 5 0 5
2 2 11
s3sβep JO JQqUJnN
The accuracy range on UCR 85 time series datasets archive
5.0%	10.0%	15.0%	20.0%	25.0%	30.0%+
Accuracy range
5 0 5
1 1
Xue-36e∙l3z
Figure 1: Left: A model’s accuracy on the UCR 85 datasets changes by tuning the model’s receptive
field sizes from 10 to 200. Right: The average rank results of each receptive field size are pretty
similar, which means that no single receptive field size can significantly outperform others on most
datasets.
the number of layers into considerations. These are all important factors for the RF of CNNs and
the performance for TSC.
Although a number of researchers have searched for the best RF of 1D-CNNs for TSC, there is still
no agreed answer to 1) what size of the RF is the best? And 2) how many different RFs should be
used? Models need to be equipped with different sizes and different numbers of RFs for a specific
dataset. Using the same setup for every dataset can lead to a significant performance drop for some
datasets. For example, as shown by the statistics on the University of California Riverside (UCR) 85
“bake off” datasets in Figure 1a, the accuracy of most datasets can have a variance of more than 5%
just by changing the RF sizes of their model while keeping the rest of the configurations the same.
As also shown in Figure 1b, no RF can consistently perform the best over different datasets.
To avoid those complicated and resource-consuming searching work, we propose Omni-Scale block
(OS-block), where the kernel choices for 1D-CNNs are automatically set through a simple and
universal rule that can cover the RF of all scales. The rule is inspired by Goldbach’s conjecture,
where any positive even number can be written as the sum of two prime numbers. Therefore, the
OS-block uses a set of prime numbers as the kernel sizes except for the last layer whose kernel
sizes are 1 and 2. In this way, a 1D-CNN with these kernel sizes can cover the RF of all scales
by transforming TS through different combinations of these prime size kernels. What’s more, the
OS-block is easy to implement to various TS datasets via selecting the maximum prime number
according to the length of the TS.
In experiments, we show consistent state-of-the-art performance on four TSC benchmarks. These
benchmarks contain datasets from different domains, i.e., healthcare, human activity recognition,
speech recognition, and spectrum analysis. Despite the dynamic patterns of these datasets, 1D-
CNNs with our OS-block robustly outperform previous baselines with the unified training hyper-
parameters for all datasets such as learning rate, batch size, and iteration numbers. We also did a
comprehensive study to show our OS-block, the no time scale search solution, always matches the
performance with the best RF size for different datasets.
2	Motivations
Two phenomena of 1D-CNNs inspire the design of the OS-block. In this section, we will introduce
the two phenomena with examples in Figure 2 and more discussions can be found in Section 4.6.
Firstly, we found that, although the RF size is important, the 1D-CNNs are not sensitive to the
specific kernel size configurations that we take to compose that RF size. An example is given in the
right image of the Figure 2
Secondly, the performance of 1D-CNNs is mainly determined by the best RF size it has. To be
specific, supposing we have multiple single-RF-size-models which are of similar model size and
layer numbers, but each of them has a unique RF size. Let’s denote the set of those RF sizes as S.
When testing those models on a dataset, we will have a set of accuracy results A. Then, supposing
we have a multi-kernel model which has multiple RF sizes3 and set of those sizes is also S. Then,
3A detailed discussion about how to calculate RF sizes for 1D-CNNs with multiple kernels in each layer
can be found in Section 3.2
2
Published as a conference paper at ICLR 2022
Google Speechcommands dataset
(Receptive field size)：
kernel size for each layer
——(9)：5_5_1_1_1
—(9)：5_4_2_1_1
—(9)：5_3_3_1_1
—(9)：5_2_2_2_2
——(39):20_20_l_l_l
——(39):20_ll_10_l_l
—(39):20_8_7_7_l
—(39):20_6_6_6_5
——(99):50_50_l_l_l
——(99):50_26_25_l_l
——(99):50_17_17_16_l
——(99):50_14_13_13_13
Google Speechcommands dataset
7 6 5 4
■ ■ ■ a
>us3uuπtt⅞L
Set of receptive field size
——{9}
一 {9J}
——{9,7,5.3.1}
——{9tol}
——{39}
一 {39,29)
一 {39,34,29)
一 {39,34,29,24)
——{39 Co 1)
——{99}
——{99,80,60}
——{99,89,79,59,49.19}
——{99,94,89,84,79,74,69}
——{99 1» 1)
Figure 2: Left: The label of each line denotes receptive field size and the kernel configuration of
each ID-CNN. For example, (9):5_5_LL1 means the ID-CNN has five layers and the receptive
field size is 9, and from the first layer to the last layer, kernel sizes of each layer are 5, 5, 1, 1,
and 1. Lines of similar color are 1D-CNNs with the same receptive field size, and they are also of
similar performance. Right: Lines with similar colors are models which have the same best receptive
field size. For example, all (red/green/blue) lines have the receptive field size (9/39/99), and their
performances are similar to the bright (red/green/blue) line which denotes the model only has the
receptive field size (9/39/99).
the accuracy of the multiple-RF-sizes-model will be similar to the highest value of A. An example is
given in the left image of Figure 2. Specifically, when testing single-RF-size-models on the Google
Speechcommands dataset, the model’s performance is positive correlation with the model’s RF
size. For example, the light blue line whose set of RF size is {99} outperforms the light green line
{39} and light red line{9}. For those multiple-RF-sizes-models which has more than one element
in their set of RF sizes, their performance are determined by the best (also the largest because of
the positive correlation) RF size it has. Having more worse (smaller) RF sizes will not have much
influence on the performance.
The second phenomenon means that, instead of searching for the best time scales, if the model
covers all RF sizes, its performance will be similar to that of a model with the best RF size. However,
there are many designs that can cover all RF sizes. Which one should be preferred? Based on the
first phenomenon, from the performance perspective, we could choose any design that we want.
However, as we will show in Section 3.3, those candidate designs are not of the same characteristics
such as the model size or the expandability for long TS data. Therefore, the design of the OS-block
that we propose aims at covering all RF sizes in an efficient manner.
3	Method
The section is organized as follows: Firstly, we give the problem definition in Section 3.1. Then,
we will explain how to construct the Omni-scale block (OS-block) which covers all receptive field
sizes in Section 3.2. Section 3.3 will explain the reason why OS-block can cover RF of all sizes in
an efficient manner. In Section 3.4, we will introduce how to apply the OS-block on TSC tasks.
3.1	Problem Definition
TS data is denoted as X = [x1, x2, ..., xm], where m is the number of variates. For uni-
variate TS data, m = 1 and for m > 1, the TS are multivariate. Each variate is a vec-
tor of length l. A TS dataset, which has n data and label pairs, can be denoted as: D =
{(X 1,y1), (X2,y2),…,(Xn, yn)}, where (X*,y*) denotes the TS data X* belongs to the class
y*. The task of TSC is to predict the class label y* when given a TS X*.
3.2	Architecture of OS -block
The architecture of the OS-block is shown in Figure 3. It is a three-layer multi-kernel structure, and
each kernel does the same padding convolution with input. For the kernel size configuration, we use
P(i) to denote the kernel size set of the i-th layer:
P(i)	{1, 2, 3, 5,...,pk}	,i∈ {1, 2}
P = {1,2}	,i=3
(1)
3
Published as a conference paper at ICLR 2022
Mathematical phenomenon
Prime number list
SUm
1 2 3 I 5 7 11 13 I 17 19 …
1	2
2	4
1D-CNN classifier
3-5 7 U口 W
Prime number list
Green : prime number	: OS to cover all sizes
Red : even number	: OS to cover all sizes in a range
ID-CNN block design
OS-block I
Layer 1
Layer 2
Layer 3
Concatenation
BatChnOrm+ReLU
Layer output
Concatenation
Batchnorm+Re LU
Layer output
Batchnorm+ReLU
Concatenation
Figure 3:	The left image shows that every even number from 2 to 38 can be composed via two
prime numbers from 1 to 19. This phenomenon can be extended to all even numbers. Based on this
phenomenon, with the OS-block structure in the middle image, we could cover all receptive field
sizes. Specifically, the first two layers have prime-sized kernels from 1 to Pk. Thus, the two layers
can cover all even number receptive field sizes. With kernels of sizes 1 and 2 in the third layer, we
could cover all integer receptive field sizes in a range via selecting the value pk. The OS-block is
easy to be applied on time series classification tasks. A simple classifier with the OS-block, namely
OS-CNN, is given in the right image, which achieves a series of SOTA performances.
Where {1, 2, 3, 5, 7, ...,pk} is a set of prime numbers from 1 to pk. The value ofpk is the smallest
prime number that can cover all sizes of RF in a range. Here, the range that we mentioned is all
meaningful scales. For example, since the TS length is l, we don’t need to cover RFs that are larger
than l or smaller than 1. Therefore, the pk is the smallest prime number that can cover the RF size
from 1 to l. If we have prior knowledge, such as that we know there are cycles in the TS, or we
know the length range of the hidden representative pattern. We could change the RF size range of
the OS-block by simply changing the prime number list. An example is given in the left image in
Figure 3, which uses the prime number list in the blue block to cover the RF size range from 10 to
26.
RF sizes of the OS-block: The RF is defined as the size of the region in the input that produces
the feature. Because each layer of the OS-block has more than one convolution kernel, there will
be several different paths from the input signal to the final output feature (Araujo et al., 2019; Luo
et al., 2016), and each path will have a RF size. For the 3-layer OS-block, which has no pooling
layer and the stride size is 1, the set of RF sizes S is the set of RF size of all paths, and it can be
described as:
S = {p(1) + p(2) + p(3) - 2 | p(i) ∈ P(i),i ∈ {1, 2, 3}}.	(2)
For the reasons that P(i) are prime number list when i ∈ {1, 2}, the set {p(1) + p(2) |p(i) ∈ P(i), i ∈
{1, 2}} is the set of all even numbers E.4 Thus, we have
S = {e + p(3) - 2 | p(3) ∈ P(3),e ∈ E}.	(3)
With Equation 3 and Equation 1, we have
S = {e|e ∈ E} ∪{e- 1|e ∈ E} ≡ N+.	(4)
Where N+ is the set of all integer numbers in the range. Specifically, the S ≡ N+ is because a real
number must be an odd number or an even number, while E is the even number set, {e - 1|e ∈ E} is
4This is according to Goldbach’s conjecture. Specifically, the conjecture states that any positive even num-
ber can be composed of two prime numbers. For example, 8 = 5 + 3, 12 = 7 + 5, and more examples can be
found in the left image of Figure 3. Despite that the conjecture is yet unproven in theory, but its correctness has
been validated up to 4 × 1014 (Richstein, 2001), which is larger than the length of all available TS data.
4
Published as a conference paper at ICLR 2022
OS-block with residual connection
OS-block with ensemble learning
OS-block on each variate for multi variate
time series data
OS-block
OS-block
OS-block
Input data
Input data
OS-block
]
Input data
Input data variate 1 I	,
I Input data variate 2
Global average pooling ∣
I-----------[ Input data 1
-∣OS-block J
OS-block
I Fully conne Global average pooling +
I Fully COnnel Global average pooling
Input data variate
I- OS-block^^P---------1
1-----------OS-block J--------------1
1----------|OS-block
Concatenation
Global average pooling
Fully connected
Fully connected
Voting
Output result
OS-block
Global average pooling
I Fully connected
Output result
Figure 4:	Examples of using OS-block with other deep learning structures.
the odd number set. Therefore, with the proper selection of pk, we could cover any integer RF size
in a range. It should be noticed that, there might be many options to cover all RF sizes, We use the
Godlach,s conjecture to make sure that We could all scales.
3.3	OS-block cover all scales in an efficient manner
From the model size perspective, using prime numbers is more efficient than using even numbers
or odd numbers. To be specific, to cover receptive fields up to size r, the model size complexity of
using prime size kernels is O(r2/log(r)). On the other hand, no matter we use even number pairs
or odd number pairs, the model size complexity is O(r2). We also empirically show the advantage
of our model on efficiency in the following table and this table has been added to Appendix A.7:
3.4	How to apply OS-block on TSc tasks
Firstly, the OS-block could take both univariate and multivariate TS data by adjusting the input
channel the same as the variate number of input TS data. A simple example classifier with OS-
block, namely OS-cNN, is given in Figure 3. The OS-cNN is composed of an OS-block with one
global average pooling layer as the dimensional reduction module and one fully connected layer
as the classification module. Other than OS-cNN, the OS-block is flexible and easy to extend.
Specifically, convolution layers of OS-block can be calculated parallelly. Thus, each layer can be
viewed as one convolutional layer with zero masks. Therefore, both the multi-kernel layers or the
OS-block itself are easy to extend with more complicated structures (such as dilation (Oord et al.,
2016), attention or transformer (Shen et al., 2018a), and bottleneck) that are normally used in 1D-
cNN for performance gain. in Figure 4, we give three examples which uses OS-block with other
structures.
4	Experiment
4.1	Benchmarks
We evaluate OS-block on 4 TSc benchmarks which include, in total, 159 datasets. The details of
each benchmark is as follows:
•	Magnetoencephalography recording for Temporal Lobe Epilepsy diagnosis (MEG-
TLE) dataset (Gu et al., 2020): The Magnetoencephalography dataset was recorded from
epilepsy patients and was introduced to classify two subtypes (simple and complex) of
temporal Lobe Epilepsy. The dataset contains 2877 recordings which were obtained at the
sampling frequency 1200 Hz. Each recording is approximately 2 sec. Therefore the length
is about 2400.
•	University of East Anglia (UEA) 30 archive (Bagnall et al., 2018): This formulation of
the archive was a collaborative effort between researchers at the University of East Anglia
and the University of california, Riverside. it is an archive of 30 multivariate TS datasets
5
Published as a conference paper at ICLR 2022
Individual dataset benchmark
Dataset	Method	ACCuracy(%)	F1-sCore	# parameters
	CNN (GuetaL,2020)	832	82.3	3.8M
	PF (GUetaL ,2020)	82.6	68.2	-
MEG-TLE	SVM (GUetaL,2020)	55.2	85.2	-
(Gu et al., 2020)	MSAM (GU et al., 2020)	83.6	83.4	2.3M
	Rocket (Dempster et al., 2020)	87.7	89.9	-
		OS-CNN (Ours)	91.3	91.6	235k
Multivariate dataset archive benchmark
ArChive	Method	Baseline wins	OS-CNN (Ours) wins	Tie	Average Rank
	DTW-INND(norm)(Zhang et al., 2020)-	7	23	0	5.68
	DTW-INN-I(norm)(Zhang et al., 2020)	5	24	1	6.70
	ED-INN(norm)(Zhang et al., 2020)	5	25	0	7.45
	DTW-INND (Zhang etal., 2020)	7	23	0	5.28
UEA 30 arChive	DTW-1NN-I (Zhang et al., 2020)	7	22	1	6.07
(Bagnall et al., 2018)	ED-1NN (Zhang et al., 2020)	5	25	0	7.12
	WEASEL+MUSE (Schafer & Leser, 2017)	10	19	1	4.15
	MLSTM-FCN (Karim et al., 2019)	7	23	0	5.62
	TapNet (Zhang et al., 2020)	9	20	1	3.80
		OS-CNN (Ours)	-	-	-	3.13
Univariate dataset archives benchmarks
Archive	Method	Baseline wins	OS-CNN (Ours) wins	Tie	Average rank
	PF (LUCaSetaL,2019)	13	67	5	6.57
	ReSNet(WangetaL,2017)	19	61	5	5.41
	STC (Hameurlain et al., 2017)	27	56	2	5.05
UCR 85 archive	InceptionTime (Ismail Fawaz et al., 2019)	34	42	9	4.05
(Chen et al., 2015)	ROCKET (Dempster et al., 2020)	33	44	8	3.64
	HIVE-COTE (Lines et al., 2016)	34	43	8	3.99
	TS-CHIEF (Shifaz et al., 2020)	42	39	4	3.68
	OS-CNN (Ours)	-	-	-	3.59
	ResNet (Wang et al., 2017)	19	83	26	3.21
UCR 128 archive	InceptionTime (Ismail Fawaz et al., 2019)	30	59	39	2.41
(DaU et al., 2018)	ROCKET (Dempster et al., 2020)	43	62	23	2.36
		OS-CNN (Ours)		-	-	-	2.02
Table 1: Performance comparison on 4 time series classification benchmarks
from various domains such as motion detection, physiological data, audio spectra classi-
fication. Besides domains, those datasets also have various characteristics. For instance,
among those datasets, the class number various from 2 to 39, the length of each dataset
various from 8 to 17,894, and the number of variates various from 2 to 963.
•	University of California, Riverside (UCR) 85 archive (Chen et al., 2015): This is an
archive of 85 univariate TS datasets from various domains such as speech reorganizations,
health monitoring, and spectrum analysis. What’s more, those datasets also have different
characteristics. For instance, among those datasets, the class number varies from 2 to 60,
the length of each dataset varies from 24 to 2709. The number of training data varies from
16 to 8,926.
•	University of California, Riverside (UCR) 128 archive (Dau et al., 2018): This is an
archive of 128 univariate TS datasets. It is the updated version of the UCR 85 archive.
However, the new archive cannot be viewed as a replacement for the former because they
have different characteristics. For example, for the UCR 85 archive, all TS data within a
single dataset are of the same length, but that is not the same for the UCR 128 archive.
Besides that, in general, the added data in the UCR 128 archive, their default test set is
bigger than the train set to reflect real-world scenarios.
4.2	Evaluation criteria
For all benchmarks, we follow the standard settings from previous literature. Specifically, for the
MEG-TLE dataset, following Multi-Head Self-Attention Model (MSAM) (Gu et al., 2020), models
are evaluated by test accuracy and f1 score. Besides using recommended metrics of each benchmark,
we also compare the model size of OS-block with other deep learning methods. For UEA 30, UCR
85 archives, and UCR 128 archives, following the evaluation advice from the archive (Dau et al.,
2018; Bagnall et al., 2018), count of wins, and critical difference diagrams (cd-diagram) (Dau et al.,
2018) were selected as the evaluation method. Due to the page limitation, we list the average rank
6
Published as a conference paper at ICLR 2022
SEatlodo*u.
au≡d
30。
ωuβt∙
SXeaa>_电3
mMPBMS
saΛJny⅞Γμss
UOH3npay3NSEαl5α
KUaqME:IS
TaUgn Ssqσuog-luos
HSH
bl
sUJpe 9 ωu
Accuracy of OS-CNN vs Accuracy range of RF size tunning
AccuracyofOS-CNN
• Accuracy of model with various RF size
aEauoud
iwωc=c-
SaU-AaUOHEaGEStj
≈>⅛BH
WUXUmeUda-PPM
adʌt UaanS
dneoa6v8u=so*ueoxd≡!pp∑
PUnOSsa⅛u-Mwasu-
6UEaH
SPXCO-OXa-SW-Q
Sse-Uowilsiujom
EQH
S94enbqtteuj
sa□ue=ddvuaxsQ=eES
s∞>acp∙ctias
SJasdEO。
SEAUOUASEOM
teJqnaJn⅞awu⅛Λn
d n QJOaHVBU =⅛oxuβQq⅛ssQ
ZxJeq πaJmsaoa>BMn
tsauo⅛∙u =:InOXU5eqd -ss-ɑ
sa6eE--3-paΣ
≡pxcβ-βxtt-βE -XOJd
SUUoM
⅛u-5⅛π
⅛u 一 ua⅞□
SPJoMA34 H
XΛJe q ∏ aι msaoa>eMn
υROɔəusnoXU5eqd a 一 pp∑
¾ag
tsaUoQSaU=gosaeuemd
OefitoUWOCU
Es⅛⅛fw
=OS=O
ɔe 一 PV
BEOU.
PeaHMRV
dnRoaβvau≡noxu5eqdoE-x2d
Wc-S
UOH£UaUUOuau μo-lo
Jo®=。
>-⅛-⅛φffl
N-9-utυ
=va3eu∙
ʌjæpɪŋ
saw®-d d yu aɪs mE(3
43aJ-10⅛-u≡ncixu5ex½eE><αJd
uæpɪɔp-lm
omo>
OONOUW
=VSadeMS
feu
u-ej⅛iaow
OOOS目
=VXJ e q __lal n⅛a□a>eM n
mso
PU eE90,JaM0d>-g
SaU=⅛0pueH
VPJoU.
ZUO-1? aE 8S 9Ql
-JnodMeu.
TUO-⅛w aE 6βs≡QL
Z x≡j Oc - 3M- - ewa>se>u -U 02
T XeJ OMj_00111- ewaaggAU -U 02
Zauen SsqoMogl-uos
Honsaued
⅛ω≡
⅞i
S-OqEAS
^mu
一 EUOOUHaEUAS
Dataset name
Figure 5: Classification accuracies for OS-CNN vs. accuracies from 20 ID-CNNs with receptive
field size. As we can see, for most of the dataset, the orange points (accuracy of OS-CNN) are near
the top of blue points. More analysis for this comparison can be found in Appendix A.1
in the result table because it is the main criteria of the cd-diagram. The full cd-diagram results are
listed in Appendix A.3.
4.3	Experiment setup
For the MEG-TLE dataset, they were normalized by z-normalization (Chen et al., 2015). For the
other archives, we take the raw dataset without processing for datasets in those archives already
normalized with z-normalization.
Following the setup of (Wang et al., 2017), we use the learning rate of 0.001, batch size of 16, and
Adam (Kingma & Ba, 2014) optimizer. The baselines are chosen from the top seven methods from
the leaderboard 5 of each benchmark. For UCR archives, we ensemble five OS-CNNs, which stacks
two OS-blocks with residential connections followed by the baseline IncpetionTime (Ismail Fawaz
et al., 2019). We use PyTorch 6 to implement our method and run our experiments on Nvidia Titan
XP.
4.4	State-of-the-art performance on benchmarks
We show consistent state-of-the-art performance on four benchmarks as in Table 1. As we can see,
for the MIT-TLE dataset, OS-CNN outperforms baselines in a ten times smaller model size. For
all dataset archives, the OS-block achieves the best average rank, which means that, in general, the
OS-block design can achieve better performance.
4.5	OS-block can capture the best time scale
To demonstrate that the OS-block can capture the best time scale, we build 20 FCN models with
different RF sizes (from 10 to 200 with step 10), and compare their performance with OS-CNN on
the UCR 85 archive. Specifically, the FCN (Wang et al., 2017) is selected as the backbone model
for it has a similar structure as OS-CNN.
To obtain FCN with various RF sizes, we change the kernel size of each layer proportionally. To be
specific, the kernel sizes of the original three layer FCN are 8, 5, and 3, and the RF size is 14. To
obtain the RF size 30, we will set kernel sizes of each layer as 16,10, and 6. To control variables,
when the kernel size increases, we will reduce the channel number to keep the model size constant.
This will not influence the conclusion. To check that, in Appendix A.2, we also provide the static
result comparison between OS-CNN and FCNs with the fixed channel number.
5http://www.timeseriesclassification.com/results.php6https://pytorch.org/
7
Published as a conference paper at ICLR 2022
ScreenType feature map
frequency
Figure 6: The class activation map of OS-CNN is similar to that of the model which has a better
performance. For the ScreenType dataset, FCN(10) outperforms FCN(200), and the class activation
map of OS-CNN (green) is similar to FCN(10)(blue). For the InsectWingbeatSound dataset, the
class activation map is similar to FCN(200) for FCN(200) outperforms FCN(10).
frequency
Due to the page limitation, the full result can be found in the supplementary material. And in
Figure 5, a simple result comparison is given, and we could see that for most of the datasets, OS-
CNN can achieve a similar result as models with the best time scale.
4.6	Discussion about best time scale capture ability
The result in Figure 5 empirically verifies two phenomena that we mentioned in Section 2 with
multiple datasets from multiple domains. Firstly, the OS-block covers all scales. Therefore, besides
the important size, it also covers many redundant sizes, but those redundancies will not pull down
the performance. Secondly, OS-block composes the RF size via the prime design while the FCN
uses a different design. It means that the performances of 1D-CNNs are determined mainly by the
RF size instead of the kernel configuration to compose that.
4.7	Case study for the best time scale capture ability
To further demonstrate the RF size capture ability, we will give a case study that compares the class
activation map (Zhou et al., 2016) of OS-CNN with that of models with the best RF size. We select
the ScreenType and InsectWingbeatSound datasets for the case study. They were selected because
they are of the largest and the smallest accuracy difference calculated by the accuracy of FCN with
RF size 10 (FCN(10)) minus accuracy of FCN with RF size 200 (FCN(200)). Specifically, it can
be seen as, among UCR 85 datasets, the ScreenType is the dataset which the FCN(10) outperform
FCN(200) most, and InsectWingbeatSound is the dataset which the FCN(200) outperforms FCN(10)
most. We visualize the class activation map of the first instance in the two datasets, and the results
are shown in Figure 6. As we can see in Figure 6, the class activation map of the OS-block is similar
to that of the model with the best RF size.
5	Related works
A TS data is a series of data points. TSC aims at labeling unseen TS data via a model trained by
labeled data (Dau et al., 2018; Chen et al., 2015). One well-known challenge for TSC is telling the
model in What time scale to extract features (Hills et al., 2014; Schafer, 2015; Berndt & Clifford,
1994). This is because TS data is naturally composed of multiple signals on different scales (Hills
et al., 2014; Schafer, 2015; Dau et al., 2018) but, without prior knowledge, it is hard to find those
scales directly.
The success of deep learning encourages researchers to explore its application on TS data (LangkviSt
et al., 2014; Fawaz et al., 2019; Dong et al., 2021). The Recurrent Neural Network (RNN) is de-
signed for temporal sequence. In general, it does not need extra hyper-parameters to identify infor-
mation extraction scales. However, RNN is rarely applied on TS classification (Fawaz et al., 2019).
There are many reasons for this situation. One widely accepted reason is that when faced with long
TS data, RNN models suffer from vanishing gradient and exploding gradient (Pascanu et al., 2013;
Fawaz et al., 2019; Bengio et al., 1994).
Nowadays, the most popular deep-learning method for TSC is 1D-CNN. However, for 1D-CNNs,
the feature extraction scale is still a problem. For example, there is an unresolved challenge with
8
Published as a conference paper at ICLR 2022
kernel size selection where there exists different approaches but non consensus on which is best.
To date, the selection of feature extraction scales for 1D-CNN is regarded as a hyper-parameter
selection problem e.g., (Cui et al., 2016) uses a grid search to find kernel sizes, while the following
methods tune it empirically (Zheng et al., 2014; Wang et al., 2017; Rajpurkar et al., 2017; Serra
et al., 2018; Ismail Fawaz et al., 2019; Kashiparekh et al., 2019).
Dilated convolution (Oord et al., 2016) is widely adopted in 1D-CNN to improve generalization
ability for TS tasks (Oord et al., 2016; Zhang et al., 2020; Li et al., 2021). It takes a lower sampling
frequency than the raw signal input thus can be viewed as a structure-based low bandpass filter.
Compared with the OS-block, the dilated convolution also needs prior knowledge or searching work
to set the dilation size which will determine the threshold to filter out redundant information from
TS data.
Inception structure (Szegedy et al., 2015) is widely used in 1D-CNN for TSC tasks (Ismail Fawaz
et al., 2019; Kashiparekh et al., 2019; Chen & Shi, 2021; Dong et al., 2021). The design of the
multi-kernel structure of OS-block is inspired from the inception structure (Szegedy et al., 2015).
Compared with existing works, the OS-block has two differences. Firstly, the OS-block does not
need to assign weight to important scales via complicated methods such as pre-train (Kashiparekh
et al., 2019), attention (Chen & Shi, 2021; Shen et al., 2018b), or a series of modifications such as
bias removal and bottleneck for convolutions (Ismail Fawaz et al., 2019). Secondly, OS-block does
not need to search for candidate scales. Specifically, those methods can only assign weight to a
limited number of scales. Thus, they still need searching works to answer a series of questions. For
example, Which sequence, such as geometric or arithmetic, should be preferred? What’s the largest
length to stop? How do they select the depth of the neural network? And how do they select the
common difference or ratio for their sequence?
Adaptive receptive field (Han et al., 2018; Tabernik et al., 2020; Xiong et al., 2020; Pintea et al.,
2021; Liu et al., 2021; Tomen et al., 2021; Dong et al., 2021), has been proposed to learn the optimal
kernel sizes during the training stage. Generally, it can be viewed as learning a weight mask on
kernels to control the receptive field size. The weight of the mask can be learned during the training
step. On the other hand, OS-block learns the linkage between kernels and uses kernels of different
sizes to compose different receptive field sizes. In principle, the adaptive receptive field can be used
on the time series classification tasks. It improves the performance by enabling 1D-CNNs to have
the best receptive field size. But the OS-block targets at covering all sizes of receptive filed sizes
and assign large weight on important sizes.
Mathematically, OS-block is a very general technique and can be extended to time series vision tasks
by using the prime size design on the time dimension. This is because the video classification task
and time series classification task share the same challenge (Xie et al., 2018; Bian et al., 2017; Tan
et al., 2021; Liu et al., 2020; Li et al., 2020), which is the same region of interest might of different
time scales for different data. Thus, using the kernel of various sizes will increase the probability to
catch proper scales. However, in this paper, we mainly target the classic 1D time series classification,
which is an active research area with many open problems (Fawaz et al., 2019; Zhang et al., 2020;
Dempster et al., 2020) unsolven.
6	Conclusion
The paper presents a simple 1D-CNN block, namely OS-block. It does not need any feature extrac-
tion scale tuning and can achieve a similar performance as models with the best feature extraction
scales. The key idea is using prime number design to cover all RF sizes in an efficient manner. We
conduct experiments to demonstrate that the OS-block can robustly capture the best time scale on
datasets from multiple domains. Due to the strong scale capture ability, it achieves a series SOTA
performance on multiple TSC benchmarks. Besides that, the OS-CNN results reveal two charac-
teristics of 1D-CNN models, which will benefit the development of the domain. In the future, we
could extend our work in the following aspects. Firstly, other than the prime kernel size design,
there might be a more efficient design to cover all RF sizes. Secondly, the OS-block can work with
existing deep neural structures to achieve better performance, but there might be unique structures
or variants of those existing structures that are more suitable for the OS-block. Besides that, char-
acteristics of OS-block are empirically analyzed via the way there must be a theoretical explanation
of the characteristics.
9
Published as a conference paper at ICLR 2022
References
Andre Araujo, Wade Norris, and Jack Sim. Computing receptive fields of convolutional neural
networks. Distill, 4(11):e21, 2019.
Anthony Bagnall, Hoang Anh Dau, Jason Lines, Michael Flynn, James Large, Aaron Bostrom, Paul
Southam, and Eamonn Keogh. The uea multivariate time series classification archive, 2018. arXiv
preprint arXiv:1811.00075, 2018.
Yoshua Bengio, Patrice Simard, and Paolo Frasconi. Learning long-term dependencies with gradient
descent is difficult. IEEE transactions on neural networks, 5(2):157-166, 1994.
Donald J Berndt and James Clifford. Using dynamic time warping to find patterns in time series. In
KDD workshop, volume 10, pp. 359-370. Seattle, WA, 1994.
Yunlong Bian, Chuang Gan, Xiao Liu, Fu Li, Xiang Long, Yandong Li, Heng Qi, Jie Zhou, Shilei
Wen, and Yuanqing Lin. Revisiting the effectiveness of off-the-shelf temporal modeling ap-
proaches for large-scale video classification. arXiv preprint arXiv:1708.03805, 2017.
Wei Chen and Ke Shi. Multi-scale attention convolutional neural network for time series classifica-
tion. Neural Networks, 136:126-140, 2021.
Yanping Chen, Eamonn Keogh, Bing Hu, Nurjahan Begum, Anthony Bagnall, Abdullah Mueen,
and Gustavo Batista. The ucr time series classification archive, July 2015. www.cs.ucr.edu/
~eamonn/time_series_data/.
Zhicheng Cui, Wenlin Chen, and Yixin Chen. Multi-scale convolutional neural networks for time
series classification. arXiv:1603.06995, 2016.
Hoang Anh Dau, Anthony Bagnall, Kaveh Kamgar, and et.al. The ucr time series archive.
arXiv:1810.07758, 2018.
Angus Dempster, Francois Petitjean, and Geoffrey I Webb. Rocket: Exceptionally fast and accu-
rate time series classification using random convolutional kernels. Data Mining and Knowledge
Discovery, pp. 1-42, 2020.
Xuanyi Dong, David Kedziora, Katarzyna Musial, and Bogdan Gabrys. Automated deep learning:
Neural architecture search is not the end. arXiv preprint arXiv:2112.09245, 2021.
Hassan Ismail Fawaz, Germain Forestier, Jonathan Weber, Lhassane Idoumghar, and Pierre-Alain
Muller. Deep learning for time series classification: a review. Data Mining and Knowledge
Discovery, 33(4):917-963, 2019.
Peipei Gu, Ting Wu, Mingyang Zou, Yijie Pan, Jiayang Guo, Jianbing Xiahou, Xueping Peng,
Hailong Li, Junxia Ma, and Ling Zhang. Multi-head self-attention model for classification of
temporal lobe epilepsy subtypes. Frontiers in Physiology, 11:1478, 2020.
A. Hameurlain, J. Keung, R. Wagner, S. Madria, and T. Hara. Transactions on Large-Scale
Data- and Knowledge-Centered Systems XXXII: Special Issue on Big Data Analytics and Knowl-
edge Discovery. Transactions on Large-Scale Data- and Knowledge-Centered Systems. Springer
Berlin Heidelberg, 2017. ISBN 9783662556092. URL https://books.google.com.au/
books?id=RF5HzQEACAAJ.
Shizhong Han, Zibo Meng, Zhiyuan Li, James O’Reilly, Jie Cai, Xiaofeng Wang, and Yan Tong.
Optimizing filter size in convolutional neural networks for facial action unit recognition. In Pro-
ceedings of the IEEE conference on computer vision and pattern recognition, pp. 5070-5078,
2018.
Jon Hills, Jason Lines, Edgaras Baranauskas, James Mapp, and Anthony Bagnall. Classification of
time series by shapelet transformation. Data Mining and Knowledge Discovery, 28(4):851-881,
2014.
Hassan Ismail Fawaz, Benjamin Lucas, Germain Forestier, Charlotte Pelletier, Daniel F. Schmidt,
Jonathan Weber, Geoffrey I. Webb, and et.al. InceptionTime: Finding AlexNet for Time Series
Classification. arXiv e-prints, art. arXiv:1909.04939, Sep 2019.
10
Published as a conference paper at ICLR 2022
Fazle Karim, Somshubra Majumdar, Houshang Darabi, and Samuel Harford. Multivariate lstm-fcns
for time series classification. Neural Networks, 116:237-245, 2019.
Kathan Kashiparekh, Jyoti Narwariya, Pankaj Malhotra, Lovekesh Vig, and Gautam Shroff.
Convtimenet: A pre-trained deep convolutional neural network for time series classification.
arXiv:1904.12546, 2019.
Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint
arXiv:1412.6980, 2014.
Martin Langkvist, Lars Karlsson, and Amy Loutfi. A review of unsupervised feature learning and
deep learning for time-series modeling. Pattern Recognition Letters, 42:11-24, 2014.
Guozhong Li, Byron Choi, Jianliang Xu, Sourav S Bhowmick, Kwok-Pan Chun, and Grace LH
Wong. Shapenet: A shapelet-neural network approach for multivariate time series classification.
In Proceedings of the AAAI Conference on Artificial Intelligence, pp. 8375-8383, 2021.
Xianhang Li, Yali Wang, Zhipeng Zhou, and Yu Qiao. Smallbignet: Integrating core and contextual
views for video classification. In Proceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition, pp. 1092-1101, 2020.
Jason Lines, Luke M Davis, Jon Hills, and Anthony Bagnall. A shapelet transform for time series
classification. In ACM SIGKDD, pp. 289-297. ACM, 2012.
Jason Lines, Sarah Taylor, and Anthony Bagnall. Hive-cote: The hierarchical vote collective of
transformation-based ensembles for time series classification. In 2016 IEEE 16th international
conference on data mining (ICDM), pp. 1041-1046. IEEE, 2016.
Lu Liu, Tianyi Zhou, Guodong Long, Jing Jiang, and Chengqi Zhang. Attribute propagation network
for graph zero-shot learning. In Proceedings of the AAAI Conference on Artificial Intelligence,
volume 34, pp. 4868-4875, 2020.
Lu Liu, Tianyi Zhou, Guodong Long, Jing Jiang, Xuanyi Dong, and Chengqi Zhang. Isometric
propagation network for generalized zero-shot learning. arXiv preprint arXiv:2102.02038, 2021.
Benjamin Lucas, Ahmed Shifaz, Charlotte Pelletier, Lachlan O’Neill, Nayyar Zaidi, Bart Goethals,
Francois Petitjean, and Geoffrey I Webb. Proximity forest: an effective and scalable distance-
based classifier for time series. Data Mining and Knowledge Discovery, 33(3):607-635, 2019.
Wenjie Luo, Yujia Li, Raquel Urtasun, and Richard Zemel. Understanding the effective receptive
field in deep convolutional neural networks. In Proceedings of the 30th International Conference
on Neural Information Processing Systems, pp. 4905-4913, 2016.
Aaron van den Oord, Sander Dieleman, Heiga Zen, Karen Simonyan, Oriol Vinyals, Alex Graves,
Nal Kalchbrenner, Andrew Senior, and Koray Kavukcuoglu. Wavenet: A generative model for
raw audio. arXiv preprint arXiv:1609.03499, 2016.
Razvan Pascanu, Tomas Mikolov, and Yoshua Bengio. On the difficulty of training recurrent neural
networks. In International conference on machine learning, pp. 1310-1318, 2013.
Silvia L Pintea, Nergis Tomen, Stanley F Goes, Marco Loog, and Jan C van Gemert. Res-
olution learning in deep convolutional networks using scale-space theory. arXiv preprint
arXiv:2106.03412, 2021.
Pranav Rajpurkar, Awni Y Hannun, Masoumeh Haghpanahi, Codie Bourn, and Andrew Y Ng.
Cardiologist-level arrhythmia detection with convolutional neural networks. arXiv:1707.01836,
2017.
Jorg Richstein. Verifying the goldbach conjecture up to 4∕cdot104. Mathematics of computation,
70(236):1745-1749, 2001.
Patrick Schafer. The boss is concerned with time series classification in the presence of noise. Data
Mining and Knowledge Discovery, 29(6):1505-1530, 2015.
11
Published as a conference paper at ICLR 2022
Patrick Schafer and Ulf Leser. Multivariate time series classification with weasel+ muse. arXiv
preprint arXiv:1711.11343, 2017.
Joan Serra, Santiago Pascual, and Alexandros Karatzoglou. Towards a universal neural network
encoder for time series. In CCIA,pp. 120-129, 2018.
Tao Shen, Tianyi Zhou, Guodong Long, Jing Jiang, Shirui Pan, and Chengqi Zhang. Disan: Di-
rectional self-attention network for rnn/cnn-free language understanding. In Proceedings of the
AAAI conference on artificial intelligence, volume 32, 2018a.
Tao Shen, Tianyi Zhou, Guodong Long, Jing Jiang, and Chengqi Zhang. Bi-directional block self-
attention for fast and memory-efficient sequence modeling. arXiv preprint arXiv:1804.00857,
2018b.
Ahmed Shifaz, Charlotte Pelletier, Francois Petitjean, and Geoffrey I Webb. Ts-chief: A scalable and
accurate forest algorithm for time series classification. Data Mining and Knowledge Discovery,
pp. 1-34, 2020.
Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov, Du-
mitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich. Going deeper with convolutions. In
Proceedings of the IEEE CVPR, pp. 1-9, 2015.
Domen Tabernik, Matej Kristan, and Ales Leonardis. Spatially-adaptive filter units for compact and
efficient deep neural networks. International Journal of Computer Vision, 128(8):2049-2067,
2020.
Yue Tan, Guodong Long, Lu Liu, Tianyi Zhou, Qinghua Lu, Jing Jiang, and Chengqi
Zhang. Fedproto: Federated prototype learning over heterogeneous devices. arXiv preprint
arXiv:2105.00243, 2021.
Nergis Tomen, Silvia-Laura Pintea, and Jan Van Gemert. Deep continuous networks. In Interna-
tional Conference on Machine Learning, pp. 10324-10335. PMLR, 2021.
Zhiguang Wang, Weizhong Yan, and Tim Oates. Time series classification from scratch with deep
neural networks: A strong baseline. In 2017 international joint conference on neural networks,
pp. 1578-1585. IEEE, 2017.
Saining Xie, Chen Sun, Jonathan Huang, Zhuowen Tu, and Kevin Murphy. Rethinking spatiotem-
poral feature learning: Speed-accuracy trade-offs in video classification. In Proceedings of the
European conference on computer vision (ECCV), pp. 305-321, 2018.
Zhitong Xiong, Yuan Yuan, Nianhui Guo, and Qi Wang. Variational context-deformable convnets
for indoor scene parsing. In Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition, pp. 3992-4002, 2020.
Xuchao Zhang, Yifeng Gao, Jessica Lin, and Chang-Tien Lu. Tapnet: Multivariate time series
classification with attentional prototypical network. In AAAI, pp. 6845-6852, 2020.
Yi Zheng, Qi Liu, Enhong Chen, Yong Ge, and J Leon Zhao. Time series classification using
multi-channels deep convolutional neural networks. In International Conference on Web-Age
Information Management, pp. 298-310. Springer, 2014.
Bolei Zhou, Aditya Khosla, Agata Lapedriza, Aude Oliva, and Antonio Torralba. Learning deep
features for discriminative localization. In Proceedings of the IEEE CVPR, pp. 2921-2929, 2016.
12
Published as a conference paper at ICLR 2022
A APPENDIX
A.1 Statistic of the comparison (fix model size)
More statistic results of the result in Figure 5 is shown in Figure 7, Figure 8 and Figure 9
Count of datasets by the RF tuning's percentile range that OS result belongs to
40 (47.06%)
9 (10.59%)
3 (3.53%) 2(2.35%)	2 (2.35%)	3(3.53%)	3(3.53%)	](1.18%)
< 0.5	0.55	0.6	0.65	0-7	0.75	0.6	0.65	0.9	0.95	1-0+
Percentlle range
Figure 7: The histogram statics the count of datasets by which percentile range of the blue line that
the orange point belongs to. specifically, we could see that for more than 56% datasets (8+40 out of
85 datasets), the result of os-block is larger than 0.95 percentile. This means that, for an unknown
dataset, using os-block will have more than 56% chance to achieve a better result than grid search
from 20 candidate scales. When seeing the count of the number larger than 0.5 percentile, we could
see that, for an unknown dataset, using os-block will have more than 96% chance to achieve a better
result than selecting a random scale.
NN›so¾8e
Dataset sorted by： ma×(acc range)- acc of OS-CNN
■vβue∙l Uue
:pauoɔəu =InOXUQeɪd -oE-XaJd
一<XJB q ∏ aι msaoβ>eMn
SaDeE=3-pθw
N®Plo
⅛≡wu
ZXJeq-IaJmSaOaAeMn
SEXUOUASEOM
AXJeq-IaJmSaeaAeMn
X4®Plo
=OS=O
UoHɔn ρβy az-s EO4O□
=VSadeqS
jəəm
WUxUeoɪda-pp-w
,IaJeM
9UUJUO¼L
30。
SUJatlBdom
aɔeu
au≈d
few
0EOU.
^⅛sυMBXls
OOZ吊
SwOUUHaEUAS
UC_£C3O
SaUUB=ddvuauHmE>5
a5SaU=U-
TaUmJnS-OqOaO≡“AUOS
M-5
TXBJ£13uUJ_B.2a>SQ>u-UON
d n OJeaBVaU =:InOXUQ-5d-Bs□
ZUo-⅛:IUaE6a$aQt
JmMPeMS
Hunsaued
ZxeJ0ql3ullJ-Bsda>s<σ>u-u0N
u OHEWaUU 8au∙E0zu
XXJeq-IaImSaeaAeM ɔ
PUnOS4oa⅛u-m43θsu-
=VB总
tiaJ-JO。SaU=4-lnosa6ulooud
O黄
peaHMaUV
-Jn≤au,E
MiXUQOVd-QEXOJd
PUBEaaj 3Mf⅞∙:l-
⅛uc4-l⅛n
tiaj-loɔəu-Hnoxuooud a-PP - W
tiNO3βu≡noXUeβq⅛ssQ
səusnopUQH
ZaUmJns-OqoaOg-4AUOS
U-BASaow
£SH
OOOSg3
MOqEAS
UaE6挑901_
=no×uαeMd0>pps
aE⅛loqd
0βΛ5yυc-υ
SlUJOM
¾≡lnso
SaU-ASaUOHE 96μJ3u
sa>∣en I
u =⅛oxuooudoE-XaJd
e!us
yæPɪumm
A-:IaHa 留
6UEaH
E-Sa一 ad£s
Sse-OOWU.SLUJOM
SJand EOU
Dataset name
Figure 8:	The red line is the accuracy range obtained via subtracting the accuracy of OS-CNN from
the accuracy range of FCN with various kernels. We sorted those datasets in ascending order. We
could see that for most of the datasets, the highest value of the FCN accuracy range is lower than
the accuracy of OS-CNN. Which supports the OS-block has the ability to capture the best scales.
Dataset sorted by： Max(accuracy range卜 accuracy of OS-CNN and dataset type
Image-OUt:ll ne
MOtIOn_Sensors
Se nsor_ Readings
Synthetic
UOHUnp3>jaz -S E 0⅛-Q
Dataset name
Eu>⅞0idE5
⅞⅞w
ΞOUJpe30¼L
U-吕
-OJWOf-WWAS
SJand EoO
EeH
adʌt UaanS
sauue=dd WaqSOI=QES
⅛uca⅛π
aluauoɪd
OS 惠。3。UU
SaU->aαu OHo,Ja6μ
sa*onztlo3
⅛ω∑
UaaJ 3M0d>a
占字
<E£
BEM
s：IoqOMoa3AUOS
uβtsaow
OOOS 目
SaU->aαuHPSUJ
8ΛJny⅛rμss
jəəm
总OM
aɔe=
10。
SEatlodom
W£
XlJaqM£s
09zgm
SXeaa>H。廿
SaUUB=d⅛u aqaQ 96j3
TQ3⅛Jns:IoqOMO⅛3auo1λ∙
τxe∙JO419uUJo4-lsda>-se>u -U ON
7xe」0u 5OUJ-o4-la!a>-se>u -U ON
UoHeJ4-1UaU`sɔeuɪoɪu
PUnOSaeaq Bu -StiSC-
§>=0
≈>⅛BH
TUO-IWaEBaSaqL
aufi-un。
a®ISaU=U 一，
ZUOHWaEBaSaqL
XXJo-lq ∏ alntta□s>eMn
-<XJ e q __laj msa9a>eM ɔ
luɪu
AJJ®Plo
O-Iqnalmsa□s>eMn
eq□aln⅛ia□s>loMn
XJ®PIo
SseuOWU.SLUJOM
uæpɪɔpj 五
A-;IaHBsB
GUEaH
WUXUQmd ms_a
dn OJ ɔəBVaU=4-lnoxulo-louda-PP-W
SUUoM
JBalnSo
,JnOdaM
3⅛c Q-Sxd -BE-XBd
tiauoɔəu =⅛oxu eoɪd a-Pp-W
tjauoɔəu =⅛oxuooudott□
səu=:InOPUBH
q<2u.
S-OqUJAS
-IVSadeMS
≡⅛coiω⅞p∑
au≡d
UwPV
dn OJ ɔəBVaU=4-lnoxulo-loud-o⅛iɑ
JemqS-PSMS
Huns∞fi
一 lvsɔeu.
tiauo。SaU=⅛0sa6u≡eqd
OBoA
tjauoɔəu =⅛oxuooudoE-XaJd
sa6oE 一OU-PaW
SPJOMX⅛A
SEAUOUAS∙s0M
NNɔ-so¾&E3vm ■ aeue」Ausny
Figure 9:	sort datasets by dataset type and max accuracy range - accuracy of the os-CNN. We could
see that the best scale capture ability keeps the consistency cross different dataset types.
13
Accuracy range - accuracy of OS-CNN
Accuracy range - accuracy of OS-CNN
Dlato m SI zeReduct Ion
FIftyWords
WordSyno
Figure E Same StatiC metric as that of-∙gure 9
14
Medlcallmages
FacesUCR
PhalangesoutIInesCorrect
ShapesAlI
HandOutIInes
Proximal PhaIanxOutI IneCorrect
Car
Plane
Symbols
SwedlshLeaf
MlddlePhalan×OutllneCorrect
Flsh
Adlac
DIstaIPhaIa nxθutll neCorrect
M IddIePhaI an×0utl I n	eGroup
DlstaiphaIanxOutIIn eGroup
ProxlmaiphaIanxOutIIne
MIddIeP
Worms
FaceAII
DlstalPhalanxTW
OSULeaf
ArrowHead
ProxlmalPhalanxTW
FaceFour
Herring
BIrdChIcken
Worτns1⅛oClass


UWaveGestureLlbraryY
U WaveGestu reLlb raryAll
CrictetY
CrIctetZ
UWaveGestureLJbraryX
UWaveGestureLJbraryZ
GunRoInt
TbeSeg mentation 2
InIIneSkate
TbeSegmentatlonl
HaptIcs
OIIveOII
InsectWIngbeatSound
Nonlnvaslve Fetal ECGThora×2
ChlorIneConcentratIon
MoteStraIn
Nonlnvaslve Fetal ECGThoraxl
ECGFlveDays
SonyAlBoRobotSurfacel
Strawberry
1⅛ol⅛ttems
Coffee
T∙ace
Wafer
StarLIghtCurves
FordA
SonyAI BORo b□tSurface2
ElectrIcDevIces
ECG5000
Large Kite he nAp pl lances
FordB
ECG200
ItaIyPowerDemand
Meat
LIghtnIngZ
Phoneme
Earthquates
Refrlgeratlo nDevlces
Wlne
Llghtnlng7
CInCKGlbrso
SmallKltchenAppIIances
Ham
Beef
Computers
ScreenType
SynthetIcControI
CBF
1⅛ol⅛adECG
Mallat
ShapeletSlm
Dasset SOrted by： Max(accuracy rangeT accuracy Ofo5-CNN and dataser type
Figure l-∙SanIe StariC metric as rhsOf Figure 8

---magelou≡ne
--Motonlsensors
--SenSoΓRead-ngs
SyntheHC
DlatomsizeReductlon
RftyWords
CrictetX
UWaveGestureLIbraryY
UWaveGesture LI braryAII
WordSynonyms
OIIveOII
CrictetY
CricIstZ
U WaveGestu reLlbrary×
U WaveGestu reLibra ryZ
InsectWIngbeatSound
Ifoga
Medlcallmages
FacesUCR
PhalangesoutIInesCorrect
ShapesAII
N on InvaslveFetal ECCTho rax 2
Chlorl neQ>nceπtratlon
MoteStraIn
NonlnvaslveFetalECGThoraxl
HandOutIInes
GunPoInt
ECGFIveDays
SynthetlcControl
SonyAlBoRobotSurfacel
ProxlmaiphalanxoutIIneCorrect
Strawberry
CBF
Car
Coffee
TVace
1⅛oPattems
Plane
TtaoLeadECG
Wafer
StarU
Tbe Seg mentation 2
SwedIshLeaf
ElectricDevIces
Hsh
ECG5000
Mallat
Adlac
LargeKl IchenAppIIances
InIIneSkate
TbeSegmentatIonl
DlstaiphalanxoutIIneConect
MlddlephalanxOutllneAgeGrouD
FordB
DlstaiphalanxOutIIneAgeGrDup
ECG200
Proximal PhaIanxOutI IneAgeGroup
MIddIePhaIanxTW
ItalyPowerDemand
Worms
Meat
FaceAII
Distal
OSUL⅛af
ArrowHead
Phoneme
ProxlmalPhalanxTW
f⅛ceFour
Earthquates
Refrl aeration Devices
Wlne
Llghtnlng7
CInCECGTbrso
HaptIcs
Herring
SmallKltchenAppIIances
Ham
Beef
Computers
BIrdChIcten
ScreenTVpe
WOrTrSI⅛oC Cass
BeetIeFIy
ShapeIetSIm
Datasetsorted by Max(accuracy range)，accuracy⅞os-CNN
Accuracy

Figure 10《SanIe Srsic metric as rhsof-∙gure 5 and Figure 7
S
3
Gunrolnt
ECGFIveDays
SynthetIcControI
CBF
TVace
Coffee
Plane
TWoPattems
TWoLeadECG
Wafer
Flsh
SonyAJBORobotSu rfacel
Strawberry
DlatomsizeReductIon
StarLIghtCurves
SwedlshLeaf
Symbols
Mallat
Meat
FacesUCR
SonyAJBORobotSu rface2
NonlnvaslveFetalECCThoraxl
Non Invasive Fetal ECCThora×2
IbeSegmentatIonl
f⅛ceFour
TbeSeg mentation 2
FordA
HandOutIInes
Italy Rowe rDe maπd
OSULeaf
UWaveGestureLl braryAl I
ECG5000
MoteStraIn
Car
ShapesAll
ECG200
,foga
BIrdChIcken
ProxlmaiphalanxoutIIneCorrect
LargeiotchenAppIIances
CrIcketY
FaceAll
CrIcketZ
BeetleFly
CrIcketX
ChlorIneConcentratIon
Wlne
Proximal PhalanxoutIIneAgeGroup
ArrowHead
FordB
Adlac
OIIveOII
ShapeIetSIm
CInCECGlbrso
PhalangesOutIlnesCorτect
Beef
MlddlePhalan×OutIlneCoπect
UWaveGestureLIbraryX
AftyWords
LlghtnIngZ
Llghtπlng7
Worms
PrOXImaIPhaIanzrW
Medlcallmages
DlstaiphalanxOutIIneCo rτect
UWaveGestureLIbraryZ
Distal Phala π×θutll neAgeGroup
UWaveGestureLIbraryY
WordSynonyms
Computers
ElectricDevIces
SmallKltchenAppIIances
Earthquakes
Ham
WonnslWoC lass
DlstaIPhaIanxTW
Herring
InsectWI ngbeatSound
MIddIePhaIa π×0utll neAgeGroup
Screeniype
MIddIePhaIanxTW
HaptIcs
Refrlgeratl on Dev Ices
InIIneSkate
Phoneme
ACCUmCyOfoS-CNN
ACCUraCy Of mode- w-th Var-OUS RFS-Ze
ACCUraCy Of OS-CNN VS ACCUracy range Of RF SNe tunning
Published as a COnferenCe PaPer at ICLR 2022
A∙2 STATISTIC OF THE CoMPARlSoN (FlX CHANNEL NUMBER)
WheIl We keep the IIUmber Of ChamleIS COllStantiIl FCNy the StatiStiCreSUIt will be as thiThe
OS—CNN Stachieves Similar PerfonnanCe as the model With the best scale
Published as a conference paper at ICLR 2022
A.3 The cd-diagram result
The critical difference diagram shows the average rank of each method with Wilcoxon-Holm post-
hoc analysis between each series.
10	98765432
ED-lNN(norm)空∙
ED-INIM Al
DTW-INN-Knorm)
DTW-INN-I
MLSTM-FCN
PF
ResNet
STC
InceptionTime
OS-CNN
3"TapNet
二≡∙ WEASEL+MUSE
DTW-INND
DTW-lNND(norm)
Figure 13: SOTA for UEA 30 multivariate dataset archive
87654321
6.58
5.41
5.05
4.05
OS-CNN
拜土 ROCKET
TS-CHIEF
HIVE-COTE
Figure 14: SOTA on the UCR 85 datasets
ResNet
InceptionTime
OS-CNN
ROCKET
Figure 15: SOTA on the UCR 128 datasets
A.4 Examples of the two phenomena
In the Figure 2, the Google speechcommands dataset is selected as the dataset to show the example.
This is because, for this dataset, the relationship between performance and receptive field size is
proportional (As it is shown in Figure 16). Thus, it is easy to control variables. What’s more, in
Figure 18 and Figure 17, we show those two phenomena with more train and test split.
A.5 Extend OS-block with other structures
Layers in the OS-block and the OS-block itself are easy to extend with other complicated structures.
Figure 19 gives an explanation about the how to view the multi-kernel layers in OS-block as a single
layer, and gives an example that how to combine the layer with dilation. The Figure 4 shows that
how to view the OS-block as a layer, and gives another two examples rather than OS-CNN.
15
Published as a conference paper at ICLR 2022
0.8
0.7
u 0.6
⅛ 0.5
0.4
0.3
Receptive field size
Figure 16: The relationship between performance and receptive field size are proportional
SpeechCommands(0.2∕0.8): test acc	SpeechCommands(0.5/0.5)： test acc	SPeeChCommandS(0.8/0.2)： test acc
0.8	0.8
0∙7	0.7
0.6
0.5
0.4
0.3
O 200	400	600	800 IOOO
Epoch	Epoch	Epoch
Set of receptive field size
—{10,8.6.4.1}
—{10,8}
——{10}
——OS {10-l}
—{40,35,30,25}
—{40,35,30}
—{40,30}
——{40}
——OS {40-1}
—{100,90,80,60,50,20}
—{100,95,90,85,80,75,70}
—{100,80,60}
——{100}
——OS{100-1}
Figure 17: Lines in the figure are models with different sets of receptive field sizes. Lines with
similar colors are models which have the same best receptive field size. We could see that the best
receptive field size mainly dominates the performance in the set of receptive fieldsizes.
SPeeChCOmmandS(0.2/0.8)： test acc	SPeeChCOmmandS(0.5/0.5)： test acc	SPeeChCOmmandS(0.8/0.2)： test acc
0.80	0.80	0.80
Figure 18: The label of each line denotes the kernel configuration of each 1D-CNN. For example,
5_5_1_1_1 means the ID-CNN has five layers, and from the first layer to the last layer, kernel sizes
of each layer are 5, 5, 1, 1, and 1. Lines of similar color are 1D-CNNs with the same receptive field
size, and they are also of similar performance.
Set of receptive field size
{100}
{300}
{300,100}
The layer with mu∣tipe prime size kernels
σ 10	20	30	40	50	60	70	80
0
10
20
30
40
20
The dιalιated layer with multιpe pπme size kernels
40
60
ao
IOO
120
140
160
Ldiillllhh.
O
Figure 19:	Purple color in those images are the zero mask and yellow denotes the location where
has the ability to hold weight. Left: Convolution layers in of OS-block can be calculated parallelly,
thus, each layer can be viewed as one convolutional layer with zero masks.(s) Right: layers in the
OS-block can work with the dilation design
16
Published as a conference paper at ICLR 2022
A.6 Experiment result of OS-block with other structures
The Figure 20 and Figure 21 show that applied OS-block with residual connection, ensemble, and
multi-channel architectures (individually or together) could further improve the performance. The
evaluation was on both UCR 85 and UEA 30 archives which contain datasets from different domains
such as electrical devices analysis, Spectrum analysis, traffic analysis, EEG analysis.
11 10	98765432	1
PF
ResNet
OS-block
STC
OS-block + residual connection
InceptionTime
OS-block + residual connection and ensemble
TS-CHIEF
ROCKET
OS-block + ensemble
HIVE-COTE
Figure 20:	Using the OS-block with residual connection and ensemble (individually or together)
could increase the performance
ED-lNN(norm)
ED-INN
DTW-INN-Knorm)
DTW-INN-I
MLSTM-FCN
DTW-lNND(norm)
OS-block + multi-channel
OS-block
WEASEL+MUSE
TapNet
DTW-INND
Figure 21: Using the multi-channel architecture with OS-block could improve the performance
A.7 Compare the OS-block with other designs
Mathematically, finding the optimal kernel configuration is challenging, for it is a constrained com-
binatorial optimization searching for the best configuration among an exponential number of can-
didates. Our contribution is a simple and effective model design that does not need to solve the
complex optimization problems and achieves state-of-the-art performance on several benchmarks.
From the model size perspective, using prime numbers is more efficient than using even numbers or
odd numbers. To be specific, to cover RF of range r, the model size complexity of using prime size
kernels is O(r2/log(r)). On the other hand, no matter we use even number pairs or odd number
pairs, kernel sizes in each layer, the model size complexity of using the sequence is O(r2). As
Table 2 shows, compared with using odd number pairs or even numbers pairs prime numbers can
achieve similar performance in a smaller model size.
Number of parameters
Channel number	RF range	Prime numbers (OUrs)	odd numbers	even numbers
16	1 to 45	304k	507k	491k
32	1 to 45		1,203 k	2,009k	1,948k
Accuracy				
Channel number	RF range	Prime numbers (Ours)	odd numbers	even numbers
16	1 to 45	0.7524	0.7687	0.7561
32	1 to 45		0.7845	0.7783	0.7725
Table 2: Model size and performance comparison on Google SpeechCommands dataset
17