Published as a conference paper at ICLR 2022
Denoising Likelihood Score Matching
for Conditional Score-based Data Generation
Chen-Hao Chao*
National Tsing Hua University
Wei-Fang Sun
National Tsing Hua University
Bo-Wun Cheng
National Tsing Hua University
Yi-Chen Lo
Mediatek Inc.
Chia-Che Chang
Mediatek Inc.
Yu-Lun Liu
Mediatek Inc.
Yu-Lin Chang
Mediatek Inc.
Chia-Ping Chen
Mediatek Inc.
Chun-Yi Leet
National Tsing Hua University
Ab stract
Many existing conditional score-based data generation methods utilize Bayes’
theorem to decompose the gradients of a log posterior density into a mixture
of scores. These methods facilitate the training procedure of conditional score
models, as a mixture of scores can be separately estimated using a score model
and a classifier. However, our analysis indicates that the training objectives for
the classifier in these methods may lead to a serious score mismatch issue, which
corresponds to the situation that the estimated scores deviate from the true ones.
Such an issue causes the samples to be misled by the deviated scores during the
diffusion process, resulting in a degraded sampling quality. To resolve it, we
formulate a novel training objective, called Denoising Likelihood Score Matching
(DLSM) loss, for the classifier to match the gradients of the true log likelihood
density. Our experimental evidences show that the proposed method outperforms
the previous methods on both Cifar-10 and Cifar-100 benchmarks noticeably in
terms of several key evaluation metrics. We thus conclude that, by adopting DLSM,
the conditional scores can be accurately modeled, and the effect of the score
mismatch issue is alleviated.
1	Introduction
Score-based generative models are probabilistic generative models that estimate score functions, i.e.,
the gradients of the log density for some given data distribution. As described in the pioneering
work (Hyvarinen, 2005), the process of training score-based generative models is called Score
Matching (SM), in which a score-based generative model is iteratively updated to approximate the
true score function. Such a process often incurs heavy computational burdens, since the calculation
of the score-matching objective involves the explicit computation of the partial derivatives of the
score model during training. Therefore, a branch of study in this research domain (Vincent, 2011;
Song et al., 2019) resorts to reformulating the score-matching objective to reduce the training cost.
Among these works, the author in (Vincent, 2011) introduced the Denoising Score-Matching (DSM)
method. This method facilitates the training process of score-based generative models, and thus lays
the foundation for a number of subsequent researches. Recently, the authors in (Song & Ermon,
2019) proposed an unified framework based on DSM, and achieved remarkable performance on
serval real-world datasets. Their success inspired several succeeding works (Song & Ermon, 2020;
Ho et al., 2020; Song et al., 2021a;b; Dhariwal & Nichol, 2021), which together contribute to making
score-based generative models an attractive choice for contemporary image generation tasks.
A favorable aspect of score-based generative models is their flexibility to be easily extended to
conditional variants. This characteristic comes from a research direction that utilizes Bayes’ theorem
*Work done during an internship at Mediatek Inc. E-mail: lance_chao@gapp.nthu.edu.tw
^Corresponding author. E-mail: cylee@gapp.nthu.edu.tw
1
Published as a conference paper at ICLR 2022
to decompose a conditional score into a mixture of scores (Nguyen et al., 2017). Recent endeavors
followed this approach and further extended the concept of conditional score-based models to
a number of application domains, including colorization (Song et al., 2021b), inpainting (Song
et al., 2021b), and source separation (Jayaram & Thickstun, 2020). In particular, some recent
researchers (Song et al., 2021b; Dhariwal & Nichol, 2021) applied this method to the field of class-
conditional image generation tasks, and proposed the classifier-guidance method. Different from
the classifier-guidance-free method adopted by (Ho et al., 2021), they utilized a score model and
a classifier to generate the posterior scores (i.e., the gradients of the log posterior density), with
which the data samples of certain classes can be generated through the diffusion process. The authors
in (Dhariwal & Nichol, 2021) showed that the classifier guidance method is able to achieve improved
performance on large image generation benchmarks. In spite of their success, our analysis indicates
that the conditional generation methods utilizing a score model and a classifier may suffer from a
score mismatch issue, which is the situation that the estimated posterior scores deviate from the true
ones. This issue causes the samples to be guided by inaccurate scores during the diffusion process,
and may result in a degraded sampling quality consequently.
To resolve this problem, we first analyze the potential causes for the score mismatch issue through a
motivational low-dimensional example. Then, we formulate a new loss function called Denoising
Likelihood Score-Matching (DLSM) loss, and explain how it can be integrated into the current training
method. Finally, we evaluate the proposed method under various configurations, and demonstrate
its advantages in improving the sampling quality over the previous methods in terms of several
evaluation metrics.
2	Background
In this section, we introduce the essential background material for understanding the contents of
this paper. We first introduce Langevin diffusion (Roberts & Tweedie, 1996; Roberts & Rosenthal,
1998) for generating data samples X ∈ Rd of a certain dimension d from an unknown probability
density function (pdf) P(X) using the score function Vχ logp(X). Next, We describe Parzen density
estimation (Parzen, 1962) and denoising score matching (DSM) (Vincent, 2011) for approximating
Vχ logP(X) with limited data samples. Finally, we elaborate on the conditional variant of the
score function, i.e., Vx logp(X∣y), and explains how it can be decomposed into Vχ logp(X) and
Vχ log p(y∣X) for some conditional variable y ∈ Rc of dimension c.
2.1	Langevin Diffusion
Langevin diffusion (Roberts & Tweedie, 1996; Roberts & Rosenthal, 1998) can be used to generate
data samples from an unknown data distribution p(X) using only the score function Vx logp(X),
which is said to be well-defined if P(X) is everywhere non-zero and differentiable. Under the condition
that Vx logp(X) is well-defined, Langevin diffusion enables P(X) to be approximated iteratively
based on the following equation:
2
Xt = Xt-1 + ~2Vx logP(Xt-I) + ezt,	(I)
where X。is sampled from an arbitrary distribution, E is a fixed positive step size, and Zt is a noise
vector sampled from a normal distribution N(0, Id×d) for simulating a d-dimensional standard
Brownian motion. Under suitable regularity conditions, when E → 0 and T → ∞, XT is generated
as if it is directly sampled from P(X) (Roberts & Tweedie, 1996; Welling & Teh, 2011). In practice,
however, the data samples are generated with E > 0 and T < ∞, which violates the convergence
guarantee. Although it is possible to use Metropolized algorithms (Roberts & Tweedie, 1996; Roberts
& Rosenthal, 1998) to recover the convergence guarantee, we follow the assumption of the prior
work (Song & Ermon, 2019) and presume that the errors are sufficiently small to be negligible when
E is small and T is large.
The sampling process introduced in Eq. (1) can be extended to a time-inhomogeneous variant by
making P(Xt) and E dependent on t (i.e., Pt(Xt) and Et). Such a time-inhomogeneous variant is
commonly adopted by recent works on score-based generative models (Song & Ermon, 2019; Song
et al., 2021b), as it provides flexibility in controlling Pt(Xt) and Et. The experimental results in (Song
& Ermon, 2019; Song et al., 2021b) demonstrated that such a time-inhomogeneous sampling process
2
Published as a conference paper at ICLR 2022
can improve the sampling quality on real-world datasets. In Appendix A.6.1, we offer a discussion
on the detailed implementation of such a time-inhomogeneous sampling process in this work.
2.2	Parzen Density Estimation
Given a true data distribution Pdata, the empirical data distribution P0 (X) is constructed by sampling
m independent and identically distributed data points {X(i)}im=1, and can be represented as a sum of
Dirac functions ml Pm=I δ(∣∣x — x(i)k). SUch a discrete data distribution po(x) constructed from
the dataset often violates the previous assumptions that everywhere is non-zero and is differentiable.
Therefore, it is necessary to somehow adjust the empirical data distribution P0(X) before applying
Langevin diffusion in such cases.
To deal with the above issue, a previous literature (Vincent, 2011) utilized Parzen density es-
timation to replace the Dirac functions with isotropic Gaussian smoothing kernels p(X∣x) =
(2∏)1∕2σd e2σ2 kx-xk with variance σ2. Specifically, Parzen density estimation enables the calcula-
tion of Pσ(X) = m1 Pm=IPσ(X∣χ(i)). When σ > 0, the score function becomes well-defined and
can thus be represented as the following:
Vx logPσ (X)
Pm=I σ12 (X⑺-X)Pσ (XIxei))
Pm=lPσ (X|x(i))
(2)
The proof for Eq. (2) is provided in Appendix A.2. This equation can be directly applied to Eq. (1) to
generate samples with Langevin diffusion. Unfortunately, this requires summation over all m data
points during every iteration, preventing it from scaling to large datasets due to the rapid growth in
computational complexity.
2.3	Denoising Score Matching
Score matching (SM) (Hyvarinen, 2005) was proposed to estimate the score function with a model
s(X; φ), parameterized by φ. Given a trained score model s(X; φ), the scores can be generated by a
single forward pass, which reduces the computational complexity of Eq. (2) by a factor of m. To
train such a score model, a straightforward approach is to use the Explicit Score-Matching (ESM)
loss LESM, represented as:
LESM(φ) = Epσ(x) 1 l∣s(X; φ) - Vx logPσ(X)k2 .	(3)
This objective requires evaluating Eq. (2) for each training step, which also fails to scale well to
large datasets. Based on Parzen density estimation, an efficient alternative, called Denoising Score-
Matching (DSM) loss (Vincent, 2011), is proposed to efficiently calculate the equivalent loss LDSM,
expressed as:
Ldsm(Φ) = Epσ(x,x) 2l∣s(X; φ) - Vx logPσ(X∣x)k2 .	(4)
where Vx logp(X∣x) is simply σ12(x 一 X). Since the computational cost of denoising score
matching is relatively lower in comparison to other reformulation techniques (Hyvarinen, 2005; Song
et al., 2019), it is extensively adopted in recent score-based generative models (Song & Ermon, 2019;
2020; Song et al., 2021b).
2.4	Conditional Score Decomposition via Bayes’ Theorem
Score models can be extended to conditional models when conditioned on a certain label y. Similar to
X, the smoothing kernels with variance T2 can be applied on y to meet the requirement that the pdf is
everywhere non-zero. Typically, T is assumed to be sufficiently small so that PT (y) ≈ P(y). Apopular
approach adopted by researchers utilizes Bayes, theorem Pσ,τ(X∣y) = Pσ,τ(y∣X)Pσ(X)∕Pτ(y) to
decompose the conditional score Vx logPσ,τ(X|y) into a mixture of scores (Nguyen et al., 2017),
which enables conditional data generation. Following the assumptions in the previous study (Song
et al., 2021b), the decomposition can be achieved by taking the log-gradient on both sides of the
equation, expressed as follows:
Vx log Pσ,τ (X∣y) = Vx log Pσ,τ(y∣X) + Vx log P (X) — Vx log Pτ (y),	...
'----{z-----}	(5)
=0
3
Published as a conference paper at ICLR 2022
(a) Base
(b) Scaling	(c) Posterior SM	(d) Ours	(e) Oracle
Figure 1: The visualized results on the inter-twining moon dataset. The plots presented in the first two
rows correspond to the visualized vector fields for the posterior scores of the class c1 (upper crescent)
and c2 (lower crescent), respectively. The plots in the third row are the sampled points. Different
columns correspond to different experimental settings in Section 3. The detailed configurations are
presented in Appendix A.6.2.
where Nx logpσ,τ(X|y) is the posterior score, Nx logpσ,τ(y∣X) is the likelihood score, and
Vx logpσ(X) is the prior score. Base on Eq. (5), a conditional score model Nx logp(X|y； φ, θ)
can be represented as the combination of the log-gradient of a differentiable classifier p(y∣X; θ) and a
prior score model s(X; φ):
Vx log P(X |y； θ, φ) = Vx log p(y|x； θ) + s(x； φ).	⑹
This formulation enables conditional data generation using a classifier p(y∣X; θ) trained with cross-
entropy loss LCE(θ)，Epσ T(x,y)[— logp(y∣X; θ)], and a score model s(X; φ) trained with denoising
score matching loss LDSM(φ). Unfortunately, a few previous studies (Nguyen et al., 2017; Dhariwal
& Nichol, 2021) have noticed that the approximation of Vx logP(X|y； θ, φ) is empirically inaccurate
(referred to as the score mismatch issue in this work), and leveraged a scaling factor α > 0 to adjust the
likelihood score Vx logp(y∣X; θ). Such a scaling factor is a hyperparameter that empirically controls
the amount of conditional information incorporated during the sampling process (see Appendix A.3).
However, this usually causes the diversity of generated data samples to degrade noticeably (Dhariwal
& Nichol, 2021), which is later discussed in Section 5.2.
In this work, we examine and investigate the score mismatch issue from a different perspective. We
first offer a motivational example to show that the issue remains even with the scaling technique.
Then, we theoretically formulate a new loss term that enables a classifier p(y |X; θ) to produce better
likelihood score estimation.
3	Analysis on the Score Mismatch Issue
To further investigate the score mismatch issue, we first leverage a motivational experiment on the
inter-twining moon dataset to examine the extent of the discrepancy between the estimated and true
posterior scores. In this experiment, we consider five different methods to calculate the posterior
scores denoted as (a)〜(e):
•	(a) Base method. The posterior scores are estimated using a score model s(X; φ) trained
with LDSM and a classifier p(y∣X; θ) trained with LCE, as described in Eq. (6).
•	(b) Scaling method. The posterior scores are estimated in a similar fashion as method
(a) except that the scaling technique (Dhariwal & Nichol, 2021) is adopted to scale the
likelihood scores, i.e., Vx logP(X|y； θ, φ) = αVx logp(y∣X; θ) + s(X; φ), where α > 0.
•	(c) Posterior SM method. The posterior scores for different class conditions, in this case, c1
and c2, are separately estimated using different score models s(X; φ1) and s(X; φ2) trained
with LDSM . Note that, since this method requires network architectures different from
4
Published as a conference paper at ICLR 2022
Table 1: The experimental results on the inter-twining moon dataset. The quality of the sampled data
for different methods are measured in terms of the precision and recall metrics. The errors of the
score functions for different methods are measured using EU(X)[Dp(X, y)] and EU⑸[Dl(X, y)],
where U(X) is a uniform distribution over a two-dimensional subspace (i.e., the space of each subplot
in Fig. 1), y represents the classes specified in the second row of the table, and DP and DL are
defined in Eq. (7). The configurations and the hyperparameters for different experimental settings of
this experiment are presented in Appendix A.6.2.
	(a) Base		(b) Scaling		(c) Posterior SM		(d) Ours		(e) Oracle	
y	ci	c2	ci	c2	ci	c2	ci	c2	Ci	c2
SP(X,汾	Vx log p(y|x； θ) + s(x； Φ)		ɑVx logp(y∣X; θ) + s(X; φ)		S(X； φi) S(X φ2)		Vx log p(y∣χ; θ) + s(x； Φ)		Vx logPσ,τ(x∣y)	
SL(X,汾	Vx log p(y|x； θ)		αVχ logp(y∣X; θ)				Vx log p(y∣χ; θ)		Vx logPσ,τ(y∣x)	
Eu(x)[Dp(X, y)]	0.198	0.197	2.734	2.627	0.063	0.060	0.066	0.064	0.000	0.000
EU(X)[DL(X,汾]	0.190	0.181	2.730	2.618	-	-	0.052	0.052	0.000	0.000
Precision	0.94	0.93	0.95	0.94	0.97	0.97	0.96	0.95	1.00	1.00
Recall	1.00	1.00	0.97	0.97	1.00	1.00	1.00	1.00	1.00	1.00
those used in methods (a), (b), and (d), it is only adopted for analytical purposes. For more
detailed discussions about this method, please refer to Appendix A.4.
•	(d) Ours. The posterior scores are estimated in a similar fashion as method (a) except that
the classifier is trained with the proposed loss function LTotal , which is described in detail
in Section 4.
•	(e) Oracle. The oracle posterior scores are directly computed using the conditional variant
of Eq. (2), which is detailed in Appendix A.6.2.
Fig. 1 visualizes the posterior scores and the sampled points based on the five methods. It is observed
that the posterior scores estimated using methods (a) and (b) are significantly different from the true
posterior scores measured by method (e). This causes the sampled points in methods (a) and (b) to
deviate from those sampled based on method (e). On the other hand, the estimated posterior scores
and the sampled points in method (c) are relatively similar to those in method (e). The above results
therefore suggest that the score mismatch issue is severe under the cases of methods (a) and (b), but
is alleviated when method (c) is used.
In order to inspect the potential causes for the differences between the results produced by methods
(a), (b), and (c), we incorporate metrics for evaluating the sampling quality and the errors between
the scores in an quantitative manner. The sampling quality is evaluated using the precision and
recall (Kynkaanniemi et al., 2019) metrics. On the other hand, the estimation errors of the score
functions are measured by the expected values of Dp and DL, which are formulated according to the
Euclidean distances between the estimated scores and the oracle scores. The expressions of Dp and
DL are represented as the following:
Dp(x,y) = l∣Sp(x, y) - Vx logPσ,τ(x∣y)k,
Dl(x,y) = I∣Sl(x,y) - VxlogPσ,τ(y∣x)k,
(7)
where the subscripts P and L denote ‘Posterior, and ‘Likelihood,, while the terms SP(X, ry) and
Sl(X, y) correspond to the estimated posterior score and the likelihood score for a certain pair (X, y),
respectively.
Table 1 presents SP(X, y) and Sl(X, y), the expectations of DP and Dl, and the precision and
recall for different methods. It can be seen that the numerical results in Table 1 are consistent with
the observations revealed in Fig. 1, since the expectations of DP are greater in methods (a) and (b)
as compared to method (c), and the evaluated recall values in methods (a) and (b) are lower than
those in method (c). Furthermore, the results in Table 1 suggest that the possible reasons for the
disparity of the posterior scores between methods (a)〜(C) are twofold. First, adding the scaling factor
α to the likelihood scores increases the expected distance between the estimated score and oracle
score, which may exacerbate the score mismatch issue. Second, since the main difference between
methods (a)〜(C) lies in their score-matching objectives, i.e., the parameters θ in methods (a) and (b)
are optimized using LCE only while the parameters φ1 and φ2 of the score models in method (c) are
5
Published as a conference paper at ICLR 2022
optimized through LDSM, the adoption of the score-matching objective may potentially be the key
factor to the success of method (c).
The above experimental clues therefore shed light on two essential issues to be further explored and
dealt with. First, although employing a classifier trained with LCE to assist estimating the oracle
posterior score is theoretically feasible, this method may potentially lead to considerable discrepancies
in practice. This implies that the score mismatch issue stated in Section 2.4 may be the result of the
inaccurate likelihood scores produced by a classifier. Second, the comparisons between methods (a),
(b), and (c) suggest that score matching may potentially be the solution to the score mismatch issue.
Based on these hypotheses, this paper explores an alternative approach to the previous works, called
denoising likelihood score matching, which incorporates the score-matching technique when training
the classifier to enhance its capability to capture the true likelihood scores. In the next section, we
detail the theoretical derivation and the property of our method.
4	Denoising Likelihood Score Matching
In this section, we introduce the proposed denoising likelihood score-matching (DLSM) loss, a new
training objective that encourages the classifier to capture the true likelihood score. In Section 4.1,
we derive this loss function and discuss the intuitions behind it. In Section 4.2, we elaborate on
the training procedure of DLSM, and highlight the key property and implications of this training
objective.
4.1	The Derivation of the Denoising Likelihood Score Matching Loss
As discussed in Section 3, a score model trained with the score-matching objective can potentially
be beneficial in producing a better posterior score estimation. In light of this, a classifier may be
enhanced if the score-matching process is involved during its training procedure. An intuitive way to
accomplish this aim is through minimizing the explicit likelihood score-matching loss LELSM, which
is defined as the following:
Lelsm(Θ) = Epσ,τ(x,y) 2l∣Vχ logp(y∣x; θ) - Vχ logpσ,τ(y∣x)k2 .	⑻
This loss term, however, involves the calculation of the true likelihood score Vx log Pσ,τ(y |X), whose
computational cost grows with respect to the dataset size. In order to reduce the computational cost,
we follow the derivation of DSM as well as Bayes’ theorem, and formulate an alternative objective
called DLSM loss (LDLSM):
LDLSM(θ) = Epσ,τ (x,x,y,y) | l∣Vx log p(y∣X; θ) + Vx log Pσ (X)-Vx log Pσ (x∣x)k2 .⑼
Theorem 1. LDLSM (θ) = LELSM (θ) + C, where C is a constant with respect to θ.
The proof of this theorem is provided in Appendix A.5. Theorem 1 suggests that optimizing θ
with LELSM (θ) is equivalent to optimizing θ with LDLSM (θ). In contrast to LELSM, LDLSM can be
approximated in a computationally feasible fashion. This is because Vx logp(X) can be estimated
using a score model s(X; φ) trained with Ldsm, and Vx logp(X|x) = σ2 (X 一 X) as described
in Section 2.3. As Vx logp(X) and Vx logp(X|x) can be computed in a tractable manner, the
classifier can be updated by minimizing the approximated variant of LDLSM , defined as:
LDLSMo(θ)= Epσ,τ (x,x,y,y) 1 l∣Vx log p(y∣X; θ) + s(X; φ) - Vx log Pσ (X∣X)k2 .	(10)
The underlying intuition of LDLSM and LDLSM0 is to match the likelihood score via matching the
posterior score. More specifically, the sum of the first two terms Vx logp(y∣X; θ) and Vx logpσ(X)
in LDLSM should ideally construct the posterior score (i.e., Eq. (5)). By following the posterior score,
the perturbed data sample X should move towards the clean sample x, since Vx logpσ (X|x) is equal
to the weighted difference σ⅛ (X - X) (i.e., Eq. (4)). In the next section, we discuss the training
procedure with LDLSM0 as well as the property of it.
6
Published as a conference paper at ICLR 2022
Figure 2: The training procedure of the proposed methodology.
4.2	The Approximated DLSM Objective in the Classifier Training Process
Following the theoretical derivation in Section 4.1, we next discuss the practical aspects during train-
ing, and propose to train the classifier by jointly minimizing the approximated denoising likelihood
score-matching loss LDLSM0 and the cross-entropy loss LCE . In practice, the total training objective
of the classifier can be written as follows:
LTotal(θ) = LDLSM0 (θ) + λLCE (θ),	(11)
where λ > 0 is a balancing coefficient. According to Theorem 1, employing LDLSM0 allows the
gradients of the classifier to estimate the likelihood scores. However, since the computation of the
term LDLSMO requires the approximation of Vx logpσ (X) from a score model s(X; φ), the training
process that utilizes LDLSM0 alone is undesirable due to its instability on real-world datasets. To
reinforce the stability of it, an additional cross-entropy loss LCE is adopted during the training process
of the classifier. The advantage of LCE is that it leverages the ground truth labels to assist the classifier
to learn to match the true likelihood density pσ,τ (y|X), which in turn helps the score estimation
to be improved. To validate the above advantage, an ablation analysis are offered in Section 5.3
to demonstrate the differences between the classifiers trained with LTotal, LCE, and LDLSM0 . The
analysis reveals that LTotal does provide the best score-matching results while maintaining the
stability.
Fig. 2 depicts a two-stage training procedure adopted in this work. In stage 1, a score model s(X; φ) is
updated using LDSM to match Vx logpσ (X) (i.e., Eq. (4)). In stage 2, the weights of the trained score
model are fixed, and a classifier p(y∣X; θ) is updated using LTOtal. After these two training stages,
s(X; φ) and Vx logp(y∣X; θ) can then be added together based on Eq. (6) to perform conditional
sampling.
5	Experiments
In this section, we present experiments to validate the effectiveness of the proposed method. First, we
provide the experimental configurations and describe the baseline methods. Next, we evaluate the
proposed method quantitatively against the baselines, and demonstrate its improved performance on
the Cifar-10 and Cifar-100 datasets. Lastly, we offer an ablation analysis to inspect the impacts of
LCE and LDLSM0 in LTotal .
5.1	Experimental Setups
In this work, we quantitatively compare the base method, scaling method, and our method (i.e., (a),
(b), and (d) in Section 3) on the Cifar-10 and Cifar-100 datasets, which contain real-world RGB
images with 10 and 100 categories of objects, respectively. For both of the datasets, the image size
is 32×32×3, and the pixel values in an image are first rescaled to [-1, 1] before training. For the
sampling algorithm, we adopt the predictor-corrector (PC) sampler described in (Song et al., 2021b)
with the sampling steps set to T =1,000. The score model architecture is exactly the same as the one
used in (Song et al., 2021b), while the architecture of the classifier is based on ResNet (He et al.,
2016) with a conditional branch for encoding the information of the standard deviation σ (Song et al.,
2021b). When training the classifier, τ is assumed to be sufficiently small, thus the unperturbed labels
y are adopted. Furthermore, the balancing coefficient λ is set to 1 for the Cifar-10 and Cifar-100
datasets, and 0.125 for the motivational example. For more details about our implementation and
additional experimental results, please refer to Appendix A.6 and Appendix A.7.
7
Published as a conference paper at ICLR 2022
Base
SCaHng
I 矗 It 蝴q∣2
Table 2: The evaluation results on the Cifar-10 and Cifar-100
datasets. The P/R/D /C metrics with ‘(CW)’ in the last four
rows represents the average class-wise metrics described in
Section 5.2. The arrow symbols ↑ / ] represent that a higher
/ lower evaluation result correspond to a better performance.
		Base	Cifar-10 Scaling	Ours	Base	Cifar-100 Scaling	Ours
FID	J	4.10	^^12.48	2.25	4.52	12.58	3.86
IS	↑	9.08	9.37	9.90	11.53	11.59	11.62
Precision	↑	0.67	-0T75-	0.65	0.62	0.65	0.61
Recall	↑	0.61	0.49	0.62	0.62	0.52	0.63
Density	↑	1.05	1.36	0.96	0.84	0.93	0.82
Coverage	↑	0.80	0.75	0.81	0.71	0.61	0.71
CAS	ɪ	0.38	-046-	0.58	0.15	0.24	0.28
(CW) Precision	↑	0.51	-070-	0.56	0.33	0.59	0.42
(CW) Recall	↑	0.59	0.42	0.61	0.68	0.41	0.68
(CW) Density	↑	0.63	1.23	0.76	0.30	0.78	0.43
(CW) Coverage	↑	0.60	0.66	0.71	0.38	0.51	0.52
HSSΞΞΞ
Figure 3: A comparison of the
curated samples generated via
the base method and the scaling
method. As for the uncurated visu-
alized samples, please refer to Ap-
pendix A.7.4.

5.2	Results on Cifar- 1 0 and Cifar- 1 00
In this section, we examine the effectiveness of the base method, the scaling method, and our proposed
method on the Cifar-10 and Cifar-100 benchmarks with several key evaluation metrics. We adopt the
Inception Score (IS) (Barratt & Sharma, 2018) and the Frechet Inception Distance (FID) (Heusel et al.,
2017) as the metrics for evaluating the overall sampling quality by comparing the similarity between
the distributions of the generated images and the real images. We also evaluate the methods using the
Precision (P), Recall (R) (Kynkaanniemi et al., 2019), Density (D), and Coverage (C) (Naeem et al.,
2020) metrics to further examine the fidelity and diversity of the generated images. In addition, we
report the Classification Accuracy Score (CAS) (Ravuri & Vinyals, 2019) to measure if the generated
samples bear representative class information. Given a dataset containing mi images for each class i,
we first conditionally generate the same number of images (i.e., mi) for each class. The FID, IS, P / R
/D / C, and CAS metrics are then evaluated based on all the generated m = Pic=1 mi images, where
c is the total number of classes. In other words, the above metrics are evaluated in an unconditional
manner.
Table 2 reports the quantitative results of the above methods. It is observed that the proposed method
outperforms the other two methods with substantial margins in terms of FID and IS, indicating that
the generated samples bear closer resemblance to the real data. Meanwhile, for the P / R / D / C
metrics, the scaling method is superior to the other two methods in terms of the fidelity metrics (i.e.,
precision and density). However, this method may cause the diversity of the generated images to
degrade, as depicted in Fig. 3, resulting in significant performance drops for the diversity metrics
(i.e., the recall and the coverage metrics).
Another insight is that the base method achieves relatively better performance on the precision and
density metrics in comparison to our method. However, it fails to deliver analogous tendency on
the CAS metric. This behavior indicates that the base method may be susceptible to generating
false positive samples, since the evaluation of the P / R / D / C metrics does not involve the class
information, and thus may fail to consider samples with wrong classes. Such a phenomenon motivates
us to further introduce a set of class-wise (CW) metrics, which takes the class information into
account by evaluating the P / R / D / C metrics on a per-class basis. Specifically, the class-wise
metrics are evaluated separately for each class i with mi images. The evaluation results of these
metrics shown in Fig. 4 reveal that our method outperforms the base method for a majority of classes.
Moreover, the results of the average class-wise metrics presented in the last four rows of Table 2 also
show that our method yields a better performance as compared to the base method.
Base on these evidences, it can be concluded that the proposed method outperforms both baseline
methods in terms of FID and IS, implying that our method does possess a better ability to capture
the true data distribution. Additionally, the evaluation results on the CAS and the class-wise metrics
suggest that our method does offer a superior ability for a classifier to learn accurate class information
as compared to the base method.
8
Published as a conference paper at ICLR 2022
əouaɪəjjɪɑ əouaɪəjjɪɑ
Cifar-10
Precision	Recall
Sorted classes	Sorted classes
ecnereffiD
Cifar-100
Precision	Recall
ecnereffiD
Figure 4: The sorted differences between the proposed method and the base method evaluated on the
Cifar-10 and Cifar-100 datasets for the class-wise P / R / D / C metrics. Each colored bar in the plots
represents the differences between our method and the base method evaluated using one of the P / R /
D / C metrics for a certain class. A positive difference represents that our method outperforms the
base method for that class.
5.3	Ablation Analysis
To further investigate the characteristic of LTotal, we
perform an ablation analysis on the two components
LCE and LDLSM0 in LTotal using the inter-twinning
moon dataset, and observe the trends of (a) the score
errors 2EU(x)[Dl(X, ci)] + 2EU(X)DL(x, c2)], and
(b) the cross entropy Ep,,,(x,y)[- logp(y∣x; θ)] dur-
ing the training iterations. Metrics (a) and (b) mea-
sure the accuracies of the estimated likelihood scores
▽x logp(y |X; θ) and the estimated likelihood density
p(y∣X; θ), respectively. As depicted in Fig 5, an in-
Figure 5: The evaluation curves of (a) the
score errors and (b) the cross entropy during
the training iterations for LCE, LDLSM0, and
LTotal . The curves depict the mean and 95%
confidence interval of five times of training.
creasing trend is observed for metric (a) when the
classifier is trained with LCE alone. On the contrary,
the opposite tendency is observed for those trained
with LTotal and LDLSM0. The results thus suggest that
matching the likelihood scores implicitly through train-
ing a classifier with LCE alone leads to larger approx-
imation errors. In contrast, LDLSM0 and LTotal explic-
itly encourage the classifier to capture accurate like-
lihood scores, since they involve the score-matching
objective. On the other hand, for metric (b), the classifiers trained with LTotal and LCE yield stable
decreasing trend in comparison to that trained with LDLSM0 alone. These results suggest that in
addition to minimizing LDLSMO between Vχ logpσ,τ(y∣X) and Nx logp(y∣X; θ), the utilization of
LCE as an auxiliary objective enhances the stability during training. Based on the above observations,
the interplay of LCE and LDLSM0 synergistically achieves the best results in terms of metric (a) while
ensuring the stability of the training process. These clues thus validate the adoption of LTotal during
the training of the classifier.
6	Conclusion
In this paper, we highlighted the score mismatch issue in the existing conditional score-based
data generation methods, and theoretically derived a new denoising likelihood score-matching
(DLSM) loss, which is a training objective for the classifier to match the true likelihood score. We
have demonstrated that, by adopting the proposed DLSM loss, the likelihood scores can be better
estimated, and the negative impact of the score mismatch issue can be alleviated. Our experimental
results validated that the proposed method does offer benefits in producing higher-quality conditional
sampling results on both Cifar-10 and Cifar-100 datasets.
9
Published as a conference paper at ICLR 2022
Acknowledgments
This work was supported by the Ministry of Science and Technology (MOST) in Taiwan under grant
number MOST 111-2628-E-007-010. The authors acknowledge the financial support from MediaTek
Inc., Taiwan. The authors would also like to acknowledge the donation of the GPUs from NVIDIA
Corporation and NVIDIA AI Technology Center (NVAITC) used in this research work. The authors
thank National Center for High-Performance Computing (NCHC) for providing computational and
storage resources. Finally, the authors would also like to thank the time and effort of the annoymous
reviewers for reviewing this paper.
References
S. Barratt and R. Sharma. A note on the inception score. 2018.
P. Dhariwal and A. Nichol. Diffusion models beat GANs on image synthesis. arXiv preprint
arXiv:2105.05233, 2021.
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image
recognition. In Proc. of the Conf. on Computer Vision and Pattern Recognition (CVPR), pp.
770-778, 2016.
M. Heusel, H. Ramsauer, T. Unterthiner, B. Nessler, and S. Hochreiter. GANs trained by a two
time-scale update rule converge to a local nash equilibrium. In Proc. of Conf. on Neural Information
Processing Systems (NeurIPS), volume 30, 2017.
J. Ho, A. Jain, and P. Abbeel. Denoising diffusion probabilistic models. In Proc. of Conf. on Neural
Information Processing Systems (NeurIPS), 2020.
J. Ho, Chitwan S., W. Chan, D. Fleet, M. Norouzi, and T. Salimans. Cascaded diffusion models for
high fidelity image generation. ArXiv, abs/2106.15282, 2021.
A. Hyvarinen. Estimation of non-normalized statistical models by score matching. Journal ofMachine
Learning Research (JMLR), 6(24):695-709, 2005. URL http://jmlr.org/papers/v6/
hyvarinen05a.html.
V. Jayaram and J. Thickstun. Source separation with deep generative priors. In Proc. of the Int. Conf.
on Machine Learning (ICML), 2020.
A. Krizhevsky, G. Hinton, et al. Learning multiple layers of features from tiny images. 2009.
T. Kynkaanniemi, T. Karras, S. Laine, J. Lehtinen, and T. Aila. Improved precision and recall metric
for assessing generative models. In Proc. of Conf. on Neural Information Processing Systems
(NeurIPS), 2019.
M. F. Naeem, S. J. Oh, Y. Uh, Y. Choi, and J. Yoo. Reliable fidelity and diversity metrics for
generative models. In Proc. of the Int. Conf. on Machine Learning (ICML), 2020.
A. Nguyen, J. Clune, Y. Bengio, A. Dosovitskiy, and J. Yosinski. Plug & play generative networks:
Conditional iterative generation of images in latent space. In Proc. of the IEEE Conf. on Computer
Vision and Pattern Recognition (CVPR), pp. 4467-4477, 2017.
E. Parzen. On estimation of a probability density function and mode. In The annals of mathematical
statistics, volume 33, pp. 1065-1076. JSTOR, 1962.
S. Ravuri and O. Vinyals. Classification accuracy score for conditional generative models. In Proc.
of Conf. on Neural Information Processing Systems (NeurIPS), 2019.
G. O Roberts and J. S Rosenthal. Optimal scaling of discrete approximations to langevin diffusions.
Journal of the Royal Statistical Society: Series B (Statistical Methodology), 60(1):255-268, 1998.
G. O Roberts and R. L. Tweedie. Exponential convergence of Langevin distributions and their
discrete approximations. Bernoulli, 2(4):341 - 363, 1996. doi: bj/1178291835. URL https:
//doi.org/.
10
Published as a conference paper at ICLR 2022
J. Song, C. Meng, and S. Ermon. Denoising diffusion implicit models. In Proc. of the Int. Conf. on
Machine Learning (ICML), 2021a.
Y. Song and S. Ermon. Generative modeling by estimating gradients of the data distribution. In Proc.
of Conf. on Neural Information Processing Systems (NeurIPS), 2019.
Y. Song and S. Ermon. Improved techniques for training score-based generative models. In Proc. of
Conf. on Neural Information Processing Systems (NeurIPS), 2020.
Y. Song, S. Garg, J. Shi, and S. Ermon. Sliced score matching: A scalable approach to density and
score estimation. In Proc. of the Conf. on Uncertainty in Artificial Intelligence (UAI), pp. 204,
2019. URL http://auai.org/uai2019/proceedings/papers/204.pdf.
Y. Song, Jascha S.-D., Diederik P K., Abhishek K., Stefano E., and Ben P. Score-based generative
modeling through stochastic differential equations. In Int. Conf. on Learning Representations
(ICLR), 2021b. URL https://openreview.net/forum?id=PxTIG12RRHS.
P. Vincent. A connection between score matching and denoising autoencoders. Neural computation,
23(7):1661-1674, 2011.
M. Welling and Y. W Teh. Bayesian learning via stochastic gradient langevin dynamics. In Proc. of
the Int. Conf. on Machine Learning (ICML), pp. 681-688. Citeseer, 2011.
11
Published as a conference paper at ICLR 2022
A	Appendix
In this Appendix, we first provide the definitions for the symbols used in the main manuscript and the
Appendix in Section A.1. Next, We derive the theoretical proof for the closed form of Vχ logp (X)
in Section A.2. Then, we offer a number of discussions on the scaling technique in Section A.3, and
different conditional score-based data generation methods in Section A.4. Subsequently, We offer
the theoretical proof for Theorem 1 in Section A.5. Finally, in Sections A.6 and A.7, We provide the
detailed experimental setups and additional experimental results.
A. 1 The List of Symbols Used in the Paper
In this section, We provide the list of symbols used throughout the main manuscript and the Appendix.
These symbols are summarized in Tables A1 and A2, containing their notations as Well as their
detailed descriptions.
Symbol	Description
hu, Vi = UTV = Pi Uivi	dot (inner) product between two vectors.
kuk = √hu, ui	Euclidean norm of vector.
Id×d	identity matrix with dimension d × d.
	the step size used in Langevin Diffusion.
t ∈ {0, ..., T}	the discrete timestep used in Langevin Diffusion.
x, xt ∈ Rd	data sample with dimension d, where Xo is sampled from N (0, Id×d).
X ∈ Rd	perturbed data sample used in Denoising Score Matching.
y ∈ Rc	conditional class label with dimension c.
y ∈ Rc	perturbed class label used in Denoising Score Matching.
z : Rd	the noise vector used in Langevin Diffusion. (sampled from N (0, Id×d))	
x(i) ∈ Rd	the i-th example (input) from a dataset D.
y(i) ∈ {0, 1}c	the class label associated with X(i) for supervised learning (one-hot encoded).
D = {(x(1), y(1)),..., (x(m), y(m))}	Training set: m data-label pairs from pdata. (i.i.d. samples from Pdata)
pdata (x)	unknown true probability density function (pdf) of data samples.
po(χ) = ml Pi=1 δ(kχ -χ(i)k)	empirical pdf of data samples associated with the training set D.
Pσ (XIx) = (2∏)3σd e2σ2 kx-xk2 πσ	smoothing kernel or noise model: sampled from isotropic Gaussian
	N(X, σ2Id×d) with mean X and variance σ2 .
Pσ (X, X)= Pσ (X∣x)pθ(x)	joint pdf of perturbed data and clean data samples.
Pσ (X) = mm Pm=I Pσ (X|x(i))	Parzen density estimate based on D, obtainable by marginalizing Pσ (X, x).	
pdata(y)	unknown true pdf of data labels.
po(y) = ml Pi=I δ(ky - y(i)k)	empirical pdf of data labels associated with the training set D.
pτ(yIy) = (2π)1∕2τ ce 2τ2 ky-yk2	smoothing kernel or noise model: sampled from isotropic Gaussian N(y, τ2Ic×c) with mean y and variance τ2.
Pτ (y, y) = Pτ (y∣y)po(y)	joint pdf of perturbed labels and clean labels.
Pτ (y) = ml Pi=1 Pτ (y∣y(i))	Parzen density estimate based on D, obtainable by marginalizing Pτ (y, y).		
p0,0(X, y)	definedas ml £乙 δ(∣∣x - x(i)k)δ(∣∣y - y(i)k).
Pσ,o(χ, x, y)	equals to pσ(X∣x)p0,0(x, y).
po,τ (χ,y, y)	equals to pτ(y∣y)p0,0(x, y).
Pσ,τ (X, x, y, y)	defined as pσ (X∣x)pτ(y∣y)p0,0(x, y).
s(X; φ)	Score Model: approximated score function with parameters φ.
p(y∣X; θ)		Classifier: approximated probability function parameterized by θ.
Table A1: The list of symbols used in this paper.
12
Published as a conference paper at ICLR 2022
α ▽x logp(x∣y) ▽x logp(y∣X) ▽x logp(X)	the scaling factor. posterior score. likelihood score. prior score.
LESM(φ) LDSM(φ) LELSM (θ) LDLSM (θ) LDLSM0 (θ) LCE (θ) LTotal (θ)	Explicit Score Matching (ESM) loss for optimizing s(x; φ). Denoising Score Matching loss (DSM) for optimizing s(X; φ). Explicit Likelihood Score Matching (ELSM) loss for optimizing p(y∣X; θ). Denoising Likelihood Score Matching (DLSM) loss for optimizing p(y |X; θ). approximated Denoising Likelihood Score Matching loss for optimizing p(y∣X; θ). Cross Entropy (CE) loss for optimizing p(y∣X; θ). full loss for optimizing p(y∣X; θ).
Table A2: The list of symbols used in this paper.
A.2 A PROOF OF THE CLOSED FORM FOR Vχ logPσ(X)
In Sections 2.2 and 3, We utilized the closed form formula to calculate the true scores Vx logp(X).
To show the equivalence holds for Eq. (2), we provide a formal derivation as shown in the following
proposition.
Proposition 1. Given pσ(X) = m1 Pm=1Pσ(X|x⑴),Pσ(X|x) =(2n)1/2σd e2σ12kx-xk2, and σ > 0,
the Closedform of Vx logpσ (X) Can be represented asfollows:
Vx logPσ (X)
Pm=I σ2 (Xci) - X)Pσ (XIxCi))
Pm=lPσ (XIxCi))
Proof.
1m
Vx logPσ (X) = Vx log — XPσ (X∣X(i))
m
i=1
m1
=Vx log X Pσ (X∣X( )) + Vx log —
i=1	'----{zm}
=0
=Vx Pi=I Pσ (X|X(i))
Pm=I Pσ (X|X(i))
=Pi=I Vxp。(X|X(i))
Pm=I Pσ (X|X(i))
Pi=I Vx h(2∏⅛e-2kx-x(i)k2i
Pm=I Pσ (X|X(i))
Lm ∣^ (x(i)-x)∕σ2 -1 kx-x(i)k2]
_ Ei=I [&)dVd e2σ2k	k J
=	Pi=I Pσ (X|X(i))
=Pm=I。2 W" - X)P。团⑦⑴)
Pm=I Pσ (X|X(i))
□
A.3 A Discussion on the Impacts of the Scaling Technique
In this section, We first provide a proof to demonstrate the reason behind the non-equivalence
betWeen the scaling technique and the re-normalization of a likelihood density. Then, We present the
13
Published as a conference paper at ICLR 2022
derivation of the posterior scores based on a re-normalized likelihood density. Finally, we adopt a
low-dimensional example to explain the effect of re-normalization on a posterior density.
The authors in (Dhariwal & Nichol, 2021) leveraged a scaling factor α > 0 to adjust the likelihood
score Vχ logp(y∣x). To demonstrate the effect of such a scaling factor a, the authors claimed that
there always exists a normalizing constant Z such that OVx logp(y∣x) = Vx log 十p(y∣x)ɑ, where
十p(y∣x)α is a re-normalized likelihood density. However, such an equality only holds for specific
conditions, and is not applicable to general cases, as explained in Proposition 2.
Proposition 2. Given a constant α > 0, and a probability density function (pdf) p(y|x) that is
everywhere non-zero and differentiable, there does not exist a constant Z such that -1 p(y∣x)α is a
pdf for all x in general.
Proof. The proposition can be proved by contradiction. Assume that such a constant Z exists and
consider the following case:
α = 2,
x, y ∈ R,
f (y; μ,σ
2) = (2πσ2) -1 e -2-μ
p(y|X) = 2(χ21+ 1)((X +I)2f (y; 0, I) + (x —I)2f (y;0,1)).
Note that p(y|X) is a pdf and is everywhere non-zero and differentiable.
Since a Pdf sums to 1 (i.e., Jy 十p(y∣x)ɑdy = 1, ∀x), by utilizing the Gaussian integral and the above
assumption, the following derivation holds:
⇔Z
-1	2 2
丁e-y ) dy
yy
⇔Z
⇔Z
πy	πy
Π Zy e-2y2 dy =2Π Zy e-y2 dy
⇔Z
e-u du = ɪ j e-y dy
2∏
1
The final equation leads to a contradiction for the value of Z, which completes the proof of Proposi-
tion 2. Therefore, we concluded that there does not exist a constant Z such that 1 p(y∣x)α is a pdf
for all x in general.
To the best of our knowledge, the scaling technique still lacks a theoretical justification. However, if
Z is allowed to be a function of x rather than a constant, re-normalization of the likelihood density
becomes feasible. In other words, setting Z(x) = Jy p(y∣x)αdy enables Jy Z(X)p(y∣x)ɑdy = 1,
14
Published as a conference paper at ICLR 2022
PQIyl)
p(a5)	, Pα(剑 Ul)	■久(剑纳)
PQIy2)
Figure A1: The original and the renormalized densities under different choices of α.
where Z(X) p(y∣x)α，Pa (y∣x) is a re-normalized likelihood density. In this case, the score of the
re-normalized likelihood density can be written as,
Vx logPa(y∣x)
VxlOg (Zb p(yx)a
Vx logp(y|x)a — logZ(x)
(A1)
Vx logp(y∣x)a — Vx log Z(x)
αVx log p(y|x) — Vx logZ(x).
Given the joint density pa(x, y)，Pa(y∣x)p(x), the posterior of the re-normalized density can be
derived by Bayes, Theorem, i.e., Pα(x∣y) = Pa(y∣x)p(x)/Jx Pa(x, y)dx. Based on Eq. (5), the
posterior score of the re-normalized density can be written as:
Vx logPa(x∣y) = Vx logPa(y∣x) + Vx logp(x)
= αVx log p(y|x) — VxlogZ(x) + Vx log p(x).
(A2)
Through the above equation, conditional sampling based on the re-normalized likelihood density
becomes feasible.
To further investigate the effect of re-normalization on pa(x∣y), we provide an illustrative example
in Fig. A1. In this example, the condition y is assumed to be sampled from {y1 , y2 } with equal
probability 1/2. The original posterior densities p(x|y1) and p(x|y2) are normal distributions with
variance 2.25 centered at x = —1.5 and x = 1.5, which are plotted in orange and green, respectively.
On the other hand, the prior density p(x) ，1 p(x∣yι) + 2p(x∣y2) is plotted in blue, and the
likelihood density p(y|x) = p(x|y)p(y)/p(x) is defined according to Bayes’ theorem.
Subsequently, the re-normalized posterior densities Pa(x∣yι) andPα(x∣y2) can be constructed based
on the equation Z(X)p(yι∣x)α, Z(X)p(y2∣x)a, and Bayes, theorem. In Fig. A1, it is observed that
under the case that α = 5, the re-normalized posterior densities are more concentrated. Conversely,
when α = 0.2, the re-normalized posterior densities are much more dispersed. These results therefore
suggest that the re-normalized posterior density can be adjusted by controlling the value of α.
A.4 Conditional Score-based Data Generation Methods
As described in Section 3, methods (a), (b), and (d) utilize a classifier p(y∣X; θ) and a score model
s(x; φ) to estimate the posterior scores. In contrast, method (c) separately trains the posterior score
models s(x; φι) and s(X; φ2) for different class conditions. Although method (c) achieves better
evaluation results, it requires training score models for each possible y, which is usually considered
impractical in real-world applications. A potential solution to this problem is to train a score model
s(x, y ； φ) that can estimate the scores for the joint probability of X and y (denoted as ‘Method (c*),
in Fig. A2). This method, however, is inflexible in comparison to methods (a), (b), and (d), since any
change on the condition y could lead to re-training the joint score model s(X, y； φ). Therefore, in
this work, we only compare the performance of methods (a), (b), and (d), and consider method (c) to
be another orthogonal research direction.
15
Published as a conference paper at ICLR 2022
Methods (a), (b), (d)
Method (c)
Method (c*)
Score model
s(⅛⅛5≠)
Figure A2: An illustration for different conditional score-based data generation methods in Sec-
tion A.4.
A.5 A PROOF FOR DENOISING LIKELIHOOD SCORE MATCHING
In Section 4, We stated the equivalence between Lelsm (θ) and Ldlsm (θ) when optimizing θ. To
demonstrate how such an equivalence stands, we provide the theoretical proof as follows.
Theorem 1. Ldlsm (θ) = Lelsm (θ) + C, where C is a constant with respect to θ.
Proof. Lelsm (θ) and Ldlsm (θ) are defined as follows:
Lelsm(θ) = Epσ,τ(χ,y) 2∣∣V⅛ logp(y|x; θ) - V⅛ logpσ,τ(y∣X)k2 .
Ldlsm(θ) = Epσ,τ(X,χ,y,y) 1 IlVx logp(y∣x; θ) + Vx logpσ(X)- Vx logpσ(X∣x)∣2 .
The proof expands Lelsm (θ) and Ldlsm (θ) individually, leading to constant difference.
Lelsm(θ) = Epσ,τ(x,y) -∣∣Vx logp(y∣X; θ) - Vx logpσ,τ(y∣X)∣2
=%,τ(x,y) 1 l∣Vx logp(y∣X; θ)∣2 - F(θ) + C1, where
C1 = Epσ,τ(x,y) 1 ∣∣Vx logpσ,τ(y∣X)k2 is a constant, and
F(θ) = Epσ,τ(x,y) [(Vx logp(y∣X; θ), Vx logpσ,τ(y∣X)i]
=Epσ,τ (x,y) KVx log p(y∣X; θ), Vx log pσ,τ(X∣y) - Vx log pσ (X)i]
G(θ) - Epσ,τ(x,y) [(Vx logp(y∣X; θ), Vx logpσ(X)i], where
G(θ) = Epσ,τ(x,y) [(Vx logp(y∣X; θ), Vx logpσ,τ(X∣y)i]
=[[pσ,τ(X, y)(Vx logp(y∣X; θ), Vx logpσ,τ(X∣y)idydX
Jx Jy
=ZZ pτ(y)pσ,τ(X∣y)(Vx logp(y∣X; θ), Vxp，：`(XIy) )dydχ
JxJy	pσ,τ (x∣y)
=[[py (y)(Vx log p(y∣ 凉;θ), Vxpσ,τ(凉 ∣y)idyd 而
x J y
I ∕pτ(y)(Vx logp(y∣X; θ), Vx / p0,τ(χ∣y)pσ,τ(χ∣χ, y)dχ)dydχ
x J y	x
p [ py(y)(Vx logp(y∣X; θ), Vx / / p0,τ(x∣y)p0,τ(y∣x, y)pσ,τ(X∣x, y, y)dydXidydX
Jx Jy	Jx Jy
p ∕pτ (y)(Vx log p(y∣X; θ), / / po,τ(X∣y)po,τ(y∣X, y)Vxpσ,τ(X∣X, y, y)dydXidydX
xy	xy
16
Published as a conference paper at ICLR 2022
ULL
Pτ(y)po,τ(χ∣y)po,τ(y|x, y)pσ,τ(X∣χ, y, y)hV⅛ logp(y∣X; θ), Rx logPσ,τ(X∣χ, y, y)idydχdydx
x Jy x x
/ Pσ,τ(x, x, y, y) hVχ logp(y∣X; θ), Vx logpσ,τ(X∣χ, y, y))dydxdydx
y
[[][Pσ,τ(x, X, y, y)hVx logp(y∣X; θ), Vx logPσ,τ(x, X, y, y)idydχdydX
Jx Jy Jx Jy
x Jy Jx
/ Pσ,τ(x, x, y, y)hVx logp(y∣X; θ), Vx log(pσ(X∣χ)pτ(y∣y)p0,0(χ, y))idydχdydx
y
[[[[Pσ,τ(X, X, y, y)hVx logp(y∣X; θ), Vx logPσ(X∣x)idydxdydx
Jx Jy JxJy
Epσ,τ(x,x,y,y) KVx logp(y∣X; θ), Vx logPσ(X∣x)i], and now We expand Ldlsm(Θ):
Ldlsm(Θ) =Epσ,τ(x,x,y,y) 2∣∣Vx logp(y∣X; θ) + Vx logpσ(X) - Vx logpσ(X∣χ)k2
=Epσ,τ(x,y) 1 l∣Vx logp(y∣X; θ)k2 — Epb(x,x,y,y) KVx logp®X; θ), Vx logPσ(X∣χ)i] +
Epσ,τ(x,y) [hVx logp(y∣X; θ), Vx logPσ(X)i] + C2, where
C2 = Epb (x,x) 1 l∣Vx log Pσ (X)k2 + Epb (x,x) 1 ∣∣Vx log Pσ (X∣x)k2 —
Epb(x,x) [hVx logpσ (X), Vx logpσ (X|x))], is a constant, leading to the conclusion
LDLSM (θ) = LELSM (θ) - C1 + C2
Note that the domain of the integrals is {(X, x, y, y) : pσ,τ(X, x, y, y) = 0} by the definition of
expected value.
□
Remark. Theorem 1 also holds for the clean label y, which can be shown as follows:
Epb(x,y) 2l∣Vx logp(y∣X; θ) - Vx logpσ(y∣X)∣2
=Epb(x,x,y) 2l∣Vx logp(y∣X; θ) + Vx logp。(X) - Vx logp。(X∣x)∣2 + C.
A.6 The Detailed Experimental Configurations
In this section, we elaborate on the implementation details and the experimental setups. In Sec-
tion A.6.1, we describe the noise perturbation method and the sampling algorithm adopted in this work.
In Sections A.6.2 and A.6.3, we present the training configurations for the experiments on the inter-
twinning moon, Cifar-10, and Cifar-100 datasets. The code implementation for these experiments is
provided in the Github repository (https://github.com/chen-hao-chao/dlsm).
A.6.1 Noise Perturbation and Sampling Algorithm
Sampling Algorithm. In this work, we adopt the PC sampler (VE-SDE) identical to that in (Song
et al., 2021b), which is a time-inhomogeneous sampling algorithm. The PC sampler (VE-SDE) is
described in Algorithm 1. In Algorithm 1, a noise-conditioned score model s(X; φ, σt) is adopted,
where X is perturbed by noises sampled from Gaussian distributions using different standard devia-
tions σt. The standard deviations of the noises, denoted as σt = σmi∩ (器)亍,are determined by the
time step t in Algorithm 1. We set σmin = 0.01 for all of our experiments. On the other hand, we
set σmax = 50 for the Cifar-10 and Cifar-100 datasets, and σmax = 10 for the inter-twinning moom
dataset. As for the total time steps, the value of T is set to 1,000.
17
Published as a conference paper at ICLR 2022
Algorithm 1 The PC Sampler (VE-SDE)
1:	X = N(O,σmaxI)
2:	for t = T - 1 to 0 do
3:	/* Predictor */
4:	Z 〜N (O, I)	__________
5:	Xt — Xt + (σ2+ι — σ2) s(Xt+ι; φ,σt+ι) + ^+l+— — σ22 Z
6:	/* Corrector */
7:	z 〜N(O, I)
8:	Xt — Xt + et s(Xt; φ, σt) 一 √2etz
9:	return X。 * 1
Training with Different Standard Deviations. Since the PC sampler (VE-SDE) described in Al-
gorithm 1 requires the score model s(X; φ, σt) conditioned on different values of standard deviation
σt, the training objectives described in Eqs. (4) and (11) are modified accordingly. For the DSM loss
described in Eq. (4), the modified loss LDSM (φ) is represented as:
EU[0,T ](t) [λDSM(t)Epσt (x,x) [ks(X; φ,σt) -Vx log p°t (X∣x)∣∣2]] ,	(A3)
where U[0,T] (t) is a uniform distribution on the interval [0, T]. In Eq. (A3), The additional coefficient
λDSM(t) is multiplied with the original DSM loss for better training results (Song & Ermon, 2019).
For the approximated DLSM loss described in Eq. (9), the modified loss LDLSM0 (θ) is represented
as:
EU[0 T ](t) [λDLSM(t)Epσt τ (X,x,y,y) [kVχ log p(y∣X; θ, σt) + s(X; φ, σt) - Vχ log Pσt (X∣X)k2]],
,	(A4)
where p(y∣X; θ,σt) is a noise-conditioned classifier. Xdlsm(I) is the balancing coefficient for
different σt. For the cross-entropy loss, the modified loss LCE(θ) is represented as:
EU[0,T](t) [λCE⑴EPσt,τ(x,y)[- logP(y|X； θ,σt)]] ,	(A5)
where λCE(t) is the balancing coefficient for different σt. In all of our experiments, λCE(t) is set to
1. The values of λDSM(t) and λDLSM(t) are customized according to different settings, and specified
in Sections A.6.2 and A.6.3. Please note that λDSM(t), λDLSM(t), and λCE(t) are adopted to balance
the loss functions for different σt, and are different from the balancing coefficient λ in Eq. (11).
A.6.2 The Experiments on the Inter-twinning Moon Dataset
Dataset. We perform our motivational experiments on the inter-twinning moon dataset provided by
the sklearn library in python. In this dataset, the data points are sampled from two interleaving
crescents. The data points of the upper crescent are generated based on (cos(x), sin(x)), ∀x ∈ [0, π]
and are labeled as c1 . On the other hand, the data points of the lower crescent are generated based on
(1 - cos(x), 0.5 - sin(x)), ∀x ∈ [0, π] and are labeled as c2. Before training, the data points are first
normalized such that their mean become 0 and then their coordinates are scaled by a factor of 20.
Setups and Evaluation Method. In this experiment, the scores Vχ logpσ(X) and Vx logpσ (X∣y)
are obtained by calculating Eq. (2). The likelihood scores are computed according to
Vχ logpσ(y|X) = Vx logpσ(X∣τ∕) - Vx logp。(X) in Eq. (5). As for the DP and DL metrics
in Table 1, the errors between two score functions are measured using 1,225 data points uniformly
sampled from the two-dimensional subspace [-25, 25] × [-40, 40]. The scaling factor α adopted in
method (b) is set to 10. The values of Xdsm (t) and Xdlsm (t) are both set to 占,and the value of λ
σt
is set to 0.125.
Training and Implementation Details. The network architectures for the score model and the
classifier are simple three-layer multilayer perceptrons (MLPs) with ReLu as the activation function.
These networks are implemented using the pytorch library with nn.Linear layers that contain
(128, 64, 32) neurons per layer for both of the score model and the classifier. The score model is
trained using the Adam optimizer with a learning rate of 6.5 × 10-4 and a batch size of 4,000 for
40,000 iterations. The classifier is trained using the Adam optimizer with a learning rate of 2.0 × 10-5
and a batch size of 4,000 for 40,000 iterations.
18
Published as a conference paper at ICLR 2022
Table A3: The experimental results on the inter-twining moon dataset, where the classifiers are trained
with LCE, LDLSM0, and LTotal, respectively. The errors of the score functions for different methods
are measured using EU⑸[Dp(X, y)] and EU⑸[Dl(X, y)], where U(X) is a uniform distribution
over a two-dimensional subspace, y represents the classes specified in the second row of the table,
and Dp and DL are defined in Eq. (7). The arrow symbol J indicates that lower values correspond to
better performances.
		LCE	LDLSM0	LTotal
〜 	y		ci	C2	Ci	C2	Ci	C2
EU(X)DP (χ, y)]	T	0.198 0.197	0.066 0.065	0.066 0.064
EU (X)DL(x, y)]	J	0.190 0.181	0.053 0.053	0.052 0.052
A.6.3 The Experiments on the Cifar- 1 0 and Cifar- 1 00 Datasets
Dataset. We adopt the Cifar-10 and Cifar-100 datasets (Krizhevsky et al., 2009) for evaluating our
design on image generation tasks. Cifar-10 consists of 60,000 32 × 32 RGB images with 10 classes,
where each class contains 6,000 images. Cifar-100 is similar to Cifar-10, except it has 100 classes,
where each class contains 600 images. The images are first normalized to [-1, 1]d before training.
Setups and Evaluation Method. The results on the CAS metric are evaluated using a classifier
(ResNet-50 (He et al., 2016)) trained with the generated samples. This classifier is trained to minimize
the cross-entropy loss with the Adam optimizer using a learning rate of 2.0 × 10-4 with a batch size
of 150. The results OntheP /R/ D/ C metrics are calculated using the officially released code. The
hyperparameter k used in the P / R / D / C metrics is fixed to 3. The results on the FID and IS metrics
are computed on 50,000 samples using the tensorflow_gan library in python. The value of
1DSM(t) is set to σ12, while the value of Xdlsm(t) is set to 1. The value of λ is set to 1.
Training and Implementation Details. The network architecture for the score model is the same
as (Song et al., 2021b). The network architecture for the classifier is a modified ResNet-18 (He
et al., 2016) for Cifar-10 and a modified ResNet-34 for Cifar-100. The modification only involves
an additional conditional branch for encoding the standard deviation σt . The score model is trained
with the Adam optimizer using a learning rate of 2.0 × 10-4 and a batch size of 128. The classifier is
trained with the Adam optimizer using a learning rate of 2.0 × 10-4 and a batch size of 100.
A.7 Additional Experiments
In this section, we present a number of additional experimental results and provide discussions on
them. We first report the results of our method using different values of λ on Cifar-10 to demonstrate
that LTotal is less sensitive to the choices of λ. Next, we apply the scaling technique on both the base
method and our method with different choices ofα to demonstrate the influence of the hyperparameter
α on the evaluation results of several metrics. Finally, we provide uncurated examples on the Cifar-10
and Cifar-100 datasets.
A.7. 1 Ablation Analysis on the Inter-twinning Moon Dataset
Table A3 compares the evaluation results on the EU(x)[Dp(X, y)] and EU(x)[Dl(X, y)] metrics
when the classifiers are trained with LCE, LDLSM0, and LTotal, respectively. It is observed that the
score errors EU(x)[Dp(X, y)] and EU(x)[Dl(X, y)] are the lowest when LTotal is adopted. The
experimental results therefore validate the effectiveness of the proposed loss LTotal .
A.7.2 The Experiments on the Balancing Coefficient
Table A4 demonstrates the evaluation results on FID, IS, and P / R / D / C metrics using LTotal with
different values of λ. It is observed that the evaluation results only slightly fluctuate on the six metrics
with different choices of λ. The results thus experimentally validate that LTotal is less sensitive to the
choice of λ.
19
Published as a conference paper at ICLR 2022
Table A4: The experimental results of our method using LTotal with different value of λ. The arrow
symbols ↑ / J represent that a higher / lower evaluation result correspond to a better performance.
		λ = 2.0	λ = 1.0	λ = 0.5	λ = 0.125
FID	丁	-233^-	-^2.25^^	2.36	2.25
IS	↑	9.90	9.90	9.98	9.79
Precision	T	-064^^	^^0.65^^	0.64	0.64
Recall	↑	0.62	0.62	0.62	0.62
Density	↑	0.94	0.96	0.95	0.94
Coverage	↑	0.79	0.81	0.79	0.78
Table A5: A comparison of the evaluation results of the base method, the scaling method with different
α, ours method, and ours + scaling method with different α on the Cifar-10 dataset. The arrow
symbols ↑ / J represent that a higher / lower evaluation result correspond to a better performance.
		Base	Scaling					Ours	Ours + Scaling				
α	-	1.0	0.5	3.0	5.0	10.0	20.0	1.0	0.5	3.0	5.0	10.0	20.0
FID	ɪ	4.10	3.22	6.16	8.06	12.48	16.59	2.25	2.57	3.96	6.40	11.06	14.92
IS	↑	9.08	9.50	9.14	9.38	9.37	9.23	9.90	9.79	10.00	9.95	9.73	9.53
Precision	↑	0.67	0.65	0.70	0.72	0.75	0.75	0.65	0.62	0.69	0.71	0.73	0.74
Recall	↑	0.61	0.61	0.56	0.53	0.49	0.44	0.62	0.63	0.57	0.53	0.49	0.44
Density	↑	1.05	0.98	1.17	1.25	1.36	1.36	0.96	0.87	1.15	1.23	1.28	1.30
Coverage	↑	0.80	0.78	0.78	0.77	0.75	0.67	0.81	0.77	0.79	0.77	0.71	0.66
(CW) Precision	ɪ	0.51	0.43	0.63	0.67	0.70	0.73	0.56	0.48	0.65	0.68	0.71	0.72
(CW) Recall	↑	0.59	0.62	0.51	0.46	0.42	0.37	0.61	0.63	0.55	0.50	0.45	0.39
(CW) Density	↑	0.63	0.46	0.97	1.10	1.23	1.30	0.76	0.58	1.05	1.16	1.23	1.26
(CW) Coverage	↑	0.60	0.47	0.69	0.69	0.66	0.61	0.71	0.61	0.75	0.73	0.66	0.61
A.7.3 The Experiments on the Scaling Technique
Table A5 demonstrates the evaluation results of the base method, the scaling method using different
values of α, our method, and our method with the scaling technique using different values of α (i.e.,
‘ours + scaling’) on the Cifar-10 dataset. It is observed that the performance of the ‘scaling method’
and ‘ours + scaling’ method on the fidelity metrics, i.e., precision and density, improves as the value
of α grows. Conversely, the performance of the ‘scaling method’ and ‘ours + scaling’ method on the
FID, recall, and coverage metrics degrades as the value of α grows. This results thus experimentally
demonstrate the effects of the scaling technique on the performance of the base method and our
method.
A.7.4 Uncurated Examples
Figs. A3, A4, A5, and A6 depict a few uncurated examples that qualitatively compare the effectiveness
of different methods.
20
Published as a conference paper at ICLR 2022
E周・盛爵激堡
翼限”
国ILwM
卜缶变量分心断
*上匕二∖∙□
3里≡B‰DLv⅛r
gL⅞⅛gg¾a⅛¾
SSEr灯制艺L的，
蠹超露昌Sl 一0一,『设
力as≡，髭≡即2五七
闺EzEFQ>口国GfV
e3erj÷HRhfES
肉L帽⅛FX同F≡≡
Figure A3: The uncurated examples generated using the base method on the Cifar-10 dataset.
21
Published as a conference paper at ICLR 2022
Figure A4: The uncurated examples generated using the scaling method on the Cifar-10 dataset.
∙hc∙LΓ
■弘盛复购mA®通仪
>a>∙⅞<*⅛Aa
・0黄冷静理S O J
・奥••懿退暨吊♦年
酬就茎金二慰醺就窗E
S3赖氏凌市期牌d
，,, UHSQl j,19■渝必Irl
Ue思昌IW^八。£fi
—足■ CMB≡¾g^ ⅛∙IJ⅝
QEBatl3EIc≡El
⅛y⅞^
K匕t心
E3n0BM≡ES -H
7sQG≡m≡0
EJHril9⅝^>3l - —1?
④5白ɪs曲石n藤&
■
i摩
,渡 产ra⅛K4.星■=
H j[≡^^au 地■工
T "上.	、％ F"≡lk ， TU _ _，一。 一 TIIf
□A⅛E!r≡Ξ±HH≡
3Dr⅛1□室一Mp≡等
≡≡3 EJKA用一ra⅛E
SH照N配瀛堀则翦3
嘱出 伊 四，KJS≡3WE
西 EasQΞ暨匚国S
盘。尽巴即国EBJ巴口
『一 PHΞS1≡^23E
场H芯FF-∏,弼ħ≡
aEm■国 Sh四㈣？
22
Published as a conference paper at ICLR 2022
电 &Q9醛a∙ 口事A
EQa "汇唱少产D静
^HBSV →n^
κq□便ʃG亨嘴尸强
Γiil
西豫盘■EEHE二・
£SB，E95S0芟E
i≡l^uτ⅛.⅛
■』LT言上τ^isi^
±l⅛-- - ^⅛⅛
逾G回&-』±©而产
『汽⅛二 α≡于iiM笔.
崩R百衿⅜B≡四H般
三¥.除工：?与E爷
ΞBM 福阳 Q 第Hk≡
n⅛⅛ F 岂H
nX青S'
AIS-SIb
.羽屈豆，益F≡E.
aMW
 
QM 产HVEF49B≡F
hit
E*≡尊E3S53 察
≡匕次卷|画∙H-a
E≡
“□Bfcm 心气B随Si

Ra≡ls≡弋*⅛立π*
不演露齿&»MZKil
女&O,&鹫网4 0
□幽心电第U周霸蠡麴
究.扁& ••壮箸世士
≈⅛saz^nwfi^⅛ι
a燔 BEQLlG 以
⅜ 丁期
瘠G£磬■■潭三B胡
IBis^⅛
K -HBi
手Π<I3霭%警阚,
W管不置≡B∙%∙w
一2∙*∙αQ做
Itsc
一S希∙≡Qα置
l-2nl ^-Γh> < -u≡^ __________________
,B&F *mκ溟
ll>u⅛ ⅜ ■.1 *J - Jle-Iwt
^E3IA≡-
霆图迪N
・HB
常■等导簟Bs≡产* K
Ss
El^
■ F.H茸R
Fq≡9
Ship
Figure A5: The uncurated examples generated using our
筹 HL 超9≡ħr≡q骞
^≡-^≡R
除9ħbλw≡≡≡∙
S qBW Sris
method on the Cifar-10 dataset.
23
Published as a conference paper at ICLR 2022
^BΠ.<0πsv
ΓΓ□■辗Fai 招
E □□Rr口 •*>-
灯□aI≡门H∙□UE
□ □■■■
・ru二•,•*;>肉
iκsB⅛BnH
仔,“ □□□口:」
∙∙CΠB∙
ππππKI。，口ΠL1
BB□∙ 0a∙∙口∙
ΠCHEn
3∙0π■，口 ∙ħ□
□1・
□□
*
nΛ*30 冬『-"•。
Bisn^
V3π⅜温 r酸□BΓ .
□r∙JRτH 国□B幽<
m⅛πsa⅛s
§ 口酚口□口・□
⅛e⅛s⅛*⅛
*，；：□R
募‹⅛‹γw豫以* 丸
ΞCΞ3<EH*∙赛
Q嫉步・加魁J4a爵
O∙NΛW *κ号A
OJ ≠f O?
?£蜜«消，，，叫中
曹&令・趣‹∙≡*c
篇£看”五亩•
Ours
G 妈口□□□K3匚
ΠΓ【口口Hr二口七
Scaling
Base

Figure A6: The uncurated examples of classes ‘baby’, ‘apple’, ‘aquarium fish’, and ‘beargenerated’
using the base method, the scaling method, and our method on the Cifar-100 dataset.
24