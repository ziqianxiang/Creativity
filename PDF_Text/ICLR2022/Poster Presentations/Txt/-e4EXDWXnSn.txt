Published as a conference paper at ICLR 2022
Invariant Causal Representation Learning
for Out-of-Distribution Generalization
Chaochao Lu1,2, Yuhuai Wu3,4t,Jo6e Miguel Hernandez-Lobato1,5*, Bernhard Scholkopf2*
Ab stract
Due to spurious correlations, machine learning systems often fail to generalize
to environments whose distributions differ from the ones used at training time.
Prior work addressing this, either explicitly or implicitly, attempted to find a data
representation that has an invariant relationship with the target. This is done by
leveraging a diverse set of training environments to reduce the effect of spurious
features and build an invariant predictor. However, these methods have general-
ization guarantees only when both data representation and classifiers come from a
linear model class. We propose invariant Causal Representation Learning (iCaRL),
an approach that enables out-of-distribution (OOD) generalization in the nonlinear
setting (i.e., nonlinear representations and nonlinear classifiers). It builds upon
a practical and general assumption: the prior over the data representation (i.e., a
set of latent variables encoding the data) given the target and the environment be-
longs to general exponential family distributions, i.e., a more flexible conditionally
non-factorized prior that can actually capture complicated dependences between
the latent variables. Based on this, we show that it is possible to identify the data
representation up to simple transformations. We also show that all direct causes of
the target can be fully discovered, which further enables us to obtain generalization
guarantees in the nonlinear setting. Experiments on both synthetic and real-world
datasets demonstrate that our approach outperforms a variety of baseline methods.
1	Introduction
Modern machine learning algorithms still lack robustness, and may fail to generalize outside of a
specific training distribution because they learn easy-to-fit spurious correlations which are prone to
change between training and testing environments. We recall the widely used example of classifying
images of camels and cows (Beery et al., 2018). Here, the training dataset has a selection bias, i.e.,
many pictures of cows are taken on green pastures, while most pictures of camels happen to be in
deserts. After training, it is found that the model builds on spurious correlations, i.e., it relates green
pastures with cows and deserts with camels, and fails to recognize images of cows on the beach.
To address this problem, a natural idea is to identify which features of the training data present
domain-varying spurious correlations with labels and which features describe true correlations of
interest that are stable across domains. In the example above, the former are the features describing
the context (e.g., pastures and deserts), whilst the latter are the features describing the animals (e.g.,
animal shape). By exploiting the varying degrees of spurious correlation naturally present in training
data collected from multiple environments, one can try to identify stable features and build invariant
predictors. Invariant risk minimization (IRM) seeks to find data representations (Arjovsky et al.,
2019) or features (Rojas-Carulla et al., 2018) for which the optimal predictor is invariant across all
environments. The general formulation of IRM is a challenging bi-leveled optimization problem,
and theoretical guarantees require constraining both data representations and classifiers to be linear
(Arjovsky et al., 2019, Theorem 9), or considering the special case of feature selection (Rojas-Carulla
et al., 2018, Theorem 4). Ahuja et al. (2020a) study the problem from the perspective of game theory,
with an approach termed invariant risk minimization games (IRMG). They show that the set of Nash
equilibria for a proposed game is equivalent to the set of invariant predictors for any finite number
of environments, even with nonlinear data representations and nonlinear classifiers. However, these
1University of Cambridge, 2MPI for Intelligent Systems, 3Stanford University, 4Google Research,
5The Alan Turing Institute, ^ Work done at University of Toronto, * Equal Supervision, Correspondence at
cl641@cam.ac.uk.
1
Published as a conference paper at ICLR 2022
theoretical results in the nonlinear setting only guarantee that one can learn invariant predictors from
training environments, but do not guarantee that the learned invariant predictors can generalize well
across all environments including unseen testing environments.
We propose invariant Causal Representation Learning (iCaRL), a novel approach that enables out-
of-distribution (OOD) generalization in the nonlinear setting (i.e., nonlinear representations and
nonlinear classifiers1). We achieve this by extending and using methods from representation learning
and graphical causal discovery. In more detail, we first introduce our main general assumption: when
conditioning on the target (e.g., labels) and the environment (represented as an index), the prior
over the data representation (i.e., a set of latent variables encoding the data) belongs to a general
exponential family. Unlike the conditionally factorized prior assumed in recent identifiable variational
autoencoders (iVAE) (Khemakhem et al., 2020a), this is a more flexible conditionally non-factorized
prior, which can actually capture complicated dependences between the latent variables. We then
extend iVAE to the case in which the latent variable prior belongs to such a general exponential
family. The combination of this result and the previous general assumption allows us to guarantee
that the data representation can be identified up to simple transformations. We then show that the
direct causes of the target can be fully discovered by analyzing all possible graphs in a structural
equation model setting. Once they are discovered, the challenging bi-leveled optimization problem in
IRM and IRMG can be reduced to two simpler independent optimization problems, that is, learning
the data representation and learning the optimal classifier can be performed separately. This leads to
a practical algorithm and enables us to obtain generalization guarantees in the nonlinear setting.
Overall, we make a number of key contributions: (1) We propose a general framework for out-of-
distribution generalization in the nonlinear setting with the theoretical guarantees on both identifiabil-
ity and generalizability; (2) We propose a general assumption on the underlying causal diagram for
prediction (Assumption 1 and Fig. 1c), which covers many real-world scenarios (Section 3.2); (3)
We propose a general assumption on the prior over the latent variables (Assumption 2), i.e., a more
flexible conditionally non-factorized prior; (4) We prove that an extended iVAE with this conditionally
non-factorized prior is also identifiable (Theorems 1, 2&3); (5) We prove that our framework has the
theoretical guarantees for OOD generalization in the nonlinear setting (Proposition 1).
2	Preliminaries
2.1	Identifiable Variational Autoencoders
Variational autoencoders (VAEs, see Appendix B) (Kingma & Welling, 2013; Rezende et al., 2014)
lack identifiability guarantees. Consider a VAE model where X ∈ Rd stands for the observed
variables (data) and Z ∈ Rn for the latent variables. Khemakhem et al. (2020a) show that a VAE with
an unconditional prior distribution pθ(Z) over the latent variables is unidentifiable. However, they
also show that it is possible to obtain an identifiable model if one posits a conditionally factorized
prior distribution over the latent variables, pθ(Z|U), where U ∈ Rm is an additional observed
variable (HyVarinen et al., 2019). Specifically, let θ = (f, T, λ) ∈ Θ be the parameters of the
conditional generative model
pθ (X, Z |U) = Pf (X |Z )pt ,λ(z∣u),	(1)
where pf(X|Z) = p(X - f(Z)) in which is an independent noise variable with probability
density function pe(e). Importantly, the prior PT,λ(Z|U) is assumed to be conditionally factorial,
where each element of Zi ∈ Z has a univariate exponential family distribution given U. The
conditioning on U is through an arbitrary function λ(U) (e.g., a neural net) that outputs the individual
exponential family parameters λi(U) for each Zi. The prior probability density thus takes the form
Pτ,λ(Z|U) = Yi Qi(Zi)/Ci(U)exp hχk=1 Tij(Zi)M(U)],	⑵
where Qi is the base measure, Zi the i-th dimension of Z, Ci (U) the normalizing constant, Ti =
(Ti,1, . . . , Ti,k) the sufficient statistics, λi(U) = (λi,1 (U), . . . , λi,k(U)) the corresponding natural
parameters depending on U, and k the dimension of each sufficient statistic that is fixed in advance. It
is worth noting that this prior is restrictive as it is factorial and therefore cannot capture dependencies.
As in VAEs, the model parameters are estimated by maximizing the corresponding evidence lower
bound (ELBO),
LiVAE(θ, Φ) =EpD [Eqφ(zχ,u) [logPf (X|Z) + logPt,λ(Z|U) - log qφ(Z|X, U)]] ,	(3)
1In fact, we are not restricted to the classification case and allow the target to be either continuous or
categorical, which will be formally defined in Section 2.2.
2
Published as a conference paper at ICLR 2022
where We denote by PD the empirical data distribution given by the dataset D = {(X(i), U(i))}N=ι
and qφ(Z|X, U) denotes an approximate conditional distribution for Z given by a recognition
network with parameters φ. This approach is called identifiable VAE (iVAE). Most importantly, it
can be proved that under the conditions stated in Theorem 2 of Khemakhem et al. (2020a), iVAE can
identify the latent variables Z up to a permutation and a simple componentwise transformation, see
Appendix F.
2.2	Invariant Risk Minimization
Arjovsky et al. (2019) introduced invariant risk minimization (IRM), whose goal is to construct an
invariant predictor f that performs well across all environments Eall by exploiting data collected
from multiple environments Etr, where Etr ⊆ Eall. Technically, they consider datasets De :=
{(xie, yie)}in=e 1 from multiple training environments e ∈ Etr, where xie ∈ X ⊆ Rd is the input
observation and its corresponding label is yie ∈ Y ⊆ Rs.2 * The dataset De, collected from environment
e, consists of examples identically and independently distributed according to some probability
distribution P (Xe, Y e). The goal of IRM is to use these multiple datasets to learn a predictor
Y = f(X) that performs well for all the environments. Here we define the risk reached by f in
environment e as Re(f) = Eχe,γe ['(f (Xe), Ye)], where '(∙) is a loss function. Then, the invariant
predictor can be formally defined as follows:
Definition 1 (Invariant Predictor (Arjovsky et al., 2019)). We say that a data representation Φ ∈
HΦ : X → F elicits an invariant predictor w ◦ Φ across environments E if there is a classifier
W ∈ Hw : F → Y simultaneously optimalfor all environments, that is, W ∈ argminw∈Hw Re(W◦ Φ)
for all e ∈ E, where ◦ means function composition.
Mathematically, IRM can be phrased as the following constrained optimization problem:
min
Φ∈HΦ,w∈Hw
e∈Etr
Re(w ◦ Φ)
s.t. w ∈ arg min Re(W ◦ Φ), ∀e ∈ Etr.
w∈Hw
(4)
Since this is a generally infeasible bi-leveled optimization problem, Arjovsky et al. (2019) rephrased
it as a tractable penalized optimization problem by transfering the inner optimization routine to a
penalty term. The main generalization result (Theorem 9 in Arjovsky et al. (2019)) states that if both
Φ and W come from the class of linear models (i.e., HΦ = Rn×n and Hw = Rn×1), under certain
conditions on the diversity of training environments (Assumption 8 in Arjovsky et al. (2019)) and the
data generation, the invariant predictor W ◦ Φ obtained by solving Eq. (4) remains invariant in Eall .
3	Problem Setup
3.1	A Motivating Example
In this section, we extend the example which was introduced by Wright (1921) and discussed by
Arjovsky et al. (2019), and provide a further in-depth analysis.
Model 1. Consider a structural equation model (SEM) with a discrete environment variable E that
modulates the noises in the structural assignments connecting the other variables (cf. Fig. 1a below):
Zi J GauSSian(0,σι(E)), Y J Zi + GaUSSian(0,σ2(E)), Z2 J Y + Gaussian(0, σ3(E)),
where Gaussian(0, σ) denotes a Gaussian random variable with zero mean and standard deviation
σ, and σi , . . . , σ3 are functions of the value e ∈ Eall taken by the environment variable E.
To ease exposition, here we consider the simple scenario in which Eall only contains all modifications
varying the noises of Zi, Z2 and Y within a finite range, i.e., σi(e) ∈ [0, σm2 ax]. Then, to predict Y
from (Zi, Z2) using a least-square predictor Ye = c^1Zf + α2Ze for environment e, we can
•	Case 1: regress from Z；, to obtain αι = 1 and α? = 0,
•	Case 2: regress from Ze, to obtain αι = 0 and α?
σ1(e)+σ2(e)
σι (e) + σ2(e)+σ3(e),
Case 3: regress from (Ze, Ze), to obtain ɑι
σ3(e)	σ2(e)
σ2(e) + σ3(e) and α2 = σ2(e) + σ3(e) ∙
In the generic scenario (i.e., σi(e) 6= 0, σ2(e) 6= 0, and σ3(e) 6= 0), the regression using Zi in Case 1
is an invariant correlation: it is the only regression whose coefficients do not vary with e. By contrast,
2The setup applies to both continuous and categorical data. If any observation or label is categorical, we
could one-hot encode it.
3
Published as a conference paper at ICLR 2022
Figure 1: (a) Causal structure of Model 1. (b) A more practical extension of Model 1, where Z1 and Z2 are not
directly observed and X is their observation. (c) A general version of (b), where we assume there exist multiple
unobserved variables. Each of them could be either a parent, a child of Y , or has no direct connection with Y .
We allow for arbitrary connections between the latent variables (red dashed lines) as long as the resulting causal
diagram including Y is a directed acyclic graph (DAG). Grey nodes denote observed variables and white nodes
represent unobserved variables. Dashed lines denote the edges which might vary across environments and even
be absent in some scenarios, whilst solid lines indicate that they are invariant across all the environments.
the regressions in both Case 2 and Case 3 have coefficients that depend on e. Therefore, only the
invariant correlation in Case 1 will generalize well to new test environments.
Another way to understand Model 1 is through its graphical representation3, as shown in Fig. 1a.
We treat the environment as a random variable E, where E could be any information specific to
the environment (Storkey, 2009; Peters et al., 2015; Zhang et al., 2017; Huang et al., 2020). Unless
stated otherwise, for simplicity, we let E be the environment index, i.e., E ∈ {1, . . . , N}, where
N is the number of training environments. A more realistic version appearing in many settings is
shown in Fig. 1b, where the true variables {Z1, Z2} are unobserved and we can only observe their
transformation X. In this case, Invariant Causal Prediction (ICP) (Peters et al., 2015) will fail when
applied to X, even when Y is not affected by E (i.e., the edge E → Y is removed). The reason is
that each variable (i.e., each dimension) of X is jointly influenced by both Z1 and Z2 so that ICP is
unable to find the variables containing the information only about Z1 by searching for a subset of
variables X . By contrast, both IRM and IRMG work, as long as the transformation is linear. These
findings are also empirically illustrated in Appendix K.1. We now go even further and consider a
more general causal graph in which Y can have more than one parent or child.
3.2 Assumptions on the Causal Graph
We extend the causal graph in Fig. 1b to a more general setting4, as encapsulated in Fig. 1c. In
particular, we now have X ∈ X ⊆ Rd, Y ∈ Y ⊆ Rs, Z = (Zp1 , . . . , Zpr, Zc1 , . . . , Zck) ∈
Z ⊆ Rn, where n = r + k, and {Zi}i∈Ip={p1,...,pr} and {Zj}j∈Ic={c1,...,ck} are multiple scalar
causal factors and non-causal factors5 of Y , respectively. We denote Zp =. (Zp1 , . . . , Zpr) and
Zc =. (Zc1 , . . . , Zck ) for the ease of clarification. We also assume that Z is of lower dimension than
X, that is, n ≤ d. We allow for arbitrary connections between the latent variables Z as long as
the resulting causal diagram including Y is a directed acyclic graph (DAG). We use dashed lines to
indicate the causal mechanisms which might vary across environments and even be absent in some
scenarios, whilst solid lines indicate that they are invariant across all the environments. To sum up, we
assume that the underlying causal graph encapsulated in Fig. 1c satisfies the following assumption6:
Assumption 1. (a) Zi depends on one or both of Y and E for any i; (b) The causal graph containing
Z andY is a DAG; (c) X ⊥⊥ Y , E|Z, implying that p(X |Z) is invariant across all the environments;
(d) Y ⊥⊥ E|Zp, implying that p(Y |Zp) is invariant across all the environments.
One may be wondering how practical Assumption 1 is in real world applications. Let us explore
this in more detail. Assumption 1a rules out all the useless Zi in the task of predicting Y . This
is because if Assumption 1a is violated, meaning that Zi is independent of Y and E and has no
influence in predicting Y , then such Zi should be viewed as noise and thus eliminated during learning.
Assumption 1b is a common assumption in causal discovery (Spirtes et al., 2000; Pearl, 2009; Peters
et al., 2015). It also makes sense in Assumption 1c that the generative mechanism p(X|Z) is
3The relation between SEM and its graphical representation is formally defined in Appendix D.
4For simplicity, we do not explicitly consider unobserved confounders in this paper. In particular, we assume
that there are no unobserved confounders between Z, Y , X , and E.
5This means that Zj∈Ic could be either an effect of Y , independent of Y , or spuriously correlated with Y
via a third set of confounders (i.e., both Zj and Y are affected by a subset of {Zi}i6=j and E).
6For generality, we replace E with E to additionally include the case of multi-dimensional variables.
4
Published as a conference paper at ICLR 2022
Algorithm 1: Invariant Causal Representation Learning (iCaRL)
Phase 1: We first learn a NF-iVAE model, including the decoder and its corresponding encoder, by
optimizing the objective function in (10) on the data {X, Y , E}. Then, we use the mean of the NF-iVAE
encoder to infer the latent variables Z from observations {X, Y , E}. The latent variables are guaranteed
to be identified up to a permutation and simple transformation.
Phase 2: After inferring Z, we first conduct the PC algorithm to learn a Markov equivalence class of DAGs,
and then discover direct causes (parents) of Y among its neighbors by testing all pairs of latent variables
with (conditional) independence testing, i.e., finding a set of latent variables in which each pair of Zi and
Zj satisfies that the dependency between them increases after additionally conditioning on Y .
Phase 3: Having obtained Pa(Y ), we can solve (11) to learn the invariant classifier w. When in a new
environment, we first infer Pa(Y ) from X by solving (12) and then leverage the learned w for prediction.
invariant across all the environments. Otherwise, it is impossible to infer Z from X in any unseen
environment. Assumption 1d is a widely-used default assumption in OOD generalization (Peters
et al., 2015; Arjovsky et al., 2019). In fact, Assumption 1d can be further relaxed to the more practical
one that E[Y |Zp] is invariant across all the environments. That is, given Zp, we allow E to only
affect the amount of noise in the distribution of Y , because that would not change the expected value
of Y since the mean of the noise would be zero. Apparently, Assumption 1, together with the causal
graph in Fig. 1c, covers most scenarios (e.g., the ones of Zhang et al. (2013); Von Kugelgen et al.
(2020); Sun et al. (2020); Ahuja et al. (2021); von Kugelgen et al. (2021)) and is a very flexible model
for causal analysis when predicting Y from X .
3.3 Assumptions on the Prior
When the underlying causal graph satisfies Assumption 1, our primary assumption leading to identifi-
ability in this general setting is that the conditional prior p(Z |Y , E) belongs to a general exponential
family. This is formalized as follows:
Assumption 2. p(Z|Y , E) belongs to a general exponential family with parameter vector given
by an arbitrary function λ(Y , E) and sufficient statistics T (Z) = [Tf(Z)T, TNN(Z)T]T given by
the concatenation ofa) the SUffiCient statistics Tf (Z) = [Tι(Zι)τ,…，Tn(Zn)T]T ofa factorized
exponential family, where all the Ti(Zi) have dimension larger or equal to 2, and b) the output
TNN(Z) of a neural network with ReLU activations. The resulting density function is thus given by
PTNZ|Y, E) = Q(Z)/C(Y, E) exp [T(Z)tλ(Y, E)],	(5)
where Q is the base measure and C the normalizing constant.
A neural network with ReLU activation has universal approximation power. Therefore, the term
TNN(Z) in the above prior distribution will allow us to capture arbitrary dependencies between the
latent variables. The distribution in Eq. (5) is more flexible than the conditionally factorized prior
assumed by iVAEs. However, surprisingly, the identifiability results of iVAEs also hold when using
the more flexible prior in Eq. (5), as we will show in Section 4.1. This motivates using an extended
iVAE model with the above prior to model data generated by the ground truth model in Fig. 1c.
However, in this case, the data generating model and the learned model might have different priors.
For example, in the ground truth model, the prior for each Zi∈Ip might bep(Zi|E), when Zi is only
caused by E. By contrast, in the extended iVAE model the prior is p(Z|Y, E). Is this going to affect
the identifiability of the latent variables? Well, in practice not because the posterior distribution for Z
given X, Y and E would be equivalent in both models (up to identifiability guarantees).
4 Invariant Causal Representation Learning
We now introduce our algorithm, invariant Causal Representation Learning (iCaRL), which consists
of 3 phases as summarized in Algorithm 1. The idea is that we first identify Z by using an extended
iVAE model under Assumptions 1&2 (Phase 1), then discover direct causes of Y among the identified
Z (Phase 2), and finally learn an invariant predictor for Y from the discovered causes (Phase 3).
4.1 Phase 1: Identifying Latent Variables Using NF-iVAE
In this section, we describe our identifiable model, namely NF-iVAE, which is an extended iVAE
with a general non-factorized prior that is able to capture complex dependences between the latent
variables. Technically, in the general setting under Assumption 1, it is straightforward to obtain a
5
Published as a conference paper at ICLR 2022
corresponding generative model by directly substituting U with (Y , E) in Eq. (1):
Pθ(X, Z|Y, E) = Pf (X|Z)pτ,λ(Z|Y, E),	⑹
pf(X|Z) = p(X - f(Z)).	(7)
The corresponding ELBO is
LELsO1(θ, Φ) =EpD hEqφ(zχ,γ ,E) [log Pf (X|Z ) + log PT ,λ(Z∣Y, E) - log qφ(Z∣X, Y, E)]] .	(8)
To obtain an identifiability result, We assume that the prior PT,λ(Z| Y, E) satisfies Assumption 2
(i.e., Eq. (5)). Since the prior is a general multivariate exponential family distribution with unknown
normalization constant, We cannot learn its parameters (T , λ) by directly maximizing Eq. (8).
Instead, We use score matching, a Well-knoWn method for training unnormalized probabilistic models
(Hyvarinen, 2005; Vincent, 2011), and learn (T, λ) by minimizing
LpMSeI (T, λ) =EpDhEqφ(Z∣X,Y,E) [||Vz log qφ(ZlX , Y, E)- ▽Z log pT ,λ(Zl Y, E)”1] ∙	(9)
In practice, We can use a simple trick of partial integration to simplify the evaluation of Eq. (9),
see Appendix C. Furthermore, We can jointly learn (θ, φ) by combining Eq. (8) and Eq. (9) in the
folloWing objective:
Lphasel (θ, Φ) = LEL盟(f, T, λ, φ) - LpMSeI (f, T, λ, φ),	(10)
Where f, T, λ, φ are copies of f, T, λ, φ that are treated as constants and Whose gradient is not
calculated during learning. More details can be found in Appendix M.
We noW state our main theoretical results:
Theorem 1.	Assume that we observe data sampled from a generative model defined according to Eqs.
(5-7), with parameters θ := (f, T, λ), where PT ,λ(Z |Y, E) satisfies Assumption 2. Furthermore,
assume the following holds: (i) The set {X ∈ O∣^e(X) = 0} has measure zero, where WW is
the characteristic function of the density P defined in Eq. (7). (ii) Function f in Eq. (7) is
injective, and has all second-order cross derivatives. (iii) The sufficient statistics in Tf are all
twice differentiable. (iv) There exist k + 1 distinct points (Y, E)0, . . . , (Y, E)k such that the matrix
L = (λ((Y, E)1) - λ((Y, E)0),∙∙∙, λ((Y, E)k) - λ((Y, E)0)) OfSize k X k is invertible, where
k is the dimension of T. Then the parameters θ are identifiable up to a permutation and a “simple
transformation" of the latent variables Z, defined as a componentwise nonlinearity making each
recovered Ti(Zi) in Tf(Z) equal to the original up to a linear operation.
Note that, this theorem is inspired by but beyond the main results of iVAEs in that the former is
predicated on Assumption 2 Which is more flexible than the conditionally factorized prior assumed in
iVAEs. It results in several key changes in the proof, clarified in Appendix H. Interestingly, from (iv)
We can further see that E is unnecessary When there exist k + 1 distinct points Y0 , ∙ ∙ ∙ , Yk such that
the matrix L = (λ(Y1) 一 λ(Y0),..∙, λ(Yk) 一 λ(Y0)) of size k × k is invertible. Not requiring
E Would make our approach even more applicable.
We further have the folloWing consistency result for the estimation.
Theorem 2.	Assume that thefollowing holds: (i) Thefamily ofdistributions qφ(Z|X, Y, E) con-
tains pθ(Z|X, Y, E), and qφ(Z|X, Y, E) > 0 everywhere. (ii) We maximize Lphase1 (θ, φ) with
respect to both θ and φ. Then in the limit ofinfinite data, we learn the true parameters θ* up to a
permutation and simple transformation of the latent variables Z.
As a consequence of Theorems 1&2, We have:
Theorem 3.	Assume the hypotheses of Theorem 1 and Theorem 2 hold, then in the limit of infinite
data, we identify the true latent variables Z* up to a permutation and simple transformation.
Theorem 3 states that we can use NF-iVAE to infer the true Z* up to a permutation and simple
transformation. We use the mean of qφ(Z |X, Y, E) for this task. Note that the noise e may introduce
uncertainty in the estimation of Z. However, when X is high dimensional and Z is low dimensional
(as common in real world applications), qφ(Z|X, Y, E) will be highly concentrated and we will
still be able to estimate Z with high accuracy. The good results obtained by our method in various
experiments seem to corroborate this. All three theorems are proven in Appendix H.
4.2	Phase 2: Discovering Direct Causes
After estimating Z for each data point, the next step is to determine which components of Z are direct
causes of Y. We denote these components by Pa(Y). We first conduct the PC algorithm (Spirtes
et al., 2000) to learn a Markov equivalence class of DAGs, which gives us the direct neighbors of Y,
6
Published as a conference paper at ICLR 2022
denoted by Ne(Y ). Then, from Assumption 1, one observation is that in the generic case, for any
two latent variables Zi and Zj from Ne(Y ), only when both are causes of Y do we have that the
dependency between them increases after additionally conditioning on Y . Thus, when there exist at
least two causal latent variables in Ne(Y ), we can test all pairs of latent variables7 with conditional
independence testing8 (Zhang et al., 2012) to discover Pa(Y ) by comparing p-values from the two
tests: IndTest(Zi, Zj|E) and IndTest(Zi, Zj|Y , E), where IndTest denotes (conditional)
independence test. Conversely, if no such a pair is found, it implies that there is at most one causal
latent variable. This is a highly unlikely case in real world applications, which is left to Appendix G.
4.3	Phase 3: Learning an Invariant Predictor
After having obtained the causal latent variables Pa(Y ) for Y across training environments, we can
learn w by solving the following optimization problem:
wminw XeeEtr Re(W) = wminw XeeEtr EPa(YΜ。［'l(W(Pa(Y. Y')］，	(11)
where 'ι(∙) could be any loss. Since We assume that E(Y∣Pa(Y)) is invariant across Eall (the relaxed
version of Assumption 1d), the learned W is guaranteed to perform well across Eall .
The remaining question is how to infer Pa(Y) (i.e., Zp) from X in a new environment. This can be
implemented by leveraging the learned p(X|Z). The rationale behind is that p(X|Z) is assumed to
be invariant across Eall (Assumption 1c). In light of this idea, we follow Sun et al. (2020) and infer
Zp from X in any new testing environment by solving the following optimization problem:
maχ logPf (X|Zp, Zc) + λι∣∣Zp∣∣2 + λ2∣∣Zc∣∣2,	(12)
Zp,Zc
where the hyperparameters λ1 > 0 and λ2 > 0 control the learned Zp and Zc in a reasonable scale,
and both are selected on training/validation data. For optimization, we follow Schott et al. (2018) to
first use values of Z sampled from the training set as initial points and then use Adam to optimize for
several iterations.9 Note that the noise will introduce uncertainty in the estimation of Zp and Zc
from X . However, as we mentioned before (below Theorem 3), this noise is not going to affect the
estimation much because the likelihood will be highly concentrated around the ground truth values,
as corroborated by our good empirical results.
A key question is if iCaRL performs well across Eall even though it uses only data from Etr. That is,
does iCaRL enable OOD generalization, as defined by Arjovsky et al. (2019)? The answer is positive
since Theorem A.1 in Arjovsky (2021) indicates that i) any predictor W ◦ Φ with optimal OOD
generalization uses only Pa(Y) to compute Φ and ii) the classifier W in this optimal predictor can be
estimated using data from any environment e for which the distribution of Pa(Ye) has full support,
which will always be the case since the conditional prior in Eq. (5) has full support. Finally, Theorem
A.1 in Arjovsky (2021) also indicates that iii) the optimal predictor will be invariant across Eall . Key
to these results is that Pa(Y e) are available when solving (12). This requires first to identify the latent
variables Z from X, Y and E and second, to discover the direct causes of Y. The hypotheses of
Theorems 1 and 2 and Assumption 1 provide this guarantee. We therefore have the following result
whose proof is in Appendix H.
Proposition 1. Under Assumption 1 and the assumptions of Theorems 1 and 2, the predictor learned
by iCaRL across Etr in the limit of infinite data has optimal OOD generalization across Eall.
5	Experiments
We compare our approach with a variety of methods on both synthetic and real-world datasets. In
all comparisons, unless stated otherwise, we average performance over ten runs. Due to space con-
straints, we only highlight some key results while pointing to the extensive appendices for more
information. The supplement contains all the details of the experiments, e.g., datasets (Appendix J),
implementation (Appendix M), hyperparameters and architectures (Appendix N), etc.
5.1	Synthetic data
To verify the identifiability of NF-iVAE, we conduct a series of experiments on synthetic data
generated according to the causal graph shown in Fig. 2e. Details of the ground truth data generating
7We only need to consider those variables in Ne(Y ) whose edges connecting to Y are not oriented by PC.
8These conditional independence tests can be performed in parallel to largely accelerate the testing procedure.
See more in Appendix G.
9Note that, (12) can be optimized either independently for each data point or for a number of data points.
7
Published as a conference paper at ICLR 2022
(b) VAE
(a) Ground truth
(d) NF-iVAE
(c) iVAE
(e) Causal graph (f) MCC on synthetic data (g) MCC on CMNIST (h) Intervening CMNIST
Figure 2: (a-d) Visualization of the samples (i.e., Z = (Z1, Z2)) in latent space recovered through different
algorithms: (a) Samples from the true distribution; (b-c) Samples from the posterior inferred using VAE and
iVAE, respectively. Apparently, our method (d) can recover the original data up to a permutation and a simple
componentwise transformation. (e) The causal structure with Y having two causes describes the data generating
process of the synthetic dataset. (f) Mean correlation coefficient (MCC) scores for VAE, iVAE, and NF-iVAE on
synthetic data. (g) MCC scores for VAE, iVAE, and NF-iVAE on CMNIST. (h) The effects on the CMNIST
images of digit 8 (top two rows) and digit 3 (bottom two rows) when intervening on a causal factor Zi∈Ip and
on a non-causal factor (effect) Zj∈Ic, respectively.
process are given in Appendix K. The reason we choose this setting is that it is the simplest case
satisfying our requirements: a) For ease of visualization, the latent space had better be 2-dimensional;
b) To introduce the non-factorized prior given Y and E (i.e., Zi ⊥6⊥ Zj |Y , E), Y has at least two
causes. We draw 1000 samples from each of the four environments E = {0.2, 2, 3, 5}, and thus
the whole synthetic dataset consists of 4000 samples. The task is to recover the true latent variable
Z = (Z1 , Z2 ) using the samples of X , E, and Y . We compare with two widely-used baselines: VAE
(Kingma & Welling, 2013) (without identifiability guarantees) and iVAE (Khemakhem et al., 2020a)
(with a conditionally factorized prior for identifiability). Through the aforementioned theoretical
analysis, it is evident that our method has a more general assumption on the prior leading to
identifiability. This is demonstrated empirically in Figs. 2b-2d. Our method NF-iVAE can recover
the original data Z up to a permutation and a simple componentwise transformation, whereas all the
other methods fail because they are unable to handle the non-factorized case in which Zi ⊥6⊥ Zj |Y , E.
We also compute the mean correlation coefficient (MCC) used in Khemakhem et al. (2020a), which
can be obtained by calculating the correlation coefficient between all pairs of true and recovered
latent factors and then solving a linear sum assignment problem by assigning each recovered latent
factor to the true latent factor with which it best correlates. By definition, higher MCC scores indicate
stronger identifiability. From Fig. 2f, we can see that the MCC score for NF-iVAE is significantly
greater than those of VAE and iVAE, indicating much stronger identifiability. Note that, in Appendix
K we additionally compare with more methods, whose differences are further summarized in a table.
5.2	Colored MNIST, Colored Fashion MNIST, and VLCS
In this section, we first report experiments on two datasets used in IRM and IRMG: Colored MNIST
(CMNIST) and Colored Fashion MNIST (CFMNIST). We follow the same setting of Ahuja et al.
(2020a) to create these two datasets (see the details in Appendix J). The task is to predict a binary
label assigned to each image which is originally grayscale but artificially colored in a way that the
color is correlated strongly but spuriously with the class label. For all the experiments on these two
datasets, we set the number of the latent variables to n = 10.
Likewise, we investigate the identifiability of NF-iVAE on CMNIST by computing the MCC score
between samples of the true latent variable and of the recovered latent variable. Since the true latent
variable on CMNIST is inaccessible to us, we follow Khemakhem et al. (2020b) and compute an
average MCC score between samples of latent variables recovered by different models trained with
different random initialization. As shown in Fig. 2g, it is evident that the MCC score for NF-iVAE
greatly outperforms the others, showing that the latent variables recovered by NF-iVAE have much
better identifiability.
Furthermore, we demonstrate the ability of iCaRL to discover the causal latent variables (Phase 2) by
visualizing the generated images through performing intervention upon a causal latent variable and a
non-causal latent variable, respectively. Fig. 2h shows how intervening upon each of them affects the
image. Obviously, intervening on a causal latent variable affects the shape of the digit but not its color
8
Published as a conference paper at ICLR 2022
Table 1: Colored Fashion MNIST. Comparisons in Table 2: VLCS. Comparisons in terms of accuracy
terms of accuracy (%) (mean ± std deviation).	(%) (mean ± std deviation).
METHOD	TRAIN	TEST	METHOD	TEST
ERM	83.17 ± 1.01	22.46 ± 0.68	ERM	77.4 ± 0.3
ERM 1	81.33 ± 1.35	33.34 ± 8.85	IRM	78.1 ± 0.0
ERM 2	84.39 ± 1.89	13.16 ± 0.82	DRO (SagaWa et al., 2019)	77.2 ± 0.6
ROBUST MIN MAX	82.81 ± 0.11	29.22 ± 8.56	MixuP (Yan et al., 2020)	77.7 ± 0.4
F-IRM GAME	62.31 ± 2.35	69.25 ± 5.82	CORAL (Sun & Saenko, 2016)	77.7 ± 0.5
V-IRM GAME	68.96 ± 0.95	70.19 ± 1.47	MMD (Li et al., 2018b)	76.7 ± 0.9
IRM	75.01 ± 0.25	55.25 ± 12.42	DANN (Ganin et al., 2016)	78.7 ± 0.3
iCaRL (ours)	74.96 ± 0.37	73.61 ± 0.63	C-DANN (Li et al., 2018c)	78.2 ± 0.4
ERM GRAYSCALE	74.79 ± 0.37	74.67 ± 0.48	LaCIM (Sun et al., 2020)	78.4 ± 0.5
OPTIMAL	75	75	iCaRL (ours)	81.8 ± 0.6
(top plots), whilst intervening on a non-causal latent variable, which is an effect in Fig. 2h, affects the
color of the digit only (bottom plots). This visually verifies the results of iCaRL in Phase 2.
In terms of the OOD generalization performance, we compare iCaRL with 1) IRM, 2) two variants
of IRMG: F-IRM Game (with Φ fixed to the identity) and V-IRM Game (with a variable Φ), 3)
three variants of ERM: ERM (on entire training data), ERM e (on each environment e), and ERM
GRAYSCALE (on data with no spurious correlations), and 4) ROBUST MIN MAZ (minimizing the
maximum loss across the multiple environments). Table 1 shows that iCaRL outperforms all other
baselines on CFMNIST. It is worth emphasising that the train and test accuracies of iCaRL closely
approach the ones of ERM GRAYSCALE and OPTIMAL, implying that iCaRL approximately learns
the true invariant causal representations with almost no correlation with the spurious color feature.
We can draw similar conclusions from the results on CMNIST (Appendix L).
We also report the results on one of the widely used realistic datasets for OOD generalization: VLCS
(Fang et al., 2013). This dataset consists of 10, 729 photographic images of dimension (3, 224, 224)
and 5 classes from four domains: Caltech101, LabelMe, SUN09, and VOC2007. We used the
exact experimental setting that is described in Gulrajani & Lopez-Paz (2020). We provide results
averaged over all possible train and test environment combination for one of the commonly used
hyper-parameter tuning procedure: train domain validation. As shown in Table 2, iCaRL achieves
state-of-the-art performance when compared to those most popular domain generalization alternatives.
We further include experimental evidence on another popular dataset: PACS (Li et al., 2017a), all the
details of which are placed in Appendix L.
6	Related Work
Invariant Causal Prediction (ICP), aims to find the causal feature set (i.e., all direct causes of a
target variable of interest) (Peters et al., 2015) by exploiting the invariance property in causality
which has been discussed under the term “autonomy”, “modularity”, and “stability” (Haavelmo,
1944; Aldrich,1989; Hoover,1990; Pearl, 2009; DaWid et al., 2010; ScholkoPfet al., 2012). This
invariance property assumed in ICP and its nonlinear extension (Heinze-Deml et al., 2018) is limited,
because no intervention is alloWed on the target variable Y . Besides, ICP methods imPlicitly assume
that the variables of interest Z are given. The Works of Magliacane et al. (2018) and SubbasWamy
et al. (2019) attemPt to find invariant Predictors that are maximally Predictive using conditional
indePendence tests and other graPh-theoretic tools, both of Which also assume that the Z are given
and further assume that additional information about the structure over Z is knoWn. Mitrovic et al.
(2020) analyze data augmentations in self-suPervised learning from the PersPective of invariant causal
mechanisms. Arjovsky et al. (2019) reformulate this invariance as an oPtimization-based Problem,
alloWing us to learn an invariant data rePresentation from X constrained to be a linear transformation
of Z. The risks of this aPProach have been discussed in Rosenfeld et al. (2020); Kamath et al. (2021);
Nagarajan et al. (2020) and its samPle comPlexity is analyzed in Ahuja et al. (2020b).
Another line of related Work is in the field of domain generalization, Which We discuss in APPendix A.
7	Conclusion
We have ProPosed a novel frameWork to learn invariant Predictors from a diverse set of training
environments. It is based on a Practical and general assumPtion: the Prior over the data rePresentation
belongs to a general exPonential family When conditioning on the target and the environment. This
assumPtion leads to guarantees that the comPonents in the rePresentation can be identified uP to a
Permutation and simPle transformation. This alloWs us to discover all the direct causes of the target,
Which enables generalization guarantees in the nonlinear setting. We hoPe our frameWork Will insPire
neW Ways to address the OOD generalization Problem through a causal lens.
9
Published as a conference paper at ICLR 2022
Acknowledgements
We are thankful to Wenlin Chen for contributing to Step III in the proof of Theorem 4 and for
generalizing the proof in Theorem 5 to the case in which each Ti(Zi) in Tf (Z) contains arbitrary
sufficient statistics instead of just Zi and Z2. We also thank Ilyes Khemakhem, AaPo Hyvarinen,
and Arthur Gretton for their helpful discussions, and the anonymous reviewers for their constructive
comments on an earlier version of this PaPer.
References
Mardn Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen, Craig Citro, Greg S.
Corrado, Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Ian Goodfellow, Andrew
HarP, Geoffrey Irving, Michael Isard, Yangqing Jia, Rafal Jozefowicz, Lukasz Kaiser, Manjunath
Kudlur, Josh Levenberg, Dandelion Mane, Rajat Monga, Sherry Moore, Derek Murray, Chris Olah,
Mike Schuster, Jonathon Shlens, Benoit Steiner, Ilya Sutskever, Kunal Talwar, Paul Tucker, Vincent
Vanhoucke, Vijay Vasudevan, Fernanda Viegas, Oriol Vinyals, Pete Warden, Martin Wattenberg,
Martin Wicke, Yuan Yu, and Xiaoqiang Zheng. TensorFlow: Large-scale machine learning on
heterogeneous systems, 2015. URL https://www.tensorflow.org/. Software available
from tensorflow.org.
Kartik Ahuja, Karthikeyan Shanmugam, Kush Varshney, and Amit Dhurandhar. Invariant risk
minimization games. arXiv preprint arXiv:2002.04692, 2020a.
Kartik Ahuja, Jun Wang, Amit Dhurandhar, Karthikeyan Shanmugam, and Kush R Varshney.
EmPirical or invariant risk minimization? a samPle comPlexity PersPective. arXiv preprint
arXiv:2010.16412, 2020b.
Kartik Ahuja, Ethan Caballero, Dinghuai Zhang, Yoshua Bengio, Ioannis Mitliagkas, and Irina Rish.
Invariance PrinciPle meets information bottleneck for out-of-distribution generalization. arXiv
preprint arXiv:2106.06607, 2021.
John Aldrich. Autonomy. Oxford Economic Papers, 41(1):15-34, 1989.
MarHn Arjovsky. Out of distribution generalization in machine learning. CoRR, abs/2103.02667,
2021.
Martin Arjovsky, Leon Bottou, Ishaan Gulrajani, and David LoPez-Paz. Invariant risk minimization.
arXiv preprint arXiv:1907.02893, 2019.
Yogesh Balaji, Swami Sankaranarayanan, and Rama ChellaPPa. Metareg: Towards domain gen-
eralization using meta-regularization. Advances in Neural Information Processing Systems, 31:
998-1008, 2018.
Sara Beery, Grant Van Horn, and Pietro Perona. Recognition in terra incognita. In Proceedings of the
European Conference on Computer Vision (ECCV), PP. 456-473, 2018.
Shai Ben-David, John Blitzer, Koby Crammer, Fernando Pereira, et al. Analysis of rePresentations
for domain adaPtation. Advances in neural information processing systems, 19:137, 2007.
Shai Ben-David, John Blitzer, Koby Crammer, Alex Kulesza, Fernando Pereira, and Jennifer Wortman
Vaughan. A theory of learning from different domains. Machine learning, 79(1):151-175, 2010.
Yoshua Bengio, Aaron Courville, and Pascal Vincent. RePresentation learning: A review and new
PersPectives. IEEE transactions on pattern analysis and machine intelligence, 35(8):1798-1828,
2013.
Pierre Comon. IndePendent comPonent analysis, a new concePt? Signal processing, 36(3):287-314,
1994.
Koby Crammer, Michael Kearns, and Jennifer Wortman. Learning from multiPle sources. Journal of
Machine Learning Research, 9(8), 2008.
Povilas Daniusis, Dominik Janzing, Joris Mooij, Jakob Zscheischler, Bastian Steudel, Kun Zhang,
and Bernhard Scholkopf. Inferring deterministic causal relations. arXiv preprint arXiv:1203.3475,
2012.
10
Published as a conference paper at ICLR 2022
A Philip Dawid, Vanessa Didelez, et al. Identifying the consequences of dynamic treatment strategies:
A decision-theoretic overview. Statistics Surveys, 4:184-231, 2010.
Zhengming Ding and Yun Fu. Deep domain generalization with structured low-rank constraint. IEEE
Transactions on Image Processing, 27(1):304-313, 2017.
Qi Dou, Daniel C Castro, Konstantinos Kamnitsas, and Ben Glocker. Domain generalization via
model-agnostic learning of semantic features. arXiv preprint arXiv:1910.13580, 2019.
Sarah Erfani, Mahsa Baktashmotlagh, Masud Moshtaghi, Xuan Nguyen, Christopher Leckie, James
Bailey, and Rao Kotagiri. Robust domain generalisation by enforcing distribution invariance. In
Proceedings of the Twenty-Fifth International Joint Conference on Artificial Intelligence (IJCAI-
16), pp. 1455-1461. AAAI Press, 2016.
Chen Fang, Ye Xu, and Daniel N Rockmore. Unbiased metric learning: On the utilization of multiple
datasets and web images for softening bias. In Proceedings of the IEEE International Conference
on Computer Vision, pp. 1657-1664, 2013.
Jos6 AR Fonollosa. Conditional distribution variability measures for causality detection. In Cause
Effect Pairs in Machine Learning, pp. 339-347. Springer, 2019.
Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo Larochelle, FrangOiS
Laviolette, Mario Marchand, and Victor Lempitsky. Domain-adversarial training of neural networks.
The Journal of Machine Learning Research, 17(1):2096-2030, 2016.
Muhammad Ghifary, W. Bastiaan Kleijn, Mengjie Zhang, and David Balduzzi. Domain generalization
for object recognition with multi-task autoencoders. In ICCV, pp. 2551-2559. IEEE Computer
Society, 2015.
Ishaan Gulrajani and David Lopez-Paz. In search of lost domain generalization. arXiv preprint
arXiv:2007.01434, 2020.
Trygve Haavelmo. The probability approach in econometrics. Econometrica: Journal of the
Econometric Society, pp. iii-115, 1944.
Christina Heinze-Deml, Jonas Peters, and Nicolai Meinshausen. Invariant causal prediction for
nonlinear models. Journal of Causal Inference, 6(2), 2018.
Kevin D Hoover. The logic of causal inference: Econometrics and the conditional analysis of
causation. Economics & Philosophy, 6(2):207-234, 1990.
Patrik O Hoyer, Dominik Janzing, Joris M Mooij, Jonas Peters, and Bernhard Scholkopf. Nonlinear
causal discovery with additive noise models. In Advances in neural information processing systems,
pp. 689-696, 2009.
Biwei Huang, Kun Zhang, Jiji Zhang, Joseph Ramsey, Ruben Sanchez-Romero, Clark Glymour,
and Bernhard Scholkopf. Causal discovery from heterogeneous/nonstationary data. Journal of
Machine Learning Research, 21(89):1-53, 2020.
Aapo Hyvarinen. Estimation of non-normalized statistical models by score matching. Journal of
Machine Learning Research, 6(4), 2005.
Aapo Hyvarinen and Erkki Oja. Independent component analysis: algorithms and applications.
Neural networks, 13(4-5):411-430, 2000.
Aapo Hyvarinen, Hiroaki Sasaki, and Richard Turner. Nonlinear ICA using auxiliary variables and
generalized contrastive learning. In The 22nd International Conference on Artificial Intelligence
and Statistics, pp. 859-868, 2019.
Dominik Janzing, Joris Mooij, KUn Zhang, Jan Lemeire, Jakob Zscheischler, Povilas Daniusis,
Bastian Steudel, and Bernhard Scholkopf. Information-geometric approach to inferring causal
directions. Artificial Intelligence, 182:1-31, 2012.
Pritish Kamath, Akilesh Tangella, Danica J Sutherland, and Nathan Srebro. Does invariant risk
minimization capture invariance? arXiv preprint arXiv:2101.01134, 2021.
11
Published as a conference paper at ICLR 2022
Ilyes Khemakhem, Diederik Kingma, Ricardo Monti, and AaPo Hyvarinen. Variational autoencoders
and nonlinear ICA: A unifying framework. In International Conference on Artificial Intelligence
and Statistics,pp. 2207-2217, 2020a.
Ilyes Khemakhem, Ricardo Monti, Diederik Kingma, and AaPo Hyvarinen. Ice-beem: Identifiable
conditional energy-based deep models based on nonlinear ica. Advances in Neural Information
Processing Systems, 33, 2020b.
Diederik P Kingma and Max Welling. Auto-encoding variational bayes. arXiv preprint
arXiv:1312.6114, 2013.
Da Li, Yongxin Yang, Yi-Zhe Song, and Timothy M Hospedales. Deeper, broader and artier domain
generalization. In Proceedings of the IEEE international conference on computer vision, pp.
5542-5550, 2017a.
Da Li, Yongxin Yang, Yi-Zhe Song, and Timothy Hospedales. Learning to generalize: Meta-learning
for domain generalization. In Proceedings of the AAAI Conference on Artificial Intelligence,
volume 32, 2018a.
Da Li, Jianshu Zhang, Yongxin Yang, Cong Liu, Yi-Zhe Song, and Timothy M Hospedales. Episodic
training for domain generalization. In Proceedings of the IEEE/CVF International Conference on
Computer Vision, pp. 1446-1455, 2019a.
Haoliang Li, Sinno Jialin Pan, Shiqi Wang, and Alex C Kot. Domain generalization with adver-
sarial feature learning. In Proceedings of the IEEE Conference on Computer Vision and Pattern
Recognition, pp. 5400-5409, 2018b.
Wen Li, Zheng Xu, Dong Xu, Dengxin Dai, and Luc Van Gool. Domain generalization and adaptation
using low rank exemplar svms. IEEE transactions on pattern analysis and machine intelligence,
40(5):1114-1127, 2017b.
Ya Li, Xinmei Tian, Mingming Gong, Yajing Liu, Tongliang Liu, Kun Zhang, and Dacheng Tao.
Deep domain generalization via conditional invariant adversarial networks. In Proceedings of the
European Conference on Computer Vision (ECCV), pp. 624-639, 2018c.
Yiying Li, Yongxin Yang, Wei Zhou, and Timothy Hospedales. Feature-critic networks for heteroge-
neous domain generalization. In International Conference on Machine Learning, pp. 3915-3924.
PMLR, 2019b.
Francesco Locatello, Stefan Bauer, Mario Lucic, Gunnar Raetsch, Sylvain Gelly, Bernhard Scholkopf,
and Olivier Bachem. Challenging common assumptions in the unsupervised learning of dis-
entangled representations. In international conference on machine learning, pp. 4114-4124,
2019.
Sara Magliacane, Thijs van Ommen, Tom Claassen, Stephan Bongers, Philip Versteeg, and Joris M
Mooij. Domain adaptation by using causal inference to predict invariant conditional distributions.
In Advances in Neural Information Processing Systems, pp. 10846-10856, 2018.
Massimiliano Mancini, Samuel Rota Bulb, Barbara Caputo, and Elisa Ricci. Best sources forward:
domain generalization through source-specific nets. In 2018 25th IEEE international conference
on image processing (ICIP), pp. 1353-1357. IEEE, 2018.
Jovana Mitrovic, Brian McWilliams, Jacob Walker, Lars Buesing, and Charles Blundell. Representa-
tion learning via invariant causal mechanisms. arXiv preprint arXiv:2010.07922, 2020.
Saeid Motiian, Marco Piccirilli, Donald A. Adjeroh, and Gianfranco Doretto. Unified deep supervised
domain adaptation and generalization. In ICCV, pp. 5716-5726. IEEE Computer Society, 2017.
Krikamol Muandet, David Balduzzi, and Bernhard Scholkopf. Domain generalization via invariant
feature representation. In ICML, volume 28 of JMLR Workshop and Conference Proceedings, pp.
10-18, 2013.
Vaishnavh Nagarajan, Anders Andreassen, and Behnam Neyshabur. Understanding the failure modes
of out-of-distribution generalization. arXiv preprint arXiv:2010.15775, 2020.
12
Published as a conference paper at ICLR 2022
Li Niu, Wen Li, and Dong Xu. Multi-view domain generalization for visual recognition. In
Proceedings ofthe IEEE international conference on computer vision, pp. 4193-4201, 2015.
Sinno Jialin Pan and Qiang Yang. A survey on transfer learning. IEEE Transactions on knowledge
and data engineering, 22(10):1345-1359, 2009.
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor
Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas Kopf, Edward
Yang, Zachary DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner,
Lu Fang, Junjie Bai, and Soumith Chintala. Pytorch: An imperative style, high-performance
deep learning library. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alch6-Buc, E. Fox, and
R. Garnett (eds.), Advances in Neural Information Processing Systems 32, pp. 8024-8035. Curran
Associates, Inc., 2019.
Vishal M Patel, Raghuraman Gopalan, Ruonan Li, and Rama Chellappa. Visual domain adaptation:
A survey of recent advances. IEEE signal processing magazine, 32(3):53-69, 2015.
Judea Pearl. Causality. Cambridge university press, 2009.
Jonas Peters, Peter Buhlmann, and Nicolai Meinshausen. Causal inference using invariant prediction:
identification and confidence intervals. arXiv preprint arXiv:1501.01332, 2015.
Jonas Peters, Dominik Janzing, and Bernhard Scholkopf. Elements of causal inference. The MIT
Press, 2017.
Danilo Jimenez Rezende, Shakir Mohamed, and Daan Wierstra. Stochastic backpropagation and
approximate inference in deep generative models. arXiv preprint arXiv:1401.4082, 2014.
M. Rojas-Carulla, B. Scholkopf, R. Turner, and J. Peters. Invariant models for causal transfer learning.
Journal of Machine Learning Research, 19(36):1-34, 2018.
Elan Rosenfeld, Pradeep Ravikumar, and Andrej Risteski. The risks of invariant risk minimization.
arXiv preprint arXiv:2010.05761, 2020.
Shiori Sagawa, Pang Wei Koh, Tatsunori B Hashimoto, and Percy Liang. Distributionally robust
neural networks for group shifts: On the importance of regularization for worst-case generalization.
arXiv preprint arXiv:1911.08731, 2019.
B. Scholkopf, D. Janzing, J. Peters, E. Sgouritsa, K. Zhang, and J. M. Mooij. On causal and anticausal
learning. In Proceedings of the 29th International Conference on Machine Learning (ICML), pp.
1255-1262, 2012.
Lukas Schott, Jonas Rauber, Matthias Bethge, and Wieland Brendel. Towards the first adversarially
robust neural network model on mnist. arXiv preprint arXiv:1805.09190, 2018.
Peter Spirtes, Clark N Glymour, Richard Scheines, and David Heckerman. Causation, prediction,
and search. MIT press, 2000.
Amos Storkey. When Training and Test Sets Are Different: Characterizing Learning Transfer. 2009.
Adarsh Subbaswamy, Bryant Chen, and Suchi Saria. A universal hierarchy of shift-stable distributions
and the tradeoff between stability and performance. arXiv preprint arXiv:1905.11374, 2019.
Baochen Sun and Kate Saenko. Deep coral: Correlation alignment for deep domain adaptation. In
European conference on computer vision, pp. 443-450. Springer, 2016.
Xinwei Sun, Botong Wu, Chang Liu, Xiangyu Zheng, Wei Chen, Tao Qin, and Tie-yan Liu. Latent
causal invariant model. arXiv preprint arXiv:2011.02203, 2020.
Hemanth Venkateswara, Jose Eusebio, Shayok Chakraborty, and Sethuraman Panchanathan. Deep
hashing network for unsupervised domain adaptation. In Proceedings of the IEEE Conference on
Computer Vision and Pattern Recognition, pp. 5018-5027, 2017.
Pascal Vincent. A connection between score matching and denoising autoencoders. Neural computa-
tion, 23(7):1661-1674, 2011.
13
Published as a conference paper at ICLR 2022
Julius Von Kugelgen, Yash Sharma, LUigi Gresele, Wieland Brendel, Bernhard Scholkopf, Michel
Besserve, and Francesco Locatello. Self-supervised learning with data augmentations provably
isolates content from style. arXiv preprint arXiv:2106.04619, 2021.
J. von Kugelgen, A. Mey, M. Loog, and B. Scholkopf. Semi-supervised learning, causality and the
conditional cluster assumption. Conference on Uncertainty in Artificial Intelligence (UAI), 2020.
Changzhang Wang, You Zhou, Qiang Zhao, and Zhi Geng. Discovering and orienting the edges
connected to a target variable in a dag via a sequential local learning approach. Computational
Statistics & Data Analysis, 77:252-266, 2014.
Haohan Wang, Aaksha Meghawat, Louis-Philippe Morency, and Eric P Xing. Select-additive
learning: Improving generalization in multimodal sentiment analysis. In 2017 IEEE International
Conference on Multimedia and Expo (ICME), pp. 949-954. IEeE, 2017.
Haohan Wang, Zexue He, Zachary C Lipton, and Eric P Xing. Learning robust representations by
projecting superficial statistics out. arXiv preprint arXiv:1903.06256, 2019.
Garrett Wilson and Diane J Cook. A survey of unsupervised deep domain adaptation. ACM
Transactions on Intelligent Systems and Technology (TIST), 11(5):1T6, 2020.
Sewall Wright. Correlation and causation. J. agric. Res., 20:557-580, 1921.
Shen Yan, Huan Song, Nanxiang Li, Lincan Zou, and Liu Ren. Improve unsupervised domain
adaptation with mixup training. arXiv preprint arXiv:2001.00677, 2020.
Kun Zhang, Jonas Peters, Dominik Janzing, and Bernhard Scholkopf. Kernel-based conditional
independence test and application in causal discovery. arXiv preprint arXiv:1202.3775, 2012.
Kun Zhang, Bernhard Scholkopf, Krikamol Muandet, and Zhikun Wang. Domain adaptation under
target and conditional shift. In International Conference on Machine Learning, pp. 819-827.
PMLR, 2013.
Kun Zhang, Mingming Gong, and Bernhard Scholkopf. Multi-source domain adaptation: A causal
view. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 29, 2015.
Kun Zhang, Biwei Huang, Jiji Zhang, Clark Glymour, and Bernhard Scholkopf. Causal discovery
from nonstationary/heterogeneous data: Skeleton estimation and orientation determination. In
IJCAI: Proceedings of the Conference, volume 2017, pp. 1347. NIH Public Access, 2017.
Han Zhao, Remi Tachet Des Combes, Kun Zhang, and Geoffrey Gordon. On learning invariant
representations for domain adaptation. In International Conference on Machine Learning, pp.
7523-7532. PMLR, 2019.
14
Published as a conference paper at ICLR 2022
A Domain Generalization
The goal of domain generalization (DG) (Muandet et al., 2013) is OOD generalization: learning a
predictor that performs well at unseen test domains. Unlike domain adaptation (Pan & Yang, 2009;
Ben-David et al., 2007; 2010; Crammer et al., 2008; Patel et al., 2015; Zhao et al., 2019; Wilson
& Cook, 2020; Zhang et al., 2015), DG assumes that the test domain data are not available during
training. One thread of DG is to explore techniques from kernel methods (Muandet et al., 2013;
Niu et al., 2015; Erfani et al., 2016; Li et al., 2017b). Muandet et al. (2013) propose a kernel-based
optimization algorithm that learns an invariant transformation by minimizing the discrepancy among
domains and preventing the loss of relationship between input and output features. Another line ofDG
work is using end-to-end methods from deep learning: (a) reducing the differences of representations
across domains through adversarial or similar techniques (Ghifary et al., 2015; Wang et al., 2017;
Motiian et al., 2017; Li et al., 2018b;c); (b) projecting out superficial domain-specific statistics to
reduce sensitivity to the domain (Wang et al., 2019); (c) fusing representations from an ensemble of
models across domains (Ding & Fu, 2017; Mancini et al., 2018). Meta-learning can also be applied to
domain generalization, by dividing source domains into meta-training and meta-test sets, and aiming
for a low generalization error on meta-test sets after training on meta-training sets (Balaji et al., 2018;
Dou et al., 2019; Li et al., 2018a; 2019a;b). Recently, an extensive empirical survey of many DG
algorithm (Gulrajani & Lopez-Paz, 2020) suggested that with current models and data augmentation
techniques, plain ERM may be competitive with the state-of-the-art. It is worth noting that Sun
et al. (2020) also propose an approach to learning latent causal factors for prediction. However, their
assumptions over the underlying causal graph are restricted due to two reasons: 1) they only consider
the scenarios when Z and Y are generated concurrently, which excludes the cases in which some part
of Z could also be affected by Y in some manner; 2) They assume that the causal latent factors Zp
and the non-causal latent factors Zc are independent when conditioning on E, that is, Zp ⊥⊥ Zc |E .
In practice, during model learning, they actually further assume that Zi ⊥⊥ Zj |E for any i 6= j so
that VAE could be leveraged to learn the model. In this sense, their approach has the same issue as
the one in iVAE, i.e., unable to deal with the non-factorized cases. This point is also verified in Table
2, where our approach greatly outperforms theirs.
B Variational Autoencoders
We briefly describe the framework of variational autoencoders (VAEs), which allows us to efficiently
learn deep latent-variable models and their corresponding inference models (Kingma & Welling,
2013; Rezende et al., 2014). Consider a simple latent variable model where X ∈ Rd stands for an
observed variable and Z ∈ Rn for a latent variable. A VAE method learns a full generative model
Pθ(X, Z) = pθ(X|Z)pe(Z) and an inference model qφ(Z|X), typically a factorized Gaussian
distribution whose mean and variance parameters are given by the output of a neural network
with input X. This inference model approximates the posterior pθ(Z|X), where θ is a vector of
parameters of the generative model, φ a vector of parameters of the inference model, and pθ (Z)
is a prior distribution over the latent variables. Instead of maximizing the data log-likelihood, we
maximize its lower bound LVAE(θ, φ):
logPθ(X) ≥ Lvae(θ, Φ) ：= Eqφ(z∣x) [logPθ(XZ)] - KL (qφ(Z∣X)l∣Pθ(Z)),
where We have used Jensen,s inequality, and KL(∙∣∣∙) denotes the Kullback-Leibler divergence
between two distributions.
C Derivation
C.1 IVAE
In Section 2.1, the evidence lower bound of iVAE is defined by
LiVAE(θ, Φ) =EpD [Eqφ(z∣x,u) [logPf (X|Z)] - KL (qφ(Z|X, U)∣∣Pτ,λ(Z|U))]
=EpD [Eqφ(z∣χ,u)[logpf (X|Z)+logpτ,λ(Z|U) - log qφ(Z|X, U)]].
15
Published as a conference paper at ICLR 2022
∂2pτ ,λ(Z∣Y, E) + 1 ( ∂pτ ,λ(Z∣Y, E) Y
∂Zj	+2∖	∂Zj	)
+ const.
C.2 Score Matching
In Section 4.1, we follow HyVarinen (2005) and use a simple trick of partial integration to simplify
the evaluation of the score matching objective LpShMase1 in Eq. (10) of the main text:
LpMSeI(T, λ) =EpD ∣Eqφ(zχ,γ,E) [||VZ logqφ(ZX, Y, E) -Vz logPT,λ(Z|Y, E)∣∣[]
n
=EpD Eqφ(ZX,Y,E)	£
j=1
where the last equality is due to the Theorem 1 in HyVarinen (2005).
D	Definitions for SEM and IRM
Definition 2. A structural equation model (SEM) M := (S, N) governing the random vector
Z = (Z1, . . . , Zd) is a set of structural equations:
Si ： Zi J fi(Pa(Zi),Ni),
where Pa(Zi) ⊆ {Z1, . . . , Zd} \ {Zi} are called the parents of Zi, and the Ni are independent noise
random variables. We say that “Zi causes Zj ” if Zi ∈ Pa(Zj). We call causal graph of Z to the
graph obtained by drawing i) one node for each Zi, and ii) one edge from Zi to Zj if Zi ∈ Pa(Zj ).
We assume acyclic causal graphs.
Definition 3. Consider a SEM M := (S, N). An intervention e on M consists of replacing one or
several of its structural equations to obtain an intervened SEM Me := (Se, Ne), with structural
equations:
Sie : Zie J fie(Pae(Zie),Nie),
The variable Ze is intervened if Si 6= Sie or Ni 6= Nie.
Definition 4. Consider a structural equation model (SEM) S governing the random vector
(Z1, . . . , Zn, Y ), and the learning goal of predicting Y from Z. Then, the set of all environ-
ments Eall (S) indexes all the interventional distributions P(Ze, Y e) obtainable by valid interven-
tions e. An intervention e ∈ Eall (S) is valid as long as (i) the causal graph remains acyclic, (ii)
E [Y e |Pa(Y )] = E [Y |Pa(Y )], and (iii) V [Y e|Pa(Y )] remains within a finite range.
E Definitions and Lemmas for the Exponential Families
Definition 5. (Exponential family) A multivariate exponential family is a set of distributions whose
probability density function can be written as
P(Z) = QZ) exp(hT(Z), θi),	(13)
C (θ)
where Q : Z → R is the base measure, C(θ) is the normalizing constant, T : Z → Rk is the
sufficient statistics, andθ ∈ Rk is the natural parameter. The size k ≥ n is the dimension of the
sufficient statistics T and depends on the latent space dimension n. Note that k is fixed given n.
Definition 6. (Strongly exponential distributions) A multivariate exponential family distribution
P(Z) = QZ) exp(hT(Z), θi)	(14)
C (θ)
is strongly exponential, if
(∃θ∈ Rk	s.t. hT(Z),θi	= const,	∀Z ∈	Z)	=⇒	(l(Z) = 0orθ=	0),	∀Z ⊂	Rn,	(15)
where l is the Lebesgue measure.
The density of a strongly exponential distribution has almost surely the exponential component and
can only be reduced to the base measure on a set of measure zero. Note that all common multiVariate
exponential family distributions (e.g. multiVariate Gaussian) are strongly exponential.
F Definitions for Identifiability
Definition 7. Let Θ be the domain of the parameters θ = {f, T, λ}. Let 〜be an equivalence
relation on Θ. A deep generative model is said to be 〜-identifiable if
.. .. ~
Pθ (X )= Pθ(X) =⇒ θ 〜θ.
(16)
16
Published as a conference paper at ICLR 2022
(h)
(g)
(i)
(j)
Figure 3: (a) General causal structure over {Xi, Y , X, E}, where the arrow from Zi to X is a
must-have connection and the other four might not be necessary. (b) Ten possible causal structures
from (a) under Assumptions 1&2.
E
Y
X
(f)
Y
X
(k)
E
The elements in the quotient space Θ∖ 〜are called the identifiability classes.
Definition 8. Let 〜A be an equivalence relation on Θ defined by:
. . .~ ~ ~ . . -1 . . . . ~ . ~ -1 . ..
(f,T, λ)〜A	(f,T, λ)	0 ∃A, C s.t.	T (f-1(X ))	=	AT1(f-1(X)) + G	∀X	∈ O,	(17)
where A ∈ Rk×k is an invertible matrix and c ∈ Rk is a vector.
Definition 9. Let 〜P be an equivalence relation on Θ defined by:
. . .~ ~ ~ . . -1 . ~ , ~ -1 .
(f,T, λ)〜P (f,T, λ) 0 ∃P, C s.t. T (f-1(X )) = P T(f-1 (X))+ C, ∀X ∈O,	(18)
where P ∈ Rk×k is a block permutation matrix and c ∈ Rk is a vector.
G	Phase 2: Discovering S ingle Cause
G.1 Some Special Cases in Multi-Cause Settings
These conditional independence tests can be performed in parallel to largely accelerate the testing
procedure. Note that, in practice, it might occur that there exist some Zi which is independent of
any other Zj when conditioning on Y and E . It is probably because such Zi is a deterministic
transformation of Y . In this special case, we can use IGCI (Daniusis et al., 2012; Janzing et al.,
2012) to determine whether or not Zi is a cause of Y . Also note that, in some scenarios in which
the dependence signals between a pair of causal latent variables might be weak due to the data issue,
we can test the conditional independence of such a latent variable with all the other causal latent
variables. If it is conditionally dependent on more than half of them or its average p-value is larger
than the pre-specified threshold, we will select it as one cause of Y .
G.2 Discovering Single Cause
In the single-cause case, by following Wang et al. (2014), we leverage the MB-by-MB algorithm to
first construct a local structure around Y and then discover the single parent of Y according to the
constructed local graph. One obvious advantage of this approach is in efficiency, because there is no
need to construct the whole causal graph containing all the latent variables and Y .
We could have an even more efficient solution to the single-cause case in some special scenarios
where we assume that Zi ⊥⊥ Zj |Y , E for any i 6= j . In fact, this assumption covers more scenarios
than the common assumption that Zi ⊥⊥ Zj for i 6= j in latent variable models, e.g., disentanglement
(Bengio et al., 2013; Locatello et al., 2019), autoencoders (Kingma & Welling, 2013; Rezende et al.,
2014), ICA (Comon,1994; HyVarinen & Oja, 2000), etc. If Y is caused by at most one of Zi and
Zj , and no matter whether Zi and Zj are caused by E or not, then Zi ⊥⊥ Zj |Y, E holds, but we
may well haVe Zi ⊥6⊥ Zj (e.g., if Y causes both Zi and Zj, or if there is a chain Zi → Y → Zj). If
Y causes or is caused by at most one of Zi and Zj , and at most one of Zi and Zj is caused by E,
then both Zi ⊥⊥ Zj and Zi ⊥⊥ Zj | Y, E hold. If {Y, Z%, Zj} form a collider Zi → Y — Zj, and no
matter whether Zi and Zj are caused by E or not, then Zi ⊥⊥ Zj |E hold, but we may haVe Zi ⊥6⊥ Zj
(e.g., when both Zi and Zj are caused by E).
17
Published as a conference paper at ICLR 2022
Under this assumption, we are able to separately look into each Zi given Y and E, without consider-
ing any other Zj . Fig. 5a shows that there exist only five possible connections between Zi , Y , E,
and X . Among them, only the arrow from Zi to X must exist, because X is generated from Z. The
other four arrows might not be present, with the exception that there must be at least one connection
between Zi and Y or E (Assumption 1a). This leaves ten possible structures, shown in Figs. 3b-3k.
Given data {Zi, Y, E, X} in which the Zi are obtained using qφ(Z|X, Y, E) (for example, as
given by the mean of this distribution), we are able to distinguish all ten structures in Figs. 3b-3k
by using causal discovery algorithms (Peters et al., 2017; Zhang et al., 2017; Huang et al., 2020)
and performing conditional independence tests (Spirtes et al., 2000; Zhang et al., 2012). This is
summarized in Proposition 2 below. Its proof can be found in Appendix H, which also describes the
specific assumptions made. In practice, we can assess in parallel whether or not each Zi is a direct
cause of Y, which accelerates this phase significantly.
Proposition 2. Under the assumptions stated in Appendix H, the ten structures shown in Figs. 3b-3k
can be identified using causal discovery methods consistent in the infinite sample limit.
Note that there are only four cases in which Zi is a parent of Y (i.e., Figs. 3b, 3e, 3g, and 3j). We can
identify these by applying rules 1.2, 1.6, 2.1, and 3.1 from Appendix H.5.
H	Proofs
H.1 Proof of Theorem 1
The proof of this theorem consists of three parts.
In Part I, we prove that the parameters θ are 〜A identifiable (Definition 8) by using assumption (i),
the first half of assumption (ii), and assumption (iv) of Theorem 1.
In Part II, based on the result in Part I, we further prove that the parameters θ are 〜P identifiable
(Definition 9) by additionally using Assumption 2, the second half of assumption (ii) and assumption
(iii) of Theorem 1.
In Part III, we combine the results (Theorems 4&5) in both Part I and Part II into one theorem
(Theorem 1), which completes the proof.
It is worth noting that, compared to the proof in iVAE, the main changes in our proof consist of
• Part I, In step III.
-It has been updated to account for vectors of sufficient statistics whose entries can be
arbitrary functions of all entries in the random variable vector, while in the previous
proof the sufficient statistics contained entries that are functions of individual entries in
the random variable vector.
- The assumption of “The sufficient statistics in T are all linearly independent.” is not
required in our proof, but it is in the proof of iVAE.
• Part II.
- It has been updated to account for the part of the sufficient statistics which is the output
of a deep neural network with ReLU activation functions.
H.1.1 Part I
For notational simplicity, in the proof of this part we denote (Y, E) by U. Hence, our generative
model defined according to Eqs. (6-8) in the main text now becomes:
Pθ(X, Z|U) = Pf (X∣Z)pτ,λ(Z|U),	(19)
pf(X|Z) = p(X - f(Z)),	(20)
Pτ,λ(Z|U) = Q(Z)/C(U) exp [T(Z)Tλ(U)].	(21)
Theorem 4.	Suppose that we observe data sampled from a deep generative model defined according
to Eqs. (19-21) with parameters (f, T, λ). Assume that
(i)	The set {X ∈ O∣^ε(X ) = 0} has measure zero, where 夕 ε is the characteristic function of
the density pε defined in Eq. (20);
18
Published as a conference paper at ICLR 2022
(ii)	The mixing function f in Eq. (20) is injective;
(iii)	There exist k + 1 points U0, U1,…，Uk ∈ U such that the matrix
L = [λ(U1) - λ(U0),…，λ(Uk) - λ(U0)] ∈ Rk×k	(22)
is invertible.
Then the parameters {f, T, λ} are 〜A identifiable.
Proof. Define Vol(B) = ,det(BTB) for any full column rank matrix B. Suppose that We have two
.	_	，一 一 一、	-	~	z ~ ɪ ~ K	_	-	，__.__、	，__._、	.	. Z__、
sets of parameters θ = (f, T, λ) and θ = (f, T, λ) such that pθ (X |U) = pg(X |U), ∀(X, U) ∈
OXU. We want to show θ 〜A θ.
Step I. The proof of this step is similar to Step I in the proof of Theorem 1 in Khemakhem et al.
(2020a). We transform the equality of the marginal distributions over observed data into the equality
of noise-free distributions. For all pairs (X, U) ∈ O × U, we have
Pθ(X∣U)= pθ(X∣U)	(23)
T JJf (X∣Z)pτ,λ(Z∣U)dZ
=⇒ ]jε(X - f (Z))PT,λ(Z∣U)dZ
=⇒ P Pε(X - X)PT,λ(f-1(X)∣U) vol(Jf-1 (X))dX
O
=⇒ / Pε(X - X)Pf ,T ,λ,U (X)dX
Rd
=⇒ (Pf,T,λ,U * Pε)(X)
=⇒ F [pf ,T ,λ,U ](ω)夕 ε(ω)
=⇒ F[pf,T,λ,u](ω)
=⇒ pf,T,λ,U (X)
where
JJf(X∖Z)pτ,λ (Z∣U)dZ	(24)
]jε(X - f(Z))Pτ,λ(Z∣U)dZ	(25)
/ Pε(X - X)pt λ (f-1(X)∣U) vol(Jf-ι (XRdX
O
(26)
I Pε(X - X)Pf T λ U (X)dX	(27)
Rd
(P五T,λ,U * Pε)(X)	(28)
F[Pf,TK ,U ](ω)夕 ε(ω)	(29)
F [PfT,\,U ](ω)	(30)
Pf,T,λ U (X)	(31)
•	in Eq. (26), J denotes the Jacobian, and we made the change of variable X = f (Z) on the
left hand side, and X = f (Z) on the right hand side.
•	in Eq. (27), we introduced
Pf,t,λ,u(X) ,Pτ,λ(f-1(X)|U)vol(Jf-1 (X))Io(X)	(32)
on the left hand side, and similarly on the right hand side.
•	in Eq. (28), we used * for the convolution operator.
•	in Eq. (29), we used F[.] to designate the Fourier transform, and where 夕ε = F[pε] (by
definition of the characteristic function).
•	in Eq. (30), we dropped 夕ε(ω) from both sides as it is non-zero almost everywhere (by
assumption (i)).
Step II. In this step, we remove all terms that are either a function of X or U. First, by replacing
both sides of Eq. (31) by their corresponding expressions from Eq. (32), we have
Pτ,λ(fT(X )|U) vol(Jf-1 (X ))= Pτ,λ (f-1(X )|U) Vol(Jf-1 (X)).	(33)
Then, by taking logarithm on both sides of Eq. (33) and replacing pτ,λ by its expression from Eq.
(21), we obtain
logvol(Jf-1(X))+logQ(f-1(X))-logZ(U)+T(f-1(X)),λ(U)
=logVol(Jf-1 (X)) + log Q(f-1(X)) - log Z(U) + <T(f-1(X)),λ(U)) . (34)
Let U0, U1, •一，Uk ∈ U be the k + 1 points defined in assumption (iii). We evaluate the above
equation at these points to obtain k + 1 equations, and subtract the first equation from the remaining
19
Published as a conference paper at ICLR 2022
k equations to obtain:
〈T(f-1(X)), λ(Ul) - λ(U0)〉+ log ZU)
,	∖	7	0∖
Dτ(f-1(X)),λ(Ul) - λ(U0)E + log ZU),
l = 1,…，k. (35)
■	, TKFCF ∙	, ∙	∕∙ ∙ ∙∖	F? FC 1	∙	∙ 1	1 l' X ʌ τ ,	,1	, T ∙	∙	, ∙1 1	1
Let L be defined as in assumption (iii) and L defined similarly for λ. Note that L is invertible by
assumption, but L is not necessarily invertible. Letting b ∈ Rk in which bi = log Z(U 1)Z(U0), We
have
LTT(f-1(X)) =L7TT7(f7-1(X))+b.
(36)
Left multiplying both sides of the above equation by L-T gives
T(f-1(X)) =AT7(f7-1(X))+c,	(37)
where A = L-T L7 ∈ Rk×k and c = L-Tb ∈ Rk.
Step III. To complete the proof, we need to show that A is invertible. Let Zl ∈ Z , Xl =
f (Zi), l = O,…，k. We evaluate Eq. (37) at these k + 1 points to obtain k + 1 equations and
subtract the first equation from the remaining k equations to obtain
[T (Zι)- T (Z0),…，T (Zk) - T (Z0)]
、----------------V----------------}
,R∈Rk×k
A [T(f-1(Xι)) - T(f-1(X0)),…，T(f-1(Xk))- T(f-1(X0))]. (38)
|
}
{z
,R∈Rk×k
We need to show that for a given Z0 ∈ Z, there exist k points Zι, ∙∙∙ , Zk ∈ Z such that the columns
of R are linearly independent. Suppose, for contradiction, that the columns of R would never be
linearly independent for any choice of Zι,…，Zk ∈ Z. Then the function g(Z)，T(Z) - T(Z0)
would live in a k - 1 or lower dimensional subspace, and thus we could find a non-zero vector
λ ∈ Rk orthogonal to that subspace. This would imply that hT(Z) - T(Z0), λi = O and thus
hT(Z), λi = hT(Z0),λi = const, ∀Z ∈ Z, which contradicts the assumption that the prior
is strongly exponential (Definition 6). Therefore, we have shown that there exist k + 1 points
Z0, Zι, •一，Zk ∈ Z such that R is invertible. Since R = AR and A is not a function of Z, A must
□
be invertible. This completes the proof.
H.1.2 PART II
Theorem 5.	Suppose that all assumptions in Theorem 4 hold. Let the sufficient statistics
T(Z) = [Tf(Z)T, TNN(Z)T]T given by the concatenation of a) the sufficient statistics Tf(Z) =
[Tι(Zι)τ,…，Tn(Zn)T ]t ofafactorized exponential family, where all the Ti(Zi) have dimension
larger or equal to 2, and b) the output TNN(Z) of a neural network with ReLU activations. (note
that a neural network with ReLU activation has universal approximation power and should be able to
capture any dependencies of interest). Let k0 be the dimension of Tf and thus that k0 ≥ 2n. Assume
that
(i)	the sufficient statistics Tf have all second-order own derivatives;
(ii)	the mixing function f has all second-order cross derivatives.
Then the parameters {f, T, λ} are 〜P identifiable.
Proof. Let v = f7-1 ◦ f : Z → Z. Since all assumptions in Theorem 4 hold, we have
_________________________________________ . ~ , ________
T(Z) = AT7(v(Z)) +c,	(39)
where A ∈ Rk×k is invertible. We want to show that A is a block permutation matrix.
20
Published as a conference paper at ICLR 2022
Step I. In this step, we show that v is a componentwise function. First we differentiate both sides
of Eq. (39) with respect to Zs and Zt (s 6= t) to obtain
∂T(Z)	X ∂T(V(Z)) ∂vi(Z)
∂Zs = = ∂vi(Z)	∂zΓ
(40)
∂2T(Z) = A X X ∂2T(v(Z))	∂vj(Z)
∂Zs∂Zt	台 j=1 ∂vi(Z )∂vj (Z)	∂Zt
∂vi(Z) + A X ∂T(V(Z)) ∂2Vi(Z)
∂Zs + i=1 ∂vi(Z)	∂Zs∂Zt. ( )
-rʌ	,	1 1	FF	1	i' m F ΓTΓΛ	1 1	r-ɪ-ɪl	Γ∙	1
By construction, the second-order cross derivatives of T and T are all zero. Therefore, we have
n
AX
i=1
∂2T(v(Z)) ∂vi (Z) ∂vi(Z)
--: : ——•  :---- ---:---
∂vi(Z )2	∂Zt	∂Zs
n
+AX
i=1
∂T(v(Z))
∂vi(Z)
∂2Vi(Z)
∂Zs∂Zt
The above equation can be written in the matrix-vector form:
0 = AT'0(Z )vS,t(Z) + AT'(Z )vS0,t(Z),
where
T00 (Z=" ∂2T(v(Z))	∂ 2T(v(Z))
()=	∂vι(Z )2 ,…，∂vn(Z )2
×n
(42)
(43)
(44)
∈
V'0 ,t(Z) =	∂V1(Z) 	:		 ∂Zt		∂V1(Z) 	,• • • ∂Z',	∂Vn(Z) ∂Vn(Z) . :			:	 ,∂Zt	∂Zs		T ∈ Rn ,	(45)
and							
~. T0(Z)=		∂ T(v(Z )) 	:	:	.• • • ∂V1(Z),		∂ T(V(Z)) , ∂Vn(Z)	∈ Rk×n		(46)
V'00,t (Z) =			∂2V1(Z) -	:	.• ]∂Z'∂Zt ,	∂2Vn(Z) • ∙.-:	:	 ,∂Z'∂Zt	T ∈ Rn .		(47)
NoW by concatenating							
0
T000 (Z) = [T00(Z),T0(Z)] ∈ Rk×2n and v'[t(Z) = %t(Z)t, v'[t(Z)t]t ∈ R2n,	(48)
we obtain
0 = ΑT00o(Z )v'0,0t(Z).	(49)
Finally, we take the rows of T000(Z) that corresponds to the factorized strongly exponential family
distribution part and denote them by Tf0 (Z) ∈ Rk ×2n. By Lemma 5 in the iVAE paper (Khemakhem
et al., 2020a) and the assumption that k0 ≥ 2n, we have that the rank of Tf000(Z) is 2n. Since k ≥
k0 ≥ 2n, the rank of T000 (Z) is also 2n. Since the rank of A is k, the rank of ΑT00o(Z) ∈ Rk×2n is
2n. This implies that V'00,0t(Z) must be a zero vector. In particular, we have that V'0,t(Z) = 0, ∀s 6= t.
Therefore, we have shown that V is a componentwise function.
Step II. To complete the proof, we need to show that A is a block permutation matrix. With-
out loss of generality, we assume that the permutation in V is the identity. That is V(Z) =
[v1(Z1),…，Vn(Zn)]t for some nonlinear univariate scalar functions v1,…，Vn. Since f and
f are bijective, We have that V is also bijective and v-1(Z) = [v-1(Z1), ∙∙∙ , V-I(Zn)]t. We
denote T(V(Z)) = T(V(Z)) + A-1c and plug it into Eq. (39) to obtain T(Z) = AT(V(Z)).
Applying V-1 to the variables Z at both sides gives
T (VT (Z)) = AT(Z).	(50)
Let t be the index of an entry in the sufficient statistics T that corresponds to the the factorized
strongly exponential family distribution part Tf. For all s 6= t, We have
k
∂T (VT(Z))t
∂Z'
atj
∂T(Z).
j=1
∂Z'	.
(51)
γ-a ∙	.λ	. ∙	<~ rrt ι ∙	ι ∙ ι	ι ∕∙.λ	. ι ∙	ι ∙ ι	t ,	, 1 rrt	ι
Since the entries of T are linearly independent (if they Were not linearly independent, then T can be
compressed into a smaller vector by removing the redundant entries), We have that atj is zero for any
j such that dTZZ) j = 0. This includes the entries j in the sufficient statistics T that corresponds to 1)
the factorized strongly exponential family distribution part Which do not depend on Zt ; and 2) the
neural netWork part.
Σ

j
21
Published as a conference paper at ICLR 2022
Therefore, when t is the index of an entry in the sufficient statistics T that corresponds to factor i in
the factorized strongly exponential family distribution part Tf , the only non-zero atj are the ones that
map between Ti(Zi) and Ti(Vi(Zi)), where Ti are the factors in Tf that only depend on Zi and Ti is
defined similarly. Therefore, we can construct an invertible submatrix A0i with all non-zero elements
atj for all t that corresponds to factor i, such that
Ti(Zi)= AiTi(Vi(Zi))= AiTi(Vi(Zi)) + Ci, i = 1,…，n,	(52)
where Ti are the factors in Tf that only depends on Zi , and ci are the corresponding elements of c.
This means that the matrix A is a block permutation matrix. For each i = 1, ∙∙∙ ,n,the block Ai of
A affinely transforms Ti(Zi) into Ti(Vi(Zi)). There is also an additional block A0 which affinely
transforms TNN(Z) into TNN(V(Z)). ThiS completes the proof.	□
H.1.3 Part III
Now we combine Theorem 4 in Part I and Theorem 5 in Part II into one theorem, which completes
the proof of Theorem 1.
H.2 Proof of Theorem 2
We recall that the loss function in Phase 1 is as follows:
Lphase1 (θ, Φ) = LEL盟(f, T, λ, φ) - LPMSeI (f, T, λ, φ),	(53)
where
LELBOI (名初=EpD [Eqφ(Z∣X,Y,E) [log Pf (XIZ) +lθg pT ,λ(Z IY, E)-Iog qφ(Z |X , Y, E)]i , (54)
LSMSeI(T, λ) =EpD [Eqφ(z∣χ,γ,E) [||Vz logqφ(Z∣X, Y, E) -Vz logPT,λ(Z|Y, E)∣∣[] .	(55)
Proof. If the family of qφ(Z∣X, Y, E) is flexible enough to contain pθ(ZX, Y, E), then by
optimizing the loss over its parameter φ, we will minimize the score matching term LpShMase1 in
Eq. (55), which will eventually reach zero. If we assume that the model is not degenerate and
that qφ > 0 everywhere, then having that LPMSeI = 0 implies that VZ log qφ(Z∣X, Y, E) and
NZ logPT,λ(Z|Y, E) are equal. This implies that log qφ(Z∣X, Y, E) = logPT,λ(Z|Y, E) + C
for some constant c. But C is necessarily 0 because both qφ(Z|X, Y, E) and PT,λ(Z|Y, E) are
pdf’s. Therefore, the ELBO term LpEhLaBseO1 in Eq. (54) will be equal to the log-likelihood, meaning that
the loss Lphase1 in Eq. (53) will be equal to the log-likelihood. Under this circumstance, the estimation
in Eq. (53) inherits all the properties of maximum likelihood estimation (MLE). In this particular
case, since our identifiability is guaranteed up to a permutation and componentwise transformation,
the consistency of MLE means that We converge to the true parameter θ* up to a permutation
and componentwise transformation in the limit of infinite data. Because true identifiability is one
of the assumptions for MLE consistency, replacing it by identifiability up to a permutation and
componentwise transformation does not change the proof but only the conclusion.	□
H.3 Proof of Theorem 3
Proof. Theorem 1 and Theorem 2 guarantee that in the limit of infinite data, NF-iVAE can learn
the true parameters θ* := (f *, T*, λ*) up to a permutation and componentwise transformation
of the latent variables. Let (f, T, λ) be the parameters obtained by NF-iVAE. We, therefore,
have (f, T, λ) 〜P (f *, T*, λ*), where 〜P denotes the equivalence up to a permutation and
componentwise transformation. If there were no noise, this would mean that the learned f transforms
X into Z = f-1(X) that are equal to Z* = (f *)-1 (X) up to a permutation and componentwise
transformation (Definition 9). If with noise, we obtain the posterior distribution of the latent variables
up to an analogous indeterminacy.	□
H.4 Proof of Proposition 1
Proof. Theorem A.1 in (Arjovsky, 2021) has showed that i) any predictor w ◦ Φ with optimal OOD
generalization uses only Pa(Y) to compute Φ; ii) the classifier w in this optimal predictor can be
estimated using data from any environment e for which the distribution of Pa(Y e) has full support;
22
Published as a conference paper at ICLR 2022
iii)	the optimal predictor will be invariant across Eall. In iCaRL, the hypotheses of Theorems 1 and 2
and Assumption 1 guarantee that Pa(Y ) can be recovered by first identifying the latent variables Z
from X, Y and E and then discovering the direct causes of Y through solving Eq. (12). Furthermore,
since the conditional prior in Eq. (5) of the main text has full support, the distribution of Pa(Y e)
always has full support. Also, under Assumption 1 we have that p(Y |Pa(Y )) is invariant across Eall.
Hence, the classifier w in this optimal predictor can be estimated using data from any environment e.
We therefore have that the resulting optimal predictor will be invariant across Eall . This completes
the proof.
□
H.5 Proof of Proposition 2
Proof. The following rules can be independently performed to distinguish all the 10 structures shown
in Figs. 3b-3k. For clarity, we divide them into three groups. Note that, since these rules rely on
different algorithms of causal discovery and conditional independence tests, unless stated otherwise,
we assume that the assumptions of these algorithms are satisfied during the proof process.
Group 1 All the six structures in this group can be discovered only by performing conditional
independence tests.
•	Rule 1.1	If Zi	⊥⊥	Y ,	Zi	⊥6⊥ E,	and E	⊥⊥	Y , then Fig.	3d is discovered.
•	Rule 1.2	If Zi	⊥6⊥	Y ,	Zi	⊥⊥ E,	and E	⊥6⊥	Y , then Fig.	3g is discovered.
•	Rule 1.3	If Zi	⊥6⊥	Y ,	Zi	⊥6⊥ E,	and E	⊥⊥	Y , then Fig.	3f is discovered.
•	Rule 1.4	IfZi	⊥6⊥	Y,	Zi	⊥6⊥ E,E ⊥6⊥ Y,andZi ⊥⊥ Y	|E, then Fig. 3i is discovered.
•	Rule 1.5 IfZi ⊥6⊥ Y, Zi ⊥6⊥ E,E ⊥6⊥ Y,andZi ⊥⊥ E|Y, then Fig. 3h is discovered.
•	Rule 1.6 If Zi ⊥6⊥ Y , Zi ⊥6⊥ E, E ⊥6⊥ Y , and Y ⊥⊥ E|Zi, then Fig. 3e is discovered.
Group 2 If Zi ⊥6⊥ Y , Zi ⊥⊥ E, and E ⊥⊥ Y , then we can discover both Fig. 3b and Fig. 3c. These
two structures cannot be further distinguished only by conditional independence tests, because they
come from the same Markov equivalence class. Fortunately, we can further distinguish them by
running binary causal discovery algorithms (Peters et al., 2017), e.g., ANM (Hoyer et al., 2009) for
continuous data and CDS (Fonollosa, 2019) for continuous and discrete data.
•	Rule 2.1 If Zi ⊥6⊥ Y , Zi ⊥⊥ E, and E ⊥⊥ Y , and a chosen binary causal discovery
algorithm prefers Zi → Y to Zi J Y, then Fig. 3b is discovered.
•	Rule 2.2 If Zi ⊥6⊥ Y, Zi ⊥⊥ E, and E ⊥⊥ Y, and a chosen binary causal discovery
algorithm prefers Zi J Y to Zi → Y, then Fig. 3c is discovered.
Group 3 IfZi ⊥6⊥ Y, Zi ⊥6⊥ E, E ⊥6⊥ Y, Zi ⊥6⊥ Y|E, Zi ⊥6⊥ E|Y, andY ⊥6⊥ E|Zi,thenwecan
discover both Fig. 3j and Fig. 3k. These two structures cannot be further distinguished only by
conditional independence tests, because they come from the same Markov equivalence class. They
also cannot be distinguished by any binary causal discovery algorithm, since both Zi and Y are
affected by E. Fortunately, Zhang et al. (2017) provided a heuristic solution to this case based on
the invariance of causal mechanisms, i.e., P (cause) and P (effect|cause) change independently. The
detailed description of their method is given in Section 4.2 of Zhang et al. (2017). For convenience,
here we directly borrow their final result. Zhang et al. (2017) states that determining the causal
direction between Zi and Y in Fig. 3j and Fig. 3k is finally reduced to calculating the following
term:
∆Zi→γ = *iog P(YIZi) + ,	(56)
i	hP(Y ∣Zi)i∕
where〈•〉denotes the sample average, P(Y |Zi) is the empirical estimate of P(Y |Zi) on all data
points, and hP(Y|Zi)i denotes the sample average of P(Y|Zi), which is the estimate of P(Y|Zi)
in each environment. We take the direction for which ∆ is smaller to be the causal direction.
23
Published as a conference paper at ICLR 2022
•	Rule 3.1 If Zi ⊥6⊥ Y , Zi ⊥6⊥ E, E ⊥6⊥ Y , Zi ⊥6⊥ Y |E, Zi ⊥6⊥ E|Y , Y ⊥6⊥ E|Zi, and
∆Zi→Y is smaller than ∆Y →Zi, then Fig. 3j is discovered.
•	Rule 3.2 If Zi ⊥6⊥ Y , Zi ⊥6⊥ E, E ⊥6⊥ Y , Zi ⊥6⊥ Y |E, Zi ⊥6⊥ E|Y , Y ⊥6⊥ E|Zi, and
∆Y →Zi is smaller than ∆Zi→Y , then Fig. 3k is discovered.
□
I	Illustrations for Model Learning
As described in Section 3.3, in the ground truth model, the prior for each Zi∈Ip is eitherp(Zi|E) or
p(Zi), depending on whether Zi is caused by E or not. By contrast, in the NF-iVAE model the prior
is p(Z|Y , E). Is this going to affect the identifiability of the latent variables? Well, in practice not
because the posterior distribution for Z given X , Y and E would be equivalent in both models (up
to identifiability guarantees).
J Datasets
For convenience and completeness, we provide descriptions of Colored MNIST Digits and Colored
Fashion MNIST here. Please refer to the original papers (Arjovsky et al., 2019; Ahuja et al., 2020a;
Gulrajani & Lopez-Paz, 2020; Venkateswara et al., 2017) for more details.
J.1 Synthetic Data
For the nonlinear transformation, we use the MLP:
•	Input layer: Input batch (batch size, input dimension)
•	Layer 1: Fully connected layer, output size = 6, activation = ReLU
•	Output layer: Fully connected layer, output size = 10
J.2 Colored MNIST Digits
We use the exact same environment as in Arjovsky et al. (2019). Arjovsky et al. (2019) propose to
create an environment for training to classify digits in MNIST data10, where the images in MNIST
are now colored in such a way that the colors spuriously correlate with the labels. The task is to
classify whether the digit is less than 5 (not including 5). There are three environments (two training
containing 30,000 points each, one test containing 10,000 points) We add noise to the preliminary
label (y = 0 if the digit is between 0-4 and y= 1 if the digit is between 5-9) by flipping it with 25
percent probability to construct the final labels. We sample the color id z by flipping the final labels
with probability pe, where pe is 0.2 in the first environment, 0.1 in the second environment, and 0.9
in the third environment. The third environment is the testing environment. We color the digit red if
z = 1 or green if z = 0.
J.3 Colored Fashion MNIST
We modify the fashion MNIST dataset11 in a manner similar to the MNIST digits dataset. Fashion
MNIST data has images from different categories: “t-shirt”, “trouser”, “pullover”, “dress”, “coat”,
“sandal”, “shirt”, “sneaker”, “bag”, “ankle boots”. We add colors to the images in such a way that the
colors correlate with the labels. The task is to classify whether the image is that of foot wear or a
clothing item. There are three environments (two training, one test) We add noise to the preliminary
label (y = 0: “t-shirt”, “trouser”, “pullover”, “dress”, “coat”, “shirt” and y=1: “sandal”, “sneaker”,
“ankle boots”) by flipping it with 25 percent probability to construct the final label. We sample the
color id z by flipping the noisy label with probability pe, where pe is 0.2 in the first environment, 0.1
10https://www.tensorflow.org/api_docs/python/tf/keras/datasets/mnist/
load_data
11https://www.tensorflow.org/api_docs/python/tf/keras/datasets/fashion_
mnist/load_data
24
Published as a conference paper at ICLR 2022
Table 3: Results on synthetic data. Comparisons are in terms of MSE (mean ± std deviation).
g(∙)	METHOD	TRAIN (σ3 = {0.2, 2})	TEST (σ3 = 100)
	ERM	0.00 ± 0.00	0.00 ± 0.00
Identity	IRM	0.00 ± 0.00	0.00 ± 0.00
	F-IRM GAME	0.98 ± 0.23	1.03 ± 0.04
	V-IRM GAME	0.99 ± 2.74	1.07 ± 2.26
	iCaRL (ours)	0.01 ± 0.03	1.00 ± 0.01
	ERM	0.00 ± 0.00	0.00 ± 0.00
Linear	IRM	0.00 ± 0.00	0.00 ± 0.00
	F-IRM GAME	0.99 ± 0.01	1.08 ± 0.06
	V-IRM GAME	1.00 ± 5.98	1.05 ± 0.04
	iCaRL (ours)	0.01 ± 0.03	1.01 ± 0.04
	ERM	0.06 ± 0.01	220.79 ± 229.97
Nonlinear	IRM	0.08 ± 0.01	149.60 ± 104.85
	F-IRM GAME	1.06 ± 0.09	196.59 ± 150.71
	V-IRM GAME	1.00 ± 0.01	170.46 ± 125.62
	iCaRL (ours)	0.29 ± 0.04	28.16 ± 2.54
in the second environment, and 0.9 in the third environment, which is the test environment. We color
the object red if z = 1 or green if z = 0.
K	In-depth Analysis on S ynthetic Data
K. 1 Comparisons with State-of-the-Art
We first conduct a series of experiments on synthetic data generated according to an extension of
the SEM in Model 1. The extension is to map the variables Z := (Z1, Z2) into a 10 dimensional
observation X through a linear or nonlinear transformation. Our goal is to predict Y from X, where
X = g(Z). We consider three transformations: (a) Identity: g(∙) is the identity matrix I ∈ R2×2,
i.e., X = g(Z) = Z. (b) Linear: g(∙) is a random matrix S ∈ R2×10, i.e., X = g(Z) = Z ∙ S. (c)
Nonlinear: g(∙) is given by a neural network with 2-dimensional input and 10-dimensional output,
whose parameters are randomly set in advance. Since this is a regression task, we use the mean
squared error (MSE) as a metric of performance. Note that, in this problem, there is only one
causal latent variable Z1 , meaning that the conditional prior in Eq. (5) will not exhibit dependencies.
Because of this, in this case we do not include a TNN(Z) term in our NF-iVAE conditional prior. In
the following section we do consider settings with many potential causal latent variables and, in that
case, we do include TNN(Z) in the NF-iVAE prior.
We consider a simple scenario in which we fix σ1 = 1 and σ2 = 0 for all environments and only allow
σ3 to vary across environments. In this case, σ3 controls the spurious correlations between Z2 and Y .
Each experiment draws 1000 samples from each of the three environments σ3 = {0.2, 2, 100}, where
the first two are for training and the third for testing. We compare with the following baselines:12
ERM, and two variants of IRMG: F-IRM Game (with Φ fixed to the identity) and V-IRM Game (with
variable Φ).
As shown in Table 3, in the cases of Identity and Linear, our approach is better than IRMG but
only comparable with ERM and IRM. This might be because the identifiability result up to a simple
nonlinear transformation renders the problem more difficult by converting the original identity or
linear problem into a nonlinear problem. In the Nonlinear case, the gains of iCaRL are very clear.
Table 4: Comparisons of assumptions on the prior leading to identifiability in different algorithms.
METHOD
VAE (Kingma & Welling, 2013)
iVAE (Khemakhem et al., 2020a)
ICE-BeeM (Khemakhem et al., 2020b)
NF-iVAE
Assumption on the Prior for Identifiability
Non-identifiability with pT,λ(Z) = Qi p(Zi) e=.g. N (0, I)
Pτ,λ(Z∣Y, E) = Qi Qi(Zi)∕Ci(Y, E)exp[pj=ι Tij(Zi)M(Y, E)]
Pτ,λ(Z∣Y, E) = Q(Z)^C(Y, E)QieXpPk=ITij (Zi)λi,j (Y, E)]
Pτ,λ(Z|Y, E) = Q(Z)∕C(Y, E)exp [T(Z)Tλ(Y, E)]
12We also tried ICP, but ICP was unable to find any parent of Y even in the identity case.
25
Published as a conference paper at ICLR 2022
E ~U{0.2, 2, 3, 5}	(57)
Zi ~ N(Zι |E, 1)	(58)
Z2 ~N(Z2|2E,2)	(59)
Y ~N(Y|Z1 +Z2, 1)	(60)
X = g(Z1, Z2)	(61)
(b)
Figure 4:	(a) Causal structure with Y having two causes. (b) Data generating process corresponding
to (a), where U{∙} denotes the discrete uniform distribution, N(∙) the Gaussian distribution, and g(∙)
is given by a neural network with 2-dimensional input and 10-dimensional output, whose parameters
are randomly set in advance.
(a) Data generating model
(b) VAE
(c) iVAE
(d) ICE-BeeM
(e) iCaRL-NF-iVAE
IT	Ly τ∙ T	C,1	t ∕∙	今 f Γ7 Γ7 ∖∖ ∙	1	.	,1,1	II，
Figure 5:	Visualization of the samples (i.e., Z = (Z1, Z2)) in latent space generated through different
algorithms. (a) Samples from the true distribution. (b-e) Samples from the posterior of different
algorithms. Apparently, our method (e) can recover the original data up to a permutation and a simple
componentwise transformation.
K.2 Visualization of Identifiability of NF-iVAE
To further verify identifiability of NF-iVAE, we conduct a series of experiments on synthetic data
generated according to the data generating process (Fig. 4b) corresponding to the causal graph
shown in Fig. 4a. The reason we choose this setting is that it is the simplest case satisfying our
requirements: a) For ease of visualization, the latent space had better be 2-dimensional; b) To
introduce the non-factorized prior given Y and E (i.e., Zi ⊥6⊥ Zj |Y , E), Y has at least two causes.
We draw 1000 samples from each of the four environments E = {0.2, 2, 3, 5}, and thus the whole
synthetic dataset consists of 4000 samples. We compare with the following baselines: VAE Kingma
& Welling (2013) (without identifiability guarantees), iVAE Khemakhem et al. (2020a) (with a
conditionally factorized prior for identifiability), and ICE-BeeM Khemakhem et al. (2020b). It is
worth noting that in ICE-BeeM the primary assumption leading to identifiability is similar to that in
iVAE, where the base measure Q(Z) could be arbitrary to capture the dependences between latent
variables but the exponential term still has to factorize across components (dimensions). All these
are summarized in Table 4. Clearly, from the table we can see that our method has a more general
assumption on the prior leading to identifiability. This is also demonstrated empirically in Fig. 5.
Our method iCaRL can recover the original data Z up to a permutation and a simple componentwise
26
Published as a conference paper at ICLR 2022
Table 5: Colored MNIST. Comparisons in terms of
accuracy (%) (mean ± std deviation).
METHOD	TRAIN	TEST
ERM	84.88 ± 0.16	10.45 ± 0.66
ERM 1	84.84 ± 0.21	10.86 ± 0.52
ERM 2	84.95 ± 0.20	10.05 ± 0.23
ROBUST MIN MAX	84.25 ± 0.43	15.24 ± 2.45
F-IRM GAME	63.37 ± 1.14	59.91 ± 2.69
V-IRM GAME	63.97 ± 1.03	49.06 ± 3.43
IRM	59.27 ± 4.39	62.75 ± 9.59
iCaRL (ours)	70.56 ± 0.81	68.75 ± 1.45
ERM GRAYSCALE	71.81 ± 0.47	71.36 ± 0.65
OPTIMAL	75	75
Table 6: PACS. Comparisons in terms of accuracy
(%) (mean ± std deviation).
METHOD	TEST
ERM	85.7 ± 0.5
IRM	84.4 ± 1.1
DRO (Sagawa et al., 2019)	84.1 ± 0.4
Mixup (Yan et al., 2020)	84.3 ± 0.5
CORAL (Sun & Saenko, 2016)	86.0 ± 0.2
MMD (Li et al., 2018b)	85.0 ± 0.2
DANN (Ganin et al., 2016)	84.6 ± 1.1
C-DANN (Li et al., 2018c)	82.8 ± 1.5
LaCIM (Sun et al., 2020)	83.5 ± 1.2
iCaRL (ours)	88.7 ± 0.6
transformation, whereas all the other methods fail because they are unable to handle the case in which
Zi ⊥6⊥ Zj|Y,E.
L In-Depth Analysis on More Realistic Data
L.1 Colored MNIST
We compare iCaRL with 1) IRM, 2) two variants of IRMG: F-IRM Game (with Φ fixed to the identity)
and V-IRM Game (with a variable Φ), 3) three variants of ERM: ERM (on entire training data),
ERM e (on each environment e), and ERM GRAYSCALE (on data with no spurious correlations),
and 4) ROBUST MIN MAZ (minimizing the maximum loss across the multiple environments).
Table 1 shows that iCaRL outperforms all other baselines on Colored MNIST. However, this dataset
seems more difficult because even ERM GRAYSCALE, where the spurious correlation with color is
removed, falls well short of the optimum.
L.2 PACS
We report the results on another one of the widely used realistic datasets for OOD generalization:
PACS (Li et al., 2017a). This dataset consists of 9, 991 images of dimension (3, 224, 224) and 7
classes from four domains: art, cartoons, photos, and sketches. We used the exact experimental
setting that is described in Gulrajani & Lopez-Paz (2020). We provide results averaged over all
possible train and test environment combination for one of the commonly used hyper-parameter
tuning procedure: train domain validation. As shown in Table 6, iCaRL achieves state-of-the-art
performance when compared to those most popular domain generalization alternatives.
27
Published as a conference paper at ICLR 2022
M Implementation Details
M.1 Joint Training
As described in Section 4.1, we can jointly learn (θ, φ) by optimizing the following objective:
LphaseI (θ, φ) =LELBO (f,T, λ, φ) - LpMseI (f,T, λ, φ)	(62)
=EpD [Eqφ(z∣x,γ,E) [logPf (X|Z) + logPτ,λ(Z∣Y, E) - log qφ(z∣x, Y, E)ii
-EpD [Eqφ(Z∣X,Y,E) [||Vz log qφ(Z∣X, Y, E) - Vz logPT,λ(Z∣Y, E)/]] (63)
=EpD [Eqφ(Z∣X,Y ,E) [log Pf (XIZ) + log PT,λ (Z|Y, E) - log qφ(ZlX , Y, E)ii
m L	「X [∂2PT,λ(Z|Y, E) l 1 (∂pτ,λ(Z|Y, E) 丫]『
-EpD [Eqφ(Zlχ,γ,E)	[------∂Zj2------+ 2 (-------∂Z∙-----) U
+ const.	(64)
where the last equality is due to the equation in Appendix C.2, and f , T , λ, φ are copies of
f, T , λ, φ that are treated as constants and whose gradient is not calculated during learning. In
practice, f , T , λ, φ can be easily implemented through either “detach” in PyTorch Paszke et al.
(2019) or “stop_gradient” in TensorFlow Abadi et al. (2015).
M.2 The General Non-factorized Prior
In the experiments, the general non-factorized prior in Assumption 2 is implemented as follows:
PT,λ (Z|Y, E) = NN(Z; param1), NN(Y, E; param2) + concat(Z, Z2), NN(Y, E; param3) ,
V------{------} |
TNN (Z)
^^~~{^^^^^—
λNN (Y,E)
|-------{--------} |
Tf(Z)
{^~*∖∕^^^~
λf (Y,E)


where(∙,)is the dot product of two vectors, and Concat (∙, ∙) means the concatenation of two
vectors. Now let us explain each term in details.
Firstly, concat(Z, Z2) is a vector of the latent variables and their squared values,
and NN(Y , E; param3) is a deep neural network parameterized by param3 that com-
putes a vector of natural parameters as a function of Y and E . Hence, the term
concat(Z, Z2), NN(Y , E; param3) is equivalent to the factorized exponential family, which
also satisfies that each Ti(Zi) has dimension larger or equal to 2.
Secondly, NN(Z; param1) is a neural network that receives as input a vector of latent variables
and outputs another vector representing complicated nonlinear transformations of those variables.
NN(Y , E; param2) is another neural network that generates a corresponding vector of natural
parameters. Hence, the term NN(Z; param1), NN(Y , E; param2) will allow this prior to capture
the dependencies between the latent variables Z.
N Hyperparameters and Architectures
In this section, we describe the hyperparameters and architectures of different models used in different
experiments. Unless stated otherwise, we have λ1 = 1 and λ2 = 1, both of which are selected on
training/validation data.
N. 1 Synthetic Data
We used Adam optimizer for training with learning rate set to 1e-3 and batch size set to 128.
N.1.1 ERM
Linear ERM
•	Input layer: Input batch (batch size, input dimension)
•	Output layer: Fully connected layer, output size = 1
28
Published as a conference paper at ICLR 2022
Nonlinear ERM
•	Input layer: Input batch (batch size, input dimension)
•	Layer 1: Fully connected layer, output size = 6, activation = ReLU
•	Output layer: Fully connected layer, output size = 1
N.1.2 IRM
Linear Data Representation Φ
•	Input layer: Input batch (batch size, input dimension)
•	Output layer: Fully connected layer, output size = 1
Nonlinear Data Representation Φ
•	Input layer: Input batch (batch size, input dimension)
•	Layer 1: Fully connected layer, output size = 6, activation = ReLU
•	Output layer: Fully connected layer, output size = 1
N.1.3 F-IRM GAME
Linear Classifier w
•	Input layer: Input batch (batch size, input dimension)
•	Output layer: Fully connected layer, output size = 1
Nonlinear Classifier w
•	Input layer: Input batch (batch size, input dimension)
•	Layer 1: Fully connected layer, output size = 6, activation = ReLU
•	Output layer: Fully connected layer, output size = 1
N.1.4 V-IRM GAME
Linear Data Representation Φ
•	Input layer: Input batch (batch size, input dimension)
•	Output layer: Fully connected layer, output size = 2
Nonlinear Data Representation Φ
•	Input layer: Input batch (batch size, input dimension)
•	Layer 1: Fully connected layer, output size = 6, activation = ReLU
•	Output layer: Fully connected layer, output size = 2
Linear Classifier w
•	Input layer: Input batch (batch size, 2)
•	Output layer: Fully connected layer, output size = 1
Nonlinear Classifier w
•	Input layer: Input batch (batch size, 2)
•	Layer 1: Fully connected layer, output size = 6, activation = ReLU
•	Output layer: Fully connected layer, output size = 1
29
Published as a conference paper at ICLR 2022
N.1.5 ICARL
NF-iVAE λf-LinearPrior
•	Input layer: Input batch (batch size, input dimension)
•	Output layer: Fully connected layer, output size = 4
NF-iVAE λf -Nonlinear Prior
•	Input layer: Input batch (batch size, input dimension)
•	Layer 1: Fully connected layer, output size = 6, activation = ReLU
•	Output layer: Fully connected layer, output size = 4
NF-iVAE TNN-Nonlinear Prior
•	Input layer: Input batch (batch size, input dimension)
•	Layer 1: Fully connected layer, output size = 6, activation = ReLU
•	Output layer: Fully connected layer, output size = 1
NF-iVAE λNN -Nonlinear Prior
•	Input layer: Input batch (batch size, input dimension)
•	Layer 1: Fully connected layer, output size = 6, activation = ReLU
•	Output layer: Fully connected layer, output size = 1
NF-iVAE Linear Encoder
•	Input layer: Input batch (batch size, input dimension)
•	Mean Output layer: Fully connected layer, output size = 2
•	Log Variance Output layer: Fully connected layer, output size = 2
NF-iVAE Nonlinear Encoder
•	Input layer: Input batch (batch size, input dimension)
•	Layer 1: Fully connected layer, output size = 6, activation = ReLU
•	Mean Output layer: Fully connected layer, output size = 2
•	Log Variance Output layer: Fully connected layer, output size = 2
NF-iVAE Linear Decoder
•	Input layer: Input batch (batch size, 2)
•	Mean Output layer: Fully connected layer, output size = output dimension
•	Variance Output layer: 0.01 × 1, where 1 is a vector full of 1 with the length of output
dimension
NF-iVAE Nonlinear Decoder
•	Input layer: Input batch (batch size, 2)
•	Layer 1: Fully connected layer, output size = 6, activation = ReLU
•	Mean Output layer: Fully connected layer, output size = output dimension
•	Variance Output layer: 0.01 × 1, where 1 is a vector full of 1 with the length of output
dimension
30
Published as a conference paper at ICLR 2022
Linear Classifier w
•	Input layer: Input batch (batch size, 1)
•	Output layer: Fully connected layer, output size = 1
Nonlinear Classifier w
•	Input layer: Input batch (batch size, 1)
•	Layer 1: Fully connected layer, output size = 6, activation = ReLU
•	Output layer: Fully connected layer, output size = 1
N.2 CMNIST AND CFMNIST
Considering that the results of most baselines come from IRMG (Ahuja et al., 2020a), for a fair
comparison, we follow the same setting of IRMG in terms of hyper-parameters and validation
considerations. For example, the batch size is set to 256, and the learning rate is 10-4. We also did
not use the test environment data for validation. Please find more details in Ahuja et al. (2020a).
NF-iVAE TNN-Prior
•	Input layer: Input batch (batch size, input dimension)
•	Layer 1: Fully connected layer, output size = 50, activation = ReLU
•	Output layer: Fully connected layer, output size = 45
NF-iVAE λNN-Prior
•	Input layer: Input batch (batch size, input dimension)
•	Layer 1: Fully connected layer, output size = 50, activation = ReLU
•	Output layer: Fully connected layer, output size = 45
NF-iVAE λf -Prior
•	Input layer: Input batch (batch size, input dimension)
•	Layer 1: Fully connected layer, output size = 50, activation = ReLU
•	Output layer: Fully connected layer, output size = 20
NF-iVAE X-Encoder
•	Input layer: Input batch (batch size, 2, 28, 28)
•	Layer 1: Convolutional layer, output channels = 32, kernel size = 3, stride = 2, padding = 1,
activation = ReLU
•	Layer 2: Convolutional layer, output channels = 32, kernel size = 3, stride = 2, padding = 1,
activation = ReLU
•	Layer 3: Convolutional layer, output channels = 32, kernel size = 3, stride = 2, padding = 1,
activation = ReLU
•	Output layer: Flatten
NF-iVAE (Y, E)-Encoder
•	Input layer: Input batch (batch size, input dimension)
•	Output layer: Fully connected layer, output size = 100, activation = ReLU
31
Published as a conference paper at ICLR 2022
NF-iVAE (X,Y,E)-Merger/Encoder
•	Input layer: Input batch (batch size, input dimension)
•	Layer 1: Fully connected layer, output size = 100, activation = ReLU
•	Mean Output layer: Fully connected layer, output size = 10
•	Log Variance Output layer: Fully connected layer, output size = 10
NF-iVAE Decoder
•	Input layer: Input batch (batch size, 10)
•	Layer 1: Fully connected layer, output size = 32 × 4 × 4, activation = ReLU
•	Layer 2: Reshape to (batch size, 32, 4, 4)
•	Layer 3: Deconvolutional layer, output channels = 32, kernel size = 3, stride = 2, padding =
1, outpadding = 0, activation = ReLU
•	Layer 4: Deconvolutional layer, output channels = 32, kernel size = 3, stride = 2, padding =
1, outpadding = 1, activation = ReLU
•	Layer 5: Deconvolutional layer, output channels = 2, kernel size = 3, stride = 2, padding = 1,
outpadding = 1
•	Mean Output layer: activation = Sigmoid
•	Variance Output layer: 0.01 × 1, where 1 is a matrix full of 1 with the size of 2 × 28 × 28.
Classifier w
•	Input layer: Input batch (batch size, 50)
•	Layer 1: Fully connected layer, output size = 100, activation = ReLU
•	Output layer: Fully connected layer, output size = 1, activation = Sigmoid
N.3 VLCS AND PACS
We used the exact experimental setting that is described in Gulrajani & Lopez-Paz (2020). Specifically,
we trained our model over all possible train and test environment combination for one of the commonly
used hyper-parameter tuning procedure: train domain validation. We use ResNet-50 as an encoder
and reverse the architecture of ResNet-50 as a decoder. We set the number of the latent variables
to n = 50. We do the hyperparameter search by exactly following the guides given in Gulrajani &
Lopez-Paz (2020).
32