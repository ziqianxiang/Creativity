Figure 1: Comparison between fixed-to-variable (e.g., CSR) sparsity format and fixed-to-fixed(proposed) sparsity format. (a): Memory bandwidth comparison. (b): Memory access patterns withirregular sparsity.
Figure 2: Fixed-to-fixed compression of a sparse weight matrix. Even when a block involves avarying number of unpruned weights, the size of each encoded block is fixed and determined by anaverage number of unpruned weights in blocks.
Figure 3:	Encoding of weights using an XOR-gate decoder as a random number generator.
Figure 4:	Encoding efficiency (%) of random XOR-gate decoders. S is pruning rate and Nout isgiven as [N⅛ ∙ (1∕(1-S))].
Figure 5: Encoding of two blocks when a numberof unpruned weights can vary in a block.
Figure 6: Proposed fixed-to-fixed sequential encoding/decoding scheme. Weight encoding is per-formed offline, and thus, complex computation for encoding is allowed. Encoded weights are decodedduring inference through XOR-gate decoders that are best implemented by ASICs or FPGAs. Prunedweights are filled by random values during weight decoding.
Figure 7: Sequential decoding example whenNs=1, Nin=3, and Nout=8. An input is utilizedfor (Ns+1) time indices through shift registers.
Figure 8: Impact of Ns with various Nout using 1M random bits, Nin = 8, and S=0.9.
Figure 9: E with various ratio of zero in arandom vector.
