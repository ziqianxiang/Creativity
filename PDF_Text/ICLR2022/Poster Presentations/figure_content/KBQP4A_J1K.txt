Figure 1: Left: an ideal sequence of computations in a Transformer for an arithmetic expression.
Figure 2:	Example visualization of NDR. For other models, see Appendix D. Top: Attention mapfor different steps. The x/y-axis corresponds to source/target positions, respectively. Each positionfocuses on the column to the right, except the last one where the result is read from, which focuses onthe last operation. The focus becomes clear only once the result is available. Bottom: gate activationsfor different steps/layers. The gates remain closed until the data dependencies are satisfied.
Figure 3:	Example visualization of NDR on ListOps. The top row shows head 13 in different steps,which controls which arguments are used in which step. The bottom row shows different heads indifferent key steps. Please refer to Sec. 4 for the step-by-step description. More visualizations areprovided in the appendix: Fig. 12 shows the max of attention over all heads for all steps, Fig. 13shows all steps of head 13, and Fig. 14 shows the corresponding gates.
Figure 4: Average number of steps/layers for different sequence lengths on the compositional tablelookup task for the Transformer with relative positional encodings and the ACT variant described inAppendix A. The red line shows Tmax = 14. Note that the sequence length shown here includes thebegin and end tokens. Thus, the sequence length of 4 corresponds to one function application (3 forthe identity function i.e. no function is applied).
Figure 5: Structure of Transformer/NDR layer with a copy gate (Sec. 2.1). The blue part correspondsto the standard Transformer, except for the missing residual connection around the feedforward block(“FF: Update”). The gray part is the copy gate. The feedforward part corresponding to the gate isusually significantly smaller than the one used for the update.
Figure 6:	An ideal sequence of computations in a Transformer for an example CTL task.
Figure 7:	Attention map for every computational step for a baseline Transformer with relativepositional encoding on CTL. The attention pattern gets blurry very quickly, and the model does notgeneralize to longer sequences.
Figure 8:	Attention map for every computational step for a Transformer with gating and rela-tive/absolute positional encoding (presented in Figure 2) on CTL. The attention pattern is relativelystable over time, and it gets blurrier only after the given column is processed and updated. The gatesequence for the same input can be seen in Figure 9.
Figure 9:	Gates for every computational step for a Transformer with gating and relative/absolutepositional encoding on CTL. The gates are closed until all arguments of the given operation becomeavailable. The attention maps for the same input can be seen in Figure 8.
Figure 10: Attention map for every computational step of the NDR on CTL. The network correctlyand clearly focuses on the last element of the sequence, and the last sharp read happens in step 10 -corresponding to the 10 function calls in the example. The gate sequence for the same input can beseen in Figure 11.
Figure 11: Gates for every computational step of the NDR on CTL. The gates remain closed until allarguments of the given operations become available. The attention maps for the same input can beseen in Figure 10.
Figure 12:	Attention maps for every computational step of the NDR on ListOps. The network has 16heads; the max of them is shown. The input has only depth 4, which explains the early stopping ofthe computation, roughly after 8-9 steps, after which the attention barely changes. The correspondinggate maps for the same input can be seen in Figure 14.
Figure 13:	Attention maps for head 13 of the NDR in every computational step on ListOps. Thishead shows the operands for each operation. Following it, we observe the hierarchy and the order inwhich the operations are performed.
Figure 14: Gates for every computational step of the NDR on ListOps. Gates open for the deepestoperations in the tree, processing proceeds upwards in the computational tree. The input has onlydepth 4, which explains the early stopping of the computation, roughly after 8-9 steps. The attentionmaps for the same input can be seen in Figure 12.
