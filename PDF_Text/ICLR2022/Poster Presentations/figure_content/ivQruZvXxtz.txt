Figure 1: Concepts. Black arrows denote finetuning processes. The darker the part of the arrows, the lowerthe MTL loss. Upper and bottom path shows better and worse trade-off, respectively. Colored arrows denotetask gradients. Blue and red color shows high and low cosine similarity, respectively. We demonstrate thisconcept with the actual experimental results in Fig. 7a.
Figure 2: Comparison between the methods.
Figure 3: (a)〜(g) Loss surface and learning trajectory of each method. (h) HeatmaP shows average pair-wisecosine similarity between the task gradients.
Figure 4: Average pair-wise cosine similarity between the gradients computed from different tasks.
Figure 5: (a, b) Average MLM loss on (a) seen and (b) unseen languages from Common Crawl dataset. Wemask 15% tokens of sentences from Common Crawl dataset, which is preprocessed and provided by Wenzeket al. (2020), and compute the masked language modeling loss (MLM), which is reconstruction loss of themasked sentences. (c) `2 distance between the finetuned models and the initially pretrained BERT.
Figure 6: (a,b) Masked Language Modeling (MLM) loss. (c,d) `2 distance from the pretrained BERT model.
Figure 7: (a) Trade-off shown in Fig. 1: average cosine similarity between task gradients vs. MTL trainingloss. (b) Effect of the strength of gradient alignment: Average cosine similarity between task gradients andtest performance (EM) vs. inner-learning rate. (c) Computational efficiency: Test performance (EM) vs. thecumulative count of (inner-) gradient steps used for training.
Figure 8: (a) Computational efficiency: Test performance (EM) vs. wall clock. (b) Effect of the the numberof inner steps: Test performance (EM) vs the number of inner steps for Sequential Reptile.
Figure 11: (a)〜(g) Loss surface and learning trajectory of each method. (h) HeatmaP shows average pair-wisecosine similarity between the task gradients.
