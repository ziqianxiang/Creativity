Figure 1: Overview of our proposed BGRL method. The original graph is first used to derive two differentsemantically similar views using augmentations T1,2. From these, we use encoders Eθ,φ to form online andtarget node embeddings. The predictor pθ uses the online embedding H1 to form a prediction Z1 of the targetembedding H2. The final objective is then computed as the cosine similarity between Z1 and H2, flowinggradients only through Z1. The target parameters φ are updated as an exponentially moving average of θ.
Figure 2: PPI task performance, averaged over 20 seeds.
Figure 3: Histogram of GAT attention entropies.
Figure 5: Mixing varying amounts of unlabeleddata for representation learning with BGRL, averagedover 5 seeds and run for 500k steps.
Figure 4: Performance on MAG240M using BGRLor GRACE-SUBSAMPLING as an auxiliary signal, av-eraged over 5 seeds and run for 50k steps.
Figure 8: Average embedding normFigure 6:	BGRL LossFigure 7:	Embedding spreadB	Ablations on Projector NetworkAs noted in Section 2, BGRL does not use a projector network, unlike both BYOL and GRACE. Priorworks such as GRACE use a projector network to prevent the embeddings from becoming completelyinvariant to the augmentations used - however in BGRL, the predictor network can serve the samepurpose. On the other hand, BYOL relies on this for dimensionality reduction, to simplify the task ofthe predictor pθ , as it is challenging to directly predict very high-dimensional embeddings. requiredfor large-scale vision tasks like ImageNet (Deng et al., 2009). Here we empirically verify that even inour most challenging, large-scale task of MAG240M, the projector network is not needed and onlyslows down learning. In Figure 9 we can see that adding the projector network leads to both slowerlearning and a lower final performance.
Figure 6:	BGRL LossFigure 7:	Embedding spreadB	Ablations on Projector NetworkAs noted in Section 2, BGRL does not use a projector network, unlike both BYOL and GRACE. Priorworks such as GRACE use a projector network to prevent the embeddings from becoming completelyinvariant to the augmentations used - however in BGRL, the predictor network can serve the samepurpose. On the other hand, BYOL relies on this for dimensionality reduction, to simplify the task ofthe predictor pθ , as it is challenging to directly predict very high-dimensional embeddings. requiredfor large-scale vision tasks like ImageNet (Deng et al., 2009). Here we empirically verify that even inour most challenging, large-scale task of MAG240M, the projector network is not needed and onlyslows down learning. In Figure 9 we can see that adding the projector network leads to both slowerlearning and a lower final performance.
Figure 7:	Embedding spreadB	Ablations on Projector NetworkAs noted in Section 2, BGRL does not use a projector network, unlike both BYOL and GRACE. Priorworks such as GRACE use a projector network to prevent the embeddings from becoming completelyinvariant to the augmentations used - however in BGRL, the predictor network can serve the samepurpose. On the other hand, BYOL relies on this for dimensionality reduction, to simplify the task ofthe predictor pθ , as it is challenging to directly predict very high-dimensional embeddings. requiredfor large-scale vision tasks like ImageNet (Deng et al., 2009). Here we empirically verify that even inour most challenging, large-scale task of MAG240M, the projector network is not needed and onlyslows down learning. In Figure 9 we can see that adding the projector network leads to both slowerlearning and a lower final performance.
Figure 9: Performance on OGB-LSC MAG240M task, averaged over 5 seeds, testing effect of usingprojector network.
Figure 10: Performance on OGB-LSC MAG240M task, averaged over 3 seeds, using GCN encoders.
Figure 11: Memory usage of BGRL and GRACE across 5 standard datasets.
Figure 12: Performance on OGB-LSC MAG240M task, averaged over 5 seeds, under frozen evalua-tion protocol.
