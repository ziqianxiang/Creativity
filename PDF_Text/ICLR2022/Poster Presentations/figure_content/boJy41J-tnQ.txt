Figure 1: Few-shot class incremental learning: (a) A base classifier is trained on a large dataset (D(0)). (b)This classifier is extended to also discriminate among a set of new classes with a small number of labeledexamples (D(1)). (c) Models are evaluated on a test set that includes all seen classes (Q(1)). This paperfocuses on extremely simple, regularization-based approaches to FSCIL, with and without side informationfrom natural language: (i) We regularize novel classifier weights toward the shortest direction to the subspacespanned by base classifier weights. (ii) We regularize novel classifiers pulling them toward the weightedaverage of base classifiers where weights are calculated using label/description similarity between novel andbase class names or one-sentence descriptions. (iii) We learn a linear mapping L between word labels andclassifier weights of the base classes. Later, we project the novel label white wolf and regularize the novelclassifier weight ηwhite wolf towards the projection.
Figure 2: Multi-Session FSCIL accuracy (%) results on miniImageNet. In the first session 0, there are a totalof 60 classes (base). Every session following the first one introduces 5 novel classes with 5 labeled samplesfrom each. Each session provides accuracy over all classes that were seen thus far. Weighted average is theweighted combination of novel and base accuracies with respect to the number of classes in each category.
Figure 3: Simple fine-tuning (top) vs. subspace regularization (bottom) predictions without memory across thefirst four incremental sessions of miniImageNet. In the x- and y-axes, we present predictions and gold labelsranging from 0 to 79 where the first 60 are base classes. The number of classes grows by 5 every sessionstarting from 60 up to 80. Brighter colors indicate more frequent predictions. Note that simple fune-tuningentails bias towards the most recently learned classes (top row) whereas addition of subspace regularization onthe novel weights remedies the aforementioned bias; resulting in a fairer prediction performance for all classes.
Figure 4: Clasifier weight space when subspace regularization is applied for miniImageNetsingle-session 5-shot setting. First two principal components are shown according to PCA. Redlabels indicate novel classes while the black indicates base. The green crosses indicate theprojection of the respective novel class weight to the base subspace. Note that unlikelabel/description similarity and linear mapping, subspace target is dynamic: it changes accordingto its corresponding novel weights and vice versa.
Figure 5: Clasifier weight space when Semantic Subspace Reg. is applied for miniImageNetsingle-session 5-shot setting. First two principal components are shown according to PCA. Redlabels indicate novel classes while the black indicates base. The green crosses indicate the semantictarget l of the respective novel class. Note that semantic targets are static: they don’t change duringfine-tuning. Notably, the semantic target for theater curtain falls closely to the class representationof the base class stage, dragging novel weight for theater curtain towards there. Same dynamic isvisible for novel class crate and base barrel.
