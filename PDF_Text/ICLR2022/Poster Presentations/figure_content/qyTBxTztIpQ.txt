Figure 1: Key parts of the CroWdPlay software architecture. Arrows show the flow of keypresses,observations and metadata between browser client, MDP environment, AI policies, and the database,and the eventual flow to an offline learning pipeline. The backend, load balancer, and database arehosted on cloud infrastructure.
Figure 2: Screenshots of the main screen of CrowdPlay (left) and an enlarged detail of the realtimeincentives (right).
Figure 3: t-SNE embedding of action distributions of different (human) participant types in single-agent games (left), and human and AI agents in cooperative and standard multiagent games (right).
Figure 4: Data quality for different incentive treat-ments and recruitment channels. Blue bars showthe total amount (in seconds) of “good data” col-lected per user, where this is defined as episodeswith at least 80% task adherence. Orange barsshow the fraction of good data compared to thetotal data collected per user.
Figure 6: Separate t-SNE embeddings of action distributions and behavioral statistics in multimodalbehaviors for human participants (left) and BC agents (right).
Figure 7: Screenshots of the “game choice” (left) and “high score” (right) screens of CrowdPlay.
Figure 8: Joint t-SNE embedding of action distributions and behavioral statistics in multimodalbehaviors for human participants (left) and BC agents (right).
Figure 9: Task specific performance profiles for offline RL algorithms on human demonstrations.
Figure 10: Aggregate metrics for offline RL algorithms on human demonstrations.).
