Figure 1: Models trained with gradient descent, with and without importance weights (IW), inthe label shift setting where classes are imbalanced in the training set. All models interpolate thetraining points with 100% accuracy. (Left) Importance weights provably fails to correct for thedistribution shift for the cross-entropy loss. The learned boundary is asymptotically the maximum-margin classifier even with reweighting. (Right) Our polynomially-tailed loss restores the effects ofimportance weights, correctly adjusting for the distribution shift.
Figure 2: A simulation study with class-conditional Gaussians, with d = 106, kμk2 = d0.502 andn = 100. The mean μι = ∣∣μ∣∣eι and μ2 = ∣∣μ∣∣e2, and q 〜N(0,Id×d). (Left) We plot the testerror of θ1 as τ varies for different choices of w , and also for the maximum margin classifier. Thechoice w = τ 3 leads to the lowest error throughout, while w = τ also does well for small τ . Boththe polynomially-tailed classifier with no importance weighting and the maximum margin classifiersuffer large test error. (Right) Here we fix the imbalance ratio τ = 10.1, and study how the error ofθb1 varies with w. When w = τ3, the error on both the majority and minority classes is almost equal,resulting in low overall test error.
Figure 3: Polynomially-tailed loss versus cross-entropy loss on a label shift dataset and a subpopu-lation shift dataset for neural networks optimized past 100% train accuracy without regularization.
Figure 4: Polynomially-tailed loss with exponentiated importance weights is better than or compet-itive with state of the art methods that address distribution shift. We tune all methods extensivelyusing the same validation set. We compare to cross entropy with undersampling (CE+US), label-distribution-aware margin loss (LDAM), class-dependent temperatures loss (CDT), logit-adjustedloss (LA), vector-scaling loss (VS), and the use of distributionally robust optimization (DRO).
Figure 5: Polynomially-tailed loss versus cross-entropy loss on a label shift dataset and a subpop-ulation shift dataset for neural networks early-stopped according to the best weighted validationaccuracy. * and ** indicate P < 0.05 and P < 0.005 statistical significance, respectively. Whileearly stopping is effective for both losses, our polynomially-tailed loss performs even better on im-balanced binary CIFAR10.
