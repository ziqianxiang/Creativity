Figure 1: Two different dimensions of lifelong lan-guage learning. The horizontal axis (Domain) indicatestasks of the same type (e.g., NER), whereas the verticalaxis (Task) indicates different kinds of tasks.
Figure 2: Task formulation for Named Entity Recognition (NER), classification and summarization.
Figure 3: Illustration of the learning process of LFPT5 for different task domains and task types. For learningnew domains, LFPT5 simultaneously trains the prompt embeddings as a task solver and a data generator. Whena new domain comes, it first generates pseudo samples of previous domains which will be combined with newdata for training to mitigate the forgetting of learned knowledge. A KL divergence loss is also optimized toachieve label consistency between the previous and current model. To learn a new task type, LFPT5 includesand tunes additional prompt embeddings for the new task while keeping the previous embeddings frozen.
Figure 4: Results for T5 prompt tuning (PT) and T5fine-tuning (FT) on summarization (ROUGE scores).
