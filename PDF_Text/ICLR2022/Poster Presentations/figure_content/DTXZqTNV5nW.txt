Figure 1: (a): The training curves of the best response against each agent. Lower is better. (b): Thetraining curves of each agent. The performance of an agent is evaluated by the average scores theagent wins against a common rule-based agent. Higher is better. We report the mean as solid curvesand the range of the average scores across 5 independent runs as shaded regions.
Figure 2: Performance of JueJong against human players.
Figure 3: The exploitability on FHP, with the x-axis being the number of episodes generated (left andright) and the number of samples consumed (middle). We report the mean as solid curves and therange as shaded regions across 3 independent runs. OS-DCFR and DREAM were run once as theirperformances are relatively stable, according to Brown et al. (2019) and Steinberger et al. (2020).
Figure 4:	The game complexity of Heads-up Limit Texas Hold’em (HULH), Heads-up No-LimitTexas Hold’em, 1-on-1 Mahjong, and 4-Player Mahjong.
Figure 5:	A list of all tiles in the 1-on-1 Mahjong game.
Figure 6: A flow chart of the 1-on-1 Mahjong game.
Figure 7: (a) The graphical user interface of 1-on-1 Mahjong with marked regions representingdifferent groups of information, which are encoded in either image-like features or one-hot features.
Figure 8: Exploitability of the weighted CFR with Wt(S) = fμ (S) and CFR (i.e., the weighted CFRwith Wt(S) = 1.0). The probability fμ (S) is determined by the behavior policy μp,t. The setting ofμp,t for each line is given in the legend, in which “Uniform” means μp,t(s) = the uniform policy;“Current” means μp,t(s) = ∏p,t(s); “Current(x)” means μp,t(s) = xUniform +(1 -x)∏p,t(s). Notethat the exploitability is reported with regard to the average policy.
Figure 9: The exploitability of the current policy in ACH with different behavior policies on FHP. Wereport the mean as solid curves and the range as shaded regions across 3 independent runs.
Figure 10: The training curves of each agent on the three benchmarks from OpenSpiel. We reportthe mean as solid curves and the range of the exploitability across 8 independent runs as shadedregions. We notice that there exists some discrepancy between the NeuRD results on Kuhn poker andLeduc poker reported here and those reported in Hennes et al. (2020) and Lanctot et al. (2019). Thereason might be due to NeuRD’s sensitivity to running environments including hyper-parameters andrandom seeds.
