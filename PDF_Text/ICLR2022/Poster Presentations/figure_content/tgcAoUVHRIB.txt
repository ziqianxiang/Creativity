Figure 1: MLP Framework for KG Reasoning. Representation of a sample query: ”List the teamswhere Brazilian football players who were awarded a Ballon d’Or played”. (A) Query representedby its logical statements and dependency graph. (B) 2D Representation of the answer entities in aone-point vector space used by the reasoning framework.
Figure 2: Multi-Later Perceptron Model (MLP) - Network Architecture.
Figure 3: MLP-Mixer. At the top, we show the block diagram of the MLP-Mixer Architecture. Itis formed by a per-patch fully connected module, N Mixer Modules, an average pooling and a lastfully connected module. The bottom figure shows the Mixer Module, which contains one channel-mixing MLP, each consisting of 2 fully-connected layers and a ReLu nonlinearity. It also includesskip-connections, dropout and layer norm on the channels.
Figure 4: Training and evaluation queries represented with their graphical structures and abbrevia-tion of their computation graphs. We consistently use the following nomenclature: p projection, iintersection, n negation, and u union.
Figure 5: Queries with negation used in the experiment used for both, training and testing. On theright side, we show the transformation process from the original queries to its negative structure.
