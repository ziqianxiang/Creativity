Figure 1: The proposed algorithm MEND enables editability by training a collection of MLPs to modify modelgradients to produce local model edits that do not damage model performance on unrelated inputs. MEND isefficient to train and apply edits, even for very large models, as shown in Section 5.1.
Figure 2: The MEND architecture, consisting of two consecutive blocks, both initialized to compute the exactidentity function. Left. The input to a MEND network is {δ'+ι, U'}, the components of the rank-1 gradient.
Figure 3: GPU VRAM consumptionduring training. ENN’s memory usage5is prohibitively high for very large mod-els, while MEND and KE can be trainedon a single GPU. Figure 4 shows similarchart for GPT models.
Figure 4: GPU VRAM consumption for training MEND, KE, and ENN in float32. MEND and KE’s memoryconsumption remain tractable for a single GPU (using 2×bfloat16 memory usage (Wang and Kanwar, 2019)for T5-11B), while ENN’s memory usage increases much more rapidly, making it impractical to run on a singleGPU. Values are computed without gradient checkpointing. Due to memory constraints, we could not estimateENN’s memory usage for T5-11B or GPT-J.
