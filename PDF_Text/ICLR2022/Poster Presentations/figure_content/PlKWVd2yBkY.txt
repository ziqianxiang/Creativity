Figure 1: 5, 10, 20, 50 and 100-steps generated results usingDDIMs, classical numerical methods and PNDMs.
Figure 2: the density distribution ofthe norm of the data.
Figure 3: The FID results under dif-ferent computation costs and differentnumerical methods on Cifar10. Theunit of time is the computational costof 1-step DDIM, which is 0.337s.
Figure 4: The upper part shows the change of norm with the number of steps using different methodsand different steps. The lower part shows the generation curves of two points using different methodsand different steps. DDIM-n means n-step DDIM method. Experiments in this subsection all usethe Cifar10 dataset and we use the 1000-step DDIM’s result as our target result.
Figure 5: The norm δ of the difference between two adjacent terms under different stepsRelationship between e§ and Xt To prove Property 3.1, assume that Xt = √αX0 + 1- - αte, NNis the neural network and θ = NN(xt, t). Because we assume that the gradient part is precise, thenwe have eθ = e. Then for all t0 ≤ t, we have:√a (SX0 + 海√ge -湛Fe) + √T-0t0eθ(Xt, t)ʌ/ α to X o + ʌ/- — α to e.
Figure 6: The generation curve of our toy example.
Figure 7: 5, 10, 20, 50, 100, 250, 500-steps generated results using DDIMs, classical numericalmethods and PNDMs on Cifar10.
Figure 8: 5, 10, 20, 50, 100, 250, 500-steps generated results using DDIMs, classical numericalmethods and PNDMs on CelebA.
Figure 9: Generated images of PNDMs on Cifar10.
Figure 10: Generated images of PNDMs on CelebA.
Figure 11: 5, 10, 20, 50, 100-steps generated results using DDIMs, classical numerical methods andPNDMs on LSUN-church.
Figure 12: 5, 10, 20, 50, 100-steps generated results using DDIMs, classical numerical methods andPNDMs on LSUN-bedroom.
Figure 13: Visualization results under 5, 10, 20, 25, 40 and 50 steps.
