Figure 1: MultiCriticAL breaks from the common practice of using a single unified critic in MTRLand instead uses separate critics for each task learned. The proposed method is used to successfullytrain multiple distinct behavior styles in various games including Pong and UFC.
Figure 2: The path-following task requires agents to learn a Circular, Square, or Triangular path.
Figure 3: Behav-ior samples for Ag-gressive and Defen-sive play in Pong.
Figure 4: Evaluated over two Sonic games with 17 training levels per game, where levels functionsimilarly but have significantly different layouts and visual design, MultiCriticAL offers consistentlysuperior performance to the single-critic baseline and achieves comparable, if not better performanceto agents trained specifically for each level - additional data and visualization in Appendix A.2.2.
Figure 5: We show 8 seconds of play with one representative frame per second for the differentstyles of play for the MultiCriticAL agent trained to play UFC. The RL agent has black hair whilethe stock AI has white hair. All styles are captured for the same RL agent, trained to play withmultiple behavior styles. As desired, the agent more frequently goes on the offensive when set toAggressively, prioritizes constant blocking and avoiding damage on Defensive, standing its groundand blocking incoming attacks on Blocking and moving around the ring for Moving.
Figure 6: Learning Curves for all tested SAC variants on the Path Following benchmark.
Figure 7: Learning Curves for all tested PPO variants on the Path Following benchmark.
Figure 8: Learning Curves for all tested SAC variants on the Pong benchmark.
Figure 9: Learning Curves for all tested PPO variants on the Pong benchmark.
Figure 10: Average Learning Curves the Sonic the Hedgehog benchmark games. Representedhere is the averaged reward over the 17 levels of the game as training progresses. We chose thisrepresentation in the interest of providing a more compact representation instead of including 34separate figures, with one for each level, as that would both require a lot of space and be moredifficult to parse.
Figure 11: Box and Whisker plots for Pong Results presented in Section 5.
Figure 12: Sonic Results from Tables 4 and 5 visualizedA.2.3 UFC Reward and Action StatisticsTable 6: Action probabilities for MTPPO and MH-MultiCriticAL-PPO on UFCDominant Style 11 No-action		Strike	Block	Move U Win Rate (%)	MTPPO					Aggressive	3.80	32.99	3.60	59.61	96Defensive	7.48	5.42	73.86	13.22	4(48% ties)Neutral	7.48	20.97	24.12	47.42	100Blocking	8.31	20.89	27.21	43.59	96Moving	6.46	26.75	15.91	50.89	88MH-MUltiCritiCAL-PPO					Aggressive	0.27	15.04	15.78	68.91	96Defensive	0.52	4.94	30.20	64.34	12 (56% ties)Neutral	0.57	11.30	22.88	65.25	88 (4% ties)Blocking	0.49	14.88	23.92	60.71	88Moving	0.59	8.70	20.88	69.82	64(8% ties)We observe from Figure A.2.3 and Table 6 that MultiCriticAL more consistently learns delineatedstyles that are consistent with the behaviors that the rewards try to encourage. Note that, with ourmethod, it is, in fact, the aggressive style that wins most fights consistently and the defensive stylelearns to block and move to not lose as quickly, whereas MTPPO tends seems to equate defensive
Figure 13: Box and Whisker plots for UFC style rewards presented in Section 5.
Figure 14: MN-MultiCriticAL and MH-MultiCriticAL frameworks compared. The main differ-ences between the multi-network (MN) and multi-headed (MH) is in how the critic functions areultimately represented by the neural network(s). In the MN case, separate and independent net-works are maintained for each style/task value function, whereas the MH configuration allows valuefunctions to share a common backbone and instead utilizes different network heads (i.e. outputnodes) for each learned value. While the former appears to offer superior performance in most ofthe tested cases, the latter can be less computationally expensive and may incur reduced trainingcosts. It should be noted, however, that neither architecture needs to impact the actor, thus preserv-ing run-time inference cost.
