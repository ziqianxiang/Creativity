Figure 1: An example of reward hacking when cars merge onto a highway. A human-driver modelcontrols the grey cars and an RL policy controls the red car. The RL agent observes positionsand velocities of nearby cars (including itself) and adjusts its acceleration to maximize the proxyreward. At first glance, both the proxy reward and true reward appear to incentivize fast traffic flow.
Figure 2: Increasing the RL policy’s model size decreases true reward on three selected environ-ments. The red line indicates a phase transition.
Figure 3: In addition to parameter count, we consider three other agent capabilities: training steps,action space resolution, and observation noise. In Figure 3a, an increase in the proxy reward comesat the cost of the true reward. In Figure 3b, increasing the granularity (from right to left) causes theagent to achieve similar proxy reward but lower true reward. In Figure 3c, increasing the fidelityof observations (by increasing the random testing rate in the population) tends to decrease the truereward with no clear impact on proxy reward.
Figure 4: The larger model prevents the AVs (in red) from moving to increase the velocity of thehuman cars (unobserved cars in white and observed cars in blue). However, this greatly increasesthe average commute per person.
Figure 5: For COVID, ICU usage is a proxy for public health and regulation stage is a proxy foreconomic health. The blue line indicates the maximum stage (right) enforced by the larger policy andthe corresponding ICU level (left) at that stage. The red line is the equivalent for the smaller policy.
Figure 6: Correlations between the proxy and true rewards, along with the reward hacking induced.
Figure 7: Additional model size scatter plots. Observe that not all misspecifications cause mis-alignment. We plot the proxy reward with "•" and the true reward with "x”. The proxy reward ismeasured on the left-hand side of each figure and the true reward is measured on the right hand sideof each figure.
Figure 8: Correlations between the proxy and true rewards, along with the reward hacking induced.
Figure 9: ROC curves for Traffic-Mer - misweighting.
Figure 10: ROC curves for Traffic-Mer - scope.
Figure 11: ROC curves for Traffic-Mer - ontological.
Figure 12: ROC curves for Traffic-Bot - misweighting.
Figure 13: ROC curves for COVID - ontological.
