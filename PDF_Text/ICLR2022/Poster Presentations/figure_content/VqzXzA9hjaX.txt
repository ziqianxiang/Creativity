Figure 1: Amalgamated optimizer performance as measured by the best log validation loss and log trainingloss (lower is better) after 25 epochs; 95% confidence intervals are shown, and are estimated by a linear mixedeffects model (Appendix D). In order to use a common y-axis, the validation loss is measured relative to themean validation loss of the optimizer amalgamated from the large pool using optimal Choice amalgamation.
Figure 2: Comparison with other learned optimizers; for each problem, 95% confidence intervals of the meanare computed using a linear mixed effects model (Appendix D). Error bars are normalized by subtracting themean log validation loss of the amalgamated optimizer to use the same Y-axis. Uncropped and accuracy versionscan be found in Appendix E.3. The amalgamated optimizer performs better than other learned optimizers on allproblems, and is significantly better except in some problems when compared to the Stronger Baselines trainedRNNProp (Chen et al., 2020a).
Figure 4: Relationship between optimiza-tion stability and performance as measuredby validation loss on the Train optimizee;smaller stability and validation loss are better.
Figure 5: Optimization stability (lower is more stable) of an optimizer amalgamated by Optimal Choice from thelarge pool compared to optimization stability of the optimizers in that pool; 95% confidence intervals are shown.
Figure 6: Amalgamation meta-stability forvarying magnitudes of random and adver-sarial perturbations (lower is better). Meta-stability is measured by the variance acrossreplicates of the training loss after 25 epochson the Train convolutional network, adjustedfor the variance of evaluation.
Figure 8: Amalgamated optimizer ablations on problems of increasing size relative to the trainingproblem.
Figure 9: Uncropped version of Figure 2. Poor performance of “Scale” and “Original” on small batchand differentially private training cause differences between the best performers (Amalgamated and StrongerBaselines) to be unreadable. A version showing the best validation accuracy is also included (higher is better);the accuracy results largely preserve relative differences between methods, and lead to the same conclusion.
Figure 10: Uncropped version of Figure 5 including similar plots for Training and Validation loss.
Figure 11: An accuracy version of Figure 3 comparing the best Amalgamated Optimizer (blue) and the OracleOptimizer (orange); the shaded area shows ±2 standard deviations from the mean. The title of each plotcorresponds to an optimizee; full definitions can be found in Appendix B. The amalgamated optimizer performssimilarly or better than the Oracle analytical optimizer on problems spanning a variety of training settings,architectures, and datasets, and has the largest advantage on more difficult problems such as CIFAR-10, ResNet,and MNIST-DP.
Figure 12: Comparison of 8 replicates amalgamated from the Large pool using Choice amalgamation withRNNProp baseline with Gaussian perturbations, with magnitude 1 × 10-4. With perturbations, the RNNPropbaseline is significantly improved, though not enough to match the performance of our amalgamation method.
