Figure 1: (a) Our proposed ReLoss significantly improves the ranking correlations between lossesand metrics on various tasks. (b) Taking neural machine translation task as an example, we sample10 sentences from WMT16 RO-EN dataset, then measure the BLEU, cross entropy (CE) loss, andReLoss with trained network and ground-truth references. Compared to the original CE loss, ourReLoss obtains a stronger rank correlation.
Figure 2: Visualization of our toy experiments on the synthetic dataset. (a) Visualization of out-puts of approximation-based surrogate loss and evaluation metric on the validation set. (b) Curvesof Spearmansâ€™ rank correlations between surrogate losses and evaluation metric in the training oflosses. (c) Evaluation curves of different losses in training, lower is better.
Figure 3: (a) Evaluation results on CIFAR-10 using ReLoss with different rank correlations. (b)Evaluation results on CIFAR-10 using different capacities of surrogate losses.
Figure 4: Convergence curves (validation accuracies) of CE loss and our loss on CIFAR-10, CIFAR-100, and ImageNet datasets. The data is smoothed using a moving average with a factor 0.25. Zoomup to view better.
