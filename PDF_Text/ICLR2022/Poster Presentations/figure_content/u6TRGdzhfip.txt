Figure 1: (a) Unreliability issue: Comparison of the teacher model’s accuracy on the natural data andthe student model’s adversarial data from CIFAR-10 datasets. Different from the ordinary distillationin which the natural data is unchanged and the teacher model has the consistent standard performance,the teacher model’s robust accuracy on the student model’s adversarial data is decreasing duringdistillation, which means the guidance of the teacher model in adversarial distillation is progressivelyunreliable. (b) Overview of Introspective Adversarial Distillation (IAD): The student partiallytrusts the teacher guidance and partially trusts self-introspection during adversarial distillation.
Figure 2: (a) Toy illustration: An illustration of three situations about the prediction of the teachermodel. The blue/orange areas represent the decision region (in which the model can give the correctpredictions) of the teacher/student model, and the red dashed box represents the unit-norm ball of AT.
Figure 3: Reliability certification about self-introspection of the student model: Left, PGD-10 trainingaccuracy of teacher/student model; Middle, PGD-10 training accuracy of teacher model and thatcombined with the self-introspection of the student model; Right, PGD-10 test accuracy of the studentmodel which only trusts the soft labels and the student model which also considers self-introspection.
Figure 4: Analysis about using different β and warming-up periods in IAD: Left, the values of ɑ(Eq. 4) under different β; Middle, Natural and PGD-20 accuracy of teacher model using different β;Right, Natural and PGD-20 accuracy of the teacher model with different warming-up periods.
