Figure 1: Efficiency vs accuracy comparison under the linear classification protocol on ImageNet.
Figure 2: Pre-training objectives, including view-level (left) and region-level (right) prediction.
Figure 3: Linear probing on 18 downstream datasets. Averaged scores are reported for each method.
Figure 5: The learned correspondences. Yellow lines are the top-10 correspondences between twoviews, where the numbers indicates the rankings of similarity scores, yellow dots with the samenumber are paired.
Figure 6: Visualization of the the learned attention map for different heads in the last layer. The queryis the blue dot in the center of the images. We visualize masks (as red) obtained by thresholdingthe self-attention maps to keep 60% of the probability mass. Note that all 6 heads are visualizedfor DINO with DeiT-S, and 6 out of 24 heads in EsViT are chosen to visualize (ranked by entropyvalues). Please see enlarged pictures with all heads in Appendix.
Figure 7: Architecture comparison. (a) The monolithic transformer. For all layers, the transformerblocks share the same network configurations and input token sequence sizes are the same. (b) Themulti-stage Transformer organizes an input image into a long sequence of smaller patches, sparseself-attentions (S.A.) are utilized at early stages to maintain model expressiveness while reducingcomputational complexity; The neighboring tokens at an intermediate layer are gradually merged,constituting a short sequence to ease the compute burden of self-attention at late stages.
Figure 8: Quantitative evaluation on correspondence learning on ImageNet validation set. LR cansignificantly improve correspondence learning quality for multi-stage architectures. As a reference,DINO (LV with monolithic Transformer architecture) achieves 0.95 accuracy and 2.49 distance error,which we believe is a strong evidence to identify the intriguing property of automatic correspondencelearning.
Figure 9: The learned correspondences. Yellow lines are the top-10 correspondences between twoviews, where the numbers indicates the rankings of similarity scores, yellow dots with the samenumber are paired. The blue dot and red triangle indicates the most similar local regions thatcorrespond to the global feature of the view itself and the other view, respectively. Please zoom in fordetailed correspondence mappings.
Figure 10: The learned attention maps for all heads at the top layer, ranked by the entropy of softmaxprobability. Query is the blue dot in the top-left of the image. Top: Entropy of each heads. Middle:top 60% probability mass. Bottom: full attention maps. LR shows more attention patterns than LVonly.
Figure 11: The learned attention maps for all heads at the top layer, ranked by the entropy of softmaxprobability. Query is the blue dot in the center of the image. Top: Entropy of each heads. Middle: top60% probability mass. Bottom: full attention maps. LR shows more attention patterns than LV only.
Figure 12: The learned attention maps for all heads at the top layer, ranked by the entropy of softmaxprobability. Query is the blue dot in the top-left of the image. Top: Entropy of each heads. Middle:top 60% probability mass. Bottom: full attention maps. DINO mainly attends the main object evenwhen the query is a background region.
