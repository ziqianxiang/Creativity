Figure 1: Picture hanging task with varying sets of tool-actions. The strategy with each action setdepends on all the pairwise action relations. (Left) The agent infers that a nail and a hammer arestrongly related (bold line). Thus, it takes nail-action in Step-1 because hammer-action is availablefor Step-2. (Right) With a different action set, the nail-action is no longer useful due to the absenceof a hammer. So, the agent must use an adhesive-tape in Step-1 since its related action of the hook isavailable for later use. We show that a policy with GAT over actions can learn such action relations.
Figure 2: Given an action set, AGILE builds a complete graph where each node is composed of anaction representation and the state encoding. A graph attention network (GAT) learns action relationsby attending to other relevant actions for the current state. For example, the attention weight betweenthe cannon and the fire is high because fire can activate the cannon. The GAT outputs more informedrelational action representations than the original inputs. Finally, a utility network computes eachaction’s value or selection probability in parallel using its relational action representation, the state,and a mean-pooled summary vector of all available actions’ relational features.
Figure 3: Environment Setup. (Left) In Grid World, the red agent must avoid orange and Pinklava to reach the green goal. The dig-lava skills enable shortcut paths to the goal when available.
Figure 4: We evaluate AGILE against baselines on training actions (top) and unseen testing actions(bottom). Generalization is enabled by continuous action representations, except Grid World (Ap-pendix A). An architectures share the same RL algorithm (PPO or CDQN). The results are averagedover 5 random seeds, and the seed variance is shown with shading. AGILE outperforms all baselinesthat assume a fixed action set (cannot generalize) or treat actions independently (suboptimal).
Figure 5: Test performance of AGILE against ablations with utility network using only action setsummary, but not the relational action representations. The difference is most pronounced in CRE-ATE, where there are several diverse action (tool) relations for each action decision.
Figure 6:	Qualitative Analysis. (a,b) The attention maps from GAT show the reasoning behind anaction decision. The nodes show available actions, and edge widths are proportional to attentionweight (thresholded for clarity). (b) Utility Policy learns the same suboptimal solution for anygiven action set, while Summary-GAT (like AGILE) adapts to the best strategy by exploiting dig-skills. (c) AGILE can optimize CPR by identifying the most common item category available,unlike Utility Policy. We provide qualitative video results for Grid World and CREATE on theproject page https://sites.google.com/view/varyingaction.
Figure 7:	Additional Analyses. (i) GAT v/s GCN (ii) state-action relations v/s action-only relations.
Figure 8: CREATE Activator Mapping: Original CREATE tools (right) are activated by the re-spective newly introduced activator tools (left). E.g., a Cannon tool (abbreviated as CNN in attentionmaps) placed on the environment will only be functional when a Fire tool is placed in contact withit. Other objects are not affected by non-functional tools - they simply pass through.
Figure 9: t-SNE visualization of synthetically generated items in RecSim.
Figure 10: Real-Data Recommender System: F1 Score for Training/test user models. (Left) Theonline user model is trained on online-training data and evaluated on both online-training (green)and online-held-out (orange) data. (Right) The offine user model is trained on offline-training dataand evaluated on both offline-training (green) and offline-held-out data (orange). Thus, the disparitybetween online data training and evaluation curves (left) shows that it is hard to train the online usermodel. In contrast, the offline user model generalizes reasonably well (right).
Figure 11: (a) t-SNE visualization of split of train and test item representations. This shows that thetrain and test items are within the same distribution (b) Visualizations of item representations clus-tered according to the main category. This shows that item representations contain information aboutthe main category, which is necessary to maximize CPR. (c) Item distribution labeled according tosub category, which is another information necessary for CPR.
Figure 12: Effect of using domain knowledge to predefine the possible relations via edges in theaction graph of AGILE. We know that in the Grid Navigation task, only the action relations withrespect to variable actions are important. Thus, we remove all the other edges. This makes thelearning slightly faster and more stable as shown by a reduction in seed variance. (5 seeds)(b) Attention Map: Fewer edgesB.2	Validating design choices for value-based AGILEWe conducted an exhaustive search on the architecture of value-based AGILE from two different per-spectives; (a) Hyper-parameters and (b) Architectures. Note that the same hyper-parameter searchprocedure of this section was applied to all other methods, and the same trend of the improvementin AGILE was found for other methods. In this section, AGILE used in the main results (Fig. 4, 5,7) is called AGILE-Tuned. The barebone version of AGILE-Tuned is called AGILE-Untuned. Weillustrate how each change contributes to an improvement in performance.
Figure 13: Results of value-based AGILE on RecSim CPR task (a) hyperparameter testing and (b)validating architecture design choices, on train actions (left) and test actions (right).
Figure 14: Comparison against the baselines on train (top) and test (bottom) actions on the DirectCPR (left) and Pairing (right) ReCSim environments. Along with Figure 4, these results exhibit thesame trend that AGILE consistently outperforms all the baselines on both train and test actions.
Figure 15: Comparison against ablations on the Direct CPR (left) and Pairing (right) RecSim envi-ronments. Along with Figure 5, these results exhibit the same trend that AGILE slightly outperformsthe various summary ablations, which do not explicitly utilize relational action features and rely onlyon the summary vector to encode all the necessary action relations.
Figure 16: Analyses of (i) GAT v/s GCN and (ii) state-action graph v/s action-only graphs on (left)RecSim: Direct CPR environment and (right) RecSim: Pairing environment.
Figure 17: ArChiteCtures of all methods used as baselines (SeC. 6.1.1), ablations (SeC. 6.1.2), andanalyses (Sec. 6.3.2). (a) Following prior work in SAS-MDPs (Boutilier et al., 2018; Chandak et al.,2020a) and invalid action masking (Huang & θntanðn, 2020; Ye et al., 2020; Kanervisto et al.,2020), the mask-output baseline masks out the unavailable actions assuming a known action set.
