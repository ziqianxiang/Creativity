Figure 1: Two existing approaches to use optimal transport in generative models.
Figure 2: Monge’s OT.
Figure 3: The existing most prevalent approach to use OT maps in generative models.
Figure 4: The scheme of our approach for learningOT maps betWeen unequal dimensions. In the fig-ure, the setup of M5.1 is shown: μ is a noise, Q isthe bicubic upscaling, V is a distribution of images.
Figure 5: Randomly generated MNIST, CIFAR10, and CelebA samples by our method (OTM).
Figure 6: The training/testing scheme that we use for unpaired restoration tasks.
Figure 7: OTM for image denoising on test C part of CelebA, 64 × 64.
Figure 8: OTM for image colorization on test C part of CelebA, 64 × 64.
Figure 9: OTM for image inpainting on test C part of CelebA, 64 × 64.
Figure 10: Qualitative results of OTM on the ”Early” images benchmark pair (μ, V) by Korotin et al.
Figure 11: OTM between 128-dimensional noise and CelebA, 128 × 128. The 1st line showsthe grayscale embedding Q (repeating bicubic upscaling of a noise, 16 × 8), the 2nd line showscorresponding generated samples, and the 3rd line shows random samples from the dataset.
Figure 12: OTM between 192-dimensional noise and Anime, 128 × 128. The 1st line shows thecolor embedding Q (bicubic upscaling of a noise, 3 × 8 × 8), the 2nd line shows correspondinggenerated samples, and the 3rd line shows random samples from the dataset.
Figure 13: Randomly generated MNIST, CIFAR10, and CelebA samples by our method (OTM).
Figure 14: OTM for latent space interpolation on CelebA, 64 × 64. Extended samples.
Figure 15: OTM for image denoising for varying levels of noise on test C part of CelebA, 64 × 64.
Figure 16: Mapping between a Gaussian and a Mixture of 8 Gaussians in 2D by various methods.
Figure 17: OTM on toy datasets, D = 2. Here, the colors green, blue, and peru represent input,pushforward, and output samples respectively.
