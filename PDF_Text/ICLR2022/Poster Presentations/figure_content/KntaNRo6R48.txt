Figure 1: Illustration of '0-DCCA. Data from two observed views propagate through stochasticgates (defined in Eq. 4). The gates output is fed into two neural sub-nets that have a shared loss (seeEq. 5). We compute this shared loss based on the neural sub-nets outputs (with dimension d = 3 inthis example). Our shared loss combines a total correlation term with a differentiable regularizationterm which induces sparsity in the input variables (by sparsifying the gates).
Figure 2: Left: Regularization path of '0-CCA on data generated from the linear model I (describedin Section 5.1). Values on the left y-axis (green) represent the sum of active gates (by expectation).
Figure 3: Left: two samples from the spinning puppets videos. The videos capture the rotation of 3desk puppets. Arrows indicate the spinning direction of each puppet. We use '0-CCA to identify asparse subset of pixels that are correlated from both videos. Right: the values of the gates for eachvideo zx and zy. After training, the values of the gates are binary (i.e., {0, 1}), with 372 and 403active gates for the left and right videos, respectively. '0-CCA correctly select correlated subsets ofpixels that highlight the common DUDDet (BUndOg) in this example.
Figure 4: The correlated '0-CCA representations (visualized using MVDM (Lindenbaum et al.,2020)) of the Yoda+Bulldog video (left) and Bulldog+Bunny (right). We superimpose each em-bedding with 6 images corresponding to 6 points in the embedding spaces. The transformationsare based on the information described by pixels whose gates are active (presented in Fig. 3). Theresulting embeddings are correlated with each other, with a total correlation of P= 1.99. The struc-ture captured by the embeddings correctly represent the angular rotation of the Bulldog, which isthe common latent parameter in this experiment.
Figure 5: Images from the coupled noisy MNIST dataset. In the bottom right of both panels, Wepresents the active gates (white values within a green frame). There are 277 and 258 active gates forvieW I and II, respectively.
Figure 6: Top: Clean sample sonograms of an explosion based on the E and N channels (left andright, respectively). Arrows highlight the Primary (P) and Secondary (S) waves caused by the ex-plosion. Middle: noisy sonograms generated by adding sonograms of vehicle recordings. Bottom:the active gates for both channels. Note that the gates are active at time-frequency bins which corre-spond to the P and S waves (see top left panel).
Figure 7: Regularization path of `0 -CCA on data generated from the linear model I (described inSection 5.1). Values on the left y-axis (green) represent the sum of active gates (by expectation).
Figure 8: k-means and SVM classification accuracy (left) and mutual information score (right) vs.
Figure 9: Classification accuracy on the noisy seismic data. Performance is evaluated using linearSVM in the 3 dimensional embedding. Comparing performance of '0-DCCA for different levels ofsparsity, and using linear and nonlinear activation (tanh).
Figure 10: Run time evaluation of the proposed approach. We measure the average runtime (over100 runs) for different values of N and Dx , Dy .
