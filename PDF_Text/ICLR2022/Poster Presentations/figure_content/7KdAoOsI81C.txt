Figure 1: An example of the transfer problem with changed observation space. The source-task agent observesthe x-y coordinates of itself and the goal, while the target-task agent observes a top-down view/image of thewhole maze. The two observation spaces are drastically different, but the two tasks are structurally similar. Ourgoal is to transfer knowledge from the source task to accelerate learning in the target task, without knowing orlearning any inter-task mapping.
Figure 2: The architecture of proposed method.
Figure 3: Our proposed transfer method outperforms all baselines in target tasks over all tested scenarios. (Thedashed green lines are the learning curves in source tasks.) Results are averaged over 10 random seeds.
Figure 4: Ablation Studytrol the weight of the transferred model-based regularizer. Figure 7 in Appendix E.2 shows that, fora wide range of λ's, the agent consistently outperforms the single-task learner.
Figure 5: Ablation study of our method on different transferred components.
Figure 6: In the Vec-to-pixel CartPole environment,sanity check verifies the effectiveness of our algorithmdesign. Results are averaged over 20 random seeds.
Figure 7: In the Vec-to-pixel CartPole environment,under different selections of hyperparameter λ, the al-gorithm works better than learning from scratch (whenλ = 0). Results are averaged over 20 random seeds.
