Figure 1: Overview of our proposed approach. Given a pre-trained neural network model, whichcan be either an unsupervised generative model pθ (x) (e.g. GANs, VAEs), or a supervised learningmodel pθ (y|x), We aim to extract a compact yet informative representation from it. By reinterpretingvarious families of models as energy-based models (EBM), We introduce Neural Fisher Kernel (NFK)Knfk as a principled and unified kernel formulation for neural network models (Section. 3.1). Weintroduce a highly efficient and scalable kernel approximation algorithm (Section. 3.2) to obtain thelow-dimensional feature embedding ex , which serves as the extracted data representation from NFK.
Figure 2: Left: The spectrum structure of NFKs from a CNN (green) and a MLP (red), trained onMNIST binary classification task. The NFK of CNN concentrates on fewer eigen-modes comparedto the MLP. Right: The low-rankness of the NFK on a DCGAN trained on MNIST. For a trainedmodel, the first 100 principle components of the Fisher Vector matrix explain 99.5% of all variances.
Figure 3: Top row: Running time efficiency evaluation for truncated SVD algorithm on single GPU.
Figure 4: Inverting a DCGAN with 100d NFK embeddings (a), compared with image reconstructionwith 100d PCA embeddings (b). In either case, the left plot corresponds to real test images and theright corresponds to the reconstructions. Note that NFK embeddings care capable of inverting aGAN by producing high quality semantic reconstructions. With PCA, embeddings with the samedimensionality produces more blurry reconstructions (thus less semantic).
Figure 5: The low-rankness of the NFK on a DCGAN trained on MNIST. For a trained model,the first 100 principle components of the Fisher Vector matrix explains 99.5% of all variances. Anuntrained model with the same architecture on the other hand, demonstrates a much lower degree oflow-rankness.
Figure 6: Images with the largest projections on the first five principle components. Each rowcorresponds to a principle component.
Figure 7: Linear probing accuracy on CIFAR10 with different number of principle components inembedding. We use our proposed low-rank approximation method to compute the embedding fromthe teacher model on CIFAR10 for knowledge distillation.
