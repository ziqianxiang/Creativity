Figure 1: Illustration of existing rehearsal-based CL and Online Coreset Selection (OCS): (a) Existingrehearsal-based methods train on all the arrived instances and memorize a fraction of them in the replay buffer,which results in a suboptimal performance due to the outliers (noisy or biased instances). (b) OCS obtains thecoreset by leveraging our three selection strategies, which discard the outliers at each iteration. Consequently,the selected examples promote generalization and minimize interference With the previous tasks.
Figure 2: Realistic continual learning scenarios: (a) Each task consists of class-imbalanced instances.
Figure 3: Per-class accuracy and average forgettingwhen a model trained on MNIST (T1) is updated on asingle data point at class c on CIFAR- 1 0 (T2).
Figure 4: (a) Average accuracy (b) First task accuracy for balanced/imbalanced Rotated MNIST during CL.
Figure 5: Performance comparison on various coreset sizes for balanced/imbalanced continual learning.
Figure 7: Randomly picked coreset examples. Top:Imbalanced Rotated MNIST. Bottom: Noisy RotatedMNIST with 60% of noisy instances.
Figure 6: Interpolat-ion between S and V .
Figure 8: T-SNE visualization of the selected sampleson Imbalanced Rotated MNIST.
