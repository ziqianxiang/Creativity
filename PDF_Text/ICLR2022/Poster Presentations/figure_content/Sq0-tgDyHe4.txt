Figure 1: Channel-consistent LOcal Permutation Layer (CLOP)α=0α = 0.2α = 0.4	α = 0.6	α = 0.8	α = 1Figure 2: Examples of CLOP layer outputs with different values for αThe CLOP technique transposes these intuitions into convolutional networks. We implement it as aregularization layer that we introduce after the deepest convolutional layer’s feature maps. Duringtraining, it swaps the position of pixels in these feature maps, while preserving the consistencyacross channels, so as to preserve the positional consistency between feature maps. This swappingis performed sequentially in a random order among pixels, locally (each pixel is swapped with oneof its neighbors), and with probability α. At evaluation time, the CLOP layer behaves like theidentity function. Figure 1 illustrates this process and presents the pseudo-code. Since pixels aretaken in a random order, a given pixel value might be “transported” far from its original position,with a small probability. Figure 2 illustrates the effect of varying values of α on the output of thelayer. Since CLOP is applied after the deepest convolutional layer, each of the pixels in this imageshould be interpreted as a salient high-level feature in the input image, and the channels correspondto different filters. CLOP shuffles these descriptors while preserving channel consistency (no newcolors are created in Figure 2) and neighborhoods (objects remain close to each other).
Figure 2: Examples of CLOP layer outputs with different values for αThe CLOP technique transposes these intuitions into convolutional networks. We implement it as aregularization layer that we introduce after the deepest convolutional layer’s feature maps. Duringtraining, it swaps the position of pixels in these feature maps, while preserving the consistencyacross channels, so as to preserve the positional consistency between feature maps. This swappingis performed sequentially in a random order among pixels, locally (each pixel is swapped with oneof its neighbors), and with probability α. At evaluation time, the CLOP layer behaves like theidentity function. Figure 1 illustrates this process and presents the pseudo-code. Since pixels aretaken in a random order, a given pixel value might be “transported” far from its original position,with a small probability. Figure 2 illustrates the effect of varying values of α on the output of thelayer. Since CLOP is applied after the deepest convolutional layer, each of the pixels in this imageshould be interpreted as a salient high-level feature in the input image, and the channels correspondto different filters. CLOP shuffles these descriptors while preserving channel consistency (no newcolors are created in Figure 2) and neighborhoods (objects remain close to each other).
Figure 3: Example of levels heterogeneity on two Procgen environments(b) Leapereralization performance compared to the other methods, thus confirming the intuition that localizedpermutations at the feature level during training may improve generalization at testing. Appendix Dfeatures an extended discussion on the application of CLOP to other datasets (including Imagenet)and a comparison with mixup (Zhang et al., 2018c).
Figure 4: Average sum of rewards on test environments, versus time steps.
Figure 5: Influence of the α parameter on test performance.
Figure 6: Applying the CLOP layer (α = 0.5). Ablation of the locality and consistency properties.
Figure 7: Ablation study, effect on the score(c) Chaser(a) CLOP (b) No locality (c) CLOP (d) No locality (e) CLOP (f) No localityFigure 8: Saliencies induced by the locality property (α = 0.5)ing spatial knowledge (length, width, and channel-wise) in the latent space. We also used Grad-Cam(Selvaraju et al., 2017) to produce visual explanations of the importance of these two factors (Fig-ure 8).3 An agent trained using a CLOP layer stripped of the local permutation feature focuses ona spread-out portion of the image, while the full CLOP agent displays very focused saliency areas.
Figure 8: Saliencies induced by the locality property (α = 0.5)ing spatial knowledge (length, width, and channel-wise) in the latent space. We also used Grad-Cam(Selvaraju et al., 2017) to produce visual explanations of the importance of these two factors (Fig-ure 8).3 An agent trained using a CLOP layer stripped of the local permutation feature focuses ona spread-out portion of the image, while the full CLOP agent displays very focused saliency areas.
Figure 9: CLOP layer within the IMPALA architectureGame	alphaBigfiSh- StarPilot FruitBot BossFight Ninja Plunder CaveFlyer CoinRun Jumper Chaser Climber Dodgeball Heist Leaper Maze Miner	0.6 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.3 0.8 0.3 0.6 0.3 0.8 0.3 0.3Table 4: Values of αB	Reproducib ilityAll the experiments from Section 5 were run on a desktop machine (Intel i9, 10th generation pro-cessor, 32GB RAM) with a single NVIDIA RTX 3080 GPU. Details about each experiments arereported in Table 5.
Figure 10: Train and test learning curves in easy modeDifference(b) Testing levelsIUn8432AUnoU(a) Training levelsFigure 11: Comparison of CLOP and IDAAC’s performance (data from Table 13)19Published as a conference paper at ICLR 2022Game	PPO	Mixreg	Rand + FM	UCB-DraC	IBAC-SNI	RAD	IDAAC	CLOP (Ours)Bigfish	18.1 ± 4.0 =	15.0 ± 1.3	6.0 ± 0.9	12.8 ± 1.8	19.1 ± 0.8	13.2 ± 2.8	21.8 ± 1.8 =	26.9 ± 2.0BossFight	10.3 ± 0.6	7.9 ± 0.8	5.6 ± 0.7	8.1 ± 0.4	7.9 ± 0.7	8.1 ± 1.1	10.4 ± 0.4	10.6 ± 0.6CaveFlyer	7.8 ± 1.4	6.2 ± 0.7	6.5 ± 0.5	5.8 ± 0.9	6.2 ± 0.5	6.0 ± 0.8	6.2 ± 0.6	6.6 ± 0.5Chaser	8.0 ± 1.2	3.4 ± 0.9	2.8 ± 0.7	7.0 ± 0.6	3.1 ± 0.8	6.4 ± 1.0	7.5 ± 0.8	9.6 ± 1.0Climber	10.2 ± 0.4	7.5 ± 0.8	7.5 ± 0.8	8.6 ± 0.6	7.1 ± 0.7	9.3 ± 1.1	10.2 ± 0.7	9.6 ± 0.2CoinRun	10.0 ± 0.0	9.5 ± 0.2	9.6 ± 0.6	9.4 ± 0.2	9.6 ± 0.4	9.6 ± 0.4	9.8 ± 0.1	9.9 ± 0.1Dodgeball	10.8 ± 1.7	9.1 ± 0.5	4.3 ± 0.3	7.3 ± 0.8	9.4 ± 0.6	5.0 ± 0.7	4.9 ± 0.3	11.7 ± 1.5
Figure 11: Comparison of CLOP and IDAAC’s performance (data from Table 13)19Published as a conference paper at ICLR 2022Game	PPO	Mixreg	Rand + FM	UCB-DraC	IBAC-SNI	RAD	IDAAC	CLOP (Ours)Bigfish	18.1 ± 4.0 =	15.0 ± 1.3	6.0 ± 0.9	12.8 ± 1.8	19.1 ± 0.8	13.2 ± 2.8	21.8 ± 1.8 =	26.9 ± 2.0BossFight	10.3 ± 0.6	7.9 ± 0.8	5.6 ± 0.7	8.1 ± 0.4	7.9 ± 0.7	8.1 ± 1.1	10.4 ± 0.4	10.6 ± 0.6CaveFlyer	7.8 ± 1.4	6.2 ± 0.7	6.5 ± 0.5	5.8 ± 0.9	6.2 ± 0.5	6.0 ± 0.8	6.2 ± 0.6	6.6 ± 0.5Chaser	8.0 ± 1.2	3.4 ± 0.9	2.8 ± 0.7	7.0 ± 0.6	3.1 ± 0.8	6.4 ± 1.0	7.5 ± 0.8	9.6 ± 1.0Climber	10.2 ± 0.4	7.5 ± 0.8	7.5 ± 0.8	8.6 ± 0.6	7.1 ± 0.7	9.3 ± 1.1	10.2 ± 0.7	9.6 ± 0.2CoinRun	10.0 ± 0.0	9.5 ± 0.2	9.6 ± 0.6	9.4 ± 0.2	9.6 ± 0.4	9.6 ± 0.4	9.8 ± 0.1	9.9 ± 0.1Dodgeball	10.8 ± 1.7	9.1 ± 0.5	4.3 ± 0.3	7.3 ± 0.8	9.4 ± 0.6	5.0 ± 0.7	4.9 ± 0.3	11.7 ± 1.5FruitBot	31.5 ± 0.5	29.9 ± 0.5	29.2 ± 0.7	29.3 ± 0.5	29.4 ± 0.8	26.1 ± 3.0	29.1 ± 0.7	31.6 ± 1.0Heist	8.8 ± 0.3	4.4 ± 0.3	6.0 ± 0.5	6.2 ± 0.6	4.8 ± 0.7	6.2 ± 0.9	4.5 ± 0.3	9.3 ± 0.4Jumper	8.9 ± 0.4	8.5 ± 0.4	8.9 ± 0.4	8.2 ± 0.1	8.5 ± 0.6	8.6 ± 0.4	8.7 ± 0.2	8.9 ± 0.3LeaPer	7.1 ± 1.6	3.2 ± 1.2	3.2 ± 0.7	5.0 ± 0.9	2.7 ± 0.4	4.9 ± 0.9	8.3 ± 0.7	9.9 ± 0.2Maze	9.9 ± 0.1	8.7 ± 0.7	8.9 ± 0.6	8.5 ± 0.3	8.2 ± 0.8	8.4 ± 0.7	6.4 ± 0.5	9.7 ± 0.1Miner	12.7 ± 0.2	8.9 ± 0.9	11.7 ± 0.8	12.0 ± 0.3	8.5 ± 0.7	12.6 ± 1.0	11.5 ± 0.5	12.8 ± 0.1Ninja	9.6 ± 0.3	8.2 ± 0.4	7.2 ± 0.6	8.0 ± 0.4	8.3 ± 0.8	8.9 ± 0.9	8.9 ± 0.3	8.0 ± 0.5Plunder	8.9 ± 1.7	6.2 ± 0.3	5.5 ± 0.7	10.2 ± 1.8	6.0 ± 0.6	8.4 ± 1.5	24.6 ± 1.6	6.8 ± 1.0StarPilot	44.7 ± 2.4	28.7 ± 1.1	26.3 ± 0.8	33.1 ± 1.3	26.7 ± 0.7	36.5 ± 3.9	38.6 ± 2.2	45.6 ± 2.8
Figure 12: CLOP and PPO performance in hard mode.
Figure 13: Ablation study on all games.
Figure 14: Test accuracy for different positions of the CLOP layer24Published as a conference paper at ICLR 2022Figure 7 reports the difference in performance between the two versions of PPO, confirming thisanalysis on a limited set of Procgen games.
