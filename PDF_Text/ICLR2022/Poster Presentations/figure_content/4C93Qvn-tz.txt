Figure 1: Demonstration of mixing MCMC with neural transport learned from a mixture of eight2D Gaussians. The Markov chains pulled back into data space x freely traverse the modes of themixture of Gaussians. Left: observed examples (black) and trajectories (blue) of Markov chains(red) in data space x and latent space z. Right: density estimations with exponentially tilted modelpθ and underlying flow qα .
Figure 2: Diagnostics for the mixing of MCMC chains with n = 2, 000 steps of Langevin (blue) andHMC (orange), learned from SVHN dataset. (a-b) Histograms of Gelman-Rubin statistic of multiplelong-run Markov chains. R < 1.2 indicates approximative convergence. (c-d) Auto-correlation of asingle long-run Markov chain over time lag ∆t with mean depicted as line and min/max as bands.
Figure 3: Long-run Markov chains for learned models without and with mixing. Top: Chainstrapped in an over-saturated local mode. Model learned by short-run MCMC (Nijkamp et al., 2019)without mixing. Bottom: Chain is freely traversing local modes. Model learned by Hamiltonianneural transport with mixing.
Figure 4: A single long-run Markov Chain with n = 2, 000 steps depicted in 5 steps intervalssampled by Hamiltonian neural transport on SVHN (32 × 32 × 3).
Figure 5: Low energy path between Z1 and Z2 by magnetized Langevin dynamics over n = 1, 000steps on MNIST (28 × 28 × 1). Top: Trajectory in data-space. Bottom: Energy profile over time.
Figure 6: Comparison of generated samples by ancestral sampling from flow qα and neural transportsampling from pθ learned by NT-EBM. Left: SVHN (32 × 32 × 3). Right: CelebA (64 × 64 × 3).
Figure 7: Metropolis-Hastings acceptance rate (top) and adaptive step-size (bottom) over time.
Figure 8: Generated samples from a model learned by NT-EBM on CIFAR-10 (32 × 32 × 3).
Figure 9: A single long-run Markov Chain with n = 2, 000 steps depicted in 5 steps intervalssampled by Hamiltonian neural transport on CelebA (64 × 64 × 3).
Figure 10: A single long-run Markov Chain with n = 2, 000 steps depicted in 5 steps intervalssampled by HMC neural transport for a model learned by NCE on SVHN (32 × 32 × 3).
Figure 11: Generated samples from a model learned by NCE-EBM on CelebA (64 × 64 × 3).
