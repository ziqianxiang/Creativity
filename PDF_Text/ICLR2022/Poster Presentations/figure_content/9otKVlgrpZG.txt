Figure 1: Graphical models of three different stochastic processes for multiple functions. Gray andwhite circles represent observable and latent variables, respectively.
Figure 2: Architecture of the neural network model for MTNP.
Figure 3: (a) Predictions from NP baselines and MTNP. Black line: true function. Black dots: contextpoints. Black crosses: imputed points from STNP. Lighter colored lines: posterior predictive sampleswhere different colors used for different tasks. Darker colored line: mean of the samples. (b) Relativeperformance of MTNP variants on synthetic tasks with different levels of inter-task correlation. Top:on totally correlated tasks. Middle: on partially correlated tasks. Bottom: on independent tasks.
Figure 4: Visualization of MTNP’s internal knowledge transfer. By observing additional data fromCloud task (at red triangles) given upon a few context points (at blue dots), the predicted mean andvariance of Precip task improve at the additionally observed region.
Figure 5: Qualitative results on 2D function regression. Performances of all models improve as thenumber of observable contexts (m) increases. However, under the limited number of observablecontexts (e.g. m = 10), STNP and S+JTNP produce inaccurate outputs (e.g. mis-predicting hairs andposes as in the green box) or incoherent outputs (e.g. different head poses as in the red box).
Figure 6: Performance (normalized MSE) of models against various context sizes (m). Missing rate(γ) is fixed to 0.5.
Figure 7: Performance (normalized MSE) of models against various missing rates (γ). Context size(m) is fixed to 10.
Figure 8: Qualitative results on synthetic task with γ = 0, m = 10. For latent variable models (STNP,JTNP, MTNP), we sample the latents 25 times and plot the mean prediction from each sample. Forthe other models, we plot the mean prediction.
Figure 9: Qualitative results on synthetic task with γ = 0.25, m = 10. For latent variable models(STNP, JTNP, MTNP), we sample the latents 25 times and plot the mean prediction from each sample.
Figure 10: Qualitative results on synthetic task with γ = 0.5, m = 10. For latent variable models(STNP, JTNP, MTNP), we sample the latents 25 times and plot the mean prediction from each sample.
Figure 11: Qualitative results on synthetic task with γ = 0.75, m = 10. For latent variable models(STNP, JTNP, MTNP), we sample the latents 25 times and plot the mean prediction from each sample.
Figure 12: Predicted mean and standard deviation of STNP, S+JTNP, and MTNP with MAP estima-tions.
Figure 13: Qualitative results on 2D function regression. (γ = 0)OIHUIOOIHUINIgHUl39Published as a conference paper at ICLR 2022Table 23: Average reconstruction errors (performance) and disagreement of predictions (coherency)on 2D function regression, with varying context size (m) and γ = 0.25.
Figure 14: Qualitative results on 2D function regression. (γ = 0.25)40Published as a conference paper at ICLR 2022Table 24: Average reconstruction errors (performance) and disagreement of predictions (coherency)on 2D function regression, with varying context size (m) and γ = 0.5.
Figure 15: Qualitative results on 2D function regression. (γ = 0.5)OIHUIOOIHUINlgHUl41Published as a conference paper at ICLR 2022Table 25: Average reconstruction errors (performance) and disagreement of predictions (coherency)on 2D function regression, with varying context size (m) and γ = 0.75.
Figure 16: Qualitative results on 2D function regression. (γ = 0.75)OIHUIOOIHUINlgHUl42Published as a conference paper at ICLR 2022H Ablation StudyIn this section, we provide results of ablation study on the implementations of MTNP. We conductexperiments on synthetic and weather datasets to analyze the effect of various design choices wemade for MTNP.
Figure 17: Visualization of per-task attention weights of MTNP assigned on different context pointsin synthetic tasks. Size and color of markers represent the amount of attention weight assigned oneach point.
Figure 18: t-SNE plot (with 2 components) of the learned task embeddings of MTNP in synthetictasks.
Figure 19: t-SNE plot (with 2 components) of the learned task embeddings of MTNP in weathertasks.
