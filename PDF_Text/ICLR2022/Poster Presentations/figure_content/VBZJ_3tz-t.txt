Figure 1: From shallow to deep. Test accuracy of training randomly pruned subnetworks fromscratch with different depth on CIFAR-10. ResNet-A refers to a ResNet model with A layers in total.
Figure 2: From narrow to wide. Test accuracy of training randomly pruned subnetworks fromscratch with different width on CIFAR-10. ResNet-A-B refers to a ResNet model with A layers intotal and B filters in the first convolutional layer.
Figure 3: Uncertainty estimation (ECE). The experiments are conducted with various models onCIFAR-10. Lower ECE values represent better uncertainty estimation.
Figure 4:	Out-of-distribution performance (ROC-AUC). Experiments are conducted with modelstrained on CIFAR-10, tested on CIFAR-100. Higher ROC-AUC refers to better OoD performance.
Figure 5:	Summary of evaluation on ImageNet. Various Evaluation of ResNets on ImageNet,including predictive accuracy on the original ImageNet, adversarial robustness with FGSM, OoDperformance on ImageNet-O, and uncertainty (ECE and NLL). The sparsity of randomly prunedsubnetworks is set as [0.7, 0.5, 0.3] from left to right for each line.
Figure 6: Gradient norm of randomly pruned networks during training. Top: Comparisonbetween gradient norm of SNIP and ERK with 50% sparse ResNet-20, ResNet-56, and ResNet-110on CIFAR-10. Bottom: Comparison between gradient norm of SNIP and ERK with Wide ResNet-50on ImageNet at various sparsities.
Figure 7: Test accuracy of training randomly pruned ResNet-20, ResNet-32, and ResNet-44 fromscratch with ERK ratios when model width varies on CIFAR-10.
Figure 8: From shallow to deep. Test accuracy of training randomly pruned subnetworks fromscratch with different depth on CIFAR-10. ResNet-A refers to a ResNet model with A layers in total.
Figure 9: From narrow to wide. Test accuracy of training randomly pruned subnetworks fromscratch with different width on CIFAR-10. ResNet-A-B refers to a ResNet model with A layers intotal and B filters in the first convolutional layer.
Figure 10: From shallow to deep. Test accuracy of training randomly pruned subnetworks fromscratch with different depth on CIFAR-100. ResNet-A refers to a ResNet model with A layers intotal.
Figure 11:	From narrow to wide. Test accuracy of training randomly pruned subnetworks fromscratch with different width on CIFAR-100. ResNet-A-B refers to a ResNet model with A layers intotal and B filters in the first convolutional layer.
Figure 12:	From shallow to deep. Test accuracy of training randomly pruned VGGs from scratchwith different depth on CIFAR-10.
Figure 13: From shallow to deep. Test accuracy of training randomly pruned VGGs from scratchwith different depth on CIFAR-100.
Figure 14: Test accuracy of Wide ResNet-50 on ImageNet. Left: Performance of ERK withvarious sparsity of the last fully-connected layer. We vary the sparsity of the last fully-connectedlayer while keeping the overall sparsity fixed as 70%. Results of the original ERK are indicated withdashed red lines. Right: Performance comparison between randomly pruned Wide ResNet-50 and thecorresponding dense equivalents with a similar parameter count.
Figure 15: Out-of-distribution performance (ROC-AUC). The experiments are conducted withvarious models trained on CIFAR-10, tested on SVHN. Higher ROC-AUC refers to better OoDperformance.
Figure 16: Uncertainty estimation (NLL). The experiments are conducted with various models onCIFAR-10. Lower NLL values represent better uncertainty estimation.
Figure 17: Adversarial robustness. The experiments are conducted with various models on CIFAR-10. Higher values represent better adversarial robustness.
