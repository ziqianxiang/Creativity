Figure 1: (Left) Linear convergence of PSDCA to the optimal value of the regularized objective, with test lossas for the supplementary. (Right) Comparison of predictive accuray of P-SDCA, PDA, and SGD. The error-barindicates the standard error over 10 independent repetitions.
Figure 2:	The number of gradient evaluations versus the excess primal objective for P-SDCA, PDAand SGD for a teacher network with a single ReLU neuron.
Figure 3:	The number of gradient evaluations versus the excess primal objective for P-SDCA, PDAand SGD for a teacher network with multiple tanh neurons.
Figure 4:	Evolution of singular values of the first layer’s weight matrix during optimization. Thefigure shows top 5 largest singular values in addition to the k × 10-th largest singular values fork = 2, 3, 4, . . . , 9 and k × 100-th largest singular values for k = 1, 2, 3, .
Figure 5:	Evolution of kernel alignment of the extracted features during optimization.
