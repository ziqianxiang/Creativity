Figure 1: Attacks and defenses for facial recognition poisoning. (1) Users perturb their picturesbefore posting them online. (2) A model trainer continuously scrapes the Web for pictures. (3-4)The model trainer builds a model from collected pictures and evaluates it on unperturbed pictures.
Figure 2: Adaptive defenses break facial poisoning attacks. Existing attacks break a standardWebFace model, but fail against a model expliclty trained on these attacks’ perturbations.
Figure 3: Transferability of ad-versarial examples over time.
Figure 4:	Oblivious defenses break Fawkes. Fawkes v0.3 does not transfer to any facial recognitionmodel that it does not explicitly target. Fawkes v1.0 fares better, but fails against new models suchas MagFace or CLIP. Moreover, a user that perturbs half their pictures with the original weak v0.3attack and then switches to the stronger v1.0 attack cannot reclaim their privacy.
Figure 5:	Oblivious defenses can break LowKey. The attack transfers well to canonical facialrecognition models, but fails to transfer to our fine-tuned CLIP model.
Figure 6: A facial recognition system can use two mod-els to achieve state-of-the-art accuracy and robustness.
Figure 7: Poisoning attacks failwhen a few images are unpro-tected. Uploading a single unpro-tected image online can significantlyreduce a user’s protection rate.
Figure 8:	Security games for training-only clean-label poisoning attacks.
Figure 9:	Adaptive defenses against Fawkes and LowKey. We report (a) the baseline performance(i.e. when no defense is used) for three training modes (Linear, End to end, Nearest neighbors); (b)the attack performance after robust training.
Figure 10: Adaptive and oblivious defenses break Fawkes on PubFig. As on FaceScrub inFigure 2 and Figure 4, the Fawkes v0.3 attack fails to transfer, and the Fawkes v1.0 attack fails againstnew models such as MagFace or CLIP as well as against an adaptively trained model.
Figure 11: Adaptive and oblivious defenses break LowKey on PubFig. As on FaceScrub inFigure 2 and Figure 5, the LowKey attacks transfers well to canonical pre-trained facial featureextractors, but fails against our CLIP model and against an adaptively trained model.
Figure 12: Replication of Figure 6 on PubFig. (Left) A system that runs both MagFace and a robustmodel (either CLIP or our adaptive model) in parallel achieves high top-2 accuracy and robustness;(Right) A system that only runs the robust model when MagFace fails to make a confident predictionhas high top-1 accuracy and robustness.
