Figure 1:	Images and captions are only loosely correlated in many image-text datasets. The ground-truth pairing is not the only sensible match between texts and images. In the example above, we canfind permutations of text captions that can still match with original images.
Figure 2:	Architecture of OTTER. We use image and text embeddings to compute similarity matricesSv (and St), which is then used to solve for matching probabilities Mv* (and Mt*) as targets.
Figure 3: Visualization of OTTER's matching on a batch of 9 image/text pairs.
Figure 4: Visualization of top-8 image-text pairs matched by OTTER in a batch of 512 samples.
Figure 5:	Illustration of the image + text -> image retrieval.
Figure 6:	Image and text query example.
Figure 7: Qualitative results of text + image retrieval. Blue lines indicate texts attributes, and redlines indicate image attributes. For the demonstration purpose, we only label parts of the attributesthat are easy to recognize.
