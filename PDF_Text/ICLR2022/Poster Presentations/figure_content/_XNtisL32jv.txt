Figure 1: Workflow of temporal efficient training (TET). To obtain a more generalized SNN, wemodify the optimization target to adjust each moment’s output distribution.
Figure 2:	Loss landscape of VGGSNN. The 2D landscape of LSDT and LTET from two differenttraining methods.
Figure 3:	TET helps to jump out the local minimum point. We provide the test accuracy (A) andloss (B) change after changing the SDT to TET at epoch 200. TET efficiently improves the testperformance and reduces the two kinds of loss.
Figure 4: Time scalability robustness and network efficiency of ResNet-19 on CIFAR100. (A) Thecomparison of training from scratch (dots) and inheriting from a small simulation length (lines). (B)SNN network performance changes with energy consumption.
Figure 5: STD loss landscape of ResNet-19 on CIFAR100 from different training approaches.
Figure 6: The accuracy under different levels of λ.
Figure 7: Statistical results. The overall performance of SNN is highly positively associated withthe average accuracy of each moment. The standard training obtains the green dots, while the reddots are trained by the TET method.
Figure 8: The accuracy after increasing the simulation length. We first train the SNN with TET (onlyuse LTET) and SDT (LSDT) with simulation length (T) is 2, 3, or 4. Then, we increase the simulationto 64 without finetuning and record the test the classification accuracy (A) and the accuracy relativegrowth rate (B) of the total SNN output (integrate membrane potential) at each simulation time.
