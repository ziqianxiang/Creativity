Figure 1: Examples of spurious features discovered using our framework for a Standard Resnet-50model. In the top row, red color highlights regions with spurious features. The bottom row showsimages generated by visually amplifying these features. Adding a small amount of gaussian noise(with σ = 0.25) to spurious regions (red regions) significantly reduces the model accuracy (shownin dark red in captions) for a subset of 65 images with the shown class labels.
Figure 2: Our framework for constructing the Salient Imagenet dataset. We annotate neural featuresas core (non-spurious) or spurious using minimal human supervision. We next show that theseannotations generalize to many more new samples. We highlight core and spurious regions on theinput samples using activation maps of these neural features.
Figure 3: On the left, the heatmap suffices to explain that the focus is on ground. But on the right,the heatmap covers both cougar and wires. Feature attack clarifies that the focus is on wires.
Figure 4: In the top row, we show number of images for different classes with at least 1 spuriousfeature in the Salient Imagenet dataset. Bottom row shows various plots using the dataset.
Figure 5: Each image denotes the heatmap for different neural features for the class drake. Usinga standard Resnet-50 model, (clean accuracy of 95.4%), we observe a drop of at least 41.5% byadding gaussian noise with σ = 0.25 to spurious masks while a drop of at most 4.6% for coremasks. This shows that the model heavily relies on spurious features in its predictions for this class.
Figure 6: In the top row, we observe a similar drop in accuracy irrespective of whether noise is addedto spurious or core regions suggesting that trained models do not differentiate between the spuriousand core regions for predicting the desired class. In the bottom row, we show core accuracy vs. noiseparameter σ for several classes. In particular, for both classes “triumphal arch” and “ostrich”, themodel has a standard accuracy of 100% (at σ = 0). However, the core accuracy for triumphal archis high even at σ = 2.0 (≈ 40%) while that for ostrich is almost 0%.
Figure 7: Neural activation map generationOoo QlFigure 7 describes the Neural Activation Map generation procedure. To obtain the neural activationmap for feature j, we select the feature map from the output of the tensor of the previous layer (i.ethe layer before the global average pooling operation). Next, we simply normalize the feature mapbetween 0 and 1 and resize the feature map to match the image size, giving the neural activationmap.
Figure 8: Feature attack generationOoo。!/4B Selecting the classes for discovering spurious featuresBecause conducting a Mechanical Turk (MTurk) study for discovering the spurious features for all1000 classes of Imagenet can be expensive, we selected a smaller subset of classes as follows. Usingsome pretrained neural network h, for each class i in Imagenet, we obtain groups of images with thelabel i (called label grouping) and prediction i (i.e h predicts i, called prediction grouping) giving2000 groups. For each group, we compute their accuracy using the network h. For each grouping(label/prediction), we selected 50 classes with the highest and 50 with the lowest accuracy giving100 classes per grouping and take the union. We used two pretrained neural networks: standard androbust Resnet-50 resulting in total 232 classes.
Figure 9:	Mechanical Turk study for discovering spurious features16Published as a conference paper at ICLR 2022C.1 Quality controlOnly allowed workers with at least 95% approval rates and minimum of 1000 HITs were allowed tocomplete our tasks. Additionally, short and generic answers to Q3 were rejected.
Figure 10:	Mechanical Turk study for validating heatmaps18Published as a conference paper at ICLR 2022E	Discovering spurious visual attributes in other image datasetsUSING OUR FRAMEWORKIn this work, we consider the problem of classification on Imagenet and introduce a methodology todiscover core/spurious features. Our framework can be applied to discover the spurious/core visualattributes of other image classification datasets using the following steps:(i)	Train a robust model using the l2 norm of some large radii (we use 3 in this work).
Figure 11: Visualization of feature 625 for class barn spider (class index: 73).
Figure 12: Visualization of feature 957 for class ruffed grouse (class index: 82).
Figure 13: A simple graphical model relationship between core, spurious and label variables.
Figure 14: Comparing between the core accuracy (uSing σ = 0.25) and uSual accuracy of differentImagenet trained modelS.
Figure 15: We plot the Core aCCuraCy for different ClaSSeS aS noiSe level σ inCreaSeS. For SomeClaSSeS, Core aCCuraCy iS high even at large σ, but for moSt it deCreaSeS rapidly (e.g., triumphal arCh,jellyfiSh on EffiCientnet-b7).
Figure 16: Images randomly sampled from the set D(i, j) where i(feature index). Class name: space bar.
Figure 17: Images randomly sampled from the set D(i, j) where i(feature index). Class name: lighter.
Figure 18: Images randomly sampled from the set D(i, j) where i = 975 (class index) and j516(feature index). Class name: lakeside, lakeshore.
Figure 19: Images randomly sampled from the set D(i, j) where i = 809 (class index) and j = 895(feature index). Class name: soup bowl.
Figure 20: Images randomly sampled from the set D(i, j) where i = 657 (class index) and j = 961(feature index). Class name: missile.
Figure 21: Images randomly sampled from the set D(i, j) where i = 536 (class index) and j = 76(feature index). Class name: dock.
Figure 22: Visualization of feature 230 for class sorrel (class index: 339).
Figure 23: Visualization of feature 925 for class black swan (class index: 100).
Figure 24: Visualization of feature 223 for class geyser (class index: 974).
Figure 25: Visualization of feature 1468 for class oystercatcher (class index: 143).
Figure 26: Visualization of feature 341 for class red breasted merganser (class index: 98).
Figure 27: Visualization of feature 1697 for class albatross (class index: 146).
Figure 28: Visualization of feature 981 for class rock beauty (class index: 392).
Figure 29: Visualization of feature 820 for class water ouzel (class index: 20).
Figure 30: Visualization of feature 535 for class water ouzel (class index: 20).
Figure 31: Visualization of feature 1475 for class coral fungus (class index: 991).
Figure 32: Visualization of feature 1556 for class jacamar (class index: 95).
Figure 33: Visualization of feature 189 for class potter’s wheel (class index: 739).
Figure 34: Visualization of feature 1832 for class desk (class index: 526).
Figure 35: Visualization of feature 895 for class wok (class index: 909).
Figure 36: Visualization of feature 43 for class plate (class index: 923).
Figure 37: Visualization of feature 56 for class bullet train (class index: 466).
Figure 38: Visualization of feature 925 for class red breasted merganser (class index: 98).
Figure 39: Visualization of feature 1406 for class jellyfish (class index: 107).
Figure 40: Visualization of feature 925 for class hippopotamus (class index: 344).
Figure 41: Visualization of feature 123 for class band aid (class index: 419).
Figure 42: Visualization of feature 325 for class space bar (class index: 810).
Figure 43: Visualization of feature 1536 for class dock (class index: 536).
Figure 44: Visualization of feature 421 for class promontory (class index: 976).
Figure 45: Visualization of feature 1772 for class gondola (class index: 576).
Figure 46: Visualization of feature 925 for class american coot (class index: 137).
Figure 47: Visualization of feature 1753 for class rock beauty (class index: 392).
Figure 48: Visualization of feature 1986 for class lighter (class index: 626).
Figure 49: Visualization of feature 895 for class soup bowl (class index: 809).
Figure 50: Visualization of feature 798 for class spider monkey (class index: 381).
Figure 51: Visualization of feature 516 for class dock (class index: 536).
Figure 52: Visualization of feature 516 for class lakeside (class index: 975).
Figure 53: Visualization of feature 1832 for class space bar (class index: 810).
Figure 54: Visualization of feature 1797 for class sulphur butterfly (class index: 325).
Figure 55: Visualization of feature 481 for class gondola (class index: 576).
Figure 56: Visualization of feature 432 for class potter’s wheel (class index: 739).
Figure 57: Visualization of feature 1287 for class lighter (class index: 626).
Figure 58: Visualization of feature 840 for class soup bowl (class index: 809).
Figure 59: Visualization of feature 2000 for class wok (class index: 909).
Figure 60: Visualization of feature 961 for class missile (class index: 657).
Figure 61: Visualization of feature 2025 for class plate (class index: 923).
Figure 62: Visualization of feature 387 for class space bar (class index: 810).
Figure 63: Visualization of feature 1120 for class titi (class index: 380).
Figure 64: Visualization of feature 1797 for class admiral (class index: 321).
Figure 65: Visualization of feature 595 for class sulphur butterfly (class index: 325).
Figure 66: Visualization of feature 1642 for class lighter (class index: 626).
Figure 67: Visualization of feature 447 for class band aid (class index: 419).
Figure 68: Visualization of feature 1296 for class soup bowl (class index: 809).
Figure 69: Visualization of feature 76 for class dock (class index: 536).
Figure 70: Visualization of feature 2 for class desk (class index: 526).
Figure 71: Visualization of feature 1469 for class space bar (class index: 810).
Figure 72: Visualization of feature 961 for class projectile (class index: 744).
Figure 73: Visualization of feature 36 for class stupa (class index: 832).
Figure 74: Visualization of feature 371 for class house finch (class index: 12).
Figure 75: Visualization of feature 1556 for class bittern (class index: 133).
Figure 76: Visualization of feature 1541 for class junco (class index: 13).
Figure 77: Visualization of feature 96 for class pineapple (class index: 953).
Figure 78: Visualization of feature 961 for class sandbar (class index: 977).
Figure 79: Visualization of feature 510 for class space bar (class index: 810).
Figure 80: Visualization of feature 1541 for class titi (class index: 380).
Figure 81: Visualization for class junco (class index: 13).
Figure 82: Visualization for class titi (class index: 380).
Figure 83: Visualization for class plate (class index: 923).
Figure 84: Visualization for class icecream (class index: 928).
Figure 85: Visualization of feature 1964 for class ostrich (class index: 9).
Figure 86: Visualization of feature 63 for class ostrich (class index: 9).
Figure 87: Visualization of feature 457 for class brambling (class index: 10).
Figure 88: Visualization of feature 371 for class brambling (class index: 10).
Figure 89: Visualization of feature 1667 for class house finch (class index: 12).
Figure 90: Visualization of feature 371 for class house finch (class index: 12).
Figure 91: Visualization of feature 762 for class bulbul (class index: 16).
Figure 92: Visualization of feature 660 for class bulbul (class index: 16).
Figure 93: Visualization of feature 170 for class coucal (class index: 91).
Figure 94: Visualization of feature 614 for class coucal (class index: 91).
Figure 95: Visualization of feature 1339 for class jacamar (class index: 95).
Figure 96: Visualization of feature 1556 for class jacamar (class index: 95).
Figure 97: Visualization of feature 1113 for class drake (class index: 97).
Figure 98: Visualization of feature 1339 for class drake (class index: 97).
Figure 99: Visualization of feature 925 for class drake (class index: 97).
