Figure 1: Illustration of the AdaAug pipeline. In the exploitation pass (solid line), the training im-ages are augmented by the policy network (hγ ◦ fα (x)) as new unseen data to train the classifier(colored in blue). In the exploration pass (dotted line), each validation data instance passes throughmultiple augmentation paths. The corresponding latent representations are summed with the gen-erated augmentation probabilities as weights. The policy projection network (colored in green) isupdated to minimize the validation loss. To compute the probability and magnitude vectors, σ andsm denote the sigmoid and softmax functions, respectively.
Figure 2: Illustration of the learned augmentation probability for CIFAR-10 (left) and SVHN (right).
Figure 3: Visualization of the augmented images under different augmentation strengths using: Ran-dAugment (left); and AdaAug (right). (k is the number of operators, m is the magnitude parameterin RandAugment, and δ is the magnitude perturbation parameter in AdaAug.)Quality of augmented data. We compare the augmented images from AdaAug with RandAugmentunder different augmentation strengths in Figure 3. In terms of augmentation diversity, RandAug-ment produces more variations of the input image. However, not all augmented images produced areplausible. As RandAugment applies the augmentations uniformly, some augmented flower imagesshow a strange color difference to the original image. With an increasing number of operators andmagnitude, the flower object is sometimes translated out of the frame and results in a black image.
Figure 4: Convergence of the training loss (left) and validation loss (right) during the policy learningon CIFAR-10 dataset.
Figure 5: Update of the augmentation probability (left) and magnitude (right) during the policylearning.
Figure 6: Illustration of the learned augmentation magnitudes for CIFAR-10 (left) and SVHN (right).
Figure 7: Illustration of the policy probability variations for CIFAR-10 (left) and SVHN (right).
Figure 8: Illustration of the augmentation probability (left) and magnitude (right) when transferringthe learned augmentation policy to the Flower, Pet, Car and Aircraft datasets.
