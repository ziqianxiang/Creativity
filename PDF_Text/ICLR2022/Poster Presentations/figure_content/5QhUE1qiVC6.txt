Figure 1: Rectified Ellipsoid Q := {(XU)+ :kUk2 ≤ 1} and its extreme points (spikes).
Figure 2: Convex absolute polar set Q* ofthe Rectified Ellipsoid (purple) and other dualFigure 3: Trajectories of (Xw^ι,i)+ along thetraining dynamics of gradient descent.
Figure 3: Trajectories of (Xw^ι,i)+ along thetraining dynamics of gradient descent.
Figure 4: Trajectories of w^ι,iwi,ikw1,ik2along the training dynamics of gradient de-scent.
Figure 5: Two-layer ReLU network gradient descent dynamics on an orthogonal separable dataset.
Figure 6: The ellipsoid set and the rectified ellipsoid set. Orthogonal separable dataset.
Figure 7: Multiple independent random initializations of gradient descent trajectories on the sameorthogonal separable dataset.
Figure 8: The ellipsoid set and the rectified ellipsoid set for a non-spike-free dataset.
Figure 9: Recitified Ellipsoidal set and correspond-ing extreme points for a non-spike-free dataset.
Figure 10: Multiple independent random initializations of gradient descent trajectories on the samenon-spike-free dataset. Note that the optimal extreme point (star), which is the uniquely optimal singleneuron is on the boundary of the main two-dimensional ellipsoid and not on the one-dimensionalspikes (projected ellipsoids). Also note that some neurons are stuck at spurious stationary points.
