Figure 1: (a) After pretraining: Distribution of discrimina-tor loss on replaced tokens by 4/6/8-layer generators. His-tograms/Curves are distribution bins/kernel density estimates.
Figure 2: Overview of AMOS. The generator has multiple layers trained with MLM to providetraining signals of various levels of difficulty. The mixture weights over MLM outputs are learnedto maximize the discriminator loss, by backpropagating the estimated reversed gradient from thediscriminator via Gumbel-Softmax. The discriminator is trained by the RTD task.
Figure 3: (a) The average mixture weights of the 4th/6th/8thgenerator layers on all masked positions during pretraining.
Figure 4: AMOSBase accuracy on MNLI Dev.
