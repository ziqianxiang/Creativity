Figure 1: VRL-PGM: a probabilistic graphical model for representing the relational learning problem;the observed r.v. a and b are generated from some random process (parameterized by θ) involving alatent r.v. z.
Figure 2: Information flow diagrams depicting VRL’s gradients updating process, where each pathuses its associated parameters to propagate information in the forward direction and gradients in thebackward direction: (a) Overfitting occurs when the learning of pθ (b(i) |a(i), z(i)) rely only on thedash-dotted path (deterministic-mapping) or the dashed path (information-shortcut); (b) Parameterupdating process improved with RPDA.
Figure 3: Learning decoupled relative rotational relationship with VRL: (a) Scatter plots of 2-Drelational property of XO inferred by VRL (relative rotational relationship labels: # :0。，O : 72°,+ : 144°, X : 216°, ♦ : 288°); (b) Images predicted from sampled latent variables (sampling thecentroid of each cluster in (a): “#” → z(1), “O”→ z(2),“+” → z(3), “x” →z(4), “◊” → z(5)); eachimage b(r,c), 1 ≤ r,c ≤ 5, was predicted from a(c) (shown in the top row) and z(r) by b(r,c) 〜pθ( b | a(c), z(r) ); (c) Relational mappings of top row images by applying relational property inferredfrom pairs of source images (as, b(sr)) shown in the left-most column with as, b(s1), ..., b(s5) arrangedfrom top to bottom; each image b(r,c), 1 ≤ r,c ≤ 5 was generated by b(r,c) 〜 pθ(b | a(c), z(r) )where z(r)〜q@( Z | a§, bSr)).
Figure 4: Learning coupled relative rotational relationship with VRL: (a) Scatter plot of 2-D relationalproperty of XM inferred by VRL (relative rotational relationship labels: # :0。，O : 72。，+ :144°,X : 216°, ♦ : 288°); (b) Images predicted from sampled latent variables (sampling the centroid ofeach cluster in (a): “#” → Z(I), “O” → Z⑵,“十” → Z⑶，“x” → Z⑷，“♦” → Z⑸)；(c) Relationalmappings of top row images by applying relational property inferred from pairs of source images(as, b(sr)) in the left-most column.
Figure 5: Learning relative relationships between facial images and speech waveforms: (a) Learn-ing relative facial expression changes with 2-D VRL relational property (labels: O:“happy-sad”,#:“happy-surprised”, +:“surprised-sad”); (b) Learning relative facial illumination condition changeswith 2-D VRL relational property (labels: O:“L-R, ◊:“F-T, #: “L-F, +：“L-T, x:“F-R, 2：“R-T);(c) Learning relative speech emotion changes with 2-D VRL relational property (labels: O:“calm-fearful”, #:“calm-angry”, +:“angry-fearful”)(a)(c)6	Discussion and conclusionThe proposed VRL method comes with both advantages and disadvantages: the main advantageof VRL is its relational learning capabilities; however, this may also be one of its disadvantages.
Figure 6: Examples of facial images and speech waveforms: (a) Subjects (columns) with differentfacial expressions (rows): happy, surprised, sad; (b) Subjects (rows) with different illuminationconditions (columns): left, front, right, top; (c) Log-mel spectrogram of actors vocalizing twostatements with different speech emotions (Columns: 1. male actor vocalizing "Kids are talking bythe door", 2. female actor vocalizing "Kids are talking by the door", 3. male actor vocalizing "Dogsare sitting by the door", 4. female actor vocalizing "Dogs are sitting by the door"; Rows: calm, angry,fearful).
Figure 7:	Manipulating latent codes of InfoGAN on MNIST where each row represents randomsamples from varying continuous latent code c2 in (a) and c3 in (b) while other latent codes and noiseare fixed; different rows correspond to different categorical code c1 = 1 . . . 10.
Figure 8: Examples of VRL relational mapping for facial images and speech waveforms; each pair ofimages shows VRL relational mapping predictions based on the relational property inferred fromthe first two images in the same row; (a) Relative facial illumination condition changes; (b) Relativefacial expression changes; (c) Relative speech emotion changes.
Figure 9: Learning multiple relative relationship with VRL: (a) Scatter plot of 2-D relational propertyof XM10 inferred by VRL (relative relationship labels: #(blue) :00, O : 72。，+ :144°, X : 216°,♦ : 288°, 2 : 0°, ×1.5, > : 72°, ×1.5, V : 144°, ×1.5, 4 : 216°, ×1.5, O(Cyan): 288°, ×1.5);(b) Images predicted from sampled latent variables (sampling the centroid of each cluster in (a):“#”(blue)→Z(I), “O”→Z⑵,“十”→Z⑶，“x”→Z⑷，“♦”→Z⑸，“□”→Z⑹，“>”→Z⑺，“V”→z(8), “4” → z(9), “#”(cyan) → z(10)).
Figure 10: Learning continuous relative relationship with VRL: (a) Scatter plot of 2-D relationalproperty of XMc inferred by VRL, each point is color-coded (best viewed in color) by the degreesof relative rotation between the corresponding data point; (b) Images predicted from sampled latentvariables (denoted by markers “X” in (a)).
Figure 11: Scatter plot of 3-D relational property of XMc inferred by VRL (with z ∈ R3); each plotshows a different vantage point of the 3-D scatter plot, and each point is color-coded (best viewed incolor) by the degrees of relative rotation between the corresponding data point.
