Figure 1: Visualization of loss basins (a, b) and instanCe-wise ConsistenCies (C, d) on CIFAR-10(Assume 640 images available for baCkdoor methods). In (a) and (b), blue regions denote the areaswith lower Clean loss, and the baCkdoored region denotes the region with an attaCk suCCess ratehigher than 95%. (b) is the zoomed version of the loss basin near the Clean model in (a).
Figure 2:	Performance of BadNets and anchoring (位=0.05) methods with various training data sizesin (a), (b). Performance of anchoring methods with various 位 (640 images are available) in (c), (d).
Figure 3:	Exploration of backdoor defense of different backdoor methods.
Figure 4: An illustration of the 5-pixel backdoor pattern on CIFAR-10.
Figure 5:	Performance of L2 penalty and anchoring methods with various 位 on CIFAR-10. Here L2means the L2 penalty, Anchor means the anchoring method, and F means the full dataset is available,otherwise, only 640 images are available.
Figure 6:	Performance of the anchoring method with various 位 on CIFAR-100 (a-d) and Tiny-ImageNet (e-h). Here Full means the full dataset is available, otherwise 640 images are available.
Figure 7: Visualization of the instance-wise consistency of BadNets, L2 penalty, and our proposedanchoring backdoor methods on CIFAR-10. Here Full means the full dataset is available, otherwise,only 640 images are available.
Figure 8:	Visualization of the instance-wise consistency of BadNets, L2 penalty, and our proposedanchoring backdoor methods on CIFAR-100. Here only 640 images are available.
Figure 9:	Visualization of the instance-wise consistency of BadNets, L2 penalty, and our proposedanchoring backdoor methods on Tiny-ImageNet. Here only 640 images are available.
Figure 10: Detailed visualization of the loss basin.
