Figure 1: Demonstration of how our proposed scheme thwarts inference attacks at different granularities. Fig.
Figure 2: Trusted shuffler mediates on yowners first randomize their inputs via a -LDP mechanism to generate yi = M(xi). Additionally,just like in the shuffle model, we have a trusted shuffler. It mediates upon the noisy responsesy = hy1,…，yn〉to obtain the final output sequence Z = A(y) (A corresponds to Alg. 1) which issent to the untrusted data analyst. The shuffler can be implemented via trusted execution environments(TEE) just like Google’s Prochlo. Next, we formally discuss the notion of order and its implications.
Figure 3: An example social me-dia connectivity graph te.gAny choice of grouping G = {G1, G2, . . . , Gn} can be accommodated under dσ -privacy. Each dataowner may choose a group large enough to hide anyone they feel sufficient risk from. We outline twosystematic approaches to assigning groups as follows:•	Let t = ht1 , ∙ ∙ ∙ , tni, ti ∈ T denote some public auxiliary information about each individual.
Figure 4: Our scheme interpolates between standard LDP (orange line) and uniform shuffling (blue line) in bothprivacy and data learnability. All plots increase group size along x-axis (except (d)). (a) → (b): The fractionof participants vulnerable to an inferential attack. (c) → (d): The accuracy of a calibration model trained onz predicting the distribution of LDP outputs at any point t ∈ T, such as the distribution of medical insurancetypes used specifically in the Houston area (not possible when uniformly shuffling across Texas).
Figure 6: Illustration of Alg. 1Which lets US Set θ = 费 for any given ɑ privacy value. To reiterate, lower θ results in morerandomness in the mechanism.
Figure 7: (η, δ)-Preservation AnalysisIn this section, we evaluate the characteristics of the (η, δ)-preservation for Kendall’s τ distancedτ(∙, ∙).
Figure 8: Adult dataset experimentsdiffers from our approach in two ways. First, it focuses completely on the DP guarantee. The privacyamplification is manifested in the from of a lower e (roughly a factor of ^n) when viewed in analternative DP model known as the central DP model. Erlingsson et al. (2019); Cheu et al. (2019);Balle et al. (2019); Feldman et al. (2020); Bittau et al. (2017a); Balcer & Cheu (2020). However,our result caters to local inferential privacy. Second, the shuffle model involves an uniform randomshuffling of the entire dataset. In contrast, our approach the granularity at which the data is shuffledis tunable which delineates a threshold for the learnability of the data.
Figure 9: Comparison of our heuristic's performance With that of an optimal reference permutation σ^. Anoptimal σ0 is generated with every group having size w. A graph is generated from this optimal σ0 from whichour heuristic (blue) attempts to reconstruct the optimal permutation. For baselining, the performance of a randomσ0 selection is plotted (orange). We observe that at worst, our heuristic picks a reference permutation with width2.5× that of the optimal reference permutation (green). See Section 4.4 for definition of terms.
Figure 10: example of our heuristic’s performance on randomly generated graphs. As r increases, so does theconnectivity of the random graphs and the average group size (green). As shown by Theorem A.3, computingthe optimal ωGσ is NP-hard. The average group size (green) in G is a loose lower bound on the optimal ωGσ . Theperformance of a random σ0 assignment (orange) is also plotted for reference. Our heuristic BFS algorithm(blue) consistently outperforms the random baseline.
