Figure 1: VNCA self-organized growth and damage recovery. Left: The VNCA has learned aself-organising generative process that generates faces, from an initial random seed of cells fromN(0, I). Time goes top-down and left-to-right. Every eight steps all the cells duplicate, which canbe seen on the diagonal. Right: A damage recovery sequence for an MNIST digit.
Figure 2: VNCA overview. Left: Generative process. z0 is sampled from p(z) and acts as an initial2 × 2 seed of cells, which grows through a series of K doubling NCA steps. |Z| denotes the sizeof the latent space, which is identical to the size of the cell states. Finally, the last cell hidden stateconditions the parameters of the likelihood distribution p(x|z). Middle: Each doubling NCA stepconsists of a number of NCA steps followed by a doubling operation. At each NCA step, the cellscan only communicate with their immediate neighbors. Right: The doubling operator doubles thecell grid as depicted, where the color indicates the state vector of each cell.
Figure 3: Left: Test set reconstructions. Right: Unconditional samples from the prior. The VNCAachieves log p(x) ≥ -84.23 nats evaluated with 128 importance weighted samples.
Figure 4: Self-organising MNIST, with the seed cell states sampled from the prior. Each 32 × 32 sub-image shows the digit after 1 step of NCA or doubling. Time flows top-to-bottom and left-to-right.
Figure 5: Exploring the latent space of VNCA. Fig. 5a shows several linear interpolations betweenrandom digits in the latent space of a VNCA trained on binarized MNIST. Figs. 5b and 5c showthe result of reducing the dimensionality of 5000 digits chosen at random for the VNCA and for thedeep convolutional baseline respectively. Notice how the latent space of VNCA has more t-SNEstructure and cleaner separation of digit encodings. Note: this shows sample averages for clarity.
Figure 6: CelebA results. Left: Test set reconstructions. Right: Unconditional samples from theprior. The VNCA achieves 4.42 bits per dimension on the test set evaluated with 128 importanceweighted samples.
Figure 7: VNCA CelebA results when trained with β = 100. Left: Test set reconstructions. Right:Unconditional samples from the prior. Note: this shows sample averages for clarity. This versionachieves much worse bits per dimension ≥ 5.40, but visually the samples are much better. Note:this shows sample averages for clarity.
Figure 8: Growth of CelebA samples from the prior from a VNCA trained with β = 100. Note: thisshows sample averages for clarity.
Figure 9: Damage recovery on MNIST samples. Left: From top to bottom: samples from the model,samples with damage applied, recovered samples after T NCA steps. Right: details of the damagerecovery process showing T = 36 steps of NCA growth on the leftmost damaged sample (T issampled uniformly from 32 to 64). Note: this shows sample averages for clarity.
Figure 10: CelebA Damage Recovery. Left: From top to bottom: samples from the model, sampleswith damage applied, recovered samples after T NCA steps. Right: details of the damage recoveryprocess, cropped for brevity, showing the first 24 and the last 2 steps on the leftmost damagedsample. For all 121 steps, see the appendix. Note: this shows sample averages for clarity.
Figure 11: Unconditional samples, after being exposed to damage at varying stages of growth. Theleftmost image is not exposed to any damage. The next six images represent damage applied at stepst = [0, 8, 16, 24, 32, 40] corresponding to the initial state, and the steps just before each doubling. (b)shows the equivalent process in a deep convolutional baseline: the leftmost image is left intact, andthe following columns present the result of damaging the hidden state before each up-convolution.
Figure 12: Non-doubling VNCA variant architecture.
Figure 13: Noto Emoji results. Left: Test set reconstructions. Right: Unconditional samples fromthe prior. The VNCA achieves 3.09 bits per dimension on the test set evaluated with 128 importanceweighted samples.
Figure 14: CelebA unconditional individual samples from a VNCA trained with β = 100.
Figure 15: CelebA growth of unconditional sample from a VNCA trained with β = 100.
Figure 16: CelebA recovery of damage showing T = 121 NCA steps. Note: this shows sampleaverages for clarity.
Figure 17: Growth of CelebA and MNIST digits for the non-doubling VNCA variant.
