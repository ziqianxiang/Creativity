Figure 1: Displacement mapping in 1D. Thedetailed surface (upper blue) is created byoffsetting samples of the base surface (upperblack) using the height map shown below.
Figure 2: Method overview. We represent detailed geometries as a sum of a coarse base shape representedas low-frequency signed distance function and a high-frequency implicit displacement field, which offsets thebase iso-surface along the base’s normal directions.
Figure 3: An implicit displacement field fora 1D-curve. The displacement is defined notonly on the zero-isosurface S0 but also onarbitrary isosurfaces Sτ3.1	Implicit displacement fieldsIn classic displacement mapping as shown in Figure 1, high-frequency geometric details are ob-tained on a smooth base surface by taking samples from the base surface and offsetting them alongtheir normal directions by a distance obtained (with interpolation) from a discrete height map. Twoelements in this setting impede a direct adaptation for implicit shape representation: 1. the displace-ment mapping is defined discretely and only on the base surface, whereas implicit surface functionsare typically defined continuously on the R3 domain; 2. the base surface is known and fixed, whereasour goal is to learn the base surface and the displacement jointly on-the-fly.
Figure 4: Smoothness control via siren’s frequency hyperpa-rameter ω. Overfitting s iren to the right image with ω = 30(first) and ω = 60 (middle) shows that smaller ω leads to asmoother result.
Figure 5: Attenuation as a function of baseSDF.
Figure 6: Illustrations for transferable and non-transferable implicit fields. The transferable modules are in pinkand the shape-specific modules are in yellow. Instead of consuming the euclidean coordinates, the transferabledisplacement network takes a scale-and-translation invariant feature as inputs, which describes the relativeposition of the query point to the base shape.
Figure 7: Comparison of detail reconstruction (better viewed with zoom-in). We show the best 5 methods andtheir model sizes according to Table 1, more results are provided in section B.1.
Figure 9: Transferring spatially-variant geometric details using various methods. Small to severe distortions areintroduced when removing different components of the proposed transferable IDF. Thanks to the combinationof global/local query feature, our method transfers spatially-variant details while Hertz et al. (2020) can onlyhandle spatially-invariant isometric details.
Figure 10: Transferable IDF applied to detail transfer. Left: the base shape is provided and lies closely to theground truth detailed surface; right: only the detailed shapes are provided, thus the base and the displacementsneed to estimated jointly.
Figure 8: Detail trans-fer without scaling f.
Figure 11: Sketch for proof.
Figure 12: Examples of the direct residual and D-SDF models.
Figure 13: Effect of ωB and ωD demonstrated on meshes with different level of details. For smooth low-resolution meshes such as the example shown in the first row, a small ω suffices to represent all the details inthe given mesh. In this case, the base SDF (e.g. ωB = 15) alone can accurately express the surface geometry,rendering the displacement network unnecessary, as a result the composed surface is indistinguishable fromthe base surface, as shown in (a). To enforce detail separation, one can reduce ωB, e.g. to 5, as shown in (b).
Figure 14: Qualitative evaluation given sparse and noisy inputs.
Figure 15: Detail transfer to multiple similarly aligned target shapes. Given a (detailed) source shape, we train abase network N ωB to represent the smooth base surface (see learned source base), as well as a feature extractorφ and a transferrable displacement network TωD to represent the surface details. During detail transfer, weonly need to fit the lightweight base network for each new target, while the feature extractor and displacementnet can be applied to the new shapes without adaptation.
Figure 16: Comparison of detail reconstruction (better viewed with zoom-in). Methods that did not convergeare omitted in the visual comparison.
Figure 16: (Cont.) Comparison of detail reconstruction (better viewed with zoom-in). Methods that did notconverge are omitted in the visual comparison.
