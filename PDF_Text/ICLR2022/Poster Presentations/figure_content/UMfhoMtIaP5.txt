Figure 1: Overview of PARADE. The green triangle denoted T represents the ground truth adversarialregion and the red crosses represent the attacks obtained by A. The dashed blue and violet dottedrectangles denoted O and U , represent the fitted overapproximation and underapproximation boxes,respectively. The solid black lines represent hyperplanes generated by the verification procedure,while their dash-dotted counterparts represent the hyperplanes after bias-adjustment. The arrowsgoing out of the hyperplanes represent the direction of their corresponding half-spaces.
Figure 2: Overview of our method for generating provably robust polyhedral adversarial examples.
Figure 3: Convex approximations for the ReLU function: (a) shows the triangle approximationEhlers (2017) with the minimum area in the input-output plane, (b) and (c) show the two convexapproximations used in DeepPoly Singh et al. (2019). In the figure, λi,j = ui,j/(ui,j - li,j) andμi,j = -li,j ∙ ui,j/(ui,j - li,j). The figure is taken from Singh et al. (2019).
Figure 4:	Adversarial region robust to pixel intensity changes.
Figure 5:	Sensitivity of probably robust adversarial examples based on pixel intensity changes on theMNIST ConvBig network.
Figure 6: Sensitivity of probably robust adversarial examples based on pixel intensity changes on theMNIST ConvSmall network.
Figure 7: Sensitivity of probably robust adversarial examples based on pixel intensity changes on theMNIST 8 × 200 network.
Figure 8:	Sensitivity of probably robust adversarial examples based on pixel intensity changes on theCIFAR10 ConvSmall network.
Figure 9:	Sensitivity of probably robust adversarial examples based on geometric perturbations.
Figure 10: Sensitivity of probably robust adversarial examples based on geometric perturbations.
