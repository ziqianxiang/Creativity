Figure 1: Example of the deep neural network approach to phase retrieval problem. FCNN refersfully-connected neural network here but can be replaced by any machine learning model. The mag-nitude is encoded into an input of size N while the output is an N -dimensional complex vector ofcorresponding phases.
Figure 2: Structure of BPNN (and piecewise BPNN): BPNN is an end-to-end model. Predictionsare constructed by the combination of the Blaschke coefficients output of FCNN and values of inputmagnitude. In the piece-wise BPNN case, FCNN generates the sets of Blaschke coefficients for allsegments (partitions) of the frequency range, and predictions are made for each segment separatelyand the results are concatenated.
Figure 3: Performance comparison of a number of neural networks of different structures, each withits best hyper-parameters, and BPNN on two synthetic phase retrieval problems with training set ofvarious size.
Figure 4: Performance comparison of family of neural networks, each with its best hyper-parametersand BPNN (without hyper-parameter search) on MMA dataset along with four other baselines: theKK method, linear regressor+Blaschke Product, MUSIC algorithm and the AAA method.
Figure 5: On the left is the performance comparison of family of neural networks, each with its besthyper-parameters and BPNN along with four other baseline methods. On the right is the comparisonof median MSE loss of the best neural network in the large family and median MSE loss of BPNN.
Figure 6: On the left is the heatmap of minimum test MSE (mean squared error) of Piecewise BPNNwith different hyper-parameter configurations on Hyugenâ€™s metasurface dataset. On the right is theheatmap of minimum test MSE of Piecewise BPNN with different hyper-parameter configurationson membrane metasurface dataset. Each minimum MSE is calculated with 3 runs of training fromdifferent initialization.
