Figure 2: (a): The proposed Cold Brew framework. In normal case (left upper), GNN relies on both nodefeature and adjacency structure to make prediction. In cold start case (left lower) when the adjacency structureis missing, the cold brew student model first estimate the adjacency structure, then use both node feature andadjacency structure to make prediction. The “SE” (right) is the structural embedding learned by Cold Brew'steacher GNN. (b): Four atomic components deciding the GNN embeddings of node i. Our proposed FCR metricdisentangles them into two models: the MLP that only considers Part 1 and Part 3, and label propagation thatonly considers Part 1 and Part 2.
Figure 3: Inference procedure illustration for GNN and Cold Brew.
Figure 4: Top two subfigures: the last-layer embeddings of GCN and Simple MLP. Bottom twosubfigures: the last-layer embeddings of GraphMLP and Cold Brew,s student MLP. All embeddingsare projected to 2D with t-SNE. Cold Brew,s MLP has the fewest isolated nodes that are misplacedinto wrong clusters.
