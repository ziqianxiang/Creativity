Figure 1: The left panels in (a) and (b) show training accuracy of the two example groups for twotypes of weight perturbation. The right panels in (a) and (b) show the accuracy of each examplegroup for the same model with weight perturbation applied. Same colors represent the same for-getting operation, and dashed lines represent the accuracy on the difficult or mislabeled examples.
Figure 2: The left panels in (a) and (b) show train accuracy of the compositional (Comp) and non-compositional (Perm) language examples; blue lines here are hidden behind orange lines. The rightpanels in (a) and (b) show the accuracy of each group for the same model with weight perturba-tion applied. Same colors represent the same forgetting operation, and dashed lines represent theaccuracy on the non-compositional examples. Results are averaged over 5 runs.
Figure 3: Analysis experiments performed on Flower dataset with ResNet18. (b)-(c) show the min,max, and average of 3 runs. (a) shows that KE induces no forgetting after the first 2 generations.
Figure 4: Topographic similarity (ρ) in the Lewis game with different forms of forgetting. (a)presents the ρ across all phases of iterated learning; (b) zooms into the first 40000 steps to illustratethat ρ improves in two stages for every generation: first during reinitialization and imitation (forget),but it is generally during interaction that the sender starts outperforming the previous generation’s ρ(relearn). (c) plots ρ at the end of each generation for the ease-of-teaching setting.
Figure A1: The left panels in (a) and (b) show training accuracy of easy and hard example groupsfor different types of weight perturbation. The right panels in (a) and (b) show the accuracy of eachexample group for the same model with weight perturbation applied. Same colors represent thesame forgetting operation, and dashed lines represent the accuracy on the hard examples. Resultsare averaged over 5 runs. Lowess smoothing is applied for visual clarity.
Figure A2: The left panels in (a) and (b) show training accuracy of true and mislabeled examplegroups for different types of weight perturbation. The right panels in (a) and (b) show the accuracyof each example group for the same model with weight perturbation applied. Same colors representthe same forgetting operation, and dashed lines represent the accuracy on the mislabeled examples.
Figure A3: KNN probe train accuracy for various ResNet18 models trained on Flower. The layersshown are the end of each block and after the softmax operation. We use K=3 to compute accuracyusing the activations from each layer. The different curves in each panel show that overall predictiondepth (as approximated by average KNN accuracy across layers) decreases with more training. LLFin (c) shows the most significant change, with the KNN probe performing near perfect at layer 6,which is earlier than the other two methods.
Figure A4: Mappings from input dimension to message dimension learned by the sender usingiterated learning in the setting of Ren et al. (2020), logged after every generation for the first 32200training iterations across all phases. A compositional language appears as a permutation matrix,where each input dimension maps to a unique message dimension.
Figure A5: Mappings from input dimension to message dimension learned by the sender withoutany form of forget-and-retrain in the setting of Ren et al. (2020), logged uniformly for the first33000 training iterations. A compositional language would have appeared as a permutation matrix,where each input dimension maps to a unique message dimension.
Figure A6: Mappings from input dimension to message dimension learned by the sender usingPartial Balanced Forgetting (PBF) in the setting of Li & Bowling (2019), logged after every twogenerations for the first 48000 training iterations. A more compositional language has unique non-overlapping message dimension activations for different input dimensions.
Figure A7: Mappings from input dimension to message dimension learned by the sender by reset-ting the receiver periodically following the setting of Li & Bowling (2019), logged after everygeneration for the first 48000 training iterations. A more compositional language has unique non-overlapping message dimension activations for different input dimensions.
Figure A8: Mappings from input dimension to message dimension learned by the sender withoutany form of forget-and-retrain in the setting of Li & Bowling (2019), logged uniformly for thefirst 48000 training iterations. A more compositional language has unique non-overlapping messagedimension activations for different input dimensions.
