Figure 1: (a) A time-varying input spike sequence received by two memory pathways: neuronmembrane potential plots show the different response from the neurons to the given input. (b) Aminimal multi-neuron-dynamic (mMND) network with m layers and n neuron dynamics.
Figure 2: (a) The proposed network with BPTT training, each multi-neuron-dynamic layer containsa set of neuron dynamics from d1 to dm. (b) The proposed network with STDP training.
Figure 3: Validation error over optimization iterations for the proposed dual-search-space Bayesianoptimization compared to the normal single-search-space Bayesian optimization.
Figure 4: Using a set of memory pathways to map a piece-wise constant function for approximatinga time-varying function.
Figure 5: MSE loss vs. number of trainable parameters for the function approximation experiments.
Figure 6: (a) MSE loss (log) of baseline network (top) and the proposed network (bottom) forapproximating functions with different parameters m and n. (b) Heat plots of MSE loss for approx-imating functions with different parameters m and n.
Figure 7: (a) Raster plot for function approximation experiment; t is the simulation time step. (b)Raster plots for the proposed SNN trained for N-Caltech101 with BPTT; t is the simulation timestep; (i), (iii) and (V) are from layer 8; (ii), (iv) and (vi) are from the final layer.
Figure 8: Visualization of the learned distribution from Bayesian optimization: N-Caltech101 vali-dation accuracy vs. skip-layer configurations.
