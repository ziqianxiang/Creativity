Figure 1: Generalized kernel thinning (KT) vs i.i.d. sampling for an 8-component mixture of Gaussianstarget P. For kernels k without fast-decaying square-roots, KT+ offers visible and quantifiable im-provements over i.i.d. sampling. For Gaussian k, TARGET KT closely mimics ROOT KT.
Figure 2: MMD and single-function integration error for Gaussian k and standard Gaussian P in Rd.
Figure 3: Kernel thinning+ (KT+) vs. standard MCMC thinning (ST). For kernels without fast-decayingsquare-roots, KT+ improves MMD and integration error decay rates in each posterior inference task.
Figure 4: Generalized kernel thinning (KT) and i.i.d. coresets for various kernels k (in parentheses) andan 8-component mixture of Gaussian target P with equidensity contours underlaid. These plots areindependent replicates of Fig. 1. See Sec. 4 for more details.
Figure 5: Kernel thinning versus i.i.d. sampling. For mixture of Gaussians P with M âˆˆ {4, 6} com-ponents and the kernel choices of Sec. 4, the TARGET KT with GAUSS k provides comparableMMDk (P, Pout) error to the root KT, and both provide an n- 1 decay rate improving significantlyover the n- 1 decay rate from i.i.d. sampling. For the other kernels, KT+ provides a decay rate closeto n- 1 for IMQ and B-SPLINE k, and n-0.35 for LAPLACE k, providing an excellent agreementwith the MMD guarantees provided by our theory. See Sec. 4 for further discussion.
Figure 6: Kernel thinning+ (KT+) vs. standard MCMC thinning (ST). For kernels without fast-decayingsquare-roots, KT+ improves MMD and integration error decay rates in each posterior inference task.
