Figure 1: Dependencies exist in (a) texture, (b) semantic and (c) color space.
Figure 2: In (a), we show the architecture of image compression model with with hyerprpriorand context model. The main autoencoder learns an latent representation of image, while a hyper-autoencoder learns a hyperprior representation. Context model learns correlation of latents fromtheir decoded context. Real-valued latent representation (y, z) is quantized (Q) to create Iatents (y)and hyper-latents (Z), which are compressed into a bitstream using an arithmetic encoder (AE) anddecompressed by an arithmetic decoder (AD). The latents use a Gaussian entropy model condi-tioned on hyperprior and context. The region in dashed line corresponds to our Entroformer, whichis shown in (b). A transformer encoder learns the hyerprprior, while a transformer decoder learnsthe context using masked self-attention. Linear component is used to joint these features to generatethe Gaussian parameters (i.e. μ, σ).
Figure 4: Parallel bidirectional context model.
Figure 3: Rate increase ratios of different posi-tion when the corresponding context is masked.
Figure 5: The Entroformer (context + hyperprior) achieves better RD performance than previousCNNs-based methods and standard codecs on the Kodak image set as measured by PSNR (RGB)(left). The right graph compares the relative performance of different versions of our method. OurEntroformer architecture helps significantly at hyperprior-only and context-only model by 12.4%and 11.3% respectively at low bit rates. Note that parallel Entroformer has almost no effect ( about1% bpp increase) for RD performance.
Figure 6: Results for varying the clipping `1 dis-tance of diamond RPE. The base implementa-tion uses a transformer context model withoutposition encoding. All models are optimizedwith λ = 0.02 (PNSR ≈ 35.0 on Kodak).
Figure 7: Effect of restricting the self-attentionto various top-k similar content. All models usea transformer context model and are optimizedwith λ = 0.02 (PNSR ≈ 35.0 on Kodak).
Figure 8: Examples of the self-attention mechanism for three points.
Figure 10: Self-attention from models with different k.
Figure 9: Self-attention heads following long-range dependencies with different patterns.
Figure 11:	Rate-Distortion curves on the Kodak image set using PSNR. Each point on the RDcurves is calculated by averaging over the MS-SSIM and bit rate. Note that the models with * usedeeper main auto-encoder (transform between image and latent).
Figure 12:	Rate-Distortion curves on the Kodak image set using MS-SSIM. Each point on the RDcurves is calculated by averaging over the MS-SSIM and bit rate. To improve readability, this graphshows MS-SSIM scores in dB using the formula: MS-SSIMdB = -10 log10(1 - MS-SSIM). Notethat the models with * use deeper main auto-encoder (transform between image and latent).
