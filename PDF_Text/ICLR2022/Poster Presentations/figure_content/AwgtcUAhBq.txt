Figure 1: We study domain-adversarial training from a gameperspective. In DAL (Ganinet al. (2016)), three networks in-teract with each other: the fea-ture extractor (g), the domainclassifier (h0) and the classifier(h). During backpropagation,the GRL flips the sign of the gra-dient with respect to g.
Figure 2: Our method vs popular optimizers on theDigits Benchmark. (Top-Left) Loss in target domain.
Figure 3: Comparison among op-timization algorithms (M→U) withDANN.
Figure 4: Robustness to hyperparameters. We compare the transfer perfor-mance of our method for different hyperarameters in the task M→ U in theDigits benchmark. Green line shows the best score for the best performinghyperparameters of GD. Blue star corresponds to the best solution. Ourmethod performs well for a wide variety of hyperparameters.
Figure 5: Sensitivity to Sam-pling Noise . Different amountsof sampling noise controlled bythe batch size (64, 128, 160)(Visda).
Figure 6: Transfer Perfor-mance on Visda (DANN).
Figure 7: Stability anal. on Digits.
