Figure 1: Rescaled values of prior-weighted EI (purple), EI (blue) and πn (red) on a 1D-Braninin logscale (grey) with global optimum in the center of the search space. Runs with two differentprior locations (“Well-located” slightly right of optimum, “Off-center” significantly left of optimum)are shown in the two columns. Each row represents an iteration (iteration 4, 6 and 8), for anoptimization run with β = 2. The current selection can be seen as a vertical violet line, and allprevious observations are marked as crosses. πBO amplifies EI in a gradually increasing regionaround the prior, and moves away from the prior as iterations progress. This is particularly evident inthe Off-center example.
Figure 2: Comparison of πBO, Spearmint, and two sampling approaches on Branin, FCNet andXGBoost for various prior strengths. Mean and standard error of log simple regret is displayed over100 iterations, averaged over 20 runs. The vertical line represents the end of the initial design phase.
Figure 3: Comparison of πBO, BOPrO, BOWS, and prior sampling for 5D MLP tuning on variousOpenML datasets for a prior centered on default values. We show mean and standard error of theaccuracy across 20 runs. The vertical line represents the end of the initial design phase.
Figure 4: Comparison of approaches for U-Net Medical and ImageNette-128 for a prior centered ondefault values. We show mean and standard error of the accuracy across 20 runs for U-Net Medicaland 10 runs for ImageNette-128. The vertical line represents the end of the initial design phase.
Figure 5: Comparison of πBO and Spearmint with varying values of β for Branin and Profetbenchmarks for the strong, weak and wrong prior qualities. The mean and standard error of logsimple regret is displayed over 100 iterations, averaged over 10 repetitions. Iteration 1 is removed forvisibility purposes. The vertical line represents the end of the initial design phase.
Figure 6: πBO on SMAC using a GP surrogate for the EI, UCB, PI and TS acquisition functions,β = 10 for Branin and Profet benchmarks for varying prior qualities. The mean and standard error oflog simple regret is displayed over 100 iterations, averaged over 10 repetitions. Iteration 1 is removedfor visibility purposes. The vertical line represents the end of the initial design phase.
Figure 7: Point selection strategy evolution for πBO on SMAC with a GP surrogate for the EI, PI,UCB and TS acquisition functions on the Log-1D-Branin function. The plots show rescaled values ofthe prior-weighted acquisition function (purple), the regular acquisition function (blue) and πn (red)on a 1D-Branin (grey) with global optimum in the center of the search space and the current selectionas a vertical violet line. The rows represent iterations 4, 6 and 8 for a run with β = 2.
Figure 8: πBO with binning and SMAC using and RF surrogate and EI acquisition function, β = 10,and the supporting frameworks for Branin and Profet benchmarks for varying prior qualities. Themean and standard error of log simple regret is displayed over 100 iterations, averaged over 10repetitions. Iteration 1 is removed for visibility purposes. The vertical line represents the end of theinitial design phase.
Figure 9: Point selection strategy evolution for πBO on SMAC with a RF surrogate, when employinga smooth prior (left) and binned prior (right) for the 1D-Branin function. The plots show rescaledvalues of prior-weighted EI (purple), EI (blue) and πn (red) on a 1D-Branin (grey) with globaloptimum in the center of the search space and the current selection as a vertical violet line. The rowsrepresent iterations 5, 10, 15 and 20, for a run with β = 5.
Figure 10: Comparison of πBO, Spearmint and other approaches for priors over the optimum forBranin, Hartmann and Profet benchmarks. πBO is implemented in Spearmint. The mean and standarderror of log simple regret is displayed over 100 iterations, averaged over 20 repetitions. Iteration 1 isremoved for visibility purposes. The vertical line represents the end of the initial design phase.
Figure 11: Comparison of πBO, Hypermapper and other approaches for priors over the optimumfor Branin, Hartmann and Profet benchmarks. πBO is implemented in Spearmint. The mean andstandard error of log simple regret is displayed over 100 iterations, averaged over 20 repetitions.
Figure 12: Comparison of πBO, BOPrO, BOWS, and prior sampling for 5D MLP tuning on variousOpenML datasets for a prior centered around default values. We show mean and standard error ofthe accuracy across 20 repetitions. Iteration 1 is removed for visibility purposes. The vertical linerepresents the end of the initial design phase.
Figure 13: Value of Cn,n at iteration 50 for a centered Gaussian prior in a one-dimensional searchspace, varying σ and β. The value of Cn,n upper bounds the loss incurred by EInrelative EI at the atthe given iteration, given the same data. Regions in dark represent pairs of (σ, β) where the upperbound on prior-weighted EI is low relative to EI, whereas regions in yellow represent pairs of (σ, β)where the upper bound is approximately the same.
Figure 14: Comparison on Branin of priors with varying widths and offsets over the optimum onπBO, Spearmint, Spearmint with mode initialization, and sampling from the prior. The mean andstandard error of log simple regret is displayed over 100 iterations, averaged over 20 repetitions.
Figure 15: Comparison on Hartmann-6 of priors with varying widths and offsets over the optimumon πBO, Spearmint, Spearmint with mode initialization, and sampling from the prior. The meanand standard error of log simple regret is displayed over 100 iterations, averaged over 20 repetitions.
Figure 16: Comparison on SVM of priors with varying widths and offsets over the optimum on πBO,Spearmint, Spearmint with mode initialization, and sampling from the prior. The mean and standarderror of log simple regret is displayed over 100 iterations, averaged over 20 repetitions. Iteration 1 isremoved for visibility purposes.
Figure 17: Comparison on FCNet of priors with varying widths and offsets over the optimum onπBO, Spearmint, Spearmint with mode initialization, and sampling from the prior. The mean andstandard error of log simple regret is displayed over 100 iterations, averaged over 20 repetitions.
Figure 18: Comparison on XGBoost of priors with varying widths and offsets over the optimumon πBO, Spearmint, Spearmint with mode initialization, and sampling from the prior. The meanand standard error of log simple regret is displayed over 100 iterations, averaged over 20 repetitions.
