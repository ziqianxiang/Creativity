Figure 1: Within-class variation collapse. (a) CDNV on the source training data; (b) CDNVover the source test data; (c) CDNV over the target classes, all plotted in log-log scale. (d) Targetaccuracy rate (lin-log scale). In each experiment we trained the model on a different number ofsource classes l ∈ {5, 10, 20, 30, 40, 50, 60} (as indicated in the legend).
Figure 2: Averaged class variance and accuracy rates when varying the number of sourceclasses on CIFAR-FS. In (a) we plot the CDNV and accuracy rates on the source training data(resp.), in (b) on the source test data and in (c) on the target test data. In each experiment we traineda WRN-28-4 with SGD on a set of l ∈ {5, 10, 20, 30, 40, 50, 60} source classes (as indicated in thelegend). The i’th column stands for learning rate η = 2-2i-2.
Figure 3: Averaged class variance and accuracy rates when varying the number of sourceclasses on EMNIST. In (a) we plot the CDNV and accuracy rates on the source training data (resp.),in (b) on the source test data and in (c) on the target test data. In each experiment we trained a WRN-28-4 with SGD on a set of l ∈ {5, 10, 20, 30, 40, 50, 60} source classes (as indicated in the legend).
Figure 4: Within-class variation and few-shot performance with learning rate η = 2-4. Wetrained WRN-28-4 using SGD with learning rate scheduling on l ∈ {5, 10, 20, 30, 40, 50, 64} sourceclasses (as indicated in the legend). For each dataset, in (a-c) we plot the CDNV on the train andtest data and the target classes (resp.). In (d-g) we plot the 1,5,10 and 20-shot accuracy rates (resp.).
Figure 5: Within-class variation and few-shot performance with learning rate scheduling. Wetrained WRN-28-4 using SGD with learning rate scheduling on l ∈ {5, 10, 20, 30, 40, 50, 64} sourceclasses (as indicated in the legend). For each dataset, in (a-c) we plot the CDNV on the train andtest data and the target classes (resp.). In (d-g) we plot the 1,5,10 and 20-shot accuracy rates (resp.).
Figure 6: Within-class variation collapse of the second-to-last embedding layer. In each ex-periment we trained a WRN-28-4 using SGD with η = 2-4 on a set of l = 64 source classeson CIFAR-FS. We compare the CDNVs and 5-shot accuracy rates of the second-to-last embeddinglayer and the top embedding layer of the network. In (a) we compare the CDNV on the source traindata, in (b) the CDNV on the source test data, (c) the CDNV on the target classes and in (d) the5-shot accuracy rates.
Figure 7: Dynamics of minimal class-means distance. In (a) We plot mmi=∙ ∣∣μ∕ (Si) - μf (Sj )k,in (b) We plot mi%=j ∣∣μf (Pi)-μf (Pj- )k and in (c) We plot mi%=j ∣∣μf (Pi)-μf (Pj- )k as a functionof the number of training iterations. In each experiment We trained a WRN-28-4 using SGD on a setof l ∈ {5, 10, 20, 30, 40, 50, 60} source classes on CIFAR-FS (as indicated in the legend). The i’thcolumn corresponds to the results of training With SGD With η = 2-2i-2 .
Figure 8: Results of WRN-28-4 on Mini-ImageNet. (row 1) CDNV, (row 2) CCNV, and (row 3)accuracy on the source train, test, and the target data (columns a,b,c, resp.). Each model Was trainedusing SGD With η = 2-4 on a set of l ∈ {5, 10, 20, 30, 40, 50, 60} source classes (as indicated inthe legend).
Figure 9: Results of Conv-28-4 on CIFAR-FS. (row 1) CDNV, (row 2) CCNV, and (row 3) ac-curacy on the source train, test, and the target data (columns a,b,c, resp.). Each model was trainedusing SGD with η = 2-4 on a set of l ∈ {5, 10, 20, 30, 40, 50, 60} source classes (as indicated inthe legend).
Figure 10: Within-class variation collapse on CIFAR-FS. In (a) We plot the CCNV on the sourcetraining data, in (b) on the source test data and in (c) on the target test data. In each experimentwe trained a WRN-28-4 using SGD on a set of l ∈ {5, 10, 20, 30, 40, 50, 60} source classes (asindicated in the legend). The i’th column stands for the results when training with learning rateη = 2-2i-2.
Figure 11: Within-class variation collapse on EMNIST. In (a) We plot the CCNV on the sourcetraining data, in (b) on the source test data and in (c) on the target test data. We trained a WRN-28-4with SGD on a set of l ∈ {5, 10, 15, 20, 25, 30, 35} source classes (as indicated in the legend). Thei’th column shows results for learning rate η = 2-2i-2 .
