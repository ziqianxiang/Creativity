Figure 1: Overview of our approach. We select goals based on the predicted probability of a locationcontaining our target and the uncertainty of the prediction. Note that in this particular example, thesofa to the right of the agent is not visible, but it is correctly predicted by our method.
Figure 2: Overview of our semantic map predictor approach for a single time-step. The modelpredicts the top-down egocentric semantics of unobserved areas in a two-step procedure. First, theoccupancy Pt is predicted, which is concatenated with a ground-projected semantic segmentationof the RGB observation before producing the final output τmt. Note that our model learns to predictsemantically plausible maps (i.e. chairs surrounding a table) as shown in this example.
Figure 3: Qualitative map predic-tion results.
Figure 4: Semantic mapping results per class over different active training methods.
Figure 6: Ablations of our method that investigate the effect of the stop decision and local policy.
Figure 7: Our actively trained semantic mapping model shows consistently higher performance onhard episodes.
Figure 8: Examples of successful navigation episodes where the targets are “chair” (top) and “bed”(bottom). For each example, first row shows egocentric RGB observations, second row are theegocentric semantic predictions, third row are the registered geocentric predictions, and the last rowshows the model uncertainty of the target class over the geocentric predictions (brighter color signifieshigher uncertainty). The agent is shown as a blue dot, and the current goal as magenta.
Figure 9: Qualitative semantic prediction results using our L2M-Active approach.
Figure 10: Qualitative semantic prediction from the individual models in the ensemble (first fourcolumns) using our L2M-Active approach.
