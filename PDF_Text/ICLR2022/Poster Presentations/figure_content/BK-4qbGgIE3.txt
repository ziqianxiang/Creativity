Figure 1: As training methodology diverges (Reinit → Dataset), errors become uncorrelated.
Figure 2: As uncorrelated errors increase, so does ensemble performance (left, center), and sodoes ensemble efficiency (right). Left: Error inconsistency is linearly correlated With the ensembleperformance improvement, relative to the mean accuracy of the models in the ensemble. Starsrepresent averages over models in each category (W/ error bars). Center: Because We limited ouranalysis to models in the same 74-78% accuracy range, the increase in relative accuracy translatesinto absolute accuracy boost, With best performing ensembles comprising of models Whose trainingmethodologies are most different. Right: Surprisingly, the conversion rate - the rate at Which theseexamples are converted into correct predictions by the ensemble - also increases. This indicates thatthe benefits of combining divergently-trained models go beyond increasing the number of examplesthat can become correct predictions, to also increasing hoW efficiently these examples do becomecorrect predictions.
Figure 3: Differently-trained models specialize: We plot histograms of examples where at least oneensemble produced error inconsistency, as a function of specialization measure θ, the angle distancein the confidence-confidence plot (upper left). As we saw in Fig. 1, when model training setupsdiverge (Reinit → Arch → Dataset), the fraction of consistent errors decreases (upper center & right),in favor of more error inconsistency (lower center & right). This added error inconsistency comeswith specialization of the models in an ensemble: when only Model 1 makes a correct prediction, itis often more confident (lower right), and vice-versa for Model 2 (lower center). Faint dotted linesindicate values of θ for which a model’s top-1 prediction is likely to prevail at ensemble time.
Figure 4: Specialization type depends on training setup: When models differ in dataset (rightplot), not only is specialization highest (see Fig. 3), but also this specialization happens in differentclasses - CLIP is better at anthropogenic classes (Cids 500-900) than ResNet-50, which is better atnature classes (cids 0-300; Right detail). When models differ in their architecture (Center plot), theyare more specialized than reinitializations (Left plot), but such specialization does not correlate withspecific classes.
Figure 5: Lower-accuracy models can benefit high-accuracy ensembles: Left: Starting with 4high-accuracy models (colored markers; CLIP-L, ALIGN, BiT-1k, EfficientNet-B3), we greedilyselect the best lower accuracy models (each with max individual accuracy 77.9%, indicated in thelegend) to ensemble, and plot the ensemble’s accuracy. Colors indicate which high-accuracy modelthe ensemble begins with, shapes indicate which models are added. By adding only lower-accuracymodels to a high-accuracy one, we are able to create ensembles that reach as high as 86.7%. Thisshows that lower-accuracy models can be made useful, if they are diverse enough. Right: In eachcase, the best first model to add is one that complements the base model’s training methodology.
Figure 6: Specialization comes from overlapping (not supersetting) representations. When wecombine the representations of two models at different rates (Left, 25/75 using 25% of the ResNetembedding and 75% of the other model’s embedding), we find that: 1) despite being smaller numberof dimensions, the concatenated embeddings (Center, e.g.: 50/50) yield higher LBFGS accuracy thanthe complete embedding of any of the two models (100/0 or 0/100). This indicates that each modelhas learned overlapping, but not supersetting, features, which when combined maximize performance.
Figure 7: Diverse training methodologies yield the best downstream performance. Left: Thehighest-accuracy ImageNet model (MPL) is not the best-performing on Pascal VOC. Center: CLIP-Sis the model with the most prediction diversity, among the models analyzed. Right: Combiningmodels that are most diverse seems to yield the biggest boost when performing stacked generalizationon a downstream task (i.e.: training a linear layer on top of 2 models’ concatenated embeddings).
Figure 8: As training methodology diverges, errors become uncorrelated. The number of testexamples where only one model predicts correctly increases (Left, same as "Error Inconsistency" inFig. 1). Similarly, the number of examples where both models predict correctly (Center) and neithermodel predicts correctly (Right) decreases. For the most diverse training methodology ("Dataset",purple), we find more examples with inconsistent errors (left) than examples where both modelspredict correctly (right). This means that for an ensemble to perform better than another, it needs toresolve these inconsistent errors efficiently, to compensate for the decrease in the examples in thecenter plot.
Figure 9: Justification for θ. The white dotted lines represent the thresholds where an example’sensemble prediction will correspond to the higher-confidence-model’s top-1 prediction. Thetameasures distances in a way that aligns with these thresholds, allowing us to visualize the number ofcorrectly-classified examples at a glance (by looking at the number of examples to the right/left ofthe dotted lines in Fig 3). Because y-x does not align with this threshold, it’s harder to visualize theeffect of specialization on performance, as can be seen by the histograms.
Figure 10:	Conversion rate of examples where "neither model" is correct individually. We findthat, as training methodology diverges, the conversion rate of these examples increases: Reinit (94converted out of 7154 examples), Architecture (190 / 6246), Dataset (355 / 5192). This is consistentwith our finding that different training methodologies create more efficient ensembles. We note thatdespite the higher conversion rate, a bigger effect on performance is in the decrease of exampleswhere neither is correct (7154 -> 6246 -> 5192).
Figure 11:	Interpolating between ensemble members. Left: We interpolate between the twomodels in the ensemble using a single parameter, and find that the optimal interpolating parameterseems to be at or near 0.5 (i.e.: it’s just as good to simply average the logits with equal weight).
Figure 12:	Specialization of CLIP-S and SimCLR. We find that these two models seem to alsospecialize in a way that is aligned with anthropogenic/nature classes (cids 500-900, and 0-300respectively). We suspect the distribution of CLIP’s pre-training dataset has a huge effect in makingthis happen. We also stress that these two models are still in very distinct categories: when comparingagainst each other (and not against our base model), we must note that they are different in reinit,architecture, params, and dataset, even if framework is kept the same.
Figure 13:	CKA vs Error Consistency. Here, CKA is measured between the two pre-logitrepresentations of ResNet, and each of the models ResNet, CLIP-S-ZS, SimCLR, EfficientNet,ViT-B/16 and DenseNet-121. CKA and Error Consistency are not well correlated, likely due to CKAbeing sensitive to the geometry of representations.
