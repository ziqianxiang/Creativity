title,year,conference
 Curriculum adversarial training,2018, In IJCAI
 Towards evaluating the robustness of neural networks,2017, InIEEE Symposium on Security and Privacy (SP)
 Unlabeled dataimproves adversarial robustness,2019, In NeurIPS
 Robust overfittingmay be mitigated by properly learned smoothening,2021, In ICLR
 Extracting tree-structured representations of trained networks,1996, InNeurIPS
 BERT: Pre-training of deepbidirectional transformers for language understanding,2019, In NAACL
 Mma training: Directinput space margin maximization through adversarial training,2020, In ICLR
 Learning diverse-structured networks for adversarial robustness,2021, In ICML
 Adversarially robust distillation,2020, InAAAI
 Explaining and harnessing adversarialexamples,2015, In ICLR
 Deep residual learning for imagerecognition,2016, In CVPR
 Distilling the knowledge in a neural network,2015, InarXiv
 Robust pre-training by adversarialcontrastive learning,2020, In NeurIPS
 Learning multiple layers of features from tiny images,2009, In arXiv
 Tiny imagenet visual recognition challenge,2015, In CS231N course
 Autonomous vehicle implementation predictions,2017, Victoria Transport Policy InstituteVictoria
 On the loss landscapeof adversarial training: Identifying challenges and how to overcome them,2020, In NeurIPS
 Distillation as adefense to adversarial perturbations against deep neural networks,2016, In IEEE Symposium on Securityand Privacy (SP)
 Overfitting in adversarially robust deep learning,2020, In ICML
 Encoding robustness to image stylevia adversarial feature perturbations,2021, In NeurIPS
 Towardsefficient and effective adversarial training,2021, In NeurIPS
 Intriguing properties of neural networks,2014, In ICLR
 Once-for-all adversarial training: In-situ tradeoff between robustness and accuracy for free,2020, In NeurIPS
 On theconvergence and robustness of adversarial training,2019, In ICML
 Device-cloudcollaborative learning for recommendation,2021, In KDD
 Wide residual networks,2016, In arXiv
 Attacks which do not kill training make adversarial learning stronger,2020, In ICML
 Revisiting adversarial robustness distillation:Robust soft labels make student better,2021, In ICCV
