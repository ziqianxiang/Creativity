title,year,conference
 High-dimensional dynamics ofgeneralization error in neural networks,0893, Neural Networks
 Data-dependent com-pression of random features for large-scale kernel approximation,2019, In The 22nd InternationalConference on Artificial Intelligence and Statistics
 Fine-grained analysis ofoptimization and generalization for overparameterized two-layer neural networks,2019, In InternationalConference on Machine Learning
 On the inductive bias of neural tangent kernels,2019, arXiv preprintarXiv:1905
 Probability and Measure,9781, Wiley Series in Probability and Statistics
 Similarity estimation techniques from rounding algorithms,2002, In Proceedings of thethiry-fourth annual ACM symposium on Theory of computing
 Kernel methods for deep learning,2012, University of California
 Kernel spectral clustering of large dimensionaldata,2016, Electronic Journal of Statistics
 Classification asymptotics in the random matrixregime,2018, In 2018 26th European Signal Processing Conference (EUSIPCO)
 Two-way kernel matrix puncturing:towards resource-efficient pca and spectral clustering,2021, arXiv preprint arXiv:2102
 Imagenet: A large-scalehierarchical image database,2009, In 2009 IEEE conference on computer vision and pattern recognition
 Exact expressions fordouble descent and implicit regularization via surrogate random design,2020, In Advancesin Neural Information Processing Systems
 Gradient descent finds globalminima of deep neural networks,1675, In International Conference on Machine Learning
 Spectra of the conjugate kernel and neural tangent kernel for linear-width neural networks,2020, arXiv preprint arXiv:2005
 Improved approximation algorithms for maximum cutand satisfiability problems using semidefinite programming,1995, Journal of the ACM (JACM)
 Compressing deep convolutionalnetworks using vector quantization,2014, arXiv preprint arXiv:1412
 Deep learning withlimited numerical precision,1737, In International conference on machine learning
 Learning both Weights and Connections forEfficient Neural Network,2015, In Advances in Neural Information Processing Systems
 BinarizedNeural Networks,2016, In Advances in Neural Information Processing Systems
 Neural tangent kernel: Convergence andgeneralization in neural networks,2018, arXiv preprint arXiv:1806
 Implicitregularization of random feature models,4631, In Proceedings of the 37th International Conference onMachine Learning
 Multidimensional Scaling,9780, 1978
 Learning multiple layers of features from tiny images,2009, 2009
 Kernel and nonlinear canonical correlation analysis,2000, InternationalJournal of Neural Systems 
 Gradient-based learning applied todocument recognition,0018, Proceedings of the IEEE
 Deep neural networks as gaussian processes,2017, arXiv preprint arXiv:1711
 Wide neural networks of any depth evolve as linear modelsunder gradient descent,2019, arXiv preprint arXiv:1902
 Simple strategies for recovering inner products from coarsely quantizedrandom projections,2017, Advances in Neural Information Processing Systems
 Random projections with asymmetric quantization,2019, Advances in NeuralInformation Processing Systems
 Quantization algorithms for random fourier features,2021, arXiv preprintarXiv:2102
 Towards a unified analysis of randomfourier features,2021, Journal of Machine Learning Research
 The dynamics of learning: A random matrix approach,2018, InInternational Conference on Machine Learning
 On the spectrum of random features maps of high dimensionaldata,2018, In International Conference on Machine Learning
 Inner-product Kernels are Asymptotically Equivalent to BinaryDiscrete Kernels,2019, arXiv
 Sparse quantized spectral clustering,2021, InInternational Conference on Learning Representations
 Neural networks withfew multiplications,2015, arXiv preprint arXiv:1510
 Sparse convolu-tional neural networks,2015, In Proceedings of the IEEE conference on computer vision and patternrecognition
 Concentration of measure and large random matrices with anapplication to sample covariance matrices,2018, arXiv preprint arXiv:1805
 Spherical structured feature maps for kernel approximation,2017, In International Confer-ence on Machine Learning
 Implicit self-regularization in deep neural networks: Ev-idence from random matrix theory and implications for learning,2018, arXiv preprint arXiv:1810
 Traditional and heavy-tailed self regularization in neuralnetwork models,2019, arXiv preprint arXiv:1901
 The generalization error of random features regression: Preciseasymptotics and double descent curve,2019, arXiv preprint arXiv:1908
 Bayesian deep convolutional networks with manychannels are gaussian processes,2018, arXiv preprint arXiv:1810
 On random matrices arising in deep neural networks,2020, gaussian case
 Nonlinear random matrix theory for deep learning,2017, 2017
 Binary neuralnetworks: A survey,2020, Pattern Recognition
 Random Features for Large-Scale Kernel Machines,2008, In Advancesin Neural Information Processing Systems
 Nonlinear Component Analysis as aKernel Eigenvalue Problem,0899, Neural Computation
 Kernel principal componentanalysis,1997, In International conference on artificial neural networks
 A kernel random matrix-based approach for sparse pca,2019, In International Conference on Learning Representations (ICLR)
 A tutorial on spectral clustering,2007, Statistics and computing
 Kernel ridge regression,2013, In Empirical inference
 CompUting with infinite networks,1997, Advances in neural informationprocessing systems
 Orthogonal random featUres,2016, Advances in neural information processingsystems
 Low-precision random fourier features formemory-constrained kernel approximation,2019, In The 22nd International Conference on ArtificialIntelligence and Statistics
 Trained ternary quantization,2016, arXivpreprint arXiv:1612
