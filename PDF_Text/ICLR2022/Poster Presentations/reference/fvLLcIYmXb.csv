title,year,conference
 End-to-end object detection with transformers,2020, In European Conferenceon Computer Vision (ECCV)
 CrossViT: Cross-attention multi-scale vision transformer for image classification,2021, In Proceedings of the IEEE/CVF InternationalConference on Computer Vision (ICCV)
 Encoder-decoder with atrous separable convolution for semantic image segmentation,2018, In Proceedings ofthe European Conference on Computer Vision (ECCV)
 Cyclemlp: A mlp-like architec-ture for dense prediction,2021, arXiv preprint arXiv:2107
 Twins: Revisiting the design of spatial attention in vision transformers,2021, In Ad-vances in Neural Information Processing Systems (NeurIPS)
 Conditional positional encodings for vision transformers,2021, arXiv preprint arXiv:2102
 MMSegmentation: Openmmlab semantic segmentation toolboxand benchmark,2020, https://github
 Deformableconvolutional networks,2017, In Proceedings of the IEEE International Conference on Computer Vi-sion (ICCV)
 Imagenet: A large-scalehierarchical image database,2009, In Proceedings of the IEEE Conference on Computer Vision andPattern Recognition (CVPR)
 BERT: Pre-training of deepbidirectional transformers for language understanding,2018, arXiv preprint arXiv:1810
 An im-age is worth 16x16 words: Transformers for image recognition at scale,2021, In International Confer-ence on Learning Representations (ICLR)
 Dual attentionnetwork for scene segmentation,2019, In Proceedings of the IEEE Conference on Computer Vision andPatternRecognition (CVPR)
 Adaptivecontext network for scene parsing,2019, In Proceedings of the IEEE International Conference onComputer Vision (ICCV)
 Container:Context aggregation network,2021, In Advances in Neural Information Processing Systems (NeurIPS)
 Levit: A vision transformer in convnet¡¯s clothing for faster inference,2021, InProceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)
 Beyond self-attention: Externalattention using two linear layers for visual tasks,2021, arXiv preprint arXiv:2105
 Transformer intransformer,2021, In Advances in Neural Information Processing Systems (NeurIPS)
 Deep residual learning for image recog-nition,2016, In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition(CVPR)
 Mask R-CNN,2017, In Proceedings ofthe IEEE International Conference on Computer Vision (ICCV)
 Axial attention in multidi-mensional transformers,2019, arXiv preprint arXiv:1912
 Vi-sion permutator: A permutable mlp-like architecture for visual recognition,2021, arXiv preprintarXiv:2106
 Deep networks withstochastic depth,2016, In European Conference on Computer Vision (ECCV)
 Imagenet classification with deep con-volutional neural networks,2012, Advances in neural information processing systems
 Localvit: Bringing localityto vision transformers,2021, arXiv preprint arXiv:2104
 Microsoft COCO: Common objects in context,2014, In EuropeanConference on Computer Vision (ECCV)
 Pay attention to mlps,2021, arXiv preprintarXiv:2105
 Decoupled weight decay regularization,2019, In International Confer-ence on Learning Representations (ICLR)
 Do you even need attention? a stack of feed-forward layers does surprisinglywell on imagenet,2021, arXiv preprint arXiv:2105
 Designingnetwork design spaces,2020, In Proceedings of the IEEE Conference on Computer Vision and PatternRecognition (CVPR)
 Very deep convolutional networks for large-scale imagerecognition,2015, In International Conference on Learning Representations (ICLR)
 Sparse R-CNN: End-to-end object detection withlearnable proposals,2021, In Proceedings of the IEEE Conference on Computer Vision and PatternRecognition (CVPR)
 Rethink-ing the inception architecture for computer vision,2016, In Proceedings of the IEEE Conference onComputer Vision and Pattern Recognition (CVPR)
 Efficientnet: Rethinking model scaling for convolutional neural net-works,2019, In International Conference on Machine Learning (ICML)
 Efficientnetv2: Smaller models and faster training,2021, In InternationalConference on Machine Learning (ICML)
 MLP-Mixer: Anall-mlp architecture for vision,2021, arXiv preprint arXiv:2105
 ReSMLP:Feedforward networks for image classification with data-efficient training,2021, arXiv preprintarXiv:2105
 Training data-efficient image transformers & distillation through attention,2021, InInternational Conference on Machine Learning (ICML)
 Go-ing deeper with image transformers,2021, In Proceedings of the IEEE International Conference onComputer Vision (ICCV)
 Attention is all you need,2017, In Advances in Neural Infor-mation Processing Systems (NeurIPS)
 Pyramid vision transformer: A versatile backbone for dense prediction withoutconvolutions,2021, In Proceedings of the IEEE International Conference on Computer Vision (ICCV)
 Unified perceptual parsing forscene understanding,2018, In Proceedings of the European Conference on Computer Vision (ECCV)
 Aggregated residual trans-formations for deep neural networks,2017, In Proceedings of the IEEE Conference on Computer Visionand Pattern Recognition (CVPR)
 Multi-scale context aggregation by dilated convolutions,2016, In Interna-tional Conference on Learning Representations (ICLR)
 S2-MLP: Spatial-shift mlp architecturefor vision,2021, arXiv preprint arXiv:2106
 Tokens-to-token vit: Training vision transformers from scratch onimagenet,2021, In Proceedings of the IEEE International Conference on Computer Vision (ICCV)
 Object-contextual representations for semantic seg-mentation,2020, In Computer Vision-ECCV 2020: 16th European Conference
 Aggregating nested trans-formers,2021, arXiv preprint arXiv:2105
 DeepViT: Towards deeper vision transformer,2021, arXiv preprint arXiv:2103
