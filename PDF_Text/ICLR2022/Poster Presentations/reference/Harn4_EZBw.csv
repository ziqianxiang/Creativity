title,year,conference
 Remembering the past and imagining the future: Commonand distinct neural substrates during event construction and elaboration,2007, Neuropsychologia
 On iterative computation of generalized inverses and associatedprojections,1966, SIAM Journal on Numerical Analysis
 Generalized inverses: theory and applications,2001,2001
 Variational memory addressingin generative models,2017, Advances in Neural Information Processing Systems
 Attention approximates sparse distributed memory,2021, NeurIPS
 Importance weighted autoencoders,2016, ICLR
 Variational lossy autoencoder,2017, ICLR
 Fast computation of moore-penrose inverse matrices,2008, arXiv preprint arXiv:0804
 Maximum likelihood from incomplete data via the emalgorithm,1977,1977
 Blessing of dimensionality: mathematical foundations ofthe statistical physics of data,2018, Philosophical Transactions of the Royal Society A: Mathematical
 Associative compression networks forrepresentation learning,2018, arXiv preprint arXiv:1804
 Draw: A recurrentneural network for image generation,2015, ICML
 Some applications of the pseudoinverse of a matrix,1960, SIAM review
 Long short-term memory,1997, Neural computation
 Neural networks and physical systems with emergent collective computationalabilities,1982, Proceedings ofthe national academy ofsciences
 Probability theory: The logic of science,2003, Cambridge university Press
 Auto-encoding variational bayes,2014, ICLR
 Learning multiPle layers of features from tiny images,2009,2009
 Deep learning face attributes in the wild,2015, InProceedings of International Conference on Computer Vision (ICCV)
 Mae: Mutual posterior-divergence regularization forvariational autoencoders,2019, ICLR
 Product kanerva machines: Factorized bayesianmemory,2020, arXiv preprint arXiv:2002
 Metalearned neuralmemory,2019, In NeurIPS
 Thinking of the future and past: the roles of the frontal pole and themedial temporal lobes,2003, NeuroImage
 Automatic differentiation inpytorch,2017,2017
 Collective computational properties of neural networks: Newlearning mechanisms,1986, Physical Review A
 Swish: a self-gated activation function,2017, arXiv:Neural and Evolutionary Computing
 Hopfield networksis all you need,2020, arXiv preprint arXiv:2008
 HoPfield networks is allyou need,2021, In International Conference on Learning Representations
 Pixelcnn++: ImProving the Pixelcnnwith discretized logistic mixture likelihood and other modifications,2017, ArXiv
 On the numerical properties of an iterative method for computing themooreapenrose generalized inverse,1974, SIAM Journal on Numerical Analysis
 On the effect of noise on the moore-penrose generalized inverseassociative memory,1985, IEEE Transactions on Pattern Analysis and Machine Intelligence
 Vae with a vampprior,2018, In International Conference on ArtificialIntelligence and Statistics
 A new method for computing moore-penrose inverse matrices,2009, Journalof Computational and applied Mathematics
 Attention is all you need,2017, ArXiv
 The kanerva machine: A generative distributedmemory,2018, ICLR
 Learning attractor dynamics forgenerative memory,2018, NeurIPS
 Fashion-mnist: a novel image dataset for benchmarkingmachine learning algorithms,2017, ArXiv
 A learning and forgetting algorithm in associative memories: results involvingpseudo-inverses,1991, IEEE Transactions on Circuits and Systems
