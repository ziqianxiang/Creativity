title,year,conference
 A convergence theory for deep learning via over-parameterization,2019, In International Conference on Machine Learning
 On the optimization of deep networks: Im-plicit acceleration by overparameterization,2018, In International Conference on Machine Learn-ing
 Obfuscated gradients give a false senseof security: Circumventing defenses to adversarial examples,2018, In International Conference onMachine Learning
 Universal approximation with certifiednetworks,2020, In International Conference on Learning Representations
 Adversarial training and provable defenses: Bridgingthe gap,2020, In International Conference on Learning Representations
 Aunified view of piecewise linear neural network verification,2018, In Advances in Neural InformationProcessing Systems
 Adversarial examples are not easily detected: Bypassing tendetection methods,2017, In Proceedings of the 10th ACM Workshop on Artificial Intelligence andSecurity
 Certified adversarial robustness via random-ized smoothing,2019, In International Conference on Machine Learning
 Gradient descentfinds global minima of deep neural networks,2019, In International Conference on Machine Learn-ing
 Gradient descent provably optimizesover-parameterized neural networks,2019, In International Conference on Learning Representations
 Training verified learners with learned ver-ifiers,2018, arXiv preprint arXiv:1805
 Convergence ofadversarial training in overparametrized neural networks,2019, In Advances in Neural Information Pro-cessing Systems
 Explaining and harnessing adversarialexamples,2015, In International Conference on Learning Representations
 On the effectiveness of interval bound propagation fortraining verifiably robust models,2018, arXiv preprint arXiv:1810
 Countering adversarialimages using input transformations,2018, In International Conference on Learning Representations
 Polylogarithmic width suffices for gradient descent to achievearbitrarily small test error with shallow relu networks,2019, CoRR
 Loss landscaPe matters: Trainingcertifiably robust models with favorable loss landscaPe,2021, OpenReview
 Certified adversarial robustness withadditive noise,2019, In Advances in Neural Information Processing Systems
 Towardsevaluating and training verifiably robust neural networks,2021, In Proceedings of the IEEE/CVF Con-ference on Computer Vision and Pattern Recognition
 To-wards deeP learning models resistant to adversarial attacks,2018, In International Conference on Learn-ing Representations
 Differentiable abstract interPretation forProvably robust neural networks,2018, In International Conference on Machine Learning
 Certified defenses against adversarialexamPles,2018, In International Conference on Learning Representations
 Semidefinite relaxations for certifyingrobustness to adversarial examPles,2018, In Advances in Neural Information Processing Systems
 Provably robust deeP learning via adversarially trainedsmoothed classifiers,2019, In Advances in Neural Information Processing Systems
 Fast certified robusttraining via better initialization and shorter warmup,2021, arXiv preprint arXiv:2103
 Fastand effective robustness certification,2018, In Advances in Neural Information Processing Systems
 An abstract domain for certi-fying neural networks,2019, Proceedings of the ACM on Programming Languages
 Pixeldefend:Leveraging generative models to understand and defend against adversarial examples,2018, In Interna-tional Conference on Learning Representations
 Intriguing properties of neural networks,2014, In International Conference onLearning Representations
 On adaptive attacks toadversarial example defenses,2020, arXiv preprint arXiv:2002
 Mixtrain: Scalable training of formallyrobust neural networks,2018, arXiv preprint arXiv:1811
 Formal security analysisof neural networks using symbolic intervals,2018, In 27th {USENIX} Security Symposium ({USENIX}Security 18)
 On theconvergence and robustness of adversarial training,2019, In International Conference on MachineLearning
 Interval universal approximationfor neural networks,2020, arXiv preprint arXiv:2007
 Towards fast computation of certified robustness for relu net-works,2018, In International Conference on Machine Learning
 Provable defenses against adversarial examples via the convex outeradversarial polytope,2018, In International Conference on Machine Learning
 Enhancing adversarial defense by k-winners-take-all,2020, In International Conference on Learning Representations
 Trainingfor faster adversarial robustness verification via inducing relu stability,2019, In International Confer-ence on Learning Representations
 Automatic perturbation analysis for scalable certifiedrobustness and beyond,2020, Advances in Neural Information Processing Systems
 Towards certifying l-infinity ro-bustness using neural networks with l-inf-dist neurons,2021, In International Conference on MachineLearning 
 Efficient neural net-work robustness certification with general activation functions,2018, In Advances in Neural InformationProcessing Systems
 Towards stable and efficient training of verifiably robust neural networks,2020, InInternational Conference on Learning Representations
 Over-parameterized adversarial training: An analysis overcoming the curse of dimensionality,2020, arXivpreprint arXiv:2002
 Stochastic gradient descent optimizesover-parameterized deep relu networks,2018, arXiv preprint arXiv:1811
 Provable robustness of adversarial training for learninghalfspaces with noise,2021, arXiv preprint arXiv:2104
