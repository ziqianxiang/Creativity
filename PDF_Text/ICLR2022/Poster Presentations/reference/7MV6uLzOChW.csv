title,year,conference
 Do gans actually learn the distribution? an empirical study,2017, arXivpreprint arXiv:1706
 Filling-in by joint interpolation of vector fields and gray levels,2001, IEEE transactions on image processing
 Pattern recognition and machine learning,2006, springer
 On the opportu-nities and risks of foundation models,2021, arXiv preprint arXiv:2108
 Bayesian experimental design: A review,1995, StatisticalScience
 Object removal by exemplar-based inpaint-ing,2003, In 2003 IEEE Computer Society Conference on Computer Vision and Pattern Recognition
 Imagenet: A large-scale hi-erarchical image database,2009, In 2009 IEEE conference on computer vision and pattern recognition
 Pre-train and plug-in: Flexibleconditional text generation with variational auto-encoders,2019, arXiv preprint arXiv:1911
 Neural processes,2018, arXiv preprint arXiv:1807
 Generative adversarial networks,2014, arXiv preprintarXiv:1406
 Near-optimal glimpse sequences for improvedhard attention neural network training,2019, arXiv preprint arXiv:1906
 Hierarchical Vaes know What theydon¡¯t know,2021, arXiv preprint arXiv:2102
 A baseline for detecting misclassified and out-of-distributionexamples in neural networks,2016, arXiv preprint arXiv:1610
 Globally and locally consistent imagecompletion,2017, ACM Transactions on Graphics (ToG)
 Image-to-image translation withconditional adversarial networks,2016, arxiv (2016)
 Variational autoencoder with arbitrary condi-tioning,2018, arXiv preprint arXiv:1806
 A style-based generator architecture for generativeadversarial networks,2019, In Proceedings of the IEEE/CVF Conference on Computer Vision andPattern Recognition
 Analyz-ing and improving the image quality of stylegan,2020, In Proceedings of the IEEE/CVF Conference onComputer Vision and Pattern Recognition
 Attentive neural processes,2019, arXiv preprint arXiv:1901
 Improving variational inference with inverse autoregressive flow,2016, arXiv preprintarXiv:1606
 Learninghierarchical priors in vaes,2019, arXiv preprint arXiv:1905
 Learning how to inpaint from global image statistics,2003, InICCV
 Recurrent feature reasoning forimage inpainting,2020, In Proceedings of the IEEE/CVF Conference on Computer Vision and PatternRecognition
 Multimodal image synthesis with con-ditional implicit maximum likelihood estimation,2020, International Journal of Computer Vision
 Anycost gans for interactiveimage synthesis and editing,2021, arXiv preprint arXiv:2103
 Pd-gan: Probabilisticdiverse gan for image inpainting,2021, arXiv preprint arXiv:2105
 Eddi: Efficient dynamic discovery of high-value information withpartial vae,2018, arXiv preprint arXiv:1809
 Divergence measures and message passing,2005, Technical report
 Readingdigits in natural images with unsupervised feature learning,2011,2011
 Plug & playgenerative networks: Conditional iterative generation of images in latent space,2016,-2016
 Contextencoders: Feature learning by inpainting,2016, In Proceedings of the IEEE conference on computervision and pattern recognition
 Generating diverse structure for imageinpainting with hierarchical vq-vae,2021, arXiv preprint arXiv:2103
 Likelihood ratios for out-of-distribution detection,2019, arXiv preprintarXiv:1906
 Shepard convolutional neural networks,2015, InProceedings of the 28th International Conference on Neural Information Processing Systems-Volume 1
 Stochastic backpropagation and ap-proximate inference in deep generative models,2014, In International conference on machine learning
 Painting outside the box: Image outpainting with gans,2018, arXiv preprintarXiv:1808
 Improved techniques for training gans,2016, In Advances in Neural Information ProcessingSystems 29
 Learning structured output representation usingdeep conditional generative models,2015, Advances in neural information processing systems
 Laddervariational autoencoders,2016, arXiv preprint arXiv:1602
 Score-based generative modeling through stochastic differential equations,2020, arXiv preprintarXiv:2011
 SPg-net: Segmen-tation Prediction and guidance network for image inPainting,2018, arXiv preprint arXiv:1805
 Nvae: A deeP hierarchical variational autoencoder,2020, arXiv preprintarXiv:2007
 High-fidelity Pluralistic image comPletionwith transformers,2021, arXiv preprint arXiv:2103
 Chestx-ray8: HosPital-scale chest x-ray database and benchmarks on weakly-suPervisedclassification and localization of common thorax diseases,2017, In Proceedings of the IEEE conferenceon computer vision and pattern recognition
 Transformers: State-of-the-artnatural language Processing,2020, In Proceedings of the 2020 Conference on Empirical Methods inNatural Language Processing: System Demonstrations
 Conditional inference in Pre-trained variational autoen-coders via cross-coding,2018, arXiv preprint arXiv:1805
 Likelihood regret: An out-of-distribution detection scorefor variational auto-encoder,2020, arXiv preprint arXiv:2003
 Semantic image inPainting with deeP generative models,2017, In Proceedings of the IEEEconference on computer vision and pattern recognition
 Generative imageinPainting with contextual attention,2018, In Proceedings of the IEEE conference on computer visionand pattern recognition
 Free-form imageinPainting with gated convolution,2019, In Proceedings of the IEEE/CVF International Conference onComputer Vision
 The unreasonableeffectiveness of deeP features as a PercePtual metric,2018, In Proceedings of the IEEE conference oncomputer vision and pattern recognition
 Pluralistic image completion,2019, In Proceedings ofthe IEEE/CVF Conference on Computer Vision and Pattern Recognition
 Tfill: Image completion via a transformer-basedarchitecture,2021, arXiv preprint arXiv:2104
 Toward multimodal image-to-image translation,2017, arXiv preprint arXiv:1711
