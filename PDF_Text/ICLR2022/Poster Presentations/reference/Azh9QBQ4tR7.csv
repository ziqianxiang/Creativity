title,year,conference
 Square at-tack: a query-efficient black-box adversarial attack via random search,2020, In Proceedings of theEuropean Conference on Computer Vision
 Obfuscated gradients give a false sense of se-curity: Circumventing defenses to adversarial examples,2018, In Proceedings of the 35th InternationalConference on Machine Learning
 Towards evaluating the robustness of neural networks,2017, In 2017IEEE Symposium on Security and Privacy (SP)
 Unlabeleddata improves adversarial robustness,2019, In Advances in Neural Information Processing Systems
 Robust overfittingmay be mitigated by properly learned smoothening,2021, In International Conference on LearningRepresentations
 Dawnbench: An end-to-end deep learningbenchmark and competition,2017, In NIPS ML Systems Workshop
 Reliable evaluation of adversarial robustness with an ensem-ble of diverse parameter-free attacks,2020, In Proceedings of the 37th International Conference onMachine Learning
 Robustbench: a standardized adversarial robustness bench-mark,2020, arXiv preprint arXiv:2010
 Imagenet: A large-scale hier-archical image database,2009, In 2009 IEEE Conference on Computer Vision and Pattern Recognition
 Explaining and harnessing adversarialexamples,2015, In International Conference on Learning Representations
 Uncoveringthe limits of adversarial training against norm-bounded adversarial examples,2021, arXiv preprintarXiv:2010
 Deep residual learning for image recognition,2016, In 2016 IEEEConference on Computer Vision and Pattern Recognition
 Identity mappings in deep residualnetworks,2016, In Proceedings of the European Conference on Computer Vision
 Benchmarking neural network robustness to common cor-ruptions and perturbations,2019, In International Conference on Learning Representations
 Using pre-training can improve model robustnessand uncertainty,2019, In Proceedings of the 36th International Conference on Machine Learning
 Distilling the knowledge in a neural network,2015, InNIPS Deep Learning and Representation Learning Workshop
 Denoising diffusion probabilistic models,2020, In Advancesin Neural Information Processing Systems
 Adversarial logit pairing,2018, arXiv preprintarXiv:1803
 Perceptual adversarial robustness: Defense againstunseen threat models,2021, In International Conference on Learning Representations
 Deepfool: a simple andaccurate method to fool deep neural networks,2016, In Proceedings of the IEEE Conference on Com-puter Vision and Pattern Recognition
 Readingdigits in natural images with unsupervised feature learning,2011, In NIPS Workshop on Deep Learningand Unsupervised Feature Learning
 Holdme tight! influence of discriminative features on deep network boundaries,2020, In Advances in NeuralInformation Processing Systems
 Bag of tricks for adversarialtraining,2021, In International Conference on Learning Representations
 Distillation as adefense to adversarial perturbations against deep neural networks,2016, In 2016 IEEE Symposium onSecurity and Privacy (SP)
 Fixing data augmentation to improve adversarial robustness,2021, arXiv preprintarXiv:2103
 Overfitting in adversarially robust deep learning,2020, InProceedings of the 37th International Conference on Machine Learning
 Adver-sarially robust generalization requires more data,2018, In Advances in Neural Information ProcessingSystems
 Towards deep learning mod-els resistant to large perturbations,2020, arXiv preprint arXiv:2003
 Super-convergence: Very fast training of residual networksusing large learning rates,2018, arXiv
 Intriguing properties of neural networks,2014, In International Conference onLearning Representations
 80 million tiny images: A large data set fornonparametric object and scene recognition,2008, IEEE Transactions on Pattern Analysis and MachineIntelligence
 On adaptive attacks toadversarial example defenses,2020, In Advances in Neural Information Processing Systems
 Ensemble adversarial training: Attacks and defenses,2018, In International Conference onLearning Representations
 On theconvergence and robustness of adversarial training,2019, In Proceedings of the 36th InternationalConference on Machine Learning
 Improvingadversarial robustness requires revisiting misclassified examples,2020, In International Conference onLearning Representations
 Adversarial weight perturbation helps robust gener-alization,2020, In Advances in Neural Information Processing Systems
 Enhancing adversarial defense by k-winners-take-all,2020, In International Conference on Learning Representations
 A closer look at accuracy vs,2020, robustness
 Wide residual networks,2016, In Proceedings of the BritishMachine Vision Conference
 Attacks which do not kill training make adversarial learning stronger,2020, In Proceedings of the37th International Conference on Machine Learning
