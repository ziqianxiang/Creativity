title,year,conference
 The effects of adding noise during backpropagation training on a generalizationperformance,1996, Neural Computation
 Training with noise is equivalent to Tikhonov regularization,1995, Neural Computation
 Explicitregularisation in Gaussian noise injections,2020, arXiv preprint arXiv:2007
 On mixup regulariza-tion,2020, arXiv preprint arXiv:2006
 Probabilistic robustness estimates for feed-forward neural networks,2021, NeuralNetworks
 Training invariant support vector machines,2002, MachineLearning
 Imagenet: A large-scale hier-archical image database,2009, In 2009 IEEE Conference on Computer Vision and Pattern Recognition
 The total variation distance between high-dimensional Gaussians,2018, arXiv preprint arXiv:1810
 The algorithmic foundations of differential privacy,2014, Found
 Largemargin deep networks for classification,2018, arXiv preprint arXiv:1803
 Adversarial robustness as a prior for learned representations,2020, ArXiv preprintarXiv:1906
 Robustness of classifiers:from adversarial to random noise,2016, arXiv preprint arXiv:1608
 On choosing and bounding probability metrics,2002, InternationalStatistical Review
 Maxup: A simple way to improvegeneralization of neural network training,2020, arXiv preprint arXiv:2002
 Making machine learning robust againstadversarial inputs,2018, Communications of the ACM
 Explaining and harnessing adversarialexamples,2014, arXiv preprint arXiv:1412
 k-mixupregularization for deep learning via optimal transport,2021, arXiv preprint arXiv:2106
 Identity mappings in deep residualnetworks,2016, In European Conference on Computer Vision
 Formal guarantees on the robustness of a classifieragainst adversarial manipulation,2017, arXiv preprint arXiv:1705
 Benchmarking neural network robustness to common corrup-tions and perturbations,2019, Proceedings of the International Conference on Learning Representations
 Robust learning with Jacobian regularization,2019, arXivpreprint arXiv:1908
 Puzzle mix: Exploiting saliency and localstatistics for optimal mixup,5275, In International Conference on Machine Learning
 Puzzle mix: Exploiting saliency and localstatistics for optimal mixup,2020, In International Conference on Machine Learning
 Mixup training as the complexity reduction,2020, arXiv preprint arXiv:2006
 Learning multiple layers of features from tiny images,2009, Technical Report
 Imagenet classification with deep convo-lutional neural networks,2012, Advances in Neural Information Processing Systems
 Principled learningmethod for Wasserstein distributionally robust optimization with local perturbations,2020, In Interna-tional Conference on Machine Learning
 Interpolated adversarial training:Achieving robust neural networks without sacrificing too much accuracy,2019, In Proceedings of the12th ACM Workshop on Artificial Intelligence and Security
 Certifiedrobustness to adversarial examples with differential privacy,2019, In 2019 IEEE Symposium on Securityand Privacy (SP)
 Noisy recurrentneural networks,2021, arXiv preprint arXiv:2102
 Implementing regularization implicitly via approximate eigenvectorcomputation,2011, In International Conference on Machine Learning
 Sensitivity and generalization in neural networks: an empirical study,2018, arXiv preprintarXiv:1802
 Vision transformers are robust learners,2021, arXiv preprintarXiv:2105
 A unified view on differentialprivacy and robustness to adversarial examples,2019, arXiv preprint arXiv:1906
 On the robustness of randomized classifiers to adversarial examples,2021, arXiv preprintarXiv:2102
 Understandingand mitigating the tradeoff between robustness and accuracy,2020, arXiv preprint arXiv:2002
 Distributionally robust optimization: A review,2019, arXivpreprint arXiv:1908
 Fixing data augmentation to improve adversarial robustness,2021, arXiv preprintarXiv:2103
 Overfitting in adversarially robust deep learning,2020, InInternational Conference on Machine Learning
 Adver-sarially robust generalization requires more data,2018, arXiv preprint arXiv:1804
 On the adversarial robustnessof visual transformers,2021, arXiv preprint arXiv:2103
 Robust large margin deepneural networks,2017, IEEE Transactions on Signal Processing
 Distributionally robust deep learning as a generalization ofadversarial training,2017, In NIPS workshop on Machine Learning and Computer Security
 The Nature of Statistical Learning Theory,2013, Springer Science & Business Media
 Manifold mixup: Better representations by interpolating hidden states,2019, InInternational Conference on Machine Learning
 Data-dependent sample complexity of deep neural networks via Lipschitzaugmentation,2019, arXiv preprint arXiv:1905
 Improved sample complexities for deep networks and robust classificationvia an all-layer margin,2019, arXiv preprint arXiv:1910
 On the generalization effects oflinear transformations in data augmentation,2020, In International Conference on Machine Learning
 A closer look at accuracy vs,2020, robustness
 BatchMixup: Improving training by interpo-lating hidden states of the entire mini-batch,2021, In Findings of the Association for ComputationalLinguistics: ACL-IJCNLP 2021
 Wide residual networks,2016, arXiv preprint arXiv:1605
 Mixup: Beyond empiricalrisk minimization,2017, arXiv preprint arXiv:1710
 When and how mixup improvescalibration,2021, arXiv preprint arXiv:2102
