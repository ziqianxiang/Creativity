title,year,conference
 Thompson sampling for contextual bandits with linear payoffs,2013, InInternational Conference on Machine Learning
 Gone fishing: Neural activelearning with fisher embeddings,2021, Neural Information Processing Systems
 Using confidence bounds for exploitation-exploration trade-offs,2002, Journal of MachineLearning Research
 Exponential polynomials,1934, Annals of Mathematics
 The power of ensemblesfor active learning in image classification,2018, In IEEE Conference on Computer Vision and PatternRecognition
 Exploration by random networkdistillation,2018, arXiv preprint arXiv:1810
 The elliptical potential lemmarevisited,2020, arXiv preprint arXiv:2010
 Convergence rates ofactive learning for maximum likelihood estimation,2015, arXiv preprint arXiv:1506
 Stochastic linear optimization under banditfeedback,2008, In Conference on Learning Theory
 An efficient algorithm for generalized linearbandit: Online stochastic gradient descent and thompson sampling,2021, In International Conferenceon Artificial Intelligence and Statistics
 Variational intrinsic control,2016, arXivpreprint arXiv:1611
 Efficient bayes-adaptive reinforcement learning usingsample-based search,2012, Advances in neural information processing systems
 Model-predictive policy learning with uncertaintyregularization for driving in dense traffic,2019, arXiv preprint arXiv:1901
 Randomized exploration for reinforcement learning with general value functionapproximation,2021, arXiv preprint arXiv:2106
 Scalable generalizedlinear bandits: Online computation and hashing,2017, arXiv preprint arXiv:1706
 Perturbed-history exploration in stochastic linear bandits,2019, arXiv preprint arXiv:1903
 Bandit algorithms,2020, Cambridge University Press
 A contextual-bandit approach topersonalized news article recommendation,2010, In Proceedings of the 19th international conference onWorld wide web
 Continuous control with deep reinforcement learning,2015, arXivpreprint arXiv:1509
 Count-based explorationin feature space for reinforcement learning,2017, arXiv preprint arXiv:1706
 Human-level controlthrough deep reinforcement learning,2015, nature
 Online limited memory neural-linear bandits withlikelihood matching,2021, arXiv preprint arXiv:2102
 Deep exploration viabootstrapped dqn,2016, arXiv preprint arXiv:1602
 Count-based exploration withneural density models,2017, In International conference on machine learning
 Intrinsic motivation systems for au-tonomous mental development,2007, IEEE transactions on evolutionary computation
 Curiosity-driven explorationby self-supervised prediction,2778, In International Conference on Machine Learning
 Linearly parameterized bandits,2010, Mathematics ofOperations Research
 Proximal policyoptimization algorithms,2017, arXiv preprint arXiv:1707
 Active learning for convolutional neural networks: A core-setapproach,2018, In International Conference on Learning Representations
 Introduction to multi-armed bandits,2019, arXiv preprint arXiv:1904
 Incentivizing exploration in reinforcementlearning with deep predictive models,2015, arXiv preprint arXiv:1507
 An analysis of model-based interval estimation formarkov decision processes,2008, Journal of Computer and System Sciences
 A bayesian framework for reinforcement learning,2000, In ICML
 On the likelihood that one unknown probability exceeds another in view ofthe evidence of two samples,1933, Biometrika
 Upper and lower tails of gaussian maxima,2017, https://stephentu
 Deep neural linear bandits: Overcoming catastrophic forgettingthrough likelihood matching,2019, arXiv preprint arXiv:1901
 Neural thompson sampling,2020, arXivpreprint arXiv:2010
