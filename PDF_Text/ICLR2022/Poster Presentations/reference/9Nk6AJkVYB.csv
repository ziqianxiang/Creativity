title,year,conference
 Deep speech 2:End-to-end speech recognition in english and mandarin,2016, In ICML
 Common Voice: A massively-multilingual speech corpus,2020, In Proceedings of The 12th Language Resources and EvaluationConference
 Convolutional recurrent neural networks for small-footprint keywordspotting,2017, In INTERSPEECH
 wav2vec 2,2020,0: A frameworkfor self-supervised learning of speech representations
 End-to-end attention-based large vocabulary speech recognition,2016, In ICASSP
 Parrotron: An end-to-endspeech-to-speech conversion model and its applications to hearing-impaired speech and speechseparation,2019, In INTERSPEECH
 Efficient conformer: Progressive downsampling and groupedattention for automatic speech recognition,2021, arXiv preprint arXiv:2109
 The lottery tickets hypothesis for supervised and self-supervised pre-training incomputer vision models,2020, arXiv preprint arXiv:2012
 The lottery ticket hypothesis for pre-trained BERT networks,2020, In NeurIPS
 A unified lotteryticket hypothesis for graph neural networks,2021, arXiv preprint arXiv:2102
 Long live the lottery:The existence of winning tickets in lifelong learning,2021, In ICLR
 Coarsening thegranularity: Towards structurally sparse lottery tickets,2022, arXiv preprint arXiv:2202
 Sparsity winning twice: Better robust generalization from more efficienttraining,2022, In International Conference on Learning Representations
 Earlybert:Efficient bert training via early-bird lottery tickets,2020, arXiv preprint arXiv:2101
 You are caught stealing mywinning lottery ticket! making a lottery ticket claim its ownership,2021, Advances in Neural InformationProcessing Systems
 GANs can play lottery tickets too,2021, InICLR
 State-of-the-art speechrecognition with SeqUence-to-sequence models,2018, In ICASSP
 Adaptive speaker normalization forctc-based speech recognition,2020, In INTERSPEECH
 Speech-transformer: a no-recurrence sequence-to-sequencemodel for speech recognition,2018, In 2018 IEEE International Conference on Acoustics
 Extending recurrent neural aligner for streamingend-to-end speech recognition in Mandarin,2018, In INTERSPEECH
 The difficulty of training sparse neuralnetworks,2019, arXiv preprint arXiv:1906
 From speech to letters-using anovel neural network architecture for grapheme based ASR,2009, In 2009 IEEE Workshop on AutomaticSpeech Recognition & Understanding
 Linear modeconnectivity and the lottery ticket hypothesis,2020, In ICML
 Linear modeconnectivity and the lottery ticket hypothesis,2020, In ICML
 The state of sparsity in deep neural networks,2019, arXivpreprint arXiv:1902
 Rethinking pruningfor accelerating deep inference at the edge,2020, In SIGKDD
 Maximum a posteriori estimation for multivariate gaussian mixtureobservations of markov chains,1994, IEEE transactions on speech and audio processing
 Sequence transduction with recurrent neural networks,2012, arXiv preprint arXiv:1211
 Towards end-to-end speech recognition with recurrent neuralnetworks,2014, In ICML 
 Speech recognition with deep recurrentneural networks,2013, In ICASSP
 Gpu kernels for block-sparse weights,2017, arXivpreprint arXiv:1711
 Modelcompression with adversarial robustness: A unified optimization framework,2019, arXiv preprintarXiv:1902
 Conformer: Convolution-augmented transformer forspeech recognition,2020, arXiv preprint arXiv:2005
 Speech processing for digital home assistants:Combining signal processing with deep-learning techniques,2019, IEEE Signal processing magazine
 Deep speech: Scaling up end-to-endspeech recognition,2014, arXiv preprint arXiv:1412
 Streaming end-to-end speech recogni-tion for mobile devices,2019, In ICASSP
 Application of pretraineddeep neural networks to large vocabulary speech recognition,2012, In INTERSPEECH
 Direct speech-to-speech translation with a sequence-to-sequence model,2019, In INTERSPEECH
 Winning lottery tickets in deep generativemodels,2020, arXiv preprint arXiv:2010
 Attention based on-devicestreaming speech recognition with large speech corpus,2019, In ASRU
 The reverbchallenge: A common evaluation framework for dereverberation and recognition of reverberantspeech,2013, In 2013 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics
 Improving noise robustautomatic speech recognition with single-channel time-domain enhancement network,2020, In ICASSP
 Tracenorm regularization and faster inference for embedded speech recognition RNNs,2017, arXiv preprintarXiv:1710
 Sentencepiece: A simple and language independent subwordtokenizer and detokenizer for neural text processing,2018, In EMNLP (Demonstration)
 Maximum likelihood linear regression for speakeradaptation of continuous density hidden markov models,1995, Computer speech & language
 Compression of acoustic model viaknowledge distillation and pruning,2018, In ICPR
 An overview of noise-robust automaticspeech recognition,2014, IEEE/ACM Transactions on Audio
 Speaker adaptation for end-to-end CTCmodels,2018, In SLT
 Mutual-learning sequence-level knowledgedistillation for automatic speech recognition,2021, Neurocomputing
 Speaker adaptation of context dependent deep neural networks,2013, In ICASSP
 Towards understanding thetransferability of deep representations,2019, arXiv preprint arXiv:1909
 Rethinking the value ofnetwork pruning,2019, In ICLR
 Goodstudents play big lottery better,2021, arXiv preprint arXiv:2101
 Personalizedspeech recognition on mobile devices,2016, In ICASSP
 Sparse transfer learning via winning lottery tickets,2019, arXiv preprint arXiv:1905
 Speaker adaptation for attention-basedend-to-end speech recognition,2019, In INTERSPEECH
 EESEN: End-to-end speech recognitionusing deep RNN models and WFST-based decoding,2015, In ASRU
 One ticket to win them all:Generalizing lottery ticket initializations across datasets and optimizers,2019, In NeurIPS
 Exploring sparsity in recurrentneural networks,2017, arXiv preprint arXiv:1704
 Librispeech: An ASRcorpus based on public domain audio books,2015, In ICASSP
 Fully neural networkbased speech recognition on mobile and embedded devices,2018, In NeurIPS
 Minimum word error rate training for attention-based sequence-to-sequencemodels,2018, In ICASSP
 Comparing rewinding and fine-tuning in neuralnetwork pruning,2020, In ICLR
 TED-LIUM: an automatic speech recognitiondedicated corpus,2012, In LREC
 A streaming on-device end-to-end modelsurpassing server-side conventional model quality and latency,2020, In ICASSP
 ¡°Your word is my command¡±: Google search by voice: Acase study,2010, In Advances in speech recognition
 Sound event detection in syntheticdomestic environments,2020, In ICASSP
 Optimizing speechrecognition for the edge,2019, arXiv preprint arXiv:1909
 Natural TTS synthesis by conditioningWavenet on Mel spectrogram predictions,2018, In ICASSP
 An investigation into on-device personalizationof end-to-end automatic speech recognition models,2019, In INTERSPEECH
 An investigation of a knowledge distillationmethod for ctc acoustic models,2018, In 2018 IEEE International Conference on Acoustics
 Node pruning based on entropy ofweights and node activity for small-footprint acoustic model based on deep neural networks,2017, InINTERSPEECH
 Attention is all you need,2017, In Advances in neural informationprocessing systems
 Speechalator: Two-wayspeech-to-speech translation on a consumer PDA,2003, In Eighth European Conference on SpeechCommunication and Technology
 Picking winning tickets before training bypreserving gradient flow,2020, In ICLR
 An overview of end-to-end automatic speech recogni-tion,2019, Symmetry
 Transformer-basedacoustic modeling for hybrid speech recognition,2020, In ICASSP 2020-2020 IEEE InternationalConference on Acoustics
 Tacotron: Towards end-to-end speechsynthesis,2017, In INTERSPEECH
 Learning intrinsic sparse structures within long short-term memory,2018, In ICLR
 Speaker adaptation for continUoUs density hmms: A revieW,2001, In ISCA Tutorial andResearch Workshop (ITRW) on Adaptation Methods for Speech Recognition
 Dynamic sparsityneUral netWorks for aUtomatic speech recognition,2021, In ICASSP 2021-2021 IEEE InternationalConference on Acoustics
 Adversarial robUstness vs,2019, model compression
 TUtornet: ToWardsflexible knoWledge distillation for end-to-end speech recognition,2021, IEEE/ACM Transactions onAudio
 DraWing early-bird tickets: ToWard more efficient training ofdeep netWorks,2020, In ICLR
 Playing the lottery With reWards andmUltiple langUages: Lottery tickets in RL and NLP,2020, In ICLR
 One-shot prUning of recUrrent neUral netWorks by jacobianspectrUm evalUation,2019, In ICLR
 Very deep convolUtional netWorks for end-to-endspeech recognition,2017, In ICASSP
 Foreign accent conversion by synthe-sizing speech from phonetic posteriorgrams,2019, In INTERSPEECH
