title,year,conference
 Deep variational informationbottleneck,2016, arXiv preprint arXiv:1612
 Variationalimage compression with a scale hyperprior,2018, arXiv preprint arXiv:1802
 Objectnet: A large-scale bias-controlled dataset for pushingthe limits of object recognition models,2019, 2019
 Recognition in terra incognita,2018, In Proceedings of theEuropean conference on computer vision (ECCV)
 Analysis of representationsfor domain adaptation,2007, Advances in neural information processing systems
 A theory of learning from different domains,2010, Machine Learning
 Large-scale machine learning with stochastic gradient descent,2010, In Proceedings ofCOMPSTATâ€™2010
 Emerging properties in self-supervised vision transformers,2021, arXiv preprintarXiv:2104
 Learning optimal repre-sentations with the decodable information bottleneck,2020, In H
 Lossy compression forlossless prediction,2021, arXiv preprint arXiv:2106
 Unbiased metric learning: On the utilization of multipledatasets and web images for softening bias,2013, In Proceedings of the IEEE International Conferenceon Computer Vision
 In search of lost domain generalization,2021, In InternationalConference on Learning Representations
 Deep residual learning for imagerecognition,2016, In Proceedings of the IEEE conference on computer vision and pattern recognition
 The many faces of robustness: A criticalanalysis of out-of-distribution generalization,2020, arXiv preprint arXiv:2006
 Natural adver-sarial examples,2021, In Proceedings of the IEEE/CVF Conference on Computer Vision and PatternRecognition
 Support and invertibility in domain-invariant representations,2019, In The 22nd International Conference on Artificial Intelligence andStatistics
 Supervised contrastive learning,2020, arXiv preprintarXiv:2004
 Adam: A method for stochastic optimization,2014, arXiv preprintarXiv:1412
 Invariant information bottleneck for domain generalization,2021, arXiv preprintarXiv:2106
 Domain generalization with adver-sarial feature learning,2018, In Proceedings of the IEEE Conference on Computer Vision and PatternRecognition
 Learning transferable features withdeep adaptation networks,2015, In International conference on machine learning
 Deep transfer learning with jointadaptation networks,2017, In International conference on machine learning
 Domain adaptation: Learning boundsand algorithms,2009, arXiv preprint arXiv:0902
 Kl guided domainadaptation,2021, arXiv preprint arXiv:2106
 Representation learning with contrastive predictivecoding,2018, arXiv preprint arXiv:1807
 Moment matchingfor multi-source domain adaptation,2019, In Proceedings of the IEEE/CVF International Conference onComputer Vision
 On variationalbounds of mutual information,5171, In International Conference on Machine Learning
 Laion-400m: Open dataset ofclip-filtered 400 million image-text pairs,2021, arXiv preprint arXiv:2111
 Learning and generalization with the informationbottleneck,2010, Theor
 Wasserstein distance guided representationlearning for domain adaptation,2018, In Thirty-Second AAAI Conference on Artificial Intelligence
 Deep coral: Correlation alignment for deep domain adaptation,2016, InEuropean conference on computer vision
 Domain adaptationwith conditional distribution matching and generalized label shift,2020, Advances in Neural InformationProcessing Systems
 Measuring robustness to natural distribution shifts in image classification,2020, arXivpreprint arXiv:2007
 The information bottleneck method,2000, arXivpreprint physics/0004057
 Deephashing network for unsupervised domain adaptation,2017, In Proceedings of the IEEE conference oncomputer vision and pattern recognition
 Learning robust global representa-tions by penalizing local predictive power,2019, arXiv preprint arXiv:1905
 Multi-modal self-supervised learning of general audio representations,2021, arXiv preprint arXiv:2104
 Minimum excess risk in bayesian learning,2020, arXiv preprintarXiv:2012
 Improve unsupervised domainadaptation with mixup training,2020, arXiv preprint arXiv:2001
