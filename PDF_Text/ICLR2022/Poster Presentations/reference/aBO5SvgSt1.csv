title,year,conference
 Dynamic policy programming,2012, Journal of MachineLearning Research
 First-order methods in optimization,2017, SIAM
 Mirror descent and nonlinear projected subgradient methods forconvex optimization,2003, Operations Research Letters
 The arcade learningenvironment: An evaluation platform for general agents,2013, Journal of Artificial IntelligenceResearch
 Im-plementation matters in deep RL: A case study on PPO and TRPO,2020, In Proceeding of the 8thInternational Conference on Learning Representations
 Addressing function approximation error in actor-criticmethods,2018, In International Conference on Machine Learning
 A theory of regularized Markov decision processes,2019, InProceedings of the 36th International Conference on Machine Learning
 Soft actor-critic: Off-policy maximum entropydeep reinforcement learning with a stochastic actor,2018, In Proceedings of the 35th InternationalConference on Machine Learning
 Introduction to online convex optimization,2019, arXiv preprint arXiv:1909
 Approximately optimal approximate reinforcement learning,2002, InProceedings of the 19th International Conference on Machine Learning
 Path integrals and symmetry breaking for optimal control theory,2005, Journal ofStatistical Mechanics
 Sparse Markov decision processes with causal sparse Tsallis entropyregularization for reinforcement learning,2018, Robotics and Automation Letters
 Tsallis reinforcement learning: A unified frameworkfor maximum entropy reinforcement learning,2019, Preprint arXiv:1902
 On principled entropy explorationin policy optimization,2019, In Proceedings of the 28th Joint Conference on Artificial Intelligence
 Trust-PCL: An off-policy trust regionmethod for continuous control,2017, Preprint arXiv:1707
 Bridging the gap between value and policybased reinforcement learning,2017, In Proceedings of the 31st Conference on Neural InformationProcessing Systems
 Path consistency learning in Tsallis entropyregularized mdps,2018, In Proceedings of the 35th International Conference on Machine Learning
 A unified view of entropy-regularized markov decisionprocesses,2017, Preprint arXiv:1705
 High-dimensional continuouscontrol using generalized advantage estimation,2015, Preprint arXiv:1506
 Proximal policy optimizationalgorithms,2017, Preprint arXiv:1707
 Adaptive trust region policy optimization: Global conver-gence and faster rates for regularized MDPs,2020, In Proceedings of the 33rd AAAI Conference onArtificial Intelligence
 Linearly-solvable Markov decision problems,2006, In Proceedings of the 19th Advancesin Neural Information Processing
 Truly proximal policy optimization,2019, In Proceeding of the 35thConference on Uncertainty in Artificial Intelligence
