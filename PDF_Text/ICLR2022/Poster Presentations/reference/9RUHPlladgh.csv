title,year,conference
 Learning representations andgenerative models for 3d point clouds,2018, In International conference on machine learning
 Invariant risk minimization,2019, arXivpreprint arXiv:1907
 Objectnet: A large-scale bias-controlled dataset for pushing the limits of object recognitionmodels,2019, In Advances in Neural Information Processing Systems
 Controlling selection bias in causal inference,2012, In Artificial Intelligence andStatistics
 Causal inference and the data-fusion problem,2016, Proceedings of the NationalAcademy of Sciences
 Measuring abstract reasoning inneural networks,2018, In International conference on machine learning
 Simulation as an engine of physical sceneunderstanding,2013, Proceedings of the National Academy of Sciences
 A theory of independent mechanisms for extrapolation ingenerative models,2021, In 35th AAAI Conference on Artificial Intelligence: A Virtual Conference
 Understanding disentangling in Î²-VAE,2018, arXiv preprint arXiv:1804
 Group equivariant convolutional networks,2016, In International conference onmachine learning
 Gauge equivariant convolutional networksand the icosahedral cnn,2019, In International Conference on Machine Learning
 Are neural nets modular? inspecting func-tional modularity through differentiable weight masks,2021, In International Conference on Learning Represen-tations
 Underspecification presents challengesfor credibility in modern machine learning,2020, arXiv preprint arXiv:2011
 How We Learn: Why Brains Learn Better Than Any Machine,2020,
 Imagenet: A large-scale hierarchicalimage database,2009, In 2009 IEEE conference on computer vision and pattern recognition
 A framework for the quantitative evaluation of disentangledrepresentations,2018, In In International Conference on Learning Representations
 Diagvib-6: A diagnostic benchmark suite for vision models in the presence ofshortcut and generalization opportunities,2021, In Proceedings of the IEEE/CVF International Conference onComputer Vision
 A comparative studyof methods for measurement of energy of computing,2019, Energies
 Clusterability inneural networks,2021, arXiv preprint arXiv:2103
 Five points to checkwhen comparing visual perception in humans and machines,2021, Journal of Vision
 Shortcut learning in deep neural networks,2020, Nature Machine Intelligence
 On the transferof inductive bias from simulation to the real world: a new disentanglement dataset,2019, In Advances in NeuralInformation Processing Systems
 Inductive biases for deep learning of higher-level cognition,2020, arXiv preprintarXiv:2011
 On the binding problem in artificial neuralnetworks,2020, arXiv preprint arXiv:2012
 Deep residual learning for image recognition,2016, InProceedings of the IEEE conference on computer vision and pattern recognition
 Invariant causal prediction for nonlinear mod-els,2018, Journal of Causal Inference
 Benchmarking neural network robustness to common corruptions andperturbations,2019, Proceedings of the International Conference on Learning Representations
 Causal inference: What if,2020, Boca Raton: Chapman & Hall/CRC
 beta-VAE: Learning basic visual concepts with a constrained variationalframework,2017, In International Conference on Learning Representations
 Densely connected convolutionalnetworks,2017, In Proceedings of the IEEE conference on computer vision and pattern recognition
 Unsupervised feature extraction by time-contrastive learning and non-linear ica,2016, In Proceedings of the 30th International Conference on Neural Information Processing Systems
 Nonlinear ica of temporally dependent stationary sources,2017, In ArtificialIntelligence and Statistics
 Independent component analysis: algorithms and applications,2000, Neural net-works
 Nonlinear independent component analysis: Existence and uniquenessresults,1999, Neural networks
 In H,2019, Wallach
 On the" steerability" of generative adversarial networks,2019, arXivpreprint arXiv:1907
 Variational autoencoders andnonlinear ica: A unifying framework,2020, In International Conference on Artificial Intelligence and Statistics
 Generalization in anti-causal learning,2018, In NeurIPS2018 Workshop on Critiquing and Correcting Trends in Machine Learning
 Disentangling by factorising,2018, In International Conference on Machine Learn-ing
 Auto-encoding variational bayes,2013, arXiv preprint arXiv:1312
 Glow: Generative flow with invertible 1x1 convolutions,2018, In S
 Towards nonlinear disentanglement in natural data with temporal sparse coding,2020, arXiv preprintarXiv:2007
 Bias plus variance decomposition for zero-one loss functions,1996, In ICML
 Imagenet classification with deep convolutional neuralnetworks,2012, Advances in neural information processing systems
 Variational inference of disentangled latentconcepts from unlabeled observations,2018, In International Conference on Learning Representations
 Generalization without systematicity: On the compositional skills ofsequence-to-sequence recurrent networks,2018, In International Conference on Machine Learning
 Building machines thatlearn and think like people,2017, Behavioral and brain sciences
 Handwritten digit recognition with a back-propagation network,1989, In Proceedings of the2nd International Conference on Neural Information Processing Systems
 Deep learning,2015, nature
 In S,2018, Bengio
 Deep learning face attributes in the wild,2015, In Proceed-ings of International Conference on Computer Vision (ICCV)
 Challenging common assumptions in the unsupervised learning of disentangled repre-sentations,2018, arXiv preprint arXiv:1811
 Weakly-supervised disentanglement without compromises,2020, arXiv preprint arXiv:2002
 Object-centric learning with slot attention,2020, In Advancesin Neural Information Processing Systems
 Nonlinear invariant riskminimization: A causal approach,2021, arXiv preprint arXiv:2102
 Exploring the limits of weakly supervised pretraining,2018, InECCV
 Deep learning: A critical appraisal,2018, arXiv preprint arXiv:1801
 dsprites: Disentanglement testingsprites dataset,2017, https://github
 Benchmarking robustness in object detection: Autonomous drivingwhen winter is coming,2019, arXiv preprint 1907
 The roleof disentanglement in generalisation,2021, In International Conference on Learning Representations
 Mnist-c: A robustness benchmark for computer vision,2019, arXiv preprintarXiv:1906
 Assessing the suitability of the greenhouse gas protocol for calculation of emissions from publiccloud computing workloads,2020, Journal ofCloud Computing
 The finiteness theorem for invariants of finite groups,1915, In Mathematische Annalen
 Assessinggeneralization in deep reinforcement learning,2018, arXiv preprint arXiv:1810
 Transportability of causal and statistical relations: A formal approach,2011, InProceedings of the AAAI Conference on Artificial Intelligence
 Causal inference by using invariant prediction: identi-fication and confidence intervals,2016, Journal of the Royal Statistical Society
 Elements ofcausal inference: foundations and learn-ing algorithms,2017, The MIT Press
 Stochastic backpropagation and approximateinference in deep generative models,1278, In International conference on machine learning
 On linear identifiability of learned representations,2020, arXivpreprint arXiv:2007
 Invariant models for causaltransfer learning,2018, The Journal of Machine Learning Research
 Effects of degradations on deep neuralnetwork architectures,2018, arXiv preprint 1807
 ImageNet Large ScaleVisual Recognition Challenge,2015, International Journal of Computer Vision (IJCV)
 A simple neural network module for relational reasoning,2017, In I
 Deep learning in neural networks: An overview,2015, Neural networks
 Toward causal representation learning,2021, Proceedings of the IEEE
 Weakly supervised disentanglementwith guarantees,2019, In International Conference on Learning Representations
 Implicitneural representations with periodic activation functions,2020, arXiv preprint arXiv:2006
 A formal theory of inductive inference,1964, Information and Control
 Principles of object perception,1990, Cognitive science
 When training and test sets are different: characterizing learning transfer,2009, Dataset shift inmachine learning
 Purereasoning in 12-month-old infants as probabilistic inference,2011, Science
 On disentangled representations learned from correlated data,2020, arXivpreprint arXiv:2006
 The nature of statistical learning theory,1995, Springer International Publishing
 Necessary and sufficient conditions for the uniform convergenceof means to their expectations,1982, Theory of Probability & Its Applications
 Semi-generative modelling: Covariate-shift adaptationwith cause and effect features,2019, In The 22nd International Conference on Artificial Intelligence and Statistics
 The lack of a priori distinctions between learning algorithms,899, Neural Comput
 No free lunch theorems for optimization,1997, IEEE Transactions on Evolution-ary Computation
 Challenge of spatial cognition for deep learning,2019, CoRR
 Self-training with noisy student improves ima-genet classification,2020, In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recogni-tion
 A comparativeevaluation of approximate probabilistic simulation and deep neural networks as accounts of human physicalscene understanding,2016, CoRR
 Deep set prediction networks,2019, In H
