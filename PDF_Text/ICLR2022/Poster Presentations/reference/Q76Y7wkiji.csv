title,year,conference
 Sorting out lipschitz function approximation,2019, In Inter-national Conference on Machine Learning
 Obfuscated gradients give a false sense of se-curity: Circumventing defenses to adversarial examples,2018, In International conference on machinelearning
 Random smoothing might be unableto certify '¡Þ robustness for high-dimensional images,2020, arXiv preprint arXiv:2002
 Adversarial examples are not easily detected: Bypassing ten de-tection methods,2017, In Proceedings of the 10th ACM workshop on artificial intelligence and security
 Parsevalnetworks: Improving robustness to adversarial examples,2017, In International Conference on MachineLearning
 Certified adversarial robustness via randomizedsmoothing,2019, In International Conference on Machine Learning
 Reliable evaluation of adversarial robustness with an ensembleof diverse parameter-free attacks,2020, In International conference on machine learning
 Provable robustness of relu net-works via maximization of linear regions,2019, In the 22nd International Conference on ArtificialIntelligence and Statistics
 Enabling certification of verification-agnostic networks via memory-efficientsemidefinite programming,2020, In Advances in Neural Information Processing Systems
 Mma training: Directinput space margin maximization through adversarial training,2020, In International Conference onLearning Representations
 Adual approach to scalable verification of deep networks,2018, arXiv preprint arXiv:1803
 Efficient neural network verification with exactness characterization,2020, In Uncertaintyin Artificial Intelligence
 Generalizable adversarial training via spectral normal-ization,2019, In International Conference on Learning Representations
 Ai2: Safety and robustness certification of neural networks with abstract interpreta-tion,2018, In 2018 IEEE Symposium on Security and Privacy (SP)
 Explaining and harnessing adversarialexamples,2014, arXiv preprint arXiv:1412
 Regularisation of neural networksby enforcing lipschitz continuity,2018, arXiv preprint arXiv:1804
 On the effectiveness of intervalbound propagation for training verifiably robust models,2018, arXiv preprint arXiv:1810
 Boosting randomizedsmoothing with variance reduced classifiers,2022, In International Conference on Learning Represen-tations
 Limitations of the lipschitz constant as adefense against adversarial examples,2018, In Joint European Conference on Machine Learning andKnowledge Discovery in Databases
 Consistency regularization for certified robustness of smoothedclassifiers,2020, Advances in Neural Information Processing Systems
 Adam: A method for stochastic optimization,2015, In InternationalConference on Learning Representations
 Curse of dimensionality onrandomized smoothing for certifiable robustness,2020, In International Conference on Machine Learn-ing
 Adversarial machine learning at scale,2016, arXivpreprint arXiv:1611
 Certifiedrobustness to adversarial examples with differential privacy,2019, In 2019 IEEE Symposium on Securityand Privacy (SP)
 Lipschitz-certifiable training with a tight outerbound,2020, Advances in Neural Information Processing Systems
 Globally-robust neural networks,2021, In InternationalConference on Machine Learning (ICML)
 Certified adversarial robustness withadditive noise,2019, Advances in Neural Information Processing Systems
 Towardsevaluating and training verifiably robust neural networks,2021, In Proceedings of the IEEE/CVF Con-ference on Computer Vision and Pattern Recognition
 Differentiable abstract interpretation for prov-ably robust neural networks,3578, In International Conference on Machine Learning
 The fundamental limits of interval arith-metic for neural networks,2021, arXiv preprint arXiv:2112
 Training robustneural networks using lipschitz bounds,2021, IEEE Control Systems Letters
 L2-nonexpansive neural networks,2019, In International Conferenceon Learning Representations
 Certified defenses against adversarial exam-ples,2018, In International Conference on Learning Representations
 A convex relax-ation barrier to tight robustness verification of neural networks,2019, Advances in Neural InformationProcessing Systems
 Fast certified robusttraining with short warmup,2021, In ICML 2021 Workshop on Adversarial Machine Learning
 Skew orthogonal convolutions,2021, In International Conference on Ma-chine Learning
 Improved deterministic l2 robustness on CIFAR-10and CIFAR-100,2022, In International Conference on Learning Representations
 Intriguing properties of neural networks,2013, arXiv preprint arXiv:1312
 On adaptive attacks toadversarial example defenses,2020, Advances in Neural Information Processing Systems
 Lipschitz-margin training: Scalable certifi-cation of perturbation invariance for deep neural networks,2018, In Advances in neural informationprocessing systems
 Adversarial risk and thedangers of evaluating against weak attacks,2018, In International Conference on Machine Learning
 Efficient formal safetyanalysis of neural networks,2018, Advances in Neural Information Processing Systems
 Improvingadversarial robustness requires revisiting misclassified examples,2020, In International Conference onLearning Representations
 Towards fast computation of certified robustness for relu networks,2018, InInternational Conference on Machine Learning
 Provable defenses against adversarial examples via the convex outeradversarial polytope,2018, In International Conference on Machine Learning
 Scaling provable adversarialdefenses,2018, In Proceedings of the 32nd International Conference on Neural Information ProcessingSystems
 Completing thepicture: Randomized smoothing suffers from the curse of dimensionality for a large family ofdistributions,3763, In International Conference on Artificial Intelligence and Statistics
 Training forfaster adversarial robustness verification via inducing relu stability,2019, In International Conferenceon Learning Representations
 Automatic perturbation analysis for scalable certifiedrobustness and beyond,2020, Advances in Neural Information Processing Systems
 Randomizedsmoothing of all shapes and sizes,2020, In International Conference on Machine Learning
 A closer look at accuracy vs,2020, robustness
 On the certified robust-ness for ensemble models and beyond,2022, In International Conference on Learning Representations
 Spectral norm regularization for improving the generalizabilityof deep learning,2017, arXiv preprint arXiv:1705
 Towards certifying l-infinity ro-bustness using neural networks with l-inf-dist neurons,2021, In International Conference on MachineLearning
 Black-box certificationwith randomized smoothing: A functional optimization based framework,2020, Advances in NeuralInformation Processing Systems
 Fixup initialization: Residual learning withoutnormalization,2019, In International Conference on Learning Representations
 Efficient neural net-work robustness certification with general activation functions,2018, Advances in Neural InformationProcessing Systems
 Towards stable and efficient training of verifiably robust neural networks,2020, InInternational Conference on Learning Representations
