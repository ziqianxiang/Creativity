title,year,conference
 Contrastivebehavioral similarity embeddings for generalization in reinforcement learning,2021, In InternationalConference on Learning Representations
 The option-critic architecture,2017, In Proceedings ofthe Thirty-First AAAI Conference on Artificial Intelligence
 Robustlocally-linear controllable embedding,2018, In AISTATS
 The option keyboard:Combining skills in reinforcement learning,2019, In H
 A distributional perspective on reinforcementlearning,2017, In Proceedings of the 34th International Conference on Machine Learning
 Scalable methods for computing state similarity in deterministic markovdecision processes,2020, In AAAI
 A simple frameworkfor contrastive learning of visual representations,2020, CoRR
 Deep reinforcementlearning in a handful of trials using probabilistic dynamics models,2018, In Proceedings of the 32ndInternational Conference on Neural Information Processing Systems
 Efficient model-based deep reinforcementlearning with variational state tabulation,2018, In Proceedings of the 35th International Confer-ence on Machine Learning
 Using relative novelty to identify useful temporal abstrac-tions in reinforcement learning,2004, In Proceedings of the Twenty-First International Conference onMachine Learning
 Identifying useful subgoals in reinforcementlearning by local graph partitioning,1595, In Proceedings of the 22nd International Conference onMachine Learning
 Linear bellman combination for controlof character animation,2009, ACM Trans
 Hierarchical relative en-tropy policy search,2016, Journal of Machine Learning Research
 Policy evaluation with temporal differences:A survey and comparison,2014, Journal of Machine Learning Research 
 Hierarchical reinforcement learning with the maxq value function decompo-sition,2000, J
 Learning actionable rep-resentations from visual observations,2018, In 2018 IEEE/RSJ International Conference on IntelligentRobots and Systems (IROS)
 Self-supervised visual planning withtemporal skip connections,2017, In Annual Conference on Robot Learning
 Search on the replay buffer:Bridging planning and reinforcement learning,2019, In Advances in Neural Information Process-ing Systems
 Deep visual foresight for planning robot motion,2017, In ICRA
 Stochastic neural networks for hierarchical re-inforcement learning,2017, In International Conference on Learning Representations
 Learning actionable representations withgoal conditioned policies,2019, In ICLR
 The theory of affordances,0069, In Perceiving
 Transfer and exploration via the information bottleneck,2019, InInternational Conference on Learning Representations
 Affordance as general value function: A ComPUta-tional model,2020, CoRR
 Shaping Belief States with Generative Environment Models for RL,2019, 2019
 Learning invariantfeature sPaces to transfer skills with reinforcement learning,2017, In 5th International Conference onLearning Representations
 Learning latent dynamics for planning from pixels,2018, arXiv preprint arXiv:1811
 Dream to control: Learningbehaviors by latent imagination,2020, In International Conference on Learning Representations
 Deep reinforcement learning with double q-learning,2016, In Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence
 Rainbow: Combining improve-ments in deep reinforcement learning,2018, Proceedings of the AAAI Conference on Artificial In-telligence
 Darla: Improving zero-shottransfer in reinforcement learning,2017, ArXiv
 Learning robot control - using control policies as abstractactions,1998, In In NIPSâ€™98 Workshop: Abstraction and Hierarchy in Reinforcement Learning
 Robot motion planning in learned latent spaces,2019, IEEE Robotics andAutomation Letters
 Reinforcement learning with unsupervised auxiliary tasks,2017, InInternational Conference on Learning Representations
 BC-z: Zero-shot task generalization with robotic imitation learning,2021, In 5thAnnual Conference on Robot Learning
 Mt-opt: Continuous multi-task robotic rein-forcement learning at scale,2021, CoRR
 Learnings options end-to-endfor continuous action tasks,2017, CoRR
 Bandit based monte-carlo planning,2006, In Machine Learning:ECML 2006
 Skill discovery in continuous reinforcement learning domainsusing skill chaining,2009, In Y
 Constructing symbolic represen-tations for high-level planning,2014, Proceedings of the AAAI Conference on Artificial Intelligence
 Hierarchical reinforcement learning using spatio-temporal abstractions and deep neuralnetworks,2016, 2016
 Hierar-chical deep reinforcement learning: Integrating temporal abstraction and intrinsic motivation,2016, InAdvances in Neural Information Processing Systems
 Autonomous reinforcement learning on rawvisual input data in a real world application,2012, The 2012 International Joint Conference on NeuralNetworks (IJCNN)
 CURL: Contrastive unsupervised representa-tions for reinforcement learning,2020, In International Conference on Machine Learning
 Stochastic latent actor-critic:Deep reinforcement learning with a latent variable model,2019, In Advances in Neural InformationProcessing Systems
 Continuous control with deep reinforcement learn-ing,2016, CoRR
 Automatic discovery of subgoals in reinforcement learningusing diverse density,2001, In Proceedings of the Eighteenth International Conference on MachineLearning
 Q-cut - dynamic discovery of sub-goals in rein-forcement learning,2002, In Machine Learning: ECML 2002
 Asynchronous methods for deep reinforcementlearning,2016, In ICML
 Visualreinforcement learning with imagined goals,2018, In Proceedings of the 32nd International Conferenceon Neural Information Processing Systems
 A survey of numerical methods for optimal control,2009, 2009
 Learning abstract options,2018, In Advances in Neu-ral Information Processing Systems
 Learning abstract op-tions,2018, In Advances in Neural Information Processing Systems
 Mo-bilenetv2: Inverted residuals and linear bottlenecks,2018, In Proceedings of the IEEE Conference onComputer Vision and Pattern Recognition (CVPR)
 Semi-parametric topological memoryfor navigation,2018, In International Conference on Learning Representations
 Universal value function approxima-tors,2015, In Proceedings of the 32nd International Conference on Machine Learning
 Facenet: A unified embedding for facerecognition and clustering,2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition(CVPR)
 Time-contrastive networks: Self-supervised learning from multi-view observation,2017, In 2017 IEEE Conference on Computer Visionand Pattern Recognition Workshops (CVPRW)
 Dynamics-awareunsupervised discovery of skills,2020, In International Conference on Learning Representations
 Loss is its own reward:Self-supervision for reinforcement learning,2016, CoRR
 Hierarchical reinforcement learning with movement primitives,2011, In2011 11th IEEE-RAS International Conference on Humanoid Robots
 Reinforcement Learning: An Introduction,2018, 2018
 Between MDPs and semi-MDPs:A framework for temporal abstraction in reinforcement learning,1999, Artificial Intelli-gence
 A deep hi-erarchical approach to lifelong learning in minecraft,2017, In Proceedings of the Thirty-First AAAIConference on Artificial Intelligence
 Motor primitive discovery,2012, In 2012 IEEE InternationalConference on Development and Learning and Epigenetic Robotics (ICDL)
 Natural option critic,2019, Proceedings of the AAAI Conference onArtificial Intelligence
 Compositionality of optimal control laws,2009, In Advances in Neural InformationProcessing Systems
 Representation learning with contrastive predic-tive coding,2018, CoRR
 Visualizing data using t-SNE,2008, Journalof Machine Learning Research
 Unsupervised control through non-parametric discriminative rewards,2018, CoRR
 Embed tocontrol: A locally linear latent dynamics model for control from raw images,2015, In Advances inNeural Information Processing Systems
 Model predictive path integralcontrol using covariance variable importance sampling,2015, CoRR
 Improv-ing sample efficiency in model-free reinforcement learning from images,2019, CoRR
 Learninginvariant representations for reinforcement learning without reconstruction,2021, In International Con-ference on Learning Representations
 Hierarchical reinforcement learning by discovering intrinsicoptions,2021, In International Conference on Learning Representations
 Modeling Purposeful Adaptive Behavior with the Principle of Maximum CausalEntropy,2010, PhD thesis
