title,year,conference
 Inductive biases for deep learning of higher-level cognition,2020, arXiv preprintarXiv:2011
 The need for biases in learning generalizations,1980,1980
 An overview of gradient descent optimization algorithms,2016, arXiv preprint arXiv:1609
 Sgdr: Stochastic gradient descent with warm restarts,2016, arXiv preprintarXiv:1608
 Unbiased look at dataset bias,2011, In CVPR 2011
 Do wide and deep networks learn the same things?uncovering how neural network representations vary with width and depth,2020, arXiv preprint arXiv:2010
 Towards understandinglearning representations: To what extent do different neural networks learn the same representation,2018, arXivpreprint arXiv:1810
 The origins and prevalence of texture bias inconvolutional neural networks,2019, arXiv preprint arXiv:1911
 The pitfalls ofsimplicity bias in neural networks,2020, arXiv preprint arXiv:2006
 Representational similarity analysis-connectingthe branches of systems neuroscience,2008, Frontiers in systems neuroscience
 Similarity of neural networkrepresentations revisited,2019, In International Conference on Machine Learning
 Individual differencesamong deep neural network models,2020, Nature communications
 Paradox in deep neural networks: Similar yet different while differentyet similar,2019, arXiv preprint arXiv:1903
 Beyond accuracy: quantifying trial-by-trial behaviourof CNNs and humans by measuring error consistency,2020, Advances in Neural Information Processing Systems
 On the surprising similarities between supervised and self-supervised models,2020, arXivpreprint arXiv:2010
 The space of transferableadversarial examples,2017, arXiv preprint arXiv:1704
 Model similarity mitigates testset overuse,2019, arXiv preprint arXiv:1905
 Are my deep learning systems fair? an empirical study of fixed-seed training,2021, Advancesin Neural Information Processing Systems
 Pervasive label errors in test sets destabilize machinelearning benchmarks,2021, arXiv preprint arXiv:2103
 From ImageNetto image classification: Contextualizing progress on benchmarks,2020, In International Conference on MachineLearning
 Towards fairer datasets: Filteringand balancing the distribution of the people subtree in the ImageNet hierarchy,2020, In Proceedings of the 2020Conference on Fairness
 Accelerating deep learning by focusingon the biggest losers,2019, arXiv preprint arXiv:1910
 Not all samples are created equal: Deep learning with importancesampling,2018, In International conference on machine learning
 Deep learning through the lens of exampledifficulty,2021, arXiv preprint arXiv:2106
 Deep learning on a data diet: Finding importantexamples early in training,2021, arXiv preprint arXiv:2107
 Let¡¯s agree to agree: Neural networks share classifica-tion order on real datasets,2020, In International Conference on Machine Learning
 An empirical study of example forgetting during deep neural network learning,2018, arXiv preprintarXiv:1812
 SGD on neural networks learns functions of increasing complexity,2019, Advances in Neural InformationProcessing Systems
 Partial success in closing the gap between human and machine vision,2021, InAdvances in Neural Information Processing Systems 34
 A simple framework for contrastivelearning of visual representations,2020, In International conference on machine learning
 Billion-scale semi-supervisedlearning for image classification,2019, arXiv preprint arXiv:1905
 An image is worth 16x16 words:Transformers for image recognition at scale,2020, arXiv preprint arXiv:2010
 Deep residual learning for image recognition,2016, InProceedings of the IEEE conference on computer vision and pattern recognition
5 mb model size,2016, arXiv preprintarXiv:1602
 Approximating cnns with bag-of-local-features models works surprisinglywell on imagenet,2019, arXiv preprint arXiv:1904
 Learning transferable visual models from natural languagesupervision,2021, arXiv preprint arXiv:2103
 Small is beautiful: In defense of the small-n design,2018, Psychonomic bulletin &review
 Intriguing properties of neural networks,2013, arXiv preprint arXiv:1312
 Transferability in machine learning: from phenomenato black-box attacks using adversarial samples,2016, arXiv preprint arXiv:1605
 Underspecification presents challengesfor credibility in modern machine learning,2020, arXiv preprint arXiv:2011
 Natural categories,1973, Cognitive Psychology
 Recognition-by-components: A theory of human image understanding,1987, Psychological Review
 Psychophysical support for a two-dimensional view interpolationtheory of object recognition,1992, Proceedings of the National Academy of Sciences
 The generic viewpoint assumption in a framework for visual perception,1994, Nature
 Speed of processing in the human visual system,1996, Nature
 Animal detection in natural scenes:Critical features revisited,2010, Journal of Vision
 On the importance of initialization andmomentum in deep learning,2013, In International conference on machine learning
 Determinism in deep learning,2019, GPU Technology Conference
 Thingsvision: a python toolbox for streamlining the extraction ofactivations from deep neural networks,2021, bioRxiv preprint bioRxiv:2021
 Learning multiple layers of features from tiny images,2009,2009
 Imagenet: A large-scale hierarchicalimage database,2009, In 2009 IEEE conference on computer vision and pattern recognition
 Whose vote should countmore: Optimal integration of labels from labelers of unknown expertise,2009, Advances in neural informationprocessing systems
 Human uncertaintymakes classification more robust,2019, In Proceedings of the IEEE/CVF International Conference on ComputerVision
 The disagreementdeconvolution: Bringing machine learning performance metrics in line with reality,2021, In Proceedings of the2021 CHI Conference on Human Factors in Computing Systems
