title,year,conference
 Scalable second orderoptimization for deep learning,2020, arXiv preprint arXiv:2002
 Layer normalization,2016, arXiv preprintarXiv:1607
 Distributed second-order optimization using kronecker-factored approximations,2017, In International Conference on Learning Representations
 Rezero is all you need: Fast convergence at large depth,2020, arXiv preprintarXiv:2003
 Characterizing signal propagation to close the per-formance gap in unnormalized resnets,2021, In International Conference on Learning Representations
 High-performance large-scaleimage recognition without normalization,2021, arXiv preprint arXiv:2102
 Language models arefew-shot learners,2020, arXiv preprint arXiv:2005
 Deep networks and the multiple manifold problem,2020, InInternational Conference on Learning Representations
 Kernel methods for deep learning,2009, Advances in Neural Informa-tion Processing Systems
 Toward deeper understanding of neural networks: Thepower of initialization and a dual view on expressivity,2016, Advances In Neural Information ProcessingSystems
 Batch normalization biases residual blocks towards the identity functionin deep networks,2020, Advances in Neural Information Processing Systems
 Imagenet: A large-scalehierarchical image database,2009, In 2009 IEEE conference on computer vision and pattern recognition
 Repvgg:Making vgg-style convnets great again,2021, In Proceedings of the IEEE/CVF Conference on ComputerVision and Pattern Recognition
 Avoiding pathologies in verydeep networks,2014, In Artificial Intelligence and Statistics
 Understanding the difficulty of training deep feedforward neuralnetworks,2010, In Proceedings of the thirteenth international conference on artificial intelligence andstatistics
 On the impact of the activation function ondeep neural networks training,2672, In International conference on machine learning
 Delving deep into rectifiers: Surpassinghuman-level performance on imagenet classification,2015, In Proceedings of the IEEE internationalconference on computer vision
 Deep residual learning for imagerecognition,2016, In Proceedings of the IEEE conference on computer vision and pattern recognition
 Identity mappings in deep residualnetworks,2016, In European conference on computer vision
 Nonlinear systems third edition,2008, 2008
 Self-normalizingneural networks,2017, Advances in neural information processing systems
 Imagenet classification with deep convolu-tional neural networks,2012, Advances in neural information processing systems
 Learning multiple layers of features from tiny images,2009, 2009
 Efficient backprop,1998, InNeural networks: Tricks of the trade
 SGDR: Stochastic gradient descent with warm restarts,2016, arXivpreprint arXiv:1608
 Bidirectional self-normalizing neuralnetworks,2020, arXiv preprint arXiv:2006
 Rectifier nonlinearities improve neural networkacoustic models,2013, In International Conference on Machine Learning
 Optimizing neural networks with kronecker-factored approximatecurvature,2015, In International conference on machine learning
 Rapid training of deep neural networks without skipconnections or normalization layers using deep kernel shaping,2021, arXiv preprint arXiv:2110
 Bayesian learning for neural networks,1996, Lecture notes in statistics
 Going deeper with neural networkswithout skip connections,2020, In 2020 IEEE International Conference on Image Processing (ICIP)
 Resurrecting the sigmoid in deeplearning through dynamical isometry: theory and practice,2017, In Proceedings of the 31st InternationalConference on Neural Information Processing Systems
 Exponentialexpressivity in deep neural networks through transient chaos,2016, Advances in neural informationprocessing systems
 An efficient method for finding the minimum of a function of several variableswithout calculating derivatives,1964, The Computer Journal
 Deep isometric learning forvisual recognition,2020, In International Conference on Machine Learning
 Exact solutions to the nonlinear dynamicsof learning in deep linear neural networks,2013, arXiv preprint arXiv:1312
 Deep informationpropagation,2017, In International Conference on Learning Representations
 Mastering the game of go withouthuman knowledge,2017, nature
 Highway networks,2015, arXiv preprintarXiv:1505
 Rethinkingthe inception architecture for computer vision,2016, In Proceedings of the IEEE conference on computervision and pattern recognition
 Residual networks behave like ensembles ofrelatively shallow networks,2016, Advances in neural information processing systems
 Disentangling trainability and generaliza-tion in deep neural networks,1046, In International Conference on Machine Learning
 Mean field residual networks: On the edge of chaos,2017, In Advancesin Neural Information Processing Systems
 Amean field theory of batch normalization,2019, ArXiv
 Large batch optimization for deeplearning: Training bert in 76 minutes,2019, arXiv preprint arXiv:1904
 Wide residual networks,2016, In British Machine VisionConference 2016
 Which algorithmic choices matter at which batch sizes? insightsfrom a noisy quadratic model,2019, Advances in neural information processing systems
 Fixup initialization: Residual learning withoutnormalization,2018, In International Conference on Learning Representations
