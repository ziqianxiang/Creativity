title,year,conference
 Obfuscated gradients give a falsesense of security: Circumventing defenses to adversarial examples,2018, In InternationalConference on Machine Learning
 Generating natural language adversarial examples,2018, CoRR
 Evasion attacks against machine learning attest time,2013, In Joint European conference on machine learning and knowledge discoveryin databases
 Reliable evaluation of adversarial robustness withan ensemble of diverse parameter-free attacks,2020, In Proceedings of the 37th InternationalConference on Machine Learning
 Certified adversarial robustnessvia randomized smoothing,2019, arXiv preprint arXiv:1902
 Adversarial examples are not easily detected:Bypassing ten detection methods,2017, In Proceedings of the 10th ACM Workshop onArtificial Intelligence and Security
 Towards evaluating the robustness of neuralnetworks,2017, In 2017 IEEE symposium on security and privacy
 Audio adversarial examples: Targeted attacks onspeech-to-text,2018, In 2018 IEEE Security and Privacy Workshops (SPW)
 Imagenet: Alarge-scale hierarchical image database,2009, In 2009 IEEE conference on computer visionand pattern recognition
 Detectingadversarial samples from artifacts,2017, arXiv preprint arXiv:1703
 Explaining and harnessingadversarial examples,2015, International Conference on Learning Representations
 Imbal-anced gradients: A new cause of overestimated adversarial robustness,2020, arXiv preprintarXiv:2006
 Ensemble classifiers for Steganalysisof digital media,2012, In IEEE Transactions on Information Forensics and Security
 Detection based defense against adversarial examples from thesteganalysis point of view,2019, In Proceedings of the IEEE/CVF Conference on ComputerVision and Pattern Recognition
 Magnet: a two-pronged defense against adversarialexamples,2017, In Proceedings of the 2017 ACM SIGSAC conference on computer andcommunications security
 On detectingadversarial perturbations,2017, arXiv preprint arXiv:1702
 Characterizing adver-sarial subspaces using local intrinsic dimensionality,2018, arXiv preprint arXiv:1801
 Towards deep learning models resistant to adversarial attacks,2017, InternationalConference on Learning Representations
 The odds are odd: A statistical testfor detecting adversarial examples,2019, In International Conference on Machine Learning
 Certified defenses againstadversarial examples,2018, arXiv preprint arXiv:1801
 Dla:Dense-layer-analysis for adversarial example detection,2020, In 2020 IEEE EuropeanSymposium on Security and Privacy (EuroS&P)
 DLA: dense-layer-analysis for adversarial example detection,2019, CoRR
 Intriguing properties of neural networks,2014, InInternational Conference on Learning Representations (ICLR)
 On adaptiveattacks to adversarial example defenses,2020, CoRR
 Detecting adversarial ex-amples from sensitivity inconsistency of spatial-transform domain,2021, arXiv preprintarXiv:2103
 Feature squeezing: Detecting adversarialexamples in deep neural networks,2017, arXiv preprint arXiv:1704
