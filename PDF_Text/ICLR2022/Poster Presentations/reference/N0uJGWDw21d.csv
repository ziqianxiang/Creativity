title,year,conference
 Compress: Self-supervisedlearning by compressing representations,2020, Advances in Neural Information Processing Systems
 Bigself-supervised models are strong semi-supervised learners,2020, Advances in Neural InformationProcessing Systems
 Improved baselines with momentumcontrastive learning,2020, arXiv preprint arXiv:2003
 Unsupervised representation transfer for small networks:I believe i can distill on-the-fly,2021, Advances in neural information processing systems
 Imagenet: A large-scalehierarchical image database,2009, In 2009 IEEE conference on computer vision and pattern recognition
 Witha little help from my friends: Nearest-neighbor contrastive learning of visual representations,2021, arXivpreprint arXiv:2104
 Seed:Self-supervised distillation for visual representation,2020, In International Conference on LearningRepresentations
 Disco: Remedy self-supervised learning on lightweight models with distilled contrastivelearning,2021, arXiv preprint arXiv:2104
 Bootstrapyour own latent: A new approach to self-supervised learning,2020, In Neural Information ProcessingSystems
 Deep residual learning for imagerecognition,2016, In Proceedings of the IEEE conference on computer vision and pattern recognition
 Mask r-cnn,2017, In Proceedings oftheIEEE international conference on computer vision
 Momentum contrast forunsupervised visual representation learning,2020, In Proceedings of the IEEE/CVF Conference onComputer Vision and Pattern Recognition
 Distilling the knowledge in a neural network,2015, arXivpreprint arXiv:1503
 Supervised contrastive learning,2020, Advances in NeuralInformation Processing Systems
 Unsupervised representation learning by predicting imagerotations,2018, In International Conference on Learning Representations (ICLR)
 Microsoft coco: Common objects in context,2014, In Europeanconference on computer vision
 Simreg:Regression as a simple yet effective tool for self-supervised knowledge distillation,2021, In BritishMachine Vision Conference (BMVC)
 Unsupervised learning of visual representations by solving jigsawpuzzles,2016, In European Conference on Computer Vision
 Relational knowledge distillation,2019, In Proceed-ings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition
 Contextencoders: Feature learning by inpainting,2016, In Proceedings of the IEEE conference on computervision and pattern recognition
 Faster r-cnn: Towards real-time objectdetection with region proposal networks,2015, Advances in neural information processing systems
 Fitnets: Hints for thin deep nets,2014, arXiv preprint arXiv:1412
 Contrastive representation distillation,2019, In Interna-tional Conference on Learning Representations
 Knowledge distillation meets self-supervision,2020, In European Conference on Computer Vision
 Seed theviews: Hierarchical semantic alignment for contrastive representation learning,2020, arXiv preprintarXiv:2012
 Paying more attention to attention: Improving the perfor-mance of convolutional neural networks via attention transfer,2016, arXiv preprint arXiv:1612
 Colorful image colorization,2016, In Europeanconference on computer vision
