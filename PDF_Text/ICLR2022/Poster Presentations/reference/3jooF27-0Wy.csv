title,year,conference
 An empirical evaluation of generic convolutional andrecurrent networks for sequence modeling,2018, arXiv preprint arXiv:1803
 Trellis networks for sequence modeling,2018, arXivpreprint arXiv:1810
 Antisymmetricrnn: A dynamical system viewon recurrent neural networks,2019, arXiv preprint arXiv:1902
 Parallelizing legendre memory unit training,2021, arXiv preprintarXiv:2102
 A downsampled variant of imagenet as analternative to the CIFAR datasets,2017, CoRR
 An analysis of single-layer networks in unsupervisedfeature learning,2011, In Proceedings of the fourteenth international conference on artificial intelligenceand statistics
 On the relationship between self-attention and convolutional layers,2019, arXiv preprint arXiv:1911
 Deformableconvolutional networks,2017, In Proceedings of the IEEE international conference on computer vision
 Complete discrete 2-d gabor transforms by neural networks for image analysis andcompression,1988, IEEE Transactions on Acoustics
 Lipschitz recurrent neural networks,2020, arXiv preprint arXiv:2006
 Generalizing convolutionalneural networks for equivariance to lie groups on arbitrary continuous data,2020, arXiv preprintarXiv:2002
 Hippo: Recurrent memory withoptimal polynomial projections,2020, arXiv preprint arXiv:2008
 Improving thegating mechanism of recurrent neural networks,2020, In International Conference on Machine Learning
 Deep residual learning for imagerecognition,2016, In ProCeedings of the IEEE ConferenCe on Computer vision and pattern reCognition
 Structuredreceptive fields in cnns,2016, In ProCeedings of the IEEE ConferenCe on Computer Vision and PatternReCognition
 Spinalnet: Deep neural network with gradual input,2020, arXivpreprint arXiv:2007
 Alias-free generative adversarial networks,2021, arXiv preprint arXiv:2106
 On translation invariance in cnns: Convolutional layerscan exploit absolute spatial location,2020, In ProCeedings of the IEEE/CVF ConferenCe on ComputerVision and Pattern ReCognition (CVPR)
 Neural controlled differential equationsfor irregular time series,2020, arXiv preprint arXiv:2005
 Adam: A method for stochastic optimization,2014, arXiv preprintarXiv:1412
 ImageNet Classification with DeepConvolutional Neural Networks,2012, In F
 A simple way to initialize recurrent networks ofrectified linear units,2015, arXiv preprint arXiv:1504
 MNIST handwritten digit database,2010,2010
 Gradient-based learning applied todocument recognition,1998, Proceedings of the IEEE
 Network in network,2013, arXiv preprint arXiv:1312
 Scale-covariant and scale-invariant gaussian derivative networks,2021, In Scale Spaceand Variational Methods in Computer Vision :
 Sgdr: Stochastic gradient descent with warm restarts,2016, arXivpreprint arXiv:1608
 Extended batch normalization,2020, arXivpreprint arXiv:2003
 Efficient-capsnet: Capsule networkwith self-attention routing,2021, arXiv preprint arXiv:2101
 Deepsdf:Learning continuous signed distance functions for shape representation,2019, In Proceedings of theIEEE Conference on Computer Vision and Pattern Recognition
 Large kernel matters-improvesemantic segmentation by global convolutional network,2017, In Proceedings of the IEEE conferenceon computer vision and pattern recognition
 Resolutionlearning in deep convolutional networks using scale-space theory,2021, arXiv preprint arXiv:2106
 Ckconv:Continuous kernel convolution for sequential data,2021, arXiv preprint arXiv:2102
 Unicornn: A recurrent model for learning very long timedependencies,2021, arXiv preprint arXiv:2103
 ImageNetLarge Scale Visual Recognition Challenge,2015, International Journal of Computer Vision (IJCV)
 Blurring the line between structure and learningto optimize and adapt receptive fields,2019, ArXiv
 From points to parts:3d object detection from point cloud with part-aware and part-aggregation network,2019, arXiv preprintarXiv:1907
 Dynamic edge-conditioned filters in convolutional neuralnetworks on graphs,2017, In Proceedings of the IEEE conference on computer vision and patternrecognition
 Very deep convolutional networks for large-scale imagerecognition,2014, arXiv preprint arXiv:1409
 Im-plicit neural representations with periodic activation functions,2020, Advances in Neural InformationProcessing Systems
 Going deeper with convolutions,2015, InProceedings of the IEEE conference on computer vision and pattern recognition
 Spatially-adaptive filter units for compactand efficient deep neural networks,2020, International Journal of Computer Vision
 Deep continuous networks,1032, In Marina Meilaand Tong Zhang (eds
 Fixing the train-test resolution discrepancy,2019, InNeurIPS
 Learning longer-term dependen-cies in rnns with auxiliary losses,2018, arXiv preprint arXiv:1803
 Impact of aliasing on generalization in deep convolutional networks,2021, arXiv preprintarXiv:2108
 Deep parametriccontinuous convolutional neural networks,2018, In Proceedings of the IEEE Conference on ComputerVision and Pattern Recognition
 Speech commands: A dataset for limited-vocabulary speech recognition,2018, arXiv preprintarXiv:1804
 Variational context-deformable convnetsfor indoor scene parsing,2020, In Proceedings of the IEEE/CVF Conference on Computer Vision andPattern Recognition (CVPR)
 Wide residual networks,2016, arXiv preprint arXiv:1605
 Making convolutional networks shift-invariant again,2019, In International conference onmachine learning
 Neural architecture search with reinforcement learning,2016, arXiv preprintarXiv:1611
