title,year,conference
 Markov decision problems and state-action frequencies,1991, SIAMjournal on control and optimization
 Solving pomdps using quadrat-ically constrained linear programs,2006, In Proceedings of the fifth international joint conference onAutonomous agents and multiagent systems
 Open problem: Ap-proximate planning of POMDPs in the class of memoryless policies,2016, In Conference on LearningTheory
 Policy Gradient in PartiallyObservable Environments: Approximation and Convergence,2018, arXiv:1810
 The Algebraic Degree of Geometric Optimization Problems,1988, Discrete & Compu-tational Geometry
 Different Bounds on the Different Betti Numbers of Semi-Algebraic Sets,2003, Discreteand Computational Geometry
 Algorithms in Real Algebraic Geometry: A Survey,2014, arXiv:1409
 Infinite-Horizon Policy-Gradient Estimation,2001, Journal ofArtificial Intelligence Research
 Reinforcement Learning in POMDP’s via Direct GradientAscent,2000, In ICML
 A Markovian decision process,1957, Journal of mathematics and mechanics
 Moduli spaces of morse functions for persistence,2020, Journalof Applied and Computational Topology
 Linear Programming for Decision Processes with Partial Infor-mation,2018, arXiv:1811
 Les problemes de decisions sequentielles,1960, Cahiers du Centre d’Etudes deRecherche Operationnelle
 Finite state Markovian decision processes,1970, Academic Press
 Counting connected components ofa semialgebraic set in subex-ponential time,1992, Computational Complexity
 Average Reward Optimization Objective In Partially ObservableDomains,2013, In International Conference on Machine Learning
 Linear matrix inequality representation of sets,2007, Communica-tions on Pure and Applied Mathematics: A Journal Issued by the Courant Institute of Mathemat-ical Sciences
 Linear Programming Methods for Solving Finite Markovian De-cision Problems ,1981, In DGOR
 Dynamic programming and Markov processes,1960, MIT Press
 Chapter 2 - generating functions,1983, In Jeffrey J
 Equality Set Projection: A new algorithm forthe projection of polytopes in halfspace representation,2004, Technical report
 Planning and acting inpartially observable stochastic domains,1998, Artificial intelligence
 Survey of linear programming for standard and nonstandard Markoviancontrol problems,1994, Part I: Theory
 Reinforcement learning in robotics: A survey,2013, TheInternational Journal of Robotics Research
 The computational complexity of algebraic numbers,1973, In Proceedings of the fifth annualACM symposium on Theory of computing
 Finding optimal memoryless policies of POMDPsunder the expected average reward criterion,2011, European Journal of Operational Research
 An optimization-based categorization of reinforcement learning environ-ments,1993, In Jean-Arcady Meyer
 Memoryless policies: Theoretical limitations and practical results,1994, In Proceed-ings of the Third International Conference on Simulation of Adaptive Behavior: From Animals toAnimats 3: From Animals to Animats 3
 Using Eligibility Traces to Find the Best Memoryless Policy inPartially Observable Markov Decision Processes,1998, In Proceedings of the Fifteenth InternationalConference on Machine Learning
 On the undecidability of probabilis-tic planning and related stochastic optimization problems,2003, Artificial Intelligence
 Linear Programming and Sequential Decisions,1960, Management Science
 Geometry of Policy Improvement,2017, In International Conferenceon Geometric Science of Information
 Geometry and Determinism of Optimal Sta-tionary Control in Partially Observable Markov Decision Processes,2015, arXiv:1503
 Task-agnostic constraining in average rewardPOMDPs,2019, In Task-agnostic reinforcement learning Workshop at ICLR 2019
 A Survey of POMDP Solution Techniques,2000, Environment
 Polynomials with and without determinantal representations,2012, Linearalgebra and its applications
 Real Algebraic Tools in Stochastic Games,2003, In Stochastic games and applica-tions
 Algebraic Degree of Polynomial Optimization,2009, SIAM Journalon Optimization
 Learning Policies with ExternalMemory,1999, In Proceedings of the 16th International Conference on Machine Learning
 Analyzing and escaping local optima in plan-ning as inference for partially observable domains,2011, In Joint European Conference on MachineLearning and Knowledge Discovery in Databases
 Markov Decision Processes: Discrete Stochastic Dynamic Programming,2014, JohnWiley & Sons
 A continuity result for optimal memoryless planningin pomdps,2021, 2021
 Semialgebraic and semianalytic sets,1991, Cahiers du se´ minaire d’histoire desmathematiques
 Learning without state-estimation inpartially observable Markovian decision processes,1994, In Machine Learning Proceedings 1994
 Reinforcement Learning: An Introduction,2018, MIT press
 Temporal Difference Learning and TD-Gammon,1995, Commun
 Numerical Nonlinear Algebra,2021, PhD thesis
 Pure and Spurious Critical Points: a GeometricStudy of Linear Networks,2019, In International Conference on Learning Representations
 A note on the matrix determinant lemma,2016, International Journal of Pure and AppliedMathematics
 Exponential Families with Incompatible Statistics and Their Entropy Dis-tance,2010, Friedrich-Alexander-UniversitatErlangen-Nurnberg (Germany)
 Reward is enoughfor convex MDPs,2021, arXiv:2106
 Semialgebraic statistics and latent tree models,2016, Monographs on Statistics andApplied Probability
 Optimal Control ofMarkov Processes with Incomplete State Information,1965, Jour-nal OfMathematicalAnalysis andApplications
 Wasserstein distance to independence models,2021, Journal of Symbolic Computation
