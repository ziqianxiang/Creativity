title,year,conference
 NCP-VAE: variational autoen-coders with noise contrastive priors,2020, CoRR
 Learning representations by maximizingmutual information across views,2019, arXiv preprint arXiv:1906
 Beit: BERT pre-training of image transformers,2021, arXiv preprintarXiv:2106
 Large scale gan training for high fidelity naturalimage synthesis,2019, In ICLR
 Language models arefew-shot learners,2020, arXiv preprint arXiv:2005
 Emerging properties in self-supervised vision transformers,2021, arXiv preprintarXiv:2104
 A simple frameWork forcontrastive learning of visual representations,2020, In International conference on machine learning
 Big self-supervised models are strong semi-supervised learners,2020, arXiv preprint arXiv:2006
 Pixelsnail: An improved autore-gressive generative model,2018, In Jennifer G
 Improved baselines with momentumcontrastive learning,2020, arXiv preprint arXiv:2003
 Semi-supervised sequence learning,2015, Advances in neural informationprocessing systems
 On the ge-nealogy of machine learning datasets: A critical history of imagenet,2021, Big Data & Society
 BERT: pre-training ofdeep bidirectional transformers for language understanding,2019, In Jill Burstein
 Diffusion models beat gans on image synthesis,2021, arXiv preprintarXiv:2105
 Large scale adversarial representation learning,2019, arXiv preprintarXiv:1907
 Adversarial feature learning,2016, arXiv preprintarXiv:1605
 Adversarial feature learning,2017, In ICLR
 Animage is worth 16x16 words: Transformers for image recognition at scale,2020, arXiv preprintarXiv:2010
 A note on data biases in generative models,2020, InNeurIPS 2020 Workshop on Machine Learning for Creativity and Design
 Taming transformers for high-resolution imagesynthesis,2021, In CVPR
 Unsupervised representation learning bypredicting image rotations,2018, In ICLR
 Unsupervised representation learning bypredicting image rotations,2018, arXiv preprint arXiv:1803
 Generative adversarial nets,2014, In NeurIPS
 Bootstrap your own latent: Anew approach to self-supervised learning,2020, arXiv preprintarXiv:2006
 Momentum contrast forunsupervised visual representation learning,2020, In Proceedings of the IEEE/CVF Conference onComputer Vision and Pattern Recognition
 Pioneer networks: Progressively growing generativeautoencoder,2018, In Asia conference on computer vision
 Data-efficient image recognition with contrastive predictive coding,2020, In InternationalConference on Machine Learning
 beta-vae: Learning basic visual concepts with aconstrained variational framework,2017, In ICLR
 The curious case of neural textdegeneration,2020, In International Conference on Learning Representations
 Image-to-image translation withconditional adversarial networks,2017, In 2017 IEEE Conference on Computer Vision and PatternRecognition (CVPR)
 Perceptual losses for real-time style transfer andsuper-resolution,2016, In European conference on computer vision
 A style-based generator architecture for generativeadversarial networks,2019, In Proceedings of the IEEE/CVF Conference on Computer Vision andPattern Recognition (CVPR)
 Analyz-ing and improving the image quality of stylegan,2020, In Proceedings of the IEEE/CVF Conference onComputer Vision and Pattern Recognition
 Adam: A method for stochastic optimization,2014, arXiv preprintarXiv:1412
 Auto-encoding variational bayes,2014, In ICLR
 Glow: Generative flow with invertible 1x1 convolu-tions,2018, In S
 Imagenet classification with deep con-volutional neural networks,2012, Advances in neural information processing systems
 Principled hybrids of generativeand discriminative models,2006, In 2006 IEEE Computer Society Conference on Computer Vision andPattern Recognition (CVPRâ€™06)
 Decoupled weight decay regularization,2017, arXiv preprintarXiv:1711
 Pulse: Self-supervisedphoto upsampling via latent space exploration of generative models,2020, In The IEEE Conference onComputer Vision and Pattern Recognition (CVPR)
 Generating images with sparse repre-sentations,2021, ICML
 UnsUpervised learning of visUal representations by solving jigsawpUzzles,2016, In Bastian Leibe
 UnsUpervised learning of visUal representations by solving jigsawpUzzles,2016, In European conference on computer vision
 Image transformer,2018, In Jennifer G
 UnsUpervised representation learning with deepconvolUtional generative adversarial networks,2016, In YoshUa Bengio and Yann LeCUn (eds
 Improving langUage Under-standing by generative pre-training,2018, 2018
 LangUagemodels are UnsUpervised mUltitask learners,2019, OpenAI blog
 Zero-shot text-to-image generation,2021, In Marina Meila and Tong Zhang (eds
 Generating diverse high-fidelity images withVQ-VAE-2,2019, In Hanna M
 A u-net based discriminator for generativeadversarial networks,2020, In Proceedings of the IEEE/CVF Conference on Computer Vision andPattern Recognition
 Very deep convolutional networks for large-scale imagerecognition,2014, arXiv preprint arXiv:1409
 Image representations learned with unsupervised pre-training con-tain human-like biases,2021, In The 2021 ACM Conference on Fairness
 NVAE: A deep hierarchical variational autoencoder,2020, In HugoLarochelle
 Conditional image generation with pixelcnn decoders,2016, In Daniel D
 Neural discrete representation learn-ing,2017, In Isabelle GUyon
 Representation learning with contrastive predic-tive coding,2018, arXiv preprint arXiv:1807
 Attention is all you need,2017, In NeurIPS
 The emergence of deepfake technology: A review,1927, Technology InnovationManagementReview
 Self-attention generativeadversarial networks,2019, In International conference on machine learning
 Self-attention generativeadversarial networks,2019, In ICML
 The unreasonableeffectiveness of deep features as a perceptual metric,2018, In Proceedings of the IEEE conference oncomputer vision and pattern recognition
