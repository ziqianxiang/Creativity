title,year,conference
 Structureddenoising diffusion models in discrete state-spaces,2021, arXiv preprint arXiv:2107
 A neural probabilisticlanguage model,2003, The journal of machine learning research
 Generating sentences from a continuous space,2015, arXiv preprint arXiv:1511
 Language models arefew-shot learners,2020, arXiv preprint arXiv:2005
 Language gans falling short,2020, In 8th International Conference on Learning Representa-tions
 Im-puter: Sequence modelling via imputation and dynamic programming,2020, In International Confer-ence on Machine Learning
 Maximum-likelihood augmented discrete generative adversarial networks,2017, arXiv preprintarXiv:1702
 Electra: Pre-trainingtext encoders as discriminators rather than generators,2020, arXiv preprint arXiv:2003
 Pre-training transform-ers as energy-based cloze models,2020, arXiv preprint arXiv:2012
 Training languagegans from scratch,2019, arXiv preprint arXiv:1905
 Residualenergy-based models for text generation,2020, arXiv preprint arXiv:2004
 Bert: Pre-training of deepbidirectional transformers for language understanding,2018, arXiv preprint arXiv:1810
 Nice: Non-linear independent components esti-mation,2014, arXiv preprint arXiv:1410
 Density estimation using real nvp,2016, arXivpreprint arXiv:1605
 Mask-predict: Paralleldecoding of conditional masked language models,2019, arXiv preprint arXiv:1904
 Semi-autoregressive training improvesmask-predict decoding,2020, arXiv preprint arXiv:2001
 Generative adversarial nets,2014, Advances in neural informationprocessing systems
 Non-autoregressiveneural machine translation,2017, arXiv preprint arXiv:1711
 Levenshtein transformer,2019, arXiv preprintarXiv:1905
 Long text generation viaadversarial training with leaked information,2017, arxiv e-prints
 Jointly masked sequence-to-sequence model for non-autoregressive neural machine translation,2020, In Proceedings of the 58th Annual Meeting of theAssociation for Computational Linguistics
 Training products of experts by minimizing contrastive divergence,2002, Neuralcomputation
 Denoising diffusion probabilistic models,2020, arXiv preprintarXiv:2006
 Argmaxflows and multinomial diffusion: Towards non-autoregressive language models,2021, arXiv preprintarXiv:2102
 Neural networks and physical systems with emergent collective computationalabilities,1982, Proceedings of the national academy of sciences
 Fast decoding in sequence models using discrete latent variables,2018, In International Con-ference on Machine Learning
 Non-autoregressive machine trans-lation with disentangled context transformer,2020, In International Conference on Machine Learning
 Sequence-level knowledge distillation,2016, arXiv preprintarXiv:1606
 Adam: A method for stochastic optimization,2014, arXiv preprintarXiv:1412
 Auto-encoding variational bayes,2013, arXiv preprintarXiv:1312
 Incorporating a local translation mechanism intonon-autoregressive translation,2020, arXiv preprint arXiv:2011
 Sentencepiece: A simple and language independent subwordtokenizer and detokenizer for neural text processing,2018, arXiv preprint arXiv:1808
 A tutorial on energy-basedlearning,2006, Predicting structured data
 Deterministic non-autoregressive neural se-quence modeling by iterative refinement,2018, arXiv preprint arXiv:1802
 Iterative refinement in the continuous space fornon-autoregressive neural machine translation,2020, arXiv preprint arXiv:2009
 Hint-based trainingfor non-autoregressive machine translation,2019, arXiv preprint arXiv:1909
 Adversarial ranking forlanguage generation,2017, arXiv preprint arXiv:1705
 Roberta: A robustly optimized bert pretrainingapproach,2019, arXiv preprint arXiv:1907
 Sgdr: Stochastic gradient descent with warm restarts,2016, arXivpreprint arXiv:1608
 Decoupled weight decay regularization,2017, arXiv preprintarXiv:1711
 Flowseq:Non-autoregressive conditional sequence generation with generative flow,2019, arXiv preprintarXiv:1909
 Text 8 dataset,2011, http://mattmahoney
 Symbolic music generation withdiffusion models,2021, arXiv preprint arXiv:2103
 Improved denoising diffusion probabilistic models,2021, arXivpreprint arXiv:2102
 Bleu: a method for automaticevaluation of machine translation,2002, In Proceedings of the 40th annual meeting of the Associationfor Computational Linguistics
 A call for clarity in reporting bleu scores,2018, arXiv preprint arXiv:1804
 Exploring the limits of transfer learning with a unified text-to-texttransformer,2019, arXiv e-prints
 Guiding non-autoregressive neural machine translationdecoding with reordering information,2019, arXiv preprint arXiv:1911
 Preventing posterior collapse withdelta-vaes,2019, arXiv preprint arXiv:1901
 Variational inference with normalizing flows,2015, In Interna-tional conference on machine learning
 Stochastic backpropagation and ap-proximate inference in deep generative models,2014, In International conference on machine learning
 Non-autoregressivemachine translation with latent alignments,2020, arXiv preprint arXiv:2004
 Neural machine translation of rare words withsubword units,2015, arXiv preprint arXiv:1508
 Latent-variable non-autoregressive neural machine translation with deterministic inference using a delta posterior,2020, InProceedings of the AAAI Conference on Artificial Intelligence
 Deep unsupervisedlearning using nonequilibrium thermodynamics,2015, In International Conference on Machine Learn-ing
 Score-based generative modeling through stochastic differential equations,2020, arXiv preprintarXiv:2011
 Insertion transformer: Flexiblesequence generation via insertion operations,2019, In International Conference on Machine Learning
 Fast structureddecoding for sequence models,2019, arXiv preprint arXiv:1910
 Generating text with recurrent neural net-works,2011, In ICML
 Attention is all you need,2017, In Advances in neural informationprocessing systems
 Non-autoregressivemachine translation with auxiliary regularization,2019, In Proceedings of the AAAI Conference onArtificial Intelligence
 Seqgan: Sequence generative adversarial netswith policy gradient,2017, In Proceedings of the AAAI conference on artificial intelligence
