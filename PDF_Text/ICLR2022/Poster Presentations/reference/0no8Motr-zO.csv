title,year,conference
 Explore the context: Optimal data collection for context-conditional dynamics models,2021, In Arindam Banerjee and Kenji Fukumizu (eds
 Model-based reinforcement learning with agenerative model is minimax optimal,2020, In Jacob Abernethy and Shivani Agarwal (eds
 Minimax pac bounds on thesample complexity of reinforcement learning with a generative model,2013, Machine learning
 Unifying count-based exploration and intrinsic motivation,2016, CoRR
 Actively learning gaussian processdynamics,2020, In Alexandre M
 Exploration by random networkdistillation,2019, In International Conference on Learning Representations
 Bayesian experimental design: A review,1995, StatisticalScience
 Offline contextual bayesian optimization,2019, Advancesin Neural Information Processing Systems
 UCB and infogain exploration viaq-ensembles,2017, CoRR
 Deep rein-forcement learning in a handful of trials using probabilistic dynamics models,2018, InS
 Bayesian q-learning,1998, In Aaai/iaai
 Model-based bayesian exploration,1999, CoRR
 Pilco: A model-based and data-efficientapproach to policy search,2011, In Proceedings of the 28th International Conference on InternationalConference on Machine Learning
 A tutorial on bayesian optimization,2018, arXiv preprint arXiv:1807
 Addressing function approximation error in actor-critic methods,2018, In Jennifer Dy and Andreas Krause (eds
 Bayesian reinforcementlearning: A survey,2016, CoRR
 Efficient bayes-adaptive reinforcement learning usingsample-based search,2012, In Proceedings of the 25th International Conference on Neural InformationProcessing Systems - Volume 1
 Soft actor-critic: Off-policymaximum entropy deep reinforcement learning with a stochastic actor,2018, In International conferenceon machine learning
 DiSECt:A Differentiable Simulation Engine for Autonomous Robotic Cutting,2021, In Proceedings of Robotics:Science and Systems
 On the sample complexity of reinforcement learning,2003, University ofLondon
 Data-efficient reinforcement learning with probabilisticmodel predictive control,2018, In Amos Storkey and Fernando Perez-Cruz (eds
 A sparse sampling algorithm for near-optimalplanning in large markov decision processes,2002, Machine learning
 Near-bayesian exploration in polynomial time,2009, In Proceedings ofthe 26th annual international conference on machine learning
 Breaking the sam-ple size barrier in model-based reinforcement learning with a generative model,2020, InH
 Continuous control with deep reinforcement learning,2015, arXivpreprint arXiv:1509
 Exploration in model-basedreinforcement learning by empirically estimating learning progress,2012, In F
 Bayesian nonlinear modeling for the prediction competition,1994, ASHRAEtransactions
 Neural dynamical systems: Balancing structure andflexibility in physical prediction,2020, arXiv preprint arXiv:2006
 Playing atari with deep reinforcement learning,2013, arXiv preprintarXiv:1312
 Bayesian Learning for Neural Networks,1995, PhD thesis
 Bayesian algorithm execution: Esti-mating computable properties of black-box functions using mutual information,2021, In InternationalConference on Machine Learning
 Information-directedexploration for deep reinforcement learning,2019, In International Conference on Learning Representa-tions
 Deep explorationvia bootstrapped dqn,2016, In D
 Curiosity-driven explorationby self-supervised prediction,2778, In International conference on machine learning
 Mbrl-lib: A modular library for model-based reinforcement learning,2021, Arxiv
 Sample-efficient cross-entropy method for real-time planning,2020, arXivpreprint arXiv:2008
 Random features for large-scale kernel machines,2007, In NIPS
 Learning to optimize via information-directed sam-pling,2014, In Z
 Information collection on a graph,2011, Operations Research
 Bayesian explorationfor approximate dynamic programming,2019, Operations research
 A possibility for implementing curiosity and boredom in model-building neuralcontrollers,1991, In Proc
 Proximal policyoptimization algorithms,2017, arXiv preprint arXiv:1707
 Taking thehuman out of the loop: A review of bayesian optimization,2015, Proceedings of the IEEE
 Model-based active exploration,2019, InKamalika Chaudhuri and Ruslan Salakhutdinov (eds
 Probabilistic planning for robotic exploration,2007, Carnegie Mellon University
 Reinforcement Learning: An Introduction,1998, MIT Press
 Exploring model-based planning with policy networks,2020, In InternationalConference on Learning Representations
 Gaussian processes for regression,1996,1996
