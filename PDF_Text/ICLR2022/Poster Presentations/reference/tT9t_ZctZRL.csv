title,year,conference
 A convergence theory for deep learning via over-parameterization,2019, In International Conference on Machine Learning
 Simple and deep graph con-volutional networks,2020, In International Conference on Machine Learning
 On the equivalence between neuralnetwork and support vector machine,2021, Advances in Neural Information Processing Systems
 On the spectra of general random graphs,2011, The electronic journal ofcombinatorics
 On provable benefits of depth in traininggraph convolutional networks,2021, Advances in Neural Information Processing Systems
 Gaussian process behaviour in wide deep neural networks,2018, In International Conference onLearning Representations
 Spectral distributions of adjacency and laplacian matrices of randomgraphs,2010, The annals of applied probability
 Gradient descent finds globalminima of deep neural networks,2019, In International conference on machine learning
 Graph neural tangent kernel: Fusing graph neural networks with graph kernels,2019, In Advancesin Neural Information Processing Systems
 On the strength of connectedness of a random graph,1961, Acta Mathemat-ica Hungarica
 On the evolution of random graphs,2011, In The Structure and dynamics ofnetworks
 Convergence theorem for finite markov chains,2017, Proc
 Geometrically prin-cipled connections in graph neural networks,2020, In ProceedingS of the IEEE/CVF Conference onComputer ViSion and Pattern Recognition
 Expressivity of deep neural networks,2020, arXivpreprint arXiv:2007
 On the impact of the activation function ondeep neural networks training,2672, In International conference on machine learning
 Mean-field behaviour of neural tangentkernel for deep neural networks,2019, arXiv preprint arXiv:1905
 Measuring and improving the use of graph information in graph neural networks,2019, InInternational Conference on Learning Representations
 Infinite attention: Nngp andntk for deep attention networks,2020, In International Conference on Machine Learning
 Critical percolationclusters in seven dimensions and on a complete graph,2018, Physical Review E
 On the neural tangent kernel of deep networkswith orthogonal initialization,2021, In Proceedings of the Thirtieth International Joint Conference onArtificial Intelligence
 Tackling over-smoothing for general graph convolutional networks,2020, arXiv preprint arXiv:2008
 Neural tangent kernel: Convergence and gen-eralization in neural networks,2018, In Advances in neural information processing systems
 How to find your friendly neighborhood: Graph attention designwith self-supervision,2020, In International Conference on Learning Representations
 Variational graph auto-encoders,2016, NIPS Workshop on BayesianDeep Learning
 Semi-supervised classification with graph convolutional net-works,2017, In International Conference on Learning Representations (ICLR)
 Predict then propagate:Graph neural networks meet personalized pagerank,2019, In International Conference on LearningRepresentations
 Deep neural networks as gaussian processes,2018, In International Conference onLearning Representations
 Wide neural networks of any depth evolve as linear modelsunder gradient descent,2019, In Advances in neural information processing systems
 Self-attention graph pooling,2019, In International confer-ence on machine learning
 Deepergcn: All you need to traindeeper gcns,2020, arXiv preprint arXiv:2006
 Deeper insights into graph convolutional networks forsemi-supervised learning,2018, In Thirty-Second AAAI conference on artificial intelligence
 What graph neural networks cannot learn: depth vs width,2020, In International Con-ference on Learning Representations
 Graph neural networks exponentially lose expressive power for nodeclassification,2020, In International Conference on Learning Representations
 Exponen-tial expressivity in deep neural networks through transient chaos,2016, In Advances in neural informa-tion processing systems
 Dropedge: Towards deep graphconvolutional networks on node classification,2019, In International Conference on Learning Repre-sentations
 Convergence rates for markov chains,1995, Siam Review
 Graph neuralnetworks exponentially lose expressive power for node classification,2017, In International Conferenceon Learning Representations
 Pitfallsof graph neural network evaluation,2018, arXiv preprint arXiv:1811
 GraPh attention networks,2018, In International Conference on Learning Representations
 Disentangling trainability and general-ization in deeP neural networks,2020, In International Conference on Machine Learning
 RePresentation learning on graPhs with jumPing knowledge networks,2018, In InternationalConference on Machine Learning
 StructPool: Structured graPh Pooling via conditional random fields,2020, In ICLR
 DeeP graPh neural networks with shallow subgraPhsamPlers,2020, ICLR
 Pairnorm: Tackling oversmoothing in gnns,2020, In InternationalConference on Learning Representations
 Towards deePergraPh neural networks with differentiable grouP normalization,2020, In Advances in neural informationprocessing systems
 Stochastic gradient descent oPtimizesover-Parameterized deeP relu networks,2018, arxiv e-Prints
