title,year,conference
 Deep residual learning for imagerecognition,2016, In 2016 IEEE Conference on Computer Vision and Pattern Recognition
 Generative adversarial networks,2014, arXiv preprintarXiv:1406
 Auto-encoding variational bayes,2014, In Yoshua Bengio andYann LeCun
 Gradients as features for deep representation learning,2020, In8th International Conference on Learning Representations
 Neural tangent kernel: Convergence andgeneralization in neural networks,2018, In Samy Bengio
 Priors for infinite networks,1996, In Bayesian Learning for Neural Networks
 Continuous neural networks,2007, In Marina Meila and XiaotongShen
 Deep neural networks as gaussian processes,2018, In 6th International Conference onLearning Representations
 Deep neural tangent kernel and laplace kernel have the same RKHS,2021, In9th International Conference on Learning Representations
 On the similarity between the laplace and neural tangent kernels,2020, InHugo Larochelle
 To understand deep learning we need to understandkernel learning,2018, In Jennifer G
 Fisher kernels on visual vocabularies for imagecategorization,2007, In 2007 IEEE Computer Society Conference on Computer Vision and PatternRecognition (CVPR 2007)
 NICE: non-linear independent componentsestimation,2015, In Yoshua Bengio and Yann LeCun
 Deep learning,2014, In Sofus A
 Task2vec: Task embedding for meta-learning,2019, In2019 IEEE/CVF International Conference on Computer Vision
 Calibratingenergy-based generative adversarial networks,2017, In 5th International Conference on LearningRepresentations
 Adversarial fisher vec-tors for unsupervised representation learning,2019, In Hanna M
 Your GAN is secretly an energy-based model and you should use discriminatordriven latent sampling,2020, In Hugo Larochelle
 Importance weighted autoencoders,2016, InYoshua Bengio and Yann LeCun
 Your classifier is secretly an energy based model and you should treat it likeone,2020, In 8th International Conference on Learning Representations
 Contractive auto-encoders: Explicit invariance during feature extraction,2011, In Lise Getoor and Tobias Scheffer
 The man-ifold tangent classifier,2011, In John Shawe-Taylor
 Gradient-based learning applied todocument recognition,1998, Proceedings of the IEEE
 Unsupervised representation learning with deepconvolutional generative adversarial networks,2016, In Yoshua Bengio and Yann LeCun
 Functions ofpositive and negativetypeand theircommection with the theory ofintegralequations,1909, Philos
 Using the nystrom method tospeed up kernel machines,2000, In Todd K
 Finding structure with randomness:Probabilistic algorithms for constructing approximate matrix decompositions,2011, SIAM Rev
 Eigenvalue computation in the 20th century,2000, Journal ofComputational and Applied Mathematics
 Solution methods for large generalized eigenvalue problems in structuralengineering,1971, National Technical Information Service
 Neural tangents: Fast and easy infinite neural networks in python,2020, In8th International Conference on Learning Representations
 Randomized numerical linear algebra: Foundationsand algorithms,2020, Acta Numer
 Unsupervised representation learning by pre-dicting image rotations,2018, In 6th International Conference on Learning Representations
 AET vs,2019, AED: unsupervisedrepresentation learning by auto-encoding transformations rather than data
 mixup: Beyond empiricalrisk minimization,2018, In 6th International Conference on Learning Representations
 Virtual adversarial training:A regularization method for supervised and semi-supervised learning,2019, IEEE Trans
 Mean teachers are better role models: Weight-averaged con-sistency targets improve semi-supervised deep learning results,2017, In Isabelle Guyon
 Mixmatch: A holistic approach to semi-supervised learning,2019, In Hanna M
 In Daniel D,2016, Lee
 Temporal ensembling for semi-supervised learning,2017, In 5th Interna-tional Conference on Learning Representations
 Regularization with stochastictransformations and perturbations for deep semi-supervised learning,2016, In Daniel D
 Fitnets: Hints for thin deep nets,2015, In Yoshua Bengio and Yann LeCun
 Paying more attention to attention: Improving the perfor-mance of convolutional neural networks via attention transfer,2017, In 5th International Conference onLearning Representations
 Implicit regularization via neural feature alignment,2021, In ArindamBanerjee and Kenji Fukumizu
 Stacked denoising autoencoders: Learning useful representations in a deep networkwith a local denoising criterion,2010, Journal of machine learning research
 Representation learning with contrastive predictivecoding,2018, arXiv preprint arXiv:1807
 A simple framework forcontrastive learning of visual representations,2020, In Proceedings of the 37th International Conferenceon Machine Learning
 Momentum contrast forunsupervised visual representation learning,9726, In 2020 IEEE/CVF Conference on Computer Visionand Pattern Recognition
 Learning deep representations by mutual information estimationand maximization,2019, In 7th International Conference on Learning Representations
 On variational boundsof mutual information,5171, In Kamalika Chaudhuri and Ruslan Salakhutdinov
 Learning structured latent factors fromdependent data:a generative model framework from information-theoretic perspective,1114, In Proceed-ings of the 37th International Conference on Machine Learning
 Self-supervised visual feature learning with deep neural networks: Asurvey,2020, IEEE Transactions on Pattern Analysis and Machine Intelligence
 Similarity-preserving knowledge distillation,2019, In 2019 IEEE/CVFInternational Conference on Computer Vision
 Contrastive representation distillation,2020, In 8thInternational Conference on Learning Representations
 Natural gradient works efficiently in learning,1998, Neural computation
