title,year,conference
 Tensorflow: A system for large-scale machine learning,2016, In 12th {USENIX} symposium on operating systems design and imple-mentation ({OSDI} 16)
 Database-friendly random projections,2001, In Proceedings of the twentieth ACMSIGMOD-SIGACT-SIGART symposium on Principles of database systems
 Computational graphs and rounding error,1974, SIAM Journal on Numerical Analysis
 Optimization methods for large-scale machinelearning,2018, Siam Review
 Graph coarsening with neural networks,2021, arXiv preprintarXiv:2102
 Graphnorm: A prin-cipled approach to accelerating graph neural network training,2021, In International Conference onMachine Learning
 Backprop with approximate activations for memory-efficient network training,2019, Advances in Neural Information Processing Systems
 Stochastic training of graph convolutional networks withvariance reduction,2017, In International conference on machine learning
 A statisticalframework for low-bitwidth training of deep neural networks,2020, arXiv preprint arXiv:2010
 Actnn: Reducing training memory footprint via 2-bit activation compressedtraining,2021, In International Conference on Machine Learning
 Fastgcn: fast learning with graph convolutional networks viaimportance sampling,2018, arXiv preprint arXiv:1801
 Simple and deep graph con-volutional networks,2020, In International Conference on Machine Learning
 A unified lotteryticket hypothesis for graph neural networks,2021, In International Conference on Machine Learning
 Training deep nets with sublinearmemory cost,2016,-2016
 Binaryconnect: Training deep neuralnetworks with binary weights during propagations,2015, In Advances in neural information processingsystems
 AC-GC: Lossy activation compression with guaranteed con-vergence,2021, In Thirty-Fifth Conference on Neural Information Processing Systems
 Jpeg-act: accelerating deep learning via transform-based lossy compression,2020, In 2020 ACM/IEEE 47th Annual International Symposium on ComputerArchitecture (ISCA)
 Sgquant: Squeezing thelast bit on graph neural networks with specialized quantization,2020, In 2020 IEEE 32nd InternationalConference on Tools with Artificial Intelligence (ICTAI)
 Fast graph representation learning with PyTorch Geometric,2019, InICLR Workshop on Representation Learning on Graphs and Manifolds
 Gnnautoscale: Scalable and ex-pressive graph neural networks via historical embeddings,2021, In International conference on machinelearning
 Don¡¯twaste your bits! squeeze activations and gradients for deep neural networks via tinyscript,2020, InInternational Conference on Machine Learning
 Inductive representation learning on largegraphs,2017, In Proceedings of the 31st International Conference on Neural Information ProcessingSystems
 Open graph benchmark: Datasets for machine learning on graphs,2020, arXivpreprint arXiv:2005
 Combining labelpropagation and simple models out-performs graph neural networks,2020, In International Conferenceon Learning Representations
 Adaptive sampling towards fast graphrepresentation learning,2018, In Advances in Neural Information Processing Systems
 Checkmate: Breaking the memory wall with optimal tensor rematerial-ization,2019, arXiv preprint arXiv:1910
 A fast and high quality multilevel scheme for partitioning irreg-ular graphs,1998, SIAM Journal on scientific Computing
 Adam: A method for stochastic optimization,2014, arXiv preprintarXiv:1412
 Semi-supervised classification with graph convolutional net-works,2017, In International Conference on Learning Representations
 Dynamic tensor rematerialization,2020, arXiv preprintarXiv:2006
 Predict then propagate:Graph neural networks meet personalized pagerank,2018, In International Conference on LearningRepresentations
 Sgcn: Agraph sparsifier based on graph convolutional networks,2020, In Pacific-Asia Conference on KnowledgeDiscovery and Data Mining
 Graph traversal with tensor functionals: Ameta-algorithm for scalable learning,2021, In International Conference on Learning Representations
 Training deeper models by gpumemory optimization on tensorflow,2017, In Proc
 Mixed precisiontraining,2017, arXiv preprint arXiv:1710
 Graph neural networks exponentially lose expressive power for nodeclassification,2019, arXiv preprint arXiv:1905
 Graph sparsification by effective resistances,2011, SIAMJournal on Computing
 Degree-quant:Quantization-aware training for graph neural networks,2021, In International Conference on LearningRepresentations
 Significantly improving lossy com-pression for scientific data sets based on multidimensional prediction and error-controlled quanti-zation,2017, In 2017 IEEE International Parallel and Distributed Processing Symposium (IPDPS)
 Cusz: An efficient gpu-based error-boundedlossy compression framework for scientific data,2020, arXiv preprint arXiv:2007
 Graph attention networks,2017, In International Conference on Learning Representations
 BNS-GCN: Efficient full-graphtraining of graph convolutional networks with partition-parallelism and random boundary nodesampling,2021, In Fifth Conference on Machine Learning and Systems
 Scalable graph neural networks for hetero-geneous graphs,2020, arXiv preprint arXiv:2011
 Graph-saint: Graph sampling based inductive learning method,2020, In International Conference on LearningRepresentations
 Link prediction based on graph neural networks,2018, Advances in NeuralInformation Processing Systems
 Learned lowprecision graph neural networks,2020, arXiv preprint arXiv:2009
 Robust graph representation learning via neural sparsification,2020, In InternationalConference on Machine Learning
 Distdgl: distributed graph neural network training for billion-scale graphs,2020, In2020 IEEE/ACM 10th Workshop on Irregular Applications: Architectures and Algorithms (IA3)
 Layer-dependentimportance sampling for training deep and large graph convolutional networks,2019, arXiv preprintarXiv:1911
