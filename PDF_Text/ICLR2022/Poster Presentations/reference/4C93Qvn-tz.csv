title,year,conference
 A tutorial on adaptive mcmc,2008, Statistics and computing
 Better mixing via deep represen-tations,2013, In International conference on machine learning
 Large scale gan training for high fidelity naturalimage synthesis,2018, arXiv preprint arXiv:1809
 General methods for monitoring convergence of iterativesimulations,1998, Journal of computational and graphical statistics
 Calibratingenergy-based generative adversarial networks,2017, arXiv preprint arXiv:1702
 Maxi-mum entropy methods for texture synthesis: theory and practice,2021, SIAM Journal on Mathematicsof Data Science
 Nice: Non-linear independent components esti-mation,2014, arXiv preprint arXiv:1410
 Density estimation using real nvp,2016, arXivpreprint arXiv:1605
 Implicit generation and generalization in energy-based models,2019, arXivpreprint arXiv:1903
 Improved contrastive divergencetraining of energy based models,2020, arXiv preprint arXiv:2012
 Neural spline flows,2019, Ad-vances in Neural Information Processing Systems
 Learning generative con-vnets via multi-grid modeling and sampling,2018, In Proceedings of the IEEE Conference on ComputerVision and Pattern Recognition
 Flowcontrastive estimation of energy-based models,2019, arXiv preprint arXiv:1912
 Inference from iterative simulation using multiple se-quences,1992, Statistical science
 Understanding the difficulty of training deep feedforward neuralnetworks,2010, In Proceedings of the thirteenth international conference on artificial intelligence andstatistics
 Generative adversarial nets,2014, In Advances in neural infor-mation processing Systems
 Ffjord:Free-form continuous dynamics for scalable reversible generative models,2018, arXiv preprintarXiv:1810
 No mcmc for me: Amortized sampling for fast and stable training of energy-basedmodels,2020, arXiv preprint arXiv:2010
 Noise-contrastive estimation: A new estimation principlefor unnormalized statistical models,2010, In Proceedings of the Thirteenth International Conferenceon Artificial Intelligence and Statistics
 Alternating back-propagation for generatornetwork,2017, In Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence
 Building a telescope to look into high-dimensionalimage spaces,2019, Quarterly of Applied Mathematics
 Neutra-lizing bad geometry in hamiltonian monte carlo using neural transport,2019, arXivpreprint arXiv:1903
 Introspective classification with convolutional nets,2017, InAdvances in Neural Information Processing Systems
 Variational autoencoders and nonlin-ear ica: A unifying framework,2019, arXiv preprint arXiv:1907
 Deep directed generative models with energy-based probabilityestimation,2016, arXiv preprint arXiv:1606
 Efficient gradient-based inference through transformationsbetween bayes nets and neural nets,2014, In International Conference on Machine Learning
 Adam: A method for stochastic optimization,2015, In 3rd Inter-national Conference on Learning Representations
 Auto-encoding variational bayes,2013, arXiv preprintarXiv:1312
 Glow: Generative flow with invertible 1x1 convolutions,2018, InAdvances in Neural Information Processing Systems
 Im-proved variational inference with inverse autoregressive flow,2016, In Advances in neural informationprocessing systems
 Imagenet classification with deep convo-Iutional neural networks,2012, In Advances in neural information processing Systems
 Videoflow: A flow-based generative model for video,2019, arXiv preprintarXiv:1903
 Maximumentropy generators for energy-based models,2019, arXiv preprint arXiv:1901
 On the theory of Brownian motion,1908, 1908
 Gradient-based learning appliedto document recognition,1998, Proceedings of the IEEE
 A tutorial on energy-basedlearning,2006, Predicting structured data
 Rapid mixing of hamiltonian monte carlo on strongly log-concavedistributions,2017, arXiv preprint arXiv:1708
 Spectral normalizationfor generative adversarial networks,2018, arXiv preprint arXiv:1802
 MCMC using hamiltonian dynamics,2011, Handbook ofMarkov Chain Monte Carlo
 Readingdigits in natural images with unsupervised feature learning,2011, 2011
 On learning non-convergent short-run mcmctoward energy-based model,2019, arXiv preprint arXiv:1904
 Searching for activation functions,2017, arXivpreprint arXiv:1710
 Variational inference with normalizing flows,2015, arXivpreprint arXiv:1505
 Whole-sentence exponential language models:a vehicle for linguistic-statistical integration,2001, Computer Speech & Language
 Rethink-ing the inception architecture for computer vision,2016, In Proceedings of the IEEE conference oncomputer vision and pattern recognition
 Training restricted boltzmann machines using approximations to the likelihoodgradient,2008, In Proceedings of the 25th international conference on Machine learning
 Discrete flows:Invertible generative models of discrete data,2019, arXiv preprint arXiv:1905
 Learning generative models via discriminative approaches,2007, In 2007 IEEE Conferenceon Computer Vision and Pattern Recognition
 Revisiting the gelman-rubin diagnostic,2018, arXiv preprintarXiv:1812
 Learning neural trans-dimensional random field language models withnoise-contrastive estimation,2018, In 2018 IEEE International Conference on Acoustics
 Vaebm: A symbiosis between varia-tional autoencoders and energy-based models,2020, In International Conference on Learning Repre-sentations
 A theory of generative convnet,2016, InInternational Conference on Machine Learning
 Cooperative training of de-scriptor and generator networks,2018, IEEE transactions on pattern analysis and machine intelligence
