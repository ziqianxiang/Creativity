title,year,conference
 Domain-adversarialneural networks,2014, stat
 Obfuscated gradients give a false sense of security:Circumventing defenses to adversarial examples,2018, In Jennifer G
 Towards evaluating the robustness of neural networks,2017, In 2017 IEEESymposium on Security and Privacy
 Unlabeled data improvesadversarial robustness,2019, In Hanna M
 Estimating generalization under distribution shiftsvia domain-invariant representations,2020, In Proceedings of the 37th International Conference on Machine Learn-ing
 Reliable evaluation of adversarial robustness with an ensemble of diverseparameter-free attacks,2020, In ICML
 Reliable evaluation of adversarial robustness with an ensemble of diverseparameter-free attacks,2206, In Proceedings of the 37th International Conference on Machine Learning
 MMA training: Direct inputspace margin maximization through adversarial training,2020, In 8th International Conference on LearningRepresentations
 An adaptive and momental bound method forstochastic learning,2019, CoRR
 Domain-adversarial training of neural networks,2016, J
 Beyond perturbations:Learning guarantees with arbitrary adversarial test examples,2020, CoRR
 A research agenda: Dynamic models to defend against correlated attacks,2019, CoRR
 Deep residual learning for image recognition,2016, In2016 IEEE Conference on Computer Vision and Pattern Recognition
 Benchmarking neural network robustness to common corruptionsand perturbations,2019, In 7th International Conference on Learning Representations
 Using pre-training can improve model robustness anduncertainty,2019, In Kamalika Chaudhuri and Ruslan Salakhutdinov (eds
 Neural tangent kernel: Convergence and gen-eralization in neural networks,2018, In S
 Adversarial Robustness - Theory and Practice,2018, https://adversarial-ml-tutorial
 Learning multiple layers of features from tiny images,2009,2009
 Adversarial examples in the physical world,2017, In 5thInternational Conference on Learning Representations
 The mnist database of handwritten digits,1998, http://yann
 Delving into transferable adversarial examples andblack-box attacks,2016, CoRR
 Stochastic hyperparameter optimization through hypernetworks,2018, CoRR
 Towards deeplearning models resistant to adversarial attacks,2018, In 6th International Conference on Learning Representations
 Deepfool: A simple and accuratemethod to fool deep neural networks,2016, In 2016 IEEE Conference on Computer Vision and Pattern Recognition
 Adversarially robustgeneralization requires more data,2018, In Advances in Neural Information Processing Systems
 HYDRA: pruning adversarially ro-bust neural networks,2020, In Hugo Larochelle
 Certifying some distributional robustness with principledadversarial training,2018, In 6th International Conference on Learning Representations
 Man vs,2012, computer: Benchmarkingmachine learning algorithms for traffic sign recognition
 On adaptive attacks toadversarial example defenses,2020, In Hugo Larochelle
 The space of transferableadversarial examples,2017, arXiv
 Statistical learning theory,1998, Wiley
 Fighting gradients with gradients:Dynamic defenses against adversarial attacks,2021, arXiv preprint arXiv:2105
 Improving adversar-ial robustness requires revisiting misclassified examples,2020, In 8th International Conference on LearningRepresentations
 A survey of unsupervised deep domain adaptation,2020, ACM Transactions onIntelligent Systems and Technology (TIST)
 Fast is better than free: Revisiting adversarial training,2020, In 8thInternational Conference on Learning Representations
 Adversarial weight perturbation helps robustgeneralization,2020, In Hugo Larochelle
