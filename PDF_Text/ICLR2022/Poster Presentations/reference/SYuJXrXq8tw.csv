title,year,conference
 Critical learning periods in deep net-works,2019, In International Conference on Learning Representations
 Obfuscated gradients give a false sense ofsecurity: Circumventing defenses to adversarial examples,2018, arXiv preprint arXiv:1802
 Adversarial risk boundsfor neural networks through sparsity based compression,2019, arXiv preprint arXiv:1906
 Adversariallyoptimized mixup for robust classification,2021, arXiv preprint arXiv:2103
 Towards evaluating the robustness of neural networks,2017, In 2017ieee symposium on security and privacy (sp)
 The lottery tickets hypothesis for supervised and self-supervised pre-trainingin computer vision models,2020, arXiv preprint arXiv:2012
 The lottery ticket hypothesis for pre-trained bert networks,2020, arXiv preprintarXiv:2007
 Adversarialrobustness: From self-supervised pre-training to fine-tuning,2020, In Proceedings of the IEEE/CVFConference on Computer Vision and Pattern Recognition
 Long live the lottery:The existence of winning tickets in lifelong learning,2021, In International Conference on LearningRepresentations
 Robust overfittingmay be mitigated by properly learned smoothening,2021, In International Conference on LearningRepresentations
 Coarsening thegranularity: Towards structurally sparse lottery tickets,2022, arXiv preprint arXiv:2202
 You are caught stealing my win-ning lottery ticket! making a lottery ticket claim its ownership,2021, Advances in Neural InformationProcessing Systems
 Gans can play lottery tickets too,2021, InInternational Conference on Learning Representations
 Reliable evaluation of adversarial robustness with an ensembleof diverse parameter-free attacks,2020, In International Conference on Machine Learning
 Imagenet: A large-scale hi-erarchical image database,2009, In 2009 IEEE conference on computer vision and pattern recognition
 Sparse networks from scratch: Faster training without losingperformance,2019, arXiv preprint arXiv:1907
 Stochastic activation pruning for robustadversarial defense,2018, In International Conference on Learning Representations
 Stochastic activation pruning for robust adversarial de-fense,2018, arXiv preprint arXiv:1803
 Boost-ing adversarial attacks with momentum,2018, In Proceedings of the IEEE Conference on ComputerVision and Pattern Recognition
 Exploringmemorization in adversarial training,2021, arXiv preprint arXiv:2106
 A study of the effect of jpgcompression on adversarial images,2016, arXiv preprint arXiv:1608
 Evaluating and understanding the robustnessof adversarial logit pairing,2018, arXiv preprint arXiv:1807
 The difficulty of training sparseneural networks,2019, arXiv preprint arXiv:1906
 Rigging the lottery:Making all tickets winners,2943, In International Conference on Machine Learning
 Rigging the lottery:Making all tickets winners,2020, In Hal Daume In and Aarti Singh (eds
 Linear modeconnectivity and the lottery ticket hypothesis,2020, In ICML
 Deepcloak: Masking deep neuralnetwork models for robustness against adversarial samples,2017, arXiv preprint arXiv:1702
 Explaining and harnessing adversarialexamples,2015, In International Conference on Learning Representations
 Countering adversarialimages using input transformations,2018, In International Conference on Learning Representations
 Sparse dnns with improved adver-sarial robustness,2018, arXiv preprint arXiv:1810
 Learning both weights and connections forefficient neural network,2015, In Advances in neural information processing systems
 Deep residual learning for image recog-nition,2016, In CVPR
 Channel pruning for accelerating very deep neural net-works,2017, In Proceedings of the IEEE International Conference on Computer Vision
 Distilling the knowledge in a neural network,2015, arXivpreprint arXiv:1503
 Averaging weights leads to wider optima and better generalization,2018, arXiv preprintarXiv:1803
 Adversariallyrobust learning via entropic regularization,2020, arXiv preprint arXiv:2008
 Top-kast:Top-k always sparse training,2021, arXiv preprint arXiv:2106
 Robust pre-training by adversarialcontrastive learning,2020, arXiv preprint arXiv:2010
 Learning multiple layers of features from tiny images,2009, Masterâ€™sthesis
 Optimal brain damage,1990, In Advances in neuralinformation processing systems
 Adversarial vertex mixup: Toward better adver-sarially robust generalization,2020, In Proceedings of the IEEE/CVF Conference on Computer Visionand Pattern Recognition
 Towards practical lottery ticket hypothesis for adversarial training,2020, arXiv preprintarXiv:2003
 Defense against adversarial attacks usinghigh-level representation guided denoiser,2018, In 2018 IEEE/CVF Conference on Computer Visionand Pattern Recognition
 Selfish sparse rnntraining,2021, arXiv preprint arXiv:2101
 Do we actually needdense over-parameterization? in-time over-parameterization in sparse training,2021, arXiv preprintarXiv:2102
 Towards robust neural networks viarandom self-ensemble,2018, In Proceedings of the European Conference on Computer Vision (ECCV)
 Learn-ing efficient convolutional networks through network slimming,2017, In Proceedings of the IEEEinternational conference on computer vision
 To-wards deep learning models resistant to adversarial attacks,2018, In International Conference on Learn-ing Representations
 To-wards deep learning models resistant to adversarial attacks,2018, In International Conference on Learn-ing Representations
 A topological insight into restricted boltzmann machines,2016, Machine Learning
 Variational dropout sparsifies deep neuralnetworks,2017, In International Conference on Machine Learning
 Importance estimationfor neural network pruning,2019, In Proceedings of the IEEE Conference on Computer Vision andPattern Recognition
 Adversarial robustness may be at odds with simplicity,2019, arXiv preprintarXiv:1901
 Training adversarially robust sparse networks via bayesianconnectivity sampling,8314, In International Conference on Machine Learning
 Bag of tricks for adversarialtraining,2021, In International Conference on Learning Representations
 Adversarialtraining can hurt generalization,2019, In ICMLW
 Sparse weight activation training,2020, arXiv preprintarXiv:2001
 Universalityof deep neural network lottery tickets: A renormalization group perspective,2021, arXiv preprintarXiv:2110
 Comparing rewinding and fine-tuning in neuralnetwork pruning,2020, In International Conference on Learning Representations
 Overfitting in adversarially robust deep learning,8093, InHal Daume In and Aarti Singh (eds
 Ad-versarially robust generalization requires more data,2018, In NeurIPS
 Towards compact and robust deepneural networks,2019, arXiv preprint arXiv:1906
 Hydra: Pruning adversarially robustneural networks,2020, arXiv preprint arXiv:2002
 Grad-cam: Visual explanations from deep networks via gradient-based local-ization,2017, In Proceedings of the IEEE international conference on computer vision
 Very deep convolutional networks for large-scale imagerecognition,2014, arXiv preprint arXiv:1409
 Low curvature activations reduce overfit-ting in adversarial training,2021, arXiv preprint arXiv:2102
 Smoothgrad:removing noise by adding noise,2017, arXiv preprint arXiv:1706
 Robust local featuresfor improving the generalization of adversarial training,2019, arXiv preprint arXiv:1909
 Relating adversarially robust generalization to flatminima,2021, arXiv preprint arXiv:2104
 Con-sistency regularization for adversarial robustness,2021, arXiv preprint arXiv:2103
 Pruning neural networkswithout any data by iteratively conserving synaptic flow,2020, arXiv preprint arXiv:2006
 Connectivity matters: Neural network pruning through the lensof effective sparsity,2021, arXiv preprint arXiv:2107
 Bilateral adversarial training: Towards fast training of morerobust models against adversarial attacks,2019, In Proceedings of the IEEE International Conferenceon Computer Vision
 Defending dnn adversarial attacks withpruning and logits augmentation,2018, In 2018 IEEE Global Conference on Signal and InformationProcessing (GlobalSIP)
 Fast is better than free: Revisiting adversarial training,2020, InInternational Conference on Learning Representations
 Adversarial weight perturbation helps robust gener-alization,2020, In NeurIPS
 Steepest descent neural architecture opti-mization: Escaping local optimum with signed neural splitting,2020, arXiv preprint arXiv:2003
 Mitigating adversarialeffects through randomization,2018, In International Conference on Learning Representations
 Feature squeezing: Detecting adversarial examples in deepneural networks,2017, arXiv preprint arXiv:1704
 Procrustes: a dataflow and accelerator for sparse deep neural network training,2020, In 202053rd Annual IEEE/ACM International Symposium on Microarchitecture (MICRO)
 Adversarial robustness vs,2019, model compression
 Drawing early-bird tickets: Toward more efficient training ofdeep networks,2020, In International Conference on Learning Representations
 Attacks which do not kill training make adversarial learning stronger,2020, In Internationalconference on machine learning
 Efficient lottery ticket finding:Less data is more,2021, In International Conference on Machine Learning
 Im-proving white-box robustness of pre-processing defenses via joint adversarial training,2021, arXivpreprint arXiv:2106
 Less is more: Towards compact cnns,2016, In EuropeanConference on Computer Vision
 Revisiting adversarial robustness distilla-tion: Robust soft labels make student better,2021, arXiv preprint arXiv:2108
