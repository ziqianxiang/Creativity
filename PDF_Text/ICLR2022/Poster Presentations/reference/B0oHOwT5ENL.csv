title,year,conference
 Iterative procedures for nonlinear integral equations,1965, Journal of the ACM(JACM) 
 Learning to learn by gradient descent by gradientdescent,2016, In Neural Information Processing Systems
 Deep equilibrium models,2019, In Neural InformationProcessing Systems
 Multiscale deep equilibrium models,2020, In NeuralInformation Processing Systems
 Stabilizing equilibrium models by Jacobianregularization,2021, In International Conference on Machine Learning (ICML)
 Language models arefew-shot learners,2020, arXiv:2005
 A class of methods for solving nonlinear simultaneous equations,1965, Mathematicsof Computation
 Neural ordinary differen-tial equations,2018, In Neural Information Processing Systems
 Training deep nets with sublinearmemory cost,2016, arXiv:1604
 Theory of ordinary differential equations,1955, Tata McGraw-Hill Education
 The Cityscapes dataset for semantic urbanscene understanding,2016, In Computer Vision and Pattern Recognition (CVPR)
 Language modeling with gatedconvolutional networks,2017, In International Conference on Machine Learning (ICML)
 ImageNet: A large-scalehierarchical image database,2009, In Computer Vision and Pattern Recognition (CVPR)
 BERT: Pre-training of deepbidirectional transformers for language understanding,2019, In NAACL-HLT
 Animage is worth 16x16 words: Transformers for image recognition at scale,2020, arXiv preprintarXiv:2010
 Augmented neural ODEs,2019, In Neural InformationProcessing Systems
 HoW to train yourneural ODE,2020, arXiv:2002
 Fixedpoint netWorks: Implicit depth models With Jacobian-free backprop,2021, arXiv:2103
 Deep equilibrium architectures for inverseproblems in imaging,2021, arXiv:2102
 FFJORD:Free-form continuous dynamics for scalable reversible generative models,2019, In International Confer-ence on Learning Representations (ICLR)
 Implicit graphneural netWorks,2020, In Neural Information Processing Systems
 Deep residual learning for imagerecognition,2016, In Computer Vision and Pattern Recognition (CVPR)
 Long short-term memory,1997, Neural Computation
 Neural jumP stochastic differential equations,2019, arXiv:1905
 Learning differentialequations that are easy to solve,2020, In Neural Information Processing Systems
 Adam: A method for stochastic optimization,2015, In InternationalConference on Learning Representations (ICLR)
 Learning to optimize,2016, arXiv:1606
 Learning to optimize neural nets,2017, arXiv:1703
 SGDR: Stochastic gradient descent with warm restarts,2017, InInternational Conference on Learning Representations (ICLR)
 Implicit normalizing flows,2021, InInternational Conference on Learning Representations (ICLR)
 Pointer sentinel mixturemodels,2017, In International Conference on Learning Representations (ICLR)
 Spectral normalization forgenerative adversarial networks,2018, In International Conference on Learning Representations (ICLR)
 A focused back-propagation algorithm for temporal pattern recognition,1989, ComplexSystems
 Deep contextualized word representations,2018, arXiv preprint arXiv:1802
 Hypersolvers:Toward fast continuous-depth models,2020, arXiv:2007
 Optimization as a model for few-shot learning,2016, In InternationalConference on Learning Representations (ICLR)
 The utility driven dynamic error propagation network,1987, Universityof Cambridge Department of Engineering Cambridge
 Latent ODEs for irregularly-sampled timeseries,2019, arXiv:1907
 WaveNet: A generative model forraw audio,2016, arXiv:1609
 Attention is all you need,2017, In Neural Information Processing Systems
 Anderson acceleration for fixed-point iterations,2011, SIAM Journal onNumerical Analysis
 Deep high-resolution representation learning for visual recognition,2020, IEEE Transactionson Pattern Analysis and Machine Intelligence
 SATNet: Bridging deep learning andlogical reasoning using a differentiable satisfiability solver,2019, In International Conference on MachineLearning (ICML)
 Learned optimizers that scale and generalize,2017, InInternational Conference on Machine Learning (ICML)
 Monotone operator equilibrium networks,2020, In Neural InformationProcessing Systems
 Xlnet: Generalized autoregressive pretraining for language understanding,2019, arXiv preprintarXiv:1906
