title,year,conference
 Fine-grained analysis of op-timization and generalization for overparameterized two-layer neural networks,2019, In InternationalConference on Machine Learning
 Fine-grained analysis ofoptimization and generalization for overparameterized two-layer neural networks,2019, In 36th In-ternational Conference on Machine Learning
 Learning with pseudo-ensembles,2014, Advances inneural information processing systems
 Learning two layer rectified neural networksin polynomial time,2019, In Conference on Learning Theory
 A discriminative model for semi-supervised learning,2010, Jour-nal of the ACM (JACM)
 Rademacher and gaussian complexities: Risk bounds andstructural results,2002, Journal of Machine Learning Research
 Remixmatch: Semi-supervised learning with distribution matching and augmenta-tion anchoring,2019, In International Conference on Learning Representations
 Mixmatch: A holistic approach to semi-supervised learning,2019, arXiv preprintarXiv:1905
 Training a 3-node neural network is np-complete,1992, NeuralNetworks
 Sgd learns over-parameterized networks that provably generalize on linearly separable data,2018, In InternationalConference on Learning Representations
 Unlabeleddata improves adversarial robustness,2019, Advances in Neural Information Processing Systems
 Bigself-supervised models are strong semi-supervised learners,2020, Advances in Neural InformationProcessing Systems
 Self-training avoids using spuriousfeatures under domain shift,2020, Advances in Neural Information Processing Systems
 Gradient descent provably optimizesover-parameterized neural networks,2018, In International Conference on Learning Representations
 Self-ensembling for visual domain adapta-tion,2018, In International Conference on Learning Representations
 Guaranteed recovery of one-hidden-layer neural networksvia cross entropy,2020, IEEE Transactions on Signal Processing
 Unsupervised domain adaptation by backpropagation,2015, InInternational conference on machine learning
 Domain-adversarial training of neural net-works,2016, The journal of machine learning research
 Learning one-hidden-layer neural networks with land-scape design,2018, In International Conference on Learning Representations
 Connecting the dots with landmarks: Discrimina-tively learning domain-invariant features for unsupervised domain adaptation,2013, In InternationalConference on Machine Learning
 Semi-supervised learning by entropy minimization,2005, In Con-ference d’apprentissage CAp
 Deep self-learning from noisy labels,2019, In Proceedingsof the IEEE/CVF International Conference on Computer Vision
 Revisiting self-training for neuralsequence generation,2019, In International Conference on Learning Representations
 Neural tangent kernel: Convergence and gen-eralization in neural networks,2018, In Proceedings of the 32nd International Conference on NeuralInformation Processing Systems
 Self-training for end-to-end speech recognition,2020, InICASSP 2020-2020 IEEE International Conference on Acoustics
 Agnosticallylearning halfspaces,2008, SIAM Journal on Computing
 Tensor factorization via matrix factoriza-tion,2015, In Artificial Intelligence and Statistics
 Temporal ensembling for semi-supervised learning,2016, arXiv preprintarXiv:1610
 Efficient backprop,2012, InNeural networks: Tricks of the trade
 Pseudo-label: The simple and efficient semi-supervised learning method fordeep neural networks,2013, In Workshop on challenges in representation learning
 Deep neural networks as gaussian processes,2018, In International Conference onLearning Representations
 Overcoming catastrophic forgetting with un-labeled data in the wild,2019, In Proceedings of the IEEE/CVF International Conference on ComputerVision 
 Learning overparameterized neural networks via stochastic gradientdescent on structured data,2018, In Advances in Neural Information Processing Systems
 Convergence analysis of two-layer neural networks with ReLU activa-tion,2017, In Advances in Neural Information Processing Systems
 Learning transferable features withdeep adaptation networks,2015, In International conference on machine learning
 Virtual adversarial training: aregularization method for supervised and semi-supervised learning,2018, IEEE transactions on patternanalysis and machine intelligence
 The impact of unlabeled pat-terns in rademacher complexity theory for kernel classifiers,2011, Advances in neural informationprocessing systems
 Statistical and algorithmic insights for semi-supervisedlearning with self-training,2020, arXiv preprint arXiv:2006
 End-to-end learning of a convolutional neural network viadeep tensor decomposition,2018, arXiv preprint arXiv: 1805
 Understandingand mitigating the tradeoff between robustness and accuracy,2020, In International Conference onMachine Learning
 Training deep neural networks on noisy labels with bootstrapping,2015, In ICLR (Work-shop)
 Generalization error bounds in semi-supervised classification under the clusterassumption,2007, Journal of Machine Learning Research
 Semi-supervised self-training of objectdetection models,2005, In Proceedings of the Seventh IEEE Workshops on Application of ComputerVision (WACV/MOTION’05)-Volume 1-Volume 01
 Regularization with stochastic transfor-mations and perturbations for deep semi-supervised learning,2016, Advances in neural informationprocessing systems
 Probability of error of some adaptive pattern-recognition machines,1965, IEEE Transac-tions on Information Theory
 Fixmatch: Simplifying semi-supervisedlearning with consistency and confidence,2020, Advances in Neural Information Processing Systems
 Theoretical insights into the optimizationlandscape of over-parameterized shallow neural networks,2018, IEEE Transactions on InformationTheory
 Mean teachers are better role models: Weight-averaged consis-tency targets improve semi-supervised deep learning results,2017, In Proceedings of the 31st Interna-tional Conference on Neural Information Processing Systems
 User-friendly tail bounds for sums of random matrices,2012, Foundations of computationalmathematics
 Deep domain confusion:Maximizing for domain invariance,2014, arXiv preprint arXiv:1412
 Virtual andreal world adaptation for pedestrian detection,2013, IEEE transactions on pattern analysis and machineintelligence
 Introduction to the non-asymptotic analysis of random matrices,2010, arXiv preprintarXiv:1011
 Theoretical analysis of self-trainingwith deep networks on unlabeled data,2020, In International Conference on Learning Representations
 Self-training with noisy studentimproves imagenet classification,2020, In Proceedings of the IEEE/CVF Conference on ComputerVision and Pattern Recognition
 Billion-scale Semi-supervised learning for image classification,2019, arXiv preprint arXiv:1905
 Unsupervised word sense disambiguation rivaling supervised methods,1995, In 33rdannual meeting of the association for computational linguistics
 Guaranteed convergenceof training convolutional neural networks via accelerated gradient descent,2020, In 2020 54th An-nual Conference on Information Sciences and Systems (CISS)
 Fast learning of graph neuralnetworks with guaranteed generalizability:one-hidden-layer case,2020, In 2020 International Confer-ence on Machine Learning (ICML)
 Improved linear convergenceof training cnns with generalizability guarantees: A one-hidden-layer case,2020, IEEE Transactionson Neural Networks and Learning Systems
 Why lottery ticket wins? a the-oretical perspective of sample complexity on pruned neural networks,2021, In Thirty-fifth Conferenceon Neural Information Processing Systems (NeurIPS)
 Learning one-hidden-layer relunetworks via gradient descent,2019, In The 22nd International Conference on Artificial Intelligenceand Statistics 
 L1-regularized neural networks are improperlylearnable in polynomial time,2016, In Proceedings of The 33rd International Conference on MachineLearning
 Recovery guaran-tees for one-hidden-layer neural networks,2017, In Proceedings of the 34th International Conferenceon Machine Learning-Volume 70
 Unsupervised domain adaptation for se-mantic segmentation via class-balanced self-training,2018, In Proceedings of the European conferenceon computer vision (ECCV)
