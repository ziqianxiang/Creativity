title,year,conference
 Maximum Likelihood with Bias-Corrected Calibration is Hard-To-Beat at Label Shift Adaptation,2020, In International Conferenceon Machine Learning
 The Missing Ingredient in Zero-Shot Neural Machine Translation,2019, arXiv:1903
 Wasserstein Generative Adversarial Net-works,2017, In International Conference on Machine Learning
 Massively Multilingual Sentence Embeddings for Zero-ShotCross-Lingual Transfer and Beyond,2019, Transactions of the Association for Computational Linguis-tics
 Unsupervised Neural MachineTranslation,2018, In International Conference on Learning Representations
 Translation Artifacts in Cross-lingual TransferLearning,2020, In Proceedings of the 2020 Conference on Empirical Methods in Natural LanguageProcessing (EMNLP)
 On the Cross-lingual Transferability of Mono-lingual Representations,2020, In Proceedings of the 58th Annual Meeting of the Association for Com-putational Linguistics
 A Call for MoreRigor in Unsupervised Cross-lingual Learning,2020, In Proceedings of the 58th Annual Meeting of theAssociation for Computational Linguistics
 Regularized Learn-ing for Domain Adaptation under Label Shifts,2019, In International Conference on Learning Repre-sentations
 UXLA: A Robust Unsupervised Data Aug-mentation Framework for Zero-Resource Cross-Lingual NLP,1978, In Proceedings of the 59th AnnualMeeting of the Association for Computational Linguistics and the 11th International Joint Confer-ence on Natural Language Processing (Volume 1: Long Papers)
 Analysis of representationsfor domain adaptation,2007, In B
 Multilingual Alignment of Contextual Word Represen-tations,2020, In International Conference on Learning Representations
 Adversarial DeepAveraging Networks for Cross-Lingual Sentiment Classification,2018, Transactions of the Associationfor Computational Linguistics
 Cross-lingual Language Model Pretraining,2019, In Advancesin Neural Information Processing Systems
 XNLI: Evaluating Cross-lingual Sentence Representations,2018, InProceedings of the 2018 Conference on Empirical Methods in Natural Language Processing
 Un-supervised Cross-lingual Representation Learning at Scale,2020, In Proceedings of the 58th AnnualMeeting of the Association for Computational Linguistics
 Emerging Cross-lingual Structure in Pretrained Language Models,2020, In Proceedings of the 58th Annual Meeting ofthe Association for Computational Linguistics
 BERT: Pre-training of DeepBidirectional Transformers for Language Understanding,2019, In Proceedings of the 2019 Conferenceof the North American Chapter of the Association for Computational Linguistics: Human Lan-guage Technologies
 A Robust Self-Learning Framework for Cross-Lingual Text Classifi-cation,2019, In Q
 The Secret is in the Spectra:Predicting Cross-lingual Task Performance with Spectral Similarity Measures,2020, In Proceedingsof the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)
 Domain-Adversarial Training of Neural Net-works,1533, Journal of Machine Learning Research
 A Unified View of LabelShift Estimation,2020, In Advances in Neural Information Processing Systems
 Generative adversarial nets,2014, In Z
 On Calibration of Modern NeuralNetworks,2017, In International Conference on Machine Learning
 Explicit AlignmentObjectives for Multilingual Bidirectional Encoders,2021, In Proceedings of the 2021 Conference ofthe North American Chapter of the Association for Computational Linguistics: Human LanguageTechnologies
 Cross-lingual Multi-Level Adversarial Transfer to EnhanceLow-Resource Name Tagging,2019, In Proceedings of the 2019 Conference of the North AmericanChapter of the Association for Computational Linguistics: Human Language Technologies
 Cross-language Learning with Ad-versarial Neural Networks,2017, In Proceedings of the 21st Conference on Computational NaturalLanguage Learning (CoNLL 2017)
 Cross-Lingual Ability of MultilingualBERT: An Empirical Study,2020, In International Conference on Learning Representations
 Adversarial Learning with Contextual Embeddingsfor Zero-resource Cross-lingual Classification and NER,2019, In Proceedings of the 2019 Conferenceon Empirical Methods in Natural Language Processing and the 9th International Joint Confer-ence on Natural Language Processing (EMNLP-IJCNLP)
 The Multilingual Amazon ReviewsCorpus,2020, In Proceedings of the 2020 Conference on Empirical Methods in Natural LanguageProcessing (EMNLP)
 Cross-Lingual TransferLearning for POS Tagging without Cross-Lingual Resources,2017, In Proceedings of the 2017 Confer-ence on Empirical Methods in Natural Language Processing
 Similarity of NeuralNetwork Representations Revisited,2019, In International Conference on Machine Learning
 From Zero to Hero: On theLimitations of Zero-Shot Language Transfer with Multilingual Transformers,2020, In Proceedingsof the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)
 Unsupervised DomainAdaptation of a Pretrained Cross-Lingual Language Model,2020, In Twenty-Ninth International JointConference on Artificial Intelligence
 On the Language Neutrality of Pre-trainedMultilingual Representations,2020, In Findings of the Association for Computational Linguistics:EMNLP 2020
 Detecting and Correcting for Label Shiftwith Black Box Predictors,3122, In International Conference on Machine Learning
 Conditional adversarialdomain adaptation,2018, In S
 Adversarial Augmentation Policy Search for Domain andCross-Lingual Generalization in Reading Comprehension,2020, In Findings of the Association forComputational Linguistics: EMNLP 2020
 Hidden factors and hidden topics: Understanding rating dimen-sions with review text,2013, In Proceedings of the 7th ACM Conference on Recommender Systems
 Exploiting Similarities among Languages forMachine Translation,2013, arXiv:1309
 Analyzing the effectiveness and applicability of co-training,2000, InProceedings of the Ninth International Conference on Information and Knowledge Management
 Prevalence of neural collapse during the terminalphase of deep learning training,1091, Proceedings of the National Academy of Sciences
 MAD-X: An Adapter-BasedFramework for Multi-Task Cross-Lingual Transfer,2020, In Proceedings of the 2020 Conference onEmpirical Methods in Natural Language Processing (EMNLP)
 Improving Zero-shot Trans-lation with Language-Independent Constraints,2019, In Proceedings of the Fourth Conference on Ma-chine Translation (Volume 1: Research Papers)
 Massively Multilingual Transfer for NER,2019, In Pro-ceedings of the 57th Annual Meeting of the Association for Computational Linguistics
 Neural Transfer Learning for Natural Language Processing,2019, PhD thesis
 Strong Baselines for Neural Semi-Supervised Learning underDomain Shift,2018, In Proceedings of the 56th Annual Meeting of the Association for ComputationalLinguistics (Volume 1: Long Papers)
 Adjusting the Outputs of a Classifierto New a Priori Probabilities: A Simple Procedure,0899, Neural COmPutatiOn
 A Corpus for Multilingual Document Classification in Eight Lan-guages,2018, In PrOceedings Of the Eleventh InternatiOnal COnference On Language ResOurces andEvaluatiOn (LREC 2018)
 Domain Adaptationwith Conditional Distribution Matching and Generalized Label Shift,2020, In Advances in NeuralInformation Processing Systems
 Improving Generalization and Stabilityof Generative Adversarial Networks,2019, In International Conference on Learning RePresentations
 Do-main Adversarial Fine-Tuning as an Effective Regularizer,2020, In Findings of the Association forComPutational Linguistics: EMNLP 2020
 SwitchOut: An Efficient Data Aug-mentation Algorithm for Neural Machine Translation,1100, In Proceedings of the 2018 Conference onEmPirical Methods in Natural Language Processing
 MetaXL: Meta Representation Transformation for Low-resourceCross-lingual Learning,2021, In Proceedings of the 2021 Conference of the North American ChaPter ofthe Association for ComPutational Linguistics: Human Language Technologies
 Revisiting Knowledge Distillationvia Label Smoothing Regularization,2020, In 2020 IEEE/CVF Conference on Computer Vision andPattern Recognition (CVPR)
 Adversarial Training for UnsupervisedBilingual Lexicon Induction,1959, In Proceedings of the 55th Annual Meeting of the Association forComputational Linguistics (Volume 1: Long Papers)
 On Learning Language-Invariant Representations forUniversal Machine Translation,2020, In International Conference on Machine Learning
 Tri-training: Exploiting unlabeled data using three classifiers,2005, IEEETransactions on Knowledge and Data Engineering
