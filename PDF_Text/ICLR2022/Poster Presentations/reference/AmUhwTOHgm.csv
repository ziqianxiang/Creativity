title,year,conference
 A large annotatedcorpus for learning natural language inference,2015, In EMNLP 2015
 Semantic re-tuning with contrastive tension,2021, In ICLR 2021
 DiPair: Fast and accurate distillation for trillion-scale textmatching and pair modeling,2020, In EMNLP-findings 2020
 Dual-view distilled bert for sentence embedding,2021, In SIGIR 2021
 BERT: Pre-training of deepbidirectional transformers for language understanding,2019, In NAACL
 Simcse: Simple contrastive learning of sentenceembeddings,2021, In EMNLP 2021
 DeCLUTR: Deep contrastive learning forunsupervised textual representations,2021, In ACL-IJCNLP 2021
 Momentum contrast forunsupervised visual representation learning,2020, In CVPR 2020
 Learning distributed representations of sentencesfrom unlabelled data,2016, In NAACL 2016
 Poly-encoders: Archi-tectures and pre-training strategies for fast and accurate multi-sentence scoring,2020, In ICLR 2020
 Self-guided contrastive learning for BERT sentencerepresentations,2021, In ACL-UCNLP 2021
 Skip-thought vectors,2015, In NeurIPS 2015
 On the sentenceembeddings from pre-trained language models,2020, In EMNLP 2020
 Roberta: A robustly optimized bert pretrainingapproach,2019, arXiv preprint arXiv:1907
 An efficient framework for learning sentence representa-tions,2018, In ICLR 2018
 Decoupled weight decay regularization,2019, In ICLR 2019
 A SICK cure for the evaluation of compositional distributional semantic models,2014, InLREC 2014
 Self-distillation amplifies regularizationin hilbert space,2020, arXiv preprint arXiv:2002
 Representation learning with contrastive predictivecoding,2018, arXiv preprint arXiv:1807
 Rocketqa: An optimized training approach to dense passage retrieval foropen-domain question answering,2021, In NAACL 2021
 Sentence-BERT: Sentence embeddings using Siamese BERT-networks,2019, In EMNLP-IJCNLP 2019
 Augmented SBERT:Data augmentation method for improving bi-encoders for pairwise sentence scoring tasks,2021, InNAACL 2021
 ConSERT: Acontrastive framework for self-supervised sentence representation transfer,2021, In ACL-IJCNLP 2021
 Bootstrapped unsupervisedsentence representation learning,2021, In ACL-IJCNLP 2021
 Scheduled DropHead: A regulariza-tion method for transformer models,2020, In EMNLP-findings 2020
