title,year,conference
 The power of ensemblesfor active learning in image classification,2018, In CVPR
 Adaptive neural networksfor efficient inference,2017, In ICML
 Bagging predictors,1996, Machine learning
 Once-for-all: Train onenetwork and specialize it for efficient deployment,2020, In ICLR
 Learnable embedding space for efficient neuralarchitecture compression,2019, In ICLR
 A shortnote about kinetics-600,2018, arxiv:1808
 Fine-grained stochastic architecture search,2020, arXiv:2006
 Rethinking atrousconvolution for semantic image segmentation,2017, arXiv:1706
 The cityscapes dataset for semanticurban scene understanding,2016, In CVPR
 Animage is worth 16x16 words: Transformers for image recognition at scale,2021,2021
 X3d: Expanding architectures for efficient video recognition,2020, In CVPR
 Deep ensembles: A loss landscape per-spective,2019, arXiv:1912
 A decision-theoretic generalization of on-line learning and anapplication to boosting,1997, Journal of computer and system sciences
 Energy-efficient amortized inference with cascadeddeep classifiers,2018, In IJCAI
 On calibration of modern neuralnetworks,2017, In ICML
 Dynamic neuralnetworks: A survey,2021, arXiv:2102
 Deep residual learning for image recog-nition,2016, In CVPR
 Searching for mobilenetv3,2019, In ICCV
 Mobilenets: Efficient convolutional neural networks formobile vision applications,2017, arXiv:1704
 Densely connectedconvolutional networks,2017, In CVPR
 When ensembling smallermodels is more efficient than single large models,2020, arXiv:2005
 Simple and scalable predictiveuncertainty estimation using deep ensembles,2017, In NeurIPS
 On power lawsin deep ensembles,2020, In NeurIPS
 Cream of the crop:Distilling prioritized paths for one-shot neural architecture search,2020, In NeurIPS
 Imagenet large scale visualrecognition challenge,2015, IJCV
 Mo-bilenetv2: Inverted residuals and linear bottlenecks,2018, In CVPR
 The strength of weak learnability,1990, Machine learning
 Outrageously large neural networks: The sparsely-gated mixture-of-experts layer,2017, InICLR
 Approximation algorithms for cascading prediction models,2018, In ICML
 Going deeper with convolutions,2015, InCVPR
 Rethinkingthe inception architecture for computer vision,2016, In CVPR
 Efficientnet: Rethinking model scaling for convolutional neural net-works,2019, In ICML
 Mnasnet: Platform-aware neural architecture search for mobile,2019, In CVPR
 Fixing the train-test resolutiondiscrepancy,2019, In NeurIPS
 Convolutional networks with adaptive inference graphs,2018, In ECCV
 Synthetic depth-of-field with a single-camera mobile phone,2018, ACM Transactions on Graphics (TOG)
 Skipnet: Learning dy-namic routing in convolutional networks,2018, In ECCV
 Batchensemble: an alternative approach to efficientensemble and lifelong learning,2020, In ICLR
 Hyperparameter ensembles forrobustness and uncertainty quantification,2020, In NeurIPS
 Blockdrop: Dynamic inference paths in residual networks,2018, In CVPR
 Bignas: Scaling up neural archi-tecture search with big single-stage models,2020, In ECCV
 Shufflenet: An extremely efficientconvolutional neural network for mobile devices,2018, In CVPR
 Learning transferable architecturesfor scalable image recognition,2018, In CVPR
