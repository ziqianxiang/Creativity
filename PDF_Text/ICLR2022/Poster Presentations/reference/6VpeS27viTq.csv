title,year,conference
 Square at-tack: a query-efficient black-box adversarial attack via random search,2020, In European Conference9Published as a conference paper at ICLR 2022on Computer Vision
 Obfuscated gradients give a false sense ofsecurity: Circumventing defenses to adversarial examples,2018, In ICML
 Poisoning attacks against support vector ma-chines,2012, arXiv preprint arXiv:1206
 ToWards evaluating the robustness of neural netWorks,2017, In SP
 Rays: Aray searching method for hard-label adversarial attack,2020, InSIGKDD
 A frank-Wolfe frameWork for efficientand effective adversarial attacks,2020, In AAAI
 Zoo: Zeroth order opti-mization based black-box attacks to deep neural netWorks Without training substitute models,2017, InAISec
 Minimally distorted adversarial examples With a fast adaptive boundaryattack,2020, In ICML
 Autoaugment:Learning augmentation policies from data,2018, arXiv preprint arXiv:1805
 Imagenet: A large-scale hi-erarchical image database,2009, In 2009 IEEE conference on computer vision and pattern recognition
 Bert: Pre-training of deepbidirectional transformers for language understanding,2018, arXiv preprint arXiv:1810
 Witches¡¯ breW: Industrial scale data poisoning via gradient matching,2020, arXivpreprint arXiv:2009
 Badnets: Identifying vulnerabilities in themachine learning model supply chain,2017, arXiv preprint arXiv:1708
 Deep neural netWorksfor acoustic modeling in speech recognition,2012, IEEE Signal processing magazine
 Densely connectedconvolutional networks,2017, In Proceedings of the IEEE conference on computer vision and patternrecognition
 Unlearnableexamples: Making personal data unexploitable,2021, arXiv preprint arXiv:2101
 Metapoison: Prac-tical general-purpose clean-label data poisoning,2020, arXiv preprint arXiv:2004
 Black-box adversarial attacks with limited queries and information,2018, InICML
 Stronger data poisoning attacks break datasanitization defenses,2018, arXiv preprint arXiv:1811
 Functional adversarial attacks,2019, arXiv preprint arXiv:1906
 Gradient-based learning applied todocument recognition,1998, Proceedings of the IEEE
 Sgdr: Stochastic gradient descent with warm restarts,2016, arXivpreprint arXiv:1608
 Parsimonious black-box adversarial attacks viaefficient combinatorial optimization,2019, In ICML
 Towards poisoning of deep learning algorithms with back-gradientoptimization,2017, In Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security
 Practical black-box attacks against machine learning,2017, In Proceedings of the 2017 ACMon Asia conference on computer and communications security
 Defending neural backdoors via generative distributionmodeling,2019, arXiv preprint arXiv:1910
 Very deep convolutional networks for large-scale imagerecognition,2014, arXiv preprint arXiv:1409
 Intriguing properties of neural networks,2013, arXiv preprint arXiv:1312
 Diversity can be transferred: Output diversificationfor white-and black-box attacks,2020, Advances in Neural Information Processing Systems
 Generative poisoning attack method against neuralnetworks,2017, arXiv preprint arXiv:1703
 mixup: Beyond empiri-cal risk minimization,2018, In International Conference on Learning Representations
 Thelimitations of adversarial training and the blind-spot attack,2019, arXiv preprint arXiv:1901
