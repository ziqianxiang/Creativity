title,year,conference
 Tensorflow: A system for large-scalemachine learning,2016, In 12th USENIX Symposium on Operating Systems Design and Implementation(OSDI) 16
 Information-bottleneck under mean field initialization,2020, In Inter-national Conference on Machine Learning (ICML): Workshop on Uncertainty and Robustness inDeep Learning
 Deep variationalinformation bottleneck,2017, arXiv
 Learning representations for neural network-basedclassification using the information bottleneck principle,2019, IEEE Transactions on Pattern Analysisand Machine Intelligence
 An information theoretic view on learningof artificial neural networks,2018, In International Conference on Signal Processing and CommunicationSystems (ICSPCS)
 Comparison ofclassifier methods: a case study in handwritten digit recognition,1994, In International Conference onPattern Recognition (ICPR)
 Adaptive estimators show informationcompression in deep neural networks,2019, In International Conference on Learning Representations(ICLR)
 Utilizing information bottleneck toevaluate the capability of deep neural networks for image classification,2019, Entropy
 The MNIST database of handwritten digit images for machine learning research,2012, IEEESignal Processing Magazine
 Direct validation of the informationbottleneck principle for deep nets,2019, In Proceedings of the IEEE/CVF International Conference onComputer Vision (ICCV) Workshops
 Dissecting deep learning networks¡ªvisualizingmutual information,2018, Entropy
 Entropy and mutual information in models of deep neural networks,2019, Journalof Statistical Mechanics: Theory and Experiment
 On information plane analyses of neural network classifiers - a review,2020, arXiv
 Estimating information flow in deep neural networks,2019, In InternationalConference on Machine Learning (ICML)
 Quantizedneural networks: Training neural networks with low precision weights and activations,2017, Journal ofMachine Learning Research
 Quantization and training of neural networks for efficientinteger-arithmetic-only inference,2018, In 2018 IEEE/CVF Conference on Computer Vision and PatternRecognition
 Convergence behavior of dnns withmutual-information-based regularization,2020, Entropy
 Scalable training with information bottleneck objec-tives,2020, In International Conference on Machine Learning (ICML): Workshop on Uncertainty andRobustness in Deep Learning
 Estimating mixture entropy with pairwise distances,2017, Entropy
 Scalable mutual information estimation usingdependence graphs,2019, In IEEE International Conference on Acoustics
 Theoretical issues in deep networks,2020, Proceed-ings of the National Academy of Sciences
 Understanding learning dynamics of binary neuralnetworks via information bottleneck,2020, arXiv
 Discussion on openreview,2017,net
 On the information bottleneck theory of deep learning,2018, In International Conference onLearning Representations (ICLR)
 Learning and generalization with the informationbottleneck,2010, Theoretical Computer Science
 Information in infinite ensembles of infinitely-wideneural networks,2020, In Symposium on Advances in Approximate Bayesian Inference
 Markov information bottleneck to improve information flow instochastic neural networks,2019, Entropy
 Deep learning and the information bottleneck principle,2015, In 2015IEEE Information Theory Workshop (ITW)
 The information bottleneck method,1999, In The37¡¯th Allerton Conference on Communication
 Information plane analysis of deep neural networks via matrix-based Renyi¡¯s entropy andtensor kernels,2019, arXiv
 Understanding convolutionalneural networks with information theory: An initial exploration,2020, IEEE Transactions on NeuralNetworks and Learning Systems
