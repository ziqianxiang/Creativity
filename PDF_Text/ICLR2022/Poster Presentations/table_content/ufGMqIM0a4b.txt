Table 1: Quantitative evaluation on Flickr-Landscape. Despite we use a disadvantageous settingfor our InfinityGAN (discussed in Section 4.1), it still outperforms all baselines after extending thesize to 4× larger. Furthermore, the user study shows an over 90% preference favors our Infinity-GAN results. The preference is marked as x% when x% of selections prefer the results from theCorresPonding method over InfinityGANJ The images are first resized to 128 before resizing to 197.
Table 2: Outpainting performance. The combi-nation of In&Out (Cheng et al., 2021) and Infin-ityGAN achieves state-of-the-art IS (higher bet-ter) and FID (lower better) performance on imageoutpainting task.
Table 3: Inference speed up with parallelbatching. Benefit from the spatial independentgeneration nature, InfinityGAN achieves up to7.20× inference speed up by with parallel batch-ing at 8192×8192 pixels. The complete table canbe found in Appendix P.
Table 4: Possible coordinate designs for different types of dataset. The choice of coordinatesystem for InfinityGAN is a dataset-dependent hyperparameter.
Table 5: Inference speed up with parallel batching. Benefit from the spatial independent gener-ation nature, InfinityGAN achieves up to 7.20× inference speed up by with parallel batching. Weconduct all experiments at a batch size of 1, and OOM indicates out-of-memory. Note that the GPUtime here accounts for pure GPU execution time and (if applicable) data-parallel scatter-aggregationtime.
