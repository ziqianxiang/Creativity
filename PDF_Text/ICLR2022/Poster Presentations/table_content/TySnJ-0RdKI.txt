Table 1: The effectiveness (%) of defending against three attacks. Note that NC and NAD need anadditional local benign dataset, which is not required in DPSGD, ShrinkPad, and our method.
Table 2: The effectiveness (%) of defending against label-consistent attack on CIFAR-10 dataset.
Table 3: The ablation study of our proposed method.
Table 4: Statistics of datasets and DNNs adopted in our main experiments.
Table 5: The Effectiveness of WaNet with different kernel size k when the noise rate is set to 0 andstrength s = 1 on the ImageNet dataset.
Table 6: The Effectiveness of WaNet with different strength strength kernel size k = 224 on the ImageNet dataset.		s when the noise rate is set to 0 andS →	0.4	0.6	0.8	1BA	ɪθl^^8145^^81.32	80.98ASR	^8006^^9222^^94.23	96.22Table 7: The Effectiveness of WaNet with and without the noise mode when the kernel size k = 224and strength s = 1 on the ImageNet dataset.
Table 7: The Effectiveness of WaNet with and without the noise mode when the kernel size k = 224and strength s = 1 on the ImageNet dataset.
Table 8: Statistics of the VGGFace2 dataset and model structure adopted in our experiments.
Table 9: Defending against attacks on VGGFace2 dataset. Note that NC and NAD need an additionallocal benign dataset, which is not required in DPSGD, ShrinkPad, and our method.
Table 10: Results ofDPSGD against the BadNets and blended attack with different noise scale σ.
Table 11: Results of DPSGD against the label-consistent attack with different noise scale σ.
Table 12: Results of DPSGD against the WaNet with different noise scale σ.
Table 13: Results of the fine-tuning process in NAD against the BadNets and blended attack withdifferent learning rates η.
Table 14: Results of the fine-tuning process in NAD against the label-consistent attack with differentlearning rates η on the CIFAR-10 dataset.
Table 15: Results of the fine-tuning process in NAD against WaNet with different learning rates η.
Table 16: Results of the NAD against attacks on the CIFAR-10 dataset with different β.
Table 17: Results of the NAD against attacks on the ImageNet dataset with different β.
Table 18: Results of the NAD against attacks on the VGGFace2 dataset with different β.
Table 19: Results of the NAD against the label consistent attack on the CIFAR-10 dataset withdifferent β.______________________________________________________________________________J	Poisoning Rate J	β→ Metric J	500	1,000	1,500	2,000	2,500	5,000	0.6%	BA	92.94	91.66	90.29	85.14	73.05	18.4916		ASR	53.11	33.78	12.43	4.39	4.36	0.1	2.5%	BA	93.36	93.04	90.31	75.11	54.55	24.37		ASR	36.13	3.95	1.88	3.13	0.22	0	0.6%	BA	92.81	92.13	91.21	85.72	60.06	18.8132		ASR	52.50	57.63	38.53	9.99	1.33	0.06	2.5%	BA	93.40	92.02	90.98	86.32	68.45	20.53		ASR	48.73	17.99	6.54	2.93	1.79	0E Defending against Label-Consistent Attack with a SmallerPoisoning RateFor the label-consistent attack, except for the 2.5% poisoning rate examined in the main manuscript,0.6% is also an important setting provided in its original paper (Turner et al., 2019). In this section,we compare different defenses against the label-consistent attack with poisoning rate γ = 0.6%.
Table 20: The effectiveness (%) of defending against the label-consistent attack with 0.6% and 2.5%poisoning rate on CIFAR-10 dataset. Among all defense methods, the one with the best performanceis indicated in boldface and the value with underline denotes the second-best result. Note thatNC and NAD require to have an additional local benign dataset, which is not required in DPSGD,ShrinkPad, and our method.
Table 21: DBD against BadNets with different triggers on CIFAR-10 dataset.
Table 22: The successful filtering rate (# filtered poisoned samples / # all filtered samples, %) underdifferent ε in the target class on CIFAR-10 dataset.
Table 23: The number of remaining poisoned samples over filtered non-malicious samples onCIFAR-10 dataset._______________________________________________________________Defense J, Attack →	BadNets	Blended	WaNet	Label-ConsistentSS (ε = 500)	1801/42500	2421/42500	2500/42500	1217/42500SS (ε = 1000)	1186/35000	2067/35000	2400/35000	1115/35000AC	-0/42500^^	^^0/37786^^	5000/45546	1250/39998DBD	8/25000	6/25000	38/25000	13/25000Table 24: The BA (%) and ASR (%) of models trained on non-malicious samples filtered by SS andAC on CIFAR-10 dataset.___________________________________________________Defense →	SS (ε	=500)	SS (ε =	1000)	AC	Attack J, Metric →	BA	ASR	BA	ASR	BA	ASRBadNets	92.99	100	93.27	99.99	85.90	0Blended	92.84	99.07	92.56	99.18	77.17	0WaNet	92.69	98.13	91.92	99.00	84.60	99.02Label-Consistent	92.93	99.79	92.88	99.86	75.95	99.75Table 25: The BA (%) and ASR (%) of our DBD defending against four attacks with differentself-supervised methods on CIFAR-10 dataset.
Table 24: The BA (%) and ASR (%) of models trained on non-malicious samples filtered by SS andAC on CIFAR-10 dataset.___________________________________________________Defense →	SS (ε	=500)	SS (ε =	1000)	AC	Attack J, Metric →	BA	ASR	BA	ASR	BA	ASRBadNets	92.99	100	93.27	99.99	85.90	0Blended	92.84	99.07	92.56	99.18	77.17	0WaNet	92.69	98.13	91.92	99.00	84.60	99.02Label-Consistent	92.93	99.79	92.88	99.86	75.95	99.75Table 25: The BA (%) and ASR (%) of our DBD defending against four attacks with differentself-supervised methods on CIFAR-10 dataset.
Table 25: The BA (%) and ASR (%) of our DBD defending against four attacks with differentself-supervised methods on CIFAR-10 dataset.
Table 26: The BA (%) and ASR (%) of our DBD defending against four attacks with differentlabel-noise learning methods on CIFAR-10 dataset.
