Table 1:	Quantitative results of MoCA on the FastGAN-based architecture. FastGAN (Liu et al., 2021) istrained following the setting in original paper, which uses differentiable augmentation (DiffAug) (Zhao et al.,2020) to train the discriminator. All experiments in this table are conducted using 256x256 size images. Resultssuggest a consistent improvement from the MoCA layer across different few-shot generation datasets.
Table 2:	Quantitative results of MoCA on the StyleGAN2 base architecture. Following the setting in StyleGAN2-ADA’s original paper (Karras et al., 2020b,a), we use adaptive discriminator augmentation (ADA) to train thediscriminator. We use 64x64 image size when performing experiments on StyleGAN2 and MoCA-StyleGAN2on ImageNet-100* and COCO-300* and 256x256 image size synthesis on Animal Face Dog and Obama dataset.
Table 3: Ablation study on the improvement of MoCA comparing with GAN employing standard self-Attention (Zhang et al., 2019a)on the discriminator side do not affect MoCA’s improvement, as FastGAN based models use DiffAugwhereas StyleGAN2 based models employ the ADA technique.
Table 4: Ablation study on FastGAN + MoCA with different update mechanism4.3	Prototype Concept AnalysisHere, we demonstrate that MoCA can learn in distinct semantic concepts in an unsupervised manner,represented by the "grandmother cells" or their representatives, during adversary learning for imagesynthesis.
Table 5: Image synthesis FID by MoCA-FastGAN on CUB under different levels of noise injection.
Table 6: StyleGAN2 on CIFAR-10 with dif-ferent architectures. The first column denotesthe number of cluster in the memory, 1 in-dicates no clustering mechanism is applied.
Table 7: Quantitative results of MoCA on LS-GAN based architecture. All experiements in this tableare conducted using 64x64 size images. Results suggest a consistent improvement of MoCA layer.
Table 8: Quantitative results of MoCA on Grumpy-cat dataset.
