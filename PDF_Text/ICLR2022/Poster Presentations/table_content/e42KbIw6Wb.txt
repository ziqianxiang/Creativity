Table 1: Comparison of average precision, over multiple thresholds and object sizes, on COCOvalidation set. Each section compares different methods of the similar ResNet “backbone”. Ourmodels achieve competitive results to both Faster R-CNN and DETR baselines.
Table 2: Average precision of finetuned Pix2seq models on COCO with different backbone archi-tectures and image sizes. All models are pretrained on Objects365 dataset. As a comparison, ourbest model without pretraining obtains 45.0 AP (in Table 1) with image size of 1333×1333. Thepretraining is with 640×640 image size while fine-tuning (a few epochs) can use larger image sizes.
Table 3: Impact of sequence augmentation whenpretraining on Objects365 and finetuning onCOCO. Sequence augmentation has a major im-pact on average recall (@100) but a smaller influ-ence on AP. Most improvements can be achievedduring fine-tuning.
