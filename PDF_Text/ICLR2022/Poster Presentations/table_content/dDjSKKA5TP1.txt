Table 1: Linear evaluation and transfer learning on three benchmarks. We report the Top-1classification accuracy (%). The upper group uses a more compact backbone (AlexNet (Krizhevskyet al., 2012) or ResNet-50 (He et al., 2016)), and smaller pre-training batchsize (6 256).
Table 2: Semi-supervised learning on ImageNet. We report the Top-5 classification accuracy (%).
Table 3: Object detection and instance segmentation on COCO. We report bounding-box AP(APbb) and mask AP (APmk) on val2017 (Lin et al., 2014) (%). We use Mask R-CNN (He et al.,2017) with C4 backbone as the model, and the schedule is the default 2× in Girshick et al. (2018).
Table 4: Clustering quality on ImageNet. We compare k-means clustering (k = 1000) perfor-mance for different algorithms (mostly for deep clustering-based methods) using Normalized MutualInformation (Strehl & Ghosh, 2002) (%) for evaluation. We run k-means five times and report theaverage score with the standard deviation. All results are from the official pre-trained models.
Table 5: Effect of false negatives on self-supervised learning. We report the Top-1 classifica-tion accuracy (%) and use the results of SupCon as the oracle performance with no effect of falsenegative. ∆ represents the performance drop due to training with false negatives.
Table 6: Different strategies for pseudo label assignment and false negative removal on CIFAR-100. We report MTPR (%, ↑) and MTNR (%, ↑) of k-means clustering (k = 100) and the Top-1classification accuracy (%). Note that, [a] is the instance-level learning; [b] and [c] uses the strategyin DeepCluster (Caron et al., 2018) and PCL (Li et al., 2021) (Step scheme starts to use the pseudolabels after 100th epoch over 1000 training epochs); [g] is the final setting of the proposed method.
Table 7: Ablation comparison with PCL (Li et al., 2021) on CIFAR-100. t indicates the baselinemodel. We mark the component which is different from the baseline in red and compute the perfor-mance gaps to the baseline. The implementation of LProtoNCE and confidence estimation in PCLare directly from the official repository.
