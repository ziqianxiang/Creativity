Table 1: Rotated ModelNet10 (O(3) symmetry). * indicates wider models to fix the computational cost.
Table 2: ModelNet10 (O(2) symmetry)G	Description	Accuracy{e}	Conventional CNN	91.2 ± 0.5SO(2)	Azimuthal Symmetry	91.9 ± 0.8SO(3)	Chiral (Regular, |G| = 72)	89.8 ± 0.6O(2)	Full Azimuthal Symmetry	92.3 ± 0.4O(3)	Achiral (Regular, |G| = 120)	89.9 ± 1.0C2 o F	Klein Group (dihedral symmetry)	91.0 ± 0.6VOXNet (Maturana & Scherer, 2015)	92.0C2 o F Klein Group (Worrall & Brostow, 2018) 94.2Ligand Binding Affinity (LBA) regression We also evaluate our models on a regression task usingthe LBA dataset (Townshend et al., 2020), containing protein-ligand complexes from the PDBBinddatabase (Wang et al., 2004; Liu et al., 2014). In Townshend et al. (2020), an SO(3)-equivariantmodel with tensor product activations performed the best, despite its cost prevented training on thefull dataset. We propose a volumetric SO(3) network with a computational cost equivalent to aconventional CNN by leveraging the benefit of regular non-linearities. Tab. 3 reports our results.
Table 3: Ligand Binding Affinity dataset. * indicates wider models to fix the computational cost.
Table 4: Approximate inference times. * indicates wider models to preserve the computational cost.			G	Description	time (ms)	# params (×106){e}	Conventional CNN	41.6 ± 0.2	36I	Icosahedral Symmetry	43.1 ± 0.2	0.49SO(3)	Chiral (Gated non-linearities)	52.2 ± 0.2	0.37SO(3)	Chiral (Regular, |G| = 96)	28.2 ± 0.2	0.25SO(3)	Chiral (Regular, |G| = 192)*	51.6 ± 0.2	0.24H.8 LBA ExperimentsTo perform the LBA experiments, we use the atom3d library from Townshend et al. (2020). Inparticular, we adapted the 3DCNN example from their repository. In the example code, each testmolecule is randomly rotated at every run of the test. To make the testing procedure deterministic, wegenerate a test set by rotating each test molecule with 5 random SO(3) rotations. The occupancy gridof a molecule is generated by setting to 1 the voxel cell which is closest to each atom. This results in acoarser rendering of the data, with respect to the ModelNet10 datasets. To mitigate the discretizationnoise, we use voxels with a higher resolution of 65 pixels. Note that Townshend et al. (2020) usedvoxel grids with resolution 40 pixels. However, the larger resolution of the input data can drasticallyincrease the memory cost of the models. To prevent this, all models include a first Conv3D layerwith kernel_size = 7 and stride = 2 which immediately downsamples the input. This firstconvolution layer is then followed by 4 residual blocks. In each residual block, the stride = 2convolution is performed in the first Conv3D rather than the second. In the conventional network,
