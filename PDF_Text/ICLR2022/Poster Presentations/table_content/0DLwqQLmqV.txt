Table 1: Overview of NAS benchmarks in NAS-Bench-Suite.
Table 2: Average relative performance ranking among five NAS algorithms (left) or five performancepredictors (right) across 25 settings. Results are weighted by search space; e.g., each of the threeNAS-Bench-201 benchmarks are weighted by 1/3. For abbreviations, see Table 3.
Table 4: A comprehensive overview of NAS benchmarks.
Table 5: Raw values from the performance predictor hyperparameter transferability experiment fromFigure 5 (left). Each search space has 0-1 scaling done to fairly compare trends between searchspaces. Results are weighted by search space. E.g., each of the three NAS-Bench-201 benchmarksare averaged into one row/column.
Table 6: Raw values from the black-box algorithm hyperparameter transferability experiment fromFigure 5 (right). Each search space has 0-1 scaling done to fairly compare trends between searchspaces. Results are weighted by search space. E.g., each of the three NAS-Bench-201 benchmarksare averaged into one row/column.
Table 7: Summaries from the performance predictor transferability experiment from Figure 5 (left).
Table 8: Summaries from the black-box algorithm transferability experiment from Figure 5 (right).
Table 9: Leave one out experiments for performance predictors. For a search space A, the besthyperparameter setting on average over all search spaces except A is computed, and compared againstthe best hyperparameter setting of search space A When transferring to (or from) search space A.
Table 10: Correlation insights for five NAS algorithms (left) or five performance predictors (right).
