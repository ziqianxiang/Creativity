Table 1: Hyper-parameters setting in our experimentsParameters	CIFAR10		ImageNet		Untargeted	Targeted	Untargeted	TargetedPopulation size (P)	10	10	10	10Initialization rate (α)	0.004	0.004	0.004	0.004Mutation rate (μ)	0.04	0.01	0.004	0.001A.3 Robustness to Hyper-Parameters and Investigating Recombination andMutation SchemesIn this section, we conduct comprehensive experiments to study the impacts of hyper-parametersused in our algorithm and different recombination and mutation schemes we considered. Theseexperiments are carried on 1,000 randomly selected images from CIFAR10 in an untargeted setting.
Table 2: Median sparsity and ASR at different query budgets. A comprehensive comparison amongdifferent attacks (PGD0, Pointwise and SparseEvo) on small and large scale balance datasets.
Table 3: Accuracy of ResNet50 and ViT under attacks at different query budgets and sparsity thresh-olds. A comprehensive comparison among different attacks (PGDq and SparseEvo) on small andlarge scale balanced evaluation sets from ImageNetSetting	Methods~~	Query Budget	ReSNet50		ViT	Sparsity			0.002	0.004	0.002	0.004	PGDo	na	5%	0.0%	31%	14%Untargeted	SparseEvo	2000	20%		45%	25%		5000	17%	0.0%	35%	7%	SParSity				0.02	0.03	0.02	0.03	PGDo	na	2.0%	1.2%	4.4%	0.2%Targeted	SparseEvo	10000	66.8%	52.8%	20%	9.0%		20000	2.2%	0.6%	2.4%	0.2%A.6 Algorithmic Comparison with PointWiseIn this section, we discuss why SparseEvo is capable of searching for a desirable solution (an adver-sarial example with a smaller number of perturbed pixels) with much fewer queries.
Table 4: Mean sparsity measure at different queries (lower is better) for a targeted attack setting. Acomparison between SparseEvo and improved Pointwise on a set of 100 image pairs on ImageNet(here PW-np denotes PointWise with number of selections set to np and italicised fonts indicate thebest results for PW.)Query Budgets	1	500	1000	2000	4000	8000	12000	16000	20000PW(published version)	T00^	1.00	1.00	1.00	1.00	1.00	1.00	1.00	1.00PW-4	1.00	1.00	1.00	1.00	1.00	0.99	0.97	0.93	0.88PW-8	1.00	1.00	1.00	1.00	0.99	0.94	0.81	0.58	0.35PW-16	1.00	1.00	1.00	0.99	0.94	0.64	0.45	0.42	0.40PW-32	1.00	1.00	0.99	0.95	0.71	0.54	0.50	0.46	0.42PW-64	1.00	1.00	0.95	0.78	0.67	0.62	0.56	0.51	0.46PW-128	1.00	0.96	0.84	0.77	0.74	0.67	0.61	0.56	0.52SparseEvo	TW	0.76	0.63	0.46	0.26	0.08	0.03	0.01	0.01PointWise randomly selects and alters one dimension (a colour channel) of a randomly selectedpixel position i, j of an image x0 ∈ RC×W×H at a time (i.e per query). Therefore, the Pointwiseformulation leads to a search space with a size of C × W × H where C is the three RGB channels,W is image width and H is image height. Consequently, it is not scalable to large image sizes, forexample ImageNet with a size of 224 × 224; this can be observed in Fig. 4 and 5.
Table 5: Mean sparsity measure at different queries (lower is better) for a targeted setting. A com-parison between l0-HSJA and SparseEvo on a set of 100 image pairs on CIFAR10Queries	1	500	1000	2000	4000	8000	12000	16000	20000l0-HSJA	TOO=	0Q22~	0.95	0.92	0.92	0.95	0.95	0.94	0.94SparseEvo	1.00	0.36	0.027	0.025	0.025	0.025	0.025	0.025	0.025A.9 A Discussion on Results with the Whitebox BaselineNotably, PGD0 is an adapted-to-l0version of the PGD attack with a projection. PGD0 simplyprojects the adversarial example generated by PGD attack onto the l0 -ball (we described the processin Appendix A.8 earlier regarding adopting non-sparse decision based attacks). This projection doesnot guarantee that a projected solution yields the best gradient descent direction for the followingiteration of PGD to find an adversarial example that minimises l0 . Hence, even with full access tothe model, PGD0 may not always yield the optimal solution but rather an approximation. So PGD0may not always be an upper bound for the attack performance, particularly in the untargeted settingon ImageNet as shown in Figure 5(b) and the second plot of Figure 6.
