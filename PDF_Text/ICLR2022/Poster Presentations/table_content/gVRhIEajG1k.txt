Table 1: Transferability against normal models: the success rates of black-box attacks (untargeted)crafted on RN50, RN152, DN121 and DN201.
Table 2: Top-5 accuracy on different target models when predicting the black-box adversarial exam-ples crafted (untargeted) on RN50, RN152, DN121 and DN201. The best results are in bold.
Table 3: Transferability against normal models: the success rates (%) of black-box attacks crafted(targeted) on RN50, RN152, DN121 and DN201. The best results are in bold. The results areaveraged on 8 different target classes.
Table 4: Transferability against robustly trained models: the success rates of black-box attackscrafted on source models: ResNet-50, ResNet-152, DenseNet121 and DenseNet201.
Table 5: Transferability against different models: the success rates of black-box attacks (untargeted)crafted on an ensemble of 3 models (RN34, RN152 and DN201). The best results are in bold.
Table 6: Transferability against normal models: the success rates of black-box attacks crafted onVGG16 and VGG19 (DNNs without skip connection). The best results are in bold.
Table 7: Transferability against different models: the success rates of black-box attacks (untargeted)crafted on ResNet-50 and ResNet-152. The best results are in bold.
Table 8: The attack success rate when applying different types of corruption on the LDD and HDDagainst different target models (VGG19, RN50, DN121). The best results are in bold.
Table 9: Top-1/Top-5 accuracy on different defense models when predicting the black-box adver-sarial examples crafted by different methods on RN50. We consider two strengths of adversarialperturbation ( = 16 and = 24). The best results are in bold.
Table 10: The attack sUccess rate when Using different optimizing methods to choose strUctUralhyperparameters. The best results are in bold.
