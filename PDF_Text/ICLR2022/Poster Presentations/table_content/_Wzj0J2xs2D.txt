Table 1: Quantitative results on the DTU evaluationdataset (lower is better).
Table 2: Evaluation of estimated depth with differentimage resolutions on DTU (higher is better).
Table 3: Performance comparisons (F-score) of various reconstruction algorithms on the intermediate se-quences of the Tanks & Temples benchmark. The higher value of F-score implies better reconstruction results.
Table 4: Comparison between our learnable curvature and the original curvature (Xu et al., 2020). All modelsare trained on a subset of DTU training set, using the same setups and hyperparameters. The evaluation ofdepth map and pointcloud is collected on DTU validation and test set, respectively.
Table 6: The accuracy of estimated depth overdifferent stages in our CDS-MVSNet. The entireMVS network is trained on DTU training set. Thetrained model is used to evaluate on the DTU testset at the resolution 1536 × 1152Table 5: Impact of the number of candidate scales in CD-SConv layer. The models are trained on DTU training setat the resolution 320 × 256, without 3D cost regulariza-tion. The statistics below are collected on DTU valida-tion set.
Table 5: Impact of the number of candidate scales in CD-SConv layer. The models are trained on DTU training setat the resolution 320 × 256, without 3D cost regulariza-tion. The statistics below are collected on DTU valida-tion set.
