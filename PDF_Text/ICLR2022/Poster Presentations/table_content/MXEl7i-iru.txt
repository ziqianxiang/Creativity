Table 1: Comparison of our method GraphENS with other baselines in extremely class-imbalanced settings(Imbalance ratio:100). We report the averaged accuracy, balanced accuracy, and F1-score with the standarderrors for 5 repetitions on three benchmark datasets for node classification tasks.
Table 2: Results on AmazonPhoto and AmazonComputers in Table 3: Ablation study. SM, NS, andcomparison to baselines. The experiment was repeated 5 times and PS denote saliency masking, neighbor sam-standard errors are reported. Note that the Acc. is equal to bAcc. pling, and prediction similari,ty, respectively.
Table 4: Comparison of our method GraphENS with other baselines in semi-supervised learning settings. Wereport the averaged accuracy, balanced accuracy, and F1-score with the standard errors for 5 repetitions.
Table 5: The results of node replacing (node memorization) and neighbor replacing (neighbor memorization)experiments on five benchmark datasets. We report the averaged accuracy for 5 repetitions.
Table 6: Accuracy/F1-score on AmazonPhoto and AmazonComputers benchmark datasets in comparisonto other baselines. The experiment was performed five times and the averaged accuracy and F1-score withstandard error are reported. Note that the accuracy is equal to balance accuracy since the test sets are balanced.
Table 7: Comparison of our method GraphENS with other baselines in semi-supervised learning settings(public split). We report the averaged accuracy, balanced accuracy, and F1-score with the standard errors for 5repetitions on three benchmark datasets for node classification tasks.
Table 8: Evaluation of GraphENS with other baselines in semi-supervised learning settings (random split).
Table 9: Data summary - Label distribution of training datasets [%]Dataset	Domain	L0	Li	L2	L3	L4	L5	L6	L7	L8	L9Cora-Semi	Citation Network	23.26	23.26	23.26	23.26	2.33	2.33	2.33	-	-	-Cora-LT		54.04	25.04	11.57	5.39	2.38	1.11	0.48	-	-	-CiteSeer-Semi	Citation Network	30.30	30.30	30.30	3.03	3.03	3.03	-	-	-	-CiteSeer-LT		60.72	24.06	9.49	3.76	1.47	0.49	-	-	-	-PubMed-Semi	Citation Network	83.33	8.33	8.33	-	-	-	-	-	-	-PubMed-LT		90.10	9.01	0.89	-	-	-	-	-	-	-AmazonPhoto	Co-Purchase Graph	31.58	26.64	11.70	11.06	9.92	7.59	1.12	0.39	-	-AmazonComputers	Co-Purchase Graph	44.26	17.07	16.94	10.35	4.95	2.45	1.96	1.49	0.34	0.18F.2 ArchitectureWe evaluate our method with three representative GNN architectures - GCN (Kipf & Welling, 2017),GAT (Velickovic et al.), and GraphSAGE (Hamilton et al., 2017). In this section, we describethe detailed architecture of each GNN. For GCN, our model consists of l GCN layers with ReLUactivation, followed by dropout Srivastava et al. (2014) with 0.5 dropping rate and a linear classifier.
