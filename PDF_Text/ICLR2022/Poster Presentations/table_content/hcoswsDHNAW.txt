Table 1: The performance of vanilla training, AdvProp, same-budget AdvProp, and Fast AdvProp onvarious datasets. â†‘/] indicate the higher/lower the better.
Table 2: The performance of AdvProp with different settings. +AdvProp denotes the originalAdvProp. +1 ITER denotes the AdvProp with PGD-1 attacker. +DECOUPLED denotes the decoupledtraining where only a small portion (e.g., 20% here) of training images are used for generatingadversarial examples. The last column reports the corresponding training budget in one epoch.
Table 3: The ImageNet accuracy and robustness generalization of vanilla training and Fast AdvProp.
Table 4:	Ablation study on the influence of the percentage of the adversarial images.
Table 5:	Ablation study of the effects on re-balancing samples and synchronizing updating speed.
Table 6:	Robustness when combining our Fast Advprop with existing data augmentation methods.
Table 7:	object detection mAp(%) and robustness measurements on coco and coco-c.
