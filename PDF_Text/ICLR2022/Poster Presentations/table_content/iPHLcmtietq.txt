Table 1: Error of linear classifiers applied to a scattering (Scat), learned scattering (LScat) andlearned scattering with skip connections (+ skip), on CIFAR-10 and ImageNet. The last columngives the single-crop error of ResNet-20 for CIFAR-10 and ResNet-18 for ImageNet, taken fromhttps://pytorch.org/vision/stable/models.html.
Table 2: Top-1 error (in %) on CIFAR-10 with a linear classifier applied to a Scattering network(Scat) and several Learned Scattering networks (LScat) with several non-linearities. They include amodulus (Mod), an amplitude soft-thresholding (Thresh), an amplitude hyperbolic tangent (ATanh),an amplitude sigmoid (ASigmoid), and an amplitude Soft-sign (ASign).
Table 3: Classification errors on ImageNet of bias-free ResNet-18 (BFResNet) architectures withseveral non-linearities. They include a ReLU, an absolute value which performs sign collapses (Abs),a soft-thresholding (Thresh), a hyperbolic tangent (Tanh), and a soft-sign (Sign). They are comparedto the original ResNet-18 architecture, which uses a ReLU and learns biases.
Table 4: Number cj of complex output channels of Pj, 1 ≤ j ≤ J. The total number of projectors isJ = 8 for CIFAR and J = 11 for ImageNet.
Table 5: Number of real parameters (in millions) of Learned Scattering network architectures. Acomplex parameter is counted as two real parameters.
