Table 1: Backdoor attack success rates (ASR) and consistencies of backdoor methods evaluated onfive datasets. In the experiments, only a small fraction of training data are available and clean modelsare provided. The detailed definition of metrics is provided in Section 2.3. Here ASR+ACC meansthe sum of ASR and Top-1 ACC compared to BadNets. Best results are denoted in bold.
Table 2: Backdoor attack success rates (ASR) and consistencies of logit anchoring compared toknowledge distillation (KD) methods and hidden state anchoring methods on CIFAR-10. The cleanmodel is trained on the full dataset, and only 640 images are available in backdoor training. AWPdenotes whether perturbations are AWPs. Clean accuracies of small, mid, and large teachers are93.87%, 94.55%, and 94.58%, respectively.
Table 3: Backdoor attack success rates (ASR) and consistencies of backdoor methods evaluated onthe CIFAR-10 dataset with different data accessibility and training settings. AWP denotes whetherperturbations are AWPs. As analyzed in Section 3.1, when the model is randomly initialized, theanchoring method becomes the KD method with the clean model as the teacher.
Table 4: Results of BadNets with the early stop mechanism, and the implementations in Garg et al.
