Table 1: Mean Chamfer loss and 95% confidence interval over 6 runs. Methods in italic are thoseused in the original papers for TSPN (Kosiorek et al., 2020) and DSPN (Zhang et al., 2019) Resultdiffer from the original papers due to a difference in the loss computation (cf. Appendix D.1).
Table 2: Bounding box prediction on CLEVR. The metric is the average precision on the test set fordifferent intersection-over-union thresholds, computed over 6 runs (higher is better).
Table 3: Full scene prediction on CLEVR. The metric is the average precision on the test set, com-puted over 6 runs (higher is better). While MLP and i.i.d. sampling have better training metrics,Top-n generalizes much better to new images.
Table 4: Mean and 95% confidence interval over 5 runs on synthetic molecule-like data in 3d.
Table 5: Molecular graph generation on QM9. Baseline results are from the original authors. Our ar-chitecture provides an effective approach to one-shot molecule generation. Apart from independentsampling creation, the different set creation methods seem to be equivalent in this setting.
Table 6: Train reconstruction error and valency loss in the generated sets over 5 runs for a modifiedversion of our dataset, where the cardinality varies less across sets. We observe a tradeoff betweenreconstruction performance and generalization.
