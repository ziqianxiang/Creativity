Table 1: The four datasets used in our experiments.
Table 2: Performance comparison on UCI-HAR dataset.
Table 3: Performance comparison on OPPORdataset.
Table 4: Performance comparison on BCI- CIV2a dataset.		Table 5: Performance comparison on NinaPro dataset.	Methods	BCICIV2a	Methods	NinaPro	Accuracy		AccuracyCTCNN	0.4767 ± 0.1506	GengNet	0778EEGNet	0.5130 ± 0.0518	MV-CNN	0.874EEG Image	0.3270 ± 0.0430	TCN	0.898Cascade model	0.3183 ± 0.0399	HuNet	0.870Parallel model	0.3267 ± 0.4499	WeiNet	0.850NG-CRAM	0.6011 ± 0.0996	XceptionTime	0.918MIN2Net	06033 ± 00924	DLPR	0.911T-WaveNet	0.6301 ± 0.Q212~	T-WaveNet	0.932 ± 0.0103~Muscular movement recognition (NinaPro DB1)As shown in Table 5, T-WaveNet achieves a relative 6.65% improvement over WeiNet (Wei et al.,2019) that trains a CNN classifier on hand-crafted features, and 1.52% improvement over Xcep-tionTime (Rahimian et al., 2020) that solely relies on time domain features. DLPR (Pancholi et al.,2021) combines both the time- (peaks and zero-crossing) and frequency- (power spectral) domainfeatures with CNNs and achieves remarkable performance for this task. However, this solutionrequires lots of domain knowledge and much efforts to design signal-specific features, which ischallenging to be generalized to other signal types. In contrast, the proposed INN-based wavelettransform in T-WaveNet is adaptive for learning information from both time- and frequency-domain,
Table 6: Results with structural variants. “-Haar”means the frequency bisection operator is replacedby the traditional Haar wavelet. “-LS” denotes thedeep version of the Lifting Scheme. “-noF usion”means the feature fusion module is removed fromT-WaveNet.
