Table 1: Results with either training (train) or OOD instructions (test) in 500 maps (per size) of differ-ent dimensions. Note that sizes 14 and 22 are OOD for all the agents. MC refers Minecraft whereasMG to MiniGrid. Results show the average reward and standard deviation from 10 independent runs(i.r.). Values are normalized so that 100 refers to the highest performance achieved by the best runglobally in maps of the given size and benchmark. Best average rewards in each setting and size isbolded.
Table 2: Results from 5 i.r. of a vanilla BRIM (BRIM), a BRIM with residual connection (ResBRIM)and BRIM with latent goals (BRIMLG). Best results for each setting and size are in bold.
Table 3: Ablation studies in Minecraft (5 i.r. per variant). PrediNetnLoGSub and PrediNetnLoGPos arevariants of PrediNetLG without the element-wise subtraction and the feature coordinates respectively.
Table 4: Ablation studies with PrediNetLG in Minecraft (5 i.r. per variant). In the first set we explorethe impact of different bottleneck sizes. In the second we contrast having Ls task-agnostic or not.
Table 5: Two-way ANOVA test with Alpha= 0.05 in Minecraft. Neural network refers to the impactof the different neural networks in the central modules, whereas architecture configuration refers tothe impact of whether using a latent goal or a standard configuration.
Table 6: Two-way ANOVA test with Alpha = 0.05 in MiniGrid.
Table 7: Study on compositional learning with zero-shot objects and instructions. Results show theperformance obtained by each network in 200 test maps when rewards are given according to the"real goal", while the symbolic module provides the "given instruction" to the neural module. Anagent learning compositionally should have 1st row > 2nd row > 3rd row for the values within itscolumn. Also, values lower than random are only acceptable in the third row (deceptive instruction).
