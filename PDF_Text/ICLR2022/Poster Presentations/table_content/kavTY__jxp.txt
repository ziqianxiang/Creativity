Table 1: Primary objective and other summary metrics in single-objective optimization	Docking Score				Validity		Uniq.	Div.	QED	SA	1st	2nd	3rd	mean	ordinary	adjusted				REINVENT	-8.38	-7.33	-7.28	-4.66	95.1%	94.6%	95.1%	0.88	0.64	7.51JTVAE	-7.48	-7.32	-6.96	-4.55	100%	100%	34.2%	0.87	0.67	2.65GCPN	-6.34	-6.28	-6.24	-3.18	100%	78.6%	100%	0.91	0.47	5.48MolDQN	-8.01	-7.92	-7.86	-5.38	100%	100%	100%	0.88	0.37	5.04MARS		_ ^8.11 _	j7.99 _	-7.86	_ gji_	工00%	_ _99.0%	J00%_	_0.89_	_ 0.34_	_3?8- DGaPN ^ 一	-—10.07 -	二9.83 一	-9.19	-—6.77	—100%^	一 ^99.8% 一	100%^	—0.81	—0.31—	_291 一In the result table, ordinary validity is checked by examining atoms’ valency and consistency ofbonds in aromatic rings. In addition, we propose adjusted validity which further deems moleculesthat fail on conformer generation (Riniker & Landrum, 2015) invalid on top of the ordinary validitycriteria. This is required for docking evaluation, and molecules that fail this check are assigneda docking score of 0. We also provide additional summary metrics to help gain perspective ofthe generated molecules: Uniq. and Div. are the uniqueness and diversity (Polykovskiy et al.,2020); QED (Bickerton et al., 2012) is an indicator of drug-likeness, SA (Ertl & Schuffenhauer,2009) is the synthetic accessibility. QED is better when the score is higher and SA is better whenlower. Definitions of QED and SA can be found in Appendix E. On this task, DGAPN significantlyoutperformed state-of-the-art models in terms of top scores and average score, obtaining a highstatistical significance over the second best model (MolDQN) with a p-value of 8.55 × 10-209 under
Table 2: Docking scores and other metrics under differenttraining and evaluation settingsgenerated by the greedy approach, we can see that the environment and the stochasticity design ofaction space alone are powerful for the efficacy and exploration of our policies. While the innovationbonus helped discover molecules with better docking scores, it also worsened SA. We further inves-tigated this docking score vs. SA trade-off in Section 3.2.3. To see samples of molecules generatedby DGAPN in evaluation, visit our repoSitoryL3.2.2	Constrained optimizationThe goal of constrained optimization is to find molecules that have large improvement over a givenmolecule from the dataset while maintaining a certain level of similarity:rmo(sτ) = rm(ST) - λ ∙ max{0, δ - SIM{so, ST}}	(12)where λ is a scaling coefficient, for which We chose 100; SIM{∙, ∙} is the Tanimoto similaritybetween Morgan fingerprints. We used a subset of 100 molecules from our dataset as the startingmolecules, chose the two most recent and best performing benchmark models in single-objectiveoptimization to compete against, and evaluated 100 molecules generated from theirs and ours. Theresults are shown in Table 3.
Table 3: Objective improvements and molecule similarities under different constraining coefficientsMolDQN	MARS	DGAPNδ	Improvement	Similarity	Improvement	Similarity	Improvement	Similarity0	0.62 ± 0.86	0.22 ± 0.06	0.10 土 1.50	0.15 ± 0.06	1.69 ± 1.35	0.26 ± 0.180.2	0.58 ± 0.91	0.26 ± 0.07	0.02 ± 1.30	0.16 ± 0.07	1.45 ± 1.05	0.32 ± 0.210.4	0.25 ± 0.95	0.46 ± 0.09	-0.06 ± 1.20	0.16 ± 0.06	0.41 ± 1.06	0.42 ± 0.180.6	0.01 ± 0.75	0.67 ± 0.16	0.09 ± 1.23	0.17 ± 0.06	0.33 ± 0.68	0.64 ± 0.21From the results, it seems that MARS is not capable of performing optimizations with similarity con-straint. Compared to MolDQN, DGAPN gave better improvements across all levels of δ, althoughMolDQN was able to produce molecules with more stable similarity scores.
Table 4: Top QED and pLogP scores	QED			pLogP			1st	2nd	3rd	1st	2nd	3rdREINVENT	0.945	0.944	0.942	49.04	48.43	48.43JTVAE	0.925	0.911	0.910	5.30	4.93	4.49GCPN	0.948	0.947	0.946	7.98	7.85	7.80MolDQN	0.948	0.944	0.943	11.84	11.84	11.82MARS		0.948	0.948	0.948	44.99	_ 44.32 _	43.81- DGaPN ^ 一	—0.948 —	0.948 —	0.948 —	12:35	—12730 —	12722 -The results from REINVENT were produced in our own experiments, while others were directlypulled out from the original results reported in the literature.
