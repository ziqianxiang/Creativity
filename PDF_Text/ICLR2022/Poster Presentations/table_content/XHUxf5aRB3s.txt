Table 1: Dynamic regret comparisons for single-agent RL in non-stationary MDPs. S and A are thenumbers of states and actions, L is the number of abrupt changes, ∆ = Br + Bp , D is the maximumdiameter, H is the number of steps per episode, and T is the total number of steps. O(∙) suppresseslogarithmic terms.
Table 2: The proportion of the timesteps that the MAMT meets the condition of a<b to the totaltimesteps in the training procedure of different cooperative tasks.
Table 3: Default settings of our methods used in experiments.
Table 4: Default settings of MAAC used in experiments.
Table 5: Default settings of MADDPG used in experiments.
Table 6: Default settings of MAPPO used in experiments.
Table 7: Default settings of LOLA(+DQN) used in experiments.
Table 8: Tuning ranges of key hyperparameters of MAMD in experiments.
Table 9: Tuning ranges of key hyperparameters of MAMT in experiments.
Table 10: The average return of baselines and ablation algorithms in the last 1, 000 episodes ofthe training stage. The red part represents the newly added experiment results. The numbers inparentheses indicate the standard deviations under 5 (the red part is 3) different random seeds.
