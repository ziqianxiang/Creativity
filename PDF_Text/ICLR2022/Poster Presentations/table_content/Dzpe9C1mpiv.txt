Table 1: Comparisons of natural classification accuracy (Nat) and adversarial accuracies againstdifferent attacks. Best scores are highlighted in boldface.
Table 2: Robustness evaluation under different PGD attackstrengths . Avg represents for the average improvement of ourDR methods over their counterparts.
Table 3: Adversarial accuracy in the blackbox settings. Avg represents for the average improvementof our DR methods over their counterparts.
Table 4: Robustness evaluation against Auto-Attack and PGD (k = 100) with WRN-34-10 onthe full test set of CIFAR10 dataset. (*) Omit thecross-entropy loss of natural images. Detail can befound in Appendix D.
Table 5: Average norm L1 and L∞ of the perturbation δ = |xa - x|p	L1	L∞	p(δ ≤ 0.9)	p(δ ≤ )	p(δ ≤ 1.1)PGD	0.0270	0.031	19.7%	100%	100%UDR-PGD at epoch 0th	0.0278	0.031	18.9%	100%	100%UDR-PGD at epoch 200th	0.0301	0.034	19.5%	22.1%	100%Table 6: Comparison to PGD-AT with different perturbation limitations.
Table 6: Comparison to PGD-AT with different perturbation limitations.
Table 7: Robustness evaluation against C&W attack with WRN-34-10 on the full test set of theCIFAR10 dataset (10K test images). c is box-constraint coefficient. (*) Omit the cross-entropy lossof natural images.
Table 8: Result of WRM with different = 0.5∕γ on the CIFAR10 dataset.
Table 9: Comparisons of natural classification accuracy (Nat) and adversarial accuracies againstdifferent attacks. Recall results from Table 1 with additional results of WRM. Best scores arehighlighted in boldface.
Table 10: Robustness evaluation on CIFAR100 dataset. The last column “Avg” represents the averagegap of robust accuracy between our methods and their standard AT counterparts.
Table 11: Distance function and its gradient	cX (x, x0)	Vχ0 c(x,x0)	L1	Pid=1 xi-x0i	1, ∀i ∈ [1,d]L2	2 Pd=1 (Xi-Xi)2	Pid=1(x0i-xi) =	0L∞	maxi xi - x0i	1,i = argmaxi xi - xi 0, otherwiseperformance than that of TRADES); that might explain the lower gap between UDR-MART andMART with the new .
