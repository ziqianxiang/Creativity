Table 1: Point cloud completion results on MVP, MVP-40 and Completion3D datasets at the resolution of2048 points. CD loss is multiplied by 104. EMD loss is multiplied by 102. Scale factors of the two losses arethe same in all the other tables. The two losses are the lower the better, while F1 score is the higher the better.
Table 2: Completion results on MVP dataset atthe resolution of 4096, 8192, 16384 points.
Table 3: Comparison of different networkstructures in term of training the conditionalgeneration network and refinement network.
Table 4: Data augmentations used in MVP, MVP-40 and Completion3D dataset by the conditionalgeneration network, refinement network, and all baselines.
Table 5: Complete Point cloud completion results on MVP-40 dataset. The missing ratio is at 50%,25% and 12.5%,respectively. CD loss is multiplied by 104. EMD loss is multiplied by 102.
Table 6: Comparison of coarse point clouds generated by conditional generation networks of differ-ent structures on MVP dataset at the resolution of 2048 points. Experiments are conducted undertwo circumstances: with and without data augmentation. The networks without data augmentationare trained for 300 epochs, and networks with data augmentation are trained for 600 epochs. Thedata augmentation we use is specified in Table 4 for the MVP dataset. We report the networksâ€™performance on both the training set and the test set. We can see the overfitting problem is largelymitigated by data augmentation.
Table 7: Refine coarse point clouds generated by the accelerated DDPMs on the MVP dataset at theresolution of 2048 points. We can see performance drop is slight for the refined point clouds. Wealso report the average generation time ofa single point cloud evaluated on one NVIDIA GEFORCERTX 2080 Ti GPU for DDPM of different reverse steps.
