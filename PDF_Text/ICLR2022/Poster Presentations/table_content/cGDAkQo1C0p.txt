Table 1: Comparison of forecasting errors between the baselines and RevIN. The analysis on thefour datasets, ETTh1, ETTh2, ETTm1, and ECL, is conducted by increasing the prediction lengthfrom 24 to 960/1344. We report the average errors for five runs. The complete results are providedin Appendix A.14, including standard deviation and the originally reported values for the baselines.
Table 2: Comparison of long sequence forecasting performance. We analyze the forecasting errorof the baselines and RevIN by increasing the prediction length from 48 to 960 while the input lengthis fixed to 48. The experiment is conducted on ETTh1. The average errors for five runs are reported,and the complete results, including standard deviation, are provided in Appendix A.14.
Table 3: Comparison with classical and state-of-the-art normalization methods. The meansquared errors are compared on the four datasets, using N-BEATS as the baseline for all experiments.
Table 4: Forecasting performance on the air quality, Nasdaq, and M4 competition datasets.
Table 5: Cross-domain time-series forecasting results. We conduct a cross-domain evaluation onthe ETT datasets, ETTh1, ETTh2, and ETTm1. We train RevIN using SCINet as the baseline. Wereport the average errors and the standard deviation values for five runs.
Table 6: Ablation study results. We ablate the affine transformation (affine.) from RevIN and evalu-ate forecasting performance on the six datasets. N-BEATS is used as the baseline for all experiments.
Table 7: Effectiveness of RevIN when added to the intermediate layers in the model. We addRevIN to the first stack of N-BEATS and SCINet and evaluate their performance on the six datasets.
Table 8: Comparison results on similarity metrics for time series. We assess the model forecast-ing results in terms of the shape and temporal errors using the DTW and the TDI, respectively (thelower, the better). The experiments are conducted for the four datasets, using the three baselines. Wereport the average value and standard deviation of five experiments.
Table 9: Forecasting performance of RevIN in comparison with existing dynamic normaliza-tion methods. LSTNet* indicates the model where the autoregressive linear bypass module ofLST-Net is added to the baseline network. ES-RNN* indicates the model where the exponential Smooth-ing of ES-RNN is added to the baseline network. The experiments are conducted on the ETTh1,ETTh2, ETTm1, ECL, and the M4 datasets using N-BEATS as the baseline. The missing perfor-mances in the table are where the model fails to converge.
Table 10: Additional results on the comparison with classical and state-of-the-art normaliza-tion methods in Table 3 in the main manuscript. The mean squared error is measured on theETTh1, ETTh2, ETTm1, and ECL datasets. Ty indicates the prediction length. RevBN is the modi-fied version of RevIN, where the input normalization is replaced by batch normalization.
Table 11: Standard deviation values of the five runs for the comparison of long sequence fore-casting performance in Table 2 in the main manuscript.
Table 12: Complete results for the comparison of the forecasting errors in Table 1 in the main manuscript. The mean and standard deviation of the fiveindependent experiments are recorded. denotes the reported performances for the baselines in their original paper.
