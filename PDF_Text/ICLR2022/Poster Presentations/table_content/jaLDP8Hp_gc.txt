Table 1: Number of parameters in NeurHalC.2 Datasets and Training detailsScanNet. The ScanNet (Dai et al., 2017) dataset is a large-scale indoor dataset containing monoc-ular RGB videos and dense depth images, along with ground truth absolute camera poses. AsSuperGlue (Sarlin et al., 2020) and LoFTR (Sun et al., 2021), we pre-compute the visual overlapsbetween all image pairs for both training and test scenes. For the training set we sample images witha visual overlap between 2% and 50% from the ScanNet training scenes, which provides us withchallenging images to handle. We assemble 6M image pairs and randomly subsample 200k pairsat every training epoch. For testing images, we sample 2, 500 image pairs with overlaps between2% and 80% from the ScanNet testing scenes, using several bins to ensure the sampling is close tobeing uniform. For both training and testing images, we sample keypoints in the source image alonga regular grid with cell sizes of 16 pixels. We remove keypoints with invalid depth, as well as thosewhere the local depth gradient is too high, as the depth information might not be reliable. We markkeypoints falling outside the target image plane as being outpainted, and we automatically detect thekeypoints to inpaint through a cyclic projection of the source keypoints to the target image and back.
