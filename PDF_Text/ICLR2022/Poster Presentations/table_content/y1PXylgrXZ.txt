Table 1: Illustration of architectures. CONV-h-kxk-s denotes a convolution with h output chan-nels, kxk kernel size, and s stride. We consider DEQ models where a CONV layer is replaced by aIBPMON-h-kxk-s layer with an equivalently-sized convolutional operation.
Table 2: Certified robustness results. We display the average certified error and standard (clean)error for explicit and IBP-MonDEQ architectures (lower is better). We compute the mean errors over3 independent training runs, with standard deviations in parentheses. Our results show that the IBP-MonDEQ models can achieve smaller certifiably robust error than their fully explicit counterparts.
Table 3: train v.s. test for MNIST.
