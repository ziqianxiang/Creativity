Table 1: Transfer between Resnet models: Classification accuracy (%) of transfer learning from ImageNet(224 × 224) to Caltech-UCSD Bird 200 (CUB200), Stanford Dogs datasets, MIT Indoor Scene Recognition(MIT67) and Stanford 40 Actions (Stanford40). ResNet34 and ResNet18 are used as source and target networksrespectively. Best results are bolded and each experiment is repeated 3 times. *DNR: did not reportSource task	ImageNet			Target task	CUB200	Stanford Dogs	MIT67	Stanford40Scratch	39.11±0.52	57.87±0.64	48.30±1.01	37.42±0.55Finetune	41.38±2.96	54.76±3.56	48.50±1.42	37.15±3.26LwF	45.52±0.66	66.33±0.45	53.73±2.14	39.73±1.63AT	57.74±1.17	69.70±0.08	59.18±1.57	59.29±0.91LwF+AT	58.90±1.32	72.67±0.26	61.42±1.68	60.20±1.34FM	48.93±0.40	67.26±0.88	54.88±1.24	44.50±0.96L2T-ww	65.05±1.19	78.08±0.96	64.85±2.75	63.08±0.88SAaD	68.29±DNR	76.06±DNR	66.47±DNR	67.92±DNRAuto-Transfer				- full	67.86±0.70	84.07±0.42	74.79±0.60	77.40±0.74- fixed	64.86±0.06	86.10±0.08	69.44±0.41	77.27±0.32- route	74.76±0.39	86.16±0.24	75.86±1.01	80.10±0.58for Stanford40 and report results in Figure 2 (top). Auto-Transfer Route significantly improves theperformance over existing baselines. For example, at 60% training set (~60 images per class), our
Table 2: Resources used by Auto-TransferA.4 Training and Testing Performance200——FT(18-18)AΓ(18-18)AΓ(34-18)Figure 7: Above we see test accuracies as a function of training time (minutes) plotted for following archi-tectures (i) Finetuning (ResNet18 - ResNet18), (ii) AutoTransfer (ResNet18 - ResNet18), (iii) AutoTransfer(ResNet34 - ResNet18), denoted FT(18-18), AT(18-18), and AT(34-18), respectively. We significantly outper-form finetuning in all datasets.
Table 3: Classification accuracy (%) of transfer learning for matched architectures ResNet18 - ResNet18 forAuto-Transfer and Finetuning. Best results are bolded.
Table 4: Average classification accuracy (%) and average inference times of transfer learning for time matchedarchitectures using ResNet18 - ResNet18 for Auto-Transfer and ResNet34 - ResNet34 for Finetuning.
Table 5: Final source layer selected at 200th epoch for each target layer for 3 repetitions for Table 1 experiments.
Table 6: Transfer between Resnet model and VGG model: Classification accuracy (%) of transfer learningfrom TinyImageNet to CIFAR100 and VGG9. ResNet32 and VGG9 are used as source and target networksrespectively. Best results are bolded and each experiment is repeated 3 times.
Table 7: Classification accuracy (%) of transfer learning ResNet34 to ResNet18 transfer where the source-targetlayer pairs are fixed to Auto-Transfer (route) selected ones at 200th epoch from previous runs.
Table 8: Classification accuracy (%) of transfer learning ResNet34 to ResNet18 transfer where the aggregationoperator is fixed to Identity (iden), Simple Addition (sAdd), Weighted Addition (wtAdd), Linear Combination(LinComb) and Factored Reduction (FactRed).
