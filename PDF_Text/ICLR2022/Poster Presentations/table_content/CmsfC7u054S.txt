Table 1: Comparing the probability mass of the third most probable state in the stationary distribution.
Table 2: Mean ± standard deviation of expected return for: our algorithms (C-SAC, C-CEM), acontinual RL algorithm (GPMM), a POMDP algo (RNN-PPO), and SAC with a known context(FI-SAC). For soft failure experiments, we have increased the maximum applicable force by thefactor of two. Best performances are highlighted in bold.
Table 3: Mean ± standard deviation of expected return for various algorithms and tasks over threeseeds. Our contextual approaches, which marked by the letter C, are competitive with FI-SAC (SACwith full context information) and outperform NI-SAC (SAC with no context information).
Table A1: Hyper-parameters for model learning.
Table A2: Hyper-parameters for SAC experiments.
Table A3: Hyper-parameters for MPC experiments.
Table A4: Comparing the probability mass of the third most probable state in the stationary distribu-tion. We vary the cardinality of the estimated context set C and the distillation threshold εdistil . Redindicates underestimation of the distillation threshold. Reproduction of Table 1 from the main text.
Table A5: Comparing the estimated transition matrices using the metric 6@ =	ICR^------. We vary,1	1∙	1∙,方 …	1. ,11 ,.	,1	1 1 1the cardinality C and the distillation threshold εdistil .
Table A6: Mean ± standard deviation for: our algorithms (C-SAC, C-CEM), continual learningalgos (GPMM, DNNMM, ANPMM), a POMDP algo (RNN-PPO), and SAC with a known context(FI-SAC). For soft failure experiments, we have increased the maximum applicable force by thefactor of two. Reproduction of Table 2 from the main text.
