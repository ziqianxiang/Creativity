Table 1: Initial and personalized accuracy of FedAvg on CIFAR100 under various FL settingswith 100 clients. MobileNet is used. The initial and personalized accuracy indicate the evaluatedperformance without fine-tuning and after five fine-tuning epochs for each client, respectively.
Table 2: Initial and personalized accuracy of FedAvg on CIFAR100 under a realistic FL setting(N =100, f =0.1, τ =10) according to p, which is the percentage of all client data that the server alsohas. Here, the entire (or, full) network or body is updated on the server using the available data.
Table 3: Initial accuracy of FedAvg and FedBABUon CIFAR100 under various settings with 100clients. The trained head is replaced with the near-est template to calculate “w/o head” accuracy andMobileNet is used.
Table 4: Personalized accuracy of FedAvg and FedBABU on CIFAR100 according to the fine-tunedpart. The fine-tuning epochs is 5 and f is 0.1.
Table 5: Personalized accuracy comparison on CIFAR100 under various settings with 100 clients andMobileNet is used.
Table 6: Performance according to the fine-tune epochs (FL setting: f =0.1, and τ =10).
Table 7: Initial and personalized accuracy of FedProx and FedProX+BABU with μ=0.01 on CIFAR100with 100 clients and f =0.1.
Table 8: Composition of CIFAR and EMNIST.
Table 9: Personalization of the centralized models. F is trained entirely, and B is trained body-partiallyin the centralized setting.
Table 10: Initial and personalized accuracy according to momentum (m) during local updates under arealistic FL setting (N =100, f =0.1, and τ =10).
Table 11: Initial and personalized accuracy of FedAvg and FedBABU on CIFAR100 under varioussettings with 500 clients. The used network is MobileNet.
Table 12: Initial accuracy of FedAvg and FedBABU according to the existence of classifier onCIFAR10 under various settings with 100 clients. The used network is 4convNet.
Table 13: Personalized accuracy comparison on CIFAR10 under various settings with 100 clients.
Table 14: Initial accuracy comparison on CIFAR10 under various settings with 100 clients. The usednetwork is 4convNet.
Table 15: Personalized accuracy comparison on CIFAR10 under various settings with 100 clients.
Table 16: Initial and personalized accuracy of FedAvg and FedBABU on CIFAR100 under varioussettings with 100 clients. The used network is ResNet18. f is 0.1.
Table 17: Initial and personalized accuracy of FedAvg and FedBABU on CIFAR100 under varioussettings with 100 clients. The used network is ResNet50. f is 0.1.
Table 18: Personalized accuracy comparison on Dirichlet distribution-based non-IID CIFAR100 with100 clients (FL setting: f =0.1, and τ =10). The used network is MobileNet.
Table 19: Personalized accuracy comparison on EMNIST with 1488 clients (FL setting: f =0.1, andτ =10). The used network is 3convNet.
Table 20: In-distribution (ID) and out-of-distribution (OOD) accuracy of FedAvg and FedBABUbefore/after personalization under various settings with 100 clients. The used network is MobileNet.
Table 21: Initial and personalized accuracy of FedBABU on CIFAR100 under realistic FL settings(N =100, f =0.1, and τ =10) according to the p, which is the percentage of all client data that the serveralso has. Here, the body is updated only on the server using available data.
Table 22: Initial and personalized accuracy of FedProx and FedProx+BABU with μ of 0.01 onCIFAR100 with 100 clients andf of 1.0.
Table 23: FedAvg with different learning rates under realistic FL setting (f =0.1 and τ =10). We setthe body’s initial learning rate (αb) as 0.1.
Table 24: Initial and personalized accuracy of FedBABU on CIFAR100 according to the head’sorthogonality under various FL settings with 100 clients (f =0.1) . MobileNet is used.
Table 25: Personalized accuracy comparison on CIFAR100 under various settings with 100 clientsand MobileNet is used with the total epochs of 640 (f =0.1).
