Table 1: R / S classification accuracy onthe test set for ChIRo and 3D GNN base-lines. Mean and standard deviations arereported across three trials.
Table 2: Comparisons of ChIRo with baselines when classifying enantiomers as l / d and rankingenantiomers by their docking scores. Mean accuracies and standard deviations are reported on thetest sets across 5 folds (l / d) or three trials (enantiomer ranking).
Table 3: Effects of ablating components of ChIRo on test-set accuracies for the l / d classificationand enantiomer docking score ranking tasks. Mean and standard deviations are reported across 5folds (l / d) or 3 repeated trials (enantiomer ranking). The first row indicates the original ChIRo.
Table 4: Effects of ablating components of ChIRo on test-set accuracies for the l / d classification andenantiomer docking score ranking tasks, when chiral message passing is included prior to readout.
Table 5: Hyperparameters optimized for ChIRo on each task. Parameters for chiral message passingare shown, although chiral message passing is omitted in the default version of ChIRo.
Table 6: Hyperparameters selected for SphereNet on each task. See appendix A.6 for hyperparame-ter optimizations.
Table 7: Hyperparameters selected for SchNet on each task. Apart from the number of out channelsand the inclusion of a readout MLP, the default SchNet architecture was used. Note that we used thesame readout MLP architecture as in the optimized SphereNet.
Table 8: Hyperparameters selected for DimeNet++ on each task. Apart from the number of outchannels and the inclusion of a readout MLP, the default DimeNet++ architecture was used. Notethat we used the same readout MLP architecture as in the optimized SphereNet.
Table 9: Hyperparameters selected for DMPNN on each task. Following Pattanaik et al., we onlyoptimize hyperparameters for the baseline sum aggregator and extend these hyperparameters to theTetraDMPNN models.
Table 10: Hyperparameter search space for ChIRoHyperparameter	Search SpaceEConv MLP Hidden Layer Size	[32, 64, 128, 256]EConv MLP # Hidden Layers	[1,2]h0, hT , htCMP Dimension	[8, 16, 32, 64]ht, t = 1, ..., T - 1 Dimension	[16, 32, 64]# GAT Layers	[2,3,4]# GAT Heads	[1,2,4,8]fd, fφ, fα, fc Hidden Layer Size	[32, 64, 128, 256]fd, fφ, fα, fc # Hidden Layers	[1,2,3,4]f Hidden Layer Size	[32, 64, 128, 256]f # Hidden Layers	[1,2,3,4]fout Hidden Layer Size	[32, 64, 128, 256]fout # Hidden Layers	[1,2,3,4]zd, zφ , zα Dimension	[8, 16, 32, 64]CMP EConv Hidden Layer Size	[32, 64, 128, 256]CMP EConv # Hidden Layers	[1,2,3,4]# CMP GAT Layers	[1,2,3,4]# CMP GAT Heads	[1,2,4,8]γaux	log uniform (1e-4, 1e-2)
Table 11: Hyperparameter search space for SphereNetHyperparameter	Search Spacehidden-channels	[64, 128, 256]out-channels	[16, 32, 64, 128, 256]cutoff	[5.0, 10.0]num」ayers	[3,4,5]int_emb_size	[32, 64, 128]basis_emb_size_dist	8basis_emb_size_angle	8basis_emb_sizeJorsion	8out_emb_channels	[64, 128, 256]num_spherical	7num_radial	6envelope_exponent	5num_before_skip	1num_after_skip	2num_output_layers	3Readout MLP Hidden Size	[32, 64, 128, 256]Readout MLP # of Hidden Layers	[1,2,3,4]Learning Rate	log uniform (5e-5, 1e-2)
Table 12: Hyperparameter search space for DMPNNHyperparameter	Search Spacehidden_size	[300, 600, 900,1200]depth	[2, 3, 4, 5, 6]dropout	[0, 0.2, 0.4, 0.6, 0.8, 1]Max Learning Rate	log uniform (1e-5, 1e-3)Batch Size	[25, 50,100]A.6.2 SphereNetHyperparameters were also tuned for SphereNet on the R / S, l / d, and ranking enantiomers bydocking score tasks, using the same optimization methodologies as when tuning ChIRo. The hy-perparameter search space is specified in Table 11. In each of these tasks, we trained a total of 50models with different hyperparameter combinations for a maximum of 50 epochs, using the Hyper-OptSearch algorithm and the Async Hyperband Scheduler (grace period = 5, reduction factor = 3,brackets = 1) for aggressive early stopping.
Table 13: Balance of R/S labels in the R/S classification dataset.
Table 14: Balance of l / d labels in dataset.
Table 15: Frequency of R/S labels amongst enantiomers in the l / d dataset that rotate light in thepositive (d) or negative (l) direction. The balance in R/S labels indicates the lack of empiricalcorrelation between these two classification schemes.
Table 16: Effects of not learning the parameters in f and f on ChIRo,s performance on the l /d classification and the ranking enantiomers by docking score tasks. For the original, unablatedChIRo (first row), mean accuracy and standard deviations on the test sets are reported across 5 folds(l / d) or three repeated trials (enantiomer ranking). To better account for the impact of randomnetwork initializations, for the ablated models we report the mean accuracy and standard deviationson the test sets across 3 repeated trials (enantiomer ranking) or the mean, fold-averaged accuracy(e.g., mean of means) and standard error of this mean across three repeated 5-fold CV trials (l / dclassification).
