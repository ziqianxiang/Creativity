Table 1: Performance comparison among state-of-the-art (SOTA) image classifiers on CIFAR-10/100.
Table 2: Performance comparison of the architectures selected by NASI with random vs. truelabels/data on CIFAR-10. The standard method denotes the search with the true labels and data ofCIFAR-10 and each test error in the table is reported with the mean and standard deviation of fiveindependent searches.
Table 3: Comparison of the Spearman correlation and the Kendall’s tau for various training-free metrics in the three search spaces of NAS-Bench-1Shot1 on CIFAR-10.						Methods	Spearman Correlation			Kendall’s Tau			S1	S2	S3	S1	S2	S3SNIP (Lee et al., 2019b)	-0.49	-0.62	-0.79	-0.39	-0.49	-0.63GraSP (Wang et al., 2020)	0.41	0.54	0.17	0.33	0.42	0.15SynFlow (Tanaka et al., 2020)	-0.52	-0.45	-0.53	-0.42	-0.40	-0.47NASWOT (Mellor et al., 2021)	0.21	0.32	0.54	0.16	0.24	0.44NASI (conditioned)	0.62	^^0.74	0.76	0.44	0.53	0.53Table 4: The comparison among state-of-the-art (SOTA) NAS algorithms on NAS-Bench-201. The performance of the final architectures selected by NASI is reported with the mean and standard deviation of four independent trials. The search costs are evaluated on a single Nvidia 1080Ti.					Architecture	Test Accuracy (%)			Search Cost (GPU Sec.)	Search Method	C10	C100	IN-16-120		ResNet (He et al., 2016)	93.97	70.86	43.63	-	-ENAS (Pham et al., 2018)	54.30	15.61	16.32	13315	RLDARTS (1st) (Liu et al., 2019)	54.30	15.61	16.32	10890	gradientDARTS (2nd) (Liu et al., 2019)	54.30	15.61	16.32	29902	gradientGDAS (Dong & Yang, 2019)	93.61±0.09	70.70±0.30	41.84±0.90	28926	gradientNASWOT (N=10) (Mellor et al., 2021)	92.44±1.13	68.62±2.04	41.31±4.11	3	training-freeNASWOT (N=100) (Mellor et al., 2021)	92.81±0.99	69.48±1.70	43.10±3.16	30	training-freeNASWOT (N=1000) (Mellor et al., 2021)	92.96±0.81	69.98±1.22	44.44±2.10	306	training-freeTE-NAS (Chen et al., 2021)	93.90±0.47	71.24±0.56	42.38±0.46	1558	training-free
Table 4: The comparison among state-of-the-art (SOTA) NAS algorithms on NAS-Bench-201. The performance of the final architectures selected by NASI is reported with the mean and standard deviation of four independent trials. The search costs are evaluated on a single Nvidia 1080Ti.					Architecture	Test Accuracy (%)			Search Cost (GPU Sec.)	Search Method	C10	C100	IN-16-120		ResNet (He et al., 2016)	93.97	70.86	43.63	-	-ENAS (Pham et al., 2018)	54.30	15.61	16.32	13315	RLDARTS (1st) (Liu et al., 2019)	54.30	15.61	16.32	10890	gradientDARTS (2nd) (Liu et al., 2019)	54.30	15.61	16.32	29902	gradientGDAS (Dong & Yang, 2019)	93.61±0.09	70.70±0.30	41.84±0.90	28926	gradientNASWOT (N=10) (Mellor et al., 2021)	92.44±1.13	68.62±2.04	41.31±4.11	3	training-freeNASWOT (N=100) (Mellor et al., 2021)	92.81±0.99	69.48±1.70	43.10±3.16	30	training-freeNASWOT (N=1000) (Mellor et al., 2021)	92.96±0.81	69.98±1.22	44.44±2.10	306	training-freeTE-NAS (Chen et al., 2021)	93.90±0.47	71.24±0.56	42.38±0.46	1558	training-freeKNAS (Xu et al., 2021)	93.05	68.91	34.11	4200	training-freeNASI (T)	93.08±0.24	69.51±0.59	40.87±0.85	30	training-freeNASI (4T)	93.55±0.10	71.20±0.14	44.84±1.41	120	training-freeNAS methods in (Abdelfattah et al., 2021) for the comparison. Table 3 summarizes the comparison,where the results of our metric are reported under the constraint in (8). Interestingly, our metricgenerally achieves a higher positive correlation than other training-free metrics, which confirms thereasonableness and also the effectiveness of our training-free metric.
Table 5: Performance comparison among SOTA image classifiers on ImageNet. Note that architec-tures followed by C10 are transferred from the CIFAR-10 dataset, while architectures followed byImageNet are directly selected on ImageNet.
Table 6: Search with varying architecture widths N in the three search spaces OfNAS-Bench-IShotI.
Table 7: Pearson correlation between our NTK trace norm approximation and the exact NTK tracenorm in the three search spaces of NAS-Bench-1Shot1.
Table 8: Search with varying batch sizes b in the three search spaces of NAS-Bench-1Shot1.
