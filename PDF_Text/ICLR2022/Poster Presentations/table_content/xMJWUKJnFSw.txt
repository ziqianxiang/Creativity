Table 1: Node embedding sizes of state-of-the-art KG embedding models compared to BERT Large.
Table 2: Transductive link prediction on smaller KGs. f results taken from (SUn et al., 2019). | V|denotes vocabulary size (anchors + relations), #P is a total parameter count (millions). % denotes theHits@10 ratio based on the strongest model.
Table 3: Transductive link prediction on bigger KGs. The same denotation as in Table 2. SecondRotatE has a similar parameter budget as a NodePiece-based model.
Table 4: Test MRR and parameterbudget on OGB WikiKG 2.
Table 5: Inductive link prediction results, Hits@10. Best results are in bold, second best areunderlined. f results taken from TerU et al. (2020). NBFNet results taken from ZhU et al. (2021).
Table 6: Node classification results. |V | denotes vocabulary size (anchors + relations), #P is a totalparameter count (millions).
Table 7: Out-of-sample link prediction. f results are taken from (Albooyeh et al., 2020). | V| denotesvocabulary size (anchors + relations), #P is a total parameter count (millions).
Table 8: Dataset statistics. LP - link prediction, RP - relation prediction, NC - node classification,OOS - out-of-sample. In OOS-LP, Nodes also shows the amount of unseen nodes in validation/test.
Table 9: Inductive relation prediction dataset statistics. Facts denote the size of the input graph whilequeries denote the triples to be predicted. Training sets contain all queries as facts. Note that invalidation and test we receive a new graph disjoint from the training one, and queries are sent againstthis new inference graph (hence the number of entities and facts for validation and test is the same).
Table 10: NodePiece hyperparameters for transductive link prediction experimentsParameter	FB15k-237	WN18RR	CoDEx-L	YAGO 3-10	OGB WikiKG 2# Anchors, |A|	1000	500	7000	10000	20000# Anchors per node, k	20	50	20	20	20Relational context, m	15	4	6	5	12Vocabulary dim, d	200	200	200	200	200Batch size	512	512	256	512	512Learning rate	0.0005	0.0005	0.0005	0.00025	0.0001Epochs	400	600	120	600	300k (steps)Encoder type	MLP	MLP	MLP	MLP	MLPEncoder dim	400	400	400	400	400Encoder layers	2	2	2	2	2Encoder dropout	0.1	0.1	0.1	0.1	0.1Loss function	BCE	NSSAL	BCE	NSSAL	NSSALMargin	-	15	-	50	50# Negative samples	-	20	-	10	128Label smoothing	0.4	-	0.3	-	-Training time, hours	7	5.5	26	23	11Table 11: RotatE hyperparameters for transductive link prediction experiments. CoDEx-L and YAGO3-10 also list the hyperparameters (after the symbol / ) for smaller models (reported in Table 3) of the
Table 11: RotatE hyperparameters for transductive link prediction experiments. CoDEx-L and YAGO3-10 also list the hyperparameters (after the symbol / ) for smaller models (reported in Table 3) of thesame parameter budget as NodePieceParameter	FB15k-237	WN18RR	CoDEx-L	YAGO 3-10Embedding dim, d	2000	1000	1000 / 50	1000 / 40Batch size	1024	512	512 / 512	1024 / 512Loss function	NSSAL	NSSAL	NSSAL	NSSALMargin	9	6	25 / 9	24/ 15# Negative samples	256	1024	100/ 100	400 / 100A.3 Relation PredictionConfigurations (Table 12) for the compared models are almost identical to those of the transductivelink prediction experiment. We mostly reduce the number of epochs and negative samples as modelsconverge faster on this task.
Table 12: Hyperparameters for relation prediction experiments. The content is largely identical toTable 10, only changed parameters are listedParameter	NodePiece + RotatE			RotatE			FB15k-237	WN18RR	YAGO 3-10	FB15k-237	WN18RR	YAGO 3-10Batch size	512	512	512	512	512	512Epochs	20	150	7	150	150	150Loss function	NSSAL	NSSAL	NSSAL	NSSAL	NSSAL	NSSALMargin	15	12	25	9	3	5# Negative samples	20	20	20	20	20	20Training time, min	25	30	25	28	10	57Table 13: Hyperparameters for node classification experimentsParameter	NodePiece + ComPGCN	ComPGCN	MLP# Anchors, |A|	50	-	-# Anchors per node, k	10	-	-Relational context, m	5	-	-Vocabulary dim, d	100	100	100Batch size	512	512	512Learning rate	0.001	0.001	0.001Epochs	4000	4000	4000NodePiece encoder	MLP	-	-
Table 13: Hyperparameters for node classification experimentsParameter	NodePiece + ComPGCN	ComPGCN	MLP# Anchors, |A|	50	-	-# Anchors per node, k	10	-	-Relational context, m	5	-	-Vocabulary dim, d	100	100	100Batch size	512	512	512Learning rate	0.001	0.001	0.001Epochs	4000	4000	4000NodePiece encoder	MLP	-	-NodePiece encoder dim	200	-	-NodePiece encoder layers	2	-	-NodePiece encoder dropout	0.1	-	-GNN (MLP) layers	3	3	3GNN (MLP) dropout	0.5	0.5	0.5Loss function	BCE	BCE	BCELabel smoothing	0.1	0.1	0.1Training time, hours	14	22	6times for NodePiece models exclude evaluation. Training times of the baseline oDistMult were notreported by its authors.
Table 14: Hyperparameters for out-of-sample link prediction experiments. The content is largelyidentical to Table 10, only changed parameters are listedParameter	NodePiece + DistMult		oDistMult	oFB15k-237	OYAGO 3-10	oFB15k-237# Anchors, |A|	1000	10000	-# Anchors per node, k	20	20	-Relational context, m	15	5	-Vocabulary dim, d	200	200	200Batch size	256	256	1000Learning rate	0.0005	0.0005	0.01Epochs	40	40	1000NodePiece encoder	Transformer	Transformer	-NodePiece encoder dim	512	512	-NodePiece encoder layers	2	2	-NodePiece encoder dropout	0.1	0.1	-Loss function	Softplus	Softplus	Softplus# Negative samples	5	5	1Training time, hours	2	8	-B Limitations and Future WorkOur experimental results demonstrate the promise of using NodePeice to significantly reduce the
Table 15: Relation prediction results. |V | denotes vocabulary size (anchors + relations).
Table 16: Hyperparameters for inductive link prediction experiments. Entries are shared among 4splits of each graph if not particularly specified. V1 | V2 | V3 | V4 otherwise.
