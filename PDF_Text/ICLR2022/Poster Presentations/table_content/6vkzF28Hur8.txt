Table 1: Success count table for three arm manipulation tasks. Each entry represents an averagesuccess count with a standard deviation over 50 simulations with three different random seeds. Ourmethod performs better than using a single policy trained with TRPO and shows close results toLee et al. (2019). Both Lee et al. (2019) and our method approach perfect success counts (5 forRepetitive picking up, 5 for Repetitive catching, and 1 for Serve).
Table 2: Success count table for three locomotion tasks. Each entry represents an average successcount with a standard deviation over 50 simulations with three different random seeds. Our methodperforms better than using a single policy trained with TRPO and Lee et al. (2019).
Table 3: Update numbers for the arm manipulation tasks with how many interactions are required toget the success-fail data.
Table 4: Update numbers for the bipedal locomotion tasks with how many interactions are requiredto get the success-fail data.
