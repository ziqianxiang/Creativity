Table 1: Components of our instance-level evaluation scheme. Training PM on samples from PL,we comparePM(x) to PL(X) for X ∈ Σ*.
Table 2: Sample of sequences drawn from our artificial language.
Table 3: PERTURB (x) randomly ap-plies one of these perturbations to x.
Table 4: P P on validation set generated by the artificial language the LM attempts to model (val),and on real sentences sampled from OpenWebText (eng).
Table 5: GPT2-medium P P on validation set generated by the artificial language the LM attemptsto model (val), and on real sentences sampled from OpenWebText (eng) for models used in Section4.5A.4 Language Samplesx	log pL (x)he was a complete east end player .	-26.399a former harvard university graduate told cnn that in recent weeks , u.s. intelligence officials have begun to gather evidence that trump ’s campaign colluded with russia to influence the election .	-61.846in the current study , we examined whether participants in the study performed more or less “ active ” in weight loss -lrb- p = 0.05 -rrb- .	-51.6566you , the one that is the republican candidate , who is taking over the senate and government as a democrat and who is a bipartisan democrat , and you ’ve got to be able to get that done .	-92.703since the 1970s , the city has been in the midst of a landmark urban pride .	-44.9523Table 6: Sequences ancestrally sampled from the artificial language generated by GPT2-mediumwith softmax T = 0.70.
Table 6: Sequences ancestrally sampled from the artificial language generated by GPT2-mediumwith softmax T = 0.70.
Table 7: Sequences ancestrally sampled from the artificial language generated by GPT2-mediumwith softmax T = 0.85.
Table 8: Sequences ancestrally sampled from the artificial language generated by GPT2-mediumwith softmax T = 1.00.
Table 9: Sequences ancestrally sampled from the artificial language generated by GPT2-mediumwith softmax T = 1.15.
