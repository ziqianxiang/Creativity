Table 1: Difference between equivariance properties in the context of multisets. Only when satisfyingexclusive multiset-equivariance (this paper) is it enforced that order does not matter while alsoallowing equal input elements to be mapped to different output elements like in push_apart.
Table 2: Sample efficiency of equivariance properties on a task that requires separating equal elements.
Table 3: Performance on CLEVR object property set prediction task, average precision (AP) in %(mean ± standard deviation) over 8 random seeds for our results, higher is better. Slot MLP and SlotAttention results are from Locatello et al. (2020), DSPN results are from Zhang et al. (2019). DSPNis trained at 10 iterations and evaluated at 30 iterations. For Slot Attention* and f, Locatello et al.
Table 4: Extended experimental results for class-specific numbering with input set size 64 for 4 and 8classes. Data augmentation (DA) by randomly permuting the elements for the not-equivariant modelscloses the performance gap to the exclusively multiset-equivariant models on 4 classes, but not forthe slightly more complicated case of 8 classes. Accuracy in % (mean ± standard deviation) over 6seeds, higher is better.
Table 5: Full results for autoencoding sets on every dataset configuration with set size n and setelement dimensionality d, every model, and varying number of iterations. Reconstruction Huber loss(mean ± standard deviation) over 8 runs for most results, lower is better. Some dataset configurationswith DSPN use fewer runs, see Appendix E.2 for the explanation.
Table 6: Autoencoding random sets on every dataset configuration with set size n and set elementdimensionality d and varying number of iterations for set-equivariant iDSPN variants. ReconstructionHuber loss (mean ± standard deviation) over 8 runs for most results, lower is better. Some datasetconfigurations with iDSPN+mom+Sum use fewer runs due to divergent training behavior.
Table 7: Performance on CLEVR object property set prediction task, average precision (AP) in %(mean ± standard deviation) over 8 random seeds, higher is better. The first block compares iDSPNmodels that use different pooling methods (resulting in different equivariance properties), the secondblock compares iDSPN to DSPN performance in an otherwise like-to-like training setup. iDSPN +FSPool + 0.9 momentum is the same setting as shown in the main paper.
Table 8: Worst failure cases for numbering elements within a class, selected by the highest amount ofwrong numberings in one prediction. Predictions are sorted for better readability. Wrong numberingsare marked in red.
Table 9: CLEVR examples with 128x128 images, cherry-picked by difficulty (highly-occludedobjects). Incorrect attributes and Euclidean distances (d) greater than 0.25 marked in red. Ground-truth objects are ordered going from top left to bottom right diagonally, predicted objects are matchedto that ordering based on Equation 44. We choose an iDSPN run with median performance andevaluate at different iterations.
Table 10: CLEVR examples with 256x256 images, cherry-picked by difficulty (highly-occludedobjects), same examples as in Table 9. Incorrect attributes and Euclidean distances (d) greater than0.25 marked in red. Ground-truth objects are ordered going from top left to bottom right diagonally,predicted objects are matched to that ordering based on Equation 44. We choose an iDSPN run withmedian performance and evaluate at different iterations.
