Table 1: LaMer achieves competitive performance in three TST tasks. CAE (Shen et al., 2017),DelRetrGen (Li et al., 2018a), DualRL (Luo et al., 2019), Style Transformer (Dai et al., 2019), DeepLatent Seq (He et al., 2020) are popular TST models not built on LMs. TSF-DelRetGen (Sudhakaret al., 2019), IMaT (Jin et al., 2019), and STRAP (Krishna et al., 2020) are recent LM-based TSTmodels. Input Copy directly copies the source style sentence as the transfer output. GM: GeometricMean of Transfer Accuracy (ACC) and BLEU. i-PINC measures net transfer ability by not countingwords that can be directly copied from the source style sentence, as discussed in §3.2. We color ( ■)the best results, and UnderIine the second best, not including the Input Copy reference.
Table 2: Few-shot performance on Formality TST (only 1% training data available) of LaMer and other LM-based baselines. We also include a zero-shot TST method built on GPT-3 (Reif et al., 2021) for reference. We annotate Standard deviation next to the results as well.									Table 3: Compared with other baselines, LaMer re- quires neither extra data nor training additional models.		Training Data (%)	1% (0% for GPT3)					100%			Ext. Resource?	Data	ModelMethod	ACC	SIM	FL	JA,S,F	ACC	SIM	FL	JA,S,F	TSF-DelRetGen	!	!TSF-DelRetGen	16.51.4	5.51.9	90.30.1	2.61.1	54.11.4	30.50.8	98.90.1	29.70.5	IMaT	!	IMaT	35.90.4	22.10.2	23.00.4	3.20.7	59.51.2	39.71.1	99.60.1	37.40.2	STRAP	!	!STRAP Ours: LaMer	37.70.7 48.80.4	12.50.9 27.40.6	70.40.2 89.80.1	5.30.4 13.50.3	67.71.2 66.40.5	72.51.1 74.30.3	90.40.7 97.80.1	45.51.2 53.20.1	Ours: LaMer	%	%GPT-3promptTST	10.20.6	17.11.1	98.00.2	6.50.4	-	一	一	一	GPT-3promptTST	%	%LaMer is robust in few-shot settings. LaMer learns the inherent parallelism within the unsuper-vised data, which could be challenging in data scarce cases. Recent works have explored the limitsof TST in few-shot settings (Riley et al., 2021; Krishna et al., 2021), we conduct similar studies bylimiting the available training data (to 1%), aiming to answer whether or not LaMer can still providecomparable performance as others. We consider LM-based baselines which show strong resultsin Table 1. We also compare with a zero-shot prompt-based TST baseline built upon GPT-3 (Reifet al., 2021) for reference. For evaluation metrics, we use the recently proposed J -score framework(including ACCuracy, SIMilarity, and FLUenCy) (Krishna et al., 2020), which solves many of the7Published as a conference paper at ICLR 2022858075
Table 4: Further ablation on components of LaMer imitation learning (IL). dSEM : semantic coherencedistance, dOrder and dExist are sub-components of scene preservation distance dPSV . Removing allIL modules (MLE only) will cause severe drop in content preservation (BLEU), especially forchallenging TST tasks (Formality and Political Stance TST).
Table 5: Effectiveness of SAS align- Table 6: Human evaluations on the political stance transfer taskment for mining weakly parallel sen- (on a 7 point scale). We bold the highest average rating. LaMertences. Similarity: "How much Was rated significantly higher than the next-best method (p <the mined pairs are similar in style- .05). All≥5: The ratio for which the ratings are ≥ 5 for all threeindependent content?” SAS Align: PerSPeCtives.___________________________________________________“How well SAS scores reflect such sim- ■ Political Stance Style Content Readabilityilarity?” Ratings are on a 7 Point Methods					Mean 4.91 5.14 5.15	SD 1.59 1.60 1.37	Mean 4.85 4.93 4.87	SD 1.58 1.63 1.59	Mean 5.04 4.96 5.15	SD 1.68 1.60 1.53	All≥5 12% 11% 27%scale. All≥4 : The ratio for which the ratings are ≥ 4 for both questions.				CAE DelRetrGen Dual RL								Similarity	SAS									TST Tasks	MeanSD	MeanSD	All≥4 Style Transformer		5.31	1.19	5.34	1.36	5.18	1.40	28%	—			DeeP Latent Seq	5.42	0.57	5.29	1.20	5.30	1.26	25%Sentiment	5.421.36	5.561.17	88%	TSF-DelRetGen	4.87	0.65	5.23	1.14	5.20	1.13	15%Formality	5.581.14	5.741.09	82%	STARP	5.33	1.25	5.31	1.40	5.43	1.07	21%Political	5.451.17	5.431.16	74%	Ours: LaMer	5.59	1.17	5.44	1.11	5.56	1.05	37%4	Related WorkBesides the baselines we have studies in the PaPer, we notice there are other TST methods focusingon either latent vector maniPulation (Liu et al., 2020a; Wang et al., 2019; John et al., 2019) or surfacelevel editing (Castro et al., 2017; Karadzhov et al., 2017; Mansoorizadeh et al.). LaMer differs fromthem as it is learning to transfer with self-suPervision mined from the unsuPervised data, withoutcomPlicated maniPulation or editing. The idea of mining roughly Parallel demonstrations in LaMer
Table 7: Data statistics for the three TST tasks in this work: Sentiment, Formality, and Political StanceTransfer. We compare the S-Emb. + SAS aligned data (the upper part), with the human-annotatedreference file (the bottom part). Notice that after alignment, the SAS of training data becomesmuch closer to that of human reference, which demonstrates we successfully align the non-paralleldata into parallel form (comparable to the human reference). Among the three TST datasets, wefind the political stance TST has the longest sentence length (see Avg. Sent Len), and more sceneentities involved on average (see Avg. # Scene Ent. / Sent). Human written references also revealsimilar statistics (see the lower part of the table), which will potentially increase the difficulty forentity-matched transfer. We thus consider the political stance TST as a more challenging task thanthe other two.
Table 8: Human judgement results (on a 7-point scale) of seven existing methods and LaMer onsentiment transfer task. We bold the highest average rating. SD: Standard Deviation.
Table 9: Human judgement results (on a 7-point scale) of seven existing methods and LaMer onformality transfer task. We bold the highest average rating. SD: Standard Deviation.
Table 10: Perplexity measure of LaMer and other baselines. We use GPT2-large as the judgementLM, and bold the lowest perplexity (the best), and Underline the second best.
