Table 1: Success rate of off- and on-policy preference-based RL algorithms (e.g. PEBBLE andPrefPPO) in addition to RUNE with different budgets of feedback queries. The results show themean averaged and standard deviation computed over five runs and the best results are indicated inbold. All learning curves (including means and standard deviations) are in Appendix C.
Table 2: Hyperparameters of the PEBBLE algorithm.
Table 3: Hyperparameters of the SAC algorithm. Most hyperparameters values are unchanged acrossenvironments with the exception for learning rate.
