Table 1: Cifar10 test accuracy with 2-layer convolutional kernels with 3x3 patches and pool-ing/downsampling sizes [2,5], with different choices of patch kernels κ1 and κ2 . The last model issimilar to a 1-layer convolutional kernel. See Section 5 for experimental details.
Table 2: Cifar10 test accuracy for two-layer architectures with larger second-layer patches, or threelayer architectures. κ denote the patch kernels used at each layer, ‘conv’ the patch sizes, and ‘pool’the downsampling factors for Gaussian pooling filters. We include the Myrtle10 convolutionalkernel Shankar et al. (2020), which consists of 10 layers including Exp kernels on 3x3 patches and2x2 average pooling.
Table 3: Cifar10 test accuracy with 3-layer convolutional kernels with 3x3 patches and pool-ing/downsampling sizes [2,2,2], with different choices of patch kernels κ1, κ2 and κ3. The lastmodel is similar to a 1-layer convolutional kernel. Due to high computational cost, we use 10ktraining images instead of the full training set (50k images) in most cases.
Table 4: Cifar10 test accuracy on 10k examples with 2-layer convolutional kernels with 3x3 patchesat the first layer, pooling/downsampling sizes [2,5] and patch kernels [Exp,Poly2], with differentpatch sizes at the second layer.
Table 5: Cifar10 test accuracy with patch kernels that are either arc-cosine kernels (denoted ReLU) orpolynomial kernels. The 2-layer architectures use 3x3 patches and [2,5] downsampling/pooling as inTable 1. “ReLU-NTK” indicates that we consider the neural tangent kernel for a ReLU network withsimilar architecture, instead of the conjugate kernel.
Table 6: Cifar10 test accuracy for one-layer architectures with larger patches of size 6x6, exponentialkernels, and different downsampling/pooling sizes (using Gaussian pooling filters with bandwidthand size of filters proportional to the downsampling factor). The results are for 10k training samples.
Table 7: Gaussian vs average pooling for two models from Table 2.
Table 8: SVHN test accuracy for a two-layer convolutional kernel network with NystrGm approXima-tion (Mairal, 2016) with patch size 3x3, pooling sizes [2,5], and filters [256, 4096].
