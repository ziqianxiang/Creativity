Table 1: BD-rate of image codecs relative to VTM-12.1 (smaller is better).
Table 2: BD-rate of video codecs, with Conv-SSF (reproduced) as anchor.
Table 3: Decoding complexity. All models are trained with β = 0.001, evaluated on 768 × 512images (average 0.7 bpp). Decoding time is broken down into inference time of hyper-decoder hsand decoder gs, entropy decoding time of hyper-code z and code y (including inference time of theprior model if it is ChARM).
Table 4: GPU encoding complexity. All models are trained with β = 0.001, evaluated on theresolution 768 × 512 (the average bitrate is around 0.7 bpp). For the encoding time, we show thenetwork inference time for the encoder ga, the hyper encoder ha, the hyper decoder hs , the entropyencoding time for the hyper latent z and the latent y (including network inference time for the priormodel if it is ChARM). GMACs and GPU peak memory during encoding and the parameter countof the entire model are also listed.
Table 5: CPU decoding complexity. All models are trained with β = 0.001, evaluated on 768 × 512images (average 0.7 bpp). Decoding time is broken down into inference time of hyper-decoder hsand decoder gs, entropy decoding time of hyper-code z and code y (including inference time of theprior model if it is ChARM).
Table 6: CPU encoding complexity. All models are trained with β = 0.001, evaluated on theresolution 768 × 512 (the average bitrate is around 0.7 bpp). For the encoding time, we show thenetwork inference time for the encoder ga, the hyper encoder ha, the hyper decoder hs, the entropyencoding time for the hyper latent z and the latent y (including network inference time for the priormodel if it is ChARM).
Table 7: Decoding and encoding time of VTM-12.1 averaged over 24 Kodak images.
