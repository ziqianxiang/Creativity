Table 1: Model architectures of SIFAR. Thenumber in a model name indicates the window sizeused by the model before the last layer. “B” meansSWin-B. f denotes the models using 16 frames asinput and 去 indicates the models using a largerinput image resolution.
Table 2: Comparison with Baseline Meth-ods. All models use 8 frames as input.
Table 3: Comparison with Other Approaches on Kinetics400.
Table 4: Comparison with Other Approaches on SSV2.
Table 5: Comparison with Other Methods on MiT.
Table 6: Comparison with Other Approaches on Jester and Diving48.
Table 7: CNN-based SIFAR Results	On SSV2, the results of CNN-based SIFAR are less satisfactory but reasonable. This is because Model	I # FrameS ssV2 KinetiCS400	3x3 convolutions are local with a small recep-	I3D-R50 (Carreira et al., 2017) TSM-R50 (Wang et al., 2016) TAM-R50 (Fan et al., 2019)	8	61.1	72.6	tive field, thus failing to capturing long-range 8	59'1	72'2	temporal dependencies in super images. We hy-SIFAR-R50 SIFAR-R101 SIFAR-R152 × 2*	—8	508	73^—	pothesize that a larger kernel size with a wider 8	56.3	76.6	receptive field may address this limitation and —8	582	790—	potentially improve the performance of CNN-SIFAR-R50-C7 SIFAR-R50-C11 SIFAR-R50-C21 SIFAR-R50-C21-11 SIFAR-R101-C21 SIFAR-R101-C21-11 *: a model two times wider than R1	8	54.4 (+3.6)	74.4 (+1.2)	ha,QrlSrPARmCrlQk TcxzaIIrIafQfhIc vua nar 8	55 2 (+4 2)	74 5 (+1 3)	based SIFAR models. To validate this, we peι- 8	55.8 (+5.0)	74.8 (+1.6)	form additional experiments by adding one or 8	57.6 (+6.8)	75.1 (+1.9)	fwc TnCrQ raclrliial h^lcr∙"c fc thQ QnrI CfRQC'Mat 8	58.1 (+1.8)	77.7 (+1.1)	two more IeSiduaI blocks to the end of ReSNet 8	59.6(+3.3) 77.5(+0.9) models with larger kernel sizes, i.e. replacing 52	the second convolution in those new blocks by a7x7, 11x11 or 21x21 kernel. These models are indicated by names ending with “C7” (7x7), “C11”(11x11) or “C21” (21x21) in Table 7. As seen from the table, using larger kernel sizes consistentlyimproves the results on both ResNet50 and ResNet101 models. For example, we obtain an absolute5.0% improvement over original ResNet50 and 2.0% over original ResNet101 respectively, usingone more block with a kernel size of 21x21. When adding another block with a kernel size of 11x11(i.e. SIFA-R50-C21-11 and SIFA-R101-C21-11), it further boosts the performance up to 6.8% withResNet50 and 2.7% with ResNet101. These results strongly suggest that expanding the receptivefield of CNNs be a promising direction to design better CNN-based SIFAR models.
Table 8: Ablation Study. The effects of each component on model accuracy.
