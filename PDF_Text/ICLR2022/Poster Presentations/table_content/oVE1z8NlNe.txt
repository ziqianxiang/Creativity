Table 1: Top-1 accuracy comparison of SSL methods using the FedSSL framework on non-IIDCIFAR datasets. FedBYOL performs the best, whereas FedSimSiam performs the worst.
Table 2: Top-1 accuracy comparison on various non-IID levels — the number of classes per clienton the CIFAR-10 dataset. Update-both means updating both Wk and Wkt with Wg .
Table 3: Top-1 accuracy comparison under linear probing on CIFAR datasets. Our proposedFedEMA outperforms all other methods. Full results are in Table 5.
Table 4: Top-1 accuracy comparison on 1% and 10% of labeled data for semi-supervised learningon non-IID CIFAR datasets. FedEMA outperforms other methods. Full results are in Table 7.
Table 5: Top-1 accuracy comparison under linear evaluation protocol on CIFAR datasets. Ourproposed FedEMA outperforms all other methods on non-IID settings.
Table 6: Top-1 accuracy comparison on larger numbers of clients with client subsampling: 1) ran-domly selecting 5 out of 20 clients per round (5/20); 2) randomly selecting 8 out of 80 clients perround (8/80). FedEMA, trained with autoscaler, consistently outperforms FedBYOL in both set-tings.
Table 7: Top-1 accuracy comparison on using 1% and 10% of labeled data for semi-supervisedlearning on the non-IID settings of CIFAR datasets. FedEMA outperforms all other methods.
Table 8: Top-1 accuracy comparison on various non-IID levels — the number of classes per clienton the CIFAR-100 dataset. Update-both means updating both Wk and Wkt with Wg .
Table 9: Comparison of FedBYOL without exponential moving average (EMA) and stop-gradient(sg) on the CIFAR datasets. FedBYOL w/o EMA and sg can hardly learn, but updating both Wkand Wkt with Wg (update-both) enables it to achieve comparable results.
Table 10: Top-1 accuracy comparison on various batch sizes B on the non-IID setting of CIFAR-10dataset. The batch size should not be either too small or too large. Besides, FedEMA outperformsFedBYOL.
Table 11: Comparison of needed communication rounds to reach target accuracy using differentlocal epochs E on the non-IID setting of the CIFAR-10 dataset. E = 1 is unable to reach 80% in100 rounds. A larger E can reduce communication costs by increasing the computation cost.
Table 12: Top-1 accuracy comparison of various data amounts in clients and different numbers ofclients. Increasing the number of clients does not improve performance, whereas increasing the dataamount of clients results in better performance.
