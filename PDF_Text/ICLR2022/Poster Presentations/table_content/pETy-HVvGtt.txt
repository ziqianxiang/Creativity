Table 1: Exact values of metrics for toy model. We use U = I - -ɪ 11τ for the attacks. We do notnormalize the metrics by H(yk) as y is isotropic and continuous; normalization by itjust scales theresults by a constant scalar. For the attacked models, We show the limit of α → ∞ to understandhow well each metric reacts to completely entangled representations.
Table 2: Encoder and decoder architectures used in the dSprites and 3dshapes experiments.
Table 3: Training hyperparameters used for dSprites experiments.
Table 4: Training hyperparameters used for 3dshapes experiments.
Table 5: Qualitative summary of PID decomposition for model-factor pairs. Each pair is explainedby the following terms: disentangled: the unique information is larger than other terms; synergistic,redundant: the corresponding PID term is large; flat: no term exceeds others much, which indicatesthat all three terms are small (i.e., multiple variables contain distinct information of the factor) orboth redundancy and synergy are large. Note that these qualitative analyses are only applicable toour experimental settings. In particular, high redundancy of JointVAE (marked by * in the table)may be caused by a capacity hyperparameter. See Appendix G for details.
Table 6: KL terms and total correlation of latent variables learned by JointVAE. The values inparentheses show the standard deviation.
