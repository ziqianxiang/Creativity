Table 1: Accuracy on ImageNet with ResNet-50.
Table 2: Main comparison on CIFAR and ImageNet-100. Proj. and Pred. mean the hidden dimen-sion in projector and predictor. Negs means negatives (both feature-wise and instance-wise). Allmethods are trained 1000 epochs on CIFAR-10/100 (batch size 256) and 400 epochs on ImageNet-100 (batch size 128). N means number of samples, d means hidden dimensions, M is the numberof views and C is the clustering classes. The complexity only considers objective function in linewith peer works e.g. (Zhang et al., 2021a), since other parts like feedforward computing share thesame overhead. Note that some results are directly quoted from solo-learn (da Costa et al., 2021).
Table 3: Convergence rate. Cholesky-FCL and Table 4: Analysis on negatives. The hidden di-Cholesky-ICL mean replace ZCA whitening with mension of Zero-ICL and -FCL is set 256 andCholesky whitening on feature and instance-wise, 2048. SimCLR w/o negatives means directly us-respectively. For fairness, we set the dimension of ing MSE loss after l2 normalization between pos-projection head 128-128-128 and batch size 256. itive embeddings, while the reproduced BarlowMethod	100 eps		1000 eps		Twins w/o negatives means only using the invari- ance term in Eq. 4.					Acc@1	ACC@5	Acc@1	Acc@5					Barlow Twins	80.65	99.10	87.27	99.46	Method	w/o negatives		w/ negatives	SimCLR	78.39	98.84	90.16	99.66		Acc@1	Acc@5	Acc@1	Acc@5Zero-ICL	84.59	99.28	90.15	99.71	Barlow Twins SimCLR	16.98 6.92	41.26 22.36	65.81 64.98	90.18 89.91Cholesky-ICL	76.51	98.75	85.24	99.16					Zero-FCL	83.2	99.11	88.25	99.41										Zero-ICL ZerO-FCL	67.54 67.31	90.85 90.76	62.61 65.95	87.89 90.15Cholesky-FCL	82.83	99.02	87.63	99.37					Zero-CL	85.01	99.36	90.24	99.70					layer and modify the first convolutional layer with kernel size 3 and strides 1 in ResNet-18, whichare commonly used tricks in low-resolution datasets (Chen et al., 2020). The MLP (Projector) inour methods is quantified as three linear layers with two BNs (Ioffe & Szegedy, 2015) and ReLUactivation function. Table 2 shows the results on CIFAR and ImageNet-100 datasets. We compareour Zero-FCL with Barlow Twins with the same hidden dimension. With 256 hidden dimension,
Table 5: Ablation study of asym-metric/symmetric architectures asgenerated by applying stop gra-dient (‘SG’)/predictor (‘Pred’) onone of the branches, by follow-ing (Zbontar et al., 2021).
