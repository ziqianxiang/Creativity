Table 1: Results for conformal quantile finetuning on real-data regression tasks at level 1 - α = 90%. Foreach method we report the (test) coverage, length, and pinball loss of the corresponding base quantile predictor.
Table 2: Results for multi-output regression on next-state prediction tasks, at level 1 - α = 90%. For eachmethod we report the (test) coverage and volume of its learned box-shaped prediction set. The reported volumeis the “halfened” version Qid=ou1t ui . All results are averaged over 8 random seeds.
Table 3: Information about the regression datasets. Here (n, d) denotes the (sample size, feature dim).
Table 4: Information about the next-state prediction datasets. Here (dS , dA) denotes the (state, action) dimen-sion of the corresponding RL task. Datasets with a (slim) note only extract a subset of the full state (so that dSis less than the full state dimension). We also report the mean reward of the behavior policies.
Table 5: Results for ImageNet Prediction Sets with Conformal Ensembling. For each method we reportthe (test) coverage and set size. Each entry reports the (mean, std) over 8 random seeds.
Table 6: Results for conformal quantile finetuning on real-data regression tasks at level 1 - α = 80%. Foreach method we report the (test) coverage, length, and pinball loss of the corresponding base quantile predictor.
Table 7: Results for conformal quantile finetuning on real-data regression tasks at level 1 - α = 95%. Foreach method we report the (test) coverage, length, and pinball loss of the corresponding base quantile predictor.
Table 8: Results for multi-output regression on next-state prediction tasks, at level 1 - α = 80%. For eachmethod we report the (test) coverage and volume of its learned box-shaped prediction set. The reported volumeis the “halfened” version Qid=ou1t ui . All results are averaged over 8 random seeds.
Table 9: Results for multi-output regression on next-state prediction tasks, at level 1 - α = 95%. For eachmethod we report the (test) coverage and volume of its learned box-shaped prediction set. The reported volumeis the “halfened” version Qid=ou1t ui . All results are averaged over 8 random seeds.
Table 10: Comparison of CP-Gen and CP-Gen-Recal on the multi-output regression tasks. The reportedvolume is the “halfened” version Qid=ou1t ui .
Table 11: Conditional coverage results for conformal quantile finetuning on real-data regression tasks atlevel 1 - α = 90%. For each method we report the (absolute) correlation coefficient as well as the HSIC metricbetween length and indicator of coverage. All results are averaged over 8 random seeds.
Table 12: Results for conformal quantile finetuning on real-data regression tasks at level 1-α = 90%. Herewe compare our CP-Gen-Recal method with tweaked versions of the baseline CQR method. All resultsare averaged over the same 8 random seeds as in Table 1. All (average) coverages are within (90 ± 0.5)% andomitted here.
Table 13: Results for multi-output regression on next-state prediction tasks, at level 1 - α = 90%. Thesetting is the same as in Table 2 (with the same 8 random seeds), and here we compare additionally with theMax-score-Conformal baseline method described in (16).
Table 14: Results for conformal quantile finetuning on real-data regression tasks at level 1 - α = 90%. Foreach method we report the (test) coverage, length, and pinball loss of the corresponding base quantile predictor.
Table 15: Results for multi-output regression (mean) on next-state prediction tasks, at level 1 - α = 90%.
Table 16: Results for multi-output regression (standard deviation) on next-state prediction tasks, at level1 - α = 90%. For each method we report the (test) coverage and volume of its learned box-shaped predictionset. The reported volume is the “halfened” version Qid=ou1t ui. All standard deviations are computed over 100random seeds.
