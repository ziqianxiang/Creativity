Table 1: Results and ablation study on the WMT datasets. * Indicates our training results, asthe original papers did not report results on these datasets. For CMLM we report re-run resultsfrom (Kasai et al., 2021) as they are better than those reported in the original paper.
Table 2: Qualitative examples of test sentence translation from CMLM and CMLMC on the IWSLTâ€™14De-En dataset. For both models we show translations after the first self-correction iteration (fromfully masked sentence) and after the last iteration.
Table A.1: Results and ablation study on the IWSLr14 De-En and En-De datasets. * Indicates CMLMand SMART models that were trained by us, as (Ghazvininejad et al., 2019) and (Ghazvininejadet al., 2020b) does not report results on these datasets.
Table B.1: CMLMC hyper-parameters.
