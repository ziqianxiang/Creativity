Table 1: Hyper-parameters for experimentsHyper-parameters	Values	RangesSubgoal dimension d	2	Radius rg of subgoal selecting neighborhood	20	{10, 20}Grid size for count estimation	3	{2, 3, 5, 8}Number of candidate subgoals M	1000	Learning rate for both level policies	0.0002	Learning rate for the subgoal representation	0.0001	Discount factor γ for both levels and cumulative counts	0.99	Soft update rate for both levels	0.005	Replay buffer size for both levels	1e6	Reward scaling for high level	0.1	{1, 0.1}Reward scaling for low level	1	{1, 0.1}High-level action frequency c	50	{10, 20, 50, 100}Batch size for both level policies	128	Batch size for representation learning	100	Intrinsic reward coefficient η1	1000	{10, 100, 1000}Intrinsic reward coefficient η2	10	{10, 100, 1000}Stability regularization coefficient λ0	0.1	Number of episodes I between representation updates	100	
