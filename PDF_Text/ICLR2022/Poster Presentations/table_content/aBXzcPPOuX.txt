Table 1: The Wasserstein-1 metric for global data generation across all four datasets and models.
Table 2:	The Wasserstein-1 metric for fiberwise data generation across all four datasets and the threemodels that have a conditional component. Intervals represent 95% CIs over 10 trials.
Table 3:	The Wasserstein-1 metric for fiberwise data generation for models using either a single1-dimensional Gaussian or a uniform distribution on the circle as a prior.
Table 4: Torus vs sliced torus. Torus results are juxtaposed with those of the sliced torus to give anapproximate benchmark for comparison since both distributions have similar scale.
Table 5: Hyperparameter choices used in all models trained and evaluated during the course of thiswork (unless otherwise noted in the main text). If multiple values are given, the format is (torus,MobiUs band, wine, airfoil).
Table 6: Generative performance (Wasserstein-1 distance) of BUndleNet on the TorUs dataset interms of the nUmber of neighborhoods of Y Used. Each model was trained once and evalUatedmUltiple times to generate 95% CIs for a particUlar set of model weights.
Table 7: Generative performance (Wasserstein-1 distance) of BUndleNet on the Airfoil dataset interms of the nUmber of circUlar priors Used in latent space. The total dimension of the latent spacewas 18. 1-dimensional GaUssians accoUnt for additional dimensions where circle priors were notUsed.
Table 8: Generative performance metrics for the torus dataset for CGAN variationsGlobal	BundleNet (ours)	CGAN	CGAN-local-mixed	CGAN-localMSMD	0.073 ± 0.001	36.41 ± 0.365	58.63 ± 0.355	0.930 ± 0.013MMD (×10-3)	0.406 ± 0.018	35.04 ± 0.214	173.4 ± 1.173	2.336 ± 0.054KL-Fwd	0.812 ± 0.035	10.62 ± 0.021	11.41 ± 0.023	3.615 ± 0.028KL-Bwd	0.221 ± 0.021	11.97 ± 0.013	15.78 ± 0.010	4.070 ± 0.044W1	0.461 ± 0.020	7.114 ± 0.015	7.821 ± 0.017	1.610 ± 0.031W2	0.793 ± 0.108	25.76 ± 0.097	31.60 ± 0.123	2.715 ± 0.118Fiberwise	BundleNet (ours)	CGAN	CGAN-local-mixed	CGAN-localMSMD	0.017 ± 0.002	29.81 ± 1.911	55.54 ± 0.370	0.148 ± 0.011MMD (×10-3)	10.02 ± 0.557	83.46 ± 1.230	153.8 ± 1.394	28.74 ± 1.941KL-Fwd	5.047 ± 0.130	16.91 ± 0.110	18.01 ± 0.064	7.440 ± 0.180KL-Bwd	1.907 ± 0.090	9.422 ± 0.059	11.45 ± 0.040	3.122 ± 0.194W1	0.251 ± 0.013	7.996 ± 0.015	7.980 ± 0.021	0.450 ± 0.018W2	0.101 ± 0.010	32.60 ± 0.114	32.73 ± 0.167	0.183 ± 0.01017Published as a conference paper at ICLR 2022In this section we focus on CGAN and its failure modes on our synthetic data. We show how we can
Table 9: Generative performance metrics (global). Each metric is applied to a trained model asdetailed in section 5.1 with 95% confidence intervals determined by bootstrapping. Conditioning,when built into the model, is used to generate points over (uniformly sampled) base points to con-struct the point cloud.
Table 10: Generative performance metrics (fiberwise). Results were obtained by randomly sampling5 base points and generating points in the fiber over each. Each metric is applied to the generatedpoints and points sampled from the true distribution and averaged. Intervals represent 95% CIs over10 repeated experiments. WGAN is excluded since it has no built-in way to condition on the basepoint.
