Table 1: Online latency measured on TPUv3.
Table 2: Offline throughput (images processedper second) measured on TPUv3. Comparedwith Efficient-B6 or B7, our cascade achieves a3.0x or 3.5x increase in throughput respectively.
Table 3: Comparison with SOTA NAS methods.
Table 4: Cascades can be built with a guarantee on worst-case FLOPs. We use ‘with’ or ‘w/o’ toindicate whether a cascade can provide such a guarantee or not. Cascades with such a guaranteeare assured to use fewer FLOPs than single models in the worst-case scenario, and also achieve aconsiderable speedup in average-case FLOPs.
Table 5: Self-cascades. In the column of self-cascades, the two numbers represent the two resolu-tions r1 and r2 used in the cascade. Self-cascades use fewer FLOPs than comparable single models.
Table 6: Cascades of X3D models on Kinetics-600. We outperform X3D-XL by 1.2%.									Single Models		Cascades - Similar FLOPs			Cascades - Similar Accuracy			Top-1 (%)	FLOPs (B)	Top-1 (%)	FLOPs (B)	∆Top-1	Top-1 (%)	FLOPs (B)	SpeedupX3D-M	78.8	6.2 × 30	80.3	5.7 × 30	1.5	79.1	3.8 × 30	1.6xX3D-L	80.6	24.8 × 30	82.7	24.6 × 30	2.1	80.8	7.9 × 30	3.2xX3D-XL	81.9	48.4 × 30	83.1	38.1 × 30	1.2	81.9	13.0 × 30	3.7xWe consider the X3D (Feichtenhofer, 2020) architecture family for video classification, which is thestate-of-the-art in terms of both the accuracy and efficiency. The X3D family contains a series ofmodels of different sizes. Specifically, we build cascades of X3D models to match the FLOPs oraccuracy of X3D-M, X3D-L or X3D-XL on Kinetics-600 (Carreira et al., 2018).
Table 8: Average latency on TPUv3 for the case of online processing with batch size 1. Cascadesare much faster than single models in terms of the average latency while being similarly accurate.
Table 9: Throughput on TPUv3 for the case of offline processing. Throughput is measured as thenumber of images processed per second. Cascades achieve a much larger throughput than singlemodels while being equally accurate.
Table 10: Training time (TPUv3 days) of EfficientNet.
Table 11: Training time (TPU v3 days) of ensembles. We use the ‘+’ notation to indicate the modelsin enmsebles. Ensembles are faster than single models in both training and inference while achievea similar accuracy.
Table 12: Performance of the cascade of ViT-B-224 and ViT-L-224 on ImageNet with differentconfidence functions. For each confidence function, we set the threshold such that the cascade has asimilar throughput when using different confidence functions (〜409 images per second). The tableshows that different confidence functions give a similar accuracy.
Table 13: Cascades of EfficientNet, ResNet or MobileNetV2 models on ImageNet. This table con-tains the numerical results for Figure 5a-5d. Middle: Cascades obtain a higher accuracy than singlemodels when using similar FLOPs. Right: Cascades achieve a similar accuracy to single modelswith significantly fewer FLOPs (e.g., 5.4x fewer for B7). The benefit of cascades generalizes toall three convolutional architecture families and all computation regimes.
Table 14: Cascades of ViT models on ImageNet. This table contains the numerical results forFigure 5e. 224 or 384 indicates the image resolution the model is trained on. Throughput is measuredon NVIDIA RTX 3090. Our cascades can achieve a 1.0% higher accuracy than ViT-L-384 with asimilar throughput or achieve a 2.3x speedup over it while matching its accuracy. The benefit ofcascades generalizes to Transformer architectures.
Table 15: A Family of Cascades C0 to C7. C0 to C7 significantly outperform single EfficientNetmodels in all computation regimes. C1 and C2 also compare favorably with state-of-the-art NASmethods, such as BigNAS (Yu et al., 2020), OFA (Cai et al., 2020) and Cream (Peng et al., 2020).
Table 16: Exit ratios of cascades. We use the ‘+’ notation to indicate the models in cascades.
Table 17: Max, min, mean, and standard deviation of the performance of 8 single B5 models, 28possible 2-B5 ensembles, and 56 possible 2-B5 cascades.
Table 18: Cascades of models of same architectures vs. Cascades of models of different architec-tures. The ‘+’ notation indicates the models used in cascades.
