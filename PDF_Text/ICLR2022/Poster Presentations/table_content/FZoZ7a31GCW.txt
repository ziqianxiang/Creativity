Table 1: Variables and notation used for the Draupnir model.
Table 2:	Dimensions of variablesA.2 Draupnir settingsNeural network architecture The Draupnir model contains three neural networks (seeAlgorithm 1, Figure 1 and Figure 8): a fully connected network, NN(θ1) , that maps the pre-computed BLOSUM vectors, V, to BLOSUM embeddings, E; a bidirectional GRUθ (Choet al., 2014) with a single layer that takes as input the BLOSUM embeddings and the latent(2)vector of the k-th leaf sequence, Zk,:, and a second fully connected network, NNθ , thatmaps the GRUθ states to the logit vectors of the sequence characters. The dimensionalityof the state of the bidirectional GRUθ is 2 × 60.
Table 3: Descriptions of the eleven data sets used for benchmarking and the leaves-onlydata set used in the co-evolutionary analysis. All data sets contain insertions and deletions(gaps), except the one in italic (top), which only contains substitutions. Data sets labelledwith an asterisk only contain the sequence of the root node.
Table 4: Training settings and running times (Intel(R) Xeon(R) Gold 6136 CPU @ 3.00GHz,Quadro RTX 6000 GPU). On the largest dataset (800 leaves), we make use of a Reduce onplateau learning scheduler combined with plating to further improve the accuracy results.
Table 5: Benchmarking results using protein sequences. The table shows the means andthe standard deviation of the percent identity for all the predicted ancestral sequences andtheir corresponding true sequences. In the case of Draupnir-MAP, the means and standarddeviations are calculated using the most likely sequence of each ancestral node. In the caseof Draupnir-marginal samples, they are calculated using 50 samples per ancestral node.
Table 6: Benchmarking results using DNA sequences. The table is similar to Table 5 but thereconstructions for the standard ASR methods were obtained using DNA instead of aminoacid sequences. The DNA sequences were subsequently translated into protein sequencesbefore comparison.
