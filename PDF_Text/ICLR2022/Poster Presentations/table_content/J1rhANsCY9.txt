Table 1: CIFAR-10 accuracies of linear evaluation on top of representations learned with unsupervisedand self-supervised methods. NFK-128d denotes the 128 dimensional embeddings from the low-rankapproximation of the NFK (ie AFV). Remarkably, we can use 128 dimensions to exactly recover theperformance of the 5.9M dimensional Fisher Vectors.
Table 2: Error rates of semi-supervised classification on CIFAR10 and SVHN, varying labels from 500to 4000. NFK-128d yields extremely competitive performance, compared to other more sophisticatedbaselines, Mixup (Zhang et al., 2018), VAT (Miyato et al., 2019), MeanTeacher(Tarvainen and Valpola,2017), MixMatch (Berthelot et al., 2019), Improved GAN(Salimans et al., 2016), all are jointly learnswith labels, . Also note that the architecture used by MixMatch yields a 4.13% supervised learningerror rate, which is a much stronger than our supervised baseline (7.3%).
Table 3: Supervised knowledge distillation results (classification accuracy on test dataset) on CIFAR10against baseline methods KD (Hinton et al., 2015), FitNet (Romero et al., 2015), AT (Zagoruyko andKomodakis, 2017), NST (Huang and Wang, 2017), VID-I (Ahn et al., 2019), numbers are from (Ahnet al., 2019).
