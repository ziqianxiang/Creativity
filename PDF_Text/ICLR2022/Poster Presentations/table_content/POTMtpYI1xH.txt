Table 1: Alignment of BERT concepts (Layer 12) with the pre-defined conceptsFigure 4:	Layer-wise alignment of pre-defined concepts in BERT. The vertical axis represents thenumber of aligned clusters for a given concept, normalized by the maximum across all layers. Num-bers inside parenthesis show the maximum alignment for each concept.
Table 2: Inter-annotator agreement using Fleiss Kappa (Îº). A refers to annotator, and C refers toconsolidation.
Table 3:	ConcePt labelS: LEX and POS.
Table 4:	Concept labels: SEM.
Table 5:	Concept labels: SEM.
Table 6: Pre-defined conceptsD.2 Data and Experimental SetupWe used standard splits for training, development and test data for the 4 linguistic tasks (POS,SEM, Chunking and CCG super tagging). The splits to preprocess the data are available through git20Published as a conference paper at ICLR 20220.86 4 2Lo.o.o.o.
Table 7: Data statistics (number of sentences) on training, development and test sets using in theexperiments and the number of tags to be predictedE Comparing Pre-trained ModelsHow do models compare with respect to the pre-defined concepts? Similar to BERT, we cre-ated layer-wise latent clusters using RoBERTa (Liu et al., 2019b) and XLNet (Yang et al., 2019).
Table 8: Concept labels (LEX, POS) with token and type.
Table 9: Concept labels SEM with token and type.
Table 10: Concept labels SEM with token and type.
Table 11: Example of Sem tags with associated words.
