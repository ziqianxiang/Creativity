Table 1: CIFAR-10: Robustness to common corruptions, `p norm bounded perturbations and generaliza-tion performance. Mean corruption error (mCE) summarizes robustness to common image corruptions fromCifar-10-C; the corruption error for each group of corruptions (averaged across 5 severities and individual cor-ruption types) is also shown. Generalization performance is measured by accuracy on Cifar-10.1. Robustnessto 'p adversarial perturbations is summarized by the accuracy against '∞ and '2 norm bounded perturbations.
Table 2: IMAGENET: Robustness to common corruptions, `p norm bounded perturbations and general-ization performance. Mean corruption error (mCE) summarizes robustness to common image corruptions fromImageNet- C; the corruption error for each major group of corruptions is also shown. we measure generaliza-tion to IMAGENET-V2 (“IN-v2”) and IMAGENET-R (“IN-R”). Robustness to `p adversarial perturbations issummarized by the accuracy against '∞ and '2 norm bounded perturbations.
Table 3: Computational complexity and memory requirements for one training step of ourmethod and related works. M represents the number of inner/adversarial optimizer steps (i.e. PGDsteps in AdA or AT); |x| is the dimensionality of the input; ∣θ∣ and ∣φ∣ are the number of parametersof the main classifier and of the auxiliary network respectively. The number of adversarial weightperturbations in AWP or SAM is denoted by W; this is typically set to 1 (Wu et al., 2020; Foret et al.,2021). For PAT, we also refer to the number of bisection iterations as N and to the number of stepsused for updating the Lagrange multiplier as S; N is set to 10 and S to 5 by default (Laidlaw et al.,2021, Appendix A.3).
Table 4:	Robustness to common image corruptions under stochastic parameter perturbations.
Table 5:	Performance of Perceptual Adversarial Training on common image corruptions. Thetable lists the performance of ResNet50 models trained using Perceptual Adversarial Training bythe original authors of Laidlaw et al. (2021) on common image corruptions and two of our AdA-trained models. The table shows clean error, mean corruption error on Cifar-10-C and individualcorruption errors for each corruption type (averaged across all severities). “PAT-self” denotes thecase where the same model is used for classification as well as for computing the LPiPs distance,while “PAT-AlexNet” denotes the case where the LPiPs distance is computed using a pre-trainedCifar- 1 0 AlexNet (Krizhevsky et al., 2012) classifier.
Table 6: Effect of number of inner optimization steps on robustness to common image corrup-tions (Cifar-10-C). The table shows the performance of the AdA (EDSR) model while varying thenumber of inner optimization steps (M). The table shows the clean top-1 error, the mean corruptionerror on Cifar- 1 0-C and on individual corruptions (averaged across all severities).
Table 7: Effect of perturbation radius on robustness to common image corruptions (Cifar-10-C). The table shows the performance of the best AdA-combination from Table 1 from the mainmanuscript (AdA (EDSR) + DeepAugment + AugMix) while varying the perturbation radius (ν).
Table 8: Cifar-10: Extended results on robustness to common image corruptions. The tableshows mean corruption error on Cifar-10-C and individual corruption errors for each corruptiontype (averaged across all 5 severities).
Table 9: ImageNet (128×128): Extended results on robustness to common image corruptions.
