title,year,conference
 Deep learning through the lens ofexample difficulty,2021, arXiv preprint arXiv:2106
 Spectrally-normalized margin bounds for neuralnetworks,2017, arXiv preprint arXiv:1706
 Deepmind lab,2016, arXiv preprintarXiv:1612
 Revisiting resnets: Improved training and scaling strategies,2021, arXivpreprint arXiv:2103
 Language models arefew-shot learners,2020, arXiv preprint arXiv:2005
 Remote sensing image scene classification: Benchmarkand state ofthe art,2017, Proceedings ofthe IEEE
 De-scribing textures in the wild,2014, In Proceedings of the IEEE Conference on Computer Vision andPattern Recognition
 The efficiencymisnomer,2021, arXiv preprint arXiv:2110
 Scenic: A JAXlibrary for computer vision research and beyond,2021, arXiv preprint arXiv:2110
 The benchmark lottery,2021, arXiv preprint arXiv:2107
 Imagenet: A large-scale hierarchicalimage database,2009, In CVPR
 Comparing transfer and meta learning approaches on a unified few-shot classificationbenchmark,2021, arXiv preprint arXiv:2104
 Vision meets robotics: The kittidataset,2013, The International Journal ofRobotics Research
 Self-supervised pretraining of visualfeatures in the wild,2021, arXiv preprint arXiv:2103
 Eurosat: A novel datasetand deep learning benchmark for land use and land cover classification,2019, IEEE Journal of SelectedTopics in Applied Earth Observations and Remote Sensing
 Predicting the generalization gapin deep networks with margin distributions,2018, arXiv preprint arXiv:1810
 Clevr: A diagnostic dataset for compositional language and elementary visualreasoning,2017, In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition
 Adam: A method for stochastic optimization,2014, arXiv preprintarXiv:1412
 Wilds: Abenchmark of in-the-wild distribution shifts,2020, arXiv preprint arXiv:2012
 3d object representations for fine-grainedcategorization,2013, In 4th International IEEE Workshop on 3D Representation and Recognition(3dRR-13)
 Learning methods for generic object recognition withinvariance to pose and lighting,2004, In Proceedings of the 2004 IEEE Computer Society Conference onComputer Vision and Pattern Recognition
 Learning generative visual models from few trainingexamples: An incremental bayesian approach tested on 101 object categories,2004, In 2004 conferenceon computer vision and pattern recognition workshop
 Factors ofinfluence for transfer learning across diverse appearance domains and task types,2021, arXiv preprintarXiv:2103
 Accuracy on the line: On the strong correlationbetween out-of-distribution and in-distribution generalization,2021, In International Conference onMachine Learning
 Supervised transfer learning atscale for medical imaging,2021, arXiv preprint arXiv:2101
 The deep bootstrap: Good online learnersare good offline generalizers,2020, arXiv preprint arXiv:2010
 Exploring general-ization in deep learning,2017, arXiv preprint arXiv:1706
 Carbon emissions and large neural network training,2021, arXivpreprint arXiv:2104
 Meta pseudo labels,2020, arXivpreprint arXiv:2003
 Scalable transfer learning with expert models,2020, arXivpreprint arXiv:2009
 Learning transferable visualmodels from natural language supervision,2021, arXiv preprint arXiv:2103
 Transfusion: Understandingtransfer learning for medical imaging,2019, arXiv preprint arXiv:1902
 Imagenet large scale visual recognitionchallenge,2015, International journal of computer vision
 Revisiting unreasonableeffectiveness of data in deep learning era,2017, In ICCV
 Measuring robustness to natural distribution shifts in image classification,2020, arXivpreprint arXiv:2007
 Omninet: Omnidirectional representations from transformers,2021, arXivpreprint arXiv:2103
 Scale efficiently: Insights frompre-training and fine-tuning transformers,2021, arXiv preprint arXiv:2109
 Mlp-mixer: Anall-mlp architecture for vision,2021, arXiv preprint arXiv:2105
 Meta-dataset: A datasetof datasets for learning to learn from few examples,2019, arXiv preprint arXiv:1903
 Alarge-scale study of representation learning with the visual task adaptation benchmark,2019, arXivpreprint arXiv:1910
