title,year,conference
 Cloze-drivenpretraining of self-attention networks,2019, arXiv preprint arXiv:1903
 Beat theai: Investigating adversarial human annotation for reading comprehension,2020, Transactions of theAssociation for Computational Linguistics
 ¡°going on a vacation¡± takes longer than¡°going for a walk¡±: A study of temporal commonsense understanding,2019, In EMNLP
 The fifth pascal recognizingtextual entailment challenge,2009, In TAC
 Semantic parsing on Freebase fromquestion-answer pairs,2013, In Proceedings of the 2013 Conference on Empirical Methods in NaturalLanguage Processing
 Beyond the imitation game: Measuring and extrapolating the capabilitiesof language models,2021, In preparation
 Piqa: Reasoningabout physical commonsense in natural language,2020, In Thirty-Fourth AAAI Conference on ArtificialIntelligence
 On the opportunities and risks of foundation models,2021, CoRR
 Language models are few-shot learners,2020, In H
 Multitask learning,1997, Mach
 QuAC: Question answering in context,2018, In Proceedings of the 2018 Con-ference on Empirical Methods in Natural Language Processing
 The pascal recognising textual entailment chal-lenge,2005, In Machine Learning Challenges Workshop
 Quoref: A readingcomprehension dataset with questions requiring coreferential reasoning,2019, arXiv:1908
 Hate Speech Dataset froma White Supremacy Forum,2018, In Proceedings of the 2nd Workshop on Abusive Language Online(ALW2)
 Bert: Pre-training of deepbidirectional transformers for language understanding,2019, In Proceedings of the 2019 Conference ofthe North American Chapter of the Association for Computational Linguistics: Human LanguageTechnologies
 The third pascal recognizingtextual entailment challenge,2007, In Proceedings of the ACL-PASCAL workshop on textual entailmentand paraphrasing
 Samsum corpus: A human-annotated dialogue dataset for abstractive summarization,2019, arXiv preprint arXiv:1911
 English gigaword,2003, Linguistic Data Con-sortium
 A joint many-taskmodel: Growing a neural network for multiple NLP tasks,2016, CoRR
 Teaching machines to read and comprehend,2015, In Advances inneural information processing systems
 Towardsemantics-based answer pinpointing,2001, In Proceedings of the First International Conference onHuman Language Technology Research
 Cosmos qa: Machine readingcomprehension with contextual commonsense reasoning,2019, In arXiv:1909
 triviaqa: A Large Scale DistantlySupervised Challenge Dataset for Reading Comprehension,2017, arXiv e-prints
 Lookingbeyond the surface:a challenge set for reading comprehension over multiple sentences,2018, In Pro-ceedings of North American Chapter of the Association for Computational Linguistics (NAACL)
 Unifiedqa: Crossing format boundaries with a single QA system,2020, CoRR
 UNIFIEDQA: Crossing format boundaries with a single QA system,2020, InFindings of the Association for Computational Linguistics: EMNLP 2020
 Qasc: A datasetfor question answering via sentence composition,2020, arXiv:1910
 What changes can large-scale language models bring? intensive study on hyperclova: Billions-scale korean generativepretrained transformers,2021, arXiv preprint arXiv:2109
 Quantifying thecarbon emissions of machine learning,2019, arXiv preprint arXiv:1910
 Race: Large-scale readingcomprehension dataset from examinations,2017, arXiv preprint arXiv:1704
 Generating text from structured data with appli-cation to the biography domain,2016, CoRR
 Deduplicating training data makes language models better,2021, arXivpreprint arXiv:2107
 The power of scale for parameter-efficient prompttuning,2021, CoRR
 The winograd schema challenge,2012, In Thir-teenth International Conference on the Principles of Knowledge Representation and Reasoning
 Datasets: A communitylibrary for natural language processing,2021, emnlp
 Learning question classifiers,1150, In COLING 2002: The 19th InternationalConference on Computational Linguistics
 CommonGen: A constrained text generation challenge for generative commonsensereasoning,2020, In Findings of the Association for Computational Linguistics: EMNLP 2020
 Reasoning over paragraph effects insituations,2019, In MRQA@EMNLP
 Learning word vectors for sentiment analysis,2011, In Proceedings of the 49th Annual Meetingof the Association for Computational Linguistics: Human Language Technologies
 Hidden factors and hidden topics: understanding rating dimen-sions with review text,2013, In Proceedings of the 7th ACM conference on Recommender systems
 The natural languagedecathlon: Multitask learning as question answering,2018, CoRR
 Right for the wrong reasons: Diagnosing syntacticheuristics in natural language inference,2019, CoRR
 Can a suit of armor conductelectricity? a new dataset for open book question answering,2018, In EMNLP
 Natural instruc-tions: Benchmarking generalization to new tasks from natural language instructions,2021, CoRR
 CrowS-Pairs: A ChallengeDataset for Measuring Social Biases in Masked Language Models,2020, In Proceedings of the 2020Conference on Empirical Methods in Natural Language Processing
 Ad-versarial nli: A new benchmark for natural language understanding,2020, In Proceedings of the 58thAnnual Meeting of the Association for Computational Linguistics
 Seeing stars: Exploiting class relationships for sentiment categorizationwith respect to rating scales,2005, In Proceedings of the ACL
 The lambada dataset:Word prediction requiring a broad discourse context,2016, In Proceedings of the 54th Annual Meetingof the Association for Computational Linguistics (Volume 1: Long Papers)
 Carbon emissions and large neural network training,2021, arXivpreprint arXiv:2104
 Inherent disagreements in human textual inferences,2019, Trans-actions of the Association for Computational Linguistics
 Collecting diverse natural language inference problems for sentencerepresentation evaluation,2018, In Proceedings of the 2018 Conference on Empirical Methods in Nat-ural Language Processing
 Languagemodels are unsupervised multitask learners,2019, OpenAI blog
 Exploring the limits of transfer learning with a unified text-to-texttransformer,2020, Journal of Machine Learning Research
 Prompt programming for large language models: Beyond thefew-shot paradigm,2021, CoRR
 Choice of plausible alternatives:An evaluation of commonsense causal reasoning,2011, In 2011 AAAI Spring Symposium Series
 Getting closer to AI com-plete question answering: A set of prerequisite real tasks,2020, In The Thirty-Fourth AAAI Conferenceon Artificial Intelligence
 Gender bias incoreference resolution,2018, In Proceedings of the 2018 Conference of the North American Chapterof the Association for Computational Linguistics: Human Language Technologies
 A neural attention model for abstractivesentence summarization,2015, Proceedings of the 2015 Conference on Empirical Methods in NaturalLanguage Processing
 DuoRC: TowardsComplex Language Understanding with Paraphrased Reading Comprehension,2018, In Meeting of theAssociation for Computational Linguistics (ACL)
 WINOGRANDE: anadversarial winograd schema challenge at scale,2019, CoRR
 Exploiting cloze-questions for few-shot text classification andnatural language inference,2021, In Proceedings of the 16th Conference of the European Chapter ofthe Association for Computational Linguistics: Main Volume
 Green ai,2020, Communications of theACM
 Get to the point: Summarization with pointer-generator networks,2017, CoRR
 Release strategies and the social impacts of language models,2019, CoRR
 Energy and policy considerations for deeplearning in NLP,2019, In Proceedings of the 57th Annual Meeting of the Association for ComputationalLinguistics
 DREAM: A challengedataset and models for dialogue-based reading comprehension,2019, Transactions of the Associationfor Computational Linguistics
 Quarel: A datasetand models for answering questions about qualitative relationships,2018, CoRR
 Exploring and predicting transferabilityacross NLP tasks,2020, In Proceedings of the 2020 Conference on Empirical Methods in Natural Lan-guage Processing (EMNLP)
 Superglue: A stickier benchmark for general-purpose languageunderstanding systems,2019, CoRR
 Anlizing the adversarial natural language infer-ence dataset,2020, arXiv preprint arXiv:2010
 Crossfit: A few-shot learning challenge for cross-taskgeneralization in nlp,2021, arXiv preprint arXiv:2104
 WikiQA: A Challenge Dataset for Open-DomainQuestion Answering,2015, Association for Computational Linguistics
 Character-level convolutional networks for text classi-fication,2015, In Advances in neural information processing Systems
 Character-level convolutional networks for textclassification,2015, In NIPS
 PAWS: Paraphrase Adversaries from Word Scram-bling,2019, In Proc
 Gender bias incoreference resolution: Evaluation and debiasing methods,2018, In Proceedings of the 2018 Con-ference of the North American Chapter of the Association for Computational Linguistics: Hu-man Language Technologies
 Adapting language models for zero-shotlearning by meta-tuning on dataset and prompt collections,2021, CoRR
 Most humans would con-sider taking an exam in history vs,2020, in physics as two different tasks
