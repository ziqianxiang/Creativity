title,year,conference
 Improved algorithms for linear stochasticbandits,2011, In Advances in neural information processing Systems
 Opal: Offline prim-itive discovery for accelerating offline reinforcement learning,2021, In International Conference onLearning Representations
 Uncertainty-based offline rein-forcement learning with diversified q-ensemble,2021, In Advances in neural information processingsystems
 Minimax regret bounds for reinforce-ment learning,2017, In International Conference on Machine Learning
 Efficient explorationthrough bayesian deep q-networks,2018, In 2018 Information Theory and Applications Workshop (ITA)
 Behavioral priors anddynamics models: Improving performance and domain transfer in offline rl,2021, arXiv preprintarXiv:2106
 Mitigat-ing covariate shift in imitation learning via offline data without great coverage,2021, arXiv preprintarXiv:2106
 Decision transformer: Reinforcement learningvia sequence modeling,2021, In Advances in neural information processing systems
 Deep reinforcement learn-ing in a handful of trials using probabilistic dynamics models,2018, Advances in Neural InformationProcessing Systems
 D4rl: Datasets for deepdata-driven reinforcement learning,2020, arXiv preprint arXiv:2004
 A minimalist approach to offline reinforcement learning,2021, InAdvances in neural information processing systems
 Addressing function approximation error in actor-critic methods,2018, In International Conference on Machine Learning
 Off-policy deep reinforcement learning withoutexploration,2019, In International Conference on Machine Learning
 Dropout as a bayesian approximation: Representing modeluncertainty in deep learning,1050, In International Conference on Machine Learning
 Emaq: Expected-max q-learning operator for simple yet effective offline and online rl,2021, In International Conferenceon Machine Learning
 Soft actor-critic: Off-policymaximum entropy deep reinforcement learning with a stochastic actor,2018, In International Confer-ence on Machine Learning
 Near-optimal regret bounds for reinforcementlearning,2010, Journal of Machine Learning Research
 When to trust your model: Model-based policy optimization,2019, Advances in Neural Information Processing Systems
 Provably efficient reinforcementlearning with linear function approximation,2137, In Conference on Learning Theory
 Infor-mation theoretic regret bounds for online nonlinear control,2020, arXiv preprint arXiv:2006
 Morel: Model-based offline reinforcement learning,2020, In Advances in Neural Information Processing Systems
 Offline reinforcement learningwith fisher divergence critic regularization,2021, In International Conference on Machine Learning
 Stabilizing off-policyq-learning via bootstrapping error reduction,2019, In Advances in Neural Information Processing Sys-tems
 Conservative q-learning for offlinereinforcement learning,2020, In H
 Sunrise: A simple unified frame-work for ensemble learning in deep reinforcement learning,2021, In International Conference on Ma-chine Learning
 Offline-to-onlinereinforcement learning via balanced replay and pessimistic q-ensemble,2021, In Annual Conference onRobot Learning
 What matters in learning from offlinehuman demonstrations for robot manipulation,2021, In Annual Conference on Robot Learning
 Active learning for nonlinear system identifi-cation with guarantees,2020, arXiv preprint arXiv:2006
 Deployment-efficient reinforcement learning via model-based offline optimization,2020, In International Confer-ence on Learning Representations
 Distributionalreinforcement learning for efficient exploration,2019, In International conference on machine learning
 Learning to navigate incities without a map,2018, Advances in Neural Information Processing Systems
 Model-freerepresentation learning and exploration in low-rank MDPs,2021, arXiv preprint arXiv:2102
 Accelerating online reinforcementlearning with offline datasets,2020, arXiv preprint arXiv:2006
 Information-directed exploration for deep reinforcement learning,2019, In International Conference on LearningRepresentations
 Deep exploration viabootstrapped dqn,2016, In Advances in Neural Information Processing Systems
 Randomized prior functions for deep reinforcementlearning,2018, Advances in Neural Information Processing Systems
 Randomized prior functions for deep reinforcementlearning,2018, Advances in Neural Information Processing Systems
 Can you trust your model¡¯s uncertainty? evaluatingpredictive uncertainty under dataset shift,2019, Advances in Neural Information Processing Systems
 The uncertainty bellmanequation and exploration,2018, In International Conference on Machine Learning
 Offline reinforcement learning as anti-exploration,2021, arXiv preprintarXiv:2106
 Keep doing whatworked: Behavioral modelling priors for offline reinforcement learning,2020, In International Confer-ence on Learning Representations
 Reinforcement learning: An introduction,2018, MIT press
 GELATO: geometrically enriched latent model foroffline reinforcement learning,2021, CoRR
 Representation learning for online and offlineRL in low-rank MDPs,2021, arXiv preprint arXiv:2110
 On reward-free reinforce-ment learning with linear function approximation,2020, In Advances in neural information processingsystems
 Critic regularizedregression,2020, Advances in Neural Information Processing Systems
 Uncertainty weighted actor-critic for offline reinforcement learning,2021, InInternational Conference on Machine Learning
 Bellman-consistentpessimism for offline reinforcement learning,2021, In Advances in neural information processing sys-tems
 Policy finetuning: Bridg-ing sample-efficient offline and online reinforcement learning,2021, arXiv preprint arXiv:2106
 Reinforcement learning in healthcare: A survey,2019, arXivpreprint arXiv:1908
 Mopo: Model-based offline policy optimization,2020, In Advances in NeuralInformation Processing Systems
 Provable benefits of actor-critic meth-ods for offline reinforcement learning,2021, Advances in neural information processing systems
 Plas: Latent action space for offline reinforce-ment learning,2020, In Conference on Robot Learning
