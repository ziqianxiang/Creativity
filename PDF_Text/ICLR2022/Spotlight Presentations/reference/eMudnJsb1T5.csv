title,year,conference
 Natural gradient works efficiently in learning,1998, Neural Computation
 Stein’s method and Poisson process convergence,1988, Journal of Applied Probability
 Mirror descent and nonlinear projected subgradient methods forconvex optimization,2003, Operations Research Letters
 Reproducing kernel Hilbert spaces in probability andstatistics,2011, Springer Science & Business Media
 Stochastic processes with applications,2009, SIAM
 Latent Dirichlet allocation,2003, Journal of MachineLearning Research
 Projected Steinvariational Newton: A fast and scalable Bayesian inference method in high dimensions,2019, InAdvances in Neural Information Processing Systems
 A kernel test of goodness of fit,2016, InInternational Conference on Machine Learning
 Further and stronger analogy between sampling and optimization: Langevin MonteCarlo and gradient descent,2017, In Conference on Learning Theory
 Adaptive subgradient methods for online learning andstochastic optimization,2011, Journal of Machine Learning Research
 On the geometry of Stein variational gradientdescent,2019, arXiv preprint arXiv:1912
 Efficient Bayesian computation by proximalMarkov chain Monte Carlo: when Langevin meets Moreau,2018, SIAM Journal on Imaging Sciences
 Reflection couplings and contraction rates for diffusions,2016, Probability Theory andRelatedFields
 Learning to draw samples with amortized Stein variationalgradient descent,2017, Uncertainty in Artificial Intelligence
 Eigenvalues of integral operators defined by smooth positive definitekernels,2009, Integral Equations and Operator Theory
 Bayesian posterior approximationvia greedy particle optimization,2019, In Proceedings of the AAAI Conference on Artificial Intelligence
 Dirichlet approximation of equilibrium distributions inCannings models with mutation,2017, Advances in Applied Probability
 Large sample analysis of the medianheuristic,2017, arXiv preprint arXiv:1707
 Measuring sample quality with Stein’s method,2015, In Advances inNeural Information Processing Systems
 Measuring sample quality with kernels,2017, In InternationalConference on Machine Learning
 Measuring samplequality with diffusions,2019, The Annals of Applied Probability
 Stochastic stein discrepancies,2020, arXiv preprintarXiv:2007
 Reinforcement learning withdeep energy-based policies,2017, In International Conference on Machine Learning
 Neural networks for machine learning lecture6a: overview of mini-batch gradient descent,2012, 2012
 The No-U-Turn sampler: adaptively setting path lengthsin Hamiltonian Monte Carlo,2014, Journal of Machine Learning Research
 Mirrored Langevin dynamics,2018, InAdvances in Neural Information Processing Systems
 Random feature Stein discrepancies,2018, In S
 A Linear-Time KernelGoodness-of-Fit Test,2017, In Advances in Neural Information Processing Systems
 Fast yet simple natural-gradient descent for variationalinference in complex models,2018, In 2018 International Symposium on Information Theory and ItsApplications (ISITA)
 A non-asymptotic analysisfor Stein variational gradient descent,2020, Advances in Neural Information Processing Systems
 Riemannian Stein variational gradient descent for Bayesian inference,2018, InProceedings of the AAAI Conference on Artificial Intelligence
 Understanding and acceleratingparticle-based variational inference,2019, In International Conference on Machine Learning
 Understanding MCMC dynamics as flows on the Wassersteinspace,2019, In Proceedings of the 36th International Conference on Machine Learning
 Stein variational gradient descent as gradient flow,2017, In Advances in Neural InformationProcessing Systems
 Stein variational gradient descent: A general purpose Bayesian inferencealgorithm,2016, Advances in Neural Information Processing Systems
 A complete recipe for stochastic gradient MCMC,2015, InAdvances in Neural Information Processing Systems
 New insights and perspectives on the natural gradient method,2014, arXiv preprintarXiv:1412
 On learning vector-valued functions,2005, Neural Computa-tion
 Problem complexity and methodefficiency in optimization,1983, 1983
 Stochastic Differential Equations: An Introduction with Applications,2003, SpringerScience & Business Media
 Stochastic gradient Riemannian Langevin dynamics on theprobability simplex,2013, In Advances in Neural Information Processing Systems
 The information geometry of mirror descent,2015, IEEETransactions on Information Theory
 Genotypic predictors of human immunodeficiency virus type 1 drug resistance,2006, Proceedingsof the National Academy of Sciences
 Optimal thinning of MCMC output,2020, arXiv preprint arXiv:2005
 A spectral approach to gradient estimation for implicitdistributions,2018, In International Conference on Machine Learning
 Stochastic quasi-Newton LangevinMonte Carlo,2016, In International Conference on Machine Learning
 A bound for the error in the normal approximation to the distribution of a sum ofdependent random variables,1972, In Proceedings of the Sixth Berkeley Symposium on Mathemati-cal Statistics and Probability
 Statistical learning and selective inference,2015, Proceedings ofthe National Academy of Sciences
 Stein variational message passing for continuous graphicalmodels,2018, In International Conference on Machine Learning
 Stein variational gradient descent withmatrix-valued kernels,2019, In Advances in Neural Information Processing Systems
 Bayesian learning via stochastic gradient Langevin dynamics,2011, InInternational Conference on Machine Learning
 Langevindiffusions and the Metropolis-adjusted Langevin algorithm,2014, Statistics & Probability Letters
 Variance reduction in stochastic particle-optimizationsampling,2020, In Proceedings of the 37th International Conference on Machine Learning
 Wasserstein control ofmirror Langevin Monte Carlo,2020, arXiv preprint arXiv:2002
 Variance reduction and quasi-Newton for particle-basedvariational inference,2020, In Proceedings of the 37th International Conference on Machine Learning
 Message passing Steinvariational gradient descent,2018, In International Conference on Machine Learning
