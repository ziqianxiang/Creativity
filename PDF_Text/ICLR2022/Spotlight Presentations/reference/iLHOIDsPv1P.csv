title,year,conference
 Information dropout: Learning optimal representations through noisycomputation,2018, IEEE Transactions on Pattern Analysis and Machine Intelligence
 Understanding disentangling in Î²-VAE,2018, arXiv preprint arXiv:1804
 Estimating uncertainty formassive data streams,2012, Technical report
 Diffusion for global optimization in Rn ,1987, SIAMJournal on Control and Optimization
 An analysis of single-layer networks in unsupervised featurelearning,2011, In International Conference on Artificial Intelligence and Statistics
 Residuals and influence in regression,1982, New York: Chapman and Hall
 Compressing neural networks using the variational infor-mation bottleneck,2018, In International Conference on Machine Learning
 Data-dependent PAC-Bayes priors via differential privacy,2018, InAdvances in Neural Information Processing Systems
 On the role of datain PAC-Bayes,2021, In International Conference on Artificial Intelligence and Statistics
 Estimating information flow in deep neural networks,2019, In International Conference onMachine Learning
 InfoBot: transfer and exploration via the information bottleneck,2019, In InternationalConference on Learning Representations
 Adam: A method for stochastic optimization,2014, arXiv preprintarXiv:1412
 Elementary statistical physics,2004, Courier Corporation
 Understanding black-box predictions via influence functions,2017, In InternationalConference on Machine Learning
 Caveats for information bottleneck in determin-istic scenarios,2018, In International Conference on Learning Representations
 Learning multiple layers of features from tiny images,2009, Technicalreport
 Gradient-based learning applied to documentrecognition,1998, Proceedings of the IEEE
 New insights and perspectives on the natural gradient method,2020, Journal of Machine LearningResearch
 Generalization bounds of SGLD for non-convexlearning: Two theoretical viewpoints,2018, In Conference on Learning Theory
 Information-theoretic generalization bounds for SGLD via data-dependent estimates,2019, arXiv preprint arXiv:1911
 Reading digits innatural images with unsupervised feature learning,2011, 2011
 In search of the real inductive bias: On the role ofimplicit regularization in deep learning,2015, In International Conference on Learning Representations Workshop
 Disentangled information bottleneck,2020, arXiv preprintarXiv:2012
 Non-convex learning via stochastic gradientLangevin dynamics: a nonasymptotic analysis,2017, In Conference on Learning Theory
 PAC-Bayes bounds for stable algorithms with instance-dependent priors,2018, In Advances in Neural InformationProcessing Systems
 On the information bottleneck theory of deep learning,2019, Journal of Statistical Mechanics:Theory and Experiment
 Information in infinite ensembles of infinitely-Wide neural net-Works,2020, In Symposium on Advances in Approximate Bayesian Inference
 Opening the black box of deep neural netWorks via information,2017, arXivpreprint arXiv:1703
 Deep learning and the information bottleneck principle,2015, In IEEE Informa-tion Theory Workshop
 The information bottleneck method,2000, arXiv preprintphysics/0004057
 Deep multi-vieW information bottle-neck,2019, In Proceedings of the SIAM International Conference on Data Mining
 Informationtheoretic counterfactual learning from missing-not-at-random feedback,2020, In Advances in Neural InformationProcessing Systems
 Finding influentialinstances for distantly supervised relation extraction,2020, arXiv preprint arXiv:2009
 Bayesian learning via stochastic gradient Langevin dynamics,2011, In InternationalConference on Machine Learning
 Graph information bottleneck,2020, arXiv preprintarXiv:2010
 Information-theoretic analysis of generalization capability of learning algo-rithms,2017, In Advances in Neural Information Processing Systems
 An information-theoretic view for deep learning,2018, arXivpreprint arXiv:1804
