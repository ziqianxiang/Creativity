title,year,conference
 Constrained Markov Decision Processes,1999, Chapman and Hall
 Logarithmic online regret bounds for undiscounted reinforcementlearning,2007, In B
 Near-optimal regret bounds for re-inforcement learning,2009, In D
 R-max - a general polynomial time algorithm for near-optimal reinforcement learning,2003, J
 Risk-constrained re-inforcement learning with percentile risk criteria,2015, CoRR
 Deep reinforcementlearning in a handful of trials using probabilistic dynamics models,2018, CoRR
 Structured variationalinference in partially observable unstable gaussian process state space models,2020, In Learning forDynamics and Control
 Pilco: A model-based and data-efficient ap-proach to policy search,2011, In Proceedings of the 28th International Conference on InternationalConference on Machine Learning
 Practical variational inference for neural networks,2011, In J
 Learning latent dynamics for planning from pixels,2019, In International Conference onMachine Learning
 Dream to con-trol: Learning behaviors by latent imagination,2019, CoRR
 Learning-based modelpredictive control for safe exploration,2018, In 2018 IEEE Conference on Decision and Control (CDC)
 Aug-mented lagrangian method for instantaneously constrained reinforcement learning prob-lems,2021, 2021
 Safe exploration in markov decision processes,2012, CoRR
 Robust Control of Markov Decision Processeswith Uncertain Transition Matrices,2005, Operations Research
 Numerical Optimization,2006, Springer
 Benchmarking Safe Exploration in Deep Reinforce-ment Learning,2019, 2019
 A stochastic approximation method,2007, Annals of Mathematical Statistics
 Reinforcement Learning: An Introduction,0262, A BradfordBook
