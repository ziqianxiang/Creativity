title,year,conference
 Robustness to augmentations as ageneralization metric,2021, arXiv preprint arXiv:2101
 Do gans learn the distribution? some theory andempirics,2018, In International Conference on Learning Representations
 Seeing what a gan cannot generate,2019, In Proceedings of the IEEE/CVF InternationalConference on Computer Vision (ICCV)
 Large scale GAN training for high fidelitynatural image synthesis,2019, In International Conference on Learning Representations
 In search of robust measures of generaliza-tion,2020, Advances in Neural Information Processing Systems
 Generalization bounds via distillation,2020, InInternational Conference on Learning Representations
 Evaluating gradient in-version attacks and defenses in federated learning,2021, Advances in Neural Information ProcessingSystems
 Predicting the generalization gapin deep networks with margin distributions,2018, arXiv preprint arXiv:1810
 Fantas-tic generalization measures and where to find them,2019, In International Conference on LearningRepresentations
 Assessing generalization ofSgd via disagreement,2021, arXiv e-prints
 Robustness to augmentations as a generalizationmetric,2021, arXiv preprint arXiv:2101
 Network in network,2013, arXiv preprint arXiv:1312
 Towardsunderstanding the role of over-parametrization in generalization of neural networks,2018, 2018
 Seeing is not necessarily believing: Limitations of biggans fordata augmentation,2019, 2019
 A classification-based study of covari-ate shift in gan distributions,4480, In International Conference on Machine Learning
 Detecting ovefitting of deep generativenetworks via latent recovery,1127, In Proceedings of the IEEE/CVF Conference on Computer Visionand Pattern Recognition
 Differentiable augmentation fordata-efficient gan training,2020, Advances in Neural Information Processing Systems
