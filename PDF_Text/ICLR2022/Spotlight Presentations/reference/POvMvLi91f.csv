title,year,conference
 Towards characterizing divergence in deepq-learning,2019, arXiv preprint arXiv:1903
 An optimistic perspective onoffline reinforcement learning,2020, In International Conference on Machine Learning (ICML)
 Deep reinforcement learning at the edge of the statistical precipice,2021, Advances in NeuralInformation Processing Systems
 On the optimization of deep networks: Implicitacceleration by overparameterization,2018, arXiv preprint arXiv:1802
 Interference and generalization in tem-poral difference learning,2020, arXiv preprint arXiv:2003
 Implicit regularization for deepneural networks driven by an ornstein-uhlenbeck like process,2020, In Conference on learningtheory
 Accounting for variance in machine learning benchmarks,2021, Proceedings of MachineLearning and Systems
 The intriguing role of modulecriticality in the generalization of deep networks,2019, arXiv preprint arXiv:1912
 Information-theoretic considerations in batch reinforcement learn-ing,2019, ICML
 Exploring simple siamese representation learning,2020, arXivpreprint arXiv:2011
 Label noise sgd provably prefers flat global mini-mizers,2021, arXiv preprint arXiv:2106
 The linear programming approach to approximate dynamic program-ming: Theory and application,2002, PhD thesis
 Minimax-optimal off-policy evaluation with linearfunction approximation,2701, In International Conference on Machine Learning
 Td learning with constrained gradients,2018,2018
 Error propagation for ap-proximate policy and value iteration,2010, In Advances in Neural Information Processing Systems(NIPS)
 Revisiting fundamentals of experience replay,2020, arXiv preprintarXiv:2007
 Diagnosing bottlenecks in deepQ-learning algorithms,2019, arXiv preprint arXiv:1902
 D4rl: Datasets fordeep data-driven reinforcement learning,2020, arXiv preprint arXiv:2004
 Benchmarks for deep off-policy evaluation,2021, In International Con-ference on Learning Representations
 Representations for stable off-policy reinforcementlearning,2020, arXiv preprint arXiv:2007
 Bootstrap your own latent: Anew approach to self-supervised learning,2020, arXivpreprint arXiv:2006
 Rlunplugged: Benchmarks for offline reinforcement learning,2020,2020
 Implicit regularization in matrix factorization,2017, In Advances in Neural InformationProcessing Systems
 Soft actor-critic:Off-policy maximum entropy deep reinforcement learning with a stochastic actor,2018, CoRR
 Discor: Corrective feedback in reinforce-ment learning via distribution correction,2020, arXiv preprint arXiv:2003
 Conservative q-learning foroffline reinforcement learning,2020, arXiv preprint arXiv:2006
 Implicit under-parameterization inhibits data-efficient deep reinforcement learning,2021, In International Confer-ence on Learning Representations
 Towards explaining the regularization effect of initiallarge learning rate in training neural networks,2019, In Advances in Neural Information ProcessingSystems
 Convergent temporal-difference learning with arbitrary smooth functionapproximation,2009, In Proceedings of the 22nd International Conference on Neural InformationProcessing Systems
 Emphatic temporal-difference learning,2015, arXiv preprint arXiv:1507
 Human-level control through deep rein-forcement learning,28, Nature
 Unique properties of flat minima in deep networks,2020, InInternational Conference on Machine Learning
 Observe andlook further: Achieving consistent performance on atari,2018, arXiv preprint arXiv:1805
 Cog:Connecting new skills to past experience with offline reinforcement learning,2020, arXiv preprintarXiv:2010
 Reinforcement learning: An introduction,2018, Secondedition
 An emphatic approach to theproblem of off-policy temporal-difference learning,1532, J
 Understanding self-supervisedlearning with dual deep networks,2020, arXiv preprint arXiv:2010
 Understanding self-supervised learning dy-namics without contrastive pairs,2021, arXiv preprint arXiv:2102
 Deep reinforcement learning and the deadly triad,2018, ArXiv
 Deep reinforcement learning and the deadly triad,2018, arXiv preprint arXiv:1812
 Instabilities of offlinerl with pre-trained neural representation,2021, arXiv preprint arXiv:2103
 Regularization matters: Generalization andoptimization of neural nets vs their induced kernel,2019,2019
 Behavior regularized offline reinforcement learn-ing,2019, arXiv preprint arXiv:1911
 Q* approximation schemes for batch reinforcement learning: Aeoretical comparison,2020,2020
 Exponential lower bounds for batch reinforcement learning: Batch rl can beexponentially harder than online rl,2020, arXiv preprint arXiv:2012
