Figure 2: Test accuracy for different |C| at train (lines) and eval (subplot) times on ImageNet. (a)Easy eval task: no differentiation between methods. (b) Hard eval task: more candidates at traininginduces higher test accuracy. Shaded region represents the standard deviation across 10 seeds.
Figure 3: (left) TopSim (x100) with different representation of the input space (Image and Attributes)for different training difficulties, |C |. We do not observe a correlation between TopSim and |C |, andthus generalization. ± denotes 1 standard error of the mean. (right) Example of predicted images bynew Listener trained on reconstruction task given a message of 1-pair for |C|=1024. Reconstructionsare expected to be blurry, as we are regressing the mean of all faces associated to one message.
Figure 4: ETL per datasets and tasks. The results are averaged across min(N, 5) Speakers, 3 new-born Listeners’ over 10 different seeds. The shaded region represents the standard deviation.
Figure 5: Example of a discrimination game on Imagenet with a set C of 4 candidates. In thisspecific instance, Listener does not select an image X that is identical to the target image X receivedby Speaker. Therefore the reward received by both player R(x, X) = 1χ=^ will be 0.
Figure 6: Graphical representation of a speaker’s architecture that shows how the words (wt)tT=-01are computed from the inputs x.
Figure 7: Graphical representation of a listener’s architecture that shows how the scorescore(m, X, φ) is computed given a message (wt)T- and an input image X.
Figure 8: Face reconstructions. Left: Randomly sampled input images from the CelebA dataset;Middle: Reconstructions, using messages from a model trained with 16 candidates; Right: Recon-structions, using messages from a model trained with 1024 candidates.
Figure 9: Training accuracy for a 1 communicating pair when varying the KL coefficient β . Eachsub-figure represents the results for a fixed entropy coefficient α. Thin lines represent the trainingaccuracy curves of different seeds. Thick lines represent the average across 10 seeds.
Figure 10: Training accuracy for a 10 communicating pairs when varying the KL coefficient β. Eachsub-figure represents the results for a fixed entropy coefficient α. Thin lines represent the trainingaccuracy curves of different seeds. Thick lines represent the average across 10 seeds.
Figure 11: Training accuracy for 1 and 10 pairs. Each sub-figure compares the best setting withno KL regularization (with entropy coefficient of 0.01) and the selected setting for our experiments,with a KL coefficient of 0.5 and entropy coefficient of 0.0001. Thin lines represent the trainingaccuracy curves of different seeds. Thick lines represent the average across 10 seeds. In both cases,the setting with the KL regularization, (0.5, 0.0001), exhibits a more stable convergence with alarger difference for population of 10 pairs.
Figure 12: ETL for the CelebA dataset of the emergent languages for different tasks. The results areaveraged across the emergent languages of min(5, N) different Speakers, newborn listeners’ seeds,and across the 10 seeds of each setting. The shaded region represents the standard deviation.
Figure 13: Test accuracy for different number of candidates at training time (subplot) and at evalu-ation time (lines) on ImageNet. As one would expect, given one model trained with |C| candidates,the more complex the evaluation task, the lower is the accuracy.
Figure 14: Test accuracy for different number of candidates at training time (lines) and at evaluationtime on ImageNet. The more we complexify evaluation, the better we discriminate representations.
