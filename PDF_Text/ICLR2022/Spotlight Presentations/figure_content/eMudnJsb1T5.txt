Figure 1: Updating particle approximations in constrained domains Θ. Standard updates like SVGD(dashed arrow) can push particles outside of the support. Our mirrored Stein updates in Alg. 1 (solidarrows) preserve the support by updating particles in a dual space and mapping back to Θ.
Figure 2: Quality of 50-particle approximations to 20-dimensional distributions on the simplex afterT particle updates. (Left) Sparse Dirichlet posterior of Patterson & Teh (2013). (Right) Quadraticsimplex target of Ahn & Chewi (2020). Details of the target distributions are in App. G.1.
Figure 3: Coverage of post-selection CIs across (a) 500 / (b) 200 replications of simulation of Sepehri& Markovic (2017).
Figure 4: (a) Sampling from a 2D selective density; (b) Unadjusted and post-selection CIs for themutations selected by the randomized Lasso as candidates for HIV-1 drug resistance (see Sec. 5.2).
Figure 5: Value of non-Euclidean geometry in large-scale Bayesian logistic regression.
Figure 6: The density functions of the same distribution in θ (left) and η (right) space underthe transformation η = Vψ(θ). Each θ folloWs a Beta distributions on [0, 1]. We choose thenegative entropy ψ(θ) = θ log θ + (1 - θ) log(1 - θ). Then, the transformation is the logit functionη = log(θ∕(1 — θ)) and its reverse is the sigmoid function θ = 1/(1 + e-η). TOP: θ 〜Beta(0.5,0.5).
Figure 7:	Sampling from a Dirichlet target on a 20-simplex. We plot the energy distance to a groundtruth sample of size 1000.
Figure 8:	Sampling from a quadratic target on a 20-simplex. We plot the energy distance to a groundtruth sample of size 1000 drawn by NUTS (Hoffman & Gelman, 2014).
Figure 9:	Width of post-selection CIs across (a) 500 / (b) 200 replications of simulation of Sepehri &Markovic (2017).
Figure 10: Logistic regression results on validation sets with learning rates in {0.01, 0.05, 0.1, 0.5,1}. Running RSVGD with learning rates 0.5 and 1 produces numerical errors. Therefore, we did notinclude them in the plot.
