Figure 1: Forsaken (Hsieh et al., 2021, Example 5.2) provides an example where the weak MVI constantρ does not satisfy algorithmic requirements of (EG+) and (EG+) does not converge to a stationary pointbut rather the attracting limit cycle (left). In contrast, adaptively choosing the extrapolation stepsize largeenough with our new method, called (CurvatureEG+), is sufficient for avoiding the limit cycles (right).
Figure 2: The grey region indicates where convergence provably cannot be guaranteed by Theorem 3.4.
Figure 3: Deterministic setting. In (a) we have an instance of Example 3 with P V —1/2Lfor whichTheorem 3.4 provides lower bound for extrapolation stepsize γk “ 1{L. However, adaptively choosingγk larger can converge as illustrated with (CurvatureEG+). In addition, (b) confirms with Example 5,that (CEG+) for αk = 1/2 and CEG may indeed not converge even when P “ —1/3l. In contrast, bothAdaptiVeEG + and (CurvatureEG+) converges to the stationary point. Note that picking ak V 1/3 wouldlead to convergence of (CEG+) by Corollary 3.2. See Fig. 6 and Fig. 7for supplementary experiments.
Figure 4: Stochastic setting. In (a) we test the stochastic algorithms on our nonconvex-nonconcave con-strained minimax example. The cycling behavior of SEG is inline with Hsieh et al. (2021), who shows thatthe sequence generated by SEG can converge to limit cycles of the underlying operator F. On the otherhand, we observe that SEG+ escapes the attracting limit cycle. In (b) we also provide a more challengingexample motivated by our lower bound.
Figure 5: We can construct the desired properties in polar coordinates pr, θq and subsequently transformit into a vectorfield in cartesian coordinates px,yq. This is illustrated by a PolarGame with attracting limitcycles at radius }z} “ 1 and repellant limit cycle at }z} “ 3{4 for the associated operator Fz as indicatedin red and blue respectively.
Figure 6: Example 3 for different values of a (and thereby different values of ρ). Note that even extragra-dient may escape the limit cycles even though P V 0. This is not in conflict with the negative results ofHsieh et al. (2021) since the stepsize is not diminishing. However, in the general case even extragradientwith fixed stepsize will not converge as shown by the lower bound in Theorem 3.4.
Figure 7: In (a) we observe that all algorithms converge, despite F having an attracting limit cycle inExample 4. However, note that in the stochastic setting, where diminishing stepsize is required, SEG doesnot converge to the critical point (see Fig. 4a). In (b) we demonstrate that when P “ 一1∕3l, pickingαk V 1∕3 for (CEG+) is necessary for convergence in general. See Section 6for the experimental setup.
Figure 8: Demonstration of algorithms on (Hsieh et al., 2021, Example 5.2). Only (CurvatureEG+) con-verges to the critical point, while the remaining methods, CEG, (CEG+) with ak = 1/2, and AdaptiveEG+converges to an attracting limit cycle. See Section 6 for further specification of the algorithms.
