Figure 1: Anomaly Transformer. Anomaly-Attention (left) models the prior-association and series-association simultaneously. In addition to the reconstruction loss, our model is also optimized bythe minimax strategy with a specially-designed stop-gradient mechanism (gray arrows) to constrainthe prior- and series-associations for more distinguishable association discrepancy.
Figure 2: Minimax association learning. At the minimize phase, the prior-association minimizes theAssociation Discrepancy within the distribution family derived by Gaussian kernel. At the maximizephase, the series-association maximizes the Association Discrepancy under the reconstruction loss.
Figure 3: ROC curves (horizontal-axis: false-positive rate; vertical-axis: true-positive rate) for thefive datasets. A higher AUC value (area under the ROC curve) indicates a better performance. Thepredefined threshold proportion r is in {0.5%, 1.0%, 1.5%, 2.0%, 10%, 20%, 30%}.
Figure 5: Visualization of different anomaly CategOrieS (Lai et al., 2021). We plot the raw SerieS(first row) from NeUrIPS-TS dataset, as well as their COrreSPOnding reconstruction (SeCOnd row) andassociation-baSed Criteria (third row). The POint-Wise anomalies are marked by red circles and thePattenI-WiSe anomalies are in red segments. The wrongly detected CaSeS are bounded by red boxes.
Figure 6: Learned scale parameter σ for different types of anomalies (highlight in red).
Figure 7: Parameter sensitivity for sliding window size (left) and loss weight λ (right). The modelwith λ = 0 still adopts the association-based criterion but only supervised by reconstruction loss.
Figure 8: Visualization of learned criterion for the NeurIPS-TS dataset. Anomalies are labeled byred circles and red segments (first row). The failure cases of the baselines are bounded by red boxes.
Figure 9: Visualization of the model learned criterion in real-world datasets. We select one dimen-sion of the data for visualization. These showcases are from the test set of corresponding datasets.
Figure 10: Change curve of reconstruction loss ∣∣X - XkF in real-world datasets during training.
Figure 11: Change curve of aSSociation diScrepancy kASSDiS(P, S; X)k1 in real-world dataSetSduring the training process.
