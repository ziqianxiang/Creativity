Figure 1: Illustration of the role of SA layers in Transformer-based ASR models and the proposedlayer-wise attention map reuse. We discover that lower layers and upper layers show different be-havior.
Figure 2: Cumulative at-tention diagonality (CAD)of each attention head.
Figure 3: Visualization of the phonetic localization. Each element corresponds to A[i, j] where i, jindicates the frame index. Several rows that correspond to a certain phoneme, give higher attentionto similar phonemes across the columns. For better visualization, we selectively draw boxes on threerepresentative patterns (S, ER, and IY).
Figure 4: Phoneme classi-fication accuracy on Lib-riSpeech test datasets. Thezeroth entry implies theclassifier is trained fromhidden representations ob-tained before the first SAlayer.
Figure 5: Averaged phoneme attention relationship of the lower half (1st, ... 8th) and upper half(9th, ... 16th) layers. The result is averaged through layers and heads on test-clean dataset. Eachrow and column corresponds to the phoneme index. Brighter (yellow) values indicate strongerattention between phonemes. Elements that stand out are highlighted, where phonemes with similarproperties tend to attend to each other.
Figure 6: Accumulated PAR coverage of lower layers (1st, ... 8th). Averaged PAR of the baseline(Figure 5(a)) is set to 1.0, which is considered to be a desirable reference. The left plot on theaccumulated coverage shows how each layer participates in covering the strength of the relationship.
Figure 8: Confusion matrix and phoneme accuracy for selected layers. Visualized the result fromthe LibriSpeech test-other dataset. Each row and column corresponds to the 37 phoneme classes,including ‘silence’ as zeroth class.
Figure 9: Examples of typical cumulative attention diagonality (CAD). (a) and (b) visualizes curves(before the integral) of four attention heads in each layer. x-axis and y-axis depict the relativedistance r and accumulated attention probability, respectively. CAD is represented as the area undercurve. CAD values of each head are also listed.
Figure 10: Sorted CAD over attention heads in the baseline model. Over 64 heads, 42 heads belongto the CAD value under 0.75. The table on the right side indicates the number of linguistic attentionheads that are of CAD value under 0.75.
Figure 11: Phoneme attention relationships (PAR) in SA layers. Averaged PAR of even-numberedlayers (2nd, 4th, ... 16th) are visualized. Lower layers show high correlations between similarphonetic features, but these relationships are weakened in upper layers.
Figure 12: Phoneme attention relationships of self-attention heads. Each head see different aspects,enriching the overall information the layer captures.
Figure 13: Phoneme attention relationship (PAR) for three attention map reuse configurations (2 × 8,4 × 4, 8 × 2). PAR(a)(b)(c) are obtained by averaging PAR of lower layers. Key missing relationshipis highlighted in white circles, such as (B, P), (G, K), and (DH, TH) in Figure 5(a).
