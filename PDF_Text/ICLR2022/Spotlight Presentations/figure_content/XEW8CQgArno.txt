Figure 1: Transformation of a feedforward network into a tree net. All nodes apart from the inputnodes use ReLU activation. The two neural nets drawn here compute the same function. This ideahas been used in Khim & Loh (2019) to prove generalization bounds for adversarial risk.
Figure 2: Pulling back of weights in a tree net. All nodes apart from the input nodes use theReLU activation. The original net was drawn in Figure 1a and 1b. This is possible due to thepositive-homogeneity of the activation function. From Figure 2b, one can recover the final tree netin Theorem 1 with weights from {-1, +1} and input from the path enumeration function h of theneural net by subdividing the edge incident to the input neurons and assign weights correspondingto sgn(h(x)).
Figure 3: Construction of G0 . G1 and G2 are the modified copies of G in step 2. In step 3, thetransformation TGi happens to coincide with Gi for i = 1, 2 in this case. G0 is created in step 4 byadding an extra vertex oG0 and connecting it to v1 and v2 with the appropriate weights and activationand can be seen in Figure 1b.
Figure 4: Jagged path. Here the straight arrow denote a single edge in the graph while the snakedarrow denote a path with possibly more than one edge. u and v are nodes in the statement of thesecond part of Lemma 2, a ∈ IN = INv = INu , b ∈ OUT = OUTv = OUTu .
