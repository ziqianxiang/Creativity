Figure 1: Machine Learning API with calibrated Proof-of-work. Answering queries with PoW consists ofthe following steps: θ An attacker sends queries drawn from an unlabeled dataset to a machine learning service.
Figure 2: Binary HashCash.
Figure 3: Privacy Cost vs Number of Queries. We measure the privacy cost against the number ofqueries for various query selection strategies on the MNIST, SVHN and CIFAR10 datasets.
Figure 4: Accuracy vs Privacy Cost. We measure the accuracy against the privacy cost for variousquery selection strategies on the MNIST, SVHN and CIFAR10 datasets. An attacker cannot achieve abetter tradeoff than a user with in-distribution data.
Figure 5: Adaptive attacks using in-distribution data.. We observe a tradeoff between attackers’goal to bypass our defense and the resulting accuracy they achieve. Accuracy, Entropy, Gap, andPrivacy costs of the victim model vs number of Queries and Accuracy vs Privacy for MNIST, SVHNand CIFAR10 datasets. We note that for the Accuracy vs Privacy graph, the final privacy cost of allmethods is the same. This is because at the end of the querying process all methods have used all theavailable samples.
Figure 6: Adaptive attacks using out-of-distribution data. Accuracy, Entropy, Gap, and Privacyof the victim model vs number of Queries and Accuracy vs Privacy for the MNIST, SVHN andCIFAR10 datasets.
Figure 7:	PoW against model extraction attacks for the CIFAR10 dataset.
Figure 8:	PoW against model extraction attacks for MNIST and SVHN datasets.
Figure 9:	PoW against model extraction attacks for the CIFAR10 dataset using the PkNN basedprivacy cost.
Figure 10: PoW against model extraction attacks for MNIST and SVHN datasets using the PkNNbased Privacy Cost. Here the worstcase and entropyrev methods use out of distribution data.
Figure 11:	InOut attack: Accuracy, Entropy, Gap, and Privacy of the victim model on all theanswered queries vs number of Queries for MNIST, SVHN and CIFAR10 datasets.
Figure 12:	AL attack: Accuracy of the attacker model vs number of Queries for MNIST, SVHNand CIFAR10 datasets, respectively. The accuracy of the student model resembles the increase inaccuracy for standard training. The higher the model accuracy, the more queries are needed (higherentropy is incurred) to further improve the model.
Figure 13:	AL attacks: Entropy, Gap, Privacy costs of the victim model on all the answeredqueries vs number of Queries for the MNIST, SVHN and CIFAR10 datasets, respectively. Theactive learning methods and random querying have similar trends in the privacy metrics. In this case,the gap-based attack helps more to achieve higher accuracy with fewer queries than the entropy attack.
Figure 14:	AL attacks: Entropy, Gap, Privacy costs of the victim model on all the answeredqueries vs number of Queries for the Imagenet dataset. It is easy to differentiate between the activelearning methods and random querying using all three metrics. Based on these empirical trends, theprivacy cost resembles more to entropy than the gap metric.
Figure 15: DataFree attack: Accuracy (of the student/attacker model) vs number of Queries forMNIST, SVHN, and CIFAR10 datasets, respectively. The accuracy of the student model resemblesthe increase in accuracy for a standard training. The higher the model accuracy, the more queries areneeded (higher entropy is incurred) to further improve the model. DataFree needs 2 mln queries toeither match the accuracy of the victim model (for SVHN) or 1.5 mln for MNIST and 20 mln forCIFAR10 to achieve its highest possible accuracy (which is a few percentage points lower than theaccuracy of the victim model).
Figure 16: Jacobian attacks: Accuracy (of the student/attacker model) vs number of Queriesfor MNIST, SVHN, and CIFAR10 datasets, respectively. The accuracy of the student model increasesby a large amount at the beginning when using small number of initial queries and then remainsrelatively constant (when there are more Jacobian augmented queries). This is likely because after theinitial subset of images, the others are generated based on Jacobian augmentation and thus eventuallywill not lead to sufficient new information for the model to learn from. Jacobian attack achieveslower accuracy of the extracted model than the other attacks (only about 80% for MNIST and 20%for SVHN as well as CIFAR10).
Figure 17:	Jacobian attacks: Entropy, Gap, Privacy costs of the victim model on all the an-swered queries vs number of Queries for the MNIST, SVHN and CIFAR10 datasets, respectively.
Figure 18:	MixMatch attack: Accuracy (of the student/attacker model) vs number of Queriesfor MNIST, SVHN, and CIFAR10 datasets, respectively. A higher number of queries leads to a higheraccuracy. The test accuracy corresponding to the epoch with the maximum validation accuracy isused for these plots. MixMatch is the best performing attack in terms of the task accuracy goal. Itrequires only around a few hundreds queries for MNIST, 1000 for SVHN, and 8000 for CIFAR10, toalmost match the accuracy of the victim model.
Figure 19:	MixMatch attack: Entropy, Gap, and Privacy costs of the victim model on all theanswered queries vs number of Queries for MNIST, SVHN and CIFAR10 datasets, respectively.
Figure 20:	AL attacks: Accuracy, Entropy, Gap, and Privacy of the victim model on all theanswered queries vs number of Queries for the Fashion-MNIST dataset. Random queries canprovide higher accuracy of the extracted model and lower costs incurred by the queries on the victim’sside than the simple AL methods.
Figure 21:	Jacobian attacks: Accuracy, Entropy, Gap, and Privacy of the victim model on allthe answered queries vs number of Queries for the Fashion-MNIST dataset.
Figure 22:	DataFree Attack: Accuracy, Entropy, Gap, and Privacy of the victim model on allthe answered queries vs number of Queries for the Fashion-MNIST dataset.
