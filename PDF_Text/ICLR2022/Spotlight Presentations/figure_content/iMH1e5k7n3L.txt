Figure 1: Continuous sequence spotting. A: Example spiking inputs. Black rectangles indicatefive spiking or silent continuous time-steps implying a positive example (blue, not red). B-D: RC-trained inference. B: Labels. C: first output spikes (blue, red, and grey indicate positive, negative, orno spike). D: Activations until first spike. E-G: Non-RC-trained model (backpropagation from theend of each sequence). In F and G the model was allowed to continue operating after the first spike.
Figure 2: (A) Input examples & (B) inference times of RC & non-RC LSTM throughout training.
Figure 3: Temporal MNIST with RC-convLSTM. 2 distinct regimes, i.e. an accurate & a fast one.
Figure 4: Validation accuracies (top row) and spike times (bottom row) during RC- (left) and con-ventional (right) training on Google Speech Commands, for varying regularization parameters. Theleft panels (RC-training) include a non-RC-trained baseline.
Figure 5: Speed-accuracy trade-off curves of RC- & non-RC-trained models produced by varyingthe RC threshold θ at inference, for various values ofβ. Red: The resulting composite best trade-off.
Figure 6: RC vs non-RC training on temporal MNIST. A. The non-RC model does not minimize itstiming throughout training, even if tested with RC inference, and even if trained much longer. B.
Figure 7: Effect of the threshold used during the RC training-phase on the 2-sequence problem’s testperformance. Colours and dots on a curve represent training-phase- and testing-phase-θ respectively.
Figure 8: Hidden temporal dynamics in the RC LSTM network in response to an example recordingof the utterance ”On”. The activity that would occur if operation were not stopped after the firstoutput spike is shown in grey-scale.
Figure 9: RC vs non-RC training of the SNN model introduced by Wu et al. (2018). A. The meantime of the first observed spike during training. B. The accuracy when evaluated at those first spikes.
Figure 10: Speed-accuracy trade-off curves of the final SNN models when evaluated at a range ofthreshold values.
