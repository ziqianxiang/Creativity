Figure 1: An illustration of the iterative generation procedure. Our model constructs the synthetic treein a bottom-up manner, starting from the available building blocks and building up to progressivelymore complex molecules. Generation is conditioned on an embedding for a target molecule. If thetarget molecule is in the chemical space reachable by our template set and building blocks, the finalroot molecule should match or at least be similar to the input target molecule.
Figure 2: Overview of our model. Within each step, at most two root molecules (most recent andanother) and the target molecule as a conditional code fully describe the state. The networks takethe embedding of the state and predict the action type, first reactant, reaction template, and secondreactant, successively. Those results are used to update the synthetic tree for one reaction step.
Figure 3: Examples from ChEMBL used as the target molecule for conditioned generation. (A)A successfully recovered molecule where the low similarity to any training examples indicates thegeneralizability of the model. (B) A molecule that is not recovered as an example of synthesizableanalog recommendation (i.e., a similar product). (C) A molecule that is not recovered but may inspireroute development to the true target. Matched substructures are highlighted.
Figure 4: Correlation between properties of Mtarget and Mproduct molecules.
Figure 5: Results of synthesizable molecular design. (A) A comparison between results of our model,DST, MARS, and GA+D on GSK3Î² bioactivity optimization. Our model proposes a highly scoredmolecule with a much simpler structure than the other baselines. (B) The results of docking scoreoptimization for Mpro of SARS-Cov-2. Our model successfully proposes multiple molecules withstronger predicted binding affinity than a known inhibitor.
Figure 6: Illustration of a synthetic pathway as a synthetic tree (A) and reaction templates (B &C). (A) is the synthetic tree of remdesivir, a drug authorized for emergency use to treat COVID-19.
Figure 7: Illustration of the genetic algorithm used to optimize the molecules. We use the conditionalsynthetic tree generator as a decoder to obtain molecules corresponding to input fingerprints. Wecrossover and mutate on the pool of fingerprints to optimize the molecule implicitly.
Figure 8: Correlation between input and output values on ChEMBL molecules.
Figure 9: Correlation between input and output values on test set molecules.
Figure 10: Correlation between input and output values on validation set molecules.
Figure 11: Correlation between input and output values on training set molecules.
Figure 12: The optimized structures and their corresponding synthetic pathways for various inhibitordesign tasks. The third row is optimizing docking score against the Mpro of SARS-Cov-2.
Figure 13: The validation loss during training with different radius and number of bits as networkinput. The validation loss is 1-accuracy, where the accuracies for the reactant networks are theaccuracies of the k-NN searches (k = 1).
Figure 14: The validation loss during training using different action embeddings to conduct the k-NNsearch. The validation loss is 1-accuracy, where the accuracies for the reactant networks are theaccuracies of the k-NN searches (k = 1).
