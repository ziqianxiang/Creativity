Figure 1: Schematic of 8-bit optimizers via block-wise dynamic quantization, see Section 2 for moredetails. After the optimizer update is performed in 32-bit, the state tensor is chunked into blocks,normalized by the absolute maximum value of each block. Then dynamic quantization is performed,and the index is stored. For dequantization, a lookup in the index is performed, with subsequent de-normalization by multiplication with the block-wise absolute maximum value. Outliers are confinedto a single block through block-wise quantization, and their effect on normalization is limited.
Figure 2: (1) The first bit of the data type is reserved fora sign. (2) The number of subsequent zero bits indicatesthe magnitude of the exponent. (3) The first bit that is setto one indicates that all folloWing values are reserved for Figure 2: Dynamic tree quantization.
Figure 3: Sensitivity analysis of 8-bit vs 32-bit Adam hyperparameters. We can see that there islittle variance between 8 and 32-bit performance, which suggests that 8-bit Adam can be used as adrop-in replacement for 32-bit Adam without any further hyperparameter tuning.
Figure 4: Good quantization methods do not have overlaps between regions of high use and higherror. The plot shows that for linear quantization regions of high usage and high error overlap. Fordynamic quantization regions with high relative error are used infrequently while only small regionshave high usage and high absolute error. Block-wise dynamic quantization spreads out the usageover a large space and has the lowest overlap between regions of high use and errors. This meansthat not only is the overall error of block-wise dynamic quantization lower, but also that large errorsfor individual parameter updates are rarer compared to other methods, thus improving stability. Seethe main text for more details.
Figure 5: Distribution of Adam error among each of the 256 8-bit values of the first Adam state.
Figure 6: Visualization of the quantization maps for the linear, dynamic and quantile quantization.
