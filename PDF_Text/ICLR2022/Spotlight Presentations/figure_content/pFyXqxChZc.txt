Figure 1: Comparison among IntSGD (8-bit or 32-bit), Heuristic IntSGD (8-bit or 32-bit), and full-precision SGD on the tasks of training ResNet18 and LSTM.
Figure 2: Time of communicating FP32 and Int8 messages based on all-reduce.
Figure 3: Convergence curves of IntSGD (Random) and IntSGD (Determ.) and the baseline algo-rithms on the task of training ResNet18 on the CIFAR-10 dataset.
Figure 4:rithms onConvergence curves of IntSGD (Random) and IntSGD (Determ.)the task of training a 3-layer LSTM on the Wikitext-2 dataset.
Figure 5:	Test accuracy (on the image classification task) and test loss (on the language modelingtask) of IntSGD under different hyperparameters β and ε. "↑" or "]” denotes the larger, the better orvice versa.
Figure 6:	Objective gaps and the max integer in the aggregated vector	in=1 Q(gik).
