title,year,conference
 Selective Dyna-style planningunder limited model capacity,2020, In ICML
 What matters for on-policy deep actor-critic methods? a large-scale study,2021, In InternationalConference on Learning Representations
 Model-based offline planning,2021, In International Confer-ence on Learning Representations
 Augmented world models facilitatezero-shot dynamics generalization from a single offline environment,2021, In Marina Meila and TongZhang (eds
 Weight uncertaintyin neural network,2015, In Francis Bach and David Blei (eds
 Sample-efficient reinforcement learning with stochastic ensemble value expansion,2018, In Advances in NeuralInformation Processing Systems
 Mea-suring the reliability of reinforcement learning algorithms,2020, In International Conference on LearningRepresentations
 Deep reinforcementlearning in a handful of trials using probabilistic dynamics models,2018, In Advances in NeuralInformation Processing Systems 31
 Primal Wassersteinimitation learning,2021, In International Conference on Learning Representations
 PILCO: A model-based and data-efficientapproach to policy search,2011, In Proceedings of the 28th International Conference on InternationalConference on Machine Learning
 Implementation matters in deep RL: A case study on PPO and TRPO,2020, InInternational Conference on Learning Representations
 Benchmarks for deep off-policy evaluation,2021, In International Confer-ence on Learning Representations
 On calibration of modern neuralnetworks,2017, In Doina Precup and Yee Whye Teh (eds
 Soft actor-critic algorithmsand applications,2018, CoRR
 When to trust your model: Model-basedpolicy optimization,2019, In Advances in Neural Information Processing Systems
 Accurate uncertainties for deep learningusing calibrated regression,2018, In Jennifer Dy and Andreas Krause (eds
 Conservative Q-learning for offlinereinforcement learning,2020, In Advances in Neural Information Processing Systems
 Model-ensembletrUst-region policy optimization,2018, In International Conference on Learning Representations
 Simple and scalable predictiveUncertainty estimation Using deep ensembles,2017, In Proceedings of the 31st International Conferenceon Neural Information Processing Systems
 Bayesian Methods for Adaptive Models,1992, PhD thesis
 Asimple baseline for bayesian Uncertainty in deep learning,2019, In H
 55-60 vol,1994,1
 Model predictive-actorcritic reinforcement learning for dexteroUs manipUlation,2021, In 2020 International Conference onComputer
 Can yoU trUst yoUr model's Uncertainty? evalU-ating predictive Uncertainty Under dataset shift,2019, In H
 In Uncertainty in ArtificialIntelligence,2021,2021
 Trust the model when it is confident: Maskedmodel-based actor-critic,2020, In H
 Provably efficient online hyperparameteroptimization with population-based bandits,2020, In Advances in Neural Information ProcessingSystems
 MBRL-Lib: A modular library for model-based reinforcement learning,2021, Arxiv
 Offline reinforcement learningfrom images with latent space models,2020, In Offline Reinforcement Learning Workshop at NeuralInformation Processing Systems
 Bayesian optimisationover multiple continuous and categorical inputs,2020, In International Conference on Machine Learning
 Model-based policy optimization with unsu-pervised model adaptation,2020, In H
 Uncertainty estimation using asingle deep deterministic neural network,9690, In Proceedings of the 37th International Conference onMachine Learning
 Visualizing data using t-SNE,2008, Journal of Ma-chine Learning Research
 Behavior regularized offline reinforcement learning,2021, InTo Appear: The International Conference on Learning Representations (ICLR)
 MOPO: Model-based offline policy optimization,2020, In Advances in Neural InformationProcessing Systems
 On the importance of hyperparameter optimization formodel-based reinforcement learning,2021, In Proceedings of The 24th International Conference onArtificial Intelligence and Statistics
