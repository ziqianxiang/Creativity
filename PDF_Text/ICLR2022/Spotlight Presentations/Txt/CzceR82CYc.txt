Published as a conference paper at ICLR 2022
Score-Based Generative	Modeling with
Critically-Damped Langevin Diffusion
Tim Dockhorn1,2,3,*
Arash Vahdat1
Karsten Kreis1
1NVIDIA	2University of Waterloo 3Vector Institute
tim.dockhorn@uwaterloo.ca,	{avahdat,kkreis}@nvidia.com
arXiv:2112.07068v4 [stat.ML] 25 Mar 2022
Ab stract
Score-based generative models (SGMs) have demonstrated remarkable synthe-
sis quality. SGMs rely on a diffusion process that gradually perturbs the data
towards a tractable distribution, while the generative model learns to denoise.
The complexity of this denoising task is, apart from the data distribution itself,
uniquely determined by the diffusion process. We argue that current SGMs em-
ploy overly simplistic diffusions, leading to unnecessarily complex denoising pro-
cesses, which limit generative modeling performance. Based on connections to
statistical mechanics, we propose a novel critically-damped Langevin diffusion
(CLD) and show that CLD-based SGMs achieve superior performance. CLD can
be interpreted as running a joint diffusion in an extended space, where the auxil-
iary variables can be considered “velocities” that are coupled to the data variables
as in Hamiltonian dynamics. We derive a novel score matching objective for CLD
and show that the model only needs to learn the score function of the conditional
distribution of the velocity given data, an easier task than learning scores of the
data directly. We also derive a new sampling scheme for efficient synthesis from
CLD-based diffusion models. We find that CLD outperforms previous SGMs in
synthesis quality for similar network architectures and sampling compute budgets.
We show that our novel sampler for CLD significantly outperforms solvers such as
Euler-Maruyama. Our framework provides new insights into score-based denois-
ing diffusion models and can be readily used for high-resolution image synthesis.
Project page and code: https://nv-tlabs.github.io/CLD- SGM.
1	Introduction
Score-based generative models (SGMs) and denoising diffusion probabilistic models have emerged
as a promising class of generative models (Sohl-Dickstein et al., 2015; Song et al., 2021c;b; Vahdat
et al., 2021; Kingma et al., 2021). SGMs offer high quality synthesis and sample diversity, do not
require adversarial objectives, and have found applications in image (Ho et al., 2020; Nichol &
Dhariwal, 2021; Dhariwal & Nichol, 2021; Ho et al., 2021), speech (Chen et al., 2021; Kong et al.,
2021; Jeong et al., 2021), and music synthesis (Mittal et al., 2021), image editing (Meng et al.,
2021; Sinha et al., 2021; Furusawa et al., 2021), super-resolution (Saharia et al., 2021; Li et al.,
2021), image-to-image translation (Sasaki et al., 2021), and 3D shape generation (Luo & Hu, 2021;
Zhou et al., 2021). SGMs use a diffusion process to gradually add noise to the data, transforming a
complex data distribution into an analytically tractable prior distribution. A neural network is then
utilized to learn the score function—the gradient of the log probability density—of the perturbed
data. The learnt scores can be used to solve a stochastic differential equation (SDE) to synthesize
new samples. This corresponds to an iterative denoising process, inverting the forward diffusion.
In the seminal work by Song et al. (2021c), it has been shown that the score function that needs to be
learnt by the neural network is uniquely determined by the forward diffusion process. Consequently,
the complexity of the learning problem depends, other than on the data itself, only on the diffusion.
Hence, the diffusion process is the key component of SGMs that needs to be revisited to further
improve SGMs, for example, in terms of synthesis quality or sampling speed.
* Work done during internship at NVIDIA.
1
Published as a conference paper at ICLR 2022
Figure 1: In critically-damped Langevin diffusion, the data xt is augmented with a velocity vt . A diffusion
coupling xt and vt is run in the joint data-velocity space (probabilities in red). Noise is injected only into vt .
This leads to smooth diffusion trajectories (green) for the data Xt. DenoiSing only requires Nvt logP(Vt |xt).
Inspired by statistical mechanics (Tuckerman, 2010), we propose a novel forward diffusion process,
the critically-damped Langevin diffusion (CLD). In CLD, the data variable, xt (time t along the
diffusion), is augmented with an additional “velocity” variable vt and a diffusion process is run in the
joint data-velocity space. Data and velocity are coupled to each other as in Hamiltonian dynamics,
and noise is injected only into the velocity variable. As in Hamiltonian Monte Carlo (Duane et al.,
1987; Neal, 2011), the Hamiltonian component helps to efficiently traverse the joint data-velocity
space and to transform the data distribution into the prior distribution more smoothly. We derive
the corresponding score matching objective and show that for CLD the neural network is tasked
with learning only the score of the conditional distribution of velocity given data Nvt log Pt (vt∣xt),
which is arguably easier than learning the score of diffused data directly. Using techniques from
molecular dynamics (Bussi & Parrinello, 2007; Tuckerman, 2010; Leimkuhler & Matthews, 2013),
we also derive a new SDE integrator tailored to CLD’s reverse-time synthesis SDE.
We extensively validate CLD and the novel SDE solver: (i) We show that the neural networks
learnt in CLD-based SGMs are smoother than those of previous SGMs. (ii) On the CIFAR-10
image modeling benchmark, we demonstrate that CLD-based models outperform previous diffusion
models in synthesis quality for similar network architectures and sampling compute budgets. We
attribute these positive results to the Hamiltonian component in the diffusion and to CLD’s easier
score function target, the score of the velocity-data conditional distribution Nvt logpt(vt|xt). (iii)
We show that our novel sampling scheme for CLD significantly outperforms the popular Euler-
Maruyama method. (iv) We perform ablations on various aspects of CLD and find that CLD does
not have difficult-to-tune hyperparameters.
In summary, we make the following technical contributions: (i) We propose CLD, a novel diffusion
process for SGMs. (ii) We derive a score matching objective for CLD, which requires only the
conditional distribution of velocity given data. (iii) We propose a new type of denoising score
matching ideally suited for scalable training of CLD-based SGMs. (iv) We derive a tailored SDE
integrator that enables efficient sampling from CLD-based models. (v) Overall, we provide novel
insights into SGMs and point out important new connections to statistical mechanics.
2	Background
Consider a diffusion process ut ∈ Rd defined by the Ito SDE
dut = f(ut,t)dt+ G(ut,t)dwt, t ∈ [0,T],	(1)
with continuous time variable t ∈ [0, T], standard Wiener process wt, drift coefficient f : Rd ×
[0, T] → Rd and diffusion coefficient G: Rd X [0, T] → Rd×d. Defining Ut := UT-t, a correspond-
ing reverse-time diffusion process that inverts the above forward diffusion can be derived (Anderson,
1982; Haussmann & Pardoux, 1986; Song et al., 2021c) (with positive dt and t ∈ [0, T]):
dut = h-f (Ut, T - t) + G(Ut, T - t)G(ut, T - t)> Vut logPT-t(Ut)i dt + G(Ut, T - t)dwt, (2)
where Vut log PT-t (Ut) is the score function of the marginal distribution over Ut at time T — t.
The reverse-time process can be used as a generative model. In particular, Song et al. (2021c) model
data x, setting P(U0)=Pdata(x). Currently used SDEs (Song et al., 2021c; Kim et al., 2021) have
drift and diffusion coefficients of the simple form f(xt, t)=f (t)xt and G(xt, t)=g(t)Id. Generally,
f and G are chosen such that the SDE’s marginal, equilibrium density is approximately Normal at
time T, i.e., P(UT)≈N (0, Id). We can then initialize x0 based on a sample drawn from a complex
2
Published as a conference paper at ICLR 2022
data distribution, corresponding to a far-from-equilibrium state. While the state x0 relaxes towards
equilibrium via the forward diffusion, We can learn a model sθ(xt,t) for the score Vχt logPt(Xt),
which can be used for synthesis via the reverse-time SDE in Eq. (2). If f and G take the simple
form from above, the denoising score matching (Vincent, 2011) objective for this task is:
min Et 〜U[0,T]Exo 〜p(xo)Ext 〜pt(xt |xo) [λ(t)ksθ (Xt,t) — VxtlOg Pt(Xt |x0)k2]
(3)
If f and G are affine, the conditional distribution Pt(Xt|X0) is Normal and available analyti-
Cally (Sarkka & Solin, 2019). Different λ(t) result in different trade-offs between synthesis quality
and likelihood in the generative model defined by sθ(Xt, t) (Song et al., 2021b; Vahdat et al., 2021).
3	Critically-Damped Langevin Diffusion
We propose to augment the data Xt ∈ Rd with auxiliary velocity1 variables vt ∈ Rd and utilize a
diffusion process that is run in the joint Xt-vt-space. With ut = (Xt, vt)> ∈ R2d, we set
f (ut,t) := ((-0β JTMMT) X Id) Ut , G(ut,t) = (0 √20Γβ) X Id	(4)
where X denotes the Kronecker product. The coupled SDE that describes the diffusion process is
(A-Xvt) βdt + (—rMd-1Vt) βdt + (√2Γβ) dwt,
(5)
'-----------------------------------}	'-------------------------------------------------------------------------------------}
z
z
Hamiltonian component=:H
Ornstein-Uhlenbeck process=:O
which corresponds to Langevin dynamics in each dimension. That is, each xi is independently cou-
pled to a velocity vi , which explains the blockwise structure of f and G. The mass M ∈ R+ is
a hyperparameter that determines the coupling between the Xt and vt variables; β ∈ R+ is a con-
stant time rescaling chosen such that the diffusion converges to its equilibrium distribution within
t ∈ [0, T] (in practice, we set T=1) when initialized from a data-defined non-equilibrium state and is
analogous to β(t) in previous diffusions (we could also use time-dependent β(t), but found constant
β,s to work well, and therefore opted for simplicity); Γ ∈ R+ is a friction coefficient that deter-
mines the strength of the noise injection into the velocities. Notice that the SDE in Eq. (5) consists
of two components. The H term represents a Hamiltonian component. Hamiltonian dynamics are
frequently used in Markov chain Monte Carlo methods to accelerate sampling and efficiently ex-
plore complex probability distributions (Neal, 2011). The Hamiltonian component in our diffusion
process plays a similar role and helps to quickly and smoothly converge the initial joint data-velocity
distribution to the equilibrium, or prior (see Fig. 1). Furthermore, Hamiltonian dynamics on their
own are trivially invertible (Tuckerman, 2010), which intuitively is also beneficial in our situation
when using this diffusion for training SGMs. The O term corresponds to an Ornstein-Uhlenbeck
process (Sarkka & Solin, 2019) in the velocity component, which injects noise such that the diffu-
sion dynamics properly converge to equilibrium for any Γ>0. It can be shown that the equilibrium
distribution of this diffusion is PEQ(U) = N (X; 0d, Id) N (v; 0d, MId) (see App. B.2).
There is a crucial balance between M and Γ (McCall, 2010): For Γ2<4M (underdamped Langevin
dynamics) the Hamiltonian component dominates, which implies oscillatory dynamics of Xt and vt
that slow down convergence to equilibrium. For Γ2 >4M (overdamped Langevin dynamics) the O-
term dominates which also slows down convergence, since the accelerating effect by the Hamiltonian
component is suppressed due to the strong noise injection. For Γ2 =4M (critical damping), an ideal
balance is achieved and convergence toPEQ(U) occurs as fast as possible in a smooth manner without
oscillations (also see discussion in App. A.1) (McCall, 2010). Hence, we propose to set Γ2=4M
and call the resulting diffusion critically-damped Langevin diffusion (CLD) (see Fig. 1).
Diffusions such as the VPSDE (Song et al., 2021c) correspond to overdamped Langevin dynamics
with high friction coefficients Γ (see App. A.2). Furthermore, in previous works noise is injected
directly into the data variables (pixels, for images). In CLD, only the velocity variables are subject
to direct noise and the data is perturbed only indirectly due to the coupling between Xt and vt .
1We call the auxiliary variables velocities, as they play a similar role as velocities in physical systems.
Formally, our velocity variables would rather correspond to physical momenta, but the term momentum is
already widely used in machine learning and our mass M is unitless anyway.
3
Published as a conference paper at ICLR 2022
3.1	Score Matching Objective
Considering the appealing convergence properties of CLD, we propose to utilize
CLD as forward diffusion process in SGMs. To this end, we initialize the joint
p(u0)=p(x0) p(v0)=pdata(x0)N(v0; 0d, γMId) with hyperparameter γ<1 and let the dis-
tribution diffuse towards the tractable equilibrium—or prior—distribution pEQ (u). We can then
learn the corresponding score functions and define CLD-based SGMs. Following a similar
derivation as Song et al. (2021b), we obtain the score matching (SM) objective (see App. B.3):
minEt〜U[0,τ]Eut〜Pt(Ut) [λ(t)ksθ(Ut,t) - Vvt logPt(Ut)k2]	(6)
θ
Notice that this objective requires only the velocity gradient of the log-density of the joint distribu-
tion, i.e., Vvt logpt(Ut). This is a direct consequence of injecting noise into the velocity variables
only. Without loss of generality, pt(Ut)=pt(xt, vt)=pt(vt|xt)pt(xt). Hence,
Vvt logpt(Ut) = Vvt [logpt(vt|xt) + logpt(xt)] = Vvt logpt(vt|xt)	(7)
This means that in CLD the neural network-defined score
model sθ(Ut, t) only needs to learn the score of the condi-
tional distribution pt(vt|xt), an arguably easier task than
learning the score of pt (xt), as in previous works, or of
the jointpt(Ut). This is the case, because our velocity dis-
tribution is initialized from a simple Normal distribution,
such that pt(vt|xt) is closer to a Normal distribution for
all t≥0 (and for any xt) thanpt(xt) itself. This is most ev-
ident at t=0: The data and velocity distributions are inde-
pendent at t=0 and the score ofp0(v0|x0)=p0(v0) simply
corresponds to the score of the Normal distribution p0 (v0)
from which the velocities are initialized, whereas the score
of the data distribution p0 (x0) is highly complex and can
even be unbounded (Kim et al., 2021). We empirically
verify the reduced complexity of the score ofpt(vt|xt) in
Fig. 2. We find that the score that needs to be learnt by
the model is more similar to a score corresponding to a
Normal distribution for CLD than for the VPSDE. We also
measure the complexity of the neural networks that were
learnt to model this score via the squared Frobenius norm
of their Jacobians. We find that the CLD-based SGMs have
significantly simpler and smoother neural networks than
VPSDE-based SGMs for most t, in particular when lever-
aging a mixed score formulation (see next section).
3.2	Scalable Training
A Practical Objective. We cannot train directly with
Eq. (6), since we do not have access to the marginal dis-
tribution pt(Ut). As presented in Sec. 2, we could employ
denoising score matching (DSM) and instead sample U0 ,
Figure 2: Top: Difference ξ(t) (via L2
norm) between score of diffused data and
score of Normal distribution. Bottom:
Frobenius norm of Jacobian JF (t) of the
neural network defining the score function
for different t. The underlying data distri-
bution is a mixture of Normals. Insets: Dif-
ferent axes (see App. E.1 for detailed defi-
nitions of ξ(t) and JF (t)).
and diffuse those samples, which would lead to a tractable objective. However, recall that in CLD
the distribution at t=0 is the product of a complex data distribution and a Normal distribution over
the initial velocity. Therefore, We propose a hybrid version of score matching (Hyvarinen, 2005)
and denoising score matching (Vincent, 2011), which we call hybrid score matching (HSM). In
HSM, We draW samples from p0 (x0)=pdata (x0) as in DSM, but then diffuse those samples While
marginalizing over the full initial velocity distribution p0 (v0)=N(v; 0d, γMId) as in regular SM
(HSM is discussed in detail in App. C). Since p0(v0) is Normal (and f and G affine), p(Ut|x0) is
also Normal and this remains tractable. We can Write this HSM objective as:
minEt∈[0,T]EX0〜P0(χo)EutZpt(Ut|xo) [λ(t)ksθ(Ut,t) - Vvt logPt(Ut|x0)k2].	⑻
θ
In HSM, the expectation over P0 (v0) is essentially solved analytically, While DSM Would use a
sample-based estimate. Hence, HSM reduces the variance of training objective gradients compared
to pure DSM, Which We validate in App. C.1. Furthermore, When draWing a sample U0 to diffuse in
4
Published as a conference paper at ICLR 2022
DSM, we are essentially placing an infinitely sharp Normal with unbounded score (Kim et al., 2021)
at u0, which requires undesirable modifications or truncation tricks for stable training (Song et al.,
2021c; Vahdat et al., 2021). Hence, with DSM we could lose some benefits of the CLD framework
discussed in Sec. 3.1, whereas HSM is tailored to CLD and fundamentally avoids such unbounded
scores. Closed form expressions for the perturbation kernel pt(ut|x0) are provided in App. B.1.
Score Model Parametrization. (i) Ho et al. (2020) found that it can be beneficial to parameter-
ize the score model to predict the noise that was used in the reparametrized sampling to generate
perturbed samples ut. For CLD, Ut = μt(xo) + Lt侬,where ∑t = LtL> is the Cholesky de-
composition of pt(ut|xo)’s covariance matrix,功& 〜N(5； 02d,I2d), and μt(xo) is Pt(ut∣xo),s
mean. Furthermore,十旷, logpt(u∕xo) = —'t^d：2d, where，：2d denotes those d components of 与&
that actually affect Vvt logPt(Ut |xo) (since We take velocity gradients only, not all are relevant).
With
we have `t :=
Σtxx
∑xx∑vv - (∑xv)2 .
(ii) Vahdat et al. (2021) showed that it can be beneficial to assume that the diffused marginal distri-
bution is Normal at all times and parametrize the model with a Normal score and a residual “correc-
tion”. For CLD, the score is indeed Normal at t = 0 (due to the independently initialized x and v at
t=0). Similarly, the target score is close to Normal for large t, as we approach the equilibrium.
Based on (i) and (ii), we parameterize sθ(ut,t) = -'tɑe(ut,t) with ae(ut,t) = '-1vt∕∑Vv +
α0θ(Ut, t), where Σtvv corresponds to the v-v component of the “per-dimension” covariance matrix of
the Normal distributionPt(Ut|x0 = 0d). In other words, we assumedP0(x0) = δ(x) when defining
the analytic term of the score model. Formally, -v∕Σtvv is the score of a Normal distribution with
covariance ΣtvvId. Following Vahdat et al. (2021), we refer to this parameterization as mixed score
parameterization. Alternative model parameterizations are possible, but we leave their exploration
to future work. With this definition, the HSM training objective becomes (details in App. B.3):
min Et 〜U [0,T]EX0 〜po(X0)E€2d 〜N(€2d；02d,l2d) [λ⑴'2 || 42d - αθ (%(XO)+ Lt ^2d ,tXl2],	⑼
θ
which corresponds to training the model to predict the noise only injected into the velocity during
reparametrized sampling of Ut, similar to noise prediction in Ho et al. (2020); Song et al. (2021c).
Objective Weightings. For λ(t) = Γβ, the objective corresponds to maximum likelihood learning
(Song et al., 2021b) (see App. B.3). Analogously to prior work (Ho et al., 2020; Vahdat et al., 2021;
Song et al., 2021b), an objective better suited for high quality image synthesis can be obtained by
setting λ(t) = `t-2, which corresponds to “dropping the variance prefactor” `t2 .
3.3 Sampling from CLD-based SGMs
To sample from the CLD-based SGM we can either directly simulate the reverse-time diffusion pro-
cess (Eq. (2)) or, alternatively, solve the corresponding probability flow ODE (Song et al., 2021c;b)
(see App. B.5). To simulate the SDE of the reverse-time diffusion process, previous works often re-
lied on Euler-Maruyama (EM) (Kloeden & Platen, 1992) and related methods (Ho et al., 2020; Song
et al., 2021c; Jolicoeur-Martineau et al., 2021a). We derive a new solver, tailored to CLD-based
models. Here, we provide the high-level ideas and derivations (see App. D for details).
Our generative SDE can be written as (with Ut = UT-t, Xt = XT-t, Vt = VT-t):
(dX；) = (Mxtvt) βdt+ (-rM-1Vt) βdt + (√2⅛w) +(2「[s(Ut,T -0(t) + MTvt]) βdt
s--------------{z------} V--------------{z-------------} V----------------V-------------}
AH	AO	S
It consists of a Hamiltonian component AH, an Ornstein-Uhlenbeck process AO, and the score
model term S. We could use EM to integrate this SDE; however, standard Euler methods are not
well-suited for Hamiltonian dynamics (Leimkuhler & Reich, 2005; Neal, 2011). Furthermore, if S
was 0, we could solve the SDE in closed form. This suggests the construction of a novel integrator.
We use the Fokker-Planck operator2 formalism (Tuckerman, 2010; Leimkuhler & Matthews, 2013;
2015). Using a similar notation as Leimkuhler & Matthews (2013), the Fokker-Planck equation
2The Fokker-Planck operator is also known as Kolmogorov operator. If the underlying dynamics is fully
Hamiltonian, it corresponds to the Liouville operator (Leimkuhler & Matthews, 2015; Tuckerman, 2010).
5
Published as a conference paper at ICLR 2022
_ _ ʌ ʌ ʌ ʌ
corresponding to the generative SDE is ∂pt(ut)∕∂t=(LA+LS)pt(ut), where LA and LS are the
non-commuting Fokker-Planck operators corresponding to the A:=AH +AO and S terms, respec-
ʌ ʌ
tively. Expressions for LA and LS can be found in App. D. We can construct a formal, but intractable
solution of the generative SDE as Ut = et(LA+LS)u0, where the operator et(LA+LS) (known as the
classical propagator in statistical physics) propagates states U0 for time t according to the dynamics
ʌ ʌ
defined by the combined operators LA + LS. Although this operation is not analytically tractable,
it can serve as starting point to derive a practical integrator. Using the symmetric Trotter theorem or
Strang splitting formula as well as the Baker-Campbell-Hausdorff formula (Trotter, 1959; Strang,
1968; Tuckerman, 2010), it can be shown that:
et(LA+LS) = Nlim∞ he粤LAeδtLSe粤LAiN ≈ he粤LAeδtLSe萼LAiN + O(Nδt3),	(10)
for large N ∈ N+ and time step δt := t/N. The expression suggests that instead of directly
evaluating the intractable et(LA+LS), We can discretize the dynamics over t into N pieces of step
size δt, such that We only need to apply the individual e δt LA and eδtLS many times one after another
for small steps δt. A finer discretization results in a smaller error (since N=t∕δt,the error effectively
scales as O(δt2) for fixed t). Hence, this implies an integration method. Indeed, eδtLA Ut is available
^*
in closed form, as mentioned before; however, eδtLS Ut is not. Therefore, We approximate this latter
component of the integrator via a standard Euler step. Thus, the integrator formally has an error of
the same order as standard EM methods. Nevertheless, as long as the dynamics is not dominated by
the S component, our proposed integration scheme is expected to be more accurate than EM, since
we split off the analytically tractable part and only use an Euler approximation for the S term. Recall
that the model only needs to learn the score of the conditional distribution pt (vt |xt), which is close
to Normal for much of the diffusion, in which case the S term will indeed be small. This suggests
that the generative SDE dynamics are in fact dominated by AH and AO in practice. Note that only
the propagator eδtL*S is computationally expensive, as it involves evaluating the neural network. We
coin our novel SDE integrator for CLD-based SGMs Symmetric Splitting CLD Sampler (SSCS). A
detailed derivation, analyses, and a formal algorithm are presented in App. D.
4	Related Work
Relations to Statistical Mechanics and Molecular Dynamics. Learning a mapping between a
simple, tractable and a complex distribution as in SGMs is inspired by annealed importance sam-
pling (Neal, 2001) and the Jarzynski equality from non-equilibrium statistical mechanics (Jarzynski,
1997a;b; 2011; Bahri et al., 2020). However, after Sohl-Dickstein et al. (2015), little attention has
been given to the origins of SGMs in statistical mechanics. Intuitively, in SGMs the diffusion pro-
cess is initialized in a non-equilibrium state U0 and we would like to bring the system to equilibrium,
i.e., the tractable prior distribution, as quickly and as smoothly as possible to enable efficient denois-
ing. This “equilibration problem” is a much-studied problem in statistical mechanics, particularly in
molecular dynamics, where a molecular system is often simulated in thermodynamic equilibrium.
Algorithms to quickly and smoothly bring a system to and maintain at equilibrium are known as
thermostats. In fact, CLD is inspired by the Langevin thermostat (Bussi & Parrinello, 2007). In
molecular dynamics, advanced thermostats are required in particular for “multiscale” systems that
show complex behaviors over multiple time- and length-scales. Similar challenges also arise when
modeling complex data, such as natural images. Hence, the vast literature on thermostats (Ander-
sen, 1980; Nose, 1984; Hoover, 1985; Martyna et al., 1992; Hunenberger, 2005; Bussi et al., 2007;
Ceriotti et al., 2009; 2010; Tuckerman, 2010) may be valuable for the development of future SGMs.
Also the framework for developing SSCS is borrowed from statistical mechanics. The same tech-
niques have been used to derive molecular dynamics algorithms (Tuckerman et al., 1992; Bussi &
Parrinello, 2007; Ceriotti et al., 2010; Leimkuhler & Matthews, 2013; 2015; Kreis et al., 2017).
Further Related Work. Generative modeling by learning stochastic processes has a long history
(Movellan, 2008; Lyu, 2009; Sohl-Dickstein et al., 2011; Bengio et al., 2014; Alain et al., 2016;
Goyal et al., 2017; Bordes et al., 2017; Song & Ermon, 2019; Ho et al., 2020). We build on Song et al.
(2021c), which introduced the SDE framework for modern SGMs. Nachmani et al. (2021) recently
introduced non-Gaussian diffusion processes with different noise distributions. However, the noise
is still injected directly into the data, and no improved sampling schemes or training objectives are
introduced. Vahdat et al. (2021) proposed LSGM, which is complementary to CLD: we improve
6
Published as a conference paper at ICLR 2022
the diffusion process itself, whereas LSGM “simplifies the data” by first embedding it into a smooth
latent space. LSGM is an overall more complicated framework, as it is trained in two stages and
relies on additional encoder and decoder networks. Recently, techniques to accelerate sampling from
pre-trained SGMs have been proposed (San-Roman et al., 2021; Watson et al., 2021; Kong & Ping,
2021; Song et al., 2021a). Importantly, these methods usually do not permit straightforward log-
likelihood estimation. Furthermore, they are originally not based on the continuous time framework,
which we use, and have been developed primarily for discrete-step diffusion models.
A complementary work to CLD is “Gotta Go Fast” (GGF) (Jolicoeur-Martineau et al., 2021a), which
introduces an adaptive SDE solver for SGMs, tuned towards image synthesis. GGF uses standard
Euler-based methods under the hood (Kloeden & Platen, 1992; Roberts, 2012), in contrast to our
SSCS that is derived from first principles. Furthermore, our SDE integrator for CLD does not make
any data-specific assumptions and performs extremely well even without adaptive step sizes.
Some works study SGMs for maximum likelihood training (Song et al., 2021b; Kingma et al., 2021;
Huang et al., 2021). Note that we did not focus on training our models towards high likelihood.
Furthermore, Chen et al. (2020) and Huang et al. (2020) recently trained augmented Normalizing
Flows, which have conceptual similarities with our velocity augmentation. Methods leveraging
auxiliary variables similar to our velocities are also used in statistics—such as Hamiltonian Monte
Carlo (Neal, 2011)—and have found applications, for instance, in Bayesian machine learning (Chen
et al., 2014; Ding et al., 2014; Shang et al., 2015). As shown in Ma et al. (2019), our velocity is
equivalent to momentum in gradient descent and related methods (Polyak, 1964; Kingma & Ba,
2015). Momentum accelerates optimization; the velocity in CLD accelerates mixing in the diffusion
process. Lastly, our CLD method can be considered as a second-order Langevin algorithm, but even
higher-order schemes are possible (Mou et al., 2021) and could potentially further improve SGMs.
5	Experiments
Architectures. We focus on image synthesis and implement CLD-based SGMs using NCSN++ and
DDPM++ (Song et al., 2021c) with 6 input channels (for velocity and data) instead of 3.
Relevant Hyperparameters. CLD’s hyperparameters are chosen as β=4, Γ=1 (or equivalently
M-1=4) in all experiments. We set the variance scaling of the inital velocity distribution to γ=0.04
and use the proposed HSM objective with the weighting λ(t)='-2, which promotes image quality.
Sampling. We generate model samples via: (i) Probability flow using a RUnge-KUtta 4(5) method;
reverse-time generative SDE sampling using either (ii) EM or (iii) our SSCS. For methods without
adaptive stepsize (EM and SSCS), we use evaluation times chosen according to a quadratic function,
like previous work (Song et al., 2021a; Kong & Ping, 2021; Watson et al., 2021) (indicated by QS).
Evaluation. We measure image sample quality for CIFAR-10 via Frechet inception distance (FID)
with 50k samples (Heusel et al., 2017). We also evaluate an upper bound on the negative log-
likelihood (NLL): - logp(xo)≤-Ev0〜p(v0)logpε(xo, vo)-H, where H is the entropy of p(vo)
and logpε(x0, v0) is an unbiased estimate of logp(x0, v0) from the probability flow ODE (Grath-
wohl et al., 2019; Song et al., 2021c). As in Vahdat et al. (2021), the stochasticity of logpε(x, v)
prevents us from performing importance weighted NLL estimation over the velocity distribution
(Burda et al., 2015). We also record the number of function—neural network—evaluations (NFEs)
during synthesis when comparing sampling methods. All implementation details in App. B.5 and E.
5.1	Image Generation
Following Song et al. (2021c), we focus on the widely used CIFAR-10 unconditional image genera-
tion benchmark. Our CLD-based SGM achieves an FID of 2.25 based on the probability flow ODE
and an FID of 2.23 via simulating the generative SDE (Tab. 1). The only models marginally out-
performing CLD are LSGM (Vahdat et al., 2021) and NSCN++/VESDE with 2,000 step predictor-
corrector (PC) sampling (Song et al., 2021c). However, LSGM uses a model with ≈475M pa-
rameters to achieve its high performance, while we obtain our numbers with a model of ≈100M
parameters. For a fairer comparison, we trained a smaller LSGM also with ≈100M parameters,
which is reported as “LSGM-100M” in Tab. 1 (details in App. E.2.7). Our model has a significantly
better FID score than “LSGM-100M”. In contrast to NSCN++/VESDE, we achieve extremely strong
results with much fewer NFEs (for example, see n∈{150, 275, 500} in Tab. 3 and also Tab. 2)—the
VESDE performs poorly in this regime. We conclude that when comparing models with similar
7
Published as a conference paper at ICLR 2022

GiER*r>Hl≡
Table 1: Unconditional CIFAR-10 generative performance.
Class	Model	NLLJ	FIDJ
Score	CLD-SGM (Prob. Flow) (ours)	≤3.31	2.25
	CLD-SGM (SDE) (ours)	-	2.23
	DDPM++, VPSDE (Prob. Flow) (Song et al., 2021C)	3.13	3.08
	DDPM++, VPSDE (SDE) (Song et al., 2021c)	-	2.41
	DDPM++, sub-VP (Prob. Flow) (Song et al., 2021C)	2.99	2.92
	DDPM++, sub-VP (SDE) (Song et al., 2021C)	-	2.41
	NCSN++, VESDE (SDE) (Song et al., 2021C)	-	2.20
	LSGM (Vahdat et al., 2021)	≤3.43	2.10
	LSGM-100M (Vahdat et al., 2021)	≤2.96	4.60
	DDPM (Ho et al., 2020)	≤3.75	3.17
	NCSN (Song & Ermon, 2019)	-	25.3
Score	Adversarial DSM (JoliCoeur-Martineau et al., 2021b)	-	6.10
	Likelihood SDE (Song et al., 2021b)	2.84	2.87
	DDIM (100 steps) (Song et al., 2021a)	-	4.16
	FastDDPM (100 steps) (Kong & Ping, 2021)	-	2.86
	Improved DDPM (NiChol & Dhariwal, 2021)	3.37	2.90
	VDM (Kingma et al., 2021)	≤2.49	7.41 (4.00)
	UDM (Kim et al., 2021)	3.04	2.33
	D3PM (Austin et al., 2021)	≤3.44	7.34
	Gotta Go Fast (JoliCoeur-Martineau et al., 2021a)	-	2.44
	DDPM Distillation (Luhman & Luhman, 2021)	-	9.36
	SNGAN (Miyato et al., 2018)	-	21.7
	SNGAN+DGflow (Ansari et al., 2021)	-	9.62
	AutoGAN (Gong et al., 2019)	-	12.4
GANs	TransGAN (Jiang et al., 2021)	-	9.26
	StyleGAN2 w/o ADA (Karras et al., 2020)	-	8.32
	StyleGAN2 w/ ADA (Karras et al., 2020)	-	2.92
	StyleGAN2 Wl Diffaug (Zhao et al., 2020)	-	5.79
	DiStAUg (JUn et al., 2020)	2.53	42.90
	PixelCNN (Oord et al., 2016)	3.14	65.9
	Glow (Kingma & Dhariwal, 2018)	3.35	48.9
Aut.-Reg.,	ReSidual Flow (Chen et al., 2019)	3.28	46.37
Flows,	NVAE (Vahdat & Kautz, 2020)	2.91	23.5
VAEs,	NCP-VAE (Aneja et al., 2021)	-	24.08
EBMs	DC-VAE Parmar et al. (2021)	-	17.90
	IGEBM (Du & MordatCh, 2019)	-	40.6
	VAEBM (Xiao et al., 2021)	-	12.2
	ReCovery EBM (Gao et al., 2021)	3.18	9.58
幽门「saiEi，IB
运商的■里■
∙J≡?雇||。，
iSΓ≡BD⅛n
92T33
Figure 3: CIFAR-10 samples.
Figure 4: CelebA-HQ-256 samples.

network capacity and under NFE budgets ≤500, our CLD-SGM outperforms all published results in
terms of FID. We attribute these positive results to our easier score matching task. Furthermore, our
model reaches an NLL bound of 3.31, which is on par with recent works such as Nichol & Dhariwal
(2021); Austin et al. (2021); Vahdat et al. (2021) and indicates that our model is not dropping modes.
However, our bound is potentially quite loose (see discussion in App. B.5) and the true NLL might
be significantly lower. We did not focus on training our models towards high likelihood.
To demonstrate that CLD is also suitable for high-resolution image synthesis, we additionally trained
a CLD-SGM on CelebA-HQ-256, but without careful hyperparameter tuning due to limited compute
resources. Model samples in Fig. 4 appear diverse and high-quality (additional samples in App. F).
5.2	Sampling Speed and Synthesis Quality Trade-Offs
We analyze the sampling speed vs. synthesis quality trade-off for CLD-SGMs and study SSCS’s
performance under different NFE budgets (Tabs. 2 and 3). We compare to Song et al. (2021c) and
use EM to solve the generative SDE for their VPSDE and PC (reverse-diffusion + Langevin sampler)
for the VESDE model. We also compare to the GGF (Jolicoeur-Martineau et al., 2021a) solver for
the generative SDE as well as probability flow ODE sampling with a higher-order adaptive step
size solver. Further, we compare to LSGM (Vahdat et al., 2021) (using our LSGM-100M), which
also uses probability flow sampling. With one exception (VESDE with 2,000 NFE) our CLD-SGM
outperforms all baselines, both for adaptive and fixed-step size methods. More results in App. F.2.
Several observations stand out: (i) As expected (Sec. 3.3), for CLD, SSCS significantly outperforms
EM under limited NFE budgets. When using a fine discretization of the SDE (high NFE), the two
perform similarly, which is also expected, as the errors of both methods will become negligible.
(ii) In the adaptive solver setting, using a simpler ODE solver, we even outperform GGF, which is
tuned towards image synthesis. (iii) Our CLD-SGM also outperforms the LSGM-100M model in
terms of FID. It is worth noting, however, that LSGM was designed primarily for faster synthesis,
which it achieves by modeling a smooth distribution in latent space instead of the more complex
data distribution directly. This suggests that it would be promising to combine LSGM with CLD
and train a CLD-based LSGM, combining the strengths of the two approaches. It would also be
interesting to develop a more advanced, adaptive SDE solver that leverages SSCS as the backbone
8
Published as a conference paper at ICLR 2022
Table 2: (right) Performance using adaptive stepsize solvers (ODE is based on probability flow, GGF simulates
generative SDE). f: taken from JoliCoeur-Martineau et al. (2021a). LSGM corresponds to the small LSGM-
100M model for fair comparison (details in App. E.2.7). Error tolerances were chosen to obtain similar NFEs.
Table 3: (bottom) Performance using non-adaptive stepsize solvers (for
PC, QS performed poorly). f: 2.23 FID is our evaluation, Song et al.
(2021c) reports 2.20 FID. See Tab. 9 in App. F.2 for extended results.
Model	Sampler	FID at n function evaluations 1					
		n=50	n=150	n=275	n=500	n=1000	n=2000
CLD	EM-QS	52.7	7.00	3.24	2.41	2.27	2.23
CLD	SSCS-QS	20.5	3.07	2.38	2.25	2.30	2.29
VPSDE	EM-QS	28.2	4.06	2.65	2.47	2.66	2.60
VESDE	PC	460	216	11.2	3.75	2.43	2.231
Model	Solver	NFEs1	FID1
CLD	ODE	312	2.25
VPSDE	GGF	330	2.561
VESDE	GGF	488	2.991
CLD	ODE	147	2.71
VPSDE	ODE	141	2.76
VPSDE	GGF	151	2.731
VESDE	ODE	182	7.63
VESDE	GGF	170	10.151
LSGM	ODE	131	4.60
and, for example, potentially test our method within a framework like GGF. Our current SSCS only
allows for fixed step sizes—nevertheless, it achieves excellent performance. Table 4: Mass hyperpa-
5.3	Ablation Studies
rameter.
M-1	NLLI	FID1
1	≤3.30	3.23
4	≤3.37	3.14
16	≤3.26	3.16
Table 5: Initial velocity
distribution width.
γ	NLLI	FID1
0.04	≤3.37	3.14
0.4	≤3.15	3.21
1	≤3.15	3.27
We perform ablation studies to study CLD’s new hyperparameters (run with
a smaller version of our CLD-SGM used above; App. E for details).
Mass Parameter: Tab. 4 shows results for a CLD-SGM trained with dif-
ferent M-1 (also recall that M-1 and Γ are tied together via Γ2 = 4M; we
are always in the critical-damping regime). Different mass values perform
mostly similarly. Intuitively, training with smaller M-1 means that noise
flows from the velocity variables vt into the data xt more slowly, which
necessitates a larger time rescaling β. We found that simply tying MT and
β together via β=8√M works well and did not further fine-tune.
Initial Velocity Distribution: Tab. 5 shows results for a CLD-SGM trained with different initial
velocity variance scalings γ. Varying γ similarly has only a small effect, but small γ seems slightly
beneficial for FID, while the NLL bound suffers a bit. Due to our focus on synthesis quality as
measued by FID, we opted for small γ. Intuitively, this means that the data at t=0 is “at rest”, and
noise flows from the velocity into the data variables only slowly.
Mixed Score: Similar to previous work (Vahdat et al., 2021), we find training with the mixed score
(MS) parametrization (Sec. 3.2) beneficial. With MS, we achieve an FID of 3.14, without only 3.56.
Hybrid Score Matching: We also tried training with regular DSM, instead of HSM. However,
training often became unstable. As discussed in Sec. 3.2, this is likely because when using standard
DSM our CLD would suffer from unbounded scores close to t=0, similar to previous SDEs (Kim
et al., 2021). Consequently, we consider our novel HSM a crucial element for training CLD-SGMs.
We conclude that CLD does not come with difficult-to-tune hyperparameters. We expect our chosen
hyperparameters to immediately translate to new tasks and models. In fact, we used the same M-1,
γ, MS and HSM settings for CIFAR-10 and CelebA-HQ-256 experiments without fine-tuning.
6	Conclusions
We presented critically-damped Langevin diffusion, a novel diffusion process for training SGMs.
CLD diffuses the data in a smoother, easier-to-denoise manner compared to previous SGMs, which
results in smoother neural network-parametrized score functions, fast synthesis, and improved ex-
pressivity. Our experiments show that CLD outperforms previous SGMs on image synthesis for
similar-capacity models and sampling compute budgets, while our novel SSCS is superior to EM in
CLD-based SGMs. From a technical perspective, in addition to proposing CLD, we derive CLD’s
score matching objective termed as HSM, a variant of denoising score matching suited for CLD, and
we derive a tailored SDE integrator for CLD. Inspired by methods used in statistical mechanics, our
work provides new insights into SGMs and implies promising directions for future research.
We believe that CLD can potentially serve as the backbone diffusion process of next generation
SGMs. Future work includes using CLD-based SGMs for generative modeling tasks beyond images,
combining CLD with techniques for accelerated sampling from SGMs, adapting CLD-based SGMs
towards maximum likelihood, and utilizing other thermostating methods from statistical mechanics.
9
Published as a conference paper at ICLR 2022
7	Ethics and Reproducibility
Our paper focuses on fundamental algorithmic advances to improve the generative modeling perfor-
mance of SGMs. As such, the proposed CLD does not imply immediate ethical concerns. However,
we validate CLD on image synthesis benchmarks. Generative modeling of images has promising
applications, for example for digital content creation and artistic expression (Bailey, 2020), but can
also be used for nefarious purposes (Vaccari & Chadwick, 2020; Mirsky & Lee, 2021; Nguyen et al.,
2021). It is worth mentioning that compared to generative adversarial networks (Goodfellow et al.,
2014), a very popular class of generative models, SGMs have the promise to model the data more
faithfully, without dropping modes and introducing problematic biases. Generally, the ethical impact
of our work depends on its application domain and the task at hand.
To aid reproducibility of the results and methods presented in our paper, we made source code to
reproduce the main results of the paper publicly available, including detailed instructions; see our
project page https://nv-tlabs.github.io/CLD-SGM and the code repository https:
//github.com/nv-tlabs/CLD-SGM. Furthermore, all training details and hyperparameters
are already in detail described in the Appendix, in particular in App. E.
References
Guillaume Alain, Yoshua Bengio, Li Yao, Jason Yosinski, Eric Thibodeau-Laufer, Saizheng Zhang,
and Pascal Vincent. GSNs: generative stochastic networks. Information and Inference: A Journal
ofthe IMA, 5(2):210-249, 03 2016. ISSN 2049-8764.
Hans C. Andersen. Molecular dynamics simulations at constant pressure and/or temperature. The
Journal of Chemical Physics, 72(4):2384-2393, 1980.
Brian DO Anderson. Reverse-time diffusion equation models. Stochastic Processes and their Ap-
plications, 12(3):313-326, 1982.
Jyoti Aneja, Alexander Schwing, Jan Kautz, and Arash Vahdat. A Contrastive Learning Ap-
proach for Training Variational Autoencoder Priors. In Neural Information Processing Systems
(NeurIPS), 2021.
Abdul Fatir Ansari, Ming Liang Ang, and Harold Soh. Refining Deep Generative Models via Dis-
criminator Gradient Flow. In International Conference on Learning Representations, 2021.
Jacob Austin, Daniel Johnson, Jonathan Ho, Danny Tarlow, and Rianne van den Berg. Structured
Denoising Diffusion Models in Discrete State-Spaces. In Neural Information Processing Systems
(NeurIPS), 2021.
Yasaman Bahri, Jonathan Kadmon, Jeffrey Pennington, Sam S. Schoenholz, Jascha Sohl-Dickstein,
and Surya Ganguli. Statistical Mechanics of Deep Learning. Annual Review of Condensed Matter
Physics, 11:501-528, 2020.
J. Bailey. The tools of generative art, from flash to neural networks. Art in America, 2020.
Yoshua Bengio, Eric Laufer, Guillaume Alain, and Jason Yosinski. Deep Generative Stochastic Net-
works Trainable by Backprop. In Proceedings of the 31st International Conference on Machine
Learning, 2014.
Florian Bordes, Sina Honari, and Pascal Vincent. Learning to Generate Samples from Noise through
Infusion Training. In 5th International Conference on Learning Representations, ICLR, 2017.
Yuri Burda, Roger Grosse, and Ruslan Salakhutdinov. Importance Weighted Autoencoders.
arXiv:1509.00519, 2015.
Giovanni Bussi and Michele Parrinello. Accurate sampling using Langevin dynamics. Phys. Rev. E,
75:056707, 2007.
Giovanni Bussi, Davide Donadio, and Michele Parrinello. Canonical sampling through velocity
rescaling. The Journal of Chemical Physics, 126(1):014101, 2007.
10
Published as a conference paper at ICLR 2022
Michele Ceriotti, Giovanni Bussi, and Michele Parrinello. Langevin Equation with Colored Noise
for Constant-Temperature Molecular Dynamics Simulations. Physical Review Letters, 102:
020601, 2009.
Michele Ceriotti, Michele Parrinello, Thomas E. Markland, and David E. Manolopoulos. Efficient
stochastic thermostatting of path integral molecular dynamics. The Journal of Chemical Physics,
133(12):124104, 2010.
Jianfei Chen, Cheng Lu, Biqi Chenli, Jun Zhu, and Tian Tian. VFlow: More Expressive Generative
Flows with Variational Data Augmentation. In International Conference on Machine Learning,
pp.1660-1669. PMLR, 2020.
Nanxin Chen, Yu Zhang, Heiga Zen, Ron J Weiss, Mohammad Norouzi, and William Chan. Wave-
Grad: Estimating Gradients for Waveform Generation. In International Conference on Learning
Representations, 2021.
Ricky T. Q. Chen, Yulia Rubanova, Jesse Bettencourt, and David Duvenaud. Neural Ordinary Dif-
ferential Equations. Advances in Neural Information Processing Systems, 2018.
Ricky T. Q. Chen, Jens Behrmann, David Duvenaud, and Jorn-Henrik Jacobsen. Residual Flows for
Invertible Generative Modeling. In Advances in Neural Information Processing Systems, 2019.
Tianqi Chen, Emily Fox, and Carlos Guestrin. Stochastic Gradient Hamiltonian Monte Carlo. In
Proceedings of the 31st International Conference on Machine Learning, 2014.
Prafulla Dhariwal and Alex Nichol. Diffusion Models Beat GANs on Image Synthesis. In Neural
Information Processing Systems (NeurIPS), 2021.
Nan Ding, Youhan Fang, Ryan Babbush, Changyou Chen, Robert D Skeel, and Hartmut Neven.
Bayesian Sampling Using Stochastic Gradient Thermostats. In Advances in Neural Information
Processing Systems, 2014.
J. R. Dormand and P. J. Prince. A family of embedded Runge-Kutta formulae. Journal of Compu-
tational and Applied Mathematics, 6(1):19-26, 1980.
Yilun Du and Igor Mordatch. Implicit Generation and Modeling with Energy Based Models. In
Advances in Neural Information Processing Systems, pp. 3608-3618, 2019.
Simon Duane, A.D. Kennedy, Brian J. Pendleton, and Duncan Roweth. Hybrid Monte Carlo. Physics
Letters B, 195(2):216-222, 1987.
Chie Furusawa, Shinya Kitaoka, Michael Li, and Yuri Odagiri. Generative Probabilistic Image
Colorization. arXiv:2109.14518, 2021.
Ruiqi Gao, Yang Song, Ben Poole, Ying Nian Wu, and Diederik P Kingma. Learning Energy-Based
Models by Diffusion Recovery Likelihood. In International Conference on Learning Represen-
tations, 2021.
Xinyu Gong, Shiyu Chang, Yifan Jiang, and Zhangyang Wang. AutoGAN: Neural Architecture
Search for Generative Adversarial Networks. In Proceedings of the IEEE/CVF International
Conference on Computer Vision, pp. 3224-3234, 2019.
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair,
Aaron Courville, and Yoshua Bengio. Generative Adversarial Nets. Advances in neural informa-
tion processing systems, 27, 2014.
Anirudh Goyal, Nan Rosemary Ke, Surya Ganguli, and Yoshua Bengio. Variational Walkback:
Learning a Transition Operator as a Stochastic Recurrent Net. In Proceedings of the 31st Inter-
national Conference on Neural Information Processing Systems, 2017.
Will Grathwohl, Ricky T. Q. Chen, Jesse Bettencourt, Ilya Sutskever, and David Duvenaud.
FFJORD: Free-form Continuous Dynamics for Scalable Reversible Generative Models. Inter-
national Conference on Learning Representations, 2019.
11
Published as a conference paper at ICLR 2022
Ulrich G Haussmann and Etienne Pardoux. Time Reversal of Diffusions. The Annals of Probability,
pp.1188-1205,1986.
Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter.
GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium. In
I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett
(eds.), Advances in Neural Information Processing Systems, volume 30. Curran Associates, Inc.,
2017.
Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising Diffusion Probabilistic Models. In Advances
in Neural Information Processing Systems, 2020.
Jonathan Ho, Chitwan Saharia, William Chan, David J Fleet, Mohammad Norouzi, and Tim Sali-
mans. Cascaded Diffusion Models for High Fidelity Image Generation. arXiv:2106.15282, 2021.
William G. Hoover. Canonical dynamics: Equilibrium phase-space distributions. Physical Review
A, 31:1695-1697, 1985.
Chin-Wei Huang, Laurent Dinh, and Aaron Courville. Augmented Normalizing Flows: Bridging
the Gap Between Generative Flows and Latent Variable Models. arXiv:2002.07101, 2020.
Chin-Wei Huang, Jae Hyun Lim, and Aaron Courville. A Variational Perspective on Diffusion-
Based Generative Models and Score Matching. In Neural Information Processing Systems
(NeurIPS), 2021.
PhilippeH. HUnenberger. ThermostatAlgorithmsforMolecular Dynamics Simulations, volume 173
of Advanced Computer Simulation. Advances in Polymer Science. Springer, Berlin, Heidelberg,
2005.
Aapo Hyvarinen. Estimation of Non-Normalized Statistical Models by Score Matching. Journal of
Machine Learning Research, 6:695-709, 2005. ISSN 1532-4435.
Christopher Jarzynski. Equilibrium free-energy differences from nonequilibrium measurements: A
master-equation approach. Physical Review E, 56:5018-5035, 1997a.
Christopher Jarzynski. Nonequilibrium Equality for Free Energy Differences. Physical Review
Letters, 78:2690-2693, 1997b.
Christopher Jarzynski. Equalities and Inequalities: Irreversibility and the Second Law of Thermo-
dynamics at the Nanoscale. Annual Review of Condensed Matter Physics, 2(1):329-351, 2011.
Myeonghun Jeong, Hyeongju Kim, Sung Jun Cheon, Byoung Jin Choi, and Nam Soo Kim. Diff-
TTS: A Denoising Diffusion Model for Text-to-Speech. arXiv preprint arXiv:2104.01409, 2021.
Yifan Jiang, Shiyu Chang, and Zhangyang Wang. TransGAN: Two Pure Transformers Can Make
One Strong GAN, and That Can Scale Up. arXiv:2102.07074, 2021.
Alexia Jolicoeur-Martineau, Ke Li, Remi Piche-Taillefer, Tal Kachman, and Ioannis Mitliagkas.
Gotta Go Fast When Generating Data with Score-Based Models. arXiv:2105.14080, 2021a.
Alexia Jolicoeur-Martineau, Remi Piche-Taillefer, Ioannis Mitliagkas, and Remi Tachet des
Combes. Adversarial score matching and improved sampling for image generation. In Inter-
national Conference on Learning Representations, 2021b.
Heewoo Jun, Rewon Child, Mark Chen, John Schulman, Aditya Ramesh, Alec Radford, and Ilya
Sutskever. Distribution Augmentation for Generative Modeling. In International Conference on
Machine Learning, pp. 5006-5019. PMLR, 2020.
Tero Karras, Miika Aittala, Janne Hellsten, Samuli Laine, Jaakko Lehtinen, and Timo Aila. Training
Generative Adversarial Networks with Limited Data. In Neural Information Processing Systems
(NeurIPS), 2020.
Dongjun Kim, Seungjae Shin, Kyungwoo Song, Wanmo Kang, and Il-Chul Moon. Score Matching
Model for Unbounded Data Score. arXiv:2106.05527, 2021.
12
Published as a conference paper at ICLR 2022
Diederik P Kingma and Jimmy Ba. Adam: A Method for Stochastic Optimization. In International
Conference on Learning Representations, 2015.
Diederik P Kingma, Tim Salimans, Ben Poole, and Jonathan Ho. Variational Diffusion Models.
arXiv:2107.00630, 2021.
Durk P Kingma and Prafulla Dhariwal. Glow: Generative Flow with Invertible 1x1 Convolutions.
In Advances in neural information processing systems, pp. 10215-10224, 2018.
Peter E. Kloeden and Eckhard Platen. Numerical Solution of Stochastic Differential Equations.
Springer, Berlin, 1992.
Zhifeng Kong and Wei Ping. On Fast Sampling of Diffusion Probabilistic Models.
arXiv:2106.00132, 2021.
Zhifeng Kong, Wei Ping, Jiaji Huang, Kexin Zhao, and Bryan Catanzaro. DiffWave: A Versatile
Diffusion Model for Audio Synthesis. In International Conference on Learning Representations,
2021.
Karsten Kreis, Kurt Kremer, Raffaello Potestio, and Mark E. Tuckerman. From classical to quantum
and back: Hamiltonian adaptive resolution path integral, ring polymer, and centroid molecular
dynamics. The Journal of Chemical Physics, 147(24):244104, 2017.
Benedict Leimkuhler and Charles Matthews. Rational Construction of Stochastic Numerical Meth-
ods for Molecular Sampling. Applied Mathematics Research eXpress, 2013(1):34-56, 2013.
Benedict Leimkuhler and Charles Matthews. Molecular Dynamics: With Deterministic and Stochas-
tic Numerical Methods. Interdisciplinary Applied Mathematics. Springer, 2015.
Benedict Leimkuhler and Sebastian Reich. Simulating Hamiltonian Dynamics. Cambridge Mono-
graphs on Applied and Computational Mathematics. Cambridge University Press, 2005.
Haoying Li, Yifan Yang, Meng Chang, Huajun Feng, Zhihai Xu, Qi Li, and Yueting Chen. SRDiff:
Single Image Super-Resolution with Diffusion Probabilistic Models. arXiv:2104.14951, 2021.
Eric Luhman and Troy Luhman. Knowledge Distillation in Iterative Generative Models for Im-
proved Sampling Speed. arXiv:2101.02388, 2021.
Shitong Luo and Wei Hu. Diffusion Probabilistic Models for 3D Point Cloud Generation. In Pro-
ceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),
2021.
Siwei Lyu. Interpretation and Generalization of Score Matching. In Proceedings of the Twenty-Fifth
Conference on Uncertainty in Artificial Intelligence, UAI ’09, pp. 359-366, Arlington, Virginia,
USA, 2009. AUAI Press.
Yi-An Ma, Niladri Chatterji, Xiang Cheng, Nicolas Flammarion, Peter Bartlett, and Michael I Jor-
dan. Is There an Analog of Nesterov Acceleration for MCMC? arXiv:1902.00996, 2019.
Glenn J. Martyna, Michael L. Klein, and Mark Tuckerman. Nose-Hoover chains: The canonical
ensemble via continuous dynamics. The Journal of Chemical Physics, 97(4):2635-2643, 1992.
Martin W McCall. Classical Mechanics: From Newton to Einstein: A Modern Introduction, 2nd
Edition. Wiley, Hoboken, N.J., 2010.
Chenlin Meng, Yang Song, Jiaming Song, Jiajun Wu, Jun-Yan Zhu, and Stefano Ermon. SDEdit:
Image Synthesis and Editing with Stochastic Differential Equations. arXiv:2108.01073, 2021.
Yisroel Mirsky and Wenke Lee. The Creation and Detection of Deepfakes: A Survey. ACM Comput.
Surv., 54(1), 2021.
Gautam Mittal, Jesse Engel, Curtis Hawthorne, and Ian Simon. Symbolic music generation with
diffusion models. In Proceedings of the 22nd International Society for Music Information Re-
trieval Conference, 2021. URL https://archives.ismir.net/ismir2021/paper/
000058.pdf.
13
Published as a conference paper at ICLR 2022
Takeru Miyato, Toshiki Kataoka, Masanori Koyama, and Yuichi Yoshida. Spectral Normalization
for Generative Adversarial Networks. In International Conference on Learning Representations
(ICLR), 2018.
Wenlong Mou, Yi-An Ma, Martin J. Wainwright, Peter L. Bartlett, and Michael I. Jordan. High-
Order Langevin Diffusion Yields an Accelerated MCMC Algorithm. Journal of Machine Learn-
ingResearch, 22(42):1-41, 2021.
Javier R. Movellan. Contrastive Divergence in Gaussian Diffusions. Neural Computation, 20(9):
2238-2252, 2008.
Eliya Nachmani, Robin San Roman, and Lior Wolf. Non Gaussian Denoising Diffusion Models.
arXiv:2106.07582, 2021.
Radford M. Neal. Annealed importance sampling. Statistics and Computing, 2001.
Radford M. Neal. MCMC Using Hamiltonian Dynamics. Handbook of Markov Chain Monte Carlo,
54:113-162, 2011.
Thanh Thi Nguyen, Quoc Viet Hung Nguyen, Cuong M. Nguyen, Dung Nguyen, Duc Thanh
Nguyen, and Saeid Nahavandi. Deep Learning for Deepfakes Creation and Detection: A Sur-
vey. arXiv:1909.11573, 2021.
Alexander Quinn Nichol and Prafulla Dhariwal. Improved Denoising Diffusion Probabilistic Mod-
els. In International Conference on Machine Learning, 2021.
ShUichi Nose. A unified formulation of the constant temperature molecular dynamics methods. The
Journal of Chemical Physics, 81(1):511-519, 1984.
Aaron van den Oord, Nal Kalchbrenner, and Koray Kavukcuoglu. Pixel Recurrent Neural Networks.
International Conference on Machine Learning, 2016.
Gaurav Parmar, Dacheng Li, Kwonjoon Lee, and Zhuowen Tu. Dual Contradistinctive Generative
Autoencoder. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
Recognition, pp. 823-832, 2021.
B. T. Polyak. Some methods of speeding up the convergence of iteration methods. USSR Computa-
tional Mathematics and Mathematical Physics, 4(5):1-17, 1964. ISSN 0041-5553.
A. J. Roberts. Modify the Improved Euler scheme to integrate stochastic differential equations.
arXiv:1210.0933, 2012.
Chitwan Saharia, Jonathan Ho, William Chan, Tim Salimans, David J Fleet, and Mohammad
Norouzi. Image Super-Resolution via Iterative Refinement. arXiv:2104.07636, 2021.
Robin San-Roman, Eliya Nachmani, and Lior Wolf. Noise Estimation for Generative Diffusion
Models. arXiv:2104.02600, 2021.
Simo Sarkka and Arno Solin. Applied Stochastic Differential Equations, volume 10. Cambridge
University Press, 2019.
Hiroshi Sasaki, Chris G. Willcocks, and Toby P. Breckon. UNIT-DDPM: UNpaired Image Transla-
tion with Denoising Diffusion Probabilistic Models. arXiv:2104.05358, 2021.
Xiaocheng Shang, Zhanxing Zhu, Benedict Leimkuhler, and Amos J Storkey. Covariance-
Controlled Adaptive Langevin Thermostat for Large-Scale Bayesian Sampling. In Advances in
Neural Information Processing Systems, 2015.
Abhishek Sinha, Jiaming Song, Chenlin Meng, and Stefano Ermon. D2C: Diffusion-Denoising
Models for Few-shot Conditional Generation. arXiv:2106.06819, 2021.
Jascha Sohl-Dickstein, Peter Battaglino, and Michael R. DeWeese. Minimum Probability Flow
Learning. In Proceedings of the 28th International Conference on International Conference on
Machine Learning, 2011.
14
Published as a conference paper at ICLR 2022
Jascha Sohl-Dickstein, Eric Weiss, Niru Maheswaranathan, and Surya Ganguli. Deep Unsuper-
vised Learning using Nonequilibrium Thermodynamics. In International Conference on Machine
Learning, 2015.
Jiaming Song, Chenlin Meng, and Stefano Ermon. Denoising Diffusion Implicit Models. In Inter-
national Conference on Learning Representations, 2021a.
Yang Song and Stefano Ermon. Generative Modeling by Estimating Gradients of the Data Distribu-
tion. In Proceedings of the 33rd Annual Conference on Neural Information Processing Systems,
2019.
Yang Song, Conor Durkan, Iain Murray, and Stefano Ermon. Maximum Likelihood Training of
Score-Based Diffusion Models. In Neural Information Processing Systems (NeurIPS), 2021b.
Yang Song, Jascha Sohl-Dickstein, Diederik P Kingma, Abhishek Kumar, Stefano Ermon, and Ben
Poole. Score-Based Generative Modeling through Stochastic Differential Equations. In Interna-
tional Conference on Learning Representations, 2021c.
Gilbert Strang. On the Construction and Comparison of Difference Schemes. SIAM Journal on
Numerical Analysis, 5(3):506-517,1968.
H. F. Trotter. On the Product of Semi-Groups of Operators. Proceedings of the American Mathe-
matical Society, 10:545-551, 1959.
M. Tuckerman, B. J. Berne, and G. J. Martyna. Reversible multiple time scale molecular dynamics.
The Journal of Chemical Physics, 97(3):1990-2001, 1992.
Mark E. Tuckerman. Statistical Mechanics: Theory and Molecular Simulation. Oxford University
Press, New York, 2010.
Cristian Vaccari and Andrew Chadwick. Deepfakes and Disinformation: Exploring the Impact of
Synthetic Political Video on Deception, Uncertainty, and Trust in News. Social Media + Society,
6(1):2056305120903408, 2020.
Arash Vahdat and Jan Kautz. NVAE: A Deep Hierarchical Variational Autoencoder. In Neural
Information Processing Systems (NeurIPS), 2020.
Arash Vahdat, Karsten Kreis, and Jan Kautz. Score-based Generative Modeling in Latent Space. In
Neural Information Processing Systems (NeurIPS), 2021.
Pascal Vincent. A Connection Between Score Matching and Denoising Autoencoders. Neural
Computation, 23(7):1661-1674, 2011.
Daniel Watson, Jonathan Ho, Mohammad Norouzi, and William Chan. Learning to Efficiently
Sample from Diffusion Probabilistic Models. arXiv:2106.03802, 2021.
Zhisheng Xiao, Karsten Kreis, Jan Kautz, and Arash Vahdat. VAEBM: A Symbiosis between Vari-
ational Autoencoders and Energy-based Models. In International Conference on Learning Rep-
resentations, 2021.
Richard Zhang. Making Convolutional Networks Shift-Invariant Again. In Kamalika Chaudhuri
and Ruslan Salakhutdinov (eds.), Proceedings of the 36th International Conference on Machine
Learning, volume 97 of Proceedings of Machine Learning Research, pp. 7324-7334. PMLR,
09-15 Jun 2019.
Shengyu Zhao, Zhijian Liu, Ji Lin, Jun-Yan Zhu, and Song Han. Differentiable Augmentation for
Data-Efficient GAN Training. Advances in Neural Information Processing Systems, 33, 2020.
Linqi Zhou, Yilun Du, and Jiajun Wu. 3D Shape Generation and Completion through Point-
Voxel Diffusion. In Proceedings of the IEEE/CVF International Conference on Computer Vision
(ICCV), 2021.
15
Published as a conference paper at ICLR 2022
Contents
1	Introduction	1
2	Background	2
3	Critically-Damped Langevin Diffusion	3
3.1	Score Matching Objective .................................................. 4
3.2	Scalable Training ......................................................... 4
3.3	Sampling from CLD-based SGMs .............................................. 5
4	Related Work	6
5	Experiments	7
5.1	Image Generation .......................................................... 7
5.2	Sampling Speed and Synthesis Quality Trade-Offs ........................... 8
5.3	Ablation Studies .......................................................... 9
6	Conclusions	9
7	Ethics and Reproducibility	10
References	10
A	Langevin Dynamics	18
A.1 Different Damping Ratios .................................................. 18
A.2 Very High Friction Limit and Connections to previous SDEs in SGMs ......... 18
B	Critically-Damped Langevin Diffusion	20
B.1	Perturbation Kernel ...................................................... 20
B.2	Convergence and Equilibrium ............................................. 21
B.3	CLD Objective ........................................................... 22
B.4	CLD-specific Implementation Details ..................................... 24
B.5	Lower Bounds and Probability Flow ODE ................................... 24
B.6	On Introducing a Hamiltonian Component into the Diffusion ............... 26
C	HSM: Hybrid Score Matching	26
C.1 Gradient Variance Reduction via HSM ....................................... 28
D	Symmetric Splitting CLD Sampler (SSCS)	29
D.1 Background ................................................................ 29
D.2 Derivation and Analysis ................................................... 29
E	Implementation and Experiment Details	34
16
Published as a conference paper at ICLR 2022
E.1 Score and Jacobian Experiments ............................................ 34
E.2 Image Modeling Experiments ................................................ 35
E.2.1	Training Details and Model Architectures ........................... 36
E.2.2	CIFAR-10 Results for VESDE and VPSDE ............................... 36
E.2.3	Quadratic Striding ................................................. 37
E.2.4	Denoising .......................................................... 37
E.2.5	Solver Error Tolerances for RUnge-KUtta 4(5)........................ 38
E.2.6	Ablation Experiments ............................................... 38
E.2.7	LSGM-100M Model .................................................... 38
F	Additional Experiments	39
F.1	Toy Experiments ........................................................... 39
F.1.1 Analytical Sampling ................................................ 39
F.1.2 MaximUm Likelihood Training ........................................ 39
F.2	CIFAR-10 — Extended ResUlts ............................................... 42
F.3	CelebA-HQ-256 — Extended ResUlts .......................................... 45
G	Proofs of Perturbation Kernels	50
G.1 Forward DiffUsion ......................................................... 50
G.1.1	Proof of Correctness	of the Mean .................................. 50
G.1.2	Proof of Correctness	of the Covariance ............................ 51
G.2	Analytical Splitting Term of SSCS ........................................ 52
G.2.1	Proof of Correctness	of the Mean .................................. 53
G.2.2	Proof of Correctness	of the Covariance ............................ 53
17
Published as a conference paper at ICLR 2022
A Langevin Dynamics
Here, we discuss different aspects of Langevin dynamics. Recall the Langevin dynamics, Eq. (5),
from the main paper:
Hamiltonian component=:H
+ (-rMdτJ βdt + (√20rβ) dwt.
S---------------{z---------------}
Ornstein-Uhlenbeck process=:O
(11)
A. 1 Different Damping Ratios
As discussed in Sec. 3, Langevin dynamics can be run with different ratios between mass M and
squared friction Γ2. To recap from the main paper:
(i)	For Γ2 < 4M (underdamped Langevin dynamics), the Hamiltonian component dominates, which
implies oscillatory dynamics of xt and vt that slow down convergence to equilibrium.
(ii)	For Γ2 > 4M (overdamped Langevin dynamics), the O-term dominates which also slows down
convergence, since the accelerating effect by the Hamiltonian component is suppressed due to the
strong noise injection.
(iii)	For Γ2 = 4M (critical-damping), an ideal balance is achieved and convergence to pEQ (u)occurs
quickly in a smooth manner without oscillations.
In Fig. 5, we visualize diffusion trajectories according to Langevin dynamics run in the different
damping regimes. We observe that underdamped Langevin dynamics show undesired oscillatory
behavior, while overdamped Langevin dynamics perform very inefficiently, too. Critical-damping
achieves a good balance between the two and mixes and converges quickly. In fact, it can be shown
to be optimal in terms of convergence; see, for example, McCall (2010).
Consequently, we propose to set Γ2 = Γc2ritical := 4M in CLD.
A.2 Very High Friction Limit and Connections to previous SDEs in SGMs
Let us re-write the above Langevin dynamics and consider the more general case with time-
dependent β(t):
dxt = M -1 vt β (t)dt,	(12)
dvt = — Xtβ(t)dt	— ΓM-1vtβ(t)dt + p2Γβ(t)dwt.	(13)
、---{----}	、------{--------} 、-------{-----}
(ii): potential term	(iii): friction term	(iv): noise term
To solve this SDE, let us assume a simple Euler-based integration scheme, with the update equation
for a single step at time t (this integration scheme would not be optimal, as discussed in Sec. 3.3.,
however, it would be accurate for sufficiently small time steps and we just need this to make the
connection to previous works like the VPSDE):
Xn+1 = Xn + β(t)M-1vn+1δt,	(14)
Vn+1 =	Vn	— β(t)Xnδt	— β(t)ΓM-1Vnδt + p2β(t)Γ N (0d,δtId),	(15)
s{z}	'—{—}	'-{-} '-{-----}
(i): current step velocity	(ii): potential term	(iii): friction term	(iv): noise term
Now, let Us assume a friction coefficient Γ = Γmaχ := /t%?∙ Since the time SteP δt is usually very
small, this correspond to a very high friction. In fact, it can be considered the maximum friction
limit, at which the friction is so large that the current steP velocity (i) is comPletely cancelled out by
the friction term (iii). We obtain:
Xn+1 = Xn + β(t)M-1Vn+1δt
M
vn+1 = -β(t)xtδt + 2~N N (Od,δtId).
δt
(16)
(17)
18
Published as a conference paper at ICLR 2022
Figure 5: Langevin dynamics in different damping regimes. Each pair of visualizations corresponds to the
(coupled) evolution of data xt and velocities vt . We show the marginal (red) probabilities and the projections
of the (green) trajectories. The probabilities always correspond to the same optimal setting Γ = Γcritical (recall
that Γcritical = 2λ∕M and Γmax = M/(β(t)δt); see Sec. A.2). The trajectories correspond to different Langevin
trajectories run in the different regimes with indicated friction coefficients Γ. We see in (b), that for critical
damping the xt trajectories quickly explore the space and converge according to the distribution indicated
by the underlying probability. In the under-damped regime (a), even though the trajectories mix quickly we
observe undesired oscillatory behavior. For over-damped Langevin dynamics, (c) and (d), the xt trajectories
mix and converge only very slowly. Note that the visualized diffusion uses different hyperparameters compared
to the diffusion shown in Fig. 1 in the main text: Here, we have chosen a much larger β, such that also the slow
overdamped Langevin dynamics trajectories shown here mix a little bit over the visualized diffusion time (while
the probability distribution and the trajectories for critical damping converge almost instantly).
Now the velocity update, Eq. (17), does not depend on the current step velocity on the right-hand-
side anymore. Hence, we can insert Eq. (17) directly into Eq. (16) and obtain:
Xn+1 = Xn - β(t)2MTXnδt2 + √2β(t)2δtMTN(0d, δtId)
=Xn - β(t)2MTXnδt2 + p2β(t)2δt2MTN(0d, Id).
(18)
Re-defining δt0 := δt2 and β0(t) := β(t)2, we obtain
Xn+1 = Xn — β0(t)MTXnδt0 + P^0(t)δt0M-1,N(0d, Id),	(19)
which corresponds to the high-friction overdamped Langevin dynamics that are frequently run,
for example, to train energy-based generative models (Du & Mordatch, 2019; Xiao et al., 2021).
Let’s further absorb the mass M-1 and the time step δt0 into the time rescaling, defining β(t) :=
19
Published as a conference paper at ICLR 2022
2β0(t)M-1δt0. We obtain:
Xn+1 = Xn - 1 β(t)Xn + Jβ(t)N(0d, Id)
=(1 - 2β(t))xn + √βi)N(0d, Id)
≈ J1- β(t)Xn + ββN/0(0d, Id),
(20)
ʌ
where the last approximation is true for sufficiently small β (t). However, this expression corre-
sponds to
q
1 - β(t)Xn,β(t)Id)	(21)
which is exactly the transition kernel of the VPSDE’s Markov chain (Ho et al., 2020; Song et al.,
2021c). We see that the VPSDE corresponds to the high-friction limit of a more general Langevin
dynamics-based diffusion process of the form of Eq. (11).
If we assume a diffusion as above but with the potential term (ii) set to 0, we can similarly derive
the VESDE Song et al. (2021c) as a high-friction limit of the corresponding diffusion. Generally,
all previously used diffusions that inject noise directly into the data variables correspond to such
high-friction diffusions.
In conclusion, we see that previous high-friction diffusions require an excessive amount of noise
to be injected to bring the dynamics to the prior, which intuitively makes denoising harder. For our
CLD in the critical damping regime we can run the diffusion for a much shorter time or, equivalently,
can inject less noise to converge to the equilibrium, i.e., the prior.
B Critically-Damped Langevin Diffusion
Here, we present further details about our proposed critically-damped Langevin diffusion (CLD).
We provide the derivations and formulas that were not presented in the main paper in the interest of
brevity.
B.1	Perturbation Kernel
To recap from the main text, in this work we propose to augment the data Xt ∈ Rd with auxiliary ve-
locity variables vt ∈ Rd . We then run the following diffusion process in the joint Xt-vt -space
dut := dXvtt = f(ut,t)dt + G(ut, t)dwt	(22)
f (ut,t) = (f(t)③ Id)Ut, f (t) := (-β0(t) -β(t)MMMT) ,	(23)
G(ut,t) = G(t)乳 Id, G(t) := ɑ PTeW)，	(24)
where wt is a standard Wiener process in R2d andβ : [0, T] → R0+ is a time rescaling.3 In particular,
We consider the critically-damped Langevin diffusion which can be obtained by setting M = Γ2∕4,
resulting in the following drift kernel
fcLD(Ut,t) = (fcLD(t) 了 Id)Ut,
fCLD (t) :
0
-β(t)
4β(t)Γ-2
-4β (t)Γ-1 .
(25)
Since we only consider the critically-damped case in this work, we redefine f := fCLD and
f := fCLD for simplicity. Since our drift f and diffusion G coefficients are affine, Ut is Nor-
mally distributed for all t ∈ [0,T] if uo is Normally distributed at t = 0 (Sarkka & Solin, 2019). In
particular, given that uo 〜N(uo; μo, ∑o = ∑o 0 Id), where ∑o = diag(∑χx, Σ0v) is a positive
3For our experiments, we only used constant β ; however, for generality, we present all derivations for
time-dependent β(t).
20
Published as a conference paper at ICLR 2022
semi-definite diagonal 2-by-2 matrix (we restrict our derivation to diagonal covariance matrices at
t = 0 for simplicity, since in our situation velocity and data are generally independent at t = 0), we
derive expressions for μt and ∑t, the mean and the covariance matrix of ut, respectively.
Following Sarkka & Solin (2019) (Section 6.1), the mean and covariance matrix of Ut obey the
following respective ordinary differential equations (ODEs)
专=(f (t)乳 Id)μt,
dt
^^dft = (f (t) 乳 Id)Q + [(f (t) 乳 Id)%]> + (G⑴G⑴>)乳 Id.
Notating μ0 = (x0, v0)›, the solutions to the above ODES are
2B(t)Γ-1x0 + 4B(t)Γ-2v0 +x0	-2B(t)Γ-1
μt=	-B(t)xo- 2B(t)Γ-1vo + vo	e ,
and
(26)
(27)
(28)
Q =巳乳 Id,	(29)
Σt= ΣΣtxtxxv ΣΣttvxvve-4B(t)Γ-1,	(30)
Σtxx = Σ0xx + e4B(t)Γ-1 - 1 + 4B(t)Γ-1 (Σ0xx - 1) + 4B2(t)Γ-2 (Σ0xx -2) + 16B(t)2Γ-4Σ0vv,
(31)
Σtxv = -B(t)Σ0xx + 4B(t)Γ-2Σv0v - 2B2(t)Γ-1 (Σ0xx - 2) - 8B2(t)Γ-3Σ0vv,	(32)
Σvv = γ2 94B㈤γ-1 - 1)+ B(t)Γ + Σvv (1 + 4B(t)2Γ-2 - 4B(t)Γ-1) + B(t)2 (Σxx - 2),
(33)
where B(t) = Rt β(t) d£. For constant β(t) = β (as is used in all our experiments), We simply have
B(t) = tβ. The correctness of the proposed mean and covariance matrix can be verified by simply
plugging them back into their respective ODEs; see App. G.1.
With the above derivations, we can find analytical expressions for the perturbation kernel p(ut∣∙).
For example, when conditioning on initial data and velocity samples x0 and v0 (as in denoising
score matching (DSM)), the mean and covariance matrix of the perturbation kernelp(ut|u0) can be
obtained by setting μo = (x0, v0)>, ∑χx = 0, and Σ0v = 0.
In our experiments, the initial velocity distribution is set to N (0d, γMId). Conditioning only on
initial data samples x0 and marginalizing over the full initial velocity distribution (as in our hybrid
score matching (HSM), see Sec. C), the mean and covariance matrix of the perturbation kernel
p(ut∣xo) can be obtained by setting μ0 = (x0, 0d)>, ∑χx = 0, and ∑Vv = YM.
B.2	Convergence and Equilibrium
Our CLD-based training of SGMs—as well as denoising diffusion models more generally—relies
on the fact that the diffusion converges towards an analytically tractable equilibrium distribution for
sufficiently large t. In fact, from the above equations we can easily see that,
lim Σtxx t→∞	1,	(34)
lim Σtxv t→∞	0,	(35)
lim Σtvv t→∞	Γ2 T M	(36)
lim μt 二 t→∞	02d,	(37)
which establishes pEQ(u) = N(x; 0d, Id) N(v; 0d, MId).
Notice that our CLD is an instantiation of the more general Langevin dynamics defined by
(dvt) = (vxt Mg pvott(xt)) βdt + (-rMd-1vt) Bdd + (√2rβ) dwt.	(38)
21
Published as a conference paper at ICLR 2022
which has the equilibrium distribution PEQ(U) = Ppot(x) N(v; 0d, MId) (LeimkUhler & Matthews,
2015; Tuckerman, 2010). However, the perturbation kernel of this Langevin dynamics is not avail-
able analytically anymore for arbitrary Ppot(x). In our case, however, we have the analytically
tractable Ppot(x) = N(x; 0d, Id). Note that this corresponds to the classical “harmonic oscillator”
problem from physics.
B.3	CLD Objective
To derive the objective for training CLD-based SGMs, we start with a derivation that targets maxi-
mum likelihood training in a similar fashion to Song et al. (2021b). Let P0 and q0 be two densities,
then
DKL(P0 k q0) = DKL(P0 k q0) - DKL(PT k qT ) + DKL(PT k qT )
-0T dDKLdttk qt) dt + DKL(PT k qτ),
(39)
where Pt and qt are the marginal densities of P0 and q0 , respectively, diffused by our critically-
damped Langevin diffusion. As has been shown in Song et al. (2021b), Eq. (39) can be written as a
mixture (over t) of score matching losses. To this end, let Us consider the Fokker-Planck equation
associated with the critically-damped Langevin diffusion:
∂pt(ut)
∂t
Vut ∙ [ 1 (G(t)G(t)> N Id) VutPt(Ut)- Pt(Ut)(f(t) N Id)ut]
Vut ∙ [hp(ut,t)pt(ut)],	hp(ut,t) := 2 (G(t)G(t)> N Id) VutlOgPt(Ut) - (f(t) N Id)Ut.
(40)
Similarly, We have 驾Ut) = Vut ∙ [hq(Ut,t)qt(Ut)]. Assuming logPt(Ut) and logqt(Ut) are
smooth functions with at most polynomial growth at infinity, we have
lim hp(Ut, t)Pt(Ut) = lim hq(Ut, t)qt(Ut) = 0.	(41)
ut→∞	ut→∞
Using the above fact, we can compute the time-derivative of the Kullback-Leibler divergence be-
tween Pt and qt as
∂DKL (Pt k qt)
∂t
d ZPtMtIO 需 dUt
-	Pt(Ut) [hp(Ut, t) - hq(Ut, t)]> [Vut logPt(Ut) - Vut log qt(Ut)] dUt
—	2 /Pt(Ut) [Vut logPt(Ut)- Vut log qt(Ut)]> (G(t)G(t)> N Id) [Vut logPt(Ut)
-	Vut logqt(Ut)] dUt
-	β(t)Γ	Pt(Ut)kVvt logPt(Ut) - Vvt logqt(Ut)k22dUt.
(42)
Notice that due to the form of G(t), we now have only gradients with respect to the velocity com-
ponent vt . Combining the above with Eq. (39), we have
DKL (P0 k qo) = Et 〜U[0,T ],ut 〜pt(u) [rβ(t)kVvtlOg Pt(Ut) -VvtlOg qt (Ut)k2] + DKL(PT k qτ)
≈ Et~U[0,T],ut~pt(u) Γβ(t)kVvt logPt(Ut) - Vvt logqt(Ut)k22 ,
(43)
Note that the approximation holds if PT is sufficiently “close” to qT . We obtain a more general
objective function by replacing Γβ(t) with an arbitrary function λ(t), i.e.,
Et~U[0,T],ut~pt(u) λ(t)kVvt logPt(Ut) - Vvt logqt(Ut)k22	(44)
22
Published as a conference paper at ICLR 2022
As shown in App. C, the above can be rewritten, up to irrelevant constant terms, as either of the
following two objectives:
HSM(Nt))= Et~U[0,T ],x0~p0(x0),ut~pt(ut∣x0)卜⑴ kVvtlOg Pt (UtI XO)-Vvtlog qt(ut)k2],
(45)
DSM(Nt)) := Et~U[0,T],u0~p0(u0),ut~pt(ut∣u0) [λ⑴kvvtlogPt(UtI UO)-Vvtlog qt(Ut)k2].
(46)
For both HSM and DSM, we have shown in App. B.1 that the perturbation kernels Pt(Ut I XO) and
Pt(Ut I UO) are Normal distributions with the following structure of the covariance matrix:
∑t = ∑t ㊈ Id,	∑t
(47)
We can use this fact to compute the gradient Vut logPt(Ut I ∙)
Vut logPt(Ut I∙) = -Vut1 (Ut — μt)∑-1(Ut — μt)
=-ς-I(Ut - μt)
=-L->L-1(Ut - μt)
= -Lt-> 2d ,
(48)
where "& ~ N(0, I2&) and ∑t = LtL> is the Cholesky factorization of the covariance matrix ∑t.
Note that the structure of Σt implies that Lt = Lt 0 Id, where LtLt> is the Cholesky factorization
of Σt, i.e,
Lt
Ltxv
Ltvv
Σtxx
∑xv
∕∑xx
0
qΣxx Σvv -(Σxv )2
∑χx
(49)
Furthermore, we have
Lt-> = Lt-> 0Id
∑xx
xv
ς
∕∑F
-1
ΣxxΣvv-(Σxv)2
1
∑xx
0
∑xx
-∑xz
(50)
Ixx ∑zz - (∑xv ) 2
∑xx
0 Id .
∑xx∑vv - (∑xv )2
0


0 Id
Using the above, we can compute
VvtlogPt(UtI ∙) = [vut logPt(UtI -)]d：2d
= -Lt->2d d:2d
= -`t d:2d,
(51)
where
`t:=
Σtxx
Σtxx Σtvv
(52)
	
and €d：2d denotes those (latter) d components of w2& that actually affect VvtlogPt(Ut∣∙).
Note that `t depends on the conditioning in the perturbation kernel, and therefore `t is different for
DSM, which is based on P(Ut I UO), and HSM, which is based on P(Ut I XO). Therefore, we will
henceforth refer to 'HSM and 'dsm if distinction of the two cases is necessary (otherwise We will
simply refer to `t for both).
As discussed in Section 3.2, We model Vvtlog qt(Ut) as sθ(Ut, t) = -'tαθ(Ut,t). Plugging every-
thing back into our objective functions, Eq. (45) and Eq. (46), we obtain
HSM(λ(t)) = Et~u [o,t ],χo~P0 (xo ),ut~pt(ut |X0)
DSM(λ(t)) = Et~U [O,T],u0~p0(u0),ut~pt(ut∣u0)
hλ(t) ('HSM) k€d：2d - αθ(Ut,t)∣∣2],
hλ(t) ('dsm)2 k€d：2d - αθ(Ut,t)k2i ,
(53)
(54)
23
Published as a conference paper at ICLR 2022
140 1
120 -
100 -
80 -
40 -
20 -
0 -
7
60 -
10-1
100
10-3
10-4
10-5
10-2
t
Figure 6: Comparison of 'HSM (in green) and 'DSM (in orange) for our main hyperparameter setting
with M = 0.25 and Y = 0.04. In contrast to 'DSM, 'HSM is analytically bounded. Nevertheless,
numerical computation can be unstable (even when using double precision) in which case adding
a numerical stabilization of num = 10-9 to the covariance matrix before computing `t suffices to
make HSM work (see App. B.4).
where ut is sampled via reparameterization:
Ut = μt + Lte = μt + ( r xv t_i_ ；VvU	).
Lt 0:d + Lt d:2d
Note again that Lt is different for HSM and DSM.
(55)
Analogously to prior work (Ho et al., 2020; Vahdat et al., 2021; Song et al., 2021b) an objective
better suited for high quality image synthesis can be obtained by “dropping the variance prefactor”:
HSM (λ(t) = ('Hsm)-2)
=Et~U [O,T],X0~po(X0),ut~pt(ut|x0)
DSM (λ(t) = ('t	)	) = Et~U[O,T],u0~po(u0),ut~pt(ut|u0)
hked:2d - αθ(ut,t)k22 ,
hked:2d - αθ(ut,t)k22 .
(56)
(57)
B.4	CLD-specific Implementation Details
Analytically, 'HsM is bounded (in particular, 'HSM = 1∕√γM), whereas 'dsm is diverging for
t → 0. In practice, however, We found that computation of 'HSM can also be numerically unstable,
even when using double precision. As is common practice for computing Cholesky decompositions,
we add a numerical stabilization matrix numI2d to Σt before computing `t. In Fig. 6, we visualize
'Hsm and 'Dsm for different values of ∈num using our main experimental setup of M = 0.25 and
γ = 0.04 (also, recall that in practice we have T = 1). Note that a very small numerical stabilization
of num = 10-9 in combination with the use of double precision makes HSM work in practice.
B.5	Lower Bounds and Probability Flow ODE
Given the score model sθ (ut, t), we can synthesize novel samples via simulating the reverse-time
diffusion SDE, Eq. (2) in the main text. This can be achieved, for example, via our novel SSCS,
24
Published as a conference paper at ICLR 2022
Euler-Maruyama, or methods such as GGF (Jolicoeur-Martineau et al., 2021a). However, Song et al.
(2021b;c) have shown that a corresponding ordinary differential equation can be defined that gener-
ates samples from the same distribution, in case sθ (ut , t) models the ground truth scores perfectly.
This ODE is:
dut = -f (ut,T - t) + 2G(Ut, T - t)G(ut,T - t)> Vut logPT-t(Ut) dt (58)
This ODE is often referred to as the probability flow ODE. We can use it to generate novel data
by sampling the prior and solving this ODE, like previous works (Song et al., 2021c). Note that
in practice sθ(Ut, t) won’t be a perfect model, though, such that the generative models defined by
simulating the reverse-time SDE and the probability flow ODE are not exactly equivalent (Song
et al., 2021b). Nevertheless, they are very closely connected and it has been shown that their perfor-
mance is usually very similar or almost the same, when we have learnt a good sθ (Ut, t). In addition
to sampling the generative SDE in our paper, we also sample from our CLD-based SGMs via this
probability flow approach.
With the definition of our CLD, the ODE becomes:
(59)
Notice the interesting form of this probability flow ODE for CLD: It corresponds to Hamiltonian
dynamics (A0H) plus the score function term S0. Compared to the generative SDE (Sec. 3.3), the
Ornstein-Uhlenbeck term disappears. Generally, symplectic integrators are best suited for integrat-
ing Hamiltonian systems (Neal, 2011; Tuckerman, 2010; Leimkuhler & Reich, 2005). However,
our ODE is not perfectly Hamiltonian, due to the score term, and modern non-symplectic methods,
such as the higher-order adaptive-step size Runge-Kutta 4(5) ODE integrator (Dormand & Prince,
1980), which we use in practice to solve the probability flow ODE, can also accurately simulate
Hamiltonian systems over limited time horizons.
Importantly, the ODE formulation also allows us to estimate the log-likelihood of given test data,
as it essentially defines a continuous Normalizing flow (Chen et al., 2018; Grathwohl et al., 2019),
that we can easily run in either direction. However, in CLD the input into this ODE is not just the
data x0, but also the velocity variable v0 . In this case, we can still calculate a lower bound on the
log-likelihood:
logp(x0) = log	p(x0, v0)dv0
=log (ZP(vο)'(：0，：0)dv。)
p(v0)
≥ EV0~p(vο) [logp(x0, v0) - logp(v0)]
=Evο〜p(vο) [logp(xο, vο)] + H(p(vο))
(60)
where H(p(vο)) denotes the entropy of p(v。) (We have H(p(vo)) = 2 log (2∏eγM)). We can
obtain a stochastic, but unbiased estimate of logp(x0, v0) ≈ logpε(x0, v0) via solving the prob-
ability flow ODE with initial conditions (x0, v0) and calculating a stochastic estimate of the log-
determinant of the Jacobian via Hutchinson’s trace estimator (and also calculating the probability of
the output under the prior), as done in Normalizing flows (Chen et al., 2018; Grathwohl et al., 2019)
and previous works on SGMs (Song et al., 2021c;b). In the main paper, we report the negative of
Eq. (60) as our upper bound on the negative log-likelihood (NLL).
Note that this bound can be potentially quite loose. In principle, it would be desirable to per-
form an importance-weighted estimation of the log-likelihood, as in importance-weighted autoen-
coders (Burda et al., 2015), using multiple samples from the velocity distribution. However, this
isn’t possible, as we only have access to a stochastic estimate logpε(x0, v0). The problems arising
from this are discussed in detail in Appendix F of Vahdat et al. (2021). We could consider training
a velocity encoder network, somewhat similar to Chen et al. (2020), to improve our bound, but we
leave this for future research.
25
Published as a conference paper at ICLR 2022
B.6	On Introducing a Hamiltonian Component into the Diffusion
Here, we provide additional high-level intuitions and motivations about adding the Hamiltonian
component to the diffusion process, as is done in our CLD.
Let us recall how the data distribution evolves in the forward diffusion process of SGMs: The
role of the diffusion is to bring the initial non-equilibrium state quickly towards the equilibrium or
prior distribution. Suppose for a moment, we could do so with “pure” Hamiltonian dynamics (no
noise injection). In that case, we could generate data from the backward model without learning
a score or neural network at all, because Hamiltonian dynamics is analytically invertible (flipping
the sign of the velocity, we can just integrate backwards in reverse time direction). Now, this is not
possible in practice, since Hamiltonian dynamics alone usually cannot convert the non-equilibrium
distribution to the prior distribution. Nevertheless, Hamiltonian dynamics essentially achieves a
certain amount of mixing on its own; moreover, since it is deterministic and analytically invertible,
this mixing comes at no cost in the sense that we do not have to learn a complex score function to
invert the Hamiltonian dynamics. Our thought experiment shows that we should strive for a diffusion
process that behaves as deterministically (meaning that deterministic implies easily invertible) as
possible with as little noise injection as possible. And this is exactly what is achieved by adding
the Hamiltonian component in the overall diffusion process. In fact, recall that it is the diffusion
coefficient G of the forward SDE that ultimately scales the score function term of the backward
generative SDE (and it is the score function that is hard to approximate with complex neural nets).
Therefore, in other words, relying more on a deterministic Hamiltonian component for enhanced
mixing (mixing just like in MCMC in that it brings us quickly towards the target distribution, in
our case the prior) and less on pure noise injection will lead to a nicer generative SDE that relies
less on a score function that requires complex and approximate neural network-based modeling, but
more on a simple and analytical Hamiltonian component. Such an SDE could then be solved easier
with an appropriate integrator (like our SSCS). In the end, we believe that this is the reason why our
networks are “smoother” and why given the same network capacity and limited compute budgets
we essentially outperform all previous results in the literature (on CIFAR-10).
We would also like to offer a second perspective, inspired by the Markov chain Monte Carlo
(MCMC) literature. In MCMC, “mixing” helps to quickly traverse the high probability parts of
the target distribution and, if an MCMC chain is initialized far from the high probability manifold,
to quickly converge to this manifold. However, this is precisely the situation we are in with the
forward diffusion process of SGMs: The system is initialized in a far-from-equilibrium state (the
data distribution) and we need to traverse the space as efficiently as possible to converge to the
equilibrium distribution, this is, the prior. Without efficient mixing, it takes longer to converge to
the prior, which also implies a longer generation path in the reverse direction—which intuitively
corresponds to a harder problem. Therefore, we believe that ideas from the MCMC literature that
accelerate mixing and traversal of state space may be beneficial also for the diffusions in SGMs. In
fact, leveraging Hamiltonian dynamics to accelerate sampling is popular in the MCMC field (Neal,
2011). Note that this line of reasoning extends to thermostating techniques from statistical mechan-
ics and molecular dynamics, which essentially tackle similar problems like MCMC methods from
the statistics literature (see discussion in Sec. 4).
C HSM: Hybrid Score Matching
We begin by recalling our objective function from App. B.3 (Eq. (44)):
Et 〜U [0,T ] 卜(t)Eut〜Pt(U)[∣∣Vvt logPt(Ut) -Sθ(ut,t)k2]] ,	(61)
where sθ(U, t) is our score model. In the following, we dissect the “score matching” part of the
above objective:
LSM := Eut〜Pt(UtjkVvtlOgPt(Ut) - sθ(Ut,t)k2]	(62)
=Eut 〜pt(ut)ksθ (Ut,t)k2 — 2S(θ) + C2(t).
where C2(t) := Eut〜Pt(Ut)[∣∣Vvt logPt(Ut)∣∣2] and S(θ) is the cross term discussed below. Fol-
lowing Vincent (2011), we can rewrite LSM as an equivalent (up to addition of a time-dependent
26
Published as a conference paper at ICLR 2022
constant) denoising score matching objective LDSM :
LDSM := Eu0~p(uο),ut~pt(ut∣uο) k VvtlogPt(Ut | UO) ― sθ(Ut,t)∣2
= LSM + C3 (t) - C2 (t),
(63)
where C3(t) ：= Eu0〜p(u°),ut〜pt(ut∣u0) [∣∣Vvt logpt(ut | u0)k2]. Something that might not neces-
sarily be quite obvious is that there is no fundamental need to “denoise” with the distribution p(u0)
(this is, use samples from the joint x0-v0 distribution p(u0), perturb them, and learn the score for
denoising).
Instead, we can “denoise” only with the datadistributionp(x0) and marginalize over the entire initial
velocity distributionp(v0), which results in
LHSM := Exo~p(xo),ut~pt(ut∣xo) k VvtlogPt(Utl XO) ― sθ(UtIt) k2
=Eut~pt(ut) k sθ (Ut,t)∣2 ― 2Exo~p(xo ),ut~pt(ut∣xo) [hVvt log Pt(UtI XO), sθ (ut,t)i] + C4⑴,
(64)
where C4(t) ：= Eχ0 〜p(x0),ut 〜pt(ut∣x0) [kVvtlog Pt(ut | xo)k2] and h∙, .〉donates the inner product
(notation chosen to be consistent with Vincent (2011)). In our case, this makes sense since p(v0) is
Normal, and therefore (as shown in App B.1), the perturbation kernel pt(ut | x0) is still Normal.
In the following, for completeness, we redo the derivation of Vincent (2011) and show that LSM is
equivalent to LHSM (up to addition of a constant). Starting from S(θ), we have
S (θ) = Eut 〜Pt(Ut)(Vvt log Pt(Ut),Sθ (Ut,t)i
=	Pt(Ut) hVvt logPt(Ut), sθ(Ut,t)i dUt
ut
=	hVvtPt(Ut), sθ(Ut,t)i dUt
= Vvt	Pt (Ut l XO)PO (XO) dXO, sθ (Ut, t) dUt
=	Pt(Ut l XO)PO(XO)Vvt logPt(Ut l XO) dXO, sθ(Ut,t) dUt
ut	x0
ZuZxPt(Ut l XO)PO(XO) hVvt logPt(Ut l XO), sθ(Ut, t)i dXO dUt
0
=EX0~P0(xο),ut~p(ut∣X0) [hVvt logPt(Ut l XO), sθ(Ut, t)i] .
(65)
Hence, we have that
This further implies that
LHSM = LSM + C4 (t) - C2 (t).
LHSM = LDSM + C4(t) - C3 (t).
(66)
(67)
Using the analysis from APP B.1, We realize that C3 and C4 can be simplified to d ('dsm)2 and
d ('HSM) , respectively. Here, we used the fact that the expected squared norm of a multivariate
standard Normal random variable is equal to its dimension, i.e., Eε 〜N (0d,id)kεk2 = d. This analysis
then simplifies Eq. (67) to
LHSM = LDSM + d (('Dsm)2 - ('Hsm)2) .	(68)
Using this relation, we can also find a connection between our CLD objective functions from
App. B.3. In particular, we have
HSM(λ(t)) = Et〜U[0,T] [λ(t)LHSM]
=Et〜U[o,t] [λ(t)LDSM] + dEt〜U[o,t] hλ(t) (('dsm)2 - ('HSM)2)i ,	(69)
=DSM(λ(t)) + dEt〜U[o,t] [λ(t) (('DSM)2 - ('HSM)2)i .
27
Published as a conference paper at ICLR 2022
C.1 Gradient Variance Reduction via HSM
Above, we derived that LHSM = LDSM + const, so one might wonder why we advocate for HSM
over DSM. As discussed in Sec. 3.2, one advantage of HSM is that it avoids unbounded scores at
t → 0. However, there is a second advantage: In practice, we never solve expectations analytically
but rather approximate them using Monte Carlo estimates. In the remainder of this section, we will
show that in practice (Monte Carlo) gradients based on HSM have lower variance than those based
on DSM.
From Eq. (69), we have
VθHSM(λ(t)) = Et〜U[o,τ] [λ(t)VθLhsm]
Et〜U[0,t] [λ(t)VθLdsm],
VθDSM(λ(t)),
(70)
where θ are the learnable parameters of the neural network. Instead of comparing the above expec-
tations directly, we instead compare λ(t)VθLHsM with λ(t)VθLDsM for t ∈ [0, 1] (we use T = 1
in all experiments) at discretized time values (as is done in practice). Replacing LHsM and LDsM
with a single Monte Carlo estimate (as is used in practice), we have
λ(t)VθLHsM ≈ λ(t)Vθsθ(ut,t)Vsθ(ut,t)kVvt logpt(ut | x0) - sθ(ut,t)k22,	(71)
xo 〜p(xo), Ut 〜pt(ut | X0),
λ(t)VθLDsM ≈ λ(t)Vθsθ(ut,t)Vsθ(ut,t)kVvt logpt(ut | u0) - sθ(ut,t)k22,	(72)
Uo 〜p(uo), Ut 〜Pt(ut | uo),
where we applied the chain-rule. Note that in Eq. (71) and Eq. (72), ut is sampled from the same
distribution. Hence, λ(t)Vθsθ (Ut, t) acts as a common scaling factor, with the variance difference
between HSM and DSM originating from the squared norm term. Hence, we ignore λ(t)Vθsθ(Ut, t)
and only focus our analysis on the gradient of the norm terms, which we can further simplify:
12
2Vsθ(ut,t)IlVvt logpt(ut | X0)— Sθ(Ut,t)k2 = Sθ(ut,t) — Vvt logpt(ut | xo) =： Khsm, (73)
and
1
12
2Vsθ(ut,t)IlVvt logpt(ut | uo) — sθ(ut,t)∣∣2 = sθ(ut,t) — Vvt logpt(ut | uo) =： Kdsm. (74)
We explore this difference in a realistic setup; in particular, we evaluate KHsM and KDsM for all
data points in the CIFAR-10 training set. We choose sθ to be our trained ablation CLD model (with
the standard setup of M -1 = β = 4, see Sec. E.2.1 for model details). We then use these samples
to compute the empirical covariance matrices CovHsM and CovDsM of the random variables KHsM
and KDsM , respectively.
As is common practice in statistics, we consider only the trace of the estimated covariance matrices.4
The trace of the covariance matrix (of a random variable) is also commonly referred to as the total
variation (of a random variable).
We visualize our results in Fig. 7. For HSM, there is barely any visual difference in Tr(Cov) for
γ = 0.04 and γ = 1. For DSM, both γ = 0.04 and γ = 1 result in very large Tr(Cov) values for
small t. For large t, Tr(Cov) is considerably smaller for γ = 0.04 than for γ = 1. However, in
practice, we found that DSM is even unstable for small γ. Given this analysis, we believe this is due
to the large gradient variance for small t. In conclusion, these results demonstrate a clear variance
reduction by the HSM objective, in particular for large γ. Ultimately, this is expected: In HSM,
we are effectively integrating out the initial velocity distribution when estimating gradients, while in
DSM we use noisy samples for the initial velocity.
Note that re-introducing λ(t) weightings would allow us to scale the Tr(Cov) curves according to
the “reweighted” objective or the maximum likelihood objective. However, we believe it is most
instructive to directly analyze the gradient of the relevant norm term itself.
4Arguably, the most prominent algorithm that follows this practice is principal component analysis (PCA).
28
Published as a conference paper at ICLR 2022
(AOU)U
Figure 7: Traces of the estimated covariance matrices.
D Symmetric Splitting CLD Sampler (SSCS)
In this section, we present a more complete derivation and analysis of our novel Symmetric Splitting
CLD Sampler (SSCS).
D.1 Background
Our derivation is inspired by methods from the statistical mechanics and molecular dynamics liter-
ature. In particular, We are leveraging symmetric splitting techniques as Wen as (Fokker-PlanCk)
operator concepts. The high-level idea of symmetric splitting as well as the operator formalism are
Well-explained in Tuckerman (2010), in particular in their Section 3.10, Which includes simple ex-
amples. Symmetric splitting methods for stochastic dynamics in particular are discussed in detail
in Leimkuhler & MattheWs (2015). We also recommend Leimkuhler & MattheWs (2013), Which
discusses splitting methods for Langevin dynamics in a concise but insightful manner.
D.2 Derivation and Analysis
Generative SDE. From Sec. 3.3, recall that our generative SDE can be written as (with Ut = UT-t,
Xt = XT-t, Vt = VT-t):
dxt
dvt
Axtvt) βdt + (-ΓMd-1Vt) βdt +
∖_____ _____✓ ∖____________ __
Wt) + (2Γ [s(ut,T 0：) + MTvt]) βdt.
____✓ ∖________________ ________________✓
V
AH
V
AO
V
S
(75)
Fokker-Planck Equation and Fokker-Planck Operators. The evolution of the probability distri-
bution PT-t(Ut) is described by the general Fokker-Planck equation (Sarkka & Solin, 2019):
∂PT-t(u t)
-∂t-
2d	2d 2d	2
-X 万二 [μi(Ut, T - t)PT-t(Ut)] + XX Y 用—
一 ∂Ui	W ∂Ui∂Uj
i=1 i=1 j=1
[Dij (Ut,T -OpT-t(Ut)],
(76)
29
Published as a conference paper at ICLR 2022
with
μ(u t,T - t) = ( Mxtvt) β + (-rMd-1v) β + (2Γ [s(u t,T - dt) + M-1vt]) β, (77)
D(Ut,T -1)=(0 Γβ) X Id.	(78)
For our SDE, We can write the Fokker-Planck equation in short form as
dpτ -Tt) = (LA+LS )pt-t(u t),	(79)
with the Fokker-Planck operators (defined via their action on functions of the variables φ(Ut)):
LAφ(ut) := βMTvtVxtφ(Ut) - βxtVvtφ(Ut) + ΓβMTVvt [vtφ(ut)] + Γβ∆vtφ(Ut),
(80)
(81)
(82)
LSφ(Ut) ：= -2ΓβVvt [(s(Ut, T — t) + MTvt) φ(Ut)]
d ∂2	∂2
vt L	Zfl∂x2	+	∂ν2	J
i=1 i	i
We are providing these formulas for transparency and completeness. We do not directly leverage
them. However, working with these operators can be convenient. In particular, the operators de-
scribe the time evolution of states Ut under the stochastic dynamics defined by the SDE. Given an
initial state U0, we can construct a formal solution to the generative SDE via (Tuckerman, 2010;
Leimkuhler & Matthews, 2015):
U t = et(LA+LS )U 0,	(83)
where the operator et(LA+LS) is known as the classical propagator that propagates states U0 for
ʌ ʌ
time t according to the dynamics defined by the combined Fokker-Planck operators LA + LS (to
avoid confusion, note that in Eq. (83) the operator et(LA+LS) is applied on U0 in an element-wise
or “vectorized” fashion on all elements of U0 in parallel). The problem with that expression is that
we cannot analytically evaluate it. However, we can leverage it to design an integration method.
Symmetric Splitting Integration. Using the symmetric Trotter theorem or Strang splitting formula
as well as the Baker-Campbell-Hausdorff formula (Trotter, 1959; Strang, 1968; Tuckerman, 2010),
it can be shown that:
et(LA+LS) = Nim 卜萼LAeδtLSe萼LAi ≈ [e萼LAeδtLSe萼LAi + O(Nδt3),	(84)
for large N ∈ N+ and time step δt := t/N. The expression suggests that instead of directly
evaluating the intractable et(LA +LS), we can discretize the dynamics over t into N pieces of step size
δt, such that we only need to apply the individual e粤 LA and eδtLS many times one after another for
small time steps δt. A finer discretization implies a smaller error (since N=t∕δt the error effectively
scales as O(δt2) for fixed t). Hence, this implies an integration method. The general idea of such
splitting schemes is to split an initially intractable propagator into separate terms, each of which is
analytically tractable. In that case, the overall integration error for many steps is only due to the
splitting scheme error,5 but not due to the evaluation of the individual updates. Such techniques are,
for example, popular in molecular dynamics to develop symplectic integrators as well as accurate
samplers (Tuckerman et al., 1992; Tuckerman, 2010; Leimkuhler & Matthews, 2013; 2015; Bussi &
Parrinello, 2007).
Analyzing the Splitting Terms. Next, we need to analyze the two individual terms:
(i) Let us first analyze eδtLA Ut: This term describes the stochastic evolution of Ut under the dy-
namics of an SDE like Eq. (75), but with S set to zero. However, if S is set to zero, the remaining
5In principle, the error of the splitting scheme is defined more specifically by the commutator of the non-
commuting Fokker-Planck operators. See, for example Leimkuhler & Matthews (2013; 2015); Tuckerman
(2010).
30
Published as a conference paper at ICLR 2022
SDE has affine drift and diffusion coefficients. In that case, if the input is Normal (or a discrete
state corresponding to a Normal with 0 variance) then the distribution is Normal at all times and we
can calculate the evolution analytically. In particular, we can solve the differential equations for the
mean μ粤 and covariance Σ萼 of the Normal (See Sec. B.1), and obtain
μ δ2t (Ut)
(2βδtΓ-1Xt - 4βδtΓ-2Vt + Xt∖ e-2β萼Γ-1
V	βδ2tXt- 2βδtr-1vt+Vt j
as well as
Σ δt = Σ δt 0 Id,
2	2
Σχχ = e4βδr-1 - 1 - 4βδtΓ-1 - 8 (β∣t) 2 Γ-2,
∑X=-4 d )2 Γ-1,
ς 翠= γ42 卜4β 萼 L- 1)+ βδt γ - 2 (βf )2.
(85)
(86)
(87)
(88)
(89)
(90)
The correctness of the proposed mean and covariance matrix can be verified by simply plugging
them back in their respective ODEs; see App. G.2.
Now, we can write the action of the the propagator eδtLA on a state Ut as:
e δt LA U t 〜N (u t+ δt; μ δt (u t), Σ δt).	(91)
^+ ^*
(ii): Next, we need to analyze eδtLSUt. Unfortunately, we cannot calculate the action of the prop-
agator eδtLS on Ut analytically and we need to make an approximation. From Eq. (75), we can
^f
easily see that the propagator eδtLS describes the evolution of the velocity component Vt for time
step δt under the ODE (this can be easily seen by noticing that the S term in Eq. (75) only acts on
the velocity component of the joint state Ut):
dVt = 2βΓ [s(Ut, T — t) + M-1Vt] dt.	(92)
We propose to simply solve this ODE for the step δt via a simple step of Euler’s method, resulting
in:
eδtLSUt ≈ Ut + δt QβΓ [s(Ut,T -dt) + MTVt]) + O(δt2)
eδtLS EuIer u t + O(δt2),
with the informal definition
c. ^* Euler _	_	(	0d
e S Ut := Ut + δt QβΓ [s(Ut,T - t) + MT
(93)
(94)
Error Analysis. It is now instructive to study the overall error of our proposed integrator. With the
additional Euler integration in one of the splitting terms, we have
et(LA+LS) ≈ heδLA }δtLSEUler + O(δt2)) e萼LAiN + O(Nδt3)
=heδtLAdLSEUler) eδtLAiN + NO(δt2)	(95)
=heδtLA 卜δtLSEUl")e粤LAiN + O(δt),
where we used N =盍 and only kept the dominating error terms of lowest order in δt. We see that,
just like Euler,s method, also our SSCS is a first-order integrator with local error 〜δt2 and global
31
Published as a conference paper at ICLR 2022
(a) Euler-Maruyama
/=仁。+魂)/Uo
Euler-based
Approximation
Figure 8: Conceptual visualization of our new SSCS sampler and comparison to Euler-Maruyama
(for image synthesis): (a) In EM-based sampling, in each integration step the entire SDE is inte-
grated using an Euler-based approximation. This can be formally expressed as solving the full-step
{δt(L⅛ + C
ʌ
propagator exp
S) via Euler-based approximation for N small steps of size δt (See
red steps; for simplicity, this visualization assumes constant δt). (b): In contrast, in our SSCS the
propagator is partitioned into an analytically tractable component exp{ δ2t L%} (blue) and the score
model term exp{δtLS} (brown). Only the latter requires numerical approximation, which results
in an overall more accurate integration scheme.
error 〜δt, which can be also seen from the last two lines of Eq. (95). This is expected, considering
that we used an Euler step for the S term. Nevertheless, as long as the dynamics is not dominated by
the S component, our proposed integration scheme is still expected to be more accurate than EM,
since we split off the analytically tractable part and only use an Euler approximation for the S term.
To this end, recall that the model only needs to learn the score of the conditional distribution
pt(vt|xt), which is close to Normal for much of the diffusion, in which case the S term will in-
deed be small. This suggests that the generative SDE dynamics are in fact dominated by AH and
AO in practice. From another perspective, note that (recalling that sθ(ut,t) = -'tα0(ut,t) with
αθ(ut,t) = '-1vt∕∑Vv + αθ(ut,t) from Sec. 3.2):
S(U t, T — t)+M-1vt = — `t αθ (ut, t) — ^Vv+M-1 vt
Σt
=-'tαθ(ut,t)+ vt (M — ∑vv
(96)
For large parts of the diffusion, ∑Vv is indeed close to M, such that the Vt term is very small (this
cancellation is the reason why We pulled the M_1Vt term into the S component). In Sec. 3, We
have also seen that our neural network component α0θ (ut , t) can be much smoother than that of
previous SGMs. Overall, this suggests that the error of SSCS indeed might be smaller than the error
We would obtain when applying a naive Euler-Maruyama integrator to the full generative SDE. Our
positive experimental results in Sec. 5.2 validate that. Only in the limit for very small steps, both
our SSCS and EM make only very small errors and are expected to perform equally well, which is
exactly what we observe in our experiments. Our SSCS turns out to be well-suited for integrating
the generative SDE of CLD-SGMs with relatively few synthesis steps.
32
Published as a conference paper at ICLR 2022
Note that error analysis of stochastic differential equation solvers is usually performed in terms of
weak and strong convergence (Kloeden & Platen, 1992). Due to the use of Euler’s method for the S
component, as argued above, we expect our SSCS to formally have the same weak and strong con-
vergence properties like EM, this is, weak convergence of order 1 and strong convergence of order
1 as well, since the noise is additive in our case (and assuming appropriate smoothness conditions
for the drift and diffusion coefficients; furthermore, without additive noise, we would have strong
convergence of order 0.5). We leave a more detailed analysis to future work.
In practice, we do not use SSCS to integrate all the way from t=0 to t=T , but only up to t=T - ,
and perform a denoising step, similar to previous works (Jolicoeur-Martineau et al., 2021a; Song
et al., 2021c). It is worth noting that our SSCS scheme would also be applicable when we used
time-dependent β(t), as in our more general derivation of the CLD perturbation kernel in App. B.
However, since we only used constant β in the main paper, we also presented SSCS in that way.
A promising direction for future work would be to extend SSCS to adaptive step sizes and to use
techniques to facilitate higher-order integration, while still leveraging the advantages of SSCS.
SSCS Algorithm. Finally, we summarize SSCS in terms of a concise algorithm:
Algorithm 1 Symmetric Splitting CLD Sampler (SSCS)
Input: Score function sθ(Ut,T — t), CLD parameters Γ, β, M = Γ2∕4, number of sampling steps N, step
sizes {δtn ≥ 0}nN=-01 * * * * chosen such that := T - PnN=-01 δtn ≥ 0 (stepsizes can vary, for example in QS).
Output: Synthesized model sample XN, along With a velocity sample VN.
Xo 〜N(Xo； 0d, Id), Vo 〜N(Vo； 0d,MId), Uo = (Xo, Vo)	. Draw initial prior samples from PEQ(U)
t = 0	. Initialize time
for n = 0 to N — 1 do
Un+1 〜N(un+1 ； μδtn (Un), Σ δtn )	. First half-step: apply exp{δ2nLA} on Un
2	2	^2^	^2^
U n+ 1 J U n+ 1 + δtn (2βr [s(Ut,T 0dt)+ M-1 vt])	. FUIISteP: apply exp{δtnLS } on 乙+ 1
Un+1 〜N(Un+1； μδtn (U：+ 1), ΣΣ峥)	.Second half-step: apply exp{δ2nLA} on U0n+1
t J t + δtn	. Update time
end for
U N J— U N 一 €
(XN, VN) = uN
一ΓMM-ι)⑥ Id) Un + € QβrS⅛t, €))	. DenOiSing
. Extract output data and velocity samples
Note that the algorithm uses the expressions in Eqs. (85) and (86) for μt and Σt. Furthermore, in
practice in the denoising step at the end, we usually only update the XN component of UN, since we
are only interested in the data sample. This saves us the final neural network call during denoising,
which only affects the VN component (also see App. E.2.4). However, we wrote the algorithm in
the general way, which also allows to correctly generate the velocity sample VN. In Fig. 8, we show
a conceptual visualization of our SSCS and contrast it to EM.
Also note that we could combine the second half-step from one iteration of SSCS with the first half-
step from the next iteration of SSCS. This is commonly done in the Leapfrog integrator (Leimkuhler
& Reich, 2005; Tuckerman, 2010; Neal, 2011; Leimkuhler & Matthews, 2015),6 which follows a
similar structure as our SSCS. However, it is not important in our case, as the only computationally
costly operation is in the center full step, which involves the neural network evaluation. The first
and last half-steps come at virtually no computational cost.
33
Published as a conference paper at ICLR 2022
(a) Difference ξ(t) (via L2 norm) between score of (b) Frobenius norm of Jacobian JF (t) of the neural
diffused data and score of Normal distribution. network defining the score function for different t.
Figure 9: Toy experiments for mixture of Normals dataset.
E Implementation and Experiment Details
E.1 Score and Jacobian Experiments
In this section, we provide details for the experiments presented in Sec. 3.1. For both experiments,
we consider a two-dimensional simple mixture of Normals of the form
pdata(x)
91
X 9日
(97)
where p(k) (x) = N(x; μk; 0.04212) and
_ 1
and a = 2- 2. The choice of this data distribution is not arbitrary. In fact, mixture of Normal
distributions are diffused by simply diffusing the components, i.e., setting p0 (x0) = pdata (x), we
have
91
Pt(Xt) = X 9Pt (Xt),
k=1
(98)
where Pt(k) are the diffused components (analogously for CLD with velocity augmentation). This
means that for both CLD as well as VPSDE Song et al. (2021c) we can diffuse Pdata(X) with
analytical access to the diffused marginal Pt (Xt) or Pt (ut). This allows us to perform interesting
analyses that would be impossible when working, for example, with image data. We visualize the
data distribution in Fig. 10.
Score experiment: We empirically verify the reduced complexity of the score ofPt(vt|Xt), which
is learned in CLD, compared to the score of Pt (Xt), which is learned in VPSDE. To avoid scaling
issues between VPSDE and CLD, we chose M = γ = 1 for CLD in this experiment; this results
in an equilibrium distribution of N(02 , I2) (for both data and velocity components, which are inde-
pendent at equilibrium), which is the same as the equilibrium distribution of the VPSDE. We then
6The Leapfrog integrator corresponds to the velocity Verlet integrator in molecular dynamics.
34
Published as a conference paper at ICLR 2022
(a) Data pdata
(b) CLD w/ MS
(c) CLD w/o MS	(d) VPSDE w/ MS (e) VPSDE w/o MS
Figure 10: Mixture of Normals: data and trained models (samples).
measure the difference of the respective scores at time t and the equilibrium (or prior) scores, i.e.
(recall that the score of a Normal distribution P(X) = N(02, I2) is simply Vx logP(X) = -x),
ξVPSDE(t) ：= Ext ~p(xt)kVxt log pt (xt)+ Xt k2,	(99)
ξCLD (t) := EUt~p(ut) kvvtlogPt (Vt | Xt) + Vt k2.	(100)
The expectations are approximated using 105 samples from P(Xt) and P(ut) for VPSDE and CLD,
respectively. As can be seen in Fig. 9a, ξCLD (t) is smaller than ξVPSDE (t) for all t ∈ [0, T]. The
difference is particularly striking for small time values t. Other previous SDEs, such as the VESDE,
sub-VPSDE, etc., are expected to behave similarly. This result implies that the ground truth scores
that need to be learnt in CLD are closer to Normal scores than the ground truth scores in previous
SDEs like the VPSDE. Since the score of a Normal is very simple—and indeed directly leveraged
in our mixed score formulation—we would intuitively expect that the CLD training task is easier.
Complexity experiment: Therefore, to understand the above observations in terms of learning
neural networks, we train a small ResNet architecture (less than 100k parameters) for each of the
following four setups: both CLD and VPSDE each with and without a mixed score parameterization.
The mixed score of the VPSDE simply assumes a standard Normal data distribution (which is also
the equilibrium distribution of VPSDE) resulting in adding -Xt to the score function. Formally,
-Xt is the score of a Normal distribution with unit variance.
We train the models for 1M iterations using fresh data synthesized from Pdata at a batch size of 512.
The model and data distributions are visualized in Fig. 10. We see that all models have learnt good
representations of the data. We measure the complexity of the trained neural networks using the
squared Frobenius norm of the networks’ Jacobians. For CLD, we have
JFCLD(t) := Eut~p(ut)IlVutαθ(Ut)IlF.	(101)
Similarly, for the VPSDE we compute
JIVPSDE(t) := Ext~p(xt)IlVxtαθ(Xt)IlF.	(102)
For both CLD and VPSDE, expectations are again approximated using 105 samples. As can be seen
in Fig. 9b the neural network complexity is significantly lower for CLD compared to VPSDE. A
mixed score formulation further helps decreasing the neural network complexity for both CLD and
VPSDE. This result implies that the arguably simpler training task in CLD indeed also translates to
reduced model complexity in that the neural network is smoother as measured by JF (t). In large-
scale experiments, this would mean that, given similar model capacity, a CLD-based SGM could
potentially have a higher expressivity. Or, on the other hand, similar performance could be achieved
with a smoother and potentially smaller model. Indeed these findings are in line with our strong
results on the CIFAR-10 benchmark.
E.2 Image Modeling Experiments
We perform image modeling experiments on CIFAR-10 as well as CelebA-HQ-256. We report
FID scores on CIFAR-10 for our main model for various different solvers; see Tab. 3 and Tab. 2.
We further present generated samples for both models in Sec. 5 using Euler-Maruyama with 2000
35
Published as a conference paper at ICLR 2022
Hyperparameter	CIFAR10 (Main)	CelebA (Qualitative)	CIFAR10 (Ablation)
Model			
EMA rate	0.9999	0.9999	0.9999
# of ResBlocks per Resolution	8	2	2
Normalization	Group Normalization	Group Normalization	Group Normalization
Scaling by σ	X	X	X
Nonlinearity	Swish	Swish	Swish
Attention resolution	16	16	16
Embedding type	Fourier	Positional	Positional
Progressive	None	None	None
Progressive input	Residual	None	None
Progressive combine	Sum	N/A	N/A
Finite Impulse Response (Zhang, 2019)	✓	X	X
# of parameters	≈ 108M	≈ 68M	≈ 39M
Training			
# of iterations	800k	320k	1M
# of warmup iterations	100k	100k	100k
Optimizer	Adam	Adam	Adam
Mixed precision	✓	✓	✓
Learning rate	2∙10-4	10-4	2∙10-4
Gradient norm clipping	1.0	1.0	1.0
Dropout	0.1	0.1	0.1
Batch size per GPU	8	4	8
# of GPUs	16	16	16
t-sampling cutoff during training	10-5	10-5	10-5
SDE			
M	0.25	0.25	varies
γ	0.04	0.04	varies
β	4	4	varies
num	10-9	10-6	10-9
Table 6: Model architectures as well as SDE and training setups for our experiments on CIFAR-10
and CelebA-HQ-256.
quadratic striding steps and RUnge-KUtta 4(5) for CIFAR10 and CelebA-HQ-256, respectively. We
present additional samples for various solver settings in App. F. All (average) NFES for the Runge-
KUtta solver are compUted Using a batch size of 128.
E.2.1 Training Details and Model Architectures
Our models are based on the NCSN++ and the DDPM++ architectures from Song et al. (2021c).
Importantly, we changed the number of input channels from three to six to facilitate the additional
velocity variables. Note that the number of additional neural network parameters due to this change
is negligible.
For fair a comparison, we train our models using the same t-sampling cutoff during training as is
used for VESDE and VPSDE in Song et al. (2021c). Note, however, that this is not strictly necessary
for CLD as we do not have any “blow-up” of the SDE due to unbounded scores as t → 0 (also see
Fig. 18 and Fig. 19).
We summarize our three model architectures as well as our SDE and training setups in Tab. 6.
E.2.2 CIFAR- 1 0 Results for VESDE and VPSDE
The results reported for VESDE and VPSDE using the GGF sampler are taken from Jolicoeur-
Martineau et al. (2021a). All other results for VESDE and VPSDE are generated using the provided
PyTorch code as well as the provided checkpoints from Song et al. (2021c).7 We used EM and PC
7https://github.com/yang-song/score_sde_pytorch
36
Published as a conference paper at ICLR 2022
to sample from the VPSDE and VESDE models, respectively (see Sec. 5.2), since these choices
correspond to their recommended settings.8
Furthermore, in App. F.2 we also used DDIM (Song et al., 2021a) to sample the VPSDE. DDIM’s
update rule is
αt-1
xt-ι =------
αt
xt + σt2sθ(xt,t) - σt-1σtsθ(xt,t),
(103)
where αt = exp -0.5 R0t β(t) dt , σt2 = 1 - exp - R0t β(t) dt , and β(t) = 0.1 + 19.9t.
E.2.3 Quadratic Striding
When we simulate our generative SDE numerically, using for example EM or our SSCS, we need to
choose a time discretization. Given a certain NFE budget NNFE, how do we choose time step sizes?
The standard approach is to use an equidistant discretization, corresponding to a set of evaluation
time steps {δti ≥ 0}N=NFET with δt = N^∀i ∈ [0, NNFE - 1]. However, prior work (Song et al.,
2021a; Kong & Ping, 2021; Watson et al., 2021) has shown that it can be beneficial to focus function
evaluations (neural network calls) on times t “close to the data”. This is because the diffusion
process distribution is most complex close to the data and almost perfectly Normal close to the
prior. Among other techniques, these works used a useful heuristic, denoted as quadratic striding
(QS), which discretizes the integration interval such that the evaluation times follow a quadratic
schedule and the individual time steps follow a linear schedule. We also used this QS approach in
our experiments.
We can formally define it as follows (assuming a time interval [0.0, 1.0] here for simplicity): Denote
the evaluation times as τi (including 0.0 and 1.0) and define:
τi = cτi2 ∀i ∈ [0, NNFE].	(104)
Hence,
δti = τi - τi-1 = cτ (2i - 1) ∀i ∈ [1, NNFE],	(105)
and cτ =舄一to ensure that TNFE = 1.0.
NNFE
This describes the time steps as going from t = 0 to t = 1. During synthesis, however, we are going
backwards. Hence, we can define our time steps as
δtj = cτ [2NNFE - 2j + 1]	∀j ∈ [1, NNFE],	(106)
where j now counts time steps in the other direction. Note that this can be easily adapted to general
integration intervals [, T].
E.2.4 Denoising
As has been pointed out in Jolicoeur-Martineau et al. (2021b), samples that are generated with
models similar to ours can contain noise that is hard to detect visually but worsens FID scores
significantly.
Denoising Formulas. For a fair comparison we use the same denoising setup for all experiments
we conducted (including VESDE (PC/ODE) and VPSDE (EM/ODE)) except for LSGM.9 We sim-
ulate the underlying generative ODE/SDE until the time cutoff ε = 10-3 and then take a single
denoising step of the form
u0 = uε - εf(uε,ε) + εG(uε, ε)G(uε, ε)> sθ(0udε,ε) .	(107)
This denoising step can be considered as an Euler-Maruyama step without noise injection. For
SDEs acting on data directly (VESDE, VPSDE, etc.) the corresponding denoising formula is
x0 = xε - εf(xε,ε) + εG(xε,ε)G(xε,ε)>sθ(xε,ε).	(108)
8https://colab.research.google.com/drive/1dRR_0gNRmfLtPavX2APzUggBuXyjWW55
9Denoising has not been used in the original LSGM work (Vahdat et al., 2021) and is not needed in their
case, since the output of the latent SGM lives in a smooth latent space and is further processed by a decoder.
37
Published as a conference paper at ICLR 2022
Table 7: Influence of denoising step on FID scores (using our main CIFAR-10 model).
Sampler	Denoising	FID at n function evaluations ]	
		n=50	n=500
SSCS	✓	81.1	2.30
SSCS-QS	✓	20.5	2.25
SSCS	X	78.9	2.32
SSCS-QS	X	28.5	2.3
Influence of Denoising on Results. For SDEs acting in the data space directly, it has been reported
that this denoising step is crucial to obtain good FID scores Jolicoeur-Martineau et al. (2021b); Song
et al. (2021c). When we simulate the generative probability flow ODE we found that denoising is
important in order for the RUnge-KUtta solver not to “blow-up” as t → 0. On the other hand, when
simulating CLD using our new SSCS solver, we found that denoising only slightly influences FID
(see Tab. 7). We believe that this might be becaUse the neUral network does not have any inflUence
on the denoising step for CLD. More specifically, the neUral network only denoises the velocity
component. However, we are primarily interested in the data component. PUtting the drift and
diffUsion coefficients of CLD in the denoising formUla in Eq. (107), we obtain
u0 = uε-ε( (-β	-βMMM-i)㊈ Id)	uε + εQrβs0duε,ε))	=⇒	x0	=	xε	-	εβM-1vε.
(109)
E.2.5 S olver Error Tolerances for Runge–Kutta 4(5)
In Tab. 2, we report FID scores for a RUnge-KUtta 4(5) solver (Dormand & Prince, 1980) as well as
the “Gotta Go Fast” solver from JolicoeUr-MartineaU et al. (2021a) (see their Table 1). For simUlating
CLD with RUnge-KUtta 4(5) we chose the solver error tolerances to hit certain regimes of NFEs to
facilitate comparisons with VPSDE and VESDE. We obtain a mean nUmber of fUnction evalUations
of 312 and 137 Using RUnge-KUtta 4(5) solver error tolerances of 10-5 and 10-3, respectively.
For VESDE, VPSDE and LSGM we Used 10-5 as the ODE solver error tolerance, following the
recommended defaUlt setUps (Song et al., 2021c; Vahdat et al., 2021). These valUes are Used for
both relative and absolUte error tolerances.
E.2.6 Ablation Experiments
The model architectUre Used for all ablation experiments can be foUnd in Tab. 6. As pointed oUt in
Sec. 5 we foUnd that the hyperparameters γ and M only have small effects on CIFAR-10 FID scores.
On the other hand, we foUnd that the mixed score parameterization helps significantly in obtaining
competitive FIDs.
E.2.7 LSGM-100M Model
OUr CLD-based SGM has ≈108M parameters, while the original CIFAR-10 Latent SGM from
Vahdat et al. (2021), to which we compare in Tab. 1, Uses ≈476M parameters. To establish a
fairer comparison between oUr CLD-based SGMs and LSGM (Vahdat et al., 2021), we train an-
other smaller LSGM model with ≈109M parameters. To do this, we followed the exact setUp of
the “CIFAR-10 (balanced)” model from LSGM (see Table 7 in Vahdat et al. (2021)), with a few
minor modifications: We Used a VAE backbone model with only 10 groUps instead of 20, which
corresponds to a redUction in parameters by a factor of 2 in the encoder and decoder networks. We
also redUced the convolUtional channels in the latent space SGM from 512 to 256 and redUced the
nUmber of the residUal cells per scale from 8 to 4. With these modifications the resUlting “LSGM-
100M” Uses only ≈109M parameters overall with approximately half of them in the encoder and
decoder networks and the other half in the latent SGM. Other than these architectUre modifications,
oUr model is trained in exactly the same way as the bigger, original models in Vahdat et al. (2021).
38
Published as a conference paper at ICLR 2022
Table 8: Performance (measured in negative log-likelihood) using analytical scores for non-adaptive stepsize
solvers for varying numbers of synthesis steps n (function evaluations).
-logP(X) at n function evaluations ]
Model	Sampler	n=20	n=50	n=100	n=200
CLD	EM	60.6	9.71	0.72	-1.04
CLD	SSCS	10.5	1.55	-1.25	-1.54
VPSDE	EM	14.2	4.68	-0.35	-1.11
For evaluation, we follow the recommended setting by Vahdat et al. (2021) and use the same Runge-
Kutta 4(5) ODE solver with an error tolerance of 10-5 to solve the probability flow ODE in LSGM’s
latent space. LSGM-100M achieves an FID of 4.60, an NLL bound of 2.96 bpd, and requires on
average 131 NFE for sampling new images. We report these results in Tabs. 1 and 2 in the main
text.
Note that we also tried training a model following the “CIFAR-10 (best FID)” setup, but found train-
ing to be unstable (however, the orignal “CIFAR-10 (best FID)” model from Vahdat et al. (2021)
only performs marginally better in FID than their “CIFAR-10 (balanced)” model anyway). Fur-
thermore, we also tried training another small LSGM with a similar number of parameters but with
more parameters in the latent SGM and less in the encoder and decoder networks, compared to the
reported LSGM-100M. However, this model performed significantly worse.
F Additional Experiments
F.1 Toy Experiments
F.1.1 Analytical Sampling
In order to test combinations of diffusions and numerical samplers in isolation, we consider a dataset
for which we know the ground truth score function (for all t) analytically. In particular, we use the
mixture of Normals introduced in App. E.1; see Fig. 10a for a visualization of the data distribution.
In Fig. 11, we show samples for VPSDE (EUler-MarUyama (EM) sampler) and CLD (EM and
SSCS samplers). For quantitative comparison, we also compute negative log-likelihoods for the
three combinations (which can be done easily due to our access to the ground truth distribution): as
can be seen in Tab. 8, for each number of steps n ∈ {20, 50, 100, 200} CLD with SCSS outperforms
both VPSDE and CLD with EM. As discussed in Sec. 3.3, we can see in Tab. 8 that EM is not well-
suited for CLD. This is true, in particular, when using a small number of synthesis steps n (function
evaluations). In Fig. 11, we see that CLD with EM leads to sampling distributions which are too
broad. These results are exactly in line with the “diverging” dynamics that is observed when solving
Hamiltonian dynamics with a non-symplectic integrator, such as the standard Euler method (Neal,
2011). This problematic behavior of Euler-based techniques is more pronounced when using fewer
steps with larger stepsizes, which is also what we observe in our experiments. These results further
motivate the use of our novel SSCS, which addresses these challenges, for sampling from our CLD-
based SGMs.
F.1.2 Maximum Likelihood Training
For maximum likelihood training, models based on overdamped Langevin dynamics such as VPSDE
need to learn an unbounded score for t → 0. Our model, on the other hand, only ever needs to learn
a bounded score even for t = 0. For our image data experiments, we use a reweighted objective
function to improve visual quality of samples (as is general practice).
Here, we also study training towards maximum likelihood on toy dataset tasks. To explore this, we
repeat the neural network complexity experiment from App. E.1 with maximum likelihood training
(instead of the reweighted objective). Furthermore, we also train VPSDE-based and CLD-based
SGMs on a challenging toy dataset and find that CLD significantly outperforms VPSDE. We leave
the study of CLD with maximum likelihood training for high-dimensional (image) datasets to future
work.
39
Published as a conference paper at ICLR 2022
(b) CLD + EM, n = 20
(c) CLD + SSCS, n = 20
(a) VPSDE + EM, n = 20
(d) VPSDE + EM, n
(e) CLD + EM, n
(f) CLD + SSCS, n = 50
(g) VPSDE + EM, n = 100
(j) VPSDE + EM, n = 200
(h) CLD + EM, n = 100
(k) CLD + EM, n = 200
(i) CLD + SSCS, n = 100
(l) CLD + SSCS, n = 200
Figure 11: Mixture of Normals: numerical simulation with analytical score function for different
diffusions (VPSDE with EM vs. CLD with EM/SSCS) and number of synthesis steps n. A visual-
ization of the data distribution can be found in Fig. 10a.
40
Published as a conference paper at ICLR 2022
Figure 12: Frobenius norm JF (t) of the neural network defining the score function for different t.
Complexity Experiment. The setup of this experiment is equivalent to the setup in App. E.1 up
to the training objective: in this experiment we do maximum likelihood learning, i.e., we train CLD
models with the objective from Eq. (8) with λ(t) = Γβ.10 Furthermore, we test CLD in this setup
for three different values of γ . The results of this experiment can be found in Fig. 12. For CLD, we
find that larger values of γ generally lead to less complex networks, in particular for smaller times
t. However, even for γ = 0.04 the learned neural network is still significantly smoother than the
network learned for the VPSDE when a mixed score parameterization is used.11
Challenging Toy Dataset. Using the same simple ResNet architecture (less than 100k parameters)
from the above experiment, we trained a VPSDE-based as well as a CLD-based SGM to maximize
the likelihood of a more challenging toy dataset (the dataset is essentially “multi-scale”, as it involves
both large scale—the placement of the swiss rolls—and fine scale—the swiss rolls themselves—
structure). Similar to the other toy datasets, the models are trained for 1M iterations using fresh data
synthesized from the data distribution in each batch at a batch size of 512.
In Fig. 13, we compare samples of the models to the data distribution. Even with our simple model
architecture, CLD is able to capture the multi-scale structure of the dataset: the five rolls are ade-
quately resembled and only a few samples are in between modes. VPSDE, on the other hand, only
captures the main modes, but not the fine structure. Furthermore, VPSDE has the undesired behavior
of “connecting” the modes.
Overall, we conclude that also in the maximum likelihood training setting CLD is a promising
diffusion showing superior behavior compared to the VPSDE in our toy experiments.
10For the ML objective of the VPSDE, we refer the reader to Song et al. (2021b).
11The VPSDE-based model with mixed score parameterization did not converge to the target distribution,
and therefore is not included in Fig. 12.
41
Published as a conference paper at ICLR 2022
二?	③
cl
0)	◎
(a) Data
(b) VPSDE
(c) CLD
Figure 13: Data distribution and model samples for multi-scale toy experiment.
Table 9: Performance using non-adaptive step size solvers. Extended version of Tab. 3.
Model	Sampler	FID at n function evaluations ]					
		n=50	n=150	n=275	n=500	n=1000	n=2000
CLD	EM	143	31.5	10.9	3.96	2.50	2.27
CLD	EM-QS	52.7	7.00	3.24	2.41	2.27	2.23
CLD	SSCS	81.1	10.5	2.86	2.30	2.32	2.29
CLD	SSCS-QS	20.5	3.07	2.38	2.25	2.30	2.29
VPSDE	EM	92.0	30.3	13.1	4.42	2.46	2.43
VPSDE	EM-QS	28.2	4.06	2.65	2.47	2.66	2.60
VPSDE	DDIM	6.04	4.04	3.53	3.26	3.09	3.01
VPSDE	DDIM-QS	3.78	3.15	3.05	2.99	2.96	2.95
VESDE	PC	460	216	11.2	3.75	2.43	2.23
VESDE	PC-QS	461	388	155	5.47	11.4	11.2
F.2 CIFAR-10 — Extended Results
In this section, we provide additional results on the CIFAR-10 image modeling benchmark.
An extended version of Tab. 3 (sampling the generative SDE with different fixed-step size solvers
for different compute budgets) including additional baselines can be found in Tab. 9. Note that time
stepping with quadratic striding (QS) improves sampling from VPSDE- and CLD-based models for
all settings except for the combination of VPSDE and EM sampling in the setting n = {1000, 2000}.
For the VESDE (using PC sampling), QS significantly worsens FID scores. The reason for this could
be that the variance of the VESDE already follows an exponential schedule (see Fig. 5 in Song et al.
(2021c)). We additionally present results for the VPSDE using the DDIM (Denoising Diffusion
Implicit Models) sampler (Song et al., 2021a). As was observed by Song et al. (2021a), QS also helps
for DDIM. Importantly, for any n ≥ 150, our CLD with our novel SSCS (and QS) even outperforms
DDIM. Only for n = 50, DDIM performs better. It needs to be mentioned, however, that the
DDIM sampler was specifically designed for few-step sampling, whereas our CLD with SSCS is
derived in a general fashion without this particular regime in mind. In particular, DDIM sampling
can be interpreted as a non-Markovian sampling method and it is not clear how to calculate the log-
likelihood of hold-out validation data under this non-Markovian synthesis approach. Nevertheless,
it would be interesting to also explore non-Markovian DDIM-inspired techniques for CLD-SGMs
to further improve sampling speed in CLD-SGMs.
Note that our DDIM results shown in Tab. 9 are better than those presented in Song et al. (2021a)
itself, because we are relying on the DDPM++ model trained in Song et al. (2021c), whereas Song
et al. (2021a) uses the DDPM model from Ho et al. (2020).
Finally, we present additional generated samples from our CLD-SGM model: see Fig. 14 and Fig. 15
for samples from EM-QS with 2000 evaluations and SSCS-QS with 150 evaluations, respectively.
42
Published as a conference paper at ICLR 2022
Figure 14: Additional samples using EM-QS with 2000 function evaluations. This setup gave us our
best FID score of 2.23.
K器整 IH&■■
,πlci0H∙∙
H□*E9□M
Siases 0 A ~
E≡Rb -:/K匕 A
Bn
KEI□L一川, Eħh2>面■■■■一a
■昆 He工B纪Knaq gβ□□ar≡Lfi
-,34 £=|9尊 r ∙aκ∕<Hαc!≡∙
/UM工BF够■&1Isnn
H≡lα∏^■■ fsBi3^B
ralsF &£一 Rga”s*B*F胃区、ra及
■CIHK亶sŋ乎FL□》TF 殍1
■HlsQEHI-liIT音电，£|| 整Ξ¾E K
-⅛ m2*b≡ħ>0旧 F∙ΞH1■就
0，熹QkJBn∙BMn 照〕PH∙≡国总
m4κ∙∙Br 脉温rlsFwy ⅝9
43
Published as a conference paper at ICLR 2022
Figure 15: Additional samples using SSCS-QS. This setup resulted in an FID score of 3.07 using
only 150 function evaluations.
αHB黑
⅛用界工AEi
战不泼D∙≡
>FE■
SRHnn 上吊门sð率s∙
QMm他盛地妣97匾 JtiL」
d□BB≡^r A OK- S
再S金翔∙Ξ3*D
Er*r,sŋ口-

44
Published as a conference paper at ICLR 2022
F.3 CelebA-HQ-256 — Extended Results
In this section, we provide additional qualitative results on CelebA-HQ-256. For high quality sam-
ples using our new SSCS solver see Fig. 16.
Samples generated with an adaptive step size RUnge-KUtta 4(5) solver at different solver tolerances
can be found in Fig. 17. We found that our model still generates very good samples even for a solver
error tolerance of 10-3 Using an average of 129 neUral network evalUations.
Lastly, we show “generation paths” of samples from oUr CelebA-HQ-256 model: see Fig. 18 and
Fig. 19 for samples from the probability flow ODE and the generative SDE, respectively. We visU-
alize the continUoUs generation paths via snapshots of data and velocity variables at eight different
time steps. Interestingly, we can see that the velocity variables “encode” the data at intermediate t.
On the other hand, at time t = 1.0, by constrUction, both data and velocity are distribUted according
to the “eqUilibriUm distribUtion” of the diffUsion, namely, pEQ(u) = N (x; 0d, Id) N (v; 0d, MId).
FUrthermore, as t → 0 the data variables approximately converge to the data distribUtion, while the
velocity variables approximately converge to another Normal distribUtion N (v; 0d, γMId) (with
γ = 0.04 in oUr experiments).
Recall that for CLD, the neural network approximates the score Nvt logpt(vjxt). We believe that
the generation paths are fUrther evidence that CLD-SGMs need to learn simpler models: for fixed
t the velocity variable vt appears to be a “noisy” version of the data xt, and therefore we believe
pt(vt|xt) to be relatively smooth and simple when compared to the marginalpt(xt).
Finally, note that in Figs. 18 and 19, when visUalizing the velocity variables, we Used a colorization
scheme that corresponds exactly to the inverse of the color scheme Used for visUalizing the images
themselves. Alternatively, we coUld also interpret this in sUch a way that we are not actUally visU-
alizing velocities, bUt negative velocities with flipped signs. When Using this inverse colorization
scheme for the velocities, we see that at intermediate t, where the velocities encode the data, the
color valUes visUalizing image data and velocities are, apart from the additional noise in the veloc-
ities, similar (i.e. the velocities appear as noisy versions of the actUal images). This implies that
image pixel valUes xt translate into corresponding negative velocities vt that pUll the pixel valUes
back towards the mean of the eqUilibriUm distribUtion. This is a conseqUence of the Hamiltonian
coUpling between the data and velocity variables. In other words, it is a resUlt of the negative sign
in front of xt in the H term in Eq. (5) (and analogoUsly for the reverse-time generative SDE). Also
see the visUalizations on oUr project page (https://nv-tlabs.github.io/CLD-SGM).
45
Published as a conference paper at ICLR 2022
Figure 16: Samples generated by our model on the CelebA-HQ-256 dataset using our SSCS solver.
46
Published as a conference paper at ICLR 2022
(a) ODE solver error tolerance 10-5; 273 average NFE.
(b) ODE solver error tolerance 10-4; 190 average NFE.
(c) ODE solver error tolerance 10-3; 129 average NFE.
(d) ODE solver error tolerance 10-2; 99.4 average NFE.
Figure 17: Samples generated by our model on the CelebA-HQ-256 dataset using a Runge-Kutta
4(5) adaptive ODE solver to solve the probability flow ODE. We show the effect of the ODE solver
error tolerance on the quality of samples ((a), (b), (c) and (d) were generated using the same prior
samples). Little visual differences can be seen between 10-5 and 10-4. Low frequency artifacts can
be observed at 10-3. Deterioration starts to set in at 10-2.
47
Published as a conference paper at ICLR 2022
Figure 18: Generation paths of samples from our CelebA-HQ-256 model (RUnge-KUtta 4(5) solver;
mean NFE: 288). Odd and even rows visualize data and velocity variables, respectively. The eight
columns correspond to times t ∈ {1.0, 0.5, 0.3, 0.2, 0.1, 10-2, 10-3, 10-5} (from left to right). The
velocity distribution converges to a Normal (different variances) for both t → 0 and t → 1. See
App. F.3 for visualization details and discussion.

48
Published as a conference paper at ICLR 2022
Figure 19: Generation paths of samples from our CelebA-HQ-256 model (SSCS-QS using only 150
steps). Odd and even rows visualize data and velocity variables, respectively. The eight columns
correspond to times t ∈ {1.0, 0.5, 0.3, 0.2, 0.1, 10-2, 10-3, 10-5} (from left to right). The velocity
distribution converges to a Normal (different variances) for both t → 0 and t → 1. See App. F.3 for
visualization details and discussion.
49
Published as a conference paper at ICLR 2022
G Proofs of Perturbation Kernels
In this section, we prove the correctness of the perturbation kernels of the forward diffusion
(App. B.1) as well as for the analytical splitting term in our SSCS (App. D.2). All derivations
are presented for general time-dependent β(t).
G. 1 Forward Diffusion
We have the following ODEs describing the evolution of the mean and the covariance matrix
where	dμt ---= dt dΣt ---= dt	:(f(t) 0 Id)μt, :(f (t) 0 Id)∑t + [(f (t) 0 Id)∑t]> + (G(t)G>(t)) 0 Id,		(110) (111)
		f(t):=	0	4β(t)Γ-2 f(t) := -β(t) -4β(t)Γ-1 ,		(112)
		Gt= (0 p2Γβ(t)).		(113)
In App. B.1, we claim the following solutions:				
		μt := Ctμt,		(114)
		μ t := (μv),		(115)
		Ct := e-2B(t)Γ-1,		(116)
		μχ := 2B(t)Γ-1X0 + 4B(t)Γ-2vt + X0,		(117)
		μv ：= -B(t)x0 — 2B(t)Γ-1V0 + v0,		(118)
and				
Σt :=	Σt 0 Id ,			(119)
Σt :=	Dtς t,			(120)
∑ t ：=	Σtxx Σtxv Σtxv Σtvv	,		(121)
Dt :=	-4B(t)Γ-1 e,			(122)
Σxx :=	Σ0xx + e4B(t)Γ	1 - 1 + 4B(t)Γ-1 (Σ0xx - 1) +4B2(t)Γ-2 (Σ0xx	- 2) + 16B2(t)Γ	-4 vv Σ0 ,
				(123)
Σxv :=	-B(t)Σ0xx + 4B(t)Γ-2 Σ0vv - 2B2 (t)Γ-1 (Σ0xx - 2) - 8B2 (t)Γ		3 vv Σ0 ,	(124)
Σvv :=	Γ2 ( AB(t)Γ-1 ~ Ie	—1)+ B(t)Γ + Σvv(1 + 4B2(t)Γ-2 — 4B(t)Γ-	1) + B2(t) (Σ0xx	— 2) ,
(125)
where B(t) = Rt β(t) dt and μ0 = [x0, v0]> as well as ∑χx and ∑Vv are initial conditions.
G.1.1 Proof of Correctness of the Mean
Plugging the claimed solution (Eqs. (114)-(118)) back into the ODE (Eq. 110), we obtain
/ɪt~ΓΓ + ~~7ΓCt = Ct(f (t) 0 Id)μt.	(126)
dt dt
The above can be decomposed into two equations:
-2β(t)Γ-1μX + 等=4β(t)Γ-2μV,	(127)
-2β(t)Γ-1μV + dμv = -β(t)μX - 4β(t)Γ-1μV,	(128)
50
Published as a conference paper at ICLR 2022
where we used the fact that 符=-2β(t)Γ-1Ct.
Eq. (127): Plugging the claimed solution into Eq. (127), We obtain:
-2β(t)Γ-1 [2B(t)Γ-1x0 +4B(t)Γ-2v° +x0] + [2β(t)Γ- 1x0 +4β(t)Γ-2v°] =4β(t)Γ-2 [-B(t)x0-2B(t)Γ-1 v0+v0].
(129)
Eq. (128): After simplification, plugging in the claimed solution into Eq. (128), we obtain:
2β(t)Γ-1 [-B(W-2B(t)Γ-1 V0⅛V0^ + [-β(t)X0-W)P-IV0] = -β(t) h2B(t)P-1X0+4B(t)Γ-2
^
,V0 +x0j .
(130)
This completes the proof of the correctness of the mean.
G.1.2 Proof OF Correctness OF the Covariance
Plugging the claimed solution (Eqs. (119)-(125)) back in the ODE (Eq. (111)), we obtain

Dt +-----τ--∑t % Id = Dt (f (t) % Id)(Σ t % Id)+ Dt
dt	dt

[(f(t)⑥ Id)(Σt ⑥ Id)]> + (G(t)G>(t))⑥ Id.
(131)
Noting that
∕∖
∕∖
(f(t)乳 Id)(Σt 乳 Id) = (f(t)Σt)乳 Id
and
4Γ-2Σxv
4Γ-2Σvv
—Σχx — 4Γ-1 Σχv —Σxv — 4Γ-1 Σw
(132)
β⑴
③Id,
G⑴GT ⑴=(0 2Γβ(t)),
(133)
as well as the fact that dDt = —4β(t)Γ-1Dt, we can decompose Eq. (131) into three equations:
—4β(t)Γ-	jσ,,∣ dΣxx ∑t + 丁二	=8β (t)Γ-2Σxv,	(134)
—4β (t)Γ-	xvxv K+，	=β(t) [—Σxx — 4Γ-1Σxv + 4Γ-2Σvv],	(135)
—4β(t)Γ	£Vv F +泉二	=β(t) [—2Σxv — 8Γ-1Σvv] + 2Γβ(t)D-1.	(136)
Eq. (134): Plugging the claimed solution into Eq. (134), we obtain
-4β(t)Γ-1 [∑Xx +
+ 4β(t)Γ-1 C∑X3 +8β( t
，—1
+ 4

Γ-2 (∑Xx - 2)÷16B2(⅛)Γ-4∑Vv]
T - 2)+32β(t)B(t)Γ-4Σ0v
(137)
Eq. (135): After simplification, plugging the claimed solution into Eq. (135), we obtain
(138)
51
Published as a conference paper at ICLR 2022
Eq. (136): After simplification, plugging the claimed solution into Eq. (136), We obtain
4β(t)Γ-1 [S GiB∙k1-1)+ B(t)Γ + ∑0
，v
+ [⅛W-⅛4Bwr-r+β(t)Γ + ∑vv (8B(tM<-2-4β(t)Γ-1) +2β(t)B(t) (∑0x-2)]
=-2β(t) [-B(t)∑Xx+4B(t)P-2∑Vv-2B2(t)Γ-1 (∑Xx - 2)-8B2(tΓ3∑0v]
+2Γβ(t)e4B(t)r-1.
This completes the proof of the correctness of the covariance.
(139)
G.2 Analytical Splitting Term OF SSCS
We have the folloWing ODEs describing the evolution of the mean and the covariance matrix
~tj~ = (f(T - t)③ Id)μt,	(14O)
^df^ =	(f (T	-1)③ Id)Nt	+	[(f (T	- t)③	Id)Nt]	+ (G(T — t)Gτ(T	— t)) 0 Id,	(141)
Where
f(T — t"	(	0 "T	-	t)r-2ʌ	(142)
f (I t) =	+β(T - t) -4β(T-	t)Γ-1)	,	(142)
G(T - t) ：=	(θ √2Γβ(T - t)}	(143)
These ODEs are very similar to the ODEs of the forward diffusion in App. G.1, the only difference
being flipped signs in the off-diagonal terms of f (T - t) (highlighted in red).
in App. D.2, we claim the following solutions
and
μ t	=Cta t,	(144)
∣⅛≠ 林t	弋X），	(145)
Ct	=e-2B(t)Γ-1,	(146)
μχ	=2B(t)Γ-1Xto -4B(t)Γ-2Vto + Xt，，	(147)
μ v	=+B(t)Xt，一 2B(t)Γ 1Vt ' + Vt ',	(148)
∑ t =	μt 0 Id,	(149)
Σμ t =	Dta t,	(150)
Σ t =	(μxx μXv) μχv μvv ,	(151)
Dt =	e-4B(t)Γ-1,	(152)
μ xx =	e4B(t)r-1 - 1 - 4B(t)Γ-1 - 8B2(t)Γ-2,	(153)
μ Xv =	-4B2(t)Γ-1,	(154)
Σμ vv =	γ42 (e4B(t)r-1 - 1) + B(t)Γ - 2B2(t),	(155)
where B(t) = R； β(T -1) dt and μt = [xtz, "t，]> is an initial condition. Differences of the above
solution to the solutions of the forward diffusion are again highlighted in red. Note that by con-
struction the initial covariance for the analytical splitting term of SSCS is the zero matrix, i.e.,
ΣXX = ΣXv = ΣVv = 0, since we always initialize from an “updated sample”, which itself does not
have any uncertainty. Also note that in this derivation we use general initial t0 (whereas in App. G.1
we set t0 = 0 for simplicity).
52
Published as a conference paper at ICLR 2022
G.2.1 Proof OF Correctness OF THE MEAN
Plugging the claimed solution (Eqs. (144)-(148)) into the ODE (Eq. (140)), We obtain
jμt~IΓ + ~7TCt = Ct(f (T — t) 0 Id)μt.
dt dt
The above can be decomposed into tWo equations:
—2β(T — t)Γ-1μ X + T = —4β(T — t)Γ-2 4,
—2β(T — t)Γ-1μ V + T = β(T — t)μ X — 4β(T — t)Γ-1μ V,
where we used the fact that 曦=—2β(T — t)Γ-1Ct.
(156)
(157)
(158)
Eq. (157): Plugging the claimed solution into Eq. (157), we obtain:
-2β(T - t)Γ-1 [2B(t)Γ- 1xt，-4B(⅛)P-aV0+er∣ + [2^(^--t)Γ-4χ7-4β(T - t)Γ-2v J
=-4β(T - t)Γ-2 [B(t)Xt，-B«-*Vr+Vt，].
Eq. (128): After simplification, plugging the claimed solution into Eq. (128), we obtain:
2β(T - t)Γ-1 Ixt)X^-2B(t)Γ- 1Vt，+Vt^ + [β(T - t)Xt，-β(τ-)r-≤∣
l	」	(160)
=β(T -1) ∣;2BW-⅛7-4B(t)Γ-2Vt，+Xt，].
This completes the proof of the correctness of the mean.
G.2.2 Proof of Correctness of the Covariance
Plugging the claimed solution (Eqs. (149)-(155)) into the ODE (Eq. (141)), we obtain
~dt Dt + dt^ ς t % Id = Dt(f % Id)(Σ t % Id) + Dt
with f = f (T — t) and G = G(T — t).
Noting that
[(f ⑥ Id)(Σt ⑥ Id)]τ + (GGT) Igl Ia
(161)


(f (T — t) 0 Id)(∑t 0 Id) = (f (T — t)Σt) 0 Id
and
β (T — t)
_ —4Γ-2ΣK
Σ xx — 4Γ-1Σ;
_ —4Γ-2ΣVV
Σ xv — 4Γ-1Σ,
VV 0 Id ,
(162)
G(T — t)Gτ(T — t)
0 2Γβ(T — t),
(163)

0
IxV
0

as well as the fact dDt = —4β(T — t)Γ-1Dt, we can decompose Eq. (161) into three equations:
—4β(T — t)Γ-1Σ xx +
—4β (T — t)Γ-1Σχv +
—4β(T — t)Γ-1 ΣVV +
dΣ xx
dt
dΣ xv
dt
dΣ vv
dt
—8β (T — t)Γ-2ΣXV,
(164)
β(T — t) [Σχx — 4Γ-1 ΣXV — 4Γ-2Σvv],
β(T — t) [2ΣXV — 8Γ-1ΣVV] + 2Γβ(T — t)D-1.
(165)
(166)
Eq. (164): Plugging the claimed solution into Eq. (164), we obtain
-4β(T - t)Γ-1 [eiB(i)r-1-1 -4B(t)Γ-1 j-8B2-ft)T-2∣
4β(T-

(167)
-8β(T - t)Γ-2
53
Published as a conference paper at ICLR 2022
Eq. (165): After simplification, plugging the claimed solution into Eq. (165), We obtain
-8
β(T -1)
-4Γ-2β(T - t)[牛卜幽小-1 — ι)+b(⅛)Γ-2B2(t)].
Eq. (166): After simplification, plugging the claimed solution into Eq. (166), We obtain
4β(T - t)Γ-1 [^ ^e4B(t)r-1 -1) +B(t)Γj-2Ba(t)∣
Ire(T - t)e4B(t)r-1 +β(τ-t)Γ--4β(T - t)B(t)]
(168)
(169)
=2β(T-t)]-4B2(tTΓτ] +2Γβ(T -
This completes the proof of the correctness of the covariance.
To connect back to the SSCS as presented in App. D.2, recall that in practice we use constant β (and
T = 1) and that we solve for small time steps of size 竽,such that B(t) = β 竽,which leads to the
expressions presented in App. D.2.
54