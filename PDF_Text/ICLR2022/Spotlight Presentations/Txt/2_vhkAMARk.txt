Published as a conference paper at ICLR 2022
Escaping limit cycles: Global convergence for con-
strained nonconvex-nonconcave minimax problems
Thomas Pethick* Puya Latafat: Panagiotis Patrinos: Olivier Fercoq; Volkan Cevher*
Abstract
This paper introduces a new extragradient-type algorithm for a class of
nonconvex-nonconcave minimax problems. It is well-known that finding a local
solution for general minimax problems is computationally intractable. This ob-
servation has recently motivated the study of structures sufficient for convergence
of first order methods in the more general setting of variational inequalities when
the so-called weak Minty variational inequality (MVI) holds. This problem class
captures non-trivial structures as we demonstrate with examples, for which a large
family of existing algorithms provably converge to limit cycles. Our results require
a less restrictive parameter range in the weak MVI compared to what is previously
known, thus extending the applicability of our scheme. The proposed algorithm is
applicable to constrained and regularized problems, and involves an adaptive step-
size allowing for potentially larger stepsizes. Our scheme also converges globally
even in settings where the underlying operator exhibits limit cycles.
1 Introduction
Many machine learning applications, from generative adversarial networks (GANs) to robust re-
inforcement learning, result in nonconvex-nonconcave constrained minimax problems, which pose
notorious difficulties to the scalable first order methods. Indeed, there is no shortage of results illus-
trating divergent or cycling behavior When going beyond minimization problems (BenaIm & Hirsch,
1999; Hommes & Ochea, 2012; Mertikopoulos et al., 2018b; Hsieh et al., 2021).
Traditionally, minimax problems have been studied for more than half a century under the umbrella
of the variational inequalities (VIs). The extragradient-type algorithms from the VI literature Was
recently brought to the aWareness of the machine learning community (Mertikopoulos et al., 2018a;
Gidel et al., 2018; Bohm et al., 2020), and have provided a principled way of stabilizing training and
avoiding PoinCare recursions. However, these results mostly concern the convex-concave setting.
In nonconvex-nonconcave minimax problems, or more generally nonmonotone variational inequali-
ties (VIs), even finding a local solution is in general intractable. This has been made precise through
exponential lower bound of the classical optimization type (Hirsch & Vavasis, 1987) and computa-
tional complexity results (Papadimitriou, 1994; Daskalakis et al., 2021b). This is in sharp contrast
to minimization problems, where only finding a global solution is intractable. The recent result of
(Hsieh et al., 2021) provides some intuition behind this difference by showing that the asymptotic
limits of most schemes, including extragradient, can converge to attracting limit cycles.
To make progress in lieu of these negative results, Diakonikolas et al. (2021) proposes a simple
generalization of extragradient, called (EG+), that can converge to a stationary point even for a class
of nonmonotone problems provided that the weak Minty variational inequality (MVI) holds. This
problem class is parametrized by a constant ρ, which controls the degree of nonconvexity. However,
given the range of ρ in Diakonikolas et al. (2021), the new class is still too small to include even the
simplest counterexample of Hsieh et al. (2021) for the general Robbins-Monro schemes.
φLaboratory for Information and Inference Systems (LIONS), EPFL (thomas.pethick@epfl.ch)
:Department of Electrical Engineering (ESAT-STADIUS), KU Leuven
; Laboratoire Traitement et Communication d’Information, Telecom Paris, Institut Polytechnique de Paris
1
Published as a conference paper at ICLR 2022
Figure 1: Forsaken (Hsieh et al., 2021, Example 5.2) provides an example where the weak MVI constant
ρ does not satisfy algorithmic requirements of (EG+) and (EG+) does not converge to a stationary point
but rather the attracting limit cycle (left). In contrast, adaptively choosing the extrapolation stepsize large
enough with our new method, called (CurvatureEG+), is sufficient for avoiding the limit cycles (right).
The repellant limit cycle is indicated in black and the stream plot shows the vectorfield Fz. The blue and
red curves indicate multiple trajectories of the algorithms starting from initializations indicated in black.
See Appendix C.4 for properties of Forsaken.
Contributions Building on the analysis in Diakonikolas et al. (2021), we propose a new adaptive
scheme, called (CurvatureEG+), that converges even in the difficult counter example of Hsieh et al.
(2021) as illustrated in Fig. 1. Our main contributions are summarized below.
1.	We propose an adaptive extragradient-type algorithm that converges for a larger range of ρ, the
parameter in the weak MVI assumption (cf. Assumption I(iii)) than previously known.
2.	More importantly, We show that convergence is ensured if 2ρ + Yk > 0, where Yk is the extrapola-
tion stepsize. This is crucial since by selecting γk through a backtracking procedure larger stepsizes
are allowed, which in turn implies convergence for more negative values of ρ, thus capturing a larger
class of problems. In addition, we show that the linesearch eventually passes without triggering any
backtrack if initialized based on the Jacobian of F (cf. Section 4).
3.	We present a non-adaptive variant of our algorithm (CEG+), and show that for particular pa-
rameter choices (EG+) of Diakonikolas et al. (2021), and when ρ “ 0 the celebrated forward-
backward-forward (FBF) algorithm of Tseng (2000) are recovered, thus unifying and generalizing
both methods. We improve upon Diakonikolas et al. (2021) by not only relaxing the problem class
but also the stepsize range. We show that our results are tight by providing a matching lower bound,
thus providing a complete picture of (EG+) under weak MVI.
Related work The community has resorted to various approaches to make progress for
nonconvex-nonconcave minimax problems. One line of work focuses on deriving local convergence
results (Mazumdar et al., 2019; Fiez & Ratliff, 2020; Heusel et al., 2017). For global results, the
two primary approaches have been to either assume a global oracle for the inner problem (Jin et al.,
2019; Davis & Drusvyatskiy, 2018) or assume particular problem structure such as the Polyak-
匕OjaSieWicz condition (Nouiehed et al., 2019; Yang et al., 2020) or concavity for the inner problem
(Rafique et al., 2019).
We follow the same tradition of assuming structure, but from the general perspective of operator
theory. The idea of studying minimax and related problems through the lens of variational inequality
has a long history (Minty, 1962; Rockafellar, 1976; Polyak, 1987; Bertsekas, 1997), with recent
renewed interest due to its relevance for minimax formulations (Mertikopoulos et al., 2018a; Gidel
et al., 2018; Azizian et al., 2020).
One relaxation of the monotone case for which we have positive results is that of Minty varia-
tional inequalities (MVI) (Mertikopoulos et al., 2018a; Song et al., 2021; Zhou et al., 2017; Liu
et al., 2021), which includes all quasiconvex-concave and starconvex-concave problems. Diakoniko-
las et al. (2021) introduced the relaxed condition of weak MVI. In the unconstrained setting they
showed non-asymptotic convergence results under a restricted problem constant ρ. Similarly to us,
Lee & Kim (2021a) extends the regime but under the stronger condition of cohypomonotonicity.
2
Published as a conference paper at ICLR 2022
They do so by studying a more evolved variant of extragradient building on anchoring techniques.
We instead directly improve upon (EG+) and generalize it to new settings.
In the stochastic setting, usually the stepsize for the extrapolation step is diminishing. This is the
case in BOhm et al. (2020) where they consider a forward-backward-forward type scheme. However,
they remain in the monotone setting, where the limit cycles are non-attracting, as exemplified by a
bilinear game. Hsieh et al. (2021) recently showed that a large family of algorithms, which includes
the extragradient method with diminishing stepsize, can converge to attracting limit cycles. Going
beyond this restriction, prior to Diakonikolas et al. (2021), Hsieh et al. (2020) interestingly considers
two separate and diminishing stepsizes under the stronger assumption of MVI.
2 Problem formulation and preliminaries
In this paper We are interested in finding zeros of an operator (or set-valued mapping) T : ‘n * 'n
that is written as the sum of a Lipschitz continuous (but possibly nonmonotone) operator F and a
maximally monotone operator A. That is, we wish to find z P ’n such that the general inclusion
0 P Tz B Az ' Fz	(2.1)
holds. The set of all such points is denoted by zer T B tz P Rn | 0 P Tzu. Throughout the paper
problem (2.1) is studied under the following assumptions (definitions can be found in Appendix A).
Assumption I. In problem (2.1),
(i)	Operator A : ’n * ’n is a maximally monotone operator.
(ii)	Operator F : ‘n → 'n is L-LiPschitz continuous.
(iii)	Weak Minty variational inequality (MVI) holds, i.e., there exists a nonempty set S< 三 Zer T
Such thatfor all Z< P S< and some P P (— 2L, 8)
XV, Z — Z*〉ep}v}2, forall (z, V) P gph T.	(2.2)
Generally, we do not require the weak Minty assumption to hold at every z‹ P zer T . In fact, as
shown in Theorem 3.1 nonemptiness of S‹ is sufficient for ensuring that the limit points belong to
zerT. Interestingly, despite nonmonotonicity ofF, global (as opposed to subsequential) convergence
can be established when S‹ “ zerT, an assumption that is still weaker than cohypomonotonicity.
VIs provide a convenient abstraction for a range of problems. We mention some central examples
below but otherwise defer to the overview in Facchinei & Pang (2007). Subsequently, we provide
examples where the weak MVI holds.
Example 1:	(minimax optimization). A comprehensive way to capture a wide range of applications
in machine learning is to consider structured minimax problems of the form
minimize maximize L(x, y) B φ(x, y) ' g(X) — h(y),	(2.3)
xP’nx	yP’ny
where φ is not necessarily convex in x or concave in y. Functions g and h are proper extended
real-valued lower semicontinuous and convex, with easy to compute proximal maps. Common ex-
amples for g and h involve regularizers such as `1, `2 norms, or indicator functions of sets al-
lowing us to capture constrained minimax problems. The first order optimality condition asso-
ciated with this problem may be written in the form of the structured inclusion (2.1) by letting
Fz “ (Vxφ(X,y), — Vyφ(X,y)), Az “ (Bg(X), Bh(y)).
As it will become clear in the next section (cf. Algorithm 1), the main computations involved in the
proposed scheme are evaluations of F and resolvent Ja “ (id ' A)´1. Recall that the resolvent of a
maximally monotone operator is firmly nonexpansive with full domain (cf. (Bauschke & Combettes,
2017, Sect. 23)). IfA “ Bf is the subdifferential operator ofa convex function f, then its resolvent
is the proximal mapping. For instance when A is as in Example 1, then its resolvent is given by
JA (X, y) “ (proxg (X), proxh (y)).
Example 2:	(N-player games). More generally, we can consider a continuous game ofN players in
normal form. Denote the decision variables z :“ (zi; z´i) :“ (z1, ..., zN ) and let the loss incurred by
3
Published as a conference paper at ICLR 2022
the ith player be Li pZi; Z´) “ φi pz) ' gi(Ziq where @ is the payoff function and gi typically enforce
constraints on zi. Then we seek a Nash equilibrium, which is any decision which is unilaterally
stable, i.e.,
LiPz<;z´i-) ≤ LiPZi；z´i-) @Zi andi PrNSB {1,∙∙∙,N}∙	(2.4)
The corresponding first order optimality conditions may be written as AZ “ pBg1 pZ1q, . . . , BgN pZN qq
andFZ = 0 1 φ1(Z),..., JφNPZ)).
A solution to (2.1) thus returns a candidate for which the first order condition of the above problems
is satisfied. In the monotone case these two solution concepts coincide, while in the more general
case of weak MVI, we provide examples where this still holds. In particular, we introduce in Sec-
tion 5 a nonconvex-nonconcave minimax game which additionally exhibits limit cycles for FZ. As
a consequence most schemes including gradient descent ascent, extragradient and optimistic gradi-
ent descent ascent do not converge to a stationary point globally (Hsieh et al., 2021). However, the
global Nash equilibrium satisfies Assumption I(iii) with P > —1/2L, which We show is sufficient for
global convergence of (CEG+).
The weak MVI condition is satisfied in certain reinforcement learning settings. Specifically, Di-
akonikolas et al. (2021); Daskalakis et al. (2021a) considers a two-player zero-sum game where the
weak MVI holds, while neither MVI nor cohypomonotonicity holds. Interestingly, the formulation
requires constraint—a condition they do not handle. We thus provide the first provable algorithm for
this setting. Weak MVI also contains all quasiconvex-concave and starconvex-concave problems.
For further examples, the literature on cohypomonotonicity (Bauschke et al., 2020) is relevant since
it implies weak MVI, see for instance Lee & Kim (2021b, Example 1).
3	Generalizing Extragradient+
Our starting point is the Extragradient+ (EG+) algorithm of Diakonikolas et al. (2021) which is
identical to extragradient (Korpelevich, 1976) except for the second stepsize being smaller. They
only treat the inclusion (2.1) when A ” 0, and in our notation require ρ P P—1/8L, 0s. Specifically,
Zk “ Z — YkFZ, Z'1 = Z — αkYkFZ	(EG+)
where they choose Yk = 1/L and αk = 1∕2 (Diakonikolas et al., 2021, Thm. 3.2).
We generalize (EG+) in Algorithm 1 to take the operator A into account—consequently we capture
constraint and regularized problems as well. In addition, the scheme is adaptive in αk. We will show
that the weaker requirement ofρ P P—1/2L, 8) suffices even for the more general inclusion (2.1).
The main convergence results of Algorithm 1 are established in the next theorem. The proof is
largely inspired by recent developments in operator splitting techniques in the framework of mono-
tone inclusions (Latafat & Patrinos, 2017; Giselsson, 2021). The key idea lies in interpreting each
iteration of the algorithm as a projection onto a certain hyperplane, an interpretation that dates back
to Solodov & Tseng (1996); Solodov & Svaiter (1999).
Theorem 3.1. Suppose that Assumption I holds, and let λk P (0,2), Yk P ([—2ρU',1/Ll where
txU' B max{0,X}, δk P (´Yk∕2,ρS, liminfk_8 λk(2 — λk) > 0, and Hminfk一g(δk ' Yk∕2) > 0.
Consider the sequences (Z)kpN, (Zk)kPN generated by Algorithm 1. Thenfor all Z< P S<,
k-mɪn m Y2}Hzk — H/2 ≤ K⅛}z° — z<}2,	(3.1)
k“0,1,...,m k
where K = liminfk→8 λk(2 — λk)(δk ' Yk∕2)2. Moreover thefollowing holds
(i)	(Zk)kPN is bounded and its limit points belong to Zer T;
(ii)	if in addition limsupk f8 Yk < 1/L and S< = Zer T, then (Zk)kpN, (Zk)kPN both converge to
some Z‹ P zer T.
Note that whenever limsupk_8 Yk < L, Lemma A.3(ii) may be used to derive a similar inequality
in terms of }Zk — Z} by lower bounding }Hk — Hzk} in (3.1). We also remark that tighter rates may
be obtained in the regime P20, however, this will not be pursued in this work.
4
Published as a conference paper at ICLR 2022
Algorithm 1 (AdaptiveEG+) Deterministic algorithm for problem (2.1)
Initiauze Z0 “ Zinit P Rn, λk P (0,2), Yk P ([—2ρ[+, 1/L‰, δk P (´Y√2,ρ],
Repeat for k “ 0, 1, . . . until convergence
1	.ι: Let Zk = 'id + γkA) ´1 (Z ´ γkFzk)
1.2:	Compute stepsize
=δk + XZk ´ Zk, HZk ´ Hzk y
αk _ Yk	}HZk ´ Hzk}2	,
where H “ id ´ YkF.
1.3:	Update the vector Z'1 = Z + λkαk(HZk — HZ)
Return Z '1
3.1 Non-adaptive stepsize variant
Although we do not incur additional costs for evaluating the adaptive stepsize αk in step 1.2, it
proves instructive to present a variant with constant stepsize. As a result we compare the range of our
stepsizes against Diakonikolas et al. (2021) showing an improvement by a factor of 3{2. Moreover, in
the monotone case (ρ = 0), with a certain choice of stepsizes the algorithm reduces to the celebrated
forward-backward-forward (FBF) algorithm of Tseng (2000). We remark that the relation of FBF to
projection-type algorithms was noted in Tseng (2000), (Giselsson, 2021, Sect. 6.2.1).
To this end, in this subsection consider the following non-adaptive variant of Algorithm 1 that gen-
eralizes (EG+). Letting ak p (0,1 + 2δ"γk):
Zk = (id + YkA )´1' Z — YkFZ), Z '1 = Z + αk (HZ — HZ).	(CEG+)
The convergence of this algorithm is an immediate byproduct of Theorem 3.1. To see this, note
that the Z'1 update in step 1.3 may be written as Zk'1 = Z + 2ηkαk(Hk — HZ), for ηk P (0,1).
Therefore, convergence is still ensured for any αk < 2ɑk as the difference may be absorbed by the
relaxation parameter ηk . Note that by 1{2-cocoercivity of H (cf. Lemma A.3(i))
αk < 2δk + 1 W 2δk + 2〈H ´HZ' Z"—力=2ɑk,	(3.2)
k	yk	W Yk	}HZk — HZk}2	k,	(	)
establishing the validity of the prescribed stepsize range. The convergence of the non-adaptive vari-
ant is summarized in the next corollary that for simplicity is stated with constant parameters (drop-
ping subscripts k).
Corollary 3.2 (Constant stepsize). Suppose that Assumption I holds, and let Y P ([—2ρU',1/l∖,
δ p (一力，0],and α p (0,1 + 2%). Consider the SequenceS (Zk)kpN, (Zk)kPN generated according to
the update rule (CEG+). Then,
}Z0	Z‹}2
min }Hzk — Hzk}2 W	,	(3.3)
k“0,1,...,m	κ(m + 1)
where K = α(1 + 2δ — α). Moreover, the claims of Theorems 3.1(i) and 3.1(ii) hold true.
The setting of Diakonikolas et al. (2021) in (EG+) involves the stepsizes Yk = 1/L, αk = 1/2. Note
that when restricting to A ” 0, the iterates (CEG+) simplify to this form owing to the fact that
Hk — Hzk = Zk — yFZk — Hzk = —yFZk. In comparison, in our setting if δ = P = ´1∕8L (the smallest
ρ permitted in Diakonikolas et al. (2021)) is selected, then based on our analysis in Corollary 3.2 we
may select Yk = 1/L, and αk P (0,3∕4), thus the upper bound for the second stepsize is 3∕2 times that
of Diakonikolas et al. (2021).
Remark 3.3 (relation to FBF). In Corollary 3.2 the range of stepsizes γ, α may alternatively be set
as γ p ([—2ρU',1/L), α p (0,1 +2δ∕γS. This is due to the fact that if Y < 1/l (strictly), then H is strictly
1∕2-cocoercive. Therefore, in (3.2), 1 + 2δ < 2ɑk holds, and thus the stepsize α = 1 + 2δ is permitted.
Although this may appear to be of little practical significance, by setting Y P (0, 1/L), δ = ρ = 0,
and α = 1 in (CEG+), We obtain Z'1 = Zk + YFZ — YFZk, which is the forward-backward-forward
(FBF) algorithm of Tseng (2000), (Bauschke & Combettes, 2017, Thm. 26.17)).	□
5
Published as a conference paper at ICLR 2022
Figure 2: The grey region indicates where convergence provably cannot be guaranteed by Theorem 3.4.
The dashed line indicates where P “ 一1/8l. This is the condition under which (Diakonikolas et al., 2021,
Thm. 3.2)shows the first convergence result (♦). Corollary 3.2 improves their result by matching the lower
boundfor any α, in particularfor α “ 3/4 ( ∙). The adaptive scheme in Theorem 3.1 matches the smallest
possible ρ for any (EG+) scheme with fixed stepsize pq.
3.2 Lower bounds
We show that the result in Corollary 3.2 is tight by providing a matching lower bound when A ” 0.
We do so by fixing αk and showing a stepsize dependent lower bound. In particular, note that if
αk “ 1/2 as in Diakonikolas et al. (2021, Thm. 3.2), then Theorem 3.4 implies a lower bound of
ρ > —1/4l for the (EG+) scheme. The lower bound is contextualized in Fig. 2 by relating it to our
convergence results and existing results in the literature.
Theorem 3.4. Consider a sequence pzkqkPN generated according to (EG+) fixing γk “ γ “ 1/L
1α
and αk “ α P (0, 1). Let —pL ≥ 72-. Then, there exists an F : Rn → Rn, n > 1, satisfying
Assumption I(ii) and Assumption I(iii) for which the sequence will not converge.
4 Adaptively taking larger stepsizes using local curvature
As made apparent in the analysis in Section 3 (cf. Appendix B.1) the bound on the smallest weak
MVI constant P in Assumption I(iii) may be replaced with the requirement that P > —γk/2 for all
k P N. Therefore, larger stepsizes Yk would guarantee global convergence for an even larger class
of problems. Since a global Lipschitz constant is inherently pessimistic the natural question then
becomes how to locally choose a maximal stepsize without diverging.
The proposed scheme involves a backtracking linesearch that uses the local curvature for its initial
guess. The reason being that this will immediately pass, close enough to the solution z‹ , by argu-
ment of continuity. More precisely, we will set the initial guess to something slightly smaller than
} JF (Z )}—1, where JF (Z) denotes the Jacobian of F at Z and }∙ } is the spectral norm. Note that, de-
spite the use of second order information, the scheme remains efficient since }JF(z)} only requires
one eigenvalue computation performed through Jacobian-vector product (Pearlmutter, 1994).
Given an initial point Z0 “ Zinit and ν P (0, 1), the final scheme which we denote (CurvatureEG+)
proceeds for k “ 0, 1, . . . as follows:
1.	Obtain Yk and Zk according to Algorithm 2 with YInit “ ν} JF(Z)}一1
k 1	(CurvatureEG+)
2.	Compute zk'1 according to steps 1.2 and 1.3 of Algorithm 1
The above intuitive reasoning is made precise in the next lemma where it is shown that backtracking
linesearch will terminate in finite time and that Yinit will be immediately accepted asymptotically.
Algorithm 2 Lipschitz constant backtracking
Initialize Z P Rn, T P (0, 1), ν P (0, 1)
2.ι:	Set initial guess Y “ γinit, and let Gγ(Z) B 'id ' YA)´1'Z — YFz)
while y}F(GYpZ)) — Fz}> ν}GYpZ) — zk} do Y D TY
Return Yk “ Y and Zk “ Gy (Z)
6
Published as a conference paper at ICLR 2022
Lemma 4.1 (Lipschitz constant backtracking). Suppose that F : ‘n → 'n is a L-Lipschitz Contin-
uous operator. Consider the linesearch procedure in Algorithm 2. Then,
(i)	The linesearch terminates infinite time with Yemin{γinit, VTzL};
(ii)	Suppose that Pz)kPN converges to Z< P Zer T. If F is continuously differentiable, and YmIt P
P0,ν} JFPz)}T) with v P P0,1), then eventually the backtrack will never be invoked (γιnιt
would be accepted).
The convergence results for (CurvatureEG+) are deduced based of the above lemma and The-
orem 3.1 and are provided in Corollary B.1 in Appendix B.2. We illustrate the behavior of
(CurvatureEG+) in Fig. 1 and in Section 6.
5 Constructing toy examples
When Assumption I(iii) holds for negative ρ, limit cycles of the underlying operator Fz can emerge.
We illustrate this with simple polynomial examples for which all the properties of interest can be
computed in closed form.
Definition 1 (PolarGame). A PolarGame denotes a two-player game whose associated operator F
has limit cycles at }z}2 “ ci for all i P rks where ci ‰ 0.
This turns out to be particularly easy to construct in polar coordinates as the name suggests (see
Appendix C.1). Apart from introducing arbitrary number of limit cycles it also gives us control over
ρ. This is illustrated in the following instantiations capturing three important cases.
Example 3: (PolarGame). Consider Fz “ (ψ(羽y) — y,ψ(y, X) ` X) where }z}g ≤ 11∕10 and
ψPx,y) “ 16ax(—1 ' X2 ' y2)(—9 ' 16X2 ' 16y2). We have the following three cases:
(i)	a = 1 then P P (— L, — 2L) (ii) a = 4 then P P (- 2L, 一 ±) (iii) a “ 3 then P P (—8L, 一 ^L)
where L denotes the Lipschitz constant of F restricted to the constraint set. For all cases F exhibits
limit cycles at }z} “ 1 and }z} “ 3∕4. Proof is deferred to Appendix C.2.
Example 4: (minimax). In the particular case of constrained minimax problem we introduce the
following polynomial game:
minimize maximize φ(X, y) :“ Xy ` ψ(X) — ψ(y),	(GlobalForsaken)
| X W4∕3	| y W4∕3
where ψ(Z) “ 呈—z4 ' z2. We provide proof of the following properties in Appendix C.3:
(i)	There exists a repellant limit cycle and an attracting limit cycle of F.
(ii)	z‹ “ (0, 0) is a global Nash equilibrium for which Assumption I(iii) holds inside the constraint
with P > 一1∕2L, where L denotes the Lipschitz constant of F restricted to the constraint set.
6	Experiments
The algorithms considered in the experiments include the adaptive Algorithm 1, (CurvatureEG+),
and constant stepsize methods that can be seen as instances of (CEG+) for various choices of Yk
and ak. When Yk “ 1∕L and ak = 1 we recover a constrained variant of extragradient, which We
denote CEG. When ak “ 1∕2 we denote the scheme CEG+, which is the direct generalization to the
constraint setting of the (EG+) scheme studied in Diakonikolas et al. (2021, Thm. 3.2). Note that this
choice of αk restricts the problem class for which we otherwise can have guaranteed convergence
according to Corollary 3.2. When ak is chosen adaptively according to Algorithm 1 we refer to it as
AdaptiveEG+. Finally, when Yk is additionally chosen adaptively we use the name (CurvatureEG+).
In the stochastic setting, when Yk “ 1∕k and αk “ 1, effectively both stepsizes diminish, and we
recover a constrained variant of the popular stochastic extragradient scheme (see e.g. Hsieh et al.
7
Published as a conference paper at ICLR 2022
(a) Example 3 (a “ 1)
(b) Example 5(P “ 一力L)
-→- CEG -→- CEG+ →- AdaptiveEG+ T- CurvatureEG+
Figure 3: Deterministic setting. In (a) we have an instance of Example 3 with P V —1/2Lfor which
Theorem 3.4 provides lower bound for extrapolation stepsize γk “ 1{L. However, adaptively choosing
γk larger can converge as illustrated with (CurvatureEG+). In addition, (b) confirms with Example 5,
that (CEG+) for αk = 1/2 and CEG may indeed not converge even when P “ —1/3l. In contrast, both
AdaptiVeEG + and (CurvatureEG+) converges to the stationary point. Note that picking ak V 1/3 would
lead to convergence of (CEG+) by Corollary 3.2. See Fig. 6 and Fig. 7for supplementary experiments.
(a) Example 4
(b) Example 5 (P “ —1/3L)
Figure 4: Stochastic setting. In (a) we test the stochastic algorithms on our nonconvex-nonconcave con-
strained minimax example. The cycling behavior of SEG is inline with Hsieh et al. (2021), who shows that
the sequence generated by SEG can converge to limit cycles of the underlying operator F. On the other
hand, we observe that SEG+ escapes the attracting limit cycle. In (b) we also provide a more challenging
example motivated by our lower bound.
(2021, Algorithm 3)), which we refer to as SEG. We also consider a heuristic variant where γk “ 1{L
and only αk is decreasing, which we refer to as SEG+.
We test the algorithms on the constructed examples and confirm their convergence guarantees.
Specifically, we apply the algorithms to the minimax problem in Example 4, the PolarGames in
Example 3, and a worst case construction, Example 5, from the proof of the lower bound (cf. Ap-
Pendix B.3). For Example 5 We choose the problem parameters such that P “ 一1∕3L according to
(B.13), and additionally add an '8-ball constraint to keep the iterates bounded. To simulate the
stochastic setting We add Gaussian noise to calls of F. Results for the deterministic setting and
stochastic setting can be found in Fig. 3 and Fig. 4 respectively.
7	Conclusion
This paper introduced an EG-type algorithm for a class of nonconvex-nonconcave minimax prob-
lems that satisfy the weak Minty variational inequality (MVI). The range of parameter in the Weak
8
Published as a conference paper at ICLR 2022
MVI was extended compared to EG+ of Diakonikolas et al. (2021), and tightness of our results were
demonstrated through construction of a counter example. In addition, EG+ (Diakonikolas et al.,
2021), as well as the forward-backward-forward algorithm (Tseng, 2000) were all shown to be spe-
cial cases of our scheme. Furthermore, (CurvatureEG+) was proposed that performs a backtracking
linesearch on the extrapolation stepsize γk allowing for larger stepsizes and relaxes the condition
P > 2l to P > ´γk{2 which is often a much weaker condition. More importantly, it is shown that
asymptotically the linesearch always passes with Yk “ ν}JF(Z)}T for any V P (0,1), thus rat-
ifying the name (CurvatureEG+). Future direction include exploring applications of the proposed
algorithm in particular in the setting of GANs. It is also interesting to develope a variance reduced
variant of the algorithm for finite sum minimax problems.
8	Acknowledgments and disclosure of funding
We would like to especially thank Yu-Guan Hsieh for providing valuable feedback and discussion.
This project has received funding from the European Research Council (ERC) under the European
Union’s Horizon 2020 research and innovation programme (grant agreement n° 725594 - time-data).
This work was supported by the Swiss National Science Foundation (SNSF) under grant number
200021_205011. The work of the second and third author was supported by the Research Founda-
tion Flanders (FWO) postdoctoral grant 12Y7622N and research projects G081222N, G0A0920N,
G086518N, and G086318N; Research Council KU Leuven C1 project No. C14/18/068; Fonds de
la Recherche Scientifique - FNRS and the Fonds Wetenschappelijk Onderzoek - Vlaanderen un-
der EOS project no 30468160 (SeLMA); European Union’s Horizon 2020 research and innovation
programme under the Marie Sklodowska-Curie grant agreement No. 953348. The work of Olivier
Fercoq was supported by the Agence National de la Recherche grant ANR-20-CE40-0027, Optimal
Primal-Dual Algorithms (APDO).
References
WaiSS Azizian, Ioannis Mitliagkas, Simon Lacoste-Julien, and Gauthier GideL A tight and unified
analysis of gradient-based methods for a whole spectrum of differentiable games. In International
Conference on Artificial Intelligence and Statistics, pp. 2863-2873. PMLR, 2020.
Heinz H. Bauschke and Patrick L. Combettes. Convex analysis and monotone operator theory in
Hilbert spaces. CMS Books in Mathematics. Springer, 2017. ISBN 978-3-319-48310-8.
Heinz H Bauschke, Walaa M Moursi, and Xianfu Wang. Generalized monotone operators and their
averaged resolvents. Mathematical Programming, pp. 1-20, 2020.
Michel Benaim and Morris W Hirsch. Mixed equilibria and dynamical systems arising from ficti-
tious play in perturbed games. Games and Economic Behavior, 29(1-2):36-72, 1999.
Dimitri P Bertsekas. Nonlinear programming. Journal of the Operational Research Society, 48(3):
334-334, 1997.
Axel Bohm, Michael Sedlmayer, Erno Robert Csetnek, and Radu Ioan Bot. Two steps at a time-
taking gan training in stride with tseng’s method. arXiv preprint arXiv:2006.09033, 2020.
Constantinos Daskalakis, Dylan J Foster, and Noah Golowich. Independent policy gradient methods
for competitive reinforcement learning. arXiv preprint arXiv:2101.04233, 2021a.
Constantinos Daskalakis, Stratis Skoulakis, and Manolis Zampetakis. The complexity of constrained
min-max optimization. In Proceedings of the 53rd Annual ACM SIGACT Symposium on Theory
of Computing, pp. 1466-1478, 2021b.
Damek Davis and Dmitriy Drusvyatskiy. Stochastic subgradient method converges at the rate $O(k{-
1/4})$ on weakly convex functions. arXiv:1802.02988 [cs, math], February 2018.
Jelena Diakonikolas, Constantinos Daskalakis, and Michael Jordan. Efficient methods for struc-
tured nonconvex-nonconcave min-max optimization. In International Conference on Artificial
Intelligence and Statistics, pp. 2746-2754. PMLR, 2021.
9
Published as a conference paper at ICLR 2022
Francisco Facchinei and Jong-Shi Pang. Finite-dimensional variational inequalities and comple-
mentarity problems. Springer Science & Business Media, 2007.
Tanner Fiez and Lillian Ratliff. Gradient descent-ascent provably converges to strict local minmax
equilibria with a finite timescale separation. arXiv preprint arXiv:2009.14820, 2020.
GaUthier GideL Hugo Berard, Gaetan Vignoud, Pascal Vincent, and Simon Lacoste-JUlien.
A variational inequality perspective on generative adversarial networks.	arXiv preprint
arXiv:1802.10551, 2018.
Pontus Giselsson. Nonlinear forward-backward splitting with projection correction. SIAM Journal
on Optimization, 31(3):2199-2226, 2021. doi:10.1137/20M1345062.
Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter.
Gans trained by a two time-scale update rule converge to a local nash equilibrium. Advances
in neural information processing systems, 30, 2017.
M Hirsch and S Vavasis. Exponential lower bounds for finding Brouwer fixed points. In Proceedings
of the 28th Symposium on Foundations of Computer Science, pp. 401-410, 1987.
Cars H Hommes and Marius I Ochea. Multiple equilibria and limit cycles in evolutionary games
with logit dynamics. Games and Economic Behavior, 74(1):434-441, 2012.
Ya-Ping Hsieh, Panayotis Mertikopoulos, and Volkan Cevher. The limits of min-max optimization
algorithms: Convergence to spurious non-critical sets. In International Conference on Machine
Learning, pp. 4337-4348. PMLR, 2021.
Yu-Guan Hsieh, Franck Iutzeler, J6r6me Malick, and Panayotis Mertikopoulos. Explore aggres-
sively, update conservatively: Stochastic extragradient methods with variable stepsize scaling.
arXiv preprint arXiv:2003.10162, 2020.
Chi Jin, Praneeth Netrapalli, and Michael I. Jordan. What is local optimality in nonconvex-
nonconcave minimax optimization? arXiv:1902.00618 [cs, math, stat], June 2019.
Galina M Korpelevich. The extragradient method for finding saddle points and other problems.
Matecon, 12:747-756, 1976.
Puya Latafat and Panagiotis Patrinos. Asymmetric forward-backward-adjoint splitting for solving
monotone inclusions involving three operators. Computational Optimization and Applications,
68(1):57-93, Sep 2017.
Sucheol Lee and Donghwan Kim. Fast extra gradient methods for smooth structured nonconvex-
nonconcave minimax problems. arXiv preprint arXiv:2106.02326, 2021a.
Sucheol Lee and Donghwan Kim. Semi-anchored multi-step gradient descent ascent
method for structured nonconvex-nonconcave composite minimax problems. arXiv preprint
arXiv:2105.15042, 2021b.
Mingrui Liu, Hassan Rafique, Qihang Lin, and Tianbao Yang. First-order convergence theory for
weakly-convex-weakly-concave min-max problems. Journal of Machine Learning Research, 22
(169):1-34, 2021.
Eric V. Mazumdar, Michael I. Jordan, and S. Shankar Sastry. On finding local Nash equilibria (and
only local Nash equilibria) in zero-sum games. arXiv:1901.00838 [cs, math, stat], January 2019.
Panayotis Mertikopoulos, Bruno Lecouat, Houssam Zenati, Chuan-Sheng Foo, Vijay Chan-
drasekhar, and Georgios Piliouras. Optimistic mirror descent in saddle-point problems: Going
the extra (gradient) mile. arXiv preprint arXiv:1807.02629, 2018a.
Panayotis Mertikopoulos, Christos Papadimitriou, and Georgios Piliouras. Cycles in adversarial
regularized learning. In Proceedings of the Twenty-Ninth Annual ACM-SIAM Symposium on
Discrete Algorithms, pp. 2703-2717. SIAM, 2018b.
George J Minty. Monotone (nonlinear) operators in hilbert space. Duke Mathematical Journal, 29
(3):341-346, 1962.
10
Published as a conference paper at ICLR 2022
Maher Nouiehed, Maziar Sanjabi, Tianjian Huang, Jason D Lee, and Meisam Razaviyayn. Solv-
ing a class of non-convex min-max games using iterative first order methods. arXiv preprint
arXiv:1902.08297, 2019.
Christos H Papadimitriou. On the complexity of the parity argument and other inefficient proofs of
existence. Journal of Computer and system Sciences, 48(3):498-532,1994.
Barak A Pearlmutter. Fast exact multiplication by the hessian. Neural computation, 6(1):147-160,
1994.
Boris T Polyak. Introduction to optimization. Optimization Software New York, 1987.
Hassan Rafique, Mingrui Liu, Qihang Lin, and Tianbao Yang. Non-convex min-max optimization:
Provable algorithms and applications in machine learning. arXiv:1810.02060 [cs, math], January
2019.
R. T. Rockafellar and R. J.-B. Wets. Variational analysis, volume 317. Springer Science & Business
Media, 2009.
R Tyrrell Rockafellar. Monotone operators and the proximal point algorithm. SIAM journal on
control and optimization, 14(5):877-898, 1976.
Ralph Tyrell Rockafellar. Convex analysis. Princeton University Press, 1970.
M. V. Solodov and P. Tseng. Modified projection-type methods for monotone variational inequali-
ties. SIAM Journal on Control and Optimization, 34(5):1814-1830, 1996.
Mikhail V Solodov and Benar F Svaiter. A hybrid projection-proximal point algorithm. Journal of
convex analysis, 6(1):59-70, 1999.
Chaobing Song, Zhengyuan Zhou, Yichao Zhou, Yong Jiang, and Yi Ma. Optimistic dual extrap-
olation for coherent non-monotone variational inequalities. arXiv preprint arXiv:2103.04410,
2021.
Gerald Teschl. Ordinary differential equations and dynamical systems, volume 140. American
Mathematical Soc., 2012.
P. Tseng. A modified forward-backward splitting method for maximal monotone mappings. SIAM
Journal on Control and Optimization, 38(2):431-446, 2000.
Junchi Yang, Negar Kiyavash, and Niao He. Global convergence and variance-reduced optimization
for a class of nonconvex-nonconcave minimax problems. arXiv preprint arXiv:2002.09621, 2020.
Zhengyuan Zhou, Panayotis Mertikopoulos, Nicholas Bambos, Stephen Boyd, and Peter W Glynn.
Stochastic mirror descent in variationally coherent optimization problems. In I. Guyon, U. V.
Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett (eds.), Advances in
Neural Information Processing Systems, volume 30. Curran Associates, Inc., 2017.
11
Published as a conference paper at ICLR 2022
A Preliminary definitions
Notationally We will use [X[` B max{0, X} throughout. We additionally recall some standard defini-
tions and results and refer to Bauschke & Combettes (2017); Rockafellar (1970)) for further details.
An operator or set-valued mapping A : ‘n * ’d maps each point X P ’n to a subset Ax of ’d. We
will use the notation ApXq and AX interchangably. We denote the domain of A by
domA B tX P ’n | AX ‰ Hu,
its graph by
gph A B tPx,yq P ’n X ’d | y P Ax},
and the set of its zeros by zerA B tX P ’n | 0 P AXu. The inverse ofA is defined through its graph:
gph AT B tPy, xq | (x,y) P gph A}. The resolvent of A is defined by Ja B (id ' A)´1, where id
denotes the identity operator.
Definition A.1 ((co)monotonicity Bauschke et al. (2020)). An Operator A : ’n * ’n is said to be
ρ-monotone for some ρ P ’, if for all (x,yq, (x1, y1q P gphA
ρ}X - X 1}2 ≤ Xχ - X 1,y - y 1y,
and it is said to be ρ-comonotone if for all (x,yq, (x1, y1q P gphA
ρ}y - y 1}2 ≤ Xχ - X1,y - y'〉.
The operator A is said to be maXimally (co)monotone if its graph is not strictly contained in the
graph of another (co)monotone operator.
We say that A is monotone if it is 0-monotone. When P < 0, ρ-comonotonicity is also referred to as
∣ρ | -cohypomonotonicity.
Definition A.2 (Lipschitz continuity and cocoercivity). Let D J ’n bea nonempty Subset of ’n. A
SingIe-valued operator A : D → 'n is said to be L-LiPschitz continuous if for any χ, χ1 P D
}Ax — Ax 1} ≤ L}X — X1},
and β-cocoercive if
β}Ax — Axz}2 WXX — X1,Aχ — Aχ八〉.
Moreover, A is said to be noneXpansive if it is 1-Lipschitz continuous, and firmly noneXpansive if it
is 1-cocoercive.
The resolvent operator JA is firmly nonexpansive (with dom JA “ ’n) if and only ifA is (maximally)
monotone.
The following lemma plays an important role in our convergence analysis.
Lemma A.3. Let A : ’n → ’n denote a single valued operator. Then,
(i)	A is 1-Lipschitz if and only if T “ id — A is 1{2-cocoercive.
(ii)	IfA is L-Lipschitz, then T “ id — ηA, η P (0, 1{Lq, is (1 — ηLq-monotone, and in particular
}Tu — Tv}》(1 — ηLq}u — V} forall u, V P 'n.
Proof. The first claim follows directly from (Bauschke & Combettes, 2017, Prop.4.11). That T is
strongly monotone is a consequence of the Cauchy Schwarz inequality and Lipschitz continuity of
A:
XTv — Tu, v — u〉“ }v — u}2 — ηXAv — Au, v — u〉》(1 — ηL)}v — u}2.
In turn, the last claim follows from the Cauchy-Schwarz inequality.	□
B	Proofs and further results
B.1 Proofs of Section 3
12
Published as a conference paper at ICLR 2022
Proofof Theorem 3.1. Let H “ id — YkF. By Step 1.1 Hzk P Zk ' YkAzk. Therefore,
YpHzk — Hzkq P Azk + FZ	(B.1)
In what follows we will show that Algorithm 1 is equivalent to taking a forward-backward step
followed by a correction step. Consider the updates
zk B (id + YkAq´1'Z — γkF/),	(B.2)
Z'1 “(1 ´ λkqZ + λk∏Dk(Zq, where Dk b !W |〈HZ — HZ,zk — w〉》Y}H^k — Hzk}2).
Note that
XHZ — Hzk, Z — zky + Y}Hf — Hzk}2 > (1 + Yq}Hzk — Hzk}2	(B.3)
where in the inequality Lemma A.3(i) was used. Hence, by (B.3) the stepsize αk is positive and
bounded away from zero. Moreover, if Z P Dk, then from (B.3) we may conclude that} Hk—HZ} ≤
0 which implies that the generated sequence remains constant and zk P Zer T (cf. (B.1)).
The projection onto Dk for any v R Dk is given by
X zk — V, Hzk — Hzk y— δk} Hzk — Hzk }2
∏Dk(Vq = V + ----------Q	丁Yi 2-----------(HzC — Hzkq
} Hzk — Hzk }2
Moreover, (B.1) together with Assumption I(iii) at zk yields
5xHz — Hz, Z — z<〉》γp2}Hz — Hz}22Y2}Hz — Hz}2,	(B.4)
thus ensuring z< P S< J Dk. The projection onto Dk is then given by ∏d兀(Zc) “ Z + αk(Hk — Hz),
where αk is as in step 1.2.
Finally, since the projection ΠDk is firmly nonexpansive, it follows from (Bauschke & Combettes,
2017, Cor. 4.41) that the mapping (1 — λkqid + λk ΠDk is λk{2-averaged. Consequently, we may con-
clude that (ZqkPN is Fejer monotone relative to S< (Bauschke & Combettes, 2017, Prop. 4.35(iii)).
That is for all z‹ P S‹
}zk'1 — z<}2 & }Zk — z<}2 — λk(2 — λkqak}Hz — Hzk}2.
(B.3)	≤ }Zk — z<}2 — Y}Hz — Hzk}2,	(B.5)
where εk b λk(2—λc)(与 +δc)2. The convergence rate in (3.1) is obtainedby telescoping (B.5). Since
liminfk_8 εk > 0, (Y2}Hz — Hzk}2q卜PN converges to zero. Moreover, (}z — z<}2q卜PN converges
and the sequence (ZkqkPN is bounded. Since Yk is bounded, and F and the resolvents (id + YkA)t are
Lipschitz continuous (cf. (Bauschke & Combettes, 2017, Cor. 23.9)), so is their composition. Hence,
(zk qkPN is also bounded. Let (zkq kPK be a subsequence converging to some z P ’n. Combined with the
fact that (J}Hk — Hz }2q左 N converges to zero, we may conclude from (B.1) along with (Bauschke
Yk	kPN
& Combettes, 2017, Prop. 20.38) and Lipschitz continuity of F that Z P Zer T. Finally, if in addition
Y “ limsupk—g Yk < 1{L, then (1 — YLq}zk — z} ≤ }Hzk — Hzk} (invoke Lemma A.3(ii)). There-
fore, (}zk — z}qkPN converges to zero, which in turn implies that a subsequence (ZkqkPK converges
to a point z1 iff so does the subsequence (zk q卜PK1. Hence, (Zk qkPK also converges to z P Zer T. Conse-
quently, if Assumption I(iii) holds at all of the zeros of T, i.e., ifS‹ “ ZerT, then the second claim
follows by invoking (Bauschke & Combettes, 2017, Thm. 5.5).	□
Proof of Corollary 3.2 (Constant stepsize). The proof of convergence was already given prior to
the statement of the corollary. It remains to derive (3.3). By Assumption I(iii) and owing to 1{2-
cocoercivity of H (cf. Lemma A.3(i))
X Zk — z *, HZk — Hzk〉“〈Zk — z *, HZk — Hzk〉+ X Zk — Zk, Hzk — Hzk〉
(B.4)	≤ —(2 + δkq}HZ — HZ}2.	(B.6)
Yk
Therefore, provided that α > 0 we have
}Zk'1 — z*}2 “ }Zk — z*}2 + <02}hZ — HZ}2 + 2αχzk — z<, HZ — Hzky
(B.6) ≤ }Zk — z*}2 — α(2(2 + Yq — aq}hZ — hZc}2.
Telescoping the above inequality yields the claimed inequality.	□
13
Published as a conference paper at ICLR 2022
B.2 Convergence results and proofs of Section 4
The convergence results for (CurvatureEG+) are provided in the next corollary where ρ in Assump-
tion I(iii) is allowed to take potentially larger values provided that P > ´´≠. Note that owing to the
lower bound on γk (cf. Lemma 4.1(i)), the weak MVI assumption in the corollary is always satisfied
if ρ P (—ντ{2L, 8), however, in practice Yk may take larger values.
Corollary B.1. Suppose that Assumptions I(i) and I(ii) hold, and consider the sequences Pz)kpN,
(Zk)kPN generated by (CUrVatureEG+). Suppose that Assumption I(iii) holds for some P P ’
satisfying Yk	'	2ρ	>	0,	and let	δk	P	(´Y√2,ρS,	λk	P	(0,2),	Hminfk→8 λk(2	—	λk)	>	0,	and
liminfk_80k ' y√2) > 0. Then,
(i) The SeqUence (}Zk — Z}2)kPN vanishes;
5)(Zk qkPN,(ZqkPN are bounded, and have the same limit points belonging to zer T;
(iii) if in addition S< “ Zer T, then (Z)kpn，(Zk)kPN both converge to some Z< P Zer T.
Moreover, ifZ, Zk → Z< P Zer T (as is the case in B.1(iii)), and F is continuously differentiable, then
eventually the backtrack will never be invoked.
Proof. Observe that in the proof of Theorem 3.1 1-Lipschitz continuity of YkF is only used at the
generated points Zk and Z (see (B.3)), and is thus ensured by the linesearch Algorithm 2. Therefore,
it is easy to see that ɑk is positive and bounded away from zero provided that P > —γk{2, see (B.3).
Moreover, since Yk}FZk 一 Fz} < ν}Zk — Z}, arguing as in LemmaA.3(ii) We obtain }HZk — Hzk}》
(1 — ν)}Zk — Z}. Hence, it follows from (B.5) that
}Zk'1 — Z*}2 ≤ }Zk — z<}2 — εkp!≠}Zk — zk}2,
Yk
By telescoping the inequality and noting that Yk is bounded, We obtain XkPN }Zk — Z}2 < 8,
implying B.1(i). Noting this and arguing as in the last part of the proof of Theorem 3.1 establishes
B.1 (ii), B.1 (iii). The last claim is the direct consequence of Lemma4.1 (ii).	□
Proof of Lemma 4.1 (LipschitZ constant backtracking). 4.1(i): Since F is L-Lipschitz continuous
the linesearch would terminate in finite steps. Either Yinit satisfies the condition, or else the back-
track procedure is invoked, which in turn implies the previous candidate Y{τ should have violated
the condition leading the the claimed lower bound.
4.1 (ii): Since the resolvent (id'YA)´1 and F are Lipschitz continous, so is their composition. Hence,
GY(Zk) → GY(Z‹). Furthermore, by definition Z‹ — YFZ‹ P GY(Z‹) ` YA(GY(Z‹)). Consequently,
using monotonicity of A at GY(z<) and Z<, and that — Fz< P Az< yields 0 WxZ< — YFz< — Gy(z<) '
FZ‹, GY(Z‹) —Z‹y “ — }Z‹ — GY(Z‹)}2. Thus GY(Z‹) “ Z‹. Using the fact that both (GY(Zk))kPN and
(Zk)kPN converges to Z‹ P Zer T:
..}F (G y( Ziyq — Fz}
k _8	} G y( zk) - zk}
& lzmIUp「“lip f (z *)“} JFp <)}，
where (Rockafellar & Wets, 2009, Thm. 9.7) was used. The claim follows from continuity of JF
and the fact that (Z)女PN converges to Z<.	□
B.3 Proofs of Section 3.2
To prove the lower bound we introduce the following unconstrained bilinear minimax problem with
an unstable critical point.
Example 5: Consider the following minimax problem:
b
minimiZe maximiZe f(x, y) :“ axy ' ɔ( x2 — y2),	(B.7)
xPR	yPR	2
where b < 0 and a > 0.
14
Published as a conference paper at ICLR 2022
Proof of Theorem 3.4. The associated operator of Example 5 can easily be computed,
Fz “ pay ` bx, by ´ axq,	(B.8)
where z “ px, yq. In this particular case, both L and ρ turn out to be constants. By simple calculation
we have,
} JF P Z q} “ a a2 + b2, P = 2 b ,2	(B.9)
a2 ` b2
where } ∙ } is the spectral norm. Since the norm of the Jacobian is constant it equates the global
Lipschitz constant, L “ }JFpzq}.
By linearity of F, one step of (EG+) is conveniently also a linear operator. Specifically,
with
T :“
(1-a q a 2' b (´ɑ ʌ/ a 2' b2 `ɑ b ' b)
a2' b 2
aα ´ ?a2'b2 ´2b)
a2' b 2
aa( ʌ/ a 2' b 2´2 b)
a 2' b 2
(1-α q a2' b (´ɑ Na 2' b2 `ɑ b ' b)
a2 ' b 2
(B.10)
We know that a linear dynamical system is globally asymptotically stable if and only if the spectral
radius of the linear mapping is strictly less than 1.
Let λ1, λ2 be the eigenvalues of T. Then the spectral radius is the largest absolute value of the
eigenvalues. For T this becomes,
(2(α ´ i)α + ιqa2 ´ 2α(α + iqb' Na2 + b2 ´ b) + b2
max ∣λj “ ∖ -
iPti,2u
a2 + b2
(B.ii)
So We can ask what C in P “ 一 L needs to be for the sequence PZk)kPN to converge. Solving for C in
this equality with maxi ∣λi | < 1, we obtain,
provided that we pick
(B.12)
(B.13)
Equation (B.13) provides a specification for Example 5. As long as (B.12) is satisfied, (EG+) is
guaranteed to converge for γk “ 1{L. On the other hand, since (B.10) is a linear system, we simulta-
neously learn that picking C any larger would imply non-convergence through maxi ∣λi |21 (given
z0 ‰ 0). We can trivially embed problem (B.10) into a higher dimension to generalize the result.
Noting that C “ ´p L completes the proof.	□
We provide Mathematica code to verify each step of the above proof.1
C Toy examples
In the following appendix, L denotes the Lipschitz constant of F restricted to the constraint set and
P is the parameter of the weak MVI (Assumption I(iii)) when restricted to the constraint set. This
restriction of the definitions is warranted, since zk remains within the constraint set in all simulations,
while Zk is guaranteed to stay within by definition of Step 1.1 in Algorithm 1 (and likewise for all
other considered method treating problem (2.1)).
All computer-assisted calculations can be found in the supplementary code.1
C.1 Constructing a PolarGame (Definition 1)
Recall Definition 1 which considers a vectorfield F : Rn → Rn with limit cycles at r P {c 1,..., Ck U
where Ci ‰ 0 for all i P rks. Such a vectorfield can be constructed for n “ 2 by departing from the
1The supplementary code can be found at https://github.com/LIONS-EPFL/weak-minty-code/.
15
Published as a conference paper at ICLR 2022
Figure 5: We can construct the desired properties in polar coordinates pr, θq and subsequently transform
it into a vectorfield in cartesian coordinates px,yq. This is illustrated by a PolarGame with attracting limit
cycles at radius }z} “ 1 and repellant limit cycle at }z} “ 3{4 for the associated operator Fz as indicated
in red and blue respectively.
(a) a “ 1
(b) a “ 3{4
(c) a “ 1{3
Figure 6: Example 3 for different values of a (and thereby different values of ρ). Note that even extragra-
dient may escape the limit cycles even though P V 0. This is not in conflict with the negative results of
Hsieh et al. (2021) since the stepsize is not diminishing. However, in the general case even extragradient
with fixed stepsize will not converge as shown by the lower bound in Theorem 3.4.
following dynamics in polar coordinates,
B “一 a ∙ rptq ∏(rptq ' ciq ∙ Prptq ´ ciq
i“1
(C.1)
Bθ
Bt “—b ∙ rptq,
with a, b ‰ 0. Transforming this dynamics into cartesian coordinates yields the desired vectorfield,
F, while subsequently integrating with respect to x andy yields the two potentials associated with the
two players. Note that the roots {—ciUJk=I for the polynomial defining r are not strictly necessary for
showing existence of limit cycles, but leads to a simpler form for Fz. We illustrate the construction
in Fig. 5.
Proposition 1. Let Fz “ px9, y9q be the evolution in cartesian coordinates of the associated vectorfield
in polar coordinates defined by (C.1). Then the only stationary point of F is at the origin p0, 0q and
there exists a limit cycle at r “ ci for all i P rks.
Proof. Let r “ ʌ/X2 + y2. It is easy to see from (C.1) that the only stationary point is at r = 0. By
construction, r9 is a polynomial with roots ci for all i P rks, so any trajectory starting on the circle
defined by r “ ci remains in that set. However, θ is strictly nonzero. As a consequence Fz is nonzero,
so r “ ci must define a limit cycle, which proofs the claim.	□
16
Published as a conference paper at ICLR 2022
(b) Example 5 (ρ “ 1{3L)
Figure 7: In (a) we observe that all algorithms converge, despite F having an attracting limit cycle in
Example 4. However, note that in the stochastic setting, where diminishing stepsize is required, SEG does
not converge to the critical point (see Fig. 4a). In (b) we demonstrate that when P “ 一1∕3l, picking
αk V 1∕3 for (CEG+) is necessary for convergence in general. See Section 6for the experimental setup.
(a) Example 4
3Ba0B
C.2 Proof for properties of Example 3
The operator F : R2 → R2 defined in Example 3 is obtained by constructing the associated dynamics
in polar coordinates,
“ ´a -rp tq -Pr p tq + 1q ∙P rp tq — 1q ∙P rp tq + 3{4q ∙P rp tq ´ 3{4q
(C.2)
“ ´rptq.
This can easily be verified by a change of variables. From Proposition 1 it then follows, that there
must exist a limit cycle at }z} “ 1 and }z} “ 3{4. To verify the conditions on ρ we compute the
closed form solution to ρ and L in Mathematica:
⑴ F	I WP have C _ _ ^0126 d L _ ?2538096?7^^9+702469896"
(i)	For a _ 1 We have ρ —	1050977 and L —	20000
(ii)	For a = 3∕4we have C =	602112 and L = ?7614288 ?63^WT+63502290655I
(ii)	For a — /4 we have P —	16798825 and L —	80000
(iii	) F	1∕3 WP have c ——328 d L - ?2538096?7^^9+734469896"
Uii) For a — ∕3 we have P — 9439585 and L —	60000
It can easily be verified that the stated conditions for P in Example 3 are met for the values above.
This completes the proof.
We provide Mathematica code verifying the construction of F and the closed form solutions to L
and P.
C.3 Proof for properties of Example 4
Under the definitions of P and L in Appendix C, we claim that the origin P0, 0q in (GlobalForsaken)
is a global Nash equilibrium and satisfies Assumption I(iii) with P > —1/2L.
To verify that P0, 0q is indeed a global Nash equilibrium we need to check that the solution cannot
be unilaterally improved. In other words, the solution should coincide with Px‹, y‹q where
x‹ — arg min φP x, 0q
x
y‹ — arg max φP0, yq.
y
(C.3)
17
Published as a conference paper at ICLR 2022
We can easily verify this with Minimize in Mathematica, since the functions are polynomial for
which a closed form solutions to the global optimization problem will be returned.
To find ρ for z‹ “ p0, 0q we solve the global minimization problem,
minimize (XF： Z — Z<y
Z	} Fz }2
(C.4)
for which a closed form solution can be found with Mathematica, which when numerically evaluated
is approximately —0.119732.
We need to compute L to ensure P > —1 * * * * * * * IX∕2l. In our case of convex constraints, C, We have that
L “ SupZpc }JF(Zq} where } ∙ } denotes the spectral norm (Rockafellar & Wets, 2009, Thm. 9.2
and 9.7). Under our constraint }z}g ≤ %, this can similarly be computed in closed form, yielding
L = b2 (9409 ?5972W+74125591)/2835. So — 2L « —0.165432 which satisfy the condition P > — 2L.
This completes the proof.
Proposition 2. Let F be the associated operator of φ in (GlobalForsaken) defined as FZ “
(VXφ(见yq, 一%φ(羽yqq. Define the radius as r “ }z}. Then, Fz has a stable critical point at the
origin (0,0), at least one attracting limit cycle in the region defined by ʌ/3∕2 < r < 2 and at least
one repellant limit cycle within r ≤ ʌ∕3∕2.
Proof. We follow a similar argument as in Hsieh et al. (2021, D.2). We can compute the associated
operator F ,
4X5	4X3	2X
万-----3" + τ + y
4y5	4y3	2 y .
一X ' ^	3^ ' T/
With a change of variables into polar coordinates (r, θ) we get that r = 'x2 + y2 evolves as,
r = — 42r '9r4 cos(4θ) — 14r2 cos(4θ) + 15r4 — 42r2 + 28).
(C.5)
(C.6)
When r “ a3∕2 this reduces to r “ 3 CosP?'5 and we observe that r > 0 for any θ. Likewise for
r = 2, we have that r “ — 24- (22 cos(4θ)'25) which implies r < 0. Since there is no stationary point
in the region S “ {(r, θ) : a3∕2 < r < 2} it then follows from the POinCare-BendixSOn theorem
(Teschl, 2012, Thm. 7.16) that there must exist at least one attracting limit cycle in S. Further, it
is easy to see that (0, 0q is a critical point and that it is stable by inspection of the Jacobian JF(Zq.
Since S is trapping, it follows from POinCare-Hopf index theorem, that there must exist a repellant
limit cycles in the region defined by r < ʌ∕3{2. This completes the proof.
□
C.4 Proof of properties for (Hsieh et al., 2021, Example 5.2)
This section considers (Hsieh et al., 2021, Example 5.2) on the constraint domain D = tZ P ’n |
}z} 8 ≤ 3∕2}. We show that the unique critical point Z< does not satisfies the weak MVI for P > —1/2L
even when restricted to the constraint setZ P D. We restate the example with the additional constraint
for convenience.
Example 6: (Hsieh et al., 2021, Example 5.2)
minimize maximize φ(X, yq := X(y — 0.45q + ψ(Xq — ψ(yq,	(Forsaken)
IX l≤3{2	| y l≤3{2
where ψ( Z) = 1Z2 — 2 Z4 + 1Z6.
By using Mathematica, we can obtain a closed form solution of the Lipschitz constant L of F re-
stricted to the constraint set, which we find to be L =* ʌ/2'1089 ?801761 + 993841). Math-
ematica can solve approximately for the critical point, yielding Z‹= (0.0780267, 0.411934). To
find ρ we want to globally minimize ρ(Z) := XFZF´Z < for Z P D. Mathematica finds the candi-
date Z1 = (—1.01236, —0.104749) for which P(Z1) = —0.477761. So P must be at least this small,
i.e. ρ < —0.477761. Since —1/2L « —0.04, this implies that P < —1/2l. See Forsaken.nb for
Mathematica-assisted computations.
18
Published as a conference paper at ICLR 2022
Figure 8: Demonstration of algorithms on (Hsieh et al., 2021, Example 5.2). Only (CurvatureEG+) con-
verges to the critical point, while the remaining methods, CEG, (CEG+) with ak = 1/2, and AdaptiveEG+
converges to an attracting limit cycle. See Section 6 for further specification of the algorithms.
This rules out convergence guarantees for both (CEG+) and AdaptiveEG+ (Algorithm 1), which is
supported by the simulation in Figure 8. However, as observed, (CurvatureEG+) converges in the
simulations.
19