Table 1: kNN-TAPT, which augments the Task Adaptive PreTraining (TAPT) setting of Gururanganet al. (2020), harnesses the in-context bias and improves SentEval sentence similarity scores.
Table 2: Impact of model size and regular pretraining steps on the Natural Questions F1 score ofkNN-Pretraining.
Table 3: Zero-shot accuracy scores on several GLUE tasks of a kNN-Pretrained model versus 3baselines that trained regularly on the same data.
