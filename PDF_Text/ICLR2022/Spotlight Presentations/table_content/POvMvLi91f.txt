Table 1: IQM normalized average performance (training stability) across 17 games, with 95% CIs in parenthe-sis, after 6.5M gradient steps for the 1% setting and 12.5M gradient steps for the 5%, 10% settings. Individualperformances reported in Tables F.4-F.9. DR3 improves the stability over both CQL and REM.
Table 2: Performance of CQL, CQL + DR3 after 2M and 3M gradient steps with a learning rate of3e-4 for the Q-function averaged over 3 seeds. This is training for 6x and 9x longer compared to CQL defaults.
Table A.1: Normalized interquartile mean performance with 95% stratified bootstrap CIs [3] across 17 Atarigames of REM, REM + ∆0(Φ) (Stop gradient in DR3), REM + DR3 after 6.5M gradient steps for the 1%setting and 12.5M gradient steps for the 5%, 10% settings. Observe that REM + ∆0(φ) also improves over thebase REM method significantly, by about 130%, even though ∆0 (φ) is generally comparable and somewhatworse than the DR3 regularizer used in the main paper.
Table A.2: Performance of CQL, CQL + DR3 after 2M gradient steps on the Franka Kitchen domainsaveraged over 3 seeds. This is training for 6x longer compared to CQL defaults. Observe that CQL + DR3outperforms CQL at 2M steps, indicating is efficacy in preventing long term performance degradation.
Table E.1: Hyperparameters used by the offline RL Atari agents in our experiments. FollowingAgarwal et al. [2], the Atari environments used by us are stochastic due to sticky actions, i.e., thereis a25% chance at every time step that the environment will execute the agents previous action again,instead of the new action commanded. We report offline training results with same hyperparametersover 5 random seeds of the offline dataset, game simulator and network initialization.
Table F.1: Normalized interquartile mean (IQM) final performance (last iteration return) of CQL, CQL +DR3, REM and REM + DR3 after 6.5M gradient steps for the 1% setting and 12.5M gradient steps for the 5%,10% settings. Intervals in brackets show 95% CIs computed using stratified percentile bootstrap [3]Data	CQL	CQL + DR3	REM	REM + DR31%	44.4 (31.0, 54.3)	61.6 (39.1, 71.5)	0.0 (-0.7, 0.1)	13.1 (9.9, 18.3)5%	89.6 (67.9, 98.1)	100.2 (90.6, 102.7)	3.9 (3.1, 7.6)	74.8 (59.6, 84.4)10%	57.4 (53.2, 62.4)	67.0 (62.8, 73.0)	24.9 (15.0, 29.1)	72.4 (65.7, 81.7)Table F.2: Performance of DR3 when applied in conjunction with BRAC [49]. Note that DR3attains a larger final performance (at the end of 2M steps of training) as well as a higher averageperformance (i.e. stability score) across all iterations of training.
Table F.2: Performance of DR3 when applied in conjunction with BRAC [49]. Note that DR3attains a larger final performance (at the end of 2M steps of training) as well as a higher averageperformance (i.e. stability score) across all iterations of training.
Table F.4: Mean evaluation returns per Atari game across 5 runs with standard deviations for1% dataset. The coefficient for DR3 is 0.03 with a CQL coefficient of 1.0. The average performanceis computed over 20 checkpoints spaced uniformly over training for 100 iterations where 1 iterationcorresponds to 62,500 gradient updates.
Table F.5: Mean evaluation returns per Atari game across 5 runs with standard deviations for5% dataset. The coefficient for DR3 is 0.03 with aCQL coefficient of 0.1. The average performanceis computed over 20 checkpoints spaced uniformly over training for 200 iterations where 1 iterationcorresponds to 62,500 gradient updates.
Table F.6: Mean returns per Atari game across 5 runs with standard deviations for initial 10%dataset. The coefficient for DR3 is 0.03 with a CQL coefficient of 0.1. The average performance iscomputed over 20 checkpoints spaced uniformly over training for 200 iterations.
Table F.7: Mean returns per Atari game across 5 runs with standard deviations for 1% dataset.
Table F.8: Mean returns per Atari game across 5 runs with standard deviations for the 5%dataset. The coefficient for DR3 is 0.001 while we use a multi-headed REM with 200 Q-heads [2].
Table F.9: Mean returns per Atari game across 5 runs with standard deviations for initial 10%dataset. The coefficient for DR3 is 0.001 while we use a multi-headed REM with 200 Q-heads [2].
