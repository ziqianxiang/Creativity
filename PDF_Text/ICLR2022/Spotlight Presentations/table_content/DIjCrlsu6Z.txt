Table 1: CMNIST		Table 2: CelebA-GH					Z1 acc.	Z2 acc.	Z1 acc.		Z2 acc.	FID JVanilla	90.2	14.3	Vanilla	88.4	16.8	38.5wx ∖ w1 (MLDG)	94.9	91.1	wx ∖ w1 (MLDG)	90.9	53.0	46.2wx ∖ w1 (TRM)	89.2	96.2	wx ∖ w1 (TRM)	92.2	56.5	39.8wx ∖ w1 (Fish)	93.9	98.0	wx ∖ w1 (Fish)	88.8	42.9	43.4IS (Oracle)	90.0	100	IS (Oracle)	89.1	40.6	44.3wx ∖ w1 (Oracle)	94.9	100	wx ∖ w1 (Oracle)	93.7	57.4	39.7we set λd = 0.9 and λb = 0.8. Our goal is to transfer the digit color (Z1) while leaving the backgroundcolor (Z2) invariant. (b) CelebA-GH: We construct the CelebA-G(ender)H(air) dataset based on thegender and hair color attributes in CelebA (Liu et al., 2015). CelebA-GH consists of 110919 imagesresized to (3, 128, 128). In CelebA-GH, domain A is non-blond-haired males, and the domain B isblond-haired females. Our goal is to transfer the facial characteristic of gender (Z1) while keeping thehair color (Z2) intact.
Table 3: Test accuracy on visual domain adaptation benchmarksSource Target	MNIST MNIST-M	SVHN MNIST	MNIST SVHN	DIGITS SVHN	SIGNS GTSRB	CIFAR STL	STL CIFARSource-Only	51.8	75.7	34.5	85.0	74.7	68.7	47.7ADDA	89.7	78.2	38.4	86.0	90.6	66.8	50.4CyCADA	-	82.8	39.6	-	-	-	-VADA	77.8	79.0	35.7	90.3	93.6	72.4	53.1VADA + IW	71.2；	87.1↑	34.5 ；	90.7 ↑	95.4↑	74.0↑	53.8↑VADA + wx ∖ w1	79.1	88.0↑	40.5↑	90.6↑	95.2↑	74.5 ↑	54.1↑6	Orthogonal Classifier for Fairnes sWe are given a dataset D = {(xt, yt, ut)}tn=1 that is sampled iid from the distribution pXYU, whichcontains the observations x ∈ X, the sensitive attributes u ∈ U and the labels y ∈ Y. Our goal is to learn aclassifier that is accurate w.r.t y and fair w.r.t u. We frame the fairness problem as finding the orthogonalclassifier of an “totally unfair” classifier w1 that only uses the sensitive attributes u for prediction. Wecan directly get the unfair classifier w1 from the dataset statistics, i.e., w1 (x)y = p(Y = y∣U = u(x)).
Table 4: Accuracy v.s. Fairness (Adults)	Acc.↑	△dp 1	△EO 1Vanilla	84.5	0.19	0.20LAFTR (γ = 0.1)	84.2	0.14	0.09LAFTR (γ = 0.5)	84.0	0.12	0.07L-MIFR (γ = 0.05)	81.6	0.04	0.15L-MIFR (γ = 0.1)	82.0	0.06	0.16ReBias (γ = 100)	84.3	0.15	0.11ReBias (γ = 50)	84.4	0.17	0.16wx ∖ w1	81.6	0.12	0.12Table 5: Accuracy v.s. Fairness (German)	Acc.↑	△DP 1	△EO 1Vanilla	76.0	0.19	0.33LAFTR (γ = 0.1)	73.0	0.11	0.17LAFTR (γ = 0.5)	72.7	0.11	0.19L-MIFR (γ = 0.1)	75.8	0.10	0.21L-MIFR (γ = 0.05)	75.6	0.08	0.18ReBias (γ = 100)	73.0	0.07	0.17ReBias (γ = 50)	75.0	0.10	0.20wx ∖ w1	75.4	0.09	0.18
Table 5: Accuracy v.s. Fairness (German)	Acc.↑	△DP 1	△EO 1Vanilla	76.0	0.19	0.33LAFTR (γ = 0.1)	73.0	0.11	0.17LAFTR (γ = 0.5)	72.7	0.11	0.19L-MIFR (γ = 0.1)	75.8	0.10	0.21L-MIFR (γ = 0.05)	75.6	0.08	0.18ReBias (γ = 100)	73.0	0.07	0.17ReBias (γ = 50)	75.0	0.10	0.20wx ∖ w1	75.4	0.09	0.187	Related WorksDisentangled representation learning Similar to orthogonal random variables, disentangled represen-tations are also based on specific notions of feature independence. For example, Higgins et al. (2018)defines disentangled representations via equivalence and independence of group transformations, Kim &Mnih (2018) relates disentanglement to distribution factorization, and Shu et al. (2020) characterizesdisentanglement through generator consistency and a notion of restrictiveness. Our work differs in twokey respects. First, most definitions of disentanglement rely primarily on the bijection between latentsand inputs (Shu et al., 2020) absent labels. In contrast, our orthogonal features must be conditionallyindependent given labels. Further, in our work orthogonal features remain implicit and they are useddiscriminatively in predictors. Several approaches aim to learn disentangled representations in an un-
Table 6: CelebA	Z1 acc.	Z2 acc.	FID JVanilla	75.3	87.0	36.2wX ∖ w1-MLDG	81.8	93.5	35.2wX ∖ w1-TRM	76.3	92.5	33.5wX ∖ w1 -Fish	74.2	93.3	33.1IS-Oracle	733	88.1	36.5wX ∖ w1 -Oracle	84.0	95.2	38.5We show transferred samples for both domains in Fig. 4 on CMNIST and CelebA-GH.
