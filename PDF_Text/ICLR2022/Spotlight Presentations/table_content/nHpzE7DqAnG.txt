Table 1:	Root mean squared error (RMSE) of different methods for node regression; accuracy (%)of different methods for node classification. Top results are boldfaced, all of which are statisticallysignificant. Please see supplementary for standard errors and further details, as well as Figure 1 below.
Table 2:	Accuracy results on the OGB-ArXivdataset. As mentioned in the text, the OGB-ArXiv node features are not generally favorableto boosted tree models. SOTA is taken from theOGB leaderboard.
Table S1:	Mean squared error of different methods for node regression. Top results are boldfaced.
Table S2:	Mean squared error of different methods for different random seeds, which presentsdifferent training and testing splits. Top results are boldfaced.
Table S3:	Accuracy (%) of different methods for node classification. Top results are boldfaced.
Table S4: Ablation study for BGNN with one step of gradient step per iteration.
Table S5: Hyperparameter settings used for EBBS, which are shared across all random seeds/dataset-splits. We emphasize here that all BGNN results (the SOTA model for graph data with tabular nodefeatures) follow the code from https://github.com/nd7141/bgnn, which executes a costlyindependent sweep over 6 hyperparameters for each dataset and for each random seed/dataset-split toachieve the reported performance.
