Table 1: Comparison on BREEDS datasets. Bold and underlined numbers are the best and second best results.
Table 2: Comparison on CIFAR-100datasets. Bold and underlined numbersare the best and second best results.
Table 3: Intra-class few-shot learning results of the comparedmethods on BREEDS datasets.
Table 4: Computational costs on 4 Quadro RTX6000 24G GPUs.
Table 5: Comparison on ∕7ere^ImageNet.
Table 6: The comparison resultson Dialysis-Event dataset.
Table 7: Effects of more shots (all-way)Table 7 and 8 summarize the performance of SCGM-G and SCGM-A, with the strongest baselineANCOR and ANCOR-fc, together with the coarse baseline Coarse+, on Living17 dataset. From17Published as a conference paper at ICLR 2022Method	1-shot	5-shot	10-shot	20-shotCoarse+	79.29±0.65	92.99±0.41	94.33±0.36	95.27±0.31ANCOR	89.23±0.55	94.44±0.36	95.33±0.31	95.90±0.27ANCOR-fc	90.41±0.57	93.84±0.36	94.52±0.32	95.09±0.29SCGM-G	89.72±0.54	94.38±0.37	95.09±0.35	95.52±0.31SCGM-A	90.97±0.55	94.41±0.34	95.11±0.30	95.43±0.28Table 8: Effects of more shots (5-way)Table 7, we observe SCGM-A continuously improves performance as more shots are added, consis-tently outperforms other models, which validate the effectiveness of SCGM framework with varyingnumber of shots. SCGM-G’s performance becomes comparable to ANCOR(-fc) as more shots areadded, due to its simpler architecture, which however is more computationally efficient. Thus it pro-vides a good balance between performance and efficiency. From Table 8, we observe ANCOR andSCGM perform similarly. This is because the task is close to the regular superclass classification,and its performance limit can be easily reached by adding a few more shots. This can be seen fromCoarse+’s results, which become close to other models when there are 20 shots in the support set.
Table 8: Effects of more shots (5-way)Table 7, we observe SCGM-A continuously improves performance as more shots are added, consis-tently outperforms other models, which validate the effectiveness of SCGM framework with varyingnumber of shots. SCGM-G’s performance becomes comparable to ANCOR(-fc) as more shots areadded, due to its simpler architecture, which however is more computationally efficient. Thus it pro-vides a good balance between performance and efficiency. From Table 8, we observe ANCOR andSCGM perform similarly. This is because the task is close to the regular superclass classification,and its performance limit can be easily reached by adding a few more shots. This can be seen fromCoarse+’s results, which become close to other models when there are 20 shots in the support set.
Table 9: Impacts of the number of latent variables r on the performance of SCGM-GTable 9 presents the results of SCGM-G on Living17 by varying the number of latent variables rfrom 50 to 500. As can be seen, the performance of SCGM-G is generally stable and it consistentlyoutperforms Coarse(+) (Table 1) w.r.t. different r. By looking into the details, we observe too small(e.g., 50) or too big (e.g., 500) r may degenerate the performance in the all-way case, which may becaused by slight underfitting and overfitting, respectively. In the 5-way case, small r does not impactperformance obviously, this is because the 5-way case is close to evaluate coarse classification,which does not need exact inference of subclasses. Thus a small number of r is fine (which may notdistinguish all possible subclasses).
Table 10: Impacts of the variance parameter σ2 on the performance of SCGM-GTable 10 presents the results of SCGM-G on Living17 by varying the variance σ2 of subclasses,which resembles the temperature scaling in Eq. (7). As described in Sec. 3.1, in our experiments,We set σ2 = 1 and tune σ2 to adjust the relativity between super- and subclasses, which We foundis empirically effective. From Table 10, we observe σ2 is better to be selected from 0.1 to 0.2, anda too small (e.g., 0.05) or too big (e.g., 0.3) value may degenerate the performance in the all-waycase. This observation is similar to the evaluation of the temperature scaling parameter in MoCo-v2(Chen et al., 2020b). In the 5-way case, the performance is relatively stable w.r.t. different values ofσ2 . Similar to the observation in Appendix D.2, this is because the 5-way case is close to evaluatecoarse classification, which is less impacted by the learning of subclasses.
