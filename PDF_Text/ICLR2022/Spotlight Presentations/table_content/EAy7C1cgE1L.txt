Table 1: Taxonomy of model extraction attacks. We use IND for in-distribution and OOD forout-of-distribution data. The MixMatch attack is the best performing one with very few queries runagainst the ML API and a high accuracy of the extracted model, mainly due to the abundant andefficient usage of the problem domain (i.e., task-specific) data. At the other end of the spectrum isDataFree attack with only synthetic OOD data.
Table 2: Comparison of the attacks against the PoW-based defense. The notation: IND- in-distribution, SYN- Synthetic. IND * denotes limited in-distribution data with additional data generatedusing the Jacobian augmentation. MiXMatch^ uses as many additional unlabeled training examples forthe semi-supervised training as the number of answered queries. The results for Standard, EntropyRev,and WorstCase are the same so we report only Standard. Time PoW is after applying our defense.
Table 3: Comparison of the attacks against the PoW-based defense. (Extended results fromTable 2.) We present the number of required queries, gap, entropy, privacy cost PkNN (as computedfor alternative metrics from Appendix B.6), time before (Time) and after PoW (Time PoW), andaccuracy (ACC) for different datasets and attacks. The results are aligned according to the highestaccuracy achieved by the attacks.
Table 4: Taxonomy of model extraction defenses.
Table 5: Compare computation times (in seconds) of querying the API when only inference isperformed or with the additional computation of the query cost when labeling samples.
