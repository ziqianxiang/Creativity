Table 1: Mean Squared Error (MSE) in the N-body system experiment, and forward time in secondsfor a batch size of 100 samples running on a GeForce RTX 2080 Ti GPU. Results except for EGNNand SEGNN are taken from (Satorras et al., 2021) and verified. Runtimes are re-measured.
Table 2: Performance comparison on the QM9 dataset. Numbers are reported for Mean AbsoluteError (MAE) between model predictions and ground truth.
Table 3: QM9 ablation study to compare SEGNN performances for different (maximum) orders ofsteerable featUre vectors (lf) and attribUtes (la). Models with only trivial featUres are akin to theinvariant EGNN. The method with a fUlly connected graph Uses soft edge estimation (Satorras et al.,2021). Forward time is measUred for a batch of 128 samples rUnning on a GeForce RTX 3090 GPU.
Table 4: Comparison on the OC20 IS2RE task in terms of Mean AbsolUte Error (MAE) betweenmodel predictions and groUnd trUth energy and % of predictions within = 0.02 eV of the groUndtrUth (EwT). NUmbers are taken from the OC20 leaderboard. SEGNNs oUtperform all competitors.
Table C.1: A full ablation study on the performance and runtime of different (maximum) orders ofsteerable features (lf) and attributes (la). The ablation study includes steerable linear convolutions,steerable non-linear convolutions, as well as SEGNN approaches. SEnon-linear++ uses the structuralinformation (velocity) in the two embedding and read-out layers. Performance is measure using theMean Squared Error (MSE).
Table C.2: SEGNN and EGNN performance comparison on the N-body system experiment. Perfor-mance is compared for different number of available training samples, and measured using the MeanSquared Error (MSE). SEGNNs are significantly more data efficient.
Table C.3: Mean Squared Error (MSE) for positional (pos) and force prediction in the gravitationalN-body system experiment, and forward time in seconds for a batch size of 20 samples running on anNVIDIA GeForce RTX 3090 GPU.
Table C.4: Comparison on the validation sets of the OC20 IS2RE tasks. Model selection is doneon those datasets which are conceptually the nearest. We compare the performance for the usage ofdifferent (maximum) orders of steerable features (lf) and attributes (la), as well as the performancefor cutoff radii of 5A and 3A on the OC20 dataset. The case la = 0 and lf = 0 corresponds to ourEGNN implementation. The SElinear corresponds to our implementation as outlined in Alg. 1 andcan be seen as instance of e.g. TFNs Thomas et al. (2018). Runtime numbers are reported for oneforward pass and are measured for a batch of size 8 on a Nvidia Tesla V100 GPU. Higher orders oflf and la in general do not improve results. The Dimenet++ runtime is given as reference.
