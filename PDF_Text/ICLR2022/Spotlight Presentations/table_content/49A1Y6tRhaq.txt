Table 1: Results on image captioning transfer using three fine-tuning dataset sizes. base, +ec, +nldenote training from scratch and pre-training using EC captions and NL captions, respectively.
Table 3: Pearson correlations be-tween different metrics (validation ac-curacy, topographic similarity, emer-gent to natural language translationROUGE_L) and downstream languageTable 2: Ablations on EC game, corpus, and transfer setups. modeling performance (negated per-Standard deviations in parentheses. The language model is plexity)an GRU for last two rows and a Transformer for others.	.
Table 2: Ablations on EC game, corpus, and transfer setups. modeling performance (negated per-Standard deviations in parentheses. The language model is plexity)an GRU for last two rows and a Transformer for others.	.
Table 4: Image captioning results with different pre-training languages or no pre-training.
