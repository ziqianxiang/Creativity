Table 1: Optimization algorithms viewed as steepest descent algorithm w.r.t. the given L2-norms.
Table 2: Hyperparameters for different optimization algorithms in figure 2bMethod	Adadelta	Adagrad	Adam	GN	HIG	RMSprop	SGDb	-512~~	512	-^512^^	128	128	512	512η	0.1	0.1	3∙10-4	-	1	10-4	0.1τ	-	-	-	10-6	10-6	-	-Table 3: Nonlinear oscillators: memory requirements, update duration and duration of the Jacobiancomputation for Adam and HIGOptimizer	Adam	Adam	Adam	HIG	HIG	HIGBatch size	256	512	1024	32	64	128Memory (MB)	11.1	22.2	44.5	169	676	2640Update duration (sec)	0.081	0.081	0.081	0.087	0.097	0.146Jacobian duration (sec)	0.070	0.070	0.070	0.070	0.070	0.070from the [-1, 1] interval, and a batch size of 256. For the optimizers, the following hyperparameterswere used for both the well-conditioned loss and the ill-conditioned loss: Adam η = 0.3; GN hasno learning rate (equivalent to η = 1), τ = 10-4; HIG η = 1.0, τ = 10-6.
Table 3: Nonlinear oscillators: memory requirements, update duration and duration of the Jacobiancomputation for Adam and HIGOptimizer	Adam	Adam	Adam	HIG	HIG	HIGBatch size	256	512	1024	32	64	128Memory (MB)	11.1	22.2	44.5	169	676	2640Update duration (sec)	0.081	0.081	0.081	0.087	0.097	0.146Jacobian duration (sec)	0.070	0.070	0.070	0.070	0.070	0.070from the [-1, 1] interval, and a batch size of 256. For the optimizers, the following hyperparameterswere used for both the well-conditioned loss and the ill-conditioned loss: Adam η = 0.3; GN hasno learning rate (equivalent to η = 1), τ = 10-4; HIG η = 1.0, τ = 10-6.
Table 4: Poisson problem: memory requirements, update duration and duration of the Jacobiancomputation for Adam and HIGOptimizer	Adam	HIGBatch size	-64-	-64-Memory (MB)	1.3	3560Update duration (sec)	0.011	13.8Jacobian duration (sec)	0.010	0.0035b) 4 -IO-23-10-2ω 2 IO-2(ΛO-Iio-2Adampretrained HIG----Adam after HIG6 - 10~3 ⅛IO51.1-IO5 1.2-105 1.3 - IO5
Table 5: Quantum dipole: memory requirements, update duration and duration of the Jacobiancomputation for Adam and HIGOptimizer	Adam	Adam	Adam	HIG	HIGBatch size	256	512	1024	-8-	~~L6~Memory (MB)	460	947	2007	1064	-3039Update duration (sec)	0.40	0.50	1.33	0.42	^060Jacobian duration (sec)	0.39	0.49	1.32	0.40	-033"19Published as a conference paper at ICLR 2022Figure 10: Quantum dipole with Convolutional Neural Network: Experiments with Adam fordifferent learning rates η and batch sizes b.
