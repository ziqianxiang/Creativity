Table 1: A coarse summary of hindsight information matching (HIM) algorithms. The notation follows Section 4.
Table 2: Quantitative evaluation of state-feature distribution matching, measuring Wasserstein-1 distance betweenthe rollout and target distributions. We compare Categorical DT against DT, BC, Meta-BC, and FOCAL. CDTachieves better matching than baselines. See Table 9 in Appendix E.1 for the reward distribution results.
Table 3: State-feature (z-velocity) distribution matching with uni-modal and (synthesized) bi-modal targettrajectories in HalfCheetah environment. Categorical DT matches both uni- and bi-modal trajectories better thanDT and FOCAL, and is comparable to Meta-BC that originally aims to solve multi-task problem.
Table 4: Generalization to unseen target velocity (x-velocity = 0.5, 1.5, 2.5) among training dataset (x-velocity âˆˆ[0.0, 3.0]\{0.5, 1.5, 2.5}; uniformly spaced at 0.1 intervals), which is a popular setting in meta RL/IL. CDTsuccessfully deals with unseen target velocities well, outperforming DT and FOCAL, and is slightly better thanMeta-BC through the offline multi-task SMM evaluation.
Table 5: The results of BDT on the state-feature distribution matching problem (m = 16). While even simpleauto-encoder regularizers sometimes work well, BDT with longer contexts seems to outperform other strategiesand is comparable to CDT or DT (in Table 2). See Appendix E.6 for the full results including m = 1, 4.
Table 6: List of hyperparameters for DT, CDT and BDT. We refer Chen et al. (2021a).
Table 7: A Review of evaluation for distribution matching algorithms.
Table 8: Review of problem settings among offline meta RL, meta IL, and ours. In offline meta RL, the agentsare trained offline and tested with several demonstrations (few-shot), in a fully-offline manner or allowing onlinedata-collection for adaptation. In meta IL, IRL-based methods train the agents online (Yu et al., 2019; Xu et al.,2019; Ghasemipour et al., 2019) while BC-based methods (Finn et al., 2017; Duan et al., 2017) do offline.
Table 9: Quantitative evaluation of reward distribution matching via measuring Wasserstein-1 distance betweenthe rollout and target distributions. We compare Categorical DT and DT. Since it can capture the multi-modalnature of target distributions, CDT matches the distribution better than the original DT.
Table 10: Evaluation on the task rewards; conditioning on the held-out trajectories as done in Section 6. Wecompare the performance between Categorical DT, and DT. DT seems consistently better methods on the taskrewards evaluations, and achieves similar performances to the held-out trajectories (averaged over 5 trajectories).
Table 11: Quantitative evaluation of 2D state-feature (xy-velocities) distribution matching, measuringWasserstein-1 distance. CDT performs better even in the two-dimensional problem.
Table 12: The results of BDT and DT-X variants on the reward distribution matching problem (m = 1, 4, 16).
Table 13: The results of BDT and DT-X variants on the state-feature (x-velocity) distribution matching problem(m = 1, 4, 16).
Table 14: Wasserstein-1 distance between shifted reward distribution and the rollout distributions. CategoricalDT handles the target distribution shifts and matches the distributions better than DT, since CDT is aware ofdistributional information of entire trajectories.
Table 15: Wasserstein-1 distance between shifted state-feature (x-velocity) distribution and the rollout distri-butions. Similar to the case of reward, Categorical DT handles the target distribution shifts and matches thedistributions better than DT.
Table 16: State-feature (x-velocity) distribution matching with synthesized, physically unrealistic target distri-butions generated from scripted Gaussian distributions. We compare Categorical DT and DT. Categorical DTmanages to deal with such unrealistic target matching.
