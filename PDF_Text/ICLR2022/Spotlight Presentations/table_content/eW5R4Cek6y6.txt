Table 1: Comparison of our method to the Top-3 teams of the PGDL competition. Scores shown arecalculated using the Conditional Mutual Information metric, higher is better. DBI*LWM=Davies-Bouldin Index*Label-wise Margin, MM=Mixup Margin and AM=Augment Margin are the pro-posed methods from first place solution by Natekar & Sharma (2020). R2A=Robustness to Aug-mentations (Aithal et al., 2021) and VPM=Variation of the Penultimate layer with Mixup (Lassanceet al., 2020) are the second and third place solutions. Task 4 and Task 5 differ in that Task 4 classi-fiers have batch-norm while Task 5 do not.
Table 2: Comparison of predicting generalization using GAN samples to the Top-3 methods of Jianget al. (2018) (qrt+log, qrt+log+unnorm and moment+log) on DEMOGEN. Overall, ourmethod of predicting generalization using GAN samples outperforms any of the previous solutionby a large margin. The BigGAN+DiffAug appears to be the best performing. ‘—’ means not tested.
