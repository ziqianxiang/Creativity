Table 1: Paired Multi-Bootstrap results for CDA intervention over the base MultiBerts checkpointson Winogender. Accuracy is computed by bootstrapping over all 720 examples, while for bias corre-lation we first compute per-occupation bias scores and then bootstrap over the 60 occupation terms.
Table 2: Unpaired Multi-Bootstrap results comparing CDA-full to CDA-incr on Winogender. Ex-amples are treated as in Figure 1. The “Seeds” column bootstraps only over pre-training seedswhile using the full set of 60 occupations, while the “Examples” column bootstraps over examples,averaging over all pre-training seeds. For all tests we use 1,000 bootstrap samples.
Table 3: Average per-example agreement between model predictions on each task. This is computedas the average “accuracy” between the predictions of two runs for classification tasks, or Pearsoncorrelation for regression (STS-B). We separate pairs of models that use the same pre-training seedbut different fine-tuning seeds (Same) and pairs that differ both in their pre-training and fine-tuningseeds (Diff). HANS (neg) refers to only the anti-stereotypical examples (non-entailment), whichexhibit significant variability between models (McCoy et al., 2020).
Table 4: Unpaired Multi-Bootstrap on Wino-gender bias correlation, comparing pretrainingseed 0 to pretraining seed 1.
Table 5: Expected scores (accuracy), effect sizes, and p-values from Multi-Bootstrap on selectedGLUE tasks. We pre-select the best fine-tuning learning rate by averaging over runs; this is 3e-5for checkpoints at 1M steps, and 2e-5 for checkpoints at 2M pre-training steps. All tests use 1000bootstrap samples, in paired mode on the five seeds for which both 1M and 2M steps are available.
