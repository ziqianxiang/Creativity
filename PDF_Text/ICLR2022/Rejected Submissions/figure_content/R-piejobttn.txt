Figure 1: (a) Multi-arm autoencoder framework pro-posed as the cpl-mixVAE model. Individual armsreceive non-identical noisy copies of given samplesx, i.e. {xa , xb, . . . }, where they all belong to thesame category, to learn mixture representations, i.e.
Figure 2: Interpretable continuous latent traversals of 1-st arm of the cpl-mixVAE framework with twoautoencoders, for MNIST (top) and dSprites (bottom). The discrete variable c is constant for all reconstructionsin the same row.
Figure 3: Categorical assignments for the scRNA-seq datasets. The top row shows confusion matrices ofJointVAE (a.1), CascadeVAE (a.2), and cpl-mixVAE (a.3) trained by |c| = 115, |s| = 2, for the Smart-seq ALM-VISp dataset. The dendrogram on the y-axis shows MG-based hierarchical classification with 115 cell types,suggested by Tasic et al. (2018). The bottom row shows confusion matrices of JointVAE (b.1), CascadeVAE (b.2),and cpl-mixVAE (b.3) trained by |c| = 140, |s| = 2, for the 10X MOp dataset. Cell types on the y-axis aresorted based on a hierarchical classification suggested by Yao et al. (2021). (c) Improvement of the categoricalrepresentation (ACC) of cpl-mixVAE by adding more arms to the multi-arm framework. A-arm’s performancefor A ≥ 2 is compared with the baseline 1-arm, JointVAE, across 3 randomly initialized runs.
Figure 4: Continuous latent traversal analysis for two excitatory cell types: (I) “L5 NP” and (II) “L6 CT”,in different brain regions. For each type, the traversal is color-mapped to a normalized reconstructed geneexpression value (colorbar) as a function of the state variable for 3 gene subsets: marker genes (MG), immediateearly genes (IEG), and housekeeping genes (HKG).
