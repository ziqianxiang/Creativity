Figure 1: Illustration of video action anticipation problem. The context of action may be differentthan the preamble of action. Models can only observe some frames before action actually starts,which is strictly ensured by an inaccessible ”Skip” period, and based on the evidence collected topredict the following action.
Figure 2: Overview of proposed unified recurrent model. The message function, update function,and readout function leverage multi-head self-attention. Our proposed message function is designedto be flexible to work in conjugation with explicit edges information provided.
Figure 3: Propose edge learning extensions to the multi-head self-attention layer. The three blockdiagrams present the (left) edge attention, (middle) class token projection, and (right) template bank,respectively.
