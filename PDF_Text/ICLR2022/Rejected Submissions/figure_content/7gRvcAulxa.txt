Figure 1: (a) The DCT of Noise Gradients averaged across the validation sets, visualized withhistogram equalization. (b) shows the standard 8×8 DCT block with the all 64 frequencies arrangedin zigzag order.
Figure 2: Vulnerability scores (Accuracy under attack) visualized per frequency across datasets.
Figure 3:	Accuracy for models trained with varying drop rates, for different frequency ranges.
Figure 4:	Frequency-based adversarial training across datasets. In the first column we show theresults of adversarially training and testing for different frequency ranges. Next, we show results ofthe same experiments across individual frequencies. The last column shows clean accuracy for eachfrequency.
Figure 5:	Illustration of unequal epsilon distribution. Here we see that models where low frequencyperturbations are favoured ends up with higher robustness, but lower clean accuracy.
Figure 6: Clean Accuracy vs Robustness across datasets, compared with standard adversarial train-ing for free method. Note that the Y-axis scales are different. Here λ controls the weight of adver-sarial perturbation towards lower frequencies.
