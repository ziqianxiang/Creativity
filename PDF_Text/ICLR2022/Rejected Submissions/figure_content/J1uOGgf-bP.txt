Figure 1: A schematic of our overall approach. Left: at test time, as detailed in Section 3, we havea trained model that outputs a probabilistic predictive distribution and has adaptable parameters θ,a single test input x, and a set of data augmentation functions {a1, . . . , aM}. Note that we do notassume access to the model training procedure or multiple test inputs for adaptation. We performdifferent augmentations to x and pass these augmented inputs to the model in order to estimate themarginal output distribution averaged over augmentations. Right: rather than using this distributionto make the final prediction, we instead perform a gradient update on the model to minimize theentropy of this marginal distribution, thus encouraging the model predictions to be invariant acrossdifferent augmentations while maintaining confident predictions. The final prediction is then madeon the original data point, i.e., the predictive distribution in the top right of the schematic.
Figure 2: We visualize augmentations of a randomly chosen data point from the “Gaussian Noise level3” ImageNet-C test set. Even for a robust model trained with heavy data augmentations (Hendryckset al., 2021a), both its predictive accuracy and confidence drop sharply when encountering testdistribution shift. As shown in the bottom two rows, these drops can be remedied via MEME.
Figure 3: Plotting MEME efficiency as seconds per evaluation (x axis) and % test error onImageNet-R (y axis) for the ResNet-50 models (left) and RVT* -small (right) while varyingB = {1, 2, 4, 8, 16, 32, 64, 128}. Note the log scale on the x axis.
