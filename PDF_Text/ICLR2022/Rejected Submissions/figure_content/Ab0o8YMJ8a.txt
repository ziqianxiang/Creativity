Figure 1: ImageNet accuracy of pruned EfficientNet B0 and B1. Considering FLOPs/accuracy trade-off thesome pruned models are better than FBNetV2, which to our knowledge has SOTA results in its FLOPs range.
Figure 2: An subset of a network with logit predictor and masking. The colors indicate the correspondencebetween channels. The logit predictor takes a feature map produced by the sum operation and use it topredict an update for the channel logits.
Figure 3: Breaking up an extended orbit. An extended orbit is broken up into two final orbits. Nodes C 1 andC2 must have their channels pruned jointly. Node C3 can be pruned separately.
Figure 4: ImageNet accuracy of pruned EfficientNet B0 and B1. Considering FLOPs/accuracy trade-off thesome pruned models are better than FBNetV2.
Figure 5: Pruning results for MobileNetV2 and EfficientNetV28Under review as a conference paper at ICLR 2022Table 3: Top 1 ImageNet accuracy and FLOPs for EfficientNetV2 B0 prunedModel	Standard training	B0 teacher	hierarchical teachers	FLOPs (G)original	78.67	-	-	0.722m20	-	77.59	78.93	0.506m17	-	77.25	78.37	0.431m15	-	76.70	77.64	0.379m12	-	75.59	76.36	0.299319320321322323324325326327328
Figure 6: Visualisation of the layer width after channels are removed. There is a noticeable patter in whichthe first block in a series of residual blocks at the same spatial resolution is the most important one and thealgorithm is reluctant to remove the channels. Later blocks seem to be less informative, proportionally totheir depth.
Figure 7: Validation results for pruned RawRGB denoising models.
Figure 8: Validation results for pruned human segmentation.
