Figure 1: Generated samples from COCO (Left) and ArtEmis (Right) using HyperNet con-ditioned convolution-based (discrete) and INR-based generators (continuous). For continuousimages, the regions outside the bounding boxes are extrapolations beyond the training image dimen-sions.
Figure 2: The architecture of the proposed HyperCGAN comprising of a Text encoder; hyper-networks TGs body, TGs and TGw and heads for conditioning the generator; and TDs and TDwfor conditioning the discriminator. HyperCGAN is a one-stage pipeline for image synthesis usingcontinuous or discrete generators. Sentence-level conditioning hypernetworks use the s subscriptwhile the attention-based word-level conditioning heads use the w subscript. The discrete Style-GAN2 generator takes a constant input, while the continuous INR-GAN generator takes an (x, y)coordinate.
Figure 3: Qualitative comparison of the proposed HyperCGAN model with state-of-the-art models(DM-GAN, DF-GAN) for T2I synthesis.
Figure 4: Qualitative Results on ArtEmis dataset (Attn-GAN, DM-GAN, DF-GAN, HyperCGAN )14Under review as a conference paper at ICLR 2022Figure 5: Out-of-the-Box generationwhich is based on a bi-directional Long Short-Term Memory (LSTM). In the bi-directional LSTM,each word corresponds to two hidden states, one for each direction. To represent the semanticmeaning of a word, they concatenate its two hidden states. The last hidden states of the bi-directionalLSTM are concatenated to be the global sentence vector. The hidden size of both embeddings isequal to 256.
Figure 5: Out-of-the-Box generationwhich is based on a bi-directional Long Short-Term Memory (LSTM). In the bi-directional LSTM,each word corresponds to two hidden states, one for each direction. To represent the semanticmeaning of a word, they concatenate its two hidden states. The last hidden states of the bi-directionalLSTM are concatenated to be the global sentence vector. The hidden size of both embeddings isequal to 256.
Figure 6: HyperCGAN Head and Body Ablation Qualitative Results on ArtEmis datasetThe use of many colors with	The dark colors and blunt The clouds are so cool and	This a picture of colors of	This looks very creepy it looks like The primary colors are bold and Lost in a city and finding myself The woman has a pleading lookthis painting makes me feel	Iinesfeel chaotic and brash.	Veryattracting.	flowers that look like that will	the feet of a dead person in the	playful as are the larger shapes.	in a bad area of abandoned	in her eyes.
Figure 7: Example of affective captions and corresponding emotion from ArtEmis dataset.
Figure 8:	Numpy-like pseudocode for core tensor modulation implementation.
Figure 9:	Numpy-like pseudocode for attention-based word-level tensor modulation.
Figure 10:	High-resolution generations (1024x1024) from our HyperCGANStyleGAN2 modeltrained on COCO.
