Figure 1: We cluster graph nodes belongingtogether (gray shades) and connect them toa common virtual node (blue). This easesinformation exchange and hence prediction oflinks between nodes not directly related (red).
Figure 2: Performance depending on layers: Hits@k and time per epoch (sec.); ddi (left), collab.
Figure 3: Impact of virtual nodenumber; ddi (top) and collab.
Figure 4: Example of using two virtual nodes to improve expressiveness. In Figure 4(a), a typicalmessage-passing GNN (see Section 3) computes the same representation for v2 and v3, and wecannot discriminate the node pairs (v1, v2) and (v1, v3) if we just use the node representation forlink prediction, as it is usual. In Figure 4(b), by adding two virtual nodes s1 and s2, v2 and v3 haveclearly different features (because they connect to different virtual nodes with different labels) anddifferent representations after GNN embedding, so (v1, v2) and (v1, v3) can be easily discriminated.
Figure 5: Performance depending on layers: time per epoch (sec.); ddi. We observe from Figure 2that we get better Hits@20 for the virtual nodes models already at 2 layers than for GCN at 6 layers(its best score), hence we also compare these models. Here we see that a single virtual node canhave a positive impact at the same time on both prediction scores and efficiency. The clustering takesmore time.
