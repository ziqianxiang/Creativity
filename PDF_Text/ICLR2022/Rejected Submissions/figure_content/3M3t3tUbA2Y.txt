Figure 1: DreamerPro learns the world model through online clustering, eliminating the need forreconstruction. At each time step t, it first compares the observation to a set of trainable prototypes{c1 , . . . , cK} to obtain the target cluster assignment wt. Then, it predicts this target from boththe world model state zt and another augmented view of the observation (each aug(ot) denotes anindependent application of data augmentation). The predictions are improved by optimizing thetwo objective terms, JTtemp and JStWAV , respectively, where the first term crucially distills temporalstructures from zt into the prototypes.
Figure 2: Performance curves in standard DMC. DreamerPro is the only model that is comparableor better than Dreamer on all tasks. In particular, DreamerPro greatly outperforms Dreameron Finger Spin and Reacher Easy, and achieves better data efficiency on Cup Catch.
Figure 3: Performance curves in natural background DMC. DreamerPro significantly outper-forms all baselines on Cartpole Swingup, Finger Spin, and Walker Run, while Dreamer completelyfails on all tasks.
Figure 4: Visualization of learned latent states through reconstruction from an auxiliary decoder.
Figure 5: Visualization of learned latent states through nearest neighbor queries.
Figure 6:	Ablation study. Both JStWAV and JTtemp are necessary for achieving good performance.
Figure 7:	Performance curves in six Atari games.
Figure 8: Prototype visualization for Cartpole Swingup.
Figure 9: Prototype visualization for Cheetah Run.
Figure 10: Prototype visualization for Cup Catch.
Figure 13: Prototype visualization for Walker Run.
