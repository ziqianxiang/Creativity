Figure 1: The standard classifier retraining (cRT) setup on the left, and the experimental configu-ration we use on the right. Instead of resampling, we swap datasets between stages to simulate an”ideal” classifier or an ”ideal” representation.
Figure 2: Table 1 in graphic form, showing that a biased representation is very difficult to overcome,but a biased classifier can be mitigated if the representation is unbiased.
Figure 3: Data augmentation improves fair classification performance in long-tailed settings(CIFAR-10 with an imbalance factor of 100)ance factor of a dataset unchanged. Nevertheless, input data augmentation such as MixUp (Zhanget al., 2018), Manifold Mixup (Verma et al., 2019) and AutoAug (Cubuk et al., 2019) have proven tobe highly effective for reducing bias in long-tailed classification (Zhong et al.; Zhang et al., 2021b;Tan et al., 2020). When combined with decoupled training (Kang et al., 2020), data augmenta-tion results in even larger increases (Fig 3). However, the mechanism by which data augmentationimproves performance and reduces bias is not known. It cannot address data imbalance, so dataaugmentation must be affecting another quality of the representation.
Figure 4: The second moments of features learned from long-tailed distributions are substantiallydifferent from those of representations learned from the true distribution. Variance for the tail classesis higher, and the covariance matrices have larger norms for the body and the tail.
Figure 5: The feature space of long-tailed representations is biased — their variance is concentratedin fewer dimensions than those of the representations trained on the true class distributions. This canbe seen by the relatively higher proportion of variance explained by the first principal component.
Figure 6: More unseen samples from the true data distribution fall outside the angular maximum ofthe tail class distributions for long-tailed representations, than for representations trained on the truedistributions. Augmentation can mitigate this effect.
Figure 7: When unseen samples from the true data distribution are embedded into the long-tailedfeature space, inter-class separation significantly drops. This is not true for the long-tailed distribu-tion, which sees relatively small shifts in inter-class separation. Augmentation mitigates this effect,and augmented representations experience a small change in inter-class separation.
Figure 8: Tail classes are poorly localized w.r.t to the true data distribution for long-tailed represen-tations. The class centers experience a large angular shift, nearly equal to the width of the classesfor classes in the tail.
