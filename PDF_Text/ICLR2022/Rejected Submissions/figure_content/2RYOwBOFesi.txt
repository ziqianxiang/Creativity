Figure 1: (Left) Illustration of our fine-tuning procedure used throughout this paper, i.e., we fine-tunea pre-trained model on training dataset D and evaluate the model performance on OOD data ToOd - adata domain not seen during training. (Right) Evaluating ID and OOD accuracies for two classes ofpre-trained models. Orange squares represent the ImageNet-1k pre-trained models and blue circlesrepresent the IG-1B pre-trained models, where IG-1B is a larger dataset than ImageNet-1k. Largermarker size means the model size is larger.
Figure 2: Evaluating models (SWSL-ResNext101-32x4d) fine-tuned using different learning rateson ID and OOD data. (Top row) Scatter plot of ID accuracy (X-axis) and OOD accuracy (Y -axis).
Figure 3: OOD accuracy of models (SWSL-ResNext101-32x4d) during training. We visualize modelstrained with three different learning rates in terms of OOD accuracy vs. training loss. Each point inthe above plots represents the model evaluated at one iteration during trainingobserve that, in most of the settings considered in this paper, the models trained with smaller learningrates achieve much better OOD generalization1, even when the ID accuracy does not change much.
Figure 4:	Evaluating OOD and ID performance of models pre-trained on different datasets. Eachcolor corresponds to the models pre-trained on a distinct dataset and the dash-dotted line representsthe model picked by our model selection procedure. For each model we report the accuracy acrossdifferent fine-tuning learning rates.
Figure 5:	A comparison of four ViT models and three BiTm models on OOD accuracy and IDaccuracy. The orange squares represent ViT models and the blue circles represent BiTm models. Thedash-dotted lines represent the selected models. We do not distinguish the model architectures withinthe same model class.
Figure 6:	Evaluating OOD generalization for three classes of models with different model sizes. Left:Results for ResNe(x)t models pre-trained on ImageNet-1k. Middle: Results for BiTm-ReSNetV2models pre-trained on ImageNet-21k. Right: Results for SWSL-ReSNe(x)t models pre-trained onIG-IB-Targeted. For a given model class, each model size is represented by a distinct color.
Figure 7:	Evaluating OOD generalization performance of models trained with different number oftraining samples. X-axis represents the number of training samples. We use SWSL-ResNext50-32x4d and SWSL-ResNext101-32x8d as the pre-trained models. For each pre-trained model, wevisualize the OOD accuracies of the top-3 models selected by ID accuracy.
Figure 8: (Additional results) Evaluating models (SWSL-ResNext101-32x4d) fine-tuned by differentlearning rates on in-distribution and out-of-distribution data. (Top row) Scatter plot of in-distributionaccuracy (X-axis) and out-of-distribution accuracy (Y -axis). (Bottom row) Compare in-distributionaccuracy with out-of-distribution accuracy w.r.t. learning rate (X -axis). The green dashed linecorresponds to the baseline OOD accuracy, and the blue dash-dotted line represents the selectedmodel (by selecting the model with best in-distribution accuracy).
Figure 9: Evaluating models (SWSL-ResNext101-32x8d) fine-tuned by different learning rateson in-distribution and out-of-distribution data. (Top row) Scatter plot of in-distribution accuracy(X-axis) and out-of-distribution accuracy (Y -axis). (Bottom row) Compare in-distribution accuracywith out-of-distribution accuracy w.r.t. learning rate (X -axis). The green dashed line corresponds tothe baseline OOD accuracy, and the blue dash-dot line represents the selected model (by selecting themodel with best in-distribution accuracy).
Figure 10: Evaluating models (SWSL-ResNext50-32x4d) fine-tuned by different learning rateson in-distribution and out-of-distribution data. (Top row) Scatter plot of in-distribution accuracy(X-axis) and out-of-distribution accuracy (Y -axis). (Bottom row) Compare in-distribution accuracywith out-of-distribution accuracy w.r.t. learning rate (X -axis). The green dashed line corresponds tothe baseline OOD accuracy, and the blue dash-dot line represents the selected model (by selecting themodel with best in-distribution accuracy).
Figure 11: Evaluating BiTm models (BiTm-ResNetV2-50x3) fine-tuned by different learning rateson in-distribution and out-of-distribution data. (Top row) Scatter plot of in-distribution accuracy(X-axis) and out-of-distribution accuracy (Y -axis). (Bottom row) Compare in-distribution accuracywith out-of-distribution accuracy w.r.t. learning rate (X -axis). The green dashed line corresponds tothe baseline OOD accuracy, and the blue dash-dot line represents the selected model (by selecting themodel with best in-distribution accuracy).
Figure 12:	Evaluating models (ResNext101-32x8d pre-trained on ImageNet) fine-tuned by differentlearning rates on in-distribution and out-of-distribution data. (Top row) Scatter plot of in-distributionaccuracy (X-axis) and out-of-distribution accuracy (Y -axis). (Bottom row) Compare in-distributionaccuracy with out-of-distribution accuracy w.r.t. learning rate (X -axis). The green dashed linecorresponds to the baseline OOD accuracy, and the blue dash-dot line represents the selected model(by selecting the model with best in-distribution accuracy).
Figure 13:	Evaluating models (ResNext50-32x4d pre-trained on ImageNet) fine-tuned by differentlearning rates on in-distribution and out-of-distribution data. (Top row) Scatter plot of in-distributionaccuracy (X-axis) and out-of-distribution accuracy (Y -axis). (Bottom row) Compare in-distributionaccuracy with out-of-distribution accuracy w.r.t. learning rate (X -axis). The green dashed linecorresponds to the baseline OOD accuracy, and the blue dash-dot line represents the selected model(by selecting the model with best in-distribution accuracy).
Figure 14:	OOD accuracy of models (SWSL-ResNext101-32x4d) during training. We visualizemodels trained with three different learning rates in terms of OOD accuracy v.s. training loss. Eachpoint in the above plots represents the model evaluated at one iteration during training.
Figure 15:	Evaluating out-of-distribution and in-distribution performance of models pre-trained ondifferent datasets. Each color corresponds to models pre-trained on one dataset and the dash-dot linerepresents the selected model.
Figure 16: A comparison of four ViT models and three BiTm models on out-of-distribution accuracyand in-distribution accuracy. The orange squares represent ViT models and the blue circles representBiTm models. The dash-dot lines represent the selected models. We do not distinguish the modelarchitectures within the same model class.
Figure 17:	Evaluating OOD generalization performance of models trained with different number oftraining samples on the TerraIncognita dataset. X-axis represents the number of training samples.
Figure 18:	Evaluating models (SWSL-ResNext50-32x4d) fine-tuned by different learning rates (withstage-wise learning rate decay) on in-distribution and out-of-distribution data. (Top row) Scatterplot of in-distribution accuracy (X -axis) and out-of-distribution accuracy (Y -axis). (Bottom row)Compare in-distribution accuracy with out-of-distribution accuracy w.r.t. learning rate (X-axis). Thegreen dashed line corresponds to the baseline OOD accuracy, and the blue dash-dot line representsthe selected model (by selecting the model with best in-distribution accuracy).
Figure 19:	A comparison of ResNext101-32x8d models pre-trained on IG-1B-Targeted (SWSL-ResNext101-32x8d) v.s. ResNext101-32x8d without pre-training on out-of-distribution accuracy andin-distribution accuracy. The orange squares represent ResNext101-32x8d without pre-training andthe blue circles represent models pre-trained on IG-1B-Targeted. We evaluate the models on both IDand OOD data every 100 iterations, and we visualize all the ID/OOD results in the above figures.
Figure 20: A comparison of ResNet50 pre-trained on 1/8 classes of the ImageNet-1k v.s. ResNet50pre-trained on 1/8 training samples of the ImageNet-1k on out-of-distribution accuracy and in-distribution accuracy. The orange squares represent models pre-trained on 1/8 classes and the bluecircles represent models pre-trained on 1/8 training samples.
Figure 21: Evaluating models (SWSL-ResNext50-32x4d) fine-tuned by different learning rates onin-distribution and out-of-distribution data. X-axis represents the distance between the fine-tunedmodel weights and initial pre-trained model weights (i.e., kθFine-tuned - θInit k22). Each point in thescatter plot corresponds to one learning rate. The green dashed line corresponds to the baselineOOD accuracy. The orange squares represent the in-distribution accuracy results and the blue circlesrepresent out-of-distribution accuracy results.
Figure 22: Evaluating models (SWSL-ResNext50-32x4d) fine-tuned by different learning rates (withmore learning rates, i.e., η ∈ {5 × 10-2, 1 × 10-2, 5 × 10-3, 1 × 10-3, 5 × 10-4, 1 × 10-4, 5 ×10-5, 1 × 10-5, 5 × 10-6, 1 × 10-6, 5 × 10-7, 1 × 10-7}) on in-distribution and out-of-distributiondata. (Top row) Scatter plot of in-distribution accuracy (X -axis) and out-of-distribution accuracy(Y -axis). (Bottom row) Compare in-distribution accuracy with out-of-distribution accuracy w.r.t.
