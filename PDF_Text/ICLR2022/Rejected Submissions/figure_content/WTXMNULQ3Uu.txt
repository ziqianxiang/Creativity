Figure 1: The hierarchical graphical model for LOMs. We assumethat scenes x are generated from K object-centric slot latent variablesz1:K. The slots are independent conditional on a causal sequence ofdeterministic variables (shown in boxes). This causal sequence is pre-dicted from the top-level scene latent variable s. By conditioning eachslot on one of the deterministic variables, we provide the order-dependentrelational information necessary for scene generation.
Figure 2: Inference for Latent Object Models. Circles are slot latents. Dotted edges signify variablesfrom the auxiliary orderless model and solid edges are variables from the LOM model. Boxes aredeterministic variables. In steps 1-2 we infer an orderless slot posterior and the scene posterior. Instep 3 we use the scene posterior to generate slots via the deterministic variables. In Step 4 wealign the orderless slot posterior to the prior. Finally in step 5 we estimate new order-aware scaleparameters for the aligned slot posterior through another set of deterministic variables.
Figure 3: (a-c) Unconditional samples from LOM (GenV2-G). d) LOMs learn a relatively stable anddeterministic assignment of objects to specific slots for generating scenes. The color of each segmentindicates the slot number. e-h) A few generated ShapeStacks scenes. GEN scenes are generated witha trained model released by the authors. LOM (GENv2-G) generates scenes that most accuratelyreflect multi-object structure in the data and with the fewest visual artifacts.
Figure 4: LOMs can generate interpolated scenes between two random samples from the sceneprior by smoothly changing individual object and scene-level attributes. We use spherical linearinterpolation to generate the intermediate latents between two random samples from p(s). Thissuggests the LOM has learned a good scene-level manifold.
Figure 5: The Transformer architectures used to implement the LOM. We visualize each with K = 5.
Figure 6: Ablation and variation results. Box plots are shown for the five random seeds. a)Test KL for ablated models. Lower is better. b) FID scores for ablated models. Lower is better.
Figure 7: FID vs. sampling temperature (Ï„ ) on Objects Room. Error bars show std. dev. acrossthree seeds. The blue solid curve is LOM-EMORL and the orange dashed curve is LOM-GenV2-G.
Figure 8: Hierarchical clustering example. The top 5 retrieved scenes based on Euclidean distancebetween their scene-level latent and the query scene latent (the query is shown on the left, and scenesare shown left-right in decreasing similarity rank). a) The most similar scene has similar cameraperspective, wall color, object color, and object distance from the camera as the query. b) We use theslot for the green cone (boxed) to re-rank the results against the slots for each retrieved scene. Thetop retrieved scene has the exact same camera perspective and relative object placement (shown witharrows) as the green cone.
Figure 9: Additional hierarchical clustering examples. Similar to Figure 8, the query is shownon the left, the top row shows the initially retrieved scenes in decreasing order of similarity, andthe bottom row shows the re-ranking based on the selected slot (shown with black boxes). ForShapeStacks, we found that the initial scene-level retrieval was highly successful at finding sceneswith similar camera perspective and scene background as the query.
Figure 10: Objects Room SLERP between two random samples from the LOM scene prior.
Figure 11: CLEVR6 SLERP between two random samples from the LOM scene prior.
Figure 12: ShapeStacks SLERP between two random samples from the LOM scene prior.
Figure 13: Objects Room unconditional samples from each generative model with both images andmasks displayed.
Figure 14: ShapeStacks unconditional samples from each generative model with both images andmasks displayed.
Figure 15: CLEVR6 unconditional samples from each generative model with both images and masksdisplayed. For EMORL, the samples shown in columns one through three are drawn from the priorof a model that scores an average ARI-FG of 96 and FID of 244. The remaining three samples aredrawn from a different model trained to keep the KL low throughout training and which achieves alower average ARI-FG of 89 but FID score of 75.
Figure 16: LOM-EMORL reconstruction and segmentation.
Figure 19: GNM reconstruction and segmentation. Its symbolic variables, which are bound to aspatial grid of fixed resolution, are unable to properly bind to individual objects in the Objects Roomand ShapeStacks scenes. In Objects Room, the 3D shapes are segmented into strips and groupedalongside parts of the floor. The wall is erroneously not considered one of the foreground objects. InShapeStacks, distinct blocks are often segmented together when they fall within the same grid cell.
Figure 20: NVAE qualitative results.
