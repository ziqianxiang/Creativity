Figure 1: Comparison between the three different units, RNN, LSTM and GRU, respectively.
Figure 2: Example input (top row) and output (bottom row) time sequences.
Figure 3: Average training and validation RMSE of ten simulations, with recurrent layers of size 16and 8 (left) and 64 and 32 (right).
Figure 4:	Experiment 1: real (red & blue) and predicted (green & black) sequences for DB1 andLUAL (1st and 3rd rows) and PVR and VB1 (2nd and 4th rows) for two sequences of the test set(one selected simulation out of ten).
Figure 5:	Experiment 2: real (red & blue) and predicted (green & black) sequences for DB1 andLUAL (1st and 3rd rows) and PVR and VB1 (2nd and 4th rows) for two sequences of the test set(one selected simulation out of ten).
Figure 6: Average training and validation RMSE of ten simulations. Left: for 6 different hidden sizesof the GRU-based recurrent layer, for the iteration with the smallest validation loss. Right: for thetwo datasets with two different hidden sizes with a GRU-based recurrent layer.
Figure 7: Experiment 3: real (red & blue) and predicted (green & black) sequences for DB1 andLUAL (1st and 3rd rows) and PVR and VB1 (2nd and 4th rows) for two sequences of the test set(one selected simulation out of ten).
