Figure 1: Illustration of different losses for confidence maximization. Losses (left, shifted such thatmaxima of all losses are at 0) and the resulting gradients with respect to the first logit (right) as afunction of the first classes confidence are shown for the case of a binary classification problem.
Figure 2: Test-time adaptation results on (top row) ImageNet-C, averaged across all 15 corruptions andseverities, (middle row) ImageNet-R, (bottom row) clean ImageNet. NA refers to "No Adaptation".
Figure 3: Test-time adaptation of ResNet50 using (top row) a subset of classes, and (bottom row) asubset of samples per class on 4 different corruptions at severity 5. Accuracy is computed based onthe evaluation of adapted model on the entire target data. Note that error bars are smaller to visualize.
Figure A1: Structure of our adaptable model g, that comprises of rψ .
Figure A2: Qualitative results of image transformation from input transformation module adaptedwith SLR.
Figure A3: Effect of different κ on both (a) HLR and (b) SLR20Under review as a conference paper at ICLR 2022Loss LHard Likelihood RatioSoft Likelihood Ratio----Entropy----MS(a)Confidence IyI(b)Soft Likelihood RatioEntropyCharbonnier(Entropy, eta=0.75)Charbonnier(Entropy, eta =0.90)Charbonnier(Entropy, eta=0.99)Figure A4: (a) Illustration of Max Square (MS) loss and (b) Charbonnier penalty with different η.
Figure A4: (a) Illustration of Max Square (MS) loss and (b) Charbonnier penalty with different η.
