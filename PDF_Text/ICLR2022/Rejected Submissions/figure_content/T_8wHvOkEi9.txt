Figure 1: A motivating example withthe accuracy and the relative joint Qerror of max-sum algorithm w.r.t. thenumber of agents.
Figure 2: Illustration of our basic idea. For ease of viewing, we mark each edge with a uniquecolor. Our algorithm conducts different coordination graphs for different environment states. Forexample, the selection of graph topologies on states s1 and s2 depends on the utility functions oncorresponding states. These utility values are updated through the learning procedure.
Figure 3: Ablation studies on Sensor-network: (a) comparison against DCG with online data collec-tion; (b) comparison against DCG with offline dataset; (c) comparison with static topologies.
Figure 4: Sensor-network.
Figure 5: Learning curves on Pursuit, Chasing and Postman. The optimal return is demonstrated ifit is available.
Figure 6: Various coordination graphs learned by our algorithm on Chase: (a) Self-organized group-ing at initialization; (b) Connecting to agent with rich observation for better information sharing; (c)Concentrated collaboration structure around an enclosed adversary.
Figure 7: Ablation studies about the graph relabeling technique.
Figure 8: Learning curves on StarCraft II micromanagement tasks.
Figure 9: Learning curves on 1o10b_vs_1r and 12z_vs_2ul.
Figure 10: Learning curves on a series of toy games.
