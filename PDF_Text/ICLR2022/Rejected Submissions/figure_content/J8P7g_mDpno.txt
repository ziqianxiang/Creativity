Figure 1: Time (∆) it takes for weights to decorrelate (normalized by the total number of trainingsteps) as a function of weight magnitudes obtained after training. Points correspond to the me-dian ∆ over weight bins sampled from a single neural layer. Shaded regions distinguish betweenweights that are needed (white) or can be removed (yellow) at inference time. From left to right:Transformer-XL (Language Modeling), GNMT (Machine Translation), ResNet50 (Image Classifi-cation).
Figure 2: Investigations into various aspects of training sparse models using ResNet50. Left: Taskerror (or accuracy difference between dense and sparse models) as a function of rewiring steps r .
Figure 3: Task error after training Transformer-XL Base using different exploration versus ex-ploitation strategies as a function of model sized. Appendix A covers data for a broader span ofneural models and tasks.
Figure 4: Accuracy difference between dense and sparse models comparing various methods asa function of model size d. Left to right: ResNet50 (Classification), Transformer (Translation),Transformer-XL (Language Modeling). Appendix F covers a broader span of data.
Figure 5: Same as Figure 2 (left). From left to right: InceptionV3 (Image Classification), MaskRCNN (Semantic Segmentation), Pix2PixHD (Image Generation).
Figure 6:	Same as Figure 2 (middle). From left to right: Mask R-CNN (Semantic Segmentation),Transformer (Machine Translation), Transformer-XL (Language Modeling).
Figure 7: Same as Figure 2 (right). From left to right: Mask RCNN (Semantic Segmentation),Transformer-XL (Language Modeling), GNMT (Machine Translation).
Figure 8: Same as Figure 3. From left to right: Transformer (Translation), Transformer-XL Large(Language Modeling).
Figure 9:	Fraction of accuracy that sparse models achieve between dense and smaller models asa function of d across various tasks and neural architectures. We measure the fraction as f =(DENSE - SEARCH)/(DENSE - SMALL).
Figure 10:	Effects of sparsity with longer training of ResNet18. Left: Accuracy differences as afunction of training time t (or ratio of steps to the original training schedule). Middle: Task errorbetween dense and sparse models trained for the same duration. Right: Training time it takes forsparse models to match accuracy of dense models.
Figure 11:	Same as Figure 10 (left). Left to right: ResNet50 (Classification), InceptionV3 (Classifi-cation), Transformer-XL (Language Modeling).
Figure 13: Same as Figure 4. Clockwise: InceptionV3 (Classification), DenseNet161 (Classifica-tion), VGG19 (Classification), GNMT (Translation), Pix2PixHD (Generation), Mask RCNN (Seg-mentation).
