Figure 1: Overview of the one-sample adaptation process. Based on a single test sample, we create abatch of images by augmenting the original input with multi-scale versions. Furthermore, we add ahorizontally flipped and grayscaled version for every scale. In order to project the resulting outputfrom every version back to the original image, we apply the respective inverse affine transformationto every prediction. Afterwards, we average the predicted softmax probabilities and create a pseudolabel using a class-dependent confidence threshold. We update the model parameters by minimizingthe cross-entropy loss w. r. t. the pseudo label and repeat this process for a small number of iterations,Nt, before producing the final prediction. The updated model is then discarded.
Figure 2: Runtime-accuracy comparison on GTA → Cityscapes generalization. The curves traceSeg-TTT iterations, i. e. the first point corresponds to Nt = 1, while the last shows Nt = 10. WhileSeg-TTT increases the inference time of the baseline and TTA for the sake of improved accuracy, it isstill more efficient and accurate than model ensembles of 10 networks. The choice of the layers forSeg-TTT updates (the naming follows He et al. (2016)) further provides a favorable runtime-accuracytrade-off. Runtimes are computed on a single NVIDIA GeForce RTX 2080 GPU.
Figure 3: Qualitative semantic segmentation results for the generalization from GTA to Cityscapes,BDD, Mapillary, and IDD for the ResNet-50 backbone. The input image, ground truth, prediction ofthe baseline model, and prediction of the proposed combination of IaBN and Seg-TTT are shown.
Figure 4: Mean IoU (%, ↑) using IaBN based on the optimal alpha on the development set (WildDash).
Figure 5: Runtime-accuracy comparison on GTA → BDD (top) and GTA → IDD (bottom) general-ization. The curves on this plot trace Seg-TTT iterations, i. e. the first point corresponds to Nt = 1,while the last shows Nt = 10. While Seg-TTT increases the inference time of the baseline and TTAfor the sake of improved accuracy, it is still more efficient and accurate than model ensembles of10 networks. The choice of the layers for Seg-TTT updates (the naming follows He et al. (2016))further provides a favorable runtime-accuracy trade-off. Runtimes are computed on a single NVIDIAGeForce RTX 2080 GPU.
Figure 6: Qualitative semantic segmentation results for generalization from GTA to Cityscapes, BDD,Mapillary, and IDD for the ResNet-101 backbone.
Figure 7: Qualitative semantic segmentation results for generalization fromBDD, Mapillary, and IDD for the ResNet-50 backbone.
Figure 8: Qualitative semantic segmentation results for generalization from SYNTHIA to Cityscapes,BDD, Mapillary, and IDD for the ResNet-101 backbone.
Figure 9: Failure cases of semantic segmentation for generalization results from GTA to Cityscapes,BDD, Mapillary, and IDD for the ResNet-50 backbone.
Figure 10: Density distribution of the individual images for generalization from source domain (GTA)to target domains (Cityscapes, BDD, IDD and Mapillary) for the ResNet-50 backbone. We visualizethe relative improvement of our test-time inference strategy w.r.t. the baseline in terms of accuracywith ∆ IoU (%).
