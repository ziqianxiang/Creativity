Figure 1: Red dashed lines denote real data manifolds in pixel space and their inverse images inlatent space; yellow circles and squares denote samples for sound generation in latent space and pixelspace; black circles and squares denote samples for bad generation in latent space and pixel space; theorange dashed lines denote the generator mapping; the blue dashed lines denote z transform in latentspace; blue shades and solid blue lines denote the latent distribution and the generated distribution.
Figure 2: Red dashed lines denote real data manifolds; blue shades and blue lines denote the generateddistribution. The generated distributions mapped from a fixed latent distribution reflect the mappingquality. (a) shows the case of bad quality when the generated distribution does not match the realdistribution well. (b) shows the case of bad diversity when the mapping misses modes. Our methodtries to train mappings with better properties, as shown on the right side of each case.
Figure 3: Generation examples of StyleGAN2-ada (Karras et al., 2020). Sampling equidistantly fromp(z) in the latent space, the samples in the generated distribution pg (x) of the pixel space are shownhere. The beginning and ending images of each row locate in different manifolds. The intermediateresults are sampled by crossing between disconnected manifolds. The discontinuity causes weirdgeneration in the transition, marked with yellow boxes (first row: the cat misses an ear, and its headis crooked; second row: white spots on the nose; third row: two bodies share one head).
Figure 4: Results of latent sample transform on the SNGAN model pre-trained on STL-10. Theoriginal generated images are shown on the left, and the images generated with the newly found zsafter 100 steps iteration of I-FGSM are shown on the right. We notice that the right figures containricher colors and more realistic details, with the main content remaining consistent. We measuregeneration quality in a batch by Inception Score, which increases from 6.944 to 7.475.
Figure 5: Each of the six columns shows two compared pairs of generated example (first pair: 1st+ 2nd row; second pair: 3rd row + 2nd row) by our diversity driven iterative transform scheme inlatent space with the same number of iterations to obtain z* from initial z. Middle row: generationby vanilla latent sampling z ; Top: by latent sample transformed by Eq. 8; Bottom: by latent sampletransformed by Eq. 8â€™s inverse form. It shows using Eq. 8 generates more similar image pairs servingas hard samples for training, rather than using its inverse form (see quantitative results in Table 1).
Figure 6: The logic of our 5 variantmethods in Sec. 4.1. Blue and redis for quality and diversity.
Figure 7: Post-training latent sampling improve-ment on Grid and Ring by AdvLatGAN-qua.
Figure 8: Latent distribution transform With WGAN-GP/DCGAN as backbone on MNIST. As theI-FGSM iteration continues, the latent distribution deviates from the standard Gaussian, and containsmore valleys and peaks Which can be mapped into generated images as shoWn in the bottom. Notethe generations by the valley points are of loW quality and they can be effectively avoided by ourscheme as the sampling probability is loW (valley) in our transformed distribution.
Figure 9: Results of AdvlatGAN-z on AFHQ and FFHQ. The first row are bad generations (thefirst three correspond to those in Fig. 3) with the defects as follows: first column: the cat missesan ear; second column: white spots on the nose; third column: two bodies share one head; fourthcolumn: green face; fifth and sixth columns: semi-existing glasses. The second row are resultsunder AdvLatGAN-z. The results show that AdvLatGAN-z can effectively mitigate image defects.
Figure 10: Left: points generated by the generator after training for one epoch. Middle: apply latentiterative sampling strategy for the generator shown in the left image. Right: generated points aftertraining 100 epochs.
Figure 11: Results of using AdvLatGAN-qua.
Figure 12: Results of SNGAN on CIFAR-10 and STL-10.
Figure 13: Results of WGAN-GP on CIFAR-10 and STL-10.
Figure 14: Results of latent iterations for diversity by using DCGAN Radford et al. (2016) pre-trainedon CIFAR-10.
