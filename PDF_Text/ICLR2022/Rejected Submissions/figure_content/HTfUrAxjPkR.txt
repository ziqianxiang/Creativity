Figure 1: A Translatotron 2 model that translates Spanish speech into English speech.
Figure 2: Sample mel-spectrograms on input withspeaker turns. The input is a concatenation of anutterance from a male speaker followed by anotherutterance from a female speaker. Translatotron 2preserves the voices of each speaker in the translatedspeech.
Figure 3: Affinity matrices of d-vector similarity among 100 random examples. (“s2st” refers to thepredictions from Translatotron 2.)Table 7: Objective d-vector similarity between the predicted translated speech (English) and thesource human speech (Spanish) on speaker turns. The similarity between the leading/trailing 1.6-second segment from the predicted speech and the entire 1st/2nd source speaker’s speech is measured.
Figure 4: Augmented PnG NAT TTS model for cross-lingual voice transferring.
