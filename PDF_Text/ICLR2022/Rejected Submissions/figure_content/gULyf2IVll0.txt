Figure 1: An illustrative comparison of two networks that have different PRS ratios (High and Low)with similar test accuracy. (Left column) Each colored box image corresponds to the colored dotin the right column. The orange/red box image is the perturbed image in each network under anadversarial attack respectively. (Middle column) The network with a low PRS ratio learns moresparse feature representation than that with a high PRS ratio. (Right column) Decision boundariesand regions in the section of input space for the target layer. Contour indicates the logit value fordog class.
Figure 2: (a) The number of PRS for the depth of each layers. (b) Training/Test accuracy and thePRS ratio on the penultimate layer on CNN-6 with batch size 2048/128. We select the networks atthe 300th epoch and call these two CNN-6 as Network A and B, respectively, throughout the paper(PRS ratio of Network A: 0.99, and Network B: 0.007).
Figure 3: Robust accuracy under various adversarial attacks on networks A and B. The x-axis indi-cates perturbation and the y-axis indicates the training/test robust accuracy under the attack.
Figure 4: Relationship between the PRS ratio and RA attacked by PGD method in various modelsand datasets. The colored dots are for the independent models described in Appendix A. The coloreddashed lines indicate the trend for each dataset.
Figure 5: PRS ratio and RA for training epochs on three different networks with CIFAR-10. Theblue line indicates the test accuracy, the orange line indicates the RA, and the green line indicatesthe PRS ratio. The shaded lines depict the standard deviation for five fixed random seeds.
Figure 6: (a) Comparison of the ratio of the zero gradient in the failure attack for the test samplesunder the PGD attack on Lâˆž with = 0.0313 and 20-step size (Network A and B). (b) The illustra-tive examples of attacked samples on Network A and B which is failed on B, and the correspondinglogits before/after the attack. After the attack, the logits move on almost parallel direction with theoriginal logits in Network B. More examples are provided in Appendix C.
Figure 7: (a) Cosine similarity matrix for the final layer on Network A. (b) Similarity matrix forepochs on Network B. As the epoch increases, the cosine similarity for each parameter increases.
Figure 8: Relationship between the PRS ratio and the cosine similarity in various models anddatasets. The colored dots represent the independent models. The colored dashed lines indicatethe trends for each of the datasets.
Figure 9: Test accuracy under adversarial attacks for inclusion/exclusion groups for CNN-6 onCIFAR-10 for five fixed random seeds. The blue/orange line indicates the exclusion/inclusiongroups, respectively. The exclusion group is shown to be more vulnerable under adversarial attacks.
Figure 10: Relationship between the PRS ratio and the inclusion ratio for CNN-6, VGG-16 andResNet-18 on the various datasets. The colored dashed lines indicate the trend for each dataset.
Figure 11: Visualization of feature maps for CNN-6 trained on CIFAR-10. (First row) Feature mapsfor Network A. (Second row) Feature maps for Network B.
Figure 12:	Relationship between the PRS ratio and the average sparsity for CNN-6, VGG-16 andResNet-18 on the various datasets. The colored dashed lines indicate the trend for each dataset.
Figure 13:	Visualization of the projected feature space with t-SNE for CNN-6 trained with variousdatasets. The colored code indicates the class. The samples in low PRS ratio cases are more denselylocated in each class compared to the samples in high PRS ratio.
