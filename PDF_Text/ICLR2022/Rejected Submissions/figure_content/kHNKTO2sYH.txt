Figure 1: Images for model repair (reconstruction), outlier (corrupted) and inlier (uncorrupted): (a) Original(Outlier); (b) Ground-Truth (Inlier); (c) VAE-L2; (d) VAEGMM; (e) CVAE; (f) CCVAE; (g) CLSVAE-NODC;(h) CLSVAE. A larger version of this figure is found in Annex I.
Figure 2: Outlier detection uses AVPR score where highest is best. Repair for dirty pixels, and for clean pixels(distortion), uses SMSE where lowest is best. (a) Trusted set range sweep for FaShion-MNIST where [0.12,0.25, 0.64, 1.28] % of the dataset, at 35 % noise level. (b) Table for results at 35% noise level, and 10 labelledsamples per class for the trusted set. Boldface corresponds to the best performances within a standard error,and green color to best mean performance overall. Standard error in brackets.
Figure 3:	Images for model repair (reconstruction), outlier (corrupted) and inlier (uncorrupted): (a) Original(Outlier); (b) Ground-Truth (Inlier); (c) VAE-L2; (d) VAEGMM; (e) CVAE; (f) CCVAE; (g) CLSVAE-NODC;(h) CLSVAE.
Figure 4:	Synthetic-Shapes. Outlier detection (AVPR) where higher is better. Trusted set range sweep whereTSsize = [5, 10, 25, 50] samples per class, i.e.[0.8%, 1.6%, 4%, 8%] of the entire dataset.
Figure 5: Synthetic-Shapes. Repair of dirty pixels in outliers (SMSE), where lower is better. Trusted set rangesweep where TSsize = [5, 10, 25, 50] samples per class, i.e. [0.8%, 1.6%, 4%, 8%] of the entire dataset.
Figure 6: Synthetic-Shapes. Repair of clean pixels in outliers (SMSE), i.e. distortion, where lower is better.
Figure 7: Frey-Faces. Outlier detection (AVPR) where higher is better. Trusted set range sweep where TSsize =[5, 10, 25, 50] samples per class, i.e. [1.3%, 2.5%, 6.4%, 12.7%] of the entire dataset.
Figure 8: Frey-Faces. Repair of dirty pixels in outliers (SMSE), where lower is better. Trusted set range sweepwhere TSsize = [5, 10, 25, 50] samples per class, i.e. [1.3%, 2.5%, 6.4%, 12.7%] of the entire dataset.
Figure 9: Frey-Faces. Repair of clean pixels in outliers (SMSE), i.e. distortion, where lower is better. Trustedset range sweep where TSsize = [5, 10, 25, 50] samples per class, i.e. [1.3%, 2.5%, 6.4%, 12.7%] of the entiredataset.
Figure 10:	Fashion-MNIST. Outlier detection (AVPR) where higher is better. Trusted set range sweep whereTSsize = [5, 10, 25, 50] samples per class, i.e. [0.12%, 0.25%, 0.64%, 1.28%] of the entire dataset.
Figure 11:	Fashion-MNIST. Repair of dirty pixels in outliers (SMSE), where lower is better. Trusted setrange sweep where TSsize = [5, 10, 25, 50] samples per class, i.e. [0.12%, 0.25%, 0.64%, 1.28%] of the entiredataset.
Figure 12: Fashion-MNIST. Repair of clean pixels in outliers (SMSE), i.e. distortion, where lower is better.
Figure 13: Images for model repair (reconstruction), outlier (corrupted) and inlier (uncorrupted): (a) Original(Outlier); (b) Ground-Truth (Inlier); (c) VAE-L2; (d) VAEGMM; (e) CVAE; (f) CCVAE; (g) CLSVAE-NODC;(h) CLSVAE. The first two rows are inlier examples, the others being outliers. Synthetic-Shapes: 35% noise,5 labels per class (0.8% of dataset).
Figure 14: Images for model repair (reconstruction), outlier (corrupted) and inlier (uncorrupted): (a) Original(Outlier); (b) Ground-Truth (Inlier); (c) VAE-L2; (d) VAEGMM; (e) CVAE; (f) CCVAE; (g) CLSVAE-NODC;(h) CLSVAE. The first two rows are inlier examples, the others being outliers. Synthetic-Shapes: 35% noise,50 labels per class (8% of dataset).
Figure 15: Images for model repair (reconstruction), outlier (corrupted) and inlier (uncorrupted): (a) Original(Outlier); (b) Ground-Truth (Inlier); (c) VAE-L2; (d) VAEGMM; (e) CVAE; (f) CCVAE; (g) CLSVAE-NODC;(h) CLSVAE. The first two rows are inlier examples, the others being outliers. Synthetic-Shapes: 45% noise,5 labels per class (0.8% of dataset).
Figure 16: Images for model repair (reconstruction), outlier (corrupted) and inlier (uncorrupted): (a) Original(Outlier); (b) Ground-Truth (Inlier); (c) VAE-L2; (d) VAEGMM; (e) CVAE; (f) CCVAE; (g) CLSVAE-NODC;(h) CLSVAE. The first two rows are inlier examples, the others being outliers. Frey-Faces: 35% noise, 10labels per class (2.5% of dataset).
Figure 17: Images for model repair (reconstruction), outlier (corrupted) and inlier (uncorrupted): (a) Original(Outlier); (b) Ground-Truth (Inlier); (c) VAE-L2; (d) VAEGMM; (e) CVAE; (f) CCVAE; (g) CLSVAE-NODC;(h) CLSVAE. The first two rows are inlier examples, the others being outliers. Frey-Faces: 35% noise, 50labels per class (12.7% of dataset).
Figure 18: Images for model repair (reconstruction), outlier (corrupted) and inlier (uncorrupted): (a) Original(Outlier); (b) Ground-Truth (Inlier); (c) VAE-L2; (d) VAEGMM; (e) CVAE; (f) CCVAE; (g) CLSVAE-NODC;(h) CLSVAE. The first two rows are inlier examples, the others being outliers. Frey-Faces: 45% noise, 10labels per class (2.5% of dataset).
Figure 19:	Images for model repair (reconstruction), outlier (corrupted) and inlier (uncorrupted): (a) Original(Outlier); (b) Ground-Truth (Inlier); (c) VAE-L2; (d) VAEGMM; (e) CVAE; (f) CCVAE; (g) CLSVAE-NODC;(h) CLSVAE. The first two rows are inlier examples, the others being outliers. Fashion-MNIST : 35% noise,10 labels per class (0.25% of dataset).
Figure 20:	Images for model repair (reconstruction), outlier (corrupted) and inlier (uncorrupted): (a) Original(Outlier); (b) Ground-Truth (Inlier); (c) VAE-L2; (d) VAEGMM; (e) CVAE; (f) CCVAE; (g) CLSVAE-NODC;(h) CLSVAE. The first two rows are inlier examples, the others being outliers. Fashion-MNIST : 35% noise,50 labels per class (1.28% of dataset).
Figure 21:	Images for model repair (reconstruction), outlier (corrupted) and inlier (uncorrupted): (a) Original(Outlier); (b) Ground-Truth (Inlier); (c) VAE-L2; (d) VAEGMM; (e) CVAE; (f) CCVAE; (g) CLSVAE-NODC;(h) CLSVAE. The first two rows are inlier examples, the others being outliers. Fashion-MNIST : 45% noise,10 labels per class (0.25% of dataset).
Figure 22:	Entropy of ground-truth training data (clean: without corruption) VS the entropy of corrupted trainingdata (as in Table 1). Entropy estimation via IWAE (Burda et al., 2016), using a standard VAE (not regularized).
