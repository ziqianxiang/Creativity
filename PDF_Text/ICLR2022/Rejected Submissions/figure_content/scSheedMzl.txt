Figure 1: Above we visualize for theIRIS dataset the Coefficient Inconsis-tency (CI) (see Section 5 for exact def-inition and setup details) between theexplanation (top two features) for an ex-ample and its nearest neighbor in thedataset. Each circle denotes an exam-2 Related WorkPosthoc explanations can typically be partitioned into twobroad categories global and local. Global explainabil-ity avers to trying to understand a black-box model at aholistic level where the typical tact is knowledge transferple and a rainbow colormap depicts thedegree of inconsistency w.r.t. its nearestneighbor where red implies least incon-sistency, while violet implies the most.
Figure 2: Sample results using FMNIST dataset for two classes. (a-c): Class Dress, (d-f): ClassSandal. (a, d): MeLIME explanations. (b, d): LINEX explanations. (c, f): Original images. Weobserve that LINEX explanations capture important artifacts and thus exhibit significantly highercorrelation with the original images, where in aggregate too the correlations are high w.r.t. imagesbelonging to a particular class, thus showcasing higher stability (i.e. high CAC) as is seen in Table 3.
Figure 4: Coefficient inconsistency (CI) vs. Perturbation neighborhood size.
Figure 5: Class attribution consistency (CAC) vs. Perturbation neighborhood size.
Figure 6: Unidirectionality (Y) vs. Perturbation neighborhood size.
Figure 7: Generalized infidelity (GI) vs. Perturbation neighborhood size.
Figure 8: Infidelity (INFD) vs.
Figure 9: Coefficient inconsistency (CI) vs. Number of environments.
Figure 11: Unidirectionality (Υ) vs. Number of environments.
Figure 12: Generalized infidelity (GI) vs. Number of environments.
Figure 13: Infidelity (INFD)(a) Iris(b) MEPS(c) FMNIST (random)0 0350003750.03250.03«0.02750.0225-⅛0.100.120.04-0.02-0.00-Number of environments2.0	2.53.5 4.0 4.5(d) FMNIST (realistic)2.0	2.5	3.0	3.5	4.0	4.5	5-0
Figure 14: Unidirectionality (Υ) vs. Kernel width.
Figure 16: Class attribution consistency (CAC) vs. Kernel width.
Figure 18: Infidelity (INFD) vs. Kernel width.
Figure 19: Results using individual samples for realistic perturbations for FMNIST dataset for allclasses:1-10 (T-shirt/top, Trouser, Pullover, Dress, Coat, Sandal, Shirt, Sneaker, Bag and Ankle boot).
Figure 20: Results using realistic perturbations for FMNIST dataset with mean feature importancesfor all classes:1-10 (T-shirt/top, Trouser, Pullover, Dress, Coat, Sandal, Shirt, Sneaker, Bag and Ankleboot). (a) Mean feature attributions of all images in the class using MeLIME. (b) Mean featureattributions of all images in the class using LINEX. (c) Mean of all images in the class. The r valuesshow Pearson’s correlation between average feature attributions and mean of the original imagesfrom the respective classes. We observe that LINEX explanations/attributions exhibit significantlyhigher correlation with the original images belonging to a particular class (i.e. high CAC).
Figure 21: Error analysis for a chosen set of examples in FMNIST using MeLIME and LINEX/realmethods. The three columns are the MeLIME feature attributions, LINEX/real feature attributions,and the original images. The rows correspond to different examples. We show the Pearson’scorrelation coefficient between feature attributions and mean of the original images from the respectiveclasses (r) and instance-level infidelity (INFD) measures. LINEX seems to highlight importantfeatures like stripes in the t-shirt, handles of the bags, outlines of the boots/shoes more prominently,while MeLIME seems to overfit to the data while missing out on highlighting some key featuresprominently.
