Figure 1:	A depiction of the generative model of data curation, with S = 3. Annotators are in-structed to classify images as trains or buses. The left-hand image is clearly a train, so the annotatorsagree and consensus is reached. The middle image is clearly a bus, so annotators agree and consen-sus is reached. The right-hand image, however, is ambiguous or even has an ill-defined class label.
Figure 2:	GraPhical models under consideration. The observed variables are highlighted in red. AThe generative model for standard suPervised learning with no data curation. Note that the label,YsuP ∈ Y , only takes on values in the label set, so it differs from our label, Y , which could alsobe None. B The generative model for standard suPervised learning, omitting the label. Under thismodel P (θ∣X) reduces to P (θ) (see Sec. 2.3). C The generative model with data curation forlabelled Points, note that if there is consensus, Y ∈ Y and if there is no consensus, Y = None. DThe generative model with data curation for unlabelled Points. C is a random variable rePresentingwhether or not consensus was reached, so we have C = 1 if consensus was reached (i.e. Y ∈ Y)and C = 0 if consensus was not reached (i.e. Y = None). Critically, C acts as a “label”, sothe posterior over parameters, P (θ∣X, C), does not reduce to P (θ), unlike in the case of standardsuPervised learning when we omit the label (Panel B).
Figure 3: Our generative model of data curation applied to a simple 2D dataset. Data from eachclass was sampled from a different Gaussian, and the true decision boundary (green dashed line)was given by the posterior probability of class given (x0, x1). A Datapoints far from the decisionboundary are unambiguous, so annotators agree and consensus is reached (red and blue points).
Figure 4: A. A toy dataset generated to illustrate the dangers of using the clustering of the inputpoints to inform classification boundaries. The input features, x0 and x1 are plotted on the x and y-axes and the class is represented by colour. B. A schematic diagram demonstrating the effect of ourprincipled likelihood incorporating data-augmentation on the certainty of predictions for differentdegrees of invariance. More invariant NNs (left) give similar predictive distributions for differentaugmentations (blue), and hence a certain averaged predictive distribution (bottom; orange). Lessinvariant NNs (right) give different predictive distributions for different augmentations (blue), andhence highly uncertain averaged predictive distributions (bottom; orange).
Figure 5: Test log-likelihood and accuracy for Langevin sampling for Bayesian SSL on toy datasetssampled from the model as a function of the number of unlabelled points.
Figure 6: Test log-likelihood and error for curated and uncurated GZ2 datasets as a function of thenumber of unlabelled points. Exact corresponds to Eq. (18) (which is exact in the limit as K → ∞)and pseudo corresponds to the pseudo labelling version of the augmented objective (Eq. 19).
