Figure 1: Difference between (a) spherical Gaussian belief states and (b) true belief states (Betterviewed in color).
Figure 2: The PGM ofPOMDP2Under review as a conference paper at ICLR 2022sum of discounted rewards E [Pt∞=0 γtrt]. Such a POMDP model can also be described as a proba-bilistic graphical model (PGM) as shown in Figure 2. After having taken action at-1 and observingot , an agent needs to update its belief state, which is defined as the probability distribution of theenvironment state conditioned on all historical information:b(st) = p(st | τt, ot)	(1)where τt = {o1, a1, . . . ,ot-1, at-1}.
Figure 2:State transition model : P(st|st-1, at-1)Observation model : P(ot |st)	(6)Reward model : P(rt |st )3Under review as a conference paper at ICLR 2022In addition, We have a belief inference model q(st∖τt, ot) to approximate the true posterior distri-bution p(st∣τt, ot), where Tt = {oι,αι,..., ot-ι,at-ι} is the past information. The above com-ponents of FORBES can be optimized jointly by maximizing the Evidence LoWer BOund (ELBO)(Jordan et al., 1999) or more generally the variational information bottleneck (Tishby et al., 2000;Alemi et al., 2016):log p(o1:T, r1:T |a1:T)T≥ Eq(s1:T |o1:T,a1:T -1)	(lnp(ot|st) + lnp(rt|st) - DKL(q(st|st-1, at-1, ot)kp(st |st-1, at-1)))t=1T=	Eq(st|st-1,at-1,ot)(lnp(ot|st) + lnp(rt|st))-t=1Eq(st-1 |st-2 ,at-2 ,ot-1 ) (DKL (q(st |st-1 , at-1 , ot)kp(st |st-1 , at-1 ))) = JModel(7)
Figure 3: The algorithm framework of FORBES. Figure 3a shows how to calculate prior and poste-rior belief distribution given previous information. The blue arrows bring in historical observationsand actions, and the green path shows the evolution of prior belief distribution. The red path takesan additional ot and shows the evolution of posterior belief distribution. Figure 3b shows predictionof future trajectories given the future actions.
Figure 4: Predictions on sequential MNIST of two models.
Figure 5: ELBO on digit writ-ingprediction is clear and distinct from other digits. Given the beginning of the digit 7, FORBES suc-cessfully predicts both 7 and 3 since they have a similar beginning. The results can be partiallyexplained via the mixed-up belief and the empty belief as shown in Figure 1, which support theclaim that FORBES can better capture the complex belief states.
Figure 6:	Performance on DeepMind Control Suite. The shaded areas show the standard deviationacross 3 seeds. FORBES achieves better performance and sample efficiency in various challengingtasks.
Figure 7:	Comparison of the performance between FORBES and Dreamer with multiple imaginedtrajectories.
Figure 8:	An ablation study on the effect of different N on DMC environments.
Figure 9:	The training curve on DMC environment for 1M environment steps.
Figure 10: An ablation study on the effect of adding parameters to Dreamer on two DMC environ-ments.
Figure 11: The ELBO of FORBES and RSSM.
Figure 13: The reconstruction results on of FORBES six environments from DeepMind ControlSuite(Tassa et al., 2018).
