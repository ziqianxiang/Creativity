Figure 1: Our proposed framework for predicting NN performance in a downstream image classification task,shown for one test instance. The input to our framework is an NN trained for a few epochs (3, in this example).
Figure 2: Unrolled graph representation example. Thetwo typed nodes in the resultant bipartite graph map tothe filtration operation and the output. For the stride inthis example, the output node o1 (in dark blue) is theoutput of 4 operation-typed nodes (in light blue).
Figure 3: Rolled graph representation example.
Figure 4: CIFAR-10: NN performance classification for different NN architectures, graph representations, andfeatures for the temporal signatures. Shorthands: ‘deg’ for degree-based and ‘evec’ for eigenvector centrality-based temporal signature. (a)-(d): Accuracy based on weighted degree-based signature vectors for both therolled and unrolled graph representations. Our rolled graph representation is as effective as the unrolledrepresentation in predicting the image classification performance of NNs, while being significantly more efficient.
Figure 5: ImageNet: NN classification using theweighted degree-based and eigenvector centrality-basedsignature vectors for LeNet, AlexNet and ResNet. Eigen-vector centrality-based signatures (b), (d), (f) yieldhigher performance compared to the weighted degree-based signatures (a), (c), (e).
Figure 6: Average total runtime for the NN training, and the rolled/unrolled graph generation (S1) and featureextraction (S2) on CIFAR-10 dataset ((a)-(c)), ResNet architecture on both CIFAR-10 (ResNet-44) and ImageNet(ResNet-50)(d). Rolled graph representation is more efficient/faster than early stopping to generate graph andcalculate signature vector for all the architectures.
Figure 7: VGG on CIFAR-10: (a) The top three most important features in SVM classification are the mean,stdev, and median of the node degrees. (b) The change of the average node degree over time shows that, ingraphs corresponding to high-accuracy NNs (blue lines), the average degree exhibits an increasing pattern, whileit has a flat pattern for low-accuracy cases (red lines). The few cases of low-accuracy NNs with increasing trendmay be miss-classified in the classification task. (c) (d) The changes of the standard deviation and median ofnode degrees follow a similar pattern to mean for both low- and high-accuracy cases.
Figure 8: LeNet on CIFAR-10: (a) The top three most important features in SVM classification are the mean,standard deviation and median of the node degrees. (b)(d) The change of average node degree over time showsthat in graphs corresponding to high-accuracy NNs (blue lines) the average degree tends to change over timewith a smooth pattern, while it tends to follow a flat line pattern (after an early extreme spike) for low-accuracycases (red lines).
Figure 9: ReNet-44 on CIFAR-10: (a) The top three most important features in SVM classification are the mean,standard deviation and median of the node degrees. (b)(d) The change of average node degree over time showsthat in graphs corresponding to high-accuracy NNs (blue lines) the average degree tends to change over timedrastically, while it tends to follow a flat line pattern for low-accuracy cases (red lines).
Figure 10: NN classification based on degree signatures for the empirical setup that tests generalization to unseenarchitectures. (a) Train on ResNet-32, test on ResNet-44. (b) Train on ResNet-34, test on ResNet-50. (c)-(d)Train on LeNet, AlexNet and VGG, test on ReNet-32 and ResNet-44, respectively. Our proposed framework isable to accurately predict the performance level on previously unseen architectures based on the NN structuraldynamics in a small number of epochs (<10).
Figure 11: CIFAR-10: NN classification based on eigenvector centrality-based signatures. The eigenvectorcentrality is a strong predictor of NN performance after observing a few epochs of training. The MLP classifier(red lines) outperforms SVM for all the architectures.
Figure 12: CIFAR-10, ResNet-32: NN classification based on degree and eigenvector centrality-basedsignatures. The both degree and eigenvector centrality are strong predictor of NN performance after observing afew epochs of training.
