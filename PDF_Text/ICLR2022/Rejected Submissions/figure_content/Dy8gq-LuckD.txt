Figure 1: The multi-modal DNN with in-termediate fusion that we study in thiswork. Blue and red blocks represent thetwo uni-modal networks learning frommodalities mo and mi. The fusion lay-ers are marked with green, green-blue, andgreen-red. The predictions from the twouni-modal branches are denoted by yo andyi. We denote the average of the two by ywhich is the model,s prediction.
Figure 2: Histograms and estimateddensity functions of dutil and dspeedof models trained using ModelNet40(top) or NVGesture (bottom). Wemark zero and E[dutil] with dashedlines. Many models have high dutil .
Figure 3: The observed | dutil | and | dspeed | for models trained with different weights (λ) on the L1regularizer. Left: | dutil| and | dspeed | as a function of log(λ). Middle: | dutil| increases along R(f).
Figure 4: Histograms and esti-mated denSity functionS of dutilof modelS trained uSing theguided and the vanilla algorithm.
Figure 1: (a) The Colored MNIST dataset (Kim et al., 2019). We consider the monochromatic image,and the gray-scale image as the two input modalities (b) The ModelNet40 dataset (SU et al., 2015).
Figure 2: Histograms and estimated density functions of dutil and dspeed of models trained forcolored-and-gray-MNIST, using monochromatic and gray-scale images as two modalities, usingidentical monochromatic images as two modalities and using identical gray-scale images as twomodalities.
Figure 3: The imbalance in utilization, measured by dutil for models trained using different learningrate. It appears that high learning rates can help with mitigating the imbalance in utilization betweenmodalities.
Figure 4:	The mean and standard deviation of R(f) for three model repetitions obtained by trainingthe model with λ as the weight on the L1 regularization. Generally, the larger the λ is, the higher theR(f) is, i.e., the sparser the model’s parameters are.
Figure 5:	Models’ behavior when using different values for the re-balancing window size Q in thebalanced multi-modal training algorithm. We use ModelNet40 (front and rear views) in the study. Wefix the learning rate at 0.1 and the imbalance tolerance parameter at 0.01 while using Q of 1, 5, 10,20 and 50. We can effectively control the imbalance in conditional utilization except for Q = 50 (seedutil shown in the left panel). According to the accuracy the model reaches, we choose to use Q = 5.
Figure 6:	Models’ behavior when using different values for the imbalance tolerance parameter αin the balanced multi-modal training algorithm. We use ModelNet40 (front and rear views) in thestudy and fix the learning rate at 0.1 and the re-balancing window size at 5. The values we use forα are ratios of E(dutil) computed in the study in §5.2. Precisely, we use 0.01E(dutil), 0.1E(dutil),0.25E(dutil), 0.5E(dutil), E(dutil). Based on the pattern of dutil shown in the left panel, using lessthan 0.25 of E(bdutil) gives desirable results. We choose to use α = 0.1E(bdutil) = 0.01 according tothe accuracy.
Figure 7: Histograms and estimated density functions of dutil for random version of the balancedmulti-modal learning process and the vanilla process. Both versions of the balanced multi-modallearning process are less greedy than the vanilla one.
