Figure 1:	An example of the multi-hop questions in HOTPOTQA.The the supporting facts inblue.The red area is an entity that is highly relevant to the question.
Figure 2:	a example of attention mechanism Figure 3: a example of semantic relational tablePeople can identify the supporting factors in the paragraph and give a detailed explanation of thejudgment result. We argue that the more specific the semantic interpretation, the more helpful themodel imitates the human reasoning process. The input of the most recent model is Pre-trainedembeddings, which have the advantage of capturing semantic similarity, but it is hard to explainin detail. We believe that the model uses interpretable features for reasoning, which contributes toenhanced interpretability. Recently, the attention mechanism has achieved remarkable performanceon many natural language processing tasks. The model of attention mechanism learns the relevancebetween words through training(Figure 2). Inspired by the attention mechanism, for establishingrich and interpretable semantic features, we propose the semantic relational table(Figure 3).
Figure 4: q_feature,tFigure 6: a_feature,tThe question_feature_table (Figure 4) shows the distribution of the semantic structure informationof the question sentence. ”Who” does not appear in the figure due to it is regarded as a stop word.
Figure 6: a_feature,tThe question_feature_table (Figure 4) shows the distribution of the semantic structure informationof the question sentence. ”Who” does not appear in the figure due to it is regarded as a stop word.
Figure 9: SentLfeatUre_a_tThe question_feature_sent1 .table (Figure 7) and The sent1 feature_question_table (Figure 8) denotesthe semantic relationship between the problem and the target sentence.
Figure 13: There are 9 semantic role relation tables. In this figure, we use two tables of a sentencesize. Each sentence contains three verbs, and each verb has 25 corresponding semantic role tags.
Figure 14: case studies4	Related Work4.1	Supporting factSupporting factors is useful and becomes an important component in multiple-choice reading com-prehension (Wang et al., 2019), natural language inference (Chen et al., 2017), open-domain ques-tion answering (Lin et al., 2018). Following HotpotQA , several benchmarks on open-domain taskshave gradually refined the supporting facts annotation, whose benefits have been demonstrated interms of interpretability, bias, and performance (Dua et al., 2020; Inoue et al., 2020).
