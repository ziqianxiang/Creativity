Figure 1: Proposed forward-backward network can be utilized in unwarping or editing the surfacetexture: The flattened texture can be edited and warped back to produce a texture edited image.
Figure 2: Proposed surface parameterization learning using the forward (FUv) and backward MLP(Fz): Given camera pose T, and a pixel P wejointly learn the geometry represented by a SDF ZÎ¸ , theFuv, and the Fz. Zp is the ray-surface intersection point in 3D domain and tp is the correspondingtexture coordinate in UV domain. The yellow arrows denote the input and output of the IDR (YariVet al., 2020), and Cp is the predicted RGb color. Triangles denote the losses defined in Eq. 12.
Figure 3: Without a prior the for-ward network, Fuv leads to degen-erate cases: multiple 3D points, Zpare mapped to the same texture co-ordinate tp .
Figure 4: Qualitative comparison with DewarpNet (Das et al., 2019): (a) Input image, (b) Dewarp-Net unwarping, (c) proposed unwarping, (d) GT scanned image, (e) enlarged regions: DewarpNet(top), and proposed (bottom). We use reasonable frontal view of the document for a fair comparison.
Figure 5: Comparison of DeWarPNet (a,c,e) With the proposed unwarped result (b,d,f) for the VieWthat yields the best LD with DewarpNet. Proposed results are clearly better, however this improve-ment is not captured by LD. FolloW the blue dashed boxes for discrimitative regions.
Figure 6: Illustration of weighted Lz , and conformality effects: b is for the model trained withoutconformality constraints and with Wp = 1; w is for weighted Lz and c is for the use of conformalityconstraints. GT is the ground-truth scan. The number in parenthesis denote the respective LD values.
