Figure 1: Executability v.s. semantic correctness of generated action plans (left) and sample action plans gen-erated by different models (right). Large models can produce action plans indistinguishable from plans createdby humans, but frequently are not executable in the environment. Using our techniques, we can significantlyimprove executability, albeit at the cost of correctness.
Figure 2: We investigate the possibility of extracting actionable knowledge from pre-trained language mod-els without any additional training. We first show surprising finding that large language models (LLMs) candecompose high-level tasks into sensible low-level action plans (left). To make the action plans executable,we propose to translate each step into admissible action via another LLM (middle). The translated action isappended to the original prompt used for generating the remaining steps (right).
Figure 3: Visualization of VirtualHome programs generated by our approach. The top row shows the execu-tion of the task “Complete Amazon Turk Surveys”, and the bottom row shows the task “Get Glass of Milk”.
Figure 4: An example prompt containing step-by-step instructions.
