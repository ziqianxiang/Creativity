Figure 1: Motivating the effect of planning for HPO.
Figure 2: Architecture of the transitionfunctionEd-pd^ log ^Θ (S(D), a)2	('(D)(a)- μθ(S(D) ,a))2+	26θ (S(D),a)2+ ct .
Figure 3: Simulated Trajec-tory rewards. MPC selects thefirst item. LookAhead MPCselects the third item.
Figure 4: (top) Investigating the impact of planning and LookAhead across different horizons; (bot-tom) Increasing the number of sampled trajectories improves planning (solid lines→ 1000 trajecto-ries vs. dashed lines → 100 trajectories).
Figure 5: Investigating the performance of MPC under various dynamics.
