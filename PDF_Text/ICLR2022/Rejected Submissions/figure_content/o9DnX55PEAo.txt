Figure 1: The bidirectional CMOW component of our proposed architecture during pretraining.
Figure 2: Seperate encoding (DiffCat) for sequence pairs using a Bidirectional CMOW/CBOW-Hybrid model during fine-tuning, optionally, with task-specific distillation with a BERT teacher.
Figure 3: All considered for embeddings and downstream classifiers, pretraining and fine-tuning.
