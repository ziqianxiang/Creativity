Figure 1: An illustration of our version of the Halevi-Shoup method that utilises a padding method.
Figure 2: Comparison of LoLa's matrix-vector product methods with the Halevi-Shoup approach,in terms of the number of rotations required for computing a fully-connected layer from n inputs tom outputs.
Figure 3: The architecture used in LoLa. k indicates the kernel size and s indicates the stride ofconvolution and pooling. Note that the original 28 Ã— 28 input is padded.
