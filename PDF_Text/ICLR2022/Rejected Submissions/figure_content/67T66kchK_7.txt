Figure 1: Protocol of Self-Imitation Policy Learning through Iterative Distillation (SPLID) in the practicalimplementation (Algorithm 2).
Figure 2: Three goal-oriented tasks involved in this paper.
Figure 3: Test performance (Success Rate) of SPLID (our proposed method), GCSL, PCHID, HER, ES, andSPLID without SELECT function. Results are averaged under 5 random seeds.
Figure 4: Ablation study on learning horizon H.
Figure 5: Ablation study on exploration factor Ïƒ.
Figure 6: Average Return of SPLID and SPLID w/o SELECT function on Fetch environments. Results areaveraged under 5 seeds.
Figure 7:	Three new environments: Point2D Four Rooms, Sawyer Door, and Reacher.
Figure 8:	Average Return of SPLID and GCSL on three new environments. Results are averaged under 5 seeds.
Figure 9:	Success Rate of SPLID and GCSL on three new environments. Results are averaged under 5 seeds.
