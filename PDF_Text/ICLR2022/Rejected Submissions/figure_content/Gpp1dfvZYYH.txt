Figure 1: An overview of ProgFed on (a) feed-forward networks and (b) U-nets (Symmetric). We progressivelytrain a deep neural network from the shallower sub-models, e.g. M1 consisting of main block E1 and head G1(Eq. 2), gradually expanding to the full model MS = M (Eq. 1). Note that the local heads Gi in feed-forwardnetworks are only used for training sub-models and discarded when progressing to the next stage.
Figure 2: Accuracy (%) vs. GFLOPs on CIFAR-100 in the centralized setting.
Figure 3: Computation cost reduction at {98%, 99%,99.95%, best} compared to the baseline (training fullmodels) performance in the centralized setting.
Figure 4: Communication cost reduction at {98%,99%, 99.95%, best} compared to the baseline perfor-mance in the federated setting.
Figure 5: Communication cost vs. Accuracy (%) in federated settings on EMNIST (3400 clients, non-IID),CIFAR-10 (100 clients, IID), CIFAR-100 (500 clients, non-IID), and BraTS (10 clients, IID).
Figure 6: Relative performance vs. communication cost reduction with federated ResNet-18 on CIFAR-100with (a) modest compression and (b) intensive compression.
Figure 7: Norm discrepancy.
Figure 8: Performance vs. computation costs and Performance vs. epochs when comparing our method todifferent updating strategies.
Figure 9: Accuracy (%) vs. Epochs on CIFAR-100 in the centralized setting.
Figure 10: DICE (%) vs. computation costs on BraTS.
Figure 11: Computation acceleration at different percentage of performance. The orange bar indicates the bestperformance of our method.
Figure 12: Computation cost reduction at {50%, Figure 13: Communication cost reduction at {50%,60%, 70%, 80%, 90% 98%, 99%, 99.95%, best} of 60%, 70%, 80%, 90% 98%, 99%, 99.95%, best} ofthe baseline performance in the centralized setting. the baseline performance in the federated setting.
Figure 14: Accuracy vs. computation costs and accuracy vs. epochs in the federated setting. (a)(b)(c) shows theresult for three classification tasks; (d) shows the result for the segmentation task, where two update strategiesSymmetric and Asymmetric are adopted for 3D-Unet.
Figure 15: Communication cost reduction at different percentage of performance. The orange bar indicates thebest performance of our method.
Figure 16: Visualization of federated segmentation. From left to right: Input, Ground Truth, Baseline, Asym-metric, and Symmetric updating strategies. Despite the comparable performance, Symmetric consumes signifi-cantly fewer communication costs.
Figure 17: Segmentation results under {≈ 0.18%, ≈ 9.40% , ≈ 36.40%} of communication costs of theconverged baseline. From top to bottom: baseline, Asymmetric (Ours), and Symmetric (Ours). Only Symmetriccan achieve 0.18% (6.7536 MB) compression ratio, since the size of the other models is already around 34 MB(i.e. 0.908%).
