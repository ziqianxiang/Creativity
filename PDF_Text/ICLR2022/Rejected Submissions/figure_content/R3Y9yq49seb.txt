Figure 1: Comparison between standard quantization and our (joint-channel) wavelet compression.
Figure 2: The workflow of WCC. From Left to right: the input channels, their Haar transform, thejoint shrinkage of the 2D Haar representation into equal sized 1D vectors and a single bit-map (or alist of indices), the application of the 1 Ã— 1 convolution on the 1D vectors, and lastly on the right: theinverse transform back to the spatial domain. Here, the shrinkage ratio is set to 0.1.
Figure 3: Feature maps from layers 2 and 3 (top and bottom triplets, respectively) of a pretrainedResNet50 on ImageNet. The maps are compressed with uniform quantization (2-bit) and waveletcompression (25% shrinkage + 8-bit quantization, equivalent to 2-bit quantization in terms of size). Itis clear that wavelet compression loses much less information than aggressive quantization.
Figure 4: Cityscapes segmentation results. All the networks use weight quantization of 8-bits. (a)input image. (b) ground truth. (c), (d) normal quantization with 8- and 4-bits activations respectively.
Figure 5: Kitti depth estimation prediction examples. We compare two compressed networks withthe same BOP magnitude, the first uses our wavelet compression method and the second uses low-bitquantization.
