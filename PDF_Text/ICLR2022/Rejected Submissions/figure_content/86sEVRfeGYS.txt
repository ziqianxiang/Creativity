Figure 1: The input and targetfunction generating the outputin the Bit-Flipping problem.
Figure 2: Target selection inSemi-stationary Reacher is atwo-step process. First, oneof the 100 sub-squares is se-lected for 30 episodes. Sec-ond, for each episode, a newtarget point is randomly se-lected inside the current sub-square. Here, the target is se-lected from sub-square (2,8).
Figure 3: The learning curve on the Bit-Flipping problemusing Backprop. Surprisingly, after performing well ini-tially, the error goes up for all step-sizes and activation func-tions. Backprop’s ability to track becomes worse under ex-tended tracking on the Bit flipping problem. For Relu, itsperformance gets even worse than the linear learner.
Figure 4: The online classificationaccuracy of a deep ReLU-networkon Permuted MNIST. The onlineaccuracy is binned among bins ofsize 60,000. The performance ofBackprop gets worse over time forall step-sizes, meaning that Back-prop loses its ability to adapt underextended tracking.
Figure 5: A feature/hidden-unit in a network. The util-ity of a feature at time tis the product of its contri-bution utility and its adapta-tion utility. Adaptation util-ity is the inverse of the sum ofthe magnitude of the incom-ing weights. And, contribu-tion utility is the product ofthe magnitude of the outgo-ing weights and feature acti-vation (hl,i) minus its average(fl,i). fl,i is a running averageof hl,i.
Figure 6: The learning curves and parameter sensitivity plots of Backprop(BP), Backprop with L2,Backprop with Online Normalization, and Continual Backprop (CBP) on the Bit-Flipping problem.
Figure 7: The online classifica-tion accuracy of various algorithmson Permuted MNIST. The perfor-mance of all algorithms exceptCBP degrade over time. CBPmaintains a good level of perfor-mance for a wide range of replace-ment rates, ρ.
Figure 8: Evolution of the meanmagnitude of the weights in thelast layer with various learningalgorithms on Permuted MNIST.
Figure 9: Performance of PPO, PPO+L2, and Continual-PPO on non-stationary RL problems. In both problems, theperformance of PPO degraded rapidly. In contrast, the per-formance of Continual-PPO and PPO+L2 either degradedslowly or remained at a high level.
Figure 10: Learning curve of BP on the Bit-Flipping problem for various activation functions usingSGD. After performing well initially, the performance of Backprop gets worse over time for allactivation functions.
Figure 11: SGD with a smaller step-size on the Bit-Flipping problem. After running for 1M steps inFigure 3, it may seem that performance for step-size of 0.001 does not worsen over time. However,after running the experiment for longer, 5M steps, we found that the error for step-size of 0.001either increases significantly or remains significantly higher than larger step-sizes.
Figure 12: The learning curve on the Bit-Flipping problem using Adam. Again, after performingwell initially, the error goes up for all activation function. Backprop’s ability to track becomes worseunder extended tracking even with Adam.
Figure 13: Adam with a smaller step-size on the Bit-Flipping problem. Like SGD, after running for1M steps in Figure 11, it may seem that the performance for step-size of 0.001 does not worsen overtime. However, after tracking for 5M examples, the error for step-size of 0.001 increase too.
Figure 14: Parameter sweep and online performance of various learning algorithm using SGD forstep-size of 0.01 on the Bit-Flipping problem. Only CBP and BP+L2 are suitable for continuallearning, the performance of all the other algorithms degrade over time. For all activation functions,CBP and BP+L2 perform significantly better than BP for almost all values of hyperprameters. CBPis less sensitive to its hyperparameter than BP+L2.
Figure 15: The learning curves of Backprop(BP), Backprop with L2(BP+L2) and Continual Back-prop (CBP) on the Bit-Flipping problem using Adam with step-size of 0.01. Both BP+L2 and CBPare performed robustly on this problem as their performance did not degrade over time. The bestparameters for CBP and BP+L2 are chosen separately for each activation. For all activations, CBPis either significantly better than BP+L2 or just slightly worse.
Figure 16: Parameter sweep for CBP and BP+L2 when used with Adam for step-size of 0.01 onthe Bit-Flipping problem. Again, for all activation functions both CBP and L2 perform significantlybetter than BP for most values of replacement-rate and weight-decay. For some activations likeSigmoid and ELU, BP+L2 performs better than CBP, while for other activations like ReLU andLeaky-ReLU, CBP performs better than BP+L2.
Figure 17: CBP with different utility measures on different problems•	Overall utility, u ,at every time-step is updated as described in Equation 5Next we compared the two best performing utility measures, overall and mean-corrected contribu-tion, on Slippery Ant. The results are presented in Figure 17b. The results show that both utilitymeasures perform significantly better than PPO. But, the overall utility performs significantly betterthan the other utility measure. This difference in more pronounced near the end, when ContinualPPO with the overall utility measure performs almost as well as it did at the beginning.
Figure 18: The online classification accuracy ofa deep ReLU-network on Permuted MNIST withdifferent speeds of distribution change. The timeafter which the distribution changes varies from10k to 1M. The online accuracy is binned amongbins of size 1M. It shows that the speed of the de-cay in performance increases with the increase inthe speed of distribution change.
Figure 19:	Evolution of feature saturation and the gradient of the input weights for various learningalgorithms.
Figure 20: The online classification accuracy ofdeep ReLU-networks with different widths onPermuted MNIST The distribution changes afterevery 60k examples, and the online accuracy isbinned among bins of size 60k. It shows that thespeed of the decay in performance is larger forsmaller network.
