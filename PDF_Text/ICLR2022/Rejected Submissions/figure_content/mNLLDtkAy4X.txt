Figure 1: AMAs can learn to ignore stochastic transitions. (a) Example transitions from the NoisyMNIST environment along with associated predictions. The top two rows show stochastic transitionswhere AMA,s predicted variance is high in the majority of the image allowing intrinsic reward to besmall despite the stochastic transition. (b) Two reward curves for MSE and AMA are plotted wherestochastic is the 1 → {2, ..., 9} transitions and deterministic is the 0 → 0 transitions.
Figure 2: AMA agents effectively explore sparse reward minigrid environments that contain actiondependent stochastic traps. (C) and (d) panel show performance on the easiest environment, containingfour rooms, while the (a) and (b) show performance on a more challenging environment with six rooms.
Figure 3: Pixel AMA performs significantly better than all baselines With a noisy TV (a) and (C) andwithout the distracting noisy TV AMA nearly matches its most directly comparable method PixelMSE (b) and (d). No extrinsic rewards were used for policy optimisation. In Mario distance coveredand extrinsic reward are equivalent. The y-axis plots extrinsic rewards per episode.
Figure 4: Pixel AMA performs significantly better than all baselines with a noisy TV (a) and (C) andwithout the distracting noisy TV AMA nearly matches its most directly comparable method PixelMSE (b) and (d). No extrinsic rewards were used for policy optimisation. In Mario distance coveredand extrinsic reward are equivalent. The y-axis plots extrinsic rewards per episode.
Figure 5: Predictions on a theoretical experiment to illuminate the epistemic or aleatoric nature ofcholinergic signalling in the brain. (a) and (b) show that the epistemic model predicts acetycholinewill eventually decrease in both zones while the aleatoric model predicts acetylcholine decreasingto zero in the stable zone but remaining high in the noisy zone. Panel (c) shows our 1D model ofthe proposed animal experiment where the bandit samples different 'corridor positions, and receivesscalar stimuli, which it is trying to predict-using the resulting prediction errors as intrinsic rewards.
Figure 6: MNIST image to image architecture. For the MSE network the second log variance branchwas discarded. A skip connection was provided from the input to the final layer for both AMA andMSE.
Figure 7: Actor critic architecture for the policy network in the minigrid experiments.
Figure 8: Curiosity forward prediction architecture for the minigrid experiments. For the MSEbaseline the variance predictions are not used and loss is computed via a standard MSE.
Figure 9: AMA prediction network for bandit tasks.
Figure 10: Epistemic prediction network for the bandit task.
Figure 11: Four examples of frames that an agent might see when interacting with the CIFAR noisyTv This is a complex noise distribution picked to test the limits of the heteroScedaStic aleatoricuncertainty estimation.
Figure 12: AMA is robust to Noisy TVs of a very random unifrom noise distribution (random pixelsfrom 0-255) while other baselines are also trapped by this additional noisy TV that is significantlydifferent to the noise distribution used for the results used in the main text.
Figure 13: Overall, the mario results are not very sensitive to the setting of η.
Figure 14: AS the Uncertainy penalty (λ) increases performance with the noisy TV becomes poor(expected) because higher uncertainty penalty moves AMA more towards a MSE curiosity. Otherwisefor Mario results are not very sensitive to hyperparameter values.
Figure 15: Performance on minigrid is not very sensitive to η but λ requires some tuning.
Figure 16: Repeats ran for more frames on Mario for MSE Pixel curiosity and MSE IDF curiosity.
