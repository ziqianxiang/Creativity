Figure 1: (a) ERM misclassifies samples by spurious background features, visualized With GradCAM (SelVarajUet al., 2017). (b) CNC uses contrastive learning to learn similar representations for same-class samples withdifferent ERM predictions. (c) Resulting models ignore spurious attributes and classify samples correctly.
Figure 2: UMAP visualization oflearned CMNIST* representations.
Figure 3: Accuracy and representation metrics from ERM models trained on increasingly spuriously correlatedColored MNIST. High WorSt-group accuracy corresponds to both I (Y; Z) > I (A; Z) and small alignment loss.
Figure 4: Higher Worst-group accuracy With upsamplingcoincides With keeping I(Y; Z)	I(A; Z).
Figure 5: Alignment loss (a) and mutual information (b, c) of models trained With ERM, JTT, and CNC, onWaterbirds and CelebA. CnC most effectively removes dependence on the spurious attribute, and obtains smallergaps for per-class Worst-group vs. average error (d), as supported by Thm. 3.1.
Figure 6: UMAPs of Waterbirds representations, colored by class (left) and spurious attribute (right). ERMdepends on both classes Y and spurious attributes A, though with greater separability for the latter. JTTrepresentations depend more on Y , but also on A. CNC gets closer to fully removing the dependence on A.
Figure 7: Alignment loss and mutual information representation metrics with worst-group accuracy onincreasingly spurious CMNIST*. CNC highest worst-group accuracy (a) coincides with learning representationswith better alignment (b) and ratio of mutual information dependence on the labels vs the spurious attribute (c).
Figure 8: The two stages of Correct-n-Contrast. In Stage 1, we train a model with standard ERMand a cross-entropy loss. Then in Stage 2, we train a new model with the same architecture, butspecifically learn spurious-attribute-invariant representations with a contrastive loss (3) and batchesof anchors, positives, and negatives sampled with the ERM model’s predictions. We also update thefull model jointly with a cross-entropy loss on the classifier layer output and the input class labels.
Figure 9: Illustration of two-sided contrastive batch sampling with Colored MNIST as an example.
Figure 10: UMAP visualization of ERM data representations for the Waterbirds training data. We visualize thelast hidden layer outputs for a trained ERM ResNet-50 model given training samples from Waterbirds, coloringby either the ERM model’s “standard” predictions, the actual spurious attribute values (included here just foranalysis), and predictions computed by clustering the representations as described above. Clustering-basedpredictions more closely align with the actual spurious attributes than the ERM model outputs.
Figure 11: UMAP visualizations of learned representations for Colored MNIST (a), Waterbirds (b), and CelebA(c). We color data points based on the class label (left) and spurious attribute (right). Most consistently acrossdata sets, CNC representations exhibit dependence and separability by the class label but not the spuriousattribute, suggesting that they best learn features which only help classify class labels.
Figure 13: Additional GradCAM visualizations for the CelebA dataset. For models trained with ERM, JTT, and CNC, we use GradCAM tovisualize the “salient“ observed features used to classify whether a celebrity has blond(e) hair. ERM models interesting also “ignore” theactual hair pixels in favor of other pixels, presumably associated with the spurious gender attribute. In contrast, GradCAMs for JTT and CnCmodels usually depict higher salience for regions that at least include hair pixels. CnC models most consistently do so.
