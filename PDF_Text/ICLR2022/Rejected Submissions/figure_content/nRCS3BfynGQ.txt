Figure 1: Representation of relative distance (left) and angle (right) preserving maps.
Figure 2: Graphical representation of the graph architectures3.1	The starting point - graph network block (GN)A general standard graph network block can be defined in terms of edge, node and global updatesase+i = Φe(vj, vi, eji, u),	∀(j, i) ∈ E (4a)v+ = φv (vi,ρe→v ({e+i}j∈Ni), u),	∀i ∈ V	Gb)u+ = φu(ρv→u({v+}i∈v),ρe→u({e+i}(j,i)∈E), U)	(4c)where φe : R2nv+ne+nu → Rne+, φv : Rnv+ne++nu → Rnv+, φu : Rnv++ne++nu → Rnu+ areupdate functions (usually defined as neural networks whose parameters are to be learned) andρe→v, ρe→u, ρv→u are aggregation functions reducing a set of elements of variable length to a singleone via an input’s permutation equivariant operation like element-wise summation or mean.
Figure 3: Equivariance of the two networks. The green/red square denotes the base graph and theblue/black ones alternative coordinate embeddings, equivariant for the DGN (red) or AGN (green).
Figure 4:	Test accuracy vs samples per polytope in the training set for a standard GNN (n = 3).
Figure 5:	QM9: test MSE loss on the 12 target properties.
