Figure 1: Overview of our proposed method. In our framework, domain specific transformationfunctions {Tj-(∙)}jk=ι and a density model Q are cooperatively trained to make the transformedrepresentations be indistinguishable in the shared latent space. (a) 1-D example. By minimizing ourproposed AUB loss, the transformation functions T1 and T2 are trained to map the correspondingdistributions PX1 and PX2 to latent distributions PT1(X1) and PT2(X2) that have higher likelihoodwith respect to a base distribution Q. The density model Q, on the other hand, is trained to fit themixture of the latent distributions PT1(X1) and PT2(x2). (b) Intuitively, the optimization process ofour method can be seen to make the Q distribution tight around the mixture of latent distributions toincrease the likelihood (i.e., MLE) while the transformation functions T1 and T2 are encouraged toexpand to fill the latent space defined by Q. Eventually, the latent distributions and Q are convergeto be the same distribution, which means that they are aligned.
Figure 2: High-level comparison with the baseline models. AlignFlow, LRMF, and our setup areillustrated in a row from left. Transformation functions in AlignFlow are independently trained tobe fitted to the fixed standard gaussian distribution. T1 in LRMF is aimed to directly map the givenX1 to another image distribution X2 . The density model Q in LRMF is not fixed and learned to fitto {Z1 ∩ X2}. In our setup, T1 and T2 are trained to obtain the high likelihood from the learnable Qdistribution which is fitted to the shared latent distributions. In every setup, the latent distributionsZ1 and Z2 are getting closer to the target distribution as training goes by. Details are provided inSection 3.
Figure 3: Top row is latent space and bottom is the data translated into the other space. (a-c) LRMF,which only has one transformation T may not be able to align the datasets if the density model classQ is not expressive enough (in this case Gaussian distributions) while using two transformations asin our framework can align them. (d-f) AlignFlow (without adversarial terms) may not align becauseQz is fixed at a standard normal, while our approach with learnable mixture of Gaussians for Qz isable to learn an alignment (both use the same Tj models).
Figure 4: An unregularized alignment loss (figure (a) and (b)) can lead to excessive and unexpectedmovement of points in the latent representation (lines connect transported points), while our regular-ized alignment loss ((figure (c) and (d))) yields a unique and regularized solution that moves pointssignificantly less and is closer to the identity function.
Figure 5: All pair-wise translation results among MNIST digits 0-2 where each block has first imageas the original digit followed by the latent image, and three corresponding translated digits. Pleasenote that second column of LRMF is set to be black because it does not have latent representation,and LRMF fails to translate in this situation which is why the numbers are all the same.
Figure 6: Qualitative comparison on translationresults across 10 classes with AlignFlow and ourswith transportation cost.
Figure 7: Figure (a) is translation result between USPS and MNIST dataset. Top two images arethe training and testing result if using pretrained PixelCNN++(Salimans et al., 2017) models afteronly 1 epochs, and the bottom images are the results of MLE version of AlignFlow models after 200epochs. Figure (b) shows the generated images of our model for all domains. Model used in thistask is adapted from multi-domain translation tasks in subsection 4.2.
Figure 8: This figure shows the translation results of interpolated images. In the first row, the twoimages selected by red rectangles are real images from the dataset; and all eight images in betweenare generated by linear interpolation in the latent space. Starting from the second row, each rowcontains translated images which are transformed from the same latent vector in the same columnand the first row.
Figure 9: This figure shows the translation results for three attributes (Black Hair, Blonde Hair,Brown Hair) in CelebA dataset. The first column corresponds to real images in the test dataset. Thenext three columns are translated results into three different attributes/domains (Each of the threecolumns represents translation to Black Hair, Blonde Hair, Brown Hair attribute respectively) fromour model. The final three columns shows the translation results of MLE version of AlignFlowmodel with the same format as the previous three columns.
