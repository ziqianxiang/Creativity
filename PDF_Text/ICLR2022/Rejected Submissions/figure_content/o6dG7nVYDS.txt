Figure 1: Linear SVC performance on DomainBed benchmark datasets is governed by model com-plexity parameter C . Optimal tuning for performance on novel target domains (DG condition, red)always requires stronger regularisation (lower C) than for performance on seen domains (blue).
Figure 2: Performance of neural networks as a function of their measured model complexity aftertraining using DomainBed (DB). The overall results are consistent with a standard bias-variancetrade-off (cf. Fig 1 for linear models): performance depends on how well each model was tuned byDBâ€™s hyper-parameter search procedure. Top: Leave-one-domain-out cross-validation performanceof various neural DG algorithms evaluated by DomainBed. Horizontal error bars correspond to thestandard deviation of the model complexity measured for each cross-validation iteration. Bottom:Performance of ERM model checkpointed at different training iterations. The central tendencyis obtained via fitting a support vector regression model (Shevade et al., 2000) with a 6th orderpolynomial kernel.
Figure 3: Performance of various neural network DG algorithms as a function of their measuredmodel complexity after training using DomainBed. Breakdown by held-out dataset. The top fourrows correspond to individual domains, the bottom row is the leave-one-domain-out cross-validationestimate of the DG performance, and horizontal error bars correspond to the standard deviation ofthe model complexities measured in each iteration of cross-validation.
