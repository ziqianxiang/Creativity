Figure 1: Illustration of the training pipeline. The three steps are depicted: 1. Selecting the groupof pseudo-labels and their corresponding weights; 2. SSL training with the selected pretext task; 3.
Figure 2	: Evolution of the CI estimation with different numbers of considered speakers for threepretext tasks : F0, Voicing and logHNR. We can see that the values obtained with 20 speakers, whilelogically exhibiting more variance, are already close to the final values for every pretext task.
Figure 3: Boxplots of the CI values for every pretext tasks, when more than 200 speakers are con-sidered. Voicing and Loudness are slightly overlapping, but otherwise, the values are separable. Wedivide the pretext-tasks in two groups according to their CI values for a better visualisation of theresults.
Figure 4: CI-Based utility estimator as a function of the weighting for groups of three pseudo-labels.
