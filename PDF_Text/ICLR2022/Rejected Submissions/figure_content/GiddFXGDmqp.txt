Figure 1: (a) Structure of SPAIR3D. For better illustration, we adopt 2D abstraction and use colorsto highlight important correspondence. (b) Structure of Glimpse VAE. Glimpse encoder encodesforeground glimpses and produce ziwhat , zimask and zipres for each glimpse. Point Graph Decodertakes ziwhat and reconstructs input points (left branch). Mask Decoder takes zimask and generatesmasks for each point (middle branch). The dashed line represents the dependency on the coordinatesof the intermediate points in the hierarchy and Gi . Multi-layer PointGNN networks enable messagepassing between (ci , fi) and produces zipres (right branch).
Figure 2: Visualization of segmentation results on UOR and UOT dataset.
Figure 3: t-SNE visualization of zwhat on UOT7Under review as a conference paper at ICLR 2022Figure 4: Test set performance distributions on UOR (first row) and UOT (second row).
Figure 4: Test set performance distributions on UOR (first row) and UOT (second row).
Figure 5: Segmentation on scenes with 6 to 12 objects (a - d) and on object matrix (e-h)4.3	Object Centric RepresentationTo show that our model learns meaningful representations, for each object type in UOT datasetwe collect the zwhat of 200 instances and visualize them with t-SNE algorithm (van der Maaten &Hinton, 2008). Fig 3 clearly shows the zwhat of different object types cluster at different regions. Notsurprisingly, the embeddings of pot and box instances occupy the same area since they have almostidentical spatial structure. See appendix Sec. D for object specification.
Figure 6: The comparison between models with (left) and without (right) multi-layer PointGNNs. Itshows that objects are over-segmented severely without multi-layer PointGNNs.
Figure 7: PGD trained on ShapeNet. (a) Input point cloud with N points. Reconstruction with (b)1.5N, (c) 1.25N, (d) N, (e) 0.75N , and (f) 0.5N points.
Figure 8: Visualization of glimpse boundary structure, glimpse boundary weights and the correspond-ing gradients. Fig. 8c illustrates the glimpse structure where c is the glimpse center and x is an pointliving in the glimpse boundary. The linear decay function (orange) and parabola decay function (blue)are plotted in Fig. 8a with the corresponding gradients shown in Fig. 8b.
Figure 9: Structure of PointConv.
Figure 10: Data captured by each camera in UOR dataset (top) and UOT dataset (bottom). From leftto right are RGB, depth, normal, instance label, semantic label and constructed point cloud. Pointclouds are obtained by merging multi-view depth images. Instance labels and semantic labels areused to train PointGroup (Jiang et al., 2020) baseline. RGB images and normal maps are not used inthis work.
Figure 11: Closest neighbor distance distribution of our data generation process for 2-5 objects(above), and for 6-12 objects (below)18Under review as a conference paper at ICLR 2022Table 13: UOR object pool.
Figure 12: Scene layout in Object Room dataset has four walls. SPAIR3D groups four walls togetherwith the floor in each scene as the scene layout component. Column (a) and column (c) are instancelabels. Column (b) and column (d) are the corresponding SPAIR3D segmentation.
Figure 13: Typical UOR test cases that achieves above 0.8 SC. Column (a) and column (c) areinstance labels. Column (b) and column (d) are the corresponding SPAIR3D segmentation.
Figure 14: Typical UOT test cases that achieve above 0.8 SC. Column (a) and column (c) are instancelabels. Column (b) and column (d) are the corresponding SPAIR3D segmentation results.
Figure 15: UOR test cases that achieves below 0.7 SC. Column (a) and column (c) are instance labels.
Figure 16: UOT test cases that achieve below 0.7 SC. Column (a) and column (c) are instance labels.
Figure 17: More results on UOR scenes with 6-12 objects. Column (a) and column (c) are instancelabels. Column (b) and column (d) are the corresponding SPAIR3D segmentation.
Figure 18: More results on UOT scenes with 6-12 objects. Column (a) and column (c) are instancelabels. Column (b) and column (d) are the corresponding SPAIR3D segmentation.
Figure 19: More results on UOR and UOT Object Matrix scenes. Column (a) and column (c) areinstance labels. Column (b) and column (d) are the corresponding SPAIR3D segmentation results.
