Figure 1: Example tasks in Safe Multi-Agent MuJoCo Environment. (a): Safe 2x4-Ant, (b): Safe4x2-Ant, (c): Safe 2x3-HalfCheetah. Body parts of different colours are controlled by differentagents. Agents jointly learn to manipulate the robot, while avoiding crashing into unsafe red areas.
Figure 2: Performance comparisons on tasks of Safe ManyAgent Ant, Safe Ant, and Safe HalfChee-tah in terms of cost (the first row) and reward (the second row). The safety constraint values are: 1for ManyAgent Ant, 0.2 for Ant, and 5 for HalfCheetah. Our methods consistently achieve almostzero costs, thus satisfying safe constraints, on all tasks. In terms of reward, our methods outperformIPPO and MAPPO on some tasks but underperform HAPPO, which is also an unsafe algorithm.
Figure 3: ManyAgent Ant 3x2 with a corridor and Ant 4x2 with three corridors.
Figure 4: HalfCheetah 2x3 and Couple HalfCheetah 1P1.
Figure 5: Many-Agent Ant 3x2 with two folding line walls.
Figure 6: Performance comparisons on tasks of Safe ManyAgent Ant in terms of cost (the first row)and reward (the second row). The safety constraint values is set to 10. Our algorithms are the onlyones that learn the safety constraints, while achieving satisfying performance in terms of the reward.
