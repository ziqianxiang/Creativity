Figure 1: General overview of our CheXT frame-work for Cardiopulmonary Disease Classificationand Localization from chest X-rays. CheXT takesthe chest X-ray image as the input and outputsa heatmap for pathology localization, based onwhich the bounding box could be obtained. Ra-diomic features are further extracted from thebounded region and are fed to predict the disease.
Figure 2: Overview of our proposed CheXT. It contains two branches, the Image branch and theRadiomics branch, to process the image and radiomic features (generated by the BYOA moduleshown in Figure 3), respectively. The output tokens are then fused by an efficient module via crossattention of the CLS tokens. Finally, the output of two CLS tokens (Icls and Rcls) are used for diseaseclassification. We minimize the classification errors via a focal loss. Since we train with both labeledand unlabeled images, we leverage a contrastive learning strategy. Specifically, we generate the imageview zi = gi(Icls) by a projection head gi. Similarily, we generate the radiomic view zr = gr(Rcls)by another projection head gr . We maximize the agreement between zi and zr via a contrastive loss(NT-Xent). Of note, the contrastive loss is only active during the training.
Figure 3: Overview of our BYOA module. For the input chest X-rays, we look at the self-attentionof the CLS token of the Image branch on the heads of the final output of the cross attention module.
Figure 4: AUC comparison for varying T in (A) attention map generation and (B) Î» in Equation 3.
Figure 5: Examples of visualization of localization on the test images. The attention maps aregenerated from the self-attention maps of the CLS token. The ground-truth bounding boxes are shownin blue. The left image in each pair is the localization result of ViT (Dosovitskiy et al., 2020). Theright one is our localization results. All examples are positive for corresponding disease labels. Bestviewed in color.
