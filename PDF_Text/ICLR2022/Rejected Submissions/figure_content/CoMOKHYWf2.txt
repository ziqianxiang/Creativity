Figure 1: Calibration behaviour of ResNet-50 trained on CIFAR-10 with cross entropy (CE), focalloss γ = 3, 4, 5 (FL-3/4/5) and FLSD-53 (or FL-53). The statistics are computed using 15 equal-massbinning on the validation set. (a) AdaECE, and (b) Calibration error Eval,i = Cval,i - Aval,i for alower (bin-0), middle (bin-7), and upper (bin-14) bin. The black horizontal lines in (b) representEval,i = 0. These exemplify the downside of regular focal loss i.e. although FL-4 achieves theoverall lowest calibration error (AdaECE), the best performing γ is different for different bins.
Figure 2: Correspondence between average confidence of a group of training samples (Ctrain) and agroup of validation samples (Cval) for ResNet-50 trained on CIFAR-10 with focal loss γ = 0 (CE),3, 5. The binning involves 15 equal-mass bins with a lower (bin-0), middle (bin-7) and upper (bin-14)shown here. We see a good correspondence between Ctrain (solid lines) and Cval (starred lines).
Figure 3: ResNet-50 trained on CIFAR-10 with cross entropy (CE) and CalFocal (CF-λ). Sub-figure(d) compares Ctrain , Cval and Aval in validation bin-0 to show that as CalFocal tries to keep Ctraincloser to Aval, Cval also gets closer to Aval.
Figure 4: Test set error and Calibration of ResNet-50 trained on small to large-sCale image datasetswith Cross entropy (CE), FLSD-53 and AdaFoCal. In eaCh subfigure Left: Error (%), Right: ECE(%). The plots have been averaged over 5 runs. AdaFoCal Consistently aChieves low Calibration erroraCross all datasets while maintaining the aCCuraCy.
Figure 5: Dynamics of γ in different bins and calibration statistics of validation set used by AdaFocalfor ResNet-50 trained on CIFAR-10 and ImageNet. Each bin has two subplots: Top: Eval =Cval - Aval, Bottom: evolution of γt. Black dotted line in top plot represent zero calibration error.
Figure 6: ROC for ResNet-110 and Wide-ResNet-26-10 trained on in-distribution CIFAR-10 andtested on out-of-distribution (a) SVHN and (b) CIFAR-10-C. FL-3 refers to Focal loss γ = 3, Pre/PostT refers to before and after temperature scaling respectively.
Figure 7: Test set error and calibration of ResNet-50 trained on ImageNet. Left: Error, Right: ECE.
Figure 8: Dynamics of γ and calibration in different bins when ResNet-50 is trained on ImageNet.
Figure 9: ResNet50 model trained on CIFAR-10 using different focal losses γ = 0, 3, 4, 5. Top:Eval,i = Cval,i - Aval,i, Bottom: bin boundaries. The statistics are computed on the validations set(5, 000 examples) using 15 equal-mass bins. The black horizontal line in top subgfigure representszero calibration error Eval,i = 0.
Figure 10: ResNet50 trained on CIFAR-10 with focal loss γ = 3. It shows that Ctrain,true,i andCtrain,top,i are almost the same during major part of the training. This is because as the modelapproaches towards 100% accuracy on the training set, the top predicted class and the true class for atraining sample become the same.
Figure 11: Independent binning: training samples and validation samples are grouped indepen-dently into training-bin and validation-bin respectively. The top subfigure for each bin shows thecorrespondence between average confidence of a group of training samples Ctrain,true,i and a groupof validation samples Cval,top,i when ResNet-50 is trained on CIFAR-10 with focal loss γ = 0, 3, 5.
Figure 12: Common binning: training samples are grouped using the bin boundaries of the validation-bins. The top subfigure for each bin shows the correspondence between average confidence of agroup of training samples Ctrain,true,i and a group of validation samples Cval,top,i when ResNet-50is trained on CIFAR-10 with focal loss γ = 0, 3, 5. The binning is adaptive with 15 equal-mass bins.
Figure 13: ResNet-50 trained on CIFAR-10 using CalFocal loss. LExp,λ = CalFocal loss in Eq. 1 ofthe main paper. Legend λ = CalFocal loss in Eq. 2 with common γb for all training samples in bin b.
Figure 14: ECE error bars with mean and standard deviation computed over 5 runs with differ-ent initialization seed. The dark and light colors show pre and post temperature scaling resultsrespectively.
Figure 15: ResNet-50 trained on CIFAR-10 with cross entropy (CE), AdaFocal, and the movingaverage γ-update rule (MA-α). We see that MA-α is not as effective as AdaFocal’s γ update rule.
Figure 16: Training ResNet-50 on CIFAR-10 using AdaFOcal and MA-α. Each bin has two subplots:top: Eval,i = Cval,i - Aval,i, bottom: evolution of γt. Black dotted line in top plot represent zerocalibration error. We observe that for MA-α the γ for different bins are not as free to move around asthat under AdaFocal.
Figure 17: ResNet-50 trained on CIFAR-10 using 5 runs of cross entropy (CE), FLSD-53 andAdaFocal with different initialization seed. AdaFocal with γmax = 20 is consistently better.
Figure 18: Evolution of γt for 9 runs of ResNet-50 trained on CIFAR-10 using AdaFocal γmax = 20.
Figure 19: Plots for ResNet-50 trained on CIFAR-10 using cross entropy (1 run), FLSD-53 (3 runs)and AdaFocal (5 runs). AdaFocal with γmax = 50 although is mostly better than FLSD-53 it doesexhibit greater variability than γmax = 20.
Figure 20: Evolution of γt for multiple runs of ResNet-50 trained on CIFAR-10 using AdaFocalγmax = 50.
Figure 21: Plots for ResNet-50 trained on CIFAR-10 using cross entropy (1 run), FLSD-53 (3 runs)and AdaFocal (9 runs). AdaFocal with unconstrained γ does exhibit some variability across differentruns: 7 out of 9 times it is better than FLSD-53, two times it is similar or slightly worse.
Figure 22: Evolution of γt for multiple runs of ResNet-50 trained on CIFAR-10 using unconstrainedAdaFocal.
Figure 23: ResNet-50 trained on CIFAR-10 with cross entropy (CE), focal loss γ = 3, FLSD-53 andAdaFocal. (a) Error, (b) ECE, (c) AdaECE and (d) classwise-ECE. AdaFocal achieves the lowestcalibration error while maintaining similar error performance.
Figure 24: CIFAR-10, ResNet-110: Test set Error, ECE, AdaECE, classwise-ECE and Validationset bin information used by AdaFocal during training.
Figure 25: CIFAR-10, Wide-ResNet: Test set Error, ECE, AdaECE, classwise-ECE and Validationset bin information used by AdaFocal during training.
Figure 26: CIFAR-10, DenseNet-121: Test set Error, ECE, AdaECE, classwise-ECE and Validationset bin information used by AdaFocal during training.
Figure 27: CIFAR-100, ResNet-50: Test set Error, ECE, AdaECE, classwise-ECE and Validationset bin information used by AdaFocal during training.
Figure 28: CIFAR-100, ResNet-110: Test set Error, ECE, AdaECE, classwise-ECE and Validationset bin information used by AdaFocal during training.
Figure 29: CIFAR-100, Wide-ResNet: Test set Error, ECE, AdaECE, classwise-ECE and Validationset bin information used by AdaFocal during training.
Figure 30: CIFAR-100, DenseNet-121: Test set Error, ECE, AdaECE, classwise-ECE and Validationset bin information used by AdaFocal during training.
Figure 31: Tiny-ImageNet, ResNet-50: Test set Error, ECE, AdaECE, classwise-ECE and Validationset bin information used by AdaFocal during training.
Figure 32: 20 Newsgroups, CNN: Test set Error, ECE, AdaECE, classwise-ECE and Validation setbin information used by AdaFocal during training.
