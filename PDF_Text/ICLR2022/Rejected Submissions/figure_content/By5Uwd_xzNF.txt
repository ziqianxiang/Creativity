Figure 1: Abstract visual analogy problemture (Planet revolves around Sun =^ Electron revolves around Nucleus, Sun more massivethan Planets =^ Nucleus more massive than Electrons). However, the domain attributes,such as the Sun being yellow or hot are not mapped to the Nucleus in drawing an analogy.
Figure 2: Neural Structure Mapping overview. Inset: RPM Analogy Problem from Fig 1. Left(yellow box): Visual Relationship Encoder to extract the object, attribute and relationship from thefirst row of panels. Right (green box): Analogy Inference Engine that uses the relationship label toconfigure a neural module net for matching the correct candidate to the second row of panels.
Figure 3: Two different types of candidates for the same target domain. (a) Contrasting candidates,each of which satisfies a relationship structure and requires identifying semantic structure duringcandidate selection. (b) Normal candidates, which are merely perceptually similar to the context.
Figure 4: Types of relationship and corresponding Analogy Inference Engine layout. Onlycorrect candidate panel shown. See Section 4.2 for detailsture vector lφshared is then passed through three different fully connected layers lφtask “ F Cφtask plφshared qfor each task t P {object, attribute, relation} classification. Finally, each lφtask ispassed through a fully connected layer outtφask “ F Cφouttask plφtaskq of sizes 2, 5, and 4 for the object,attribute, and relation prediction tasks respectively. A Softmax over the outputs outtφask yields aprobability distribution over the possible to, a, ru values that constitute the triplet R.
Figure 5: Relationship prediction test accuracy of our Visual Relationship Encoder. Results arefirst grouped (L-R) by test candidate regimes (contrasting, normal, and mixed candidates) and thensub-grouped (L-R) by training candidate regimes. Since the encoder is trained on the source domainpanels, it does not have to generalize systematically and performs consistently across all splits.
Figure 6: Systematic generalization test performance with Normal training candidates which lack aprior on the dataset that maximizes structure learning during training.
