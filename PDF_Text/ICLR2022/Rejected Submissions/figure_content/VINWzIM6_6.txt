Figure 1: For each protein we sample random sub-structures which are then encoded into two repre-sentations, h and z, using encoders E and P . Then,we minimize the distance between representationsz from the same protein and maximize the distancebetween representations from different proteins.
Figure 2: Our sampling strategy used during con-trastive learning. For a protein chain (a), we selecta random amino acid (b). Then we travel alongthe chain in both directions until we have a certainpercentage p of the sequence covered (c).
Figure 3: Dimensionality reduction of the protein representations using TSNE (Van der Maaten &Hinton, 2008). Left: Proteins from the Fold Classification task, training set on the left, test set on theright, color-coded based on the highest hierarchy level in the SCOPe classification system. Right:Proteins from the Enzyme Classification task, training on the left, test set on the right, color-codedbased on the highest level of the Enzyme Commission number.
Figure 4: Illustration of our protein encoder. We use an amino acid embedding as our input featuresthat are then processed by consecutive ResNet Bottleneck blocks and pooling operations. To obtainthe final protein representation we use the average of the features from the remaining graph nodes.
