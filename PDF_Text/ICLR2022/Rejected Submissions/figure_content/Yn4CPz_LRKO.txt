Figure 1: Illustration of discriminators/classifiers of existing conditional GANs (PD-GAN (Miyato& Koyama, 2018), AC-GAN (Odena et al., 2017), and TAC-GAN (Gong et al., 2019)) and theproposed ADC-GAN. l indicates real (l = 1) or fake (l = 0) and y is the class-label of data x. ADC-GAN is different from PD-GAN with explicitly predicting the label and is different with AC-GANand TAC-GAN that the classifier Cd also distinguishes real from fake like the discriminator.
Figure 2: Distribution learning results on one-dimensional synthetic data.
Figure 3: Hyper-parameter robustness results on overlapping MNIST.
Figure 4: (a,d) FID comparison of methods with different λ0 on CIFAR-10 and CIFAR-100. Theobjective of competing methods is (1 - λ0)V (G, D) + λ0VC(G, C), where VC(G, C) is the taskbetween the generator and classifier. (b,e) FID curves with GAN training iterations on CIFAR-10and CIFAR-100. (c,f) T-SNE visualization of CIFAR-10 training data, using learned representationsextracted from the penultimate layer in discriminators. Different colors represent different classes.
Figure 5: Distribution learning results on the one-dimensional synthetic data.
Figure 6: Distribution learning results on the two-dimensional synthetic data.
Figure 7: FID curves with GAN training iterations on Tiny-ImageNet.
