Figure 1: (a): Block structure arises in wide and deep networks. Heatmaps show similarity between layerrepresentations, measured with linear CKA, for models of varying widths and depths trained on CIFAR-10.
Figure 2: (a): The first principal component of representations inside the block structure explains themajority of the variance in representations. Top: Linear CKA similarity heatmaps for networks that doand do not exhibit block structure. Bottom: Fraction of variance in representations explained by first principalcomponent. See Appendix B for more networks. (b): Representations inside the block structure are highlyunique to each seed. 2 leftmost panels show similarity of representations within networks trained with 2different random seeds. Rightmost panel shows similarity between the 2 networks.
Figure 3: Visualization of the distribution of projected values onto the first principal component by testinputs. There exist a small number of datapoints that yield significantly larger projected values than the restand dominate the first principal component of the network. Here we show examples of those dominant imagesfor two different seeds of ResNet-164 (1×) (columns). Each seed’s dominant images share similar backgroundcolors, but these background colors differ between seeds. Further visualization of dominant datapoints acrossdifferent layers — for instance, layers 250 and 500 in this case — show that they are consistent across layersmaking up the block structure. See Appendix C for analysis of other models and tasks.
Figure 4: Removing a small number of dominant datapoints eliminates the block structure. Plots showthe effect of removing examples with the largest projections on the first PC of layer 300 of ResNet-164 (1 ×)models. Columns reflect different numbers of examples removed; rows reflect models trained from differentseeds. Within each group, the top left plot shows linear CKA heatmaps, the bottom left shows the fraction ofvariance explained by the first PC, and the images reflect the new examples with the largest projection on thefirst PC after data removal.
Figure 5: Datapoints that dominate the first principal components of the block structure also stronglyactivate the corresponding layers. We explore the relationship between dominant datapoints and activationnorms for ResNet-164 (1×) trained on CIFAR-10 (top row) and ResNet-80 (1×) trained on Patch Camelyondata (bottom row). For layers inside the block structure (left column), dominant datapoints (inset) produce muchlarger activation norms than the median of a randomly selected minibatch (middle column). Moreover, withinthese layers, the norms of the activations of different datapoints are highly correlated with the magnitudes oftheir projections on the first principal component (right column).
Figure 6: Solid color images strongly activate intermediate layers. Rows show models with the same ar-chitecture (ResNet-164 (1×)) that are trained from different random initializations. The first model’s dominantdatapoints consist of images with blue backgrounds (see inset images), whereas the second network preferswhite background images. We then observe that layers of the first model are strongly activated by solid blueimages, but not solid white images, whereas the second model shows the opposite pattern. Layers of both mod-els are strongly activated by their respective dominant datapoints (red lines), but other solid colors (e.g., green)do not yield strong activations in either. To improve readability of the plot, we plot only the representations atthe end of each ResNet block. See Appendix E for similar findings on Patch Camelyon models.
Figure 7: Simply adding color augmenta-tion helps reduce the block structure ef-fect. Having established that the activationsand representational components of somelarge-capacity models pick up on commonbackground colors from the inputs, we ex-periment with color dropping and color jit-tering during training to counter this effect.
Figure 8: Block structure phenomenon arises early during training, but the corresponding dominantdatapoints continue to change substantially. We compute the CKA between all pairs of layers within aResNet-110 (1×) model at different stages of training, and find that the shape of the block structure is definedearly in training (top row). However, comparing these different model checkpoints to the fully-trained modelreveals that the block structure representations at different epochs are considerably dissimilar to the final rep-resentations, especially during the first half of the training process (middle row). The dominant datapoints alsovary significantly over the course of training, even after the block structure is clearly visible in the heatmaps(bottom row). See Appendix F for similar plots with greater granularity, different seeds and architectures.
Figure 9: Training with principal component regularization, transfer learning and Shake-Shake regu-larization helps to eliminate the block structure. We directly regularize the first PC of each layer activationsgiven that this component explains a large fraction of variance in block structure representations, and find thatthis eliminates the block structure. Full algorithm details can be found in Appendix G. Shake-Shake regular-ization (Gastaldi, 2017) has a similar effect. We also find that transfer learning reduces the appearance of theblock structure, although it is still present in the largest network we trained. These results demonstrate that theblock structure phenomenon is dependent on the training mechanism (see Appendix I for implications of thesetraining methods on representations across random seeds).
