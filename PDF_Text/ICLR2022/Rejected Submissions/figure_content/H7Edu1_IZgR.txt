Figure 1: Illustration of the TrMRL agent. At each timestep, it associates the recent past of workingmemories to build an episodic memory through transformer layers recursively. We argue that theself-attention works as a fast adaptation strategy since it provides context-dependent parameters.
Figure 2: The illustration of two tasks (T1and T2) as distributions over working memo-ries. The intersection of both densities repre-sents the ambiguity between T1 and T2 .
Figure 3: Illustration of causal self-attention as a fast adaptation strategy. In this simplified scenario(2 working memories), the attention weights αi,j drives the association between the current work-ing memory and the past ones to compute a task representation μt. Self-attention computes thisassociation by relative similarity.
Figure 4: Meta-Training results for MetaWorld benchmarks. The plots on top represents perfor-mance on training tasks, while the plots on bottom represents in the test tasks.
Figure 5: TrMRL’s adaptation for HalfChee-tahVel environment.
Figure 6: Fast adaptation results on MuJoCo locomotion tasks. Each curve represents the averageperformance over 20 test tasks. TrMRL presented high performance since the first episode due tothe online adaptation nature from attention weights.
Figure 7: OOD Evaluation in HalfChee-tahVel environment.
Figure 8:	Meta-Training results for MuJoCo locomotion benchmarks. The plots on top representperformance on training tasks, while the plots on bottom represent the test tasks.
Figure 9:	3-D Latent visualization of the working memories for the HalfCheetahVel environment.
Figure 10:	Ablation results for the T-Fixup component.
Figure 11: Ablation results for the working memory sequence length.
Figure 12: Ablation study for the number of transformer layers.
Figure 13: Ablation study for the number of attention heads.
