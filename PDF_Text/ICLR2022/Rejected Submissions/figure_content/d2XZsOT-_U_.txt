Figure 1: Overview of our two level player history embedding model. See text for details.
Figure 2: Architecture of the 3-layer Transformer (Vaswani et al., 2017) used for functions φ(.) andζ(.). See text for details.
Figure 3: Match prediction on the evaluation set of four real-world datasets: chess 1, chess2, base-ball, and hockey. Pearson correlation with the true outcome of each game is plotted. Our learnedhistory embeddings approach is shown in blue. Depth 1 corresponds to the architecture describedSection 3.2, and depth 2 corresponds to the architecture described in Section 3.3. Exponential MovingAverage (EMA), Bayesian Bradley-Terry (Weng and Lin, 2011), Blade-Chest (Chen and Joachims,2016c), Melo2K (Balduzzi et al., 2018), and Glicko (Glickman, 1995) baselines are shown in orange.
Figure 4: A breakdown of our performance as a function of history size, i.e. number of match-ups foreach player in the evaluation set (min over each pairing) on the chess 1 (L) and chess2 (R) datasets.
