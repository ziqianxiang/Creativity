Figure 1: Masked CIFAR-10 images generated by our procedure with λTV = 0.01 shows theartifacts exist for masks generated for incorrect labels. More examples can be find in Figure 7 inAppendix. The base classifier outputs the correct label on the original image (ship and bird resp.)with probability at least 0.99, and assigns probability at most 10-5 for the incorrect label (cat andfrog resp.). With the generated masks, the AUC metric for the correct label remains high (around0.94 and 0.90), which corresponds to completeness, but AUC metric for the incorrect label risestremendously (around 0.18 for cat mask, 0.71 for frog mask.) This suggests violation of soundness.
Figure 2: Images containing both elephant(s) and zebra(s), and the corresponding masked onesgenerated by our method and the best-performing CA model in Phang et al. (2020). The masksby Phang et al. (2020) are identical for different labels, and contains both elephant and zebra. Incontrast, our method outputs descent masks for elephant and zebra accordingly.
Figure 3: Plot of model output probability as more pixels from the original image are retained usinglearned masks. The remaining pixels are replaced with gray. Different curves correspond to differentvalues of TV regularization (λT V ). Larger area-under-curve (AUC) for the left figure (best label)suggests good completeness, while lower AUC for the right figure suggests good soundness. Plotssuggest that adding TV significantly helps with soundness, while only slightly hurting completeness.
Figure 4: Top: Masking validating the correct label of ImageNet images using Section 4. Pixels out-side the salient set S are rendered as grey. Size of S (as % of total pixels) appears below the images.
Figure 5: [CIFAR-10] AUC curves with as the fraction of pixels retained from the original imagesbased on the mask varies from 0 to 1.0 on the X-axis. The probabilities assigned by the model(averaged over 1600 images) on the Y-axis. Left: Mask learned for ground truth label, probabilitiesfor ground truth label while replacing remaining pixels with grey. Center Left: Mask learnedfor ground truth label, probabilities for ground truth label while replacing remaining pixels withother image pixels. Center Right: Mask learned for second best label, probabilities for secondbest label while replacing remaining pixels with grey. Right: Mask learned for second best label,probabilities for second best label while replacing remaining pixels with other image pixels. Wesee that increasing TV regularization results in only a mild drop in completeness, but significantlyimproves soundness.
Figure 6: Details in Appendix C.1 Panel 6a Partial statistical assignments validating the correctlabel of CIFAR-10 images using the procedure outlined in Section 4 on ResNet-164. Columns(1,3,5,7) depict masked images at 30 (retained) % mask sparseness. Columns (2,4,6,8) depict theoriginal mask. TV values shown above. Original image shown in rightmost column. Model proba-bility of correct label for masked images on y axis. Panel 6b Partial statistical assignments validatingthe second most probable label of CIFAR-10 images using the procedure outlined in Section 4 onResNet-164. Columns (1,3,5,7) depict masked images at 30 % mask sparseness. Columns (2,4,6,8)depict the original mask.TV values shown above. Original image shown in rightmost column. Modelprobability of second best label for masked images on y axis.
Figure 7: A demonstration of artifacts created by masking. Pixels (partially) masked out are filledwith gray based on the fractions they are masked out. Masks generated without or only with lowlevel regularization can easily produce artifacts. It is more common and/or severe for the incorrectlabel than correct label.
Figure 8: [CIFAR-100] AUC curves with as the fraction of pixels retained from the original imagesbased on the mask varies from 0 to 1.0 on the X-axis. The probabilities assigned by the model(averaged over 1600 images) on the Y-axis. Left: Mask learned for ground truth label, probabilitiesfor ground truth label while replacing remaining pixels with grey. Center Left: Mask learnedfor ground truth label, probabilities for ground truth label while replacing remaining pixels withother image pixels. Center Right: Mask learned for second best label, probabilities for secondbest label while replacing remaining pixels with grey. Right: Mask learned for second best label,probabilities for second best label while replacing remaining pixels with other image pixels. Wesee that increasing TV regularization results in only a mild drop in completeness, but significantlyimproves soundness.
Figure 9: Details in Appendix C.2 Panel 9a Partial statistical assignments validating the correctlabel of CIFAR-100 images using the procedure outlined in Section 4 on ResNet-164. Columns(1,3,5,7) depict masked images at 30 (retained) % mask sparseness. Columns (2,4,6,8) depict theoriginal mask. TV values shown above. Original image shown in rightmost column. Model proba-bility of correct label for masked images on y axis. Panel 9b Partial statistical assignments validatingthe second most probable label of CIFAR-100 images using the procedure outlined in Section 4 onResNet-164. Columns (1,3,5,7) depict masked images at 30 % mask sparseness. Columns (2,4,6,8)depict the original mask.TV values shown above. Original image shown in rightmost column. Modelprobability of second best label for masked images on y axis.
Figure 10: Details in Appendix C.3.1. US stands for upsampled mask, where we derive a (56,56)mask and interpolate to (224,224). Panel 10a Partial statistical assignments validating the correct la-bel of ImageNet images using the procedure outlined in Section 4 on ResNet-50. Columns (1,3,5,7)depict masked images at 30 (retained) % mask sparseness. Columns (2,4,6,8) depict the originalmask. TV values shown above. Original image shown in rightmost column. Model probabilityof correct label for masked images on y axis. Panel 10b Partial statistical assignments validatingthe second most probable label of ImageNet images using the procedure outlined in Section 4 onResNet-50. Columns (1,3,5,7) depict masked images at 30 % mask sparseness. Columns (2,4,6,8)depict the original mask.TV values shown above. Original image shown in rightmost column. Modelprobability of second best label for masked images on y axis. We find, unsurprisingly, that addingTV regularization and upsampling make the mask more continuous and “human interpretable” and,more importantly, make it harder to find masks that can get high probability for the second bestlabel, thus ensuring higher soundness.
Figure 11: Results of randomizing the last layer of a ResNet-18 model on ImageNet data for the pro-cedure described in Section 4. US indicates a (56, 56) map was learned and upsampled to (224, 224).
Figure 12: Effect of ensembling Partial statistical assignments validating the correct label of Ima-geNet and ResNet-18 images as we vary K, the number of maps. Details in Appendix C.3.1.
Figure 13: ImageNet data. Left: AUC curves as fraction of pixels used varies from 0 to 1.0 forground truth label when replacing with grey. Center Left: AUC curves as fraction of pixels usedvaries from 0 to 1.0 for ground truth label when replacing with other images. Center Right: AUCcurves as fraction of pixels used varies from 0 to 1.0 for second best label when replacing withgrey. Right: AUC curves as fraction of pixels used varies from 0 to 1.0 for second best label whenreplacing with other images.
