Figure 1: Visualizing different feature priors: (a) an image from the STL-10 dataset; (b) Sobel edgedetection; (c) Canny edge detection; (d) the limited receptive field of a BagNet.
Figure 4: Test accuracy of pre-trained, self-trained, and co-trained models selecting the best fea-ture prior for each (full results in Table 3, Appendix Table 13, and Table 5 respectively). Noticehow combinations of models with different feature priors consistently outperform combinations ofmodels with the same feature prior.
Figure 6: Correlation between the correct predictions of shape- and texture-biased models overthe course of co-training for STL-10 and CIFAR-10. For comparison, we also plot the correlationbetween the predictions when the models induced by these priors are individually self-trained, aswell as the correlation of two standard models when co-trained together.
Figure 8: Tinted STL-10 images. The tint is class-specific and thus models can learn to predictbased mostly on that tint.
Figure 9: The customized BagNet architecture used for training texture-biased models. The basicbuilding block consists of a convolutional layer, followed by batch normalization and finally a ReLUnon-linearity (denoted collectively as CBR).
Figure 10: Further visualizations of the different feature priors we introduce. For each originalimage (a), we visualize the output of both edge detection algorithms—Sobel (b) and Canny (c)—aswell as the receptive field of the BagNet model.
