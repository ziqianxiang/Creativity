Figure 1: High-level view of a computer vision network. The backbone (left) processes the imageto output a set of feature maps (i.e. a feature pyramid). The core (middle) takes in a feature pyramid(denoted by FP) and returns an updated feature pyramid. Finally, the head (right) produces the lossduring training and makes predictions during inference from the final feature pyramid. In this work,we focus on improving the core.
Figure 2: Collection of building blocks for core architecture design. Here Pl denotes feature map oflevel l which is 2l times smaller compared to the initial image resolution. (Left) General top-downoperation updating feature map Pl with information from lower resolution map Pl+1. (Middle)General self-processing operation updating feature map Pl with information from itself, i.e. fromfeature map Pl . (Right) General bottom-up operation updating feature map Pl with informationfrom higher resolution map Pl-1.
Figure 3: (Left) A layer from the FPN core architecture. (Right) A layer from the PANet corearchitecture.
Figure 4: Our TPN core architecture consisting of L consecutive TPN core layers (bottom), witheach self-processing operation consisting of B consecutive bottleneck layers (top).
Figure 5: Bottleneck layer used as base self-processing operation. It is a skip-connection operationwith a residual branch consisting of three convolution operations: a convolution operation of kernelsize 1 reducing the original feature size to the hidden feature size, a content convolution operationof kernel size 3 applied on the hidden feature size, and finally a convolution operation of kernelsize 1 expanding the hidden feature size back to the original feature size. Note that each convolutionoperation (i.e. pink convolution node) consists of the actual convolution preceded (He et al., 2016b)by group normalization (Wu & He, 2018) and a ReLU activation function.
Figure 6: Implementation of the top-down (left) and bottom-up (right) operations. The pink convolu-tion nodes are defined as in Figure 5, with the subscript denoting the kernel size and the superscriptdenoting the stride (stride 1 when omitted). The green node is an interpolation node resizing theinput feature map to the required resolution by using bilinear interpolation.
Figure 7: (Left) The baseline bFPN core architecture simulating a heavier backbone followed bya single FPN layer. (Right) The baseline hFPN core architecture simulating a single FPN layerfollowed by a heavier head.
Figure 8: Accuracy vs. efficiency comparisons between 15 different (L, B) TPN configurationsusing the ‘parameters’ (left), ‘training latency’ (middle) and ‘inference latency’ (right) efficiencymetrics. The accuracies correspond to the COCO validation APs, obtained after training the mod-els for 12 epochs using the 1x schedule. The TPN configurations yielding the best accuracy vs.
