Figure 1: The upper figure shows a ResBlock during the training phase. The lower figure is theconverted RMBlock for inference, which has no residual connections. Both blocks have equal outputgiven the same input.
Figure 2: (a) and (b) show two methods of removing downsample branch in the original Down-Sample ResBlock.
Figure 3: The process of converting MobileNetV2 into MobileNetV1.
Figure 4: The process of pruning on ResNet. During the process, RMNet can serve as a transitionto gain larger pruning ratio.
Figure 5: This figure shows the influence of depth on RMNet and RepVGG.
Figure 6:	(a) and (b) show the CIFAR10 accuracy with respect to network speed and prunedparameters ratio in pruning task.
Figure 7: The first row shows the speed-up ratio of RMNet over ResNet. The second row shows theexact inference speed for ResNet and RMNet. Basic width, Multiply times and Channels/Groupsare hyper-parameters of Network Structure introduced in Section 4.2. The larger the value, the morecomplex the network structure.
Figure 8: Comparison of ResBlock in ResNet and RepBlock in RepVGG.
Figure 9: In each sub-figure, green line and blue line are the accuracies of the ResNet model with orwithout the BN layer, respectively.
