Figure 1: Comparison MASHA1 (Algorithm 1) and MASHA2 (Algorithm 2) with existing methods initerations and in Mbytes.
Figure 2: (upper left) ALBERT training objective convergence rate with different compressionalgorithms; (upper right) ALBERT training objective convergence rate with different compressionalgorithms (zoomed); (lower) Average wall time per communication round with standard deviationover 5 repetitions and downstream evaluation scores on GLUE benchmark tasks after at 80 billiontraining tokens (â‰ˆ104 optimizer steps).
