Figure 1: Clean Model (left) vs. Backdoored Model (right) behavior with clean inputs (top) andtrigger added inputs (bottom). Note the fault injection (right) to model in memory device changesbehavior of classifier as shown by the confusion matrix (bottom, right).
Figure 2: Bit flips in one of the 4KB pages showing the sparsity of the actual bit flips.
Figure 3: Total loss graph at every training iteration during the backdoor injection to the ResNet18can expect to be flipped in practice. Therefore, when the attack is implemented on DRAM withRowhammer, the Attack performance decreases to below 3%. In CFT, rmatch is relatively higherthan the previous methods since it modifies only one parameters in a page. However, it does not puta constraint on the number of bit flips within a byte during the optimization. Therefore, the attackperformance degrades drastically in practice. In all experiments, CFT+BR has 100% rmatch since italready considers the bit locations that can be flipped during the attack. Since the bit flips are sparseacross different memory pages in CFT+BR, 100% of the bit flips can actually be flipped.
Figure 4: The change in GradCAM (SelvarajU et al., 2017) heatmaps that belong to ReSNet18 beforethe attack (left) and after the attack (right). The focus of the model shifts through the trigger patternif it is backdoored.
