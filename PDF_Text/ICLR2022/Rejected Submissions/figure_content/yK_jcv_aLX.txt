Figure 1: A graphical illustrationof the generative environmentmodel. Grey nodes denote ob-served variables and white nodesrepresent unobserved variables.
Figure 2: Diagram of neural net-work architecture to learn staterepresentations. The correspond-ing structural constraints are in-volved in “Deconv” and “MLP”,and “AP" represents the action pre-diction part for sufficient state rep-resentation learning.
Figure 3: Cumulative rewards ofmodel-based ASRs, model-free ASRs,700λ0ω⊃-ro> ssuw100GenerationVRL, SLAC, PlaNet, DBC andDreamer evaluated on CarRacing.
Figure 4: Fitness Value of ASRscompared to world models evaluatedon CarRacing, including mean score,max score, and the best average score.
Figure 5: Comparisons withDreamer and DBC in CarRacingwith natural video distractors, af-ter 2000 training episodes, withstandard error.
Figure 6: Comparing ASRs andSOTA methods evaluated on Viz-Doom.
Figure 7: Fitness value of ASRs(with CMA-ES) compared to worldmodels evaluated on VizDoom.
Figure 8: An illustration of Car Racing environment.
Figure 9: Visualization of estimated structural matrices D~.o, D~.r, D&+~, and D~ in Car Racing.
Figure 10: Ablation study of latent dynamicsprediction (LDP) evaluated on Car Racingwith model-free ASR.
Figure 11: An illustration of VizDoomtake cover scenario.
Figure 12: Network architecture of preprocessor.
Figure 13: Network architecture of observationreconstruction.
Figure 14: Network architecture of observationprediction.
Figure 15: Network architecture of reward.
Figure 16: Network architecture of transi-tion/dynamics.
Figure 17: Network architecture of action prediction.
Figure 18:	Visualization of estimated structural matrices Ds⅛o, D~+r, Da+~, and Ds in Car Racing,without the explicit sparsity constraints.
Figure 19:	Visualization of estimated structural matrices D~>o, D~>r, Da+~, and Ds in VizDoom.
