Figure 1: A flagged non-adversarialexample37UnderreVieW as a COnferenCe PaPer at ICLR 2022AIgO=∙thm∙1: Degradation attack algorithmInputs: A model j mWJL" anp2 m ʌʃ" an attack bound c mand a distance mec 0POUtPUt: An aUackpm WD ① gradationAttaQk“x5T £ := AttaQk (r2c%P)应〈=PrOj ① Qt(3FAF)return XfAIgO=∙thm 32: SmOOthed PrQjeCted gradient descent attack (SPGD)Inputs: A model j mwi 石mappingpsIOgir 0u3uts- aSS funnanp2 m ʌʃ" an attackboundma distance metric £ a SteP SiZe η. a number Of SSPS NS a number Of SamPleS n" and a noiseParamerer QOUtPUt: AnaUackinpufo/m毋QSmooth ① dPgdAttaQkSCSXseP sη"N sna)二=for O ≤ SteP 八 NdO
Figure 2: Upper bounds for false positive rates on Gloro Nets(a)	(b)	(c)	(d)Figure 3: Upper bounds for false positive rates on Randomized Smoothingsatisfies a monotonicity property 4. GloroNets and randomized smoothing are both monotonic in this sense(See Appendix A). However, if the (26,'p)-local robustness check fails at x, then even though the model iscertified (6,'p)-locally robust at x, there may exist an input x0 in the eball at X where the model cannotbe certified (6,'p)-locally robust and an adversary can force an unnecessary rejection. Therefore, if thestronger check fails at x, we add it to testA .
Figure 3: Upper bounds for false positive rates on Randomized Smoothingsatisfies a monotonicity property 4. GloroNets and randomized smoothing are both monotonic in this sense(See Appendix A). However, if the (26,'p)-local robustness check fails at x, then even though the model iscertified (6,'p)-locally robust at x, there may exist an input x0 in the eball at X where the model cannotbe certified (6,'p)-locally robust and an adversary can force an unnecessary rejection. Therefore, if thestronger check fails at x, we add it to testA .
Figure 4: Visualizations of successful degradation attacks on CIFAR-10 ( = 0.141).
