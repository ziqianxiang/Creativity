Figure 1: Ranking efficiency (Definition 4.1) of different LSH methods with various ρ, c = 0.95.
Figure 2: Average p to N -th neighbor.
Figure 3:	Recall vs. b. “recall@100” is the recall evaluated on the top-100 retrieved neighbors. Notethat in our case, recall@100 is equivalent to precision@100.
Figure 4:	Recall vs. number of retrieved neighbors. 1st row: b = 512. 2nd row: b = 1024.
Figure 5:	Recall@100 (precision@100) vs. γ, with b = 512.
Figure 6: Left panel: Recall@1000 (precision@1000) vs. b. Mid & Right panel: Recall vs. #retrieved points, b = 512, 1024.
Figure 7:	LSH efficiency of different LSH methods with various γ, c = 0.95. The x-axis k is theGaussian kernel value in alignment with Definition 2.3, Proposition 3.2, 3.2 and 4.1.
Figure 8:	1st row: Precision@10 against b. 2nd row: Precision vs. # of retrieved points, b = 512.
Figure 9: Data processing time (1000 queries).
Figure 10: CIFAR Top-10 retrieved images (right) for two query points (left) with b = 512: Auto-mobile and Cat. 1st row: true nearest neighbors in terms of cosine similarity of the features extractfrom the last fc layer of VGG-16. 2nd row: SignRFF. 3rd row: KLSH. 4th row: CIB. The numberon each retrieved image is the cosine similarity to the VGG-feature of the query.
