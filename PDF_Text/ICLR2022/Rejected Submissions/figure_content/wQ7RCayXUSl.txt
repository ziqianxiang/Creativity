Figure 1: Verifying theoretical predictions on the toy Continuous Chain MDP. The marked interval[-0.33, 0.33] denotes the region of state-space with no data. As anticipated by Theorem 4.1, when the valuefunctions are trained independently, the derived uncertainties capture the interaction between available data,the structure of the MDP, and the policy being evaluated. When the targets are shared, the networks behavesimilarly to performing regression for oracle-given target values, i.e. there is randomness amongst ensemblemembers only between [-0.33, 0.33] because there is no data in that region.
Figure 2: Results for efficient ensembles and ensemble ablations. Numerical values can be found in Table 4.
Figure 4: Results for DM Control Suite subset of the RL Unplugged benchmark (Gulcehre et al., 2020). Wenote that: 1) the architecture we used are smaller by a factor of approximately 60x, 2) CRR results are reportedby their best checkpoint throughout training which differs from ours, BC, and MuZero Unplugged which reportperformance at the end of training. Baseline results taken from Schrittwieser et al. (2021).
Figure 5: Comparing results of finite-width networks to closed form equations derived in Theorem4.1. In the NTK parameterization, as width → ∞, the structure of the variances collapse and resem-ble the infinite-width closed-form results. We believe this is due to infinite-width networks underthe NTK regime not being able to learn features (Yang & Hu, 2020). Supporting this hypothesis,we observe that networks parameterized by the Maximal Parameterization of Yang & Hu (2020)maintain the desired uncertainty structure as the width of the networks grows larger.
Figure 7: Results on the six antmaze domains. Each color represents the mean and standard devia-tion of results across 5 seeds for a particular hyperparameter setting (β ∈ -4, -8 and α ∈ 0, 0.1).
