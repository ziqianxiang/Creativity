Figure 1: Bandit Experiment Results. All results are averaged over 5 random seeds and plotted with95% confidence intervals. (a) Comparing MI and Entropy regularization on Principal utility. Theconstant 0-pay schedule provides a meaningful lower bound. (b, c) Pay schedule means under MI(b) and Entropy (c) regularization (pay schedule standard deviations are plotted in the Appendix).
Figure 2: Additional Bandit Experiment Results. All results are averaged over 5 random seeds andplotted with 95% confidence intervals. Results are shown for each level of MI cost (λ, x-axis) acrossmultiple levels of Agent policy temperatures (β , color). (a, b) Agent and principal utility. (c) MutualInformation between output z and payment w.
Figure 3: A depiction of a single timestep in an episode of our Sequential Multi-Agent Setting.
Figure 4: Sequential, multi-agent experiment results. All results are averaged over 20 runs andgenerated with T = 5. (a, b) Principal and Agent utility heatmaps (a) and scatter plot (b), for eachλz and λe. (c) Average wage for each Agent type, under a rational (λz = 0, yellow) and a boundedlyrational (λz = 6, blue) Principal. Error bars denote to 95% confidence intervals. (d) Utility for thelowest (k = 0) and highest (k = 4) ability Agent types, for each λz and λe .
Figure 5: Additional sequential, multi-agent experiment results. All results are averaged over 20runs. Shaded regions denote to 95% confidence. All results except (c) were generated with T = 5.
Figure 6: Additional bandit experiment results. All results were averaged across 5 random seeds andhave 95% confidence regions shaded. (a) The noise distribution between hours and output (P(z|h)).
Figure 7: Additional sequential, Multi-Agent experiment results. All results are averaged over 20random seeds and all confidence regions depict 95% confidence intervals. (a, b) Principal Utilitywith Output (λz) and Effort (λe) MI Costs. (c) The unscaled Output and Effort MI with λz and λe .
