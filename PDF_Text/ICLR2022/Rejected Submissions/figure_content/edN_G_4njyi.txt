Figure 1: Illustration of the Decomposition Theorem 1 for the synthetic scenario described in Section4.1 for n = 10 clients when sampling m = 5 of them. Panels (a) and (b) show the theoreticaldistances between global model and FL optimum obtained with the Decomposition Theorem 1 inrespectively iid and non-iid settings. Panels (c) and (d) show the distances estimated experimentallywhen averaging over 1000 simulations for iid and non-iid settings. We consider ηg = 1, ηl = 0.1,and K = 10.
Figure 2: Difference between the convergence of the global losses resulting from MD and Uniformsampling when considering n ∈ {10, 20, 40, 80} clients and sampling m = n/2 of them. In (a),clients have identical importance, i.e. pi = 1/n. In (b), clients importance is proportional to theiramount of data, i.e. pi = ni/M. Differences in global losses are averaged across 30 FL experimentswith different model initialization (global losses are provided in Appendix E).
Figure 3: Additional plots for Figure 1. Illustration of the Decomposition Theorem 1 for the syn-thetic scenario described in Section 4.1 for n = 10 clients when sampling m = 5 of them. Panels(a) to (d) show the distances estimated experimentally when averaging over 1000 simulations foriid (Panels (a) and (c)), and non-iid settings, (Panels (b) and (d)), and with the associated standarddeviation, (Panels (a) and (b)), and minimum and maximum distances, (Panels (c) and (d)). Weconsider ηg = 1, ηl = 0.1, and K = 10.
Figure 4: We consider the synthetic scenario described in Section 4.1 for n = 100 clients whensampling m = 5 and r = 0.9. We show the distances estimated experimentally when averagingover 1000 simulations for iid (Panel (a)), and non-iid settings (Panel (b)). We consider ηg = 1,ηl = 0.2, and K = 1. With K = 1, we show that the divergence does not come from asking toomuch work to the local clients. Uniform sampling divergence can be prevented by lowering the locallearning rate ηl (consistently with Theorem 2).
Figure 5: Convergence speed of the global loss with MD sampling and Uniform sampling whenconsidering n = 10 ((a) and (e)), n = 20 ((b) and (f)), n = 40 ((c) and (g)), and n = 80 ((d) and(h)), while sampling m = n/2 of them. In (a-d) , clients have identical importance, i.e. pi = 1/n,and, in (e-h), their importance is proportional to their amount of data, i.e. pi = ni/M. Global lossesare estimated on 30 different model initialization.
Figure 6:	Difference between the convergence of the global losses resulting from MD and Uniformsampling when considering n = 80 clients and sampling m ∈ {4, 8, 40} of them while clientsperform K = 50 SGD steps . In (a), clients have identical importance, i.e. pi = 1/n. In (b), clientsimportance is proportional to their amount of data, i.e. pi = ni/M. Differences in global losses areaveraged across 15 FL experiments with different model initialization (global losses are provided inFigure 7).
Figure 7:	Convergence speed of the global loss with MD sampling and Uniform sampling whenconsidering n = 80 clients while sampling m = 4 ((a) and (c)), and m = 8 ((b) and (d)) whileclients perform K = 50 SGD steps. In (a-b) , clients have identical importance, i.e. pi = 1/n, and,in (d-f), their importance is proportional to their amount of data, i.e. pi = ni/M . Global losses areestimated on 15 different model initialization.
Figure 8:	Difference between the convergence of the global losses resulting from MD and Uniformsampling when considering n = 80 clients and sampling m ∈ {8, 40} of them while clients performK = 1 SGD step. In (a), clients have identical importance, i.e. pi = 1/n. In (b), clients importanceis proportional to their amount of data, i.e. pi = ni/M. Differences in global losses are averagedacross 15 FL experiments with different model initialization (global losses are provided in Figure9).
Figure 9: Convergence speed of the global loss with MD sampling and Uniform sampling whenconsidering n = 80 clients while sampling m = 4 ((a) and (d)), m = 8 ((b) and (e)), m = 40 ((c)and (f)) while clients perform K = 1 SGD steps. In (a-c) , clients have identical importance, i.e.
Figure 10: Convergence speed of the global loss with MD sampling and Uniform sampling whenconsidering n = 100 clients, while sampling m = 10 of them. Clients are partitioned using aDirichlet distribution with parameter α = 0.1 (a), α = 0.01 (b), and α = 0.001 (c). Global lossesare estimated on 30 different model initialization.
