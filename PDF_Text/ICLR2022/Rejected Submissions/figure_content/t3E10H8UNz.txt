Figure 1: (a) Both the high-level network and sub-skills need to be transferred to new tasks. Above:when the robot arm is over a half-open drawer, the task can be either opening or closing the drawer,which requires the high-level network to call different sub-skills. Below: a same sub-skill pick-placemay exhibit different specific forms in new tasks. (b) DMIL aims to integrate MAML into HIL witha novel iterative optimization procedure that meta-learns both the high-level network and sub-skills.
Figure 2: The iterative meta-learning process of DMIL at each iteration. Left: the supervision ofhigh-level network (sub-skill categories) comes from the most accurate sub-skill (the green one,sub-skill 1 here). Right: the sub-skill updated at current step (the green one, sub-skill 0 here) isdetermined by the fine-tuned high-level network.
Figure 3: The iterative meta-learning process of DMIL at each iteration. Left: the supervision ofhigh-level network (sub-skill category) comes from the most accurate sub-skill. Right: the sub-skillupdated at current step is determined by the fine-tuned high-level network.
Figure 4: T-sne results and ablation studies about the bi-level meta-learning process.
Figure 5: The training loss of the high-level network with a softmax shows a trend of rising first andthen falling.
Figure 6: The ML45 environment.
Figure 7: The ML10 environment.
Figure 8: Task push-around-wall.
Figure 9: Kitchen environments.
Figure 10:	The ML10 results of different methods after 3-shot adaptation.
Figure 11:	The ML45 results of different methods after 3-shot adaptation.
