Figure 1: 3D bit-tensor connecting two dense layers, U and V, with 4 and 3 nodes, respectively.
Figure 2: Classification accuracy and sparsity as a function of the weights bit-depth with LeNet(left) and ResNet (right). The right-most data point indicates the performance of the standard 32-bittraining technique. Lower panels indicate the amount of non-zero weights remaining after training.
Figure 3: Weight distribution of the second LeNet layer before and after training.
Figure 4:	LeNet trained with all bit patterns for 2 (left), 4 (right) and 8 bits (bottom panel).
Figure 5:	ReSNet trained with all bit patterns for 2 (left), 4 (right) and 8 bits (bottom panel).
Figure 6: ResNet test accuracy and sparsity after bit-wise training: only the magnitude bits (blue),only the sign bit (red), all bits (green). Baseline indicated by right-most data point.
Figure 7: ResNet accuracy as a function of number of trainable bits, counting from the sign bit.
Figure 8: Test accuracy for LeNet (left) and Conv6 (right) as a function of the number of changedbits after training. Red points correspond to setting bits to 1; green correspond to 0; blue violinscorrespond to setting bits randomly to either 0 or 1. Bottom panels indicate sparsity.
Figure 9: Test accuracy with various messages embedded in the first 29 untrainable bits of ResNet.
