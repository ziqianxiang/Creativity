Figure 1: Illustration of the proposed architecture to enforce domain invariant representation. Thefeature extractor and label classifier form the a regular DNN architecture that can be used for themain natural task. The domain classifier is incorporated alongside the label classifier. The reversalgradient layer multiplies the gradient by a negative number during the back-propagation.
Figure 2: Mean and std differences comparison between DIAL, naturally trained model and modeltrained using standard adversarial training on five random features from the features layer. Each barrepresent the difference between the means/std of the natural examples and the mean/std of theircorresponding adversarial examples on this same feature.
Figure 3: Accuracy comparison over all unfore-seen corruptions.
Figure 4: Ablation studies for DIALKL and DIALCE on CIFAR-10.
Figure 5: t-SNE embedding of model output (logits) into two-dimensional space for DIAL andTRADES using the CIFAR-10 natural test data and the corresponding adversarial examples.
Figure 6: Accuracy comparison with all tested methods over unforeseen corruptions.
Figure 7: Mean and std differences comparison between DIAL, naturally trained model and modeltrained using standard adversarial training on thirty random features from the features layer on theCIFAR-10 dataset with WRN-34-10 architecture. Each bar represents the absolute difference be-tween the means/std of the natural examples and the mean/std of their corresponding adversarialexamples on this same feature.
Figure 8: t-SNE embedding of model output in two-dimensional space for MART, AT, and ATDAunder natural and adversarial test data from CIFAR-10.
