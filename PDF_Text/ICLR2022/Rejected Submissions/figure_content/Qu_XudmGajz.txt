Figure 1: Top: Samples gener-ated with a standard VAE exhibit-ing pixel-wise independent noise.
Figure 2: Qualitative results comparing a standard VAE (2a) and the proposed VAE (2b) on theCELEBA dataset. Same comparison on the UKBB dataset (2c & 2d). The rows from top to bottom:the mean of the observational distribution, a sample from the observational distribution, the differ-ence between the mean and the given sample, the pixel-wise independent variance per pixel, a sliceof the covariance matrix: positive covariance and negative covariance to the central pixel.
Figure 3: Spherical linear interpolation between auxiliary noise variables ωp . The four cornersare random samples from a predicted distribution with all intermediate steps as interpolations be-tween them. The two images represent interpolations in the observation space for two observationaldistributions predicted from different latent codesya and yb . This is shown in equation 3, where ωp ∈ RR and ωd ∈ R(S×C)are both auxiliarynoise variables, slerp is the spherical interpolation function (see appendix D) and t ∈ [0, 1] is theinterpolation factor.
Figure 4: The effect of scaling each of the ten most principal components (each row), from top tobottom for a fixed auxiliary noise variable. The scale factor for each component ranges from -5 to+5 with intervals of 0.5.
Figure 5: Sequentially editing hair colour and skin tone interactively. From left to right: a predictedimage with a small coloured edit made to the hair, the image after the conditional distribution hasbeen calculated, the image with a further edit to the skin tone, the image after the conditional distri-bution has been recalculated. N.B: The red circles highlighting the manual edits are for illustrationpurposes only and serve no computational purpose.
Figure 6: A qualitative comparison between 100 samples from the learnt observation space at rank= 25 with no deep learning components (left) and 100 samples from a linear PCA model with 25features (right). In both cases, the data used for fitting is the same random subset of 10000 imagesfrom the CELEBA dataset.
Figure 7: The results after training with a pre-training phase and weight initialisation, but withoutthe fixed component, D = I, or the entropy constraint. The first row represents the predicted meansand all other rows represent samples from the predicted distribution outputted from the probabilisticdecoder. Each column is a new sample from the latent prior decoded to predict distributions overthe observation space. Model trained for 100 epochs on a random subset of 10000 images from theCELEBA dataset. Latent dimensionality: l = 128, rank: R = 25, target KL loss: ξKL = 45.
Figure 8: The effect of scaling each of the principal components (each row), from top to bottom fora fixed auxiliary noise variable and a rank 25 parameterisation. The scale factor for each componentranges from -5 to +5 with intervals of 0.5. Observational distribution predicted by our VAE aftertraining on the CELEBA dataset.
Figure 9: The effect of scaling each of the principal components (each row), from top to bottom fora fixed auxiliary noise variable and a rank 25 parameterisation. The scale factor for each componentranges from -5 to +5 with intervals of 0.5. Observational distribution predicted by our VAE aftertraining on the UKBB dataset.
Figure 10: Sequential interactive editing. From left to right: predicted image with a small colourededit made to the hair, the image after the conditional distribution has been calculated, the imagewith a further edit to the skin tone, the image after the conditional distribution has been recalculated.
Figure 11: Interactive editing. Left: predicted image with a single-pixel manual coloured edit overthe hair. Right: the mean of the calculated conditional distribution. N.B: The red circle highlightingthe manual edit is for illustration purposes only and serves no computational purpose.
Figure 12: Interactive editing. Left: predicted image with a manual coloured edit over the skin.
Figure 13: Interactive editing. Left: predicted image with a manual coloured edit over the back-ground. Right: the mean of the calculated conditional distribution.
