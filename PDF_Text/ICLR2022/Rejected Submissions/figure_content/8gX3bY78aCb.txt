Figure 1: Example of building a motifs vocabulary. Given a molecule Tosic Acid, We first extract sixbonds and rings from its atom graph. After removing duplicates, we add five unique motifs into thevocabulary. Blue, red, and purple nodes represent Carbon, Sulfur, and Oxygen atoms, respectively.
Figure 2: Example of a heterogeneous motif graph. In this graph, there are five molecular nodes:Phenol, Styrene, Toluene, m-Cresol, and 3-Chlorophenol. Here, we have five motifs in the vocab-ulary. We connect a molecular node with a motif node if the molecule contains this motif. Forexample, Phenol has Benzene and carbon-oxygen bond. Thus, We connect the Phenol node with theBenzene node and carbon-oxygen bond node. We connect two motif nodes if they share at least oneatom in molecules. In this graph, we connect the Benzene node and the carbon-oxygen bond nodesince they share a carbon atom.
Figure 3: Example of our HM-GNN. Given an input Phenol, we first apply a GNN on its atom-levelgraph structure to learn its atom-level feature embedding. Meanwhile, we add it into a heteroge-neous motif graph and use a heterogeneous GNN to learn its motif-level graph embedding. In theheterogeneous motif graph, Phenol is one of the molecular nodes. Finally, we concatenate graphembeddings from two GNNs and feed them into a MLP for prediction.
Figure 4: Example of generating a sub-graph for a 3-layer HM-GNN via an edge sampler. A sam-pling rule is we sample all edges, one edge, two edges for each layer, respectively (We select motif-motif edges at first). In this graph, we have four molecular nodes and seven motifs nodes. We usesolid lines to represent selected edges and dashed lines to indicate unselected edges. We randomlychoose node S as the "starting" node. In the first hop, we keep all edges connecting the node Sand motif nodes. We sample one motif-motif edge for each motif node connecting to node S in thesecond hop. In the third hop, two motif-motif edges are selected for each newly added motif nodein the last hop. Finally, the resulting sub-graph contains all nodes and edges we sampled.
Figure 5: Results of ROC-AUC and memory us-age using different number of starting nodes. Wevary the number of starting nodes from 5,000 to29,000. The ROC-AUC performances and mem-ory usages of different batch sizes are illustratedon blue and red lines, respectively.
Figure 6: The impact of the motif keeping ra-tio. We evaluate our method using differentkeeping ratio of the original motif vocabu-lary.
