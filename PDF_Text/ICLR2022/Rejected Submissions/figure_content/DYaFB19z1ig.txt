Figure 1: General structure of a self-distribution distilled model. M stochastic teacher branch forwardpropagations are trained on cross-entropy and simultaneously distribution distilled to the student.
Figure 2: Dirichlet S2D model during training. Only the black part of the network is retained duringprediction time, matching the behaviour of a standard model.
Figure 3: The architecture of a diagonal H2D-Gauss student.
Figure 4: Histograms of various uncertainties produced by Deep ensemble, S2D, S2D Deep ensembleand H2D-Gauss systems. Out-of-distribution data was generated from the SVHN test set.
