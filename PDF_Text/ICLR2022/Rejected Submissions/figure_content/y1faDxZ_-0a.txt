Figure 1: Depiction of the Self-supervised and Personalized Federated Learning (SSFL) framework.
Figure 2: Training and Evaluation using SSFLThe goal of this experiment is to understand the accuracy gap between supervised and self-supervisedfederated learning in both I.I.D. and non-I.I.D. settings where we aim to train a global model fromprivate data from clients.
Figure 3: Training and Evaluation using SSFLWe illustrate our results in Figure 10 and Table 2. To confirm the convergence, we draw loss curvesfor all methods in Figure 10(b) (note that they have different scaled values due to the differenceof their loss functions). Figure 10(b) indicates that Per-SSFL performs best among all methods.
Figure 4: Results for batch sizesand knowledge distillation. We defer the discussion to Appendix F.
Figure 5: Evaluation on Different Degress of Non-I.I.D.ness0	200	400	600	800(a) Averaged Personalized Accuracyâ€”alpha (0.5)-alpha (0.1)round(b) Training LossFigure 6: Understanding theEvaluation Protocol5.4.3 Understanding the Linear Evaluation of Personalized EncodersAs we discussed in 4, in SSFL, we can easily verify the quality of the SimSiam encoder usingfederated linear evaluation; however, in Per-SSFL, each client learns a personalized SimSiamencoder. Such heterogeneity in diverse encoders makes a fair evaluation difficult. To demonstrate this,we run experiments with naive federated linear evaluation on personalized encoders and surprisinglyfind that such an evaluation protocol downgrades the performance. As shown in Figure 6, the federatedlinear evaluation for Per-SSFL performs worse than even LA-SSFL. This may be attributed tothe fact that the naive aggregation drags close to the parameter space of all heterogeneous encoders,making the encoder degenerate in terms of personalization.
Figure 6: Understanding theEvaluation Protocol5.4.3 Understanding the Linear Evaluation of Personalized EncodersAs we discussed in 4, in SSFL, we can easily verify the quality of the SimSiam encoder usingfederated linear evaluation; however, in Per-SSFL, each client learns a personalized SimSiamencoder. Such heterogeneity in diverse encoders makes a fair evaluation difficult. To demonstrate this,we run experiments with naive federated linear evaluation on personalized encoders and surprisinglyfind that such an evaluation protocol downgrades the performance. As shown in Figure 6, the federatedlinear evaluation for Per-SSFL performs worse than even LA-SSFL. This may be attributed tothe fact that the naive aggregation drags close to the parameter space of all heterogeneous encoders,making the encoder degenerate in terms of personalization.
