Figure 1: An illustration of the semantic linking injection pipeline in SCAN. The two middleboxesshow the augmented dataset used for semantic linking through deductive learning (upper) and in-ductive learning (lower). In practice, the prior knowledge (left) and the augmented dataset (middle)are for training, and the new compositions of variants (right) are for testing. Models are expected togeneralize to new compositions given prior knowledge and semantic linking.
Figure 2: Experiments on SCAN with a decreasing number of training samples per variant from thecomplete set (100%) to a single sample (1). The solid line represents the change of overall trainingsize, and the dashed line stands for that of test sequence accuracy. There is hardly a performancedip when training samples are deleted until only one remained.
Figure 3: Experiments over RNN on SCAN with varying |PSCAN | (a) and |VSCAN | (b).
Figure 4: A concrete example of semantic linking. The bidirectional arrows denote symmetricrelations. Mississippi and Massachusetts are two specific states, thus both hyponyms of state. Inturn, state is a hypernym of them. Due to a common hypernym, Mississippi and Massachusettsbecome a co-hyponym for each other. {heavily populated, congested, populus}, {area, region}are two groups of synonyms for sharing same or similar semantics. Finally, U.S., as a kind ofabbreviation, is a lexical variant of United States.
