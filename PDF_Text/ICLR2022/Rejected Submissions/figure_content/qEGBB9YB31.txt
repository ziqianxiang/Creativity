Figure 1: Filter-wise parameter saliency profile. ResNet-50 filter-wise saliency profile (withoutstandardization) averaged over samples in ImageNet validation set. The filter saliency values in eachlayer are sorted in descending order, and each layer’s saliency values are concatenated. The layersare displayed left-to-right from shallow to deep and have equal width on x-axis.
Figure 2: Standardized filter-wise saliency profiles, correctly vs incorrectly classified samples.
Figure 3: Effect of turning salient filters off. (a) Change in incorrect class confidence score. (b)Change in true class confidence score. (c) Percentage of samples that were corrected as the resultof pruning filters. These trends are averaged across all images misclassified by ResNet-50 in theImageNet validation set. The error bars represent 95% bootstrap confidence intervals.
Figure 5: Neighbors in parameter saliency space found using only early or only deep layers.
Figure 6:	Effect of updating a small number of filters. (a) Percentage of samples that are correctedafter fine-tuning. (b) Average percentage of nearest neighbors that are also corrected after fine-tuning.
Figure 7:	Interaction between input features and salient filters. (a) Reference image of “greatwhite shark” misclassified by ResNet-50 as “killer whale” with confidence scores. (b) Input-spacesaliency visualization. Pixels that cause the top 10 salient filters to have high saliency. (c) Change insaliency values of the erroneous filters across masking experiments. The vertical bars represent thestandard deviation of the change across 10 most salient filters. (d)-(f) Masking experiments.
Figure 8: Different types of network mistakes. All of the presented images are misclassified byResNet-50. The correct class label is specified in the top row and the incorrect class label - in thebottom row of the subcaption on each panel. (a)-(b) The target object is confused with another objectin the image. (c) A regular mistake. The salient pixels are focused on the target object features whichconfuse the network. (d) Background features confuse the network. (e) An example of a noisy labelwhere the network is “more correct” than the target label. These are examples where masking top 5%of the salient pixels corrects the misclassification.
Figure 9: Filter-wise saliency profiles for other architectures. (a) VGG-19 saliency profile (with-out standardization). (b) Inception v3 saliency profile (without standardization). (c) DenseNetsaliency profiles (without standardization). In each panel the filter-wise saliency profile is averagedover the ImageNet validation set. In every panel, the filter saliency values in each layer are sortedin descending order, and each layer’s saliency values are concatenated. The layers are displayedleft-to-right from shallow to deep and have equal width on x-axis.
Figure 10: Standardized saliency profiles averaged over correctly vs incorrectly classified sam-ples. (a) VGG-19 saliency profiles. (b) Inception v3 saliency profiles. (c) DenseNet saliency profiles.
Figure 11: Examples of nearest neighbors in the feature representation space (from ImageNet).
Figure 12: CIFAR-10 examples of nearest neighbors in parameter saliency space. On CIFAR-10images that cause similar filters to malfunction are often misclassified in a similar way.
Figure 13: ImageNet examples of nearest neighbors in parameter saliency space. In every panel,the reference image is in the left column and its nearest neighbors are in the right column. Panels arecaptioned by the true label of their reference image.
Figure 14:	Effect of updating a small number of filters on the ImageNet-v2 test data. (a)Percentage of samples that are corrected after fine-tuning. (b) Average percentage of nearest neighborsthat are also corrected after fine-tuning. (c) Average change in the confidence score of the true classamong nearest neighbors. The horizontal line in each plot is the effect of updating the entire network.
Figure 15:	Effect of updating a small number of filters on VGG-19. (a) Percentage of samplesthat are corrected after fine-tuning. (b) Average percentage of nearest neighbors that are also correctedafter fine-tuning. (c) Average change in the confidence score of the true class among nearest neighbors.
Figure 16:	Effect of randomly perturbing filters. (a) Change in incorrect class confidence score.
Figure 17:	Masking non-salient parts of the image. (a) Reference image of “great white shark”misclassified by the model as “killer whale” and the corresponding confidence scores. (b) Pixelsthat cause the top 10 most salient filters to have high saliency. (c) Masked (non-salient) human. (d)Masked non-salient water region.
Figure 18: Sample “great white shark” images with boat and seal. The salient region from thecase study image pasted onto other “great white shark” images.
Figure 19: ImageNet examples of “killer whale”.
Figure 20: Pixels responsible for mistakes focused on the target object. (a)-(b) Masking thesalient pixels corrects the misclassification where masking confusing features (e.g. dog ears orspot patterns) helps distinguish animals. (c)-(d) Masking the salient pixels results in correct classconfidence decrease, when the salient pixels are densely focused on the target object. The correctclass label is specified in the top row and the predicted incorrect class label - in the bottom row of thesubcaption on each panel.
Figure 21: Comparison to GradCAM. Top row: original image. Middle row: GradCAM input-space saliency map for the predicted label. Bottom row: our input-space saliency technique whichhighlights pixels that drive high parameter saliency values of specific filters (i.e., pixels that confusethe network). The correct class label is specified in the top row and the predicted incorrect class label-in the bottom row of the subcaption on each panel.
Figure 22: Comparison to GradCAM. Top row: original image. Middle row: GradCAM input-space saliency map for the predicted label. Bottom row: our input-space saliency technique whichhighlights pixels that drive high parameter saliency values of specific filters (i.e., pixels that confusethe network). The correct class label is specified in the top row and the predicted incorrect class label-in the bottom row of the subcaption on each panel.
Figure 23: Sanity checks. (a) No randomization of ResNet-50. (b) Only stage 4 of ResNet-50is randomized. (c) Stages 3-4 of ResNet-50 are randomized. (d) Stages 2-4 of ResNet-50 arerandomized. (e) The entire ResNet-50 is randomized.
