Figure 1: Limitations of first-order uncertainty measures and their handling with KLoS. (a) Anin-distribution image with conflicting evidence between dog and wolf. (b) An outlier with same classconfusion but a lower amount of evidence. An evidential neural network (ENN) outputs class-wiseevidence information as concentration parameters of a Dirichlet density (visualized on the simplex)over 3-class distributions. Although this density is flatter for the second input, the predictive entropyand MCP, only based on first-order statistics, are equal for both inputs. In contrast, the proposedmeasure, KLoS, captures both class confusion and lack of evidence, hence correctly reflecting thelarger uncertainty for the latter sample.
Figure 2: Precision densitiesfor ID (CIFAR-10) and OOD(TinyImageNet) samples whenno OOD training data is used.
Figure 3: KLoS and KLoS* on the probability simplex. Given the input sample, the blue regionrepresents the distribution predicted by the evidential model and the orange region represents theprototype DiriChlet distribution with parameters Yy = (1, ∙ ∙ ∙ , 1,τ, 1,..., 1) focused on the pre-dicted class y. Illustration of the behavior of KLoS in absence of uncertainty (a), in case of classconfusion (b) and in case of a different amount of evidence, either lower (c) or higher (d).
Figure 4: KLoS*KLoS*(x,y)，KL(Dir(π∣α(x, θ)) ∣∣ Dir(π∣γy)),	(7)where Yy corresponds to the uniform concentrations except for the true class y with T = 1 + λ-1 .
Figure 5: Comparison of various uncertainty measures for a given evidential classifier on a toydataset. (a) Training samples from 3 input Gaussian distributions with large overlap (hence classconfusion) and OOD test samples (blue); (b) Correct (yellow) and erroneous (red) class predictionson in-domain test samples; (c-f) Visualisation of different uncertainty measures derived from theevidential model trained on the toy dataset. Yellow (resp. purple) indicates high (resp. low) certainty.
Figure 6: Effect of OOD training data on precision α0. Den-sity plots for CIFAR-10/TinyImageNet benchmark: (a,b) with in-appropriate OOD samples (SVHN, LSUN); (c) with close OODsamples (CIFAR-100).
Figure 7: Impact of the over-sampling factor κ (CIFAR-10/TinyImageNet).
Figure 8: Comparative detection results with different OOD training datasets. While usingOOD samples in training improves performance in general, the gain value varies widely, sometimeseven being negative for inappropriate OOD samples e.g., SVHN. KLoS remains the best measure inevery setting. Experiment with VGG-16 architecture on CIFAR-10 dataset.
Figure 9:	Visualisation of the different terms of KLoS, derived from the evidential model trained onthe same toy dataset than in the main paper.
Figure 10:	Results with SVHN as OOD dataset (% mean AUROC and std. over 5 runs).
Figure 11: Effect of inverse adversarial perturbations on OOD-designed measures and KLoS formisclassification detection, OOD detection and simultaneous detection with VGG-16 architecture.
Figure 12:	Selective classification on CIFAR10-C. Comparative performance in AURC (%) ofclassification with the option to reject misclassified test samples and samples from shifted distribu-tions. Results are average on 5 runs (mean ± std.).
Figure 13:	Selective classification on CIFAR100-C. Comparative performance in AURC (%) ofclassification with the option to reject misclassified test samples and samples from shifted distribu-tions. Results are average on 5 runs (mean ± std.).
