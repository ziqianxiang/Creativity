Figure 1: Illustration of CEM approachesin optimization. Shades of red indicate rela-tive value of the 2D optimization landscape:brighter is better. Optimal solutions are nearbottom left corner of the solution space. Bluedots ∙ are top-k samples, and black dots ∙are other samples. Open dots O represent thesampling distributions with size of dots indi-cating number of generated samples.
Figure 2: Cross Entropy Method (CEM) for Planning in MBRLby φ, where each sample τj is an action sequence from the current time step up to the planninghorizon H. The domain of gφ(τ) has a dimension of dτ = daH.
Figure 3: Left: The objective function in a 1D optimization task. Right: Comparison of our proposedDecentCEM method to CEM and CEM-GMM, wherein the line and the shaded region denote themean and the min/max cost from 10 independent runs. X: resulting solution of each method.
Figure 4: How the sampling distributions evolve in the 1D optimization task, after the specifiediteration. Symbols include samples ∙, elites ∙, local optima ∙, global . 2nd row in each figureshows the weighted p.d.f of individual distribution. Population size: 200.
Figure 5: DecentCEM planning architecture. ψi = φifor planning in action space and ψi = θi for planningin policy network parameter space.
Figure 6:	The learning curves of the proposed DecentCEM methods and the baseline methods oncontinuous control environments. The line and shaded region shows the mean and standard error ofevaluation results from 5 training runs using different random seeds. Each run is evaluated per train-ing episode in an environment independent from training and reports average return of 5 episodes.
Figure 7:	Ablation study on the policy network size where POPLIN-A&P have a bigger policynetwork equivalent in the total number of neural network weights to their DecentCEM counterparts.
Figure 8: Ablation of ensemble diversity. Left:Cumulative selection ratio of each CEM instance.
Figure 9: The iterative sampling process in the 1D optimization task.
Figure 10: The learning curves of the proposed DecentCEM methods and the baseline methods oncontinuous control environments. The line and shaded region shows the mean and standard errorof evaluation results from 5 training runs using different random seeds. Each run is evaluated in anenvironment independent from training and reports average return of 5 episodes at every trainingepisode. To ensure that the evaluation environments are the same across different methods andmultiple runs, we set a fixed random seed in the evaluation environment of each task.
Figure 11: More Ablation (a) Pairwise distance between the actions of 5 instances in DecentCEM-A during training (b) Ensemble size ablation: E2 denotes an ensemble size of 2 (c) Policy controlperformance where the policy network is directly used for control without CEM policy improvement19Under review as a conference paper at ICLR 2022Figure 11 (a) is an additional plot for the ensemble diversity ablation. It shows the statistics of thepairwise distance between the output actions by the CEM instances at each time step. The same asin Fig. 8 (b), we only show a time window toward the end of training for visual clarity and the lineand shaded region represent the mean and min/max distances.
