Figure 1: Overview of the ImpressLearn method (best viewed in colour). Given a fixed-weightrandomly initialized backbone network, we show that a few binary mask ”impressions” from trainingprior tasks (3 in this case) can form a linear combination with coefficients α to learn new tasks.
Figure 2: Left: Average validation performance on 10 new Rotated MNIST tasks by number ofimpressions and impression type. X indicates incorrect mask. Numbers 5, 10, . . . indicate heteroge-neous and numbers with ∧ indicate a homogeneous impression set. Right: Average performance ontasks 1 to min(|Mhom|, 25) in basis-GN regime on basis tasks without task identity. All results areaveraged over 3 different seeds and masks of density ∈ {5, 8, 10, 15, 20, 25, 30} × 10-2.
Figure 3: Left: Average performance on 10 new PermutedMNIST tasks by number of impressionsand impression type. X indicates incorrect mask. Numbers N indicate a heterogeneous and N ∧ ahomogeneous impression set. Right: Performance of our α-optimization in the basis-GN regimeaveraged over min(|M|, 25) basis tasks. All results are averaged over 3 different seeds and masks ofdensity ∈ {5, 8, 10, 15, 20, 25, 30} × 10-2 .
Figure 4: Left: Average performance on 5 new Split CIFAR-100 tasks by number of impressionsand impression type. X indicates incorrect mask. Numbers N indicate a heterogeneous and N ∧ ahomogeneous impression set. Right: Performance of our α-optimization in the basis-GN regimeaveraged over min(|M|, 25) basis tasks. All results are averaged over 3 different seeds and masks ofdensity ∈ {5, 8, 10, 15, 20, 25, 30} × 10-2 .
Figure 5: Left: Average performance on 5 new SplitImageNet tasks by number of heterogeneousimpressions. X indicates incorrect mask. Right: Performance of our α-optimization in the basis-GNregime averaged over min(|M|, 25) basis tasks.
Figure 6: Comparison of inference accuracy between basis-GN, SupSup GG and SupSup GNon PermutedMNIST. GN performance averaged over 10 different data splits and orderingsper seed and sparsity. All results are averaged over 3 different seeds and masks of density∈ {5, 8, 10, 15, 20, 25, 30} × 10-2.
Figure 7: Random vs Homogeneous masks: Average validation performance on 10 unseen Ro-tated MNIST tasks by number of impressions and impression type.X indicates incorrect mask.
Figure 8: Random vs Homogeneous masks: Average validation performance on 10 unseen Per-muted MNIST tasks by number of impressions and impression type. X indicates incorrect mask.
Figure 9: Random vs Homogeneous masks: Average performance on 5 unseen Split CIFAR-100tasks by number of impressions and impression type. X indicates incorrect mask. Standard numbersindicate an impression set of random, untrained masks and N ∧ indicates a homogeneous impressionset.All results averaged over 3 different seeds and masks of density ∈ {5, 8, 10, 15, 20, 25, 30}× 10-2.
Figure 10: Left: Hybrid vs Regular (Heterogeneous Impressions). Right: Hybrid vs Regular(Homogeneous Impressions). Average performance on 5 new Split CIFAR-100 tasks by numberof impressions and impression type. h denotes a hybrid model was used whereas ∧ indicates ahomogeneous impression set. h∧ indicates both. All results averaged over 3 different seeds andmasks of density ∈ {5, 8, 10, 15, 20, 25, 30} × 10-2.
