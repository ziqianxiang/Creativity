Figure 1: Showcasing a prime from the test set steered in two different ways. The original contin-uation has arpeggiation (the steep rising and falling lines) throughout. The right piano rolls weresteered with a logical feature that checks for many simultaneous notes (block chords). In particular,the bottom right piano roll shows that the model learned to ”exploit” the logical feature by repeatinga low note, while still sounding musical.
Figure 2: Overall training setup, where the (positive) feature being learned is φj (with parametersθj), and the negative feature is φi (with parameters θi). The parameters θ, used for the unconditionalnegative log-likelihood, are not learned.
Figure 3: Prefix- and bias-tuning methods used to steer the music transformer.
Figure 4: MLE loss during training of the bias tuning method. Using the contrastive loss is moreeffective at discriminating between cofactual and counterfactual features (see subsection 5.2).
Figure 5: Left: Difficulty is quantified as the efficacy of the unconditional model. In mostcases, contrastive learning significantly improves over non-contrastive learning (as evidenced bythe dashed orange lines). In only a few cases does prefix tuning fail to improve over the uncon-ditional model. Middle and right: Efficacy of various methods with various numbers of steeredfeatures on cofactual and random features.
Figure 6: Varying difficulties of features, evaluated with the unconditional model.
Figure 7: Bar plots.
Figure 8: Additional gain after 5 features are already included occur along almost every feature,suggesting that the bias-tuned transformer really can be used compositionally.
