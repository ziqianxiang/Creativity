Figure 1: Basic explanation: (a) Learned prototypes that represent the training dataset and distancesbetween the input and prototypes. Additional explanations(b-d): (b) Relationships between inputand prototypes. Bottom of the figure explains that the explanation space enables us to see howinput 9 gradually becomes prototype 4. (c) Relationships between prototypes. Providing gradualchanges from prototype to another prototype that explains how model discriminates prototypes. (d)Prototype distribution visualization with two dimensions based on standard deviation demonstratingthat prototypes are not luckily chosen.
Figure 2: Overall model architecture. The entire model is trained end-to-end. Since the uncertaintylayer was used to reduce uncertainty in the training process, classification proceeds through logits.
Figure 3: Visualizations for the latent space of FashionMNIST by three models. (a) Li et al. (2018)(b) Proposed model with VAE. (c) Proposed model with FactorVAE.
Figure 4: Explanations of classification network with 20 prototype distributions and FactorVAE.
Figure 5: Accuracy and visualizations of prototypes. (a) Classification accuracy by changing numbersof prototype distributions (b) Visualization of prototypes μ% (i = 1,...,m) at number of prototypedistributions m = [2, 3, 10, 30, 100]We conducted two surveys through Amazon Mechanical Turk with50 Mechanical Turk masters. Each survey consists of 12 questions,6 per correct classification and misclassification. The average re-sponse rate for answering the factor is in Table 3. This result showsthat participants were better able to answer factors for model pre-dictions when given the additional explanations of the relationshipbetween inputs and prototypes. It shows that relationships enablesus to better understand the factors that compute distances.
Figure 6: Example of interactive reconstruction experiment.
Figure 7:	Consent form and example of survey without relationships.
Figure 8:	Consent form and example of survey with relationships.
Figure 9: Prototypes made with the proposed model using (a) KL-divergence, (b) JSD, and (c) JTDas distance measurements. Visualizations for their latent space by t-SNE (d) KL-divergence, (e) JSD,(f) JTD. Models are trained using vanilla VAE at the VAE layer with 1000 epochs.
Figure 10: T-SNE visualizations for the embedded FashionMNIST using three types of VAE for theVAE layer. (a) vanilla VAE, (b) β-VAE, (c) FactorVAE.
Figure 11:	Visualized prototypes from proposed model with three types of VAE for the VAE layer.
Figure 12:	(a) Basic explanation with prototypes and distance between embedded input and prototypedistributions. (b) Relationships between input and prototypes. (c) Relationships between prototypesthe factors that caused the model to predict distance farther by the relationships between the inputand the prototypes. Also, by examining the relationship between each prototype, we can find out howthe model distinguishes the classes. If the explanation is insufficient, more detailed explanations canbe obtained by visualizing more interpolation values between prototypes.
