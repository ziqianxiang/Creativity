Figure 1: (a) A toy example of intersectional bias. Suppose all intersectional groups are equallyrepresented in the data. A model has the same 80% average accuracy on each of the listed agegroups and genders. However, some intersectional groups (e.g., 60 yr females) have only 70%accuracy. (b) Figure of samples from the ImageNet’s “Programmer” synset but balanced along theattributes of gender, skin color and age (taken from Yang et al. (2020)). Our ImageNet experimentsexplore methods of mitigating bias against the intersection of these attributes.
Figure 2: Bias mitigation algorithms on CelebA-SL task for k ∈ [1, 7]. The left figure plots thereweighted accuracy. Independent-SP and U-JTT have low reweighted accuracy compared to theremaining methods. The middle figure plots bias amplification. Only Independent-SP has a abovezero bias amplification score. The right figure plots intersectional bias. U-ERM and U-JTT havepoor intersectional bias. The unlabeled method U-SD has competitive intersectional bias for smallk but, for large k, is outperformed by Weighted ERM with a margin increasing in k.
Figure 3: Bias mitigation algorithms on CelebA-ML task for k ∈ [1, 7]. The left figure plots thereweighted mAP. The left middle plots the bottom quartile mAP scores. U-ERM and Independent-SP score marginally higher than Weighted ERM. The right middle plots bias amplification withWeighted ERM having the lowest bias amplification. The right figure plots intersectional bias withIndependent-SP having the lowest intersectional bias. U-JTT starts with low intersectional bias, butgrows beyond that of Weighted ERM and Independent-SP with the number of protected attributes.
