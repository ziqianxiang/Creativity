Figure 1: Synthetic multi-task problem. Following Yu et al. (2020), we evaluate our approach andrecent baseline MTL methods on a multi-task optimization problem, where the multi-task objectivegradient is dominated by one task. For each MTL method, we visualize the trajectory of gradientupdates computed for an equal number of iterations. The proposed θ-aligned method can handle theimbalance and converges faster compared to prior state-of-the-art MTL approaches.
Figure 2: Geometric interpretation. (a) Decomposition of the original problem to orthogonalcomponents through a SVD. (b) Re-weighting the gradient directions by balancing the conditioning.
Figure 3: Sketch of J> J ≈ λI. TheJacobian matrix J was computed for thefirst 50 channels from the output of layer4 of ResNet-18.
Figure 4: Performance of MTL methods on CelebA. The percentage error per attribute on theCelebA data set presented as a radar chart, where tighter is better. Following Sener & Koltun (2018),we divide the attributes into two categories: easy (left) and hard (right). See Sec. 5.2 for more details.
