Figure 1: The 1D visualization of solutions of different network structures obtained with or withoutdropout layers. (a) The FNN is trained on MNIST dataset. For experiment with dropout layers, weadd dropout layer after the first and the second layers, the dropout rates of the two dropout layersare 0.8 and 0.5, respectively. The test accuracy for model with dropout layers is 98.7% while 98.1%for model without dropout layers. (b) The vgg-9 network is trained on CIFAR-10 dataset using thefirst 2048 examples as training dataset. For experiment with dropout layers, we add dropout layersafter the pooling layers, the dropout rates of dropout layers are 0.8. The test accuracy for model withdropout layers is 60.6% while 59.2% for model without dropout layers. (c) The ResNet-20 networkis trained on CIFAR-100 dataset using the 50000 examples as training dataset. For experiment withdropout layers, we add dropout layers after the convolutional layers, the dropout rates of dropoutlayers are 0.8. The test accuracy for model with dropout layers is 54.7% while 34.1% for modelwithout dropout layers.
Figure 2: The inverse relation between the variance {λi (Σ)}iN=1 and the flatness {Fvi(Σ) }iN=1 fordifferent choices of dropout rate p and learning rate lr. The FNN is trained on MNIST datasetusing the first 10000 examples as training dataset. The PCA is done for different datasets S sampledfrom parameters for (a) and sampled from gradients of parameters for (b). The dash lines give theapproximate slope of the scatter.
Figure 3: The inverse relation between the variance {λi(Σ)}iN=1 and the flatness {Fvi(Σ)}iN=1 for dif-ferent choices of dropout rate p and learning rate lr. The ResNet is trained on CIFAR-100 dataset.
Figure 4: The relation between the variance {Var(Projvi(S))}iD=1 and the eigenvalue {λi (H)}iD=1for different choices of dropout rate p and learning rate lr. The FNN is trained on MNIST datasetusing the first 10000 examples as training dataset. The projection is done for different datasets Ssampled from parameters for (a) and sampled from gradients of parameters for (b). The dash linesgive the approximate slope of the scatter.
Figure 5: The relation between the variance {Var(Projvi (S))}iD=1 and the eigenvalue {λi(H)}iD=1for different choices of dropout rate p and learning rate lr. The ResNet is trained on CIFAR-100dataset using all the examples as training dataset. The projection is done for different datasets Ssampled from parameters for (a) and sampled from gradients of parameters for (b). The dash linesgive the approximate slope of the scatter.
Figure 6: Comparison between Tr(Hi∑i) and Tr(HiEi) in each training epoch i for differentchoices of dropout rate p and learning rate lr. The FNN is trained on MNIST dataset using the first10000 examples as training dataset. The solid and the dotted lines represent the value of Tr(HiΣi)and Tr(Hi ∑i), respectively.
