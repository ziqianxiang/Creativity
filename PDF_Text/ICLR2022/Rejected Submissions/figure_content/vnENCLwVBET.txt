Figure 1: Training process of the discriminatorThe trained discriminator will be used to score a sentence. Since some text generation tasks lackstandard reference, we use relative metrics to avoid this problem. The OUMG metric is used tocompare the sentences generated by the two models and measure the gap between them. In practicalapplication, we need to compare the two text generation models G1 and G2, and obtain the relativescores of the two models. To ensure the fairness of the two models, when generating the sample dataset, we stipulate that sentences generated by the two models are mixed equally, thus (1) becomesl(θ) = - X log (Dθ (x)) - X log(1 - Dθ(x)) X log(1 - Dθ(x))	(2)x∈X1	x∈XG1	x∈XG2After fully trained to converge, the discriminator can distinguish human-generated and machine-generated sentences with high accuracy. The higher the sentence scores, the closer it is to human-generated sentences. Next, we use the trained discriminator to score two test sets from the modelG1 and G2 and get two groups of scores. We process the score of the discriminator adopting thefollowing two relative metrics:3Under review as a conference paper at ICLR 2022Figure 2: Process of evaluation using the discriminatorHigh Score Rate Difference(HSRD): When a sentence gets a score of more than 0.5 after it is inputinto the discriminator, we call it a high score, indicating that the discriminator determines that thesentence is written by humans. High score rate(HSR) refers to the ratio ofa set of sentences that are
Figure 2: Process of evaluation using the discriminatorHigh Score Rate Difference(HSRD): When a sentence gets a score of more than 0.5 after it is inputinto the discriminator, we call it a high score, indicating that the discriminator determines that thesentence is written by humans. High score rate(HSR) refers to the ratio ofa set of sentences that arejudged as high score to all sentences in a model and high score rate difference is expressed asNDθ(XG1 )>0.5 - NDθ(XG2 )>0.5(3)NWhere N represents the total number of sentences generated by each model, NDθ(xG )>0.5 andNDθ(xG )>0.5 represent the number of high-score sentences in the two groups. To avoid the inter-ference of redundant factors, the same number of sentences generated by each model is required inthe comparison.
Figure 3: Guiding text generation with discriminatork>->It1	lt2	l；■ ■ ■	■ ■ ■'tk	Iktext generation model, the probability distribution of the model is not the same as that of the actualnatural language, which leads to the bias of the above conditional probability. As the generatedtext gradually grows longer, the bias will become larger and larger. OUMG changes the probabilitydistribution of the final output by scoring the candidate with a discriminator at each step, making itcloser to the probability distribution of natural language, thus alleviating the bias.
