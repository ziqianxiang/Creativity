Figure 1: In ILP, the grounded background knowledge and known relational predicates between atomsare provided to induce consistent rules. In the temporal case, we are operating over raw temporaldata samples, such as videos, with potentially multiple labels. Therefore the latent temporal structurebetween the atomic events is recovered, and then the rules for composite events are learned.
Figure 2: The first step (1) of Neural TLP involves learning the convolution and predicate modelparameters from the raw time series and labels. Then the structure learning step (2) is learningattention s over a sparse combinatorial matrix to infer the labels. This attention and sparse matrix isthen used to carry out the final rule induction (3).
Figure 3: An overview of how intervals are computed from raw data. First the compressed atomicevent scores (1) are multiplied with the time scalar (2) to compute MA (3), where we observe a singlesample vector tiu . In step 4 we find the max value of tiu , representing the end of the interval, and usethis value to initialize the mask in step 5 (Equation 3). When steps 4 and 5 are summed in step 6, weget a representation whose min corresponds to the start of the interval as shown in Equation 4.
Figure 4: In the parameter learning stage (1) we learn the most relevant grounded predicates used forpredicting each label yr through W. In the structure learning stage (2) we select the most relevantpredicates and construct the combinatorial matrix C, where each column indicates a conjunction ofpredicates. Vector s is learned to select the most likely conjunction to induce the rule r.
Figure 5: In CATER, generative rules are used to synthesize the labels from the videos. Neural TLPcan then learn these rules from the raw atomic event data and labels. We then verify our rule inductionperformance over the ground truth rules.
Figure 6: We compare Neural TLP (Blue) and Temporal MAP (Red) with varying number of activelabels and samples. Each curve represents the overall variable length accuracy up to rule length n. Onthe left we compare the variable length performance when we sampled more event rules per video,increasing the active labels and timeline noise with fixed 10000 samples. On the right we compareperformances as the number of samples increase and fix j = 1.
