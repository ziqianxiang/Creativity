Figure 1: Problem setting and dataset space. (a) Upon viewing an object, an agent might extractvarious input features, mapping these to output features or “words” in order to refer to the item(Brighton & Kirby, 2006). (b) We schematize this setting with a space of datasets containing sys-tematic (Ω) and non-systematic (Γ) features in the input (left panel) and output (middle panel). Rowscontain examples and columns contain features. In this case cars are named with both a systematiccomponent (based on features: presence of stripe, colour and number of doors) and non-systematiccomponent (based on brand). In iterated learning, the names of objects change from the initial labelsover generations until they stabilize at the refined final labels (right panel, Ωy, Γy).
Figure 2: Analytical learning dynamics for deep (panels a-b) and shallow (panels c-d) linear net-works. (a,c) Comparison of predicted and actual singular value trajectories over learning, for thethree unique dataset singular values. (b,d) Comparison of predicted and actual Frobenius norms ofthe input-output mapping to/from systematic (Ωχ, Ωy) and non-systematic (Γχ, Γy) features. Deepnetworks show distinct stages of improvement over learning. However, at no point is a purely sys-tematic mapping learned. Parameters: nx = 3, ny = 1, kx = 3, ky = 1, r = 1.
Figure 3: Impact of architectural biases. Architectures that partition systematic and non-systematicfeatures in different ways with the corresponding graphical representation of the resulting networkmappings. The dynamical modes π1 , π2, and π3 contain contributions from systematic and non-systematic input components, depicted as the color of the bottom half of the each mode; and theymake contributions to systematic and non-systematic output features, depicted as the color of the tophalf of each mode (red for systematic, green for non-systematic, and orange for mixed). To learn asystematic mapping, the fastest mode π1 must be systematic. The output partitioned network is ableto obtain output systematicity but not input systematicity. Only the fully partitioned network obtainscomplete systematicity.
Figure 4: Iterated learning dynamics. (a) Generations of agents learn from languages generated bytheir parent, and pass on their acquired language to their children. (b) Norm of non-systematic outputmapping over 20 generations of the IL procedure using deep, shallow and output-split networks.
Figure 5: (a) Normalized training loss, (b) test loss of a deep CNN with ReLU activation on theCompositional-MNIST dataset averaged over 10 runs. Error bars reflects one standard-deviation.
Figure 6: Singular Values and Frobenius norms of the shallow network mappings(a) Systematic output norm partitioned by the system- (b) Non-systematic output norm partitioned by sys-atic and non-systematic input components.	tematic and non-systematic input components.
Figure 7: Frobenius Norm of the systematic and non-systematic deep network mapping partitionedby the systematic and non-systematic inputs on a dense linear network.
Figure 8: Singular Values and Frobenius norms of the split network mappings(c) Phase diagram of the split net-work vs shallow network FrobeniusnormsWe can also consider the Frobenius norm from the full input to either the systematic or non-systematic components of the output (obtained by summing over input features). This takes a simplerform,Ωy-Norm =(2nx n ∏2(t) ∖2kyr2 + 2nx )ry-NOrm = ( kyny[2* + (nx - ny)π2(t) + (2nx - nx)π2 ⑴kyr + 2 x(21)(22)E Modularity and ArchitectureIn Figure 8 we depict the Frobenius norm of the mapping from the entire input to the systematic andnon-systematic output, for the output-partitioned network. The dynamics of this case can equallybe seen as using one neural module responsible for the systematic mapping and another for thenon-systematic mapping. Now, from the perspective of the non-systematic mapping, none of thesystematic features in the input are present in the output, and the mapping will no longer be depen-
Figure 9: Dense network architecture trained to perform the CMNIST classification task.
Figure 10: Split network architecture trained to perform the CMNIST classification task.
