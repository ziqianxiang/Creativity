Figure 1: (a) An example of hierarchical species classification on animal mimicry images. Thehierarchy is an example of the label taxonomy. The two loss matrices are optimized in the layer-by-layer learning-to-abstain problems in the proposed method. Bold labels are the index of the nodes inthe tree. The “a” in the figure represents the abstaining option in each layer in our proposed method.
Figure 2: (a) The training mechanism of the proposed approach. For the training of the non-leaflayers, We relabel the data using the corresponding nodes and initialize the backbone models usingparameters from leaf layers, except for the last layer of the neural network. (b) The predictionprocedure over the hierarchy. The leaf model is first employed to make predictions on all the samples,then the models on the father layers are employed to make predictions on the abstained samplescollected from the previous layers.
Figure 4: In the learning-to-abstain problems, the abstaining loss affects the error rate and abstainingrate. The larger the abstaining loss is, the more aggressive the classifier is, thus the larger the errorrate and the smaller the abstaining rate.
Figure 5: (a) (b)(aC)umulative non-abstained accura(cby) for each layer on bird classificat(ico)n. We compareLAM with abstaining cost 0.1, 0.4 with DARTS that achieves a similar overall accuracy; (c) The costcomparison of 5 different LAM models with their corresponding DARTS models achieving the sameoverall accuracy in the cell classification task.
Figure 6: Binary search heuristic torate is greater than the error rate achieved by the target model, recover DARTS performance.
Figure 7: (a) (b) Average cost-sensitive loss vs. corresponding absolute accuracy on CIFAR10 andSVHN. We compare LAM with abstaining costs 0.1, 0.15, 0.2,..., 0.85 with DG of equivalent reward.
