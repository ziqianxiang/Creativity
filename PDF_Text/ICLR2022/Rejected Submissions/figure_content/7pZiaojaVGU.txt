Figure 1: Accuracy of the globalmodel under attack by CGA.
Figure 2: Successful model attack against `22 by combining CGA and Proposition 3.
Figure 3: Successful data attack against `22 by the efficient data generation scheme.
Figure 4: Linear model on noisy FashionMNIST, for λ = 0.01.
Figure 5: 2-layer neural network on noisy FashionMNIST, for λ = 0.01.
Figure 6:	Linear model on noisy FashionMNIST, for λ = 0.1.
Figure 7:	2-layer neural network on noisy FashionMNIST, for λ = 0.1.
Figure 8:	Linear model on noisy FashionMNIST, for λ = 1.
Figure 9: 2-layer neural network on noisy FashionMNIST, for λ = 1.
Figure 10:	Linear model on noisy FashionMNIST, for λ = 10.
Figure 11:	2-layer neural network on noisy FashionMNIST, for λ = 10.
Figure 13: 2-layer neural network on noisy FashionMNIST, for λ = 100.
Figure 12: Linear model on noisy FashionMNIST, for λ = 100.
Figure 14: Linear model on FashionMNIST (without noise), for λ = 1.
Figure 15: 2-layer neural network on FashionMNIST (without noise), for λ = 1.
Figure 16:	Norm of global model, distance to initialisation and distance to target, under attack byCGA. In particular, we see that the attack against `22 is successful, as the distance between the globalmodel and the target model goes to zero.
Figure 17:	CGA on cifar-10.
Figure 18:	Model attack on cifar-10.
Figure 19:	Data poisoning on cifar-10.
