Figure 1:	Presentation of our top-down perspective, two-dimensional continuous environment. Left:At each time step, the agent moves between positions rt and rt+1 by performing an action attr . Theimage it perceives through its retina, now centered on the new position rt+1, is modified accord-ingly, as the ”landmarks” now occupy different positions with respect to the center of the retinalarray. Right: Each neuron in the retinal array has an associated receptive field of the ”Differenceof Gaussians” type (for clarity, we represent only two); depending on the position of the landmarkwith respect to its receptive field, each neuron will be more or less activated, generating the ”retinalstate” that we will consider in the following as the ”observation” received from the environmentObservation -----AReafferentaction" Convolutional”Network VVisualRepresentationDenseNetwork PEncodedactionRecurrent
Figure 2:	Shared structure of the models of Path Integration. The signals coming from the allocentricand proprioceptive sensors (respectively, the retinal activity and the reafferent action) are encodedthrough a first set of Neural Networks, before being used as inputs to a Recurrent Neural Network,whose output will be the predicted total displacement.
Figure 3: Overview of the direct-inverse model architecture, in which operators acting on internalrepresentations aim at reproducing the dynamics of an environment. Dotted arrows indicate that themodule they come from is trained to output the quantity they point towards (eqs. 4, 5).
Figure 4: Minimal model for a Resetting Path Integrator, based on a Direct-Inverse model of envi-ronment dynamics. We assume that the agent is able to see correctly on the first step of the trajectory,and to keep a stable memory of this initial observation; this initial state is then updated by either us-ing the direct model and the encoded reafferent action, or the new visual representation (resetting);the choice between those two behaviors is determined by the gating module G .
Figure 5: Example of Path Integration trajectory Left: Crosses represent the true position of theagent, while stars represent the one evaluated through Path Integration; black circles are placedaround the positions at which an image was provided; time along the trajectory is represented bythe color of the symbols. Top right: logarithm of the value of the resetting gate as a function oftime along the trajectory. Bottom right: error between the true and reconstructed position. Verticaldashed lines indicate the time-steps at which the image was available to the network and not cor-rupted. In this example, actions are not drawn from the ”free foraging” random policy but chosen toforce exploration of the entire environment to better evaluate generalization at long distances, andreafferent actions are exact, so that errors are due only to the network itself.
Figure 6: Path Integration errors achieved by our Resetting Path Integrator, with occasionally avail-able retinal images (orange) and without images (blue). A: the reafferent action (proprioceptivesignal) is exactly equal to the true one. B: a small amplitude Gaussian noise is added to thereafferent action. Dashed vertical lines indicate steps at which images were presented, kept equalacross 512 trajectories for each of the 8 networks used in the averaging. The qualitative agreementbetween those two plots, as well as results from Appendix I, suggest that our procedure is robust tosmall reafference errors, which have the same effect as direct model errors.
Figure 7: Comparison between representative neurons in the visual module V (top row) and theinternal state h observed during Path Integration (bottom row) as a function of position within ourambiguous environment. The ”dynamic” representation constructed during PI lifts the ambiguitybetween the two opposite rooms of the middle row, which contain the same landmark and are sur-rounded by identical rooms. Each column represents the normalized activation of a single neuron.
Figure 8: Example of retina: a regular square lattice of Difference of Gaussians fields. We describeas the ”area of effect” of the retina the zone in which an object would contributes to the activityvector of the retina as a whole above some arbitrary threshold, e.g. 10-2.
Figure 9: Reconstruction error on a grid with 100 subdivisions on x and y as a function of position,represented as a heatmap. On the left, the reconstruction error of the optimal linear decoder showsclear geometric patterns related to the geometry of the underlying array of cells. On the right, thereconstruction error for a ”deep” 3-layer ReLU network. While the highest observed error is higherfor this deep network, the error on all points except the corners is much lower than for the linearnetwork. Additionally, the geometric patterns are not observed in that case.
Figure 10: Computation diagram for a LSTM cell, as implemented in Paszke et al. (2019).
Figure 11: Comparison between representations obtained after training the Direct-Inverse Modelmodule in our environment. Each panel represents the normalized activation of a single neuron inthe visual representation V(s), obtained at the end of the visual processing module, represented asa function of position within the environment through a color code presented on the right scale. Theactivities are of the same order of magnitude in all cases. When optimizing only the inverse loss (eq.
Figure 12: Computation diagram for the hybrid path integrator structure.
Figure 13: Evolution of the different losses when training a Resetting Path Integrator, whose visual,direct and inverse modules were pretrained using transition tuples from the environment, in the threedifferent protocols described in the text.
Figure 14: Activity of four representative neurons in the internal state population of an RPI trainedwith (left) or without (right) the model losses, as a function of absolute position in the environment.
Figure 15: Activity of four representative neurons in the internal state population of an RPI trainedwith (left) or without (right) the model losses, as a function of position along the trajectories. Onlythe ones trained without those losses (and not performing resetting) are close to a linear function ofposition within the trajectory.
Figure 16: Cumulative distribution function of the natural logarithm of the reset gate g across theenvironment in different conditions. A: Varying the level of noise in the reafferent action dur-ing training. As expected, high levels of noise favor strong resettings, hence lower values of g .
Figure 17: Activity of four representative neurons in the “reset" and “input“ gates, as a functionof time, aggregated across 128 trajectories in which images are always presented at the same time-steps.
Figure 18: Example of Path Integration trajectory on the Ambiguous DoubleDonut environment.
Figure 19: Value of the natural logarithm of the resetting gate g as a function of position, averagedacross 8 realizations of the training. As expected, resetting happens at least partially at every positionin the environment, except within the two rooms that have ambiguous visual cues.
