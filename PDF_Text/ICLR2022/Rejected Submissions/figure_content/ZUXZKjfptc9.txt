Figure 1: Binary encoding.
Figure 2: Federated Learning with BitRand Algorithm.
Figure 3: Expected error bound comparisonfor an embedded feature a with r = 1, 000,l = 10, and m = 5.
Figure 4: Randomization proba- tion probability qX across bits in the corrected OME. To betterbility qX and qtop-k, given l = 10, show the comparison, we draw an average top-k measure curve:r = 1, 000, and X = 1.	∀k ∈ [0, l - 1] : qtop-k = 1/k Pik=0 qi, where qi is the bit i’s qX,to evaluate the average qX across bits. The smaller qtop-k is, the better the randomization probabilityqX is. Given a tight privacy budget X = 0.1, our mechanism and the corrected OME have a similarqtop-k. However, when X increases, i.e., X ∈ {1, 2}, our mechanism achieves significantly smallervalues of qtop-k than the corrected OME (p = 5.1e - 3).
Figure 5: Randomization proba-bility qX as a function of r withfixed l = 10 and X = 1.
Figure 6: Randomization proba-bility qX as a function of l withfixed r = 1, 000 and X = 1.
Figure 7: RandomizationProba-bility qY with varying Y and C .
Figure 8: AUC values of each algorithm applied on the gradients 5θu with the anonymizer.
Figure 9: Impacts of r and l on Corrected/X in LATENT (Arachchige et al., 2019) and OME (Lyuet al., 2020a).
Figure 10: RMSE error comparison as a func-tion of X .
Figure 11: Expected error bound as a function of X with fixed r and l.
Figure 12: Randomization probability qX and qtop-k, given l = 10 and r = 1, 000.
Figure 13: Randomization probability q (p = 1 - q) as a function of r with fixed l and .
Figure 14: Randomization probability qX (pX0.4r = 10, 000 and X(j) r = 10, 000 and X = 0.1(e) r = 100 and XSign bitW∙ Highest Integer bit▼- Lowest Integer bit▲ " Highest Fraction bit♦ ■ Lowest Fraction bit(l) r = 10, 000 and X(h) r = 1, 000 and X0.5q×0.5q×0.5q×0.5qχ
Figure 15: Accuracy of LDP algorithms applied on the embedded features ex in the AG, SEC, andFEMNIST datasets.
Figure 16: Accuracy of LDP algorithms applied on the gradients 5θu in the AG, SEC, and FEMNISTdatasets.
Figure 17: Accuracy of LDP algorithms applied on the gradients 5θu with the anonymizer (Sun et al.,2021).	t28Under review as a conference paper at ICLR 202290123456789 10Privacy budget εχ(c) SEC「RR & Label-Laplace (εγ = 1.0)-	<-「RR & Label-Laplace (εγ = 2.5)—	「RR & Label-Laplace (εγ = 5.0)「RR & Label-Laplace (εγ = 10.0)∙∙*∙∙ BitRand (εγ= 1.0)BitRand (εy = 2.5)—	BitRand (εy= 5.0)-	4- BitRand (εy= 10.0)→— Random—Noiseless10090
Figure 19: AUC values of LDP algorithms applied on the embedded features ex in the AG, SEC, andFEMNIST dataset.
Figure 20: AUC values of LDP algorithms applied on the gradients 5θu in the AG, SEC, andFEMNIST datasets.	tThree-outputs [vθt]PM-SUB [v⅛]corrected LATENT [ex]corrected OME [ex]BitRand [ex] (εγ= ∞)BitRand [ex] (εy= 1.0)BitRand [ex] (εy = 2.5)BitRand [ex] (εy= 5.0)BitRand [ex] (εy= 10.0)Random →- NoiselessPrivacy budget ε×(b) FEMNIST「RR & Label-Laplace (εγ= 1.0)「RR & Label-Laplace (εγ = 2.5)「RR & Label-Laplace (εγ = 5.0)「RR & Label-Laplace (εγ= 10.0)BitRand (εγ= 1.0)BitRand (εy = 2.5)
Figure 21: AUC values of each mechanism applied on labels in the AG, SEC, and FEMNIST datasets.
