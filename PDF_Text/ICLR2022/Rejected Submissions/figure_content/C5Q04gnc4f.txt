Figure 1: Left: Simplified creation process of the Stylized COCO dataset. Style images are randomly chosenfrom Kaggles Painter by Numbers dataset. Right: We use mask annotations to create counterfactual, object-centric versions of Stylized COCO. We append more examples of the creation process in the Appendix.
Figure 2: Depending on the styleimage, object boundaries can van-ish due to strong stylization. TheStylized Objects and Backgroundversions of Stylized COCO resolvethis issue.
Figure 3: Top roW: Comparison of COCO and Stylized COCO at different alphas. The AdaIN method in-troduces subtle artifacts even at α = 0 (no style). Bottom left: We control the style strength in feature space(yelloW to pink) and pixel space (blue to pink). Note that every alpha value in these sequences depicts a separateand complete version of the accordingly styled COCO val2017 subset. Bottom right: Comparison of imagegradients and color histograms at different alphas.
Figure 4: Left: Average structuralsimilarity between image gradientsin relation to COCO (a score of 1means that there is no differencebetween images). Right: Wasser-stein distance between RGB his-tograms (reversed y-axis).
Figure 5: Absolute performances on COCO val2017. Training schedules in epochs have been appended tomodel names. Note that Yolo is bbox AP which is not directly comparable but included for model completeness.
Figure 6: General overview of model robustness(zoom in for better visibility). Masking the styletransfer effect to ground truth objects results in im-proved relative performance without changing theoverall trend. Structural similarity as displayed inFigure 4 seems highly predictive for the low al-pha range but can not explain the further decreas-ing robustness values. We also like to point outthe small performance dip of the control group atα = 0.1 that seems to be induced by color shift.
Figure 7:	Object-centric robustness by framework. Note that we compromised on R-101 for SOTR and F-BCNet, see Table 1 for an overview of available backbone combinations.
Figure 8:	Top: Object-centric robustness by backbone architecture (zoom in for better visibility). Modelsmarked with * are trained with LSJ. Bottom: Robustness by neck architecture. Deformable convolutions arehighlighted for better visibility. Note that Yolo scores are bbox and not directly comparable.
Figure 9: Object-centric robustness bypre-training and data augmentation.
Figure 10: Creation process of Stylized COCO. We plot the mask annotations to locate ground truth instancein the stylized images. These are also used to create the masked version of Stylized COCO.
Figure 11: Comparison of AdaIn style transfer strength. Depending on the style image, an alpha value of 1(pink) can produce rather extreme versions where objects are almost eradicated from the scene. An alpha valueof 0 (yellow) corresponds to a style transfer of the content image with itself. As can bee seen in the middlecolumn, this variant already introduces subtle shape changes to the images.
Figure 12: Comparison of Stylized COCO, Stylized Objects and Background for the last example in Figure 11.
Figure 13: Full example for one image. Top row: Creation Process of Stylized-COCO. Second row: Com-parison of AdaIn style strength. Third row: Comparison of the stylized datasets. Last three rows: BlendingSequences for Stylized-COCO, Stylized-Objects and Stylized-Background. We create these for every imagewhich results in 60 modified copies of the COCO val2017 subset.
Figure 16:	General overview of model robustness. Top row shows relative performance as in the main paper.
Figure 17:	Object-centric robustness by framework (bbox). Note that we compromised on R-101 for SOTR.
Figure 18:	Full comparison of object-centric robustness by backbone architecture. Models marked with * aretrained with LSJ.
Figure 19:	Full comparison of object-centric robustness by neck architecture. Models with dynamic compo-nents are highlighted.
