Figure 1: Illustrations of our SSX (a), VIPER-D (b), and abstract states used for compression (c)methods based on an expert policy for the Four Rooms game with neither having information aboutthe underlying topology of the state space. Colors/Shapes denote different meta-states/clusters. Theblack X in the upper right is the goal state. SSX clusters the four rooms exactly with strategic statesdenoted by larger markers, where the biggest marker implies the priority strategic state. SSX explainsthat the expert policy will head towards the open doors in each room preferring the door that leads tothe room with the goal state. VIPER-D clusters states by action (black/plus=up, green/circle=down,blue/diamond=left, red/square=right) based on the full (discrete) state space, rather than samples,since it is tractable here. The compressed state space in (c) is also a function of the experts(conditional) action distribution. Clusters in (b) and (c) are scattered making it challenging for ahuman to understand any policy over clusters.
Figure 2: Illustration of our SSX method on Door-Key. Policies were trained on two differentenvironments: Locked Door and Unlocked Door. Each row corresponds to a meta-state and strategicstate (outlined in pink) from running SSX starting at a different number of moves into the same path(one path for completing the task in each of the two environments).
Figure 3: Illustration of our SSX method on minipacman. Two policies, EAT and HUNT, aredisplayed. Two clusters, one per row, are shown as part of the SSX result. The last board with pinkbackground is a strategic state for each cluster. The color scheme is as follows: green = pacman, red= ghost, yellow = edible ghost, cyan = pill, blue = food, black = food eaten, white/pink=wall.
Figure 4: Above (left) we see the percentage (human) accuracy in predicting if the expert policy isEat or Hunt based on SSX and Viper-D. As can be seen users perform much better with SSX withdifference in performance being statistically significant (paired t-test p-value=0.01). Above (right)we see a 5-point Likert scale (higher better) for four qualitative metrics used in previous studies(Madumal et al., 2020). Here too the difference is statistically significant for all four metrics (p-valuesare all less than 2 × 10-5 ). Error bars are 1 std error.
Figure 5: Illustrations of SSX state space size in minipacman. Worst case state space size for localapproximations is NM where N is the maximum number of moves made and M is the number ofpossible actions per move. Pacman’s state space is averaged over 100 random samples for eachN = 1, . . . , 10. The state space of minipacman, while also growing exponentially, grows muchslower (like a game with 2-3 actions per move) which makes SSX a practical method for such games.
Figure 6: Illustration of selecting important states on minipacman. Two policies, EAT and HUNT,are displayed across two scenarios for each. For each scenario, a single cluster is shown. For agiven cluster, the last board with pink background is an important state for that cluster as defined byequation (D). The color scheme is as follows: green = pacman, red = ghost, yellow = edible ghost,cyan = pill, blue = food, black = food eaten, white/pink=wall.
Figure 7:	Illustration of our SSX method on two additional scenarios of minipacman. Two policies,EAT and HUNT, are displayed across the two scenarios. For each scenario, two clusters, one per row,are shown as part of the SSX result. The last board with pink background is a strategic state for eachcluster. The color scheme is as follows: green = pacman, red = ghost, yellow = edible ghost, cyan =pill, blue = food, black = food eaten, white/pink=wall. In EAT scenarios, pacman generally ignoresthe pill and stays away from the ghost (even if the pill has been eaten). In HUNT, pacman generallylooks for the pill (but stays away if the ghost is near it) and moves toward the ghost (if the pill hasbeen eaten).
Figure 8:	Screenshot of user study instructions. SSX explanations are anonymized as Type Aexplanations and Viper-D explanations are anonymized as Type B explanations.
Figure 9:	Screenshot of SSX explanation example used to train the participant taken from user study.
Figure 10:	Screenshot of Viper-D explanation example used to train the participant taken from userstudy. Viper-D explanations are anonymized as Type B explanations.
Figure 11: Screenshot of SSX explanation survey question taken from user study. SSX explanationsare anonymized as Type A explanations.
Figure 12: Screenshot of Viper-D explanation survey question taken from user study. Viper-Dexplanations are anonymized as Type B explanations.
