Figure 1: The 1d horizontal data collapse forms a sequence of lab tokens while ignoring their values;a 1d vertical collapse takes a summary statistic (e.g. the mean) for each lab sequence.
Figure 2: Architecture diagrams for pre-training and fine-tuning a value-aware transformer[EOS] token: we use a floating classification head which attaches itself at this position, taking as itsinput the output embedding of [EOS]. We use a simple but flexible one-hidden-layer feed-forwardneural net with an output layer to the number of classes relevant for the classification problem.
