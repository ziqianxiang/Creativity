Figure 1: Bayesian classification (blue) on the rotated MNIST task. Although the ensemble hasreasonable uncertainty quantification, it can sporadically fluctuates over rotations and exhibits regionsof overconfidence. Using function-space VI, the uniform prior (red) regularizes the prediction outsideof the data distribution to be more consistent and reasonable in its uncertainty. Here, the index set isthe training data and uncertainty is expressed through the 1st, 3rd and 25th percentile.
Figure 2: Reducing observations from a simplex (left) to their mean (middle) discards informationwhich is present in the variance of the predictions that reflects model uncertainty. A Dirichletdistribution (right) fitted to the same samples can capture the uncertainty with its density function.
Figure 3: Toy classification problem using the Two Moons dataset. Each row corresponds to adifferent network. The first column shows the undesirable predictive certainty of standard weight-space priors outside of the data distribution. The second column illustrates how our function-spaceinference approach combined with a uniform Dirichlet prior prevents unreasonable extrapolationbehavior and instead adequately increases model uncertainty outside of the observed data. Thethird and fourth column show that our approach can also be combined with class-biased predictivepriors that inform the OOD-prediction without sacrificing accuracy. This explicit design is notstraightforward with weight-space priors.
Figure 4: Comparison of rotated MNIST log-likelihood for models trained with fVI using differentindex sets: training data without rotations (left), 90° augmentations (middle), and 90° and 180°augmentations. Colored lines denote the mean and shaded areas denote two standard deviations over10 seeds. The 90° augmentation improved fVI performance for that scale of perturbation, but worsensperformance at 180°. We attribute the degradation to the nature of parametric function approximation.
Figure 5: Metrics for corrupted image classification on CIFAR10 (top) and CIFAR100 (bottom).
Figure 6: Metrics for adversarial examples on CIFAR10 (top) and CIFAR100 (bottom). All modelsuse a ResNet-18 architecture. For CIFAR10, there are significant benefits of fVI over weight-spaceapproaches across all metrics. For CIFAR100, the fVI benefits are still evident, but the higher labeldimensionality results in stronger regularization from the uniform prior. As a result, the weight-spaceensembles achieve slightly better performance over all epsilons.
Figure 7: A summary of the improvement in log-likelihood for function-space inference over weightspace, for CIFAR10 and CIFAR100 experiments under corruption and adversarial perturbations. Thegeneral trend shows that models that use reparameterization gradients (Radial and Rank1) benefitthe most from fVI. The improvement also generally increases as the test data becomes more OOD.
Figure 8:	Comparing Prior Networks and Belief Matching against MAP and MAP fVI models on thecorrupted CIFAR10 task.
Figure 9:	Metrics for rotated MNIST. All models use a MLP architecture with two hidden layers with50 units each. In terms of log-likelihood and expected calibration error, the fVI models outperformtheir respective baselines, which indicates improved uncertainty quantification. The linearized laplacesubnetwork metrics are taken from Daxberger et al. (2021), and uses a ResNet-18 rather than an MLP.
Figure 10:	Reproduction of CIFAR10 corruption results in Figure 5, including MC Dropout resultswith 5 predictive samples during training. For 5 sample MC Dropout, 3 random seeds were usedrather than 10 due to the additional training time.
Figure 11:	A toy classification example on a hypercube to illustrate the scaling issues associatedwith the Dirichlet density. The vanilla MAP performance acts as a baseline, and demonstrates thetypical range of log likelihood values for this task across increasing label dimensionality. For fVI, theDirichlet fKL reports a significantly larger range that is x100 the log likelihood range. This valueimbalance affects the fELBO objective, resulting in significant underfitting. Applying a heuristic toscale the fKL term, keeping the fKL invariant across label dimensionality avoids the underfittingphemonema. Plot reports mean and 2 standard deviations over 10 seeds.
Figure 13: Reproduction of the Two Moons toy problem (Figure 3) with varying uniform priorprecision.
