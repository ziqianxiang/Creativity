Figure 1: Comparison between learning curves of PROMISSING and mPROMISSING with dataimputation approaches on simulated MCAR, MAR, and MNAR data, when tested on a test setwithout missing values (first row) and with 50% missing values (second row).
Figure 2: Comparing AUC drops in classification tasks with respect to the full model across fivedifferent imputation methods, HGB, and (m)PROMISSING in MCAR, MAR, and MNAR settings.
Figure 3: The NN architecture with middle andlate information fusion for psychosis prognosisprediction on multi-modal data.
Figure 4: The trajectories of model predictions for 17 patients with information loss when using a)data imputation, b) PROMISSING, and c) mRPOMISSING methods to handle missing data.
Figure 5: Counterfactual interpretation of model decisions using mPROMISSING for a) true nega-tive, b) true positive, c) false negative, and d) false positive examples in model predictions.
Figure 6: In each panel: a) The simulated XOR data. The effect of b) zero, c) mean, d) KNN,and e) iterative imputations on simulated data with MCAR, MAR, and MNAR missing values. Themissing values for the first feature (x-axis) are selected based on a random range of the secondfeature (y-axis).
Figure 7: Comparison between learning curves of PROMISSING and mPROMISSING with dataimputation approaches on simulated MCAR, MAR, and MNAR data, when tested on a test setwithout missing values (first row) and with 30% missing values (second row).
Figure 8: Patterns of neutralizer elements across two input features and the four neurons across 100simulation repetitions. The markers with the same color and shape show the neutralizer values foreach of four neurons in a specific run (the legends) of the pipeline. The blue and red dots in thebackground are representing the simulated data.
Figure 9: Pattern of neutralizers in U across two input features and the four neurons. The markerswith the same color show the neutralizer values for each of four neurons in a specific run (legends)of the pipeline. The blue and red dots in the background are representing the simulated data.
Figure 10: Comparison between the performance of our simple NN architecture with random forestacross a) 31 classification and b) 21 regression tasks.
Figure 11: Comparing increase in SMSEs in regression tasks with respect to the full model acrossfive different imputation methods, HGB, and (m)PROMISSING in MCAR, MAR, and MNAR set-tings.
Figure 12: Comparing AUC drops with respect to the full model across four different imputationmethods, HGB, and (m)PROMISSING in classification tasks.
Figure 13: Comparing increase in SMSEs with respect to the full model across four different impu-tation methods, HGB, and (m)PROMISSING in regression tasks.
