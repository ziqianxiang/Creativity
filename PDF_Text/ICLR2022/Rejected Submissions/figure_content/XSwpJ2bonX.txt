Figure 1: Nematode. (A) The nematode C. elegans achieves forward locomotion through alternatingdorsal-ventral muscle contraction waves propagating down the body. (B) Muscle wave propagation,oscillation, steering, and speed control are coordinated by a highly stereotyped, modular, and repeatedmicrocircuit. B neurons sense bending in the previous module via proprioception and excite ipsilateralmuscles, while inhibiting contralateral muscles via D neurons. Intrinsic oscillations in B neuronsinitiate waves. SMB neurons bias head and neck muscles for steering. AVB attenuates all B neuronsvia gap junctions for speed control.
Figure 2: Architectural Components. (A) An integrator unit models a simple neuron. The gradedinput signals are multiplied by weights that represent synaptic efficacy and which are constrained tobe either excitatory (positive, green boxes) or inhibitory (negative, red boxes). The graded outputsignal is produced from an activation function. (B) An oscillator unit produces driving signals muchlike intrinsic pacemaker cells and network-based oscillators. The graded output signal is generatedthrough periodic functions, e.g. square waves and sine waves.
Figure 3: Swimmer. (A) The Swimmer has an articulated body with N joints connecting N + 1links. Its observation space is normalized joint positions q, and its action space is normalizedjointaccelerations q. (B) Our network architecture closely conforms to the modular microcircuit of thenematode. Each module i senses bending in the previous module q%-Î¹ and drives B neurons b andmuscles mi, which are combined to createjoint accelerations q%.
Figure 4: Performance and Data Efficiency. (A) Comparison of different algorithms for eacharchitecture. Our architecture starts with high reward and improves with learning, achieving signifi-cantly better data efficiency and comparable performance. (B) Comparison of different architecturesfor each algorithm. Our architecture with 4 parameters overperforms small MLPS (MLP(2,2) has 70parameters) and is comparable to large MLPS (MLP(256, 256) has 77,222 parameters). Plots showaverages over 10 random seeds (solid lines) and 95% bootstrap confidence intervals (shaded areas).
Figure 5: Parameter Efficiency.
Figure 6: Transfer. Zero-shottransfer to new bodies after train-ing on N = 5 by leveraging ar-chitecture modularity.
Figure 7: Ablations. (A) Ablations of weight sharing, sign constraints, and weight initialization indifferent combinations. Sign constraints (i.e. principled excitation/inhibition) are crucial for learning.
