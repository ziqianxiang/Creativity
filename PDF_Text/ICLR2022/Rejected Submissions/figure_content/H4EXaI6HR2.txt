Figure 1: Parametric network series. When re-computing the hourly model, we can do a warm-restart by droping the leftmost network and adding a new one to the right.
Figure 2: Depiction of the common random numbers in a one-dimensional state space. The blueand red trajectories correspond to two different initial states. The dotted trajectories correspond toone random seed, and the solid ones to another.
Figure 3: Difference between PDS for âˆ† = 167 and the Classic algorithm as a function of theiteration. The PDS-based method surpasses the classic one after 30 iterations.
Figure 4: Here we show the effect of g(t, a) on a few network weights (left), and the derivativeof the cost-to-go function w.r.t the state variables (right), reflecting the parsimonious nature of theweights.
Figure 5: Value Iteration - Learning loop.
