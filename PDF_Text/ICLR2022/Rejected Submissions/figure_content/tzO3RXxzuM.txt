Figure 1: Numerical results for training CNN using SGLD (σt = "(Int/βt) on MNIST, FaShion-MNIST and CIFAR-10. X-axis shows the number of training epochs. (a)-(d) shows our bound isnon-vacuous and can be used to bound the empirical test error. (e)-(h) compare our bound withthe existing bounds and show the effect on αt2. (i)-(l) show the key factors in each bound, i.e.,the squared gradient norm in Li et al. (2020), the gradient incoherence in Negrea et al. (2019),the two-sample incoherence in Rodriguez-Gaivez et al. (2021), and the gradient discrepancy in ourbound. Our bounds are numerically sharper than existing bounds, and larger αt2 leads to tightergeneralization bounds which is consistent with the theoretical analysis.
Figure 2: Numerical results for training CNN using SGLD (σt = 0.2ηt) on a subset of MNIST (n =10000) with different randomness on labels. (a) demonstrates that, as the randomness increases, theempirical test error (dashed lines) increases but still can be bounded by our generalization bound bycombining the empirical training error (solid lines). (b) presents our bound in Theorem 2. (c) showsthe gradient discrepancy ∣∣V' (Wt,zn) — V' (Wt, z：)k2. (d) plots the training error. The gradientdiscrepancy increases as randomness increases, so does our generalization bound.
Figure 3: (a)-(d) show the training dynamics of CNN on MNIST and Fashion-MNIST, and ResNet-18 on CIFAR-10 and CIFAR-100 using noisy sign-SGD with different scaling αt . Legends indicatethe choice of αt and the numbers in brackets are test errors at convergence. As αt → 0, Nosiysign-SGD matches both the optimization trajectory as well as the final test accuracy of the originalsign-SGD (Bernstein et al., 2018a). (e)-(f) show that empirical test error can be bounded by ourbound and the corresponding training error. The larger αt is the sharper our bound is.
