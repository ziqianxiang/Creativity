Figure 1: Data valuation using leave-one-out valuation. The left image shows a setting where thedecision boundary difference between ground-truth and learned boundary is used. The center imagewhere the difference is computed w.r.t. a baseline model, and the right image where only the meshgrid is evaluated w.r.t. to the ground-truth decision boundary. The straight line is always the ground-truth decision boundary g and the curve is the learned decision boundary. In the first two cases,important points are clearly in the area between ground-truth and learned decision boundary. Hence,they are the miss-classified points. In the right plot all points seem to be equally important exceptfor some noise.
Figure 2: Data valuation with data Shapley. On the left, we again use X as baseline and sequentiallyadd points xiMP ∈ XMP to estimate their data value w.r.t the ground-truth model g. In the centerimage, we use the same setup with fX as reference, and, in the right image estimation is done on themesh grid only. In the left two plots, the regions roughly match those from Figure 1 where importantpoints are miss-classified points. In the right most plot there seems to be a small bias towards pointsleft of the decision boundary.
Figure 3: Data valuation using sample forgetting, last learned and memorization. The left plotshows results for standard catastrophic forgetting. The center plot shows results for latest learneddata values and the right plot shows results with memorization. In the two left plots, especiallypoints in the miss-classified region between the two clusters, interval [5, 7] on the x-axis and [3, 5]on the y-axis, are recognized as important. Some points in the upper miss-classified region are alsoconsidered as important but not points in the bottom region. In the right plot memorization almostexactly finds all miss-classified regions.
Figure 4: Data valuation using reinforcement learning. Left when labels and residuals are available(dvrl(xi, yi, (yi - fX (xi))) → R), center with only predictions (dvrl(xi, fX(xi)) → R), and rightwhen both are not available (dvrl(xi) → R). In all cases, the learned boundary does not match theprevious results. DVRL seems to distill the data only.
Figure 5: Snapshot of the synthetic data set for two clusters with means (0, 1) and (10, 7) in the leftplot, with four clusters in the center, and with overlapping (noisy) clusters on the right.
Figure 6: Data valuation using three common out-of-distribution (OOD) methods. Blue areas havea high data value (are OOD) while red areas are less important. The Gaussian process (left plot)recognizes all points outside of the train distribution as OOD while Monte Carlo dropout (centerplot) and ensemble methods (right plot) recognize only points close to the decision boundary. MonteCarlo Dropout is better in finding points in the upper part of the decision boundary.
Figure 7: Model stability for different architectures of a single layer MLP with hidden layer size 3,50 and 1000 for 15 training runs. Each line is the decision boundary after a full training. Largermodels produce more stable decision boundaries.
Figure 8: Stability of models when a new miss-labeled point (blue square) appears in the center ofthe cluster. Larger data sets seem to be distracted more. The hidden layer size of the MLP is 1000in these experiments. Hence, without the miss-labeled point we would expect the same stability asabove. While the miss-labeled point does not have an impact on the predictions in the train data, itinduces noise to the decision boundary, which might be problematic.
Figure 9: Model stability for different sizes of the training set when a new correctly labeled point(blue square) is added to the data set. The left column shows the data set without the new point(therefore, it is grey) and the right one with new point. The first three rows show data set sizes of50, 100 and 500. The forth row shows a size of 500 again. As before, for larger data sets a newpoint seems to cause more variance in the decision boundary. In the top three rows this variance ismoderate. In the last row it is, however, larger although it is the same setup as in row three exceptthat the data set was re-sampled. Apparently, some initializations are more prone to noise. We didnot observe such noise in the experiments in the paper.
Figure 10: Valuation of the training data. The size of a point represents its data value. Leave-one-out(top left) and catastrophic forgetting (shown in Figure 16) assign the same data value to every point.
Figure 11: Data valuation of training data with leave-one-out, Shapley, latest-learned and DVRLon data from four clusters. Again, leave-one-out (top left) assigns almost the same data value toeach point. Shapley (top right) shows more variance this time and values one of the two clusters foreach label slightly higher than the other. The results for catastrophic forgetting are visible in Figure17. As mentioned in Figure 17, it seems to find points close to the decision boundary to be mostimportant. Last learned and DVRL again show the most variance in the data values and considerone cluster as much less important than the others. Again they produces the best results if the goalis to reduce the size of the data set.
Figure 12: Results for data valuation on noisy data (overlapping clusters). Results are similar tothose in the main paper. Leave-one-out and shapely (top row) largely agree on the miss-classifiedregion to be important. Sample forgetting (bottom left) finds points between the clusters as well aspart of the points in the upper miss-classified region as important. DVRL again produces differentresults.
Figure 13: Results for data valuation on data from four means. Again, results are similar to theones before. Leave-one-out and Shapley agree on the miss-classified regions as important but do notfind the very small miss-classified region between clusters as important. Sample forgetting finds theregion between clusters and, additionally, both other miss-classified regions as important. DVRLagain falls out of the box.
Figure 14: Leave-one-out, sample forgetting and DVRL on zero centered data. In the main paper weuse data not centered in the origin because we find that our MLP thereby learns a non-linear decisionboundary in the interval of interest. Here, we show results on data centered in the origin. This plotmay also serve as reminder that data normalization is important. Apart from this, points in the miss-classified region and close to the decision boundaries seem more important with leave-one-out andsample forgetting. DVRL finds the region around the center including small parts of each cluster tobe important. Results with DVRL seem more intuitive in this case.
Figure 15: Data valuation with catastrophic forgetting and memorization events on mesh grid only.
Figure 16:	Trajectory of decision boundary for catastrophic forgetting and importance of points assize. The first plot shows 10 different random decision boundaries on initialization of the MLP. Thenext four plots show the decision boundary after the first, third, ninth and fourteenth epoch. Thelast image shows the final data values as size of training points. All points have the same data valuehere.
Figure 17:	Trajectory of decision boundary for catastrophic forgetting on data from four means. Thefirst plot exemplary shows 10 different decision boundaries on another data set. The next four plotsshow the decision boundary after the first, third, ninth and fourteenth epoch. The last image showsthe final data values as size of training points. Only points close to the decision boundary have ahigh data value.
Figure 18:	Trajectory of decision boundary for catastrophic forgetting on noisy data. The first plotexemplary shows 10 different decision boundaries on another data set. The next four plots show thedecision boundary after the first, third, ninth and fourteenth epoch. The last image shows the finaldata values as size of training points. Again, points close to the decision boundary have a high datavalue.
Figure 19: Data valuation with last-learned samples (top), frequently-forgotten samples (middle)and simple forgetting (bottom). For finding last-learned samples we use the epoch a point wascorrectly classified in for the first time as data value. Frequently forgotten samples are similar tosample forgetting in the main paper, but we only require them to be classified correctly at least once(and not in the previous epoch). Simple forgetting counts how often a point was forgotten but doesnot require that is was correctly classified before. Hence, never learned points count here as well.
Figure 20: Three iterations of DVRL on the same training set produce different results.
Figure 21: DVRL with new rare point. The new point is the orange dot at (15, 5) and as suchfalls into the miss-classified region. In this case, DVRL with the full input correctly labels thepoint as important. DVRL with predictions only does not recognize it as important. DVRL withoutpredictions or labels, however, recognizes it as important, and, surprisingly, finds a region close tothe miss-classified region to be important.
