Figure 1: Generative models for a single time step of a deterministic autoregressive LSTM, theVRNN and SRNN, and the CW-VAE with one layer of latent variables. Red arrows indicate purelydeterministic paths from the output xt to previous input x<t without passing a stochastic node.
Figure 2: Inference (left) and generative (right) models for the Clockwork VAE with a hierarchy oftwo latent variables with s1 = 1 and s2 = 2. The models are unrolled over four consecutive timesteps but note that the graph continues towards t = 0 and t = Tx . Blue arrows indicate parametersharing between the inference and generative models. We omit the deterministic variable for clarity.
Figure 3: (left) Clustering of phonemes in a two-dimensional Linear Discriminant Analysis (LDA)subspace of a CW-VAE latent space of z1. (right) A leave-one-out classification accuracy for a k-nearest-neighbor classifier for different k fitted to a 5D linear subspace of a CW-VAE latent space.
Figure 4: Leave-one-out k-nearest-neighbor accuracy with different k for (left) the speakerâ€™s genderand (right) the height of male speakers (female speakers yield a similar result).
Figure 5: Clustering of speaker gender in an one-dimensional linear subspace defined by a lineardiscriminant analysis of the CW-VAE latent space and of a time-averaged mel spectrogram. Thetotal overlap is slightly smaller in the subspace of the CW-VAE latent space and the separationbetween the distribution peaks is larger.
Figure 6: Clustering of speaker height in an two-dimensional linear subspace defined by a lineardiscriminant analysis of the CW-VAE latent space.
Figure 7: CW-VAE generative model p(x, z) in (a) and inference model q(z|x) in (b) for a three-layered model with k1 = 1 and c = 2 giving k2 = 2 and k3 = 4 unrolled over eight steps in theobserved variable. Blue arrows are (mostly) shared between the inference and generative models.
Figure 8: CW-VAE cell state slt update. All blue arrows are shared between generation and infer-ence. The dashed arrow is used only during inference. The solid arrow has unique transformationsduring inference and generation.
Figure 9: VRNN (Chung et al., 2015) generative model p(x, z) in (a) and inference model q(z|x) in(b) unrolled over three steps in the observed variable. Blue arrows are shared between the inferenceand generative models.
Figure 10: SRNN (Fraccaro et al., 2016) generative model p(x, z) in (a) and inference model q(z|x)in (b) unrolled over three steps in the observed variable. Blue arrows are shared between the infer-ence and generative models.
Figure 11: Boxplots of the duration of the pronunciation of phonemes in TIMIT for a specificspeaker DRW0 in (a) and globally in (b). Not all phonemes are pronounced by speaker DRW0 overthe course of their 10 test set sentences and hence they are missing from the x-axis compared to theglobal durations.
