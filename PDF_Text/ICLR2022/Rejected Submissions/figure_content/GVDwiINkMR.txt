Figure 1: Results on SUSY. We visualize results in terms of train (green) and test error (orange) forFedDC (a) and federated learning (b), both using Radon points for aggregation. The network has441 clients with 2 data points per client. ‚ÄùOptimal performance, i.e., that of a central model trainedon all data, is indicated by dashed line.
Figure 2: Differential privacy results. We show the per-formance of FedDC (top solid line) compared to runswith clipped parameter updates and added Gaussian noise(dashed lines) on CIFAR10 with 250 clients.
Figure 3: Synthetic data results. Comparison of FEDDC (left) and FedAvg (right) for training MLPson a synthetic dataset. Mean and confidence test accuracy of each client is reported in orange, wherethe optimal reachable accuracy, as given by centralized training, is indicated by the dashed blackline.
Figure 4: Averaging periods on CIFAR10. For250 clients with small ResNets and 64 samplesper client, we visualize the performance (higheris better) of FedDC and FedAvg for different ag-gregation periods b.
