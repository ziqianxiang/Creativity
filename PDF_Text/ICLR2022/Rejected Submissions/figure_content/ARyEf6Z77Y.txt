Figure 1: Framework of CoE with 3 experts. Delegator outputs the probabilities to select each expertand a rough prediction to trigger potential early termination. Each input is processed through allexperts during training, but only through at most one expert during inference.
Figure 2: Architecture of dele-gator.
Figure 3: A demo to illustrate the training procedure of CoE. The training samples are denotedas green triangles or pink circles based on which expert is suitable. They are partitioned into twoportions based on expert suitability or hypothesis learned by delegator, then WGM enables eachexpert to focus on one portion. Delegator is trained with selection labels that indicate the suitableexpert, thus delegator learns hypothesis to select the suitable expert for each sample.
Figure 4: Accuracy v.s. FLOPs and training cost on ImageNet.
Figure 5:	The Vogel approximation method.
Figure 6:	The modified architecture of delegator.
Figure 7: Selection probabilities for each expert at different TCP values.
Figure 8: Selection probabilities for each expert. The horizontal axis indicates the rough predictionclass. The 1000 probability vectors are clustered for better visualization.
Figure 9: Images that are predicted as ’meat market’ by the delegator. They are partitioned into fourgroups based on which expert is selected. The red border indicates humans are contained, greenborder indicates humans are not contained.
Figure 10: Accuracy v.s. FLOPs. “ET” means Early Termination and “CC” indicates CondConv.
