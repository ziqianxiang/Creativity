Figure 1: We measure the discrepancy between two distributions living respectively in Rp and Rq .
Figure 2: Examples of distance computationbetween (left) two-translating Gaussian distri-butions. (right) two spirals.
Figure 3: Examples of target distribu-tions for our generative models (left) 3D4-mode. (right) 2D 5-mode.
Figure 6: Classification perfor-mance under transformations.
Figure 4: Examples of generated distributions across iterations (10, 10000, 20000, and 30000) fortwo targets.From top to bottom (first-row) HWD for the 4-mode. (second-row) SGW for the 4-mode(third-row) HWD for 3D 5-mode. (fourth-row) SGW for 5-mode. For each row, the last panel showsthe evolution of the loss over the 30000 iterations.
Figure 5: Computation time with respect to n, the number of vertices on each shape. (Left-panel)Instances of 3D objects. (Right-panel) Running time.
Figure 7: The implemented approach. Both the distributional and mappings parts are achieved bydeep neural networks. A number K of projections is used to compute 1D-Wasserstein distances.
Figure 8: Comparing (top) HWD and (bottom) SGW on generating 2D distributions from 3D target.
Figure 9: Comparing (top) HWD and (bottom) SGW on generating 3D distributions from 2D target.
Figure 10: Instances of the shape dataset with null and isometry transformations. The classesare respectively human,dog and horse. For the experiments of Figure 6 we also consider the"topology", "scale", "shotnoise" transformations that respectively amount to deform, to upscale andto add noise to the shapes of each class.
