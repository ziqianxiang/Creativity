Figure 1: Visualization of different normalization methods. Horizontal is channel dimension, andvertical is batch dimension. The small square grid is the pixel set along the spatial height and widthdimensions.
Figure 2:	Test accuracy (%) by using different normalization combinations on ResNet18. Redderrepresents higher accuracy. Slash means the failure of training. The diagonal cells are the traditionalhomologous normalization, while other cells are heterologous normalization.
Figure 3:	Test accuracy (%) by using different channel groups to calculate Extend Normalization'smean and std. Redder represents higher accuracy. When the group is c, which means the number ofchannels, Extend Normalization is equal to Batch Normalization.
Figure 4: Comparisons between SN and HNwith different batch sizes.
Figure 5: Test accuracy of ResNet18 on ImageNet vs. the number of training epoch.
Figure 6: Comparion of statistics’ std whichreflects the statistics’ fluctuation quantita-tively. Neuron i-j represents the jth neuronof the ith layer, and bs refers to batch size.
Figure 7: Statistics evolution over the course of training. Neuron i-j represents the jth neuronof the ith layer. Horizontal axis represents training step. The small batch size problem of BatchNormalization is caused mainly by the fluctuation of the std.
