Figure 1: Performance of approximating the behavior policy on the eight-Gaussian dataset. A conditional VAE(“CVAE”), a conditional GAN (“CGAN”), and a Gaussian-generator conditional GAN (“G-CGAN”) are fittedusing the conditional-distribution (policy) matching approach. A conditional GAN (“GAN”) is fitted using thebasic state-action-joint-visitation matching strategy (Section 4.1). More details are provided in Appendix D.1.
Figure 2: Performance of approximating the behavior policy on the eight-Gaussian dataset by conditionalGAN with default (implicit) generator and Gaussian generator. A conditional GAN (“CGAN”) and a Gaussian-generator conditional GAN (“G-CGAN”) are fitted using the conditional-distribution matching approach. Aconditional GAN (“GAN”) and a Gaussian-generator conditional GAN (“G-GAN”) are fitted using the basicjoint-visitation matching strategy (Section 4.1). Performance is judged by (1) clear concentration on the eightcenters, and (2) smooth interpolation between centers, which implies a good and smooth fit to the behaviorpolicy. Details of this toy experiment are presented on Appendix D.1.
Figure 3: KDE plots of the first two dimensions of actions in the “maze2d-umaze-v1” dataset. From left toright: (a) Action distribution in the offline dataset; (b) Action distribution produced by the final Gaussian policyin Table 4; (c) Action distribution by the final implicit policy (Section 4.1) in Table 4.
