Figure 1: Concept niches and their complement:(a) given a set of concepts and a set of classifi-cation labels, (b) a concept nicher identifies theconcepts on which a label depends strongly (redblocks); thus (c) a concept niche is the set of theseconcepts that a label depends on strongly; and (d)a complement concept niche is the set of conceptsthat a label does not depend on strongly.
Figure 2: Mean concept AUC calculated by averaging over all the AUCs of predicting individual ground-truthconcepts from the entire set of learnt concepts. Each AUC is calculated using a ReLU MLP with hidden layers{64, 64} that is trained to predict the target concept.
Figure 3: Impurity scores (both oracle and non-oracle) in 3dshapes(λ).
Figure 4: Evaluation of different models, deployed across various tasks, using our proposed metrics.
Figure 5: Absolute Pearson correlation coefficients of the top-10 concepts with highest label mutual informationin CUB dataset. Notice that there exist strong correlations between some of the concepts.
Figure 6: The impaCt of CCorrN’s β on niChe purity, impurity, and size in dSprites(λ = 0).
Figure 7: Absolute values of concepts-to-tasks linear correlation coefficients in CUB.
Figure 8: Effect of network capacity (i.e., number of hidden activations used in the encoder and decoder) in aCBM’s concept accuracy and oracle impurity.
Figure 9: Downstream task predictive AUC for all datasets using original pre-trained models prior to bottleneckconstruction. Note that because DGL methods have no downstream task supervision in their training pipelines,we do not include those methods.
Figure 10: Downstream task predictive AUC for all datasets using the overall set of learnt concepts to predictthe task labels. Note that this plot faithfully replicates the downstream task predictive AUC of methods thatreceived direct task supervision in their training (shown in Figure 9).
Figure 11: Impurity scores (both oracle and non-oracle) in 3dshapes(λ).
