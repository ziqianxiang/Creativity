Table 1: Comparison result of our TAViT to other dis-tributed learning strategies. Q# denotes the quality ofJPEG images for deblocking task.
Table 2: Comparison results on Benchmark datasets. For Transformer-based methods, EL is theend-to-end learning, STL is the single-task learning, and ours is the multi-task learning using TAViT.
Table 3: The Transformer body architecture and its parameters in our experiments. For each encoderlayer l, MHA is the multi-head attention modules, LN is the layer-normalization, DropOut is thedropout layer, Linear is the fully-connected layer, and ReLU is the ReLU activation function.
Table 4: Model sizes of the head, body, and tail in our experiment.
Table 5: Quantitative results of TAViT according to the cycles, which are visualized with graphs inthe main paper. The best results are highlighted in bold.
Table 6: Quantitative results of TAViT on multiple image processing tasks with 1/2 data for each taskin the task-agnostic learning. The best results are highlighted in bold.
Table 7: Results of study on the weight aggregation period of FL for image deblocking task. The bestresults are highlighted in bold. Q# denotes the quantization quality of JPEG images.
Table 8: Results of study on the effect of the Transformer body of TAViT versus CNN body.
Table 9: Results of the study on the sampling strategy of clients in task-agnostic learning.
Table 10: Results of applications to diverse image processing tasks using different image domains.
