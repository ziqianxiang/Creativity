Table 1: Performance comparisons between different Transformer-based modules: Mean accuracy(%) ± 95% confidence interval. Boldface letters are used to mark the best results. Results on moredatasets are summarized at Table 12 in Appendix A.5.1.
Table 2: Efficiency comparisons between different Transformer-based modules: average training time per epoch (ms)/total training time (s). Underlined letters imply results with mini-batch training.							Cora	CiteSeer	PubMed	Chameleon	Actor	SquirrelGraphSAGE	3.01/0.94	4.09/1.09	4.88/2.97	7.19/1.67	4.45/0.90	32.85/6.64+Graphormer(All)	10.09/2.11	15.22/3.17	23319.70/6995.91	14.34/2.91	37.27/7.54	48.41/9.81+Reformer	13.71/3.84	15.57/4.05	37.05/18.46	21.53/4.85	23.72/4.79	46.82/9.51+RT	572.48/226.31	449.96/186.34	2964.85/950.29	349.41/121.71	860.45/301.07	720.47/256.76Coarformer	7.61/2.28 —	9.14/2.13 —	8.81/5.21	10.95/2.52~~	8.14/1.64—	34.00/6.88~~5.1.2 Effectivenes s and robustness of Coarformer’ s global viewIn the previous section, we have shown the superiority of Coarformer, where GraphSAGE is adoptedas the module working in Coarformer’s local view. To verify the generality of the benefits brought7Under review as a conference paper at ICLR 2022mw) A-IoUjəE nd。pəsɔOo300O OO OO O1 O1 1
Table 3: Performance comparisons on different GNN-based module: Mean accuracy (%) ± 95% confidence interval. Boldface letters are used to mark the improvements. Results on more datasets are summarized at Table 13 in Appendix A.5.2.									GCN	GIN	GAT	GT	APPNP	GPR-GNN	w/o	87.06±0.63	84.11±0.82	87.18±0.66	86.42±0.82	88.10±0.73	88.48±0.51Cora	w/	87.64±0.65	85.63±0.83	87.83±0.76	86.91±0.62	88.78±0.62	88.93±0.31	∆	0.58	1.52	0.65	0.49	0.68	0.45	w/o	79.28±0.61	74.92±1.34	79.60±0.80	78.80±0.50	79.58±0.70	78.49±1.15CiteSeer	w/	78.91±1.02	78.96±0.74	78.34±0.59	78.72±0.94	79.44±0.80	78.24±1.00	∆	-0.27	4.04	-1.26	-0.08	-0.14	-0.25	w/o	86.86±0.28	88.57±0.44	86.12±0.29	88.75±0.16	88.35±0.23	90.90±0.65PubMed	w/	89.76±0.41	88.57±0.40	87.96±0.52	90.08±0.21	88.72±0.46	91.26±0.48	∆	2.90	0.00	1.84	1.33	0.37	0.36	w/o	58.80±0.90	38.84±2.55	59.41±1.55	57.86±1.2	53.76±1.44	66.63±1.41Chameleon	w/	67.64±1.29	63.85±2.36	67.59±1.88	66.59±0.86	59.85±0.99	67.09±1.53	∆	8.84	25.01	8.18	8.73	6.09	0.46	w/o	33.61±0.54	34.07±0.46	35.79±0.64	40.23±0.69	39.55±1.01	40.74±0.53Actor	w/	37.18±0.74	34.12±0.42	35.85±0.67	41.37±0.60	40.21±0.73	41.67±0.70	∆	3.57	0.05	0.06	1.14	0.66	0.93	w/o	46.46±0.92	19.32±0.56	48.2±1.85	52.89±0.51	36.4±1.50	52.31±1.09Squirrel	w/	54.75±1.12	43.13±0.69	56.23±1.22	53.18±0.40	46.80±0.91	51.85±1.18	∆	8.29	23.81	8.03	0.29	10.40	-0.46
Table 4: Performance comparison on OGB: Mean accuracy (%) ± 95% confidence interval. Boldface letters are used to mark the best results.					GCN	+Reformer	+RT	Coarformerogbn-arxiv	71.32±0.25	69.62±0.24	67.07±0.12	71.66±0.24ogbn-products	78.70±0.34	74.09±0.23	OOM	79.18±0.205.3 Sensitivity analysisSince Coarformer applies the Transformer-based module on a coarse graph, a question naturallycomes up—Are the performances of Coarformer sensitive to the choice of coarsening algorithm aswell as the adopted coarsening rate? Therefore, we evaluate Coarformer with different coarsen-ing algorithms and different coarsening rates. Considered coarsening algorithms include VariationNeighborhoods (VN) (Loukas, 2019), Variation Edges (VE) (Loukas, 2019), and Algebraic JC (AlgJC) (Ron et al., 2011). Experimental settings are deferred to Appendix A.3.3.
Table 5: Sensitivity analysis: Mean accuracy (%) ± 95% confidence interval. Boldface letters areused to mark the best results.
Table 6: Performance comparisons on Cora with different splits: Mean accuracy (%) ± 95% confi-dence interval. Boldface letters are used to mark the best results.
Table 7: Details about HPO for Graphormer on Cora.
Table 8: Dataset statistics	Cora	CiteSeer	PubMed	Computers	Photo	Chameleon	Actor	Squirrel	Texas	Cornell#Nodes	2,708	3,327	19,717	13,752	7,650	2,277	7,600	5,201	183	183#Edges	5,278	4,522	44,324	245,861	119,081	31,371	26,659	198,353	279	277#Features	1,433	3,703	500	767	767	2,325	932	2,089	1,703	1,703#Classes	7	6	5	10	8	5	5	5	5	5A.3 Experimental detailsA.3.1 Details about performance comparisonsIn this section, we describe the details of the experiment with parameter settings. It is worth notingthat, unlike the GPR-GNN setup, we report the accuracy of the test set when the model achievesthe highest accuracy in the validation set. In contrast, GPR-GNN reports the accuracy of the testset when the loss function is lowest in the validation set. We use accuracy with a 95% confidenceinterval, equal to the micro-f1 score when it is a single-label classification, as an evaluation metricof effectiveness and the average training time as an evaluation metric of efficiency. In addition, we13Under review as a conference paper at ICLR 2022Table 9: OGB dataset statistics.
Table 9: OGB dataset statistics.
Table 10: Efficiency comparisons on homophilic graphs: Average training time per epoch (ms)/totaltraining time (s). Underlined letters indicate results under mini-batch training.
Table 11: Efficiency comparisons on heterophilic graphs: Average training time per epoch(ms)/average total training time (s). Underlined letters indicate results under mini-batch training.
Table 12: Performance comparisons between different Transformer-based methods: Mean accuracy(%) ± 95% confidence interval. Boldface letters are used to mark the best results.
Table 13: Performance comparisons on different GNN-based module: Mean accuracy (%) ± 95%confidence interval. Boldface letters are used to mark the improvements.
