Table 1: Ablation summary on agent Alpaca. In this table, we show the Task, Run and Jump val-idation loss of proposed method and its ablated versions. Full represents the proposed method. Theabbreviations under training setting represent name of components to remove. To be more specific,OP: Optimizer, AF: Activation Function, BS: Batch Size, PS: Periodic Signal, SV: State Vector, TV:Targets, LD: Loss Design. *Difftaichi is an implementation of Hu et al. (2020), enhanced with ourloss design. It can be observed that the Full method achieves the best performance on Task lossamong all models.
Table 2: Grid search for Adam hyperparameters. The values in the table represent the normal-ized validation loss for Task. We chose 5 different values for β1 and β2 in Adam, which are sampledin logarithmic scale. For each setting, the experiments are repeated for multiple times. *The defaultvalues for Adam hyperparameters are β1 = 0.9 and β2 = 0.999.
Table 3: PPO hyper-parametersParameter	Valueslearning rate	2.5e-4entropy coef	0.01value loss coef	0.5number of processes	8number of simulation steps.	1000Reward Design. We design a reward function for PPO based on our loss functions. Recall thevelocity part of equation 4. We define the total velocity reward as:Rv = λv X X gv(n)2 - (v(t) - gv(n))2	(6)n∈T t∈[Pr,P]If we directly split the reward into each time steps by t, the rewards of first Pr time steps would bezero and it is too difficult for PPO to learn the policy. Therefore, we modified the reward function totackle this issue. By equation 1, we haveRv = λv ^X	^X gv (n)2 - P (C⑴-c(t - Pr)) - gv (n)	⑺n∈T t∈[Pr,P]	r=P X x [Prgv (n)]2 - [c(t) - (c(t - Pr) + Prgv (n))] .	(8)r n∈T t∈[Pr,P]We can define a function fn(t0, t) = [Prgv(n)]2 - [c(t0) - (c(t - Pr) + Prgv(n))]2 and substituteit back to equation 8. The reward can be re-written as
Table 4: Ablation Summary on Monster.
Table 5: Ablation Summary on HugeStool.
Table 6: Ablation Summary on Stool.
Table 7: Full ablation studies for activation functions. The values in the table represent thenormalized validation loss for Task. For each setting, the experiments are repeated for multipletimes. It can be observed that the model using sin for both hidden and output layer achieves the bestresults.
