Table 1: Proper loss functions. A proper loss is a function L(F, G) over a forecast F targeting avariable y ∈ Y whose true distribution is G and for which S(F, G) ≥ S(G, G) for all F. EachL(F, G) decomposes into the sum of a calibration loss term Lc (F, Q) (also known as reliability)and a refinement loss term Lr (Q) (which itself decomposes into a sharpness and an uncertaintyterm). Here, Q(y) denotes the cumulative distribution function of the conditional distribution P(Y =y | FX = F) of Y given a forecast F, and q(y), f (y) are the probability density functions of Qand F , respectively. We give three examples of proper losses: the log-loss, the continuous rankedprobability score (CRPS), and the quantile loss.
Table 2: Calibration and accuracy on UCI regression datasets. We evaluate Bayesian linear regression,Bayesian neural networks, and deep ensembles using mean average error (MAE), mean absolute percent er-ror (MAPE), and the check score (CHK); we compare against Kuleshov et al. (2018) and Song et al. (2019).
Table 3: Performance on Image Classification6.3	Classification Experiments on MNIST, SVHN, CIFAR 1 0We report the results of the image classificationexperiments in Table 3. We measure perfor-mance using accuracy and calibration error ofKuleshov et al. (2018) on the test set. We reportthese metrics for baseline and calibrated ver-sions of convolutional neural network classifier.
