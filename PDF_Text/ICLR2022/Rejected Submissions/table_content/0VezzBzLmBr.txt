Table 1: Performance of OTC on BCQ.
Table 2: Performance of OTC on AWAC.
Table 3: Experimental settings and hyperparametersHyperparameter	BCQ	AWACdiscount (γ)	0.99	0.99|B|	512	512|D|	2000	2000batch size	128	128hidden sizes	(64, 64)	(256, 256)activation	ReLU	ReLUactor learning rate	10-4	10-4critic learning rate	10-4	5 × 10-4embedding dimension	10	10finetuning updates (L)	4000	2000B OTC ON MABCQAs the transition distribution of the learned policy in MABCQ does not follow PBi , MABCQ is nota suitable backbone algorithm, though we additionally provides some results of OTC on MABCQin Figure 9. OTC+MABCQ could outperform MABCQ in online tuning. In halfcheetah-random,MABCQ achieves better performance than BCQ in offline learning. However, since value deviationin MABCQ has made the agent be optimistic toward other agents in offline training, the modifiedtransition dynamics in MABCQ is close to the real transition dynamics during the online interactionwith improved other agents, and thus MABCQ does not benefit from online tuning in halfcheetah-
