Table 1: Robust test accuracy achieved by various training methods on the entire training set, evaluatedby various attack methods. “*” indicates the transfer attack from a surrogate model.
Table 2: Training objectives in the outer minimization in various adversarial training methods, where'(∙, ∙) indicates the cross-entropy loss, f (∙) indicates the probabilistic prediction of a model andfy (∙) indicates the probability corresponding to class y, δ indicates the adversarial perturbation of Xgenerated by the inner maximization.
Table 3: Performance of adversarially training a pre-activation ResNet-18 on CIFAR-10 using PGDand TRADES with different training perturbation radii.
