Table 1: MLP does not overfit thetraining dataset. We report train-ing NLL (NLLtrain) and testing NLL(NLLtest) of ResNet-50 on CIFAR-100.
Table 2: Spatial smoothing and temporal smoothing are complementary. We provide predictiveperformance of MC dropout in semantic segmentation. Spat and Temp each stand for spatialsmoothing and temporal smoothing. Acc and Cons stand for accuracy and consistency. The numbersin brackets denote the performance improvements over the baseline.
Table A.1: Hyperparameters of models for image classification.
Table B.1: We use tanh as the default for Prob based on the predictive performance ofMC dropoutfor CIFAR-100 with various Probs.
Table B.2: The optimal shape of the blur kernel is model-dependent. We measure the predictiveperformance ofMC dropout using spatial smoothing with various size of Blur kernels on CIFAR-100.
Table C.1: MLP classifier does not overfit training dataset, i.e., GAP does not regularize NNs. Weprovide predictive performance of MC dropout with various classifiers on CIFAR-100. Err is error.
Table C.2: Pre-activation arrangement improves uncertainty as well as accuracy. We measurethe predictive performance of models with pre-activation arrangement on CIFAR-100.
Table E.1: Spatial smoothing improves both accuracy and uncertainty at the same time. Predic-tive performance of models with spatial smoothing in image classification on CIFAR-10, CIFAR-100,and ImageNet.
Table E.2: Spatial smoothing improves adversarial robustness. We measure the accuracy (ACC)and the Attack Success Rate (ASR) of ResNet-50 against adversarial attacks on ImageNet.
Table E.3: Spatial smoothing improves the consistency, robustness against shift-perturbation.
Table E.4: Spatial smoothing and temporal smoothing are complementary. We provide predictiveperformance of MC dropout in semantic segmentation on CamVid for each method. Spat and Tempeach stand for spatial smoothing and temporal smoothing. Cons stands for consistency.
