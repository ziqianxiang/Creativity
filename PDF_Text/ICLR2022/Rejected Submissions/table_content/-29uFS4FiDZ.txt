Table 1: Top 5 nearest neighbours of words in context based on cosine similarity. We also report theindex of the selected sense and its probability in that context.
Table 2: ARI (Adjusted Rand Index) scores for word sense induction tasks. All models havedimension of 300. The Adagram and Disambiguated skip-gram models learn variable number ofsenses while all other models learn fixed number of senses per word. All baseline results exceptMUSE were collected from Grzegorczyk & Kurdziel (2018). SenseEmbed - Sense embedding modelwithout distillation, BERTSense - Sense embedding model (Sec. 3.2.1), BERTKDEmbed - Senseembedding with distillation4.4	Contextual Word SimilarityHere, the task is to predict the similarity of the meaning of 2 words given the context they were used.
Table 3: Spearman rank correlation score (ρ × 100) on the SCWS dataset. Skip-gram is the onlysingle-sense embedding model. All other embedding models are 300 dimensional. Skip-gram resultsare reported in Bartunov et al. (2016), MUSE score is obtained using their published model weightsand for other models the results are from the respective papers.
Table 4: Word sense induction using the BERT Sense model (768D) and knowledge distilled senseembedding model (300D). ARI (Adjusted Rand Index) scores are reported.
Table 5: Comparison of BERT sense model with sense embedding trained with knowledge distillation.
