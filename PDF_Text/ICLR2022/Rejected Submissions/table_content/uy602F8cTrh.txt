Table 1: Model ArchitectureModules	Hidden Layers	Neurons Per LayerWorld Model	3	200Policy Actor	2	256Policy Critic	2	256B HyperparameterThe size of the real experience replay buffer Dr is 100k for MBPO and our method CausalDynain all three settings. For SAC, it is 1M as we notice SAC with 100k-size replay buffer cannot betrained well. For the world model training, The replay buffer Dr is split randomly into a training setDr,train with 80% of the data and a holdout set Dr,holdout containing the remaining data. We trainthe model once for every 250 real environment steps until converge is evaluated on the holdout set.
