Table 1: Effect of combining LayerNorm tuning with fine-tuning methods. Normal refers to LN tuning bysimultaneously tuning LayerNorm parameters with the specified fine-tuning method. For all approaches, theaddition of LayerNorm tuning in either form provides a significant performance boost. Linear probe and prompttuning receive the largest benefit when combined with any form of LayerNorm tuning.
Table 2: Results on the WILDS benchmark. We benchmarkour fine-tuning methods on three image classification datasetsand find that our fine-tuning methods improve upon zero-shotCLIP performance significantly.
Table 4: Few-shot classification accuracy on CUB.
Table 3: Few-shot classification accuracy on Mini-ImageNet. Just zero-shot CLIP performs strongly onfew-shot adaptation, and our fine-tuning methods pro-vide additional performance gains. A combination ofLinear Probe with LayerNorm tuning performs the best,exceeding the current reported SOTA on Mini-ImageNet.
Table 5: Dataset information.
