Table 1: Comparison of the FID scores for dif-ferent models on the MNIST dataset. We reportthe mean and the variance of FID scores from 5simulations with different weight initializations.
Table 2: Reconstruction quality. L2 distance between target and the reconstructed image. (Im-ageVAE is taken from Reddy et al. (2021), it indicates a purely raster-based autoencoder. )8Under review as a conference paper at ICLR 2022E	0	S	H	0	1 1 7	Γ∏ E E	Ce G)	ð © 6	X h h	够由雷X 1 1	Em m	r⅛∕⅛ r⅛	a ð >		屯E有ILL	m m(r\	四金八	β ð ⅞	M> /中修	场倡（S_^9 夕?7 797/7-T一7τ7φ7r7XxxS乂 XyXxxΝ以双圆0 W双回 0fi	α	n	6 6 4
Table 3: Hyperparameters for unconditional generation. λ1 and λ2 refer to the respective hyper-parameters in Equation 1. α and tau refer to the respective hyperparameters of entropy penalty inEquation 2.
Table 4: Hyperparameters for reconstruction (parsing). λ1 refers to the ‘number of action’ penaltyin Equation 3. α and tau refer to the respective hyperparameters of entropy penalty in Equation 2.
Table 5: For each alphabet in the Omniglot evaluation set, we present the number of strokes ouragent used to reconstruct the given image vs. mean number of strokes obtained from human-labeleddata. The stroke count for human-labeled data is calculated using the labels within the Omniglotdataset.
