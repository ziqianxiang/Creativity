Table 1: Comparison of attack strategies (1000 samples). SCAR was implemented according tothe pseudo code in Balkanski et al. (2020) and PGD was run for 50 iterations. SparseFool takesonly a fraction of the time compared to PGD while obtaining much sparser results at almost perfectsuccess rate on Neuromorphic MNIST. The input size for this dataset is set to (60,2,34,34). We alsouse SparseFool to attack samples from the IBM Gestures dataset at different values of Î», a parametertrading-off speed and sparsity. The success rate is here defined as the fraction of samples that wereinitially correctly classified, for which the attack algorithm converged to an adversarial example thatthe network classifies incorrectly.
Table 2: Adversarial patches for different target labels were evaluated on- and off-chip. Shown hereare the success rates in percent for each target label. An attack is considered successful if the originallabel is not the target label and the network predicts the target label when the patch is applied.
