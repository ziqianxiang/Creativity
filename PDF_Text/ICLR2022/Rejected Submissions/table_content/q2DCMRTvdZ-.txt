Table 1: A case study showing the importance of separately evaluating supernet training andarchtiecture selection. The DARTS-PT architecture selection method run on a supernet trained onstandard DARTS (left) shows improved peformance when not training architecture weights. Butwhen the same perturbation method is applied to a supernet trained via DARTS- to results from in-cluding auxiliary skip connection (right), we see improvement when including architecture weights.
Table 2: Combined results of all S1 and S2 search algorithms on CIFAR-10 in NAS-Bench-201We also evaluate each Stage-1 and Stage-2 algorithm and their combinations on CIFAR100 andImageNet16-120, with the result provided in the Appendix.
Table 3: Combined results of all S1 and S2 search algorithms on CIFAR-10 in DARTS-space6	ConclusionIn order to facilitate integration of recent advances in NAS and well as more robust evaluation inNAS research, we have reframed existing differentiable supernet NAS algorithms as combinationsof two separate search algorithms, the first being an implicit search via the process of training thesupernet using architecture weights and the second being the process of selecting an architectureusing the supernet. We propose two statistics approximating the quality of the weighting over thearchitecture space and the capacity of the supernet to provide information about the relative qual-ity of individual candidate architectures, as well as two corresponding statistics approximating thereliance of architecture selection methods on each of these components of the supernet.
Table 4: Detailed account of Stage-2 Search method review.
Table 5: Combined results of all S1 and S2 search algorithms on CIFAR-100 in NAS-Bench-201A.3 ImageNet 1 6- 1 20 results	prune	valid	synflow	jac cov	perturbdarts	81.59 ± 0.00	79.21 ± 5.36	57.41 ± 0.90	71.52 ± 4.47	65.04 ± 1.22darts-	77.03 ± 4.70	77.49 ± 5.21	54.68 ± 1.44	61.61 ± 5.11	64.65 ± 3.03snas	53.66 ± 0.00	53.44 ± 0.11	56.93 ± 2.31	54.64 ± 0.76	56.20 ± 2.97gdas	58.98 ± 0.00	69.26 ± 4.79	58.62 ± 0.82	63.39 ± 4.54	59.01 ± 2.13dirichlet	53.66 ± 0.00-	54.68 ± 0.17	53.66 ± 0.00-	56.15 ± 1.46	56.04 ± 3.07^Table 6: Combined results of all S1 and S2 search algorithms on ImageNet16-120 in NAS-Bench-20113Under review as a conference paper at ICLR 2022valid	synflow jacob_cov perturbFigure 5: Comparison of Stage-2 search algorithm performance on CIFAR-100 with given baselinemodels. ”Initial” refers to untrained model, ”Uniform” refers to a model trained by training a uni-formly randomly sampled architecture at each batch, and ”Biased” refers to a model trained by anarchitecture sampled from an arbitrarily good distribution at each batch.
Table 6: Combined results of all S1 and S2 search algorithms on ImageNet16-120 in NAS-Bench-20113Under review as a conference paper at ICLR 2022valid	synflow jacob_cov perturbFigure 5: Comparison of Stage-2 search algorithm performance on CIFAR-100 with given baselinemodels. ”Initial” refers to untrained model, ”Uniform” refers to a model trained by training a uni-formly randomly sampled architecture at each batch, and ”Biased” refers to a model trained by anarchitecture sampled from an arbitrarily good distribution at each batch.
