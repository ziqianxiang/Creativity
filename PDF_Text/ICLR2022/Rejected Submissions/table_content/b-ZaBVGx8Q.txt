Table 1: Performance (± standard error obtained via multiple runs) and total communication (inGB), achieved for different privacy guarantees ε. Results for DDGauss (marked DDGx for x bits)are taken from (Kairouz et al., 2021), which uses a slightly smaller version of the FEMNIST dataset(3.4k clients instead of 3.5k).
Table 2: Federated training setsDataset	Number of devices	Total samples	Samples per device				mean	stdMNIST	100	50, 000	500.00	73.10FEMNIST	3500	705, 595	201.60	78.92Shakespeare	660	3, 678, 451	5573.41	6460.77StackOverflow	342, 477	135, 818, 730	396.58	1278.94of 62 classes. The federated nature of the dataset is naturally determined by the writer for a givendatapoint. Additionally, the size of the individual clients’ datasets differ significantly. In the literature,there are two versions of this dataset used for experimentation. Originally published by (Caldas et al.,2018), their published code1 provides a recipe to pre-process the dataset into the federated version.
Table 3: Compression-only (i.e., no DP) ablation studies, all run for 4k rounds. * was still improvingafter 4k rounds.
