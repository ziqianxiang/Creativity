Table 1: Final performance of D&E and baselines on MiniGrid environments. All the methods aretrained in 50M total timesteps.
Table 2: Performance of D&E and baselines on the VizDoom environment.
Table 3: Hyperparameters used in D&EB Additional ExperimentsB.1	harder exploration taskThere are many harder exploration tasks in MiniGrid that have not been well resolved in previousstudies, for example, MiniGrid-KeyCorridorS10R4-v0. The difficulty of this task comes from threeperspectives. Firstly, because the agent can only observe a small range of 7 × 7, large map will con-fuse corridors and rooms, making it difficult for the agent to know about its own location through ob-servation. Secondly, the larger environment makes agent’s trajectory longer and the rewards becomemore sparse, and this reinforces agent’s dependence on intrinsic rewards during training. Thirdly,the larger environment makes the connection between rooms more complex, and agent often needsto go through several rooms to find the key and the object. However, D&E achieves amazing per-formance as shown in Fig.6, which shows that D&E does enhance ability to solve problems ratherthan simply improve efficiency.
