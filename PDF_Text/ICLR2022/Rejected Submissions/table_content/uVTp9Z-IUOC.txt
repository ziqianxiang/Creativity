Table 1: Test-time adaptation of ResNet50 on ImageNet-C at highest severity level 5. Ground truthlabels are used to adapt the model in supervised manner to obtain empirical upper bound performance.
Table 2: SSIM and SLR-adapted ResNet50 accuracy without and with input transformation (IT).
Table A1: Illustrates the error of the decision boundary parameter for different loss functions anddifferent number of samples averaged over 100 runs (shown are mean and standard error of mean).
Table A2: Ablation study on the components of input transformation module on ResNet50 for allcorruptions at severity level 5.
Table A3: Test-time adaptation of ResNet50 on ImageNet-C at highest severity level 5 with andwithout Input Transformation (IT) module. Reported are the mean accuracy(%) across three randomseeds (2020/2021/2022). While IT also improves performance when combined with TENT+, it isstill clearly outperformed by SLR+IT.
Table A4: Comparing the online and offline adaptation results with and without freezing the affineparameters of top normalization layers of ResNet50 at severity 5. Here, "Freeze" and "NoFreeze"refer to the setting with and without freezing the top affine layers respectively.
Table A5: Test-time adaptation of ResNet50 on ImageNet-C at highest severity level 5. Same asTable 1 with error bars.
Table A6: Test-time adaptation of ResNet50 on ImageNet-C at highest severity level 5 with andwithout the pseudo labeling strategy (Liang et al., 2020).
Table A7: Test-time adaptation of modified ResNet50 (following (Liang et al., 2020)) on ImageNet-Cat highest severity level 5 with pseudo labeling strategy at epoch 1 and epoch 5.
Table A8: Test-time adaptation of modified ResNet50 (following (Liang et al., 2020)) on ImageNet-Cat highest severity level 5 with and without pseudo labeling strategy.
Table A9: Performance on VisDA-C datasetMethod	Accuracy(%)No Adaptation	46.1TENT+	81.83±0.16SLR	82.32±0.16is conducted with Adam optimizer with constant learning rate 0.001 for 20 epochs on TENT, TENT+and SLR with three random seeds (2020/2021/2022). Table A10 compares our proposed loss SLRwith TENT variants on ResNet26 and shows that our approach outperforms them across all thedatasets.
Table A10: Digit domain adaptation from SVHN to MNIST / MNIST-M / USPS. Reported values aremean accuracy(%) over three random seeds (2020/2021/2022).
Table A11: Test-time online adaptation of ResNet50 on ImageNet-C at highest severity level 5.
Table A12: ResNet50 adaptation on ImageNet-A (reported is the model accuracy)No adaptation TENT TENT+ HLR SLRImageNet-A 0.0%	0.04%	0.08%	0.51%	0.55%A.9 Additional studies on TENT/TENT+Optimizer and learning rate: The default optimization setting proposed for TENT (Wang et al.,2020) is SGD with learning rate (lr) 0.00025. Table A13 provide additional results for TENT andTENT+ results with both SGD and Adam at different learning rates for both online and offline (5epochs) adaptation settings on ResNet50 for all corruptions at severity level 5. We can notice thatSGD shown to perform better than Adam for TENT and slightly better for TENT+. Among differentlearning rates with SGD, higher learning rates bring additional improvements for TENT and TENT+in online adaptation setting but they are still outperformed by our SLR results. However, for offlineupdates, the higher learning rates shown to hurt the model performance with TENT / TENT+ andour SLR results are superior over them. Note that our optimizer and learning rate remain same forboth online and offline adaptation settings. Here, TENT behaves differently in online and offlineadaptation for the same learning rate and our HLR/SLR behaves the same in both the settings.
Table A13: Evaluation of TENT and TENT+ with both SGD and Adam at different learning rate onResNet50 for all corruptions at severity level 5.
Table A14: Evaluation of TENT+ with and without freezing the top affine layers at different learningrate on ResNet50 for all corruptions at severity level 5. Here, "Freeze" and "NoFreeze" refer to thesetting with and without freezing the top affine layers respectively.
