Table 1: Human-evaluated correctness and evaluation results in VirtualHome. Although action plans generatedby GPT-3 and Codex can even surpass the annotated GT in correctness measure, they are rarely executable. Bytranslating the naive action plans, we show an important step towards grounding LLMs in embodied environ-ments, but we observe room to achieve this without trading executability for correctness. We also observe afailure mode among smaller models that lead to high executability.
Table 4: An example program for the activity ”Relax on sofa”.
Table 6: Average executability & program length of different methods and human annotations.
