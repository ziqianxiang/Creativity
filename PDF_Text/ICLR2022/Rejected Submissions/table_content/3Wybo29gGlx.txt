Table 1: Comparison of vanilla CNNs vs. ViTs with different initialization strategies on medicalimage classification tasks.
Table 2: Medical image segmentation with DEEPLAB 3 comparing CNN vs. ViT encoders.
Table 3: The k-NN evaluation of CNNs and ViTs with different initialization methods includingrandom initialization, ImageNet pretraining, and self-supervision using DINO (Caron et al., 2021)on the target medical dataset. For each task, we use the metrics that are commonly used in the liter-ature, and for random initialization we report the median (± standard deviation) over 5 repetitions.
Table 4: Effect of model capacity on the performance after fine-tuning, with three different ResNetvariants (ResNet18, ResNet50 and ResNet 1 52) and DeiT variants (DeiT-T, DeiT-S andDEIT-B ) using IMAGENET pretraining. For each task, we report the median (± standard devi-ation) over 5 repetitions using the metrics that are commonly used in the literature. We can seethat both CNNs and ViTs mostly benefit from increased model capacity. Further, model types withsimilar capacity perform approximately on par in most of the datasets, indicating that ViTs scalesimilarly to CNNs. The numbers in this table correspond to Figure 3.
Table 5: Comparison of performance of DEIT-S using 8 × 8 and 16 × 16 pixel input patches onstandard medical image classification datasets. Performance is measured after fine-tuning on thedataset. For each task we report the median (± standard deviation) over 5 repetitions using themetrics that are commonly used in the literature. Although, the model using 8 × 8 patch sizes medianperformance is slightly better in the majority of datasets, we see no significant improvements, asidefrom CheXpert.
