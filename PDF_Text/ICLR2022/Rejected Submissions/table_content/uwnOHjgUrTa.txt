Table 1: Obtained accuracy of ResNet18 (R18) trained on CIFAR10 (C10) and CIFAR100(C100) for quantized weights, only. We consider numerous quantization functions (min-max,SAWB, BWN and TWN). Note, that FP refers to full precision (i.e. Qpw, 32q â€œ w).
Table 2: Obtained accuracy of ResNet18 (R18) trained on CIFAR10 (C10) and CIFAR100(C100), when quantizing both weights and activations to 2bit. Note, that PS refers toPACT-SAWB.
Table 3: Experiments on the ImageNet dataset, using the ResNet18 (R18) and the Mo-bileNetV2 (MV2) networks with quantized weights, only. Quantized DNNs trained withDQA consistently outperform quantized DNNs that have been trained with just a singlequantization method. It also drastically reduces the accuracy drop when quantizing Mo-bilenetV2.
Table 4: Experiments on the ImageNet dataset, when quantizing both weights and activa-tions of ResNet18 (R18).
