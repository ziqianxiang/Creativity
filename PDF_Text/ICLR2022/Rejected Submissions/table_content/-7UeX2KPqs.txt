Table 1: Normalized returns for experiments on the D4RL suite of tasks. We perform experiments on tasksfrom the Maze2D, Gym-Mojoco, and Adroit domains. High average scores and low average ranks are desirable.
Table 2: Default Hyperparameters for GAN joint matching.
Table 3: Raw returns for experiments on the D4RL suite of tasks. We performs experiments on tasks fromthe Gym-Mojoco, Maze2D, and Adroit domains. For our algorithm, we report in this table the mean andstandard deviation of the raw returns of the last five rollouts across three random seeds {0, 1, 2}. We run CQLourselves and report the average raw return of the last five rollouts over random seeds {0, 1, 2}. Results forother algorithms are from Fu et al. (2021).
Table 4: Normalized returns for comparing the implicit policy with the Gaussian policy on the basic algorithm(Section 4.1) on the D4RL suite of tasks. The reported number are the means and standard deviations of thenormalized returns of the last five rollouts across three random seeds {0, 1, 2}.
Table 5: Normalized returns for comparing our full algorithm with its counterpart of no state-smoothing in thejoint matching of the state-action-visitation. The reported number are the means and standard deviations of thenormalized returns of the last five rollouts across three random seeds {0, 1, 2}.
Table 6: Normalized returns for comparing our full algorithm with its counterpart of no state-smoothing in theBellman backup. The reported number are the means and standard deviations of the normalized returns of thelast five rollouts across three random seeds {0, 1, 2}.
Table 7: Normalized returns under several values of σ , σB = σJ (Appendix D.2.1) in the full algorithm ofGAN-joint-matching. The reported number are the means and standard deviations of the normalized returns ofthe last five rollouts across three random seeds {0, 1, 2}.
