Table 1: Percentage of robust and inaccurate samples for various recent robust models and datasets,which we describe in more detail in Section 7. Each model is trained for the indicated threat modeland evaluated using 40-step APGD (Croce & Hein, 2020).
Table 2: Robust accuracy (Rraoccb) and robust inaccuracy (Rroabcc) of existing robust models fine-tuned with our proposed loss LCRA . All models are certified via randomized smoothing, using thehyperparameters listed in Appendix A.2.
Table 3: Comparison of our proposed loss LCRA with the Lnoise used in probabilistic certification.
Table 4: Improvement of applying our approach to models trained to optimize natural accuracy only.
Table 5: Robust selection (Rsreolb) and robust accuracy (Rraocbc) of empirical robustness indicator abstainmodels (F, SERI), trained using LERA (Equation 5) and LDGA (Equation 20).
Table 6: Improvements of 2-compositional architectures using models Frobust trained with ourmethod over non-compositional models trained to optimize natural accuracy only (Appendix A.8).
Table 7: Natural (Rnat) and adversarial accuracy (Rraocbc) of standard trained core models, used in2-compositional architectures in Section 7.3 and Appendix A.7.
Table 8: CIFAR-10 robustness-accuracy dataset partitioning. We consider a TRADES (Zhang et al.,2019a) trained ResNet-50, adversarially trained WideResNet-28-10 models (Carmon et al., 2019;Gowal et al., 2020), and a standard trained ResNet-50. Adversarially trained models are trained forthe respective perturbation region. Each model is evaluated for the indicated '∞ threat model, using40-step APGD (Croce & Hein, 2020).
Table 9: CIFAR-100 robustness-accuracy dataset partitioning. We consider a standard trainedWideResNet-28-10 and the adversarially trained WideResNet-28-10 by Rebuffi et al. (2021), trainedfor the respective perturbation region considered in each evaluation. Each model is evaluated for theindicated '∞ threat model, using 40-step APGD (Croce & Hein, 2020).
