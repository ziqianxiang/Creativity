Table 1: FID (lower is better) and PRD score (higher is better) for different models and datasets.
Table 2: Classification results averaged on 20 independent runs. For the generative models, theclassifier is trained on 2K generated samples per class.
Table 3: Neural networks used for the encoder and decoders of VAEs in the benchmarks	MNIST [CIFAR10]	SVHN	CELEBA	OASISEncoder	(1[3], 32, 32)	(3, 32, 32)	(3,64,64)	=	(1, 208, 176)Layer 1	Conv(128, (4, 4), stride=2) Batch normalization Relu	Linear(1000) Relu	CONV(128, (5, 5), STRIDE=2) Batch normalization Relu	Conv(64, (5, 5), stride=2) ReluLayer 2	Conv(256, (4, 4), stride=2) Batch normalization Relu	Linear(500) Relu	-Conv(256, (5, 5), STRIDE=2)- Batch normalizati on Relu	Conv( 128, (5, 5), stride=2) ReluLayer 3	Conv(512, (4, 4), stride=2) Batch normalization Relu	LINEAR(500, 16*)	-Conv(512, (5, 5), STRIDE=2)- Batch normalizati on Relu	Conv(256, (5, 5), stride=2) ReluLayer 4	Conv(1024, (4, 4), stride=2) Batch normalization Relu	-	-CONV(1024, (5, 5), STRIDE=2)- Batch normalizati on Relu	Conv(512, (5, 5), stride=2) ReluLayer 5	LINEAR(4096, 16*)	-	LINEAR(16384, 64*)	Conv(1024, (5, 5), stride=2) ReluLayer 6	-	-	-	LINEAR(4096, 16*)Decoder	(16 [32])	(16)	(64)	=	(16)Layer 1	Linear(65536) RESHAPE(1024, 8, 8)	Linear(500) Relu	Linear(65536) RESHAPE(1024, 8, 8)	Linear(65536) RESHAPE(1 024, 8, 8)Layer 2	ConvT(512, (4, 4), stride=2) Batch normalization Relu	Linear ( 1000) Relu	CONVT(512,(5, 5), STRIDE=2) Batch normalizati on Relu	CONVT(51 2, (5, 5), STRIDE=(3, 2)) ReluLayer 3	ConvT(256, (4, 4), stride=2) Batch normalization Relu	Linear(3072) RESHAPE(3, 32, 32) Sigmoid	CONVT(256,(5, 5), STRIDE=2) Batch normalizati on Relu	ConvT(256, (5, 5), stride=2) ReluLayer 4	ConvT(3, (4, 4), stride= 1) Batch normalization Sigmoid	-	CONVT(128,(5, 5), STRIDE=2) Batch normalizati on Relu	ConvT(1 28, (5, 5), stride=2) ReluLayer 5	-	-	CONVT(3, (5, 5), STRIDE=1) Batch normalizati on SIGMOID	ConvT(64, (5, 5), stride=2) ReluLayer 6	-	-	-	ConvT(1, (5, 5), stride=1) Relu2MNIST images are re-scaled to 32x32 images with a 0 padding.
Table 4: Neural Network used for the classifier in Sec. 5.3	OASIS ClassifierInput Shape	(1, 208,176)Laye r 1	~CONV(8, (3, 3), STRIDE=1)- Batch normalization LeakyRelu MAXPOOL(2, stride=2)Laye r 2	CONV(16, (3, 3), STRIDE=1) Batch normalization LeakyRelu MaxPool(2, stride=2)Laye r 3	Conv(32, (3, 3), STRIDE=2) Batch normalization LeakyRelu MaxPool(2, stride=2)Laye r 4	Conv(64, (3, 3), STRIDE=2) Batch normalization LeakyRelu MaxPool(2, stride=2)Laye r 5	LINEAR(256,100) ReluLaye r 6	LINEAR(100, 2) S oftmax25Under review as a conference paper at ICLR 2022F Dataset Size Sensibility on SVHNIn Figure 10, we show the same plot for SVHN as in Sec. 5.2. Again the proposed method appearsto be part of the most robust generation procedures to dataset size changes.
Table 5: Classification results averaged on 20 independent runs. For the VAEs, the classifier istrained on 2K generated samples per class.
