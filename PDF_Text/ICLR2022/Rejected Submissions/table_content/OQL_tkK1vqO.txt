Table 1: Configuration of three methods used in the ZARTS scheme. The main difference lies in themeaning of function φ(∙): RS follows the traditional gradient estimation algorithms, MGS estimatesthe update according to the improvement of loss function, while GLD uses direct search. Note thatthe ZARTS framework is general and can support more configurations besides the listed ones.
Table 2: Test error (%) with DARTS and its variants ondifferent search spaces. We adopt the same settings as R-DARTS (Zela et al., 2020a). The best and second best isunderlined in boldface and in boldface, respectively.
Table 3: Performance on CIFAR. The top block reports the accuracy of the best model. The bottomblock gives the mean of four independent searches as recommended by (Zela et al., 2020b; Chen &Hsieh, 2020; Yu et al., 2020). Reported by (Dong & Yang, 2019). ? by (Zela et al., 2020b).
Table 5: Comparison of different sampling numbers toapproximate the optimal update for architecture parame-ters on the standard search space of DARTS on CIFAR-10 dataset. For each N, three parallel tests are conductedby searching on different random seeds and the mean andstandard deviation of top-1 accuracy are reported.
Table 7: Comparison with peer methods under the settings of SDARTS. (left) Test error of othermethods are obtained from SDARTS (Chen & Hsieh, 2020), indicating the best performance amongfour replicate experiments with different random seeds. Note that ‘RS’ in SDARTS indicates randomsmoothing technique, while ‘RS’ in ZARTS indicates random search, a zero-order optimizationalgorithm. The best and second best is underlined in boldface and in boldface, respectively. (right)We report the average error and standard deviation of our method among four replicate experiments.
Table 6: Comparison of different iteration numbers toapproximate the optimal operation weights in DARTS’sstandard search space on CIFAR-10. We conduct threeparallel tests for each M and report the mean and stan-dard deviation of top-1 accuracy.
