Table 1: CIFAR-10 - Comparison of different full training schemes: We train WideResNet-28-10 with TRADES-XENT loss (except for MNG-AC which we use as originally proposed) for eachscheme (repeated for 3 seeds), and report the robust accuracy wrt l∞, l2, l1 and the union of thethreat models. Moreover, we show the clean accuracy and the time per epoch of training.
Table 2: CIFAR-10 - 3 epochs of E-AT fine-tuning on lp-robustmodels: We use E-AT to fine-tunemodels robust wrt a single lp -norm for multiple-norm robustness, and report the robust accuracyon 1000 test points for all threat models, and the difference compared to the initial classifier. (*)indicates that additional data is used.
Table 3: ImageNet - Results of one epoch of E-AT fine-tuning of existing robust models: We useexisting models trained to be robust wrt a single lp-ball (either l∞ or l2) from Engstrom et al. (2019)and fine-tune them for a single epoch with our E-AT scheme.
Table 4: Fine-tuning lp-robust models to another threat model: For each norm we fine-tunethe most robust models wrt the other ones for 3 epochs for CIFAR-10 and 1 epoch for ImageNetand report clean and robust accuracy for all threat models. Even for the threat models where therobustness of the original model is low, the fine-tuning is sufficient to yield robustness almost atthe same level of the specialized models with same architecture. For each threat model (column)we highlight in blue the model trained for the specific norm, in orange those only fine-tuned in thetarget norm. The values of the thresholds are the same used the multiple norms experiments.
Table 5: CIFAR-10 - Comparison of different full training schemes for multiple-norm robust-ness on PreAct ResNet-18: For each scheme we report the robust accuracy wrt l∞ , l2 , l1 and theworst case over the union of the threat models. Moreover, we show the clean accuracy and the timeper epoch of training. MSD and MAX perform best in the union, but our E-AT achieves almost thesame robustness in the union but is better in l1 - and l2-robustness and requires only about about athird or half of the training time. (*) indicates the original MSD model from Maini et al. (2020).
Table 6: CIFAR-10 - Comparison of different full training schemes: We repeat the results fromTable 1 and Table 5 with additionally the average robust accuracy over the three threat models (lastcolumn).
Table 7: CIFAR-10 - 3 epochs of fine-tuning with E-AT: We report the results of fine-tuningPreAct ResNet-18 models to become robust wrt the union of the threat models. Fine-tuning any lp -robust model leads to competitive clean and robust accuracy to full training, differently from usinga naturally trained model.
Table 8: CIFAR-10 - Uniform vs biased sampling in E-AT for fine-tuning: We fine-tune with E-AT for 3 epochs the RN-18 robust wrt individual norms with either uniform (E-AT unif.) or biased(E-AT) sampling scheme (mean and standard deviation of the clean and robust accuracy over 5 seedsis reported). The biased sampling scheme is helpful when fine-tuning the l2 and l1 models whichare not robust in the most challenging threat model, i.e. l∞ .
Table 9: CIFAR-10 - Fine-tuning for more epochs: We show the effect of fine-tuning for differentnumber of epochs (3 is the standard we use) the PreAct ResNet-18 (standard or robust wrt l∞).
Table 10: ImageNet - Fine-tuning for more epochs: We fine-tune the l2-robust model fromEngstrom et al. (2019) for either 1 or 3 epochs with our E-AT scheme.
Table 11: CIFAR-10 - Fine-tuning for 1 epoch: We show the effect of fine-tuning for a single(compared to the standard 3) models robust wrt a single norm.
Table 12: CIFAR-10 - Other methods vs E-AT for fine-tuning: We fine-tune with different meth-ods for multiple norms for 3 epochs the RN-18 robust wrt individual norms (mean and standarddeviation of the clean and robust accuracy over 5 seeds is reported). Additionally, we report E-ATwith 6 epochs since it is at least two times faster than MAX and MSD.
Table 13: CIFAR-10 - 3 epochs of E-AT fine-tuning on lp-robust models: We use E-AT to fine-tune models robust wrt a single lp-norm for multiple-norm robustness, and report the robust accuracyon 1000 test points for all threat models, and the difference compared to the initial classifier.
Table 14: CIFAR-10 - Robustness against non lp -bounded attacks: We test the robustness ofWRN-28-10 trained in different threat models against different types of attacks. Moreover, we addthe PAT model from Laidlaw et al. (2021), which uses RN-50 as architecture.
Table 15: MNIST - Comparison of full training schemes and fine-tuning with E-AT for mul-tiple norm robustness: We train classifier (architecture as in Maini et al. (2020)) on MNIST withdifferent training scheme. For SAT and E-AT we report, together with the statistics over multiplerandom seeds, the results of the best run. Additionally, we show the results of fine-tuning the l2-ATmodel with E-AT for different numbers of epochs, which achieves the best results. (*) AVG, MAXand MSD classifiers are those provided by Maini et al. (2020).
