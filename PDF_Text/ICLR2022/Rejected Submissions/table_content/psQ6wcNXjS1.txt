Table 1: Comparison ofFID scores among representative generative models. (*=EBM, f=conditional)CIFAR-10 32 × 32		Celeb-A 64 × 64			Model	FIDModel	FID				Our铲 Miyato et al. (2018) Song & Ermon (2020) Han et al. (2019)*	16.3 5.7 10.2 31.9Our铲 Du et al. (2020)* Grathwohl et al. (2021)* Xie et al. (2018)* Gao et al. (2020a)* Grathwohl et al. (2020)* Du & Mordatch (2019)* Yuetal.(2020a)*f Du & Mordatch (2019)*f	22.1 25.1 27.5 33.6			37.3 38.4	ImageNet 128 × 128		40.6 30.9 37.9	Model	FID		Our铲 Chen et al. (2019) Lee et al. (2021) Miyatoetal. (2018)	38.9 43.9 58.9 65.7Ho et al. (2020) Song & Ermon (2020) Brock et al. (2019) Miyato et al. (2018)	3.2 10.9 14.7 21.7				-Miyatoetal.(2018)f^^ Du & Mordatch (2019)*f	27.6 43.7			above. We use the SNGAN (Miyato et al., 2018) architectures for all models, where EBMs usethe SNGAN discriminator with no normalization. The generator has batch normalization for theCIFAR-10 and Celeb-A experiments only. Table 1 displays the FID scores achieved by our model incomparison with prior methods.
Table 2: Defense vs. whitebox attacks with l∞ perturbation ε = 8/255 for CIFAR-10.
Table 3: Defense vs. l∞ whitebox attacks for ImageNet.
Table 4: FID for 5K samplesafter 100K Langevin and 1MLangevin steps. FID remainsstable over long trajectories.
Table 5: Defense for l∞ against high-power whitebox attacks on ImageNet and on CIFAR-10.
