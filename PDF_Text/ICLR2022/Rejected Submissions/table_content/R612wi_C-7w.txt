Table 1: Comparison between our Resetting Path Integrator model and standard LSTM in theSnakePath environment. When trained without the model losses, both architectures fail to establisha proper resetting strategy, leading to higher error rates when tested on long trajectories (T = 100)than on short ones (T = 5), and the internal state during PI is a linear function of displacementalong the trajectory, rather than of absolute position in the environment as is the case when modellosses are used. Errors bars were estimated from 20 realizations of the training which differ both byinitialization of the network weights, and drawn training trajectories.
Table 2: Comparison of the inverse model performance and the representation regularity betweenmodels trained with or without the direct loss. The addition of the direct loss shifts the distributionof R2 scores between neuron activities and spatial position towards one, meaning it made someneuron activities closer to linear functions of position, which we argue is a desirable property inorder to obtain transferable representations. While this shift is noticeable, it does not come withany appreciable change in inverse model performance. Means and deviations computed across 8realizations.
Table 3: Comparison between the different LSTM variants we considered on the SnakePath environ-ment, in terms of both errors and representation correlation with position, see main text for details.
Table 4: Comparison between our Resetting Path Integrator model and standard LSTM in the Dou-bleDonut environment. As was the case in the SnakePath environment, models trained without thedirect-inverse losses fail to learn how to perform resetting and show lower levels of spatial structurein their representations.
