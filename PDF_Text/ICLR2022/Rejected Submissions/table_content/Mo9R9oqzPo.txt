Table 1: We compute AUC of insertion game with gray infilling as masking explanation. The lasttwo columns are the mask-model consistency conditioned on whether the base classifier predicts theground truth y . The best two of each column are marked bold. From the table, our method withupscaling factor s = 4 achieves the best consistency.
Table 2: Completeness and soundness for each saliency methods, averaged over test samples. Com-pleteness are computed on labels that the model predicts, and soundness are computed on the in-correct labels (w.r.t. model prediction). For soundness, we compute both the average among theincorrect labels and the minimum one among them. Consistency scores are listed in the last columnfor a comparison. The best two of each column are marked bold. Consistency scores are highlycorrelated to completeness/soundness in the table.
Table 3: Consistency scores for different λTV in CIFAR-10. The last two rows are the mask-modelconsistency conditioned on whether the base classifier predicts the ground truth. The best one ineach row is marked bold. λTV = 0.1 performs the best in both situations.
Table 4: Completeness and soundness for a ResNet-164 CIFAR-10 as defined in Equation (8). Eachcolumn contains a tuple (Grey/Noise, TV 0.0/ TV 0.001/ TV 0.01/ TV 0.1). Grey indicates pixelswere greyed during calculation. Noise indicates they were replaced with other images. TV indicatesa TV regularization value of 0.0, 0.001, 0.01, or 0.1.
Table 5: Performance of our method on CIFAR-10 and some baselines on various intrinsic saliencymetrics proposed in prior work. We find that while both our masks (learned with and without TV)have very good performance on the insertion metric. The deletion and saliency metrics are uninfor-mative in this case, since all methods are as good (or worse) compared to a random mask.
Table 6: Completeness and soundness for a ResNet-164 CIFAR-100 as defined in Equation (8).
Table 7: Performance of our method on CIFAR-100 and some baselines on various intrinsic saliencymetrics proposed in prior work. We find that while both our masks (learned with and without TV)have very good performance on the insertion metric. The deletion and saliency metrics are uninfor-mative in this case, since all methods are as good (or worse) compared to a random mask.
Table 8: Completeness and soundness for a ResNet-18 model on ImageNet as defined in Equa-tion (8). Each column contains a tuple (Grey/Noise, TV 0.0/ TV 0.001/ TV 0.01/ TV 0.1). Greyindicates pixels were greyed during calculation. Noise indicates they were replaced with other im-ages. no US indicates the full (224,224) mask was derived. US indicates a (56, 56) mask was derivedthen upsampled by a factor of 4. TV indicates a TV regularization value of 0.0 or 0.01.
Table 9: Performance of our method on ImageNet and ResNet-18 model and some baselines onvarious intrinsic saliency metrics proposed in prior work. We find that while both our masks (learnedwith and without TV) have very good performance on the insertion metric, the mask learned withTV has much better performance on the saliency metric. The deletion metric is uninformative inmost cases, since most methods are as good (or worse) compared to a random mask.
Table 10: Performance of our method on ImageNet and ResNet-50 model and some baselines onvarious intrinsic saliency metrics proposed in prior work. We find that while both our masks (learnedwith and without TV) have very good performance on the insertion metric, the mask learned withTV has much better performance on the saliency metric. The deletion metric is uninformative inmost cases, since most methods are as good (or worse) compared to a random mask.
