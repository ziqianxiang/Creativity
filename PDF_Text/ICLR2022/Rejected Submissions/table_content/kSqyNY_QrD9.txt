Table 3: MRTA - TAPTC Group 2: Performance of CAM, AM and baselines in terms of averagecompletion rate. Bold style indicate the best value for the scenario. Higher the better.
Table 4: MRTA - TAPTC Group 2: Average computation time (in milliseconds) to generate theentire solution for each scenario.
Table 5: CVRP: Comparison of average cost function (and average time 6 Conclusion taken to generate the entire solution). Lower the better.						In this paper, we proposed a new GNN architecture, called CAM, for a multi- robot task allocation problem with a set of complexities, includ- ing tasks with time	# OF Tasks	Avg. Cost Function (Avg. Computing Time)						LKH3	GOOGLE OR	AM	CAM		50	10.53 (46s)	11.3 (2s)	12.3 (0.04s)	12.2 (0.04s)		100	15.58 (60s)	-17.6 (5s)-	17.4 (0.09s)	17.9 (0.09s)		T00	17.69 (86s)	-21.3 (20s)-	21.6 (0.18s)	21.8 (0.17s)		^300	24.87 (123s)	-54.5 (20s)-	34.0 (0.53s)	29.1 (0.53s)		1000-	28.67 (189s)	81.8 (200s)	64.1 (1.51s)	41.6 (1.49s)	deadline and robots with constrained range. This new architecture incorporates an encoder basedon covariant node-based embedding and a decoder based on attention mechanism. A simple RLalgorithm has been implemented for learning the features of the encoder and decoder. In addition, tocompare the performance of the proposed CAM method, an attention-based mechanism approach(aka AM) has been extended to be able to handle a multi-agent CO setting problem, along with arecent state-of-the-art method BiG-MRTA, and a mypoic baseline method Feas-RND. To evaluate theperformance of the proposed CAM architecture and the extended version of AM, they are trainedwith the same settings. All the methods were tested on 100 unseen case studies. Performancewas analyzed in terms of the cost value and the completion rate. Our primary proposition, CAM,outperformed AM and Feas-RND on test scenarios by achieving better cost function value, andwas also able to achieve high task completion rate (> 92%) for even larger sized problems withoutthe need to retrain, which is comparable to the near-optimal (but O(101 - 102) more expensively
Table 6: MRTA: Training algorithm settings for CAM and AM for MRTA-TAPTCI Details	∣ AM ∣ CAMAlgorithm	REINFORCE	REINFORCEBaseline	Rollout	RolloutEpochs	100	100# of tasks	200	200Training samples	10000	10000Baseline samples	1000	1000Optimizer	Adam	AdamLearning step Size	0.0001	0.0001Training frequency	100 SAMPLES	100 SAMPLESTable 7: MRTA - Multi-UAV flood response: Comparison of CAM and AM on completion rate.
Table 7: MRTA - Multi-UAV flood response: Comparison of CAM and AM on completion rate.
Table 8: MRTA - Multi-UAV flood response: Ablation studies. The performance is comparedwith respect to the average cost function of 100 testing scenarios (with % task completion rate).
Table 9: MRTA - TAPTC: Settings for model training for all CAM models and AMDetails	ValuesAlgorithm	REINFORCEBaseline	RolloutEpochs	100# of tasks	100Training samples	500,000Baseline samples	10,000Optimizer	AdamLearning step size	0.0001Training frequency	500 SAMPLESF.4 Result and DiscussionsTables 3 and 10 summarize the performance of CAM alongside the baseline methods, in terms ofthe average completion rate, i.e, the ratio of the number of successfully completed tasks to the totalnumber of tasks averaged over 3 samples for all the scenarios (denoted by A and R). The CAMmodel here uses k = 9, where k represents the number of nearest neighbors considered for a nodefor computing its node embedding. For group 1, the CAM model was able to generate the bestresults for 8 out of the 16 different scenarios (Table 10). From Table 10, it can be inferred that CAMhas a superior performance compared to the baselines for cases with larger number of robots (bestperformance for all cases with A = 7, and for 3 out of 4 scenarios with A = 5), including a maximum
Table 10: MRTA - TAPTC Group 1: Performance of CAM, AM and baselines in terms of averagecompletion rate. Bold font values indicate the best performer for the corresponding scenario. Higherthe better.
Table 11: MRTA - TAPTC Group 1: Average computation time (in milliseconds) to generate theentire solution for each scenario.
Table 12: MRTA - TAPTC Group 1: Comparison of performance (average completion rate) of CAMmodels with varying neighborhood size (k). Higher the better.
Table 13: MRTA - TAPTC Group 2: Comparison of performance (average completion rate) of CAMmodels with varying neighborhood size (k). Higher the better.
Table 14: CVRP: Training algorithm settings for CAM and AM for CVRPI Details	∣ AM ∣ CAMAlgorithm	REINFORCE	REINFORCEBaseline	Rollout	RolloutEpochs	100	100# of tasks	100	100Training samples	20000	20000Baseline samples	1000	1000Optimizer	Adam	AdamLearning step size	0.0001	0.0001Training frequency	100 SAMPLES	100 SAMPLESG.3 Baseline details for CVRPLin-Kernighan heuristics (LKH3): We performed a single run with a maximum number of trailsas 10000.
Table 15: The capacity of the vehicle for different test scenarios# of Tasks	Capacity (C)50	40100	50200	100500	2501000	500The dataset used for training CVRP consists of scenarios with 100 locations and one depot. Thex and y coordinates of the locations (including the depot) are randomly generated from a uniformdistribution within the limits [0, 1]. The demand for all task locations will be a random integer froma uniform distribution between [1,9], with depot assigned a 0 demand. The vehicle capacity (C)25Under review as a conference paper at ICLR 2022for a scenario with 100 locations, is considered as 50. The dataset used for testing (to analyze bothgeneralizability and scalibility) has the same limits as explained above. The assumed capacity of thevehicle for test scenarios of different number of locations are shown in Table 15.
Table 16: Abbreviations used in this paperCAM	Covariant-Attention based ModelCCN	Covariant Compositional NetworksCO	Combinatorial OptimizationCVRP	Capacitated Vehicle Routing ProblemEILS	Enhanced Iterated Local SearchGNN	Graph Neural NetworkID	In-schedule DependenciesILP	Integer Linear ProgrammingILS	Iterated Local SearchINLP	Integer Non-Linear ProgrammingMDP	Markov Decision ProcessMHA	Multi-Head AttentionMR	Multi-RobotMRTA	Multi-Robot Task AllocationmTSP	multi-Traveling Salesman ProblemRL	Reinforcement LearningSR-ST	Single-Robot task Single Task robotTAPTC	Task Allocation Problem with Time and CapacityTSP	Traveling Salesman problem
