Table 2: Attack success rate (%) of targetmodels against AutoAttack with different attackradii, in a similar format as Table 1.
Table 1: Attack success rate (%) of target mod-els against 40-step PGD attack with differentradii and the clean accuracy (“clean acc”).
Table 3: Results of adversarial training for dif-ferent models using PGD-7 (7-step PGD attack)and TRADES respectively on CIFAR-10. ViT-B/4 is a variant of ViT-B/16 where we down-sample the patch embedding kernel from 16×16to 4 × 4 to accommodate the smaller image sizeon CIFAR-10. We report the clean accuracy (%)and robust accuracy (%) evaluated with PGD-10 and AutoAttack respectively. Each model istrained using only 20 epochs to reduce the cost.
Table 4: Frequency study and the ASR (%) of the target models against PGD attack. In the “Low-pass” column, only low-frequent adversarial perturbations are preserved and added to the inputimages. In the “High-pass” column, only high-frequent perturbations can pass through the filter.
Table 5: Comparison of the target models investigated in the main text.
Table 6: Robust accuracy of ViT-B/4 and WideResNet against PGD-10 attack with different attackradii.
Table 7: SOTA ViT models investigated in our experiments.
Table 8: Robust accuracy (%) of ViTs described in Table 7 against 40-step PGD attack with differentattack radii, and also the clean accuracy (“Clean”). A model is considered to be more robust if therobust accuracy is higher.
Table 9: Robust accuracy (%) of ViTs described in Table 7 against AutoAttack with different attackradii, and also the clean accuracy (“Clean”). A model is considered to be more robust if the robustaccuracy is higher.
Table 10: Robust accuracy (%) against AFef under the default setting described in Alaifari et al.
