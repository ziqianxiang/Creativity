Table 1: Quantitative comparison of DT-GAN with baseline image synthesis methods using FIDand KID. Note that the reported values are not comparable between columns, because they werecalculated on different training sets.
Table 2: Quantitative comparison of the baseline methods on defect classification task at the scaleof 12000 images/class. The reported values are the achieved error rates (%) over five runs.
Table 3: Experimental results on using different amount of synthetic images generated by DT-GANto train classifiers. The left-most column stands for number of samples per class to be classified.
Table 4: Cross-domain effect on single product classifiers trained with reference-guided syntheticimages at the scale of 12000 images/class.
Table 5: DistribUtion of the full SDI dataset.
Table 6: The training set for DT-GAN andthe baseline image synthesis methods.
Table 7: The training, validation and test set for classifier training, where N increasesincrementally—1500, 2200, 4000 and 6200.
Table 8: Classification results with regard to the synthetic images generated from the two subnet-works and the mixture set.__________________________________________________________Dataset Size	All				Trad-Aug	Latent	Reference	Mix4500	12.75±0.61	10.72±0.96	11.48±0.88	11.04±0.766600	13.07±1.57	10.34±1.86	11.55±1.64	10.60±0.4812000	12.05±0.81	9.90±1.26	10.40±0.99	9.90±0.6918600	12.37±0.32	11.04±1.26	12.12±0.75	10.21±0.96Frechet inception distance (FID) and Kernel inception distance (KID). We used the featurevectors from the last average pooling layer of the ImageNet pretrained Inception-V3 to calculateboth scores. For each test image from the Normal domain, we translated it into a synthetic defectiveimage of each defect domain. The style codes and contents for the translation were acquired in twoways: by randomly sampling from the standard normal distribution and by randomly sampling areference image from the train set of a defect domain. To calculate the FID and KID score, wegenerated 4000 defective samples per product per defect domain for each way of guidance, andformed the mixture set by randomly sampling 2000 images per product per defect domain fromeach way. The reported FID and KID scores were then computed between the defective images inthe training set and the mixture set of synthetic defective images. The same procedure was appliedwhen computing scores on single product subsets of the SDI dataset. For example, for product A,we calculated the scores between the defective image of product A in the training set and the mixture
Table 9: Generator architecture. (a) Encoder			Layer	Resample	Norm	Output ShapeImage x		-	128 X 128 X 3Conv 1×1	-		-	128 X 128 X 128ResBlk	AvgPool	IN	64 X 64 X 256ResBlk	AvgPool	IN	32 X 32 X 512ResBlk	AvgPool	IN	16 X 16 X 512ResBlk	-	IN	16 X 16 X 512ResBlk	-	IN	16 X 16 X 512	(b) Background Decoder		(c) Foreground DecoderLayer	Resample Norm Output Shape	Layer	Resample Norm Output ShapeInput	-	-	16 X 16 X 448	Input	-	-	16 X 16 X 64ResBlk	-	IN	16 X 16 X 448	ResBlk	-	AdaIN 16 X 16 X 64ResBlk	-	IN	16 X 16 X 512	ResBlk	-	AdaIN 16 X 16 X 256ResBlk	-	IN	16 X 16 X 512	ResBlk	-	AdaIN 16 X 16 X 256ResBlk	Upsample IN 32 X 32 X 512	ResBlk	Upsample AdaIN 32 X 32 X 256ResBlk	Upsample IN 64 X 64 X 256	ResBlk	Upsample AdaIN 64 X 64 X 128ResBlk	Upsample IN 128 X 128 X 448	ResBlk	Upsample AdaIN 128 X 128 X 64(d) Fusion			Layer	Resample	Norm	Output Shape
Table 11: Style-content encoder and discriminator architectures.
Table 12: Quantitative results for DT-GAN as a data augmentation method to train general and singleproduct classifiers. The left-most column indicates the number of samples per class, including allimages from the training set plus increasing amounts of synthetic images. In the first row, 20A refersto the case of 20 real defective samples for product A, while All refers to the full training set.
Table 13: Cross-domain effect on single product classifiers trained with reference-guided syntheticimages at all scales. Note that here A, B and C stand for 3 products in the SDI dataset while vA, vB,VC and VABC indicate the defects are copied from which reference set.
Table 14: Quantitative comparison of DT-GAN with baseline image synthesis methods using FIDand KID. Note that the reported values are not comparable between columns, because they arecalculated on different training sets. The scores of StarGAN v2 on single products are omittedbecause generating images with specified background is not possible due to its network design.
Table 15: Ablation study with regard to FID and KID scores.
Table 16: Quantitative comparison of DT-GAN with baseline image synthesis methods using FIDand KID. Note that the reported values are not comparable between columns, because they werecalculated on different training sets.
Table 17: Overview of our formation of the MVTec Anomaly Detection sub-dataset. The firstcolumn represents the original defect types in the MVTec Anomaly Detection dataset while the firstrow stands for the defect types in our targeted scenario. We list the ID of samples we took from theMVTec Anomaly Detection dataset and show the number of samples in row Sum.
