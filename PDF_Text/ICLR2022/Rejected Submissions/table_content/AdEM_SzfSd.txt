Table 1: Test accuracies on miniImagenet in the 5-way setting for both 1-shot and 5-shot4.3	Implementation DetailsWe follow the same setting as other few-shot learning models (Vinyals et al. (2016); Snell et al.
Table 2: Design choinces for the ICNN Loss function using a ConvNet and ResNet-12 as featureextractors and 5-way tasks on both 1-shot and 5-shot settingsModel	Backbone	1-shot	5-shotProto-Triplet	ConvNet	48.85	67.79Cross Entropy + Proto-Triplet	ConvNet	41.66	66.09Proto-Triplet + Full ICNN	ConvNet	46.00	62.72Cross-Entropy + Proto-Triplet + Full ICNN	ConvNet	49.82	68.76Proto-Triplet	ResNet-12	60.87	78.78Cross Entropy + Proto-Triplet	ResNet-12	60.09	79.33Proto-Triplet + Full ICNN	ResNet-12	59.58	78.53Cross-Entropy + Proto-Triplet + Full ICNN	ResNet-12	61.32	79.93Table 3: Design choinces for the Proto-Triplet Loss function using a ConvNet and ResNet-12 asfeature extractors and 5-way tasks on both 1-shot and 5-shot settingsWhen using a ConvNet as the feature extractor, our method achieves an improvement of 8.8% overthe baseline (Chen et al. (2019b)), 5.3% over the Matching Networks (Vinyals et al. (2016)) and0.4% over the base prototypical Networks for the 5-way 1-shot setting. For the setting of 5-way5-shot, we achieve an improvement of 13.4% over the Matching Networks, 3.4% over the RelationNetworks and 0.5% over the prototypical networks.
Table 3: Design choinces for the Proto-Triplet Loss function using a ConvNet and ResNet-12 asfeature extractors and 5-way tasks on both 1-shot and 5-shot settingsWhen using a ConvNet as the feature extractor, our method achieves an improvement of 8.8% overthe baseline (Chen et al. (2019b)), 5.3% over the Matching Networks (Vinyals et al. (2016)) and0.4% over the base prototypical Networks for the 5-way 1-shot setting. For the setting of 5-way5-shot, we achieve an improvement of 13.4% over the Matching Networks, 3.4% over the RelationNetworks and 0.5% over the prototypical networks.
