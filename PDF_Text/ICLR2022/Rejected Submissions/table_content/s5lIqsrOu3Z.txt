Table 1: Quantitative comparison on MNIST and CIFAR-10. Average Inception scores (IS) (Salimans et al.,2016) and FID scores (HeuSel et al., 2017). â†‘ means higher is better. ] means lower is better.
Table 2: Comparison on CIFAR-10 and STL-10. Comparison with more existing methods and on ImageNetcan be found in Table 13 in the Appendix.
Table 3: Classification accuracy on MNIST, comparing to classifier based VAE methods (Parmar et al., 2021).
Table 4:	Decoder for MNIST.
Table 5:	Encoder for MNIST.
Table 6:	Decoder for CIFAR-10.
Table 7:	Encoder for CIFAR-10.
Table 8:	Decoder for STL-10.
Table 9:	Encoder for STL-10.
Table 10:	Decoder for CelebA-128,LSUN-bedroom-128, and ImageNet-128.
Table 11:	Encoder for CelebA-128, LSUN-bedroom-128, andImageNet-128.
Table 12: ID and correspond category for 10 classes of ImageNetID	Categoryn02930766	cab, hack, taxi, taxicabn04596742	wokn02974003	car wheeln01491361	tiger shark, Galeocerdo cuvierin01514859	henn09472597	volcanon07749582	lemonn09428293	seashore, coast, seacoast, sea-coastn02504458	African elephant, Loxodonta africanan04285008	sports car, sport carA.2 MNISTSettings. On MNIST dataset, we train our model using DCGAN (Radford et al., 2015) architecturewith our proposed models LDR-Multi (11) and LDR-Binary (12). We set the learning rate to 10-4,batch size to 2048, and training 15,000 iterations. Due to the advantages of the LDR objective, wecan achieve between-class discriminative representations while the within-class diversity of theserepresentations can be preserved, which are shown in the following experimental results.
Table 13: Comparison on CIFAR-10, STL-10, and ImageNet.
