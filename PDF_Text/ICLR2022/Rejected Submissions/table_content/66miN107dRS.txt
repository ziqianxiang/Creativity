Table 1: Comparison with representative CL methods. K and Mdenotes the number of positive and negative samples, respectively.
Table 2: The linear classification accuracy (%) of different contrastive objectives on small-scale datasets,pretrained on regular and label-imbalanced CIFAR10/100 with AlexNet backbone. “Linear” and “Exponentional”indicate the number of samples in each class are chosen by following a linear rule or an exponential rule,respectively. The performance drops compared with the performance in regular CIFAR data are shown next toeach result.__________________________________________________________________________________Label imbalance	Regular	Linear	ExponentialDataset	CIFAR-10 CIFAR-100	CIFAR-10 CIFAR-100	CIFAR-10 CIFAR-100SimCLR (CL)	83.47	55.41	79.883.5” 52.293.57j	71.74ii.73j 43.29i2.57jAU-CL	83.49	55.31	80.253.i4j 52.742.57j	71.6211.76j 44.38i0.93jHN-CL	83.67	55.87	80.5l3.i5j 52.723.i4j	72.74io.93j 45.13io.73jCACR (K = 1)	83.73	56.52	80.463.27j 54.122.40j	73.02io.7ij 46.599.93jCMC (K = 4)	85.54	58.64	82.203.34j 55.383.26j	74.77io.77j 48.879.77 jCACR (K = 4)	86.54	59.41	83.622.92j 56.9l2.50j	75.89io.65j 50.179.24j——-H(Linlf)——H(CL)-'M(AU-CL)75 IOO 125 150 175 200Epoch---H(unlf)	--- MHN-CL)---H(CL)	——MCACR(K=I))
Table 3: Top-1 classification accuracy (%) compari-son with SOTAs, pretrained with ResNet50 encoderon ImageNet-1K dataset. We mark Top-3 best resultsin bold and highlight CL methods.
Table 4: Top-1 classification accuracy (%) onImageNet-1K, with the pre-trained ResNet50 on large-scale regular (200 epochs) and label-imbalanced(100/20 epochs) datasets. The performance drops areshown next to each result.
Table 5: Results of transferring features to object detection and segmentation task on Pascal VOC, with thepre-trained ResNet50 on ImageNet-1k. Contrastive learning methods are highlighted.
Table 6: The top-1 classification accuracy (%) of different contrastive objectives with SimCLRframework on small-scale datasets. All methods follow SimCLR setting and apply AlexNet encoderand trained with 200 epochs.
Table 7: The top-1 classification accuracy (%) of different contrastive objectives with SimCLRframework on small-scale datasets. All methods follow SimCLR setting and apply a ResNet50encoder and trained with 400 epochs.
Table 8: Linear classification performance (%) of different variants of conditional probability. Thisexperiment is done on CIFAR-10, with K = 4 and mini-batch size M = 128.
Table 9: Linear classification performance (%) of different variants of our method. “CACR” representsthe normal CACR configuration, “w/o ∏+ ” means without the positive conditional distribution, “w/oπθ- ” means without the negative conditional distribution. “UAUR” indicates the uniform cost (see themodel we discussed in Equation 11), i.e. without both positive and negative conditional distribution.
Table 10: The top-1 classification accuracy (%) of different contrastive objectives with differenttraining epochs on small-scale datasets, following SimCLR setting and applying the AlexNet-basedencoder.______________________________________________________________________________________Dataset	Trained with 400 epochs				Trained with 200 epochs		CL	AU-CL HN-CL CACR(K=1)			CMC(K=4) CACR(K=4)	CIFAR-10	83:61	83.57	83.72	83.86	85.54	86.54CIFAR-100	55.41	56.07	55.80	56.41	58.64	59.41STL-10	83.49	83.43	82.41	84.56	84.50	85.59used per iteration is not greater than those used when K = 1. To further justify if the performanceboost comes from seeing more samples when using multiple positive pairs, we also let the methodsallowing single positive pair train with double epochs. As shown in Table 10, we can observe eventrained with 400 epochs, the performance of methods using single positive pair still have a gap fromthose using multiple positive pairs.
Table 11: GPU time (s) per iteration of CACR w.r.t. different K on CIFAR-10 with AlexNet framework(mini-batch size is 128), tested on Tesla-v100 GPU.
Table 12: The classification accuracy(%) of CACR (K = 4, M = 128) with different hyper-parameters t+ on small-scale datasets.
Table 13: The classification accuracy(%) of CACR (K = 1, M = 768) and CACR (K = 4, M128) with different hyper-parameters t- on small-scale datasets.
Table 14: Comparison with contrastive learn-ing methods: Top-1 classification accuracy (%)of different contrastive learning objectives onMoCo-v2 framework and ResNet50 encoder,pretrained on ImageNet-1K dataset with 200epochs. The results from paper or Github pageare marked by ?.
Table 15: Comparison with state-of-the-arts onlinear probe classification accuracy, pretrainedwith different epochs, using ResNet50 encoderbackbone on ImageNet-1k.
Table 16: GPU time (s) per iteration of different loss on MoCoV2 framework, tested on 32G-V100 GPUMethods	CL	AU-CL	HN-CL CACR(K=1) CL (K=4) CACR(K=2) CACR(K=3) CACR(K=4)					Batch size M	25^^	256	256	256	64	128	64	64# samples (KxM) / iteration	256	256	256	256	256	256	192	256GPU time (s) / iteration	0.837	0.840	0.889	0.871	3.550	0.996	1.017	1.342B.5 Connection to other representation learning methodsResults of different cost metrics23Under review as a conference paper at ICLR 2022Recall that the definition of the point-to-point cost metric is usually set as the quadratic Euclideandistance:c(fθ (χ),fθ (y)) = llfθ (X)- fθ (y)ll2.
Table 17: The classification accuracy (%) of CACR (K = 1) and CACR (K = 4) with different costmetrics on CIFAR-10, CIFAR-100 and STL-10. Euclidean indicates the cost defined in 12, and RBFindicates the Cost metrics defined in13.__________________________________________________Methods	CostMetricICIFAR-10 CIFAR-100 STL-10			CACR(K = 1)	Euclidean	83.73	56.21	83.55	RBF	83.08^^	55.90	84.20CACR(K = 4)	Euclidean	85.94	59.41	85.59	RBF	86.20^^	58.81	85.80Discussion: Relation to triplet loss CACR is also related to the widely used triplet loss (Schroffet al., 2015; Sun et al., 2020b). A degenerated version of CACR where the conditional distributionsare all uniform can be viewed as triplet loss, while underperform the proposed CACR, as discussed inSection B.2. In the view of triplet loss, CACR is dealing with the margin between expected positivepair similarity and negative similarity:LCACR = [Eπt+ (x+∣x)[c(x, x+)] - Ent- (x-|x)[c(x,x-)] + m] +which degenerates to the generic triplet loss if the conditional distribution degenerates to a uniformdistribution:LUAUR = [Ep(x+) [c(x, x+)] - Ep(x-) [c(x, x-)] + m]+ = [c(x,x+) - c(x, x-) + m]+This degeneration also highlights the importance of the Bayesian derivation of the conditionaldistribution. The experimental results of the comparison between CACR and the degenerated uniformversion (equivalent to generic triplet loss) are presented in Table 9.
Table 18: The 100 randomly selected classes from ImageNet forms the ImageNet-100 dataset. Theseclasses are the same as (Wang & Isola, 2020; Tian et al., 2019).
