Table 1: Mean and std. over 5 runs on classical control tasks (with number of training environmentsteps). Bold denotes the best mean. Underline denotes good results (if exist), statistically indifferentfrom the best in terms of Cohen effect size less than 0.5.
Table 2: Mean and std. over 5 runs on 6 Mujoco tasks at 10M environment steps.
Table 3: Features of the context vector.
Table 4: Network architecture shared across baselines.
Table 5: Tasks used in the paper.
Table 6: Network architecture shared across baselines on Pendulum, LunarLander, BipedalWalker,MiniGrid and BipedalWaker HardcoreModel	Speed (env. steps/s)MCPO (N=5)	17170MCPO (N=10)	927MCPO (N=40)	560PPO	1,250Table 7: Computing cost of MCPO and PPO on Pendulum.
Table 7: Computing cost of MCPO and PPO on Pendulum.
Table 8: Signature hyperparameters used in MiniGrid tasks.
Table 9: Network architecture shared across baselines on Mujoco and Atarithat share the same total rank, we prefer the middle value. The other hyperparameters for this taskis listed in Table 6.
Table 10: Signature hyperparameters used in Atari tasks.
Table 11: Average normalized human score over 6 games. For each model, the performance of eachrun is measured by the best checkpoint during training over 10 million frames, then take averageover 5 runs.
Table 12: Average normalized human score over 9 games. For each model, the performance of eachrun is measured by the best checkpoint during training over 10 million frames, then take averageover 5 runs.
