Table 1: Top-1 exact match (EM) accuracy on the abstract benchmark with and without pre-training.
Table 2: Top-1 exact match (EM) accuracy on the concrete benchmark with and without pre-training.
Table 3: Comparison of the edit sequence length between JSON differencing and grammar-awaredifferencing algorithms.
Table 4: A trade-off between the accuracy and bug detection coverage.
Table 5: Effects of the graph model size and pre-training on Graphix.
Table 6: Role of the multi-head architecture when the dimension d and the number of heads H vary.
Table 7: Effects of the per-layer Versus last-layer multi-head architectures.								Head type	H	Agg.	d	Size	Abstract Small^^Medium		Concrete Small Medium	Single-head	1	N/A	256	4M	14.94%	7.07%	16.58%	7.79%Last-layer MH	4	Concat	128	4M	15.37%	7.88%	16.79%	8.34%Per-layer MH	8	AVerage	256	6M	15.78%	7.40%	16.18%	7.93%Last-layer MH (Graphix)	8	Concat	256	32M	18.20%	9.19%	17.87%	9.01%We can see this model performs slightly better than the single-head model thanks to the additionalmulti-head layers across the datasets, but it is worse than GRAPHIX with 4 heads at the end and 2Mfewer parameters, except for the abstract, small dataset. Along with the preVious empirical study onthe width, this experiment demonstrates the benefits of the proposed multi-head architecture oVerpurely increasing the graph neural networkâ€™s depth or width.
