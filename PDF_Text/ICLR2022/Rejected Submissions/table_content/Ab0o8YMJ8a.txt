Table 1: Top 1 ImageNet accuracy and FLOPs for for EfficientNet B0 and B1 pruned(a) B0 prunedModel	Standard training	B0 teacher	B1 teacher (after using B0 first)	FLOPs (G)original	77.30	-	-	0.393m6	-	73.49	73.72	0.156m8	-	74.88	75.00	0.197m10	-	76.01	76.56	0.248m12	-	76.54	77.30	0.299NPRR Hou et al. (2021)	-	77.00	-	0.346(b) B1 prunedModel	Standard training	B1 teacher	B2 teacher (after using B1 first)	FLOPs (G)original	79.10	-	-	0.700m12	-	77.02	76.99	0.299m14	-	77.26	77.74	0.348m16	-	77.66	78.35	0.400272273274275276
Table 2: Top 1 ImageNet accuracy and FLOPs for MobileNetV2 pruned9.9.Oiai7.7.&7 7 7 7 7 7 7IBNBOeE-UO A<Jgn<J<Je【a归(b) EfficientNet B1 prunedModel	Standard training	MobileNetV2 teacher	B0 teacher (after using MobileNetV2 first)	FLOPs (G)original	71.52	-	-	0.301m5	-	67.58	67.99	0.135GSPE Ye et al. (2020)	68.8	-	-	0.138m6	-	67.08	68.76	0.140META Liu et al. (2019b)	68.2	-	-	0.140GFP Liu et al. (2021a)	69.16	-	-	0.150GSPE Ye et al. (2020)	69.7	-	-	0.152m7	-	69.79	70.05	0.170GSPE Ye et al. (2020)	70.4	-	-	0.170m8	-	69.47	71.28	0.199GSPE Ye et al. (2020)	71.2	-	-	0.201GSPE Ye et al. (2020)	71.6	-	-	0.220m9	-	70.92	72.22	0.228309 When it comes to EfficientNetV2, we are able to outperform the original model’s results on ImageNet with
Table 3: Top 1 ImageNet accuracy and FLOPs for EfficientNetV2 B0 prunedModel	Standard training	B0 teacher	hierarchical teachers	FLOPs (G)original	78.67	-	-	0.722m20	-	77.59	78.93	0.506m17	-	77.25	78.37	0.431m15	-	76.70	77.64	0.379m12	-	75.59	76.36	0.299319320321322323324325326327328329330331
Table 4: Pruning results for image denoising and human segmentation.
