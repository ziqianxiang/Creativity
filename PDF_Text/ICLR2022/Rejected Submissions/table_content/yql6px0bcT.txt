Table A.2: Best Hyper-ParameterTotal Population Size100	200	500	1000CEM-GMM	M	= 10	M	=8	M	=8	M	=8	κ=	0.25,	κ=	0.5	κ=	0.25	κ=	0.5	r=	‘m’	r=	‘m’	r=	‘m’	r=	‘s’DecentCEM	E	10	E 二	10	E	10	E=	8Table A.3: Total Time of 10 RUns (in Seconds)	Total Population Size				100	200	500	1000CEM	0.079	0.093	0.165	0.318CEM-GMM	7.322	11.500	24.431	59.844DecentCEM	0.407	0.420	0.506	0.545A.2 Output of CEM ApproachesIn terms of the oUtpUt of CEM approaches, there exist different options in the literatUre. The mostcommon option is to retUrn the sample in the domain that corresponds to the highest probabilitydensity in the final sampling distribUtion. It is the mean in the case of GaUssian and the modewith the highest probability density in the case of GMM. One can also draw a sample from thefinal sampling distribUtion (Okada & TanigUchi, 2020) and retUrn it. Another option is to retUrn thebest sample observed (Pinneri et al., 2020). The best option among the three may be application
Table A.3: Total Time of 10 RUns (in Seconds)	Total Population Size				100	200	500	1000CEM	0.079	0.093	0.165	0.318CEM-GMM	7.322	11.500	24.431	59.844DecentCEM	0.407	0.420	0.506	0.545A.2 Output of CEM ApproachesIn terms of the oUtpUt of CEM approaches, there exist different options in the literatUre. The mostcommon option is to retUrn the sample in the domain that corresponds to the highest probabilitydensity in the final sampling distribUtion. It is the mean in the case of GaUssian and the modewith the highest probability density in the case of GMM. One can also draw a sample from thefinal sampling distribUtion (Okada & TanigUchi, 2020) and retUrn it. Another option is to retUrn thebest sample observed (Pinneri et al., 2020). The best option among the three may be applicationdependent. It has been observed that in many applications, the seqUence of sampling distribUtionsnUmerically converges to a deterministic one (De Boer et al., 2005), in which case the first twooptions are identical.
Table B.1: The setup of the environments. The number in the bracket in the “Environment Name”column denotes the source of this environment: [1] refers to the benchmark paper from Wang et al.
Table B.2: Reward Functions. dt denotes the vector between the end effector to the target position.
Table D.1: Random Seed. The set {1,2,3,4,5} refers to the seeds for five runs. Note that we controlthe random seed for the environments since there is a random number generator in openai gymenvironments independent from other sourcesSource of randomness	Random Seeddeep learning framework (tensorflow in our case)numpy	{1,2,3,4,5 }Python random modulethe training environment	1234the evaluation environment	0D.2 HyperparametersThis section includes the details of the key hyperparameters used in the proposed DecentCEM al-gorithm (Table D.5) and the baseline algorithms PETS (Table D.3), POPLIN (Table D.4) and SAC6(Table D.2). For the neural network architecture for the dynamics model, the DecentCEM methodsexactly follow the original one in PETS and POPLIN for a fair comparison, which is an ensembleof fully connected networks.
Table D.2: Hyperparameters of SACParameter	ValueActor learning rate Critic learning rate Actor network architecture Critic network architecture	0.0001 0.0001 [dim(observation), 64, 64, 2× dim(action)] [dim(observation)+dim(action), 64, 64, 1]Table D.3: Hyperparameters of PETSParameter	ValueModel learning rate	0.001Warmup episodes	1Planning Horizon	30CEM population size	500 (except in PETS-reacher3D: 400)CEM proportion of elites	10%CEM initial distribution variance	0.25CEM max number of internal iterations	56Our SAC implementation used network architectures that are similar to the policy network in our method.
Table D.3: Hyperparameters of PETSParameter	ValueModel learning rate	0.001Warmup episodes	1Planning Horizon	30CEM population size	500 (except in PETS-reacher3D: 400)CEM proportion of elites	10%CEM initial distribution variance	0.25CEM max number of internal iterations	56Our SAC implementation used network architectures that are similar to the policy network in our method.
Table D.4: Hyperparameters of POPLINA and POPLINPParameter	ValueModel learning rateWarmup episodesPlanning HorizonCEM population sizeCEM proportion of elitesCEM initial distribution varianceCEM max number of internal iterationsPolicy network architecture (A)Policy network architecture (P)Policy network learning ratePolicy network activation function0.001130500 (except in PETS-reacher3D: 400)10%0.255
Table D.5: Hyperparameters of the proposed DecentCEM-A/PParameter	ValueModel learning rateWarmup episodesPlanning HorizonEnsemble SizeCEM population size in each instanceCEM proportion of elitesCEM initial distribution varianceCEM max number of internal iterationsPolicy network architecture (A)Policy network architecture (P)Policy network learning ratePolicy network activation function0.0011305100 (except in PETS-reacher3D: 80)10%
