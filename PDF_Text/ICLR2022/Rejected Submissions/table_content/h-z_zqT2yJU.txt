Table 1: The Performance Degradation Problem.
Table 2: The Ssharpness of different models with temperature set to one.
Table 3: CIFAR-100 experiments.
Table 4: ImageNet experiments with Top1 accuracy.
Table 5: Performance Degradation Problem on CIFAR-100. Student is ResNet14. ATKD archiveslower training loss and higher accuracy. The Gs_gap between the distilled student and teacher is alsoreduced significantly. Temperature is set to 4 in vanilla KD.
Table 6: Performance Degradation Problem on ImageNet.
Table 7: The Ssharpness of Early Stopped models, temperature set to 1.
Table 8: Experiments of different fixed temperaturesτT	4	4	4	4	4	ATKDτS	3.5	3.7	4	4.3	4.5	ATKDAccuracy	68.27	68.11	68.06	68.22	68.30	69.0S s-gap	0.23	0.25	0.30	0.35	0.37	0.19τT	3.5	3.7	4	4.3	4.5	5τS	4	4	4	4	4	4Accuracy	67.79	68.01	68.06	68.10	68.07	68.01S s-gap	0.40	0.33	0.30	0.27	0.24	0.21Table 9: Experiments varies with width	WRN-16-2		WRN-16-3	WRN-16-4	WRN-16-5	WRN-16-6Test acc	Vanilla KD	68.22	67.88	68.27	67.80	67.2	ATKD	69.39	69.33	69.39	69.40	69.21Gs_gap	Vanilla KD	0.37	0.49	0.59	0.71	0.83	ATKD	0.10	0.22	0.34	0.41	0.55A.3 Entropy Score of ModelsEntropy was used as confidence score at Pereyra et al. (2017), that is related to the sharpness ofmodel output. We measured the entropy values of different models (Table 10). Experimental detailsfollow the setting in section 3.
Table 9: Experiments varies with width	WRN-16-2		WRN-16-3	WRN-16-4	WRN-16-5	WRN-16-6Test acc	Vanilla KD	68.22	67.88	68.27	67.80	67.2	ATKD	69.39	69.33	69.39	69.40	69.21Gs_gap	Vanilla KD	0.37	0.49	0.59	0.71	0.83	ATKD	0.10	0.22	0.34	0.41	0.55A.3 Entropy Score of ModelsEntropy was used as confidence score at Pereyra et al. (2017), that is related to the sharpness ofmodel output. We measured the entropy values of different models (Table 10). Experimental detailsfollow the setting in section 3.
Table 10: Logits EntropyResNet14	ResNet20	ResNet32	ResNet44	ResNet56	ResNet1100.97	0.74	0.45	0.35	0.22	0.09A.4 Sharpness Gap During TrainingFigure 2 shows the sharpness gap changes during the training. ResNet20 and WRN-16-1 are usedas students, and ResNet56 and WRN-16-3 are used as teachers respectively.
Table 11: Experiments on SVHNTeacher acc		ResNet20 96.40	ResNet32 96.68	ResNet44 96.73	ResNet56 96.89Test acc	Vanilla KD	96.57	96.54	96.61	96.59	ATKD	96.70	96.83	96.73	96.77G s_gap	Vanilla KD	0.05	0.05	0.07	0.07	ATKD	0.03	0.04	0.04	0.04Where pj is the jth class probability of the student and the qj is the probability of the teacher. Wecan get the gradient to P zj by adding these gradients:∂LX 豆=X (Pj- qj ) = 1-1 = 0	(17)jjjTherefore, the gradient to the sum of logits is zero.
Table 12: The value of P zj	ResNet20	ResNet32	ResNet44	ResNet56	ResNet110Logits Sum	-5e-5	-4.7e-5	-5.7e-5	-7.9e-4	-6.1e-5	WRN-16-1	WRN-16-2	WRN-16-3	WRN-16-4	VGG13Logits Sum	-4.8e-5	-6.1e-6	-5.5e-5	-1.2e-5	-3.1e-5Table 13: Mean Value of Adaptive TemperaturesResNet14	ResNet20	ResNet32	ResNet44	ResNet56	ResNet1103.34	3.43	3.49	3.58	3.71	3.8712Under review as a conference paper at ICLR 2022A.7 The Adaptive TemperaturesWe provide the mean value of the temperatures in table 13.
Table 13: Mean Value of Adaptive TemperaturesResNet14	ResNet20	ResNet32	ResNet44	ResNet56	ResNet1103.34	3.43	3.49	3.58	3.71	3.8712Under review as a conference paper at ICLR 2022A.7 The Adaptive TemperaturesWe provide the mean value of the temperatures in table 13.
