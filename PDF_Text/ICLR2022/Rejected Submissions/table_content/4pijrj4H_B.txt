Table 1: Comparative Results with Baselines on Node Classification	Pokec-z			Pokec-n			Accuracy (%)	δSP (%)	δeo (%)	Accuracy (%)	δsp (%)	∆EO (%)DeepWalk	60.82 ± 0.77	9.79 ± 3.43	8.51 ± 1.67	59.66 ± 1.02	20.19 ± 3.38	22.96 ± 3.44Node2Vec	61.56 ± 0.50	16.18 ± 12.40	14.88 ± 12.31	60.31 ± 0.75	20.76 ± 1.64	20.32 ± 1.36FairWalk	57.48 ± 0.11	12.03 ± 10.19	10.95 ± 8.82	57.44 ± 0.73	15.00 ± 1.40	15.72 ± 1.80DGI	65.56 ± 1.29	4.82 ± 1.89	5.81 ± 0.97	65.71 ± 0.24	5.18 ± 2.15	7.16 ± 2.44GRACE	67.09 ± 0.47	6.20 ± 2.22	6.18 ± 2.46	67.90 ± 0.13	8.85 ± 1.39	10.13 ± 2.11GCA	66.85 ± 0.71	7.40 ± 4.14	7.46 ± 4.09	67.02 ± 0.43	5.31 ± 0.62	7.75 ± 1.49NIFTY	66.09 ± 0.40	5.86 ± 1.97	6.19 ± 1.72	65.44 ± 0.17	5.18 ± 2.80	5.78 ± 3.18FairAug	67.04 ± 0.69	3.29 ± 1.66	3.04 ± 1.37	67.88 ± 0.45	4.81 ± 0.59	6.52 ± 0.99FairAug wo ED	67.38 ± 0.31	2.66 ± 3.22	4.26 ± 2.92	67.57 ± 0.18	3.37 ± 0.62	5.13 ± 1.12Table 2: Ablation Study on Node Classification	Pokec-z			Pokec-n			Accuracy (%)	δsp (%)	δeo (%)	Accuracy (%)	δsp (%)	∆EO (%)GRACE	67.09 ± 0.47	6.20 ± 2.22	6.18 ± 2.46	67.90 ± 0.13	8.85 ± 1.39	10.13 ± 2.11FairAug	67.04 ± 0.69	3.29 ± 1.66	3.04 ± 1.37	67.88 ± 0.45	4.81 ± 0.59	6.52 ± 0.99FairAug wo FM	66.88 ± 0.42	4.64 ± 1.91	5.50 ± 1.80	66.15 ± 0.75	7.61 ± 0.29	9.28 ± 1.06FairAug wo NS	67.01 ± 0.41	6.05 ± 2.63	6.83 ± 2.88	66.33 ± 0.20	6.26 ± 0.26	9.16 ± 0.63FairAug wo ED	67.38 ± 0.31	2.66 ± 3.22	4.26 ± 2.92	67.57 ± 0.18	3.37 ± 0.62	5.13 ± 1.12
Table 2: Ablation Study on Node Classification	Pokec-z			Pokec-n			Accuracy (%)	δsp (%)	δeo (%)	Accuracy (%)	δsp (%)	∆EO (%)GRACE	67.09 ± 0.47	6.20 ± 2.22	6.18 ± 2.46	67.90 ± 0.13	8.85 ± 1.39	10.13 ± 2.11FairAug	67.04 ± 0.69	3.29 ± 1.66	3.04 ± 1.37	67.88 ± 0.45	4.81 ± 0.59	6.52 ± 0.99FairAug wo FM	66.88 ± 0.42	4.64 ± 1.91	5.50 ± 1.80	66.15 ± 0.75	7.61 ± 0.29	9.28 ± 1.06FairAug wo NS	67.01 ± 0.41	6.05 ± 2.63	6.83 ± 2.88	66.33 ± 0.20	6.26 ± 0.26	9.16 ± 0.63FairAug wo ED	67.38 ± 0.31	2.66 ± 3.22	4.26 ± 2.92	67.57 ± 0.18	3.37 ± 0.62	5.13 ± 1.12FairAug wo EA	66.96 ± 1.08	2.86 ± 1.79	3.22 ± 1.29	67.96 ± 0.19	7.13 ± 0.29	9.40 ± 0.81values. Second, we note that similar to our framework, GCA is built upon GRACE through adaptiveaugmentations as well. However, the adaptive augmentations utilized in GCA are not fairness-aware,and the results of Table 1 demonstrate that the effect of such augmentations on the fairness metricsis unpredictable. Third, the results indicate that all contrastive learning methods provide betterfairness performance than random walk-based methods on evaluated datasets, including Fairwalk,which is a fairness-aware study. Since the sole information source of random walk-based studies isthe graph structure, obtained results confirm that the graph topology indeed propagates bias, whichis consistent with the motivation of our graph data augmentation design. Finally, the results of Table1 demonstrate that the closest competitor scheme to FairAug is NIFTY (Agarwal et al., 2021) interms of fairness measures. For ∆SP, FairAug outperforms NIFTY on both datasets, whereas interms of ∆EO , FairAug and NIFTY outperform each other on Pokec-z and Pokec-n, respectively.
Table 3: Link prediction results obtained on node representations	UCSD34			Berkeley13			AUC (%)	δSP (%)	δeo (%)	AUC (%)	δsp (%)	∆EO (%)GCA	71.59 ± 0.29	0.70 ± 0.27	1.92 ± 0.45	69.69 ± 0.38	0.50 ± 0.36	6.52 ± 0.99GRACE	71.57 ± 0.28	0.49 ± 0.28	1.48 ± 0.70	69.55 ± 0.46	0.76 ± 0.44	4.34 ± 1.20FairAug	71.46 ± 0.30	0.71 ± 0.38	1.62 ± 0.62	69.48 ± 0.29	0.70 ± 0.43	4.24 ± 0.90FairAug wo NS	71.50 ± 0.31	0.41 ± 0.32	1.16 ± 0.65	69.65 ± 0.33	0.68 ± 0.34	4.22 ± 0.97Table 4: Employment of fair edge deletion as an edge dropout method	Accuracy (%)	AUC (%)	∆SP (%)	∆EO (%)Cora	Edge Dropout 82.79 ± 0.83	90.52 ± 0.52	57.22 ± 2.19	36.18 ± 4.53	Fair ED	80.38 ± 1.14	87.95 ± 1.22	48.78 ± 2.58	27.79 ± 3.89Citeseer	Edge Dropout 78.30 ± 1.17	87.93 ± 1.05	43.05 ± 2.39	25.45 ± 3.69	Fair ED	77.26 ± 1.80	86.79 ± 1.39	39.90 ± 3.57	25.02 ± 6.93Pubmed	Edge Dropout 88.63 ± 0.34	95.14 ± 0.16	45.59 ± 0.78	15.81 ± 0.92	Fair ED	87.48 ± 0.54	94.15 ± 0.36	40.90 ± 1.10	11.70 ± 0.68and GRACE, obtained results confirm our previous assessment regarding the unpredictable effect ofGCA’s augmentations on the fairness metrics. Finally, comparing FairAug with and without NS, theresults of Table 3 show that in UCSD34 and Berkeley13, the employment of node sampling can beineffective in improving fairness metrics, or can even worsen them. In UCSD34 and Berkeley13, wehave |Sχ∣ >> |ST (see Table 5 of Appendix A.5). Therefore, for NS on these datasets, half of the
Table 4: Employment of fair edge deletion as an edge dropout method	Accuracy (%)	AUC (%)	∆SP (%)	∆EO (%)Cora	Edge Dropout 82.79 ± 0.83	90.52 ± 0.52	57.22 ± 2.19	36.18 ± 4.53	Fair ED	80.38 ± 1.14	87.95 ± 1.22	48.78 ± 2.58	27.79 ± 3.89Citeseer	Edge Dropout 78.30 ± 1.17	87.93 ± 1.05	43.05 ± 2.39	25.45 ± 3.69	Fair ED	77.26 ± 1.80	86.79 ± 1.39	39.90 ± 3.57	25.02 ± 6.93Pubmed	Edge Dropout 88.63 ± 0.34	95.14 ± 0.16	45.59 ± 0.78	15.81 ± 0.92	Fair ED	87.48 ± 0.54	94.15 ± 0.36	40.90 ± 1.10	11.70 ± 0.68and GRACE, obtained results confirm our previous assessment regarding the unpredictable effect ofGCA’s augmentations on the fairness metrics. Finally, comparing FairAug with and without NS, theresults of Table 3 show that in UCSD34 and Berkeley13, the employment of node sampling can beineffective in improving fairness metrics, or can even worsen them. In UCSD34 and Berkeley13, wehave |Sχ∣ >> |ST (see Table 5 of Appendix A.5). Therefore, for NS on these datasets, half of thenodes are sampled randomly from the sets S1χ and S0χ (as the limit on the minimum node samplingbudget is half of the initial group size to avoid a possible over-sampling, see Appendix A.7). Since|Sχ∣ >> |Sω|, such a sampling framework coincides with random sampling, which makes the ef-fects of the proposed node sampling scheme unpredictable on the fairness metrics. Furthermore,while γι suggests that the cardinality of the set |Sχ∣ should be reduced when |Sω | ≤ |Sχ∣, γι ac-tually appears in the upper bound and not in the exact kρk1 expression. The removal of nodes withinter-edges is actually counter-intuitive, as inter-edges generally help to reduce bias in graphs where
Table 5: Dataset statistics for social networksDataset	ISXI	IS0ω I	ISXI	IS1ω I	IEXI	IEω I S0	IESω1 IPokec-z	622	4229	582	2226	1730	23428	15942Pokec-n	423	3617	479	1666	1422	18548	10672UCSD34	2246	118	1697	71	51607	36787	19989Berkeley13	1619	80	1488	77	27542	19550	13582Table 6: Dataset Statistics for Citation networksDataset	IVI	# sensitive attr.	IEXI	IEωICora	2708	7	1428	5964Citeseer	3327	6	1628	4746Pubmed	19717	3	12254	49802A.6 Contrastive Learning over GraphsThe main goal of contrastive learning is to learn discriminable representations by contrasting the em-beddings of positive and negative examples, through minimizing a specific contrastive loss (Opolkaet al., 2019; Velickovic et al., 2019; ZhU et al., 2021; 2020). The contrastive loss in the present workis designed to maximize node-level agreement, meaning that the representations of the same nodegenerated from different graph views can be discriminated from the embeddings of other nodes. Let1	11	2	22H1 = f(A1, X1) and H2 = f(A2, X2) denote the nodal embeddings generated with graph views12	i	i	i
Table 6: Dataset Statistics for Citation networksDataset	IVI	# sensitive attr.	IEXI	IEωICora	2708	7	1428	5964Citeseer	3327	6	1628	4746Pubmed	19717	3	12254	49802A.6 Contrastive Learning over GraphsThe main goal of contrastive learning is to learn discriminable representations by contrasting the em-beddings of positive and negative examples, through minimizing a specific contrastive loss (Opolkaet al., 2019; Velickovic et al., 2019; ZhU et al., 2021; 2020). The contrastive loss in the present workis designed to maximize node-level agreement, meaning that the representations of the same nodegenerated from different graph views can be discriminated from the embeddings of other nodes. Let1	11	2	22H1 = f(A1, X1) and H2 = f(A2, X2) denote the nodal embeddings generated with graph views12	i	i	iG1 and G2 , where Ai, and Xi are the adjacency and featUre matrices of Gi, which are corrUptedversions of the matrices A and X. Let hi1 and hi2 denote the embeddings for vi : They shoUld bemore similar to each other than to the embeddings of all other nodes. Hence, the representations ofall other nodes are Used as negative samples. The contrastive loss for generating embeddings hi1 andhi2 (considering hi1 as the anchor representation) can be written ases(h1,h2)/T
Table 7: SensitiVity analysis for α on Pokec networks for FairAug.
Table 8: Sensitivity analysis for α on Facebook networks for FairAugα	UCSD34			Berkeley13			AUC (%)	δSP (%)	δeo (%)	AUC (%)	δsp (%)	∆EO (%)0.0/0.1	71.46 ± 0.30	0.71 ± 0.38	1.62 ± 0.62	69.48 ± 0.29	0.70 ± 0.43	4.24 ± 0.900.1/0.2	71.54 ± 0.33	0.65 ± 0.13	1.76 ± 0.38	69.50 ± 0.42	0.55 ± 0.22	4.31 ± 0.760.2/0.3	71.51 ± 0.30	0.58 ± 0.26	1.50 ± 0.66	69.57 ± 0.46	0.55 ± 0.35	4.15 ± 0.790.3/0.4	71.55 ± 0.41	0.49 ± 0.14	1.65 ± 0.50	69.41 ± 0.35	0.97 ± 0.19	4.47 ± 1.10The sensitivity analysis for π is carried out by examining the values[0.75, 0.80, 0.85, 0.90, 0.95, 1.00] for FairAug algorithm for both views. The sensitivity anal-yses for Pokec and Facebook networks on FairAug algorithm are presented in Tables 9 and 10,respectively. In Tables 9 and 10, π = 1 is the parameter choice utilized to generate the results inTable 2 and π = 0.8 is the selection for the results in Table 3.
Table 9: Sensitivity analysis for π on Pokec networks for FairAug.
Table 10: Sensitivity analysis for ∏ on Facebook networks for FairAugπ	UCSD34			Berkeley13			AUC (%)	δsp (%)	δeo (%)	AUC (%)	δsp (%)	∆EO (%)0.80	71.46 ± 0.30	0.71 ± 0.38	1.62 ± 0.62	69.48 ± 0.29	0.70 ± 0.43	4.24 ± 0.901.00	71.30 ± 0.41	0.56 ± 0.47	1.41 ± 0.57	69.70 ± 0.32	0.74 ± 0.36	4.35 ± 1.110.95	71.37 ± 0.41	0.60 ± 0.30	1.48 ± 0.69	69.52 ± 0.42	0.66 ± 0.16	3.99 ± 0.840.90	71.40 ± 0.38	0.59 ± 0.34	1.45 ± 0.44	69.48 ± 0.31	0.86 ± 0.72	4.64 ± 1.370.85	71.39 ± 0.36	0.65 ± 0.28	1.38 ± 0.54	69.49 ± 0.41	0.70 ± 0.40	4.19 ± 0.840.75	71.47 ± 0.23	0.63 ± 0.37	1.55 ± 0.65	69.52 ± 0.43	0.74 ± 0.48	4.31 ± 1.19The sensitivity analysis for π on Pokec networks shows that π = 1 results in the best performancesin terms of fairness. However, we note that the fairness results for the remaining π values alsooutperform our baseline, GRACE, together with similar node classification accuracies. Furthermore,the results of Table 10 demonstrate that the presented results for link prediction in Table 3 canindeed be improved with a grid search, as better fairness performances can be obtained with π 6=0.8. Moreover, the results for different π values vary less for link prediction compared to nodeclassification.
Table 11: Effects of proposed augmentations on γ2	Original	Node Sampling	Edge Deletion	Edge AdditionPokec-z	0.90	0.59	0.87	0.77Pokec-n	0.91	0.62	0.89	0.81UCSD34	0.18	0.45	0.03	0.11Berkeley13	0.18	0.43	0.03	0.06Tables 11 and 12 present the effects of the proposed framework on γ values for different datasets. InTable 11, the effect of each augmentation step on γ2 is considered independently. Table 12 demon-strates the effect of augmentations sequentially in the overall algorithm in a cumulative manner(e.g., the “Edge Deletion” column implies both Node Sampling and Edge Deletion are applied).
Table 12: Effects of each step in FairAug		Original Graph	Node Sampling	Edge Deletion	Edge AdditionPokec-z	γ1	0.66	0.11	0.11	0.11	γ2	0.90	0.59	0.50	0.43Pokec-n	γ1	0.67	0.15	0.15	0.15	γ2	0.91	0.62	0.55	0.50UCSD34	γ1	0.91	0.86	0.86	0.86	γ2	0.18	0.45	0.17	0.17Berkeley13	γ1	0.90	0.83	0.83	0.83	γ2	0.18	0.43	0.17	0.17directly designed based on γ2, the proposed approaches indeed reduce the values of it. In addition,presented γ values can also help to explain the ineffectiveness of edge deletion on Pokec networks.
Table 13:	Effects of optimal augmentations on γιOriginal Node Sampling Edge Deletion Edge AdditionPokec-z	0.66	0.00	0.67	1.00Pokec-n	0.67	0.00	0.67	1.00Table 14:	Effects of optimal augmentations on γ2Original Node Sampling Edge Deletion Edge AdditionPokec-z	0.90	0.48	0.00	0.00Pokec-n	0.91	0.46	0.00	0.0024Under review as a conference paper at ICLR 2022Table 15: Effects of each step in Node Sampling + Edge Deletion	Original Graph	Node Sampling	Edge DeletionPokec-z γ1	0.66	0.00	0.08γ2	0.90	0.48	0.00Pokec-n γ1	0.67	0.00	0.11γ2	0.91	0.46	0.00Table 16: Effects of each step in Node Sampling + Edge Addition	Original Graph	Node Sampling	Edge AdditionPokec-z γ1	0.66	0.00	0.73γ2	0.90	0.48	0.00
Table 14:	Effects of optimal augmentations on γ2Original Node Sampling Edge Deletion Edge AdditionPokec-z	0.90	0.48	0.00	0.00Pokec-n	0.91	0.46	0.00	0.0024Under review as a conference paper at ICLR 2022Table 15: Effects of each step in Node Sampling + Edge Deletion	Original Graph	Node Sampling	Edge DeletionPokec-z γ1	0.66	0.00	0.08γ2	0.90	0.48	0.00Pokec-n γ1	0.67	0.00	0.11γ2	0.91	0.46	0.00Table 16: Effects of each step in Node Sampling + Edge Addition	Original Graph	Node Sampling	Edge AdditionPokec-z γ1	0.66	0.00	0.73γ2	0.90	0.48	0.00Pokec-n γ1	0.67	0.00	0.70γ2	0.91	0.46	0.00Tables 13-16 demonstrate that the utilized node sampling, edge deletion/addition frameworks areoptimal in the sense that they reduce γ1 and γ2 to zero, respectively. However, presented γ1 and
Table 15: Effects of each step in Node Sampling + Edge Deletion	Original Graph	Node Sampling	Edge DeletionPokec-z γ1	0.66	0.00	0.08γ2	0.90	0.48	0.00Pokec-n γ1	0.67	0.00	0.11γ2	0.91	0.46	0.00Table 16: Effects of each step in Node Sampling + Edge Addition	Original Graph	Node Sampling	Edge AdditionPokec-z γ1	0.66	0.00	0.73γ2	0.90	0.48	0.00Pokec-n γ1	0.67	0.00	0.70γ2	0.91	0.46	0.00Tables 13-16 demonstrate that the utilized node sampling, edge deletion/addition frameworks areoptimal in the sense that they reduce γ1 and γ2 to zero, respectively. However, presented γ1 andγ2 values also show the interference of optimal edge manipulations on γ1 , as γ1 increases after theapplication of edge deletion/addition following node sampling. Specifically, edge addition has agreat impact on it.
Table 16: Effects of each step in Node Sampling + Edge Addition	Original Graph	Node Sampling	Edge AdditionPokec-z γ1	0.66	0.00	0.73γ2	0.90	0.48	0.00Pokec-n γ1	0.67	0.00	0.70γ2	0.91	0.46	0.00Tables 13-16 demonstrate that the utilized node sampling, edge deletion/addition frameworks areoptimal in the sense that they reduce γ1 and γ2 to zero, respectively. However, presented γ1 andγ2 values also show the interference of optimal edge manipulations on γ1 , as γ1 increases after theapplication of edge deletion/addition following node sampling. Specifically, edge addition has agreat impact on it.
