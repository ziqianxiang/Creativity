Table 1: Dataset description. We show sample counts in labelled and unlabelled training sets, as well ascounts for majority and minority groups. The number of labelled samples are about 10% of total samples.
Table 2: Quantitative Results. For baselines, we consider an ERM, Unsup DRO [14], Group DRO (Partial)for partly labelled Group DRO [30] method, Group DRO (Oracle) for the fully supervised model. Our methodWorst-off DRO improves the minority group’s accuracy (min) while maintaining a similar overall accuracy(avg) relative to baselines. The accuracies are computed on the test set and are an average over three randomruns. The standard deviations are provided in the Appendix Table 5.
Table 3: Grid search for Table 2. The range of values for each hyper-parameter is listed. A grid searchover these hyper-parameters is conducted to identify the best performing model. Models outside these rangevalues were observed to be either unstable or not converging. Model selection is done based on NVP (novelvalidation procedure) where first the models, with higher overall accuracies, are selected. From the top fivesuch performing models, the one with the highest minority group accuracy is picked.
Table 4: Hyperparamter choices for Table 2. We list the hyper-parameters selected using the NVP procedure(see Section 4) after performing grid-search. Learning rate and weight decay are an important set of parametersthat influences the minority group performance. Each baseline has it’s algorithm-specific hyper-parameter suchas step-size of the simplex weights in Group DRO (ηGDRO), the loss threshold in Unsup DRO (ηUDRO) andthe step size for the group weights in Worst-off DRO (ηWDRO). The symbol “-” for batchsize in CMNISTexperiments indicate the use of full-batch data for training.
Table 5: Quantitative Results - Standard Deviations. The standard deviations over three random runs ofTable 2 is provided. For baselines, we consider an ERM, Unsup DRO [14], Group DRO (Partial) for partlylabelled Group DRO [30] method, Group DRO (Oracle) for the fully supervised model.
