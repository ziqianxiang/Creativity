Table 1: Comparison of the performancefor MNIST of robust classifiers trained withLangevin and PGD (with 40 iterations). Thearchitecture of the two classifiers is architectureA. The attacks are FGSM, PGD 40, PGD 100,and autoattack (Croce and Hein [2020]). Theclassifier trained with Langevin is more robustthan the one trained with PGD for each measureexcept Autoattack.
Table 2: Comparison of the performance forCIFAR-10 of robust classifiers trained withLangevin and PGD (with 40 iterations). The ar-chitecture of the two classifiers is RESTNET18.
Table 3: Comparison of the performance of robust classifiers trained with the Adversarial Transportframework (Langevin) and PGD (trained with 40 iterations). The architecture of the two classifiers isthe above architecture A. The robustness of these two models is tested against FGSM attacks, PGDwith 40 iterations (PGD 40) and PGD with 100 iterations (PGD 100). The trained classifier withLangevin is more robust than the one with PGD.
Table 4: Performance of robust classifiers trained with the Adversarial Transport framework(Langevin) with architecture B. The robustness of this model is tested against FGSM attacks, PGDwith 40 iterations (PGD 40) and PGD with 100 iterations (PGD 100). The results are better than forarchitecture A. Especially, we notice that there is no loss of performance between PGD 40 attacksand PGD 100 attacks. As explained in Madry et al. [2018], networks with larger capacity are strongeragainst adversarial attacks.
Table 5: Performance comparison of a wide ResNet (Zagoruyko and Komodakis [2017]) trained withthe Adversarial Transport framework (Langevin) and PGD 40 on CIFAR-10. No hyperparametertuning was done; the same setup as described in Section 5 is used with the exception of only trainingfor 36 epochs instead of 100. The Langevin framework took about 2h10m to train, while PGD 40took 43h43m to train.
