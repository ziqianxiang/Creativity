Table 1: The success rate of each option whentesting on different subtasks.
Table 3: Reinforcement Learning ParametersTable 2: Imitation Learning ParametersHyparameter	Value	HyParameter	Valuebatch size	512	batch size	256learning rate	0.001	learning rate	0.0003train episodes	1500	hidden size	128hidden size	128	entropy	0.001optimizer	Adam	ppo epoch	4temperature for Softmax	10	gamma	0.97		optimizer	AdamA.3 BaselinescompILE We modify the encoder and decoder of compILE so that the model can adapt to theobservation of our environment. We use the discrete latent as the original paper describes. Were-initialize the encoder to predict latent for the new tasks and freeze the decoder which predicts theactions in RL.
Table 2: Imitation Learning ParametersHyparameter	Value	HyParameter	Valuebatch size	512	batch size	256learning rate	0.001	learning rate	0.0003train episodes	1500	hidden size	128hidden size	128	entropy	0.001optimizer	Adam	ppo epoch	4temperature for Softmax	10	gamma	0.97		optimizer	AdamA.3 BaselinescompILE We modify the encoder and decoder of compILE so that the model can adapt to theobservation of our environment. We use the discrete latent as the original paper describes. Were-initialize the encoder to predict latent for the new tasks and freeze the decoder which predicts theactions in RL.
