Table 1: Summary of MRR@10 and nDCG@10 for all methods on MSMARCO Passage and Natural Questions(NQ). We compare cross-attention, dual-encoder, and distilled dual-encoder BERT models. Wehighlight the best performing DE based model. Distilling the dual-encoder with our proposed techniquessignificantly improves performance over one-hot training and existing distillation techniques. Resultsmarked * are quoted from the corresponding reference,“N/A” are not applicable (e.g., the cross-attentionmodel is not feasible to apply for retrieval), and “—” are not available from the reference. ♦ SeeAppendix C.11 for analysis of potential label noise influencing the results. ? See text for discussion.
Table 2: Comparison of cross-attention (CA) and dot-product based dual-encoder (DE) models on theMSMARCO-Passage re-ranking task. Notably, for sufficiently large embedding dimension, theDE model closely matches the performance of the CA on the training set; however, there is a sizable gapon the test set. This points to the poorer DE model performance being largely an issue of generalisation,rather than capacity.
Table 3: Sample of (query, passage) pairs from MSMARCO-Passage dev set with largest discrepancy betweenthe CA and DE model scores. In most of these cases, the passage is not relevant to the query; however,there is a high degree of token overlap between the two, indicating superficial similarity.
Table 4: Re-ranking results on MSMARCO-Passage dev set, using a small-bert-6-128 model.
Table 5: Re-ranking results on MSMARCO-Passage dev set, using a small-bert-2-768 model.
Table 6: Sensitivity analysis of distillation losses to number of documents per sample.
Table 7: Results on MSMARCO Passage dev set with ColBERT model.
Table 8: Effect of label smoothing on DE models, on the re-ranking task for the MSMARCO-Passage dataset.
Table 9: Results of various regularisation strategies on MSMARCO Passage dev set. For all rows, we use a DEmodel trained on the triplet data.
Table 10: Comparison of top-5 scoring passages for margin MSE and softmax CE on TREC DL19 test set. Thecells shaded blue correspond to passages rated positive. Several other passages are however seen to beequally valid answers to the source query.
Table 11: Comparison of top-5 scoring passages for margin MSE and softmax CE on TREC DL19 test set. Thecells shaded blue correspond to passages rated positive. Several other passages are however seen to beequally valid answers to the source query.
Table 12: Results of negative mining for DE models, on MSMARCO passage re-ranking task.
