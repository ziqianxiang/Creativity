Table 1: Each stage of our on-target adaptation improvestarget accuracy. Contrastive learning (stage 2), for fittingthe representation on target data alone, helps whether or notthe teacher is adapted (stage 1).
Table 2: Classification accuracy of on-target adaptation on VisDA-C (validation) across all cate-gories and averaged over classes (avg.) and images (acc.). R18/50/101S denotes ResNet-18/50/101randomly initialized from scratch and R18/50/101P denotes ResNet-18/50/101 pretrained on Ima-geNet.
Table 3: Classification accuracy of our method supervised by three teachers: source-only, SHOT, andTENT-IM on VisDA-C (test). R50/101S denotes ResNet-50/101 randomly initialized from scratchand R50/101P denotes ResNet-50/101 pretrained on ImageNet.
Table 4: Adaptation on ImageNet-Sketch.	Table 5: Adaptation on Office-Home.
Table 6: Comparing our method performance with learnable weight scaling (LWS) on long-tailedbenchmarks including iNaturalist18 and ImageNet-LT. Note that LWS adapts during training whileour method can adapt during testing, which is more efficient.
Table 7: Classification accuracy on VisDA-C (validation). “Imagenet pretrain” indicates whether weutilize ResNet pretrained on ImageNet at stage 0. “Source only” indicates whether we skip test-timeadaptation (stage 1) and directly use the source model to generate pseudo labels at stage 3.
Table 8: Classification accuracy on VisDA-C (validation) . Leftside: Ablation results on the student model with various initial-ization. Right side: Ablation results on the contrastive learningmethod using MoCo, SwAV, SimSiam, and Barlow Twins.
Table 9: Classification accuracy of our method on VisDA-C (validation). “Soft” indicates thatthe hard-label cross-entropy loss is replaced with the soft-label KL divergence loss for each even-numbered phase. Note that our default number of phases (phase 3) is highlighted.
