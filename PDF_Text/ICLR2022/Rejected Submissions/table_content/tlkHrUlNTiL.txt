Table 1: Information flow in a FC-DNN with ReLU. Here, 'q’s are pre-activation inputs, 'z’s are output of thehidden layers, 'G’s are the gating values. l ∈ [d - 1] is the index of the layer, iout and iin are indices of nodes inthe current and previous layer respectively.
Table 2: Shows the information flow in the convolutional architecture described at the beginning ofAppendix B.
Table A: GLNM-CD4	Test 1	Test 2	Test 3	Test 4	Test 5	Test 6	Test 7	Test 8Train 1	94.32±0.16	-	-	-	-	-	-	-Train 2	92.98±0.21	94.27±0.07	-	-	-	-	-	-Train 3	92.37±0.15	93.63±0.06	94.52±0.07	-	-	-	-	-Train 4	91.41±0.05	92.55±0.07	93.15±0.17	94.48±0.1	-	-	-	-Train 5	89.53±0.23	91.70±0.27	92.33±0.22	93.41±0.21	94.31±0.1	-	-	-Train 6	86.99±1.02	90.94±0.95	91.07±0.68	91.84±0.21	93.14±0.5	94.20±0.34	-	-Train 7	84.91±0.73	89.94±0.49	90.14±0.26	90.41±0.32	91.21±0.5	93.06±0.28	94.12±0.29	-Train 8	82.86±0.39	85.53±1.27	88.22±0.97	89.00±0.5	90.49±0.57	92.11±0.5	92.6±0.32	93.98±0.31									Table B: GLNMD-CDI										Test 1	Test 2	Test 3	Test 4	Test 5	Test 6	Test 7	Test 8Train1	90.28±1.21	-	-	-	-	-	-	-Train2	81.89±1.45	90.29±1.09	-	-	-	-	-	-Train3	75.19±4.45	84.18±2.45	89.4±0.24	-	-	-	-	-Train4	72.69±0.71	80.95±0.34	84.69±1.57	91.3±0.5	-	-	-	-Train5	61.02±2.79	73.16±2.53	76.06±2.09	83.14±0.74	91.42±0.7	-	-	-Train6	53.22±2.47	70.77±2.65	73.63±1.01	68.56±0.52	84.92±0.68	91.66±0.36	-	-Train7	49.21±4.6	61.20±1.99	64.35±1.14	72.85±4.11	79.13±2.18	83.25±0.91	91.29±0.29	-
Table C: DLGN-SF-128x16 Sparse Activity: Top 128 Gates Active									Test 1	Test 2	Test 3	Test 4	Test 5	Test 6	Test 7	Test 8Train 1	96.08±0.03	-	-	-	-	-	-	-Train 2	95.79±0.25	96.52±0.07	-	-	-	-	-	-Train 3	94.61±0.27	96.45±0.13	96.55±0.24	-	-	-	-	-Train 4	93.64±0.67	96.12±0.18	96.45±0.26	96.73±0.09	-	-	-	-Train 5	91.43±0.39	95.93±0.15	96.32±0.23	96.41±0.09	96.78±0.2	-	-	-Train 6	90.13±1.00	95.66±0.04	96.08±0.25	95.94±0.18	96.50±0.19	96.95±0.1	-	-Train 7	89.34±1.18	95.03±0.15	95.72±0.09	95.73±0.19	96.07±0.21	96.70±0.05	96.92±0.03	-Train 8	88.87±0.61	94.27±0.30	95.46±0.09	95.77±0.15	95.98±0.24	96.72±0.04	96.57±0.06	96.79±0.14Table D: DLGN-SF-128x16No SParSe Activity:〜128×16 GateS are ACtiVe	Test 1	Test 2	Test 3	Test 4	Test 5	Test 6	Test 7	Test 8Train 1	96.87±0.02	-	-	-	-	-	-	-Train 2	96.07±0.02	97.04±0.08	-	-	-	-	-	-Train 3	90.60±0.94	96.35±0.35	97.06±0.01	-	-	-	-	-Train 4	81.85±0.60	91.89±0.47	96.21±0.40	96.97±0.04	-	-	-	-Train 5	62.41±4.27	84.61±3.75	93.19±0.41	95.72±0.16	96.92±0.01	-	-	-Train 6	59.02±4.92	66.48±2.49	80.74±1.89	91.73±1.28	96.45±0.15	97.12±0.08	-	-Train 7	46.57±10.13	55.19±2.36	66.82±1.87	87.26±1.54	94.36±0.29	96.63±0.10	97.2±0.09	-
Table D: DLGN-SF-128x16No SParSe Activity:〜128×16 GateS are ACtiVe	Test 1	Test 2	Test 3	Test 4	Test 5	Test 6	Test 7	Test 8Train 1	96.87±0.02	-	-	-	-	-	-	-Train 2	96.07±0.02	97.04±0.08	-	-	-	-	-	-Train 3	90.60±0.94	96.35±0.35	97.06±0.01	-	-	-	-	-Train 4	81.85±0.60	91.89±0.47	96.21±0.40	96.97±0.04	-	-	-	-Train 5	62.41±4.27	84.61±3.75	93.19±0.41	95.72±0.16	96.92±0.01	-	-	-Train 6	59.02±4.92	66.48±2.49	80.74±1.89	91.73±1.28	96.45±0.15	97.12±0.08	-	-Train 7	46.57±10.13	55.19±2.36	66.82±1.87	87.26±1.54	94.36±0.29	96.63±0.10	97.2±0.09	-Train 8	29.15±8.43	54.17±4.26	62.69±3.32	76.67±4.23	82.23±3.96	90.83±4.01	92.94±4.33	93.96±4.5422Under review as a conference paper at ICLR 2022Table E: DLGN-SF-128x2No Sparse Activity:〜128 Gates Active	Test 1	Test 2	Test 3	Test 4	Test 5	Test 6	Test 7	Test 8Train1	96.29±0.13	-	-	-	-	-	-	-Train2	94.85±0.87	96.62±0.03	-	-	-	-	-	-Train3	87.44±0.89	94.96±0.68	96.42±0.2	-	-	-	-	-Train4	76.54±1.47	87.62±0.25	93.74±0.62	96.59±0.17	-	-	-	-
Table E: DLGN-SF-128x2No Sparse Activity:〜128 Gates Active	Test 1	Test 2	Test 3	Test 4	Test 5	Test 6	Test 7	Test 8Train1	96.29±0.13	-	-	-	-	-	-	-Train2	94.85±0.87	96.62±0.03	-	-	-	-	-	-Train3	87.44±0.89	94.96±0.68	96.42±0.2	-	-	-	-	-Train4	76.54±1.47	87.62±0.25	93.74±0.62	96.59±0.17	-	-	-	-Train5	60.69±3.13	80.16±2.18	87.55±4.35	94.58±0.13	96.44±0.14	-	-	-Train6	40.89±7.04	59.1±3.65	71.62±8.58	83.75±1.13	94.46±1.01	96.51±0.2	-	-Train7	37.86±2.74	46.3±3.14	61.75±5.84	76.75±3.18	87.41±1.39	94.5±0.59	96.55±0.17	-Train8	29.7±4.05	42.08±1.87	55.73±6.33	63.63±0.56	70.29±3.85	82.15±4.48	90.7±1.42	96.36±0.06Observation. From Tables C with Tables D and E, we can observe that the DLGN-SF-128x16with CIIC and CISA performs well and DLGN-SF-128x16 without CIIC and CISA as well asDLGN-SF-128x2 without CIIC and CISA perform poorly.
Table F: DLGN-SF-128x2Sparse Activity: Top 16 Gates Active	Test 1	Test 2	Test 3	Test 4	Test 5	Test 6	Test 7	Test 8Train1	94.48±0.16	-	-	-	-	-	-	-Train2	92.86±0.41	95.18±0.08	-	-	-	-	-	-Train3	91.61±0.75	94.26±0.48	95.56±0.13	-	-	-	-	-Train4	91.35±0.68	93.8±0.48	95.14±0.14	95.47±0.14	-	-	-	-Train5	89.65±0.98	93.41±0.48	94.6±0.15	94.87±0.31	95.44±0.14	-	-	-Train6	88.71±0.69	92.5±0.82	93.58±0.14	94.02±0.3	94.92±0.15	95.54±0.05	-	-Train7	88.24±0.59	90.9±0.77	92.82±0.28	93.66±0.34	94.41±0.05	95.01±0.05	95.33±0.07	-Train8	87.54±0.63	88.84±0.69	92.41±0.33	93.57±0.28	94.03±0.13	94.83±0.19	94.65±0.29	95.68±0.11Observation The difference between Table E and Table F is that the model in Table F has sparseactivity, and we observe that it sparse activity ensures good performance.
