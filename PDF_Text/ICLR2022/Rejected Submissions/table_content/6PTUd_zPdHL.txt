Table 1: ImageNet-1K result comparison to state-of-the-art. Among the overall best performingdifferentiable sorting / ranking methods, almost all results in reasonable settings outperform theirrespective baseline on Top-1 and Top-5 accuracy. For publicly available models / backbones, weachieve a new state-of-the-art for top-1 and top-5 accuracy. Our results are averaged over 10 runs.
Table 2: ImageNet-1K results for fine-tuning the head of ResNeXt-101 32x48d WSL (Mahajanet al., 2018) averaged over 10 runs. The displayed metrics are Top-1 | Top-5 accuracies.
Table 3: ImageNet-21K-P results for fine-tuning the head of ResNeXt-101 32x48d WSL (Mahajanet al., 2018). The metrics are Top-1 | Top-5 accuracy averaged over 2 seeds.
Table 4: CIFAR-100 results for training a ResNet18 from scratch averaged over 2 seeds.
Table 5: ImageNet 21K with top-5, top-10 and top-20 components. The displayed metrics percolumn are (Top-1 | Top-5 | Top-10 | Top-20).
Table 6: Depths of sorting networks and selection networks (which are equal for odd-even, pairwise,or bitonic networks) compared to selection networks constructed with our splitter-based approach.
