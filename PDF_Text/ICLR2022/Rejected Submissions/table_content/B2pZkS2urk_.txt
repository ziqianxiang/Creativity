Table 1: A brief review of meta-learning methodsa novel meta-learning framework namely Evolutionary Plastic Recurrent Neural Networks (EPRNN)for task generalization. Specifically, this work makes contributions as follows.
Table 2: Summarized performances comparison in Sequence Predicting tasksMethods	l=1,K=10,N=20	l=1,K=25,N=50	l=3,K=10,N=20	l=3,K=25,N=50ES-RNN	-0.385 ± 0.060	-1.228 ± 0.191	-1.273 ± 0.009	-1.811 ± 0.015ES-LSTM	-0.165 ± 0.014	-0.283 ± 0.013	-1.229 ± 0.010	-1.475 ± 0.016ES-MAML	-1.452 ± 0.292	-1.747 ± 0.064	-1.218 ± 0.013	-1.796 ± 0.013EPMLP	-0.732 ± 0.031	-1.185 ± 0.045	-1.339 ± 0.004	-1.735 ± 0.013EPMLP- (Random)	-1.233 ± 0.115	-1.319 ± 0.035	-1.489 ± 0.023	-1.788 ± 0.003EPRNN	-0.114±0.012	-0.208±0.025	-1.107±0.015	-1.430±0.019EPRNN (w/o m)	-0.135 ± 0.026	-0.351 ± 0.058	-1.128 ± 0.014	-1.520 ± 0.041Table 3: Summarized performances comparison in Wheeled Robot Navigating tasksMethods	Low Noise (σ = 0.01)	Median Noise (σ = 0.05)	High Noise (σ = 0.2)ES-RNN	-16.90 ± 1.30	-18.99 ± 0.14	-31.23 ± 3.95ES-LSTM	-14.04 ± 0.08	-15.50 ± 0.58	-22.53 ± 0.45ES-MAML (zero-shot)	-37.18 ± 0.45	-37.91 ± 0.80	-37.90 ± 0.05ES-MAML (1 rollout)	-23.10 ± 0.46	-29.21 ± 0.46	-37.12 ± 0.12EPMLP	-21.24 ± 6.08	-16.65 ± 0.39	-23.75 ± 2.02EPMLP (Random)	-13.02 ± 0.19	-18.25 ± 0.23	-28.85 ± 1.1EPRNN	-12.71 ± 0.75	-15.07 ± 0.03	-23.79 ± 0.55EPRNN (w/o m)	-14.93 ± 0.49	-16.72 ± 0.33	-24.11 ± 0.34Among plasticity based methods, we show that recursion is more advantageous than MLP in evaluated
Table 3: Summarized performances comparison in Wheeled Robot Navigating tasksMethods	Low Noise (σ = 0.01)	Median Noise (σ = 0.05)	High Noise (σ = 0.2)ES-RNN	-16.90 ± 1.30	-18.99 ± 0.14	-31.23 ± 3.95ES-LSTM	-14.04 ± 0.08	-15.50 ± 0.58	-22.53 ± 0.45ES-MAML (zero-shot)	-37.18 ± 0.45	-37.91 ± 0.80	-37.90 ± 0.05ES-MAML (1 rollout)	-23.10 ± 0.46	-29.21 ± 0.46	-37.12 ± 0.12EPMLP	-21.24 ± 6.08	-16.65 ± 0.39	-23.75 ± 2.02EPMLP (Random)	-13.02 ± 0.19	-18.25 ± 0.23	-28.85 ± 1.1EPRNN	-12.71 ± 0.75	-15.07 ± 0.03	-23.79 ± 0.55EPRNN (w/o m)	-14.93 ± 0.49	-16.72 ± 0.33	-24.11 ± 0.34Among plasticity based methods, we show that recursion is more advantageous than MLP in evaluatedtasks. It is also worth noticing that EPMLP and EPMLP (Random) perform steadily beyond thegradient-based learner (ES-MAML). In ES-MAML, the gradient can only be calculated after anepisode is completed, while EPMLP is able to perform sequential learning even though no feedbackis available during its life time. This demonstrates the possibility of surpassing human-designedgradient-based learning rules with automatically learned unsupervised rules. Moreover, comparisonbetween EPMLP and EPMLP (Random) validate the proposal of Najarro & Risi (2020), implyingthe possibility of discovering global plastic learning rules instead of rules coupled with the initial1 https://github.com/WorldEditors/EvolvingPRNN2https://github.com/PaddlePaddle/PARL
