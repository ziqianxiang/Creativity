Table 1: Test accuracies of GLS on clean and noisy UCI datasets with best two smooth rates (green: NLS;red: PLS). Results on more benchmark datasets are deferred to Appendix D.
Table 2: Test accuracies (meanstd) of GLS on synthetic noisy CIFAR datasets. Best two smooth rates foreach synthetic noise setting are highlighted for each (green: NLS; red: PLS).
Table 3: Performance comparisons on synthetic noisy CIFAR datasets: we adopt the same model architecturefor all methods (ResNet 34 (He et al., 2016)), best achieved test accuracy is reported.
Table 4: Comparison of test accuracies on CIFAR-10 under symmetric label noise.
Table 5: The difference between the empirical true risk of Y * on the clean data and empirical risk GLS onnoisy labels (UCI-WavefOrm dataset): r*, empirical true risk, and empirical noisy risks under various noiselevels are highlighted in purple.
Table 6: Test accuracies of GLS on assymetric noisy CIFAR-10 and symmetric CIFAR-100 (left/right denotesdirect train / warm-up).
Table 7: Test accuracies of GLS on clean and noisy synthetic data. We report best test accuracy for eachmethod. ropt and the corresponding test accuracy are highlighted (green: NLS; red: pLS).
Table 8: Test accuracies of GLS on clean and noisy UCI datasets (Image, Waveform, Heart, Banana) withbest two smooth rates (green: NLS; red: PLS).
