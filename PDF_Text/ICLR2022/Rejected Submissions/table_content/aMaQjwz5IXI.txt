Table 1: Quantitative results on VCTK dataset. The reference style inputs are seen (randomlyselected from the training set). WER measures content accuracy; cosine-similarity (cos-sim) andavgRank measure style similarity.
Table 2: Quantitative results on LibriTTS-all-960 dataset.
Table 3: Style opinion scores of speech synthesizers.
Table 4: Block formulation used in Fig. 5Block name	Architectureconv blocks	blur → conv(3, f1, 2, 0) → Swish → dropout(0.1) →	blur → conv(3, f2, 2, 0) → Swish → dropout(0.1) →multihead atten- tion	blur	→	conv(3, f3, 2, 0)	→	Swish	→	dropout(0.1)	→ blur	→	conv(3, f4, 2, 0)	→	Swish	→	dropout(0.1) (32, 64, 128, 256),	for handwriting (f1,f2,f3,f4) = (256, 384, 512, 512), for speech number of heads = 4 (128, for handwriting dimension of query, key, value = 64, for VCTK (192, for LibriTTSbottom LSTMnumber of layers = 1512,2048,for handwritingfor speechdimensiontop LSTMnumber of layers = 2dimensionfor handwritingfor speech512,2048,content attention	number of Gaussian windows = 10 See Graves (2013) for the exact formulation.
Table 5: Ablation study results on the role of x0 . All models are trained on LibriTTS-all-960 dataset.
Table 6: Overview of controllable sequence models. The table provides a high-level overview ofvarious controllable sequence models. For details, please see individual references.
