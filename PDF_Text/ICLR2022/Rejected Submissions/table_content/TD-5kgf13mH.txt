Table 1: Overview of key properties of sparse MoEs and ensembles. dense is a base model uponwhich we add the sparse MoE or ensemble logic, e.g., a ViT model in this paper.
Table 2: Feature-level vs. prediction-level ensembling. ImageNet performance of V-MoE and anaive multi-head variant (means ± standard errors over 5 replications). All models have a ViT-B/32architecture. For the multi-head variant the last MoE layer is modified as in (2).
Table 3: ImageNet performance (means ± standard errors over 8 replications) of pBE and two abla-tions, disabling either the tiling or the expert partitioning. All models have a ViT-B/32 architecture.
Table 4: Specifications of ViT-S, ViT-B, ViT-L and ViT-H.
Table 5: Hyperparameter values for fine-tuning on different datasets. Compared with Dosovitskiyet al. (2021) and Riquelme et al. (2021), we further consider several factors {0.5, 1.0, 1.5, 2.0} tosweep over different numbers of steps.
Table 6: Impact of using the enlarged sweep of hyperparameters described in Table 5. We typicallyimprove the results reported in Riquelme et al. (2021), therefore strengthening the baselines wecompare to. The table displays means and standard errors over 8 replications, except for H/14 thathas 4 replications. L/16?: For L/16, we consider the setting where the upstream models are trainedwith 7 epochs, as opposed to 14 epochs in Riquelme et al. (2021), hence the slightly worse accuracyreported in this paper.
Table 7: Comparison of two approaches, “joint” and “disjoint”, to compute the linear few-shotevaluation in the case of ensembles. For the ViT families S/32, B/32 and L/32, the mean error acrossdatasets is averaged over 8 replications and over all the ensemble models of size 2 and 4.
Table 8: Percentage improvements in NLL for pBE with (K, M) = (1, 2) and V-MoE with K = 1vs. ViT for families of increasing size. The top two rows show normalised improvements, see (4),which take into consideration the increased difficulty of improving NLL for larger ViT familieswhose performance is beginning to saturate. The bottom two rows are the original percentage im-provements without normalisation.
Table 9: ImageNet performance of different efficient ensemble approaches. The table reports themeans ± standard errors over 8 replications. All models have a ViT-B/32 architecture. K stands forthe sparsity in V-MoEs, M denotes the ensemble size while “BR” corresponds to the batch repetitionin MIMO (Havasi et al., 2020).
Table 10: Comparison of upstream and downstream ensembles of V-MoE with (K = 1).
Table 11: Downstream training GFLOPs for the various pBE, V-MoE, and ViT baselines used inthis work.
Table 12: Percentage difference in downstream training FLOPs for pBE with (K, M) = (1, 2)compared with V-MoE with K = 1 and an ensemble of two such V-MoE members.
Table 13: ImageNet comparison of V-MoE, downstream ensembles there-of, and pBE with 2 experts per input in each case.
Table 14: ImageNet comparison of V-MoE, downstream ensembles there-of, and pBE with 4 experts per input in each case.
Table 15: ImageNet comparison of V-MoE and ViT.
Table 16: Cifar10 comparison of V-MoE, downstream ensembles there-of, and pBE with 2 expertsper input in each case.
Table 17: Cifar10 comparison of V-MoE, downstream ensembles there-of, and pBE with 4 expertsper input in each case.
Table 18: Cifar10 comparison of V-MoE and ViT.
Table 19: Cifar10 OOD comparison of V-MoE, downstream ensembles there-of, and pBE with 2 experts per input in each case.
Table 20: Cifar10 OOD comparison of ViT and V-MoE		K	M	CIFAR 10 VS. CIFAR1 00						CIFAR 1 0 VS. DTD						CIFAR1 0 VS. PLACES365						CIFAR10 VS. SVHN									AUC (PR) ↑		AUC (ROC) ↑		FPR@95 J		AUC (PR) ↑		AUC (ROC) ↑		FPR@95 J		AUC (PR) ↑		AUC (ROC) ↑		FPR@95 J		AUC (PR) ↑		AUC (ROC) ↑		FPR@95 J	L/16	V-MoE	"Γ^	1	0.9891	± 0.0004	0.9895	± 0.0004	0.0379	± 0.0022	0.9999	± 0.0000	0.9997	± 0.0000	0.0001	± 0.0001	0.9400	± 0.0057	0.9960	± 0.0002	0.0162	± 0.0013	0.9972	± 0.0001	0.9984	± 0.0001	0.0007	± 0.0001	ViT	-	1	0.9839	± 0.0008	0.9845	± 0.0007	0.0541	± 0.0026	0.9996	± 0.0000	0.9978	± 0.0002	0.0018	± 0.0004	0.7334	± 0.0227	0.9857	± 0.0010	0.0492	± 0.0024	0.9947	± 0.0003	0.9967	± 0.0002	0.0022	± 0.0003L/32	V-MoE	1	1	0.9854	± 0.0003	0.9850	± 0.0003	0.0573	± 0.0018	0.9996	± 0.0000	0.9976	± 0.0002	0.0030	± 0.0003	0.7489	± 0.0049	0.9862	± 0.0003	0.0520	± 0.0011	0.9946	± 0.0003	0.9967	± 0.0002	0.0015	± 0.0003	ViT	-	1	0.9842	± 0.0005	0.9847	± 0.0004	0.0551	± 0.0018	0.9998	± 0.0000	0.9987	± 0.0001	0.0016	± 0.0003	0.9164	± 0.0046	0.9938	± 0.0003	0.0279	± 0.0015	0.9942	± 0.0002	0.9966	± 0.0001	0.0028	± 0.0003B/16	V-MoE	"Γ^	1	0.9856	± 0.0004	0.9855	± 0.0004	0.0554	± 0.0025	0.9998	± 0.0000	0.9992	± 0.0001	0.0015	± 0.0005	0.8598	± 0.0191	0.9912	± 0.0008	0.0413	± 0.0028	0.9949	± 0.0003	0.9972	± 0.0002	0.0027	± 0.0003	ViT	-	1	0.9801	± 0.0005	0.9798	± 0.0004	0.0857	± 0.0023	0.9996	± 0.0000	0.9979	± 0.0001	0.0046	± 0.0007	0.8536	± 0.0057	0.9895	± 0.0003	0.0511	± 0.0012	0.9926	± 0.0002	0.9961	± 0.0002	0.0048	± 0.0003B/32	V-MoE	"Γ^	1	0.9814	± 0.0003	0.9806	± 0.0003	0.0853	± 0.0027	0.9998	± 0.0000	0.9989	± 0.0001	0.0017	± 0.0005	0.8590	± 0.0097	0.9902	± 0.0005	0.0506	± 0.0021	0.9923	± 0.0003	0.9958	± 0.0003	0.0061	± 0.0005	ViT	-	1	0.9752	± 0.0005	0.9716	± 0.0006	0.1485	± 0.0040	0.9985	± 0.0001	0.9915	± 0.0004	0.0186	± 0.0010	0.6507	± 0.0056	0.9734	± 0.0006	0.1021	± 0.0037	0.9872	± 0.0004	0.9920	± 0.0003	0.0148	± 0.0012S/32	V-MoE	"Γ^	1	0.9685	± 0.0008	0.9658	± 0.0010	0.1922	± 0.0056	0.9996	± 0.0000	0.9977	± 0.0002	0.0045	± 0.0007	0.8092	± 0.0105	0.9841	± 0.0008	0.0821	± 0.0032	0.9874	± 0.0006	0.9929	± 0.0004	0.0185	± 0.0019	ViT	-	1	0.9629	± 0.0004	0.9588	± 0.0004	0.2422	± 0.0027	0.9993	± 0.0000	0.9963	± 0.0002	0.0134	± 0.0013	0.7177	± 0.0048	0.9775	± 0.0003	0.1110	± 0.0015	0.9807	± 0.0003	0.9889	± 0.0002	0.0426	± 0.00134Table 21: Cifar100 OOD comparison of V-MoE, downstream ensembles there-of, and pBE with 2 experts per input in each case.
Table 21: Cifar100 OOD comparison of V-MoE, downstream ensembles there-of, and pBE with 2 experts per input in each case.
Table 22: Cifar100 OOD comparison of V-MoE and ViTCIFAR 100 VS. CIFAR 1 0	CIFAR1 00 VS. DTD	CIFAR100 VS. PLACES365	CIFAR100 VS. SVHNK MlAUC(PR) ↑ AUC(ROC) ↑ FPR@95 J IAUC(PR) ↑ AUC(ROC) ↑	FPR@95 J IAUC(PR) ↑ AUC(ROC) ↑ FPR@95 J IAUC(PR) ↑ AUC(ROC) ↑ FPR@95 JL/16	V-MoE	1	1	0.9454	± 0.0013	0.9481	± 0.0015	0.2682	± 0.0073	0.9976	± 0.0000	0.9882	± 0.0002	0.0658	± 0.0024	0.7631	± 0.0043	0.9667	± 0.0007	0.2141	± 0.0040	0.9115	± 0.0035	0.9533	± 0.0020	0.2794	± 0.0123	ViT	-	1	0.9411	± 0.0019	0.9449	± 0.0012	0.2734	± 0.0062	0.9970	± 0.0001	0.9854	± 0.0006	0.0853	± 0.0039	0.7552	± 0.0118	0.9608	± 0.0017	0.2566	± 0.0066	0.8697	± 0.0033	0.9326	± 0.0016	0.3690	± 0.0058L/32	V-MoE	1	1	0.9358	± 0.0028	0.9368	± 0.0018	0.3431	± 0.0052	0.9961	± 0.0001	0.9806	± 0.0004	0.1148	± 0.0022	0.6757	± 0.0080	0.9461	± 0.0016	0.3308	± 0.0081	0.8863	± 0.0093	0.9459	± 0.0025	0.3063	± 0.0123	ViT	-	1	0.9285	± 0.0020	0.9323	± 0.0016	0.3201	± 0.0068	0.9967	± 0.0001	0.9838	± 0.0006	0.0911	± 0.0036	0.7541	± 0.0066	0.9634	± 0.0014	0.2292	± 0.0068	0.8495	± 0.0068	0.9234	± 0.0035	0.3949	± 0.0137B/16	V-MoE	丁	1	0.9206	± 0.0015	0.9241	± 0.0014	0.3572	± 0.0061	0.9951	± 0.0002	0.9776	± 0.0007	0.1094	± 0.0034	0.5924	± 0.0076	0.9334	± 0.0012	0.3532	± 0.0035	0.8720	± 0.0048	0.9309	± 0.0023	0.3705	± 0.0122	ViT	-	1	0.9177	± 0.0013	0.9171	± 0.0014	0.3925	± 0.0069	0.9906	± 0.0003	0.9571	± 0.0012	0.2199	± 0.0059	0.4913	± 0.0088	0.8980	± 0.0024	0.4927	± 0.0079	0.8525	± 0.0045	0.9204	± 0.0022	0.4226	± 0.0065B/32	V-MoE	丁	1	0.9166	± 0.0017	0.9145	± 0.0012	0.4211	± 0.0048	0.9940	± 0.0002	0.9714	± 0.0009	0.1562	± 0.0068	0.5433	± 0.0089	0.9178	± 0.0016	0.4258	± 0.0049	0.8730	± 0.0071	0.9276	± 0.0033	0.4026	± 0.0100	ViT	-	1	0.9038	± 0.0022	0.9044	± 0.0018	0.4180	± 0.0061	0.9927	± 0.0002	0.9663	± 0.0008	0.1631	± 0.0055	0.5306	± 0.0046	0.9112	± 0.0015	0.4176	± 0.0062	0.8379	± 0.0029	0.9116	± 0.0014	0.4328	± 0.0062S/32	V-MoE	丁	1	0.8678	± 0.0012	0.8631	± 0.0015	0.5281	± 0.0050	0.9893	± 0.0007	0.9524	± 0.0031	0.1978	± 0.0129	0.4024	± 0.0091	0.8778	± 0.0029	0.4763	± 0.0085	0.8224	± 0.0058	0.8945	± 0.0034	0.4729	± 0.0098	ViT	-	1	0.8644	± 0.0018	0.8541	± 0.0020	0.5716	± 0.0061	0.9836	± 0.0007	0.9287	± 0.0026	0.2976	± 0.0082	0.3149	± 0.0031	0.8349	± 0.0024	0.5982	± 0.0061	0.8088	± 0.0051	0.8894	± 0.0029	0.4888	± 0.008443Table 23: Few-shot comparison of pBE, V-MoE and ensembles thereof.
Table 23: Few-shot comparison of pBE, V-MoE and ensembles thereof.
Table 24: Few-shot comparison of V-MoE and ViT.
Table 25: New feature-level vs. prediction-level ensembling ablation results. ImageNet performanceof V-MoE and a naive multi-head variant (means ± standard errors over 8 replications). All modelshave a ViT-B/32 architecture. For the multi-head variant the last MoE layer is modified as in (2)	K	NLL J	ERROR J	ECE J	KL ↑V-MoE	2	0.638 ± 0.0oι	16.76 ± o.o5	o.o33 ± o.oo1	—Naive Multi-head	2	0.636 ± 0.0oι	17.16 ± o.o2	0.024 ± o.ooo	o.o32 ± o.oo1V-MoE	4	0.636 ± 0.0oι	16.70 ; o.o4	o.o34 ± o.oo1	—Naive Multi-head	4	0.645 ± 0.0oι	17.39 ± o.o4	0.021 ± o.ooo	o.o11 ± o.oo1V-MoE	8	0.635 ± o.oo2	16.72 ; o.o6	o.o28 ± o.oo1	—Naive Multi-head	8	0.650 ± o.ooι	17.5o ± o.o3	0.021 ± o.ooo	o.oo5 ± o.oooJ.2 New Results for the Static versus Adaptive AblationFigure 20 repeats the experiment of Figure 2a with two new random seeds. The new results showa smoother improvement in LL as K increases. In particular, we see that there is nothing special44Under review as a conference paper at ICLR 2022about K = 5 or K = 6. This indicates that the anomalous drop at K = 6 in the original results wassimply due to noise in the training of the upstream model. We note that, like Riquelme et al. (2021),we have observed that training noise is more pronounced in the smallest (i.e., S/32) models.
Table 26: Parameter counts for ViT vs V-MoE and pBE.
