Table 1: Molecular graph generation results. GraphVAE results are taken from (Liu et al., 2018).
Table 2: Graph generation results depicting MMD for various graph statistics between the test setand generated graphs. MGVAE outperforms all competing methods.
Table 3: Citation graph link prediction results (AUC & AP)Dataset	Cora		Citeseer	Method	AUC (ROC)	AP	AUC (ROC)	APSC	84.6 ± 0.01	88.5 ± 0.00	80.5 ± 0.01	85.0 ± 0.01∏-DW	83.1 ± 0.01	85.0 ± 0.00	80.5 ± 0.02	83.6 ± 0.01VGAE	90.97 ± 0.77	91.88 ± 0.83	89.63 ± 1.04	91.10 ± 1.02MGVAE (Spectral)	91.19 ± 0.76	92.27 ± 0.73	90.55 ± 1.17	91.89 ± 1.27MGVAE (K-Means)	93.07 ± 5.61	92.49 ± 5.77	90.81 ± 1.19	91.98 ± 1.02MGVAE	95.67 ± 3.11一	95.02 ± 3.36一	93.93 ± 5.87一	93.06 ± 6.33一17Under review as a conference paper at ICLR 2022Method	Min	Max	STD	KL divergenceSPeCtral	1~	2020	177.52	3.14 —K-MeanS	-Γ~	364	40.17	0.84Learn to cluster		36	4.77	0.02	—Table 4: Learning to cluster algorithm returns balanced cuts on Cora.
Table 4: Learning to cluster algorithm returns balanced cuts on Cora.
Table 5: Learning to cluster algorithm returns balanced cuts on Citeseer.
Table 6: All-at-once MGVAE with MLP decoder vs. second order decoder.
Table 7: The list of chemical/atomic features used for the all-at-once MGVAE on ZINC. We denoteeach feature by its API in RDKit.
Table 8: SMILES of the generated molecules included in Fig. 8. Online drawing tool: https://pubchem.ncbi.nlm.nih.gov//edit3/index.htmlFigure 9: Interpolation on the latent space: we randomly select two molecules from ZINC and wereconstruct the corresponding molecular graphs on the interpolation line between the two latents.
Table 9: Description and statistics of 13 learning targets on QM9.
Table 10: Unsupervised molecular representation learning by MGVAE to predict molecular prop-erties calculated by DFT on QM9 dataset.
Table 11: Supervised MGN to predict solubility on ZINC dataset.
Table 12: Quantitative evaluation of the generated set by FID metric for each resolution level onMNIST. It is important to note that the generation for each resolution is done separately: for the `-thresolution, we sample a random vector of size dz = 256 from N (0, 1), and use the global decoderd(`) to decode into the corresponding image size. The baselines are taken from (Dieng et al., 2019).
