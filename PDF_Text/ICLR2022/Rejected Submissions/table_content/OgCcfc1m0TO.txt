Table 1: Evaluation on robustness to distribution shift. M : CoOp’s context length.
Table 2: Comparison with prompt ensembling. Table 3: Random vs. manual initialization.
Table 4: The nearest words for each of the 16 context vectors learned by CoOp, with their distancesshown in parentheses. N/A means non-Latin characters.
Table 5: Datasets statistics.
Table 6: Comparison with zero-shot CLIP on robustness to distribution shift using different visionbackbones. M : CoOp’s context length.
Table 7: Comparison with prompt engineering and prompt ensembling on ImageNet using differentvision backbones.
