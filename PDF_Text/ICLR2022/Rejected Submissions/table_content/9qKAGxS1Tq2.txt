Table 1: Dataset statistics in Section3.4. Test size is often dozens of times the training size due toreplacement augmentation. Additional details are offered in Appendix.
Table 2: Evaluation results over RNN, CNN, and TFM on SCAN, GEO, and ADV in Section 3.4.1conditioned on Standard, Difficult and Challenging settings.
Table 3: Evaluation results over RNN, CNN, and TFM on SCAN, GEO, and ADV in Section 3.4.2conditioned on Standard and Difficult settings.
Table 4: BLEU and SacreBLEU scores on IWSLT’14 English-German (En-De) and German-English (De-En), IWSLT’15 English-French (En-Fr) and French-English (Fr-En) translation tasks.
Table 5: Token and sequence accuracy on Geography and Advising. We mark the addition of conceptrules as Entity Augmentation.
Table 6: Example source and target sequences from SCAN, GEO, ADV, Geography, and Advising.
Table 7: Data statistics and training time per epoch in seconds. The batch size of each epoch forGEO and Geography is 32, and that for the others is 128.
Table 8: Prompts with example primitives and sampled variants. In SCAN, primitives share thesame prompt and the number of variants can be changed. In ADV, we randomly sample 5 variantsfor each source sequence so that We cover all the variants with a test set of an appropriate size.
Table 9: Results of Standard inductive learning.
Table 10: Results of Difficult inductive learning.
Table 11: Results of Challenging inductive learning.
Table 12: Concept rules with primitives and their example variants.
Table 13: Results of Standard deductive learning.
Table 14: Results of Difficult deductive learning.							Data	Model	Loss	Train Token Acc.%	Seq. Acc.%	Test							Loss	Token Acc.%	Seq. Acc.%	RNN	0.00 ± 0.00	99.99 ± 0.01	99.95 ± 0.07	0.08 ± 0.08	98.70 ± 0.92	95.39 ± 2.72SCAN	CNN	0.00 ± 0.00	99.62 ± 0.34	98.82 ± 1.09	0.13 ± 0.29	98.59 ± 3.10	96.66 ± 7.27	TFM	0.00 ± 0.00	99.82 ± 0.03	98.78 ± 0.12	0.21 ± 0.20	96.68 ± 2.21	91.26 ± 5.80	RNN	0.20 ± 0.03	96.93 ± 0.71	75.35 ± 3.57	4.40 ± 2.50	39.71 ± 18.38	7.67 ± 5.34GEO	CNN	0.08 ± 0.01	97.77 ± 0.76	76.41 ± 2.80	32.94 ± 4.26	41.07 ± 7.48	4.04 ± 2.18	TFM	0.02 ± 0.00	99.56 ± 0.11	91.08 ± 1.56	5.97 ± 1.05	65.97 ± 5.17	31.57 ± 7.42	RNN	0.08 ± 0.02	98.54 ± 0.28	67.10 ± 3.45	7.87 ± 1.01	36.42 ± 7.39	12.66 ± 5.19ADV	CNN	0.04 ± 0.05	98.78 ± 1.91	77.14 ± 23.28	32.44 ± 6.07	35.34 ± 14.68	23.58 ± 16.04	TFM	0.00 ± 0.00	99.92 ± 0.02	96.41 ± 0.26	14.92 ± 1.31	53.33 ± 3.85	43.24 ± 5.14training supplementary for IWSLT’14 En-De and De-En, and 110,099 for IWSLT’15 En-Fr and Fr-En, which leads to a total of 305,113 training samples for IWSLT’14 En-De and De-En and 315,671for IWSLT’15 En-Fr and Fr-En after such vocabulary augmentation.
