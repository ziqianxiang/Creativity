Table 1: Comparison of current de-oversmoothing methods	Constant Divergence Indicator	Easy-to-Determine Divergence Indicator	Model-Agnostic StrategyAPPNP (KliCPera et al.,2019)	=	Yes	No	YesMADReg + AdaEdge (Chen et al., 2020a)	No	Not Sure	YesPairNorm (Zhao & Akoglu, 2020)	Yes	No	YesDropEdge (Rong et al., 2020)	No	No	YesGCNn(Chen et al.,2020b)	Yes	Yes	NoDAGNN (Liu et al., 2020)	Yes	No	YesDGN (Zhou et al., 2020)	No	No	YesTGCL (Our MethOd)	ä¸€	Yes	Yes	Yeson the prior knowledge of the input graph data, which is hard to determine. (The discussion of otherde-oversmoothing methods can be found in Section 5.)As shown in Table 1, PairNorm is an effective de-oversmoothing method that maintains two metricsbut needs prior knowledge to scale divergence between node pairs. While our proposed TGCLtransfers this hard-to-acquire prior knowledge into the topology information of the input graph,where the divergence guidance between nodes is constant and easy to be determined. To be specific,our TGCL is the first de-oversmoothing method attempting to maintain these three metrics at thesame time. In the next section, we formally introduce the proposed TGCL with theoretical prooffor the model effectiveness. Moreover, we prove that the objective of PairNorm is just a special caseof our TGCL, which shows the effectiveness of our TGCL from another perspective.
Table 2: Accuracy on node classification on four benchmark datasets.
Table 3: Accuracy of node classification on four datasets by masking p percent of node attributes.
