Table 1: Average cost of solutions for the Knapsack Problem across five random seeds and, inparentheses, optimality gap to best solution found among solvers. Bigger is better. *Values asreported by Bello et al. (2016) for reference.
Table 2: Average cost of solutions for the Bin Packing Problem across five random seeds and, inparentheses, optimality gap to best solution found among solvers. Lower is better. We set a time outof 1 minute per problem for Or-Tools; * indicates only the trivial solution was found in this time.
Table 3: Comparison of Neural SA against different solvers and deep learning models on TSP.
Table 4: Running Times	Knapsack			Bin Packing	Il		Ours	OR-Tools		Ours	OR-Tools50N	0.74s	<	0.01s	1.14s	54s100N	1.13s	<	0.01s	2.27s	56s200N	3.01s	<	0.01s	4.79s	≥ 1m500N	9.40s		0.01s	14.18s	≥ 1m1000N	38.68s		0.02s	37.67s	≥ 1m2000N	130.86s		0.08s	121.74s	≥ 1mA.1 Knapsack ProblemData We consider problems of different sizes, with KNAPN consisting of N items, each with aweight Wi and value Vi sampled from a uniform distribution, WiQi 〜 U(o：i). Each problem hasalso an associated capacity, that is, the maximum weight the knapsack can comport. Here we follow(Bello et al., 2016) and set C50 = 12.5, C100 = 25 and C200 = 25. However, for larger problemswe set CN = N/8.
Table 5: ES results on the Knapsack benchmark. Bigger is better. Comparison among rollouts ofdifferent lengths: 1, 2, 5 or 10 times the dimension of the problem.
Table 6: PPO results on the Knapsack benchmark. Bigger is better. Comparison among rollouts ofdifferent lengths: 1, 2, 5 or 10 times the dimension of the problem.
Table 7: ES results on the Bin Packing benchmark. Lower is better.
Table 8: PPO results on the Bin Packing benchmark. Lower is better.
Table 9: PPO results on the TSP benchmark. Lower is better	Greedy ×1	×1	Sampled			LKH-3	Concorde			×2	×5	×10		TSP20	4.937 ±.001	3.941 ± .001	3.898 ± .001	3.865 ±.000	3.852 ± .000	3.836	3.836TSP50	8.104 ±.006	5.916 ± .002	5.847 ±.001	5.789 ±.000	5.762 ± .000	5.696	5.696TSP100	11.764 ±.012	8.167 ± .000	8.052 ± .001	7.956 ±.001	7.907 ± .001	7.764	7.764Table 10: ES results on the TSP benchmark. Lower is better	Greedy ×1	×1	Sampled			LKH-3	Concorde			×2	×5	×10		TSP20	3.868 ±.000	3.868 ± .001	3.854 ± .000	3.844 ±.000	3.840 ± .000	3.836	3.836TSP50	6.020 ±.002	6.022 ± .002	5.947 ±.001	5.871 ±.000	5.828 ± .001	5.696	5.696TSP100	8.659 ±.003	8.660 ± .002	8.477 ± .001	8.298 ±.002	8.191 ± .002	7.764	7.764First city selectorSecond city selector11Resulting tour if action is acceptedUFigure 6: Policy for the Travelling Salesperson Problem. At each step, an action consists of selectinga pair of cities (i,j), one after the other. The figure depicts aTSP problem layed out in the 2D plane,with the learnt proposal distribution over the first city i in the left, and in the right, the distribution
Table 10: ES results on the TSP benchmark. Lower is better	Greedy ×1	×1	Sampled			LKH-3	Concorde			×2	×5	×10		TSP20	3.868 ±.000	3.868 ± .001	3.854 ± .000	3.844 ±.000	3.840 ± .000	3.836	3.836TSP50	6.020 ±.002	6.022 ± .002	5.947 ±.001	5.871 ±.000	5.828 ± .001	5.696	5.696TSP100	8.659 ±.003	8.660 ± .002	8.477 ± .001	8.298 ±.002	8.191 ± .002	7.764	7.764First city selectorSecond city selector11Resulting tour if action is acceptedUFigure 6: Policy for the Travelling Salesperson Problem. At each step, an action consists of selectinga pair of cities (i,j), one after the other. The figure depicts aTSP problem layed out in the 2D plane,with the learnt proposal distribution over the first city i in the left, and in the right, the distributionover the second city j, given i = 12. We mask out and exclude the neighbours of i (0 and 14) ascandidates for j because selecting those would lead to no changes in the tour. It is clear the modelhas a strong preference towards a few cities, but otherwise the probability mass is spread almostuniformly among the other nodes. However, once i is fixed, Neural SA strongly favours nodes jthat are close to i. That is a desirable behaviour and even features in popular algorithms like LKH-3(Helsgaun, 2000). That is because a 2-opt move (i,j) actually adds edge (i, j) to the tour, so leaning
Table 11: Comparison of different TSP solvers on the 10K instances for TSP20∕50∕100 provided in Kool et al. (2018).
