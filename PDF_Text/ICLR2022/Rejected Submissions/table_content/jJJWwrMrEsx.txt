Table 1: Comparison of TT-DCNN with and without filtering with state-of-the-art regarding completeadversarial robustness verification for high noise bounded by l∞ (results are reported as in the originalarticles).___________________________________________________________________________________________________Dataset and Noise Level	Complete Verification Method		Accuracy		Mean time (s)	Timeout	#cls/#vars			Verifiable	Natural			MNIST		TT-DCNN (Ours)	94.24%	97.77%	0.2885	0	1K/0.4K	SAT-based	TT-DCNN + Filtering (Ours)	94.26%	97.70%	0.3724	0	1K/0.4K		Jia & Rinard (2020)	91.68%	97.46%	0.1115	0	21K/48Ktest = 0.1	Real-value-based	Xiao et al. (2018)	94.33%	98.68%	5.47	0.05%	-		Tjeng et al. (2017)	95.62%	98.11%	3.52	0	-MNIST		TT-DCNN (Ours)	79.93%	96.79 %	0.4135	0	4K/1K	SAT-based	TT-DCNN + Filtering (Ours)	80.36%	96.73 %	0.5722	0	4K/1K		Jia & Rinard (2020)	77.59%	96.36%	0.1179	0	21K/48Ktest = 0.3	Real-value-based	Xiao et al. (2018)	80.68%	97.33%	7.12	1.02%	-		Tjeng et al. (2017)	74.21%	86.60%	5.13	0	-CIFAR10		TT-DCNN (Ours)	32.72%	40.67%	0.1988	0	0.7K/0.3K	SAT-based	TT-DCNN + Filtering (Ours)	33.04 %	40.62%	0.7782	0	0.7K/0.2Ktest = 2/255		Jia & Rinard (2020)	32.18%	37.75%	0.0236	0	33K/70K	Real-value-based	Xiao et al. (2018)	45.93%	61.12%	66.08	1.86%	-							
Table 2: Examples of inequality conversion into SAT formulas according to different methodologiesInequality to convert into SAT Formulas	X1 - 2X2 + 3X3 ≤ 3Encoding 1 - Ab^o et al. (2011)	(l4) ∧ (ll ∨ l2 ∨ l5) ∧ (l5 ∨ l3 ∨ 16)∧。6)Encoding 2 - Holldobler et al. (2012)	_	(l4 ∨ Ig) ∧ (l5_∨ l10) ∧ (16 ∨ l11)		 ∧(17 ∨ 112) ∧ (18 ∨ 113) ∧ (19 ∨ 114) ∧ (IIO ∨ 115) ∧ (III ∨ 116) _A(112 ∨ 117) ∧ (113 ∨l18)∧ (13 ∨ 14) ∧ (13 ∨15) ∧ (13 ∨lS)∧ (l2 ∨ l9) ∧ (l2 ∨ l10) ∧ (11 ∨ 14) ∧ (l4 ∨ l2 ∨ l11)∧ (l5 ∨ 12 ∨ 112) ∧ (16 ∨ 12 ∨ 113) ∧ (1g ∨ 11 ∨ 115)∧ (110 ∨ 11 ∨ 11s) ∧ (111 ∨ 11 ∨ 117) ∧ (112 ∨ 11 ∨ 118) ∧ 电)人 (18) ∧ (17 ∨ 12) ∧ (113 ∨ 11)Encoding 3 - E6n & Sorensson (2006)	(15 ∨ I3 ∨ 12) ∧ (17 ∨ 13 ∨ 11) ∧ (18 ∨ 13) ∧ (18 ∨ 12) ∧ (16 ∨ 18 ∨ 17) ∧ (14 ∨ 16 ∨ h) ∧ (%)Encoding 4 - E6n & Sorensson (2006)	03 ∨ 11 ∨ 14) ∧ ¢3 ∨ 11 ∨ 14) ∧ ¢3 ∨ 11 ∨ 14) ∧ ¢3 ∨ 11 ∨ 14) ∧ ¢3 ∨ 1s)∧ (11 ∨W) ∧J(13 ∨ 11 Y 15) ∧J(13 ∨ 12 ∨ 15 Y 16) ∧J(13 ∨ 12 ∨ 15 ∨ 16)∧ _	_	(13 ∨ 12 ∨ 15 ∨	16)	∧	(13 Y 12 ∨	15 ∨ 16)	∧J(13 ∨	12 ∨ 15 ∨ 16)	_	_	_ ∧(I3 ∨ 12	∨	15	∨	A)	∧	(I3 ∨ 12 ∨ 15 ∨ A) ∧	(I3 ∨ 12 ∨ 15	∨ A) ∧	(12 ∨ 15	∨ 17) ∧ (I3 ∨ 15	∨ 17)	∧	(I3	∨ 12 ∨	17) ∧02 ∨ 15 ∨ 17) ∧	(13	∨	15 ∨ 17) ∧	(13 ∨ 12	∨ 17) ∧	(17 ∨ 16 ∨ I3)∧ (I7	∨	16	∨ 12 ) ∧ (17 ∨ 16 ∨ 15)	∧ (17	∨ 16 ∨ 13)	∧ (17 ∨	16 ∨ 12)	∧ (17 ∨ 16 ∨ 15)	∧ (17	∨	1§)Encoding 5 - Manthey et al. (2014)	(14) ∧	(13	∨ 15) ∧ (11	∨ 15) ∧ (13 ∨ 11 ∨	16) ∧ (13 ∨ 17)	∧ (12	∨ 17) ∧ (13 ∨ 12 ∨ 3	∧。7	∨ 1g)∧ (18 ∨	11o) ∧ (16 ∨ 1g) ∧	(17 ∨ 16 ∨ 11o)	∧ (18	∨ 16 ∨ 111) ∧ (111)A.3	Model descriptionA.3.1 Overall ArchitectureIn this study, we considered the two architectures shown in Table 3. All the paddings are set to 0.
Table 3: Different StUdied model architectures details.
Table 4: Performance of studied models as BNN for equitable ComParaisonDataset and Noise Level	Model & Training condition	Accuracy		Mean time (s)	Timeout	#cls/#vars		Verifiable	Natural			MNIST 0.3	Model Big as BNN	49.53%	93.62%	0.010	0	23K/33KCIFAR10 2/255	Model Big as BNN	28.43%	37.66%	0.008	0	32K/46KCIFAR10	Model Small as BNN	~~20.21%	29.38%	0.005	0	15K/22K8/255	Architecture proposed in Jia & Rinard (2020) as BNN with our training noise conditions	19.86%	31.95%	0.002	0	31K/64KA.8 Model countingExact model counting. Given a CNF formula Φ, the Problem of model counting is to calculate thecorresponding number of satisfying assignments #①.This problem is complete for the complexity class#P (Toda, 1991). A number of tools for exact model counting have been develoPed and for this study weare using the recent Ganak model counter (Sharma et al., 2019). An application example of model countingis to establish how many adversarial attacks exist for a trained DNN. In this case, prec defines an -ball ofvalid perturbations and prop states that the classification should change under small perturbations. And theproblem is given to a model counting solver (instead of a SAT solver) in the form of CNF.
Table 5: ResUlts of TT-DCNN in the likelihood adversarial examples Set-UP for MNISTModel	Noise train	Noise test	Loss type	Amplification	Final Linear	P(adv)		AccUracy - P(adv)		TimeoUt - P(adv)		P(adv) with 50% noise		AccUracy - P(adv) with 50% noise		TimeoUt - P(adv) with 50% noise						Normal	Filtered	Normal Filtered		Normal Filtered		Normal	Filtered	Normal Filtered		Normal Filtered	0	0.3	0	Small	Bin	0.0119		716		101		0.05		875		0-		0.3	0	Normal	Bin	0.00084	0.00162	526	549	432	388	0.0135	0.012	898	862	13	6	0.1	0.1	0	Normal	Bin	0.2135	0.2194	-936	932	0	0	0.3787	0.3559	938	930	00Small	0.3	0.3	0	Normal	Bin	0.09265	0.1068	-900	883	1	1	0.2849	0.28267	899	884	00		0.3	3	Normal	Bin	0.1003	0.1085	901	863	0	0	0.3019	0.289	903	865	00		0.3	0	Small	Bin	0.4045		-837		0		0.467		832		0-		0.3	0	Normal	Bin	0.2099		877		0		0.3439		853		0-	0.4	0.3	1	Normal	Bin	0.1643		880		0		0.3038		883		0-		0.3	3	Normal	Bin	0.1914	0.2060	886	877	0	0	0.36322	0.3412	899	898	00		0.3	0	Normal	Ter	0.0		641		354		0		795		195	-	0	0.3	0	Normal	Bin	0.0		111		888							0.1	0.1	0	Normal	Bin	0.022	0.039	-973	970	13	17	0.03	0.05	979	978	01Big	0.3	0.3	0	Normal	Bin	2E-10	2E-10	-802	815	184	174							0.3	3	Normal	Bin	3E-06	2E-06	802	805	196	195	0.014	0.017	936	942	31	31		0.3	0	Normal	Bin	0.0053		-864		108							0.4	0.3	1	Normal	Bin	0.00464		862		125								0.3	3	Normal	Bin	0.005	0.009	867	864	105	94	0.012	0.0377	936	923	84
Table 6: Comparison of natUral accUracy between TT-DCNN, BNN and DCNN.
Table 7: ComParison of model architectures between TT-DCNN, BNN and DCNN.
Table 8: Comparison of the natural accuracy of TT-DCNN for three different types of amplificationconfiguration, for CIFAR10 and MNIST, in the case of training with noise and without noise.
Table 9: Results of TT-DCNN in the Untargeted attack set-up for CIFAR10Model	Noise train	Noise test	Loss type	Amplification	Final Linear	Natural Accuracy		Verifiable Accuracy		Mean time (s)		#cls/#vars							Normal	Filtered	Normal	Filtered	Normal	Filtered	Normal	Filtered	0	8/255	0	Small	Bin	-448-	-	20	-	0.254	-	9722/1610	-			0	Normal	Bin	456	-	18	-	0.266	-	10859/1555	-	2/255	2/255	0	Normal	Bin	460	-456- 463	328	330 (light) 299 (strong)	0.105	0.208 0.200	661/258	639/250 584/233			3	Normal	Bin	463	446	300	288	01:45	03:25	696/273	675/269	2.2/255		0	Normal	Bin	458	431	305	316	0.106	0.217	730/279	676/257			0	Small	Bin	348	-248-	190	185	0.090	0.239	1349/395	1273/390Small	8/255	8/255	0	Normal	Bin	357	357 356	196	229 (light) 231 (Strong)	0.109	0.208 0.213	2269/509	2246/508 2176/507			1	Normal	Bin	368	347	173	186	0.110	0.223	1890/494	1519/464			3	Normal	Bin	358	299	178	192	0.113	0.200	2337/557	2031/538			0	Small	Bin	232	-	135	-	0.061	-	1148/368	-			0	Normal	Bin	329	-	219	-	0.092	-	1342/425	-	16/255	8/255	1	Normal	Bin	344	-	194	-	0.095	-	1339/413	-			3	Normal	Bin	334	334	194	193	0.093	0.206	1473/461	1273/428			0	Normal	Ter	390	-	139	-	0.104	-	3119/1302	-	16.7/255		0	Normal	Bin	347	332	201	244	0.998	0.199	1379/451	1300/440	0	8/255	0	Small	Bin	-506-	-	15	-	0.703	-	26183/3545	-			0	Normal	Bin	539	-	10	-	0.640	-	23777/3874	-
Table 10: Results of TT-DCNN in the untargeted attack set-up for MNISTModel	Noise train	Noise test	Loss type	Amplification	Final Linear	Natural Accuracy		Verifiable Accuracy		Mean time (s)		Timeout		#cls/#vars							Normal	Filtered	Normal	Filtered	Normal	Filtered	Normal	Filtered	Normal	Filtered	0	0.3	0	Small	Bin	909	-	226	-	0.183	-	0	-	2771 / 795	-			0	Normal	Bin	936	908	169	161	0.239	0.268	0	0	3209/871	2974/838	0.1	0.1	0	Normal	Bin	943	937	848	665	0.073	0.128	0	0	456/199	442/195Small	0.3	0.3	0	Normal	Bin	906	902	674	648	0.139	0.207	0	0	1406/501	1370/498			3	Normal	Bin	912	866	665	637	0.147	0.217	0	0	665 1403	1332 493			0	Small	Bin	819	-	670	-	0.114	-	0	-	977/397	-			0	Normal	Bin	859	-	676	-	0.127	-	0	-	1091/425	-	0.4	0.3	1	Normal	Bin	889	-	651	-	0.146	-	0	-	1239/467	-			3	Normal	Bin	886	881	677	680	0.117	0.245	0	0	1059 421	1041 419			0	Normal	Ter	930	-	641	-	0.324	-	0	-	4016/1887	-	0	0.3	0	Normal	Bin	974	-	111	-	0.716	-	0	-	9879/2637	-	0.1	0.1	0	Normal	Bin	976	978	944	947 (low)	0.302	0.494	0	0	1146 461	1137 459							977		946 (low)		0.491		0		1138/459Big			0	Normal	Bin	957	953	771	776	0.463	0.634	0	0	4047/1250	3834/1206	0.3	0.3	3	Normal	Bin	965	964	774	778 (high)	0.485	0.634	0	0	3923 1240	3863/1231							959		773 (high)		0.696		0		3820 1223			0	Normal	Bin	951	-	790	-	0.423	-	0	-	3163/1039	-
