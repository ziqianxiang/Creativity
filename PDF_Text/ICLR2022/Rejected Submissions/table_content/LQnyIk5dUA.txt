Table 1: Stochastic gradient complexity for finding an -approximate solution of nonconvex prob-lems (1), under Assumption 1Algorithms	Stochastic gradient complexity			Full gradient computationGD (Nesterov, 2004)	O( nL∆0)			Computed for every iterationSVRG (Reddi et al., 2016; Allen-Zhu & Hazan, 2016), SCSG (Lei et al., 2017), SVRG+ (Li & Li, 2018)	O	n + n*LA'		Computed for the initial point and periodically computed for every l iterationsSNVRG (Zhou et al., 2018), Geom-SARAH (Horvath et al., 2020)	Oe	(n + √¾δ0 )		Computed for the initial point and periodically computed for every l iterationsSPIDER (Fang et al., 2018), SpiderBoost (Wang et al., 2018), SARAH (Pham et al., 2019), SSRGD (Li, 2019), PAGE (Li et al., 2021)	O	(n + √nL∆0 )		Computed for the initial point and periodically computed for every l iterationsZeroSARAH (this paper, Corollary 1)	O	(n + √¾δ0 )		Only computed once for the initial point1ZeroSARAH (this paper, Corollary 2)	。（	√n(L∆0+G0)		Never computed 21 In Corollary 1, ZeroSARAH only computes the full gradient Vf (x0) = 1 Pn=I Vfi(x0)once for the initial point x0, i.e., minibatch size bo = n, and then bk ≡ √n for all iterationsk ≥ 1 in Algorithm 2.
Table 2: Stochastic gradient complexity for finding an -approximate solution of distributed non-convex problems (2), under Assumption 2Algorithms	Stochastic gradient complexity		Full gradient computationDC-GD 1 (Khaled & Richtarik, 2020; Li & Richtarik, 2020)	O( mL∆∆0)		Computed for every iterationD-SARAH 2 (Cen et al., 2020)	O (m + √m log2mLA0 )		Computed for the initial point and periodically computed across all n clientsD-GET 2 (Sun et al., 2020)	O (m +呼今)		Computed for the initial point and periodically computed across all n clientsSCAFFOLD 3 (Karimireddy et al., 2020)	O (m + nm3 堂	)	Only computed once for the initial pointDC-LSVRG/DC-SAGA 1 (Li & RichtOrik, 2020)	O (m+m2/3 堂	)	Computed for the initial point and periodically computed across all n clientsFedPAGE 3 (Zhao et al., 2021)	O (m +恭堂)		Computed for the initial point and periodically computed across all n clients(Distributed) SARAH/SPIDER/SSRGD 4 (Nguyen et al., 2017; Fang et al., 2018; Li, 2019)	O (m + P堂		Computed for the initial point and periodically computed across all n clientsD-ZeroSARAH (this paper, Corollary 3)	O (m + Pm堂)		Only computed once for the initial pointD-ZeroSARAH (this paper, Corollary 4)	O (Pf lδο+g0 )		Never computed1 Distributed compressed methods. Here we translate their results to this distributed setting (2).
Table 3: Metadata of datasetsDataset	n (# of datapoints)	d (# of features)a9a	32561	123abalone	4177	8mg -	1385	6mushrooms	8Γ24	∏2phishing	ΓΓ055	68pyrim	74	27triazines	186	60w8a	49749	300A.2 Experiments for the distributed settingBefore presenting the experimental results in the distributed setting (2), we also need a distributedvariant of SARAH-type methods in order to compare with our distributed variant of ZeroSARAH.
