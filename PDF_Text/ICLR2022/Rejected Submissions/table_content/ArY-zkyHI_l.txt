Table 1: Vanilla-Ensemble diversity testing: successful '∞-adversarial attack. Each column shows themisclassification samples out of 1000. The first (resp. second) row corresponds to '∞ adversarial attacksgenerated from model 2 (resp. vanilla-ensemble). The last row relates to clean accuracy with no attack.
Table 2: MAT diversity testing: successful '∞ adversarial attack. Each column shows the misclassificationsamples out of 1000. The first (resp. second) row corresponds to '∞ adversarial attacks generated fromsub-model 2 (resp. MAT). The last row relates to clean accuracy with no attack.
Table 3: Testing: Robustness accuracy of MATand its sub model: each row corresponds to dif-ferent attacks; and each column depicts the ro-bustness accuracy of MAT and its sub model.
Table 4: Testing on MNIST: each row corresponds to different attacks; each column compares the robustnessaccuracy of MAT with different baseline models.
Table 5: Testing on CIFAR-10: each row corresponds to different attacks; each column compares therobustness accuracy of MAT with different baseline models.
Table 6: Computation comparison between different methods (for each batch of data, i.e., each iteration of theouter minimization)Methods	Forward passes	Backwards passesStandard Training	1	1Standard MIMO Training [8]	1	1Vanilla AT (K-step PGD) [17]	K+1	K+1M-Vanilla Ensemble AT (K-step PGD)	M(K + 1)	M(K+1)Multi-perturbation AT (K-step PGD) [27]	MK + M	MK + MM-MSD AT (K-step PGD) [18]	(1+M)K+1	K+1M-MIMO AT without Approx. AT(K-step PGD)	K+1	MK + 1(Ours) MAT: M-MIMO Approx. AT (K-step PGD)	K+1	K+1(Ours) M-MIMO MSD (K-step PGD)	(1+M)K+1	K+1C Experiments settingC.1 Hyperparameters for training the modelsModels. We use ResNet18 [9] for all experiments on MNIST dataset. We also reproduce MSD results usingthe same neural network in their original paper. For CIFAR10, we use ResNet50.
Table 7: The wall clock time for training the model. All the models are training using ResNet-18 (resp.
Table 8: Three sub-models trained with same Adversarial Attacks on MNIST: the first row shows the cleanaccuracy; the remaining rows corresponds to different attacks; different column compares the robustnessaccuracy of '∞ AT (resp. '2 AT or MSD) with MAT('∞) (resp. MAT('2) or MAT+MSD), where MAT('∞)(resp. MAT('2)) denotes MAT with each sub model trained using '∞-attack (resp. '2-attack), and MAT+MSDdenotes MAT with each sub model trained using MSD.
Table 9: Vanilla-Ensemble diversity testing: successful '2-adversarial attack. Each column shows themisclassification samples out of 1000. The first (resp. second) row corresponds to `2 adversarial attacksgenerated from model 2 (resp. vanilla-ensemble). The last row relates to clean accuracy with no attack.
Table 10: MAT diversity testing: successful `2 adversarial attack. Each column shows the misclassificationsamples out of 1000. The first (resp. second) row corresponds to '∞ adversarial attacks generated fromsub-model 2 (resp. MAT). The last row relates to clean accuracy with no attack.
Table 11: Vanilla-Ensemble diversity testing: successful '1-adversarial attack. Each column shows themisclassification samples out of 1000. The first (resp. second) row corresponds to '∞ adversarial attacksgenerated from model 2 (resp. vanilla-ensemble). The last row relates to clean accuracy with no attack.
Table 12: MAT diversity testing: successful '1 adversarial attack. Each column shows the misclassificationsamples out of 1000. The first (resp. second) row corresponds to '∞ adversarial attacks generated fromsub-model 2 (resp. MAT). The last row relates to clean accuracy with no attack.
