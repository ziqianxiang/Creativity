Table 1: Test Accuracy in the Byzantine SettingDataset	Distri- bution	sign- SGD	Co- Med	Pro- posedFashion-	i.i.d.	61.5%	77.7%	91.4%MNIST	non-i.i.d	61.0%	73.4%	89.4%CIFAR-	i.i.d.	13.5%	29.3%	76.6%10	non-i.i.d	11.0%	28.7%	72.0%Table 2: Effect of the Normalization FunctionFashion- MNIST	a				0.5	1.5	2.5	10float i.i.d. binary	90.7%	90.6%	90.0%	88.2%	88.7%	90.4%	89.9%	88.2%non- float	87.3%	86.9%	85.7%	85.0%i.i.d. binary 83.3%		85.5%	85.2%	84.6%qm. We set α = 0.5 unless noted otherwise. We use a LeNet-5 architecture for Fashion-MNISTand a VGG-7 architecture for CIFAR-10. Results are obtained over three repetitions.
Table 2: Effect of the Normalization FunctionFashion- MNIST	a				0.5	1.5	2.5	10float i.i.d. binary	90.7%	90.6%	90.0%	88.2%	88.7%	90.4%	89.9%	88.2%non- float	87.3%	86.9%	85.7%	85.0%i.i.d. binary 83.3%		85.5%	85.2%	84.6%qm. We set α = 0.5 unless noted otherwise. We use a LeNet-5 architecture for Fashion-MNISTand a VGG-7 architecture for CIFAR-10. Results are obtained over three repetitions.
Table 3: Test Accuracy of TNN and BNN	Table 4: Forward Pass EfficiencyD ∙	∙ Distri-	BNN TNN ataset bution	Neural Weight Adds Muls Energy Net	Type	(mJ)Fashion- i.i.d.	91.1%	91.9% MNIST	non-i.i.d	88.3%	89.4%	τ z∙u float	1.7×109 1.8×109 8.1 LeNet5 binary 1.7 × 109 1.0 × 10* 1 * * * 5 * 7 1.5CIFAR- i.i.d.	80.5%	82.5% 10	non-i.i.d	74.6%	77.6%	「r float	4.8×1010 5.4×1010 242.9 VGG-7 binary	4.8×1010 2.1×105 43.3Normalization Function. From Remark 4, we know that the normalization function can influencethe model convergence. We empirically examine the impact in this experiment. For normalizationfunction 夕(x) = tanh(ax), We choose a from {0.5,1.5, 2.5,10}. We test the model accuracy after20 communication rounds on Fashion-MNIST. The results are shown in Table 2. As a increases,the linear region of the normalization function shrinks, and the algorithm converges sloWer dueto a larger c2 . On the other hand, the gap betWeen the model With normalized Weight we and theone With binary Weight w also decreases due to smaller quantization errors. A good choice of thenormalization function should take this trade-off into consideration.
