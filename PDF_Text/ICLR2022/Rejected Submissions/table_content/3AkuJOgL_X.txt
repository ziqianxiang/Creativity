Table 1: Ablation of different FedRBN components. Standard deviations are enclosed in brackets.
Table 2: Benchmarks of robustness propagation, where we measure the computation time (T ) bycounting Ã—1012 times of float add-or-multiplication operations (FLOPs).
Table 3: Compare FedRBN versusefficient federated AT on Digits.
Table 4: Evaluation of RA with various attacks on Digits. nand are the step number and the magnitude of attack.
Table 5: Evaluation with different FL configurations.
Table 7:	Network architecture for Digits dataset.
Table 8:	Network architecture for DomainNet dataset.
Table 9: Comparison to baselines on the Office-Caltech10dataset. Standard deviations are reported in brackets.
Table 10: Comparison to robustness transferring by fine-tuning (FT).
Table 11: Results and detailed configurations of Fig. 1b on the 5-domain Digits dataset. FedAvg andFedBN corresponds to FATAvg and FATBN in the figure.
Table 12: The robust accuracy of FedRBN under joint PGD attacks. Baseline results are present withPGD attacks. Standard deviations are included in brackets.
Table 13: Detection accuracy by PGD and joint PGDattacks.
Table 14: Evaluation with different FLconfigurationsB	E	method	RA	SA10	1	FATBN	50.9	83.9	1	FedRBN	60.0	82.810	4	FATBN	42.0	75.8	4	FedRBN	56.3	76.110	8	FATBN	30.9	63.1	8	FedRBN	53.4	68.450	1	FATBN	37.0	85.8	1	FedRBN	53.2	84.5100	1	FATBN	35.7	85.3	1	FedRBN	53.0	83.822Under review as a conference paper at ICLR 2022D Additional Experiments for RebuttalD. 1 Partial participantsIn reality, we can not expect that all users are available for training in each round. Therefore, itis important to evaluate the federated performance when only a few users can contribute to thelearning. To simulate the scenario, we uniformly sample a number of users without replacement per
Table 15: Robustness propagation using ResNet18.
