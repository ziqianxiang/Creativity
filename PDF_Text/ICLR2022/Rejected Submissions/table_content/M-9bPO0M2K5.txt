Table 1: Comparison of test accuracy (%) on CIFAR-10. ‘Naive’ indicates training on imbalanceddata and OS and US denote oversampling of minority classes and undersampling of majority classes,respectively. We consider two imbalance scenarios: moderate imbalance (Mod. Imb.) and severeimbalance (Sev. Imb.). Meta-B denotes MetaBalance, CMix and OS-CMix denote CutMix andCutMix with oversampling.
Table 2: AUC-ROC of various training algorithms on the credit-card fraud detection and loan defaultprediction tasks. MetaBal refers to the MetaBalance routine with undersampling in the outer loopand MS-MetaBal indicates the use of the best performing samplers in both loops. Bold figures reflectthe row maximium.
Table 3: Accuracy of face recognition models. We compare models trained in a naive way, trainedwith oversampling, and trained using our MetaBalance routine.
Table 4: Learning rates that produces the best results for each of the popular re-sampling techniquesDatasetSampling Method	CC Fraud	Loan DefaultSimple	0.1	0.05SMOTE	0.1	0.1BorderlineSMOTE	0.1	0.1SVMSmote	0.1	0.1ADASYN	0.1	0.1Over-sampling	0.05	0.1Cluster-Centroids	0.01	0.01Under-sampling	0.1	0.1NearMiss	0.05	0.05AllKNN	0.1	0.05SMOTEENN	0.02	0.05and create a balanced validation dataset by removing different percentages (1%, 5%, 10% and 20%)of data, and for each combination we use SGD same as previous setting with a range of learning rates(0.01, 0.02, 0.05 and 0.1) and finally report the best results which we get when we use a learning rateof 0.02 and use 20% of the data for validation. For the loss re-weighting strategy we use a range ofβ (0.9999, 0.999, 0.99 and 0.9) and a range of learning rates (0.01, 0.02, 0.05 and 0.1) and reportresults on best combination which were 0.9 and 0.01 respectively. For MetaBalance, we use SGD
Table 5: The number of channels in each layer of the feed-forward neural networks used for credit-cardfraud detection.
Table 6: AUC-ROC for other training algorithms on the credit-card fraud detection and loan defaultprediction tasks.
Table 7: Standard error of AUC-ROC for credit card fraud detectionDataset	Naive	Over-S	Under-S	Sampling Method				MetaBal	MS-MetaBal				Smote	SVMSmote	AllKNN	CC		CC Fraud	0.006	0.003	0.003	0.008	0.003	0.003	0.004	0.004	0.002Loan Default	0.009	0.013	0.004	0.008	0.011	0.002	0.009	0.003	0.004Table 8: The Standard Errors of Test Accuracy for the Cifar 10 Experiments	Naive	Method									Meta-B		OS	US	mixup	CMix	OS-mixup	OS-CMix	MWN	LRwt	M2M	Mod. Imb.	0.806	0.837	0.096	0.523	0.299	0.471	0.352	0.826	2.00	0.366	0.321Sev. Imb.	0.238	0.358	0.309	0.109	0.095	0.340	0.070	0.953	0.564	0.622	0.165A.6 Compute resourcesIn order to train using MetaBalance, for both severe and moderate class imbalance on CIFAR-10,we require approximately 100 Nvidia GeForece RTX 2080Ti GPU hours. For both credit card fraudand loan detection we require less than 2 hours of 2080Ti compute time. For facial recognition, werequire 52 2080Ti GPU hours.
Table 8: The Standard Errors of Test Accuracy for the Cifar 10 Experiments	Naive	Method									Meta-B		OS	US	mixup	CMix	OS-mixup	OS-CMix	MWN	LRwt	M2M	Mod. Imb.	0.806	0.837	0.096	0.523	0.299	0.471	0.352	0.826	2.00	0.366	0.321Sev. Imb.	0.238	0.358	0.309	0.109	0.095	0.340	0.070	0.953	0.564	0.622	0.165A.6 Compute resourcesIn order to train using MetaBalance, for both severe and moderate class imbalance on CIFAR-10,we require approximately 100 Nvidia GeForece RTX 2080Ti GPU hours. For both credit card fraudand loan detection we require less than 2 hours of 2080Ti compute time. For facial recognition, werequire 52 2080Ti GPU hours.
