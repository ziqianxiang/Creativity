Table 1: Datasets, models and neighborhoods used in experiments. RF→ Random Forest, NN→Neural Network and NB→ Naive Bayes.
Table 2: Below we see three example positive sentiment sentences from the Rotten Tomatoes dataset.
Table 3: Comparing the different methods using metrics infidelity (INFD), generalized infidelity(GI), coefficient inconsistency (CI), class attribution consistency (CAC) and unidirectionality (Υ). ↑indicates higher value for the metric is better, and J indicates lower is better. Results better by ≥ 1%are bolded. LINEX is better than baselines in 18 out of 35 cases, and worse only in 5 cases. Plotsshowing behavior of these metrics with varying neighborhood size, number of environments andkernel width are in Appendix C.
Table 4: Comparing the different methods using metrics infidelity (INFD), generalized infidelity(GI), coefficient inconsistency (CI), class attribution consistency (CAC) and unidirectionality (Υ).
Table 5: Comparing the different methods using metrics infidelity (INFD), generalized infidelity(GI), coefficient inconsistency (CI), class attribution consistency (CAC) and unidirectionality (Υ).
