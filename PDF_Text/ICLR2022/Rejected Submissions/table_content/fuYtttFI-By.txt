Table 1: Quality of reconstructed volumes after optimizing microscope parameters to image sampleType D on 256 × 256 pixel camera (mean ± s.e.m., n			10)		Microscope	Reconstruction	LHNMSE 1	MS-SSIM ↑	PSNR ↑	Time 1 (s)FourierNet2D	FourierNet3D	0.6409 ± 0.0213	0.955 ± 0.004	34.78 ± 0.88	0.71FourierNet2D	FourierUNet3D	0.6325 ± 0.0222	0.956 ± 0.003	34.74 ± 0.83	1.37FourierNet2D	UNet3D	0.7659 ± 0.0130	0.922 ± 0.008	30.06 ± 0.93	3.68UNet2D	UNet3D	0.7120 ± 0.0160	0.913 ± 0.009	29.17 ± 1.13	3.68We compare optimizing microscope parameters φ with two neural networks: 1) using our FourierNetwith 2D convolutions (FourierNet2D) and 2) using a vanilla UNet with 2D convolutions (UNet2D).
Table 2: Sample specific microscope parameter optimization across 3 different zebrafish sample typesimaged with 512 × 512 pixel camera (mean PSNR (top), MS-SSIM (bottom) ± s.e.m., n = 10).
Table 3: Quality of natural image reconstruction on the DiffuserCam Lensless Mirflickr Dataset(mean ± s.e.m., n = 999). Superscripts denote loss function: 1 MSE,2 MSE+LPIPS.
Table 4: Specifications of all zebrafish datasets Type A, B, C, D for reconstruction				Dataset	Camera (px)	Height (planes)	Span (z, y, x) (μm)	Aperture Diameter (μm)Type A	512 ×512	12	(25, 832, 832)	386Type B	512 × 512	128	(250, 832, 832)	386Type C	512 ×512	128	(250, 832, 832)	-Type D	256 × 256	96	(200,416,416)	193Parallelizing imaging and reconstruction Furthermore, because this simulation can become tooexpensive in memory to fit on a single device, we generally perform the simulation, reconstruction,and loss calculation in parallel for both training modes. Therefore, any variable that has a s subscriptrefers to a list of chunks of that variable that will be run on each device. A j superscript indicatesa particular chunk for GPU j . For example zs is a list of plane indices to be imaged/reconstructed,and zsj is the jth chunk of plane indices that will be imaged/reconstructed on GPU j . We denoteparallel for any operations that are performed in parallel and scatter for splitting data intochunks and spreading across multiple GPUs. Imaging can be cleanly parallelized: chunks of aPSF and sample can be partially imaged on multiple GPUs independently because the convolutionoccurs per plane, then finally all partial images can be summed together onto a single GPU. Thereconstructions can similarly take the final image and reconstruct partial chunks (as well as calculatelosses on partial chunks) of the volume independently per device. We implicitly gather data tothe same GPU when computing sums (P) or means (E). The functions parallel image andcompute PSF follow the definitions above in equations 14 and 12. In the algorithms shown here,
Table 5: Type D experiment training timesNetwork	Optimizing	# parameters	# train steps	Train step time (s)	Total time (h)FourierNet2D	θ,φ	〜4.2 X 107	106	〜0.8	〜222FourierNet3D	θ	〜6.3 X 107	106	〜0.4	~ 111FourierUNet3D	θ	〜8.4 X 107	106	〜0.7	~ 194UNet2D	θ,φ	〜4.0 X 107	106	〜1.3	~ 361UNet3D	θ	〜1.0 X 108	106	~ 0.8	~ 222A.4 Details for FourierNets outperform UNets for engineering non-localoptical encoders and 3D snapshot microscopy volume reconstructionFor our experiments in Sections 3.1 and 3.2, we use 40 planes at 5μm resolution in Z and therefore 40reconstruction networks to train PSFs. When training reconstruction networks only to produce thehigher quality reconstructions, we use 96 planes at 1μm resolution in Z (chosen so that the planesactually span 200 μm in z). We train in both settings without any sparse planewise gradients, meaningwe image and reconstruct all 40 or all 96 planes, respectively. We show details of all datasets used fortraining reconstructions in Table 4.
Table 6: Type A, B, C experiment training timesNetwork	Optimizing	# parameters Type # train steps Train step time (s) Total time (h)FourierNet2D	θ,φ	〜1.7 X 108 A	5.8 X 105	〜1.1	〜177FourierNet3D	θ (fixed φ for A)	〜3.4 x 108 A 〜2.6 x 105	〜1.6	〜116FourierNet3D	θ (fixed φ for A)	〜3.4 x 108 B 〜1.3 x 105	〜1.6	〜58FourierNet3D	θ (fixed φ for A)	〜3.4 x 108 C 〜1.3 x 105	〜1.6	〜58FourierNet2D	θ,φ	〜1.7 X 108 B	5.8 X 105	〜1.1	〜177FourierNet3D	θ (fixed φ for B)	〜3.4 X 108 A 〜1.2 X 105	〜1.6	〜53FourierNet3D	θ (fixed φ for B)	〜3.4 x 108 B	106	〜1.6	〜444FourierNet3D	θ (fixed φ for B)	〜3.4 x 108 C 〜5.0 x 105	〜1.6	〜222FourierNet2D	θ,φ	〜1.7 x 108 C	5.8 x 105	〜1.1	〜177FourierNet3D	θ (fixed φ for C)	〜3.4 x 108 A 〜3.4 x 105	〜1.6	〜151FourierNet3D	θ (fixed φ for C)	〜3.4 x 108 B 〜3.4 x 105	〜1.6	〜151FourierNet3D	θ (fixed φ for C)	〜3.4 x 108 C 〜3.7 x 105	〜1.6	〜164Table 7: FoUrierNet2D detailed architecture (1 per plane)Layer type	Kernel size	Stride	Notes	Shape (C, D, H, W)InputScaling	-	-	scale: 0.01	(1, 1, 256, 256)FourierConv2D	(256, 256)	(2, 2)	-	(8, 1, 256, 256)LeakyReLU	-	-	slope: -0.01	(8, 1, 256, 256)BatchNorm2D	-	-	-	(8, 1, 256, 256)
Table 7: FoUrierNet2D detailed architecture (1 per plane)Layer type	Kernel size	Stride	Notes	Shape (C, D, H, W)InputScaling	-	-	scale: 0.01	(1, 1, 256, 256)FourierConv2D	(256, 256)	(2, 2)	-	(8, 1, 256, 256)LeakyReLU	-	-	slope: -0.01	(8, 1, 256, 256)BatchNorm2D	-	-	-	(8, 1, 256, 256)Conv2D	(11, 11)	(1, 1)	-	(1, 1, 256, 256)ReLU	-	-	-	(1, 1, 256, 256)InputRescaling	-	-	scale: 0.01	(1, 1, 256, 256)Table 8: FoUrierNet3D detailed architecture (8 GPUs)Layer type	Kernel size	Stride	Notes	Shape (C, D, H, W)InputScaling	-	-	scale: 0.01	(1, 1, 256, 256)FourierConv2D	(256, 256)	(2, 2)	-	(60, 1, 256, 256)LeakyReLU	-	-	slope: -0.01	(60, 1, 256, 256)BatchNorm2D	-	-	-	(60, 1, 256, 256)Reshape2D3D	-	-	-	(5, 12, 256, 256)Conv3D	(11, 7, 7)	(1, 1, 1)	-	(5, 12, 256, 256)LeakyReLU	-	-	slope: -0.01	(5, 12, 256, 256)BatchNorm3D	-	-	-	(5, 12, 256, 256)Conv3D	(11, 7, 7)	(1, 1, 1)	-	(1, 12, 256, 256)
Table 8: FoUrierNet3D detailed architecture (8 GPUs)Layer type	Kernel size	Stride	Notes	Shape (C, D, H, W)InputScaling	-	-	scale: 0.01	(1, 1, 256, 256)FourierConv2D	(256, 256)	(2, 2)	-	(60, 1, 256, 256)LeakyReLU	-	-	slope: -0.01	(60, 1, 256, 256)BatchNorm2D	-	-	-	(60, 1, 256, 256)Reshape2D3D	-	-	-	(5, 12, 256, 256)Conv3D	(11, 7, 7)	(1, 1, 1)	-	(5, 12, 256, 256)LeakyReLU	-	-	slope: -0.01	(5, 12, 256, 256)BatchNorm3D	-	-	-	(5, 12, 256, 256)Conv3D	(11, 7, 7)	(1, 1, 1)	-	(1, 12, 256, 256)ReLU	-	-	-	(1, 12, 256, 256)InputRescaling	-	-	scale: 0.01	(1, 12, 256, 256)trained all networks for Type D for the same number of iterations (more than necessary for PSFs tomeaningfully converge)2.
Table 9: FourierUNet3D detailed architecture (8 GPUs)						Scale	Repeat	Layer type	Kernel size	Stride	Notes	Shape (C, D, H, W)1	1	InputScaling	-	-	scale: 0.01	(1, 1, 256, 256)1	1	Multiscale FourierConv2D + ReLU + BatchNorm2D	(256, 256)	(2, 2)	-	(60, 1, 256, 256)2			(128, 128)	(2, 2)		(60, 1, 128, 128)3			(64, 64)	(2, 2)		(60, 1, 64, 64)4			(32, 32)	(2, 2)		(60, 1, 32, 32)4	1	Reshape2D3D	-	-	-	(5, 12, 32, 32)3	1	Upsample2D	-	-	-	(5, 12, 64, 64)3	2	Conv3D + ReLU + BatchNorm3D	(11, 7, 7)	(1, 1, 1)	-	(5, 12, 64, 64)2	1	Upsample2D	-	-	-	(5, 12, 128, 128)2	2	Conv3D + ReLU + BatchNorm3D	(11, 7, 7)	(1, 1, 1)	-	(5, 12, 128, 128)1	1	Upsample2D	-	-	-	(5, 12, 256, 256)1	2	Conv3D + ReLU + BatchNorm3D	(11, 7, 7)	(1, 1, 1)	-	(5, 12, 256, 256)1	1	Conv3D + ReLU	(1, 1, 1)	(1, 1, 1)	-	(1, 12, 256, 256)1	1	InputRescaling	-	-	scale: 0.01	(1, 12, 256, 256)producing the 3D reconstruction output. We show a diagram of this architecture in Figure 1C, anddetails of this architecture in Table 9.
Table 10: UNet2D detailed architecture (1 per plane)						Scale	Repeat	Layer type	Kernel size	Stride	Notes	Shape (C, D, H, W)1	1	InputScaling	-	-	scale: 0.01	(1, 1, 256, 256)1	1	Conv2D + ReLU + BatchNorm2D	(7, 7)	(1, 1)	-	(12, 1, 256, 256)1	1	Conv2D + ReLU + BatchNorm2D	(7, 7)	(1, 1)	-	(24, 1, 256, 256)2	1	MaxPool2D	(2, 2)	(2, 2)	-	(24, 1, 128, 128)2	2	Conv2D + ReLU + BatchNorm2D	(7, 7)	(1, 1)	-	(24, 1, 128, 128)n	1	MaxPool2D	(2, 2)	(2, 2)	-	(24, 1, 22561, 22561)n	2	Conv2D + ReLU + BatchNorm2D	(7, 7)	(1, 1)	-	(24,1, ɪ,科)8	1	MaxPool2D	(2, 2)	(2, 2)	-	(24, 1,2,2)8	2	Conv2D + ReLU + BatchNorm2D	(7, 7)	(1, 1)	-	(24, 1,2,2)7	1	Upsample2D	-	-	-	(24, 1,4,4)7	2	Conv2D + ReLU + BatchNorm2D	(7, 7)	(1, 1)	-	(24, 1,4,4)n	1	Upsample2D	-	-	-	(24, 1,部,部)n	2	Conv2D + ReLU + BatchNorm2D	(7, 7)	(1, 1)	-	(24,1,2n56i, 2n56i)1	1	Upsample2D	-	-	-	(24, 1, 256, 256)1	2	Conv2D + ReLU + BatchNorm2D	(7, 7)	(1, 1)	-	(24, 1, 256, 256)1	1	Conv2D + ReLU	(1, 1)	(1, 1)	-	(1, 1, 256, 256)1	1	InputRescaling	-	-	scale: 0.01	(1, 1, 256, 256)planes are chosen randomly at every iteration from the 64 total possible planes, making potentially
Table 11: UNet3D detailed architecture (8 GPUs)						Scale	Repeat	Layer type	Kernel size	Stride	Notes	Shape (C, D, H, W)1	1	InputScaling	-	-	scale: 0.01	(1, 1, 256, 256)1	1	Conv2D + ReLU + BatchNorm2D	(7, 7)	(1, 1)	-	(30, 1, 256, 256)1	1	Conv2D + ReLU + BatchNorm2D	(7, 7)	(1, 1)	-	(60, 1, 256, 256)2	1	MaxPool2D	(2, 2)	(2, 2)	-	(60, 1, 128, 128)2	2	Conv2D + ReLU + BatchNorm2D	(7, 7)	(1, 1)	-	(60, 1, 128, 128)3	1	MaxPool2D	(2, 2)	(2, 2)	-	(60, 1, 64, 64)3	2	Conv2D + ReLU + BatchNorm2D	(7, 7)	(1, 1)	-	(60, 1, 64, 64)4	1	MaxPool2D	(2, 2)	(2, 2)	-	(60, 1, 32, 32)4	2	Conv2D + ReLU + BatchNorm2D	(7, 7)	(1, 1)	-	(60, 1, 32, 32)4	1	Reshape2D3D	-	-	-	(5, 12, 32, 32)3	1	Upsample2D	-	-	-	(5, 12, 64, 64)3	2	Conv3D + ReLU + BatchNorm3D	(11, 7, 7)	(1, 1, 1)	-	(5, 12, 64, 64)2	1	Upsample2D	-	-	-	(5, 12, 128, 128)2	2	Conv3D + ReLU + BatchNorm3D	(11, 7, 7)	(1, 1, 1)	-	(5, 12, 128, 128)1	1	Upsample2D	-	-	-	(5, 12, 256, 256)1	2	Conv3D + ReLU + BatchNorm3D	(11, 7, 7)	(1, 1, 1)	-	(5, 12, 256, 256)1	1	Conv3D + ReLU	(1, 1, 1)	(1, 1, 1)	-	(1, 12, 256, 256)1	1	InputRescaling	-	-	scale: 0.01	(1, 12, 256, 256)
Table 12: FourierNet2D detailed architecture (1 per plane)Layer type	Kernel size	Stride	Notes	Shape (C, D, H, W)InputScaling	-	-	scale: 0.01	(1, 1, 512, 512)FourierConv2D	(512, 512)	(2, 2)	-	(5, 1, 512, 512)LeakyReLU	-	-	slope: -0.01	(5, 1, 512, 512)BatchNorm2D	-	-	-	(5, 1, 512, 512)Conv2D	(11, 11)	(1, 1)	-	(1, 1, 512, 512)ReLU	-	-	-	(1, 1, 512, 512)InputRescaling	-	-	scale: 0.01	(1, 1, 512, 512)A.6 Details for FourierNets outperform state-of-the-art for reconstructingnatural images captured by DiffuserCam lensless cameraWe performed no augmentations for this set of trainings reconstructing RGB color images of naturalscenes from RGB diffused images taken through a DiffuserCam [20]. We modified our FourierNet2Darchitecture to create the FourierNetRGB architecture and our FourierUNet2D architecture to create24Under review as a conference paper at ICLR 2022Table 13: FoUrierNet3D detailed architecture (8 GPUs)Layer type	Kernel size	Stride	Notes	Shape (C, D, H, W)InputScaling	-	-	scale: 0.01	(1, 1, 512, 512)FourierConv2D	(512, 512)	(2, 2)	-	(80, 1, 512, 512)
Table 13: FoUrierNet3D detailed architecture (8 GPUs)Layer type	Kernel size	Stride	Notes	Shape (C, D, H, W)InputScaling	-	-	scale: 0.01	(1, 1, 512, 512)FourierConv2D	(512, 512)	(2, 2)	-	(80, 1, 512, 512)LeakyReLU	-	-	slope: -0.01	(80, 1, 512, 512)BatchNorm2D	-	-	-	(80, 1, 512, 512)Reshape2D3D	-	-	-	(5, 16, 512, 512)Conv3D	(11, 7, 7)	(1, 1, 1)	-	(5, 16, 512, 512)LeakyReLU	-	-	slope: -0.01	(5, 16, 512, 512)BatchNorm3D	-	-	-	(5, 16, 512, 512)Conv3D	(11, 7, 7)	(1, 1, 1)	-	(1, 16, 512, 512)ReLU	-	-	-	(1, 16, 512, 512)InputRescaling	-	-	scale: 0.01	(1, 16, 512, 512)Table 14: DLMD experiment training times. Superscripts denote loss function: 1 MSE, 2MSE+LPIPS.
Table 14: DLMD experiment training times. Superscripts denote loss function: 1 MSE, 2MSE+LPIPS.
Table 15: FoUrierNetRGB detailed architectureLayer type	Kernel size	Stride	Notes	Shape (N, C, H, W)FourierConv2D	(270, 480)	(2, 2)	-	(4, 3, 270, 480)LeakyReLU	-	-	slope: -0.01	(4, 20, 270, 480)BatchNorm2D	-	-	-	(4, 20, 270, 480)Conv2D	(11, 11)	(1, 1)	-	(4, 64, 270, 480)BatchNorm2D	-	-	-	(4, 64, 270, 480)LeakyReLU	-	-	slope: -0.01	(4, 64, 270, 480)Conv2D	(11, 11)	(1, 1)	-	(4, 64, 270, 480)BatchNorm2D	-	-	-	(4, 64, 270, 480)LeakyReLU	-	-	slope: -0.01	(4, 64, 270, 480)Conv2D	(11, 11)	(1, 1)	-	(4, 3, 270, 480)ReLU	-	-	-	(4, 3, 270, 480)the FourierUNetRGB architecture, outlined in Table 15 and Table 16 respectively. Training details areshown in Table 14. Because these reconstructions are of 2D images only and required no microscopesimulation, we were able to use a batch size of 4 images per iteration.
Table 16: FoUrierUNetRGB detailed architectureScale	Repeat	Layer type	Kernel size	Stride	Notes Shape (N, C, H, W)1	1	Multiscale FourierConv2D + ReLU + BatchNorm2D	(270, 480)	(2, 2)	-	(4, 64, 270, 480)2			(135, 240)	(2, 2)	(4, 64, 135, 240)3			(67, 120)	(2, 2)	(4, 64, 67, 120)4			(33, 60)	(2, 2)	(4, 64, 33, 60)3	1	Upsample2D	-	-	-	(4, 64, 67, 120)3	2	Conv2D + ReLU + BatchNorm2D	(11, 11)	(1, 1)	-	(4, 64, 67, 120)2	1	Upsample2D	-	-	-	(4, 64, 135, 240)2	2	Conv2D + ReLU + BatchNorm2D	(11, 11)	(1, 1)	-	(4, 64, 135, 240)1	1	Upsample2D	-	-	-	(4, 64, 270, 480)1	2	Conv2D + ReLU + BatchNorm2D	(11, 11)	(1, 1)	-	(4, 64, 270, 480)1	1	Conv2D + ReLU	(1, 1)	(1, 1)	-	(4, 3, 270, 480)26Under review as a conference paper at ICLR 2022Figure 8: Slab views of a Type D example volume reconstruction, showing our methods (Fouri-erNet/FourierUNet) do the best job of reconstructing throughout the volume. Note that the UNetreconstructions are blurry across all slabs, with few exceptions. Colored boxes show which sampleplanes a particular slab comes from, corresponding to boxes in xz projection view at top. AnnotationMφ shows which network architecture was used for microscope optimization; annotation Rθ shows
