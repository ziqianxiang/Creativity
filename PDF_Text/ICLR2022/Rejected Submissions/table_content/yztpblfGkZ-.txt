Table 1: Results (mean accuracy ± stdev) onnode classification with different data splits (* andf denoting the results cited from (Zhu et al., 2020) and(Li et al., 2021), respectively).
Table 2: Results on graph classification with 20 runs for different datasets (#P/L denotes the numberof free parameters per hidden layer).
Table 3: Study on the order K of filters and the number of subspaces s per layer.
Table 4: Classification accuracy on CIFAR-10 andOgbg-molhiv (no edge attributes) datasets.
Table S1: Dataset statistics and properties (L indicates node categorical features and A denotes nodeattributes)._____________________________________________________________________________________________________	ENZ	D&D	PROT	NCI1	NCI109	MUTA	FRAN	CIFAR-10	Ogbg-molhivAvg |V|	32.63	284.32	39.06	29.87	29.68	30.32	16.90	117.63	25.51Avg |E|	62.14	715.66	72.82	32.30	32.13	30.77	17.88	564.86	27.47Node feature	L+A	L	L	L	L	L	A	A	ADim(feat)	3+18	89	3	37	38	14	780	5	9#Classes	6	2	2	2	2	2	2	10	2#Graphs	600	1,178	1,113	4,110	4,127	4,337	4,337	60,000	41,127Finally, a prediction module composed of a linear fully connected layer and a softmax layer makesthe prediction of the category of the input graph. The cross-entropy (represented as TΘ(G, Y )) isadopted as the loss function, which together with the regularization Ω(α) for diversity conditioncomposes the objective function:TΘ(G,Y) + Y Ω(α)	(S10)where Θ denotes all the free parameters and Y indicates ground truth categorical labels.
Table S2: Ablation study on the diversity regularization with BankGCN (K = 2, s = 8).
