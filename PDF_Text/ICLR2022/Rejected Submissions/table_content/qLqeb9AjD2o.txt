Table 1: Comparison of ACR and approximate certified test accuracy (%) on MNIST. For eachcolumn, we set our result bold-faced whenever the value improves the Gaussian baseline. We markthe highest and lowest values of certified accuracy at each radius in blue and red colors, respectively.
Table 2: Comparison of ACR and approximate certified test accuracy (%) on CIFAR-10. For eachcolumn, we set our result bold-faced whenever the value improves the Gaussian baseline. We markthe highest and lowest values of certified accuracy at each radius in blue and red colors, respectively.
Table 3: Comparison of ACR and approximate certified test accuracy (%) varying components ofCAT-RS on CIFAR-10. We assume σ = 0.5 in this experiment. The best ACR is bold-faced.
Table 4: Comparison of ACR and approximate certified test accuracy on MNIST for varying hyper-parameters of three different methods: Consistency, SmoothMix, and CAT-RS (ours). We assumeσ = 1.0 in this experiment. “Gaussian” indicates the baseline Gaussian training. Consistency andSmoothMix degenerates to Gaussian when their hyperparameter is set to 0.
Table 5: Comparison of ACR and approximate certified test accuracy (%) varying p0 on CIFAR-10.
Table 6: Comparison of ACR and approximate certified test accuracy (%) for varying λ on CIFAR-10. We assume σ = 0.5 in this experiment. For each column, we set the best value bold-faced.
Table 7: Comparison of ACR and approximative certified test accuracy (%) for varying M onCIFAR-10. We assume σ = 0.5 in this experiment.
