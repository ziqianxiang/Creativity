Table 1: Performance on graph-level classification tasks, scores are averaged over 5 runs. Bold andunderlined numbers highlight the top-2 performance. OOM indicates running out-of-memory on a56GB Nvidia A6000 GPU.
Table 2: Performance on node-level datasets, 20 runs averaged. Results of SSL methods with the bestperformance are highlighted in bold numbers. Left: Mean classification accuracy on transductivedatasets. Right: Micro-averaged F1 scores on larger-scale inductive datasets .
Table 3: Model performance when trained on a subset of nodes.
Table 4: Summary and statistics of common graph datasets for self-supervised learning.
Table 5: Model configurations for graph-level datasets.
Table 6: Model configurartions for node-level datasets.
Table 7: GIN results for Semi-supervised learning.
Table 8: GCN results for Semi-supervised learning.
Table 9: Effect of training with different objectives on graph-level datasets.
Table 10: Effect of performing concatenation with node features.
