Table 1: Test loss and accuracy across a suite of models on CIFAR-10 comparing normal SGDMwith Orthogonal-SGDM, standard error across five runs.
Table 2: Test loss and accuracy of a resnet20, as in He et al. (2015), on CIFAR-10; hyper-parametertuned to normal SGDM vs Orthogonal-SGDM, standard error across five runs. Mini-batch size of128, see section 3.6 for why this hyper-parameter value impedes Orthogonal-SGDM, learning-rateof 0.1, momentum of 0.9, weight-decay of 10-4, and a learning rate schedule of ×0.1 at epochs100, 150 for 200 epochs.
Table 3: Test accuracy across a suite of hyper-parameter sets on CIFAR-10 on a resnet20, standarderror across five runs. For Adam β2 = 0.99.
Table 4: Test accuracy for several models trained with SGDM, Normalised SGDM, ComponentNormalised SGDM, and Orthogonal-SGDM; trained as in section 2.3.1.
Table 5: Test accuracy and loss for Orthogonal-SGDM on CIFAR-10 when orthogonalising all layersvs orthogonalising just the convolutional layers. Trained as in section 2.3.1, standard error acrossfive runs.
Table 6: Test loss across a suite of hyper-parameter sets on CIFAR-10 on a resnet20, standard erroracross five runs. For Adam β2 = 0.99.
Table 7: Test loss for several models trained with SGDM, Normalised SGDM, Component Nor-malised SGDM, and Orthogonal-SGDM.
