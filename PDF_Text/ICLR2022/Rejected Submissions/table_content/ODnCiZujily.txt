Table 1: Certified test accuracy (%) of PGD-trained models on CIFAR10 through ADMM,the Lagrangian decomposition methods (Dvijotham et al., 2018; Bunel et al., 2020b), andfast dual/linear (Wong et al., 2018; Xu et al., 2020) or interval bounds (Gowal et al., 2018).
Table 2: The percentage of actions from a deep Q-network that are certifiably robust tochanges in the state space for three RL tasks: Bankheist, Roadrunner, and Pong. Wecompare fast linear bounds (Linear) (Wong et al., 2018; Xu et al., 2020) and ADMM.
Table 3: Approximate verification time for solving the LP relaxation through ADMM.
Table 4: Certified accuracy of PGD-trained models on MNIST when using a computationallycheap bound (linear-based bounds (Wong et al., 2018; Xu et al., 2020)) vs. our method(ADMM)Model	Epsilon	Certified test accuracy (%)				Linear	ADMM	DiffMNIST-A	0.02	67.8	77.1	9.3	0.03	7.8	14.2	6.5MNIST-B	0.07	88.8	91.5	2.7	0.08	74.5	82.2	7.7	0.09	43.0	58.9	15.9	0.10	2.6	8.8	6.2bounds of the LP (Linear) (Wong et al., 2018; Xu et al., 2020), and interval bounds (IBP)(Gowal et al., 2018). We additionally compare to a suite of Lagrangian-based baselines, whoseeffectiveness at this scale was previously unknown. These methods include supergradientascent (Adam) (Bunel et al., 2020b), dual supergradient ascent (Dual Adam) (Dvijothamet al., 2018) and a variant thereof (Dual Decomp Adam) (Bunel et al., 2020b), and aproximal method (Prox) (Bunel et al., 2020a). Lagrangian-based baselines were given thesame computational budget as the ADMM solver, with further details in Appendix G.
Table 5: Comparison of computed bounds using LiRPA (Xu et al., 2020)) vs. our method(ADMM) on a ResNet18 for CIFAR10.
