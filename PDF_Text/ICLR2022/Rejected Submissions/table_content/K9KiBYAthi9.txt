Table 1: Network design of the proposed DMSANet.			Output	ResNet-50	DMSANet	112×112 56×56 56×56 28×28 14×14 7×7 1×1	7×7, 64 3×3 max poo 1×1,	64 3×3,	64 1×1, 256 1×1, 128 3×3, 128 1×1, 512 1×1,	256 3×3,	256 1×1, 1024 1×1,	512 3×3,	512 1×1, 2048 7×7 GAP,10	l 1. )(	7×7, 64 3×3 max pool 1×1,	64 ×3	DMSA, 64	× 3 1×1,	256 1×1,	128 × 4	DMSA, 128 × 4 1×1,	512 1×1,	256 × 6 DMSA, 256	× 6 1×1,	1024 1×1,	512 × 3 DMSA, 512	× 3 1×1,	2048 -dfc 7×7 GAP,1000-d fcWe use Residual Network along with FPN as the backbone network (Lin et al., 2017a) for objectdetection. The detectors we benchmark against are Faster RCNN (Ren et al., 2015), Mask RCNN(Heet al., 2017) and RetinaNet (Lin et al., 2017b) on MS-COCO dataset (Lin et al., 2014). StochasticGradient Descent is used as the optimizer with a weight decay of 1e-4, momentum is 0.9, and thebatch size is 16 per GPU for 10 epochs. The learning rate is set as 0.01 and is decreased by the factorof 10 every 10th epoch.
Table 6:6Under review as a conference paper at ICLR 2022Table 2: Comparison of various attention methods on ImageNet with ResNet50 as backbone in termsof network parameters(in millions), floating point operations per second (FLOPs), Top-1 and Top-5Validation Accuracy(%). The best records are marked in bold.
Table 2: Comparison of various attention methods on ImageNet with ResNet50 as backbone in termsof network parameters(in millions), floating point operations per second (FLOPs), Top-1 and Top-5Validation Accuracy(%). The best records are marked in bold.
Table 3: Comparison of various attention methods on ImageNet with ResNet 101 as backbone interms of network parameters(in millions), floating point operations per second (FLOPs), Top-1 andTop-5 Validation Accuracy(%). The best records are marked in bold.
Table 4: Comparison of object detection results on COCO val2017 using Faster RCNN detector. Thebest records are marked in bold.___________________________________________________Backbone	Params(M)	GFLOPs	AP	AP50	AP75	APS	APM	APLResNet-50	41.53	207.07	36.4	58.2	39.5	21.8	40.0	46.2SENet-50	44.02	207.18	37.7	60.1	40.9	22.9	41.9	48.2ECANet-50	41.53	207.18	38.0	60.6	40.9	23.4	42.1	48.0SANet-50	41.53	207.35	38.7	61.2	41.4	22.3	42.5	49.8FcaNet-50	44.02	215.63	39.0	61.1	42.3	23.7	42.8	49.6EPSANet-50(Small)	38.56	197.07	39.2	60.3	42.3	22.8	42.4	51.1EPSANet-50(Large)	43.85	219.64	40.9	62.1	44.6	23.6	44.5	54.0DMSANet	44.17	222.31	41.4	61.9	46.2	25.8	44.7	55.34.3	Instance Segmentation on MS COCOWe used Mask-RCNN (He et al., 2017) as benchmark on MS-COCO dataset (Lin et al., 2014).
Table 5: Comparison of object detection results on COCO val2017 using Mask RCNN detector. Thebest records are marked in bold.
Table 6: Comparison of object detection results on COCO val2017 using RetinaNet detector. Thebest records are marked in bold.
Table 7: Instance segmentation results of different attention networks by using the Mask R-CNN onCOCO. The best records are marked in bold.______________________________________Network	AP	AP5o	AP75	APS	APM	APLResNet-50	34.1	55.5	36.2	16.1	36.7	50.0SENet-50	35.4	57.4	37.8	17.1	38.6	51.8GCNet	35.7	58.4	37.6	-	-	-ECANet	35.6	58.1	37.7	17.6	39.0	51.8FcaNet	36.2	58.6	38.1	-	-	-SANet	36.1	58.7	38.2	19.4	39.4	49.0EPSANet-50(Small)	35.9	57.7	38.1	18.5	38.8	49.2EPSANet-50(Large)	37.1	59.0	39.5	19.6	40.4	50.4DMSANet	37.4	61.1	40.7	19.3	40.9	51.74.4	Ablation StudyThe ablation studies of our architecture is shown in Table 8. The results are best obtained usinginstance normalization. Both removing Fc() and using 1 × 1 Conv results in reduced performance ascompared to the original network. The earlier is because Fc() is used to enhance the performance ofindividual features while latter is because number of channels in each sub-feature is too few, so it isnot important to exchange information among different channels.
Table 8: Performance comparisons of our network using ResNet 50 as backbone with four options(i.e., original, using Batch Normalization, using Group Normalization, using shuffle normalization,eliminating Fc() and using 1 × 1 Conv to replace Fc() on ImageNet-1k in terms of GFLOPs andTop-1∕Top-5 accuracy (in %). The best records are marked in bold.
