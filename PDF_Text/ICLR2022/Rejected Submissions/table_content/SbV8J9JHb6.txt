Table 1: Performance of inference on garbled circuit models with binary versus ternary parameters.
Table 2: Number of parameters and corresponding sparsity and trained model test accuracy forMNIST (m1) architecture with various levels of scaling factor. The table reports the statistics of theexperiment in Figure 1b.
Table 3: Performance analysis of existing secure schemes for private neural network inference. Wecompare S oteria constructed on fixed model architectures with ternary parameters, as well asoptimal architectures constructed by Soteria, with the prior work. We provide the descriptionsof the model architectures in Table 6 . We use the same scaling factor for Soteria and XONNfor fixed model architectures (1.75 for m1, 4.0 for m2, 2.0 for m3, 2.0 for m4, 3.0 for m5, 2.0 form6), and use 3.0 for MNIST (Soteria) and CIFAR10 (Soteria) for the models constructed byour architecture search algorithm.
Table 4: (a) Runtime and communication cost of each operation based on their garbled circuit infer-ence. We also calculate the performance penalty factor (which we use in our regularized architecturesearch algorithm) as the average of the relative costs for each unit w.r.t the most expensive operation.
Table 5: Properties of secure computation cryptographic primitives: Partially and fully homomor-phic encryption schemes (PHE, FHE), Goldreich-Micali-Widgerson protocol (GMW), arithmeticsecret sharing (SS), and Yaoâ€™s garbled circuit (GC).
Table 6: Model architectures used in our experiments. Models m1-6 are used in the prior workon MNIST and CIFAR10 datasets, and we constructed the S oteria models using our regularizedarchitecture search algorithm.
Table 7: Overview of the existing private inference methods, including the cryptographic schemesused, precision of neural networks supported, number of parties involved, evaluation setup configu-ration and availability of code.
