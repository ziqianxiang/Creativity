Table 1: Results on Mini-ImageNet dataset. Our NC method outperforms other approaches whichbecomes clear as we move to larger architectures. We can also see that our linear classifier serves asa strong baseline and can be used to learn robust few-shot classifier.
Table 2: Comparison with (Wang et al., 2021) on Mini-ImageNet dataset. Note that both TRADESand CL use additional unlabelled data in a semi-supervised manner. Our method outperforms previousapproaches using a standard adversarial training procedure.
Table 3: Results on CIFAR-FS dataset. We can see our NC method outperforms compared toprevious approaches. This experiment uses the same attack parameters as (Goldblum et al., 2019).
Table 4: Comparison with (Wang et al., 2021) for Conv4 backbone on CIFAR-FS dataset. Comparingmethods that use same base training procedure (AT or TRADES ) , we can see that our NC methodoutperforms on Robust Accuracy under both 1-shot and 5-shot settings. This experiment shows thatour method can generalize to other adversarial training methods as well.
Table 5: Results on CUB dataset. We show that robustness transfers from base to novel datasetsunder fine-grained classification setting as well. Our Linear classifier serves as a strong baseline andour NC method outperforms on both metrics.
Table 6: Illustration of different configurations of Base and Novel training. Here we show results onResNet18 backbone on Mini-ImageNet dataset. WA represents Weight Averaging, DC representsDistribution Calibration and NC corresponds to to Nearest Centroid classifier.
Table 7: Extension to verifiably robust classifiers. We show that it is possible to train verifiably robustmodels for few-shot settings. This is an added advantage of our framework due to the similarity tostandard classifier training. Results are shown using ResNet18 backbone on CIFAR-FS dataset.
Table 8: Experiment where adversarial examples from few-shot data are included to perform adversar-ial training on the linear classifier. No Adv refers to clean examples used for learning the linear layer.
Table 9: Variation of attack iterationsVariation of Robust Accuracy with perturbation budget : To check for the absence of gradientmasking, we increase from 8/255 to 128/255 in Figure 1. As expected, we observe that both 1-shotand 5-shot accuracy drop to zero with increased . Note that we plot only the the mean accuracy over1000 different tasks.
Table 10: Results on TieredImageNet dataset.
