Table 1: Comparison of NLI tasks and αNLI tasks, where E, N, and C represent entailment, neutraland contradiction, respectivelyTask	Context	AnswerNLI	P: A man inspects the uniform of a figure in some East Asian country. H: The man is sleeping. P: An older and younger man smiling. H: TWo men are smiling and laughing at the cats playing on the floor. P: A soccer game with multiple males playing. H: Some men are playing a sport.	E,Nor C E, N orC E ,NorCαNLI	Oi： Dotty was being very grumpy. H1: Dotty ate something bad. H2: Dotty call some close friends to chat. O2: She felt much better afterwards.	H1 or H2Under this new ranking-based framework, (Paul & Frank (2020)) introduces a novel multi-headknowledge attention model which learns to focus on multiple pieces of knowledge at the same time,and is capable of refining the input representation in a recursive manner for αNLI.
Table 2: The format of data input and output in αNLI taskTaskInput FormatαNLI[CLS] Oi [SEP] Hi [SEP] O2 [SEP]Output FormatH1 or H2Hyperparameter details: Due to the difference in the amount of data, the focusing parameter andthe amount of training data will vary. For different training data, select the hyperparameter thatproduces the best performance on the test set. Specifically, the learning rate is fixed at 1e-6, thebatch size is fixed at 1, and the training batch will vary with the amount of training data. Traininguses Cross Softmax+Focal Loss. For the validation set, ACC and AUC are used for evaluation. Usethe results of five different seeds to evaluate the performance of the test set.
Table 3: Results on the αNLi task: The results are quoted from (Bhagavatula et al., 2020), L=LargeModel	DeV(ACC%)	Dev(AuC%)	Test(ACC%)Human Perf	-	-	91.40Majority	50.80	-	-GPT	62.70	-	62.30BERT-L	69.10	69.03	68.90RoBERTa-L	85.76	85.02	84.48L2R2	88.44	87.53	86.81MHKA	87.85	-	87.34Ours			RoBERTa-L+iMSL	89.20	92.50	87.83and the improvement of AuC is mainly attributed to the exploitation of the relationship between thehypotheses by the proposed information interaction layer.
