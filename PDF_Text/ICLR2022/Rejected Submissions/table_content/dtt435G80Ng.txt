Table 1: Quantization levels by representation (2-bit example)Case	Quantization levels	Representation-1-	{-2, -1,0, 1}	^CLQ2	{-1,0,1,2}	CLQ-alternative3	{-1,0, 1}	RSQ (Ternary)4	{-2,-1, 0,1, 2}	ESQ*5	{-2,-1,1, 2}	NSQ6	{-1.5, -0.5,0.5,1.5}	CSQ7	{-3, -1, 1, 3}		CSQ (SCaledby 2)*Note: ESQ requires more than 2 bits.
Table 2: List of values in the product term (2-bit example, unsigned activation)	W-A: CLQs -CLQu		 W-A: CSQ-CLQu	W (signed) A (unsigned)	{-2, -110,1} ,	{0,1, 2, 3}		{-1.5, -0.5, 0.5,1.5} ,	{0,1, 2, 3}	W ∙ A 一	{-6,-4,-3,-2,1, 0,1, 2, 3}	{-4.5, -3, -1.5, -1, -。5, 0,。5,1,1.5, 3, 4.5}4 Analysis of CSQ4.1	Improved Representational Capacity of CSQEven though both CSQ and CLQ have the same number of quantization levels, and therefore thesame representational capacity on the operand level, multiplication result, or the product of weightand activation, may have different representational capacity depending on the choice of quantizer.
Table 3: Number of unique values in the product term#bits	Unsigned Activation (W-A)		Signed Activation (W-A)			CLQs-CLQu	CSQ-CLQu	CLQs-CLQs	CSQ-CLQs	CSQ-CSQ2-bit	9	^^11 (+22.2%)	6	9 (+50.0%)	6 (0.0%)3-bit	35	43 (+22.9%)	18	31 (+72.2%)	20 (+11.0%)4-bit	120	155 (+29.2%)	60	105 (+75.0%)	66 (+10.0%)—o0O—X-X---------Of Z1	½	2	3( = Z CSQ)	( = ZCLQ)Figure 2:	Zero-point for CLQ and CSQ at 2-bit precision. Affine quantizer allows integer zero-pointonly (shown in green circles). In relaxed affine quantizer, zero-point can take any real value.
Table 4: Comparison of number representations: CLQ vs. CSQ (2-bit example)2-bit binary	CLQs	CLQu	CSQ00	0	0	--TT5^01	1	1	-0.510	-2	2	0.511	-1		3	1.5which has a very similar mathematical structure as a CLQ number, allowing us to use the same trickof changing the order of precision (n) and vector dimension (N) as in the inner-product computationof two CLQ numbers. Finally, we arrive at the following inner-product computation method (formore detail, see Appendix I):V ∙ X = (VH ∙ XH << 2) + (VH ∙ XL << 1) + (vl ∙ XH << 1) + Vl ∙ XL	(14)which is shown for the 2-bit case (n = 2). xH and xL (similarly for vH and vL) are the N-dimensional bit-vectors of X containing only the higher and lower bits only, respectively, and <<is the bitwise shift-left operation. Each product on the right-hand side of (14) can be computed onBNN hardware in a single cycle. Thus V ∙ X can be computed in four cycles, using an additionaladder/accumulator. It is worth mentioning that the same method as illustrated in (14) is also usedwhen computing the inner-product of two CLQ vectors.
Table 5: Comparison of CLQ and CSQ (ours) on ResNet-20 for CIFAR-10.
Table 6: Comparison of CLQ, CSQ and other quantization-aware training methods on ImageNet.
Table 7: Matrix multiplication runtime (size: 16384×16384) on Nvidia RTX 2080 TIKernel	Runtime (ms)	Relative SpeedcuBLAS	579.81 ± 9.16	11-bit	85.44 ± 11.99	6.82-bit CSQ	197.85 ± 6.82	2.92-bit CLQ	197.85 ± 10.20	2.96.6	GPU Implementation ResultsTo see the speedup on GPU, we have implemented three custom kernels that use concatenation andbitwise operations to compute matrix multiplication (see Appendix I.2). We compare these customkernels with cuBLAS. The first kernel is 1-bit CSQ, which is the same as 1-bit BNN. The secondand third kernels are 2-bit, each using CSQ and CLQ.
Table 8: Comparison of CSQ with affine quantizer using BRECQ on ImageNet.
Table 9: Comparison of CSQ vs. CLQ using knowledge distillation training on ImageNet.
