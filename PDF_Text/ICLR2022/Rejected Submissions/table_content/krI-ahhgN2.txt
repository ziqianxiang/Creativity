Table 1: The results of linear evaluation on ResNet-18 and ResNet-50 for various datasets. Inthe supervised setting, we compare our SelfCon-M and SelfCon-S with cross-entropy (CE) loss,supervised contrastive loss with multi-view (SupCon), and without multi-view (SupCon-S). Boldtype is for all the values of which the standard deviation range overlaps with that of the best accuracy.
Table 2: The classification accuracy onResNet-18 and ResNet-50 for ImageNet-	80100. Parentheses indicate the performance of	78ensemble prediction in the multi-exit frame-work (refer to Section 5.4). We reported	76the results with one random seed. Note that	74Acc@5 shows the same trend of Acc@1.
Table 3: Memory (GiB / GPU) and computation time (SeC / step) comparison. All numbers aremeasured with ResNet-18 training on 8 RTX 2080 Ti GPUS and Intel i9-10940X CPU. Note thatFLOPS is for one sample. B stands for batch size. For the results of ResNet-50, see Appendix H.
Table 4: CIFAR-100 results on ResNet-18with various batch sizes. We omitted the stan-dard deviation due to the lack of margin.
Table 5: Classification accuracy with the classifiers after backbone, sub-network, and the en-semble of them. The encoder is pretrained by SelfCon-S loss function.
Table 6: The results of linear evaluation on WRN-16-8 and VGG-16 with BN for variousdatasets. We tuned the best structure and position of the sub-network for each architecture. AppendixC summarizes the implementation details.
Table 7: CIFAR-100 1-stage training re-suits on ResNet architectures. ↑ describesa modification to 1-stage training withmulti-exit framework. We omitted the stan-dard deviation. Parentheses indicate thesub-network’s accuracy.
Table 8: The results of SelfCon-S loss according to the structure and position of sub-network.
Table 9: The results of SelfCon-S loss according to the structure and position of sub-network.
Table 10: The results under the unsupervised scenario. We compared our SelfCon-MU andSelfCon-SU loss with SimCLR in the unsupervised setting. For the comparison with supervisedlearning, we also added the classification accuracy of CE loss. We used ResNet-18 encoder andCIFAR-100 dataset. Accuracy* denotes the accuracy of SelfCon learning with the anchors only fromthe sub-network (see details in Appendix D.2).
Table 11: CIFAR-100 results with SelfCon extensions. Accuracy* denotes the accuracy of SelfConlearning with the anchors only from the sub-network.
Table 12: The detailed results of mutual information estimation. x, y, T (x), and F (x) respec-tively denotes the input variable, label variable, intermediate feature, and the last feature. Recall thatT (x) is the intermediate feature of the backbone network, which is an input to the auxiliary networkpath. We summarized the average of estimated MI through multiple random seeds. We highlightedthe MI between the intermediate and the last features, which is the main concern of the SelfCon loss.
Table 13: The classification accuracy on ResNet-18 for ImageNet.
Table 14: Memory (GiB / GPU) and computation time (sec / step) comparison. All numbers aremeasured with ResNet-50 training on 8 RTX 2080 Ti GPUs and Intel i9-10940X CPU. Note thatFLOPS is for one sample. B stands for batch size.
Table 15: CIFAR-100 results on ResNet-18 with various learning rates. Bold typeis for the best accuracy within each method.
Table 16: CIFAR-100 results on ResNet-18 with various augmentation policies.
Table 17: The detailed results of mutual information estimation. Every notation is same as Table12. We used ResNet-18 on CIFAR-100 dataset for the measurements.
