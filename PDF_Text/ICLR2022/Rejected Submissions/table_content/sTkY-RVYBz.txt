Table 1: CT’s mean corruption error (mCE) compared to common self-supervised and contrastivelearning methods on CIFAR-10-C and CIFAR-100-C. All SSL models are first pre-trained (self-supervised), then fine-tuned (supervised).
Table 2: CIFAR-10-C and CIFAR-100-C mean corruption error (mCE) compared to commondata augmentation techniques. AdvT, and AutoAug refer to adversarial training, Auto Augment,respectively. Our CT approach outperforms six out of seven methods while it achieves comparableresults to AugMix which leverages complex augmentations.
Table 3: Multi-source domain generalization accuracy (%) on the VLCS dataset with ResNet-18 asthe base network for classification. All reported numbers are averaged over three runs.
Table 4: Robust classification accuracy on RobustPointSet. The Noise column for example showsthe result of training on the Original train set and testing with the Noise test set. When we trainPointNet using our CT method its performance significantly improves on average and particularly onNoise, Translation, MissingPart, and Sparse test sets.
Table 5: MNIST small CNN architecture with batch normalization layers. Batch normalization layers(in gray) are omitted in the Teacher network.
Table 6: Changes in clean error (CLN-E), mean corruption error (mCE), and corruption error withrespect to changes in adaptation batch size (BS). In this table, the model’s batch normalizationlayers are only adapted to one corruption (CRP) based on the method presented in Benz et al.
Table 7: CT’s mean corruption error (mCE) compared to common self-supervised and contrastivelearning methods on CIFAR-10-C and CIFAR-100-C. Encoders are frozen and only classificationlayer is trained (linear evaluation).
