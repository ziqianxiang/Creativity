Table 1: Quantitative evaluation with state-of-the-arts on the 26 Atari games (Kaiser et al., 2019)after 100K time steps using 10 random seeds: Numbers in bold represent 1st ranking. S3R achievesthe best performance on 13 out of 26 environments. We compared results with SimPLe (Kaiser et al.,2019), Data-Efficient Rainbow (DER) (van Hasselt et al., 2019), OverTrained Rainbow (OTRainbow)(Kielak, 2020), CURL (Laskin et al., 2020b), DrQ (Kostrikov et al., 2020), and SPR (Schwarzer et al.,2021).____________________________________________________________________________________________________Game	Human	Random	Rainbow	SimPLe	DER	OTRainbow	CURL	DrQ	SPR	S3RAlien	7127.7	227.8	318.7	616.9	739.9^^	824.7	558.2	771.2	801.5	1030.1Amidar	1719.5	5.8	32.5	88.0	188.6	82.8	142.1	102.8	176.3	114.3Assault	742.0	222.4	231.0	527.2	431.2	351.9	600.6	452.4	571.0	708.3Asterix	8503.3	210.0	243.6	1128.3	470.8	628.5	734.5	603.5	977.8	959.3Bank Heist	753.1	14.2	15.55	34.2	51.0	182.1	131.6	168.9	380.9	95.8BattleZone	37187.5	2360.0	2360.0	5184.4	10124.6	4060.6	14870.0	12954.0	16651.0	16688.0Boxing	12.1	0.1	-24.8	9.1	0.2	2.5	1.2	6.0	35.8	35.9Breakout	30.5	1.7	1.2	16.4	1.9	9.8	4.9	16.1	17.1	17.5ChopperCommand	7387.8	811.0	120.0	1246.9	861.8	1033.3	1058.5	780.3	974.8	1251.2Crazy Climber	35829.4	10780.5	2254.5	62583.6	16185.3	21327.8	12146.5	20516.5	42923.6	42544.0Demon Attack	1971.0	152.1	163.6	208.1	508.0	711.8	817.6	1113.4	545.2	884.0Freeway	29.6	0.0	0.0	20.3	27.9	25.0	26.7	9.8	24.4	24.8Frostbite	4334.7	65.2	60.2	254.7	866.8	231.6	1181.3	331.1	1821.5	776.9
Table 2: Quantitative evaluation of mean and standard deviation with state-of-the-arts on the DM-Control suite (Tassa et al., 2018) after 100K time steps and 500K time steps using 10 randomseeds. Numbers in bold represent 1st ranking, and S3R achieves the best performance on 4 out of6 environments for 500K time steps. We compared results with state-based SAC and pixel-basedSAC (Haarnoja et al., 2018b), SAC+AE (Yarats et al., 2019), Dreamer (Hafner et al., 2019a), PlaNet(Hafner et al., 2019b), CURL (Laskin et al., 2020b), RAD (Laskin et al., 2020a), and DrQ (Kostrikovet al., 2020).___________________________________________________________________________________________100K step scores	State SAC	Pixel SAC	SAC+AE	Dreamer	PlaNet	CURL	RAD	DrQ	S3RFinger, Spin	811±46	179±66	740±64	341±70	136±216	767±56	856±73	901±104	880±127Cartpole, Swingup	835±22	419±40	311±11	326±27	297±39	582±146	828±27	759±92	841±47Reacher, Easy	746±25	145±30	274±14	314±155	20±50	538±233	826±219	601±213	621±202Cheetah, Run	616±18	197±15	267±24	235±137	138±88	299±48	447±88	344±67	251±34Walker, Walk	891±82	42±12	394±22	277±12	224±48	403±24	504±191	612±164	595±104Ball in Cup, Catch	746±91	312±63	391±82	246±174	0±0	769±43	840±179	913±53	922±60500K step scores	State SAC	Pixel SAC	SAC+AE	Dreamer	Planet	CURL	RAD	DrQ	OursFinger, Spin	923±21	179±166	884±128	796±183	561±284	926±45	947±101	938±103	954±131Cartpole, Swingup	848±15	419±40	735±63	762±27	475±71	841±45	863±9	868±10	880±34Reacher, Easy	923±24	145±30	627±58	793±164	210±390	929±44	955±71	942±71	932±41Cheetah, Run	795±30	197±15	550±34	570±253	305±131	518±28	728±71	660±96	501±63Walker, Walk	948±54	42±12	847±48	897±49	351±58	902±43	918±16	921±45	930±75
Table 3: To study the impact of several losses, we measured the average performance over 10 randomseeds according to the combinations of losses on DMControl Suite (Tassa et al., 2018) with 500Ktime steps. Refer to Section 4.3 for 'F'，‘F+W’，‘P'，and 'F+P’.
Table 4: Hyperparameters used for S3R experiments on Atari GamesParameter	ValueObservation Size Augmentation Image Gray-scale Update Stacked Frames Action Repeat Reward Clipping Training Steps Evaluation Trajectories Minimum Replay Size (for sampling) Max Frames (per episode) Support Of Q-Distribution Discount Factor Optimizer Optimizer: learning rate Optimizer: β1 Optimizer: β2 Optimizer: Max Gradient Norm Multi Step Return Target Network: Update Period Q Network: Channels Q Network: Filter Size Q Network: Stride Q Network: Hidden Units Non-Linearity Replay Period Every Updates Per Step Exploration Noisy Nets Parameter Priority Exponent Priority Correction	(84, 84) Random shifts (±4 pixels), Intensity (scale=0.05) True Distributional Q 4 4 [-1, 1] 100K 100 2000 108K 51 bins 0.99 Adam 0.0001 0.9 0.999 0.00015 10 10 1 32, 64, 64 8 × 8, 4 × 4, 3 × 3 (4, 4), (2, 2), (1, 1) 256 ReLU 1 2 Noisy Nets 0.5 0.5 0.4 → 1For the reproducibility of our work, we provide full hyperparameters for our experiments on AtariGames (Kaiser et al., 2019) in Table 4. We follow the common practices used to set up RainbowDQN van Hasselt et al. (2019) in existing methods Laskin et al. (2020b); Schwarzer et al. (2021) forexperimenting on Atari Games. Table 5 shows a full list of hyperparameters for DMControl suitesexperiments. We utilize the similar hyperparameters and optimizer to CURL Laskin et al. (2020b).
Table 5: Hyperparameters used for S3R experiments on DMControlParameter	ValueObservation Size	(84, 84)Observation Rendering	(100, 100)Augmentation	Random crop, translationStacked Frames	3 2 (finger-spin, walker-walk),Action Repeat	8 (cartpole-swingup), 4 (otherwise)Evaluation Episodes	10Discount Factor	0.99Optimizer	Adam(β1,β2) → (fθ,πψ,Qφ)	(0.9, 0.999)(β1 , β2 ) → (α)	(0.5, 0.999)Learning Rate (fθ , πψ , Qφ)	2e - 4 (cheetah-run), 1e - 3 (otherwise)Learning Rate (α)	1e-4Batch Size	64Replay Buffer Size	100000Initial Steps	1000Hidden Units (MLP)	1024Q Function EMA τ	0.01Critic Target Update Frequency	2
Table 6: Detailed describtion of the proposed network architectureEncoder			Layer ∣ Operations		Input	Output1	Conv(N32, K8, S4) - ReLU - DropOut	It 〜It+M	en1t^en1t+M2	Conv(N64, K4, S2) - ReLU - DropOut	en1t^en1t+M	en2t 〜en2t+M3	Conv(N64, K3,S1)- ReLU - DropOut	en2t 〜en2t+M	en3t 〜en3t+MFlowNetLayer	Operations	Input	Output4	Conv(N32, K1,S1)-BN- LReLU	en3t	~c en3t5	Compute Correlation Volume	en3t, en3t+k	corr6	Concatenation	~c en3t, corr	conc05	Conv(N256, K3, S1)-BN- LReLU	conc0	conv16	Conv(N512, K3, S1) - BN - LReLU	conv1	conv2p7	Conv(N512, K3, S1) - BN - LReLU	conv2p	conv28	Conv(N512, K3, S1) - BN - LReLU	conv2	conv3p9	Conv(N512, K3, S1) - BN - LReLU	conv3p	conv310	Conv(N2, K3,S1)	conv3	flow311	Upsampling	flow3, conv2	flow3up, conv2up12	Deconv(N256, K4, S2) - LReLU	conv3	conv3d13	Concatenation	conv2up, conv3d, flow3up	conc3
Table 7: To study the impact of various data augmentation, we measured the average performanceover 10 random seeds according to the data augmentation on DMControl Suite (Tassa et al., 2018)with 500K time steps.
