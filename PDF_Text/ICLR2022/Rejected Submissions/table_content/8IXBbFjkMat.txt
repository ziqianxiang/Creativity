Table 1: Results on Gigaword sentencesummarization. Scores represent ROUGE-L with average output words in parenthe-ses. T and T++ denote Transformer andTransformer++, respectively.
Table 2: Basic statistics for each dataset used in this study. Average number of words refers to inputtexts and output texts, respectively.
Table 3: Asymptotic computation time in the Emb2Emb framework as a function of the latentrepresentation size n and the length of the input text |s|, depending on the type of autoencoder.
Table 4: The number of seconds it takes to process 5% of the validation set (1264 samples) with abatch size of 1. Lower is better.
Table 5: 10 randomly sampled examples from Yelp-Sentences.
