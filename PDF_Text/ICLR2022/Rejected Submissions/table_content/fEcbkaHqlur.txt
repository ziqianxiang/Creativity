Table 1: Four Rooms HyperparametersHyperparameter	DQN	Polyak DQN	FR DQN	Deep MellowLearning rate	1e-3, 1e-4	1e-4	1e-4	1e-4Batch size	32, 512	512	512	512Target Update Period	10, 25, 50, 100, 250	1	-	-Prior Update Period	-	-	50, 500, 5000	-τ	-	5e-1, 1e-1, 5e-2, 1e-2	-	-κ	-	-	[0.1, . . . , 0.9]	-Mellow Temperature	-	-	-	25, 50, 100, 250Deep Neural Network	[128, 128]	[128, 128]	[128, 128]	[128, 128]	0.05	0.05	0.05	0.05agent = FR DQN	agent = DQN	agent = Polyak DQN0.0	0.2	0.4	0.6	0.0	0.2	0.4	0.6	0.8	0.0	0.2	0.4	0.6true error	true error	true errorFigure 11: Return.
Table 2: Atari HyperparametersHyperparameter	Polyak DQN	FR DQN	FR Double DQN	Deep Mellowτ	5e-5, 2.5e-5, 1e-5, 5e-6	-	-	-Target Update Period	100	-	-	-Prior Update Period	-	4e4	4e4	-κ	-	0.25, 0.5, 0.75	0.75	-Mellow Temperature	-	-	-	25, 50, 75, 100C Additional Experimental DetailsD Return and optimal value function error17Under review as a conference paper at ICLR 2022~I~-÷-_I_Figure 12: Value function of the 4 Rooms environments estimated via tabular Q-learning.
