Table 1: Evaluation of tabular datasets. § and ^ indi-cate results taken from Anghel etal. (2019) and Ank &Pfister (2020), respectively. The taken results of XG-Boost and LightGBM for Higgs Boson are evaluatedon the same test set as ours, with exhaustive hyper-parameter optimization.
Table 2: Classification top-1 accuracy of different en-semble methods on CIFAR-10 and CIFAR-100 withK = 3. The * indicates result is taken from the orig-inal paper, while the § represents from Zhang et al.
Table 3: Hyper-parameters we tune for the ensemble network. We search learning rates using loguniform.
Table 4: The comparison experiments on Tiny ImageNet using 祖fferent backbones, with ensemblesize of3.
Table 5: Complete comparison results on CIFAR-10 and CIFAR-100 with K = 3. The * in祖CateSresult is taken from the original paper, while the § represents from Zhang et al. (2020).
Table 6: The comparison experiments on CIFAR-10/100 using ResNet-20 between SANE andHyper-parameter Ensemble marked in green, with K = 4. The results of Hyper-parameter En-semble are taken from the original paper (Wenzel et al., 2020). The values in parentheses representthe performance improvement brought by the ensemble compared to the single model results.
