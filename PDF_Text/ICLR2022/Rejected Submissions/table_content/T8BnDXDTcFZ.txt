Table 1: Parameter setting examples for first-order linear integrate-and-fire models expressed in theform given in Eq. 2.
Table 2: Network performance comparison on the MNIST and CIFAR10 datasets with differentinitialization methods. A hyphen in the table indicates invalid training in a given setting.
Table A3: Surrogate functions for the non-differentiable model (a is the parameter).
Table A4: Detailed hyperparameter settings in the experimental validation. The networks weredesigned to fit the different shapes of input data.
Table A5: Optimizers and their parameters used to test the versatility.
Table A6: Validation accuracy achieved when training on MNIST for 3 epochs using four differentoptimizers, different (k, λ, θ) settings and different initialization methods. A hyphen in this tableindicates invalid training in a given setting.
Table A7: Validation accuracy achieved when training on MNIST for 3 epochs using four differentsurrogate functions, different (k, λ, θ) settings and different initialization methods. A hyphen in thistable indicates invalid training in a given setting.
Table A8: Accuracy comparison with different normalization technique training with VGG11 onlarge datasets. A hyphen in this table indicates invalid training in a given setting.
