Table 1: Comparison of HYDRASUMâ€™s generated summaries using individual decoders (D0 and D1) and theirmodel-derived mixture (Mix). Results show significant differences along multiple dimensions (highlighted ingray), most notably abstractiveness and specificity for Cnn and Newsroom, and specificity for XSum.
Table 2: Diversity performance of the baseline Bart models (Base) and HydraSum (HS).
Table 3: Performance of HydraSum models in the guided setting. Compared to the unguided set-ting, we observe higher variation in style between D0 and D1 as well as better TopK style diversity.
Table 4: Example summaries generated using low and high specificity decoders in the specificity-guided setting. The underlined text highlights additional details in the more specific summaries.
Table 6: Dataset statisticsTable 7 outlines the hyperparameters used for training and inference. For all our experiments, we useBart-Large as the pre-trained initialization. During inference for HydraSum, we incorporatetop-k and top-p sampling using values 30 and 0.5 respectively. For top-k decoding for using baselineBART model in Table 2, we set k = 30. Diverse beam search is run using 2 beam groups anddiversity penalty 0.5.
Table 7: Hyperparameters used from fine-tuning and decoding the Bart-based summarization mod-els. (**For specificity-controlled models in Section 3.2, we employ a learning rate of 2e-5)Dataset	Decoder	Rouge (R1/R2/RL)	Overlap	Spec.	Length	Characteristics	D0	32.35/10.90/29.29	.48	.34	39.9	Low Copy, Low spec.
Table 8: Comparison of generated summaries for a 3-decoder HYDRASUM model. Results show highercoverage of summary styles by individual decoders compared to the 2-decoder version. For e.g., D0 and D2of the XSum model learn to generate relatively more extractive and longer summaries; partitioning alongabstractiveness and length was not observed in the 2-decoder version (see Table 1).
Table 9: Effect of varying the number of shared layers between the 2 decoders of HydraSum.
Table 10: Performance of style-controlled HYDRASUM models. Compared to the unguided setting,We observe higher variation in style between D0 andD1 along the control dimension (indicated withf). Similarly, higher style diversity is observed among top 5 summaries along the control dimension.
Table 11: Comparison of human-rated Relevance/Coherence/Grammaticality/Factuality scoresof HydraSum models under the unguided setting and the baseline Bart model.
