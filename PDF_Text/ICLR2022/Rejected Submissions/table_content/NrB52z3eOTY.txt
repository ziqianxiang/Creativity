Table 1: Comparative experiments on CIFAR-10 and CIFAR-100. Misclassification (Mis.), out-of-distribution (OOD) and simultaneous (Mis+OOD) detection results (mean % AUROC and std.
Table 2: Impact of confidence learning. Comparison of detection performances between KLoSand KLoSNet for CIFAR-10 and CIFAR-100 experiments with VGG-16 architecture.
Table 3: Results of KLoS decompo-sition on synth. data.
Table 4: Mean accuracies(%) and std. over five runs.
Table 6: Other baselines results on comparative experiments on CIFAR-10 and CIFAR-100.
Table 5: Synthetic experiment: misclassifica-tion (Mis.), out-of-distribution detection (OOD)and simultaneous detection (Mis+OOD) (mean %AUC and std. over 5 runs). Bold type indicatessignificant top performance (p < 0.05) accordingto paired t-test.
Table 7: AUPR results for experiments with VGG-16 architecture on CIFAR-10 and CI-FAR100: Misclassification (Mis.), out-of-distribution (OOD) and simultaneous (Mis.+OOD) de-tection results (% mean and std. over 5 runs).
Table 8: Comparative experiments including relative Mahalanobis (RelMaha) and Maha-lanobis (Maha) baselines on CIFAR-10 and CIFAR-100. Misclassification (Mis.), out-of-distribution (OOD) and simultaneous (Mis+OOD) detection results (mean % AUROC and std. over5 runs). Bold type indicates significantly best performance (p<0.05) according to paired t-test.
