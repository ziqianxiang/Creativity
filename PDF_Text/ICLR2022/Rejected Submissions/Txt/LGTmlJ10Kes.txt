Under review as a conference paper at ICLR 2022
Curriculum Discovery through an Encompass-
ing Curriculum Learning Framework
Anonymous authors
Paper under double-blind review
Ab stract
We describe a curriculum learning framework capable of discovering optimal
curricula in addition to performing standard curriculum learning. We show that
this framework encompasses existing curriculum learning approaches such as
difficulty-based data sub-sampling, data pruning, and loss re-weighting. We em-
ploy the proposed framework to address the following key questions in curriculum
learning: (a) what is the best curriculum to train a given model on a given dataset?
and (b) what are the characteristics of optimal curricula for different datasets and
difficulty metrics? We show that our framework outperforms competing state-
of-the-art curriculum learning approaches in natural language inference and two
other text classification tasks. Exhaustive experiments illustrate the generalizabil-
ity of the discovered curricula across the datasets and difficulty metrics.
1 Introduction
Curriculum Learning (CL) is a technique in Machine Learning that mimics human education sys-
tems. To learn a complex subject, students must first learn the foundational and basic materials
before learning more complex ones. Without a curriculum, learning may be intractable, inefficient
and learners may never reach a full understanding of a topic due to lack of the required background
knowledge. Machine learning optimization through stochastic gradient descent trains models by ob-
serving example data instances. Some data instances are harder than others and require background
knowledge, which could be acquired by observing and being adept at easier examples before harder
ones. CL techniques seek to order examples according to their difficulty for training to generate bet-
ter models. It has been shown that CL improves performance in solving harder tasks, or in cases of
limited or noisy data (Wu et al., 2021). CL research has made significant progress in the last decade
through the work of Bengio et al. (2009), although the principle of ordering training samples from
easier to harder was introduced in the 1990s (Elman, 1993; Sanger, 1994; Rohde & Plaut, 1999).
A curriculum can be defined by ordering training samples based on their difficulty to learn. Given a
measure of difficulty, there are different types of CL approaches for ordering the data: sub-sampling
techniques, which sample the easiest or hardest data points at every iteration for training (Zhou
et al., 2020; Bengio et al., 2009; Xu et al., 2020; Guo et al., 2018; Platanios et al., 2019), sample
weighting techniques, which use the complete data at every iteration but weight data points differ-
ently according to their difficulty (Castells et al., 2020; Kumar et al., 2010; Jiang et al., 2015; 2018;
Zhou et al., 2020; Yang et al., 2019), and pruning techniques, which prune the hard or noisy samples
from the dataset prior to training (Northcutt et al., 2021; Guo et al., 2018). Sub-sampling methods
can be cumulative, exclusive or a combination of both. Cumulative approaches add new data points
to the ones that have previously been used for training. On the other hand, exclusive approaches
create a new subset of data at every training stage. Such methods can introduce samples from easy
to hard (Bengio et al., 2009; Kumar et al., 2010) or hard to easy, which can be an effective learning
strategy in some specific tasks (Kocmi & Bojar, 2017; Zhang et al., 2018; 2019). In addition, CL
methods may impose a curriculum by adjusting model’s capacity according to the difficulty of their
inputs (Karras et al., 2018; Sinha et al., 2020; Morerio et al., 2017) or schedule the order of tasks
in the context of multi-task learning (CaUbriere et al., 2019; Sarafianos et al., 2017; Florensa et al.,
2017). Other CL approaches such as (Zhou et al., 2020; Saxena et al., 2019) use O(n), where n is
the number of training samples, extra parameters for learning curricula.
1
Under review as a conference paper at ICLR 2022
1.0
0.8
0.6
0.4
0.2
0.0
0.0	0.2	0.4	0.6	0.8	1.0
Training Progress
(a) Effect of varying the parameters.
Figure 1: The effect of the rate of growth and shift parameters (r, s). (a) illustrates different weight-
ing strategies that can be obtained by varying the rate and shift parameters. (b) a specific parameter
configuration for a curriculum that first introduces easier training samples to a model, and then
gradually introduces medium and hard samples at 30% and 60% of the training epochs.
Current CL approaches calculate difficulty scores for training samples based on the loss of a trained
model (Xu et al., 2020; Wu et al., 2021), trainable parameters that weight samples (Kumar et al.,
2010; Jiang et al., 2015; Castells et al., 2020), loss value during training (Wu et al., 2021), moving
average of loss during training (Zhou et al., 2020), transformations of the loss during training (Jiang
et al., 2018; Castells et al., 2020), and consistency in the correct classification of samples (Amiri
et al., 2017; Xu et al., 2020). The difficulty scores will then be used to order samples for training.
In this work, we focus on an alternative approach, where examples can be ordered based on prior
knowledge about their difficulty, e.g., object shape or orientation in image classification (Bengio
et al., 2009). We will demonstrate a CL framework that encompasses existing CL approaches
through an effective and flexible data partitioning and weighting scheme. Our framework provides a
new paradigm for selecting an ordering strategy. Instead of a pre-determined strategy, the framework
allows searching over the curriculum space to identify the best curriculum for a particular dataset
and model. It partitions training data into several groups of training samples, e.g. {easy, medium,
hard} samples, according to a difficulty scoring function. Parameterized weighting functions will
then be defined for each data group to specify the weight of its samples during training. Each weight
function is controlled by two parameters, which can be set empirically or adjusted using Bayesian
optimization. In addition, the framework discovers optimal curricula by optimizing the parame-
ters of the weight functions (only 2 parameters per function) using a hyper-parameter optimization
algorithm. Furthermore, the curricula identified through this search provide useful insight about
the dataset, such as the relative importance of different samples or knowledge dependency between
samples, e.g. which samples should be learned first.
We begin by explaining our framework and showing how it is capable of approximating existing CL
approaches. Then, in the context of the proposed framework, we investigate curriculum discovery,
characteristics of discovered curricula, and generalizability of curricula with respect to their datasets.
2 Curriculum Learning Framework
2.1 Weighting Functions
We define the curriculum using generalized logistic functions (Richards, 1959) of the form:
w(t; r，S)=1+exp(-r * (t-s))，
(1)
where r ∈ R is the rate-of-change parameter, which specifies how fast the weight can increase
(r > 0) or decrease (r < 0); t ∈ [0, 1] is the training progress (iteration number divided by max
iterations); and s ∈ R shifts the pivot weight of the logistics function (w(.) = .5) to the left or right
such that at t = s the weight is 0.5. Figure 1a illustrates the effect of varying these parameters.
Greater absolute values for the rate parameter enforce greater slope and faster rate of changes in
weights, while greater values of the shift parameter enforce longer delays in reaching the pivot
2
Under review as a conference paper at ICLR 2022
0.0	0.5	1.0
Entropy
(a) SNLI Entropy
(d) SNLI Loss
›⅛ω⊂ΦQ A4->一 SU ① 0
Entropy
(b) Alcohol Entropy
(e) Alcohol Loss
6 4 2
Aaωu ① 0
0
Figure 2: Distributions of entropy and loss of the three datasets used in the experiments. Figures
(a) - (c) show entropy, and (d) - (f) show loss. Samples of the easy class are to the left of the first
vertical line, those of the medium class are between the two vertical lines, and samples of the hard
class are to the right of the second line.
weight of 0.5. These parameters provide flexibility in controlling sample weights during training,
which is critical for deriving effective curricula. Given the weighting function, we encode prior
knowledge about sample difficulty into the training paradigm of our CL framework by splitting the
data into several partitions of increasing difficulty according to the prior knowledge. Then, we define
a weight function by a pair of parameters (r, s) for each partition,
The proposed sample weighting framework provides flexibility in sample-ordering according to
difficulty. It can be learned to approximate existing predetermind curricula. For example, it is
possible to begin with only easy instances or only difficult instances (as an anti-curriculum) or a
combination of both. Figure 1b shows a specific configuration for the logistic functions based on
standard CL (Bengio et al., 2009; Kumar et al., 2010), where training starts with easier samples and
gradually proceeds with harder ones. In addition, our approach enables discovering new data-driven
curricula from data.
Prior to training, the difficulty scores of samples are computed and each sample is assigned to
a difficulty class c ∈ {easy, medium, hard}, see §2.2. In addition, the hyper-parameters of
our three weight functions are optimized prior to training and kept fixed throughout training
{(re, se), (rm, sm), (rh, sh)}. During training, the weighted loss is computed as follows.
Ii = w(t；rc,Sc) * Ii	(2)
Where li is the unweighted and instantaneous loss of instance i, li is the weighted loss, t is the
current training iteration divided by the maximum number of iterations, c is the difficulty class of
instance i, and (rc, sc) are the corresponding rate and shift parameters for the difficulty class c.
2.2	Scoring Functions
Ground-truth labels for many datasets are often obtained through human annotation and crowd-
sourcing. This is achieved by collecting multiple annotations per data sample and aggregating the
results, typically by majority voting. We use sample-level annotator disagreement to define a dif-
ficulty score for each sample using Shannon entropy (Shannon, 2001), where higher disagreement
among annotators corresponds to higher sample difficulty. Entropy is a natural measure of diffi-
culty (for human population) and may serve as a reliable prior knowledge for partitioning data by
3
Under review as a conference paper at ICLR 2022
difficulty. Entropy of each sample xi is calculated as H(xi) = - l pc log pc where c is a class
category and pc is the fraction of annotators who chose label c for the sample. The use of entropy
is supported by Nie et al. (2020), who studied the correlation between human agreement and model
performance and reported a consistent positive correlation between model accuracy and level of
human agreement, showing that model performs better on samples with a high level of agreement.
Furthermore, training loss contains valuable information about difficulty with respect to the model
(learner), which may be different among architectures and tasks, and indicative of the model’s spe-
cific needs. However, loss at a particular step (e.g., final loss) is dictated by the stochastic gradient
descent and mini-batching dynamics and therefore is not a good indicator of difficulty (Zhou et al.,
2020; Wu et al., 2021). Using a baseline model, trained with no curriculum and with default hyper-
parameters, we collect the loss values of all training instances at intervals of 0.5 epochs and use
the average loss to estimate sample difficulty. In our experiments, we obtain twenty observations of
the loss and compute the average for each instance. Such an estimation is supported by Zhou et al.
(2020) who showed that the moving average of a sample’s instantaneous loss is a good metric for
difficulty. Partitioning the data into three groups of increasing difficulty can be done using difficulty
score percentiles, or 1-dimensional k-means clustering of the scores. Examples of data partitions
using entropy and loss are shown in Figure 2.
2.3	Encompassing Framework
Curriculum learning approaches can be divided into three categories depending on how they process
their input data: approaches that identify and prune noisy data that may hurt performance (Northcutt
et al., 2021; Guo et al., 2018; Rooyen et al., 2015; Patrini et al., 2016; Chen et al., 2019), approaches
that use different sub-samples of data during training (Bengio et al., 2009; Zhou et al., 2020; Xu
et al., 2020; Platanios et al., 2019; Zhou & Bilmes, 2018), and approaches that re-weight loss ac-
cording to sample difficulty, choosing to emphasize either easy or hard samples (Castells et al., 2020;
Jiang et al., 2015; 2018; Yang et al., 2019; Saxena et al., 2019). The framework presented in this
paper is capable of representing all of the three approaches.
First, data pruning can be done by assigning negative values to the rate change and shift parameters
in our framework, r and s in Eq. 2. A negative r causes the weight to approach zero, and a negative
s shifts the curve to the left, so the curve reaches zero before training begins. The framework also
allows flexibility in pruning: by setting a small positive s, the noisy data can be seen by the model
for a short amount of time before reaching zero weight, or by setting a positive r and a large positive
s the noisy data will only be seen at the end of training (after it stabilizes).
Second, data sub-sampling can be represented by the weight going to zero or increasing from zero at
different stages of training. For instance, Figure 1b illustrates a curriculum where the easy samples
are sub-sampled in the beginning, and harder samples are introduced at later stages.
Third, we display in Figure 3 the confidence scores assigned to our data by three loss re-weighting
approaches. The results are generated by our implementations of the three approaches, evaluated
on the three datasets introduced in §3.1, where each model runs with five random seeds. The parti-
tioning of easy, medium, and hard is according to the entropy-based difficulty classes, as described
in §2.2. We record the average weight (confidence) assigned to each class. The result is averaged
over all runs, and the shaded area is the 95% confidence interval. The approaches that estimate
sample confidence based on loss (Castells et al., 2020; Zhou et al., 2020; Kumar et al., 2010; Jiang
et al., 2015; Felzenszwalb et al., 2009) tend to generate monotonic curves over the course of training
because training loss tends to be non-increasing at every step. Therefore, the confidence scores as-
signed by these re-weighting approaches follow a monotonic curve that can be approximated by our
weighting functions (§2.1, Figure 1). We note that although the weight scale of SuperLoss (Castells
et al., 2020) in Figure 3a is larger than one, this model can still be represented by our CL framework
because the increased scale corresponds to a scaling of the learning rate, as shown below:
θt =	θt-1	-	nV— ^X σili	=	θt-1	-	(η ∙ σmaX)▽— ^X ----- Ii,	(3)
n i	n i σmax
where li and σi are the loss and confidence of sample i, respectively. Therefore, our framework can
also represent CL approaches with a confidence scale larger then one.
4
Under review as a conference paper at ICLR 2022
Figure 3: Confidence assignment to samples in our datasets by three curriculum learning approaches
that re-weight their loss functions by computing confidence scores for samples. The x-axis is the
epoch number, and y-axis is the average weight assigned to instances of different difficulty. Blue
(solid) is easy, orange (dashed) is medium, and green (dash-dot) is hard. The shaded area is the 95%
confidence interval (CI) over three datasets with five random seeds each. The curves are monotonic
for most parts, and can be approximated by the monotonic curves generated by our framework.
2.4	Curriculum Discovery
We employ a hyperparameter optimization framework (Akiba et al., 2019) to find the optimal value
of the curriculum parameters (r, s) for each difficulty class. Using this method, we can learn a data-
driven curriculum beyond what we could manually design through empirical settings or a choice
among the limited ordering strategies. To optimize the three pairs of parameters, we use the Tree-
structured Parzen Estimator (TPE) sampling algorithm (Bergstra et al., 2011). Unlike grid or random
search (Bergstra & Bengio, 2012), TPE traverses the parameter space by estimating the parameters
that are most probable to perform better on a trial, based on the previous trials. TPE defines two
Gaussian Mixture Models, l(x) and g(x) which are formed using the best and remaining observed
parameters, respectively. TPE selects the parameter x with a high probability under l(x) and low
probability under g(x), i.e. arg maxx l(x)/g(x). This choice of sampling algorithm greatly speeds
up the search of our curriculum parameters.
We note that the discovered curricula are optimal within this framework, constrained by the method
of data partitioning and the class of weight functions. We argue that the proposed framework is able
to approximate curricula defined by existing CL approaches, and outperform existing CL approaches
across several datasets.
3	Experiments
3.1	Datasets
We evaluate our approach on three datasets that contain multiple annotations for each sample. First,
the Stanford Natural Language Inference (SNLI) benchmark (Bowman et al., 2015), which contains
550k training samples, 10k development samples, and 10k test samples. Within the training samples,
there are 36.7k samples annotated by 5 workers and 2.6k annotated by 4 workers, which we use for
our experiments and refer to as SNLI “full.” Furthermore, in order to control for variance due
to imbalanced difficulty classes, we create a balanced subset of the data. As shown in Figure 2a
(notice the y-axis scale), SNLI is highly imbalanced in entropy classes. The data is downsampled by
selecting an equal number of samples from each entropy-class. The balanced subset contains a total
of 2.3k samples, i.e. 774 samples in each entropy class. On the other hand, loss classes are fairly
distributed, see Figure 2d. The downsampled subset contains both entropy and loss classes which
will be used in experiments.
The Alcohol dataset (Amiri et al., 2018; Weitzman et al., 2020) has been developed to obtain
population-level statistics of alcohol use reports through social media. The dataset consists of more
than 9k tweets. Given an alcohol relevant tweet, annotators are asked to determine if it reports first-
5
Under review as a conference paper at ICLR 2022
person alcohol use, and if yes, the intensity of the drinking (light vs. heavy), the context of drinking
(social vs. individual), and the time of drinking (past, present, or future). All samples in the dataset
are labeled by at least three workers, including over 1.3k samples labeled by five or more workers.
We define a multi-class classification task for this dataset based on alcohol relevance, intensity and
context of drinking. The categories and their data distributions are reported in Appendix A. We ran-
domly split the data into 5.4k training samples, 1.8k development samples, and 1.8k test samples.
The balanced version of the training set contains a total of 2.5k training samples, i.e. 863 samples
in each entropy class.
The Cancer dataset has been developed to obtain population-level statistics of cancer patients; it
contains 3.8k Reddit posts. Annotators are asked to determine if the post describes the experience
of a cancer patient, the type of cancer, and the relation of the author of the post to the patient. We
define a multi-class classification task based on post relevance and caner type. The categories and
their data distribution are reported in Appendix A. All samples are labeled by at least three workers,
including about 1k labeled by at least five. We randomly split the data into around 2.2k training
samples, 765 development samples, and 765 test samples. The balanced version of the training set
contains a total number of 1.7k sample, i.e. 578 samples in each entropy class.
We note that the datasets are significantly different in average document length, ranging from 10
(SNLI), to 15 (Alcohol) to 174 (Cancer) words. This variation can induce significant variance in the
created models.
3.2	Baselines
We compare the performance of our CL approach with the following state-of-the-art approaches.
SuperLoss (SL) (Castells et al., 2020) is a CL approach that defines a task-agnostic confidence-
aware loss function. It infers the confidences of instances from the instance loss with minimal
cost, providing a closed-form solution function for estimating confidence. It up-weights samples
with smaller loss values (easier instances), while down-weights those with larger loss values (harder
ones) (Figure 3a). MentorNet (Jiang et al., 2018) uses an auxiliary network to generate a weight for
training samples at every training iteration. It incorporates additional signals such as epoch number
and instance loss history to learn data-driven curricula and is particularly strong against noisy data.
Difficulty Prediction (DP) (Yang et al., 2019) defines a difficulty score based on multi-annotator
data, and weight samples according to the following formula W = 1 - α(di - TDP)/(1 - TDP),
where di is the sample difficulty and τ is a pre-defined threshold.
As discussed before, our approach employs two scoring functions (§ 2.2) and two curriculum con-
figurations for each dataset. A curriculum configuration refers to a particular setting of the six
parameters controlling the three weight curves (§ 2.1). The two scoring functions are labeled as
Loss and Ent (entropy). In addition, the first curriculum configuration is a gradually increasing ap-
proach in Figure 1b named inc., this configuration is applied identically to all models. The second
configuration is the specialized configuration (sp.) that is obtained through hyper-parameter search
as discussed in § 2.4.
3.3	Settings
We tune the parameters λ of SL and α and TDP ofDP using development data. The optimal values
found are λ = 1.2, α = 0.9 and TDP is set dynamically upon loading the dataset to the 50-percentile
difficulty value. Following Castells et al. (2020), we set TSL (instances with li > TSL are considered
hard) to the moving average of the loss in all experiments.
We use the transformers python package (Wolf et al., 2020), using the bert-base-uncased
model for SNLI and Cancer, and twitter-roberta-base for Alcohol. We set Iearning_rate
to 1e - 5, batch_size to 16, epochs to 10 (We confirm that this number of iterations is sufficient for
all models to converge), and the optimizer to Adam (Kingma & Ba, 2017). For each experiment,
we train five models using five random seeds applied to both pytorch and numpy. Additionally,
during all data pre-processing, splitting, and sub-sampling, the random seed is set to 0, and a single
NVIDIA A100 40GB GPU is used for training. The development set is used to determine the best
training step which is used for the final evaluation.
6
Under review as a conference paper at ICLR 2022
Figure 4: Overall accuracy averaged over three datasets with five random seeds. Loss and Ent
indicate curricula that partition the data based on difficulty classes determined by loss and entropy
respectively (§2.2). inc is the easy to hard curriculum shown in Figure 1b, sp is the specialized
curriculum obtained by curriculum discovery (§2.4), which is different for each dataset.
In addition, we conduct a hyper-parameter search over the (r, s) for each weight function or difficulty
classes (easy, medium, and hard). We set the search space of r to be from -10 to 10 with a step of
2, and of s to be -0.5 to 1.5 with a step of 0.25. We observe that changes smaller than this step size
have little effect on performance. This search space consists of 11 possible values for r and 9 for s,
for a total of 970k combinations. The search is run for at least 100 trials, as compared to over 1000
trials by random search, using the method described in §2.4. Each trial is run with 5 random seeds
and the result is averaged. The search objective is to maximize accuracy over development data.
3.4	Performance Gain from Curricula Discovery
Results are shown in Figure 4. Accuracy is averaged over the six datasets (full and balanced version
of each dataset). The gradually increasing curriculum (inc) achieves a significant improvement over
No-CL using either of the scoring functions while being a static, off-the-shelf curriculum configura-
tion. This improvement shows the effectiveness of our approach of partitioning the data using gen-
eralized logistic functions (§2.1). Moreover, both (inc) and the specialized (sp) curricula obtained
through curriculum discovery perform significantly better than the state-of-the-art CL approaches.
In our three datasets, loss as a scoring function performs better than entropy on average. This is ex-
pected as loss values can capture sample difficulty with respect to the downstream learner (model),
as apposed to entropy values which do not take into account the model.
Appendix B includes further breakdown of the results by dataset and accuracy across samples of
different difficulty.
3.5	Characteristics of Discovered Curricula
Figure 5 shows the mean and 95% CI of the top 25 performing configurations on our datasets and
scoring functions. We observe several insightful patterns: the resulting curricula are non-trivial and
greatly differ from the known strategies reported in current literature, such as gradually increasing
difficulty or anti-curriculum. In addition, the weights of hard samples tend to approach zero, sup-
porting the hypothesis that either these instances are too difficult for the models to learn or they are
noisy. The results support the principle of pruning techniques because noisy samples induce more
noise than useful signal; in several plots, the weight of hard samples increases only at the end of
training after the model stabilizes. In addition, in SNLI and Alcohol easy samples carry the most
significant weight, unlike Cancer, where easy samples are down-weighted early during the training.
These weighting patterns reveal the relative importance of samples in each dataset. Finally, the full
SNLI dataset with entropy-class partitions provides useful information. Figure 2a shows that en-
tropy classes are highly imbalanced, with hard samples being much fewer than easy ones. In the
7
Under review as a conference paper at ICLR 2022
(d) S-F-L
(a) S-B-E	(b) S-B-L	(c) S-F-E
(e) A-B-E
(f) A-B-L
(g) A-F-E
(h) A-F-L
(i) C-B-E
(j) C-B-L
(k) C-F-E
(l) C-F-L
Figure 5: Each caption is composed of the first character of the name of a dataset: {SNLI, Alcohol,
Cancer}, the type of the dataset {Balanced or Full}, and the difficulty score used {Entropy, Loss}.
The x-axis is the training progress and y-axis is the confidence assigned to samples of a difficulty-
class. The blue line (circle marker) is easy, orange line (x marker) is medium, and green line (dia-
mond marker) is hard. The solid line is the mean of the top 25 performing configurations for each
dataset and scoring function pair, and the shaded area represents the 95% CI.
optimal curriculum shown in Figure 5c, hard samples are assigned weights around 0.5, unlike the
three other cases of SNLI. We attribute this result to the reduced presence/effect of hard samples.
3.6	Generalizable Curricula
Figure 6 shows the accuracy obtained when training using different curriculum configurations from
Figure 5. Each cell in the figure is the average result of 5 seeds. We observe common characteristics
among datasets that cause the curriculum to be transferable between them. First, the top three
configurations are all products of down-sampled, balanced datasets. Second, the curricula obtained
using the small balanced datasets generalize and achieve high performance on the large datasets.
This is useful as it allows performing the hyper-parameter search much faster and cheaper on smaller
datasets, providing evidence that the framework can be applied to large datasets by searching for
a curriculum on a small subset of the data. Third, the inc curriculum is available off-the-shelf
and performs consistently well across datasets and scoring functions. Fourth, as noted previously,
instances of the Cancer dataset consist of long paragraphs, causing high variance in models trained
using the dataset. Consequently, the curricula obtained using the Cancer and loss as measure of
difficulty are of lower quality and perform the worst.
An extended version of Figure 6 is included in Appendix C with results of models trained with
balanced versions of datasets.
8
Under review as a conference paper at ICLR 2022
100.0
Figure 6: Using the same notation as Figure 5, the x-axis lists different curriculum configurations
from the increasing curriculum inc (Figure 1b), to No-CL, to curricula discovered using a particular
dataset and scoring function. The y-axis lists models that are trained using each configuration. For
example, the cell at the intersection of row ”S-F-L” and column ”A-F-E” represents a model trained
on SNLI full dataset that is partitioned by loss as a measure of difficulty, using the curriculum
discovered for the full Alcohol dataset partitioned by entropy (Figure 5g). Each row of the table is
normalized to match the scales of the different models.
4	Conclusion and Future Work
We introduce an effective curriculum learning (CL) framework that employs prior knowledge about
sample-level difficulty in its training paradigm, and effectively creates and explores a curricula space
for curricula discovery and model generalizability. The proposed framework partitions its input data
into three groups of increasing difficulty, defines three parameterized logistic weight functions to
weight the loss of samples in each of the three groups, and provides the capability of tuning the pa-
rameters of the weight function to discover new curricula performing better than existing baselines.
We demonstrate that this framework is capable of representing major CL approaches. In addition, an
important advantage of our approach is that the curricula that it discovers for smaller and balanced
datasets work well on larger datasets, across the three datasets that we experimented with. The pro-
posed research opens a new paradigm in CL by removing the limitations imposed by selecting a
single CL strategy, and instead, using a flexible framework to discover optimal curricula for given
datasets and models, and extract valuable insights about the data. Our work has the limitation of
using monotonic logistic functions because the weight curves can not take arbitrary forms. This
challenge can be addressed in future work by adding an extra set of logistic functions and having
every weight function be a linear combination of two or more logistic functions, which makes it
possible to represent non-monotonic functions. Nevertheless, we have demonstrated that major CL
approaches that estimate difficulty as a function of training loss result in monotonic curves because
of gradient descent that causes training loss to be non-increasing.
There are several promising areas for future work. These include approaches for learning new dif-
ficulty indicators that are centered on data (e.g., text difficulty), prioritizing medium level instances
and those with greatest progress in training, and developing challenge datasets that contain diverse
data samples with different level of difficulty.
9
Under review as a conference paper at ICLR 2022
5	Ethics Statement
This investigation included publicly available yet sensitive data from social media, developed for an
important task: obtaining population-level statistics about different public health issues. Our work
does not access, use, or release any personal data, and only textual data is used for experiments.
6	Reproducibility Statement
The source code is included as supplementary material. It provides the required details for data
processing, hyper-parameter setting, random seed setting, model evaluation, etc.
References
Takuya Akiba, Shotaro Sano, Toshihiko Yanase, Takeru Ohta, and Masanori Koyama. Optuna:
A next-generation hyperparameter optimization framework. In Proceedings of the 25th ACM
SIGKDD international conference on knowledge discovery & data mining, pp. 2623-2631, 2019.
Hadi Amiri, Timothy Miller, and Guergana Savova. Repeat before forgetting: Spaced repetition for
efficient and effective training of neural networks. In Proceedings of the 2017 Conference on Em-
pirical Methods in Natural Language Processing (EMNLP), pp. 2401-2410, Copenhagen, Den-
mark, September 2017. Association for Computational Linguistics. doi: 10.18653/v1/D17-1255.
URL https://aclanthology.org/D17-1255.
Hadi Amiri, Kara M Magane, Lauren E Wisk, Guergana Savova, and Elissa R Weitzman. Toward
large-scale and multi-facet analysis of first person alcohol drinking. In American Medical Infor-
matics Association (AMIA), 2018.
Yoshua Bengio, Jerome Louradour, Ronan Collobert, and Jason Weston. Curriculum learning. In
ACM International Conference Proceeding Series, volume 382, pp. 1-8, New York, New York,
USA, jul 2009. ACM Press. ISBN 9781605585161. doi: 10.1145/1553374.1553380.
James Bergstra and Yoshua Bengio. Random search for hyper-parameter optimization. Journal of
Machine Learning Research (JMLR), 13(2), 2012.
James Bergstra, Remi Bardenet, Yoshua Bengio, and Balazs KegL Algorithms for hyper-parameter
optimization. Advances in Neural Information Processing Systems (NIPS), 24, 2011.
Samuel R Bowman, Gabor Angeli, Christopher Potts, and Christopher D Manning. A large an-
notated corpus for learning natural language inference. In Conference on Empirical Methods in
Natural Language Processing, EMNLP 2015, pp. 632-642. Association for Computational Lin-
guistics (ACL), 2015.
Thibault Castells, Philippe Weinzaepfel, and Jerome Revaud. Superloss: A generic loss for robust
curriculum learning. Advances in Neural Information Processing Systems (NeurIPS), 33, 2020.
Antoine CaUbriere, Natalia Tomashenko, Antoine Laurent, Emmanuel Morin, Nathalie Camelin, and
Yannick Esteve. Curriculum-based transfer learning for an effective end-to-end spoken language
understanding and domain portability. In 20th Annual Conference of the International Speech
Communication Association (InterSpeech), pp. 1198-1202, 2019.
Pengfei Chen, Ben Ben Liao, Guangyong Chen, and Shengyu Zhang. Understanding and utilizing
deep neural networks trained with noisy labels. In International Conference on Machine Learn-
ing, pp. 1062-1070. PMLR, 2019.
Jeffrey L Elman. Learning and development in neural networks: The importance of starting small.
Cognition, 48(1):71-99, 1993.
Pedro F Felzenszwalb, Ross B Girshick, David McAllester, and Deva Ramanan. Object detection
with discriminatively trained part-based models. IEEE transactions on pattern analysis and ma-
chine intelligence, 32(9):1627-1645, 2009.
10
Under review as a conference paper at ICLR 2022
Carlos Florensa, David Held, Markus Wulfmeier, Michael Zhang, and Pieter Abbeel. Reverse cur-
riculum generation for reinforcement learning. In Conference on robot learning, pp. 482-495.
PMLR, 2017.
Sheng Guo, Weilin Huang, Haozhi Zhang, Chenfan Zhuang, Dengke Dong, Matthew R Scott, and
Dinglong Huang. Curriculumnet: Weakly supervised learning from large-scale web images. In
Proceedings of the European Conference on Computer Vision (ECCV), pp. 135-150, 2018.
Suchin Gururangan, Swabha Swayamdipta, Omer Levy, Roy Schwartz, Samuel R Bowman, and
Noah A Smith. Annotation artifacts in natural language inference data. In 2018 Conference of
the North American Chapter of the Association for Computational Linguistics: Human Language
Technologies, NAACL HLT 2018, pp. 107-112. Association for Computational Linguistics (ACL),
2018.
Lu Jiang, Deyu Meng, Qian Zhao, Shiguang Shan, and Alexander G Hauptmann. Self-paced cur-
riculum learning. In Twenty-Ninth AAAI Conference on Artificial Intelligence, 2015.
Lu Jiang, Zhengyuan Zhou, Thomas Leung, Li-Jia Li, and Li Fei-Fei. Mentornet: Learning data-
driven curriculum for very deep neural networks on corrupted labels. In International Conference
on Machine Learning (ICML), pp. 2304-2313. PMLR, 2018.
Tero Karras, Timo Aila, Samuli Laine, and Jaakko Lehtinen. Progressive growing of gans for im-
proved quality, stability, and variation. In International Conference on Learning Representations,
2018.
Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization, 2017.
Tom Kocmi and Ondrej Bojar. Curriculum learning and minibatch bucketing in neural machine
translation. In Proceedings of the International Conference Recent Advances in Natural Language
Processing, RANLP 2017, pp. 379-386, 2017.
M Kumar, Benjamin Packer, and Daphne Koller. Self-paced learning for latent variable models.
Advances in Neural Information Processing Systems (NIPS), 23:1189-1197, 2010.
Pietro Morerio, Jacopo Cavazza, Riccardo Volpi, Rene Vidal, and Vittorio Murino. Curriculum
dropout. In 2017 IEEE International Conference on Computer Vision (ICCV), pp. 3564-3572.
IEEE Computer Society, 2017.
Yixin Nie, Xiang Zhou, and Mohit Bansal. What can we learn from collective human opinions on
natural language inference data? In Proceedings of the 2020 Conference on Empirical Methods
in Natural Language Processing (EMNLP), pp. 9131-9143, 2020.
Curtis Northcutt, Lu Jiang, and Isaac Chuang. Confident learning: Estimating uncertainty in dataset
labels. Journal of Artificial Intelligence Research, 70:1373-1411, 2021.
Giorgio Patrini, Frank Nielsen, Richard Nock, and Marcello Carioni. Loss factorization, weakly su-
pervised learning and label noise robustness. In Proceedings of the 33rd International Conference
on International Conference on Machine Learning-Volume 48, pp. 708-717, 2016.
Emmanouil Antonios Platanios, Otilia Stretcu, Graham Neubig, Barnabas Poczos, and Tom M
Mitchell. Competence-based curriculum learning for neural machine translation. In Proceed-
ings of the Conference of the North American Chapter of the Association for Computational
Linguistics: Human Language Technologies, NAACL-HLT, pp. 1162-1172, 2019.
Adam Poliak, Jason Naradowsky, Aparajita Haldar, Rachel Rudinger, and Benjamin Van Durme.
Hypothesis only baselines in natural language inference. NAACL HLT 2018, pp. 180, 2018.
FJ Richards. A flexible growth function for empirical use. Journal of experimental Botany (JXB),
10(2):290-301, 1959.
Douglas LT Rohde and David C Plaut. Language acquisition in the absence of explicit negative
evidence: How important is starting small? Cognition, 72(1):67-109, 1999.
11
Under review as a conference paper at ICLR 2022
Brendan van Rooyen, Aditya Krishna Menon, and Robert C Williamson. Learning with symmetric
label noise: the importance of being unhinged. In Proceedings of the 28th International Confer-
ence on Neural Information Processing Systems-Volume 1, pp. 10-18, 2015.
Terence D Sanger. Neural network learning control of robot manipulators using gradually increasing
task difficulty. IEEE transactions on Robotics and Automation, 10(3):323-333, 1994.
Nikolaos Sarafianos, Theodore Giannakopoulos, Christophoros Nikou, and Ioannis A Kakadiaris.
Curriculum learning for multi-task classification of visual attributes. In Proceedings of the IEEE
International Conference on Computer Vision Workshops, pp. 2608-2615, 2017.
Shreyas Saxena, Oncel Tuzel, and Dennis DeCoste. Data parameters: A new family of parameters
for learning a differentiable curriculum. Advances in Neural Information Processing Systems, 32:
11095-11105, 2019.
Claude Elwood Shannon. A mathematical theory of communication. ACM SIGMOBILE mobile
computing and communications review, 5(1):3-55, 2001.
Samarth Sinha, Animesh Garg, and Hugo Larochelle. Curriculum by smoothing. Advances in
Neural Information Processing Systems, 33, 2020.
Elissa R Weitzman, Kara M Magane, Po-Hua Chen, Hadi Amiri, Timothy S Naimi, and Lauren E
Wisk. Online searching and social media to detect alcohol use risk at population scale. American
journal of preventive medicine (ACPM), 58(1):79-88, 2020.
Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi,
Pierric Cistac, Tim Rault, Remi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Patrick
von Platen, Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger,
Mariama Drame, Quentin Lhoest, and Alexander M. Rush. Transformers: State-of-the-art natural
language processing. In Proceedings of the 2020 Conference on Empirical Methods in Natural
Language Processing (EMNLP): System Demonstrations, pp. 38-45, Online, October 2020. As-
sociation for Computational Linguistics. URL https://www.aclweb.org/anthology/
2020.emnlp- demos.6.
Xiaoxia Wu, Ethan Dyer, and Behnam Neyshabur. When do curricula work? In International
Conference on Learning Representations (ICLR), 2021. URL https://openreview.net/
forum?id=tW4QEInpni.
Benfeng Xu, Licheng Zhang, Zhendong Mao, Quan Wang, Hongtao Xie, and Yongdong Zhang. Cur-
riculum learning for natural language understanding. In Proceedings of the 58th Annual Meeting
of the Association for Computational Linguistics (ACL), pp. 6095-6104, 2020.
Yinfei Yang, Oshin Agarwal, Chris Tar, Byron C Wallace, and Ani Nenkova. Predicting annotation
difficulty to improve task routing and model performance for biomedical information extraction.
In Proceedings of the Conference of the North American Chapter of the Association for Compu-
tational Linguistics: Human Language Technologies, NAACL-HLT, pp. 1471-1480, 2019.
Xuan Zhang, Gaurav Kumar, Huda Khayrallah, Kenton Murray, Jeremy Gwinnup, Marianna J Mar-
tindale, Paul McNamee, Kevin Duh, and Marine Carpuat. An empirical exploration of curriculum
learning for neural machine translation. arXiv preprint arXiv:1811.00739, 2018.
Xuan Zhang, Pamela Shapiro, Gaurav Kumar, Paul McNamee, Marine Carpuat, and Kevin Duh.
Curriculum learning for domain adaptation in neural machine translation. In Proceedings of the
2019 Conference of the North American Chapter of the Association for Computational Linguis-
tics: Human Language Technologies (NAACL-HLT), pp. 1903-1915, 2019.
Tianyi Zhou and Jeff Bilmes. Minimax curriculum learning: Machine teaching with desirable diffi-
culties and scheduled diversity. In International Conference on Learning Representations, 2018.
Tianyi Zhou, Shengjie Wang, and Jeff A Bilmes. Curriculum learning by dynamic instance hardness.
Advances in Neural Information Processing Systems (NeurIPS), 33, 2020.
12
Under review as a conference paper at ICLR 2022
A Data Categories Distribution
Class	Count
(no)	5,325
(yes, light use, individual)	1,464
(yes, heavy use, individual)	964
(yes, not sure, individual)	457
(yes, heavy use, other)	423
(yes, heavy use, group)	284
(yes, light use, group)	161
Total	9,078
(a) Alcohol
Class	Count
(irrelevant, no patient experience)	"Γ,996
(relevant, breast cancer)	617
(relevant, colon cancer)	444
(relevant, brain cancer)	284
(irrelevant, none of the above)	251
(irrelevant, other cancer types)	162
(irrelevant, news related to cancer)	70
Total	3,824
(b) Cancer
Table 1: Statistics of the Alcohol and Cancer datasets.
13
Under review as a conference paper at ICLR 2022
B Accuracy Breakdown
The accuracy achieved on each dataset using each approach is shown in Figure 7.
Models that achieve a high accuracy may be generating correct predictions for a high percentage of
easy samples while failing to correctly predict the output of the medium and hard samples. Standard
evaluation benchmarks often contains artifacts that make it east to correctly predict the label of
some samples (Gururangan et al., 2018; Poliak et al., 2018). Therefore, it is important to closely
analyze the model’s performance on harder instances. We break down the accuracy of each difficulty
class (with entropy-class partitioning) for balanced, full, and all datasets in Figures 8, 9, and 10,
respectively. Our approach is exceptionally powerful in predicting samples of medium difficulty.
Furthermore, the accuracy achieved on hard samples is almost equal by all approaches, including
No-CL, supporting the hypothesis that those samples tend to be noisy or inaccurately labeled.
Accuracy
snli_special
(a) Full datasets.
Accuracy
(b) Balanced datasets.
Figure 7: Accuracy of different CL approaches on each dataset.
14
Under review as a conference paper at ICLR 2022
0.925
0.900
0.875
0.850
0.825
0.800
0.775
0.750
0.700
(b) Medium
0.72
0.60
0.55
0.50
0.45
(a) Easy
0.70
肺M业W
X 6 6 r 3
6 6 Z> /"
0.94
0.92
0.90
0.88
0.86
0.84
(c) Hard
(d) Balanced Accuracy
Figure 8: Average over balanced datasets.
0.72
≡
0.70
0.68
0.66
由

J " 6 一
S P 6«`F 邕
3 / 6 3	—
(a) Easy
(b) Medium
0.600
0.575
0.550
0.525
0.500
0.475
0.450

7
0.72
(d) Balanced Accuracy
Figure 9: Average over full datasets.
(c) Hard
15
Under review as a conference paper at ICLR 2022
(a) Easy
(b) Medium
(c) Hard
Figure 10: Average over all datasets.
3xd修护城贮户
6 〜/Qo
(d) Balanced Accuracy
16
Under review as a conference paper at ICLR 2022
C Extended Configuration Generalizablity Experiments
Məpow
100.0	99.6	99.7		99.5	99.0	I 99.8	99.0	I 99.9	99.8	99.8	99.5 I	98.9	99.1
99.5	99.5	99.8	99.2	100.0	99.8	99.8	99.8	99.6	99.6	99.2	99.4	99.3	98.6
100.0	99.3	99.9		99.5	99.8	99.9	99.6	99.5	99.7	97.9	99.8	98.4	98.3
98.3	99.2	99.1		99.0	99.4	99.5	98.6	99.3	98.7	99.2	99.1	98.5	98.9
99.5	99.9	100.0	98.6		99.3	98.1		97.0	98.4	99.0	98.7	99.2	99.1
99.6	99.0	99.0		99.1	98.6	98.8	99.0		98.9	99.3	98.6	98.0	98.1
99.4	100.0	99.1	97.6	99.2	1100.0	99.3	98.8	98.6	98.9	99.2	98.6	98.7	97.6
99.7	100.0	98.4	96.9	98.6	100.0	98.6	98.0	98.5	99.1	99.2		98.0	97.4
98.9	99.3	98.8		98.0	99.4	97.5	98.9	98.2	97.6	98.7	97.1	98.1	98.2
99.0	98.9	98.4	98.7	98.6	100.0	97.1	98.9	96.0	98.6	96.1	95.9	98.9	98.8
100.0	98.5	99.1		98.7	96.5	I 99.3	96.7	99.1	98.3	97.3	96.4	92.2	91.5
99.7	99.1	1100.0	99.0	99.9	96.3	99.3	97.7	98.3	95.0	92.3	93.3	87.7	83.8
99.5	99.4	99.3	99.1	99.1	99.0	98.9	98.7	98.6	98.5	98.1	98.0	97,2 96.6
Figure 11: An extended version of Figure 6 including experiments on balanced versions of the
datasets.
Figure 11 shows the full results including evaluation on the balanced datasets.
17
Under review as a conference paper at ICLR 2022
D Full Curriculum Search Results
This section shows the top 25 performing configurations on each dataset scoring function pair. Blue
lines (circle marker) is easy, orange (x marker) is medium, and green (diamond marker) is hard.
Above each plot is the development set accuracy. The plot legend contains the parameters (r, s) for
each class.
0.5
0.0
1.0
0.0
O (74.95%)
* med (4, 1)
k hard (-6,) ∣
I t
1.0
0.5
0.0
1 (74.93%)
• easy (-8,1) I
«* med (2,1)
♦ hard (-6,)
1.0
0.5
0.0
2 (74.92%)
* med (4r 1)
♦ hard (-6, )
1.0
0.5
0.0
3 (74.91%)
• easy (-6,1)
« med (2, 1)
b hard (-6,)
0.5
0.00 0.25 0.50 0.75
5 (74.77%)
0.00 0.25 0.50 0.75
8 (74.74%)
0.00 0.25 0.50 0.75
7 (74.74%)
0.00 0.25 0.50 0.75
6 (74.74%)
1.0
0.5
0.00 0.25 0.50 0.75
0.00 0.25 0.50 0.75
0.00 0.25 0.50 0.75
0.00 0.25 0.50 0.75
0.5
0.0
4 (74.77%)
• easy (-4, .75) I
<* med (2, 1)
♦ hard (-6,)
0.00 0.25 0.50 0.75
9 (74.74%)
easy (-6, .75)
0.0
•	easy (-6, .75)	j
A	*	med (4. 1)
ʌk	♦	hard (-6,)	∣
I I
0.00 0.25 0.50 0.75
10 (74.63%)	11 (74.62%)	12 (74.59%)	13 (74.59%)	14 (74.58%)
0.00 0.25 0.50 0.75
0.00 0.25 0.50 0.75
0.00 0.25 0.50 0.75
0.00 0.25 0.50 0.75
0.00 0.25 0.50 0.75
0.4
0.2
0.0
15 (74.58%)
0.75
0.50
0.25
0.00
16 (74.58%)
17 (74.46%)
18 (74.45%)
19 (74.44%)
0.00 0.25 0.50 0.75
20 (74.43%)
0.00 0.25 0.50 0.75
0.50
0.00 0.25 0.50 0.75
22 (74.37%)
.25 0.50 C
23 (74.37%)
• med (0, 1
♦ hard (-6.)
Figure 12: S-B-E
0.00 0.25 0.50 0.75
21 (74.42%)
v*	ɪτ1τ Jz
Λ	• easy (ψ.5)1 med (d, 1) ♦ hard (-8f )
	
18
Under review as a conference paper at ICLR 2022
♦ hard 4,1.2
12 78.00%
15 (77.99%)
16 77.98%
18 77.97%
19 77.97%
• easy (-8, Ij
• easy (-2,1.5)
* med (O, .5)
♦ hard (8, 1.23
6 78.08%
0.00 0.25 0.50 0.75
11 (78.01%)
•	easy (-2,1.2)
•	med (0, .5)
.hard (8t 1.¾ ∣
25 0.50
7 (78.07%)
• easy (-2, LP)
* med (2, .25)
♦ hard (6, 1.5)
0.00 0.25 0.50 0.75
8 (78.04%)
0.00 0.25 0.50 0.75
14 (78.00%)
0.00 0.25 0.50 0.75
13 (78.00%)
0.25 0.50
0.25 0.50
0.25 0.50
23 (77.93%)
• easy (-6,1.5)
• med (O, .5)
♦ hard (8. 1.2)
0.00 0.25 0.50 0.75
0.00 0.25 0.50 0.75
0.00 0.25 0.50 0.75
0.00 0.25 0.50 0.75
0.00 0.25 0.50 0.75
•	easy (-4, 1.5j
•	med (-2∣ .25)
♦ hard (10, 1.2)
Figure 13: S-B-L
0.00 0.25 0.50 0.75
1.0
• easy (8,)
« med (4, .75)
♦ hard (0f 1)
• easy (6, -0.25j
7 86.42%
14 86.40%
• easy (8,)
■ med (10. 1)
0.00 0.25 0.50 0.75
10 (86.40%)
0.00 0.25 0.50 0.75
15 (86.40%)
0.00 0.25 0.50 0.75
20 (86.37%)
0.00 0.25 0.50 0.75
6 (86.42%)
• easy (6, -0.25)
« med (6, 1)
k hard (-6, -0.5)
0.00 0.25 0.50 0.75
11 (86.40%)
•	easy (8,)
•	med (4, .75)
• easy (8,)
* med (10f 1)
♦ hard (O. 1.5)
0.00 0.25 0.50 0.75
16 (86.39%)
•	easy (iθΛ025)
*	med (8, 1)
♦	hard (0f .75)
0.00 0.25 0.50 0.75
21 (86.35%)
17 (86.39%)
• easy (8, -0.5)~I	
» med ⑵ 1)	
♦ hard (-10, -0.5)	
8 (86.41%)
卜 hard 卜4, .75)]	
D.00 0.25 0.50 0.75
13 (86.40%)
18 (86.38%)
d	
23 (86.35%)
• easy (6, -0.25)
, med (8, 1)
4 (86.45%)
0.00 0.25 0.50 0.75
19 (86.38%)
• easy (4, -0.25)
» med (8,1.2)
0.00 0.25 0.50 0.75
24 (86.34%)
• easy (6, .5)
* med (8, .75)
♦ hard (-8. -0.5)
Figure 14: S-F-E
19
Under review as a conference paper at ICLR 2022
19 86.35%
* med (O, .75
0.00 0.25 0.50 0.75
10 (86.40%)
0.00 0.25 0.50 0.75
11 (86.38%)
0.00 0.25 0.50 0.75
13 (86.36%)
0.00 0.25 0.50 0.75
14 (86.36%)
•	easy (4, .25)
•	med (O, .75)
♦ hard (8, 1)
				L
				
	二 。h	asy (2, .5) ɔed (O, .25) ard (8,1) ∣	1	；
				
0.25 0.50 0.75
16 (86.36%)
• easy (6, .25)
* med (O, .25H
♦ hard (s,ɪ) q
• easy (4r .25)
0.00 0.25 0.50 0.75
17 (86.36%)
Figure 15: S-F-L
O (78.51%)
1 (78.40%)
0.75
1.0
2 (78.40%)
3 (78.37%)
0.75
1.0
4 (78.37%)
0.50
0.25
• easy (-2, 1) I
• med (-6, .25)
♦ hard (4, .75)
• easy (-6,1) I
• med (-6, .25)
♦ hard (2, 1)
0.5
• easy (-8, 1) I
• med (-6, .25)
♦ hard (2, 1)
0.50
0.25
• easy (-2, 1) I
• med (-8, .25)
♦ hard (2, 1)
0.5
• easy (-4, 1ΓΠ
• med (-6f .25)
♦ hard (2, 1)
0.00
0.0
0.0
0.00
0.0
0.00 0.25 0.50 0.75
5 (78.36%)
0.75
0.50
« med (-6, .25)
0.5
0.25
0.00
0.00 0.25 0.50 0.75
6 (78.30%)
med (-4, .25)
♦ hard ⑵ 1)
****^^t
1.00
0.00 0.25 0.50 0.75
7 (78.28%)
0.00 0.25 0.50 0.75
8 (78.27%)
0.00 0.25 0.50 0.75
9 (78.25%)
0.5
0.00 0.25 0.50 0.75
10 (78.23%)
eɪ
∖∣∙ med (-4, .25)
♦ hard ⑵ 1)
0.00 0.25 0.50 0.75
11 (78.22%)
0.75
0.50
0.25
∣∙ easy (-2, 1)
• med (-8, .25)
♦ hard (4, 1)
0.00
1.0
0.00 0.25 0.50 0.75
15 (78.17%)
0.00 0.25 0.50 0.75
16 (78.16%)
0.5
0.5
0.0
0.0
∙ easy (-4, .75)1
med (-4, .25)
♦ hard (4f 1)
q
0.75
0.50
0.25
• easy (-8, 1)
♦ med (O, .25)
0.5
0.0
0.00 0.25 0.50 0.75
12 (78.20%)
0.75
0.50
0.25
0.00
1.0
0.5
0.0
0.00 0.25 0.50 0.75
20 (78.14%)
0.00 0.25 0.50 0.75
21 (78.14%)
0.0
l∙ easy (-6f 1) I
* med (-6, .25)
♦ hard ⑵
0.75
0.50
0.25
• easy (-2, 1) I
,« med (-4,)
♦ hard (2, 1)
0.00 0.25 0.50 0.75
0.00
0.00 0.25 0.50 0.75
• easy (-2, 1) I
• med (-6, .25)
♦ hard (4, 1)
0.00 0.25 0.50 0.75
17 (78.16%)
med (-4, .25)
♦ hard (4, 1)
e,l I I
0.00 0.25 0.50 0.75
22 (78.12%)
0.75
0.50
0.25
• easy (-2, 1) I
« med (-4, .25)
♦ hard (2, 1)
0.00 0.25 0.50 0.75
• easy (-4, 1)
» med (-8, .25)
，hard (2, 1)
0.75
0.50
0.25
• easy (-4, .75)
« med (-4f .25)
♦ hard (4, .75)
0.00 0.25 0.50 0.75
13 (78.17%)
0.00 0.25 0.50 0.75
14 (78.17%)
0.75
0.50
0.25
0.00
0.75
• easy (-2, 1) I
• med (-6, .25)
♦ hard (6, .75)
0.50
0.25
0.00
0.00 0.25 0.50 0.75
18 (78.15%)
0.75
0.50
0.25
∙ easy (-4, .75)1
med (-4, .5)
⅜	♦ hard ⑵,75)
*
0.00 0.25 0.50 0.75
23 (78.10%)
0.75
0.50
0.25
0.00
1.00
• easy (0,1)
* med (-6, .25)
!♦ hard (4, .75)
0.00 0.25 0.50 0.75
19 (78.15%)
0.75
0.50
0.25
1.0
• easy (-6,1)
« med (-6f .75
♦ hard (2, 1)
0.00 0.25 0.50 0.75
24 (78.10%)
• easy (-2, 1)
med (-8, .25)
♦ hard (2. .75) .
0.00 0.25 0.50 0.75
0.5
0.0
• easy (-4, 1)
・ med (-6f .25)
0.00 0.25 0.50 0.75
Figure 16: A-B-E
20
Under review as a conference paper at ICLR 2022
O (80.12%)
0.0
O (82.15%)
7 79.92%
• easy (2, 1.2)
6 (81.83%)
9 (81.78%)
19 81.71%
20 81.69%
0.00 0.25 0.50 0.75
12 (81.76%)
1.2)
* med (-2, 1.2)
♦ hard (-10, .25)
.75)
* med (-6, -0.5)
♦ hard (10, 1.5)
♦ hard (-10, .25)
• easy (2, .5)
» med (-4, 1.2)
♦ hard (-10, .25)
• easy (2,.75)
* med (-2,1.2)
♦ hard (-10, .25)
• easy (2, 1.5]
* med (2f)
♦ hard (-10, .25) I
« med (-4, 1.2)
♦ hard (-10, .25)
0.00 0.25 0.50 0.75
5 (79.93%)
0.00 0.25 0.50 0.75
6 (79.93%)
0.00 0.25 0.50 0.75
8 (79.90%)
25 0.50
9 (79.90%)
« med (-4, 1.5)
♦ hard (-10, .25]
• easy (4 .5)
* med (-6, 1.2)
♦ hard (-10, .25)
♦ hard (-10, .25)
♦ hard (-8, .25)
0.00 0.25 0.50 0.75
10 (79.90%)
0.00 0.25 0.50 0.75
11 (79.88%)
0.00 0.25 0.50 0.75
12 (79.88%)
0.00 0.25 0.50 0.75
13 (79.86%)
0.00 0.25 0.50 0.75
14 (79.84%)
15 (79.84%)
0.00 0.25 0.50 0.75
20 (79.79%)
easy (O, 1.2)
med (10f .51
hard (-8l .25)
• easy (2, 1.2)
0.00 0.25 0.50 0.75
5 (81.83%)
• easy (2, 1.5)
♦ med (-10, .25)
♦ hard (8, 1.2)
0.25 0.50 0.75
10 (81.78%)
15 (81.74%)
•	easy (2, ,5)
•	med (-4, 1.5)
♦ hard (-10, .25)
* med (-4,1)
♦ hard (-10, .25)
0.00 0.25 0.50 0.75
16 (79.82%)
0.50
17 (79.81%)
0.00 0.25 0.50 0.75
18 (79.79%)
•	easy (0,1)
•	med (-6,1.2)
♦ hard (-10, .25)
0.00 0.25 0.50 0.75
21 (79.79%)
0.00 0.25 0.50 0.75
22 (79.79%)
0.00 0.25 0.50 0.75
23 (79.77%)
1 (82.04%)
<					
	∖				
	∖	• easy (O, 1.5) • med (-8,) ♦ hard (8, 1.2) ∣			►
0.00 0.25 0.50 0.75
16 (81.71%)
easy (0,1.2) I
med (-10f .25)
•	easy (4, 1.2)
•	med (-2r .25)
♦ hard (-10, .251
* med (-6,1.2)
‘♦ hard (-10, .25)
0.00 0.25 0.50 0.75
Figure 17: A-B-L
2 (81.98%)
3 (81.93%)
4 (81.93%)
	• easy (2, 1.5) • med (-10,) .hard (10f 1.2) ∣			:
• easy (2, 1.5) ♦ med (-8, -0.25)		
		
		
7 (81.82%)
• easy (2, 1.5)
* med (-8, -0.25)
♦ hard (10,1.5)
• easy (6, .75)∣
* med (-6,)
♦ hard (6, 1.2)
0.00 0.25 0.50 0.75
17 (81.71%)
• easy (O, 1.5)
* med (-10f .25)
♦ hard (10,1.2)
0.00 0.25 0.50 0.75
22 (81.69%)
easy (2, 1.2)
ed (-10, .25：
a rd (8,1.2)
0.00 0.25 0.50 0.75
8 (81.80%)
	<	> easy (O, 1.5) 卜 med (-10f .25) ► hard (8f 1)
一	S	
13 (81.76%)
∖	• easy (2,1.5) I ♦ med (-8,) .hard (10, 1.2) ∣			■
SS				t
0.00 0.25 0.50 0.75
18 (81.71%)
• easy (0,1.2)
• med (-10f .25)
♦ hard (10, 1.2)
0.00 0.25 0.50 0.75
23 (81.65%)
* med (-IQ1 .25)
♦ hard (10,1.2)
0.00 0.25 0.50 0.75
14 (81.74%)
	• easy (6,1) * med (-4, -0.25) .hard (6, 1.5)	∣	
0.00 0.25 0.50 0.75
24 (81.60%)
Figure 18: A-F-E
21
Under review as a conference paper at ICLR 2022
O (81.43%)
med 2, -0.25
5 81.36%
6 (81.34%)
14 81.20%
15 81.20%
20 81.16%
Figure 19: A-F-L
5 75.20%
9 75.07%
10 75.03%
13 75.00%
• easy (8, .5]
• easy (4, .5)
16 74.95%
18 74.94%
19 74.93%
20 74.90%
22 (74.86%)
23 74.84%
• easy (8, .5]
• easy (4, .5)
« med (8, .25)
♦ hard (2, .75)
» med (-4, .25) ,
♦ hard (4, a ∖
• easy (6, .5)
• med (-6,1)
• easy (10, -0.5]
» med (10,
0.00 0.25 0.50 0.75
11 (81.25%)
0.00 0.25 0.50 0.75
12 (75.01%)
• easy (8,-0.5)
* med (10, -0.25)
♦ hard ⑵ 1.2)
• easy (8, -0.5)
* med (10f -0.25)
♦ hard (4, 1.2)
7 (81.29%)
• easy (6^^∣
•» med (O, .25)
10 (81.25%)
D.00 0.25 0.50 0.75
12 (81.23%)
0.00 0.25 0.50 0.75
8 (81.29%)
• easy (6,-0.5) ∣ * med (8, -0.5) .hard (4, 1.2) ∣		
・ 4 Q		
13 (81.21%)
9 (81.27%)
• easy (8, -0.5)
* med (8, -0.25)
♦ hard (2f 1.2)
• easy (10, -0.5)
* med (10, -0.25)
♦ hard ⑵ 1)
0.50
16 (81.18%)
♦ easy (2, -0.5)
* med (4, -0.25)
♦ hard (2, 1.2)
0.00 0.25 0.50 0.75
6 (75.13%)
• easy (6, -0.5)
« med (6, -0.5)
♦ hard (4,1.2)
/ ∙ easy (10, -0.5)
，	« med (10,)
♦ hard (2,1.5)
0.00 0.25 0.50 0.75
18 (81.18%)
0.00 0.25 0.50 0.75
19 (81.16%)
• easy (8f -0.25)
“ med (10, -0.25)
• easy (4, -0.5)
• med (4, -0.25)
♦ hard (2.1.2)
0.00 0.25 0.50 0.75
22 (81.14%)
0.00 0.25 0.50 0.75
24 (81.12%)
• easy (8, -0.5)
« med (8, -0.25)
.hard (4,1)
2 (75.33%)
0.00 0.25 0.50 0.75
7 (75.08%)
0.00 0.25 0.50 0.75
14 (75.00%)
Figure 20: C-B-E
22
Under review as a conference paper at ICLR 2022
O (72.49%)
1 (72.49%)
3 (72.35%)
5 72.27%
6 72.23%
9 72.07%
0.00 0.25 0.50 0.75
20 (71.59%)
21 71.58%
0.00 0.25 0.50 0.75
0.75
♦ easy (8,.
* med (0,
easy (10f .25)
med (O, .5)
hard (-6. .75)
• easy (10, .25)
* med (O, .75)
♦ hard (-6, .75)
•	easy (10f .5)
•	med (O, .75)
♦ hard (-4. .75)
8 (72.09%)
• easy (8, .5)
* med (O, 1)
• easy (10, .5)
* med (2, .75)
♦ hard (-8. .75)
•	easy (6f .5)
•	med (-2, 1)
♦ hard (6, .25)
•	easy (8f .5)
•	med (0,1)
♦ hard (-4, .75)
12 (72.00%)
•	easy (10, .5)^
•	med (2, .5)
♦ hard (-2. .75)
• easy (10, .5)
* med (O, .75)
♦ hard (-6, 1)
13 (71.81%)
f '	ɪ,0 —
• med (O, -75)T^^	/
♦ hard (-6, .75) ∣
”…0 5一”一犬
/ « med (O, .75)	/ ▼
• easy (10, .25)
* med (-2,)
♦ hard (-6,1.2)
.25 0.50 (
19 (71.62%)
•	easy (10, .5)
•	med (0f .75)
♦ hard (-2, .75)
•	easy (10f .5)
•	med (O, .75)
♦ hard (-8,1)
• easy (8, .5)
* med (O, 1)
.hard (-2f 1.2)∣∣
24 (71.50%)
•	easy (4, .5)
•	med (-2f .5)
♦	hard (10, .25)
Figure 21: C-B-L
7 73.75%
10 (73.41%)
20 73.15%
• easy (-8, 1.2)
• easy (-10, 1.2]
• med (-2,1.2)
• easy (-10,1.2)
* med (0.1)
• easy (8,-0.5)
* med (-4. .75)
D.00 0.25 0.50 0.75
23 (73.14%)
0.00 0.25 0.50 0.75
24 (73.12%)
D.00 0.25 0.50 0.75
8 (73.75%)
0.8
0.8
0.8
•	easy (-10, 1.2]
•	med (O, 1)
♦ hard (O, -0.25)
•	easy (-10, 1.2)
•	med (0,1.2)
♦ hard (O, -0.25)
0.8
• easy (-10, 1.2J
« med (O, 1)
♦ hard (0.1)
•	easy (-10, 1.2)
•	med (O, 1.2)
♦	hard (O. 1)
0.00 0.25 0.50 0.75
6 (73.75%)
0.00 0.25 0.50 0.75
9 (73.55%)
			
•	easy RO? 1.2) •	med (O, 1.2) ，hard (O, 1.5)			
			
	
•	easy (-10, 1.2) •	med (-2f 1.5) ♦ hard (O, 1.2)	
	
• easy (-10, 1.2)
« med (0,1.5)
0.8
•	easy (-10,1.2)
•	med (0,1.5)
					
	•	easy (-10,1.2)1 •	med (O, 1.5) ♦ hard (O, -0.25)				
					
		1
• easy (-8f 1) » med (O, 1) ♦ hard (O, -0.25)		
		
0.00 0.25 0.50 0.75
11 (73.36%)
0.00 0.25 0.50 0.75
16 (73.28%)
•	easy (-8, .75)
*	med (0,1)
♦	hard (O, .25)
0.00 0.25 0.50 0.75
21 (73.15%)
12 (73.36%)
	.	
• easy (-10,1) • med (0,1.5) .hard (O, -0.5) ∣		
		
17 (73.19%)
22 (73.15%)
D.00 0.25 0.50 0.75
13 (73.31%)
0.00 0.25 0.50 0.75
14 (73.31%)
		
•	easy (-10,1.2) •	med (-2f 1.2) ，hard (O, -0.5) ∣	∙s∙	
		
		
•	easy (-10, 1.2) •	med (-2,1.2) .hard (O, L2) ∣		
		
0.00 0.25 0.50 0.75
18 (73.18%)
0.00 0.25 0.50 0.75
19 (73.16%)
	
• easy (-4,1) I » med (O, 1) .hard (O, .25) ∣	k
	12
Figure 22: C-F-E
23
Under review as a conference paper at ICLR 2022
1.0
0.5
0.0
1.0
0.8
1.00
0.75
0.50
0.25
1.0
0.5
0.0
1.0
0.5
0.0
0 (74.01%)
0.50
0.00
1 (73.92%)
2 (73.88%)
0.00 0.25 0.50 0.75
0.00 0.25 0.50 0.75
0.0
0.00
3 (73.88%)
4 (73.87%)
0.00 0.25 0.50 0.75
5 (73.80%)
7 (73.79%)
6 (73.79%)
0.25 0.50 0.75
8 (73.70%)
0.00 0.25 0.50 0.75
0.00 0.25 0.50 0.75
0.0
0.00
9 (73.66%)
0.25 0.50 0.75
0.00 0.25 0.50 0.75
10 (73.57%)
11 (73.57%)
12 (73.55%)
13 (73.54%)
14 (73.53%)
0.00 0.25 0.50 0.75
0.00 0.25 0.50 0.75
0.00 0.25 0.50 0.75
0.00 0.25 0.50 0.75
0.00 0.25 0.50 0.75
15 (73.49%)
16 (73.48%)
17 (73.45%)
18 (73.44%)
0.00 0.25 0.50 0.75
0.00 0.25 0.50 0.75
0.00 0.25 0.50 0.75
0.75
0.50
0.25
1.00
0.00 0.25 0.50 0.75
20 (73.44%)
21 (73.40%)
22 (73.36%)
0.00 0.25 0.50 0.75
0.00 0.25 0.50 0.75
0.50
0.25
Figure 23: C-F-L
23 (73.31%)
∙ easy (4, -0.25)
卜 med (-2, .25)
♦ hard (-4l 1.2)
0.00 0.25 0.50 0.75
19 (73.44%)
0.00 0.25 0.50 0.75
24 (73.31%)
0.00 0.25 0.50 0.75
24