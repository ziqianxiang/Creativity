Under review as a conference paper at ICLR 2022
Distributionally Robust Recourse Action
Anonymous authors
Paper under double-blind review
Ab stract
Recourse actions aim to explain a particular algorithmic decision by showing one
or multiple ways in which the instance could be modified to receive an alter-
nate outcome. Existing recourse recommendations often assume that the machine
learning models do not change over time. However, this assumption does not
always hold in practice because of data distribution shifts, and in this case, the re-
course actions may become invalid. To redress this shortcoming, we propose the
Distributionally Robust Recourse Action framework, which generates a recourse
action that has high probability of being valid under a mixture of model shifts. We
show that the robust recourse can be found efficiently using a projected gradient
descent algorithm and we discuss several extensions of our framework. Numerical
experiments with both synthetic and real-world datasets demonstrate the benefits
of our proposed framework.
1 Introduction
Post-hoc explanations of machine learning models are useful for understanding and making reliable
predictions in consequential domains such as loan approvals, college admission and healthcare.
Recently, recourse is rising as an attractive tool do diagnose why the machine learning models have
made a particular decision for a given instance. Recourse work by providing possible actions to
modify a given instance to receive an alternate decision (Ustun et al., 2019). Consider, for example,
the case of loan approvals in which a credit application is rejected. The counterfactual will offer the
reasons for rejection by showing what the application package should have been to get approved. A
concrete example of a counterfactual in this case may be “the monthly salary should be higher by
$500” or “20% of the current debt should be reduced”.
Recourses have a positive, forward-looking meaning: they list out the recourse actions that a person
should implement so that they can get a more favorable outcome in the future. If a specific applica-
tion can provide the negative outcomes with recourse actions, it can improve the user engagement
and boost the interpretability at the same time (Ustun et al., 2019; Karimi et al., 2021). Explanations
thus play a central role in the future development of human-centric machine learning.
Despite its attractiveness, providing recourse for the negative instances is not a trivial task. For real-
world implementation, designing a recourse needs to strike an intricate balance between conflicting
criteria. First and foremost, a recourse action should be feasible: if the prescribed action is taken,
then the prediction of a machine learning model should be flipped. At the same time, a framework
for generating recourse should minimize the cost to take recourse actions to avoid making a drastic
change to the characteristics of the input instance. An algorithm for finding recourse must make
change to only features that are actionable, and should leave immutable features (relatively) un-
changed. For example, we must consider date of birth as an immutable feature; in contrast, we can
consider salary or debt amount as actionable features.
Various solutions has been proposed to provide recourses for a model prediction (Karimi et al.,
2021; Stepin et al., 2021; Artelt & Hammer, 2019). For instance, Ustun et al. (2019) used an integer
programming approach to obtain actionable recourses, and also provide a feasibility guarantee for
linear models. Karimi et al. (2020) proposed a model-agnostic approach to generate nearest coun-
terfactual explanations and focus on structured data. Dandl et al. (2020) proposed a method which
finds counterfactual by solving a multi-objective optimization problem. Recently, Russell (2019)
and Mothilal et al. (2020) focus on finding a set of multiple diverse recourse actions, where the
1
Under review as a conference paper at ICLR 2022
diversity is imposed by a rule-based approach or by internalize a determinant point process cost in
the objective function.
These aforementioned approaches make a fundamental assumption that the machine learning model
does not change over time. However, the dire reality suggests that this assumption rarely holds. In
fact, data shifts are so common nowadays in machine learning that they have sparkled the emerg-
ing field of domain generalization and domain adaptation. Organizations usually retrain models
as a response to data shifts and this induces corresponding shifts in the machine learning models
parameters, which in turns cause serious concerns for the feasibility of the recourse action in the
future (Rawal et al., 2021). In fact, all of the aforementioned approaches design the action which is
feasible only with the current model parameters, and they provide no feasibility guarantee for the
future parameters. If a recourse action fails to generate a favorable outcome in the future, then the
recourse action may become less beneficial (Venkatasubramanian & Alfano, 2020), the pledge of
a brighter outcome is shattered, and the trust on the machine learning system is lost (Rudin, 2019;
Ribeiro et al., 2016).
To tackle this challenge, Upadhyay et al. (2021) proposed ROAR, a framework for generating in-
stance level recourses (counterfactual explanations) that are robust to shifts in the underlying pre-
dictive model. ROAR used a robust optimization approach that hedges against an uncertainty set
containing plausible values of the future model parameters. However, it is well-known that ro-
bust optimization solutions can be overly conservative because they may hedge against a patholog-
ical parameter in the uncertainty set. A promising approach that can promote robustness, while
at the same time prevent from over-conservatism is the distributionally robust optimization frame-
work (El Ghaoui et al., 2003; Delage & Ye, 2010; Rahimian & Mehrotra, 2019; Bertsimas et al.,
2018). This framework models the future model parameters as random variables whose underlying
distribution is unknown, but is likely to be contained in an ambiguity set. The solution is designed
to counter the worst-case distribution in the ambiguity set in a min-max sense. Distributionally
robust optimization is also gaining popularity in many estimation and prediction tasks in machine
learning (Namkoong & Duchi, 2017; Kuhn et al., 2019).
Contributions. This paper combines ideas and techniques from two principal branches of explain-
able artificial intelligence: counterfactual explanations and robustness, in order to resolve the re-
course problem under uncertainty. Concretely, our main contributions are the following:
1.	We propose the framework of Distributionally Robust Recourse Action (DiRRAc) for designing
a recourse action that is robust to mixture shifts of the model parameters. Our DiRRAc maxi-
mizes the probability that the action is feasible with respect to a mixture shift of model parame-
ters, while at the same time cap the action in the neighborhood of the input instance. Moreover,
the DiRRAc model also hedges against the misspecification of the nominal distribution using a
min-max form with a mixture ambiguity set prescribed by moment information.
2.	We reformulate the DiRRAc problem into a finite-dimensional optimization problem with an
explicit objective function. We also provide a projected gradient descent to solve the resulting
reformulation with convergence guarantees.
3.	We extend our DiRRAc framework along several axis to handle mixture weight uncertainty, to
minimize the worst-case component probability of receiving unfavorable outcome, and also to
inject the Gaussian parametric information.
We first describe the recourse action problem with mixture shift in Section 2. In Section 3, we
present our proposed DiRRAc framework, its reformulation and the numerical routine for solving
it. The extension to the parametric Gaussian setting will be subsequently discussed in Section 4.
Section 5 reports the numerical experiments showing the benefits of the DiRRAc framework and its
extensions.
Notations. For each integer K, we have [K] = {1, . . . , K}. We use Sd+ (Sd++) to denote the
space of symmetric positive semidefinite (definite, respectively) matrices. For any A ∈ Rm×m ,
the trace operator is defined as Tr [A] = Pid=i Au. We write Qk 〜(μk, ∑k) to denote that the
distribution Qk has mean vector μk and covariance matrix ∑k. If additionally Qk is Gaussian, We
write Qk 〜N(μk, ∑k). With a slight abuse of notation, Q 〜(Qk,pk )k∈[κ] means Q is a mixture
of K component distributions, the k-th component has weight pk and distribution Qk.
2
Under review as a conference paper at ICLR 2022
2 Recourse Action under Mixture Shifts
We consider a binary classification setting with label Y = {0, 1}, where 0 represents the unfavorable
outcome while 1 denotes the favorable one. The covariate space is Rd, and any linear classifier
Cθ : Rd → Y characterized by the d-dimensional parameter θ is of the form
C ( )	1 ifθ>x≥0,
θ 0 otherwise.
Note that the bias term can be internalized into θ by adding an extra dimension, and thus it is omitted.
Suppose that at this moment (t = 0), the current classifier is parametrized by θ0 , and we are given
an input instance x0 ∈ Rd with unfavorable outcome, that is, Cθ0 (x0) = 0. One period of time from
now (t = 1), the parameters of the predictive model will change stochastically, and are represented
by a d-dimensional random vector θ . This paper focuses on finding a recourse action x which is
reasonably close to the instance x0 , and at the same time, has a high probability of receiving a
favorable outcome in the future. Figure 1 gives a bird’s eye view of the setup
Now
Future
t = 0
t = 1
Current classifier: θ0
Input: xq with Cθo (a⅛) = 0
Counterfactual: x
---------------1----------------► Time
Future classifier: θ 〜(θk, ∑fc,pfc)fc∈[κ]
Figure 1: A canonical setup of the recourse action under mixture shifts problem.
To measure the closeness between the action x and the input x0 , we assume that the covariate space
is endowed with a non-negative, continuous cost function c. In addition, suppose temporarily that θ
follows a distribution P. Because maximizing the probability of the favorable outcome is equivalent
to minimizing the probability of the unfavorable outcome, the recourse can be found by solving
.	ʌ Z -	Z	X	一、
mm	P(Cd(X) = 0)
s. t.	x ∈ X, c(x, x0) ≤ δ.
(1)
The parameter δ ≥ 0 in (1) governs how far a recourse action can be from the input instance x0.
Note that we constrain x in a set X which captures operational constraints, for example, the highest
education of a credit applicant should not be decreasing over time.
In this paper, we model the random vector θ using a finite mixture of distributions with K com-
ponents, the mixture weights are pb satisfying Pk∈[K] pbk = 1. Each component in the mixture
represents one specific type of data shifts: the weights pb reflect the proportion of the shift types
while the component distribution Pk representing the (conditional) distribution of the future model
parameters in the k-th shift. Further information on mixture distributions and their applications in
machine learning can be found in Murphy (2012, §3.5).
If each Pk is a Gaussian distribution N (θk , Σk), then P is a mixture of Gaussian distributions. The
objective of problem (1) can be expressed as
Pb(Cθd(x) = 0) = X pbkPbk (Cθd(x) = 0) = X pbkΦ
k∈[K]
k∈[K]
-x> θbk
x>Σbkx
where the first equality follows from the law of conditional probability, and Φ is the cumulative
distribution function of a standard Gaussian distribution. Under the Gaussian assumption, we can
solve (1) using a projected gradient descent type of algorithm (Boyd & Vandenberghe, 2004).
Remark 2.1 (Nonlinear models). Our analysis focuses on linear classifiers, which is a common
setup in the literature (Upadhyay et al., 2021; Ustun et al., 2019; Rawal et al., 2021; Karimi et al.,
2020; Wachter et al., 2018; Ribeiro et al., 2016). To extend to nonlinear classifiers, we can follow
a similar approach as in Rawal & Lakkaraju (2020) and Upadhyay et al. (2021) by first using
LIME (Ribeiro et al., 2016) to approximate the nonlinear classifiers locally with an interpretable
linear model, then subsequently applying our framework.
3
Under review as a conference paper at ICLR 2022
3 Distributionally Robust Recourse Action Framework
Our Distributionally Robust Recourse Action (DiRRAc) framework robustifies formulation (1) by
relaxing the parametric assumption and hedging against distribution misspecification. First, we
assume that the mixture components Pbk are specified only through moment information, and no
particular parametric form of the distribution is imposed. In effect, Pbk is assumed to have mean
vector θbk ∈ Rd and positive definite covariance matrix Σb k 0. Second, we leverage ideas from
distributionally robust optimization to propose a min-max formulation of (1), in which we consider
an ambiguity set which contains a family of probability distributions that are sufficiently close to the
nominal distribution P. To prescribe the ambiguity set, we use the Gelbrich distance.
Definition 3.1 (Gelbrich distance). The Gelbrich distance G between two tuples (θ, Σ) ∈ Rd × Sd+
and (θ, Σ) ∈ Rd X S+ amounts to G((θ, Σ), (b, Σ))，^∖∖θ - b∣∣2 +Tr [∑ + Σ - 2(Σ2ΣΣ 1) 1 ].
It is easy to verify that G is non-negative, symmetric and it vanishes to zero if and only if
(θ, Σ) = (θb, Σb). Further, G is a distance on Rd X Sd+ because it coincides with the type-2 Wasser-
stein distance between two GaUssian distributions N(μ, Σ) and N(μ, Σ) (Givens & Shortt, 1984).
Distributionally robust formulations with moment information prescribed by the G distance are
computationally tractable under mild conditions, deliver reasonable performance guarantees and
also generate a conservative approximation of the Wasserstein distributionally robust optimization
problem (Kuhn et al., 2019).
In this paper, we use
the Gelbrich distance G to form a
neighborhood around each Pbk
as
Bk(Pk) , {Qk : Qk 〜(θk, Σk), G((θk, Σk), (bk, Σk)) ≤ Pk}.
Intuitively, one can view Bk (Pbk ) as a ball centered at the nominal component Pbk of radius ρk ≥
0 prescribed using the distance G. This component set Bk(Pbk) is non-parametric, and the first
two moments of Qk are sufficient to decide whether Qk belongs to Bk (Pk). Moreover, if Qk ∈
Bk (Pk ), then any distribution Q0k with the same mean vector and covariance matrix as Qk also
^
^
belongs to Bk(Pk). Notice that even when the radius ρk is zero, the component set Bk (Pk) does not
collapse into a singleton. Instead, if ρk = 0 then Bk(Pk) still contains all distributions of the same
moment (θk, Σk) with the nominal component distribution Pk, and consequentially it possesses the
robustification effects against the parametric assumption on Pbk. The component sets are utilized to
construct the ambiguity set for the mixture distribution as
B(b)，{Q ： ∃Qk ∈ Bk(bk) ∀k ∈ [K] such that Q 〜(Qk方"闿}.
Any Q ∈ B(P) is also a mixture distribution with K components, with the same mixture weights pb.
Thus, B(P) contains all perturbations of P induced separately on each component by Bk(Pk).
We are now ready to introduce our DiRRAc model, which is a min-max problem of the form
inf	SUP Q(CQ)= 0)
x∈X	Q∈B(Pb)
s. t. c(x, x0) ≤ δ	(2)
sup	Qk (C,(χ) = 0) < 1	∀k ∈ [K].
- -~ ,ʌ ,
Qk ∈Bk (bPk)
The objective of (2) is to minimize the worst-case probability of unfavorable outcome of the recourse
action. Moreover, the last constraint imposes that for each component, the worst-case conditional
probability of unfavorable outcome should be strictly less than 1. Put differently, this last constraint
requires that the action should be able to lead to favorable outcome for any distribution in Bk (Pk).
By definition, each supremum subproblem in (2) is an infinite-dimensional maximization problem
over the space of probability distributions, and thus it is inherently difficult. Fortunately, because we
use the Gelbrich distance to prescribe the set Bk (Pk), we can solve these maximization problems
4
Under review as a conference paper at ICLR 2022
analytically. This consequentially leads to a closed-form reformulation of the DiRRAc model into
a finite-dimensional problem. Next, we will reformulate the DiRRAc problem (2), provide a sketch
of the proof and propose a numerical solution routine.
3.1	Reformulation of DiRRAc
Each supremum in (2) is an infinite-dimensional optimization problem on the space of probability
distributions. We now show that (2) can be reformulated as a finite-dimensional problem. Towards
this end, let X be the following d-dimensional set
X，{x ∈ X : c(x,xo) ≤ δ, -b>x + Pk∣∣xk2 < 0 ∀k ∈ [K] } .	(3)
The next theorem asserts that the DiRRAc problem (2) can be reformulated as a d-dimensional
optimization problem with an explicit, but complicated, objective function.
Theorem 3.2 (Equivalent form of DiRRAc). Problem (2) is equivalent to the following finite-
dimensional problem
xi∈nXf	pbk
k∈[K]
Pkb>χ∣∣χ∣∣2 + Jχ>∑kχʌ/(b>χ)2 + χτ∑kχ - Pkkχ∣2	2
(b>x)2 + x>∑ k X
(4)
3.2	Proof S ketch
We now sketch the proof of Theorem 3.2. For any component k ∈ [K], define the following worst-
case probability of unfavorable outcome function
fk(x) ,	sup	Qk(Cd(X) =0)= sup	Qk(”x ≤ 0) Vk ∈ [K].	(5)
,	.〜 ,o 、	.	,0 、
Qk∈Bk (bPk)	Qk∈Bk (bPk)
To proceed, we rely on the following elementary result from Nguyen (2019, Lemma 3.31).
Lemma 3.3 (Worst-case Value-at-Risk). For any X ∈ Rd and β ∈ (0, 1), we have
inf T : sup	Qk (θτx ≤ -T) ≤ β
Qk ∈Bk(bPk)
∣X∣2.
(6)
Note that the left-hand side of (6) is the worst-case Value-at-Risk with respect to the ambiguity set
in	∖ ɪ	∙	,1 ∙	1, ,1	,	∙ , ∙	∙ 1 ,1	1 ,∙ if	c e / 、
Bk (Pk ). Leveraging this result, the next proposition provides the analytical form of fk (X).
Proposition 3.4 (Worst-case probability). For any k ∈ [K] and (θbk, Σb k, Pk) ∈ Rd × Sd+
× R+,
define the following constants Ak , -θbkτX, Bk
XτΣb kX, and Ck , Pk ∣X∣2. We have
fk (x) ,	sup Qk (”x ≤ 0)
Qk ∈Bk (Pbk )
∈ (0, 1)
ifAk+Ck ≥0,
ifAk+Ck <0.
The proof of Theorem 3.2 follows by noticing that the DiRRAc problem (2) can be reformulated
using the elementary functions fk as
min J X pkfk(x) : c(x,xo) ≤ δ, fk(x) ≤ 0 Vk ∈ [K]J ,
x∈X
(k∈[K]
where the objective function follows from the definition of the set B(Pb ). It suffices now to combine
with Proposition 3.4 to obtain the necessary result. The detailed proof is relegated to the Appendix.
5
Under review as a conference paper at ICLR 2022
3.3	Projected Gradient Descent Algorithm
We consider in this section an iterative numerical routine to solve the DiRRAc problem in the equiv-
alent form (4). First, notice that the second constraint that defines X in (3) is a strict inequality, thus
the set X is open. We thus modify slightly this constraint by considering the following set
Xε = x ∈ X : c(x, x0) ≤ δ, -θbk>x + ρkkxk2 ≤ -ε ∀k ∈ [K]
for some value ε > 0 sufficiently small. Moreover, if the parameter δ is too small, it may happen that
the feasible set Xε becomes empty. Let δmin ∈ R+ be defined as the optimal value of the following
optimization problem
δ ,	inf	c(x,x0)
δmin ,	s.t.	x ∈ X,	-θbk>x+ρkkxk2	≤ -ε	∀k	∈ [K].
(7)
Then it is easy to see that Xε is non-empty whenever δ ≥ δmin . In addition, because c is continuous
and X is closed, the set Xε is compact. In this case, we can consider problem (4) with the feasible
set being Xε , for which the optimal solution is guaranteed to exist.
Let us now define the projection operator ProjX
as
ProjXε(x0) = arg min {∣∣x - x0∣∣2 : X ∈ Xε }.
If X is convex and c( ∙, x0) is a convex function,
then Xε is also convex, and the projection opera-
tion can be efficiently computed using convex op-
timization. In particular, suppose that c(x, x0) =
kx - x0 k2 is the Euclidean norm and X is second-
order cone representable, then the projection is
equivalent to a second-order cone program, and
can be solved using off-the-shelf solvers such as
GUROBI or Mosek (MOSEK ApS, 2019). The
projection operator ProjX now forms the build-
ing block of a projected gradient descent algo-
rithm with a backtracking linesearch. The details
regarding the algorithm, along with the conver-
gence guarantee, are presented in Appendix E.
Figure 2: Shaded area represents X . Cir-
cular arc represents the proximity constraint
c(x, x0) = δ. Dashed lines represent the hy-
perplane -θbk>x = 0, elliptic curves represent
the robust margin -θbk>x + ρk kxk = 0. In-
creasing ρk brings the elliptic curves farther
away from the dash lines, and the set X moves
deeper inside the favorable prediction region.
4 Gaussian DiRRAc Framework
We here revisit the Gaussian assumption on the component distributions, and propose the parametric
Gaussian DiRRAc framework. We make the temporary assumption that Pbk are Gaussian for all
k ∈ [K], and we will robustify against only the misspecification of the nominal mean vector and
covariance matrix (θk, Σk). To do this, we first construct the Gaussian component ambiguity sets
Vk :	BN(Pk) , {Qk : Qk ~ N(θk, Σk), G((θk, Σk), (θk, Σk)) ≤ Pk},
where the superscript emphasizes that the ambiguity sets are neighborhoods in the space of Gaussian
distributions. The resulting ambiguity set for the mixture distribution is
BN(P) = {q ： ∃Qk ∈ BN(Pk) Vk ∈ [K] SUCh that Q ~ (Qk,bk)k∈[K]}.
The Gaussian DiRRAc problem is formally defined as
min SUp Q(C.(x) = 0)
x∈X Q∈BN (bP)
s. t. c(x, x0) ≤ δ	(8)
sup	Qkg(X) =0) < 1	Vk ∈ [K].
Qk∈BkN(bPk)
6
Under review as a conference paper at ICLR 2022
Similar to Section 3, we will provide the reformulation of the Gaussian DiRRAc formulation and a
sketch of the proof in the sequence. Note that the last constraint in (8) has margin 2 instead of 1 as
in the DiRRAc problem (2). The detailed reason is revealed in the proof sketch in Section 4.2.
4.1 Reformulation of Gaussian DiRRAc
Remind that the feasible set X is defined as in equation 3. The next theorem asserts the equivalent
form of the Gaussian DiRRAc problem (8).
Theorem 4.1 (Gaussian DiRRAc reformulation). The Gaussian DiRRAc problem (8) is equivalent
to the following optimization problem
xm∈iXn 1 -	pbkΦ
k∈[K]
(θbk>x)2 - ρ2kkxk22
b>xy x>ΣkX + Pk∣∣χk2 J(θ>χ)2 + x>∑kX - Pkkxk2
(9)
Problem (9) can be solved using the projected gradient descent algorithm discussed in Section 3.3.
Note that the gradient of the objective function can be evaluated easily using the chain rule.
4.2 Proof S ketch
The proof of Theorem 4.1 relies on the following result which asserts the analytical form of the
worst-case Value-at-Risk under parametric Gaussian ambiguity set (Nguyen, 2019, Lemma 3.31).
Lemma 4.2 (Worst-case Gaussian ValUe-at-Risk). For any X ∈ Rd and β ∈ (0,1 ], we have
inf T : sup	Qk(”x ≤ —τ) ≤ β = —θ>x + tγ x>ΣkX + Pp 1 +12∣∣x∣2	(10)
Qk∈BkN (bPk)
with t = Φ-1(1 — β).
It is important to note that Lemma 4.2 is only valid for β ∈ (0,0.5]. Indeed, for β > 1, evaluat-
ing the infimum problem in the left-hand side of (10) requires solving a non-convex optimization
problem as t = Φ-1(1 - β) < 0. As a consequence, the last constraint of the Gaussian DiRRAc
formulation (8) is capped at a probability value of 0.5 to ensure the convexity of the feasible set
in the reformulation (9). The proof of Theorem 4.1 follows a similar line of argument as for the
DiRRAc formulation, the details are relegated to the appendix.
5 Numerical Experiments
In this section, we evaluate the performance of our DiRRAc framework on popular benchmarks.
We will compare our proposed DiRRAc model (2) and Gaussian DiRRAc model (8) against
three state-of-the-art methods: the Robust and Reliable Algorithmic Recourse (ROAR) (Upad-
hyay et al., 2021), Actionable Recourse (AR) in linear classification (Ustun et al., 2019) and
Model Agnostic Contrastive Explanations (MACE) (Karimi et al., 2020). Throughout, we use
the l1 distance c(X, X0) = ∣X — X0 ∣1. Complementary results and details about the datasets and
the experiment setup are provided in Appendix A. All codes and results can be accessed from
https://anonymous.4open.science/r/DiRRAc.
Results on synthetic data. We synthesize 2-dimensional data by using K = 3 different shifts
similar to Upadhyay et al. (2021): mean shift, covariance shift, and both shifts. First, we fix the
unshifted conditional distributions with X|Y = y 〜 N (μy, Σy) ∀y ∈ Y. For mean shift, we
replace μo by μ∩llft
replace Σ0 by Σs0hift
shift, We replace (μo, ∑o) by (μ
μo + [α, 0]>, where α is a mean shift magnitude. For covariance shift, we
(1+β)Σ0, Where β is a covariance shift magnitude. For mean and covariance
s0hift, Σs0hift). We generate 500 samples each class from the unshifted
distribution with μo = [—3; -3], μι = [3; 3], and ∑o = ∑ι = I. To estimate θk and Σk for
synthetic data, we define valid mixture weights pb, generate data for each component for 100 times
with the same ratio as the mixture weight. We train 100 logistic classifiers to compute the empirical
mean θbk and the empirical covariance matrix Σb k for the k-th component. We generate recourse for
7
Under review as a conference paper at ICLR 2022
each test instance that belongs to negative class. Finally, we compute the empirical validity as the
fraction of instances that are still valid with respect to the shifted classifiers. The results in Figure 3
demonstrate that recourses generated by our framework are robust to model shifts, other baselines
have low validity with even a small shift magnitude.
β	a,β
Figure 3: Impact of magnitude of distribution shifts to empirical validity
Real-world data. We use three real-world datasets which capture different data distribution
shifts (Dua & Graff, 2017): (i) the German credit dataset, which captures a correction shift. (ii)
the Small Business Administration (SBA) dataset, which captures a temporal shift. (iii) the Stu-
dent performance dataset, which captures a geospatial shift. Each dataset contains original data and
shifted data. We normalize all continuous features to [0, 1]. Similar to Mothilal et al. (2020), we
use one-hot encodings for categorial features, then consider them as continuous features in [0, 1]. To
ease the comparison, we choose K = 1. To estimate (θ1, Σ1), we split randomly 80% of the original
dataset and train a logistic classifier. This process is repeated independently 100 times to obtain 100
observations of the model parameters, then we compute the empirical mean and covariance matrix
for (θ1, Σ1). In parallel, we randomly split 80-20 the shifted dataset 100 times, and each time train
a logistic classifier on the training set. This procedure generates 100 future model parameters.
To measure the performance of each method, we do a (80% training, 20% testing) split of the original
dataset, train a linear classifier on the training data. and generate recourse for each test instance that
is classified as unfavorable. To compute M1 validity, we split randomly 80% of the original data
100 times and train 100 logistic classifier. The M1 validity is computed by the empirical validity
on those 100 model parameters. The M2 validity is measured by the empirical validity on the 100
future model parameters, and we also compute the l1 and l2 distance between the recourse and the
original instance. The results in Table 1 demonstrate that our DiRRAc have high validity, while
keeping the l1 and l2 cost low. ROAR has high validity in all three datasets, but also has higher cost
than our framework.
Table 1: Benchmark of M1 validity, M2 validity, l1 and l2 cost on different real-world datasets.
Dataset	Methods	Mi validity	M2 validity	l1 cost	l2 cost
German Credit	AR	0.73 ± 0.25	0.78 ± 0.00	1.26 ± 0.68	0.94 ± 0.41
	MACE	0.87 ± 0.15	0.97 ± 0.00	2.11 ± 0.86	1.20 ± 0.47
	ROAR	1.00 ± 0.00	1.00 ± 0.00	2.60 ± 0.40	1.08 ± 0.16
	DiRRAc	1.00 ± 0.00	1.00 ± 0.00	2.09 ± 0.43	0.96 ± 0.18
	Gaussian DiRRAc	1.00 ± 0.00	0.93 ± 0.05	0.73± 0.47	0.47± 0.38
SBA	AR	0.26 ± 0.24	0.42 ± 0.14	3.41 ± 2.10	1.56 ± 0.76
	MACE	1.00 ± 0.00	1.00 ± 0.00	6.85 ± 0.56	2.50 ± 0.11
	ROAR	1.00 ± 1.00	1.00 ± 0.00	2.25 ± 0.55	0.98 ± 0.23
	DiRRAc	1.00 ± 0.00	1.00 ± 0.00	1.13 ± 0.43	0.82 ± 0.31
	Gaussian DiRRAc	1.00 ± 0.01	1.00 ± 0.00	1.14 ± 0.42	0.83 ± 0.30
Student Performance	AR	0.28 ± 0.08	0.35 ± 0.12	1.18 ± 0.99	0.82 ± 0.60
	MACE	0.66 ± 0.12	0.57 ± 0.10	0.81 ± 0.40	0.51 ± 0.24
	ROAR	1.00 ± 0.01	0.98 ± 0.02	1.70 ± 0.27	0.81 ± 0.13
	DiRRAc	1.00± 0.00	0.99± 0.02	0.74 ± 0.18	0.63 ± 0.14
	Gaussian DiRRAc	1.00 ± 0.00	0.98 ± 0.02	0.74 ± 0.18	0.74 ± 0.18
Nonlinear models. Following the previous work as in Rawal et al. (2021) and Upadhyay et al.
(2021), we adapt our framework and other baselines to non-linear models by first generating local
8
Under review as a conference paper at ICLR 2022
linear approximations using LIME (Ribeiro et al., 2016). LIME is a popular method that explains
the predictions of a machine learning model by learning an interpretable model locally around an
input instance x0 . To obtain a local explanation, LIME synthesizes perturbed examples in the lo-
cal neighborhood of x0, queries the predictions of models for these examples, and then trains an
interpretable model based on these labeled synthetic examples.
For each instance x0 , we first do a 80-20 split on the original dataset and train a MLPs classifier
on the training data. Then generate a local linear model for MLPs classifier 10 times using LIME
with 1000 perturbed samples. To estimate (θ1, Σ1), we compute the mean and covariance matrix
of parameters θx0 of 10 local linear models. We generate recourse for each instance of test data
that belongs to negative class . We choose randomly 10% of shifted dataset and concatenate with
training data of original dataset, then train a MLPs classifier. This process is repeated 10 times to
obtain 10 shifted classifiers. We evaluate the M1 and M2 validity of each method by computing
validity of recourses on the original MLPs classifier and the shifted classifiers.
The results in Table 2 demonstrate that our DiRRAc have a higher validity than other baselines in
the original and shifted MLPs classifier, while keeping the l1 and l2 cost low.
Table 2: Benchmark of M1 validity, M2 validity, l1 and l2 cost for non-linear models on different
real-world datasets.
Dataset	Methods	Mi validity	M2 validity	l1 cost	l2 cost
German Credit	AR	0.67 ± 0.47	0.59 ± 0.38	1.00± 0.00	1.00
	MACE	0.67 ± 0.47	0.31 ± 0.22	1.99 ± 0.29	1.19 ± 0.13
	ROAR	0.87 ± 0.26	0.66 ± 0.33	2.66 ± 0.16	1.21 ± 0.01
	DiRRAc	1.00± 0.00	0.80± 0.18	1.07 ± 0.01	1.00 ± 0.01
	Gaussian DiRRAc	0.91 ± 0.29	0.73 ± 0.29	1.05 ± 0.07	0.95 ± 0.17
SBA	AR	1.00 ± 0.00	0.72 ± 0.27	1.02± 0.04	1.00 ± 0.00
	MACE	1.00 ± 0.00	0.75 ± 0.16	5.90 ± 0.45	2.31 ± 0.07
	ROAR	0.91 ± 0.29	0.91 ± 0.29	3.34 ± 0.22	1.07 ± 0.07
	DiRRAc	1.00± 0.00	0.97± 0.09	1.07 ± 0.03	0.73 ± 0.11
	Gaussian DiRRAc	1.00 ± 0.00	0.85 ± 0.23	1.07 ± 0.03	0.81 ± 0.09
Student Performance	AR	0.47 ± 0.50	0.41 ± 0.44	1.02 ± 0.02	1.02 ± 0.02
	MACE	0.60 ± 0.49	0.60 ± 0.49	3.04 ± 1.61	1.44 ± 0.57
	ROAR	0.95 ± 0.22	0.86 ± 0.29	3.67 ± 0.60	1.24 ± 0.17
	DiRRAc	1.00 ± 0.00	0.94 ± 0.17	0.95 ± 0.56	0.84 ± 0.26
	Gaussian DiRRAc	1.00 ± 0.00	0.96± 0.16	0.95 ± 0.56	0.87 ± 0.30
6 Concluding Remarks
In this work, we proposed the Distributionally Robust Recourse Action (DiRRAc) framework to
address the problem of recourse robustness to model shifts. We introduced a distributionally robust
optimization approach for generating robust recourse using a projected gradient descent algorithm.
Furthermore, we also discuss several extensions of our framework. The experiments with synthetic
and real-world datasets demonstrated that our framework has the ability to generate recourse that
are robust to model shifts under different types of data distribution shifts. We also showed that our
framework can be adapted to different model types, linear and non-linear models.
Remark 6.1 (Extensions). The DiRRAc framework can be extended to hedge against the misspec-
ification of the mixture weights pb. Alternatively, the objective function of DiRRAc can be modified
to minimize the worst-case component probability. These extensions are explored in Section C.
Corresponding extensions for the Gaussian DiRRAc framework are presented in Section D.
Remark 6.2 (Choice of ambiguity set). The distributionally robust result in this paper relies funda-
mentally on the design of the ambiguity sets using a Gelbrich distance on the moment space. This
Gelbrich ambiguity set leads to the ∣∣ ∙ ∣∣2-regularizations of the worst-case Value-at-Risk in Lem-
mas 3.3 and 4.2. If we consider other moment ambiguity sets, for example, the moment bounds
in Delage & Ye (2010) or the Kullback-Leibler-type sets in Taskesen et al. (2021), then these reg-
ularization equivalence are not available, and there is no trivial way to extend the distributionally
robust results to provide the reformulation of the (Gaussian) DiRRAc framework.
9
Under review as a conference paper at ICLR 2022
References
Andre Artelt and Barbara Hammer. On the computation of Counterfactual explanations - a survey.
arXiv:1911.07749, 2019.
G. Bayraksan and D. K. Love. Data-driven stochastic programming using phi-divergences. IN-
FORMS TutORials in Operations Research,pp.1-19, 2015.
Amir Beck. First-order Methods in Optimization. SIAM, 2017.
Aharon Ben-Tal, Dick Den Hertog, Anja De Waegenaere, Bertrand Melenberg, and Gijs Rennen.
Robust solutions of optimization problems affected by uncertain probabilities. Management Sci-
ence, 59(2):341-357, 2013.
D. Bertsimas, V. Gupta, and N. Kallus. Data-driven robust optimization. Mathematical Program-
ming, 167(2):235-292, 2018.
S. Boyd and L. Vandenberghe. Convex Optimization. Cambridge University Press, 2004.
Paulo Cortez and Alice Silva. Using data mining to predict secondary school student performance.
Proceedings of 5th FUture BUsiness TEChnology Conference, 2008.
Susanne Dandl, Christoph Molnar, Martin Binder, and Bernd Bischl. Multi-objective counterfactual
explanations. In International Conference on Parallel Problem Solving from Nature, pp. 448-469.
Springer, 2020.
E. Delage and Y. Ye. Distributionally robust optimization under moment uncertainty with application
to data-driven problems. Operations Research, 58(3):595-612, 2010.
Dheeru Dua and Casey Graff. UCI machine learning repository, 2017. URL http://archive.
ics.uci.edu/ml.
John C Duchi, Peter W Glynn, and Hongseok Namkoong. Statistics of robust optimization: A
generalized empirical likelihood approach. Mathematics of Operations Research, 2021.
L. El Ghaoui, M. Oks, and F. Oustry. Worst-case value-at-risk and robust portfolio optimization: A
conic programming approach. Operations Research, 51(4):543-556, 2003.
C.R. Givens and R.M. Shortt. A class of Wasserstein metrics for probability distributions. The
Michigan Mathematical Journal, 31(2):231-240, 1984.
Tatsunori Hashimoto, Megha Srivastava, Hongseok Namkoong, and Percy Liang. Fairness without
demographics in repeated loss minimization. In International Conference on Machine Learning,
pp. 1929-1938, 2018.
Amir-Hossein Karimi, Gilles Barthe, Borja Balle, and Isabel Valera. Model-agnostic counterfactual
explanations for consequential decisions. arXiv preprint arXiv:1905.11190, 2020.
Amirhossein Karimi, Bernhard Scholkopf, and Isabel Valera. A survey of algorithmic recourse:
Contrastive explanations and consequential recommendations. arXiv preprint arXiv:2010.04050,
2021.
D. Kuhn, P. Mohajerin Esfahani, V.A. Nguyen, and S. Shafieezadeh-Abadeh. Wasserstein distribu-
tionally robust optimization: Theory and applications in machine learning. INFORMS TutORials
in Operations Research, pp. 130-169, 2019.
Min Li, Amy Mickel, and Stanley Taylor. “Should this loan be approved or denied?”: A large dataset
with class assignment guidelines. Journal of Statistics Education, 26(1):55-66, 2018.
MOSEK ApS. MOSEK Optimizer API for Python 9.2.10, 2019. URL https://docs.mosek.
com/9.2/pythonapi/index.html.
Ramaravind K Mothilal, Amit Sharma, and Chenhao Tan. Explaining machine learning classifiers
through diverse counterfactual explanations. In Proceedings of the 2020 Conference on Fairness,
Accountability, and Transparency, pp. 607-617, 2020.
10
Under review as a conference paper at ICLR 2022
K.P. Murphy. Machine Learning: A Probabilistic Perspective. MIT Press, 2012.
Hongseok Namkoong and John C Duchi. Variance-based regularization with convex objectives. In
Advances in Neural Information Processing Systems 30,pp. 2971-2980, 2017.
Viet Anh Nguyen. Adversarial Analytics. PhD thesis, Ecole PolytechniqUe Federale de Lausanne,
2019.
Leandro Pardo. Statistical Inference Based on Divergence Measures. CRC Press, 2018.
Hamed Rahimian and Sanjay Mehrotra. Distributionally robust optimization: A review. arXiv
preprint arXiv:1908.05659, 2019.
Kaivalya Rawal and Himabindu Lakkaraju. Interpretable and interactive summaries of actionable
recourses. arXiv e-prints, pp. arXiv-2009, 2020.
Kaivalya Rawal, Ece Kamar, and Himabindu Lakkaraju. Algorithmic recourse in the wild: Under-
standing the impact of data and model shifts. arXiv preprint arXiv:2012.11788, 2021.
Marco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin. ”Why should I trust you?”: Explaining the
predictions of any classifier. In Proceedings of the 22nd ACM SIGKDD International Conference
on Knowledge Discovery and Data Mining, pp. 1135-1144, 2016.
Cynthia Rudin. Stop explaining black box machine learning models for high stakes decisions and
use interpretable models instead, 2019.
Chris Russell. Efficient search for diverse coherent explanations. In Proceedings of the Conference
on Fairness, Accountability, and Transparency, FAT* ’19, pp. 20-28. Association for Computing
Machinery, 2019.
Alexander Shapiro, Darinka Dentcheva, and Andrzej Ruszczynski. Lectures on Stochastic Program-
ming: Modeling and Theory. SIAM, 2009.
Ilia Stepin, Jose M. Alonso, Alejandro Catala, and Martin Pereira-Farifia. A survey of contrastive
and counterfactual explanation generation methods for explainable artificial intelligence. IEEE
Access, 9:11974-12001, 2021.
Bahar Taskesen, Man-Chung Yue, Jose Blanchet, Daniel Kuhn, and Viet Anh Nguyen. Sequential
domain adaptation by synthesizing distributionally robust experts. In Proceedings of the 38th
International Conference on Machine Learning, 2021.
Sohini Upadhyay, Shalmali Joshi, and Himabindu Lakkaraju. Towards robust and reliable algorith-
mic recourse. In Advances in Neural Information Processing Systems 35, 2021.
Berk Ustun, Alexander Spangher, and Yang Liu. Actionable recourse in linear classification. In
Proceedings of the Conference on Fairness, Accountability, and Transparency, FAT* ’19, pp.
10-19, 2019.
Suresh Venkatasubramanian and Mark Alfano. The philosophical basis of algorithmic recourse.
In Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency, FAT*
’20, pp. 284-293, New York, NY, USA, 2020. Association for Computing Machinery. ISBN
9781450369367. doi: 10.1145/3351095.3372876. URL https://doi.org/10.1145/
3351095.3372876.
Sandra Wachter, Brent Mittelstadt, and Chris Russell. Counterfactual explanations without opening
the black box: Automated decisions and the GDPR. Harvard Journal of Law & Technology, 2018.
11
Under review as a conference paper at ICLR 2022
A Additional Experiment Results
Synthetic data. For synthetic data, we perform experiments on datasets capturing 3 types of data
distribution shift: mean shift, covariance shift, mean and covariance shift (both shift)
We define the adaptive mean and covariance shift magnitude as α = μ adapt X iter, β = ∑adaτ>t * iter
with μadapt, ∑adapt are the factor of data shifts, iter is the index of iterative loop of synthesizing
process.
To visualize feasible set as Figure 2, we generate synthetic data with the following parameters:
μo = [-3; -3], μι = [3; 3], and ∑o = ∑ι = I. Then, We split data to training set and test set
(80% for training and 20% for testing), train the original classifier on training set and then choose
one instance on test set that is classified as negative class to visualize the feasible set. For data
distribution shifts, we generate mean shifts and covariance shifts 50 times each type with adaptive
mean and covariance shift magnitude, with the parameters μadapt = Σadapt = 0.1. Then we train
^
and get the parameters θk and Σk same as above.
Table 3: Parameters for the feasible set visualiza- Table 4: Parameters for the impact of data dis-
tion experiment in Figure 2	tribution shifts experiment in Figure 3
Parameters	Values	Parameters	Values
K	2	K	3
δadd	2	δadd	0.2
pb	[0.5, 0.5]	pb	[0.3, 0.4, 0.3]
ρ	[1, 1]	ρ	[0, 0, 0]
λ	0.7	λ	0.7
ζ	1	ζ	1
To visualize the data and decision boundaries of linear classifiers, we generate synthetic data with
the same parameters as above. Then we train 4 classifiers on original data and synthetic capturing
3 types of distribution shifts and visualize the decision boundaries as Figure 4. Then we synthesize
shifted data 100 times, 33 mean shifts, 33 covariance shifts and 34 mean and covariance shifts (both
shifts) and visualize 100 model’s parameters in 2D as Figure 5.
(a) Original data
(b) Mean shift (c) Covariance shift (d) Both shift
Figure 4: Synthetic data shifts and the corresponding model parameter shifts (decision boundaries).
12
Under review as a conference paper at ICLR 2022
2.75
2.50-
2.25
1.50-
1.25-
2.00-
φ
1.75-
★ Original
• Mean shift
• Cov shift
• Both shift
10° 0.6	0.8	1.0	1.2	1.4	1.6	1.8	2.0
θ0
Figure 5: Parameter θ of the classifier with different types of data distribution shifts
To evaluate how magnitude of upper bound cost affects the validity of our models, we use different
values of upper bound cost. We define δ = δmin + δadd with δmin is defined in (7). We use the same
parameters as above for generating synthetic data. For each value of δadd , we evaluate the validity
by using 100 classifiers trained on 100 different data distribution shifts with 3 different shift types.
A~p=e> S
1.0
0.8
0.6
0.4
0.2
0.0
0.00	0.05	0.10	0.15	0.20
6 add
Figure 6: Impact of choosing δadd to the validity of DiRRAc
Additional results for the Impact of magnitude of distribution shifts to empirical validity.
Figure 7: Impact of magnitude of distribution shifts to empirical validity of Gaussian DiRRAc
13
Under review as a conference paper at ICLR 2022
To evaluate the trade-offs between the l1 cost and the validity of DiRRAc, we benchmark these two
criteria by running DiRRAc with different values of δ. We define δ = δmin + δadd as before. For
each value of δ, we evaluate the l1 cost and validity by using 100 classifiers trained on 100 different
data distribution shifts with 3 different shift types.
We also evaluate the trade-offs between l1 cost and validity of DiRRAc using 20 instances. In the
comparison with ROAR, we evaluate l1 cost and validity of DiRRAc and ROAR using 10 instances.
We use a wide range of parameters for ROAR and compute the l1 cost and validity of recourses. We
report the results of 2 experiments in Figure 8 and Figure 9.
1.0
A~p=e> S
0.8
0.6
0.4
0.2
0.0
5.800 5.825 5.850 5.875 5.900 5.925 5.950
I1 cost
Figure 8: Cost of robustness of DiRRAc
A~p=e> zs
1.0
0.9
0.8
0.7
0.6
0.5
3.4	3.6	3.8	4.0	4.2	4.4
I1 cost
Figure 9: Comparison of M2 validity as a function of the l1 distance between input instance and the
recourse for our DiRRAc method and ROAR
Real-world data. For each of three real-world datasets, we choose a number of features to bench-
mark with other baselines:
14
Under review as a conference paper at ICLR 2022
•	For German credit dataset from UCI repository, we choose 5 features: Status, Duration,
Credit amount, Personal status, Age. We found in the description of two datasets that
feature Status in the data correction shift dataset corrects the coding errors in the original
dataset (Dua & Graff, 2017).
•	For SBA dataset, following the work from Li et al. (2018) and Upadhyay et al. (2021)
we choose the following features: Selected, Term, NoEmp, CreateJob, RetainedJob, Ur-
banRural, ChgOffPrinGr, GrAppv, SBA_Appv, New, RealEstate, Portion, Recession. We
use the instances during 1989-2006 as the original data, and the remaining instances as
temporal shift data.
•	For Student Performance dataset, motivated by Cortez & Silva (2008), we choose feature
G3 - final grade for deciding the label pass or fail for each student. The student who has
G3 < 12 is labeled 0 (failed) and 1 (passed) otherwise. For input features, we choose
9 features: Age, Study time, Famsup, Higher, Internet, Health, Absences, G1, G2. We
separate the dataset into the original and the geospatial shift data by 2 different schools.
Table 5: Accuracy of the underlying classifiers.
Dataset	Methods	Accuracy
German Credit	LR	0.72 ± 0.00
	MLPs	0.76 ± 0.01
Shifted German Credit	LR	0.7 ± 0.00
	MLPs	0.72 ± 0.01
SBA	LR	0.79 ± 0.01
	MLPs	0.93 ± 0.02
Shifted SBA	LR	0.77 ± 0.01
	MLPs	0.89 ± 0.01
Student Performance	LR	0.84 ± 0.01
	MLPs	0.91 ± 0.01
Shifted Student Performance	LR	0.91 ± 0.00
	MLPs	0.99 ± 0.01
Experiments with Euclidean norm. We accumulate here the numerical results with c(x, x0) =
kx - x0k2. Table 6 reports the M2 validity, along with the l1 and l2 distance between the input
instance and its corresponding recourse. Results are mean ± standard deviation, calculated from
100 independent replications. The settings of this experiments are the same as the experiments in
Section 5
Table 6: Benchmark of validity, l1 and l2 using Euclidean cost on different real-world datasets.
Dataset	Methods	M2 validity	l1 cost	l2 cost
German Credit	AR	0.78 ± 0.00	1.26± 0.68	0.94 ± 0.41
	MACE	0.97 ± 0.00	2.10 ± 0.86	1.20 ± 0.47
	DiRRAc	0.99 ± 0.02	1.72 ± 0.49	0.77 ± 0.19
	Gaussian DiRRAc	1.00± 0.00	1.78 ± 0.49	0.77± 0.19
SBA	AR	0.41 ± 0.13	1.80± 1.14	1.16± 0.60
	MACE	0.98 ± 0.14	3.99 ± 0.22	1.92 ± 0.07
	DiRRAc	0.98± 0.02	2.43 ± 1.30	1.17 ± 0.53
	Gaussian DiRRAc	0.92 ± 0.02	2.43 ± 1.35	1.18 ± 0.54
Student Performance	AR	0.35 ± 0.12	1.18 ± 0.99	0.82 ± 0.60
	MACE	0.64 ± 0.09	0.81± 0.40	0.51± 0.23
	DiRRAc	1.00± 0.00	1.30 ± 0.38	0.69 ± 0.16
	Gaussian DiRRAc	1.00 ± 0.00	1.32 ± 0.40	0.71 ± 0.16
15
Under review as a conference paper at ICLR 2022
Table 7: Parameters for the experiments with real-world data in Table 6
Parameters Values
K	1
δadd	0.5
pb	[1]
ρ	[0]
λ	0.7
ζ	1
Experiments with prior on Σ.
In this experiments we assume that we does not have access to the training data. We set the θ1 = θ0,
θo is parameters of the original classifier. Then We choose ∑ι = T * I. We generate recourse for
each input instance and compute M1 using the original classifier and M2 validity using the shifted
classifiers. In this experiments We choose τ = 0.1.
The results in Table 8 shoW that our methods remain the same performance While keeping the l1 and
l2 cost loWer than ROAR in three datasets except the l2 cost in SBA dataset.
Table 8: Benchmark ofM1 validity, M2 validity, l1 and l2 using Σ1 = 0.1 *I on different real-World
datasets.
Dataset	Methods	Mi validity	M2 validity	l1 cost	l2 cost
German Credit	ROAR	1.00 ± 0.00	1.00 ± 0.00	2.60 ± 0.40	1.08 ± 0.16
	DiRRAc	1.00 ± 0.00	0.97 ± 0.05	1.97 ± 0.34	1.06 ± 0.13
	Gaussian DiRRAc	1.00 ± 0.00	0.98 ± 0.04	1.97 ± 0.34	0.97± 0.14
SBA	ROAR	1.00 ± 1.00	1.00 ± 0.00	2.25 ± 0.55	0.98 ± 0.23
	DiRRAc	1.00 ± 0.00	1.00 ± 0.00	2.13 ± 0.41	1.44 ± 0.26
	Gaussian DiRRAc	1.00 ± 0.00	1.00 ± 0.00	2.11 ± 0.45	1.27 ± 0.41
Student Performance	ROAR	1.00 ± 0.01	0.98 ± 0.02	1.70 ± 0.27	0.81 ± 0.13
	DiRRAc	1.00± 0.00	1.00 ± 0.00	1.73 ± 0.18	1.43 ± 0.16
	Gaussian DiRRAc	1.00 ± 0.00	1.00 ± 0.00	1.21 ± 0.33	0.64 ± 0.16
B Proofs
B.1 Proofs of Section 3
To prove Proposition 3.4, We are using the notion of Value-at-Risk Which is formally defined as
folloWs.
Definition B.1 (Value-at-Risk). For any fixed distribution Qk of θ, the Value-at-Ri.sk at the risk
tolerance level β ∈ (0,1) ofthe loss θ>x is defined as
Qk- VaRe(θi>x)，inf{τ ∈ R : Qk(^>x ≤ T) ≥ 1 — β}
We are noW ready to provide the proof of Proposition 3.4.
Proof of Proposition 3.4. Using the definition of the Value-at-Risk in Definition B.1, We have
sup	Qk(θ>x ≤ 0) = inf < β : β ∈ [0,1],
Qk∈Bk(bPk)
= inf β : β ∈ [0, 1],
sup
Qk ∈Bk (bPk)
sup
Qk ∈Bk (bPk)
Qk(θ>x ≤ 0) ≤ β}
Qk - VaRe (—θ>X) ≤ 0}
16
Under review as a conference paper at ICLR 2022
By Nguyen (2019, Lemma 3.31), we can reformulate the worst-case value-at-risk as
sup Qk - VaRe (—θ>x)
Qk ∈Bk (bPk )
—θ>x +
It is now easy to observe that in the first case when —bb>χ + Pkkχ∣∣2 ≥ 0, then We should have
suPQk∈Bk(bk) Qk(θ~τx ≤ O) = L
We now consider the second case when -θ>χ + √kxk2 < 0. It is easy to see, by the monotocity
of the worst-case value-at-risk with respect to β, that the minimal value β? should satisfies
—θ>x +
0.
Using the transformation t J √β?, we have
—θ>χt + pl —12 γχ>∑ kχ + Pk ∣∣χ∣∣2 = 0.
By rearranging terms and then squaring up both sides, we have the equivalent quadratic equation
(A2k+Bk2)t2+2AkCkt+Ck2—Bk2=0
with Ak，-θ>x ≤ O, Bk，Jx>∑kx ≥ 0, and Ck , ρk kxk2 ≥ 0 as defined in the statement of
the proposition. Note, moreover, that we also have A2k ≥ Ck2 . This leads to the solution
t _ —Ak Ck + Bk VZAk + B2 - Ck'o
=	Ak+Bk	≥
Thus, we find
fk (x) = (-AkCk + A 节 2+ B^C )2
This completes the proof.
□
We now provide the proof of Theorem 3.2.
Proof of Theorem 3.2. We first consider the objective function f of (2), which can be re-expressed
as
f(x) = sup P(Cd(X) =0)= sup X PkQk (θ>x ≤ 0)
_ ,ʌ. ,ʌ . < 一
P∈B(Pb)	Qk∈Bk(bPk) ∀k k∈[K]
=X Pk X sup	Qk (θ>x ≤ 0)
k∈[K]	Qk ∈Bk (Pbk )
=	Pbk × fk (x),
k∈[K]
where the equality in the second line follows from the non-negativity ofPbk, and the last equality fol-
lows from the definition of fk (x) in (5). Applying Proposition 3.4, we obtain the objective function
of problem (4).
Consider now the last constraint of (2). Using the result of Proposition 3.4, this constraint is equiv-
alent to
—p>x + Pkkxk2 < 0	∀k ∈ [K].
This leads to the feasible set X as is defined in (3). This completes the proof.
□
17
Under review as a conference paper at ICLR 2022
B.2 Proofs of Section 4
To prove Theorem 4.1, we first define the following worst-case Gaussian component probability
function
fN(x)，	sup	Qk(Cd(X) = 0)= sup Qk(”x ≤ 0)	∀k ∈ [K].	(11)
Qk∈BkN (bPk)	Qk ∈BkN (bPk)
The next proposition provides the reformulation of fkN.
Proposition B.2 (Worst-case probability - Gaussian). For any x ∈ Rd, any k ∈ [K] and any
(θbk, Σbk, ρk) ∈ Rd × Sd+ × R+, define the following constants Ak , -θbk>x, Bk
Ck , ρk kxk2. The following holds:
x>Σbkx, and
(i)	We have fN(x) < 2 ifand only if Ak + Ck < 0.
(ii)	If x satisfies fN (x) < 2, then
fkN (x)
1 - φ(_____Ak - C2
JAkBk + Ck PAk + Bik - Ck
Proof of Proposition B.2. We first prove Assertion (i). Pick any Qk ∈ BkN(Pbk), then Qk is a Gaus-
Sian distribution Qk 〜 N(θk, ∑k), and thus
Qk(θ>χ ≤ 0) = φ(√-θ>k=).
x>Σx
Guaranteeing fN(x) < 2 is equivalent to guaranteeing
sup	- θk> x ≤ 0.
G((θk,Σk),(θbk ,Σb k))≤ρk
Note that we also have
sup	- θk>x = sup - θk>x = -θbk>x + ρk kxk2
G((θk,Σk),(θbk ,Σbk))≤ρk	θk:kθk -θbk k2≤ρk
by the properties of the dual norm. This leads to the equivalent condition that Ak + Ck < 0.
We now prove Assertion (ii). Using the definition of the Value-at-Risk in Definition B.1, we have
sup	Qk(”x ≤ 0)=inf(β : β ∈ [0,1),
Qk∈BkN(bPk)	2
=inf {β ： β ∈ [0, 2),
sup
Qk∈BkN(bPk)
sup
Qk∈BkN(bPk)
Qk(”x ≤ 0) ≤ β}
Qk- VaRe(-B>χ) ≤ 0}
Using the result from Nguyen (2019, Lemma 3.31), we have
sup	Qk - VaRe (—”x) = —bb> x + tλ∕x>∑ kx + ρp1 +12 ∣∣x∣∣2 = Ak + Bkt + Ck √1 +1,
Qk ∈Bk (Pbk )
with t = Φ-1 (1 — β). Taking the infimum over β is then equivalent to finding the root of the
equation
Ak + tBk + Ck p1 +12 = 0.
Using a transformation τ = 1/t, the above equation becomes
AkT + Bk + Ck p1 + T2 = 0
with solution
-Ak Bk + Ck ʌ/Ak + B2 - C2
AFC
> 0.
Notice that Ak +Ck < 0, and we also have A2k > Ck2, thus T is well-defined. The result now follows
by noticing that fN(x) = 1 一 Φ(t) = 1 一 Φ(1∕τ).	□
18
Under review as a conference paper at ICLR 2022
We are now ready to prove Theorem 4.1.
Proof of Theorem 4.1. Problem (8) is equivalent to
min Pk∈[K] pbk X fkN (x)
s. t.	c(x, x0) ≤ δ
fN(x) <2	∀k ∈ [K].
Applying Proposition B.2, We obtain the necessary result.
□
C Extensions of the DiRRAc Framework
Throughout this section, we explore two extensions of our DiRRAc framework. In Section C.1,
we study an additional layer of robustification with respect to the mixture weights pb. Next, in
Section C.2, we consider an alternative formulation of the objective function to minimize the worst-
case component probability.
C.1 Robustification against Mixture Weight Uncertainty
The DiRRAc problem considered in Section 3 only robustifies the component distributions Pbk . We
noW discuss a plausible approach to robustify against the misspecification of the mixture Weights
pb. Because the mixture Weights should form a probability vector, it is convenient to model the
perturbation in the mixture Weights using the φ-divergence.
Definition C.1 (φ-divergence). Let φ : R → R be a convex function on the domain R+, φ(1) = 0,
0 X φ(a∕0) = a X limt↑∞ φ(t)∕t for a > 0, and 0 X φ(0∕0) = 0. The φ-divergence Dφ between
two probability vectors p, pb ∈ R+K amounts to Dφ(p k pb) , k∈[K] pbk × φ(pk /pbk).
The family of φ-divergences contains many Well-knoWn statistical divergences such as the Kullback-
Leibler divergence, the Hellinger distance, etc. Further discussion on this family can be found
in Pardo (2018). Distributionally robust optimization models With φ-divergence ambiguity set Were
originally studied in decision-making problems (Ben-Tal et al., 2013; Bayraksan & Love, 2015) and
have recently gained attention thanks to their successes in machine learning tasks (Namkoong &
Duchi, 2017; Hashimoto et al., 2018; Duchi et al., 2021).
Let ε ≥ 0 be a parameter indicating the uncertainty level of the mixture Weights. The uncertainty
set for the mixture Weights is formally defined as
∆ , {p ∈ [0,1]K : 1>P = 1, Dφ(p k b) ≤ ε},
Which contains all K-dimensional probability vectors Which are of φ-divergence at most ε from the
nominal Weights pb. The ambiguity set of the mixture distributions that hedge against the Weight
misspecification is
U(P)，{Q ：	∃p	∈	∆,	∃Qk	∈ Bk (Pk) Vk ∈	[K]	such that Q 〜(Qk,pk)	},
Where the component sets Bk (Pbk) are defined as in Section 3. The DiRRAc problem With respect to
the ambiguity set U(P) becomes
min sup P(Cd(X) = 0)
P∈U (Pb)
s. t. c(x, x0) ≤ δ
sup	Qk (Cθd(x) = 0) < 1	∀k ∈ [K].
rʌ、
(12)
Qk ∈Bk (Pbk )
It is important to note at this point that the feasible set of (12) coincides with the feasible set of (2).
Thus, to resolve problem (12), it suffices to analyze the objective function of (12). Given the function
φ, We define its conjugate function φ* : R → R ∪{∞} by
φ*(s) = sup{ts — φ(t)}.
t≥0
The next theorem asserts that the worst-case probability under U(P) can be computed by solving a
convex program.
19
Under review as a conference paper at ICLR 2022
Theorem C.2 (Objective value). The feasible set of problem (12) coincides with X. Further, for
every x ∈ X, the objective value of (12) equals to the optimal value of a convex optimization
problem
sup P(CA(X) = 0) = min η + ελ + λ X Pbkφ* ( fk(x)——-
p∈u (b)	λ∈R+,η∈R	k∈[K]	' λ
where fk (x) are computed using Proposition 3.4.
Proof of Theorem C.2. From the definition of the set U (P), we can rewrite F using a two-layer
decomposition
F(x) = sup P(Cρ(x) = 0) = sup sup	^X PkQk(θ>x ≤ 0)
P∈U(bP)	p∈∆ Qk∈Bk(bPk) ∀k k∈[K]
=sup EPk X	SUP- Qk(θ>x ≤ 0)
p∈∆ k∈[K]	Qk ∈Bk (bPk )
= sup Pk × fk(x),
p∈∆ k∈[K]
where the equality in the second line follows from the non-negativity of Pk, and the last equal-
ity follows from the definition of fk(x) in (5). By applying the result from Ben-Tal et al. (2013,
Corollary 4.2), we have
J min - +ελ + λ X ρkφ (fk (x[ - η)
F(x) =	k∈[K]	λ
[s.t. λ ∈ R+, - ∈ R.
The proof is complete.	口
From the result of Theorem C.2, we can derive the gradient of the objective function of (12) using
Danskin’s theorem (Shapiro et al., 2009, Theorem 7.21), or simply using auto-differentiation. Fur-
thermore, φ* is convex, and thus solving the minimization problem in Theorem C.2 can be done
efficiently using convex optimization algorithms.
C.2 Minimizing the Worst-Case Component Probability
Instead of minimizing the (total) probability of unfavorable outcome, we can consider an alternative
formulation where the recourse action minimizes the worst-case conditional probability of unfavor-
able outcome over all K components. Mathematically, if we opt for the component ambiguity sets
Bk (Pk ) constructed in Section 3, then we can solve
min max sup	Qk (CθA(x) = 0)
k∈[K] Qk∈Bk(bPk)
s. t. c(x, x0) ≤ δ	(13a)
sup	Qk (CθA(x) = 0) < 1	∀k ∈ [K].
Qk∈Bk(Pbk)
Interestingly, problem (13a) does not involve the mixture weighs Pb. As a consequence, a trivial ad-
vantage of this model is that it hedges automatically against the misspecification of Pb. To complete,
we provide its equivalent finite-dimensional form.
Corollary C.3 (Component Probability DiRRAc). Problem (13a) is equivalent to
.	Pk b>xkxk2 + Vx>ς k x ∖∕(θkxy2 + x>ς k x - Pk kxk2	(13b)
min max	.	()
x∈X k∈[K]	(θbk> x)2 + x> Σb k x
20
Under review as a conference paper at ICLR 2022
D Extensions of the Gaus s ian DiRRAc Framework
In this section, we leverage the results in Section C to extend the Gaussian DiRRAc framework to
(i) handle the uncertainty of the mixture weight and (ii) minimize the worst-case modal probability.
Remind that each individual mixture ambiguity set BkN (Pbk) is of the form
BN(bk) = {Qk : Qk 〜N(θk, Σk), G((θk, Σk), (bk, ∑k)) ≤ Pk O ,
which is a ball in the space of Gaussian distributions.
D. 1 Handling Mixture Weight Uncertainty - Gaussian DiRRAc
Following the notations in Section C.1, we define the set of possible mixture weights as
∆= {p ∈ [0,1]K : l>p = 1, Dφ(p k p) ≤ ε}
and the ambiguity set with Gaussian information is defined as
UN(P) = {q ： ∃P ∈ ∆, ∃Qk ∈ BN(bk) ∀k ∈ [K] such that Q 〜(Qk,pk底的}.
The distributionally robust problem with respect to the ambiguity set U(P) is
inf sup P(Cd(X) = 0)
P∈UN (bP)
s. t. c(x, x0) ≤ δ	(14)
SUp	Qk (CQ)= 0) < 1	∀k ∈ [K].
Qk∈BkN(bPk)
Following the results in Section 4, the feasible set of (14) coincides with the set X. It suffices now
to provide the reformulation for the objective function of (14).
Corollary D.1. For any x ∈ X, we have
sup P(Cθd(x) = 0) =
P∈UN (Pb)
inf
s. t.
η + ελ + λ X Pkφ*(fN「)
k∈[K]
λ∈R+, η∈R,
where the values fkN (x) are obtained in Proposition B.2.
Corollary D.2 follows from Theorem D.2 by replacing the quantities fk (x) by fkN (x) to take into
account the Gaussian parametric information. The proof of Corollary D.2 is omitted.
D.2 Minimizing Worst-Case Component Probability
We now consider the Gaussian DiRRAc that minimizes the worst-case modal probability of infeasi-
bility. More concretely, we consider the recourse action obtained by solving
inf max sup	Qk (Cθd(x) = 0)
k∈[K] Qk ∈BkN (Pbk)
s. t. c(x, x0) ≤ δ	(15a)
SUP	Qk(Cd(X) = 0) < 1	∀k ∈ [K].
Qk∈BkN(bPk)
The next corollary provides the equivalent form of the above optimization problem.
Corollary D.2. Problem (15a) is equivalent to
___________________(b>x)2 - Pkkxk2____________________
b>xy χ>∑kx + Pk∣∣χ∣∣2 J(b>x)2 + x>∑kX - Pk 13122
(15b)
inf max 1 - Φ
x∈X k∈[K] I
21
Under review as a conference paper at ICLR 2022
Algorithm 1 Projected gradient descent algorithm with backtracking line-search
Input: Input instance X0, feasible set Xε and objective function f
Line search parameters: λ ∈ (0, 1), ζ > 0 (Default values: λ = 0.7, ζ = 1)
Initialization: Set x0 - Proj χε (xo)
for t = 0, . . . , T - 1 do
Find the smallest integer i ≥ 0 such that
f(Projχε (xt -λiZ Vf(Xt))) ≤ f (xt)-去 kxt - ProjXε(xt -我,Vf(Xt))∣∣2∙
Set xt+1 = Pro jX (xt - λiζVf(xt)).
end for
Output: xT
E Projected Gradient Descent Algorithm
The pseudocode of the algorithm is presented in Algorithm 1. The convergence guarantee for Algo-
rithm 1 follows from Beck (2017, Theorem 10.15), and is distilled in the next theorem.
Theorem E.1 (Convergence guarantee). Let {xt}t=0,1,...,T be the sequence generated by Algo-
rithm 1. Then, all limit points of the sequence {xt}t=0,1,...,T are stationary points of problem (4)
with the modified feasible set Xε. Furthermore, there exists some constant C > 0 such that for any
T ≥ 1, we have
min
t=0,1,...,T
Ilxt - PrθjXε (Xt - Z Vf(Xt)) ∣∣2
ζ
C
≤√T∙
22