Under review as a conference paper at ICLR 2022
Subpixel object segmentation using wavelets
AND MULTI RESOLUTION ANALYSIS
Anonymous authors
Paper under double-blind review
Ab stract
We propose a novel deep learning framework for fast prediction of boundaries
of two-dimensional simply connected domains using wavelets and Multi Resolu-
tion Analysis (MRA). The boundaries are modelled as (piecewise) smooth closed
curves using wavelets and the so-called Pyramid Algorithm. Our network ar-
chitecture is a hybrid analog of the U-Net, where the down-sampling path is a
two-dimensional encoder with learnable filters, and the upsampling path is a one-
dimensional decoder, which builds curves up from low to high resolution levels.
Any wavelet basis induced by a MRA can be used. This flexibility allows for
incorporation of priors on the smoothness of curves. The effectiveness of the
proposed method is demonstrated by delineating boundaries of simply connected
domains (organs) in medical images using Debauches wavelets and comparing
performance with a U-Net baseline. Our model demonstrates up to 5x faster in-
ference speed compared to the U-Net, while maintaining similar performance in
terms of Dice score and Hausdorff distance.
1	Introduction
Semantic image segmentation is a core component of many medical imaging related tasks. Both as
part of a pipeline to find a region of interest, or a task by itself, e.g., for measuring tumor volume.
Nowadays, almost all segmentation algorithms in medical imaging are replaced by U-Net-like ar-
chitectures Ronneberger et al. (2015) combining an encoder and decoder. Typically, the decoder is
an upsampling path, and additional skip connections between the encoding and decoding part are
added to recover the image’s spatial information. While many variants or more exotics methods,
such as multi-scale and pyramid based approaches, recurrent networks or generative techniques, can
be designed, all of these still yield per-pixel classifications. In these settings an image is interpreted
as a discrete collection of ordered pixels (or voxels in the three-dimensional case), where the task
is to assign an appropriate class to each pixel using a probabilistic model. Typically, the pixels are
assumed to be independent so that the joint-likelihood is tractable.
In practice, e.g., in medical imaging, the boundary of a region is annotated and not the region it-
self. Hence the raw ground-truth data is a discretization of a closed curve. The main motivation
of our paper is to construct a deep learning model which (i) may directly use such raw ground-
truth data if available (ii) is guaranteed to predict smooth planar curves (iii) improves inference
speed by predicting 1d objects (curves) instead of 2d objects. We argue that in traditional pipelines,
where pixel-based predictions are constructed, smooth boundaries are not faithfully represented. In
particular, no prior information about the geometry of planar curves is incorporated. In this paper,
we present a hybrid analog of the U-Net, where the down-sampling path is a two-dimensional en-
coder with learnable filters, and the upsampling path is an one-dimensional decoder, which predicts
(smooth) representations of curves.
A fundamental component in the setup of our framework is the decision on how to represent (closed)
curves. While the Fourier basis is a natural candidate at first glance, its global nature may hamper
accurate predictions of curves which exhibit highly localized behavior, requiring accurate estimates
of small noisy high-frequency modes. For this reason, we have chosen to represent contours using
wavelets and Multi Resolution Analysis (MRA) instead. The main idea is to choose a single map 夕,
the so-called scaling function or father wavelet, and to construct subspaces of functions associated
to prescribed resolution levels by taking the span of appropriate dilations and translations of 夕.This
1
Under review as a conference paper at ICLR 2022
setup provides an efficient way to decompose and reconstruct contours, from low to high resolution
level, using the classical Pyramid Algorithm Mallat (2008) as a decoder. The filters in the decoder
are not learned but uniquely determined by the chosen wavelet basis. Any wavelet basis induced by
a MRA can be used. This flexibility allows for incorporation of priors on the smoothness of curves.
Related work Previous work by Chen et al. (2019); Marcos et al. (2018); Hatamizadeh et al.
(2020) also proposed models to predict contours by combining Active Contour Models (ACM) with
a CNN into an end-to-end model. In these papers the representation of curves is ultimately still based
on pixel-based computations. For instance, in Hatamizadeh et al. (2020) curves are modelled as level
sets of distance maps defined on a discretization of the domain of the image. In Chen et al. (2019) a
similar approach is followed, but a smoothed approximation of an indicator function is used instead
of a distance map. The work in Marcos et al. (2018) is perhaps most closely related to ours; they
directly construct polygonal approximations of curves and represent them using (pixel) coordinates
of the nodes. The objectives minimized in the cited papers are based on a careful consideration of
mean pixel intensities and geometric properties such as area and arc length. These properties are
implicitly encoded in an objective function (energy-functional) defined on a space of distance maps
Hatamizadeh et al. (2020), suitable approximations of indicator functions Chen et al. (2019), or
family of polygons Marcos et al. (2018). However, in contrast to our approach, the above methods
all provide pixel-based output. To the best of our knowledge, our work is the first to use MRA and
wavelet analysis to construct pixel-independent representations of (closed) curves.
This paper is organized as follows. In Section 2 we review the mathematical background needed to
construct our model. We explain how contours can be decomposed and reconstructed on different
resolution levels. The reconstruction algorithm, the Pyramid Algorithm, forms a core component
of our network architecture. In Section 3 we set up the model architecture and loss. Subsequently
the datasets, training method and performance measures are described in Section 4. We end the
paper with results and a discussion in Section 5. Further mathematical details are provided in the
appendix.
2	Background and mathematical setup
In this section we describe our mathematical setup and review the theory needed to construct our
model. We consider two dimensional gray-valued images x ∈ X := [0, 1]n×n, e.g., slices of MRI
scans of size n × n, where n ∈ N. We assume that each image contains a (uniquely identifiable)
simply connected region R(x) ⊂ R2, e.g., an organ, with boundary ∂R(x). It is assumed that
∂R(x) can be parameterized by a simple closed continuous curve γ(x). We will develop a deep
learning framework for computing such parameterizations γ(x) using Multi Resolution Analysis
(MRA). Since wavelets play a seminal role in our set up, we first review the necessary theory in
Sections 2.1 and 2.2 as a subject in its own right in the context of general scalar-valued signals γ. In
the remainder of the paper, we return to the context in which γ = γ(x) is interpreted as a periodic
(planar) curve parameterizing the boundary of a region.
2.1	Multi resolution analysis
In this section we briefly review wavelet theory using the framework of a multi resolution analysis
(MRA). We closely follow the exposition in Pereyra & Ward (2012) and Montefusco & Puccio
(2014). Throughout this section we denote the space of square integrable functions on R, equipped
with standard inner product, by L2 (R).
The uncertainty principle in Fourier analysis dictates that a signal γ ∈ L2 (R) cannot be simulta-
neously localized in the time and frequency domain, see Pereyra & Ward (2012). Multi resolution
analysis aims to address this shortcoming by decomposing a signal on different discrete resolution
levels. The idea is to construct subspaces Vj ⊂ L2(R), associated to various resolution levels j ∈ Z,
spanned by integer shifts of a localized mapping 夕j. The level of localization associated to Vj- is
determined by taking an appropriate dilation of a prescribed map 夕；the so-called scaling function.
In the MRA framework the dilation factors are chosen to be powers of two. Formally, we require
that (φjk)k∈z is an orthonormal basis for Vj, where φjk(t) := 22φ(2jt - k), see Figures 1a and
2
Under review as a conference paper at ICLR 2022
Figure 1: Example of the Haar MRA: (a) Dilated translation of the Haar scaling map 夕 = I[0,1).
(b) The approximation subspace at level j consists of all step-functions with step-size 2-j . (c)
Dilated translation of the mother wavelet ψ = 19ι)- 1[ 1,1). (d) Example of a function in the
detail subspace at level j .
1b. Altogether, this yields an increasing sequence of closed subspaces Vj ⊂ Vj+1 ⊂ L2(R) dense
in L2(R), where Vj+1 is the next level up in resolution after Vj.
The representation of γ at resolution level j, denoted by γj := Pjγ, is its orthogonal projection
onto Vj . Here Pj denotes the orthogonal projection onto Vj . The coefficients of γj with respect to
the basis for Vj, denoted by aj(γ) = (ajk (γ))k∈Z, are called the approximation coefficients. The
associated subspaces Vj are referred to as the approximation subspaces (see Figure 1b). To study
the information that is lost when a signal in Vj +1 is projected onto Vj , we consider the operator
Qj := Pj+1 - Pj. The range of Qj, denoted by Wj, is referred to as the detail subspace at level j;
it is the orthogonal complement of Vj in Vj+1 . The detail subspaces (Wj )j∈Z are mutually disjoint
and orthogonal by construction. A fundamental result, known as Mallat’s Theorem, states that the
subspaces Wj can too be spanned by dilating and shifting a single map. More precisely, there
exists a map ψ ∈ W0, the so-called mother wavelet, such that (ψjk)k∈Z is an orthonormal basis
for Wj, see Pereyra & Ward (2012). The coefficients of Qjγ with respect to this basis, denoted by
dj (γ) := (djk (γ))k∈Z, are referred to as the detail coefficients ofγ at resolution level j. The detail
coefficients store the information needed to go back one level up in resolution, since Pj+1 = Pj+Qj
by construction. We often write aj (γ) = aj and dj (γ) = dj for brevity. In practice, we only
approximate a finite number of approximation and detail coefficients, see Section 2.3.
2.2	The Discrete Wavelet Transform
In this section we describe how to compute the approximation and detail coefficients given a pre-
scribed scaling function 夕. Many fundamental aspects of MRA,s, both theoretical and compu-
tational, can be traced back to the following key observation. Since V0 ⊂ V1, there must exist
coeficients h = (hk)k∈z such that 夕 = Pk∈z hk夕ik. This equation is referred to as the scaling
equation; one of the fundamental properties ofa scaling function. The sequence h, the so-called low-
pass filter, completely characterizes the scaling function. Similarly, since ψ ∈ W0 ⊂ V1, there exist
coefficients g = (gk)k∈z, the so-called high-pass filter associated to h, such that ψ = Pk∈z gkψik.
For Mallat,s mother wavelet, We have gk = (-1)k-1hι-k. Altogether, in order to define a MRA,
one only needs to specify an appropriate low-pass filter h.
The scaling equations can be used to derive an efficient scheme for computing lower order approx-
imation coefficients (of any order) given an initial approximation aj+1 . Conversely, the orthogonal
decomposition Vj+ι = Vj ㊉ Wj can be used to reconstruct a,十 ι given the approximation and de-
tail coefficients aj and dj , respectively, at resolution level j . The computations are summarized in
Figure 2. The reconstruction and decomposition formulae together form the well-known Pyramid
Algorithm Mallat (2008).
In practice, our signals are periodic and do not directly fit into the MRA framework, since non-zero
periodic signals are not elements in L2 (R). We will address this issue in the next section by using
an appropriate cut-off. Here we only remark that the periodicity needs to be carefully taken into
account in the decomposition and reconstruction formulae, see Appendix A.2.
3
Under review as a conference paper at ICLR 2022
(b) Reconstruction
Figure 2: (a) Decomposing approximation coefficients at level j + 1 into approximation and detail
coefficients at level j. Here h and g are defined by hk := h-k and gk := g-k, respectively, * is
the two-sided discrete convolution and ] downsamples a sequence by discarding all terms with odd
index. (b) Reconstructing approximation coefficients at level j + 1 from the approximation and
detail coefficients at level j. Here ↑ samples a sequence up by putting zeros in between every term.
2.3	Wavelet representation of periodic curves
Figure 3: The cut-off signal γ*(t) = γ(lt)1[-ι,i] (t) depicted in blue. We only compute approxima-
tion coefficients associated to the region [一2, 2].
In this section We explain how a scalar-valued periodic signal Y with period l > 0 can be approxi-
mated using a MRA. Let jι ∈ N be a desired resolution-level. First, we re-parameterize Y to have
period 1. The reason for this is rather technical and we refer the reader to Appendix A.1. In essence,
we require the number of approximation coefficients to be a power of two and this parameterization
fits nicely with this requirement. Next, to address the issue that periodic signals are not contained
in L2(R), we restrict the re-parameterized curve to [-1,1], i.e., set Y*(t) := γ(lt)1[-ι,i](t). In
general, this will introduce discontinuities at the boundary points 一1 and 1. This is, however, not an
issue, since we only need information about γ* on a strict subset [Io, Iι] ⊂ [-1,1] of length 1.
it is shown in Lemma A.1 how (and which) approximation coefficients can be related to the sam-
ple values of Y. in particular, if j1 is sufficiently large, the approximation coefficients needed to
b2j1 -βc
(approximately) cover [-1,1] are (ajιk (γ*))k=-2j1∙ Here β > 0 is the support of the underlying
wavelet. These coefficients will be close to the (scaled) sample values of Y on {k2-j1 : -2j1 ≤
k ≤ [2j1 - βC}. Motivated by this observation, and the fact that we only need Y on [-2, ɪ], we
use the coefficients "通(γ* ))k=_；—i—i only, which cover [-ɪ, 1-22 j1 ] approximately, see Figure
3. To ensure that 2j1-1 - 1 < [2j1 - βC, we require that jι ≥ [空瓢1)+ 1^∣. This quantity is
well-defined for all bases considered in this paper, except the Haar-basis. 3
3	Model
in this section we formulate our objective and network architecture. Henceforth Y = Y(x) is asso-
ciated to an image x and has two components [Y(x)]1 and [Y(x)]2. All operations from the previous
sections are understood to be carried out component-wise.
4
Under review as a conference paper at ICLR 2022
Bottleneck
f(cn, nlatent)
Flatten
Residual Convblock
AvgPool 2 × 2
{-Res-dua- b-ock 3 × 31
-s-dubck 3 × 3 一 —
Sk-P connection
■ Reconstruct (Pyramid algorithm) ■ 1 X 1 Conv (4 filters)
Figure 4: A schematic picture of our network. Here a “residual block” corresponds to a standard
residual convolutional layer. The first residual conv-block uses 32 filters and is doubled after every
two residual conv-blocks. Each green block corresponds to the operation depicted in Figure 2b. In
the decoder, we only predict detail coefficients up to level j1 . No detail coefficients are used at levels
j1 + 1 ≤ j ≤ j2 . In this example, we have set j1 = j0 + 2 and j2 = j0 + 3. In reality, the decoder
consists of two upsampling paths, one for each spatial component of the curve. We have only drawn
one for notational convenience. During training, only the approximation coefficients at the lowest
and highest resolution levels (most right curves in blue) are supervised.
3.1	Network architecture
To formulate our objective, consider an image x ∈ X with an associated boundary ∂R(x) of a
simply connected region R(x). We assume that ∂R(x) is parameterized by a closed continuous
curve γ(x) of length l(x) > 0. The objective is to compute the relevant approximation coefficients
of γ* (x), see the explanation in Section 2.3, where Y* (x) denotes the cut-off re-parameterization of
γ(x), using a suitable neural network.
Our network is a hybrid analog of the U-net. It consists of an encoder, bottleneck and decoder with
skip-connections in between. Only the approximation coefficients at the lowest resolution-level j0
are “directly” computed by the network (in the bottleneck). Afterwards, the Pyramid Algorithm
takes over to compute approximation coefficients on higher resolution levels (the decoder). In prac-
tice, the detail coefficients are negligible on sufficiently high resolution levels. For this reason, we
only predict detail coefficients up to a prescribed levelj1. The predictions at higher resolution levels
j1 < j ≤ j2 are computed without detail coefficients. The full architecture is summarized in Figure
4.
3.2	Loss
The loss L consists of two parts: ordinary cross-entropy for optimizing the likelihood of p(x)
and a part corresponding to the L2-error between observed and predicted curves on different res-
olution levels. More precisely, set r(x) = 1 if R(X) = 0 and r(x) = 0 otherwise, then
Lce (p(x), r(x)) := r(x) log p(x) + (1 - r(x)) log(1 - p(x)). Next, suppose a([γ*(x)]) =
(aj0 ([γ*(x)]), . . . , aj2 ([γ*(x)])) are the approximation coefficients of γ*(x) on resolution levels
j0 ≤ j ≤ j2. Define Ljs(fj(x),aj(γ*(x))) := k[fj (x)]s - aj([γ*(x)]s)k2 for s ∈ {1, 2} and
j ∈ {j0,j2}. Here fj (x) are the network predictions of the relevant approximation coefficients at
level j. This loss-term corresponds to the L2-error on resolution level j between the curves with
5
Under review as a conference paper at ICLR 2022
approximation coefficients [fj (x)]s and aj ([γ* (x)]s). Finally, define the total loss by
L(F (x),a):= WLCe(P(x),r(x)) + r(x)	E	Ljs(fj (x),aj (γ*(x))),
s∈{1,2}
j∈{j0 ,j2}
where w > 0 is a weight. Notice that L measures the discrepancies between observed and predicted
curves on the lowest and highest resolution levels only. In practice, this enforces the approximation
and detail coefficients at intermediate levels to agree as well; see the experiments in Section 5.
4	Training
In this section we describe the dataset on which we test our method. In addition, we provide details
about preprocessing steps and model development (training).
4.1	Datasets
Toy dataset The main purpose of the toy-example is to create a setting in which the annotated
contours differ substantially from annotations confined to a grid. For this purpose, we consider
piecewise smooth curves having a finite number of non-differentiable points. The toy-dataset con-
sists of hypocycloids, up to an Euclidian motion and scaling, defined by
η(t) :=	(ri — r2)	cos t +	r?	cos (	r1-r21	)	(ri	— r2)sint - r? sin (	r1——r21	)	,
r2	r2
where ri > r2 and t ∈ R. If r1 ∈ N, then η is closed and has exactly r1 cusps (non-differentiable
points). To easily control the number of cusps, we fix r2 = 1 and vary ri . Note that in this case η
has ri cusps and period 2π.
We construct curves and binary masks of various sizes, orientation and positions, by sampling a
radius ri ∈ {3,4, 5, 6} from U({3,4,5,6}), angle θ from U([— ∏, ∏]), components q1,q2 from
U ([—80, 80]) for a shift, and a scaling factor κ from U ([10, 20]). Here U(I) denotes a random
variable uniformly distributed on I, where I is an interval of finite length or a discrete finite set.
Next, we evaluate the curve κ R(θ)η + [160 + qi 160 + q2]T on an equispaced grid of [0, 2π]
of size 512. Here R(θ) corresponds to an anti-clockwise rotation around the origin with angle θ.
Finally, the discretized curve is used to construct a binary mask of size 320 × 320 using SKIMAGE.
Medical decathlon The data used to evaluate the performance of our model consists of MRI
images of the prostate central gland, henceforth abbreviated as just the prostate, and CT scans of the
spleen. The datasets are part of a public dataset made available for the Medical Decathlon Contest
Simpson et al. (2019) . The dataset for the prostate consists of T2-weighted MRI images of size
320 × 320, which were cropped to size 224 × 224. The dataset for the spleen consists of CT scans
of size 512 × 512 and was cropped to size 256 × 256. The cropping was based on constructing
bounding boxes of the form [umin — δp, umax + δp] × [vmin — δp, vmax + δp] for the training set, where
umin , vmin , umax and vmax are the minimal and maximal coordinates of the segmentation in each
direction, respectively, using an offset of δp = 65 pixels. A residual CNN (encoder of five blocks)
was trained (and validated) on the training set to regress the corner and center points of the bounding
boxes using a RMSE-loss. This rather crude approach is not meant to produce tight bounding boxes,
but serves as a rough necessary localization step to improve performance, and allows us to focus on
the task of shape-prediction only.
4.2	Construction ground-truth
In this section we describe how the ground-truth data is generated using the Pyramid Algorithm and
Lemma A.1. Let (x, u) ∈ X × Rns×np be an image (slice) - contour pair, where x is a slice of the
CT or MRI scan, u is a finite sequence of points approximating a closed curve and ns = 2 is the
number of spatial components. Since we only have access to binary masks (for the public datasets),
and not to the raw annotations themselves, we extract u using OPENCV. While not ideal, we stress
that u contains “subpixel” information and is not constrainted to an integer-valued grid.
6
Under review as a conference paper at ICLR 2022
Fourier coefficients To initialize the Pyramid Algorithm, we compute the approximation coeffi-
cients at level j1 using Lemma A.1. To accomplish this, we need to compute a Fourier expansion for
u. First, we parameterize the contour by arc length. The arc length l is approximated by summing up
the Euclidian distances between subsequent points in u. The Fourier coefficients are then computed
by evaluating the contour on an equispaced grid of [0, l] of size 2N - 1, where N ∈ N, using linear
interpolation and the Discrete Fourier Transform. Since the contours are real-valued, we only store
the Fourier coefficients (Ym)N-I ∈ (Cns )N. Fourier coefficients that are too small, i.e., have no
relevant contribution, are set to zero; see Appendix B.1 for the details.
Consistency To have consistent parameterizations for all slices, we ensure that u is always tra-
versed anti clock-wise (using opencv). Furthermore, since the parameterization is only determined
up to a translation in time, we need to pick out a specific one. We choose the unique parameteriza-
tion such that the contour starts at angle zero at time zero relative to the midpoint c = (c1 , c2) ∈ R2
of R. The implementation details are provided in Appendix B.2.
Approximation and detail coefficients Altogether, the above steps yield a contour γ with Fourier
coefficients (γm)Nm=-11-N and period l. We reparameterize γ to have period 1, as explained in Section
2.3, and “center” the contour using the average midpoint computed over the training-set. The initial
approximation coefficients at level j2 are then computed using Lemma A.1. Next, the Pyramid
Algorithm is used to compute approximation and detail coefficients at levels j0 ≤ j ≤ j2 - 1.
We set the detail coefficients which are in absolute value below ε = 5 ∙ 10-3 to zero to reduce
noise. Subsequently, we reconstruct the approximation coefficients at levels j0 + 1 ≤ j ≤ j1
using the thresholded detail coefficients. No detail coefficients are used to compute approximation
coefficients at levels j1 + 1 ≤ j ≤ j2 . The final approximation and (thresholded) detail coefficients
a and d , respectively, are used as ground-truth.
The resulting dataset D thus consists of tuples (x, a, d). The training and validation set Dtrain and
Dval, respectively, are obtained by randomly omitting subjects from the the full dataset D. For
the toy-example, spleen and prostate we have (|Dtrain|, |Dval|) = (1650, 250), (|Dtrain|, |Dval|) =
(527, 75), and (|Dtrain|, |Dval|) = (3148, 502), respectively. Before feeding the images x into the
model, we linearly rescale the image intensities at each instance to [0, 1]. Furthermore, for the
spleen and prostate, we use extensive data augmentation: we use random shifts, random rotations,
random scaling, elastic deformations, horizontal shearing and random cropping.
4.3	Model training
We use the Adam optimizer Kingma & Ba (2015) to train our network for 150 epochs. In the first
five epochs, We use a linearly increasing learning rate from 5 ∙ 10-4 to 10-3, which is subsequently
decayed by a factor of 0.5 each time the loss does not significantly decrease for 10 subsequent
epochs (for the remaining 145 epochs). A batch size of 16 samples is used in each descent step.
Finally, the model with the lowest loss is selected. The computations were performed in PyTorch
on a Geforce RTX 2080 Ti. 5
5 Results
In this section we examine the performance of our method and its dependence on the choice of
basis. We fix all other hyper-parameters (as much as possible). We consider the Debauches wavelets
dbp with p ∈ {1, 2, 4, 8, 16} vanishing moments. Roughly speaking, dbp corresponds to the unique
MRA for which the mother wavelet has minimal support and p vanishing moments. For each basis,
we fix appropriate resolution levels j0, j1 and j2 as follows. We fix j0 as the smallest possible
resolution level for which the length of our signal (2j0) still exceeds the length of the low-pass filter.
Since dbp	has a low-pass filter of length	2p,	this forces	j0 (p)	=	p.	The choice for	j1	≥	j0	is
based on the observations that the norm of dj decreases as j increases and small detail coefficients
have no significant impact anymore (see Figure 11). We fix j1 ≥ j0 as the smallest level for which
|[djιk]s| < 5 ∙ 10-3 for all samples in the training set (also see the discussion in Section 4.2). The
final resolution level j2 and the support of the mother wavelet determine how much of the contour is
covered, see Figure 3. We therefore fixj2 ≥ j1 as the smallest resolution level for which the distance
between the end-points of the curves are within 1 pixel distance for all samples in the training set.
7
Under review as a conference paper at ICLR 2022
Figure 5: Predicted and observed boundaries colored in red and orange, respectively, for the spleen
and prostate for the best models (db8). The last two columns correspond to “hard” examples. Pre-
dictions for the other wavelet bases, as well as the toy-example, can be found in Appendix D.
We use 64 Fourier coefficients for the the toy-problem, spleen and prostate, respectively to initialize
the approximation coefficients.
Baseline For the prostate and spleen we use the U-Net in Ronneberger et al. (2015) and a recently
developed variant in Nikolov et al. (2018) for comparison. We have modified the network archi-
tectures to match the parameter count with our networks (approximately), while maintaining the
structure and idea,s presented in the original papers as much as possible, see Appendix C. We stress,
however, that our objective, i.e., parameterizing contours, is different from the U-Net,s objective.
The binary ground-truth matched by a U-Net is a fundamentally different (often easier) object than
the continuous representation of a curve matched by our networks. Subtle curvature and geometry
may be accurately presented using our ground-truth curves, e.g., by using a sufficiently large number
ofFourier coefficients to compute approximation coefficients. Binary ground-truth masks, however,
cannot capture such subtle geometry due to their discrete nature.
Performance measures We evaluate accuracy using two-dimensional quantities only, since our
models are 2d. We compute the component-wise L2-errors between observed and predicted curves
on the highest resolution level j2 by taking the '2-norm of the approximation coefficients. Further-
more, we compute the dice score and Haussdorf distance between curves using the implementation
in shapely. This requires a polygonal approximation of the contour, which is easily obtained us-
ing the approximation coefficients at level j2. Note that the Hausdorff distance between subsets of
a general metric space may differ from the Hausdorff distance between the associated boundaries
(wavelet models), but coincide for (compact) simply connected subsets ofRn. The results are shown
in Table 1. The predictions for the best performing wavelet models with respect to the Hausdorff-
score are shown in Figure 5. Predictions for other bases, corresponding wavelet decompositions,
and detailed visualization of statistics (violin plots) can be found in Appendix D.
Toy problem We observe that all models perform well and are capable of accurately parameter-
izing piecewise smooth curves. For db1, however, we observe relatively large gaps between the
end-points, since its support is relatively small. In addition, db1 has difficulty with accurately pre-
dicting small “densely” sampled cycloids. In general, the predictions associated to the less regular
wavelets db1 and db2 sometimes exhibit “small” oscillatory behavior. We found that the latter two
issues were caused by a too large resolution level j2 . To see why, note that the features extracted
from the images only contain information up to a certain resolution level. The subpixel information
needed to “fill in the blanks”, so to speak, is in part provided by the ground-truth data and in part by
the chosen wavelet basis. The regularity and support of the wavelet determines to which extent, i.e.,
up to which resolution level, subpixel information can be “filled in”. As the regularity (and support)
of the wavelet decreases, the maximal achievable resolution level decreases as well.
Spleen The predictions of our models are accurate and on par with the baseline U-Nets. The more
advanced U-Net in Nikolov et al. (2018) performs slightly better; this is mostly due to “edge” cases
where the boundary of the spleen is small and about to disappear from our two-dimensional sliced-
view. In such cases it may sometimes be ambiguous to define an accurate ground-truth contour,
8
Under review as a conference paper at ICLR 2022
Table 1: Mean and standard deviation of various performance measures for the toy example, spleen
and prostate. The standard deviation is reported in parentheses. The column Np is the approximate
number of model parameters in millions, T is the inference time per image in milliseconds, and dbp-
refers to a network trained without detail coefficients. The length of the encoder for the toy-example
is six and five for the prostate and spleen.
Model	(j0 , j1 , j2)	Dice	HaUsdorff	L2 (s = 1)	L2 (s = 2)	Np	T
db1	(1, 6, 8)	0.962 (0.028)	3.520 (1.804)	0.846 (0.317)	0.830 (0.281)	7.70	15.6
db2	(2, 6, 8)	0.971 (0.021)	2.330 (0.889)	0.377 (0.172)	0.373 (0.161)	5.96	15.1
db4	(3, 6, 8)	0.980 (0.014)	1.317 (0.509)	0.264 (0.122)	0.267 (0.124)	5.45	14.5
db8	(4, 6, 8)	0.978 (0.016)	1.287 (0.520)	0.276 (0.149)	0.281 (0.162)	5.25	14.1
db16	(5, 6, 8)	0.978 (0.018)	1.469 (0.503)	0.252 (0.104)	0.254 (0.111)	5.26	14.0
db2-	(2, -, 8)	0.787 (0.036)	13.623 (4.868)	2.968 (0.758)	3.015 (0.916)	5.11	14.9
db4-	(3, -, 8)	0.873 (0.165)	7.222 (6.699)	1.239 (0.569)	1.213 (0.541)	5.11	14.3
db8-	(4, -, 8)	0.967 (0.013)	2.215 (0.845)	0.432 (0.170)	0.430 (0.177)	5.11	14.0
db16-	(5, -, 8)	0.977 (0.018)	1.525(0.516)	0.264 (0.104)	0.264 (0.110)	5.11	14.0
db1	(1, 5, 8)	0.926 (0.034)	5.203(2.040P	2.543 (0.997)	2.915 (1.276)	9.92	11.6
db2	(2, 5, 8)	0.943 (0.030)	4.200 (1.680)	1.798 (1.170)	2.113 (1.322)	5.62	10.5
db4	(3, 5, 8)	0.939 (0.039)	4.102 (1.637)	1.904 (1.096)	2.135 (1.086)	4.48	9.92
db8	(4, 5, 8)	0.940 (0.036)	4.107 (1.572)	1.821 (1.073)	2.058 (1.272)	4.11	9.26
db16	(5, 5, 8)	0.940 (0.037)	4.175 (1.371)	1.880 (1.025)	1.968 (1.183)	3.98	9.92
db2-	(2, -, 8)	0.761 (0.032)	14.611 (4.810)	7.344 (2.609)	6.511 (1.864)	3.97	9.77
db4-	(3, -, 8)	0.930 (0.041)	4.661 (1.592)	2.050 (0.768)	2.429 (1.129)	3.97	9.35
db8-	(4, -, 8)	0.938 (0.042)	4.205 (2.303)	1.990 (1.455)	2.155 (1.315)	3.98	8.99
db16-	(5, -, 8)	0.939 (0.035)	4.058 (1.517)	1.798 (0.881)	1.960 (1.007)	3.98	8.79
Ronneberger et al. (2015)	一	0.952 (0.040)	4.369 (4.913)	-	-	7.76	38.9
Nikolov et al. (2018)	一	0.948 (0.038)	3.584 (1.397)	-	-	6.16	40.7
db1	(1, 5, 6)	0.931 (0.032)	5.328 (2.587P	2.369 (1.269)	2.407 (0.803)	8.38	11.2
db2	(2, 5, 6)	0.930 (0.035)	5.450 (2.647)	2.148 (1.360)	2.120 (0.788)	5.07	9.66
db4	(3, 5, 6)	0.935 (0.032)	5.333 (2.572)	2.026 (1.242)	2.005 (0.894)	4.17	8.64
db8	(4, 5, 6)	0.931 (0.032)	5.323 (2.584)	2.147 (1.381)	2.019 (0.873)	3.87	7.59
db16	(5, 5, 6)	0.924 (0.040)	5.583 (2.665)	2.218 (1.280)	2.197 (0.994)	3.74	7.65
db2-	(2, -, 6)	0.779 (0.025)	14.584 (4.487)	6.072 (1.937)	6.577 (1.998)	3.73	8.22
db4-	(3, -, 6)	0.921 (0.037)	6.040 (3.264)	2.353 (1.316)	2.328 (1.046)	3.73	7.84
db8-	(4, -, 6)	0.923 (0.041)	6.082 (3.380)	2.334 (1.485)	2.328 (1.008)	3.73	7.79
db16-	(5, -, 6)	0.928 (0.032)	5.499 (2.901)	2.177 (1.273)	2.078 (0.784)	3.74	7.56
Ronneberger et al. (2015)	一	0.932 (0.047)	5.673 (2.402)	-	-	7.76	37.2
Nikolov et al. (2018)	-	0.937 (0.030)	5.475(2.380)	-	-	5.49	32.4
resulting in curves with subtle spurious curvature. Such geometry is not (and cannot be) present in
the binary ground-truth mask due its discrete nature.
Prostate central gland The wavelet models produce accurate predictions and are on par with
the U-Nets. Our models perform slightly better in terms of Hausdorff distance. While all models
produce accurate predictions for most examples, there are instances where both the wavelet models
and the baseline U-Nets fail to produce accurate predictions; see the last two columns of Figure 5.
In these examples, the detail coefficients associated to parts of the curve with high curvature are too
small in magnitude to be accurately predicted. While detail coefficients of such small magnitude
were less relevant in the latter two examples, they are important for the prostate.
Ablation study (no detail coefficients) To demonstrate the importance of the detail coefficients,
we have trained models without them, i.e., without the skip-connections. In this set up, we do not
supervise the predictions on the lowest resolution level during training. The results demonstrate, as
expected, that the lower-order wavelets db1, db2 perform significantly worse without detail coeffi-
cients. In fact, for db1 our model failed to produce any sensible approximations that can be evaluated
and were therefore omitted. A small drop in performance is observed for db4. In general, for db16
there is not much gain, with respect to accuracy, memory-footprint and inference time, to explicitly
model the detail coefficients. 6
6 Conclusion
We have introduced a novel method to model boundaries of two dimensional simply connected
domains using wavelets and MRAs. In effect this allows for subpixel segmentations. The efficacy of
the method has been demonstrated by modeling the boundaries of hypercloids (toy-example), spleen
and prostate, demonstrating that the results are on par with typical U-Nets, yielding up to five times
faster inference speed.
9
Under review as a conference paper at ICLR 2022
References
P. Abry and P. Flandrin. On the initialization of the discrete wavelet transform algorithm. IEEE
SignalProcessing Letters,1(2):32-34,1994. doi: 10.1109/97.300311.
David Acuna, Amlan Kar, and Sanja Fidler. Devil is in the edges: Learning semantic boundaries
from noisy annotations. In 2019 IEEE/CVF Conference on Computer Vision and Pattern Recog-
nition (CVPR), pp. 11067-11075, 2019. doi: 10.1109/CVPR.2019.01133.
Arantxa Casanova, Pedro O. Pinheiro, Negar Rostamzadeh, and Christopher J. Pal. Reinforced ac-
tive learning for image segmentation. In International Conference on Learning Representations,
2020. URL https://openreview.net/forum?id=SkgC6TNFvr.
Jianxu Chen, Lin Yang, Yizhe Zhang, Mark Alber, and Danny Z Chen. Combin-
ing fully convolutional and recurrent neural networks for 3d biomedical image seg-
mentation. In D. Lee, M. Sugiyama, U. Luxburg, I. Guyon, and R. Garnett
(eds.), Advances in Neural Information Processing Systems, volume 29. Curran Asso-
ciates, Inc., 2016a. URL https://proceedings.neurips.cc/paper/2016/file/
4dcf435435894a4d0972046fc566af76-Paper.pdf.
Liang-Chieh Chen, George Papandreou, Iasonas Kokkinos, Kevin Murphy, and Alan Yuille.
Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and
fully connected crfs. IEEE Transactions on Pattern Analysis and Machine Intelligence, PP, 06
2016b. doi: 10.1109/TPAMI.2017.2699184.
Liang-Chieh Chen, Yukun Zhu, George Papandreou, Florian Schroff, and Hartwig Adam. Encoder-
decoder with atrous separable convolution for semantic image segmentation. In Vittorio Ferrari,
Martial Hebert, Cristian Sminchisescu, and Yair Weiss (eds.), Computer Vision - ECCV2018, pp.
833-851, Cham, 2018. Springer International Publishing. ISBN 978-3-030-01234-2.
Xu Chen, Bryan M Williams, Srinivasa R Vallabhaneni, Gabriela Czanner, Rachel Williams, and
Yalin Zheng. Learning Active Contour Models for Medical Image Segmentation. In Proceedings
of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 11632-
11640, 2019.
Jun Fu, Jing Liu, Haijie Tian, Yong Li, Yongjun Bao, Zhiwei Fang, and Hanqing Lu. Dual attention
network for scene segmentation. pp. 3141-3149, 06 2019. doi: 10.1109/CVPR.2019.00326.
Loukas Grafakos. Classical Fourier Analysis, volume 249 of Graduate Texts in Mathemat-
ics.	Springer New York, New York, NY, 2008. ISBN 9780387094311. doi: 10.
1007/978-0-387-09432-8. URL http://www.springerlink.com/index/10.1007/
978-0-387-09432-8.
Ali Hatamizadeh, Debleena Sengupta, and Demetri Terzopoulos. End-to-end trainable deep active
contour models for automated image segmentation: Delineating buildings in aerial imagery. In
European Conference on Computer Vision, pp. 730-746. Springer, 2020.
Ali Hatamizadeh, Yucheng Tang, Vishwesh Nath, Dong Yang, Andriy Myronenko, Bennett Land-
man, Holger Roth, and Daguang Xu. Unetr: Transformers for 3d medical image segmentation,
2021.
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image
recognition. In Proceedings of the IEEE Computer Society Conference on Computer Vision
and Pattern Recognition, volume 2016-December, pp. 770-778. IEEE Computer Society, dec
2016. ISBN 9781467388504. doi: 10.1109/CVPR.2016.90. URL http://image-net.
org/challenges/LSVRC/2015/.
Xiaoling Hu, Fuxin Li, Dimitris Samaras, and Chao Chen. Topology-preserving deep image
segmentation. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alch6-Buc, E. Fox, and
R. Garnett (eds.), Advances in Neural Information Processing Systems, volume 32. Curran As-
sociates, Inc., 2019. URL https://proceedings.neurips.cc/paper/2019/file/
2d95666e2649fcfc6e3af75e09f5adb9- Paper.pdf.
10
Under review as a conference paper at ICLR 2022
Fabian Isensee, Paul F Jaeger, Simon A A Kohl, Jens Petersen, and Klaus H Maier-Hein. nnu-
net: a self-configuring method for deep learning-based biomedical image segmentation. Nature
methods, 18(2):203—211, February 2021. ISSN 1548-7091. doi: 10.1038/s41592-020-01008-z.
URL https://doi.org/10.1038/s41592-020-01008-z.
Simon J6gou, Michal Drozdzal, David Vazquez, Adriana Romero, and YoshUa Bengio. The one
hundred layers tiramisu: Fully convolutional densenets for semantic segmentation. In 2017 IEEE
Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), pp. 1175-1183,
2017. doi: 10.1109/CVPRW.2017.156.
A. Khoreva, R. Benenson, M. Omran, M. Hein, and B. Schiele. Weakly supervised object bound-
aries. In 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 183-
192, Los Alamitos, CA, USA, jun 2016. IEEE Computer Society. doi: 10.1109/CVPR.2016.27.
URL https://doi.ieeecomputersociety.org/10.1109/CVPR.2016.27.
Diederik P. Kingma and Jimmy Lei Ba. Adam: A method for stochastic optimization. In 3rd
International Conference on Learning Representations, ICLR 2015 - Conference Track Proceed-
ings. International Conference on Learning Representations, ICLR, dec 2015. URL https:
//arxiv.org/abs/1412.6980v9.
Jeremy B Maitin-Shepard, Viren Jain, Michal Januszewski, Peter Li, and Pieter Abbeel. Combinato-
rial energy learning for image segmentation. In D. Lee, M. Sugiyama, U. Luxburg, I. Guyon, and
R. Garnett (eds.), Advances in Neural Information Processing Systems, volume 29. Curran As-
sociates, Inc., 2016. URL https://proceedings.neurips.cc/paper/2016/file/
31857b449c407203749ae32dd0e7d64a-Paper.pdf.
Stphane Mallat. A Wavelet Tour of Signal Processing, Third Edition: The Sparse Way. Academic
Press, Inc., USA, 3rd edition, 2008. ISBN 0123743702.
Diego Marcos, Devis Tuia, Benjamin Kellenberger, Lisa Zhang, Min Bai, Renjie Liao, and Raquel
Urtasun. Learning deep structured active contours end-to-end. In Proceedings of the IEEE Con-
ference on Computer Vision and Pattern Recognition (CVPR), pp. 8877-8885, 2018.
Kuo Men, Huaizhi Geng, Chingyun Cheng, Haoyu Zhong, Mi Huang, Yong Fan, John P Plastaras,
Alexander Lin, and Ying Xiao. Technical note: More accurate and efficient segmentation of
organs-at-risk in radiotherapy with convolutional neural networks cascades. Medical physics,
46(1):286—292, January 2019. ISSN 0094-2405. doi: 10.1002/mp.13296. URL https://
europepmc.org/articles/PMC6322972.
L. Montefusco and L. Puccio. Wavelets: Theory, Algorithms, and Applications. ISSN. Elsevier
Science, 2014. ISBN 9780080520841. URL https://books.google.nl/books?id=
Ln6jBQAAQBAJ.
Stanislav Nikolov, Sam Blackwell, Ruheena Mendes, Jeffrey De Fauw, CIemens Meyer, Cian
Hughes, Harry Askham, Bernardino Romera-Paredes, Alan Karthikesalingam, Carlton Chu,
Dawn Carnell, Cheng Boon, Derek D’Souza, Syed Ali Moinuddin, Kevin Sullivan, Deep-
Mind Radiographer Consortium, Hugh Montgomery, Geraint Rees, Ricky Sharma, Mustafa Su-
leyman, Trevor Back, Joseph R. Ledsam, and Olaf Ronneberger. Deep learning to achieve clini-
cally applicable segmentation of head and neck anatomy for radiotherapy. CoRR, abs/1809.04430,
2018. URL http://arxiv.org/abs/1809.04430.
Sida Peng, Wen Jiang, Huaijin Pi, Xiuli Li, Hujun Bao, and Xiaowei Zhou. Deep snake for real-
time instance segmentation. In 2020 IEEE/CVF Conference on Computer Vision and Pattern
Recognition (CVPR), pp. 8530-8539, 2020. doi: 10.1109/CVPR42600.2020.00856.
M.C. Pereyra and L.A. Ward. Harmonic Analysis: From Fourier to Wavelets. IAS/Park city
mathematical subseries. American Mathematical Society, 2012. ISBN 9780821875667. URL
https://books.google.nl/books?id=ovsjX_t0kOkC.
Olaf Ronneberger, Philipp Fischer, and Thomas Brox. U-net: Convolutional networks for biomed-
ical image segmentation. In Nassir Navab, Joachim Hornegger, William M. Wells, and Alejan-
dro F. Frangi (eds.), Medical Image Computing and Computer-Assisted Intervention - MICCAI
2015, pp. 234-241, Cham, 2015. Springer International Publishing. ISBN 978-3-319-24574-4.
11
Under review as a conference paper at ICLR 2022
Amber L. Simpson, Michela Antonelli, Spyridon Bakas, Michel Bilello, Keyvan Farahani, Bram
van Ginneken, Annette Kopp-Schneider, Bennett A. Landman, Geert Litjens, Bjoern Menze, Olaf
Ronneberger, Ronald M. Summers, Patrick Bilic, Patrick F. Christ, Richard K. G. Do, Marc
Gollub, Jennifer Golia-Pernicka, Stephan H. Heckers, William R. Jarnagin, Maureen K. McHugo,
Sandy Napel, Eugene Vorontsov, Lena Maier-Hein, and M. Jorge Cardoso. A large annotated
medical image dataset for the development and evaluation of segmentation algorithms. 2019.
Nuo Tong, Shuiping Gou, Shuyuan Yang, Dan Ruan, and Ke Sheng. Fully automatic multi-organ
segmentation for head and neck cancer radiotherapy using shape representation model constrained
fully convolutional neural networks. Medical Physics, 45, 08 2018. doi: 10.1002/mp.13147.
Wenxuan Wang, Chen Chen, Meng Ding, Hong Yu, Sen Zha, and Jiangyun Li. Transbts: Multi-
modal brain tumor segmentation using transformer. In Marleen de Bruijne, Philippe C. Cattin,
StePhane Cotin, Nicolas Padoy, Stefanie SPeideL Yefeng Zheng, and Caroline Essert (eds.), Med-
ical Image Computing and Computer Assisted Intervention - MICCAI2021 ,pp.109-119, Cham,
2021. SPringer International Publishing. ISBN 978-3-030-87193-2.
Yueyue Wang, Liang Zhao, Manning Wang, and Zhijian Song. Organ at risk segmentation in head
and neck ct images using a two-stage segmentation framework based on 3d u-net. IEEE Access,
7:144591-144602, 2019. doi: 10.1109/ACCESS.2019.2944958.
Yuxin Wu and Kaiming He. Group normalization. In Vittorio Ferrari, Martial Hebert, Cristian
Sminchisescu, and Yair Weiss (eds.), Computer Vision - ECCV 2018, pp. 3-19, Cham, 2018.
Springer International Publishing. ISBN 978-3-030-01261-8.
Jimei Yang, Brian Price, Scott Cohen, Honglak Lee, and Ming-Hsuan Yang. Object contour detec-
tion with a fully convolutional encoder-decoder network. In 2016 IEEE Conference on Computer
Vision and Pattern Recognition (CVPR), pp. 193-202, 2016. doi: 10.1109/CVPR.2016.28.
Yundong Zhang, Huiye Liu, and Qiang Hu. Transfuse: Fusing transformers and cnns for medical
image segmentation. In MICCAI, 2021.
S. Zheng, J. Lu, H. Zhao, X. Zhu, Z. Luo, Y. Wang, Y. Fu, J. Feng, T. Xiang, P. S. Torr, and
L. Zhang. Rethinking semantic segmentation from a sequence-to-sequence perspective with
transformers. In 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition
(CVPR), pp. 6877-6886, Los Alamitos, CA, USA, jun 2021. IEEE Computer Society. doi:
10.1109/CVPR46437.2021.00681. URL https://doi.ieeecomputersociety.org/
10.1109/CVPR46437.2021.00681.
A	Theoretical results
In this section we prove theoretical results regarding the computation of wavelet decompositions. In
addition, we provide all the implementation details.
A.1 EXPLICIT EXPRESSION FOR ajk
To address the issue that periodic signals are not contained in L2(R), We consider the cut-off 7 :=
YI[-1,1]. In this section we derive an explicit formula for hγ, Wjki by exploiting the periodicity
of γ . In particular, We Will quantify the claim that (scaled) sample values of γ may be used as
approximation coefficients. For this purpose, we first review some facts about the scaling equation.
If we take the Fourier transform ofboth sides of the scaling equation, we obtain the relation W(ξ)=
H(2)W(2) for ξ ∈ R, where H(ξ) = √12 Pk∈z hke-i2πξk. The map H is referred to as the
refinement mask associated toh. Throughout this paper we assume that h is finite, in which case
W has compact support and H is a trigonometric polynomial of period 1. It is beyond the scope of
this paper to discuss the properties of H in detail and refer the reader to Pereyra & Ward (2012);
Montefusco & Puccio (2014). Here we only need the following result. Under suitable conditions,
one may iterate the equation for W and show that W(ξ) = Q∞=1 H(2k) for all ξ ∈ R.
12
Under review as a conference paper at ICLR 2022
Lemma A.1 (Initialization approximation coefficients). Let h ∈ '2(Z) be a low-pass-filter defining
a MRA on L2 (R) and H the associated refinement mask. Assume h is non-zero for only a finite
number of coefficients, Supp (夕)⊂ [0,β] for some β > 0, and 夕 is bounded. Furthermore, suppose
that ⅛^(ξ) = Qn=I H(2n) for all ξ ∈ R. If Y ∈ Cer([0, l]) is a l-periodic map with Fourier
coefficients (γm)m∈Z, then
∞
hY,怦i = 2-2 X YmeiSm2j Y H (- j) ,	(1)
m∈Z	n=1
where ω(l) := 2∏ is the angularfrequency of Y ,for any j ∈ Z and k ∈ {「一2jl],..., [2jl — β1}.
Proof. Letj ∈ Z and k ∈ {d-2j le, . . . , b2jl - βc} be arbitrary. A change of variables shows that
〈机夕jk i
2- j [ Y (2-j(t + k)) φ(t) dt,
[0,β]
k ∈ Z,
since supp(夕)⊂ [0,β]. In particular, note that 2-j(t + k) ∈ [-l,l] for t ∈ [0,β], since k ∈
{d-2jl],..., 12jl — βC}. Therefore, We may plug in the Fourier expansion for Y and compute
Y Y (2-j(t + k)) ψ(t) dt = I X Ymeiω⑷mtj φ(t) dt.
[0,β]	[0,β] m∈Z
Next, note that that series inside the integral converges pointwise to Y (2-j(t + k))夕(t) on
[0, β]. Furthermore, the partial sums can be bounded from above on [0, β] by a constant, since
Y ∈ Cer([0,l]) and 夕 is bounded. Therefore, we may interchange the order of summation and
integration by the Dominated Convergence Theorem:
X X Ymeiω(I)m岩 ψ(t) dt = X Ymeiω⑷m2j I	eiω(I)m j ψ(t) dt.
[0,β] m∈Z	m∈Z	[0,β]
Finally, changing the domain of integration to R again, we see that
X Ymes 2j
m∈Z
/0 J(I)m 2j。⑴dt=XZ Lm "W)
The stated result now follows from the assumption that <7^(ξ) = Q∞=ι H(晟)for any ξ ∈ R.	□
Remark A.2. The bounds d—2j le and b2jl — βc are the smallest and largest integer, respectively,
for which 2-j (t + k) ∈ [—l, l] for all t ∈ [0, β]. The bounds on k are somewhat artificial, however,
since the argument may be repeated for any truncation of Y on [—nl, nl], where n ∈ N. This
observation is reflected in the righthand-side of (1), which is well-defined for all k ∈ Z (but not
squared-summable). The reason for choosing this particular truncation is to identify a minimal
number of approximation coefficients needed to cover the full signal Y.
The requirement that ⅛^(ξ) = Q∞=ι H(齐)for ξ ∈ R is satisfied for all MRA's considered in this
paper. In particular, we remark that。is continuous at ξ = 0 and ⅛^(0) = 1. It follows from these
observations and Lemma A.1 that ajk(Y) = ajk(Y) ≈ 2- j Y(k2-j) for j sufficiently large and k
constrained to {d—2j le, . . . , b2jl — βc}.
A.2 Pyramid Algorithm - implementation details
In this section we provide the computational details for how to compute approximation and detail
coefficients using the Discrete Fourier Transform (DFT). In the following arguments all sequences
are assumed to be two-sided. We will frequently abuse notation and write that a finite sequence is an
element in Cn orRn. What we actually mean by this, is that we have a two-sided sequence of length
n which can be embedded in `2 (Z) by appropriately padding with zeros. In such a situation we will
explicitly specify the indices of the sequence so that the intended ordering is clear. Similarly, all
operators in this section are implicitly assumed to be defined on the associated (two-sided) sequence
spaces, even though we may write that they are defined on Cn or Rn .
13
Under review as a conference paper at ICLR 2022
Let a = (ak)kN=--1N ∈ R2N and g = (gk)kM=-11-M ∈ R2M-1 be arbitrary. Here g may be interpreted
as a high-pass-filter of length M with N ≥ M ≥ 2. Similarly, we may think of a as the approxima-
tion coefficients of a 1-periodic signal at a specific resolution level j, with N = 2j-1, as explained
in Section 2.3. In this section, however, we will not emphasize these interpretations, e.g., write ajk
instead of ak, to avoid clutter in the notation. Observe that the righthand-side of (1) is a 2j -periodic
sequence for 1-periodic signals. Therefore, to properly deal with “boundary terms”, we will use the
2N-periodic extension a ∈ RZ of a to evaluate discrete convolutions.
Convolution and multiplication of trigonometric polynomials To compute the detail and ap-
proximation coefficients, we need to evaluate expressions of the form
(a * g)k =	〉:	akι gk2 =	〉:	ɑk-k2 gk2	(2)
k1+k2 = k	∣k2∣≤M — 1
∣k2∣≤M -1	一
k1∈Z
for -N ≤ k ≤ N 一 1. Note that although a is an infinite 2N-periodic sequence, the series in
(2) contains	only	a	finite	number	of nonzero-terms, since gk2 =	0 for |k2 |	≥	M.	Furthermore,	for
-N	≤	k	≤	N 一	1,	we do not need the full periodic extension a,	but only a	partial	(finite)	extension
PK (a), where PK : C2N → CK is defined by
{ak+2N 1 - N - M ≤ k	≤ -N -	1,
ak	-N ≤ k ≤ N -	1,
ak-2N N ≤ k ≤ N + M - 2
andK := 2(N+M - 1). That is, (aa * g)k = (PK(a) *g)k for -N ≤ k ≤ N- 1.
We use standard arguments to compute PK (a) * g. Namely, we interpret PK (a) * g as the Fourier
coefficients of uv, where u, v : R → C are the trigonometric polynomials defined by
Kf-1	M-1
u(θ) = X (PK(a))keikθ,	v(θ) = X gkeikθ.
k=-f	k = 1-M
The product uv is a trigonometric polynomial with Ka := K + 2(M - 1) non-zero coefficients
corresponding to terms of order -K ≤ k ≤ K - 1. The coefficients of uv can be characterized
∙-v	∙-v
by evaluating it on K distinct points in C. After fixing K such points, we may go back and forth
between value and coefficient representations of u, v and uv using the isomorphism defined by the
evaluation operator.
Evaluation at the roots of unity We evaluate u and v, in the complex variable z = eiθ, at the Ka -
th roots of unity. To do this, we first extend PK (a) and g to sequences in CK by padding with zeros.
More precisely, define ZKen : CK → CK by (ZKen(b))k = bk for -与 ≤ k ≤ K - 1 and zero for
T^'	r/	r/	τ^r	ι∙ιcκ∙r T	T^-	ɪ ɪ ,	..
-K ≤ k < -K and K ≤ k < KK. Similarly, define ZMd : C2M-1 → CK by (ZMMd(b))k = bk for
2.，.	2
|k| < M and zero for -K ≤ k ≤ -M and M ≤ k < K. We Can now evaluate U and V at the K-th
roots of unity by computing DFTK ◦ SK ◦ ZKen ◦ PK(a) and GK ：= DFTK ◦ SK ◦ ZMMd(g),
respectively, where SK2 : CK2 → CK2 is defined by
f bk ,	0 ≤ k ≤ K - 1,
(SK2 b)k :=
Ibk-K, K ≤ k ≤ K - L
∙-v
Consequently, uv can be evaluated at the K-th roots of unity by taking the element-wise product of
the latter two vectors. Finally, the desired coefficients (PK (a) *g)kN=--1N are obtained by going back
to coefficient space using the inverse DFT , i.e.,
(PK(a) * g)N=-N = ∏nSKIDFTKI (GK © DFTK ◦ SK ◦ ZKen。PK⑷).
Here denotes the Hadamard-product and ΠN : CK2 → C2N is the truncation operator defined by
ΠN (b) := (bk)kN=--1N.
14
Under review as a conference paper at ICLR 2022
B Preprocessing
In this section we provide the details of our preprocessing steps.
B.1	Truncation Fourier coefficients
The magnitude of the approximated Fourier coefficients will typically stagnate and stay con-
stant (approximately) beyond some critical order, since all computations are performed in finite
(single) precision. We locate this critical order m0(s) ∈ N for each component S ∈ {1,2},
if present, by iteratively fitting the best line, in the least squares sense, through the points
{(mJ∣(IBm]sl)⅛=m0∣∣1) ： mo ≤ m ≤ N - l} for 1 ≤ m0 ≤ N - L We iterate this process
until the residual is below a prescribed threshold δN > 0. In practice, we set δN = 0.1. The Fourier
coefficients with index strictly larger than mɔ(s) are set to zero.
B.2	Consistent parameterizations
To have consistent parameterizations we enforce that all contours start at angle zero at time zero rela-
tive to the midpoint c = (c1, c2) ∈ R2 of the region of interest R. This is accomplished by exploiting
the Fourier representation of the curve. More precisely, let Y := t → P∣m∣≤N-ι 7meiω(l)mt, where
ω(l) = 2∏, be the contour with Fourier coefficients Γ := (Ym)m=1-N. The midpoint C of the region
enclosed by γY is given by
dλz	([Γ]ι* [Γ]2 * [Γ0]s)o
Uu dλ(u1,u2) = (-1)	([Γ]ι * Ph)。
s∈{1,2}
(3)
by Green’s Theorem. Here λ denotes the Lebesgue measure on R2, [Γ]s are the Fourier coefficients
of [γY]s, and (Γ0)m := imω(l)γm for |m| ≤ N - 1. We can now compute the desired parameteriza-
[γY (-τ ) - c]1
tion by determining T ∈ [0,l] such that arccos 7--——ʌ--π- ≈ 0 and defining γ(t) := γ(t 一 T).
kγY(-τ) - ck2
While T can be easily found using Newton’s method, it suffices in practice to simply re-order y from
the start, before computing the Fourier coefficients. More precisely, we first define a shift yYof y by
yk := yk + k* mod np for 0 ≤ k ≤ np 一 1, Where k*
([yiι )1np-1
Illyk-Cll2Jj∖=0
argmin arccos
C U-Net architectures (baselines)
In this section we describe our modifications to the networks presented in Ronneberger et al. (2015)
and Nikolov et al. (2018). The goal of the modifications is to match the parameter count with
our networks (approximately), while maintaining the structure and idea’s presented in the original
papers as much as possible. Our modifications to the original U-Net in Ronneberger et al. (2015)
is minimal: we use 32 filters in the first layer instead of 64 and use group normalization with four
groups. Our modifications to the network in Nikolov et al. (2018) are as follows. We use residual
blocks of length two (instead of three), we use a bottleneck with 256 channels (instead of 1024), and
we do not use 1d convolutions in the “third” direction (to keep our model 2d). Furthermore, we use
an encoder and decoder of length six. The number of filters used in the encoder, from top to bottom,
is 32, 32, 64, 64, 128, and 128, respectively. The number of filters used in the decoder, from bottom
to top, is 128, 128, 64, 64, 64 and 64, respectively.
15
Under review as a conference paper at ICLR 2022
D	Figures
In this section we provide additional visualizations of the statistics, wavelet decompositions and
predicted contours.
D.1 Toy example
ι.oo-
0.95-
0.90-
0.85-
0.80-
0.75-
dbl	db2	db4	db8 dbl6	dbl	db2	db4	db8 dbl6
Models	Models
(a) Dice	(b) Hausdorff
Figure 6: Boxplots and visualization of approximate densities for the dice scores and Hausdorff
distances for the toy problem.
Figure 7: Predicted curve (in red) for a binary mask (in white). In order to visualize the predicted
curve without too much clutter we have not depicted the ground-truth contour.
16
Under review as a conference paper at ICLR 2022
(a) db1
(b) db2
(c) db4
(d) db8
Figure 8: Predicted and observed wavelet decompositions of the first component of the contour
depicted in the fourth column in Figure 7.
17
Under review as a conference paper at ICLR 2022
D.1.1 Spleen
dbl db2 db4 db8 dbl6 uπetbasehπe	dbl db2 db4 db8 dbl6 uπetbasehπe
Models	Models
(a) Dice	(b) Hausdorff
Figure 9: Boxplots and visualization of approximate densities for the dice scores and Hausdorff
distances for the spleen.
db1
db2
db4
db8
db16
(a)
Figure 10: Predicted and observed boundaries colored in red and orange, respectively, of the spleen.
The last two columns correspond to a few “hard” examples.
18
Under review as a conference paper at ICLR 2022
(a) db1
(b) db2
Figure 11: Predicted and observed wavelet decompositions of the first component of the contour
depicted in the first column in Figure 10. For db4 and db8 the detail coefficients on higher resolution
levels are too small to be accurately predicted, but have little impact on the accuracy of the final
approximation.
19
Under review as a conference paper at ICLR 2022
D.1.2 Prostate
dbl db2 db4 db8 dbl6 Unet baseline	dbl db2 db4 dbδ dbl6 unet-baseli∏e
Models	Models
(a) Dice	(b) Hausdorff
Figure 12: Boxplots and visualization of approximate densities for the dice scores and Hausdorff
distances for the prostate.
db16
(a)
Figure 13: Predicted and observed boundaries colored in red and orange, respectively, of the
prostate. The last two columns correspond to “hard” examples.
20
Under review as a conference paper at ICLR 2022
(a) db1, fifth column
(b) db2, fifth column
(c) db1, sixth column
(d) db2, sixth column
Figure 14: Predicted and observed wavelet decompositions of the first component of the hard exam-
ples depicted in (a), (b) the fifth column and (c), (d) the sixth column of Figure 13.
21