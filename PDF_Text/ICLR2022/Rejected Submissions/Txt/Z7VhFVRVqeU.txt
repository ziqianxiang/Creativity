Under review as a conference paper at ICLR 2022
Neural B ootstrapping Attention for Neural
Processes
Anonymous authors
Paper under double-blind review
Ab stract
Neural Processes learn to fit a broad class of stochastic processes with neural net-
works. Modeling functional uncertainty is an important aspect of learning stochastic
processes. Recently, Bootstrapping Neural Processes (b (a)np) propose a bootstrap
method to capture the functional uncertainty which can replace the latent variable in
(Attentive) Neural Processes ((a)np), thus overcoming the limitations of Gaussian
assumption on the latent variable. However, b(a)np conduct bootstrapping in a
non-parallelizable and memory-inefficient way and fail to capture diverse patterns
in the stochastic processes. Furthermore, we found that anp and banp both tend
to overfit in some cases. To resolve these problems, we propose an efficient and
easy-to-implement approach, Neural Bootstrapping Attentive Neural Processes
(neubanp). neubanp learns to generate the bootstrap distribution of random func-
tions by injecting multiple random weights into the encoder and the loss function.
We evaluate our models in benchmark experiments including Bayesian optimization
and contextual multi-armed bandit. neubanp achieves the best performance in the
sequential decision-making tasks among np methods, and this empirically shows
that our method greatly improves the quality of functional uncertainty modeling.
1 Introduction
Neural Processes (np) (Garnelo et al., 2018b) define distributions over functions given a set of
observations, and are trained via a meta-learning framework so that it can adapt to new functions
rapidly. np learns to model a wide range of stochastic processes and can estimate the uncertainty over
the predictions with less computational effort, compared to Gaussian Processes (gp) (Rasmussen,
2003). However, np frequently suffers from a fundamental drawback of underfitting. As a remedy
of the underfitting issue, Attentive Neural Processes (anp) (Kim et al., 2018) applies the attention
modules to the encoder network. Despite this modification, a single Gaussian latent variable of (a)np
has a limitation in inducing functional uncertainty (Louizos et al., 2019), a global uncertainty that
decides the distribution over the space of trajectories or functions.
Appropriate modeling of functional uncertainty in stochastic processes improves the predictive
performance and diversity in function realizations (Le et al., 2018), thus provides a principled way
to guide agents to find optimal candidates in sequential decision-making problems. In these tasks, a
model needs to approximate a function and estimate uncertainty correctly to optimize a black-box
function whose analytic information is not given. Although gp is widely used for these tasks, these
are the promising area for the application of np because gp is computationally expensive, and it can
be hard to choose an appropriate prior. Recently, Bootstrapping Neural Processes (b (a)np) (Lee
et al., 2020) modify (a)np to induce more robust uncertainty estimation by employing the residual
bootstrapping. However, b(a)np underperforms in capturing a functional uncertainty because the
residual bootstrapping works in a homoscedastic way, removing the connection between the feature
and the label in its bootstrapped samples. The bootstrap strategy used in b(a)np demands a higher
computational burden compared to (a)np since it requires multiple computations of the encoder
network and additional heuristics, including the adaptation layer and the lower bound on the variance1.
Furthermore, anp and banp tend to overfit for a simple regression task rather than learning the
underlying heteroscedasticity. We observed that this problem is a by-product of the attention modules
1We colored the revised or added sentences in blue only for the rebuttal. This color will not appear in the
final version of the manuscript.
1
Under review as a conference paper at ICLR 2022
used in both models (see Figure 1 and 5). This finding suggests that effective regularization of
attention modules is required to prevent overfitting. Additionally, as explained in Section 4, anp and
banp often tend to estimate homogeneous uncertainty regardless of whether the observation is given.
Fig. 1. Each plot shows predictions given by anp, banp, and the proposed method in a linear regression.
The ground-truth function is a simple linear function with heterogeneous variance: y = x + β(x) where
e(x)〜N(0, σ2(x)) and σ(x) = √x2 + 10-5. See Appendix B.1 for more details.
To resolve the problems of previous nps, we introduce a novel bootstrapping method for neural
processes, Neural Bootstrapping Attentive Neural Processes (neubanp). Motivated from the recent
work on efficient bootstrapping of the neural network, Neural Bootstrapper (NeuBoots) (Shin et al.,
2021), we introduce bootstrapping of the attention in a computationally efficient way by simple
modification of the input of attention modules and the loss function, instead of memory-inefficient
resampling and contrived heuristics employed in banp. The simplicity and computational efficiency
of neubanp directly come from NeuBoots, but it does not guarantee the performance in modeling the
functional uncertainty since neubanp operates on the meta-learning framework. Thus, we modify the
method for training the model to learn the randomness present in the underlying function, allowing the
model to estimate random functions generated by any stochastic process. This modification is simple
but gives a strong consistency between the bootstrapped samples and the representations from the
attention modules, unlike the residual bootstrapping used in banp. Besides, our bootstrapping method,
which implements the concatenation and multiplication of random bootstrap weights, operates as
a regularizer on the attention networks, thus preventing overfitted predictions observed in previous
attention-based np methods. neubanp is trained to generate a valid predictive distribution by utilizing
the uncertainty inherent in observations by bootstrapping instead of the uncertainty that depends
on the prior assumption on the latent variable as in (a)np. This leads to the success in capturing
heteroscedasticity of the data and modeling functional uncertainty in stochastic processes. As a result,
neubanp achieves the best performance in sequential decision-making problems such as Bayesian
optimization and contextual multi-armed bandit. The experimental results demonstrate that our model
provides promising capabilities as an efficient neural approximation of stochastic processes.
Contributions We propose neubanp, an easy-to-implement and computationally efficient method
for bootstrapping anp. The proposed method has a novelty in learning a generator for bootstrapping
stochastic processes under a meta-learning framework. neubanp resolves overfitting problem of
attention modules and shows robust performance on heteroscedastic models without heuristics like
the extra adaptation layer in banp. neubanp estimates functional uncertainty better than banp and
achieves the best performance in stochastic optimization problems, including multi-dimensional
Bayesian optimization and contextual multi-armed bandit, compared to previous np methods.
2 Preliminaries
2.1 Meta-Learning Framework of Neural Processes
Consider data D = (X, Y ) = {(xi, yi)}in=1 ⊂ X × Y, the pairs of inputs xi ∈ X and outputs yi ∈ Y.
Let P be a probability distribution over functions f ∈ F; yi = f (Xi) + Ci where Ci〜N(0, σ2),
hence P determines the distribution of D. For disjoint index sets C and T satisfying C ∪ T = [n],
define context DC = (XC,YC) = {(xc,yc)}c∈C and target DT = (XT ,YT) = {(xt, yt)}t∈T, so
that D = DC ∪ DT . The task is to learn the neural processes pθ that fits the stochastic processes
2
Under review as a conference paper at ICLR 2022
f 〜P given DC when C 〜Pn is a randomly chosen subset of [n], as follows:
θ?
argmin Ef〜P R〜p” [ - logpθ(Y|X, DC)口 .
(1)
This meta-learning framework allows pθ to learn diverse patterns in F via a prior distribution P ;
hence np can predict target points conditioned on contexts adaptively in the inference phase.
2.2	(Bootstrapping) Attentive Neural Processes
ANP anp is a variant of np equipped with attention modules in the encoder part. See Appendix
A for the detailed definition of attention operations. Let the context DC is given, and the model
aims to infer y for a given feature x ∈ X. The encoder network of anp maps (x, DC) into a pair of
representation vectors r = (z, h) as follows:
{sjc∈c = SelfAttn(DC), SC = mean({sj°∈c), Z 〜N(z∣μz(sc), σ2(s°))	⑵
{hc}c∈C = SelfAttn(DC),	h = CrossAttn(x, XC, {hc}c∈C)	(3)
Here, μz and σz are single linear layers that map SC to mean and standard deviation of the latent
variable Z, respectively. In anp, Z and h refer to latent path and deterministic path, respectively. The
deterministic path models the overall skeleton of the encoder network, while the latent path models the
functional uncertainty using a stochastic global latent variable (Garnelo et al., 2018b; Kim et al., 2018).
Then the decoder network takes the representations r and target data X as inputs to predict μ(χ, r)
and σ(x, r), the parameters of the conditional predictive distribution p(y∣x, DC) = N (y∖μ, σ2).
BANP The global latent variable in anp potentially limits the flexibility in expressing functional
uncertainty. banp proposes a method that utilizes paired bootstrapping and residual bootstrapping
to model stochasticity in a data-driven way. First, they resample pairs of (xc, yc) with replacement
to construct DCb) = (XCb) ,YC(b)). Here b = 1,...,B implies the number of bootstrap samples. The
resampled context is encoded into the representation vector r(b) = (Z㈤，h⑹)by replacing DC
(b)
in (2) and (3) by DC . Then banp conducts the residual bootstrapping to construct bootstrapped
contexts again DCb) = (XCb),Y(b)). By using DC and DCb) in (2) and (3) separately, BANP gets the
representations of contexts (r, r(b)). Finally, BANP uses an adaptation layer to merge (r, Kb)) and
obtain μ(b),σ(b) through the decoder network (see Figure 2).
1B
p(y∖χ,r,r(b)) = N(y∖μ(b), (σ(b))2), p(y∖χ,Dc) ≈ BEp(y∖χ,r,r(b)).	(4)
b=1
Due to the residual bootstrapping, banp conducts the encoder computation three times and the
decoder computation twice for a single forward propagation. These additional calculations cause the
computational bottleneck in the training and inference (see Appendix B.6).
2.3	Neural Bootstrapper
Repetitions of training restrain the practical use of bootstrap procedures in deep neural networks due
to their high computational burden. To alleviate this, Shin et al. (2021) proposes Neural Bootstrapper
(NeuBoots). NeuBoots circumvents multiple training of networks by learning a bootstrap generator.
Random Weight Bootstrapping Let 52c∈c '(f (Xc),yc) be the loss function of interest for a
neural network f . In standard bootstrap procedures, a bootstrapped neural network can be obtained
by minimizing the loss function weighted by a random bootstrap weight wC := {wc : c ∈ C}:
L(wc,f,Dc) = Ewc'(f(xc),yc).
(5)
c∈C
According to the choice of the distribution on wC , various bootstrap procedures can be represented
under the form of (5); e.g., the paired bootstrap by WC 〜MUltinomial(n; 1/n,..., 1/n) and the
Random Weight Bootstrapping (RWB) (Præstgaɑrd & Wellner, 1993; Newton & Raftery, 1994)
by WC 〜∖C∖ × DiriChlet(1,..., 1). NeuBoots utilizes RWB to avoid the data discard problem
which can occur in the standard bootstrapping. We then compute bootstrapped neural networks
{fb(b) : b = 1, . . . , B} via minimization of (5) for sampled WC(1), . . . , WC* * * (B).
3
Under review as a conference paper at ICLR 2022
Learning To Generate Bootstrap Distribution The main idea of NeuBoots is to construct a single
generative network that models the bootstrapped neural networks with varying bootstrap weights in
(5). This formulation modifies the backbone network in a form of f(x, wC) that inputs both feature x
and bootstrap weight wC. Shin et al. (2021) show that the minimizer of the following loss generates
valid bootstrap evaluations that match the results of the standard bootstrap procedure:
L(f, DC) = EWC〜∣C∣×Dirichlet(1,…,1) [L(wC,f (∙, WC), DC))] ,
We call this weighted bootstrapping loss. Once this generator is trained via a single optimization
procedure, we can efficiently generate bootstrapped predictions by plugging random bootstrap weights
in the trained generator; i.e., for a feature of interest x, the trained generator inputs {WC(b)}bB=1 and
produces bootstrapped predictions y(b) = f(χ, WCb)) for b = 1,...,B.
3	Neural B ootstrapping Attentive Neural Processes
We propose a novel class of np, called Neural Bootstrapping Attentive Neural Processes (neubanp).
Aligned with the previous formulation of NP families, we can define our model pθ as:
Pθ (Y |X, DC)
n
∕pr(Y∣X, h, z)q(z∣DC)dz = / Ypψ(yi∖xi, h, z)q(z∣DC)dz
i=1
n
≈ Y[pφ(yi∖xi, h, z) where Z 〜q(z∣DC).
i=1
(6)
(7)
Here PW is the decoder and q denotes the posterior distribution. Since the above integral is intractable,
we approximate the predictive distribution by sampling Z from the bootstrap distribution q(∙∣DC), in-
stead of Gaussian distribution as in (A)NP. Precisely, we train a generative encoder network gφ, which
outputs bootstrapped representation pairs (h, z) = {(h(b), z(b))}bB=1 = gφ (X, DC, {W(Cb)}bB=1).
Through the meta-learning framework (1), our model learns to generate bootstrapped predictions
for an arbitrarily given function f 〜 P. Thus, our approach can be regarded as a learn-to-bootstrap
method for stochastic processes. Compared to the fixed bootstrap method used in banp, our learnable
bootstrap method can find the best strategy to appropriately generate the random functions regarding
the given context and the general property of the underlying data generating process. This will lead
to the better modeling of functional uncertainty of the target stochastic processes. Also, note that
neubanp can obtain a number of bootstrapped predictions by simply plugging different bootstrap
weights into gφ, while BANP needs repetitive data resampling from scratch. Figure 2 shows the
difference between the forward computation paths of banp and neubanp in detail.
3.1	Neural Bootstrapping Contexts with Attention Modules
To train a generative network, which outputs the bootstrapped representations, we modify the encoder
in anp to take both (x, DC) and bootstrap weight WC as inputs. We introduce the posterior and
the prediction paths in the encoder, analogous to np’s latent and deterministic paths. neubanp is
designed to leverage RWB, which is theoretically proven as a valid bootstrap method. In detail, the
posterior and prediction path in neubanp take the random bootstrap weight as an auxiliary input.
This input provides enough randomness into the network so that our model can successfully capture
the functional uncertainty.
Posterior path We tag each context (xc , yc ) ∈ DC with a bootstrap weight wc(b) to construct
bootstrapped contexts DC(b) := {(xc, yc, wc(b))}c∈C. Then the posterior path receives DC(b) as input
and outputs a latent variable z(b). In detail, we apply self-attention to DC(b) and multiply the resultant
representation z(Cb) by the bootstrap weight WC(b) before mean aggregation. This path connects the con-
texts with weighted bootstrapping loss during the training and allows the bootstrap weights to model
bootstrapped posterior distribution q by controlling the magnitude of each context representation.
Prediction path The prediction path outputs a target-specific representation h(b) that is relevant
for the prediction. We apply self-attention to contexts DC and multiply the bootstrap weight W(Cb)
4
Under review as a conference paper at ICLR 2022
Fig. 2. A single forward computation of (a) BANP and (b) NeUBANP. Note that the inference for each target point
requires B times of this forward computation.
element-wisely to compute another bootstrapped representation. Cross-attention module uses XC and
this bootstrapped representation as key-value pairs to which the target query x attends. Consequently,
reflecting the bootstrap weights shared with the posterior path, the prediction path models interactions
between the given context and the target input.
We summarize the above posterior and prediction paths as follows:
z(Cb) = {zc(b)}c∈C = SelfAttn(DC(b)), z(b) = mean(z(Cb) wC(b))	(8)
hC = {hc}c∈C = SelfAttn(DC), h(b) = CrossAttn(x, XC , hC wC(b) )	(9)
where denotes element-wise multiplication. We concatenate random bootstrap weights to context
data, unlike NeuBoots, which only utilizes random weight multiplication in the final layer. Concatena-
tion of weights and the contexts in the posterior path yields two effects. First, concatenating random
information in given contexts provides sufficient randomness to the model, allowing it to cover a
wide range of function samples in a space where a true function is likely to exist. Second, we made
this modification to maximize the use of random weights and provide bootstrapping information
to the model without resampling the data, enabling better uncertainty estimation. Additionally, by
multiplying the random weights to the representations from both paths, as in (8) and (9), the repre-
sentations are consistent with the weights and maximize bootstrapping effect. We think that these
multiplications also provide the effect of regularization, which mitigates the overfitting tendency
which anp and banp show in a simple regression experiment (see Figure 1).
Decoder and Bootsrapped Prediction The decoder takes (z(b), h(b)) from the encoder and target
X ∈ X as inputs to generate a prediction y(b) = MLP(χ, z(b), h(b)). We can generate bootstrap sam-
ples y(1),y(2),..., y(B) by plugging Wg), w(2),…,WCB) into the encoder gφ(χ, De, ∙), respectively.
We estimate the predictive mean and standard deviation using bootstrap samples:
1 B	^^1	B
μ = B X y(b),	σ = tB-1 XW	(10)
b=1	b=1
In the previous np methods, the decoder directly outputs the parameters of the predictive distribution,
but the decoder of NeUBANP outputs the stochastic predictions {y(b)}B=ι∙ This design of output is
a distinction of our model from other np methods and allows the nonparametric estimation. Due
to this structure, existing nps set the lower bound of standard deviation for robust performance.
5
Under review as a conference paper at ICLR 2022
We found that the performance was susceptible to the lower bound value. However, neubanp
naturally obtains parameters of predictive distribution using bootstrap predictions and shows better
performance without such heuristics. It also has the advantage of calculating higher-order statistics
without changing the structure.
3.2	Training
Weighted Bootstrapping Loss We train neubanp with weighted loss similar to that of NeuBoots
as demonstrated in Section 2.3. Only context data has the corresponding bootstrap weight in our
setting, but the model still has to fit target data. Thus we designed loss function as a sum of weighted
context loss Lcontext and non-weighted target loss Ltarget as follows:
Ltotal
Lcontext
log N (yc lμc, σ2D + ∣Tη X ( - log N(yt∖μt, σ2 D
|T| t∈T
-----------------} X-----------------------------}
(11)
Ltarget
where μc, σc, μt, and σt are computed by (10) for context (xc, yj ∈ DC and target (xt, yt) ∈ DT.
Averaging weighted context loss with multiple bootstrap weights improves the robustness of a
model by showing various bootstrap samples during training. We trained the model with negative
log-likelihood (nll). One can replace the nll with a different loss function, such as cross-entropy
according to the target tasks.
4	Experiments
We conducted experiments to compare neubanp with the previous np methods for regression
and sequential decision-making problems. For regression tasks, we conducted one-dimensional
(1D) regression experiments on random functions generated from gp prior and image completion
tasks as two-dimensional (2D) regression (see Appendix B.5 for image completion). For sequential
decision-making problems, we evaluated each method in Bayesian optimization (b o) and Contextual
Multi-Armed Bandit (cmab).
4.1	Nonparametric Regression and Uncertainty Estimation
Settings We followed the settings in Lee et al. (2020). To obtain meta-training datasets, we sampled
batches of random functions from gp prior with RBF kernel, and context and target points were
chosen randomly from each function. In addition, kernel parameters of gp were randomly sampled so
that the models could learn about various functions. neubanp was trained with 10 bootstrap samples,
and we confirmed that it is robust to the number of samples. Please refer to Appendix B.2 for details.
Results The numerical results are summarized in Table 2. anp and banp tend to estimate homo-
geneous uncertainties for all target points in a situation where context points are sufficiently given
(see Figure 3), because they place the heuristic lower bound on the variance. In the case of banp,
homoscedasticity occurs even when the number of context is small. Another problem only occurs in
banp, which is that it does not properly estimate functional uncertainty. Since the uncertainty about
the shape of the true function is high in the region where the context point is not given, models should
generate a wide range of function samples. However, we can see that banp generates almost the same
functions, not like those of the other methods, so we argue that banp is not an appropriate method
for modeling functional uncertainty. neubanp resolves these problems efficiently and achieves the
best performance except for target prediction in the Periodic kernel.
4.2	Bayesian Optimization
Since np can approximate a class of arbitrary functions, it can replace gp, the commonly used
surrogate model of bo. It is crucial to approximate the objective function from the given observations
using the surrogate model, but evaluating the acquisition function and determining the subsequent
samples are vital for efficient exploration. We evaluated the proposed method on various black-box
functions, which may be unobserved in the meta-training step (see Algorithm 1).
6
Under review as a conference paper at ICLR 2022
Fig. 3. Comparison of anp, banp, and neubanp in 1D regression given 4 context points (top) and 20 context
points (bottom). Orange lines represent the ground-truth function. Blue lines are predictive mean given by each
model and shaded region denotes the standard deviation (amount of uncertainty). To visualize the quality of
functional uncertainty, we overlapped multiple shaded areas obtained with 30 sampled outputs for each input.
Settings For 1D, we followed the same setting in Lee et al. (2020). We set objective functions gen-
erated from GP With RBF, Matern 5/2, and Periodic kernels and applied the models trained in Section
4.1. Furthermore, we demonstrated the b o performance of neubanp for multi-dimensional settings
(2D and 3D). We set objective functions as various benchmark functions used in the optimization
literature (Kim, 2020; Kim & Choi, 2017). See Appendix B.3 for details. A simple regret measured
the performance of each model, and the mean performance over 100 experiments is reported for
reliable evaluations.
2D MiChaIeWiCZ________	________Time COmPleXity
2D ACkley
2D DrOPWaVe
Fig. 4. Left: Multi-dimensional Bayesian optimization results on various benchmark functions with ucb as an
acquisition function. Bold lines represent the mean performance over 100 experiments. We indicate 20% of the
standard deviation. Right most: Time complexity of each model as the number of observations increases.
Results neubanp outperformed the other methods in bo experiments (see Figure 4 and 8). Table
3 and 4 shows numerical results. For multi-dimensional bo, neubanp achieved the best results for
every function except the Hartmann-3D when using Upper Confidence Bound (ucb) as an acquisition
function. For the Hartmann-3D, the performance of neubanp is statistically comparable to the best
method (anp) when considering the standard deviation. For Goldsteinprice and Rastrigin functions,
gp records poor performance due to its numerical errors during the optimization procedure (see
Appendix B.3). The rightmost plots of Figure 4 show the time complexity according to the number
of observation points. neubanp has the fastest decreasing rate of regrets in terms of iterations
in both cases. We also conducted bo experiments using Expected Improvement (ei) to test the
performance of neubanp to be independent of the selection of acquisition functions (Figure 9).
Figure 10 demonstrates the better exploration strategy of neubanp compared to banp. The second
7
Under review as a conference paper at ICLR 2022
Regret	Method	δ = 0.5	δ = 0.7	δ = 0.9	δ= 0.95	δ=0.99
	Uniform	100.00 ± 0.08	100.00 ± 0.09	100.00 ± 0.25	100.00 ± 0.37	100.00 ± 0.78
	Neural Linear	0.95 ± 0.02	1.60 ± 0.03	4.65 ± 0.18	9.56 ± 0.36	49.63 ± 2.41
	MAML	2.95 ± 0.12	3.11 ± 0.16	4.84 ± 0.22	7.01 ± 0.33	22.93 ± 1.57
Cumulative	NP	1.60 ± 0.06	1.75 ± 0.05	3.31 ± 0.10	5.71 ± 0.24	22.13 ± 1.23
	ANP	2.17 ± 1.89	3.59 ± 8.03	5.63 ± 8.48	11.68 ± 8.97	24.75 ± 7.08
	BANP	2.04 ± 1.52	2.34 ± 1.23	4.30 ± 0.77	6.76 ± 1.03	21.18 ± 1.69
	neubanp	0.85 ± 0.22	1.02 ± 0.27	1.85 ± 0.56	3.04 ± 0.88	9.76 ± 1.93
	Uniform	100.00 ± 0.45	100.00 ± 0.78	100.00 ± 1.18	100.00 ± 2.21	100.00 ± 4.21
	Neural Linear	0.33 ± 0.04	0.79± 0.07	2.17 ± 0.14	4.08 ± 0.20	35.89 ± 2.98
	MAML	2.49 ± 0.12	3.00 ± 0.35	4.75 ± 0.48	7.10 ± 0.77	22.89 ± 1.41
Simple	NP	1.04 ± 0.06	1.26 ± 0.21	2.90 ± 0.35	5.45 ± 0.47	21.45 ± 1.3
	ANP	0.99 ± 1.68	1.50 ± 2.21	3.64 ± 4.71	6.32 ± 7.33	21.65 ± 1.72
	BANP	1.22 ± 1.83	2.37 ± 3.04	3.27 ± 5.33	7.73 ± 12.16	20.63 ± 34.21
	neubanp	0.86 ± 0.06	1.04 ± 0.08	1.88 ± 0.14	3.09 ± 0.23	9.96 ± 0.70
Table 1. Results of the wheel bandit problem according to the value of δ. Mean and standard deviation for
cumulative regret and simple regret over 50 runs are reported. Regrets are normalized to that of the uniform
policy.
and fourth columns show the explored points by banp and neubanp, respectively. In most cases,
neubanp converged to the optimum faster than banp. The third and fifth column shows the contour
plots of acquisition functions of each method. Note that neubanp accurately infers the potential
area of the optimum compared to banp. As explained above, neubanp can estimate heterogeneous
uncertainty, and thus it is able to handle well for the exploration-exploitation trade-off, which is
essential in sequential decision-making problems.
4.3	Contextual Multi-Armed Bandit
We conducted a cmab experiment, the wheel bandit problem, as in Garnelo et al. (2018b) to show
that neubanp works efficiently as well as bo based on its performance of uncertainty estimation.
Settings We followed the same environment in Garnelo et al. (2018b), but used ucb policy. For
more details, please refer to Appendix B.4. The parameter δ determines the environment of the
wheel bandit problem. As δ increases, high-reward observation becomes sparse, which makes the
problem more difficult. We set the baselines of cmab experiment to maml (Finn et al., 2017), Neural
Linear (Riquelme et al., 2018) and np. We measured cumulative regrets and simple regrets for 2,000
iterations to demonstrate the performance of each model.
Results neubanp performed well for various δ values (see Table 1). Note that neubanp showed
better performance in challenging environments with sparse high rewards. neubanp showed the
ability to learn various reward distributions based on appropriate functional uncertainty modeling.
The result demonstrates that neubanp can utilize a small number of context information and make
accurate estimations. neubanp also has stable results as its small variance shows. On the other hand,
anp has extremely high variance in the performance because it overfits to certain prediction and
failed to adapt to the various bandit environments.
5	Related Work
Neural Processes cnp (Garnelo et al., 2018a) uses a pair of encoder and decoder networks to
produce a predictive posterior distribution over functions. np (Garnelo et al., 2018b) introduces a
global latent variable to embed functional uncertainty in the deterministic architecture of cnp and
predicts various outputs given the same context data. anp (Kim et al., 2018) then enhances predictive
accuracy by replacing mlp modules in np with the attention modules. bnp (Lee et al., 2020) proposes
the bootstrap method to model uncertainty in stochastic processes without the assumption of a single
latent variable on which previous methods rely. In addition to these works, there are many attempts
to use nps in various tasks. Singh et al. (2019) tackles sequential stochastic processes, where the
8
Under review as a conference paper at ICLR 2022
dynamics of the given system changes as the time being. Leveraging time-variant context points,
Singh et al. (2019) models the underlying temporal 3D structures. Gordon et al. (2020) extends NP
families to contain translation equivariant functions, providing theoretical formulation to represent
translation-invariant functional representations. Louizos et al. (2019) do not assume explicit global
latent variables, instead supported by dependency graph among local latent variables, to encode
inductive bias for given data easier than nps that use global latent variables.
Bootstrapping Neural Networks Bootstrap method (Efron, 1987) is a reliable approach to esti-
mate predictive uncertainty (Lakshminarayanan et al., 2017; Osband et al., 2016). However, it is
computationally inefficient to go through the feed-forward computation as much as the number of
bootstraps; hence, it discourages the practical application of bootstrap in neural networks. There have
been several works to circumvent this issue by approximating bootstrapped distribution. Amortized
bootstrap (Nalisnick & Smyth, 2017) approximates bootstrap distribution over model parameters
by using amortized inference and implicit models. Generative Bootstrap Sampler (Shin et al., 2020)
proposes a computational bootstrap procedure that constructs a generator function of bootstrap evalu-
ations for classical statistical models. Neural Bootstrapper (Shin et al., 2021) suggests a simple recipe
for generating bootstrapped predictive distributions of mlps and convolutional neural networks.
Meta-Learning based Stochastic Optimization nps are trained with a meta-learning framework
to solve various tasks related to the data generation process through a single optimization. Santoro
et al. (2016); Chen et al. (2017) follow the same training procedure of np. However, Santoro et al.
(2016) proposes an memory-augmented network for robust meta-learning, while Chen et al. (2017)
proposes the method to produce an algorithm for black-box optimization using recurrent networks.
Sharaf & Daume In (2019) presents a meta-learning algorithm for learning a good exploration policy
in the contextual bandit. Ravi & Beatson (2019) also solves contextual bandits based on the Bayesian
framework by inferring a posterior on weights of neural networks. Galashov et al. (2019) introduces
a unified framework for applying np to a wide range of sequential decision-making problems.
6	Conclusion
We have proposed neubanp, a novel bootstrap method for a family of np to model functional
uncertainty appropriately. Instead of the standard bootstrap, neubanp learns to construct a generator
function that produces valid bootstrapped distribution without resampling which can be considered as
a learn-to-bootstrap method. neubanp successfully worked in a meta-learning framework, providing
diverse trajectories of underlying data-generating processes, consistent to any given context. In
addition, neubanp estimates the local uncertainty accurately, resolving overfitted prediction and
variance overestimation problems observed in both anp and banp. We replace the additional layer
and repetitive computations in banp with the simple attachment of bootstrap weights to the model,
which leads to lower computations and smaller memory. neubanp shows superior performance to
previous np methods in regression and stochastic optimization tasks, including multi-dimensional
setting, which has been the desired application of np. However, due to the numerical instability of gp,
there is a limit in sampling high-dimensional stochastic processes for the meta-learning framework.
We suggest that this is a primary task for scalable applications of np in stochastic optimization, as a
challenging research direction.
7	Reproducibility
For reproducibility of experimental results, we provide a link to anonymous github that contains
our source code in Appendix B. The source code includes the implementation of our model, data
generation, and experiments. Additionally, the data generation steps are thoroughly explained in
Appendix B.
References
Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E. Hinton. Layer normalization, 2016.
9
Under review as a conference paper at ICLR 2022
Maximilian Balandat, Brian Karrer, Daniel R. Jiang, Samuel Daulton, Benjamin Letham, Andrew Gor-
don Wilson, and Eytan Bakshy. Botorch: A framework for efficient Monte-Carlo bayesian opti-
mization. In Advances in Neural Information Processing Systems, 2020.
Yutian Chen, Matthew W. Hoffman, Sergio G6mez Colmenarejo, Misha DeniL Timothy P Lillicrap,
Matt Botvinick, and Nando de Freitas. Learning to learn without gradient descent by gradient
descent. In International Conference on Machine Learning, pp. 748-756. PMLR, 2017.
Gregory Cohen, Saeed Afshar, Jonathan Tapson, and Andre van Schaik. Emnist: Extending MNIST
to handwritten letters. In International Joint Conference on Neural Networks, pp. 2921-2926.
IEEE, 2017.
Bradley Efron. Better bootstrap confidence intervals. Journal of the American statistical Association,
82(397):171-185, 1987.
Chelsea Finn, Pieter Abbeel, and Sergey Levine. Model-agnostic meta-learning for fast adaptation of
deep networks. In International Conference on Machine Learning, pp. 1126-1135. PMLR, 2017.
Alexandre Galashov, Jonathan Schwarz, Hyunjik Kim, Marta Garnelo, David Saxton, Pushmeet
Kohli, S.M. Ali Eslami, and Yee Whye Teh. Meta-learning surrogate models for sequential decision
making. arXiv preprint arXiv:1903.11907, 2019.
Jacob Gardner, Geoff Pleiss, Kilian Q. Weinberger, David Bindel, and Andrew Gordon Wilson.
Gpytorch: Blackbox matrix-matrix gaussian process inference with gpu acceleration. In Advances
in Neural Information Processing Systems, volume 31, pp. 7576-7586, 2018.
Marta Garnelo, Dan Rosenbaum, Christopher Maddison, Tiago Ramalho, David Saxton, Murray
Shanahan, Yee Whye Teh, Danilo Rezende, and S.M. Ali Eslami. Conditional neural processes. In
International Conference on Machine Learning, pp. 1704-1713. PMLR, 2018a.
Marta Garnelo, Jonathan Schwarz, Dan Rosenbaum, Fabio Viola, Danilo J Rezende, SM Eslami, and
Yee Whye Teh. Neural processes. arXiv preprint arXiv:1807.01622, 2018b.
Jonathan Gordon, Wessel P. Bruinsma, Andrew Y. K. Foong, James Requeima, Yann Dubois, and
Richard E. Turner. Convolutional conditional neural processes, 2020.
Hyunjik Kim, Andriy Mnih, Jonathan Schwarz, Marta Garnelo, Ali Eslami, Dan Rosenbaum, Oriol
Vinyals, and Yee Whye Teh. Attentive neural processes. In International Conference on Learning
Representations, 2018.
Jungtaek Kim. Benchmark functions for bayesian optimization. https://github.com/
jungtaekkim/bayeso-benchmarks, 2020.
Jungtaek Kim and Seungjin Choi. BayesO: A Bayesian optimization framework in Python. https:
//bayeso.org, 2017.
Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In International
Conference on Learning Representations (Poster), 2015.
Balaji Lakshminarayanan, Alexander Pritzel, and Charles Blundell. Simple and scalable predictive
uncertainty estimation using deep ensembles. In Advances in Neural Information Processing
Systems, 2017.
Tuan Anh Le, Hyunjik Kim, Marta Garnelo, Dan Rosenbaum, Jonathan Schwarz, and Yee Whye Teh.
Empirical evaluation of neural process objectives. In Advances in Neural Information Processing
Systems Workshop on Bayesian Deep Learning, 2018.
Juho Lee, Yoonho Lee, Jungtaek Kim, Eunho Yang, Sung Ju Hwang, and Yee Whye Teh. Bootstrap-
ping neural processes. In Advances in Neural Information Processing Systems, 2020.
Ziwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou Tang. Deep learning face attributes in the wild. In
International Conference on Computer Vision, pp. 3730-3738, 2015.
Christos Louizos, Xiahan Shi, Klamer Schutte, and Max Welling. The functional neural process.
arXiv preprint arXiv:1906.08324, 2019.
10
Under review as a conference paper at ICLR 2022
Eric Nalisnick and Padhraic Smyth. The amortized bootstrap. In International Conference on
Machine Learning 2017 Workshop on Implicit Models, 2017.
Michael A. Newton and Adrian E. Raftery. Approximate Bayesian inference with the weighted
likelihood bootstrap. Journal of the Royal Statistical Society: Series B (Methodological), 56(1):
3-26,1994.
Ian Osband, Charles Blundell, Alexander Pritzel, and Benjamin Van Roy. Deep exploration via
bootstrapped DQN. arXiv preprint arXiv:1602.04621, 2016.
Jens præstgaard and Jon A Wellner. Exchangeably weighted bootstraps of the general empirical
process. The Annals of Probability, pp. 2053-2086, 1993.
Carl Edward Rasmussen. Gaussian processes in machine learning. In Summer School on Machine
Learning, pp. 63-71. Springer, 2003.
Sachin Ravi and Alex Beatson. Amortized bayesian meta-learning. In International Conference on
Learning Representations, 2019.
Carlos Riquelme, George Tucker, and Jasper Snoek. Deep bayesian bandits showdown: An empirical
comparison of bayesian deep networks for thompson sampling. In International Conference on
Learning Representations, 2018.
Adam Santoro, Sergey Bartunov, Matthew Botvinick, Daan Wierstra, and Timothy Lillicrap. Meta-
learning with memory-augmented neural networks. In International Conference on Machine
Learning, pp. 1842-1850. PMLR, 2016.
Amr Sharaf and Hal DaUme III. Meta-Iearning for contextual bandit exploration. arXiv preprint
arXiv:1901.08159, 2019.
Minsuk Shin, Lu Wang, and Jun S Liu. Scalable uncertainty quantification via generativebootstrap
sampler. arXiv preprint arXiv:2006.00767, 2020.
Minsuk Shin, Hyungjoo Cho, Hyun-seok Min, and Sungbin Lim. Neural bootstrapper. In Advances
in Neural Information Processing Systems, 2021.
Gautam Singh, Jaesik Yoon, Youngsung Son, and Sungjin Ahn. Sequential neural processes. In
Advances in Neural Information Processing Systems, volume 32, 2019.
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz
Kaiser, and Illia Polosukhin. Attention is all you need. In Advances in Neural Information
Processing Systems, 2017.
A Model
A. 1 Basic Operation
Muti-Layer Perceptron MLP (di, dh, do, nl) denotes the multi-layer perceptron consisting of nl
linear transformations and ReLU activations between them. Let parameters di , dh , do the dimension
of input, hidden and output feature, repectively. We used same dh for every hidden layers. Lin(p, q)
denotes the linear transformation of input with feature dimension p into output with feature dimension
q.
MLP(di, dh,do, nl)(X) = Lin(dh, do) ◦ (ReLU ◦ Lin(dh, dh))nl-2 ◦ ReLU ◦ Lin(di, dh)(X)
(12)
Dot Product Attention DotProdAttn (Vaswani et al., 2017) denotes the attention operation with
attention score based on cosine similarity. Dot product of query (Q) and key (K) tensors calculates
the similarity of each vectors in query tensor relative to each vectors in key tensor. Attention score is
calculated through softmax operation of normalized similiarity. Let dk the feature dimension of key
and query tensors, and dv that of value tensors.
DotProdAttn(Q, K, V) = Softmax(QTK/Pdk)V	(13)
11
Under review as a conference paper at ICLR 2022
Multi-Head Attention MHA denotes multi-head attention with dot product attention. The input is
pre-processed with MLP and the output of attention is post-processed with layer normalization. For
simplicity, we omit parameters of each MLP layers. split(X, n) denotes splitting of tensor X with
respect to feature axis into a tuple of n tensors (Xi0)in=1 which have same dimension in feature axis.
[X1, X2, ..., Xn] denotes the concatenation of tensors X1, X2, ..., Xn with respect to feature axis.
LayerNorm denotes the layer normalization introduced in Ba et al. (2016). Let nhead the number of
heads in multi-head attention.
(Q0i)in=h1ead = split(MLPqk(Q), nhead)	(14)
(Ki0)in=he1ad = split(MLPqk(K), nhead)	(15)
(Vi0)in=he1ad = split(MLPv(V), nhead)	(16)
MHA(Q, K, V) = LayerNorm([(DotProdAttn(Q0i,Ki0,Vi0))in=he1ad])	(17)
Self-Attention We used self-attention to calculate efficient representations of context DC =
(XC , YC ). We define self-attention based on multi-head attention as follows:
DC0 = [XC,YC] = ([xc,yc])c∈C, SelfAttn(DC) :=MHA(DC0,DC0,DC0)	(18)
Cross-Attention We used cross-attention to calculate representation of context specific to target
feature x in interest, when original representations (hc)c∈C is given. We define cross-attention based
on multi-head attention as follows:
CrossAttn(x, XC, (hc)c∈C) := MHA(x, XC, [(hc)c∈C]).	(19)
A.2 Architecture
For fair comparison, we used the same architecture of all models as in Lee et al. (2020). For neubanp,
we increased the input dimension of SelfAttn in the posterior path by one to take bootstrap weight as
additional input. Please refer to Lee et al. (2020) for detailed model architecture of anp and banp.
A.3 Non-attentive Case
As an ablation study, we consider the non-attentive case of neubanp, called Neural Bootstrapping
Neural Processes (neubnp). Like the architecture of neubanp is based on anp, the architecture of
this model is based on NP, the non-attentive counterpart of ANP. With DC(b) = {(xc, yc, wc(b) }c∈C as
defined in 3, we applied the similar strategy of using random weights in the encoder as follows, and
trained with the same loss function:
z(Cb) = {zc(b) }c∈C = MLP(DC(b) , z(b) = mean(z(Cb) w(Cb))	(20)
h(Cb) = {h(cb)}c∈C = MLP(DC(b), h(b) = mean(h(Cb) wC(b))	(21)
(22)
To make the non-attentive counterpart of neubanp, we use random weights in both paths, re-
suiting in two latent variables z(b), h(b). They induce randomness into the decoder output y(b) =
MLP(x, z(b), h(b)), and the predictive distribution is construct by (10). The results in Table 2 and
Table 3 shows that this model performs worse than neubanp, but outperforms bnp and np, showing
the quality of functional uncertainty the model learns with the bootstrap.
B Experiments
Implementation2 of nps other than neubanp was borrowed from the source code of Lee et al. (2020)3.
Regression and Bayesian optimization experiment was done in single GeForce RTX 2080 Ti GPU
with the memory of 11, 019 MiB. Multi-dimensional regression including image completion was
done in Tesla V100 GPU with the memory of 32, 480 MiB.
2https://anonymous.4open.science/r/neubanp_initial
3https://github.com/juho-lee/bnp, MIT License.
12
Under review as a conference paper at ICLR 2022
Fig. 5. Each plot shows predictions given by np, bnp in a linear regression. The ground-truth function is
a simple linear function with heterogeneous variance: y = X + β6(x) where e(x) 〜N(0,σ2(x)) and
σ(x) = √x2 + 10-5. We used the official code provided by Lee et al. (2020). Unlike the case of ANP and
banp, considering that overfitting does not occur in np and bnp, we can notice that attention modules are the
leading cause of overfitting.
B.1	Simple Linear Regression
We experimented using a linear function rather than a function sampled from the gp to analyze
how well the np models work in a simple regression task. Additionally, we need to examine how
well the NP models predict uncertainty in the presence of heterogeneous noise in the data, and
We add C(X)〜N(0, σ2(x)), σ(x) = √x2 + 10-5 to the linear function. We multiplied the noise
by coefficient β to follow the meta-learning framework, and the β value was uniformly randomly
sampled from [0.1, 1.0] during training. In this task, np, bnp, and neubanp were able to estimate
the underlying true linear function and the uncertainty of heterogeneous noise. On the other hand, in
case of anp and banp, overfitting occurred and failed to predict the true function and its uncertainty
(see Figures 1 and 5). As explained in the main text, we can see that the overfitting phenomenon
occurs because of the attention mechanism that has appeared to solve the underfitting issue of the np.
neubanp has the advantage of the attention mechanism and achieved better performance through
regularization using random weights. For (a)np and b (a)np, we used the official code provided by
Lee et al. (2020). The remaining training settings are the same as the 1D regression in Appendix B.2,
and we changed only the training iteration to 10, 000.
B.2	1d Regression
Training For all models, training dataset consists of randomly sampled context and target from
functions following GP with RBF kernel k(x,y) = s2 ∙ exp(-∣∣x - y||2/⑵2)). Parameters of
kernel are randomly sampled with S 〜Uniform(0.1,1.0) and l 〜Uniform(0.1, 0.6). Feature values
(xi)i∈C∪T is chosen uniformly at random in [-2, 2]. The size of context and target are randomly
sampled with |C| 〜 Uniform(3,47) and |T| 〜 Uniform(3, 50 — |C|). We trained all models for
100,000 iterations and used Adam optimizer (Kingma & Ba, 2015). For stable learning, we used the
cosine annealing scheduler with initial learning rate 5 × 10-4.
Results Table 2 shows log-likelihood of nps for various evaluation dataset sampled from gp
with RBF, Matern 5/2, Periodic kernel. As in generation of training dataset, parameters of Matern
5/2 kernel k(x,y) = s2(1 + √5∣∣x — y||2/(3l2)) exp(-√5∣∣x — y||/l) and Periodic kernel
k(x,y) = s2 exp(—2sin2(π||x — y||2/p)/l2) was randomly sampled with S 〜 Uniform(0.1,1.0),
l 〜 Uniform(0.1, 0.6) and P 〜 Uniform(0.1, 0.5). For RBF and Matern 5/2 dataset, neubanp
showed state-of-the-art performance both in fitting context and predicting target. We added figures
showing the predictions of anp, banp, and neubanp for the Matern 5/2 and Periodic kernel (see
Figure 6 and 7). In the case of the Matern kernel, the two problems described in the main text
occurred identically for anp and banp (see Section 4.1). However, in the case of Periodic, we can
see that all models failed to approximate the true function correctly. This result came out because we
experimented with testing the models’ generalization performance when trained with the RBF kernel.
And the quantitative results in Table 2 show that the prediction performance of the attention-based
13
Under review as a conference paper at ICLR 2022
Method	RBF		Matern 5/2		Periodic	
	context	target	context	target	context	target
CNP	1.17 ± 0.08	0.87 ± 0.36	1.06 ± 0.11	0.65 ± 0.39	-0.31 ± 0.41	-2.05 ± 1.17
NP	1.11 ± 0.09	0.78 ± 1.47	0.99 ± 0.11	0.56 ± 0.50	-0.28 ± 0.37	-1.73 ± 1.09
ANP	1.38 ± 0.00	1.08 ± 0.41	1.38 ± 0.00	0.94 ± 0.47	0.21 ± 0.76	-6.82 ± 2.83
BNP	1.20 ± 0.07	0.92 ± 0.34	1.09 ± 0.09	0.72 ± 0.35	-0.18 ±037	-1.16 ± 0.56
BANP	1.38 ± 0.00	1.12±0.33	1.38 ± 0.00	0.99 ± 0.38	0.28 ± 0.69	-5.69 ± 2.37
NeuBNP	1.54 ± 0.20	1.01 ± 0.55	1.22±0.22	0.53 ± 0.59	-0.34 ± 0.45	-2.34 ± 1.95
NeuBANP	3.17 ± 0.28	1.38 ± 0.60	3.09 ± 0.29	1.13 ± 0.64	1.56 ± 0.73	-11.49 ± 8.08
Table 2. Log-Likelihood of nps for 48,000 different evaluations of context and target.
model on the target data is poor. Among them, neubanp has the worst performance, and we think the
reason is the lower bound on the predicted variance set by anp and banp. Quantitative results show
similar predictions for all models, but anp and banp achieve numerically more robust performance
by setting a lower bound on the variance. We find some cases with the jumps in the function values
which do not seem like a smooth function (See Figure 3, 6, and 7). This phenomena occurs in every
attentive models including anp, banp, and neubanp. It looks like a distorted prediction on particular
region, however, since our model predicts high variance in such region, this does not raise a problem
in predicting the global trend, as we can see in high average log likelihood in 1d regression.
Fig. 6. Comparison of ANP, BANP, and NeuBANP in 1D regression. Matern 5/2 kernel case.
Fig. 7. Comparison of anp, banp, and neubanp in 1D regression. Periodic kernel case.
B.3	Bayesian Optimization
One-dimensional case Table 3 shows the performance of gp and various nps for 1D Bayesian
optimization task. RBF, Matern 5/2, and Periodic kernels are used to generate evaluation dataset.
14
Under review as a conference paper at ICLR 2022
Algorithm 1: Neural Process based Bayesian Optimization.
Input : Target function f?; Acquisition function U ; Observed data D0 = {(x0 , f? (x0))};
Maximum evaluation step T .
ι Meta-train a neural process pθ on f 〜 P(F).
2	for t = 1, . . . , T do
3	Find Xt by optimizing acquisition function: Xt = argmin U (pθ (y |x, Dt-1))
x∈X
4	Evaluate f ?(Xt) and update the observed data: Dt — Dt-1 ∪ {(xt, f *(xt))}
RBF	Matern 5/2	Periodic
Fig. 8. 1D Bayesian optimization results. Bold lines shoW the mean of simple regrets over 100 experiments. We
also report 10% of the standard deviation.
2D Ackley	2D Dropwave	2D Michalewicz	Time complexity
Fig. 9. Left: Multi-dimensional Bayesian optimization results on various benchmark functions with ei as an
acquisition function. Bold lines represent the mean performance over 100 experiments. We indicate 20% of the
standard deviation. Right most: Time complexity of each model as the number of observations increases.
Multi-dimensional case In multi-dimensional BO experiments, we used GPyTorch 4 (Gardner
et al., 2018) for scalable GP regression, and BoTorch 5 (Balandat et al., 2020) for overall BO process
(e.g., optimization of acquisition functions). GP was set to the default setting of BoTorch. In detail,
GP model was parameterized With Matern 5/2 kernel With ARD and constant mean function, and
prior distribution for hyperparameters was set as Gamma(3, 6) for length scale l and Gamma(2, 0.15)
for output scale s. For three-dimensional B O experiment in Figure 4, the overall time complexity of
anp and banp is almost the same. This result is seemingly in contrast With the fact that anp takes a
shorter time for prediction than banp. HoWever, since the bo algorithm contains the optimization of
the acquisition function, the qualities of acquisition functions obtained by the model predictions may
affect the overall time complexity. We conjecture that banp gives an acquisition function easier to
optimize than that of anp so that the overall time complexities of both models are similar. Additionally,
We did not report the results of gp for the tWo functions. Specifically, We omitted the Goldstein-Price
4 https://github.com/cornellius- gp/gpytorch, MIT License.
5https://github.com/pytorch/botorch, MIT License.
15
Under review as a conference paper at ICLR 2022
Fig. 10. First column: 2D objective functions Second & Fourth columns: Contour plots of functions and the
evaluated points during Bayesian optimization. Third & Fifth columns: ucb value at the last iteration.
Method I	RBF	Matern 5/2	Periodic
GP (RBF)	0.016 ± 0.052	0.048 ± 0.206	0.104 ± 0.242
CNP	0.072 ± 0.188	0.081 ± 0.198	0.096 ± 0.166
NP	0.154 ± 0.273	0.187 ± 0.303	0.083 ± 0.121
ANP	0.209 ± 0.364	0.223 ± 0.328	0.107 ± 0.142
BNP	0.109±0.214	0.105 ± 0.188	0.071 ± 0.091
BANP	0.114 ± 0.216	0.136 ± 0.256	0.077 ± 0.11
NeuBNP	0.069 ± 0.169	0.125±0.238	0.058 ± 0.069
NeuBANP	0.006 ± 0.011	0.011 ± 0.055	0.028 ± 0.035
Table 3. 1D Bayesian optimization results. Mean and standard deviations of simple regrets over 100 runs are
reported.
since the simple regret value of gp was too large (the performance was poor) compared to other
models and omitted the Rastrigin since the 46 errors occurred out of 100 experiments. An error may
occur when ill-conditioned data is given during the kernel training process of the gp, and the data
recommended by the ucb during the exploration (or exploitation) process seems to correspond to
this condition. If we report the performance ignoring the numerical error, the simple regret for the
Goldstein-Price was 52049.13, and the simple regret for the Rastrigin was 18.48. For the Rastrigin
function, gp with ucb is numerically unstable, but like ei, it achieved the best performance.
B.4	Contextual Multi-Armed Bandit
Setting We followed wheel bandit setting introduced in Riquelme et al. (2018). At every step
t (< T), a two-dimensional point (xt, yt) inside the unit circle Runit = {(x, y) ∈ R2 : x2 + y2 ≤ 1}
is given as a context ct. The algorithm chooses an action at ∈ {1, 2, 3, 4, 5}. The stochastic reward
rt = r(at, ct) is sampled from the reward distribution. Let R1, R2, R3, R4, R5 ⊂ Runit the disjoint
16
Under review as a conference paper at ICLR 2022
						
Dim	Target	GP	ANP	BNP	BANP	neubanp
	Ackley	2.84 ± 1.82	0.19 ± 0.53	1.82 ± 1.03	0.50 ± 1.03	0.08 ± 0.27
2D	Dropwave	0.36 ± 0.17	0.22 ± 0.15	0.32 ± 0.18	0.28 ± 0.17	0.15 ± 0.10
	Goldsteinprice	-	475.52 ± 469.15	2098.22 ± 1509.88	80.67 ± 65.85	30.33 ± 25.42
	Michalewicz	0.67 ± 0.45	0.61 ± 0.40	1.00 ± 0.46	0.69 ± 0.38	0.45 ± 0.42
	Ackley	3.39 ± 1.25	5.36 ± 0.97	3.29 ± 1.11	4.30 ± 1.15	0.34 ± 0.26
3D	Cosine	0.04 ± 0.24	0.10 ± 0.10	1.12 ± 0.57	0.25 ± 0.43	0.005 ± 0.003
	Hartmann	0.42 ± 0.77	0.33 ± 0.50	1.94 ± 0.86	0.93 ± 0.98	0.39 ± 0.39
	Rastrigin	-	54.94 ± 19.84	48.55 ± 14.34	38.36 ± 8.20	23.06 ± 19.77
Table 4. Multi-dimensional Bayesian optimization results. Mean and standard deviations of simple regrets over
100 runs are reported.
sets (regions) of unit circle as follows:
R1 = {(x, y)	: x2 + y2 < δ}	(23)
R2 = {(x, y)	: δ ≤ x2 + y2 ≤ 1, x > 0, y > 0}	(24)
R3 = {(x, y)	: δ ≤ x2 + y2 ≤ 1, x < 0, y > 0}	(25)
R4 = {(x, y)	: δ ≤ x2 + y2 ≤ 1, x < 0, y < 0}	(26)
R5 = {(x, y)	: δ ≤ x2 + y2 ≤ 1, x > 0, y < 0}	(27)
where the constant δ determines the size of R1 relative to other regions. Each action results in rewards
following different distribution according to the region to which the given context belongs, where N
denotes the normal distribution.
r(1,c) ~N(1.2, 0.012)
r(a, C) ~
N (50, 0.012),
N(1, 0.012),
if c ∈ Ra
otherwise
∀a ∈ {2, 3, 4, 5}
(28)
(29)
Note that action {1} always produces a moderate reward, but the other actions {2, 3, 4, 5} sometimes
produce a very high reward when the context is sampled from the corresponding high-reward region.
Thus, learning different reward distributions for actions {2, 3, 4, 5} by apprehension of context
information is critical to bandit performance. As δ increases, the high-reward regions for each actions
become smaller. Then the model should learn from rare observation of such high reward, which
means the problem becomes more difficult.
Training and Evaluation When pre-training neubanp, as in Garnelo et al. (2018b), 8 training
batches of 512 contexts and 50 targets were generated from the environment with hyperparameter
randomly sampled; δ 〜Uniform(0,1). We consider two-dimensional context point Ci as feature
xi ∈ R2 and five rewards for actions (r(1, ci), r(2, ci), r(3, ci), r(4, ci), r(5, ci)) as label yi ∈ R5.
At evaluation, only rewards for chosen actions are observed by the model. Thus, we replace other
unobserved rewards with dummy values randomly sampled from N (0, 1), following the usual strategy.
B.5	Image Completion
Settings We compared the baseline nps and neubanp on image completion tasks. Following Lee
et al. (2020), we trained all models on EMNIST (Cohen et al., 2017) and CelebA (Liu et al., 2015)
which was resized to 32 × 32. For EMNIST, we used only 10 classes for training and reported
the evaluation results for both seen classes and unseen classes separately. neubanp was trained
with 10 samples, and the other baselines were trained with 4 samples. For evaluation, we used
50 samples for all methods. Similar to 1D regression experiment, we randomly select the pixels
of a given image as context/target, and the number of context/target were drawn randomly from
Uniform distribution. However, in this case, we increased the maximum number of given points;
i.e., |C| ~ UnifOrm(3,197), |T| ~ Uniform(3,200 - |C|). X values were rescaled to [-1,1] and
the corresponding y values were rescaled to [-0.5, 0.5]. We trained all models for 200 epochs and
set a initial learning rate of 5 × 10-4 using the Adam optimizer (Kingma & Ba, 2015) with cosine
annealing scheduler for learning rate decay.
17
Under review as a conference paper at ICLR 2022
Fig. 11. Qualitative result of EMNIST image comple-
tion.
Method	Seen classes (0-9)		Unseen classes (10-46)	
	context	target	context	target
CNP	0.926 ± 0.007	0.751 ± 0.005	0.766 ± 0.009	0.498 ± 0.012
NP	0.948 ± 0.006	0.806 ± 0.005	0.808 ± 0.005	0.600 ± 0.009
ANP	1.383 ± 0.000	0.993 ± 0.005	1.383 ± 0.000	0.894 ± 0.004
BNP	1.004 ± 0.008	0.880 ± 0.005	0.883 ± 0.010	0.722 ± 0.006
BANP	1.383 ± 0.000	1.010 ± 0.006	1.382 ± 0.000	0.942 ± 0.005
neubanp	1.475 ± 0.345	1.337 ± 0.224	1.333 ± 0.516	1.119 ± 0.388
Table 5. Quantitative result of EMNIST image comple-
tion. Mean and standard deviationd of likelihoood over
5 experiments.
Fig. 12. Qualitative result of CelebA image comple-
tion.
	context	target
CNP	2.975 ± 0.013	2.199 ± 0.003
NP	3.066 ± 0.0iι	2.492 ± 0.014
ANP	4.150 ± 0.000	2.731 ± 0.006
BNP	3.269 ± 0.008	2.788 ± 0.005
BANP	4.149 ± 0.000	3.129 ± 0.005
neubanp	13.946 ± 0.590	2.870 ± 0.021
Table 6. Quantitative result of CelebA results. Mean and
standard deviationd of likelihoood over 5 experiments.
Results Figure 11 and 12 show the mean prediction and uncertainty estimation of anp, banp,
and neubanp for test images in unseen classes. For both datasets, though our model shows noisy
mean prediction due to the random weights, we can demonstrate the advantage of neubanp in
uncertainty estimation. neubanp estimated the uncertainty correctly in the area where the color of
the pixel changes and thus possesses significant uncertainty. This leads to the overall improvement in
quantitative performance (see Table 5 and 6).
B.6	Time Complexity
Settings We measured the time complexity empirically according to the number of context points,
target points, and bootstrap samples. We fixed the number of targets to 25 and adjusted the number
of contexts to 10, 20, 30, 40, and 50 to see how inference time varies with the number of contexts.
Conversely, to see the inference time according to the number of targets, we fixed the number
of context points to 25. We fixed the number of bootstrap samples to 50 as in the 1D regression
experiment. When conducting experiments with the number of bootstrap samples, the number of
context and target points was fixed at 20 and 25. All experiments were conducted with a batch
containing 100 tasks.
Results banp places a remarkably high computational cost in that the approach of bootstrapping the
attention module is inefficient, as demonstrated in Figure 13. The inference time becomes noticeably
longer as the number of context points increases. neubanp, on the other hand, learns to bootstrap
efficiently; therefore, its time complexity is comparable to that of bnp, which does not use the
attention module.
Method	10	Number of contexts			50	10	Number of targets				Number of bootstrap samples		
		20	30	40			20	30	40	50	10	50	100
BNP	1.797	1.977	2.222	2.546	2.886	1.830	1.882	1.965	2.057	2.156	1.532	1.639	1.950
BANP	3.512	4.405	5.345	6.509	7.793	4.439	4.626	4.834	4.926	5.117	3.189	3.699	4.775
neubanp	1.632	1.813	2.217	2.757	3.369	1.768	1.941	2.063	2.212	2.357	1.606	1.705	2.149
Table 7. Inference time measurement. Mean of inference time over 5 runs are reported.
18
Under review as a conference paper at ICLR 2022
Fig. 13. Inference time measurement.
19