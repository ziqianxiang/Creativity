Under review as a conference paper at ICLR 2022
Improving Out-of-Distribution Robustness via
Selective Augmentation
Anonymous authors
Paper under double-blind review
Ab stract
Machine learning algorithms typically assume that training and test examples
are drawn from the same distribution. However, distribution shifts is a common
problem in real-world applications and can cause models to perform dramatically
worse at test time. In this paper, we specifically consider the problems of domain
shifts and subpopulation shifts, where learning invariant representations by align-
ing domain-specific representations or balancing the risks across domains with
regularizers are popular solutions. However, designing regularizers that are suit-
able for diverse real-world datasets is challenging. Instead, we shed new light on
addressing distribution shifts by directly eliminating domain-related spurious cor-
relations with augmentation, leading to a simple technique based on mixup, called
LISA (Learning Invariant Representations via Selective Augmentation). LISA se-
lectively interpolates samples either with the same labels but different domains or
with the same domain but different labels. Empirically, we study the effective-
ness of LISA on nine benchmarks ranging from subpopulation shifts to domain
shifts. The results indicate that LISA consistently outperforms other state-of-the-
art methods with superior invariant representations. The empirical findings are
further strengthened by our theoretical analysis.
1	Introduction
To deploy machine learning algorithms in real-world applications, we must pay attention to distri-
bution shifts, i.e. when the test distribution is different from the training distribution, which sub-
stantially degrades model performance. In this paper, we refer this problem as out-of-distribution
(OOD) generalization and specifically consider performance gaps caused by two kinds of distribu-
tion shifts: domain shifts and subpopulation shifts. In domain shifts, the test data is sampled from
different domains than the training data, which requires the trained model to generalize well to test
domains without seeing training data from those domains. Take health risk prediction as an exam-
ple. We may want to train a model on patients from a few sampled hospitals and then deploy the
model to a broader set of hospitals (Koh et al., 2021). In subpopulation shifts, the proportions of
subpopulations in the test distribution differ from the proportions in the training distribution. When
subpopulation shift occur, models perform poorly when they falsely rely on spurious correlations,
which may occur when some subpopulations are under-represented in the training set. For example,
in financial risk prediction, a machine learning model trained on the entire population may associate
the labels with demographic features (e.g., religion and race), making the model fail on the test set
when such an association does not hold in reality.
To improve model robustness under these two kinds of distribution shifts, methods for learning
invariant representations have shown effectiveness in various applications. These methods learn
features or prediction mechanisms that are invariant to different domains while still containing suf-
ficient information for the targeted task (Li et al., 2018; Arjovsky et al., 2019). Concretely, some
prior works learn invariant representations by aligning and regularizing the domain-specific repre-
sentations (Li et al., 2018; Sun & Saenko, 2016). Other works aim to find invariant representations
by balancing the risk across domains using regularizers (Arjovsky et al., 2019; Krueger et al., 2021;
Rosenfeld et al., 2021), which further increases the dependency between the invariant representa-
tions and labels. However, designing regularizers that are widely suitable to datasets from diverse
domains is especially challenging and insuitable regularizers may adversely limit the model’s ex-
pressive power, leading to inconsistent performance among various real-world datasets. For exam-
ple, on the WILDS datasets (Koh et al., 2021), invariant risk minimization (IRM) (Arjovsky et al.,
1
Under review as a conference paper at ICLR 2022
2019) outperforms empirical risk minimization (ERM) on CivilComments, but fails to improve ro-
bustness on a variety of other datasets like Camelyon17 and RxRx1. A similar phenomenon is also
reflected in the performance of CORAL (Sun & Saenko, 2016).
Instead of explicitly imposing regularization to learn invariant representations, we turn towards an
implicit solution. Inspired by mixup (Zhang et al., 2018), we aim to alleviate the effects of domain-
related spurious information through data interpolation, leading to a simple algorithm called LISA
(Learning Invariant Representations with Selective Augmentation). Concretely, LISA linearly in-
terpolates the features for a pair of samples and applies the same interpolation strategy on the cor-
responding labels. Critically, the pairs are selectively chosen according to two sample selection
strategies. In selection strategy I, LISA interpolates samples with the same label but from different
domains, aiming to eliminate domain-related spurious correlations. In selection strategy II, LISA
interpolates samples with the same domain but different labels, where the model should to ignore
the domain information and generate different predicted values as the interpolation ratio changes.
In this way, LISA encourages the model to learn domain-invariant predictors without explicitly con-
straining or regularizing the representation.
The primary contributions of this paper are as follows: (1) We develop a method that tackles the
problem of distribution shifts by canceling out the domain-related spurious correlations via data in-
terpolation. (2) We conduct broad empirical experiments to evaluate the effectiveness of LISA on
nine benchmark datasets from diverse domains. In these experiments, we make the following obser-
vations. First, we find that LISA consistently outperforms seven prior methods in addressing both
domain shifts and subpopulation shifts. Second, we identify that the performance gains of LISA are
indeed caused by canceling out domain-specific information and learning invariant representations,
rather than simply involving more data via interpolation. Third, when the degree of distribution shift
increases, LISA achieves more significant performance gains. (3) Finally, we provide theoretical
analysis of the phenomena distilled from the empirical studies, where we provably demonstrate that
LISA can achieve smaller worst-domain error compared with ERM and vanilla mixup. We also note
that to the best of our knowledge, this is the first theoretical analysis of how mixup (with or without
the selection strategies) affects mis-classification error.
2	Preliminaries
In this paper, we consider the setting where one predicts
the label y ∈ Y based on the input feature X ∈ X. Given a
parameter space Θ and a loss function ', We are supposed
to train a model fθ under the training distribution Ptr,
where θ ∈ Θ. In empirical risk minimization (ERM), as-
sume the empirical distribution over training data is Ptr,
ERM optimizes the following objective:
yi： Waterbird
72.9% of train data
>2: Landbird
3.8% oftrain data
1.2% oftrain data 22.1% oftrain data
Figure 1: Group illustration of Water-
bird data. Domains and labels are rep-
resented by background and bird type.
Most training samples are drawn from
waterbird in water (di, yi) and landbird
in land (d2, y2). The trained model is
spuriously biased by the background.
θ* := argm∈in E(χ,y)~P ['(fθ(X),y)].	(I)
In a traditional machine learning setting, a test set, sam-
pled from a test distribution Pts, is used to evaluate the
generalization of the trained model θ*, where the test dis-
tribution is assumed to be the same as the training distri-
bution, i.e., Ptr = Pts. In this paper, we are interested in
the setting when distribution shift occurs, i.e., Ptr = Pts.
Specifically, follow Muandet et al. (2013); Albuquerque
et al. (2019); Koh et al. (2021), we regard the overall
data distribution containing D = {1,...,D} domains
and each domain d ∈ D is associated with a data distribu-
tion Pd over a set (X, Y, d) = {(xi, y%, d)}N=ι, where Nd
is the number of samples in domain d. Then, we formu-
late the training distribution as the mixture of D domains,
i.e., Ptr = Pd∈D rd Pd, where {rd} denotes the mixture probabilities in training set. Here, the
training domains are defined as Dtr = {d ∈ D∣rttr > 0}. Similarly, the test distribution could be
represented as Pts = Pd∈D rdtsPd, where {rdts} is the mixture probabilities in test set. The test
domains are defined as Dts = {d ∈ D|rdts > 0}.
2
Under review as a conference paper at ICLR 2022
In domain shifts, we investigate the problem that the test domains are disjoint from the training
domains, i.e., Dtr ∩ Dts = 0. In general, We assume the test domains share some common ProP-
erties with the training domains. For example, in Camelyon17 (Koh et al., 2021) data, we train the
model on some hosPitals and test it in a neW hosPital. We evaluate the Worst-domain or average
Performance of the classifier among all test domains.
In subPoPulation shifts, the test set have domains that have been seen in the training set, but With
a different ProPortion of subPoPulations, i.e., Dts ⊆ Dtr but {rdts } 6= {rdtr }. Under this setting,
folloW SagaWa et al. (2020a), We sPecially consider grouP-based sPurious correlations, Where each
grouP g ∈ G is defined to be associated With a domain d and a label y, i.e., g = (d, y). We assume
the domain identification is sPuriously correlated With the label. For examPle, We illustrate the
Waterbirds dataset in Figure 1, Where the background d (Water or land) is sPuriously correlated With
the label y (Waterbird or landbird). Based on the grouP definition, We evaluate the model via the
worst test group error, i.e., maxg E(x,y)〜g ['0-1 (fθ(x),y)], where '0-1 represents the 0-1 loss.
3	Learning Invariant Representations with Selective
Augmentation
This section presents LISA, a simple way to improve robustness to domain shifts or subpopulation
shifts. The key idea behind LISA is to encourage the model to alleviate the effects of domain-related
spurious correlations by selective data interpolation. Before detailing how to select interpolated
samples, we first provide a general formulation for data interpolation.
In LISA, we perform linear interpolation between training samples. Specifically, given samples
(xi, yi, di) and (xj, yj, dj) drawn from domains di and dj, we apply mixup (Zhang et al., 2018), a
simple data interpolation strategy, separately on the input features and corresponding labels as:
xmix = λxi + (1 - λ)xj, ymix = λyi + (1 - λ)yj,	(2)
where the interpolation ratio λ ∈ [0, 1] is sampled from a Beta distribution Beta(α, β) and yi and
yj are one-hot vectors for classification problem. Notice that the mixup approach in equation 2 can
be replaced by CutMix (Yun et al., 2019), which shows stronger empirical performance in vision-
based applications. In text-based applications, we replace the feature interpolation in equation 2 with
Manifold Mixup (Verma et al., 2019), where the interpolation strategy is performed on the output
representation of a pre-trained model, e.g., the output of BERT (Devlin et al., 2019).
After obtaining the interpolated features and labels, we replace the original features and labels in
ERM with the interpolated ones. Then, the optimization process in equation 1 is reformulated as:
θ* := argmin E{(χi,yi,di),(χj,yj,dj)}〜户 ['(fθ (Xmix),ymiX)].	⑶
Without additional selection strategies, vanilla mixup will regularize the model and reduce overfit-
ting (Zhang et al., 2021b), allowing it to attain good in-distribution generalization. However, vanilla
mixup may not be able to cancel out spurious correlations, causing the model to still fail at attaining
good OOD generalization (see empirical comparisons in Section 4.3 and theoretical discussion in
Section 5). In LISA, we instead adopt a new strategy where mixup is only applied across specific
domains or groups, which leans towards learning invariant representations and thus better OOD
performance. Specifically, the two kinds of sample selection strategies are presented as follows:
• Selection Strategy I: Interpolating samples with the same label. In selection strategy I, LISA
interpolates samples with the same label but different domains (i.e., di 6= dj , yi = yj). This
produces datapoints that have both domains partially present, effectively eliminating spurious cor-
relations between domain and label in cases where the pair of domains correlate differently with
the label. Additionally, if domain information does not fully reflect the spurious correlations in
some datasets, we can also enlarge the interpolation scope to cover more potentially spurious cor-
relations by only interpolating samples within the same class regardless domain information (i.e.,
yi = yj). As a result, LISA with selection strategy I should learn domain-invariant representations
for each class and thus achieve better OOD robustness.
• Selection Strategy II: Interpolating samples with the same domain. Supposing domain infor-
mation is highly spuriously correlated with the label information, selection strategy II applies the
3
Under review as a conference paper at ICLR 2022
interpolation strategy on samples with the same domain but different labels, i.e., di = dj , yi 6= yj .
Intuitively, even within the same domain, the model is supposed to generate different predicted
labels since the interpolation ratio λ is randomly sampled, corresponding to different labels ymix .
This causes the model to make predictions that are less dependent on the domain, again improving
OOD robustness.
In LISA, we randomly perform selection strategies I orII during the training process with probability
psel and 1 - psel for each batch of data, where psel is treated as a hyperparameter in our experiments.
The choice of psel depends on the number of domains and the relation between domain information
and spurious correlations. Empirically, using selection strategy I only brings much more benefits
when there are more domains, and/or the domain information can not fully reflect the spurious
correlations. LISA with selection strategy II can benefit the performance when domain information
is highly spuriously correlated with the label, where we find a balanced ratio (i.e., psel = 0.5)
performs the best. The pseudocode of the training procedure of LISA is shown in Algorithm 1.
Algorithm 1 Training Procedure of LISA
Require: Training data, Step size η
1:	while not converge do
2:	Sample λ 〜Beta(α, β)
3:	Sample a set of samples B1 uniformly from the training data
4:	Randomly select a sample selection strategy I or II with the probability psel and 1 - psel
5:	if use selection strategy I then
6:	For each sample (xi, yi, di), find another one (xj , yj , dj) from the dataset with the same
label (yi = yj) but different domains (di 6= dj), and construct set B2 .
7:	else if use selection strategy II then
8:	For each sample (xi , yi , di), find another one (xj , yj , dj ) from the same domain (di = dj )
but different labels (yi 6= yj), constructing set B2 .
9:	Update θ with data λB1 + (1 - λ)B2.
4 Experiments
In this section, we conduct comprehensive experiments to evaluate the effectiveness of LISA. Specif-
ically, we aim to answer the following questions: Q1: Compared to prior methods, can LISA im-
prove robustness to domain shifts and subpopulation shifts (Section 4.1 and Section 4.2)? Q2:
Which aspects of LISA are the most important for improving robustness (Section 4.3)? Q3: How
does LISA perform with varying degrees of distribution shifts (Section 4.4)? Q4: Does LISA suc-
cessfully produce invariant representations (Section 4.5)?
To answer Q1, we compare to ERM, IRM (Arjovsky et al., 2019), MMD (Li et al., 2018),
DRNN (Ganin & Lempitsky, 2015), GroupDRO (Sagawa et al., 2020a), DomainMix (Xu et al.,
2020), and Fish (Shi et al., 2021). Upweighting (UW) is particularly suitable for subpopulation
shifts, so we also use it for comparison. We adopt the same model architectures for all approaches.
4.1	Evaluating Robustness to Domain Shifts
Experimental Setup. To study domain shifts, we study five datasets. Four datasets (Camelyon17,
FMoW, RxRx1, and Amazon) are selected from WILDS (Koh et al., 2021), covering real-world dis-
tribution shifts across diverse domains (e.g., health, natural language process, and vision). Besides
the WILDS data, we also apply LISA on the MetaShift datasets (Liang & Zou, 2021), constructed
using the real-world images and natural heterogeneity of Visual Genome (Krishna et al., 2016).
We summarize the datasets in Table 8 of Appendix A.1.1, including domain information, evalua-
tion metric, model architecture, and the number of classes. Detailed dataset descriptions and other
training details are discussed in Appendix A.1.1 and A.1.2, respectively.
Results. We report the results of domain shifts in Table 1, where the full results that include vali-
dation performance and other metrics are listed in Appendix A.1.3. The optimal strategy selection
probability psel is set as 1.0 for these domain shifts problems, i.e., only selection strategy I is used.
4
Under review as a conference paper at ICLR 2022
In addition, we only interpolate samples with the same labels regardless the domain information,
which empirically leads to the best performance. According to Table 1, we have two key findings:
•	There are no significant performance differences between ERM and other invariant representation
learning methods (e.g. IRM, CORAL, DomainMix) on most datasets, which is consistent with
the reported results on WILDS (Koh et al., 2021). A potential reason is that the existing domain
information may not fully reflects the spurious correlation. For example, in Camelyon17-wilds
dataset (Koh et al., 2021), the presence of tumor tissue (i.e., label) mainly depends on the de-
mographic of patients (e.g., race, gender), which shows no significant difference across hospitals
(i.e., domain information). This could also explain why only interpolating samples with the same
labels regardless the domain information achieves the best performance, which also corroborates
our claims in the description of the selection strategy I in Section 3.
•	The consistent superiority of LISA outperforms prior methods on all five datasets regardless of
the model architecture and dataset types (i.e., image or text), demonstrating its effectiveness in
improving OOD robustness by canceling out spurious correlations with augmentation.
Table 1: Main domain shifts results. LISA outperforms prior methods on all five datasets. Following
the instructions of Koh et al. (2021), we report the performance of Camelyon17 over 10 different
seeds and the results of other datasets are obtained over 3 different seeds.
		Camelyon17	FMoW	RxRx1	Amazon	MetaShift
	Avg. Acc.	Worst Acc.	Avg. Acc.	10-th Per. Acc.	Worst Acc.
ERM	70.3 ± 6.4%	32.3 ± 1.25%	29.9 ± 0.4%	53.8 ± 0.8%	52.1 ± 0.4%
IRM	64.2 ± 8.1%	30.0 ± 1.37%	8.2± 1.1%	52.4 ± 0.8%	51.8 ± 0.8%
CORAL	59.5 ± 7.7%	31.7 ± 1.24%	28.4 ± 0.3%	52.9 ± 0.8%	47.6 ± 1.9%
GroupDRO	68.4 ± 7.3%	30.8 ± 0.81%	23.0 ± 0.3%	53.3 ± 0.0%	51.9 ± 0.7%
DomainMix	69.7 ± 5.5%	34.2 ± 0.76%	30.8 ± 0.4%	53.3 ± 0.0%	51.3 ± 0.5%
Fish	74.7 ± 7.1%	34.6 ± 0.18%	10.1 ± 1.5%	53.3 ± 0.0%	49.2 ± 2.1%
LISA (ours)	77.1 ± 6.5%	35.5 ± 0.65%	31.9 ± 0.8%	54.7 ± 0.0%	54.2 ± 0.7%
4.2	Evaluating Robustness to Subpopulation Shifts
Evaluation Protocol. In subpopulation shifts, we evaluate the performance on four binary clas-
sification datasets, including Colored MNIST (CMNIST), Waterbirds (Sagawa et al., 2020a),
CelebA (Liu et al., 2015), and Civilcomments (Borkan et al., 2019). We summarize brief data statis-
tics in Table 14 of Appendix A.2.1, covering domain information, model architecture, and class
information. Full dataset descriptions of subpopulation shifts are also presented in Appendix A.2.1.
Following Sagawa et al. (2020a), in subpopulation shifts, we use the worst-group accuracy to evalu-
ate the performance of all approaches and the domain identifications are highly spurious correlated
with the label information. For example, as suggested in Figure 1, 95% images in the Waterbirds
dataset have the same background and bird type, i.e., waterbirds in water or landbirds in land. Full
hyperparameter settings and training details are listed in Appendix A.2.2.
Results. In Table 2, we report the overall performance of LISA and other methods. Similar to the
observations in domain shifts, LISA consistently outperforms prior methods in CMNIST, CelebA,
and CivilComments. In Waterbirds, LISA outperforms other invariant representation learning meth-
ods (e.g., IRM, CORAL, DomainMix, Fish) and shows similar performance to GroupDRO. These
results demonstrate the effectiveness of LISA in improving OOD robustness. In CMNIST, Water-
birds, and CelebA, we find that psel = 0.5 works well for choosing selection strategies I and II,
while psel is set as 1.0 in CivilComments. This is not surprising because it might be more beneficial
to use the strategy I more often to eliminate domain effects when there are more domains, i.e., eight
domains in CivilComments v.s. two domains in others.
4.3	Ablation Study: Is the Performance Gain from Data Augmentation ?
In LISA, we apply selective interpolation strategies on samples either with the same label but dif-
ferent domains or with the same domain but different labels. Here, we explore two substitute in-
terpolation strategies: (1) Vanilla mixup: In Vanilla mixup, we do not add any constraint on the
5
Under review as a conference paper at ICLR 2022
Table 2: Results of subpopulation shifts. Here, we show the average and worst group accuracy. We
repeat the experiments three times and put full results with standard deviation in Table 16.
	CMNIST		Waterbirds		CelebA		CivilComments	
	Avg.	Worst	Avg.	Worst	Avg.	Worst	Avg.	Worst
ERM	27.8%	0.0%	97.0%	63.7%	94.9%	47.8%	92.2%	56.0%
UW	72.2%	66.0%	95.1%	88.0%	92.9%	83.3%	89.8%	69.2%
IRM	72.1%	70.3%	87.5%	75.6%	94.0%	77.8%	88.8%	66.3%
CORAL	71.8%	69.5%	90.3%	79.8%	93.8%	76.9%	88.7%	65.6%
GroupDRO	72.3%	68.6%	91.8%	90.6%	92.1%	87.2%	89.9%	70.0%
DomainMix	51.4%	48.0%	76.4%	53.0%	93.4%	65.6%	90.9%	63.6%
Fish	46.9%	35.6%	85.6%	64.0%	93.1%	61.2%	89.8%	71.1%
LISA (ours)	74.0%	73.3%	91.8%	89.2%	92.4%	89.3%	89.2%	72.6%
sample selection, i.e., the mixup is performed on any pairs of samples; (2) In-group mixup: This
strategy applies data interpolation on samples with the same labels and from the same domains. No-
tice that all the substitute interpolation strategies use the same mixup types (e.g., mixup/Manifold
Mixup/CutMix) as LISA. Finally, since upweighting (UW) small groups significantly improves per-
formance in subpopulation shifts, we also evaluate UW combined with Vanilla/In-group mixup.
The ablation results of domain shifts and subpopulation shifts are in Table 3 and Table 4, respec-
tively. Furthermore, we also conduct experiments on datasets without spurious correlation in Ta-
ble 18 of Appendix A.3. From the results, we make the following three key observations. First,
compared with Vanilla mixup, the performance of LISA verifies that selective data interpolation
does improve the out-of-distribution robustness by canceling out the spurious correlations and en-
couraging invariant representation learning rather than simply data augmentation. This findings are
further strengthened by the results in Table 18, where Vanilla mixup outperforms LISA and ERM
without spurious correlations but LISA achieves the best performance with spurious correlations.
Second, the superiority of LISA over In-group mixup verifies that only interpolating samples within
each group is incapable of eliminating out the spurious information, where In-group mixup still
performs the role of data augmentation. Finally, though incorporating UW significantly improves
the performance of Vanilla mixup and In-group mixup in subpopulation shifts, LISA still achieves
larger benefits than these enhanced substitute strategies, demonstrating its stronger power in improv-
ing OOD robustness.
Table 3: Compared LISA with substitute mixup strategies in domain shifts.
	Camelyon17	FMoW	RxRx1	Amazon	MetaShift
	Avg. Acc.	Worst Acc.	Avg. Acc.	10-th Per. Acc.	Worst Acc.
	 ERM	70.3 ± 6.4%	32.8 ± 0.45%	29.9 ± 0.4%	53.8 ± 0.8%	52.1 ± 0.4%
Vanilla mixup	71.2 ± 5.3%	34.2 ± 0.45%	26.5 ± 0.5%	53.3 ± 0.0%	51.3 ± 0.7%
In-group mixup	75.5 ± 6.7%	32.2 ± 1.18%	24.4 ± 0.2%	53.8 ± 0.6%	52.7 ± 0.5%
LISA (ours)	77.1 ± 6.5%	35.5 ± 0.65%	31.9 ± 0.8%	54.7 ± 0.0%	54.2 ± 0.7%
Table 4: Compared LISA with substitute mixup strategies in subpopulation shifts. UW represents
upweighting. Full results with standard deviation is listed in Table 17.
	CMNIST		Waterbirds		CelebA		CivilComments	
	Avg.	Worst	Avg.	Worst	Avg.	Worst	Avg.	Worst
ERM	27.8%	0.0%	97.0%	63.7%	94.9%	47.8%	92.2%	56.0%
Vanilla mixup	32.6%	3.1%	81.0%	56.2%	95.8%	46.4%	90.8%	67.2%
Vanilla mixup + UW	72.2%	71.8%	92.1%	85.6%	91.5%	88.0%	87.8%	66.1%
In-group mixup	33.6%	24.0%	88.7%	68.0%	95.2%	58.3%	90.8%	69.2%
In-group mixup + UW	72.6%	71.6%	91.4%	87.1%	92.4%	87.8%	84.8%	69.3%
LISA (ours)	74.0%	73.3%	91.8%	89.2%	92.4%	89.3%	89.2%	72.6%
4.4 Effect of the Degree of Distribution Shifts
6
Under review as a conference paper at ICLR 2022
We further investigate the performance of LISA
with respect to the degree of distribution shifts.
Here, we use MetaShift to evaluate performance,
where the distance between training and test do-
mains is measured as the node similarity on a meta-
graph (Liang & Zou, 2021). To vary the distance
between training and test domains, we change the
backgrounds of training objects (see full experi-
mental details in Appendix A.1.1). The perfor-
mance with varied distances is illustrated in Table 5,
where the top four best methods (i.e., ERM, Group-
DRO, IRM, DomainMix) are reported for compar-
Table 5: Effects of the degree of distribution
shifts w.r.t. the performance. Distance repre-
sents the distribution distance between train-
ing and test domains.
Distance	0.44	0.71	1.12	1.43
ERM	80.1%	68.4%	52.1%	33.2%
IRM	79.5%	67.4%	51.8%	32.0%
DomainMix	76.0%	63.7%	51.3%	30.8%
GroupDRO	77.0%	68.9%	51.9%	34.2%
LISA (ours) I 81.3%		69.7%	54.2%	37.5%
ison. We observe that LISA consistently outperforms other methods under all scenarios. Addi-
tionally, another interesting finding is that LISA achieves more substantial improvements with the
increases of distance. A potential reason is that the models may rely more heavily on domain corre-
lations when there is a larger distance between training and test domains.
4.5 Analysis about Learned Invariance
Finally, we analyze the invariance learned by LISA. Specif-
ically, we investigate representation-level and prediction-
level invariances below.
Representation-level Invariance. For each label y, as-
sume the hidden representation for each domain d as Hdy .
The representation-level invariance IVr is measured by the
pairwise KL divergence of distribution P (Hdy) among all
domains as IVr = |Y|1D|2 Py∈γ Pd0,d∈D KL(P (HDy |
D = d)|P (HDy | D = d0)), where smaller IVr values indi-
cate that the learned representations are more invariant with
respect to the labels. We report the results on CMNIST and
MetaShift in Table 6. Our key observations are: (1) Com-
Table 6: Results of representation-
level invariance (×108), where
smaller values denote stronger
invariance w.r.t. labels.
		CMNIST	MetaShift
ERM	1.683	0.632
Vanilla mixup	4.392	0.634
IRM	1.905	0.627
DomainMix	2.155	0.614
LISA (ours)	0.421	0.585
pared with ERM, the invariance of LISA indicates its promise in improving the OOD robustness by
encouraging invariant representation learning. (2) LISA has greater invariance than vanilla mixup,
validating that the invariant representations are not caused by naive data interpolation. (3) LISA pro-
vides more invariant representations than regularization-based methods, i.e., IRM and DomainMix.
Prediction-level Invariance. Motivated by Arjovsky et al.
(2019); Krueger et al. (2021), the prediction-level invariance
IVp is measured by the variance of test risks across all do-
mains, i.e., IVp = Var({R1 (θ), . . . , RD(θ)}), where D rep-
resents the number of test domains. A small IVp represents
strong prediction-level invariance. The results on CMNIST
and MetaShift are reported in Table 7, where the superiority
of LISA verifies that it could also improve the prediction-level
invariance.
5	Theoretical Analysis
Table 7: Results of the analysis of
prediction-level invariance. Smaller
values denote stronger invariance.
		CMNIST	MetaShift
ERM	12.0486	1.8824
Vanilla mixup	0.2769	0.2659
IRM	0.0112	0.8748
DomainMix	0.1674	1.1158
LISA (ours)	0.0012	0.2387
In this section, we provide some theoretical understandings that explain several of the empirical
phenomena from the previous experiments and theoretically compare the worst-group errors of three
methods: the proposed LISA, ERM, and vanilla mixup. Specifically, we consider a Gaussian mixture
model with subpopulation and domain shifts, which has been widely adopted in theory to shed
light upon complex machine learning phenomenon such as in Montanari et al. (2019); Zhang et al.
(2021c). We also note here that despite the popularity of mixup in practice, the theoretical analysis
of how mixup (with or without the selection strategies) affects the misclassification error is still
largely unexplored in the literature even in the simple models. As discussed in Section 2, here, we
define y ∈ {0, 1} as the label, and d ∈ {B, G} as the domain information. For y ∈ {0, 1} and
7
Under review as a conference paper at ICLR 2022
d ∈ {B, G}, we consider the following model:
Xi∣yi = y,di = d 〜N(μ(y,d), Σ(d)), i = 1,...,n(y,d),	(4)
where μ(y,d) ∈ Rp is the conditional mean vector and Σ(d) ∈ Rp×p is the covariance matrix.
Let n = Py∈{o,i},d∈{B,G} n(y,d). Let ∏(y,d) = ≡‰ = y,di = d), ∏(y) = ≡‰ = y), and
π(d) =P(di = d).'	'
To account for the spurious correlation brought by domains, We consider μ(y,B) = μ(y,G) in general
for y ∈ {0, 1} and the imbalanced case where π(0,B), π(1,G) < 1/4. Moreover, we assume there
exists some invariance across different domains. Specifically, we assume
μ(1,B) - μ(0,B) = μ(1,G) - μ(OC) := ∆ and Σ(G) = Σ(B).
According to the theory of Fisher’s linear discriminant analysis rule (Anderson, 1962), the optimal
classification rule is linear with slope Σ-1∆. The assumption above implies that (Σ-1∆)>x is the
(unknown) invariant representation in model equation 4.
Suppose we use some method A and obtain a linear classifier xT b + b0 > 0 from a training data,
we will apply it to a test data and compute the worst-group misclassification error, where the mis-
classification error for domain d and class y is E(y,d)(b,bo) := IP(I(XTb + bo > ɪ) = y|d =
d, yi = y), and we denote the worst-group error with the method A as
E
(wst)
A
max
d∈{B,G},y∈{0,1}
E(y,d)(bA, b0,A),
where bA and b0,A are the slope and intercept based on the method A. Specifically, A = ERM
denotes the ERM method (by minimizing the sum of squares loss on the training data altogether),
A = mix denotes the vanilla mixup method (without any selection strategy), and A = LISA denotes
the mixup strategy for LISA. We also denote its finite sample version by EAwSt).
Let ∆ = E[xi∣yi = 1] - !E[χi |yi = 0] denote the marginal difference and ξ = ]： j.j denote the
correlation operator between the domain-specific difference ∆ and the marginal difference ∆e with
respect to Σ. We see that smaller ξ indicates larger discrepancy between the marginal difference
and the domain-specific difference and therefore implies stronger spurious correlation between the
domains and labels. We present the following theorem showing that our proposed LISA algorithm
outperforms the ERM and vanilla mixup in the subpopulation shifts setting.
Theorem 1 (Worst-group error comparison with subpopulation shifts). Consider n independent
samples generated from model (4), π(B) = π(1) = 1/2, π(0,B) = π(1,G) = α < 1/4,
maxy,d ∣∣μ(y,d) ∣∣2 ≤ C, and Σ is positive definite. Suppose (ξ, α) satisfies that ξ ≤ min{ |同]；, 1}—
2E[λ2i	一，，	r„ .-l
Ca for some large enough constant C and ∣∣∆∣∑ ≤ X max{3va；(t .) 1/4} ∙ Thenforany PSel ∈ [0,1],
EbL(wISSAt) ≤min{EbE(wRMSt),Ebm(wixSt)}+OP
plogn
n
where p is the dimension of x. Theorem 1 implies that when ξ is small (indicating that the domain
has strong spurious correlation with the label) andp = o(αn), the worst-group classification errors
of LISA are asymptotically smaller than that of ERM and vanilla mixup. In fact, our analysis shows
that LISA yields a classification rule closer to the invariant classification rules by leveraging the
domain information.
In the next theorem, we present the mis-classification error comparisons with domain shifts. That
is, consider samples from a new unseen domain:
x(0,∙) 〜N(μ(", Σ), x(1,∙) 〜N(μ(1,*), Σ).
Let ∆* = 2(μ(0,*) - E[xi]), where E[xi] is the mean of the training distribution, and assume
μ(1,*) - μ(0,*) = δ∙ Let ξ* = ∆≥∆⅛and Y = ⅛⅛⅛⅛ denote the COrreIatiOnfOr(A*, δ)
and for (∆e*, ∆), respectively, with respect to Σ-1. Let EA(wSt*) = maxy∈{0,1} E(y,*) (bA, b0,A) and
its sample version be E(wst*).
8
Under review as a conference paper at ICLR 2022
Theorem 2 (Mis-classification error comparison with domain shifts). Suppose n samples are in-
dependently generated from model (4), π(B) = π(1) = 1/2, π(0,B) = π(1,G) = α < 1/4,
maxy,d ∣∣μ(y,d)k2 ≤ C and Σ is positive definite. Suppose that (ξ,ξ*,γ) satisfy that 0 ≤
ξ* ≤ γξ and ξ ≤ min{2	, 1} — Ca for some large enough constant C and ∣∣∆∣∣∑ ≤
qmax{3Va⅞),l∕4}・ ThenfOranyPsel ∈ [0, 1],
E樱A*) ≤ min{EE需*),E±st*)} + Op (Pogn +
Similar to Theorem 1, this result shows that when domain has strong spurious correlation with the
label (corresponding to small ξ), such a spurious correlation leads to the downgraded performance
of ERM and vanilla mixup, while our proposed LISA method is able to mitigate such an issue by
selective data interpolation. Proofs of Theorem 1 and Theorem 2 are provided in Appendix B.
6	Related Work and Discussion
In this paper, we focus on improving the robustness of machine learning models to domain shifts
and subpopulation shifts. Here, we discuss related approaches from the following three categories:
Learning Invariant Representations with Domain Alignment. Motivated by unsupervised do-
main adaptation (Ben-David et al., 2010; Ganin et al., 2016), the first category of works learns
invariant representations by aligning representations across domains. The major research line of this
category aims to eliminate the domain dependency by minimizing the divergence of feature distri-
butions with different distance metrics, e.g., maximum mean discrepancy (Tzeng et al., 2014; Long
et al., 2015), an adversarial loss (Ganin et al., 2016; Li et al., 2018), Wassertein distance (Zhou et al.,
2020a). Follow-up works applied data augmentation to (1) generate more domains and enhance the
consistency of representations during training (Yue et al., 2019; Zhou et al., 2020b; Xu et al., 2020;
Yan et al., 2020; Shu et al., 2021; Wang et al., 2020) or (2) generate new domains in an adversar-
ial way to imitate the challenging domains without using training domain information (Zhao et al.,
2020; Qiao et al., 2020; Volpi et al., 2018). Unlike these latter methods, LISA instead focuses on
canceling out correlations in the dataset between the domain and the label through selective data
interpolation, leading to stronger empirical performance.
Learning Invariant Representations with Invariant Predictors. Beyond using domain alignment
to learning invariant representations, recent work aims to further enhance the correlations between
the invariant representations and the labels (Koyama & Yamaguchi, 2020). Representatively, moti-
vated by casual inference, invariant risk minimization (IRM) (Arjovsky et al., 2019) aims to find a
predictor that performs well across all domains. After IRM, the following works propose stronger
regularizers by penalizing the variance of risks across all domains (Krueger et al., 2021), by align-
ing the gradient across domains (Koyama & Yamaguchi, 2020), by smoothing the cross-domain
interpolation paths (Chuang & Mroueh, 2021), or through game-theoretic invariant rationalization
criterion (Chang et al., 2020). Instead of using regularization, LISA eliminates spurious correlations
in the data directly via data interpolation.
Group Robustness. The last category of methods combats spurious correlations and are particularly
suitable for subpopulation shifts. These approaches include directly optimizing the worst-group
performance with Distributionally Robust Optimization (Sagawa et al., 2020a; Zhang et al., 2021a;
Zhou et al., 2021), generating samples around the minority groups (Goel et al., 2021), and balancing
the majority and minority groups via reweighting (Sagawa et al., 2020b) or regularizing (Cao et al.,
2019; 2020). Here, LISA proposes a more general strategy based on data augmentation that is
suitable for both domain shifts and subpopulation shifts.
7	Conclusion
To tackle the distribution shifts, we propose LISA, a simple and efficient algorithm, to improve
the out-of-distribution robustness. LISA aims to eliminate the domain-related spurious correlations
among the training set by selective sample interpolation. We evaluate the effectiveness of LISA
on nine datasets under subpopulation shifts and domain shifts settings, demonstrating its promise.
Our theoretical results further strengthen the superiority of LISA by showing smaller worst-group
mis-classification error compared with ERM and vanilla mixup.
9
Under review as a conference paper at ICLR 2022
Reproducibility S tatement
We conduct experiments under the setting of domain shifts and subpopulation shifts problems. In
terms of the domain shifts, the results are reported in in Table 1. The dataset details are pro-
vided in Appendix A.1.1, and the training details along with the hyperparameter settings are in
appendix A.1.2. Then, for the subpopulation shifts, we have included the full results including the
error bounds in Table 16. The dataset details are discussed in Appendix A.2.1, while the train-
ing details and the hyperparameter settings are in Appendix A.2.2. We will release the code upon
publication. Besides, The detailed proof of Theorem 1 and Theorem 2 are provided in Appendix B.
References
Isabela Albuquerque, Joao Monteiro, Mohammad Darvishi, Tiago H Falk, and Ioannis Mitliagkas.
Generalizing to unseen domains via distribution matching. arXiv preprint arXiv:1911.00804,
2019.
Theodore Wilbur Anderson. An introduction to multivariate statistical analysis. Technical report,
Wiley New York, 1962.
Martin Arjovsky, Leon BottoU,Ishaan Gulrajani, and David Lopez-Paz. Invariant risk minimization.
arXiv preprint arXiv:1907.02893, 2019.
Peter Bandi, Oscar Geessink, Quirine Manson, Marcory Van Dijk, Maschenka Balkenhol, Meyke
Hermsen, Babak Ehteshami Bejnordi, Byungjae Lee, Kyunghyun Paeng, Aoxiao Zhong, et al.
From detection of individual metastases to classification of lymph node status at the patient level:
the camelyon17 challenge. IEEE Transactions on Medical Imaging, 2018.
Shai Ben-David, John Blitzer, Koby Crammer, Alex Kulesza, Fernando Pereira, and Jennifer Wort-
man Vaughan. A theory of learning from different domains. Machine learning, 79(1):151-175,
2010.
Daniel Borkan, Lucas Dixon, Jeffrey Sorensen, Nithum Thain, and Lucy Vasserman. Nuanced
metrics for measuring unintended bias with real data for text classification. In Companion pro-
ceedings of the 2019 world wide web conference, pp. 491-500, 2019.
Kaidi Cao, Colin Wei, Adrien Gaidon, Nikos Arechiga, and Tengyu Ma. Learning imbalanced
datasets with label-distribution-aware margin loss. NeurIPS, 2019.
Kaidi Cao, Yining Chen, Junwei Lu, Nikos Arechiga, Adrien Gaidon, and Tengyu Ma. Het-
eroskedastic and imbalanced deep learning with adaptive regularization. arXiv preprint
arXiv:2006.15766, 2020.
Shiyu Chang, Yang Zhang, Mo Yu, and Tommi Jaakkola. Invariant rationalization. In International
Conference on Machine Learning, pp. 1448-1458. PMLR, 2020.
Gordon Christie, Neil Fendley, James Wilson, and Ryan Mukherjee. Functional map of the world.
In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2018.
Ching-Yao Chuang and Youssef Mroueh. Fair mixup: Fairness via interpolation. ICLR, 2021.
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert: Pre-training of deep
bidirectional transformers for language understanding. 2019.
Yaroslav Ganin and Victor Lempitsky. Unsupervised domain adaptation by backpropagation. In
International conference on machine learning, pp. 1180-1189. PMLR, 2015.
Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo Larochelle, Francois
Laviolette, Mario Marchand, and Victor Lempitsky. Domain-adversarial training of neural net-
works. The journal of machine learning research, 17(1):2096-2030, 2016.
Karan Goel, Albert Gu, Yixuan Li, and Christopher Re. Model patching: Closing the subgroup
performance gap with data augmentation. In ICLR, 2021.
10
Under review as a conference paper at ICLR 2022
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recog-
nition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pp.
770-778, 2016.
Gao Huang, Zhuang Liu, Laurens Van Der Maaten, and Kilian Q Weinberger. Densely connected
convolutional networks. In Proceedings of the IEEE conference on computer vision and pattern
recognition, pp. 4700-4708, 2017.
Pang Wei Koh, Shiori Sagawa, Sang Michael Xie, Marvin Zhang, Akshay Balsubramani, Weihua
Hu, Michihiro Yasunaga, Richard Lanas Phillips, Irena Gao, Tony Lee, et al. Wilds: A benchmark
of in-the-wild distribution shifts. In International Conference on Machine Learning, pp. 5637-
5664. PMLR, 2021.
Masanori Koyama and Shoichiro Yamaguchi. Out-of-distribution generalization with maximal in-
variant predictor. arXiv preprint arXiv:2008.01883, 2020.
Ranjay Krishna, Yuke Zhu, Oliver Groth, Justin Johnson, Kenji Hata, Joshua Kravitz, Stephanie
Chen, Yannis Kalantidis, Li-Jia Li, David A Shamma, Michael Bernstein, and Li Fei-Fei. Visual
genome: Connecting language and vision using crowdsourced dense image annotations. 2016.
URL https://arxiv.org/abs/1602.07332.
David Krueger, Ethan Caballero, Joern-Henrik Jacobsen, Amy Zhang, Jonathan Binas, Dinghuai
Zhang, Remi Le Priol, and Aaron Courville. Out-of-distribution generalization via risk extrapo-
lation (rex). In International Conference on Machine Learning, pp. 5815-5826. PMLR, 2021.
Haoliang Li, Sinno Jialin Pan, Shiqi Wang, and Alex C Kot. Domain generalization with adver-
sarial feature learning. In Proceedings of the IEEE Conference on Computer Vision and Pattern
Recognition, pp. 5400-5409, 2018.
Weixin Liang and James Zou. Metadataset: A dataset of datasets for evaluating distribution shifts
and training conflicts. In ICML2021 ML4data Workshop, 2021.
Ziwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou Tang. Deep learning face attributes in the wild.
In ICCV, 2015.
Mingsheng Long, Yue Cao, Jianmin Wang, and Michael Jordan. Learning transferable features with
deep adaptation networks. In International conference on machine learning, pp. 97-105. PMLR,
2015.
Andrea Montanari, Feng Ruan, Youngtak Sohn, and Jun Yan. The generalization error of max-
margin linear classifiers: High-dimensional asymptotics in the overparametrized regime. arXiv
preprint arXiv:1911.01544, 2019.
Krikamol Muandet, David Balduzzi, and Bernhard Scholkopf. Domain generalization via invariant
feature representation. In International Conference on Machine Learning, pp. 10-18. PMLR,
2013.
Jianmo Ni, Jiacheng Li, and Julian McAuley. Justifying recommendations using distantly-labeled
reviews and fine-grained aspects. In Proceedings of the 2019 Conference on Empirical Methods
in Natural Language Processing and the 9th International Joint Conference on Natural Language
Processing (EMNLP-IJCNLP), 2019.
Fengchun Qiao, Long Zhao, and Xi Peng. Learning to learn single domain generalization. In Pro-
ceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 12556-
12565, 2020.
Elan Rosenfeld, Pradeep Ravikumar, and Andrej Risteski. The risks of invariant risk minimization.
In ICLR, 2021.
Shiori Sagawa, Pang Wei Koh, Tatsunori B Hashimoto, and Percy Liang. Distributionally robust
neural networks for group shifts: On the importance of regularization for worst-case generaliza-
tion. In ICLR, 2020a.
11
Under review as a conference paper at ICLR 2022
Shiori Sagawa, Aditi Raghunathan, Pang Wei Koh, and Percy Liang. An investigation of why
overparameterization exacerbates spurious correlations. In ICML, pp. 8346-8356. PMLR, 2020b.
Victor Sanh, Lysandre Debut, Julien Chaumond, and Thomas Wolf. Distilbert, a distilled version of
bert: smaller, faster, cheaper and lighter. arXiv preprint arXiv:1910.01108, 2019.
Yuge Shi, Jeffrey Seely, Philip HS Torr, N Siddharth, Awni Hannun, Nicolas Usunier, and Gabriel
Synnaeve. Gradient matching for domain generalization. arXiv preprint arXiv:2104.09937, 2021.
Yang Shu, Zhangjie Cao, Chenyu Wang, Jianmin Wang, and Mingsheng Long. Open domain gen-
eralization with domain-augmented meta-learning. In Proceedings of the IEEE/CVF Conference
on Computer Vision and Pattern Recognition, pp. 9624-9633, 2021.
Baochen Sun and Kate Saenko. Deep coral: Correlation alignment for deep domain adaptation. In
European conference on computer vision, pp. 443-450. Springer, 2016.
J. Taylor, B. Earnshaw, B. Mabey, M. Victors, and J. Yosinski. Rxrx1: An image set for cellular mor-
phological variation across many experimental batches. In International Conference on Learning
Representations (ICLR), 2019.
Eric Tzeng, Judy Hoffman, Ning Zhang, Kate Saenko, and Trevor Darrell. Deep domain confusion:
Maximizing for domain invariance. arXiv preprint arXiv:1412.3474, 2014.
Vikas Verma, Alex Lamb, Christopher Beckham, Amir Najafi, Ioannis Mitliagkas, David Lopez-
Paz, and Yoshua Bengio. Manifold mixup: Better representations by interpolating hidden states.
In International Conference on Machine Learning, pp. 6438-6447. PMLR, 2019.
Riccardo Volpi, Hongseok Namkoong, Ozan Sener, John Duchi, Vittorio Murino, and Silvio
Savarese. Generalizing to unseen domains via adversarial data augmentation. arXiv preprint
arXiv:1805.12018, 2018.
C. Wah, S. Branson, P. Welinder, P. Perona, and S. Belongie. The Caltech-UCSD Birds-200-2011
Dataset. Technical Report CNS-TR-2011-001, California Institute of Technology, 2011.
Yufei Wang, Haoliang Li, and Alex C Kot. Heterogeneous domain generalization via domain mixup.
In ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Process-
ing (ICASSP), pp. 3622-3626. IEEE, 2020.
Minghao Xu, Jian Zhang, Bingbing Ni, Teng Li, Chengjie Wang, Qi Tian, and Wenjun Zhang.
Adversarial domain adaptation with domain mixup. In Proceedings of the AAAI Conference on
Artificial Intelligence, volume 34, pp. 6502-6509, 2020.
Shen Yan, Huan Song, Nanxiang Li, Lincan Zou, and Liu Ren. Improve unsupervised domain
adaptation with mixup training. arXiv preprint arXiv:2001.00677, 2020.
Xiangyu Yue, Yang Zhang, Sicheng Zhao, Alberto Sangiovanni-Vincentelli, Kurt Keutzer, and Bo-
qing Gong. Domain randomization and pyramid consistency: Simulation-to-real generalization
without accessing target domain data. In Proceedings of the IEEE/CVF International Conference
on Computer Vision, pp. 2100-2110, 2019.
Sangdoo Yun, Dongyoon Han, Seong Joon Oh, Sanghyuk Chun, Junsuk Choe, and Youngjoon Yoo.
Cutmix: Regularization strategy to train strong classifiers with localizable features. In Proceed-
ings of the IEEE/CVF International Conference on Computer Vision, pp. 6023-6032, 2019.
Hongyi Zhang, Moustapha Cisse, Yann N Dauphin, and David Lopez-Paz. mixup: Beyond empirical
risk minimization. 2018.
Jingzhao Zhang, Aditya Menon, Andreas Veit, Srinadh Bhojanapalli, Sanjiv Kumar, and Suvrit Sra.
Coping with label shift via distributionally robust optimisation. In ICLR, 2021a.
Linjun Zhang, Zhun Deng, Kenji Kawaguchi, Amirata Ghorbani, and James Zou. How does mixup
help with robustness and generalization? In ICLR, 2021b.
Linjun Zhang, Zhun Deng, Kenji Kawaguchi, and James Zou. When and how mixup improves
calibration. arXiv preprint arXiv:2102.06289, 2021c.
12
Under review as a conference paper at ICLR 2022
Long Zhao, Ting Liu, Xi Peng, and Dimitris Metaxas. Maximum-entropy adversarial data augmen-
tation for improved generalization and robustness. arXiv preprint arXiv:2010.08001, 2020.
Bolei Zhou, Agata Lapedriza, Aditya Khosla, Aude Oliva, and Antonio Torralba. Places: A 10
million image database for scene recognition. IEEE transactions on pattern analysis and machine
intelligence, 40(6):1452-1464, 2017.
Chunting Zhou, Xuezhe Ma, Paul Michel, and Graham Neubig. Examining and combating spurious
features under distribution shift. In ICML, 2021.
Fan Zhou, Zhuqing Jiang, Changjian Shui, Boyu Wang, and Brahim Chaib-draa. Domain general-
ization with optimal transport and metric learning. arXiv preprint arXiv:2007.10573, 2020a.
Kaiyang Zhou, Yongxin Yang, Timothy Hospedales, and Tao Xiang. Deep domain-adversarial im-
age generation for domain generalisation. In Proceedings of the AAAI Conference on Artificial
Intelligence, volume 34, pp. 13025-13032, 2020b.
A	Additional Experiments
A.1 Domain Shifts
A.1.1 Dataset Details
In this section, we provide detailed descriptions of datasets used in the experiments of domain shifts
and report the data statistics in Table 8.
Camelyon17 We use Camelyon17 from the WILDS benchmark (Koh et al., 2021; Bandi et al.,
2018), which provides 450, 000 lymph-node scans sampled from 5 hospitals. Camelyon17 is a
medical image classification task where the input x is a 96 × 96 image and the label y is whether
there exists tumor tissue in the image. The domain d denotes the hospital that the patch was taken
from. The training dataset is drawn from the first 3 hospitals, while out-of-distribution validation
and out-of-distribution test datasets are sampled from the 4-th hospital and 5-th hospital respectively.
FMoW The FMoW dataset is from the WILDS benchmark (Koh et al., 2021; Christie et al., 2018)
— a satellite image classification task which includes 62 classes and 80 domains (16 years x 5
regions). Concretely, the input x is a 224 × 224 RGB satellite image, the label y is one of the 62
building or land use categories, and the domain d represents the year that the image was taken as
well as its corresponding geographical region - Africa, the Americas, Oceania, Asia, or Europe.
The train/test/validation splits are based on the time when the images are taken. Specifically, images
taken before 2013 are used as the training set. Images taken between 2013 and 2015 are used as the
validation set. Images taken after 2015 are used for testing.
RxRx1 RxRx1 (Koh et al., 2021; Taylor et al., 2019) from the WILDS benchmark is a cell image
classification task. In the dataset, some cells have been genetically perturbed by siRNA. The goal of
RxRx1 is to predict which siRNA that the cells have been treated with. Concretely, the input x is an
image of cells obtained by fluorescent microscopy, the label y indicates which of the 1, 139 genetic
treatments the cells received, and the domain d denotes the experimental batches. Here, 33 different
batches of images are used for training, where each batch contains one sample for each class. The
out-of-distribution validation set has images from 4 experimental batches. The out-of-distribution
test set has 14 experimental batches. The average accuracy on out-of-distribution test set is reported.
Amazon Each task in the Amazon benchmark (Koh et al., 2021; Ni et al., 2019) is a multi-class
sentiment classification task. The input x is the text of a review, the label y is the corresponding
star rating ranging from 1 to 5, and the domain d is the corresponding reviewer. The training set
has 245, 502 reviews from 1, 252 reviewers, while the out-of-distribution validation set has 100, 050
reviews from another 1, 334 reviewers. The out-of-distribution test set also has 100, 050 reviews
from the rest 1, 252 reviewers. We evaluate the models by the 10th percentile of per-user accuracies
in the test set.
13
Under review as a conference paper at ICLR 2022
MetaShift We use the MetaShift (Liang & Zou, 2021), which is derived from Visual Genome (Kr-
ishna et al., 2016). MetaShift leverages the natural heterogeneity of Visual Genome to provide many
distinct data distributions for a given class (e.g. “cats with cars” or “cats in bathroom” for the “cat”
class). A key feature of MetaShift is that it provides explicit explanations of the dataset correlation
and a distance score to measure the degree of distribution shift between any pair of sets. We adopt
the “Cat vs. Dog” task in MetaShift, where we evaluate the model on the “dog(shelf )” domain with
306 images, and the “cat(shelf )” domain with 235 images. The training data for the “Cat” class is
the cat(sofa + bed), including cat(sofa) domain and cat(bed) domain. MetaShift provides 4 different
sets of training data for the “Dog” class in an increasingly challenging order, i.e., increasing the
amount of distribution shift. Specifically, dog(cabinet + bed), dog(bag + box), dog(bench + bike),
dog(boat + surfboard) are selected for training, where their corresponding distances to dog(shelf )
are 0.44, 0.71, 1.12, 1.43.
Table 8: Dataset Statistics for Domain Shifts.
Datasets	Domains	Metric	Base Model	Num. of classes
Camelyon17	5 hospitals	Avg. Acc.	DenseNet-121	2
FMoW	16 years x 5 regions	Worst-group Acc.	DenseNet-121	62
RxRx1	51 experimental batches	Avg. Acc.	ResNet-50	1,139
Amazon	7,676 reviewers	10th Percentile Acc.	DistilBERT-uncased	5
MetaShift	4 backgrounds	Worst-group Acc.	ResNet-50	2
A.1.2 Training Details
Follow WILDS Koh et al. (2021), we adopt pre-trained DenseNet121 (Huang et al., 2017) for Came-
lyon17 and FMoW datasets, ResNet-50 (He et al., 2016) for RxRx1 and MetaShift datasets, and
DistilBert (Sanh et al., 2019) for Amazon datasets.
In each training iteration, we first draw a batch of samples B1 from the training set. With B1, we
then select another sample batch B2 with same labels as B1 for data interpolation. The interpolation
ratio λ is drawn from the distribution Beta(2, 2). We use the same image transformers as Koh et al.
(2021), and all other hyperparameter settings are listed in Table 9.
Table 9: Hyperparameter settings for the domain shifts.
Dataset	CameIyon17	FMoW	RxRx1	Amazon	MetaShift
Learning rate	1e-4	1e-4	1e-3	2e-6	1e-3
Weight decay	0	0	1e-5	0	1e-4
Scheduler	n/a	n/a	Cosine Warmup	n/a	n/a
Batch size	32	32	72	8	16
Type of mixup	CutMix	CutMix	CutMix	ManifoldMix	CutMix
Architecture	DenSeNet121	DenseNet121	ResNet50	DistilBert	ResNet50
Optimizer	SGD	Adam	Adam	Adam	SGD
Maximum Epoch	2	5	90	3	100
Strategy sel. prob. psel	1.0	1.0	1.0	1.0	1.0
A.1.3 Full Results of WILDS data
Follow Koh et al. (2021), we reported more results on WILDS datasets in Table 10 - Table 13,
including validation performance and the results of other metrics. According to these additional
results, we could see that LISA outperforms other baseline approaches in all scenarios. Particularly,
we here discuss two additional findings: (1) In Camelyon dataset, the test data is much more visually
distinctive compared with the validation data, resulting in the large gap (〜10%) between validation
and test performance of ERM (see Table 10). However, LISA significantly reduces the performance
gap between the validation and test sets, showing its promise in improving OOD robustness; (2)
In Amazon dataset, though LISA performs worse than ERM in average accuracy, it achieves the
best accuracy at the 10th percentile, which is regarded as a more common and important metric to
evaluate whether models perform consistently well across all users (Koh et al., 2021).
14
Under review as a conference paper at ICLR 2022
Table 10: Full Results of Camelyon17. We report both validation accuracy and test accuracy.
		Validation Acc.	Test Acc.
ERM	84.9 ± 3.1%	70.3 ± 6.4%
IRM	86.2 ± 1.4%	64.2 ± 8.1%
Coral	86.2 ± 1.4%	59.5 ± 7.7%
GroupDRO	85.5 ± 2.2%	68.4 ± 7.3%
DomainMix	83.5 ± 1.1%	69.7 ± 5.5%
Fish	83.9 ± 1.2%	74.7 ± 7.1%
LISA (ours)	81.8 ± 1.3%	77.1 ± 6.5%
Table 11: Full Results of FMoW. Here, we report the average accuracy and the worst-domain accu-
racy on both validation and test sets.
	Validation		Test	
	Avg. Acc.	Worst Acc.	Avg. Acc.	Worst Acc.
ERM	59.5 ± 0.37%	48.9 ± 0.62%	53.0 ± 0.55%	32.3 ± 1.25%
IRM	57.4 ± 0.37%	47.5 ± 1.57%	50.8 ± 0.13%	30.0 ± 1.37%
Coral	56.9 ± 0.25%	47.1 ± 0.43%	50.5 ± 0.36%	31.7 ± 1.24%
GroupDRO	58.8 ± 0.19%	46.5 ± 0.25%	52.1 ± 0.50%	30.8 ± 0.81%
DomainMix	58.6 ± 0.29%	48.9 ± 1.15%	51.6 ± 0.19%	34.2 ± 0.76%
Fish	57.8 ± 0.15%	49.5 ± 2.34%	51.8 ± 0.32%	34.6 ± 0.18%
LISA (ours)	58.7 ± 0.92%	48.7 ± 0.74%	52.8 ± 0.94%	35.5 ± 0.65%
A.2 Subpopulation Shifts
A.2.1 Dataset Details
We detail the data descriptions of subpopulation shifts below and report the detailed data statistics
in Table 14.
Colored MNIST (CMNIST): We classify MNIST digits from 2 classes, where classes 0 and 1
indicate original digits (0,1,2,3,4) and (5,6,7,8,9). The color is treated as a spurious attribute. Con-
cretely, in the training set, the proportion between red samples and green samples is 8:2 in class 0,
while the proportion is set as 2:8 in class 1. In the validation set, the proportion between green and
red samples is 1:1 for all classes. In the test set, the proportion between green and red samples is 1:9
in class 0, while the ratio is 9:1 in class 1. The data sizes of train, validation, and test sets are 30000,
10000, and 20000, respectively.
Waterbirds (Sagawa et al., 2020a): The Waterbirds dataset aims to classify birds as “waterbird” or
“landbird”, where each bird image is spuriously associated with the background “water” or “land”.
Waterbirds is a synthetic dataset where each image is composed by pasting a bird image sampled
from CUB dataset (Wah et al., 2011) to a background drawn from the Places dataset Zhou et al.
(2017). The bird categories in CUB are stratified as land birds or water birds. Specifically, the
following bird species are selected to construct the waterbird class: albatross, auklet, cormorant,
frigatebird, fulmar, gull, jaeger, kittiwake, pelican, puffin, tern, gadwall, grebe, mallard, merganser,
guillemot, or Pacific loon. All other bird species are combined as the landbird class. We define (land
background, waterbird) and (water background, landbird) are minority groups. There are 4,795
training samples while only 56 samples are “waterbirds on land” and 184 samples are “landbirds
on water”. The remaining training data include 3,498 samples from “landbirds on land”, and 1,057
samples from “waterbirds on water”.
CelebA (Liu et al., 2015; Sagawa et al., 2020a): For the CelebA data (Liu et al., 2015), we follow
the data preprocess procedure from Sagawa et al. (2020a). CelebA defines a image classification
task where the input is a face image of celebrities and the classification label is its corresponding
hair color - "blond" or “not blond." The label is spuriously correlated with gender, i.e., male or
female. In CelebA, the minority groups are (blond, male) and (not blond, female). The number of
15
Under review as a conference paper at ICLR 2022
Table 12: Full Results of RxRx1. ID: in-distribution; OOD: out-of-distribution
	Validation Acc.	Test ID Acc.	Test OOD Acc.
	 ERM	19.4 ± 0.2%	35.9 ± 0.4%	29.9 ± 0.4%
IRM	5.6 ± 0.4%	9.9 ± 1.4%	8.2± 1.1%
Coral	18.5 ± 0.4%	34.0 ± 0.3%	28.4 ± 0.3%
GrouPDRO	15.2 ± 0.1%	28.1 ± 0.3%	23.0 ± 0.3%
DomainMix	19.3 ± 0.7%	39.8 ± 0.2%	30.8 ± 0.4%
Fish	7.5 ± 0.6%	12.7 ± 1.9%	10.1 ± 1.5%
LISA (ours)	20.1 ± 0.4%	41.2 ± 1.0%	31.9 ± 0.8%
Table 13: Full Results of Amazon. Both the average accuracy and the 10th Percentile accuracy are
reported.
	Validation		Test	
	Avg. Acc.	10-th Per.	Avg. Acc.	10-th Per. Acc.
ERM	72.7 ± 0.1%	55.2 ± 0.7%	71.9 ± 0.1%	53.8 ± 0.8%
IRM	71.5 ± 0.3%	54.2 ± 0.8%	70.5 ± 0.3%	52.4 ± 0.8%
Coral	72.0 ± 0.3%	54.7 ± 0.0%	70.0 ± 0.6%	52.9 ± 0.8%
GrouPDRO	70.7 ± 0.6%	54.7 ± 0.0%	70.0 ± 0.6%	53.3 ± 0.0%
DomainMix	71.9 ± 0.2%	54.7 ± 0.0%	71.1 ± 0.1%	53.3 ± 0.0%
Fish	72.5 ± 0.0%	54.7 ± 0.0%	71.7 ± 0.1%	53.3 ± 0.0%
LISA (ours)	71.2 ± 0.3%	55.1 ± 0.61%	70.6 ± 0.3%	54.7 ± 0.0%
samples for each group are 71,629 “dark hair, female”, 66,874 “dark hair, male”, 22,880 “blond hair,
female”, 1,387 “blond hair, male”.
CivilComments (Borkan et al., 2019; Koh et al., 2021): We use CivilComments from the WILDS
benchmark (Koh et al., 2021). CivilComments is a text classification task, aiming to predict whether
an online comment is toxic or non-toxic. The spurious domain identifications are defined as the
demographic features, including male, female, LGBTQ, Christian, Muslim, other religion, Black,
and White. CivilComments contains 450,000 comments collected from online articles. The number
of samples for training, validation, and test are 269,038, 45,180, and 133,782, respectively. The
readers may kindly refer to Table 17 in Koh et al. (2021) for the detailed group information.
Table 14: Dataset Statistics for Subpopulation Shifts. All datasets are binary classification tasks and
we use the worst group accuracy as the evaluation metric.
Datasets	Domains	Base Model	Class Information
CMNIST	2 digit colors	ResNet-50	digit (0,1,2,3,4) v.s. (5,6,7,8,9)
Waterbirds	2 backgrounds	ResNet-50	waterbirds v.s. landbirds
CelebA	2 hair colors	ResNet-50	man v.s. women
CivilComments	8 demographic identities	DistilBERT-uncased	toxic v.s. non-toxic
A.2.2 Training Details
We adopt pre-trained ResNet-50 (He et al., 2016) and BERT (Sanh et al., 2019) as the model for
image data (i.e., CMNIST, Waterbirds, CelebA) and text data (i.e., CivilComments), respectively.
In each training iteration, we sample a batch of data per group. For sample selection strategy I, we
randomly apply mixup on sample batches with the same labels but different domains. For sample
selection strategy II, we instead apply mixup on sample batches with the same domain but different
labels. The interpolation ratio λ is sampled from the distribution Beta(2, 2). All hyperparameters
are listed in Table 15.
16
Under review as a conference paper at ICLR 2022
Table 15: Hyperparameter settings for the subpopulation shifts.
Dataset	CMNIST	Waterbirds	CelebA	CivilComments
Learning rate	1e-3	1e-3	1e-4	1e-5
Weight decay	1e-4	1e-4	1e-4	0
Scheduler	n/a	n/a	n/a	n/a
Batch size	16	16	16	8
Type of mixup	mixup	mixup	CutMix	ManifoldMix
Architecture	ResNet50	ResNet50	ResNet50	DistilBert
Optimizer	SGD	SGD	SGD	Adam
Maximum Epoch	300	300	50	3
Strategy sel. prob. psel	0.5	0.5	0.5	1.0
A.2.3 Additional Results
In this section, we have added the full results of subpopulation shifts in Table 16 and Table 17.
Table 16: Full results of subpopulation shifts with standard deviation. All the results are performed
with three random seed.
	CMNIST		Waterbirds	
	Avg.	Worst	Avg.	Worst
ERM	27.8 ± 1.9%	0.0 ± 0.0%	97.0 ± 0.2%	63.7 ± 1.9%
UW	72.2 ± 1.1%	66.0 ± 0.7%	95.1 ± 0.3%	88.0 ± 1.3%
IRM	72.1 ± 1.2%	70.3 ± 0.8%	87.5 ± 0.7%	75.6 ± 3.1%
Coral	71.8 ± 1.7%	69.5 ± 0.9%	90.3 ± 1.1%	79.8 ± 1.8%
GroupDRO	72.3 ± 1.2%	68.6 ± 0.8%	91.8 ± 0.3%	90.6 ± 1.1%
DomainMix	51.4 ± 1.3%	48.0 ± 1.3%	76.4 ± 0.3%	53.0 ± 1.3%
Fish	46.9 ± 1.4%	35.6 ± 1.7%	85.6 ± 0.4%	64.0 ± 0.3%
LISA	74.0 ± 0.1%	73.3 ± 0.2%	91.8 ± 0.3%	89.2 ± 0.6%
	CelebA		CivilComments	
	Avg.	Worst	Avg.	Worst
ERM	94.9 ± 0.2%	47.8 ± 3.7%	92.2 ± 0.1%	56.0 ± 3.6%
UW	92.9 ± 0.2%	83.3 ± 2.8%	89.8 ± 0.5%	69.2 ± 0.9%
IRM	94.0 ± 0.4%	77.8 ± 3.9%	88.8 ± 0.7%	66.3 ± 2.1%
Coral	93.8 ± 0.3%	76.9 ± 3.6%	88.7 ± 0.5%	65.6 ± 1.3%
GroupDRO	92.1 ± 0.4%	87.2 ± 1.6%	89.9 ± 0.5%	70.0 ± 2.0%
DomainMix	93.4 ± 0.1%	65.6 ± 1.7%	90.9 ± 0.4%	63.6 ± 2.5%
Fish	93.1 ± 0.3%	61.2 ± 2.5%	89.8 ± 0.4%	71.1 ± 0.4%
LISA (ours)	92.4 ± 0.4%	89.3 ± 1.1%	89.2 ± 0.9%	72.6 ± 0.1%
A.3 Results on Datasets without Spurious Correlations
In order to analyze the factors that lead to the performance gains of LISA, we conduct experiments
on datasets without spurious correlations. To be more specific, we balance the number of samples
for each group under the subpopulation shifts setting. The results of ERM, Vanilla mixup and LISA
on CMNIST, Waterbirds and CelebA are reported in Table 18. The results show that LISA per-
forms similarly compared with ERM when datasets do not have spurious correlations. If there exists
any spurious correlation, LISA significantly outperforms ERM. Another interesting finding is that
Vanilla mixup outperforms LISA and ERM without spurious correlations, while LISA achieves the
best performance with spurious correlations. This finding strengthens our conclusion that the perfor-
mance gains of LISA are caused by eliminating spurious correlations rather than data augmentation.
17
Under review as a conference paper at ICLR 2022
Table 17: Full table of the comparison between LISA and other substitute mixup strategies in sub-
population shifts. UW represents upweighting.
	CMNIST		Waterbirds	
	Avg.	Worst	Avg.	Worst
ERM	27.8 ± 1.9%	0.0 ± 0.0%	97.0 ± 0.2%	63.7 ± 1.9%
Vanilla mixup	32.6 ± 3.1%	3.1 ± 2.4%	81.0 ± 0.2%	56.2 ± 0.2%
Vanilla mixup + UW	72.2 ± 0.7%	71.8 ± 0.1%	92.1 ± 0.1%	85.6 ± 1.0%
In-group Group	33.6 ± 1.9%	24.0 ± 1.1%	88.7 ± 0.3%	68.0 ± 0.4%
In-group + UW	72.6 ± 0.1%	71.6 ± 0.2%	91.4 ± 0.6%	87.1 ± 0.6%
LISA (ours)	74.0 ± 0.1%	73.3 ± 0.2%	91.8 ± 0.3%	89.2 ± 0.6%
	CelebA		CivilComments	
	Avg.	Worst	Avg.	Worst
ERM	94.9 ± 0.2%	47.8 ± 3.7%	92.2 ± 0.1%	56.0 ± 3.6%
Vanilla mixup	95.8 ± 0.0%	46.4 ± 0.5%	90.8 ± 0.8%	67.2 ± 1.2%
Vanilla mixup + UW	91.5 ± 0.2%	88.0 ± 0.3%	87.8 ± 1.2%	66.1 ± 1.4%
Within Group	95.2 ± 0.3%	58.3 ± 0.9%	90.8 ± 0.6%	69.2 ± 0.8%
Within Group + UW	92.4 ± 0.4%	87.8 ± 0.6%	84.8 ± 0.7%	69.3 ± 1.1%
LISA (ours)	92.4 ± 0.4%	89.3 ± 1.1%	89.2 ± 0.9%	72.6 ± 0.1%
Table 18: Results on Datasets without Spurious Correlations
Dataset	ERM	Vanilla mixup	LISA
CMNIST	73.67%	74.28%	73.18%
Waterbirds	88.07%	88.23%	87.05%
CelebA	86.11%	88.89%	87.22%
B Proofs of Theorem 1 and Theorem 2
Outline of the proof. We will first find the mis-classification errors based on the population version
of OLS with different mixup strategies. Next, we will develop the convergence rate of the empirical
OLS based on n samples towards its population version. These two steps together give us the
empirical mis-classification errors of different methods. We will separately show that the upper
bounds in Theorem 1 and Theorem 2 hold for two strategies of LISA and hence hold for any psel ∈
[0, 1]. Let L1 denote selection strategy I of LISA method and L2 denote selection strategy II of
LISA method.
Let ∏ι = IP(yi = 1) and ∏o = IP(yi = 0) denote the marginal class proportions in the training sam-
ples. Let ∏b = P(di = B) and ∏g = P (di = G) denote the marginal subpopulation proportions
in the training samples. Let ∏g∣i = P (di = G|yi = 1) and define ∏g∣o, ∏b∣i, and ∏b∣o similarly.
We consider the setting where α := π(1,G) = π(0,B) is relatively small and π(1) = π(0) = π(G) =
π(B) = 1/2.
B.1	Decomposing the loss function
Recall that ∆ = μ(1,G) 一 μ(0,G) = μ(1,B) 一 μ(0,B). We further define ∆ = μ⑴ 一 μ(0), θ(G) =
μ(Oe) — E[xi], and θ(B) = μ(O，B)-的岛].
For the mixup estimators, we will repeatedly use the fact that λi has a symmetric distribution with
support [0, 1].
18
Under review as a conference paper at ICLR 2022
For ERM estimator based on (X, y), where bo = 2 - E[xi]Tb, We have
(μ(O，G))T b + bo = (μ(O，G)- E[Xi])T b +2
=(θ(G))T b + E[yi]
(μ(1,G))Tb + bo = (μ(1,G)- E[xi])Tb + 2
=∆T b +(θ(G))T b + E[yi],
Notice that based on the estimator b, bo
E(1,d) (b, bo) = Φ(
-∆Tb -(θ⑷)tb
√bT Σb
) and E(o,d)(b,bo) = Φ(
(θ(d))T b
√bT Σb )
B.2	Classification errors of four methods with infinite training samples
We first provide the limit of the classification errors when n → ∞.
B.2.1	Baseline method: ERM
For the training data, it is easy to show that
Var(X) = E[var(x∣y)] + Var(IE[x∣y])
=∑ + E[var(E[x∣y, D]|y)] + var((μ⑴一μ(0))y)
=∑ + E[var(μ(0,B) - 〃(0,G))I(D = B)|y)] + ∆02π(1)π(o)
=∑ + 1(μ(0,B) - μ(0,G))I82(∏b∣i∏g∣i + ∏b∣o∏g∣o) + ∆02∏α)∏(O)
cov(x,y) = CoV(IE[x∣y],y)
=cov(μ(O) + ∆ y,y)
= coV(∆e y, y) = ∆e π(1)π(O)
For a。= 1 (∏b∣i∏g∣i + ∏b∣o∏g∣o) and Δo = μ(0,G) - μ(0,B), the ERM has slope and intercept
being
b = Var(x)-1coV(x, y)
(X (∑ + ao∆^2)-1∆
=ς-i∆ _ ς-iδ	aoXTς-1δo
=	o ∙ 1 + ao∆TΣ-1∆o
bo = E[y] — E[xT b].
In the extreme case where πo,B = π1,G = 0, we have
∆ = μ(1,B) - μ(O,G),θ(G) = - 1∆,θ(B) = 1∆ - ∆, and ∆o = ∆ - ∆.
Hence,
Eo(wst) = max{Φ
「), Φ (√S)}
(5)
where b is computed via ERM.
B.2.2	Baseline method: Vanilla mixup
The vanilla mixup does not use the group information. Let i1 be a random draw from {1, . . . , n}.
Let i2 be a random draw from {1, . . . , n} independent of i1. Let
yi = λiyiι + (I - λi)yi2
19
Under review as a conference paper at ICLR 2022
and
Xi = λixiι + (I - λi)xi2 .
We can find that
Cov(Xi,yi) = cov(λiXiι +(1 - λi)xi2 ,λiyiι +(1 -入力期匕?)
= cov(λixi1,λiyi1) + cov((1 - λi)xi2, (1 - λi)yi2)
=(E[λ2] +E[(1 - λi)2])cov(xi,yi).
Cov(Xi) = (E[λ2] + E[(1 - λi)2])cov(xi).
Hence, the population-level slope is the same as the slope in the benchmark method. It is easy to
show that the population-level intercept is also the same. Hence,
(wst)	(wst)
Emix = E0	.
B.3	LISA with Selection S trategy (LISA-II): mixup within each class
Define
Xi(λ) = λiXi(1yi,G) + (1 - λi)Xi(2yi,B)
where i1 is a random draw from {l : yl = yi, Dl = G} and i2 is a random draw from {l : yl
yi, Dl = B}. Then we perform OLS based on (Xi(λ), yi), i = 1, . . . , n.
We can calculate that
cov(x(λ),yi) = Cov(IE[x(λ)∣yi],yi) = cov(1 μ(yi,G) + 1 μ(yi,B),yi)
= var(yi)∆ = π(1)π(0)∆
cov(x(λ)) = E[cov(x(λ)∣yi, λi)] + Cov(IE[x(λ)∣yi, λi])
=2E[λ2]Σ + cov(λi(μ(OC)- μ(0,B)) + ∆y)
=2E[λ2]Σ + var(λi)(μ(0,G) -仙(°，B)产 + π⑴π⑼△嫡
Notice that
叫 X(λ)] = 4(μ(0,G)+1+μ(0,B)+「∣(μ(0,G)+产B=叫词.
For aLi = var(λi)∕(2E[λ2]) and ∆0 = μ(0,G) - μ(0,B), the OLS has slope and intercept being
b = var(Xi(λ))-1Cov(Xi(λ) , y)
(X (∑+Vi^(NG)-"，B)产)-1∆
(X ∑-1∆ - ∑-1∆o ∙	aLH∑-1δo
0 1 + aLi∆T ∑-1∆o
bo = E[y] - E[(x(λ))Tb].
EL(w1 st) = max{Φ
(1 △ - ∆)Tb
√bτΣb
(6)
, Φ M },
where b is computed based on (Xi(λ), yi), i = 1, . . . , n.
B.4	LISA with Selection S trategy II (LISA-II): mixup within each Domain
The interpolated sample can be written as
(yi,Xi) = (λi,λiX(1,G) + (1- λi)x(0,G)) if di = G
(yi, Xi) = (λi, λiX(1,B) + (1 - λi)x(0,B)) if di = B,
20
Under review as a conference paper at ICLR 2022
where iι is a random draw from {l : dι = d%,yi = 1} and i2 is a random draw from {l : a
di, yi = 0}.
We consider regress yi on Xi.
cov(Xi,yi∖di = G) = cov(^E[xi∖iji,di = G],yi∣di = G) = vαr(yi)(μ(1,G) - μ(0,G))
Var(XiIdi = G) = !E[vαr(Xi∖, %, Di = G)∖di = G] + Var(IE[X∕, %, di = G]∖R = G]
=2E[λ2]Σ + Var(%μ(Ie) + (1 - %)μ(Oc)Idi = G)
=2E[λ2]∑ + vαr(yi)∆02.
We further have
COV(Xi,yi) = E[cov(Xi,yi∣di)] + COV(IE[Xi∣di], E[yi∣di])
=coV(XiG), y(G))n(G) + COV(X(B), y(B))π(B)
=Var(yi)(μ(1,G) — μ(0,G))π(G) + Var(yi)(μ(1,B) — μ(0,B))π(B)
=Var(yi)∆.
Moreover,
Var(Xi) = E[Var(Xi∣di)] + Var(IE[Xi ∣di])
=Var(X(G))π(G) + Var(X(B))π(B) + (1E[X(G)] — 1E[X(B)]尸 2π(G)π(B)
=2E[λ2]Σ + Var(λi)∆02 + (小0，G)-小0，B)产2n(G)n(B).
Slope:
b = Var(Xi)-1coV(Xi, yi)
x (Σ + aL2∆f2)-1∆
二…-…。∙ 1二工々0,
,	π(B)π(G)
where aL2 = π2WJr.
Moreover, b0 = E[yi] - E[Xi]τb = ɪ - E[Xi]τb. Notice that
E[Xi ] = ；(〃◎G) + 〃(1，G) + 〃(0，B) + 〃(1，B))
= ；(2〃(0，G) +∆ + 2〃0,B)- ∆)
= 1(μ(0,G) + 〃(1，B))=IE[Xi].
Hence,
(1 ∆ - ∆)Tb
ELwSt) = max{Φ
√bTΣb
-2∆ T b
√bTΣb
},
(7)
where b is computed based on (Xi,yi), i = 1,..., n.
Method comparison. We only need to compare (5), (6), and (7).
For the ERM, 0 ≤ a° ≤ 2α and
b = (1+ 标TK1A )Σ-1 ∆ - aST∑-1∆
= (1+ 1 + a0∆TΣ-1∆0 )Σ	1 + a0∆TΣ-1∆0
(X Σ-1∆ -
a0∆T Σ-1∆0
1 + a0 ∆T Σ-1∆0 + a0∆ T ∑-1∆0
Σ-1∆
X Σ-1∆ -	aa'T三丛: Σ-1∆.
1 + a0 ∆t Σ 1∆0
,Φ
21
Under review as a conference paper at ICLR 2022
Let c0 =号燃&:整 and c1 = ∣c0∣∣∣∆∣∣∑∕k∆∣∣ς. For SimPliCity, let ∣∣v∣∣∑ = vτΣ-1v. We first
lower bound it via
	ʌ- b	b∖	b ∆ cor(bERM, ∆) = —7^	, (E	)	∣∆k∑√bτΣb	ʌ- 	 ʌ- 	 ʌ- _ ∆TΣ-1 ∆ - C0∆τΣ-1∆ =	∣∆ k∑ √bτΣb ∆ T Σ-1∆	∣c0∆τ Σ-1∆ ∣ > R	R	R	I 	 _ k∆k∑(∣∣∆∣∣∑ + ∣C0∣∣∆∣∑)	k∆ k∑√bτΣb 、	1	。0冬公氐 							 1 + ∣C0∣∣∆∣∑∕∣∆k∑	k∆k∑ -C0∣∆∣∑ >	1 - (1 + ξ)c1 - c1	1 c >	-T-I- = 1 - Ca
Similarly, we have
cor(bERM, ∆)
bτ∆	_ ∆τΣ-1∆ - C0∆τΣ-1∆
k∆k∑√bτΣ =	k∆k∑√bτΣ
/	∆T Σ-1∆	∣c0∆τ Σ-1∆∣
≤	+
I∣∆k∑(∣∣∆k∑ ± C0∣∣∆∣∣∑)	(k∆k∑ -C0∣∣∆k∑)∣∣∆k∑
■~■
1	° ,	C0∣∆k∑∕k∆k∑
■~■	ξ ~∖	■~■
1 ± C0∣∆k∑∕k∆k∑	1-C0∣∣∆k∑∕∣∣∆ k∑
≤ (
ξ
1 ± C1
-τ⅛23
Hence,
F(WSt)
EERM
> max
卜((2
1
-CO)k∆k∑ - (ξ - Cα)k∆k∑), Φ((-2 + Cα)k∆k∑))
(8)
for some constant C depending on the true parameters.
For method LISA-I, using the fact that ∆0 = ∆ - ∆,
	bL1 (X (1 -	aL1△:)Σ-1∆+	2：Σ-1∆ 1 + «L1 ∆0 Σ 1∆0	1 + aL1∆0 Σ 1∆0 X Σ-1∆ + CL1Σ-1∆
for	=1 + aL1∆τΣ-1∆0 - aL1∆τΣ-1∆0 CLI=	αL1∆τ Σ-1∆0	.
Hence,	G 八	∆ T bL1	ll∆ ll∑ + CL10AM cor(bL1, ∆) == k∆ ∣∣∑,bT1ΣbL1	忸 + %1因工 COr(M ∆)=	bTA	= 6/3公限 + CL1I△归 k∆k∑qT1ΣbL1 =	I∆k∑∣∆ + CL1∆k∑	.
To have ELWSt) ≤ EEwMt), it suffices to require that (-2 - Cα)∣∣∆∣∣∑ ≤ (ɪ - Cα)∣∣∆∣∣∑ - (ξ +
Cα)∣∣∆∣∣∑ and
11
2cor(bL1, ∆)∣∣∆∣∣∑ - cor(bL1, ∆)∣∣∆∣∣∑ ≤ (2 - Cα)∣∆∣∑ - (ξ + Cα)∣∣∆∣∣∑
11
-Dc"(bL1, ∆)∣∣∆∣∣∑ ≤ (- - Ca)II∆∣∣∑ - (ξ + Ca)Il∆∣∣∑.
22
Under review as a conference paper at ICLR 2022
A sufficient condition is
1	1	∣∆e ∣Σ
ξ ≤ (2 + 2cor(bL1, △))∣δ------------Ca, cor(bL1, ∆) ≥ ξ + Ca, cor(bL1, ∆) ≤ 1 一 2Ca.
We can find that a further sufficient condition is
e
ξ ≤ η-vη----Cα,cLi > 0,ξ ≤
k∆kΣ
k∆ + cL1∆kΣ - k∆kΣ
k∆e + cL1∆kΣ ≥ k∆ekΣ, ξ≤
cL1k∆kΣ
cL1k∆kΣ
(9)
—T------------------------------------T--------- — f 1 a
√<∙t**	√*∙t**	V- I ,L--⅛
k∆e + cL1 ∆kΣ - k∆e kΣ
(10)


- 1 α

1	1	k∆kΣ
ξ ≤ (5 + 5cor®, ∆))心-Ca.	(
2	2	k∆kΣ
We first find sufficient conditions for the statements in (9) and (10). Parameterizing t
Cli 11 △ 11 ς /11 △ k∑, we further simplify the condition in (9) and (10) as
IlAll-	≠
ξ ≤ L⅛ς — Cα,t > 0, - I ≤ ξ ≤ t
k∆kΣ	2
(11)
ξ≤
- 1α, ξ ≤
t+2ξ
- 1α.
We only need to require
t ≥ 2 and ξ ≤ min{
k∆e kΣ
k∆k∑,
1} - Cα.
Some tedious calculation shows that t ≥ 2 can be guaranteed by
1	11
2I∣δ∣I∑ ≤ I∣δ∣I∑ ≤ √3ajj or 2I∣δ∣I∑ ≥ IAM
It is left to consider the constraint in (11). Notice that it holds for any ξ ≤ 0. When ξ > 0, we can
see
t
cor(bL1, ∆e )
≥
∣∣δ ∣∣∑ + &liIAM
k∆ + CLl∆∣∑
仁≥ξ.
1+t
Hence, it suffices to guarantee that


(1 -
1 k∆⅛ )ξ< 1 k∆⅛
2 k∆k∑)ξ< 2 k∆k∑
1 + tξ
- Cα.


If∣∆k∑/∣∣∆∣∣∑ ≥ 2, then LHS is negative and it holds. If 1 ≤ ∣∣∆k∑∕k∆∣∑ < 2, then the inequality
becomes ξ ≤ 1 一 Ca. If ∣∆∣∣∑∕k∆∣∑ < 1, then the inequality becomes ξ ≤ k∆⅛ - Ca. Because
We have required ξ ≤ min{	,1} - Ca for some large enough C, the constraint (11) always
holds. To summarize, El1 ≤ EERM given that ξ ≤ min{号时,1}- Ca for some large enough C
and ∣δ∣∣ς ≤ √⅛∙
For method LISA-II, we can similarly show that EL2 ≤ EERM given that ξ ≤ min{ ∙∣∆∣∑, 1} - Ca
1
for some large enough C and ∣∣∆∣∣∑ ≤ √3=.
B.5 Finite sample analysis
The empirical loss can be written as
IP(I((XG))Tb + bo > 1)= y(G))
=2F((XG))Tb + bo > 1 Iy(G)= 0) + 21P((XG))Tb + bo < 2Iy(G) = 1),
(12)
23
Under review as a conference paper at ICLR 2022
where
IP((XG))Tb + b0 > 11y(G) = 0) = Φ(-1 TμJb -b0).
2	√bτ Σb
F((XG))Tb + bo < 11y(G) = I) = Φ(2 TpZb - b0).
2	λ∕^t v^
First notice that
We have
(μ(0,G))T b + bo = (μ(0,G)-X)T b + y
=(μQG) - E[xi])Tb + 1 + {(y - XTb) - (E[yi] - E[xi]Tb)}
2 '{z}
R1
(μ(1,G))Tb + bo = (μ(1,G) - x)Tb + y
=∆Tb + (μ0G)- E[xi])Tb + 1 + R1.
Therefore, according to (12),
1Φ(-2 -…T b - b0) + 1Φ( 1 -",G))T b - b0
C ∖	/ʌ ʌ	/	1 Q ∖	/ʌ ~
2	VbT Σb	2	VbT Σb
_1 ①Jθ(G))Tb + R1^ , 1φz △+ (θ(G))Tb + R1.
=2φ( ρT∑b )+ 2φ(--p≡ —)
=1(θ(G))T b + R1
2 (
/ʌ_ ʌ
VZbT Σb
)+2φ(-
(θ(G))T b + Ri
/ ʌ  ʌ
√bT Σb
)
fι* (θ(G))Tb + Ri	I* ∆ + (Θ(G))Tb + Ri 1
-oφ() - 3φ()
[2	VZbT Σb	2	VZbT Σb	J
1	(ιφr (θ(G))tb + Rj Iφr ∆Tb + (θ(G))Tb + Ri
2	-L E )- 2φ(	pτ∑-)
Then the mis-classification error can be written as
1	1 ∫av(θ(G))T b + Ri)5(θ(G))T b - ∆τ b + Ri
2	- 2 产	√bτ∑b )- φ( —pτ∑ 一)
S------------------V-----------------
L(b)
(13)
τ	..?/八	„	..	.	C ..
Larger the L(b), smaller the mis-classification error.
We first find that
^ ʌ, .. .
L(b) - L(b) ≤ C |
(θ(G) )τb + Ri
√bτ Σb
(θ(G))Tb	(θ(G))Tb - ∆τb + Ri _ (θ(G))Tb - ∆τb
√bτ∑b ।+ ।	√T∑	√bτΣb 一 |
J 、	一一 一	)
In the event that
∣∣ΣiS(b - b)k2 = o(1) max ∣∣μ(y,d)∣∣2 ≤ C, Σ is positive definite.
y,d
24
Under review as a conference paper at ICLR 2022
for the denominator, we have
|bτ∑b - bT∑b∣ ≤ (2∣∣∑1∕2b∣∣2 + k∑1∕2(b - b)∣∣2)k∑1∕2(b - b)∣∣2
≤ 2(1 +。⑴)∣∣∑1∕2b∣∣2k∑1∕2(b -b)∣∣2
I VZbT ∑b - √bτ ∑b ∣ ≤
IbT ∑b - bτ ∑b∣
VZbT ∑b + √bτ ∑b
≤ 2(1 +。⑴)k∑1∕2(b -b)∣∣2.
For the numerator, we have
11∆Tb + Ri - 1∆Tb∣ ≤∣R1∣ + 2k∑τ∕2∆∣∣2∣∑1∕2(b-b)∣2.
We arrive at
Ti ≤ (1 +。⑴)
∣R1∣ + 2 k∑τ∕2∆ ∣∣2 k∑1∕2(b - b)k
k∑"b∣∣2
-+ (1 + o(1))
∣∆Tb∣ k∑1%b - b)∣∣2
VbT ∑b	VbT ∑b
T ≤(1 + o(1))
∣R1∣ + 2(∣∣∑τ∕2∆∣∣2 + ∣∣∑τ∕2∆∣∣2)∣∣∑1∕2(b - b)∣∣2
+ (1 + o(i))
〜	k∑1∕2b∣∣2
12∆Tb - atb∣ ∣b - b∣2
Moreover Ri ≤ ∣∣b - b∣∣2 + OF(√n). To summarize,
.-ʃ '- . 一 . .................,,
∣L(b)- L(b)∣ < (1 + °(1))(∣∣b-b∣∣2 +
In the following, we will upper bound ∣∣b - b∣2 for each method. For the ERM method,
b = {(X - X)T (X - X)}T(X - X)T (y - y).
It is easy to show that
kb - b∣2 = Of(PEN「叫=Of(N).
For the vanilla mixup method, we first see that
1 二
-X xi
n
i=1
1 n
1X y
n
i=1
1 J	”	”
~〉：(％xii + (1 — λi)xi2) = x + OF(n	) = μ + OF(n	)
i=1
π ⑴ + OF (n-1/2).
Next,
1 n
1
一 > xiyi
n
i=1
1 n
n〉: {λi xiiyiι + (1 - λi) xi2yi2 + λi(1 - λi)xiιyi2 + λi(1 - λi)xi2yii }
1 n
-V"xiyi - E[xiyi]
n i=1
i=1
1 n
1X
n i=1
Xiyi - E[xiyi∣X, y] + E[xiyi∣X, y]-册[必词.
{z,
Ei
{z*
E2
√F∑b	√F∑b
O ,0
I
,
O
,
For E2,
n
E2
2E[λ2]
Exiyi - E[≡iyi] = 2E[λ2]E[xiyi].
i=1
n
25
Under review as a conference paper at ICLR 2022
Hence,
kE2k2=OP (n).
For Ei, conditioning on (X, y), λ2xiιy” - 回n> Ρ2ι "i are independent SUb-GaUssian vectors.
The sub-Gaussian norm of N £3 入^gy%、— 5^1 £3 xi,jyi (conditioning on (X, y)) can be
upper bounded by C maχi≤N ∣xi,j ∣/√n. Hence
p(kEik2 ≥ tX,y) ≤ 2exP{-maxp=ιcmt2i≤N x2'j }.
As xi,j are Gaussian distributed, we know that
p
p(ɪ^ max x2j ≥ P log n) ≤ exp{-c3 log n}.
j=1 i≤n
Hence, with probability at least 1 - exp(-c1 log n),
CPlogn
Ei ≤ ---------.
n
To summarize,
1 n	1 n 1 n
-Xxiy/i - (— Xxi)(— Xyi) - cov(xi,y%)
n	nn
i=i	i=i	i=i
Similarly, we can show that
2
=OP (3).
n
2
1n
1T
-Xxixi
n
i=1
i=1
i=1
2
=OP (a).
n
2
Hence,
,∣∣2 C (P log n∖
kb- bk2 = OP ( — ).
For the LISA-L We first see that
1X x(λ) = n X (λix(i,G) + (1 - λi)x(i,B)) +1X (λix(0,G) + (1 - λi)xi0,B))
i=i	yi=i	yi=0
=g(x(1,G) + x(1,B))∏ι + g(x(0,G) + x(0,B))∏0
We have
nn
—(X(λ))τy - y- Xxi - cov(xi ),y%) = —(X(λ))Ty - y- Xxi ) - cov(xi ∖yɪ∣X,y)
n	ni	i	n	ni	i
i=i	i=i
X-----{-----}
E1
+ cov(xi , yi|X, y) - cov(xi ,yi)
'------------------V-----------------}
E2
For E2,
E2 = ∏21 (x(1,G) + x(1,B)) - ∏ι(∣(x(1,G) + x(1,B))∏ι + 1(x(0,G) + x(0,B))∏0) - cov(x(λ),y%)
=1(x(1,G) + x(1,B) - x(0,G) - x(0,B))∏ι∏0 - ∏⑴∏(0)∆.
It is easy to shoW that
kE2 ∣∣2 = OP (----——7 r).
kmιny,e n(y,e) J
26
Under review as a conference paper at ICLR 2022
For Ei, conditioning on X and y, χiλ)yi - E[x(λ)yi∣X,y] are independent SUb-GaUssian vectors
with mean zero. The sub-Gaussian norm of * Pn=I x( j)yi (conditioning on X and y) can be upper
bounded by C maxi≤n |xij ∣∕√N.
p1n
∑∣1 ∑{x(j)yi- E[x(j)yi∣X,y]}∣2 ≥ t2∣X,y
j =1 n i=1
≤ 2exp (-Pp~~c2nt-----).
j=1 maxi≤n xi2,j
Hence,
To summarize,
Ei = OP(ʌ尸=i maxi≤n x2j ) = OP(X).
nn
k 1(X(I))Ty-叫χ(%]k2 = OP( . Pse) + pɪogn)∙
n	miny,e n(y,e)	n
We can use similar analysis to bound
kN(X(I))TX(λ) -叫X(I)(X(I))T]k2.
The sub-exponential norm of 焉 PN=I x(j)xi? (conditioning on X) can be upper bounded by
maxi≤N |xij ∣∣Xi,k ∣∕√N. We can show that
k 1(X (λ))T X (λ) -叫 X(I)(X(I))T]k2 =OP ( . P (y e) + Plogn ).
n	miny,e n(y,e)	n
For the LISA-IL We first see that
1XXXi = 1 X (λiχi1,G) + (1 - λi)χ(0,G)) +1 X (λiχ(1,B)+ (1 - λi)xi0,B))
i=i	Di=G	Di=B
2(X(1,G) + X(0,G))∏G + 1(X(1,B) + X(0,B))∏B
1
y
2
Next,
1n
1
一 > Xiyi
n
i=i
1n
一Y' Xiyi - Xy - cov(x, y)
n
i=i
1 X {λ2*,G) + λi(i-%)x(0，g)} + 1 X {λ2*,B) + λi(1 -%)x(0，b)}
n Di=G	n Di=B
1n
n∑Xiyi - Xy - Cov(Xi,y∕X, y) + Cov(Xi,y∕X,y) - Cov(Xi,yj.
:i=1_______________________, `------------{-----------}
X--------------{-----------'	E 2
E1
For E2,
E2 =必?E后回1,G)- X(0,G)) + 1 X(0,G)) + 分⑻㈣入2]^1,B)- X(0,B)) + 1 X(0,B))-
；(X(1,G) + X(0,G) )∏G — ；(X(i,B) + X(0,B))∏B - var(λi)∆
=Π(G)var(λi)(X(1,G) — X(0,G)) + ∏(B) var(λi)(X(1,B) — X(0,B)) - var(λi)∆.
Notice that E2 is a sub-Gaussian vector with sub-Gaussian norm upper bounded by
2222
∏2	∏2	∏2	∏2	4	∏d
GIGIBIB- ≤ max
n(1,G) + n(0,G) + n(1,B) + n(0,B) ≤ n *著 ∏y∣d .
27
Under review as a conference paper at ICLR 2022
Using sub-Gaussian concentration, we can show that
E2
OP(ʌ /p max πd-).
V n y,d πy∣d
Notice that maxy,d ∏πd~^ ≥ 1. For Ei, conditioning on X and y Xiyi - E[Xiyi∣X, y] are independent
SUb-GaUssian vectors with mean zero. The SUb-GaUssian norm of n P2i Xi,jyi conditioning on X
and y can be upper bounded by c maxi,j |xi,j |. Similar analysis on E1 leads to
1n
1X
i=1
Xiyi- Xy - cov(χ,y) = OP (
P max 工).
n y,d ∏y∣d
For the sample covariance matrix, we can also show that
1n
1T
-5 χiχi
i=1
n
—
i=1
1n
1X
i=1
—Cov(Xi)
B.6 Domain shifts: Proof of Theorem 2
2
2
OP(
P max ∏dL).
n y,d πy∣d
It still holds that △ * = 2(μ(0,*) - E[x(λ)]) = 2(μ(0,*) - E[Xi]). It is easy to show that the worst
groUp mis-classification error for this new environment is
EAwst,*) = max J Φ I 1 (△ *)TbA I , Φ
I qT∑A^J
2(△ *)tbA - ∆TbA
JbA ς%
(14)
where A ∈ {ERM, mix, L1, L2}. Notice that
△ * = 2μ(0,*) - (μ(0,G) + μ(1,B)) = △ + 〃(0，*)- 〃(0，G)
..≈ . .. .. ≈ ..
Weassume !!△*k2 = ∣∣^k2. Letξ*


cor(∆, △*) and Y = cor(∆, △*). We have


cor(bERM, △*)
γ∣∣∆k∑k∆*k∑ -coξ*k∆k∑∣∣∆*k∑


k∆* k∑k∆ + co∆k∑
γk∆ekΣ
k∆k∑ ±kco∆k∑
±
∣coξ*lk∆k∑
k∆k∑ ±kco∆k∑
γ ± Cα.
Hence,
EEwMt) ≥ max {φ((2 - Cα)k^k∑ - (ξ -。。)|出|工),Φ((-2 - Cα)∣^∣∣∑)}
for some constant C depending on the trUe parameters.
(15)
Hence,
cor(bL1, △e*)
(△ *)T bL1
/ *k∑q*1∑bL1
Yk△ k∑ + CL**kA|£
区 + CliAIe
To have ELwst*) ≤ EEwMt*), it suffices to require that (-2 - Ca)∣∆∣ς ≤ (2 - Cα)∣∆∣ς - (ξ +
Ca)∣∆∣∑ and
1Y
2cor(bL1, △ *)∣∆∣∑ - cor(bL1, ∆)k∆∣∑ ≤ (2 - Cα)∣∆k∑ - (ξ + Ca)∣∆∣∑
1Y
-2cor(bL1, △ *)k∆k∑ ≤ (2 - Cα)k∆∣∑ - (ξ + Ca)∣∆∣∑.
A sUfficient condition is
ξ ≤ (2 + 1 cor(bL1, △ *)) ∣∣δ∣∣∑ - Cα, cor(bL1, △) ≥ ξ + Cα, cor(bL1, △ *) ≤ Y - 2Cα.
28
Under review as a conference paper at ICLR 2022
We can find that a further sufficient condition is
一'~■一
1 W 1+ Y IAM _ C 0 CY
ξ ≤ -1- k∆∑ - Cα,cLI > 0,ξ ≤
γ(k∆ + cL1∆kΣ - k∆kΣ)
cL1 k∆kΣ
(16)
k∆ + cL1∆kΣ ≥ k∆kΣ, ξ≤
cL1 k∆kΣ
—-----------——6ι α
I∆e + cL1 ∆IΣ - I∆e IΣ
(17)


- 1 α



ξ ≤ (2+1 CMbL1, δ *)) PiB -Cα∙
(18)
We first find sufficient conditions for the statements in (9) and (10).
cli∣∣Δ∣∣ς∕∣∣Δ∣∣ς, We further simplify the condition in (16) and (17) as
..~..	/--------------
Parameterizing t
1+ γk~YIAM c t o c*
ξ ≤ -1-Pk∑ - Cα,t > 0, ξ ≤
γ(√1+12 +2tξ - 1)
t
- 1α,
-1 ≤ ξ ≤ t, ξ ≤
t+ 2ξ
- 1α.
We only need to require
t ≥ 2 and ξ ≤ min{审鲁，1}- Ca, ξ* ≤ 卡.
Some tedious calculation shoWs that t ≥ 2 can be guaranteed by
1	11
2∣∣δ∣∣∑ ≤ ∣∣δ∣∣∑ ≤ √3- or 2I∣δ"∑ ≥ IAM
It is left to consider the constraint in (18). Notice that it holds for any ξ ≤ 0. When ξ > 0, We can
see
cor(bL1, ∆e *)
YI∆e IΣ + ξ*cL1 I∆IΣ
Y + tξ*
≥
I∆e + cL1∆IΣ
Y + tξ*
1+1 .
Hence, it suffices to guarantee that
ξ* + Y ≥ 21δς ξ + Ca
一 k∆k∑
To summarize, it suffices to require

"N 1ς ≤ √⅛, 0 ≤ ξ* ≤ γξ,ξ ≤ min{ Y W∑, 1}- Cm
For LISA-II, We can similarly show that ELwSt ≤ EEwMt* given that
iδ k∑ ≤√⅛,0 ≤ ξ*≤ γξ,ξ ≤ min{Y 鲁
Σ
,1}-Cα.
29