Under review as a conference paper at ICLR 2021
On the interventional consistency of autoen-
CODERS
Anonymous authors
Paper under double-blind review
Ab stract
Autoencoders have played a crucial role in the field of representation learning
since its inception, proving to be a flexible learning scheme able to accommo-
date various notions of optimality of the representation. The now established idea
of disentanglement and the recently popular perspective of causality in represen-
tation learning identify modularity and robustness to be essential characteristics
of the optimal representation. In this work, we show that the current concep-
tual tools available to assess the quality of the representation against these criteria
(e.g. latent traversals or disentanglement metrics) are inadequate. In this regard,
we introduce the notion of interventional consistency of a representation and ar-
gue that it is a desirable property of any disentangled representation. We develop
a general training scheme for autoencoders that takes into account interventional
consistency in the optimality condition. We present empirical evidence toward the
validity of the approach on three different autoencoders, namely standard autoen-
coders (AE), variational autoencoders (VAE) and structural autoencoders (SAE).
Another key finding in this work is that differentiating between information and
structure in the latent space of autoencoders can increase the modularity and in-
terpretability of the resulting representation.
1	Introduction
Representation learning is the problem of finding a low dimensional description of the data. The
characteristics ofa ’good representation’ have long since been a matter of debate, often depending on
the context in which the representation has to be employed. Multiple works (cf. Bengio et al. (2013),
ScholkoPf et al. (2021)) identify modularity, robustness to distribution shifts and interpretability as
crucial features of a ’good representation’, motivating the quest toward disentanglement (Bachman
et al. (2019), Locatello et al. (2020), Ridgeway & Mozer (2018)) and causal rePresentations (Suter
et al.(2019), TraUble et al. (2021)). The insight shared by both these fields is that complex world
Phenomena arise from the ’rich interaction of many sources’, and thus enable comPact descriPtions
in terms of the basic components participating in their generative process. More formally, the hy-
pothesis is that there exist a set of semantically meaningful variables S and an arbitrarily non-linear
function G such that X = G(S1, ..., Sn), where X are the observations.
Autoencoders have played a crucial role in the field of representation learning since its inception.
Their success is largely due to their simplicity and surprising effectiveness. Mathematically autoen-
coders can be represented as the tuple (E : Rd → Rn, D : Rn → Rd). Capacity constraints (e.g.
n d) force the latent space to prioritize certain information in the input, thus yielding a useful
representation. Additional requirements may be imposed either structurally or through regularisa-
tion. Intuitively, consistency means that an input generated by the decoder can be mapped back to
the point in the latent space that produced it. The central idea of Cemgil et al. (2020) is making the
encoder and the decoder consistent both on the training data P(X) and on the auxiliary observations
generated by the decoder P (X0).
Our contribution. Unsupervised causal representation learning is largely unsolved today. In a
recent paper Locatello et al. (2019) prove that ’the unsupervised learning of disentangled represen-
tations is fundamentally impossible without inductive biases on both the models and the data’. Mo-
tivated by this result, in this work we, investigate the structure and in particular the self-consistency
1
Under review as a conference paper at ICLR 2021
of the learned autoencoder, rather than focusing on the representation’s relation to the ”groundtruth”
factors. In this context, we formulate an inductive bias for autoencoders, that we call interventional
consistency, and we link it to the solution space of the disentanglement problem. Additionally, we
introduce a new architectural module for the latent space of autoencoders which unifies the disen-
tanglement objective and the, more structured, causal perspective.
2	Method
Consider the ’artificial’ generative process implemented by
the decoder as X 〜P(Z)P(X|Z; θ). We express the latent
space dynamics in terms of a Structural Causal Model (SCM)
(Pearl, 2009) on Z. An SCM is defined by a set of so-called
noise variables N = N1, ..., Nn, with a distribution P(N)
that factorises, and a set of structural assignments f1, ..., fn
of the form:
Zi := fi(PAi,Ni) fori = 1, ..., n,	(1)
where PAi refers to the set of direct causes of the variable Zi .
The set of directed interactions between causal variables iden-
tifies a graph, which is usually assumed to be acyclic (i.e. a Figure 1: Diagram illustrating In-
DAG). This formulation naturally entails a distribution P(Z) terventional consistency: a change
and a corresponding causal factorisation:	in one of the factors participating in
P(Z) (i.e. F4) affects only one of
P(Z) =	P(Zi|PAi).	(2) the factors in P(Z0) (i.e. F20). The
i	response R maps Z to Z0 .
For a thorough introduction to SCM we refer the reader to Pe-
ters et al. (2017). We can now apply results from causality to the artificial generative process. In
particular, we turn to the ICM principle (Peters et al., 2017), which states that the modules partic-
ipating in the generative process are independent and can thus be separately manipulated. Let us
refer to the composition R = E ◦ D as the response map, as done in Leeb et al. (2021), mapping
the latent space Z ⊆ Rn back to itself, i.e. R : Z → Z. Let R(Z0 |Z) be the posterior distribution
entailed by the map, with Z, Z0 being distinct random variables. Furthermore, consider the response
aggregate posterior distribution and any factorisation thereof:
P(Z0) = P(Z)R(Z0|Z)dZ=YP(Zi0|Zj06=i).
i
The implications of the ICM principle are trivial if applied to thepriorP(Z): modifying P(Zi|PAi)
willnotaffectP(Zj|PAj) forj 6= i. However the consequences get far from trivial if we require the
response map to preserve the validity of the principle. LetP(Z) denote the intervention distribution:
P(Z) = P(ZmIPAm) ɪɪ P(Zi∣PAi).
i6=m
Then we say that the ICM principle is preserved by the response map if:
r
P(Z0) = I P(Z)R(Z0∣Z)dZ
P(Zk∖Zj=k) ∏P(z0∣zj=i),
i6=k
(3)
(4)
where the indices m and k are not necessarily equivalent, although we will from here on assume their
equivalence.1 Intuitively, R preserves the ICM principle if any localised change in P(Z) produces
a corresponding localised change in P(Z0). The idea is illustrated in Figure 1. Crucially, this
property mirrors the definition of disentanglement in the context of the artificial generative process:
each factor in the representation (P (Zk0 |Zj06=k)) is sensitive to changes in a single generative factor
(P(Zm|PAm)), while being relatively invariant to changes elsewhere in the generative process. This
1Allowing m 6= k essentially takes into account the possibility of permutation of the original space dimen-
sions in the representation, which is the norm in disentanglement metrics. By assuming m = k we get rid of
one degree of freedom in the problem.
2
Under review as a conference paper at ICLR 2021
尸♦尸N22N72222ZZZZZ
422Z2222222222222233
LLI:乙ZZZZZZ222222222
)))))J 1 J∙2Z222Z22N222
2 2 22ZZZ222— Ada= ">>****▼
&&&aaR222N222ZZZZZZZ
a S
6 (£>
b b
J G
b ⅛
A 4
4 L 必 b G Q
L-
L
b 6 6
to
L
6
L
L
6
L
L
υ4G
(a) AE
Figure 2: (Top) Traversals for autoencoder models on MNIST. (Bottom) Response error measured
on each of the six latent dimensions when traversing along the last dimension (= 5). Each line
(in different colors) represents a sample drawn from the aggregate posterior. The horizontal axis
tracks the dimension being traversed. The vertical axis records the difference between response and
original sample along the corresponding dimension. For unregularized models, the traversals are
performed in a range whose extremities are identified by the aggregate marginal posterior Q(Z).
Observe that the model equipped with consistency training exhibits significantly lower error upon
intervention than a standard autoencoder.
L)
b
Q
Q
4
(β
b
lo
6
(b) XCAE-I

LGQx⅛6

analogy suggests that the condition expressed in Equation 4 has to be satisfied by a representation
that disentangles the true generative process. We call this condition interventional consistency.
Interventional consistency can be formulated in terms of invariance and equivariance of the response
map. If the autoencoder satisfies interventional consistency, then P(Zi0|Zj0<i) is invariant to the ac-
tion of the group of interventions Im localised on P(Zm|Zj<m) with i 6= m. Moreover, assuming
we are able to perform an intervention on the response variables I0 equivalent to the one performed
on the prior I , the response map is equivariant to the intervention, meaning that the order in which
the response and the intervention are applied is not important. From this symmetry viewpoint, inter-
ventional consistency belongs to causal representations: ’the right causal order is the one invariant
to the right kind of interventions’ (Herb Simon, cf. Hoover (2008)).
Importantly, a representation that satisfies the interventional consistency condition does not neces-
sarily solve the identifiability problem (Gresele et al., 2021), as any bijective transformation of the
true causal factors would equally satisfy the condition for the correspondingly transformed inter-
ventions. Instead, it is manipulable by construction. Without this feature, there is no guarantee the
decoder can extrapolate to latent samples not seen during training. As an example, consider the
common diagnostic tool of latent traversals: it consists of atomic interventions applied to the differ-
ent dimensions of the representation. Often a good representation is associated with semantically
meaningful traversals in the image space. However, the observed result is only half of the story: if
the encoder fails to interpret the generated samples the representation cannot be called disentangled.
To illustrate this example, in Figure 2 we show the error recorded on the response to traversals on a
standard autoencoder.
2.1	Consistency training
It is possible to use the invariance or equivariance formulation to incorporate interventional consis-
tency into the solution space of an autoencoding problem. Let LINV(R) and LEQV(R) be real valued
functions measuring the violation of the invariance and equivariance property by the response map
R, respectively. Then the space of interventionally consistent autoencoders is defined as:
{(E, D) : LINV(E ◦ D) = 0 or LEQV(E ◦ D) = 0}.
3
Under review as a conference paper at ICLR 2021
This hard constraint is replaced with a differentiable regularization by augmenting the optimization
objective with LINV or LEQV. Next, we propose evaluation metrics that make the consistency penal-
ties easier to interpret. Algorithm 1 and 2 in the Appendix demonstrate how to compute LINV and
LEQV. Importantly, LINV is independent of the network architecture of choice, therefore it can be
applied to any existing autoencoder method with latent space N . Meanwhile, LEQV only requires an
explicit distinction between noises N and causes Z (of the artificial generative process) outlined in
the previous section, which, in our experiments, is implemented by the explicit causal latent block
(see 4).
Note some additional mild approximations are necessary to make the penalty terms tractable. Firstly,
we assume that the response aggregate posterior P (Z0) factorises like P (Z), i.e. that the statistical
dependencies in the prior are preserved by the response map. When using an autoencoder with ex-
plicit structural mappings this assumption is equivalent to assuming that the response aggregate noise
posterior P (N0) factorises. Secondly, we employ Monte Carlo sampling to estimate the consistency
by sampling hard interventions on the noise variable distribution of the form: P(Nm) J δ(v),
with v from the aggregate marginal posterior Q(Nm) = EX Q(Nm |X). Finally, in order to assess
equivariance we treat I0 = I, which relies on the equivalence between Z and Z0 . This assumption is
satisfied as long as the reconstructions are sufficiently similar to corresponding the training samples
(i.e. the autoencoder fidelity is high).
Below, Nk denotes a sample from the prior P(N) and Nk its intervened version. Moreover we let
A
〜
N0k and Nk0 be the expectation of the response to Nk and Nk, respectively. Let Nk0 be the result
kk
of the intervention I applied to N0k and We denote the corresponding causal variables by Z0k and
Zk
Invariance score. Let UIm be a measure of the magnitude of the intervention Im and σi the standard
deviation of each dimension in the response space. Then we define the invariance error in response
to the intervention Im recorded on the dimension i as
eim,i= U1σ EN [||(N 0 - NIm )il∣2].
Im i
More precisely we define UIm := EN [||(N 一 NIm)i|图.Consequently we score the invariance of
the i-th dimension with respect to interventions on the m-th dimension as:
INV[m,i] = 1 - EIm〜Im [eIm,i].	⑸
We approximate all the expectations with their Monte Carlo estimates. According to this formula-
tion, a perfectly invariant response map would score 1 on the off-diagonal elements of the matrix.
Notice that invariance is not concerned with the diagonal entries of the matrix. However, we can
interpret a high invariance score on the i-th diagonal element as a sign of the unresponsiveness of
the dimension as it implies interventions on i are not registered in the response. We henceforth
refer to these unresponsive latent dimensions with the appellative ”collapsed”, in reference to the
well-known effect of posterior collapse (rather common in βVAE models).
Equivariance score. Similarly, we define the equivariance error and equivariance score as :
TIm ,i = U EN [ll(ZIm - ZI m )^]
EQV [m, i] = 1 - EIm 〜Im [rIm,i].
In the case of equivariance perfect consistency corresponds to all the entries being 1. Notice however
that high equivariance is also obtained by the trivial solution (i.e. a constant encoding map). This is
due to the fact that the intervention values are sampled from the aggregate posterior.
Self-consistency score. Finally, the self-consistency score evaluates the response inner consistency
under no intervention. More specifically, we measure the amount of error introduced by the response
on average over the prior. In formula:
SCN[i] = 1 - ɪEN [||(N0 - N)i∣∣2]
σi
Importantly, self-consistency is the only score relating the prior and the response space and is closely
related to the regularization used by AVAEs (Cemgil et al., 2020).
4
Under review as a conference paper at ICLR 2021
Figure 4: Diagram comparing the structure of an autoencoder with (right) and without (left) the
Explicit Causal Latent Block. Instead of a single space modelling the representation, an XBlock
employs a noise or information space N and a causal or structure space Z.
2.2	Explicit Causal Latent Block
Inspired by the distinction between noise and structure in the SCM
we insert a similar bias into the latent space of autoencoders by di-
rectly joining the representation layer with a structural mixing block
as shown in Figure 4. We henceforth will refer to the botteneck layer
as noise terms or N, and to the units produced by the subsequent
mixing layer as causes or Z. Each Zi is obtained from its correspond-
ing noise term Ni and its predecessors Z<i through a learned non-
linear function fi , much like in an SCM (implemented as an MLP).
To increase the sparsity of the structure we apply a learnable mask
Mi ∈ R(i-1) to the parents , such that Zi = fi(Mi Z<i-1, Ni).
The masks are parametrised through the Gumbel trick (Jang et al.,
2016) to induce weight sharpening, and thus act as a gating mecha-
nisms of the information provided by the predecessors.
We name this extension of the representation layer ”explicit causal
latent block” (XBlock) and we call XNet (or prefix ”X”) any net-
work using this module. Most disentanglement methods attempt to
learn a representation consisting of causal variables or disentangled
”factors” which are statistically independent (Higgins et al., 2017a).
However, except in the trivial case, it is not the Zi that should be
treated as statistically independent, but the Ni . Consequently, the
explicit separation between noise and structure reconciles with the
conventional disentanglement perspective while also providing the
model with additional power to learn identifiable relationships be-
tween the latent variables terms. The causal links revealed by Mi
can then be used to help identify how interventions will affect the
resulting samples for downstream tasks such as controllable gener-
ation. Moreover, differentiating between noise and structure allows
to expand the dimensionality of the causal variables Z, without any
need to reparametrise the noise distribution. We partition the causes
in units, each one consisting of multiple dimensions and representing
a single statistical variable.
3	Related work
To the best of our knowledge, this is the first work to formally intro-
duce the notion of interventional consistency and develop a training
scheme based on it. However, related ideas have been discussed in
previous works.
Recently, there is particular interest in applying causality to represen-
tation learning (KocaoglU et al. (2017), Suter et al. (2019), TraUble
et al. (2021), ScholkoPf et al. (2021)). In Yang et al. (2021) the au-
thors introdUce a learnable Causal Layer, which essentially describes
a SCM, in the latent sPace of a variational aUtoencoder. MUch like
oUr XBlock, the caUsal layer in Yang et al. (2021) transforms inde-
Pendent noise variables into caUsal ones, thUs seParating the informa-
(b) XCAE-I
(c) XCAE-E
FigUre 3: Invariance matri-
ces for aUtoencoders of the
Standard (a), ’XC-I’ (b) and
’XC-E’ (c) variant. We ob-
serve a PronoUnced increase
in the score dUe to the con-
sistency training. Note that
invariance and eqUivariance
regUlarisation achieve a sim-
ilar Performance.
5
Under review as a conference paper at ICLR 2021
tion from the structure. The structural assignments of the Causal Layer integrate physical limitations
to the system’s dynamics that are not present in the XBlock (i.e. additive noise assumption, mild
non-linearity). Moreover, Yang et al. adopt a perspective radically different from this work: their
goal is to solve causal disentanglement, and they rely on weak supervision to do so.
The introduction of symmetries in the representation layer has been examined from multiple per-
spectives (Cohen & Welling (2016), Finzi et al. (2020), Finzi et al. (2021), Weiler et al. (2018), Ben-
ton et al. (2020), ?). In Keller & Welling (2021) the authors use topographic capsules parametrised
through variational inference to obtain equivariance to geometric transformations in the input. Like
Yang et al. (2021), the work uses weak supervision (in the form of ordered input sequences) to
disentangle salient characteristics in the data. Interestingly, in Keller & Welling (2021) disentangle-
ment is obtained as a by-product of equivariance, echoing the definition of disentanglement given in
Higgins et al. (2018).
Perhaps the discussion most relevant to the present work is presented by Leeb et al. (2021) and
Besserve et al. (2018). Leeb et al. develop a framework to assess the characteristics of the response
map of variational autoencoders, thus laying the groundwork of the present study. The invariance
score proposed in Section 2.1 is closely related to the Latent Response Matrix presented in Leeb
et al. (2021). Unlike this paper, in Leeb et al. additionally introduce new tools to evaluate rep-
resentations in regards to disentanglement based on the response map. In Besserve et al. (2018),
interventions on the deep layers of a generative model are employed to discover independent mod-
ules participating in the representation. Similarly to the present work, Besserve et al. (2018) adopts
a perspective completely agnostic of the true generative process instead focusing on the artificial
one. However both Leeb et al. and Besserve et al. are only concerned with analyzing and evaluating
generative processes, while we develop training methods and metrics to directly optimize for the
desired structure.
4	Experiments
In the following experiments we demonstrate the relevance of interventional consistency and the
strength of the proposed approach. More specifically, we are able to learn representations that are
markedly more robust to interventions and can correctly handle manipulations. We quantitatively
and qualitatively verify that consistency training is effective in improving the model’s interventional
consistency without harming the model’s generative performance. Moreover we produce evidence
on the benefit of differentiating between information and structure in the latent space, by analysing
the effects of the XBlock on the learned representation.
4.1	Experimental details
In our experiments we employ three baselines with fundamental differences in their representa-
tion layer, namely: convolutional autoencoders (AE) (Bourlard & Kamp (1988), Hinton & Zemel
(1994)), variational autoencoders (β VAE) (Higgins et al., 2017b), and structural autoencoders (SAE)
(Leeb et al., 2020). For each of the baselines two variants are considered: ’X’ and ’XC’, where
the former extends the original model by integrating the explicit causal latent block and the lat-
ter augments the ’X’ version through consistency training. The ’XC’ variant in turn comes in two
modalities employing the invariance (’XCI’) and equivariance (’XCE’) regularisation respectively.
Additionally, we include an implementation of the AVAE model to compare the two consistency
training schemes.
The experiments are performed on MNIST (LeCun & Cortes, 2010) and CelebA (Liu et al., 2015)
datasets. These datasets have been chosen for being closer to real-world scenarios than artificially
manufactured alternatives whilst being well known and historically recognised in the literature.
The neural architectures considered vary only in size, keeping a coherent overall skeleton across
experiments. Specifically, we consider 3 different size standards for MNIST (’S’, ’Standard’, ’S4’)
and another 2 for CelebA (’v32’, ’v324’). The differences are reported in Table 3 in the appendix,
together with the details on the skeleton and training hyperparamters.
6
Under review as a conference paper at ICLR 2021
5	Results and discussion
(a) FID scores for all the models on MNIST (lower is
better). We evaluate the FID on the reconstructions
(left), prior samples (middle) and traversals (right).
Perhaps unsurprisingly, the variational baseline scores
markedly higher than the alternative. Crucially, the ’X’
and ’XC’ versions’ scores are comparable to the Stan-
dard models.
(b) Summary of the invariance score on all
experiments (MNIST and CelebA). For each
model, all its variants are evaluated against
the invariance score. The matrix is re-
duced to a single number through averag-
ing. The variational baseline scores system-
atically higher than the alternatives. This re-
sult is partly due to the presence of collapsed
dimensions in the representation, which in-
crease the model’s score due to their abso-
lute unresponsiveness. Importantly, we no-
tice that the ’XC’ variants tends to perform
better than the others.
Consistency training improves the model’s interventional consistency without harming the re-
construction quality. From Figure 7 and 6 it can be seen across all datasets that the ’X’ and ’XC’
variants do not interfere with the quality of the reconstructed or prior samples. To quantitatively
support this claim we include the corresponding FID scores (Heusel et al., 2017) for all the exper-
iments in Figure 5a. Additional samples are shown in Section A.4.1. One principle against which
to evaluate the quality of the prior samples is their intrinsic diversity. Real world datasets such as
MNIST and CelebA are rich in low probability details that are thus hard to capture in the represen-
tation. In this regard the autoencoder outperforms the respective VAE models (see A.4.1). The prior
samples for deterministic autoencoders are obtained through hybrid sampling, a technique proposed
in (Leeb et al. (2020), Besserve et al. (2018)) which allows to generate previously unseen combi-
nations of latent factors by randomly aggregating different posterior samples. For more details on
hybrid sampling we refer the reader to Leeb et al..
Figure 2 shows the standard latent traversal plot alongside the traversals response error. The error
is measured as the signed difference between the intervened prior noise vector and its expected re-
SPonSe as defined in Section 2.1, i.e. Ni - Nik. This figure best depicts the discrepancy between
generation and inference which lies at the heart of this work and motivates the consistency perspec-
tive. By only analysing the traversal plots one might conclude that the learned representation can
correctly resolve the alteration introduced by the traversal, and thus that it possesses the generali-
sation and modularity suggested by the quality of the generated samples. In short, consistency is
assumed to hold. However, the errors recorded on the response show that this assumption is false:
the intervention applied is not preserved by the encoder, which presumably projects the sample into
the observational distribution manifold (Radhakrishnan et al., 2018). In summary Figure 2 reveals
that (i) the current autoencoders (i.e. without consistency requirements) are indeed not consistent
under interventions and that (ii) consistency training can improve the model’s consistency. Signifi-
cantly, consistency training only acts on the response error indirectly since the regularisation terms
do not include take into account the prior samples. The increase in consistency with consistency
training can also be assessed in Figure 3. It must be taken into account that the invariance regu-
larisation directly aims at optimising the invariance score, whilst the equivariance score only does
so indirectly. Full summaries of the consistency scores for the different training modalities can be
found in Section A.4.3. A quantitative summary of the invariance scores for all experiments is given
in Figure 5b. We observe that the AVAE baseline has the lowest score on interventional consistency
among the variational family, comparably to the βVAE. On the contrary it is among the highest
7
Under review as a conference paper at ICLR 2021
a倦,电❷
Figure 6: Traversals for the autoencoder model in 3 variants, namely: Standard (left), ’X’ (center)
and ’XC-I’ (right). The different variants are comparable in terms of generation quality. However,
the Xnets show a higher degree of modularity between the dimensions. We hypothesise that the
Xblock favours independence. We include the full traversal plots in the Additional material (18).
Figure 7: Input reconstructions (first row) and prior samples (second row) for the autoencoder model
in 3 variants, namely: Standard, ’X’ and ’XC-I’. The prior samples are obtained through hybrid
sampling from the aggregate posterior distribution.
performing models when evaluated on self-consistencty (see Figure 28). This discrepancy confirms
that consistency, as defined in Cemgil et al. (2020) does not imply interventional consistency.
The explicit causal latent block provides sparsity and self-consistency. A mask element with a
low value prevents the information from passing from the parent to the child node. Consequently, if
the noise variables are independent, one can read off the adjacency matrix the structure of the exist-
ing statistical relations between latent units. This is not possible in the current standard of a single
space carrying both the information and the statistical structure. A sparse configuration is desirable
for interpretability, since it simplifies the dynamics of the generation process. Moreover simpler
models are more likely to be correct, according to the widely accepted principle of parsimony also
known as Occam’s razor. Section A.4.4 in the appendix displays the mask values for the learned
XBlock of different models.
Table 1 reports the sparsity levels for different latent sizes. The results show that it is possible to
obtain sparsity for every model without the need of any additional regularisation. The introduction
of learnable masks endowed with weight sharpening has proved to be sufficient to induce sparsity
LATENT SIZE (N)	SPARSITY (%)		SAMPLING MODE	AE	XAE	XCAE
6	41.66	Posterior	0.96	0.96	0.95
12	45.83	Hybrid	0.75	0.81	0.88
32	48.44	Uniform	0.66	0.68	0.80
Table 2: Average self consistency under posterior,
hybrid and uniform sampling for AE (left), XAE
(middle) and XCAE (right). The average is taken
over the latent dimension for the S MNIST mod-
els.
Table 1: Sparsity levels per varying latent
size. The right column records the percent-
age of edges in the Xblock over the set of
possible connections based on the learned
mask.
8
Under review as a conference paper at ICLR 2021
Figure 8: MMD between noises ag-
gregate posterior and hybrid sam-
pling distribution, measured using
an Inverse Multiquadratic kernel
(IMQ). The distributions are ob-
tained by recording the MMD met-
ric over all S models configurations
(including different random seeds).
in the latent block structure. The number of latent dimension has systematically turn out to be the
only indicator for the sparsity level achieved. Moreover, the structure of dependencies in the model
varied only slightly with respect to the model family and exhibited greater sensitivity to the latent
unit size (cf A.4.4).
Table 2 records the self consistency of autoencoders under
three different prior sampling procedures: posterior, hybrid
and uniform sampling, respectively from top to bottom. ’Pos-
terior’ refers to drawing samples from the aggregate posterior
Q(N) = R Q(N|X)P(X = x)dx, ’hybrid’ applies to its hy-
bridised version, and finally in the ’uniform’ case we consider
a uniform distribution whose extremes on each dimension are
derived from Q(N). We would normally expect a decreasing
self-consistency going from the first to the last row: in fact,
hybrid sampling breaks any existing statistical correlation be-
tween the noise variables, and uniform sampling additionally
compels a continuous support in the latent data manifold to
be preserved by the response map. In Table 2 the expected
trend is approximately confirmed by the AE model. We no-
tice that the ’X’ version improves the self consistency score
under all sampling procedures, proving to be less sensitive to
the distribution shifts introduced by hybridisation and conti-
nuity. Consistency training further increases the score under
all sampling modes. This behaviour suggests the hypothesis
that the explicit causal latent block in fact favours indepen-
dence between the noise dimensions.
In order to give an objective ground to this hypothesis in the additional material (Figure 8) we look at
an empirical measure of independence between the noise variables for all models. More specifically,
we compute the Maximum Mean Discrepancy (MMD) between the aggregate posterior distribution
over the noise variables and its hybridised version. By construction hybridisation destroys any
existing statistical relationship between the latent dimensions. For both the AE and VAE model
families the ’X’ version’s metric distribution appears significantly shifted to the left, thus indicating
a higher degree of independence between the noise variables.
6	Conclusion
In this work we focus on the modularity and self-consistency of a representation, rather than address-
ing the identifiability problem. More specifically, we have formulated and studied the interventional
consistency property of autoencoders. The metrics and regularization objectives we develop result in
representations that remain consistent under interventions thus enabling meaningful manipulation.
We propose a novel architecture that can be applied to any existing autoencoder, inspired by causal
representation learning, to explicitly model the dependencies between latent variables. The architec-
ture has empirically shown to improve the model’s self-consistency and independence in the latent
space. The separation of the information and structure of the representation therein connects the dis-
entanglement perspective to the more structured causal framework, thereby also opening the door to
new analysis tools to enrich the representation’s interpretability and controllability by exposing the
learned mechanisms.
Reproducibility S tatement
The used datasets are publicly available. Implementation details for all the experiments are in-
cluded in the Additional material (A.3). A description of the hyperparameters and network architec-
tures used is included in Appendix A.3. As indicated as an option in the author guide https:
//iclr.cc/Conferences/2021/AuthorGuide for sharing the code anonymously, in a
first step we will make a comment directly to the reviewers and area chairs with the link to an
anonymous repository once the discussion forums open and in the second step make the full reposi-
tory public once the paper is accepted.
9
Under review as a conference paper at ICLR 2021
References
Philip Bachman, R Devon Hjelm, and William Buchwalter. Learning representations by maximizing
mutual information across views. arXiv preprint arXiv:1906.00910, 2019.
Yoshua Bengio, Aaron Courville, and Pascal Vincent. Representation learning: A review and new
perspectives. IEEE transactions on pattern analysis and machine intelligence, 35(8):1798-1828,
2013.
Gregory Benton, Marc Finzi, Pavel Izmailov, and Andrew Gordon Wilson. Learning invariances in
neural networks. arXiv preprint arXiv:2010.11882, 2020.
Michel Besserve, Arash Mehrjou, Remy Sun, and Bernhard Scholkopf. Counterfactuals uncover the
modular structure of deep generative models. arXiv preprint arXiv:1812.03253, 2018.
Herve Bourlard and Y Kamp. Auto-association by multilayer perceptrons and singular value de-
composition. Biological cybernetics, 59:291-4, 02 1988. doi: 10.1007/BF00332918.
A Taylan Cemgil, Sumedh Ghaisas, Krishnamurthy Dvijotham, Sven Gowal, and Pushmeet Kohli.
Autoencoding variational autoencoder. arXiv preprint arXiv:2012.03715, 2020.
Taco Cohen and Max Welling. Group equivariant convolutional networks. In International confer-
ence on machine learning, pp. 2990-2999. PMLR, 2016.
Marc Finzi, Samuel Stanton, Pavel Izmailov, and Andrew Gordon Wilson. Generalizing convolu-
tional neural networks for equivariance to lie groups on arbitrary continuous data. In International
Conference on Machine Learning, pp. 3165-3176. PMLR, 2020.
Marc Finzi, Max Welling, and Andrew Gordon Wilson. A practical method for constructing equiv-
ariant multilayer perceptrons for arbitrary matrix groups. arXiv preprint arXiv:2104.09459, 2021.
Xavier Glorot and Yoshua Bengio. Understanding the difficulty of training deep feedforward neural
networks. In Proceedings of the thirteenth international conference on artificial intelligence and
statistics, pp. 249-256. JMLR Workshop and Conference Proceedings, 2010.
LUigi Gresele, Julius von Kugelgen, Vincent Stimper, Bernhard Scholkopf, and Michel Besserve.
Independent mechanism analysis, a new concept? arXiv preprint arXiv:2106.05200, 2021.
Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter.
Gans trained by a two time-scale update rule converge to a local nash equilibrium. Advances in
neural information processing systems, 30, 2017.
Irina Higgins, Loic Matthey, Arka Pal, Christopher Burgess, Xavier Glorot, Matthew Botvinick,
Shakir Mohamed, and Alexander Lerchner. beta-VAE: Learning basic visual concepts with a
constrained variational framework. ICLR, 2(5):6, 2017a.
Irina Higgins, Loic Matthey, Arka Pal, Christopher P. Burgess, Xavier Glorot, Matthew M.
Botvinick, Shakir Mohamed, and Alexander Lerchner. beta-vae: Learning basic visual concepts
with a constrained variational framework. In ICLR, 2017b.
Irina Higgins, David Amos, David Pfau, Sebastien Racaniere, Loic Matthey, Danilo Rezende,
and Alexander Lerchner. Towards a definition of disentangled representations. arXiv preprint
arXiv:1812.02230, 2018.
Geoffrey E Hinton and Richard S Zemel. Autoencoders, minimum description length, and helmholtz
free energy. Advances in neural information processing systems, 6:3-10, 1994.
Kevin Hoover. Causality in Economics and Econometrics, pp. 1-13. 01 2008. doi: 10.1057/
978-1-349-95121-5.2227-1.
Eric Jang, Shixiang Gu, and Ben Poole. Categorical reparameterization with gumbel-softmax. arXiv
preprint arXiv:1611.01144, 2016.
T Anderson Keller and Max Welling. Topographic vaes learn equivariant capsules. arXiv preprint
arXiv:2109.01394, 2021.
10
Under review as a conference paper at ICLR 2021
Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint
arXiv:1412.6980, 2014.
Murat Kocaoglu, Christopher Snyder, Alexandros G Dimakis, and Sriram Vishwanath. Causal-
gan: Learning causal implicit generative models with adversarial training. arXiv preprint
arXiv:1709.02023, 2017.
Yann LeCun and Corinna Cortes. MNIST handwritten digit database. 2010. URL http://yann.
lecun.com/exdb/mnist/.
Felix Leeb, Yashas Annadani, Stefan Bauer, and Bernhard Scholkopf. Structure by architecture:
Disentangled representations without regularization. arXiv e-prints, pp. arXiv-2006, 2020.
Felix Leeb, Stefan Bauer, and Bernhard Scholkopf. Interventional assays for the latent space of
autoencoders. arXiv preprint arXiv:2106.16091, 2021.
Ziwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou Tang. Deep learning face attributes in the wild.
In Proceedings ofthe IEEE international conference on computer vision, pp. 3730-3738, 2015.
Francesco Locatello, Stefan Bauer, Mario Lucic, Gunnar Raetsch, Sylvain Gelly, Bernhard
Scholkopf, and Olivier Bachem. Challenging common assumptions in the unsupervised learning
of disentangled representations. In international conference on machine learning, pp. 4114-4124.
PMLR, 2019.
Francesco Locatello, Ben Poole, Gunnar Ratsch, Bernhard Scholkopf, Olivier Bachem, and Michael
Tschannen. Weakly-supervised disentanglement without compromises. In International Confer-
ence on Machine Learning, pp. 6348-6359. PMLR, 2020.
Misra D Mish. A self regularized non-monotonic activation function. arXiv preprint
arXiv:1908.08681, 2020.
Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary DeVito,
Zeming Lin, Alban Desmaison, Luca Antiga, and Adam Lerer. Automatic differentiation in
pytorch. 2017.
J. Pearl. Causality: Models, Reasoning, and Inference. Cambridge University Press, New York, NY,
2nd edition, 2009.
J. Peters, D. Janzing, and B. Scholkopf. Elements of Causal Inference - Foundations and Learning
Algorithms. MIT Press, Cambridge, MA, USA, 2017.
Adityanarayanan Radhakrishnan, Karren Yang, Mikhail Belkin, and Caroline Uhler. Memorization
in overparameterized autoencoders. arXiv preprint arXiv:1810.10333, 2018.
Karl Ridgeway and Michael C Mozer. Learning deep disentangled embeddings with the f-statistic
loss. arXiv preprint arXiv:1802.05312, 2018.
Bernhard Scholkopf, Francesco Locatello, Stefan Bauer, Nan Rosemary Ke, Nal Kalchbrenner,
Anirudh Goyal, and Yoshua Bengio. Toward causal representation learning. Proceedings of
the IEEE, 109(5):612-634, 2021.
Raphael Suter, Djordje Miladinovic, Bernhard Scholkopf, and Stefan Bauer. Robustly disentangled
causal mechanisms: Validating deep representations for interventional robustness. In Interna-
tional Conference on Machine Learning, pp. 6056-6065. PMLR, 2019.
Frederik Trauble, Elliot Creager, Niki Kilbertus, Francesco Locatello, Andrea Dittadi, Anirudh
Goyal, Bernhard Scholkopf, and Stefan Bauer. On disentangled representations learned from
correlated data. In International Conference on Machine Learning, pp. 10401-10412. PMLR,
2021.
Maurice Weiler, Mario Geiger, Max Welling, Wouter Boomsma, and Taco Cohen. 3d steerable cnns:
Learning rotationally equivariant features in volumetric data. arXiv preprint arXiv:1807.02547,
2018.
Mengyue Yang, Furui Liu, Zhitang Chen, Xinwei Shen, Jianye Hao, and Jun Wang. Causalvae:
disentangled representation learning via neural structural causal models. In Proceedings of the
IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 9593-9602, 2021.
11
Under review as a conference paper at ICLR 2021
Figure 9: Diagram illustrating interventional consistency.
A Appendix
A. 1 Notation
In this section we report a guide to the notation used in the work. Throughout this paper we use N
and Z for stochastic variables in the latent space. N0 and Z0 are used for stochastic variables in the
response space. X is be used for input data and X for the input space. (E, D) denote the encoder
and decoder mapping, respectively. R = E ◦ D defines the response. N k denotes a sample from the
k	k	q0k
prior P(N) and Nk its intervened version. Moreover we let N0k and N be the expectation of the
response to Nk and Nk ,respectively. For a Dirac posterior (deterministic map) We use its center as
expectation. Finally, Nqk 0 marks the result of the intervention I applied to Nq0k and We denote the
k	qk
corresponding causal variables by Z0k and Zk .
A.2 Consistency training
In this Appendix We take a closer look at the connection betWeen interventional consistency and
the pointWise estimate of invariance and equivariance. Interventional consistency can be formalised
With the tWo folloWing definitions.
Definition 1 (Interventions Invariant Response). Given an autoencoder (E, D), anda causal fac-
torisation of the prior over the latent space P(Z) = i P(Zi|PAi) the response R = E ◦ D is
invariant to interventions on Z if for every intervention I in the set of interventions Im localised on
the factor indexed by m the following conditions are verified:
P(Z0) = P(Z)R(Z0|Z)dZ=YP(Zi0|Zj06=i)
i
f	_ _
P(Z0) = [I ◦ P(Z)]R(Z0∣Z)dZ = P(Zm∣Zj=m) ɪɪ P(Zi∣Zj=i)
i6=m
(6)
(7)
Definition 2 (Interventions Equivariant Response). Given an autoencoder (E, D), and a causal
factorisation of the prior over the latent space P (Z) = ∩i P (ZjPAJ the response R = E ◦ D is
equivariant to interventions on Z if, for every intervention I in the set of interventions Im localised
on the factor indexed by m, there exist an equivalent intervention I0 acting in the Z0 space, such
that the following condition is verified:
/[I ◦ P(Zm∣Zp[m)] Y P(Zi∣PAi)R(Z0∣Z)dZ = 10 ◦ P(Zm∣Zj=m) Y P(Zi∣Zj=i)	(8)
i6=m	i6=m
Equivariance implies invariance, as it provides a strictly stronger condition on the response map.
The caveat is that to evaluate equivariance one must additionally deduce I0 from I, Which requires
12
Under review as a conference paper at ICLR 2021
knowledge of the relation between Z and Z0 . Notice that interventional consistency is effectively a
property of the response map and is thus oblivious to the prior Z.
Due to the deterministic nature of the structural assignments definitions 1 and 2 can be reformulated
without any loss of generality in terms of the noise variables. Let N and N0 be the noise variables
before and after the response respectively, with
P(N0) =
P (N)R(N 0|N)dN
P(N 0) = /
P(N )R(N 0|N )dN
δ(Nm - v) Y
i6=m
P(Ni)R(N0|N)dN
(9)
(10)
In the invariance case We require P (N 0)i to match P(N 0)i for all i = m. In the equivariance case
We additionally require P(N0)m = I0 ◦ P(N0)m = I ◦ P(N0)m = δ(v). In formulas, the solution
space has to satisfy one of the folloWing conditions:
d(P(N )i, P(N0)i) = 0 ∀i = m (invariance)	(11)
d(P(N 0 )i, I ◦ P (N )i) = 0 ∀i ∈ [1, n] (equivariance),	(12)
Where I ◦ P(N0)i = P(N0)i for i 6= m and d is a generic distance in the space of distributions on
N. We can approximate P(N0) and P(N0) by sampling from the prior (i.e. P(N) and P(N) re-
spectively) and subsequently applying the response map to each sample. Using a pointWise estimate
of the above terms can be vieWed as adopting a distance that to decompose into the sum of the intra-
sample distances. This choice rules out solutions for Which the response posterior suffers a shift in
a non-intervened dimension When an intervention is applied. We noW turn to a full characterisation
of the pointWise estimates of invariance and equivariance.
Pointwise invariance. We measure the Euclidean distance betWeen the responses expectations, i.e.
∣Ni,k - Nik∣∣2 for i = 1, ..., n and k = 1, ..., T , With T being the total number of samples. By
focusing on the noise terms We can leverage the noise independence assumption to significantly
simplify the equations. Notice that We couldn’t apply the same direct measurement With the causal
variables Zik and Z0 because of the existing connections between causal variables, i.e. when
modifying Nm we can expect N0=m to stay constant but we cannot say the same for Zi=m if i is
a descendant of m. However, invariance can be checked distributionally for Z, by looking at the
conditionals P(Zi0|Zi06=m).
Pointwise equivariance. To compute pointwise equivariance we can directly work in the causal
variables space measuring the Euclidean distance || Zik - Zk || 2. The argument for evaluating equiv-
ariance at the causal variables level is purely practical: in this way the structural assignments receive
a stronger training signal, which is beneficial especially early on in training when the set of connec-
tions is being first outlined.
Algorithms 1 and 2 show how to compute pointwise invariance and equivariance, respectively.
13
Under review as a conference paper at ICLR 2021
Algorithm 1 Algorithm computing the in-
variance regularisation term.
for m in [1, n] do
for Im in Im ⊆ Im do
Sample N 1,...,NT 〜P(N)
Copy Nk — Nk for k = 1,..., T
Intervene Nm J VIm
elm	J	n∙T Pk Pi=m llNIik -
Nik l∣2
end
end
LINV = ∣⅛ PImEJm eIm
Algorithm 2 Algorithm computing the equivari-
ance regularisation term.
for m in [1, n] do
for Im in IIm ⊆ IIm do
SampleN1, ...,NT 〜 P(N)
Copy Nk J Nk
Intervene Nmk J VIm
△ .τ	_ .τ
Copy NI 0k J NI 0k
Intervene NIm0k J VIm
Zik J fi(Nk,PAli)
kk
Zi J fi(N0i ,PAk)
k
rIm J η1τPkPi=ml∣Z0k-Z0ill
end
end
LEQV =尚 PIm EIm TIm
The regularisation terms LINV and LEQV are included in the standard loss weighted by λINV and
λEQV, respectively. In our experiments we use λINV = λEQV = 4. We consider both stochastic
and deterministic encoders, while treating the decoder as deterministic (a Gaussian noise model
is used, with the mean parametrised by D). If the encoder is stochastic the response R(N 0lN)
defines a distribution over the N0 space: in the case of the VAE this distribution is known to be
Gaussian, thus fully described by its mean and variance. Experimentally, including information on
the spread of the distribution in the regularisation term has not benefited training, often resulting in
numerical instabilities. This outcome has been observed for parametric distances as well as well-
known divergence measures (such as the Kullback-Leibler).
A.3 Experimental details
In this section we provide the details regarding experimental settings.
All experiments are performed on 1 GPU core NVIDIA A100 40GB and based on the Pytorch
(Paszke et al., 2017) framework. The models are trained using the stochastic iterative optimiser
Adam (Kingma & Ba, 2014), with default parameters. The learning rate is set to 0.0001 and halved
every 30 epochs. The MNIST and CelebA models are trained for 100k and 200k iterations, respec-
tively. We use a batch size of 128 or all the experiments. Each model is trained with 5 different
random seeds (11, 13, 17, 37, 121) and every pseudo-random number generator in pytorch, numpy
and python.random is seeded accordingly.
As anticipated in 4.1 we adopt a single architectural skeleton for all the models, varying only in size.
The skeleton is shown in Figure 10. All the architectures use the Mish (Mish, 2020) nonlinearity.
The number of pooling layers is set to 3 for MNIST and 7 for CelebA. The number of filters in the
convolutional layers is fixed to 32 for MNIST, 100 for CelebA. All the layers, except for the nor-
malization ones, are initialised using the method discussed in Glorot & Bengio (2010). Differently
from what is shown in Figure 10 the ’X’ and ’XC’ variants include an additional layer (forming the
explicit causal latent block) applied to the latent vector as shown in Figure 4. Finally, in Table 4 we
report the size of each model in terms of the number of trainable parameters.
A.4 Additional results
A.4. 1 Comparing samples quality
In this section we report the reconstructions, generated and traversal samples for the main experi-
ments performed on MNIST and CelebA.
14
Under review as a conference paper at ICLR 2021
Figure 10: Architectural skeleton used for all models. The input is fed to a convolutional network
(ConvNet) to obtain its latent representation (in green). This is then fed to a second convolutional
network (UpsampleNet), equipped with bilinear upsampling layers, that produces the output image.
The ConvNet comprises blocks of convolutional layers (ConvBlock) and regularly spaced pooling
layers (red). The precise structure of the ConvNet is determined by two parameters specifying the
number of ConvBlocks and pooling layers, respectively. As an example, the ConvNet in this figure
has depth 6 and 3 pooling layers. Each ConvBlock is composed of a convolutional layer with a fixed
number of filters (blue), a non-linear activation (green), and a batch normalisation (yellow). The
last ConvBlock in the ConvNet is followed by a dense head (purple) which processes the flattened
version of the ConvBlock output to reduce it to the latent space size. The dense head consists of
3 linear layers interleaved by non-linear activations. Finally, the UpsampleNet copies the ConvNet
structure in reverse order, and with upsampling layers instead of pooling ones. The output of the
UpsampleNet is passed through a Sigmoid activation to project is back to the input space.
NAME	DEPTH LATENT UNIT	DATASET SIZE (N) SIZE (Zi)
Standard	12	12	1	MNIST
S	12	6	1	MNIST
S4	12	6	4	MNIST
v32	16	32	1	CelebA
v324	16	32	4	CelebA
Table 3: Overview of the architecture variants. The Depth entry refers to the number of convolutional
layers employed in the encoder. The decoder has depth equal to that of the encoder.
15
Under review as a conference paper at ICLR 2021
SIZE NAME NUMBER of
PARAMETERS
Standard	AE	423,259
Standard	XAE	425,677
S	AE	309,973
S	XAE	310,984
S4	XAE	313,936
v32	AE	2,840,827
v32	XAE	2,850,299
v324	XAE	2,878,523
Standard	VAE	298,771
Standard	XVAE	301,189
S	VAE	186,025
S	XVAE	187,036
S4	XVAE	188,836
v32	VAE	2,763,707
v32	XVAE	2,773,179
v324	XVAE	2,795,259
Standard	SAE	442,267
Standard	XSAE	444,685
S	SAE	320,488
S	XSAE	320,488
S4	XSAE	323,440
Table 4: Number of trainable parameters for all the models in the experiments. The ’XC’ model
variants have the same size as the ’X’ variants and thus are not reported in this table. The training
time varies between 3 hours (for the smaller models) to 2 days (for the bigger ones, with consistency
training).
16
Under review as a conference paper at ICLR 2021
6 31nH-l∕∕Q∙^4∙H
ʃT 5 5 8 ∖ 32λ2
86rCΓ∕7y
OOg 3
4
S
0
Q
2
0
0
7
N
5ofu*a*Gi3F5a∙
9
i 7 q
q 2 6
0 0 2
7 « 3
/ 7 H
1 5 5
5 I ff
5 I H
6 5 7
O，5
7	1	I	β	I
⅛	I	7	a	7
M	/	5	q	2
3	r	7	I	?
0	0	5	19
/ 69工。
3	¾	7	3	G
S	I	1	∖	B
S	H	(⅛	7	I
2.0 S I S
7
S
1
5
5
g
∖63 222
3
£
7
S
5
gz∖q<o 彳Γ3
/ b √
a q &
c s^ q
3 2 7
q z 5
(H 2
■ w0
ə » 7
s 7 q
*b O Λ
(a) AE S
(b) VAE S
(c) SAE S
4,
I
ʃ
ʃ
8
S予Q
ι
l
0
ti
8
H
ʒ
7
g
5
8 I
g A
3 4
4 7
，。
o ∖
9 5
T 5
3 3
P斗
7 1
OYZ 3iλγ∙s%
C
3
q
y%u∙762Γ7ai/^
b qs2ZHZyft7o
g 5 4 G 5 ∙7
6-73/71
Γ3 ISGO
U 5 q ʃ 1 q
I g I 8 / 8
O ∖ I ∖ O t∖
3 G / I I 3
q，q o 3 F
/ 2 8 ⅛ / 7
zzq I 3 3
q 2 q ι q 3
« i o / √
8 a D ¼ η S
⅛ ⅛ T 6 S H
«1 7 3 ε> ʃ I
g o a q z 5
0 ⅜ / 6 9 Λ
9 3 A η q F
λ, 5 τ a a 7
5 a 3 g 7 *1
P 7 240,
T 1
6 3i⅛i∕∕98√h
5f-558∖G>32λ2
g6ΓSJC3ol∕l4
5 7u I
°
(q
q
⅛
o
H
8
qI
3
7
8
5
g I 0
A 0
3 4。
4 7 2
q o 8
o ∖ I
夕5 N
τs η
3 3 S
八、
7 1

e-ə 9
3 y
q S
5 q
2 7
Z 5
9 a
q r
a 7
7 q
O /
(d) XAE S
(e) XVAE S
(f) XSAE S
80 9 NO slb4>01
2002 q 华，7s55q
I
q
o
y
8
5
G
O
4 3l4f∕∕q84q
S「553\63222
g6ΓLIδ>3<Γ∕2"
7
I
0
li
8
W
ʒ
,
7
S
5
g I 0
g J o
3 4 q
q 7 2
ς o ∂
o % I
彳5 Λ
T 5 r}
3 3 6
P ¥%
1 1
C 3 g4

b
q
s
H
a
7
O
y¾4752Γ7α∙Λ
q
3
5
q
7 8 5
0
IJq
“勺？
G 5*√
0 2 7
q Z 5
C η 2
q与犷
3 a 7
1 ?
SOA
∕q2G4a 3 b∖8
Tzb O q58685q
qqo7sc>，？≠3
y4"M6 0⅜o5σ-cr
q 3 q 〃 O 7 8 8/ qg
Sfcq874 g3s 3 7 C-
Ugq 3 HP Zofo
Λ ¾sβAU35∕toxz7
3 β A TT Oo of b qo62
d3，，q3o，，4<r
io/əoʒnfo 2g2
2¾∖3 9 319o<∂a
(g) XCAE-I S
(h) XCVAE-I S
(i) XCSAE-I S

q
2
O
7
S
I
I
3
¾
1
q
g
*1
3
O
1 3
7，
⅛ I
T (
S 4∙
O 0
3 0
3 q
ς i
q H
X 0
7
S
千
5
9
7
3
(o
g
ð I
2 I
¾ 2
I »
β 6
∖ S
2 Z
8，
5 7 U--
，, SbOQ
“gio
ι J a o
o 3 <? q
q q 7 3
2 ς o £
q o ∖ I
5 v 5 ɪ
S 5 r∖
1 δ I I
8 Fl 1
SI 7
ysu≡∕52Γ7τ
<Γ5z2g4y⅞r-
/X45flz> 0*37
Z8NbgfT7*l8l
so5 0 i qqq∕ 92 I
2 9 75∙q∖CT/ 8 % Z
qN。HooZ 8 @3 I ɔ
VOZ?V53O0Sl9
5- ə 5 1 R A 3 b 9 L 0
fII2IV33A76C
Sb∣35l¢ff∕3∖5
5^∕∕5∣-∣9Hfe7l
5005631，。g"
斗，I 4 O、3 7
(j) XCAE-E S	(k) XCVAE-E S	(l) XCSAE-E S
Figure 11: Comparison of reconstruction quality of S models.
17
Under review as a conference paper at ICLR 2021
(a) AE S
T 匕/。KG oz±t 上/
^ArJ /
<<LbQ,∖∖σ4∙ />
δ3∙∖∕e,5∖2.1 J /
4p,k>4∙3644Al
L^~ IS — 14/O,T 夕
iFcr4q Ι，^、J /。
30,夕夕，¾/ J /
(b) VAE S
A S
8
(c) SAES
3yyQ5½32 6 70s
QIUP 5965102/26
5r5, Bf42∖r1∖
5。S-∙6S*S2 5Aʃ
^⅛L15β∖∕Z^A∖( A 1
(e) XVAE S
夕
7 / Λw / ʃ
3。
36 7,g735g∙ 了2
(f) XSAE S
(d) XAE S
66ZO ∙tΓ75*7i∕⅜
Io ∖ / 6c3∖
√z^2xt∕lL953Jr
8 Zq4 6 6。？ 3 2 5b
4I-⅜R6 5∖425∖5
夕W7YCr'r66MH38
Urz 尸。。，？37，5
55 6<j6>2 7jγ∖0
。。乙
?30』5323一94
7033^7 / 57 夕 43
l√f73rX2Λfl3
∖qarq33684Q?
IF33b39412
qj∕Λq74∕tf∕a-/
fS∕9(∣13927? I
7qq6a,997θ*夕
3∕3l^4∕qS92∕
B2by!39，qqqf
?334q"g∕2
qgi>"∣ 2(» (, g i 2.
(i) XCSAE-I S
(g) XCAE-I S
(h) XCVAE-I S
b
/∕7974gJ3l3l
2 9i^ΛSS2fHHZ
g4S93∕ZS39
73332W4/Q夕a，
ZI3321S3^^34
1 夕3279 23 9 ¥
6N4,∕39 9夕 4，，
√√^123-23Γ5F1
"Jg，2g3/?3/5
777 I23til37<ob
#53/js//ɪiʃ/
⅛2⅛t4Aβ3 I 2 2 S
(l) XCSAE-E S
(j) XCAE-E S
(k) XCVAE-E S
Figure 12: Comparison of S models on generated samples quality.
18
Under review as a conference paper at ICLR 2021
(g) XCAE-I S
(h) XCVAE-I S
(i) XCSAE-I S
QQQQDQDQQQObbbbbbbbb
bbboooo。oo。。。。。。。。oo
・・・・••••・•0。0000000。
CDOoo 0。。。。。。〃〃，〃〃/
C OCO 00 0 0 0000。。。。。。。。
）。00。。。。。，夕夕夕夕夕"。。，/〃
(j) XCAE-E S
(k) XCVAE-E S
Figure 13: Comparison of S models on traversals quality.
(l) XCSAE-E S
(a) AE v32
(b) XAE v32
(c) XCAE-I v32
(d) XCAE-E v32
Figure 14: Comparison of v32 models on reconstruction quality.
19
Under review as a conference paper at ICLR 2021
(b) XAE v32
(a) AE v32
(c) XCAE-I v32	(d) XCAE-E v32
Figure 15: Comparison of v32 models on the generated samples quality.
需 H,γtfr⅜ytfrees S■■■■■■■■
(a) AE v32

(b)	XAE v32
需 KVJ0∕HHS SSSS 9 » » 金金 4 4 ¾∣
(c)	XCAE-I v32
WH99¾τiT0⅞y ∙1∙∙∙∙∙<⅝⅞⅞
(d)	XCAE-E v32
Figure 16: Comparison of v32 models on the interpolation samples quality.
20
Under review as a conference paper at ICLR 2021
♦，♦，@ 卷
⅜ ⅜ ⅛r⅜
Γ⅜T⅜T⅜ .ft ⅜ ⅜
⅛⅞M⅜T⅜T⅜
⅜ ⅜ % ⅜ ⅜ ⅝
⅝τ∙T⅜T⅜I⅜ te
⅜ ⅜ tit
G 电&e
i i i ⅜ ⅜Γ⅜
⅜ ⅜ ⅝ ⅜ ⅜ ⅜
■ r⅜ r⅜ i⅜ r∣r∙
W。。。
•曹，⑧理♦♦♦■§*
红触，僦胱
[ɔɪ I < 04

■—.000000
WWffVWI b 6000
密密⅜ ⅜ ⅜ [⅜ [⅜
利 66Cj
000bk,
[*TiT⅜ >⅜T⅜ Q
赧卸图，密
>I⅜ ⅜ ⅜ ⅜ι⅜
(a) AE v32
Figure 17: Comparison of v32 models
(b)	XAE v32
on traversals quality (1).
21
Under review as a conference paper at ICLR 2021
l⅛⅛ft⅛⅛∙
0„痣，修他
Ggnnbi 剧
僖,修旧回后牌
2MM胤㈣
⅛⅛ΛAft⅝
⅛fefe⅛∙fefe
陶修的晶除修
I∙⅛⅛⅛.[⅛i⅛
,的倦,⑥回一
♦ B修偏心知
Ek偏僖&*
■2僖b
停隔儡僖僖修
区除修昆,修
⅛fefefe⅛⅛
蜀•崭■)■•
• & & % T1T1
嬴黝就衙曹厚
古 £ ■ ' ■ € ■'
& & &, ■)■ 91
常卷6■，'，
w∙∙∙
? /'$&&&
&161献■传传(
・•♦曾曾匈
■',：&各 #&
领新& ∙i就,
S &&，1劭®!
CiAfieefi
鼠鼠4 &'型朝
崭&
争，I& & -/■1
多船& ■ ■ 6
制暂βl武武，'
® 8' 81 Sl 51 &'
就制€1新e161
βι霸鼠eι∙∙
Sl新Cl武兽卷
船&：，' ∙∣∙∣e
& e w *
网闾&ι∙∙ιe
髭[® 9∣9∣β
■翼a e等e
(a) XCAE-I v32
(b) XCAE-E v32
Figure 18: Comparison of v32 models on traversals quality (2).
22
Under review as a conference paper at ICLR 2021
(c) Traversal on 2
(d) Traversal on 3
(e) Traversal on 4
(f) Traversal on 5
Figure 19: BetaVAE traversal response errors.
(a) Traversal on 0
(b) Traversal on 1
A.4.2 Traversal responses.
We here report the complete traversal response plots for the S version of the MNIST experiments.
Each plot shows the errors registered on all the latent dimensions as the traversal is performed.
βVAE family traversal response errors. The models in βVAE family are exposed to the well-
known effect of posterior collapse. In the following plots collapsed dimensions can be distinguished
by the particular behaviour of the response error (zero when the dimension is not intervened on
and equivalent to the intervention value elsewhere). We also include the traversal response errors
measured on the AVAE model. Interstingly, all the variants in the VAE family present two collapsed
dimensions, except for the XVAE model, that has 3 collapsed dimensions (50% of the total number
in this case) and the AVE model which has none.
AE family traversal response errors. Additionally we show the traversal response errors for the
autoencoder family of models. Notice how in this case, as for the variational case, consistency
training effectively decreases the error.
23
Under review as a conference paper at ICLR 2021
(a) Traversal on 0
(b) Traversal on 1
(c) Traversal on 2
(d) Traversal on 3
(e) Traversal on 4
Figure 20: AVAE traversal response errors.
(f) Traversal on 5
24
Under review as a conference paper at ICLR 2021
(b) Traversal on 1
(a) Traversal on 0
(c) Traversal on 2
(d) Traversal on 3
(e) Traversal on 4
(f) Traversal on 5
Figure 21: XVAE traversal response errors.
25
Under review as a conference paper at ICLR 2021
(a) Traversal on 0
(b) Traversal on 1
(c) Traversal on 2
(d) Traversal on 3
(e) Traversal on 4
(f) Traversal on 5
Figure 22: XCVAE-I traversal response errors.
26
Under review as a conference paper at ICLR 2021
(b) Traversal on 1
(a) Traversal on 0
(c) Traversal on 2
(d) Traversal on 3
(e) Traversal on 4
(f) Traversal on 5
Figure 23: AE traversal response errors.
27
Under review as a conference paper at ICLR 2021
(a) Traversal on 0
(b) Traversal on 1
(c) Traversal on 2
(d) Traversal on 3
(e) Traversal on 4
Figure 24: XAE traversal response errors.
(f) Traversal on 5
28
Under review as a conference paper at ICLR 2021
(b) Traversal on 1
(a) Traversal on 0
(c) Traversal on 2
(d) Traversal on 3
(e) Traversal on 4
(f) Traversal on 5
Figure 25: XCAE-I traversal response errors.
29
Under review as a conference paper at ICLR 2021
A.4.3 Consistency metrics
In this sections we report the results on the new consistency metrics for all the models. We make the
following key observations: (i) that consistency training generally strengthens the models’ invari-
ance and equivariance, (ii) that although equivariance implies invariance, models using invariance
regularisation have comparable performances to those using equivariance regularisation.
(a) Invariance score for all experiments compar-
ing performance of models with and without con-
sistency training.
(b) Invariance score for all the models with con-
sistency training comparing invariance-based and
equivariance-based regularisation.
Standard training
CorkStstency training
VAE
(a) Equivariance score comparing performance of
models with and without consistency training.
(b) Equivariance score for all the models with con-
sistency training comparing invariance-based and
equivariance-based regularisation.
We proceed to present the self-consistency scores for all the experiments. Notice that self-
consistency is the only metric that, similarly to Cemgil et al. (2020), directly compares the response
to the prior. Since, the AVAE model objective is conceptually analogous to self-consistency, we
would expect the AVAE model to score higher than the VAE baseline on this consistency metric.
Figure 28 confirms this prediction.
30
Under review as a conference paper at ICLR 2021
(a) AE S
(b) AE Standard
(c) XAE S
(d) XAE Standard
(e) XCAE-I S
(f) XCAE-I Standard
Figure 29: Self-consistency score for each noise variable of the autoencoder family. Results are
shown for both the S and Standard model sizes.
Figure 28: Summary of self-consistency for multiple random seeds and model versions. The score is
reduced to a single number by averaging across the dimensions. Note that for the variational models
the score is obtained by sampling from the prior distribution, while for the AE and SAE families
posterior sampling is used.
A.4.4 Xnets
Masks structure. We can look at the structure learned in the explicit causal latent blocks. The
mask values in the Xblock describe a weighted adjacency matrix, which is displayed by the follow-
ing heatmaps. Interestingly, the structure is not significantly affected by the training scheme adopted
(i.e. consistency regularisation) or the model family. Instead its variability is mostly linked to the
causal units size and latent size.
31
Under review as a conference paper at ICLR 2021
(a) XAE S
	Causal	block adjacency		I matrix	
0.00	0.00	0.00	1.00	0.00	0.00
					
0.00	0.00	0.00	1.00	0.00	0.00
0.00	0.00	0.00	1.00	1.00	0.00
					
0.00	0.00	0.00	0.00	1.00	0.43
0.00	0.00	0.00	0.00	0.00	0.00
0.00	0.00	0.00	0.00	0.00	0.00
0	I	2	3	I 4	5
(c)	XCAE-I S
	Causal block ad		Ijacenci	I matrix	
o - 0.00	0.00	0.00	1.00	0.00	0.42
I- 0.00	0.00	0.00	1.00	0.00	0.00
OJ - 0.00	0.00	0.00	1.00	1.00	0.00
					
m- 0.00	0.00	0.00	0.00	1.00	0.09
寸-0.00	0.00	0.00	0.00	0.00	0.00
in - 0.00	0.00	0.00	0.00	0.00	0.00
6		2	3	4	5
(b) XAE S4
o - 0.00	Causal block ad		jacency matrix		
	0.00	0.00	1.00	1.00	1.00
T- 0.00	0.00	0.00	1.00		1.00
cm - 0.00	0.00	0.00	0.00	1.00	1.00
				—	
m - 0.00	0.00	0.00	0.00	1.00	0.00
寸-0.00	0.00	0.00	0.00	0.00	0.00
UI - 0.00	0.00	0.00	0.00	0.00	0.00
0	I	2	3	I 4	5
	(d) XCAE-I S4				
	Causal block adjacency			f matrix	
o - 0.00	0.00	0.00	1.00	1.00	L00
I- 0.00	0.00	0.00	1.00		L00
OJ - 0.00	0.00	0.00	0.00	1.00	1.00
				—	
m- 0.00	0.00	0.00	0.00	1.00	0.00
寸-0.00	0.00	0.00	0.00	0.00	0.00
in - 0.00	0.00	0.00	0.00	0.00	0.00
6		2	3	4	5
(e) XCAE-E S
(f) XCAE-E 4S
32
Under review as a conference paper at ICLR 2021
(a) XAE standard
(b) XCAE-I Standard
33
Under review as a conference paper at ICLR 2021
0.00
0.00
Z - 0.00
m - 0.00
寸-0.00
0.00
0.00
0.00
0.00
.00
.00
.00
0.00
0.00
0.00
0.00
O - 0.00
0.00
Z - 0.00
m - 0.00
寸-0.00
UI - 0.00
o - 0.00
I- 0.00
Causal
0.00
0.00
0.00
.00
0.00
0.00
0.00
0.00
0.00
.00
0.00
.00
0.00
0.00
3
10
111
(a) XCAE-E Standard
block adjacency matrix
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
Causal
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
block adjacency matrix
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0
1
4
5
0.00
0.00
0.00
0.00
Causal
(b) XCSAE-I S
0.00
block adjacency matrix
0.00
0.00
0.00
寸-0.00
0.00
0.00
0.00
0.00
0.00
0.00
m - 0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0.00
0
1
4
5
0
1
4
5
(c) XVAE S
XBlock visualisation tools.
(d)	XCVAE-I S
We introduce a qualitative evaluation tool reliant on interventional
consistency that permits to interrogate each representation dimension with specific examples. We
34
Under review as a conference paper at ICLR 2021
produce hybrids between two or more prior samples by separately intervening on different dimen-
sions. More precisely, given a base N1 〜P(N) and an alternative N2 〜P(N), We obtain n
hybrids by applying the following interventions one at a time:
Ni — N for i = 1,...,n
By decoding the result noise vector We obtain a visualisation of the hybridisation: We can thus
visually assess the effect of a localised intervention on the representation. Examples are given in
Figure 34.
Many dimensions do not shoW any change in response to the intervention. A lack of reaction could
be due to a general insensitivity of the dimension (e.g. the case of a collapsed unit), or to an inci-
dental overlapping of the tWo samples, or even to an inability of the decoder to generalise outside
of support. Moreover for the ’X’ and ’XC’ model variants We observe that the change produced
by the interventions is semantically different on distinct latent dimensions. This suggests that the
representation has developed a certain degree of modularity.
Ooooo
6、& ∖ 6 Q
@tC Cu 4 C
6 b g q , 4
bb、∖ b、
6 ∖ t
Oooooo
Figure 35: Double intervention matrix on N (left) and Z (right) for a XCAE-I S model on MNIST.
The yelloW box contains the base sample, While the tWo alternatives are displayed inside the blue
and red boxes. The hybrid samples are displayed in the matrix according to the interventions indices,
i.e. element i, j correspond to the hybrid obtained by replacing the i-th and j-th elements of the base
With the corresponding components in the first and second alternative respectively. The items on the
diagonal correspond to the result of hybridisation only With the first alternative.
We put consistency training to test by simultaneously applying tWo interventions on the base sample
using tWo different alternatives. Additionally, We look at the result both When the interventions are
applied on the noise and on the causal variables. Applying an intervention on the causes breaks
the connection from the parent to the intervened unit, thus altering the statistical relations betWeen
causal variables. The results are shoWn in Figure 35. There is a noticeable difference in the quality
of the hybrid samples betWeen the tWo kinds of interventions: hybrids on the causal variables more
often do not appear connected to any of the prior samples, sometimes producing meaningless shapes
(e.g. element (4, 1) in the matrix on the right). On the other hand, the noise hybrid samples appear
convincing and mostly semantically homogeneous. Interestingly, as highlighted in orange in Figure
35, the tWo different interventions can provide tWo different interpretations of the original ambiguous
shape.
35
Under review as a conference paper at ICLR 2021
T
室:N,
富"K'
7V,
患姓
***
号**
-*¥
*"
NF'
■3*
Ff
■1*
*
,* 丁冲
室请令
亨源，
富川富
¥：&写
因落¥
察N
室**
¾⅜x
(a) AE v32
Figure 34: Hybridisation on v32 models representation. The left column corresponds to the base
sample, the middle column to the presented alternative and the hybridisation result for each dimen-
sion is shown on the right.
36