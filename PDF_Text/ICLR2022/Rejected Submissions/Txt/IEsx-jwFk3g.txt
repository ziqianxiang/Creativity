Under review as a conference paper at ICLR 2022
Deep Representations for Time-varying
Brain Datasets
Anonymous authors
Paper under double-blind review
Ab stract
Finding an appropriate representation of dynamic activities in the brain is crucial
for many downstream applications. Due to its highly dynamic nature, temporally
averaged fMRI (functional magnetic resonance imaging) cannot capture the whole
picture of underlying brain activities, and previous works lack the ability to learn
and interpret the latent dynamics in brain architectures. In this paper, we build an
efficient graph neural network model that incorporates both region-mapped fMRI
sequences and structural connectivities obtained from DWI (diffusion-weighted
imaging) as inputs. Through novel sample-level adaptive adjacency matrix learn-
ing and multi-resolution inner cluster smoothing, we find good representations
of the latent brain dynamics. We also attribute inputs with integrated gradients,
which enables us to infer (1) highly involved brain connections and subnetworks
for each task (2) keyframes of imaging sequences along the temporal axis, and (3)
subnetworks that discriminate between individual subjects. This ability to iden-
tify critical subnetworks that characterize brain states across heterogeneous tasks
and individuals is of great importance to neuroscience research. Extensive experi-
ments and ablation studies demonstrate our proposed method’s superiority and ef-
ficiency in spatial-temporal graph signal modeling with insightful interpretations
of brain dynamics.
1	Introduction
Neuroimaging techniques such as fMRI (functional magnetic resonance imaging) and DWI
(diffusion-weighted imaging) provide a window into complex brain processes. Yet, modeling and
understanding these signals has always been a challenge. Network neuroscience (Bassett & Sporns,
2017) views the brain as a multiscale networked system and models these signals in their graph rep-
resentations: nodes represent brain ROIs (regions of interest), and edges represent either structural
or functional connections between pairs of regions.
With larger imaging datasets and developments in Graph Neural Networks (Scarselli et al., 2009),
recent works leverage variants of the graph deep learning, modeling brain signals with data-driven
models and getting rid of Gaussian assumptions typically existed in linear models (Zhang et al.,
2019; Li et al., 2019). These methods are making progress on identifying physiological characteris-
tics and brain disorders: In Kim & Ye (2020), authors combine grad-CAM (Selvaraju et al., 2017)
and GIN (Xu et al., 2018) to highlight brain regions that are responsible for gender classification
with resting-state fMRI data. Li et al. (2020) utilizes the regularized pooling with GNN to iden-
tify fMRI biomarkers. Noman et al. (2021) embeds both topological structures and node signals of
fMRI networks into low-dimensional latent representations for a better identification of depression.
However, the first two works use time-averaged fMRI, losing rich dynamics in the temporal domain.
The third combines nodes’ temporal and feature dimensions instead of handling them separately,
leading to a suboptimal representation (as discussed in section 3.2). To overcome these issues, we
propose ReBraiD (Deep Representations for Time-varying Brain Datasets), a graph neural network
model that jointly models dynamic functional signals and structural connectivities, leading to a more
comprehensive deep representation of brain dynamics.
To simultaneously encode signals along spatial and temporal dimensions, some notable works in
traffic prediction and activity recognition domains such as Graph WaveNet (Wu et al., 2019b) alter-
nate TCN (temporal convolution network) (Lea et al., 2016) and GCN (graph convolutional network)
1
Under review as a conference paper at ICLR 2022
predicted class
distribution
2 pooling layers
axis
Figure 1: The proposed ReBraiD model for integrating brain structure and dynamics (the architec-
ture shown is for classification). For each batch with batch size B, input X has a dimension of
(B, 1, N, T)1, and A, Aadp both have the dimension (B, N, N). The encoder (green part) encodes
temporal and spatial information alternatively, producing a latent representation in (B, dlatent, N, 1).
These embeddings are followed by linear layers for pooling and classification. The final output has
a dimension of (B, C).
inner-cluster
SiTiooting
(Kipf & Welling, 2017). Others (Song et al., 2020; Liu et al., 2020) use localized spatial-temporal
graph to embed both domains’ information in this extended graph. There are also works incorporat-
ing gated recurrent networks for the temporal domain such as (Seo et al., 2018; Ruiz et al., 2020).
We choose the first option for ReBraiD, as it is more memory and time efficient, and can support
much longer inputs. We also explore the best option when alternating spatial and temporal layers
for encoding brain activities with extensive ablation studies. Upon this structure, we propose novel
sample-level adaptive adjacency matrix learning and multi-resolution inner cluster smoothing, both
of which learn and refine latent dynamic structures. We also make the model more efficient while
being effective with the choice of the temporal layer.
Equally important as finding a good representation of brain dynamics is interpreting them. We
utilize integrated gradients (Sundararajan et al., 2017) to identify how brain ROIs participate in
various processes. This can lead to better behavioral understanding, biomarker discoveries, and
characterization of individuals or groups with their brain imagings. We also make the novel contri-
bution of identifying temporally important frames with graph attribution techniques; this can enable
more fine-grained temporal analysis around keyframes when combined with other imaging modali-
ties such as EEG (electroencephalogram). In addition, our subject-level and group-level attribution
studies unveil heterogeneities among ROIs, tasks, and individuals.
2	Method
2.1	Preliminaries
We utilize two brain imaging modalities mapped onto a same coordinate: SC (structural connec-
tivity) from DWI scans, and time-varying fMRI scans. We represent them as a set of L graphs
Gi = (Ai, Xi) with i ∈ [1, L], in which Ai ∈ RN×N represents normalized adjacency matrix with
-	- -	-
an added self-loop:	Ai	=	DSC2 SCiDSC2 , SCi	= SCi +	IN	and	DSCi	=	w (SCi)vw	is the diagonal
node degree matrix. Graph signal matrix obtained from fMRI scans of the ith sample is represented
as Xi ∈ RN×T. Here N is the number of nodes, and each node represents a brain region; T is the
input signal length on each node. Our objective focuses on classifying brain signals Gi into one of
C task classes through learning latent graph structures.
2.2 model
ReBraiD takes (A, X) as inputs, and outputs task class predictions. The overall model structure is
shown in fig. 1. For the ith sample Xi ∈ RN ×1×T , the initial 1 × 1 convolution layer increases
1Axis order follows PyTorch conventions. Dimension at the second index is the expanded feature dimension.
2
Under review as a conference paper at ICLR 2022
Strided TCN	dialated causal TCN
Figure 2: Comparison of strided non-causal TCN (left) and dilated causal TCN (right). The causal
aspect is achieved through padding (kerneLsize — 1) X dilation zeros to the layer's input. The
resulting y always has the same length as input x, in which yτ only depends on inputs xt≤τ. We
can view strided non-causal TCN as the rightmost node of a dilated causal TCN.
its hidden feature dimension to dh1, outputting (N, dh1, T). The encoder then encodes temporal
and spatial information alternately, reducing information to feature axis and generating a hidden
representation of size (N, dh2, 1). The encoder is followed by two linear layers to perform node
embedding pooling and two MLP layers for classification. Cross entropy is used as the loss function:
LCE = 一 PC yi log y, where yi ∈ RC is the one-hot vector of ground truth task label and r^i ∈ RC
is model’s predicted distribution. We now explain different components of the model.
(I)	Learning sample-level latent graph structures. Structural scans serve as our graph adjacency
matrices. However, they are static not only across temporal frames but also across different tasks.
In contrast, functional connectivities (FC) are highly dynamic, as shown in appendix A.1.1. To
better capture dynamic graph structures, we assign an adaptive adjacency matrix to each input graph
signal. Unlike other works such as Wu et al. (2019b) that use a universal latent graph structure, our
model do not assume all samples share the same latent graph. Instead, in ReBraiD, each sample
has a unique latent structure reflecting its signal status. This implies that the latent adjacency matrix
cannot be treated as a learnable parameter as a part of the model. To solve this, we minimize the
assumption down to a shared projection Θadp that projects each input sequence into an embedding
space and use this embedding to generate the latent graph structure. Θadp can be learned in an end-
to-end manner. The generated adaptive adjacency matrix for the ith sample can be written as, where
Softmax is applied column-wise:
Ai_adp = SoftmaX (ReLU ((XiΘadp ) (XiΘadp )>)) , Θadp ∈ RT×hadp	(1)
(II)	Gated TCN (Temporal Convolutional Network). To encode temporal information, we use the
gating mechanism as in Oord et al. (2016) in our temporal layers: H(l+1) = tanh TCNemb(H(l))
σ TCNgate(H(l)) , whereH(l) ∈ RN×d×t isone sample’s activation matrix of the lth layer, de-
notes the Hadamard product, and σ is the Sigmoid function. Different from TCNs generally used in
sequence to sequence models that consist of dilated Conv1d and causal padding along the temporal
dimension (van den Oord et al. (2016)), we simply apply Conv1d with kernel 2 and stride 2 as our
TCNemb and TCNgate to embed temporal information. The reason is twofold: first, for a sequence
to sequence model with a length-T output, yτ should only depend on xt≤τ to avoid information
leakage, and causal convolution can ensure this. In contrast, our model’s task is classification, and
the goal of our encoder along the temporal dimension is to embed signal information into the feature
axis while reducing temporal dimension to 1. The receptive field of this single temporal point (with
multiple feature channels) is meant to be the entire input sequence. Essentially, our TCN is the same
as the last output node of a kernel 2 causal TCN whose dilation increases by 2 at each layer (fig. 2).
Second, from a practical perspective, directly using strided non-causal TCN works the same as us-
ing dilated causal TCNs and taking the last node, while simplifies the model structure and reduces
training time to less than a quarter.
(III)	Graph Network layer. In our model, every l temporal layers (appendix A.2.3 studies the best
l to choose) are followed by a spatial layer to encode signals with the graph structure. Building tem-
poral and spatial layers alternatively helps spatial modules to learn embeddings at different temporal
scales, and this generates better results than putting spatial layers after all temporal ones.
To encode spatial information, Kipf & Welling (2017) uses first-order approximation of spectral fil-
ters to form the layer-wise propagation rule ofa GCN layer: H(l+1) = GCN(H(l)) = f(AH(l)W(l)).
It can be understood as spatially aggregating information among neighboring nodes to form new
node embeddings. In the original setting without temporal signals, H(l) ∈ RN ×d is the activation
matrix of lth layer, A ∈ RN ×N denotes the normalized adjacency matrix with self-connections
3
Under review as a conference paper at ICLR 2022
as discussed in section 2.1, W(l) ∈ Rd×d0 is learnable model parameters, and f is a nonlinear
activation function of choice. Parameters d and d0 are the number of feature channels.
We view a GCN layer as a local smoothing operation followed by an MLP, and simplify stacking
K layers to AKH as in Wu et al. (2019a). In ReBraiD, every graph network layer aggregates infor-
mation from each node’s K-hop neighborhoods based on both brain structural connectivity and the
latent adaptive adjacency matrix: namely We have both AiKH(I)WK and Ai_adpKH(I)WK_adp for input
H(l). We also gather different levels (from 0 to K) of neighbor information with concatenation. In
other Words, one graph convolution layer here corresponds to a small module that is equivalent to K
simple GCN layers With residual connections. We can Write our layer as:
H(l+1) = GNN(I) (H(l)) = MLP [Concatk=ι (H⑴,ReLU(AikH(l)), ReLU(Ai_adpkH⑷)，	(2)
With the additional temporal dimension, H(l) ∈ RN×d×t in eq. (2), and Ai ∈ RN×N applies on
H(l)’s first tWo dimensions While multiplying. Outputs of different GNN(l) layers are parametrized
and then skip connected With a summation. Since the temporal lengths of these outputs are different
because of TCNs, max-pooling is used before each summation to make the lengths identical.
(IV)	Multi-resolution inner cluster smoothing. While GNN layers can effectively passing in-
formation betWeen neighboring nodes, long-range relationships among brain regions that neither
appear in SC nor learned by latent Aadp can be better captured using soft assignments similar to
DIFFPOOL (Ying et al. (2018)). To generate the soft assignment tensor assigning N nodes into c
clusters (c chosen manually), We use GNN(plo)ol that obeys the same propagation rule as in eq. (2),
folloWed by Softmax along c. This assignment is applied to the output of GNN(elm) b Which carries
out the spatial embedding for the lth layer input H(l) :
S(I) = Softmax (GNNpoOl(H(')) , 1)∈ RN×c×t
Z(l) = GNN(elm) b (H(l) ∈ RN×d×t	(3)
H(I) = S(I)>z(I) ∈ Rc×d×t
The extra temporal dimension alloWs nodes to be assigned to heterogeneous clusters at different
frames. We find that using coarsened Ai(l+1) = S(l)>Ai(l)S(l) ∈ Rc×c as the graph adjacency matrix
leads to worse performance compared to using SC-generated Ai and learned Ai adp (comparison
in section 3.1). In addition, if the number of nodes is changed, residual connections coming from
the beginning of temporal-spatial blocks can not be used and this impacts overall performance. To
continue use Ai and Ai_adp as graph adjacency matrices and allow residual connections, we reverse-
assign H(l) with assignment tensor obtained from applying Softmax on S(l)> along N, so that the
number of nodes is kept unchanged:
S(I)= SoftmaX (S(I)>,l) ∈ Rc×N×t
H(`+I) = S(l)>H(I) ∈ RN×d×t
(4)
In fact, eqs. (3) and (4) perform signal smoothing on nodes within each soft-assigned cluster (ap-
pendix A.1.2 shows a toy example). With the bottleneck c < N, the model is forced to pick up latent
community structures. This inner-cluster smoothing is carried out at different spatial resolutions: as
the spatial receptive field increases with more graph layers, we decrease cluster number c for the
assignment operation.
2.3 Attribution with IG (Integrated Gradients).
As one approach to model interpretability, attribution assigns credits to each part of the input, as-
sessing how important they are to the final predictions. Wiltschko et al. (2020) gives an extensive
comparison between different graph attribution approaches, in which IG (Sundararajan et al. (2017))
is top-performing and can be applied to trained models without extra alterations of the model struc-
ture. IG also has other desirable properties such as implementation invariance that other gradient
methods are lacking. It is also more rigorous and accurate than obtaining explanations from atten-
tion weights or pooling matrices that span multiple feature channels. Intuitively, IG calculates how
real inputs contribute differently compared to a selected baseline; it does so by aggregating model
gradients at linearly interpolated inputs between the real and baseline inputs. For each sample, we
4
Under review as a conference paper at ICLR 2022
Input Length (frames)
(a)	(b)
Figure 3: 3a: Ablation studies on different input length (please see table 3 in appendix for numerical
values of weighted F1 under each setting); 3b: Choosing number of GNN to TCN layer ratio.
calculate attributions at each point of both input A ∈ RN ×N and X ∈ RN ×T :
ATTRAvw = (Avw - Avw) × X a /A Intrpl，~~× M , AIntrPl = AO + M × (A - AO)
m=1	Intrplvw
ATTRXvt = (Xvt — Xvt)× X "S, XIntrPl) × -M，XIntrpl = X0 + M × (X — X0)
m=1	∂XIntrplvt	M	M
(5)
F(A, X) here rePresents our signal classification model, M is the steP number when doing Riemann
aPProximation of the Path integral, and A0 , X0 are baselines of A, X (see section 3.3 for more
details). Note that eq. (5) calculates the attribution of one Point on one samPle. The Process is
rePeated for every Point of the inPut, so attributions have identical dimensions as inPuts. To obtain
brain region imPortance of a task, we aggregate attributions across multiPle samPles of that task.
3	Experiments
We use fMRI signals from CRASH dataset (Lauharatanahirun et al. (2020)) for our exPeriments.
The model classifies inPut fMRI into 6 tasks: resting state, visual working memory task (VWM),
dynamic attention task (DYN), math task (MOD), dot Probe task (DOT), and Psychomotor vigilance
task (PVT) (aPPendix A.2.1 has detailed task descriPtions). We PreProcess 4D voxel-level fMRI
images into graPh signals G = (A, X) by averaging voxel activities into regional signals with the
200-ROI cortical Parcellation (voxel to region maPPing) sPecified by Schaefer et al. (2018). We
also standardize signals for each region and discard scan sessions with obvious abnormal sPikes that
may be caused by head movement, etc.. DWI scans are maPPed into the same MNI152 coordinate
and Processed into adjacency matrices with the same Parcellation as fMRI uses. Valid data contains
1940 scan sessions from 56 subjects, session length varies from 265 frames to 828 frames and TR
(RePetition Time) is 0.91s. These 1940 scan sessions are seParated into training, validation, and
test sets with a ratio of 0.7-0.15-0.15. HyPerParameters including droPout rate, learning rate, and
weight decay are chosen with grid search based on validation loss, and all results rePorted in this
section are obtained from the test set. For each scan session, we use a sliding window to generate
inPut sequences (in the following exPeriments T ∈ {8, 16, 32, 64, 128, 256}) and feed them to the
model. To encode temPoral and sPatial information alternatively, we find stacking two TCN layers
Per one GNN layer leads to better Performance most times (fig. 3b, see more on aPPendix A.2.3
(II)). Models are written in PyTorch, trained with Google Colab GPU runtimes, and 60 ePochs are
run for each exPeriment setting. Codes and data will be released uPon accePtance.
3.1	Model components
Graph adjacency matrices. For each inPut samPle Gi , we test different oPtions to Provide graPh
adjacency matrices to the GNN layer. They include (i) our ProPosed method: using both adaPtive
adjacency matrix Ai adp and SC-induced Ai; (ii) only using Ai; (iii) only using Ai adp; (iv) replacing
Ai_adp in setting i with Ai_FC derived from functional connectivity; (v) only using random graph
5
Under review as a conference paper at ICLR 2022
adjacency matrices with the same level of sparsity as real As. We set hadp to be 5 in eq. (1), which
works better for our data than larger hadp choices. K is set to 2 for eq. (2), meaning each GNN ag-
gregates information from 2-hop neighbors based on the provided adjacency matrices. We evaluate
our model with weighted F1 as the metric because of the imbalance among tasks. The results under
different settings are reported in fig. 3a (and table 3 in appendix for numerical values).
From the results of setting (ii) plotted in fig. 3a, we see that removing the adaptive adjacency matrix
impacts the performance differently at different input lengths: the gap peaks for signals of length 64
- 128, and becomes smaller for either shorter or longer sequences. This could suggest the existence
of more distinct latent states of brain signals of this length that cannot be captured by structural
connectivities. On the other hand, removing SC (setting (iii)) seems to have a more constant impact
on the model performance, with shorter inputs more likely to see a slightly larger drop. In general,
only using Aadp leads to smaller performance drop than only using SC, indicating the effectiveness
of Aadp in capturing useful latent graph structures. More detailed studies in appendix A.2.3 shows
Aadp learns distinct representations not captured by A.
As mentioned in section 2, our motivation behind creating sample-level adaptive adjacency matrices
is FC’s highly dynamic nature. Therefore, for setting (iv), we test directly using adjacency matri-
Ces Ai-FC obtained from FC instead of the learned Ai adp. In particular, Ai_FC = DDFC2 FCiDFC： ∈
R200×200, where (FCi)Vw = Corr((Xi)v, (Xi)w), FCi = FCi + IN and DFCi = Pw(FCi)vw. Fig.
3a shows Ai_FC constantly underperforms Ai_adp, except for being really close with length-8 inputs.
Larger performance gaps are observed for longer inputs, where Corr((Xi)v , (Xi)w ) struggles to
capture the changing dynamics in the inputs. This demonstrates that our input-based latent Ai_adp
has better representation power than input-based FC. We also notice batch correlation coefficients
calculation for Ai-FC results in a slower training speed than computing Ai_adp.
An interesting result comes from setting (v), where We use randomly generated ErdOs-Renyi graphs
with the edge creation probability the same as averaged edge existence probability of As. Its perfor-
mance is at a similar level or even better than settings (ii) and (iii). Our hypothesis is the model can
learn the latent graph structure out of randomness, and we will verify this hypothesis in section 3.3.
Multi-resolution inner cluster smoothing. To verify the capability of inner-cluster smoothing
operation in capturing latent graph dynamics, we test the following settings: (vi) using our proposed
model and inputs, except removing paralleled GNNpool and inner-cluster smoothing module; (vii)
previous setting (v) but remove GNNpool and inner-cluster smoothing module; (viii) keep GNNpool,
but using coarsened graph instead of performing smoothing and increasing the node number back
(essentially performing DiffPool with an added temporal dimension). In this last setting, we
hierarchically pool graph nodes until node number reaches 1, and we keep the total number of GNN
layers the same as our other settings. Values of soft-assigned cluster number c are chosen to be
halved per smoothing module, starting from half of the graph nodes number, namely: 100, 50, 25,
etc. for our experiments. Different choices of c affect model converging rate, but only have minor
impacts on the final performance (see appendix A.2.3 (III)). Results are reported in fig. 3a (and
table 3 in appendix). Apart from these three settings, we also test adding pooling regularization terms
(described in appendix A.1.3) into the loss function but this does not lead to much ofa difference.
The above results demonstrate that both setting (vi) and (vii) outperforms (viii) by a large margin,
indicating the importance of keeping the original node number when representing brain signals.
In addition, all three settings underperform our proposed method, and they are mostly worse than
changing graph adjacency matrices as in settings (ii)-(v): this shows inner-cluster smoothing module
has a large impact in learning latent graph dynamics. We also find using adaptive adjacency matrices
and inner cluster smoothing can stabilize training, making the model less prone to over-fitting and
achieving close-to-best performance over a larger range of hyperparameters (see fig. 11).
3.2	Model Comparisons
In this section, we compare our model with the vanilla GCN from Kipf & Welling (2017), Chebyshev
Graph Convolutional Gated Recurrent Unit (GConvGRU) from Seo et al. (2018), GraphSAGE from
Hamilton et al. (2017), GAT V2 from Brody et al. (2021) and Graph Transformer as in Shi et al.
(2021). To use them in our fMRI classificaiton problem, we directly take corresponding layers from
6
Under review as a conference paper at ICLR 2022
Table 1: Model comparisons under the 256 input length setting.
Model	Accuracy (%)	WeightedFI	Training time (s / epoch)
GCN (KiPf & Wening (2017))	41.53	42:84	7T3
GAT V2 (Brody et al. (2021))	50.44	50.36	1142
GConvGRU (Seo et al. (2018))	52.26	56.05	9886
GraPhSAGE (Hamilton et al. (2017))	61.84	61.87	1048
Graph Transformer (Shi et al.(2021))	66.51	66.11	1890
ReBraiD (ProPosed method: TCN + GNN)	-8556-	9085	298
ReBraiD (TCN only)	72.44	71.98	119
ReBraiD (TCN + CNN)	75.89	75.79	124
PyTorch Geometric 2 and PyTorch Geometric Temporal 3 and construct the models similar to ours:
four graph layers taking in both signals and adjacency matrices, followed by two linear layers along
node axis and two linear layers for the final classification. We train baseline models with the same
setting as our model: 256-frame inputs, Adam optimizer, cross entropy loss, and 60 epochs (all
models well-converged). Grid search is used to optimize the rest of hyperparameters. We compare
accuracy, weighted F1 score, and training time per epoch in table 1; we also plot our model and
Graph Transformer’s confusion matrices in appendix fig. 12.
We observe that our proposed method significantly outperforms the baseline graph models by a mar-
gin of 20 to 40 percent and has much less training time. This demonstrates our proposed model’s
effectiveness in capturing latent brain dynamics. For these baseline models, temporal content is used
as features; the comparison shows separating them into different axis is more advantageous. This is
further confirmed with models only having TCN layers: we test both removing GNN layers all to-
gether and replacing them with 1 × 1 CNN layers. Both outperform graph models that focuses on the
spatial modeling aspect. Although temporal modeling is crucial, including the spatial information
in its graph format as our proposed model can improve the performance much further.
3.3	Interpretations with IG
In this section, we study the contributions of different brain ROIs and subnetworks defined by
their functionalities. For the subnetwork definition, we choose to use the 17 networks specified
in Thomas Yeo et al. (2011)) which has a mapping from our previous 200-ROI parcellation. See
table 4 in appendix for all subnetwork names. We compute IG of a model trained on length-256 in-
put signals because the model has higher performance with longer inputs, leading to more accurate
attributions. To select baseline inputs, we follow the general baseline selection principle for attribu-
tion methods: when the model takes in a baseline input, it should produce a near-zero prediction and
Softmax(outputs) should give each class about the same probability in a classification model. All-
zero A0 and X0 can roughly achieve this for our model, so we choose them as our baseline inputs.
For each task, the IG computation is done on 900 inputs to get an overall distribution.
Temporal importance. On the single input level, we can attribute which parts of the inputs in Gi
are more important in predicting the target class by looking into (ATTRX)i. This attribution map
not only shows which brain regions contribute more but also reveals the important signal frames.
One critical drawback of fMRI imaging is its low temporal resolution, but if we can know which
part is more important, we can turn to more temporally fine-grained signals such as EEG to see if
there are any special activities during that time. To confirm that the attributions we get are valid
and consistent, we perform a sanity check of IG results on two overlapped inputs with an offset
τ : the first input is obtained from window [t0 , t0 + T] and the second is obtained from window
[t0 + τ, t0 + τ + T ]. Offset aligned results are shown in fig. 4a, and we can see the attributions agree
with each other quite well.
Spatial importance. We examine the connection importance between brain ROIs by looking at
AttrA (task-averaged AttrA are plotted in fig. 14 in appendix). In particular, columns in AttrA
with higher average values are sender ROIs of high-contributing connections, which is what matters
in the GNN operation. We also explore why using random graph adjacency matrices (setting (v) in
section 3.1) can produce a similar result for length-256 inputs compared to using both SC-induced
2https://pytorch-geometric.readthedocs.io/
3https://pytorch-geometric-temporal.readthedocs.io/
7
Under review as a conference paper at ICLR 2022
(a)	(b)
Figure 4: 4a: Temporal importance sanity check of IG results on two pieces of inputs with a large
overlap period. Attribution maps are offset aligned; 4b: AttrX distributions across brain regions for
VWM task, where the upper one separates left and right hemispheres and the lower one combines
them (e.g. LH-VisCent and RH-VisCent are combined to region VisCent). Refer to table 4 in
appendix to see brain region names that the x-axis numbers represent.
Figure 5: Column averages of task-averaged AttrA (mapped into 34 subnetworks defined by the
17-network parcellation with left, right hemispheres). Top row is obtained from real SC induced A
and bottom rows is obtained from random SC induced Arand. Attributions are normalized to [0, 1].
Ai and Ai_adp (setting (i)). By examining ATTRA under both settings (fig. 5), We see that the column
averages of AttrA under these two settings are similar for almost all tasks, meaning the model can
learn Where to pay attention to even using random adjacency matrix inputs. We credit this ability
partially to multi-resolution inner cluster smoothing, as the performance Would drop notably Without
it (setting (vii)). HoWever, using ground truth SC not only gives us higher performance for shorter
inputs but also provides the opportunity to better interpret brain region connections. We can directly
use task-averaged AttrA as the Weighted adjacency matrix to plot edges betWeen brain ROIs, just as
in fig. 6. Important brain regions obtained from AttrA mostly comply With the previous literature
(see appendix A.2.5 for details).
AttrX can also give us insights on spatial importance When the attribution maps are averaged or
summed up along the temporal dimension. But it does so from another perspective: instead of
shoWing important structural connections that support information passing, it reveals regions or
subnetWorks that are sources of the important signals. In fig. 4b, We plot the distribution of t-
averaged and subnetWork-averaged (mapping 200 ROIs into 17 subnetWorks) AttrX during VWM
task. We can see the clear dominance of VisCent, DorsAttnA, and ContA subnetWorks (numbered
as 1, 5, 11), indicating signals from these regions are useful for model to decide if the input is
from VWM task. For the boxplots of other tasks and subnetWork rankings, please see fig. 16,
table 5 and table 6 in appendix. More informative than the rankings is the distribution itself: even
though VisCent, DorsAttnA, and ContA ranked top 3 for both resting state and VWM task for signal
attributions, their relative importance and attribution distribution variances are totally different. In a
sense, the distribution can act as a task fingerprint based on brain signal states.
We notice that signal-important ROIs are not necessarily the same as connection-important ROIs:
top-ranked subnetWorks for resting state are DefaultA and DefaultB by AttrA , and VisCent and
DorsAttnA by AttrX; although they do coincide With each other for tasks like VMN. This disparity
is reflected in fig. 6 as edge and node differences.
Group, session, and region heterogeneity. Average variances of attributions are very different
across tasks, especially those of AttrX : VWM and DYN have much smaller attribution variances
compared to other tasks. This can be caused by either task dynamics When certain tasks have more
phase transitions and brain status changes, or/and group heterogeneity When individuals carry out
8
Under review as a conference paper at ICLR 2022
Figure 6: ROI attributions from ATTRA and ATTRX . Tasks are: Resting, VWM, DYN, DOT, MOD,
PVT from left to right. Edge color and width are based on task-averaged ATTRA ∈ R200×200, and
nodes color and size are based on task and temporal-averaged ATTRX ∈ R200. For the visualization
purpose, only edges with highest attributions are kept to ensure sparsity being 0.009 (down from
around 0.196). For ROI attributions based only on AttrA where important sender ROIs are reflected
by node sizes, please refer to fig. 13 in appendix.
Figure 7: AttrX distributions of 3 subjects doing VWM task (left) and MOD task (right). Outliers
that go beyond [Q1 - 1.5 IQR, Q3 + 1.5 IQR] are omitted. VWM has a much smaller average
attribution variance than MOD.
certain tasks more differently than the others. We investigate the cause by looking into 3 subjects;
each of them has multiple scan sessions for every task.
We report the following findings: (1) Even only aggregating attributions over a single subject’s
sessions, attribution variances of the other four tasks are still larger than VWM and DYN. The
variance values are comparable to that of aggregating over many subjects. This means the large
variances are not mainly due to group heterogeneity, rather some tasks having more states than
others. (2) Apart from different task dynamics, there is still group heterogeneity. For tasks with
more dynamics (high attribution variances), the group heterogeneity is also more obvious. We can
see from fig. 7 that attributions for VMM are much more concentrated and universal across subjects
than that of MOD. (3) Flexibility of different subnetworks varies: subnetworks that have small
distribution IQR (Interquartile Range) of the same subject’s different sessions will also be more
consistent across subjects. One example is subnetwork 18 during MOD task has both higher within-
subject IQR and larger across-subject differences compared to subnetwork 19. This indicates for a
certain task, some subnetworks are more individual and flexible (may activate differently across t),
while others are more universal and fixed. In summary, we can reveal both critical regions that a
particular task must rely on, and regions that can characterize individual differences during tasks.
4	Conclusions
In this paper, we propose ReBraiD, a high-performing and efficient graph neural network model
that embeds both structural and dynamic functional brain signals for task classifications. To better
capture latent dynamics, we propose input-dependent adjacency matrix learning and inner-cluster
smoothing at multiple resolutions. Apart from quantitative results showing ReBraiD’s superiority in
representing brain activities, we also leverage integrated gradients to attribute and interpret the im-
portance of both spatial brain regions and temporal keyframes, as well as presenting heterogeneities
among subnetworks, tasks, and individuals. These findings can potentially reveal new neural basis
or biomarkers of tasks and brain disorders when combined with behavioral metrics, and enable more
fine-grained temporal analysis around keyframes when combined with other imaging techniques.
9
Under review as a conference paper at ICLR 2022
References
Danielle S Bassett and Olaf Sporns. Network neuroscience. Nature neuroscience, 20(3):353-364,
2017.
Shaked Brody, Uri Alon, and Eran Yahav. How attentive are graph attention networks?, 2021.
Joshua M Carlson, Felix Beacher, Karen S Reinke, Reza Habib, Eddie Harmon-Jones, Lilianne R
Mujica-Parodi, and Greg Hajcak. Nonconscious attention bias to threat is correlated with an-
terior cingulate cortex gray matter volume: a voxel-based morphometry result and replication.
Neuroimage, 59(2):1713-1718, 2012.
Joshua M Carlson, Jiook Cha, and Lilianne R Mujica-Parodi. Functional and structural amygdala-
anterior cingulate connectivity correlates with attentional bias to masked fearful faces. Cortex, 49
(9):2595-2600, 2013.
Sean PA Drummond, Amanda Bischoff-Grethe, David F Dinges, Liat Ayalon, Sara C Mednick, and
MJ Meloy. The neural basis of the psychomotor vigilance task. Sleep, 28(9):1059-1068, 2005.
Roland M Friedrich and Angela D Friederici. Mathematical logic in the human brain: semantics.
PLoS One, 8(1):e53699, 2013.
Roland H Grabner, Gernot Reishofer, Karl Koschutnig, and Franz Ebner. Brain correlates of math-
ematical competence in processing mathematical representations. Frontiers in human neuro-
science, 5:130, 2011.
William L Hamilton, Rex Ying, and Jure Leskovec. Inductive representation learning on large
graphs. In Proceedings of the 31st International Conference on Neural Information Processing
Systems, pp. 1025-1035, 2017.
Sayan Kahali, Marcus E Raichle, and Dmitriy A Yablonskiy. The role of the human brain neuron-
glia-synaptic composition in forming resting state functional connectivity networks. bioRxiv,
2021.
Byung-Hoon Kim and Jong Chul Ye. Understanding graph isomorphism network for rs-fmri func-
tional connectivity analysis. Frontiers in Neuroscience, 14:630, 2020. ISSN 1662-453X. doi:
10.3389/fnins.2020.00630.
Jangjin Kim, Edward A Wasserman, Leyre Castro, and John H Freeman. Anterior cingulate cor-
tex inactivation impairs rodent visual selective attention and prospective memory. Behavioral
neuroscience, 130(1):75, 2016.
Thomas N. Kipf and Max Welling. Semi-supervised classification with graph convolutional net-
works. In International Conference on Learning Representations (ICLR), 2017.
Nina Lauharatanahirun, Kanika Bansal, Steven M Thurman, Jean M Vettel, Barry Giesbrecht, Scott
Grafton, James C Elliott, Erin Flynn-Evans, Emily Falk, and Javier O Garcia. Flexibility of brain
regions during working memory curtails cognitive consequences to lack of sleep. arXiv preprint
arXiv:2009.07233, 2020.
Colin Lea, Rene Vidal, Austin Reiter, and Gregory D. Hager. Temporal convolutional networks: A
unified approach to action segmentation. In Gang Hua and Herve Jegou (eds.), Computer Vision
-ECCV2016 Workshops,pp. 47-54, Cham, 2016. Springer International Publishing. ISBN 978-
3-319-49409-8.
Robert Leech and David J Sharp. The role of the posterior cingulate cortex in cognition and disease.
Brain, 137(1):12-32, 2014.
Lingge Li, Dustin Pluta, Babak Shahbaba, Norbert Fortin, Hernando Ombao, and Pierre Baldi.
Modeling dynamic functional connectivity with latent factor gaussian processes. Advances in
neural information processing SyStemS, 32:8263-8273, 2019.
10
Under review as a conference paper at ICLR 2022
Xiaoxiao Li, Yuan Zhou, Nicha C. Dvornek, Muhan Zhang, Juntang Zhuang, Pamela Ventola, and
James S. Duncan. Pooling regularized graph neural network for fmri biomarker analysis. Medical
image computing and computer-assisted intervention : MICCAI ... International Conference on
Medical Image Computing and Computer-Assisted Intervention,12267:625-635, 2020.
Ziyu Liu, Hongwen Zhang, Zhenghao Chen, Zhiyong Wang, and Wanli Ouyang. Disentangling
and unifying graph convolutions for skeleton-based action recognition. In Proceedings of the
IEEE/CVF conference on computer vision and pattern recognition, pp. 143-152, 2020.
Sylvia Loh, Nicole Lamond, Jill Dorrian, Gregory Roach, and Drew Dawson. The validity of psy-
chomotor vigilance tasks of less than 10-minute duration. Behavior Research Methods, Instru-
ments, & Computers, 36(2):339-346, 2004.
Steven J Luck and Edward K Vogel. The capacity of visual working memory for features and
conjunctions. Nature, 390(6657):279-281, 1997.
Andrew Mattarella-Micke, Jill Mateo, Megan N Kozak, Katherine Foster, and Sian L Beilock.
Choke or thrive? the relation between salivary cortisol and math performance depends on in-
dividual differences in working memory and math-anxiety. Emotion, 11(4):1000, 2011.
Fuad Noman, Chee-Ming Ting, Hakmook Kang, Raphael C. W. Phan, Brian D. Boyd, Warren D.
Taylor, and Hernando Ombao. Graph autoencoders for embedding learning in brain networks and
major depressive disorder identification, 2021.
Aaron van den Oord, Nal Kalchbrenner, Oriol Vinyals, Lasse Espeholt, Alex Graves, and Koray
Kavukcuoglu. Conditional image generation with pixelcnn decoders. In Proceedings of the 30th
International Conference on Neural Information Processing Systems, pp. 4797-4805, 2016.
Marcus E Raichle. The brain’s default mode network. Annual review of neuroscience, 38:433-447,
2015.
Luana Ruiz, Fernando Gama, and Alejandro Ribeiro. Gated graph recurrent neural networks. IEEE
Transactions on Signal Processing, 68:6303-6318, 2020.
Franco Scarselli, Marco Gori, Ah Chung Tsoi, Markus Hagenbuchner, and Gabriele Monfardini.
The graph neural network model. IEEE Transactions on Neural Networks, 20(1):61-80, 2009.
doi: 10.1109/TNN.2008.2005605.
Alexander Schaefer, Ru Kong, Evan M Gordon, Timothy O Laumann, Xi-Nian Zuo, Avram J
Holmes, Simon B Eickhoff, and BT Thomas Yeo. Local-global parcellation of the human cerebral
cortex from intrinsic functional connectivity mri. Cerebral cortex, 28(9):3095-3114, 2018.
Ramprasaath R Selvaraju, Michael Cogswell, Abhishek Das, Ramakrishna Vedantam, Devi Parikh,
and Dhruv Batra. Grad-cam: Visual explanations from deep networks via gradient-based local-
ization. In Proceedings of the IEEE international conference on computer vision, pp. 618-626,
2017.
Youngjoo Seo, Michael Defferrard, Pierre Vandergheynst, and Xavier Bresson. Structured sequence
modeling with graph convolutional recurrent networks. In International Conference on Neural
Information Processing, pp. 362-373. Springer, 2018.
Yunsheng Shi, Zhengjie Huang, Shikun Feng, Hui Zhong, Wenjin Wang, and Yu Sun. Masked label
prediction: Unified message passing model for semi-supervised classification, 2021.
Maurice L Sipos, Yair Bar-Haim, Rany Abend, Amy B Adler, and Paul D Bliese. Postdeploy-
ment threat-related attention bias interacts with combat exposure to account for ptsd and anxiety
symptoms in soldiers. Depression and Anxiety, 31(2):124-129, 2014.
Chao Song, Youfang Lin, Shengnan Guo, and Huaiyu Wan. Spatial-temporal synchronous graph
convolutional networks: A new framework for spatial-temporal network data forecasting. In
Proceedings of the AAAI Conference on Artificial Intelligence, volume 34, pp. 914-921, 2020.
Mukund Sundararajan, Ankur Taly, and Qiqi Yan. Axiomatic attribution for deep networks. In
International Conference on Machine Learning, pp. 3319-3328. PMLR, 2017.
11
Under review as a conference paper at ICLR 2022
BT Thomas Yeo, Fenna M Krienen, Jorge Sepulcre, Mert R Sabuncu, Danial Lashkari, Marisa
Hollinshead, Joshua L Roffman, Jordan W Smoller, Lilla Zollei, Jonathan R Polimeni, et al. The
organization of the human cerebral cortex estimated by intrinsic functional connectivity. Journal
Ofneurophysiology,106(3):1125-1165, 2011.
J Jay Todd and Rene Marois. Capacity limit of visual short-term memory in human posterior parietal
cortex. Nature, 428(6984):751-754, 2004.
Aaron van den Oord, Sander Dieleman, Heiga Zen, Karen Simonyan, Oriol Vinyals, Alex Graves,
Nal Kalchbrenner, Andrew Senior, and Koray Kavukcuoglu. WaveNet: A Generative Model for
Raw Audio. In Proc. 9th ISCA Workshop on Speech Synthesis Workshop (SSW 9), pp. 125, 2016.
Alexander B Wiltschko, Benjamin Sanchez-Lengeling, Brian Lee, Emily Reif, Jennifer Wei,
Kevin James McCloskey, Lucy Colwell, Wesley Qian, and Yiliu Wang. Evaluating attribution
for graph neural networks. Google Research, 2020.
Felix Wu, Amauri Souza, Tianyi Zhang, Christopher Fifty, Tao Yu, and Kilian Weinberger. Sim-
plifying graph convolutional networks. In International conference on machine learning, pp.
6861-6871. PMLR, 2019a.
Zonghan Wu, Shirui Pan, Guodong Long, Jing Jiang, and Chengqi Zhang. Graph wavenet for
deep spatial-temporal graph modeling. International Joint Conferences on Artificial Intelligence
(IJCAI), 2019b.
Keyulu Xu, Weihua Hu, Jure Leskovec, and Stefanie Jegelka. How powerful are graph neural
networks? In International Conference on Learning Representations, 2018.
Steven Yantis, Jens Schwarzbach, John T Serences, Robert L Carlson, Michael A Steinmetz, James J
Pekar, and Susan M Courtney. Transient neural activity in human parietal cortex during spatial
attention shifts. Nature neuroscience, 5(10):995-1002, 2002.
Rex Ying, Jiaxuan You, Christopher Morris, Xiang Ren, William L Hamilton, and Jure Leskovec.
Hierarchical graph representation learning with differentiable pooling. In Proceedings ofthe 32nd
International Conference on Neural Information Processing Systems, pp. 4805-4815, 2018.
Gemeng Zhang, Biao Cai, Aiying Zhang, Julia M Stephen, Tony W Wilson, Vince D Calhoun, and
Yu-Ping Wang. Estimating dynamic functional brain connectivity with a sparse hidden markov
model. IEEE transactions on medical imaging, 39(2):488-498, 2019.
12
Under review as a conference paper at ICLR 2022
A Appendix
A.1 Models
A.1.1	Dynamic functional connectivities.
Fig. 8 shows functional connectivities (FCs) among N brain regions, where each FC ∈ RN ×N . The
value at FCij is calculated as the Pearson correlation coefficient between signals of brain region i
and region j . The figure shows 6 FCs calculated from 6 consecutive sliding windows within a same
fMRI session, with signal window length being 30 and sliding stride being 30. From the figure, we
can clearly tell that FCs are highly dynamic.
Figure 8: Dynamic functional connectivities.
A.1.2 Inner-cluster smoothing toy example.
Here we show a toy example demonstrating the inner-cluster smoothing module described in eqs. (3)
and (4). Note that we will only show one time slice, and the same operation is done along every
t: on a particular t, we have Z ∈ RN ×d , S ∈ RN ×c . We will use N = 3, c = 2 and node values
a, b, c ∈ Rd for this toy example. In addition, this example is just to illustrate the concept behind the
smoothing operation, and Softmax along the axis 1 is simplified as row normalization for a clearer
presentation.
⇒ Hnew
=S> H =
rγ	ι ∙ ι
S = row-normalized
⇒ H = S > z =
3 a + 3 b
万a +万b + Cc
3b+fc 3
a + 2 b、
(2b + c)
Figure 9: Inner-cluster smoothing toy example.
In this example, 1st and 2nd nodes are assigned to the first cluster, and 2nd and 3rd node are assigned
to the second cluster. The final Hnew after our smoothing module will mingle the first two nodes’
values, and the last two nodes’ values (based on assignment weights) while keeping their original
node number unchanged.
A.1.3 Regularization terms for the soft-assignment.
For each soft assignment matrix S ∈ RN ×c×t in eq. (3), we test three regularization terms:
•	Similar to DiffPool, for ensuring a more clearly defined node assignment, namely each
node is only assigned to few clusters (the closer to one the better), we can minimize the
entropy of single node assignments: LEI = C Ec=I H(Si), where Si is along c.
•	To ensure a representation separation among nodes, meaning the assignment shouldn’t as-
sign all the nodes a same way, we maximize the entropy of node assignment patterns across
all nodes: LE2 = -C Ec=I H(En=I Sij), where j is along n and i is along c.
13
Under review as a conference paper at ICLR 2022
• To make assignment along temporal axis smoother, we penalize assignment variances
within a small window [t, t + T]: LT = t-1τ P^=T σ(S[^,^+τ]), where σ represents standard
deviation.
Together with cross entropy classification loss LCE, the final loss function of the model will be:
Lreg = α1LCE + α2LE1 + α3LE2 + α4LT,
αi = 1
i
(6)
A.2 Experiments
A.2.1 Task descriptions.
The following are task descriptions of CRASH (Cognitive Resilience and Sleep History) dataset:
Resting state: The subject simply lays in the scanner awake, with eyes open for 5 minutes.
Visual working memory task (VWM): The subject is presented with a pattern of colored squares
on a computer screen for a very brief period (100ms). After 1000ms, they are presented with a
single square and must determine if it is the same or different color as the previously presented
square at that location. Responses are made with a button press (Luck & Vogel (1997)).
Dynamic Attention Task (DYN): Two streams of orientation gratings are presented to the left and
right of fixation. Subjects monitor specified stream for a target (about 2 degree shift in orientation,
clockwise or counter clockwise) that indicates whether the subject should continue to monitor the
current stream (hold) or monitor the other stream (shift) and respond with a button press (Yantis
et al. (2002)).
Dot Probe Task (Faces) (DOT): On each trial, two faces are presented, one neutral and the other
happy or angry for 500ms. Then, either of two simple symbols is presented at the position of either
of the faces. The subject must make a forced choice discrimination of the symbol. Reaction time
differences as a function of the valance for the preceding facial expression are calculated. There is
increased variability of the bias with PTSD and fatigue (Sipos et al. (2014)).
Math task (MOD): Subjects perform a modular math computation every 8 seconds and respond
with a yes or no button press. The object of modular arithmetic is to judge the validity of problems
such as 51=19(mod 4). One way to solve it is to subtract the middle number from the first number
(i.e., 51-19) and then divide this difference is by the last number (32/4). If the dividend is a whole
number, the answer is “true.” Otherwise the answer is false (Mattarella-Micke et al. (2011)).
Psychomotor vigilance task (PVT): The subject monitors the outline ofa red circle on a computer
screen for 10 minutes, and whenever a counter clockwise red sweep begins, they press a button
as fast as possible. Subjects are provided with response time feedback. The experimenter records
response latencies (Loh et al. (2004)).
A.2.2 Data details
After discarding scan sessions with abnormal spikes that may be caused by head movements, the
valid session details for different tasks are listed in table 2.
Table 2: fMRI scan details for six tasks.		
Tasks	Resting VWM DYN DOT MOD PVT	(Total)
Valid scan sessions	-209	5Γ4	767	155	138	157-	1940
Frames / Scan	321	300	265	798	828	680	/
A.2.3 Ablation studies
Numerical values of fig. 3a are reported in table 3. Training time ranges from 51 seconds / epoch
for length-8 inputs to 298 seconds / epoch for length-256 inputs. Although the model is trained for
60 epochs in all experiments, it converges to a relatively stable loss level within 20 epochs.
14
Under review as a conference paper at ICLR 2022
Table 3: Weighted F1 of ablation study settings.
Input length (frames)	8	16	32	64	128	256
(i): SC + adp	66.19	70.18	75.87	76.14	82.91	90.85
(ii): SC only	64.54	65.58	71.79	70.31	73.63	89.79
(iii): adp only	64.32	65.20	74.01	71.42	80.63	89.46
(iv): SC + FC	66.10	67.58	70.26	75.02	76.91	84.68
(v): random adj	62.17	66.25	72.30	73.72	76.58	89.22
(vi): (i) without smoothing	63.57	62.82	70.19	65.82	72.91	79.65
(vii): (v) without smoothing	56.88	64.08	72.27	62.72	75.16	83.75
(viii): coarsened graph	37.92	42.23	46.18	52.12	57.17	64.25
(b) Ai_adp ∈ r200×200 of 6 consecutive inputs from a same session during DOT task.
(e) 34 (17 with LR) subnetworks’ column averages of task-averaged Aadp. Task order is the same as (c).
Figure 10: Learned latent adaptive adjacency matrices Aadp.
(I)	Latent adaptive adjacency matrix Aadp. As we mentioned in section 3.1, latent Aadp can
complement the task- and temporal-fixed A. We will now show that the learned Ai_adp is sparse for
each sample, has evident task-based patterns, and differs from what Ai can provide: fig. 10 shows
visualizations of latent Aadp, which we can tell is quite sparse as in fig. 10a: each input only gets
few important columns (information providing nodes in GNN), and they vary from one sample to
another, indicating Aadp’s ability to adapt to changing inputs within a same task. However, when we
look into inputs (not shuffled) generated by consecutive sliding windows from a same scan session
as in fig. 10b, we can see the latent structures appear to be in a smooth transition. In addition, when
averaged across many samples for each task, undeniable task-based patterns emerge, as in figs. 10c
15
Under review as a conference paper at ICLR 2022
to 10e. But the task-average patterns are also different from what we saw from AttrA in fig. 5,
suggesting Aadp is embedding dynamics that are not captured by A. One interesting phenomenon
in fig. 10e is that across all tasks, LimbicB-OFC, DefaUlt_B, and LimbicA-TempPole are always
among the most important subnetworks appeared in the latent Aadp. Further exploration is needed
for explaining the case.
(II)	Number of GNN layers. The total nUmber of temporal layers depends on the inpUt signal
length since each strided TCN layer redUces the temporal length by a factor of2: if the inpUt length
is 2i, there need to be i temporal layers. BUt is alternating every TCN with GNN the best strategy, or
do we only need to follow one GNN after a few TCNs? We stUdy this qUestion with different inpUt
lengths.
Model weighted F1 are plotted in fig. 3b for all possible GNN to total TCN ratios (e.g. length-256
inputs requires 8 TCN layers. The possible ratios are 8, 4, 2, 1 since We can insert one GNN per
8, 4, 2, 1 TCN layers). The figUre shows alternating every layer rarely yields the highest perfor-
mance and the best ratio lines around one GNN per two TCN layers for our dataset. We repeat the
experiment for K = 1, 3 (in eq. (2)) to rule out the possibility that this result is related to how many
neighbors one GNN layer can reach; we find they have roughly the same pattern as the K = 2 case.
Our hypothesis is that lower GNN to TCN ratio does not capture enough spatial context, while
higher ones might be overfitting. We leave exploring the relationship between this ratio and nodes
number N to a future study.
The best GNN to TCN ratio also depends on whether model incorporates latent adjacency matrices
or not: without Aadp, length-128 signals achieves its relative best (among all ratios) when having
one GNN per two TCNs, but it only needs one GNN per three TCNs if using Aadp. This shows
learning latent structures Aadp not only improves overall model accuracy but can also reduce model
parameters, thus complexity, in achieving the relative best results.
(III)	Effects of soft-assignment cluster numbers. During our experiments, we find as long as the
smoothing module is used, the final performance will be close to each other, only the convergence
rates are different. Fig. 11b shows how validation loss converges with different c settings and when
there is no smoothing module used. From it, we can see halving numbers (100-50-25-12) is most
helpful and we use it for our other experiments; decreasing numbers (160-120-80-40) or all larger
numbers (all 100) works better than increasing numbers (12-25-50-100) or all smaller numbers (all
12). Using the inner-cluster smoothing module, all cluster number settings converges to around 0.23
at their smallest when trained for 60 epochs and have test weighted F1 from 89.47 (model with 12-
25-50-100) to 90.85 (model with 100-50-25-12). On the contrary, if no smoothing module is used,
the model overfits easily and the validation loss can only reach about 0.4 before going up (with the
best set of learning rate and weight decay parameters found with grid search). It is understandable
that the model is prone to overfitting given the complexity of GNN and the relatively small dataset
size. Our added inner-cluster smoothing module seem to effectively countering the effect and brings
the loss down further and stabler.
A.2.4 Model comparisons.
We plot confusion matrices of our model, model from ablation study setting (viii), and the best
performing baseline in fig. 12. Misclassification pairs clustered as the first three tasks (resting,
VWM, DYN) and the latter three (DOT, MOD, PVT). Shown confusion matrices are from models
trained on 256-frame inputs. We note that these misclassification pairs may be different for models
trained on other input lengths (like 128-frame, etc.).
A.2.5 IG AttrA AND AttrX
See fig. 13 for the visualization of important ROIs based on AttrA, and fig. 14 for task-averaged
AttrA under real and random SC settings. Many discriminatory regions obtained from AttrA com-
plies with the literature:
For resting state: the top attributed ROIs belong to the default mode network, which is regarded
salient during the resting state (Raichle, 2015).
For VWM: the dominant attributions are from visual regions and posterior parietal regions, which
complies with Todd & Marois (2004).
For DYN: attributions from our model suggest regions along cingulate gyrus (defaultA-
16
Under review as a conference paper at ICLR 2022
Figure 11: 11a: adding inner cluster smoothing or input-dependent adaptive adjacency matrix makes
the model more stable across various learning rates. 11b: Validation loss v.s. training epochs. Input
length is 256 and four smoothing modules are used. Legends are the soft-assignment cluster numbers
of the four smoothing modules. Our other experiments are using decreasing cluster numbers that
halved each module, corresponding to the 100-50-25-12 here.
(a)
(b)
(c)
Figure 12: Confusion matrices of: (12a) ReBraiD (our proposed model), (12b) model with coarsened
graph (setting (viii)), (12c) Graph Transformer (best-performing baseline). Tasks are 1-Resting, 2-
VWM, 3-DYN, 4-DOT, 5-MOD, 6-PVT.
Figure 13: Important ROIs based on AttrA . Tasks are: Resting, VWM, DYN, DOT, MOD, PVT
from left to right. Node sizes are based on column sums of AttrA ∈ R200×200 and edge width are
direcly based on AttrA . For the visualization purpose, only edges with highest attributions are kept
to ensure sparsity being 0.009 (down from around 0.196).
SalValAttnB-ContA-ContC-defaultC), as well as peripheral visual and somatomotor regions. Liter-
ature suggests anterior cingulate cortex (ACC) to be active (Kim et al., 2016) and posterior cingulate
cortex (PCC) to be inactive (Leech & Sharp, 2014) during visual attention tasks. This means both
regions provide discriminative information about classifying DYN states, which is what our attribu-
tion method is voting for.
For DOT: important ROIs from our analysis are located in control networks, in particular both ACC
and PCC, as well as in the peripheral visual system. In the literature, dorsal and rostral regions of
the ACC are proved to be involved with dot-probe performance (Carlson et al., 2012; 2013).
17
Under review as a conference paper at ICLR 2022
Figure 14: Task-averaged ATTRA ∈ R200×200 . The top row is obtained from real SC induced A,
and the bottom row is obtained from random SC induced Arand .
For MOD: our important ROIs are mostly in temporal-parietal regions and default mode network
(anatomically fronto-parietal), and literature suggests similar regions: parietal (Grabner et al., 2011)
and prefrontal (Friedrich & Friederici, 2013).
For PVT: our top attributed ROIs belong to control networks, attention networks, and somatomotor
regions. Similar as stated in Drummond et al. (2005), where both attention and motor systems are
considered important.
To view brain regions in the 17-networks setting instead of 200-ROI parcellations, table 5 has the
subnetwork rankings based on column-average AttrA and table 6has the subnetwork rankings based
on temporal-averaged AttrX. For a visualization of the 17-network parcellation, please refer to
fig. 15.
See fig. 16 for the complete attribution distributions for every task based on temporal-averaged
AttrX . Corresponding brain regions of a certain number are listed in table 4. For boxplots showing
17 regions, we combine LH and RH for their common network.
Table 4: Brain subnetworks in the 17-network definition.
1	LH-VisCent
18 RH-VisCent
2	LH-VisPeri	19	RH-VisPeri
3	LH-SomMotA	20	RH-SomMotA
4	LH-SomMotB	21	RH-SomMotB
5	LH-DorsAttnA	22	RH-DorsAttnA
6	LHDorsAttnB	23	RHDorsAttnB
7	LH-SalVentAttnA	24	RH-SalVentAttnA
8	LH-SalVentAttnB	25	RH-SalVentAttnB
9	LH_LimbiCB-OFC	26	RH_LimbiCB-OFC
10	LH-LimbiCA-TemPPole	27	RH-LimbiCA-TemPPole
11	LH-ContA	28	RH-ContA
12	LH-ContB	29	RH-ContB
13	LH-ContC	30	RH-ContC
14	LHRefaUltA	31	RHDefaultA
15	LHRefaultB	32	RH_DefaultB
16	LHDefaultC	33	RHRefaUltC
17	LH-TemPPar	34	RH-TemPPar
18
Under review as a conference paper at ICLR 2022
■ Ni! Viscent	■ N2: VisPen ■ NS: SomMotA ∣ N4: SomMotB ■ NS: DorsAttnA ■ N6: DorsAttnB
■ N7: SalVentAttnA	∣ N8： SaIVentAttnB ■ N9: LimbicB N10: LimbicA ■ Nil: ContA	■ NL2: ContB
■ N13: ContC	Nl4: DefauItA	■ N15: DefauItB ∣ N16: DefauitC ∣ N17:TempPar
Figure 15: Network parcellation of Yeo’s 17-networks. Figure is from Kahali et al. (2021)
Table 5: AttrA: Top 10 brain subnetworks initiate important connections during different tasks
(fig. 13 provides a ROI-based visualization).
	rest	VWM	DYN	DOT	MOD	PVT
1	RH-DefaUltA	RH-ViSPeri	LH-SomMotB	RH-ViSPeri	RH-DefaUltA	RH-ContA
2	LH-DefaUkA	LH-ViSPeri	RH-DefaUltC	LH-VisPeri	LH-DefaultA	RH-SalVentAttnA
3	RH-DefaultB	LH-ViSCent	LH-VisPeri	RH-ContC	LH-DefaultC	RH-ContC
4	RH-ContB	RH-VisCent	LH-SalVentAttnA	RH-DorSAttnA	RH-DefaUltC	LH-SalVentAttnA
5	RH-LimbiCB-OFC	LH-DefaUltC	RH-ContC	RH-SalVentAttnA	RH-DefaUltB	RH-DefaUltA
6	RH-SalVentAttnB	RH-SomMotB	RH-ContA	LH-ContC	RHLmbiCB-OFC	LH-ContC
7	RH-SomMotB	RH-DefaultC	RH-DefaUltA	RH-DefaUltC	LH-SomMotB	RH-DorSAttnA
8	RH-TemPPar	LH-SomMotB	RH-SalVentAttnA	LH-SomMotB	RHLmbiCA-TemPPole	LH_LimbicB_OFC
9	LH-DefaUltB	LHLmbiCA-TemPPole	LH-DefaUltC	RH-ContA	LH-DefaultB	LH-SomMotB
10	RH-SalVentAttnA	RH-LimbiCA-TemPPole	RH-ViSPeri	RH-ViSCent	RH-SomMotB	RH-DefaUltC
Table 6: AttrX : Top 10 brain subnetworks that are sources of the important signals during different
tasks (fig. 6 provides a ROI-based visualization).
	rest	VWM	DYN	DOT	MOD	PVT
1	RH-VisCent	RH-ViSCent	LH-TemPPar	RH-LimbiCBqFC	LH-TemPPar	RH-ViSCent
2	LH-VisCent	LH-VisCent	RH-SomMotB	LH-LimbiCA-TemPPOle	LH _LimbiCA-TemPPOle	LH-DOrSAttnA
3	LH-DOrSAttnA	LH-DOrSAttnA	LH-VisPeri	RH-DefaUltB	RH-SomMotB	LH-VisCent
4	RH-DorsAttnA	RH-DOrSAttnA	LH-DefaUltA	LH-TemPPar	LH-DefaUltB	RH-DOrSAttnA
5	LH-ContA	LH-ContA	LH-DefaUltC	RH _LimbiCA-TemPPOle	RH-DefaultA	RH-LimbiCB-OFC
6	LHRorsAttnB	LH-DorsAttnB	RH-DefaultC	RH-TemPPar	RH-LimbiCA-TemPPOle	LH-ContA
7	LH-SomMotA	LH-SalVentAttnA	RH-SomMotA	LH-DefaultB	LH_LimbicB_OFC	RH-LimbiCA-TemPPOle
8	LH-SalVentAttnA	LH-SomMotA	LH-ContB	LH-LimbicB-OFC	RH-DefaultB	LH-SomMotA
9	RH-ContA	RH-LimbiCBqFC	RH-SalVentAttnA	RH-SomMotB	LH-ContB	LHLmbiCBqFC
10	LH-LimbicB-OFC	LH-LimbicB-OFC	LH-DefaultB	LH-DefaultA	LH-DefaultA	LH-DorsAttnB
19
Under review as a conference paper at ICLR 2022
(a) Resting state.
(b) Visual working memory task.
1	2 i 4	5	6 T β 9	10	11	12	13	14	15	16	17
H∏∣{
° O
(c) Dynamic Attention Task.
(f) Psychomotor vigilance task.
(d) Dot Probe Task.
(e) Math Task.
Figure 16: Brain subnetwork attribution distributions from AttrX .
20
Under review as a conference paper at ICLR 2022
A.2.6 Attribution reproducibility
In order to be used for downstream tasks, the extracted important regions should be reproducible
across different initializations. Since the overall problem is non-convex, we test the reproducibility
empirically with two models trained on two data splits, both initialized randomly and taking in
length 256 inputs.
(a) Column averages of AttrA ∈ R200×200 .
(b) Temporal averages of AttrX ∈ R200×256
Figure 17: Reproducibility validation: attributions obtained from two models trained on different
data split and initialized randomly. Attribution values are normalized to [0, 1] and the larger the
attribution value, the stronger indicating power that ROI has for a certain task. Tasks are Resting,
VWM, DYN, DOT, MOD, and PVT.
21
Under review as a conference paper at ICLR 2022
A.2.7 Simulation study
To validate interpretation results, we perform simulation studies with know ground truth. For gener-
ating graph signals, we first define graph structures. All graphs are generated with stochastic block
model (SBM) using a same community structure (200 nodes, 10 communities), but each graph has
its own adjacency matrix. This mimics brain structures in that samples share similar community
structures but have different structural connectivities. Fig 18a shows a typical adjacency matrix of
a synthetic graph. All adjacency matrices are binary. Time-series on each node are then generated
with codes adapted from this repo 4. In particular, the value at each time step of each node is a
small temporal Gaussian random noise plus signals from neighbors (a small Gaussian spatial noise
is added to the adjacency matrix).
Simulation (I) We create two classes for this simulation: in class one, only the first three commu-
nities (nodes 1 - 60) generate small temporal noises and other nodes are only affected by neighbors;
in class two, only the last three communities (nodes 141 - 200) generate small temporal noises and
other nodes are only affected by neighbors. We visualize task aggregated AttrX and Aadp and in
figs. 18b and 18c. The signal importance differences are relatively well reflected in AttrX. For the
generated series, signals are more important in node 1 - 60 for class 1 and 141 - 200 for class 2:
Aadp catches this up and help propagating signals in these regions better. We notice that AttrA are
mostly random and no obvious patterns are shown. This also reflects the graph signal generation:
when aggregating information from neighbors, all connected edges are weighted the same (binary),
thus the connections not really affect generated signals. To see the opposite, we perform another
study below.
Simulation (II) We again create two classes for the simulation: in class one, connections from nodes
61 - 100 are strengthened; in class two, connections from nodes 101 - 140 are strengthened. The
weights of strengthened edges are increased from 1 to 5 during signal generation, but model still
takes in binary adjacency matrices as inputs (processed as mentioned in section 2.1 before feeding
to the model). We visualize task aggregated Aadp and AttrA in figs. 18d and 18e. We can see this
time the connection differences are reflected in AttrA. Signals in node 61 - 100 for class 1 or 101
-140 for class 2 are less important because they can be sent out by stronger connections: this results
in smaller values for corresponding columns in Aadp . Combined with previous simulation, regions
that are strong signal senders and connections from them are weak or not reflected in graph adja-
cency matrices tend to have higher Aadp values. In other words, Aadp complements both signals and
connections to encode latent dynamics, while attributions obtained from IG are better at interpreting
the modalities separately.
4https://github.com/alelab-upenn/graph-neural-networks
22
Under review as a conference paper at ICLR 2022
(a) Adjacency matrix
O 50 IOO 150 O 50 IOO 150
(b) Simulation (I) AttrX
(d) Simulation (II) Aadp
Figure 18: 18a: A typical adjacency matrix for simulated graph signals. 18b: Task averaged AttrX
of simulation (I). Attribution values are normalized. 18c: Task averaged Aadp of simulation (I) and
its entry averages per column. 18d: Task averaged Aadp of simulation (II). 18e: Task averaged AttrA
of simulation (II). Attribution values are normalized.
(c) Simulation (I) Aadp
(e) Simulation (II) AttrA
23