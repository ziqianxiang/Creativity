Under review as a conference paper at ICLR 2022
Fundamental Limits of Transfer Learning in
B inary Classifications
Anonymous authors
Paper under double-blind review
Ab stract
A critical performance barrier in modern machine learning is scarcity of labeled
data required for training state of the art massive models, especially in quickly
emerging problems with lack of extensive data sets or scenarios where data col-
lection and labeling is expensive/time consuming. Transfer learning is gaining
traction as a promising technique to alleviate this barrier by utilizing the data of
a related but different source task to compensate for the lack of data in a target
task where there are few labeled training data. While there has been many recent
algorithmic advances in this domain, a fundamental understanding of when and
how much one can transfer knowledge from a related domain to reduce the amount
of labeled training data is far from understood. We provide a precise answer to
this question for binary classification problems by deriving a novel lower bound
on the generalization error that can be achieved by any transfer learning algorithm
(regardless of its computational complexity) as a function of the amount of source
and target samples. Our lower bound depends on a natural notion of distance
that can be easily computed on real world data sets. Other key features of our
lower bound are that it applies to any arbitrary source/target data distributions
and requires minimal assumptions that enables it application to a broad range of
problems. We also consider a more general setting where there are more than one
source domains for knowledge transfer to the target task and develop new bounds
on generalization error in this setting. We also corroborate our theoretical findings
on real image classification and action recognition data sets. These experiments
demonstrate that our natural notion of distance is indicative of the difficulty of
knowledge transfer between different pairs of source/target tasks, allowing us to
investigate the effect of different sources on the target generalization error. Further-
more, to evaluate the sharpness of our bounds we compare our developed lower
bounds with upper-bounds achieved by transfer learning base-lines that utilize
weighted empirical risk minimization on the combination of source(s) and target
data sets.
1	Introduction
Modern machine learning models such as deep neural networks have enjoyed wide success in many
domains Krizhevsky et al. (2012). The success of such deep models critically relies on an enormous
amount of data required for training these massive models. For instance, GPT3 which is the state
of the art model for natural language process has 175 billion parameters and requires a data set of
size 45 terabytes for training. However, in new or emerging application domains it is often extremely
difficult or costly to gather such large labeled training data.
A promising approach to this problem has been via transfer learning which aims at leveraging
abundant available labeled data from a related source task to reduce the amount of labeled data
required for the target task Pan & Yang (2009); Weiss et al. (2016). From a practical perspective
transfer learning has been rather successful empirically. In particular, state of the art transfer learning
approaches based on pretrained models and fine tuning has led to significant improvements on various
benchmark datasets. Despite this empirical success however there is a huge gap between theory and
practice in transfer learning and the fundamental limits and benefits of transfer learning are not well
understood. Key challenging questions include: What is an appropriate notion of similarity between
different tasks and how can it be quantitatively defined and computed on real data? What is the best
1
Under review as a conference paper at ICLR 2022
achievable accuracy of any transfer learning algorithm with only a limited number of source and
target samples? How does this accuracy depend on the number of samples and the similarity between
the source and target tasks?
While the answer to these challenging questions are still not fully understood, they have indeed
attracted a lot of interesting theoretical work in this area Galanti et al. (2016). We will discuss
this literature in thorough detail in Section 2. In this paper, we take a step towards answering the
aforementioned key questions enabling a better understanding of the fundamental limits of transfer
learning. We focus on binary classifications where the goal is to learn a classifier from a hypothesis
class with a finite VC-dimension. This covers most contemporary classification models including the
training deep neural networks for binary classification. In this setting, we first define a natural notion
of similarity between source and target tasks via the performance of the best source hypothesis on the
target task. Then equipped with this notion of similarity, we derive a statistical minimax lower bound
on the target generalization error in terms of the number of labeled data from source and target tasks
as well as the VC dimension of the hypothesis class and the similarity between source and target
tasks. Furthermore, we extend this result to the case where there are multiple sources with different
similarity to the target. Our results demonstrate that sources with high similarity to the target are
more effective at reducing the target generalization error. Towards bridging the theory-practice gap
in transfer learning we also demonstrate the utility of our theoretical result in concrete applications.
Indeed, a key feature of our result is that our lower bounds can be easily and efficiently computed on
real data sets and apply to a broad class of practical settings.
In summary our key contributions are as follows:
•	We develop a novel statistical minimax lower bound on the generalization error that can be
achieved by any transfer learning algorithm as a function of the amount of source and target
samples and a natural notion of similarity between source and target tasks.
•	A key features of our lower bound (including our notion of similarity) is that it can be easily
computed on real world data sets. Furthermore, our lower bound holds for any source/target
distribution and applies with minimal assumptions to a wide variety of contemporary learning
models including deep neural networks.
•	We investigate the sharpness of our lower bounds and demonstrate their utility via experi-
ments on action recognition and image classification.
2	Prior Works
A closely related literature to transfer learning is domain adaptation where there is no or very few
labeled target data and the goal is to adapt the hypothesis learned on the source domain to achieve a
low target generalization error Chen et al. (2019); Blitzer et al. (2007); Azizzadenesheli et al. (2018);
Long et al. (2016); Shen et al. (2018). Most of this literature assume that source and target share a
common labeling rule but there is a shift in the marginal distributions. There are many upper bounds
for the target generalization error in this setting this setting. For instance, Ben-David et al. (2007;
2010) gives an upper bound for the target generalization error in terms of source generalization error
and a divergence measure between the domains that can be estimated by finitely many unlabeled
data from the source and target. In another work Mansour et al. (2009) introduces a new discrepancy
distance and generalizes the results of Ben-David et al. (2007) for a wide family of loss functions
using Rademacher complexity. Similar to this setting, but for multiple source domain adaption
scheme, Mansour et al. (2021) proposes a family of algorithms based on the idea of model selection
under the assumption that target distribution is close to some convex combination of sources. A more
recent work Lei et al. (2021) studies linear regression under shift distribution including covariate
shift (i.e. conditional distributions of source and target are the same) as well as model shift (i.e. only
distributions of the features of the source and target are the same) and develops algorithms achieving
near optimal minimax risk in this setting.
In addition to upper bounds, there are also a few results which provide lower bounds for target
generalization error. David et al. (2010) provides impossibility results under the assumption of
covariate shift and small discrepancy of unlabeled distributions. Mousavi Kalan et al. (2020) studies
transfer learning with one hidden layer neural networks for regression problems. This result defines a
notion of similarity between the source and target tasks based on a distance between the ground truth
2
Under review as a conference paper at ICLR 2022
parameters of the source and target networks. Using this distance this paper develops a statistical
minimax lower bound for the target generalization error in terms of the number of source and target
samples as well as the defined similarity of the source and target under the distribution shift with the
assumption that the features are generated by Gaussian distributions. Compared to Mousavi Kalan
et al. (2020) our result has quite a few unique advantages: (1) We do not assume that the source
and target data are generated according to a planted (teacher) network and our results now even
hold in the agnostic setting. (2) Mousavi Kalan et al. (2020) applies to regression problems but this
result covers classification (3) Mousavi Kalan et al. (2020) only considered one-hidden layer neural
networks for predicting the labels of extracted features. In this result we can handle arbitrary deep
neural networks. (4) Our notion of similarity between the source and target distributions can be much
more easily estimated by using only a few target data without the need for estimating the ground truth
target parameters which requires lots of labeled target data.
More closely related to this work Hanneke & Kpotufe (2019) derives a minimax lower bound for
target generalization error in binary classification under the assumption of a relaxed version of
covariate shift and small transfer exponent parameter which is defined to measure the discrepancy of
the source and target distributions. Our work differs from this previous work as except for assuming
the VC dimension of the model is finite we do not make any further assumptions. This makes our
results applicable in a much broader set of classifications or decision making problems. Furthermore,
our lower bound can be evaluated on real data sets and serve as a guideline to practitioners helping
them decide when utilizing additional knowledge from a source domain is useful for a given target
task.
Most of the literature in transfer learning try to provide sufficiency and necessity results by deriving
upper and lower bounds for target generalization error in a relatively general setting. However, these
papers often require a variety of assumptions to find the optimal classifier in a target domain in closed
form. For instance, Karbalayghareh et al. (2019; 2018) defines a joint prior distribution of source
and target domains using a Wishart distribution which relate the source and target tasks and then
makes it possible to study and understand the transferability between domains. Furthermore, in this
setting, the authors develop a closed form optimal Bayesian transfer learning and demonstrate its
advantage over a classifier obtained by only target data. Related to this setting but for regressions,
Karbalayghareh et al. (2018) obtains the optimal Bayesian transfer learning under setting of joint
Gaussian feature/label distribution. In contrast with the above in our paper we do not make any
assumptions about the distribution of the data.
3	Problem Formulation
We consider a transfer learning problem where there are some labeled training data from a source
task and a target task with the goal of inferring a hypothesis function with small generalization error
in the target task. More specifically, we assume have nS and nT source and target labeled data where
each training data consists of an input/feature as well as an output/label. We denote the source and
training data by (XS, ys)〜P and (XT, yτ)〜Q, respectively, where ys, yτ ∈ {0,1} and P, Q are
the joint feature-label distributions of source and target data. Additionally, we assume that source
and target features/inputs share a same domain, XS , XT ∈ χ, and H ⊂ 2χ denotes a fixed hypothesis
class with dH VC-dimension.
In transfer learning the goal is to find a hypothesis from H that minimizing the target excess risk
defined below based on a combination of source and target data.
Definition 1 (Excess risk) For a hypothesis function h ∈ H and source and target label-feature data
generated according to distributions P and Q ((xs, ys) 〜 P and (XT, yτ)〜Q), we define the
source and target excess risks as follows
ET(h) = Q[h(χτ) = yτ] - Q[hT(XT) = yτ]
and
ES(h) = P[h(xs) = ys] - P[hS(XS) = ys]
where hT = argminh∈H Q[h(XT) = y] and hS = argminh∈H P[h(Xs) = ys]
Next, we need to define an appropriate notion of distance between the source and target. In the
literature of domain adaptation, where the conditional expectation remains unchanged and there is
3
Under review as a conference paper at ICLR 2022
only a shift in input distributions, it is common to define the distance as the error of performance of
the best source hypothesis in the target task. We also define the distance between source and target as
the target excess risk of the best source hypothesis.
Definition 2 (Transfer distance) We define the transfer distance between a source and a target with
distributions P and Q as follows
ρ(P, Q) ：= Q[hS(XT) = yτ] - Q[hT(XT) = yτ]	(3.1)
Since we aim to derive a minimax lower bound for transfer learning in binary classifications, we
consider the class of pairs of distributions whose transfer distance is within a fixed number ∆. As we
will elaborate further in Remark 7 below this notion of distance can be easily estimated/computed in
practice.
4	Main Results
In this section we characterize the fundamental limits of transfer learning in binary classifications by
deriving a minimax lower bound via information-theoretic arguments.
Theorem 1 Consider a transfer learning problem where there are nS and nT number of source as
well as target data and the hypothesis class H has VC dimension dH obeying dH ≥ 10. Furthermore,
suppose that h = h(SP, SQ) is an estimated hypothesis for the target task using source and target
data in which SP and SQ denote i.i.d. feature-label data pairs {(X(Si), yS(i))}in=S1 and {(X(Ti), yT(i))}in=T1
generated according to the source and target distributions P and Q. Fix a transfer distance ∆ < 0.99.
Then for any h there exists (P, Q) with ρ(P, Q) ≤ ∆ and a universal constant c such that
Prob (ET(h) > c ∙ e(ns,nτ,dχ, △)) ≥ 32^2-,
SP,SQ	8
where
e(nS, nT, dH, △ = nT nτ + 1 ns 一
d dH	d%+ns ∆
This also implies that
inf sup E Et(h)^∣ ≥ C ∙ e(ns,nT,dχ, △).	(4.1)
h p(p,q)≤δ sp,sq L
Remark 1 The bound above characterizes the fundamental limits of transfer learning by providing
a lower bound on the excess risk of any algorithm (regardless of computational tractability) as a
function of the number of source and target training data, the similarity/distance between the source
and target tasks and the dimension of the hypothesis class used.
Remark 2 The assumption △ < 0.99 in the statement of Theorem 1 is just made for simplifying the
analysis and the upper bound of 0.99 can be replaced by any constant in the interval (0, 1).
Remark 3 One can show that the numerical constant C in equation 4.1 obeys C > 3-48/2.
Remark 4 (Connection to PAC learning) We note that the well-known agnostic PAC learning result
for a single task gives a lower bound of C ∙ ʌ/dH where n is the number of samples of the task.
Theorem 1 recovers this result when there is not any source task, namely nS = 0, and the transfer
learning problem reduces to learning a task without any prior knowledge from the source.
Remark 5 (Identical source and target) When the source and target tasks are identical, then the
transfer learning problem reduces to learning a single task with nS + nT training data. Theorem 1,
also leads to the same conclusion in this special case as when the source and target data are identical

△ = 0 and thus e
nS +nT
which states that the lower bound is proportional to reciprocal of
combination of source and target samples as expected.
4
Under review as a conference paper at ICLR 2022
Remark 6 (Sharpness in a special case) We note that the above lower bound is known to be tight
in special cases. For instance when there is a small amount of source data and ∆ is rather large,
the lower bound reduces to JnH which is known to be tight based on known agnostic PAC learning
bounds.
Remark 7 (How to apply Theorem 1 in practical settings.) In this remark we explain how Theorem
1 can be applied when using contemporary machine learning models involving artificial neural
networks. In this case, the hypothesis class corresponds to all neural networks with a fixed architecture
but different parameters. It is known that the class of neural networks with a fixed architecture has
finite VC dimension and Harvey et al. (2017) gives upper and lower bounds for VC dimension
of neural networks with ReLU activation functions. Thus, to apply Theorem 1, one only needs to
have an estimate of the transfer distance per Definition 2. We note that the transfer distance 3.1
consists of two terms: To estimate the first term, we note that hS can be easily estimated due to
the abundance of source data in most applications. Also with an estimate of hS in hand one can
estimate Q[hS (XT) = yτ] rather accurately using a simple empirical average with afew target test
data as well-known concentration of bounded functions imply that this empirical average is well
concentrated around Q[hS (XT) = yτ ]. UP on first glance it seems that estimating the second term
which corresponds to the lowest possible error in the target domain among the hypothesis class,
requires a large amount of labeled target data which is not available in a practical problem. However,
in an overparametrized setting, it is typical to assume that there exists a network which achieves
very small target generalization error so we can ignore the second term in most practical problems.
Finally we note that as stated earlier the lower bound on the target excess risk gives an estimate of
what generalization performance we can expect with a certain number of source and target samples.
Furthermore, by comparing the estimated transfer distance of different pairs of tasks, we can find the
pairs that are more suitable for transfer learning. This knowledge can in turn significantly reduce the
required number of target samples to achieve a certain accuracy.
Next, we extend our result to a multiple source transfer learning setup where instead of only one
source task there are several source tasks available and the goal is to transfer knowledge from multiple
sources to a given target task to achieve a small target generalization error.
Theorem 2 Suppose that there are nS1 , nS2, ..., nSN number of samples from N source tasks as well
as nT number of samples from a target task and the hypothesis class H has VC dimension dH obeying
∕AΓ . rʌ Λr∕rx∖ ʃ-'	.1	.1	. 1~ W / C C	C Γ∙f ∖ ∙	,♦	,7
dH ≥ max (N + 9, N/2). Furthermore, suppose that h = h(SP1 , SP2 , ..., SPN , SQ) is an estimated
hypothesis for the target task using N sources and target data where SPj and SQ denote i.i.d. data
{(X(Si), yS(i))}in=S1j and {(X(Ti), yT(i))}in=T1 generated according to souce and target distributions Pj and
Q for j = 1,..., N. Fix transfer distances {∆j}N=ι where 0 ≤ ∆j ≤ 1. Thenfor any h there exists
(P1, ..., PM, Q) with ρ(Pj, Q) ≤ ∆j and a universal constant c such that
(3 - 2√2
Eτ(h) > C ∙ eg、,∙∙∙,nSN,nτ,dH, δi,∙∙∙, δn) ≥ ——&——,
8
where
e(nS1, ..., nSN, nτ, dH, ∆1, ..., ∆N )
∖T nτ +____nSι____
dH	dH+nS1 ∆1
1
+^"~+ ∙ nSN 二
d d d" +nsN ∆N
This in turn implies that
inf sup
h P(Pj,Q)≤∆j
j=1,...N
E
SP1 ,...,PN ,SQ
IET(h)] ≥ c ∙ e(nsι,..., nSN, nτ, dH, ∆1, ..., ∆N ).
(4.2)
Remark 8 Similar to the previous theorem, Theorem 2 provides a minimax lower bound for target
excess risk with the key distinction that now it applies in the setting where there are multiple source
with different transfer distances to the target. This theorem characterizes the exces risk achievable by
any algorithm as a function of these transfer distances as well as the number of samples from the
different sources and the target data. Theorem 2 indicates that the more sources we have, the better
performance we can achieve in the target domain. However, this performance gain maybe marginal
5
Under review as a conference paper at ICLR 2022
for source tasks that have a large transfer distance to the target or where there are very few training
data. In these cases of course it may be more computationally efficient to discard these sources given
the marginal improvement in the generalization performance suggested by this theorem.
Remark 9 (Identical sources) if all the source tasks are identical, then there are effec-
tively nS1 + ... + nSN number of source samples and by Theorem 1 the lower bound
would be ------------PN---------. Theorem 2 also gives the same order wise lower bound as
nT + Aj=I nSj
V dH +dH + ∆ PN=InSj
v≡+PN1
dHjj - jnτ+—PN=IJnSj	-" dHdH+pN=ι dH^nj
V dH d<i+ + P PN=InSj
Remark 10
(Infinitely many source samples) When ∆i > 0 and nsi → ∞, thefraction 卜 nS——
dH+nSi ∆i
saturates at 六 which shows that When the source and target have positive distance, the source can
never compensate for the target samples.
Remark 11 In the lower bound, the product terms ∆inSi appear which indicate that a source with
large transfer distance can sometimes be as useful as a source with small transfer distance when
there is a large amount of training data available from that source.
5 Experimental Results
In this section we evaluate our theoretical results on real data sets for action recognition and image
classification tasks. By estimating the parameters appearing in Theorem 1 for different pairs of tasks,
we first plot the lower bounds and then by running weighted empirical risk minimization investigate
the sharpness of the bounds. We also investigate the effectiveness of different source tasks with
different transfer distances on the target generalization error.
5.1 Action Recognition
Experimental setup. We first perform experiments on the UCF101 action recognition data set.
We pick CricketBowling and TableTennis videos from UCF101 as the target task as well as three
different pairs of classes as the source tasks: 1- CricketBowling and BaseballPitch, 2- Cricketshot and
Archery, 3- BasketballDunk and Basketball. We pass the videos through an i3d network pretrained on
kinetics400 Carreira & Zisserman (2017) with the fully connected top classifier removed and extract
the corresponding features of dimension 2048 from the raw videos. We then work with the extracted
features instead of the raw videos.
Training. We train a one hidden layer neural network with 15 number of hidden units and ReLU
activation functions for each pair of data sets. Table 3 consists of test accuracy on CricketBowling
vs. TableTennis, when using the network trained on each source task. We use these accuracies for
deriving the corresponding lower bounds. Furthermore, we run weighted empirical risk minimization
as a simple transfer learning approach to find some upper bounds on the target generalization error.
Given nS and nT number of source and target samples, for estimating the corresponding one hidden
layer neural network parameters we minimize the following weighted empirical risk
min
W1,W2
1 λ nT	λ nS
----XCost(W2ReLU(WιxT)),yT)) + -λ XCost(W2ReLU(WιxS0),y?) (5.1)
T i=1	S i=1
where the function Cost denotes the logistic regression cost andλ∈ {0, 0.2, 0.4, 0.6, 0.8, 1}. We
then pick the lambda which minimizes the target test error.
Results. First we calculate the transfer distance by Definition 2 for each source/target pairs using
Table 1. To this end, we assume that best target generalization error is zero and using the Table 1 we
obtain the transfer distance for each pair which is demonstrated in Table 2. As it can be observed
by Table 2, the pair of Source1 and Target has the lowest transfer distance among other pairs since
both of the source and target tasks share a same class which is CricketBowling. Furthermore, Table 2
determines which pairs are more suitable for transferring the source knowledge to the target.
6
Under review as a conference paper at ICLR 2022
Task
Target: CricketBowling vs. TableTennis
Source1: CricketBowling vs. Baseball Pitch
Source2: Cricketshot vs. Archery
Source3: BasketballDunk vs. Basketball
Test accuracy of Target us-
ing the source network
0.946
0.61
0.52
Table 1
pair of tasks	ρ(Source, Target)
(Source1, Target) (Source2, Target) (Source3, Target)	-0.053 0.39 0.48	
Table 2: Transfer distance of pairs of source and target on UCF101 action recognition.
Sourcel-Target
Source2-Target
Source3-Target
(a) Theoretical lower bounds	(b) Lower bounds and upper bounds
Figure 1: (a) depicts our lower bounds for three pairs of source and target tasks on action classification.
(b) depicts the lower bounds along with the upper bounds obtained via weighted empirical risk
minimization.
Next, we draw the lower bound curves for each pair in Fig 1a. To this end, we need to find the
VC dimension of the hypothesis class which consists of neural networks with the architecture of
2048 * 15 * 1 With ReLU activation functions. Theorem 1 in Harvey et al. (2017) gives a lower bound
for VC dimension of neural networks with ReLU activation functions by 焉 WL log2 W where W
and L are the number of parameters and layers, respectively. Then in Figure 1b we plot the lower
bounds along with the upper bounds obtained via Formula 5.1 for three different pairs of source and
target as well as using only target samples. We obtained these upper bounds by running Formula 5.1
five times and then averaging the results. Fig 1b shows that when the distance of a source from the
target is small it would be more effective in achieving small target generalization error. We would
like to mention that in all of these plots we choose the same number of source samples for each pair.
Figure 2 shows the average λ, the weight appearing in Formula 5.1, when the number of target
samples is 100 to 150. It shows that in the pair Source1 and Target the average λ is high which
demonstrate the usefulness of the source in the target task. Furthermore, the small value of λ in the
pair Source3 and Target suggests that when the transfer distance is high, source samples are no longer
usefull.
5.2 Image Classification
Experimental setup. In this section we focus on image classification tasks and utilize Theorem 1 to
recognize appropriate pairs of tasks that are suitable for transfer learning. We choose some classes of
the DomainNet data set Peng et al. (2019) as source and target tasks. We pick Clock and Ambulance
from DomainNet Clipart for the target task and three different pairs of classes as the source tasks:
1- Clock and Ambulance, 2- Cricketshot and TableTennis, 3- TableTennis and FrontCraw. Here we
7
Under review as a conference paper at ICLR 2022
λ egarevA
42
0. 0.
□ □Pair1 □□Pair2 □□Pair3 I
Figure 2:	Average λ in weighted empirical risk minimization for three different pairs of source and
target tasks for action recognition.
Task	Test Accuracy of Target using the source network
Target: Clock vs. Ambulance (Clipart) SourCe1: Clock vs. Ambulance (Sketch) SourCe2: Clock vs. CroW (Sketch) Source3: Crow vs. Basket (Sketch)	- 0.916 0.697 0.65	
Table 3
(b) Lower bounds and upper bounds
Figure 3:	(a) depicts our lower bounds for three pairs of source and target tasks on image classification.
(b) depicts the lower bounds along with the upper bounds obtained via weighted empirical risk
minimization.
pair of tasks	ρ(Source, Target)
(Source1, Target)	-0.083
(Source2, Target)	0.3
(SourCe3, Target)	0.35	
Table 4: Transfer distance of pairs of source and target on DomainNet image classifications].
use ResNet50 network pretrained on Imagenet for extracting features of dimension 2048 and in the
sequel we work with the extracted features rather than the raw image data.
Training. We train a one hidden layer neural network with 15 number of hidden units and ReLU
activation functions for each of pairs of the tasks. Table 3 includes the test accuracy on the target task
when using the networks trained on different sources, which is necessary for estimating/calculating
the transfer distance as demonstrated in Table 4. Similar to the subsection 5.1, we also run weighted
empirical risk minimization for finding upper bounds for the pairs of the source and target tasks.
Results. Similar to the previous section on action recognition, using Table 3 we can obtain the
transfer distances and based on this distance we can identify suitable pairs of source and target tasks
8
Under review as a conference paper at ICLR 2022
Figure 4: Average λ in weighted empirical risk minimization for three different pairs of source and
target tasks for image classification.
for transfer learning. In the pair1 Source and target tasks share the same objects which are Clock and
Ambulance which results in low transfer distance. In pair2, still one of the objects which is Clock is
the same in the source and target and we can see that the transfer distance for pair2 is lower than that
for pair3. Then we plot the lower bounds in Fig 3a and the corresponding upper bounds obtained by
weighted empirical risk minimization in Fig 3b. One can see that sources that are closer to the target
according to our notion of distance are more effective in achieving small target generalization error.
CricketBowling is common both in the source and Target1. This suggests that these tasks are
similar to each other and the estimated transfer distance conforms with this intuition. Furthermore,
CricketBowling and Cricketshot are intuitively similar to one another and this is also reflected in the
lower transfer distance between source and Target2.
In Fig 4 we plot the average λ, the weight appearing in Formula 5.1 when the number of target
samples varies from 150 to 200. 4 demonstrates that when a source is close to the target the weight of
source risk in weighted empirical risk becomes high which shows the effectiveness of source samples
in achieving small target generalization error.
6	Proof outline
The main idea of proof is based on the following proposition proved in Tsybakov (2009)
Proposition 1 [Theorem 2.5 of Tsybakov (2009)] Assume that M ≥ 2 and the function d(∙, ∙) is a
semi-distance. Also suppose that {Pθj }θj ∈Θ is a family of distributions indexed over a parameter
space, Θ, and Θ contains elements θ0, θ1, ..., θM such that:
(i)	d(θi, θj ) ≥ 2s > 0, ∀ 0 ≤ j < k ≤ M
(ii)	Pj	P0, ∀j = 1,...,M,, and
1M
M EDkl(Pj∖Po) ≤ α log M
j=1
with 0 < α < 1/8 and Pj = Pθj, j = 0, 1, ..., M and Dkl denotes the KL-divergence. Then
in^fsuP Pθ(d(θ,θ) ≥ S) ≥ T^Mj (1 — 2α — mɪ)
θ θ∈θ	1 + √M	V log M
Based on Proposition 1 we construct a family of pairs of distributions, namely source and target
distributions, whose transfer distances satisfy the ∆-constraint. To do so we pick some points from
the domain χ shattered by the hypothesis class and define appropriate distributions on this set of
points. Furthermore, this family of distributions are indexed in the space of {—1, 1}d which can be
a metric space using Hamming distance. In order to satisfy the condition (i) in Proposition 1, the
indexes have to be well separated which can be achieved using the well-known Gilbert-Varshamov’s
bound. Finally we show that estimating a parameter with small hamming distance is equivalent to
estimating an appropriate hypothesis with small excess risk error.
9
Under review as a conference paper at ICLR 2022
References
Kamyar Azizzadenesheli, Anqi Liu, Fanny Yang, and Animashree Anandkumar. Regularized learning
for domain adaptation under label shifts. In International Conference on Learning Representations,
2018.
Shai Ben-David, John Blitzer, Koby Crammer, Fernando Pereira, et al. Analysis of representations
for domain adaptation. Advances in neural information processing systems, 19:137, 2007.
Shai Ben-David, John Blitzer, Koby Crammer, Alex Kulesza, Fernando Pereira, and Jennifer Wortman
Vaughan. A theory of learning from different domains. Machine learning, 79(1):151-175, 2010.
John Blitzer, Koby Crammer, Alex Kulesza, Fernando Pereira, and Jennifer Wortman. Learning
bounds for domain adaptation. In NIPS, 2007.
Joao Carreira and Andrew Zisserman. Quo vadis, action recognition? a new model and the kinetics
dataset. In proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp.
6299-6308, 2017.
Xinyang Chen, Sinan Wang, Mingsheng Long, and Jianmin Wang. Transferability vs. discriminability:
Batch spectral penalization for adversarial domain adaptation. In Kamalika Chaudhuri and Ruslan
Salakhutdinov (eds.), Proceedings of the 36th International Conference on Machine Learning,
volume 97 of Proceedings of Machine Learning Research. PMLR, 2019.
Shai Ben David, Tyler Lu, Teresa Luu, and David Pal. Impossibility theorems for domain adaptation.
In Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics,
pp. 129-136. JMLR Workshop and Conference Proceedings, 2010.
Tomer Galanti, Lior Wolf, and Tamir Hazan. A theoretical framework for deep transfer learning.
Information and Inference: A Journal of the IMA, 5(2):159-209, 2016.
Steve Hanneke and Samory Kpotufe. On the value of target data in transfer learning. In NeurIPS,
2019.
Nick Harvey, Christopher Liaw, and Abbas Mehrabian. Nearly-tight vc-dimension bounds for
piecewise linear neural networks. In Conference on learning theory, pp. 1064-1068. PMLR, 2017.
Alireza Karbalayghareh, Xiaoning Qian, and Edward R Dougherty. Optimal bayesian transfer
regression. IEEE Signal Processing Letters, 25(11):1655-1659, 2018.
Alireza Karbalayghareh, Xiaoning Qian, and Edward Russell Dougherty. Optimal bayesian transfer
learning for count data. IEEE/ACM transactions on computational biology and bioinformatics,
2019.
Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classification with deep con-
volutional neural networks. Advances in neural information processing systems, 25:1097-1105,
2012.
Qi Lei, Wei Hu, and Jason Lee. Near-optimal linear regression under distribution shift. In Interna-
tional Conference on Machine Learning, pp. 6164-6174. PMLR, 2021.
Mingsheng Long, Han Zhu, Jianmin Wang, and Michael I Jordan. Unsupervised domain adaptation
with residual transfer networks. Advances in Neural Information Processing Systems, 2016.
Yishay Mansour, Mehryar Mohri, and Afshin Rostamizadeh. Domain adaptation: Learning bounds
and algorithms. In 22nd Conference on Learning Theory, COLT 2009, 2009.
Yishay Mansour, Mehryar Mohri, Jae Ro, Ananda Theertha Suresh, and Ke Wu. A theory of multiple-
source adaptation with limited target labeled data. In International Conference on Artificial
Intelligence and Statistics, pp. 2332-2340. PMLR, 2021.
Seyed Mohammadreza Mousavi Kalan, Zalan Fabian, Salman Avestimehr, and Mahdi Soltanolkotabi.
Minimax lower bounds for transfer learning with linear and one-hidden layer neural networks. In
Advances in Neural Information Processing Systems, 2020.
10
Under review as a conference paper at ICLR 2022
Sinno Jialin Pan and Qiang Yang. A survey on transfer learning. IEEE Transactions on knowledge
and data engineering, 22(10):1345-1359, 2009.
Xingchao Peng, Qinxun Bai, Xide Xia, Zijun Huang, Kate Saenko, and Bo Wang. Moment matching
for multi-source domain adaptation. In Proceedings of the IEEE/CVF International Conference on
Computer Vision, pp. 1406-1415, 2019.
Jian Shen, Yanru Qu, Weinan Zhang, and Yong Yu. Wasserstein distance guided representation
learning for domain adaptation. In Thirty-Second AAAI Conference on Artificial Intelligence, 2018.
Alexandre B Tsybakov. Introduction to Nonparametric Estimation. Springer series in statistics.
Springer, Dordrecht, 2009. doi: 10.1007/b13794.
Karl Weiss, Taghi M Khoshgoftaar, and DingDing Wang. A survey of transfer learning. Journal of
Big data, 3(1):1-40, 2016.
7	Appendix
7.1	Proof of Theorem 1
We also use the following famous result in information theory known as Gilbert-Varhsamov’s bound
for packing argument.
Proposition 2 (Lemma 2.9 of Tsybakov (2009)) Let d ≥ 8. Then there exists a subset
{w(O),…,w(M)} of Ω = { -1,1}d such that W(O) = (1,1,…,1),
dist(wj, w(k)) ≥ —, V 0 ≤ j<k ≤ M and M ≥ 2d/8,
8
where dist(w, w0) = Pdk=1 I(wk 6= wk0 ) is the Hamming distance between binary sequences
w = (w1, ..., wd) and w0 = (w10 , ..., wd0 ).
We will also use the following lemma proved in Hanneke & Kpotufe (2019). We would like to
mention that some ideas of the proof are similar to those in Hanneke & Kpotufe (2019). However, as
discussed in section 2, the problem setting of Hanneke & Kpotufe (2019) is different from that of this
work which results in constructing a different set of distributions.
Lemma 1 Let 0 < < 1/2 and z ∈ {-1, 1}. Then
Dkl ker(1/2 + (z/2) ∙ e), Ber(1/2 — (z/2) ∙ e)) ≤ co ∙ e2 for some co ≤ 4 independent of e
Now we are in place to provide the proof of Theorem 1. Let d = dH - 2 and pick x-1, xO, ..., xd
from χ shattered by H.
Next, we construct a family of pairs of distributions (Pw, Qw) indexed by w ∈ {-1, 1}d where
{-1, 1}d is the parameter space playing the role of Θ in Proposition 1. For the following, fix e =
ci ∙ e(ns, nτ, dχ, ∆) ≤ ɪ for some constant ci to be determined later in proof and e(ns, nτ, dχ, ∆)
is defined in Theorem 1.
Distribution Qw : Qw is composed of a marginal and a conditional distribution, namely Qw =
Qxw × Qyw|x . We define the marginaldistributions as follows:
Qxw(x=	x-i)	=∆
Qxw(x=	xo) =	0.99-∆
Qxw(x=	xi) =	≡dfor i = 1,..,d
For the conditional distributions:		
Qyw|x(y = 1|x	= x-i)	= Qyw|x(y = 1|x = xo) = 1
Qyw|x(y = 1|x	= xi) =	1/2+ (wi)e for i = 1, ..,d
11
Under review as a conference paper at ICLR 2022
Distribution Pw : Pw is composed of a marginal and a conditional distribution, namely Pw
Pxw × Pyw|x . We define the marginal distributions as follows:
Pw(X = XT) = Pw(X = ^ = 1/2(1- d+dS∆)
Pxw(x=xi)
-------------for i = 1,.., d
d+ nS∆
For the conditional distributions:
Pyw|x(y = 1|X = X-1) = 0
Pyw|x(y = 1|X = X0) = 1
Pyw|x(y = 1|X = Xi) = 1/2+ (wi) for i = 1, .., d
Verifying ρ(Pw, Qw) ≤ ∆: Bayes classifier of the domain generated by Pw is as follows:
hS (x-i) = 0
hs (xo) = 1
hS(Xi) = 1 if Wi = 1 , otherwise hS(Xi) = 0 for i = 1,.., d
Similarly for the domain generated by Qw , we have
hT (x-ι) = hT (xo) = 1
hT(Xi) = 1 if Wi = 1 , otherwise hT(Xi) = 0 for i = 1,.., d
So hS and hT disagree only on x-i which implies that
ρ(Pw,Qw) = Q[hS(XT) = IyT] - Q[hT(XT) = yτ] = ∆
Since we want to derive a lower bound for the minimax risk stated in Theorem 1, among the
hypotheses that they agree on Xi for i = 1, ..., d, the hypothesis that outputs X-1 and X0 as 1
results in a smaller target error. Hence, we can restrict ourselves to H which is the projection of
H onto {-1, 1}d with the constraint that h(X-ι) = h(Xo) = 1 for all h ∈ H. Furthermor, for any
W, W0 ∈ {-1, 1}d we have
e /, 、— dist(w, w0)	L 公
ET(hw0) = 100d ∙ 3 ∀ hw0 ∈ H
when the target domain is generated by Qw
Reduction to a packing: By using Proposition 2, we can geta subset Σ of {-1, 1}d whose cardinality
is M ≥ 2d/8 and for any W, W0 belonging to Σ we have dist(W, W0) ≥ d/8. Furthermore, for any
W, W0 ∈ Σ we have
EhW) ≥ d ∙ ≡d = 8⅛
On the other hand, there is a bijective map between {-1, 1}d and elements of H and any classifier
h : {Xi} → {0, 1} with h(X-1) = h(X0) = 1 can be reduced to a W ∈ {-1, 1}d. So we can choose
Σ as the set of indices in Proposition 1 with Hamming distance as the semi-metric and the expression
Pw(dist(W,w) > d/8) translates into Pw(Er(hw) > c ∙ e).
KL divergence bound (part (ii) of Proposition 1): Define Pw = PnwS × QnwT . For any W, W0 ∈ Σ
we have
Dkl(Pw ∣Pwo) = ns ∙ Dkl(Pw |Pw) + nT ∙ Dki(QwIQwo)
=ns ∙ EDkl(PwIxIPwIx) + nT ∙ QEDkl(Qw∣χ∣Qw∣χ)
xx
dd
=ns ∙ X d+n^Dkl(Pw∣Xi∣Pw∣Xi) + nT ∙ X 100dDkl(QwlXiIQwlXi)
i=1 + ns	i=1
d 2	12
≤ ns ∙ K-ʌ c0e + nT ∙	c0e
d+ ns∆	100
≤ C0C2 ∙ d
if ci < 6 then c°c2 < ɪ and We can apply Proposition 1.
12
Under review as a conference paper at ICLR 2022
7.2 Proof of Theorem 2
Proof of Theorem 2 is similar to that of Theorem 1. However, we construct different target and source
probability distributions.
Let d = dH - N - 1 and pick x-M, ..., x0, x1, ..., xd from χ shattered by H. Then we
construct a family of distributions (P(w1) , ..., P(wN) , Qw) indexed by w ∈ {-1, 1}d. Let =
ci ∙ e(nsι ,…，nsN ,nτ, dχ, ∆ι,…，Δn) for some constant ci < 1 to be determined later in proof.
Furthermore, without loss of generality assume that 1 ≥ ∆1 ≥ ∆2 ≥ ... ≥ ∆N ≥ 0.
Distribution Qw : Qw is composed of a marginal and a conditional distribution, namely Qw =
Qxw × Qyw|x . We define the marginal distributions as follows:
Qxw(x = x-i) = ∆i - ∆i+i for i = 1, ..., N - 1 and Qxw(x = x-N) = ∆N
Qxw (x = x0) = 0.99 - ∆i
Qw(X = Xi) = i00d for i = 1,..,d
For the conditional distributions:
Qyw|x (y = 1|X = X-i) = 1 for i = 1, ..., N
Qyw|x(y = 1|X = X0) = 1
Qyw|x(y = 1|X = Xi) = 1/2 + (wi)e for i = 1, ..., d
Distribution P(wi) : P(wi) is composed of a marginal and a conditional distribution, namely P(wi)
Pxw(i) × Pyw|x(i). We define the marginal distributions as follows:
Pw (i)(X=x-j )=N1+ι 0- d+ndsi ∆i)for j=1,…,N
Pw (i)(x = χ0) = n+i (1-二)
Pw("(χ = xj) = ~r~ K for j = 1,..,d
d+ nSi ∆i
For the conditional distributions:
Pyw|x(y = 1|X = X-j) =0 if j ≥ i, otherwise Pyw|x(y = 1|X = X-j) = 1 for j = 1, ..., N
Pyw|x (y = 1|X = X0 ) = 1
Pyw|x(y = 1|X = Xj) = 1/2 + (wj)e for j = 1, .., d
Verifyingρ(P(wi),Qw) ≤ ∆i:
Bayes classifier of the domain generated by P(wi) is as follows:
hSi(x-j) = 0 if j ≥ i, otherwise hS(x-j) = 1 for j = 1,..., N
hSi (XO) = 1
h^Si (xj) = 1 if Wj = 1, otherwise hS (xj) = 0 for j = 1,.., d
Similarly for the domain generated by Qw , we have
hT(x-j) = 1 for j = 1,..., N
hT (xo) = 1
hT(Xj) = 1 if Wj = 1 , otherwise hT(Xj) = 0 for j = 1,.., d
So hS and hT disagree on x-i,.., X-N which implies that
ρ(Pw), Qw) = Q[hSi(XT) = yτ] - Q[hT(XT) = yτ] = ∆
13
Under review as a conference paper at ICLR 2022
With the same argument we used in the proof of Theorem 1 we can restrict ourselves to H which is
the projection of H with the constraint that h(x-N) = ... = h(x-1) = h(x0) = 1 for all h ∈ H.
The rest of the proof is exactly the same except the part regarding the KL divergence bound.
KL divergence bound: Define Pw = P(w1)nS1 × ... × P(wN) nSN × QnwT .
N
Dkl(Pw|Pw0) = X nSj ∙ Dki(Pj) ∣Pj0)) + nτ ∙ Dki(Qw|Qw，)
j=1
N	0 (j )	0
∑nSj ∙ pE) Dkl (Pwx	X )+ nτ ∙ QE Dkl (Qw|x IQwx)
N	d	1	(j )	d 1
=X nSj ∙ X d+nS^, Dkl (Pwxij) IPwxij )+ nτ ∙ X 100d Dkl (QwIxiIQwxi)
j=1	i=1	j j	i=1
N
d 2	12
≤ ∑nSj ∙ d + nsj ∆ c0e + nT ^ 100 c06
≤ Coc2 ∙ d
for small enough c1 we can apply Proposition 1.
7.3 Additional Experimental Results
In section 5 we fix number of source samples and vary the number of target samples. Here in order to
investigate the effect of source samples on the target generalization error, we fix the number of target
samples at nT = 3 and vary the number of source samples. Fig 5 depicts the theoretical lower bounds
along with the upper bounds obtained by empirical risk minimization for image classifications. We
use the same source/target pairs as used in section 5.2. Fig 5 demonstrates that Source1 is more
helpful in reducing the target generalization error because it has a low distance from the target.
Furthermore, it shows that increasing the number of source samples is useful up to a point and beyond
that point the error saturates and does not decrease further as discussed in Remark 10.
JoaUOlyEZ=E∙IOUO0⅛bjo,Tel
Figure 5: Depicts the lower bounds along with the upper bounds obtained via weighted empirical risk
minimization. In this setting the number of target samples is fixed at nT = 3
14