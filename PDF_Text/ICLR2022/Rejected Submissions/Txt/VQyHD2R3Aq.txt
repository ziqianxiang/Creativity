Under review as a conference paper at ICLR 2022
SPIDE: A Purely Spike-based Method for
Training Feedback Spiking Neural Networks
Anonymous authors
Paper under double-blind review
Ab stract
Spiking neural networks (SNNs) with event-based computation are promising
brain-inspired models for energy-efficient applications on neuromorphic hard-
ware. However, most high-performance supervised SNN training methods in ma-
chine learning research, such as conversion from artificial neural networks or di-
rect training with surrogate gradients, require complex computation not supported
by spiking neurons, which hinders them from spike-based energy-efficient train-
ing. Among them, the recently proposed method, implicit differentiation on the
equilibrium state (IDE), for training feedback SNNs is a promising way possi-
ble for generalization to spike-based learning with flexible network structures. In
this paper, we study spike-based implicit differentiation on the equilibrium state
(SPIDE) that extends IDE for supervised local learning with spikes, which could
be possible for energy-efficient training on neuromorphic hardware. Specifically,
we first introduce ternary spiking neuron couples to realize ternary outputs with
the common neuron model, and prove that implicit differentiation can be solved by
spikes based on this design. With this approach, the whole training procedure can
be made as event-driven spike computation and weights are updated locally with
two-stage average firing rates. Then to reduce the approximation error of spikes
due to the finite simulation time steps, we propose to modify the resting membrane
potential. Based on it, the average firing rate, when viewed as a stochastic estima-
tor, achieves an unbiased estimation of iterative solution for implicit differentia-
tion and the variance of this estimator is reduced. With these key components, we
can train SNNs with either feedback or feedforward structures in a small number
of time steps. Further, the firing sparsity during training demonstrates the great po-
tential for energy efficiency. Meanwhile, even with these constraints, our trained
models can still achieve competitive results on MNIST, CIFAR-10, CIFAR-100,
and CIFAR10-DVS. Our proposed method demonstrates the great potential for
energy-efficient training of SNNs on neuromorphic hardware.
1	Introduction
Spiking neural networks (SNNs) are brain-inspired models that transmit spikes between neurons for
event-driven energy-efficient computation. SNNs can be implemented with less energy on neuro-
morphic hardware (Akopyan et al., 2015; Davies et al., 2018; Pei et al., 2019; Roy et al., 2019),
which can remedy the defects of large energy consumption of artificial neural networks (ANNs).
Different from ANNs, however, directly supervised training of SNNs is a hard problem due to the
complex spiking neuron model which is discontinuous. To solve this problem, converting ANNs to
SNNs (Hunsberger & Eliasmith, 2015; Rueckauer et al., 2017; Sengupta et al., 2019; Rathi et al.,
2019; Deng & Gu, 2021; Yan et al., 2021), or many other direct SNN training methods (Wu et al.,
2018; Bellec et al., 2018; Jin et al., 2018; Shrestha & Orchard, 2018; Wu et al., 2019; Neftci et al.,
2019; Zhang & Li, 2019; Kim et al., 2020; Zheng et al., 2021; Bohte et al., 2002; Zhang & Li, 2020;
Kim et al., 2020; Xiao et al., 2021) have been proposed. While these methods could partly tackle
the problems of unsatisfactory performance or high latency, they require complex computation for
gradient calculation or approximation, which cannot be implemented by common spiking neurons
on neuromorphic hardware. They aim at training SNNs on commonly used computational units, e.g.
GPU, and deploying trained models for energy-efficient inference. However they do not consider
if the training procedure could leverage the same spike-based computation for gradient calculation
and training to reduce the large energy consumption during training as well.
1
Under review as a conference paper at ICLR 2022
Table 1: Comparison of different supervised SNN training methods with respect to performance,
latency, structure flexibility, neuron model, spike-based or not, and neuromorphic plausibility.
Method	High Perform.	Low Latency	Struc. Flexi.	Common Neuron Model	Spike-based	Neuro. Plaus.
ANN-SNN	X	×	×	X	×	Low
BPTT with Surrogate Gradients	X	X	X	X	×	Low
DFA with Spikes	×	?	×	X	X	High
SpikeGrad (Thiele et al., 2019a)	X	?	×	×	X	Medium
IDE (Xiao et al., 2021)	X	X	X	X	×	Low
SPIDE (ours)	X	X	X	X	X	High
A few previous works try to train SNNs with spikes (Guerguiev et al., 2017; Neftci et al., 2017;
Samadi et al., 2017; O’Connor & Welling, 2016; Thiele et al., 2019b;a). They either are based
on direct feedback alignment (DFA) (N0kland, 2016) and performs poorly, or require impractical
special neuron models (Thiele et al., 2019b;a). Besides, they only focus on feedforward network
structures imitated from ANNs, which ignores feedback connections that are ubiquitous in the hu-
man brain and enable neural networks tobe shallower and more efficient (Kubilius et al., 2019; Xiao
et al., 2021). Actually, feedback structures suit SNNs more since SNNs will naturally compute with
multiple time steps, which could reuse representations and avoid uneconomical costs to unfold along
time that ANNs suffer from (Xiao et al., 2021). So training algorithms for feedback SNNs, which
may also degrade to feedforward structures by taking feedback as zero, is worth more exploration.
An ideal SNN training method should tackle the common problems, be suitable for flexible struc-
tures (feedforward or feedback) and be spike-based with high neuromorphic plausibility. The im-
plicit differentiation on the equilibrium state (IDE) method (Xiao et al., 2021), which is recently
proposed to train feedback spiking neural networks (FSNNs), is a promising method that may gen-
eralize to spike-based learning for requirement. They derive that the forward computation of FSNNs
converges to an equilibrium state, which follows a fixed-point equation. Based on it, they propose
to train FSNNs by implicit differentiation on this equation, which tackles the common difficulties
for SNN training including non-differentiability and large memory costs, and has interesting local
update properties. In their method, however, they leverage general root-finding methods to solve
implicit differentiation, which requires complex computation on standard computation systems.
In this work, we extend the IDE method to spike-based IDE (SPIDE), which fulfills our require-
ments and has great potential for energy-efficient training of SNNs on neuromorphic hardware, by
introducing ternary spiking neuron couples and proposing to solve implicit differentiation by spikes
based on them. Our method is also applicable to feedforward structures by degrading the feedback
connection as zero. In practice, however, it may require long time steps to stabilize the training
with spikes due to approximation error for gradients. So we further dive into the approximation
error from the statistical perspective, and propose to simply adjust the resting potential of SNNs to
achieve an unbiased estimation of gradients and reduce the estimation variance of SNN computa-
tion. With these methods, we can train our models in a small number of time steps, which could
further improve the energy efficiency as well as the latency. Our contributions include:
1.	We propose the SPIDE method that is the first to train high-performance SNNs by spikes
with common neuron models. Specifically, we propose ternary spiking neuron couples and
prove that implicit differentiation for gradient calculation can be solved by spikes based on
this design. Our method is applicable to both feedback and feedforward structures.
2.	We theoretically analyze the approximation error of solving implicit differentiation by
spikes, and propose to modify the resting potential to remove the approximation bias and
reduce the estimation variance, which enables training in a small number of time steps.
3.	Experiments show the low latency and firing sparsity during training, which demonstrates
the great potential for energy-efficient training of SNNs on neuromorphic hardware. The
performance on MNIST, CIFAR-10, CIFAR-100 and CIFAR10-DVS are also competitive.
2	Related Work
Early works seek biologically inspired methods to train SNNs, e.g. spike-time dependent plastic-
ity (STDP) (Diehl & Cook, 2015) or reward-modulated STDP (Legenstein et al., 2008). Since the
rise of successful ANNs, several works try to convert trained ANNs to SNNs to obtain high perfor-
mance (Hunsberger & Eliasmith, 2015; Rueckauer et al., 2017; Sengupta et al., 2019; Rathi et al.,
2019; Deng & Gu, 2021; Yan et al., 2021). However, they suffer from extremely large time steps
2
Under review as a conference paper at ICLR 2022
and their structures are limited in the scope of ANNs. Others try to directly train SNNs by imitating
backpropagation throught time (BPTT) and use surrogate derivative for discontinuous spiking func-
tions (Lee et al., 2016; Wu et al., 2018; Bellec et al., 2018; Jin et al., 2018; Shrestha & Orchard, 2018;
Wu et al., 2019; Zhang & Li, 2019; Neftci et al., 2019; Zheng et al., 2021) or compute gradient with
respect to spiking times (Bohte et al., 2002; Zhang & Li, 2020; Kim et al., 2020). However, they suf-
fer from approximation error and large memory costs. Xiao et al. (2021) propose the IDE method to
train feedback spiking neural networks, which decouples the forward and backward procedures and
avoids the common SNN training problems. However, all these methods require complex compu-
tation during training rather than spike-based. A few works focusing on training SNNs with spikes
either are based on feedback alignment and limited in simple datasets (Guerguiev et al., 2017; Neftci
et al., 2017; Samadi et al., 2017; O’Connor & Welling, 2016), or require impractical special neuron
models that require consideration of accumulated spikes for spike generation (Thiele et al., 2019b;a),
which is impractical on neuromorphic hardware. And they are only applicable to feedforward archi-
tectures. Instead, we are the first to leverage spikes with common neuron models to train SNNs with
feedback or feedforward structures. The comparison of different methods is illustrated in Table 1.
3	Preliminaries
We first introduce preliminaries about spiking neurons and the IDE training method. The basic
thought of IDE (Xiao et al., 2021) is to identify the underlying equilibrium states of FSNN compu-
tation so that gradients can be calculated based on implicit differentiation on the equilibrium state.
We will briefly introduce the conclusion of equilibrium states in Section 3.2 and the IDE method in
Section 3.3. For more descriptions about the background please refer to Appendix A.
3.1	Spiking Neural Network Models
Spiking neurons draw inspirations from the human brain to communicate with each other by spikes.
Each neuron integrates information from input spike trains by maintaining a membrane potential
through a differential equation, and generates an output spike once the membrane potential exceeds
a threshold, following which the membrane potential is reset to the resting potential. We consider
the commonly used integrate and fire (IF) model and simple current model, whose discretized com-
putational form is:
ui [t + 0.5] = ui[t] +	wij sj [t] + b,
j
si [t + 1] = H(ui [t + 0.5] - Vth),
ui[t + 1] = ui [t + 0.5] - (Vth - urest)si [t + 1],
(1)
where ui [t] is the membrane potential of neuron i at time step t, si [t] is the binary output spike train
of neuron i, wij is the connection weight from neuron j to neuron i, b is bias, H is the Heaviside step
function, Vth is the firing threshold, and urest is the resting potential. We use subtraction as the reset
operation. urest is usually taken as 0 in previous work, while we will reconsider it in Section 4.3.
3.2	Equilibrium States of Feedback Spiking Neural Networks
Xiao et al. (2021) derive that the (weighted) average rate of spikes during FSNN computation with
common neuron models would converge to an equilibrium state following a fixed-point equation
given convergent inputs. We focus on the conclusions with the discrete IF model under both single-
layer and multi-layer feedback structures. The single-layer structure has one hidden layer of neurons
with feedback connections on this layer. The update equation of membrane potentials is:
u[t + 1] = u[t] + Ws[t] + Fx[t] + b - (Vth - urest)s[t + 1],	(2)
where u[t] and s[t] are the vectors of membrane potentials and spikes of these neurons, x[t] is the
input at time step t, W is the feedback weight matrix, and F is the weight matrix from inputs to
these neurons. The average input and average firing rate are defined as x[t] = 士 PT=0 x[τ] and
α[t] = 1 PT=ι s[τ], respectively. Define σ(x) = min(1, max(0, x)).
The equilibrium state of the single-layer FSNN is described as (Xiao et al., 2021): If the average
inputs converge to an equilibrium point x[t] → x *, and there exists γ < 1 such that k W k 2 ≤ YVth,
then the average firing rates of FSNN with discrete IF model will converge to an equilibrium point
a[t] → α*, which satisfies the fixed-point equation a* = σ (V^ (Wa* + Fx* + b)). Note that
they take urest = 0 in this conclusion, if we consider nonzero urest, the constraint and the fixed-
point equation should be ∣∣W∣∣2 ≤ Y(Vth - Urest) and α* = σ (V^-U~~- (Wα* + Fx* + b)).
3
Under review as a conference paper at ICLR 2022
The multi-layer structure incorporates more non-linearity into the equilibrium fixed-point equation,
which has multiple layers with feedback connections from the last layer to the first layer. The update
equations of membrane potentials are expressed as:
u1[t+ 1] = u1[t] + W1sN [t] +F1x[t] +b1 - (Vth - urest)s1[t+ 1],	(3)
ɪul [t + 1] =	ul[t]	+ Flsl	1[t	+ 1] +	bl	— (Vth	— Urest)sl[t	+ 1], l =	2,…，N.
The equilibrium state of the multi-layer FSNN with urest is described as (Xiao et al., 2021): If
the average inputs converge to an equilibrium point x[t] → x*, and there exists γ < 1 such that
IlWIII2∣∣Fn∣∣2 …∣∣F2∣∣2 ≤ Y(Vth — Urest)N, then the average firing rates of multi-layer FSNN
with discrete IF model will converge to equilibrium points al [t] → αl , which satisfy the fixed-
point equations α1* = f f ◦…O f2(α1*), x*) and ɑl+1* =力+ι(αl*), where fι(α, x)=
σ ( Vth-Urest (WIa + FIX + b1)) and fl(α)= ° ( Vth-Urest (Fla +
3.3	IDE Training Method
Based on the equilibrium states in Section 3.2, we can train FSNNs by calculating gradients with
implicit differentiation (Xiao et al., 2021). Let a = fθ(a) denote the fixed-point equation of the
equilibrium state which is parameterized by θ, gθ(a) = fθ(a) 一 a, and let L(a*) denote the
objective function with respect to the equilibrium state a*. The implicit differentiation satisfies
(I - df∂0α" dOr = df∂α*) (Bai et al., 2019) (we follow the numerator layout convention for
derivatives). Therefore, the differentiation of L(a*) for parameters can be calculated as:
∂L(a*) -	∂L(a*)(]∣	] ∂fθ(a*)
∂θ =	∂a* 〈 gθ lα*1	∂θ
(4)
where J-1«* is the inverse Jacobian of gθ evaluated at a*. The calculation of inverse Jacobian can
be avoided by solving an alternative linear system (Bai et al., 2019; 2020; Xiao et al., 2021):
♦la* ) β + (察 l S	(5)
Note that a readout layer after the last layer of neurons will be constructed for output (Xiao et al.,
2021), which is equivalent to a linear transformation on the approximate equilibrium state, i.e. the
output would be o = Woa*, and the loss will be calculated between o and labels y with a common
criterion such as cross-entropy. Then the gradient on the equilibrium state could be calculated. For
the solution of implicit differentiation, Xiao et al. (2021) follow Bai et al. (2019; 2020) to leverage
root-finding methods, while we will solve it by spike dynamics, as will be derived in Section 4.
We treat the forward computation of average firing rates a[T] of FSNNs at time step T roughly
reach the equilibrium state. Then by substituting a* by a[T] in the above equations, gradients for
the parameters can be calculated only with a[T] and the equation, and we calculate them based on
spikes. With the gradients, first-order optimization methods such as SGD (Rumelhart et al., 1986)
and its variants can be applied to update parameters.
4	Spike-based Implicit Differentiation on the Equilibrium State
In this section, we present our SPIDE method that calculates the whole training procedure based on
spikes. We first introduce ternary spiking neuron couples in Section 4.1 and how to solve implicit
differentiation in Section 4.2. Then we theoretically analyze the approximation error and propose the
improvement in Section 4.3. Finally, a summary of the training pipeline is presented in Section 4.4.
4.1	Ternary Spiking Neuron Couples
The common spiking neuron model only generates spikes when the membrane potential exceeds a
positive threshold, which limits the firing rate from representing negative information. To enable
approximation of possible negative values for implicit differentiation calculation in Section 4.2, we
require negative spikes, whose expression could be: ɪ ,长 十 ° 5]〉V
si[t +1] = T (ui[t + 0.5], Vth) = I O,	∣Ui[t + 0.5] l ≤ Vth ,	(6)
l - 1, Ui [t + 0.5] < -Vth
and the reset is the same as usual: Ui[t +1] = Ui[t +0.5] — (Vth —Urest)si[t +1]. Direct realization of
such ternary output, however, may be not supported by common neuromorphic hardware for SNNs.
4
Under review as a conference paper at ICLR 2022
We propose to leverage two coupled common neurons to realize
this computation. As illustrated in Figure 1, the two coupled neu-
rons with the common IF model (Eq. (1)) receive opposite inputs
and output opposite spikes, which aim to deal with positive infor-
mation and negative information with spikes, respectively. They
should share a reset operation in order to accord with Eq. (6),
which can be realized by the connection between them: as we use
subtraction as the reset operation, the connection whose weight
equals Vth - urest enables one neuron to reset another equiva-
lently. To see how this works, consider the condition that the
accumulated membrane potential of neuron 1 reaches Vth , then
neuron 1 would generate a spike and reset, and the output is this
positive spike. At the same time, the membrane potential of neu-
ron 2 is -Vth and the neuron will not fire and reset, but the spike
from neuron 1 will reset it to -urest, which accords with our de-
sired reset for ternary output. Similarly, if the inputs are negative,
neuron 2 will generate a spike which will be treated negative as output, and both neurons are reset.
For the operation of taking negative, one solution is to enable the reverse operation on hardware, an-
other is to reconnect neuron 2 with other neurons while taking the weight negative to that of neuron
1. Therefore, such kind of coupled neurons with the common IF model could realize ternary output.
We note that the SpikeGrad algorithm (Thiele et al., 2019a) also requires neurons for ternary output.
However, they do not consider how such kind of operation can be implemented with the common
neuron model on neuromorphic hardware, and moreover, they propose another modified ternary
model in practice that requires consideration of accumulated spikes for spike generation, which is
further impractical on neuromorphic hardware. Differently, our method can be realized with the
common neuron model suitable for neuromorphic hardware.
Input x
Si + (-S2)
output
Figure 1: Illustration of ternary
spiking neuron couples.
4.2	S olving Implicit Differentiation with Spikes
Based on the coupled neurons in Section 4.1, we can solve implicit differentiation with spikes. For
notation simplicity, we directly use Eq. (6) as a ternary neuron without detailing coupled neurons
below. Our main focus is on solving Eq. (5) with spikes. The brief outline for the derivation is:
we first derive the update equation of membrane potentials in SNN computation, then we derive the
equivalent equation of the rate of spikes with eliminating perturbation, finally, we could prove that
the rate of spikes converges to the solution of Eq. (5).
We first consider the single-layer condition. Let α[TF] denote the average firing rate of these neu-
rons after the forward computation with time steps TF as an approximate equilibrium state (we treat
the forward procedure as the first stage), g = ^∂c∂[Tf ]) denote the gradient of the loss function
on this approximate equilibrium state, and m = σ0(α[TF]), M = Diag(m) denote a mask indicator
based on the firing condition in the first stage, where σ0 (x) =	, < x < . We will have another
0, else
TB time steps in the second backward stage to calculate implicit differentiation. We set the input to
these neurons as g at all time steps, which can be viewed as input currents (Zhang & Li, 2020; Xiao
et al., 2021). Then along the inverse connections of neurons and with a mask on neurons or weights
and an output rescale, the computation of FSNN with ternary neurons is calculated as:
u[t + 1] = u[t] + 亍一-----(MW)>s[t] + g - (Vth - Ubest)s[t + 1],
Vth - urest
(7)
where Vth , urest and Vtbh , ubrest are the threshold and resting potential during the first and second
stage, respectively. Define the ‘average firing rate, at this second stage as β[t] = 1 PT=1 s[τ], and
u[0] = 0, s[0] = 0, then through summation, we have:
β[t + 1] = Vb 1 b	(7TT J-(MW)>β[t] + g - u⅛U) .	(8)
Vth - urest t + 1 Vth - urest	t + 1
Since there could be at most t spikes during t time steps, β would be bounded in the
range of [-1, 1]. The membrane potential ui [t] will maintain the exceeded terms, i.e. de-
fine vi[t] = (t:、V,-U,-St (MW)>β[t] + g) , We can divide ujt] as UE[t] + uB[t], where
5
Under review as a conference paper at ICLR 2022
uiE [t] = max vi [t] - Vtbh , 0 + min vi [t] + Vtbh , 0 is the exceeded term while uiB [t] is a bounded
term (Xiao et al., 2021) which is typically bounded in the range of [-Vtbh, Vtbh]. Then, Eq. (8) turns
β[t +1]= φ (Vb 1 b	(ɪ J—(MW)>β[t] + g - uB[t+1])) ,	(9)
Vth - urest t + 1 Vth - urest	t + 1
where φ(x) = min(1, max(-1, x)). Note that if the input g and weight (MW)> are in an appro-
priate range, there would be no exceeded term and therefore φ will not take effect. Indeed we will
rescale the loss to control g in an appropriate range, as will be indicated in Section 4.3. With this
consideration, we could derive that the average firing rate β [t] converges to the solution of Eq. (5).
Theorem 1. If there exists γ < 1 such that k(MW)> k2 ≤ γ(Vth - urest)(Vtbh - ubrest), then the
average firing rate β[t] will converge to an equilibrium point β[t] → β*. When Vh — Urest = 1,
and there exists λ < 1 such that ∣∣(MW)>k∞ ≤ λ(Vth - Urest) and ∣∣gk∞ ≤ 1 — λ, then β* is the
solution of Eq. (5).
The proof and discussion of assumptions are in Appendix B. With Theorem 1, we can solve Eq. (5)
by simulating this second stage of SNN computation to obtain the ‘firing rate’ β[TB] as the ap-
proximate solution. Plugging this solution to Eq. (4), the gradients can be calculated by: RW L =
Vh-^ Mβ[TB ]α[TF ]>, VFL = Vth-Urest MePB ]x[TF ]>, VbL = Vh-^ Mβ[TB ].
Note that in practice, even if the data distribution is not properly in the range of φ, we can still view
φ as a kind of clipping for improperly large numbers, which could be similar to empirical techniques
like “gradient clipping” to stabilize the training.
Then We consider the extension to the multi-layer condition. Let al [TF ],l = 1,2,∙∙∙ ,N denote
the average firing rate of neurons in layer l after the forward computation, g = (∂θN‰y) denote
the gradient of the loss function on the approximate equilibrium state of the last layer, and ml =
σ0(αl[TF]), Ml = Diag(ml) denote the mask indicators. Similarly, we will have another TB time
steps in the second stage to calculate implicit differentiation. We set the input to the last layer as
g at all time steps. Then along the inverse connections of neurons and with a mask on neurons or
weights and an output rescale, the computation of FSNN with ternary neurons is calculated as:
fuN[t + 1] = UN[t] + J-(M1W1)>s1[t]+ g -(Vtbh -Urest)SN[t +1],
Vth - Urest
∣ul[t	+ 1] =	ul[t]	+	V^—(Ml+1Fl+1)>sl+1[t + 1] -(Vh	-Urest)sl[t	+	1],	l = N -	1,…J
Vth - Urest
(10)
The ‘average firing rates’ βl [t] are similarly defined for each layer, and the equivalent form can be
similarly derived as:
eN[t + 1] = φ (Vb 1 b	(£ 一一(M1w1)>β1[t]+g - uN [t + 1])),
Vth - Urest	t + 1 Vth - Urest	t + 1
βl [t +1] = φ( Vb 1 b	(V^—(Ml+1Fl+1)>βl+1[t +1] - Ult) +1])].
Vth - Urest	Vth - Urest	t + 1
(11)
The convergence of the ‘firing rate’ at the last layer to the solution of Eq. (5) can be similarly
derived as Theorem 1. However, we need to calculate gradients for each parameter as Eq. (4), which
is more complex than the single layer condition. Actually, we can derive that the ‘firing rates’ at
each layer converge to equilibrium points, based on which the gradients can be easily calculated
with information from the adjacent layers. Theorem 2 gives a formal description.
Theorem 2. Ifthere exists Y < 1 Suchthatk(M1W1)>∣2∣(MNFN)>∣2 …k(M2F2)>∣2 ≤
γ(Vth - Urest)N (Vtbh - Ubrest)N, then the average firing rates βl [t] will converge to equilibrium
points βl [t] → βl*. When Vh - Ubest = 1,and there exists λ < 1 such that ∣(M1W1 )> ∣∞ ≤
λ(Vth - Urest),k(MlFl)>∣∣∞ ≤ λ(Vth - Urest),l = 2,…，N and kgk∞ ≤ 1 - λN, then βN*
is the solution of Eq. (5), and βl * =(黑：[；加 *))) βN * ,l = N — 1,…，1, where hl(αN ")=
力◦•••◦ f2 (fι(αN *, x*)) ,l = N,…，1.
6
Under review as a conference paper at ICLR 2022
The functions fl are defined in Section 3.2. For the proof please refer to Appendix C. With Theo-
rem 2, by plugging the solutions explicitly into Eq. (4), the gradients can be calculated by Vfi L =
Vth-IurestMlβl[TB]αl-1[TF]>,ι = 2,…，n, VfiL = Vth-Iures;M1β1PB]x[Tf]>, RWL =
Vth-Uest Ml βl[TB ]αN[TF ]>, Vbl L = Vth-Iures; Ml βlP⅛〕.
Note that the gradient calculation shares an interesting local property, i.e. it is proportional to the
firing rates of the two neurons connected by it: VFl L = -τr^1-miβiαj-1. During calculation,
i,j	Vth -urest i i j
since we will have the firing rate of the first stage before the second stage, this calculation can also
be carried out by event-based calculation triggered by the spikes in the second stage. So it would be
plausible on neuromorphic hardware as well.
Also, note that the theorems still hold if we degrade our feedback models to feedforward ones by
setting feedback connections as zero. In this setting, the dynamics and equilibriums degrade to direct
functional mappings, and the implicit differentiation degrades to the explicit gradient. We can still
approximate gradients with this computation.
In the following, we take Vtbh-ubrest = 1 by default to fulfill the assumption of theorems (it may take
other values ifwe correspondingly rescale the outputs and we set 1 for simplicity). Other techniques
like dropout can also be integrated into the calculation. Please refer to Appendix D for details.
4.3	Reducing Approximation Error
Section 4.2 derives that we can solve implicit differentiation with spikes, as the average firing rate
will gradually converge to the solution. In practice, however, we will simulate SNNs for finite
time steps, and a smaller number of time steps is better for lower energy consumption. This will
introduce approximation error which may hamper training. In this subsection, we theoretically
study the approximation error and propose to adjust the resting potential to reduce it. Inspired by
the theoretical analysis on quantized gradients (Chen et al., 2020), we will analyze the error from
the statistical perspective.
For the ‘average firing rates’ βl [t] in Eq. (8) and the multilayer counterparts, the approximation error
e to the equilibrium states consists of three independent parts ee, er and ei : the first is ulE [t + 1]
that is the exceeded term due to the limitation of spike number, the second is ulB [t + 1] which
can be viewed as a bounded random variable, and the third is the convergence error of the iterative
update scheme without ul[t + 1], i.e. let bl[t] denote the iterative sequences for solving βl as
bl[t+1] = t++ι V JU-- (Ml+1Fl+1)>bl [t], the convergence error is ∣∣bl[t]-βl*∣∣. Thesecondpart
er can be again decomposed into two independent components er = eq + es: eq is the quantization
effect due to the precision of firing rates (T1 for T time steps) if we first assume the same average
inputs at all time steps, and es is due to the random arrival of spikes rather than the average condition,
as there might be unexpected output spikes, e.g. the average input is 0 and the expected output
should be 0, but two large positive inputs followed by one larger negative input at the last time
would generate two positive spikes while only one negative spike. So the error is divided into:
e = ee + eq + es + ei. Since the iterative formulation is certain for ei, we focus on ee, eq and es.
Firstly, the error eq due to the quantization effect is influenced by the input scale and time steps TB .
To enable proper input scale and smaller time steps, we will rescale the loss function by a factor
sl, since the magnitude of gradients considering the direct cross-entropy loss function is relatively
small. We scale the loss to an appropriate range so that information can be propagated by SNNs
in smaller time steps, and most signals are in the range of φ as analyzed in Section 4.2. The base
learning rate will be scaled by ɪ correspondingly. This is also adopted by Thiele et al. (2019a).
sl
Then given the scale and number of time steps, eq, ee and es can be treated as random variables
from statistical perspective, and we view βl [t] as stochastic estimators for the equilibrium states
with ei. For the stochastic optimization algorithms, the expectation and variance of the gradients are
important for convergence and convergence rate (Bottou, 2010), i.e. we hope an unbiased estimation
of gradients and smaller estimation variance. As for ee and es, they depends on the input data and
the expectations are E[ee] = 0, E[es] = 0 (the positive and negative parts have the same probability).
While for eq , it will depend on our hyperparameters Vtbh and ubrest. Since the remaining terms in
ulB [t + 1] caused by the quantization effect is in the range of [ubrest, Vtbh] for positive terms while
[-Vtbh, -ubrest] for negative ones, given Vtbh - ubrest and considering the uniform distribution, only
7
Under review as a conference paper at ICLR 2022
when ubrest = -Vtbh, the expectation E[eq] = 0 for both positive and negative terms. Therefore, we
should adjust the resting potential from commonly used 0 (Wu et al., 2018; Sengupta et al., 2019;
Xiao et al., 2021) to -Vtbh for unbiased estimation, as described in Proposition 1.
Proposition 1. For fixed Vtbh - ubrest and uniformly distributed inputs and eq, only when urbest =
-Vtbh, βl [t] are unbiased estimators for bl [t].
Also, taking ubrest = -Vtbh achieves the smallest estimation variance for the quantization effect eq,
considering the uniform distribution on [ubrest , Vtbh] ∪ [-Vtbh , -ubrest]. Since the effects of ee, es and
ei are independent of eq and their variance is certain given inputs, it leads to Proposition 2.
Proposition 2. Taking ubrest = -Vtbh reduces the variance of estimators βl [t].
With this analysis, we will take Vtbh = 0.5, ubrest = -0.5 in the following to stabilize the training.
For Vth and urest during the first forward stage, we will also take urest = -Vth.
4.4	Details and Training Pipeline
The original IDE method (Xiao et al., 2021) leverages other training techniques including modi-
fied batch normalization (BN) and restriction on weight spectral norm. Since the batch statistical
information might be hard to obtain for calculation on neuromorphic hardware and we seek for algo-
rithms that could be possible on it, we drop the BN component in our SPIDE method. The restriction
on the weight norm, however, is necessary for the convergence of feedback models, as indicated in
theorems. We will adjust it for a more friendly calculation, please refer to Appendix D for details.
We summarize our training pipeline as follows (we also provide detailed pseudocodes in Ap-
pendix E). There are two stages for forward and backward procedures respectively. In the first stage,
SNNs will receive inputs and perform the calculation as Eq. (1,2,3) for TF time steps, after which
we get the output from the readout layer, and save the average inputs as well as the average firing
rates and masks of each layer for the second stage. In the second stage, the last layer of SNNs will
receive gradients for outputs and perform calculation along the inverse connections as Eq. (6,7,10)
for TB time steps, after which we get the ‘average firing rates’ of each layer. Based on the firing
rates from two stages, the gradients for parameters can be calculated as in Section 4.2 and then the
first-order optimization algorithm is applied to update the parameters.
5	Experiments
In this section, we conduct experiments to demonstrate the effectiveness of our method and the great
potential for energy-efficient training. We simulate the computation on common computational
units. Please refer to Appendix D for implementation details and descriptions.
We first evaluate the effectiveness of our method in a small number of time steps. As shown in
Table 2, we can train high-performance models with low latency (TF = 30) in a very small number
time steps during training (e.g. TB = 50), which indicates the low latency and high energy effi-
ciency. Note that the ANN-SNN methods usually require hundreds to thousands of time steps just
for satisfactory inference performance, and direct training methods show that relatively small time
steps are enough for inference, while we are the first to demonstrate that even training of SNNs can
be carried out with spikes in a very small number of time steps. This is due to our analysis and
improvement to reduce the approximation error, as illustrated in the ablation study in Appendix F.1.
Then we analyze the firing rate statistics to demonstrate the potential of energy efficiency. Since
the energy consumption on event-driven neuromorphic hardware is proportional to the number of
spikes, we present the average firing rates for forward and backward stages (for backward, both
positive and negative spikes are considered as firing) in Figure 2. It shows the firing sparsity of our
method, and spikes are sparser in the backward stage with around only 3%. Combined with the
small number of time steps, this demonstrates the great potential for the energy-efficient training of
SNNs based on our method on neuromorphic hardware.
Finally we evaluate the performance of our method on MNIST (LeCun et al., 1998), CIFAR-10 and
CIFAR-100 (Krizhevsky & Hinton, 2009). We compare our method to several ANN-SNN meth-
ods (Hunsberger & Eliasmith, 2015; Sengupta et al., 2019; Deng & Gu, 2021), direct SNN training
methods (Wu et al., 2018; Xiao et al., 2021), and SpikeGrad (Thiele et al., 2019a). As shown in
Table 3, we can train models with a small number of time steps and our trained models achieve
8
Under review as a conference paper at ICLR 2022
competitive results on MNIST and CIFAR-10. Compared with the original IDE method (Xiao et al.,
2021), since we discard the BN component, our generalization performance is poorer (a detailed
discussion is in Appendix F.2). Compared with SpikeGrad (Thiele et al., 2019a), we can use fewer
neurons and parameters due to flexible network structure choices, and a small number of time steps
while they do not report this important feature. Besides, we use common neuron models while they
require impractical models, as indicated in Section 4.1. The results and discussion on CIFAR-100
and CIFAR10-DVS are in Appendix F.3 and F.4 due to the space limit, and our model could achieve
64.07% and 60.7% accuracy respectively. The result on CIFAR-100 is competitive for networks
without BN, though it is poorer than IDE with BN. And the result on CIFAR10-DVS is competitive
among results of common SNN models. It shows the effectiveness of our method even with con-
straints of purely spike-based training. Future work could seek normalization techniques friendly
for neuromorphic computation and our desired algorithm to further improve the performance.
Table 2: Evaluation of
training with different time
steps in the backward stage.
Training is on CIFAR-10
with AlexNet-F structure and
TF = 30. Results are based
on 3 runs of experiments.
Figure 2: The average firing rates for forward and back-
ward stages during training. ‘A’ means AlexNet-F, ‘C’ means
CIFARNet-F, and T means time steps for the backward stage.
TB I	Mean±Std (Best)
50
100
250
500
88.41%±0.48% (89.07%)
89.17%±0.14% (89.35%)
89.61%±0.11% (89.70%)
89.57%±0.08% (89.67%)
0.1
0.08
0.06
0.04
0.02
0
Epochs
—A, T=50,
Forward
--A, T=50,
Backward
—A, T=100,
Forward
--A, T=100,
Backward
—A, T=250,
Forward
--A, T=250,
Backward
—A, T=500,
Forward
--A, T=500,
Backward
—C, T=250,
Forward
--C, T=250,
Backward
Table 3: Performance on MNIST and CIFAR-10. Results are based on 3 runs of experiments.
MNIST						
Method	Network structure	TF	TB	Mean±Std (Best)	Neurons	Params
BP (Lee et al., 2016)	20C5-P2-50C5-P2-200	›200	/	(99.31%)	33K	518K
STBP (Wu et al., 2018)	15C5-P2-40C5-P2-300	30	/	(99.42%)	26K	607K
IDE (Xiao et al., 2021)	64C5 (F64C5)	30	/	99.53%±0.04% (99.59%)	13K	229K
SpikeGrad (Thiele et al., 2019a)	15C5-P2-40C5-P2-300	Unknown	Unknown	99.38%±0.06% (99.52%)	26K	607K
SPIDE (ours)	64C5s-64C5s-64C5 (F64C3u)		30	100	99.34%±0.02% (99.37%)	20K	275K
SPIDE (ours, degraded)	15C5-P2-40C5-P2-300	30	100	99.44%±0.02% (99.47%)	26K	607K
CIFAR-10						
Method	Network structure	TF	TB	Mean±Std (Best)	Neurons	Params
ANN-SNN (Hunsberger & Eliasmith,	2015)	AlexNet	80	/	(83.52%)	595K	21M
ANN-SNN Sengupta et al. (2019)	VGG-16		2500	/	(91.55%)	311K	15M
ANN-SNN (Deng & Gu, 2021)	CIFARNet	400-600	/	(90.61%)	726K	45M
STBP (Wu et al., 2019)	AlexNet	12	/	(85.24%)	595K	21M
STBP (w/o NeuNorm) (Wu et al., 2019)	CIFARNet		12	/	(89.83%)	726K	45M
STBP (Xiao et al., 2021)	AlexNet-F	30	/	(87.18%)	159K	3.7M
IDE (Xiao et al., 2021)	AlexNet-F	30	/	91.74%±0.09% (91.92%)	159K	3.7M
IDE (Xiao et al., 2021)	CIFARNet-F	30	/	92.08%±0.14% (92.23%)	232K	11.8M
SpikeGrad (Thiele et al., 2019a)	CIFARNet	Unknown	Unknown	89.49%±0.28% (89.99%)	726K	45M
SPIDE (ours)	AlexNet-F	30	250	89.61%±0.11% (89.70%)	159K	3.7M
SPIDE (ours)	CIFARNet-F	30	250	89.94%±0.17% (90.13%)	232K	11.8M
6	Conclusion
In this work, we propose the SPIDE method that generalize the IDE method to enable the whole
training of SNNs with either feedback or degraded feedforward structures to be based on spikes
with common neuron models. We prove that the implicit differentiation can be solved with spikes
by our coupled neurons. We also analyze the approximation error due to finite time steps, and
propose to adjust the resting potential of SNNs. Experiments show that we could achieve competitive
performance with a small number of training time steps and sparse spikes, which demonstrates the
great potential of our method for energy-efficient training of SNNs on neuromorphic hardware.
9
Under review as a conference paper at ICLR 2022
References
Filipp Akopyan, Jun Sawada, Andrew Cassidy, Rodrigo Alvarez-Icaza, John Arthur, Paul Merolla,
Nabil Imam, Yutaka Nakamura, Pallab Datta, Gi-Joon Nam, et al. TrueNorth: Design and tool
flow of a 65 mw 1 million neuron programmable neurosynaptic chip. IEEE Transactions on
Computer-Aided Design ofIntegrated Circuits and Systems, 34(10):1537-1557, 2015.
Shaojie Bai, J Zico Kolter, and Vladlen Koltun. Deep equilibrium models. In Advances in Neural
Information Processing Systems, 2019.
Shaojie Bai, Vladlen Koltun, and J Zico Kolter. Multiscale deep equilibrium models. In Advances
in Neural Information Processing Systems, 2020.
Shaojie Bai, Vladlen Koltun, and Zico Kolter. Stabilizing equilibrium models by jacobian regular-
ization. In International Conference on Machine Learning, 2021.
Guillaume Bellec, Darjan Salaj, Anand Subramoney, Robert Legenstein, and Wolfgang Maass. Long
short-term memory and learning-to-learn in networks of spiking neurons. In Advances in Neural
Information Processing Systems, 2018.
Sander M Bohte, Joost N Kok, and Han La Poutre. Error-backpropagation in temporally encoded
networks of spiking neurons. Neurocomputing, 48(1-4):17-37, 2002.
Leon Bottou. Large-scale machine learning with stochastic gradient descent. In Proceedings of
COMPSTAT’2010. 2010.
Jianfei Chen, Yu Gai, Zhewei Yao, Michael W Mahoney, and Joseph E Gonzalez. A statistical
framework for low-bitwidth training of deep neural networks. In Advances in Neural Information
Processing Systems, 2020.
Mike Davies, Narayan Srinivasa, Tsung-Han Lin, Gautham Chinya, Yongqiang Cao, Sri Harsha
Choday, Georgios Dimou, Prasad Joshi, Nabil Imam, Shweta Jain, et al. Loihi: A neuromorphic
manycore processor with on-chip learning. IEEE Micro, 38(1):82-99, 2018.
Shikuang Deng and Shi Gu. Optimal conversion of conventional artificial neural networks to spiking
neural networks. In International Conference on Learning Representations, 2021.
Peter U Diehl and Matthew Cook. Unsupervised learning of digit recognition using spike-timing-
dependent plasticity. Frontiers in Computational Neuroscience, 9:99, 2015.
Wei Fang, Zhaofei Yu, Yanqi Chen, Timothee Masquelier, Tiejun Huang, and Yonghong Tian. In-
corporating learnable membrane time constant to enhance learning of spiking neural networks. In
Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), 2021.
Jordan Guerguiev, Timothy P Lillicrap, and Blake A Richards. Towards deep learning with segre-
gated dendrites. Elife, 6:e22901, 2017.
Eric Hunsberger and Chris Eliasmith. Spiking deep networks with LIF neurons. arXiv preprint
arXiv:1510.08829, 2015.
Michael F Hutchinson. A stochastic estimator of the trace of the influence matrix for laplacian
smoothing splines. Communications in Statistics-Simulation and Computation, 18(3):1059-1076,
1989.
Yingyezhe Jin, Wenrui Zhang, and Peng Li. Hybrid macro/micro level backpropagation for training
deep spiking neural networks. In Advances in Neural Information Processing Systems, 2018.
Jinseok Kim, Kyungsu Kim, and Jae-Joon Kim. Unifying activation-and timing-based learning rules
for spiking neural networks. In Advances in Neural Information Processing Systems, 2020.
Alex Krizhevsky and Geoffrey Hinton. Learning multiple layers of features from tiny images. Tech-
nical report, University of Toronto, 2009.
10
Under review as a conference paper at ICLR 2022
Jonas Kubilius, Martin Schrimpf, Kohitij Kar, Rishi Rajalingham, Ha Hong, Najib Majaj, Elias Issa,
Pouya Bashivan, Jonathan Prescott-Roy, Kailyn Schmidt, et al. Brain-like object recognition with
high-performing shallow recurrent anns. In Advances in Neural Information Processing Systems,
2019.
Yann LeCun, Leon Bottou, YoshUa Bengio, and Patrick Haffner. Gradient-based learning applied to
document recognition. Proceedings of the IEEE, 86(11):2278-2324,1998.
Jun Haeng Lee, Tobi Delbruck, and Michael Pfeiffer. Training deep spiking neural networks using
backpropagation. Frontiers in Neuroscience, 10:508, 2016.
Robert Legenstein, Dejan Pecevski, and Wolfgang Maass. A learning theory for reward-modulated
spike-timing-dependent plasticity with application to biofeedback. PLoS Comput Biol, 4(10):
e1000180, 2008.
Hongmin Li, Hanchao Liu, Xiangyang Ji, Guoqi Li, and Luping Shi. Cifar10-dvs: an event-stream
dataset for object classification. Frontiers in Neuroscience, 11:309, 2017.
Emre O Neftci, Charles Augustine, Somnath Paul, and Georgios Detorakis. Event-driven random
back-propagation: Enabling neuromorphic deep learning machines. Frontiers in neuroscience,
11:324, 2017.
Emre O Neftci, Hesham Mostafa, and Friedemann Zenke. Surrogate gradient learning in spiking
neural networks: Bringing the power of gradient-based optimization to spiking neural networks.
IEEE Signal Processing Magazine, 36(6):51-63, 2019.
Arild N0kland. Direct feedback alignment provides learning in deep neural networks. In Advances
in Neural Information Processing Systems, 2016.
Peter O’Connor and Max Welling. Deep spiking networks. arXiv preprint arXiv:1602.08323, 2016.
Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor
Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al. Pytorch: An imperative style, high-
performance deep learning library. In Advances in Neural Information Processing Systems, 2019.
Jing Pei, Lei Deng, Sen Song, Mingguo Zhao, Youhui Zhang, Shuang Wu, Guanrui Wang, Zhe
Zou, Zhenzhi Wu, Wei He, et al. Towards artificial general intelligence with hybrid Tianjic chip
architecture. Nature, 572(7767):106-111, 2019.
Nitin Rathi, Gopalakrishnan Srinivasan, Priyadarshini Panda, and Kaushik Roy. Enabling deep
spiking neural networks with hybrid conversion and spike timing dependent backpropagation. In
International Conference on Learning Representations, 2019.
Kaushik Roy, Akhilesh Jaiswal, and Priyadarshini Panda. Towards spike-based machine intelligence
with neuromorphic computing. Nature, 575(7784):607-617, 2019.
Bodo Rueckauer, Iulia-Alexandra Lungu, Yuhuang Hu, Michael Pfeiffer, and Shih-Chii Liu. Con-
version of continuous-valued deep networks to efficient event-driven networks for image classifi-
cation. Frontiers in Neuroscience, 11:682, 2017.
David E Rumelhart, Geoffrey E Hinton, and Ronald J Williams. Learning representations by back-
propagating errors. Nature, 323(6088):533-536, 1986.
Arash Samadi, Timothy P Lillicrap, and Douglas B Tweed. Deep learning with dynamic spiking
neurons and fixed feedback weights. Neural Computation, 29(3):578-602, 2017.
Abhronil Sengupta, Yuting Ye, Robert Wang, Chiao Liu, and Kaushik Roy. Going deeper in spiking
neural networks: Vgg and residual architectures. Frontiers in Neuroscience, 13:95, 2019.
Sumit Bam Shrestha and Garrick Orchard. Slayer: spike layer error reassignment in time. In
Advances in Neural Information Processing Systems, 2018.
Amos Sironi, Manuele Brambilla, Nicolas Bourdis, Xavier Lagorce, and Ryad Benosman. Hats:
Histograms of averaged time surfaces for robust event-based object classification. In Proceedings
of the IEEE Conference on Computer Vision and Pattern Recognition, 2018.
11
Under review as a conference paper at ICLR 2022
Johannes C Thiele, Olivier Bichler, and Antoine Dupret. Spikegrad: An ann-equivalent computation
model for implementing backpropagation with spikes. In International Conference on Learning
Representations, 2019a.
Johannes C Thiele, Olivier Bichler, Antoine Dupret, Sergio Solinas, and Giacomo Indiveri. A spik-
ing network for inference of relations trained with neuromorphic backpropagation. In 2019 Inter-
national Joint Conference on Neural Networks (IJCNN), 2019b.
Jibin Wu, Yansong Chua, Malu Zhang, Guoqi Li, Haizhou Li, and Kay Chen Tan. A tandem learning
rule for effective training and rapid inference of deep spiking neural networks. IEEE Transactions
on Neural Networks and Learning Systems, 2021.
Yujie Wu, Lei Deng, Guoqi Li, Jun Zhu, and Luping Shi. Spatio-temporal backpropagation for
training high-performance spiking neural networks. Frontiers in Neuroscience, 12:331, 2018.
Yujie Wu, Lei Deng, Guoqi Li, Jun Zhu, Yuan Xie, and Luping Shi. Direct training for spiking neural
networks: Faster, larger, better. In Proceedings of the AAAI Conference on Artificial Intelligence,
2019.
Mingqing Xiao, Qingyan Meng, Zongpeng Zhang, Yisen Wang, and Zhouchen Lin. Training feed-
back spiking neural networks by implicit differentiation on the equilibrium state. In Advances in
Neural Information Processing Systems, 2021.
Zhanglu Yan, Jun Zhou, and Weng-Fai Wong. Near lossless transfer learning for spiking neural
networks. In Proceedings of the AAAI Conference on Artificial Intelligence, 2021.
Wenrui Zhang and Peng Li. Spike-train level backpropagation for training deep recurrent spiking
neural networks. In Advances in Neural Information Processing Systems, 2019.
Wenrui Zhang and Peng Li. Temporal spike sequence learning via backpropagation for deep spiking
neural networks. In Advances in Neural Information Processing Systems, 2020.
Hanle Zheng, Yujie Wu, Lei Deng, Yifan Hu, and Guoqi Li. Going deeper with directly-trained
larger spiking neural networks. In Proceedings of the AAAI Conference on Artificial Intelligence,
2021.
12
Under review as a conference paper at ICLR 2022
A More Background ab out the IDE Training Method
Due to the complex spiking neuron model which is discontinuous, directly supervised training
of SNNs is a hard problem, since the explicit computation is non-differentiable and therefore
backpropagation along the forward computational graph could be problematic. The IDE training
method (Xiao et al., 2021) considers another approach to calculating gradients that does not rely
on the exact reverse of the forward computation, which avoids the problem of non-differentiability
as well as large memory costs by BPTT-like methods with surrogate gradients. Specifically, the
IDE training method first derives that the (weighted) average firing rate of FSNN computation with
common neuron models would gradually evolve to an equilibrium state along time, which follows a
fixed-point equation. Then by viewing the forward computation of FSNN as a black-box solver for
this equation, and applying implicit differentiation on the equation, gradients can be calculated only
based on this equation and the (weighted) average firing rate during forward computation rather than
the exact forward procedure. Therefore, the forward and backward procedures are decoupled and
the non-differentiability is avoided.
As briefly introduced in Section 3.2, the IDE method defines the average firing rates of spikes during
forward computation, i.e. α[t]. Then IDE could derive an equivalent update equation for α[t], based
on the integrated update equations of membrane potentials Eq. (2,3). With the equivalent equation
for α[t], IDE proves that under certain conditions, α[t] converges to an equilibrium state following a
fixed-point equation. With the assumption that α[T] after simulation ofT time steps roughly follows
the fixed-point equation of the equilibrium state, gradients of the loss function for parameters can
be calculated by implicit differentiation, as introduced in Section 3.3. So the training pipeline for
the IDE method can be summarized as: first simulate FSNN computation for T time steps to obtain
the rate of spikes α[T], then solve the implicit differentiation by root-finding methods for gradient
calculation based on α[T] and the derived fixed-point equation of equilibrium states, finally apply
gradient-based optimizers to update parameters.
Contribution of this work compared with IDE. Compared with IDE, this work extends the
thought of equilibrium of spikes to solving implicit differentiation, which enables the whole training
procedure to be based on spike computation with common neuron models and provides the potential
for energy-efficient training of SNNs on neuromorphic hardware. IDE only derives the equilibrium
states of forward FSNN computation and requires general root-finding methods with complex com-
putation to solve implicit differentiation for training. It remains unclear if it could be solved by
common spiking neuron models with only positive firing. This work design ternary spiking neuron
couples and prove that the equilibrium of spike computation can be leveraged to solve implicit dif-
ferentiation based on the design, and we propose to modify the resting membrane potential to make
it practical in a relatively small number of time steps. This enables the proposed SPIDE method to be
the first to train high-performance SNNs with low latency and firing sparsity by spikes with common
neuron models, demonstrating the great potential for energy-efficient training of high-performance
SNNs on neuromorphic hardware.
B Proof of Theorem 1
Proof. We first prove the convergence of β[t]. Let Vu and Vub denote Vth - urest and Vtbh - ubrest
respectively. Consider kβ[t + 1] - β[t]k, it satisfies:
kβ[t + 1] - β[t]k
Iφ (V1b (t+ι V1u (MW)>β[t]+g - u⅛+H1
-φ
g(MW)>β[t- 1] + g - uB[t]
Vu	t
≤
φ (Vb (F(MW)>β[t] + g φ (Vb (F(MW)>β[t-1] + g))
+1 φ (⅛(t+1 Vu(MW)>β[t]+g- u⅛+11 φ (⅛ &(MW)>β[t]+g
13
Under review as a conference paper at ICLR 2022
+ ∣φ (V1b (t-rVu(MW)>β[t -1]+g - ¥))- φ (V1b &(MW)>β[t -1]+g))
≤
φ (Vb (F(MW)>β[t] + g
φ (Vb (F(MW)>β[t- 1]+ g
1
+ Vb
u
Q t+ι 左(MW)>βT+
111+
VVF(MW)> β[t - 1]
t Vu
(12)
As k(MW)> k2≤ γVu Vub, γ < 1, and |uiB [t]| is bounded, we have kβ[t + 1]k ≤
Y kβ[t]k + V1u (kgk + Il u：++1JD ≤ Y kβ[t]k + C, where C is a constant. Therefore ∣∣β[t]k
is bounded. Then ∀ > 0, ∃T1 such that when t > T1, we have:
Vb (I t+ι V(MW)> β[t]ll+1 uB⅛al I+1 ⅛(MW)>β[t-1]||+1UBH I) ≤ F
(13)
And since ∣(MW)> ∣2≤ YVu Vub, we have:
φ (Vb	(F(MW)>β[t] + g)) - φ	(Vb	(F(MW)Tβ[t-	1]	+ g))	≤ Ykβ[t]	- β[t -	1]k.
u u	u u	(14)
Therefore, when t > T1, it holds that:
kβ[t + 1] - β[t]k ≤ Y kβ[t] - β[t - 1]k + ɪɪ).	(15)
By iterating the above inequality, we have ∣β[t + 1] - β[t]∣ ≤ Yt-T1 ∣β[T1 + 1] - β[T1]∣ +
e(1-γ) (1 + γ +--+ γt-T1-1) < γt-T1 ∣β[Tι + 1] - β[Tι]∣ + 2. There exists T2 such that when
t > Ti + T2, Yt-TIkβ[T1 + 1] - β[Tι]∣ ≤ f, and therefore ∣∣β[t + 1] - β[t]∣ < e. According
to Cauchy's convergence test, the sequence {β[t]}∞=0 converges to β*. Considering the limit, it
satisfies β* = φ(VIb (VIU(MW)>β* + g)).
When Vtbh - ubrest = 1, and there exists λ < 1 such that ∣(MW)> ∣∞ ≤ λ(Vth - urest) and
kgk∞ ≤ 1 - λ, the equation turns into β* = φ (/(MW)>β* + g). We have:
kβ*k∞ = φg(MW)>β*+ g)∣	≤ V^(MW)>β*	+ kgk∞ ≤ λ kβ*k∞ + kgk∞ .
u	∞ u	∞	(16)
Therefore, kβ*k∞ ≤ kg-∞ ≤ 1, and ∣Vu(MW)>β* + g^ ≤ ∣Vu(MW)>β*k + kgk∞ ≤
λ + (1 - λ) = 1. Itmeans β* = φ (*(MW)>β* + g)=/(MW)>β* + g.
Taking fθ3) = σ 不\(Wα* + Fx* +
(i.e. the fixed-point equation at the
equilibrium state as in Section 3.2) explicitly into Eq. (5), the linear equation turns into
(Vk(MW)> - I)β + g = 0, where Vu, M, g are previously defined. Therefore, β* satisfies
this equation. And since ∣∣(MW)> ∣∣2≤ yVU,y < 1, the equation has the unique solution β*.
□
Remark 1. As for the assumptions in the theorem, firstly, when Vtbh - ubrest = 1 as we will take,
the assumption for the convergence is weaker than that for the convergence in the forward stage (in
Section 3.2), because ∣(MW)> ∣2 ≤ ∣W∣2as M is a diagonal mask matrix. We will restrict the
14
Under review as a conference paper at ICLR 2022
spectral norm of W following Xiao et al. (2021) to encourage the convergence of the forward stage
(in Appendix D), then this backward stage would converge as well.
The assumptions for the consistency of the solution is a sufficient condition. In practice, the weight
norm will be partially restricted by weight decay and our restriction on Frobenius norm (in Ap-
pendix D), as well as the diagonal mask matrix M which would be sparse if the forward firing
events are sparse, and we will rescale the loss so that the input g is in an appropriate range, as
indicated in Section 4.3. Even if these assumptions are not satisfied, we can view φ as a kind of
empirical clipping techniques to stabilize the training, as indicated in Section 4.2. The discussion is
similar for the multi-layer condition (Theorem 2) in the next section.
C Proof of Theorem 2
Proof. We first prove the convergence of βl [t]. Let Vu and Vub denote Vth - urest and Vtbh - ubrest
respectively. Let gN+1(β, g, UB) = φ (表(t+1 V1u (M1W1)>β + g -鲁)),
gt(β, UB) = Φ (表(VU(Ml+1Fl+1)>β — 吟)),1 = 1,…,N - 1,
gN(β, g) = Φ (Vb(VU(M1W1)>β + g)),
gι(β) = Φ (吉(合(Ml+1Fl+1)>β)) ,1 = 1,…,N — 1.
Then eN[t + 1] = gt+1 (gt (…gN -i (βN[t], UNTB[t])…，UIB [t]) , g, UNB[t + 1]).
We have:
βN[t+1]-βN[t]
=gtN1 (gt (…gN-1 (βN [t], UNTB [t])…，UIB [t]) , g, UNB [t + 1])
-gN (gt-1 (…gt--1 (βN [t - 1], UN TB [t - 1])…，u/ [t - 1]) , g, UNB [t]) U
≤ UgN (gl (…gN-1 (βN [t])…),g) — gN (gl (…gN-1 (βN [t - 1])…),g)||
+	gt+1	(gt	(…gN-1	(βN [t],	UNTB	[t])…，u" [t])	, g, UNB [t	+ 1]) - gN	(gl	(…gN-1	(βN [t])…),g) U
+	gN	(gt-1 (…gtN-1	(βN [t	- 1],	UNTB [t	-	1])…，u" [t	-	1])	, g, UNB [t])
-gN (g1 (…gN-1 (βN [t - 1])…),g) U
≤ UgN (g1 (…gN-1 (βN [t])…),g) - gN (g1 (…gN-1 (βN [t - 1])…),g) U
+ V1b (U t-ɪɪ V(MIW1)>gt (…gN-1 (βN[t], unTB町…，U1B[t])U
15
Under review as a conference paper at ICLR 2022
For the term A and B, they are bounded by:
A ≤ yb (|卜(M1W1)> _ (MNFN)> (g2 (…gN-1 (βN用,UNTB [t])…，uB) 一 g2 (…gN-1 (βN[t])…))[
+ | 左(MIWI)T
≤	....
≤	Vb J(MIWI)Tu1⅛ + …+ VbN-τ V⅛r(MIWI)T(MNFN)t
3	. U	3
and B has the same form as A by substituting t with t — 1.
-(M3F3)T —1
(18)
Since k(M1W1)τ∣∣2k(MNFn)t∣∣2 …∣∣(M2F2)τ∣∣2 ≤ YVf VuN, we have:
9n(91 (∙ ∙ ∙ 9n-1 (βN[t]) ∙ ∙ ∙) , g) — 9n(91 (∙ ∙ ∙ 9n-1 (βN[t — 1]) ∙ ∙ ∙) , g) ∣∣
≤	Vb Vr (MIWI)T(91( ∙ ∙ 9n-1 CβN[t]) ∙ ∙ ∙) — 91 (∙ ∙ ∙ 9n-1 (ON[t — 1]) ∙ ∙ ∙))
≤	..... (19)
≤	||*VN(M1W1)t(MnFn)t ∙∙∙ (M2F2)t (βN[t] — βN[t — 1])
∣ ∣ Vu	u
≤	YIeN[t] — βN[t —1]∣∣.
And since UiB [t] is bounded, then ∀e > 0, ∃T1 such that when t > T1, we have:
IeN[t + 1] — βN[t]∣∣ ≤ YIeN[t] — βN[t — 1]∣∣ + &U.	(20)
Then IleN[t + 1] — βN[t]∣∣ < Yt-TIkeN[T1 + 1] — βN[T1]∣∣ + 另 and there exists T2 such that
when t > T1 + T2, IIeN[t + 1] — eN[t]∣∣ < e. According to Cauchy,s convergence test, eN[t]
converges to eN*, which satisfies eN* = 9n(91 ◦ ∙ ∙ ∙ ◦ 9n-1(eN*), g). Considering the limit,
B1 [t] converges to el*, which satisfies el* = 9ι(el+1 *).
When Vh — UreSt = 1, and there exists λ < 1 such that ∣∣(M1W1)t∣∞ ≤ λ(V九 —
UreSt)J(Ml Fl)Th ≤ λ(Vth — UreSt),l = 2, ∙ ∙ ∙ ,N and ∣∣gk∞ ≤ 1 — λN, we have:
IeN *∣L = ∣9N(91 o ∙ ∙ ∙ o 9N-1(eN *), g) L ≤ V√M1W1)t91 O ∙ ∙ ∙ O 9n-1(eN *)	+ l∣gk∞
≤λ ∣∣91o ∙ ∙ ∙o 9N-1(eN *)L + ι∣gk∞ ≤.≤λN ∣∣eN *∣∣oo + ι∣gk∞	(21)
Therefore, ∣∣Bn*∣∣	≤ k⅜N ≤ 1, and ∣∣9n-1(eN*)∣∣	≤ λ ∣∣eN*∣∣	≤ λ,.,
∣∣91 o ∙ ∙ ∙ o9n-1(eN*)L ≤ an-1, ∣∣(7n 伍 o ∙ ∙ ∙ o9n-1(eN*),g) ∣∣oo ≤ λN + (1 — λN)=
1, where 9n(e, g) = ⅛(MIWI)Te + g,9l(e)=/(M'+1F'+1Ne, l = 1,∙∙∙,N — 1,
(i.e. 9l is 9l without the function φ). It means eN* = 9N (91 o ∙ ∙ ∙ o 9N-1(eN*), g) =
9n(91 o ∙ ∙ ∙ o 9n-1(eN *), g) and el * = 9l (el+1*) = 9∕(el+1*).
Taking ɑ1* = f (∕n o ∙ ∙ ∙ o f2(a1*), x*) and ɑl+1* = ∕l+1 (al*) (i.e. the fixed-point equa-
tion at the equilibrium state as in Section 3.2) explicitly into Eq. (5), the linear equation turns
into 91 o ∙ ∙ ∙ o 9n-1(e) — e + g = 0. Therefore, eN* satisfies this equation. And since
∣∣(M1W1)t∣∣2∣I(MNFN)TIl2 ∙∙∙∣∣(M2F2)t∣∣2 ≤ YVN,γ < 1, the equation has the unique
16
Under review as a conference paper at ICLR 2022
solution βN*. Further, because gι(β) = (©h+ON*)) β, Where hι(αN*) = 力 ◦ ∙∙∙ ◦
f2 (fι(αN*,x*)) ,l = N,…，1, Wehave βl* = (⅞⅛N⅞)> βN*，1 = N - 1,…，L
□
D	Training details
D.1 Dropout
Dropout is a commonly used technique to prevent over-fitting, and We folloW Bai et al. (2019; 2020);
Xiao et al. (2021) to leverage variational dropout, i.e. the dropout of each layer is the same at dif-
ferent time steps. Since applying dropout on the output of neurons is a linear operation With a mask
and scaling factor, it can be integrated into the Weight matrix Without affecting the conclusions of
convergence. The detailed computation With dropout is illustrated in the pseudocode in Appendix E.
D.2 Restriction on weight norm
As indicated in the theorems, a sufficient condition for the convergence to equilibrium states in
both forWard and backWard stages is the restriction on the Weight spectral norm. Xiao et al. (2021)
leverages re-parameterization to restrict the spectral norm, i.e. they re-parameterize W as W =
a kWW∣2, where ∣∣W∣∣2 is computed as the implementation of Spectral Normalization and α is a
learnable parameter to be clipped in the range of [-c， c] (c is a constant). HoWever, the computation
of spectral norm and re-parameterization may be hard to realize on neuromorphic hardWare. We
adjust it for a more friendly calculation as folloWs.
First, the spectral norm is upper-bounded by the Frobenius norm: kWk2 ≤ kWkF . We can al-
ternatively restrict the Frobenius norm Which is easier to compute. Further, considering that con-
nection weights may not be easy for readout compared with neuron outputs, we can approximate
IWkF by ∣∣W∣∣F = √tr(WW>) = /E6n(0,Id) [ke>W∣∣2], according to the Hutchinson esti-
mator (Hutchinson, 1989). It can be viewed as source neurons outputting noises and target neurons
accumulating signals to estimate the Frobenius norm. We will estimate the norm based on the
Monte-Carlo estimation (we will take 64 samples), which is similarly adopted by Bai et al. (2021)
to estimate the norm of their Jacobian matrix. Then based on the estimation, we will restrict W
as W = α kWWkF where a = min(c, ∣W∣f), C is a constant for norm range. This estimation and
calculation may correspond to large amounts of noises in our brains, and a feedback inhibition on
connection weights based on neuron outputs.
Following Xiao et al. (2021), we only restrict the norm of feedback connection weight W1 for the
multi-layer structure, which works well in practice.
D.3 Other details
For SNN models with feedback structure, we set Vth= 1， urest = -1 in the forward stage to form
an equivalent equilibrium state as Xiao et al. (2021). The constant for restriction in Appendix D.2
is c = 2. Following Xiao et al. (2021), we train models by SGD with momentum for 100 epochs.
The momentum is 0.9, the batch size is 128, and the initial learning rate is 0.05. For MNIST, the
learning rate is decayed by 0.1 every 30 epochs, while for CIFAR-10 and CIFAR-100, it is decayed
by 0.1 at the 50th and 75th epoch. We apply linear warmup for the learning rate in the first 400
iterations for CIFAR-10 and CIFAR-100. We apply the weight decay with 5 × 10-4 and variational
dropout with rate 0.2 for AlexNet-F and 0.25 for CIFARNet-F. The initialization of weights follows
Wu et al. (2018), i.e. we sample weights from the standard uniform distribution and normalize them
on each output dimension. The scale for the loss function (as in Section 4.3) is 100 for MNIST, 400
for CIFAR-10, and 500 for CIFAR-100.
For SNN models with degraded feedforward structure, our hyperparameters mostly follow Thiele
et al. (2019a), i.e. we set Vth = 0.5， urest = -0.5, train models by SGD with momentum 0.9 for
17
Under review as a conference paper at ICLR 2022
60 epochs, set batch size as 128, and the initial learning rate as 0.1 which is decayed by 0.1 every 20
epochs, and apply the variational dropout only on the first fully-connected layer with rate 0.5.
The notations for our structures mean: ‘64C5’ represents a convolution operation with 64 output
channels and kernel size 5, ‘s’ after ‘64C5’ means convolution with stride 2 (which downscales 2×)
while ‘u’ after that means a transposed convolution to upscale 2×, ‘P2’ means average pooling with
size 2, and ‘F’ means feedback layers. The network structures for CIFAR-10 are:
AlexNet (Wu et al., 2019): 96C3-256C3-P2-384C3-P2-384C3-256C3-1024-1024,
AlexNet-F (Xiao et al., 2021): 96C3s-256C3-384C3s-384C3-256C3 (F96C3u),
CIFARNet (Wu et al., 2019): 128C3-256C3-P2-512C3-P2-1024C3-512C3-1024-512,
CIFARNet-F (Xiao et al., 2021): 128C3s-256C3-512C3s-1024C3-512C3 (F128C3u).
We simulate the computation on commonly used computational units. The code implementation
is based on the PyTorch framework (Paszke et al., 2019), and experiments are carried out on one
NVIDIA GeForce RTX 3090 GPU.
E Pseudocode of the SPIDE algorithm
Our algorithm consists of two-stage SNN computation, as explained in Section 4.4. The detailed
computation for both stages are illustrated in Algorithm 1 and Algorithm 2 respectively.
Algorithm 1 Forward procedure of SPIDE training - Stage 1.
Input: Network parameters F 1,b1,∙∙∙ ,F N, bN, W 1, Wo, bo; Input data x; Time steps TF;
Forward threshold Vth ; Dropout rate r;
Output: Output of the readout layer o.
1:	Initializeui[0] = 0,i = 1,2,…，Ν
2:	If use dropout, randomly generate dropout masks Di(i = 1, 2, •…，N), Df with rate r //
Di, Df are saved for backward
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
for t = 1,2,…，Tf do
if t == 1 then
u1[t] = u1[t - 1] + D1	(F1x[t] + b1)
else
u1[t] =u1[t- 1] +D1	(F1x[t] +b1)+Df	(W1sN[t- 1])
s1[t] = H(u1[t] ≥ Vth)
u1[t] = u1 [t] - 2Vths1 [t]	// urest = -Vth, the same below
for l = 2, 3,…，N do
ul[t] =ul[t- 1] +Dl	(Flsl-1[t] +bl)
sl [t] = H(ul [t] ≥ Vth)
ul [t] = ul [t] - 2Vthsl [t]
o = o+WosN[t]+bo	// o can be accumulated here, or calculated later by o = WoαN+bo
o = T
αi = Pt=TS [t], i = 1, 2,∙∙∙,N // Save for backward, firing rate in Stage 1
mi = H(αi > 0) ∧ H(αi < 1)	// Save for backward, mask
If X is not constant, save X = Pt=T x[t] for backward
return o
F More experimental comparisons
F.1 Ablation S tudy
In this section, we conduct ablation study on our improvement to reduce the approximation error
by setting the resting potential as negative threshold. To formulate equivalent equilibrium states, we
18
Under review as a conference paper at ICLR 2022
Algorithm 2 Backward procedure of SPIDE training - Stage 2.
Input: Network parameters F1,b1, •…，F N, bN, W 1,Wo, bo; Forward output o; Label y; Time
steps TB; Forward threshold Vth; Backward threshold Vtbh = 0.5; Other hyperparameters and saved
variables;
Output: Trained network parameters F1,b1,…，F N, bN, W 1,W o, bo.
1:	Calculate g = dLdO，y)	// for CE loss, dL∂θ,y) = Softmax(o) — y, in practice We will scale the
loss by a factor si, then dL∂oy) = Sl (Softmax(o) - y)
2:	Initializeui[0] = 0,i = 1,2,…，Ν
3:	fort = 1,2,…，Tb do
4:	if t == 1 then
5:	uN [t] = uN[t - 1] + Wo>g
6:	else
7:	UN[t] = UN[t — 1] + Wo>g + 忐W 1>(Df Θ m1 Θ s1[t — 1])	// mi is the saved
mask in Stage 1
8:	sN [t] = T (UN [t], 0.5)	// realized by two coupled neurons
9:	UN [t] = UN [t] - sN [t]	// realized by two coupled neurons
10:	for l = N — 1,Ν — 2,…，1 do
11:	ul [t] = ul [t 一 1] + 2V1^Fl>(Dl Θ ml+1 Θ sl+1[t])	// mi	is the saved mask in Stage 1
12:	sl[t] = T(Ul [t], 0.5)	// realized by two coupled neurons
13:	Ul [t] = Ul [t] 一 sl[t]	// realized by two coupled neurons
14:	βi = Pt=TS [t], i = 1, 2,…，N // “firing rate” in Stage 2
15:	Calculate gradients:
16:	(1) Vfi L = 2V1^(m1 Θ β1)χ>	// mi,χ are the saved mask and average input in Stage 1
17:	(2) VF i L = 2V^ (mi Θ βi)αi-1>, i = 2, 3,…，N // mi ,αi are the saved mask and firing
rate in Stage 1
18:	⑶ VbiL = 2vth (mi θ βi), i = 1, 2,…，N
19:	(4) VWι L = 2V1th (m1 Θ β1 )αN	// mi , αi are the saved mask and firing rate in Stage 1
20:	(5) VWo L = αN ( dL∂θ,y))	// αi is the saved firing rate in Stage 1
21:	(6) Vbo L = (dLoy )>
22:	Update F 1,b1,∙∙∙ ,F N, bN, W 1, W o, bo based on the gradient-based optimizer // SGD
learning rate η + momentum a & weight decay μ, the base learning rate is scaled by the factor
sl of the loss, i.e. η =
23:	(1) Update the momentum Mg = α * Mg + (1 — α) * VθL, θ ∈ {Fi, bi, W 1, Wo, bo}
24:	(2) Update parameters θ = (1 一 μ) * θ + η * Mg, θ ∈ {Fi, bi, W1, Wo, bo}
25:	(3) Restrict the norm of W1
26:	return F1,b1, •一 ,FN,bN,W 1,Wo,bo
take the same Vth 一 Urest = Vu and the same Vtbh 一 Ubrest = Vub, and we consider the following
settings: (1) both forward and backward stages apply our improvement, i.e. Urest = -Vth, Ubest =
-Vth;(2) remove the improvement on the backward stage, i.e. Vth = Vb, Urest = 0;(3) remove the
improvement on both forward and backward stages, i.e. Vth = Vu, Urest = 0 and Vtbh = Vub, Ubrest =
0. The latter two setting are denoted by “w/o B” and “w/o F&B” respectively.
The models are trained on CIFAR-10 with AlexNet-F structure and 30 forward time steps. The
training and testing curves under different settings and backward time steps are illustrated in Fig-
ure 3 and Figure 4 respectively. It demonstrates that without our improvement, the training can not
perform well within a small number of backward time steps, probably due to the bias and large
variance of the estimated gradients. When the backward time steps are large, the performance gap
is reduced since the bias of estimation is reduced. It shows the superiority of our improvement to
training SNNs within a small number of backward time steps.
19
Under review as a conference paper at ICLR 2022
Testing Accuracy	Training Accuracy
1	11	21	31	41	51	61	71	81	91
——T=50
一	w/o	B, T=50
---w/o	F&B, T=50
——T=100
—	w/o	B, T=100
---w/o	F&B, T=100
——T=250
w/o B, T=250
---w/o	F&B, T=250
——T=500
—	w/o	B, T=500
---w/o	F&B, T=500
Epochs
Figure 3: Comparison of training curves under different settings and backward time steps.
1	11	21	31	41	51	61	71	81	91
——T=50
—	w/o	B, T=50
---w/o	F&B, T=50
T=100
—	w/o	B, T=100
w/o F&B, T=100
T=250
—	w/o B, T=250
w/o F&B, T=250
—	—T=500
—	w/o B, T=500
---w/o F&B, T=500
Epochs
Figure 4: Comparison of testing curves under different settings and backward time steps.
20
Under review as a conference paper at ICLR 2022
Figure 5: Comparison of training and testing curves between IDE and SPIDE on CIFAR-10 with
AlexNet-F structure and TF = 30.
F.2 Comparison to IDE
Table 3 in Section 5 shows that the SPIDE method performs poorer than the original IDE
method (Xiao et al., 2021). We further investigate the training and testing curves during optimiza-
tion to analyze this phenomenon. As shown in Figure 5, the SPIDE method could achieve the same
training accuracy as the IDE method, while the generalization performance is poorer. Since the hy-
perparameters are the same for experiments, except that we drop the modified BN component (as
explained in Section 4.4), the performance gap may be caused by the implicit regularization effect
of BN. Therefore, the optimization ability of the SPIDE method should be similar to that of IDE,
while future work would be to investigate how to realize operations similar to BN with possible
computation that could be friendly on neuromorphic hardware.
Also, we note that models trained by the IDE method (Xiao et al., 2021) have sparser spikes, as their
forward average firing rates are only around 1% (Xiao et al., 2021), while ours are around 7% as
shown in Figure 2. It is again probably due to BN which would subtract the statistical mean value
of neuron inputs, therefore regularizing the weights so that neurons will generate sparser spikes. An
interesting future work is to further reduce the number of spikes considering this phenomenon.
F.3 Results on CIFAR- 1 00
Table 4: Performance on CIFAR-100. Results are based on 3 runs of experiments.
Method	Network structure	BN	TF	TB	Mean±Std (Best)	Neurons	Params
BP (Thiele et al., 2019a)	CIFARNet	×	Unknown	/	(64.69%)	726K	45M
IDE (Xiao et al., 2021)	CIFARNet-F	X	30	/	71.56%±0.31% (72.10%)	232K	14.8M
SpikeGrad (Thiele et al., 2019a)	CIFARNet	×	Unknown	Unknown	(64.40%)	726K	45M
SPIDE (ours)	CIFARNet-F	×	30	100	63.57%±0.30%(63.91%)	232K	14.8M
SPIDE (ours)	CIFARNet-F	×	30	250	64.00%±0.11%(64.07%)	232K	14.8M
In this section, we present the results on CIFAR-100. As shown in Table 4, our model could achieve
64.07% accuracy. Compared with IDE, the performance is poorer, and the main reason is probably
again the absence of BN which could be important for alleviating overfitting on CIFAR-100 with
relatively small number of images per class. The training accuracy of SPIDE is similar to IDE
(around 93% v.s. around 94%) while the generalization performance is poorer. Despite this, the
performance of our model is competitive for networks without BN and our model is with fewer
neurons and parameters and a small number of time steps. Compared with SpikeGrad (Thiele et al.,
2019a), we can use fewer neurons and parameters due to flexible network structure choices, and
we leverage common neuron models while they require complex impractical models. Future work
could investigate more suitable structures and if there are normalization techniques friendly for
neuromorphic computation and our desired algorithm to further improve the performance.
21
Under review as a conference paper at ICLR 2022
F.4 RESULTS ON CIFAR10-DVS
In this section, we supplement some results on the spiking dataset CIFAR10-DVS (Li et al., 2017).
The CIFAR10-DVS dataset is the neuromorphic version of the CIFAR-10 dataset converted by a
Dynamic Vision Sensor (DVS), which is composed of 10,000 samples, one-sixth of the original
CIFAR-10. It consists of spike trains with two channels corresponding to ON- and OFF-event spikes.
The pixel dimension is expanded to 128 × 128. Following the common practice, we split the dataset
into 9000 training samples and 1000 testing samples. As for the data pre-processing, we reduce
the time resolution by accumulating the spike events (Fang et al., 2021) into 30 time steps, and we
reduce the spatial resolution into 48 × 48 by interpolation. We apply the random crop augmentation
as CIFAR-10 to the input data. We leverage the network structure: 512C9s (F512C5), where the
notations follow Appendix D.3. We train the model by SGD with momentum for 70 epochs. The
momentum is 0.9, the batch size is 128, the weight-decay is 5 × 10-4, and the initial learning rate is
0.05 which is decayed by 0.1 at the 50th epoch. No dropout is applied. The initialization of weights
follows the widely used Kaiming initialization. The constant for restriction in Appendix D.2 is
c = 10 due to the large channel size, and the scale for the loss function as well as the firing thresholds
and resting potentials are the same as the CIFAR-10 experiment.
Table 5: Performance on CIFAR10-DVS.
Method	Model	TF	TB	Accuracy
Gabor-SNN (Sironi et al., 2018)	Gabor-SNN	/	/	24.5%
HATS (Sironi et al., 2018)	HATS	/	/	52.4%
STBP (Wu et al., 2019)	Spiking CNN (LIF, w/o NeuNorm)	40	/	58.1%
STBP (Wu et al., 2019)	Spiking CNN (LIF, w/ NeuNorm)	40	/	60.5%
Tandem Learning (Wu et al., 2021)	Spiking CNN (IF)	20	/	58.65%
Spike-based BP (Fang et al., 2021)	Spiking CNN (PLIF, w/ BN)	20	/	74.8%
SPIDE (ours)	Spiking CNN (IF)	30	250	60.7%
As shown in Table 5, our model could achieve 60.7% accuracy, which is competitive among re-
sults of common SNN models, demonstrating the effectiveness of our method. Fang et al. (2021)
leverages many techniques such as learnable membrane time constant, batch normalization, and
max pooling to achieve better performance. We do not aim at outperforming the state-of-the-art
results, but demonstrate that a competitive performance could be achieved even with our constraints
of purely spike-based training in a relatively small number of time steps, verifying the effectiveness.
22