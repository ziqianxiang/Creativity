Under review as a conference paper at ICLR 2022
Non-convex Optimization for Learning a Fair
Predictor under Equalized Loss Fairness Con-
STRAINT
Anonymous authors
Paper under double-blind review
Ab stract
Supervised learning models have been increasingly used in various domains such
as lending, college admission, natural language processing, face recognition, etc.
These models may inherit pre-existing biases from training datasets and exhibit
discrimination against protected social groups. Various fairness notions have been
introduced to address fairness issues. In general, finding a fair predictor leads to
a constrained optimization problem, and depending on the fairness notion, it may
be non-convex. In this work, we focus on Equalized Loss (EL), a fairness notion
that requires the prediction error/loss to be equalized across different demographic
groups. Imposing this constraint to the learning process leads to a non-convex op-
timization problem even if the loss function is convex. We introduce algorithms
that can leverage off-the-shelf convex programming tools and efficiently find the
global optimum of this non-convex problem. In particular, we first propose the
ELminimizer algorithm, which finds the optimal EL fair predictor by reducing
the non-convex optimization problem to a sequence of convex constrained opti-
mizations. We then propose a simple algorithm that is computationally more effi-
cient compared to ELminimizer and finds a sub-optimal EL fair predictor using
unconstrained convex programming tools. Experiments on real-world data show
the effectiveness of our algorithms.
1 Introduction
As machine learning (ML) algorithms are increasingly being used in applications such as education,
lending, recruitment, healthcare, criminal justice, etc., there is a growing concern that the algorithms
may exhibit discrimination against protected population groups. For example, speech recognition
products such as Google Home and Amazon Alexa were shown to have accent bias (Harwell, 2018).
The COMPAS recidivism prediction tool, used by courts in the US in parole decisions, has been
shown to have a substantially higher false positive rate for African Americans compared to the
general population (Dressel & Farid, 2018). Amazon had been using automated software since 2014
to assess applicants’ resumes, which were found to be biased against women (Dastin, 2018).
Various fairness notions have been proposed in the literature to measure and remedy the biases in
ML systems; they can be roughly classified into two classes: 1) individual fairness focuses on the
equity at individual level and it requires the similar individuals to be treated similarly (Dwork et al.,
2012; Biega et al., 2018; Jung et al., 2019; Gupta & Kamble, 2019); 2) group fairness requires
certain statistical measures to be (approximately) equalized across different groups distinguished by
some sensitive attributes. Their suitability for use is often application dependent, and many of them
are incompatible with each other (Zhang et al., 2019; Hardt et al., 2016; Conitzer et al., 2019; Zhang
et al., 2020; Khalili et al., 2020). Extensive approaches have been developed to satisfying a given
definition of fairness and they generally fall under three categories: pre-processing, by modifying
the original dataset such as removing certain features and reweighing, e.g., (Kamiran & Calders,
2012; Celis et al., 2020); in-processing, by modifying the algorithms such as imposing fairness
constraints or changing objective functions, e.g., (Zhang et al., 2018; Agarwal et al., 2018; 2019;
Reimers et al., 2021; Calmon et al., 2017); post-processing, by adjusting the output of the algorithms
based on sensitive attributes, e.g., (Hardt et al., 2016).
1
Under review as a conference paper at ICLR 2022
In this paper, we focus on group fairness and we aim to mitigate unfairness issues in supervised
learning using in-processing approaches. The problem can be cast as a constrained optimization
problem where a fair predictor can be found by minimizing the prediction error (i.e., loss) subject to
certain group fairness constraint. In Section 2.1, we present a number of definitions of commonly
used group fairness notions, namely, statistical parity (Dwork et al., 2012), equal opportunity (Hardt
et al., 2016), equalized loss (Zhang et al., 2019), and bounded group loss (Agarwal et al., 2019).
Here we are particularly interested in equalized loss which requires the expected loss to be equalized
across different groups.
Constrained optimization problems for finding a fair predictor have been studied in the iterature. In
general, imposing a fairness criterion to the optimization problem may lead to a non-convex opti-
mization problem. Existing works have proposed various approaches to solving such a non-convex
optimization in different settings. For example, Komiyama et al. (2018) studied the non-convex op-
timization for regression problems under the coefficient of determination constraint. Agarwal et al.
(2019) proposed an approach to finding a fair regression model under bounded group loss and statis-
tical parity fairness constraints. Agarwal et al. (2018) studied classification problems and aimed at
finding fair classifiers under various fairness notions including statistical parity and equal opportu-
nity. In particular, they considered zero-one loss as the objective function and trained a randomized
fair classifier over a finite hypothesis space; this problem was reduced to a problem of finding the
saddle point of a linear Lagrangian function in (Agarwal et al., 2018). Zhang et al. (2018) proposed
an adversarial debasing technique to find a fair classifier under equalized odd, equal opportunity,
and statistical parity. However, there is no guarantee that this technique finds the global optimal
solution. The main difference between the present work and the existing in-processing approaches
are as follows: 1) we consider a non-convex problem for finding a fair predictor satisfying Equalized
Loss fairness notion, which has not been studied in the literature to the best of our knowledge. 2) We
propose algorithms for finding the global optimal solution to this non-convex problem efficiently.
3) Our algorithms are easy to implement and are applicable to both regression and classification
problems. 4) Unlike (Agarwal et al., 2018), our algorithms are not limited to finite hypothesis space.
Non-convex optimization problems have also been studied in other contexts such as learning over-
parametrized models. For example, deep neural networks are typically trained by solving uncon-
strained, non-convex problems, and methods such as gradient descent may not be suitable as they
are likely to find saddle points but not optimums. To address this issue, approaches have been pro-
posed in recent works by incorporating the higher order derivatives (Celis et al., 2020; Anandkumar
& Ge, 2016) or noisy gradients (Ge et al., 2015). However, these methods only find a local minimum
(not a global minimum) and are not applicable to our problem with a non-convex constraint.
In this work, we develop novel algorithms that find the fair (sub-)optimal solutions under Equalized
Loss fairness constraint efficiently. Note that while our approach and algorithms are presented in
the context of fair machine learning, they are applicable to any problem that can be formulated as a
constrained optimization problem in the form of minw L0 (w) +αL1(w) s.t. |L0(w) - L1(w)| < γ,
where α is a constant
Our main contributions and findings are as follows.
1.	We study the relationship between Equalized Loss (EL) and Bounded Group Loss (BGL) fairness
notions. We show that given the existence of feasible solutions satisfying (approximate) BGL
fairness, imposing (approximate) EL fairness constraint never increase losses of both groups
simultaneously (Theorems 1 and 2 in Section 2.1). These results help policy makers to have a
better understanding of these two fairness notions.
2.	We develop an algorithm (ELminimizer) to solve a non-convex constrained optimization prob-
lem that finds the optimal (approximate) EL fair solution. We show that such non-convex opti-
mization can be reduced to a sequence of convex constrained optimizations and the convergence
property of the algorithm is analyzed (Theorems 3 and 4, Section 3).
3.	We develop a simple algorithm for finding a sub-optimal (approximate) EL fair solution. We
show that a sub-optimal solution is a linear combination of optimal solutions to two uncon-
strained optimizations and it can be found efficiently without solving constrained optimizations
(Theorem 5, Section 4).
4.	We conduct sample complexity analysis and provide the guarantee on generalization performance
(Theorem 7, Section 5).
5.	We validate the theoretical results by conducting experiments on real-world data (Section 6).
2
Under review as a conference paper at ICLR 2022
2	Problem Formulation
Consider a supervised learning problem where the training dataset consists of triples (X, A, Y )
from two social groups. Random variable X ∈ X ⊂ Rdx is the feature vector (in form of a column
vector), A ∈ {0, 1} is the sensitive attribute (e.g., race, gender) indicating the group membership,
and Y ∈ Y ⊂ R is the label. The feature vector X may or may not include sensitive attribute
A. Label Y can be either discrete or continuous depending on the given problem: if Y is discrete
(resp. continuous), then the problem is a classification (resp. regression) problem. Let F be a set
of predictors fw : X → R parameterized by weight vector w ∈ Rdw .1 Consider loss function l :
Y × X → R where l(Y, fw(X)) measures the error of fw in predicting label Y . Denote the expected
loss with respect to the joint probability distribution of (X, Y ) by L(w) := E{l(Y, fw(X))}. Then,
La(w) := E{l(Y, fw(X))|A = a} denotes the expected loss of the group with attribute A = a.
A predictor that minimizes the total expected loss, i.e., arg minw L(w), can be biased against certain
groups. To mitigate the risk of unfairness, various fairness notions have been proposed in the litera-
ture. Some of the most commonly used notions of group fairness are as follows: 1) Statistical Parity
(SP) (Dwork et al., 2012) implies that the predictor and the sensitive attribute should be indepen-
dent, i.e., fw(X) ⊥ A; 2) Equal Opportunity (EqOpt) (Hardt et al., 2016) requires that conditional
on Y = 1, prediction and sensitive attribute are independent, i.e., fw(X) ⊥ A|Y = 1; 3) Equalized
Odds (EO) (Hardt et al., 2016) requires the conditional independence between prediction and sen-
sitive attribute given Y , i.e., fw(X) ⊥ A|Y ; 4) Equalized Loss (EL) (Zhang et al., 2019; Berk et al.,
2021) requires that the losses experienced by different groups are equalized, i.e., L0 (w) = L1 (w);
5) Bounded Group Loss (BGL) (Agarwal et al., 2019) requires that the loss experienced by each
group is bounded.
With fairness consideration, the goal is to find weight vector w that minimizes total expected loss in
predicting Y given X, subject to certain fairness condition, i.e., minw L(w) s.t. fairness constraint.
This is a typical formulation in fair machine learning literature, and above method of finding a fair
predictor belongs to in-processing approaches. Because such constrained optimization can be non-
convex, finding the optimal solution efficiently can be challenging. In this work, we develop novel
algorithms that solves such an optimization problem udder EL fairness constraint.
2.1	EQUALIZED LOSS (EL) AND BOUNDED GROUP LOSS (BGL)
As mentioned in Section 2, various fairness notions have been introduced in the literature. Among
them, Statistical Parity (SP), Equal Opportunity (EqOpt), Equalized Odds (EO), and Bounded
Group Loss (BGL) have been studied extensively in the literature, and both in-processing and post-
processing approaches have been developed to satisfy these constraints (Dwork et al., 2012; Agarwal
et al., 2018; Hardt et al., 2016; Zafar et al., 2019; Fitzsimons et al., 2019). Note that different fairness
notions may be conflict with each other and which one to adopt is application and context dependent.
In this work, we are interested in Equalized Loss (EL) fairness notion (Zhang et al., 2019; Berk et al.,
2021) which implies that the prediction error should be the same across different groups,1 2 and Group
Bounded Loss (BGL) fairness notion (Agarwal et al., 2019) which requires the prediction error of
every group to be bounded. We consider a relaxed version of EL fairness defined as follows.
Definition 1 (γ-EL) A predictor f satisfies γ-EL if the expected losses experienced by different
demographic groups satisfy the following,
-γ ≤ L0 (w) - L1 (w) ≤ γ.	(1)
Parameter γ controls the degree of fairness; the smaller γ implies the stronger fairness. When γ = 0,
the exact EL fairness is attained. We say a group is disadvantaged if it experiences a larger loss.
Similarly, Group Bounded Loss (BGL) fairness notion is formally defined as follows.
Definition 2 (γ-BGL) A predictor f satisfies γ-BGL if the expected loss of each demographic group
is bounded by γ, i.e.,
La(W) ≤ Y, ∀a ∈ {0,1}.	(2)
1Predictive models such as logistic regression, linear regression, deep learning models, etc., are parameter-
ized by a weight vector.
2EL has also been referred to as Overall Accuracy Equality in (Berk et al., 2021; Agarwal et al., 2019).
3
Under review as a conference paper at ICLR 2022
2.2 RELATIONS BETWEEN γ-EL AND γ-BGL
In this section, we formally study the relations between γ-EL and γ-BGL fairness notions. Under
γ-EL fairness constraint, finding a fair predictor is equivalent to solving the following constrained
optimization problem:
minw L(w) s.t. |L0(w) - L1(w)| ≤ γ.	(3)
Let w* be denoted as the solution to (3) and fw* is the optimal Y-EL fair predictor. Theorem 1 below
shows that given the existence ofa feasible point satisfying γ-BGL fairness, it’s impossible for both
groups experiencing loss larger than γ from the optimal γ-EL fair predictor.
Theorem 1	Consider the following optimization for finding the optimal γ-BGL fair predictor,
minw L(w) s.t. La (w) ≤ γ, ∀a ∈ {0, 1}.	(4)
If L0(w*) > γ and L1(w*) > γ, then optimization problem (4) does not have a feasible point.
Proof 1 We prove by contradiction. Assume W is a feasible point of optimization (4). Note that W
is a feasible point for optimization problem (3) as well. Since both L0(w*) and L1(w*) are larger
than γ, we have,
E{l(Y, fw*)} = Pr{A = 0}L0(W*) + Pr{A = 1}L1(W*) >γ,
E{l(Y,fw)} = Pr{A = 0}Lo(W)+Pr{A =1}Lι(W) ≤ γ.
Therefore, W* can not be the solution to (3). This contradiction proves that the optimization problem
(4) cannot have a feasible point.
Theorem 1 implies that if γ-EL notion leads to an increase of the loss of every demographic group,
then there is no optimal predictor under γ-BGL.3 The next theorem further shows that for any pre-
dictor satisfying γ-EL, it must satisfy 2γ-BGL.
Theorem 2	Assume optimization problem (4) has at least one feasible point. Then, we have,
min{L0 (W*), L1(W*)} ≤ γ and max{L0(W*), L1(W*)} ≤ 2γ.
Proof 2 Let W be afeasible point ofoptimization problem (4) ,then W is also afeasible point to (3). If
min{Lo(w*), Lι(w*)} > Y, then L(w*) > γ ≥ L(W) must hold. This is a contradiction because it
implies that W* is not an optimal solution to (3). Therefore, min{L0 (W*), L1(W*)} ≤ γ. Similarly,
we can prove max{L0(W*), L1(W*)} ≤ 2Y by contradiction. Assume max{L0 (W*), L1(W*)} >
2Y. Then, max{L0(W*), L1(W*)} - min{L0(W*), L1(W*)} > Y which shows that W* is not a
feasible point for (3). This is a contradiction. Therefore, max{L0(W*), L1(W*)} ≤ 2Y.
Theorems 1 and 2 investigated the relations between EL and BGL fairness notions. Since Y-EL
implies 2Y-BGL and it additionally requires the approximate equality across different groups, we
will focus on Y-EL fairness notion in the rest of the paper. Because optimization problem (3) is a
non-convex optimization, finding the optimal fair Y-EL solution efficiently can be challenging. In
the next sections, we propose a number of algorithms that are easy to implement and can solve the
optimization (3) efficiently.
3	OPTIMAL FAIR MODEL UNDER EL FAIRNESS
In this section, we consider the optimization problem (3) under the EL fairness constraint. Note
that this optimization problem is non-convex and finding the global optimal solution is difficult.
However, we propose an algorithm which is able to find the solution to non-convex optimization (3)
by solving a sequence of convex optimization problems. Before presenting the algorithm, we need
to introduce two assumptions.
Assumption 1 L0 (W), L1 (W), and L(W) are strictly convex functions in W.
3Theorem 1 is related to (Agarwal et al., 2019). In particular, they considered γ-BGL fairness and mentioned
that the equalized loss fairness notion may increase the loss of both groups.
4
Under review as a conference paper at ICLR 2022
Algorithm 1: Function ELminimizer
1	ELminimizer(wG0, wG1 , , γ):
2	λs0tart = L0(wG0)
3	λe0nd = L0(wG1)
4	Define L1(w) = L1(w) + Y
5	i=0
6	while λ(ein)d - λ(sit)art > do
λ(i)	(λ(i) + λ(i) )/2
7	λmid = (λend + λstart) / * 1 2 3 4 5 6 7 8
8	Solve the following convex optimization problem,
w↑ = arg min Lι(w) s.t. L0(w) ≤ ^^
wm
(5)
9
10
11
12
13
14
15
16
17
18
λ⑴=L ι(w力
if λ(i) ≥ λ(mi)id then
λ(i+1)	λ(i)	λ(i+1)	λ(i)
start = mid;	end = end;
end
else
(i+1)	(i)	(i+1)	(i)
λend = λmid; λstart = λstart;
end
i=i+1;
end
Return w*
Example 1 Consider a linear classifier fw(X) = wTX with squared loss l(Y, fw(X)) = (wTX -
Y )2. In this example, E{l(Y, fw (X))} = wTE{XXT}w - 2E{Y XT}w + E{Y 2} is strictly
convex in w if covariance matrix E{XXT} is positive definite. Similarly, La(w) is strictly convex
if E{XXT |A = a} is positive definite.
Let wGa be the weight vector minimizing the loss associated with group A = a. That is,
wGa = arg min La(w).	(6)
w
Since optimization problem (6) is an unconstrained convex optimization problem, wGa can be found
efficiently by the first order condition or the gradient descent. We make the following assumption.
Assumption 2 We assume that the following holds,
L0(wG0) ≤ L1(wG0) and L1(wG1) ≤ L0(wG1).
Algorithm 2: Solving Optimization Problem (3)
Input： WGo, WGι ,e,Y
1 wγ = ELminimizer(wG0 , wG1 , , γ);
2 w-γ = ELminimizer(wG0 , wG1 , , -γ);
3 if L(wγ) ≤ L(w-γ) then
4 I w* = WY ；
5 end
6 else
7 I W* = W-γ ；
8 end
Output: w*
Assumption 2 implies that when a group ex-
periences its lowest possible loss, it should
not be the disadvantaged group. Under
Assumption 2, given wG0 and wG1 , Al-
gorithm 1 with γ = 0 (i.e., function
ELminimizer(wG0 , wG1 , , 0)) finds the
optimal 0-EL fair solution, where parame-
ter > 0 specifies the stopping criterion; as
→ 0, the output approaches to the opti-
mal solution. Intuitively, Algorithm 1 solves
non-convex optimization (3) by solving a se-
quence of convex and constrained optimiza-
tion problems. If γ > 0, Algorithm 2 finds
the optimal predictor under γ-EL using func-
tion ELminimizer.
The convergence of Algorithm 1 for finding the optimal 0-EL fair solution, and convergence of
Algorithm 2 for finding the optimal γ-EL fair solution are proved in the following theorems.
5
Under review as a conference paper at ICLR 2022
Theorem 3 Consider sequences {λmid|i = 1,2,...} and {w* |i = 1,2,...} generated by Algo-
rithm 1 when γ = 0, i.e., ELminimizer(wG0, wG1 , → 0, 0). Under Assumptions 1 and 2, we
have,
lim Wi = w* and lim λfid = E{L(Y,笳* (X))}
i→∞	i→∞
where fw* is the optimal 0-EL fair predictor.
Similarly, we can prove the convergence for the approximate EL fairness when γ 6= 0.
Theorem 4 Assume that L0(wG0) - L1(wG0) < -γ and L0(wG1 ) - L1 (wG1 ) > γ. Then, as
→ 0, the output of Algorithm 2 goes to the optimal γ-EL fair solution w*.
Complexity Analysis: The While loop in Algorithm 1 is executed for O(log(1/)) times. There-
fore, Algorithm 1 needs to solve a constrained convex optimization problem for O(log(1/)) times.
Note that constrained convex optimization problems can be efficiently solved via sub-gradient meth-
ods (Nedic & Ozdaglar, 2009), brier methods (Wright, 2001), stochastic gradient descent with one
projection (Mahdavi et al., 2012), etc. For instance, Nedic & Ozdaglar (2009) introduces a SUb-
gradient method that finds the saddle point of the Lagrangian function corresponding to (5) and it
converges at the rate of O(1/k) (k is the number of iterations). Therefore, if is the maximum error
tolerance for (5), the total time complexity of Algorithm 2 is O(1/ log(1/)).
4	SUB-OPTIMAL FAIR MODEL UNDER γ-EL
In Section 3, we have shown that non-convex optimization problem (3) can be reduced to a sequence
of convex constrained optimizations (5), and based on this we proposed an algorithm (Algorithm 2)
that finds the optimal γ-EL fair predictor. However, the proposed algorithm still requires solving
a convex constrained optimization in each iteration. In this section, we propose another algorithm
which finds a sub-optimal solution to optimization (3) without solving constrained optimization in
each iteration.
The algorithm consists of two phases in sequence: (1) finding two weight vectors by solving two
unconstrained convex optimization problems; (2) generating a new weight vector satisfying γ-EL
fairness with the two weight vectors found in the first phase. Because of the convexity, two uncon-
strained convex optimization problems in the first phase can be solved efficiently.
Phase 1: Unconstrained optimization. In this phase, we remove EL fairness constraint and first
solve the following uncontrained optimization problem,
wO = arg min L(w)	(7)
w
Because L(w) is strictly convex in w, the above optimization problem can be solved efficiently using
the gradient descent method. Predictor fwO is the optimal predictor without fairness constraint, and
L(WO) is the smallest overall expected loss that is attainable. Let ^ = arg maxα∈{o,i} La(WO), i.e.,
group a is the group that is disadvantaged under predictor fω0. Then, for the disadvantaged group
^, We find wg^ by solving unconstrained optimization problem (6).
Phase 2: Binary search to find the fair predictor. For β ∈ [0, 1], we define the followings,
g(β) = La ((1 - β)wO + βwGa) - Li-a((1 - β )wO + βwg^);
h(β) = L((1 - β)wO + βWGa),
where function g(β ) can be interpreted as loss disparity between two demographic group under
predictor f(1-β)wO+βwG , and h(β) is the corresponding overall expected loss. Some properties of
functions g(.) and h(.) are summarized in the following theorem.
Theorem 5 Under Assumptions 1 and 2, the followings hold,
1.	There exists β0 ∈ [0, 1] such that g(β0) = 0.
2.	h(β) is strictly increasing in β ∈ [0, 1]; g(β) is strictly decreasing in β ∈ [0, 1].
6
Under review as a conference paper at ICLR 2022
Theorem 5 implies that in a dw dimensional space, if We start from WO and move toward wg^ along
a straight line, the overall loss increases and the disparity between two groups decreases until we
reach(1 - βo)wO + βoWG^, at which 0-EL fairness is satisfied. Note that βo is the unique root
of g. Since g(β) is a strictly decreasing function, β0 can be found using binary search. For the
approximate γ-EL fairness, there are multiple values of β such that (1 - β)wO + βwG^ satisfies Y-
EL. Since h(β) is strictly increasing in β, among all β that satisfies γ-EL fairness, we would choose
the smallest one. The method for finding a sub-optimal solution to optimization (3) is described in
Algorithm 3.
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
Algorithm 3: Sub-optimal solution to optimization problem (3)
Input: Wg^ , wO, e, Y
Initialization: gγ (β) = g(β) - γ, i = 0, βs(0ta)rt = 0, βe(0n)d = 1
if gγ (0) ≤ 0 then
I w = wO, and go to line 16;
end
while βe(in)d - βs(it)art > do
βmid =Mart + β(n)d)∕2;
ifgγ(βm(i)id) ≥ 0 then
I /o(i+1) — R(i) /o(i+1)—仅⑶.
I βstart = βmid, βend = βend;
end
else
I β(i+1) = e(i)	β(* i+I) = β(i).
βstart = βstart , βend = βmid;
end
end
w=(I - βmid)wO+βmidwGa;
Output: w
Note that while loop in Algorithm 3 is repeated for O(log(1∕)) times. Since the time complexity
of operations in each loop is O(1), the total time complexity of Algorithm 3 is O(log(1∕)). We can
formally prove that the output returned by Algorithm 3 satisfies Y-EL fairness constraint.
Theorem 6 Assume that Assumption 1 holds. If gγ (0) ≤ 0, then wO satisfies the Y-EL fairness; if
gγ(0) > 0, then limi→∞ ①^^ = β∖∞ exists, and (1 - βm∞))wO + βm∞d))wG^ Satisfies the Y-EL
fairness constraint.
It is worth mentioning, since h(β) is incrasing, we are intrested in finding the smallest possible β
that (1 - β)wO + βwG^ satisfies γ-EL. Here, β((∞d is the smallest possible β under which (1 -
β)wO + βwG^ satisfies γ-EL.
5 Generalization Performance
So far we proposed algorithms for solving optimization (3). In practice, the joint probability distribu-
tion of (X, A, Y ) is often unknown and the expected loss needs to be estimated using the empirical
loss. Specifically, given n samples (Xi, Ai, Yi), i = 1, . . . , n and predictor fw, the empirical losses
of entire population and each group are defined as follows,
1n	1
L(W) = nEl(K,fw(χi)); La(W) = n E i(γi,fw(χ/,
i=1	a i:Ai =a
(8)
where na = |{i|Ai = a}|. Because Y-EL fairness constraint is defined in terms of expected loss, the
optimization problem of finding an optimal Y-EL fair predictor using empirical losses is as follows,
W = arg min L(W) s.t. ∣Lo(w) — Lι(w)∣ ≤ γ.	(9)
Note that γ = Y and one goal in this section is to find relation between Y and γ. We aim to investigate
how to determine Y so that with high probability the predictor found by solving problem (9) satisfies
7
Under review as a conference paper at ICLR 2022
Y-EL fairness, and meanwhile W is a good estimate of w*. To present our result, We make the
following assumption.
Assumption 3 With probability 1 - δ, we have the following,
sup |L(w) — L(w)∣ ≤ B(δ,n, F),
fw ∈F
where B(δ, n, F) is a bound that goes to zero as n goes to infinity.
Note that if the class F is learnable with respect to loss function l, then there exists such a bound
B(δ, n, F) that goes to zero as n goes to infinity (Shalev-Shwartz & Ben-David, 2014).4
Theorem 7 Let F be a set of learnable functions, and let fw^ and fw* be the solution to (9) and
(3) respectively with Y = Y + 52a∈{o i} B(δ,na, F). Then, with probability at least 1 — 6δ the
followings hold,
L(W) — L(w*) ≤ 2B(δ, n, F) and ∣Lo(W) — Lι(W)∣ ≤ Y + 2B(δ, n0, F) + 2B(δ, nι, F).
Theorem 7 shows that as no, nι go to infinity, Y → Y, and both empirical loss and expected loss
satisfy Y-EL. In addition, as n goes to infinity, the expected loss at W goes to the minimum possible
expected loss. Therefore, solving (9) using empirical loss is equivalent to solving (3) if the number
of data points from each group is sufficiently large.
6	Experiments
6.1	Experiment 1: Quadratic Functions
First, we solve optimization problem (3) given the following quadratic functions,
Lo(w)	=	(wι	+ 5)2 + (w2 + 2)2 +	(w3	+ 1)2 +	4wι ∙ w3,
Lι(w)	=	(wι	- 9)2 + (w2 — 9)2 +	(w3	— 9)2 +	wι ∙ w2 + w2	∙ w3 +	wι	∙ w3	+ 1,
L(W) = L0(W) + L1(W).
By the first order condition, we obtain WG0, WG1 ,WO as follows,
WG0 = [1, —2, —3]T, WG1 = [4.5, 4.5, 4.5]T, WO = [24.53, 3.0, 26.53]T
We use Algorithm 1 to find the optimal solution to (3) and run Algorithm 3 to find a sub-optimal so-
lution. In particular, we adopt the penalty method (Ben-Tal & Zibulevsky, 1997) to solve constrained
convex optimization (5), i.e., by solving the following unconstrained optimization,
minLι(w) +1 ∙ max{0, (Lo(w)—1^^)}2,
w
(10)
where t is the penalty parameter. We solve the optimization problem (10) using gradient descent
with learning rate 0.001 and 10000 iterations. We set penalty parameter t = 0.5 and increase t by
0.1 after every 250 iterations. Note that optimization (5) is convex and the penalty method for a
constrained convex optimization converges to the optimal solution (Ben-Tal & Zibulevsky, 1997).
We compare the our algorithms with a baseline: the solution to optimization problem (3) found
using the penalty method, i.e., by solving the following unconstrained optimization,
minLo(w) + Lι(w) +1 ∙ [max{0, (L0(w) — Lι(w) — y)}2 + max{0, (LI(W) — Lo(w) — Y)}2].
w	(11)
When solving the optimization problem (11), we use learning rate 0.001. We set penalty parameter
t = 0.5 and increase it by 0.1 every 250 iterations. Figure 1a illustrates the overall loss L(W) at the
(sub-) optimal points obtained from Algorithms 2 and 3 and the baseline. x-axis represents fairness
parameter Y. Since Algorithm 2 converges to the optimal solution, it achieves the smallest loss.
Figure 1b illustrates the distance of the optimal point W* from the sub-optimal solutions obtained
by Algorithm 3 and the baseline penalty method. It shows that when Y is sufficiently large (less
strict fairness constraint), a sub-optimal solution generated by Algorithm 3 is closer to the optimal
solution than the solution found using the baseline method.
4As an example, if F is a compact subset of linear predictors in Reproducing Kernel Hilbert Space (RKHS)
and loss l(y, f (x)) is Lipschitz in f (x) (second argument), then Assumption 3 can be satisfied (Bartlett &
Mendelson, 2002). Vast majority of linear predictors such as support vector machine and logistic regression
can be defined in RKHS.
8
Under review as a conference paper at ICLR 2022
(a)	(b)	(c)	(d)
Figure 1: a) Experiment 1: loss as a function of fairness parameter γ. Algorithm 2 and Algorithm
3 significantly improve the loss compared to the baseline. b) Experiment 1: distance between the
sub-optimal solution and the optimal solution. Algorithm 3 generates a sub-optimal solution closer
to the optimal solution compared to the baseline. c) Experiment 2: loss as a function of fairness
parameter γ. Both Algorithm 2 and Algorithm 3 outperform the baseline. d) Experiment 2: distance
between the sub-optimal solution and the optimal solution.
6.2	Experiment 2: Logistic Regression and The Adult Income Dataset
The adult income dataset is a public dataset containing the information of 48,842 individuals (Ko-
havi, 1996). Each data point includes 14 features including age, education, race, etc. Consider race
(White or Black) as the sensitive attribute, we denote White demographic group by A = 0 and Black
group by A = 1.
We first pre-process the dataset by removing the data points with a missing value or with the race
other than Black and White and obtain 41,961 data points. Among these data points, 4585 belong
to Black demographic group. For each data point, we convert all the categorical features to one-hot
vectors and result in dx = 110 dimensional features. We then normalize the feature vectors such
that they have zero mean value and unit variance. Our goal is to find a logistic regression model
satisfying γ-EL to predict whether the income of an individual is above $50K or not.
We use Algorithm 2 and Algorithm 3 with = 0.01 to find the optimal logistic regression model
under EL. We use the penalty method described in equation (11) as the baseline. Similar to Experi-
ment 1, we set learning rate as 0.001 for solving (10) and (11). Penalty parameter t is set to be 0.5
and increases by 0.1 every 250 iterations. Figure 1c illustrates the loss of logistic regression model
trained by Algorithm 2, Algorithm 3, and the baseline. It shows that Algorithm 2 outperforms the
baseline; this is because that the baseline only finds a sub-optimal solution while Algorithm 2 finds
the global optimal solution. As mentioned in Section 4, Algorithm 3 finds a sub-optimal solution
that satisfies γ-EL, and its performance can vary from case to case. Even though Algorithm 3 has a
good performance in Experiment 1, it does not outperform the baseline in Experiment 2. Figure 1d
illustrates the distances from the optimal point w* to the sub-optimal solutions obtained by Algo-
rithm 3 and the baseline penalty method. It shows that the distance from w* to the solution obtained
under Algorithm 3 is slightly larger than that from w* to the solution obtained under the baseline.
7	Conclusion
In this work, we studied the problem of fair supervised learning under the Equalized Loss (EL)
fairness notion which requires the prediction error/loss to be the same across different demographic
groups. By imposing EL constraint, the learning problem can be formulated as a non-convex op-
timization problem. We introduce a number of algorithms that find the global optimal solution to
this non-convex optimization problem. In particular, we showed that the optimal solution to such
a non-convex problem can be found by solving a sequence of convex constrained optimizations.
We also introduced a simple algorithm for finding a sub-optimal solution to the non-convex problem
without solving constrained convex optimization problems. In addition to the theoretical guarantees,
we demonstrated the performance of the proposed algorithm through numerical experiments.
9
Under review as a conference paper at ICLR 2022
8	Reproducibility Statement
Regarding the theoretical results: This paper includes six Theorems. The proof of Theorem 1 and
Theorem 2 have been provided in the main text. Due to the page limit, the proofs of the other
theorems have been provided in the appendix.
Regarding the numerical examples: the first experiment does not use any dataset, and we study
the performance of our proposed method on quadratic objective functions. The values for hyper-
parameters (including learning and penalty parameter) have been explicitly mentioned in section 6.
In the second numerical example, we used the adult income dataset which is a well-known public
dataset in our community. We explained the data pre-processing procedure in Section 6.2 in details.
9	Ethics Statement
In this work, we proposed algorithms to find fair predictors under the EL fairness notion. We want
to emphasize that selecting a right fairness notion depends on the application and the authors do not
make any suggestions to policy/law makers about choosing or avoiding this fairness notion.
References
Alekh Agarwal, Alina Beygelzimer, Miroslav Dudik, John Langford, and Hanna Wallach. A re-
ductions approach to fair classification. In International Conference on Machine Learning, pp.
60-69. PMLR, 2018.
Alekh Agarwal, Miroslav Dudik, and Zhiwei Steven Wu. Fair regression: Quantitative definitions
and reduction-based algorithms. In International Conference on Machine Learning, pp. 120-129.
PMLR, 2019.
Animashree Anandkumar and Rong Ge. Efficient approaches for escaping higher order saddle points
in non-convex optimization. In Conference on learning theory, pp. 81-102. PMLR, 2016.
Peter L Bartlett and Shahar Mendelson. Rademacher and gaussian complexities: Risk bounds and
structural results. Journal of Machine Learning Research, 3(Nov):463-482, 2002.
Aharon Ben-Tal and Michael Zibulevsky. Penalty/barrier multiplier methods for convex program-
ming problems. SIAM Journal on Optimization, 7(2):347-366, 1997.
Richard Berk, Hoda Heidari, Shahin Jabbari, Michael Kearns, and Aaron Roth. Fairness in criminal
justice risk assessments: The state of the art. Sociological Methods & Research, 50(1):3-44,
2021.
Asia J Biega, Krishna P Gummadi, and Gerhard Weikum. Equity of attention: Amortizing individual
fairness in rankings. In The 41st international acm sigir conference on research & development
in information retrieval, pp. 405-414, 2018.
Flavio P Calmon, Dennis Wei, Bhanukiran Vinzamuri, Karthikeyan Natesan Ramamurthy, and
Kush R Varshney. Optimized pre-processing for discrimination prevention. In Proceedings of
the 31st International Conference on Neural Information Processing Systems, pp. 3995-4004,
2017.
L Elisa Celis, Vijay Keswani, and Nisheeth Vishnoi. Data preprocessing to mitigate bias: A maxi-
mum entropy based approach. In International Conference on Machine Learning, pp. 1349-1359.
PMLR, 2020.
Vincent Conitzer, Rupert Freeman, Nisarg Shah, and Jennifer Wortman Vaughan. Group fairness
for the allocation of indivisible goods. In Proceedings of the AAAI Conference on Artificial Intel-
ligence, volume 33, pp. 1853-1860, 2019.
Jeffrey Dastin. Amazon scraps secret ai recruiting tool that showed bias against women. http:
//reut.rs/2MXzkly, 2018.
10
Under review as a conference paper at ICLR 2022
Julia Dressel and Hany Farid. The accuracy, fairness, and limits of predicting recidivism. Science
advances, 4(1):eaao5580, 2018.
Cynthia Dwork, Moritz Hardt, Toniann Pitassi, Omer Reingold, and Richard Zemel. Fairness
through awareness. In Proceedings of the 3rd innovations in theoretical computer science confer-
ence, pp. 214-226, 2012.
Jack Fitzsimons, AbdulRahman Al Ali, Michael Osborne, and Stephen Roberts. A general frame-
work for fair regression. Entropy, 21(8):741, 2019.
Rong Ge, Furong Huang, Chi Jin, and Yang Yuan. Escaping from saddle points—online stochastic
gradient for tensor decomposition. In Conference on learning theory, pp. 797-842. PMLR, 2015.
Swati Gupta and Vijay Kamble. Individual fairness in hindsight. In Proceedings of the 2019 ACM
Conference on Economics and Computation, pp. 805-806, 2019.
Moritz Hardt, Eric Price, and Nati Srebro. Equality of opportunity in supervised learning. Advances
in neural information processing systems, 29:3315-3323, 2016.
Drew Harwell. The accent gap. http://wapo.st/3pUqZ0S, 2018.
Christopher Jung, Michael Kearns, Seth Neel, Aaron Roth, Logan Stapleton, and Zhiwei Steven Wu.
Eliciting and enforcing subjective individual fairness. arXiv preprint arXiv:1905.10660, 2019.
Faisal Kamiran and Toon Calders. Data preprocessing techniques for classification without discrim-
ination. Knowledge and Information Systems, 33(1):1-33, 2012.
Mohammad Mahdi Khalili, Xueru Zhang, Mahed Abroshan, and Somayeh Sojoudi. Improving
fairness and privacy in selection problems. arXiv preprint arXiv:2012.03812, 2020.
Ron Kohavi. Scaling up the accuracy of naive-bayes classifiers: A decision-tree hybrid. In Kdd,
volume 96, pp. 202-207, 1996.
Junpei Komiyama, Akiko Takeda, Junya Honda, and Hajime Shimao. Nonconvex optimization for
regression with fairness constraints. In International conference on machine learning, pp. 2737-
2746. PMLR, 2018.
Mehrdad Mahdavi, Tianbao Yang, Rong Jin, Shenghuo Zhu, and Jinfeng Yi. Stochastic gradient
descent with only one projection. Advances in neural information processing systems, 25:494-
502, 2012.
Angelia Nedic and AsUman Ozdaglar. SUbgradient methods for saddle-point problems. Journal of
optimization theory and applications, 142(1):205-228, 2009.
Christian Reimers, PaUl Bodesheim, Jakob RUnge, and Joachim Denzler. Towards learning
an Unbiased classifier from biased data via conditional adversarial debiasing. arXiv preprint
arXiv:2103.06179, 2021.
Shai Shalev-Shwartz and Shai Ben-David. Understanding machine learning: From theory to algo-
rithms. Cambridge University press, 2014.
Stephen J Wright. On the convergence of the newton/log-barrier method. Mathematical program-
ming, 90(1):71-100, 2001.
MUhammad Bilal Zafar, Isabel Valera, ManUel Gomez-RodrigUez, and Krishna P GUmmadi. Fair-
ness constraints: A flexible approach for fair classification. The Journal of Machine Learning
Research, 20(1):2737-2778, 2019.
Brian HU Zhang, Blake Lemoine, and Margaret Mitchell. Mitigating Unwanted biases with adver-
sarial learning. In Proceedings of the 2018 AAAI/ACM Conference on AI, Ethics, and Society, pp.
335-340, 2018.
XUerU Zhang, Mohammadmahdi Khaliligarekani, Cem Tekin, et al. GroUp retention when Using ma-
chine learning in seqUential decision making: the interplay between User dynamics and fairness.
Advances in Neural Information Processing Systems, 32:15269-15278, 2019.
XUerU Zhang, Mohammad Mahdi Khalili, and Mingyan LiU. Long-term impacts of fair machine
learning. Ergonomics in Design, 28(3):7-11, 2020.
11
Under review as a conference paper at ICLR 2022
Appendix
Proofs
In order to prove Theorem 3, we first introduce two lemmas.
Lemma 1 Under assumption 2, there exists W ∈ Rdw such that Lo(W) = Lι(w) = L(W) and
λS1a r ≤ L(W) ≤ λen)d.
Proof. Let h0(β) = L0((1 - β)WG0 + βWG1) and h1 (β) = L1((1 - β)WG0 + βWG1), and
h(β) = ho(β) - hι(β), β ∈ [0, l]. Note that RwLa(WGa) = 0 because WGa is the minimizer of
La(W). Moreover, VwLa(W) is positive semi-definit because La(.) is a strictly convex function.
First, we show that L0((1 - β)WG0 + βWG1 ) is an increasing function in β, and L1((1 - β)WG0 +
βWG1 ) is a decreasing function in β. Note that h00(0) = (WG1 - WG0 )TVwL0(WG0 ) = 0, and
h000(0) = (WG1 - WG0)T V2wL0(WG0)(WG1 -WG0) ≥ 0. This implies that h00(β) ≥ 0,∀β ∈ [0, 1].
Similarly, we can show that h01(β) ≤ 0, ∀β ∈ [0, 1].
Note that under Assumption (2), h(0) < 0 and h(1) > 0. Therefore, by the intermediate value
theorem, the exists β ∈ (0,1) such that h(β) = 0. Define W =(1 - B)wg° + Bwg「We have,
h(β) = 0 =⇒ Lo(w) = Lι(W) = L(W)	(12)
wgo is minimizer of Lo =⇒ L(W) = Lo(W) ≥ X*九	(13)
h0(β) ≥ 0,∀β ∈ [0,1] F ho(1) ≥ ho(β) F Sid ≥ Lo(W) = L(W)	(14)
Lemma 2 Lo(w* )=/诃,where w* is the solution to (5).
Proof. We proceed by contradiction. Assume that Lo(w*) < 入弋^. Since wg` is not in the feasible
set of (5), VwL1(Wi*) 6= 0. This is a contradiction because Wi* is an interior point of the feasible set
ofa convex optimization and cannot be optimal if VwL1(Wi*) is equal to zero.
Proof [Theorem 3]
Let Ii = [λ(sit)art, λ(ein)d] be a sequence of intervals. It is easy to see that Ii ⊇ I2 ⊇ •… and
λ(ein)d -λ(sit)art → 0 as i → ∞. Therefore, by the Nested Interval Theorem, ∩i∞=1Ii consists of exactly
one real number λ*, and both 1^^ and Wnd converge to λ*. Because Mid = λstart+λstart, Nid
also converges to λ*.
Now, we show that L(W*) ∈ Ii for all i. Note that L(W*) = Lo(W*) ≥ λ(s1ta)rt because WG0 is the
minimizer of Lo. Moreover, λ!nd ≥ L(w*) otherwise L(W) < L(w*) (W is defined in Lemma 1)
and W* is not optimal solution under 0-EL. Therefore, L(W*) ∈ I1.
Now we proceed by induction. Suppose L(W*) ∈ Ii. We show that L(W*) ∈ Ii+1 as well. We
consider two cases.
• L(W*) ≤ λ(mi)id. In this case W* is a feasible point for (5), and λ(i) ≤ L(W*) ≤ λ(mi)id.
Therefore, L(W*) ∈ Ii+1.
• L(W*) < λ(mi)id. In this case, we proceed by contradiction to show that λ(i) ≥ λ(mi)id .
Assume that λ(i) < λ(mi)id. Define g(β) = go(β) -g1(β), where gi (β) = Li((1 -β)WG0 +
βWi*). Note that λ(i) = g1(1) By Lemma 2, go(1) = λ(mi)id. Therefore, g(1) = λ(mi)id -
λ(i) > 0. Moreover, under Assumption 2, g(0) < 0. Therefore, by the intermediate value
theorem, there exists β ∈ (0,1) such that g(β) = 0. Similar to the proof of Lemma 1,
We can show that go(β) in an increasing function for all β ∈ [0,1]. As a result go(β) <
12
Under review as a conference paper at ICLR 2022
go(1) = λmid. Define W =(1 - Ie)WGO + βwi- We have,
go(β) = Lo(W) = Lι(W) = L(W) < λfid	(15)
L(w*) < λmid	(16)
The last two equations imply that w* is not an optimal fair solution under 0-EL fairness
constraint. This is a contradiction. Therefore, if L(w*) > 1^)^, then λ(i) ≥ ^2^. As a
result, L(W*) ∈ Ii+1
By two above cases and the nested interval theorem, we conclude that,
L(W*) ∈ ∩i∞=1Ii, lim λ(mi)id = L(W*)
i→∞
For the second part of the theorem, consider the following,
W*∞ = arg min L1(W)s.t., L0(W) ≤ λm∞id = L(W*)
w
lim Wi* = W*
∞
i→∞
In order to show that W*∞ is equal to W*, we proceed by contradiction. Suppose W*∞ 6= W*. As a
result, L1(W*∞) < L(W*). Define η(β) = η0(β) -η1(β), where ηi (β) = Li((1 - β)WG0 + βW*∞).
Note that L1(W*∞) = η1 (1). By Lemma 2, the condition in (5) is binding and η0(1) = L(W*).
Therefore, η(1) = L(W*) - L1(W*∞) > 0. Moreover, under Assumption 2, η(0) < 0. Therefore,
by the intermediate value theorem, there exists β ∈ (0,1) such that η(β) = 0. Similar to the
proof of Lemma 1, we can show that η0(β) is an increasing function for all β ∈ [0, 1]. As a result
ηo(β) < ηo(1) = L(w*). Define W = (1 一 β)wG0 + βw∞. We have,
no (β) = Lo(W) = Lι(W) = L(W) < L(w* )	(17)
The last equation implies that W* is not an optimal fair solution under 0-EL fairness constraint. This
a contradiction. As a result, w∞ = W.
Proof [Theorem 4 ]
Let W* be the optimal weight vector under γ-EL.
Step 1. we show that one of the following holds,
Lo(W*) 一 L1(W*) = γ	(18)
Lo(w*) — Li(w*) = -Y	(19)
Proof by contradiction. Assume —γ < Lo(w*) — Li(w*) < γ. This implies that w* is an inte-
rior point of the feasible set of optimization problem (3). Since w* = WO, then VL(w*) = 0.
As a result, object function of (3) can be improved at w* by moving toward -VL(w*). This a
contradiction. Therefore, |Lo(W*) — L1(W*)| = γ.
Step 2. Function Wγ = ELminimizer(WG0, WG0 , , γ) is the solution to the following optimiza-
tion problem,
min Pr{A = 0}Lo(W) + Pr{A = 1}L1 (W), s.t., Lo(W*) — L1 (W*) = γ	(20)
w
To show the above claim, notice that the solution to optimization problem (20) is the same as the
following,
mιnPr{A = 0}L0(w) + Pr{A = 1}Lι(w), s.t., L0(w*) — Li(w*) = 0,	(21)
where L1(W) = L1(W) + γ. Since Lo (WG0) — L1(WG0) < 0 and Lo(WG1) — L1(WG1) > 0, by
Theorem 3, we know that Wγ = ELminimizer(WG0, WG0 , , γ) find the solution to (21).
13
Under review as a conference paper at ICLR 2022
Lastly, because ∣L0(w*) - Lι(w*)∣ = Y, We have,
w* = W wY	if L(WY) ≤ L(W-Y)
w-γ	o.W.
Thus, Algorithm 2 finds the solution to (3).
Proof [Theorem 5]
(22)
1.	Under Assumption 2, g(1) < 0. Moreover, g(0) ≥ 0. Therefore, by the intermediate value
theorem, there exists β0 ∈ [0, 1] such that g(β0) = 0.
2.	Since WO is the minimizer of L(W), h0(0) = 0. Moreover, since L(W) is strictly convex,
h00(0) > 0. As a result, h0(β) > 0 for β > 0.
3.	Since wg^ is theminimizer ofLa (w), and La(W) is strictly convex, La((1-β)w0 +βwG^)
is strictly decreasing function.
Note that since h(β) = Pr{A = a}La((1 - β)wo + βwG^) + Pr{A = 1 - a}Lι-^((1 -
β)wo + βwG^) is strictly increasing and La((1 - β)wo + βwG^) is strictly decreasing,
we conclude that Lι-^((1 - β)w0 + βwG^) is strictly increasing. As a result, g should be
strictly decreasing.
Proof [Theorem 6] First, we show that if gY (0) ≤ 0, then WO satisfies γ-EL.
gγ(O) ≤ 0 =⇒ g(β) - Y ≤ 0 =⇒ La (WO) - Lι-a(WO) ≤ Y
Moreover, La (WO) - Lι-a(WO) ≥ 0 because a = argmax。La (WO). Therefore, Y-EL is satisfied.
Secondly, assume that g7(0) > 0. Under Assumption 1, g7(1) = La(wg&) - Lι-^(wg^) - γ < 0.
Therefore, by the intermediate value there exists β0 such that gY (β0) = 0. Moreover, gY is a
strictly decreasing function. Therefore, the binary search proposed in Algorithm 3 converges to root
of gγ (β). As a result, (1 - βm∞∞))WO + βm∞∞)WG^ satisfies satisfies γ-EL. Moreover, La (WO)-
Lι-a(WO) ≥ 0 because a = argmaxa La(WO). Note that since g(β) is decreasing, βm(∞id) is the
smallest possible β under which (1 - β)WO + Bwg^ γ-EL. Since h is increasing, the smallest
possible β gives us a better accuracy.
Proof [Theorem 7]
By the triangle inequality, the following holds,
sup ||L0(W) - L1(W)| - |L0(W) - L1(W)|| ≤ sup |L0(W) - L0(W)| + sup |L1(W) - L1(W)|.
fw ∈F	fw ∈F	fw ∈F
(23)
Therefore, with probability at least 1 - 2δ we have,
.., . . . ʌ	ʌ , ... _ , _ _ _ , _ _
SUp ∣∣Lο(w)	- Li(w)∣	- ∣Lο(w) -	Li(w)∣∣	≤ B(δ,no, F)	+ B(δ,nι, F)	(24)
fw ∈F
As a result, with probability 1 - 2δ holds,
, .. —.、 . . — . ʌ ʌ
{W∣fw ∈ F, ∣Lο(w) - Li(w)∣ ≤ γ} ⊆ {W∣fw ∈ F, |Lo(w) - Li(w)∣ ≤ γ}	(25)
Now consider the following,
L(W) — L(w*) = L(W) — L(W) + L(W) — L(w*) + L(w*) — L(w*)	(26)
By (25), L(W) - L(w* ) ≤ 0 with probability 1 - 2δ. Thus, with probability at least 1 - 2δ, we have,
L(W) — L(w*) ≤ L(W) — L(W) + L(w*) — L(w*).	(27)
Therefore, under assumption 3, we can conclude with probability at least 1 - 6δ, L(W) - L(w*) ≤
2B(δ, n, F). In addition, by (24), with probability at least 1 - 2δ, we have,
14
Under review as a conference paper at ICLR 2022
._	, . .	_	, . . .	_ , _	_ _ , _	__ . ʌ	Λ ,
∣Lo(w) - LI(W)I ≤ B(δ,n0,F) + B(δ,nι,F) + ∣L°(w) - Lι(w)∣
≤ Y + B(δ,no, F) + B(δ,nι, F) = Y + 2B(δ, n°, F) + 2B(δ,n∖, F)
15