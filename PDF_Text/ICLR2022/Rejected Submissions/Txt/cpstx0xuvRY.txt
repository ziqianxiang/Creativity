Under review as a conference paper at ICLR 2022
Information-Theoretic Generalization Bounds
for Iterative Semi-Supervised Learning
Anonymous authors
Paper under double-blind review
Abstract
We consider iterative semi-supervised learning (SSL) algorithms that iteratively
generate pseudo-labels for a large amount unlabelled data to progressively refine
the model parameters. In particular, we seek to understand the behaviour of the
generalization error of iterative SSL algorithms using information-theoretic prin-
ciples. To obtain bounds that are amenable to numerical evaluation, we first work
with a simple model—namely, the binary Gaussian mixture model. Our theoreti-
cal results suggest that when the class conditional variances are not too large, the
upper bound on the generalization error decreases monotonically with the number
of iterations, but quickly saturates. The theoretical results on the simple model
are corroborated by extensive experiments on several benchmark datasets such as
the MNIST and CIFAR datasets in which we notice that the generalization error
improves after several pseudo-labelling iterations, but saturates afterwards.
1 Introduction
In real-life machine learning applications, it is relatively easy and cheap to obtain large amounts of
unlabelled data, while the number of labelled data examples is usually small due to the high cost of
annotating them with true labels. In light of this, semi-supervised learning (SSL) has come to the
fore (Chapelle et al., 2006; Zhu, 2008; Van Engelen & Hoos, 2020). SSL makes use of the abundant
unlabelled data to augment the performance of learning tasks with few labelled data examples. This
has been shown to outperform supervised and unsupervised learning under certain conditions. For
example, in a classification problem, the correlation between the additional unlabelled data and the
labelled data may help to enhance the accuracy of classifiers. Among the plethora of SSL methods,
pseudo-labelling (Lee et al., 2013) has been observed to be a simple and efficient way to improve the
generalization performance empirically. In this paper, we consider the problem of pseudo-labelling
a subset of the unlabelled data at each iteration based on the previous output parameter and then
refining the model progressively, but we are interested in analysing this procedure theoretically. Our
goal in this paper is to understand the impact of pseudo-labelling on the generalization error.
A learning algorithm can be viewed as a randomized map from the training dataset to the output
model parameter. The output is highly data-dependent and may suffer from overfitting to the given
dataset. In statistical learning theory, the generalization error is defined as the expected gap between
the test and training losses, and is used to measure the extent to which the algorithms overfit to the
training data. In SSL problems, the unlabelled data are expected to improve the generalization
performance in a certain manner and thus, it is worthwhile to investigate the behaviour theoretically.
In this paper, we leverage results in Bu et al. (2020); Wu et al. (2020) to derive an information-
theoretic generalization error bound at each iteration for iterative SSL.
We state our main theoretical contribution informally as follows.
Theorem [Informal] For a d-variate binary Gaussian mixture model
(bGMM) in which each component has variance σ2, the generalization
error across the different semi-supervised training iterations |gen | can
be bounded with high probability as follows:
∣genj / const ∙ E [J G。(F、tT) (α)) ],	(1)
19f
簟
17
r∣ 16
a15
n 14
13
0	2	4	6	8	10
Figure 1: Upper bound on
|gent | as a function of t.
1
Under review as a conference paper at ICLR 2022
where α represents the correlation between the optimal and estimated parameter vectors, Fσ(t) is
the iterated composition of the function Fσ (sketched in Figure 3), and Gσ (sketched in Figure 5)
represents the KL-divergence between the pseudo-labelled and true data distributions.
As shown in Figure 1, the upper bound is monotonically decreasing in the iteration count t and
converges at around t =2with a sufficiently large amount of unlabelled data. In Section 4, we also
show that when the number of labelled data or the variance is large enough, using the unlabelled
data does not help to significantly reduce the generalization error across iterations t. The behaviour
of the empirical generalization error for the bGMM coincides with the upper bound. The results
suggest that the proposed upper bound serves as a useful guide to understand how the generalization
error changes across the semi-supervised training iterations and it can be used to establish conditions
under which unlabelled data can help in terms of generalization. Experimental results on the MNIST
and CIFAR datasets corroborate the phenomena for the bGMM that with few labelled data and
abundant unlabelled data, the generalization error decreases quickly in the early pseudo-labelling
iterations and saturates thereafter. For a more extensive literature review, please refer to Appendix A.
2 Problem Setup
Let the instance space be Z = X×Y⊂Rd+1, the model parameter space be Θ and the loss fucntion
be l : Z×Θ → R, where d ∈ N. We are given a labelled training dataset Sl = {Z1,...,Zn} =
{(Xi,Yi)}n=1 drawn from Z, where each Zi =(Xi,Yi) is independently and identically distributed
(i.i.d.) from PZ = PX,Y ∈P(Z) and Xi is i.i.d. from PX ∈ P(X). For any i ∈ [n], Xi is a vector
of features and Yi is a label indicating the class to which Xi belongs. However, in many real-life
machine learning applications, we only have a limited number of labelled data while we have access
to a large amount of unlabelled data, which are expensive to annotate. Then we can incorporate the
unlabelled training data together with the labelled data to improve the performance of the model.
This procedure is called semi-supervised learning (SSL). We are given an independent unlabelled
training dataset Su = {X10 ,...,Xτ0m},τ ∈ N, where each X0 is i.i.d. generated from PX ∈ P(X).
Typically, m》n.
In the following, we consider the iterative self-training with pseudo-labelling in SSL setup, as shown
in Figure 2. Let t ∈ [0 : τ] denote the iteration counter. In the initial round (t =0), the labelled data
Sl are first used to learn an initial model parameter θ0 ∈ Θ. Next, we split the unlabelled dataset Su
into τ disjoint equal-size sub-datasets {Su,k}τ=1, where Su,k = {X(0 -1) +1,...,X0 }. In each
subsequent round t ∈ [1 : τ], based on θt-1 trained from the previous round, we use a predictor
fθt-ι : X → Y to assign a pseudo-label 月0 to the unlabelled sample X0 for all i ∈ [(t - 1)m + 1 :
tm] := {(t — 1)m, (t — 1)m + 1,...,tm}. Let S^u,t = {(X0,Y0)}t=m^t--ιym+ι denote the tth pseudo-
labelled dataset. After pseudo-labelling, both the labelled data Sl and the pseudo-labelled data Su,t
are used to learn a new model parameter θt . The procedure is then repeated iteratively until the
maximum number of iterations τ is reached.
Figure 2: Paradigm of iterative self-training with pseudo-labelling in SSL.
Under the setup of iterative SSL, during each iteration t, our goal is to find a model parameter θt ∈ Θ
that minimizes the population risk with respect to the underlying data distribution
Lpz(θt) ：= EZ〜PZ [l(θt, Z)].	(2)
Since PZ is unknown, LPZ (θt) cannot be computed directly. Hence, we instead minimize the em-
pirical risk. The procedure is termed empirical risk minimization (ERM). For any model parameter
θt ∈ Θ, the empirical risk of the labelled data is defined as
1n
LSl (θt) ：= - X l(θt,Zi),	(3)
n i=1
2
Under review as a conference paper at ICLR 2022
and for t ≥ 1, the empirical risk of pseudo-labelled data Su,t as
tm
LSu,t(Ot) = m X	l(θt,(Xi,Yi)).
i=(t-1)m+1
(4)
We set L ^ t(θt) = 0 for t = 0. For a fixed weight W ∈ [0,1], the total empirical risk can be defined
as the following linear combination of LSl (θt) and L^u t(θt):
Lsl,Su,t (Ot)= WLSl(Ot) + (I- W)LSu,t(Ot).
(5)
An SSL algorithm can be characterized by a randomized map from the labelled and unlabelled
training data S∖, SU to a model parameter O according to a conditional distribution Pθ∣sl,su. Then
at each iteration t, we can use the sequence of conditional distributions {Pθk |Sl,Su}t =0 with
Pθo∣sl,su = Pθo∣sl to represent an iterative SSL algorithm. The generalization error at the t-th
iteration is defined as the expected gap between the population risk of Ot and the empirical risk on
the training data:
gent(PZ, PX, {Pθk∣Sl,Su }k=0, {fθk }k=0 ) := E[LPz (Ot)- LSl ,Su,t (Ot)]
=w✓Eθt [Ez[l(Ot,Z) | Ot]] - 1 XEθt,Zi[l(Ot,Zi)])
n i=1
(6)
1	tm
+ (1-w) Eθt [Ez [l(θt,Z) | Ot]] - m X	Eθt,χi,γo [l(θt, (X0,Y0))] .	(7)
i=(t-1)m+1
When t =0andw =1, the definition of the generalization error above reduces to that of vanilla
supervised learning. The generalization error gent is used to measure the extent to which the it-
erative learning algorithm overfits the training data at the t-th iteration. Instead of focusing on the
total generalization error induced during the entire process, we are more interested in the following
questions. How does gent evolve as the iteration count t increases? Do the unlabelled data examples
in Su help to improve the generalization error?
3	Preliminaries
Inspired by the information-theoretic generalization results in Bu et al. (2020, Theorem 1) and Wu
≡(2020, Theorem 1), We derive an upper bound on the generalization error gent for any t ∈
] in terms of the mutual information between input data samples (either labelled or pseudo-
labelled) and the output model parameter Ot, as well as the KL-divergence between the underlying
data distributions and the joint distribution of feature vectors and pseudo-labels.
We denote an R-SUb-GaUSSian random variable L ∈ R (Vershynin, 2018) as L 〜SUbG(R). Fur-
thermore, let us recall the following non-standard information quantities.
Definition 1. For arbitrary random variables X, Y and U, define the disintegrated mutual infor-
mation (Negrea et al., 2019; Haghifam et al., 2020) between X and Y given U as IU(X; Y):=
D(Pχ,γ|ukPχ∖u ③ Py|u), and the disintegrated KL-divergence between PX and Pγ given U as
DU (PX kPY):=D(PX|UkPY|U). These are σ(U)-measurable random variables. It follows imme-
diately that the conditional mutual information I(X; Y|U) = EU[IU(X; Y)] and the conditional
KL-divergence D(Pχ∣u∣∣Pγ∣u|Pu) = EU[Du(Pχ∣∣Pγ)].
Let O(t) =(O0,...,Ot) for any t ∈ [0 : τ]. In iterative SSL, we can upper bound the generalization
error as shown in Theorem 1 to follow by applying the law of total expectation.
Theorem 1 (Generalization error upper bound for iterative SSL). Suppose l(O, Z) 〜subG(R)
under Z 〜PZ for all O ∈ Θ, thenfor any t ∈ [0 : T],
n
Igent(PZ ,Pχ, {Pθk∣Sl,Su }k=o, {fθk }k=0)∣ ≤ n X Eθ(t-1) hP2R2Iθ(t-1) (Ot； Zi)i
i=1
tm	___________________________________________
+ʒmW	X	Eθ(t-i) hq2R2(Iθ(t-1)(Ot; X0,Y0) + Dθ(t-1) (Pχi,γo kPz))].	(8)
i=(t-1)m+1
3
Under review as a conference paper at ICLR 2022
The proof of Theorem 1 is provided in Appendix B, in which we provide a general version of
upper bound not only applicable for sub-Gaussian loss functions. Compared to Bu et al. (2020,
Theorem 1) and Wu et al. (2020, Theorem 1), this bound focuses on the generalization error at each
iteration during the learning process, which depends on the disintegrated mutual information and
the disintegrated KL-divergence conditioned on the previous outputs. Intuitively, in the upper bound
in Theorem 1, the mutual information between the individual input data sample Zi and the output
model parameter θt measures the extent to which the algorithm is sensitive to the input data, and
the KL-divergence between the underlying PZ and pseudo-labelled distribution PX，^，
i, i
measures
how well the algorithm generalizes to the true data distribution. As n →∞and m →∞, we
i	,ι , , i τ ∙	, 1	, i ∙ i`	. ∙ τ	/∕ι ʌr / -∕z^/ ∖ , ι , zʌ ∕∙	KK ∙ ι ∙ , ∖ ι ∙ ι
show that the disintegrated mutual information Iθ(t-1) (θt; X0, Y0) tends to 0 (in probability), which
means that there are sufficient training data such that the algorithm can generalize well. On the other
hand, the impact on the generalization error of pseudo-labelling is reflected in the KL-divergence
De(t-i)(Pxo ^o ∣∣Pz) and this term does not necessarily vanish as n, m → ∞. We quantify this
i, i
precisely in Remark 1 in Section 4.
In iterative learning algorithms, it is usually difficult to directly calculate the mutual information
and KL-divergence between the input and the final output (Paninski, 2003; Nguyen et al., 2010;
McAllester & Stratos, 2020). However, by applying the law of total expectation and conditioning
the information-theoretic quantities on the output model parameters θ(t-1) = {θ1,...,θt-1} from
previous iterations, we are able to calculate the upper bound iteratively. In the next section, we
apply the iterated generalization error bound to a classification problem under a specific generative
model—the bGMM. This simple model allows us to derive a tractable upper bound on the general-
ization error as a function of iteration number t that we can compute numerically.
4 Main Results
We now particularize the iterative semi-supervised classification setup to the bGMM. We calculate
the term in (8) to understand the effect of multiple self-training rounds on the generalization error.
Fix a unit vector μ ∈ Rd and a scalar σ ∈ R+ = (0, ∞). Under the bGMM with mean μ and
standard deviation σ (bGMM(μ, σ)), We assume that the distribution of any labelled data example
(X, Y) is specified as follows. Let Y = {-1, +1}, Y 〜PY, where PY (-1) = PY (1) = 1, and
X|Y 〜N(Yμ, σ1 2Id), where Id is the identity matrix of size d X d. In anticipation of leveraging
Theorem 1 together with the sub-Gaussianity of the loss function for the bGMM to derive gener-
alization bounds in terms of information-theoretic quantities (just as in Russo & Zou (2016); Xu
& Raginsky (2017); Bu et al. (2020)), we find it convenient to show that X and l(θ, (X,Y)) are
bounded w.h.p.. By defining the '∞ ball By := {x ∈ Rd : ∣X — yμ∣∣∞ ≤ r}, we see that
d
Pr(X ∈BrY)
:1
- δr,d ,
(9)
where Φ(∙) is the Gaussian cumulative distribution function. By choosing r appropriately, the failure
probability δr,d can be made arbitrarily small.
The random vector X is distributed according to the mixture distribution pμ = 2N(μ, σ2Id) +
1N(-μ, σ2Id). In the unlabelled dataset Su, each X0 for i ∈ [1 : Tm] is drawn i.i.d. from pμ.
For any θ ∈ Θ, under the bGMM(θ, σ), the joint distribution of any pair of (X, Y) ∈Zis given by
N(Yθ, σ2Id) 0 PY. Let the loss function be the negative log-likelihood, which can be expressed as
l(θ, (X,y)) = TOg(PY (y)Pθ (XIy)) = - log 2p2∏p 羡 十 ,(X - yθ)>(x -通.(IO)
The minimizer of mine∈θ E(x,y)〜N(Y读/Id)OPY [l(θ, (X, Y))] is equal to μ. To show that θ is
bounded with high probability, define the set Θμ,c := {θ ∈ Θ : ∣θ 一 μ∣∞ ≤ c} for some c > 0.
For any θ ∈ Θμ,c, we have
min l(θ, (x, y)) = 一 log ——,1 - =:ci, and
(x,y)∈Z	2 P (2π)dσ d
1	d(c + r)2
max	l(θ, (x,y)) ≤ 一log ——,	----1------——
χ∈By,y∈Y I '	2P(2∏)dσd	2σ2
: c2 .
(11)
(12)
4
Under review as a conference paper at ICLR 2022
For any (X, Y) from the bGMM(μ, σ) and any θ ∈ Θμ,c, the probability that l(θ, (X, Y)) belongs
to the interval [c1,c2] (c1, c2 depend on δr,d) can be lower bounded by
Pr (l(θ, (X, Y)) ∈ [ci, c2]) ≥ 1 - δr,d∙	(13)
Thus, according to Hoeffding's lemma, with probability at least 1 - δr,d, l(θ, (X, Y)) ~ SUbG((C2 -
ci )/2) under (X, Y) ~ N (Y μ, σ2Id)於 Pγ for all θ ∈ Θμ,c, i.e., for all λ ∈ R,
Ex,y [exp (λ(l(θ, (X,Y)) - Eχ,γ[l(θ, (X,Y))]))] ≤ exp
^λ2(C2 - ci)2)
(14)
Under this setup, the iterative SSL procedure is shown in Figure 2, but the labelled dataset Sl is only
used to train in the initial round t =0; we discuss the use of Sl in all iterations in Corollary 3. The
algorithm operates in the following steps.
•	Step 1: Initial round t =0with Sl: By minimizing the empirical risk of labelled dataset Sl
nn
LSl (θ) = — ^X l(θ, (Xi, 匕))=2 2 ^X(Xi -匕θ)> (Xi- Yiθ),	(15)
n i=1	2σ n i=1
where =c means that both sides differ by a constant independent of θ, we obtain the minimizer
θ0 = argminLSl(θ)
θ∈Θ
1n
-X 匕 Xi.
n i=1
(16)
•	Step 2: Pseudo-label data in Su: At each iteration t ∈ [1 : τ], for any i ∈ [(t - 1)m +1 : tm],
we use θt-ι to assign a pseudo-label for Xi, that is, Yi0 = fe1 (Xi) = sgn(θt-1Xi).
•	Step 3: Refine the model: We then use the pseudo-labelled dataset Su,t to train the new model.
By minimizing the empirical risk of Su,t
tm	tm
LSu,t (θ) = m	X	l(θ, (Xi,Y0)) = 2σ2m	X	(Xi - ⅛θ)>(Xi - Y0” (17)
i=(t-1)m+1	i=(t-1)m+1
we obtain the new model parameter
tm	tm
θt = m X	YOXi = m X	sgn(θ3Xi)Xi.	(18)
i=(t-1)m+1	i=(t-1)m+1
If t<τ, go back to Step 2.
To state our result succinctly, we first define some non-standard notations and functions. From (16),
We know that θo ~ N(μ, σId) and inspired by Oymak & Gulcu (2021), We can decompose θo as
θo = (1 + √ξo)μ + √μ⊥, where ξo ~ N(0, 1), μ⊥ ~ N(0, Id - μμ 1 ),and μ⊥ is perpendicular
to μ and independent of ξo (the details of this decomposition are provided in Appendix C).
Given two vectors (a, b), define their correlation as ρ(a, b) := 1珑]%? in [-1, 1]. The correlation
between the estimated parameter θ° and true parameter μ is given by
α(ξo, μ⊥) ：= ρ(θo, μ)
_______1 + √⅛ ξ0______
√(1 + √σn ξo)2 + σ2 kμ⊥k2
(19)
Let β(ξo, μ⊥) = p1 - α(ξo, μ⊥)2. We abbreviate α(ξo, μ⊥) and β(ξo, μ⊥) to ɑ and β respec-
tively in the following. We can decompose the normalized vector Θ0∕∣∣θ0k2 as follows
θo :
θo
αμ + βυ,
(20)
5
Under review as a conference paper at ICLR 2022
where U = μ⊥∕kμ⊥k2. Let θ⊥ := (2β 2μ - 2ɑβυ)∕σ, which is a vector perpendicular to θ0.
Define the KL-divergence between the pseudo-labelled data distribution and the true data distribu-
tion after the first iteration Gσ : [-1, 1] × R × Rd → [0, ∞) as
Gσ (α, ξo, μ⊥):= d(φ( -a >g+ 等 ∣g≤ -α Ig) Pg⊥+θ⊥ + 中(| M∣g≤ α Ig) Pg⊥[g Ig) Pg j，(21)
where g 〜 N(0,1), g⊥ 〜 N(0, Id - θoθ>), g⊥ is independent of g and perpendicular to %.
Note that p~+ 2α ∣~≤-α is the Gaussian probability density function with mean 2α and variance 1
truncated to the interval (-∞, -α), and similarly for Pg∣g≤α. In general, when Gσ(α, ξo, μ⊥) is
small, so is the generalization error.
Let Q(∙) := 1 — Φ(∙). Define the correlation evolution function Fσ : [-1,1] → [-1,1] that
quantifies the increase to the correlation (between the current model parameter and the optimal one)
and improvement to the generalization error as the iteration counter increases from t to t +1:
(22)
Figure 3: Fσ(t) (x) versus x for
different t when σ = 0.5.
Figure 4:	Fσ (x) versus x for
σ =0.3 and 0.5.
Figure 5:	Gσ (α) versus α for
different σ.
The tth iterate of the function Fσ is defined as Fσ(t) := Fσ ◦ Fσ(t-1) with Fσ(0) (x)=x. As shown
in Figure 3, for any fixed σ, we can see that Fσ(2) (x) ≥ Fσ(x) ≥ x for x ≥ 0 and Fσ(2)(x) <
Fσ(x) <xfor x<0. It can also be easily deduced that for any t ∈ [0 : τ], Fσ(t+1) (x) ≥ Fσ(t)(x)
for any x ≥ 0 and Fσ(t+1)(x) < Fσ(t)(x) for any x<0. This important observation implies that if
the correlation α, defined in (19), is positive, Fσ(t)(α) increases with t; and vice versa. Moreover, as
shown in Figure 4, by varying σ, We can see that smaller σ results in a larger ∣Fσ(x)|.
By applying the result in Theorem 1, the following theorem provides an upper bound for the gener-
alization error at each iteration t for m large enough.
Theorem 2. Fix any σ ∈ R+, d ∈ N, e ∈ R+ and δ ∈ (0,1). With probability at least 1 — δ, the
absolute generalization error at t =0can be upper bounded as follows
Mo(PZ,Px,ρθo∣sι,su)∣ ≤ r(c2 4ci) dlogn-ɪ.	(23)
For each t ∈ [1 : τ],for m large enough, with probability at least 1 - δ,
∣gent(pZ,PX, {Pθk ∣Sι,Su }tk=0, {fθk }k=0)∣
≤ r (c2 ~ c1)2 Eξ0,μ⊥ ,Gσ (Fσt-1)(α(ξ0, μ⊥)), ξo,μ⊥) + e .	(24)
The proof of Theorem 2 is provided in Appendix C. Several remarks are in order.
First, to gain more insight, we numerically plot Gσ(α, ξ0, μ⊥) when d = 2 and μ = (1,0) in
Figure 5. Under these settings, Gσ(α, ξ0, μ⊥) depends only on α and hence, we can rewrite it
as Gσ(α). As shown in Figure 5, for all σ1 >σ2, there exists an α0 ∈ [-1, 1] such that for all
6
Under review as a conference paper at ICLR 2022
Ooooo
0 5 0 5
PnnOqJoXla noI3«ezqe.Iaa9D
30
20
10

(a) σ =0.3	(b) σ =0.7	(c) n =10,σ = 0.6. Empir- (d) n =20, σ =3
ical simulation with d =50.
Figure 6: (a) and (b): Upper bounds for generalization error at t =0and t = 1 under different σ when d =2
and μ = (1, 0). (C) and (d): The comparison between the upper bound for ∣genj and the empirical
generalization error at each iteration t. The upper bounds are both for d =2.
α ≥ α0 = α0(σ1,σ2), Gσ1 (α) >Gσ2 (α). From (19), we can see that α is close to 1 of high
probability, which means that σ 7→ Gσ (α) is monotonically increasing in σ with high probability.
As a result, Eα[pGσ(α)] increases as σ increases. This is consistent with the intuition that when
the training data has larger variance, it is more difficult to generalize well. Moreover, for α > 0,
Gσ(α) decreases as α increases. Since Fσ(t) (α) is increasing in t for α>0, then Gσ(Fσ(t) (α)) is
decreasing in t, which implies that the upper bound in (24) is also decreasing in t.
Remark 1. As n → ∞, θo → μ and α = ρ(θo, μ) → 1 almost surely, which means that the
estimator converges to the optimal classifier for this bGMM. However, since there is no margin
1	，	r 1 .	t,ι	ι ι ∙ι ∙. tλ /W/ Z ʌ z^∕ ∖ rʌ / r / ∖ 、 r> / ι ∙ ι
between two groups of data samples, the error probability Pr(Y0 = Y0) → Q(1∕σ) > 0 (which
is the Bayes error rate) and the disintegrated KL-divergence Dξ0,μ⊥
(PXjM kpχ,Y)
between the
estimated and underlying distributions cannot converge to 0. We discuss the other extreme case in
which α = -1 in Remark 2 in Appendix C of the supplementary material.
Second, by letting e → 0, we compare the upper bounds for ∣gen°∣ and ∣gen∕, as shown in Fig-
ures 6(a) and 6(b). For any fixed σ, when n is sufficiently small, the upper bound for |gen0 | is
greater than that for |gen1 |. As n increases, the upper bound for |gen1| surpasses that of |gen0|, as
shown in Figure 6(b). This is consistent with the intuition that when the labelled data is limited, us-
ing the unlabelled data can help improve the generalization performance. However, as the number of
labelled data increases, using the unlabelled data may degrade the generalization performance, if the
distributions corresponding to classes +1 and -1 have a large overlap. This is because the labelled
data is already effective in learning the unknown parameter θt well and additional pseudo-labelled
data does not help to further boost the generalization performance. Furthermore, by comparing Fig-
ures 6(a) and 6(b), we can see that for smaller σ, the improvement from |gen0| to |gen1 | is more
pronounced. The intuition is that when σ decreases, the data samples have smaller variance and
thus the pseudo-labelling is more accurate. In this case, unlabelled data can improve the general-
ization performance. Let us examine the effect of n, the number of labelled training samples. By
expanding α, defined in (19), using a Taylor series, we have
α = 1 - 3-kμ⊥k2 + o(_).	(25)
2n	n
It can be seen that as n increases, α converges to 1 in probability. Suppose the dimension d =2
and μ = (1,0). Then μ⊥ = [0,μ⊥] where μ⊥ 〜N(0,1). The upper bound for the absolute
generalization error at t =1can be rewritten as
|geni| / r(C2 - CI) Z	√√ne-n2 PGσ(1 - y2) dy,	(26)
2	√-√2 √∏σ
which is a decreasing function of n, as shown in Figures 6(a) and 6(b).
Third, given any pair of (ξo, μ⊥), if α(ξo, μ⊥) > 0, F!"(a(£o, μ⊥)) > F∣tT)(α(ξo, μ⊥)) for all
t ∈ [1 : τ], as shown in Figure 3. This means that if the quality of the labelled data Sl is reasonably
good, by using θ0 which is learned from Sl , the generated pseudo-labels for the unlabelled data
are largely correct. Then the subsequent parameters θt,t ≥ 1 learned from the large number of
pseudo-labelled data examples can improve the generalization error. Therefore, the upper bound
for |gent| decreases as t increases. In Figure 6(c), we plot the theoretical upper bound in (24) by
7
Under review as a conference paper at ICLR 2022
ignoring e. Unfortunately it is computationally difficult to numerically calculate the bound in (24)
for high dimensions d (due to the need for high-dimensional numerical integration), but we can still
gain insight from the result for d =2. It is shown that the upper bound for |gent | decreases as
t increases and finally converges to a non-zero constant. The gap between the upper bounds for
|gent| and for |gent+1 | decreases as t increases and shrinks to almost 0 for t ≥ 2. The intuition
is that as m →∞, there are sufficient data at each iteration and the algorithm can converge at
very early stage. In the empirical simulation, We let d = 50, μ =(1,0,..., 0) and iteratively
run the self-training procedure for 20 iterations and 2000 rounds. We find that the behaviour of
the empirical generalization error (the red ‘-x’ line) is similar to the theoretical upper bound (the
blue ‘-o’ line), Which almost converges to its final value at t =2. This result shoWs that the
theoretical upper bound in (24) serves as a useful rule-of-thumb for hoW the generalization error
changes over iterations. In Figure 6(d), We plot the theoretical bound and result from the empirical
simulation based on the toy example for d =2but larger n and σ. This figure shoWs that When We
increase n and σ, using unlabelled data may not be able to improve the generalization performance.
The intuition is that for n large enough, merely using the labelled data can yield sufficiently loW
generalization error and for subsequent iterations With the pseudo-labelled data, the reduction in
the test loss is negligible but the training loss Will decrease more significantly (thus causing the
generalization error to increase). When σ is larger, the data samples have larger variance and the
classes have a larger overlap, and thus, the initial parameter θ0 learned by the labelled data cannot
produce pseudo-labels With sufficiently high accuracy. Thus, the pseudo-labelled data cannot help
to improve the generalization error significantly.
Fourth, We consider an “enhanced” scenario in Which the labelled data in Sl are reused in each
iteration. Set W = n+m in (5). We can extend Theorem 2 to Corollary 3 as folloWs. Similarly to Fσ,
let us define the enhanced correlation evolution function Fσ,ξ0,μ⊥ : [-1,1] → [-1,1] as follows:
Fσ,ξo,μ⊥ (X)
-1
(Wσkn⅛ + (1- w)(2⅝F exp(-S))2	∖ 2
(w(1 + √ξ0) + (1- w)(1- 2Q(X) + 舞 exp(-春铲)
(27)
Corollary 3. Fix any σ ∈ R+ , d ∈ N, e ∈ R+ and δ ∈ (0, 1). For m large enough, with probability
at least 1 - δ, the absolute generalization error at any t ∈ [1 : τ] can be upper bounded as follows
∣gent(pZ,PX, {Pθk ∣Sι,Su
}k=0, {fθk }k=0)∣≤ Wr(C2 -4c1)2d
log
n
n-1
+ (1 - W)r(C2 -2c1)2 Eξ0,μ⊥ ]qGσ(Et-iμ⊥ m(ξ0,μ⊥)), ξ0, μ⊥) + e 1.	(28)
The details are provided in Appendix D and the proof of Corollary 3 is provided in Appendix E. It
can be seen from Figure 11 that the new upper bound for |gent| remains as a decreasing function
of t. We find that when n = 10, m = 1000, the upper bound is almost the same as that one in
Figure 6(c), which means that for large enough m, reusing the labelled data does not necessarily
help to improve the generalization performance. Moreover, when m = 100, the upper bound is
higher than that for m = 1000, which coincides with the intuition that increasing the number of
unlabelled data helps to reduce the generalization error.
5	Experimental Results
In Sections 3 and 4, we theoretically analyse the upper bound of generalization error across the iter-
ations for iterative self-training and especially for the case of bGMM classification. In this section,
we conduct experiments on real datasets to demonstrate that our theoretical results on the bGMM
example can also reflect the training dynamics on complicated tasks.
We train deep neural networks via a iterative self-learning strategy (under the same setting as that
for Corollary 3) to perform binary and multi-class classification tasks. In the first iteration, we only
use the labelled data to optimize the deep neural network (DNN) and train the model for a relatively
large number of epochs so that the training loss will converge to a small value and the model is
initialized well. In the following iterations, we first sample a subset of unlabelled data from the
whole set and generate pseudo-labels for them via the model trained in the previous iteration. Then,
we update the model for a small number of epochs with both the labelled and pseudo-labelled data.
8
Under review as a conference paper at ICLR 2022
Experimental settings: For binary classification, we collect pairs of classes of images, i.e., “au-
tomobile” and “truck”, “horse” and “ship”, from the CIFAR10 (Krizhevsky, 2009) dataset. In this
dataset, each class has 5000 images for training and 1000 images for testing. We use the whole set
of images in the selected pair of categories and divide them into two sets, i.e., the labelled training
set with 500 images and the unlabelled training set with 9500 images. We train a convolutional
neural network, ResNet-10 (He et al., 2016), to minimize the cross-entropy loss via the self-learning
strategy to perform the binary classification. The model is trained for 100 epochs in the first iteration
and 20 epochs in the following iterations; we use the Adam (Kingma & Ba, 2015) optimizer with
a learning rate of 0.001. In each iteration after the initial one, we sample 2500 unlabelled images
assign them pseudo-labels. The complete training procedure lasts for 100 self-training iterations.
We further validate our theoretical contributions on a multi-class classification problem in which we
train a ResNet-6 model with the cross-entropy loss to perform 10-class handwritten digits classifi-
cation on the MNIST (LeCun et al., 1998) dataset. We sample 51000 images from the training set,
which contains 6000 images for each of the ten classes. We divide them into two sets, i.e., a labelled
training set with 1000 images and an unlabelled set with 50000 images. The optimizer and training
iterations follow those in the aforementioned binary classification tasks.
Experimental observations: We perform each experiment 3 times and report the average test and
training (cross entropy) losses, the generalization error, and test and training accuracies in Figures∣7-
9. The generalization error appears to have relatively large reduction in the early training iterations
and then fluctuates around a constant value afterwards. For example, in Figure 7, the generalization
error converges to around 0.25 after 30 iterations; in Figure 8, it converges to around 0.4 after 10
iterations; in Figure 9, it converges to around 0.1 after 12 iterations. These results corroborate
the theoretical and empirical analyses in the bGMM case, which again verifies the validity of the
proposed generalization error bound in Theorem 2 and Corollary 3 on benchmark datasets. It also
reveals that the generalization performance of iterative self-training on real datasets from relatively
distinguishable classes can be quickly improved with the help of unlabelled data. We also show
that the test accuracy increases with the iterations and has significant improvement compared to the
initial iteration when only labelled data are used. In Figure 7, the highest accuracy has about a 4%
increase from the initial point; in Figure 8, there is about a 10% increase; and in Figure 9, there
is about a 3% increase. Thus, these numerical results suggest that via iterative self-training with
pseudo-labelling, not only can we improve the generalization error as the iteration count increases,
but we can also enhance the test accuracy. In addition, apart from the “horse-ship” and “automobile-
truck” pairs (that are relatively easy to distinguish based on the high classification accuracy and low
loss as shown in Figures 7 and 8), we also perform another experiment (detailed in Appendix F) on a
harder-to-distinguish pair, “cat” and “dog” (see Table 1), whose results show that the generalization
error does not decrease with the iterations even though the classification accuracy increases. This
again corroborates the results in Figure 6(d) for the bGMM with large variance.
Figure 7: Binary classification on
the “horse” and “ship” classes from
the CIFAR10 dataset.
0 10 20 30 40 50 60 70 80 90
Figure 8: Binary classification on
the “automobile” and “truck”
classes from the CIFAR10 dataset.
0 10 20 30 40 50 60 70 80 90
Figure 9: 10-class classification on
the MNIST handwritten digits
dataset.
9
Under review as a conference paper at ICLR 2022
References
StePhane Boucheron, Olivier Bousquet, and Gabor Lugosi. Theory of classification: A survey of
some recent advances. ESAIM: Probability and Statistics, 9:323-375, 2005.
Stephane Boucheron, Gabor Lugosi, and Pascal Massart. Concentration Inequalities: A NonasymP-
totic Theory of Independence. Oxford University Press, 2013.
Yuheng Bu, Shaofeng Zou, and Venugopal V Veeravalli. Tightening mutual information based
bounds on generalization error. IEEE Journal on Selected Areas in Information Theory, 1(1):
121-130, 2020.
Kaidi Cao, Colin Wei, Adrien Gaidon, Nikos Arechiga, and Tengyu Ma. Learning imbalanced
datasets with label-distribution-aware margin loss. In Proceedings of the 33rd International Con-
ference on Neural Information Processing Systems, pp. 1567-1578, 2019.
Yair Carmon, Aditi Raghunathan, Ludwig Schmidt, Percy Liang, and John C Duchi. Unlabeled data
improves adversarial robustness. In Proceedings of the 33rd International Conference on Neural
Information Processing Systems, pp. 11192-11203, 2019.
Olivier Chapelle, Bernhard Schlkopf, and Alexander Zien (eds.). Semi-SuPervised Learning.
The MIT Press, 2006. ISBN 9780262033589. URL http://dblp.uni-trier.de/db/
books/collections/CSZ2006.html.
Nitesh V Chawla and Grigoris Karakoulas. Learning from labeled and unlabeled data: An empirical
study across techniques and domains. Journal of Artificial Intelligence Research, 23:331-366,
2005.
Robert Dupre, Jiri Fajtl, Vasileios Argyriou, and Paolo Remagnino. Improving dataset volumes
and model accuracy with semi-supervised iterative self-learning. IEEE Transactions on Image
Processing, 29:4337-4348, 2019.
Amedeo Roberto Esposito, Michael Gastpar, and Ibrahim Issa. Generalization error bounds via
Renyi-, f -divergences and maximal leakage. IEEE Transactions on Information Theory, 67(8):
4986-5004, 2021. doi: 10.1109/TIT.2021.3085190.
Mahdi Haghifam, Jeffrey Negrea, Ashish Khisti, Daniel M Roy, and Gintare Karolina Dziugaite.
Sharpened generalization bounds based on conditional mutual information and an application to
noisy, iterative algorithms. Advances in Neural Information Processing Systems, 33:9925-9935,
2020.
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recog-
nition. In Proceedings of the IEEE Conference on ComPuter Vision and Pattern Recognition, pp.
770-778, 2016.
Sharu Theresa Jose and Osvaldo Simeone. Information-theoretic bounds on transfer generalization
gap based on Jensen-Shannon divergence. arXiv PrePrint arXiv:2010.09484, 2020.
Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In Yoshua
Bengio and Yann LeCun (eds.), 3rd International Conference on Learning RePresentations, ICLR
2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings, 2015. URL http:
//arxiv.org/abs/1412.6980.
A Krizhevsky. Learning multiple layers of features from tiny images. Master’s thesis, University of
Toronto, 2009.
Yann LeCun, Leon Bottou, Yoshua Bengio, and Patrick Haffner. Gradient-based learning applied to
document recognition. Proceedings of the IEEE, 86(11):2278-2324, 1998.
Dong-Hyun Lee et al. Pseudo-label: The simple and efficient semi-supervised learning method for
deep neural networks. In WorkshoP on Challenges in RePresentation Learning, ICML, volume 3,
pp. 896, 2013.
10
Under review as a conference paper at ICLR 2022
Jian Li, Yong Liu, Rong Yin, and Weiping Wang. Multi-class learning using unlabeled samples:
Theory and algorithm. In IJCAI,pp. 2880-2886, 2019.
Adrian Tovar Lopez and Varun Jog. Generalization error bounds using wasserstein distances. In
2018 IEEE Information Theory Workshop (ITW), pp. 1-5. IEEE, 2018.
David McAllester and Karl Stratos. Formal limitations on the measurement of mutual information.
In International Conference on Artificial Intelligence and Statistics, pp. 875-884. PMLR, 2020.
Jeffrey Negrea, Mahdi Haghifam, Gintare Karolina Dziugaite, Ashish Khisti, and Daniel M Roy.
Information-theoretic generalization bounds for SGLD via data-dependent estimates. In Advances
in Neural Information Processing Systems, pp. 11013-11023, 2019.
XuanLong Nguyen, Martin J Wainwright, and Michael I Jordan. Estimating divergence functionals
and the likelihood ratio by convex risk minimization. IEEE Transactions on Information Theory,
56(11):5847-5861, 2010.
Samet Oymak and Talha Cihad Gulcu. A theoretical characterization of semi-supervised learning
with self-training for gaussian mixture models. In International Conference on Artificial Intelli-
gence and Statistics, pp. 3601-3609. PMLR, 2021.
Liam Paninski. Estimation of entropy and mutual information. Neural Computation, 15(6):1191-
1253, 2003.
Ankit Pensia, Varun Jog, and Po-Ling Loh. Generalization error bounds for noisy, iterative algo-
rithms. In 2018 IEEE International Symposium on Information Theory (ISIT), pp. 546-550. IEEE,
2018.
Daniel Russo and James Zou. Controlling bias in adaptive data analysis using information theory.
In Artificial Intelligence and Statistics, pp. 1232-1240, 2016.
Aarti Singh, Robert Nowak, and Jerry Zhu. Unlabeled data: Now it helps, now it doesn’t. Advances
in Neural Information Processing Systems, 21:1513-1520, 2008.
Thomas Steinke and Lydia Zakynthinou. Reasoning about generalization via conditional mutual
information. In Conference on Learning Theory, pp. 3437-3452. PMLR, 2020.
Isaac Triguero, Salvador Garcia, and Francisco Herrera. Self-labeled techniques for semi-supervised
learning: taxonomy, software and empirical study. Knowledge and Information Systems, 42(2):
245-284, 2015.
Jesper E Van Engelen and Holger H Hoos. A survey on semi-supervised learning. Machine Learn-
ing, 109(2):373-440, 2020.
V. Vapnik. The Nature of Statistical Learning Theory. Springer, 2000.
Roman Vershynin. High-Dimensional Probability: An Introduction with Applications in Data Sci-
ence. Cambridge Series in Statistical and Probabilistic Mathematics. Cambridge University Press,
2018. doi: 10.1017/9781108231596.
Xuetong Wu, Jonathan H Manton, Uwe Aickelin, and Jingge Zhu. Information-theoretic analysis
for transfer learning. In 2020 IEEE International Symposium on Information Theory (ISIT), pp.
2819-2824. IEEE, 2020.
Aolin Xu and Maxim Raginsky. Information-theoretic analysis of generalization capability of learn-
ing algorithms. In Advances in Neural Information Processing Systems, pp. 2524-2533, 2017.
Xiaojin Zhu and Andrew B Goldberg. Introduction to semi-supervised learning. Synthesis Lectures
on Artificial Intelligence and Machine Learning, 3(1):1-130, 2009.
Xiaojin Jerry Zhu. Semi-supervised learning literature survey. 2008.
11